 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.5
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.276565
 >> iter 2000, loss: 9.097233
 >> iter 3000, loss: 3.836476
 >> iter 4000, loss: 1.650547
 >> iter 5000, loss: 0.694372
 >> iter 6000, loss: 0.376843
 >> iter 7000, loss: 0.165257
 >> iter 8000, loss: 0.077936
 >> iter 9000, loss: 0.035596
 >> iter 10000, loss: 0.027205
   Number of active neurons: 10
 >> iter 11000, loss: 0.041341
 >> iter 12000, loss: 0.018913
 >> iter 13000, loss: 0.011400
 >> iter 14000, loss: 0.007114
 >> iter 15000, loss: 0.053197
 >> iter 16000, loss: 0.026390
 >> iter 17000, loss: 0.012535
 >> iter 18000, loss: 0.006947
 >> iter 19000, loss: 0.033313
 >> iter 20000, loss: 0.014796
   Number of active neurons: 10
 >> iter 21000, loss: 0.007437
 >> iter 22000, loss: 0.004390
 >> iter 23000, loss: 0.003106
 >> iter 24000, loss: 0.002595
 >> iter 25000, loss: 0.070383
 >> iter 26000, loss: 0.029025
 >> iter 27000, loss: 0.033948
 >> iter 28000, loss: 0.022231
 >> iter 29000, loss: 0.010701
 >> iter 30000, loss: 0.005715
   Number of active neurons: 10
 >> iter 31000, loss: 0.003577
 >> iter 32000, loss: 0.002597
 >> iter 33000, loss: 0.002223
 >> iter 34000, loss: 0.001941
 >> iter 35000, loss: 0.001806
 >> iter 36000, loss: 0.001791
 >> iter 37000, loss: 0.001617
 >> iter 38000, loss: 0.001450
 >> iter 39000, loss: 0.001334
 >> iter 40000, loss: 0.013920
   Number of active neurons: 10
 >> iter 41000, loss: 0.006079
 >> iter 42000, loss: 0.003092
 >> iter 43000, loss: 0.001903
 >> iter 44000, loss: 0.001440
 >> iter 45000, loss: 0.001240
 >> iter 46000, loss: 0.001164
 >> iter 47000, loss: 0.001095
 >> iter 48000, loss: 0.009681
 >> iter 49000, loss: 0.014956
 >> iter 50000, loss: 0.006478
   Number of active neurons: 10
 >> iter 51000, loss: 0.003264
 >> iter 52000, loss: 0.001947
 >> iter 53000, loss: 0.001507
 >> iter 54000, loss: 0.001230
 >> iter 55000, loss: 0.001085
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.315095
 >> iter 2000, loss: 9.521871
 >> iter 3000, loss: 5.636584
 >> iter 4000, loss: 2.690970
 >> iter 5000, loss: 1.114718
 >> iter 6000, loss: 0.534767
 >> iter 7000, loss: 0.245626
 >> iter 8000, loss: 0.237616
 >> iter 9000, loss: 0.123652
 >> iter 10000, loss: 0.070884
   Number of active neurons: 10
 >> iter 11000, loss: 0.035371
 >> iter 12000, loss: 0.073502
 >> iter 13000, loss: 0.083289
 >> iter 14000, loss: 0.035388
 >> iter 15000, loss: 0.034214
 >> iter 16000, loss: 0.016365
 >> iter 17000, loss: 0.064327
 >> iter 18000, loss: 0.087374
 >> iter 19000, loss: 0.048772
 >> iter 20000, loss: 0.076693
   Number of active neurons: 10
 >> iter 21000, loss: 0.104796
 >> iter 22000, loss: 0.074426
 >> iter 23000, loss: 0.073697
 >> iter 24000, loss: 0.059436
 >> iter 25000, loss: 0.050836
 >> iter 26000, loss: 0.022491
 >> iter 27000, loss: 0.064065
 >> iter 28000, loss: 0.032951
 >> iter 29000, loss: 0.020076
 >> iter 30000, loss: 0.009781
   Number of active neurons: 10
 >> iter 31000, loss: 0.005567
 >> iter 32000, loss: 0.003793
 >> iter 33000, loss: 0.003010
 >> iter 34000, loss: 0.036249
 >> iter 35000, loss: 0.025247
 >> iter 36000, loss: 0.010908
 >> iter 37000, loss: 0.005454
 >> iter 38000, loss: 0.073910
 >> iter 39000, loss: 0.031923
 >> iter 40000, loss: 0.013394
   Number of active neurons: 10
 >> iter 41000, loss: 0.029058
 >> iter 42000, loss: 0.012344
 >> iter 43000, loss: 0.006412
 >> iter 44000, loss: 0.003489
 >> iter 45000, loss: 0.002434
 >> iter 46000, loss: 0.002222
 >> iter 47000, loss: 0.001750
 >> iter 48000, loss: 0.001481
 >> iter 49000, loss: 0.001430
 >> iter 50000, loss: 0.001293
   Number of active neurons: 10
 >> iter 51000, loss: 0.001289
 >> iter 52000, loss: 0.001197
 >> iter 53000, loss: 0.017490
 >> iter 54000, loss: 0.007263
 >> iter 55000, loss: 0.039717
 >> iter 56000, loss: 0.015831
 >> iter 57000, loss: 0.006781
 >> iter 58000, loss: 0.003417
 >> iter 59000, loss: 0.002017
 >> iter 60000, loss: 0.061222
   Number of active neurons: 10
 >> iter 61000, loss: 0.024288
 >> iter 62000, loss: 0.009920
 >> iter 63000, loss: 0.004559
 >> iter 64000, loss: 0.005488
 >> iter 65000, loss: 0.027698
 >> iter 66000, loss: 0.011046
 >> iter 67000, loss: 0.004908
 >> iter 68000, loss: 0.002567
 >> iter 69000, loss: 0.001796
 >> iter 70000, loss: 0.001333
   Number of active neurons: 10
 >> iter 71000, loss: 0.058091
 >> iter 72000, loss: 0.022459
 >> iter 73000, loss: 0.009178
 >> iter 74000, loss: 0.016854
 >> iter 75000, loss: 0.007188
 >> iter 76000, loss: 0.004067
 >> iter 77000, loss: 0.002312
 >> iter 78000, loss: 0.001585
 >> iter 79000, loss: 0.001287
 >> iter 80000, loss: 0.001095
   Number of active neurons: 10
 >> iter 81000, loss: 0.010804
 >> iter 82000, loss: 0.004590
 >> iter 83000, loss: 0.022797
 >> iter 84000, loss: 0.009030
 >> iter 85000, loss: 0.029123
 >> iter 86000, loss: 0.011437
 >> iter 87000, loss: 0.004886
 >> iter 88000, loss: 0.002436
 >> iter 89000, loss: 0.001533
 >> iter 90000, loss: 0.001161
   Number of active neurons: 10
 >> iter 91000, loss: 0.001008
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.542856
 >> iter 2000, loss: 9.691347
 >> iter 3000, loss: 6.226538
 >> iter 4000, loss: 3.696187
 >> iter 5000, loss: 1.869438
 >> iter 6000, loss: 0.993392
 >> iter 7000, loss: 0.559129
 >> iter 8000, loss: 0.329825
 >> iter 9000, loss: 0.204923
 >> iter 10000, loss: 0.136282
   Number of active neurons: 10
 >> iter 11000, loss: 0.121640
 >> iter 12000, loss: 0.159604
 >> iter 13000, loss: 0.105549
 >> iter 14000, loss: 0.068208
 >> iter 15000, loss: 0.032374
 >> iter 16000, loss: 0.028145
 >> iter 17000, loss: 0.019592
 >> iter 18000, loss: 0.013982
 >> iter 19000, loss: 0.010939
 >> iter 20000, loss: 0.035404
   Number of active neurons: 10
 >> iter 21000, loss: 0.017316
 >> iter 22000, loss: 0.036353
 >> iter 23000, loss: 0.017071
 >> iter 24000, loss: 0.041069
 >> iter 25000, loss: 0.063894
 >> iter 26000, loss: 0.050477
 >> iter 27000, loss: 0.029050
 >> iter 28000, loss: 0.013864
 >> iter 29000, loss: 0.012199
 >> iter 30000, loss: 0.012395
   Number of active neurons: 10
 >> iter 31000, loss: 0.033213
 >> iter 32000, loss: 0.014962
 >> iter 33000, loss: 0.007993
 >> iter 34000, loss: 0.023199
 >> iter 35000, loss: 0.012043
 >> iter 36000, loss: 0.006430
 >> iter 37000, loss: 0.004281
 >> iter 38000, loss: 0.068927
 >> iter 39000, loss: 0.045235
 >> iter 40000, loss: 0.060771
   Number of active neurons: 10
 >> iter 41000, loss: 0.033305
 >> iter 42000, loss: 0.014510
 >> iter 43000, loss: 0.007432
 >> iter 44000, loss: 0.004621
 >> iter 45000, loss: 0.004512
 >> iter 46000, loss: 0.003393
 >> iter 47000, loss: 0.006487
 >> iter 48000, loss: 0.004106
 >> iter 49000, loss: 0.003092
 >> iter 50000, loss: 0.002610
   Number of active neurons: 10
 >> iter 51000, loss: 0.002353
 >> iter 52000, loss: 0.002117
 >> iter 53000, loss: 0.002019
 >> iter 54000, loss: 0.001876
 >> iter 55000, loss: 0.001839
 >> iter 56000, loss: 0.001732
 >> iter 57000, loss: 0.001686
 >> iter 58000, loss: 0.006325
 >> iter 59000, loss: 0.006544
 >> iter 60000, loss: 0.014132
   Number of active neurons: 10
 >> iter 61000, loss: 0.006266
 >> iter 62000, loss: 0.003316
 >> iter 63000, loss: 0.002272
 >> iter 64000, loss: 0.001740
 >> iter 65000, loss: 0.012938
 >> iter 66000, loss: 0.005640
 >> iter 67000, loss: 0.002946
 >> iter 68000, loss: 0.002021
 >> iter 69000, loss: 0.001554
 >> iter 70000, loss: 0.014397
   Number of active neurons: 10
 >> iter 71000, loss: 0.006309
 >> iter 72000, loss: 0.003104
 >> iter 73000, loss: 0.040697
 >> iter 74000, loss: 0.024729
 >> iter 75000, loss: 0.009961
 >> iter 76000, loss: 0.004482
 >> iter 77000, loss: 0.002497
 >> iter 78000, loss: 0.001682
 >> iter 79000, loss: 0.001402
 >> iter 80000, loss: 0.001232
   Number of active neurons: 10
 >> iter 81000, loss: 0.001182
 >> iter 82000, loss: 0.001139
 >> iter 83000, loss: 0.006237
 >> iter 84000, loss: 0.003026
 >> iter 85000, loss: 0.001856
 >> iter 86000, loss: 0.001650
 >> iter 87000, loss: 0.002152
 >> iter 88000, loss: 0.001450
 >> iter 89000, loss: 0.001190
 >> iter 90000, loss: 0.001150
   Number of active neurons: 10
 >> iter 91000, loss: 0.001029
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.979512
 >> iter 2000, loss: 8.897951
 >> iter 3000, loss: 3.999524
 >> iter 4000, loss: 1.677630
 >> iter 5000, loss: 0.794582
 >> iter 6000, loss: 0.615505
 >> iter 7000, loss: 0.354243
 >> iter 8000, loss: 0.155018
 >> iter 9000, loss: 0.070127
 >> iter 10000, loss: 0.066538
   Number of active neurons: 10
 >> iter 11000, loss: 0.052316
 >> iter 12000, loss: 0.039126
 >> iter 13000, loss: 0.021484
 >> iter 14000, loss: 0.031601
 >> iter 15000, loss: 0.033319
 >> iter 16000, loss: 0.016909
 >> iter 17000, loss: 0.009765
 >> iter 18000, loss: 0.010905
 >> iter 19000, loss: 0.025491
 >> iter 20000, loss: 0.030688
   Number of active neurons: 10
 >> iter 21000, loss: 0.014765
 >> iter 22000, loss: 0.007967
 >> iter 23000, loss: 0.005381
 >> iter 24000, loss: 0.004054
 >> iter 25000, loss: 0.003535
 >> iter 26000, loss: 0.003043
 >> iter 27000, loss: 0.006716
 >> iter 28000, loss: 0.048776
 >> iter 29000, loss: 0.019904
 >> iter 30000, loss: 0.009245
   Number of active neurons: 10
 >> iter 31000, loss: 0.005283
 >> iter 32000, loss: 0.003835
 >> iter 33000, loss: 0.002962
 >> iter 34000, loss: 0.002606
 >> iter 35000, loss: 0.026596
 >> iter 36000, loss: 0.011257
 >> iter 37000, loss: 0.005605
 >> iter 38000, loss: 0.003359
 >> iter 39000, loss: 0.002440
 >> iter 40000, loss: 0.002013
   Number of active neurons: 10
 >> iter 41000, loss: 0.002109
 >> iter 42000, loss: 0.001916
 >> iter 43000, loss: 0.001842
 >> iter 44000, loss: 0.019336
 >> iter 45000, loss: 0.008960
 >> iter 46000, loss: 0.015664
 >> iter 47000, loss: 0.006988
 >> iter 48000, loss: 0.003598
 >> iter 49000, loss: 0.002365
 >> iter 50000, loss: 0.002064
   Number of active neurons: 10
 >> iter 51000, loss: 0.001705
 >> iter 52000, loss: 0.001601
 >> iter 53000, loss: 0.001462
 >> iter 54000, loss: 0.001559
 >> iter 55000, loss: 0.001398
 >> iter 56000, loss: 0.001272
 >> iter 57000, loss: 0.022140
 >> iter 58000, loss: 0.008992
 >> iter 59000, loss: 0.004144
 >> iter 60000, loss: 0.002290
   Number of active neurons: 10
 >> iter 61000, loss: 0.001633
 >> iter 62000, loss: 0.001321
 >> iter 63000, loss: 0.001204
 >> iter 64000, loss: 0.001162
 >> iter 65000, loss: 0.001135
 >> iter 66000, loss: 0.001065
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.248480
 >> iter 2000, loss: 9.582618
 >> iter 3000, loss: 5.987949
 >> iter 4000, loss: 2.722905
 >> iter 5000, loss: 1.224816
 >> iter 6000, loss: 0.555506
 >> iter 7000, loss: 0.383354
 >> iter 8000, loss: 0.381881
 >> iter 9000, loss: 0.268700
 >> iter 10000, loss: 0.122189
   Number of active neurons: 10
 >> iter 11000, loss: 0.125123
 >> iter 12000, loss: 0.137322
 >> iter 13000, loss: 0.085755
 >> iter 14000, loss: 0.139161
 >> iter 15000, loss: 0.083015
 >> iter 16000, loss: 0.066516
 >> iter 17000, loss: 0.076477
 >> iter 18000, loss: 0.129336
 >> iter 19000, loss: 0.094186
 >> iter 20000, loss: 0.042500
   Number of active neurons: 10
 >> iter 21000, loss: 0.020290
 >> iter 22000, loss: 0.010845
 >> iter 23000, loss: 0.011996
 >> iter 24000, loss: 0.025986
 >> iter 25000, loss: 0.012292
 >> iter 26000, loss: 0.006953
 >> iter 27000, loss: 0.028650
 >> iter 28000, loss: 0.070947
 >> iter 29000, loss: 0.036463
 >> iter 30000, loss: 0.023351
   Number of active neurons: 10
 >> iter 31000, loss: 0.029105
 >> iter 32000, loss: 0.018308
 >> iter 33000, loss: 0.008987
 >> iter 34000, loss: 0.020243
 >> iter 35000, loss: 0.066066
 >> iter 36000, loss: 0.039999
 >> iter 37000, loss: 0.018059
 >> iter 38000, loss: 0.008701
 >> iter 39000, loss: 0.017307
 >> iter 40000, loss: 0.047019
   Number of active neurons: 10
 >> iter 41000, loss: 0.019549
 >> iter 42000, loss: 0.008899
 >> iter 43000, loss: 0.005102
 >> iter 44000, loss: 0.003341
 >> iter 45000, loss: 0.002670
 >> iter 46000, loss: 0.002148
 >> iter 47000, loss: 0.002136
 >> iter 48000, loss: 0.001957
 >> iter 49000, loss: 0.001883
 >> iter 50000, loss: 0.001687
   Number of active neurons: 10
 >> iter 51000, loss: 0.001670
 >> iter 52000, loss: 0.001588
 >> iter 53000, loss: 0.001585
 >> iter 54000, loss: 0.001491
 >> iter 55000, loss: 0.001693
 >> iter 56000, loss: 0.001454
 >> iter 57000, loss: 0.001305
 >> iter 58000, loss: 0.113013
 >> iter 59000, loss: 0.081694
 >> iter 60000, loss: 0.050435
   Number of active neurons: 10
 >> iter 61000, loss: 0.030231
 >> iter 62000, loss: 0.013041
 >> iter 63000, loss: 0.041563
 >> iter 64000, loss: 0.017829
 >> iter 65000, loss: 0.030073
 >> iter 66000, loss: 0.032747
 >> iter 67000, loss: 0.013727
 >> iter 68000, loss: 0.015150
 >> iter 69000, loss: 0.007052
 >> iter 70000, loss: 0.003767
   Number of active neurons: 10
 >> iter 71000, loss: 0.002485
 >> iter 72000, loss: 0.020861
 >> iter 73000, loss: 0.041288
 >> iter 74000, loss: 0.050620
 >> iter 75000, loss: 0.020460
 >> iter 76000, loss: 0.009061
 >> iter 77000, loss: 0.006256
 >> iter 78000, loss: 0.039402
 >> iter 79000, loss: 0.039583
 >> iter 80000, loss: 0.018696
   Number of active neurons: 10
 >> iter 81000, loss: 0.050382
 >> iter 82000, loss: 0.020421
 >> iter 83000, loss: 0.008788
 >> iter 84000, loss: 0.007239
 >> iter 85000, loss: 0.004202
 >> iter 86000, loss: 0.002650
 >> iter 87000, loss: 0.001978
 >> iter 88000, loss: 0.001637
 >> iter 89000, loss: 0.013336
 >> iter 90000, loss: 0.005964
   Number of active neurons: 10
 >> iter 91000, loss: 0.003122
 >> iter 92000, loss: 0.001986
 >> iter 93000, loss: 0.001478
 >> iter 94000, loss: 0.001295
 >> iter 95000, loss: 0.001195
 >> iter 96000, loss: 0.001053
 >> iter 97000, loss: 0.001062
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.165786
 >> iter 2000, loss: 8.990639
 >> iter 3000, loss: 4.363167
 >> iter 4000, loss: 2.158976
 >> iter 5000, loss: 1.122434
 >> iter 6000, loss: 0.611741
 >> iter 7000, loss: 0.322627
 >> iter 8000, loss: 0.384034
 >> iter 9000, loss: 0.510585
 >> iter 10000, loss: 0.242428
   Number of active neurons: 10
 >> iter 11000, loss: 0.142765
 >> iter 12000, loss: 0.241955
 >> iter 13000, loss: 0.124331
 >> iter 14000, loss: 0.056767
 >> iter 15000, loss: 0.065054
 >> iter 16000, loss: 0.079292
 >> iter 17000, loss: 0.047786
 >> iter 18000, loss: 0.176126
 >> iter 19000, loss: 0.090818
 >> iter 20000, loss: 0.077450
   Number of active neurons: 10
 >> iter 21000, loss: 0.156140
 >> iter 22000, loss: 0.095973
 >> iter 23000, loss: 0.059803
 >> iter 24000, loss: 0.066819
 >> iter 25000, loss: 0.099330
 >> iter 26000, loss: 0.043384
 >> iter 27000, loss: 0.027753
 >> iter 28000, loss: 0.018301
 >> iter 29000, loss: 0.010878
 >> iter 30000, loss: 0.007278
   Number of active neurons: 10
 >> iter 31000, loss: 0.052357
 >> iter 32000, loss: 0.035471
 >> iter 33000, loss: 0.023598
 >> iter 34000, loss: 0.025088
 >> iter 35000, loss: 0.046850
 >> iter 36000, loss: 0.020289
 >> iter 37000, loss: 0.010047
 >> iter 38000, loss: 0.005867
 >> iter 39000, loss: 0.012227
 >> iter 40000, loss: 0.007012
   Number of active neurons: 10
 >> iter 41000, loss: 0.007703
 >> iter 42000, loss: 0.004767
 >> iter 43000, loss: 0.004932
 >> iter 44000, loss: 0.004239
 >> iter 45000, loss: 0.003328
 >> iter 46000, loss: 0.002670
 >> iter 47000, loss: 0.002931
 >> iter 48000, loss: 0.002801
 >> iter 49000, loss: 0.002472
 >> iter 50000, loss: 0.002466
   Number of active neurons: 10
 >> iter 51000, loss: 0.045168
 >> iter 52000, loss: 0.018226
 >> iter 53000, loss: 0.030043
 >> iter 54000, loss: 0.012757
 >> iter 55000, loss: 0.008657
 >> iter 56000, loss: 0.005230
 >> iter 57000, loss: 0.018684
 >> iter 58000, loss: 0.008273
 >> iter 59000, loss: 0.004282
 >> iter 60000, loss: 0.003289
   Number of active neurons: 10
 >> iter 61000, loss: 0.005004
 >> iter 62000, loss: 0.007275
 >> iter 63000, loss: 0.004357
 >> iter 64000, loss: 0.003059
 >> iter 65000, loss: 0.002368
 >> iter 66000, loss: 0.001950
 >> iter 67000, loss: 0.028786
 >> iter 68000, loss: 0.036757
 >> iter 69000, loss: 0.023553
 >> iter 70000, loss: 0.013513
   Number of active neurons: 10
 >> iter 71000, loss: 0.043096
 >> iter 72000, loss: 0.039077
 >> iter 73000, loss: 0.017186
 >> iter 74000, loss: 0.008125
 >> iter 75000, loss: 0.034698
 >> iter 76000, loss: 0.014177
 >> iter 77000, loss: 0.024177
 >> iter 78000, loss: 0.017810
 >> iter 79000, loss: 0.007850
 >> iter 80000, loss: 0.037379
   Number of active neurons: 10
 >> iter 81000, loss: 0.069891
 >> iter 82000, loss: 0.036773
 >> iter 83000, loss: 0.015470
 >> iter 84000, loss: 0.007020
 >> iter 85000, loss: 0.003949
 >> iter 86000, loss: 0.002607
 >> iter 87000, loss: 0.002120
 >> iter 88000, loss: 0.001805
 >> iter 89000, loss: 0.040594
 >> iter 90000, loss: 0.016061
   Number of active neurons: 10
 >> iter 91000, loss: 0.007047
 >> iter 92000, loss: 0.003545
 >> iter 93000, loss: 0.002522
 >> iter 94000, loss: 0.052283
 >> iter 95000, loss: 0.020560
 >> iter 96000, loss: 0.008668
 >> iter 97000, loss: 0.017687
 >> iter 98000, loss: 0.007512
 >> iter 99000, loss: 0.008240
 >> iter 100000, loss: 0.013623
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.270763
 >> iter 2000, loss: 8.485861
 >> iter 3000, loss: 3.448788
 >> iter 4000, loss: 1.409234
 >> iter 5000, loss: 0.598669
 >> iter 6000, loss: 0.259380
 >> iter 7000, loss: 0.190447
 >> iter 8000, loss: 0.155763
 >> iter 9000, loss: 0.078741
 >> iter 10000, loss: 0.066626
   Number of active neurons: 10
 >> iter 11000, loss: 0.094277
 >> iter 12000, loss: 0.041676
 >> iter 13000, loss: 0.031988
 >> iter 14000, loss: 0.073350
 >> iter 15000, loss: 0.059255
 >> iter 16000, loss: 0.068517
 >> iter 17000, loss: 0.029948
 >> iter 18000, loss: 0.014633
 >> iter 19000, loss: 0.028054
 >> iter 20000, loss: 0.044263
   Number of active neurons: 10
 >> iter 21000, loss: 0.081024
 >> iter 22000, loss: 0.038630
 >> iter 23000, loss: 0.017408
 >> iter 24000, loss: 0.025559
 >> iter 25000, loss: 0.012934
 >> iter 26000, loss: 0.031519
 >> iter 27000, loss: 0.013842
 >> iter 28000, loss: 0.007334
 >> iter 29000, loss: 0.042050
 >> iter 30000, loss: 0.018252
   Number of active neurons: 10
 >> iter 31000, loss: 0.029563
 >> iter 32000, loss: 0.012799
 >> iter 33000, loss: 0.028263
 >> iter 34000, loss: 0.019973
 >> iter 35000, loss: 0.009886
 >> iter 36000, loss: 0.005331
 >> iter 37000, loss: 0.003870
 >> iter 38000, loss: 0.002698
 >> iter 39000, loss: 0.002355
 >> iter 40000, loss: 0.015752
   Number of active neurons: 10
 >> iter 41000, loss: 0.007158
 >> iter 42000, loss: 0.003754
 >> iter 43000, loss: 0.002591
 >> iter 44000, loss: 0.002399
 >> iter 45000, loss: 0.002057
 >> iter 46000, loss: 0.001922
 >> iter 47000, loss: 0.001642
 >> iter 48000, loss: 0.001387
 >> iter 49000, loss: 0.001715
 >> iter 50000, loss: 0.011453
   Number of active neurons: 10
 >> iter 51000, loss: 0.013782
 >> iter 52000, loss: 0.006398
 >> iter 53000, loss: 0.003349
 >> iter 54000, loss: 0.001999
 >> iter 55000, loss: 0.001612
 >> iter 56000, loss: 0.001328
 >> iter 57000, loss: 0.001200
 >> iter 58000, loss: 0.001077
 >> iter 59000, loss: 0.021620
 >> iter 60000, loss: 0.009300
   Number of active neurons: 10
 >> iter 61000, loss: 0.004398
 >> iter 62000, loss: 0.002428
 >> iter 63000, loss: 0.001561
 >> iter 64000, loss: 0.001417
 >> iter 65000, loss: 0.001158
 >> iter 66000, loss: 0.001083
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.389929
 >> iter 2000, loss: 9.825357
 >> iter 3000, loss: 6.067423
 >> iter 4000, loss: 2.794228
 >> iter 5000, loss: 1.155173
 >> iter 6000, loss: 0.449186
 >> iter 7000, loss: 0.202583
 >> iter 8000, loss: 0.179604
 >> iter 9000, loss: 0.120079
 >> iter 10000, loss: 0.076741
   Number of active neurons: 10
 >> iter 11000, loss: 0.069303
 >> iter 12000, loss: 0.060331
 >> iter 13000, loss: 0.077520
 >> iter 14000, loss: 0.093780
 >> iter 15000, loss: 0.050566
 >> iter 16000, loss: 0.035026
 >> iter 17000, loss: 0.042311
 >> iter 18000, loss: 0.026843
 >> iter 19000, loss: 0.016691
 >> iter 20000, loss: 0.009757
   Number of active neurons: 10
 >> iter 21000, loss: 0.082083
 >> iter 22000, loss: 0.042911
 >> iter 23000, loss: 0.024843
 >> iter 24000, loss: 0.013096
 >> iter 25000, loss: 0.038230
 >> iter 26000, loss: 0.016783
 >> iter 27000, loss: 0.008686
 >> iter 28000, loss: 0.005450
 >> iter 29000, loss: 0.005655
 >> iter 30000, loss: 0.003893
   Number of active neurons: 10
 >> iter 31000, loss: 0.003274
 >> iter 32000, loss: 0.002770
 >> iter 33000, loss: 0.002450
 >> iter 34000, loss: 0.002173
 >> iter 35000, loss: 0.002140
 >> iter 36000, loss: 0.001938
 >> iter 37000, loss: 0.001857
 >> iter 38000, loss: 0.001718
 >> iter 39000, loss: 0.001653
 >> iter 40000, loss: 0.001530
   Number of active neurons: 10
 >> iter 41000, loss: 0.001488
 >> iter 42000, loss: 0.078243
 >> iter 43000, loss: 0.072278
 >> iter 44000, loss: 0.075629
 >> iter 45000, loss: 0.029844
 >> iter 46000, loss: 0.012603
 >> iter 47000, loss: 0.006450
 >> iter 48000, loss: 0.003739
 >> iter 49000, loss: 0.002785
 >> iter 50000, loss: 0.002340
   Number of active neurons: 10
 >> iter 51000, loss: 0.002075
 >> iter 52000, loss: 0.005844
 >> iter 53000, loss: 0.003268
 >> iter 54000, loss: 0.081649
 >> iter 55000, loss: 0.032641
 >> iter 56000, loss: 0.013523
 >> iter 57000, loss: 0.022886
 >> iter 58000, loss: 0.021279
 >> iter 59000, loss: 0.009372
 >> iter 60000, loss: 0.004664
   Number of active neurons: 10
 >> iter 61000, loss: 0.029806
 >> iter 62000, loss: 0.012360
 >> iter 63000, loss: 0.005841
 >> iter 64000, loss: 0.003619
 >> iter 65000, loss: 0.026578
 >> iter 66000, loss: 0.011041
 >> iter 67000, loss: 0.009201
 >> iter 68000, loss: 0.004455
 >> iter 69000, loss: 0.002738
 >> iter 70000, loss: 0.001927
   Number of active neurons: 10
 >> iter 71000, loss: 0.001709
 >> iter 72000, loss: 0.001502
 >> iter 73000, loss: 0.001450
 >> iter 74000, loss: 0.001287
 >> iter 75000, loss: 0.001287
 >> iter 76000, loss: 0.001171
 >> iter 77000, loss: 0.001128
 >> iter 78000, loss: 0.001064
 >> iter 79000, loss: 0.001072
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.225328
 >> iter 2000, loss: 9.170799
 >> iter 3000, loss: 4.466987
 >> iter 4000, loss: 1.962215
 >> iter 5000, loss: 0.770473
 >> iter 6000, loss: 0.392359
 >> iter 7000, loss: 0.164863
 >> iter 8000, loss: 0.102457
 >> iter 9000, loss: 0.045763
 >> iter 10000, loss: 0.021961
   Number of active neurons: 10
 >> iter 11000, loss: 0.053525
 >> iter 12000, loss: 0.082053
 >> iter 13000, loss: 0.055971
 >> iter 14000, loss: 0.024961
 >> iter 15000, loss: 0.047553
 >> iter 16000, loss: 0.022500
 >> iter 17000, loss: 0.011819
 >> iter 18000, loss: 0.007038
 >> iter 19000, loss: 0.004886
 >> iter 20000, loss: 0.004077
   Number of active neurons: 10
 >> iter 21000, loss: 0.004306
 >> iter 22000, loss: 0.003559
 >> iter 23000, loss: 0.003065
 >> iter 24000, loss: 0.002616
 >> iter 25000, loss: 0.002418
 >> iter 26000, loss: 0.014969
 >> iter 27000, loss: 0.007358
 >> iter 28000, loss: 0.004148
 >> iter 29000, loss: 0.002827
 >> iter 30000, loss: 0.002501
   Number of active neurons: 10
 >> iter 31000, loss: 0.002589
 >> iter 32000, loss: 0.021822
 >> iter 33000, loss: 0.023371
 >> iter 34000, loss: 0.061175
 >> iter 35000, loss: 0.024089
 >> iter 36000, loss: 0.010290
 >> iter 37000, loss: 0.004973
 >> iter 38000, loss: 0.003080
 >> iter 39000, loss: 0.002179
 >> iter 40000, loss: 0.032710
   Number of active neurons: 10
 >> iter 41000, loss: 0.013521
 >> iter 42000, loss: 0.028117
 >> iter 43000, loss: 0.012175
 >> iter 44000, loss: 0.013472
 >> iter 45000, loss: 0.006290
 >> iter 46000, loss: 0.003474
 >> iter 47000, loss: 0.002267
 >> iter 48000, loss: 0.001757
 >> iter 49000, loss: 0.001606
 >> iter 50000, loss: 0.001355
   Number of active neurons: 10
 >> iter 51000, loss: 0.007324
 >> iter 52000, loss: 0.003638
 >> iter 53000, loss: 0.002068
 >> iter 54000, loss: 0.024201
 >> iter 55000, loss: 0.016149
 >> iter 56000, loss: 0.033654
 >> iter 57000, loss: 0.013876
 >> iter 58000, loss: 0.006234
 >> iter 59000, loss: 0.003148
 >> iter 60000, loss: 0.001945
   Number of active neurons: 10
 >> iter 61000, loss: 0.001904
 >> iter 62000, loss: 0.001357
 >> iter 63000, loss: 0.001122
 >> iter 64000, loss: 0.001039
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.471257
 >> iter 2000, loss: 9.405861
 >> iter 3000, loss: 4.632195
 >> iter 4000, loss: 1.985169
 >> iter 5000, loss: 0.939726
 >> iter 6000, loss: 0.414152
 >> iter 7000, loss: 0.213616
 >> iter 8000, loss: 0.096377
 >> iter 9000, loss: 0.229686
 >> iter 10000, loss: 0.097229
   Number of active neurons: 10
 >> iter 11000, loss: 0.058725
 >> iter 12000, loss: 0.045495
 >> iter 13000, loss: 0.049312
 >> iter 14000, loss: 0.023732
 >> iter 15000, loss: 0.020424
 >> iter 16000, loss: 0.011597
 >> iter 17000, loss: 0.028885
 >> iter 18000, loss: 0.014285
 >> iter 19000, loss: 0.024851
 >> iter 20000, loss: 0.024195
   Number of active neurons: 10
 >> iter 21000, loss: 0.012155
 >> iter 22000, loss: 0.007119
 >> iter 23000, loss: 0.005081
 >> iter 24000, loss: 0.039847
 >> iter 25000, loss: 0.019671
 >> iter 26000, loss: 0.009573
 >> iter 27000, loss: 0.005683
 >> iter 28000, loss: 0.004055
 >> iter 29000, loss: 0.087141
 >> iter 30000, loss: 0.034608
   Number of active neurons: 10
 >> iter 31000, loss: 0.015160
 >> iter 32000, loss: 0.007474
 >> iter 33000, loss: 0.004574
 >> iter 34000, loss: 0.003317
 >> iter 35000, loss: 0.030307
 >> iter 36000, loss: 0.138344
 >> iter 37000, loss: 0.053741
 >> iter 38000, loss: 0.037310
 >> iter 39000, loss: 0.016162
 >> iter 40000, loss: 0.008112
   Number of active neurons: 10
 >> iter 41000, loss: 0.004894
 >> iter 42000, loss: 0.003685
 >> iter 43000, loss: 0.003059
 >> iter 44000, loss: 0.002702
 >> iter 45000, loss: 0.002535
 >> iter 46000, loss: 0.088880
 >> iter 47000, loss: 0.035090
 >> iter 48000, loss: 0.017287
 >> iter 49000, loss: 0.008439
 >> iter 50000, loss: 0.017086
   Number of active neurons: 10
 >> iter 51000, loss: 0.047340
 >> iter 52000, loss: 0.019696
 >> iter 53000, loss: 0.015781
 >> iter 54000, loss: 0.024698
 >> iter 55000, loss: 0.011207
 >> iter 56000, loss: 0.005803
 >> iter 57000, loss: 0.003837
 >> iter 58000, loss: 0.002994
 >> iter 59000, loss: 0.003125
 >> iter 60000, loss: 0.034515
   Number of active neurons: 10
 >> iter 61000, loss: 0.026441
 >> iter 62000, loss: 0.011665
 >> iter 63000, loss: 0.005777
 >> iter 64000, loss: 0.006356
 >> iter 65000, loss: 0.003910
 >> iter 66000, loss: 0.002780
 >> iter 67000, loss: 0.002324
 >> iter 68000, loss: 0.002024
 >> iter 69000, loss: 0.001899
 >> iter 70000, loss: 0.001870
   Number of active neurons: 10
 >> iter 71000, loss: 0.001713
 >> iter 72000, loss: 0.001616
 >> iter 73000, loss: 0.001620
 >> iter 74000, loss: 0.008110
 >> iter 75000, loss: 0.003999
 >> iter 76000, loss: 0.002628
 >> iter 77000, loss: 0.022454
 >> iter 78000, loss: 0.009311
 >> iter 79000, loss: 0.021113
 >> iter 80000, loss: 0.008814
   Number of active neurons: 10
 >> iter 81000, loss: 0.004269
 >> iter 82000, loss: 0.023588
 >> iter 83000, loss: 0.009652
 >> iter 84000, loss: 0.004659
 >> iter 85000, loss: 0.002579
 >> iter 86000, loss: 0.002098
 >> iter 87000, loss: 0.001792
 >> iter 88000, loss: 0.001448
 >> iter 89000, loss: 0.001315
 >> iter 90000, loss: 0.001198
   Number of active neurons: 10
 >> iter 91000, loss: 0.001157
 >> iter 92000, loss: 0.001098
 >> iter 93000, loss: 0.001196
 >> iter 94000, loss: 0.006019
 >> iter 95000, loss: 0.005335
 >> iter 96000, loss: 0.002728
 >> iter 97000, loss: 0.001751
 >> iter 98000, loss: 0.014489
 >> iter 99000, loss: 0.006228
 >> iter 100000, loss: 0.003066
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.795274
 >> iter 2000, loss: 7.797344
 >> iter 3000, loss: 3.539501
 >> iter 4000, loss: 1.560430
 >> iter 5000, loss: 0.645365
 >> iter 6000, loss: 0.356171
 >> iter 7000, loss: 0.219040
 >> iter 8000, loss: 0.206093
 >> iter 9000, loss: 0.148574
 >> iter 10000, loss: 0.108845
   Number of active neurons: 10
 >> iter 11000, loss: 0.092697
 >> iter 12000, loss: 0.076021
 >> iter 13000, loss: 0.037753
 >> iter 14000, loss: 0.062437
 >> iter 15000, loss: 0.030589
 >> iter 16000, loss: 0.021003
 >> iter 17000, loss: 0.028009
 >> iter 18000, loss: 0.040883
 >> iter 19000, loss: 0.153262
 >> iter 20000, loss: 0.062115
   Number of active neurons: 10
 >> iter 21000, loss: 0.027127
 >> iter 22000, loss: 0.014289
 >> iter 23000, loss: 0.009067
 >> iter 24000, loss: 0.008373
 >> iter 25000, loss: 0.022452
 >> iter 26000, loss: 0.013716
 >> iter 27000, loss: 0.022316
 >> iter 28000, loss: 0.010861
 >> iter 29000, loss: 0.006398
 >> iter 30000, loss: 0.043376
   Number of active neurons: 10
 >> iter 31000, loss: 0.047460
 >> iter 32000, loss: 0.019756
 >> iter 33000, loss: 0.009350
 >> iter 34000, loss: 0.005301
 >> iter 35000, loss: 0.003651
 >> iter 36000, loss: 0.003001
 >> iter 37000, loss: 0.002561
 >> iter 38000, loss: 0.002267
 >> iter 39000, loss: 0.002263
 >> iter 40000, loss: 0.002082
   Number of active neurons: 10
 >> iter 41000, loss: 0.001975
 >> iter 42000, loss: 0.001828
 >> iter 43000, loss: 0.001830
 >> iter 44000, loss: 0.001709
 >> iter 45000, loss: 0.002033
 >> iter 46000, loss: 0.138779
 >> iter 47000, loss: 0.066997
 >> iter 48000, loss: 0.027105
 >> iter 49000, loss: 0.011851
 >> iter 50000, loss: 0.005984
   Number of active neurons: 10
 >> iter 51000, loss: 0.003688
 >> iter 52000, loss: 0.005143
 >> iter 53000, loss: 0.003406
 >> iter 54000, loss: 0.002826
 >> iter 55000, loss: 0.002258
 >> iter 56000, loss: 0.001982
 >> iter 57000, loss: 0.040869
 >> iter 58000, loss: 0.017430
 >> iter 59000, loss: 0.007773
 >> iter 60000, loss: 0.051430
   Number of active neurons: 10
 >> iter 61000, loss: 0.040514
 >> iter 62000, loss: 0.062955
 >> iter 63000, loss: 0.024879
 >> iter 64000, loss: 0.027681
 >> iter 65000, loss: 0.032208
 >> iter 66000, loss: 0.032439
 >> iter 67000, loss: 0.013498
 >> iter 68000, loss: 0.006299
 >> iter 69000, loss: 0.003614
 >> iter 70000, loss: 0.024373
   Number of active neurons: 10
 >> iter 71000, loss: 0.015434
 >> iter 72000, loss: 0.007004
 >> iter 73000, loss: 0.003801
 >> iter 74000, loss: 0.009453
 >> iter 75000, loss: 0.082274
 >> iter 76000, loss: 0.043076
 >> iter 77000, loss: 0.017343
 >> iter 78000, loss: 0.007728
 >> iter 79000, loss: 0.032917
 >> iter 80000, loss: 0.013834
   Number of active neurons: 10
 >> iter 81000, loss: 0.006398
 >> iter 82000, loss: 0.003576
 >> iter 83000, loss: 0.002509
 >> iter 84000, loss: 0.001999
 >> iter 85000, loss: 0.002128
 >> iter 86000, loss: 0.001727
 >> iter 87000, loss: 0.001525
 >> iter 88000, loss: 0.001450
 >> iter 89000, loss: 0.001383
 >> iter 90000, loss: 0.004185
   Number of active neurons: 10
 >> iter 91000, loss: 0.002361
 >> iter 92000, loss: 0.001672
 >> iter 93000, loss: 0.001343
 >> iter 94000, loss: 0.016434
 >> iter 95000, loss: 0.006931
 >> iter 96000, loss: 0.003393
 >> iter 97000, loss: 0.002007
 >> iter 98000, loss: 0.001565
 >> iter 99000, loss: 0.001287
 >> iter 100000, loss: 0.001172
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.284813
 >> iter 2000, loss: 9.027400
 >> iter 3000, loss: 3.879294
 >> iter 4000, loss: 1.702288
 >> iter 5000, loss: 0.727841
 >> iter 6000, loss: 0.321577
 >> iter 7000, loss: 0.141864
 >> iter 8000, loss: 0.103865
 >> iter 9000, loss: 0.046319
 >> iter 10000, loss: 0.023575
   Number of active neurons: 10
 >> iter 11000, loss: 0.021477
 >> iter 12000, loss: 0.112912
 >> iter 13000, loss: 0.048267
 >> iter 14000, loss: 0.022604
 >> iter 15000, loss: 0.012640
 >> iter 16000, loss: 0.021266
 >> iter 17000, loss: 0.011207
 >> iter 18000, loss: 0.038913
 >> iter 19000, loss: 0.018112
 >> iter 20000, loss: 0.061527
   Number of active neurons: 10
 >> iter 21000, loss: 0.074287
 >> iter 22000, loss: 0.039797
 >> iter 23000, loss: 0.018739
 >> iter 24000, loss: 0.039130
 >> iter 25000, loss: 0.017915
 >> iter 26000, loss: 0.009249
 >> iter 27000, loss: 0.007159
 >> iter 28000, loss: 0.004617
 >> iter 29000, loss: 0.140911
 >> iter 30000, loss: 0.186698
   Number of active neurons: 10
 >> iter 31000, loss: 0.073692
 >> iter 32000, loss: 0.030585
 >> iter 33000, loss: 0.014229
 >> iter 34000, loss: 0.034102
 >> iter 35000, loss: 0.015457
 >> iter 36000, loss: 0.008037
 >> iter 37000, loss: 0.020087
 >> iter 38000, loss: 0.071001
 >> iter 39000, loss: 0.029583
 >> iter 40000, loss: 0.013242
   Number of active neurons: 10
 >> iter 41000, loss: 0.007035
 >> iter 42000, loss: 0.004395
 >> iter 43000, loss: 0.004033
 >> iter 44000, loss: 0.018518
 >> iter 45000, loss: 0.009066
 >> iter 46000, loss: 0.005342
 >> iter 47000, loss: 0.016883
 >> iter 48000, loss: 0.008460
 >> iter 49000, loss: 0.004529
 >> iter 50000, loss: 0.002907
   Number of active neurons: 10
 >> iter 51000, loss: 0.002314
 >> iter 52000, loss: 0.033346
 >> iter 53000, loss: 0.020925
 >> iter 54000, loss: 0.009539
 >> iter 55000, loss: 0.004905
 >> iter 56000, loss: 0.026575
 >> iter 57000, loss: 0.011368
 >> iter 58000, loss: 0.020724
 >> iter 59000, loss: 0.008975
 >> iter 60000, loss: 0.004468
   Number of active neurons: 10
 >> iter 61000, loss: 0.011277
 >> iter 62000, loss: 0.020389
 >> iter 63000, loss: 0.008641
 >> iter 64000, loss: 0.004229
 >> iter 65000, loss: 0.002552
 >> iter 66000, loss: 0.001870
 >> iter 67000, loss: 0.001612
 >> iter 68000, loss: 0.001399
 >> iter 69000, loss: 0.001299
 >> iter 70000, loss: 0.001429
   Number of active neurons: 10
 >> iter 71000, loss: 0.001342
 >> iter 72000, loss: 0.001195
 >> iter 73000, loss: 0.012439
 >> iter 74000, loss: 0.005286
 >> iter 75000, loss: 0.011040
 >> iter 76000, loss: 0.004793
 >> iter 77000, loss: 0.005033
 >> iter 78000, loss: 0.002828
 >> iter 79000, loss: 0.001745
 >> iter 80000, loss: 0.006278
   Number of active neurons: 10
 >> iter 81000, loss: 0.009424
 >> iter 82000, loss: 0.004272
 >> iter 83000, loss: 0.002521
 >> iter 84000, loss: 0.033529
 >> iter 85000, loss: 0.021176
 >> iter 86000, loss: 0.014267
 >> iter 87000, loss: 0.016325
 >> iter 88000, loss: 0.007046
 >> iter 89000, loss: 0.003500
 >> iter 90000, loss: 0.022040
   Number of active neurons: 10
 >> iter 91000, loss: 0.009325
 >> iter 92000, loss: 0.004360
 >> iter 93000, loss: 0.002420
 >> iter 94000, loss: 0.001632
 >> iter 95000, loss: 0.001290
 >> iter 96000, loss: 0.022631
 >> iter 97000, loss: 0.027234
 >> iter 98000, loss: 0.011295
 >> iter 99000, loss: 0.005147
 >> iter 100000, loss: 0.002742
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.031056
 >> iter 2000, loss: 9.484741
 >> iter 3000, loss: 5.505661
 >> iter 4000, loss: 2.365678
 >> iter 5000, loss: 1.012326
 >> iter 6000, loss: 0.537205
 >> iter 7000, loss: 0.328324
 >> iter 8000, loss: 0.154784
 >> iter 9000, loss: 0.120548
 >> iter 10000, loss: 0.056675
   Number of active neurons: 10
 >> iter 11000, loss: 0.069595
 >> iter 12000, loss: 0.046940
 >> iter 13000, loss: 0.059097
 >> iter 14000, loss: 0.033682
 >> iter 15000, loss: 0.083518
 >> iter 16000, loss: 0.065981
 >> iter 17000, loss: 0.041963
 >> iter 18000, loss: 0.019617
 >> iter 19000, loss: 0.030355
 >> iter 20000, loss: 0.056934
   Number of active neurons: 10
 >> iter 21000, loss: 0.024832
 >> iter 22000, loss: 0.028154
 >> iter 23000, loss: 0.064243
 >> iter 24000, loss: 0.027097
 >> iter 25000, loss: 0.012831
 >> iter 26000, loss: 0.064992
 >> iter 27000, loss: 0.051716
 >> iter 28000, loss: 0.023086
 >> iter 29000, loss: 0.033298
 >> iter 30000, loss: 0.018629
   Number of active neurons: 10
 >> iter 31000, loss: 0.023521
 >> iter 32000, loss: 0.067520
 >> iter 33000, loss: 0.053178
 >> iter 34000, loss: 0.022344
 >> iter 35000, loss: 0.077150
 >> iter 36000, loss: 0.059282
 >> iter 37000, loss: 0.024804
 >> iter 38000, loss: 0.011552
 >> iter 39000, loss: 0.006163
 >> iter 40000, loss: 0.017964
   Number of active neurons: 10
 >> iter 41000, loss: 0.023281
 >> iter 42000, loss: 0.031439
 >> iter 43000, loss: 0.013866
 >> iter 44000, loss: 0.006933
 >> iter 45000, loss: 0.008104
 >> iter 46000, loss: 0.004550
 >> iter 47000, loss: 0.003033
 >> iter 48000, loss: 0.002368
 >> iter 49000, loss: 0.002054
 >> iter 50000, loss: 0.001823
   Number of active neurons: 10
 >> iter 51000, loss: 0.001686
 >> iter 52000, loss: 0.001649
 >> iter 53000, loss: 0.001582
 >> iter 54000, loss: 0.001536
 >> iter 55000, loss: 0.001428
 >> iter 56000, loss: 0.001327
 >> iter 57000, loss: 0.001275
 >> iter 58000, loss: 0.001208
 >> iter 59000, loss: 0.001157
 >> iter 60000, loss: 0.001186
   Number of active neurons: 10
 >> iter 61000, loss: 0.001168
 >> iter 62000, loss: 0.001079
 >> iter 63000, loss: 0.001123
 >> iter 64000, loss: 0.027981
 >> iter 65000, loss: 0.011209
 >> iter 66000, loss: 0.004948
 >> iter 67000, loss: 0.002490
 >> iter 68000, loss: 0.050277
 >> iter 69000, loss: 0.057612
 >> iter 70000, loss: 0.023059
   Number of active neurons: 10
 >> iter 71000, loss: 0.009858
 >> iter 72000, loss: 0.005040
 >> iter 73000, loss: 0.002871
 >> iter 74000, loss: 0.070765
 >> iter 75000, loss: 0.027239
 >> iter 76000, loss: 0.017634
 >> iter 77000, loss: 0.007378
 >> iter 78000, loss: 0.003523
 >> iter 79000, loss: 0.002014
 >> iter 80000, loss: 0.001468
   Number of active neurons: 10
 >> iter 81000, loss: 0.001250
 >> iter 82000, loss: 0.001081
 >> iter 83000, loss: 0.001033
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.799066
 >> iter 2000, loss: 9.352246
 >> iter 3000, loss: 5.441090
 >> iter 4000, loss: 2.716376
 >> iter 5000, loss: 1.503362
 >> iter 6000, loss: 0.865056
 >> iter 7000, loss: 0.551773
 >> iter 8000, loss: 0.333745
 >> iter 9000, loss: 0.195038
 >> iter 10000, loss: 0.204164
   Number of active neurons: 10
 >> iter 11000, loss: 0.133772
 >> iter 12000, loss: 0.157310
 >> iter 13000, loss: 0.258952
 >> iter 14000, loss: 0.246590
 >> iter 15000, loss: 0.109871
 >> iter 16000, loss: 0.163588
 >> iter 17000, loss: 0.162843
 >> iter 18000, loss: 0.124170
 >> iter 19000, loss: 0.111583
 >> iter 20000, loss: 0.233029
   Number of active neurons: 10
 >> iter 21000, loss: 0.101570
 >> iter 22000, loss: 0.154560
 >> iter 23000, loss: 0.063832
 >> iter 24000, loss: 0.028686
 >> iter 25000, loss: 0.013417
 >> iter 26000, loss: 0.124933
 >> iter 27000, loss: 0.056940
 >> iter 28000, loss: 0.024462
 >> iter 29000, loss: 0.020179
 >> iter 30000, loss: 0.037917
   Number of active neurons: 10
 >> iter 31000, loss: 0.045940
 >> iter 32000, loss: 0.020645
 >> iter 33000, loss: 0.009640
 >> iter 34000, loss: 0.005209
 >> iter 35000, loss: 0.003379
 >> iter 36000, loss: 0.006765
 >> iter 37000, loss: 0.043072
 >> iter 38000, loss: 0.018877
 >> iter 39000, loss: 0.008472
 >> iter 40000, loss: 0.004357
   Number of active neurons: 10
 >> iter 41000, loss: 0.002888
 >> iter 42000, loss: 0.011426
 >> iter 43000, loss: 0.091007
 >> iter 44000, loss: 0.045388
 >> iter 45000, loss: 0.029928
 >> iter 46000, loss: 0.012849
 >> iter 47000, loss: 0.044602
 >> iter 48000, loss: 0.202584
 >> iter 49000, loss: 0.088159
 >> iter 50000, loss: 0.095595
   Number of active neurons: 10
 >> iter 51000, loss: 0.159038
 >> iter 52000, loss: 0.139730
 >> iter 53000, loss: 0.074380
 >> iter 54000, loss: 0.030953
 >> iter 55000, loss: 0.019877
 >> iter 56000, loss: 0.009504
 >> iter 57000, loss: 0.005319
 >> iter 58000, loss: 0.003513
 >> iter 59000, loss: 0.023392
 >> iter 60000, loss: 0.010108
   Number of active neurons: 10
 >> iter 61000, loss: 0.005069
 >> iter 62000, loss: 0.067465
 >> iter 63000, loss: 0.090667
 >> iter 64000, loss: 0.095885
 >> iter 65000, loss: 0.053501
 >> iter 66000, loss: 0.022009
 >> iter 67000, loss: 0.009866
 >> iter 68000, loss: 0.005099
 >> iter 69000, loss: 0.003158
 >> iter 70000, loss: 0.002427
   Number of active neurons: 10
 >> iter 71000, loss: 0.002678
 >> iter 72000, loss: 0.046364
 >> iter 73000, loss: 0.054729
 >> iter 74000, loss: 0.023168
 >> iter 75000, loss: 0.010747
 >> iter 76000, loss: 0.005254
 >> iter 77000, loss: 0.003276
 >> iter 78000, loss: 0.062007
 >> iter 79000, loss: 0.085230
 >> iter 80000, loss: 0.037328
   Number of active neurons: 10
 >> iter 81000, loss: 0.047917
 >> iter 82000, loss: 0.026911
 >> iter 83000, loss: 0.011825
 >> iter 84000, loss: 0.005836
 >> iter 85000, loss: 0.004100
 >> iter 86000, loss: 0.017392
 >> iter 87000, loss: 0.031042
 >> iter 88000, loss: 0.013145
 >> iter 89000, loss: 0.023676
 >> iter 90000, loss: 0.026212
   Number of active neurons: 10
 >> iter 91000, loss: 0.030700
 >> iter 92000, loss: 0.012478
 >> iter 93000, loss: 0.005636
 >> iter 94000, loss: 0.002978
 >> iter 95000, loss: 0.001951
 >> iter 96000, loss: 0.001473
 >> iter 97000, loss: 0.001278
 >> iter 98000, loss: 0.001235
 >> iter 99000, loss: 0.001381
 >> iter 100000, loss: 0.001106
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.496769
 >> iter 2000, loss: 9.441769
 >> iter 3000, loss: 4.453587
 >> iter 4000, loss: 2.129918
 >> iter 5000, loss: 1.087156
 >> iter 6000, loss: 0.505139
 >> iter 7000, loss: 0.368923
 >> iter 8000, loss: 0.215901
 >> iter 9000, loss: 0.125916
 >> iter 10000, loss: 0.111153
   Number of active neurons: 10
 >> iter 11000, loss: 0.195917
 >> iter 12000, loss: 0.143600
 >> iter 13000, loss: 0.062543
 >> iter 14000, loss: 0.151394
 >> iter 15000, loss: 0.066877
 >> iter 16000, loss: 0.088151
 >> iter 17000, loss: 0.090558
 >> iter 18000, loss: 0.052443
 >> iter 19000, loss: 0.058409
 >> iter 20000, loss: 0.037465
   Number of active neurons: 10
 >> iter 21000, loss: 0.066104
 >> iter 22000, loss: 0.037152
 >> iter 23000, loss: 0.016981
 >> iter 24000, loss: 0.030023
 >> iter 25000, loss: 0.047371
 >> iter 26000, loss: 0.020779
 >> iter 27000, loss: 0.034133
 >> iter 28000, loss: 0.015355
 >> iter 29000, loss: 0.008096
 >> iter 30000, loss: 0.032747
   Number of active neurons: 10
 >> iter 31000, loss: 0.044655
 >> iter 32000, loss: 0.018936
 >> iter 33000, loss: 0.025327
 >> iter 34000, loss: 0.056303
 >> iter 35000, loss: 0.037336
 >> iter 36000, loss: 0.016417
 >> iter 37000, loss: 0.010198
 >> iter 38000, loss: 0.005753
 >> iter 39000, loss: 0.003831
 >> iter 40000, loss: 0.002876
   Number of active neurons: 10
 >> iter 41000, loss: 0.002540
 >> iter 42000, loss: 0.002326
 >> iter 43000, loss: 0.002087
 >> iter 44000, loss: 0.001996
 >> iter 45000, loss: 0.001836
 >> iter 46000, loss: 0.001674
 >> iter 47000, loss: 0.001584
 >> iter 48000, loss: 0.001598
 >> iter 49000, loss: 0.050614
 >> iter 50000, loss: 0.085772
   Number of active neurons: 10
 >> iter 51000, loss: 0.046147
 >> iter 52000, loss: 0.018991
 >> iter 53000, loss: 0.008706
 >> iter 54000, loss: 0.004841
 >> iter 55000, loss: 0.003559
 >> iter 56000, loss: 0.025779
 >> iter 57000, loss: 0.038444
 >> iter 58000, loss: 0.040440
 >> iter 59000, loss: 0.097913
 >> iter 60000, loss: 0.039324
   Number of active neurons: 10
 >> iter 61000, loss: 0.016487
 >> iter 62000, loss: 0.088994
 >> iter 63000, loss: 0.035648
 >> iter 64000, loss: 0.034338
 >> iter 65000, loss: 0.016848
 >> iter 66000, loss: 0.008236
 >> iter 67000, loss: 0.004807
 >> iter 68000, loss: 0.003279
 >> iter 69000, loss: 0.190525
 >> iter 70000, loss: 0.074784
   Number of active neurons: 10
 >> iter 71000, loss: 0.030159
 >> iter 72000, loss: 0.016551
 >> iter 73000, loss: 0.008611
 >> iter 74000, loss: 0.004745
 >> iter 75000, loss: 0.003193
 >> iter 76000, loss: 0.002477
 >> iter 77000, loss: 0.002170
 >> iter 78000, loss: 0.001867
 >> iter 79000, loss: 0.001717
 >> iter 80000, loss: 0.001535
   Number of active neurons: 10
 >> iter 81000, loss: 0.001456
 >> iter 82000, loss: 0.001418
 >> iter 83000, loss: 0.001339
 >> iter 84000, loss: 0.001247
 >> iter 85000, loss: 0.001232
 >> iter 86000, loss: 0.001193
 >> iter 87000, loss: 0.001173
 >> iter 88000, loss: 0.001102
 >> iter 89000, loss: 0.014620
 >> iter 90000, loss: 0.006223
   Number of active neurons: 10
 >> iter 91000, loss: 0.013698
 >> iter 92000, loss: 0.005846
 >> iter 93000, loss: 0.003008
 >> iter 94000, loss: 0.001842
 >> iter 95000, loss: 0.001388
 >> iter 96000, loss: 0.001120
 >> iter 97000, loss: 0.001071
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.185993
 >> iter 2000, loss: 9.545490
 >> iter 3000, loss: 5.282724
 >> iter 4000, loss: 2.729211
 >> iter 5000, loss: 1.351103
 >> iter 6000, loss: 0.620142
 >> iter 7000, loss: 0.369815
 >> iter 8000, loss: 0.188496
 >> iter 9000, loss: 0.135824
 >> iter 10000, loss: 0.089935
   Number of active neurons: 10
 >> iter 11000, loss: 0.052621
 >> iter 12000, loss: 0.026951
 >> iter 13000, loss: 0.076003
 >> iter 14000, loss: 0.039856
 >> iter 15000, loss: 0.067530
 >> iter 16000, loss: 0.088230
 >> iter 17000, loss: 0.166794
 >> iter 18000, loss: 0.079662
 >> iter 19000, loss: 0.049035
 >> iter 20000, loss: 0.023679
   Number of active neurons: 10
 >> iter 21000, loss: 0.046101
 >> iter 22000, loss: 0.021581
 >> iter 23000, loss: 0.011472
 >> iter 24000, loss: 0.070215
 >> iter 25000, loss: 0.029851
 >> iter 26000, loss: 0.014081
 >> iter 27000, loss: 0.008286
 >> iter 28000, loss: 0.075792
 >> iter 29000, loss: 0.068736
 >> iter 30000, loss: 0.036135
   Number of active neurons: 10
 >> iter 31000, loss: 0.034025
 >> iter 32000, loss: 0.020152
 >> iter 33000, loss: 0.024045
 >> iter 34000, loss: 0.013546
 >> iter 35000, loss: 0.007349
 >> iter 36000, loss: 0.004884
 >> iter 37000, loss: 0.003919
 >> iter 38000, loss: 0.129527
 >> iter 39000, loss: 0.050644
 >> iter 40000, loss: 0.054118
   Number of active neurons: 10
 >> iter 41000, loss: 0.022212
 >> iter 42000, loss: 0.010135
 >> iter 43000, loss: 0.018951
 >> iter 44000, loss: 0.012471
 >> iter 45000, loss: 0.006892
 >> iter 46000, loss: 0.019411
 >> iter 47000, loss: 0.008962
 >> iter 48000, loss: 0.015217
 >> iter 49000, loss: 0.007942
 >> iter 50000, loss: 0.018750
   Number of active neurons: 10
 >> iter 51000, loss: 0.192754
 >> iter 52000, loss: 0.140248
 >> iter 53000, loss: 0.107689
 >> iter 54000, loss: 0.044416
 >> iter 55000, loss: 0.030827
 >> iter 56000, loss: 0.028673
 >> iter 57000, loss: 0.014212
 >> iter 58000, loss: 0.009312
 >> iter 59000, loss: 0.006295
 >> iter 60000, loss: 0.007159
   Number of active neurons: 10
 >> iter 61000, loss: 0.004291
 >> iter 62000, loss: 0.003323
 >> iter 63000, loss: 0.002654
 >> iter 64000, loss: 0.002543
 >> iter 65000, loss: 0.002313
 >> iter 66000, loss: 0.002025
 >> iter 67000, loss: 0.001896
 >> iter 68000, loss: 0.001729
 >> iter 69000, loss: 0.018465
 >> iter 70000, loss: 0.017050
   Number of active neurons: 10
 >> iter 71000, loss: 0.007745
 >> iter 72000, loss: 0.003906
 >> iter 73000, loss: 0.020323
 >> iter 74000, loss: 0.008544
 >> iter 75000, loss: 0.004204
 >> iter 76000, loss: 0.002696
 >> iter 77000, loss: 0.001835
 >> iter 78000, loss: 0.001466
 >> iter 79000, loss: 0.001347
 >> iter 80000, loss: 0.001689
   Number of active neurons: 10
 >> iter 81000, loss: 0.017234
 >> iter 82000, loss: 0.007366
 >> iter 83000, loss: 0.003672
 >> iter 84000, loss: 0.002175
 >> iter 85000, loss: 0.001619
 >> iter 86000, loss: 0.001326
 >> iter 87000, loss: 0.001251
 >> iter 88000, loss: 0.001191
 >> iter 89000, loss: 0.001113
 >> iter 90000, loss: 0.029105
   Number of active neurons: 10
 >> iter 91000, loss: 0.011860
 >> iter 92000, loss: 0.005216
 >> iter 93000, loss: 0.002826
 >> iter 94000, loss: 0.042907
 >> iter 95000, loss: 0.016973
 >> iter 96000, loss: 0.020994
 >> iter 97000, loss: 0.009528
 >> iter 98000, loss: 0.004450
 >> iter 99000, loss: 0.053886
 >> iter 100000, loss: 0.041369
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.323833
 >> iter 2000, loss: 9.249710
 >> iter 3000, loss: 4.663470
 >> iter 4000, loss: 1.996510
 >> iter 5000, loss: 0.951104
 >> iter 6000, loss: 0.469347
 >> iter 7000, loss: 0.244166
 >> iter 8000, loss: 0.105988
 >> iter 9000, loss: 0.102196
 >> iter 10000, loss: 0.072036
   Number of active neurons: 10
 >> iter 11000, loss: 0.064179
 >> iter 12000, loss: 0.074286
 >> iter 13000, loss: 0.067285
 >> iter 14000, loss: 0.029385
 >> iter 15000, loss: 0.014907
 >> iter 16000, loss: 0.008961
 >> iter 17000, loss: 0.007210
 >> iter 18000, loss: 0.005509
 >> iter 19000, loss: 0.004844
 >> iter 20000, loss: 0.015938
   Number of active neurons: 10
 >> iter 21000, loss: 0.008058
 >> iter 22000, loss: 0.090865
 >> iter 23000, loss: 0.040466
 >> iter 24000, loss: 0.031673
 >> iter 25000, loss: 0.050672
 >> iter 26000, loss: 0.084351
 >> iter 27000, loss: 0.047374
 >> iter 28000, loss: 0.020620
 >> iter 29000, loss: 0.010241
 >> iter 30000, loss: 0.006020
   Number of active neurons: 10
 >> iter 31000, loss: 0.004814
 >> iter 32000, loss: 0.033366
 >> iter 33000, loss: 0.014539
 >> iter 34000, loss: 0.007038
 >> iter 35000, loss: 0.004225
 >> iter 36000, loss: 0.006676
 >> iter 37000, loss: 0.015603
 >> iter 38000, loss: 0.007722
 >> iter 39000, loss: 0.005043
 >> iter 40000, loss: 0.003180
   Number of active neurons: 10
 >> iter 41000, loss: 0.002519
 >> iter 42000, loss: 0.002039
 >> iter 43000, loss: 0.001720
 >> iter 44000, loss: 0.001557
 >> iter 45000, loss: 0.040271
 >> iter 46000, loss: 0.016135
 >> iter 47000, loss: 0.038588
 >> iter 48000, loss: 0.015478
 >> iter 49000, loss: 0.006883
 >> iter 50000, loss: 0.003616
   Number of active neurons: 10
 >> iter 51000, loss: 0.002466
 >> iter 52000, loss: 0.001843
 >> iter 53000, loss: 0.001631
 >> iter 54000, loss: 0.001441
 >> iter 55000, loss: 0.001354
 >> iter 56000, loss: 0.001328
 >> iter 57000, loss: 0.001309
 >> iter 58000, loss: 0.087072
 >> iter 59000, loss: 0.033398
 >> iter 60000, loss: 0.036412
   Number of active neurons: 10
 >> iter 61000, loss: 0.014818
 >> iter 62000, loss: 0.006714
 >> iter 63000, loss: 0.003631
 >> iter 64000, loss: 0.002336
 >> iter 65000, loss: 0.001894
 >> iter 66000, loss: 0.001557
 >> iter 67000, loss: 0.001402
 >> iter 68000, loss: 0.026788
 >> iter 69000, loss: 0.010895
 >> iter 70000, loss: 0.004913
   Number of active neurons: 10
 >> iter 71000, loss: 0.002730
 >> iter 72000, loss: 0.001814
 >> iter 73000, loss: 0.001395
 >> iter 74000, loss: 0.001528
 >> iter 75000, loss: 0.006813
 >> iter 76000, loss: 0.003291
 >> iter 77000, loss: 0.001928
 >> iter 78000, loss: 0.001362
 >> iter 79000, loss: 0.001154
 >> iter 80000, loss: 0.001240
   Number of active neurons: 10
 >> iter 81000, loss: 0.001079
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.584765
 >> iter 2000, loss: 9.315415
 >> iter 3000, loss: 4.504087
 >> iter 4000, loss: 1.866821
 >> iter 5000, loss: 0.749538
 >> iter 6000, loss: 0.437345
 >> iter 7000, loss: 0.207942
 >> iter 8000, loss: 0.124037
 >> iter 9000, loss: 0.095689
 >> iter 10000, loss: 0.119917
   Number of active neurons: 10
 >> iter 11000, loss: 0.090436
 >> iter 12000, loss: 0.069134
 >> iter 13000, loss: 0.089684
 >> iter 14000, loss: 0.064885
 >> iter 15000, loss: 0.028556
 >> iter 16000, loss: 0.023770
 >> iter 17000, loss: 0.016962
 >> iter 18000, loss: 0.048514
 >> iter 19000, loss: 0.025033
 >> iter 20000, loss: 0.012029
   Number of active neurons: 10
 >> iter 21000, loss: 0.033797
 >> iter 22000, loss: 0.035682
 >> iter 23000, loss: 0.015865
 >> iter 24000, loss: 0.008078
 >> iter 25000, loss: 0.004965
 >> iter 26000, loss: 0.015108
 >> iter 27000, loss: 0.007402
 >> iter 28000, loss: 0.029198
 >> iter 29000, loss: 0.061310
 >> iter 30000, loss: 0.064349
   Number of active neurons: 10
 >> iter 31000, loss: 0.031245
 >> iter 32000, loss: 0.014558
 >> iter 33000, loss: 0.007101
 >> iter 34000, loss: 0.004120
 >> iter 35000, loss: 0.024387
 >> iter 36000, loss: 0.011029
 >> iter 37000, loss: 0.005643
 >> iter 38000, loss: 0.003487
 >> iter 39000, loss: 0.085804
 >> iter 40000, loss: 0.091955
   Number of active neurons: 10
 >> iter 41000, loss: 0.067346
 >> iter 42000, loss: 0.027239
 >> iter 43000, loss: 0.012060
 >> iter 44000, loss: 0.006040
 >> iter 45000, loss: 0.003648
 >> iter 46000, loss: 0.068354
 >> iter 47000, loss: 0.027730
 >> iter 48000, loss: 0.038959
 >> iter 49000, loss: 0.037226
 >> iter 50000, loss: 0.093131
   Number of active neurons: 10
 >> iter 51000, loss: 0.039033
 >> iter 52000, loss: 0.016807
 >> iter 53000, loss: 0.009241
 >> iter 54000, loss: 0.015824
 >> iter 55000, loss: 0.008836
 >> iter 56000, loss: 0.007561
 >> iter 57000, loss: 0.004388
 >> iter 58000, loss: 0.003165
 >> iter 59000, loss: 0.002431
 >> iter 60000, loss: 0.002236
   Number of active neurons: 10
 >> iter 61000, loss: 0.001991
 >> iter 62000, loss: 0.001727
 >> iter 63000, loss: 0.001564
 >> iter 64000, loss: 0.001472
 >> iter 65000, loss: 0.001446
 >> iter 66000, loss: 0.001308
 >> iter 67000, loss: 0.001348
 >> iter 68000, loss: 0.001233
 >> iter 69000, loss: 0.001154
 >> iter 70000, loss: 0.001341
   Number of active neurons: 10
 >> iter 71000, loss: 0.014751
 >> iter 72000, loss: 0.006189
 >> iter 73000, loss: 0.003000
 >> iter 74000, loss: 0.001744
 >> iter 75000, loss: 0.001316
 >> iter 76000, loss: 0.001067
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.131658
 >> iter 2000, loss: 9.100730
 >> iter 3000, loss: 4.863071
 >> iter 4000, loss: 2.524600
 >> iter 5000, loss: 1.184412
 >> iter 6000, loss: 0.642169
 >> iter 7000, loss: 0.342984
 >> iter 8000, loss: 0.345039
 >> iter 9000, loss: 0.353896
 >> iter 10000, loss: 0.260773
   Number of active neurons: 10
 >> iter 11000, loss: 0.258843
 >> iter 12000, loss: 0.284793
 >> iter 13000, loss: 0.414144
 >> iter 14000, loss: 0.225799
 >> iter 15000, loss: 0.211971
 >> iter 16000, loss: 0.169894
 >> iter 17000, loss: 0.071866
 >> iter 18000, loss: 0.097757
 >> iter 19000, loss: 0.079978
 >> iter 20000, loss: 0.057353
   Number of active neurons: 10
 >> iter 21000, loss: 0.027161
 >> iter 22000, loss: 0.021919
 >> iter 23000, loss: 0.012275
 >> iter 24000, loss: 0.007989
 >> iter 25000, loss: 0.049685
 >> iter 26000, loss: 0.021798
 >> iter 27000, loss: 0.010971
 >> iter 28000, loss: 0.006541
 >> iter 29000, loss: 0.005219
 >> iter 30000, loss: 0.004068
   Number of active neurons: 10
 >> iter 31000, loss: 0.031485
 >> iter 32000, loss: 0.124165
 >> iter 33000, loss: 0.066007
 >> iter 34000, loss: 0.062179
 >> iter 35000, loss: 0.048747
 >> iter 36000, loss: 0.020958
 >> iter 37000, loss: 0.010283
 >> iter 38000, loss: 0.006160
 >> iter 39000, loss: 0.004462
 >> iter 40000, loss: 0.011722
   Number of active neurons: 10
 >> iter 41000, loss: 0.045015
 >> iter 42000, loss: 0.036770
 >> iter 43000, loss: 0.044568
 >> iter 44000, loss: 0.028066
 >> iter 45000, loss: 0.012942
 >> iter 46000, loss: 0.006980
 >> iter 47000, loss: 0.004789
 >> iter 48000, loss: 0.003697
 >> iter 49000, loss: 0.003533
 >> iter 50000, loss: 0.002951
   Number of active neurons: 10
 >> iter 51000, loss: 0.028081
 >> iter 52000, loss: 0.012069
 >> iter 53000, loss: 0.029100
 >> iter 54000, loss: 0.012503
 >> iter 55000, loss: 0.010928
 >> iter 56000, loss: 0.007292
 >> iter 57000, loss: 0.006350
 >> iter 58000, loss: 0.003727
 >> iter 59000, loss: 0.019141
 >> iter 60000, loss: 0.008777
   Number of active neurons: 10
 >> iter 61000, loss: 0.007282
 >> iter 62000, loss: 0.003915
 >> iter 63000, loss: 0.003253
 >> iter 64000, loss: 0.013577
 >> iter 65000, loss: 0.006183
 >> iter 66000, loss: 0.003383
 >> iter 67000, loss: 0.002346
 >> iter 68000, loss: 0.001893
 >> iter 69000, loss: 0.001728
 >> iter 70000, loss: 0.001724
   Number of active neurons: 10
 >> iter 71000, loss: 0.014882
 >> iter 72000, loss: 0.006631
 >> iter 73000, loss: 0.003512
 >> iter 74000, loss: 0.003069
 >> iter 75000, loss: 0.002135
 >> iter 76000, loss: 0.001697
 >> iter 77000, loss: 0.001516
 >> iter 78000, loss: 0.001446
 >> iter 79000, loss: 0.018224
 >> iter 80000, loss: 0.014757
   Number of active neurons: 10
 >> iter 81000, loss: 0.027337
 >> iter 82000, loss: 0.011132
 >> iter 83000, loss: 0.005133
 >> iter 84000, loss: 0.002837
 >> iter 85000, loss: 0.001971
 >> iter 86000, loss: 0.001590
 >> iter 87000, loss: 0.001445
 >> iter 88000, loss: 0.001324
 >> iter 89000, loss: 0.001308
 >> iter 90000, loss: 0.001223
   Number of active neurons: 10
 >> iter 91000, loss: 0.001210
 >> iter 92000, loss: 0.003846
 >> iter 93000, loss: 0.002279
 >> iter 94000, loss: 0.001599
 >> iter 95000, loss: 0.017204
 >> iter 96000, loss: 0.007209
 >> iter 97000, loss: 0.030031
 >> iter 98000, loss: 0.012059
 >> iter 99000, loss: 0.005363
 >> iter 100000, loss: 0.002824
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.603536
 >> iter 2000, loss: 8.963552
 >> iter 3000, loss: 3.828402
 >> iter 4000, loss: 1.677059
 >> iter 5000, loss: 0.736135
 >> iter 6000, loss: 0.443522
 >> iter 7000, loss: 0.271858
 >> iter 8000, loss: 0.189920
 >> iter 9000, loss: 0.079958
 >> iter 10000, loss: 0.052784
   Number of active neurons: 10
 >> iter 11000, loss: 0.081846
 >> iter 12000, loss: 0.036439
 >> iter 13000, loss: 0.017986
 >> iter 14000, loss: 0.010391
 >> iter 15000, loss: 0.048409
 >> iter 16000, loss: 0.054709
 >> iter 17000, loss: 0.037059
 >> iter 18000, loss: 0.016757
 >> iter 19000, loss: 0.015123
 >> iter 20000, loss: 0.110911
   Number of active neurons: 10
 >> iter 21000, loss: 0.071261
 >> iter 22000, loss: 0.033338
 >> iter 23000, loss: 0.067268
 >> iter 24000, loss: 0.035333
 >> iter 25000, loss: 0.025779
 >> iter 26000, loss: 0.038113
 >> iter 27000, loss: 0.032189
 >> iter 28000, loss: 0.014482
 >> iter 29000, loss: 0.017111
 >> iter 30000, loss: 0.042084
   Number of active neurons: 10
 >> iter 31000, loss: 0.018333
 >> iter 32000, loss: 0.008914
 >> iter 33000, loss: 0.014105
 >> iter 34000, loss: 0.017664
 >> iter 35000, loss: 0.024530
 >> iter 36000, loss: 0.020981
 >> iter 37000, loss: 0.011724
 >> iter 38000, loss: 0.006220
 >> iter 39000, loss: 0.019395
 >> iter 40000, loss: 0.081199
   Number of active neurons: 10
 >> iter 41000, loss: 0.035022
 >> iter 42000, loss: 0.015119
 >> iter 43000, loss: 0.008057
 >> iter 44000, loss: 0.004491
 >> iter 45000, loss: 0.003200
 >> iter 46000, loss: 0.002628
 >> iter 47000, loss: 0.002218
 >> iter 48000, loss: 0.010168
 >> iter 49000, loss: 0.004931
 >> iter 50000, loss: 0.002876
   Number of active neurons: 10
 >> iter 51000, loss: 0.002036
 >> iter 52000, loss: 0.001659
 >> iter 53000, loss: 0.001445
 >> iter 54000, loss: 0.001381
 >> iter 55000, loss: 0.001281
 >> iter 56000, loss: 0.001205
 >> iter 57000, loss: 0.001143
 >> iter 58000, loss: 0.001246
 >> iter 59000, loss: 0.001127
 >> iter 60000, loss: 0.001368
   Number of active neurons: 10
 >> iter 61000, loss: 0.003397
 >> iter 62000, loss: 0.003236
 >> iter 63000, loss: 0.003423
 >> iter 64000, loss: 0.014820
 >> iter 65000, loss: 0.006634
 >> iter 66000, loss: 0.003386
 >> iter 67000, loss: 0.001909
 >> iter 68000, loss: 0.029733
 >> iter 69000, loss: 0.011631
 >> iter 70000, loss: 0.004912
   Number of active neurons: 10
 >> iter 71000, loss: 0.002478
 >> iter 72000, loss: 0.005184
 >> iter 73000, loss: 0.002720
 >> iter 74000, loss: 0.026745
 >> iter 75000, loss: 0.011366
 >> iter 76000, loss: 0.007848
 >> iter 77000, loss: 0.004201
 >> iter 78000, loss: 0.002281
 >> iter 79000, loss: 0.001487
 >> iter 80000, loss: 0.011765
   Number of active neurons: 10
 >> iter 81000, loss: 0.020208
 >> iter 82000, loss: 0.008270
 >> iter 83000, loss: 0.003762
 >> iter 84000, loss: 0.002029
 >> iter 85000, loss: 0.001580
 >> iter 86000, loss: 0.057161
 >> iter 87000, loss: 0.021973
 >> iter 88000, loss: 0.008864
 >> iter 89000, loss: 0.004024
 >> iter 90000, loss: 0.009782
   Number of active neurons: 10
 >> iter 91000, loss: 0.005831
 >> iter 92000, loss: 0.002780
 >> iter 93000, loss: 0.002448
 >> iter 94000, loss: 0.001644
 >> iter 95000, loss: 0.001290
 >> iter 96000, loss: 0.058401
 >> iter 97000, loss: 0.032382
 >> iter 98000, loss: 0.012864
 >> iter 99000, loss: 0.005540
 >> iter 100000, loss: 0.002773
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

