 > Problema: tomita1nueva
 > Args:
   - Hidden size: 16
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.926527
 >> iter 2000, loss: 4.070196
 >> iter 3000, loss: 1.523934
 >> iter 4000, loss: 0.588615
 >> iter 5000, loss: 0.236009
 >> iter 6000, loss: 0.119921
 >> iter 7000, loss: 0.080530
 >> iter 8000, loss: 0.051184
 >> iter 9000, loss: 0.041908
 >> iter 10000, loss: 0.039070
   Number of active neurons: 4
 >> iter 11000, loss: 0.037202
 >> iter 12000, loss: 0.033079
 >> iter 13000, loss: 0.029316
 >> iter 14000, loss: 0.028189
 >> iter 15000, loss: 0.027475
 >> iter 16000, loss: 0.026908
 >> iter 17000, loss: 0.025845
 >> iter 18000, loss: 0.027707
 >> iter 19000, loss: 0.028369
 >> iter 20000, loss: 0.028455
   Number of active neurons: 3
 >> iter 21000, loss: 0.024193
 >> iter 22000, loss: 0.023084
 >> iter 23000, loss: 0.024403
 >> iter 24000, loss: 0.028029
 >> iter 25000, loss: 0.024466
 >> iter 26000, loss: 0.025740
 >> iter 27000, loss: 0.024239
 >> iter 28000, loss: 0.022720
 >> iter 29000, loss: 0.024078
 >> iter 30000, loss: 0.023943
   Number of active neurons: 2
 >> iter 31000, loss: 0.024693
 >> iter 32000, loss: 0.021785
 >> iter 33000, loss: 0.021853
 >> iter 34000, loss: 0.034354
 >> iter 35000, loss: 0.030702
 >> iter 36000, loss: 0.024695
 >> iter 37000, loss: 0.023210
 >> iter 38000, loss: 0.021812
 >> iter 39000, loss: 0.022167
 >> iter 40000, loss: 0.036431
   Number of active neurons: 2
 >> iter 41000, loss: 0.038123
 >> iter 42000, loss: 0.029079
 >> iter 43000, loss: 0.026808
 >> iter 44000, loss: 0.025032
 >> iter 45000, loss: 0.021350
 >> iter 46000, loss: 0.020095
 >> iter 47000, loss: 0.023824
 >> iter 48000, loss: 0.025617
 >> iter 49000, loss: 0.023221
 >> iter 50000, loss: 0.022481
   Number of active neurons: 2
 >> iter 51000, loss: 0.020613
 >> iter 52000, loss: 0.021096
 >> iter 53000, loss: 0.038660
 >> iter 54000, loss: 0.029127
 >> iter 55000, loss: 0.029056
 >> iter 56000, loss: 0.024303
 >> iter 57000, loss: 0.026615
 >> iter 58000, loss: 0.022498
 >> iter 59000, loss: 0.021235
 >> iter 60000, loss: 0.022690
   Number of active neurons: 2
 >> iter 61000, loss: 0.023340
 >> iter 62000, loss: 0.026240
 >> iter 63000, loss: 0.031405
 >> iter 64000, loss: 0.026705
 >> iter 65000, loss: 0.025446
 >> iter 66000, loss: 0.036253
 >> iter 67000, loss: 0.031333
 >> iter 68000, loss: 0.026547
 >> iter 69000, loss: 0.027168
 >> iter 70000, loss: 0.034253
   Number of active neurons: 2
 >> iter 71000, loss: 0.031966
 >> iter 72000, loss: 0.025362
 >> iter 73000, loss: 0.027948
 >> iter 74000, loss: 0.022025
 >> iter 75000, loss: 0.024888
 >> iter 76000, loss: 0.038648
 >> iter 77000, loss: 0.039555
 >> iter 78000, loss: 0.037233
 >> iter 79000, loss: 0.028675
 >> iter 80000, loss: 0.031217
   Number of active neurons: 2
 >> iter 81000, loss: 0.028429
 >> iter 82000, loss: 0.050341
 >> iter 83000, loss: 0.034763
 >> iter 84000, loss: 0.025328
 >> iter 85000, loss: 0.022390
 >> iter 86000, loss: 0.026260
 >> iter 87000, loss: 0.022630
 >> iter 88000, loss: 0.020466
 >> iter 89000, loss: 0.022458
 >> iter 90000, loss: 0.026955
   Number of active neurons: 1
 >> iter 91000, loss: 0.022078
 >> iter 92000, loss: 0.023846
 >> iter 93000, loss: 0.020427
 >> iter 94000, loss: 0.019683
 >> iter 95000, loss: 0.023049
 >> iter 96000, loss: 0.019535
 >> iter 97000, loss: 0.020364
 >> iter 98000, loss: 0.019778
 >> iter 99000, loss: 0.018805
 >> iter 100000, loss: 0.018356
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 10.923701
 >> iter 2000, loss: 4.060043
 >> iter 3000, loss: 1.520531
 >> iter 4000, loss: 0.602088
 >> iter 5000, loss: 0.245112
 >> iter 6000, loss: 0.107855
 >> iter 7000, loss: 0.069487
 >> iter 8000, loss: 0.043340
 >> iter 9000, loss: 0.059982
 >> iter 10000, loss: 0.052818
   Number of active neurons: 4
 >> iter 11000, loss: 0.042155
 >> iter 12000, loss: 0.034929
 >> iter 13000, loss: 0.035140
 >> iter 14000, loss: 0.035049
 >> iter 15000, loss: 0.037209
 >> iter 16000, loss: 0.036268
 >> iter 17000, loss: 0.033662
 >> iter 18000, loss: 0.027817
 >> iter 19000, loss: 0.026119
 >> iter 20000, loss: 0.028003
   Number of active neurons: 4
 >> iter 21000, loss: 0.029585
 >> iter 22000, loss: 0.027354
 >> iter 23000, loss: 0.032447
 >> iter 24000, loss: 0.028117
 >> iter 25000, loss: 0.031041
 >> iter 26000, loss: 0.026566
 >> iter 27000, loss: 0.024335
 >> iter 28000, loss: 0.027646
 >> iter 29000, loss: 0.029023
 >> iter 30000, loss: 0.026595
   Number of active neurons: 3
 >> iter 31000, loss: 0.031378
 >> iter 32000, loss: 0.035783
 >> iter 33000, loss: 0.034098
 >> iter 34000, loss: 0.028544
 >> iter 35000, loss: 0.026839
 >> iter 36000, loss: 0.027018
 >> iter 37000, loss: 0.024345
 >> iter 38000, loss: 0.023209
 >> iter 39000, loss: 0.033092
 >> iter 40000, loss: 0.025632
   Number of active neurons: 2
 >> iter 41000, loss: 0.027142
 >> iter 42000, loss: 0.022764
 >> iter 43000, loss: 0.025279
 >> iter 44000, loss: 0.034542
 >> iter 45000, loss: 0.024663
 >> iter 46000, loss: 0.022969
 >> iter 47000, loss: 0.026331
 >> iter 48000, loss: 0.021321
 >> iter 49000, loss: 0.018406
 >> iter 50000, loss: 0.019428
   Number of active neurons: 1
 >> iter 51000, loss: 0.041306
 >> iter 52000, loss: 0.030683
 >> iter 53000, loss: 0.026551
 >> iter 54000, loss: 0.021595
 >> iter 55000, loss: 0.018266
 >> iter 56000, loss: 0.017585
 >> iter 57000, loss: 0.023515
 >> iter 58000, loss: 0.038064
 >> iter 59000, loss: 0.025710
 >> iter 60000, loss: 0.028166
   Number of active neurons: 1
 >> iter 61000, loss: 0.020691
 >> iter 62000, loss: 0.019825
 >> iter 63000, loss: 0.022775
 >> iter 64000, loss: 0.024024
 >> iter 65000, loss: 0.021742
 >> iter 66000, loss: 0.030147
 >> iter 67000, loss: 0.022220
 >> iter 68000, loss: 0.022408
 >> iter 69000, loss: 0.018728
 >> iter 70000, loss: 0.023096
   Number of active neurons: 1
 >> iter 71000, loss: 0.018370
 >> iter 72000, loss: 0.021799
 >> iter 73000, loss: 0.037685
 >> iter 74000, loss: 0.030113
 >> iter 75000, loss: 0.022239
 >> iter 76000, loss: 0.023654
 >> iter 77000, loss: 0.020340
 >> iter 78000, loss: 0.019162
 >> iter 79000, loss: 0.047698
 >> iter 80000, loss: 0.031995
   Number of active neurons: 1
 >> iter 81000, loss: 0.032237
 >> iter 82000, loss: 0.024385
 >> iter 83000, loss: 0.021627
 >> iter 84000, loss: 0.018448
 >> iter 85000, loss: 0.017859
 >> iter 86000, loss: 0.018184
 >> iter 87000, loss: 0.018233
 >> iter 88000, loss: 0.016654
 >> iter 89000, loss: 0.016379
 >> iter 90000, loss: 0.023992
   Number of active neurons: 1
 >> iter 91000, loss: 0.026379
 >> iter 92000, loss: 0.019627
 >> iter 93000, loss: 0.017825
 >> iter 94000, loss: 0.019242
 >> iter 95000, loss: 0.028201
 >> iter 96000, loss: 0.019818
 >> iter 97000, loss: 0.021825
 >> iter 98000, loss: 0.018372
 >> iter 99000, loss: 0.016890
 >> iter 100000, loss: 0.018536
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.966156
 >> iter 2000, loss: 4.081676
 >> iter 3000, loss: 1.542460
 >> iter 4000, loss: 0.596183
 >> iter 5000, loss: 0.248511
 >> iter 6000, loss: 0.115405
 >> iter 7000, loss: 0.066348
 >> iter 8000, loss: 0.046210
 >> iter 9000, loss: 0.041046
 >> iter 10000, loss: 0.037815
   Number of active neurons: 7
 >> iter 11000, loss: 0.038989
 >> iter 12000, loss: 0.041424
 >> iter 13000, loss: 0.038578
 >> iter 14000, loss: 0.032184
 >> iter 15000, loss: 0.030955
 >> iter 16000, loss: 0.035370
 >> iter 17000, loss: 0.038117
 >> iter 18000, loss: 0.032244
 >> iter 19000, loss: 0.030881
 >> iter 20000, loss: 0.028685
   Number of active neurons: 4
 >> iter 21000, loss: 0.042429
 >> iter 22000, loss: 0.034308
 >> iter 23000, loss: 0.033957
 >> iter 24000, loss: 0.027251
 >> iter 25000, loss: 0.030000
 >> iter 26000, loss: 0.028919
 >> iter 27000, loss: 0.027716
 >> iter 28000, loss: 0.031887
 >> iter 29000, loss: 0.026903
 >> iter 30000, loss: 0.026802
   Number of active neurons: 2
 >> iter 31000, loss: 0.040856
 >> iter 32000, loss: 0.031159
 >> iter 33000, loss: 0.029594
 >> iter 34000, loss: 0.041030
 >> iter 35000, loss: 0.034678
 >> iter 36000, loss: 0.026818
 >> iter 37000, loss: 0.023456
 >> iter 38000, loss: 0.021060
 >> iter 39000, loss: 0.023749
 >> iter 40000, loss: 0.021226
   Number of active neurons: 2
 >> iter 41000, loss: 0.024035
 >> iter 42000, loss: 0.022008
 >> iter 43000, loss: 0.027906
 >> iter 44000, loss: 0.023586
 >> iter 45000, loss: 0.023564
 >> iter 46000, loss: 0.021539
 >> iter 47000, loss: 0.024760
 >> iter 48000, loss: 0.023470
 >> iter 49000, loss: 0.038342
 >> iter 50000, loss: 0.041863
   Number of active neurons: 2
 >> iter 51000, loss: 0.029178
 >> iter 52000, loss: 0.026034
 >> iter 53000, loss: 0.029150
 >> iter 54000, loss: 0.028144
 >> iter 55000, loss: 0.023820
 >> iter 56000, loss: 0.020497
 >> iter 57000, loss: 0.020804
 >> iter 58000, loss: 0.022721
 >> iter 59000, loss: 0.021444
 >> iter 60000, loss: 0.025832
   Number of active neurons: 2
 >> iter 61000, loss: 0.024959
 >> iter 62000, loss: 0.020636
 >> iter 63000, loss: 0.021226
 >> iter 64000, loss: 0.021986
 >> iter 65000, loss: 0.027036
 >> iter 66000, loss: 0.024127
 >> iter 67000, loss: 0.020724
 >> iter 68000, loss: 0.019510
 >> iter 69000, loss: 0.018880
 >> iter 70000, loss: 0.033507
   Number of active neurons: 1
 >> iter 71000, loss: 0.023933
 >> iter 72000, loss: 0.021717
 >> iter 73000, loss: 0.026988
 >> iter 74000, loss: 0.020428
 >> iter 75000, loss: 0.017944
 >> iter 76000, loss: 0.024319
 >> iter 77000, loss: 0.028409
 >> iter 78000, loss: 0.020607
 >> iter 79000, loss: 0.033546
 >> iter 80000, loss: 0.048578
   Number of active neurons: 1
 >> iter 81000, loss: 0.039949
 >> iter 82000, loss: 0.026088
 >> iter 83000, loss: 0.020908
 >> iter 84000, loss: 0.019105
 >> iter 85000, loss: 0.020739
 >> iter 86000, loss: 0.021027
 >> iter 87000, loss: 0.019619
 >> iter 88000, loss: 0.017443
 >> iter 89000, loss: 0.016971
 >> iter 90000, loss: 0.016891
   Number of active neurons: 1
 >> iter 91000, loss: 0.025546
 >> iter 92000, loss: 0.021314
 >> iter 93000, loss: 0.019378
 >> iter 94000, loss: 0.017258
 >> iter 95000, loss: 0.016771
 >> iter 96000, loss: 0.023481
 >> iter 97000, loss: 0.033982
 >> iter 98000, loss: 0.038274
 >> iter 99000, loss: 0.024561
 >> iter 100000, loss: 0.020647
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 10.952789
 >> iter 2000, loss: 4.065440
 >> iter 3000, loss: 1.526684
 >> iter 4000, loss: 0.584814
 >> iter 5000, loss: 0.244130
 >> iter 6000, loss: 0.110715
 >> iter 7000, loss: 0.056693
 >> iter 8000, loss: 0.043273
 >> iter 9000, loss: 0.035859
 >> iter 10000, loss: 0.037796
   Number of active neurons: 5
 >> iter 11000, loss: 0.031276
 >> iter 12000, loss: 0.028801
 >> iter 13000, loss: 0.028650
 >> iter 14000, loss: 0.035175
 >> iter 15000, loss: 0.030269
 >> iter 16000, loss: 0.033292
 >> iter 17000, loss: 0.031714
 >> iter 18000, loss: 0.035201
 >> iter 19000, loss: 0.033175
 >> iter 20000, loss: 0.026983
   Number of active neurons: 2
 >> iter 21000, loss: 0.025891
 >> iter 22000, loss: 0.022408
 >> iter 23000, loss: 0.059044
 >> iter 24000, loss: 0.045301
 >> iter 25000, loss: 0.030440
 >> iter 26000, loss: 0.026930
 >> iter 27000, loss: 0.022161
 >> iter 28000, loss: 0.023782
 >> iter 29000, loss: 0.024421
 >> iter 30000, loss: 0.021438
   Number of active neurons: 2
 >> iter 31000, loss: 0.022558
 >> iter 32000, loss: 0.038053
 >> iter 33000, loss: 0.035605
 >> iter 34000, loss: 0.027560
 >> iter 35000, loss: 0.047458
 >> iter 36000, loss: 0.031946
 >> iter 37000, loss: 0.025836
 >> iter 38000, loss: 0.021331
 >> iter 39000, loss: 0.028534
 >> iter 40000, loss: 0.026398
   Number of active neurons: 2
 >> iter 41000, loss: 0.022369
 >> iter 42000, loss: 0.031645
 >> iter 43000, loss: 0.037441
 >> iter 44000, loss: 0.027604
 >> iter 45000, loss: 0.023697
 >> iter 46000, loss: 0.024195
 >> iter 47000, loss: 0.023995
 >> iter 48000, loss: 0.022973
 >> iter 49000, loss: 0.024590
 >> iter 50000, loss: 0.031327
   Number of active neurons: 2
 >> iter 51000, loss: 0.025389
 >> iter 52000, loss: 0.043332
 >> iter 53000, loss: 0.031171
 >> iter 54000, loss: 0.030287
 >> iter 55000, loss: 0.035917
 >> iter 56000, loss: 0.027772
 >> iter 57000, loss: 0.023893
 >> iter 58000, loss: 0.020699
 >> iter 59000, loss: 0.019974
 >> iter 60000, loss: 0.030171
   Number of active neurons: 2
 >> iter 61000, loss: 0.028009
 >> iter 62000, loss: 0.024517
 >> iter 63000, loss: 0.024880
 >> iter 64000, loss: 0.022212
 >> iter 65000, loss: 0.060779
 >> iter 66000, loss: 0.034993
 >> iter 67000, loss: 0.025780
 >> iter 68000, loss: 0.022626
 >> iter 69000, loss: 0.022852
 >> iter 70000, loss: 0.021502
   Number of active neurons: 2
 >> iter 71000, loss: 0.021007
 >> iter 72000, loss: 0.023959
 >> iter 73000, loss: 0.022989
 >> iter 74000, loss: 0.025182
 >> iter 75000, loss: 0.024111
 >> iter 76000, loss: 0.021635
 >> iter 77000, loss: 0.021626
 >> iter 78000, loss: 0.021307
 >> iter 79000, loss: 0.022113
 >> iter 80000, loss: 0.021744
   Number of active neurons: 2
 >> iter 81000, loss: 0.022398
 >> iter 82000, loss: 0.026561
 >> iter 83000, loss: 0.025120
 >> iter 84000, loss: 0.021699
 >> iter 85000, loss: 0.022524
 >> iter 86000, loss: 0.020529
 >> iter 87000, loss: 0.023184
 >> iter 88000, loss: 0.022960
 >> iter 89000, loss: 0.024767
 >> iter 90000, loss: 0.025112
   Number of active neurons: 2
 >> iter 91000, loss: 0.021379
 >> iter 92000, loss: 0.021443
 >> iter 93000, loss: 0.019796
 >> iter 94000, loss: 0.019610
 >> iter 95000, loss: 0.021840
 >> iter 96000, loss: 0.020618
 >> iter 97000, loss: 0.019652
 >> iter 98000, loss: 0.039412
 >> iter 99000, loss: 0.028807
 >> iter 100000, loss: 0.024481
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.951828
 >> iter 2000, loss: 4.077539
 >> iter 3000, loss: 1.552735
 >> iter 4000, loss: 0.597134
 >> iter 5000, loss: 0.245418
 >> iter 6000, loss: 0.112233
 >> iter 7000, loss: 0.060995
 >> iter 8000, loss: 0.043678
 >> iter 9000, loss: 0.033617
 >> iter 10000, loss: 0.030811
   Number of active neurons: 4
 >> iter 11000, loss: 0.027863
 >> iter 12000, loss: 0.025903
 >> iter 13000, loss: 0.037461
 >> iter 14000, loss: 0.028820
 >> iter 15000, loss: 0.026438
 >> iter 16000, loss: 0.025467
 >> iter 17000, loss: 0.026254
 >> iter 18000, loss: 0.026633
 >> iter 19000, loss: 0.030040
 >> iter 20000, loss: 0.030805
   Number of active neurons: 3
 >> iter 21000, loss: 0.028037
 >> iter 22000, loss: 0.025027
 >> iter 23000, loss: 0.023953
 >> iter 24000, loss: 0.024735
 >> iter 25000, loss: 0.031186
 >> iter 26000, loss: 0.029938
 >> iter 27000, loss: 0.025268
 >> iter 28000, loss: 0.023682
 >> iter 29000, loss: 0.023041
 >> iter 30000, loss: 0.024817
   Number of active neurons: 3
 >> iter 31000, loss: 0.043874
 >> iter 32000, loss: 0.035619
 >> iter 33000, loss: 0.029339
 >> iter 34000, loss: 0.027777
 >> iter 35000, loss: 0.036132
 >> iter 36000, loss: 0.028164
 >> iter 37000, loss: 0.027178
 >> iter 38000, loss: 0.024238
 >> iter 39000, loss: 0.027748
 >> iter 40000, loss: 0.028997
   Number of active neurons: 3
 >> iter 41000, loss: 0.026912
 >> iter 42000, loss: 0.028151
 >> iter 43000, loss: 0.024622
 >> iter 44000, loss: 0.029387
 >> iter 45000, loss: 0.025784
 >> iter 46000, loss: 0.024269
 >> iter 47000, loss: 0.021985
 >> iter 48000, loss: 0.026874
 >> iter 49000, loss: 0.030088
 >> iter 50000, loss: 0.024894
   Number of active neurons: 2
 >> iter 51000, loss: 0.024013
 >> iter 52000, loss: 0.032826
 >> iter 53000, loss: 0.022824
 >> iter 54000, loss: 0.023076
 >> iter 55000, loss: 0.020352
 >> iter 56000, loss: 0.024105
 >> iter 57000, loss: 0.028597
 >> iter 58000, loss: 0.027011
 >> iter 59000, loss: 0.024601
 >> iter 60000, loss: 0.021271
   Number of active neurons: 2
 >> iter 61000, loss: 0.028776
 >> iter 62000, loss: 0.031818
 >> iter 63000, loss: 0.023163
 >> iter 64000, loss: 0.020392
 >> iter 65000, loss: 0.019452
 >> iter 66000, loss: 0.019471
 >> iter 67000, loss: 0.022235
 >> iter 68000, loss: 0.033741
 >> iter 69000, loss: 0.024046
 >> iter 70000, loss: 0.026081
   Number of active neurons: 2
 >> iter 71000, loss: 0.022229
 >> iter 72000, loss: 0.020855
 >> iter 73000, loss: 0.032603
 >> iter 74000, loss: 0.024469
 >> iter 75000, loss: 0.029385
 >> iter 76000, loss: 0.031481
 >> iter 77000, loss: 0.025068
 >> iter 78000, loss: 0.022858
 >> iter 79000, loss: 0.021190
 >> iter 80000, loss: 0.028255
   Number of active neurons: 2
 >> iter 81000, loss: 0.023805
 >> iter 82000, loss: 0.025015
 >> iter 83000, loss: 0.024138
 >> iter 84000, loss: 0.020530
 >> iter 85000, loss: 0.021788
 >> iter 86000, loss: 0.025090
 >> iter 87000, loss: 0.024689
 >> iter 88000, loss: 0.028353
 >> iter 89000, loss: 0.034216
 >> iter 90000, loss: 0.024619
   Number of active neurons: 2
 >> iter 91000, loss: 0.020373
 >> iter 92000, loss: 0.020196
 >> iter 93000, loss: 0.020311
 >> iter 94000, loss: 0.029759
 >> iter 95000, loss: 0.023184
 >> iter 96000, loss: 0.022576
 >> iter 97000, loss: 0.027620
 >> iter 98000, loss: 0.022184
 >> iter 99000, loss: 0.022276
 >> iter 100000, loss: 0.021099
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.976988
 >> iter 2000, loss: 4.097503
 >> iter 3000, loss: 1.531546
 >> iter 4000, loss: 0.587868
 >> iter 5000, loss: 0.238815
 >> iter 6000, loss: 0.110373
 >> iter 7000, loss: 0.061686
 >> iter 8000, loss: 0.043716
 >> iter 9000, loss: 0.037148
 >> iter 10000, loss: 0.033568
   Number of active neurons: 5
 >> iter 11000, loss: 0.033027
 >> iter 12000, loss: 0.028167
 >> iter 13000, loss: 0.033562
 >> iter 14000, loss: 0.031355
 >> iter 15000, loss: 0.027321
 >> iter 16000, loss: 0.030257
 >> iter 17000, loss: 0.030831
 >> iter 18000, loss: 0.027620
 >> iter 19000, loss: 0.032606
 >> iter 20000, loss: 0.026564
   Number of active neurons: 3
 >> iter 21000, loss: 0.025368
 >> iter 22000, loss: 0.024474
 >> iter 23000, loss: 0.022670
 >> iter 24000, loss: 0.022742
 >> iter 25000, loss: 0.023236
 >> iter 26000, loss: 0.024827
 >> iter 27000, loss: 0.065323
 >> iter 28000, loss: 0.039105
 >> iter 29000, loss: 0.030842
 >> iter 30000, loss: 0.025136
   Number of active neurons: 2
 >> iter 31000, loss: 0.057585
 >> iter 32000, loss: 0.053387
 >> iter 33000, loss: 0.036044
 >> iter 34000, loss: 0.029725
 >> iter 35000, loss: 0.028211
 >> iter 36000, loss: 0.023525
 >> iter 37000, loss: 0.021923
 >> iter 38000, loss: 0.020634
 >> iter 39000, loss: 0.020783
 >> iter 40000, loss: 0.021799
   Number of active neurons: 2
 >> iter 41000, loss: 0.034812
 >> iter 42000, loss: 0.032604
 >> iter 43000, loss: 0.030268
 >> iter 44000, loss: 0.029015
 >> iter 45000, loss: 0.023165
 >> iter 46000, loss: 0.023969
 >> iter 47000, loss: 0.022674
 >> iter 48000, loss: 0.023344
 >> iter 49000, loss: 0.020770
 >> iter 50000, loss: 0.021751
   Number of active neurons: 2
 >> iter 51000, loss: 0.027935
 >> iter 52000, loss: 0.028548
 >> iter 53000, loss: 0.022919
 >> iter 54000, loss: 0.022909
 >> iter 55000, loss: 0.022707
 >> iter 56000, loss: 0.032989
 >> iter 57000, loss: 0.026378
 >> iter 58000, loss: 0.025821
 >> iter 59000, loss: 0.025711
 >> iter 60000, loss: 0.023744
   Number of active neurons: 2
 >> iter 61000, loss: 0.021224
 >> iter 62000, loss: 0.022962
 >> iter 63000, loss: 0.020068
 >> iter 64000, loss: 0.025417
 >> iter 65000, loss: 0.032279
 >> iter 66000, loss: 0.032473
 >> iter 67000, loss: 0.023310
 >> iter 68000, loss: 0.021576
 >> iter 69000, loss: 0.021264
 >> iter 70000, loss: 0.022805
   Number of active neurons: 2
 >> iter 71000, loss: 0.022906
 >> iter 72000, loss: 0.021635
 >> iter 73000, loss: 0.029321
 >> iter 74000, loss: 0.024407
 >> iter 75000, loss: 0.026051
 >> iter 76000, loss: 0.022660
 >> iter 77000, loss: 0.021226
 >> iter 78000, loss: 0.021138
 >> iter 79000, loss: 0.026096
 >> iter 80000, loss: 0.023462
   Number of active neurons: 2
 >> iter 81000, loss: 0.022020
 >> iter 82000, loss: 0.021816
 >> iter 83000, loss: 0.025777
 >> iter 84000, loss: 0.024512
 >> iter 85000, loss: 0.027911
 >> iter 86000, loss: 0.039198
 >> iter 87000, loss: 0.046215
 >> iter 88000, loss: 0.035338
 >> iter 89000, loss: 0.030187
 >> iter 90000, loss: 0.025727
   Number of active neurons: 2
 >> iter 91000, loss: 0.033771
 >> iter 92000, loss: 0.024722
 >> iter 93000, loss: 0.023661
 >> iter 94000, loss: 0.031559
 >> iter 95000, loss: 0.026707
 >> iter 96000, loss: 0.021340
 >> iter 97000, loss: 0.024880
 >> iter 98000, loss: 0.023648
 >> iter 99000, loss: 0.022305
 >> iter 100000, loss: 0.020034
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.929211
 >> iter 2000, loss: 4.069725
 >> iter 3000, loss: 1.530204
 >> iter 4000, loss: 0.590206
 >> iter 5000, loss: 0.248575
 >> iter 6000, loss: 0.110734
 >> iter 7000, loss: 0.061132
 >> iter 8000, loss: 0.046237
 >> iter 9000, loss: 0.037044
 >> iter 10000, loss: 0.061482
   Number of active neurons: 6
 >> iter 11000, loss: 0.049520
 >> iter 12000, loss: 0.046666
 >> iter 13000, loss: 0.039850
 >> iter 14000, loss: 0.044732
 >> iter 15000, loss: 0.038889
 >> iter 16000, loss: 0.038051
 >> iter 17000, loss: 0.046590
 >> iter 18000, loss: 0.035669
 >> iter 19000, loss: 0.031069
 >> iter 20000, loss: 0.027434
   Number of active neurons: 3
 >> iter 21000, loss: 0.035841
 >> iter 22000, loss: 0.028726
 >> iter 23000, loss: 0.026661
 >> iter 24000, loss: 0.033034
 >> iter 25000, loss: 0.035891
 >> iter 26000, loss: 0.027546
 >> iter 27000, loss: 0.032368
 >> iter 28000, loss: 0.037787
 >> iter 29000, loss: 0.027651
 >> iter 30000, loss: 0.025110
   Number of active neurons: 2
 >> iter 31000, loss: 0.022201
 >> iter 32000, loss: 0.021488
 >> iter 33000, loss: 0.020210
 >> iter 34000, loss: 0.022294
 >> iter 35000, loss: 0.027312
 >> iter 36000, loss: 0.027187
 >> iter 37000, loss: 0.024085
 >> iter 38000, loss: 0.023463
 >> iter 39000, loss: 0.021624
 >> iter 40000, loss: 0.040158
   Number of active neurons: 2
 >> iter 41000, loss: 0.027428
 >> iter 42000, loss: 0.022624
 >> iter 43000, loss: 0.030037
 >> iter 44000, loss: 0.022964
 >> iter 45000, loss: 0.039785
 >> iter 46000, loss: 0.027866
 >> iter 47000, loss: 0.024476
 >> iter 48000, loss: 0.027259
 >> iter 49000, loss: 0.024003
 >> iter 50000, loss: 0.020922
   Number of active neurons: 1
 >> iter 51000, loss: 0.019728
 >> iter 52000, loss: 0.019480
 >> iter 53000, loss: 0.018863
 >> iter 54000, loss: 0.017730
 >> iter 55000, loss: 0.018334
 >> iter 56000, loss: 0.018003
 >> iter 57000, loss: 0.020852
 >> iter 58000, loss: 0.018159
 >> iter 59000, loss: 0.018490
 >> iter 60000, loss: 0.023739
   Number of active neurons: 1
 >> iter 61000, loss: 0.026294
 >> iter 62000, loss: 0.020750
 >> iter 63000, loss: 0.018025
 >> iter 64000, loss: 0.015895
 >> iter 65000, loss: 0.017934
 >> iter 66000, loss: 0.022872
 >> iter 67000, loss: 0.023973
 >> iter 68000, loss: 0.024846
 >> iter 69000, loss: 0.018651
 >> iter 70000, loss: 0.019817
   Number of active neurons: 1
 >> iter 71000, loss: 0.018791
 >> iter 72000, loss: 0.016281
 >> iter 73000, loss: 0.015813
 >> iter 74000, loss: 0.021710
 >> iter 75000, loss: 0.019753
 >> iter 76000, loss: 0.016852
 >> iter 77000, loss: 0.023826
 >> iter 78000, loss: 0.018264
 >> iter 79000, loss: 0.019739
 >> iter 80000, loss: 0.018828
   Number of active neurons: 1
 >> iter 81000, loss: 0.021426
 >> iter 82000, loss: 0.023646
 >> iter 83000, loss: 0.019008
 >> iter 84000, loss: 0.020632
 >> iter 85000, loss: 0.026195
 >> iter 86000, loss: 0.020639
 >> iter 87000, loss: 0.019701
 >> iter 88000, loss: 0.018102
 >> iter 89000, loss: 0.021458
 >> iter 90000, loss: 0.019696
   Number of active neurons: 1
 >> iter 91000, loss: 0.035415
 >> iter 92000, loss: 0.022814
 >> iter 93000, loss: 0.019499
 >> iter 94000, loss: 0.020338
 >> iter 95000, loss: 0.019309
 >> iter 96000, loss: 0.022745
 >> iter 97000, loss: 0.020172
 >> iter 98000, loss: 0.023525
 >> iter 99000, loss: 0.026797
 >> iter 100000, loss: 0.031542
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.942460
 >> iter 2000, loss: 4.104164
 >> iter 3000, loss: 1.546215
 >> iter 4000, loss: 0.605397
 >> iter 5000, loss: 0.258131
 >> iter 6000, loss: 0.118303
 >> iter 7000, loss: 0.065201
 >> iter 8000, loss: 0.046866
 >> iter 9000, loss: 0.035120
 >> iter 10000, loss: 0.032199
   Number of active neurons: 4
 >> iter 11000, loss: 0.037859
 >> iter 12000, loss: 0.033519
 >> iter 13000, loss: 0.041672
 >> iter 14000, loss: 0.035524
 >> iter 15000, loss: 0.030476
 >> iter 16000, loss: 0.030131
 >> iter 17000, loss: 0.030791
 >> iter 18000, loss: 0.027664
 >> iter 19000, loss: 0.025259
 >> iter 20000, loss: 0.022137
   Number of active neurons: 3
 >> iter 21000, loss: 0.023392
 >> iter 22000, loss: 0.023987
 >> iter 23000, loss: 0.035102
 >> iter 24000, loss: 0.028333
 >> iter 25000, loss: 0.027339
 >> iter 26000, loss: 0.027546
 >> iter 27000, loss: 0.034111
 >> iter 28000, loss: 0.028472
 >> iter 29000, loss: 0.024993
 >> iter 30000, loss: 0.024435
   Number of active neurons: 2
 >> iter 31000, loss: 0.023750
 >> iter 32000, loss: 0.028181
 >> iter 33000, loss: 0.027090
 >> iter 34000, loss: 0.021755
 >> iter 35000, loss: 0.023550
 >> iter 36000, loss: 0.045623
 >> iter 37000, loss: 0.046294
 >> iter 38000, loss: 0.030910
 >> iter 39000, loss: 0.029142
 >> iter 40000, loss: 0.023283
   Number of active neurons: 2
 >> iter 41000, loss: 0.023717
 >> iter 42000, loss: 0.025455
 >> iter 43000, loss: 0.030680
 >> iter 44000, loss: 0.025671
 >> iter 45000, loss: 0.029108
 >> iter 46000, loss: 0.023484
 >> iter 47000, loss: 0.025719
 >> iter 48000, loss: 0.022709
 >> iter 49000, loss: 0.021808
 >> iter 50000, loss: 0.021350
   Number of active neurons: 1
 >> iter 51000, loss: 0.020444
 >> iter 52000, loss: 0.020994
 >> iter 53000, loss: 0.049320
 >> iter 54000, loss: 0.031623
 >> iter 55000, loss: 0.024952
 >> iter 56000, loss: 0.025429
 >> iter 57000, loss: 0.023738
 >> iter 58000, loss: 0.028105
 >> iter 59000, loss: 0.020846
 >> iter 60000, loss: 0.017542
   Number of active neurons: 1
 >> iter 61000, loss: 0.016257
 >> iter 62000, loss: 0.016648
 >> iter 63000, loss: 0.029525
 >> iter 64000, loss: 0.021244
 >> iter 65000, loss: 0.023057
 >> iter 66000, loss: 0.022190
 >> iter 67000, loss: 0.022032
 >> iter 68000, loss: 0.023811
 >> iter 69000, loss: 0.027699
 >> iter 70000, loss: 0.022772
   Number of active neurons: 1
 >> iter 71000, loss: 0.020254
 >> iter 72000, loss: 0.019798
 >> iter 73000, loss: 0.028421
 >> iter 74000, loss: 0.021684
 >> iter 75000, loss: 0.033536
 >> iter 76000, loss: 0.023059
 >> iter 77000, loss: 0.018142
 >> iter 78000, loss: 0.017724
 >> iter 79000, loss: 0.016510
 >> iter 80000, loss: 0.017392
   Number of active neurons: 1
 >> iter 81000, loss: 0.022152
 >> iter 82000, loss: 0.030198
 >> iter 83000, loss: 0.021677
 >> iter 84000, loss: 0.032033
 >> iter 85000, loss: 0.023906
 >> iter 86000, loss: 0.018661
 >> iter 87000, loss: 0.037042
 >> iter 88000, loss: 0.030875
 >> iter 89000, loss: 0.022500
 >> iter 90000, loss: 0.017864
   Number of active neurons: 1
 >> iter 91000, loss: 0.022707
 >> iter 92000, loss: 0.019875
 >> iter 93000, loss: 0.019933
 >> iter 94000, loss: 0.023518
 >> iter 95000, loss: 0.020576
 >> iter 96000, loss: 0.019317
 >> iter 97000, loss: 0.016665
 >> iter 98000, loss: 0.022880
 >> iter 99000, loss: 0.017433
 >> iter 100000, loss: 0.019252
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.873534
 >> iter 2000, loss: 4.052879
 >> iter 3000, loss: 1.518107
 >> iter 4000, loss: 0.583128
 >> iter 5000, loss: 0.236476
 >> iter 6000, loss: 0.106599
 >> iter 7000, loss: 0.058336
 >> iter 8000, loss: 0.041615
 >> iter 9000, loss: 0.032894
 >> iter 10000, loss: 0.029621
   Number of active neurons: 4
 >> iter 11000, loss: 0.030166
 >> iter 12000, loss: 0.028617
 >> iter 13000, loss: 0.025578
 >> iter 14000, loss: 0.028650
 >> iter 15000, loss: 0.027812
 >> iter 16000, loss: 0.027068
 >> iter 17000, loss: 0.024989
 >> iter 18000, loss: 0.026430
 >> iter 19000, loss: 0.023575
 >> iter 20000, loss: 0.023559
   Number of active neurons: 3
 >> iter 21000, loss: 0.031927
 >> iter 22000, loss: 0.026642
 >> iter 23000, loss: 0.030279
 >> iter 24000, loss: 0.025426
 >> iter 25000, loss: 0.032824
 >> iter 26000, loss: 0.027514
 >> iter 27000, loss: 0.030663
 >> iter 28000, loss: 0.027939
 >> iter 29000, loss: 0.027876
 >> iter 30000, loss: 0.025076
   Number of active neurons: 3
 >> iter 31000, loss: 0.024350
 >> iter 32000, loss: 0.056997
 >> iter 33000, loss: 0.041698
 >> iter 34000, loss: 0.029303
 >> iter 35000, loss: 0.035903
 >> iter 36000, loss: 0.030250
 >> iter 37000, loss: 0.024495
 >> iter 38000, loss: 0.022617
 >> iter 39000, loss: 0.031074
 >> iter 40000, loss: 0.026294
   Number of active neurons: 3
 >> iter 41000, loss: 0.025919
 >> iter 42000, loss: 0.031684
 >> iter 43000, loss: 0.026617
 >> iter 44000, loss: 0.032223
 >> iter 45000, loss: 0.026555
 >> iter 46000, loss: 0.029724
 >> iter 47000, loss: 0.028745
 >> iter 48000, loss: 0.024972
 >> iter 49000, loss: 0.035743
 >> iter 50000, loss: 0.026632
   Number of active neurons: 2
 >> iter 51000, loss: 0.025381
 >> iter 52000, loss: 0.025659
 >> iter 53000, loss: 0.022546
 >> iter 54000, loss: 0.021755
 >> iter 55000, loss: 0.025648
 >> iter 56000, loss: 0.021979
 >> iter 57000, loss: 0.026056
 >> iter 58000, loss: 0.027765
 >> iter 59000, loss: 0.036064
 >> iter 60000, loss: 0.025140
   Number of active neurons: 2
 >> iter 61000, loss: 0.025331
 >> iter 62000, loss: 0.022760
 >> iter 63000, loss: 0.023547
 >> iter 64000, loss: 0.023684
 >> iter 65000, loss: 0.022675
 >> iter 66000, loss: 0.023248
 >> iter 67000, loss: 0.027620
 >> iter 68000, loss: 0.024720
 >> iter 69000, loss: 0.021226
 >> iter 70000, loss: 0.020613
   Number of active neurons: 2
 >> iter 71000, loss: 0.026647
 >> iter 72000, loss: 0.023891
 >> iter 73000, loss: 0.046991
 >> iter 74000, loss: 0.035218
 >> iter 75000, loss: 0.028001
 >> iter 76000, loss: 0.024089
 >> iter 77000, loss: 0.031497
 >> iter 78000, loss: 0.023703
 >> iter 79000, loss: 0.020293
 >> iter 80000, loss: 0.023415
   Number of active neurons: 2
 >> iter 81000, loss: 0.021537
 >> iter 82000, loss: 0.021869
 >> iter 83000, loss: 0.021118
 >> iter 84000, loss: 0.028572
 >> iter 85000, loss: 0.040076
 >> iter 86000, loss: 0.030317
 >> iter 87000, loss: 0.026530
 >> iter 88000, loss: 0.025547
 >> iter 89000, loss: 0.025231
 >> iter 90000, loss: 0.022786
   Number of active neurons: 2
 >> iter 91000, loss: 0.021607
 >> iter 92000, loss: 0.023811
 >> iter 93000, loss: 0.020612
 >> iter 94000, loss: 0.020377
 >> iter 95000, loss: 0.032404
 >> iter 96000, loss: 0.041778
 >> iter 97000, loss: 0.028768
 >> iter 98000, loss: 0.025828
 >> iter 99000, loss: 0.024192
 >> iter 100000, loss: 0.023761
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.004169
 >> iter 2000, loss: 4.089892
 >> iter 3000, loss: 1.534488
 >> iter 4000, loss: 0.595665
 >> iter 5000, loss: 0.244720
 >> iter 6000, loss: 0.108063
 >> iter 7000, loss: 0.063263
 >> iter 8000, loss: 0.043428
 >> iter 9000, loss: 0.039001
 >> iter 10000, loss: 0.035728
   Number of active neurons: 5
 >> iter 11000, loss: 0.032609
 >> iter 12000, loss: 0.030731
 >> iter 13000, loss: 0.028085
 >> iter 14000, loss: 0.027439
 >> iter 15000, loss: 0.028619
 >> iter 16000, loss: 0.026579
 >> iter 17000, loss: 0.029901
 >> iter 18000, loss: 0.026532
 >> iter 19000, loss: 0.030100
 >> iter 20000, loss: 0.042539
   Number of active neurons: 3
 >> iter 21000, loss: 0.048683
 >> iter 22000, loss: 0.034528
 >> iter 23000, loss: 0.038678
 >> iter 24000, loss: 0.028277
 >> iter 25000, loss: 0.029220
 >> iter 26000, loss: 0.026190
 >> iter 27000, loss: 0.025013
 >> iter 28000, loss: 0.026728
 >> iter 29000, loss: 0.022789
 >> iter 30000, loss: 0.024438
   Number of active neurons: 2
 >> iter 31000, loss: 0.027556
 >> iter 32000, loss: 0.023100
 >> iter 33000, loss: 0.022417
 >> iter 34000, loss: 0.020808
 >> iter 35000, loss: 0.023911
 >> iter 36000, loss: 0.024478
 >> iter 37000, loss: 0.024292
 >> iter 38000, loss: 0.030008
 >> iter 39000, loss: 0.030913
 >> iter 40000, loss: 0.031667
   Number of active neurons: 2
 >> iter 41000, loss: 0.025553
 >> iter 42000, loss: 0.023189
 >> iter 43000, loss: 0.022471
 >> iter 44000, loss: 0.021657
 >> iter 45000, loss: 0.023202
 >> iter 46000, loss: 0.021016
 >> iter 47000, loss: 0.020046
 >> iter 48000, loss: 0.024298
 >> iter 49000, loss: 0.023391
 >> iter 50000, loss: 0.021123
   Number of active neurons: 2
 >> iter 51000, loss: 0.022972
 >> iter 52000, loss: 0.044222
 >> iter 53000, loss: 0.030061
 >> iter 54000, loss: 0.023156
 >> iter 55000, loss: 0.022645
 >> iter 56000, loss: 0.020890
 >> iter 57000, loss: 0.029314
 >> iter 58000, loss: 0.024254
 >> iter 59000, loss: 0.028629
 >> iter 60000, loss: 0.022551
   Number of active neurons: 2
 >> iter 61000, loss: 0.023981
 >> iter 62000, loss: 0.022277
 >> iter 63000, loss: 0.020757
 >> iter 64000, loss: 0.020354
 >> iter 65000, loss: 0.027357
 >> iter 66000, loss: 0.044828
 >> iter 67000, loss: 0.039890
 >> iter 68000, loss: 0.028106
 >> iter 69000, loss: 0.025629
 >> iter 70000, loss: 0.036608
   Number of active neurons: 2
 >> iter 71000, loss: 0.028611
 >> iter 72000, loss: 0.026894
 >> iter 73000, loss: 0.024296
 >> iter 74000, loss: 0.020443
 >> iter 75000, loss: 0.021734
 >> iter 76000, loss: 0.022567
 >> iter 77000, loss: 0.026080
 >> iter 78000, loss: 0.038589
 >> iter 79000, loss: 0.036538
 >> iter 80000, loss: 0.044300
   Number of active neurons: 2
 >> iter 81000, loss: 0.032746
 >> iter 82000, loss: 0.024475
 >> iter 83000, loss: 0.021120
 >> iter 84000, loss: 0.020445
 >> iter 85000, loss: 0.020757
 >> iter 86000, loss: 0.021469
 >> iter 87000, loss: 0.021197
 >> iter 88000, loss: 0.021776
 >> iter 89000, loss: 0.021087
 >> iter 90000, loss: 0.024725
   Number of active neurons: 2
 >> iter 91000, loss: 0.022842
 >> iter 92000, loss: 0.023727
 >> iter 93000, loss: 0.020832
 >> iter 94000, loss: 0.034646
 >> iter 95000, loss: 0.041167
 >> iter 96000, loss: 0.029518
 >> iter 97000, loss: 0.022946
 >> iter 98000, loss: 0.027047
 >> iter 99000, loss: 0.023732
 >> iter 100000, loss: 0.024967
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.992041
 >> iter 2000, loss: 4.094398
 >> iter 3000, loss: 1.542623
 >> iter 4000, loss: 0.590592
 >> iter 5000, loss: 0.234676
 >> iter 6000, loss: 0.110978
 >> iter 7000, loss: 0.063607
 >> iter 8000, loss: 0.045233
 >> iter 9000, loss: 0.038018
 >> iter 10000, loss: 0.031969
   Number of active neurons: 4
 >> iter 11000, loss: 0.029079
 >> iter 12000, loss: 0.031261
 >> iter 13000, loss: 0.033104
 >> iter 14000, loss: 0.031039
 >> iter 15000, loss: 0.030697
 >> iter 16000, loss: 0.026513
 >> iter 17000, loss: 0.029822
 >> iter 18000, loss: 0.027132
 >> iter 19000, loss: 0.026512
 >> iter 20000, loss: 0.025492
   Number of active neurons: 4
 >> iter 21000, loss: 0.025298
 >> iter 22000, loss: 0.025605
 >> iter 23000, loss: 0.026914
 >> iter 24000, loss: 0.036378
 >> iter 25000, loss: 0.036003
 >> iter 26000, loss: 0.044635
 >> iter 27000, loss: 0.033137
 >> iter 28000, loss: 0.027515
 >> iter 29000, loss: 0.034752
 >> iter 30000, loss: 0.032005
   Number of active neurons: 3
 >> iter 31000, loss: 0.036736
 >> iter 32000, loss: 0.029023
 >> iter 33000, loss: 0.029693
 >> iter 34000, loss: 0.027448
 >> iter 35000, loss: 0.047632
 >> iter 36000, loss: 0.040295
 >> iter 37000, loss: 0.030457
 >> iter 38000, loss: 0.029622
 >> iter 39000, loss: 0.039485
 >> iter 40000, loss: 0.031544
   Number of active neurons: 3
 >> iter 41000, loss: 0.027663
 >> iter 42000, loss: 0.028145
 >> iter 43000, loss: 0.024976
 >> iter 44000, loss: 0.022807
 >> iter 45000, loss: 0.023149
 >> iter 46000, loss: 0.022633
 >> iter 47000, loss: 0.034229
 >> iter 48000, loss: 0.034766
 >> iter 49000, loss: 0.027516
 >> iter 50000, loss: 0.024710
   Number of active neurons: 2
 >> iter 51000, loss: 0.036528
 >> iter 52000, loss: 0.026831
 >> iter 53000, loss: 0.030327
 >> iter 54000, loss: 0.033709
 >> iter 55000, loss: 0.025552
 >> iter 56000, loss: 0.026459
 >> iter 57000, loss: 0.026718
 >> iter 58000, loss: 0.022941
 >> iter 59000, loss: 0.024451
 >> iter 60000, loss: 0.020799
   Number of active neurons: 1
 >> iter 61000, loss: 0.020608
 >> iter 62000, loss: 0.027784
 >> iter 63000, loss: 0.021328
 >> iter 64000, loss: 0.018565
 >> iter 65000, loss: 0.018779
 >> iter 66000, loss: 0.041348
 >> iter 67000, loss: 0.037344
 >> iter 68000, loss: 0.026360
 >> iter 69000, loss: 0.027184
 >> iter 70000, loss: 0.021521
   Number of active neurons: 1
 >> iter 71000, loss: 0.017637
 >> iter 72000, loss: 0.017240
 >> iter 73000, loss: 0.050868
 >> iter 74000, loss: 0.028919
 >> iter 75000, loss: 0.035314
 >> iter 76000, loss: 0.023061
 >> iter 77000, loss: 0.020233
 >> iter 78000, loss: 0.019069
 >> iter 79000, loss: 0.020527
 >> iter 80000, loss: 0.022174
   Number of active neurons: 1
 >> iter 81000, loss: 0.023534
 >> iter 82000, loss: 0.029925
 >> iter 83000, loss: 0.022510
 >> iter 84000, loss: 0.020334
 >> iter 85000, loss: 0.036436
 >> iter 86000, loss: 0.024013
 >> iter 87000, loss: 0.022229
 >> iter 88000, loss: 0.018360
 >> iter 89000, loss: 0.018945
 >> iter 90000, loss: 0.018823
   Number of active neurons: 1
 >> iter 91000, loss: 0.018789
 >> iter 92000, loss: 0.020775
 >> iter 93000, loss: 0.020805
 >> iter 94000, loss: 0.021305
 >> iter 95000, loss: 0.017124
 >> iter 96000, loss: 0.016747
 >> iter 97000, loss: 0.022100
 >> iter 98000, loss: 0.019386
 >> iter 99000, loss: 0.020109
 >> iter 100000, loss: 0.022090
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.972941
 >> iter 2000, loss: 4.073361
 >> iter 3000, loss: 1.525634
 >> iter 4000, loss: 0.591134
 >> iter 5000, loss: 0.242834
 >> iter 6000, loss: 0.109122
 >> iter 7000, loss: 0.058012
 >> iter 8000, loss: 0.042334
 >> iter 9000, loss: 0.051170
 >> iter 10000, loss: 0.044369
   Number of active neurons: 4
 >> iter 11000, loss: 0.036450
 >> iter 12000, loss: 0.028187
 >> iter 13000, loss: 0.026778
 >> iter 14000, loss: 0.026289
 >> iter 15000, loss: 0.029170
 >> iter 16000, loss: 0.025715
 >> iter 17000, loss: 0.027755
 >> iter 18000, loss: 0.029649
 >> iter 19000, loss: 0.028608
 >> iter 20000, loss: 0.040931
   Number of active neurons: 2
 >> iter 21000, loss: 0.029249
 >> iter 22000, loss: 0.026917
 >> iter 23000, loss: 0.026980
 >> iter 24000, loss: 0.023330
 >> iter 25000, loss: 0.021018
 >> iter 26000, loss: 0.027010
 >> iter 27000, loss: 0.023044
 >> iter 28000, loss: 0.022598
 >> iter 29000, loss: 0.022260
 >> iter 30000, loss: 0.023774
   Number of active neurons: 2
 >> iter 31000, loss: 0.025121
 >> iter 32000, loss: 0.024904
 >> iter 33000, loss: 0.021553
 >> iter 34000, loss: 0.032626
 >> iter 35000, loss: 0.025514
 >> iter 36000, loss: 0.023940
 >> iter 37000, loss: 0.027003
 >> iter 38000, loss: 0.021185
 >> iter 39000, loss: 0.020624
 >> iter 40000, loss: 0.020148
   Number of active neurons: 2
 >> iter 41000, loss: 0.022948
 >> iter 42000, loss: 0.021393
 >> iter 43000, loss: 0.037579
 >> iter 44000, loss: 0.045893
 >> iter 45000, loss: 0.030423
 >> iter 46000, loss: 0.026127
 >> iter 47000, loss: 0.025305
 >> iter 48000, loss: 0.028181
 >> iter 49000, loss: 0.023084
 >> iter 50000, loss: 0.022199
   Number of active neurons: 2
 >> iter 51000, loss: 0.043047
 >> iter 52000, loss: 0.031019
 >> iter 53000, loss: 0.039678
 >> iter 54000, loss: 0.051519
 >> iter 55000, loss: 0.033299
 >> iter 56000, loss: 0.028821
 >> iter 57000, loss: 0.027585
 >> iter 58000, loss: 0.024003
 >> iter 59000, loss: 0.022188
 >> iter 60000, loss: 0.023662
   Number of active neurons: 2
 >> iter 61000, loss: 0.027718
 >> iter 62000, loss: 0.024736
 >> iter 63000, loss: 0.022689
 >> iter 64000, loss: 0.023483
 >> iter 65000, loss: 0.021514
 >> iter 66000, loss: 0.023008
 >> iter 67000, loss: 0.020874
 >> iter 68000, loss: 0.021935
 >> iter 69000, loss: 0.021812
 >> iter 70000, loss: 0.020566
   Number of active neurons: 2
 >> iter 71000, loss: 0.021422
 >> iter 72000, loss: 0.021909
 >> iter 73000, loss: 0.021599
 >> iter 74000, loss: 0.020854
 >> iter 75000, loss: 0.022764
 >> iter 76000, loss: 0.024324
 >> iter 77000, loss: 0.020907
 >> iter 78000, loss: 0.022627
 >> iter 79000, loss: 0.026608
 >> iter 80000, loss: 0.030024
   Number of active neurons: 1
 >> iter 81000, loss: 0.024822
 >> iter 82000, loss: 0.026493
 >> iter 83000, loss: 0.022683
 >> iter 84000, loss: 0.020531
 >> iter 85000, loss: 0.031689
 >> iter 86000, loss: 0.023393
 >> iter 87000, loss: 0.025645
 >> iter 88000, loss: 0.020002
 >> iter 89000, loss: 0.020851
 >> iter 90000, loss: 0.030908
   Number of active neurons: 1
 >> iter 91000, loss: 0.024644
 >> iter 92000, loss: 0.019491
 >> iter 93000, loss: 0.017181
 >> iter 94000, loss: 0.033841
 >> iter 95000, loss: 0.028328
 >> iter 96000, loss: 0.022758
 >> iter 97000, loss: 0.019433
 >> iter 98000, loss: 0.019779
 >> iter 99000, loss: 0.018522
 >> iter 100000, loss: 0.032926
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.905160
 >> iter 2000, loss: 4.057795
 >> iter 3000, loss: 1.524311
 >> iter 4000, loss: 0.582347
 >> iter 5000, loss: 0.235266
 >> iter 6000, loss: 0.109118
 >> iter 7000, loss: 0.061147
 >> iter 8000, loss: 0.041572
 >> iter 9000, loss: 0.034938
 >> iter 10000, loss: 0.046099
   Number of active neurons: 4
 >> iter 11000, loss: 0.042517
 >> iter 12000, loss: 0.031736
 >> iter 13000, loss: 0.031439
 >> iter 14000, loss: 0.028825
 >> iter 15000, loss: 0.026871
 >> iter 16000, loss: 0.032931
 >> iter 17000, loss: 0.028713
 >> iter 18000, loss: 0.034600
 >> iter 19000, loss: 0.034420
 >> iter 20000, loss: 0.028183
   Number of active neurons: 4
 >> iter 21000, loss: 0.028393
 >> iter 22000, loss: 0.024900
 >> iter 23000, loss: 0.026979
 >> iter 24000, loss: 0.026321
 >> iter 25000, loss: 0.029226
 >> iter 26000, loss: 0.031473
 >> iter 27000, loss: 0.028377
 >> iter 28000, loss: 0.024846
 >> iter 29000, loss: 0.023788
 >> iter 30000, loss: 0.025874
   Number of active neurons: 2
 >> iter 31000, loss: 0.023491
 >> iter 32000, loss: 0.030079
 >> iter 33000, loss: 0.027107
 >> iter 34000, loss: 0.023718
 >> iter 35000, loss: 0.021377
 >> iter 36000, loss: 0.020561
 >> iter 37000, loss: 0.021958
 >> iter 38000, loss: 0.027264
 >> iter 39000, loss: 0.024100
 >> iter 40000, loss: 0.020838
   Number of active neurons: 1
 >> iter 41000, loss: 0.019279
 >> iter 42000, loss: 0.025301
 >> iter 43000, loss: 0.024403
 >> iter 44000, loss: 0.018532
 >> iter 45000, loss: 0.024238
 >> iter 46000, loss: 0.029835
 >> iter 47000, loss: 0.022931
 >> iter 48000, loss: 0.022538
 >> iter 49000, loss: 0.019101
 >> iter 50000, loss: 0.021661
   Number of active neurons: 1
 >> iter 51000, loss: 0.017878
 >> iter 52000, loss: 0.018854
 >> iter 53000, loss: 0.021535
 >> iter 54000, loss: 0.018305
 >> iter 55000, loss: 0.017904
 >> iter 56000, loss: 0.021226
 >> iter 57000, loss: 0.018649
 >> iter 58000, loss: 0.030153
 >> iter 59000, loss: 0.023022
 >> iter 60000, loss: 0.038092
   Number of active neurons: 1
 >> iter 61000, loss: 0.024933
 >> iter 62000, loss: 0.024145
 >> iter 63000, loss: 0.033944
 >> iter 64000, loss: 0.033574
 >> iter 65000, loss: 0.034375
 >> iter 66000, loss: 0.031227
 >> iter 67000, loss: 0.022297
 >> iter 68000, loss: 0.020137
 >> iter 69000, loss: 0.026267
 >> iter 70000, loss: 0.021967
   Number of active neurons: 1
 >> iter 71000, loss: 0.020106
 >> iter 72000, loss: 0.017696
 >> iter 73000, loss: 0.018587
 >> iter 74000, loss: 0.023043
 >> iter 75000, loss: 0.020227
 >> iter 76000, loss: 0.030947
 >> iter 77000, loss: 0.021125
 >> iter 78000, loss: 0.018911
 >> iter 79000, loss: 0.028835
 >> iter 80000, loss: 0.021244
   Number of active neurons: 1
 >> iter 81000, loss: 0.023287
 >> iter 82000, loss: 0.018737
 >> iter 83000, loss: 0.017540
 >> iter 84000, loss: 0.017089
 >> iter 85000, loss: 0.016874
 >> iter 86000, loss: 0.018960
 >> iter 87000, loss: 0.018173
 >> iter 88000, loss: 0.020098
 >> iter 89000, loss: 0.018721
 >> iter 90000, loss: 0.017978
   Number of active neurons: 1
 >> iter 91000, loss: 0.017079
 >> iter 92000, loss: 0.020537
 >> iter 93000, loss: 0.018800
 >> iter 94000, loss: 0.031070
 >> iter 95000, loss: 0.026530
 >> iter 96000, loss: 0.020083
 >> iter 97000, loss: 0.016519
 >> iter 98000, loss: 0.023357
 >> iter 99000, loss: 0.020970
 >> iter 100000, loss: 0.020932
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.972292
 >> iter 2000, loss: 4.105729
 >> iter 3000, loss: 1.541498
 >> iter 4000, loss: 0.597679
 >> iter 5000, loss: 0.243490
 >> iter 6000, loss: 0.112934
 >> iter 7000, loss: 0.063559
 >> iter 8000, loss: 0.046452
 >> iter 9000, loss: 0.039806
 >> iter 10000, loss: 0.032812
   Number of active neurons: 6
 >> iter 11000, loss: 0.030027
 >> iter 12000, loss: 0.031665
 >> iter 13000, loss: 0.030632
 >> iter 14000, loss: 0.027644
 >> iter 15000, loss: 0.033367
 >> iter 16000, loss: 0.040608
 >> iter 17000, loss: 0.034423
 >> iter 18000, loss: 0.033928
 >> iter 19000, loss: 0.028044
 >> iter 20000, loss: 0.025848
   Number of active neurons: 4
 >> iter 21000, loss: 0.028966
 >> iter 22000, loss: 0.041617
 >> iter 23000, loss: 0.039533
 >> iter 24000, loss: 0.030280
 >> iter 25000, loss: 0.026416
 >> iter 26000, loss: 0.024507
 >> iter 27000, loss: 0.025542
 >> iter 28000, loss: 0.029543
 >> iter 29000, loss: 0.027565
 >> iter 30000, loss: 0.025565
   Number of active neurons: 2
 >> iter 31000, loss: 0.024304
 >> iter 32000, loss: 0.022132
 >> iter 33000, loss: 0.026909
 >> iter 34000, loss: 0.023858
 >> iter 35000, loss: 0.024855
 >> iter 36000, loss: 0.021514
 >> iter 37000, loss: 0.021790
 >> iter 38000, loss: 0.027707
 >> iter 39000, loss: 0.022145
 >> iter 40000, loss: 0.019836
   Number of active neurons: 2
 >> iter 41000, loss: 0.028350
 >> iter 42000, loss: 0.032140
 >> iter 43000, loss: 0.027836
 >> iter 44000, loss: 0.032341
 >> iter 45000, loss: 0.029798
 >> iter 46000, loss: 0.022519
 >> iter 47000, loss: 0.026355
 >> iter 48000, loss: 0.037906
 >> iter 49000, loss: 0.027153
 >> iter 50000, loss: 0.023063
   Number of active neurons: 2
 >> iter 51000, loss: 0.039431
 >> iter 52000, loss: 0.028785
 >> iter 53000, loss: 0.023869
 >> iter 54000, loss: 0.034045
 >> iter 55000, loss: 0.026165
 >> iter 56000, loss: 0.023309
 >> iter 57000, loss: 0.024311
 >> iter 58000, loss: 0.022978
 >> iter 59000, loss: 0.021732
 >> iter 60000, loss: 0.020697
   Number of active neurons: 2
 >> iter 61000, loss: 0.032371
 >> iter 62000, loss: 0.043183
 >> iter 63000, loss: 0.031575
 >> iter 64000, loss: 0.023869
 >> iter 65000, loss: 0.022339
 >> iter 66000, loss: 0.030474
 >> iter 67000, loss: 0.032275
 >> iter 68000, loss: 0.024153
 >> iter 69000, loss: 0.022311
 >> iter 70000, loss: 0.021286
   Number of active neurons: 2
 >> iter 71000, loss: 0.030658
 >> iter 72000, loss: 0.038696
 >> iter 73000, loss: 0.027813
 >> iter 74000, loss: 0.023642
 >> iter 75000, loss: 0.022680
 >> iter 76000, loss: 0.022507
 >> iter 77000, loss: 0.022325
 >> iter 78000, loss: 0.022028
 >> iter 79000, loss: 0.023530
 >> iter 80000, loss: 0.022909
   Number of active neurons: 2
 >> iter 81000, loss: 0.022949
 >> iter 82000, loss: 0.026636
 >> iter 83000, loss: 0.023295
 >> iter 84000, loss: 0.021982
 >> iter 85000, loss: 0.021828
 >> iter 86000, loss: 0.026080
 >> iter 87000, loss: 0.029515
 >> iter 88000, loss: 0.022472
 >> iter 89000, loss: 0.023310
 >> iter 90000, loss: 0.019937
   Number of active neurons: 1
 >> iter 91000, loss: 0.019996
 >> iter 92000, loss: 0.017962
 >> iter 93000, loss: 0.016257
 >> iter 94000, loss: 0.019866
 >> iter 95000, loss: 0.018107
 >> iter 96000, loss: 0.020755
 >> iter 97000, loss: 0.018925
 >> iter 98000, loss: 0.018064
 >> iter 99000, loss: 0.017852
 >> iter 100000, loss: 0.023264
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.988954
 >> iter 2000, loss: 4.084044
 >> iter 3000, loss: 1.524982
 >> iter 4000, loss: 0.608472
 >> iter 5000, loss: 0.244971
 >> iter 6000, loss: 0.113648
 >> iter 7000, loss: 0.069107
 >> iter 8000, loss: 0.047159
 >> iter 9000, loss: 0.036777
 >> iter 10000, loss: 0.030217
   Number of active neurons: 5
 >> iter 11000, loss: 0.030284
 >> iter 12000, loss: 0.027968
 >> iter 13000, loss: 0.032268
 >> iter 14000, loss: 0.028720
 >> iter 15000, loss: 0.029252
 >> iter 16000, loss: 0.029964
 >> iter 17000, loss: 0.025998
 >> iter 18000, loss: 0.024837
 >> iter 19000, loss: 0.025580
 >> iter 20000, loss: 0.021669
   Number of active neurons: 2
 >> iter 21000, loss: 0.068677
 >> iter 22000, loss: 0.038822
 >> iter 23000, loss: 0.042815
 >> iter 24000, loss: 0.031698
 >> iter 25000, loss: 0.026724
 >> iter 26000, loss: 0.031129
 >> iter 27000, loss: 0.026055
 >> iter 28000, loss: 0.024675
 >> iter 29000, loss: 0.025192
 >> iter 30000, loss: 0.027119
   Number of active neurons: 2
 >> iter 31000, loss: 0.024910
 >> iter 32000, loss: 0.022149
 >> iter 33000, loss: 0.021428
 >> iter 34000, loss: 0.021713
 >> iter 35000, loss: 0.025533
 >> iter 36000, loss: 0.022717
 >> iter 37000, loss: 0.024207
 >> iter 38000, loss: 0.021580
 >> iter 39000, loss: 0.030963
 >> iter 40000, loss: 0.026557
   Number of active neurons: 2
 >> iter 41000, loss: 0.025217
 >> iter 42000, loss: 0.026442
 >> iter 43000, loss: 0.026595
 >> iter 44000, loss: 0.026665
 >> iter 45000, loss: 0.023558
 >> iter 46000, loss: 0.035016
 >> iter 47000, loss: 0.026254
 >> iter 48000, loss: 0.051957
 >> iter 49000, loss: 0.042823
 >> iter 50000, loss: 0.031801
   Number of active neurons: 2
 >> iter 51000, loss: 0.027917
 >> iter 52000, loss: 0.028492
 >> iter 53000, loss: 0.033867
 >> iter 54000, loss: 0.028921
 >> iter 55000, loss: 0.032853
 >> iter 56000, loss: 0.028260
 >> iter 57000, loss: 0.023827
 >> iter 58000, loss: 0.020375
 >> iter 59000, loss: 0.019729
 >> iter 60000, loss: 0.024467
   Number of active neurons: 2
 >> iter 61000, loss: 0.022622
 >> iter 62000, loss: 0.020714
 >> iter 63000, loss: 0.021405
 >> iter 64000, loss: 0.020857
 >> iter 65000, loss: 0.029739
 >> iter 66000, loss: 0.025797
 >> iter 67000, loss: 0.045973
 >> iter 68000, loss: 0.027486
 >> iter 69000, loss: 0.020369
 >> iter 70000, loss: 0.021621
   Number of active neurons: 1
 >> iter 71000, loss: 0.020544
 >> iter 72000, loss: 0.031891
 >> iter 73000, loss: 0.022492
 >> iter 74000, loss: 0.022074
 >> iter 75000, loss: 0.022847
 >> iter 76000, loss: 0.022045
 >> iter 77000, loss: 0.019917
 >> iter 78000, loss: 0.016866
 >> iter 79000, loss: 0.027082
 >> iter 80000, loss: 0.019738
   Number of active neurons: 1
 >> iter 81000, loss: 0.017789
 >> iter 82000, loss: 0.015997
 >> iter 83000, loss: 0.030677
 >> iter 84000, loss: 0.031788
 >> iter 85000, loss: 0.026893
 >> iter 86000, loss: 0.025391
 >> iter 87000, loss: 0.021180
 >> iter 88000, loss: 0.019072
 >> iter 89000, loss: 0.020761
 >> iter 90000, loss: 0.017619
   Number of active neurons: 1
 >> iter 91000, loss: 0.018759
 >> iter 92000, loss: 0.026315
 >> iter 93000, loss: 0.020372
 >> iter 94000, loss: 0.017670
 >> iter 95000, loss: 0.017593
 >> iter 96000, loss: 0.025887
 >> iter 97000, loss: 0.020113
 >> iter 98000, loss: 0.018935
 >> iter 99000, loss: 0.023834
 >> iter 100000, loss: 0.019829
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.941547
 >> iter 2000, loss: 4.084495
 >> iter 3000, loss: 1.536008
 >> iter 4000, loss: 0.600656
 >> iter 5000, loss: 0.248194
 >> iter 6000, loss: 0.111635
 >> iter 7000, loss: 0.064619
 >> iter 8000, loss: 0.042808
 >> iter 9000, loss: 0.035545
 >> iter 10000, loss: 0.033853
   Number of active neurons: 5
 >> iter 11000, loss: 0.035642
 >> iter 12000, loss: 0.036627
 >> iter 13000, loss: 0.031557
 >> iter 14000, loss: 0.027189
 >> iter 15000, loss: 0.027039
 >> iter 16000, loss: 0.028113
 >> iter 17000, loss: 0.036588
 >> iter 18000, loss: 0.033403
 >> iter 19000, loss: 0.042741
 >> iter 20000, loss: 0.040224
   Number of active neurons: 4
 >> iter 21000, loss: 0.029762
 >> iter 22000, loss: 0.028772
 >> iter 23000, loss: 0.026181
 >> iter 24000, loss: 0.027127
 >> iter 25000, loss: 0.035453
 >> iter 26000, loss: 0.029393
 >> iter 27000, loss: 0.027321
 >> iter 28000, loss: 0.034750
 >> iter 29000, loss: 0.028723
 >> iter 30000, loss: 0.038060
   Number of active neurons: 4
 >> iter 31000, loss: 0.029307
 >> iter 32000, loss: 0.027015
 >> iter 33000, loss: 0.027534
 >> iter 34000, loss: 0.028045
 >> iter 35000, loss: 0.028575
 >> iter 36000, loss: 0.024801
 >> iter 37000, loss: 0.025143
 >> iter 38000, loss: 0.027765
 >> iter 39000, loss: 0.024360
 >> iter 40000, loss: 0.022525
   Number of active neurons: 2
 >> iter 41000, loss: 0.025348
 >> iter 42000, loss: 0.027720
 >> iter 43000, loss: 0.024151
 >> iter 44000, loss: 0.023598
 >> iter 45000, loss: 0.027271
 >> iter 46000, loss: 0.021864
 >> iter 47000, loss: 0.020881
 >> iter 48000, loss: 0.021127
 >> iter 49000, loss: 0.020076
 >> iter 50000, loss: 0.023752
   Number of active neurons: 2
 >> iter 51000, loss: 0.020671
 >> iter 52000, loss: 0.019827
 >> iter 53000, loss: 0.024311
 >> iter 54000, loss: 0.022377
 >> iter 55000, loss: 0.023247
 >> iter 56000, loss: 0.024117
 >> iter 57000, loss: 0.025880
 >> iter 58000, loss: 0.032663
 >> iter 59000, loss: 0.027001
 >> iter 60000, loss: 0.055790
   Number of active neurons: 2
 >> iter 61000, loss: 0.034913
 >> iter 62000, loss: 0.024905
 >> iter 63000, loss: 0.023709
 >> iter 64000, loss: 0.022313
 >> iter 65000, loss: 0.021122
 >> iter 66000, loss: 0.027281
 >> iter 67000, loss: 0.034410
 >> iter 68000, loss: 0.028534
 >> iter 69000, loss: 0.022940
 >> iter 70000, loss: 0.022246
   Number of active neurons: 2
 >> iter 71000, loss: 0.029069
 >> iter 72000, loss: 0.028589
 >> iter 73000, loss: 0.048237
 >> iter 74000, loss: 0.030885
 >> iter 75000, loss: 0.023924
 >> iter 76000, loss: 0.029362
 >> iter 77000, loss: 0.026735
 >> iter 78000, loss: 0.026505
 >> iter 79000, loss: 0.025780
 >> iter 80000, loss: 0.022488
   Number of active neurons: 2
 >> iter 81000, loss: 0.024269
 >> iter 82000, loss: 0.027232
 >> iter 83000, loss: 0.022185
 >> iter 84000, loss: 0.022969
 >> iter 85000, loss: 0.026752
 >> iter 86000, loss: 0.031175
 >> iter 87000, loss: 0.027165
 >> iter 88000, loss: 0.023706
 >> iter 89000, loss: 0.021354
 >> iter 90000, loss: 0.023361
   Number of active neurons: 2
 >> iter 91000, loss: 0.022766
 >> iter 92000, loss: 0.025210
 >> iter 93000, loss: 0.037887
 >> iter 94000, loss: 0.027895
 >> iter 95000, loss: 0.022817
 >> iter 96000, loss: 0.022329
 >> iter 97000, loss: 0.024039
 >> iter 98000, loss: 0.027910
 >> iter 99000, loss: 0.024390
 >> iter 100000, loss: 0.029512
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.977470
 >> iter 2000, loss: 4.078812
 >> iter 3000, loss: 1.531824
 >> iter 4000, loss: 0.587661
 >> iter 5000, loss: 0.244728
 >> iter 6000, loss: 0.119683
 >> iter 7000, loss: 0.067360
 >> iter 8000, loss: 0.043131
 >> iter 9000, loss: 0.035137
 >> iter 10000, loss: 0.033026
   Number of active neurons: 5
 >> iter 11000, loss: 0.030092
 >> iter 12000, loss: 0.037672
 >> iter 13000, loss: 0.031660
 >> iter 14000, loss: 0.036721
 >> iter 15000, loss: 0.035723
 >> iter 16000, loss: 0.036662
 >> iter 17000, loss: 0.031417
 >> iter 18000, loss: 0.027302
 >> iter 19000, loss: 0.023961
 >> iter 20000, loss: 0.030082
   Number of active neurons: 3
 >> iter 21000, loss: 0.026201
 >> iter 22000, loss: 0.025871
 >> iter 23000, loss: 0.028377
 >> iter 24000, loss: 0.039959
 >> iter 25000, loss: 0.045853
 >> iter 26000, loss: 0.030664
 >> iter 27000, loss: 0.025262
 >> iter 28000, loss: 0.024893
 >> iter 29000, loss: 0.025069
 >> iter 30000, loss: 0.032812
   Number of active neurons: 3
 >> iter 31000, loss: 0.027675
 >> iter 32000, loss: 0.025514
 >> iter 33000, loss: 0.026393
 >> iter 34000, loss: 0.040258
 >> iter 35000, loss: 0.030369
 >> iter 36000, loss: 0.025722
 >> iter 37000, loss: 0.028618
 >> iter 38000, loss: 0.023991
 >> iter 39000, loss: 0.041080
 >> iter 40000, loss: 0.030803
   Number of active neurons: 3
 >> iter 41000, loss: 0.027804
 >> iter 42000, loss: 0.026108
 >> iter 43000, loss: 0.022893
 >> iter 44000, loss: 0.023057
 >> iter 45000, loss: 0.025644
 >> iter 46000, loss: 0.023505
 >> iter 47000, loss: 0.021483
 >> iter 48000, loss: 0.022954
 >> iter 49000, loss: 0.021824
 >> iter 50000, loss: 0.029093
   Number of active neurons: 2
 >> iter 51000, loss: 0.036349
 >> iter 52000, loss: 0.031582
 >> iter 53000, loss: 0.039899
 >> iter 54000, loss: 0.028174
 >> iter 55000, loss: 0.023926
 >> iter 56000, loss: 0.038794
 >> iter 57000, loss: 0.025928
 >> iter 58000, loss: 0.023464
 >> iter 59000, loss: 0.027156
 >> iter 60000, loss: 0.022965
   Number of active neurons: 2
 >> iter 61000, loss: 0.020670
 >> iter 62000, loss: 0.019929
 >> iter 63000, loss: 0.020668
 >> iter 64000, loss: 0.019612
 >> iter 65000, loss: 0.040287
 >> iter 66000, loss: 0.031649
 >> iter 67000, loss: 0.024682
 >> iter 68000, loss: 0.028168
 >> iter 69000, loss: 0.032580
 >> iter 70000, loss: 0.026748
   Number of active neurons: 2
 >> iter 71000, loss: 0.025978
 >> iter 72000, loss: 0.026508
 >> iter 73000, loss: 0.021889
 >> iter 74000, loss: 0.030240
 >> iter 75000, loss: 0.025332
 >> iter 76000, loss: 0.024471
 >> iter 77000, loss: 0.025020
 >> iter 78000, loss: 0.022575
 >> iter 79000, loss: 0.024076
 >> iter 80000, loss: 0.021815
   Number of active neurons: 2
 >> iter 81000, loss: 0.021206
 >> iter 82000, loss: 0.024260
 >> iter 83000, loss: 0.029767
 >> iter 84000, loss: 0.023737
 >> iter 85000, loss: 0.022554
 >> iter 86000, loss: 0.022218
 >> iter 87000, loss: 0.023429
 >> iter 88000, loss: 0.024160
 >> iter 89000, loss: 0.022124
 >> iter 90000, loss: 0.019619
   Number of active neurons: 2
 >> iter 91000, loss: 0.020905
 >> iter 92000, loss: 0.022939
 >> iter 93000, loss: 0.020755
 >> iter 94000, loss: 0.020985
 >> iter 95000, loss: 0.023509
 >> iter 96000, loss: 0.024748
 >> iter 97000, loss: 0.023546
 >> iter 98000, loss: 0.026583
 >> iter 99000, loss: 0.025316
 >> iter 100000, loss: 0.021699
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.029380
 >> iter 2000, loss: 4.104708
 >> iter 3000, loss: 1.539429
 >> iter 4000, loss: 0.586665
 >> iter 5000, loss: 0.243790
 >> iter 6000, loss: 0.110191
 >> iter 7000, loss: 0.069984
 >> iter 8000, loss: 0.048429
 >> iter 9000, loss: 0.035861
 >> iter 10000, loss: 0.031241
   Number of active neurons: 6
 >> iter 11000, loss: 0.036059
 >> iter 12000, loss: 0.034736
 >> iter 13000, loss: 0.041731
 >> iter 14000, loss: 0.041155
 >> iter 15000, loss: 0.031896
 >> iter 16000, loss: 0.029957
 >> iter 17000, loss: 0.036823
 >> iter 18000, loss: 0.038910
 >> iter 19000, loss: 0.038282
 >> iter 20000, loss: 0.028125
   Number of active neurons: 3
 >> iter 21000, loss: 0.025849
 >> iter 22000, loss: 0.031356
 >> iter 23000, loss: 0.025711
 >> iter 24000, loss: 0.029107
 >> iter 25000, loss: 0.034434
 >> iter 26000, loss: 0.026130
 >> iter 27000, loss: 0.022625
 >> iter 28000, loss: 0.021849
 >> iter 29000, loss: 0.035550
 >> iter 30000, loss: 0.026397
   Number of active neurons: 2
 >> iter 31000, loss: 0.025074
 >> iter 32000, loss: 0.024562
 >> iter 33000, loss: 0.021905
 >> iter 34000, loss: 0.021629
 >> iter 35000, loss: 0.021106
 >> iter 36000, loss: 0.022354
 >> iter 37000, loss: 0.021580
 >> iter 38000, loss: 0.021270
 >> iter 39000, loss: 0.027780
 >> iter 40000, loss: 0.027804
   Number of active neurons: 2
 >> iter 41000, loss: 0.021295
 >> iter 42000, loss: 0.023501
 >> iter 43000, loss: 0.042313
 >> iter 44000, loss: 0.028187
 >> iter 45000, loss: 0.038184
 >> iter 46000, loss: 0.031685
 >> iter 47000, loss: 0.029563
 >> iter 48000, loss: 0.025799
 >> iter 49000, loss: 0.021096
 >> iter 50000, loss: 0.020755
   Number of active neurons: 2
 >> iter 51000, loss: 0.020359
 >> iter 52000, loss: 0.020177
 >> iter 53000, loss: 0.022918
 >> iter 54000, loss: 0.024166
 >> iter 55000, loss: 0.022619
 >> iter 56000, loss: 0.033633
 >> iter 57000, loss: 0.027651
 >> iter 58000, loss: 0.022335
 >> iter 59000, loss: 0.040196
 >> iter 60000, loss: 0.027952
   Number of active neurons: 2
 >> iter 61000, loss: 0.026280
 >> iter 62000, loss: 0.029761
 >> iter 63000, loss: 0.028945
 >> iter 64000, loss: 0.024797
 >> iter 65000, loss: 0.022578
 >> iter 66000, loss: 0.021646
 >> iter 67000, loss: 0.021744
 >> iter 68000, loss: 0.023112
 >> iter 69000, loss: 0.026753
 >> iter 70000, loss: 0.023980
   Number of active neurons: 2
 >> iter 71000, loss: 0.019787
 >> iter 72000, loss: 0.019536
 >> iter 73000, loss: 0.023071
 >> iter 74000, loss: 0.027783
 >> iter 75000, loss: 0.025824
 >> iter 76000, loss: 0.026298
 >> iter 77000, loss: 0.025711
 >> iter 78000, loss: 0.022526
 >> iter 79000, loss: 0.020715
 >> iter 80000, loss: 0.019166
   Number of active neurons: 1
 >> iter 81000, loss: 0.018191
 >> iter 82000, loss: 0.020781
 >> iter 83000, loss: 0.024716
 >> iter 84000, loss: 0.021468
 >> iter 85000, loss: 0.025671
 >> iter 86000, loss: 0.024200
 >> iter 87000, loss: 0.019390
 >> iter 88000, loss: 0.027137
 >> iter 89000, loss: 0.032438
 >> iter 90000, loss: 0.025876
   Number of active neurons: 1
 >> iter 91000, loss: 0.020192
 >> iter 92000, loss: 0.017986
 >> iter 93000, loss: 0.018396
 >> iter 94000, loss: 0.017257
 >> iter 95000, loss: 0.020442
 >> iter 96000, loss: 0.018413
 >> iter 97000, loss: 0.075922
 >> iter 98000, loss: 0.072812
 >> iter 99000, loss: 0.050716
 >> iter 100000, loss: 0.032081
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.004599
 >> iter 2000, loss: 4.105643
 >> iter 3000, loss: 1.577381
 >> iter 4000, loss: 0.610519
 >> iter 5000, loss: 0.249716
 >> iter 6000, loss: 0.118654
 >> iter 7000, loss: 0.066583
 >> iter 8000, loss: 0.048682
 >> iter 9000, loss: 0.046762
 >> iter 10000, loss: 0.036039
   Number of active neurons: 4
 >> iter 11000, loss: 0.033403
 >> iter 12000, loss: 0.032558
 >> iter 13000, loss: 0.030796
 >> iter 14000, loss: 0.028831
 >> iter 15000, loss: 0.027872
 >> iter 16000, loss: 0.030571
 >> iter 17000, loss: 0.033503
 >> iter 18000, loss: 0.067658
 >> iter 19000, loss: 0.046401
 >> iter 20000, loss: 0.033164
   Number of active neurons: 2
 >> iter 21000, loss: 0.039702
 >> iter 22000, loss: 0.030957
 >> iter 23000, loss: 0.027120
 >> iter 24000, loss: 0.043939
 >> iter 25000, loss: 0.029973
 >> iter 26000, loss: 0.025020
 >> iter 27000, loss: 0.031222
 >> iter 28000, loss: 0.024763
 >> iter 29000, loss: 0.025064
 >> iter 30000, loss: 0.029592
   Number of active neurons: 2
 >> iter 31000, loss: 0.025783
 >> iter 32000, loss: 0.023067
 >> iter 33000, loss: 0.023218
 >> iter 34000, loss: 0.024324
 >> iter 35000, loss: 0.022074
 >> iter 36000, loss: 0.020423
 >> iter 37000, loss: 0.019106
 >> iter 38000, loss: 0.018631
 >> iter 39000, loss: 0.019352
 >> iter 40000, loss: 0.020196
   Number of active neurons: 1
 >> iter 41000, loss: 0.036464
 >> iter 42000, loss: 0.032197
 >> iter 43000, loss: 0.051939
 >> iter 44000, loss: 0.035757
 >> iter 45000, loss: 0.051049
 >> iter 46000, loss: 0.031645
 >> iter 47000, loss: 0.027258
 >> iter 48000, loss: 0.020795
 >> iter 49000, loss: 0.029778
 >> iter 50000, loss: 0.021428
   Number of active neurons: 1
 >> iter 51000, loss: 0.019566
 >> iter 52000, loss: 0.018134
 >> iter 53000, loss: 0.019918
 >> iter 54000, loss: 0.018129
 >> iter 55000, loss: 0.019609
 >> iter 56000, loss: 0.018598
 >> iter 57000, loss: 0.016224
 >> iter 58000, loss: 0.017351
 >> iter 59000, loss: 0.017535
 >> iter 60000, loss: 0.017536
   Number of active neurons: 1
 >> iter 61000, loss: 0.063148
 >> iter 62000, loss: 0.048217
 >> iter 63000, loss: 0.030032
 >> iter 64000, loss: 0.026506
 >> iter 65000, loss: 0.027182
 >> iter 66000, loss: 0.023246
 >> iter 67000, loss: 0.019551
 >> iter 68000, loss: 0.032146
 >> iter 69000, loss: 0.030406
 >> iter 70000, loss: 0.023080
   Number of active neurons: 1
 >> iter 71000, loss: 0.018545
 >> iter 72000, loss: 0.020087
 >> iter 73000, loss: 0.017996
 >> iter 74000, loss: 0.057882
 >> iter 75000, loss: 0.034817
 >> iter 76000, loss: 0.029746
 >> iter 77000, loss: 0.023739
 >> iter 78000, loss: 0.024439
 >> iter 79000, loss: 0.019931
 >> iter 80000, loss: 0.018687
   Number of active neurons: 1
 >> iter 81000, loss: 0.019131
 >> iter 82000, loss: 0.025597
 >> iter 83000, loss: 0.020258
 >> iter 84000, loss: 0.017412
 >> iter 85000, loss: 0.020126
 >> iter 86000, loss: 0.019282
 >> iter 87000, loss: 0.016660
 >> iter 88000, loss: 0.035040
 >> iter 89000, loss: 0.025760
 >> iter 90000, loss: 0.020138
   Number of active neurons: 1
 >> iter 91000, loss: 0.019942
 >> iter 92000, loss: 0.023912
 >> iter 93000, loss: 0.028933
 >> iter 94000, loss: 0.020217
 >> iter 95000, loss: 0.018648
 >> iter 96000, loss: 0.021391
 >> iter 97000, loss: 0.058959
 >> iter 98000, loss: 0.036038
 >> iter 99000, loss: 0.026436
 >> iter 100000, loss: 0.020392
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.899542
 >> iter 2000, loss: 4.059303
 >> iter 3000, loss: 1.530929
 >> iter 4000, loss: 0.591648
 >> iter 5000, loss: 0.237353
 >> iter 6000, loss: 0.121426
 >> iter 7000, loss: 0.063330
 >> iter 8000, loss: 0.044235
 >> iter 9000, loss: 0.040250
 >> iter 10000, loss: 0.033613
   Number of active neurons: 5
 >> iter 11000, loss: 0.031007
 >> iter 12000, loss: 0.030070
 >> iter 13000, loss: 0.027846
 >> iter 14000, loss: 0.029465
 >> iter 15000, loss: 0.033117
 >> iter 16000, loss: 0.027865
 >> iter 17000, loss: 0.027953
 >> iter 18000, loss: 0.025958
 >> iter 19000, loss: 0.026348
 >> iter 20000, loss: 0.024440
   Number of active neurons: 2
 >> iter 21000, loss: 0.024960
 >> iter 22000, loss: 0.024504
 >> iter 23000, loss: 0.037266
 >> iter 24000, loss: 0.029634
 >> iter 25000, loss: 0.024696
 >> iter 26000, loss: 0.022569
 >> iter 27000, loss: 0.020903
 >> iter 28000, loss: 0.020824
 >> iter 29000, loss: 0.020851
 >> iter 30000, loss: 0.024373
   Number of active neurons: 2
 >> iter 31000, loss: 0.022088
 >> iter 32000, loss: 0.020011
 >> iter 33000, loss: 0.022573
 >> iter 34000, loss: 0.022087
 >> iter 35000, loss: 0.020330
 >> iter 36000, loss: 0.023223
 >> iter 37000, loss: 0.022206
 >> iter 38000, loss: 0.020974
 >> iter 39000, loss: 0.030677
 >> iter 40000, loss: 0.024667
   Number of active neurons: 2
 >> iter 41000, loss: 0.021732
 >> iter 42000, loss: 0.020036
 >> iter 43000, loss: 0.021337
 >> iter 44000, loss: 0.025104
 >> iter 45000, loss: 0.024340
 >> iter 46000, loss: 0.022041
 >> iter 47000, loss: 0.021713
 >> iter 48000, loss: 0.020854
 >> iter 49000, loss: 0.024148
 >> iter 50000, loss: 0.021511
   Number of active neurons: 2
 >> iter 51000, loss: 0.036850
 >> iter 52000, loss: 0.025045
 >> iter 53000, loss: 0.024669
 >> iter 54000, loss: 0.025592
 >> iter 55000, loss: 0.025465
 >> iter 56000, loss: 0.024913
 >> iter 57000, loss: 0.031150
 >> iter 58000, loss: 0.038726
 >> iter 59000, loss: 0.029275
 >> iter 60000, loss: 0.026090
   Number of active neurons: 2
 >> iter 61000, loss: 0.027603
 >> iter 62000, loss: 0.024612
 >> iter 63000, loss: 0.021457
 >> iter 64000, loss: 0.023107
 >> iter 65000, loss: 0.023484
 >> iter 66000, loss: 0.025347
 >> iter 67000, loss: 0.023624
 >> iter 68000, loss: 0.020726
 >> iter 69000, loss: 0.022994
 >> iter 70000, loss: 0.025463
   Number of active neurons: 2
 >> iter 71000, loss: 0.022657
 >> iter 72000, loss: 0.031546
 >> iter 73000, loss: 0.033345
 >> iter 74000, loss: 0.036733
 >> iter 75000, loss: 0.026166
 >> iter 76000, loss: 0.028725
 >> iter 77000, loss: 0.024147
 >> iter 78000, loss: 0.020307
 >> iter 79000, loss: 0.021096
 >> iter 80000, loss: 0.020293
   Number of active neurons: 2
 >> iter 81000, loss: 0.025912
 >> iter 82000, loss: 0.022066
 >> iter 83000, loss: 0.025509
 >> iter 84000, loss: 0.037162
 >> iter 85000, loss: 0.027825
 >> iter 86000, loss: 0.023441
 >> iter 87000, loss: 0.026932
 >> iter 88000, loss: 0.022299
 >> iter 89000, loss: 0.022955
 >> iter 90000, loss: 0.022523
   Number of active neurons: 2
 >> iter 91000, loss: 0.028993
 >> iter 92000, loss: 0.027966
 >> iter 93000, loss: 0.027263
 >> iter 94000, loss: 0.024072
 >> iter 95000, loss: 0.025021
 >> iter 96000, loss: 0.035507
 >> iter 97000, loss: 0.026452
 >> iter 98000, loss: 0.024988
 >> iter 99000, loss: 0.022642
 >> iter 100000, loss: 0.021533
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

