 > Problema: tomita1nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 0.0004
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.976296
 >> iter 2000, loss: 4.088447
 >> iter 3000, loss: 1.547454
 >> iter 4000, loss: 0.609688
 >> iter 5000, loss: 0.264410
 >> iter 6000, loss: 0.135936
 >> iter 7000, loss: 0.088923
 >> iter 8000, loss: 0.070429
 >> iter 9000, loss: 0.064161
 >> iter 10000, loss: 0.060769
   Number of active neurons: 1
 >> iter 11000, loss: 0.060237
 >> iter 12000, loss: 0.059005
 >> iter 13000, loss: 0.059410
 >> iter 14000, loss: 0.058521
 >> iter 15000, loss: 0.059117
 >> iter 16000, loss: 0.058341
 >> iter 17000, loss: 0.058991
 >> iter 18000, loss: 0.058270
 >> iter 19000, loss: 0.058914
 >> iter 20000, loss: 0.058258
   Number of active neurons: 1
 >> iter 21000, loss: 0.058893
 >> iter 22000, loss: 0.058212
 >> iter 23000, loss: 0.058878
 >> iter 24000, loss: 0.058174
 >> iter 25000, loss: 0.058873
 >> iter 26000, loss: 0.058195
 >> iter 27000, loss: 0.058868
 >> iter 28000, loss: 0.058201
 >> iter 29000, loss: 0.058842
 >> iter 30000, loss: 0.058170
   Number of active neurons: 1
 >> iter 31000, loss: 0.058824
 >> iter 32000, loss: 0.058147
 >> iter 33000, loss: 0.058802
 >> iter 34000, loss: 0.058135
 >> iter 35000, loss: 0.058828
 >> iter 36000, loss: 0.058120
 >> iter 37000, loss: 0.058818
 >> iter 38000, loss: 0.058095
 >> iter 39000, loss: 0.058823
 >> iter 40000, loss: 0.058086
   Number of active neurons: 1
 >> iter 41000, loss: 0.058805
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058775
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058772
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058799
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058148
 >> iter 53000, loss: 0.058786
 >> iter 54000, loss: 0.058218
 >> iter 55000, loss: 0.058767
 >> iter 56000, loss: 0.058229
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058198
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058221
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058820
 >> iter 64000, loss: 0.058195
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058207
 >> iter 67000, loss: 0.058795
 >> iter 68000, loss: 0.058254
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058218
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058248
 >> iter 73000, loss: 0.058801
 >> iter 74000, loss: 0.058230
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058786
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058207
   Number of active neurons: 1
 >> iter 81000, loss: 0.058908
 >> iter 82000, loss: 0.058212
 >> iter 83000, loss: 0.058947
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058931
 >> iter 86000, loss: 0.058187
 >> iter 87000, loss: 0.058932
 >> iter 88000, loss: 0.058181
 >> iter 89000, loss: 0.058913
 >> iter 90000, loss: 0.058205
   Number of active neurons: 1
 >> iter 91000, loss: 0.058910
 >> iter 92000, loss: 0.058223
 >> iter 93000, loss: 0.058932
 >> iter 94000, loss: 0.058201
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058188
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058171
 >> iter 99000, loss: 0.059018
 >> iter 100000, loss: 0.058235
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.854266
 >> iter 2000, loss: 4.044247
 >> iter 3000, loss: 1.537365
 >> iter 4000, loss: 0.614155
 >> iter 5000, loss: 0.275616
 >> iter 6000, loss: 0.150048
 >> iter 7000, loss: 0.103791
 >> iter 8000, loss: 0.081590
 >> iter 9000, loss: 0.071104
 >> iter 10000, loss: 0.065059
   Number of active neurons: 1
 >> iter 11000, loss: 0.063024
 >> iter 12000, loss: 0.060893
 >> iter 13000, loss: 0.060739
 >> iter 14000, loss: 0.059468
 >> iter 15000, loss: 0.059805
 >> iter 16000, loss: 0.058838
 >> iter 17000, loss: 0.059356
 >> iter 18000, loss: 0.058534
 >> iter 19000, loss: 0.059108
 >> iter 20000, loss: 0.058399
   Number of active neurons: 1
 >> iter 21000, loss: 0.058997
 >> iter 22000, loss: 0.058288
 >> iter 23000, loss: 0.058935
 >> iter 24000, loss: 0.058215
 >> iter 25000, loss: 0.058903
 >> iter 26000, loss: 0.058217
 >> iter 27000, loss: 0.058885
 >> iter 28000, loss: 0.058213
 >> iter 29000, loss: 0.058850
 >> iter 30000, loss: 0.058176
   Number of active neurons: 1
 >> iter 31000, loss: 0.058829
 >> iter 32000, loss: 0.058150
 >> iter 33000, loss: 0.058804
 >> iter 34000, loss: 0.058137
 >> iter 35000, loss: 0.058829
 >> iter 36000, loss: 0.058121
 >> iter 37000, loss: 0.058818
 >> iter 38000, loss: 0.058095
 >> iter 39000, loss: 0.058823
 >> iter 40000, loss: 0.058086
   Number of active neurons: 1
 >> iter 41000, loss: 0.058805
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058775
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058104
 >> iter 47000, loss: 0.058772
 >> iter 48000, loss: 0.058125
 >> iter 49000, loss: 0.058798
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058148
 >> iter 53000, loss: 0.058785
 >> iter 54000, loss: 0.058218
 >> iter 55000, loss: 0.058767
 >> iter 56000, loss: 0.058229
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058198
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058221
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058820
 >> iter 64000, loss: 0.058196
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058207
 >> iter 67000, loss: 0.058795
 >> iter 68000, loss: 0.058254
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058219
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058248
 >> iter 73000, loss: 0.058800
 >> iter 74000, loss: 0.058230
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058231
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058207
   Number of active neurons: 1
 >> iter 81000, loss: 0.058908
 >> iter 82000, loss: 0.058212
 >> iter 83000, loss: 0.058947
 >> iter 84000, loss: 0.058206
 >> iter 85000, loss: 0.058930
 >> iter 86000, loss: 0.058187
 >> iter 87000, loss: 0.058932
 >> iter 88000, loss: 0.058181
 >> iter 89000, loss: 0.058912
 >> iter 90000, loss: 0.058205
   Number of active neurons: 1
 >> iter 91000, loss: 0.058910
 >> iter 92000, loss: 0.058224
 >> iter 93000, loss: 0.058932
 >> iter 94000, loss: 0.058201
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058188
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058171
 >> iter 99000, loss: 0.059018
 >> iter 100000, loss: 0.058235
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.926130
 >> iter 2000, loss: 4.069811
 >> iter 3000, loss: 1.540557
 >> iter 4000, loss: 0.607134
 >> iter 5000, loss: 0.263461
 >> iter 6000, loss: 0.135579
 >> iter 7000, loss: 0.088787
 >> iter 8000, loss: 0.070375
 >> iter 9000, loss: 0.064138
 >> iter 10000, loss: 0.060757
   Number of active neurons: 1
 >> iter 11000, loss: 0.060231
 >> iter 12000, loss: 0.059002
 >> iter 13000, loss: 0.059407
 >> iter 14000, loss: 0.058520
 >> iter 15000, loss: 0.059117
 >> iter 16000, loss: 0.058340
 >> iter 17000, loss: 0.058991
 >> iter 18000, loss: 0.058269
 >> iter 19000, loss: 0.058914
 >> iter 20000, loss: 0.058257
   Number of active neurons: 1
 >> iter 21000, loss: 0.058893
 >> iter 22000, loss: 0.058212
 >> iter 23000, loss: 0.058878
 >> iter 24000, loss: 0.058174
 >> iter 25000, loss: 0.058873
 >> iter 26000, loss: 0.058195
 >> iter 27000, loss: 0.058869
 >> iter 28000, loss: 0.058200
 >> iter 29000, loss: 0.058841
 >> iter 30000, loss: 0.058170
   Number of active neurons: 1
 >> iter 31000, loss: 0.058825
 >> iter 32000, loss: 0.058146
 >> iter 33000, loss: 0.058801
 >> iter 34000, loss: 0.058135
 >> iter 35000, loss: 0.058829
 >> iter 36000, loss: 0.058120
 >> iter 37000, loss: 0.058817
 >> iter 38000, loss: 0.058096
 >> iter 39000, loss: 0.058824
 >> iter 40000, loss: 0.058085
   Number of active neurons: 1
 >> iter 41000, loss: 0.058804
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058776
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058773
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058798
 >> iter 50000, loss: 0.058117
   Number of active neurons: 1
 >> iter 51000, loss: 0.058801
 >> iter 52000, loss: 0.058147
 >> iter 53000, loss: 0.058785
 >> iter 54000, loss: 0.058219
 >> iter 55000, loss: 0.058768
 >> iter 56000, loss: 0.058227
 >> iter 57000, loss: 0.058813
 >> iter 58000, loss: 0.058199
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058220
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058231
 >> iter 63000, loss: 0.058821
 >> iter 64000, loss: 0.058194
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058208
 >> iter 67000, loss: 0.058796
 >> iter 68000, loss: 0.058253
 >> iter 69000, loss: 0.058799
 >> iter 70000, loss: 0.058219
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058247
 >> iter 73000, loss: 0.058800
 >> iter 74000, loss: 0.058231
 >> iter 75000, loss: 0.058803
 >> iter 76000, loss: 0.058229
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058196
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058206
   Number of active neurons: 1
 >> iter 81000, loss: 0.058907
 >> iter 82000, loss: 0.058213
 >> iter 83000, loss: 0.058947
 >> iter 84000, loss: 0.058204
 >> iter 85000, loss: 0.058930
 >> iter 86000, loss: 0.058188
 >> iter 87000, loss: 0.058933
 >> iter 88000, loss: 0.058180
 >> iter 89000, loss: 0.058911
 >> iter 90000, loss: 0.058206
   Number of active neurons: 1
 >> iter 91000, loss: 0.058911
 >> iter 92000, loss: 0.058222
 >> iter 93000, loss: 0.058931
 >> iter 94000, loss: 0.058202
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058187
 >> iter 97000, loss: 0.059006
 >> iter 98000, loss: 0.058172
 >> iter 99000, loss: 0.059019
 >> iter 100000, loss: 0.058234
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.834220
 >> iter 2000, loss: 4.036909
 >> iter 3000, loss: 1.534743
 >> iter 4000, loss: 0.613251
 >> iter 5000, loss: 0.275319
 >> iter 6000, loss: 0.149914
 >> iter 7000, loss: 0.103312
 >> iter 8000, loss: 0.080792
 >> iter 9000, loss: 0.070556
 >> iter 10000, loss: 0.064738
   Number of active neurons: 1
 >> iter 11000, loss: 0.062832
 >> iter 12000, loss: 0.060773
 >> iter 13000, loss: 0.060658
 >> iter 14000, loss: 0.059412
 >> iter 15000, loss: 0.059765
 >> iter 16000, loss: 0.058809
 >> iter 17000, loss: 0.059335
 >> iter 18000, loss: 0.058519
 >> iter 19000, loss: 0.059097
 >> iter 20000, loss: 0.058391
   Number of active neurons: 1
 >> iter 21000, loss: 0.058991
 >> iter 22000, loss: 0.058284
 >> iter 23000, loss: 0.058931
 >> iter 24000, loss: 0.058212
 >> iter 25000, loss: 0.058901
 >> iter 26000, loss: 0.058216
 >> iter 27000, loss: 0.058884
 >> iter 28000, loss: 0.058212
 >> iter 29000, loss: 0.058849
 >> iter 30000, loss: 0.058176
   Number of active neurons: 1
 >> iter 31000, loss: 0.058829
 >> iter 32000, loss: 0.058150
 >> iter 33000, loss: 0.058803
 >> iter 34000, loss: 0.058137
 >> iter 35000, loss: 0.058830
 >> iter 36000, loss: 0.058121
 >> iter 37000, loss: 0.058818
 >> iter 38000, loss: 0.058096
 >> iter 39000, loss: 0.058824
 >> iter 40000, loss: 0.058086
   Number of active neurons: 1
 >> iter 41000, loss: 0.058805
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058776
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058773
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058799
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058147
 >> iter 53000, loss: 0.058786
 >> iter 54000, loss: 0.058219
 >> iter 55000, loss: 0.058768
 >> iter 56000, loss: 0.058228
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058199
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058220
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058821
 >> iter 64000, loss: 0.058195
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058208
 >> iter 67000, loss: 0.058796
 >> iter 68000, loss: 0.058253
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058219
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058247
 >> iter 73000, loss: 0.058801
 >> iter 74000, loss: 0.058231
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058206
   Number of active neurons: 1
 >> iter 81000, loss: 0.058908
 >> iter 82000, loss: 0.058213
 >> iter 83000, loss: 0.058947
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058930
 >> iter 86000, loss: 0.058188
 >> iter 87000, loss: 0.058933
 >> iter 88000, loss: 0.058180
 >> iter 89000, loss: 0.058912
 >> iter 90000, loss: 0.058206
   Number of active neurons: 1
 >> iter 91000, loss: 0.058911
 >> iter 92000, loss: 0.058223
 >> iter 93000, loss: 0.058932
 >> iter 94000, loss: 0.058202
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058187
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058172
 >> iter 99000, loss: 0.059019
 >> iter 100000, loss: 0.058234
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 10.919374
 >> iter 2000, loss: 4.067280
 >> iter 3000, loss: 1.544990
 >> iter 4000, loss: 0.615968
 >> iter 5000, loss: 0.275516
 >> iter 6000, loss: 0.149502
 >> iter 7000, loss: 0.104336
 >> iter 8000, loss: 0.086747
 >> iter 9000, loss: 0.080625
 >> iter 10000, loss: 0.073558
   Number of active neurons: 1
 >> iter 11000, loss: 0.068375
 >> iter 12000, loss: 0.064090
 >> iter 13000, loss: 0.062733
 >> iter 14000, loss: 0.060778
 >> iter 15000, loss: 0.060707
 >> iter 16000, loss: 0.059473
 >> iter 17000, loss: 0.059813
 >> iter 18000, loss: 0.058864
 >> iter 19000, loss: 0.059348
 >> iter 20000, loss: 0.058573
   Number of active neurons: 1
 >> iter 21000, loss: 0.059125
 >> iter 22000, loss: 0.058381
 >> iter 23000, loss: 0.059003
 >> iter 24000, loss: 0.058264
 >> iter 25000, loss: 0.058940
 >> iter 26000, loss: 0.058244
 >> iter 27000, loss: 0.058904
 >> iter 28000, loss: 0.058227
 >> iter 29000, loss: 0.058861
 >> iter 30000, loss: 0.058184
   Number of active neurons: 1
 >> iter 31000, loss: 0.058835
 >> iter 32000, loss: 0.058155
 >> iter 33000, loss: 0.058807
 >> iter 34000, loss: 0.058139
 >> iter 35000, loss: 0.058831
 >> iter 36000, loss: 0.058122
 >> iter 37000, loss: 0.058820
 >> iter 38000, loss: 0.058096
 >> iter 39000, loss: 0.058823
 >> iter 40000, loss: 0.058086
   Number of active neurons: 1
 >> iter 41000, loss: 0.058805
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058775
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058786
 >> iter 46000, loss: 0.058104
 >> iter 47000, loss: 0.058772
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058799
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058148
 >> iter 53000, loss: 0.058786
 >> iter 54000, loss: 0.058218
 >> iter 55000, loss: 0.058767
 >> iter 56000, loss: 0.058229
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058198
 >> iter 59000, loss: 0.058824
 >> iter 60000, loss: 0.058221
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058229
 >> iter 63000, loss: 0.058820
 >> iter 64000, loss: 0.058196
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058207
 >> iter 67000, loss: 0.058795
 >> iter 68000, loss: 0.058254
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058218
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058248
 >> iter 73000, loss: 0.058801
 >> iter 74000, loss: 0.058230
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058786
 >> iter 78000, loss: 0.058194
 >> iter 79000, loss: 0.058845
 >> iter 80000, loss: 0.058207
   Number of active neurons: 1
 >> iter 81000, loss: 0.058908
 >> iter 82000, loss: 0.058212
 >> iter 83000, loss: 0.058946
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058931
 >> iter 86000, loss: 0.058187
 >> iter 87000, loss: 0.058932
 >> iter 88000, loss: 0.058181
 >> iter 89000, loss: 0.058913
 >> iter 90000, loss: 0.058205
   Number of active neurons: 1
 >> iter 91000, loss: 0.058910
 >> iter 92000, loss: 0.058224
 >> iter 93000, loss: 0.058932
 >> iter 94000, loss: 0.058201
 >> iter 95000, loss: 0.058990
 >> iter 96000, loss: 0.058188
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058171
 >> iter 99000, loss: 0.059018
 >> iter 100000, loss: 0.058235
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.836840
 >> iter 2000, loss: 4.035694
 >> iter 3000, loss: 1.532555
 >> iter 4000, loss: 0.610288
 >> iter 5000, loss: 0.272147
 >> iter 6000, loss: 0.146790
 >> iter 7000, loss: 0.102099
 >> iter 8000, loss: 0.084873
 >> iter 9000, loss: 0.079915
 >> iter 10000, loss: 0.077238
   Number of active neurons: 2
 >> iter 11000, loss: 0.077616
 >> iter 12000, loss: 0.076561
 >> iter 13000, loss: 0.075792
 >> iter 14000, loss: 0.070081
 >> iter 15000, loss: 0.066419
 >> iter 16000, loss: 0.063009
 >> iter 17000, loss: 0.062121
 >> iter 18000, loss: 0.060432
 >> iter 19000, loss: 0.060452
 >> iter 20000, loss: 0.059360
   Number of active neurons: 1
 >> iter 21000, loss: 0.059694
 >> iter 22000, loss: 0.058793
 >> iter 23000, loss: 0.059304
 >> iter 24000, loss: 0.058484
 >> iter 25000, loss: 0.059101
 >> iter 26000, loss: 0.058361
 >> iter 27000, loss: 0.058990
 >> iter 28000, loss: 0.058290
 >> iter 29000, loss: 0.058907
 >> iter 30000, loss: 0.058217
   Number of active neurons: 1
 >> iter 31000, loss: 0.058860
 >> iter 32000, loss: 0.058172
 >> iter 33000, loss: 0.058820
 >> iter 34000, loss: 0.058149
 >> iter 35000, loss: 0.058839
 >> iter 36000, loss: 0.058127
 >> iter 37000, loss: 0.058823
 >> iter 38000, loss: 0.058100
 >> iter 39000, loss: 0.058826
 >> iter 40000, loss: 0.058088
   Number of active neurons: 1
 >> iter 41000, loss: 0.058806
 >> iter 42000, loss: 0.058099
 >> iter 43000, loss: 0.058776
 >> iter 44000, loss: 0.058112
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058773
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058798
 >> iter 50000, loss: 0.058117
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058147
 >> iter 53000, loss: 0.058785
 >> iter 54000, loss: 0.058219
 >> iter 55000, loss: 0.058767
 >> iter 56000, loss: 0.058228
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058199
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058221
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058231
 >> iter 63000, loss: 0.058820
 >> iter 64000, loss: 0.058195
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058208
 >> iter 67000, loss: 0.058795
 >> iter 68000, loss: 0.058254
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058219
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058247
 >> iter 73000, loss: 0.058800
 >> iter 74000, loss: 0.058231
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058196
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058206
   Number of active neurons: 1
 >> iter 81000, loss: 0.058907
 >> iter 82000, loss: 0.058213
 >> iter 83000, loss: 0.058947
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058930
 >> iter 86000, loss: 0.058188
 >> iter 87000, loss: 0.058933
 >> iter 88000, loss: 0.058181
 >> iter 89000, loss: 0.058912
 >> iter 90000, loss: 0.058206
   Number of active neurons: 1
 >> iter 91000, loss: 0.058911
 >> iter 92000, loss: 0.058223
 >> iter 93000, loss: 0.058931
 >> iter 94000, loss: 0.058202
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058187
 >> iter 97000, loss: 0.059006
 >> iter 98000, loss: 0.058172
 >> iter 99000, loss: 0.059019
 >> iter 100000, loss: 0.058235
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.818946
 >> iter 2000, loss: 4.032874
 >> iter 3000, loss: 1.533005
 >> iter 4000, loss: 0.612007
 >> iter 5000, loss: 0.274369
 >> iter 6000, loss: 0.149342
 >> iter 7000, loss: 0.104432
 >> iter 8000, loss: 0.086635
 >> iter 9000, loss: 0.078602
 >> iter 10000, loss: 0.070383
   Number of active neurons: 1
 >> iter 11000, loss: 0.066205
 >> iter 12000, loss: 0.062811
 >> iter 13000, loss: 0.061964
 >> iter 14000, loss: 0.060289
 >> iter 15000, loss: 0.060379
 >> iter 16000, loss: 0.059245
 >> iter 17000, loss: 0.059650
 >> iter 18000, loss: 0.058747
 >> iter 19000, loss: 0.059264
 >> iter 20000, loss: 0.058512
   Number of active neurons: 1
 >> iter 21000, loss: 0.059080
 >> iter 22000, loss: 0.058349
 >> iter 23000, loss: 0.058978
 >> iter 24000, loss: 0.058247
 >> iter 25000, loss: 0.058927
 >> iter 26000, loss: 0.058234
 >> iter 27000, loss: 0.058898
 >> iter 28000, loss: 0.058222
 >> iter 29000, loss: 0.058857
 >> iter 30000, loss: 0.058181
   Number of active neurons: 1
 >> iter 31000, loss: 0.058833
 >> iter 32000, loss: 0.058152
 >> iter 33000, loss: 0.058805
 >> iter 34000, loss: 0.058138
 >> iter 35000, loss: 0.058831
 >> iter 36000, loss: 0.058122
 >> iter 37000, loss: 0.058818
 >> iter 38000, loss: 0.058097
 >> iter 39000, loss: 0.058824
 >> iter 40000, loss: 0.058086
   Number of active neurons: 1
 >> iter 41000, loss: 0.058805
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058776
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058773
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058798
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058147
 >> iter 53000, loss: 0.058785
 >> iter 54000, loss: 0.058218
 >> iter 55000, loss: 0.058768
 >> iter 56000, loss: 0.058228
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058198
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058221
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058821
 >> iter 64000, loss: 0.058195
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058207
 >> iter 67000, loss: 0.058796
 >> iter 68000, loss: 0.058254
 >> iter 69000, loss: 0.058799
 >> iter 70000, loss: 0.058219
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058248
 >> iter 73000, loss: 0.058800
 >> iter 74000, loss: 0.058230
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058206
   Number of active neurons: 1
 >> iter 81000, loss: 0.058907
 >> iter 82000, loss: 0.058212
 >> iter 83000, loss: 0.058947
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058930
 >> iter 86000, loss: 0.058188
 >> iter 87000, loss: 0.058933
 >> iter 88000, loss: 0.058181
 >> iter 89000, loss: 0.058912
 >> iter 90000, loss: 0.058205
   Number of active neurons: 1
 >> iter 91000, loss: 0.058911
 >> iter 92000, loss: 0.058223
 >> iter 93000, loss: 0.058931
 >> iter 94000, loss: 0.058201
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058187
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058171
 >> iter 99000, loss: 0.059019
 >> iter 100000, loss: 0.058235
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.851976
 >> iter 2000, loss: 4.045885
 >> iter 3000, loss: 1.539150
 >> iter 4000, loss: 0.615470
 >> iter 5000, loss: 0.275790
 >> iter 6000, loss: 0.146169
 >> iter 7000, loss: 0.095451
 >> iter 8000, loss: 0.074380
 >> iter 9000, loss: 0.066663
 >> iter 10000, loss: 0.062433
   Number of active neurons: 1
 >> iter 11000, loss: 0.061396
 >> iter 12000, loss: 0.059827
 >> iter 13000, loss: 0.060005
 >> iter 14000, loss: 0.058952
 >> iter 15000, loss: 0.059434
 >> iter 16000, loss: 0.058571
 >> iter 17000, loss: 0.059160
 >> iter 18000, loss: 0.058392
 >> iter 19000, loss: 0.059004
 >> iter 20000, loss: 0.058323
   Number of active neurons: 1
 >> iter 21000, loss: 0.058942
 >> iter 22000, loss: 0.058247
 >> iter 23000, loss: 0.058904
 >> iter 24000, loss: 0.058193
 >> iter 25000, loss: 0.058888
 >> iter 26000, loss: 0.058206
 >> iter 27000, loss: 0.058877
 >> iter 28000, loss: 0.058206
 >> iter 29000, loss: 0.058845
 >> iter 30000, loss: 0.058173
   Number of active neurons: 1
 >> iter 31000, loss: 0.058827
 >> iter 32000, loss: 0.058148
 >> iter 33000, loss: 0.058802
 >> iter 34000, loss: 0.058136
 >> iter 35000, loss: 0.058829
 >> iter 36000, loss: 0.058120
 >> iter 37000, loss: 0.058817
 >> iter 38000, loss: 0.058096
 >> iter 39000, loss: 0.058824
 >> iter 40000, loss: 0.058085
   Number of active neurons: 1
 >> iter 41000, loss: 0.058804
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058776
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058773
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058798
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058801
 >> iter 52000, loss: 0.058147
 >> iter 53000, loss: 0.058785
 >> iter 54000, loss: 0.058218
 >> iter 55000, loss: 0.058768
 >> iter 56000, loss: 0.058228
 >> iter 57000, loss: 0.058813
 >> iter 58000, loss: 0.058198
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058221
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058821
 >> iter 64000, loss: 0.058195
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058207
 >> iter 67000, loss: 0.058796
 >> iter 68000, loss: 0.058254
 >> iter 69000, loss: 0.058799
 >> iter 70000, loss: 0.058218
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058247
 >> iter 73000, loss: 0.058800
 >> iter 74000, loss: 0.058230
 >> iter 75000, loss: 0.058803
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058847
 >> iter 80000, loss: 0.058206
   Number of active neurons: 1
 >> iter 81000, loss: 0.058907
 >> iter 82000, loss: 0.058212
 >> iter 83000, loss: 0.058948
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058930
 >> iter 86000, loss: 0.058187
 >> iter 87000, loss: 0.058933
 >> iter 88000, loss: 0.058181
 >> iter 89000, loss: 0.058911
 >> iter 90000, loss: 0.058205
   Number of active neurons: 1
 >> iter 91000, loss: 0.058912
 >> iter 92000, loss: 0.058223
 >> iter 93000, loss: 0.058931
 >> iter 94000, loss: 0.058201
 >> iter 95000, loss: 0.058992
 >> iter 96000, loss: 0.058187
 >> iter 97000, loss: 0.059006
 >> iter 98000, loss: 0.058171
 >> iter 99000, loss: 0.059019
 >> iter 100000, loss: 0.058234
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.905703
 >> iter 2000, loss: 4.064943
 >> iter 3000, loss: 1.546123
 >> iter 4000, loss: 0.617963
 >> iter 5000, loss: 0.275905
 >> iter 6000, loss: 0.144570
 >> iter 7000, loss: 0.094168
 >> iter 8000, loss: 0.073601
 >> iter 9000, loss: 0.066191
 >> iter 10000, loss: 0.062132
   Number of active neurons: 1
 >> iter 11000, loss: 0.061193
 >> iter 12000, loss: 0.059686
 >> iter 13000, loss: 0.059903
 >> iter 14000, loss: 0.058879
 >> iter 15000, loss: 0.059380
 >> iter 16000, loss: 0.058531
 >> iter 17000, loss: 0.059132
 >> iter 18000, loss: 0.058372
 >> iter 19000, loss: 0.058989
 >> iter 20000, loss: 0.058312
   Number of active neurons: 1
 >> iter 21000, loss: 0.058933
 >> iter 22000, loss: 0.058241
 >> iter 23000, loss: 0.058899
 >> iter 24000, loss: 0.058190
 >> iter 25000, loss: 0.058885
 >> iter 26000, loss: 0.058204
 >> iter 27000, loss: 0.058875
 >> iter 28000, loss: 0.058205
 >> iter 29000, loss: 0.058845
 >> iter 30000, loss: 0.058172
   Number of active neurons: 1
 >> iter 31000, loss: 0.058827
 >> iter 32000, loss: 0.058148
 >> iter 33000, loss: 0.058802
 >> iter 34000, loss: 0.058136
 >> iter 35000, loss: 0.058829
 >> iter 36000, loss: 0.058120
 >> iter 37000, loss: 0.058818
 >> iter 38000, loss: 0.058096
 >> iter 39000, loss: 0.058823
 >> iter 40000, loss: 0.058085
   Number of active neurons: 1
 >> iter 41000, loss: 0.058804
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058776
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058773
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058798
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058801
 >> iter 52000, loss: 0.058147
 >> iter 53000, loss: 0.058785
 >> iter 54000, loss: 0.058218
 >> iter 55000, loss: 0.058768
 >> iter 56000, loss: 0.058228
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058198
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058221
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058821
 >> iter 64000, loss: 0.058195
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058207
 >> iter 67000, loss: 0.058796
 >> iter 68000, loss: 0.058254
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058218
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058247
 >> iter 73000, loss: 0.058800
 >> iter 74000, loss: 0.058230
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058206
   Number of active neurons: 1
 >> iter 81000, loss: 0.058907
 >> iter 82000, loss: 0.058212
 >> iter 83000, loss: 0.058948
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058930
 >> iter 86000, loss: 0.058187
 >> iter 87000, loss: 0.058933
 >> iter 88000, loss: 0.058181
 >> iter 89000, loss: 0.058912
 >> iter 90000, loss: 0.058205
   Number of active neurons: 1
 >> iter 91000, loss: 0.058911
 >> iter 92000, loss: 0.058223
 >> iter 93000, loss: 0.058931
 >> iter 94000, loss: 0.058201
 >> iter 95000, loss: 0.058992
 >> iter 96000, loss: 0.058187
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058171
 >> iter 99000, loss: 0.059019
 >> iter 100000, loss: 0.058234
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.868377
 >> iter 2000, loss: 4.048357
 >> iter 3000, loss: 1.532615
 >> iter 4000, loss: 0.604194
 >> iter 5000, loss: 0.262368
 >> iter 6000, loss: 0.135169
 >> iter 7000, loss: 0.088630
 >> iter 8000, loss: 0.070312
 >> iter 9000, loss: 0.064112
 >> iter 10000, loss: 0.060745
   Number of active neurons: 1
 >> iter 11000, loss: 0.060224
 >> iter 12000, loss: 0.058998
 >> iter 13000, loss: 0.059405
 >> iter 14000, loss: 0.058518
 >> iter 15000, loss: 0.059116
 >> iter 16000, loss: 0.058339
 >> iter 17000, loss: 0.058991
 >> iter 18000, loss: 0.058268
 >> iter 19000, loss: 0.058913
 >> iter 20000, loss: 0.058257
   Number of active neurons: 1
 >> iter 21000, loss: 0.058892
 >> iter 22000, loss: 0.058212
 >> iter 23000, loss: 0.058878
 >> iter 24000, loss: 0.058174
 >> iter 25000, loss: 0.058873
 >> iter 26000, loss: 0.058195
 >> iter 27000, loss: 0.058869
 >> iter 28000, loss: 0.058200
 >> iter 29000, loss: 0.058841
 >> iter 30000, loss: 0.058170
   Number of active neurons: 1
 >> iter 31000, loss: 0.058825
 >> iter 32000, loss: 0.058146
 >> iter 33000, loss: 0.058801
 >> iter 34000, loss: 0.058135
 >> iter 35000, loss: 0.058829
 >> iter 36000, loss: 0.058120
 >> iter 37000, loss: 0.058817
 >> iter 38000, loss: 0.058095
 >> iter 39000, loss: 0.058824
 >> iter 40000, loss: 0.058085
   Number of active neurons: 1
 >> iter 41000, loss: 0.058804
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058776
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058773
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058798
 >> iter 50000, loss: 0.058117
   Number of active neurons: 1
 >> iter 51000, loss: 0.058801
 >> iter 52000, loss: 0.058147
 >> iter 53000, loss: 0.058785
 >> iter 54000, loss: 0.058219
 >> iter 55000, loss: 0.058768
 >> iter 56000, loss: 0.058227
 >> iter 57000, loss: 0.058813
 >> iter 58000, loss: 0.058199
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058220
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058231
 >> iter 63000, loss: 0.058821
 >> iter 64000, loss: 0.058194
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058208
 >> iter 67000, loss: 0.058796
 >> iter 68000, loss: 0.058253
 >> iter 69000, loss: 0.058799
 >> iter 70000, loss: 0.058219
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058246
 >> iter 73000, loss: 0.058800
 >> iter 74000, loss: 0.058231
 >> iter 75000, loss: 0.058803
 >> iter 76000, loss: 0.058229
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058196
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058205
   Number of active neurons: 1
 >> iter 81000, loss: 0.058907
 >> iter 82000, loss: 0.058213
 >> iter 83000, loss: 0.058947
 >> iter 84000, loss: 0.058204
 >> iter 85000, loss: 0.058930
 >> iter 86000, loss: 0.058188
 >> iter 87000, loss: 0.058933
 >> iter 88000, loss: 0.058180
 >> iter 89000, loss: 0.058912
 >> iter 90000, loss: 0.058206
   Number of active neurons: 1
 >> iter 91000, loss: 0.058911
 >> iter 92000, loss: 0.058222
 >> iter 93000, loss: 0.058931
 >> iter 94000, loss: 0.058202
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058187
 >> iter 97000, loss: 0.059006
 >> iter 98000, loss: 0.058172
 >> iter 99000, loss: 0.059019
 >> iter 100000, loss: 0.058234
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.982501
 >> iter 2000, loss: 4.098478
 >> iter 3000, loss: 1.563515
 >> iter 4000, loss: 0.626055
 >> iter 5000, loss: 0.279709
 >> iter 6000, loss: 0.146601
 >> iter 7000, loss: 0.095228
 >> iter 8000, loss: 0.074181
 >> iter 9000, loss: 0.066543
 >> iter 10000, loss: 0.062363
   Number of active neurons: 1
 >> iter 11000, loss: 0.061355
 >> iter 12000, loss: 0.059802
 >> iter 13000, loss: 0.059989
 >> iter 14000, loss: 0.058941
 >> iter 15000, loss: 0.059425
 >> iter 16000, loss: 0.058565
 >> iter 17000, loss: 0.059157
 >> iter 18000, loss: 0.058390
 >> iter 19000, loss: 0.059002
 >> iter 20000, loss: 0.058322
   Number of active neurons: 1
 >> iter 21000, loss: 0.058940
 >> iter 22000, loss: 0.058247
 >> iter 23000, loss: 0.058904
 >> iter 24000, loss: 0.058192
 >> iter 25000, loss: 0.058887
 >> iter 26000, loss: 0.058205
 >> iter 27000, loss: 0.058876
 >> iter 28000, loss: 0.058206
 >> iter 29000, loss: 0.058846
 >> iter 30000, loss: 0.058172
   Number of active neurons: 1
 >> iter 31000, loss: 0.058826
 >> iter 32000, loss: 0.058148
 >> iter 33000, loss: 0.058803
 >> iter 34000, loss: 0.058136
 >> iter 35000, loss: 0.058828
 >> iter 36000, loss: 0.058121
 >> iter 37000, loss: 0.058818
 >> iter 38000, loss: 0.058095
 >> iter 39000, loss: 0.058823
 >> iter 40000, loss: 0.058086
   Number of active neurons: 1
 >> iter 41000, loss: 0.058805
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058775
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058786
 >> iter 46000, loss: 0.058104
 >> iter 47000, loss: 0.058772
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058799
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058147
 >> iter 53000, loss: 0.058786
 >> iter 54000, loss: 0.058219
 >> iter 55000, loss: 0.058767
 >> iter 56000, loss: 0.058228
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058198
 >> iter 59000, loss: 0.058824
 >> iter 60000, loss: 0.058220
   Number of active neurons: 1
 >> iter 61000, loss: 0.058807
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058820
 >> iter 64000, loss: 0.058195
 >> iter 65000, loss: 0.058821
 >> iter 66000, loss: 0.058207
 >> iter 67000, loss: 0.058795
 >> iter 68000, loss: 0.058253
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058219
   Number of active neurons: 1
 >> iter 71000, loss: 0.058796
 >> iter 72000, loss: 0.058247
 >> iter 73000, loss: 0.058801
 >> iter 74000, loss: 0.058231
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058786
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058845
 >> iter 80000, loss: 0.058206
   Number of active neurons: 1
 >> iter 81000, loss: 0.058908
 >> iter 82000, loss: 0.058212
 >> iter 83000, loss: 0.058946
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058931
 >> iter 86000, loss: 0.058188
 >> iter 87000, loss: 0.058932
 >> iter 88000, loss: 0.058180
 >> iter 89000, loss: 0.058913
 >> iter 90000, loss: 0.058205
   Number of active neurons: 1
 >> iter 91000, loss: 0.058910
 >> iter 92000, loss: 0.058223
 >> iter 93000, loss: 0.058932
 >> iter 94000, loss: 0.058201
 >> iter 95000, loss: 0.058990
 >> iter 96000, loss: 0.058187
 >> iter 97000, loss: 0.059008
 >> iter 98000, loss: 0.058171
 >> iter 99000, loss: 0.059018
 >> iter 100000, loss: 0.058234
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.819661
 >> iter 2000, loss: 4.037133
 >> iter 3000, loss: 1.535983
 >> iter 4000, loss: 0.611643
 >> iter 5000, loss: 0.272324
 >> iter 6000, loss: 0.145884
 >> iter 7000, loss: 0.100573
 >> iter 8000, loss: 0.082573
 >> iter 9000, loss: 0.077425
 >> iter 10000, loss: 0.074389
   Number of active neurons: 2
 >> iter 11000, loss: 0.074769
 >> iter 12000, loss: 0.074031
 >> iter 13000, loss: 0.075325
 >> iter 14000, loss: 0.074769
 >> iter 15000, loss: 0.076159
 >> iter 16000, loss: 0.075706
 >> iter 17000, loss: 0.077024
 >> iter 18000, loss: 0.076232
 >> iter 19000, loss: 0.075131
 >> iter 20000, loss: 0.069436
   Number of active neurons: 1
 >> iter 21000, loss: 0.065967
 >> iter 22000, loss: 0.062779
 >> iter 23000, loss: 0.061963
 >> iter 24000, loss: 0.060317
 >> iter 25000, loss: 0.060403
 >> iter 26000, loss: 0.059293
 >> iter 27000, loss: 0.059668
 >> iter 28000, loss: 0.058780
 >> iter 29000, loss: 0.059266
 >> iter 30000, loss: 0.058479
   Number of active neurons: 1
 >> iter 31000, loss: 0.059052
 >> iter 32000, loss: 0.058312
 >> iter 33000, loss: 0.058923
 >> iter 34000, loss: 0.058224
 >> iter 35000, loss: 0.058894
 >> iter 36000, loss: 0.058167
 >> iter 37000, loss: 0.058852
 >> iter 38000, loss: 0.058121
 >> iter 39000, loss: 0.058843
 >> iter 40000, loss: 0.058099
   Number of active neurons: 1
 >> iter 41000, loss: 0.058814
 >> iter 42000, loss: 0.058105
 >> iter 43000, loss: 0.058781
 >> iter 44000, loss: 0.058115
 >> iter 45000, loss: 0.058788
 >> iter 46000, loss: 0.058107
 >> iter 47000, loss: 0.058774
 >> iter 48000, loss: 0.058125
 >> iter 49000, loss: 0.058799
 >> iter 50000, loss: 0.058117
   Number of active neurons: 1
 >> iter 51000, loss: 0.058801
 >> iter 52000, loss: 0.058147
 >> iter 53000, loss: 0.058786
 >> iter 54000, loss: 0.058219
 >> iter 55000, loss: 0.058768
 >> iter 56000, loss: 0.058228
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058199
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058220
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058821
 >> iter 64000, loss: 0.058195
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058208
 >> iter 67000, loss: 0.058796
 >> iter 68000, loss: 0.058253
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058219
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058247
 >> iter 73000, loss: 0.058801
 >> iter 74000, loss: 0.058231
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058206
   Number of active neurons: 1
 >> iter 81000, loss: 0.058908
 >> iter 82000, loss: 0.058212
 >> iter 83000, loss: 0.058947
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058930
 >> iter 86000, loss: 0.058188
 >> iter 87000, loss: 0.058933
 >> iter 88000, loss: 0.058180
 >> iter 89000, loss: 0.058912
 >> iter 90000, loss: 0.058206
   Number of active neurons: 1
 >> iter 91000, loss: 0.058911
 >> iter 92000, loss: 0.058223
 >> iter 93000, loss: 0.058932
 >> iter 94000, loss: 0.058202
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058187
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058172
 >> iter 99000, loss: 0.059019
 >> iter 100000, loss: 0.058234
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.892424
 >> iter 2000, loss: 4.063053
 >> iter 3000, loss: 1.546790
 >> iter 4000, loss: 0.616565
 >> iter 5000, loss: 0.274778
 >> iter 6000, loss: 0.147742
 >> iter 7000, loss: 0.102219
 >> iter 8000, loss: 0.084685
 >> iter 9000, loss: 0.079603
 >> iter 10000, loss: 0.076843
   Number of active neurons: 2
 >> iter 11000, loss: 0.077259
 >> iter 12000, loss: 0.076450
 >> iter 13000, loss: 0.077288
 >> iter 14000, loss: 0.074835
 >> iter 15000, loss: 0.070658
 >> iter 16000, loss: 0.065601
 >> iter 17000, loss: 0.063665
 >> iter 18000, loss: 0.061393
 >> iter 19000, loss: 0.061088
 >> iter 20000, loss: 0.059797
   Number of active neurons: 1
 >> iter 21000, loss: 0.060004
 >> iter 22000, loss: 0.059015
 >> iter 23000, loss: 0.059464
 >> iter 24000, loss: 0.058600
 >> iter 25000, loss: 0.059186
 >> iter 26000, loss: 0.058423
 >> iter 27000, loss: 0.059036
 >> iter 28000, loss: 0.058323
 >> iter 29000, loss: 0.058931
 >> iter 30000, loss: 0.058236
   Number of active neurons: 1
 >> iter 31000, loss: 0.058873
 >> iter 32000, loss: 0.058182
 >> iter 33000, loss: 0.058827
 >> iter 34000, loss: 0.058154
 >> iter 35000, loss: 0.058842
 >> iter 36000, loss: 0.058131
 >> iter 37000, loss: 0.058825
 >> iter 38000, loss: 0.058100
 >> iter 39000, loss: 0.058827
 >> iter 40000, loss: 0.058089
   Number of active neurons: 1
 >> iter 41000, loss: 0.058807
 >> iter 42000, loss: 0.058099
 >> iter 43000, loss: 0.058776
 >> iter 44000, loss: 0.058112
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058773
 >> iter 48000, loss: 0.058125
 >> iter 49000, loss: 0.058798
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058148
 >> iter 53000, loss: 0.058785
 >> iter 54000, loss: 0.058218
 >> iter 55000, loss: 0.058768
 >> iter 56000, loss: 0.058229
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058198
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058221
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058820
 >> iter 64000, loss: 0.058196
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058207
 >> iter 67000, loss: 0.058795
 >> iter 68000, loss: 0.058254
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058219
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058248
 >> iter 73000, loss: 0.058800
 >> iter 74000, loss: 0.058230
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058231
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058845
 >> iter 80000, loss: 0.058207
   Number of active neurons: 1
 >> iter 81000, loss: 0.058908
 >> iter 82000, loss: 0.058212
 >> iter 83000, loss: 0.058946
 >> iter 84000, loss: 0.058206
 >> iter 85000, loss: 0.058931
 >> iter 86000, loss: 0.058187
 >> iter 87000, loss: 0.058932
 >> iter 88000, loss: 0.058181
 >> iter 89000, loss: 0.058912
 >> iter 90000, loss: 0.058205
   Number of active neurons: 1
 >> iter 91000, loss: 0.058910
 >> iter 92000, loss: 0.058224
 >> iter 93000, loss: 0.058932
 >> iter 94000, loss: 0.058201
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058188
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058171
 >> iter 99000, loss: 0.059018
 >> iter 100000, loss: 0.058235
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.643843
 >> iter 2000, loss: 13.889908
 >> iter 3000, loss: 12.640979
 >> iter 4000, loss: 12.050337
 >> iter 5000, loss: 11.959945
 >> iter 6000, loss: 11.800730
 >> iter 7000, loss: 11.874594
 >> iter 8000, loss: 11.764637
 >> iter 9000, loss: 11.869667
 >> iter 10000, loss: 11.754222
   Number of active neurons: 0
 >> iter 11000, loss: 11.868697
 >> iter 12000, loss: 11.745830
 >> iter 13000, loss: 11.872263
 >> iter 14000, loss: 11.741379
 >> iter 15000, loss: 11.869900
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 11.740684
 >> iter 17000, loss: 11.869047
 >> iter 18000, loss: 11.749229
 >> iter 19000, loss: 11.863583
 >> iter 20000, loss: 11.755475
   Number of active neurons: 0
 >> iter 21000, loss: 11.867532
 >> iter 22000, loss: 11.751387
 >> iter 23000, loss: 11.869776
 >> iter 24000, loss: 11.743824
 >> iter 25000, loss: 11.870449
   Number of active neurons: 0
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 26000, loss: 11.746653
 >> iter 27000, loss: 11.869609
 >> iter 28000, loss: 11.749369
 >> iter 29000, loss: 11.864215
 >> iter 30000, loss: 11.741868
   Number of active neurons: 0
 >> iter 31000, loss: 11.861762
 >> iter 32000, loss: 11.737607
 >> iter 33000, loss: 11.854445
 >> iter 34000, loss: 11.744082
 >> iter 35000, loss: 11.858672
   Number of active neurons: 0
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 36000, loss: 11.739917
 >> iter 37000, loss: 11.857806
 >> iter 38000, loss: 11.735691
 >> iter 39000, loss: 11.858576
 >> iter 40000, loss: 11.736750
   Number of active neurons: 0
 >> iter 41000, loss: 11.852862
 >> iter 42000, loss: 11.737772
 >> iter 43000, loss: 11.846965
 >> iter 44000, loss: 11.742211
 >> iter 45000, loss: 11.846121
   Number of active neurons: 0
   SHOCK
   Setting new limit to 287500.0 iters...
 >> iter 46000, loss: 11.739800
 >> iter 47000, loss: 11.843543
 >> iter 48000, loss: 11.744093
 >> iter 49000, loss: 11.849695
 >> iter 50000, loss: 11.743343
   Number of active neurons: 0
 >> iter 51000, loss: 11.852161
 >> iter 52000, loss: 11.752327
 >> iter 53000, loss: 11.849680
 >> iter 54000, loss: 11.765299
 >> iter 55000, loss: 11.845535
   Number of active neurons: 0
   SHOCK
   Setting new limit to 293750.0 iters...
 >> iter 56000, loss: 11.763201
 >> iter 57000, loss: 11.853107
 >> iter 58000, loss: 11.758121
 >> iter 59000, loss: 11.858596
 >> iter 60000, loss: 11.763517
   Number of active neurons: 0
 >> iter 61000, loss: 11.853237
 >> iter 62000, loss: 11.762811
 >> iter 63000, loss: 11.863451
 >> iter 64000, loss: 11.756194
 >> iter 65000, loss: 11.862634
   Number of active neurons: 0
   SHOCK
   Setting new limit to 296875.0 iters...
 >> iter 66000, loss: 11.757012
 >> iter 67000, loss: 11.857330
 >> iter 68000, loss: 11.767152
 >> iter 69000, loss: 11.858044
 >> iter 70000, loss: 11.760629
   Number of active neurons: 0
 >> iter 71000, loss: 11.857198
 >> iter 72000, loss: 11.769180
 >> iter 73000, loss: 11.856348
 >> iter 74000, loss: 11.762677
 >> iter 75000, loss: 11.855499
   Number of active neurons: 0
   SHOCK
   Setting new limit to 298437.5 iters...
 >> iter 76000, loss: 11.761930
 >> iter 77000, loss: 11.851504
 >> iter 78000, loss: 11.754967
 >> iter 79000, loss: 11.861973
 >> iter 80000, loss: 11.757483
   Number of active neurons: 0
 >> iter 81000, loss: 11.876318
 >> iter 82000, loss: 11.763131
 >> iter 83000, loss: 11.881208
 >> iter 84000, loss: 11.762390
 >> iter 85000, loss: 11.877772
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299218.75 iters...
 >> iter 86000, loss: 11.760110
 >> iter 87000, loss: 11.876988
 >> iter 88000, loss: 11.760921
 >> iter 89000, loss: 11.873320
 >> iter 90000, loss: 11.766372
   Number of active neurons: 0
 >> iter 91000, loss: 11.873979
 >> iter 92000, loss: 11.768609
 >> iter 93000, loss: 11.876116
 >> iter 94000, loss: 11.763557
 >> iter 95000, loss: 11.885496
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299609.375 iters...
 >> iter 96000, loss: 11.756714
 >> iter 97000, loss: 11.883410
 >> iter 98000, loss: 11.754338
 >> iter 99000, loss: 11.886833
 >> iter 100000, loss: 11.771590
   Number of active neurons: 0
 >> iter 101000, loss: 11.888816
 >> iter 102000, loss: 11.775449
 >> iter 103000, loss: 11.885424
 >> iter 104000, loss: 11.777689
 >> iter 105000, loss: 11.884645
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299804.6875 iters...
 >> iter 106000, loss: 11.776973
 >> iter 107000, loss: 11.881006
 >> iter 108000, loss: 11.777723
 >> iter 109000, loss: 11.875735
 >> iter 110000, loss: 11.785796
   Number of active neurons: 0
 >> iter 111000, loss: 11.873318
 >> iter 112000, loss: 11.797450
 >> iter 113000, loss: 11.869289
 >> iter 114000, loss: 11.791862
 >> iter 115000, loss: 11.863538
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299902.34375 iters...
 >> iter 116000, loss: 11.791215
 >> iter 117000, loss: 11.864354
 >> iter 118000, loss: 11.794708
 >> iter 119000, loss: 11.868476
 >> iter 120000, loss: 11.790036
   Number of active neurons: 0
 >> iter 121000, loss: 11.870815
 >> iter 122000, loss: 11.786469
 >> iter 123000, loss: 11.868382
 >> iter 124000, loss: 11.784239
 >> iter 125000, loss: 11.861134
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299951.171875 iters...
 >> iter 126000, loss: 11.781960
 >> iter 127000, loss: 11.865301
 >> iter 128000, loss: 11.790485
 >> iter 129000, loss: 11.867668
 >> iter 130000, loss: 11.791214
   Number of active neurons: 0
 >> iter 131000, loss: 11.871541
 >> iter 132000, loss: 11.799159
 >> iter 133000, loss: 11.872219
 >> iter 134000, loss: 11.801218
 >> iter 135000, loss: 11.872888
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299975.585938 iters...
 >> iter 136000, loss: 11.796623
 >> iter 137000, loss: 11.872047
 >> iter 138000, loss: 11.793100
 >> iter 139000, loss: 11.884845
 >> iter 140000, loss: 11.789418
   Number of active neurons: 0
 >> iter 141000, loss: 11.879811
 >> iter 142000, loss: 11.785607
 >> iter 143000, loss: 11.874488
 >> iter 144000, loss: 11.786398
 >> iter 145000, loss: 11.878315
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299987.792969 iters...
 >> iter 146000, loss: 11.782501
 >> iter 147000, loss: 11.872931
 >> iter 148000, loss: 11.780109
 >> iter 149000, loss: 11.878389
 >> iter 150000, loss: 11.779324
   Number of active neurons: 0
 >> iter 151000, loss: 11.880558
 >> iter 152000, loss: 11.773642
 >> iter 153000, loss: 11.878247
 >> iter 154000, loss: 11.767782
 >> iter 155000, loss: 11.875887
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299993.896484 iters...
 >> iter 156000, loss: 11.774025
 >> iter 157000, loss: 11.870404
 >> iter 158000, loss: 11.771577
 >> iter 159000, loss: 11.871138
 >> iter 160000, loss: 11.770798
   Number of active neurons: 0
 >> iter 161000, loss: 11.871858
 >> iter 162000, loss: 11.781798
 >> iter 163000, loss: 11.883606
 >> iter 164000, loss: 11.784186
 >> iter 165000, loss: 11.887206
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299996.948242 iters...
 >> iter 166000, loss: 11.789605
 >> iter 167000, loss: 11.884972
 >> iter 168000, loss: 11.790342
 >> iter 169000, loss: 11.881209
 >> iter 170000, loss: 11.788137
   Number of active neurons: 0
 >> iter 171000, loss: 11.883393
 >> iter 172000, loss: 11.787382
 >> iter 173000, loss: 11.878080
 >> iter 174000, loss: 11.795702
 >> iter 175000, loss: 11.878771
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299998.474121 iters...
 >> iter 176000, loss: 11.796419
 >> iter 177000, loss: 11.874807
 >> iter 178000, loss: 11.804190
 >> iter 179000, loss: 11.875528
 >> iter 180000, loss: 11.802286
   Number of active neurons: 0
 >> iter 181000, loss: 11.874656
 >> iter 182000, loss: 11.807066
 >> iter 183000, loss: 11.876954
 >> iter 184000, loss: 11.805186
 >> iter 185000, loss: 11.882291
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.237061 iters...
 >> iter 186000, loss: 11.801855
 >> iter 187000, loss: 11.877024
 >> iter 188000, loss: 11.801153
 >> iter 189000, loss: 11.877708
 >> iter 190000, loss: 11.797581
   Number of active neurons: 0
 >> iter 191000, loss: 11.878385
 >> iter 192000, loss: 11.802767
 >> iter 193000, loss: 11.879055
 >> iter 194000, loss: 11.799225
 >> iter 195000, loss: 11.875170
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.61853 iters...
 >> iter 196000, loss: 11.798475
 >> iter 197000, loss: 11.874301
 >> iter 198000, loss: 11.793256
 >> iter 199000, loss: 11.873430
 >> iter 200000, loss: 11.789351
   Number of active neurons: 0
 >> iter 201000, loss: 11.872559
 >> iter 202000, loss: 11.785345
 >> iter 203000, loss: 11.870106
 >> iter 204000, loss: 11.777951
 >> iter 205000, loss: 11.867621
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.809265 iters...
 >> iter 206000, loss: 11.773711
 >> iter 207000, loss: 11.865116
 >> iter 208000, loss: 11.772949
 >> iter 209000, loss: 11.865894
 >> iter 210000, loss: 11.780979
   Number of active neurons: 0
 >> iter 211000, loss: 11.861753
 >> iter 212000, loss: 11.776873
 >> iter 213000, loss: 11.862560
 >> iter 214000, loss: 11.779488
 >> iter 215000, loss: 11.861689
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.904633 iters...
 >> iter 216000, loss: 11.788638
 >> iter 217000, loss: 11.859165
 >> iter 218000, loss: 11.792528
 >> iter 219000, loss: 11.870025
 >> iter 220000, loss: 11.793272
   Number of active neurons: 0
 >> iter 221000, loss: 11.869158
 >> iter 222000, loss: 11.786541
 >> iter 223000, loss: 11.865129
 >> iter 224000, loss: 11.782582
 >> iter 225000, loss: 11.861004
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.952316 iters...
 >> iter 226000, loss: 11.785055
 >> iter 227000, loss: 11.866810
 >> iter 228000, loss: 11.785862
 >> iter 229000, loss: 11.864355
 >> iter 230000, loss: 11.789809
   Number of active neurons: 0
 >> iter 231000, loss: 11.861874
 >> iter 232000, loss: 11.796659
 >> iter 233000, loss: 11.857732
 >> iter 234000, loss: 11.793079
 >> iter 235000, loss: 11.853511
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.976158 iters...
 >> iter 236000, loss: 11.790840
 >> iter 237000, loss: 11.859520
 >> iter 238000, loss: 11.797676
 >> iter 239000, loss: 11.857022
 >> iter 240000, loss: 11.794101
   Number of active neurons: 0
 >> iter 241000, loss: 11.851194
 >> iter 242000, loss: 11.799298
 >> iter 243000, loss: 11.853767
 >> iter 244000, loss: 11.807107
 >> iter 245000, loss: 11.856248
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.988079 iters...
 >> iter 246000, loss: 11.813097
 >> iter 247000, loss: 11.858642
 >> iter 248000, loss: 11.808855
 >> iter 249000, loss: 11.865743
 >> iter 250000, loss: 11.808224
   Number of active neurons: 0
 >> iter 251000, loss: 11.864915
 >> iter 252000, loss: 11.807568
 >> iter 253000, loss: 11.868606
 >> iter 254000, loss: 11.809653
 >> iter 255000, loss: 11.867798
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99404 iters...
 >> iter 256000, loss: 11.810356
 >> iter 257000, loss: 11.864037
 >> iter 258000, loss: 11.809692
 >> iter 259000, loss: 11.867773
 >> iter 260000, loss: 11.818711
   Number of active neurons: 0
 >> iter 261000, loss: 11.871381
 >> iter 262000, loss: 11.816850
 >> iter 263000, loss: 11.879165
 >> iter 264000, loss: 11.821551
 >> iter 265000, loss: 11.878474
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99702 iters...
 >> iter 266000, loss: 11.819707
 >> iter 267000, loss: 11.880462
 >> iter 268000, loss: 11.824386
 >> iter 269000, loss: 11.878426
 >> iter 270000, loss: 11.818735
   Number of active neurons: 0
 >> iter 271000, loss: 11.873536
 >> iter 272000, loss: 11.815311
 >> iter 273000, loss: 11.872724
 >> iter 274000, loss: 11.813142
 >> iter 275000, loss: 11.871902
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99851 iters...
 >> iter 276000, loss: 11.812382
 >> iter 277000, loss: 11.866609
 >> iter 278000, loss: 11.817550
 >> iter 279000, loss: 11.871990
 >> iter 280000, loss: 11.813994
   Number of active neurons: 0
 >> iter 281000, loss: 11.880081
 >> iter 282000, loss: 11.807339
 >> iter 283000, loss: 11.884872
 >> iter 284000, loss: 11.817505
 >> iter 285000, loss: 11.886830
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999255 iters...
 >> iter 286000, loss: 11.810876
 >> iter 287000, loss: 11.883532
 >> iter 288000, loss: 11.813195
 >> iter 289000, loss: 11.885535
 >> iter 290000, loss: 11.809347
   Number of active neurons: 0
 >> iter 291000, loss: 11.887518
 >> iter 292000, loss: 11.808541
 >> iter 293000, loss: 11.885465
 >> iter 294000, loss: 11.806153
 >> iter 295000, loss: 11.886090
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999627 iters...
 >> iter 296000, loss: 11.800522
 >> iter 297000, loss: 11.885330
 >> iter 298000, loss: 11.796372
 >> iter 299000, loss: 11.880336
 >> iter 300000, loss: 11.800701
   Number of active neurons: 0
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 18.1216375672
   - Test - Long: 1.72491375431
   - Test - Big: 18.3068169318
   - Test - A: 48.5100993267
   - Test - B: 1.21991867209
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.851732
 >> iter 2000, loss: 4.046735
 >> iter 3000, loss: 1.538836
 >> iter 4000, loss: 0.610018
 >> iter 5000, loss: 0.265886
 >> iter 6000, loss: 0.137189
 >> iter 7000, loss: 0.089857
 >> iter 8000, loss: 0.071109
 >> iter 9000, loss: 0.064661
 >> iter 10000, loss: 0.061134
   Number of active neurons: 1
 >> iter 11000, loss: 0.060506
 >> iter 12000, loss: 0.059202
 >> iter 13000, loss: 0.059555
 >> iter 14000, loss: 0.058627
 >> iter 15000, loss: 0.059196
 >> iter 16000, loss: 0.058398
 >> iter 17000, loss: 0.059034
 >> iter 18000, loss: 0.058300
 >> iter 19000, loss: 0.058936
 >> iter 20000, loss: 0.058274
   Number of active neurons: 1
 >> iter 21000, loss: 0.058905
 >> iter 22000, loss: 0.058221
 >> iter 23000, loss: 0.058885
 >> iter 24000, loss: 0.058178
 >> iter 25000, loss: 0.058876
 >> iter 26000, loss: 0.058198
 >> iter 27000, loss: 0.058871
 >> iter 28000, loss: 0.058202
 >> iter 29000, loss: 0.058842
 >> iter 30000, loss: 0.058171
   Number of active neurons: 1
 >> iter 31000, loss: 0.058825
 >> iter 32000, loss: 0.058147
 >> iter 33000, loss: 0.058801
 >> iter 34000, loss: 0.058136
 >> iter 35000, loss: 0.058828
 >> iter 36000, loss: 0.058120
 >> iter 37000, loss: 0.058817
 >> iter 38000, loss: 0.058096
 >> iter 39000, loss: 0.058823
 >> iter 40000, loss: 0.058085
   Number of active neurons: 1
 >> iter 41000, loss: 0.058804
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058775
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058772
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058798
 >> iter 50000, loss: 0.058117
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058147
 >> iter 53000, loss: 0.058785
 >> iter 54000, loss: 0.058219
 >> iter 55000, loss: 0.058767
 >> iter 56000, loss: 0.058228
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058199
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058220
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058231
 >> iter 63000, loss: 0.058820
 >> iter 64000, loss: 0.058195
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058208
 >> iter 67000, loss: 0.058795
 >> iter 68000, loss: 0.058253
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058220
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058247
 >> iter 73000, loss: 0.058800
 >> iter 74000, loss: 0.058231
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058196
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058206
   Number of active neurons: 1
 >> iter 81000, loss: 0.058907
 >> iter 82000, loss: 0.058213
 >> iter 83000, loss: 0.058947
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058930
 >> iter 86000, loss: 0.058188
 >> iter 87000, loss: 0.058933
 >> iter 88000, loss: 0.058180
 >> iter 89000, loss: 0.058912
 >> iter 90000, loss: 0.058206
   Number of active neurons: 1
 >> iter 91000, loss: 0.058911
 >> iter 92000, loss: 0.058223
 >> iter 93000, loss: 0.058931
 >> iter 94000, loss: 0.058202
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058187
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058172
 >> iter 99000, loss: 0.059019
 >> iter 100000, loss: 0.058234
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.129063
 >> iter 2000, loss: 4.145167
 >> iter 3000, loss: 1.568435
 >> iter 4000, loss: 0.617453
 >> iter 5000, loss: 0.267295
 >> iter 6000, loss: 0.137017
 >> iter 7000, loss: 0.089336
 >> iter 8000, loss: 0.070591
 >> iter 9000, loss: 0.064229
 >> iter 10000, loss: 0.060799
   Number of active neurons: 1
 >> iter 11000, loss: 0.060252
 >> iter 12000, loss: 0.059014
 >> iter 13000, loss: 0.059416
 >> iter 14000, loss: 0.058525
 >> iter 15000, loss: 0.059120
 >> iter 16000, loss: 0.058343
 >> iter 17000, loss: 0.058993
 >> iter 18000, loss: 0.058271
 >> iter 19000, loss: 0.058915
 >> iter 20000, loss: 0.058258
   Number of active neurons: 1
 >> iter 21000, loss: 0.058893
 >> iter 22000, loss: 0.058212
 >> iter 23000, loss: 0.058878
 >> iter 24000, loss: 0.058174
 >> iter 25000, loss: 0.058874
 >> iter 26000, loss: 0.058195
 >> iter 27000, loss: 0.058868
 >> iter 28000, loss: 0.058201
 >> iter 29000, loss: 0.058842
 >> iter 30000, loss: 0.058170
   Number of active neurons: 1
 >> iter 31000, loss: 0.058824
 >> iter 32000, loss: 0.058147
 >> iter 33000, loss: 0.058802
 >> iter 34000, loss: 0.058135
 >> iter 35000, loss: 0.058828
 >> iter 36000, loss: 0.058120
 >> iter 37000, loss: 0.058818
 >> iter 38000, loss: 0.058095
 >> iter 39000, loss: 0.058823
 >> iter 40000, loss: 0.058086
   Number of active neurons: 1
 >> iter 41000, loss: 0.058805
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058775
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058772
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058799
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058148
 >> iter 53000, loss: 0.058786
 >> iter 54000, loss: 0.058218
 >> iter 55000, loss: 0.058767
 >> iter 56000, loss: 0.058229
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058198
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058221
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058820
 >> iter 64000, loss: 0.058195
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058207
 >> iter 67000, loss: 0.058795
 >> iter 68000, loss: 0.058254
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058218
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058248
 >> iter 73000, loss: 0.058801
 >> iter 74000, loss: 0.058230
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058786
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058207
   Number of active neurons: 1
 >> iter 81000, loss: 0.058908
 >> iter 82000, loss: 0.058212
 >> iter 83000, loss: 0.058946
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058931
 >> iter 86000, loss: 0.058187
 >> iter 87000, loss: 0.058932
 >> iter 88000, loss: 0.058181
 >> iter 89000, loss: 0.058913
 >> iter 90000, loss: 0.058205
   Number of active neurons: 1
 >> iter 91000, loss: 0.058910
 >> iter 92000, loss: 0.058224
 >> iter 93000, loss: 0.058932
 >> iter 94000, loss: 0.058201
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058188
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058171
 >> iter 99000, loss: 0.059018
 >> iter 100000, loss: 0.058235
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.947407
 >> iter 2000, loss: 4.077712
 >> iter 3000, loss: 1.543480
 >> iter 4000, loss: 0.608217
 >> iter 5000, loss: 0.263863
 >> iter 6000, loss: 0.135730
 >> iter 7000, loss: 0.088844
 >> iter 8000, loss: 0.070397
 >> iter 9000, loss: 0.064148
 >> iter 10000, loss: 0.060762
   Number of active neurons: 1
 >> iter 11000, loss: 0.060234
 >> iter 12000, loss: 0.059003
 >> iter 13000, loss: 0.059408
 >> iter 14000, loss: 0.058521
 >> iter 15000, loss: 0.059117
 >> iter 16000, loss: 0.058341
 >> iter 17000, loss: 0.058991
 >> iter 18000, loss: 0.058270
 >> iter 19000, loss: 0.058914
 >> iter 20000, loss: 0.058258
   Number of active neurons: 1
 >> iter 21000, loss: 0.058893
 >> iter 22000, loss: 0.058212
 >> iter 23000, loss: 0.058878
 >> iter 24000, loss: 0.058174
 >> iter 25000, loss: 0.058873
 >> iter 26000, loss: 0.058195
 >> iter 27000, loss: 0.058868
 >> iter 28000, loss: 0.058201
 >> iter 29000, loss: 0.058842
 >> iter 30000, loss: 0.058170
   Number of active neurons: 1
 >> iter 31000, loss: 0.058824
 >> iter 32000, loss: 0.058147
 >> iter 33000, loss: 0.058801
 >> iter 34000, loss: 0.058135
 >> iter 35000, loss: 0.058828
 >> iter 36000, loss: 0.058120
 >> iter 37000, loss: 0.058818
 >> iter 38000, loss: 0.058095
 >> iter 39000, loss: 0.058823
 >> iter 40000, loss: 0.058086
   Number of active neurons: 1
 >> iter 41000, loss: 0.058805
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058775
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058772
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058798
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058148
 >> iter 53000, loss: 0.058786
 >> iter 54000, loss: 0.058218
 >> iter 55000, loss: 0.058767
 >> iter 56000, loss: 0.058228
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058198
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058221
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058820
 >> iter 64000, loss: 0.058195
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058207
 >> iter 67000, loss: 0.058795
 >> iter 68000, loss: 0.058254
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058218
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058248
 >> iter 73000, loss: 0.058801
 >> iter 74000, loss: 0.058230
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058207
   Number of active neurons: 1
 >> iter 81000, loss: 0.058908
 >> iter 82000, loss: 0.058212
 >> iter 83000, loss: 0.058946
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058931
 >> iter 86000, loss: 0.058187
 >> iter 87000, loss: 0.058932
 >> iter 88000, loss: 0.058181
 >> iter 89000, loss: 0.058912
 >> iter 90000, loss: 0.058205
   Number of active neurons: 1
 >> iter 91000, loss: 0.058910
 >> iter 92000, loss: 0.058223
 >> iter 93000, loss: 0.058932
 >> iter 94000, loss: 0.058201
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058188
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058171
 >> iter 99000, loss: 0.059018
 >> iter 100000, loss: 0.058235
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.770725
 >> iter 2000, loss: 4.012195
 >> iter 3000, loss: 1.524564
 >> iter 4000, loss: 0.608213
 >> iter 5000, loss: 0.272457
 >> iter 6000, loss: 0.148188
 >> iter 7000, loss: 0.103707
 >> iter 8000, loss: 0.086474
 >> iter 9000, loss: 0.080988
 >> iter 10000, loss: 0.075868
   Number of active neurons: 1
 >> iter 11000, loss: 0.070581
 >> iter 12000, loss: 0.065441
 >> iter 13000, loss: 0.063532
 >> iter 14000, loss: 0.061272
 >> iter 15000, loss: 0.061032
 >> iter 16000, loss: 0.059695
 >> iter 17000, loss: 0.059970
 >> iter 18000, loss: 0.058976
 >> iter 19000, loss: 0.059430
 >> iter 20000, loss: 0.058633
   Number of active neurons: 1
 >> iter 21000, loss: 0.059168
 >> iter 22000, loss: 0.058413
 >> iter 23000, loss: 0.059025
 >> iter 24000, loss: 0.058282
 >> iter 25000, loss: 0.058952
 >> iter 26000, loss: 0.058253
 >> iter 27000, loss: 0.058911
 >> iter 28000, loss: 0.058231
 >> iter 29000, loss: 0.058864
 >> iter 30000, loss: 0.058187
   Number of active neurons: 1
 >> iter 31000, loss: 0.058837
 >> iter 32000, loss: 0.058156
 >> iter 33000, loss: 0.058808
 >> iter 34000, loss: 0.058140
 >> iter 35000, loss: 0.058832
 >> iter 36000, loss: 0.058123
 >> iter 37000, loss: 0.058820
 >> iter 38000, loss: 0.058097
 >> iter 39000, loss: 0.058824
 >> iter 40000, loss: 0.058086
   Number of active neurons: 1
 >> iter 41000, loss: 0.058805
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058776
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058786
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058773
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058799
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058147
 >> iter 53000, loss: 0.058786
 >> iter 54000, loss: 0.058219
 >> iter 55000, loss: 0.058768
 >> iter 56000, loss: 0.058228
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058199
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058220
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058821
 >> iter 64000, loss: 0.058195
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058208
 >> iter 67000, loss: 0.058796
 >> iter 68000, loss: 0.058253
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058219
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058247
 >> iter 73000, loss: 0.058801
 >> iter 74000, loss: 0.058231
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058206
   Number of active neurons: 1
 >> iter 81000, loss: 0.058908
 >> iter 82000, loss: 0.058213
 >> iter 83000, loss: 0.058947
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058930
 >> iter 86000, loss: 0.058188
 >> iter 87000, loss: 0.058933
 >> iter 88000, loss: 0.058180
 >> iter 89000, loss: 0.058912
 >> iter 90000, loss: 0.058206
   Number of active neurons: 1
 >> iter 91000, loss: 0.058911
 >> iter 92000, loss: 0.058223
 >> iter 93000, loss: 0.058932
 >> iter 94000, loss: 0.058202
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058187
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058172
 >> iter 99000, loss: 0.059019
 >> iter 100000, loss: 0.058234
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.140577
 >> iter 2000, loss: 4.149437
 >> iter 3000, loss: 1.570011
 >> iter 4000, loss: 0.618035
 >> iter 5000, loss: 0.267510
 >> iter 6000, loss: 0.137098
 >> iter 7000, loss: 0.089366
 >> iter 8000, loss: 0.070603
 >> iter 9000, loss: 0.064234
 >> iter 10000, loss: 0.060801
   Number of active neurons: 1
 >> iter 11000, loss: 0.060253
 >> iter 12000, loss: 0.059015
 >> iter 13000, loss: 0.059416
 >> iter 14000, loss: 0.058525
 >> iter 15000, loss: 0.059120
 >> iter 16000, loss: 0.058343
 >> iter 17000, loss: 0.058993
 >> iter 18000, loss: 0.058271
 >> iter 19000, loss: 0.058915
 >> iter 20000, loss: 0.058258
   Number of active neurons: 1
 >> iter 21000, loss: 0.058893
 >> iter 22000, loss: 0.058212
 >> iter 23000, loss: 0.058878
 >> iter 24000, loss: 0.058174
 >> iter 25000, loss: 0.058874
 >> iter 26000, loss: 0.058195
 >> iter 27000, loss: 0.058868
 >> iter 28000, loss: 0.058201
 >> iter 29000, loss: 0.058842
 >> iter 30000, loss: 0.058170
   Number of active neurons: 1
 >> iter 31000, loss: 0.058824
 >> iter 32000, loss: 0.058147
 >> iter 33000, loss: 0.058802
 >> iter 34000, loss: 0.058135
 >> iter 35000, loss: 0.058828
 >> iter 36000, loss: 0.058120
 >> iter 37000, loss: 0.058818
 >> iter 38000, loss: 0.058095
 >> iter 39000, loss: 0.058823
 >> iter 40000, loss: 0.058086
   Number of active neurons: 1
 >> iter 41000, loss: 0.058805
 >> iter 42000, loss: 0.058098
 >> iter 43000, loss: 0.058775
 >> iter 44000, loss: 0.058111
 >> iter 45000, loss: 0.058785
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058772
 >> iter 48000, loss: 0.058124
 >> iter 49000, loss: 0.058798
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058148
 >> iter 53000, loss: 0.058786
 >> iter 54000, loss: 0.058218
 >> iter 55000, loss: 0.058767
 >> iter 56000, loss: 0.058228
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058198
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058221
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058820
 >> iter 64000, loss: 0.058195
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058207
 >> iter 67000, loss: 0.058795
 >> iter 68000, loss: 0.058254
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058218
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058248
 >> iter 73000, loss: 0.058801
 >> iter 74000, loss: 0.058230
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058230
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058207
   Number of active neurons: 1
 >> iter 81000, loss: 0.058908
 >> iter 82000, loss: 0.058212
 >> iter 83000, loss: 0.058946
 >> iter 84000, loss: 0.058205
 >> iter 85000, loss: 0.058931
 >> iter 86000, loss: 0.058187
 >> iter 87000, loss: 0.058932
 >> iter 88000, loss: 0.058181
 >> iter 89000, loss: 0.058912
 >> iter 90000, loss: 0.058205
   Number of active neurons: 1
 >> iter 91000, loss: 0.058910
 >> iter 92000, loss: 0.058224
 >> iter 93000, loss: 0.058932
 >> iter 94000, loss: 0.058201
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058188
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058171
 >> iter 99000, loss: 0.059018
 >> iter 100000, loss: 0.058235
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 10.850466
 >> iter 2000, loss: 4.041616
 >> iter 3000, loss: 1.534726
 >> iter 4000, loss: 0.610749
 >> iter 5000, loss: 0.271971
 >> iter 6000, loss: 0.146218
 >> iter 7000, loss: 0.101166
 >> iter 8000, loss: 0.083717
 >> iter 9000, loss: 0.078806
 >> iter 10000, loss: 0.076116
   Number of active neurons: 2
 >> iter 11000, loss: 0.076581
 >> iter 12000, loss: 0.075841
 >> iter 13000, loss: 0.077061
 >> iter 14000, loss: 0.076325
 >> iter 15000, loss: 0.076272
 >> iter 16000, loss: 0.070998
 >> iter 17000, loss: 0.067055
 >> iter 18000, loss: 0.063406
 >> iter 19000, loss: 0.062335
 >> iter 20000, loss: 0.060612
   Number of active neurons: 1
 >> iter 21000, loss: 0.060564
 >> iter 22000, loss: 0.059408
 >> iter 23000, loss: 0.059747
 >> iter 24000, loss: 0.058803
 >> iter 25000, loss: 0.059334
 >> iter 26000, loss: 0.058530
 >> iter 27000, loss: 0.059115
 >> iter 28000, loss: 0.058380
 >> iter 29000, loss: 0.058973
 >> iter 30000, loss: 0.058266
   Number of active neurons: 1
 >> iter 31000, loss: 0.058896
 >> iter 32000, loss: 0.058198
 >> iter 33000, loss: 0.058839
 >> iter 34000, loss: 0.058163
 >> iter 35000, loss: 0.058848
 >> iter 36000, loss: 0.058135
 >> iter 37000, loss: 0.058829
 >> iter 38000, loss: 0.058103
 >> iter 39000, loss: 0.058829
 >> iter 40000, loss: 0.058090
   Number of active neurons: 1
 >> iter 41000, loss: 0.058808
 >> iter 42000, loss: 0.058100
 >> iter 43000, loss: 0.058777
 >> iter 44000, loss: 0.058113
 >> iter 45000, loss: 0.058786
 >> iter 46000, loss: 0.058105
 >> iter 47000, loss: 0.058773
 >> iter 48000, loss: 0.058125
 >> iter 49000, loss: 0.058798
 >> iter 50000, loss: 0.058116
   Number of active neurons: 1
 >> iter 51000, loss: 0.058800
 >> iter 52000, loss: 0.058148
 >> iter 53000, loss: 0.058785
 >> iter 54000, loss: 0.058218
 >> iter 55000, loss: 0.058768
 >> iter 56000, loss: 0.058229
 >> iter 57000, loss: 0.058814
 >> iter 58000, loss: 0.058198
 >> iter 59000, loss: 0.058825
 >> iter 60000, loss: 0.058221
   Number of active neurons: 1
 >> iter 61000, loss: 0.058806
 >> iter 62000, loss: 0.058230
 >> iter 63000, loss: 0.058820
 >> iter 64000, loss: 0.058196
 >> iter 65000, loss: 0.058820
 >> iter 66000, loss: 0.058207
 >> iter 67000, loss: 0.058795
 >> iter 68000, loss: 0.058254
 >> iter 69000, loss: 0.058800
 >> iter 70000, loss: 0.058219
   Number of active neurons: 1
 >> iter 71000, loss: 0.058797
 >> iter 72000, loss: 0.058248
 >> iter 73000, loss: 0.058800
 >> iter 74000, loss: 0.058231
 >> iter 75000, loss: 0.058802
 >> iter 76000, loss: 0.058231
 >> iter 77000, loss: 0.058785
 >> iter 78000, loss: 0.058195
 >> iter 79000, loss: 0.058846
 >> iter 80000, loss: 0.058207
   Number of active neurons: 1
 >> iter 81000, loss: 0.058908
 >> iter 82000, loss: 0.058212
 >> iter 83000, loss: 0.058947
 >> iter 84000, loss: 0.058206
 >> iter 85000, loss: 0.058930
 >> iter 86000, loss: 0.058187
 >> iter 87000, loss: 0.058932
 >> iter 88000, loss: 0.058181
 >> iter 89000, loss: 0.058912
 >> iter 90000, loss: 0.058205
   Number of active neurons: 1
 >> iter 91000, loss: 0.058910
 >> iter 92000, loss: 0.058224
 >> iter 93000, loss: 0.058932
 >> iter 94000, loss: 0.058201
 >> iter 95000, loss: 0.058991
 >> iter 96000, loss: 0.058188
 >> iter 97000, loss: 0.059007
 >> iter 98000, loss: 0.058171
 >> iter 99000, loss: 0.059018
 >> iter 100000, loss: 0.058235
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

