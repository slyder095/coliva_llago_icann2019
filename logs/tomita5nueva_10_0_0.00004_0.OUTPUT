 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 4e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.561021
 >> iter 2000, loss: 10.491333
 >> iter 3000, loss: 8.625243
 >> iter 4000, loss: 7.909857
 >> iter 5000, loss: 7.690385
 >> iter 6000, loss: 7.592811
 >> iter 7000, loss: 7.540837
 >> iter 8000, loss: 7.075537
 >> iter 9000, loss: 3.433250
 >> iter 10000, loss: 1.310616
   Number of active neurons: 8
 >> iter 11000, loss: 0.512482
 >> iter 12000, loss: 0.212402
 >> iter 13000, loss: 0.099213
 >> iter 14000, loss: 0.055701
 >> iter 15000, loss: 0.038920
 >> iter 16000, loss: 0.031925
 >> iter 17000, loss: 0.029162
 >> iter 18000, loss: 0.027688
 >> iter 19000, loss: 0.027134
 >> iter 20000, loss: 0.026587
   Number of active neurons: 8
 >> iter 21000, loss: 0.026478
 >> iter 22000, loss: 0.026145
 >> iter 23000, loss: 0.026136
 >> iter 24000, loss: 0.025845
 >> iter 25000, loss: 0.025816
 >> iter 26000, loss: 0.025530
 >> iter 27000, loss: 0.025530
 >> iter 28000, loss: 0.025296
 >> iter 29000, loss: 0.025311
 >> iter 30000, loss: 0.025082
   Number of active neurons: 8
 >> iter 31000, loss: 0.025108
 >> iter 32000, loss: 0.024911
 >> iter 33000, loss: 0.024918
 >> iter 34000, loss: 0.024658
 >> iter 35000, loss: 0.024540
 >> iter 36000, loss: 0.024186
 >> iter 37000, loss: 0.023896
 >> iter 38000, loss: 0.023395
 >> iter 39000, loss: 0.022981
 >> iter 40000, loss: 0.022588
   Number of active neurons: 8
 >> iter 41000, loss: 0.022311
 >> iter 42000, loss: 0.022034
 >> iter 43000, loss: 0.021845
 >> iter 44000, loss: 0.021638
 >> iter 45000, loss: 0.021463
 >> iter 46000, loss: 0.021275
 >> iter 47000, loss: 0.021115
 >> iter 48000, loss: 0.020949
 >> iter 49000, loss: 0.020807
 >> iter 50000, loss: 0.020621
   Number of active neurons: 7
 >> iter 51000, loss: 0.020451
 >> iter 52000, loss: 0.020257
 >> iter 53000, loss: 0.020097
 >> iter 54000, loss: 0.019929
 >> iter 55000, loss: 0.019799
 >> iter 56000, loss: 0.019664
 >> iter 57000, loss: 0.019552
 >> iter 58000, loss: 0.019436
 >> iter 59000, loss: 0.019328
 >> iter 60000, loss: 0.019228
   Number of active neurons: 7
 >> iter 61000, loss: 0.019118
 >> iter 62000, loss: 0.019025
 >> iter 63000, loss: 0.018894
 >> iter 64000, loss: 0.018783
 >> iter 65000, loss: 0.018651
 >> iter 66000, loss: 0.018559
 >> iter 67000, loss: 0.018449
 >> iter 68000, loss: 0.018383
 >> iter 69000, loss: 0.018294
 >> iter 70000, loss: 0.018242
   Number of active neurons: 7
 >> iter 71000, loss: 0.018160
 >> iter 72000, loss: 0.018110
 >> iter 73000, loss: 0.018037
 >> iter 74000, loss: 0.017993
 >> iter 75000, loss: 0.017930
 >> iter 76000, loss: 0.017895
 >> iter 77000, loss: 0.017838
 >> iter 78000, loss: 0.017807
 >> iter 79000, loss: 0.017757
 >> iter 80000, loss: 0.017727
   Number of active neurons: 7
 >> iter 81000, loss: 0.017676
 >> iter 82000, loss: 0.017656
 >> iter 83000, loss: 0.017605
 >> iter 84000, loss: 0.017588
 >> iter 85000, loss: 0.017538
 >> iter 86000, loss: 0.017526
 >> iter 87000, loss: 0.017478
 >> iter 88000, loss: 0.017467
 >> iter 89000, loss: 0.017417
 >> iter 90000, loss: 0.017411
   Number of active neurons: 7
 >> iter 91000, loss: 0.017360
 >> iter 92000, loss: 0.017358
 >> iter 93000, loss: 0.017308
 >> iter 94000, loss: 0.017288
 >> iter 95000, loss: 0.017219
 >> iter 96000, loss: 0.017196
 >> iter 97000, loss: 0.017133
 >> iter 98000, loss: 0.017120
 >> iter 99000, loss: 0.017063
 >> iter 100000, loss: 0.017060
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.538485
 >> iter 2000, loss: 10.498704
 >> iter 3000, loss: 8.639321
 >> iter 4000, loss: 7.932627
 >> iter 5000, loss: 7.693188
 >> iter 6000, loss: 7.579738
 >> iter 7000, loss: 7.665256
 >> iter 8000, loss: 7.390343
 >> iter 9000, loss: 5.676039
 >> iter 10000, loss: 2.159465
   Number of active neurons: 7
 >> iter 11000, loss: 0.825683
 >> iter 12000, loss: 0.326171
 >> iter 13000, loss: 0.138788
 >> iter 14000, loss: 0.067758
 >> iter 15000, loss: 0.040495
 >> iter 16000, loss: 0.029638
 >> iter 17000, loss: 0.025153
 >> iter 18000, loss: 0.023028
 >> iter 19000, loss: 0.021968
 >> iter 20000, loss: 0.021266
   Number of active neurons: 7
 >> iter 21000, loss: 0.020872
 >> iter 22000, loss: 0.020535
 >> iter 23000, loss: 0.020352
 >> iter 24000, loss: 0.020137
 >> iter 25000, loss: 0.020020
 >> iter 26000, loss: 0.019869
 >> iter 27000, loss: 0.019785
 >> iter 28000, loss: 0.019658
 >> iter 29000, loss: 0.019577
 >> iter 30000, loss: 0.019455
   Number of active neurons: 7
 >> iter 31000, loss: 0.019380
 >> iter 32000, loss: 0.019256
 >> iter 33000, loss: 0.019178
 >> iter 34000, loss: 0.019064
 >> iter 35000, loss: 0.019011
 >> iter 36000, loss: 0.018924
 >> iter 37000, loss: 0.018885
 >> iter 38000, loss: 0.018824
 >> iter 39000, loss: 0.018786
 >> iter 40000, loss: 0.018706
   Number of active neurons: 7
 >> iter 41000, loss: 0.018640
 >> iter 42000, loss: 0.018568
 >> iter 43000, loss: 0.018521
 >> iter 44000, loss: 0.018468
 >> iter 45000, loss: 0.018432
 >> iter 46000, loss: 0.018390
 >> iter 47000, loss: 0.018355
 >> iter 48000, loss: 0.018313
 >> iter 49000, loss: 0.018282
 >> iter 50000, loss: 0.018241
   Number of active neurons: 7
 >> iter 51000, loss: 0.018189
 >> iter 52000, loss: 0.018129
 >> iter 53000, loss: 0.018058
 >> iter 54000, loss: 0.018015
 >> iter 55000, loss: 0.017925
 >> iter 56000, loss: 0.017884
 >> iter 57000, loss: 0.017781
 >> iter 58000, loss: 0.017746
 >> iter 59000, loss: 0.017642
 >> iter 60000, loss: 0.017621
   Number of active neurons: 7
 >> iter 61000, loss: 0.017514
 >> iter 62000, loss: 0.017505
 >> iter 63000, loss: 0.017416
 >> iter 64000, loss: 0.017435
 >> iter 65000, loss: 0.017353
 >> iter 66000, loss: 0.017381
 >> iter 67000, loss: 0.017300
 >> iter 68000, loss: 0.017335
 >> iter 69000, loss: 0.017249
 >> iter 70000, loss: 0.017284
   Number of active neurons: 7
 >> iter 71000, loss: 0.017196
 >> iter 72000, loss: 0.017233
 >> iter 73000, loss: 0.017140
 >> iter 74000, loss: 0.017172
 >> iter 75000, loss: 0.017071
 >> iter 76000, loss: 0.017087
 >> iter 77000, loss: 0.016957
 >> iter 78000, loss: 0.016965
 >> iter 79000, loss: 0.016844
 >> iter 80000, loss: 0.016849
   Number of active neurons: 6
 >> iter 81000, loss: 0.016725
 >> iter 82000, loss: 0.016735
 >> iter 83000, loss: 0.016605
 >> iter 84000, loss: 0.016610
 >> iter 85000, loss: 0.016464
 >> iter 86000, loss: 0.016475
 >> iter 87000, loss: 0.016337
 >> iter 88000, loss: 0.016363
 >> iter 89000, loss: 0.016238
 >> iter 90000, loss: 0.016276
   Number of active neurons: 7
 >> iter 91000, loss: 0.016157
 >> iter 92000, loss: 0.016208
 >> iter 93000, loss: 0.016093
 >> iter 94000, loss: 0.016144
 >> iter 95000, loss: 0.016040
 >> iter 96000, loss: 0.016093
 >> iter 97000, loss: 0.015989
 >> iter 98000, loss: 0.016043
 >> iter 99000, loss: 0.015941
 >> iter 100000, loss: 0.015995
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.573591
 >> iter 2000, loss: 10.497472
 >> iter 3000, loss: 8.627833
 >> iter 4000, loss: 7.911323
 >> iter 5000, loss: 7.686475
 >> iter 6000, loss: 7.554998
 >> iter 7000, loss: 7.070448
 >> iter 8000, loss: 3.508641
 >> iter 9000, loss: 1.333351
 >> iter 10000, loss: 0.517589
   Number of active neurons: 8
 >> iter 11000, loss: 0.212259
 >> iter 12000, loss: 0.097013
 >> iter 13000, loss: 0.053125
 >> iter 14000, loss: 0.035779
 >> iter 15000, loss: 0.028751
 >> iter 16000, loss: 0.025488
 >> iter 17000, loss: 0.023932
 >> iter 18000, loss: 0.022914
 >> iter 19000, loss: 0.022310
 >> iter 20000, loss: 0.021783
   Number of active neurons: 7
 >> iter 21000, loss: 0.021467
 >> iter 22000, loss: 0.021166
 >> iter 23000, loss: 0.020981
 >> iter 24000, loss: 0.020772
 >> iter 25000, loss: 0.020648
 >> iter 26000, loss: 0.020509
 >> iter 27000, loss: 0.020430
 >> iter 28000, loss: 0.020323
 >> iter 29000, loss: 0.020245
 >> iter 30000, loss: 0.020137
   Number of active neurons: 7
 >> iter 31000, loss: 0.020043
 >> iter 32000, loss: 0.019932
 >> iter 33000, loss: 0.019866
 >> iter 34000, loss: 0.019781
 >> iter 35000, loss: 0.019728
 >> iter 36000, loss: 0.019650
 >> iter 37000, loss: 0.019601
 >> iter 38000, loss: 0.019543
 >> iter 39000, loss: 0.019478
 >> iter 40000, loss: 0.019405
   Number of active neurons: 6
 >> iter 41000, loss: 0.019344
 >> iter 42000, loss: 0.019275
 >> iter 43000, loss: 0.019218
 >> iter 44000, loss: 0.019146
 >> iter 45000, loss: 0.019078
 >> iter 46000, loss: 0.019010
 >> iter 47000, loss: 0.018926
 >> iter 48000, loss: 0.018829
 >> iter 49000, loss: 0.018719
 >> iter 50000, loss: 0.018638
   Number of active neurons: 6
 >> iter 51000, loss: 0.018546
 >> iter 52000, loss: 0.018483
 >> iter 53000, loss: 0.018392
 >> iter 54000, loss: 0.018346
 >> iter 55000, loss: 0.018243
 >> iter 56000, loss: 0.018212
 >> iter 57000, loss: 0.018108
 >> iter 58000, loss: 0.018102
 >> iter 59000, loss: 0.017992
 >> iter 60000, loss: 0.017986
   Number of active neurons: 6
 >> iter 61000, loss: 0.017865
 >> iter 62000, loss: 0.017865
 >> iter 63000, loss: 0.017753
 >> iter 64000, loss: 0.017771
 >> iter 65000, loss: 0.017665
 >> iter 66000, loss: 0.017694
 >> iter 67000, loss: 0.017590
 >> iter 68000, loss: 0.017628
 >> iter 69000, loss: 0.017518
 >> iter 70000, loss: 0.017525
   Number of active neurons: 6
 >> iter 71000, loss: 0.017401
 >> iter 72000, loss: 0.017417
 >> iter 73000, loss: 0.017307
 >> iter 74000, loss: 0.017335
 >> iter 75000, loss: 0.017233
 >> iter 76000, loss: 0.017271
 >> iter 77000, loss: 0.017172
 >> iter 78000, loss: 0.017219
 >> iter 79000, loss: 0.017128
 >> iter 80000, loss: 0.017173
   Number of active neurons: 6
 >> iter 81000, loss: 0.017081
 >> iter 82000, loss: 0.017133
 >> iter 83000, loss: 0.017035
 >> iter 84000, loss: 0.017093
 >> iter 85000, loss: 0.016996
 >> iter 86000, loss: 0.017058
 >> iter 87000, loss: 0.016959
 >> iter 88000, loss: 0.017021
 >> iter 89000, loss: 0.016923
 >> iter 90000, loss: 0.016986
   Number of active neurons: 6
 >> iter 91000, loss: 0.016886
 >> iter 92000, loss: 0.016956
 >> iter 93000, loss: 0.016850
 >> iter 94000, loss: 0.016920
 >> iter 95000, loss: 0.016825
 >> iter 96000, loss: 0.016890
 >> iter 97000, loss: 0.016796
 >> iter 98000, loss: 0.016854
 >> iter 99000, loss: 0.016751
 >> iter 100000, loss: 0.016809
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.561916
 >> iter 2000, loss: 10.504130
 >> iter 3000, loss: 8.634006
 >> iter 4000, loss: 7.924700
 >> iter 5000, loss: 7.691495
 >> iter 6000, loss: 7.605584
 >> iter 7000, loss: 7.663976
 >> iter 8000, loss: 5.134413
 >> iter 9000, loss: 1.944912
 >> iter 10000, loss: 0.745001
   Number of active neurons: 10
 >> iter 11000, loss: 0.297079
 >> iter 12000, loss: 0.129078
 >> iter 13000, loss: 0.065827
 >> iter 14000, loss: 0.041436
 >> iter 15000, loss: 0.031898
 >> iter 16000, loss: 0.027777
 >> iter 17000, loss: 0.025934
 >> iter 18000, loss: 0.024846
 >> iter 19000, loss: 0.024236
 >> iter 20000, loss: 0.023696
   Number of active neurons: 9
 >> iter 21000, loss: 0.023323
 >> iter 22000, loss: 0.022930
 >> iter 23000, loss: 0.022703
 >> iter 24000, loss: 0.022456
 >> iter 25000, loss: 0.022321
 >> iter 26000, loss: 0.022130
 >> iter 27000, loss: 0.022004
 >> iter 28000, loss: 0.021832
 >> iter 29000, loss: 0.021716
 >> iter 30000, loss: 0.021574
   Number of active neurons: 9
 >> iter 31000, loss: 0.021485
 >> iter 32000, loss: 0.021352
 >> iter 33000, loss: 0.021261
 >> iter 34000, loss: 0.021120
 >> iter 35000, loss: 0.021011
 >> iter 36000, loss: 0.020864
 >> iter 37000, loss: 0.020752
 >> iter 38000, loss: 0.020640
 >> iter 39000, loss: 0.020510
 >> iter 40000, loss: 0.020389
   Number of active neurons: 8
 >> iter 41000, loss: 0.020275
 >> iter 42000, loss: 0.020179
 >> iter 43000, loss: 0.020094
 >> iter 44000, loss: 0.020026
 >> iter 45000, loss: 0.019928
 >> iter 46000, loss: 0.019792
 >> iter 47000, loss: 0.019646
 >> iter 48000, loss: 0.019517
 >> iter 49000, loss: 0.019379
 >> iter 50000, loss: 0.019267
   Number of active neurons: 7
 >> iter 51000, loss: 0.019156
 >> iter 52000, loss: 0.019058
 >> iter 53000, loss: 0.018929
 >> iter 54000, loss: 0.018841
 >> iter 55000, loss: 0.018684
 >> iter 56000, loss: 0.018622
 >> iter 57000, loss: 0.018480
 >> iter 58000, loss: 0.018451
 >> iter 59000, loss: 0.018312
 >> iter 60000, loss: 0.018299
   Number of active neurons: 7
 >> iter 61000, loss: 0.018164
 >> iter 62000, loss: 0.018157
 >> iter 63000, loss: 0.018026
 >> iter 64000, loss: 0.018026
 >> iter 65000, loss: 0.017884
 >> iter 66000, loss: 0.017885
 >> iter 67000, loss: 0.017743
 >> iter 68000, loss: 0.017771
 >> iter 69000, loss: 0.017643
 >> iter 70000, loss: 0.017682
   Number of active neurons: 9
 >> iter 71000, loss: 0.017557
 >> iter 72000, loss: 0.017602
 >> iter 73000, loss: 0.017479
 >> iter 74000, loss: 0.017529
 >> iter 75000, loss: 0.017401
 >> iter 76000, loss: 0.017454
 >> iter 77000, loss: 0.017319
 >> iter 78000, loss: 0.017369
 >> iter 79000, loss: 0.017247
 >> iter 80000, loss: 0.017305
   Number of active neurons: 9
 >> iter 81000, loss: 0.017186
 >> iter 82000, loss: 0.017252
 >> iter 83000, loss: 0.017128
 >> iter 84000, loss: 0.017199
 >> iter 85000, loss: 0.017076
 >> iter 86000, loss: 0.017152
 >> iter 87000, loss: 0.017027
 >> iter 88000, loss: 0.017103
 >> iter 89000, loss: 0.016979
 >> iter 90000, loss: 0.017056
   Number of active neurons: 9
 >> iter 91000, loss: 0.016930
 >> iter 92000, loss: 0.017013
 >> iter 93000, loss: 0.016882
 >> iter 94000, loss: 0.016947
 >> iter 95000, loss: 0.016808
 >> iter 96000, loss: 0.016863
 >> iter 97000, loss: 0.016733
 >> iter 98000, loss: 0.016797
 >> iter 99000, loss: 0.016669
 >> iter 100000, loss: 0.016726
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.591537
 >> iter 2000, loss: 10.525359
 >> iter 3000, loss: 8.659369
 >> iter 4000, loss: 7.947599
 >> iter 5000, loss: 7.713379
 >> iter 6000, loss: 7.552572
 >> iter 7000, loss: 4.997250
 >> iter 8000, loss: 1.900538
 >> iter 9000, loss: 0.733351
 >> iter 10000, loss: 0.295739
   Number of active neurons: 9
 >> iter 11000, loss: 0.130937
 >> iter 12000, loss: 0.067926
 >> iter 13000, loss: 0.043370
 >> iter 14000, loss: 0.033277
 >> iter 15000, loss: 0.028954
 >> iter 16000, loss: 0.026805
 >> iter 17000, loss: 0.025731
 >> iter 18000, loss: 0.024998
 >> iter 19000, loss: 0.024618
 >> iter 20000, loss: 0.024225
   Number of active neurons: 8
 >> iter 21000, loss: 0.023990
 >> iter 22000, loss: 0.023708
 >> iter 23000, loss: 0.023523
 >> iter 24000, loss: 0.023305
 >> iter 25000, loss: 0.023169
 >> iter 26000, loss: 0.023011
 >> iter 27000, loss: 0.022915
 >> iter 28000, loss: 0.022800
 >> iter 29000, loss: 0.022741
 >> iter 30000, loss: 0.022665
   Number of active neurons: 8
 >> iter 31000, loss: 0.022631
 >> iter 32000, loss: 0.022555
 >> iter 33000, loss: 0.022519
 >> iter 34000, loss: 0.022447
 >> iter 35000, loss: 0.022409
 >> iter 36000, loss: 0.022324
 >> iter 37000, loss: 0.022290
 >> iter 38000, loss: 0.022225
 >> iter 39000, loss: 0.022201
 >> iter 40000, loss: 0.022147
   Number of active neurons: 8
 >> iter 41000, loss: 0.022137
 >> iter 42000, loss: 0.022079
 >> iter 43000, loss: 0.022066
 >> iter 44000, loss: 0.021999
 >> iter 45000, loss: 0.021993
 >> iter 46000, loss: 0.021935
 >> iter 47000, loss: 0.021928
 >> iter 48000, loss: 0.021866
 >> iter 49000, loss: 0.021870
 >> iter 50000, loss: 0.021814
   Number of active neurons: 8
 >> iter 51000, loss: 0.021817
 >> iter 52000, loss: 0.021757
 >> iter 53000, loss: 0.021743
 >> iter 54000, loss: 0.021659
 >> iter 55000, loss: 0.021581
 >> iter 56000, loss: 0.021467
 >> iter 57000, loss: 0.021359
 >> iter 58000, loss: 0.021241
 >> iter 59000, loss: 0.021128
 >> iter 60000, loss: 0.021019
   Number of active neurons: 8
 >> iter 61000, loss: 0.020909
 >> iter 62000, loss: 0.020795
 >> iter 63000, loss: 0.020685
 >> iter 64000, loss: 0.020578
 >> iter 65000, loss: 0.020460
 >> iter 66000, loss: 0.020355
 >> iter 67000, loss: 0.020248
 >> iter 68000, loss: 0.020153
 >> iter 69000, loss: 0.020053
 >> iter 70000, loss: 0.019972
   Number of active neurons: 7
 >> iter 71000, loss: 0.019890
 >> iter 72000, loss: 0.019823
 >> iter 73000, loss: 0.019745
 >> iter 74000, loss: 0.019670
 >> iter 75000, loss: 0.019576
 >> iter 76000, loss: 0.019501
 >> iter 77000, loss: 0.019403
 >> iter 78000, loss: 0.019327
 >> iter 79000, loss: 0.019231
 >> iter 80000, loss: 0.019159
   Number of active neurons: 7
 >> iter 81000, loss: 0.019080
 >> iter 82000, loss: 0.019038
 >> iter 83000, loss: 0.018975
 >> iter 84000, loss: 0.018953
 >> iter 85000, loss: 0.018900
 >> iter 86000, loss: 0.018892
 >> iter 87000, loss: 0.018840
 >> iter 88000, loss: 0.018827
 >> iter 89000, loss: 0.018774
 >> iter 90000, loss: 0.018774
   Number of active neurons: 7
 >> iter 91000, loss: 0.018726
 >> iter 92000, loss: 0.018737
 >> iter 93000, loss: 0.018692
 >> iter 94000, loss: 0.018694
 >> iter 95000, loss: 0.018643
 >> iter 96000, loss: 0.018641
 >> iter 97000, loss: 0.018599
 >> iter 98000, loss: 0.018603
 >> iter 99000, loss: 0.018567
 >> iter 100000, loss: 0.018576
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.519459
 >> iter 2000, loss: 10.466267
 >> iter 3000, loss: 8.606461
 >> iter 4000, loss: 7.896405
 >> iter 5000, loss: 7.672355
 >> iter 6000, loss: 7.489902
 >> iter 7000, loss: 4.403565
 >> iter 8000, loss: 1.685391
 >> iter 9000, loss: 0.655476
 >> iter 10000, loss: 0.266895
   Number of active neurons: 6
 >> iter 11000, loss: 0.119353
 >> iter 12000, loss: 0.062379
 >> iter 13000, loss: 0.039779
 >> iter 14000, loss: 0.030311
 >> iter 15000, loss: 0.026063
 >> iter 16000, loss: 0.023906
 >> iter 17000, loss: 0.022720
 >> iter 18000, loss: 0.021937
 >> iter 19000, loss: 0.021447
 >> iter 20000, loss: 0.021066
   Number of active neurons: 5
 >> iter 21000, loss: 0.020821
 >> iter 22000, loss: 0.020606
 >> iter 23000, loss: 0.020455
 >> iter 24000, loss: 0.020308
 >> iter 25000, loss: 0.020203
 >> iter 26000, loss: 0.020091
 >> iter 27000, loss: 0.020014
 >> iter 28000, loss: 0.019921
 >> iter 29000, loss: 0.019849
 >> iter 30000, loss: 0.019758
   Number of active neurons: 5
 >> iter 31000, loss: 0.019683
 >> iter 32000, loss: 0.019606
 >> iter 33000, loss: 0.019546
 >> iter 34000, loss: 0.019461
 >> iter 35000, loss: 0.019401
 >> iter 36000, loss: 0.019334
 >> iter 37000, loss: 0.019292
 >> iter 38000, loss: 0.019231
 >> iter 39000, loss: 0.019166
 >> iter 40000, loss: 0.019085
   Number of active neurons: 5
 >> iter 41000, loss: 0.019009
 >> iter 42000, loss: 0.018933
 >> iter 43000, loss: 0.018874
 >> iter 44000, loss: 0.018816
 >> iter 45000, loss: 0.018772
 >> iter 46000, loss: 0.018729
 >> iter 47000, loss: 0.018695
 >> iter 48000, loss: 0.018656
 >> iter 49000, loss: 0.018633
 >> iter 50000, loss: 0.018605
   Number of active neurons: 5
 >> iter 51000, loss: 0.018586
 >> iter 52000, loss: 0.018564
 >> iter 53000, loss: 0.018540
 >> iter 54000, loss: 0.018536
 >> iter 55000, loss: 0.018502
 >> iter 56000, loss: 0.018507
 >> iter 57000, loss: 0.018470
 >> iter 58000, loss: 0.018484
 >> iter 59000, loss: 0.018445
 >> iter 60000, loss: 0.018463
   Number of active neurons: 5
 >> iter 61000, loss: 0.018425
 >> iter 62000, loss: 0.018443
 >> iter 63000, loss: 0.018397
 >> iter 64000, loss: 0.018410
 >> iter 65000, loss: 0.018364
 >> iter 66000, loss: 0.018380
 >> iter 67000, loss: 0.018339
 >> iter 68000, loss: 0.018357
 >> iter 69000, loss: 0.018316
 >> iter 70000, loss: 0.018335
   Number of active neurons: 5
 >> iter 71000, loss: 0.018299
 >> iter 72000, loss: 0.018325
 >> iter 73000, loss: 0.018293
 >> iter 74000, loss: 0.018321
 >> iter 75000, loss: 0.018291
 >> iter 76000, loss: 0.018322
 >> iter 77000, loss: 0.018291
 >> iter 78000, loss: 0.018326
 >> iter 79000, loss: 0.018303
 >> iter 80000, loss: 0.018337
   Number of active neurons: 5
 >> iter 81000, loss: 0.018313
 >> iter 82000, loss: 0.018354
 >> iter 83000, loss: 0.018327
 >> iter 84000, loss: 0.018372
 >> iter 85000, loss: 0.018346
 >> iter 86000, loss: 0.018399
 >> iter 87000, loss: 0.018370
 >> iter 88000, loss: 0.018426
 >> iter 89000, loss: 0.018399
 >> iter 90000, loss: 0.018457
   Number of active neurons: 5
 >> iter 91000, loss: 0.018429
 >> iter 92000, loss: 0.018494
 >> iter 93000, loss: 0.018458
 >> iter 94000, loss: 0.018508
 >> iter 95000, loss: 0.018476
 >> iter 96000, loss: 0.018521
 >> iter 97000, loss: 0.018499
 >> iter 98000, loss: 0.018549
 >> iter 99000, loss: 0.018535
 >> iter 100000, loss: 0.018589
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.519224
 >> iter 2000, loss: 10.475899
 >> iter 3000, loss: 8.619132
 >> iter 4000, loss: 7.903455
 >> iter 5000, loss: 7.693906
 >> iter 6000, loss: 7.373583
 >> iter 7000, loss: 4.867307
 >> iter 8000, loss: 1.842997
 >> iter 9000, loss: 0.707970
 >> iter 10000, loss: 0.283567
   Number of active neurons: 9
 >> iter 11000, loss: 0.124489
 >> iter 12000, loss: 0.064004
 >> iter 13000, loss: 0.040715
 >> iter 14000, loss: 0.031208
 >> iter 15000, loss: 0.027243
 >> iter 16000, loss: 0.025233
 >> iter 17000, loss: 0.024240
 >> iter 18000, loss: 0.023484
 >> iter 19000, loss: 0.023050
 >> iter 20000, loss: 0.022608
   Number of active neurons: 8
 >> iter 21000, loss: 0.022373
 >> iter 22000, loss: 0.022072
 >> iter 23000, loss: 0.021879
 >> iter 24000, loss: 0.021613
 >> iter 25000, loss: 0.021444
 >> iter 26000, loss: 0.021197
 >> iter 27000, loss: 0.021031
 >> iter 28000, loss: 0.020808
 >> iter 29000, loss: 0.020662
 >> iter 30000, loss: 0.020455
   Number of active neurons: 6
 >> iter 31000, loss: 0.020325
 >> iter 32000, loss: 0.020159
 >> iter 33000, loss: 0.020051
 >> iter 34000, loss: 0.019908
 >> iter 35000, loss: 0.019818
 >> iter 36000, loss: 0.019686
 >> iter 37000, loss: 0.019602
 >> iter 38000, loss: 0.019522
 >> iter 39000, loss: 0.019459
 >> iter 40000, loss: 0.019381
   Number of active neurons: 6
 >> iter 41000, loss: 0.019309
 >> iter 42000, loss: 0.019217
 >> iter 43000, loss: 0.019132
 >> iter 44000, loss: 0.019038
 >> iter 45000, loss: 0.018949
 >> iter 46000, loss: 0.018863
 >> iter 47000, loss: 0.018786
 >> iter 48000, loss: 0.018706
 >> iter 49000, loss: 0.018638
 >> iter 50000, loss: 0.018571
   Number of active neurons: 6
 >> iter 51000, loss: 0.018512
 >> iter 52000, loss: 0.018430
 >> iter 53000, loss: 0.018358
 >> iter 54000, loss: 0.018300
 >> iter 55000, loss: 0.018221
 >> iter 56000, loss: 0.018180
 >> iter 57000, loss: 0.018098
 >> iter 58000, loss: 0.018083
 >> iter 59000, loss: 0.017996
 >> iter 60000, loss: 0.017993
   Number of active neurons: 6
 >> iter 61000, loss: 0.017904
 >> iter 62000, loss: 0.017902
 >> iter 63000, loss: 0.017801
 >> iter 64000, loss: 0.017795
 >> iter 65000, loss: 0.017691
 >> iter 66000, loss: 0.017708
 >> iter 67000, loss: 0.017609
 >> iter 68000, loss: 0.017642
 >> iter 69000, loss: 0.017544
 >> iter 70000, loss: 0.017577
   Number of active neurons: 6
 >> iter 71000, loss: 0.017479
 >> iter 72000, loss: 0.017514
 >> iter 73000, loss: 0.017412
 >> iter 74000, loss: 0.017444
 >> iter 75000, loss: 0.017341
 >> iter 76000, loss: 0.017381
 >> iter 77000, loss: 0.017267
 >> iter 78000, loss: 0.017289
 >> iter 79000, loss: 0.017175
 >> iter 80000, loss: 0.017195
   Number of active neurons: 7
 >> iter 81000, loss: 0.017088
 >> iter 82000, loss: 0.017124
 >> iter 83000, loss: 0.017017
 >> iter 84000, loss: 0.017064
 >> iter 85000, loss: 0.016965
 >> iter 86000, loss: 0.017019
 >> iter 87000, loss: 0.016923
 >> iter 88000, loss: 0.016980
 >> iter 89000, loss: 0.016887
 >> iter 90000, loss: 0.016946
   Number of active neurons: 7
 >> iter 91000, loss: 0.016853
 >> iter 92000, loss: 0.016919
 >> iter 93000, loss: 0.016821
 >> iter 94000, loss: 0.016888
 >> iter 95000, loss: 0.016801
 >> iter 96000, loss: 0.016862
 >> iter 97000, loss: 0.016777
 >> iter 98000, loss: 0.016837
 >> iter 99000, loss: 0.016728
 >> iter 100000, loss: 0.016768
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.518602
 >> iter 2000, loss: 10.482670
 >> iter 3000, loss: 8.624118
 >> iter 4000, loss: 7.901640
 >> iter 5000, loss: 7.654568
 >> iter 6000, loss: 7.332097
 >> iter 7000, loss: 6.689388
 >> iter 8000, loss: 5.029510
 >> iter 9000, loss: 1.986392
 >> iter 10000, loss: 0.777608
   Number of active neurons: 8
 >> iter 11000, loss: 0.317734
 >> iter 12000, loss: 0.141664
 >> iter 13000, loss: 0.073628
 >> iter 14000, loss: 0.045800
 >> iter 15000, loss: 0.033762
 >> iter 16000, loss: 0.027455
 >> iter 17000, loss: 0.024325
 >> iter 18000, loss: 0.022527
 >> iter 19000, loss: 0.021727
 >> iter 20000, loss: 0.021136
   Number of active neurons: 8
 >> iter 21000, loss: 0.020901
 >> iter 22000, loss: 0.020651
 >> iter 23000, loss: 0.020613
 >> iter 24000, loss: 0.020455
 >> iter 25000, loss: 0.020416
 >> iter 26000, loss: 0.020271
 >> iter 27000, loss: 0.020208
 >> iter 28000, loss: 0.020057
 >> iter 29000, loss: 0.020015
 >> iter 30000, loss: 0.019923
   Number of active neurons: 8
 >> iter 31000, loss: 0.019929
 >> iter 32000, loss: 0.019873
 >> iter 33000, loss: 0.019875
 >> iter 34000, loss: 0.019828
 >> iter 35000, loss: 0.019829
 >> iter 36000, loss: 0.019791
 >> iter 37000, loss: 0.019781
 >> iter 38000, loss: 0.019731
 >> iter 39000, loss: 0.019698
 >> iter 40000, loss: 0.019651
   Number of active neurons: 8
 >> iter 41000, loss: 0.019603
 >> iter 42000, loss: 0.019558
 >> iter 43000, loss: 0.019539
 >> iter 44000, loss: 0.019474
 >> iter 45000, loss: 0.019441
 >> iter 46000, loss: 0.019361
 >> iter 47000, loss: 0.019287
 >> iter 48000, loss: 0.019269
 >> iter 49000, loss: 0.019228
 >> iter 50000, loss: 0.019228
   Number of active neurons: 8
 >> iter 51000, loss: 0.019195
 >> iter 52000, loss: 0.019201
 >> iter 53000, loss: 0.019165
 >> iter 54000, loss: 0.019171
 >> iter 55000, loss: 0.019103
 >> iter 56000, loss: 0.019100
 >> iter 57000, loss: 0.019029
 >> iter 58000, loss: 0.019044
 >> iter 59000, loss: 0.018978
 >> iter 60000, loss: 0.018995
   Number of active neurons: 8
 >> iter 61000, loss: 0.018917
 >> iter 62000, loss: 0.018947
 >> iter 63000, loss: 0.018873
 >> iter 64000, loss: 0.018917
 >> iter 65000, loss: 0.018837
 >> iter 66000, loss: 0.018852
 >> iter 67000, loss: 0.018749
 >> iter 68000, loss: 0.018783
 >> iter 69000, loss: 0.018696
 >> iter 70000, loss: 0.018743
   Number of active neurons: 8
 >> iter 71000, loss: 0.018660
 >> iter 72000, loss: 0.018714
 >> iter 73000, loss: 0.018636
 >> iter 74000, loss: 0.018686
 >> iter 75000, loss: 0.018610
 >> iter 76000, loss: 0.018654
 >> iter 77000, loss: 0.018581
 >> iter 78000, loss: 0.018624
 >> iter 79000, loss: 0.018549
 >> iter 80000, loss: 0.018590
   Number of active neurons: 8
 >> iter 81000, loss: 0.018508
 >> iter 82000, loss: 0.018536
 >> iter 83000, loss: 0.018435
 >> iter 84000, loss: 0.018458
 >> iter 85000, loss: 0.018364
 >> iter 86000, loss: 0.018391
 >> iter 87000, loss: 0.018306
 >> iter 88000, loss: 0.018333
 >> iter 89000, loss: 0.018252
 >> iter 90000, loss: 0.018279
   Number of active neurons: 8
 >> iter 91000, loss: 0.018197
 >> iter 92000, loss: 0.018223
 >> iter 93000, loss: 0.018136
 >> iter 94000, loss: 0.018133
 >> iter 95000, loss: 0.018000
 >> iter 96000, loss: 0.017971
 >> iter 97000, loss: 0.017848
 >> iter 98000, loss: 0.017834
 >> iter 99000, loss: 0.017716
 >> iter 100000, loss: 0.017691
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.531049
 >> iter 2000, loss: 10.476410
 >> iter 3000, loss: 8.618158
 >> iter 4000, loss: 7.904472
 >> iter 5000, loss: 7.708324
 >> iter 6000, loss: 7.566658
 >> iter 7000, loss: 7.240229
 >> iter 8000, loss: 6.226950
 >> iter 9000, loss: 2.371796
 >> iter 10000, loss: 0.904113
   Number of active neurons: 7
 >> iter 11000, loss: 0.355697
 >> iter 12000, loss: 0.150117
 >> iter 13000, loss: 0.072546
 >> iter 14000, loss: 0.042704
 >> iter 15000, loss: 0.030983
 >> iter 16000, loss: 0.026056
 >> iter 17000, loss: 0.023897
 >> iter 18000, loss: 0.022772
 >> iter 19000, loss: 0.022195
 >> iter 20000, loss: 0.021779
   Number of active neurons: 7
 >> iter 21000, loss: 0.021542
 >> iter 22000, loss: 0.021288
 >> iter 23000, loss: 0.021118
 >> iter 24000, loss: 0.020946
 >> iter 25000, loss: 0.020816
 >> iter 26000, loss: 0.020684
 >> iter 27000, loss: 0.020574
 >> iter 28000, loss: 0.020472
 >> iter 29000, loss: 0.020375
 >> iter 30000, loss: 0.020292
   Number of active neurons: 7
 >> iter 31000, loss: 0.020205
 >> iter 32000, loss: 0.020145
 >> iter 33000, loss: 0.020076
 >> iter 34000, loss: 0.020032
 >> iter 35000, loss: 0.019974
 >> iter 36000, loss: 0.019952
 >> iter 37000, loss: 0.019887
 >> iter 38000, loss: 0.019884
 >> iter 39000, loss: 0.019812
 >> iter 40000, loss: 0.019818
   Number of active neurons: 7
 >> iter 41000, loss: 0.019736
 >> iter 42000, loss: 0.019708
 >> iter 43000, loss: 0.019581
 >> iter 44000, loss: 0.019515
 >> iter 45000, loss: 0.019373
 >> iter 46000, loss: 0.019307
 >> iter 47000, loss: 0.019182
 >> iter 48000, loss: 0.019139
 >> iter 49000, loss: 0.019045
 >> iter 50000, loss: 0.019024
   Number of active neurons: 7
 >> iter 51000, loss: 0.018946
 >> iter 52000, loss: 0.018936
 >> iter 53000, loss: 0.018855
 >> iter 54000, loss: 0.018862
 >> iter 55000, loss: 0.018775
 >> iter 56000, loss: 0.018793
 >> iter 57000, loss: 0.018700
 >> iter 58000, loss: 0.018727
 >> iter 59000, loss: 0.018629
 >> iter 60000, loss: 0.018659
   Number of active neurons: 7
 >> iter 61000, loss: 0.018554
 >> iter 62000, loss: 0.018585
 >> iter 63000, loss: 0.018490
 >> iter 64000, loss: 0.018536
 >> iter 65000, loss: 0.018443
 >> iter 66000, loss: 0.018491
 >> iter 67000, loss: 0.018399
 >> iter 68000, loss: 0.018451
 >> iter 69000, loss: 0.018357
 >> iter 70000, loss: 0.018405
   Number of active neurons: 7
 >> iter 71000, loss: 0.018312
 >> iter 72000, loss: 0.018364
 >> iter 73000, loss: 0.018270
 >> iter 74000, loss: 0.018323
 >> iter 75000, loss: 0.018228
 >> iter 76000, loss: 0.018274
 >> iter 77000, loss: 0.018171
 >> iter 78000, loss: 0.018222
 >> iter 79000, loss: 0.018117
 >> iter 80000, loss: 0.018152
   Number of active neurons: 7
 >> iter 81000, loss: 0.018039
 >> iter 82000, loss: 0.018082
 >> iter 83000, loss: 0.017974
 >> iter 84000, loss: 0.018031
 >> iter 85000, loss: 0.017929
 >> iter 86000, loss: 0.017997
 >> iter 87000, loss: 0.017899
 >> iter 88000, loss: 0.017973
 >> iter 89000, loss: 0.017878
 >> iter 90000, loss: 0.017956
   Number of active neurons: 7
 >> iter 91000, loss: 0.017861
 >> iter 92000, loss: 0.017948
 >> iter 93000, loss: 0.017843
 >> iter 94000, loss: 0.017920
 >> iter 95000, loss: 0.017825
 >> iter 96000, loss: 0.017907
 >> iter 97000, loss: 0.017828
 >> iter 98000, loss: 0.017918
 >> iter 99000, loss: 0.017842
 >> iter 100000, loss: 0.017925
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.577647
 >> iter 2000, loss: 10.520207
 >> iter 3000, loss: 8.652975
 >> iter 4000, loss: 7.933015
 >> iter 5000, loss: 7.682786
 >> iter 6000, loss: 7.457481
 >> iter 7000, loss: 5.270343
 >> iter 8000, loss: 2.027192
 >> iter 9000, loss: 0.784174
 >> iter 10000, loss: 0.316193
   Number of active neurons: 8
 >> iter 11000, loss: 0.139582
 >> iter 12000, loss: 0.072245
 >> iter 13000, loss: 0.045850
 >> iter 14000, loss: 0.035536
 >> iter 15000, loss: 0.030679
 >> iter 16000, loss: 0.028664
 >> iter 17000, loss: 0.027305
 >> iter 18000, loss: 0.026781
 >> iter 19000, loss: 0.026101
 >> iter 20000, loss: 0.025672
   Number of active neurons: 8
 >> iter 21000, loss: 0.025372
 >> iter 22000, loss: 0.025109
 >> iter 23000, loss: 0.024956
 >> iter 24000, loss: 0.024777
 >> iter 25000, loss: 0.024679
 >> iter 26000, loss: 0.024552
 >> iter 27000, loss: 0.024473
 >> iter 28000, loss: 0.024371
 >> iter 29000, loss: 0.024310
 >> iter 30000, loss: 0.024249
   Number of active neurons: 8
 >> iter 31000, loss: 0.024227
 >> iter 32000, loss: 0.024173
 >> iter 33000, loss: 0.024202
 >> iter 34000, loss: 0.024095
 >> iter 35000, loss: 0.024118
 >> iter 36000, loss: 0.023921
 >> iter 37000, loss: 0.023930
 >> iter 38000, loss: 0.023609
 >> iter 39000, loss: 0.023648
 >> iter 40000, loss: 0.023307
   Number of active neurons: 8
 >> iter 41000, loss: 0.023384
 >> iter 42000, loss: 0.023062
 >> iter 43000, loss: 0.023175
 >> iter 44000, loss: 0.022842
 >> iter 45000, loss: 0.022964
 >> iter 46000, loss: 0.022627
 >> iter 47000, loss: 0.022795
 >> iter 48000, loss: 0.022424
 >> iter 49000, loss: 0.022633
 >> iter 50000, loss: 0.022222
   Number of active neurons: 8
 >> iter 51000, loss: 0.022481
 >> iter 52000, loss: 0.021993
 >> iter 53000, loss: 0.022256
 >> iter 54000, loss: 0.021657
 >> iter 55000, loss: 0.021938
 >> iter 56000, loss: 0.021340
 >> iter 57000, loss: 0.021673
 >> iter 58000, loss: 0.021090
 >> iter 59000, loss: 0.021448
 >> iter 60000, loss: 0.020873
   Number of active neurons: 8
 >> iter 61000, loss: 0.021155
 >> iter 62000, loss: 0.020685
 >> iter 63000, loss: 0.020908
 >> iter 64000, loss: 0.020565
 >> iter 65000, loss: 0.020699
 >> iter 66000, loss: 0.020426
 >> iter 67000, loss: 0.020489
 >> iter 68000, loss: 0.020322
 >> iter 69000, loss: 0.020359
 >> iter 70000, loss: 0.020216
   Number of active neurons: 8
 >> iter 71000, loss: 0.020245
 >> iter 72000, loss: 0.020080
 >> iter 73000, loss: 0.020097
 >> iter 74000, loss: 0.019909
 >> iter 75000, loss: 0.019914
 >> iter 76000, loss: 0.019737
 >> iter 77000, loss: 0.019727
 >> iter 78000, loss: 0.019573
 >> iter 79000, loss: 0.019529
 >> iter 80000, loss: 0.019422
   Number of active neurons: 7
 >> iter 81000, loss: 0.019346
 >> iter 82000, loss: 0.019293
 >> iter 83000, loss: 0.019187
 >> iter 84000, loss: 0.019174
 >> iter 85000, loss: 0.019033
 >> iter 86000, loss: 0.019064
 >> iter 87000, loss: 0.018889
 >> iter 88000, loss: 0.018954
 >> iter 89000, loss: 0.018743
 >> iter 90000, loss: 0.018841
   Number of active neurons: 7
 >> iter 91000, loss: 0.018603
 >> iter 92000, loss: 0.018720
 >> iter 93000, loss: 0.018458
 >> iter 94000, loss: 0.018572
 >> iter 95000, loss: 0.018294
 >> iter 96000, loss: 0.018412
 >> iter 97000, loss: 0.018136
 >> iter 98000, loss: 0.018256
 >> iter 99000, loss: 0.017974
 >> iter 100000, loss: 0.018089
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.293313779081
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 15.529088
 >> iter 2000, loss: 10.496067
 >> iter 3000, loss: 8.638713
 >> iter 4000, loss: 7.924442
 >> iter 5000, loss: 7.698527
 >> iter 6000, loss: 7.681262
 >> iter 7000, loss: 5.748497
 >> iter 8000, loss: 2.207423
 >> iter 9000, loss: 0.854557
 >> iter 10000, loss: 0.345502
   Number of active neurons: 10
 >> iter 11000, loss: 0.153468
 >> iter 12000, loss: 0.080090
 >> iter 13000, loss: 0.051487
 >> iter 14000, loss: 0.039715
 >> iter 15000, loss: 0.034673
 >> iter 16000, loss: 0.032154
 >> iter 17000, loss: 0.030881
 >> iter 18000, loss: 0.029990
 >> iter 19000, loss: 0.029433
 >> iter 20000, loss: 0.028876
   Number of active neurons: 9
 >> iter 21000, loss: 0.028526
 >> iter 22000, loss: 0.028139
 >> iter 23000, loss: 0.027908
 >> iter 24000, loss: 0.027611
 >> iter 25000, loss: 0.027441
 >> iter 26000, loss: 0.027142
 >> iter 27000, loss: 0.026956
 >> iter 28000, loss: 0.026570
 >> iter 29000, loss: 0.026377
 >> iter 30000, loss: 0.025920
   Number of active neurons: 8
 >> iter 31000, loss: 0.025733
 >> iter 32000, loss: 0.025234
 >> iter 33000, loss: 0.025049
 >> iter 34000, loss: 0.024491
 >> iter 35000, loss: 0.024227
 >> iter 36000, loss: 0.023680
 >> iter 37000, loss: 0.023351
 >> iter 38000, loss: 0.022833
 >> iter 39000, loss: 0.022492
 >> iter 40000, loss: 0.022054
   Number of active neurons: 8
 >> iter 41000, loss: 0.021736
 >> iter 42000, loss: 0.021390
 >> iter 43000, loss: 0.021134
 >> iter 44000, loss: 0.020866
 >> iter 45000, loss: 0.020653
 >> iter 46000, loss: 0.020438
 >> iter 47000, loss: 0.020240
 >> iter 48000, loss: 0.020049
 >> iter 49000, loss: 0.019855
 >> iter 50000, loss: 0.019668
   Number of active neurons: 8
 >> iter 51000, loss: 0.019482
 >> iter 52000, loss: 0.019320
 >> iter 53000, loss: 0.019164
 >> iter 54000, loss: 0.019023
 >> iter 55000, loss: 0.018874
 >> iter 56000, loss: 0.018751
 >> iter 57000, loss: 0.018617
 >> iter 58000, loss: 0.018511
 >> iter 59000, loss: 0.018382
 >> iter 60000, loss: 0.018300
   Number of active neurons: 7
 >> iter 61000, loss: 0.018177
 >> iter 62000, loss: 0.018089
 >> iter 63000, loss: 0.017955
 >> iter 64000, loss: 0.017888
 >> iter 65000, loss: 0.017775
 >> iter 66000, loss: 0.017717
 >> iter 67000, loss: 0.017600
 >> iter 68000, loss: 0.017543
 >> iter 69000, loss: 0.017444
 >> iter 70000, loss: 0.017407
   Number of active neurons: 8
 >> iter 71000, loss: 0.017325
 >> iter 72000, loss: 0.017278
 >> iter 73000, loss: 0.017177
 >> iter 74000, loss: 0.017121
 >> iter 75000, loss: 0.017020
 >> iter 76000, loss: 0.016973
 >> iter 77000, loss: 0.016879
 >> iter 78000, loss: 0.016849
 >> iter 79000, loss: 0.016771
 >> iter 80000, loss: 0.016758
   Number of active neurons: 7
 >> iter 81000, loss: 0.016686
 >> iter 82000, loss: 0.016687
 >> iter 83000, loss: 0.016619
 >> iter 84000, loss: 0.016629
 >> iter 85000, loss: 0.016562
 >> iter 86000, loss: 0.016579
 >> iter 87000, loss: 0.016522
 >> iter 88000, loss: 0.016557
 >> iter 89000, loss: 0.016505
 >> iter 90000, loss: 0.016551
   Number of active neurons: 7
 >> iter 91000, loss: 0.016498
 >> iter 92000, loss: 0.016548
 >> iter 93000, loss: 0.016494
 >> iter 94000, loss: 0.016540
 >> iter 95000, loss: 0.016489
 >> iter 96000, loss: 0.016537
 >> iter 97000, loss: 0.016483
 >> iter 98000, loss: 0.016534
 >> iter 99000, loss: 0.016478
 >> iter 100000, loss: 0.016532
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.603072
 >> iter 2000, loss: 10.526571
 >> iter 3000, loss: 8.647818
 >> iter 4000, loss: 7.923165
 >> iter 5000, loss: 7.727238
 >> iter 6000, loss: 7.695815
 >> iter 7000, loss: 7.314764
 >> iter 8000, loss: 6.548058
 >> iter 9000, loss: 2.513728
 >> iter 10000, loss: 0.958021
   Number of active neurons: 8
 >> iter 11000, loss: 0.376495
 >> iter 12000, loss: 0.158415
 >> iter 13000, loss: 0.076392
 >> iter 14000, loss: 0.044761
 >> iter 15000, loss: 0.032556
 >> iter 16000, loss: 0.027307
 >> iter 17000, loss: 0.025177
 >> iter 18000, loss: 0.023871
 >> iter 19000, loss: 0.023316
 >> iter 20000, loss: 0.022706
   Number of active neurons: 8
 >> iter 21000, loss: 0.022465
 >> iter 22000, loss: 0.022037
 >> iter 23000, loss: 0.021886
 >> iter 24000, loss: 0.021536
 >> iter 25000, loss: 0.021412
 >> iter 26000, loss: 0.021104
 >> iter 27000, loss: 0.021013
 >> iter 28000, loss: 0.020785
 >> iter 29000, loss: 0.020776
 >> iter 30000, loss: 0.020643
   Number of active neurons: 8
 >> iter 31000, loss: 0.020678
 >> iter 32000, loss: 0.020590
 >> iter 33000, loss: 0.020617
 >> iter 34000, loss: 0.020504
 >> iter 35000, loss: 0.020509
 >> iter 36000, loss: 0.020397
 >> iter 37000, loss: 0.020375
 >> iter 38000, loss: 0.020246
 >> iter 39000, loss: 0.020199
 >> iter 40000, loss: 0.020086
   Number of active neurons: 7
 >> iter 41000, loss: 0.020043
 >> iter 42000, loss: 0.019934
 >> iter 43000, loss: 0.019887
 >> iter 44000, loss: 0.019774
 >> iter 45000, loss: 0.019731
 >> iter 46000, loss: 0.019619
 >> iter 47000, loss: 0.019563
 >> iter 48000, loss: 0.019444
 >> iter 49000, loss: 0.019383
 >> iter 50000, loss: 0.019247
   Number of active neurons: 7
 >> iter 51000, loss: 0.019182
 >> iter 52000, loss: 0.019048
 >> iter 53000, loss: 0.018980
 >> iter 54000, loss: 0.018880
 >> iter 55000, loss: 0.018818
 >> iter 56000, loss: 0.018736
 >> iter 57000, loss: 0.018680
 >> iter 58000, loss: 0.018620
 >> iter 59000, loss: 0.018572
 >> iter 60000, loss: 0.018534
   Number of active neurons: 7
 >> iter 61000, loss: 0.018498
 >> iter 62000, loss: 0.018468
 >> iter 63000, loss: 0.018436
 >> iter 64000, loss: 0.018420
 >> iter 65000, loss: 0.018379
 >> iter 66000, loss: 0.018346
 >> iter 67000, loss: 0.018299
 >> iter 68000, loss: 0.018274
 >> iter 69000, loss: 0.018229
 >> iter 70000, loss: 0.018211
   Number of active neurons: 7
 >> iter 71000, loss: 0.018160
 >> iter 72000, loss: 0.018142
 >> iter 73000, loss: 0.018097
 >> iter 74000, loss: 0.018095
 >> iter 75000, loss: 0.018054
 >> iter 76000, loss: 0.018063
 >> iter 77000, loss: 0.018022
 >> iter 78000, loss: 0.018039
 >> iter 79000, loss: 0.018001
 >> iter 80000, loss: 0.018022
   Number of active neurons: 7
 >> iter 81000, loss: 0.017982
 >> iter 82000, loss: 0.018006
 >> iter 83000, loss: 0.017961
 >> iter 84000, loss: 0.017992
 >> iter 85000, loss: 0.017943
 >> iter 86000, loss: 0.017983
 >> iter 87000, loss: 0.017928
 >> iter 88000, loss: 0.017970
 >> iter 89000, loss: 0.017916
 >> iter 90000, loss: 0.017961
   Number of active neurons: 7
 >> iter 91000, loss: 0.017903
 >> iter 92000, loss: 0.017953
 >> iter 93000, loss: 0.017874
 >> iter 94000, loss: 0.017912
 >> iter 95000, loss: 0.017845
 >> iter 96000, loss: 0.017888
 >> iter 97000, loss: 0.017832
 >> iter 98000, loss: 0.017881
 >> iter 99000, loss: 0.017830
 >> iter 100000, loss: 0.017881
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.543204
 >> iter 2000, loss: 10.495885
 >> iter 3000, loss: 8.634430
 >> iter 4000, loss: 7.922055
 >> iter 5000, loss: 7.716006
 >> iter 6000, loss: 7.297786
 >> iter 7000, loss: 5.672144
 >> iter 8000, loss: 2.155495
 >> iter 9000, loss: 0.824278
 >> iter 10000, loss: 0.326231
   Number of active neurons: 8
 >> iter 11000, loss: 0.139712
 >> iter 12000, loss: 0.068958
 >> iter 13000, loss: 0.041831
 >> iter 14000, loss: 0.030861
 >> iter 15000, loss: 0.026258
 >> iter 16000, loss: 0.023969
 >> iter 17000, loss: 0.022745
 >> iter 18000, loss: 0.021849
 >> iter 19000, loss: 0.021268
 >> iter 20000, loss: 0.020751
   Number of active neurons: 7
 >> iter 21000, loss: 0.020422
 >> iter 22000, loss: 0.020103
 >> iter 23000, loss: 0.019911
 >> iter 24000, loss: 0.019674
 >> iter 25000, loss: 0.019506
 >> iter 26000, loss: 0.019290
 >> iter 27000, loss: 0.019158
 >> iter 28000, loss: 0.018992
 >> iter 29000, loss: 0.018902
 >> iter 30000, loss: 0.018787
   Number of active neurons: 6
 >> iter 31000, loss: 0.018749
 >> iter 32000, loss: 0.018664
 >> iter 33000, loss: 0.018641
 >> iter 34000, loss: 0.018565
 >> iter 35000, loss: 0.018547
 >> iter 36000, loss: 0.018482
 >> iter 37000, loss: 0.018446
 >> iter 38000, loss: 0.018368
 >> iter 39000, loss: 0.018313
 >> iter 40000, loss: 0.018259
   Number of active neurons: 6
 >> iter 41000, loss: 0.018212
 >> iter 42000, loss: 0.018164
 >> iter 43000, loss: 0.018120
 >> iter 44000, loss: 0.018082
 >> iter 45000, loss: 0.018040
 >> iter 46000, loss: 0.018008
 >> iter 47000, loss: 0.017965
 >> iter 48000, loss: 0.017933
 >> iter 49000, loss: 0.017891
 >> iter 50000, loss: 0.017863
   Number of active neurons: 6
 >> iter 51000, loss: 0.017821
 >> iter 52000, loss: 0.017796
 >> iter 53000, loss: 0.017747
 >> iter 54000, loss: 0.017721
 >> iter 55000, loss: 0.017647
 >> iter 56000, loss: 0.017629
 >> iter 57000, loss: 0.017555
 >> iter 58000, loss: 0.017550
 >> iter 59000, loss: 0.017478
 >> iter 60000, loss: 0.017482
   Number of active neurons: 6
 >> iter 61000, loss: 0.017414
 >> iter 62000, loss: 0.017411
 >> iter 63000, loss: 0.017311
 >> iter 64000, loss: 0.017293
 >> iter 65000, loss: 0.017188
 >> iter 66000, loss: 0.017189
 >> iter 67000, loss: 0.017093
 >> iter 68000, loss: 0.017117
 >> iter 69000, loss: 0.017029
 >> iter 70000, loss: 0.017060
   Number of active neurons: 6
 >> iter 71000, loss: 0.016976
 >> iter 72000, loss: 0.017016
 >> iter 73000, loss: 0.016935
 >> iter 74000, loss: 0.016979
 >> iter 75000, loss: 0.016896
 >> iter 76000, loss: 0.016943
 >> iter 77000, loss: 0.016861
 >> iter 78000, loss: 0.016912
 >> iter 79000, loss: 0.016844
 >> iter 80000, loss: 0.016885
   Number of active neurons: 6
 >> iter 81000, loss: 0.016814
 >> iter 82000, loss: 0.016863
 >> iter 83000, loss: 0.016782
 >> iter 84000, loss: 0.016837
 >> iter 85000, loss: 0.016756
 >> iter 86000, loss: 0.016813
 >> iter 87000, loss: 0.016730
 >> iter 88000, loss: 0.016789
 >> iter 89000, loss: 0.016706
 >> iter 90000, loss: 0.016766
   Number of active neurons: 6
 >> iter 91000, loss: 0.016680
 >> iter 92000, loss: 0.016746
 >> iter 93000, loss: 0.016653
 >> iter 94000, loss: 0.016721
 >> iter 95000, loss: 0.016637
 >> iter 96000, loss: 0.016699
 >> iter 97000, loss: 0.016616
 >> iter 98000, loss: 0.016679
 >> iter 99000, loss: 0.016594
 >> iter 100000, loss: 0.016656
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.588453
 >> iter 2000, loss: 10.511746
 >> iter 3000, loss: 8.641022
 >> iter 4000, loss: 7.925649
 >> iter 5000, loss: 7.700862
 >> iter 6000, loss: 7.348073
 >> iter 7000, loss: 4.391796
 >> iter 8000, loss: 1.660698
 >> iter 9000, loss: 0.637813
 >> iter 10000, loss: 0.255873
   Number of active neurons: 8
 >> iter 11000, loss: 0.112702
 >> iter 12000, loss: 0.058430
 >> iter 13000, loss: 0.037513
 >> iter 14000, loss: 0.029158
 >> iter 15000, loss: 0.025726
 >> iter 16000, loss: 0.024118
 >> iter 17000, loss: 0.023282
 >> iter 18000, loss: 0.022712
 >> iter 19000, loss: 0.022374
 >> iter 20000, loss: 0.022033
   Number of active neurons: 6
 >> iter 21000, loss: 0.021771
 >> iter 22000, loss: 0.021472
 >> iter 23000, loss: 0.021231
 >> iter 24000, loss: 0.020979
 >> iter 25000, loss: 0.020754
 >> iter 26000, loss: 0.020518
 >> iter 27000, loss: 0.020322
 >> iter 28000, loss: 0.020120
 >> iter 29000, loss: 0.019941
 >> iter 30000, loss: 0.019784
   Number of active neurons: 6
 >> iter 31000, loss: 0.019662
 >> iter 32000, loss: 0.019545
 >> iter 33000, loss: 0.019459
 >> iter 34000, loss: 0.019361
 >> iter 35000, loss: 0.019294
 >> iter 36000, loss: 0.019205
 >> iter 37000, loss: 0.019147
 >> iter 38000, loss: 0.019072
 >> iter 39000, loss: 0.019018
 >> iter 40000, loss: 0.018949
   Number of active neurons: 6
 >> iter 41000, loss: 0.018900
 >> iter 42000, loss: 0.018831
 >> iter 43000, loss: 0.018788
 >> iter 44000, loss: 0.018722
 >> iter 45000, loss: 0.018681
 >> iter 46000, loss: 0.018605
 >> iter 47000, loss: 0.018544
 >> iter 48000, loss: 0.018458
 >> iter 49000, loss: 0.018398
 >> iter 50000, loss: 0.018309
   Number of active neurons: 6
 >> iter 51000, loss: 0.018251
 >> iter 52000, loss: 0.018175
 >> iter 53000, loss: 0.018120
 >> iter 54000, loss: 0.018060
 >> iter 55000, loss: 0.017992
 >> iter 56000, loss: 0.017941
 >> iter 57000, loss: 0.017857
 >> iter 58000, loss: 0.017805
 >> iter 59000, loss: 0.017721
 >> iter 60000, loss: 0.017681
   Number of active neurons: 6
 >> iter 61000, loss: 0.017609
 >> iter 62000, loss: 0.017583
 >> iter 63000, loss: 0.017521
 >> iter 64000, loss: 0.017511
 >> iter 65000, loss: 0.017454
 >> iter 66000, loss: 0.017449
 >> iter 67000, loss: 0.017395
 >> iter 68000, loss: 0.017399
 >> iter 69000, loss: 0.017344
 >> iter 70000, loss: 0.017337
   Number of active neurons: 6
 >> iter 71000, loss: 0.017264
 >> iter 72000, loss: 0.017254
 >> iter 73000, loss: 0.017187
 >> iter 74000, loss: 0.017186
 >> iter 75000, loss: 0.017125
 >> iter 76000, loss: 0.017131
 >> iter 77000, loss: 0.017073
 >> iter 78000, loss: 0.017085
 >> iter 79000, loss: 0.017033
 >> iter 80000, loss: 0.017047
   Number of active neurons: 6
 >> iter 81000, loss: 0.016993
 >> iter 82000, loss: 0.017012
 >> iter 83000, loss: 0.016954
 >> iter 84000, loss: 0.016979
 >> iter 85000, loss: 0.016919
 >> iter 86000, loss: 0.016950
 >> iter 87000, loss: 0.016887
 >> iter 88000, loss: 0.016920
 >> iter 89000, loss: 0.016856
 >> iter 90000, loss: 0.016891
   Number of active neurons: 6
 >> iter 91000, loss: 0.016824
 >> iter 92000, loss: 0.016865
 >> iter 93000, loss: 0.016794
 >> iter 94000, loss: 0.016834
 >> iter 95000, loss: 0.016771
 >> iter 96000, loss: 0.016807
 >> iter 97000, loss: 0.016744
 >> iter 98000, loss: 0.016780
 >> iter 99000, loss: 0.016719
 >> iter 100000, loss: 0.016754
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.601881
 >> iter 2000, loss: 10.508479
 >> iter 3000, loss: 8.631563
 >> iter 4000, loss: 7.908762
 >> iter 5000, loss: 7.625987
 >> iter 6000, loss: 4.732278
 >> iter 7000, loss: 1.802338
 >> iter 8000, loss: 0.695890
 >> iter 9000, loss: 0.280461
 >> iter 10000, loss: 0.123490
   Number of active neurons: 6
 >> iter 11000, loss: 0.063581
 >> iter 12000, loss: 0.040044
 >> iter 13000, loss: 0.030538
 >> iter 14000, loss: 0.026335
 >> iter 15000, loss: 0.024412
 >> iter 16000, loss: 0.023329
 >> iter 17000, loss: 0.022773
 >> iter 18000, loss: 0.022334
 >> iter 19000, loss: 0.022097
 >> iter 20000, loss: 0.021851
   Number of active neurons: 6
 >> iter 21000, loss: 0.021754
 >> iter 22000, loss: 0.021626
 >> iter 23000, loss: 0.021574
 >> iter 24000, loss: 0.021440
 >> iter 25000, loss: 0.021364
 >> iter 26000, loss: 0.021239
 >> iter 27000, loss: 0.021190
 >> iter 28000, loss: 0.021099
 >> iter 29000, loss: 0.021050
 >> iter 30000, loss: 0.020948
   Number of active neurons: 6
 >> iter 31000, loss: 0.020886
 >> iter 32000, loss: 0.020801
 >> iter 33000, loss: 0.020761
 >> iter 34000, loss: 0.020698
 >> iter 35000, loss: 0.020667
 >> iter 36000, loss: 0.020586
 >> iter 37000, loss: 0.020538
 >> iter 38000, loss: 0.020470
 >> iter 39000, loss: 0.020434
 >> iter 40000, loss: 0.020384
   Number of active neurons: 6
 >> iter 41000, loss: 0.020369
 >> iter 42000, loss: 0.020328
 >> iter 43000, loss: 0.020329
 >> iter 44000, loss: 0.020297
 >> iter 45000, loss: 0.020308
 >> iter 46000, loss: 0.020286
 >> iter 47000, loss: 0.020304
 >> iter 48000, loss: 0.020280
 >> iter 49000, loss: 0.020310
 >> iter 50000, loss: 0.020295
   Number of active neurons: 6
 >> iter 51000, loss: 0.020329
 >> iter 52000, loss: 0.020320
 >> iter 53000, loss: 0.020351
 >> iter 54000, loss: 0.020351
 >> iter 55000, loss: 0.020355
 >> iter 56000, loss: 0.020358
 >> iter 57000, loss: 0.020364
 >> iter 58000, loss: 0.020382
 >> iter 59000, loss: 0.020386
 >> iter 60000, loss: 0.020400
   Number of active neurons: 5
 >> iter 61000, loss: 0.020380
 >> iter 62000, loss: 0.020366
 >> iter 63000, loss: 0.020325
 >> iter 64000, loss: 0.020278
 >> iter 65000, loss: 0.020181
 >> iter 66000, loss: 0.020106
 >> iter 67000, loss: 0.020012
 >> iter 68000, loss: 0.019954
 >> iter 69000, loss: 0.019873
 >> iter 70000, loss: 0.019827
   Number of active neurons: 5
 >> iter 71000, loss: 0.019747
 >> iter 72000, loss: 0.019698
 >> iter 73000, loss: 0.019619
 >> iter 74000, loss: 0.019576
 >> iter 75000, loss: 0.019500
 >> iter 76000, loss: 0.019453
 >> iter 77000, loss: 0.019368
 >> iter 78000, loss: 0.019327
 >> iter 79000, loss: 0.019248
 >> iter 80000, loss: 0.019207
   Number of active neurons: 6
 >> iter 81000, loss: 0.019124
 >> iter 82000, loss: 0.019082
 >> iter 83000, loss: 0.018988
 >> iter 84000, loss: 0.018960
 >> iter 85000, loss: 0.018886
 >> iter 86000, loss: 0.018880
 >> iter 87000, loss: 0.018816
 >> iter 88000, loss: 0.018820
 >> iter 89000, loss: 0.018764
 >> iter 90000, loss: 0.018774
   Number of active neurons: 6
 >> iter 91000, loss: 0.018719
 >> iter 92000, loss: 0.018738
 >> iter 93000, loss: 0.018683
 >> iter 94000, loss: 0.018703
 >> iter 95000, loss: 0.018656
 >> iter 96000, loss: 0.018672
 >> iter 97000, loss: 0.018631
 >> iter 98000, loss: 0.018646
 >> iter 99000, loss: 0.018606
 >> iter 100000, loss: 0.018613
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.512179
 >> iter 2000, loss: 10.488146
 >> iter 3000, loss: 8.633201
 >> iter 4000, loss: 7.923727
 >> iter 5000, loss: 7.626281
 >> iter 6000, loss: 7.273529
 >> iter 7000, loss: 6.701055
 >> iter 8000, loss: 2.720461
 >> iter 9000, loss: 1.064909
 >> iter 10000, loss: 0.432362
   Number of active neurons: 7
 >> iter 11000, loss: 0.191914
 >> iter 12000, loss: 0.097912
 >> iter 13000, loss: 0.061240
 >> iter 14000, loss: 0.045117
 >> iter 15000, loss: 0.038494
 >> iter 16000, loss: 0.034434
 >> iter 17000, loss: 0.032718
 >> iter 18000, loss: 0.036553
 >> iter 19000, loss: 0.032352
 >> iter 20000, loss: 0.029962
   Number of active neurons: 7
 >> iter 21000, loss: 0.029152
 >> iter 22000, loss: 0.033391
 >> iter 23000, loss: 0.029910
 >> iter 24000, loss: 0.041606
 >> iter 25000, loss: 0.032816
 >> iter 26000, loss: 0.042415
 >> iter 27000, loss: 0.032968
 >> iter 28000, loss: 0.033995
 >> iter 29000, loss: 0.029240
 >> iter 30000, loss: 6.601317
   Number of active neurons: 8
 >> iter 31000, loss: 3.571303
 >> iter 32000, loss: 1.395699
 >> iter 33000, loss: 0.555679
 >> iter 34000, loss: 0.227134
 >> iter 35000, loss: 0.104364
 >> iter 36000, loss: 0.057714
 >> iter 37000, loss: 0.039861
 >> iter 38000, loss: 0.032510
 >> iter 39000, loss: 0.029411
 >> iter 40000, loss: 0.027810
   Number of active neurons: 8
 >> iter 41000, loss: 0.026950
 >> iter 42000, loss: 0.026304
 >> iter 43000, loss: 0.025877
 >> iter 44000, loss: 0.025504
 >> iter 45000, loss: 0.025172
 >> iter 46000, loss: 0.024840
 >> iter 47000, loss: 0.024487
 >> iter 48000, loss: 0.024187
 >> iter 49000, loss: 0.023844
 >> iter 50000, loss: 0.100620
   Number of active neurons: 7
 >> iter 51000, loss: 0.052459
 >> iter 52000, loss: 0.061977
 >> iter 53000, loss: 0.736085
 >> iter 54000, loss: 0.305739
 >> iter 55000, loss: 0.177494
 >> iter 56000, loss: 0.354278
 >> iter 57000, loss: 0.158341
 >> iter 58000, loss: 0.146137
 >> iter 59000, loss: 0.169604
 >> iter 60000, loss: 0.168062
   Number of active neurons: 7
 >> iter 61000, loss: 0.226410
 >> iter 62000, loss: 0.132429
 >> iter 63000, loss: 0.195491
 >> iter 64000, loss: 0.125355
 >> iter 65000, loss: 1.742123
 >> iter 66000, loss: 0.696917
 >> iter 67000, loss: 0.293654
 >> iter 68000, loss: 0.137593
 >> iter 69000, loss: 0.075984
 >> iter 70000, loss: 0.081176
   Number of active neurons: 7
 >> iter 71000, loss: 0.051708
 >> iter 72000, loss: 0.117282
 >> iter 73000, loss: 0.064795
 >> iter 74000, loss: 0.083564
 >> iter 75000, loss: 0.050171
 >> iter 76000, loss: 0.088633
 >> iter 77000, loss: 0.051389
 >> iter 78000, loss: 0.115543
 >> iter 79000, loss: 0.061367
 >> iter 80000, loss: 0.085609
   Number of active neurons: 6
 >> iter 81000, loss: 0.049931
 >> iter 82000, loss: 0.098629
 >> iter 83000, loss: 0.057260
 >> iter 84000, loss: 0.038604
 >> iter 85000, loss: 0.052309
 >> iter 86000, loss: 0.063706
 >> iter 87000, loss: 0.039894
 >> iter 88000, loss: 0.102640
 >> iter 89000, loss: 0.054713
 >> iter 90000, loss: 0.083741
   Number of active neurons: 6
 >> iter 91000, loss: 0.047552
 >> iter 92000, loss: 0.074130
 >> iter 93000, loss: 0.044240
 >> iter 94000, loss: 0.073222
 >> iter 95000, loss: 0.043364
 >> iter 96000, loss: 0.067124
 >> iter 97000, loss: 0.220767
 >> iter 98000, loss: 0.166606
 >> iter 99000, loss: 0.315816
 >> iter 100000, loss: 0.234522
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0799946670222
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.565040
 >> iter 2000, loss: 10.512994
 >> iter 3000, loss: 8.647593
 >> iter 4000, loss: 7.937130
 >> iter 5000, loss: 7.642038
 >> iter 6000, loss: 7.264376
 >> iter 7000, loss: 6.851573
 >> iter 8000, loss: 6.102697
 >> iter 9000, loss: 3.553152
 >> iter 10000, loss: 1.373127
   Number of active neurons: 9
 >> iter 11000, loss: 0.562396
 >> iter 12000, loss: 0.238472
 >> iter 13000, loss: 0.112789
 >> iter 14000, loss: 0.063891
 >> iter 15000, loss: 0.044406
 >> iter 16000, loss: 0.036135
 >> iter 17000, loss: 0.032454
 >> iter 18000, loss: 0.030589
 >> iter 19000, loss: 0.029586
 >> iter 20000, loss: 0.028874
   Number of active neurons: 8
 >> iter 21000, loss: 0.028456
 >> iter 22000, loss: 0.028012
 >> iter 23000, loss: 0.027781
 >> iter 24000, loss: 0.027418
 >> iter 25000, loss: 0.027297
 >> iter 26000, loss: 0.026998
 >> iter 27000, loss: 0.026924
 >> iter 28000, loss: 0.026657
 >> iter 29000, loss: 0.026625
 >> iter 30000, loss: 0.026389
   Number of active neurons: 8
 >> iter 31000, loss: 0.026391
 >> iter 32000, loss: 0.026210
 >> iter 33000, loss: 0.026251
 >> iter 34000, loss: 0.026047
 >> iter 35000, loss: 0.026123
 >> iter 36000, loss: 0.025962
 >> iter 37000, loss: 0.026027
 >> iter 38000, loss: 0.025895
 >> iter 39000, loss: 0.025961
 >> iter 40000, loss: 0.025854
   Number of active neurons: 8
 >> iter 41000, loss: 0.025902
 >> iter 42000, loss: 0.025810
 >> iter 43000, loss: 0.025830
 >> iter 44000, loss: 0.025761
 >> iter 45000, loss: 0.025750
 >> iter 46000, loss: 0.025723
 >> iter 47000, loss: 0.025696
 >> iter 48000, loss: 0.025678
 >> iter 49000, loss: 0.025639
 >> iter 50000, loss: 0.025623
   Number of active neurons: 8
 >> iter 51000, loss: 0.025561
 >> iter 52000, loss: 0.025495
 >> iter 53000, loss: 0.025393
 >> iter 54000, loss: 0.025297
 >> iter 55000, loss: 0.025211
 >> iter 56000, loss: 0.025128
 >> iter 57000, loss: 0.025074
 >> iter 58000, loss: 0.024998
 >> iter 59000, loss: 0.024922
 >> iter 60000, loss: 0.024845
   Number of active neurons: 8
 >> iter 61000, loss: 0.024723
 >> iter 62000, loss: 0.024602
 >> iter 63000, loss: 0.024395
 >> iter 64000, loss: 0.024258
 >> iter 65000, loss: 0.024068
 >> iter 66000, loss: 0.024005
 >> iter 67000, loss: 0.023854
 >> iter 68000, loss: 0.023833
 >> iter 69000, loss: 0.023691
 >> iter 70000, loss: 0.023667
   Number of active neurons: 7
 >> iter 71000, loss: 0.023519
 >> iter 72000, loss: 0.023483
 >> iter 73000, loss: 0.023345
 >> iter 74000, loss: 0.023293
 >> iter 75000, loss: 0.023163
 >> iter 76000, loss: 0.023073
 >> iter 77000, loss: 0.022906
 >> iter 78000, loss: 0.022782
 >> iter 79000, loss: 0.022604
 >> iter 80000, loss: 0.022444
   Number of active neurons: 7
 >> iter 81000, loss: 0.022250
 >> iter 82000, loss: 0.022090
 >> iter 83000, loss: 0.021901
 >> iter 84000, loss: 0.021738
 >> iter 85000, loss: 0.021572
 >> iter 86000, loss: 0.021433
 >> iter 87000, loss: 0.021299
 >> iter 88000, loss: 0.021183
 >> iter 89000, loss: 0.021069
 >> iter 90000, loss: 0.020981
   Number of active neurons: 7
 >> iter 91000, loss: 0.020884
 >> iter 92000, loss: 0.020812
 >> iter 93000, loss: 0.020721
 >> iter 94000, loss: 0.020655
 >> iter 95000, loss: 0.020582
 >> iter 96000, loss: 0.020524
 >> iter 97000, loss: 0.020442
 >> iter 98000, loss: 0.020384
 >> iter 99000, loss: 0.020299
 >> iter 100000, loss: 0.020269
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.559744
 >> iter 2000, loss: 10.511747
 >> iter 3000, loss: 8.648670
 >> iter 4000, loss: 7.933044
 >> iter 5000, loss: 7.715023
 >> iter 6000, loss: 7.264184
 >> iter 7000, loss: 5.496466
 >> iter 8000, loss: 2.148567
 >> iter 9000, loss: 0.845911
 >> iter 10000, loss: 0.347632
   Number of active neurons: 8
 >> iter 11000, loss: 0.157394
 >> iter 12000, loss: 0.082643
 >> iter 13000, loss: 0.052748
 >> iter 14000, loss: 0.039760
 >> iter 15000, loss: 0.034017
 >> iter 16000, loss: 0.030790
 >> iter 17000, loss: 0.029256
 >> iter 18000, loss: 0.027969
 >> iter 19000, loss: 0.027430
 >> iter 20000, loss: 0.026736
   Number of active neurons: 8
 >> iter 21000, loss: 0.026600
 >> iter 22000, loss: 0.026152
 >> iter 23000, loss: 0.026143
 >> iter 24000, loss: 0.025749
 >> iter 25000, loss: 0.025805
 >> iter 26000, loss: 0.025460
 >> iter 27000, loss: 0.025541
 >> iter 28000, loss: 0.025258
 >> iter 29000, loss: 0.025350
 >> iter 30000, loss: 0.025069
   Number of active neurons: 7
 >> iter 31000, loss: 0.025115
 >> iter 32000, loss: 0.024901
 >> iter 33000, loss: 0.025004
 >> iter 34000, loss: 0.024860
 >> iter 35000, loss: 0.024999
 >> iter 36000, loss: 0.024882
 >> iter 37000, loss: 0.024994
 >> iter 38000, loss: 0.024853
 >> iter 39000, loss: 0.024895
 >> iter 40000, loss: 0.024719
   Number of active neurons: 7
 >> iter 41000, loss: 0.024760
 >> iter 42000, loss: 0.024608
 >> iter 43000, loss: 0.024662
 >> iter 44000, loss: 0.024537
 >> iter 45000, loss: 0.024586
 >> iter 46000, loss: 0.024450
 >> iter 47000, loss: 0.024470
 >> iter 48000, loss: 0.024341
 >> iter 49000, loss: 0.024371
 >> iter 50000, loss: 0.024230
   Number of active neurons: 7
 >> iter 51000, loss: 0.024233
 >> iter 52000, loss: 0.024054
 >> iter 53000, loss: 0.024052
 >> iter 54000, loss: 0.023848
 >> iter 55000, loss: 0.023860
 >> iter 56000, loss: 0.023663
 >> iter 57000, loss: 0.023689
 >> iter 58000, loss: 0.023504
 >> iter 59000, loss: 0.023535
 >> iter 60000, loss: 0.023370
   Number of active neurons: 7
 >> iter 61000, loss: 0.023401
 >> iter 62000, loss: 0.023219
 >> iter 63000, loss: 0.023208
 >> iter 64000, loss: 0.023025
 >> iter 65000, loss: 0.023026
 >> iter 66000, loss: 0.022863
 >> iter 67000, loss: 0.022875
 >> iter 68000, loss: 0.022724
 >> iter 69000, loss: 0.022738
 >> iter 70000, loss: 0.022597
   Number of active neurons: 7
 >> iter 71000, loss: 0.022607
 >> iter 72000, loss: 0.022475
 >> iter 73000, loss: 0.022503
 >> iter 74000, loss: 0.022344
 >> iter 75000, loss: 0.022353
 >> iter 76000, loss: 0.022133
 >> iter 77000, loss: 0.022088
 >> iter 78000, loss: 0.021867
 >> iter 79000, loss: 0.021851
 >> iter 80000, loss: 0.021651
   Number of active neurons: 7
 >> iter 81000, loss: 0.021648
 >> iter 82000, loss: 0.021456
 >> iter 83000, loss: 0.021452
 >> iter 84000, loss: 0.021257
 >> iter 85000, loss: 0.021275
 >> iter 86000, loss: 0.021093
 >> iter 87000, loss: 0.021134
 >> iter 88000, loss: 0.020962
 >> iter 89000, loss: 0.021008
 >> iter 90000, loss: 0.020852
   Number of active neurons: 7
 >> iter 91000, loss: 0.020907
 >> iter 92000, loss: 0.020758
 >> iter 93000, loss: 0.020821
 >> iter 94000, loss: 0.020664
 >> iter 95000, loss: 0.020720
 >> iter 96000, loss: 0.020566
 >> iter 97000, loss: 0.020628
 >> iter 98000, loss: 0.020474
 >> iter 99000, loss: 0.020530
 >> iter 100000, loss: 0.020403
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 12.2391840544
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.543196
 >> iter 2000, loss: 10.498890
 >> iter 3000, loss: 8.636608
 >> iter 4000, loss: 7.922442
 >> iter 5000, loss: 7.649120
 >> iter 6000, loss: 7.237245
 >> iter 7000, loss: 3.937950
 >> iter 8000, loss: 1.495652
 >> iter 9000, loss: 0.577412
 >> iter 10000, loss: 0.233193
   Number of active neurons: 6
 >> iter 11000, loss: 0.103714
 >> iter 12000, loss: 0.054316
 >> iter 13000, loss: 0.035183
 >> iter 14000, loss: 0.027391
 >> iter 15000, loss: 0.024103
 >> iter 16000, loss: 0.022481
 >> iter 17000, loss: 0.021690
 >> iter 18000, loss: 0.021155
 >> iter 19000, loss: 0.020874
 >> iter 20000, loss: 0.020622
   Number of active neurons: 6
 >> iter 21000, loss: 0.020508
 >> iter 22000, loss: 0.020368
 >> iter 23000, loss: 0.020288
 >> iter 24000, loss: 0.020182
 >> iter 25000, loss: 0.020122
 >> iter 26000, loss: 0.020039
 >> iter 27000, loss: 0.019971
 >> iter 28000, loss: 0.019875
 >> iter 29000, loss: 0.019810
 >> iter 30000, loss: 0.019731
   Number of active neurons: 6
 >> iter 31000, loss: 0.019689
 >> iter 32000, loss: 0.019605
 >> iter 33000, loss: 0.019560
 >> iter 34000, loss: 0.019479
 >> iter 35000, loss: 0.019437
 >> iter 36000, loss: 0.019355
 >> iter 37000, loss: 0.019316
 >> iter 38000, loss: 0.019250
 >> iter 39000, loss: 0.019197
 >> iter 40000, loss: 0.019123
   Number of active neurons: 6
 >> iter 41000, loss: 0.019076
 >> iter 42000, loss: 0.018994
 >> iter 43000, loss: 0.018931
 >> iter 44000, loss: 0.018842
 >> iter 45000, loss: 0.018778
 >> iter 46000, loss: 0.018701
 >> iter 47000, loss: 0.018649
 >> iter 48000, loss: 0.018583
 >> iter 49000, loss: 0.018542
 >> iter 50000, loss: 0.018487
   Number of active neurons: 6
 >> iter 51000, loss: 0.018446
 >> iter 52000, loss: 0.018393
 >> iter 53000, loss: 0.018343
 >> iter 54000, loss: 0.018300
 >> iter 55000, loss: 0.018227
 >> iter 56000, loss: 0.018165
 >> iter 57000, loss: 0.018054
 >> iter 58000, loss: 0.017997
 >> iter 59000, loss: 0.017898
 >> iter 60000, loss: 0.017867
   Number of active neurons: 6
 >> iter 61000, loss: 0.017781
 >> iter 62000, loss: 0.017761
 >> iter 63000, loss: 0.017679
 >> iter 64000, loss: 0.017665
 >> iter 65000, loss: 0.017577
 >> iter 66000, loss: 0.017563
 >> iter 67000, loss: 0.017472
 >> iter 68000, loss: 0.017461
 >> iter 69000, loss: 0.017366
 >> iter 70000, loss: 0.017352
   Number of active neurons: 5
 >> iter 71000, loss: 0.017255
 >> iter 72000, loss: 0.017239
 >> iter 73000, loss: 0.017134
 >> iter 74000, loss: 0.017101
 >> iter 75000, loss: 0.016977
 >> iter 76000, loss: 0.016939
 >> iter 77000, loss: 0.016826
 >> iter 78000, loss: 0.016808
 >> iter 79000, loss: 0.016718
 >> iter 80000, loss: 0.016709
   Number of active neurons: 5
 >> iter 81000, loss: 0.016627
 >> iter 82000, loss: 0.016631
 >> iter 83000, loss: 0.016551
 >> iter 84000, loss: 0.016565
 >> iter 85000, loss: 0.016489
 >> iter 86000, loss: 0.016510
 >> iter 87000, loss: 0.016433
 >> iter 88000, loss: 0.016458
 >> iter 89000, loss: 0.016383
 >> iter 90000, loss: 0.016410
   Number of active neurons: 5
 >> iter 91000, loss: 0.016333
 >> iter 92000, loss: 0.016366
 >> iter 93000, loss: 0.016287
 >> iter 94000, loss: 0.016319
 >> iter 95000, loss: 0.016249
 >> iter 96000, loss: 0.016276
 >> iter 97000, loss: 0.016191
 >> iter 98000, loss: 0.016197
 >> iter 99000, loss: 0.016112
 >> iter 100000, loss: 0.016125
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.579454
 >> iter 2000, loss: 10.510399
 >> iter 3000, loss: 8.634953
 >> iter 4000, loss: 7.918340
 >> iter 5000, loss: 7.680194
 >> iter 6000, loss: 7.604815
 >> iter 7000, loss: 7.869241
 >> iter 8000, loss: 7.444834
 >> iter 9000, loss: 4.843099
 >> iter 10000, loss: 1.829976
   Number of active neurons: 7
 >> iter 11000, loss: 0.701693
 >> iter 12000, loss: 0.280445
 >> iter 13000, loss: 0.122645
 >> iter 14000, loss: 0.062862
 >> iter 15000, loss: 0.039861
 >> iter 16000, loss: 0.030540
 >> iter 17000, loss: 0.026611
 >> iter 18000, loss: 0.024647
 >> iter 19000, loss: 0.023677
 >> iter 20000, loss: 0.022976
   Number of active neurons: 7
 >> iter 21000, loss: 0.022581
 >> iter 22000, loss: 0.022171
 >> iter 23000, loss: 0.021922
 >> iter 24000, loss: 0.021627
 >> iter 25000, loss: 0.021426
 >> iter 26000, loss: 0.021159
 >> iter 27000, loss: 0.020994
 >> iter 28000, loss: 0.020800
 >> iter 29000, loss: 0.020686
 >> iter 30000, loss: 0.020535
   Number of active neurons: 7
 >> iter 31000, loss: 0.020425
 >> iter 32000, loss: 0.020294
 >> iter 33000, loss: 0.020211
 >> iter 34000, loss: 0.020092
 >> iter 35000, loss: 0.019997
 >> iter 36000, loss: 0.019860
 >> iter 37000, loss: 0.019763
 >> iter 38000, loss: 0.019642
 >> iter 39000, loss: 0.019568
 >> iter 40000, loss: 0.019476
   Number of active neurons: 7
 >> iter 41000, loss: 0.019412
 >> iter 42000, loss: 0.019310
 >> iter 43000, loss: 0.019197
 >> iter 44000, loss: 0.019069
 >> iter 45000, loss: 0.018976
 >> iter 46000, loss: 0.018885
 >> iter 47000, loss: 0.018796
 >> iter 48000, loss: 0.018689
 >> iter 49000, loss: 0.018617
 >> iter 50000, loss: 0.018530
   Number of active neurons: 6
 >> iter 51000, loss: 0.018457
 >> iter 52000, loss: 0.018366
 >> iter 53000, loss: 0.018298
 >> iter 54000, loss: 0.018230
 >> iter 55000, loss: 0.018149
 >> iter 56000, loss: 0.018072
 >> iter 57000, loss: 0.017961
 >> iter 58000, loss: 0.017889
 >> iter 59000, loss: 0.017789
 >> iter 60000, loss: 0.017747
   Number of active neurons: 6
 >> iter 61000, loss: 0.017661
 >> iter 62000, loss: 0.017626
 >> iter 63000, loss: 0.017531
 >> iter 64000, loss: 0.017495
 >> iter 65000, loss: 0.017403
 >> iter 66000, loss: 0.017379
 >> iter 67000, loss: 0.017298
 >> iter 68000, loss: 0.017282
 >> iter 69000, loss: 0.017189
 >> iter 70000, loss: 0.017169
   Number of active neurons: 6
 >> iter 71000, loss: 0.017079
 >> iter 72000, loss: 0.017065
 >> iter 73000, loss: 0.016982
 >> iter 74000, loss: 0.016977
 >> iter 75000, loss: 0.016898
 >> iter 76000, loss: 0.016898
 >> iter 77000, loss: 0.016821
 >> iter 78000, loss: 0.016825
 >> iter 79000, loss: 0.016750
 >> iter 80000, loss: 0.016757
   Number of active neurons: 6
 >> iter 81000, loss: 0.016679
 >> iter 82000, loss: 0.016688
 >> iter 83000, loss: 0.016607
 >> iter 84000, loss: 0.016619
 >> iter 85000, loss: 0.016535
 >> iter 86000, loss: 0.016553
 >> iter 87000, loss: 0.016463
 >> iter 88000, loss: 0.016481
 >> iter 89000, loss: 0.016389
 >> iter 90000, loss: 0.016408
   Number of active neurons: 6
 >> iter 91000, loss: 0.016311
 >> iter 92000, loss: 0.016332
 >> iter 93000, loss: 0.016221
 >> iter 94000, loss: 0.016228
 >> iter 95000, loss: 0.016122
 >> iter 96000, loss: 0.016127
 >> iter 97000, loss: 0.016024
 >> iter 98000, loss: 0.016027
 >> iter 99000, loss: 0.015926
 >> iter 100000, loss: 0.015926
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

