 > Problema: tomita1nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.047185
 >> iter 2000, loss: 4.096875
 >> iter 3000, loss: 1.527233
 >> iter 4000, loss: 0.579433
 >> iter 5000, loss: 0.243204
 >> iter 6000, loss: 0.104200
 >> iter 7000, loss: 0.053334
 >> iter 8000, loss: 0.031716
 >> iter 9000, loss: 0.029653
 >> iter 10000, loss: 0.025510
   Number of active neurons: 2
 >> iter 11000, loss: 0.024826
 >> iter 12000, loss: 0.022206
 >> iter 13000, loss: 0.031947
 >> iter 14000, loss: 0.031830
 >> iter 15000, loss: 0.027823
 >> iter 16000, loss: 0.023584
 >> iter 17000, loss: 0.027019
 >> iter 18000, loss: 0.027990
 >> iter 19000, loss: 0.028372
 >> iter 20000, loss: 0.037632
   Number of active neurons: 2
 >> iter 21000, loss: 0.029599
 >> iter 22000, loss: 0.027743
 >> iter 23000, loss: 0.025274
 >> iter 24000, loss: 0.033877
 >> iter 25000, loss: 0.043908
 >> iter 26000, loss: 0.034786
 >> iter 27000, loss: 0.026785
 >> iter 28000, loss: 0.028198
 >> iter 29000, loss: 0.069593
 >> iter 30000, loss: 0.038823
   Number of active neurons: 2
 >> iter 31000, loss: 0.028136
 >> iter 32000, loss: 0.029706
 >> iter 33000, loss: 0.043993
 >> iter 34000, loss: 0.036019
 >> iter 35000, loss: 0.032358
 >> iter 36000, loss: 0.024801
 >> iter 37000, loss: 0.024116
 >> iter 38000, loss: 0.021210
 >> iter 39000, loss: 0.036707
 >> iter 40000, loss: 0.026653
   Number of active neurons: 2
 >> iter 41000, loss: 0.025174
 >> iter 42000, loss: 0.023627
 >> iter 43000, loss: 0.025897
 >> iter 44000, loss: 0.022654
 >> iter 45000, loss: 0.026335
 >> iter 46000, loss: 0.028963
 >> iter 47000, loss: 0.023063
 >> iter 48000, loss: 0.022755
 >> iter 49000, loss: 0.022890
 >> iter 50000, loss: 0.027980
   Number of active neurons: 1
 >> iter 51000, loss: 0.024272
 >> iter 52000, loss: 0.024711
 >> iter 53000, loss: 0.022074
 >> iter 54000, loss: 0.020701
 >> iter 55000, loss: 0.020339
 >> iter 56000, loss: 0.021683
 >> iter 57000, loss: 0.020745
 >> iter 58000, loss: 0.023455
 >> iter 59000, loss: 0.028892
 >> iter 60000, loss: 0.022927
   Number of active neurons: 1
 >> iter 61000, loss: 0.021819
 >> iter 62000, loss: 0.019807
 >> iter 63000, loss: 0.017582
 >> iter 64000, loss: 0.015694
 >> iter 65000, loss: 0.038032
 >> iter 66000, loss: 0.025568
 >> iter 67000, loss: 0.022095
 >> iter 68000, loss: 0.024146
 >> iter 69000, loss: 0.022719
 >> iter 70000, loss: 0.024283
   Number of active neurons: 1
 >> iter 71000, loss: 0.020237
 >> iter 72000, loss: 0.025421
 >> iter 73000, loss: 0.022628
 >> iter 74000, loss: 0.027209
 >> iter 75000, loss: 0.021697
 >> iter 76000, loss: 0.021594
 >> iter 77000, loss: 0.022592
 >> iter 78000, loss: 0.023338
 >> iter 79000, loss: 0.018495
 >> iter 80000, loss: 0.017452
   Number of active neurons: 1
 >> iter 81000, loss: 0.016357
 >> iter 82000, loss: 0.017261
 >> iter 83000, loss: 0.018683
 >> iter 84000, loss: 0.022763
 >> iter 85000, loss: 0.020707
 >> iter 86000, loss: 0.020273
 >> iter 87000, loss: 0.024554
 >> iter 88000, loss: 0.024065
 >> iter 89000, loss: 0.022687
 >> iter 90000, loss: 0.023383
   Number of active neurons: 1
 >> iter 91000, loss: 0.018589
 >> iter 92000, loss: 0.020873
 >> iter 93000, loss: 0.037174
 >> iter 94000, loss: 0.031745
 >> iter 95000, loss: 0.035244
 >> iter 96000, loss: 0.022662
 >> iter 97000, loss: 0.021056
 >> iter 98000, loss: 0.023406
 >> iter 99000, loss: 0.027625
 >> iter 100000, loss: 0.027124
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.009208
 >> iter 2000, loss: 4.097916
 >> iter 3000, loss: 1.534665
 >> iter 4000, loss: 0.585032
 >> iter 5000, loss: 0.230408
 >> iter 6000, loss: 0.105921
 >> iter 7000, loss: 0.053575
 >> iter 8000, loss: 0.040652
 >> iter 9000, loss: 0.030496
 >> iter 10000, loss: 0.026161
   Number of active neurons: 2
 >> iter 11000, loss: 0.022652
 >> iter 12000, loss: 0.049053
 >> iter 13000, loss: 0.036134
 >> iter 14000, loss: 0.028400
 >> iter 15000, loss: 0.045419
 >> iter 16000, loss: 0.030283
 >> iter 17000, loss: 0.026851
 >> iter 18000, loss: 0.023796
 >> iter 19000, loss: 0.025451
 >> iter 20000, loss: 0.022549
   Number of active neurons: 2
 >> iter 21000, loss: 0.059577
 >> iter 22000, loss: 0.045119
 >> iter 23000, loss: 0.030610
 >> iter 24000, loss: 0.025959
 >> iter 25000, loss: 0.023960
 >> iter 26000, loss: 0.021656
 >> iter 27000, loss: 0.022290
 >> iter 28000, loss: 0.022157
 >> iter 29000, loss: 0.022005
 >> iter 30000, loss: 0.029528
   Number of active neurons: 2
 >> iter 31000, loss: 0.028695
 >> iter 32000, loss: 0.024127
 >> iter 33000, loss: 0.021316
 >> iter 34000, loss: 0.022602
 >> iter 35000, loss: 0.020362
 >> iter 36000, loss: 0.030539
 >> iter 37000, loss: 0.024944
 >> iter 38000, loss: 0.025772
 >> iter 39000, loss: 0.022512
 >> iter 40000, loss: 0.030322
   Number of active neurons: 2
 >> iter 41000, loss: 0.029929
 >> iter 42000, loss: 0.038339
 >> iter 43000, loss: 0.025599
 >> iter 44000, loss: 0.021655
 >> iter 45000, loss: 0.019652
 >> iter 46000, loss: 0.027961
 >> iter 47000, loss: 0.023542
 >> iter 48000, loss: 0.030814
 >> iter 49000, loss: 0.057477
 >> iter 50000, loss: 0.037967
   Number of active neurons: 1
 >> iter 51000, loss: 0.026381
 >> iter 52000, loss: 0.022078
 >> iter 53000, loss: 0.025965
 >> iter 54000, loss: 0.023658
 >> iter 55000, loss: 0.020300
 >> iter 56000, loss: 0.022160
 >> iter 57000, loss: 0.018866
 >> iter 58000, loss: 0.018328
 >> iter 59000, loss: 0.018975
 >> iter 60000, loss: 0.018014
   Number of active neurons: 1
 >> iter 61000, loss: 0.026277
 >> iter 62000, loss: 0.029901
 >> iter 63000, loss: 0.022456
 >> iter 64000, loss: 0.023896
 >> iter 65000, loss: 0.025859
 >> iter 66000, loss: 0.027306
 >> iter 67000, loss: 0.019914
 >> iter 68000, loss: 0.017367
 >> iter 69000, loss: 0.019285
 >> iter 70000, loss: 0.017772
   Number of active neurons: 1
 >> iter 71000, loss: 0.017708
 >> iter 72000, loss: 0.015617
 >> iter 73000, loss: 0.017763
 >> iter 74000, loss: 0.029860
 >> iter 75000, loss: 0.024053
 >> iter 76000, loss: 0.033333
 >> iter 77000, loss: 0.024286
 >> iter 78000, loss: 0.020777
 >> iter 79000, loss: 0.035720
 >> iter 80000, loss: 0.023183
   Number of active neurons: 1
 >> iter 81000, loss: 0.033012
 >> iter 82000, loss: 0.022200
 >> iter 83000, loss: 0.023314
 >> iter 84000, loss: 0.024674
 >> iter 85000, loss: 0.024419
 >> iter 86000, loss: 0.018375
 >> iter 87000, loss: 0.016208
 >> iter 88000, loss: 0.027035
 >> iter 89000, loss: 0.020887
 >> iter 90000, loss: 0.019192
   Number of active neurons: 1
 >> iter 91000, loss: 0.020629
 >> iter 92000, loss: 0.018302
 >> iter 93000, loss: 0.016338
 >> iter 94000, loss: 0.023082
 >> iter 95000, loss: 0.019440
 >> iter 96000, loss: 0.017227
 >> iter 97000, loss: 0.022967
 >> iter 98000, loss: 0.021505
 >> iter 99000, loss: 0.057276
 >> iter 100000, loss: 0.034348
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.705415
 >> iter 2000, loss: 4.356162
 >> iter 3000, loss: 1.643450
 >> iter 4000, loss: 0.627774
 >> iter 5000, loss: 0.250330
 >> iter 6000, loss: 0.117184
 >> iter 7000, loss: 0.059416
 >> iter 8000, loss: 0.035539
 >> iter 9000, loss: 0.028644
 >> iter 10000, loss: 0.025308
   Number of active neurons: 1
 >> iter 11000, loss: 0.020503
 >> iter 12000, loss: 0.019328
 >> iter 13000, loss: 0.029519
 >> iter 14000, loss: 0.023586
 >> iter 15000, loss: 0.021631
 >> iter 16000, loss: 0.020651
 >> iter 17000, loss: 0.021436
 >> iter 18000, loss: 0.028657
 >> iter 19000, loss: 0.020513
 >> iter 20000, loss: 0.019031
   Number of active neurons: 1
 >> iter 21000, loss: 0.024974
 >> iter 22000, loss: 0.021449
 >> iter 23000, loss: 0.020539
 >> iter 24000, loss: 0.020098
 >> iter 25000, loss: 0.025160
 >> iter 26000, loss: 0.020928
 >> iter 27000, loss: 0.017184
 >> iter 28000, loss: 0.034221
 >> iter 29000, loss: 0.038207
 >> iter 30000, loss: 0.023830
   Number of active neurons: 1
 >> iter 31000, loss: 0.020551
 >> iter 32000, loss: 0.021076
 >> iter 33000, loss: 0.019156
 >> iter 34000, loss: 0.017984
 >> iter 35000, loss: 0.016482
 >> iter 36000, loss: 0.026310
 >> iter 37000, loss: 0.024355
 >> iter 38000, loss: 0.026743
 >> iter 39000, loss: 0.021423
 >> iter 40000, loss: 0.020436
   Number of active neurons: 1
 >> iter 41000, loss: 0.027475
 >> iter 42000, loss: 0.032694
 >> iter 43000, loss: 0.026383
 >> iter 44000, loss: 0.027299
 >> iter 45000, loss: 0.035328
 >> iter 46000, loss: 0.034266
 >> iter 47000, loss: 0.025863
 >> iter 48000, loss: 0.020236
 >> iter 49000, loss: 0.031856
 >> iter 50000, loss: 0.026549
   Number of active neurons: 1
 >> iter 51000, loss: 0.020759
 >> iter 52000, loss: 0.016907
 >> iter 53000, loss: 0.015945
 >> iter 54000, loss: 0.019463
 >> iter 55000, loss: 0.025472
 >> iter 56000, loss: 0.021900
 >> iter 57000, loss: 0.023315
 >> iter 58000, loss: 0.019969
 >> iter 59000, loss: 0.018822
 >> iter 60000, loss: 0.019105
   Number of active neurons: 1
 >> iter 61000, loss: 0.021489
 >> iter 62000, loss: 0.035685
 >> iter 63000, loss: 0.036156
 >> iter 64000, loss: 0.026236
 >> iter 65000, loss: 0.051676
 >> iter 66000, loss: 0.044642
 >> iter 67000, loss: 0.036410
 >> iter 68000, loss: 0.025996
 >> iter 69000, loss: 0.021226
 >> iter 70000, loss: 0.021943
   Number of active neurons: 1
 >> iter 71000, loss: 0.018512
 >> iter 72000, loss: 0.016939
 >> iter 73000, loss: 0.016284
 >> iter 74000, loss: 0.016948
 >> iter 75000, loss: 0.017936
 >> iter 76000, loss: 0.015964
 >> iter 77000, loss: 0.025876
 >> iter 78000, loss: 0.021952
 >> iter 79000, loss: 0.024757
 >> iter 80000, loss: 0.022844
   Number of active neurons: 1
 >> iter 81000, loss: 0.024833
 >> iter 82000, loss: 0.024477
 >> iter 83000, loss: 0.025074
 >> iter 84000, loss: 0.019791
 >> iter 85000, loss: 0.018254
 >> iter 86000, loss: 0.017063
 >> iter 87000, loss: 0.016643
 >> iter 88000, loss: 0.020152
 >> iter 89000, loss: 0.017220
 >> iter 90000, loss: 0.021325
   Number of active neurons: 1
 >> iter 91000, loss: 0.029388
 >> iter 92000, loss: 0.022109
 >> iter 93000, loss: 0.026237
 >> iter 94000, loss: 0.019674
 >> iter 95000, loss: 0.019642
 >> iter 96000, loss: 0.017992
 >> iter 97000, loss: 0.023473
 >> iter 98000, loss: 0.019151
 >> iter 99000, loss: 0.037243
 >> iter 100000, loss: 0.023177
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.078638
 >> iter 2000, loss: 4.126350
 >> iter 3000, loss: 1.547689
 >> iter 4000, loss: 0.588352
 >> iter 5000, loss: 0.242155
 >> iter 6000, loss: 0.103694
 >> iter 7000, loss: 0.056622
 >> iter 8000, loss: 0.034758
 >> iter 9000, loss: 0.028537
 >> iter 10000, loss: 0.022645
   Number of active neurons: 1
 >> iter 11000, loss: 0.021734
 >> iter 12000, loss: 0.018712
 >> iter 13000, loss: 0.019485
 >> iter 14000, loss: 0.019302
 >> iter 15000, loss: 0.022534
 >> iter 16000, loss: 0.032753
 >> iter 17000, loss: 0.024668
 >> iter 18000, loss: 0.031347
 >> iter 19000, loss: 0.027271
 >> iter 20000, loss: 0.023736
   Number of active neurons: 1
 >> iter 21000, loss: 0.019430
 >> iter 22000, loss: 0.020979
 >> iter 23000, loss: 0.019633
 >> iter 24000, loss: 0.019419
 >> iter 25000, loss: 0.018474
 >> iter 26000, loss: 0.017597
 >> iter 27000, loss: 0.024200
 >> iter 28000, loss: 0.020661
 >> iter 29000, loss: 0.019283
 >> iter 30000, loss: 0.021172
   Number of active neurons: 1
 >> iter 31000, loss: 0.018152
 >> iter 32000, loss: 0.021512
 >> iter 33000, loss: 0.024826
 >> iter 34000, loss: 0.019696
 >> iter 35000, loss: 0.021526
 >> iter 36000, loss: 0.022034
 >> iter 37000, loss: 0.019061
 >> iter 38000, loss: 0.016514
 >> iter 39000, loss: 0.017940
 >> iter 40000, loss: 0.019591
   Number of active neurons: 1
 >> iter 41000, loss: 0.021231
 >> iter 42000, loss: 0.022911
 >> iter 43000, loss: 0.018283
 >> iter 44000, loss: 0.029227
 >> iter 45000, loss: 0.031078
 >> iter 46000, loss: 0.026354
 >> iter 47000, loss: 0.023694
 >> iter 48000, loss: 0.018250
 >> iter 49000, loss: 0.019468
 >> iter 50000, loss: 0.017601
   Number of active neurons: 1
 >> iter 51000, loss: 0.017026
 >> iter 52000, loss: 0.016866
 >> iter 53000, loss: 0.017162
 >> iter 54000, loss: 0.016116
 >> iter 55000, loss: 0.023633
 >> iter 56000, loss: 0.029710
 >> iter 57000, loss: 0.021593
 >> iter 58000, loss: 0.019701
 >> iter 59000, loss: 0.022418
 >> iter 60000, loss: 0.017926
   Number of active neurons: 1
 >> iter 61000, loss: 0.016512
 >> iter 62000, loss: 0.020468
 >> iter 63000, loss: 0.020182
 >> iter 64000, loss: 0.020574
 >> iter 65000, loss: 0.030543
 >> iter 66000, loss: 0.030718
 >> iter 67000, loss: 0.032804
 >> iter 68000, loss: 0.025308
 >> iter 69000, loss: 0.027203
 >> iter 70000, loss: 0.020221
   Number of active neurons: 1
 >> iter 71000, loss: 0.029448
 >> iter 72000, loss: 0.020292
 >> iter 73000, loss: 0.020081
 >> iter 74000, loss: 0.023041
 >> iter 75000, loss: 0.018399
 >> iter 76000, loss: 0.027509
 >> iter 77000, loss: 0.023677
 >> iter 78000, loss: 0.020914
 >> iter 79000, loss: 0.017683
 >> iter 80000, loss: 0.019867
   Number of active neurons: 1
 >> iter 81000, loss: 0.021794
 >> iter 82000, loss: 0.017028
 >> iter 83000, loss: 0.016840
 >> iter 84000, loss: 0.017133
 >> iter 85000, loss: 0.018933
 >> iter 86000, loss: 0.017281
 >> iter 87000, loss: 0.024759
 >> iter 88000, loss: 0.019192
 >> iter 89000, loss: 0.026441
 >> iter 90000, loss: 0.022711
   Number of active neurons: 1
 >> iter 91000, loss: 0.019224
 >> iter 92000, loss: 0.029281
 >> iter 93000, loss: 0.052259
 >> iter 94000, loss: 0.028925
 >> iter 95000, loss: 0.023160
 >> iter 96000, loss: 0.019242
 >> iter 97000, loss: 0.018752
 >> iter 98000, loss: 0.044324
 >> iter 99000, loss: 0.030955
 >> iter 100000, loss: 0.036404
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.384629
 >> iter 2000, loss: 4.226731
 >> iter 3000, loss: 1.582776
 >> iter 4000, loss: 0.608534
 >> iter 5000, loss: 0.240110
 >> iter 6000, loss: 0.103362
 >> iter 7000, loss: 0.055749
 >> iter 8000, loss: 0.033600
 >> iter 9000, loss: 0.027334
 >> iter 10000, loss: 0.026661
   Number of active neurons: 1
 >> iter 11000, loss: 0.024770
 >> iter 12000, loss: 0.022710
 >> iter 13000, loss: 0.033840
 >> iter 14000, loss: 0.023213
 >> iter 15000, loss: 0.017834
 >> iter 16000, loss: 0.018562
 >> iter 17000, loss: 0.021149
 >> iter 18000, loss: 0.017620
 >> iter 19000, loss: 0.026354
 >> iter 20000, loss: 0.028010
   Number of active neurons: 1
 >> iter 21000, loss: 0.019165
 >> iter 22000, loss: 0.025844
 >> iter 23000, loss: 0.022252
 >> iter 24000, loss: 0.017921
 >> iter 25000, loss: 0.027206
 >> iter 26000, loss: 0.053174
 >> iter 27000, loss: 0.031757
 >> iter 28000, loss: 0.030646
 >> iter 29000, loss: 0.057873
 >> iter 30000, loss: 0.033033
   Number of active neurons: 1
 >> iter 31000, loss: 0.024782
 >> iter 32000, loss: 0.020588
 >> iter 33000, loss: 0.042996
 >> iter 34000, loss: 0.034301
 >> iter 35000, loss: 0.027694
 >> iter 36000, loss: 0.022158
 >> iter 37000, loss: 0.019549
 >> iter 38000, loss: 0.019469
 >> iter 39000, loss: 0.017612
 >> iter 40000, loss: 0.018348
   Number of active neurons: 1
 >> iter 41000, loss: 0.020557
 >> iter 42000, loss: 0.019083
 >> iter 43000, loss: 0.021724
 >> iter 44000, loss: 0.028010
 >> iter 45000, loss: 0.018861
 >> iter 46000, loss: 0.032773
 >> iter 47000, loss: 0.022161
 >> iter 48000, loss: 0.024264
 >> iter 49000, loss: 0.023096
 >> iter 50000, loss: 0.024935
   Number of active neurons: 1
 >> iter 51000, loss: 0.019659
 >> iter 52000, loss: 0.022569
 >> iter 53000, loss: 0.018246
 >> iter 54000, loss: 0.017952
 >> iter 55000, loss: 0.019935
 >> iter 56000, loss: 0.017615
 >> iter 57000, loss: 0.021226
 >> iter 58000, loss: 0.028082
 >> iter 59000, loss: 0.021144
 >> iter 60000, loss: 0.018024
   Number of active neurons: 1
 >> iter 61000, loss: 0.019314
 >> iter 62000, loss: 0.020650
 >> iter 63000, loss: 0.019450
 >> iter 64000, loss: 0.045200
 >> iter 65000, loss: 0.041156
 >> iter 66000, loss: 0.033381
 >> iter 67000, loss: 0.022978
 >> iter 68000, loss: 0.028673
 >> iter 69000, loss: 0.021758
 >> iter 70000, loss: 0.018289
   Number of active neurons: 1
 >> iter 71000, loss: 0.018817
 >> iter 72000, loss: 0.020220
 >> iter 73000, loss: 0.029580
 >> iter 74000, loss: 0.038372
 >> iter 75000, loss: 0.025962
 >> iter 76000, loss: 0.028240
 >> iter 77000, loss: 0.021554
 >> iter 78000, loss: 0.032278
 >> iter 79000, loss: 0.028322
 >> iter 80000, loss: 0.024699
   Number of active neurons: 1
 >> iter 81000, loss: 0.021023
 >> iter 82000, loss: 0.017805
 >> iter 83000, loss: 0.022478
 >> iter 84000, loss: 0.019951
 >> iter 85000, loss: 0.018005
 >> iter 86000, loss: 0.022289
 >> iter 87000, loss: 0.018917
 >> iter 88000, loss: 0.020011
 >> iter 89000, loss: 0.018364
 >> iter 90000, loss: 0.019956
   Number of active neurons: 1
 >> iter 91000, loss: 0.024690
 >> iter 92000, loss: 0.022848
 >> iter 93000, loss: 0.047135
 >> iter 94000, loss: 0.027016
 >> iter 95000, loss: 0.049675
 >> iter 96000, loss: 0.028903
 >> iter 97000, loss: 0.026151
 >> iter 98000, loss: 0.021130
 >> iter 99000, loss: 0.019543
 >> iter 100000, loss: 0.023291
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.025239
 >> iter 2000, loss: 4.090985
 >> iter 3000, loss: 1.526245
 >> iter 4000, loss: 0.579575
 >> iter 5000, loss: 0.229423
 >> iter 6000, loss: 0.107990
 >> iter 7000, loss: 0.056784
 >> iter 8000, loss: 0.043556
 >> iter 9000, loss: 0.029771
 >> iter 10000, loss: 0.029431
   Number of active neurons: 2
 >> iter 11000, loss: 0.030454
 >> iter 12000, loss: 0.028751
 >> iter 13000, loss: 0.023749
 >> iter 14000, loss: 0.023667
 >> iter 15000, loss: 0.035308
 >> iter 16000, loss: 0.026350
 >> iter 17000, loss: 0.021386
 >> iter 18000, loss: 0.023091
 >> iter 19000, loss: 0.033954
 >> iter 20000, loss: 0.033330
   Number of active neurons: 2
 >> iter 21000, loss: 0.025265
 >> iter 22000, loss: 0.023852
 >> iter 23000, loss: 0.020650
 >> iter 24000, loss: 0.029346
 >> iter 25000, loss: 0.033042
 >> iter 26000, loss: 0.026018
 >> iter 27000, loss: 0.026789
 >> iter 28000, loss: 0.021479
 >> iter 29000, loss: 0.022616
 >> iter 30000, loss: 0.022573
   Number of active neurons: 2
 >> iter 31000, loss: 0.023072
 >> iter 32000, loss: 0.058815
 >> iter 33000, loss: 0.036342
 >> iter 34000, loss: 0.026506
 >> iter 35000, loss: 0.024411
 >> iter 36000, loss: 0.024581
 >> iter 37000, loss: 0.021100
 >> iter 38000, loss: 0.031161
 >> iter 39000, loss: 0.025899
 >> iter 40000, loss: 0.026573
   Number of active neurons: 2
 >> iter 41000, loss: 0.032181
 >> iter 42000, loss: 0.037180
 >> iter 43000, loss: 0.029408
 >> iter 44000, loss: 0.028286
 >> iter 45000, loss: 0.025975
 >> iter 46000, loss: 0.022471
 >> iter 47000, loss: 0.026552
 >> iter 48000, loss: 0.031750
 >> iter 49000, loss: 0.034309
 >> iter 50000, loss: 0.029128
   Number of active neurons: 2
 >> iter 51000, loss: 0.025192
 >> iter 52000, loss: 0.022465
 >> iter 53000, loss: 0.020914
 >> iter 54000, loss: 0.021578
 >> iter 55000, loss: 0.036827
 >> iter 56000, loss: 0.025256
 >> iter 57000, loss: 0.022739
 >> iter 58000, loss: 0.028862
 >> iter 59000, loss: 0.020987
 >> iter 60000, loss: 0.022059
   Number of active neurons: 1
 >> iter 61000, loss: 0.019086
 >> iter 62000, loss: 0.019713
 >> iter 63000, loss: 0.020179
 >> iter 64000, loss: 0.017779
 >> iter 65000, loss: 0.017575
 >> iter 66000, loss: 0.018831
 >> iter 67000, loss: 0.022479
 >> iter 68000, loss: 0.024845
 >> iter 69000, loss: 0.019445
 >> iter 70000, loss: 0.018029
   Number of active neurons: 1
 >> iter 71000, loss: 0.017546
 >> iter 72000, loss: 0.015638
 >> iter 73000, loss: 0.021775
 >> iter 74000, loss: 0.020403
 >> iter 75000, loss: 0.018320
 >> iter 76000, loss: 0.016005
 >> iter 77000, loss: 0.017232
 >> iter 78000, loss: 0.026619
 >> iter 79000, loss: 0.021942
 >> iter 80000, loss: 0.023151
   Number of active neurons: 1
 >> iter 81000, loss: 0.017926
 >> iter 82000, loss: 0.021465
 >> iter 83000, loss: 0.017786
 >> iter 84000, loss: 0.017023
 >> iter 85000, loss: 0.018504
 >> iter 86000, loss: 0.018860
 >> iter 87000, loss: 0.019413
 >> iter 88000, loss: 0.027233
 >> iter 89000, loss: 0.033012
 >> iter 90000, loss: 0.054792
   Number of active neurons: 1
 >> iter 91000, loss: 0.036813
 >> iter 92000, loss: 0.024098
 >> iter 93000, loss: 0.020823
 >> iter 94000, loss: 0.020182
 >> iter 95000, loss: 0.020859
 >> iter 96000, loss: 0.020934
 >> iter 97000, loss: 0.025701
 >> iter 98000, loss: 0.022500
 >> iter 99000, loss: 0.018696
 >> iter 100000, loss: 0.019549
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.138858
 >> iter 2000, loss: 4.156115
 >> iter 3000, loss: 1.550118
 >> iter 4000, loss: 0.592811
 >> iter 5000, loss: 0.237892
 >> iter 6000, loss: 0.103737
 >> iter 7000, loss: 0.051261
 >> iter 8000, loss: 0.033617
 >> iter 9000, loss: 0.026597
 >> iter 10000, loss: 0.026928
   Number of active neurons: 2
 >> iter 11000, loss: 0.022914
 >> iter 12000, loss: 0.022723
 >> iter 13000, loss: 0.022444
 >> iter 14000, loss: 0.021479
 >> iter 15000, loss: 0.019675
 >> iter 16000, loss: 0.019308
 >> iter 17000, loss: 0.021880
 >> iter 18000, loss: 0.025767
 >> iter 19000, loss: 0.029058
 >> iter 20000, loss: 0.022815
   Number of active neurons: 2
 >> iter 21000, loss: 0.035843
 >> iter 22000, loss: 0.027798
 >> iter 23000, loss: 0.026966
 >> iter 24000, loss: 0.022365
 >> iter 25000, loss: 0.021160
 >> iter 26000, loss: 0.030799
 >> iter 27000, loss: 0.031867
 >> iter 28000, loss: 0.026931
 >> iter 29000, loss: 0.026155
 >> iter 30000, loss: 0.022440
   Number of active neurons: 2
 >> iter 31000, loss: 0.021388
 >> iter 32000, loss: 0.020756
 >> iter 33000, loss: 0.029648
 >> iter 34000, loss: 0.026717
 >> iter 35000, loss: 0.023778
 >> iter 36000, loss: 0.022757
 >> iter 37000, loss: 0.023070
 >> iter 38000, loss: 0.020656
 >> iter 39000, loss: 0.024167
 >> iter 40000, loss: 0.027182
   Number of active neurons: 2
 >> iter 41000, loss: 0.023238
 >> iter 42000, loss: 0.022526
 >> iter 43000, loss: 0.037447
 >> iter 44000, loss: 0.031417
 >> iter 45000, loss: 0.036180
 >> iter 46000, loss: 0.048228
 >> iter 47000, loss: 0.029275
 >> iter 48000, loss: 0.022911
 >> iter 49000, loss: 0.024836
 >> iter 50000, loss: 0.021519
   Number of active neurons: 1
 >> iter 51000, loss: 0.021786
 >> iter 52000, loss: 0.019229
 >> iter 53000, loss: 0.019462
 >> iter 54000, loss: 0.051491
 >> iter 55000, loss: 0.032433
 >> iter 56000, loss: 0.022598
 >> iter 57000, loss: 0.021759
 >> iter 58000, loss: 0.019795
 >> iter 59000, loss: 0.026949
 >> iter 60000, loss: 0.029536
   Number of active neurons: 1
 >> iter 61000, loss: 0.023688
 >> iter 62000, loss: 0.025412
 >> iter 63000, loss: 0.020980
 >> iter 64000, loss: 0.018328
 >> iter 65000, loss: 0.016384
 >> iter 66000, loss: 0.022624
 >> iter 67000, loss: 0.019831
 >> iter 68000, loss: 0.023104
 >> iter 69000, loss: 0.020431
 >> iter 70000, loss: 0.020006
   Number of active neurons: 1
 >> iter 71000, loss: 0.018832
 >> iter 72000, loss: 0.022353
 >> iter 73000, loss: 0.020592
 >> iter 74000, loss: 0.018399
 >> iter 75000, loss: 0.019478
 >> iter 76000, loss: 0.032934
 >> iter 77000, loss: 0.023653
 >> iter 78000, loss: 0.019210
 >> iter 79000, loss: 0.035187
 >> iter 80000, loss: 0.021992
   Number of active neurons: 1
 >> iter 81000, loss: 0.023984
 >> iter 82000, loss: 0.018098
 >> iter 83000, loss: 0.030711
 >> iter 84000, loss: 0.022960
 >> iter 85000, loss: 0.022786
 >> iter 86000, loss: 0.019887
 >> iter 87000, loss: 0.018457
 >> iter 88000, loss: 0.020494
 >> iter 89000, loss: 0.036550
 >> iter 90000, loss: 0.042744
   Number of active neurons: 1
 >> iter 91000, loss: 0.028169
 >> iter 92000, loss: 0.026107
 >> iter 93000, loss: 0.020245
 >> iter 94000, loss: 0.023869
 >> iter 95000, loss: 0.019224
 >> iter 96000, loss: 0.025248
 >> iter 97000, loss: 0.020714
 >> iter 98000, loss: 0.020830
 >> iter 99000, loss: 0.018103
 >> iter 100000, loss: 0.020069
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.995086
 >> iter 2000, loss: 4.080589
 >> iter 3000, loss: 1.540793
 >> iter 4000, loss: 0.587878
 >> iter 5000, loss: 0.232367
 >> iter 6000, loss: 0.101349
 >> iter 7000, loss: 0.052299
 >> iter 8000, loss: 0.032191
 >> iter 9000, loss: 0.037944
 >> iter 10000, loss: 0.028197
   Number of active neurons: 2
 >> iter 11000, loss: 0.026299
 >> iter 12000, loss: 0.021835
 >> iter 13000, loss: 0.024832
 >> iter 14000, loss: 0.024431
 >> iter 15000, loss: 0.022688
 >> iter 16000, loss: 0.022828
 >> iter 17000, loss: 0.022822
 >> iter 18000, loss: 0.023795
 >> iter 19000, loss: 0.021235
 >> iter 20000, loss: 0.020372
   Number of active neurons: 2
 >> iter 21000, loss: 0.023594
 >> iter 22000, loss: 0.020486
 >> iter 23000, loss: 0.030462
 >> iter 24000, loss: 0.024367
 >> iter 25000, loss: 0.024390
 >> iter 26000, loss: 0.025311
 >> iter 27000, loss: 0.023880
 >> iter 28000, loss: 0.021839
 >> iter 29000, loss: 0.064421
 >> iter 30000, loss: 0.038698
   Number of active neurons: 2
 >> iter 31000, loss: 0.031005
 >> iter 32000, loss: 0.025001
 >> iter 33000, loss: 0.027178
 >> iter 34000, loss: 0.023071
 >> iter 35000, loss: 0.023692
 >> iter 36000, loss: 0.019762
 >> iter 37000, loss: 0.020778
 >> iter 38000, loss: 0.021737
 >> iter 39000, loss: 0.020384
 >> iter 40000, loss: 0.051217
   Number of active neurons: 2
 >> iter 41000, loss: 0.033486
 >> iter 42000, loss: 0.024594
 >> iter 43000, loss: 0.022490
 >> iter 44000, loss: 0.022455
 >> iter 45000, loss: 0.027145
 >> iter 46000, loss: 0.022409
 >> iter 47000, loss: 0.032664
 >> iter 48000, loss: 0.025834
 >> iter 49000, loss: 0.024561
 >> iter 50000, loss: 0.025626
   Number of active neurons: 2
 >> iter 51000, loss: 0.023712
 >> iter 52000, loss: 0.022500
 >> iter 53000, loss: 0.023222
 >> iter 54000, loss: 0.021190
 >> iter 55000, loss: 0.023919
 >> iter 56000, loss: 0.022318
 >> iter 57000, loss: 0.024406
 >> iter 58000, loss: 0.022545
 >> iter 59000, loss: 0.021251
 >> iter 60000, loss: 0.020515
   Number of active neurons: 2
 >> iter 61000, loss: 0.022546
 >> iter 62000, loss: 0.023670
 >> iter 63000, loss: 0.023586
 >> iter 64000, loss: 0.022925
 >> iter 65000, loss: 0.022625
 >> iter 66000, loss: 0.020906
 >> iter 67000, loss: 0.023528
 >> iter 68000, loss: 0.026121
 >> iter 69000, loss: 0.021844
 >> iter 70000, loss: 0.020057
   Number of active neurons: 2
 >> iter 71000, loss: 0.023127
 >> iter 72000, loss: 0.027795
 >> iter 73000, loss: 0.023036
 >> iter 74000, loss: 0.020645
 >> iter 75000, loss: 0.029122
 >> iter 76000, loss: 0.024588
 >> iter 77000, loss: 0.023792
 >> iter 78000, loss: 0.021581
 >> iter 79000, loss: 0.024600
 >> iter 80000, loss: 0.025454
   Number of active neurons: 2
 >> iter 81000, loss: 0.027101
 >> iter 82000, loss: 0.022514
 >> iter 83000, loss: 0.021329
 >> iter 84000, loss: 0.047122
 >> iter 85000, loss: 0.031095
 >> iter 86000, loss: 0.028119
 >> iter 87000, loss: 0.025385
 >> iter 88000, loss: 0.027505
 >> iter 89000, loss: 0.022280
 >> iter 90000, loss: 0.020895
   Number of active neurons: 2
 >> iter 91000, loss: 0.028635
 >> iter 92000, loss: 0.041469
 >> iter 93000, loss: 0.030895
 >> iter 94000, loss: 0.034218
 >> iter 95000, loss: 0.027358
 >> iter 96000, loss: 0.023736
 >> iter 97000, loss: 0.022193
 >> iter 98000, loss: 0.021170
 >> iter 99000, loss: 0.034347
 >> iter 100000, loss: 0.058052
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.995330
 >> iter 2000, loss: 4.093647
 >> iter 3000, loss: 1.536208
 >> iter 4000, loss: 0.599948
 >> iter 5000, loss: 0.239266
 >> iter 6000, loss: 0.103772
 >> iter 7000, loss: 0.051373
 >> iter 8000, loss: 0.035591
 >> iter 9000, loss: 0.037349
 >> iter 10000, loss: 0.029212
   Number of active neurons: 2
 >> iter 11000, loss: 0.024907
 >> iter 12000, loss: 0.022014
 >> iter 13000, loss: 0.021549
 >> iter 14000, loss: 0.024296
 >> iter 15000, loss: 0.021766
 >> iter 16000, loss: 0.021666
 >> iter 17000, loss: 0.024406
 >> iter 18000, loss: 0.025288
 >> iter 19000, loss: 0.021660
 >> iter 20000, loss: 0.025750
   Number of active neurons: 2
 >> iter 21000, loss: 0.023158
 >> iter 22000, loss: 0.027643
 >> iter 23000, loss: 0.023350
 >> iter 24000, loss: 0.021812
 >> iter 25000, loss: 0.025606
 >> iter 26000, loss: 0.025279
 >> iter 27000, loss: 0.022416
 >> iter 28000, loss: 0.020159
 >> iter 29000, loss: 0.022527
 >> iter 30000, loss: 0.023915
   Number of active neurons: 2
 >> iter 31000, loss: 0.020313
 >> iter 32000, loss: 0.019668
 >> iter 33000, loss: 0.018926
 >> iter 34000, loss: 0.018273
 >> iter 35000, loss: 0.021632
 >> iter 36000, loss: 0.024905
 >> iter 37000, loss: 0.026257
 >> iter 38000, loss: 0.023086
 >> iter 39000, loss: 0.022590
 >> iter 40000, loss: 0.022188
   Number of active neurons: 2
 >> iter 41000, loss: 0.024963
 >> iter 42000, loss: 0.021317
 >> iter 43000, loss: 0.021340
 >> iter 44000, loss: 0.034458
 >> iter 45000, loss: 0.030480
 >> iter 46000, loss: 0.041348
 >> iter 47000, loss: 0.037903
 >> iter 48000, loss: 0.026918
 >> iter 49000, loss: 0.024136
 >> iter 50000, loss: 0.023250
   Number of active neurons: 2
 >> iter 51000, loss: 0.022844
 >> iter 52000, loss: 0.021287
 >> iter 53000, loss: 0.021604
 >> iter 54000, loss: 0.019956
 >> iter 55000, loss: 0.020018
 >> iter 56000, loss: 0.024964
 >> iter 57000, loss: 0.032356
 >> iter 58000, loss: 0.025697
 >> iter 59000, loss: 0.026885
 >> iter 60000, loss: 0.024078
   Number of active neurons: 2
 >> iter 61000, loss: 0.023139
 >> iter 62000, loss: 0.024288
 >> iter 63000, loss: 0.036011
 >> iter 64000, loss: 0.026689
 >> iter 65000, loss: 0.024509
 >> iter 66000, loss: 0.029262
 >> iter 67000, loss: 0.034527
 >> iter 68000, loss: 0.034326
 >> iter 69000, loss: 0.028809
 >> iter 70000, loss: 0.022981
   Number of active neurons: 2
 >> iter 71000, loss: 0.026480
 >> iter 72000, loss: 0.021748
 >> iter 73000, loss: 0.024645
 >> iter 74000, loss: 0.023968
 >> iter 75000, loss: 0.024466
 >> iter 76000, loss: 0.021760
 >> iter 77000, loss: 0.029636
 >> iter 78000, loss: 0.026416
 >> iter 79000, loss: 0.026498
 >> iter 80000, loss: 0.022863
   Number of active neurons: 2
 >> iter 81000, loss: 0.021080
 >> iter 82000, loss: 0.039065
 >> iter 83000, loss: 0.036511
 >> iter 84000, loss: 0.027405
 >> iter 85000, loss: 0.023351
 >> iter 86000, loss: 0.024646
 >> iter 87000, loss: 0.026577
 >> iter 88000, loss: 0.035898
 >> iter 89000, loss: 0.029093
 >> iter 90000, loss: 0.044165
   Number of active neurons: 2
 >> iter 91000, loss: 0.033213
 >> iter 92000, loss: 0.025320
 >> iter 93000, loss: 0.021422
 >> iter 94000, loss: 0.027620
 >> iter 95000, loss: 0.035003
 >> iter 96000, loss: 0.032858
 >> iter 97000, loss: 0.032906
 >> iter 98000, loss: 0.034335
 >> iter 99000, loss: 0.025510
 >> iter 100000, loss: 0.026161
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.995190
 >> iter 2000, loss: 4.076446
 >> iter 3000, loss: 1.528377
 >> iter 4000, loss: 0.585102
 >> iter 5000, loss: 0.243642
 >> iter 6000, loss: 0.104541
 >> iter 7000, loss: 0.056430
 >> iter 8000, loss: 0.035278
 >> iter 9000, loss: 0.045160
 >> iter 10000, loss: 0.030161
   Number of active neurons: 2
 >> iter 11000, loss: 0.025352
 >> iter 12000, loss: 0.021493
 >> iter 13000, loss: 0.023036
 >> iter 14000, loss: 0.024215
 >> iter 15000, loss: 0.027378
 >> iter 16000, loss: 0.026580
 >> iter 17000, loss: 0.021458
 >> iter 18000, loss: 0.020809
 >> iter 19000, loss: 0.023024
 >> iter 20000, loss: 0.023592
   Number of active neurons: 2
 >> iter 21000, loss: 0.022135
 >> iter 22000, loss: 0.023697
 >> iter 23000, loss: 0.033842
 >> iter 24000, loss: 0.024585
 >> iter 25000, loss: 0.021813
 >> iter 26000, loss: 0.020871
 >> iter 27000, loss: 0.025820
 >> iter 28000, loss: 0.022949
 >> iter 29000, loss: 0.024096
 >> iter 30000, loss: 0.024677
   Number of active neurons: 2
 >> iter 31000, loss: 0.025831
 >> iter 32000, loss: 0.020951
 >> iter 33000, loss: 0.021508
 >> iter 34000, loss: 0.028358
 >> iter 35000, loss: 0.024945
 >> iter 36000, loss: 0.024018
 >> iter 37000, loss: 0.021859
 >> iter 38000, loss: 0.020982
 >> iter 39000, loss: 0.027667
 >> iter 40000, loss: 0.021888
   Number of active neurons: 2
 >> iter 41000, loss: 0.022896
 >> iter 42000, loss: 0.024076
 >> iter 43000, loss: 0.024010
 >> iter 44000, loss: 0.024785
 >> iter 45000, loss: 0.038021
 >> iter 46000, loss: 0.032071
 >> iter 47000, loss: 0.025825
 >> iter 48000, loss: 0.023730
 >> iter 49000, loss: 0.033416
 >> iter 50000, loss: 0.026480
   Number of active neurons: 2
 >> iter 51000, loss: 0.025809
 >> iter 52000, loss: 0.023327
 >> iter 53000, loss: 0.020639
 >> iter 54000, loss: 0.020255
 >> iter 55000, loss: 0.018934
 >> iter 56000, loss: 0.024254
 >> iter 57000, loss: 0.024250
 >> iter 58000, loss: 0.021796
 >> iter 59000, loss: 0.021419
 >> iter 60000, loss: 0.019066
   Number of active neurons: 2
 >> iter 61000, loss: 0.020548
 >> iter 62000, loss: 0.022222
 >> iter 63000, loss: 0.022012
 >> iter 64000, loss: 0.034105
 >> iter 65000, loss: 0.026285
 >> iter 66000, loss: 0.022130
 >> iter 67000, loss: 0.021680
 >> iter 68000, loss: 0.024120
 >> iter 69000, loss: 0.022996
 >> iter 70000, loss: 0.029571
   Number of active neurons: 2
 >> iter 71000, loss: 0.023199
 >> iter 72000, loss: 0.022738
 >> iter 73000, loss: 0.021606
 >> iter 74000, loss: 0.020441
 >> iter 75000, loss: 0.019862
 >> iter 76000, loss: 0.022165
 >> iter 77000, loss: 0.029243
 >> iter 78000, loss: 0.023555
 >> iter 79000, loss: 0.027547
 >> iter 80000, loss: 0.022591
   Number of active neurons: 2
 >> iter 81000, loss: 0.021770
 >> iter 82000, loss: 0.023250
 >> iter 83000, loss: 0.020849
 >> iter 84000, loss: 0.029180
 >> iter 85000, loss: 0.026221
 >> iter 86000, loss: 0.022134
 >> iter 87000, loss: 0.023523
 >> iter 88000, loss: 0.027106
 >> iter 89000, loss: 0.032376
 >> iter 90000, loss: 0.025529
   Number of active neurons: 2
 >> iter 91000, loss: 0.021221
 >> iter 92000, loss: 0.055206
 >> iter 93000, loss: 0.052863
 >> iter 94000, loss: 0.039290
 >> iter 95000, loss: 0.028700
 >> iter 96000, loss: 0.028282
 >> iter 97000, loss: 0.025839
 >> iter 98000, loss: 0.021456
 >> iter 99000, loss: 0.023421
 >> iter 100000, loss: 0.021371
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.058699
 >> iter 2000, loss: 4.103144
 >> iter 3000, loss: 1.539161
 >> iter 4000, loss: 0.586972
 >> iter 5000, loss: 0.249990
 >> iter 6000, loss: 0.106736
 >> iter 7000, loss: 0.061309
 >> iter 8000, loss: 0.065474
 >> iter 9000, loss: 0.046809
 >> iter 10000, loss: 0.029911
   Number of active neurons: 2
 >> iter 11000, loss: 0.037120
 >> iter 12000, loss: 0.028057
 >> iter 13000, loss: 0.024196
 >> iter 14000, loss: 0.032541
 >> iter 15000, loss: 0.027877
 >> iter 16000, loss: 0.022959
 >> iter 17000, loss: 0.021924
 >> iter 18000, loss: 0.021665
 >> iter 19000, loss: 0.020010
 >> iter 20000, loss: 0.022151
   Number of active neurons: 1
 >> iter 21000, loss: 0.021996
 >> iter 22000, loss: 0.024100
 >> iter 23000, loss: 0.023189
 >> iter 24000, loss: 0.018964
 >> iter 25000, loss: 0.021579
 >> iter 26000, loss: 0.038999
 >> iter 27000, loss: 0.032258
 >> iter 28000, loss: 0.023429
 >> iter 29000, loss: 0.043132
 >> iter 30000, loss: 0.029364
   Number of active neurons: 1
 >> iter 31000, loss: 0.021699
 >> iter 32000, loss: 0.018754
 >> iter 33000, loss: 0.017116
 >> iter 34000, loss: 0.037098
 >> iter 35000, loss: 0.031500
 >> iter 36000, loss: 0.030679
 >> iter 37000, loss: 0.023412
 >> iter 38000, loss: 0.017857
 >> iter 39000, loss: 0.023502
 >> iter 40000, loss: 0.018906
   Number of active neurons: 1
 >> iter 41000, loss: 0.018058
 >> iter 42000, loss: 0.018961
 >> iter 43000, loss: 0.018133
 >> iter 44000, loss: 0.017211
 >> iter 45000, loss: 0.015530
 >> iter 46000, loss: 0.017639
 >> iter 47000, loss: 0.021915
 >> iter 48000, loss: 0.021241
 >> iter 49000, loss: 0.031550
 >> iter 50000, loss: 0.033943
   Number of active neurons: 1
 >> iter 51000, loss: 0.034261
 >> iter 52000, loss: 0.040878
 >> iter 53000, loss: 0.027240
 >> iter 54000, loss: 0.021500
 >> iter 55000, loss: 0.019420
 >> iter 56000, loss: 0.017816
 >> iter 57000, loss: 0.018403
 >> iter 58000, loss: 0.019748
 >> iter 59000, loss: 0.019211
 >> iter 60000, loss: 0.018253
   Number of active neurons: 1
 >> iter 61000, loss: 0.018845
 >> iter 62000, loss: 0.017090
 >> iter 63000, loss: 0.016590
 >> iter 64000, loss: 0.016654
 >> iter 65000, loss: 0.023436
 >> iter 66000, loss: 0.024044
 >> iter 67000, loss: 0.019454
 >> iter 68000, loss: 0.016615
 >> iter 69000, loss: 0.020433
 >> iter 70000, loss: 0.017349
   Number of active neurons: 1
 >> iter 71000, loss: 0.016806
 >> iter 72000, loss: 0.024481
 >> iter 73000, loss: 0.022699
 >> iter 74000, loss: 0.018924
 >> iter 75000, loss: 0.030517
 >> iter 76000, loss: 0.023808
 >> iter 77000, loss: 0.018422
 >> iter 78000, loss: 0.017925
 >> iter 79000, loss: 0.019172
 >> iter 80000, loss: 0.029730
   Number of active neurons: 1
 >> iter 81000, loss: 0.028117
 >> iter 82000, loss: 0.041556
 >> iter 83000, loss: 0.047584
 >> iter 84000, loss: 0.027949
 >> iter 85000, loss: 0.024048
 >> iter 86000, loss: 0.037532
 >> iter 87000, loss: 0.056345
 >> iter 88000, loss: 0.031897
 >> iter 89000, loss: 0.023180
 >> iter 90000, loss: 0.048697
   Number of active neurons: 1
 >> iter 91000, loss: 0.071665
 >> iter 92000, loss: 0.039776
 >> iter 93000, loss: 0.033490
 >> iter 94000, loss: 0.027412
 >> iter 95000, loss: 0.021504
 >> iter 96000, loss: 0.028050
 >> iter 97000, loss: 0.021511
 >> iter 98000, loss: 0.018550
 >> iter 99000, loss: 0.019855
 >> iter 100000, loss: 0.020855
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.989407
 >> iter 2000, loss: 4.092640
 >> iter 3000, loss: 1.527091
 >> iter 4000, loss: 0.582580
 >> iter 5000, loss: 0.230459
 >> iter 6000, loss: 0.100706
 >> iter 7000, loss: 0.053176
 >> iter 8000, loss: 0.034676
 >> iter 9000, loss: 0.037590
 >> iter 10000, loss: 0.027557
   Number of active neurons: 2
 >> iter 11000, loss: 0.027731
 >> iter 12000, loss: 0.024143
 >> iter 13000, loss: 0.023352
 >> iter 14000, loss: 0.023077
 >> iter 15000, loss: 0.021732
 >> iter 16000, loss: 0.021428
 >> iter 17000, loss: 0.021081
 >> iter 18000, loss: 0.025026
 >> iter 19000, loss: 0.024220
 >> iter 20000, loss: 0.022396
   Number of active neurons: 2
 >> iter 21000, loss: 0.022502
 >> iter 22000, loss: 0.020752
 >> iter 23000, loss: 0.021321
 >> iter 24000, loss: 0.030295
 >> iter 25000, loss: 0.027114
 >> iter 26000, loss: 0.023366
 >> iter 27000, loss: 0.029031
 >> iter 28000, loss: 0.027734
 >> iter 29000, loss: 0.025006
 >> iter 30000, loss: 0.026506
   Number of active neurons: 2
 >> iter 31000, loss: 0.022081
 >> iter 32000, loss: 0.026452
 >> iter 33000, loss: 0.027197
 >> iter 34000, loss: 0.026631
 >> iter 35000, loss: 0.021757
 >> iter 36000, loss: 0.022388
 >> iter 37000, loss: 0.023724
 >> iter 38000, loss: 0.022003
 >> iter 39000, loss: 0.022103
 >> iter 40000, loss: 0.033812
   Number of active neurons: 2
 >> iter 41000, loss: 0.025011
 >> iter 42000, loss: 0.026874
 >> iter 43000, loss: 0.024428
 >> iter 44000, loss: 0.020866
 >> iter 45000, loss: 0.023036
 >> iter 46000, loss: 0.026613
 >> iter 47000, loss: 0.040215
 >> iter 48000, loss: 0.042235
 >> iter 49000, loss: 0.052670
 >> iter 50000, loss: 0.033863
   Number of active neurons: 2
 >> iter 51000, loss: 0.025869
 >> iter 52000, loss: 0.022699
 >> iter 53000, loss: 0.045502
 >> iter 54000, loss: 0.030631
 >> iter 55000, loss: 0.028453
 >> iter 56000, loss: 0.025828
 >> iter 57000, loss: 0.029872
 >> iter 58000, loss: 0.032046
 >> iter 59000, loss: 0.028128
 >> iter 60000, loss: 0.022181
   Number of active neurons: 2
 >> iter 61000, loss: 0.034679
 >> iter 62000, loss: 0.025141
 >> iter 63000, loss: 0.024143
 >> iter 64000, loss: 0.034193
 >> iter 65000, loss: 0.052264
 >> iter 66000, loss: 0.033729
 >> iter 67000, loss: 0.024912
 >> iter 68000, loss: 0.026359
 >> iter 69000, loss: 0.023945
 >> iter 70000, loss: 0.022039
   Number of active neurons: 2
 >> iter 71000, loss: 0.022914
 >> iter 72000, loss: 0.025631
 >> iter 73000, loss: 0.026018
 >> iter 74000, loss: 0.033615
 >> iter 75000, loss: 0.024194
 >> iter 76000, loss: 0.026278
 >> iter 77000, loss: 0.022707
 >> iter 78000, loss: 0.046664
 >> iter 79000, loss: 0.050222
 >> iter 80000, loss: 0.033000
   Number of active neurons: 2
 >> iter 81000, loss: 0.027198
 >> iter 82000, loss: 0.027980
 >> iter 83000, loss: 0.027814
 >> iter 84000, loss: 0.024644
 >> iter 85000, loss: 0.031042
 >> iter 86000, loss: 0.023360
 >> iter 87000, loss: 0.023106
 >> iter 88000, loss: 0.025453
 >> iter 89000, loss: 0.033454
 >> iter 90000, loss: 0.036394
   Number of active neurons: 2
 >> iter 91000, loss: 0.028569
 >> iter 92000, loss: 0.023882
 >> iter 93000, loss: 0.023736
 >> iter 94000, loss: 0.021562
 >> iter 95000, loss: 0.025577
 >> iter 96000, loss: 0.022421
 >> iter 97000, loss: 0.021931
 >> iter 98000, loss: 0.020008
 >> iter 99000, loss: 0.029603
 >> iter 100000, loss: 0.024252
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.018644
 >> iter 2000, loss: 4.090155
 >> iter 3000, loss: 1.534467
 >> iter 4000, loss: 0.595006
 >> iter 5000, loss: 0.234835
 >> iter 6000, loss: 0.102680
 >> iter 7000, loss: 0.053044
 >> iter 8000, loss: 0.033821
 >> iter 9000, loss: 0.027332
 >> iter 10000, loss: 0.025800
   Number of active neurons: 2
 >> iter 11000, loss: 0.022621
 >> iter 12000, loss: 0.022702
 >> iter 13000, loss: 0.027124
 >> iter 14000, loss: 0.035157
 >> iter 15000, loss: 0.030279
 >> iter 16000, loss: 0.051341
 >> iter 17000, loss: 0.040395
 >> iter 18000, loss: 0.037707
 >> iter 19000, loss: 0.027355
 >> iter 20000, loss: 0.039520
   Number of active neurons: 2
 >> iter 21000, loss: 0.030487
 >> iter 22000, loss: 0.028013
 >> iter 23000, loss: 0.024690
 >> iter 24000, loss: 0.022861
 >> iter 25000, loss: 0.021025
 >> iter 26000, loss: 0.023317
 >> iter 27000, loss: 0.021234
 >> iter 28000, loss: 0.021571
 >> iter 29000, loss: 0.021903
 >> iter 30000, loss: 0.021977
   Number of active neurons: 1
 >> iter 31000, loss: 0.019869
 >> iter 32000, loss: 0.026325
 >> iter 33000, loss: 0.020833
 >> iter 34000, loss: 0.024354
 >> iter 35000, loss: 0.019406
 >> iter 36000, loss: 0.022930
 >> iter 37000, loss: 0.024570
 >> iter 38000, loss: 0.020912
 >> iter 39000, loss: 0.028364
 >> iter 40000, loss: 0.023121
   Number of active neurons: 1
 >> iter 41000, loss: 0.019858
 >> iter 42000, loss: 0.037346
 >> iter 43000, loss: 0.025677
 >> iter 44000, loss: 0.021101
 >> iter 45000, loss: 0.028186
 >> iter 46000, loss: 0.020534
 >> iter 47000, loss: 0.017991
 >> iter 48000, loss: 0.019759
 >> iter 49000, loss: 0.019764
 >> iter 50000, loss: 0.030959
   Number of active neurons: 1
 >> iter 51000, loss: 0.021899
 >> iter 52000, loss: 0.020217
 >> iter 53000, loss: 0.032262
 >> iter 54000, loss: 0.022089
 >> iter 55000, loss: 0.019152
 >> iter 56000, loss: 0.023270
 >> iter 57000, loss: 0.034634
 >> iter 58000, loss: 0.028458
 >> iter 59000, loss: 0.020807
 >> iter 60000, loss: 0.022448
   Number of active neurons: 1
 >> iter 61000, loss: 0.020463
 >> iter 62000, loss: 0.033751
 >> iter 63000, loss: 0.032685
 >> iter 64000, loss: 0.026920
 >> iter 65000, loss: 0.019474
 >> iter 66000, loss: 0.018922
 >> iter 67000, loss: 0.023884
 >> iter 68000, loss: 0.019358
 >> iter 69000, loss: 0.021185
 >> iter 70000, loss: 0.029752
   Number of active neurons: 1
 >> iter 71000, loss: 0.028196
 >> iter 72000, loss: 0.020131
 >> iter 73000, loss: 0.021855
 >> iter 74000, loss: 0.021630
 >> iter 75000, loss: 0.018675
 >> iter 76000, loss: 0.019315
 >> iter 77000, loss: 0.025894
 >> iter 78000, loss: 0.038865
 >> iter 79000, loss: 0.027331
 >> iter 80000, loss: 0.030843
   Number of active neurons: 1
 >> iter 81000, loss: 0.020677
 >> iter 82000, loss: 0.018691
 >> iter 83000, loss: 0.019738
 >> iter 84000, loss: 0.017911
 >> iter 85000, loss: 0.017819
 >> iter 86000, loss: 0.021055
 >> iter 87000, loss: 0.019467
 >> iter 88000, loss: 0.034105
 >> iter 89000, loss: 0.030573
 >> iter 90000, loss: 0.023623
   Number of active neurons: 1
 >> iter 91000, loss: 0.020059
 >> iter 92000, loss: 0.021994
 >> iter 93000, loss: 0.019144
 >> iter 94000, loss: 0.020205
 >> iter 95000, loss: 0.020882
 >> iter 96000, loss: 0.025342
 >> iter 97000, loss: 0.019965
 >> iter 98000, loss: 0.027648
 >> iter 99000, loss: 0.021214
 >> iter 100000, loss: 0.021555
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.015417
 >> iter 2000, loss: 4.088018
 >> iter 3000, loss: 1.540786
 >> iter 4000, loss: 0.594598
 >> iter 5000, loss: 0.239779
 >> iter 6000, loss: 0.105058
 >> iter 7000, loss: 0.053459
 >> iter 8000, loss: 0.034444
 >> iter 9000, loss: 0.029999
 >> iter 10000, loss: 0.040797
   Number of active neurons: 2
 >> iter 11000, loss: 0.028616
 >> iter 12000, loss: 0.033252
 >> iter 13000, loss: 0.025804
 >> iter 14000, loss: 0.023513
 >> iter 15000, loss: 0.024326
 >> iter 16000, loss: 0.021473
 >> iter 17000, loss: 0.022353
 >> iter 18000, loss: 0.030370
 >> iter 19000, loss: 0.023236
 >> iter 20000, loss: 0.021359
   Number of active neurons: 2
 >> iter 21000, loss: 0.021429
 >> iter 22000, loss: 0.025999
 >> iter 23000, loss: 0.032146
 >> iter 24000, loss: 0.027541
 >> iter 25000, loss: 0.025157
 >> iter 26000, loss: 0.021166
 >> iter 27000, loss: 0.021221
 >> iter 28000, loss: 0.025220
 >> iter 29000, loss: 0.022693
 >> iter 30000, loss: 0.020611
   Number of active neurons: 1
 >> iter 31000, loss: 0.018740
 >> iter 32000, loss: 0.027433
 >> iter 33000, loss: 0.027162
 >> iter 34000, loss: 0.019689
 >> iter 35000, loss: 0.038599
 >> iter 36000, loss: 0.026773
 >> iter 37000, loss: 0.023460
 >> iter 38000, loss: 0.029829
 >> iter 39000, loss: 0.021907
 >> iter 40000, loss: 0.018510
   Number of active neurons: 1
 >> iter 41000, loss: 0.020696
 >> iter 42000, loss: 0.019590
 >> iter 43000, loss: 0.018075
 >> iter 44000, loss: 0.016028
 >> iter 45000, loss: 0.021389
 >> iter 46000, loss: 0.026130
 >> iter 47000, loss: 0.024083
 >> iter 48000, loss: 0.019299
 >> iter 49000, loss: 0.025630
 >> iter 50000, loss: 0.041587
   Number of active neurons: 1
 >> iter 51000, loss: 0.044950
 >> iter 52000, loss: 0.026588
 >> iter 53000, loss: 0.021995
 >> iter 54000, loss: 0.019468
 >> iter 55000, loss: 0.020037
 >> iter 56000, loss: 0.018465
 >> iter 57000, loss: 0.018757
 >> iter 58000, loss: 0.016575
 >> iter 59000, loss: 0.023871
 >> iter 60000, loss: 0.033028
   Number of active neurons: 1
 >> iter 61000, loss: 0.029419
 >> iter 62000, loss: 0.023073
 >> iter 63000, loss: 0.020476
 >> iter 64000, loss: 0.023080
 >> iter 65000, loss: 0.038678
 >> iter 66000, loss: 0.027174
 >> iter 67000, loss: 0.020885
 >> iter 68000, loss: 0.019419
 >> iter 69000, loss: 0.018149
 >> iter 70000, loss: 0.026220
   Number of active neurons: 1
 >> iter 71000, loss: 0.020783
 >> iter 72000, loss: 0.036706
 >> iter 73000, loss: 0.035694
 >> iter 74000, loss: 0.025703
 >> iter 75000, loss: 0.025212
 >> iter 76000, loss: 0.025896
 >> iter 77000, loss: 0.019100
 >> iter 78000, loss: 0.018480
 >> iter 79000, loss: 0.026099
 >> iter 80000, loss: 0.021656
   Number of active neurons: 1
 >> iter 81000, loss: 0.027913
 >> iter 82000, loss: 0.022838
 >> iter 83000, loss: 0.026866
 >> iter 84000, loss: 0.024519
 >> iter 85000, loss: 0.019010
 >> iter 86000, loss: 0.018557
 >> iter 87000, loss: 0.016954
 >> iter 88000, loss: 0.016164
 >> iter 89000, loss: 0.017212
 >> iter 90000, loss: 0.021947
   Number of active neurons: 1
 >> iter 91000, loss: 0.023176
 >> iter 92000, loss: 0.019014
 >> iter 93000, loss: 0.019746
 >> iter 94000, loss: 0.018985
 >> iter 95000, loss: 0.016882
 >> iter 96000, loss: 0.019043
 >> iter 97000, loss: 0.018109
 >> iter 98000, loss: 0.024584
 >> iter 99000, loss: 0.018310
 >> iter 100000, loss: 0.022284
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.021290
 >> iter 2000, loss: 4.098060
 >> iter 3000, loss: 1.526342
 >> iter 4000, loss: 0.601384
 >> iter 5000, loss: 0.246044
 >> iter 6000, loss: 0.113947
 >> iter 7000, loss: 0.080647
 >> iter 8000, loss: 0.049217
 >> iter 9000, loss: 0.040114
 >> iter 10000, loss: 0.029821
   Number of active neurons: 2
 >> iter 11000, loss: 0.024152
 >> iter 12000, loss: 0.022203
 >> iter 13000, loss: 0.022144
 >> iter 14000, loss: 0.025741
 >> iter 15000, loss: 0.022533
 >> iter 16000, loss: 0.047257
 >> iter 17000, loss: 0.040081
 >> iter 18000, loss: 0.029553
 >> iter 19000, loss: 0.025924
 >> iter 20000, loss: 0.026452
   Number of active neurons: 2
 >> iter 21000, loss: 0.023603
 >> iter 22000, loss: 0.022350
 >> iter 23000, loss: 0.022295
 >> iter 24000, loss: 0.020890
 >> iter 25000, loss: 0.053044
 >> iter 26000, loss: 0.034183
 >> iter 27000, loss: 0.027293
 >> iter 28000, loss: 0.031372
 >> iter 29000, loss: 0.024294
 >> iter 30000, loss: 0.025510
   Number of active neurons: 2
 >> iter 31000, loss: 0.028755
 >> iter 32000, loss: 0.031650
 >> iter 33000, loss: 0.044098
 >> iter 34000, loss: 0.029077
 >> iter 35000, loss: 0.026360
 >> iter 36000, loss: 0.031088
 >> iter 37000, loss: 0.023362
 >> iter 38000, loss: 0.020784
 >> iter 39000, loss: 0.021154
 >> iter 40000, loss: 0.022193
   Number of active neurons: 2
 >> iter 41000, loss: 0.022737
 >> iter 42000, loss: 0.024522
 >> iter 43000, loss: 0.026081
 >> iter 44000, loss: 0.026384
 >> iter 45000, loss: 0.025126
 >> iter 46000, loss: 0.024647
 >> iter 47000, loss: 0.023981
 >> iter 48000, loss: 0.021416
 >> iter 49000, loss: 0.022193
 >> iter 50000, loss: 0.054584
   Number of active neurons: 2
 >> iter 51000, loss: 0.040983
 >> iter 52000, loss: 0.028021
 >> iter 53000, loss: 0.023046
 >> iter 54000, loss: 0.024929
 >> iter 55000, loss: 0.023023
 >> iter 56000, loss: 0.024067
 >> iter 57000, loss: 0.022714
 >> iter 58000, loss: 0.020988
 >> iter 59000, loss: 0.034445
 >> iter 60000, loss: 0.025162
   Number of active neurons: 2
 >> iter 61000, loss: 0.023168
 >> iter 62000, loss: 0.021138
 >> iter 63000, loss: 0.022555
 >> iter 64000, loss: 0.024733
 >> iter 65000, loss: 0.023874
 >> iter 66000, loss: 0.021424
 >> iter 67000, loss: 0.024945
 >> iter 68000, loss: 0.021531
 >> iter 69000, loss: 0.020273
 >> iter 70000, loss: 0.023523
   Number of active neurons: 2
 >> iter 71000, loss: 0.022380
 >> iter 72000, loss: 0.020849
 >> iter 73000, loss: 0.020784
 >> iter 74000, loss: 0.025687
 >> iter 75000, loss: 0.021646
 >> iter 76000, loss: 0.020539
 >> iter 77000, loss: 0.027367
 >> iter 78000, loss: 0.032177
 >> iter 79000, loss: 0.037466
 >> iter 80000, loss: 0.025010
   Number of active neurons: 1
 >> iter 81000, loss: 0.024486
 >> iter 82000, loss: 0.021819
 >> iter 83000, loss: 0.018299
 >> iter 84000, loss: 0.018519
 >> iter 85000, loss: 0.017680
 >> iter 86000, loss: 0.018886
 >> iter 87000, loss: 0.017431
 >> iter 88000, loss: 0.021201
 >> iter 89000, loss: 0.018432
 >> iter 90000, loss: 0.025626
   Number of active neurons: 1
 >> iter 91000, loss: 0.029365
 >> iter 92000, loss: 0.039374
 >> iter 93000, loss: 0.024539
 >> iter 94000, loss: 0.020503
 >> iter 95000, loss: 0.018987
 >> iter 96000, loss: 0.016718
 >> iter 97000, loss: 0.020660
 >> iter 98000, loss: 0.019718
 >> iter 99000, loss: 0.019772
 >> iter 100000, loss: 0.018919
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.218630
 >> iter 2000, loss: 4.165431
 >> iter 3000, loss: 1.557976
 >> iter 4000, loss: 0.590684
 >> iter 5000, loss: 0.235909
 >> iter 6000, loss: 0.100907
 >> iter 7000, loss: 0.057348
 >> iter 8000, loss: 0.035120
 >> iter 9000, loss: 0.025891
 >> iter 10000, loss: 0.028832
   Number of active neurons: 2
 >> iter 11000, loss: 0.033612
 >> iter 12000, loss: 0.025792
 >> iter 13000, loss: 0.025548
 >> iter 14000, loss: 0.031482
 >> iter 15000, loss: 0.032699
 >> iter 16000, loss: 0.038328
 >> iter 17000, loss: 0.037385
 >> iter 18000, loss: 0.029274
 >> iter 19000, loss: 0.023134
 >> iter 20000, loss: 0.041134
   Number of active neurons: 2
 >> iter 21000, loss: 0.029211
 >> iter 22000, loss: 0.023567
 >> iter 23000, loss: 0.035516
 >> iter 24000, loss: 0.027808
 >> iter 25000, loss: 0.023530
 >> iter 26000, loss: 0.052856
 >> iter 27000, loss: 0.034874
 >> iter 28000, loss: 0.027053
 >> iter 29000, loss: 0.024801
 >> iter 30000, loss: 0.028725
   Number of active neurons: 2
 >> iter 31000, loss: 0.029625
 >> iter 32000, loss: 0.024708
 >> iter 33000, loss: 0.021402
 >> iter 34000, loss: 0.020878
 >> iter 35000, loss: 0.051908
 >> iter 36000, loss: 0.044274
 >> iter 37000, loss: 0.029940
 >> iter 38000, loss: 0.032023
 >> iter 39000, loss: 0.024454
 >> iter 40000, loss: 0.026014
   Number of active neurons: 2
 >> iter 41000, loss: 0.022940
 >> iter 42000, loss: 0.021356
 >> iter 43000, loss: 0.019986
 >> iter 44000, loss: 0.022331
 >> iter 45000, loss: 0.037966
 >> iter 46000, loss: 0.026501
 >> iter 47000, loss: 0.027003
 >> iter 48000, loss: 0.021322
 >> iter 49000, loss: 0.019086
 >> iter 50000, loss: 0.027096
   Number of active neurons: 1
 >> iter 51000, loss: 0.023211
 >> iter 52000, loss: 0.027108
 >> iter 53000, loss: 0.021350
 >> iter 54000, loss: 0.017394
 >> iter 55000, loss: 0.029375
 >> iter 56000, loss: 0.022320
 >> iter 57000, loss: 0.022132
 >> iter 58000, loss: 0.028813
 >> iter 59000, loss: 0.022820
 >> iter 60000, loss: 0.027058
   Number of active neurons: 1
 >> iter 61000, loss: 0.032863
 >> iter 62000, loss: 0.024483
 >> iter 63000, loss: 0.027003
 >> iter 64000, loss: 0.035515
 >> iter 65000, loss: 0.024439
 >> iter 66000, loss: 0.022610
 >> iter 67000, loss: 0.018532
 >> iter 68000, loss: 0.030638
 >> iter 69000, loss: 0.028200
 >> iter 70000, loss: 0.020558
   Number of active neurons: 1
 >> iter 71000, loss: 0.040970
 >> iter 72000, loss: 0.049478
 >> iter 73000, loss: 0.032613
 >> iter 74000, loss: 0.032112
 >> iter 75000, loss: 0.022933
 >> iter 76000, loss: 0.021599
 >> iter 77000, loss: 0.018047
 >> iter 78000, loss: 0.029050
 >> iter 79000, loss: 0.021174
 >> iter 80000, loss: 0.021744
   Number of active neurons: 1
 >> iter 81000, loss: 0.020867
 >> iter 82000, loss: 0.024223
 >> iter 83000, loss: 0.018545
 >> iter 84000, loss: 0.022780
 >> iter 85000, loss: 0.019572
 >> iter 86000, loss: 0.028544
 >> iter 87000, loss: 0.031184
 >> iter 88000, loss: 0.025564
 >> iter 89000, loss: 0.057151
 >> iter 90000, loss: 0.031485
   Number of active neurons: 1
 >> iter 91000, loss: 0.025058
 >> iter 92000, loss: 0.020063
 >> iter 93000, loss: 0.022996
 >> iter 94000, loss: 0.021118
 >> iter 95000, loss: 0.020159
 >> iter 96000, loss: 0.021605
 >> iter 97000, loss: 0.020082
 >> iter 98000, loss: 0.020757
 >> iter 99000, loss: 0.021172
 >> iter 100000, loss: 0.020004
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.042932
 >> iter 2000, loss: 4.106555
 >> iter 3000, loss: 1.539669
 >> iter 4000, loss: 0.583301
 >> iter 5000, loss: 0.241052
 >> iter 6000, loss: 0.103693
 >> iter 7000, loss: 0.053193
 >> iter 8000, loss: 0.031666
 >> iter 9000, loss: 0.027663
 >> iter 10000, loss: 0.023355
   Number of active neurons: 2
 >> iter 11000, loss: 0.020965
 >> iter 12000, loss: 0.024253
 >> iter 13000, loss: 0.020813
 >> iter 14000, loss: 0.020405
 >> iter 15000, loss: 0.028761
 >> iter 16000, loss: 0.023282
 >> iter 17000, loss: 0.021249
 >> iter 18000, loss: 0.021106
 >> iter 19000, loss: 0.020826
 >> iter 20000, loss: 0.021744
   Number of active neurons: 2
 >> iter 21000, loss: 0.021735
 >> iter 22000, loss: 0.023170
 >> iter 23000, loss: 0.024972
 >> iter 24000, loss: 0.025259
 >> iter 25000, loss: 0.025132
 >> iter 26000, loss: 0.035691
 >> iter 27000, loss: 0.025463
 >> iter 28000, loss: 0.023876
 >> iter 29000, loss: 0.022231
 >> iter 30000, loss: 0.023999
   Number of active neurons: 2
 >> iter 31000, loss: 0.029593
 >> iter 32000, loss: 0.022802
 >> iter 33000, loss: 0.020215
 >> iter 34000, loss: 0.021422
 >> iter 35000, loss: 0.022255
 >> iter 36000, loss: 0.028580
 >> iter 37000, loss: 0.023412
 >> iter 38000, loss: 0.023166
 >> iter 39000, loss: 0.021709
 >> iter 40000, loss: 0.023110
   Number of active neurons: 2
 >> iter 41000, loss: 0.029213
 >> iter 42000, loss: 0.024026
 >> iter 43000, loss: 0.031828
 >> iter 44000, loss: 0.035368
 >> iter 45000, loss: 0.025585
 >> iter 46000, loss: 0.044818
 >> iter 47000, loss: 0.030872
 >> iter 48000, loss: 0.024184
 >> iter 49000, loss: 0.021811
 >> iter 50000, loss: 0.020439
   Number of active neurons: 2
 >> iter 51000, loss: 0.022516
 >> iter 52000, loss: 0.027192
 >> iter 53000, loss: 0.024813
 >> iter 54000, loss: 0.021789
 >> iter 55000, loss: 0.031423
 >> iter 56000, loss: 0.023984
 >> iter 57000, loss: 0.022088
 >> iter 58000, loss: 0.036415
 >> iter 59000, loss: 0.045060
 >> iter 60000, loss: 0.029208
   Number of active neurons: 2
 >> iter 61000, loss: 0.023306
 >> iter 62000, loss: 0.036013
 >> iter 63000, loss: 0.033535
 >> iter 64000, loss: 0.029243
 >> iter 65000, loss: 0.024493
 >> iter 66000, loss: 0.023262
 >> iter 67000, loss: 0.026837
 >> iter 68000, loss: 0.022828
 >> iter 69000, loss: 0.024532
 >> iter 70000, loss: 0.026310
   Number of active neurons: 2
 >> iter 71000, loss: 0.027590
 >> iter 72000, loss: 0.023345
 >> iter 73000, loss: 0.022172
 >> iter 74000, loss: 0.022303
 >> iter 75000, loss: 0.019749
 >> iter 76000, loss: 0.037030
 >> iter 77000, loss: 0.055378
 >> iter 78000, loss: 0.032691
 >> iter 79000, loss: 0.027755
 >> iter 80000, loss: 0.023293
   Number of active neurons: 2
 >> iter 81000, loss: 0.025762
 >> iter 82000, loss: 0.024896
 >> iter 83000, loss: 0.025274
 >> iter 84000, loss: 0.025464
 >> iter 85000, loss: 0.025210
 >> iter 86000, loss: 0.024400
 >> iter 87000, loss: 0.021043
 >> iter 88000, loss: 0.019957
 >> iter 89000, loss: 0.029672
 >> iter 90000, loss: 0.024728
   Number of active neurons: 2
 >> iter 91000, loss: 0.024408
 >> iter 92000, loss: 0.021563
 >> iter 93000, loss: 0.022714
 >> iter 94000, loss: 0.022353
 >> iter 95000, loss: 0.020203
 >> iter 96000, loss: 0.020304
 >> iter 97000, loss: 0.018360
 >> iter 98000, loss: 0.021186
 >> iter 99000, loss: 0.017354
 >> iter 100000, loss: 0.017284
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.032783
 >> iter 2000, loss: 4.140371
 >> iter 3000, loss: 1.546833
 >> iter 4000, loss: 0.614537
 >> iter 5000, loss: 0.247251
 >> iter 6000, loss: 0.107200
 >> iter 7000, loss: 0.053754
 >> iter 8000, loss: 0.033253
 >> iter 9000, loss: 0.023717
 >> iter 10000, loss: 0.034706
   Number of active neurons: 1
 >> iter 11000, loss: 0.045351
 >> iter 12000, loss: 0.027571
 >> iter 13000, loss: 0.021433
 >> iter 14000, loss: 0.035153
 >> iter 15000, loss: 0.025620
 >> iter 16000, loss: 0.027706
 >> iter 17000, loss: 0.020807
 >> iter 18000, loss: 0.018683
 >> iter 19000, loss: 0.019646
 >> iter 20000, loss: 0.020697
   Number of active neurons: 1
 >> iter 21000, loss: 0.021286
 >> iter 22000, loss: 0.021140
 >> iter 23000, loss: 0.017561
 >> iter 24000, loss: 0.019700
 >> iter 25000, loss: 0.019716
 >> iter 26000, loss: 0.016439
 >> iter 27000, loss: 0.017251
 >> iter 28000, loss: 0.024926
 >> iter 29000, loss: 0.025591
 >> iter 30000, loss: 0.031370
   Number of active neurons: 1
 >> iter 31000, loss: 0.022286
 >> iter 32000, loss: 0.032533
 >> iter 33000, loss: 0.024860
 >> iter 34000, loss: 0.022076
 >> iter 35000, loss: 0.029059
 >> iter 36000, loss: 0.019839
 >> iter 37000, loss: 0.018937
 >> iter 38000, loss: 0.036008
 >> iter 39000, loss: 0.024914
 >> iter 40000, loss: 0.027228
   Number of active neurons: 1
 >> iter 41000, loss: 0.020758
 >> iter 42000, loss: 0.021668
 >> iter 43000, loss: 0.020255
 >> iter 44000, loss: 0.019087
 >> iter 45000, loss: 0.031546
 >> iter 46000, loss: 0.032291
 >> iter 47000, loss: 0.021999
 >> iter 48000, loss: 0.019123
 >> iter 49000, loss: 0.018104
 >> iter 50000, loss: 0.017393
   Number of active neurons: 1
 >> iter 51000, loss: 0.018673
 >> iter 52000, loss: 0.021763
 >> iter 53000, loss: 0.019784
 >> iter 54000, loss: 0.018648
 >> iter 55000, loss: 0.029497
 >> iter 56000, loss: 0.023164
 >> iter 57000, loss: 0.035444
 >> iter 58000, loss: 0.023595
 >> iter 59000, loss: 0.020983
 >> iter 60000, loss: 0.024006
   Number of active neurons: 1
 >> iter 61000, loss: 0.023085
 >> iter 62000, loss: 0.019764
 >> iter 63000, loss: 0.058562
 >> iter 64000, loss: 0.037770
 >> iter 65000, loss: 0.026510
 >> iter 66000, loss: 0.024066
 >> iter 67000, loss: 0.022268
 >> iter 68000, loss: 0.023799
 >> iter 69000, loss: 0.022576
 >> iter 70000, loss: 0.021761
   Number of active neurons: 1
 >> iter 71000, loss: 0.018897
 >> iter 72000, loss: 0.026330
 >> iter 73000, loss: 0.020784
 >> iter 74000, loss: 0.028402
 >> iter 75000, loss: 0.020307
 >> iter 76000, loss: 0.018499
 >> iter 77000, loss: 0.016719
 >> iter 78000, loss: 0.016264
 >> iter 79000, loss: 0.022201
 >> iter 80000, loss: 0.019354
   Number of active neurons: 1
 >> iter 81000, loss: 0.021995
 >> iter 82000, loss: 0.018624
 >> iter 83000, loss: 0.017030
 >> iter 84000, loss: 0.022881
 >> iter 85000, loss: 0.023540
 >> iter 86000, loss: 0.051408
 >> iter 87000, loss: 0.033275
 >> iter 88000, loss: 0.042566
 >> iter 89000, loss: 0.025917
 >> iter 90000, loss: 0.022477
   Number of active neurons: 1
 >> iter 91000, loss: 0.022265
 >> iter 92000, loss: 0.034689
 >> iter 93000, loss: 0.025636
 >> iter 94000, loss: 0.019213
 >> iter 95000, loss: 0.021454
 >> iter 96000, loss: 0.020918
 >> iter 97000, loss: 0.018290
 >> iter 98000, loss: 0.016692
 >> iter 99000, loss: 0.016316
 >> iter 100000, loss: 0.018025
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.126788
 >> iter 2000, loss: 4.129457
 >> iter 3000, loss: 1.547921
 >> iter 4000, loss: 0.587831
 >> iter 5000, loss: 0.230745
 >> iter 6000, loss: 0.098962
 >> iter 7000, loss: 0.053213
 >> iter 8000, loss: 0.034572
 >> iter 9000, loss: 0.034469
 >> iter 10000, loss: 0.024339
   Number of active neurons: 2
 >> iter 11000, loss: 0.022180
 >> iter 12000, loss: 0.030353
 >> iter 13000, loss: 0.025159
 >> iter 14000, loss: 0.025007
 >> iter 15000, loss: 0.022814
 >> iter 16000, loss: 0.024928
 >> iter 17000, loss: 0.022212
 >> iter 18000, loss: 0.022923
 >> iter 19000, loss: 0.023069
 >> iter 20000, loss: 0.022309
   Number of active neurons: 2
 >> iter 21000, loss: 0.020302
 >> iter 22000, loss: 0.023558
 >> iter 23000, loss: 0.022549
 >> iter 24000, loss: 0.020576
 >> iter 25000, loss: 0.035954
 >> iter 26000, loss: 0.040560
 >> iter 27000, loss: 0.027681
 >> iter 28000, loss: 0.042303
 >> iter 29000, loss: 0.034419
 >> iter 30000, loss: 0.024203
   Number of active neurons: 2
 >> iter 31000, loss: 0.021654
 >> iter 32000, loss: 0.022372
 >> iter 33000, loss: 0.021932
 >> iter 34000, loss: 0.022619
 >> iter 35000, loss: 0.020675
 >> iter 36000, loss: 0.021652
 >> iter 37000, loss: 0.021435
 >> iter 38000, loss: 0.022186
 >> iter 39000, loss: 0.021810
 >> iter 40000, loss: 0.038644
   Number of active neurons: 2
 >> iter 41000, loss: 0.029392
 >> iter 42000, loss: 0.025895
 >> iter 43000, loss: 0.022290
 >> iter 44000, loss: 0.024243
 >> iter 45000, loss: 0.024945
 >> iter 46000, loss: 0.029153
 >> iter 47000, loss: 0.024705
 >> iter 48000, loss: 0.021238
 >> iter 49000, loss: 0.020387
 >> iter 50000, loss: 0.031284
   Number of active neurons: 2
 >> iter 51000, loss: 0.025633
 >> iter 52000, loss: 0.022050
 >> iter 53000, loss: 0.026546
 >> iter 54000, loss: 0.021334
 >> iter 55000, loss: 0.026561
 >> iter 56000, loss: 0.024945
 >> iter 57000, loss: 0.021694
 >> iter 58000, loss: 0.022076
 >> iter 59000, loss: 0.029623
 >> iter 60000, loss: 0.032965
   Number of active neurons: 2
 >> iter 61000, loss: 0.025888
 >> iter 62000, loss: 0.024689
 >> iter 63000, loss: 0.020908
 >> iter 64000, loss: 0.023674
 >> iter 65000, loss: 0.022300
 >> iter 66000, loss: 0.021719
 >> iter 67000, loss: 0.034249
 >> iter 68000, loss: 0.026998
 >> iter 69000, loss: 0.023322
 >> iter 70000, loss: 0.026308
   Number of active neurons: 2
 >> iter 71000, loss: 0.025522
 >> iter 72000, loss: 0.022378
 >> iter 73000, loss: 0.031353
 >> iter 74000, loss: 0.025101
 >> iter 75000, loss: 0.031807
 >> iter 76000, loss: 0.025735
 >> iter 77000, loss: 0.026491
 >> iter 78000, loss: 0.026581
 >> iter 79000, loss: 0.026145
 >> iter 80000, loss: 0.022962
   Number of active neurons: 2
 >> iter 81000, loss: 0.024005
 >> iter 82000, loss: 0.034812
 >> iter 83000, loss: 0.033418
 >> iter 84000, loss: 0.032315
 >> iter 85000, loss: 0.024207
 >> iter 86000, loss: 0.026724
 >> iter 87000, loss: 0.022759
 >> iter 88000, loss: 0.022417
 >> iter 89000, loss: 0.032873
 >> iter 90000, loss: 0.025324
   Number of active neurons: 2
 >> iter 91000, loss: 0.022873
 >> iter 92000, loss: 0.023801
 >> iter 93000, loss: 0.021579
 >> iter 94000, loss: 0.043191
 >> iter 95000, loss: 0.033508
 >> iter 96000, loss: 0.031280
 >> iter 97000, loss: 0.028536
 >> iter 98000, loss: 0.025379
 >> iter 99000, loss: 0.040597
 >> iter 100000, loss: 0.061066
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.047103
 >> iter 2000, loss: 4.101439
 >> iter 3000, loss: 1.531854
 >> iter 4000, loss: 0.587984
 >> iter 5000, loss: 0.236230
 >> iter 6000, loss: 0.103411
 >> iter 7000, loss: 0.068017
 >> iter 8000, loss: 0.037994
 >> iter 9000, loss: 0.027394
 >> iter 10000, loss: 0.030242
   Number of active neurons: 2
 >> iter 11000, loss: 0.029104
 >> iter 12000, loss: 0.024009
 >> iter 13000, loss: 0.025898
 >> iter 14000, loss: 0.030579
 >> iter 15000, loss: 0.032527
 >> iter 16000, loss: 0.026315
 >> iter 17000, loss: 0.023787
 >> iter 18000, loss: 0.020953
 >> iter 19000, loss: 0.021999
 >> iter 20000, loss: 0.020274
   Number of active neurons: 1
 >> iter 21000, loss: 0.026734
 >> iter 22000, loss: 0.025273
 >> iter 23000, loss: 0.022363
 >> iter 24000, loss: 0.028895
 >> iter 25000, loss: 0.021311
 >> iter 26000, loss: 0.018763
 >> iter 27000, loss: 0.016577
 >> iter 28000, loss: 0.021276
 >> iter 29000, loss: 0.017950
 >> iter 30000, loss: 0.019193
   Number of active neurons: 1
 >> iter 31000, loss: 0.029520
 >> iter 32000, loss: 0.043905
 >> iter 33000, loss: 0.028272
 >> iter 34000, loss: 0.022799
 >> iter 35000, loss: 0.019219
 >> iter 36000, loss: 0.020881
 >> iter 37000, loss: 0.021488
 >> iter 38000, loss: 0.030414
 >> iter 39000, loss: 0.023767
 >> iter 40000, loss: 0.020520
   Number of active neurons: 1
 >> iter 41000, loss: 0.016841
 >> iter 42000, loss: 0.017905
 >> iter 43000, loss: 0.022680
 >> iter 44000, loss: 0.018059
 >> iter 45000, loss: 0.018279
 >> iter 46000, loss: 0.018681
 >> iter 47000, loss: 0.017161
 >> iter 48000, loss: 0.017130
 >> iter 49000, loss: 0.019513
 >> iter 50000, loss: 0.025732
   Number of active neurons: 1
 >> iter 51000, loss: 0.019557
 >> iter 52000, loss: 0.024924
 >> iter 53000, loss: 0.018752
 >> iter 54000, loss: 0.021379
 >> iter 55000, loss: 0.033746
 >> iter 56000, loss: 0.030234
 >> iter 57000, loss: 0.028515
 >> iter 58000, loss: 0.022817
 >> iter 59000, loss: 0.025040
 >> iter 60000, loss: 0.022741
   Number of active neurons: 1
 >> iter 61000, loss: 0.025267
 >> iter 62000, loss: 0.031166
 >> iter 63000, loss: 0.023617
 >> iter 64000, loss: 0.020311
 >> iter 65000, loss: 0.047680
 >> iter 66000, loss: 0.028533
 >> iter 67000, loss: 0.021196
 >> iter 68000, loss: 0.020406
 >> iter 69000, loss: 0.025126
 >> iter 70000, loss: 0.020697
   Number of active neurons: 1
 >> iter 71000, loss: 0.025902
 >> iter 72000, loss: 0.024622
 >> iter 73000, loss: 0.033092
 >> iter 74000, loss: 0.025551
 >> iter 75000, loss: 0.020097
 >> iter 76000, loss: 0.057534
 >> iter 77000, loss: 0.032071
 >> iter 78000, loss: 0.024668
 >> iter 79000, loss: 0.022042
 >> iter 80000, loss: 0.018349
   Number of active neurons: 1
 >> iter 81000, loss: 0.022006
 >> iter 82000, loss: 0.019869
 >> iter 83000, loss: 0.018539
 >> iter 84000, loss: 0.020978
 >> iter 85000, loss: 0.019729
 >> iter 86000, loss: 0.016290
 >> iter 87000, loss: 0.025067
 >> iter 88000, loss: 0.025573
 >> iter 89000, loss: 0.024360
 >> iter 90000, loss: 0.039062
   Number of active neurons: 1
 >> iter 91000, loss: 0.027522
 >> iter 92000, loss: 0.034599
 >> iter 93000, loss: 0.034000
 >> iter 94000, loss: 0.022871
 >> iter 95000, loss: 0.022259
 >> iter 96000, loss: 0.033266
 >> iter 97000, loss: 0.031046
 >> iter 98000, loss: 0.022424
 >> iter 99000, loss: 0.018837
 >> iter 100000, loss: 0.017845
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

