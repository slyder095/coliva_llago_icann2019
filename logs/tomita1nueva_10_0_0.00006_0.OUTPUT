 > Problema: tomita1nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 6e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.799954
 >> iter 2000, loss: 3.988075
 >> iter 3000, loss: 1.479458
 >> iter 4000, loss: 0.555223
 >> iter 5000, loss: 0.214904
 >> iter 6000, loss: 0.089073
 >> iter 7000, loss: 0.042807
 >> iter 8000, loss: 0.025358
 >> iter 9000, loss: 0.019059
 >> iter 10000, loss: 0.016359
   Number of active neurons: 4
 >> iter 11000, loss: 0.015476
 >> iter 12000, loss: 0.014768
 >> iter 13000, loss: 0.014665
 >> iter 14000, loss: 0.014301
 >> iter 15000, loss: 0.014362
 >> iter 16000, loss: 0.014080
 >> iter 17000, loss: 0.014128
 >> iter 18000, loss: 0.013857
 >> iter 19000, loss: 0.013920
 >> iter 20000, loss: 0.013670
   Number of active neurons: 4
 >> iter 21000, loss: 0.013731
 >> iter 22000, loss: 0.013498
 >> iter 23000, loss: 0.013582
 >> iter 24000, loss: 0.013371
 >> iter 25000, loss: 0.013467
 >> iter 26000, loss: 0.013276
 >> iter 27000, loss: 0.013372
 >> iter 28000, loss: 0.013169
 >> iter 29000, loss: 0.013236
 >> iter 30000, loss: 0.013016
   Number of active neurons: 3
 >> iter 31000, loss: 0.013041
 >> iter 32000, loss: 0.012781
 >> iter 33000, loss: 0.012799
 >> iter 34000, loss: 0.012566
 >> iter 35000, loss: 0.012612
 >> iter 36000, loss: 0.012393
 >> iter 37000, loss: 0.012481
 >> iter 38000, loss: 0.012315
 >> iter 39000, loss: 0.012443
 >> iter 40000, loss: 0.012294
   Number of active neurons: 3
 >> iter 41000, loss: 0.012430
 >> iter 42000, loss: 0.012295
 >> iter 43000, loss: 0.012427
 >> iter 44000, loss: 0.012306
 >> iter 45000, loss: 0.012437
 >> iter 46000, loss: 0.012315
 >> iter 47000, loss: 0.012445
 >> iter 48000, loss: 0.012331
 >> iter 49000, loss: 0.012463
 >> iter 50000, loss: 0.012343
   Number of active neurons: 3
 >> iter 51000, loss: 0.012476
 >> iter 52000, loss: 0.012362
 >> iter 53000, loss: 0.012483
 >> iter 54000, loss: 0.012389
 >> iter 55000, loss: 0.012486
 >> iter 56000, loss: 0.012395
 >> iter 57000, loss: 0.012498
 >> iter 58000, loss: 0.012387
 >> iter 59000, loss: 0.012493
 >> iter 60000, loss: 0.012380
   Number of active neurons: 2
 >> iter 61000, loss: 0.012467
 >> iter 62000, loss: 0.012351
 >> iter 63000, loss: 0.012427
 >> iter 64000, loss: 0.012288
 >> iter 65000, loss: 0.012351
 >> iter 66000, loss: 0.012194
 >> iter 67000, loss: 0.012196
 >> iter 68000, loss: 0.011973
 >> iter 69000, loss: 0.011919
 >> iter 70000, loss: 0.011698
   Number of active neurons: 2
 >> iter 71000, loss: 0.011671
 >> iter 72000, loss: 0.011473
 >> iter 73000, loss: 0.011451
 >> iter 74000, loss: 0.011281
 >> iter 75000, loss: 0.011305
 >> iter 76000, loss: 0.011175
 >> iter 77000, loss: 0.011225
 >> iter 78000, loss: 0.011114
 >> iter 79000, loss: 0.011196
 >> iter 80000, loss: 0.011089
   Number of active neurons: 2
 >> iter 81000, loss: 0.011190
 >> iter 82000, loss: 0.011079
 >> iter 83000, loss: 0.011191
 >> iter 84000, loss: 0.011076
 >> iter 85000, loss: 0.011188
 >> iter 86000, loss: 0.011077
 >> iter 87000, loss: 0.011193
 >> iter 88000, loss: 0.011082
 >> iter 89000, loss: 0.011197
 >> iter 90000, loss: 0.011096
   Number of active neurons: 2
 >> iter 91000, loss: 0.011206
 >> iter 92000, loss: 0.011109
 >> iter 93000, loss: 0.011216
 >> iter 94000, loss: 0.011113
 >> iter 95000, loss: 0.011233
 >> iter 96000, loss: 0.011115
 >> iter 97000, loss: 0.011236
 >> iter 98000, loss: 0.011112
 >> iter 99000, loss: 0.011233
 >> iter 100000, loss: 0.011115
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.686013
 >> iter 2000, loss: 3.947056
 >> iter 3000, loss: 1.465205
 >> iter 4000, loss: 0.550751
 >> iter 5000, loss: 0.214126
 >> iter 6000, loss: 0.089708
 >> iter 7000, loss: 0.043868
 >> iter 8000, loss: 0.026470
 >> iter 9000, loss: 0.020004
 >> iter 10000, loss: 0.017074
   Number of active neurons: 3
 >> iter 11000, loss: 0.015934
 >> iter 12000, loss: 0.015015
 >> iter 13000, loss: 0.014691
 >> iter 14000, loss: 0.014121
 >> iter 15000, loss: 0.013939
 >> iter 16000, loss: 0.013471
 >> iter 17000, loss: 0.013389
 >> iter 18000, loss: 0.013038
 >> iter 19000, loss: 0.013021
 >> iter 20000, loss: 0.012722
   Number of active neurons: 3
 >> iter 21000, loss: 0.012719
 >> iter 22000, loss: 0.012447
 >> iter 23000, loss: 0.012484
 >> iter 24000, loss: 0.012257
 >> iter 25000, loss: 0.012341
 >> iter 26000, loss: 0.012153
 >> iter 27000, loss: 0.012246
 >> iter 28000, loss: 0.012073
 >> iter 29000, loss: 0.012159
 >> iter 30000, loss: 0.011978
   Number of active neurons: 2
 >> iter 31000, loss: 0.012029
 >> iter 32000, loss: 0.011815
 >> iter 33000, loss: 0.011843
 >> iter 34000, loss: 0.011593
 >> iter 35000, loss: 0.011614
 >> iter 36000, loss: 0.011355
 >> iter 37000, loss: 0.011357
 >> iter 38000, loss: 0.011078
 >> iter 39000, loss: 0.011094
 >> iter 40000, loss: 0.010826
   Number of active neurons: 2
 >> iter 41000, loss: 0.010851
 >> iter 42000, loss: 0.010620
 >> iter 43000, loss: 0.010675
 >> iter 44000, loss: 0.010488
 >> iter 45000, loss: 0.010573
 >> iter 46000, loss: 0.010403
 >> iter 47000, loss: 0.010502
 >> iter 48000, loss: 0.010349
 >> iter 49000, loss: 0.010458
 >> iter 50000, loss: 0.010305
   Number of active neurons: 2
 >> iter 51000, loss: 0.010420
 >> iter 52000, loss: 0.010275
 >> iter 53000, loss: 0.010385
 >> iter 54000, loss: 0.010263
 >> iter 55000, loss: 0.010356
 >> iter 56000, loss: 0.010243
 >> iter 57000, loss: 0.010345
 >> iter 58000, loss: 0.010217
 >> iter 59000, loss: 0.010328
 >> iter 60000, loss: 0.010206
   Number of active neurons: 2
 >> iter 61000, loss: 0.010310
 >> iter 62000, loss: 0.010195
 >> iter 63000, loss: 0.010299
 >> iter 64000, loss: 0.010178
 >> iter 65000, loss: 0.010291
 >> iter 66000, loss: 0.010174
 >> iter 67000, loss: 0.010280
 >> iter 68000, loss: 0.010178
 >> iter 69000, loss: 0.010276
 >> iter 70000, loss: 0.010168
   Number of active neurons: 2
 >> iter 71000, loss: 0.010273
 >> iter 72000, loss: 0.010173
 >> iter 73000, loss: 0.010274
 >> iter 74000, loss: 0.010172
 >> iter 75000, loss: 0.010277
 >> iter 76000, loss: 0.010176
 >> iter 77000, loss: 0.010279
 >> iter 78000, loss: 0.010176
 >> iter 79000, loss: 0.010298
 >> iter 80000, loss: 0.010186
   Number of active neurons: 2
 >> iter 81000, loss: 0.010321
 >> iter 82000, loss: 0.010197
 >> iter 83000, loss: 0.010342
 >> iter 84000, loss: 0.010208
 >> iter 85000, loss: 0.010351
 >> iter 86000, loss: 0.010221
 >> iter 87000, loss: 0.010366
 >> iter 88000, loss: 0.010237
 >> iter 89000, loss: 0.010380
 >> iter 90000, loss: 0.010263
   Number of active neurons: 2
 >> iter 91000, loss: 0.010388
 >> iter 92000, loss: 0.010263
 >> iter 93000, loss: 0.010390
 >> iter 94000, loss: 0.010265
 >> iter 95000, loss: 0.010414
 >> iter 96000, loss: 0.010278
 >> iter 97000, loss: 0.010432
 >> iter 98000, loss: 0.010293
 >> iter 99000, loss: 0.010451
 >> iter 100000, loss: 0.010315
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.750641
 >> iter 2000, loss: 3.969429
 >> iter 3000, loss: 1.471978
 >> iter 4000, loss: 0.551912
 >> iter 5000, loss: 0.213341
 >> iter 6000, loss: 0.088234
 >> iter 7000, loss: 0.042367
 >> iter 8000, loss: 0.025136
 >> iter 9000, loss: 0.019034
 >> iter 10000, loss: 0.016468
   Number of active neurons: 5
 >> iter 11000, loss: 0.015774
 >> iter 12000, loss: 0.015176
 >> iter 13000, loss: 0.015181
 >> iter 14000, loss: 0.014830
 >> iter 15000, loss: 0.014933
 >> iter 16000, loss: 0.014625
 >> iter 17000, loss: 0.014728
 >> iter 18000, loss: 0.014416
 >> iter 19000, loss: 0.014484
 >> iter 20000, loss: 0.014192
   Number of active neurons: 3
 >> iter 21000, loss: 0.014237
 >> iter 22000, loss: 0.013905
 >> iter 23000, loss: 0.013932
 >> iter 24000, loss: 0.013606
 >> iter 25000, loss: 0.013624
 >> iter 26000, loss: 0.013279
 >> iter 27000, loss: 0.013258
 >> iter 28000, loss: 0.012917
 >> iter 29000, loss: 0.012895
 >> iter 30000, loss: 0.012567
   Number of active neurons: 3
 >> iter 31000, loss: 0.012570
 >> iter 32000, loss: 0.012286
 >> iter 33000, loss: 0.012329
 >> iter 34000, loss: 0.012100
 >> iter 35000, loss: 0.012203
 >> iter 36000, loss: 0.012005
 >> iter 37000, loss: 0.012135
 >> iter 38000, loss: 0.011952
 >> iter 39000, loss: 0.012101
 >> iter 40000, loss: 0.011924
   Number of active neurons: 3
 >> iter 41000, loss: 0.012077
 >> iter 42000, loss: 0.011914
 >> iter 43000, loss: 0.012058
 >> iter 44000, loss: 0.011906
 >> iter 45000, loss: 0.012056
 >> iter 46000, loss: 0.011899
 >> iter 47000, loss: 0.012046
 >> iter 48000, loss: 0.011900
 >> iter 49000, loss: 0.012050
 >> iter 50000, loss: 0.011898
   Number of active neurons: 3
 >> iter 51000, loss: 0.012046
 >> iter 52000, loss: 0.011901
 >> iter 53000, loss: 0.012038
 >> iter 54000, loss: 0.011915
 >> iter 55000, loss: 0.012026
 >> iter 56000, loss: 0.011911
 >> iter 57000, loss: 0.012025
 >> iter 58000, loss: 0.011871
 >> iter 59000, loss: 0.011968
 >> iter 60000, loss: 0.011814
   Number of active neurons: 2
 >> iter 61000, loss: 0.011902
 >> iter 62000, loss: 0.011754
 >> iter 63000, loss: 0.011837
 >> iter 64000, loss: 0.011673
 >> iter 65000, loss: 0.011750
 >> iter 66000, loss: 0.011575
 >> iter 67000, loss: 0.011611
 >> iter 68000, loss: 0.011398
 >> iter 69000, loss: 0.011365
 >> iter 70000, loss: 0.011121
   Number of active neurons: 2
 >> iter 71000, loss: 0.011109
 >> iter 72000, loss: 0.010892
 >> iter 73000, loss: 0.010881
 >> iter 74000, loss: 0.010675
 >> iter 75000, loss: 0.010699
 >> iter 76000, loss: 0.010533
 >> iter 77000, loss: 0.010589
 >> iter 78000, loss: 0.010445
 >> iter 79000, loss: 0.010538
 >> iter 80000, loss: 0.010396
   Number of active neurons: 2
 >> iter 81000, loss: 0.010510
 >> iter 82000, loss: 0.010361
 >> iter 83000, loss: 0.010491
 >> iter 84000, loss: 0.010336
 >> iter 85000, loss: 0.010467
 >> iter 86000, loss: 0.010315
 >> iter 87000, loss: 0.010452
 >> iter 88000, loss: 0.010302
 >> iter 89000, loss: 0.010438
 >> iter 90000, loss: 0.010301
   Number of active neurons: 2
 >> iter 91000, loss: 0.010432
 >> iter 92000, loss: 0.010302
 >> iter 93000, loss: 0.010436
 >> iter 94000, loss: 0.010300
 >> iter 95000, loss: 0.010452
 >> iter 96000, loss: 0.010305
 >> iter 97000, loss: 0.010460
 >> iter 98000, loss: 0.010312
 >> iter 99000, loss: 0.010472
 >> iter 100000, loss: 0.010329
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.722613
 >> iter 2000, loss: 3.962334
 >> iter 3000, loss: 1.471819
 >> iter 4000, loss: 0.554049
 >> iter 5000, loss: 0.216021
 >> iter 6000, loss: 0.091069
 >> iter 7000, loss: 0.044979
 >> iter 8000, loss: 0.027539
 >> iter 9000, loss: 0.021073
 >> iter 10000, loss: 0.018258
   Number of active neurons: 3
 >> iter 11000, loss: 0.017186
 >> iter 12000, loss: 0.016332
 >> iter 13000, loss: 0.015975
 >> iter 14000, loss: 0.015356
 >> iter 15000, loss: 0.015045
 >> iter 16000, loss: 0.014458
 >> iter 17000, loss: 0.014194
 >> iter 18000, loss: 0.013706
 >> iter 19000, loss: 0.013532
 >> iter 20000, loss: 0.013186
   Number of active neurons: 2
 >> iter 21000, loss: 0.013125
 >> iter 22000, loss: 0.012871
 >> iter 23000, loss: 0.012877
 >> iter 24000, loss: 0.012655
 >> iter 25000, loss: 0.012680
 >> iter 26000, loss: 0.012464
 >> iter 27000, loss: 0.012446
 >> iter 28000, loss: 0.012175
 >> iter 29000, loss: 0.012118
 >> iter 30000, loss: 0.011858
   Number of active neurons: 2
 >> iter 31000, loss: 0.011825
 >> iter 32000, loss: 0.011590
 >> iter 33000, loss: 0.011590
 >> iter 34000, loss: 0.011407
 >> iter 35000, loss: 0.011457
 >> iter 36000, loss: 0.011301
 >> iter 37000, loss: 0.011377
 >> iter 38000, loss: 0.011239
 >> iter 39000, loss: 0.011335
 >> iter 40000, loss: 0.011205
   Number of active neurons: 2
 >> iter 41000, loss: 0.011307
 >> iter 42000, loss: 0.011190
 >> iter 43000, loss: 0.011289
 >> iter 44000, loss: 0.011185
 >> iter 45000, loss: 0.011283
 >> iter 46000, loss: 0.011180
 >> iter 47000, loss: 0.011278
 >> iter 48000, loss: 0.011182
 >> iter 49000, loss: 0.011282
 >> iter 50000, loss: 0.011181
   Number of active neurons: 2
 >> iter 51000, loss: 0.011282
 >> iter 52000, loss: 0.011187
 >> iter 53000, loss: 0.011277
 >> iter 54000, loss: 0.011197
 >> iter 55000, loss: 0.011268
 >> iter 56000, loss: 0.011188
 >> iter 57000, loss: 0.011261
 >> iter 58000, loss: 0.011164
 >> iter 59000, loss: 0.011238
 >> iter 60000, loss: 0.011136
   Number of active neurons: 1
 >> iter 61000, loss: 0.011188
 >> iter 62000, loss: 0.011078
 >> iter 63000, loss: 0.011115
 >> iter 64000, loss: 0.010974
 >> iter 65000, loss: 0.010962
 >> iter 66000, loss: 0.010735
 >> iter 67000, loss: 0.010634
 >> iter 68000, loss: 0.010394
 >> iter 69000, loss: 0.010298
 >> iter 70000, loss: 0.010067
   Number of active neurons: 1
 >> iter 71000, loss: 0.009978
 >> iter 72000, loss: 0.009764
 >> iter 73000, loss: 0.009701
 >> iter 74000, loss: 0.009527
 >> iter 75000, loss: 0.009504
 >> iter 76000, loss: 0.009361
 >> iter 77000, loss: 0.009359
 >> iter 78000, loss: 0.009232
 >> iter 79000, loss: 0.009259
 >> iter 80000, loss: 0.009138
   Number of active neurons: 1
 >> iter 81000, loss: 0.009183
 >> iter 82000, loss: 0.009063
 >> iter 83000, loss: 0.009119
 >> iter 84000, loss: 0.008998
 >> iter 85000, loss: 0.009058
 >> iter 86000, loss: 0.008941
 >> iter 87000, loss: 0.009007
 >> iter 88000, loss: 0.008893
 >> iter 89000, loss: 0.008960
 >> iter 90000, loss: 0.008855
   Number of active neurons: 1
 >> iter 91000, loss: 0.008920
 >> iter 92000, loss: 0.008820
 >> iter 93000, loss: 0.008887
 >> iter 94000, loss: 0.008783
 >> iter 95000, loss: 0.008864
 >> iter 96000, loss: 0.008749
 >> iter 97000, loss: 0.008835
 >> iter 98000, loss: 0.008719
 >> iter 99000, loss: 0.008810
 >> iter 100000, loss: 0.008703
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 10.681100
 >> iter 2000, loss: 3.944404
 >> iter 3000, loss: 1.463326
 >> iter 4000, loss: 0.548953
 >> iter 5000, loss: 0.212240
 >> iter 6000, loss: 0.087752
 >> iter 7000, loss: 0.041945
 >> iter 8000, loss: 0.024644
 >> iter 9000, loss: 0.018362
 >> iter 10000, loss: 0.015671
   Number of active neurons: 4
 >> iter 11000, loss: 0.014798
 >> iter 12000, loss: 0.014102
 >> iter 13000, loss: 0.013964
 >> iter 14000, loss: 0.013562
 >> iter 15000, loss: 0.013592
 >> iter 16000, loss: 0.013340
 >> iter 17000, loss: 0.013484
 >> iter 18000, loss: 0.013319
 >> iter 19000, loss: 0.013478
 >> iter 20000, loss: 0.013321
   Number of active neurons: 4
 >> iter 21000, loss: 0.013470
 >> iter 22000, loss: 0.013317
 >> iter 23000, loss: 0.013478
 >> iter 24000, loss: 0.013324
 >> iter 25000, loss: 0.013489
 >> iter 26000, loss: 0.013342
 >> iter 27000, loss: 0.013480
 >> iter 28000, loss: 0.013319
 >> iter 29000, loss: 0.013445
 >> iter 30000, loss: 0.013286
   Number of active neurons: 3
 >> iter 31000, loss: 0.013406
 >> iter 32000, loss: 0.013238
 >> iter 33000, loss: 0.013332
 >> iter 34000, loss: 0.013133
 >> iter 35000, loss: 0.013204
 >> iter 36000, loss: 0.012955
 >> iter 37000, loss: 0.012977
 >> iter 38000, loss: 0.012716
 >> iter 39000, loss: 0.012758
 >> iter 40000, loss: 0.012516
   Number of active neurons: 3
 >> iter 41000, loss: 0.012580
 >> iter 42000, loss: 0.012379
 >> iter 43000, loss: 0.012470
 >> iter 44000, loss: 0.012324
 >> iter 45000, loss: 0.012437
 >> iter 46000, loss: 0.012303
 >> iter 47000, loss: 0.012419
 >> iter 48000, loss: 0.012295
 >> iter 49000, loss: 0.012413
 >> iter 50000, loss: 0.012281
   Number of active neurons: 3
 >> iter 51000, loss: 0.012398
 >> iter 52000, loss: 0.012270
 >> iter 53000, loss: 0.012369
 >> iter 54000, loss: 0.012256
 >> iter 55000, loss: 0.012325
 >> iter 56000, loss: 0.012207
 >> iter 57000, loss: 0.012271
 >> iter 58000, loss: 0.012122
 >> iter 59000, loss: 0.012175
 >> iter 60000, loss: 0.012001
   Number of active neurons: 2
 >> iter 61000, loss: 0.011980
 >> iter 62000, loss: 0.011739
 >> iter 63000, loss: 0.011696
 >> iter 64000, loss: 0.011466
 >> iter 65000, loss: 0.011450
 >> iter 66000, loss: 0.011238
 >> iter 67000, loss: 0.011230
 >> iter 68000, loss: 0.011075
 >> iter 69000, loss: 0.011100
 >> iter 70000, loss: 0.010972
   Number of active neurons: 2
 >> iter 71000, loss: 0.011028
 >> iter 72000, loss: 0.010925
 >> iter 73000, loss: 0.010990
 >> iter 74000, loss: 0.010892
 >> iter 75000, loss: 0.010969
 >> iter 76000, loss: 0.010877
 >> iter 77000, loss: 0.010956
 >> iter 78000, loss: 0.010864
 >> iter 79000, loss: 0.010963
 >> iter 80000, loss: 0.010866
   Number of active neurons: 2
 >> iter 81000, loss: 0.010977
 >> iter 82000, loss: 0.010871
 >> iter 83000, loss: 0.010991
 >> iter 84000, loss: 0.010877
 >> iter 85000, loss: 0.010995
 >> iter 86000, loss: 0.010884
 >> iter 87000, loss: 0.011007
 >> iter 88000, loss: 0.010896
 >> iter 89000, loss: 0.011016
 >> iter 90000, loss: 0.010916
   Number of active neurons: 2
 >> iter 91000, loss: 0.011032
 >> iter 92000, loss: 0.010936
 >> iter 93000, loss: 0.011052
 >> iter 94000, loss: 0.010950
 >> iter 95000, loss: 0.011081
 >> iter 96000, loss: 0.010966
 >> iter 97000, loss: 0.011101
 >> iter 98000, loss: 0.010983
 >> iter 99000, loss: 0.011122
 >> iter 100000, loss: 0.011014
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.718233
 >> iter 2000, loss: 3.958313
 >> iter 3000, loss: 1.468507
 >> iter 4000, loss: 0.551014
 >> iter 5000, loss: 0.213158
 >> iter 6000, loss: 0.088279
 >> iter 7000, loss: 0.042361
 >> iter 8000, loss: 0.025100
 >> iter 9000, loss: 0.018880
 >> iter 10000, loss: 0.016278
   Number of active neurons: 4
 >> iter 11000, loss: 0.015451
 >> iter 12000, loss: 0.014796
 >> iter 13000, loss: 0.014677
 >> iter 14000, loss: 0.014256
 >> iter 15000, loss: 0.014193
 >> iter 16000, loss: 0.013802
 >> iter 17000, loss: 0.013770
 >> iter 18000, loss: 0.013457
 >> iter 19000, loss: 0.013467
 >> iter 20000, loss: 0.013232
   Number of active neurons: 3
 >> iter 21000, loss: 0.013265
 >> iter 22000, loss: 0.013012
 >> iter 23000, loss: 0.013015
 >> iter 24000, loss: 0.012736
 >> iter 25000, loss: 0.012759
 >> iter 26000, loss: 0.012519
 >> iter 27000, loss: 0.012564
 >> iter 28000, loss: 0.012374
 >> iter 29000, loss: 0.012444
 >> iter 30000, loss: 0.012285
   Number of active neurons: 3
 >> iter 31000, loss: 0.012398
 >> iter 32000, loss: 0.012266
 >> iter 33000, loss: 0.012392
 >> iter 34000, loss: 0.012267
 >> iter 35000, loss: 0.012406
 >> iter 36000, loss: 0.012275
 >> iter 37000, loss: 0.012415
 >> iter 38000, loss: 0.012283
 >> iter 39000, loss: 0.012431
 >> iter 40000, loss: 0.012297
   Number of active neurons: 3
 >> iter 41000, loss: 0.012445
 >> iter 42000, loss: 0.012319
 >> iter 43000, loss: 0.012457
 >> iter 44000, loss: 0.012343
 >> iter 45000, loss: 0.012480
 >> iter 46000, loss: 0.012365
 >> iter 47000, loss: 0.012500
 >> iter 48000, loss: 0.012393
 >> iter 49000, loss: 0.012530
 >> iter 50000, loss: 0.012417
   Number of active neurons: 3
 >> iter 51000, loss: 0.012556
 >> iter 52000, loss: 0.012451
 >> iter 53000, loss: 0.012579
 >> iter 54000, loss: 0.012493
 >> iter 55000, loss: 0.012600
 >> iter 56000, loss: 0.012519
 >> iter 57000, loss: 0.012633
 >> iter 58000, loss: 0.012533
 >> iter 59000, loss: 0.012654
 >> iter 60000, loss: 0.012555
   Number of active neurons: 3
 >> iter 61000, loss: 0.012660
 >> iter 62000, loss: 0.012564
 >> iter 63000, loss: 0.012663
 >> iter 64000, loss: 0.012548
 >> iter 65000, loss: 0.012642
 >> iter 66000, loss: 0.012520
 >> iter 67000, loss: 0.012588
 >> iter 68000, loss: 0.012464
 >> iter 69000, loss: 0.012488
 >> iter 70000, loss: 0.012282
   Number of active neurons: 2
 >> iter 71000, loss: 0.012232
 >> iter 72000, loss: 0.012012
 >> iter 73000, loss: 0.011973
 >> iter 74000, loss: 0.011770
 >> iter 75000, loss: 0.011740
 >> iter 76000, loss: 0.011558
 >> iter 77000, loss: 0.011562
 >> iter 78000, loss: 0.011420
 >> iter 79000, loss: 0.011474
 >> iter 80000, loss: 0.011349
   Number of active neurons: 2
 >> iter 81000, loss: 0.011430
 >> iter 82000, loss: 0.011308
 >> iter 83000, loss: 0.011402
 >> iter 84000, loss: 0.011278
 >> iter 85000, loss: 0.011371
 >> iter 86000, loss: 0.011251
 >> iter 87000, loss: 0.011345
 >> iter 88000, loss: 0.011221
 >> iter 89000, loss: 0.011306
 >> iter 90000, loss: 0.011186
   Number of active neurons: 1
 >> iter 91000, loss: 0.011256
 >> iter 92000, loss: 0.011128
 >> iter 93000, loss: 0.011179
 >> iter 94000, loss: 0.011026
 >> iter 95000, loss: 0.011049
 >> iter 96000, loss: 0.010801
 >> iter 97000, loss: 0.010731
 >> iter 98000, loss: 0.010443
 >> iter 99000, loss: 0.010386
 >> iter 100000, loss: 0.010124
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.697962
 >> iter 2000, loss: 3.952115
 >> iter 3000, loss: 1.466984
 >> iter 4000, loss: 0.550996
 >> iter 5000, loss: 0.213445
 >> iter 6000, loss: 0.088487
 >> iter 7000, loss: 0.042285
 >> iter 8000, loss: 0.024784
 >> iter 9000, loss: 0.018343
 >> iter 10000, loss: 0.015614
   Number of active neurons: 4
 >> iter 11000, loss: 0.014680
 >> iter 12000, loss: 0.014021
 >> iter 13000, loss: 0.013901
 >> iter 14000, loss: 0.013578
 >> iter 15000, loss: 0.013608
 >> iter 16000, loss: 0.013342
 >> iter 17000, loss: 0.013348
 >> iter 18000, loss: 0.013028
 >> iter 19000, loss: 0.012959
 >> iter 20000, loss: 0.012607
   Number of active neurons: 2
 >> iter 21000, loss: 0.012502
 >> iter 22000, loss: 0.012116
 >> iter 23000, loss: 0.011998
 >> iter 24000, loss: 0.011602
 >> iter 25000, loss: 0.011502
 >> iter 26000, loss: 0.011160
 >> iter 27000, loss: 0.011115
 >> iter 28000, loss: 0.010853
 >> iter 29000, loss: 0.010870
 >> iter 30000, loss: 0.010664
   Number of active neurons: 2
 >> iter 31000, loss: 0.010724
 >> iter 32000, loss: 0.010546
 >> iter 33000, loss: 0.010627
 >> iter 34000, loss: 0.010466
 >> iter 35000, loss: 0.010568
 >> iter 36000, loss: 0.010406
 >> iter 37000, loss: 0.010514
 >> iter 38000, loss: 0.010355
 >> iter 39000, loss: 0.010474
 >> iter 40000, loss: 0.010314
   Number of active neurons: 2
 >> iter 41000, loss: 0.010434
 >> iter 42000, loss: 0.010285
 >> iter 43000, loss: 0.010398
 >> iter 44000, loss: 0.010258
 >> iter 45000, loss: 0.010376
 >> iter 46000, loss: 0.010233
 >> iter 47000, loss: 0.010351
 >> iter 48000, loss: 0.010216
 >> iter 49000, loss: 0.010338
 >> iter 50000, loss: 0.010198
   Number of active neurons: 2
 >> iter 51000, loss: 0.010322
 >> iter 52000, loss: 0.010189
 >> iter 53000, loss: 0.010306
 >> iter 54000, loss: 0.010194
 >> iter 55000, loss: 0.010292
 >> iter 56000, loss: 0.010188
 >> iter 57000, loss: 0.010295
 >> iter 58000, loss: 0.010177
 >> iter 59000, loss: 0.010291
 >> iter 60000, loss: 0.010178
   Number of active neurons: 2
 >> iter 61000, loss: 0.010285
 >> iter 62000, loss: 0.010180
 >> iter 63000, loss: 0.010287
 >> iter 64000, loss: 0.010175
 >> iter 65000, loss: 0.010290
 >> iter 66000, loss: 0.010183
 >> iter 67000, loss: 0.010290
 >> iter 68000, loss: 0.010199
 >> iter 69000, loss: 0.010297
 >> iter 70000, loss: 0.010201
   Number of active neurons: 2
 >> iter 71000, loss: 0.010306
 >> iter 72000, loss: 0.010217
 >> iter 73000, loss: 0.010318
 >> iter 74000, loss: 0.010228
 >> iter 75000, loss: 0.010332
 >> iter 76000, loss: 0.010243
 >> iter 77000, loss: 0.010345
 >> iter 78000, loss: 0.010255
 >> iter 79000, loss: 0.010376
 >> iter 80000, loss: 0.010266
   Number of active neurons: 2
 >> iter 81000, loss: 0.010384
 >> iter 82000, loss: 0.010264
 >> iter 83000, loss: 0.010399
 >> iter 84000, loss: 0.010273
 >> iter 85000, loss: 0.010409
 >> iter 86000, loss: 0.010286
 >> iter 87000, loss: 0.010425
 >> iter 88000, loss: 0.010303
 >> iter 89000, loss: 0.010436
 >> iter 90000, loss: 0.010309
   Number of active neurons: 2
 >> iter 91000, loss: 0.010432
 >> iter 92000, loss: 0.010323
 >> iter 93000, loss: 0.010451
 >> iter 94000, loss: 0.010335
 >> iter 95000, loss: 0.010478
 >> iter 96000, loss: 0.010347
 >> iter 97000, loss: 0.010493
 >> iter 98000, loss: 0.010356
 >> iter 99000, loss: 0.010506
 >> iter 100000, loss: 0.010378
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.703992
 >> iter 2000, loss: 3.953275
 >> iter 3000, loss: 1.466947
 >> iter 4000, loss: 0.550843
 >> iter 5000, loss: 0.213521
 >> iter 6000, loss: 0.088864
 >> iter 7000, loss: 0.042990
 >> iter 8000, loss: 0.025745
 >> iter 9000, loss: 0.019492
 >> iter 10000, loss: 0.016881
   Number of active neurons: 5
 >> iter 11000, loss: 0.016058
 >> iter 12000, loss: 0.015439
 >> iter 13000, loss: 0.015368
 >> iter 14000, loss: 0.015011
 >> iter 15000, loss: 0.015034
 >> iter 16000, loss: 0.014752
 >> iter 17000, loss: 0.014821
 >> iter 18000, loss: 0.014583
 >> iter 19000, loss: 0.014647
 >> iter 20000, loss: 0.014381
   Number of active neurons: 3
 >> iter 21000, loss: 0.014394
 >> iter 22000, loss: 0.014111
 >> iter 23000, loss: 0.014112
 >> iter 24000, loss: 0.013827
 >> iter 25000, loss: 0.013844
 >> iter 26000, loss: 0.013594
 >> iter 27000, loss: 0.013600
 >> iter 28000, loss: 0.013332
 >> iter 29000, loss: 0.013312
 >> iter 30000, loss: 0.013052
   Number of active neurons: 3
 >> iter 31000, loss: 0.013057
 >> iter 32000, loss: 0.012826
 >> iter 33000, loss: 0.012868
 >> iter 34000, loss: 0.012690
 >> iter 35000, loss: 0.012780
 >> iter 36000, loss: 0.012624
 >> iter 37000, loss: 0.012734
 >> iter 38000, loss: 0.012588
 >> iter 39000, loss: 0.012712
 >> iter 40000, loss: 0.012568
   Number of active neurons: 3
 >> iter 41000, loss: 0.012689
 >> iter 42000, loss: 0.012550
 >> iter 43000, loss: 0.012657
 >> iter 44000, loss: 0.012524
 >> iter 45000, loss: 0.012617
 >> iter 46000, loss: 0.012471
 >> iter 47000, loss: 0.012545
 >> iter 48000, loss: 0.012388
 >> iter 49000, loss: 0.012434
 >> iter 50000, loss: 0.012211
   Number of active neurons: 2
 >> iter 51000, loss: 0.012183
 >> iter 52000, loss: 0.011934
 >> iter 53000, loss: 0.011903
 >> iter 54000, loss: 0.011695
 >> iter 55000, loss: 0.011658
 >> iter 56000, loss: 0.011476
 >> iter 57000, loss: 0.011488
 >> iter 58000, loss: 0.011337
 >> iter 59000, loss: 0.011390
 >> iter 60000, loss: 0.011270
   Number of active neurons: 2
 >> iter 61000, loss: 0.011333
 >> iter 62000, loss: 0.011233
 >> iter 63000, loss: 0.011308
 >> iter 64000, loss: 0.011206
 >> iter 65000, loss: 0.011293
 >> iter 66000, loss: 0.011199
 >> iter 67000, loss: 0.011282
 >> iter 68000, loss: 0.011205
 >> iter 69000, loss: 0.011279
 >> iter 70000, loss: 0.011196
   Number of active neurons: 2
 >> iter 71000, loss: 0.011275
 >> iter 72000, loss: 0.011197
 >> iter 73000, loss: 0.011269
 >> iter 74000, loss: 0.011186
 >> iter 75000, loss: 0.011257
 >> iter 76000, loss: 0.011169
 >> iter 77000, loss: 0.011231
 >> iter 78000, loss: 0.011133
 >> iter 79000, loss: 0.011200
 >> iter 80000, loss: 0.011083
   Number of active neurons: 1
 >> iter 81000, loss: 0.011142
 >> iter 82000, loss: 0.010997
 >> iter 83000, loss: 0.011021
 >> iter 84000, loss: 0.010793
 >> iter 85000, loss: 0.010717
 >> iter 86000, loss: 0.010443
 >> iter 87000, loss: 0.010375
 >> iter 88000, loss: 0.010118
 >> iter 89000, loss: 0.010051
 >> iter 90000, loss: 0.009809
   Number of active neurons: 1
 >> iter 91000, loss: 0.009760
 >> iter 92000, loss: 0.009563
 >> iter 93000, loss: 0.009553
 >> iter 94000, loss: 0.009383
 >> iter 95000, loss: 0.009411
 >> iter 96000, loss: 0.009251
 >> iter 97000, loss: 0.009298
 >> iter 98000, loss: 0.009149
 >> iter 99000, loss: 0.009211
 >> iter 100000, loss: 0.009079
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.728546
 >> iter 2000, loss: 3.961864
 >> iter 3000, loss: 1.470189
 >> iter 4000, loss: 0.551971
 >> iter 5000, loss: 0.213784
 >> iter 6000, loss: 0.088633
 >> iter 7000, loss: 0.042644
 >> iter 8000, loss: 0.025293
 >> iter 9000, loss: 0.019028
 >> iter 10000, loss: 0.016311
   Number of active neurons: 5
 >> iter 11000, loss: 0.015453
 >> iter 12000, loss: 0.014783
 >> iter 13000, loss: 0.014745
 >> iter 14000, loss: 0.014438
 >> iter 15000, loss: 0.014586
 >> iter 16000, loss: 0.014372
 >> iter 17000, loss: 0.014548
 >> iter 18000, loss: 0.014343
 >> iter 19000, loss: 0.014491
 >> iter 20000, loss: 0.014296
   Number of active neurons: 4
 >> iter 21000, loss: 0.014435
 >> iter 22000, loss: 0.014226
 >> iter 23000, loss: 0.014351
 >> iter 24000, loss: 0.014100
 >> iter 25000, loss: 0.014197
 >> iter 26000, loss: 0.013948
 >> iter 27000, loss: 0.014003
 >> iter 28000, loss: 0.013721
 >> iter 29000, loss: 0.013755
 >> iter 30000, loss: 0.013503
   Number of active neurons: 3
 >> iter 31000, loss: 0.013577
 >> iter 32000, loss: 0.013367
 >> iter 33000, loss: 0.013463
 >> iter 34000, loss: 0.013269
 >> iter 35000, loss: 0.013363
 >> iter 36000, loss: 0.013136
 >> iter 37000, loss: 0.013208
 >> iter 38000, loss: 0.012947
 >> iter 39000, loss: 0.012982
 >> iter 40000, loss: 0.012688
   Number of active neurons: 3
 >> iter 41000, loss: 0.012709
 >> iter 42000, loss: 0.012441
 >> iter 43000, loss: 0.012462
 >> iter 44000, loss: 0.012235
 >> iter 45000, loss: 0.012292
 >> iter 46000, loss: 0.012095
 >> iter 47000, loss: 0.012168
 >> iter 48000, loss: 0.011990
 >> iter 49000, loss: 0.012062
 >> iter 50000, loss: 0.011874
   Number of active neurons: 2
 >> iter 51000, loss: 0.011932
 >> iter 52000, loss: 0.011733
 >> iter 53000, loss: 0.011719
 >> iter 54000, loss: 0.011474
 >> iter 55000, loss: 0.011427
 >> iter 56000, loss: 0.011208
 >> iter 57000, loss: 0.011169
 >> iter 58000, loss: 0.010946
 >> iter 59000, loss: 0.010957
 >> iter 60000, loss: 0.010790
   Number of active neurons: 2
 >> iter 61000, loss: 0.010834
 >> iter 62000, loss: 0.010703
 >> iter 63000, loss: 0.010769
 >> iter 64000, loss: 0.010646
 >> iter 65000, loss: 0.010730
 >> iter 66000, loss: 0.010615
 >> iter 67000, loss: 0.010683
 >> iter 68000, loss: 0.010586
 >> iter 69000, loss: 0.010662
 >> iter 70000, loss: 0.010565
   Number of active neurons: 2
 >> iter 71000, loss: 0.010651
 >> iter 72000, loss: 0.010563
 >> iter 73000, loss: 0.010645
 >> iter 74000, loss: 0.010553
 >> iter 75000, loss: 0.010640
 >> iter 76000, loss: 0.010548
 >> iter 77000, loss: 0.010632
 >> iter 78000, loss: 0.010537
 >> iter 79000, loss: 0.010641
 >> iter 80000, loss: 0.010538
   Number of active neurons: 2
 >> iter 81000, loss: 0.010652
 >> iter 82000, loss: 0.010538
 >> iter 83000, loss: 0.010661
 >> iter 84000, loss: 0.010539
 >> iter 85000, loss: 0.010660
 >> iter 86000, loss: 0.010538
 >> iter 87000, loss: 0.010663
 >> iter 88000, loss: 0.010541
 >> iter 89000, loss: 0.010664
 >> iter 90000, loss: 0.010552
   Number of active neurons: 2
 >> iter 91000, loss: 0.010671
 >> iter 92000, loss: 0.010563
 >> iter 93000, loss: 0.010682
 >> iter 94000, loss: 0.010568
 >> iter 95000, loss: 0.010703
 >> iter 96000, loss: 0.010576
 >> iter 97000, loss: 0.010715
 >> iter 98000, loss: 0.010584
 >> iter 99000, loss: 0.010729
 >> iter 100000, loss: 0.010608
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.723759
 >> iter 2000, loss: 3.961504
 >> iter 3000, loss: 1.470054
 >> iter 4000, loss: 0.551746
 >> iter 5000, loss: 0.213370
 >> iter 6000, loss: 0.088212
 >> iter 7000, loss: 0.042058
 >> iter 8000, loss: 0.024681
 >> iter 9000, loss: 0.018312
 >> iter 10000, loss: 0.015644
   Number of active neurons: 3
 >> iter 11000, loss: 0.014713
 >> iter 12000, loss: 0.014040
 >> iter 13000, loss: 0.013867
 >> iter 14000, loss: 0.013475
 >> iter 15000, loss: 0.013431
 >> iter 16000, loss: 0.013110
 >> iter 17000, loss: 0.013063
 >> iter 18000, loss: 0.012731
 >> iter 19000, loss: 0.012658
 >> iter 20000, loss: 0.012311
   Number of active neurons: 2
 >> iter 21000, loss: 0.012192
 >> iter 22000, loss: 0.011819
 >> iter 23000, loss: 0.011715
 >> iter 24000, loss: 0.011383
 >> iter 25000, loss: 0.011336
 >> iter 26000, loss: 0.011064
 >> iter 27000, loss: 0.011064
 >> iter 28000, loss: 0.010855
 >> iter 29000, loss: 0.010897
 >> iter 30000, loss: 0.010727
   Number of active neurons: 2
 >> iter 31000, loss: 0.010797
 >> iter 32000, loss: 0.010648
 >> iter 33000, loss: 0.010734
 >> iter 34000, loss: 0.010599
 >> iter 35000, loss: 0.010701
 >> iter 36000, loss: 0.010566
 >> iter 37000, loss: 0.010673
 >> iter 38000, loss: 0.010541
 >> iter 39000, loss: 0.010658
 >> iter 40000, loss: 0.010528
   Number of active neurons: 2
 >> iter 41000, loss: 0.010634
 >> iter 42000, loss: 0.010499
 >> iter 43000, loss: 0.010600
 >> iter 44000, loss: 0.010484
 >> iter 45000, loss: 0.010592
 >> iter 46000, loss: 0.010478
 >> iter 47000, loss: 0.010588
 >> iter 48000, loss: 0.010483
 >> iter 49000, loss: 0.010593
 >> iter 50000, loss: 0.010469
   Number of active neurons: 2
 >> iter 51000, loss: 0.010577
 >> iter 52000, loss: 0.010474
 >> iter 53000, loss: 0.010580
 >> iter 54000, loss: 0.010495
 >> iter 55000, loss: 0.010584
 >> iter 56000, loss: 0.010503
 >> iter 57000, loss: 0.010598
 >> iter 58000, loss: 0.010503
 >> iter 59000, loss: 0.010606
 >> iter 60000, loss: 0.010513
   Number of active neurons: 2
 >> iter 61000, loss: 0.010608
 >> iter 62000, loss: 0.010521
 >> iter 63000, loss: 0.010616
 >> iter 64000, loss: 0.010521
 >> iter 65000, loss: 0.010623
 >> iter 66000, loss: 0.010531
 >> iter 67000, loss: 0.010626
 >> iter 68000, loss: 0.010549
 >> iter 69000, loss: 0.010636
 >> iter 70000, loss: 0.010552
   Number of active neurons: 2
 >> iter 71000, loss: 0.010645
 >> iter 72000, loss: 0.010567
 >> iter 73000, loss: 0.010657
 >> iter 74000, loss: 0.010575
 >> iter 75000, loss: 0.010669
 >> iter 76000, loss: 0.010588
 >> iter 77000, loss: 0.010679
 >> iter 78000, loss: 0.010595
 >> iter 79000, loss: 0.010704
 >> iter 80000, loss: 0.010612
   Number of active neurons: 2
 >> iter 81000, loss: 0.010732
 >> iter 82000, loss: 0.010629
 >> iter 83000, loss: 0.010756
 >> iter 84000, loss: 0.010645
 >> iter 85000, loss: 0.010770
 >> iter 86000, loss: 0.010660
 >> iter 87000, loss: 0.010789
 >> iter 88000, loss: 0.010678
 >> iter 89000, loss: 0.010805
 >> iter 90000, loss: 0.010704
   Number of active neurons: 2
 >> iter 91000, loss: 0.010826
 >> iter 92000, loss: 0.010730
 >> iter 93000, loss: 0.010851
 >> iter 94000, loss: 0.010749
 >> iter 95000, loss: 0.010885
 >> iter 96000, loss: 0.010770
 >> iter 97000, loss: 0.010911
 >> iter 98000, loss: 0.010792
 >> iter 99000, loss: 0.010938
 >> iter 100000, loss: 0.010829
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.712207
 >> iter 2000, loss: 3.955778
 >> iter 3000, loss: 1.467622
 >> iter 4000, loss: 0.550955
 >> iter 5000, loss: 0.213548
 >> iter 6000, loss: 0.088920
 >> iter 7000, loss: 0.043143
 >> iter 8000, loss: 0.025980
 >> iter 9000, loss: 0.019835
 >> iter 10000, loss: 0.017231
   Number of active neurons: 6
 >> iter 11000, loss: 0.016434
 >> iter 12000, loss: 0.015860
 >> iter 13000, loss: 0.015871
 >> iter 14000, loss: 0.015604
 >> iter 15000, loss: 0.015747
 >> iter 16000, loss: 0.015525
 >> iter 17000, loss: 0.015662
 >> iter 18000, loss: 0.015444
 >> iter 19000, loss: 0.015537
 >> iter 20000, loss: 0.015285
   Number of active neurons: 4
 >> iter 21000, loss: 0.015302
 >> iter 22000, loss: 0.014979
 >> iter 23000, loss: 0.014932
 >> iter 24000, loss: 0.014563
 >> iter 25000, loss: 0.014506
 >> iter 26000, loss: 0.014163
 >> iter 27000, loss: 0.014145
 >> iter 28000, loss: 0.013888
 >> iter 29000, loss: 0.013928
 >> iter 30000, loss: 0.013721
   Number of active neurons: 3
 >> iter 31000, loss: 0.013785
 >> iter 32000, loss: 0.013585
 >> iter 33000, loss: 0.013639
 >> iter 34000, loss: 0.013410
 >> iter 35000, loss: 0.013420
 >> iter 36000, loss: 0.013140
 >> iter 37000, loss: 0.013133
 >> iter 38000, loss: 0.012865
 >> iter 39000, loss: 0.012876
 >> iter 40000, loss: 0.012636
   Number of active neurons: 2
 >> iter 41000, loss: 0.012681
 >> iter 42000, loss: 0.012482
 >> iter 43000, loss: 0.012534
 >> iter 44000, loss: 0.012354
 >> iter 45000, loss: 0.012398
 >> iter 46000, loss: 0.012204
 >> iter 47000, loss: 0.012204
 >> iter 48000, loss: 0.011952
 >> iter 49000, loss: 0.011909
 >> iter 50000, loss: 0.011653
   Number of active neurons: 2
 >> iter 51000, loss: 0.011633
 >> iter 52000, loss: 0.011404
 >> iter 53000, loss: 0.011396
 >> iter 54000, loss: 0.011228
 >> iter 55000, loss: 0.011247
 >> iter 56000, loss: 0.011120
 >> iter 57000, loss: 0.011174
 >> iter 58000, loss: 0.011054
 >> iter 59000, loss: 0.011131
 >> iter 60000, loss: 0.011026
   Number of active neurons: 2
 >> iter 61000, loss: 0.011103
 >> iter 62000, loss: 0.011009
 >> iter 63000, loss: 0.011093
 >> iter 64000, loss: 0.010994
 >> iter 65000, loss: 0.011088
 >> iter 66000, loss: 0.010995
 >> iter 67000, loss: 0.011083
 >> iter 68000, loss: 0.011007
 >> iter 69000, loss: 0.011089
 >> iter 70000, loss: 0.011007
   Number of active neurons: 2
 >> iter 71000, loss: 0.011096
 >> iter 72000, loss: 0.011022
 >> iter 73000, loss: 0.011107
 >> iter 74000, loss: 0.011030
 >> iter 75000, loss: 0.011119
 >> iter 76000, loss: 0.011042
 >> iter 77000, loss: 0.011129
 >> iter 78000, loss: 0.011049
 >> iter 79000, loss: 0.011153
 >> iter 80000, loss: 0.011065
   Number of active neurons: 2
 >> iter 81000, loss: 0.011177
 >> iter 82000, loss: 0.011080
 >> iter 83000, loss: 0.011196
 >> iter 84000, loss: 0.011089
 >> iter 85000, loss: 0.011199
 >> iter 86000, loss: 0.011092
 >> iter 87000, loss: 0.011201
 >> iter 88000, loss: 0.011089
 >> iter 89000, loss: 0.011189
 >> iter 90000, loss: 0.011081
   Number of active neurons: 1
 >> iter 91000, loss: 0.011167
 >> iter 92000, loss: 0.011054
 >> iter 93000, loss: 0.011125
 >> iter 94000, loss: 0.010992
 >> iter 95000, loss: 0.011055
 >> iter 96000, loss: 0.010873
 >> iter 97000, loss: 0.010859
 >> iter 98000, loss: 0.010582
 >> iter 99000, loss: 0.010525
 >> iter 100000, loss: 0.010261
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.735020
 >> iter 2000, loss: 3.965087
 >> iter 3000, loss: 1.471379
 >> iter 4000, loss: 0.552522
 >> iter 5000, loss: 0.214170
 >> iter 6000, loss: 0.089176
 >> iter 7000, loss: 0.043204
 >> iter 8000, loss: 0.025945
 >> iter 9000, loss: 0.019733
 >> iter 10000, loss: 0.017170
   Number of active neurons: 4
 >> iter 11000, loss: 0.016387
 >> iter 12000, loss: 0.015833
 >> iter 13000, loss: 0.015821
 >> iter 14000, loss: 0.015529
 >> iter 15000, loss: 0.015590
 >> iter 16000, loss: 0.015299
 >> iter 17000, loss: 0.015291
 >> iter 18000, loss: 0.014903
 >> iter 19000, loss: 0.014767
 >> iter 20000, loss: 0.014322
   Number of active neurons: 2
 >> iter 21000, loss: 0.014121
 >> iter 22000, loss: 0.013671
 >> iter 23000, loss: 0.013500
 >> iter 24000, loss: 0.013062
 >> iter 25000, loss: 0.012886
 >> iter 26000, loss: 0.012448
 >> iter 27000, loss: 0.012256
 >> iter 28000, loss: 0.011856
 >> iter 29000, loss: 0.011717
 >> iter 30000, loss: 0.011411
   Number of active neurons: 2
 >> iter 31000, loss: 0.011370
 >> iter 32000, loss: 0.011151
 >> iter 33000, loss: 0.011174
 >> iter 34000, loss: 0.011006
 >> iter 35000, loss: 0.011071
 >> iter 36000, loss: 0.010920
 >> iter 37000, loss: 0.011003
 >> iter 38000, loss: 0.010863
 >> iter 39000, loss: 0.010962
 >> iter 40000, loss: 0.010826
   Number of active neurons: 2
 >> iter 41000, loss: 0.010929
 >> iter 42000, loss: 0.010804
 >> iter 43000, loss: 0.010902
 >> iter 44000, loss: 0.010788
 >> iter 45000, loss: 0.010888
 >> iter 46000, loss: 0.010774
 >> iter 47000, loss: 0.010874
 >> iter 48000, loss: 0.010768
 >> iter 49000, loss: 0.010871
 >> iter 50000, loss: 0.010761
   Number of active neurons: 2
 >> iter 51000, loss: 0.010867
 >> iter 52000, loss: 0.010764
 >> iter 53000, loss: 0.010863
 >> iter 54000, loss: 0.010779
 >> iter 55000, loss: 0.010861
 >> iter 56000, loss: 0.010782
 >> iter 57000, loss: 0.010874
 >> iter 58000, loss: 0.010782
 >> iter 59000, loss: 0.010883
 >> iter 60000, loss: 0.010794
   Number of active neurons: 2
 >> iter 61000, loss: 0.010888
 >> iter 62000, loss: 0.010806
 >> iter 63000, loss: 0.010902
 >> iter 64000, loss: 0.010811
 >> iter 65000, loss: 0.010914
 >> iter 66000, loss: 0.010828
 >> iter 67000, loss: 0.010925
 >> iter 68000, loss: 0.010854
 >> iter 69000, loss: 0.010942
 >> iter 70000, loss: 0.010866
   Number of active neurons: 2
 >> iter 71000, loss: 0.010960
 >> iter 72000, loss: 0.010890
 >> iter 73000, loss: 0.010981
 >> iter 74000, loss: 0.010907
 >> iter 75000, loss: 0.011002
 >> iter 76000, loss: 0.010929
 >> iter 77000, loss: 0.011020
 >> iter 78000, loss: 0.010944
 >> iter 79000, loss: 0.011053
 >> iter 80000, loss: 0.010969
   Number of active neurons: 2
 >> iter 81000, loss: 0.011086
 >> iter 82000, loss: 0.010992
 >> iter 83000, loss: 0.011114
 >> iter 84000, loss: 0.011011
 >> iter 85000, loss: 0.011128
 >> iter 86000, loss: 0.011025
 >> iter 87000, loss: 0.011143
 >> iter 88000, loss: 0.011037
 >> iter 89000, loss: 0.011148
 >> iter 90000, loss: 0.011048
   Number of active neurons: 1
 >> iter 91000, loss: 0.011148
 >> iter 92000, loss: 0.011048
 >> iter 93000, loss: 0.011138
 >> iter 94000, loss: 0.011024
 >> iter 95000, loss: 0.011117
 >> iter 96000, loss: 0.010977
 >> iter 97000, loss: 0.011055
 >> iter 98000, loss: 0.010892
 >> iter 99000, loss: 0.010914
 >> iter 100000, loss: 0.010672
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.667646
 >> iter 2000, loss: 3.939816
 >> iter 3000, loss: 1.460985
 >> iter 4000, loss: 0.547199
 >> iter 5000, loss: 0.210433
 >> iter 6000, loss: 0.085789
 >> iter 7000, loss: 0.039805
 >> iter 8000, loss: 0.022476
 >> iter 9000, loss: 0.016173
 >> iter 10000, loss: 0.013558
   Number of active neurons: 3
 >> iter 11000, loss: 0.012740
 >> iter 12000, loss: 0.012174
 >> iter 13000, loss: 0.012148
 >> iter 14000, loss: 0.011896
 >> iter 15000, loss: 0.011997
 >> iter 16000, loss: 0.011825
 >> iter 17000, loss: 0.011988
 >> iter 18000, loss: 0.011840
 >> iter 19000, loss: 0.011997
 >> iter 20000, loss: 0.011856
   Number of active neurons: 3
 >> iter 21000, loss: 0.012004
 >> iter 22000, loss: 0.011851
 >> iter 23000, loss: 0.012004
 >> iter 24000, loss: 0.011845
 >> iter 25000, loss: 0.012004
 >> iter 26000, loss: 0.011852
 >> iter 27000, loss: 0.012003
 >> iter 28000, loss: 0.011854
 >> iter 29000, loss: 0.011997
 >> iter 30000, loss: 0.011848
   Number of active neurons: 3
 >> iter 31000, loss: 0.011993
 >> iter 32000, loss: 0.011845
 >> iter 33000, loss: 0.011989
 >> iter 34000, loss: 0.011843
 >> iter 35000, loss: 0.011997
 >> iter 36000, loss: 0.011843
 >> iter 37000, loss: 0.011995
 >> iter 38000, loss: 0.011839
 >> iter 39000, loss: 0.011996
 >> iter 40000, loss: 0.011835
   Number of active neurons: 3
 >> iter 41000, loss: 0.011989
 >> iter 42000, loss: 0.011837
 >> iter 43000, loss: 0.011975
 >> iter 44000, loss: 0.011831
 >> iter 45000, loss: 0.011968
 >> iter 46000, loss: 0.011816
 >> iter 47000, loss: 0.011943
 >> iter 48000, loss: 0.011795
 >> iter 49000, loss: 0.011914
 >> iter 50000, loss: 0.011747
   Number of active neurons: 2
 >> iter 51000, loss: 0.011826
 >> iter 52000, loss: 0.011626
 >> iter 53000, loss: 0.011655
 >> iter 54000, loss: 0.011438
 >> iter 55000, loss: 0.011445
 >> iter 56000, loss: 0.011215
 >> iter 57000, loss: 0.011202
 >> iter 58000, loss: 0.010957
 >> iter 59000, loss: 0.010969
 >> iter 60000, loss: 0.010738
   Number of active neurons: 2
 >> iter 61000, loss: 0.010745
 >> iter 62000, loss: 0.010546
 >> iter 63000, loss: 0.010589
 >> iter 64000, loss: 0.010418
 >> iter 65000, loss: 0.010497
 >> iter 66000, loss: 0.010347
 >> iter 67000, loss: 0.010430
 >> iter 68000, loss: 0.010304
 >> iter 69000, loss: 0.010387
 >> iter 70000, loss: 0.010257
   Number of active neurons: 2
 >> iter 71000, loss: 0.010351
 >> iter 72000, loss: 0.010230
 >> iter 73000, loss: 0.010323
 >> iter 74000, loss: 0.010201
 >> iter 75000, loss: 0.010300
 >> iter 76000, loss: 0.010177
 >> iter 77000, loss: 0.010276
 >> iter 78000, loss: 0.010151
 >> iter 79000, loss: 0.010270
 >> iter 80000, loss: 0.010135
   Number of active neurons: 2
 >> iter 81000, loss: 0.010269
 >> iter 82000, loss: 0.010119
 >> iter 83000, loss: 0.010266
 >> iter 84000, loss: 0.010104
 >> iter 85000, loss: 0.010250
 >> iter 86000, loss: 0.010090
 >> iter 87000, loss: 0.010240
 >> iter 88000, loss: 0.010078
 >> iter 89000, loss: 0.010227
 >> iter 90000, loss: 0.010074
   Number of active neurons: 2
 >> iter 91000, loss: 0.010219
 >> iter 92000, loss: 0.010071
 >> iter 93000, loss: 0.010219
 >> iter 94000, loss: 0.010062
 >> iter 95000, loss: 0.010229
 >> iter 96000, loss: 0.010058
 >> iter 97000, loss: 0.010229
 >> iter 98000, loss: 0.010052
 >> iter 99000, loss: 0.010229
 >> iter 100000, loss: 0.010062
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.667241
 >> iter 2000, loss: 3.941176
 >> iter 3000, loss: 1.463210
 >> iter 4000, loss: 0.549934
 >> iter 5000, loss: 0.213429
 >> iter 6000, loss: 0.088856
 >> iter 7000, loss: 0.042750
 >> iter 8000, loss: 0.025215
 >> iter 9000, loss: 0.018669
 >> iter 10000, loss: 0.015866
   Number of active neurons: 3
 >> iter 11000, loss: 0.014844
 >> iter 12000, loss: 0.014131
 >> iter 13000, loss: 0.013961
 >> iter 14000, loss: 0.013612
 >> iter 15000, loss: 0.013600
 >> iter 16000, loss: 0.013299
 >> iter 17000, loss: 0.013296
 >> iter 18000, loss: 0.013016
 >> iter 19000, loss: 0.013014
 >> iter 20000, loss: 0.012775
   Number of active neurons: 3
 >> iter 21000, loss: 0.012790
 >> iter 22000, loss: 0.012587
 >> iter 23000, loss: 0.012664
 >> iter 24000, loss: 0.012503
 >> iter 25000, loss: 0.012611
 >> iter 26000, loss: 0.012471
 >> iter 27000, loss: 0.012580
 >> iter 28000, loss: 0.012447
 >> iter 29000, loss: 0.012547
 >> iter 30000, loss: 0.012411
   Number of active neurons: 2
 >> iter 31000, loss: 0.012508
 >> iter 32000, loss: 0.012365
 >> iter 33000, loss: 0.012451
 >> iter 34000, loss: 0.012300
 >> iter 35000, loss: 0.012379
 >> iter 36000, loss: 0.012202
 >> iter 37000, loss: 0.012256
 >> iter 38000, loss: 0.012028
 >> iter 39000, loss: 0.012016
 >> iter 40000, loss: 0.011743
   Number of active neurons: 2
 >> iter 41000, loss: 0.011727
 >> iter 42000, loss: 0.011484
 >> iter 43000, loss: 0.011474
 >> iter 44000, loss: 0.011263
 >> iter 45000, loss: 0.011287
 >> iter 46000, loss: 0.011119
 >> iter 47000, loss: 0.011178
 >> iter 48000, loss: 0.011044
 >> iter 49000, loss: 0.011124
 >> iter 50000, loss: 0.011000
   Number of active neurons: 2
 >> iter 51000, loss: 0.011093
 >> iter 52000, loss: 0.010984
 >> iter 53000, loss: 0.011075
 >> iter 54000, loss: 0.010988
 >> iter 55000, loss: 0.011065
 >> iter 56000, loss: 0.010985
 >> iter 57000, loss: 0.011074
 >> iter 58000, loss: 0.010982
 >> iter 59000, loss: 0.011080
 >> iter 60000, loss: 0.010994
   Number of active neurons: 2
 >> iter 61000, loss: 0.011084
 >> iter 62000, loss: 0.011004
 >> iter 63000, loss: 0.011098
 >> iter 64000, loss: 0.011009
 >> iter 65000, loss: 0.011109
 >> iter 66000, loss: 0.011025
 >> iter 67000, loss: 0.011118
 >> iter 68000, loss: 0.011049
 >> iter 69000, loss: 0.011133
 >> iter 70000, loss: 0.011057
   Number of active neurons: 2
 >> iter 71000, loss: 0.011146
 >> iter 72000, loss: 0.011076
 >> iter 73000, loss: 0.011159
 >> iter 74000, loss: 0.011084
 >> iter 75000, loss: 0.011169
 >> iter 76000, loss: 0.011092
 >> iter 77000, loss: 0.011170
 >> iter 78000, loss: 0.011087
 >> iter 79000, loss: 0.011177
 >> iter 80000, loss: 0.011081
   Number of active neurons: 1
 >> iter 81000, loss: 0.011172
 >> iter 82000, loss: 0.011059
 >> iter 83000, loss: 0.011144
 >> iter 84000, loss: 0.011011
 >> iter 85000, loss: 0.011074
 >> iter 86000, loss: 0.010923
 >> iter 87000, loss: 0.010933
 >> iter 88000, loss: 0.010694
 >> iter 89000, loss: 0.010620
 >> iter 90000, loss: 0.010360
   Number of active neurons: 1
 >> iter 91000, loss: 0.010292
 >> iter 92000, loss: 0.010052
 >> iter 93000, loss: 0.009982
 >> iter 94000, loss: 0.009744
 >> iter 95000, loss: 0.009713
 >> iter 96000, loss: 0.009505
 >> iter 97000, loss: 0.009515
 >> iter 98000, loss: 0.009336
 >> iter 99000, loss: 0.009375
 >> iter 100000, loss: 0.009223
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.718219
 >> iter 2000, loss: 3.959214
 >> iter 3000, loss: 1.469512
 >> iter 4000, loss: 0.552162
 >> iter 5000, loss: 0.214358
 >> iter 6000, loss: 0.089533
 >> iter 7000, loss: 0.043632
 >> iter 8000, loss: 0.026400
 >> iter 9000, loss: 0.020153
 >> iter 10000, loss: 0.017529
   Number of active neurons: 4
 >> iter 11000, loss: 0.016664
 >> iter 12000, loss: 0.015980
 >> iter 13000, loss: 0.015786
 >> iter 14000, loss: 0.015300
 >> iter 15000, loss: 0.015190
 >> iter 16000, loss: 0.014767
 >> iter 17000, loss: 0.014694
 >> iter 18000, loss: 0.014365
 >> iter 19000, loss: 0.014387
 >> iter 20000, loss: 0.014181
   Number of active neurons: 4
 >> iter 21000, loss: 0.014278
 >> iter 22000, loss: 0.014122
 >> iter 23000, loss: 0.014261
 >> iter 24000, loss: 0.014123
 >> iter 25000, loss: 0.014284
 >> iter 26000, loss: 0.014162
 >> iter 27000, loss: 0.014322
 >> iter 28000, loss: 0.014208
 >> iter 29000, loss: 0.014358
 >> iter 30000, loss: 0.014245
   Number of active neurons: 4
 >> iter 31000, loss: 0.014397
 >> iter 32000, loss: 0.014281
 >> iter 33000, loss: 0.014427
 >> iter 34000, loss: 0.014309
 >> iter 35000, loss: 0.014455
 >> iter 36000, loss: 0.014319
 >> iter 37000, loss: 0.014451
 >> iter 38000, loss: 0.014297
 >> iter 39000, loss: 0.014411
 >> iter 40000, loss: 0.014229
   Number of active neurons: 3
 >> iter 41000, loss: 0.014276
 >> iter 42000, loss: 0.014010
 >> iter 43000, loss: 0.013985
 >> iter 44000, loss: 0.013727
 >> iter 45000, loss: 0.013694
 >> iter 46000, loss: 0.013437
 >> iter 47000, loss: 0.013406
 >> iter 48000, loss: 0.013177
 >> iter 49000, loss: 0.013145
 >> iter 50000, loss: 0.012891
   Number of active neurons: 1
 >> iter 51000, loss: 0.012769
 >> iter 52000, loss: 0.012408
 >> iter 53000, loss: 0.012187
 >> iter 54000, loss: 0.011757
 >> iter 55000, loss: 0.011467
 >> iter 56000, loss: 0.011066
 >> iter 57000, loss: 0.010839
 >> iter 58000, loss: 0.010497
 >> iter 59000, loss: 0.010353
 >> iter 60000, loss: 0.010098
   Number of active neurons: 1
 >> iter 61000, loss: 0.010014
 >> iter 62000, loss: 0.009819
 >> iter 63000, loss: 0.009782
 >> iter 64000, loss: 0.009614
 >> iter 65000, loss: 0.009609
 >> iter 66000, loss: 0.009467
 >> iter 67000, loss: 0.009474
 >> iter 68000, loss: 0.009359
 >> iter 69000, loss: 0.009371
 >> iter 70000, loss: 0.009260
   Number of active neurons: 1
 >> iter 71000, loss: 0.009285
 >> iter 72000, loss: 0.009186
 >> iter 73000, loss: 0.009213
 >> iter 74000, loss: 0.009115
 >> iter 75000, loss: 0.009149
 >> iter 76000, loss: 0.009055
 >> iter 77000, loss: 0.009091
 >> iter 78000, loss: 0.008996
 >> iter 79000, loss: 0.009049
 >> iter 80000, loss: 0.008950
   Number of active neurons: 1
 >> iter 81000, loss: 0.009012
 >> iter 82000, loss: 0.008907
 >> iter 83000, loss: 0.008977
 >> iter 84000, loss: 0.008866
 >> iter 85000, loss: 0.008935
 >> iter 86000, loss: 0.008827
 >> iter 87000, loss: 0.008900
 >> iter 88000, loss: 0.008792
 >> iter 89000, loss: 0.008865
 >> iter 90000, loss: 0.008764
   Number of active neurons: 1
 >> iter 91000, loss: 0.008835
 >> iter 92000, loss: 0.008739
 >> iter 93000, loss: 0.008810
 >> iter 94000, loss: 0.008709
 >> iter 95000, loss: 0.008794
 >> iter 96000, loss: 0.008683
 >> iter 97000, loss: 0.008772
 >> iter 98000, loss: 0.008658
 >> iter 99000, loss: 0.008752
 >> iter 100000, loss: 0.008647
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.705634
 >> iter 2000, loss: 3.953371
 >> iter 3000, loss: 1.466492
 >> iter 4000, loss: 0.550128
 >> iter 5000, loss: 0.212702
 >> iter 6000, loss: 0.088086
 >> iter 7000, loss: 0.042300
 >> iter 8000, loss: 0.025157
 >> iter 9000, loss: 0.019075
 >> iter 10000, loss: 0.016612
   Number of active neurons: 5
 >> iter 11000, loss: 0.015922
 >> iter 12000, loss: 0.015403
 >> iter 13000, loss: 0.015415
 >> iter 14000, loss: 0.015123
 >> iter 15000, loss: 0.015199
 >> iter 16000, loss: 0.014909
 >> iter 17000, loss: 0.014964
 >> iter 18000, loss: 0.014700
 >> iter 19000, loss: 0.014779
 >> iter 20000, loss: 0.014552
   Number of active neurons: 4
 >> iter 21000, loss: 0.014628
 >> iter 22000, loss: 0.014394
 >> iter 23000, loss: 0.014451
 >> iter 24000, loss: 0.014186
 >> iter 25000, loss: 0.014233
 >> iter 26000, loss: 0.013988
 >> iter 27000, loss: 0.014031
 >> iter 28000, loss: 0.013823
 >> iter 29000, loss: 0.013909
 >> iter 30000, loss: 0.013740
   Number of active neurons: 3
 >> iter 31000, loss: 0.013846
 >> iter 32000, loss: 0.013682
 >> iter 33000, loss: 0.013783
 >> iter 34000, loss: 0.013615
 >> iter 35000, loss: 0.013708
 >> iter 36000, loss: 0.013513
 >> iter 37000, loss: 0.013576
 >> iter 38000, loss: 0.013323
 >> iter 39000, loss: 0.013326
 >> iter 40000, loss: 0.013034
   Number of active neurons: 2
 >> iter 41000, loss: 0.013021
 >> iter 42000, loss: 0.012747
 >> iter 43000, loss: 0.012728
 >> iter 44000, loss: 0.012488
 >> iter 45000, loss: 0.012491
 >> iter 46000, loss: 0.012267
 >> iter 47000, loss: 0.012248
 >> iter 48000, loss: 0.011982
 >> iter 49000, loss: 0.011928
 >> iter 50000, loss: 0.011663
   Number of active neurons: 2
 >> iter 51000, loss: 0.011637
 >> iter 52000, loss: 0.011403
 >> iter 53000, loss: 0.011391
 >> iter 54000, loss: 0.011221
 >> iter 55000, loss: 0.011238
 >> iter 56000, loss: 0.011110
 >> iter 57000, loss: 0.011163
 >> iter 58000, loss: 0.011041
 >> iter 59000, loss: 0.011118
 >> iter 60000, loss: 0.011011
   Number of active neurons: 2
 >> iter 61000, loss: 0.011087
 >> iter 62000, loss: 0.010993
 >> iter 63000, loss: 0.011076
 >> iter 64000, loss: 0.010976
 >> iter 65000, loss: 0.011069
 >> iter 66000, loss: 0.010975
 >> iter 67000, loss: 0.011064
 >> iter 68000, loss: 0.010987
 >> iter 69000, loss: 0.011068
 >> iter 70000, loss: 0.010985
   Number of active neurons: 2
 >> iter 71000, loss: 0.011074
 >> iter 72000, loss: 0.010999
 >> iter 73000, loss: 0.011084
 >> iter 74000, loss: 0.011006
 >> iter 75000, loss: 0.011096
 >> iter 76000, loss: 0.011019
 >> iter 77000, loss: 0.011105
 >> iter 78000, loss: 0.011026
 >> iter 79000, loss: 0.011130
 >> iter 80000, loss: 0.011043
   Number of active neurons: 2
 >> iter 81000, loss: 0.011156
 >> iter 82000, loss: 0.011059
 >> iter 83000, loss: 0.011178
 >> iter 84000, loss: 0.011072
 >> iter 85000, loss: 0.011185
 >> iter 86000, loss: 0.011079
 >> iter 87000, loss: 0.011193
 >> iter 88000, loss: 0.011084
 >> iter 89000, loss: 0.011191
 >> iter 90000, loss: 0.011088
   Number of active neurons: 1
 >> iter 91000, loss: 0.011183
 >> iter 92000, loss: 0.011079
 >> iter 93000, loss: 0.011164
 >> iter 94000, loss: 0.011044
 >> iter 95000, loss: 0.011129
 >> iter 96000, loss: 0.010982
 >> iter 97000, loss: 0.011049
 >> iter 98000, loss: 0.010860
 >> iter 99000, loss: 0.010848
 >> iter 100000, loss: 0.010579
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.779899
 >> iter 2000, loss: 3.982222
 >> iter 3000, loss: 1.478249
 >> iter 4000, loss: 0.555341
 >> iter 5000, loss: 0.215341
 >> iter 6000, loss: 0.089548
 >> iter 7000, loss: 0.043130
 >> iter 8000, loss: 0.025534
 >> iter 9000, loss: 0.019001
 >> iter 10000, loss: 0.016148
   Number of active neurons: 3
 >> iter 11000, loss: 0.015133
 >> iter 12000, loss: 0.014381
 >> iter 13000, loss: 0.014184
 >> iter 14000, loss: 0.013734
 >> iter 15000, loss: 0.013650
 >> iter 16000, loss: 0.013254
 >> iter 17000, loss: 0.013178
 >> iter 18000, loss: 0.012818
 >> iter 19000, loss: 0.012784
 >> iter 20000, loss: 0.012514
   Number of active neurons: 3
 >> iter 21000, loss: 0.012546
 >> iter 22000, loss: 0.012337
 >> iter 23000, loss: 0.012404
 >> iter 24000, loss: 0.012205
 >> iter 25000, loss: 0.012302
 >> iter 26000, loss: 0.012132
 >> iter 27000, loss: 0.012235
 >> iter 28000, loss: 0.012076
 >> iter 29000, loss: 0.012174
 >> iter 30000, loss: 0.012016
   Number of active neurons: 2
 >> iter 31000, loss: 0.012110
 >> iter 32000, loss: 0.011945
 >> iter 33000, loss: 0.012029
 >> iter 34000, loss: 0.011855
 >> iter 35000, loss: 0.011929
 >> iter 36000, loss: 0.011729
 >> iter 37000, loss: 0.011761
 >> iter 38000, loss: 0.011493
 >> iter 39000, loss: 0.011484
 >> iter 40000, loss: 0.011222
   Number of active neurons: 2
 >> iter 41000, loss: 0.011232
 >> iter 42000, loss: 0.010996
 >> iter 43000, loss: 0.011007
 >> iter 44000, loss: 0.010802
 >> iter 45000, loss: 0.010846
 >> iter 46000, loss: 0.010681
 >> iter 47000, loss: 0.010756
 >> iter 48000, loss: 0.010620
 >> iter 49000, loss: 0.010712
 >> iter 50000, loss: 0.010583
   Number of active neurons: 2
 >> iter 51000, loss: 0.010685
 >> iter 52000, loss: 0.010569
 >> iter 53000, loss: 0.010664
 >> iter 54000, loss: 0.010555
 >> iter 55000, loss: 0.010631
 >> iter 56000, loss: 0.010542
 >> iter 57000, loss: 0.010633
 >> iter 58000, loss: 0.010533
 >> iter 59000, loss: 0.010633
 >> iter 60000, loss: 0.010537
   Number of active neurons: 2
 >> iter 61000, loss: 0.010628
 >> iter 62000, loss: 0.010537
 >> iter 63000, loss: 0.010629
 >> iter 64000, loss: 0.010529
 >> iter 65000, loss: 0.010629
 >> iter 66000, loss: 0.010533
 >> iter 67000, loss: 0.010626
 >> iter 68000, loss: 0.010544
 >> iter 69000, loss: 0.010629
 >> iter 70000, loss: 0.010541
   Number of active neurons: 2
 >> iter 71000, loss: 0.010632
 >> iter 72000, loss: 0.010551
 >> iter 73000, loss: 0.010638
 >> iter 74000, loss: 0.010553
 >> iter 75000, loss: 0.010645
 >> iter 76000, loss: 0.010560
 >> iter 77000, loss: 0.010649
 >> iter 78000, loss: 0.010562
 >> iter 79000, loss: 0.010669
 >> iter 80000, loss: 0.010574
   Number of active neurons: 2
 >> iter 81000, loss: 0.010692
 >> iter 82000, loss: 0.010586
 >> iter 83000, loss: 0.010712
 >> iter 84000, loss: 0.010597
 >> iter 85000, loss: 0.010721
 >> iter 86000, loss: 0.010607
 >> iter 87000, loss: 0.010735
 >> iter 88000, loss: 0.010621
 >> iter 89000, loss: 0.010747
 >> iter 90000, loss: 0.010642
   Number of active neurons: 2
 >> iter 91000, loss: 0.010763
 >> iter 92000, loss: 0.010663
 >> iter 93000, loss: 0.010784
 >> iter 94000, loss: 0.010678
 >> iter 95000, loss: 0.010815
 >> iter 96000, loss: 0.010695
 >> iter 97000, loss: 0.010836
 >> iter 98000, loss: 0.010713
 >> iter 99000, loss: 0.010860
 >> iter 100000, loss: 0.010747
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.744466
 >> iter 2000, loss: 3.967339
 >> iter 3000, loss: 1.471318
 >> iter 4000, loss: 0.551503
 >> iter 5000, loss: 0.212813
 >> iter 6000, loss: 0.087557
 >> iter 7000, loss: 0.041505
 >> iter 8000, loss: 0.024190
 >> iter 9000, loss: 0.018021
 >> iter 10000, loss: 0.015537
   Number of active neurons: 5
 >> iter 11000, loss: 0.014907
 >> iter 12000, loss: 0.014451
 >> iter 13000, loss: 0.014569
 >> iter 14000, loss: 0.014374
 >> iter 15000, loss: 0.014589
 >> iter 16000, loss: 0.014435
 >> iter 17000, loss: 0.014655
 >> iter 18000, loss: 0.014512
 >> iter 19000, loss: 0.014721
 >> iter 20000, loss: 0.014588
   Number of active neurons: 5
 >> iter 21000, loss: 0.014752
 >> iter 22000, loss: 0.014581
 >> iter 23000, loss: 0.014762
 >> iter 24000, loss: 0.014607
 >> iter 25000, loss: 0.014804
 >> iter 26000, loss: 0.014661
 >> iter 27000, loss: 0.014845
 >> iter 28000, loss: 0.014704
 >> iter 29000, loss: 0.014866
 >> iter 30000, loss: 0.014707
   Number of active neurons: 5
 >> iter 31000, loss: 0.014858
 >> iter 32000, loss: 0.014701
 >> iter 33000, loss: 0.014842
 >> iter 34000, loss: 0.014676
 >> iter 35000, loss: 0.014806
 >> iter 36000, loss: 0.014611
 >> iter 37000, loss: 0.014708
 >> iter 38000, loss: 0.014475
 >> iter 39000, loss: 0.014516
 >> iter 40000, loss: 0.014224
   Number of active neurons: 2
 >> iter 41000, loss: 0.014171
 >> iter 42000, loss: 0.013786
 >> iter 43000, loss: 0.013632
 >> iter 44000, loss: 0.013174
 >> iter 45000, loss: 0.012909
 >> iter 46000, loss: 0.012418
 >> iter 47000, loss: 0.012200
 >> iter 48000, loss: 0.011804
 >> iter 49000, loss: 0.011673
 >> iter 50000, loss: 0.011378
   Number of active neurons: 2
 >> iter 51000, loss: 0.011349
 >> iter 52000, loss: 0.011145
 >> iter 53000, loss: 0.011168
 >> iter 54000, loss: 0.011026
 >> iter 55000, loss: 0.011063
 >> iter 56000, loss: 0.010948
 >> iter 57000, loss: 0.011010
 >> iter 58000, loss: 0.010892
 >> iter 59000, loss: 0.010971
 >> iter 60000, loss: 0.010864
   Number of active neurons: 2
 >> iter 61000, loss: 0.010940
 >> iter 62000, loss: 0.010842
 >> iter 63000, loss: 0.010923
 >> iter 64000, loss: 0.010818
 >> iter 65000, loss: 0.010909
 >> iter 66000, loss: 0.010810
 >> iter 67000, loss: 0.010895
 >> iter 68000, loss: 0.010812
 >> iter 69000, loss: 0.010890
 >> iter 70000, loss: 0.010801
   Number of active neurons: 2
 >> iter 71000, loss: 0.010888
 >> iter 72000, loss: 0.010806
 >> iter 73000, loss: 0.010889
 >> iter 74000, loss: 0.010805
 >> iter 75000, loss: 0.010894
 >> iter 76000, loss: 0.010810
 >> iter 77000, loss: 0.010897
 >> iter 78000, loss: 0.010812
 >> iter 79000, loss: 0.010917
 >> iter 80000, loss: 0.010824
   Number of active neurons: 2
 >> iter 81000, loss: 0.010940
 >> iter 82000, loss: 0.010838
 >> iter 83000, loss: 0.010962
 >> iter 84000, loss: 0.010852
 >> iter 85000, loss: 0.010973
 >> iter 86000, loss: 0.010865
 >> iter 87000, loss: 0.010991
 >> iter 88000, loss: 0.010882
 >> iter 89000, loss: 0.011005
 >> iter 90000, loss: 0.010907
   Number of active neurons: 2
 >> iter 91000, loss: 0.011025
 >> iter 92000, loss: 0.010931
 >> iter 93000, loss: 0.011049
 >> iter 94000, loss: 0.010949
 >> iter 95000, loss: 0.011081
 >> iter 96000, loss: 0.010968
 >> iter 97000, loss: 0.011103
 >> iter 98000, loss: 0.010986
 >> iter 99000, loss: 0.011125
 >> iter 100000, loss: 0.011018
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 10.789381
 >> iter 2000, loss: 3.984561
 >> iter 3000, loss: 1.478311
 >> iter 4000, loss: 0.555039
 >> iter 5000, loss: 0.215180
 >> iter 6000, loss: 0.089685
 >> iter 7000, loss: 0.043610
 >> iter 8000, loss: 0.026346
 >> iter 9000, loss: 0.020135
 >> iter 10000, loss: 0.017526
   Number of active neurons: 4
 >> iter 11000, loss: 0.016717
 >> iter 12000, loss: 0.016090
 >> iter 13000, loss: 0.015997
 >> iter 14000, loss: 0.015582
 >> iter 15000, loss: 0.015502
 >> iter 16000, loss: 0.015091
 >> iter 17000, loss: 0.015021
 >> iter 18000, loss: 0.014610
 >> iter 19000, loss: 0.014513
 >> iter 20000, loss: 0.014140
   Number of active neurons: 3
 >> iter 21000, loss: 0.014076
 >> iter 22000, loss: 0.013759
 >> iter 23000, loss: 0.013754
 >> iter 24000, loss: 0.013486
 >> iter 25000, loss: 0.013508
 >> iter 26000, loss: 0.013254
 >> iter 27000, loss: 0.013247
 >> iter 28000, loss: 0.012950
 >> iter 29000, loss: 0.012829
 >> iter 30000, loss: 0.012445
   Number of active neurons: 2
 >> iter 31000, loss: 0.012276
 >> iter 32000, loss: 0.011884
 >> iter 33000, loss: 0.011755
 >> iter 34000, loss: 0.011435
 >> iter 35000, loss: 0.011384
 >> iter 36000, loss: 0.011138
 >> iter 37000, loss: 0.011141
 >> iter 38000, loss: 0.010942
 >> iter 39000, loss: 0.011006
 >> iter 40000, loss: 0.010844
   Number of active neurons: 2
 >> iter 41000, loss: 0.010930
 >> iter 42000, loss: 0.010790
 >> iter 43000, loss: 0.010878
 >> iter 44000, loss: 0.010755
 >> iter 45000, loss: 0.010849
 >> iter 46000, loss: 0.010727
 >> iter 47000, loss: 0.010823
 >> iter 48000, loss: 0.010710
 >> iter 49000, loss: 0.010810
 >> iter 50000, loss: 0.010694
   Number of active neurons: 2
 >> iter 51000, loss: 0.010797
 >> iter 52000, loss: 0.010688
 >> iter 53000, loss: 0.010784
 >> iter 54000, loss: 0.010694
 >> iter 55000, loss: 0.010774
 >> iter 56000, loss: 0.010690
 >> iter 57000, loss: 0.010779
 >> iter 58000, loss: 0.010681
 >> iter 59000, loss: 0.010780
 >> iter 60000, loss: 0.010686
   Number of active neurons: 2
 >> iter 61000, loss: 0.010777
 >> iter 62000, loss: 0.010690
 >> iter 63000, loss: 0.010783
 >> iter 64000, loss: 0.010687
 >> iter 65000, loss: 0.010788
 >> iter 66000, loss: 0.010697
 >> iter 67000, loss: 0.010791
 >> iter 68000, loss: 0.010715
 >> iter 69000, loss: 0.010801
 >> iter 70000, loss: 0.010719
   Number of active neurons: 2
 >> iter 71000, loss: 0.010812
 >> iter 72000, loss: 0.010737
 >> iter 73000, loss: 0.010826
 >> iter 74000, loss: 0.010747
 >> iter 75000, loss: 0.010841
 >> iter 76000, loss: 0.010763
 >> iter 77000, loss: 0.010855
 >> iter 78000, loss: 0.010774
 >> iter 79000, loss: 0.010884
 >> iter 80000, loss: 0.010796
   Number of active neurons: 2
 >> iter 81000, loss: 0.010916
 >> iter 82000, loss: 0.010818
 >> iter 83000, loss: 0.010945
 >> iter 84000, loss: 0.010839
 >> iter 85000, loss: 0.010963
 >> iter 86000, loss: 0.010858
 >> iter 87000, loss: 0.010986
 >> iter 88000, loss: 0.010881
 >> iter 89000, loss: 0.011006
 >> iter 90000, loss: 0.010911
   Number of active neurons: 2
 >> iter 91000, loss: 0.011030
 >> iter 92000, loss: 0.010939
 >> iter 93000, loss: 0.011056
 >> iter 94000, loss: 0.010959
 >> iter 95000, loss: 0.011090
 >> iter 96000, loss: 0.010978
 >> iter 97000, loss: 0.011112
 >> iter 98000, loss: 0.010996
 >> iter 99000, loss: 0.011133
 >> iter 100000, loss: 0.011025
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.735230
 >> iter 2000, loss: 3.964785
 >> iter 3000, loss: 1.471379
 >> iter 4000, loss: 0.552432
 >> iter 5000, loss: 0.213944
 >> iter 6000, loss: 0.088730
 >> iter 7000, loss: 0.042609
 >> iter 8000, loss: 0.025161
 >> iter 9000, loss: 0.018802
 >> iter 10000, loss: 0.016063
   Number of active neurons: 4
 >> iter 11000, loss: 0.015160
 >> iter 12000, loss: 0.014452
 >> iter 13000, loss: 0.014297
 >> iter 14000, loss: 0.013884
 >> iter 15000, loss: 0.013884
 >> iter 16000, loss: 0.013540
 >> iter 17000, loss: 0.013554
 >> iter 18000, loss: 0.013242
 >> iter 19000, loss: 0.013264
 >> iter 20000, loss: 0.012968
   Number of active neurons: 3
 >> iter 21000, loss: 0.012987
 >> iter 22000, loss: 0.012710
 >> iter 23000, loss: 0.012743
 >> iter 24000, loss: 0.012462
 >> iter 25000, loss: 0.012512
 >> iter 26000, loss: 0.012263
 >> iter 27000, loss: 0.012334
 >> iter 28000, loss: 0.012133
 >> iter 29000, loss: 0.012234
 >> iter 30000, loss: 0.012063
   Number of active neurons: 3
 >> iter 31000, loss: 0.012185
 >> iter 32000, loss: 0.012030
 >> iter 33000, loss: 0.012161
 >> iter 34000, loss: 0.012015
 >> iter 35000, loss: 0.012161
 >> iter 36000, loss: 0.012011
 >> iter 37000, loss: 0.012158
 >> iter 38000, loss: 0.012008
 >> iter 39000, loss: 0.012162
 >> iter 40000, loss: 0.011997
   Number of active neurons: 3
 >> iter 41000, loss: 0.012131
 >> iter 42000, loss: 0.011977
 >> iter 43000, loss: 0.012108
 >> iter 44000, loss: 0.011969
 >> iter 45000, loss: 0.012104
 >> iter 46000, loss: 0.011962
 >> iter 47000, loss: 0.012092
 >> iter 48000, loss: 0.011958
 >> iter 49000, loss: 0.012086
 >> iter 50000, loss: 0.011942
   Number of active neurons: 2
 >> iter 51000, loss: 0.012063
 >> iter 52000, loss: 0.011922
 >> iter 53000, loss: 0.012022
 >> iter 54000, loss: 0.011893
 >> iter 55000, loss: 0.011957
 >> iter 56000, loss: 0.011821
 >> iter 57000, loss: 0.011871
 >> iter 58000, loss: 0.011679
 >> iter 59000, loss: 0.011647
 >> iter 60000, loss: 0.011396
   Number of active neurons: 2
 >> iter 61000, loss: 0.011363
 >> iter 62000, loss: 0.011147
 >> iter 63000, loss: 0.011129
 >> iter 64000, loss: 0.010921
 >> iter 65000, loss: 0.010939
 >> iter 66000, loss: 0.010771
 >> iter 67000, loss: 0.010806
 >> iter 68000, loss: 0.010684
 >> iter 69000, loss: 0.010742
 >> iter 70000, loss: 0.010632
   Number of active neurons: 2
 >> iter 71000, loss: 0.010707
 >> iter 72000, loss: 0.010610
 >> iter 73000, loss: 0.010686
 >> iter 74000, loss: 0.010588
 >> iter 75000, loss: 0.010671
 >> iter 76000, loss: 0.010575
 >> iter 77000, loss: 0.010657
 >> iter 78000, loss: 0.010560
 >> iter 79000, loss: 0.010660
 >> iter 80000, loss: 0.010555
   Number of active neurons: 2
 >> iter 81000, loss: 0.010668
 >> iter 82000, loss: 0.010552
 >> iter 83000, loss: 0.010674
 >> iter 84000, loss: 0.010550
 >> iter 85000, loss: 0.010669
 >> iter 86000, loss: 0.010547
 >> iter 87000, loss: 0.010671
 >> iter 88000, loss: 0.010547
 >> iter 89000, loss: 0.010669
 >> iter 90000, loss: 0.010556
   Number of active neurons: 2
 >> iter 91000, loss: 0.010674
 >> iter 92000, loss: 0.010565
 >> iter 93000, loss: 0.010683
 >> iter 94000, loss: 0.010568
 >> iter 95000, loss: 0.010702
 >> iter 96000, loss: 0.010574
 >> iter 97000, loss: 0.010713
 >> iter 98000, loss: 0.010581
 >> iter 99000, loss: 0.010726
 >> iter 100000, loss: 0.010604
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

