 > Problema: tomita6nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.624685
 >> iter 2000, loss: 15.098932
 >> iter 3000, loss: 13.768356
 >> iter 4000, loss: 13.274091
 >> iter 5000, loss: 13.073913
 >> iter 6000, loss: 13.001115
 >> iter 7000, loss: 12.961596
 >> iter 8000, loss: 12.953579
 >> iter 9000, loss: 12.937228
 >> iter 10000, loss: 12.548174
   Number of active neurons: 5
 >> iter 11000, loss: 6.965212
 >> iter 12000, loss: 2.645573
 >> iter 13000, loss: 1.043900
 >> iter 14000, loss: 0.410991
 >> iter 15000, loss: 0.170631
 >> iter 16000, loss: 0.077996
 >> iter 17000, loss: 0.041156
 >> iter 18000, loss: 0.025630
 >> iter 19000, loss: 0.018504
 >> iter 20000, loss: 0.014738
   Number of active neurons: 10
 >> iter 21000, loss: 0.012502
 >> iter 22000, loss: 0.010938
 >> iter 23000, loss: 0.009798
 >> iter 24000, loss: 0.008865
 >> iter 25000, loss: 0.008119
 >> iter 26000, loss: 0.007463
 >> iter 27000, loss: 0.006926
 >> iter 28000, loss: 0.006438
 >> iter 29000, loss: 0.006033
 >> iter 30000, loss: 0.005650
   Number of active neurons: 10
 >> iter 31000, loss: 0.005332
 >> iter 32000, loss: 0.005024
 >> iter 33000, loss: 0.004771
 >> iter 34000, loss: 0.004518
 >> iter 35000, loss: 0.004310
 >> iter 36000, loss: 0.004099
 >> iter 37000, loss: 0.003926
 >> iter 38000, loss: 0.003749
 >> iter 39000, loss: 0.003603
 >> iter 40000, loss: 0.003452
   Number of active neurons: 10
 >> iter 41000, loss: 0.003326
 >> iter 42000, loss: 0.003195
 >> iter 43000, loss: 0.003087
 >> iter 44000, loss: 0.002971
 >> iter 45000, loss: 0.002878
 >> iter 46000, loss: 0.002777
 >> iter 47000, loss: 0.002693
 >> iter 48000, loss: 0.002603
 >> iter 49000, loss: 0.002531
 >> iter 50000, loss: 0.002450
   Number of active neurons: 10
 >> iter 51000, loss: 0.002385
 >> iter 52000, loss: 0.002312
 >> iter 53000, loss: 0.002253
 >> iter 54000, loss: 0.002188
 >> iter 55000, loss: 0.002135
 >> iter 56000, loss: 0.002076
 >> iter 57000, loss: 0.002028
 >> iter 58000, loss: 0.001974
 >> iter 59000, loss: 0.001931
 >> iter 60000, loss: 0.001882
   Number of active neurons: 10
 >> iter 61000, loss: 0.001842
 >> iter 62000, loss: 0.001797
 >> iter 63000, loss: 0.001759
 >> iter 64000, loss: 0.001719
 >> iter 65000, loss: 0.001685
 >> iter 66000, loss: 0.001648
 >> iter 67000, loss: 0.001616
 >> iter 68000, loss: 0.001581
 >> iter 69000, loss: 0.001552
 >> iter 70000, loss: 0.001518
   Number of active neurons: 10
 >> iter 71000, loss: 0.001492
 >> iter 72000, loss: 0.001461
 >> iter 73000, loss: 0.001437
 >> iter 74000, loss: 0.001408
 >> iter 75000, loss: 0.001385
 >> iter 76000, loss: 0.001358
 >> iter 77000, loss: 0.001337
 >> iter 78000, loss: 0.001312
 >> iter 79000, loss: 0.001292
 >> iter 80000, loss: 0.001268
   Number of active neurons: 10
 >> iter 81000, loss: 0.001249
 >> iter 82000, loss: 0.001227
 >> iter 83000, loss: 0.001209
 >> iter 84000, loss: 0.001188
 >> iter 85000, loss: 0.001172
 >> iter 86000, loss: 0.001152
 >> iter 87000, loss: 0.001137
 >> iter 88000, loss: 0.001117
 >> iter 89000, loss: 0.001103
 >> iter 90000, loss: 0.001085
   Number of active neurons: 10
 >> iter 91000, loss: 0.001071
 >> iter 92000, loss: 0.001054
 >> iter 93000, loss: 0.001041
 >> iter 94000, loss: 0.001025
 >> iter 95000, loss: 0.001013
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.610025
 >> iter 2000, loss: 15.091440
 >> iter 3000, loss: 13.761692
 >> iter 4000, loss: 13.268432
 >> iter 5000, loss: 13.071674
 >> iter 6000, loss: 13.001753
 >> iter 7000, loss: 12.965112
 >> iter 8000, loss: 12.958014
 >> iter 9000, loss: 12.945097
 >> iter 10000, loss: 12.950289
   Number of active neurons: 5
 >> iter 11000, loss: 12.939492
 >> iter 12000, loss: 12.938682
 >> iter 13000, loss: 12.705051
 >> iter 14000, loss: 7.335181
 >> iter 15000, loss: 2.761365
 >> iter 16000, loss: 1.041716
 >> iter 17000, loss: 0.399953
 >> iter 18000, loss: 0.159124
 >> iter 19000, loss: 0.068110
 >> iter 20000, loss: 0.032764
   Number of active neurons: 10
 >> iter 21000, loss: 0.018678
 >> iter 22000, loss: 0.012507
 >> iter 23000, loss: 0.009633
 >> iter 24000, loss: 0.007967
 >> iter 25000, loss: 0.006973
 >> iter 26000, loss: 0.006194
 >> iter 27000, loss: 0.005649
 >> iter 28000, loss: 0.005150
 >> iter 29000, loss: 0.004781
 >> iter 30000, loss: 0.004417
   Number of active neurons: 10
 >> iter 31000, loss: 0.004145
 >> iter 32000, loss: 0.003866
 >> iter 33000, loss: 0.003657
 >> iter 34000, loss: 0.003435
 >> iter 35000, loss: 0.003269
 >> iter 36000, loss: 0.003090
 >> iter 37000, loss: 0.002954
 >> iter 38000, loss: 0.002806
 >> iter 39000, loss: 0.002694
 >> iter 40000, loss: 0.002570
   Number of active neurons: 10
 >> iter 41000, loss: 0.002476
 >> iter 42000, loss: 0.002369
 >> iter 43000, loss: 0.002289
 >> iter 44000, loss: 0.002196
 >> iter 45000, loss: 0.002128
 >> iter 46000, loss: 0.002047
 >> iter 47000, loss: 0.001988
 >> iter 48000, loss: 0.001916
 >> iter 49000, loss: 0.001865
 >> iter 50000, loss: 0.001801
   Number of active neurons: 10
 >> iter 51000, loss: 0.001756
 >> iter 52000, loss: 0.001699
 >> iter 53000, loss: 0.001658
 >> iter 54000, loss: 0.001608
 >> iter 55000, loss: 0.001571
 >> iter 56000, loss: 0.001525
 >> iter 57000, loss: 0.001492
 >> iter 58000, loss: 0.001451
 >> iter 59000, loss: 0.001421
 >> iter 60000, loss: 0.001384
   Number of active neurons: 10
 >> iter 61000, loss: 0.001357
 >> iter 62000, loss: 0.001322
 >> iter 63000, loss: 0.001297
 >> iter 64000, loss: 0.001265
 >> iter 65000, loss: 0.001243
 >> iter 66000, loss: 0.001213
 >> iter 67000, loss: 0.001193
 >> iter 68000, loss: 0.001165
 >> iter 69000, loss: 0.001147
 >> iter 70000, loss: 0.001121
   Number of active neurons: 10
 >> iter 71000, loss: 0.001104
 >> iter 72000, loss: 0.001080
 >> iter 73000, loss: 0.001064
 >> iter 74000, loss: 0.001042
 >> iter 75000, loss: 0.001027
 >> iter 76000, loss: 0.001006
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.622031
 >> iter 2000, loss: 15.125607
 >> iter 3000, loss: 13.798007
 >> iter 4000, loss: 13.300217
 >> iter 5000, loss: 13.095338
 >> iter 6000, loss: 13.017608
 >> iter 7000, loss: 12.976015
 >> iter 8000, loss: 12.954161
 >> iter 9000, loss: 12.628532
 >> iter 10000, loss: 10.990992
   Number of active neurons: 10
 >> iter 11000, loss: 4.688868
 >> iter 12000, loss: 1.759438
 >> iter 13000, loss: 0.666847
 >> iter 14000, loss: 0.260810
 >> iter 15000, loss: 0.106890
 >> iter 16000, loss: 0.048515
 >> iter 17000, loss: 0.025073
 >> iter 18000, loss: 0.015396
 >> iter 19000, loss: 0.011043
 >> iter 20000, loss: 0.008947
   Number of active neurons: 10
 >> iter 21000, loss: 0.007611
 >> iter 22000, loss: 0.006767
 >> iter 23000, loss: 0.006090
 >> iter 24000, loss: 0.005612
 >> iter 25000, loss: 0.005152
 >> iter 26000, loss: 0.004814
 >> iter 27000, loss: 0.004472
 >> iter 28000, loss: 0.004220
 >> iter 29000, loss: 0.003951
 >> iter 30000, loss: 0.003753
   Number of active neurons: 10
 >> iter 31000, loss: 0.003537
 >> iter 32000, loss: 0.003379
 >> iter 33000, loss: 0.003201
 >> iter 34000, loss: 0.003071
 >> iter 35000, loss: 0.002921
 >> iter 36000, loss: 0.002812
 >> iter 37000, loss: 0.002685
 >> iter 38000, loss: 0.002592
 >> iter 39000, loss: 0.002483
 >> iter 40000, loss: 0.002404
   Number of active neurons: 10
 >> iter 41000, loss: 0.002308
 >> iter 42000, loss: 0.002239
 >> iter 43000, loss: 0.002154
 >> iter 44000, loss: 0.002096
 >> iter 45000, loss: 0.002020
 >> iter 46000, loss: 0.001968
 >> iter 47000, loss: 0.001902
 >> iter 48000, loss: 0.001855
 >> iter 49000, loss: 0.001795
 >> iter 50000, loss: 0.001754
   Number of active neurons: 10
 >> iter 51000, loss: 0.001700
 >> iter 52000, loss: 0.001664
 >> iter 53000, loss: 0.001614
 >> iter 54000, loss: 0.001582
 >> iter 55000, loss: 0.001536
 >> iter 56000, loss: 0.001509
 >> iter 57000, loss: 0.001465
 >> iter 58000, loss: 0.001440
 >> iter 59000, loss: 0.001400
 >> iter 60000, loss: 0.001378
   Number of active neurons: 10
 >> iter 61000, loss: 0.001340
 >> iter 62000, loss: 0.001321
 >> iter 63000, loss: 0.001285
 >> iter 64000, loss: 0.001268
 >> iter 65000, loss: 0.001235
 >> iter 66000, loss: 0.001219
 >> iter 67000, loss: 0.001188
 >> iter 68000, loss: 0.001173
 >> iter 69000, loss: 0.001144
 >> iter 70000, loss: 0.001131
   Number of active neurons: 10
 >> iter 71000, loss: 0.001103
 >> iter 72000, loss: 0.001092
 >> iter 73000, loss: 0.001066
 >> iter 74000, loss: 0.001055
 >> iter 75000, loss: 0.001031
 >> iter 76000, loss: 0.001020
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.635400
 >> iter 2000, loss: 15.139639
 >> iter 3000, loss: 13.807477
 >> iter 4000, loss: 13.304279
 >> iter 5000, loss: 13.090986
 >> iter 6000, loss: 13.011071
 >> iter 7000, loss: 12.967629
 >> iter 8000, loss: 12.957975
 >> iter 9000, loss: 12.939484
 >> iter 10000, loss: 12.502452
   Number of active neurons: 10
 >> iter 11000, loss: 7.731486
 >> iter 12000, loss: 2.904994
 >> iter 13000, loss: 1.094331
 >> iter 14000, loss: 0.418903
 >> iter 15000, loss: 0.166146
 >> iter 16000, loss: 0.070602
 >> iter 17000, loss: 0.033835
 >> iter 18000, loss: 0.019093
 >> iter 19000, loss: 0.012833
 >> iter 20000, loss: 0.009826
   Number of active neurons: 10
 >> iter 21000, loss: 0.008209
 >> iter 22000, loss: 0.007156
 >> iter 23000, loss: 0.006427
 >> iter 24000, loss: 0.005836
 >> iter 25000, loss: 0.005375
 >> iter 26000, loss: 0.004964
 >> iter 27000, loss: 0.004633
 >> iter 28000, loss: 0.004324
 >> iter 29000, loss: 0.004073
 >> iter 30000, loss: 0.003829
   Number of active neurons: 10
 >> iter 31000, loss: 0.003632
 >> iter 32000, loss: 0.003435
 >> iter 33000, loss: 0.003277
 >> iter 34000, loss: 0.003113
 >> iter 35000, loss: 0.002984
 >> iter 36000, loss: 0.002845
 >> iter 37000, loss: 0.002738
 >> iter 38000, loss: 0.002620
 >> iter 39000, loss: 0.002530
 >> iter 40000, loss: 0.002427
   Number of active neurons: 10
 >> iter 41000, loss: 0.002351
 >> iter 42000, loss: 0.002261
 >> iter 43000, loss: 0.002194
 >> iter 44000, loss: 0.002116
 >> iter 45000, loss: 0.002058
 >> iter 46000, loss: 0.001988
 >> iter 47000, loss: 0.001937
 >> iter 48000, loss: 0.001874
 >> iter 49000, loss: 0.001829
 >> iter 50000, loss: 0.001773
   Number of active neurons: 10
 >> iter 51000, loss: 0.001732
 >> iter 52000, loss: 0.001681
 >> iter 53000, loss: 0.001645
 >> iter 54000, loss: 0.001598
 >> iter 55000, loss: 0.001566
 >> iter 56000, loss: 0.001523
 >> iter 57000, loss: 0.001494
 >> iter 58000, loss: 0.001454
 >> iter 59000, loss: 0.001429
 >> iter 60000, loss: 0.001391
   Number of active neurons: 10
 >> iter 61000, loss: 0.001368
 >> iter 62000, loss: 0.001334
 >> iter 63000, loss: 0.001313
 >> iter 64000, loss: 0.001280
 >> iter 65000, loss: 0.001262
 >> iter 66000, loss: 0.001231
 >> iter 67000, loss: 0.001214
 >> iter 68000, loss: 0.001185
 >> iter 69000, loss: 0.001170
 >> iter 70000, loss: 0.001143
   Number of active neurons: 10
 >> iter 71000, loss: 0.001129
 >> iter 72000, loss: 0.001104
 >> iter 73000, loss: 0.001091
 >> iter 74000, loss: 0.001067
 >> iter 75000, loss: 0.001055
 >> iter 76000, loss: 0.001032
 >> iter 77000, loss: 0.001022
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.614301
 >> iter 2000, loss: 15.109163
 >> iter 3000, loss: 13.779697
 >> iter 4000, loss: 13.284253
 >> iter 5000, loss: 13.082636
 >> iter 6000, loss: 13.010687
 >> iter 7000, loss: 12.972996
 >> iter 8000, loss: 12.966344
 >> iter 9000, loss: 12.953032
 >> iter 10000, loss: 12.957962
   Number of active neurons: 6
 >> iter 11000, loss: 12.945779
 >> iter 12000, loss: 12.949248
 >> iter 13000, loss: 12.936951
 >> iter 14000, loss: 12.934640
 >> iter 15000, loss: 12.694360
 >> iter 16000, loss: 6.161516
 >> iter 17000, loss: 2.307586
 >> iter 18000, loss: 0.870664
 >> iter 19000, loss: 0.335057
 >> iter 20000, loss: 0.134528
   Number of active neurons: 10
 >> iter 21000, loss: 0.058458
 >> iter 22000, loss: 0.029055
 >> iter 23000, loss: 0.017085
 >> iter 24000, loss: 0.011937
 >> iter 25000, loss: 0.009347
 >> iter 26000, loss: 0.007940
 >> iter 27000, loss: 0.006956
 >> iter 28000, loss: 0.006298
 >> iter 29000, loss: 0.005717
 >> iter 30000, loss: 0.005295
   Number of active neurons: 10
 >> iter 31000, loss: 0.004883
 >> iter 32000, loss: 0.004578
 >> iter 33000, loss: 0.004265
 >> iter 34000, loss: 0.004033
 >> iter 35000, loss: 0.003785
 >> iter 36000, loss: 0.003604
 >> iter 37000, loss: 0.003401
 >> iter 38000, loss: 0.003256
 >> iter 39000, loss: 0.003087
 >> iter 40000, loss: 0.002970
   Number of active neurons: 10
 >> iter 41000, loss: 0.002826
 >> iter 42000, loss: 0.002728
 >> iter 43000, loss: 0.002605
 >> iter 44000, loss: 0.002522
 >> iter 45000, loss: 0.002416
 >> iter 46000, loss: 0.002347
 >> iter 47000, loss: 0.002252
 >> iter 48000, loss: 0.002192
 >> iter 49000, loss: 0.002109
 >> iter 50000, loss: 0.002057
   Number of active neurons: 10
 >> iter 51000, loss: 0.001982
 >> iter 52000, loss: 0.001937
 >> iter 53000, loss: 0.001869
 >> iter 54000, loss: 0.001831
 >> iter 55000, loss: 0.001769
 >> iter 56000, loss: 0.001735
 >> iter 57000, loss: 0.001678
 >> iter 58000, loss: 0.001648
 >> iter 59000, loss: 0.001597
 >> iter 60000, loss: 0.001570
   Number of active neurons: 10
 >> iter 61000, loss: 0.001523
 >> iter 62000, loss: 0.001499
 >> iter 63000, loss: 0.001455
 >> iter 64000, loss: 0.001433
 >> iter 65000, loss: 0.001393
 >> iter 66000, loss: 0.001373
 >> iter 67000, loss: 0.001337
 >> iter 68000, loss: 0.001318
 >> iter 69000, loss: 0.001284
 >> iter 70000, loss: 0.001267
   Number of active neurons: 10
 >> iter 71000, loss: 0.001236
 >> iter 72000, loss: 0.001220
 >> iter 73000, loss: 0.001190
 >> iter 74000, loss: 0.001176
 >> iter 75000, loss: 0.001148
 >> iter 76000, loss: 0.001136
 >> iter 77000, loss: 0.001109
 >> iter 78000, loss: 0.001098
 >> iter 79000, loss: 0.001072
 >> iter 80000, loss: 0.001062
   Number of active neurons: 10
 >> iter 81000, loss: 0.001038
 >> iter 82000, loss: 0.001028
 >> iter 83000, loss: 0.001006
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.630868
 >> iter 2000, loss: 15.090902
 >> iter 3000, loss: 13.751381
 >> iter 4000, loss: 13.255891
 >> iter 5000, loss: 13.059704
 >> iter 6000, loss: 12.991467
 >> iter 7000, loss: 12.957013
 >> iter 8000, loss: 12.952236
 >> iter 9000, loss: 12.940753
 >> iter 10000, loss: 12.946903
   Number of active neurons: 5
 >> iter 11000, loss: 12.935374
 >> iter 12000, loss: 12.729495
 >> iter 13000, loss: 7.110427
 >> iter 14000, loss: 2.692484
 >> iter 15000, loss: 1.027377
 >> iter 16000, loss: 0.402496
 >> iter 17000, loss: 0.166255
 >> iter 18000, loss: 0.075687
 >> iter 19000, loss: 0.039787
 >> iter 20000, loss: 0.024864
   Number of active neurons: 10
 >> iter 21000, loss: 0.017976
 >> iter 22000, loss: 0.014468
 >> iter 23000, loss: 0.012295
 >> iter 24000, loss: 0.010882
 >> iter 25000, loss: 0.009752
 >> iter 26000, loss: 0.008911
 >> iter 27000, loss: 0.008157
 >> iter 28000, loss: 0.007576
 >> iter 29000, loss: 0.007021
 >> iter 30000, loss: 0.006586
   Number of active neurons: 10
 >> iter 31000, loss: 0.006155
 >> iter 32000, loss: 0.005817
 >> iter 33000, loss: 0.005476
 >> iter 34000, loss: 0.005206
 >> iter 35000, loss: 0.004926
 >> iter 36000, loss: 0.004707
 >> iter 37000, loss: 0.004473
 >> iter 38000, loss: 0.004293
 >> iter 39000, loss: 0.004094
 >> iter 40000, loss: 0.003944
   Number of active neurons: 10
 >> iter 41000, loss: 0.003773
 >> iter 42000, loss: 0.003644
 >> iter 43000, loss: 0.003497
 >> iter 44000, loss: 0.003384
 >> iter 45000, loss: 0.003256
 >> iter 46000, loss: 0.003160
 >> iter 47000, loss: 0.003045
 >> iter 48000, loss: 0.002960
 >> iter 49000, loss: 0.002859
 >> iter 50000, loss: 0.002784
   Number of active neurons: 10
 >> iter 51000, loss: 0.002693
 >> iter 52000, loss: 0.002626
 >> iter 53000, loss: 0.002543
 >> iter 54000, loss: 0.002485
 >> iter 55000, loss: 0.002409
 >> iter 56000, loss: 0.002357
 >> iter 57000, loss: 0.002288
 >> iter 58000, loss: 0.002241
 >> iter 59000, loss: 0.002179
 >> iter 60000, loss: 0.002136
   Number of active neurons: 10
 >> iter 61000, loss: 0.002078
 >> iter 62000, loss: 0.002039
 >> iter 63000, loss: 0.001985
 >> iter 64000, loss: 0.001950
 >> iter 65000, loss: 0.001902
 >> iter 66000, loss: 0.001868
 >> iter 67000, loss: 0.001824
 >> iter 68000, loss: 0.001793
 >> iter 69000, loss: 0.001752
 >> iter 70000, loss: 0.001723
   Number of active neurons: 10
 >> iter 71000, loss: 0.001685
 >> iter 72000, loss: 0.001658
 >> iter 73000, loss: 0.001622
 >> iter 74000, loss: 0.001598
 >> iter 75000, loss: 0.001564
 >> iter 76000, loss: 0.001542
 >> iter 77000, loss: 0.001510
 >> iter 78000, loss: 0.001489
 >> iter 79000, loss: 0.001459
 >> iter 80000, loss: 0.001440
   Number of active neurons: 10
 >> iter 81000, loss: 0.001412
 >> iter 82000, loss: 0.001393
 >> iter 83000, loss: 0.001367
 >> iter 84000, loss: 0.001350
 >> iter 85000, loss: 0.001324
 >> iter 86000, loss: 0.001309
 >> iter 87000, loss: 0.001284
 >> iter 88000, loss: 0.001270
 >> iter 89000, loss: 0.001247
 >> iter 90000, loss: 0.001233
   Number of active neurons: 10
 >> iter 91000, loss: 0.001212
 >> iter 92000, loss: 0.001198
 >> iter 93000, loss: 0.001178
 >> iter 94000, loss: 0.001165
 >> iter 95000, loss: 0.001146
 >> iter 96000, loss: 0.001134
 >> iter 97000, loss: 0.001116
 >> iter 98000, loss: 0.001104
 >> iter 99000, loss: 0.001087
 >> iter 100000, loss: 0.001076
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.601275
 >> iter 2000, loss: 15.076911
 >> iter 3000, loss: 13.743654
 >> iter 4000, loss: 13.250328
 >> iter 5000, loss: 13.050027
 >> iter 6000, loss: 12.982060
 >> iter 7000, loss: 12.944663
 >> iter 8000, loss: 12.940584
 >> iter 9000, loss: 12.927102
 >> iter 10000, loss: 12.933702
   Number of active neurons: 4
 >> iter 11000, loss: 12.916230
 >> iter 12000, loss: 11.845069
 >> iter 13000, loss: 4.528627
 >> iter 14000, loss: 1.705307
 >> iter 15000, loss: 0.650264
 >> iter 16000, loss: 0.255452
 >> iter 17000, loss: 0.106393
 >> iter 18000, loss: 0.049269
 >> iter 19000, loss: 0.026571
 >> iter 20000, loss: 0.017089
   Number of active neurons: 10
 >> iter 21000, loss: 0.012653
 >> iter 22000, loss: 0.010361
 >> iter 23000, loss: 0.008904
 >> iter 24000, loss: 0.007944
 >> iter 25000, loss: 0.007159
 >> iter 26000, loss: 0.006574
 >> iter 27000, loss: 0.006041
 >> iter 28000, loss: 0.005631
 >> iter 29000, loss: 0.005232
 >> iter 30000, loss: 0.004924
   Number of active neurons: 10
 >> iter 31000, loss: 0.004611
 >> iter 32000, loss: 0.004371
 >> iter 33000, loss: 0.004121
 >> iter 34000, loss: 0.003928
 >> iter 35000, loss: 0.003722
 >> iter 36000, loss: 0.003566
 >> iter 37000, loss: 0.003391
 >> iter 38000, loss: 0.003263
 >> iter 39000, loss: 0.003115
 >> iter 40000, loss: 0.003008
   Number of active neurons: 10
 >> iter 41000, loss: 0.002879
 >> iter 42000, loss: 0.002787
 >> iter 43000, loss: 0.002675
 >> iter 44000, loss: 0.002596
 >> iter 45000, loss: 0.002498
 >> iter 46000, loss: 0.002429
 >> iter 47000, loss: 0.002341
 >> iter 48000, loss: 0.002282
 >> iter 49000, loss: 0.002204
 >> iter 50000, loss: 0.002151
   Number of active neurons: 10
 >> iter 51000, loss: 0.002080
 >> iter 52000, loss: 0.002034
 >> iter 53000, loss: 0.001969
 >> iter 54000, loss: 0.001929
 >> iter 55000, loss: 0.001869
 >> iter 56000, loss: 0.001833
 >> iter 57000, loss: 0.001779
 >> iter 58000, loss: 0.001747
 >> iter 59000, loss: 0.001697
 >> iter 60000, loss: 0.001668
   Number of active neurons: 10
 >> iter 61000, loss: 0.001621
 >> iter 62000, loss: 0.001595
 >> iter 63000, loss: 0.001552
 >> iter 64000, loss: 0.001529
 >> iter 65000, loss: 0.001489
 >> iter 66000, loss: 0.001467
 >> iter 67000, loss: 0.001430
 >> iter 68000, loss: 0.001410
 >> iter 69000, loss: 0.001376
 >> iter 70000, loss: 0.001357
   Number of active neurons: 10
 >> iter 71000, loss: 0.001326
 >> iter 72000, loss: 0.001308
 >> iter 73000, loss: 0.001278
 >> iter 74000, loss: 0.001263
 >> iter 75000, loss: 0.001234
 >> iter 76000, loss: 0.001221
 >> iter 77000, loss: 0.001194
 >> iter 78000, loss: 0.001181
 >> iter 79000, loss: 0.001155
 >> iter 80000, loss: 0.001143
   Number of active neurons: 10
 >> iter 81000, loss: 0.001119
 >> iter 82000, loss: 0.001108
 >> iter 83000, loss: 0.001084
 >> iter 84000, loss: 0.001074
 >> iter 85000, loss: 0.001052
 >> iter 86000, loss: 0.001043
 >> iter 87000, loss: 0.001022
 >> iter 88000, loss: 0.001013
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.623414
 >> iter 2000, loss: 15.100566
 >> iter 3000, loss: 13.767522
 >> iter 4000, loss: 13.271844
 >> iter 5000, loss: 13.076040
 >> iter 6000, loss: 13.007052
 >> iter 7000, loss: 12.972825
 >> iter 8000, loss: 12.967523
 >> iter 9000, loss: 12.955790
 >> iter 10000, loss: 12.961751
   Number of active neurons: 6
 >> iter 11000, loss: 12.949419
 >> iter 12000, loss: 12.954267
 >> iter 13000, loss: 12.940889
 >> iter 14000, loss: 12.947538
 >> iter 15000, loss: 12.935233
 >> iter 16000, loss: 12.861925
 >> iter 17000, loss: 9.637490
 >> iter 18000, loss: 3.629080
 >> iter 19000, loss: 1.354192
 >> iter 20000, loss: 0.509934
   Number of active neurons: 10
 >> iter 21000, loss: 0.196030
 >> iter 22000, loss: 0.078707
 >> iter 23000, loss: 0.034310
 >> iter 24000, loss: 0.017158
 >> iter 25000, loss: 0.010206
 >> iter 26000, loss: 0.007193
 >> iter 27000, loss: 0.005693
 >> iter 28000, loss: 0.004856
 >> iter 29000, loss: 0.004285
 >> iter 30000, loss: 0.003881
   Number of active neurons: 10
 >> iter 31000, loss: 0.003542
 >> iter 32000, loss: 0.003277
 >> iter 33000, loss: 0.003037
 >> iter 34000, loss: 0.002843
 >> iter 35000, loss: 0.002660
 >> iter 36000, loss: 0.002511
 >> iter 37000, loss: 0.002366
 >> iter 38000, loss: 0.002248
 >> iter 39000, loss: 0.002131
 >> iter 40000, loss: 0.002034
   Number of active neurons: 10
 >> iter 41000, loss: 0.001937
 >> iter 42000, loss: 0.001857
 >> iter 43000, loss: 0.001775
 >> iter 44000, loss: 0.001707
 >> iter 45000, loss: 0.001638
 >> iter 46000, loss: 0.001580
 >> iter 47000, loss: 0.001520
 >> iter 48000, loss: 0.001470
 >> iter 49000, loss: 0.001418
 >> iter 50000, loss: 0.001374
   Number of active neurons: 10
 >> iter 51000, loss: 0.001328
 >> iter 52000, loss: 0.001290
 >> iter 53000, loss: 0.001248
 >> iter 54000, loss: 0.001216
 >> iter 55000, loss: 0.001178
 >> iter 56000, loss: 0.001149
 >> iter 57000, loss: 0.001115
 >> iter 58000, loss: 0.001089
 >> iter 59000, loss: 0.001059
 >> iter 60000, loss: 0.001035
   Number of active neurons: 10
 >> iter 61000, loss: 0.001008
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.631762
 >> iter 2000, loss: 15.115821
 >> iter 3000, loss: 13.775414
 >> iter 4000, loss: 13.273320
 >> iter 5000, loss: 13.068724
 >> iter 6000, loss: 12.995976
 >> iter 7000, loss: 12.957901
 >> iter 8000, loss: 12.950848
 >> iter 9000, loss: 12.937341
 >> iter 10000, loss: 12.940606
   Number of active neurons: 5
 >> iter 11000, loss: 12.924087
 >> iter 12000, loss: 12.712626
 >> iter 13000, loss: 8.031373
 >> iter 14000, loss: 2.992227
 >> iter 15000, loss: 1.118099
 >> iter 16000, loss: 0.422611
 >> iter 17000, loss: 0.163887
 >> iter 18000, loss: 0.066957
 >> iter 19000, loss: 0.030153
 >> iter 20000, loss: 0.015788
   Number of active neurons: 9
 >> iter 21000, loss: 0.009892
 >> iter 22000, loss: 0.007249
 >> iter 23000, loss: 0.005898
 >> iter 24000, loss: 0.005097
 >> iter 25000, loss: 0.004545
 >> iter 26000, loss: 0.004130
 >> iter 27000, loss: 0.003792
 >> iter 28000, loss: 0.003512
 >> iter 29000, loss: 0.003270
 >> iter 30000, loss: 0.003061
   Number of active neurons: 10
 >> iter 31000, loss: 0.002876
 >> iter 32000, loss: 0.002714
 >> iter 33000, loss: 0.002566
 >> iter 34000, loss: 0.002436
 >> iter 35000, loss: 0.002316
 >> iter 36000, loss: 0.002209
 >> iter 37000, loss: 0.002110
 >> iter 38000, loss: 0.002021
 >> iter 39000, loss: 0.001938
 >> iter 40000, loss: 0.001863
   Number of active neurons: 9
 >> iter 41000, loss: 0.001792
 >> iter 42000, loss: 0.001727
 >> iter 43000, loss: 0.001665
 >> iter 44000, loss: 0.001609
 >> iter 45000, loss: 0.001556
 >> iter 46000, loss: 0.001506
 >> iter 47000, loss: 0.001459
 >> iter 48000, loss: 0.001416
 >> iter 49000, loss: 0.001374
 >> iter 50000, loss: 0.001335
   Number of active neurons: 9
 >> iter 51000, loss: 0.001299
 >> iter 52000, loss: 0.001263
 >> iter 53000, loss: 0.001230
 >> iter 54000, loss: 0.001199
 >> iter 55000, loss: 0.001169
 >> iter 56000, loss: 0.001140
 >> iter 57000, loss: 0.001113
 >> iter 58000, loss: 0.001087
 >> iter 59000, loss: 0.001063
 >> iter 60000, loss: 0.001039
   Number of active neurons: 10
 >> iter 61000, loss: 0.001016
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.628916
 >> iter 2000, loss: 15.113398
 >> iter 3000, loss: 13.784567
 >> iter 4000, loss: 13.289374
 >> iter 5000, loss: 13.090758
 >> iter 6000, loss: 13.016968
 >> iter 7000, loss: 12.980194
 >> iter 8000, loss: 12.972403
 >> iter 9000, loss: 12.960429
 >> iter 10000, loss: 12.965661
   Number of active neurons: 6
 >> iter 11000, loss: 12.955698
 >> iter 12000, loss: 12.960608
 >> iter 13000, loss: 12.950914
 >> iter 14000, loss: 12.929245
 >> iter 15000, loss: 12.173492
 >> iter 16000, loss: 5.153188
 >> iter 17000, loss: 1.970600
 >> iter 18000, loss: 0.753546
 >> iter 19000, loss: 0.297371
 >> iter 20000, loss: 0.124087
   Number of active neurons: 10
 >> iter 21000, loss: 0.057310
 >> iter 22000, loss: 0.030565
 >> iter 23000, loss: 0.019255
 >> iter 24000, loss: 0.013918
 >> iter 25000, loss: 0.011113
 >> iter 26000, loss: 0.009380
 >> iter 27000, loss: 0.008207
 >> iter 28000, loss: 0.007325
 >> iter 29000, loss: 0.006632
 >> iter 30000, loss: 0.006064
   Number of active neurons: 10
 >> iter 31000, loss: 0.005588
 >> iter 32000, loss: 0.005182
 >> iter 33000, loss: 0.004832
 >> iter 34000, loss: 0.004527
 >> iter 35000, loss: 0.004255
 >> iter 36000, loss: 0.004018
 >> iter 37000, loss: 0.003800
 >> iter 38000, loss: 0.003610
 >> iter 39000, loss: 0.003432
 >> iter 40000, loss: 0.003279
   Number of active neurons: 10
 >> iter 41000, loss: 0.003130
 >> iter 42000, loss: 0.003000
 >> iter 43000, loss: 0.002875
 >> iter 44000, loss: 0.002766
 >> iter 45000, loss: 0.002659
 >> iter 46000, loss: 0.002566
 >> iter 47000, loss: 0.002473
 >> iter 48000, loss: 0.002392
 >> iter 49000, loss: 0.002311
 >> iter 50000, loss: 0.002241
   Number of active neurons: 10
 >> iter 51000, loss: 0.002168
 >> iter 52000, loss: 0.002107
 >> iter 53000, loss: 0.002040
 >> iter 54000, loss: 0.001988
 >> iter 55000, loss: 0.001928
 >> iter 56000, loss: 0.001882
 >> iter 57000, loss: 0.001828
 >> iter 58000, loss: 0.001786
 >> iter 59000, loss: 0.001737
 >> iter 60000, loss: 0.001700
   Number of active neurons: 10
 >> iter 61000, loss: 0.001655
 >> iter 62000, loss: 0.001621
 >> iter 63000, loss: 0.001580
 >> iter 64000, loss: 0.001550
 >> iter 65000, loss: 0.001512
 >> iter 66000, loss: 0.001484
 >> iter 67000, loss: 0.001449
 >> iter 68000, loss: 0.001424
 >> iter 69000, loss: 0.001391
 >> iter 70000, loss: 0.001368
   Number of active neurons: 10
 >> iter 71000, loss: 0.001338
 >> iter 72000, loss: 0.001316
 >> iter 73000, loss: 0.001288
 >> iter 74000, loss: 0.001269
 >> iter 75000, loss: 0.001242
 >> iter 76000, loss: 0.001224
 >> iter 77000, loss: 0.001200
 >> iter 78000, loss: 0.001183
 >> iter 79000, loss: 0.001160
 >> iter 80000, loss: 0.001144
   Number of active neurons: 10
 >> iter 81000, loss: 0.001122
 >> iter 82000, loss: 0.001108
 >> iter 83000, loss: 0.001087
 >> iter 84000, loss: 0.001074
 >> iter 85000, loss: 0.001054
 >> iter 86000, loss: 0.001042
 >> iter 87000, loss: 0.001023
 >> iter 88000, loss: 0.001011
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0349996500035
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.635165
 >> iter 2000, loss: 15.116488
 >> iter 3000, loss: 13.778023
 >> iter 4000, loss: 13.278831
 >> iter 5000, loss: 13.077441
 >> iter 6000, loss: 13.005563
 >> iter 7000, loss: 12.967996
 >> iter 8000, loss: 12.959820
 >> iter 9000, loss: 12.946116
 >> iter 10000, loss: 12.944200
   Number of active neurons: 6
 >> iter 11000, loss: 12.699992
 >> iter 12000, loss: 7.438535
 >> iter 13000, loss: 2.817330
 >> iter 14000, loss: 1.090928
 >> iter 15000, loss: 0.425506
 >> iter 16000, loss: 0.174160
 >> iter 17000, loss: 0.077352
 >> iter 18000, loss: 0.042395
 >> iter 19000, loss: 0.025717
 >> iter 20000, loss: 0.018293
   Number of active neurons: 10
 >> iter 21000, loss: 0.013865
 >> iter 22000, loss: 0.011304
 >> iter 23000, loss: 0.009685
 >> iter 24000, loss: 0.008592
 >> iter 25000, loss: 0.007722
 >> iter 26000, loss: 0.007072
 >> iter 27000, loss: 0.006487
 >> iter 28000, loss: 0.006039
 >> iter 29000, loss: 0.005606
 >> iter 30000, loss: 0.005271
   Number of active neurons: 10
 >> iter 31000, loss: 0.004933
 >> iter 32000, loss: 0.004673
 >> iter 33000, loss: 0.004401
 >> iter 34000, loss: 0.004193
 >> iter 35000, loss: 0.003971
 >> iter 36000, loss: 0.003802
 >> iter 37000, loss: 0.003618
 >> iter 38000, loss: 0.003475
 >> iter 39000, loss: 0.003318
 >> iter 40000, loss: 0.003199
   Number of active neurons: 10
 >> iter 41000, loss: 0.003065
 >> iter 42000, loss: 0.002961
 >> iter 43000, loss: 0.002845
 >> iter 44000, loss: 0.002755
 >> iter 45000, loss: 0.002654
 >> iter 46000, loss: 0.002576
 >> iter 47000, loss: 0.002485
 >> iter 48000, loss: 0.002417
 >> iter 49000, loss: 0.002337
 >> iter 50000, loss: 0.002277
   Number of active neurons: 10
 >> iter 51000, loss: 0.002204
 >> iter 52000, loss: 0.002150
 >> iter 53000, loss: 0.002084
 >> iter 54000, loss: 0.002037
 >> iter 55000, loss: 0.001977
 >> iter 56000, loss: 0.001935
 >> iter 57000, loss: 0.001880
 >> iter 58000, loss: 0.001842
 >> iter 59000, loss: 0.001793
 >> iter 60000, loss: 0.001758
   Number of active neurons: 10
 >> iter 61000, loss: 0.001713
 >> iter 62000, loss: 0.001680
 >> iter 63000, loss: 0.001638
 >> iter 64000, loss: 0.001608
 >> iter 65000, loss: 0.001571
 >> iter 66000, loss: 0.001543
 >> iter 67000, loss: 0.001509
 >> iter 68000, loss: 0.001484
 >> iter 69000, loss: 0.001451
 >> iter 70000, loss: 0.001427
   Number of active neurons: 10
 >> iter 71000, loss: 0.001397
 >> iter 72000, loss: 0.001375
 >> iter 73000, loss: 0.001346
 >> iter 74000, loss: 0.001327
 >> iter 75000, loss: 0.001299
 >> iter 76000, loss: 0.001281
 >> iter 77000, loss: 0.001256
 >> iter 78000, loss: 0.001239
 >> iter 79000, loss: 0.001215
 >> iter 80000, loss: 0.001200
   Number of active neurons: 10
 >> iter 81000, loss: 0.001176
 >> iter 82000, loss: 0.001163
 >> iter 83000, loss: 0.001140
 >> iter 84000, loss: 0.001127
 >> iter 85000, loss: 0.001106
 >> iter 86000, loss: 0.001094
 >> iter 87000, loss: 0.001075
 >> iter 88000, loss: 0.001063
 >> iter 89000, loss: 0.001044
 >> iter 90000, loss: 0.001033
   Number of active neurons: 10
 >> iter 91000, loss: 0.001015
 >> iter 92000, loss: 0.001005
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.629186
 >> iter 2000, loss: 15.102076
 >> iter 3000, loss: 13.769909
 >> iter 4000, loss: 13.273751
 >> iter 5000, loss: 13.069241
 >> iter 6000, loss: 12.995167
 >> iter 7000, loss: 12.954063
 >> iter 8000, loss: 12.947368
 >> iter 9000, loss: 12.932386
 >> iter 10000, loss: 12.939100
   Number of active neurons: 3
 >> iter 11000, loss: 12.926843
 >> iter 12000, loss: 12.933730
 >> iter 13000, loss: 12.922486
 >> iter 14000, loss: 12.930153
 >> iter 15000, loss: 12.882628
 >> iter 16000, loss: 9.302424
 >> iter 17000, loss: 3.530982
 >> iter 18000, loss: 1.342007
 >> iter 19000, loss: 0.519980
 >> iter 20000, loss: 0.210217
   Number of active neurons: 10
 >> iter 21000, loss: 0.091934
 >> iter 22000, loss: 0.045713
 >> iter 23000, loss: 0.026762
 >> iter 24000, loss: 0.018431
 >> iter 25000, loss: 0.014270
 >> iter 26000, loss: 0.011927
 >> iter 27000, loss: 0.010370
 >> iter 28000, loss: 0.009267
 >> iter 29000, loss: 0.008381
 >> iter 30000, loss: 0.007678
   Number of active neurons: 10
 >> iter 31000, loss: 0.007067
 >> iter 32000, loss: 0.006563
 >> iter 33000, loss: 0.006110
 >> iter 34000, loss: 0.005728
 >> iter 35000, loss: 0.005377
 >> iter 36000, loss: 0.005078
 >> iter 37000, loss: 0.004796
 >> iter 38000, loss: 0.004557
 >> iter 39000, loss: 0.004326
 >> iter 40000, loss: 0.004130
   Number of active neurons: 10
 >> iter 41000, loss: 0.003937
 >> iter 42000, loss: 0.003772
 >> iter 43000, loss: 0.003610
 >> iter 44000, loss: 0.003469
 >> iter 45000, loss: 0.003331
 >> iter 46000, loss: 0.003211
 >> iter 47000, loss: 0.003090
 >> iter 48000, loss: 0.002986
 >> iter 49000, loss: 0.002880
 >> iter 50000, loss: 0.002790
   Number of active neurons: 10
 >> iter 51000, loss: 0.002696
 >> iter 52000, loss: 0.002616
 >> iter 53000, loss: 0.002531
 >> iter 54000, loss: 0.002462
 >> iter 55000, loss: 0.002386
 >> iter 56000, loss: 0.002325
 >> iter 57000, loss: 0.002256
 >> iter 58000, loss: 0.002201
 >> iter 59000, loss: 0.002139
 >> iter 60000, loss: 0.002090
   Number of active neurons: 10
 >> iter 61000, loss: 0.002033
 >> iter 62000, loss: 0.001988
 >> iter 63000, loss: 0.001935
 >> iter 64000, loss: 0.001895
 >> iter 65000, loss: 0.001848
 >> iter 66000, loss: 0.001810
 >> iter 67000, loss: 0.001767
 >> iter 68000, loss: 0.001732
 >> iter 69000, loss: 0.001693
 >> iter 70000, loss: 0.001660
   Number of active neurons: 10
 >> iter 71000, loss: 0.001624
 >> iter 72000, loss: 0.001594
 >> iter 73000, loss: 0.001560
 >> iter 74000, loss: 0.001533
 >> iter 75000, loss: 0.001501
 >> iter 76000, loss: 0.001476
 >> iter 77000, loss: 0.001446
 >> iter 78000, loss: 0.001423
 >> iter 79000, loss: 0.001394
 >> iter 80000, loss: 0.001373
   Number of active neurons: 10
 >> iter 81000, loss: 0.001347
 >> iter 82000, loss: 0.001326
 >> iter 83000, loss: 0.001301
 >> iter 84000, loss: 0.001282
 >> iter 85000, loss: 0.001259
 >> iter 86000, loss: 0.001242
 >> iter 87000, loss: 0.001220
 >> iter 88000, loss: 0.001203
 >> iter 89000, loss: 0.001182
 >> iter 90000, loss: 0.001167
   Number of active neurons: 10
 >> iter 91000, loss: 0.001147
 >> iter 92000, loss: 0.001132
 >> iter 93000, loss: 0.001114
 >> iter 94000, loss: 0.001100
 >> iter 95000, loss: 0.001082
 >> iter 96000, loss: 0.001069
 >> iter 97000, loss: 0.001053
 >> iter 98000, loss: 0.001040
 >> iter 99000, loss: 0.001024
 >> iter 100000, loss: 0.001012
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.611355
 >> iter 2000, loss: 15.088186
 >> iter 3000, loss: 13.752805
 >> iter 4000, loss: 13.257875
 >> iter 5000, loss: 13.061431
 >> iter 6000, loss: 12.993382
 >> iter 7000, loss: 12.958642
 >> iter 8000, loss: 12.954122
 >> iter 9000, loss: 12.942400
 >> iter 10000, loss: 12.949322
   Number of active neurons: 5
 >> iter 11000, loss: 12.938941
 >> iter 12000, loss: 12.945078
 >> iter 13000, loss: 12.934947
 >> iter 14000, loss: 12.924555
 >> iter 15000, loss: 12.218428
 >> iter 16000, loss: 4.769267
 >> iter 17000, loss: 1.799188
 >> iter 18000, loss: 0.688315
 >> iter 19000, loss: 0.387145
 >> iter 20000, loss: 0.159610
   Number of active neurons: 10
 >> iter 21000, loss: 0.071937
 >> iter 22000, loss: 0.037392
 >> iter 23000, loss: 0.022929
 >> iter 24000, loss: 0.016476
 >> iter 25000, loss: 0.013090
 >> iter 26000, loss: 0.011167
 >> iter 27000, loss: 0.009804
 >> iter 28000, loss: 0.008858
 >> iter 29000, loss: 0.008048
 >> iter 30000, loss: 0.007431
   Number of active neurons: 10
 >> iter 31000, loss: 0.006862
 >> iter 32000, loss: 0.006416
 >> iter 33000, loss: 0.005987
 >> iter 34000, loss: 0.005646
 >> iter 35000, loss: 0.005309
 >> iter 36000, loss: 0.005040
 >> iter 37000, loss: 0.004767
 >> iter 38000, loss: 0.004551
 >> iter 39000, loss: 0.004326
 >> iter 40000, loss: 0.004149
   Number of active neurons: 10
 >> iter 41000, loss: 0.003959
 >> iter 42000, loss: 0.003810
 >> iter 43000, loss: 0.003648
 >> iter 44000, loss: 0.003521
 >> iter 45000, loss: 0.003383
 >> iter 46000, loss: 0.003274
 >> iter 47000, loss: 0.003152
 >> iter 48000, loss: 0.003058
 >> iter 49000, loss: 0.002951
 >> iter 50000, loss: 0.002869
   Number of active neurons: 10
 >> iter 51000, loss: 0.002773
 >> iter 52000, loss: 0.002701
 >> iter 53000, loss: 0.002614
 >> iter 54000, loss: 0.002552
 >> iter 55000, loss: 0.002473
 >> iter 56000, loss: 0.002418
 >> iter 57000, loss: 0.002347
 >> iter 58000, loss: 0.002297
 >> iter 59000, loss: 0.002233
 >> iter 60000, loss: 0.002188
   Number of active neurons: 10
 >> iter 61000, loss: 0.002128
 >> iter 62000, loss: 0.002088
 >> iter 63000, loss: 0.002033
 >> iter 64000, loss: 0.001996
 >> iter 65000, loss: 0.001947
 >> iter 66000, loss: 0.001912
 >> iter 67000, loss: 0.001867
 >> iter 68000, loss: 0.001835
 >> iter 69000, loss: 0.001793
 >> iter 70000, loss: 0.001763
   Number of active neurons: 10
 >> iter 71000, loss: 0.001725
 >> iter 72000, loss: 0.001698
 >> iter 73000, loss: 0.001662
 >> iter 74000, loss: 0.001637
 >> iter 75000, loss: 0.001603
 >> iter 76000, loss: 0.001580
 >> iter 77000, loss: 0.001548
 >> iter 78000, loss: 0.001527
 >> iter 79000, loss: 0.001497
 >> iter 80000, loss: 0.001477
   Number of active neurons: 10
 >> iter 81000, loss: 0.001449
 >> iter 82000, loss: 0.001430
 >> iter 83000, loss: 0.001403
 >> iter 84000, loss: 0.001386
 >> iter 85000, loss: 0.001361
 >> iter 86000, loss: 0.001345
 >> iter 87000, loss: 0.001321
 >> iter 88000, loss: 0.001306
 >> iter 89000, loss: 0.001283
 >> iter 90000, loss: 0.001269
   Number of active neurons: 10
 >> iter 91000, loss: 0.001248
 >> iter 92000, loss: 0.001234
 >> iter 93000, loss: 0.001214
 >> iter 94000, loss: 0.001201
 >> iter 95000, loss: 0.001182
 >> iter 96000, loss: 0.001170
 >> iter 97000, loss: 0.001152
 >> iter 98000, loss: 0.001140
 >> iter 99000, loss: 0.001123
 >> iter 100000, loss: 0.001112
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0229997700023
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.632139
 >> iter 2000, loss: 15.125286
 >> iter 3000, loss: 13.785829
 >> iter 4000, loss: 13.283403
 >> iter 5000, loss: 13.073965
 >> iter 6000, loss: 12.999268
 >> iter 7000, loss: 12.955809
 >> iter 8000, loss: 12.947798
 >> iter 9000, loss: 12.931180
 >> iter 10000, loss: 12.935481
   Number of active neurons: 3
 >> iter 11000, loss: 12.920383
 >> iter 12000, loss: 12.491612
 >> iter 13000, loss: 5.423838
 >> iter 14000, loss: 2.050036
 >> iter 15000, loss: 0.784399
 >> iter 16000, loss: 0.309502
 >> iter 17000, loss: 0.129853
 >> iter 18000, loss: 0.060686
 >> iter 19000, loss: 0.033135
 >> iter 20000, loss: 0.021491
   Number of active neurons: 10
 >> iter 21000, loss: 0.016042
 >> iter 22000, loss: 0.013154
 >> iter 23000, loss: 0.011347
 >> iter 24000, loss: 0.010113
 >> iter 25000, loss: 0.009139
 >> iter 26000, loss: 0.008381
 >> iter 27000, loss: 0.007721
 >> iter 28000, loss: 0.007189
 >> iter 29000, loss: 0.006699
 >> iter 30000, loss: 0.006297
   Number of active neurons: 10
 >> iter 31000, loss: 0.005914
 >> iter 32000, loss: 0.005600
 >> iter 33000, loss: 0.005293
 >> iter 34000, loss: 0.005042
 >> iter 35000, loss: 0.004789
 >> iter 36000, loss: 0.004584
 >> iter 37000, loss: 0.004372
 >> iter 38000, loss: 0.004203
 >> iter 39000, loss: 0.004023
 >> iter 40000, loss: 0.003881
   Number of active neurons: 10
 >> iter 41000, loss: 0.003725
 >> iter 42000, loss: 0.003602
 >> iter 43000, loss: 0.003467
 >> iter 44000, loss: 0.003361
 >> iter 45000, loss: 0.003243
 >> iter 46000, loss: 0.003152
 >> iter 47000, loss: 0.003045
 >> iter 48000, loss: 0.002965
 >> iter 49000, loss: 0.002870
 >> iter 50000, loss: 0.002800
   Number of active neurons: 10
 >> iter 51000, loss: 0.002714
 >> iter 52000, loss: 0.002651
 >> iter 53000, loss: 0.002573
 >> iter 54000, loss: 0.002518
 >> iter 55000, loss: 0.002446
 >> iter 56000, loss: 0.002397
 >> iter 57000, loss: 0.002332
 >> iter 58000, loss: 0.002288
 >> iter 59000, loss: 0.002227
 >> iter 60000, loss: 0.002187
   Number of active neurons: 10
 >> iter 61000, loss: 0.002131
 >> iter 62000, loss: 0.002095
 >> iter 63000, loss: 0.002043
 >> iter 64000, loss: 0.002011
 >> iter 65000, loss: 0.001963
 >> iter 66000, loss: 0.001933
 >> iter 67000, loss: 0.001888
 >> iter 68000, loss: 0.001863
 >> iter 69000, loss: 0.001819
 >> iter 70000, loss: 0.001795
   Number of active neurons: 10
 >> iter 71000, loss: 0.001755
 >> iter 72000, loss: 0.001732
 >> iter 73000, loss: 0.001694
 >> iter 74000, loss: 0.001674
 >> iter 75000, loss: 0.001638
 >> iter 76000, loss: 0.001620
 >> iter 77000, loss: 0.001585
 >> iter 78000, loss: 0.001569
 >> iter 79000, loss: 0.001536
 >> iter 80000, loss: 0.001520
   Number of active neurons: 10
 >> iter 81000, loss: 0.001490
 >> iter 82000, loss: 0.001475
 >> iter 83000, loss: 0.001446
 >> iter 84000, loss: 0.001432
 >> iter 85000, loss: 0.001404
 >> iter 86000, loss: 0.001392
 >> iter 87000, loss: 0.001366
 >> iter 88000, loss: 0.001354
 >> iter 89000, loss: 0.001329
 >> iter 90000, loss: 0.001317
   Number of active neurons: 10
 >> iter 91000, loss: 0.001294
 >> iter 92000, loss: 0.001283
 >> iter 93000, loss: 0.001261
 >> iter 94000, loss: 0.001250
 >> iter 95000, loss: 0.001230
 >> iter 96000, loss: 0.001219
 >> iter 97000, loss: 0.001200
 >> iter 98000, loss: 0.001190
 >> iter 99000, loss: 0.001171
 >> iter 100000, loss: 0.001162
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.631741
 >> iter 2000, loss: 15.108253
 >> iter 3000, loss: 13.778404
 >> iter 4000, loss: 13.285896
 >> iter 5000, loss: 13.087094
 >> iter 6000, loss: 13.012856
 >> iter 7000, loss: 12.970157
 >> iter 8000, loss: 12.959799
 >> iter 9000, loss: 12.941374
 >> iter 10000, loss: 12.945388
   Number of active neurons: 4
 >> iter 11000, loss: 12.930933
 >> iter 12000, loss: 12.936547
 >> iter 13000, loss: 12.924081
 >> iter 14000, loss: 12.928857
 >> iter 15000, loss: 12.555006
 >> iter 16000, loss: 8.331532
 >> iter 17000, loss: 3.174181
 >> iter 18000, loss: 1.205238
 >> iter 19000, loss: 0.466971
 >> iter 20000, loss: 0.188989
   Number of active neurons: 10
 >> iter 21000, loss: 0.082941
 >> iter 22000, loss: 0.041534
 >> iter 23000, loss: 0.024550
 >> iter 24000, loss: 0.017077
 >> iter 25000, loss: 0.013321
 >> iter 26000, loss: 0.011201
 >> iter 27000, loss: 0.009771
 >> iter 28000, loss: 0.008759
 >> iter 29000, loss: 0.007935
 >> iter 30000, loss: 0.007282
   Number of active neurons: 10
 >> iter 31000, loss: 0.006711
 >> iter 32000, loss: 0.006240
 >> iter 33000, loss: 0.005815
 >> iter 34000, loss: 0.005456
 >> iter 35000, loss: 0.005126
 >> iter 36000, loss: 0.004844
 >> iter 37000, loss: 0.004579
 >> iter 38000, loss: 0.004351
 >> iter 39000, loss: 0.004136
 >> iter 40000, loss: 0.003949
   Number of active neurons: 10
 >> iter 41000, loss: 0.003769
 >> iter 42000, loss: 0.003611
 >> iter 43000, loss: 0.003459
 >> iter 44000, loss: 0.003325
 >> iter 45000, loss: 0.003196
 >> iter 46000, loss: 0.003081
 >> iter 47000, loss: 0.002968
 >> iter 48000, loss: 0.002868
 >> iter 49000, loss: 0.002770
 >> iter 50000, loss: 0.002683
   Number of active neurons: 10
 >> iter 51000, loss: 0.002596
 >> iter 52000, loss: 0.002519
 >> iter 53000, loss: 0.002440
 >> iter 54000, loss: 0.002373
 >> iter 55000, loss: 0.002302
 >> iter 56000, loss: 0.002243
 >> iter 57000, loss: 0.002179
 >> iter 58000, loss: 0.002126
 >> iter 59000, loss: 0.002068
 >> iter 60000, loss: 0.002021
   Number of active neurons: 10
 >> iter 61000, loss: 0.001968
 >> iter 62000, loss: 0.001924
 >> iter 63000, loss: 0.001875
 >> iter 64000, loss: 0.001837
 >> iter 65000, loss: 0.001792
 >> iter 66000, loss: 0.001757
 >> iter 67000, loss: 0.001716
 >> iter 68000, loss: 0.001683
 >> iter 69000, loss: 0.001646
 >> iter 70000, loss: 0.001614
   Number of active neurons: 10
 >> iter 71000, loss: 0.001580
 >> iter 72000, loss: 0.001551
 >> iter 73000, loss: 0.001519
 >> iter 74000, loss: 0.001493
 >> iter 75000, loss: 0.001463
 >> iter 76000, loss: 0.001439
 >> iter 77000, loss: 0.001411
 >> iter 78000, loss: 0.001389
 >> iter 79000, loss: 0.001363
 >> iter 80000, loss: 0.001341
   Number of active neurons: 10
 >> iter 81000, loss: 0.001317
 >> iter 82000, loss: 0.001297
 >> iter 83000, loss: 0.001274
 >> iter 84000, loss: 0.001256
 >> iter 85000, loss: 0.001234
 >> iter 86000, loss: 0.001217
 >> iter 87000, loss: 0.001197
 >> iter 88000, loss: 0.001180
 >> iter 89000, loss: 0.001161
 >> iter 90000, loss: 0.001145
   Number of active neurons: 10
 >> iter 91000, loss: 0.001128
 >> iter 92000, loss: 0.001112
 >> iter 93000, loss: 0.001096
 >> iter 94000, loss: 0.001081
 >> iter 95000, loss: 0.001066
 >> iter 96000, loss: 0.001052
 >> iter 97000, loss: 0.001038
 >> iter 98000, loss: 0.001024
 >> iter 99000, loss: 0.001011
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.634433
 >> iter 2000, loss: 15.068481
 >> iter 3000, loss: 13.725563
 >> iter 4000, loss: 13.233222
 >> iter 5000, loss: 13.036397
 >> iter 6000, loss: 12.969375
 >> iter 7000, loss: 12.933299
 >> iter 8000, loss: 12.926482
 >> iter 9000, loss: 12.741027
 >> iter 10000, loss: 6.130508
   Number of active neurons: 10
 >> iter 11000, loss: 2.320948
 >> iter 12000, loss: 0.887724
 >> iter 13000, loss: 0.350049
 >> iter 14000, loss: 0.146372
 >> iter 15000, loss: 0.068003
 >> iter 16000, loss: 0.036806
 >> iter 17000, loss: 0.023654
 >> iter 18000, loss: 0.017516
 >> iter 19000, loss: 0.014271
 >> iter 20000, loss: 0.012263
   Number of active neurons: 10
 >> iter 21000, loss: 0.010873
 >> iter 22000, loss: 0.009809
 >> iter 23000, loss: 0.008953
 >> iter 24000, loss: 0.008245
 >> iter 25000, loss: 0.007633
 >> iter 26000, loss: 0.007111
 >> iter 27000, loss: 0.006647
 >> iter 28000, loss: 0.006248
 >> iter 29000, loss: 0.005884
 >> iter 30000, loss: 0.005565
   Number of active neurons: 10
 >> iter 31000, loss: 0.005271
 >> iter 32000, loss: 0.005012
 >> iter 33000, loss: 0.004771
 >> iter 34000, loss: 0.004555
 >> iter 35000, loss: 0.004353
 >> iter 36000, loss: 0.004173
 >> iter 37000, loss: 0.004000
 >> iter 38000, loss: 0.003848
 >> iter 39000, loss: 0.003700
 >> iter 40000, loss: 0.003569
   Number of active neurons: 10
 >> iter 41000, loss: 0.003439
 >> iter 42000, loss: 0.003324
 >> iter 43000, loss: 0.003212
 >> iter 44000, loss: 0.003110
 >> iter 45000, loss: 0.003012
 >> iter 46000, loss: 0.002922
 >> iter 47000, loss: 0.002833
 >> iter 48000, loss: 0.002754
 >> iter 49000, loss: 0.002675
 >> iter 50000, loss: 0.002604
   Number of active neurons: 10
 >> iter 51000, loss: 0.002532
 >> iter 52000, loss: 0.002468
 >> iter 53000, loss: 0.002402
 >> iter 54000, loss: 0.002345
 >> iter 55000, loss: 0.002285
 >> iter 56000, loss: 0.002234
 >> iter 57000, loss: 0.002179
 >> iter 58000, loss: 0.002132
 >> iter 59000, loss: 0.002082
 >> iter 60000, loss: 0.002038
   Number of active neurons: 10
 >> iter 61000, loss: 0.001992
 >> iter 62000, loss: 0.001952
 >> iter 63000, loss: 0.001910
 >> iter 64000, loss: 0.001873
 >> iter 65000, loss: 0.001834
 >> iter 66000, loss: 0.001799
 >> iter 67000, loss: 0.001764
 >> iter 68000, loss: 0.001731
 >> iter 69000, loss: 0.001698
 >> iter 70000, loss: 0.001668
   Number of active neurons: 10
 >> iter 71000, loss: 0.001637
 >> iter 72000, loss: 0.001609
 >> iter 73000, loss: 0.001580
 >> iter 74000, loss: 0.001554
 >> iter 75000, loss: 0.001527
 >> iter 76000, loss: 0.001503
 >> iter 77000, loss: 0.001478
 >> iter 78000, loss: 0.001455
 >> iter 79000, loss: 0.001430
 >> iter 80000, loss: 0.001409
   Number of active neurons: 10
 >> iter 81000, loss: 0.001386
 >> iter 82000, loss: 0.001366
 >> iter 83000, loss: 0.001345
 >> iter 84000, loss: 0.001326
 >> iter 85000, loss: 0.001305
 >> iter 86000, loss: 0.001288
 >> iter 87000, loss: 0.001268
 >> iter 88000, loss: 0.001252
 >> iter 89000, loss: 0.001233
 >> iter 90000, loss: 0.001217
   Number of active neurons: 10
 >> iter 91000, loss: 0.001200
 >> iter 92000, loss: 0.001185
 >> iter 93000, loss: 0.001168
 >> iter 94000, loss: 0.001154
 >> iter 95000, loss: 0.001138
 >> iter 96000, loss: 0.001125
 >> iter 97000, loss: 0.001110
 >> iter 98000, loss: 0.001097
 >> iter 99000, loss: 0.001083
 >> iter 100000, loss: 0.001070
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.605288
 >> iter 2000, loss: 15.073601
 >> iter 3000, loss: 13.739085
 >> iter 4000, loss: 13.246604
 >> iter 5000, loss: 13.048428
 >> iter 6000, loss: 12.980834
 >> iter 7000, loss: 12.944183
 >> iter 8000, loss: 12.939786
 >> iter 9000, loss: 12.926589
 >> iter 10000, loss: 12.930376
   Number of active neurons: 4
 >> iter 11000, loss: 12.655870
 >> iter 12000, loss: 6.495871
 >> iter 13000, loss: 2.450203
 >> iter 14000, loss: 0.961263
 >> iter 15000, loss: 0.374401
 >> iter 16000, loss: 0.165384
 >> iter 17000, loss: 0.080926
 >> iter 18000, loss: 0.040262
 >> iter 19000, loss: 0.023376
 >> iter 20000, loss: 0.015934
   Number of active neurons: 10
 >> iter 21000, loss: 0.012243
 >> iter 22000, loss: 0.010207
 >> iter 23000, loss: 0.008863
 >> iter 24000, loss: 0.007938
 >> iter 25000, loss: 0.007184
 >> iter 26000, loss: 0.006606
 >> iter 27000, loss: 0.006088
 >> iter 28000, loss: 0.005679
 >> iter 29000, loss: 0.005293
 >> iter 30000, loss: 0.004983
   Number of active neurons: 10
 >> iter 31000, loss: 0.004681
 >> iter 32000, loss: 0.004438
 >> iter 33000, loss: 0.004196
 >> iter 34000, loss: 0.004000
 >> iter 35000, loss: 0.003800
 >> iter 36000, loss: 0.003641
 >> iter 37000, loss: 0.003472
 >> iter 38000, loss: 0.003339
 >> iter 39000, loss: 0.003196
 >> iter 40000, loss: 0.003085
   Number of active neurons: 10
 >> iter 41000, loss: 0.002960
 >> iter 42000, loss: 0.002864
 >> iter 43000, loss: 0.002755
 >> iter 44000, loss: 0.002672
 >> iter 45000, loss: 0.002577
 >> iter 46000, loss: 0.002505
 >> iter 47000, loss: 0.002420
 >> iter 48000, loss: 0.002356
 >> iter 49000, loss: 0.002281
 >> iter 50000, loss: 0.002225
   Number of active neurons: 10
 >> iter 51000, loss: 0.002156
 >> iter 52000, loss: 0.002106
 >> iter 53000, loss: 0.002043
 >> iter 54000, loss: 0.002000
 >> iter 55000, loss: 0.001942
 >> iter 56000, loss: 0.001903
 >> iter 57000, loss: 0.001850
 >> iter 58000, loss: 0.001815
 >> iter 59000, loss: 0.001766
 >> iter 60000, loss: 0.001735
   Number of active neurons: 10
 >> iter 61000, loss: 0.001690
 >> iter 62000, loss: 0.001661
 >> iter 63000, loss: 0.001619
 >> iter 64000, loss: 0.001592
 >> iter 65000, loss: 0.001554
 >> iter 66000, loss: 0.001530
 >> iter 67000, loss: 0.001494
 >> iter 68000, loss: 0.001472
 >> iter 69000, loss: 0.001438
 >> iter 70000, loss: 0.001418
   Number of active neurons: 10
 >> iter 71000, loss: 0.001387
 >> iter 72000, loss: 0.001368
 >> iter 73000, loss: 0.001338
 >> iter 74000, loss: 0.001321
 >> iter 75000, loss: 0.001293
 >> iter 76000, loss: 0.001277
 >> iter 77000, loss: 0.001251
 >> iter 78000, loss: 0.001236
 >> iter 79000, loss: 0.001211
 >> iter 80000, loss: 0.001198
   Number of active neurons: 10
 >> iter 81000, loss: 0.001174
 >> iter 82000, loss: 0.001161
 >> iter 83000, loss: 0.001138
 >> iter 84000, loss: 0.001127
 >> iter 85000, loss: 0.001105
 >> iter 86000, loss: 0.001095
 >> iter 87000, loss: 0.001074
 >> iter 88000, loss: 0.001064
 >> iter 89000, loss: 0.001044
 >> iter 90000, loss: 0.001035
   Number of active neurons: 10
 >> iter 91000, loss: 0.001016
 >> iter 92000, loss: 0.001007
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0029999700003
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.625658
 >> iter 2000, loss: 15.109899
 >> iter 3000, loss: 13.775204
 >> iter 4000, loss: 13.275693
 >> iter 5000, loss: 13.070515
 >> iter 6000, loss: 12.996810
 >> iter 7000, loss: 12.956330
 >> iter 8000, loss: 12.948858
 >> iter 9000, loss: 12.933931
 >> iter 10000, loss: 12.939347
   Number of active neurons: 4
 >> iter 11000, loss: 12.927289
 >> iter 12000, loss: 12.930693
 >> iter 13000, loss: 12.776294
 >> iter 14000, loss: 11.478762
 >> iter 15000, loss: 4.427809
 >> iter 16000, loss: 1.672312
 >> iter 17000, loss: 0.640835
 >> iter 18000, loss: 0.254007
 >> iter 19000, loss: 0.107434
 >> iter 20000, loss: 0.050907
   Number of active neurons: 10
 >> iter 21000, loss: 0.028198
 >> iter 22000, loss: 0.018553
 >> iter 23000, loss: 0.013916
 >> iter 24000, loss: 0.011460
 >> iter 25000, loss: 0.009853
 >> iter 26000, loss: 0.008775
 >> iter 27000, loss: 0.007888
 >> iter 28000, loss: 0.007229
 >> iter 29000, loss: 0.006623
 >> iter 30000, loss: 0.006158
   Number of active neurons: 10
 >> iter 31000, loss: 0.005703
 >> iter 32000, loss: 0.005356
 >> iter 33000, loss: 0.005003
 >> iter 34000, loss: 0.004735
 >> iter 35000, loss: 0.004451
 >> iter 36000, loss: 0.004238
 >> iter 37000, loss: 0.004004
 >> iter 38000, loss: 0.003832
 >> iter 39000, loss: 0.003636
 >> iter 40000, loss: 0.003496
   Number of active neurons: 10
 >> iter 41000, loss: 0.003329
 >> iter 42000, loss: 0.003210
 >> iter 43000, loss: 0.003067
 >> iter 44000, loss: 0.002966
 >> iter 45000, loss: 0.002841
 >> iter 46000, loss: 0.002756
 >> iter 47000, loss: 0.002645
 >> iter 48000, loss: 0.002571
 >> iter 49000, loss: 0.002474
 >> iter 50000, loss: 0.002410
   Number of active neurons: 10
 >> iter 51000, loss: 0.002322
 >> iter 52000, loss: 0.002266
 >> iter 53000, loss: 0.002186
 >> iter 54000, loss: 0.002138
 >> iter 55000, loss: 0.002065
 >> iter 56000, loss: 0.002023
 >> iter 57000, loss: 0.001958
 >> iter 58000, loss: 0.001919
 >> iter 59000, loss: 0.001860
 >> iter 60000, loss: 0.001825
   Number of active neurons: 10
 >> iter 61000, loss: 0.001771
 >> iter 62000, loss: 0.001739
 >> iter 63000, loss: 0.001689
 >> iter 64000, loss: 0.001661
 >> iter 65000, loss: 0.001614
 >> iter 66000, loss: 0.001589
 >> iter 67000, loss: 0.001547
 >> iter 68000, loss: 0.001522
 >> iter 69000, loss: 0.001484
 >> iter 70000, loss: 0.001461
   Number of active neurons: 10
 >> iter 71000, loss: 0.001426
 >> iter 72000, loss: 0.001404
 >> iter 73000, loss: 0.001371
 >> iter 74000, loss: 0.001352
 >> iter 75000, loss: 0.001320
 >> iter 76000, loss: 0.001304
 >> iter 77000, loss: 0.001274
 >> iter 78000, loss: 0.001258
 >> iter 79000, loss: 0.001230
 >> iter 80000, loss: 0.001215
   Number of active neurons: 10
 >> iter 81000, loss: 0.001189
 >> iter 82000, loss: 0.001175
 >> iter 83000, loss: 0.001150
 >> iter 84000, loss: 0.001137
 >> iter 85000, loss: 0.001114
 >> iter 86000, loss: 0.001102
 >> iter 87000, loss: 0.001080
 >> iter 88000, loss: 0.001069
 >> iter 89000, loss: 0.001048
 >> iter 90000, loss: 0.001038
   Number of active neurons: 10
 >> iter 91000, loss: 0.001018
 >> iter 92000, loss: 0.001008
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.637018
 >> iter 2000, loss: 15.076986
 >> iter 3000, loss: 13.737775
 >> iter 4000, loss: 13.245214
 >> iter 5000, loss: 13.051078
 >> iter 6000, loss: 12.983413
 >> iter 7000, loss: 12.948797
 >> iter 8000, loss: 12.942960
 >> iter 9000, loss: 12.931188
 >> iter 10000, loss: 12.936269
   Number of active neurons: 4
 >> iter 11000, loss: 12.925295
 >> iter 12000, loss: 12.837537
 >> iter 13000, loss: 10.144342
 >> iter 14000, loss: 3.893557
 >> iter 15000, loss: 1.475628
 >> iter 16000, loss: 0.568991
 >> iter 17000, loss: 0.228099
 >> iter 18000, loss: 0.098492
 >> iter 19000, loss: 0.048136
 >> iter 20000, loss: 0.027723
   Number of active neurons: 9
 >> iter 21000, loss: 0.018838
 >> iter 22000, loss: 0.014512
 >> iter 23000, loss: 0.012088
 >> iter 24000, loss: 0.010526
 >> iter 25000, loss: 0.009393
 >> iter 26000, loss: 0.008515
 >> iter 27000, loss: 0.007794
 >> iter 28000, loss: 0.007195
 >> iter 29000, loss: 0.006675
 >> iter 30000, loss: 0.006229
   Number of active neurons: 10
 >> iter 31000, loss: 0.005835
 >> iter 32000, loss: 0.005488
 >> iter 33000, loss: 0.005179
 >> iter 34000, loss: 0.004902
 >> iter 35000, loss: 0.004650
 >> iter 36000, loss: 0.004426
 >> iter 37000, loss: 0.004219
 >> iter 38000, loss: 0.004032
 >> iter 39000, loss: 0.003858
 >> iter 40000, loss: 0.003702
   Number of active neurons: 10
 >> iter 41000, loss: 0.003553
 >> iter 42000, loss: 0.003420
 >> iter 43000, loss: 0.003291
 >> iter 44000, loss: 0.003177
 >> iter 45000, loss: 0.003065
 >> iter 46000, loss: 0.002965
 >> iter 47000, loss: 0.002867
 >> iter 48000, loss: 0.002779
 >> iter 49000, loss: 0.002692
 >> iter 50000, loss: 0.002615
   Number of active neurons: 10
 >> iter 51000, loss: 0.002536
 >> iter 52000, loss: 0.002468
 >> iter 53000, loss: 0.002396
 >> iter 54000, loss: 0.002337
 >> iter 55000, loss: 0.002271
 >> iter 56000, loss: 0.002218
 >> iter 57000, loss: 0.002159
 >> iter 58000, loss: 0.002111
 >> iter 59000, loss: 0.002056
 >> iter 60000, loss: 0.002013
   Number of active neurons: 10
 >> iter 61000, loss: 0.001963
 >> iter 62000, loss: 0.001924
 >> iter 63000, loss: 0.001877
 >> iter 64000, loss: 0.001843
 >> iter 65000, loss: 0.001799
 >> iter 66000, loss: 0.001767
 >> iter 67000, loss: 0.001726
 >> iter 68000, loss: 0.001697
 >> iter 69000, loss: 0.001659
 >> iter 70000, loss: 0.001632
   Number of active neurons: 10
 >> iter 71000, loss: 0.001597
 >> iter 72000, loss: 0.001572
 >> iter 73000, loss: 0.001540
 >> iter 74000, loss: 0.001517
 >> iter 75000, loss: 0.001486
 >> iter 76000, loss: 0.001465
 >> iter 77000, loss: 0.001436
 >> iter 78000, loss: 0.001416
 >> iter 79000, loss: 0.001388
 >> iter 80000, loss: 0.001370
   Number of active neurons: 10
 >> iter 81000, loss: 0.001344
 >> iter 82000, loss: 0.001328
 >> iter 83000, loss: 0.001302
 >> iter 84000, loss: 0.001287
 >> iter 85000, loss: 0.001263
 >> iter 86000, loss: 0.001249
 >> iter 87000, loss: 0.001226
 >> iter 88000, loss: 0.001213
 >> iter 89000, loss: 0.001191
 >> iter 90000, loss: 0.001179
   Number of active neurons: 10
 >> iter 91000, loss: 0.001158
 >> iter 92000, loss: 0.001147
 >> iter 93000, loss: 0.001127
 >> iter 94000, loss: 0.001116
 >> iter 95000, loss: 0.001098
 >> iter 96000, loss: 0.001087
 >> iter 97000, loss: 0.001070
 >> iter 98000, loss: 0.001060
 >> iter 99000, loss: 0.001043
 >> iter 100000, loss: 0.001033
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.645819
 >> iter 2000, loss: 15.110416
 >> iter 3000, loss: 13.770130
 >> iter 4000, loss: 13.272346
 >> iter 5000, loss: 13.074659
 >> iter 6000, loss: 13.005521
 >> iter 7000, loss: 12.970637
 >> iter 8000, loss: 12.965417
 >> iter 9000, loss: 12.953724
 >> iter 10000, loss: 12.959270
   Number of active neurons: 6
 >> iter 11000, loss: 12.948138
 >> iter 12000, loss: 12.884117
 >> iter 13000, loss: 12.015555
 >> iter 14000, loss: 10.544509
 >> iter 15000, loss: 8.867917
 >> iter 16000, loss: 5.291800
 >> iter 17000, loss: 2.459721
 >> iter 18000, loss: 0.961594
 >> iter 19000, loss: 0.471484
 >> iter 20000, loss: 0.198501
   Number of active neurons: 10
 >> iter 21000, loss: 0.767781
 >> iter 22000, loss: 6.799538
 >> iter 23000, loss: 8.365753
 >> iter 24000, loss: 5.758666
 >> iter 25000, loss: 2.198154
 >> iter 26000, loss: 0.874941
 >> iter 27000, loss: 0.382471
 >> iter 28000, loss: 0.159399
 >> iter 29000, loss: 0.073083
 >> iter 30000, loss: 0.038667
   Number of active neurons: 10
 >> iter 31000, loss: 0.023897
 >> iter 32000, loss: 0.017135
 >> iter 33000, loss: 0.013711
 >> iter 34000, loss: 0.011723
 >> iter 35000, loss: 0.010259
 >> iter 36000, loss: 0.009614
 >> iter 37000, loss: 0.014574
 >> iter 38000, loss: 0.010872
 >> iter 39000, loss: 0.008871
 >> iter 40000, loss: 0.007647
   Number of active neurons: 10
 >> iter 41000, loss: 0.006899
 >> iter 42000, loss: 0.006309
 >> iter 43000, loss: 0.005891
 >> iter 44000, loss: 0.005501
 >> iter 45000, loss: 0.005206
 >> iter 46000, loss: 0.004914
 >> iter 47000, loss: 0.004677
 >> iter 48000, loss: 0.004446
 >> iter 49000, loss: 0.004250
 >> iter 50000, loss: 0.004065
   Number of active neurons: 10
 >> iter 51000, loss: 0.003899
 >> iter 52000, loss: 0.003745
 >> iter 53000, loss: 0.003603
 >> iter 54000, loss: 0.003475
 >> iter 55000, loss: 0.003352
 >> iter 56000, loss: 0.003245
 >> iter 57000, loss: 0.003137
 >> iter 58000, loss: 0.003043
 >> iter 59000, loss: 0.002948
 >> iter 60000, loss: 0.002866
   Number of active neurons: 10
 >> iter 61000, loss: 0.002781
 >> iter 62000, loss: 0.002708
 >> iter 63000, loss: 0.002632
 >> iter 64000, loss: 0.002569
 >> iter 65000, loss: 0.002499
 >> iter 66000, loss: 0.002442
 >> iter 67000, loss: 0.002379
 >> iter 68000, loss: 0.002332
 >> iter 69000, loss: 0.002270
 >> iter 70000, loss: 0.002227
   Number of active neurons: 10
 >> iter 71000, loss: 0.002171
 >> iter 72000, loss: 0.002132
 >> iter 73000, loss: 0.002079
 >> iter 74000, loss: 0.002045
 >> iter 75000, loss: 0.001995
 >> iter 76000, loss: 0.001965
 >> iter 77000, loss: 0.001919
 >> iter 78000, loss: 0.001890
 >> iter 79000, loss: 0.001847
 >> iter 80000, loss: 0.001822
   Number of active neurons: 10
 >> iter 81000, loss: 0.001781
 >> iter 82000, loss: 0.001757
 >> iter 83000, loss: 0.001719
 >> iter 84000, loss: 0.001698
 >> iter 85000, loss: 0.001662
 >> iter 86000, loss: 0.001642
 >> iter 87000, loss: 0.001608
 >> iter 88000, loss: 0.001590
 >> iter 89000, loss: 0.001557
 >> iter 90000, loss: 0.001541
   Number of active neurons: 10
 >> iter 91000, loss: 0.001510
 >> iter 92000, loss: 0.001495
 >> iter 93000, loss: 0.001466
 >> iter 94000, loss: 0.001452
 >> iter 95000, loss: 0.001424
 >> iter 96000, loss: 0.001411
 >> iter 97000, loss: 0.001385
 >> iter 98000, loss: 0.001372
 >> iter 99000, loss: 0.001347
 >> iter 100000, loss: 0.001335
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

