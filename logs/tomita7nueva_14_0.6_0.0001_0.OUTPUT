 > Problema: tomita7nueva
 > Args:
   - Hidden size: 14
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.106045
 >> iter 2000, loss: 10.135326
 >> iter 3000, loss: 6.919329
 >> iter 4000, loss: 4.834110
 >> iter 5000, loss: 2.944916
 >> iter 6000, loss: 1.650523
 >> iter 7000, loss: 1.104410
 >> iter 8000, loss: 0.893874
 >> iter 9000, loss: 0.833234
 >> iter 10000, loss: 0.541658
   Number of active neurons: 9
 >> iter 11000, loss: 0.586897
 >> iter 12000, loss: 0.559455
 >> iter 13000, loss: 0.584380
 >> iter 14000, loss: 0.422757
 >> iter 15000, loss: 0.427925
 >> iter 16000, loss: 0.391517
 >> iter 17000, loss: 0.306157
 >> iter 18000, loss: 0.253627
 >> iter 19000, loss: 0.368753
 >> iter 20000, loss: 0.379932
   Number of active neurons: 7
 >> iter 21000, loss: 0.350394
 >> iter 22000, loss: 0.441993
 >> iter 23000, loss: 0.267239
 >> iter 24000, loss: 0.250501
 >> iter 25000, loss: 0.206620
 >> iter 26000, loss: 0.303173
 >> iter 27000, loss: 0.339077
 >> iter 28000, loss: 0.299957
 >> iter 29000, loss: 0.335742
 >> iter 30000, loss: 0.367185
   Number of active neurons: 7
 >> iter 31000, loss: 0.297512
 >> iter 32000, loss: 0.285500
 >> iter 33000, loss: 0.288118
 >> iter 34000, loss: 0.299316
 >> iter 35000, loss: 0.290547
 >> iter 36000, loss: 0.369499
 >> iter 37000, loss: 0.273287
 >> iter 38000, loss: 0.167108
 >> iter 39000, loss: 0.260392
 >> iter 40000, loss: 0.288064
   Number of active neurons: 5
 >> iter 41000, loss: 0.373838
 >> iter 42000, loss: 0.322018
 >> iter 43000, loss: 0.336059
 >> iter 44000, loss: 0.313872
 >> iter 45000, loss: 0.283802
 >> iter 46000, loss: 0.271079
 >> iter 47000, loss: 0.249808
 >> iter 48000, loss: 0.286150
 >> iter 49000, loss: 0.290254
 >> iter 50000, loss: 0.270516
   Number of active neurons: 5
 >> iter 51000, loss: 0.251864
 >> iter 52000, loss: 0.287830
 >> iter 53000, loss: 0.305888
 >> iter 54000, loss: 0.337515
 >> iter 55000, loss: 0.217679
 >> iter 56000, loss: 0.251802
 >> iter 57000, loss: 0.392494
 >> iter 58000, loss: 0.370319
 >> iter 59000, loss: 0.307877
 >> iter 60000, loss: 0.329500
   Number of active neurons: 5
 >> iter 61000, loss: 0.456361
 >> iter 62000, loss: 0.411904
 >> iter 63000, loss: 0.359122
 >> iter 64000, loss: 0.355360
 >> iter 65000, loss: 0.272630
 >> iter 66000, loss: 0.292069
 >> iter 67000, loss: 0.406196
 >> iter 68000, loss: 0.439426
 >> iter 69000, loss: 0.366669
 >> iter 70000, loss: 0.356734
   Number of active neurons: 5
 >> iter 71000, loss: 0.304862
 >> iter 72000, loss: 0.449471
 >> iter 73000, loss: 0.345557
 >> iter 74000, loss: 0.511192
 >> iter 75000, loss: 0.408275
 >> iter 76000, loss: 0.379983
 >> iter 77000, loss: 0.365887
 >> iter 78000, loss: 0.430073
 >> iter 79000, loss: 0.310296
 >> iter 80000, loss: 0.251366
   Number of active neurons: 5
 >> iter 81000, loss: 0.224995
 >> iter 82000, loss: 0.263450
 >> iter 83000, loss: 0.333540
 >> iter 84000, loss: 0.376521
 >> iter 85000, loss: 0.380854
 >> iter 86000, loss: 0.349703
 >> iter 87000, loss: 0.197428
 >> iter 88000, loss: 0.339097
 >> iter 89000, loss: 0.393824
 >> iter 90000, loss: 0.279904
   Number of active neurons: 5
 >> iter 91000, loss: 0.237419
 >> iter 92000, loss: 0.212319
 >> iter 93000, loss: 0.299838
 >> iter 94000, loss: 0.292183
 >> iter 95000, loss: 0.251138
 >> iter 96000, loss: 0.459360
 >> iter 97000, loss: 0.301006
 >> iter 98000, loss: 0.324502
 >> iter 99000, loss: 0.302751
 >> iter 100000, loss: 0.350648
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.865559
 >> iter 2000, loss: 10.280221
 >> iter 3000, loss: 6.076405
 >> iter 4000, loss: 2.922287
 >> iter 5000, loss: 1.372246
 >> iter 6000, loss: 0.742269
 >> iter 7000, loss: 0.480325
 >> iter 8000, loss: 0.446566
 >> iter 9000, loss: 0.370287
 >> iter 10000, loss: 0.396389
   Number of active neurons: 12
 >> iter 11000, loss: 0.291988
 >> iter 12000, loss: 0.232447
 >> iter 13000, loss: 0.371463
 >> iter 14000, loss: 0.367930
 >> iter 15000, loss: 0.331614
 >> iter 16000, loss: 0.259789
 >> iter 17000, loss: 0.211178
 >> iter 18000, loss: 0.467358
 >> iter 19000, loss: 0.356178
 >> iter 20000, loss: 0.359770
   Number of active neurons: 11
 >> iter 21000, loss: 0.408005
 >> iter 22000, loss: 0.294493
 >> iter 23000, loss: 0.352603
 >> iter 24000, loss: 0.284217
 >> iter 25000, loss: 0.329577
 >> iter 26000, loss: 0.330980
 >> iter 27000, loss: 0.237083
 >> iter 28000, loss: 0.255135
 >> iter 29000, loss: 0.242976
 >> iter 30000, loss: 0.278594
   Number of active neurons: 11
 >> iter 31000, loss: 0.408040
 >> iter 32000, loss: 0.357686
 >> iter 33000, loss: 0.242463
 >> iter 34000, loss: 0.241436
 >> iter 35000, loss: 0.339643
 >> iter 36000, loss: 0.328500
 >> iter 37000, loss: 0.367859
 >> iter 38000, loss: 0.384243
 >> iter 39000, loss: 0.476273
 >> iter 40000, loss: 0.382891
   Number of active neurons: 11
 >> iter 41000, loss: 0.316967
 >> iter 42000, loss: 0.226285
 >> iter 43000, loss: 0.325588
 >> iter 44000, loss: 0.217139
 >> iter 45000, loss: 0.230969
 >> iter 46000, loss: 0.426350
 >> iter 47000, loss: 0.349859
 >> iter 48000, loss: 0.272853
 >> iter 49000, loss: 0.309156
 >> iter 50000, loss: 0.281745
   Number of active neurons: 11
 >> iter 51000, loss: 0.211408
 >> iter 52000, loss: 0.268223
 >> iter 53000, loss: 0.336151
 >> iter 54000, loss: 0.329044
 >> iter 55000, loss: 0.293128
 >> iter 56000, loss: 0.326641
 >> iter 57000, loss: 0.366788
 >> iter 58000, loss: 0.360803
 >> iter 59000, loss: 0.436327
 >> iter 60000, loss: 0.320347
   Number of active neurons: 10
 >> iter 61000, loss: 0.258285
 >> iter 62000, loss: 0.250266
 >> iter 63000, loss: 0.264785
 >> iter 64000, loss: 0.363245
 >> iter 65000, loss: 0.340737
 >> iter 66000, loss: 0.220426
 >> iter 67000, loss: 0.321183
 >> iter 68000, loss: 0.251492
 >> iter 69000, loss: 0.276409
 >> iter 70000, loss: 0.211042
   Number of active neurons: 9
 >> iter 71000, loss: 0.337636
 >> iter 72000, loss: 0.365732
 >> iter 73000, loss: 0.263797
 >> iter 74000, loss: 0.196013
 >> iter 75000, loss: 0.256771
 >> iter 76000, loss: 0.240340
 >> iter 77000, loss: 0.257308
 >> iter 78000, loss: 0.293356
 >> iter 79000, loss: 0.269135
 >> iter 80000, loss: 0.292829
   Number of active neurons: 8
 >> iter 81000, loss: 0.486592
 >> iter 82000, loss: 0.403806
 >> iter 83000, loss: 0.337681
 >> iter 84000, loss: 0.382770
 >> iter 85000, loss: 0.342385
 >> iter 86000, loss: 0.234976
 >> iter 87000, loss: 0.345085
 >> iter 88000, loss: 0.371452
 >> iter 89000, loss: 0.363362
 >> iter 90000, loss: 0.300820
   Number of active neurons: 7
 >> iter 91000, loss: 0.301051
 >> iter 92000, loss: 0.234888
 >> iter 93000, loss: 0.354605
 >> iter 94000, loss: 0.277171
 >> iter 95000, loss: 0.308749
 >> iter 96000, loss: 0.265613
 >> iter 97000, loss: 0.332384
 >> iter 98000, loss: 0.285510
 >> iter 99000, loss: 0.320154
 >> iter 100000, loss: 0.305470
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.725520
 >> iter 2000, loss: 10.052872
 >> iter 3000, loss: 5.037613
 >> iter 4000, loss: 2.361744
 >> iter 5000, loss: 1.152423
 >> iter 6000, loss: 0.671358
 >> iter 7000, loss: 0.500615
 >> iter 8000, loss: 0.368970
 >> iter 9000, loss: 0.331859
 >> iter 10000, loss: 0.223788
   Number of active neurons: 6
 >> iter 11000, loss: 0.255964
 >> iter 12000, loss: 0.352647
 >> iter 13000, loss: 0.340814
 >> iter 14000, loss: 0.349067
 >> iter 15000, loss: 0.280274
 >> iter 16000, loss: 0.229208
 >> iter 17000, loss: 0.207745
 >> iter 18000, loss: 0.212417
 >> iter 19000, loss: 0.280203
 >> iter 20000, loss: 0.391937
   Number of active neurons: 6
 >> iter 21000, loss: 0.258262
 >> iter 22000, loss: 0.254317
 >> iter 23000, loss: 0.274200
 >> iter 24000, loss: 0.264514
 >> iter 25000, loss: 0.399321
 >> iter 26000, loss: 0.304345
 >> iter 27000, loss: 0.354068
 >> iter 28000, loss: 0.232973
 >> iter 29000, loss: 0.264155
 >> iter 30000, loss: 0.225625
   Number of active neurons: 6
 >> iter 31000, loss: 0.264802
 >> iter 32000, loss: 0.167794
 >> iter 33000, loss: 0.370678
 >> iter 34000, loss: 0.313120
 >> iter 35000, loss: 0.211155
 >> iter 36000, loss: 0.147015
 >> iter 37000, loss: 0.197550
 >> iter 38000, loss: 0.214861
 >> iter 39000, loss: 0.279176
 >> iter 40000, loss: 0.293932
   Number of active neurons: 5
 >> iter 41000, loss: 0.229180
 >> iter 42000, loss: 0.168356
 >> iter 43000, loss: 0.243272
 >> iter 44000, loss: 0.267962
 >> iter 45000, loss: 0.177679
 >> iter 46000, loss: 0.199158
 >> iter 47000, loss: 0.168629
 >> iter 48000, loss: 0.148029
 >> iter 49000, loss: 0.194730
 >> iter 50000, loss: 0.183707
   Number of active neurons: 5
 >> iter 51000, loss: 0.276113
 >> iter 52000, loss: 0.238207
 >> iter 53000, loss: 0.198779
 >> iter 54000, loss: 0.151141
 >> iter 55000, loss: 0.206289
 >> iter 56000, loss: 0.199530
 >> iter 57000, loss: 0.238773
 >> iter 58000, loss: 0.195254
 >> iter 59000, loss: 0.192935
 >> iter 60000, loss: 0.163437
   Number of active neurons: 5
 >> iter 61000, loss: 0.217310
 >> iter 62000, loss: 0.185439
 >> iter 63000, loss: 0.237781
 >> iter 64000, loss: 0.204009
 >> iter 65000, loss: 0.266206
 >> iter 66000, loss: 0.203323
 >> iter 67000, loss: 0.265015
 >> iter 68000, loss: 0.174350
 >> iter 69000, loss: 0.194968
 >> iter 70000, loss: 0.197040
   Number of active neurons: 5
 >> iter 71000, loss: 0.185423
 >> iter 72000, loss: 0.204371
 >> iter 73000, loss: 0.158661
 >> iter 74000, loss: 0.191303
 >> iter 75000, loss: 0.223650
 >> iter 76000, loss: 0.212900
 >> iter 77000, loss: 0.194532
 >> iter 78000, loss: 0.182087
 >> iter 79000, loss: 0.120964
 >> iter 80000, loss: 0.195755
   Number of active neurons: 5
 >> iter 81000, loss: 0.207264
 >> iter 82000, loss: 0.302000
 >> iter 83000, loss: 0.286753
 >> iter 84000, loss: 0.216754
 >> iter 85000, loss: 0.222184
 >> iter 86000, loss: 0.141508
 >> iter 87000, loss: 0.242204
 >> iter 88000, loss: 0.217452
 >> iter 89000, loss: 0.191886
 >> iter 90000, loss: 0.226357
   Number of active neurons: 5
 >> iter 91000, loss: 0.185095
 >> iter 92000, loss: 0.214759
 >> iter 93000, loss: 0.245061
 >> iter 94000, loss: 0.185977
 >> iter 95000, loss: 0.224529
 >> iter 96000, loss: 0.212787
 >> iter 97000, loss: 0.358116
 >> iter 98000, loss: 0.290263
 >> iter 99000, loss: 0.273869
 >> iter 100000, loss: 0.268316
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.017623
 >> iter 2000, loss: 9.639618
 >> iter 3000, loss: 5.179748
 >> iter 4000, loss: 2.801855
 >> iter 5000, loss: 1.654511
 >> iter 6000, loss: 0.991934
 >> iter 7000, loss: 0.843138
 >> iter 8000, loss: 0.632920
 >> iter 9000, loss: 0.563186
 >> iter 10000, loss: 0.551121
   Number of active neurons: 8
 >> iter 11000, loss: 0.487335
 >> iter 12000, loss: 0.473455
 >> iter 13000, loss: 0.433560
 >> iter 14000, loss: 0.448945
 >> iter 15000, loss: 0.310475
 >> iter 16000, loss: 0.337666
 >> iter 17000, loss: 0.411076
 >> iter 18000, loss: 0.559150
 >> iter 19000, loss: 0.493552
 >> iter 20000, loss: 0.537106
   Number of active neurons: 9
 >> iter 21000, loss: 0.480717
 >> iter 22000, loss: 0.337675
 >> iter 23000, loss: 0.429545
 >> iter 24000, loss: 0.376441
 >> iter 25000, loss: 0.362347
 >> iter 26000, loss: 0.435042
 >> iter 27000, loss: 0.468261
 >> iter 28000, loss: 0.448039
 >> iter 29000, loss: 0.416542
 >> iter 30000, loss: 0.541646
   Number of active neurons: 8
 >> iter 31000, loss: 0.503780
 >> iter 32000, loss: 0.461911
 >> iter 33000, loss: 0.422526
 >> iter 34000, loss: 0.359769
 >> iter 35000, loss: 0.430991
 >> iter 36000, loss: 0.329059
 >> iter 37000, loss: 0.340114
 >> iter 38000, loss: 0.332938
 >> iter 39000, loss: 0.445654
 >> iter 40000, loss: 0.424683
   Number of active neurons: 6
 >> iter 41000, loss: 0.543587
 >> iter 42000, loss: 0.483512
 >> iter 43000, loss: 0.358279
 >> iter 44000, loss: 0.300759
 >> iter 45000, loss: 0.404612
 >> iter 46000, loss: 0.388481
 >> iter 47000, loss: 0.406334
 >> iter 48000, loss: 0.390265
 >> iter 49000, loss: 0.445179
 >> iter 50000, loss: 0.613130
   Number of active neurons: 6
 >> iter 51000, loss: 0.539334
 >> iter 52000, loss: 0.619348
 >> iter 53000, loss: 0.454214
 >> iter 54000, loss: 0.676278
 >> iter 55000, loss: 0.578601
 >> iter 56000, loss: 0.579459
 >> iter 57000, loss: 0.546143
 >> iter 58000, loss: 0.658098
 >> iter 59000, loss: 0.550946
 >> iter 60000, loss: 0.711685
   Number of active neurons: 6
 >> iter 61000, loss: 0.505508
 >> iter 62000, loss: 0.502848
 >> iter 63000, loss: 0.564910
 >> iter 64000, loss: 0.488543
 >> iter 65000, loss: 0.500802
 >> iter 66000, loss: 0.538771
 >> iter 67000, loss: 0.489297
 >> iter 68000, loss: 0.551466
 >> iter 69000, loss: 0.452129
 >> iter 70000, loss: 0.553868
   Number of active neurons: 6
 >> iter 71000, loss: 0.612890
 >> iter 72000, loss: 0.467244
 >> iter 73000, loss: 0.438920
 >> iter 74000, loss: 0.491366
 >> iter 75000, loss: 0.642969
 >> iter 76000, loss: 0.660743
 >> iter 77000, loss: 0.558412
 >> iter 78000, loss: 0.675534
 >> iter 79000, loss: 0.691764
 >> iter 80000, loss: 0.593689
   Number of active neurons: 5
 >> iter 81000, loss: 0.455043
 >> iter 82000, loss: 0.398245
 >> iter 83000, loss: 0.435097
 >> iter 84000, loss: 0.552497
 >> iter 85000, loss: 0.530253
 >> iter 86000, loss: 0.469026
 >> iter 87000, loss: 0.471539
 >> iter 88000, loss: 0.486739
 >> iter 89000, loss: 0.599061
 >> iter 90000, loss: 0.559542
   Number of active neurons: 5
 >> iter 91000, loss: 0.748585
 >> iter 92000, loss: 0.707073
 >> iter 93000, loss: 0.658026
 >> iter 94000, loss: 0.569580
 >> iter 95000, loss: 0.491881
 >> iter 96000, loss: 0.500822
 >> iter 97000, loss: 0.433788
 >> iter 98000, loss: 0.565009
 >> iter 99000, loss: 0.560374
 >> iter 100000, loss: 0.533434
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.437600
 >> iter 2000, loss: 9.752650
 >> iter 3000, loss: 6.069316
 >> iter 4000, loss: 3.286030
 >> iter 5000, loss: 2.376475
 >> iter 6000, loss: 1.793084
 >> iter 7000, loss: 1.224548
 >> iter 8000, loss: 1.019563
 >> iter 9000, loss: 0.915666
 >> iter 10000, loss: 0.671677
   Number of active neurons: 8
 >> iter 11000, loss: 0.581225
 >> iter 12000, loss: 0.550360
 >> iter 13000, loss: 0.665718
 >> iter 14000, loss: 0.598476
 >> iter 15000, loss: 0.419019
 >> iter 16000, loss: 0.442825
 >> iter 17000, loss: 0.445096
 >> iter 18000, loss: 0.486776
 >> iter 19000, loss: 0.427927
 >> iter 20000, loss: 0.559474
   Number of active neurons: 8
 >> iter 21000, loss: 0.504573
 >> iter 22000, loss: 0.554664
 >> iter 23000, loss: 0.448379
 >> iter 24000, loss: 0.527479
 >> iter 25000, loss: 0.542199
 >> iter 26000, loss: 0.646465
 >> iter 27000, loss: 0.618496
 >> iter 28000, loss: 0.740628
 >> iter 29000, loss: 0.554777
 >> iter 30000, loss: 0.363378
   Number of active neurons: 7
 >> iter 31000, loss: 0.548305
 >> iter 32000, loss: 0.553080
 >> iter 33000, loss: 0.486501
 >> iter 34000, loss: 0.566019
 >> iter 35000, loss: 0.486511
 >> iter 36000, loss: 0.519051
 >> iter 37000, loss: 0.336769
 >> iter 38000, loss: 0.428882
 >> iter 39000, loss: 0.407225
 >> iter 40000, loss: 0.451234
   Number of active neurons: 6
 >> iter 41000, loss: 0.504588
 >> iter 42000, loss: 0.526919
 >> iter 43000, loss: 0.586506
 >> iter 44000, loss: 0.504217
 >> iter 45000, loss: 0.647495
 >> iter 46000, loss: 0.543063
 >> iter 47000, loss: 0.634875
 >> iter 48000, loss: 0.593002
 >> iter 49000, loss: 0.520915
 >> iter 50000, loss: 0.588560
   Number of active neurons: 6
 >> iter 51000, loss: 0.573041
 >> iter 52000, loss: 0.478219
 >> iter 53000, loss: 0.638492
 >> iter 54000, loss: 0.651856
 >> iter 55000, loss: 0.646388
 >> iter 56000, loss: 0.573624
 >> iter 57000, loss: 0.568814
 >> iter 58000, loss: 0.593842
 >> iter 59000, loss: 0.509675
 >> iter 60000, loss: 0.593500
   Number of active neurons: 6
 >> iter 61000, loss: 0.624346
 >> iter 62000, loss: 0.669863
 >> iter 63000, loss: 0.696616
 >> iter 64000, loss: 0.621088
 >> iter 65000, loss: 0.554340
 >> iter 66000, loss: 0.583178
 >> iter 67000, loss: 0.566349
 >> iter 68000, loss: 0.556512
 >> iter 69000, loss: 0.509708
 >> iter 70000, loss: 0.512682
   Number of active neurons: 6
 >> iter 71000, loss: 0.335569
 >> iter 72000, loss: 0.573131
 >> iter 73000, loss: 0.646603
 >> iter 74000, loss: 0.591168
 >> iter 75000, loss: 0.641884
 >> iter 76000, loss: 0.517369
 >> iter 77000, loss: 0.575075
 >> iter 78000, loss: 0.532944
 >> iter 79000, loss: 0.451321
 >> iter 80000, loss: 0.400631
   Number of active neurons: 6
 >> iter 81000, loss: 0.400452
 >> iter 82000, loss: 0.336083
 >> iter 83000, loss: 0.406139
 >> iter 84000, loss: 0.562115
 >> iter 85000, loss: 0.671637
 >> iter 86000, loss: 0.598348
 >> iter 87000, loss: 0.482929
 >> iter 88000, loss: 0.445572
 >> iter 89000, loss: 0.531124
 >> iter 90000, loss: 0.453889
   Number of active neurons: 6
 >> iter 91000, loss: 0.427670
 >> iter 92000, loss: 0.351782
 >> iter 93000, loss: 0.319565
 >> iter 94000, loss: 0.325410
 >> iter 95000, loss: 0.366262
 >> iter 96000, loss: 0.325369
 >> iter 97000, loss: 0.494212
 >> iter 98000, loss: 0.450367
 >> iter 99000, loss: 0.463285
 >> iter 100000, loss: 0.630555
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.863470
 >> iter 2000, loss: 9.752362
 >> iter 3000, loss: 6.363692
 >> iter 4000, loss: 3.853471
 >> iter 5000, loss: 2.392393
 >> iter 6000, loss: 1.558584
 >> iter 7000, loss: 1.121861
 >> iter 8000, loss: 0.889389
 >> iter 9000, loss: 0.842338
 >> iter 10000, loss: 0.571540
   Number of active neurons: 7
 >> iter 11000, loss: 0.920579
 >> iter 12000, loss: 0.692980
 >> iter 13000, loss: 0.788699
 >> iter 14000, loss: 0.611099
 >> iter 15000, loss: 0.557039
 >> iter 16000, loss: 0.439323
 >> iter 17000, loss: 0.488738
 >> iter 18000, loss: 0.549086
 >> iter 19000, loss: 0.382338
 >> iter 20000, loss: 0.323578
   Number of active neurons: 7
 >> iter 21000, loss: 0.350215
 >> iter 22000, loss: 0.363210
 >> iter 23000, loss: 0.393056
 >> iter 24000, loss: 0.476742
 >> iter 25000, loss: 0.443523
 >> iter 26000, loss: 0.341830
 >> iter 27000, loss: 0.483787
 >> iter 28000, loss: 0.438534
 >> iter 29000, loss: 0.365191
 >> iter 30000, loss: 0.353524
   Number of active neurons: 6
 >> iter 31000, loss: 0.498509
 >> iter 32000, loss: 0.361987
 >> iter 33000, loss: 0.471735
 >> iter 34000, loss: 0.413645
 >> iter 35000, loss: 0.399263
 >> iter 36000, loss: 0.461261
 >> iter 37000, loss: 0.344036
 >> iter 38000, loss: 0.359792
 >> iter 39000, loss: 0.384922
 >> iter 40000, loss: 0.371821
   Number of active neurons: 6
 >> iter 41000, loss: 0.454817
 >> iter 42000, loss: 0.493278
 >> iter 43000, loss: 0.384502
 >> iter 44000, loss: 0.456263
 >> iter 45000, loss: 0.383342
 >> iter 46000, loss: 0.352899
 >> iter 47000, loss: 0.259502
 >> iter 48000, loss: 0.200419
 >> iter 49000, loss: 0.278112
 >> iter 50000, loss: 0.276421
   Number of active neurons: 5
 >> iter 51000, loss: 0.234324
 >> iter 52000, loss: 0.296889
 >> iter 53000, loss: 0.299221
 >> iter 54000, loss: 0.227156
 >> iter 55000, loss: 0.218858
 >> iter 56000, loss: 0.231811
 >> iter 57000, loss: 0.202624
 >> iter 58000, loss: 0.234903
 >> iter 59000, loss: 0.310495
 >> iter 60000, loss: 0.236366
   Number of active neurons: 5
 >> iter 61000, loss: 0.288945
 >> iter 62000, loss: 0.242428
 >> iter 63000, loss: 0.315397
 >> iter 64000, loss: 0.312241
 >> iter 65000, loss: 0.376622
 >> iter 66000, loss: 0.246952
 >> iter 67000, loss: 0.268300
 >> iter 68000, loss: 0.293186
 >> iter 69000, loss: 0.334350
 >> iter 70000, loss: 0.205937
   Number of active neurons: 5
 >> iter 71000, loss: 0.323464
 >> iter 72000, loss: 0.351750
 >> iter 73000, loss: 0.386676
 >> iter 74000, loss: 0.287468
 >> iter 75000, loss: 0.294759
 >> iter 76000, loss: 0.279090
 >> iter 77000, loss: 0.384488
 >> iter 78000, loss: 0.333876
 >> iter 79000, loss: 0.459567
 >> iter 80000, loss: 0.439540
   Number of active neurons: 5
 >> iter 81000, loss: 0.308455
 >> iter 82000, loss: 0.340569
 >> iter 83000, loss: 0.329211
 >> iter 84000, loss: 0.331953
 >> iter 85000, loss: 0.344707
 >> iter 86000, loss: 0.441143
 >> iter 87000, loss: 0.432529
 >> iter 88000, loss: 0.360840
 >> iter 89000, loss: 0.396293
 >> iter 90000, loss: 0.421722
   Number of active neurons: 5
 >> iter 91000, loss: 0.355474
 >> iter 92000, loss: 0.397065
 >> iter 93000, loss: 0.284593
 >> iter 94000, loss: 0.275835
 >> iter 95000, loss: 0.256619
 >> iter 96000, loss: 0.341248
 >> iter 97000, loss: 0.453734
 >> iter 98000, loss: 0.376860
 >> iter 99000, loss: 0.447255
 >> iter 100000, loss: 0.401873
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.111200
 >> iter 2000, loss: 9.450801
 >> iter 3000, loss: 4.897730
 >> iter 4000, loss: 2.491453
 >> iter 5000, loss: 1.560128
 >> iter 6000, loss: 1.090337
 >> iter 7000, loss: 0.969220
 >> iter 8000, loss: 0.744535
 >> iter 9000, loss: 0.678550
 >> iter 10000, loss: 0.538856
   Number of active neurons: 4
 >> iter 11000, loss: 0.580751
 >> iter 12000, loss: 0.592611
 >> iter 13000, loss: 0.475079
 >> iter 14000, loss: 0.472102
 >> iter 15000, loss: 0.563142
 >> iter 16000, loss: 0.444049
 >> iter 17000, loss: 0.559658
 >> iter 18000, loss: 0.613763
 >> iter 19000, loss: 0.493129
 >> iter 20000, loss: 0.498206
   Number of active neurons: 4
 >> iter 21000, loss: 0.417718
 >> iter 22000, loss: 0.334634
 >> iter 23000, loss: 0.382373
 >> iter 24000, loss: 0.470249
 >> iter 25000, loss: 0.413954
 >> iter 26000, loss: 0.532608
 >> iter 27000, loss: 0.481242
 >> iter 28000, loss: 0.488281
 >> iter 29000, loss: 0.388694
 >> iter 30000, loss: 0.454195
   Number of active neurons: 4
 >> iter 31000, loss: 0.499409
 >> iter 32000, loss: 0.608453
 >> iter 33000, loss: 0.589467
 >> iter 34000, loss: 0.536650
 >> iter 35000, loss: 0.565269
 >> iter 36000, loss: 0.522978
 >> iter 37000, loss: 0.490467
 >> iter 38000, loss: 0.427137
 >> iter 39000, loss: 0.491360
 >> iter 40000, loss: 0.709595
   Number of active neurons: 7
 >> iter 41000, loss: 0.531540
 >> iter 42000, loss: 0.701744
 >> iter 43000, loss: 0.590503
 >> iter 44000, loss: 0.587924
 >> iter 45000, loss: 0.578414
 >> iter 46000, loss: 0.505484
 >> iter 47000, loss: 0.579721
 >> iter 48000, loss: 0.486393
 >> iter 49000, loss: 0.582779
 >> iter 50000, loss: 0.622535
   Number of active neurons: 4
 >> iter 51000, loss: 0.585993
 >> iter 52000, loss: 0.440994
 >> iter 53000, loss: 0.548922
 >> iter 54000, loss: 0.438810
 >> iter 55000, loss: 0.632531
 >> iter 56000, loss: 0.611378
 >> iter 57000, loss: 0.665923
 >> iter 58000, loss: 0.667434
 >> iter 59000, loss: 0.519696
 >> iter 60000, loss: 0.551199
   Number of active neurons: 4
 >> iter 61000, loss: 0.723606
 >> iter 62000, loss: 0.760315
 >> iter 63000, loss: 0.564288
 >> iter 64000, loss: 0.675614
 >> iter 65000, loss: 0.669801
 >> iter 66000, loss: 0.574403
 >> iter 67000, loss: 0.559051
 >> iter 68000, loss: 0.538853
 >> iter 69000, loss: 0.633666
 >> iter 70000, loss: 0.642976
   Number of active neurons: 5
 >> iter 71000, loss: 0.615979
 >> iter 72000, loss: 0.721521
 >> iter 73000, loss: 0.622534
 >> iter 74000, loss: 0.630550
 >> iter 75000, loss: 0.469228
 >> iter 76000, loss: 0.627300
 >> iter 77000, loss: 0.446738
 >> iter 78000, loss: 0.396490
 >> iter 79000, loss: 0.481770
 >> iter 80000, loss: 0.516264
   Number of active neurons: 4
 >> iter 81000, loss: 0.471183
 >> iter 82000, loss: 0.450954
 >> iter 83000, loss: 0.464081
 >> iter 84000, loss: 0.491868
 >> iter 85000, loss: 0.517939
 >> iter 86000, loss: 0.472254
 >> iter 87000, loss: 0.467086
 >> iter 88000, loss: 0.574850
 >> iter 89000, loss: 0.482666
 >> iter 90000, loss: 0.430039
   Number of active neurons: 4
 >> iter 91000, loss: 0.535822
 >> iter 92000, loss: 0.476210
 >> iter 93000, loss: 0.694953
 >> iter 94000, loss: 0.663034
 >> iter 95000, loss: 0.638645
 >> iter 96000, loss: 0.503541
 >> iter 97000, loss: 0.611799
 >> iter 98000, loss: 0.675125
 >> iter 99000, loss: 0.717755
 >> iter 100000, loss: 0.489324
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 17.7321511899
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.161468
 >> iter 2000, loss: 9.642022
 >> iter 3000, loss: 4.893002
 >> iter 4000, loss: 2.915687
 >> iter 5000, loss: 1.711525
 >> iter 6000, loss: 1.141101
 >> iter 7000, loss: 0.646558
 >> iter 8000, loss: 0.643323
 >> iter 9000, loss: 0.629929
 >> iter 10000, loss: 0.484349
   Number of active neurons: 5
 >> iter 11000, loss: 0.554852
 >> iter 12000, loss: 0.530494
 >> iter 13000, loss: 0.442227
 >> iter 14000, loss: 0.483588
 >> iter 15000, loss: 0.483168
 >> iter 16000, loss: 0.414591
 >> iter 17000, loss: 0.359763
 >> iter 18000, loss: 0.414863
 >> iter 19000, loss: 0.412359
 >> iter 20000, loss: 0.410502
   Number of active neurons: 5
 >> iter 21000, loss: 0.330345
 >> iter 22000, loss: 0.308887
 >> iter 23000, loss: 0.615797
 >> iter 24000, loss: 0.621409
 >> iter 25000, loss: 0.676554
 >> iter 26000, loss: 0.543625
 >> iter 27000, loss: 0.452104
 >> iter 28000, loss: 0.468441
 >> iter 29000, loss: 0.471656
 >> iter 30000, loss: 0.609636
   Number of active neurons: 5
 >> iter 31000, loss: 0.551025
 >> iter 32000, loss: 0.565976
 >> iter 33000, loss: 0.608254
 >> iter 34000, loss: 0.583900
 >> iter 35000, loss: 0.576383
 >> iter 36000, loss: 0.415059
 >> iter 37000, loss: 0.478354
 >> iter 38000, loss: 0.601820
 >> iter 39000, loss: 0.543731
 >> iter 40000, loss: 0.461259
   Number of active neurons: 5
 >> iter 41000, loss: 0.426189
 >> iter 42000, loss: 0.436495
 >> iter 43000, loss: 0.371222
 >> iter 44000, loss: 0.486573
 >> iter 45000, loss: 0.500604
 >> iter 46000, loss: 0.535515
 >> iter 47000, loss: 0.502652
 >> iter 48000, loss: 0.569369
 >> iter 49000, loss: 0.446510
 >> iter 50000, loss: 0.404558
   Number of active neurons: 5
 >> iter 51000, loss: 0.534548
 >> iter 52000, loss: 0.501475
 >> iter 53000, loss: 0.513335
 >> iter 54000, loss: 0.513824
 >> iter 55000, loss: 0.557692
 >> iter 56000, loss: 0.473452
 >> iter 57000, loss: 0.370633
 >> iter 58000, loss: 0.257415
 >> iter 59000, loss: 0.310587
 >> iter 60000, loss: 0.303236
   Number of active neurons: 5
 >> iter 61000, loss: 0.361329
 >> iter 62000, loss: 0.345842
 >> iter 63000, loss: 0.325800
 >> iter 64000, loss: 0.464957
 >> iter 65000, loss: 0.461801
 >> iter 66000, loss: 0.400949
 >> iter 67000, loss: 0.409694
 >> iter 68000, loss: 0.414898
 >> iter 69000, loss: 0.481651
 >> iter 70000, loss: 0.446897
   Number of active neurons: 5
 >> iter 71000, loss: 0.321993
 >> iter 72000, loss: 0.303070
 >> iter 73000, loss: 0.277433
 >> iter 74000, loss: 0.262476
 >> iter 75000, loss: 0.397464
 >> iter 76000, loss: 0.365638
 >> iter 77000, loss: 0.513568
 >> iter 78000, loss: 0.332332
 >> iter 79000, loss: 0.427485
 >> iter 80000, loss: 0.366095
   Number of active neurons: 5
 >> iter 81000, loss: 0.325954
 >> iter 82000, loss: 0.318712
 >> iter 83000, loss: 0.381944
 >> iter 84000, loss: 0.436464
 >> iter 85000, loss: 0.469950
 >> iter 86000, loss: 0.360824
 >> iter 87000, loss: 0.441217
 >> iter 88000, loss: 0.597676
 >> iter 89000, loss: 0.500199
 >> iter 90000, loss: 0.573866
   Number of active neurons: 5
 >> iter 91000, loss: 0.480015
 >> iter 92000, loss: 0.646762
 >> iter 93000, loss: 0.503681
 >> iter 94000, loss: 0.468219
 >> iter 95000, loss: 0.422047
 >> iter 96000, loss: 0.543034
 >> iter 97000, loss: 0.575459
 >> iter 98000, loss: 0.554411
 >> iter 99000, loss: 0.518124
 >> iter 100000, loss: 0.513472
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.828266
 >> iter 2000, loss: 10.320768
 >> iter 3000, loss: 4.967386
 >> iter 4000, loss: 2.447384
 >> iter 5000, loss: 1.263606
 >> iter 6000, loss: 0.803758
 >> iter 7000, loss: 0.587160
 >> iter 8000, loss: 0.400280
 >> iter 9000, loss: 0.372475
 >> iter 10000, loss: 0.381148
   Number of active neurons: 6
 >> iter 11000, loss: 0.414505
 >> iter 12000, loss: 0.389870
 >> iter 13000, loss: 0.392810
 >> iter 14000, loss: 0.386401
 >> iter 15000, loss: 0.310996
 >> iter 16000, loss: 0.354232
 >> iter 17000, loss: 0.380439
 >> iter 18000, loss: 0.352171
 >> iter 19000, loss: 0.397549
 >> iter 20000, loss: 0.312522
   Number of active neurons: 6
 >> iter 21000, loss: 0.280032
 >> iter 22000, loss: 0.294026
 >> iter 23000, loss: 0.314451
 >> iter 24000, loss: 0.261458
 >> iter 25000, loss: 0.218712
 >> iter 26000, loss: 0.317113
 >> iter 27000, loss: 0.439954
 >> iter 28000, loss: 0.532684
 >> iter 29000, loss: 0.415288
 >> iter 30000, loss: 0.373443
   Number of active neurons: 6
 >> iter 31000, loss: 0.415711
 >> iter 32000, loss: 0.314846
 >> iter 33000, loss: 0.300278
 >> iter 34000, loss: 0.286656
 >> iter 35000, loss: 0.262185
 >> iter 36000, loss: 0.230076
 >> iter 37000, loss: 0.274400
 >> iter 38000, loss: 0.471388
 >> iter 39000, loss: 0.344920
 >> iter 40000, loss: 0.398384
   Number of active neurons: 6
 >> iter 41000, loss: 0.374029
 >> iter 42000, loss: 0.336518
 >> iter 43000, loss: 0.341302
 >> iter 44000, loss: 0.422372
 >> iter 45000, loss: 0.433507
 >> iter 46000, loss: 0.331014
 >> iter 47000, loss: 0.467821
 >> iter 48000, loss: 0.391650
 >> iter 49000, loss: 0.360633
 >> iter 50000, loss: 0.280158
   Number of active neurons: 6
 >> iter 51000, loss: 0.363819
 >> iter 52000, loss: 0.389314
 >> iter 53000, loss: 0.264352
 >> iter 54000, loss: 0.271954
 >> iter 55000, loss: 0.273750
 >> iter 56000, loss: 0.337110
 >> iter 57000, loss: 0.355047
 >> iter 58000, loss: 0.388419
 >> iter 59000, loss: 0.375287
 >> iter 60000, loss: 0.359327
   Number of active neurons: 6
 >> iter 61000, loss: 0.417379
 >> iter 62000, loss: 0.374288
 >> iter 63000, loss: 0.373560
 >> iter 64000, loss: 0.336414
 >> iter 65000, loss: 0.409951
 >> iter 66000, loss: 0.389003
 >> iter 67000, loss: 0.330347
 >> iter 68000, loss: 0.329526
 >> iter 69000, loss: 0.428775
 >> iter 70000, loss: 0.502483
   Number of active neurons: 6
 >> iter 71000, loss: 0.399376
 >> iter 72000, loss: 0.276104
 >> iter 73000, loss: 0.266890
 >> iter 74000, loss: 0.357804
 >> iter 75000, loss: 0.306436
 >> iter 76000, loss: 0.292496
 >> iter 77000, loss: 0.339411
 >> iter 78000, loss: 0.342750
 >> iter 79000, loss: 0.489173
 >> iter 80000, loss: 0.430444
   Number of active neurons: 6
 >> iter 81000, loss: 0.354749
 >> iter 82000, loss: 0.306854
 >> iter 83000, loss: 0.277064
 >> iter 84000, loss: 0.406219
 >> iter 85000, loss: 0.328308
 >> iter 86000, loss: 0.261876
 >> iter 87000, loss: 0.243754
 >> iter 88000, loss: 0.282147
 >> iter 89000, loss: 0.269918
 >> iter 90000, loss: 0.333447
   Number of active neurons: 6
 >> iter 91000, loss: 0.360907
 >> iter 92000, loss: 0.457890
 >> iter 93000, loss: 0.438518
 >> iter 94000, loss: 0.373488
 >> iter 95000, loss: 0.459883
 >> iter 96000, loss: 0.403124
 >> iter 97000, loss: 0.317672
 >> iter 98000, loss: 0.269041
 >> iter 99000, loss: 0.261081
 >> iter 100000, loss: 0.396080
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.808720
 >> iter 2000, loss: 10.010502
 >> iter 3000, loss: 5.640724
 >> iter 4000, loss: 2.821400
 >> iter 5000, loss: 1.653303
 >> iter 6000, loss: 1.053713
 >> iter 7000, loss: 0.952627
 >> iter 8000, loss: 0.741523
 >> iter 9000, loss: 0.615156
 >> iter 10000, loss: 0.442137
   Number of active neurons: 5
 >> iter 11000, loss: 0.502724
 >> iter 12000, loss: 0.511944
 >> iter 13000, loss: 0.434416
 >> iter 14000, loss: 0.410490
 >> iter 15000, loss: 0.318654
 >> iter 16000, loss: 0.268722
 >> iter 17000, loss: 0.494666
 >> iter 18000, loss: 0.525090
 >> iter 19000, loss: 0.418949
 >> iter 20000, loss: 0.630122
   Number of active neurons: 5
 >> iter 21000, loss: 0.476994
 >> iter 22000, loss: 0.467356
 >> iter 23000, loss: 0.415998
 >> iter 24000, loss: 0.461743
 >> iter 25000, loss: 0.431037
 >> iter 26000, loss: 0.407574
 >> iter 27000, loss: 0.441167
 >> iter 28000, loss: 0.521844
 >> iter 29000, loss: 0.497231
 >> iter 30000, loss: 0.465956
   Number of active neurons: 5
 >> iter 31000, loss: 0.546287
 >> iter 32000, loss: 0.527483
 >> iter 33000, loss: 0.336939
 >> iter 34000, loss: 0.375444
 >> iter 35000, loss: 0.495275
 >> iter 36000, loss: 0.443019
 >> iter 37000, loss: 0.433503
 >> iter 38000, loss: 0.354061
 >> iter 39000, loss: 0.367339
 >> iter 40000, loss: 0.472124
   Number of active neurons: 5
 >> iter 41000, loss: 0.448824
 >> iter 42000, loss: 0.514063
 >> iter 43000, loss: 0.502812
 >> iter 44000, loss: 0.442181
 >> iter 45000, loss: 0.397688
 >> iter 46000, loss: 0.579716
 >> iter 47000, loss: 0.454641
 >> iter 48000, loss: 0.597064
 >> iter 49000, loss: 0.470924
 >> iter 50000, loss: 0.363140
   Number of active neurons: 5
 >> iter 51000, loss: 0.327648
 >> iter 52000, loss: 0.330709
 >> iter 53000, loss: 0.372672
 >> iter 54000, loss: 0.338328
 >> iter 55000, loss: 0.329510
 >> iter 56000, loss: 0.372177
 >> iter 57000, loss: 0.378020
 >> iter 58000, loss: 0.453234
 >> iter 59000, loss: 0.498856
 >> iter 60000, loss: 0.409961
   Number of active neurons: 5
 >> iter 61000, loss: 0.474274
 >> iter 62000, loss: 0.340235
 >> iter 63000, loss: 0.386381
 >> iter 64000, loss: 0.488942
 >> iter 65000, loss: 0.424012
 >> iter 66000, loss: 0.365083
 >> iter 67000, loss: 0.407537
 >> iter 68000, loss: 0.326339
 >> iter 69000, loss: 0.421602
 >> iter 70000, loss: 0.399576
   Number of active neurons: 4
 >> iter 71000, loss: 0.362358
 >> iter 72000, loss: 0.381253
 >> iter 73000, loss: 0.481013
 >> iter 74000, loss: 0.537534
 >> iter 75000, loss: 0.512384
 >> iter 76000, loss: 0.315501
 >> iter 77000, loss: 0.340675
 >> iter 78000, loss: 0.357224
 >> iter 79000, loss: 0.563842
 >> iter 80000, loss: 0.445305
   Number of active neurons: 4
 >> iter 81000, loss: 0.445483
 >> iter 82000, loss: 0.380922
 >> iter 83000, loss: 0.429658
 >> iter 84000, loss: 0.363470
 >> iter 85000, loss: 0.409843
 >> iter 86000, loss: 0.413405
 >> iter 87000, loss: 0.403745
 >> iter 88000, loss: 0.447613
 >> iter 89000, loss: 0.479552
 >> iter 90000, loss: 0.696206
   Number of active neurons: 4
 >> iter 91000, loss: 0.538680
 >> iter 92000, loss: 0.460504
 >> iter 93000, loss: 0.365109
 >> iter 94000, loss: 0.398937
 >> iter 95000, loss: 0.556870
 >> iter 96000, loss: 0.452543
 >> iter 97000, loss: 0.495928
 >> iter 98000, loss: 0.473255
 >> iter 99000, loss: 0.460655
 >> iter 100000, loss: 0.405567
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.464348
 >> iter 2000, loss: 9.350673
 >> iter 3000, loss: 5.218915
 >> iter 4000, loss: 2.408371
 >> iter 5000, loss: 1.455769
 >> iter 6000, loss: 0.859918
 >> iter 7000, loss: 0.676822
 >> iter 8000, loss: 0.455499
 >> iter 9000, loss: 0.387919
 >> iter 10000, loss: 0.358210
   Number of active neurons: 8
 >> iter 11000, loss: 0.352324
 >> iter 12000, loss: 0.370069
 >> iter 13000, loss: 0.304923
 >> iter 14000, loss: 0.325372
 >> iter 15000, loss: 0.407458
 >> iter 16000, loss: 0.324625
 >> iter 17000, loss: 0.317848
 >> iter 18000, loss: 0.313357
 >> iter 19000, loss: 0.365554
 >> iter 20000, loss: 0.314363
   Number of active neurons: 8
 >> iter 21000, loss: 0.324942
 >> iter 22000, loss: 0.321995
 >> iter 23000, loss: 0.321309
 >> iter 24000, loss: 0.360008
 >> iter 25000, loss: 0.307885
 >> iter 26000, loss: 0.322438
 >> iter 27000, loss: 0.418087
 >> iter 28000, loss: 0.401081
 >> iter 29000, loss: 0.462665
 >> iter 30000, loss: 0.333408
   Number of active neurons: 8
 >> iter 31000, loss: 0.388514
 >> iter 32000, loss: 0.439616
 >> iter 33000, loss: 0.358562
 >> iter 34000, loss: 0.245115
 >> iter 35000, loss: 0.359749
 >> iter 36000, loss: 0.370480
 >> iter 37000, loss: 0.280745
 >> iter 38000, loss: 0.362137
 >> iter 39000, loss: 0.515610
 >> iter 40000, loss: 0.498741
   Number of active neurons: 8
 >> iter 41000, loss: 0.351440
 >> iter 42000, loss: 0.496966
 >> iter 43000, loss: 0.389064
 >> iter 44000, loss: 0.372516
 >> iter 45000, loss: 0.426717
 >> iter 46000, loss: 0.298529
 >> iter 47000, loss: 0.323190
 >> iter 48000, loss: 0.358743
 >> iter 49000, loss: 0.341970
 >> iter 50000, loss: 0.329164
   Number of active neurons: 8
 >> iter 51000, loss: 0.415170
 >> iter 52000, loss: 0.374238
 >> iter 53000, loss: 0.491160
 >> iter 54000, loss: 0.404617
 >> iter 55000, loss: 0.373996
 >> iter 56000, loss: 0.665226
 >> iter 57000, loss: 0.405554
 >> iter 58000, loss: 0.339624
 >> iter 59000, loss: 0.313900
 >> iter 60000, loss: 0.410735
   Number of active neurons: 8
 >> iter 61000, loss: 0.476742
 >> iter 62000, loss: 0.357871
 >> iter 63000, loss: 0.602512
 >> iter 64000, loss: 0.444218
 >> iter 65000, loss: 0.434064
 >> iter 66000, loss: 0.544045
 >> iter 67000, loss: 0.392892
 >> iter 68000, loss: 0.492622
 >> iter 69000, loss: 0.517196
 >> iter 70000, loss: 0.395325
   Number of active neurons: 8
 >> iter 71000, loss: 0.388826
 >> iter 72000, loss: 0.459587
 >> iter 73000, loss: 0.380131
 >> iter 74000, loss: 0.278722
 >> iter 75000, loss: 0.310643
 >> iter 76000, loss: 0.439140
 >> iter 77000, loss: 0.363775
 >> iter 78000, loss: 0.462121
 >> iter 79000, loss: 0.364405
 >> iter 80000, loss: 0.659248
   Number of active neurons: 8
 >> iter 81000, loss: 0.509997
 >> iter 82000, loss: 0.416423
 >> iter 83000, loss: 0.504092
 >> iter 84000, loss: 0.515763
 >> iter 85000, loss: 0.444995
 >> iter 86000, loss: 0.461168
 >> iter 87000, loss: 0.323749
 >> iter 88000, loss: 0.519284
 >> iter 89000, loss: 0.423992
 >> iter 90000, loss: 0.338469
   Number of active neurons: 8
 >> iter 91000, loss: 0.411536
 >> iter 92000, loss: 0.448295
 >> iter 93000, loss: 0.333900
 >> iter 94000, loss: 0.304505
 >> iter 95000, loss: 0.533762
 >> iter 96000, loss: 0.422041
 >> iter 97000, loss: 0.399501
 >> iter 98000, loss: 0.326283
 >> iter 99000, loss: 0.312235
 >> iter 100000, loss: 0.389603
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0979980400392
   - Test - Long: 0.0449977501125
   - Test - Big: 0.0619993800062
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.587784
 >> iter 2000, loss: 9.529640
 >> iter 3000, loss: 5.717497
 >> iter 4000, loss: 3.486762
 >> iter 5000, loss: 1.962419
 >> iter 6000, loss: 1.102579
 >> iter 7000, loss: 0.832218
 >> iter 8000, loss: 0.638353
 >> iter 9000, loss: 0.555174
 >> iter 10000, loss: 0.456331
   Number of active neurons: 8
 >> iter 11000, loss: 0.324832
 >> iter 12000, loss: 0.353912
 >> iter 13000, loss: 0.415151
 >> iter 14000, loss: 0.350196
 >> iter 15000, loss: 0.328517
 >> iter 16000, loss: 0.321470
 >> iter 17000, loss: 0.330400
 >> iter 18000, loss: 0.251336
 >> iter 19000, loss: 0.500449
 >> iter 20000, loss: 0.334369
   Number of active neurons: 7
 >> iter 21000, loss: 0.366002
 >> iter 22000, loss: 0.314140
 >> iter 23000, loss: 0.370772
 >> iter 24000, loss: 0.379752
 >> iter 25000, loss: 0.392303
 >> iter 26000, loss: 0.417698
 >> iter 27000, loss: 0.296734
 >> iter 28000, loss: 0.404184
 >> iter 29000, loss: 0.433286
 >> iter 30000, loss: 0.311589
   Number of active neurons: 7
 >> iter 31000, loss: 0.337090
 >> iter 32000, loss: 0.343085
 >> iter 33000, loss: 0.406134
 >> iter 34000, loss: 0.360752
 >> iter 35000, loss: 0.450419
 >> iter 36000, loss: 0.391812
 >> iter 37000, loss: 0.400419
 >> iter 38000, loss: 0.447725
 >> iter 39000, loss: 0.547339
 >> iter 40000, loss: 0.346329
   Number of active neurons: 6
 >> iter 41000, loss: 0.465253
 >> iter 42000, loss: 0.411499
 >> iter 43000, loss: 0.646636
 >> iter 44000, loss: 0.635734
 >> iter 45000, loss: 0.576438
 >> iter 46000, loss: 0.475916
 >> iter 47000, loss: 0.399406
 >> iter 48000, loss: 0.318577
 >> iter 49000, loss: 0.419238
 >> iter 50000, loss: 0.393192
   Number of active neurons: 6
 >> iter 51000, loss: 0.441467
 >> iter 52000, loss: 0.434212
 >> iter 53000, loss: 0.474899
 >> iter 54000, loss: 0.469696
 >> iter 55000, loss: 0.471313
 >> iter 56000, loss: 0.342878
 >> iter 57000, loss: 0.305262
 >> iter 58000, loss: 0.339252
 >> iter 59000, loss: 0.340633
 >> iter 60000, loss: 0.466389
   Number of active neurons: 5
 >> iter 61000, loss: 0.405255
 >> iter 62000, loss: 0.417384
 >> iter 63000, loss: 0.395350
 >> iter 64000, loss: 0.371738
 >> iter 65000, loss: 0.429027
 >> iter 66000, loss: 0.316206
 >> iter 67000, loss: 0.397054
 >> iter 68000, loss: 0.461843
 >> iter 69000, loss: 0.395415
 >> iter 70000, loss: 0.452440
   Number of active neurons: 5
 >> iter 71000, loss: 0.387423
 >> iter 72000, loss: 0.326028
 >> iter 73000, loss: 0.283041
 >> iter 74000, loss: 0.378874
 >> iter 75000, loss: 0.414065
 >> iter 76000, loss: 0.277675
 >> iter 77000, loss: 0.280366
 >> iter 78000, loss: 0.455776
 >> iter 79000, loss: 0.422603
 >> iter 80000, loss: 0.473241
   Number of active neurons: 5
 >> iter 81000, loss: 0.382343
 >> iter 82000, loss: 0.322099
 >> iter 83000, loss: 0.372601
 >> iter 84000, loss: 0.358924
 >> iter 85000, loss: 0.419628
 >> iter 86000, loss: 0.487215
 >> iter 87000, loss: 0.431000
 >> iter 88000, loss: 0.431931
 >> iter 89000, loss: 0.564904
 >> iter 90000, loss: 0.360869
   Number of active neurons: 5
 >> iter 91000, loss: 0.347994
 >> iter 92000, loss: 0.411565
 >> iter 93000, loss: 0.541618
 >> iter 94000, loss: 0.461090
 >> iter 95000, loss: 0.345054
 >> iter 96000, loss: 0.320725
 >> iter 97000, loss: 0.356945
 >> iter 98000, loss: 0.335327
 >> iter 99000, loss: 0.386207
 >> iter 100000, loss: 0.404145
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.371409
 >> iter 2000, loss: 9.574952
 >> iter 3000, loss: 5.251015
 >> iter 4000, loss: 2.371454
 >> iter 5000, loss: 1.213002
 >> iter 6000, loss: 0.653820
 >> iter 7000, loss: 0.409336
 >> iter 8000, loss: 0.326819
 >> iter 9000, loss: 0.386813
 >> iter 10000, loss: 0.274885
   Number of active neurons: 10
 >> iter 11000, loss: 0.332731
 >> iter 12000, loss: 0.432596
 >> iter 13000, loss: 0.360466
 >> iter 14000, loss: 0.272928
 >> iter 15000, loss: 0.275396
 >> iter 16000, loss: 0.229313
 >> iter 17000, loss: 0.227665
 >> iter 18000, loss: 0.368247
 >> iter 19000, loss: 0.433824
 >> iter 20000, loss: 0.423843
   Number of active neurons: 10
 >> iter 21000, loss: 0.339407
 >> iter 22000, loss: 0.238663
 >> iter 23000, loss: 0.244780
 >> iter 24000, loss: 0.243985
 >> iter 25000, loss: 0.343609
 >> iter 26000, loss: 0.300074
 >> iter 27000, loss: 0.276602
 >> iter 28000, loss: 0.365675
 >> iter 29000, loss: 0.421195
 >> iter 30000, loss: 0.358951
   Number of active neurons: 9
 >> iter 31000, loss: 0.427492
 >> iter 32000, loss: 0.364858
 >> iter 33000, loss: 0.366487
 >> iter 34000, loss: 0.395171
 >> iter 35000, loss: 0.303769
 >> iter 36000, loss: 0.287186
 >> iter 37000, loss: 0.446076
 >> iter 38000, loss: 0.400804
 >> iter 39000, loss: 0.427234
 >> iter 40000, loss: 0.396277
   Number of active neurons: 9
 >> iter 41000, loss: 0.365971
 >> iter 42000, loss: 0.320923
 >> iter 43000, loss: 0.399207
 >> iter 44000, loss: 0.348578
 >> iter 45000, loss: 0.422539
 >> iter 46000, loss: 0.365437
 >> iter 47000, loss: 0.375299
 >> iter 48000, loss: 0.337996
 >> iter 49000, loss: 0.252184
 >> iter 50000, loss: 0.320951
   Number of active neurons: 8
 >> iter 51000, loss: 0.230081
 >> iter 52000, loss: 0.298443
 >> iter 53000, loss: 0.369915
 >> iter 54000, loss: 0.349434
 >> iter 55000, loss: 0.313104
 >> iter 56000, loss: 0.257434
 >> iter 57000, loss: 0.284473
 >> iter 58000, loss: 0.222260
 >> iter 59000, loss: 0.330939
 >> iter 60000, loss: 0.274205
   Number of active neurons: 8
 >> iter 61000, loss: 0.364192
 >> iter 62000, loss: 0.447750
 >> iter 63000, loss: 0.403535
 >> iter 64000, loss: 0.306626
 >> iter 65000, loss: 0.233354
 >> iter 66000, loss: 0.221142
 >> iter 67000, loss: 0.295481
 >> iter 68000, loss: 0.267103
 >> iter 69000, loss: 0.277659
 >> iter 70000, loss: 0.280556
   Number of active neurons: 8
 >> iter 71000, loss: 0.375177
 >> iter 72000, loss: 0.261129
 >> iter 73000, loss: 0.261745
 >> iter 74000, loss: 0.256804
 >> iter 75000, loss: 0.348058
 >> iter 76000, loss: 0.324624
 >> iter 77000, loss: 0.257004
 >> iter 78000, loss: 0.307617
 >> iter 79000, loss: 0.260142
 >> iter 80000, loss: 0.263224
   Number of active neurons: 7
 >> iter 81000, loss: 0.285231
 >> iter 82000, loss: 0.244681
 >> iter 83000, loss: 0.225648
 >> iter 84000, loss: 0.264579
 >> iter 85000, loss: 0.293991
 >> iter 86000, loss: 0.297257
 >> iter 87000, loss: 0.278291
 >> iter 88000, loss: 0.305843
 >> iter 89000, loss: 0.300851
 >> iter 90000, loss: 0.317485
   Number of active neurons: 7
 >> iter 91000, loss: 0.397854
 >> iter 92000, loss: 0.410588
 >> iter 93000, loss: 0.350723
 >> iter 94000, loss: 0.466116
 >> iter 95000, loss: 0.439204
 >> iter 96000, loss: 0.310380
 >> iter 97000, loss: 0.314057
 >> iter 98000, loss: 0.445856
 >> iter 99000, loss: 0.327527
 >> iter 100000, loss: 0.369889
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.198729
 >> iter 2000, loss: 9.424257
 >> iter 3000, loss: 4.437543
 >> iter 4000, loss: 2.139472
 >> iter 5000, loss: 1.052946
 >> iter 6000, loss: 0.553896
 >> iter 7000, loss: 0.443493
 >> iter 8000, loss: 0.314252
 >> iter 9000, loss: 0.288479
 >> iter 10000, loss: 0.162287
   Number of active neurons: 5
 >> iter 11000, loss: 0.348921
 >> iter 12000, loss: 0.250836
 >> iter 13000, loss: 0.208141
 >> iter 14000, loss: 0.271506
 >> iter 15000, loss: 0.237781
 >> iter 16000, loss: 0.222273
 >> iter 17000, loss: 0.217496
 >> iter 18000, loss: 0.186961
 >> iter 19000, loss: 0.223647
 >> iter 20000, loss: 0.183810
   Number of active neurons: 5
 >> iter 21000, loss: 0.182114
 >> iter 22000, loss: 0.150827
 >> iter 23000, loss: 0.241169
 >> iter 24000, loss: 0.218670
 >> iter 25000, loss: 0.183660
 >> iter 26000, loss: 0.136396
 >> iter 27000, loss: 0.163706
 >> iter 28000, loss: 0.182165
 >> iter 29000, loss: 0.161318
 >> iter 30000, loss: 0.168211
   Number of active neurons: 5
 >> iter 31000, loss: 0.177025
 >> iter 32000, loss: 0.221953
 >> iter 33000, loss: 0.168563
 >> iter 34000, loss: 0.231883
 >> iter 35000, loss: 0.257016
 >> iter 36000, loss: 0.214681
 >> iter 37000, loss: 0.291415
 >> iter 38000, loss: 0.250275
 >> iter 39000, loss: 0.221452
 >> iter 40000, loss: 0.300481
   Number of active neurons: 5
 >> iter 41000, loss: 0.349210
 >> iter 42000, loss: 0.279524
 >> iter 43000, loss: 0.247799
 >> iter 44000, loss: 0.180039
 >> iter 45000, loss: 0.392102
 >> iter 46000, loss: 0.242272
 >> iter 47000, loss: 0.247202
 >> iter 48000, loss: 0.216529
 >> iter 49000, loss: 0.239012
 >> iter 50000, loss: 0.247800
   Number of active neurons: 5
 >> iter 51000, loss: 0.241392
 >> iter 52000, loss: 0.200603
 >> iter 53000, loss: 0.188192
 >> iter 54000, loss: 0.234325
 >> iter 55000, loss: 0.262710
 >> iter 56000, loss: 0.234960
 >> iter 57000, loss: 0.275295
 >> iter 58000, loss: 0.238829
 >> iter 59000, loss: 0.264333
 >> iter 60000, loss: 0.248803
   Number of active neurons: 5
 >> iter 61000, loss: 0.265241
 >> iter 62000, loss: 0.181661
 >> iter 63000, loss: 0.230733
 >> iter 64000, loss: 0.175770
 >> iter 65000, loss: 0.214008
 >> iter 66000, loss: 0.280147
 >> iter 67000, loss: 0.301016
 >> iter 68000, loss: 0.220122
 >> iter 69000, loss: 0.192600
 >> iter 70000, loss: 0.234214
   Number of active neurons: 5
 >> iter 71000, loss: 0.214972
 >> iter 72000, loss: 0.201780
 >> iter 73000, loss: 0.256806
 >> iter 74000, loss: 0.266031
 >> iter 75000, loss: 0.192691
 >> iter 76000, loss: 0.216856
 >> iter 77000, loss: 0.197516
 >> iter 78000, loss: 0.156361
 >> iter 79000, loss: 0.301921
 >> iter 80000, loss: 0.343809
   Number of active neurons: 5
 >> iter 81000, loss: 0.286409
 >> iter 82000, loss: 0.253913
 >> iter 83000, loss: 0.207406
 >> iter 84000, loss: 0.190641
 >> iter 85000, loss: 0.176828
 >> iter 86000, loss: 0.229705
 >> iter 87000, loss: 0.324510
 >> iter 88000, loss: 0.297920
 >> iter 89000, loss: 0.180142
 >> iter 90000, loss: 0.233646
   Number of active neurons: 5
 >> iter 91000, loss: 0.214260
 >> iter 92000, loss: 0.279751
 >> iter 93000, loss: 0.263386
 >> iter 94000, loss: 0.192049
 >> iter 95000, loss: 0.225283
 >> iter 96000, loss: 0.222724
 >> iter 97000, loss: 0.250355
 >> iter 98000, loss: 0.295831
 >> iter 99000, loss: 0.233780
 >> iter 100000, loss: 0.204852
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.230533
 >> iter 2000, loss: 9.942406
 >> iter 3000, loss: 4.702903
 >> iter 4000, loss: 2.131960
 >> iter 5000, loss: 1.092908
 >> iter 6000, loss: 0.618103
 >> iter 7000, loss: 0.366924
 >> iter 8000, loss: 0.409804
 >> iter 9000, loss: 0.465452
 >> iter 10000, loss: 0.399445
   Number of active neurons: 11
 >> iter 11000, loss: 0.469827
 >> iter 12000, loss: 0.505927
 >> iter 13000, loss: 0.411985
 >> iter 14000, loss: 0.430788
 >> iter 15000, loss: 0.326063
 >> iter 16000, loss: 0.361502
 >> iter 17000, loss: 0.352388
 >> iter 18000, loss: 0.468185
 >> iter 19000, loss: 0.325869
 >> iter 20000, loss: 0.306421
   Number of active neurons: 9
 >> iter 21000, loss: 0.307011
 >> iter 22000, loss: 0.558392
 >> iter 23000, loss: 0.478542
 >> iter 24000, loss: 0.369079
 >> iter 25000, loss: 0.454265
 >> iter 26000, loss: 0.393107
 >> iter 27000, loss: 0.410925
 >> iter 28000, loss: 0.344604
 >> iter 29000, loss: 0.409647
 >> iter 30000, loss: 0.410016
   Number of active neurons: 8
 >> iter 31000, loss: 0.233947
 >> iter 32000, loss: 0.291788
 >> iter 33000, loss: 0.319291
 >> iter 34000, loss: 0.282333
 >> iter 35000, loss: 0.333404
 >> iter 36000, loss: 0.419325
 >> iter 37000, loss: 0.301788
 >> iter 38000, loss: 0.219446
 >> iter 39000, loss: 0.266496
 >> iter 40000, loss: 0.284685
   Number of active neurons: 8
 >> iter 41000, loss: 0.290928
 >> iter 42000, loss: 0.290887
 >> iter 43000, loss: 0.393968
 >> iter 44000, loss: 0.324147
 >> iter 45000, loss: 0.332343
 >> iter 46000, loss: 0.323877
 >> iter 47000, loss: 0.249566
 >> iter 48000, loss: 0.223987
 >> iter 49000, loss: 0.313426
 >> iter 50000, loss: 0.371815
   Number of active neurons: 8
 >> iter 51000, loss: 0.387517
 >> iter 52000, loss: 0.332932
 >> iter 53000, loss: 0.286196
 >> iter 54000, loss: 0.407101
 >> iter 55000, loss: 0.338258
 >> iter 56000, loss: 0.298068
 >> iter 57000, loss: 0.193847
 >> iter 58000, loss: 0.265564
 >> iter 59000, loss: 0.410798
 >> iter 60000, loss: 0.327454
   Number of active neurons: 8
 >> iter 61000, loss: 0.382563
 >> iter 62000, loss: 0.273259
 >> iter 63000, loss: 0.339133
 >> iter 64000, loss: 0.324204
 >> iter 65000, loss: 0.283245
 >> iter 66000, loss: 0.227476
 >> iter 67000, loss: 0.317650
 >> iter 68000, loss: 0.331446
 >> iter 69000, loss: 0.405018
 >> iter 70000, loss: 0.305282
   Number of active neurons: 8
 >> iter 71000, loss: 0.336251
 >> iter 72000, loss: 0.305657
 >> iter 73000, loss: 0.277165
 >> iter 74000, loss: 0.339897
 >> iter 75000, loss: 0.392260
 >> iter 76000, loss: 0.281267
 >> iter 77000, loss: 0.377724
 >> iter 78000, loss: 0.322110
 >> iter 79000, loss: 0.188515
 >> iter 80000, loss: 0.272133
   Number of active neurons: 8
 >> iter 81000, loss: 0.264137
 >> iter 82000, loss: 0.330584
 >> iter 83000, loss: 0.344465
 >> iter 84000, loss: 0.309426
 >> iter 85000, loss: 0.248866
 >> iter 86000, loss: 0.191310
 >> iter 87000, loss: 0.327026
 >> iter 88000, loss: 0.445680
 >> iter 89000, loss: 0.464023
 >> iter 90000, loss: 0.329984
   Number of active neurons: 8
 >> iter 91000, loss: 0.251808
 >> iter 92000, loss: 0.287689
 >> iter 93000, loss: 0.226607
 >> iter 94000, loss: 0.242508
 >> iter 95000, loss: 0.278885
 >> iter 96000, loss: 0.369020
 >> iter 97000, loss: 0.393725
 >> iter 98000, loss: 0.532556
 >> iter 99000, loss: 0.406673
 >> iter 100000, loss: 0.419742
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.778153
 >> iter 2000, loss: 9.802445
 >> iter 3000, loss: 5.017551
 >> iter 4000, loss: 2.286897
 >> iter 5000, loss: 1.164780
 >> iter 6000, loss: 0.750216
 >> iter 7000, loss: 0.477034
 >> iter 8000, loss: 0.348985
 >> iter 9000, loss: 0.309722
 >> iter 10000, loss: 0.436249
   Number of active neurons: 10
 >> iter 11000, loss: 0.313261
 >> iter 12000, loss: 0.276181
 >> iter 13000, loss: 0.243155
 >> iter 14000, loss: 0.188673
 >> iter 15000, loss: 0.133304
 >> iter 16000, loss: 0.265082
 >> iter 17000, loss: 0.371426
 >> iter 18000, loss: 0.252627
 >> iter 19000, loss: 0.309752
 >> iter 20000, loss: 0.399407
   Number of active neurons: 9
 >> iter 21000, loss: 0.359655
 >> iter 22000, loss: 0.406820
 >> iter 23000, loss: 0.407315
 >> iter 24000, loss: 0.246250
 >> iter 25000, loss: 0.197977
 >> iter 26000, loss: 0.222091
 >> iter 27000, loss: 0.241818
 >> iter 28000, loss: 0.285763
 >> iter 29000, loss: 0.376535
 >> iter 30000, loss: 0.333580
   Number of active neurons: 9
 >> iter 31000, loss: 0.254948
 >> iter 32000, loss: 0.283991
 >> iter 33000, loss: 0.257935
 >> iter 34000, loss: 0.294651
 >> iter 35000, loss: 0.321536
 >> iter 36000, loss: 0.325477
 >> iter 37000, loss: 0.277200
 >> iter 38000, loss: 0.252141
 >> iter 39000, loss: 0.205634
 >> iter 40000, loss: 0.263341
   Number of active neurons: 9
 >> iter 41000, loss: 0.412594
 >> iter 42000, loss: 0.297982
 >> iter 43000, loss: 0.347400
 >> iter 44000, loss: 0.288362
 >> iter 45000, loss: 0.320491
 >> iter 46000, loss: 0.331764
 >> iter 47000, loss: 0.213434
 >> iter 48000, loss: 0.327655
 >> iter 49000, loss: 0.320099
 >> iter 50000, loss: 0.325569
   Number of active neurons: 9
 >> iter 51000, loss: 0.242290
 >> iter 52000, loss: 0.385294
 >> iter 53000, loss: 0.339077
 >> iter 54000, loss: 0.359934
 >> iter 55000, loss: 0.298734
 >> iter 56000, loss: 0.409474
 >> iter 57000, loss: 0.322627
 >> iter 58000, loss: 0.350098
 >> iter 59000, loss: 0.333556
 >> iter 60000, loss: 0.294248
   Number of active neurons: 9
 >> iter 61000, loss: 0.244152
 >> iter 62000, loss: 0.494257
 >> iter 63000, loss: 0.466414
 >> iter 64000, loss: 0.357941
 >> iter 65000, loss: 0.302411
 >> iter 66000, loss: 0.413789
 >> iter 67000, loss: 0.400477
 >> iter 68000, loss: 0.332121
 >> iter 69000, loss: 0.331173
 >> iter 70000, loss: 0.343772
   Number of active neurons: 8
 >> iter 71000, loss: 0.324393
 >> iter 72000, loss: 0.295965
 >> iter 73000, loss: 0.295880
 >> iter 74000, loss: 0.383058
 >> iter 75000, loss: 0.273814
 >> iter 76000, loss: 0.281888
 >> iter 77000, loss: 0.413648
 >> iter 78000, loss: 0.365588
 >> iter 79000, loss: 0.328651
 >> iter 80000, loss: 0.253081
   Number of active neurons: 8
 >> iter 81000, loss: 0.294406
 >> iter 82000, loss: 0.351796
 >> iter 83000, loss: 0.286312
 >> iter 84000, loss: 0.299204
 >> iter 85000, loss: 0.226616
 >> iter 86000, loss: 0.300038
 >> iter 87000, loss: 0.351989
 >> iter 88000, loss: 0.330620
 >> iter 89000, loss: 0.286898
 >> iter 90000, loss: 0.271525
   Number of active neurons: 7
 >> iter 91000, loss: 0.297687
 >> iter 92000, loss: 0.272596
 >> iter 93000, loss: 0.443070
 >> iter 94000, loss: 0.385201
 >> iter 95000, loss: 0.287258
 >> iter 96000, loss: 0.305935
 >> iter 97000, loss: 0.262779
 >> iter 98000, loss: 0.398593
 >> iter 99000, loss: 0.344103
 >> iter 100000, loss: 0.219315
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.338677
 >> iter 2000, loss: 10.394282
 >> iter 3000, loss: 7.431009
 >> iter 4000, loss: 4.204564
 >> iter 5000, loss: 2.240248
 >> iter 6000, loss: 1.467307
 >> iter 7000, loss: 1.012188
 >> iter 8000, loss: 0.732554
 >> iter 9000, loss: 0.540401
 >> iter 10000, loss: 0.469990
   Number of active neurons: 7
 >> iter 11000, loss: 0.353117
 >> iter 12000, loss: 0.307651
 >> iter 13000, loss: 0.321802
 >> iter 14000, loss: 0.269049
 >> iter 15000, loss: 0.319537
 >> iter 16000, loss: 0.271471
 >> iter 17000, loss: 0.242186
 >> iter 18000, loss: 0.353942
 >> iter 19000, loss: 0.337359
 >> iter 20000, loss: 0.342874
   Number of active neurons: 7
 >> iter 21000, loss: 0.246833
 >> iter 22000, loss: 0.233461
 >> iter 23000, loss: 0.297936
 >> iter 24000, loss: 0.307804
 >> iter 25000, loss: 0.351114
 >> iter 26000, loss: 0.305314
 >> iter 27000, loss: 0.241936
 >> iter 28000, loss: 0.355316
 >> iter 29000, loss: 0.357033
 >> iter 30000, loss: 0.250185
   Number of active neurons: 6
 >> iter 31000, loss: 0.247508
 >> iter 32000, loss: 0.396305
 >> iter 33000, loss: 0.217755
 >> iter 34000, loss: 0.294700
 >> iter 35000, loss: 0.401083
 >> iter 36000, loss: 0.435515
 >> iter 37000, loss: 0.265716
 >> iter 38000, loss: 0.378391
 >> iter 39000, loss: 0.382380
 >> iter 40000, loss: 0.278564
   Number of active neurons: 6
 >> iter 41000, loss: 0.273715
 >> iter 42000, loss: 0.417958
 >> iter 43000, loss: 0.467164
 >> iter 44000, loss: 0.361500
 >> iter 45000, loss: 0.276047
 >> iter 46000, loss: 0.267606
 >> iter 47000, loss: 0.347538
 >> iter 48000, loss: 0.344264
 >> iter 49000, loss: 0.290714
 >> iter 50000, loss: 0.240387
   Number of active neurons: 6
 >> iter 51000, loss: 0.297873
 >> iter 52000, loss: 0.239909
 >> iter 53000, loss: 0.309288
 >> iter 54000, loss: 0.224963
 >> iter 55000, loss: 0.241311
 >> iter 56000, loss: 0.268148
 >> iter 57000, loss: 0.257526
 >> iter 58000, loss: 0.258143
 >> iter 59000, loss: 0.315479
 >> iter 60000, loss: 0.270116
   Number of active neurons: 6
 >> iter 61000, loss: 0.354895
 >> iter 62000, loss: 0.251291
 >> iter 63000, loss: 0.218622
 >> iter 64000, loss: 0.200317
 >> iter 65000, loss: 0.316748
 >> iter 66000, loss: 0.352995
 >> iter 67000, loss: 0.259739
 >> iter 68000, loss: 0.312091
 >> iter 69000, loss: 0.351790
 >> iter 70000, loss: 0.235315
   Number of active neurons: 6
 >> iter 71000, loss: 0.278312
 >> iter 72000, loss: 0.187506
 >> iter 73000, loss: 0.253650
 >> iter 74000, loss: 0.184929
 >> iter 75000, loss: 0.272021
 >> iter 76000, loss: 0.252517
 >> iter 77000, loss: 0.299423
 >> iter 78000, loss: 0.287992
 >> iter 79000, loss: 0.363387
 >> iter 80000, loss: 0.276665
   Number of active neurons: 6
 >> iter 81000, loss: 0.310323
 >> iter 82000, loss: 0.298500
 >> iter 83000, loss: 0.304893
 >> iter 84000, loss: 0.228354
 >> iter 85000, loss: 0.268797
 >> iter 86000, loss: 0.309903
 >> iter 87000, loss: 0.308491
 >> iter 88000, loss: 0.251399
 >> iter 89000, loss: 0.242378
 >> iter 90000, loss: 0.204240
   Number of active neurons: 6
 >> iter 91000, loss: 0.191917
 >> iter 92000, loss: 0.266657
 >> iter 93000, loss: 0.296815
 >> iter 94000, loss: 0.225542
 >> iter 95000, loss: 0.286085
 >> iter 96000, loss: 0.190294
 >> iter 97000, loss: 0.246599
 >> iter 98000, loss: 0.280241
 >> iter 99000, loss: 0.287536
 >> iter 100000, loss: 0.206559
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.851572
 >> iter 2000, loss: 10.087861
 >> iter 3000, loss: 6.277857
 >> iter 4000, loss: 3.186233
 >> iter 5000, loss: 1.625720
 >> iter 6000, loss: 0.904935
 >> iter 7000, loss: 0.658434
 >> iter 8000, loss: 0.683266
 >> iter 9000, loss: 0.564669
 >> iter 10000, loss: 0.573487
   Number of active neurons: 6
 >> iter 11000, loss: 0.551179
 >> iter 12000, loss: 0.355693
 >> iter 13000, loss: 0.404706
 >> iter 14000, loss: 0.466089
 >> iter 15000, loss: 0.405746
 >> iter 16000, loss: 0.407124
 >> iter 17000, loss: 0.372397
 >> iter 18000, loss: 0.356115
 >> iter 19000, loss: 0.398139
 >> iter 20000, loss: 0.307775
   Number of active neurons: 6
 >> iter 21000, loss: 0.293134
 >> iter 22000, loss: 0.277896
 >> iter 23000, loss: 0.374195
 >> iter 24000, loss: 0.295575
 >> iter 25000, loss: 0.366229
 >> iter 26000, loss: 0.307825
 >> iter 27000, loss: 0.321177
 >> iter 28000, loss: 0.387139
 >> iter 29000, loss: 0.352079
 >> iter 30000, loss: 0.235216
   Number of active neurons: 6
 >> iter 31000, loss: 0.238843
 >> iter 32000, loss: 0.304279
 >> iter 33000, loss: 0.262651
 >> iter 34000, loss: 0.367620
 >> iter 35000, loss: 0.341144
 >> iter 36000, loss: 0.313234
 >> iter 37000, loss: 0.387152
 >> iter 38000, loss: 0.356778
 >> iter 39000, loss: 0.397813
 >> iter 40000, loss: 0.409397
   Number of active neurons: 6
 >> iter 41000, loss: 0.424896
 >> iter 42000, loss: 0.440133
 >> iter 43000, loss: 0.328849
 >> iter 44000, loss: 0.261478
 >> iter 45000, loss: 0.292582
 >> iter 46000, loss: 0.216540
 >> iter 47000, loss: 0.308198
 >> iter 48000, loss: 0.259025
 >> iter 49000, loss: 0.219881
 >> iter 50000, loss: 0.301458
   Number of active neurons: 6
 >> iter 51000, loss: 0.292727
 >> iter 52000, loss: 0.239904
 >> iter 53000, loss: 0.329593
 >> iter 54000, loss: 0.355865
 >> iter 55000, loss: 0.320900
 >> iter 56000, loss: 0.322707
 >> iter 57000, loss: 0.252936
 >> iter 58000, loss: 0.419543
 >> iter 59000, loss: 0.377552
 >> iter 60000, loss: 0.255828
   Number of active neurons: 6
 >> iter 61000, loss: 0.220496
 >> iter 62000, loss: 0.358469
 >> iter 63000, loss: 0.375783
 >> iter 64000, loss: 0.358460
 >> iter 65000, loss: 0.323923
 >> iter 66000, loss: 0.345115
 >> iter 67000, loss: 0.393519
 >> iter 68000, loss: 0.302715
 >> iter 69000, loss: 0.339168
 >> iter 70000, loss: 0.382180
   Number of active neurons: 6
 >> iter 71000, loss: 0.400391
 >> iter 72000, loss: 0.384953
 >> iter 73000, loss: 0.353967
 >> iter 74000, loss: 0.324496
 >> iter 75000, loss: 0.422241
 >> iter 76000, loss: 0.364876
 >> iter 77000, loss: 0.347444
 >> iter 78000, loss: 0.383081
 >> iter 79000, loss: 0.490480
 >> iter 80000, loss: 0.360088
   Number of active neurons: 6
 >> iter 81000, loss: 0.338472
 >> iter 82000, loss: 0.434548
 >> iter 83000, loss: 0.426121
 >> iter 84000, loss: 0.375254
 >> iter 85000, loss: 0.341653
 >> iter 86000, loss: 0.347199
 >> iter 87000, loss: 0.316940
 >> iter 88000, loss: 0.296551
 >> iter 89000, loss: 0.253070
 >> iter 90000, loss: 0.321852
   Number of active neurons: 6
 >> iter 91000, loss: 0.289984
 >> iter 92000, loss: 0.323886
 >> iter 93000, loss: 0.395493
 >> iter 94000, loss: 0.314739
 >> iter 95000, loss: 0.356317
 >> iter 96000, loss: 0.313628
 >> iter 97000, loss: 0.396201
 >> iter 98000, loss: 0.319357
 >> iter 99000, loss: 0.289290
 >> iter 100000, loss: 0.374672
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.224123
 >> iter 2000, loss: 10.961297
 >> iter 3000, loss: 7.323054
 >> iter 4000, loss: 3.843416
 >> iter 5000, loss: 1.886256
 >> iter 6000, loss: 1.091081
 >> iter 7000, loss: 0.614926
 >> iter 8000, loss: 0.514403
 >> iter 9000, loss: 0.423054
 >> iter 10000, loss: 0.357797
   Number of active neurons: 11
 >> iter 11000, loss: 0.272798
 >> iter 12000, loss: 0.284290
 >> iter 13000, loss: 0.220145
 >> iter 14000, loss: 0.323193
 >> iter 15000, loss: 0.337246
 >> iter 16000, loss: 0.343808
 >> iter 17000, loss: 0.367912
 >> iter 18000, loss: 0.339067
 >> iter 19000, loss: 0.292385
 >> iter 20000, loss: 0.223519
   Number of active neurons: 10
 >> iter 21000, loss: 0.231596
 >> iter 22000, loss: 0.373199
 >> iter 23000, loss: 0.417291
 >> iter 24000, loss: 0.295075
 >> iter 25000, loss: 0.270818
 >> iter 26000, loss: 0.292630
 >> iter 27000, loss: 0.239451
 >> iter 28000, loss: 0.245140
 >> iter 29000, loss: 0.354847
 >> iter 30000, loss: 0.221309
   Number of active neurons: 10
 >> iter 31000, loss: 0.204666
 >> iter 32000, loss: 0.176257
 >> iter 33000, loss: 0.221221
 >> iter 34000, loss: 0.225114
 >> iter 35000, loss: 0.247066
 >> iter 36000, loss: 0.326600
 >> iter 37000, loss: 0.255606
 >> iter 38000, loss: 0.257810
 >> iter 39000, loss: 0.278335
 >> iter 40000, loss: 0.256371
   Number of active neurons: 10
 >> iter 41000, loss: 0.320950
 >> iter 42000, loss: 0.389017
 >> iter 43000, loss: 0.329565
 >> iter 44000, loss: 0.345972
 >> iter 45000, loss: 0.384972
 >> iter 46000, loss: 0.262785
 >> iter 47000, loss: 0.327244
 >> iter 48000, loss: 0.250170
 >> iter 49000, loss: 0.358192
 >> iter 50000, loss: 0.243678
   Number of active neurons: 10
 >> iter 51000, loss: 0.583593
 >> iter 52000, loss: 0.398185
 >> iter 53000, loss: 0.333284
 >> iter 54000, loss: 0.282629
 >> iter 55000, loss: 0.269914
 >> iter 56000, loss: 0.334786
 >> iter 57000, loss: 0.422948
 >> iter 58000, loss: 0.310631
 >> iter 59000, loss: 0.262251
 >> iter 60000, loss: 0.337487
   Number of active neurons: 10
 >> iter 61000, loss: 0.375653
 >> iter 62000, loss: 0.319824
 >> iter 63000, loss: 0.289022
 >> iter 64000, loss: 0.363713
 >> iter 65000, loss: 0.398587
 >> iter 66000, loss: 0.339423
 >> iter 67000, loss: 0.305228
 >> iter 68000, loss: 0.322952
 >> iter 69000, loss: 0.350639
 >> iter 70000, loss: 0.267280
   Number of active neurons: 10
 >> iter 71000, loss: 0.313708
 >> iter 72000, loss: 0.316218
 >> iter 73000, loss: 0.372095
 >> iter 74000, loss: 0.270152
 >> iter 75000, loss: 0.251536
 >> iter 76000, loss: 0.244833
 >> iter 77000, loss: 0.303799
 >> iter 78000, loss: 0.349558
 >> iter 79000, loss: 0.309893
 >> iter 80000, loss: 0.276515
   Number of active neurons: 10
 >> iter 81000, loss: 0.209327
 >> iter 82000, loss: 0.286952
 >> iter 83000, loss: 0.276829
 >> iter 84000, loss: 0.290219
 >> iter 85000, loss: 0.406952
 >> iter 86000, loss: 0.280097
 >> iter 87000, loss: 0.218648
 >> iter 88000, loss: 0.315312
 >> iter 89000, loss: 0.311392
 >> iter 90000, loss: 0.367259
   Number of active neurons: 10
 >> iter 91000, loss: 0.306332
 >> iter 92000, loss: 0.356684
 >> iter 93000, loss: 0.325868
 >> iter 94000, loss: 0.387070
 >> iter 95000, loss: 0.411711
 >> iter 96000, loss: 0.397341
 >> iter 97000, loss: 0.298460
 >> iter 98000, loss: 0.262783
 >> iter 99000, loss: 0.201900
 >> iter 100000, loss: 0.291333
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.158964
 >> iter 2000, loss: 10.121997
 >> iter 3000, loss: 5.669818
 >> iter 4000, loss: 2.770765
 >> iter 5000, loss: 1.253149
 >> iter 6000, loss: 0.794361
 >> iter 7000, loss: 0.594032
 >> iter 8000, loss: 0.437807
 >> iter 9000, loss: 0.366353
 >> iter 10000, loss: 0.405074
   Number of active neurons: 14
 >> iter 11000, loss: 0.270550
 >> iter 12000, loss: 0.463957
 >> iter 13000, loss: 0.404370
 >> iter 14000, loss: 0.323454
 >> iter 15000, loss: 0.483039
 >> iter 16000, loss: 0.310287
 >> iter 17000, loss: 0.324259
 >> iter 18000, loss: 0.448003
 >> iter 19000, loss: 0.443274
 >> iter 20000, loss: 0.289071
   Number of active neurons: 11
 >> iter 21000, loss: 0.381915
 >> iter 22000, loss: 0.344494
 >> iter 23000, loss: 0.333967
 >> iter 24000, loss: 0.384484
 >> iter 25000, loss: 0.365886
 >> iter 26000, loss: 0.368072
 >> iter 27000, loss: 0.347241
 >> iter 28000, loss: 0.419328
 >> iter 29000, loss: 0.380654
 >> iter 30000, loss: 0.335618
   Number of active neurons: 10
 >> iter 31000, loss: 0.352526
 >> iter 32000, loss: 0.351368
 >> iter 33000, loss: 0.370174
 >> iter 34000, loss: 0.295332
 >> iter 35000, loss: 0.255523
 >> iter 36000, loss: 0.411677
 >> iter 37000, loss: 0.312011
 >> iter 38000, loss: 0.428971
 >> iter 39000, loss: 0.407485
 >> iter 40000, loss: 0.402457
   Number of active neurons: 9
 >> iter 41000, loss: 0.272233
 >> iter 42000, loss: 0.286305
 >> iter 43000, loss: 0.295941
 >> iter 44000, loss: 0.338136
 >> iter 45000, loss: 0.340459
 >> iter 46000, loss: 0.353819
 >> iter 47000, loss: 0.486521
 >> iter 48000, loss: 0.332394
 >> iter 49000, loss: 0.260493
 >> iter 50000, loss: 0.320686
   Number of active neurons: 7
 >> iter 51000, loss: 0.349760
 >> iter 52000, loss: 0.289031
 >> iter 53000, loss: 0.295173
 >> iter 54000, loss: 0.303659
 >> iter 55000, loss: 0.296940
 >> iter 56000, loss: 0.320569
 >> iter 57000, loss: 0.287632
 >> iter 58000, loss: 0.294266
 >> iter 59000, loss: 0.225595
 >> iter 60000, loss: 0.169686
   Number of active neurons: 7
 >> iter 61000, loss: 0.321227
 >> iter 62000, loss: 0.254963
 >> iter 63000, loss: 0.333032
 >> iter 64000, loss: 0.269704
 >> iter 65000, loss: 0.209635
 >> iter 66000, loss: 0.289985
 >> iter 67000, loss: 0.206992
 >> iter 68000, loss: 0.254234
 >> iter 69000, loss: 0.241153
 >> iter 70000, loss: 0.220557
   Number of active neurons: 7
 >> iter 71000, loss: 0.231168
 >> iter 72000, loss: 0.323692
 >> iter 73000, loss: 0.327816
 >> iter 74000, loss: 0.417147
 >> iter 75000, loss: 0.408949
 >> iter 76000, loss: 0.360224
 >> iter 77000, loss: 0.316791
 >> iter 78000, loss: 0.235953
 >> iter 79000, loss: 0.213453
 >> iter 80000, loss: 0.220705
   Number of active neurons: 6
 >> iter 81000, loss: 0.237586
 >> iter 82000, loss: 0.237098
 >> iter 83000, loss: 0.359704
 >> iter 84000, loss: 0.234054
 >> iter 85000, loss: 0.258698
 >> iter 86000, loss: 0.255858
 >> iter 87000, loss: 0.243204
 >> iter 88000, loss: 0.327106
 >> iter 89000, loss: 0.263631
 >> iter 90000, loss: 0.294075
   Number of active neurons: 6
 >> iter 91000, loss: 0.243157
 >> iter 92000, loss: 0.443260
 >> iter 93000, loss: 0.265859
 >> iter 94000, loss: 0.179303
 >> iter 95000, loss: 0.321645
 >> iter 96000, loss: 0.248979
 >> iter 97000, loss: 0.313350
 >> iter 98000, loss: 0.312842
 >> iter 99000, loss: 0.411185
 >> iter 100000, loss: 0.317224
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

