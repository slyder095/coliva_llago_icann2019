 > Problema: tomita3nueva
 > Args:
   - Hidden size: 6
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.901067
 >> iter 2000, loss: 11.804442
 >> iter 3000, loss: 5.562526
 >> iter 4000, loss: 2.715639
 >> iter 5000, loss: 1.299402
 >> iter 6000, loss: 0.822282
 >> iter 7000, loss: 0.538768
 >> iter 8000, loss: 0.449419
 >> iter 9000, loss: 0.514930
 >> iter 10000, loss: 0.415598
   Number of active neurons: 4
 >> iter 11000, loss: 0.298234
 >> iter 12000, loss: 0.218488
 >> iter 13000, loss: 0.243172
 >> iter 14000, loss: 0.438089
 >> iter 15000, loss: 0.728345
 >> iter 16000, loss: 0.431005
 >> iter 17000, loss: 0.363402
 >> iter 18000, loss: 0.315266
 >> iter 19000, loss: 0.530999
 >> iter 20000, loss: 0.375658
   Number of active neurons: 4
 >> iter 21000, loss: 0.347429
 >> iter 22000, loss: 0.636138
 >> iter 23000, loss: 0.469091
 >> iter 24000, loss: 0.386339
 >> iter 25000, loss: 0.380995
 >> iter 26000, loss: 0.292625
 >> iter 27000, loss: 0.444224
 >> iter 28000, loss: 0.409618
 >> iter 29000, loss: 0.422094
 >> iter 30000, loss: 0.559413
   Number of active neurons: 4
 >> iter 31000, loss: 0.365620
 >> iter 32000, loss: 0.554259
 >> iter 33000, loss: 0.513912
 >> iter 34000, loss: 0.394542
 >> iter 35000, loss: 0.362433
 >> iter 36000, loss: 0.449186
 >> iter 37000, loss: 0.536474
 >> iter 38000, loss: 0.421580
 >> iter 39000, loss: 0.629286
 >> iter 40000, loss: 0.558597
   Number of active neurons: 4
 >> iter 41000, loss: 0.549540
 >> iter 42000, loss: 0.406337
 >> iter 43000, loss: 0.340387
 >> iter 44000, loss: 0.384093
 >> iter 45000, loss: 0.369441
 >> iter 46000, loss: 0.417295
 >> iter 47000, loss: 0.411524
 >> iter 48000, loss: 0.402316
 >> iter 49000, loss: 0.409310
 >> iter 50000, loss: 0.390559
   Number of active neurons: 4
 >> iter 51000, loss: 0.476042
 >> iter 52000, loss: 0.367809
 >> iter 53000, loss: 0.376232
 >> iter 54000, loss: 0.354461
 >> iter 55000, loss: 0.434259
 >> iter 56000, loss: 0.462293
 >> iter 57000, loss: 0.579243
 >> iter 58000, loss: 0.409286
 >> iter 59000, loss: 0.372438
 >> iter 60000, loss: 0.298050
   Number of active neurons: 4
 >> iter 61000, loss: 0.411382
 >> iter 62000, loss: 0.404016
 >> iter 63000, loss: 0.446957
 >> iter 64000, loss: 0.306943
 >> iter 65000, loss: 0.302738
 >> iter 66000, loss: 0.364248
 >> iter 67000, loss: 0.566455
 >> iter 68000, loss: 0.443533
 >> iter 69000, loss: 0.294147
 >> iter 70000, loss: 0.437634
   Number of active neurons: 4
 >> iter 71000, loss: 0.365899
 >> iter 72000, loss: 0.497359
 >> iter 73000, loss: 0.310561
 >> iter 74000, loss: 0.334530
 >> iter 75000, loss: 0.317918
 >> iter 76000, loss: 0.239598
 >> iter 77000, loss: 0.263851
 >> iter 78000, loss: 0.253415
 >> iter 79000, loss: 0.255927
 >> iter 80000, loss: 0.314739
   Number of active neurons: 4
 >> iter 81000, loss: 0.462470
 >> iter 82000, loss: 0.384069
 >> iter 83000, loss: 0.333899
 >> iter 84000, loss: 0.393317
 >> iter 85000, loss: 0.271959
 >> iter 86000, loss: 0.218984
 >> iter 87000, loss: 0.661479
 >> iter 88000, loss: 0.355634
 >> iter 89000, loss: 0.273682
 >> iter 90000, loss: 0.229076
   Number of active neurons: 4
 >> iter 91000, loss: 0.335327
 >> iter 92000, loss: 0.250085
 >> iter 93000, loss: 0.325830
 >> iter 94000, loss: 0.312830
 >> iter 95000, loss: 0.356079
 >> iter 96000, loss: 0.288031
 >> iter 97000, loss: 0.405727
 >> iter 98000, loss: 0.303269
 >> iter 99000, loss: 0.354148
 >> iter 100000, loss: 0.363393
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 12.6124925005
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.156185
 >> iter 2000, loss: 12.212590
 >> iter 3000, loss: 6.158069
 >> iter 4000, loss: 3.089421
 >> iter 5000, loss: 1.643459
 >> iter 6000, loss: 0.808662
 >> iter 7000, loss: 0.686479
 >> iter 8000, loss: 0.473117
 >> iter 9000, loss: 0.343151
 >> iter 10000, loss: 0.390744
   Number of active neurons: 6
 >> iter 11000, loss: 0.395796
 >> iter 12000, loss: 0.522711
 >> iter 13000, loss: 0.406194
 >> iter 14000, loss: 0.298203
 >> iter 15000, loss: 0.433319
 >> iter 16000, loss: 0.448197
 >> iter 17000, loss: 0.310060
 >> iter 18000, loss: 0.367472
 >> iter 19000, loss: 0.344716
 >> iter 20000, loss: 0.312763
   Number of active neurons: 6
 >> iter 21000, loss: 0.428215
 >> iter 22000, loss: 0.386522
 >> iter 23000, loss: 0.444781
 >> iter 24000, loss: 0.397487
 >> iter 25000, loss: 0.390241
 >> iter 26000, loss: 0.288710
 >> iter 27000, loss: 0.328554
 >> iter 28000, loss: 0.446809
 >> iter 29000, loss: 0.407795
 >> iter 30000, loss: 0.520377
   Number of active neurons: 6
 >> iter 31000, loss: 0.528966
 >> iter 32000, loss: 0.436285
 >> iter 33000, loss: 0.442618
 >> iter 34000, loss: 0.508764
 >> iter 35000, loss: 0.591216
 >> iter 36000, loss: 0.446207
 >> iter 37000, loss: 0.373584
 >> iter 38000, loss: 0.334514
 >> iter 39000, loss: 0.283172
 >> iter 40000, loss: 0.213060
   Number of active neurons: 6
 >> iter 41000, loss: 0.438664
 >> iter 42000, loss: 0.345413
 >> iter 43000, loss: 0.332293
 >> iter 44000, loss: 0.418367
 >> iter 45000, loss: 0.445097
 >> iter 46000, loss: 0.426063
 >> iter 47000, loss: 0.339867
 >> iter 48000, loss: 0.445110
 >> iter 49000, loss: 0.274760
 >> iter 50000, loss: 0.311173
   Number of active neurons: 4
 >> iter 51000, loss: 0.327122
 >> iter 52000, loss: 0.421115
 >> iter 53000, loss: 0.398734
 >> iter 54000, loss: 0.407455
 >> iter 55000, loss: 0.391929
 >> iter 56000, loss: 0.380532
 >> iter 57000, loss: 0.395224
 >> iter 58000, loss: 0.291434
 >> iter 59000, loss: 0.267059
 >> iter 60000, loss: 0.436738
   Number of active neurons: 4
 >> iter 61000, loss: 0.469946
 >> iter 62000, loss: 0.507558
 >> iter 63000, loss: 0.514272
 >> iter 64000, loss: 0.459983
 >> iter 65000, loss: 0.468572
 >> iter 66000, loss: 0.371677
 >> iter 67000, loss: 0.347156
 >> iter 68000, loss: 0.357941
 >> iter 69000, loss: 0.435884
 >> iter 70000, loss: 0.388555
   Number of active neurons: 4
 >> iter 71000, loss: 0.285786
 >> iter 72000, loss: 0.393859
 >> iter 73000, loss: 0.409386
 >> iter 74000, loss: 0.449832
 >> iter 75000, loss: 0.407320
 >> iter 76000, loss: 0.339815
 >> iter 77000, loss: 0.380637
 >> iter 78000, loss: 0.646843
 >> iter 79000, loss: 0.458399
 >> iter 80000, loss: 0.417632
   Number of active neurons: 4
 >> iter 81000, loss: 0.379985
 >> iter 82000, loss: 0.339748
 >> iter 83000, loss: 0.370645
 >> iter 84000, loss: 0.382874
 >> iter 85000, loss: 0.360750
 >> iter 86000, loss: 0.352731
 >> iter 87000, loss: 0.398154
 >> iter 88000, loss: 0.268090
 >> iter 89000, loss: 0.305165
 >> iter 90000, loss: 0.328381
   Number of active neurons: 4
 >> iter 91000, loss: 0.317396
 >> iter 92000, loss: 0.221655
 >> iter 93000, loss: 0.328865
 >> iter 94000, loss: 0.320997
 >> iter 95000, loss: 0.285252
 >> iter 96000, loss: 0.279112
 >> iter 97000, loss: 0.383667
 >> iter 98000, loss: 0.403915
 >> iter 99000, loss: 0.311790
 >> iter 100000, loss: 0.250830
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.536942
 >> iter 2000, loss: 14.226371
 >> iter 3000, loss: 11.724918
 >> iter 4000, loss: 10.581345
 >> iter 5000, loss: 10.194431
 >> iter 6000, loss: 9.689390
 >> iter 7000, loss: 9.580607
 >> iter 8000, loss: 6.983879
 >> iter 9000, loss: 5.321291
 >> iter 10000, loss: 3.893944
   Number of active neurons: 6
 >> iter 11000, loss: 2.676588
 >> iter 12000, loss: 1.593831
 >> iter 13000, loss: 1.079721
 >> iter 14000, loss: 0.598067
 >> iter 15000, loss: 0.457749
 >> iter 16000, loss: 0.494898
 >> iter 17000, loss: 0.354454
 >> iter 18000, loss: 0.290894
 >> iter 19000, loss: 0.559955
 >> iter 20000, loss: 0.438788
   Number of active neurons: 6
 >> iter 21000, loss: 0.370374
 >> iter 22000, loss: 0.324098
 >> iter 23000, loss: 0.316997
 >> iter 24000, loss: 0.467037
 >> iter 25000, loss: 0.351760
 >> iter 26000, loss: 0.336705
 >> iter 27000, loss: 0.264073
 >> iter 28000, loss: 0.273464
 >> iter 29000, loss: 0.313885
 >> iter 30000, loss: 0.302941
   Number of active neurons: 6
 >> iter 31000, loss: 0.263924
 >> iter 32000, loss: 0.317515
 >> iter 33000, loss: 0.345771
 >> iter 34000, loss: 0.394614
 >> iter 35000, loss: 0.450857
 >> iter 36000, loss: 0.404247
 >> iter 37000, loss: 0.308406
 >> iter 38000, loss: 0.444092
 >> iter 39000, loss: 0.479529
 >> iter 40000, loss: 0.371322
   Number of active neurons: 5
 >> iter 41000, loss: 0.332009
 >> iter 42000, loss: 0.435092
 >> iter 43000, loss: 0.489750
 >> iter 44000, loss: 0.360509
 >> iter 45000, loss: 0.344143
 >> iter 46000, loss: 0.384772
 >> iter 47000, loss: 0.389687
 >> iter 48000, loss: 0.467635
 >> iter 49000, loss: 0.512990
 >> iter 50000, loss: 0.408305
   Number of active neurons: 4
 >> iter 51000, loss: 0.375475
 >> iter 52000, loss: 0.390413
 >> iter 53000, loss: 0.267765
 >> iter 54000, loss: 0.388502
 >> iter 55000, loss: 0.335640
 >> iter 56000, loss: 0.424457
 >> iter 57000, loss: 0.422753
 >> iter 58000, loss: 0.394713
 >> iter 59000, loss: 0.342577
 >> iter 60000, loss: 0.343904
   Number of active neurons: 4
 >> iter 61000, loss: 0.514252
 >> iter 62000, loss: 0.516104
 >> iter 63000, loss: 0.337499
 >> iter 64000, loss: 0.306046
 >> iter 65000, loss: 0.450521
 >> iter 66000, loss: 0.346792
 >> iter 67000, loss: 0.470041
 >> iter 68000, loss: 0.482572
 >> iter 69000, loss: 0.527540
 >> iter 70000, loss: 0.464772
   Number of active neurons: 4
 >> iter 71000, loss: 0.495296
 >> iter 72000, loss: 0.327486
 >> iter 73000, loss: 0.469211
 >> iter 74000, loss: 0.305852
 >> iter 75000, loss: 0.390288
 >> iter 76000, loss: 0.484614
 >> iter 77000, loss: 0.351026
 >> iter 78000, loss: 0.369389
 >> iter 79000, loss: 0.373218
 >> iter 80000, loss: 0.367875
   Number of active neurons: 4
 >> iter 81000, loss: 0.771816
 >> iter 82000, loss: 0.649930
 >> iter 83000, loss: 0.756243
 >> iter 84000, loss: 0.529083
 >> iter 85000, loss: 0.397259
 >> iter 86000, loss: 0.339717
 >> iter 87000, loss: 0.568812
 >> iter 88000, loss: 0.456173
 >> iter 89000, loss: 0.523335
 >> iter 90000, loss: 0.392186
   Number of active neurons: 4
 >> iter 91000, loss: 0.391864
 >> iter 92000, loss: 0.399245
 >> iter 93000, loss: 0.416312
 >> iter 94000, loss: 0.398345
 >> iter 95000, loss: 0.454033
 >> iter 96000, loss: 0.355226
 >> iter 97000, loss: 0.479663
 >> iter 98000, loss: 0.379248
 >> iter 99000, loss: 0.376990
 >> iter 100000, loss: 0.398847
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.299143
 >> iter 2000, loss: 11.121350
 >> iter 3000, loss: 5.280190
 >> iter 4000, loss: 2.616562
 >> iter 5000, loss: 1.674697
 >> iter 6000, loss: 0.871445
 >> iter 7000, loss: 0.558144
 >> iter 8000, loss: 0.484912
 >> iter 9000, loss: 0.376885
 >> iter 10000, loss: 0.530931
   Number of active neurons: 5
 >> iter 11000, loss: 0.542619
 >> iter 12000, loss: 0.426388
 >> iter 13000, loss: 0.373967
 >> iter 14000, loss: 0.265929
 >> iter 15000, loss: 0.386147
 >> iter 16000, loss: 0.396768
 >> iter 17000, loss: 0.337432
 >> iter 18000, loss: 0.349749
 >> iter 19000, loss: 0.494272
 >> iter 20000, loss: 0.327080
   Number of active neurons: 5
 >> iter 21000, loss: 0.442902
 >> iter 22000, loss: 0.415944
 >> iter 23000, loss: 0.604379
 >> iter 24000, loss: 0.372989
 >> iter 25000, loss: 0.289394
 >> iter 26000, loss: 0.245652
 >> iter 27000, loss: 0.286166
 >> iter 28000, loss: 0.292654
 >> iter 29000, loss: 0.322373
 >> iter 30000, loss: 0.336928
   Number of active neurons: 5
 >> iter 31000, loss: 0.230612
 >> iter 32000, loss: 0.226104
 >> iter 33000, loss: 0.151485
 >> iter 34000, loss: 0.165905
 >> iter 35000, loss: 0.355209
 >> iter 36000, loss: 0.323137
 >> iter 37000, loss: 0.320173
 >> iter 38000, loss: 0.336771
 >> iter 39000, loss: 0.238960
 >> iter 40000, loss: 0.150772
   Number of active neurons: 5
 >> iter 41000, loss: 0.192670
 >> iter 42000, loss: 0.288708
 >> iter 43000, loss: 0.191122
 >> iter 44000, loss: 0.177753
 >> iter 45000, loss: 0.210431
 >> iter 46000, loss: 0.223512
 >> iter 47000, loss: 0.188225
 >> iter 48000, loss: 0.152850
 >> iter 49000, loss: 0.357216
 >> iter 50000, loss: 0.252041
   Number of active neurons: 4
 >> iter 51000, loss: 0.168190
 >> iter 52000, loss: 0.204136
 >> iter 53000, loss: 0.222541
 >> iter 54000, loss: 0.240250
 >> iter 55000, loss: 0.207536
 >> iter 56000, loss: 0.212251
 >> iter 57000, loss: 0.124391
 >> iter 58000, loss: 0.192246
 >> iter 59000, loss: 0.333874
 >> iter 60000, loss: 0.270179
   Number of active neurons: 4
 >> iter 61000, loss: 0.329461
 >> iter 62000, loss: 0.209010
 >> iter 63000, loss: 0.336634
 >> iter 64000, loss: 0.263005
 >> iter 65000, loss: 0.154038
 >> iter 66000, loss: 0.149223
 >> iter 67000, loss: 0.237613
 >> iter 68000, loss: 0.211089
 >> iter 69000, loss: 0.197857
 >> iter 70000, loss: 0.150579
   Number of active neurons: 4
 >> iter 71000, loss: 0.268189
 >> iter 72000, loss: 0.314437
 >> iter 73000, loss: 0.292569
 >> iter 74000, loss: 0.252539
 >> iter 75000, loss: 0.239991
 >> iter 76000, loss: 0.277854
 >> iter 77000, loss: 0.215510
 >> iter 78000, loss: 0.149842
 >> iter 79000, loss: 0.211938
 >> iter 80000, loss: 0.205255
   Number of active neurons: 4
 >> iter 81000, loss: 0.260415
 >> iter 82000, loss: 0.186462
 >> iter 83000, loss: 0.278405
 >> iter 84000, loss: 0.360600
 >> iter 85000, loss: 0.259211
 >> iter 86000, loss: 0.174842
 >> iter 87000, loss: 0.243215
 >> iter 88000, loss: 0.153732
 >> iter 89000, loss: 0.193272
 >> iter 90000, loss: 0.154998
   Number of active neurons: 4
 >> iter 91000, loss: 0.228604
 >> iter 92000, loss: 0.201128
 >> iter 93000, loss: 0.406084
 >> iter 94000, loss: 0.234263
 >> iter 95000, loss: 0.317154
 >> iter 96000, loss: 0.239729
 >> iter 97000, loss: 0.203479
 >> iter 98000, loss: 0.164290
 >> iter 99000, loss: 0.162155
 >> iter 100000, loss: 0.213362
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.219954
 >> iter 2000, loss: 13.051547
 >> iter 3000, loss: 10.077073
 >> iter 4000, loss: 8.711082
 >> iter 5000, loss: 8.583912
 >> iter 6000, loss: 8.131303
 >> iter 7000, loss: 8.173400
 >> iter 8000, loss: 8.068532
 >> iter 9000, loss: 8.064668
 >> iter 10000, loss: 7.857505
   Number of active neurons: 3
 >> iter 11000, loss: 6.137900
 >> iter 12000, loss: 4.213229
 >> iter 13000, loss: 2.731673
 >> iter 14000, loss: 1.644498
 >> iter 15000, loss: 0.882971
 >> iter 16000, loss: 0.817832
 >> iter 17000, loss: 0.709690
 >> iter 18000, loss: 0.579172
 >> iter 19000, loss: 0.482560
 >> iter 20000, loss: 0.490074
   Number of active neurons: 4
 >> iter 21000, loss: 0.549750
 >> iter 22000, loss: 0.650065
 >> iter 23000, loss: 0.451590
 >> iter 24000, loss: 0.631448
 >> iter 25000, loss: 0.467406
 >> iter 26000, loss: 0.510729
 >> iter 27000, loss: 0.501612
 >> iter 28000, loss: 0.506138
 >> iter 29000, loss: 0.599337
 >> iter 30000, loss: 0.446746
   Number of active neurons: 5
 >> iter 31000, loss: 0.382959
 >> iter 32000, loss: 0.352020
 >> iter 33000, loss: 0.420736
 >> iter 34000, loss: 0.424022
 >> iter 35000, loss: 0.321400
 >> iter 36000, loss: 0.495991
 >> iter 37000, loss: 0.553019
 >> iter 38000, loss: 0.446961
 >> iter 39000, loss: 0.373440
 >> iter 40000, loss: 0.446477
   Number of active neurons: 5
 >> iter 41000, loss: 0.411867
 >> iter 42000, loss: 0.319309
 >> iter 43000, loss: 0.362675
 >> iter 44000, loss: 0.444222
 >> iter 45000, loss: 0.413948
 >> iter 46000, loss: 0.498105
 >> iter 47000, loss: 0.544088
 >> iter 48000, loss: 0.461580
 >> iter 49000, loss: 0.585146
 >> iter 50000, loss: 0.416609
   Number of active neurons: 5
 >> iter 51000, loss: 0.416342
 >> iter 52000, loss: 0.407890
 >> iter 53000, loss: 0.464365
 >> iter 54000, loss: 0.467921
 >> iter 55000, loss: 0.344460
 >> iter 56000, loss: 0.221842
 >> iter 57000, loss: 0.416002
 >> iter 58000, loss: 0.296606
 >> iter 59000, loss: 0.367808
 >> iter 60000, loss: 0.456063
   Number of active neurons: 5
 >> iter 61000, loss: 0.281418
 >> iter 62000, loss: 0.324044
 >> iter 63000, loss: 0.320281
 >> iter 64000, loss: 0.222590
 >> iter 65000, loss: 0.372245
 >> iter 66000, loss: 0.343298
 >> iter 67000, loss: 0.316653
 >> iter 68000, loss: 0.360771
 >> iter 69000, loss: 0.423544
 >> iter 70000, loss: 0.355732
   Number of active neurons: 5
 >> iter 71000, loss: 0.318531
 >> iter 72000, loss: 0.289202
 >> iter 73000, loss: 0.195449
 >> iter 74000, loss: 0.261232
 >> iter 75000, loss: 0.359274
 >> iter 76000, loss: 0.387233
 >> iter 77000, loss: 0.377029
 >> iter 78000, loss: 0.385164
 >> iter 79000, loss: 0.453864
 >> iter 80000, loss: 0.508131
   Number of active neurons: 5
 >> iter 81000, loss: 0.427985
 >> iter 82000, loss: 0.425794
 >> iter 83000, loss: 0.355513
 >> iter 84000, loss: 0.454967
 >> iter 85000, loss: 0.386534
 >> iter 86000, loss: 0.393176
 >> iter 87000, loss: 0.361575
 >> iter 88000, loss: 0.347043
 >> iter 89000, loss: 0.351471
 >> iter 90000, loss: 0.371965
   Number of active neurons: 5
 >> iter 91000, loss: 0.441066
 >> iter 92000, loss: 0.573994
 >> iter 93000, loss: 0.559569
 >> iter 94000, loss: 0.337567
 >> iter 95000, loss: 0.274303
 >> iter 96000, loss: 0.406740
 >> iter 97000, loss: 0.431387
 >> iter 98000, loss: 0.378773
 >> iter 99000, loss: 0.324275
 >> iter 100000, loss: 0.404178
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.272531
 >> iter 2000, loss: 14.196974
 >> iter 3000, loss: 11.465594
 >> iter 4000, loss: 10.204167
 >> iter 5000, loss: 9.367548
 >> iter 6000, loss: 8.522170
 >> iter 7000, loss: 8.358441
 >> iter 8000, loss: 8.054945
 >> iter 9000, loss: 8.057207
 >> iter 10000, loss: 7.578212
   Number of active neurons: 3
 >> iter 11000, loss: 6.113760
 >> iter 12000, loss: 4.116997
 >> iter 13000, loss: 3.294037
 >> iter 14000, loss: 2.828077
 >> iter 15000, loss: 2.626180
 >> iter 16000, loss: 2.465075
 >> iter 17000, loss: 2.545373
 >> iter 18000, loss: 2.419508
 >> iter 19000, loss: 2.469680
 >> iter 20000, loss: 2.360533
   Number of active neurons: 3
 >> iter 21000, loss: 2.334338
 >> iter 22000, loss: 2.342468
 >> iter 23000, loss: 2.403995
 >> iter 24000, loss: 2.360731
 >> iter 25000, loss: 2.332374
 >> iter 26000, loss: 2.485751
 >> iter 27000, loss: 2.571571
 >> iter 28000, loss: 2.372081
 >> iter 29000, loss: 2.269066
 >> iter 30000, loss: 2.352425
   Number of active neurons: 5
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 5
 >> iter 31000, loss: 2.372815
 >> iter 32000, loss: 2.135818
 >> iter 33000, loss: 1.210542
 >> iter 34000, loss: 0.846399
 >> iter 35000, loss: 0.516300
 >> iter 36000, loss: 0.433322
 >> iter 37000, loss: 0.641067
 >> iter 38000, loss: 0.418137
 >> iter 39000, loss: 0.422320
 >> iter 40000, loss: 0.417938
   Number of active neurons: 6
 >> iter 41000, loss: 0.355873
 >> iter 42000, loss: 0.268845
 >> iter 43000, loss: 0.471305
 >> iter 44000, loss: 0.388531
 >> iter 45000, loss: 0.257788
 >> iter 46000, loss: 0.259774
 >> iter 47000, loss: 0.481516
 >> iter 48000, loss: 0.443337
 >> iter 49000, loss: 0.261820
 >> iter 50000, loss: 0.386425
   Number of active neurons: 5
 >> iter 51000, loss: 0.411393
 >> iter 52000, loss: 0.403498
 >> iter 53000, loss: 0.305508
 >> iter 54000, loss: 0.361332
 >> iter 55000, loss: 0.465761
 >> iter 56000, loss: 0.609014
 >> iter 57000, loss: 0.554834
 >> iter 58000, loss: 0.413725
 >> iter 59000, loss: 0.370161
 >> iter 60000, loss: 0.366836
   Number of active neurons: 5
 >> iter 61000, loss: 0.436823
 >> iter 62000, loss: 0.449342
 >> iter 63000, loss: 0.333499
 >> iter 64000, loss: 0.463503
 >> iter 65000, loss: 0.420009
 >> iter 66000, loss: 0.330854
 >> iter 67000, loss: 0.461658
 >> iter 68000, loss: 0.418109
 >> iter 69000, loss: 0.355500
 >> iter 70000, loss: 0.319669
   Number of active neurons: 4
 >> iter 71000, loss: 0.381356
 >> iter 72000, loss: 0.398361
 >> iter 73000, loss: 0.283064
 >> iter 74000, loss: 0.310935
 >> iter 75000, loss: 0.310169
 >> iter 76000, loss: 0.271376
 >> iter 77000, loss: 0.433932
 >> iter 78000, loss: 0.424139
 >> iter 79000, loss: 0.340682
 >> iter 80000, loss: 0.321020
   Number of active neurons: 4
 >> iter 81000, loss: 0.358856
 >> iter 82000, loss: 0.439772
 >> iter 83000, loss: 0.400998
 >> iter 84000, loss: 0.303280
 >> iter 85000, loss: 0.359151
 >> iter 86000, loss: 0.333115
 >> iter 87000, loss: 0.466820
 >> iter 88000, loss: 0.289249
 >> iter 89000, loss: 0.440544
 >> iter 90000, loss: 0.342655
   Number of active neurons: 4
 >> iter 91000, loss: 0.416202
 >> iter 92000, loss: 0.352642
 >> iter 93000, loss: 0.399817
 >> iter 94000, loss: 0.443018
 >> iter 95000, loss: 0.380160
 >> iter 96000, loss: 0.397845
 >> iter 97000, loss: 0.290764
 >> iter 98000, loss: 0.345906
 >> iter 99000, loss: 0.526999
 >> iter 100000, loss: 0.504902
   Number of active neurons: 4
 >> iter 101000, loss: 0.438065
 >> iter 102000, loss: 0.474500
 >> iter 103000, loss: 0.398437
 >> iter 104000, loss: 0.363259
 >> iter 105000, loss: 0.472206
 >> iter 106000, loss: 0.326966
 >> iter 107000, loss: 0.429982
 >> iter 108000, loss: 0.271775
 >> iter 109000, loss: 0.333284
 >> iter 110000, loss: 0.478085
   Number of active neurons: 4
 >> iter 111000, loss: 0.407030
 >> iter 112000, loss: 0.343479
 >> iter 113000, loss: 0.331968
 >> iter 114000, loss: 0.351714
 >> iter 115000, loss: 0.291020
 >> iter 116000, loss: 0.231366
 >> iter 117000, loss: 0.244099
 >> iter 118000, loss: 0.306692
 >> iter 119000, loss: 0.350169
 >> iter 120000, loss: 0.475744
   Number of active neurons: 4
 >> iter 121000, loss: 0.498548
 >> iter 122000, loss: 0.419648
 >> iter 123000, loss: 0.396718
 >> iter 124000, loss: 0.352066
 >> iter 125000, loss: 0.324575
 >> iter 126000, loss: 0.243683
 >> iter 127000, loss: 0.331197
 >> iter 128000, loss: 0.323403
 >> iter 129000, loss: 0.297019
 >> iter 130000, loss: 0.372140
   Number of active neurons: 4
 >> iter 131000, loss: 0.471821
 >> iter 132000, loss: 0.314749
 >> iter 133000, loss: 0.367289
 >> iter 134000, loss: 0.372176
 >> iter 135000, loss: 0.407009
 >> iter 136000, loss: 0.410428
 >> iter 137000, loss: 0.410095
 >> iter 138000, loss: 0.362673
 >> iter 139000, loss: 0.316041
 >> iter 140000, loss: 0.336936
   Number of active neurons: 4
 >> iter 141000, loss: 0.344303
 >> iter 142000, loss: 0.232467
 >> iter 143000, loss: 0.340346
 >> iter 144000, loss: 0.349301
 >> iter 145000, loss: 0.557634
 >> iter 146000, loss: 0.510464
 >> iter 147000, loss: 0.651452
 >> iter 148000, loss: 0.536045
 >> iter 149000, loss: 0.346754
 >> iter 150000, loss: 0.249855
   Number of active neurons: 4
 >> iter 151000, loss: 0.299493
 >> iter 152000, loss: 0.306737
 >> iter 153000, loss: 0.513795
 >> iter 154000, loss: 0.478850
 >> iter 155000, loss: 0.343522
 >> iter 156000, loss: 0.290473
 >> iter 157000, loss: 0.248691
 >> iter 158000, loss: 0.291990
 >> iter 159000, loss: 0.391055
 >> iter 160000, loss: 0.416998
   Number of active neurons: 4
 >> iter 161000, loss: 0.364294
 >> iter 162000, loss: 0.428468
 >> iter 163000, loss: 0.532238
 >> iter 164000, loss: 0.380663
 >> iter 165000, loss: 0.266766
 >> iter 166000, loss: 0.257262
 >> iter 167000, loss: 0.271220
 >> iter 168000, loss: 0.465663
 >> iter 169000, loss: 0.475896
 >> iter 170000, loss: 0.347435
   Number of active neurons: 4
 >> iter 171000, loss: 0.301345
 >> iter 172000, loss: 0.332280
 >> iter 173000, loss: 0.520601
 >> iter 174000, loss: 0.394786
 >> iter 175000, loss: 0.493401
 >> iter 176000, loss: 0.349869
 >> iter 177000, loss: 0.324850
 >> iter 178000, loss: 0.417016
 >> iter 179000, loss: 0.361783
 >> iter 180000, loss: 0.377779
   Number of active neurons: 4
 >> iter 181000, loss: 0.390026
 >> iter 182000, loss: 0.360009
 >> iter 183000, loss: 0.414663
 >> iter 184000, loss: 0.337482
 >> iter 185000, loss: 0.392039
 >> iter 186000, loss: 0.362465
 >> iter 187000, loss: 0.500729
 >> iter 188000, loss: 0.348996
 >> iter 189000, loss: 0.462107
 >> iter 190000, loss: 0.338627
   Number of active neurons: 4
 >> iter 191000, loss: 0.351406
 >> iter 192000, loss: 0.373177
 >> iter 193000, loss: 0.344949
 >> iter 194000, loss: 0.348040
 >> iter 195000, loss: 0.294793
 >> iter 196000, loss: 0.338858
 >> iter 197000, loss: 0.567360
 >> iter 198000, loss: 0.470167
 >> iter 199000, loss: 0.423341
 >> iter 200000, loss: 0.326684
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.011525
 >> iter 2000, loss: 13.978871
 >> iter 3000, loss: 8.369061
 >> iter 4000, loss: 4.905382
 >> iter 5000, loss: 3.142840
 >> iter 6000, loss: 2.436290
 >> iter 7000, loss: 1.746361
 >> iter 8000, loss: 1.269302
 >> iter 9000, loss: 1.261026
 >> iter 10000, loss: 1.220894
   Number of active neurons: 5
 >> iter 11000, loss: 1.427331
 >> iter 12000, loss: 1.073807
 >> iter 13000, loss: 0.822884
 >> iter 14000, loss: 0.851881
 >> iter 15000, loss: 1.050167
 >> iter 16000, loss: 0.982847
 >> iter 17000, loss: 1.002135
 >> iter 18000, loss: 0.843706
 >> iter 19000, loss: 0.878834
 >> iter 20000, loss: 0.850599
   Number of active neurons: 5
 >> iter 21000, loss: 0.824957
 >> iter 22000, loss: 0.786477
 >> iter 23000, loss: 0.787367
 >> iter 24000, loss: 0.690108
 >> iter 25000, loss: 0.674530
 >> iter 26000, loss: 0.728019
 >> iter 27000, loss: 0.715640
 >> iter 28000, loss: 0.829693
 >> iter 29000, loss: 1.134265
 >> iter 30000, loss: 0.808664
   Number of active neurons: 5
 >> iter 31000, loss: 0.775750
 >> iter 32000, loss: 0.691687
 >> iter 33000, loss: 0.795315
 >> iter 34000, loss: 0.648519
 >> iter 35000, loss: 0.912340
 >> iter 36000, loss: 0.770170
 >> iter 37000, loss: 0.820856
 >> iter 38000, loss: 0.698793
 >> iter 39000, loss: 0.780731
 >> iter 40000, loss: 0.848528
   Number of active neurons: 5
 >> iter 41000, loss: 0.990268
 >> iter 42000, loss: 0.797289
 >> iter 43000, loss: 1.023368
 >> iter 44000, loss: 0.928501
 >> iter 45000, loss: 0.960176
 >> iter 46000, loss: 0.757468
 >> iter 47000, loss: 0.759683
 >> iter 48000, loss: 0.814096
 >> iter 49000, loss: 0.714274
 >> iter 50000, loss: 0.718502
   Number of active neurons: 5
 >> iter 51000, loss: 0.851970
 >> iter 52000, loss: 0.867394
 >> iter 53000, loss: 0.765344
 >> iter 54000, loss: 0.647507
 >> iter 55000, loss: 0.976991
 >> iter 56000, loss: 0.806017
 >> iter 57000, loss: 0.744892
 >> iter 58000, loss: 0.573624
 >> iter 59000, loss: 0.795327
 >> iter 60000, loss: 0.911281
   Number of active neurons: 6
 >> iter 61000, loss: 0.984712
 >> iter 62000, loss: 0.785766
 >> iter 63000, loss: 0.681586
 >> iter 64000, loss: 0.728509
 >> iter 65000, loss: 0.816398
 >> iter 66000, loss: 0.804320
 >> iter 67000, loss: 0.818942
 >> iter 68000, loss: 0.655958
 >> iter 69000, loss: 0.830043
 >> iter 70000, loss: 0.712578
   Number of active neurons: 5
 >> iter 71000, loss: 0.504470
 >> iter 72000, loss: 0.435839
 >> iter 73000, loss: 0.687174
 >> iter 74000, loss: 0.698062
 >> iter 75000, loss: 0.642376
 >> iter 76000, loss: 0.798700
 >> iter 77000, loss: 0.733637
 >> iter 78000, loss: 0.647156
 >> iter 79000, loss: 0.501621
 >> iter 80000, loss: 0.829254
   Number of active neurons: 5
 >> iter 81000, loss: 0.823028
 >> iter 82000, loss: 0.755712
 >> iter 83000, loss: 0.764937
 >> iter 84000, loss: 0.627860
 >> iter 85000, loss: 0.830298
 >> iter 86000, loss: 0.752711
 >> iter 87000, loss: 1.257307
 >> iter 88000, loss: 0.973756
 >> iter 89000, loss: 1.144349
 >> iter 90000, loss: 1.027710
   Number of active neurons: 6
 >> iter 91000, loss: 0.826457
 >> iter 92000, loss: 0.697054
 >> iter 93000, loss: 0.646678
 >> iter 94000, loss: 0.558547
 >> iter 95000, loss: 0.553007
 >> iter 96000, loss: 0.688201
 >> iter 97000, loss: 0.744722
 >> iter 98000, loss: 0.662556
 >> iter 99000, loss: 0.638364
 >> iter 100000, loss: 0.775652
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.278871
 >> iter 2000, loss: 15.368140
 >> iter 3000, loss: 12.466096
 >> iter 4000, loss: 7.559575
 >> iter 5000, loss: 4.320632
 >> iter 6000, loss: 2.410881
 >> iter 7000, loss: 1.369003
 >> iter 8000, loss: 0.682189
 >> iter 9000, loss: 0.593576
 >> iter 10000, loss: 0.451217
   Number of active neurons: 5
 >> iter 11000, loss: 0.321217
 >> iter 12000, loss: 0.444453
 >> iter 13000, loss: 0.282009
 >> iter 14000, loss: 0.224627
 >> iter 15000, loss: 0.358307
 >> iter 16000, loss: 0.214577
 >> iter 17000, loss: 0.285442
 >> iter 18000, loss: 0.288816
 >> iter 19000, loss: 0.227451
 >> iter 20000, loss: 0.314675
   Number of active neurons: 5
 >> iter 21000, loss: 0.351767
 >> iter 22000, loss: 0.280093
 >> iter 23000, loss: 0.239641
 >> iter 24000, loss: 0.285785
 >> iter 25000, loss: 0.178801
 >> iter 26000, loss: 0.225485
 >> iter 27000, loss: 0.276278
 >> iter 28000, loss: 0.334680
 >> iter 29000, loss: 0.436131
 >> iter 30000, loss: 0.439322
   Number of active neurons: 5
 >> iter 31000, loss: 0.298604
 >> iter 32000, loss: 0.211608
 >> iter 33000, loss: 0.237465
 >> iter 34000, loss: 0.402262
 >> iter 35000, loss: 0.458327
 >> iter 36000, loss: 0.370080
 >> iter 37000, loss: 0.329900
 >> iter 38000, loss: 0.291584
 >> iter 39000, loss: 0.338185
 >> iter 40000, loss: 0.509556
   Number of active neurons: 5
 >> iter 41000, loss: 0.368964
 >> iter 42000, loss: 0.350718
 >> iter 43000, loss: 0.272029
 >> iter 44000, loss: 0.308283
 >> iter 45000, loss: 0.404115
 >> iter 46000, loss: 0.351378
 >> iter 47000, loss: 0.254540
 >> iter 48000, loss: 0.274241
 >> iter 49000, loss: 0.532152
 >> iter 50000, loss: 0.316637
   Number of active neurons: 5
 >> iter 51000, loss: 0.328195
 >> iter 52000, loss: 0.238846
 >> iter 53000, loss: 0.272491
 >> iter 54000, loss: 0.258047
 >> iter 55000, loss: 0.351332
 >> iter 56000, loss: 0.195548
 >> iter 57000, loss: 0.274327
 >> iter 58000, loss: 0.285898
 >> iter 59000, loss: 0.266075
 >> iter 60000, loss: 0.275202
   Number of active neurons: 5
 >> iter 61000, loss: 0.198808
 >> iter 62000, loss: 0.253976
 >> iter 63000, loss: 0.190614
 >> iter 64000, loss: 0.173350
 >> iter 65000, loss: 0.259298
 >> iter 66000, loss: 0.217167
 >> iter 67000, loss: 0.134325
 >> iter 68000, loss: 0.206350
 >> iter 69000, loss: 0.405450
 >> iter 70000, loss: 0.205380
   Number of active neurons: 5
 >> iter 71000, loss: 0.236721
 >> iter 72000, loss: 0.142188
 >> iter 73000, loss: 0.122765
 >> iter 74000, loss: 0.240486
 >> iter 75000, loss: 0.344591
 >> iter 76000, loss: 0.273450
 >> iter 77000, loss: 0.508713
 >> iter 78000, loss: 0.309135
 >> iter 79000, loss: 0.269045
 >> iter 80000, loss: 0.214750
   Number of active neurons: 5
 >> iter 81000, loss: 0.322525
 >> iter 82000, loss: 0.329870
 >> iter 83000, loss: 0.247760
 >> iter 84000, loss: 0.269844
 >> iter 85000, loss: 0.140324
 >> iter 86000, loss: 0.220941
 >> iter 87000, loss: 0.249244
 >> iter 88000, loss: 0.210259
 >> iter 89000, loss: 0.285646
 >> iter 90000, loss: 0.176363
   Number of active neurons: 5
 >> iter 91000, loss: 0.150383
 >> iter 92000, loss: 0.231179
 >> iter 93000, loss: 0.165251
 >> iter 94000, loss: 0.287595
 >> iter 95000, loss: 0.176393
 >> iter 96000, loss: 0.217057
 >> iter 97000, loss: 0.288497
 >> iter 98000, loss: 0.256177
 >> iter 99000, loss: 0.164384
 >> iter 100000, loss: 0.176970
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.175557
 >> iter 2000, loss: 12.022293
 >> iter 3000, loss: 6.728099
 >> iter 4000, loss: 4.454048
 >> iter 5000, loss: 3.026587
 >> iter 6000, loss: 1.967349
 >> iter 7000, loss: 1.460140
 >> iter 8000, loss: 1.096150
 >> iter 9000, loss: 0.974045
 >> iter 10000, loss: 0.846514
   Number of active neurons: 4
 >> iter 11000, loss: 0.897020
 >> iter 12000, loss: 0.922308
 >> iter 13000, loss: 0.786304
 >> iter 14000, loss: 0.704974
 >> iter 15000, loss: 0.723137
 >> iter 16000, loss: 0.820557
 >> iter 17000, loss: 0.688771
 >> iter 18000, loss: 0.676559
 >> iter 19000, loss: 0.618605
 >> iter 20000, loss: 0.515165
   Number of active neurons: 4
 >> iter 21000, loss: 0.755962
 >> iter 22000, loss: 0.596793
 >> iter 23000, loss: 0.713490
 >> iter 24000, loss: 0.567594
 >> iter 25000, loss: 0.542128
 >> iter 26000, loss: 0.647748
 >> iter 27000, loss: 0.570732
 >> iter 28000, loss: 0.546281
 >> iter 29000, loss: 0.443551
 >> iter 30000, loss: 0.567272
   Number of active neurons: 4
 >> iter 31000, loss: 0.547905
 >> iter 32000, loss: 0.567642
 >> iter 33000, loss: 0.498363
 >> iter 34000, loss: 0.380642
 >> iter 35000, loss: 0.360599
 >> iter 36000, loss: 0.391721
 >> iter 37000, loss: 0.453329
 >> iter 38000, loss: 0.370108
 >> iter 39000, loss: 0.449300
 >> iter 40000, loss: 0.517875
   Number of active neurons: 4
 >> iter 41000, loss: 0.481453
 >> iter 42000, loss: 0.420394
 >> iter 43000, loss: 0.456962
 >> iter 44000, loss: 0.482802
 >> iter 45000, loss: 0.501782
 >> iter 46000, loss: 0.625525
 >> iter 47000, loss: 0.547010
 >> iter 48000, loss: 0.564162
 >> iter 49000, loss: 0.553705
 >> iter 50000, loss: 0.676707
   Number of active neurons: 4
 >> iter 51000, loss: 0.804678
 >> iter 52000, loss: 0.480630
 >> iter 53000, loss: 0.695874
 >> iter 54000, loss: 0.656476
 >> iter 55000, loss: 0.547397
 >> iter 56000, loss: 0.627584
 >> iter 57000, loss: 0.703459
 >> iter 58000, loss: 0.558523
 >> iter 59000, loss: 0.468209
 >> iter 60000, loss: 0.526198
   Number of active neurons: 5
 >> iter 61000, loss: 0.491884
 >> iter 62000, loss: 0.742065
 >> iter 63000, loss: 0.924866
 >> iter 64000, loss: 0.760423
 >> iter 65000, loss: 0.668642
 >> iter 66000, loss: 0.620707
 >> iter 67000, loss: 0.457160
 >> iter 68000, loss: 0.512795
 >> iter 69000, loss: 0.488215
 >> iter 70000, loss: 0.576263
   Number of active neurons: 5
 >> iter 71000, loss: 0.549343
 >> iter 72000, loss: 0.627521
 >> iter 73000, loss: 0.502900
 >> iter 74000, loss: 0.493739
 >> iter 75000, loss: 0.416962
 >> iter 76000, loss: 0.504946
 >> iter 77000, loss: 0.412991
 >> iter 78000, loss: 0.452608
 >> iter 79000, loss: 0.611109
 >> iter 80000, loss: 0.668424
   Number of active neurons: 5
 >> iter 81000, loss: 0.752238
 >> iter 82000, loss: 0.596968
 >> iter 83000, loss: 0.537497
 >> iter 84000, loss: 0.532354
 >> iter 85000, loss: 0.566180
 >> iter 86000, loss: 0.551545
 >> iter 87000, loss: 0.610208
 >> iter 88000, loss: 0.465866
 >> iter 89000, loss: 0.454180
 >> iter 90000, loss: 0.466058
   Number of active neurons: 5
 >> iter 91000, loss: 0.758066
 >> iter 92000, loss: 0.546833
 >> iter 93000, loss: 0.425817
 >> iter 94000, loss: 0.389234
 >> iter 95000, loss: 0.529938
 >> iter 96000, loss: 0.463412
 >> iter 97000, loss: 0.472794
 >> iter 98000, loss: 0.325747
 >> iter 99000, loss: 0.375623
 >> iter 100000, loss: 0.365046
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.147997040059
   - Test - Long: 0.009999500025
   - Test - Big: 0.127998720013
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.428692
 >> iter 2000, loss: 15.774073
 >> iter 3000, loss: 14.661683
 >> iter 4000, loss: 13.418865
 >> iter 5000, loss: 11.764004
 >> iter 6000, loss: 10.775091
 >> iter 7000, loss: 9.107541
 >> iter 8000, loss: 6.593919
 >> iter 9000, loss: 5.377462
 >> iter 10000, loss: 4.148600
   Number of active neurons: 5
 >> iter 11000, loss: 3.356995
 >> iter 12000, loss: 2.849104
 >> iter 13000, loss: 2.732491
 >> iter 14000, loss: 2.500783
 >> iter 15000, loss: 2.566145
 >> iter 16000, loss: 2.471813
 >> iter 17000, loss: 2.467000
 >> iter 18000, loss: 2.442069
 >> iter 19000, loss: 2.444397
 >> iter 20000, loss: 2.471987
   Number of active neurons: 5
 >> iter 21000, loss: 2.506020
 >> iter 22000, loss: 2.356355
 >> iter 23000, loss: 2.502951
 >> iter 24000, loss: 2.449645
 >> iter 25000, loss: 2.334328
 >> iter 26000, loss: 2.295462
 >> iter 27000, loss: 2.527975
 >> iter 28000, loss: 2.504205
 >> iter 29000, loss: 2.406899
 >> iter 30000, loss: 2.295402
   Number of active neurons: 5
 >> iter 31000, loss: 2.353798
 >> iter 32000, loss: 2.335203
 >> iter 33000, loss: 2.391377
 >> iter 34000, loss: 2.291155
 >> iter 35000, loss: 2.386182
   Number of active neurons: 5
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 36000, loss: 2.384479
 >> iter 37000, loss: 2.380298
 >> iter 38000, loss: 2.493993
 >> iter 39000, loss: 2.369966
 >> iter 40000, loss: 1.195296
   Number of active neurons: 6
 >> iter 41000, loss: 0.710759
 >> iter 42000, loss: 0.772686
 >> iter 43000, loss: 0.553853
 >> iter 44000, loss: 0.568375
 >> iter 45000, loss: 0.496702
 >> iter 46000, loss: 0.331579
 >> iter 47000, loss: 0.396902
 >> iter 48000, loss: 0.388817
 >> iter 49000, loss: 0.281581
 >> iter 50000, loss: 0.314475
   Number of active neurons: 6
 >> iter 51000, loss: 0.294296
 >> iter 52000, loss: 0.520951
 >> iter 53000, loss: 0.378646
 >> iter 54000, loss: 0.430861
 >> iter 55000, loss: 0.358405
 >> iter 56000, loss: 0.511344
 >> iter 57000, loss: 0.451318
 >> iter 58000, loss: 0.414923
 >> iter 59000, loss: 0.503595
 >> iter 60000, loss: 0.385611
   Number of active neurons: 6
 >> iter 61000, loss: 0.506096
 >> iter 62000, loss: 0.311725
 >> iter 63000, loss: 0.485134
 >> iter 64000, loss: 0.480097
 >> iter 65000, loss: 0.481738
 >> iter 66000, loss: 0.406100
 >> iter 67000, loss: 0.638273
 >> iter 68000, loss: 0.441841
 >> iter 69000, loss: 0.445773
 >> iter 70000, loss: 0.528831
   Number of active neurons: 6
 >> iter 71000, loss: 0.453320
 >> iter 72000, loss: 0.461014
 >> iter 73000, loss: 0.427454
 >> iter 74000, loss: 0.403396
 >> iter 75000, loss: 0.391838
 >> iter 76000, loss: 0.382788
 >> iter 77000, loss: 0.306427
 >> iter 78000, loss: 0.449345
 >> iter 79000, loss: 0.406825
 >> iter 80000, loss: 0.579557
   Number of active neurons: 5
 >> iter 81000, loss: 0.535563
 >> iter 82000, loss: 0.541485
 >> iter 83000, loss: 0.432287
 >> iter 84000, loss: 0.380431
 >> iter 85000, loss: 0.349280
 >> iter 86000, loss: 0.364556
 >> iter 87000, loss: 0.444408
 >> iter 88000, loss: 0.407626
 >> iter 89000, loss: 0.531403
 >> iter 90000, loss: 0.446133
   Number of active neurons: 5
 >> iter 91000, loss: 0.596391
 >> iter 92000, loss: 0.498712
 >> iter 93000, loss: 0.487730
 >> iter 94000, loss: 0.373422
 >> iter 95000, loss: 0.317461
 >> iter 96000, loss: 0.374032
 >> iter 97000, loss: 0.374478
 >> iter 98000, loss: 0.266408
 >> iter 99000, loss: 0.264680
 >> iter 100000, loss: 0.330712
   Number of active neurons: 5
 >> iter 101000, loss: 0.324653
 >> iter 102000, loss: 0.359800
 >> iter 103000, loss: 0.254414
 >> iter 104000, loss: 0.330911
 >> iter 105000, loss: 0.318917
 >> iter 106000, loss: 0.316103
 >> iter 107000, loss: 0.314569
 >> iter 108000, loss: 0.303579
 >> iter 109000, loss: 0.247816
 >> iter 110000, loss: 0.411027
   Number of active neurons: 5
 >> iter 111000, loss: 0.274261
 >> iter 112000, loss: 0.199736
 >> iter 113000, loss: 0.245148
 >> iter 114000, loss: 0.273277
 >> iter 115000, loss: 0.228394
 >> iter 116000, loss: 0.246848
 >> iter 117000, loss: 0.394692
 >> iter 118000, loss: 0.286666
 >> iter 119000, loss: 0.476323
 >> iter 120000, loss: 0.447381
   Number of active neurons: 5
 >> iter 121000, loss: 0.430243
 >> iter 122000, loss: 0.418420
 >> iter 123000, loss: 0.345554
 >> iter 124000, loss: 0.454252
 >> iter 125000, loss: 0.372528
 >> iter 126000, loss: 0.385834
 >> iter 127000, loss: 0.315632
 >> iter 128000, loss: 0.259610
 >> iter 129000, loss: 0.413137
 >> iter 130000, loss: 0.318439
   Number of active neurons: 4
 >> iter 131000, loss: 0.413940
 >> iter 132000, loss: 0.453556
 >> iter 133000, loss: 0.445647
 >> iter 134000, loss: 0.322011
 >> iter 135000, loss: 0.341856
 >> iter 136000, loss: 0.198445
 >> iter 137000, loss: 0.277547
 >> iter 138000, loss: 0.405730
 >> iter 139000, loss: 0.512351
 >> iter 140000, loss: 0.442738
   Number of active neurons: 4
 >> iter 141000, loss: 0.709183
 >> iter 142000, loss: 0.497666
 >> iter 143000, loss: 0.513246
 >> iter 144000, loss: 0.472147
 >> iter 145000, loss: 0.500622
 >> iter 146000, loss: 0.418662
 >> iter 147000, loss: 0.277838
 >> iter 148000, loss: 0.353015
 >> iter 149000, loss: 0.559949
 >> iter 150000, loss: 0.538236
   Number of active neurons: 4
 >> iter 151000, loss: 0.472349
 >> iter 152000, loss: 0.498853
 >> iter 153000, loss: 0.532272
 >> iter 154000, loss: 0.346461
 >> iter 155000, loss: 0.317326
 >> iter 156000, loss: 0.394641
 >> iter 157000, loss: 0.365231
 >> iter 158000, loss: 0.532986
 >> iter 159000, loss: 0.448978
 >> iter 160000, loss: 0.532460
   Number of active neurons: 4
 >> iter 161000, loss: 0.430236
 >> iter 162000, loss: 0.395683
 >> iter 163000, loss: 0.463942
 >> iter 164000, loss: 0.483123
 >> iter 165000, loss: 0.488397
 >> iter 166000, loss: 0.386364
 >> iter 167000, loss: 0.305490
 >> iter 168000, loss: 0.439106
 >> iter 169000, loss: 0.452126
 >> iter 170000, loss: 0.432259
   Number of active neurons: 4
 >> iter 171000, loss: 0.395017
 >> iter 172000, loss: 0.290296
 >> iter 173000, loss: 0.284709
 >> iter 174000, loss: 0.472555
 >> iter 175000, loss: 0.394723
 >> iter 176000, loss: 0.614980
 >> iter 177000, loss: 0.510161
 >> iter 178000, loss: 0.433997
 >> iter 179000, loss: 0.539863
 >> iter 180000, loss: 0.378413
   Number of active neurons: 4
 >> iter 181000, loss: 0.477360
 >> iter 182000, loss: 0.535448
 >> iter 183000, loss: 0.490429
 >> iter 184000, loss: 0.293286
 >> iter 185000, loss: 0.349226
 >> iter 186000, loss: 0.279266
 >> iter 187000, loss: 0.384494
 >> iter 188000, loss: 0.360317
 >> iter 189000, loss: 0.255780
 >> iter 190000, loss: 0.349651
   Number of active neurons: 4
 >> iter 191000, loss: 0.486914
 >> iter 192000, loss: 0.331290
 >> iter 193000, loss: 0.259281
 >> iter 194000, loss: 0.461527
 >> iter 195000, loss: 0.418805
 >> iter 196000, loss: 0.481645
 >> iter 197000, loss: 0.347006
 >> iter 198000, loss: 0.394007
 >> iter 199000, loss: 0.452874
 >> iter 200000, loss: 0.291485
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.027167
 >> iter 2000, loss: 12.863245
 >> iter 3000, loss: 9.825385
 >> iter 4000, loss: 8.435150
 >> iter 5000, loss: 8.090370
 >> iter 6000, loss: 7.803534
 >> iter 7000, loss: 7.643695
 >> iter 8000, loss: 7.188118
 >> iter 9000, loss: 6.924708
 >> iter 10000, loss: 6.631894
   Number of active neurons: 4
 >> iter 11000, loss: 6.601898
 >> iter 12000, loss: 6.446023
 >> iter 13000, loss: 6.465389
 >> iter 14000, loss: 6.341251
 >> iter 15000, loss: 6.484462
 >> iter 16000, loss: 6.414642
 >> iter 17000, loss: 5.266215
 >> iter 18000, loss: 2.723802
 >> iter 19000, loss: 1.372172
 >> iter 20000, loss: 0.800628
   Number of active neurons: 6
 >> iter 21000, loss: 0.516937
 >> iter 22000, loss: 0.447265
 >> iter 23000, loss: 0.395062
 >> iter 24000, loss: 0.447653
 >> iter 25000, loss: 0.303183
 >> iter 26000, loss: 0.379336
 >> iter 27000, loss: 0.294451
 >> iter 28000, loss: 0.403147
 >> iter 29000, loss: 0.294681
 >> iter 30000, loss: 0.258950
   Number of active neurons: 6
 >> iter 31000, loss: 0.276412
 >> iter 32000, loss: 0.414352
 >> iter 33000, loss: 0.238921
 >> iter 34000, loss: 0.259421
 >> iter 35000, loss: 0.211309
 >> iter 36000, loss: 0.204866
 >> iter 37000, loss: 0.265042
 >> iter 38000, loss: 0.270533
 >> iter 39000, loss: 0.254556
 >> iter 40000, loss: 0.245221
   Number of active neurons: 6
 >> iter 41000, loss: 0.449203
 >> iter 42000, loss: 0.297188
 >> iter 43000, loss: 0.300189
 >> iter 44000, loss: 0.291673
 >> iter 45000, loss: 0.395118
 >> iter 46000, loss: 0.247919
 >> iter 47000, loss: 0.196965
 >> iter 48000, loss: 0.311425
 >> iter 49000, loss: 0.276342
 >> iter 50000, loss: 0.245360
   Number of active neurons: 6
 >> iter 51000, loss: 0.213309
 >> iter 52000, loss: 0.248165
 >> iter 53000, loss: 0.195925
 >> iter 54000, loss: 0.180991
 >> iter 55000, loss: 0.311178
 >> iter 56000, loss: 0.249288
 >> iter 57000, loss: 0.261238
 >> iter 58000, loss: 0.261443
 >> iter 59000, loss: 0.337543
 >> iter 60000, loss: 0.238120
   Number of active neurons: 6
 >> iter 61000, loss: 0.216803
 >> iter 62000, loss: 0.215267
 >> iter 63000, loss: 0.210334
 >> iter 64000, loss: 0.162448
 >> iter 65000, loss: 0.154729
 >> iter 66000, loss: 0.173862
 >> iter 67000, loss: 0.259558
 >> iter 68000, loss: 0.290710
 >> iter 69000, loss: 0.204850
 >> iter 70000, loss: 0.238454
   Number of active neurons: 5
 >> iter 71000, loss: 0.178450
 >> iter 72000, loss: 0.240262
 >> iter 73000, loss: 0.228728
 >> iter 74000, loss: 0.306604
 >> iter 75000, loss: 0.466306
 >> iter 76000, loss: 0.394670
 >> iter 77000, loss: 0.221377
 >> iter 78000, loss: 0.165149
 >> iter 79000, loss: 0.204468
 >> iter 80000, loss: 0.198463
   Number of active neurons: 4
 >> iter 81000, loss: 0.204923
 >> iter 82000, loss: 0.199346
 >> iter 83000, loss: 0.228278
 >> iter 84000, loss: 0.207467
 >> iter 85000, loss: 0.169520
 >> iter 86000, loss: 0.231276
 >> iter 87000, loss: 0.153696
 >> iter 88000, loss: 0.179686
 >> iter 89000, loss: 0.172953
 >> iter 90000, loss: 0.222283
   Number of active neurons: 4
 >> iter 91000, loss: 0.296035
 >> iter 92000, loss: 0.305290
 >> iter 93000, loss: 0.163009
 >> iter 94000, loss: 0.251274
 >> iter 95000, loss: 0.417475
 >> iter 96000, loss: 0.211284
 >> iter 97000, loss: 0.203897
 >> iter 98000, loss: 0.149916
 >> iter 99000, loss: 0.389082
 >> iter 100000, loss: 0.358474
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.006515
 >> iter 2000, loss: 12.621387
 >> iter 3000, loss: 8.925518
 >> iter 4000, loss: 6.494400
 >> iter 5000, loss: 5.408727
 >> iter 6000, loss: 4.182104
 >> iter 7000, loss: 2.877697
 >> iter 8000, loss: 2.086058
 >> iter 9000, loss: 1.558891
 >> iter 10000, loss: 1.544084
   Number of active neurons: 6
 >> iter 11000, loss: 1.089179
 >> iter 12000, loss: 0.685634
 >> iter 13000, loss: 1.295729
 >> iter 14000, loss: 0.970699
 >> iter 15000, loss: 0.805014
 >> iter 16000, loss: 0.739705
 >> iter 17000, loss: 0.626074
 >> iter 18000, loss: 0.500633
 >> iter 19000, loss: 0.542705
 >> iter 20000, loss: 0.475266
   Number of active neurons: 6
 >> iter 21000, loss: 0.441968
 >> iter 22000, loss: 0.449167
 >> iter 23000, loss: 0.684949
 >> iter 24000, loss: 0.430557
 >> iter 25000, loss: 0.467691
 >> iter 26000, loss: 0.834626
 >> iter 27000, loss: 0.676777
 >> iter 28000, loss: 0.598155
 >> iter 29000, loss: 0.626403
 >> iter 30000, loss: 0.613316
   Number of active neurons: 6
 >> iter 31000, loss: 0.483266
 >> iter 32000, loss: 0.381118
 >> iter 33000, loss: 0.400257
 >> iter 34000, loss: 0.531107
 >> iter 35000, loss: 0.688221
 >> iter 36000, loss: 0.652807
 >> iter 37000, loss: 0.636211
 >> iter 38000, loss: 0.440764
 >> iter 39000, loss: 0.554854
 >> iter 40000, loss: 0.504989
   Number of active neurons: 6
 >> iter 41000, loss: 0.561003
 >> iter 42000, loss: 0.846886
 >> iter 43000, loss: 0.712815
 >> iter 44000, loss: 0.644128
 >> iter 45000, loss: 0.609117
 >> iter 46000, loss: 0.556121
 >> iter 47000, loss: 0.647008
 >> iter 48000, loss: 0.510277
 >> iter 49000, loss: 0.459332
 >> iter 50000, loss: 0.452867
   Number of active neurons: 6
 >> iter 51000, loss: 0.710937
 >> iter 52000, loss: 0.558015
 >> iter 53000, loss: 0.616402
 >> iter 54000, loss: 0.536130
 >> iter 55000, loss: 0.589554
 >> iter 56000, loss: 0.735502
 >> iter 57000, loss: 0.582280
 >> iter 58000, loss: 0.608648
 >> iter 59000, loss: 0.645941
 >> iter 60000, loss: 0.576905
   Number of active neurons: 6
 >> iter 61000, loss: 0.622068
 >> iter 62000, loss: 0.671412
 >> iter 63000, loss: 0.634871
 >> iter 64000, loss: 0.563056
 >> iter 65000, loss: 0.613969
 >> iter 66000, loss: 0.790441
 >> iter 67000, loss: 0.556813
 >> iter 68000, loss: 0.410258
 >> iter 69000, loss: 0.386444
 >> iter 70000, loss: 0.497594
   Number of active neurons: 6
 >> iter 71000, loss: 0.563832
 >> iter 72000, loss: 0.636378
 >> iter 73000, loss: 0.485385
 >> iter 74000, loss: 0.352054
 >> iter 75000, loss: 0.483974
 >> iter 76000, loss: 0.447313
 >> iter 77000, loss: 0.445056
 >> iter 78000, loss: 0.514222
 >> iter 79000, loss: 0.658732
 >> iter 80000, loss: 0.478631
   Number of active neurons: 6
 >> iter 81000, loss: 0.362209
 >> iter 82000, loss: 0.332042
 >> iter 83000, loss: 0.531884
 >> iter 84000, loss: 0.444970
 >> iter 85000, loss: 0.519301
 >> iter 86000, loss: 0.374043
 >> iter 87000, loss: 0.649333
 >> iter 88000, loss: 0.584486
 >> iter 89000, loss: 0.536836
 >> iter 90000, loss: 0.368804
   Number of active neurons: 6
 >> iter 91000, loss: 0.351948
 >> iter 92000, loss: 0.367344
 >> iter 93000, loss: 0.440031
 >> iter 94000, loss: 0.445796
 >> iter 95000, loss: 0.641952
 >> iter 96000, loss: 0.485654
 >> iter 97000, loss: 0.596750
 >> iter 98000, loss: 0.426667
 >> iter 99000, loss: 0.452004
 >> iter 100000, loss: 0.499255
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.345412
 >> iter 2000, loss: 15.530603
 >> iter 3000, loss: 11.410190
 >> iter 4000, loss: 7.298746
 >> iter 5000, loss: 4.758782
 >> iter 6000, loss: 3.531066
 >> iter 7000, loss: 2.960374
 >> iter 8000, loss: 2.766766
 >> iter 9000, loss: 2.563394
 >> iter 10000, loss: 2.467511
   Number of active neurons: 5
 >> iter 11000, loss: 2.391319
 >> iter 12000, loss: 2.332832
 >> iter 13000, loss: 2.449874
 >> iter 14000, loss: 2.442717
 >> iter 15000, loss: 2.486793
   Number of active neurons: 5
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 2.591535
 >> iter 17000, loss: 2.372964
 >> iter 18000, loss: 2.380052
 >> iter 19000, loss: 2.349899
 >> iter 20000, loss: 2.348898
   Number of active neurons: 6
 >> iter 21000, loss: 2.430857
 >> iter 22000, loss: 2.589444
 >> iter 23000, loss: 2.527107
 >> iter 24000, loss: 1.935046
 >> iter 25000, loss: 1.598520
 >> iter 26000, loss: 1.122703
 >> iter 27000, loss: 0.954870
 >> iter 28000, loss: 0.720877
 >> iter 29000, loss: 0.703982
 >> iter 30000, loss: 0.550052
   Number of active neurons: 6
 >> iter 31000, loss: 0.535296
 >> iter 32000, loss: 0.446238
 >> iter 33000, loss: 0.397727
 >> iter 34000, loss: 0.382669
 >> iter 35000, loss: 0.278293
 >> iter 36000, loss: 0.300006
 >> iter 37000, loss: 0.295274
 >> iter 38000, loss: 0.374974
 >> iter 39000, loss: 0.389215
 >> iter 40000, loss: 0.407610
   Number of active neurons: 6
 >> iter 41000, loss: 0.584925
 >> iter 42000, loss: 0.497770
 >> iter 43000, loss: 0.402699
 >> iter 44000, loss: 0.413598
 >> iter 45000, loss: 0.506669
 >> iter 46000, loss: 0.377415
 >> iter 47000, loss: 0.338300
 >> iter 48000, loss: 0.421884
 >> iter 49000, loss: 0.358992
 >> iter 50000, loss: 0.395610
   Number of active neurons: 5
 >> iter 51000, loss: 0.368593
 >> iter 52000, loss: 0.594648
 >> iter 53000, loss: 0.469298
 >> iter 54000, loss: 0.384189
 >> iter 55000, loss: 0.392879
 >> iter 56000, loss: 0.316605
 >> iter 57000, loss: 0.358485
 >> iter 58000, loss: 0.285682
 >> iter 59000, loss: 0.327817
 >> iter 60000, loss: 0.527780
   Number of active neurons: 5
 >> iter 61000, loss: 0.584624
 >> iter 62000, loss: 0.437590
 >> iter 63000, loss: 0.479751
 >> iter 64000, loss: 0.537124
 >> iter 65000, loss: 0.419657
 >> iter 66000, loss: 0.551891
 >> iter 67000, loss: 0.485180
 >> iter 68000, loss: 0.460536
 >> iter 69000, loss: 0.419917
 >> iter 70000, loss: 0.300817
   Number of active neurons: 5
 >> iter 71000, loss: 0.274003
 >> iter 72000, loss: 0.329919
 >> iter 73000, loss: 0.228283
 >> iter 74000, loss: 0.337970
 >> iter 75000, loss: 0.544605
 >> iter 76000, loss: 0.523275
 >> iter 77000, loss: 0.485004
 >> iter 78000, loss: 0.338151
 >> iter 79000, loss: 0.506972
 >> iter 80000, loss: 0.528234
   Number of active neurons: 5
 >> iter 81000, loss: 0.312655
 >> iter 82000, loss: 0.397102
 >> iter 83000, loss: 0.288459
 >> iter 84000, loss: 0.244955
 >> iter 85000, loss: 0.408383
 >> iter 86000, loss: 0.513179
 >> iter 87000, loss: 0.465043
 >> iter 88000, loss: 0.523001
 >> iter 89000, loss: 0.596276
 >> iter 90000, loss: 0.413254
   Number of active neurons: 5
 >> iter 91000, loss: 0.401631
 >> iter 92000, loss: 0.601640
 >> iter 93000, loss: 0.501126
 >> iter 94000, loss: 0.340802
 >> iter 95000, loss: 0.577089
 >> iter 96000, loss: 0.497478
 >> iter 97000, loss: 0.480966
 >> iter 98000, loss: 0.391112
 >> iter 99000, loss: 0.405906
 >> iter 100000, loss: 0.351542
   Number of active neurons: 5
 >> iter 101000, loss: 0.372054
 >> iter 102000, loss: 0.387083
 >> iter 103000, loss: 0.732557
 >> iter 104000, loss: 0.515911
 >> iter 105000, loss: 0.812064
 >> iter 106000, loss: 0.630516
 >> iter 107000, loss: 0.435317
 >> iter 108000, loss: 0.461932
 >> iter 109000, loss: 0.443571
 >> iter 110000, loss: 0.413291
   Number of active neurons: 5
 >> iter 111000, loss: 0.403944
 >> iter 112000, loss: 0.456041
 >> iter 113000, loss: 0.472754
 >> iter 114000, loss: 0.316638
 >> iter 115000, loss: 0.496641
 >> iter 116000, loss: 0.352768
 >> iter 117000, loss: 0.469494
 >> iter 118000, loss: 0.381814
 >> iter 119000, loss: 0.404316
 >> iter 120000, loss: 0.561208
   Number of active neurons: 5
 >> iter 121000, loss: 0.537615
 >> iter 122000, loss: 0.457822
 >> iter 123000, loss: 0.377646
 >> iter 124000, loss: 0.496739
 >> iter 125000, loss: 0.404146
 >> iter 126000, loss: 0.384009
 >> iter 127000, loss: 0.408593
 >> iter 128000, loss: 0.532224
 >> iter 129000, loss: 0.445978
 >> iter 130000, loss: 0.465043
   Number of active neurons: 5
 >> iter 131000, loss: 0.355766
 >> iter 132000, loss: 0.444856
 >> iter 133000, loss: 0.528818
 >> iter 134000, loss: 0.441305
 >> iter 135000, loss: 0.442027
 >> iter 136000, loss: 0.544477
 >> iter 137000, loss: 0.474534
 >> iter 138000, loss: 0.370955
 >> iter 139000, loss: 0.377082
 >> iter 140000, loss: 0.382475
   Number of active neurons: 5
 >> iter 141000, loss: 0.380984
 >> iter 142000, loss: 0.511560
 >> iter 143000, loss: 0.647396
 >> iter 144000, loss: 0.498307
 >> iter 145000, loss: 0.347976
 >> iter 146000, loss: 0.262449
 >> iter 147000, loss: 0.287273
 >> iter 148000, loss: 0.282771
 >> iter 149000, loss: 0.477975
 >> iter 150000, loss: 0.413825
   Number of active neurons: 5
 >> iter 151000, loss: 0.513101
 >> iter 152000, loss: 0.487780
 >> iter 153000, loss: 0.446541
 >> iter 154000, loss: 0.450910
 >> iter 155000, loss: 0.552410
 >> iter 156000, loss: 0.553561
 >> iter 157000, loss: 0.415123
 >> iter 158000, loss: 0.376589
 >> iter 159000, loss: 0.435956
 >> iter 160000, loss: 0.501996
   Number of active neurons: 5
 >> iter 161000, loss: 0.529354
 >> iter 162000, loss: 0.512163
 >> iter 163000, loss: 0.402299
 >> iter 164000, loss: 0.516349
 >> iter 165000, loss: 0.348429
 >> iter 166000, loss: 0.368047
 >> iter 167000, loss: 0.411448
 >> iter 168000, loss: 0.475415
 >> iter 169000, loss: 0.588644
 >> iter 170000, loss: 0.511301
   Number of active neurons: 5
 >> iter 171000, loss: 0.402820
 >> iter 172000, loss: 0.494453
 >> iter 173000, loss: 0.325776
 >> iter 174000, loss: 0.515132
 >> iter 175000, loss: 0.552782
 >> iter 176000, loss: 0.470035
 >> iter 177000, loss: 0.711937
 >> iter 178000, loss: 0.652505
 >> iter 179000, loss: 0.438840
 >> iter 180000, loss: 0.614909
   Number of active neurons: 5
 >> iter 181000, loss: 0.461787
 >> iter 182000, loss: 0.554147
 >> iter 183000, loss: 0.487186
 >> iter 184000, loss: 0.414400
 >> iter 185000, loss: 0.399991
 >> iter 186000, loss: 0.497638
 >> iter 187000, loss: 0.339378
 >> iter 188000, loss: 0.264611
 >> iter 189000, loss: 0.352250
 >> iter 190000, loss: 0.366147
   Number of active neurons: 5
 >> iter 191000, loss: 0.407489
 >> iter 192000, loss: 0.563225
 >> iter 193000, loss: 0.592367
 >> iter 194000, loss: 0.429538
 >> iter 195000, loss: 0.452311
 >> iter 196000, loss: 0.453452
 >> iter 197000, loss: 0.477466
 >> iter 198000, loss: 0.344312
 >> iter 199000, loss: 0.347012
 >> iter 200000, loss: 0.345736
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.063300
 >> iter 2000, loss: 14.739388
 >> iter 3000, loss: 10.873841
 >> iter 4000, loss: 8.630202
 >> iter 5000, loss: 7.836390
 >> iter 6000, loss: 7.357032
 >> iter 7000, loss: 7.061759
 >> iter 8000, loss: 6.762440
 >> iter 9000, loss: 6.867195
 >> iter 10000, loss: 6.653697
   Number of active neurons: 4
 >> iter 11000, loss: 6.630411
 >> iter 12000, loss: 6.427820
 >> iter 13000, loss: 6.617595
 >> iter 14000, loss: 5.459355
 >> iter 15000, loss: 4.940444
 >> iter 16000, loss: 4.205786
 >> iter 17000, loss: 3.518176
 >> iter 18000, loss: 2.328458
 >> iter 19000, loss: 1.731044
 >> iter 20000, loss: 1.133014
   Number of active neurons: 5
 >> iter 21000, loss: 0.786078
 >> iter 22000, loss: 0.617616
 >> iter 23000, loss: 0.665451
 >> iter 24000, loss: 0.495331
 >> iter 25000, loss: 0.507614
 >> iter 26000, loss: 0.388655
 >> iter 27000, loss: 0.514188
 >> iter 28000, loss: 0.601859
 >> iter 29000, loss: 0.514454
 >> iter 30000, loss: 0.403754
   Number of active neurons: 5
 >> iter 31000, loss: 0.621154
 >> iter 32000, loss: 0.486653
 >> iter 33000, loss: 0.437049
 >> iter 34000, loss: 0.437560
 >> iter 35000, loss: 0.381734
 >> iter 36000, loss: 0.275597
 >> iter 37000, loss: 0.414993
 >> iter 38000, loss: 0.421328
 >> iter 39000, loss: 0.309368
 >> iter 40000, loss: 0.365585
   Number of active neurons: 5
 >> iter 41000, loss: 0.458559
 >> iter 42000, loss: 0.392322
 >> iter 43000, loss: 0.297168
 >> iter 44000, loss: 0.243390
 >> iter 45000, loss: 0.304942
 >> iter 46000, loss: 0.320201
 >> iter 47000, loss: 0.289865
 >> iter 48000, loss: 0.306114
 >> iter 49000, loss: 0.202538
 >> iter 50000, loss: 0.194064
   Number of active neurons: 5
 >> iter 51000, loss: 0.457268
 >> iter 52000, loss: 0.507609
 >> iter 53000, loss: 0.358411
 >> iter 54000, loss: 0.240156
 >> iter 55000, loss: 0.268646
 >> iter 56000, loss: 0.224153
 >> iter 57000, loss: 0.332299
 >> iter 58000, loss: 0.300840
 >> iter 59000, loss: 0.334619
 >> iter 60000, loss: 0.312027
   Number of active neurons: 5
 >> iter 61000, loss: 0.246112
 >> iter 62000, loss: 0.364499
 >> iter 63000, loss: 0.272280
 >> iter 64000, loss: 0.270775
 >> iter 65000, loss: 0.268406
 >> iter 66000, loss: 0.247234
 >> iter 67000, loss: 0.169380
 >> iter 68000, loss: 0.197125
 >> iter 69000, loss: 0.355600
 >> iter 70000, loss: 0.367485
   Number of active neurons: 5
 >> iter 71000, loss: 0.307406
 >> iter 72000, loss: 0.305017
 >> iter 73000, loss: 0.242833
 >> iter 74000, loss: 0.222619
 >> iter 75000, loss: 0.379119
 >> iter 76000, loss: 0.323500
 >> iter 77000, loss: 0.371835
 >> iter 78000, loss: 0.307597
 >> iter 79000, loss: 0.304440
 >> iter 80000, loss: 0.215633
   Number of active neurons: 5
 >> iter 81000, loss: 0.349689
 >> iter 82000, loss: 0.200496
 >> iter 83000, loss: 0.194478
 >> iter 84000, loss: 0.210154
 >> iter 85000, loss: 0.289553
 >> iter 86000, loss: 0.315899
 >> iter 87000, loss: 0.162427
 >> iter 88000, loss: 0.263529
 >> iter 89000, loss: 0.334707
 >> iter 90000, loss: 0.289046
   Number of active neurons: 5
 >> iter 91000, loss: 0.263366
 >> iter 92000, loss: 0.235058
 >> iter 93000, loss: 0.207537
 >> iter 94000, loss: 0.240698
 >> iter 95000, loss: 0.241695
 >> iter 96000, loss: 0.247676
 >> iter 97000, loss: 0.345172
 >> iter 98000, loss: 0.190475
 >> iter 99000, loss: 0.266548
 >> iter 100000, loss: 0.247076
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.173442
 >> iter 2000, loss: 14.410010
 >> iter 3000, loss: 12.624806
 >> iter 4000, loss: 11.584257
 >> iter 5000, loss: 10.650712
 >> iter 6000, loss: 9.532038
 >> iter 7000, loss: 9.306081
 >> iter 8000, loss: 8.922318
 >> iter 9000, loss: 9.044170
 >> iter 10000, loss: 8.859103
   Number of active neurons: 4
 >> iter 11000, loss: 8.925589
 >> iter 12000, loss: 8.630834
 >> iter 13000, loss: 8.715915
 >> iter 14000, loss: 8.372956
 >> iter 15000, loss: 8.622718
 >> iter 16000, loss: 8.368117
 >> iter 17000, loss: 8.457637
 >> iter 18000, loss: 8.157713
 >> iter 19000, loss: 8.252522
 >> iter 20000, loss: 8.031487
   Number of active neurons: 4
 >> iter 21000, loss: 8.277325
 >> iter 22000, loss: 8.037956
 >> iter 23000, loss: 8.350408
 >> iter 24000, loss: 8.193871
 >> iter 25000, loss: 8.730589
   Number of active neurons: 4
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 8.570063
 >> iter 27000, loss: 8.598808
 >> iter 28000, loss: 6.868670
 >> iter 29000, loss: 3.719819
 >> iter 30000, loss: 2.065303
   Number of active neurons: 6
 >> iter 31000, loss: 1.206812
 >> iter 32000, loss: 0.752972
 >> iter 33000, loss: 0.598256
 >> iter 34000, loss: 0.468973
 >> iter 35000, loss: 0.566013
 >> iter 36000, loss: 0.438064
 >> iter 37000, loss: 0.372120
 >> iter 38000, loss: 0.455270
 >> iter 39000, loss: 0.452860
 >> iter 40000, loss: 0.352689
   Number of active neurons: 6
 >> iter 41000, loss: 0.454189
 >> iter 42000, loss: 0.464931
 >> iter 43000, loss: 0.533659
 >> iter 44000, loss: 0.513576
 >> iter 45000, loss: 0.429118
 >> iter 46000, loss: 0.390086
 >> iter 47000, loss: 0.697372
 >> iter 48000, loss: 0.608071
 >> iter 49000, loss: 0.469699
 >> iter 50000, loss: 0.495981
   Number of active neurons: 6
 >> iter 51000, loss: 0.451489
 >> iter 52000, loss: 0.510536
 >> iter 53000, loss: 0.733586
 >> iter 54000, loss: 0.652547
 >> iter 55000, loss: 0.533225
 >> iter 56000, loss: 0.542992
 >> iter 57000, loss: 0.583909
 >> iter 58000, loss: 0.517126
 >> iter 59000, loss: 0.646216
 >> iter 60000, loss: 0.507875
   Number of active neurons: 6
 >> iter 61000, loss: 0.768393
 >> iter 62000, loss: 0.641664
 >> iter 63000, loss: 0.447485
 >> iter 64000, loss: 0.318683
 >> iter 65000, loss: 0.491436
 >> iter 66000, loss: 0.459426
 >> iter 67000, loss: 0.597685
 >> iter 68000, loss: 0.682764
 >> iter 69000, loss: 0.832833
 >> iter 70000, loss: 0.563515
   Number of active neurons: 6
 >> iter 71000, loss: 0.635685
 >> iter 72000, loss: 0.536000
 >> iter 73000, loss: 0.376777
 >> iter 74000, loss: 0.436844
 >> iter 75000, loss: 0.578863
 >> iter 76000, loss: 0.841739
 >> iter 77000, loss: 0.630057
 >> iter 78000, loss: 0.439120
 >> iter 79000, loss: 0.399539
 >> iter 80000, loss: 0.487072
   Number of active neurons: 6
 >> iter 81000, loss: 0.539807
 >> iter 82000, loss: 0.690577
 >> iter 83000, loss: 0.508618
 >> iter 84000, loss: 0.453658
 >> iter 85000, loss: 0.523393
 >> iter 86000, loss: 0.417457
 >> iter 87000, loss: 0.512776
 >> iter 88000, loss: 0.646384
 >> iter 89000, loss: 0.563829
 >> iter 90000, loss: 0.435732
   Number of active neurons: 6
 >> iter 91000, loss: 0.558652
 >> iter 92000, loss: 0.449164
 >> iter 93000, loss: 0.606533
 >> iter 94000, loss: 0.429548
 >> iter 95000, loss: 0.384941
 >> iter 96000, loss: 0.625620
 >> iter 97000, loss: 0.458886
 >> iter 98000, loss: 0.684654
 >> iter 99000, loss: 0.750944
 >> iter 100000, loss: 0.565935
   Number of active neurons: 6
 >> iter 101000, loss: 0.657032
 >> iter 102000, loss: 0.533796
 >> iter 103000, loss: 0.558007
 >> iter 104000, loss: 0.666095
 >> iter 105000, loss: 0.657410
 >> iter 106000, loss: 0.648521
 >> iter 107000, loss: 0.682674
 >> iter 108000, loss: 0.645283
 >> iter 109000, loss: 0.481757
 >> iter 110000, loss: 0.674841
   Number of active neurons: 6
 >> iter 111000, loss: 0.733498
 >> iter 112000, loss: 0.761215
 >> iter 113000, loss: 0.546936
 >> iter 114000, loss: 0.477750
 >> iter 115000, loss: 0.766130
 >> iter 116000, loss: 0.602479
 >> iter 117000, loss: 0.481670
 >> iter 118000, loss: 0.483562
 >> iter 119000, loss: 0.525710
 >> iter 120000, loss: 0.627766
   Number of active neurons: 6
 >> iter 121000, loss: 0.448647
 >> iter 122000, loss: 0.372127
 >> iter 123000, loss: 0.464485
 >> iter 124000, loss: 0.627523
 >> iter 125000, loss: 0.680399
 >> iter 126000, loss: 0.689989
 >> iter 127000, loss: 0.519781
 >> iter 128000, loss: 0.659647
 >> iter 129000, loss: 0.458827
 >> iter 130000, loss: 0.438684
   Number of active neurons: 6
 >> iter 131000, loss: 0.600589
 >> iter 132000, loss: 0.511944
 >> iter 133000, loss: 0.620722
 >> iter 134000, loss: 0.585572
 >> iter 135000, loss: 0.478224
 >> iter 136000, loss: 0.444784
 >> iter 137000, loss: 0.553822
 >> iter 138000, loss: 0.426404
 >> iter 139000, loss: 0.572703
 >> iter 140000, loss: 0.456336
   Number of active neurons: 6
 >> iter 141000, loss: 0.488701
 >> iter 142000, loss: 0.462258
 >> iter 143000, loss: 0.387167
 >> iter 144000, loss: 0.374964
 >> iter 145000, loss: 0.732268
 >> iter 146000, loss: 0.559995
 >> iter 147000, loss: 0.595426
 >> iter 148000, loss: 0.561658
 >> iter 149000, loss: 0.512406
 >> iter 150000, loss: 0.462563
   Number of active neurons: 6
 >> iter 151000, loss: 0.519667
 >> iter 152000, loss: 0.558396
 >> iter 153000, loss: 0.504829
 >> iter 154000, loss: 0.385051
 >> iter 155000, loss: 0.357054
 >> iter 156000, loss: 0.294592
 >> iter 157000, loss: 0.540216
 >> iter 158000, loss: 0.619720
 >> iter 159000, loss: 0.643023
 >> iter 160000, loss: 0.472345
   Number of active neurons: 6
 >> iter 161000, loss: 0.430507
 >> iter 162000, loss: 0.493478
 >> iter 163000, loss: 0.354255
 >> iter 164000, loss: 0.495381
 >> iter 165000, loss: 0.533080
 >> iter 166000, loss: 0.495811
 >> iter 167000, loss: 0.399588
 >> iter 168000, loss: 0.443295
 >> iter 169000, loss: 0.607436
 >> iter 170000, loss: 0.742470
   Number of active neurons: 6
 >> iter 171000, loss: 0.769350
 >> iter 172000, loss: 0.743050
 >> iter 173000, loss: 0.815717
 >> iter 174000, loss: 0.654106
 >> iter 175000, loss: 0.532408
 >> iter 176000, loss: 0.635266
 >> iter 177000, loss: 0.494038
 >> iter 178000, loss: 0.458927
 >> iter 179000, loss: 0.442204
 >> iter 180000, loss: 0.502815
   Number of active neurons: 6
 >> iter 181000, loss: 0.590673
 >> iter 182000, loss: 0.571656
 >> iter 183000, loss: 0.691621
 >> iter 184000, loss: 0.569794
 >> iter 185000, loss: 0.415053
 >> iter 186000, loss: 0.472247
 >> iter 187000, loss: 0.419040
 >> iter 188000, loss: 0.720360
 >> iter 189000, loss: 0.847273
 >> iter 190000, loss: 0.639839
   Number of active neurons: 6
 >> iter 191000, loss: 0.599643
 >> iter 192000, loss: 0.487281
 >> iter 193000, loss: 0.524622
 >> iter 194000, loss: 0.546529
 >> iter 195000, loss: 0.593555
 >> iter 196000, loss: 0.619292
 >> iter 197000, loss: 0.668577
 >> iter 198000, loss: 0.497423
 >> iter 199000, loss: 0.426517
 >> iter 200000, loss: 0.562173
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.325789
 >> iter 2000, loss: 14.040664
 >> iter 3000, loss: 11.102634
 >> iter 4000, loss: 6.913115
 >> iter 5000, loss: 3.619566
 >> iter 6000, loss: 2.130884
 >> iter 7000, loss: 1.205283
 >> iter 8000, loss: 0.803319
 >> iter 9000, loss: 0.629701
 >> iter 10000, loss: 0.512018
   Number of active neurons: 5
 >> iter 11000, loss: 0.729591
 >> iter 12000, loss: 0.507339
 >> iter 13000, loss: 0.363916
 >> iter 14000, loss: 0.461739
 >> iter 15000, loss: 0.464769
 >> iter 16000, loss: 0.422717
 >> iter 17000, loss: 0.402897
 >> iter 18000, loss: 0.401283
 >> iter 19000, loss: 0.444756
 >> iter 20000, loss: 0.300612
   Number of active neurons: 5
 >> iter 21000, loss: 0.201329
 >> iter 22000, loss: 0.430684
 >> iter 23000, loss: 0.353560
 >> iter 24000, loss: 0.350726
 >> iter 25000, loss: 0.251089
 >> iter 26000, loss: 0.469951
 >> iter 27000, loss: 0.323474
 >> iter 28000, loss: 0.277127
 >> iter 29000, loss: 0.399596
 >> iter 30000, loss: 0.392420
   Number of active neurons: 5
 >> iter 31000, loss: 0.403269
 >> iter 32000, loss: 0.523904
 >> iter 33000, loss: 0.469441
 >> iter 34000, loss: 0.300447
 >> iter 35000, loss: 0.321253
 >> iter 36000, loss: 0.226270
 >> iter 37000, loss: 0.250344
 >> iter 38000, loss: 0.290546
 >> iter 39000, loss: 0.381835
 >> iter 40000, loss: 0.407092
   Number of active neurons: 5
 >> iter 41000, loss: 0.351220
 >> iter 42000, loss: 0.316618
 >> iter 43000, loss: 0.331227
 >> iter 44000, loss: 0.227587
 >> iter 45000, loss: 0.287803
 >> iter 46000, loss: 0.171509
 >> iter 47000, loss: 0.247279
 >> iter 48000, loss: 0.182751
 >> iter 49000, loss: 0.121666
 >> iter 50000, loss: 0.271822
   Number of active neurons: 5
 >> iter 51000, loss: 0.239505
 >> iter 52000, loss: 0.232774
 >> iter 53000, loss: 0.238254
 >> iter 54000, loss: 0.273740
 >> iter 55000, loss: 0.253797
 >> iter 56000, loss: 0.255350
 >> iter 57000, loss: 0.208817
 >> iter 58000, loss: 0.237218
 >> iter 59000, loss: 0.217167
 >> iter 60000, loss: 0.300981
   Number of active neurons: 5
 >> iter 61000, loss: 0.216169
 >> iter 62000, loss: 0.303243
 >> iter 63000, loss: 0.161795
 >> iter 64000, loss: 0.377425
 >> iter 65000, loss: 0.332630
 >> iter 66000, loss: 0.245140
 >> iter 67000, loss: 0.216905
 >> iter 68000, loss: 0.161347
 >> iter 69000, loss: 0.323879
 >> iter 70000, loss: 0.200051
   Number of active neurons: 5
 >> iter 71000, loss: 0.205711
 >> iter 72000, loss: 0.202560
 >> iter 73000, loss: 0.127076
 >> iter 74000, loss: 0.193987
 >> iter 75000, loss: 0.187079
 >> iter 76000, loss: 0.164604
 >> iter 77000, loss: 0.272830
 >> iter 78000, loss: 0.370219
 >> iter 79000, loss: 0.512046
 >> iter 80000, loss: 0.349790
   Number of active neurons: 5
 >> iter 81000, loss: 0.234032
 >> iter 82000, loss: 0.229661
 >> iter 83000, loss: 0.393070
 >> iter 84000, loss: 0.306342
 >> iter 85000, loss: 0.203827
 >> iter 86000, loss: 0.291106
 >> iter 87000, loss: 0.193323
 >> iter 88000, loss: 0.314993
 >> iter 89000, loss: 0.335837
 >> iter 90000, loss: 0.283561
   Number of active neurons: 5
 >> iter 91000, loss: 0.203320
 >> iter 92000, loss: 0.179698
 >> iter 93000, loss: 0.226689
 >> iter 94000, loss: 0.299704
 >> iter 95000, loss: 0.386378
 >> iter 96000, loss: 0.233162
 >> iter 97000, loss: 0.260636
 >> iter 98000, loss: 0.276874
 >> iter 99000, loss: 0.333423
 >> iter 100000, loss: 0.233230
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.124453
 >> iter 2000, loss: 14.091546
 >> iter 3000, loss: 11.793147
 >> iter 4000, loss: 10.455826
 >> iter 5000, loss: 8.127750
 >> iter 6000, loss: 6.022785
 >> iter 7000, loss: 4.992625
 >> iter 8000, loss: 4.456239
 >> iter 9000, loss: 3.887788
 >> iter 10000, loss: 3.454263
   Number of active neurons: 4
 >> iter 11000, loss: 3.629333
 >> iter 12000, loss: 3.438010
 >> iter 13000, loss: 3.036449
 >> iter 14000, loss: 2.697139
 >> iter 15000, loss: 2.558340
 >> iter 16000, loss: 2.509226
 >> iter 17000, loss: 1.585201
 >> iter 18000, loss: 1.050875
 >> iter 19000, loss: 0.776903
 >> iter 20000, loss: 0.574311
   Number of active neurons: 5
 >> iter 21000, loss: 0.499284
 >> iter 22000, loss: 0.438546
 >> iter 23000, loss: 0.482888
 >> iter 24000, loss: 0.488935
 >> iter 25000, loss: 0.726669
 >> iter 26000, loss: 0.474665
 >> iter 27000, loss: 0.471814
 >> iter 28000, loss: 0.532681
 >> iter 29000, loss: 0.470200
 >> iter 30000, loss: 0.577004
   Number of active neurons: 5
 >> iter 31000, loss: 0.350121
 >> iter 32000, loss: 0.326599
 >> iter 33000, loss: 0.382204
 >> iter 34000, loss: 0.317144
 >> iter 35000, loss: 0.400692
 >> iter 36000, loss: 0.307363
 >> iter 37000, loss: 0.289830
 >> iter 38000, loss: 0.456887
 >> iter 39000, loss: 0.512034
 >> iter 40000, loss: 0.378711
   Number of active neurons: 5
 >> iter 41000, loss: 0.367600
 >> iter 42000, loss: 0.386552
 >> iter 43000, loss: 0.436576
 >> iter 44000, loss: 0.395408
 >> iter 45000, loss: 0.493728
 >> iter 46000, loss: 0.396107
 >> iter 47000, loss: 0.291786
 >> iter 48000, loss: 0.316157
 >> iter 49000, loss: 0.543662
 >> iter 50000, loss: 0.440882
   Number of active neurons: 5
 >> iter 51000, loss: 0.246371
 >> iter 52000, loss: 0.294290
 >> iter 53000, loss: 0.336122
 >> iter 54000, loss: 0.301236
 >> iter 55000, loss: 0.211154
 >> iter 56000, loss: 0.292330
 >> iter 57000, loss: 0.312912
 >> iter 58000, loss: 0.392989
 >> iter 59000, loss: 0.352985
 >> iter 60000, loss: 0.310412
   Number of active neurons: 5
 >> iter 61000, loss: 0.437181
 >> iter 62000, loss: 0.427733
 >> iter 63000, loss: 0.300056
 >> iter 64000, loss: 0.276630
 >> iter 65000, loss: 0.253807
 >> iter 66000, loss: 0.396050
 >> iter 67000, loss: 0.354924
 >> iter 68000, loss: 0.451711
 >> iter 69000, loss: 0.587435
 >> iter 70000, loss: 0.372200
   Number of active neurons: 5
 >> iter 71000, loss: 0.329445
 >> iter 72000, loss: 0.318007
 >> iter 73000, loss: 0.413533
 >> iter 74000, loss: 0.435109
 >> iter 75000, loss: 0.433854
 >> iter 76000, loss: 0.460150
 >> iter 77000, loss: 0.305776
 >> iter 78000, loss: 0.243325
 >> iter 79000, loss: 0.373834
 >> iter 80000, loss: 0.454812
   Number of active neurons: 5
 >> iter 81000, loss: 0.358062
 >> iter 82000, loss: 0.345388
 >> iter 83000, loss: 0.250842
 >> iter 84000, loss: 0.237092
 >> iter 85000, loss: 0.353064
 >> iter 86000, loss: 0.316886
 >> iter 87000, loss: 0.474359
 >> iter 88000, loss: 0.350212
 >> iter 89000, loss: 0.429283
 >> iter 90000, loss: 0.377282
   Number of active neurons: 5
 >> iter 91000, loss: 0.260630
 >> iter 92000, loss: 0.294601
 >> iter 93000, loss: 0.335475
 >> iter 94000, loss: 0.386487
 >> iter 95000, loss: 0.469551
 >> iter 96000, loss: 0.492186
 >> iter 97000, loss: 0.453768
 >> iter 98000, loss: 0.339310
 >> iter 99000, loss: 0.321523
 >> iter 100000, loss: 0.304060
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.210258
 >> iter 2000, loss: 12.541869
 >> iter 3000, loss: 6.661485
 >> iter 4000, loss: 3.335865
 >> iter 5000, loss: 1.931557
 >> iter 6000, loss: 1.278555
 >> iter 7000, loss: 1.290840
 >> iter 8000, loss: 1.078978
 >> iter 9000, loss: 0.936068
 >> iter 10000, loss: 0.696124
   Number of active neurons: 5
 >> iter 11000, loss: 0.856198
 >> iter 12000, loss: 0.710881
 >> iter 13000, loss: 0.677332
 >> iter 14000, loss: 0.537194
 >> iter 15000, loss: 0.552375
 >> iter 16000, loss: 0.531400
 >> iter 17000, loss: 0.608706
 >> iter 18000, loss: 0.595556
 >> iter 19000, loss: 0.653416
 >> iter 20000, loss: 0.549977
   Number of active neurons: 5
 >> iter 21000, loss: 0.510308
 >> iter 22000, loss: 0.491314
 >> iter 23000, loss: 0.466619
 >> iter 24000, loss: 0.530577
 >> iter 25000, loss: 0.678998
 >> iter 26000, loss: 0.387551
 >> iter 27000, loss: 0.356892
 >> iter 28000, loss: 0.343382
 >> iter 29000, loss: 0.518343
 >> iter 30000, loss: 0.438259
   Number of active neurons: 5
 >> iter 31000, loss: 0.555015
 >> iter 32000, loss: 0.460819
 >> iter 33000, loss: 0.580506
 >> iter 34000, loss: 0.573984
 >> iter 35000, loss: 0.740407
 >> iter 36000, loss: 0.528726
 >> iter 37000, loss: 0.629872
 >> iter 38000, loss: 0.664252
 >> iter 39000, loss: 0.476935
 >> iter 40000, loss: 0.586933
   Number of active neurons: 6
 >> iter 41000, loss: 0.628937
 >> iter 42000, loss: 0.491464
 >> iter 43000, loss: 0.409157
 >> iter 44000, loss: 0.393747
 >> iter 45000, loss: 0.543451
 >> iter 46000, loss: 0.562099
 >> iter 47000, loss: 0.475043
 >> iter 48000, loss: 0.401313
 >> iter 49000, loss: 0.490655
 >> iter 50000, loss: 0.463716
   Number of active neurons: 6
 >> iter 51000, loss: 0.421636
 >> iter 52000, loss: 0.388143
 >> iter 53000, loss: 0.355979
 >> iter 54000, loss: 0.364256
 >> iter 55000, loss: 0.542099
 >> iter 56000, loss: 0.525191
 >> iter 57000, loss: 0.427665
 >> iter 58000, loss: 0.472224
 >> iter 59000, loss: 0.329344
 >> iter 60000, loss: 0.481318
   Number of active neurons: 5
 >> iter 61000, loss: 0.463547
 >> iter 62000, loss: 0.367609
 >> iter 63000, loss: 0.516233
 >> iter 64000, loss: 0.542345
 >> iter 65000, loss: 0.390590
 >> iter 66000, loss: 0.617437
 >> iter 67000, loss: 0.596996
 >> iter 68000, loss: 0.415042
 >> iter 69000, loss: 0.524072
 >> iter 70000, loss: 0.577485
   Number of active neurons: 4
 >> iter 71000, loss: 0.577973
 >> iter 72000, loss: 0.704307
 >> iter 73000, loss: 0.703192
 >> iter 74000, loss: 0.460989
 >> iter 75000, loss: 0.474267
 >> iter 76000, loss: 0.422703
 >> iter 77000, loss: 0.427650
 >> iter 78000, loss: 0.502776
 >> iter 79000, loss: 0.615507
 >> iter 80000, loss: 0.362847
   Number of active neurons: 4
 >> iter 81000, loss: 0.365775
 >> iter 82000, loss: 0.432577
 >> iter 83000, loss: 0.341602
 >> iter 84000, loss: 0.345358
 >> iter 85000, loss: 0.659628
 >> iter 86000, loss: 0.539545
 >> iter 87000, loss: 0.533420
 >> iter 88000, loss: 0.564696
 >> iter 89000, loss: 0.732455
 >> iter 90000, loss: 0.508979
   Number of active neurons: 4
 >> iter 91000, loss: 0.611158
 >> iter 92000, loss: 0.498440
 >> iter 93000, loss: 0.665340
 >> iter 94000, loss: 0.471135
 >> iter 95000, loss: 0.612450
 >> iter 96000, loss: 0.497287
 >> iter 97000, loss: 0.530767
 >> iter 98000, loss: 0.344765
 >> iter 99000, loss: 0.482136
 >> iter 100000, loss: 0.554294
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.075731
 >> iter 2000, loss: 13.451844
 >> iter 3000, loss: 9.716161
 >> iter 4000, loss: 5.832542
 >> iter 5000, loss: 3.039411
 >> iter 6000, loss: 1.633361
 >> iter 7000, loss: 1.135764
 >> iter 8000, loss: 0.901379
 >> iter 9000, loss: 0.648433
 >> iter 10000, loss: 0.433185
   Number of active neurons: 6
 >> iter 11000, loss: 0.441993
 >> iter 12000, loss: 0.342891
 >> iter 13000, loss: 0.475477
 >> iter 14000, loss: 0.531015
 >> iter 15000, loss: 0.642475
 >> iter 16000, loss: 0.512743
 >> iter 17000, loss: 0.469003
 >> iter 18000, loss: 0.608259
 >> iter 19000, loss: 0.417681
 >> iter 20000, loss: 0.495710
   Number of active neurons: 6
 >> iter 21000, loss: 0.486445
 >> iter 22000, loss: 0.536295
 >> iter 23000, loss: 0.412227
 >> iter 24000, loss: 0.387500
 >> iter 25000, loss: 0.508044
 >> iter 26000, loss: 0.441518
 >> iter 27000, loss: 0.385832
 >> iter 28000, loss: 0.270899
 >> iter 29000, loss: 0.388098
 >> iter 30000, loss: 0.390763
   Number of active neurons: 6
 >> iter 31000, loss: 0.318548
 >> iter 32000, loss: 0.341995
 >> iter 33000, loss: 0.396772
 >> iter 34000, loss: 0.346117
 >> iter 35000, loss: 0.512295
 >> iter 36000, loss: 0.548377
 >> iter 37000, loss: 0.554816
 >> iter 38000, loss: 0.408041
 >> iter 39000, loss: 0.421070
 >> iter 40000, loss: 0.390905
   Number of active neurons: 6
 >> iter 41000, loss: 0.304244
 >> iter 42000, loss: 0.285969
 >> iter 43000, loss: 0.264723
 >> iter 44000, loss: 0.424013
 >> iter 45000, loss: 0.607740
 >> iter 46000, loss: 0.380683
 >> iter 47000, loss: 0.292933
 >> iter 48000, loss: 0.387877
 >> iter 49000, loss: 0.480011
 >> iter 50000, loss: 0.541882
   Number of active neurons: 6
 >> iter 51000, loss: 0.583486
 >> iter 52000, loss: 0.400872
 >> iter 53000, loss: 0.514204
 >> iter 54000, loss: 0.431832
 >> iter 55000, loss: 0.362056
 >> iter 56000, loss: 0.364473
 >> iter 57000, loss: 0.486802
 >> iter 58000, loss: 0.401497
 >> iter 59000, loss: 0.459375
 >> iter 60000, loss: 0.482772
   Number of active neurons: 6
 >> iter 61000, loss: 0.501323
 >> iter 62000, loss: 0.468501
 >> iter 63000, loss: 0.773942
 >> iter 64000, loss: 0.519106
 >> iter 65000, loss: 0.439080
 >> iter 66000, loss: 0.386857
 >> iter 67000, loss: 0.415077
 >> iter 68000, loss: 0.558438
 >> iter 69000, loss: 0.403821
 >> iter 70000, loss: 0.445576
   Number of active neurons: 5
 >> iter 71000, loss: 0.652869
 >> iter 72000, loss: 0.422840
 >> iter 73000, loss: 0.553653
 >> iter 74000, loss: 0.430452
 >> iter 75000, loss: 0.266573
 >> iter 76000, loss: 0.307353
 >> iter 77000, loss: 0.430001
 >> iter 78000, loss: 0.541991
 >> iter 79000, loss: 0.445788
 >> iter 80000, loss: 0.485542
   Number of active neurons: 5
 >> iter 81000, loss: 0.729501
 >> iter 82000, loss: 0.446576
 >> iter 83000, loss: 0.424143
 >> iter 84000, loss: 0.599446
 >> iter 85000, loss: 0.584933
 >> iter 86000, loss: 0.423366
 >> iter 87000, loss: 0.636189
 >> iter 88000, loss: 0.344609
 >> iter 89000, loss: 0.442762
 >> iter 90000, loss: 0.522879
   Number of active neurons: 5
 >> iter 91000, loss: 0.464024
 >> iter 92000, loss: 0.421872
 >> iter 93000, loss: 0.416344
 >> iter 94000, loss: 0.330231
 >> iter 95000, loss: 0.408192
 >> iter 96000, loss: 0.437428
 >> iter 97000, loss: 0.404287
 >> iter 98000, loss: 0.340631
 >> iter 99000, loss: 0.426879
 >> iter 100000, loss: 0.410393
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.093010
 >> iter 2000, loss: 11.544625
 >> iter 3000, loss: 5.436314
 >> iter 4000, loss: 2.607841
 >> iter 5000, loss: 1.526892
 >> iter 6000, loss: 0.842792
 >> iter 7000, loss: 0.734054
 >> iter 8000, loss: 0.675013
 >> iter 9000, loss: 0.558546
 >> iter 10000, loss: 0.547458
   Number of active neurons: 5
 >> iter 11000, loss: 0.454903
 >> iter 12000, loss: 0.339391
 >> iter 13000, loss: 0.294105
 >> iter 14000, loss: 0.274562
 >> iter 15000, loss: 0.450341
 >> iter 16000, loss: 0.429821
 >> iter 17000, loss: 0.397647
 >> iter 18000, loss: 0.381747
 >> iter 19000, loss: 0.331799
 >> iter 20000, loss: 0.303892
   Number of active neurons: 5
 >> iter 21000, loss: 0.356142
 >> iter 22000, loss: 0.392777
 >> iter 23000, loss: 0.329042
 >> iter 24000, loss: 0.297511
 >> iter 25000, loss: 0.413502
 >> iter 26000, loss: 0.592148
 >> iter 27000, loss: 0.441638
 >> iter 28000, loss: 0.417597
 >> iter 29000, loss: 0.362596
 >> iter 30000, loss: 0.243918
   Number of active neurons: 5
 >> iter 31000, loss: 0.327874
 >> iter 32000, loss: 0.400595
 >> iter 33000, loss: 0.375424
 >> iter 34000, loss: 0.397914
 >> iter 35000, loss: 0.552823
 >> iter 36000, loss: 0.447108
 >> iter 37000, loss: 0.448121
 >> iter 38000, loss: 0.343412
 >> iter 39000, loss: 0.320093
 >> iter 40000, loss: 0.308541
   Number of active neurons: 5
 >> iter 41000, loss: 0.469593
 >> iter 42000, loss: 0.331883
 >> iter 43000, loss: 0.347716
 >> iter 44000, loss: 0.387959
 >> iter 45000, loss: 0.549533
 >> iter 46000, loss: 0.357874
 >> iter 47000, loss: 0.435310
 >> iter 48000, loss: 0.476464
 >> iter 49000, loss: 0.401394
 >> iter 50000, loss: 0.360564
   Number of active neurons: 5
 >> iter 51000, loss: 0.351307
 >> iter 52000, loss: 0.449870
 >> iter 53000, loss: 0.541360
 >> iter 54000, loss: 0.556091
 >> iter 55000, loss: 0.535913
 >> iter 56000, loss: 0.546449
 >> iter 57000, loss: 0.393938
 >> iter 58000, loss: 0.419356
 >> iter 59000, loss: 0.438506
 >> iter 60000, loss: 0.455742
   Number of active neurons: 5
 >> iter 61000, loss: 0.420716
 >> iter 62000, loss: 0.374173
 >> iter 63000, loss: 0.392116
 >> iter 64000, loss: 0.302900
 >> iter 65000, loss: 0.446609
 >> iter 66000, loss: 0.458161
 >> iter 67000, loss: 0.328896
 >> iter 68000, loss: 0.424484
 >> iter 69000, loss: 0.402874
 >> iter 70000, loss: 0.388132
   Number of active neurons: 4
 >> iter 71000, loss: 0.452939
 >> iter 72000, loss: 0.306255
 >> iter 73000, loss: 0.248729
 >> iter 74000, loss: 0.211268
 >> iter 75000, loss: 0.238368
 >> iter 76000, loss: 0.376591
 >> iter 77000, loss: 0.375166
 >> iter 78000, loss: 0.384094
 >> iter 79000, loss: 0.369843
 >> iter 80000, loss: 0.331763
   Number of active neurons: 4
 >> iter 81000, loss: 0.224744
 >> iter 82000, loss: 0.209608
 >> iter 83000, loss: 0.242266
 >> iter 84000, loss: 0.385547
 >> iter 85000, loss: 0.376853
 >> iter 86000, loss: 0.303023
 >> iter 87000, loss: 0.373636
 >> iter 88000, loss: 0.349888
 >> iter 89000, loss: 0.214401
 >> iter 90000, loss: 0.314626
   Number of active neurons: 4
 >> iter 91000, loss: 0.239278
 >> iter 92000, loss: 0.457452
 >> iter 93000, loss: 0.337718
 >> iter 94000, loss: 0.322281
 >> iter 95000, loss: 0.286336
 >> iter 96000, loss: 0.249437
 >> iter 97000, loss: 0.462019
 >> iter 98000, loss: 0.660544
 >> iter 99000, loss: 0.477072
 >> iter 100000, loss: 0.592962
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 10.9526031598

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

