 > Problema: tomita1nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.939351
 >> iter 2000, loss: 4.062598
 >> iter 3000, loss: 1.519679
 >> iter 4000, loss: 0.580676
 >> iter 5000, loss: 0.237737
 >> iter 6000, loss: 0.104032
 >> iter 7000, loss: 0.058964
 >> iter 8000, loss: 0.037006
 >> iter 9000, loss: 0.044177
 >> iter 10000, loss: 0.048471
   Number of active neurons: 4
 >> iter 11000, loss: 0.035648
 >> iter 12000, loss: 0.042544
 >> iter 13000, loss: 0.033005
 >> iter 14000, loss: 0.029915
 >> iter 15000, loss: 0.028288
 >> iter 16000, loss: 0.030641
 >> iter 17000, loss: 0.028355
 >> iter 18000, loss: 0.029436
 >> iter 19000, loss: 0.029184
 >> iter 20000, loss: 0.029281
   Number of active neurons: 4
 >> iter 21000, loss: 0.028051
 >> iter 22000, loss: 0.026262
 >> iter 23000, loss: 0.024459
 >> iter 24000, loss: 0.026482
 >> iter 25000, loss: 0.025706
 >> iter 26000, loss: 0.028656
 >> iter 27000, loss: 0.026580
 >> iter 28000, loss: 0.034374
 >> iter 29000, loss: 0.030635
 >> iter 30000, loss: 0.025258
   Number of active neurons: 2
 >> iter 31000, loss: 0.024919
 >> iter 32000, loss: 0.028592
 >> iter 33000, loss: 0.029117
 >> iter 34000, loss: 0.024986
 >> iter 35000, loss: 0.026446
 >> iter 36000, loss: 0.032920
 >> iter 37000, loss: 0.037141
 >> iter 38000, loss: 0.027698
 >> iter 39000, loss: 0.026299
 >> iter 40000, loss: 0.023702
   Number of active neurons: 2
 >> iter 41000, loss: 0.028673
 >> iter 42000, loss: 0.023267
 >> iter 43000, loss: 0.027103
 >> iter 44000, loss: 0.022755
 >> iter 45000, loss: 0.023546
 >> iter 46000, loss: 0.026293
 >> iter 47000, loss: 0.022526
 >> iter 48000, loss: 0.027785
 >> iter 49000, loss: 0.030427
 >> iter 50000, loss: 0.036584
   Number of active neurons: 2
 >> iter 51000, loss: 0.031566
 >> iter 52000, loss: 0.025773
 >> iter 53000, loss: 0.026139
 >> iter 54000, loss: 0.026275
 >> iter 55000, loss: 0.027282
 >> iter 56000, loss: 0.023767
 >> iter 57000, loss: 0.020783
 >> iter 58000, loss: 0.037297
 >> iter 59000, loss: 0.026014
 >> iter 60000, loss: 0.025121
   Number of active neurons: 2
 >> iter 61000, loss: 0.022254
 >> iter 62000, loss: 0.021783
 >> iter 63000, loss: 0.026594
 >> iter 64000, loss: 0.025614
 >> iter 65000, loss: 0.025045
 >> iter 66000, loss: 0.023723
 >> iter 67000, loss: 0.022241
 >> iter 68000, loss: 0.027084
 >> iter 69000, loss: 0.025039
 >> iter 70000, loss: 0.021236
   Number of active neurons: 2
 >> iter 71000, loss: 0.029097
 >> iter 72000, loss: 0.026815
 >> iter 73000, loss: 0.027931
 >> iter 74000, loss: 0.024735
 >> iter 75000, loss: 0.028971
 >> iter 76000, loss: 0.023268
 >> iter 77000, loss: 0.020036
 >> iter 78000, loss: 0.026887
 >> iter 79000, loss: 0.023245
 >> iter 80000, loss: 0.028388
   Number of active neurons: 1
 >> iter 81000, loss: 0.027174
 >> iter 82000, loss: 0.025527
 >> iter 83000, loss: 0.027518
 >> iter 84000, loss: 0.023459
 >> iter 85000, loss: 0.018777
 >> iter 86000, loss: 0.020431
 >> iter 87000, loss: 0.031489
 >> iter 88000, loss: 0.026426
 >> iter 89000, loss: 0.036427
 >> iter 90000, loss: 0.025441
   Number of active neurons: 1
 >> iter 91000, loss: 0.021692
 >> iter 92000, loss: 0.017157
 >> iter 93000, loss: 0.016784
 >> iter 94000, loss: 0.018382
 >> iter 95000, loss: 0.018551
 >> iter 96000, loss: 0.019395
 >> iter 97000, loss: 0.017210
 >> iter 98000, loss: 0.017509
 >> iter 99000, loss: 0.029526
 >> iter 100000, loss: 0.021963
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 10.936253
 >> iter 2000, loss: 4.061316
 >> iter 3000, loss: 1.517164
 >> iter 4000, loss: 0.579208
 >> iter 5000, loss: 0.237550
 >> iter 6000, loss: 0.104631
 >> iter 7000, loss: 0.054962
 >> iter 8000, loss: 0.038712
 >> iter 9000, loss: 0.034418
 >> iter 10000, loss: 0.031183
   Number of active neurons: 4
 >> iter 11000, loss: 0.028658
 >> iter 12000, loss: 0.027448
 >> iter 13000, loss: 0.025340
 >> iter 14000, loss: 0.025871
 >> iter 15000, loss: 0.030836
 >> iter 16000, loss: 0.027222
 >> iter 17000, loss: 0.028102
 >> iter 18000, loss: 0.027835
 >> iter 19000, loss: 0.030329
 >> iter 20000, loss: 0.030060
   Number of active neurons: 3
 >> iter 21000, loss: 0.029180
 >> iter 22000, loss: 0.025299
 >> iter 23000, loss: 0.029114
 >> iter 24000, loss: 0.023807
 >> iter 25000, loss: 0.022453
 >> iter 26000, loss: 0.032453
 >> iter 27000, loss: 0.028932
 >> iter 28000, loss: 0.032759
 >> iter 29000, loss: 0.042732
 >> iter 30000, loss: 0.028688
   Number of active neurons: 3
 >> iter 31000, loss: 0.030156
 >> iter 32000, loss: 0.030784
 >> iter 33000, loss: 0.027782
 >> iter 34000, loss: 0.024333
 >> iter 35000, loss: 0.026379
 >> iter 36000, loss: 0.023416
 >> iter 37000, loss: 0.022401
 >> iter 38000, loss: 0.021972
 >> iter 39000, loss: 0.030405
 >> iter 40000, loss: 0.034780
   Number of active neurons: 2
 >> iter 41000, loss: 0.025907
 >> iter 42000, loss: 0.021208
 >> iter 43000, loss: 0.024596
 >> iter 44000, loss: 0.021236
 >> iter 45000, loss: 0.021147
 >> iter 46000, loss: 0.020458
 >> iter 47000, loss: 0.019857
 >> iter 48000, loss: 0.020557
 >> iter 49000, loss: 0.020519
 >> iter 50000, loss: 0.020450
   Number of active neurons: 2
 >> iter 51000, loss: 0.020002
 >> iter 52000, loss: 0.019442
 >> iter 53000, loss: 0.023628
 >> iter 54000, loss: 0.024554
 >> iter 55000, loss: 0.024593
 >> iter 56000, loss: 0.025469
 >> iter 57000, loss: 0.027227
 >> iter 58000, loss: 0.021507
 >> iter 59000, loss: 0.020617
 >> iter 60000, loss: 0.022533
   Number of active neurons: 2
 >> iter 61000, loss: 0.023691
 >> iter 62000, loss: 0.025188
 >> iter 63000, loss: 0.025592
 >> iter 64000, loss: 0.020882
 >> iter 65000, loss: 0.022827
 >> iter 66000, loss: 0.037524
 >> iter 67000, loss: 0.026683
 >> iter 68000, loss: 0.028498
 >> iter 69000, loss: 0.024910
 >> iter 70000, loss: 0.022900
   Number of active neurons: 2
 >> iter 71000, loss: 0.028685
 >> iter 72000, loss: 0.027614
 >> iter 73000, loss: 0.025250
 >> iter 74000, loss: 0.025572
 >> iter 75000, loss: 0.021026
 >> iter 76000, loss: 0.021494
 >> iter 77000, loss: 0.022804
 >> iter 78000, loss: 0.027272
 >> iter 79000, loss: 0.023338
 >> iter 80000, loss: 0.025877
   Number of active neurons: 2
 >> iter 81000, loss: 0.024376
 >> iter 82000, loss: 0.025899
 >> iter 83000, loss: 0.022026
 >> iter 84000, loss: 0.021683
 >> iter 85000, loss: 0.027069
 >> iter 86000, loss: 0.022365
 >> iter 87000, loss: 0.021942
 >> iter 88000, loss: 0.023226
 >> iter 89000, loss: 0.021998
 >> iter 90000, loss: 0.021403
   Number of active neurons: 2
 >> iter 91000, loss: 0.021508
 >> iter 92000, loss: 0.020598
 >> iter 93000, loss: 0.026080
 >> iter 94000, loss: 0.026069
 >> iter 95000, loss: 0.027533
 >> iter 96000, loss: 0.023804
 >> iter 97000, loss: 0.025451
 >> iter 98000, loss: 0.023932
 >> iter 99000, loss: 0.022500
 >> iter 100000, loss: 0.025079
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.974563
 >> iter 2000, loss: 4.073055
 >> iter 3000, loss: 1.520462
 >> iter 4000, loss: 0.591882
 >> iter 5000, loss: 0.238737
 >> iter 6000, loss: 0.106765
 >> iter 7000, loss: 0.058259
 >> iter 8000, loss: 0.042872
 >> iter 9000, loss: 0.040716
 >> iter 10000, loss: 0.031120
   Number of active neurons: 4
 >> iter 11000, loss: 0.039032
 >> iter 12000, loss: 0.034845
 >> iter 13000, loss: 0.029031
 >> iter 14000, loss: 0.032447
 >> iter 15000, loss: 0.028066
 >> iter 16000, loss: 0.025259
 >> iter 17000, loss: 0.033706
 >> iter 18000, loss: 0.028724
 >> iter 19000, loss: 0.030162
 >> iter 20000, loss: 0.025780
   Number of active neurons: 3
 >> iter 21000, loss: 0.024314
 >> iter 22000, loss: 0.035070
 >> iter 23000, loss: 0.029626
 >> iter 24000, loss: 0.037557
 >> iter 25000, loss: 0.030172
 >> iter 26000, loss: 0.030824
 >> iter 27000, loss: 0.032571
 >> iter 28000, loss: 0.026040
 >> iter 29000, loss: 0.022760
 >> iter 30000, loss: 0.023707
   Number of active neurons: 3
 >> iter 31000, loss: 0.023667
 >> iter 32000, loss: 0.024417
 >> iter 33000, loss: 0.024373
 >> iter 34000, loss: 0.023444
 >> iter 35000, loss: 0.025697
 >> iter 36000, loss: 0.026469
 >> iter 37000, loss: 0.023877
 >> iter 38000, loss: 0.022998
 >> iter 39000, loss: 0.038766
 >> iter 40000, loss: 0.030217
   Number of active neurons: 2
 >> iter 41000, loss: 0.027477
 >> iter 42000, loss: 0.026671
 >> iter 43000, loss: 0.023214
 >> iter 44000, loss: 0.020729
 >> iter 45000, loss: 0.027636
 >> iter 46000, loss: 0.033542
 >> iter 47000, loss: 0.026474
 >> iter 48000, loss: 0.021755
 >> iter 49000, loss: 0.020616
 >> iter 50000, loss: 0.029280
   Number of active neurons: 2
 >> iter 51000, loss: 0.030048
 >> iter 52000, loss: 0.028493
 >> iter 53000, loss: 0.022315
 >> iter 54000, loss: 0.022654
 >> iter 55000, loss: 0.021571
 >> iter 56000, loss: 0.024085
 >> iter 57000, loss: 0.021174
 >> iter 58000, loss: 0.024167
 >> iter 59000, loss: 0.020302
 >> iter 60000, loss: 0.027441
   Number of active neurons: 2
 >> iter 61000, loss: 0.051289
 >> iter 62000, loss: 0.031978
 >> iter 63000, loss: 0.028737
 >> iter 64000, loss: 0.027838
 >> iter 65000, loss: 0.024679
 >> iter 66000, loss: 0.023097
 >> iter 67000, loss: 0.021629
 >> iter 68000, loss: 0.020486
 >> iter 69000, loss: 0.038738
 >> iter 70000, loss: 0.048295
   Number of active neurons: 2
 >> iter 71000, loss: 0.029977
 >> iter 72000, loss: 0.023546
 >> iter 73000, loss: 0.027390
 >> iter 74000, loss: 0.032968
 >> iter 75000, loss: 0.031348
 >> iter 76000, loss: 0.027031
 >> iter 77000, loss: 0.022061
 >> iter 78000, loss: 0.035951
 >> iter 79000, loss: 0.025504
 >> iter 80000, loss: 0.028870
   Number of active neurons: 2
 >> iter 81000, loss: 0.024384
 >> iter 82000, loss: 0.021112
 >> iter 83000, loss: 0.020457
 >> iter 84000, loss: 0.029542
 >> iter 85000, loss: 0.032504
 >> iter 86000, loss: 0.024785
 >> iter 87000, loss: 0.024932
 >> iter 88000, loss: 0.023958
 >> iter 89000, loss: 0.029236
 >> iter 90000, loss: 0.023504
   Number of active neurons: 2
 >> iter 91000, loss: 0.030887
 >> iter 92000, loss: 0.023777
 >> iter 93000, loss: 0.027910
 >> iter 94000, loss: 0.028691
 >> iter 95000, loss: 0.023116
 >> iter 96000, loss: 0.021051
 >> iter 97000, loss: 0.019437
 >> iter 98000, loss: 0.020425
 >> iter 99000, loss: 0.021644
 >> iter 100000, loss: 0.034206
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.945086
 >> iter 2000, loss: 4.059318
 >> iter 3000, loss: 1.524796
 >> iter 4000, loss: 0.581205
 >> iter 5000, loss: 0.240660
 >> iter 6000, loss: 0.112615
 >> iter 7000, loss: 0.058411
 >> iter 8000, loss: 0.042095
 >> iter 9000, loss: 0.038993
 >> iter 10000, loss: 0.031170
   Number of active neurons: 5
 >> iter 11000, loss: 0.031729
 >> iter 12000, loss: 0.030151
 >> iter 13000, loss: 0.032250
 >> iter 14000, loss: 0.028947
 >> iter 15000, loss: 0.028780
 >> iter 16000, loss: 0.027814
 >> iter 17000, loss: 0.028364
 >> iter 18000, loss: 0.025904
 >> iter 19000, loss: 0.031613
 >> iter 20000, loss: 0.028482
   Number of active neurons: 4
 >> iter 21000, loss: 0.029544
 >> iter 22000, loss: 0.027350
 >> iter 23000, loss: 0.024000
 >> iter 24000, loss: 0.024381
 >> iter 25000, loss: 0.025083
 >> iter 26000, loss: 0.024012
 >> iter 27000, loss: 0.025708
 >> iter 28000, loss: 0.028169
 >> iter 29000, loss: 0.024900
 >> iter 30000, loss: 0.024256
   Number of active neurons: 3
 >> iter 31000, loss: 0.025674
 >> iter 32000, loss: 0.027451
 >> iter 33000, loss: 0.027310
 >> iter 34000, loss: 0.037354
 >> iter 35000, loss: 0.028295
 >> iter 36000, loss: 0.025581
 >> iter 37000, loss: 0.026779
 >> iter 38000, loss: 0.031450
 >> iter 39000, loss: 0.052666
 >> iter 40000, loss: 0.034478
   Number of active neurons: 3
 >> iter 41000, loss: 0.028219
 >> iter 42000, loss: 0.025146
 >> iter 43000, loss: 0.023538
 >> iter 44000, loss: 0.025080
 >> iter 45000, loss: 0.023571
 >> iter 46000, loss: 0.023313
 >> iter 47000, loss: 0.026530
 >> iter 48000, loss: 0.028772
 >> iter 49000, loss: 0.025387
 >> iter 50000, loss: 0.036713
   Number of active neurons: 2
 >> iter 51000, loss: 0.029917
 >> iter 52000, loss: 0.027578
 >> iter 53000, loss: 0.029956
 >> iter 54000, loss: 0.034686
 >> iter 55000, loss: 0.029910
 >> iter 56000, loss: 0.024454
 >> iter 57000, loss: 0.023863
 >> iter 58000, loss: 0.022354
 >> iter 59000, loss: 0.020797
 >> iter 60000, loss: 0.019863
   Number of active neurons: 2
 >> iter 61000, loss: 0.020396
 >> iter 62000, loss: 0.023295
 >> iter 63000, loss: 0.023406
 >> iter 64000, loss: 0.027398
 >> iter 65000, loss: 0.025042
 >> iter 66000, loss: 0.041540
 >> iter 67000, loss: 0.028665
 >> iter 68000, loss: 0.023455
 >> iter 69000, loss: 0.024388
 >> iter 70000, loss: 0.021105
   Number of active neurons: 2
 >> iter 71000, loss: 0.020804
 >> iter 72000, loss: 0.021823
 >> iter 73000, loss: 0.020615
 >> iter 74000, loss: 0.024968
 >> iter 75000, loss: 0.028634
 >> iter 76000, loss: 0.022903
 >> iter 77000, loss: 0.020970
 >> iter 78000, loss: 0.023899
 >> iter 79000, loss: 0.028836
 >> iter 80000, loss: 0.026292
   Number of active neurons: 2
 >> iter 81000, loss: 0.023090
 >> iter 82000, loss: 0.020780
 >> iter 83000, loss: 0.019498
 >> iter 84000, loss: 0.032011
 >> iter 85000, loss: 0.025887
 >> iter 86000, loss: 0.022213
 >> iter 87000, loss: 0.020424
 >> iter 88000, loss: 0.023199
 >> iter 89000, loss: 0.025678
 >> iter 90000, loss: 0.031659
   Number of active neurons: 2
 >> iter 91000, loss: 0.031019
 >> iter 92000, loss: 0.042378
 >> iter 93000, loss: 0.030265
 >> iter 94000, loss: 0.026016
 >> iter 95000, loss: 0.027105
 >> iter 96000, loss: 0.028119
 >> iter 97000, loss: 0.031967
 >> iter 98000, loss: 0.027142
 >> iter 99000, loss: 0.023372
 >> iter 100000, loss: 0.022096
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.885385
 >> iter 2000, loss: 4.043723
 >> iter 3000, loss: 1.513998
 >> iter 4000, loss: 0.588985
 >> iter 5000, loss: 0.235543
 >> iter 6000, loss: 0.105871
 >> iter 7000, loss: 0.058776
 >> iter 8000, loss: 0.043591
 >> iter 9000, loss: 0.033269
 >> iter 10000, loss: 0.030277
   Number of active neurons: 4
 >> iter 11000, loss: 0.028854
 >> iter 12000, loss: 0.026115
 >> iter 13000, loss: 0.028974
 >> iter 14000, loss: 0.026724
 >> iter 15000, loss: 0.027469
 >> iter 16000, loss: 0.025964
 >> iter 17000, loss: 0.034021
 >> iter 18000, loss: 0.030285
 >> iter 19000, loss: 0.035899
 >> iter 20000, loss: 0.031333
   Number of active neurons: 4
 >> iter 21000, loss: 0.031452
 >> iter 22000, loss: 0.026258
 >> iter 23000, loss: 0.024103
 >> iter 24000, loss: 0.023221
 >> iter 25000, loss: 0.023686
 >> iter 26000, loss: 0.031932
 >> iter 27000, loss: 0.031384
 >> iter 28000, loss: 0.025906
 >> iter 29000, loss: 0.024061
 >> iter 30000, loss: 0.023319
   Number of active neurons: 3
 >> iter 31000, loss: 0.022798
 >> iter 32000, loss: 0.024095
 >> iter 33000, loss: 0.027114
 >> iter 34000, loss: 0.023265
 >> iter 35000, loss: 0.026574
 >> iter 36000, loss: 0.023210
 >> iter 37000, loss: 0.023231
 >> iter 38000, loss: 0.024687
 >> iter 39000, loss: 0.023274
 >> iter 40000, loss: 0.026702
   Number of active neurons: 3
 >> iter 41000, loss: 0.048448
 >> iter 42000, loss: 0.033386
 >> iter 43000, loss: 0.026089
 >> iter 44000, loss: 0.023688
 >> iter 45000, loss: 0.026726
 >> iter 46000, loss: 0.025441
 >> iter 47000, loss: 0.025138
 >> iter 48000, loss: 0.028395
 >> iter 49000, loss: 0.024325
 >> iter 50000, loss: 0.024720
   Number of active neurons: 3
 >> iter 51000, loss: 0.023439
 >> iter 52000, loss: 0.030998
 >> iter 53000, loss: 0.027028
 >> iter 54000, loss: 0.027702
 >> iter 55000, loss: 0.023226
 >> iter 56000, loss: 0.022551
 >> iter 57000, loss: 0.038504
 >> iter 58000, loss: 0.029014
 >> iter 59000, loss: 0.026340
 >> iter 60000, loss: 0.025173
   Number of active neurons: 3
 >> iter 61000, loss: 0.025034
 >> iter 62000, loss: 0.025540
 >> iter 63000, loss: 0.025720
 >> iter 64000, loss: 0.026035
 >> iter 65000, loss: 0.024155
 >> iter 66000, loss: 0.024697
 >> iter 67000, loss: 0.029131
 >> iter 68000, loss: 0.030528
 >> iter 69000, loss: 0.025552
 >> iter 70000, loss: 0.030685
   Number of active neurons: 3
 >> iter 71000, loss: 0.027861
 >> iter 72000, loss: 0.026299
 >> iter 73000, loss: 0.075646
 >> iter 74000, loss: 0.047484
 >> iter 75000, loss: 0.076671
 >> iter 76000, loss: 0.046349
 >> iter 77000, loss: 0.033137
 >> iter 78000, loss: 0.032167
 >> iter 79000, loss: 0.028718
 >> iter 80000, loss: 0.030804
   Number of active neurons: 3
 >> iter 81000, loss: 0.025567
 >> iter 82000, loss: 0.036911
 >> iter 83000, loss: 0.034637
 >> iter 84000, loss: 0.048837
 >> iter 85000, loss: 0.039554
 >> iter 86000, loss: 0.030849
 >> iter 87000, loss: 0.027229
 >> iter 88000, loss: 0.024073
 >> iter 89000, loss: 0.028814
 >> iter 90000, loss: 0.032042
   Number of active neurons: 2
 >> iter 91000, loss: 0.024660
 >> iter 92000, loss: 0.027121
 >> iter 93000, loss: 0.030365
 >> iter 94000, loss: 0.025493
 >> iter 95000, loss: 0.024147
 >> iter 96000, loss: 0.057444
 >> iter 97000, loss: 0.035420
 >> iter 98000, loss: 0.025884
 >> iter 99000, loss: 0.030151
 >> iter 100000, loss: 0.033460
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.911698
 >> iter 2000, loss: 4.054949
 >> iter 3000, loss: 1.524648
 >> iter 4000, loss: 0.591260
 >> iter 5000, loss: 0.235332
 >> iter 6000, loss: 0.105563
 >> iter 7000, loss: 0.060356
 >> iter 8000, loss: 0.043056
 >> iter 9000, loss: 0.034091
 >> iter 10000, loss: 0.027974
   Number of active neurons: 3
 >> iter 11000, loss: 0.027695
 >> iter 12000, loss: 0.028159
 >> iter 13000, loss: 0.027038
 >> iter 14000, loss: 0.025556
 >> iter 15000, loss: 0.023373
 >> iter 16000, loss: 0.024888
 >> iter 17000, loss: 0.023866
 >> iter 18000, loss: 0.020865
 >> iter 19000, loss: 0.020861
 >> iter 20000, loss: 0.025524
   Number of active neurons: 2
 >> iter 21000, loss: 0.024517
 >> iter 22000, loss: 0.026740
 >> iter 23000, loss: 0.024372
 >> iter 24000, loss: 0.021052
 >> iter 25000, loss: 0.021993
 >> iter 26000, loss: 0.022403
 >> iter 27000, loss: 0.022613
 >> iter 28000, loss: 0.021292
 >> iter 29000, loss: 0.020512
 >> iter 30000, loss: 0.021059
   Number of active neurons: 2
 >> iter 31000, loss: 0.023522
 >> iter 32000, loss: 0.021697
 >> iter 33000, loss: 0.025099
 >> iter 34000, loss: 0.024096
 >> iter 35000, loss: 0.030147
 >> iter 36000, loss: 0.024733
 >> iter 37000, loss: 0.022221
 >> iter 38000, loss: 0.037549
 >> iter 39000, loss: 0.027511
 >> iter 40000, loss: 0.026499
   Number of active neurons: 2
 >> iter 41000, loss: 0.023856
 >> iter 42000, loss: 0.024867
 >> iter 43000, loss: 0.022189
 >> iter 44000, loss: 0.021060
 >> iter 45000, loss: 0.054268
 >> iter 46000, loss: 0.033092
 >> iter 47000, loss: 0.036795
 >> iter 48000, loss: 0.027202
 >> iter 49000, loss: 0.023502
 >> iter 50000, loss: 0.023991
   Number of active neurons: 2
 >> iter 51000, loss: 0.021055
 >> iter 52000, loss: 0.020076
 >> iter 53000, loss: 0.021717
 >> iter 54000, loss: 0.028281
 >> iter 55000, loss: 0.027521
 >> iter 56000, loss: 0.021519
 >> iter 57000, loss: 0.024052
 >> iter 58000, loss: 0.021022
 >> iter 59000, loss: 0.019642
 >> iter 60000, loss: 0.019489
   Number of active neurons: 2
 >> iter 61000, loss: 0.021693
 >> iter 62000, loss: 0.019762
 >> iter 63000, loss: 0.023984
 >> iter 64000, loss: 0.022317
 >> iter 65000, loss: 0.022442
 >> iter 66000, loss: 0.020625
 >> iter 67000, loss: 0.020801
 >> iter 68000, loss: 0.019697
 >> iter 69000, loss: 0.028320
 >> iter 70000, loss: 0.030119
   Number of active neurons: 2
 >> iter 71000, loss: 0.024388
 >> iter 72000, loss: 0.022070
 >> iter 73000, loss: 0.037543
 >> iter 74000, loss: 0.026715
 >> iter 75000, loss: 0.022898
 >> iter 76000, loss: 0.020881
 >> iter 77000, loss: 0.023173
 >> iter 78000, loss: 0.021428
 >> iter 79000, loss: 0.028089
 >> iter 80000, loss: 0.028661
   Number of active neurons: 2
 >> iter 81000, loss: 0.023261
 >> iter 82000, loss: 0.024832
 >> iter 83000, loss: 0.022018
 >> iter 84000, loss: 0.020757
 >> iter 85000, loss: 0.020752
 >> iter 86000, loss: 0.020293
 >> iter 87000, loss: 0.021285
 >> iter 88000, loss: 0.025741
 >> iter 89000, loss: 0.021516
 >> iter 90000, loss: 0.031826
   Number of active neurons: 2
 >> iter 91000, loss: 0.025879
 >> iter 92000, loss: 0.022869
 >> iter 93000, loss: 0.022575
 >> iter 94000, loss: 0.024481
 >> iter 95000, loss: 0.023797
 >> iter 96000, loss: 0.044755
 >> iter 97000, loss: 0.031261
 >> iter 98000, loss: 0.027267
 >> iter 99000, loss: 0.022546
 >> iter 100000, loss: 0.022482
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.922292
 >> iter 2000, loss: 4.052536
 >> iter 3000, loss: 1.527655
 >> iter 4000, loss: 0.583475
 >> iter 5000, loss: 0.236810
 >> iter 6000, loss: 0.106050
 >> iter 7000, loss: 0.056620
 >> iter 8000, loss: 0.039606
 >> iter 9000, loss: 0.035480
 >> iter 10000, loss: 0.028843
   Number of active neurons: 3
 >> iter 11000, loss: 0.028495
 >> iter 12000, loss: 0.024707
 >> iter 13000, loss: 0.024436
 >> iter 14000, loss: 0.028638
 >> iter 15000, loss: 0.024805
 >> iter 16000, loss: 0.025065
 >> iter 17000, loss: 0.026450
 >> iter 18000, loss: 0.024841
 >> iter 19000, loss: 0.026454
 >> iter 20000, loss: 0.026213
   Number of active neurons: 3
 >> iter 21000, loss: 0.030220
 >> iter 22000, loss: 0.023296
 >> iter 23000, loss: 0.021784
 >> iter 24000, loss: 0.023480
 >> iter 25000, loss: 0.026951
 >> iter 26000, loss: 0.024547
 >> iter 27000, loss: 0.022730
 >> iter 28000, loss: 0.022543
 >> iter 29000, loss: 0.022709
 >> iter 30000, loss: 0.020438
   Number of active neurons: 2
 >> iter 31000, loss: 0.023240
 >> iter 32000, loss: 0.031742
 >> iter 33000, loss: 0.025524
 >> iter 34000, loss: 0.024242
 >> iter 35000, loss: 0.022582
 >> iter 36000, loss: 0.020972
 >> iter 37000, loss: 0.039331
 >> iter 38000, loss: 0.027868
 >> iter 39000, loss: 0.028076
 >> iter 40000, loss: 0.025591
   Number of active neurons: 2
 >> iter 41000, loss: 0.035886
 >> iter 42000, loss: 0.025000
 >> iter 43000, loss: 0.025185
 >> iter 44000, loss: 0.021547
 >> iter 45000, loss: 0.019878
 >> iter 46000, loss: 0.021787
 >> iter 47000, loss: 0.026005
 >> iter 48000, loss: 0.030092
 >> iter 49000, loss: 0.023436
 >> iter 50000, loss: 0.034924
   Number of active neurons: 2
 >> iter 51000, loss: 0.026460
 >> iter 52000, loss: 0.032823
 >> iter 53000, loss: 0.024655
 >> iter 54000, loss: 0.024470
 >> iter 55000, loss: 0.022358
 >> iter 56000, loss: 0.039302
 >> iter 57000, loss: 0.029378
 >> iter 58000, loss: 0.025582
 >> iter 59000, loss: 0.037565
 >> iter 60000, loss: 0.028957
   Number of active neurons: 2
 >> iter 61000, loss: 0.023510
 >> iter 62000, loss: 0.021573
 >> iter 63000, loss: 0.020727
 >> iter 64000, loss: 0.027103
 >> iter 65000, loss: 0.023210
 >> iter 66000, loss: 0.021762
 >> iter 67000, loss: 0.026784
 >> iter 68000, loss: 0.025257
 >> iter 69000, loss: 0.023850
 >> iter 70000, loss: 0.023096
   Number of active neurons: 2
 >> iter 71000, loss: 0.021656
 >> iter 72000, loss: 0.032313
 >> iter 73000, loss: 0.024393
 >> iter 74000, loss: 0.028896
 >> iter 75000, loss: 0.034267
 >> iter 76000, loss: 0.027091
 >> iter 77000, loss: 0.024121
 >> iter 78000, loss: 0.027500
 >> iter 79000, loss: 0.024988
 >> iter 80000, loss: 0.024030
   Number of active neurons: 2
 >> iter 81000, loss: 0.021376
 >> iter 82000, loss: 0.023543
 >> iter 83000, loss: 0.022644
 >> iter 84000, loss: 0.024265
 >> iter 85000, loss: 0.021596
 >> iter 86000, loss: 0.023423
 >> iter 87000, loss: 0.023119
 >> iter 88000, loss: 0.024742
 >> iter 89000, loss: 0.023740
 >> iter 90000, loss: 0.024068
   Number of active neurons: 2
 >> iter 91000, loss: 0.031008
 >> iter 92000, loss: 0.026276
 >> iter 93000, loss: 0.042177
 >> iter 94000, loss: 0.043112
 >> iter 95000, loss: 0.033322
 >> iter 96000, loss: 0.026333
 >> iter 97000, loss: 0.022684
 >> iter 98000, loss: 0.025509
 >> iter 99000, loss: 0.023940
 >> iter 100000, loss: 0.021642
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.052956
 >> iter 2000, loss: 4.106225
 >> iter 3000, loss: 1.540528
 >> iter 4000, loss: 0.585922
 >> iter 5000, loss: 0.236168
 >> iter 6000, loss: 0.115367
 >> iter 7000, loss: 0.072421
 >> iter 8000, loss: 0.050730
 >> iter 9000, loss: 0.035778
 >> iter 10000, loss: 0.030021
   Number of active neurons: 4
 >> iter 11000, loss: 0.031831
 >> iter 12000, loss: 0.030701
 >> iter 13000, loss: 0.030692
 >> iter 14000, loss: 0.033794
 >> iter 15000, loss: 0.037129
 >> iter 16000, loss: 0.035757
 >> iter 17000, loss: 0.029791
 >> iter 18000, loss: 0.026335
 >> iter 19000, loss: 0.024874
 >> iter 20000, loss: 0.030695
   Number of active neurons: 3
 >> iter 21000, loss: 0.027154
 >> iter 22000, loss: 0.027682
 >> iter 23000, loss: 0.023014
 >> iter 24000, loss: 0.023244
 >> iter 25000, loss: 0.025491
 >> iter 26000, loss: 0.024510
 >> iter 27000, loss: 0.023876
 >> iter 28000, loss: 0.024374
 >> iter 29000, loss: 0.023705
 >> iter 30000, loss: 0.027517
   Number of active neurons: 3
 >> iter 31000, loss: 0.025119
 >> iter 32000, loss: 0.025047
 >> iter 33000, loss: 0.023341
 >> iter 34000, loss: 0.028843
 >> iter 35000, loss: 0.025472
 >> iter 36000, loss: 0.028217
 >> iter 37000, loss: 0.033050
 >> iter 38000, loss: 0.024967
 >> iter 39000, loss: 0.024574
 >> iter 40000, loss: 0.022470
   Number of active neurons: 1
 >> iter 41000, loss: 0.021671
 >> iter 42000, loss: 0.035078
 >> iter 43000, loss: 0.038855
 >> iter 44000, loss: 0.027825
 >> iter 45000, loss: 0.022248
 >> iter 46000, loss: 0.020141
 >> iter 47000, loss: 0.018352
 >> iter 48000, loss: 0.017318
 >> iter 49000, loss: 0.020958
 >> iter 50000, loss: 0.023803
   Number of active neurons: 1
 >> iter 51000, loss: 0.042684
 >> iter 52000, loss: 0.029778
 >> iter 53000, loss: 0.027966
 >> iter 54000, loss: 0.022657
 >> iter 55000, loss: 0.033582
 >> iter 56000, loss: 0.024248
 >> iter 57000, loss: 0.021992
 >> iter 58000, loss: 0.025857
 >> iter 59000, loss: 0.021904
 >> iter 60000, loss: 0.019934
   Number of active neurons: 1
 >> iter 61000, loss: 0.020656
 >> iter 62000, loss: 0.019239
 >> iter 63000, loss: 0.017131
 >> iter 64000, loss: 0.018511
 >> iter 65000, loss: 0.020435
 >> iter 66000, loss: 0.022123
 >> iter 67000, loss: 0.022066
 >> iter 68000, loss: 0.018909
 >> iter 69000, loss: 0.022315
 >> iter 70000, loss: 0.026789
   Number of active neurons: 1
 >> iter 71000, loss: 0.019854
 >> iter 72000, loss: 0.017730
 >> iter 73000, loss: 0.021554
 >> iter 74000, loss: 0.018468
 >> iter 75000, loss: 0.017418
 >> iter 76000, loss: 0.036143
 >> iter 77000, loss: 0.029361
 >> iter 78000, loss: 0.021078
 >> iter 79000, loss: 0.046905
 >> iter 80000, loss: 0.028052
   Number of active neurons: 1
 >> iter 81000, loss: 0.026284
 >> iter 82000, loss: 0.039673
 >> iter 83000, loss: 0.028184
 >> iter 84000, loss: 0.031959
 >> iter 85000, loss: 0.022843
 >> iter 86000, loss: 0.019036
 >> iter 87000, loss: 0.029612
 >> iter 88000, loss: 0.021324
 >> iter 89000, loss: 0.019553
 >> iter 90000, loss: 0.018393
   Number of active neurons: 1
 >> iter 91000, loss: 0.017193
 >> iter 92000, loss: 0.016773
 >> iter 93000, loss: 0.020131
 >> iter 94000, loss: 0.021799
 >> iter 95000, loss: 0.022206
 >> iter 96000, loss: 0.017689
 >> iter 97000, loss: 0.022297
 >> iter 98000, loss: 0.018672
 >> iter 99000, loss: 0.016421
 >> iter 100000, loss: 0.015420
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.015258
 >> iter 2000, loss: 4.111166
 >> iter 3000, loss: 1.561774
 >> iter 4000, loss: 0.604312
 >> iter 5000, loss: 0.258267
 >> iter 6000, loss: 0.114508
 >> iter 7000, loss: 0.087464
 >> iter 8000, loss: 0.055974
 >> iter 9000, loss: 0.039881
 >> iter 10000, loss: 0.064081
   Number of active neurons: 7
 >> iter 11000, loss: 0.044702
 >> iter 12000, loss: 0.034786
 >> iter 13000, loss: 0.032666
 >> iter 14000, loss: 0.029670
 >> iter 15000, loss: 0.028552
 >> iter 16000, loss: 0.028412
 >> iter 17000, loss: 0.028070
 >> iter 18000, loss: 0.025687
 >> iter 19000, loss: 0.026975
 >> iter 20000, loss: 0.025056
   Number of active neurons: 2
 >> iter 21000, loss: 0.023256
 >> iter 22000, loss: 0.023903
 >> iter 23000, loss: 0.022330
 >> iter 24000, loss: 0.021839
 >> iter 25000, loss: 0.034435
 >> iter 26000, loss: 0.028231
 >> iter 27000, loss: 0.031347
 >> iter 28000, loss: 0.025761
 >> iter 29000, loss: 0.025088
 >> iter 30000, loss: 0.022420
   Number of active neurons: 2
 >> iter 31000, loss: 0.035680
 >> iter 32000, loss: 0.033171
 >> iter 33000, loss: 0.024124
 >> iter 34000, loss: 0.020196
 >> iter 35000, loss: 0.029072
 >> iter 36000, loss: 0.033269
 >> iter 37000, loss: 0.025729
 >> iter 38000, loss: 0.020845
 >> iter 39000, loss: 0.025116
 >> iter 40000, loss: 0.041505
   Number of active neurons: 2
 >> iter 41000, loss: 0.030962
 >> iter 42000, loss: 0.025267
 >> iter 43000, loss: 0.024524
 >> iter 44000, loss: 0.023895
 >> iter 45000, loss: 0.037281
 >> iter 46000, loss: 0.031634
 >> iter 47000, loss: 0.023406
 >> iter 48000, loss: 0.026772
 >> iter 49000, loss: 0.043207
 >> iter 50000, loss: 0.030897
   Number of active neurons: 2
 >> iter 51000, loss: 0.037708
 >> iter 52000, loss: 0.027853
 >> iter 53000, loss: 0.024014
 >> iter 54000, loss: 0.022579
 >> iter 55000, loss: 0.028572
 >> iter 56000, loss: 0.026450
 >> iter 57000, loss: 0.027930
 >> iter 58000, loss: 0.026289
 >> iter 59000, loss: 0.023787
 >> iter 60000, loss: 0.022776
   Number of active neurons: 2
 >> iter 61000, loss: 0.020521
 >> iter 62000, loss: 0.023032
 >> iter 63000, loss: 0.057391
 >> iter 64000, loss: 0.034729
 >> iter 65000, loss: 0.029074
 >> iter 66000, loss: 0.031999
 >> iter 67000, loss: 0.026739
 >> iter 68000, loss: 0.039653
 >> iter 69000, loss: 0.028303
 >> iter 70000, loss: 0.025178
   Number of active neurons: 1
 >> iter 71000, loss: 0.045076
 >> iter 72000, loss: 0.042630
 >> iter 73000, loss: 0.033191
 >> iter 74000, loss: 0.025644
 >> iter 75000, loss: 0.031376
 >> iter 76000, loss: 0.027223
 >> iter 77000, loss: 0.023261
 >> iter 78000, loss: 0.025759
 >> iter 79000, loss: 0.019476
 >> iter 80000, loss: 0.019755
   Number of active neurons: 1
 >> iter 81000, loss: 0.017521
 >> iter 82000, loss: 0.024647
 >> iter 83000, loss: 0.020907
 >> iter 84000, loss: 0.088403
 >> iter 85000, loss: 0.056049
 >> iter 86000, loss: 0.031978
 >> iter 87000, loss: 0.024108
 >> iter 88000, loss: 0.024804
 >> iter 89000, loss: 0.020397
 >> iter 90000, loss: 0.016999
   Number of active neurons: 1
 >> iter 91000, loss: 0.018953
 >> iter 92000, loss: 0.034500
 >> iter 93000, loss: 0.031678
 >> iter 94000, loss: 0.022505
 >> iter 95000, loss: 0.028293
 >> iter 96000, loss: 0.032778
 >> iter 97000, loss: 0.023442
 >> iter 98000, loss: 0.018314
 >> iter 99000, loss: 0.021699
 >> iter 100000, loss: 0.018671
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.893396
 >> iter 2000, loss: 4.050110
 >> iter 3000, loss: 1.514337
 >> iter 4000, loss: 0.575169
 >> iter 5000, loss: 0.228168
 >> iter 6000, loss: 0.108963
 >> iter 7000, loss: 0.055810
 >> iter 8000, loss: 0.044871
 >> iter 9000, loss: 0.043353
 >> iter 10000, loss: 0.031655
   Number of active neurons: 3
 >> iter 11000, loss: 0.027829
 >> iter 12000, loss: 0.029635
 >> iter 13000, loss: 0.031827
 >> iter 14000, loss: 0.026218
 >> iter 15000, loss: 0.024243
 >> iter 16000, loss: 0.026827
 >> iter 17000, loss: 0.026519
 >> iter 18000, loss: 0.025950
 >> iter 19000, loss: 0.022718
 >> iter 20000, loss: 0.024378
   Number of active neurons: 2
 >> iter 21000, loss: 0.027207
 >> iter 22000, loss: 0.024172
 >> iter 23000, loss: 0.051687
 >> iter 24000, loss: 0.035328
 >> iter 25000, loss: 0.033946
 >> iter 26000, loss: 0.026388
 >> iter 27000, loss: 0.021374
 >> iter 28000, loss: 0.021220
 >> iter 29000, loss: 0.021329
 >> iter 30000, loss: 0.019714
   Number of active neurons: 2
 >> iter 31000, loss: 0.019857
 >> iter 32000, loss: 0.021346
 >> iter 33000, loss: 0.020046
 >> iter 34000, loss: 0.023045
 >> iter 35000, loss: 0.031265
 >> iter 36000, loss: 0.032521
 >> iter 37000, loss: 0.058840
 >> iter 38000, loss: 0.037315
 >> iter 39000, loss: 0.036020
 >> iter 40000, loss: 0.031337
   Number of active neurons: 2
 >> iter 41000, loss: 0.024184
 >> iter 42000, loss: 0.022812
 >> iter 43000, loss: 0.020169
 >> iter 44000, loss: 0.024068
 >> iter 45000, loss: 0.035870
 >> iter 46000, loss: 0.028558
 >> iter 47000, loss: 0.023719
 >> iter 48000, loss: 0.021377
 >> iter 49000, loss: 0.038282
 >> iter 50000, loss: 0.029142
   Number of active neurons: 2
 >> iter 51000, loss: 0.032917
 >> iter 52000, loss: 0.031781
 >> iter 53000, loss: 0.023743
 >> iter 54000, loss: 0.021406
 >> iter 55000, loss: 0.024183
 >> iter 56000, loss: 0.057309
 >> iter 57000, loss: 0.033373
 >> iter 58000, loss: 0.026971
 >> iter 59000, loss: 0.041206
 >> iter 60000, loss: 0.029485
   Number of active neurons: 2
 >> iter 61000, loss: 0.024244
 >> iter 62000, loss: 0.026068
 >> iter 63000, loss: 0.024455
 >> iter 64000, loss: 0.020632
 >> iter 65000, loss: 0.021878
 >> iter 66000, loss: 0.026894
 >> iter 67000, loss: 0.024478
 >> iter 68000, loss: 0.028399
 >> iter 69000, loss: 0.030784
 >> iter 70000, loss: 0.025491
   Number of active neurons: 2
 >> iter 71000, loss: 0.026162
 >> iter 72000, loss: 0.040751
 >> iter 73000, loss: 0.029958
 >> iter 74000, loss: 0.031064
 >> iter 75000, loss: 0.036170
 >> iter 76000, loss: 0.028906
 >> iter 77000, loss: 0.032147
 >> iter 78000, loss: 0.025888
 >> iter 79000, loss: 0.032671
 >> iter 80000, loss: 0.041276
   Number of active neurons: 2
 >> iter 81000, loss: 0.027424
 >> iter 82000, loss: 0.024406
 >> iter 83000, loss: 0.024796
 >> iter 84000, loss: 0.023565
 >> iter 85000, loss: 0.022120
 >> iter 86000, loss: 0.020529
 >> iter 87000, loss: 0.022035
 >> iter 88000, loss: 0.024445
 >> iter 89000, loss: 0.043537
 >> iter 90000, loss: 0.032630
   Number of active neurons: 2
 >> iter 91000, loss: 0.027196
 >> iter 92000, loss: 0.028620
 >> iter 93000, loss: 0.024235
 >> iter 94000, loss: 0.023751
 >> iter 95000, loss: 0.021212
 >> iter 96000, loss: 0.025139
 >> iter 97000, loss: 0.025729
 >> iter 98000, loss: 0.026661
 >> iter 99000, loss: 0.030517
 >> iter 100000, loss: 0.025660
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.939158
 >> iter 2000, loss: 4.075342
 >> iter 3000, loss: 1.523407
 >> iter 4000, loss: 0.588145
 >> iter 5000, loss: 0.235385
 >> iter 6000, loss: 0.110212
 >> iter 7000, loss: 0.065518
 >> iter 8000, loss: 0.042500
 >> iter 9000, loss: 0.033250
 >> iter 10000, loss: 0.050754
   Number of active neurons: 5
 >> iter 11000, loss: 0.037963
 >> iter 12000, loss: 0.035494
 >> iter 13000, loss: 0.036053
 >> iter 14000, loss: 0.034519
 >> iter 15000, loss: 0.034325
 >> iter 16000, loss: 0.029649
 >> iter 17000, loss: 0.027152
 >> iter 18000, loss: 0.025121
 >> iter 19000, loss: 0.023700
 >> iter 20000, loss: 0.035679
   Number of active neurons: 3
 >> iter 21000, loss: 0.032187
 >> iter 22000, loss: 0.027539
 >> iter 23000, loss: 0.028986
 >> iter 24000, loss: 0.025136
 >> iter 25000, loss: 0.025064
 >> iter 26000, loss: 0.023944
 >> iter 27000, loss: 0.030626
 >> iter 28000, loss: 0.028968
 >> iter 29000, loss: 0.031985
 >> iter 30000, loss: 0.028397
   Number of active neurons: 2
 >> iter 31000, loss: 0.024768
 >> iter 32000, loss: 0.021411
 >> iter 33000, loss: 0.021460
 >> iter 34000, loss: 0.035666
 >> iter 35000, loss: 0.034118
 >> iter 36000, loss: 0.028141
 >> iter 37000, loss: 0.029836
 >> iter 38000, loss: 0.026136
 >> iter 39000, loss: 0.024103
 >> iter 40000, loss: 0.022511
   Number of active neurons: 2
 >> iter 41000, loss: 0.059075
 >> iter 42000, loss: 0.037429
 >> iter 43000, loss: 0.029894
 >> iter 44000, loss: 0.029214
 >> iter 45000, loss: 0.024806
 >> iter 46000, loss: 0.022253
 >> iter 47000, loss: 0.025942
 >> iter 48000, loss: 0.029159
 >> iter 49000, loss: 0.027960
 >> iter 50000, loss: 0.023283
   Number of active neurons: 2
 >> iter 51000, loss: 0.021167
 >> iter 52000, loss: 0.019746
 >> iter 53000, loss: 0.027238
 >> iter 54000, loss: 0.030667
 >> iter 55000, loss: 0.033931
 >> iter 56000, loss: 0.025588
 >> iter 57000, loss: 0.026617
 >> iter 58000, loss: 0.025930
 >> iter 59000, loss: 0.022637
 >> iter 60000, loss: 0.023211
   Number of active neurons: 2
 >> iter 61000, loss: 0.025213
 >> iter 62000, loss: 0.021604
 >> iter 63000, loss: 0.020785
 >> iter 64000, loss: 0.020152
 >> iter 65000, loss: 0.022627
 >> iter 66000, loss: 0.022135
 >> iter 67000, loss: 0.025676
 >> iter 68000, loss: 0.021713
 >> iter 69000, loss: 0.020698
 >> iter 70000, loss: 0.033895
   Number of active neurons: 1
 >> iter 71000, loss: 0.023148
 >> iter 72000, loss: 0.021252
 >> iter 73000, loss: 0.020278
 >> iter 74000, loss: 0.025371
 >> iter 75000, loss: 0.024290
 >> iter 76000, loss: 0.019661
 >> iter 77000, loss: 0.022468
 >> iter 78000, loss: 0.019231
 >> iter 79000, loss: 0.019291
 >> iter 80000, loss: 0.019387
   Number of active neurons: 1
 >> iter 81000, loss: 0.033716
 >> iter 82000, loss: 0.022321
 >> iter 83000, loss: 0.018350
 >> iter 84000, loss: 0.019114
 >> iter 85000, loss: 0.023668
 >> iter 86000, loss: 0.031483
 >> iter 87000, loss: 0.026531
 >> iter 88000, loss: 0.021167
 >> iter 89000, loss: 0.021936
 >> iter 90000, loss: 0.020528
   Number of active neurons: 1
 >> iter 91000, loss: 0.017464
 >> iter 92000, loss: 0.016867
 >> iter 93000, loss: 0.017335
 >> iter 94000, loss: 0.017033
 >> iter 95000, loss: 0.020464
 >> iter 96000, loss: 0.018027
 >> iter 97000, loss: 0.022614
 >> iter 98000, loss: 0.029334
 >> iter 99000, loss: 0.027695
 >> iter 100000, loss: 0.021094
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.959114
 >> iter 2000, loss: 4.089019
 >> iter 3000, loss: 1.551854
 >> iter 4000, loss: 0.595592
 >> iter 5000, loss: 0.242527
 >> iter 6000, loss: 0.115662
 >> iter 7000, loss: 0.067046
 >> iter 8000, loss: 0.042886
 >> iter 9000, loss: 0.044303
 >> iter 10000, loss: 0.036193
   Number of active neurons: 3
 >> iter 11000, loss: 0.034028
 >> iter 12000, loss: 0.034381
 >> iter 13000, loss: 0.030325
 >> iter 14000, loss: 0.028236
 >> iter 15000, loss: 0.039430
 >> iter 16000, loss: 0.071164
 >> iter 17000, loss: 0.041810
 >> iter 18000, loss: 0.040278
 >> iter 19000, loss: 0.034756
 >> iter 20000, loss: 0.032741
   Number of active neurons: 3
 >> iter 21000, loss: 0.028274
 >> iter 22000, loss: 0.039135
 >> iter 23000, loss: 0.029497
 >> iter 24000, loss: 0.026949
 >> iter 25000, loss: 0.031584
 >> iter 26000, loss: 0.025885
 >> iter 27000, loss: 0.022422
 >> iter 28000, loss: 0.024359
 >> iter 29000, loss: 0.024102
 >> iter 30000, loss: 0.025330
   Number of active neurons: 1
 >> iter 31000, loss: 0.023677
 >> iter 32000, loss: 0.019653
 >> iter 33000, loss: 0.017871
 >> iter 34000, loss: 0.024633
 >> iter 35000, loss: 0.022035
 >> iter 36000, loss: 0.021057
 >> iter 37000, loss: 0.022275
 >> iter 38000, loss: 0.022575
 >> iter 39000, loss: 0.020504
 >> iter 40000, loss: 0.018109
   Number of active neurons: 1
 >> iter 41000, loss: 0.027612
 >> iter 42000, loss: 0.021920
 >> iter 43000, loss: 0.020930
 >> iter 44000, loss: 0.024148
 >> iter 45000, loss: 0.020662
 >> iter 46000, loss: 0.036431
 >> iter 47000, loss: 0.026550
 >> iter 48000, loss: 0.019980
 >> iter 49000, loss: 0.021978
 >> iter 50000, loss: 0.030176
   Number of active neurons: 1
 >> iter 51000, loss: 0.021118
 >> iter 52000, loss: 0.017403
 >> iter 53000, loss: 0.024679
 >> iter 54000, loss: 0.023464
 >> iter 55000, loss: 0.023050
 >> iter 56000, loss: 0.020754
 >> iter 57000, loss: 0.018271
 >> iter 58000, loss: 0.020702
 >> iter 59000, loss: 0.018747
 >> iter 60000, loss: 0.016893
   Number of active neurons: 1
 >> iter 61000, loss: 0.018151
 >> iter 62000, loss: 0.016341
 >> iter 63000, loss: 0.017304
 >> iter 64000, loss: 0.015517
 >> iter 65000, loss: 0.016472
 >> iter 66000, loss: 0.035528
 >> iter 67000, loss: 0.024926
 >> iter 68000, loss: 0.019550
 >> iter 69000, loss: 0.016927
 >> iter 70000, loss: 0.018180
   Number of active neurons: 1
 >> iter 71000, loss: 0.017144
 >> iter 72000, loss: 0.020773
 >> iter 73000, loss: 0.018283
 >> iter 74000, loss: 0.033864
 >> iter 75000, loss: 0.024273
 >> iter 76000, loss: 0.023962
 >> iter 77000, loss: 0.019894
 >> iter 78000, loss: 0.026550
 >> iter 79000, loss: 0.019217
 >> iter 80000, loss: 0.019385
   Number of active neurons: 1
 >> iter 81000, loss: 0.018791
 >> iter 82000, loss: 0.016849
 >> iter 83000, loss: 0.030343
 >> iter 84000, loss: 0.023772
 >> iter 85000, loss: 0.026520
 >> iter 86000, loss: 0.019097
 >> iter 87000, loss: 0.070554
 >> iter 88000, loss: 0.037893
 >> iter 89000, loss: 0.026983
 >> iter 90000, loss: 0.022651
   Number of active neurons: 1
 >> iter 91000, loss: 0.030166
 >> iter 92000, loss: 0.023230
 >> iter 93000, loss: 0.021824
 >> iter 94000, loss: 0.032876
 >> iter 95000, loss: 0.022708
 >> iter 96000, loss: 0.019385
 >> iter 97000, loss: 0.017320
 >> iter 98000, loss: 0.019188
 >> iter 99000, loss: 0.018339
 >> iter 100000, loss: 0.029990
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.910668
 >> iter 2000, loss: 4.063874
 >> iter 3000, loss: 1.524061
 >> iter 4000, loss: 0.585442
 >> iter 5000, loss: 0.256950
 >> iter 6000, loss: 0.116680
 >> iter 7000, loss: 0.061695
 >> iter 8000, loss: 0.042751
 >> iter 9000, loss: 0.032079
 >> iter 10000, loss: 0.038520
   Number of active neurons: 3
 >> iter 11000, loss: 0.029811
 >> iter 12000, loss: 0.026542
 >> iter 13000, loss: 0.025141
 >> iter 14000, loss: 0.024153
 >> iter 15000, loss: 0.024351
 >> iter 16000, loss: 0.025064
 >> iter 17000, loss: 0.027884
 >> iter 18000, loss: 0.025595
 >> iter 19000, loss: 0.031269
 >> iter 20000, loss: 0.025011
   Number of active neurons: 2
 >> iter 21000, loss: 0.023184
 >> iter 22000, loss: 0.030930
 >> iter 23000, loss: 0.023928
 >> iter 24000, loss: 0.038585
 >> iter 25000, loss: 0.026981
 >> iter 26000, loss: 0.023675
 >> iter 27000, loss: 0.026439
 >> iter 28000, loss: 0.030422
 >> iter 29000, loss: 0.049069
 >> iter 30000, loss: 0.030362
   Number of active neurons: 1
 >> iter 31000, loss: 0.032398
 >> iter 32000, loss: 0.026838
 >> iter 33000, loss: 0.060257
 >> iter 34000, loss: 0.034055
 >> iter 35000, loss: 0.023999
 >> iter 36000, loss: 0.020249
 >> iter 37000, loss: 0.020607
 >> iter 38000, loss: 0.036172
 >> iter 39000, loss: 0.039432
 >> iter 40000, loss: 0.025497
   Number of active neurons: 1
 >> iter 41000, loss: 0.034052
 >> iter 42000, loss: 0.023325
 >> iter 43000, loss: 0.024229
 >> iter 44000, loss: 0.022702
 >> iter 45000, loss: 0.032269
 >> iter 46000, loss: 0.041421
 >> iter 47000, loss: 0.030201
 >> iter 48000, loss: 0.023581
 >> iter 49000, loss: 0.020096
 >> iter 50000, loss: 0.022345
   Number of active neurons: 1
 >> iter 51000, loss: 0.019109
 >> iter 52000, loss: 0.017145
 >> iter 53000, loss: 0.034999
 >> iter 54000, loss: 0.024530
 >> iter 55000, loss: 0.020443
 >> iter 56000, loss: 0.018973
 >> iter 57000, loss: 0.018692
 >> iter 58000, loss: 0.016490
 >> iter 59000, loss: 0.037950
 >> iter 60000, loss: 0.029123
   Number of active neurons: 1
 >> iter 61000, loss: 0.021424
 >> iter 62000, loss: 0.017780
 >> iter 63000, loss: 0.017253
 >> iter 64000, loss: 0.031628
 >> iter 65000, loss: 0.022232
 >> iter 66000, loss: 0.021471
 >> iter 67000, loss: 0.019415
 >> iter 68000, loss: 0.019058
 >> iter 69000, loss: 0.016712
 >> iter 70000, loss: 0.016368
   Number of active neurons: 1
 >> iter 71000, loss: 0.017703
 >> iter 72000, loss: 0.021191
 >> iter 73000, loss: 0.033060
 >> iter 74000, loss: 0.025720
 >> iter 75000, loss: 0.022248
 >> iter 76000, loss: 0.024050
 >> iter 77000, loss: 0.022049
 >> iter 78000, loss: 0.017660
 >> iter 79000, loss: 0.017165
 >> iter 80000, loss: 0.018276
   Number of active neurons: 1
 >> iter 81000, loss: 0.021981
 >> iter 82000, loss: 0.017817
 >> iter 83000, loss: 0.018659
 >> iter 84000, loss: 0.022256
 >> iter 85000, loss: 0.029397
 >> iter 86000, loss: 0.046915
 >> iter 87000, loss: 0.030797
 >> iter 88000, loss: 0.022929
 >> iter 89000, loss: 0.019603
 >> iter 90000, loss: 0.020707
   Number of active neurons: 1
 >> iter 91000, loss: 0.020386
 >> iter 92000, loss: 0.018757
 >> iter 93000, loss: 0.018161
 >> iter 94000, loss: 0.016730
 >> iter 95000, loss: 0.017450
 >> iter 96000, loss: 0.022089
 >> iter 97000, loss: 0.018460
 >> iter 98000, loss: 0.019299
 >> iter 99000, loss: 0.019639
 >> iter 100000, loss: 0.016475
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.000185
 >> iter 2000, loss: 4.087917
 >> iter 3000, loss: 1.546358
 >> iter 4000, loss: 0.589038
 >> iter 5000, loss: 0.243287
 >> iter 6000, loss: 0.110612
 >> iter 7000, loss: 0.059852
 >> iter 8000, loss: 0.048391
 >> iter 9000, loss: 0.062435
 >> iter 10000, loss: 0.042554
   Number of active neurons: 5
 >> iter 11000, loss: 0.035176
 >> iter 12000, loss: 0.030833
 >> iter 13000, loss: 0.034824
 >> iter 14000, loss: 0.034190
 >> iter 15000, loss: 0.053410
 >> iter 16000, loss: 0.042033
 >> iter 17000, loss: 0.046481
 >> iter 18000, loss: 0.034466
 >> iter 19000, loss: 0.031826
 >> iter 20000, loss: 0.067725
   Number of active neurons: 5
 >> iter 21000, loss: 0.041761
 >> iter 22000, loss: 0.032295
 >> iter 23000, loss: 0.027037
 >> iter 24000, loss: 0.027983
 >> iter 25000, loss: 0.026153
 >> iter 26000, loss: 0.024708
 >> iter 27000, loss: 0.022944
 >> iter 28000, loss: 0.023902
 >> iter 29000, loss: 0.023690
 >> iter 30000, loss: 0.023835
   Number of active neurons: 3
 >> iter 31000, loss: 0.026918
 >> iter 32000, loss: 0.026504
 >> iter 33000, loss: 0.023894
 >> iter 34000, loss: 0.023269
 >> iter 35000, loss: 0.028023
 >> iter 36000, loss: 0.024240
 >> iter 37000, loss: 0.022382
 >> iter 38000, loss: 0.022912
 >> iter 39000, loss: 0.025518
 >> iter 40000, loss: 0.025199
   Number of active neurons: 2
 >> iter 41000, loss: 0.021914
 >> iter 42000, loss: 0.022666
 >> iter 43000, loss: 0.027673
 >> iter 44000, loss: 0.050223
 >> iter 45000, loss: 0.033462
 >> iter 46000, loss: 0.027790
 >> iter 47000, loss: 0.024216
 >> iter 48000, loss: 0.021344
 >> iter 49000, loss: 0.019941
 >> iter 50000, loss: 0.020530
   Number of active neurons: 2
 >> iter 51000, loss: 0.027432
 >> iter 52000, loss: 0.028932
 >> iter 53000, loss: 0.023106
 >> iter 54000, loss: 0.024423
 >> iter 55000, loss: 0.020045
 >> iter 56000, loss: 0.018997
 >> iter 57000, loss: 0.021996
 >> iter 58000, loss: 0.025508
 >> iter 59000, loss: 0.022247
 >> iter 60000, loss: 0.025505
   Number of active neurons: 2
 >> iter 61000, loss: 0.027210
 >> iter 62000, loss: 0.026843
 >> iter 63000, loss: 0.023409
 >> iter 64000, loss: 0.020985
 >> iter 65000, loss: 0.020111
 >> iter 66000, loss: 0.041789
 >> iter 67000, loss: 0.031179
 >> iter 68000, loss: 0.025199
 >> iter 69000, loss: 0.048826
 >> iter 70000, loss: 0.033190
   Number of active neurons: 2
 >> iter 71000, loss: 0.031902
 >> iter 72000, loss: 0.038642
 >> iter 73000, loss: 0.035693
 >> iter 74000, loss: 0.029616
 >> iter 75000, loss: 0.024232
 >> iter 76000, loss: 0.022390
 >> iter 77000, loss: 0.020883
 >> iter 78000, loss: 0.030461
 >> iter 79000, loss: 0.032970
 >> iter 80000, loss: 0.026913
   Number of active neurons: 2
 >> iter 81000, loss: 0.029638
 >> iter 82000, loss: 0.026139
 >> iter 83000, loss: 0.023997
 >> iter 84000, loss: 0.022266
 >> iter 85000, loss: 0.027256
 >> iter 86000, loss: 0.033291
 >> iter 87000, loss: 0.027463
 >> iter 88000, loss: 0.023180
 >> iter 89000, loss: 0.024105
 >> iter 90000, loss: 0.022389
   Number of active neurons: 2
 >> iter 91000, loss: 0.022170
 >> iter 92000, loss: 0.023366
 >> iter 93000, loss: 0.020910
 >> iter 94000, loss: 0.020658
 >> iter 95000, loss: 0.023629
 >> iter 96000, loss: 0.023253
 >> iter 97000, loss: 0.027824
 >> iter 98000, loss: 0.026696
 >> iter 99000, loss: 0.023106
 >> iter 100000, loss: 0.022687
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.987603
 >> iter 2000, loss: 4.108514
 >> iter 3000, loss: 1.539042
 >> iter 4000, loss: 0.590678
 >> iter 5000, loss: 0.239634
 >> iter 6000, loss: 0.109210
 >> iter 7000, loss: 0.062506
 >> iter 8000, loss: 0.047714
 >> iter 9000, loss: 0.040691
 >> iter 10000, loss: 0.032505
   Number of active neurons: 5
 >> iter 11000, loss: 0.033682
 >> iter 12000, loss: 0.029186
 >> iter 13000, loss: 0.031899
 >> iter 14000, loss: 0.029617
 >> iter 15000, loss: 0.027568
 >> iter 16000, loss: 0.027771
 >> iter 17000, loss: 0.031025
 >> iter 18000, loss: 0.030340
 >> iter 19000, loss: 0.028952
 >> iter 20000, loss: 0.027201
   Number of active neurons: 4
 >> iter 21000, loss: 0.028667
 >> iter 22000, loss: 0.027110
 >> iter 23000, loss: 0.032666
 >> iter 24000, loss: 0.040790
 >> iter 25000, loss: 0.029704
 >> iter 26000, loss: 0.028257
 >> iter 27000, loss: 0.026954
 >> iter 28000, loss: 0.025289
 >> iter 29000, loss: 0.027384
 >> iter 30000, loss: 0.031423
   Number of active neurons: 4
 >> iter 31000, loss: 0.026693
 >> iter 32000, loss: 0.054994
 >> iter 33000, loss: 0.044051
 >> iter 34000, loss: 0.035873
 >> iter 35000, loss: 0.029285
 >> iter 36000, loss: 0.027062
 >> iter 37000, loss: 0.029376
 >> iter 38000, loss: 0.028224
 >> iter 39000, loss: 0.025827
 >> iter 40000, loss: 0.025447
   Number of active neurons: 4
 >> iter 41000, loss: 0.030065
 >> iter 42000, loss: 0.028371
 >> iter 43000, loss: 0.028954
 >> iter 44000, loss: 0.026413
 >> iter 45000, loss: 0.027578
 >> iter 46000, loss: 0.026638
 >> iter 47000, loss: 0.025603
 >> iter 48000, loss: 0.022584
 >> iter 49000, loss: 0.025967
 >> iter 50000, loss: 0.023413
   Number of active neurons: 3
 >> iter 51000, loss: 0.025077
 >> iter 52000, loss: 0.031866
 >> iter 53000, loss: 0.029243
 >> iter 54000, loss: 0.024199
 >> iter 55000, loss: 0.025027
 >> iter 56000, loss: 0.024323
 >> iter 57000, loss: 0.023560
 >> iter 58000, loss: 0.024186
 >> iter 59000, loss: 0.046447
 >> iter 60000, loss: 0.031191
   Number of active neurons: 2
 >> iter 61000, loss: 0.025590
 >> iter 62000, loss: 0.027491
 >> iter 63000, loss: 0.028218
 >> iter 64000, loss: 0.026186
 >> iter 65000, loss: 0.026104
 >> iter 66000, loss: 0.021675
 >> iter 67000, loss: 0.024501
 >> iter 68000, loss: 0.022775
 >> iter 69000, loss: 0.023324
 >> iter 70000, loss: 0.025023
   Number of active neurons: 2
 >> iter 71000, loss: 0.037709
 >> iter 72000, loss: 0.027578
 >> iter 73000, loss: 0.024466
 >> iter 74000, loss: 0.030679
 >> iter 75000, loss: 0.025348
 >> iter 76000, loss: 0.027310
 >> iter 77000, loss: 0.024287
 >> iter 78000, loss: 0.022216
 >> iter 79000, loss: 0.022401
 >> iter 80000, loss: 0.027726
   Number of active neurons: 2
 >> iter 81000, loss: 0.023847
 >> iter 82000, loss: 0.021467
 >> iter 83000, loss: 0.020630
 >> iter 84000, loss: 0.028061
 >> iter 85000, loss: 0.022538
 >> iter 86000, loss: 0.025231
 >> iter 87000, loss: 0.022374
 >> iter 88000, loss: 0.023191
 >> iter 89000, loss: 0.023315
 >> iter 90000, loss: 0.036355
   Number of active neurons: 1
 >> iter 91000, loss: 0.026041
 >> iter 92000, loss: 0.026038
 >> iter 93000, loss: 0.027728
 >> iter 94000, loss: 0.053785
 >> iter 95000, loss: 0.038456
 >> iter 96000, loss: 0.039651
 >> iter 97000, loss: 0.026936
 >> iter 98000, loss: 0.026591
 >> iter 99000, loss: 0.024269
 >> iter 100000, loss: 0.020860
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.962126
 >> iter 2000, loss: 4.070906
 >> iter 3000, loss: 1.521604
 >> iter 4000, loss: 0.591836
 >> iter 5000, loss: 0.245593
 >> iter 6000, loss: 0.108352
 >> iter 7000, loss: 0.061776
 >> iter 8000, loss: 0.054533
 >> iter 9000, loss: 0.037635
 >> iter 10000, loss: 0.036869
   Number of active neurons: 5
 >> iter 11000, loss: 0.028822
 >> iter 12000, loss: 0.028858
 >> iter 13000, loss: 0.025844
 >> iter 14000, loss: 0.028857
 >> iter 15000, loss: 0.027739
 >> iter 16000, loss: 0.033083
 >> iter 17000, loss: 0.043185
 >> iter 18000, loss: 0.036499
 >> iter 19000, loss: 0.028750
 >> iter 20000, loss: 0.027259
   Number of active neurons: 3
 >> iter 21000, loss: 0.028870
 >> iter 22000, loss: 0.024503
 >> iter 23000, loss: 0.024770
 >> iter 24000, loss: 0.025433
 >> iter 25000, loss: 0.024609
 >> iter 26000, loss: 0.026913
 >> iter 27000, loss: 0.022452
 >> iter 28000, loss: 0.027712
 >> iter 29000, loss: 0.029844
 >> iter 30000, loss: 0.028972
   Number of active neurons: 3
 >> iter 31000, loss: 0.024957
 >> iter 32000, loss: 0.031298
 >> iter 33000, loss: 0.026665
 >> iter 34000, loss: 0.026290
 >> iter 35000, loss: 0.026020
 >> iter 36000, loss: 0.026870
 >> iter 37000, loss: 0.024528
 >> iter 38000, loss: 0.022688
 >> iter 39000, loss: 0.022728
 >> iter 40000, loss: 0.023836
   Number of active neurons: 2
 >> iter 41000, loss: 0.044618
 >> iter 42000, loss: 0.027835
 >> iter 43000, loss: 0.022981
 >> iter 44000, loss: 0.022665
 >> iter 45000, loss: 0.023166
 >> iter 46000, loss: 0.020098
 >> iter 47000, loss: 0.024098
 >> iter 48000, loss: 0.022335
 >> iter 49000, loss: 0.028123
 >> iter 50000, loss: 0.023607
   Number of active neurons: 2
 >> iter 51000, loss: 0.020761
 >> iter 52000, loss: 0.020153
 >> iter 53000, loss: 0.019991
 >> iter 54000, loss: 0.026011
 >> iter 55000, loss: 0.029958
 >> iter 56000, loss: 0.025489
 >> iter 57000, loss: 0.024418
 >> iter 58000, loss: 0.021681
 >> iter 59000, loss: 0.028506
 >> iter 60000, loss: 0.024891
   Number of active neurons: 2
 >> iter 61000, loss: 0.021778
 >> iter 62000, loss: 0.021738
 >> iter 63000, loss: 0.020179
 >> iter 64000, loss: 0.021748
 >> iter 65000, loss: 0.021621
 >> iter 66000, loss: 0.020833
 >> iter 67000, loss: 0.020245
 >> iter 68000, loss: 0.020534
 >> iter 69000, loss: 0.026092
 >> iter 70000, loss: 0.026376
   Number of active neurons: 2
 >> iter 71000, loss: 0.022310
 >> iter 72000, loss: 0.020633
 >> iter 73000, loss: 0.022125
 >> iter 74000, loss: 0.022570
 >> iter 75000, loss: 0.029418
 >> iter 76000, loss: 0.025984
 >> iter 77000, loss: 0.028416
 >> iter 78000, loss: 0.023337
 >> iter 79000, loss: 0.022914
 >> iter 80000, loss: 0.022875
   Number of active neurons: 2
 >> iter 81000, loss: 0.037324
 >> iter 82000, loss: 0.025838
 >> iter 83000, loss: 0.021334
 >> iter 84000, loss: 0.020386
 >> iter 85000, loss: 0.020154
 >> iter 86000, loss: 0.027193
 >> iter 87000, loss: 0.030584
 >> iter 88000, loss: 0.035505
 >> iter 89000, loss: 0.032075
 >> iter 90000, loss: 0.023299
   Number of active neurons: 2
 >> iter 91000, loss: 0.020958
 >> iter 92000, loss: 0.019190
 >> iter 93000, loss: 0.021508
 >> iter 94000, loss: 0.022497
 >> iter 95000, loss: 0.020487
 >> iter 96000, loss: 0.021797
 >> iter 97000, loss: 0.038046
 >> iter 98000, loss: 0.029097
 >> iter 99000, loss: 0.023321
 >> iter 100000, loss: 0.020542
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.907244
 >> iter 2000, loss: 4.061878
 >> iter 3000, loss: 1.520410
 >> iter 4000, loss: 0.581344
 >> iter 5000, loss: 0.232166
 >> iter 6000, loss: 0.105641
 >> iter 7000, loss: 0.057149
 >> iter 8000, loss: 0.038642
 >> iter 9000, loss: 0.032557
 >> iter 10000, loss: 0.029613
   Number of active neurons: 3
 >> iter 11000, loss: 0.030208
 >> iter 12000, loss: 0.033080
 >> iter 13000, loss: 0.025347
 >> iter 14000, loss: 0.025233
 >> iter 15000, loss: 0.025508
 >> iter 16000, loss: 0.024949
 >> iter 17000, loss: 0.025271
 >> iter 18000, loss: 0.024984
 >> iter 19000, loss: 0.023055
 >> iter 20000, loss: 0.022085
   Number of active neurons: 2
 >> iter 21000, loss: 0.022876
 >> iter 22000, loss: 0.020273
 >> iter 23000, loss: 0.024042
 >> iter 24000, loss: 0.025336
 >> iter 25000, loss: 0.021080
 >> iter 26000, loss: 0.021252
 >> iter 27000, loss: 0.020711
 >> iter 28000, loss: 0.020361
 >> iter 29000, loss: 0.021531
 >> iter 30000, loss: 0.022989
   Number of active neurons: 2
 >> iter 31000, loss: 0.021799
 >> iter 32000, loss: 0.027926
 >> iter 33000, loss: 0.024270
 >> iter 34000, loss: 0.026006
 >> iter 35000, loss: 0.023711
 >> iter 36000, loss: 0.031258
 >> iter 37000, loss: 0.026204
 >> iter 38000, loss: 0.023428
 >> iter 39000, loss: 0.021387
 >> iter 40000, loss: 0.019047
   Number of active neurons: 2
 >> iter 41000, loss: 0.038448
 >> iter 42000, loss: 0.057609
 >> iter 43000, loss: 0.037213
 >> iter 44000, loss: 0.027376
 >> iter 45000, loss: 0.023685
 >> iter 46000, loss: 0.021345
 >> iter 47000, loss: 0.022800
 >> iter 48000, loss: 0.022543
 >> iter 49000, loss: 0.021574
 >> iter 50000, loss: 0.031355
   Number of active neurons: 2
 >> iter 51000, loss: 0.026714
 >> iter 52000, loss: 0.026221
 >> iter 53000, loss: 0.027358
 >> iter 54000, loss: 0.046386
 >> iter 55000, loss: 0.048603
 >> iter 56000, loss: 0.031040
 >> iter 57000, loss: 0.024692
 >> iter 58000, loss: 0.024845
 >> iter 59000, loss: 0.022453
 >> iter 60000, loss: 0.026229
   Number of active neurons: 2
 >> iter 61000, loss: 0.024866
 >> iter 62000, loss: 0.032293
 >> iter 63000, loss: 0.034786
 >> iter 64000, loss: 0.028339
 >> iter 65000, loss: 0.031665
 >> iter 66000, loss: 0.038724
 >> iter 67000, loss: 0.029717
 >> iter 68000, loss: 0.025958
 >> iter 69000, loss: 0.031634
 >> iter 70000, loss: 0.023653
   Number of active neurons: 2
 >> iter 71000, loss: 0.083331
 >> iter 72000, loss: 0.051830
 >> iter 73000, loss: 0.038097
 >> iter 74000, loss: 0.026460
 >> iter 75000, loss: 0.031627
 >> iter 76000, loss: 0.025775
 >> iter 77000, loss: 0.023977
 >> iter 78000, loss: 0.030582
 >> iter 79000, loss: 0.031847
 >> iter 80000, loss: 0.025529
   Number of active neurons: 2
 >> iter 81000, loss: 0.023034
 >> iter 82000, loss: 0.041377
 >> iter 83000, loss: 0.028605
 >> iter 84000, loss: 0.024234
 >> iter 85000, loss: 0.027466
 >> iter 86000, loss: 0.022751
 >> iter 87000, loss: 0.021714
 >> iter 88000, loss: 0.020300
 >> iter 89000, loss: 0.019849
 >> iter 90000, loss: 0.019940
   Number of active neurons: 1
 >> iter 91000, loss: 0.022227
 >> iter 92000, loss: 0.019099
 >> iter 93000, loss: 0.020700
 >> iter 94000, loss: 0.032373
 >> iter 95000, loss: 0.025744
 >> iter 96000, loss: 0.021108
 >> iter 97000, loss: 0.022437
 >> iter 98000, loss: 0.030694
 >> iter 99000, loss: 0.022415
 >> iter 100000, loss: 0.019680
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.935969
 >> iter 2000, loss: 4.068949
 >> iter 3000, loss: 1.523714
 >> iter 4000, loss: 0.605788
 >> iter 5000, loss: 0.264761
 >> iter 6000, loss: 0.125766
 >> iter 7000, loss: 0.064775
 >> iter 8000, loss: 0.041428
 >> iter 9000, loss: 0.057525
 >> iter 10000, loss: 0.038911
   Number of active neurons: 2
 >> iter 11000, loss: 0.031320
 >> iter 12000, loss: 0.027866
 >> iter 13000, loss: 0.026206
 >> iter 14000, loss: 0.025184
 >> iter 15000, loss: 0.031061
 >> iter 16000, loss: 0.029490
 >> iter 17000, loss: 0.028026
 >> iter 18000, loss: 0.028956
 >> iter 19000, loss: 0.024066
 >> iter 20000, loss: 0.021239
   Number of active neurons: 2
 >> iter 21000, loss: 0.032142
 >> iter 22000, loss: 0.027130
 >> iter 23000, loss: 0.025991
 >> iter 24000, loss: 0.028115
 >> iter 25000, loss: 0.024659
 >> iter 26000, loss: 0.021325
 >> iter 27000, loss: 0.020497
 >> iter 28000, loss: 0.025391
 >> iter 29000, loss: 0.029682
 >> iter 30000, loss: 0.023395
   Number of active neurons: 1
 >> iter 31000, loss: 0.022278
 >> iter 32000, loss: 0.030784
 >> iter 33000, loss: 0.023292
 >> iter 34000, loss: 0.040167
 >> iter 35000, loss: 0.030648
 >> iter 36000, loss: 0.021922
 >> iter 37000, loss: 0.021351
 >> iter 38000, loss: 0.033383
 >> iter 39000, loss: 0.024825
 >> iter 40000, loss: 0.020213
   Number of active neurons: 1
 >> iter 41000, loss: 0.020630
 >> iter 42000, loss: 0.018348
 >> iter 43000, loss: 0.020919
 >> iter 44000, loss: 0.019234
 >> iter 45000, loss: 0.018036
 >> iter 46000, loss: 0.041049
 >> iter 47000, loss: 0.028014
 >> iter 48000, loss: 0.032941
 >> iter 49000, loss: 0.021721
 >> iter 50000, loss: 0.020844
   Number of active neurons: 1
 >> iter 51000, loss: 0.031654
 >> iter 52000, loss: 0.023825
 >> iter 53000, loss: 0.022400
 >> iter 54000, loss: 0.023568
 >> iter 55000, loss: 0.029184
 >> iter 56000, loss: 0.021643
 >> iter 57000, loss: 0.024613
 >> iter 58000, loss: 0.023671
 >> iter 59000, loss: 0.028556
 >> iter 60000, loss: 0.022722
   Number of active neurons: 1
 >> iter 61000, loss: 0.029815
 >> iter 62000, loss: 0.033187
 >> iter 63000, loss: 0.026835
 >> iter 64000, loss: 0.023676
 >> iter 65000, loss: 0.025840
 >> iter 66000, loss: 0.020647
 >> iter 67000, loss: 0.020966
 >> iter 68000, loss: 0.034228
 >> iter 69000, loss: 0.033849
 >> iter 70000, loss: 0.039143
   Number of active neurons: 1
 >> iter 71000, loss: 0.024782
 >> iter 72000, loss: 0.024818
 >> iter 73000, loss: 0.020737
 >> iter 74000, loss: 0.019391
 >> iter 75000, loss: 0.020523
 >> iter 76000, loss: 0.017597
 >> iter 77000, loss: 0.019362
 >> iter 78000, loss: 0.020647
 >> iter 79000, loss: 0.018685
 >> iter 80000, loss: 0.019434
   Number of active neurons: 1
 >> iter 81000, loss: 0.021683
 >> iter 82000, loss: 0.023746
 >> iter 83000, loss: 0.018320
 >> iter 84000, loss: 0.069497
 >> iter 85000, loss: 0.043367
 >> iter 86000, loss: 0.028698
 >> iter 87000, loss: 0.022209
 >> iter 88000, loss: 0.022253
 >> iter 89000, loss: 0.019804
 >> iter 90000, loss: 0.021371
   Number of active neurons: 1
 >> iter 91000, loss: 0.017992
 >> iter 92000, loss: 0.023275
 >> iter 93000, loss: 0.027178
 >> iter 94000, loss: 0.027267
 >> iter 95000, loss: 0.023960
 >> iter 96000, loss: 0.021605
 >> iter 97000, loss: 0.027070
 >> iter 98000, loss: 0.023815
 >> iter 99000, loss: 0.018718
 >> iter 100000, loss: 0.031257
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.925973
 >> iter 2000, loss: 4.058247
 >> iter 3000, loss: 1.522514
 >> iter 4000, loss: 0.586119
 >> iter 5000, loss: 0.234865
 >> iter 6000, loss: 0.103810
 >> iter 7000, loss: 0.054442
 >> iter 8000, loss: 0.042016
 >> iter 9000, loss: 0.034404
 >> iter 10000, loss: 0.029194
   Number of active neurons: 4
 >> iter 11000, loss: 0.032947
 >> iter 12000, loss: 0.029065
 >> iter 13000, loss: 0.031775
 >> iter 14000, loss: 0.029251
 >> iter 15000, loss: 0.033187
 >> iter 16000, loss: 0.029779
 >> iter 17000, loss: 0.026797
 >> iter 18000, loss: 0.028544
 >> iter 19000, loss: 0.027057
 >> iter 20000, loss: 0.030279
   Number of active neurons: 4
 >> iter 21000, loss: 0.026911
 >> iter 22000, loss: 0.026914
 >> iter 23000, loss: 0.028289
 >> iter 24000, loss: 0.025322
 >> iter 25000, loss: 0.024483
 >> iter 26000, loss: 0.026825
 >> iter 27000, loss: 0.031536
 >> iter 28000, loss: 0.026508
 >> iter 29000, loss: 0.026870
 >> iter 30000, loss: 0.029660
   Number of active neurons: 3
 >> iter 31000, loss: 0.032647
 >> iter 32000, loss: 0.050907
 >> iter 33000, loss: 0.038976
 >> iter 34000, loss: 0.030087
 >> iter 35000, loss: 0.027121
 >> iter 36000, loss: 0.025102
 >> iter 37000, loss: 0.024482
 >> iter 38000, loss: 0.030467
 >> iter 39000, loss: 0.033844
 >> iter 40000, loss: 0.031165
   Number of active neurons: 2
 >> iter 41000, loss: 0.028047
 >> iter 42000, loss: 0.024253
 >> iter 43000, loss: 0.021754
 >> iter 44000, loss: 0.021498
 >> iter 45000, loss: 0.037737
 >> iter 46000, loss: 0.028449
 >> iter 47000, loss: 0.027106
 >> iter 48000, loss: 0.024885
 >> iter 49000, loss: 0.024984
 >> iter 50000, loss: 0.030098
   Number of active neurons: 2
 >> iter 51000, loss: 0.025098
 >> iter 52000, loss: 0.022321
 >> iter 53000, loss: 0.027566
 >> iter 54000, loss: 0.029640
 >> iter 55000, loss: 0.025544
 >> iter 56000, loss: 0.023400
 >> iter 57000, loss: 0.022177
 >> iter 58000, loss: 0.022171
 >> iter 59000, loss: 0.021425
 >> iter 60000, loss: 0.022692
   Number of active neurons: 2
 >> iter 61000, loss: 0.025958
 >> iter 62000, loss: 0.040407
 >> iter 63000, loss: 0.032082
 >> iter 64000, loss: 0.030385
 >> iter 65000, loss: 0.028078
 >> iter 66000, loss: 0.038088
 >> iter 67000, loss: 0.036435
 >> iter 68000, loss: 0.027267
 >> iter 69000, loss: 0.021982
 >> iter 70000, loss: 0.022155
   Number of active neurons: 2
 >> iter 71000, loss: 0.032970
 >> iter 72000, loss: 0.040315
 >> iter 73000, loss: 0.033899
 >> iter 74000, loss: 0.025638
 >> iter 75000, loss: 0.021410
 >> iter 76000, loss: 0.023070
 >> iter 77000, loss: 0.022526
 >> iter 78000, loss: 0.029404
 >> iter 79000, loss: 0.025703
 >> iter 80000, loss: 0.028480
   Number of active neurons: 2
 >> iter 81000, loss: 0.037067
 >> iter 82000, loss: 0.026713
 >> iter 83000, loss: 0.022651
 >> iter 84000, loss: 0.025611
 >> iter 85000, loss: 0.026341
 >> iter 86000, loss: 0.029672
 >> iter 87000, loss: 0.023530
 >> iter 88000, loss: 0.021683
 >> iter 89000, loss: 0.020724
 >> iter 90000, loss: 0.022909
   Number of active neurons: 1
 >> iter 91000, loss: 0.023736
 >> iter 92000, loss: 0.021340
 >> iter 93000, loss: 0.022220
 >> iter 94000, loss: 0.019957
 >> iter 95000, loss: 0.024693
 >> iter 96000, loss: 0.044712
 >> iter 97000, loss: 0.027301
 >> iter 98000, loss: 0.030215
 >> iter 99000, loss: 0.031570
 >> iter 100000, loss: 0.022622
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.887317
 >> iter 2000, loss: 4.047657
 >> iter 3000, loss: 1.521653
 >> iter 4000, loss: 0.588654
 >> iter 5000, loss: 0.239624
 >> iter 6000, loss: 0.114092
 >> iter 7000, loss: 0.059123
 >> iter 8000, loss: 0.044956
 >> iter 9000, loss: 0.031895
 >> iter 10000, loss: 0.027626
   Number of active neurons: 3
 >> iter 11000, loss: 0.029617
 >> iter 12000, loss: 0.026486
 >> iter 13000, loss: 0.028130
 >> iter 14000, loss: 0.026974
 >> iter 15000, loss: 0.045445
 >> iter 16000, loss: 0.034367
 >> iter 17000, loss: 0.034548
 >> iter 18000, loss: 0.027783
 >> iter 19000, loss: 0.026075
 >> iter 20000, loss: 0.023468
   Number of active neurons: 3
 >> iter 21000, loss: 0.024253
 >> iter 22000, loss: 0.024343
 >> iter 23000, loss: 0.023607
 >> iter 24000, loss: 0.028252
 >> iter 25000, loss: 0.024884
 >> iter 26000, loss: 0.021819
 >> iter 27000, loss: 0.022259
 >> iter 28000, loss: 0.022036
 >> iter 29000, loss: 0.021916
 >> iter 30000, loss: 0.045950
   Number of active neurons: 2
 >> iter 31000, loss: 0.032756
 >> iter 32000, loss: 0.029444
 >> iter 33000, loss: 0.027499
 >> iter 34000, loss: 0.022547
 >> iter 35000, loss: 0.021898
 >> iter 36000, loss: 0.023707
 >> iter 37000, loss: 0.024219
 >> iter 38000, loss: 0.023235
 >> iter 39000, loss: 0.022418
 >> iter 40000, loss: 0.020243
   Number of active neurons: 2
 >> iter 41000, loss: 0.020079
 >> iter 42000, loss: 0.023089
 >> iter 43000, loss: 0.025126
 >> iter 44000, loss: 0.022995
 >> iter 45000, loss: 0.033998
 >> iter 46000, loss: 0.031473
 >> iter 47000, loss: 0.030257
 >> iter 48000, loss: 0.043818
 >> iter 49000, loss: 0.030410
 >> iter 50000, loss: 0.023360
   Number of active neurons: 2
 >> iter 51000, loss: 0.034179
 >> iter 52000, loss: 0.025793
 >> iter 53000, loss: 0.024072
 >> iter 54000, loss: 0.021611
 >> iter 55000, loss: 0.021532
 >> iter 56000, loss: 0.022265
 >> iter 57000, loss: 0.022098
 >> iter 58000, loss: 0.030149
 >> iter 59000, loss: 0.035676
 >> iter 60000, loss: 0.024964
   Number of active neurons: 2
 >> iter 61000, loss: 0.040438
 >> iter 62000, loss: 0.043438
 >> iter 63000, loss: 0.031097
 >> iter 64000, loss: 0.025144
 >> iter 65000, loss: 0.024675
 >> iter 66000, loss: 0.021580
 >> iter 67000, loss: 0.019781
 >> iter 68000, loss: 0.022744
 >> iter 69000, loss: 0.023228
 >> iter 70000, loss: 0.039271
   Number of active neurons: 1
 >> iter 71000, loss: 0.028179
 >> iter 72000, loss: 0.029536
 >> iter 73000, loss: 0.023413
 >> iter 74000, loss: 0.025572
 >> iter 75000, loss: 0.026592
 >> iter 76000, loss: 0.023600
 >> iter 77000, loss: 0.020777
 >> iter 78000, loss: 0.018581
 >> iter 79000, loss: 0.025376
 >> iter 80000, loss: 0.024034
   Number of active neurons: 1
 >> iter 81000, loss: 0.019758
 >> iter 82000, loss: 0.018302
 >> iter 83000, loss: 0.040957
 >> iter 84000, loss: 0.031500
 >> iter 85000, loss: 0.021166
 >> iter 86000, loss: 0.032656
 >> iter 87000, loss: 0.024183
 >> iter 88000, loss: 0.019333
 >> iter 89000, loss: 0.017025
 >> iter 90000, loss: 0.042992
   Number of active neurons: 1
 >> iter 91000, loss: 0.047093
 >> iter 92000, loss: 0.032199
 >> iter 93000, loss: 0.024456
 >> iter 94000, loss: 0.019900
 >> iter 95000, loss: 0.025303
 >> iter 96000, loss: 0.020623
 >> iter 97000, loss: 0.023893
 >> iter 98000, loss: 0.020730
 >> iter 99000, loss: 0.022948
 >> iter 100000, loss: 0.022870
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

