 > Problema: tomita3nueva
 > Args:
   - Hidden size: 20
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.319902
 >> iter 2000, loss: 11.063247
 >> iter 3000, loss: 5.278324
 >> iter 4000, loss: 2.760441
 >> iter 5000, loss: 1.331586
 >> iter 6000, loss: 0.909943
 >> iter 7000, loss: 0.814603
 >> iter 8000, loss: 0.823048
 >> iter 9000, loss: 0.515708
 >> iter 10000, loss: 0.391290
   Number of active neurons: 10
 >> iter 11000, loss: 0.351581
 >> iter 12000, loss: 0.430918
 >> iter 13000, loss: 0.366834
 >> iter 14000, loss: 0.320627
 >> iter 15000, loss: 0.342421
 >> iter 16000, loss: 0.325670
 >> iter 17000, loss: 0.434423
 >> iter 18000, loss: 0.431591
 >> iter 19000, loss: 0.477293
 >> iter 20000, loss: 0.457434
   Number of active neurons: 10
 >> iter 21000, loss: 0.310136
 >> iter 22000, loss: 0.356585
 >> iter 23000, loss: 0.326571
 >> iter 24000, loss: 0.403938
 >> iter 25000, loss: 0.201436
 >> iter 26000, loss: 0.453106
 >> iter 27000, loss: 0.300686
 >> iter 28000, loss: 0.333702
 >> iter 29000, loss: 0.283933
 >> iter 30000, loss: 0.177526
   Number of active neurons: 9
 >> iter 31000, loss: 0.404320
 >> iter 32000, loss: 0.276568
 >> iter 33000, loss: 0.175920
 >> iter 34000, loss: 0.236042
 >> iter 35000, loss: 0.405863
 >> iter 36000, loss: 0.279875
 >> iter 37000, loss: 0.217178
 >> iter 38000, loss: 0.251087
 >> iter 39000, loss: 0.351627
 >> iter 40000, loss: 0.232198
   Number of active neurons: 8
 >> iter 41000, loss: 0.267061
 >> iter 42000, loss: 0.296544
 >> iter 43000, loss: 0.221237
 >> iter 44000, loss: 0.407665
 >> iter 45000, loss: 0.382040
 >> iter 46000, loss: 0.299095
 >> iter 47000, loss: 0.462748
 >> iter 48000, loss: 0.285592
 >> iter 49000, loss: 0.347671
 >> iter 50000, loss: 0.254319
   Number of active neurons: 8
 >> iter 51000, loss: 0.246060
 >> iter 52000, loss: 0.287156
 >> iter 53000, loss: 0.237323
 >> iter 54000, loss: 0.164348
 >> iter 55000, loss: 0.249074
 >> iter 56000, loss: 0.277754
 >> iter 57000, loss: 0.186381
 >> iter 58000, loss: 0.148837
 >> iter 59000, loss: 0.176885
 >> iter 60000, loss: 0.191318
   Number of active neurons: 8
 >> iter 61000, loss: 0.239963
 >> iter 62000, loss: 0.210211
 >> iter 63000, loss: 0.222364
 >> iter 64000, loss: 0.176482
 >> iter 65000, loss: 0.271721
 >> iter 66000, loss: 0.283685
 >> iter 67000, loss: 0.177469
 >> iter 68000, loss: 0.227275
 >> iter 69000, loss: 0.299029
 >> iter 70000, loss: 0.206161
   Number of active neurons: 8
 >> iter 71000, loss: 0.214155
 >> iter 72000, loss: 0.216944
 >> iter 73000, loss: 0.241191
 >> iter 74000, loss: 0.192102
 >> iter 75000, loss: 0.185831
 >> iter 76000, loss: 0.424286
 >> iter 77000, loss: 0.434717
 >> iter 78000, loss: 0.346556
 >> iter 79000, loss: 0.372868
 >> iter 80000, loss: 0.299618
   Number of active neurons: 8
 >> iter 81000, loss: 0.336826
 >> iter 82000, loss: 0.211487
 >> iter 83000, loss: 0.189468
 >> iter 84000, loss: 0.146678
 >> iter 85000, loss: 0.278264
 >> iter 86000, loss: 0.264935
 >> iter 87000, loss: 0.328168
 >> iter 88000, loss: 0.280054
 >> iter 89000, loss: 0.206017
 >> iter 90000, loss: 0.228469
   Number of active neurons: 8
 >> iter 91000, loss: 0.256713
 >> iter 92000, loss: 0.316563
 >> iter 93000, loss: 0.295602
 >> iter 94000, loss: 0.242468
 >> iter 95000, loss: 0.302622
 >> iter 96000, loss: 0.191821
 >> iter 97000, loss: 0.335300
 >> iter 98000, loss: 0.433051
 >> iter 99000, loss: 0.433917
 >> iter 100000, loss: 0.421632
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.999555
 >> iter 2000, loss: 14.258710
 >> iter 3000, loss: 7.566883
 >> iter 4000, loss: 3.332881
 >> iter 5000, loss: 1.601856
 >> iter 6000, loss: 1.102811
 >> iter 7000, loss: 0.625212
 >> iter 8000, loss: 0.419485
 >> iter 9000, loss: 0.352631
 >> iter 10000, loss: 0.307875
   Number of active neurons: 13
 >> iter 11000, loss: 0.239977
 >> iter 12000, loss: 0.255371
 >> iter 13000, loss: 0.237493
 >> iter 14000, loss: 0.213087
 >> iter 15000, loss: 0.175854
 >> iter 16000, loss: 0.218118
 >> iter 17000, loss: 0.286028
 >> iter 18000, loss: 0.233518
 >> iter 19000, loss: 0.322170
 >> iter 20000, loss: 0.267032
   Number of active neurons: 12
 >> iter 21000, loss: 0.215290
 >> iter 22000, loss: 0.289287
 >> iter 23000, loss: 0.364296
 >> iter 24000, loss: 0.250479
 >> iter 25000, loss: 0.266661
 >> iter 26000, loss: 0.402262
 >> iter 27000, loss: 0.261570
 >> iter 28000, loss: 0.349828
 >> iter 29000, loss: 0.235160
 >> iter 30000, loss: 0.318165
   Number of active neurons: 9
 >> iter 31000, loss: 0.239152
 >> iter 32000, loss: 0.213236
 >> iter 33000, loss: 0.214522
 >> iter 34000, loss: 0.198867
 >> iter 35000, loss: 0.178003
 >> iter 36000, loss: 0.280313
 >> iter 37000, loss: 0.208621
 >> iter 38000, loss: 0.149273
 >> iter 39000, loss: 0.205680
 >> iter 40000, loss: 0.158976
   Number of active neurons: 7
 >> iter 41000, loss: 0.179685
 >> iter 42000, loss: 0.172037
 >> iter 43000, loss: 0.202891
 >> iter 44000, loss: 0.243167
 >> iter 45000, loss: 0.250283
 >> iter 46000, loss: 0.324060
 >> iter 47000, loss: 0.214179
 >> iter 48000, loss: 0.226229
 >> iter 49000, loss: 0.188682
 >> iter 50000, loss: 0.256251
   Number of active neurons: 7
 >> iter 51000, loss: 0.299898
 >> iter 52000, loss: 0.280013
 >> iter 53000, loss: 0.209916
 >> iter 54000, loss: 0.262046
 >> iter 55000, loss: 0.256841
 >> iter 56000, loss: 0.146794
 >> iter 57000, loss: 0.330245
 >> iter 58000, loss: 0.284453
 >> iter 59000, loss: 0.186837
 >> iter 60000, loss: 0.140989
   Number of active neurons: 6
 >> iter 61000, loss: 0.224438
 >> iter 62000, loss: 0.236582
 >> iter 63000, loss: 0.267285
 >> iter 64000, loss: 0.234359
 >> iter 65000, loss: 0.257869
 >> iter 66000, loss: 0.183996
 >> iter 67000, loss: 0.212250
 >> iter 68000, loss: 0.277318
 >> iter 69000, loss: 0.239999
 >> iter 70000, loss: 0.275113
   Number of active neurons: 5
 >> iter 71000, loss: 0.165298
 >> iter 72000, loss: 0.181184
 >> iter 73000, loss: 0.254394
 >> iter 74000, loss: 0.305682
 >> iter 75000, loss: 0.377154
 >> iter 76000, loss: 0.436391
 >> iter 77000, loss: 0.273414
 >> iter 78000, loss: 0.159990
 >> iter 79000, loss: 0.211416
 >> iter 80000, loss: 0.346530
   Number of active neurons: 5
 >> iter 81000, loss: 0.191692
 >> iter 82000, loss: 0.154325
 >> iter 83000, loss: 0.279103
 >> iter 84000, loss: 0.203617
 >> iter 85000, loss: 0.234493
 >> iter 86000, loss: 0.206806
 >> iter 87000, loss: 0.308975
 >> iter 88000, loss: 0.251243
 >> iter 89000, loss: 0.162449
 >> iter 90000, loss: 0.126681
   Number of active neurons: 5
 >> iter 91000, loss: 0.130118
 >> iter 92000, loss: 0.140440
 >> iter 93000, loss: 0.371443
 >> iter 94000, loss: 0.236979
 >> iter 95000, loss: 0.172171
 >> iter 96000, loss: 0.176730
 >> iter 97000, loss: 0.274796
 >> iter 98000, loss: 0.346975
 >> iter 99000, loss: 0.276609
 >> iter 100000, loss: 0.240895
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.964403
 >> iter 2000, loss: 10.080213
 >> iter 3000, loss: 4.549476
 >> iter 4000, loss: 2.137446
 >> iter 5000, loss: 1.075109
 >> iter 6000, loss: 0.603776
 >> iter 7000, loss: 0.528863
 >> iter 8000, loss: 0.543145
 >> iter 9000, loss: 0.305722
 >> iter 10000, loss: 0.383943
   Number of active neurons: 6
 >> iter 11000, loss: 0.322034
 >> iter 12000, loss: 0.322492
 >> iter 13000, loss: 0.353370
 >> iter 14000, loss: 0.304277
 >> iter 15000, loss: 0.387231
 >> iter 16000, loss: 0.393888
 >> iter 17000, loss: 0.218106
 >> iter 18000, loss: 0.330930
 >> iter 19000, loss: 0.385815
 >> iter 20000, loss: 0.374451
   Number of active neurons: 6
 >> iter 21000, loss: 0.262774
 >> iter 22000, loss: 0.355465
 >> iter 23000, loss: 0.384577
 >> iter 24000, loss: 0.318012
 >> iter 25000, loss: 0.441049
 >> iter 26000, loss: 0.405556
 >> iter 27000, loss: 0.390894
 >> iter 28000, loss: 0.371719
 >> iter 29000, loss: 0.288678
 >> iter 30000, loss: 0.253626
   Number of active neurons: 6
 >> iter 31000, loss: 0.474677
 >> iter 32000, loss: 0.435511
 >> iter 33000, loss: 0.419019
 >> iter 34000, loss: 0.483432
 >> iter 35000, loss: 0.416726
 >> iter 36000, loss: 0.335015
 >> iter 37000, loss: 0.262414
 >> iter 38000, loss: 0.258431
 >> iter 39000, loss: 0.357442
 >> iter 40000, loss: 0.435659
   Number of active neurons: 6
 >> iter 41000, loss: 0.325926
 >> iter 42000, loss: 0.254706
 >> iter 43000, loss: 0.280717
 >> iter 44000, loss: 0.461594
 >> iter 45000, loss: 0.374678
 >> iter 46000, loss: 0.252990
 >> iter 47000, loss: 0.213435
 >> iter 48000, loss: 0.330832
 >> iter 49000, loss: 0.359973
 >> iter 50000, loss: 0.327779
   Number of active neurons: 6
 >> iter 51000, loss: 0.363286
 >> iter 52000, loss: 0.460856
 >> iter 53000, loss: 0.297765
 >> iter 54000, loss: 0.373736
 >> iter 55000, loss: 0.471331
 >> iter 56000, loss: 0.426639
 >> iter 57000, loss: 0.330069
 >> iter 58000, loss: 0.400819
 >> iter 59000, loss: 0.341953
 >> iter 60000, loss: 0.283097
   Number of active neurons: 6
 >> iter 61000, loss: 0.323242
 >> iter 62000, loss: 0.379715
 >> iter 63000, loss: 0.451656
 >> iter 64000, loss: 0.371453
 >> iter 65000, loss: 0.331397
 >> iter 66000, loss: 0.518461
 >> iter 67000, loss: 0.393984
 >> iter 68000, loss: 0.310842
 >> iter 69000, loss: 0.284037
 >> iter 70000, loss: 0.235059
   Number of active neurons: 6
 >> iter 71000, loss: 0.236725
 >> iter 72000, loss: 0.302974
 >> iter 73000, loss: 0.330326
 >> iter 74000, loss: 0.218102
 >> iter 75000, loss: 0.228093
 >> iter 76000, loss: 0.183688
 >> iter 77000, loss: 0.400658
 >> iter 78000, loss: 0.444714
 >> iter 79000, loss: 0.378651
 >> iter 80000, loss: 0.303841
   Number of active neurons: 5
 >> iter 81000, loss: 0.202260
 >> iter 82000, loss: 0.275286
 >> iter 83000, loss: 0.297312
 >> iter 84000, loss: 0.309563
 >> iter 85000, loss: 0.326922
 >> iter 86000, loss: 0.276203
 >> iter 87000, loss: 0.219335
 >> iter 88000, loss: 0.219347
 >> iter 89000, loss: 0.351648
 >> iter 90000, loss: 0.307339
   Number of active neurons: 5
 >> iter 91000, loss: 0.320248
 >> iter 92000, loss: 0.308405
 >> iter 93000, loss: 0.413401
 >> iter 94000, loss: 0.249560
 >> iter 95000, loss: 0.297751
 >> iter 96000, loss: 0.271693
 >> iter 97000, loss: 0.330671
 >> iter 98000, loss: 0.449372
 >> iter 99000, loss: 0.390268
 >> iter 100000, loss: 0.276411
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.138529
 >> iter 2000, loss: 12.966756
 >> iter 3000, loss: 6.137579
 >> iter 4000, loss: 2.938670
 >> iter 5000, loss: 1.442087
 >> iter 6000, loss: 0.881421
 >> iter 7000, loss: 0.611403
 >> iter 8000, loss: 0.504305
 >> iter 9000, loss: 0.697405
 >> iter 10000, loss: 0.678390
   Number of active neurons: 8
 >> iter 11000, loss: 0.674716
 >> iter 12000, loss: 0.509374
 >> iter 13000, loss: 0.442263
 >> iter 14000, loss: 0.360571
 >> iter 15000, loss: 0.388573
 >> iter 16000, loss: 0.355685
 >> iter 17000, loss: 0.470231
 >> iter 18000, loss: 0.386097
 >> iter 19000, loss: 0.348389
 >> iter 20000, loss: 0.244876
   Number of active neurons: 8
 >> iter 21000, loss: 0.557641
 >> iter 22000, loss: 0.389170
 >> iter 23000, loss: 0.369997
 >> iter 24000, loss: 0.297189
 >> iter 25000, loss: 0.334104
 >> iter 26000, loss: 0.442370
 >> iter 27000, loss: 0.388966
 >> iter 28000, loss: 0.476300
 >> iter 29000, loss: 0.567699
 >> iter 30000, loss: 0.318472
   Number of active neurons: 8
 >> iter 31000, loss: 0.396122
 >> iter 32000, loss: 0.397845
 >> iter 33000, loss: 0.398081
 >> iter 34000, loss: 0.266041
 >> iter 35000, loss: 0.390856
 >> iter 36000, loss: 0.358738
 >> iter 37000, loss: 0.461531
 >> iter 38000, loss: 0.471833
 >> iter 39000, loss: 0.547696
 >> iter 40000, loss: 0.447892
   Number of active neurons: 8
 >> iter 41000, loss: 0.511501
 >> iter 42000, loss: 0.320448
 >> iter 43000, loss: 0.284500
 >> iter 44000, loss: 0.379114
 >> iter 45000, loss: 0.228668
 >> iter 46000, loss: 0.275182
 >> iter 47000, loss: 0.367508
 >> iter 48000, loss: 0.340472
 >> iter 49000, loss: 0.369938
 >> iter 50000, loss: 0.441934
   Number of active neurons: 7
 >> iter 51000, loss: 0.365130
 >> iter 52000, loss: 0.373726
 >> iter 53000, loss: 0.329825
 >> iter 54000, loss: 0.361411
 >> iter 55000, loss: 0.332575
 >> iter 56000, loss: 0.271768
 >> iter 57000, loss: 0.348392
 >> iter 58000, loss: 0.463601
 >> iter 59000, loss: 0.338588
 >> iter 60000, loss: 0.318801
   Number of active neurons: 6
 >> iter 61000, loss: 0.367056
 >> iter 62000, loss: 0.349638
 >> iter 63000, loss: 0.607822
 >> iter 64000, loss: 0.623692
 >> iter 65000, loss: 0.403550
 >> iter 66000, loss: 0.324494
 >> iter 67000, loss: 0.375606
 >> iter 68000, loss: 0.367068
 >> iter 69000, loss: 0.376096
 >> iter 70000, loss: 0.325111
   Number of active neurons: 6
 >> iter 71000, loss: 0.359408
 >> iter 72000, loss: 0.291591
 >> iter 73000, loss: 0.348975
 >> iter 74000, loss: 0.389195
 >> iter 75000, loss: 0.406346
 >> iter 76000, loss: 0.306138
 >> iter 77000, loss: 0.329919
 >> iter 78000, loss: 0.320182
 >> iter 79000, loss: 0.215277
 >> iter 80000, loss: 0.180916
   Number of active neurons: 5
 >> iter 81000, loss: 0.234179
 >> iter 82000, loss: 0.330706
 >> iter 83000, loss: 0.435566
 >> iter 84000, loss: 0.289627
 >> iter 85000, loss: 0.232192
 >> iter 86000, loss: 0.384066
 >> iter 87000, loss: 0.317966
 >> iter 88000, loss: 0.313785
 >> iter 89000, loss: 0.249703
 >> iter 90000, loss: 0.301372
   Number of active neurons: 5
 >> iter 91000, loss: 0.313230
 >> iter 92000, loss: 0.278895
 >> iter 93000, loss: 0.239731
 >> iter 94000, loss: 0.223582
 >> iter 95000, loss: 0.250782
 >> iter 96000, loss: 0.191349
 >> iter 97000, loss: 0.156588
 >> iter 98000, loss: 0.182847
 >> iter 99000, loss: 0.226412
 >> iter 100000, loss: 0.272524
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.187367
 >> iter 2000, loss: 10.195309
 >> iter 3000, loss: 4.516896
 >> iter 4000, loss: 1.990430
 >> iter 5000, loss: 0.913218
 >> iter 6000, loss: 0.791218
 >> iter 7000, loss: 0.625822
 >> iter 8000, loss: 0.504476
 >> iter 9000, loss: 0.394382
 >> iter 10000, loss: 0.360439
   Number of active neurons: 8
 >> iter 11000, loss: 0.462635
 >> iter 12000, loss: 0.304318
 >> iter 13000, loss: 0.351016
 >> iter 14000, loss: 0.314974
 >> iter 15000, loss: 0.386272
 >> iter 16000, loss: 0.298876
 >> iter 17000, loss: 0.270342
 >> iter 18000, loss: 0.280882
 >> iter 19000, loss: 0.196767
 >> iter 20000, loss: 0.249622
   Number of active neurons: 8
 >> iter 21000, loss: 0.354174
 >> iter 22000, loss: 0.228585
 >> iter 23000, loss: 0.279317
 >> iter 24000, loss: 0.222659
 >> iter 25000, loss: 0.326025
 >> iter 26000, loss: 0.372074
 >> iter 27000, loss: 0.207102
 >> iter 28000, loss: 0.244978
 >> iter 29000, loss: 0.260078
 >> iter 30000, loss: 0.271062
   Number of active neurons: 7
 >> iter 31000, loss: 0.259792
 >> iter 32000, loss: 0.275775
 >> iter 33000, loss: 0.214193
 >> iter 34000, loss: 0.196929
 >> iter 35000, loss: 0.141705
 >> iter 36000, loss: 0.203467
 >> iter 37000, loss: 0.149291
 >> iter 38000, loss: 0.138222
 >> iter 39000, loss: 0.246688
 >> iter 40000, loss: 0.292216
   Number of active neurons: 7
 >> iter 41000, loss: 0.444018
 >> iter 42000, loss: 0.361914
 >> iter 43000, loss: 0.491756
 >> iter 44000, loss: 0.297890
 >> iter 45000, loss: 0.264582
 >> iter 46000, loss: 0.452785
 >> iter 47000, loss: 0.256639
 >> iter 48000, loss: 0.196548
 >> iter 49000, loss: 0.112276
 >> iter 50000, loss: 0.194724
   Number of active neurons: 7
 >> iter 51000, loss: 0.211010
 >> iter 52000, loss: 0.187650
 >> iter 53000, loss: 0.215056
 >> iter 54000, loss: 0.194321
 >> iter 55000, loss: 0.168020
 >> iter 56000, loss: 0.217803
 >> iter 57000, loss: 0.204045
 >> iter 58000, loss: 0.230450
 >> iter 59000, loss: 0.188624
 >> iter 60000, loss: 0.244665
   Number of active neurons: 6
 >> iter 61000, loss: 0.293227
 >> iter 62000, loss: 0.182217
 >> iter 63000, loss: 0.336177
 >> iter 64000, loss: 0.208709
 >> iter 65000, loss: 0.183822
 >> iter 66000, loss: 0.139017
 >> iter 67000, loss: 0.237360
 >> iter 68000, loss: 0.142422
 >> iter 69000, loss: 0.206666
 >> iter 70000, loss: 0.161166
   Number of active neurons: 5
 >> iter 71000, loss: 0.334457
 >> iter 72000, loss: 0.273791
 >> iter 73000, loss: 0.370895
 >> iter 74000, loss: 0.263356
 >> iter 75000, loss: 0.202540
 >> iter 76000, loss: 0.144920
 >> iter 77000, loss: 0.131985
 >> iter 78000, loss: 0.136643
 >> iter 79000, loss: 0.143972
 >> iter 80000, loss: 0.144853
   Number of active neurons: 5
 >> iter 81000, loss: 0.165532
 >> iter 82000, loss: 0.231242
 >> iter 83000, loss: 0.310220
 >> iter 84000, loss: 0.219537
 >> iter 85000, loss: 0.224131
 >> iter 86000, loss: 0.146184
 >> iter 87000, loss: 0.131834
 >> iter 88000, loss: 0.167898
 >> iter 89000, loss: 0.177843
 >> iter 90000, loss: 0.245418
   Number of active neurons: 5
 >> iter 91000, loss: 0.426341
 >> iter 92000, loss: 0.309713
 >> iter 93000, loss: 0.167603
 >> iter 94000, loss: 0.210865
 >> iter 95000, loss: 0.276904
 >> iter 96000, loss: 0.297655
 >> iter 97000, loss: 0.206075
 >> iter 98000, loss: 0.182161
 >> iter 99000, loss: 0.150752
 >> iter 100000, loss: 0.187028
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.087046
 >> iter 2000, loss: 11.297204
 >> iter 3000, loss: 6.199241
 >> iter 4000, loss: 3.223380
 >> iter 5000, loss: 1.781305
 >> iter 6000, loss: 1.185543
 >> iter 7000, loss: 0.818679
 >> iter 8000, loss: 0.793030
 >> iter 9000, loss: 0.598343
 >> iter 10000, loss: 0.383958
   Number of active neurons: 11
 >> iter 11000, loss: 0.565528
 >> iter 12000, loss: 0.501753
 >> iter 13000, loss: 0.521143
 >> iter 14000, loss: 0.322229
 >> iter 15000, loss: 0.357953
 >> iter 16000, loss: 0.484738
 >> iter 17000, loss: 0.386569
 >> iter 18000, loss: 0.398111
 >> iter 19000, loss: 0.409183
 >> iter 20000, loss: 0.450546
   Number of active neurons: 10
 >> iter 21000, loss: 0.237638
 >> iter 22000, loss: 0.254748
 >> iter 23000, loss: 0.236136
 >> iter 24000, loss: 0.543050
 >> iter 25000, loss: 0.405409
 >> iter 26000, loss: 0.302291
 >> iter 27000, loss: 0.291137
 >> iter 28000, loss: 0.482860
 >> iter 29000, loss: 0.420412
 >> iter 30000, loss: 0.386810
   Number of active neurons: 10
 >> iter 31000, loss: 0.360978
 >> iter 32000, loss: 0.358916
 >> iter 33000, loss: 0.345701
 >> iter 34000, loss: 0.302664
 >> iter 35000, loss: 0.361449
 >> iter 36000, loss: 0.505009
 >> iter 37000, loss: 0.263492
 >> iter 38000, loss: 0.224773
 >> iter 39000, loss: 0.464588
 >> iter 40000, loss: 0.494199
   Number of active neurons: 8
 >> iter 41000, loss: 0.328723
 >> iter 42000, loss: 0.219526
 >> iter 43000, loss: 0.369114
 >> iter 44000, loss: 0.388603
 >> iter 45000, loss: 0.479703
 >> iter 46000, loss: 0.385266
 >> iter 47000, loss: 0.377589
 >> iter 48000, loss: 0.238563
 >> iter 49000, loss: 0.176561
 >> iter 50000, loss: 0.430506
   Number of active neurons: 8
 >> iter 51000, loss: 0.443564
 >> iter 52000, loss: 0.418139
 >> iter 53000, loss: 0.264125
 >> iter 54000, loss: 0.326145
 >> iter 55000, loss: 0.243492
 >> iter 56000, loss: 0.174772
 >> iter 57000, loss: 0.284091
 >> iter 58000, loss: 0.265767
 >> iter 59000, loss: 0.234308
 >> iter 60000, loss: 0.335617
   Number of active neurons: 7
 >> iter 61000, loss: 0.374701
 >> iter 62000, loss: 0.369437
 >> iter 63000, loss: 0.355122
 >> iter 64000, loss: 0.274790
 >> iter 65000, loss: 0.193061
 >> iter 66000, loss: 0.297771
 >> iter 67000, loss: 0.300033
 >> iter 68000, loss: 0.348032
 >> iter 69000, loss: 0.324685
 >> iter 70000, loss: 0.357381
   Number of active neurons: 7
 >> iter 71000, loss: 0.413551
 >> iter 72000, loss: 0.417417
 >> iter 73000, loss: 0.424408
 >> iter 74000, loss: 0.299034
 >> iter 75000, loss: 0.252725
 >> iter 76000, loss: 0.345096
 >> iter 77000, loss: 0.459758
 >> iter 78000, loss: 0.293779
 >> iter 79000, loss: 0.537789
 >> iter 80000, loss: 0.271353
   Number of active neurons: 7
 >> iter 81000, loss: 0.322165
 >> iter 82000, loss: 0.196918
 >> iter 83000, loss: 0.284198
 >> iter 84000, loss: 0.365986
 >> iter 85000, loss: 0.416958
 >> iter 86000, loss: 0.268934
 >> iter 87000, loss: 0.208971
 >> iter 88000, loss: 0.221951
 >> iter 89000, loss: 0.338709
 >> iter 90000, loss: 0.258405
   Number of active neurons: 6
 >> iter 91000, loss: 0.257141
 >> iter 92000, loss: 0.296486
 >> iter 93000, loss: 0.250532
 >> iter 94000, loss: 0.422189
 >> iter 95000, loss: 0.264631
 >> iter 96000, loss: 0.379316
 >> iter 97000, loss: 0.288795
 >> iter 98000, loss: 0.412439
 >> iter 99000, loss: 0.411522
 >> iter 100000, loss: 0.303773
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.240666
 >> iter 2000, loss: 11.099783
 >> iter 3000, loss: 5.480378
 >> iter 4000, loss: 2.400549
 >> iter 5000, loss: 1.048793
 >> iter 6000, loss: 0.616131
 >> iter 7000, loss: 0.490886
 >> iter 8000, loss: 0.347896
 >> iter 9000, loss: 0.394062
 >> iter 10000, loss: 0.317664
   Number of active neurons: 11
 >> iter 11000, loss: 0.309348
 >> iter 12000, loss: 0.302740
 >> iter 13000, loss: 0.173882
 >> iter 14000, loss: 0.234499
 >> iter 15000, loss: 0.224664
 >> iter 16000, loss: 0.372038
 >> iter 17000, loss: 0.305917
 >> iter 18000, loss: 0.399736
 >> iter 19000, loss: 0.257594
 >> iter 20000, loss: 0.250244
   Number of active neurons: 10
 >> iter 21000, loss: 0.217467
 >> iter 22000, loss: 0.221252
 >> iter 23000, loss: 0.415157
 >> iter 24000, loss: 0.243404
 >> iter 25000, loss: 0.354394
 >> iter 26000, loss: 0.326629
 >> iter 27000, loss: 0.368156
 >> iter 28000, loss: 0.236808
 >> iter 29000, loss: 0.339691
 >> iter 30000, loss: 0.248647
   Number of active neurons: 9
 >> iter 31000, loss: 0.196438
 >> iter 32000, loss: 0.169139
 >> iter 33000, loss: 0.373698
 >> iter 34000, loss: 0.241068
 >> iter 35000, loss: 0.255936
 >> iter 36000, loss: 0.200120
 >> iter 37000, loss: 0.255659
 >> iter 38000, loss: 0.264358
 >> iter 39000, loss: 0.221040
 >> iter 40000, loss: 0.214040
   Number of active neurons: 8
 >> iter 41000, loss: 0.206734
 >> iter 42000, loss: 0.242062
 >> iter 43000, loss: 0.247746
 >> iter 44000, loss: 0.336370
 >> iter 45000, loss: 0.233311
 >> iter 46000, loss: 0.206623
 >> iter 47000, loss: 0.263773
 >> iter 48000, loss: 0.260069
 >> iter 49000, loss: 0.197074
 >> iter 50000, loss: 0.152722
   Number of active neurons: 6
 >> iter 51000, loss: 0.249195
 >> iter 52000, loss: 0.172343
 >> iter 53000, loss: 0.124174
 >> iter 54000, loss: 0.213181
 >> iter 55000, loss: 0.211622
 >> iter 56000, loss: 0.174767
 >> iter 57000, loss: 0.139944
 >> iter 58000, loss: 0.185795
 >> iter 59000, loss: 0.249122
 >> iter 60000, loss: 0.246940
   Number of active neurons: 6
 >> iter 61000, loss: 0.203183
 >> iter 62000, loss: 0.199001
 >> iter 63000, loss: 0.274623
 >> iter 64000, loss: 0.198185
 >> iter 65000, loss: 0.265557
 >> iter 66000, loss: 0.295039
 >> iter 67000, loss: 0.208956
 >> iter 68000, loss: 0.288428
 >> iter 69000, loss: 0.239040
 >> iter 70000, loss: 0.218569
   Number of active neurons: 6
 >> iter 71000, loss: 0.312068
 >> iter 72000, loss: 0.224385
 >> iter 73000, loss: 0.182246
 >> iter 74000, loss: 0.288966
 >> iter 75000, loss: 0.256727
 >> iter 76000, loss: 0.254598
 >> iter 77000, loss: 0.200422
 >> iter 78000, loss: 0.131549
 >> iter 79000, loss: 0.170218
 >> iter 80000, loss: 0.221513
   Number of active neurons: 6
 >> iter 81000, loss: 0.157718
 >> iter 82000, loss: 0.310281
 >> iter 83000, loss: 0.202525
 >> iter 84000, loss: 0.174328
 >> iter 85000, loss: 0.199049
 >> iter 86000, loss: 0.234502
 >> iter 87000, loss: 0.213462
 >> iter 88000, loss: 0.221160
 >> iter 89000, loss: 0.225988
 >> iter 90000, loss: 0.234704
   Number of active neurons: 6
 >> iter 91000, loss: 0.316537
 >> iter 92000, loss: 0.180822
 >> iter 93000, loss: 0.182637
 >> iter 94000, loss: 0.155740
 >> iter 95000, loss: 0.154548
 >> iter 96000, loss: 0.105410
 >> iter 97000, loss: 0.142237
 >> iter 98000, loss: 0.293041
 >> iter 99000, loss: 0.206981
 >> iter 100000, loss: 0.273074
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.162499
 >> iter 2000, loss: 11.212701
 >> iter 3000, loss: 5.279135
 >> iter 4000, loss: 2.286229
 >> iter 5000, loss: 1.125227
 >> iter 6000, loss: 0.526240
 >> iter 7000, loss: 0.594936
 >> iter 8000, loss: 0.353829
 >> iter 9000, loss: 0.536687
 >> iter 10000, loss: 0.353359
   Number of active neurons: 9
 >> iter 11000, loss: 0.329123
 >> iter 12000, loss: 0.220253
 >> iter 13000, loss: 0.399419
 >> iter 14000, loss: 0.393730
 >> iter 15000, loss: 0.333297
 >> iter 16000, loss: 0.477299
 >> iter 17000, loss: 0.474877
 >> iter 18000, loss: 0.460613
 >> iter 19000, loss: 0.552321
 >> iter 20000, loss: 0.457493
   Number of active neurons: 8
 >> iter 21000, loss: 0.329265
 >> iter 22000, loss: 0.475145
 >> iter 23000, loss: 0.733572
 >> iter 24000, loss: 0.410767
 >> iter 25000, loss: 0.518246
 >> iter 26000, loss: 0.436393
 >> iter 27000, loss: 0.455599
 >> iter 28000, loss: 0.366084
 >> iter 29000, loss: 0.312405
 >> iter 30000, loss: 0.350636
   Number of active neurons: 8
 >> iter 31000, loss: 0.303875
 >> iter 32000, loss: 0.311253
 >> iter 33000, loss: 0.453700
 >> iter 34000, loss: 0.416591
 >> iter 35000, loss: 0.276926
 >> iter 36000, loss: 0.329735
 >> iter 37000, loss: 0.226557
 >> iter 38000, loss: 0.363407
 >> iter 39000, loss: 0.383055
 >> iter 40000, loss: 0.335472
   Number of active neurons: 8
 >> iter 41000, loss: 0.221828
 >> iter 42000, loss: 0.278503
 >> iter 43000, loss: 0.347601
 >> iter 44000, loss: 0.474085
 >> iter 45000, loss: 0.445344
 >> iter 46000, loss: 0.412491
 >> iter 47000, loss: 0.297562
 >> iter 48000, loss: 0.344648
 >> iter 49000, loss: 0.285476
 >> iter 50000, loss: 0.348210
   Number of active neurons: 7
 >> iter 51000, loss: 0.481088
 >> iter 52000, loss: 0.454759
 >> iter 53000, loss: 0.546248
 >> iter 54000, loss: 0.611463
 >> iter 55000, loss: 0.423220
 >> iter 56000, loss: 0.323736
 >> iter 57000, loss: 0.608080
 >> iter 58000, loss: 0.389780
 >> iter 59000, loss: 0.296390
 >> iter 60000, loss: 0.319924
   Number of active neurons: 7
 >> iter 61000, loss: 0.265667
 >> iter 62000, loss: 0.477476
 >> iter 63000, loss: 0.397765
 >> iter 64000, loss: 0.412761
 >> iter 65000, loss: 0.431358
 >> iter 66000, loss: 0.475150
 >> iter 67000, loss: 0.445544
 >> iter 68000, loss: 0.383749
 >> iter 69000, loss: 0.436349
 >> iter 70000, loss: 0.328562
   Number of active neurons: 7
 >> iter 71000, loss: 0.339315
 >> iter 72000, loss: 0.580174
 >> iter 73000, loss: 0.363598
 >> iter 74000, loss: 0.285424
 >> iter 75000, loss: 0.252056
 >> iter 76000, loss: 0.303644
 >> iter 77000, loss: 0.324794
 >> iter 78000, loss: 0.387984
 >> iter 79000, loss: 0.321124
 >> iter 80000, loss: 0.308350
   Number of active neurons: 6
 >> iter 81000, loss: 0.363449
 >> iter 82000, loss: 0.594939
 >> iter 83000, loss: 0.426805
 >> iter 84000, loss: 0.474661
 >> iter 85000, loss: 0.429885
 >> iter 86000, loss: 0.293911
 >> iter 87000, loss: 0.348743
 >> iter 88000, loss: 0.276964
 >> iter 89000, loss: 0.195867
 >> iter 90000, loss: 0.231605
   Number of active neurons: 6
 >> iter 91000, loss: 0.357706
 >> iter 92000, loss: 0.372941
 >> iter 93000, loss: 0.370661
 >> iter 94000, loss: 0.259631
 >> iter 95000, loss: 0.319866
 >> iter 96000, loss: 0.341896
 >> iter 97000, loss: 0.312389
 >> iter 98000, loss: 0.350372
 >> iter 99000, loss: 0.253712
 >> iter 100000, loss: 0.270541
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.033895
 >> iter 2000, loss: 12.284841
 >> iter 3000, loss: 5.723736
 >> iter 4000, loss: 2.640221
 >> iter 5000, loss: 1.404100
 >> iter 6000, loss: 0.777133
 >> iter 7000, loss: 0.552903
 >> iter 8000, loss: 0.396585
 >> iter 9000, loss: 0.391785
 >> iter 10000, loss: 0.224608
   Number of active neurons: 9
 >> iter 11000, loss: 0.371214
 >> iter 12000, loss: 0.448037
 >> iter 13000, loss: 0.497836
 >> iter 14000, loss: 0.307867
 >> iter 15000, loss: 0.279947
 >> iter 16000, loss: 0.335557
 >> iter 17000, loss: 0.193098
 >> iter 18000, loss: 0.311948
 >> iter 19000, loss: 0.318840
 >> iter 20000, loss: 0.300678
   Number of active neurons: 9
 >> iter 21000, loss: 0.413348
 >> iter 22000, loss: 0.339975
 >> iter 23000, loss: 0.372871
 >> iter 24000, loss: 0.322001
 >> iter 25000, loss: 0.285409
 >> iter 26000, loss: 0.192917
 >> iter 27000, loss: 0.260988
 >> iter 28000, loss: 0.188219
 >> iter 29000, loss: 0.195190
 >> iter 30000, loss: 0.230996
   Number of active neurons: 8
 >> iter 31000, loss: 0.417030
 >> iter 32000, loss: 0.282959
 >> iter 33000, loss: 0.221897
 >> iter 34000, loss: 0.186872
 >> iter 35000, loss: 0.233860
 >> iter 36000, loss: 0.290577
 >> iter 37000, loss: 0.238396
 >> iter 38000, loss: 0.244155
 >> iter 39000, loss: 0.179321
 >> iter 40000, loss: 0.247643
   Number of active neurons: 8
 >> iter 41000, loss: 0.306396
 >> iter 42000, loss: 0.157995
 >> iter 43000, loss: 0.216558
 >> iter 44000, loss: 0.295692
 >> iter 45000, loss: 0.261290
 >> iter 46000, loss: 0.189620
 >> iter 47000, loss: 0.242523
 >> iter 48000, loss: 0.211332
 >> iter 49000, loss: 0.385317
 >> iter 50000, loss: 0.238921
   Number of active neurons: 7
 >> iter 51000, loss: 0.221266
 >> iter 52000, loss: 0.141989
 >> iter 53000, loss: 0.372838
 >> iter 54000, loss: 0.352431
 >> iter 55000, loss: 0.302846
 >> iter 56000, loss: 0.236371
 >> iter 57000, loss: 0.286006
 >> iter 58000, loss: 0.212653
 >> iter 59000, loss: 0.256583
 >> iter 60000, loss: 0.239575
   Number of active neurons: 7
 >> iter 61000, loss: 0.261050
 >> iter 62000, loss: 0.282968
 >> iter 63000, loss: 0.240694
 >> iter 64000, loss: 0.171966
 >> iter 65000, loss: 0.179609
 >> iter 66000, loss: 0.181557
 >> iter 67000, loss: 0.302220
 >> iter 68000, loss: 0.244308
 >> iter 69000, loss: 0.352702
 >> iter 70000, loss: 0.351777
   Number of active neurons: 7
 >> iter 71000, loss: 0.233951
 >> iter 72000, loss: 0.317437
 >> iter 73000, loss: 0.276979
 >> iter 74000, loss: 0.241495
 >> iter 75000, loss: 0.219750
 >> iter 76000, loss: 0.300135
 >> iter 77000, loss: 0.291662
 >> iter 78000, loss: 0.346026
 >> iter 79000, loss: 0.216825
 >> iter 80000, loss: 0.253442
   Number of active neurons: 7
 >> iter 81000, loss: 0.186851
 >> iter 82000, loss: 0.163578
 >> iter 83000, loss: 0.186267
 >> iter 84000, loss: 0.263753
 >> iter 85000, loss: 0.219594
 >> iter 86000, loss: 0.269994
 >> iter 87000, loss: 0.410085
 >> iter 88000, loss: 0.219960
 >> iter 89000, loss: 0.236455
 >> iter 90000, loss: 0.306434
   Number of active neurons: 7
 >> iter 91000, loss: 0.225230
 >> iter 92000, loss: 0.264848
 >> iter 93000, loss: 0.318164
 >> iter 94000, loss: 0.302226
 >> iter 95000, loss: 0.160425
 >> iter 96000, loss: 0.278464
 >> iter 97000, loss: 0.325912
 >> iter 98000, loss: 0.247969
 >> iter 99000, loss: 0.250098
 >> iter 100000, loss: 0.271955
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.030335
 >> iter 2000, loss: 11.525286
 >> iter 3000, loss: 5.208048
 >> iter 4000, loss: 2.332164
 >> iter 5000, loss: 1.176240
 >> iter 6000, loss: 0.694398
 >> iter 7000, loss: 0.505797
 >> iter 8000, loss: 0.410940
 >> iter 9000, loss: 0.508407
 >> iter 10000, loss: 0.378773
   Number of active neurons: 11
 >> iter 11000, loss: 0.444676
 >> iter 12000, loss: 0.405675
 >> iter 13000, loss: 0.359752
 >> iter 14000, loss: 0.226858
 >> iter 15000, loss: 0.428687
 >> iter 16000, loss: 0.313716
 >> iter 17000, loss: 0.468905
 >> iter 18000, loss: 0.371429
 >> iter 19000, loss: 0.387673
 >> iter 20000, loss: 0.486827
   Number of active neurons: 9
 >> iter 21000, loss: 0.356395
 >> iter 22000, loss: 0.287588
 >> iter 23000, loss: 0.306795
 >> iter 24000, loss: 0.337175
 >> iter 25000, loss: 0.317663
 >> iter 26000, loss: 0.433606
 >> iter 27000, loss: 0.346823
 >> iter 28000, loss: 0.393549
 >> iter 29000, loss: 0.441516
 >> iter 30000, loss: 0.411944
   Number of active neurons: 9
 >> iter 31000, loss: 0.367959
 >> iter 32000, loss: 0.445569
 >> iter 33000, loss: 0.376756
 >> iter 34000, loss: 0.426781
 >> iter 35000, loss: 0.466106
 >> iter 36000, loss: 0.354682
 >> iter 37000, loss: 0.290174
 >> iter 38000, loss: 0.327960
 >> iter 39000, loss: 0.375275
 >> iter 40000, loss: 0.393715
   Number of active neurons: 8
 >> iter 41000, loss: 0.393825
 >> iter 42000, loss: 0.386941
 >> iter 43000, loss: 0.386509
 >> iter 44000, loss: 0.256372
 >> iter 45000, loss: 0.392903
 >> iter 46000, loss: 0.384159
 >> iter 47000, loss: 0.218463
 >> iter 48000, loss: 0.324843
 >> iter 49000, loss: 0.458184
 >> iter 50000, loss: 0.275798
   Number of active neurons: 8
 >> iter 51000, loss: 0.280664
 >> iter 52000, loss: 0.344170
 >> iter 53000, loss: 0.371160
 >> iter 54000, loss: 0.323177
 >> iter 55000, loss: 0.290739
 >> iter 56000, loss: 0.281387
 >> iter 57000, loss: 0.414868
 >> iter 58000, loss: 0.242574
 >> iter 59000, loss: 0.251501
 >> iter 60000, loss: 0.198266
   Number of active neurons: 8
 >> iter 61000, loss: 0.345959
 >> iter 62000, loss: 0.292276
 >> iter 63000, loss: 0.190317
 >> iter 64000, loss: 0.286803
 >> iter 65000, loss: 0.392993
 >> iter 66000, loss: 0.267466
 >> iter 67000, loss: 0.307490
 >> iter 68000, loss: 0.367810
 >> iter 69000, loss: 0.457319
 >> iter 70000, loss: 0.249552
   Number of active neurons: 8
 >> iter 71000, loss: 0.240285
 >> iter 72000, loss: 0.471508
 >> iter 73000, loss: 0.292238
 >> iter 74000, loss: 0.281101
 >> iter 75000, loss: 0.334423
 >> iter 76000, loss: 0.263973
 >> iter 77000, loss: 0.336313
 >> iter 78000, loss: 0.219187
 >> iter 79000, loss: 0.178242
 >> iter 80000, loss: 0.302789
   Number of active neurons: 7
 >> iter 81000, loss: 0.296320
 >> iter 82000, loss: 0.227553
 >> iter 83000, loss: 0.336513
 >> iter 84000, loss: 0.218074
 >> iter 85000, loss: 0.286553
 >> iter 86000, loss: 0.295148
 >> iter 87000, loss: 0.510254
 >> iter 88000, loss: 0.271011
 >> iter 89000, loss: 0.236051
 >> iter 90000, loss: 0.236749
   Number of active neurons: 7
 >> iter 91000, loss: 0.204561
 >> iter 92000, loss: 0.360929
 >> iter 93000, loss: 0.303862
 >> iter 94000, loss: 0.297807
 >> iter 95000, loss: 0.235562
 >> iter 96000, loss: 0.217292
 >> iter 97000, loss: 0.255012
 >> iter 98000, loss: 0.214588
 >> iter 99000, loss: 0.140143
 >> iter 100000, loss: 0.378113
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 19.129471
 >> iter 2000, loss: 12.168088
 >> iter 3000, loss: 6.024094
 >> iter 4000, loss: 3.117468
 >> iter 5000, loss: 1.877774
 >> iter 6000, loss: 1.074442
 >> iter 7000, loss: 0.758094
 >> iter 8000, loss: 0.509955
 >> iter 9000, loss: 0.372007
 >> iter 10000, loss: 0.520375
   Number of active neurons: 8
 >> iter 11000, loss: 0.489905
 >> iter 12000, loss: 0.399535
 >> iter 13000, loss: 0.443831
 >> iter 14000, loss: 0.234833
 >> iter 15000, loss: 0.151866
 >> iter 16000, loss: 0.352687
 >> iter 17000, loss: 0.385651
 >> iter 18000, loss: 0.238298
 >> iter 19000, loss: 0.233681
 >> iter 20000, loss: 0.312205
   Number of active neurons: 7
 >> iter 21000, loss: 0.215945
 >> iter 22000, loss: 0.241512
 >> iter 23000, loss: 0.220834
 >> iter 24000, loss: 0.271643
 >> iter 25000, loss: 0.237117
 >> iter 26000, loss: 0.236268
 >> iter 27000, loss: 0.261426
 >> iter 28000, loss: 0.248528
 >> iter 29000, loss: 0.208587
 >> iter 30000, loss: 0.225291
   Number of active neurons: 7
 >> iter 31000, loss: 0.397168
 >> iter 32000, loss: 0.388031
 >> iter 33000, loss: 0.277871
 >> iter 34000, loss: 0.349503
 >> iter 35000, loss: 0.370562
 >> iter 36000, loss: 0.255533
 >> iter 37000, loss: 0.226750
 >> iter 38000, loss: 0.213959
 >> iter 39000, loss: 0.260640
 >> iter 40000, loss: 0.247201
   Number of active neurons: 7
 >> iter 41000, loss: 0.288824
 >> iter 42000, loss: 0.266552
 >> iter 43000, loss: 0.184492
 >> iter 44000, loss: 0.274594
 >> iter 45000, loss: 0.227214
 >> iter 46000, loss: 0.348554
 >> iter 47000, loss: 0.347685
 >> iter 48000, loss: 0.193454
 >> iter 49000, loss: 0.317977
 >> iter 50000, loss: 0.271938
   Number of active neurons: 7
 >> iter 51000, loss: 0.391819
 >> iter 52000, loss: 0.216276
 >> iter 53000, loss: 0.258362
 >> iter 54000, loss: 0.549666
 >> iter 55000, loss: 0.418226
 >> iter 56000, loss: 0.362570
 >> iter 57000, loss: 0.272277
 >> iter 58000, loss: 0.207671
 >> iter 59000, loss: 0.277075
 >> iter 60000, loss: 0.376332
   Number of active neurons: 7
 >> iter 61000, loss: 0.211230
 >> iter 62000, loss: 0.224477
 >> iter 63000, loss: 0.332090
 >> iter 64000, loss: 0.295897
 >> iter 65000, loss: 0.247648
 >> iter 66000, loss: 0.266769
 >> iter 67000, loss: 0.190542
 >> iter 68000, loss: 0.197738
 >> iter 69000, loss: 0.250880
 >> iter 70000, loss: 0.387228
   Number of active neurons: 7
 >> iter 71000, loss: 0.288392
 >> iter 72000, loss: 0.160116
 >> iter 73000, loss: 0.229171
 >> iter 74000, loss: 0.275809
 >> iter 75000, loss: 0.223611
 >> iter 76000, loss: 0.358341
 >> iter 77000, loss: 0.239810
 >> iter 78000, loss: 0.238023
 >> iter 79000, loss: 0.282005
 >> iter 80000, loss: 0.322565
   Number of active neurons: 7
 >> iter 81000, loss: 0.313060
 >> iter 82000, loss: 0.234657
 >> iter 83000, loss: 0.389815
 >> iter 84000, loss: 0.290003
 >> iter 85000, loss: 0.286147
 >> iter 86000, loss: 0.183690
 >> iter 87000, loss: 0.431796
 >> iter 88000, loss: 0.339790
 >> iter 89000, loss: 0.276697
 >> iter 90000, loss: 0.226602
   Number of active neurons: 7
 >> iter 91000, loss: 0.316406
 >> iter 92000, loss: 0.372229
 >> iter 93000, loss: 0.263395
 >> iter 94000, loss: 0.420326
 >> iter 95000, loss: 0.284875
 >> iter 96000, loss: 0.254263
 >> iter 97000, loss: 0.300075
 >> iter 98000, loss: 0.253307
 >> iter 99000, loss: 0.288721
 >> iter 100000, loss: 0.413998
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.077801
 >> iter 2000, loss: 11.400278
 >> iter 3000, loss: 5.135482
 >> iter 4000, loss: 2.406142
 >> iter 5000, loss: 1.328097
 >> iter 6000, loss: 0.752193
 >> iter 7000, loss: 0.545725
 >> iter 8000, loss: 0.554321
 >> iter 9000, loss: 0.506611
 >> iter 10000, loss: 0.395103
   Number of active neurons: 9
 >> iter 11000, loss: 0.452592
 >> iter 12000, loss: 0.302678
 >> iter 13000, loss: 0.359401
 >> iter 14000, loss: 0.291263
 >> iter 15000, loss: 0.264538
 >> iter 16000, loss: 0.504091
 >> iter 17000, loss: 0.357165
 >> iter 18000, loss: 0.572523
 >> iter 19000, loss: 0.533025
 >> iter 20000, loss: 0.394082
   Number of active neurons: 8
 >> iter 21000, loss: 0.408331
 >> iter 22000, loss: 0.293526
 >> iter 23000, loss: 0.271935
 >> iter 24000, loss: 0.343182
 >> iter 25000, loss: 0.439822
 >> iter 26000, loss: 0.413513
 >> iter 27000, loss: 0.310539
 >> iter 28000, loss: 0.427268
 >> iter 29000, loss: 0.484491
 >> iter 30000, loss: 0.489885
   Number of active neurons: 7
 >> iter 31000, loss: 0.398902
 >> iter 32000, loss: 0.375931
 >> iter 33000, loss: 0.553179
 >> iter 34000, loss: 0.351072
 >> iter 35000, loss: 0.271245
 >> iter 36000, loss: 0.284339
 >> iter 37000, loss: 0.227951
 >> iter 38000, loss: 0.314395
 >> iter 39000, loss: 0.279339
 >> iter 40000, loss: 0.276541
   Number of active neurons: 7
 >> iter 41000, loss: 0.214326
 >> iter 42000, loss: 0.251645
 >> iter 43000, loss: 0.346422
 >> iter 44000, loss: 0.246919
 >> iter 45000, loss: 0.312367
 >> iter 46000, loss: 0.276507
 >> iter 47000, loss: 0.205399
 >> iter 48000, loss: 0.200465
 >> iter 49000, loss: 0.206530
 >> iter 50000, loss: 0.179389
   Number of active neurons: 6
 >> iter 51000, loss: 0.189203
 >> iter 52000, loss: 0.211237
 >> iter 53000, loss: 0.300717
 >> iter 54000, loss: 0.344564
 >> iter 55000, loss: 0.303175
 >> iter 56000, loss: 0.255882
 >> iter 57000, loss: 0.262265
 >> iter 58000, loss: 0.161437
 >> iter 59000, loss: 0.166249
 >> iter 60000, loss: 0.266606
   Number of active neurons: 6
 >> iter 61000, loss: 0.319404
 >> iter 62000, loss: 0.227201
 >> iter 63000, loss: 0.234501
 >> iter 64000, loss: 0.290189
 >> iter 65000, loss: 0.226667
 >> iter 66000, loss: 0.240208
 >> iter 67000, loss: 0.188507
 >> iter 68000, loss: 0.215839
 >> iter 69000, loss: 0.423771
 >> iter 70000, loss: 0.251583
   Number of active neurons: 6
 >> iter 71000, loss: 0.175930
 >> iter 72000, loss: 0.234799
 >> iter 73000, loss: 0.249190
 >> iter 74000, loss: 0.220118
 >> iter 75000, loss: 0.197260
 >> iter 76000, loss: 0.142666
 >> iter 77000, loss: 0.204825
 >> iter 78000, loss: 0.174554
 >> iter 79000, loss: 0.168626
 >> iter 80000, loss: 0.178867
   Number of active neurons: 5
 >> iter 81000, loss: 0.135399
 >> iter 82000, loss: 0.191304
 >> iter 83000, loss: 0.162911
 >> iter 84000, loss: 0.132859
 >> iter 85000, loss: 0.165739
 >> iter 86000, loss: 0.131327
 >> iter 87000, loss: 0.157868
 >> iter 88000, loss: 0.272191
 >> iter 89000, loss: 0.318668
 >> iter 90000, loss: 0.205647
   Number of active neurons: 4
 >> iter 91000, loss: 0.238011
 >> iter 92000, loss: 0.279103
 >> iter 93000, loss: 0.285938
 >> iter 94000, loss: 0.180775
 >> iter 95000, loss: 0.222053
 >> iter 96000, loss: 0.122265
 >> iter 97000, loss: 0.123977
 >> iter 98000, loss: 0.331839
 >> iter 99000, loss: 0.295488
 >> iter 100000, loss: 0.171745
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 19.069424
 >> iter 2000, loss: 11.666731
 >> iter 3000, loss: 5.526615
 >> iter 4000, loss: 2.626715
 >> iter 5000, loss: 1.338639
 >> iter 6000, loss: 0.724304
 >> iter 7000, loss: 0.461096
 >> iter 8000, loss: 0.417367
 >> iter 9000, loss: 0.409860
 >> iter 10000, loss: 0.535312
   Number of active neurons: 11
 >> iter 11000, loss: 0.447645
 >> iter 12000, loss: 0.787743
 >> iter 13000, loss: 0.478597
 >> iter 14000, loss: 0.681050
 >> iter 15000, loss: 0.476319
 >> iter 16000, loss: 0.398683
 >> iter 17000, loss: 0.468383
 >> iter 18000, loss: 0.286790
 >> iter 19000, loss: 0.322147
 >> iter 20000, loss: 0.304611
   Number of active neurons: 8
 >> iter 21000, loss: 0.550995
 >> iter 22000, loss: 0.452479
 >> iter 23000, loss: 0.323021
 >> iter 24000, loss: 0.494749
 >> iter 25000, loss: 0.445030
 >> iter 26000, loss: 0.439636
 >> iter 27000, loss: 0.318690
 >> iter 28000, loss: 0.264897
 >> iter 29000, loss: 0.458239
 >> iter 30000, loss: 0.332337
   Number of active neurons: 8
 >> iter 31000, loss: 0.353075
 >> iter 32000, loss: 0.353908
 >> iter 33000, loss: 0.434891
 >> iter 34000, loss: 0.315533
 >> iter 35000, loss: 0.357129
 >> iter 36000, loss: 0.297702
 >> iter 37000, loss: 0.300219
 >> iter 38000, loss: 0.352206
 >> iter 39000, loss: 0.529134
 >> iter 40000, loss: 0.497170
   Number of active neurons: 8
 >> iter 41000, loss: 0.356519
 >> iter 42000, loss: 0.387855
 >> iter 43000, loss: 0.396641
 >> iter 44000, loss: 0.348472
 >> iter 45000, loss: 0.422827
 >> iter 46000, loss: 0.258998
 >> iter 47000, loss: 0.182183
 >> iter 48000, loss: 0.299217
 >> iter 49000, loss: 0.247854
 >> iter 50000, loss: 0.257351
   Number of active neurons: 8
 >> iter 51000, loss: 0.550159
 >> iter 52000, loss: 0.443828
 >> iter 53000, loss: 0.356791
 >> iter 54000, loss: 0.376028
 >> iter 55000, loss: 0.235773
 >> iter 56000, loss: 0.361433
 >> iter 57000, loss: 0.324029
 >> iter 58000, loss: 0.318701
 >> iter 59000, loss: 0.240507
 >> iter 60000, loss: 0.367199
   Number of active neurons: 8
 >> iter 61000, loss: 0.205725
 >> iter 62000, loss: 0.241642
 >> iter 63000, loss: 0.242799
 >> iter 64000, loss: 0.191862
 >> iter 65000, loss: 0.247002
 >> iter 66000, loss: 0.258944
 >> iter 67000, loss: 0.202069
 >> iter 68000, loss: 0.148034
 >> iter 69000, loss: 0.259675
 >> iter 70000, loss: 0.167266
   Number of active neurons: 8
 >> iter 71000, loss: 0.343699
 >> iter 72000, loss: 0.380793
 >> iter 73000, loss: 0.347575
 >> iter 74000, loss: 0.229860
 >> iter 75000, loss: 0.217615
 >> iter 76000, loss: 0.421259
 >> iter 77000, loss: 0.394761
 >> iter 78000, loss: 0.270671
 >> iter 79000, loss: 0.155279
 >> iter 80000, loss: 0.307757
   Number of active neurons: 8
 >> iter 81000, loss: 0.406980
 >> iter 82000, loss: 0.232438
 >> iter 83000, loss: 0.240433
 >> iter 84000, loss: 0.297279
 >> iter 85000, loss: 0.302879
 >> iter 86000, loss: 0.397097
 >> iter 87000, loss: 0.329928
 >> iter 88000, loss: 0.290299
 >> iter 89000, loss: 0.256873
 >> iter 90000, loss: 0.266208
   Number of active neurons: 8
 >> iter 91000, loss: 0.303456
 >> iter 92000, loss: 0.183002
 >> iter 93000, loss: 0.408722
 >> iter 94000, loss: 0.353891
 >> iter 95000, loss: 0.299091
 >> iter 96000, loss: 0.220824
 >> iter 97000, loss: 0.439173
 >> iter 98000, loss: 0.344501
 >> iter 99000, loss: 0.280368
 >> iter 100000, loss: 0.168568
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.075136
 >> iter 2000, loss: 11.702084
 >> iter 3000, loss: 5.036333
 >> iter 4000, loss: 2.152373
 >> iter 5000, loss: 1.167347
 >> iter 6000, loss: 0.734953
 >> iter 7000, loss: 0.522827
 >> iter 8000, loss: 0.392894
 >> iter 9000, loss: 0.256955
 >> iter 10000, loss: 0.341681
   Number of active neurons: 9
 >> iter 11000, loss: 0.401391
 >> iter 12000, loss: 0.208758
 >> iter 13000, loss: 0.174062
 >> iter 14000, loss: 0.201594
 >> iter 15000, loss: 0.279435
 >> iter 16000, loss: 0.337454
 >> iter 17000, loss: 0.312677
 >> iter 18000, loss: 0.285174
 >> iter 19000, loss: 0.285344
 >> iter 20000, loss: 0.295076
   Number of active neurons: 9
 >> iter 21000, loss: 0.211140
 >> iter 22000, loss: 0.434800
 >> iter 23000, loss: 0.294259
 >> iter 24000, loss: 0.236404
 >> iter 25000, loss: 0.279388
 >> iter 26000, loss: 0.242439
 >> iter 27000, loss: 0.441070
 >> iter 28000, loss: 0.220721
 >> iter 29000, loss: 0.150171
 >> iter 30000, loss: 0.243850
   Number of active neurons: 9
 >> iter 31000, loss: 0.297871
 >> iter 32000, loss: 0.355094
 >> iter 33000, loss: 0.320770
 >> iter 34000, loss: 0.260872
 >> iter 35000, loss: 0.343538
 >> iter 36000, loss: 0.244689
 >> iter 37000, loss: 0.349473
 >> iter 38000, loss: 0.243083
 >> iter 39000, loss: 0.203066
 >> iter 40000, loss: 0.313164
   Number of active neurons: 9
 >> iter 41000, loss: 0.310080
 >> iter 42000, loss: 0.385674
 >> iter 43000, loss: 0.330184
 >> iter 44000, loss: 0.235014
 >> iter 45000, loss: 0.401467
 >> iter 46000, loss: 0.453335
 >> iter 47000, loss: 0.297030
 >> iter 48000, loss: 0.186680
 >> iter 49000, loss: 0.410493
 >> iter 50000, loss: 0.304931
   Number of active neurons: 9
 >> iter 51000, loss: 0.334597
 >> iter 52000, loss: 0.326332
 >> iter 53000, loss: 0.233800
 >> iter 54000, loss: 0.291860
 >> iter 55000, loss: 0.231634
 >> iter 56000, loss: 0.321405
 >> iter 57000, loss: 0.373284
 >> iter 58000, loss: 0.301586
 >> iter 59000, loss: 0.371396
 >> iter 60000, loss: 0.332212
   Number of active neurons: 9
 >> iter 61000, loss: 0.231663
 >> iter 62000, loss: 0.228646
 >> iter 63000, loss: 0.281754
 >> iter 64000, loss: 0.232135
 >> iter 65000, loss: 0.167388
 >> iter 66000, loss: 0.168137
 >> iter 67000, loss: 0.194795
 >> iter 68000, loss: 0.213369
 >> iter 69000, loss: 0.310556
 >> iter 70000, loss: 0.237992
   Number of active neurons: 8
 >> iter 71000, loss: 0.238839
 >> iter 72000, loss: 0.274607
 >> iter 73000, loss: 0.272034
 >> iter 74000, loss: 0.283919
 >> iter 75000, loss: 0.197906
 >> iter 76000, loss: 0.172696
 >> iter 77000, loss: 0.148278
 >> iter 78000, loss: 0.125576
 >> iter 79000, loss: 0.317080
 >> iter 80000, loss: 0.260346
   Number of active neurons: 8
 >> iter 81000, loss: 0.216286
 >> iter 82000, loss: 0.245916
 >> iter 83000, loss: 0.222831
 >> iter 84000, loss: 0.182390
 >> iter 85000, loss: 0.212689
 >> iter 86000, loss: 0.266846
 >> iter 87000, loss: 0.259739
 >> iter 88000, loss: 0.179538
 >> iter 89000, loss: 0.168338
 >> iter 90000, loss: 0.171976
   Number of active neurons: 7
 >> iter 91000, loss: 0.345855
 >> iter 92000, loss: 0.279117
 >> iter 93000, loss: 0.220491
 >> iter 94000, loss: 0.267331
 >> iter 95000, loss: 0.171372
 >> iter 96000, loss: 0.150215
 >> iter 97000, loss: 0.117396
 >> iter 98000, loss: 0.186491
 >> iter 99000, loss: 0.147320
 >> iter 100000, loss: 0.159179
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.103826
 >> iter 2000, loss: 11.134416
 >> iter 3000, loss: 4.529592
 >> iter 4000, loss: 2.015749
 >> iter 5000, loss: 0.997334
 >> iter 6000, loss: 0.708014
 >> iter 7000, loss: 0.401723
 >> iter 8000, loss: 0.247660
 >> iter 9000, loss: 0.228660
 >> iter 10000, loss: 0.277500
   Number of active neurons: 7
 >> iter 11000, loss: 0.207036
 >> iter 12000, loss: 0.214982
 >> iter 13000, loss: 0.170277
 >> iter 14000, loss: 0.179154
 >> iter 15000, loss: 0.253639
 >> iter 16000, loss: 0.373324
 >> iter 17000, loss: 0.266034
 >> iter 18000, loss: 0.316677
 >> iter 19000, loss: 0.257939
 >> iter 20000, loss: 0.198801
   Number of active neurons: 7
 >> iter 21000, loss: 0.217837
 >> iter 22000, loss: 0.160321
 >> iter 23000, loss: 0.187652
 >> iter 24000, loss: 0.182008
 >> iter 25000, loss: 0.211404
 >> iter 26000, loss: 0.178653
 >> iter 27000, loss: 0.211354
 >> iter 28000, loss: 0.265619
 >> iter 29000, loss: 0.201781
 >> iter 30000, loss: 0.199427
   Number of active neurons: 6
 >> iter 31000, loss: 0.259428
 >> iter 32000, loss: 0.383504
 >> iter 33000, loss: 0.326395
 >> iter 34000, loss: 0.224816
 >> iter 35000, loss: 0.193894
 >> iter 36000, loss: 0.226767
 >> iter 37000, loss: 0.251806
 >> iter 38000, loss: 0.136674
 >> iter 39000, loss: 0.310827
 >> iter 40000, loss: 0.274805
   Number of active neurons: 6
 >> iter 41000, loss: 0.425208
 >> iter 42000, loss: 0.326396
 >> iter 43000, loss: 0.196102
 >> iter 44000, loss: 0.139029
 >> iter 45000, loss: 0.204258
 >> iter 46000, loss: 0.127055
 >> iter 47000, loss: 0.154825
 >> iter 48000, loss: 0.170494
 >> iter 49000, loss: 0.270881
 >> iter 50000, loss: 0.252100
   Number of active neurons: 6
 >> iter 51000, loss: 0.227972
 >> iter 52000, loss: 0.137455
 >> iter 53000, loss: 0.232914
 >> iter 54000, loss: 0.221805
 >> iter 55000, loss: 0.194174
 >> iter 56000, loss: 0.136176
 >> iter 57000, loss: 0.258385
 >> iter 58000, loss: 0.271789
 >> iter 59000, loss: 0.304044
 >> iter 60000, loss: 0.183417
   Number of active neurons: 5
 >> iter 61000, loss: 0.125943
 >> iter 62000, loss: 0.338452
 >> iter 63000, loss: 0.252221
 >> iter 64000, loss: 0.273427
 >> iter 65000, loss: 0.195987
 >> iter 66000, loss: 0.203276
 >> iter 67000, loss: 0.324326
 >> iter 68000, loss: 0.233698
 >> iter 69000, loss: 0.360741
 >> iter 70000, loss: 0.267802
   Number of active neurons: 5
 >> iter 71000, loss: 0.159449
 >> iter 72000, loss: 0.217885
 >> iter 73000, loss: 0.156096
 >> iter 74000, loss: 0.280031
 >> iter 75000, loss: 0.157001
 >> iter 76000, loss: 0.177599
 >> iter 77000, loss: 0.218756
 >> iter 78000, loss: 0.188174
 >> iter 79000, loss: 0.152420
 >> iter 80000, loss: 0.176987
   Number of active neurons: 5
 >> iter 81000, loss: 0.170950
 >> iter 82000, loss: 0.251227
 >> iter 83000, loss: 0.245478
 >> iter 84000, loss: 0.294966
 >> iter 85000, loss: 0.302749
 >> iter 86000, loss: 0.204567
 >> iter 87000, loss: 0.344480
 >> iter 88000, loss: 0.206533
 >> iter 89000, loss: 0.152039
 >> iter 90000, loss: 0.208831
   Number of active neurons: 5
 >> iter 91000, loss: 0.189415
 >> iter 92000, loss: 0.171811
 >> iter 93000, loss: 0.252859
 >> iter 94000, loss: 0.268577
 >> iter 95000, loss: 0.294902
 >> iter 96000, loss: 0.219885
 >> iter 97000, loss: 0.229318
 >> iter 98000, loss: 0.257356
 >> iter 99000, loss: 0.200614
 >> iter 100000, loss: 0.207184
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 19.161437
 >> iter 2000, loss: 12.723657
 >> iter 3000, loss: 6.479233
 >> iter 4000, loss: 3.065366
 >> iter 5000, loss: 1.584095
 >> iter 6000, loss: 0.781248
 >> iter 7000, loss: 0.822947
 >> iter 8000, loss: 0.552390
 >> iter 9000, loss: 0.527522
 >> iter 10000, loss: 0.339132
   Number of active neurons: 8
 >> iter 11000, loss: 0.521208
 >> iter 12000, loss: 0.338674
 >> iter 13000, loss: 0.567264
 >> iter 14000, loss: 0.556106
 >> iter 15000, loss: 0.576828
 >> iter 16000, loss: 0.461079
 >> iter 17000, loss: 0.567219
 >> iter 18000, loss: 0.495646
 >> iter 19000, loss: 0.515114
 >> iter 20000, loss: 0.394562
   Number of active neurons: 8
 >> iter 21000, loss: 0.283747
 >> iter 22000, loss: 0.323313
 >> iter 23000, loss: 0.385825
 >> iter 24000, loss: 0.652793
 >> iter 25000, loss: 0.542178
 >> iter 26000, loss: 0.409777
 >> iter 27000, loss: 0.437564
 >> iter 28000, loss: 0.308692
 >> iter 29000, loss: 0.353604
 >> iter 30000, loss: 0.344249
   Number of active neurons: 8
 >> iter 31000, loss: 0.492458
 >> iter 32000, loss: 0.404262
 >> iter 33000, loss: 0.430504
 >> iter 34000, loss: 0.398871
 >> iter 35000, loss: 0.303178
 >> iter 36000, loss: 0.454046
 >> iter 37000, loss: 0.290807
 >> iter 38000, loss: 0.423651
 >> iter 39000, loss: 0.328440
 >> iter 40000, loss: 0.332749
   Number of active neurons: 8
 >> iter 41000, loss: 0.283946
 >> iter 42000, loss: 0.297024
 >> iter 43000, loss: 0.283431
 >> iter 44000, loss: 0.319414
 >> iter 45000, loss: 0.388621
 >> iter 46000, loss: 0.273879
 >> iter 47000, loss: 0.318211
 >> iter 48000, loss: 0.322569
 >> iter 49000, loss: 0.364077
 >> iter 50000, loss: 0.433457
   Number of active neurons: 7
 >> iter 51000, loss: 0.569653
 >> iter 52000, loss: 0.573044
 >> iter 53000, loss: 0.482178
 >> iter 54000, loss: 0.502532
 >> iter 55000, loss: 0.522069
 >> iter 56000, loss: 0.502888
 >> iter 57000, loss: 0.549931
 >> iter 58000, loss: 0.388318
 >> iter 59000, loss: 0.382817
 >> iter 60000, loss: 0.383974
   Number of active neurons: 7
 >> iter 61000, loss: 0.417874
 >> iter 62000, loss: 0.409520
 >> iter 63000, loss: 0.439010
 >> iter 64000, loss: 0.324409
 >> iter 65000, loss: 0.329017
 >> iter 66000, loss: 0.471804
 >> iter 67000, loss: 0.358444
 >> iter 68000, loss: 0.406403
 >> iter 69000, loss: 0.362541
 >> iter 70000, loss: 0.311506
   Number of active neurons: 7
 >> iter 71000, loss: 0.553619
 >> iter 72000, loss: 0.405337
 >> iter 73000, loss: 0.340817
 >> iter 74000, loss: 0.245551
 >> iter 75000, loss: 0.242580
 >> iter 76000, loss: 0.362283
 >> iter 77000, loss: 0.528132
 >> iter 78000, loss: 0.426537
 >> iter 79000, loss: 0.343312
 >> iter 80000, loss: 0.334915
   Number of active neurons: 7
 >> iter 81000, loss: 0.332786
 >> iter 82000, loss: 0.275434
 >> iter 83000, loss: 0.303069
 >> iter 84000, loss: 0.596618
 >> iter 85000, loss: 0.405533
 >> iter 86000, loss: 0.328043
 >> iter 87000, loss: 0.446165
 >> iter 88000, loss: 0.372668
 >> iter 89000, loss: 0.379226
 >> iter 90000, loss: 0.456521
   Number of active neurons: 7
 >> iter 91000, loss: 0.543850
 >> iter 92000, loss: 0.432094
 >> iter 93000, loss: 0.311697
 >> iter 94000, loss: 0.217349
 >> iter 95000, loss: 0.396297
 >> iter 96000, loss: 0.291135
 >> iter 97000, loss: 0.264054
 >> iter 98000, loss: 0.279567
 >> iter 99000, loss: 0.281080
 >> iter 100000, loss: 0.311501
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.927746
 >> iter 2000, loss: 10.953041
 >> iter 3000, loss: 5.068668
 >> iter 4000, loss: 2.440475
 >> iter 5000, loss: 1.271106
 >> iter 6000, loss: 0.679047
 >> iter 7000, loss: 0.536931
 >> iter 8000, loss: 0.394944
 >> iter 9000, loss: 0.373536
 >> iter 10000, loss: 0.400021
   Number of active neurons: 10
 >> iter 11000, loss: 0.520029
 >> iter 12000, loss: 0.368444
 >> iter 13000, loss: 0.370357
 >> iter 14000, loss: 0.516435
 >> iter 15000, loss: 0.297131
 >> iter 16000, loss: 0.383988
 >> iter 17000, loss: 0.271061
 >> iter 18000, loss: 0.293652
 >> iter 19000, loss: 0.406941
 >> iter 20000, loss: 0.250721
   Number of active neurons: 9
 >> iter 21000, loss: 0.304157
 >> iter 22000, loss: 0.412581
 >> iter 23000, loss: 0.352488
 >> iter 24000, loss: 0.218198
 >> iter 25000, loss: 0.325564
 >> iter 26000, loss: 0.429257
 >> iter 27000, loss: 0.294331
 >> iter 28000, loss: 0.323333
 >> iter 29000, loss: 0.324608
 >> iter 30000, loss: 0.461565
   Number of active neurons: 9
 >> iter 31000, loss: 0.379688
 >> iter 32000, loss: 0.235872
 >> iter 33000, loss: 0.247626
 >> iter 34000, loss: 0.220094
 >> iter 35000, loss: 0.345043
 >> iter 36000, loss: 0.358186
 >> iter 37000, loss: 0.268408
 >> iter 38000, loss: 0.398297
 >> iter 39000, loss: 0.379602
 >> iter 40000, loss: 0.301139
   Number of active neurons: 8
 >> iter 41000, loss: 0.212452
 >> iter 42000, loss: 0.231641
 >> iter 43000, loss: 0.197726
 >> iter 44000, loss: 0.207789
 >> iter 45000, loss: 0.221793
 >> iter 46000, loss: 0.287608
 >> iter 47000, loss: 0.261970
 >> iter 48000, loss: 0.231382
 >> iter 49000, loss: 0.178275
 >> iter 50000, loss: 0.210280
   Number of active neurons: 7
 >> iter 51000, loss: 0.231133
 >> iter 52000, loss: 0.164039
 >> iter 53000, loss: 0.229568
 >> iter 54000, loss: 0.325648
 >> iter 55000, loss: 0.215639
 >> iter 56000, loss: 0.191802
 >> iter 57000, loss: 0.167238
 >> iter 58000, loss: 0.147063
 >> iter 59000, loss: 0.470314
 >> iter 60000, loss: 0.376390
   Number of active neurons: 6
 >> iter 61000, loss: 0.205570
 >> iter 62000, loss: 0.211838
 >> iter 63000, loss: 0.242637
 >> iter 64000, loss: 0.208453
 >> iter 65000, loss: 0.224817
 >> iter 66000, loss: 0.178787
 >> iter 67000, loss: 0.183444
 >> iter 68000, loss: 0.192516
 >> iter 69000, loss: 0.163336
 >> iter 70000, loss: 0.226102
   Number of active neurons: 5
 >> iter 71000, loss: 0.275486
 >> iter 72000, loss: 0.174845
 >> iter 73000, loss: 0.224573
 >> iter 74000, loss: 0.232724
 >> iter 75000, loss: 0.188259
 >> iter 76000, loss: 0.215068
 >> iter 77000, loss: 0.287465
 >> iter 78000, loss: 0.314785
 >> iter 79000, loss: 0.205072
 >> iter 80000, loss: 0.162631
   Number of active neurons: 5
 >> iter 81000, loss: 0.163055
 >> iter 82000, loss: 0.360109
 >> iter 83000, loss: 0.252104
 >> iter 84000, loss: 0.167709
 >> iter 85000, loss: 0.273914
 >> iter 86000, loss: 0.162631
 >> iter 87000, loss: 0.114997
 >> iter 88000, loss: 0.207439
 >> iter 89000, loss: 0.263584
 >> iter 90000, loss: 0.393992
   Number of active neurons: 5
 >> iter 91000, loss: 0.273823
 >> iter 92000, loss: 0.246371
 >> iter 93000, loss: 0.278458
 >> iter 94000, loss: 0.292686
 >> iter 95000, loss: 0.181404
 >> iter 96000, loss: 0.155083
 >> iter 97000, loss: 0.240978
 >> iter 98000, loss: 0.264459
 >> iter 99000, loss: 0.197197
 >> iter 100000, loss: 0.152382
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.911350
 >> iter 2000, loss: 10.682659
 >> iter 3000, loss: 5.446966
 >> iter 4000, loss: 2.773592
 >> iter 5000, loss: 1.829688
 >> iter 6000, loss: 1.150763
 >> iter 7000, loss: 0.829056
 >> iter 8000, loss: 0.691034
 >> iter 9000, loss: 0.631249
 >> iter 10000, loss: 0.739199
   Number of active neurons: 10
 >> iter 11000, loss: 0.561510
 >> iter 12000, loss: 0.460527
 >> iter 13000, loss: 0.553209
 >> iter 14000, loss: 0.506878
 >> iter 15000, loss: 0.565519
 >> iter 16000, loss: 0.646759
 >> iter 17000, loss: 0.712097
 >> iter 18000, loss: 0.486563
 >> iter 19000, loss: 0.597110
 >> iter 20000, loss: 0.548326
   Number of active neurons: 8
 >> iter 21000, loss: 0.381895
 >> iter 22000, loss: 0.455298
 >> iter 23000, loss: 0.450256
 >> iter 24000, loss: 0.387003
 >> iter 25000, loss: 0.406889
 >> iter 26000, loss: 0.435290
 >> iter 27000, loss: 0.562692
 >> iter 28000, loss: 0.542835
 >> iter 29000, loss: 0.515667
 >> iter 30000, loss: 0.416412
   Number of active neurons: 8
 >> iter 31000, loss: 0.461629
 >> iter 32000, loss: 0.353805
 >> iter 33000, loss: 0.422734
 >> iter 34000, loss: 0.457252
 >> iter 35000, loss: 0.597807
 >> iter 36000, loss: 0.614053
 >> iter 37000, loss: 0.544032
 >> iter 38000, loss: 0.361719
 >> iter 39000, loss: 0.260704
 >> iter 40000, loss: 0.320298
   Number of active neurons: 8
 >> iter 41000, loss: 0.419133
 >> iter 42000, loss: 0.415656
 >> iter 43000, loss: 0.298779
 >> iter 44000, loss: 0.433611
 >> iter 45000, loss: 0.437867
 >> iter 46000, loss: 0.427210
 >> iter 47000, loss: 0.436089
 >> iter 48000, loss: 0.380530
 >> iter 49000, loss: 0.528211
 >> iter 50000, loss: 0.565491
   Number of active neurons: 8
 >> iter 51000, loss: 0.419760
 >> iter 52000, loss: 0.558746
 >> iter 53000, loss: 0.532003
 >> iter 54000, loss: 0.508622
 >> iter 55000, loss: 0.414751
 >> iter 56000, loss: 0.406535
 >> iter 57000, loss: 0.371505
 >> iter 58000, loss: 0.270003
 >> iter 59000, loss: 0.393432
 >> iter 60000, loss: 0.363424
   Number of active neurons: 6
 >> iter 61000, loss: 0.337361
 >> iter 62000, loss: 0.396103
 >> iter 63000, loss: 0.670948
 >> iter 64000, loss: 0.520294
 >> iter 65000, loss: 0.555360
 >> iter 66000, loss: 0.494712
 >> iter 67000, loss: 0.485880
 >> iter 68000, loss: 0.409430
 >> iter 69000, loss: 0.618535
 >> iter 70000, loss: 0.444709
   Number of active neurons: 6
 >> iter 71000, loss: 0.496947
 >> iter 72000, loss: 0.455856
 >> iter 73000, loss: 0.469337
 >> iter 74000, loss: 0.376168
 >> iter 75000, loss: 0.357397
 >> iter 76000, loss: 0.265208
 >> iter 77000, loss: 0.428881
 >> iter 78000, loss: 0.405016
 >> iter 79000, loss: 0.367172
 >> iter 80000, loss: 0.308264
   Number of active neurons: 6
 >> iter 81000, loss: 0.421764
 >> iter 82000, loss: 0.526477
 >> iter 83000, loss: 0.454885
 >> iter 84000, loss: 0.426955
 >> iter 85000, loss: 0.542570
 >> iter 86000, loss: 0.305539
 >> iter 87000, loss: 0.233845
 >> iter 88000, loss: 0.257011
 >> iter 89000, loss: 0.479909
 >> iter 90000, loss: 0.495223
   Number of active neurons: 6
 >> iter 91000, loss: 0.521830
 >> iter 92000, loss: 0.473746
 >> iter 93000, loss: 0.337992
 >> iter 94000, loss: 0.311501
 >> iter 95000, loss: 0.442448
 >> iter 96000, loss: 0.455786
 >> iter 97000, loss: 0.322941
 >> iter 98000, loss: 0.382813
 >> iter 99000, loss: 0.649734
 >> iter 100000, loss: 0.521927
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.069673
 >> iter 2000, loss: 12.226381
 >> iter 3000, loss: 5.317491
 >> iter 4000, loss: 2.295186
 >> iter 5000, loss: 1.178838
 >> iter 6000, loss: 0.729402
 >> iter 7000, loss: 0.579212
 >> iter 8000, loss: 0.554222
 >> iter 9000, loss: 0.443394
 >> iter 10000, loss: 0.384712
   Number of active neurons: 10
 >> iter 11000, loss: 0.426758
 >> iter 12000, loss: 0.250723
 >> iter 13000, loss: 0.223543
 >> iter 14000, loss: 0.257098
 >> iter 15000, loss: 0.310075
 >> iter 16000, loss: 0.278991
 >> iter 17000, loss: 0.368135
 >> iter 18000, loss: 0.224150
 >> iter 19000, loss: 0.202693
 >> iter 20000, loss: 0.365532
   Number of active neurons: 10
 >> iter 21000, loss: 0.519165
 >> iter 22000, loss: 0.365580
 >> iter 23000, loss: 0.282503
 >> iter 24000, loss: 0.411037
 >> iter 25000, loss: 0.303446
 >> iter 26000, loss: 0.173449
 >> iter 27000, loss: 0.307495
 >> iter 28000, loss: 0.284546
 >> iter 29000, loss: 0.288956
 >> iter 30000, loss: 0.337264
   Number of active neurons: 10
 >> iter 31000, loss: 0.382377
 >> iter 32000, loss: 0.238002
 >> iter 33000, loss: 0.273449
 >> iter 34000, loss: 0.262156
 >> iter 35000, loss: 0.342814
 >> iter 36000, loss: 0.186048
 >> iter 37000, loss: 0.178758
 >> iter 38000, loss: 0.292279
 >> iter 39000, loss: 0.230945
 >> iter 40000, loss: 0.277634
   Number of active neurons: 10
 >> iter 41000, loss: 0.257275
 >> iter 42000, loss: 0.338054
 >> iter 43000, loss: 0.255212
 >> iter 44000, loss: 0.198984
 >> iter 45000, loss: 0.231863
 >> iter 46000, loss: 0.348456
 >> iter 47000, loss: 0.281015
 >> iter 48000, loss: 0.275744
 >> iter 49000, loss: 0.156587
 >> iter 50000, loss: 0.245056
   Number of active neurons: 10
 >> iter 51000, loss: 0.330941
 >> iter 52000, loss: 0.288004
 >> iter 53000, loss: 0.248322
 >> iter 54000, loss: 0.157346
 >> iter 55000, loss: 0.258115
 >> iter 56000, loss: 0.243889
 >> iter 57000, loss: 0.286646
 >> iter 58000, loss: 0.308224
 >> iter 59000, loss: 0.254778
 >> iter 60000, loss: 0.256036
   Number of active neurons: 9
 >> iter 61000, loss: 0.283189
 >> iter 62000, loss: 0.347949
 >> iter 63000, loss: 0.296776
 >> iter 64000, loss: 0.325264
 >> iter 65000, loss: 0.316216
 >> iter 66000, loss: 0.189903
 >> iter 67000, loss: 0.244266
 >> iter 68000, loss: 0.252802
 >> iter 69000, loss: 0.294318
 >> iter 70000, loss: 0.190284
   Number of active neurons: 9
 >> iter 71000, loss: 0.395613
 >> iter 72000, loss: 0.283947
 >> iter 73000, loss: 0.413718
 >> iter 74000, loss: 0.290167
 >> iter 75000, loss: 0.212416
 >> iter 76000, loss: 0.241218
 >> iter 77000, loss: 0.308900
 >> iter 78000, loss: 0.180675
 >> iter 79000, loss: 0.188997
 >> iter 80000, loss: 0.217090
   Number of active neurons: 9
 >> iter 81000, loss: 0.317011
 >> iter 82000, loss: 0.213344
 >> iter 83000, loss: 0.325666
 >> iter 84000, loss: 0.301329
 >> iter 85000, loss: 0.231379
 >> iter 86000, loss: 0.190240
 >> iter 87000, loss: 0.278896
 >> iter 88000, loss: 0.202725
 >> iter 89000, loss: 0.197292
 >> iter 90000, loss: 0.232617
   Number of active neurons: 8
 >> iter 91000, loss: 0.190422
 >> iter 92000, loss: 0.192626
 >> iter 93000, loss: 0.292463
 >> iter 94000, loss: 0.329505
 >> iter 95000, loss: 0.368756
 >> iter 96000, loss: 0.357340
 >> iter 97000, loss: 0.242878
 >> iter 98000, loss: 0.169126
 >> iter 99000, loss: 0.248641
 >> iter 100000, loss: 0.283462
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.010182
 >> iter 2000, loss: 10.646294
 >> iter 3000, loss: 4.449670
 >> iter 4000, loss: 1.989571
 >> iter 5000, loss: 1.209352
 >> iter 6000, loss: 0.654074
 >> iter 7000, loss: 0.401834
 >> iter 8000, loss: 0.329140
 >> iter 9000, loss: 0.485132
 >> iter 10000, loss: 0.432300
   Number of active neurons: 8
 >> iter 11000, loss: 0.341706
 >> iter 12000, loss: 0.242296
 >> iter 13000, loss: 0.252602
 >> iter 14000, loss: 0.285415
 >> iter 15000, loss: 0.384844
 >> iter 16000, loss: 0.576610
 >> iter 17000, loss: 0.397530
 >> iter 18000, loss: 0.237363
 >> iter 19000, loss: 0.457769
 >> iter 20000, loss: 0.401205
   Number of active neurons: 7
 >> iter 21000, loss: 0.254613
 >> iter 22000, loss: 0.239025
 >> iter 23000, loss: 0.246739
 >> iter 24000, loss: 0.283916
 >> iter 25000, loss: 0.284617
 >> iter 26000, loss: 0.266685
 >> iter 27000, loss: 0.201055
 >> iter 28000, loss: 0.277045
 >> iter 29000, loss: 0.340797
 >> iter 30000, loss: 0.339703
   Number of active neurons: 7
 >> iter 31000, loss: 0.381111
 >> iter 32000, loss: 0.268736
 >> iter 33000, loss: 0.320820
 >> iter 34000, loss: 0.461488
 >> iter 35000, loss: 0.514756
 >> iter 36000, loss: 0.383504
 >> iter 37000, loss: 0.367807
 >> iter 38000, loss: 0.256727
 >> iter 39000, loss: 0.253625
 >> iter 40000, loss: 0.510230
   Number of active neurons: 7
 >> iter 41000, loss: 0.314153
 >> iter 42000, loss: 0.275106
 >> iter 43000, loss: 0.446006
 >> iter 44000, loss: 0.247535
 >> iter 45000, loss: 0.349468
 >> iter 46000, loss: 0.374795
 >> iter 47000, loss: 0.244178
 >> iter 48000, loss: 0.240335
 >> iter 49000, loss: 0.350803
 >> iter 50000, loss: 0.318345
   Number of active neurons: 7
 >> iter 51000, loss: 0.313962
 >> iter 52000, loss: 0.219873
 >> iter 53000, loss: 0.297389
 >> iter 54000, loss: 0.358902
 >> iter 55000, loss: 0.291431
 >> iter 56000, loss: 0.180854
 >> iter 57000, loss: 0.234451
 >> iter 58000, loss: 0.270801
 >> iter 59000, loss: 0.318057
 >> iter 60000, loss: 0.271047
   Number of active neurons: 7
 >> iter 61000, loss: 0.205080
 >> iter 62000, loss: 0.271521
 >> iter 63000, loss: 0.250565
 >> iter 64000, loss: 0.170123
 >> iter 65000, loss: 0.129628
 >> iter 66000, loss: 0.151292
 >> iter 67000, loss: 0.360809
 >> iter 68000, loss: 0.346095
 >> iter 69000, loss: 0.268587
 >> iter 70000, loss: 0.333322
   Number of active neurons: 7
 >> iter 71000, loss: 0.326433
 >> iter 72000, loss: 0.275956
 >> iter 73000, loss: 0.234202
 >> iter 74000, loss: 0.256602
 >> iter 75000, loss: 0.343241
 >> iter 76000, loss: 0.466307
 >> iter 77000, loss: 0.429035
 >> iter 78000, loss: 0.442611
 >> iter 79000, loss: 0.394617
 >> iter 80000, loss: 0.348579
   Number of active neurons: 7
 >> iter 81000, loss: 0.249315
 >> iter 82000, loss: 0.209020
 >> iter 83000, loss: 0.210976
 >> iter 84000, loss: 0.178619
 >> iter 85000, loss: 0.209554
 >> iter 86000, loss: 0.151176
 >> iter 87000, loss: 0.321311
 >> iter 88000, loss: 0.248351
 >> iter 89000, loss: 0.221150
 >> iter 90000, loss: 0.338556
   Number of active neurons: 7
 >> iter 91000, loss: 0.211716
 >> iter 92000, loss: 0.252682
 >> iter 93000, loss: 0.181064
 >> iter 94000, loss: 0.190667
 >> iter 95000, loss: 0.279179
 >> iter 96000, loss: 0.210951
 >> iter 97000, loss: 0.202415
 >> iter 98000, loss: 0.138327
 >> iter 99000, loss: 0.235610
 >> iter 100000, loss: 0.241324
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

