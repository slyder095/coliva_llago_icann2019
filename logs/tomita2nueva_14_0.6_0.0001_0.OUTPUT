 > Problema: tomita2nueva
 > Args:
   - Hidden size: 14
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.363125
 >> iter 2000, loss: 4.446564
 >> iter 3000, loss: 1.778272
 >> iter 4000, loss: 0.764250
 >> iter 5000, loss: 0.369105
 >> iter 6000, loss: 0.181093
 >> iter 7000, loss: 0.123609
 >> iter 8000, loss: 0.088270
 >> iter 9000, loss: 0.074133
 >> iter 10000, loss: 0.079132
   Number of active neurons: 9
 >> iter 11000, loss: 0.091881
 >> iter 12000, loss: 0.078033
 >> iter 13000, loss: 0.052048
 >> iter 14000, loss: 0.062890
 >> iter 15000, loss: 0.066192
 >> iter 16000, loss: 0.064953
 >> iter 17000, loss: 0.055970
 >> iter 18000, loss: 0.044318
 >> iter 19000, loss: 0.048243
 >> iter 20000, loss: 0.066685
   Number of active neurons: 9
 >> iter 21000, loss: 0.054623
 >> iter 22000, loss: 0.080294
 >> iter 23000, loss: 0.062034
 >> iter 24000, loss: 0.058263
 >> iter 25000, loss: 0.051523
 >> iter 26000, loss: 0.045297
 >> iter 27000, loss: 0.071774
 >> iter 28000, loss: 0.079786
 >> iter 29000, loss: 0.065180
 >> iter 30000, loss: 0.058511
   Number of active neurons: 7
 >> iter 31000, loss: 0.061142
 >> iter 32000, loss: 0.048205
 >> iter 33000, loss: 0.039983
 >> iter 34000, loss: 0.047909
 >> iter 35000, loss: 0.052537
 >> iter 36000, loss: 0.055136
 >> iter 37000, loss: 0.079588
 >> iter 38000, loss: 0.066411
 >> iter 39000, loss: 0.075430
 >> iter 40000, loss: 0.061073
   Number of active neurons: 5
 >> iter 41000, loss: 0.056711
 >> iter 42000, loss: 0.044496
 >> iter 43000, loss: 0.059655
 >> iter 44000, loss: 0.045521
 >> iter 45000, loss: 0.055787
 >> iter 46000, loss: 0.056876
 >> iter 47000, loss: 0.043673
 >> iter 48000, loss: 0.056468
 >> iter 49000, loss: 0.064397
 >> iter 50000, loss: 0.043720
   Number of active neurons: 3
 >> iter 51000, loss: 0.070649
 >> iter 52000, loss: 0.046331
 >> iter 53000, loss: 0.037006
 >> iter 54000, loss: 0.035856
 >> iter 55000, loss: 0.058155
 >> iter 56000, loss: 0.046007
 >> iter 57000, loss: 0.037677
 >> iter 58000, loss: 0.040749
 >> iter 59000, loss: 0.036433
 >> iter 60000, loss: 0.045531
   Number of active neurons: 3
 >> iter 61000, loss: 0.040065
 >> iter 62000, loss: 0.046879
 >> iter 63000, loss: 0.042847
 >> iter 64000, loss: 0.052940
 >> iter 65000, loss: 0.046027
 >> iter 66000, loss: 0.052286
 >> iter 67000, loss: 0.064882
 >> iter 68000, loss: 0.056246
 >> iter 69000, loss: 0.050088
 >> iter 70000, loss: 0.055812
   Number of active neurons: 2
 >> iter 71000, loss: 0.064932
 >> iter 72000, loss: 0.043649
 >> iter 73000, loss: 0.034116
 >> iter 74000, loss: 0.045771
 >> iter 75000, loss: 0.054935
 >> iter 76000, loss: 0.052197
 >> iter 77000, loss: 0.043572
 >> iter 78000, loss: 0.030949
 >> iter 79000, loss: 0.043731
 >> iter 80000, loss: 0.042166
   Number of active neurons: 2
 >> iter 81000, loss: 0.072116
 >> iter 82000, loss: 0.054081
 >> iter 83000, loss: 0.049239
 >> iter 84000, loss: 0.056405
 >> iter 85000, loss: 0.057810
 >> iter 86000, loss: 0.041519
 >> iter 87000, loss: 0.036040
 >> iter 88000, loss: 0.047028
 >> iter 89000, loss: 0.045212
 >> iter 90000, loss: 0.041925
   Number of active neurons: 2
 >> iter 91000, loss: 0.039027
 >> iter 92000, loss: 0.056382
 >> iter 93000, loss: 0.042452
 >> iter 94000, loss: 0.042706
 >> iter 95000, loss: 0.041803
 >> iter 96000, loss: 0.038097
 >> iter 97000, loss: 0.042783
 >> iter 98000, loss: 0.039865
 >> iter 99000, loss: 0.036777
 >> iter 100000, loss: 0.035615
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455180
   Number of active neurons: 0
 >> iter 1000, loss: 11.381379
 >> iter 2000, loss: 4.512104
 >> iter 3000, loss: 1.796455
 >> iter 4000, loss: 0.749574
 >> iter 5000, loss: 0.337264
 >> iter 6000, loss: 0.178859
 >> iter 7000, loss: 0.109075
 >> iter 8000, loss: 0.093103
 >> iter 9000, loss: 0.084213
 >> iter 10000, loss: 0.107560
   Number of active neurons: 8
 >> iter 11000, loss: 0.081529
 >> iter 12000, loss: 0.063891
 >> iter 13000, loss: 0.070207
 >> iter 14000, loss: 0.053492
 >> iter 15000, loss: 0.064617
 >> iter 16000, loss: 0.057546
 >> iter 17000, loss: 0.077374
 >> iter 18000, loss: 0.087000
 >> iter 19000, loss: 0.066971
 >> iter 20000, loss: 0.054764
   Number of active neurons: 7
 >> iter 21000, loss: 0.071476
 >> iter 22000, loss: 0.079945
 >> iter 23000, loss: 0.068858
 >> iter 24000, loss: 0.052284
 >> iter 25000, loss: 0.051809
 >> iter 26000, loss: 0.046951
 >> iter 27000, loss: 0.075133
 >> iter 28000, loss: 0.053083
 >> iter 29000, loss: 0.044438
 >> iter 30000, loss: 0.045780
   Number of active neurons: 6
 >> iter 31000, loss: 0.062203
 >> iter 32000, loss: 0.046758
 >> iter 33000, loss: 0.058582
 >> iter 34000, loss: 0.046030
 >> iter 35000, loss: 0.041214
 >> iter 36000, loss: 0.038207
 >> iter 37000, loss: 0.036232
 >> iter 38000, loss: 0.029022
 >> iter 39000, loss: 0.035588
 >> iter 40000, loss: 0.052270
   Number of active neurons: 6
 >> iter 41000, loss: 0.045831
 >> iter 42000, loss: 0.043755
 >> iter 43000, loss: 0.037942
 >> iter 44000, loss: 0.058187
 >> iter 45000, loss: 0.057015
 >> iter 46000, loss: 0.060482
 >> iter 47000, loss: 0.050896
 >> iter 48000, loss: 0.050628
 >> iter 49000, loss: 0.043212
 >> iter 50000, loss: 0.053003
   Number of active neurons: 4
 >> iter 51000, loss: 0.050691
 >> iter 52000, loss: 0.063482
 >> iter 53000, loss: 0.060668
 >> iter 54000, loss: 0.056604
 >> iter 55000, loss: 0.053914
 >> iter 56000, loss: 0.053760
 >> iter 57000, loss: 0.059042
 >> iter 58000, loss: 0.046407
 >> iter 59000, loss: 0.050793
 >> iter 60000, loss: 0.043014
   Number of active neurons: 3
 >> iter 61000, loss: 0.046747
 >> iter 62000, loss: 0.049928
 >> iter 63000, loss: 0.067563
 >> iter 64000, loss: 0.062340
 >> iter 65000, loss: 0.049627
 >> iter 66000, loss: 0.059424
 >> iter 67000, loss: 0.055219
 >> iter 68000, loss: 0.057780
 >> iter 69000, loss: 0.042050
 >> iter 70000, loss: 0.044170
   Number of active neurons: 3
 >> iter 71000, loss: 0.057557
 >> iter 72000, loss: 0.052733
 >> iter 73000, loss: 0.061105
 >> iter 74000, loss: 0.051940
 >> iter 75000, loss: 0.045776
 >> iter 76000, loss: 0.045481
 >> iter 77000, loss: 0.037406
 >> iter 78000, loss: 0.027438
 >> iter 79000, loss: 0.048942
 >> iter 80000, loss: 0.046068
   Number of active neurons: 2
 >> iter 81000, loss: 0.034124
 >> iter 82000, loss: 0.045671
 >> iter 83000, loss: 0.052594
 >> iter 84000, loss: 0.046849
 >> iter 85000, loss: 0.037642
 >> iter 86000, loss: 0.045148
 >> iter 87000, loss: 0.044266
 >> iter 88000, loss: 0.032199
 >> iter 89000, loss: 0.037821
 >> iter 90000, loss: 0.034542
   Number of active neurons: 2
 >> iter 91000, loss: 0.029358
 >> iter 92000, loss: 0.045306
 >> iter 93000, loss: 0.033565
 >> iter 94000, loss: 0.031666
 >> iter 95000, loss: 0.039740
 >> iter 96000, loss: 0.034597
 >> iter 97000, loss: 0.036895
 >> iter 98000, loss: 0.031936
 >> iter 99000, loss: 0.037759
 >> iter 100000, loss: 0.054568
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.334507
 >> iter 2000, loss: 4.458643
 >> iter 3000, loss: 1.766729
 >> iter 4000, loss: 0.730017
 >> iter 5000, loss: 0.343797
 >> iter 6000, loss: 0.186928
 >> iter 7000, loss: 0.126102
 >> iter 8000, loss: 0.119319
 >> iter 9000, loss: 0.086973
 >> iter 10000, loss: 0.078093
   Number of active neurons: 9
 >> iter 11000, loss: 0.065722
 >> iter 12000, loss: 0.066730
 >> iter 13000, loss: 0.078089
 >> iter 14000, loss: 0.070369
 >> iter 15000, loss: 0.063357
 >> iter 16000, loss: 0.066976
 >> iter 17000, loss: 0.084121
 >> iter 18000, loss: 0.068708
 >> iter 19000, loss: 0.071266
 >> iter 20000, loss: 0.057104
   Number of active neurons: 7
 >> iter 21000, loss: 0.081447
 >> iter 22000, loss: 0.078478
 >> iter 23000, loss: 0.063155
 >> iter 24000, loss: 0.045084
 >> iter 25000, loss: 0.049789
 >> iter 26000, loss: 0.049149
 >> iter 27000, loss: 0.065038
 >> iter 28000, loss: 0.058403
 >> iter 29000, loss: 0.055685
 >> iter 30000, loss: 0.051571
   Number of active neurons: 6
 >> iter 31000, loss: 0.040013
 >> iter 32000, loss: 0.048458
 >> iter 33000, loss: 0.064385
 >> iter 34000, loss: 0.064129
 >> iter 35000, loss: 0.054085
 >> iter 36000, loss: 0.056899
 >> iter 37000, loss: 0.064345
 >> iter 38000, loss: 0.045010
 >> iter 39000, loss: 0.047849
 >> iter 40000, loss: 0.076769
   Number of active neurons: 5
 >> iter 41000, loss: 0.057932
 >> iter 42000, loss: 0.052246
 >> iter 43000, loss: 0.040535
 >> iter 44000, loss: 0.060352
 >> iter 45000, loss: 0.095004
 >> iter 46000, loss: 0.054657
 >> iter 47000, loss: 0.051115
 >> iter 48000, loss: 0.046017
 >> iter 49000, loss: 0.042739
 >> iter 50000, loss: 0.046690
   Number of active neurons: 5
 >> iter 51000, loss: 0.042391
 >> iter 52000, loss: 0.037174
 >> iter 53000, loss: 0.047918
 >> iter 54000, loss: 0.042208
 >> iter 55000, loss: 0.064577
 >> iter 56000, loss: 0.053591
 >> iter 57000, loss: 0.049174
 >> iter 58000, loss: 0.062254
 >> iter 59000, loss: 0.057161
 >> iter 60000, loss: 0.046644
   Number of active neurons: 5
 >> iter 61000, loss: 0.051817
 >> iter 62000, loss: 0.066354
 >> iter 63000, loss: 0.048650
 >> iter 64000, loss: 0.052319
 >> iter 65000, loss: 0.065224
 >> iter 66000, loss: 0.053848
 >> iter 67000, loss: 0.058963
 >> iter 68000, loss: 0.058708
 >> iter 69000, loss: 0.053586
 >> iter 70000, loss: 0.065790
   Number of active neurons: 3
 >> iter 71000, loss: 0.051028
 >> iter 72000, loss: 0.056499
 >> iter 73000, loss: 0.059069
 >> iter 74000, loss: 0.050789
 >> iter 75000, loss: 0.057271
 >> iter 76000, loss: 0.050788
 >> iter 77000, loss: 0.051573
 >> iter 78000, loss: 0.045514
 >> iter 79000, loss: 0.041915
 >> iter 80000, loss: 0.039380
   Number of active neurons: 3
 >> iter 81000, loss: 0.043760
 >> iter 82000, loss: 0.040853
 >> iter 83000, loss: 0.037576
 >> iter 84000, loss: 0.058470
 >> iter 85000, loss: 0.038978
 >> iter 86000, loss: 0.055498
 >> iter 87000, loss: 0.044428
 >> iter 88000, loss: 0.033738
 >> iter 89000, loss: 0.040135
 >> iter 90000, loss: 0.035184
   Number of active neurons: 3
 >> iter 91000, loss: 0.040285
 >> iter 92000, loss: 0.054533
 >> iter 93000, loss: 0.057190
 >> iter 94000, loss: 0.050327
 >> iter 95000, loss: 0.057989
 >> iter 96000, loss: 0.047725
 >> iter 97000, loss: 0.040811
 >> iter 98000, loss: 0.060162
 >> iter 99000, loss: 0.045427
 >> iter 100000, loss: 0.063238
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.342877
 >> iter 2000, loss: 4.470386
 >> iter 3000, loss: 1.816993
 >> iter 4000, loss: 0.747837
 >> iter 5000, loss: 0.365311
 >> iter 6000, loss: 0.175164
 >> iter 7000, loss: 0.136657
 >> iter 8000, loss: 0.122999
 >> iter 9000, loss: 0.113169
 >> iter 10000, loss: 0.081979
   Number of active neurons: 10
 >> iter 11000, loss: 0.069959
 >> iter 12000, loss: 0.094264
 >> iter 13000, loss: 0.086286
 >> iter 14000, loss: 0.093209
 >> iter 15000, loss: 0.087951
 >> iter 16000, loss: 0.078059
 >> iter 17000, loss: 0.072647
 >> iter 18000, loss: 0.084798
 >> iter 19000, loss: 0.095301
 >> iter 20000, loss: 0.068055
   Number of active neurons: 8
 >> iter 21000, loss: 0.098122
 >> iter 22000, loss: 0.072735
 >> iter 23000, loss: 0.074857
 >> iter 24000, loss: 0.064607
 >> iter 25000, loss: 0.073766
 >> iter 26000, loss: 0.058227
 >> iter 27000, loss: 0.075958
 >> iter 28000, loss: 0.066315
 >> iter 29000, loss: 0.063611
 >> iter 30000, loss: 0.056174
   Number of active neurons: 8
 >> iter 31000, loss: 0.058314
 >> iter 32000, loss: 0.057305
 >> iter 33000, loss: 0.051193
 >> iter 34000, loss: 0.048626
 >> iter 35000, loss: 0.050735
 >> iter 36000, loss: 0.046441
 >> iter 37000, loss: 0.061132
 >> iter 38000, loss: 0.050377
 >> iter 39000, loss: 0.059325
 >> iter 40000, loss: 0.079726
   Number of active neurons: 5
 >> iter 41000, loss: 0.075026
 >> iter 42000, loss: 0.063719
 >> iter 43000, loss: 0.059409
 >> iter 44000, loss: 0.056426
 >> iter 45000, loss: 0.041246
 >> iter 46000, loss: 0.042723
 >> iter 47000, loss: 0.043294
 >> iter 48000, loss: 0.049448
 >> iter 49000, loss: 0.047339
 >> iter 50000, loss: 0.045271
   Number of active neurons: 4
 >> iter 51000, loss: 0.043259
 >> iter 52000, loss: 0.048510
 >> iter 53000, loss: 0.047845
 >> iter 54000, loss: 0.046776
 >> iter 55000, loss: 0.041184
 >> iter 56000, loss: 0.054787
 >> iter 57000, loss: 0.043560
 >> iter 58000, loss: 0.044106
 >> iter 59000, loss: 0.058736
 >> iter 60000, loss: 0.065297
   Number of active neurons: 4
 >> iter 61000, loss: 0.077156
 >> iter 62000, loss: 0.052008
 >> iter 63000, loss: 0.056596
 >> iter 64000, loss: 0.044732
 >> iter 65000, loss: 0.057548
 >> iter 66000, loss: 0.055520
 >> iter 67000, loss: 0.040302
 >> iter 68000, loss: 0.042042
 >> iter 69000, loss: 0.042311
 >> iter 70000, loss: 0.038614
   Number of active neurons: 3
 >> iter 71000, loss: 0.052739
 >> iter 72000, loss: 0.062139
 >> iter 73000, loss: 0.065897
 >> iter 74000, loss: 0.050299
 >> iter 75000, loss: 0.044208
 >> iter 76000, loss: 0.054835
 >> iter 77000, loss: 0.083904
 >> iter 78000, loss: 0.060468
 >> iter 79000, loss: 0.038919
 >> iter 80000, loss: 0.032546
   Number of active neurons: 3
 >> iter 81000, loss: 0.042938
 >> iter 82000, loss: 0.033878
 >> iter 83000, loss: 0.031581
 >> iter 84000, loss: 0.038411
 >> iter 85000, loss: 0.044528
 >> iter 86000, loss: 0.053341
 >> iter 87000, loss: 0.061401
 >> iter 88000, loss: 0.045214
 >> iter 89000, loss: 0.040543
 >> iter 90000, loss: 0.046577
   Number of active neurons: 3
 >> iter 91000, loss: 0.054338
 >> iter 92000, loss: 0.041714
 >> iter 93000, loss: 0.036862
 >> iter 94000, loss: 0.033865
 >> iter 95000, loss: 0.038189
 >> iter 96000, loss: 0.040964
 >> iter 97000, loss: 0.039232
 >> iter 98000, loss: 0.039717
 >> iter 99000, loss: 0.041091
 >> iter 100000, loss: 0.043577
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.394266
 >> iter 2000, loss: 4.441796
 >> iter 3000, loss: 1.774617
 >> iter 4000, loss: 0.728799
 >> iter 5000, loss: 0.319403
 >> iter 6000, loss: 0.165570
 >> iter 7000, loss: 0.129851
 >> iter 8000, loss: 0.079411
 >> iter 9000, loss: 0.081949
 >> iter 10000, loss: 0.086050
   Number of active neurons: 7
 >> iter 11000, loss: 0.080171
 >> iter 12000, loss: 0.083661
 >> iter 13000, loss: 0.079297
 >> iter 14000, loss: 0.068868
 >> iter 15000, loss: 0.090148
 >> iter 16000, loss: 0.057960
 >> iter 17000, loss: 0.056769
 >> iter 18000, loss: 0.068396
 >> iter 19000, loss: 0.073084
 >> iter 20000, loss: 0.069510
   Number of active neurons: 7
 >> iter 21000, loss: 0.056685
 >> iter 22000, loss: 0.045964
 >> iter 23000, loss: 0.059527
 >> iter 24000, loss: 0.059245
 >> iter 25000, loss: 0.068306
 >> iter 26000, loss: 0.055604
 >> iter 27000, loss: 0.050313
 >> iter 28000, loss: 0.056579
 >> iter 29000, loss: 0.058851
 >> iter 30000, loss: 0.046018
   Number of active neurons: 6
 >> iter 31000, loss: 0.041165
 >> iter 32000, loss: 0.054241
 >> iter 33000, loss: 0.052968
 >> iter 34000, loss: 0.045400
 >> iter 35000, loss: 0.041860
 >> iter 36000, loss: 0.049036
 >> iter 37000, loss: 0.053700
 >> iter 38000, loss: 0.054090
 >> iter 39000, loss: 0.050921
 >> iter 40000, loss: 0.042371
   Number of active neurons: 5
 >> iter 41000, loss: 0.061489
 >> iter 42000, loss: 0.059265
 >> iter 43000, loss: 0.049070
 >> iter 44000, loss: 0.049403
 >> iter 45000, loss: 0.044415
 >> iter 46000, loss: 0.042076
 >> iter 47000, loss: 0.062677
 >> iter 48000, loss: 0.050848
 >> iter 49000, loss: 0.046968
 >> iter 50000, loss: 0.039098
   Number of active neurons: 5
 >> iter 51000, loss: 0.046223
 >> iter 52000, loss: 0.055199
 >> iter 53000, loss: 0.060728
 >> iter 54000, loss: 0.061920
 >> iter 55000, loss: 0.052889
 >> iter 56000, loss: 0.048075
 >> iter 57000, loss: 0.043614
 >> iter 58000, loss: 0.046796
 >> iter 59000, loss: 0.052629
 >> iter 60000, loss: 0.041642
   Number of active neurons: 3
 >> iter 61000, loss: 0.038495
 >> iter 62000, loss: 0.034876
 >> iter 63000, loss: 0.043966
 >> iter 64000, loss: 0.038858
 >> iter 65000, loss: 0.054921
 >> iter 66000, loss: 0.039452
 >> iter 67000, loss: 0.036000
 >> iter 68000, loss: 0.046551
 >> iter 69000, loss: 0.042144
 >> iter 70000, loss: 0.044378
   Number of active neurons: 3
 >> iter 71000, loss: 0.032342
 >> iter 72000, loss: 0.042291
 >> iter 73000, loss: 0.044825
 >> iter 74000, loss: 0.036200
 >> iter 75000, loss: 0.058462
 >> iter 76000, loss: 0.044969
 >> iter 77000, loss: 0.038740
 >> iter 78000, loss: 0.058375
 >> iter 79000, loss: 0.046639
 >> iter 80000, loss: 0.042106
   Number of active neurons: 3
 >> iter 81000, loss: 0.038517
 >> iter 82000, loss: 0.053420
 >> iter 83000, loss: 0.085499
 >> iter 84000, loss: 0.050412
 >> iter 85000, loss: 0.052771
 >> iter 86000, loss: 0.046185
 >> iter 87000, loss: 0.034637
 >> iter 88000, loss: 0.042919
 >> iter 89000, loss: 0.048250
 >> iter 90000, loss: 0.049146
   Number of active neurons: 3
 >> iter 91000, loss: 0.046479
 >> iter 92000, loss: 0.039694
 >> iter 93000, loss: 0.051992
 >> iter 94000, loss: 0.048961
 >> iter 95000, loss: 0.053614
 >> iter 96000, loss: 0.061962
 >> iter 97000, loss: 0.094362
 >> iter 98000, loss: 0.074253
 >> iter 99000, loss: 0.045131
 >> iter 100000, loss: 0.047674
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455181
   Number of active neurons: 0
 >> iter 1000, loss: 11.298728
 >> iter 2000, loss: 4.435360
 >> iter 3000, loss: 1.780060
 >> iter 4000, loss: 0.760037
 >> iter 5000, loss: 0.361215
 >> iter 6000, loss: 0.215516
 >> iter 7000, loss: 0.134419
 >> iter 8000, loss: 0.093413
 >> iter 9000, loss: 0.101691
 >> iter 10000, loss: 0.079864
   Number of active neurons: 8
 >> iter 11000, loss: 0.073675
 >> iter 12000, loss: 0.083168
 >> iter 13000, loss: 0.072971
 >> iter 14000, loss: 0.089203
 >> iter 15000, loss: 0.083091
 >> iter 16000, loss: 0.082368
 >> iter 17000, loss: 0.125031
 >> iter 18000, loss: 0.085649
 >> iter 19000, loss: 0.076445
 >> iter 20000, loss: 0.076162
   Number of active neurons: 7
 >> iter 21000, loss: 0.068989
 >> iter 22000, loss: 0.059762
 >> iter 23000, loss: 0.079002
 >> iter 24000, loss: 0.064682
 >> iter 25000, loss: 0.047190
 >> iter 26000, loss: 0.049302
 >> iter 27000, loss: 0.042279
 >> iter 28000, loss: 0.039467
 >> iter 29000, loss: 0.063692
 >> iter 30000, loss: 0.052778
   Number of active neurons: 6
 >> iter 31000, loss: 0.059531
 >> iter 32000, loss: 0.038526
 >> iter 33000, loss: 0.052044
 >> iter 34000, loss: 0.043952
 >> iter 35000, loss: 0.057174
 >> iter 36000, loss: 0.040180
 >> iter 37000, loss: 0.042037
 >> iter 38000, loss: 0.047605
 >> iter 39000, loss: 0.060919
 >> iter 40000, loss: 0.057166
   Number of active neurons: 6
 >> iter 41000, loss: 0.046866
 >> iter 42000, loss: 0.046545
 >> iter 43000, loss: 0.052168
 >> iter 44000, loss: 0.064883
 >> iter 45000, loss: 0.062222
 >> iter 46000, loss: 0.056002
 >> iter 47000, loss: 0.049499
 >> iter 48000, loss: 0.044653
 >> iter 49000, loss: 0.069572
 >> iter 50000, loss: 0.048794
   Number of active neurons: 5
 >> iter 51000, loss: 0.059295
 >> iter 52000, loss: 0.057632
 >> iter 53000, loss: 0.044372
 >> iter 54000, loss: 0.068415
 >> iter 55000, loss: 0.060389
 >> iter 56000, loss: 0.043667
 >> iter 57000, loss: 0.045101
 >> iter 58000, loss: 0.047689
 >> iter 59000, loss: 0.041476
 >> iter 60000, loss: 0.046934
   Number of active neurons: 4
 >> iter 61000, loss: 0.053127
 >> iter 62000, loss: 0.052462
 >> iter 63000, loss: 0.045785
 >> iter 64000, loss: 0.036339
 >> iter 65000, loss: 0.042525
 >> iter 66000, loss: 0.035676
 >> iter 67000, loss: 0.043705
 >> iter 68000, loss: 0.056994
 >> iter 69000, loss: 0.067857
 >> iter 70000, loss: 0.055439
   Number of active neurons: 4
 >> iter 71000, loss: 0.056121
 >> iter 72000, loss: 0.055005
 >> iter 73000, loss: 0.045330
 >> iter 74000, loss: 0.042586
 >> iter 75000, loss: 0.042004
 >> iter 76000, loss: 0.046099
 >> iter 77000, loss: 0.039013
 >> iter 78000, loss: 0.042903
 >> iter 79000, loss: 0.040949
 >> iter 80000, loss: 0.046985
   Number of active neurons: 3
 >> iter 81000, loss: 0.058559
 >> iter 82000, loss: 0.044950
 >> iter 83000, loss: 0.049296
 >> iter 84000, loss: 0.037374
 >> iter 85000, loss: 0.060906
 >> iter 86000, loss: 0.046674
 >> iter 87000, loss: 0.068402
 >> iter 88000, loss: 0.049352
 >> iter 89000, loss: 0.047241
 >> iter 90000, loss: 0.061250
   Number of active neurons: 3
 >> iter 91000, loss: 0.048474
 >> iter 92000, loss: 0.044597
 >> iter 93000, loss: 0.051259
 >> iter 94000, loss: 0.060820
 >> iter 95000, loss: 0.044388
 >> iter 96000, loss: 0.061951
 >> iter 97000, loss: 0.052289
 >> iter 98000, loss: 0.050104
 >> iter 99000, loss: 0.059461
 >> iter 100000, loss: 0.051025
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.335857
 >> iter 2000, loss: 4.433614
 >> iter 3000, loss: 1.784771
 >> iter 4000, loss: 0.713223
 >> iter 5000, loss: 0.334073
 >> iter 6000, loss: 0.186733
 >> iter 7000, loss: 0.112685
 >> iter 8000, loss: 0.088012
 >> iter 9000, loss: 0.063474
 >> iter 10000, loss: 0.076484
   Number of active neurons: 7
 >> iter 11000, loss: 0.092539
 >> iter 12000, loss: 0.071559
 >> iter 13000, loss: 0.066760
 >> iter 14000, loss: 0.070170
 >> iter 15000, loss: 0.081972
 >> iter 16000, loss: 0.072772
 >> iter 17000, loss: 0.074098
 >> iter 18000, loss: 0.051721
 >> iter 19000, loss: 0.059101
 >> iter 20000, loss: 0.052328
   Number of active neurons: 7
 >> iter 21000, loss: 0.075717
 >> iter 22000, loss: 0.075764
 >> iter 23000, loss: 0.072609
 >> iter 24000, loss: 0.062102
 >> iter 25000, loss: 0.065009
 >> iter 26000, loss: 0.063438
 >> iter 27000, loss: 0.059182
 >> iter 28000, loss: 0.055885
 >> iter 29000, loss: 0.060064
 >> iter 30000, loss: 0.080627
   Number of active neurons: 5
 >> iter 31000, loss: 0.064628
 >> iter 32000, loss: 0.056583
 >> iter 33000, loss: 0.049265
 >> iter 34000, loss: 0.047075
 >> iter 35000, loss: 0.040802
 >> iter 36000, loss: 0.053348
 >> iter 37000, loss: 0.063747
 >> iter 38000, loss: 0.057231
 >> iter 39000, loss: 0.072923
 >> iter 40000, loss: 0.062059
   Number of active neurons: 5
 >> iter 41000, loss: 0.042006
 >> iter 42000, loss: 0.040011
 >> iter 43000, loss: 0.037046
 >> iter 44000, loss: 0.063937
 >> iter 45000, loss: 0.053919
 >> iter 46000, loss: 0.043414
 >> iter 47000, loss: 0.041711
 >> iter 48000, loss: 0.058362
 >> iter 49000, loss: 0.056165
 >> iter 50000, loss: 0.035660
   Number of active neurons: 4
 >> iter 51000, loss: 0.044186
 >> iter 52000, loss: 0.049891
 >> iter 53000, loss: 0.047327
 >> iter 54000, loss: 0.052948
 >> iter 55000, loss: 0.049991
 >> iter 56000, loss: 0.059677
 >> iter 57000, loss: 0.057644
 >> iter 58000, loss: 0.049018
 >> iter 59000, loss: 0.047826
 >> iter 60000, loss: 0.058201
   Number of active neurons: 3
 >> iter 61000, loss: 0.043078
 >> iter 62000, loss: 0.032700
 >> iter 63000, loss: 0.039056
 >> iter 64000, loss: 0.077690
 >> iter 65000, loss: 0.063333
 >> iter 66000, loss: 0.068368
 >> iter 67000, loss: 0.052273
 >> iter 68000, loss: 0.049653
 >> iter 69000, loss: 0.051262
 >> iter 70000, loss: 0.042396
   Number of active neurons: 3
 >> iter 71000, loss: 0.032673
 >> iter 72000, loss: 0.027734
 >> iter 73000, loss: 0.036634
 >> iter 74000, loss: 0.036343
 >> iter 75000, loss: 0.041313
 >> iter 76000, loss: 0.043126
 >> iter 77000, loss: 0.047831
 >> iter 78000, loss: 0.037567
 >> iter 79000, loss: 0.036397
 >> iter 80000, loss: 0.044148
   Number of active neurons: 3
 >> iter 81000, loss: 0.043532
 >> iter 82000, loss: 0.044159
 >> iter 83000, loss: 0.043290
 >> iter 84000, loss: 0.035680
 >> iter 85000, loss: 0.055545
 >> iter 86000, loss: 0.049305
 >> iter 87000, loss: 0.048076
 >> iter 88000, loss: 0.044414
 >> iter 89000, loss: 0.044358
 >> iter 90000, loss: 0.057940
   Number of active neurons: 3
 >> iter 91000, loss: 0.067652
 >> iter 92000, loss: 0.046286
 >> iter 93000, loss: 0.045076
 >> iter 94000, loss: 0.040458
 >> iter 95000, loss: 0.050479
 >> iter 96000, loss: 0.052179
 >> iter 97000, loss: 0.043511
 >> iter 98000, loss: 0.064214
 >> iter 99000, loss: 0.051913
 >> iter 100000, loss: 0.062243
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 11.291911
 >> iter 2000, loss: 4.429570
 >> iter 3000, loss: 1.742634
 >> iter 4000, loss: 0.731358
 >> iter 5000, loss: 0.355385
 >> iter 6000, loss: 0.197086
 >> iter 7000, loss: 0.126453
 >> iter 8000, loss: 0.092968
 >> iter 9000, loss: 0.085616
 >> iter 10000, loss: 0.081627
   Number of active neurons: 8
 >> iter 11000, loss: 0.063015
 >> iter 12000, loss: 0.061740
 >> iter 13000, loss: 0.069570
 >> iter 14000, loss: 0.066232
 >> iter 15000, loss: 0.065043
 >> iter 16000, loss: 0.063901
 >> iter 17000, loss: 0.059202
 >> iter 18000, loss: 0.060986
 >> iter 19000, loss: 0.054548
 >> iter 20000, loss: 0.055957
   Number of active neurons: 6
 >> iter 21000, loss: 0.049227
 >> iter 22000, loss: 0.048419
 >> iter 23000, loss: 0.050629
 >> iter 24000, loss: 0.051650
 >> iter 25000, loss: 0.046900
 >> iter 26000, loss: 0.052238
 >> iter 27000, loss: 0.068272
 >> iter 28000, loss: 0.043107
 >> iter 29000, loss: 0.057815
 >> iter 30000, loss: 0.075758
   Number of active neurons: 5
 >> iter 31000, loss: 0.065362
 >> iter 32000, loss: 0.079379
 >> iter 33000, loss: 0.052529
 >> iter 34000, loss: 0.044668
 >> iter 35000, loss: 0.056377
 >> iter 36000, loss: 0.057856
 >> iter 37000, loss: 0.044934
 >> iter 38000, loss: 0.033892
 >> iter 39000, loss: 0.045293
 >> iter 40000, loss: 0.044952
   Number of active neurons: 4
 >> iter 41000, loss: 0.042575
 >> iter 42000, loss: 0.063987
 >> iter 43000, loss: 0.044821
 >> iter 44000, loss: 0.055139
 >> iter 45000, loss: 0.048425
 >> iter 46000, loss: 0.035544
 >> iter 47000, loss: 0.032515
 >> iter 48000, loss: 0.030960
 >> iter 49000, loss: 0.037958
 >> iter 50000, loss: 0.049193
   Number of active neurons: 4
 >> iter 51000, loss: 0.037234
 >> iter 52000, loss: 0.046641
 >> iter 53000, loss: 0.051679
 >> iter 54000, loss: 0.042406
 >> iter 55000, loss: 0.058667
 >> iter 56000, loss: 0.043106
 >> iter 57000, loss: 0.043730
 >> iter 58000, loss: 0.045319
 >> iter 59000, loss: 0.043200
 >> iter 60000, loss: 0.044360
   Number of active neurons: 4
 >> iter 61000, loss: 0.033637
 >> iter 62000, loss: 0.034107
 >> iter 63000, loss: 0.063740
 >> iter 64000, loss: 0.058633
 >> iter 65000, loss: 0.043142
 >> iter 66000, loss: 0.049084
 >> iter 67000, loss: 0.049185
 >> iter 68000, loss: 0.050401
 >> iter 69000, loss: 0.064245
 >> iter 70000, loss: 0.077965
   Number of active neurons: 4
 >> iter 71000, loss: 0.059933
 >> iter 72000, loss: 0.040425
 >> iter 73000, loss: 0.039560
 >> iter 74000, loss: 0.045076
 >> iter 75000, loss: 0.036247
 >> iter 76000, loss: 0.031913
 >> iter 77000, loss: 0.042963
 >> iter 78000, loss: 0.041677
 >> iter 79000, loss: 0.054577
 >> iter 80000, loss: 0.037097
   Number of active neurons: 2
 >> iter 81000, loss: 0.030550
 >> iter 82000, loss: 0.033243
 >> iter 83000, loss: 0.034686
 >> iter 84000, loss: 0.037324
 >> iter 85000, loss: 0.035567
 >> iter 86000, loss: 0.031801
 >> iter 87000, loss: 0.045360
 >> iter 88000, loss: 0.045061
 >> iter 89000, loss: 0.037693
 >> iter 90000, loss: 0.030008
   Number of active neurons: 2
 >> iter 91000, loss: 0.027466
 >> iter 92000, loss: 0.046610
 >> iter 93000, loss: 0.045624
 >> iter 94000, loss: 0.052441
 >> iter 95000, loss: 0.037967
 >> iter 96000, loss: 0.042643
 >> iter 97000, loss: 0.035835
 >> iter 98000, loss: 0.056119
 >> iter 99000, loss: 0.051288
 >> iter 100000, loss: 0.053919
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.291754
 >> iter 2000, loss: 4.361061
 >> iter 3000, loss: 1.713308
 >> iter 4000, loss: 0.689575
 >> iter 5000, loss: 0.323806
 >> iter 6000, loss: 0.154560
 >> iter 7000, loss: 0.106982
 >> iter 8000, loss: 0.103712
 >> iter 9000, loss: 0.097747
 >> iter 10000, loss: 0.077742
   Number of active neurons: 7
 >> iter 11000, loss: 0.080180
 >> iter 12000, loss: 0.073387
 >> iter 13000, loss: 0.064053
 >> iter 14000, loss: 0.070691
 >> iter 15000, loss: 0.081645
 >> iter 16000, loss: 0.075037
 >> iter 17000, loss: 0.088073
 >> iter 18000, loss: 0.067050
 >> iter 19000, loss: 0.050634
 >> iter 20000, loss: 0.047953
   Number of active neurons: 6
 >> iter 21000, loss: 0.051122
 >> iter 22000, loss: 0.051873
 >> iter 23000, loss: 0.041866
 >> iter 24000, loss: 0.063447
 >> iter 25000, loss: 0.060436
 >> iter 26000, loss: 0.061164
 >> iter 27000, loss: 0.049609
 >> iter 28000, loss: 0.053640
 >> iter 29000, loss: 0.059381
 >> iter 30000, loss: 0.061930
   Number of active neurons: 6
 >> iter 31000, loss: 0.075878
 >> iter 32000, loss: 0.063165
 >> iter 33000, loss: 0.046648
 >> iter 34000, loss: 0.040124
 >> iter 35000, loss: 0.051958
 >> iter 36000, loss: 0.058855
 >> iter 37000, loss: 0.053020
 >> iter 38000, loss: 0.059092
 >> iter 39000, loss: 0.049334
 >> iter 40000, loss: 0.048525
   Number of active neurons: 4
 >> iter 41000, loss: 0.043102
 >> iter 42000, loss: 0.044117
 >> iter 43000, loss: 0.049196
 >> iter 44000, loss: 0.046797
 >> iter 45000, loss: 0.047364
 >> iter 46000, loss: 0.060350
 >> iter 47000, loss: 0.056881
 >> iter 48000, loss: 0.048381
 >> iter 49000, loss: 0.038881
 >> iter 50000, loss: 0.066024
   Number of active neurons: 4
 >> iter 51000, loss: 0.064675
 >> iter 52000, loss: 0.050949
 >> iter 53000, loss: 0.049503
 >> iter 54000, loss: 0.041700
 >> iter 55000, loss: 0.045696
 >> iter 56000, loss: 0.058428
 >> iter 57000, loss: 0.052052
 >> iter 58000, loss: 0.058662
 >> iter 59000, loss: 0.056751
 >> iter 60000, loss: 0.037990
   Number of active neurons: 4
 >> iter 61000, loss: 0.042974
 >> iter 62000, loss: 0.058168
 >> iter 63000, loss: 0.048259
 >> iter 64000, loss: 0.041765
 >> iter 65000, loss: 0.057299
 >> iter 66000, loss: 0.040877
 >> iter 67000, loss: 0.053316
 >> iter 68000, loss: 0.045584
 >> iter 69000, loss: 0.051836
 >> iter 70000, loss: 0.040804
   Number of active neurons: 4
 >> iter 71000, loss: 0.047226
 >> iter 72000, loss: 0.052357
 >> iter 73000, loss: 0.042715
 >> iter 74000, loss: 0.047067
 >> iter 75000, loss: 0.058952
 >> iter 76000, loss: 0.038119
 >> iter 77000, loss: 0.056006
 >> iter 78000, loss: 0.040647
 >> iter 79000, loss: 0.043604
 >> iter 80000, loss: 0.042891
   Number of active neurons: 4
 >> iter 81000, loss: 0.064111
 >> iter 82000, loss: 0.061542
 >> iter 83000, loss: 0.067179
 >> iter 84000, loss: 0.055435
 >> iter 85000, loss: 0.057818
 >> iter 86000, loss: 0.058890
 >> iter 87000, loss: 0.052750
 >> iter 88000, loss: 0.051832
 >> iter 89000, loss: 0.057463
 >> iter 90000, loss: 0.044861
   Number of active neurons: 3
 >> iter 91000, loss: 0.046598
 >> iter 92000, loss: 0.050710
 >> iter 93000, loss: 0.043577
 >> iter 94000, loss: 0.037687
 >> iter 95000, loss: 0.031941
 >> iter 96000, loss: 0.042379
 >> iter 97000, loss: 0.047439
 >> iter 98000, loss: 0.038865
 >> iter 99000, loss: 0.047349
 >> iter 100000, loss: 0.038248
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.274433
 >> iter 2000, loss: 4.393003
 >> iter 3000, loss: 1.756257
 >> iter 4000, loss: 0.724239
 >> iter 5000, loss: 0.338869
 >> iter 6000, loss: 0.165710
 >> iter 7000, loss: 0.134091
 >> iter 8000, loss: 0.110936
 >> iter 9000, loss: 0.092763
 >> iter 10000, loss: 0.073249
   Number of active neurons: 8
 >> iter 11000, loss: 0.069098
 >> iter 12000, loss: 0.072439
 >> iter 13000, loss: 0.084944
 >> iter 14000, loss: 0.065096
 >> iter 15000, loss: 0.080593
 >> iter 16000, loss: 0.067864
 >> iter 17000, loss: 0.079072
 >> iter 18000, loss: 0.086924
 >> iter 19000, loss: 0.064918
 >> iter 20000, loss: 0.059885
   Number of active neurons: 7
 >> iter 21000, loss: 0.054102
 >> iter 22000, loss: 0.056713
 >> iter 23000, loss: 0.058732
 >> iter 24000, loss: 0.062538
 >> iter 25000, loss: 0.078384
 >> iter 26000, loss: 0.052456
 >> iter 27000, loss: 0.059499
 >> iter 28000, loss: 0.051676
 >> iter 29000, loss: 0.049670
 >> iter 30000, loss: 0.046116
   Number of active neurons: 6
 >> iter 31000, loss: 0.046130
 >> iter 32000, loss: 0.055556
 >> iter 33000, loss: 0.051666
 >> iter 34000, loss: 0.040354
 >> iter 35000, loss: 0.071636
 >> iter 36000, loss: 0.061789
 >> iter 37000, loss: 0.055062
 >> iter 38000, loss: 0.054895
 >> iter 39000, loss: 0.059263
 >> iter 40000, loss: 0.077850
   Number of active neurons: 6
 >> iter 41000, loss: 0.079219
 >> iter 42000, loss: 0.059898
 >> iter 43000, loss: 0.051935
 >> iter 44000, loss: 0.049680
 >> iter 45000, loss: 0.054840
 >> iter 46000, loss: 0.069259
 >> iter 47000, loss: 0.073822
 >> iter 48000, loss: 0.050076
 >> iter 49000, loss: 0.043656
 >> iter 50000, loss: 0.042029
   Number of active neurons: 6
 >> iter 51000, loss: 0.051968
 >> iter 52000, loss: 0.052860
 >> iter 53000, loss: 0.049621
 >> iter 54000, loss: 0.061559
 >> iter 55000, loss: 0.069192
 >> iter 56000, loss: 0.051983
 >> iter 57000, loss: 0.038377
 >> iter 58000, loss: 0.048467
 >> iter 59000, loss: 0.041762
 >> iter 60000, loss: 0.046714
   Number of active neurons: 5
 >> iter 61000, loss: 0.044441
 >> iter 62000, loss: 0.041247
 >> iter 63000, loss: 0.045304
 >> iter 64000, loss: 0.053866
 >> iter 65000, loss: 0.041359
 >> iter 66000, loss: 0.050656
 >> iter 67000, loss: 0.042250
 >> iter 68000, loss: 0.056745
 >> iter 69000, loss: 0.047488
 >> iter 70000, loss: 0.046071
   Number of active neurons: 4
 >> iter 71000, loss: 0.077784
 >> iter 72000, loss: 0.050371
 >> iter 73000, loss: 0.040231
 >> iter 74000, loss: 0.051884
 >> iter 75000, loss: 0.049929
 >> iter 76000, loss: 0.038304
 >> iter 77000, loss: 0.053774
 >> iter 78000, loss: 0.056722
 >> iter 79000, loss: 0.059273
 >> iter 80000, loss: 0.044757
   Number of active neurons: 4
 >> iter 81000, loss: 0.050706
 >> iter 82000, loss: 0.058382
 >> iter 83000, loss: 0.049026
 >> iter 84000, loss: 0.067045
 >> iter 85000, loss: 0.058053
 >> iter 86000, loss: 0.043603
 >> iter 87000, loss: 0.051412
 >> iter 88000, loss: 0.048687
 >> iter 89000, loss: 0.036470
 >> iter 90000, loss: 0.062970
   Number of active neurons: 4
 >> iter 91000, loss: 0.079348
 >> iter 92000, loss: 0.065203
 >> iter 93000, loss: 0.069413
 >> iter 94000, loss: 0.046345
 >> iter 95000, loss: 0.051080
 >> iter 96000, loss: 0.061571
 >> iter 97000, loss: 0.046357
 >> iter 98000, loss: 0.047401
 >> iter 99000, loss: 0.040100
 >> iter 100000, loss: 0.058302
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 11.335055
 >> iter 2000, loss: 4.463039
 >> iter 3000, loss: 1.803044
 >> iter 4000, loss: 0.768134
 >> iter 5000, loss: 0.367974
 >> iter 6000, loss: 0.203935
 >> iter 7000, loss: 0.131081
 >> iter 8000, loss: 0.118215
 >> iter 9000, loss: 0.080548
 >> iter 10000, loss: 0.100999
   Number of active neurons: 9
 >> iter 11000, loss: 0.084774
 >> iter 12000, loss: 0.112982
 >> iter 13000, loss: 0.089664
 >> iter 14000, loss: 0.095165
 >> iter 15000, loss: 0.070685
 >> iter 16000, loss: 0.065718
 >> iter 17000, loss: 0.055098
 >> iter 18000, loss: 0.048993
 >> iter 19000, loss: 0.064125
 >> iter 20000, loss: 0.067387
   Number of active neurons: 7
 >> iter 21000, loss: 0.066541
 >> iter 22000, loss: 0.059314
 >> iter 23000, loss: 0.065548
 >> iter 24000, loss: 0.047307
 >> iter 25000, loss: 0.045494
 >> iter 26000, loss: 0.043851
 >> iter 27000, loss: 0.066324
 >> iter 28000, loss: 0.064738
 >> iter 29000, loss: 0.050882
 >> iter 30000, loss: 0.053220
   Number of active neurons: 6
 >> iter 31000, loss: 0.048730
 >> iter 32000, loss: 0.046741
 >> iter 33000, loss: 0.060988
 >> iter 34000, loss: 0.069084
 >> iter 35000, loss: 0.054465
 >> iter 36000, loss: 0.052082
 >> iter 37000, loss: 0.051199
 >> iter 38000, loss: 0.051978
 >> iter 39000, loss: 0.060322
 >> iter 40000, loss: 0.070704
   Number of active neurons: 5
 >> iter 41000, loss: 0.053518
 >> iter 42000, loss: 0.043603
 >> iter 43000, loss: 0.044752
 >> iter 44000, loss: 0.052323
 >> iter 45000, loss: 0.040157
 >> iter 46000, loss: 0.048446
 >> iter 47000, loss: 0.044716
 >> iter 48000, loss: 0.046163
 >> iter 49000, loss: 0.055144
 >> iter 50000, loss: 0.069808
   Number of active neurons: 3
 >> iter 51000, loss: 0.060231
 >> iter 52000, loss: 0.047114
 >> iter 53000, loss: 0.047048
 >> iter 54000, loss: 0.051712
 >> iter 55000, loss: 0.051772
 >> iter 56000, loss: 0.044261
 >> iter 57000, loss: 0.038444
 >> iter 58000, loss: 0.047592
 >> iter 59000, loss: 0.052095
 >> iter 60000, loss: 0.050982
   Number of active neurons: 2
 >> iter 61000, loss: 0.047399
 >> iter 62000, loss: 0.047054
 >> iter 63000, loss: 0.056358
 >> iter 64000, loss: 0.050826
 >> iter 65000, loss: 0.064732
 >> iter 66000, loss: 0.051134
 >> iter 67000, loss: 0.067780
 >> iter 68000, loss: 0.045289
 >> iter 69000, loss: 0.058138
 >> iter 70000, loss: 0.059280
   Number of active neurons: 2
 >> iter 71000, loss: 0.041478
 >> iter 72000, loss: 0.035647
 >> iter 73000, loss: 0.040736
 >> iter 74000, loss: 0.044099
 >> iter 75000, loss: 0.051930
 >> iter 76000, loss: 0.053425
 >> iter 77000, loss: 0.059061
 >> iter 78000, loss: 0.055832
 >> iter 79000, loss: 0.042398
 >> iter 80000, loss: 0.041899
   Number of active neurons: 2
 >> iter 81000, loss: 0.035964
 >> iter 82000, loss: 0.029614
 >> iter 83000, loss: 0.026717
 >> iter 84000, loss: 0.036547
 >> iter 85000, loss: 0.044807
 >> iter 86000, loss: 0.071888
 >> iter 87000, loss: 0.057522
 >> iter 88000, loss: 0.039749
 >> iter 89000, loss: 0.047867
 >> iter 90000, loss: 0.066316
   Number of active neurons: 2
 >> iter 91000, loss: 0.045204
 >> iter 92000, loss: 0.051074
 >> iter 93000, loss: 0.049030
 >> iter 94000, loss: 0.044771
 >> iter 95000, loss: 0.038361
 >> iter 96000, loss: 0.030543
 >> iter 97000, loss: 0.036696
 >> iter 98000, loss: 0.052152
 >> iter 99000, loss: 0.046299
 >> iter 100000, loss: 0.038138
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455180
   Number of active neurons: 0
 >> iter 1000, loss: 11.391540
 >> iter 2000, loss: 4.527930
 >> iter 3000, loss: 1.795719
 >> iter 4000, loss: 0.752688
 >> iter 5000, loss: 0.357756
 >> iter 6000, loss: 0.215980
 >> iter 7000, loss: 0.140777
 >> iter 8000, loss: 0.123744
 >> iter 9000, loss: 0.117393
 >> iter 10000, loss: 0.095555
   Number of active neurons: 10
 >> iter 11000, loss: 0.083131
 >> iter 12000, loss: 0.086941
 >> iter 13000, loss: 0.078109
 >> iter 14000, loss: 0.065537
 >> iter 15000, loss: 0.073879
 >> iter 16000, loss: 0.109705
 >> iter 17000, loss: 0.068580
 >> iter 18000, loss: 0.074040
 >> iter 19000, loss: 0.076032
 >> iter 20000, loss: 0.065493
   Number of active neurons: 8
 >> iter 21000, loss: 0.062669
 >> iter 22000, loss: 0.058587
 >> iter 23000, loss: 0.056891
 >> iter 24000, loss: 0.061327
 >> iter 25000, loss: 0.066728
 >> iter 26000, loss: 0.056819
 >> iter 27000, loss: 0.072449
 >> iter 28000, loss: 0.048340
 >> iter 29000, loss: 0.043463
 >> iter 30000, loss: 0.060794
   Number of active neurons: 7
 >> iter 31000, loss: 0.061048
 >> iter 32000, loss: 0.062813
 >> iter 33000, loss: 0.051758
 >> iter 34000, loss: 0.063533
 >> iter 35000, loss: 0.078685
 >> iter 36000, loss: 0.055169
 >> iter 37000, loss: 0.059051
 >> iter 38000, loss: 0.053569
 >> iter 39000, loss: 0.057715
 >> iter 40000, loss: 0.058526
   Number of active neurons: 6
 >> iter 41000, loss: 0.057317
 >> iter 42000, loss: 0.051281
 >> iter 43000, loss: 0.048891
 >> iter 44000, loss: 0.059858
 >> iter 45000, loss: 0.051024
 >> iter 46000, loss: 0.060607
 >> iter 47000, loss: 0.053260
 >> iter 48000, loss: 0.051282
 >> iter 49000, loss: 0.061605
 >> iter 50000, loss: 0.052746
   Number of active neurons: 4
 >> iter 51000, loss: 0.065553
 >> iter 52000, loss: 0.060392
 >> iter 53000, loss: 0.048038
 >> iter 54000, loss: 0.044451
 >> iter 55000, loss: 0.054153
 >> iter 56000, loss: 0.040575
 >> iter 57000, loss: 0.044707
 >> iter 58000, loss: 0.054858
 >> iter 59000, loss: 0.062341
 >> iter 60000, loss: 0.050009
   Number of active neurons: 3
 >> iter 61000, loss: 0.061998
 >> iter 62000, loss: 0.061362
 >> iter 63000, loss: 0.077060
 >> iter 64000, loss: 0.054146
 >> iter 65000, loss: 0.037577
 >> iter 66000, loss: 0.040316
 >> iter 67000, loss: 0.058696
 >> iter 68000, loss: 0.048342
 >> iter 69000, loss: 0.044847
 >> iter 70000, loss: 0.062515
   Number of active neurons: 3
 >> iter 71000, loss: 0.046463
 >> iter 72000, loss: 0.039353
 >> iter 73000, loss: 0.040338
 >> iter 74000, loss: 0.038825
 >> iter 75000, loss: 0.043893
 >> iter 76000, loss: 0.047143
 >> iter 77000, loss: 0.036051
 >> iter 78000, loss: 0.034961
 >> iter 79000, loss: 0.062360
 >> iter 80000, loss: 0.055946
   Number of active neurons: 3
 >> iter 81000, loss: 0.052713
 >> iter 82000, loss: 0.068259
 >> iter 83000, loss: 0.063170
 >> iter 84000, loss: 0.049164
 >> iter 85000, loss: 0.037034
 >> iter 86000, loss: 0.045986
 >> iter 87000, loss: 0.040647
 >> iter 88000, loss: 0.035686
 >> iter 89000, loss: 0.052148
 >> iter 90000, loss: 0.056278
   Number of active neurons: 2
 >> iter 91000, loss: 0.072797
 >> iter 92000, loss: 0.059112
 >> iter 93000, loss: 0.050567
 >> iter 94000, loss: 0.057879
 >> iter 95000, loss: 0.043534
 >> iter 96000, loss: 0.034677
 >> iter 97000, loss: 0.029493
 >> iter 98000, loss: 0.052463
 >> iter 99000, loss: 0.058714
 >> iter 100000, loss: 0.036733
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.348085
 >> iter 2000, loss: 4.437830
 >> iter 3000, loss: 1.784084
 >> iter 4000, loss: 0.753720
 >> iter 5000, loss: 0.369661
 >> iter 6000, loss: 0.223241
 >> iter 7000, loss: 0.129298
 >> iter 8000, loss: 0.097332
 >> iter 9000, loss: 0.108153
 >> iter 10000, loss: 0.074621
   Number of active neurons: 8
 >> iter 11000, loss: 0.069431
 >> iter 12000, loss: 0.065585
 >> iter 13000, loss: 0.068271
 >> iter 14000, loss: 0.060093
 >> iter 15000, loss: 0.075962
 >> iter 16000, loss: 0.068684
 >> iter 17000, loss: 0.069058
 >> iter 18000, loss: 0.069841
 >> iter 19000, loss: 0.053104
 >> iter 20000, loss: 0.052018
   Number of active neurons: 6
 >> iter 21000, loss: 0.056099
 >> iter 22000, loss: 0.071012
 >> iter 23000, loss: 0.069815
 >> iter 24000, loss: 0.080059
 >> iter 25000, loss: 0.086357
 >> iter 26000, loss: 0.077807
 >> iter 27000, loss: 0.054479
 >> iter 28000, loss: 0.052437
 >> iter 29000, loss: 0.049055
 >> iter 30000, loss: 0.043878
   Number of active neurons: 5
 >> iter 31000, loss: 0.060831
 >> iter 32000, loss: 0.083540
 >> iter 33000, loss: 0.078744
 >> iter 34000, loss: 0.055208
 >> iter 35000, loss: 0.042817
 >> iter 36000, loss: 0.065984
 >> iter 37000, loss: 0.062584
 >> iter 38000, loss: 0.041183
 >> iter 39000, loss: 0.050316
 >> iter 40000, loss: 0.041388
   Number of active neurons: 4
 >> iter 41000, loss: 0.063294
 >> iter 42000, loss: 0.057433
 >> iter 43000, loss: 0.061416
 >> iter 44000, loss: 0.039814
 >> iter 45000, loss: 0.050549
 >> iter 46000, loss: 0.064508
 >> iter 47000, loss: 0.054693
 >> iter 48000, loss: 0.047054
 >> iter 49000, loss: 0.060676
 >> iter 50000, loss: 0.046638
   Number of active neurons: 4
 >> iter 51000, loss: 0.040508
 >> iter 52000, loss: 0.042713
 >> iter 53000, loss: 0.046068
 >> iter 54000, loss: 0.058466
 >> iter 55000, loss: 0.058319
 >> iter 56000, loss: 0.061266
 >> iter 57000, loss: 0.054528
 >> iter 58000, loss: 0.039054
 >> iter 59000, loss: 0.037761
 >> iter 60000, loss: 0.048892
   Number of active neurons: 3
 >> iter 61000, loss: 0.048705
 >> iter 62000, loss: 0.038481
 >> iter 63000, loss: 0.047235
 >> iter 64000, loss: 0.069031
 >> iter 65000, loss: 0.052543
 >> iter 66000, loss: 0.044815
 >> iter 67000, loss: 0.038768
 >> iter 68000, loss: 0.046206
 >> iter 69000, loss: 0.054147
 >> iter 70000, loss: 0.054142
   Number of active neurons: 2
 >> iter 71000, loss: 0.038268
 >> iter 72000, loss: 0.048047
 >> iter 73000, loss: 0.040408
 >> iter 74000, loss: 0.042538
 >> iter 75000, loss: 0.040419
 >> iter 76000, loss: 0.046340
 >> iter 77000, loss: 0.044922
 >> iter 78000, loss: 0.037446
 >> iter 79000, loss: 0.046443
 >> iter 80000, loss: 0.044094
   Number of active neurons: 2
 >> iter 81000, loss: 0.046689
 >> iter 82000, loss: 0.037673
 >> iter 83000, loss: 0.038539
 >> iter 84000, loss: 0.029048
 >> iter 85000, loss: 0.051892
 >> iter 86000, loss: 0.066505
 >> iter 87000, loss: 0.052170
 >> iter 88000, loss: 0.061283
 >> iter 89000, loss: 0.063667
 >> iter 90000, loss: 0.049163
   Number of active neurons: 2
 >> iter 91000, loss: 0.034114
 >> iter 92000, loss: 0.058415
 >> iter 93000, loss: 0.041090
 >> iter 94000, loss: 0.032221
 >> iter 95000, loss: 0.031661
 >> iter 96000, loss: 0.046111
 >> iter 97000, loss: 0.045298
 >> iter 98000, loss: 0.032290
 >> iter 99000, loss: 0.030505
 >> iter 100000, loss: 0.060172
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.390904
 >> iter 2000, loss: 4.429332
 >> iter 3000, loss: 1.752017
 >> iter 4000, loss: 0.759633
 >> iter 5000, loss: 0.358088
 >> iter 6000, loss: 0.186363
 >> iter 7000, loss: 0.139644
 >> iter 8000, loss: 0.096376
 >> iter 9000, loss: 0.131298
 >> iter 10000, loss: 0.108445
   Number of active neurons: 8
 >> iter 11000, loss: 0.091051
 >> iter 12000, loss: 0.064477
 >> iter 13000, loss: 0.084531
 >> iter 14000, loss: 0.070597
 >> iter 15000, loss: 0.055599
 >> iter 16000, loss: 0.067856
 >> iter 17000, loss: 0.091015
 >> iter 18000, loss: 0.063033
 >> iter 19000, loss: 0.048806
 >> iter 20000, loss: 0.046845
   Number of active neurons: 6
 >> iter 21000, loss: 0.051125
 >> iter 22000, loss: 0.047649
 >> iter 23000, loss: 0.059819
 >> iter 24000, loss: 0.056507
 >> iter 25000, loss: 0.058031
 >> iter 26000, loss: 0.066263
 >> iter 27000, loss: 0.057764
 >> iter 28000, loss: 0.061345
 >> iter 29000, loss: 0.061605
 >> iter 30000, loss: 0.074751
   Number of active neurons: 6
 >> iter 31000, loss: 0.050322
 >> iter 32000, loss: 0.057892
 >> iter 33000, loss: 0.058124
 >> iter 34000, loss: 0.052286
 >> iter 35000, loss: 0.045065
 >> iter 36000, loss: 0.083989
 >> iter 37000, loss: 0.055191
 >> iter 38000, loss: 0.042381
 >> iter 39000, loss: 0.055582
 >> iter 40000, loss: 0.058247
   Number of active neurons: 6
 >> iter 41000, loss: 0.064100
 >> iter 42000, loss: 0.045181
 >> iter 43000, loss: 0.062062
 >> iter 44000, loss: 0.051970
 >> iter 45000, loss: 0.042047
 >> iter 46000, loss: 0.059751
 >> iter 47000, loss: 0.050180
 >> iter 48000, loss: 0.053929
 >> iter 49000, loss: 0.059172
 >> iter 50000, loss: 0.050173
   Number of active neurons: 5
 >> iter 51000, loss: 0.062480
 >> iter 52000, loss: 0.052620
 >> iter 53000, loss: 0.051969
 >> iter 54000, loss: 0.057769
 >> iter 55000, loss: 0.066848
 >> iter 56000, loss: 0.054373
 >> iter 57000, loss: 0.037042
 >> iter 58000, loss: 0.044393
 >> iter 59000, loss: 0.053294
 >> iter 60000, loss: 0.046665
   Number of active neurons: 5
 >> iter 61000, loss: 0.050063
 >> iter 62000, loss: 0.046760
 >> iter 63000, loss: 0.057372
 >> iter 64000, loss: 0.063272
 >> iter 65000, loss: 0.043195
 >> iter 66000, loss: 0.040244
 >> iter 67000, loss: 0.049565
 >> iter 68000, loss: 0.043309
 >> iter 69000, loss: 0.051387
 >> iter 70000, loss: 0.049716
   Number of active neurons: 4
 >> iter 71000, loss: 0.057502
 >> iter 72000, loss: 0.053019
 >> iter 73000, loss: 0.046974
 >> iter 74000, loss: 0.042393
 >> iter 75000, loss: 0.052280
 >> iter 76000, loss: 0.049612
 >> iter 77000, loss: 0.053465
 >> iter 78000, loss: 0.067638
 >> iter 79000, loss: 0.066203
 >> iter 80000, loss: 0.074656
   Number of active neurons: 4
 >> iter 81000, loss: 0.046311
 >> iter 82000, loss: 0.056101
 >> iter 83000, loss: 0.049568
 >> iter 84000, loss: 0.033393
 >> iter 85000, loss: 0.040163
 >> iter 86000, loss: 0.034477
 >> iter 87000, loss: 0.057214
 >> iter 88000, loss: 0.070233
 >> iter 89000, loss: 0.048439
 >> iter 90000, loss: 0.034136
   Number of active neurons: 4
 >> iter 91000, loss: 0.034748
 >> iter 92000, loss: 0.042096
 >> iter 93000, loss: 0.039956
 >> iter 94000, loss: 0.043476
 >> iter 95000, loss: 0.047749
 >> iter 96000, loss: 0.057901
 >> iter 97000, loss: 0.069784
 >> iter 98000, loss: 0.049111
 >> iter 99000, loss: 0.052315
 >> iter 100000, loss: 0.035022
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 11.351365
 >> iter 2000, loss: 4.460497
 >> iter 3000, loss: 1.770819
 >> iter 4000, loss: 0.764026
 >> iter 5000, loss: 0.348266
 >> iter 6000, loss: 0.179741
 >> iter 7000, loss: 0.121951
 >> iter 8000, loss: 0.083807
 >> iter 9000, loss: 0.070909
 >> iter 10000, loss: 0.095232
   Number of active neurons: 9
 >> iter 11000, loss: 0.081487
 >> iter 12000, loss: 0.086331
 >> iter 13000, loss: 0.062763
 >> iter 14000, loss: 0.068109
 >> iter 15000, loss: 0.064556
 >> iter 16000, loss: 0.055277
 >> iter 17000, loss: 0.052413
 >> iter 18000, loss: 0.052466
 >> iter 19000, loss: 0.057687
 >> iter 20000, loss: 0.066559
   Number of active neurons: 6
 >> iter 21000, loss: 0.076938
 >> iter 22000, loss: 0.049666
 >> iter 23000, loss: 0.050037
 >> iter 24000, loss: 0.064241
 >> iter 25000, loss: 0.048392
 >> iter 26000, loss: 0.062491
 >> iter 27000, loss: 0.053589
 >> iter 28000, loss: 0.056057
 >> iter 29000, loss: 0.053002
 >> iter 30000, loss: 0.054279
   Number of active neurons: 6
 >> iter 31000, loss: 0.057296
 >> iter 32000, loss: 0.046268
 >> iter 33000, loss: 0.050406
 >> iter 34000, loss: 0.066530
 >> iter 35000, loss: 0.054164
 >> iter 36000, loss: 0.065972
 >> iter 37000, loss: 0.062216
 >> iter 38000, loss: 0.051347
 >> iter 39000, loss: 0.046711
 >> iter 40000, loss: 0.047123
   Number of active neurons: 6
 >> iter 41000, loss: 0.047559
 >> iter 42000, loss: 0.062938
 >> iter 43000, loss: 0.052367
 >> iter 44000, loss: 0.055245
 >> iter 45000, loss: 0.056590
 >> iter 46000, loss: 0.046799
 >> iter 47000, loss: 0.045174
 >> iter 48000, loss: 0.043499
 >> iter 49000, loss: 0.067790
 >> iter 50000, loss: 0.056745
   Number of active neurons: 4
 >> iter 51000, loss: 0.057466
 >> iter 52000, loss: 0.061315
 >> iter 53000, loss: 0.058381
 >> iter 54000, loss: 0.044286
 >> iter 55000, loss: 0.058948
 >> iter 56000, loss: 0.049165
 >> iter 57000, loss: 0.042029
 >> iter 58000, loss: 0.065033
 >> iter 59000, loss: 0.061827
 >> iter 60000, loss: 0.057439
   Number of active neurons: 4
 >> iter 61000, loss: 0.051932
 >> iter 62000, loss: 0.039436
 >> iter 63000, loss: 0.037369
 >> iter 64000, loss: 0.045840
 >> iter 65000, loss: 0.044851
 >> iter 66000, loss: 0.063042
 >> iter 67000, loss: 0.045879
 >> iter 68000, loss: 0.034728
 >> iter 69000, loss: 0.048634
 >> iter 70000, loss: 0.061754
   Number of active neurons: 3
 >> iter 71000, loss: 0.064875
 >> iter 72000, loss: 0.050521
 >> iter 73000, loss: 0.048451
 >> iter 74000, loss: 0.043300
 >> iter 75000, loss: 0.045078
 >> iter 76000, loss: 0.043916
 >> iter 77000, loss: 0.035433
 >> iter 78000, loss: 0.047052
 >> iter 79000, loss: 0.030967
 >> iter 80000, loss: 0.035416
   Number of active neurons: 3
 >> iter 81000, loss: 0.054737
 >> iter 82000, loss: 0.038517
 >> iter 83000, loss: 0.032143
 >> iter 84000, loss: 0.053889
 >> iter 85000, loss: 0.040657
 >> iter 86000, loss: 0.032688
 >> iter 87000, loss: 0.051419
 >> iter 88000, loss: 0.042794
 >> iter 89000, loss: 0.044967
 >> iter 90000, loss: 0.061979
   Number of active neurons: 2
 >> iter 91000, loss: 0.042125
 >> iter 92000, loss: 0.036901
 >> iter 93000, loss: 0.048605
 >> iter 94000, loss: 0.041297
 >> iter 95000, loss: 0.036328
 >> iter 96000, loss: 0.035195
 >> iter 97000, loss: 0.045236
 >> iter 98000, loss: 0.044227
 >> iter 99000, loss: 0.030699
 >> iter 100000, loss: 0.031146
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 11.342831
 >> iter 2000, loss: 4.429402
 >> iter 3000, loss: 1.772474
 >> iter 4000, loss: 0.801514
 >> iter 5000, loss: 0.374847
 >> iter 6000, loss: 0.185285
 >> iter 7000, loss: 0.161236
 >> iter 8000, loss: 0.110946
 >> iter 9000, loss: 0.099729
 >> iter 10000, loss: 0.075249
   Number of active neurons: 10
 >> iter 11000, loss: 0.069584
 >> iter 12000, loss: 0.074044
 >> iter 13000, loss: 0.055940
 >> iter 14000, loss: 0.059263
 >> iter 15000, loss: 0.068735
 >> iter 16000, loss: 0.059766
 >> iter 17000, loss: 0.056015
 >> iter 18000, loss: 0.050575
 >> iter 19000, loss: 0.053838
 >> iter 20000, loss: 0.047456
   Number of active neurons: 8
 >> iter 21000, loss: 0.064672
 >> iter 22000, loss: 0.046823
 >> iter 23000, loss: 0.050766
 >> iter 24000, loss: 0.042516
 >> iter 25000, loss: 0.051149
 >> iter 26000, loss: 0.042055
 >> iter 27000, loss: 0.056899
 >> iter 28000, loss: 0.047876
 >> iter 29000, loss: 0.065663
 >> iter 30000, loss: 0.048757
   Number of active neurons: 4
 >> iter 31000, loss: 0.034954
 >> iter 32000, loss: 0.049084
 >> iter 33000, loss: 0.067599
 >> iter 34000, loss: 0.052154
 >> iter 35000, loss: 0.057587
 >> iter 36000, loss: 0.058970
 >> iter 37000, loss: 0.068616
 >> iter 38000, loss: 0.061866
 >> iter 39000, loss: 0.048431
 >> iter 40000, loss: 0.049599
   Number of active neurons: 4
 >> iter 41000, loss: 0.045538
 >> iter 42000, loss: 0.048820
 >> iter 43000, loss: 0.048880
 >> iter 44000, loss: 0.040314
 >> iter 45000, loss: 0.055981
 >> iter 46000, loss: 0.041151
 >> iter 47000, loss: 0.053217
 >> iter 48000, loss: 0.049024
 >> iter 49000, loss: 0.059919
 >> iter 50000, loss: 0.047045
   Number of active neurons: 3
 >> iter 51000, loss: 0.049469
 >> iter 52000, loss: 0.047219
 >> iter 53000, loss: 0.069427
 >> iter 54000, loss: 0.048637
 >> iter 55000, loss: 0.041202
 >> iter 56000, loss: 0.046551
 >> iter 57000, loss: 0.041573
 >> iter 58000, loss: 0.046976
 >> iter 59000, loss: 0.053512
 >> iter 60000, loss: 0.040967
   Number of active neurons: 3
 >> iter 61000, loss: 0.046023
 >> iter 62000, loss: 0.053859
 >> iter 63000, loss: 0.056589
 >> iter 64000, loss: 0.059244
 >> iter 65000, loss: 0.044450
 >> iter 66000, loss: 0.047936
 >> iter 67000, loss: 0.036754
 >> iter 68000, loss: 0.037476
 >> iter 69000, loss: 0.041906
 >> iter 70000, loss: 0.034990
   Number of active neurons: 3
 >> iter 71000, loss: 0.033806
 >> iter 72000, loss: 0.036840
 >> iter 73000, loss: 0.054130
 >> iter 74000, loss: 0.037547
 >> iter 75000, loss: 0.055314
 >> iter 76000, loss: 0.067977
 >> iter 77000, loss: 0.050442
 >> iter 78000, loss: 0.046601
 >> iter 79000, loss: 0.053807
 >> iter 80000, loss: 0.049286
   Number of active neurons: 3
 >> iter 81000, loss: 0.040279
 >> iter 82000, loss: 0.042631
 >> iter 83000, loss: 0.033275
 >> iter 84000, loss: 0.060484
 >> iter 85000, loss: 0.062232
 >> iter 86000, loss: 0.060116
 >> iter 87000, loss: 0.051266
 >> iter 88000, loss: 0.044704
 >> iter 89000, loss: 0.041583
 >> iter 90000, loss: 0.044120
   Number of active neurons: 3
 >> iter 91000, loss: 0.047466
 >> iter 92000, loss: 0.047858
 >> iter 93000, loss: 0.065356
 >> iter 94000, loss: 0.045870
 >> iter 95000, loss: 0.047592
 >> iter 96000, loss: 0.047434
 >> iter 97000, loss: 0.064443
 >> iter 98000, loss: 0.043990
 >> iter 99000, loss: 0.050756
 >> iter 100000, loss: 0.051314
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.332610
 >> iter 2000, loss: 4.462425
 >> iter 3000, loss: 1.792780
 >> iter 4000, loss: 0.713526
 >> iter 5000, loss: 0.330702
 >> iter 6000, loss: 0.201676
 >> iter 7000, loss: 0.127754
 >> iter 8000, loss: 0.087549
 >> iter 9000, loss: 0.072941
 >> iter 10000, loss: 0.073323
   Number of active neurons: 8
 >> iter 11000, loss: 0.074185
 >> iter 12000, loss: 0.094734
 >> iter 13000, loss: 0.069867
 >> iter 14000, loss: 0.089552
 >> iter 15000, loss: 0.068948
 >> iter 16000, loss: 0.057249
 >> iter 17000, loss: 0.078510
 >> iter 18000, loss: 0.084297
 >> iter 19000, loss: 0.090309
 >> iter 20000, loss: 0.065324
   Number of active neurons: 7
 >> iter 21000, loss: 0.055550
 >> iter 22000, loss: 0.063959
 >> iter 23000, loss: 0.052595
 >> iter 24000, loss: 0.060519
 >> iter 25000, loss: 0.073930
 >> iter 26000, loss: 0.051579
 >> iter 27000, loss: 0.054304
 >> iter 28000, loss: 0.067835
 >> iter 29000, loss: 0.057060
 >> iter 30000, loss: 0.064536
   Number of active neurons: 6
 >> iter 31000, loss: 0.072769
 >> iter 32000, loss: 0.063570
 >> iter 33000, loss: 0.058989
 >> iter 34000, loss: 0.050343
 >> iter 35000, loss: 0.057336
 >> iter 36000, loss: 0.054063
 >> iter 37000, loss: 0.060340
 >> iter 38000, loss: 0.051794
 >> iter 39000, loss: 0.065931
 >> iter 40000, loss: 0.069867
   Number of active neurons: 5
 >> iter 41000, loss: 0.080448
 >> iter 42000, loss: 0.062170
 >> iter 43000, loss: 0.060186
 >> iter 44000, loss: 0.066968
 >> iter 45000, loss: 0.069374
 >> iter 46000, loss: 0.062508
 >> iter 47000, loss: 0.049840
 >> iter 48000, loss: 0.052728
 >> iter 49000, loss: 0.071771
 >> iter 50000, loss: 0.055714
   Number of active neurons: 4
 >> iter 51000, loss: 0.048733
 >> iter 52000, loss: 0.048016
 >> iter 53000, loss: 0.052740
 >> iter 54000, loss: 0.066438
 >> iter 55000, loss: 0.044012
 >> iter 56000, loss: 0.050900
 >> iter 57000, loss: 0.045323
 >> iter 58000, loss: 0.055916
 >> iter 59000, loss: 0.054036
 >> iter 60000, loss: 0.054559
   Number of active neurons: 4
 >> iter 61000, loss: 0.060196
 >> iter 62000, loss: 0.056367
 >> iter 63000, loss: 0.050651
 >> iter 64000, loss: 0.064458
 >> iter 65000, loss: 0.058918
 >> iter 66000, loss: 0.056230
 >> iter 67000, loss: 0.049394
 >> iter 68000, loss: 0.043149
 >> iter 69000, loss: 0.059387
 >> iter 70000, loss: 0.049856
   Number of active neurons: 4
 >> iter 71000, loss: 0.069370
 >> iter 72000, loss: 0.054083
 >> iter 73000, loss: 0.048321
 >> iter 74000, loss: 0.035634
 >> iter 75000, loss: 0.040223
 >> iter 76000, loss: 0.045910
 >> iter 77000, loss: 0.049765
 >> iter 78000, loss: 0.064240
 >> iter 79000, loss: 0.047797
 >> iter 80000, loss: 0.051151
   Number of active neurons: 4
 >> iter 81000, loss: 0.049204
 >> iter 82000, loss: 0.035444
 >> iter 83000, loss: 0.032766
 >> iter 84000, loss: 0.071451
 >> iter 85000, loss: 0.072684
 >> iter 86000, loss: 0.062014
 >> iter 87000, loss: 0.052948
 >> iter 88000, loss: 0.050598
 >> iter 89000, loss: 0.039118
 >> iter 90000, loss: 0.051575
   Number of active neurons: 4
 >> iter 91000, loss: 0.052545
 >> iter 92000, loss: 0.054648
 >> iter 93000, loss: 0.037481
 >> iter 94000, loss: 0.047565
 >> iter 95000, loss: 0.038767
 >> iter 96000, loss: 0.059879
 >> iter 97000, loss: 0.036794
 >> iter 98000, loss: 0.052355
 >> iter 99000, loss: 0.053947
 >> iter 100000, loss: 0.042070
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.308239
 >> iter 2000, loss: 4.439450
 >> iter 3000, loss: 1.754868
 >> iter 4000, loss: 0.716465
 >> iter 5000, loss: 0.330197
 >> iter 6000, loss: 0.173643
 >> iter 7000, loss: 0.110624
 >> iter 8000, loss: 0.074467
 >> iter 9000, loss: 0.075130
 >> iter 10000, loss: 0.060847
   Number of active neurons: 6
 >> iter 11000, loss: 0.055234
 >> iter 12000, loss: 0.062915
 >> iter 13000, loss: 0.057096
 >> iter 14000, loss: 0.078906
 >> iter 15000, loss: 0.078391
 >> iter 16000, loss: 0.056566
 >> iter 17000, loss: 0.049341
 >> iter 18000, loss: 0.065600
 >> iter 19000, loss: 0.075538
 >> iter 20000, loss: 0.055266
   Number of active neurons: 6
 >> iter 21000, loss: 0.068119
 >> iter 22000, loss: 0.065857
 >> iter 23000, loss: 0.080669
 >> iter 24000, loss: 0.064935
 >> iter 25000, loss: 0.055337
 >> iter 26000, loss: 0.045743
 >> iter 27000, loss: 0.053642
 >> iter 28000, loss: 0.048316
 >> iter 29000, loss: 0.052845
 >> iter 30000, loss: 0.066580
   Number of active neurons: 5
 >> iter 31000, loss: 0.062331
 >> iter 32000, loss: 0.046780
 >> iter 33000, loss: 0.056186
 >> iter 34000, loss: 0.051089
 >> iter 35000, loss: 0.045204
 >> iter 36000, loss: 0.047508
 >> iter 37000, loss: 0.066964
 >> iter 38000, loss: 0.046563
 >> iter 39000, loss: 0.070222
 >> iter 40000, loss: 0.054175
   Number of active neurons: 3
 >> iter 41000, loss: 0.049310
 >> iter 42000, loss: 0.062360
 >> iter 43000, loss: 0.064596
 >> iter 44000, loss: 0.056692
 >> iter 45000, loss: 0.055190
 >> iter 46000, loss: 0.040113
 >> iter 47000, loss: 0.050603
 >> iter 48000, loss: 0.044732
 >> iter 49000, loss: 0.046457
 >> iter 50000, loss: 0.043750
   Number of active neurons: 3
 >> iter 51000, loss: 0.041397
 >> iter 52000, loss: 0.052634
 >> iter 53000, loss: 0.050109
 >> iter 54000, loss: 0.049406
 >> iter 55000, loss: 0.042377
 >> iter 56000, loss: 0.054732
 >> iter 57000, loss: 0.056561
 >> iter 58000, loss: 0.046538
 >> iter 59000, loss: 0.040083
 >> iter 60000, loss: 0.044388
   Number of active neurons: 3
 >> iter 61000, loss: 0.039843
 >> iter 62000, loss: 0.044841
 >> iter 63000, loss: 0.035374
 >> iter 64000, loss: 0.049653
 >> iter 65000, loss: 0.040191
 >> iter 66000, loss: 0.056919
 >> iter 67000, loss: 0.063343
 >> iter 68000, loss: 0.060897
 >> iter 69000, loss: 0.053773
 >> iter 70000, loss: 0.046139
   Number of active neurons: 3
 >> iter 71000, loss: 0.057036
 >> iter 72000, loss: 0.057849
 >> iter 73000, loss: 0.047078
 >> iter 74000, loss: 0.056241
 >> iter 75000, loss: 0.039344
 >> iter 76000, loss: 0.039703
 >> iter 77000, loss: 0.062893
 >> iter 78000, loss: 0.067833
 >> iter 79000, loss: 0.040106
 >> iter 80000, loss: 0.057255
   Number of active neurons: 3
 >> iter 81000, loss: 0.044258
 >> iter 82000, loss: 0.034237
 >> iter 83000, loss: 0.041060
 >> iter 84000, loss: 0.042768
 >> iter 85000, loss: 0.057595
 >> iter 86000, loss: 0.039553
 >> iter 87000, loss: 0.037275
 >> iter 88000, loss: 0.039509
 >> iter 89000, loss: 0.039198
 >> iter 90000, loss: 0.035819
   Number of active neurons: 3
 >> iter 91000, loss: 0.050041
 >> iter 92000, loss: 0.046655
 >> iter 93000, loss: 0.044302
 >> iter 94000, loss: 0.057470
 >> iter 95000, loss: 0.047752
 >> iter 96000, loss: 0.040639
 >> iter 97000, loss: 0.064942
 >> iter 98000, loss: 0.060599
 >> iter 99000, loss: 0.052198
 >> iter 100000, loss: 0.050210
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.263990
 >> iter 2000, loss: 4.365634
 >> iter 3000, loss: 1.747382
 >> iter 4000, loss: 0.737630
 >> iter 5000, loss: 0.328056
 >> iter 6000, loss: 0.185080
 >> iter 7000, loss: 0.132815
 >> iter 8000, loss: 0.079675
 >> iter 9000, loss: 0.094181
 >> iter 10000, loss: 0.073814
   Number of active neurons: 10
 >> iter 11000, loss: 0.069798
 >> iter 12000, loss: 0.071003
 >> iter 13000, loss: 0.074357
 >> iter 14000, loss: 0.072636
 >> iter 15000, loss: 0.061226
 >> iter 16000, loss: 0.057668
 >> iter 17000, loss: 0.062822
 >> iter 18000, loss: 0.062055
 >> iter 19000, loss: 0.060139
 >> iter 20000, loss: 0.063203
   Number of active neurons: 7
 >> iter 21000, loss: 0.056860
 >> iter 22000, loss: 0.070667
 >> iter 23000, loss: 0.066088
 >> iter 24000, loss: 0.052220
 >> iter 25000, loss: 0.041775
 >> iter 26000, loss: 0.039704
 >> iter 27000, loss: 0.047717
 >> iter 28000, loss: 0.066200
 >> iter 29000, loss: 0.059214
 >> iter 30000, loss: 0.044867
   Number of active neurons: 4
 >> iter 31000, loss: 0.057974
 >> iter 32000, loss: 0.050580
 >> iter 33000, loss: 0.065710
 >> iter 34000, loss: 0.056797
 >> iter 35000, loss: 0.058649
 >> iter 36000, loss: 0.056202
 >> iter 37000, loss: 0.044962
 >> iter 38000, loss: 0.046167
 >> iter 39000, loss: 0.035295
 >> iter 40000, loss: 0.043140
   Number of active neurons: 4
 >> iter 41000, loss: 0.051271
 >> iter 42000, loss: 0.055316
 >> iter 43000, loss: 0.076739
 >> iter 44000, loss: 0.070191
 >> iter 45000, loss: 0.054486
 >> iter 46000, loss: 0.041917
 >> iter 47000, loss: 0.051490
 >> iter 48000, loss: 0.042028
 >> iter 49000, loss: 0.041874
 >> iter 50000, loss: 0.044465
   Number of active neurons: 4
 >> iter 51000, loss: 0.042379
 >> iter 52000, loss: 0.057635
 >> iter 53000, loss: 0.069172
 >> iter 54000, loss: 0.044097
 >> iter 55000, loss: 0.034065
 >> iter 56000, loss: 0.038955
 >> iter 57000, loss: 0.041006
 >> iter 58000, loss: 0.038424
 >> iter 59000, loss: 0.048422
 >> iter 60000, loss: 0.048425
   Number of active neurons: 4
 >> iter 61000, loss: 0.045465
 >> iter 62000, loss: 0.037825
 >> iter 63000, loss: 0.076172
 >> iter 64000, loss: 0.055286
 >> iter 65000, loss: 0.045726
 >> iter 66000, loss: 0.048964
 >> iter 67000, loss: 0.037064
 >> iter 68000, loss: 0.043687
 >> iter 69000, loss: 0.055413
 >> iter 70000, loss: 0.049504
   Number of active neurons: 4
 >> iter 71000, loss: 0.064803
 >> iter 72000, loss: 0.061174
 >> iter 73000, loss: 0.047029
 >> iter 74000, loss: 0.046047
 >> iter 75000, loss: 0.060631
 >> iter 76000, loss: 0.053152
 >> iter 77000, loss: 0.045744
 >> iter 78000, loss: 0.049451
 >> iter 79000, loss: 0.036846
 >> iter 80000, loss: 0.037357
   Number of active neurons: 4
 >> iter 81000, loss: 0.039211
 >> iter 82000, loss: 0.044577
 >> iter 83000, loss: 0.059681
 >> iter 84000, loss: 0.050101
 >> iter 85000, loss: 0.050901
 >> iter 86000, loss: 0.049240
 >> iter 87000, loss: 0.038854
 >> iter 88000, loss: 0.056265
 >> iter 89000, loss: 0.046306
 >> iter 90000, loss: 0.047709
   Number of active neurons: 3
 >> iter 91000, loss: 0.040753
 >> iter 92000, loss: 0.041044
 >> iter 93000, loss: 0.050974
 >> iter 94000, loss: 0.061065
 >> iter 95000, loss: 0.052924
 >> iter 96000, loss: 0.069421
 >> iter 97000, loss: 0.055722
 >> iter 98000, loss: 0.062271
 >> iter 99000, loss: 0.048941
 >> iter 100000, loss: 0.033329
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.298808
 >> iter 2000, loss: 4.398377
 >> iter 3000, loss: 1.752099
 >> iter 4000, loss: 0.758764
 >> iter 5000, loss: 0.363202
 >> iter 6000, loss: 0.200092
 >> iter 7000, loss: 0.193525
 >> iter 8000, loss: 0.114806
 >> iter 9000, loss: 0.106797
 >> iter 10000, loss: 0.079205
   Number of active neurons: 9
 >> iter 11000, loss: 0.097057
 >> iter 12000, loss: 0.081921
 >> iter 13000, loss: 0.091565
 >> iter 14000, loss: 0.078343
 >> iter 15000, loss: 0.064620
 >> iter 16000, loss: 0.049586
 >> iter 17000, loss: 0.079418
 >> iter 18000, loss: 0.057984
 >> iter 19000, loss: 0.081946
 >> iter 20000, loss: 0.061449
   Number of active neurons: 8
 >> iter 21000, loss: 0.074071
 >> iter 22000, loss: 0.056963
 >> iter 23000, loss: 0.080421
 >> iter 24000, loss: 0.053958
 >> iter 25000, loss: 0.062474
 >> iter 26000, loss: 0.054705
 >> iter 27000, loss: 0.051484
 >> iter 28000, loss: 0.044237
 >> iter 29000, loss: 0.049468
 >> iter 30000, loss: 0.043596
   Number of active neurons: 5
 >> iter 31000, loss: 0.046362
 >> iter 32000, loss: 0.054484
 >> iter 33000, loss: 0.047527
 >> iter 34000, loss: 0.052205
 >> iter 35000, loss: 0.043789
 >> iter 36000, loss: 0.058058
 >> iter 37000, loss: 0.041926
 >> iter 38000, loss: 0.041369
 >> iter 39000, loss: 0.039087
 >> iter 40000, loss: 0.055208
   Number of active neurons: 4
 >> iter 41000, loss: 0.056648
 >> iter 42000, loss: 0.056374
 >> iter 43000, loss: 0.078559
 >> iter 44000, loss: 0.045689
 >> iter 45000, loss: 0.049728
 >> iter 46000, loss: 0.054328
 >> iter 47000, loss: 0.040843
 >> iter 48000, loss: 0.054622
 >> iter 49000, loss: 0.046852
 >> iter 50000, loss: 0.057996
   Number of active neurons: 4
 >> iter 51000, loss: 0.047501
 >> iter 52000, loss: 0.064835
 >> iter 53000, loss: 0.069289
 >> iter 54000, loss: 0.073295
 >> iter 55000, loss: 0.058788
 >> iter 56000, loss: 0.045240
 >> iter 57000, loss: 0.048586
 >> iter 58000, loss: 0.055124
 >> iter 59000, loss: 0.052681
 >> iter 60000, loss: 0.044260
   Number of active neurons: 4
 >> iter 61000, loss: 0.053409
 >> iter 62000, loss: 0.055922
 >> iter 63000, loss: 0.044676
 >> iter 64000, loss: 0.053723
 >> iter 65000, loss: 0.053517
 >> iter 66000, loss: 0.044271
 >> iter 67000, loss: 0.044507
 >> iter 68000, loss: 0.041797
 >> iter 69000, loss: 0.055859
 >> iter 70000, loss: 0.053674
   Number of active neurons: 4
 >> iter 71000, loss: 0.044347
 >> iter 72000, loss: 0.045029
 >> iter 73000, loss: 0.036354
 >> iter 74000, loss: 0.045222
 >> iter 75000, loss: 0.048879
 >> iter 76000, loss: 0.062648
 >> iter 77000, loss: 0.055033
 >> iter 78000, loss: 0.078560
 >> iter 79000, loss: 0.055451
 >> iter 80000, loss: 0.047729
   Number of active neurons: 4
 >> iter 81000, loss: 0.069519
 >> iter 82000, loss: 0.055920
 >> iter 83000, loss: 0.046391
 >> iter 84000, loss: 0.057015
 >> iter 85000, loss: 0.049228
 >> iter 86000, loss: 0.045061
 >> iter 87000, loss: 0.042309
 >> iter 88000, loss: 0.060436
 >> iter 89000, loss: 0.053052
 >> iter 90000, loss: 0.044114
   Number of active neurons: 3
 >> iter 91000, loss: 0.045976
 >> iter 92000, loss: 0.050011
 >> iter 93000, loss: 0.053304
 >> iter 94000, loss: 0.044267
 >> iter 95000, loss: 0.036261
 >> iter 96000, loss: 0.034643
 >> iter 97000, loss: 0.032053
 >> iter 98000, loss: 0.041397
 >> iter 99000, loss: 0.039476
 >> iter 100000, loss: 0.048819
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

