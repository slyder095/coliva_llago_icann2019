 > Problema: tomita2nueva
 > Args:
   - Hidden size: 20
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.314481
 >> iter 2000, loss: 4.488269
 >> iter 3000, loss: 1.797090
 >> iter 4000, loss: 0.760264
 >> iter 5000, loss: 0.382579
 >> iter 6000, loss: 0.230541
 >> iter 7000, loss: 0.157614
 >> iter 8000, loss: 0.145550
 >> iter 9000, loss: 0.117326
 >> iter 10000, loss: 0.133154
   Number of active neurons: 10
 >> iter 11000, loss: 0.103575
 >> iter 12000, loss: 0.085969
 >> iter 13000, loss: 0.098778
 >> iter 14000, loss: 0.089607
 >> iter 15000, loss: 0.078145
 >> iter 16000, loss: 0.062310
 >> iter 17000, loss: 0.062305
 >> iter 18000, loss: 0.088325
 >> iter 19000, loss: 0.083343
 >> iter 20000, loss: 0.069081
   Number of active neurons: 7
 >> iter 21000, loss: 0.065851
 >> iter 22000, loss: 0.081348
 >> iter 23000, loss: 0.065213
 >> iter 24000, loss: 0.076769
 >> iter 25000, loss: 0.062926
 >> iter 26000, loss: 0.072443
 >> iter 27000, loss: 0.049911
 >> iter 28000, loss: 0.043162
 >> iter 29000, loss: 0.058269
 >> iter 30000, loss: 0.056914
   Number of active neurons: 7
 >> iter 31000, loss: 0.050710
 >> iter 32000, loss: 0.054727
 >> iter 33000, loss: 0.055166
 >> iter 34000, loss: 0.066310
 >> iter 35000, loss: 0.052794
 >> iter 36000, loss: 0.042906
 >> iter 37000, loss: 0.045346
 >> iter 38000, loss: 0.038309
 >> iter 39000, loss: 0.052842
 >> iter 40000, loss: 0.060564
   Number of active neurons: 5
 >> iter 41000, loss: 0.044103
 >> iter 42000, loss: 0.046545
 >> iter 43000, loss: 0.040537
 >> iter 44000, loss: 0.041746
 >> iter 45000, loss: 0.059289
 >> iter 46000, loss: 0.052284
 >> iter 47000, loss: 0.037855
 >> iter 48000, loss: 0.034236
 >> iter 49000, loss: 0.036363
 >> iter 50000, loss: 0.053807
   Number of active neurons: 4
 >> iter 51000, loss: 0.067172
 >> iter 52000, loss: 0.047719
 >> iter 53000, loss: 0.051675
 >> iter 54000, loss: 0.038972
 >> iter 55000, loss: 0.050773
 >> iter 56000, loss: 0.060919
 >> iter 57000, loss: 0.054150
 >> iter 58000, loss: 0.045900
 >> iter 59000, loss: 0.071801
 >> iter 60000, loss: 0.042653
   Number of active neurons: 3
 >> iter 61000, loss: 0.042810
 >> iter 62000, loss: 0.040272
 >> iter 63000, loss: 0.035904
 >> iter 64000, loss: 0.040037
 >> iter 65000, loss: 0.041313
 >> iter 66000, loss: 0.038112
 >> iter 67000, loss: 0.045917
 >> iter 68000, loss: 0.041514
 >> iter 69000, loss: 0.045990
 >> iter 70000, loss: 0.035558
   Number of active neurons: 3
 >> iter 71000, loss: 0.047136
 >> iter 72000, loss: 0.037522
 >> iter 73000, loss: 0.038685
 >> iter 74000, loss: 0.046452
 >> iter 75000, loss: 0.044264
 >> iter 76000, loss: 0.054391
 >> iter 77000, loss: 0.041704
 >> iter 78000, loss: 0.044429
 >> iter 79000, loss: 0.044102
 >> iter 80000, loss: 0.041039
   Number of active neurons: 2
 >> iter 81000, loss: 0.060220
 >> iter 82000, loss: 0.052921
 >> iter 83000, loss: 0.039124
 >> iter 84000, loss: 0.040198
 >> iter 85000, loss: 0.045824
 >> iter 86000, loss: 0.042970
 >> iter 87000, loss: 0.047880
 >> iter 88000, loss: 0.051588
 >> iter 89000, loss: 0.054092
 >> iter 90000, loss: 0.040838
   Number of active neurons: 2
 >> iter 91000, loss: 0.047465
 >> iter 92000, loss: 0.063043
 >> iter 93000, loss: 0.050696
 >> iter 94000, loss: 0.042843
 >> iter 95000, loss: 0.036637
 >> iter 96000, loss: 0.052814
 >> iter 97000, loss: 0.042637
 >> iter 98000, loss: 0.031311
 >> iter 99000, loss: 0.039944
 >> iter 100000, loss: 0.035504
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455159
   Number of active neurons: 0
 >> iter 1000, loss: 11.299374
 >> iter 2000, loss: 4.487303
 >> iter 3000, loss: 1.847358
 >> iter 4000, loss: 0.825861
 >> iter 5000, loss: 0.401909
 >> iter 6000, loss: 0.220621
 >> iter 7000, loss: 0.146113
 >> iter 8000, loss: 0.144322
 >> iter 9000, loss: 0.126593
 >> iter 10000, loss: 0.120036
   Number of active neurons: 13
 >> iter 11000, loss: 0.087131
 >> iter 12000, loss: 0.089798
 >> iter 13000, loss: 0.091289
 >> iter 14000, loss: 0.099077
 >> iter 15000, loss: 0.083091
 >> iter 16000, loss: 0.075778
 >> iter 17000, loss: 0.072929
 >> iter 18000, loss: 0.079912
 >> iter 19000, loss: 0.073451
 >> iter 20000, loss: 0.069998
   Number of active neurons: 9
 >> iter 21000, loss: 0.070371
 >> iter 22000, loss: 0.056597
 >> iter 23000, loss: 0.060561
 >> iter 24000, loss: 0.059150
 >> iter 25000, loss: 0.049619
 >> iter 26000, loss: 0.059861
 >> iter 27000, loss: 0.060027
 >> iter 28000, loss: 0.044923
 >> iter 29000, loss: 0.058823
 >> iter 30000, loss: 0.057436
   Number of active neurons: 8
 >> iter 31000, loss: 0.079726
 >> iter 32000, loss: 0.061443
 >> iter 33000, loss: 0.046463
 >> iter 34000, loss: 0.060023
 >> iter 35000, loss: 0.063988
 >> iter 36000, loss: 0.049059
 >> iter 37000, loss: 0.063688
 >> iter 38000, loss: 0.063431
 >> iter 39000, loss: 0.051716
 >> iter 40000, loss: 0.051879
   Number of active neurons: 5
 >> iter 41000, loss: 0.053811
 >> iter 42000, loss: 0.060039
 >> iter 43000, loss: 0.065499
 >> iter 44000, loss: 0.056860
 >> iter 45000, loss: 0.041467
 >> iter 46000, loss: 0.038146
 >> iter 47000, loss: 0.042544
 >> iter 48000, loss: 0.041337
 >> iter 49000, loss: 0.050029
 >> iter 50000, loss: 0.045549
   Number of active neurons: 4
 >> iter 51000, loss: 0.042486
 >> iter 52000, loss: 0.068718
 >> iter 53000, loss: 0.083312
 >> iter 54000, loss: 0.050277
 >> iter 55000, loss: 0.046379
 >> iter 56000, loss: 0.040315
 >> iter 57000, loss: 0.047163
 >> iter 58000, loss: 0.053246
 >> iter 59000, loss: 0.055154
 >> iter 60000, loss: 0.047413
   Number of active neurons: 4
 >> iter 61000, loss: 0.046587
 >> iter 62000, loss: 0.073376
 >> iter 63000, loss: 0.069144
 >> iter 64000, loss: 0.047403
 >> iter 65000, loss: 0.060844
 >> iter 66000, loss: 0.055235
 >> iter 67000, loss: 0.052035
 >> iter 68000, loss: 0.057745
 >> iter 69000, loss: 0.062584
 >> iter 70000, loss: 0.052885
   Number of active neurons: 3
 >> iter 71000, loss: 0.043291
 >> iter 72000, loss: 0.039620
 >> iter 73000, loss: 0.037021
 >> iter 74000, loss: 0.037156
 >> iter 75000, loss: 0.045711
 >> iter 76000, loss: 0.034694
 >> iter 77000, loss: 0.061852
 >> iter 78000, loss: 0.058594
 >> iter 79000, loss: 0.056458
 >> iter 80000, loss: 0.039042
   Number of active neurons: 3
 >> iter 81000, loss: 0.042317
 >> iter 82000, loss: 0.047423
 >> iter 83000, loss: 0.045603
 >> iter 84000, loss: 0.036728
 >> iter 85000, loss: 0.042091
 >> iter 86000, loss: 0.059698
 >> iter 87000, loss: 0.056502
 >> iter 88000, loss: 0.064513
 >> iter 89000, loss: 0.045828
 >> iter 90000, loss: 0.050517
   Number of active neurons: 3
 >> iter 91000, loss: 0.040954
 >> iter 92000, loss: 0.034465
 >> iter 93000, loss: 0.049213
 >> iter 94000, loss: 0.055557
 >> iter 95000, loss: 0.048011
 >> iter 96000, loss: 0.040189
 >> iter 97000, loss: 0.072243
 >> iter 98000, loss: 0.057058
 >> iter 99000, loss: 0.061049
 >> iter 100000, loss: 0.043387
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 11.291236
 >> iter 2000, loss: 4.441242
 >> iter 3000, loss: 1.782052
 >> iter 4000, loss: 0.748897
 >> iter 5000, loss: 0.331984
 >> iter 6000, loss: 0.199687
 >> iter 7000, loss: 0.126738
 >> iter 8000, loss: 0.105930
 >> iter 9000, loss: 0.110895
 >> iter 10000, loss: 0.073591
   Number of active neurons: 11
 >> iter 11000, loss: 0.073437
 >> iter 12000, loss: 0.076552
 >> iter 13000, loss: 0.068972
 >> iter 14000, loss: 0.066349
 >> iter 15000, loss: 0.088334
 >> iter 16000, loss: 0.079197
 >> iter 17000, loss: 0.090892
 >> iter 18000, loss: 0.065874
 >> iter 19000, loss: 0.067429
 >> iter 20000, loss: 0.056053
   Number of active neurons: 7
 >> iter 21000, loss: 0.055673
 >> iter 22000, loss: 0.054700
 >> iter 23000, loss: 0.064894
 >> iter 24000, loss: 0.061814
 >> iter 25000, loss: 0.047953
 >> iter 26000, loss: 0.046683
 >> iter 27000, loss: 0.073520
 >> iter 28000, loss: 0.066482
 >> iter 29000, loss: 0.053856
 >> iter 30000, loss: 0.059407
   Number of active neurons: 6
 >> iter 31000, loss: 0.043750
 >> iter 32000, loss: 0.053828
 >> iter 33000, loss: 0.048776
 >> iter 34000, loss: 0.052204
 >> iter 35000, loss: 0.044952
 >> iter 36000, loss: 0.063473
 >> iter 37000, loss: 0.051798
 >> iter 38000, loss: 0.046826
 >> iter 39000, loss: 0.060613
 >> iter 40000, loss: 0.044155
   Number of active neurons: 5
 >> iter 41000, loss: 0.043753
 >> iter 42000, loss: 0.047170
 >> iter 43000, loss: 0.040961
 >> iter 44000, loss: 0.053168
 >> iter 45000, loss: 0.044136
 >> iter 46000, loss: 0.039234
 >> iter 47000, loss: 0.061885
 >> iter 48000, loss: 0.056825
 >> iter 49000, loss: 0.060942
 >> iter 50000, loss: 0.043156
   Number of active neurons: 5
 >> iter 51000, loss: 0.071296
 >> iter 52000, loss: 0.047699
 >> iter 53000, loss: 0.049982
 >> iter 54000, loss: 0.053104
 >> iter 55000, loss: 0.045896
 >> iter 56000, loss: 0.063993
 >> iter 57000, loss: 0.055762
 >> iter 58000, loss: 0.059876
 >> iter 59000, loss: 0.053829
 >> iter 60000, loss: 0.062234
   Number of active neurons: 4
 >> iter 61000, loss: 0.055451
 >> iter 62000, loss: 0.045650
 >> iter 63000, loss: 0.038804
 >> iter 64000, loss: 0.056375
 >> iter 65000, loss: 0.042231
 >> iter 66000, loss: 0.032989
 >> iter 67000, loss: 0.034744
 >> iter 68000, loss: 0.037119
 >> iter 69000, loss: 0.053447
 >> iter 70000, loss: 0.063334
   Number of active neurons: 4
 >> iter 71000, loss: 0.092275
 >> iter 72000, loss: 0.064992
 >> iter 73000, loss: 0.053168
 >> iter 74000, loss: 0.057681
 >> iter 75000, loss: 0.057287
 >> iter 76000, loss: 0.048199
 >> iter 77000, loss: 0.042253
 >> iter 78000, loss: 0.058169
 >> iter 79000, loss: 0.047037
 >> iter 80000, loss: 0.046981
   Number of active neurons: 4
 >> iter 81000, loss: 0.051554
 >> iter 82000, loss: 0.042441
 >> iter 83000, loss: 0.038675
 >> iter 84000, loss: 0.042158
 >> iter 85000, loss: 0.039189
 >> iter 86000, loss: 0.051552
 >> iter 87000, loss: 0.049895
 >> iter 88000, loss: 0.034129
 >> iter 89000, loss: 0.033541
 >> iter 90000, loss: 0.060648
   Number of active neurons: 4
 >> iter 91000, loss: 0.061361
 >> iter 92000, loss: 0.052609
 >> iter 93000, loss: 0.037026
 >> iter 94000, loss: 0.036582
 >> iter 95000, loss: 0.042566
 >> iter 96000, loss: 0.036857
 >> iter 97000, loss: 0.047108
 >> iter 98000, loss: 0.042750
 >> iter 99000, loss: 0.034158
 >> iter 100000, loss: 0.033136
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.383255
 >> iter 2000, loss: 4.437298
 >> iter 3000, loss: 1.753990
 >> iter 4000, loss: 0.741054
 >> iter 5000, loss: 0.358035
 >> iter 6000, loss: 0.181470
 >> iter 7000, loss: 0.114612
 >> iter 8000, loss: 0.092138
 >> iter 9000, loss: 0.083619
 >> iter 10000, loss: 0.079587
   Number of active neurons: 8
 >> iter 11000, loss: 0.086802
 >> iter 12000, loss: 0.071729
 >> iter 13000, loss: 0.081894
 >> iter 14000, loss: 0.070743
 >> iter 15000, loss: 0.074499
 >> iter 16000, loss: 0.062416
 >> iter 17000, loss: 0.065024
 >> iter 18000, loss: 0.060881
 >> iter 19000, loss: 0.064971
 >> iter 20000, loss: 0.047666
   Number of active neurons: 7
 >> iter 21000, loss: 0.084554
 >> iter 22000, loss: 0.078833
 >> iter 23000, loss: 0.061030
 >> iter 24000, loss: 0.044353
 >> iter 25000, loss: 0.073361
 >> iter 26000, loss: 0.067104
 >> iter 27000, loss: 0.061531
 >> iter 28000, loss: 0.050610
 >> iter 29000, loss: 0.052674
 >> iter 30000, loss: 0.073513
   Number of active neurons: 5
 >> iter 31000, loss: 0.058316
 >> iter 32000, loss: 0.048974
 >> iter 33000, loss: 0.050029
 >> iter 34000, loss: 0.068196
 >> iter 35000, loss: 0.055164
 >> iter 36000, loss: 0.051874
 >> iter 37000, loss: 0.070177
 >> iter 38000, loss: 0.056401
 >> iter 39000, loss: 0.055849
 >> iter 40000, loss: 0.050154
   Number of active neurons: 5
 >> iter 41000, loss: 0.071944
 >> iter 42000, loss: 0.054046
 >> iter 43000, loss: 0.049021
 >> iter 44000, loss: 0.046452
 >> iter 45000, loss: 0.057624
 >> iter 46000, loss: 0.069714
 >> iter 47000, loss: 0.049827
 >> iter 48000, loss: 0.056603
 >> iter 49000, loss: 0.046388
 >> iter 50000, loss: 0.051149
   Number of active neurons: 5
 >> iter 51000, loss: 0.044744
 >> iter 52000, loss: 0.053423
 >> iter 53000, loss: 0.048160
 >> iter 54000, loss: 0.042660
 >> iter 55000, loss: 0.066049
 >> iter 56000, loss: 0.064569
 >> iter 57000, loss: 0.049037
 >> iter 58000, loss: 0.052334
 >> iter 59000, loss: 0.042173
 >> iter 60000, loss: 0.046740
   Number of active neurons: 5
 >> iter 61000, loss: 0.039461
 >> iter 62000, loss: 0.057818
 >> iter 63000, loss: 0.058835
 >> iter 64000, loss: 0.052619
 >> iter 65000, loss: 0.042935
 >> iter 66000, loss: 0.046172
 >> iter 67000, loss: 0.050556
 >> iter 68000, loss: 0.043384
 >> iter 69000, loss: 0.042899
 >> iter 70000, loss: 0.045993
   Number of active neurons: 5
 >> iter 71000, loss: 0.033183
 >> iter 72000, loss: 0.041723
 >> iter 73000, loss: 0.045431
 >> iter 74000, loss: 0.063150
 >> iter 75000, loss: 0.046370
 >> iter 76000, loss: 0.041949
 >> iter 77000, loss: 0.056088
 >> iter 78000, loss: 0.052675
 >> iter 79000, loss: 0.073927
 >> iter 80000, loss: 0.066067
   Number of active neurons: 5
 >> iter 81000, loss: 0.084984
 >> iter 82000, loss: 0.059338
 >> iter 83000, loss: 0.054248
 >> iter 84000, loss: 0.039861
 >> iter 85000, loss: 0.045708
 >> iter 86000, loss: 0.044056
 >> iter 87000, loss: 0.044733
 >> iter 88000, loss: 0.036734
 >> iter 89000, loss: 0.042065
 >> iter 90000, loss: 0.058541
   Number of active neurons: 4
 >> iter 91000, loss: 0.053812
 >> iter 92000, loss: 0.076184
 >> iter 93000, loss: 0.059244
 >> iter 94000, loss: 0.041856
 >> iter 95000, loss: 0.047719
 >> iter 96000, loss: 0.063016
 >> iter 97000, loss: 0.044315
 >> iter 98000, loss: 0.036551
 >> iter 99000, loss: 0.040568
 >> iter 100000, loss: 0.062757
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.365765
 >> iter 2000, loss: 4.466911
 >> iter 3000, loss: 1.758560
 >> iter 4000, loss: 0.770671
 >> iter 5000, loss: 0.352895
 >> iter 6000, loss: 0.177494
 >> iter 7000, loss: 0.124863
 >> iter 8000, loss: 0.122909
 >> iter 9000, loss: 0.098898
 >> iter 10000, loss: 0.072097
   Number of active neurons: 9
 >> iter 11000, loss: 0.078715
 >> iter 12000, loss: 0.082537
 >> iter 13000, loss: 0.062567
 >> iter 14000, loss: 0.059611
 >> iter 15000, loss: 0.063329
 >> iter 16000, loss: 0.072886
 >> iter 17000, loss: 0.080461
 >> iter 18000, loss: 0.079861
 >> iter 19000, loss: 0.074027
 >> iter 20000, loss: 0.074473
   Number of active neurons: 7
 >> iter 21000, loss: 0.063670
 >> iter 22000, loss: 0.062754
 >> iter 23000, loss: 0.059522
 >> iter 24000, loss: 0.059428
 >> iter 25000, loss: 0.055231
 >> iter 26000, loss: 0.094023
 >> iter 27000, loss: 0.077751
 >> iter 28000, loss: 0.073951
 >> iter 29000, loss: 0.058539
 >> iter 30000, loss: 0.057015
   Number of active neurons: 6
 >> iter 31000, loss: 0.058225
 >> iter 32000, loss: 0.061060
 >> iter 33000, loss: 0.063727
 >> iter 34000, loss: 0.059158
 >> iter 35000, loss: 0.054514
 >> iter 36000, loss: 0.052550
 >> iter 37000, loss: 0.056069
 >> iter 38000, loss: 0.063249
 >> iter 39000, loss: 0.052265
 >> iter 40000, loss: 0.061876
   Number of active neurons: 6
 >> iter 41000, loss: 0.057753
 >> iter 42000, loss: 0.059830
 >> iter 43000, loss: 0.080048
 >> iter 44000, loss: 0.058596
 >> iter 45000, loss: 0.059152
 >> iter 46000, loss: 0.039950
 >> iter 47000, loss: 0.042063
 >> iter 48000, loss: 0.042451
 >> iter 49000, loss: 0.042485
 >> iter 50000, loss: 0.052774
   Number of active neurons: 4
 >> iter 51000, loss: 0.060451
 >> iter 52000, loss: 0.058976
 >> iter 53000, loss: 0.053124
 >> iter 54000, loss: 0.042888
 >> iter 55000, loss: 0.044079
 >> iter 56000, loss: 0.065817
 >> iter 57000, loss: 0.057970
 >> iter 58000, loss: 0.043748
 >> iter 59000, loss: 0.052934
 >> iter 60000, loss: 0.046310
   Number of active neurons: 4
 >> iter 61000, loss: 0.063448
 >> iter 62000, loss: 0.043732
 >> iter 63000, loss: 0.046321
 >> iter 64000, loss: 0.063659
 >> iter 65000, loss: 0.074434
 >> iter 66000, loss: 0.058723
 >> iter 67000, loss: 0.055394
 >> iter 68000, loss: 0.046889
 >> iter 69000, loss: 0.059238
 >> iter 70000, loss: 0.043891
   Number of active neurons: 4
 >> iter 71000, loss: 0.060976
 >> iter 72000, loss: 0.047118
 >> iter 73000, loss: 0.056557
 >> iter 74000, loss: 0.046650
 >> iter 75000, loss: 0.057308
 >> iter 76000, loss: 0.044255
 >> iter 77000, loss: 0.043174
 >> iter 78000, loss: 0.037487
 >> iter 79000, loss: 0.040099
 >> iter 80000, loss: 0.044743
   Number of active neurons: 4
 >> iter 81000, loss: 0.034425
 >> iter 82000, loss: 0.063550
 >> iter 83000, loss: 0.042309
 >> iter 84000, loss: 0.043964
 >> iter 85000, loss: 0.041223
 >> iter 86000, loss: 0.048098
 >> iter 87000, loss: 0.062143
 >> iter 88000, loss: 0.046028
 >> iter 89000, loss: 0.062740
 >> iter 90000, loss: 0.058310
   Number of active neurons: 3
 >> iter 91000, loss: 0.050197
 >> iter 92000, loss: 0.046973
 >> iter 93000, loss: 0.061616
 >> iter 94000, loss: 0.056520
 >> iter 95000, loss: 0.042900
 >> iter 96000, loss: 0.037032
 >> iter 97000, loss: 0.033263
 >> iter 98000, loss: 0.053306
 >> iter 99000, loss: 0.039904
 >> iter 100000, loss: 0.056398
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.397736
 >> iter 2000, loss: 4.485578
 >> iter 3000, loss: 1.810952
 >> iter 4000, loss: 0.774671
 >> iter 5000, loss: 0.368817
 >> iter 6000, loss: 0.200278
 >> iter 7000, loss: 0.132248
 >> iter 8000, loss: 0.110544
 >> iter 9000, loss: 0.095449
 >> iter 10000, loss: 0.086145
   Number of active neurons: 10
 >> iter 11000, loss: 0.084036
 >> iter 12000, loss: 0.080724
 >> iter 13000, loss: 0.082013
 >> iter 14000, loss: 0.083991
 >> iter 15000, loss: 0.069816
 >> iter 16000, loss: 0.049909
 >> iter 17000, loss: 0.057387
 >> iter 18000, loss: 0.070048
 >> iter 19000, loss: 0.068131
 >> iter 20000, loss: 0.079326
   Number of active neurons: 7
 >> iter 21000, loss: 0.059420
 >> iter 22000, loss: 0.060538
 >> iter 23000, loss: 0.053267
 >> iter 24000, loss: 0.052607
 >> iter 25000, loss: 0.051393
 >> iter 26000, loss: 0.038164
 >> iter 27000, loss: 0.071015
 >> iter 28000, loss: 0.055272
 >> iter 29000, loss: 0.068508
 >> iter 30000, loss: 0.042784
   Number of active neurons: 6
 >> iter 31000, loss: 0.058554
 >> iter 32000, loss: 0.056477
 >> iter 33000, loss: 0.070018
 >> iter 34000, loss: 0.080820
 >> iter 35000, loss: 0.063189
 >> iter 36000, loss: 0.044784
 >> iter 37000, loss: 0.046632
 >> iter 38000, loss: 0.075206
 >> iter 39000, loss: 0.060525
 >> iter 40000, loss: 0.061650
   Number of active neurons: 5
 >> iter 41000, loss: 0.056257
 >> iter 42000, loss: 0.055625
 >> iter 43000, loss: 0.050619
 >> iter 44000, loss: 0.054686
 >> iter 45000, loss: 0.055759
 >> iter 46000, loss: 0.059540
 >> iter 47000, loss: 0.060448
 >> iter 48000, loss: 0.058836
 >> iter 49000, loss: 0.052726
 >> iter 50000, loss: 0.040728
   Number of active neurons: 4
 >> iter 51000, loss: 0.043754
 >> iter 52000, loss: 0.037774
 >> iter 53000, loss: 0.053902
 >> iter 54000, loss: 0.037931
 >> iter 55000, loss: 0.064751
 >> iter 56000, loss: 0.051206
 >> iter 57000, loss: 0.054978
 >> iter 58000, loss: 0.046800
 >> iter 59000, loss: 0.045614
 >> iter 60000, loss: 0.068383
   Number of active neurons: 4
 >> iter 61000, loss: 0.063524
 >> iter 62000, loss: 0.052609
 >> iter 63000, loss: 0.044650
 >> iter 64000, loss: 0.046537
 >> iter 65000, loss: 0.050803
 >> iter 66000, loss: 0.038967
 >> iter 67000, loss: 0.039422
 >> iter 68000, loss: 0.049545
 >> iter 69000, loss: 0.045909
 >> iter 70000, loss: 0.045854
   Number of active neurons: 4
 >> iter 71000, loss: 0.051582
 >> iter 72000, loss: 0.050990
 >> iter 73000, loss: 0.047753
 >> iter 74000, loss: 0.039404
 >> iter 75000, loss: 0.046806
 >> iter 76000, loss: 0.075830
 >> iter 77000, loss: 0.057037
 >> iter 78000, loss: 0.056909
 >> iter 79000, loss: 0.053683
 >> iter 80000, loss: 0.038020
   Number of active neurons: 4
 >> iter 81000, loss: 0.054045
 >> iter 82000, loss: 0.043802
 >> iter 83000, loss: 0.055090
 >> iter 84000, loss: 0.046103
 >> iter 85000, loss: 0.042267
 >> iter 86000, loss: 0.031946
 >> iter 87000, loss: 0.042952
 >> iter 88000, loss: 0.042267
 >> iter 89000, loss: 0.039766
 >> iter 90000, loss: 0.054936
   Number of active neurons: 3
 >> iter 91000, loss: 0.041411
 >> iter 92000, loss: 0.042310
 >> iter 93000, loss: 0.038648
 >> iter 94000, loss: 0.042355
 >> iter 95000, loss: 0.036500
 >> iter 96000, loss: 0.044043
 >> iter 97000, loss: 0.042515
 >> iter 98000, loss: 0.042031
 >> iter 99000, loss: 0.039179
 >> iter 100000, loss: 0.042923
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.337675
 >> iter 2000, loss: 4.479535
 >> iter 3000, loss: 1.785343
 >> iter 4000, loss: 0.738426
 >> iter 5000, loss: 0.345062
 >> iter 6000, loss: 0.204543
 >> iter 7000, loss: 0.124898
 >> iter 8000, loss: 0.101065
 >> iter 9000, loss: 0.091592
 >> iter 10000, loss: 0.064729
   Number of active neurons: 8
 >> iter 11000, loss: 0.067200
 >> iter 12000, loss: 0.059419
 >> iter 13000, loss: 0.051189
 >> iter 14000, loss: 0.065481
 >> iter 15000, loss: 0.063784
 >> iter 16000, loss: 0.051656
 >> iter 17000, loss: 0.053606
 >> iter 18000, loss: 0.076884
 >> iter 19000, loss: 0.068065
 >> iter 20000, loss: 0.064514
   Number of active neurons: 7
 >> iter 21000, loss: 0.054066
 >> iter 22000, loss: 0.050929
 >> iter 23000, loss: 0.075373
 >> iter 24000, loss: 0.052047
 >> iter 25000, loss: 0.052001
 >> iter 26000, loss: 0.055313
 >> iter 27000, loss: 0.043040
 >> iter 28000, loss: 0.049749
 >> iter 29000, loss: 0.058818
 >> iter 30000, loss: 0.062135
   Number of active neurons: 4
 >> iter 31000, loss: 0.054660
 >> iter 32000, loss: 0.074949
 >> iter 33000, loss: 0.051488
 >> iter 34000, loss: 0.064719
 >> iter 35000, loss: 0.041054
 >> iter 36000, loss: 0.036795
 >> iter 37000, loss: 0.039894
 >> iter 38000, loss: 0.039938
 >> iter 39000, loss: 0.049545
 >> iter 40000, loss: 0.072723
   Number of active neurons: 4
 >> iter 41000, loss: 0.054815
 >> iter 42000, loss: 0.048613
 >> iter 43000, loss: 0.049547
 >> iter 44000, loss: 0.053556
 >> iter 45000, loss: 0.057061
 >> iter 46000, loss: 0.053011
 >> iter 47000, loss: 0.038271
 >> iter 48000, loss: 0.070166
 >> iter 49000, loss: 0.054579
 >> iter 50000, loss: 0.047699
   Number of active neurons: 4
 >> iter 51000, loss: 0.062335
 >> iter 52000, loss: 0.051420
 >> iter 53000, loss: 0.046431
 >> iter 54000, loss: 0.035308
 >> iter 55000, loss: 0.065660
 >> iter 56000, loss: 0.047476
 >> iter 57000, loss: 0.039724
 >> iter 58000, loss: 0.051385
 >> iter 59000, loss: 0.042054
 >> iter 60000, loss: 0.043090
   Number of active neurons: 4
 >> iter 61000, loss: 0.031472
 >> iter 62000, loss: 0.038108
 >> iter 63000, loss: 0.064793
 >> iter 64000, loss: 0.063899
 >> iter 65000, loss: 0.061536
 >> iter 66000, loss: 0.045686
 >> iter 67000, loss: 0.061366
 >> iter 68000, loss: 0.052349
 >> iter 69000, loss: 0.059912
 >> iter 70000, loss: 0.058558
   Number of active neurons: 3
 >> iter 71000, loss: 0.055233
 >> iter 72000, loss: 0.036331
 >> iter 73000, loss: 0.068270
 >> iter 74000, loss: 0.062398
 >> iter 75000, loss: 0.043125
 >> iter 76000, loss: 0.039820
 >> iter 77000, loss: 0.049906
 >> iter 78000, loss: 0.064570
 >> iter 79000, loss: 0.045909
 >> iter 80000, loss: 0.043399
   Number of active neurons: 3
 >> iter 81000, loss: 0.053656
 >> iter 82000, loss: 0.046445
 >> iter 83000, loss: 0.034811
 >> iter 84000, loss: 0.033155
 >> iter 85000, loss: 0.024755
 >> iter 86000, loss: 0.048523
 >> iter 87000, loss: 0.036829
 >> iter 88000, loss: 0.047118
 >> iter 89000, loss: 0.036027
 >> iter 90000, loss: 0.037679
   Number of active neurons: 3
 >> iter 91000, loss: 0.044841
 >> iter 92000, loss: 0.033685
 >> iter 93000, loss: 0.036837
 >> iter 94000, loss: 0.050942
 >> iter 95000, loss: 0.040238
 >> iter 96000, loss: 0.042581
 >> iter 97000, loss: 0.034850
 >> iter 98000, loss: 0.033834
 >> iter 99000, loss: 0.035687
 >> iter 100000, loss: 0.031505
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.344322
 >> iter 2000, loss: 4.472942
 >> iter 3000, loss: 1.808325
 >> iter 4000, loss: 0.740890
 >> iter 5000, loss: 0.362147
 >> iter 6000, loss: 0.210282
 >> iter 7000, loss: 0.140403
 >> iter 8000, loss: 0.106488
 >> iter 9000, loss: 0.115146
 >> iter 10000, loss: 0.123818
   Number of active neurons: 8
 >> iter 11000, loss: 0.103315
 >> iter 12000, loss: 0.087936
 >> iter 13000, loss: 0.064229
 >> iter 14000, loss: 0.063927
 >> iter 15000, loss: 0.069381
 >> iter 16000, loss: 0.080147
 >> iter 17000, loss: 0.068796
 >> iter 18000, loss: 0.070597
 >> iter 19000, loss: 0.058153
 >> iter 20000, loss: 0.083632
   Number of active neurons: 8
 >> iter 21000, loss: 0.055265
 >> iter 22000, loss: 0.067066
 >> iter 23000, loss: 0.057737
 >> iter 24000, loss: 0.058674
 >> iter 25000, loss: 0.045141
 >> iter 26000, loss: 0.057644
 >> iter 27000, loss: 0.048205
 >> iter 28000, loss: 0.038410
 >> iter 29000, loss: 0.045966
 >> iter 30000, loss: 0.051025
   Number of active neurons: 7
 >> iter 31000, loss: 0.075491
 >> iter 32000, loss: 0.054309
 >> iter 33000, loss: 0.063031
 >> iter 34000, loss: 0.051816
 >> iter 35000, loss: 0.054383
 >> iter 36000, loss: 0.054166
 >> iter 37000, loss: 0.056893
 >> iter 38000, loss: 0.042925
 >> iter 39000, loss: 0.047643
 >> iter 40000, loss: 0.037378
   Number of active neurons: 4
 >> iter 41000, loss: 0.067674
 >> iter 42000, loss: 0.059962
 >> iter 43000, loss: 0.059157
 >> iter 44000, loss: 0.048345
 >> iter 45000, loss: 0.043473
 >> iter 46000, loss: 0.039755
 >> iter 47000, loss: 0.049239
 >> iter 48000, loss: 0.043408
 >> iter 49000, loss: 0.039726
 >> iter 50000, loss: 0.060832
   Number of active neurons: 4
 >> iter 51000, loss: 0.049839
 >> iter 52000, loss: 0.058481
 >> iter 53000, loss: 0.067058
 >> iter 54000, loss: 0.061283
 >> iter 55000, loss: 0.047173
 >> iter 56000, loss: 0.040295
 >> iter 57000, loss: 0.034094
 >> iter 58000, loss: 0.047739
 >> iter 59000, loss: 0.049298
 >> iter 60000, loss: 0.048324
   Number of active neurons: 4
 >> iter 61000, loss: 0.047730
 >> iter 62000, loss: 0.038518
 >> iter 63000, loss: 0.059381
 >> iter 64000, loss: 0.046056
 >> iter 65000, loss: 0.054291
 >> iter 66000, loss: 0.048407
 >> iter 67000, loss: 0.041385
 >> iter 68000, loss: 0.064772
 >> iter 69000, loss: 0.053174
 >> iter 70000, loss: 0.061352
   Number of active neurons: 4
 >> iter 71000, loss: 0.071533
 >> iter 72000, loss: 0.069018
 >> iter 73000, loss: 0.053825
 >> iter 74000, loss: 0.047428
 >> iter 75000, loss: 0.046552
 >> iter 76000, loss: 0.033827
 >> iter 77000, loss: 0.061538
 >> iter 78000, loss: 0.061196
 >> iter 79000, loss: 0.062899
 >> iter 80000, loss: 0.049473
   Number of active neurons: 3
 >> iter 81000, loss: 0.037358
 >> iter 82000, loss: 0.047545
 >> iter 83000, loss: 0.052956
 >> iter 84000, loss: 0.048796
 >> iter 85000, loss: 0.078512
 >> iter 86000, loss: 0.069125
 >> iter 87000, loss: 0.051276
 >> iter 88000, loss: 0.045125
 >> iter 89000, loss: 0.051523
 >> iter 90000, loss: 0.053204
   Number of active neurons: 3
 >> iter 91000, loss: 0.052341
 >> iter 92000, loss: 0.046709
 >> iter 93000, loss: 0.045382
 >> iter 94000, loss: 0.049320
 >> iter 95000, loss: 0.055881
 >> iter 96000, loss: 0.045684
 >> iter 97000, loss: 0.068831
 >> iter 98000, loss: 0.048442
 >> iter 99000, loss: 0.058457
 >> iter 100000, loss: 0.045568
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455162
   Number of active neurons: 0
 >> iter 1000, loss: 11.288258
 >> iter 2000, loss: 4.412444
 >> iter 3000, loss: 1.801414
 >> iter 4000, loss: 0.777059
 >> iter 5000, loss: 0.366237
 >> iter 6000, loss: 0.212024
 >> iter 7000, loss: 0.170870
 >> iter 8000, loss: 0.121030
 >> iter 9000, loss: 0.112993
 >> iter 10000, loss: 0.106935
   Number of active neurons: 9
 >> iter 11000, loss: 0.115830
 >> iter 12000, loss: 0.099203
 >> iter 13000, loss: 0.082046
 >> iter 14000, loss: 0.076935
 >> iter 15000, loss: 0.068316
 >> iter 16000, loss: 0.080197
 >> iter 17000, loss: 0.072396
 >> iter 18000, loss: 0.088961
 >> iter 19000, loss: 0.100014
 >> iter 20000, loss: 0.080915
   Number of active neurons: 9
 >> iter 21000, loss: 0.070587
 >> iter 22000, loss: 0.078926
 >> iter 23000, loss: 0.071785
 >> iter 24000, loss: 0.068595
 >> iter 25000, loss: 0.066282
 >> iter 26000, loss: 0.077750
 >> iter 27000, loss: 0.066327
 >> iter 28000, loss: 0.063896
 >> iter 29000, loss: 0.069887
 >> iter 30000, loss: 0.057580
   Number of active neurons: 8
 >> iter 31000, loss: 0.061763
 >> iter 32000, loss: 0.081083
 >> iter 33000, loss: 0.066920
 >> iter 34000, loss: 0.061298
 >> iter 35000, loss: 0.073631
 >> iter 36000, loss: 0.068661
 >> iter 37000, loss: 0.076349
 >> iter 38000, loss: 0.064233
 >> iter 39000, loss: 0.068951
 >> iter 40000, loss: 0.057862
   Number of active neurons: 5
 >> iter 41000, loss: 0.049255
 >> iter 42000, loss: 0.059697
 >> iter 43000, loss: 0.065292
 >> iter 44000, loss: 0.052603
 >> iter 45000, loss: 0.054674
 >> iter 46000, loss: 0.067138
 >> iter 47000, loss: 0.074417
 >> iter 48000, loss: 0.073927
 >> iter 49000, loss: 0.062179
 >> iter 50000, loss: 0.050585
   Number of active neurons: 5
 >> iter 51000, loss: 0.053530
 >> iter 52000, loss: 0.057026
 >> iter 53000, loss: 0.047073
 >> iter 54000, loss: 0.065190
 >> iter 55000, loss: 0.057615
 >> iter 56000, loss: 0.053006
 >> iter 57000, loss: 0.050071
 >> iter 58000, loss: 0.045322
 >> iter 59000, loss: 0.040066
 >> iter 60000, loss: 0.056382
   Number of active neurons: 5
 >> iter 61000, loss: 0.058091
 >> iter 62000, loss: 0.070234
 >> iter 63000, loss: 0.061115
 >> iter 64000, loss: 0.061025
 >> iter 65000, loss: 0.046823
 >> iter 66000, loss: 0.044304
 >> iter 67000, loss: 0.037782
 >> iter 68000, loss: 0.049560
 >> iter 69000, loss: 0.042839
 >> iter 70000, loss: 0.047882
   Number of active neurons: 4
 >> iter 71000, loss: 0.056311
 >> iter 72000, loss: 0.063491
 >> iter 73000, loss: 0.061212
 >> iter 74000, loss: 0.053098
 >> iter 75000, loss: 0.053831
 >> iter 76000, loss: 0.046003
 >> iter 77000, loss: 0.039248
 >> iter 78000, loss: 0.044974
 >> iter 79000, loss: 0.058517
 >> iter 80000, loss: 0.050744
   Number of active neurons: 4
 >> iter 81000, loss: 0.045763
 >> iter 82000, loss: 0.042623
 >> iter 83000, loss: 0.039944
 >> iter 84000, loss: 0.035000
 >> iter 85000, loss: 0.047011
 >> iter 86000, loss: 0.043121
 >> iter 87000, loss: 0.044679
 >> iter 88000, loss: 0.048135
 >> iter 89000, loss: 0.040872
 >> iter 90000, loss: 0.044323
   Number of active neurons: 3
 >> iter 91000, loss: 0.045888
 >> iter 92000, loss: 0.062589
 >> iter 93000, loss: 0.047129
 >> iter 94000, loss: 0.045113
 >> iter 95000, loss: 0.045337
 >> iter 96000, loss: 0.041291
 >> iter 97000, loss: 0.037672
 >> iter 98000, loss: 0.036278
 >> iter 99000, loss: 0.041096
 >> iter 100000, loss: 0.054388
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 11.335840
 >> iter 2000, loss: 4.423684
 >> iter 3000, loss: 1.761654
 >> iter 4000, loss: 0.731038
 >> iter 5000, loss: 0.359015
 >> iter 6000, loss: 0.225830
 >> iter 7000, loss: 0.136123
 >> iter 8000, loss: 0.107783
 >> iter 9000, loss: 0.103444
 >> iter 10000, loss: 0.104429
   Number of active neurons: 10
 >> iter 11000, loss: 0.084088
 >> iter 12000, loss: 0.070268
 >> iter 13000, loss: 0.064106
 >> iter 14000, loss: 0.073594
 >> iter 15000, loss: 0.055734
 >> iter 16000, loss: 0.062019
 >> iter 17000, loss: 0.062070
 >> iter 18000, loss: 0.049260
 >> iter 19000, loss: 0.057142
 >> iter 20000, loss: 0.069160
   Number of active neurons: 7
 >> iter 21000, loss: 0.081577
 >> iter 22000, loss: 0.074264
 >> iter 23000, loss: 0.076817
 >> iter 24000, loss: 0.075314
 >> iter 25000, loss: 0.072101
 >> iter 26000, loss: 0.054746
 >> iter 27000, loss: 0.070743
 >> iter 28000, loss: 0.052276
 >> iter 29000, loss: 0.039237
 >> iter 30000, loss: 0.040572
   Number of active neurons: 5
 >> iter 31000, loss: 0.037888
 >> iter 32000, loss: 0.043313
 >> iter 33000, loss: 0.040853
 >> iter 34000, loss: 0.052514
 >> iter 35000, loss: 0.052380
 >> iter 36000, loss: 0.046994
 >> iter 37000, loss: 0.058030
 >> iter 38000, loss: 0.042827
 >> iter 39000, loss: 0.064330
 >> iter 40000, loss: 0.055022
   Number of active neurons: 5
 >> iter 41000, loss: 0.071718
 >> iter 42000, loss: 0.065466
 >> iter 43000, loss: 0.052470
 >> iter 44000, loss: 0.042400
 >> iter 45000, loss: 0.051035
 >> iter 46000, loss: 0.064149
 >> iter 47000, loss: 0.053869
 >> iter 48000, loss: 0.060492
 >> iter 49000, loss: 0.042573
 >> iter 50000, loss: 0.046130
   Number of active neurons: 5
 >> iter 51000, loss: 0.040487
 >> iter 52000, loss: 0.063314
 >> iter 53000, loss: 0.051546
 >> iter 54000, loss: 0.046330
 >> iter 55000, loss: 0.051384
 >> iter 56000, loss: 0.039496
 >> iter 57000, loss: 0.040828
 >> iter 58000, loss: 0.041828
 >> iter 59000, loss: 0.051968
 >> iter 60000, loss: 0.057781
   Number of active neurons: 3
 >> iter 61000, loss: 0.050973
 >> iter 62000, loss: 0.055790
 >> iter 63000, loss: 0.062852
 >> iter 64000, loss: 0.055072
 >> iter 65000, loss: 0.043016
 >> iter 66000, loss: 0.036265
 >> iter 67000, loss: 0.037341
 >> iter 68000, loss: 0.044091
 >> iter 69000, loss: 0.057341
 >> iter 70000, loss: 0.043000
   Number of active neurons: 3
 >> iter 71000, loss: 0.035944
 >> iter 72000, loss: 0.033155
 >> iter 73000, loss: 0.030233
 >> iter 74000, loss: 0.056984
 >> iter 75000, loss: 0.041299
 >> iter 76000, loss: 0.051039
 >> iter 77000, loss: 0.059224
 >> iter 78000, loss: 0.047553
 >> iter 79000, loss: 0.058546
 >> iter 80000, loss: 0.048884
   Number of active neurons: 3
 >> iter 81000, loss: 0.047365
 >> iter 82000, loss: 0.033626
 >> iter 83000, loss: 0.037483
 >> iter 84000, loss: 0.047855
 >> iter 85000, loss: 0.077510
 >> iter 86000, loss: 0.062982
 >> iter 87000, loss: 0.062518
 >> iter 88000, loss: 0.055130
 >> iter 89000, loss: 0.040938
 >> iter 90000, loss: 0.034986
   Number of active neurons: 2
 >> iter 91000, loss: 0.037363
 >> iter 92000, loss: 0.032970
 >> iter 93000, loss: 0.055482
 >> iter 94000, loss: 0.052011
 >> iter 95000, loss: 0.068854
 >> iter 96000, loss: 0.047746
 >> iter 97000, loss: 0.037347
 >> iter 98000, loss: 0.053504
 >> iter 99000, loss: 0.063198
 >> iter 100000, loss: 0.043998
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.289881
 >> iter 2000, loss: 4.459897
 >> iter 3000, loss: 1.810550
 >> iter 4000, loss: 0.753647
 >> iter 5000, loss: 0.355455
 >> iter 6000, loss: 0.193243
 >> iter 7000, loss: 0.129136
 >> iter 8000, loss: 0.113223
 >> iter 9000, loss: 0.094026
 >> iter 10000, loss: 0.075142
   Number of active neurons: 9
 >> iter 11000, loss: 0.062689
 >> iter 12000, loss: 0.085078
 >> iter 13000, loss: 0.076757
 >> iter 14000, loss: 0.083714
 >> iter 15000, loss: 0.069802
 >> iter 16000, loss: 0.070890
 >> iter 17000, loss: 0.075145
 >> iter 18000, loss: 0.069409
 >> iter 19000, loss: 0.058589
 >> iter 20000, loss: 0.070771
   Number of active neurons: 8
 >> iter 21000, loss: 0.062252
 >> iter 22000, loss: 0.058822
 >> iter 23000, loss: 0.072539
 >> iter 24000, loss: 0.062015
 >> iter 25000, loss: 0.066938
 >> iter 26000, loss: 0.061545
 >> iter 27000, loss: 0.057838
 >> iter 28000, loss: 0.046847
 >> iter 29000, loss: 0.050151
 >> iter 30000, loss: 0.042834
   Number of active neurons: 6
 >> iter 31000, loss: 0.049032
 >> iter 32000, loss: 0.051513
 >> iter 33000, loss: 0.035724
 >> iter 34000, loss: 0.043806
 >> iter 35000, loss: 0.044576
 >> iter 36000, loss: 0.052983
 >> iter 37000, loss: 0.045003
 >> iter 38000, loss: 0.047212
 >> iter 39000, loss: 0.044133
 >> iter 40000, loss: 0.040578
   Number of active neurons: 5
 >> iter 41000, loss: 0.041221
 >> iter 42000, loss: 0.048517
 >> iter 43000, loss: 0.067379
 >> iter 44000, loss: 0.047040
 >> iter 45000, loss: 0.047061
 >> iter 46000, loss: 0.040069
 >> iter 47000, loss: 0.036966
 >> iter 48000, loss: 0.036127
 >> iter 49000, loss: 0.058425
 >> iter 50000, loss: 0.047658
   Number of active neurons: 3
 >> iter 51000, loss: 0.056098
 >> iter 52000, loss: 0.057352
 >> iter 53000, loss: 0.084095
 >> iter 54000, loss: 0.075742
 >> iter 55000, loss: 0.050824
 >> iter 56000, loss: 0.037469
 >> iter 57000, loss: 0.042908
 >> iter 58000, loss: 0.032232
 >> iter 59000, loss: 0.031655
 >> iter 60000, loss: 0.036941
   Number of active neurons: 3
 >> iter 61000, loss: 0.030469
 >> iter 62000, loss: 0.057404
 >> iter 63000, loss: 0.056761
 >> iter 64000, loss: 0.037961
 >> iter 65000, loss: 0.030017
 >> iter 66000, loss: 0.039219
 >> iter 67000, loss: 0.039585
 >> iter 68000, loss: 0.031615
 >> iter 69000, loss: 0.046123
 >> iter 70000, loss: 0.045142
   Number of active neurons: 2
 >> iter 71000, loss: 0.041778
 >> iter 72000, loss: 0.041092
 >> iter 73000, loss: 0.031197
 >> iter 74000, loss: 0.050260
 >> iter 75000, loss: 0.040726
 >> iter 76000, loss: 0.046585
 >> iter 77000, loss: 0.074120
 >> iter 78000, loss: 0.044450
 >> iter 79000, loss: 0.052538
 >> iter 80000, loss: 0.038316
   Number of active neurons: 2
 >> iter 81000, loss: 0.038965
 >> iter 82000, loss: 0.035811
 >> iter 83000, loss: 0.039586
 >> iter 84000, loss: 0.051744
 >> iter 85000, loss: 0.061672
 >> iter 86000, loss: 0.042631
 >> iter 87000, loss: 0.032941
 >> iter 88000, loss: 0.043461
 >> iter 89000, loss: 0.043726
 >> iter 90000, loss: 0.042555
   Number of active neurons: 2
 >> iter 91000, loss: 0.041834
 >> iter 92000, loss: 0.044348
 >> iter 93000, loss: 0.077537
 >> iter 94000, loss: 0.056886
 >> iter 95000, loss: 0.042236
 >> iter 96000, loss: 0.050220
 >> iter 97000, loss: 0.032425
 >> iter 98000, loss: 0.036941
 >> iter 99000, loss: 0.038603
 >> iter 100000, loss: 0.043148
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.343500
 >> iter 2000, loss: 4.479037
 >> iter 3000, loss: 1.818791
 >> iter 4000, loss: 0.789676
 >> iter 5000, loss: 0.347100
 >> iter 6000, loss: 0.186068
 >> iter 7000, loss: 0.143003
 >> iter 8000, loss: 0.105820
 >> iter 9000, loss: 0.085045
 >> iter 10000, loss: 0.078095
   Number of active neurons: 9
 >> iter 11000, loss: 0.073337
 >> iter 12000, loss: 0.088154
 >> iter 13000, loss: 0.082185
 >> iter 14000, loss: 0.072236
 >> iter 15000, loss: 0.065557
 >> iter 16000, loss: 0.066237
 >> iter 17000, loss: 0.054569
 >> iter 18000, loss: 0.052988
 >> iter 19000, loss: 0.065428
 >> iter 20000, loss: 0.044342
   Number of active neurons: 7
 >> iter 21000, loss: 0.070790
 >> iter 22000, loss: 0.057662
 >> iter 23000, loss: 0.062255
 >> iter 24000, loss: 0.055472
 >> iter 25000, loss: 0.083659
 >> iter 26000, loss: 0.062627
 >> iter 27000, loss: 0.066465
 >> iter 28000, loss: 0.049446
 >> iter 29000, loss: 0.059210
 >> iter 30000, loss: 0.076250
   Number of active neurons: 4
 >> iter 31000, loss: 0.070536
 >> iter 32000, loss: 0.065006
 >> iter 33000, loss: 0.057208
 >> iter 34000, loss: 0.042458
 >> iter 35000, loss: 0.045173
 >> iter 36000, loss: 0.046380
 >> iter 37000, loss: 0.053314
 >> iter 38000, loss: 0.043948
 >> iter 39000, loss: 0.050469
 >> iter 40000, loss: 0.081695
   Number of active neurons: 4
 >> iter 41000, loss: 0.069640
 >> iter 42000, loss: 0.060195
 >> iter 43000, loss: 0.037686
 >> iter 44000, loss: 0.037492
 >> iter 45000, loss: 0.040252
 >> iter 46000, loss: 0.039037
 >> iter 47000, loss: 0.036169
 >> iter 48000, loss: 0.048350
 >> iter 49000, loss: 0.037951
 >> iter 50000, loss: 0.048739
   Number of active neurons: 4
 >> iter 51000, loss: 0.053767
 >> iter 52000, loss: 0.045898
 >> iter 53000, loss: 0.035278
 >> iter 54000, loss: 0.041854
 >> iter 55000, loss: 0.029965
 >> iter 56000, loss: 0.051030
 >> iter 57000, loss: 0.057416
 >> iter 58000, loss: 0.051098
 >> iter 59000, loss: 0.058702
 >> iter 60000, loss: 0.043402
   Number of active neurons: 4
 >> iter 61000, loss: 0.038123
 >> iter 62000, loss: 0.044424
 >> iter 63000, loss: 0.039986
 >> iter 64000, loss: 0.060212
 >> iter 65000, loss: 0.047773
 >> iter 66000, loss: 0.040595
 >> iter 67000, loss: 0.049671
 >> iter 68000, loss: 0.048743
 >> iter 69000, loss: 0.038757
 >> iter 70000, loss: 0.052435
   Number of active neurons: 4
 >> iter 71000, loss: 0.058345
 >> iter 72000, loss: 0.046839
 >> iter 73000, loss: 0.038796
 >> iter 74000, loss: 0.034688
 >> iter 75000, loss: 0.041049
 >> iter 76000, loss: 0.042393
 >> iter 77000, loss: 0.042796
 >> iter 78000, loss: 0.036272
 >> iter 79000, loss: 0.036891
 >> iter 80000, loss: 0.041016
   Number of active neurons: 4
 >> iter 81000, loss: 0.040815
 >> iter 82000, loss: 0.055641
 >> iter 83000, loss: 0.049061
 >> iter 84000, loss: 0.044857
 >> iter 85000, loss: 0.057408
 >> iter 86000, loss: 0.038267
 >> iter 87000, loss: 0.044251
 >> iter 88000, loss: 0.048544
 >> iter 89000, loss: 0.042343
 >> iter 90000, loss: 0.036206
   Number of active neurons: 3
 >> iter 91000, loss: 0.037783
 >> iter 92000, loss: 0.034284
 >> iter 93000, loss: 0.035979
 >> iter 94000, loss: 0.039067
 >> iter 95000, loss: 0.037984
 >> iter 96000, loss: 0.036550
 >> iter 97000, loss: 0.066744
 >> iter 98000, loss: 0.048052
 >> iter 99000, loss: 0.041661
 >> iter 100000, loss: 0.053254
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.338840
 >> iter 2000, loss: 4.491503
 >> iter 3000, loss: 1.778766
 >> iter 4000, loss: 0.785364
 >> iter 5000, loss: 0.366493
 >> iter 6000, loss: 0.189314
 >> iter 7000, loss: 0.138651
 >> iter 8000, loss: 0.120858
 >> iter 9000, loss: 0.090484
 >> iter 10000, loss: 0.089167
   Number of active neurons: 12
 >> iter 11000, loss: 0.073350
 >> iter 12000, loss: 0.066586
 >> iter 13000, loss: 0.072804
 >> iter 14000, loss: 0.072393
 >> iter 15000, loss: 0.060891
 >> iter 16000, loss: 0.079543
 >> iter 17000, loss: 0.084098
 >> iter 18000, loss: 0.060617
 >> iter 19000, loss: 0.087801
 >> iter 20000, loss: 0.058751
   Number of active neurons: 7
 >> iter 21000, loss: 0.075619
 >> iter 22000, loss: 0.058639
 >> iter 23000, loss: 0.054874
 >> iter 24000, loss: 0.046205
 >> iter 25000, loss: 0.056695
 >> iter 26000, loss: 0.043318
 >> iter 27000, loss: 0.039465
 >> iter 28000, loss: 0.038388
 >> iter 29000, loss: 0.042186
 >> iter 30000, loss: 0.045112
   Number of active neurons: 4
 >> iter 31000, loss: 0.039073
 >> iter 32000, loss: 0.052274
 >> iter 33000, loss: 0.055012
 >> iter 34000, loss: 0.039654
 >> iter 35000, loss: 0.055405
 >> iter 36000, loss: 0.039429
 >> iter 37000, loss: 0.068989
 >> iter 38000, loss: 0.063135
 >> iter 39000, loss: 0.062973
 >> iter 40000, loss: 0.056973
   Number of active neurons: 3
 >> iter 41000, loss: 0.045968
 >> iter 42000, loss: 0.042601
 >> iter 43000, loss: 0.043356
 >> iter 44000, loss: 0.031486
 >> iter 45000, loss: 0.039774
 >> iter 46000, loss: 0.039582
 >> iter 47000, loss: 0.054283
 >> iter 48000, loss: 0.039016
 >> iter 49000, loss: 0.043807
 >> iter 50000, loss: 0.043125
   Number of active neurons: 2
 >> iter 51000, loss: 0.028415
 >> iter 52000, loss: 0.024802
 >> iter 53000, loss: 0.027313
 >> iter 54000, loss: 0.041461
 >> iter 55000, loss: 0.033974
 >> iter 56000, loss: 0.042443
 >> iter 57000, loss: 0.050405
 >> iter 58000, loss: 0.067308
 >> iter 59000, loss: 0.063360
 >> iter 60000, loss: 0.058894
   Number of active neurons: 2
 >> iter 61000, loss: 0.053961
 >> iter 62000, loss: 0.069978
 >> iter 63000, loss: 0.050549
 >> iter 64000, loss: 0.038923
 >> iter 65000, loss: 0.046182
 >> iter 66000, loss: 0.042462
 >> iter 67000, loss: 0.052611
 >> iter 68000, loss: 0.043957
 >> iter 69000, loss: 0.033012
 >> iter 70000, loss: 0.025212
   Number of active neurons: 2
 >> iter 71000, loss: 0.045434
 >> iter 72000, loss: 0.052567
 >> iter 73000, loss: 0.049347
 >> iter 74000, loss: 0.049937
 >> iter 75000, loss: 0.049525
 >> iter 76000, loss: 0.047516
 >> iter 77000, loss: 0.036841
 >> iter 78000, loss: 0.040175
 >> iter 79000, loss: 0.041219
 >> iter 80000, loss: 0.058235
   Number of active neurons: 2
 >> iter 81000, loss: 0.036596
 >> iter 82000, loss: 0.046226
 >> iter 83000, loss: 0.052091
 >> iter 84000, loss: 0.051887
 >> iter 85000, loss: 0.064940
 >> iter 86000, loss: 0.062548
 >> iter 87000, loss: 0.052562
 >> iter 88000, loss: 0.048948
 >> iter 89000, loss: 0.045086
 >> iter 90000, loss: 0.040951
   Number of active neurons: 2
 >> iter 91000, loss: 0.043243
 >> iter 92000, loss: 0.036849
 >> iter 93000, loss: 0.038138
 >> iter 94000, loss: 0.072905
 >> iter 95000, loss: 0.067980
 >> iter 96000, loss: 0.047421
 >> iter 97000, loss: 0.044724
 >> iter 98000, loss: 0.050618
 >> iter 99000, loss: 0.032008
 >> iter 100000, loss: 0.027959
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455161
   Number of active neurons: 0
 >> iter 1000, loss: 11.334923
 >> iter 2000, loss: 4.498129
 >> iter 3000, loss: 1.851827
 >> iter 4000, loss: 0.758582
 >> iter 5000, loss: 0.358859
 >> iter 6000, loss: 0.203257
 >> iter 7000, loss: 0.130708
 >> iter 8000, loss: 0.098319
 >> iter 9000, loss: 0.088561
 >> iter 10000, loss: 0.060721
   Number of active neurons: 9
 >> iter 11000, loss: 0.076044
 >> iter 12000, loss: 0.097942
 >> iter 13000, loss: 0.079908
 >> iter 14000, loss: 0.062150
 >> iter 15000, loss: 0.056281
 >> iter 16000, loss: 0.059834
 >> iter 17000, loss: 0.053690
 >> iter 18000, loss: 0.047263
 >> iter 19000, loss: 0.061687
 >> iter 20000, loss: 0.065230
   Number of active neurons: 7
 >> iter 21000, loss: 0.074155
 >> iter 22000, loss: 0.059131
 >> iter 23000, loss: 0.048518
 >> iter 24000, loss: 0.049830
 >> iter 25000, loss: 0.062212
 >> iter 26000, loss: 0.054429
 >> iter 27000, loss: 0.049022
 >> iter 28000, loss: 0.057694
 >> iter 29000, loss: 0.046120
 >> iter 30000, loss: 0.066019
   Number of active neurons: 5
 >> iter 31000, loss: 0.044607
 >> iter 32000, loss: 0.047192
 >> iter 33000, loss: 0.048640
 >> iter 34000, loss: 0.039419
 >> iter 35000, loss: 0.043547
 >> iter 36000, loss: 0.040009
 >> iter 37000, loss: 0.036808
 >> iter 38000, loss: 0.039040
 >> iter 39000, loss: 0.055976
 >> iter 40000, loss: 0.059138
   Number of active neurons: 4
 >> iter 41000, loss: 0.048871
 >> iter 42000, loss: 0.058426
 >> iter 43000, loss: 0.043930
 >> iter 44000, loss: 0.041507
 >> iter 45000, loss: 0.038653
 >> iter 46000, loss: 0.044075
 >> iter 47000, loss: 0.046165
 >> iter 48000, loss: 0.036289
 >> iter 49000, loss: 0.065649
 >> iter 50000, loss: 0.054618
   Number of active neurons: 3
 >> iter 51000, loss: 0.054773
 >> iter 52000, loss: 0.048980
 >> iter 53000, loss: 0.054857
 >> iter 54000, loss: 0.066408
 >> iter 55000, loss: 0.051122
 >> iter 56000, loss: 0.055253
 >> iter 57000, loss: 0.036425
 >> iter 58000, loss: 0.054584
 >> iter 59000, loss: 0.041100
 >> iter 60000, loss: 0.045298
   Number of active neurons: 3
 >> iter 61000, loss: 0.078798
 >> iter 62000, loss: 0.061446
 >> iter 63000, loss: 0.076111
 >> iter 64000, loss: 0.063626
 >> iter 65000, loss: 0.048294
 >> iter 66000, loss: 0.044409
 >> iter 67000, loss: 0.056606
 >> iter 68000, loss: 0.045163
 >> iter 69000, loss: 0.037664
 >> iter 70000, loss: 0.050433
   Number of active neurons: 3
 >> iter 71000, loss: 0.054594
 >> iter 72000, loss: 0.054962
 >> iter 73000, loss: 0.045350
 >> iter 74000, loss: 0.045115
 >> iter 75000, loss: 0.042507
 >> iter 76000, loss: 0.049231
 >> iter 77000, loss: 0.050463
 >> iter 78000, loss: 0.047198
 >> iter 79000, loss: 0.044464
 >> iter 80000, loss: 0.035265
   Number of active neurons: 3
 >> iter 81000, loss: 0.042465
 >> iter 82000, loss: 0.034763
 >> iter 83000, loss: 0.038546
 >> iter 84000, loss: 0.042747
 >> iter 85000, loss: 0.044498
 >> iter 86000, loss: 0.047807
 >> iter 87000, loss: 0.045052
 >> iter 88000, loss: 0.047144
 >> iter 89000, loss: 0.031455
 >> iter 90000, loss: 0.054506
   Number of active neurons: 3
 >> iter 91000, loss: 0.072349
 >> iter 92000, loss: 0.059088
 >> iter 93000, loss: 0.051120
 >> iter 94000, loss: 0.042384
 >> iter 95000, loss: 0.041323
 >> iter 96000, loss: 0.035438
 >> iter 97000, loss: 0.039899
 >> iter 98000, loss: 0.036309
 >> iter 99000, loss: 0.040858
 >> iter 100000, loss: 0.038825
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 11.297819
 >> iter 2000, loss: 4.419637
 >> iter 3000, loss: 1.764566
 >> iter 4000, loss: 0.748207
 >> iter 5000, loss: 0.353186
 >> iter 6000, loss: 0.177103
 >> iter 7000, loss: 0.164701
 >> iter 8000, loss: 0.107920
 >> iter 9000, loss: 0.086892
 >> iter 10000, loss: 0.071459
   Number of active neurons: 8
 >> iter 11000, loss: 0.079538
 >> iter 12000, loss: 0.104604
 >> iter 13000, loss: 0.077797
 >> iter 14000, loss: 0.079761
 >> iter 15000, loss: 0.073826
 >> iter 16000, loss: 0.057018
 >> iter 17000, loss: 0.057077
 >> iter 18000, loss: 0.052311
 >> iter 19000, loss: 0.045435
 >> iter 20000, loss: 0.049629
   Number of active neurons: 6
 >> iter 21000, loss: 0.062322
 >> iter 22000, loss: 0.056461
 >> iter 23000, loss: 0.046772
 >> iter 24000, loss: 0.045796
 >> iter 25000, loss: 0.043708
 >> iter 26000, loss: 0.048984
 >> iter 27000, loss: 0.050010
 >> iter 28000, loss: 0.040743
 >> iter 29000, loss: 0.048636
 >> iter 30000, loss: 0.060147
   Number of active neurons: 6
 >> iter 31000, loss: 0.070877
 >> iter 32000, loss: 0.053082
 >> iter 33000, loss: 0.041272
 >> iter 34000, loss: 0.055849
 >> iter 35000, loss: 0.044084
 >> iter 36000, loss: 0.040440
 >> iter 37000, loss: 0.042755
 >> iter 38000, loss: 0.044291
 >> iter 39000, loss: 0.046696
 >> iter 40000, loss: 0.054740
   Number of active neurons: 6
 >> iter 41000, loss: 0.047044
 >> iter 42000, loss: 0.040235
 >> iter 43000, loss: 0.055528
 >> iter 44000, loss: 0.051880
 >> iter 45000, loss: 0.050808
 >> iter 46000, loss: 0.050477
 >> iter 47000, loss: 0.056320
 >> iter 48000, loss: 0.045959
 >> iter 49000, loss: 0.062555
 >> iter 50000, loss: 0.072463
   Number of active neurons: 5
 >> iter 51000, loss: 0.056800
 >> iter 52000, loss: 0.044816
 >> iter 53000, loss: 0.049313
 >> iter 54000, loss: 0.080080
 >> iter 55000, loss: 0.072219
 >> iter 56000, loss: 0.048911
 >> iter 57000, loss: 0.069947
 >> iter 58000, loss: 0.059864
 >> iter 59000, loss: 0.044826
 >> iter 60000, loss: 0.038127
   Number of active neurons: 4
 >> iter 61000, loss: 0.049633
 >> iter 62000, loss: 0.053165
 >> iter 63000, loss: 0.053760
 >> iter 64000, loss: 0.073889
 >> iter 65000, loss: 0.065195
 >> iter 66000, loss: 0.066610
 >> iter 67000, loss: 0.064841
 >> iter 68000, loss: 0.055057
 >> iter 69000, loss: 0.067786
 >> iter 70000, loss: 0.051685
   Number of active neurons: 4
 >> iter 71000, loss: 0.046726
 >> iter 72000, loss: 0.050455
 >> iter 73000, loss: 0.048972
 >> iter 74000, loss: 0.053214
 >> iter 75000, loss: 0.040458
 >> iter 76000, loss: 0.034967
 >> iter 77000, loss: 0.049445
 >> iter 78000, loss: 0.039418
 >> iter 79000, loss: 0.037355
 >> iter 80000, loss: 0.046451
   Number of active neurons: 3
 >> iter 81000, loss: 0.049509
 >> iter 82000, loss: 0.061466
 >> iter 83000, loss: 0.048033
 >> iter 84000, loss: 0.042150
 >> iter 85000, loss: 0.034883
 >> iter 86000, loss: 0.057271
 >> iter 87000, loss: 0.042083
 >> iter 88000, loss: 0.034657
 >> iter 89000, loss: 0.039503
 >> iter 90000, loss: 0.037942
   Number of active neurons: 3
 >> iter 91000, loss: 0.047821
 >> iter 92000, loss: 0.055383
 >> iter 93000, loss: 0.043213
 >> iter 94000, loss: 0.033889
 >> iter 95000, loss: 0.051189
 >> iter 96000, loss: 0.040058
 >> iter 97000, loss: 0.064060
 >> iter 98000, loss: 0.059664
 >> iter 99000, loss: 0.057194
 >> iter 100000, loss: 0.044139
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.323092
 >> iter 2000, loss: 4.474396
 >> iter 3000, loss: 1.751010
 >> iter 4000, loss: 0.747130
 >> iter 5000, loss: 0.357860
 >> iter 6000, loss: 0.192946
 >> iter 7000, loss: 0.140155
 >> iter 8000, loss: 0.105028
 >> iter 9000, loss: 0.108770
 >> iter 10000, loss: 0.107990
   Number of active neurons: 9
 >> iter 11000, loss: 0.082496
 >> iter 12000, loss: 0.086732
 >> iter 13000, loss: 0.081368
 >> iter 14000, loss: 0.086271
 >> iter 15000, loss: 0.066099
 >> iter 16000, loss: 0.056385
 >> iter 17000, loss: 0.070619
 >> iter 18000, loss: 0.079574
 >> iter 19000, loss: 0.077906
 >> iter 20000, loss: 0.077846
   Number of active neurons: 7
 >> iter 21000, loss: 0.069634
 >> iter 22000, loss: 0.053411
 >> iter 23000, loss: 0.063803
 >> iter 24000, loss: 0.059793
 >> iter 25000, loss: 0.065644
 >> iter 26000, loss: 0.049779
 >> iter 27000, loss: 0.047735
 >> iter 28000, loss: 0.053999
 >> iter 29000, loss: 0.047438
 >> iter 30000, loss: 0.058569
   Number of active neurons: 6
 >> iter 31000, loss: 0.062110
 >> iter 32000, loss: 0.052703
 >> iter 33000, loss: 0.056174
 >> iter 34000, loss: 0.040187
 >> iter 35000, loss: 0.037743
 >> iter 36000, loss: 0.043292
 >> iter 37000, loss: 0.052583
 >> iter 38000, loss: 0.062959
 >> iter 39000, loss: 0.052587
 >> iter 40000, loss: 0.060584
   Number of active neurons: 5
 >> iter 41000, loss: 0.060131
 >> iter 42000, loss: 0.042961
 >> iter 43000, loss: 0.040881
 >> iter 44000, loss: 0.048188
 >> iter 45000, loss: 0.059969
 >> iter 46000, loss: 0.057882
 >> iter 47000, loss: 0.038849
 >> iter 48000, loss: 0.051056
 >> iter 49000, loss: 0.046614
 >> iter 50000, loss: 0.050594
   Number of active neurons: 4
 >> iter 51000, loss: 0.051111
 >> iter 52000, loss: 0.044252
 >> iter 53000, loss: 0.040734
 >> iter 54000, loss: 0.051916
 >> iter 55000, loss: 0.067578
 >> iter 56000, loss: 0.053713
 >> iter 57000, loss: 0.043675
 >> iter 58000, loss: 0.043605
 >> iter 59000, loss: 0.038922
 >> iter 60000, loss: 0.035855
   Number of active neurons: 4
 >> iter 61000, loss: 0.051095
 >> iter 62000, loss: 0.056148
 >> iter 63000, loss: 0.061056
 >> iter 64000, loss: 0.045002
 >> iter 65000, loss: 0.040097
 >> iter 66000, loss: 0.036226
 >> iter 67000, loss: 0.078674
 >> iter 68000, loss: 0.090582
 >> iter 69000, loss: 0.060711
 >> iter 70000, loss: 0.062644
   Number of active neurons: 4
 >> iter 71000, loss: 0.054855
 >> iter 72000, loss: 0.043488
 >> iter 73000, loss: 0.039396
 >> iter 74000, loss: 0.044649
 >> iter 75000, loss: 0.036753
 >> iter 76000, loss: 0.056434
 >> iter 77000, loss: 0.040165
 >> iter 78000, loss: 0.058034
 >> iter 79000, loss: 0.062230
 >> iter 80000, loss: 0.053300
   Number of active neurons: 4
 >> iter 81000, loss: 0.051276
 >> iter 82000, loss: 0.077139
 >> iter 83000, loss: 0.068856
 >> iter 84000, loss: 0.067784
 >> iter 85000, loss: 0.063426
 >> iter 86000, loss: 0.053887
 >> iter 87000, loss: 0.046279
 >> iter 88000, loss: 0.045716
 >> iter 89000, loss: 0.053890
 >> iter 90000, loss: 0.052912
   Number of active neurons: 4
 >> iter 91000, loss: 0.037009
 >> iter 92000, loss: 0.060863
 >> iter 93000, loss: 0.067418
 >> iter 94000, loss: 0.040959
 >> iter 95000, loss: 0.034780
 >> iter 96000, loss: 0.035366
 >> iter 97000, loss: 0.065063
 >> iter 98000, loss: 0.059418
 >> iter 99000, loss: 0.060167
 >> iter 100000, loss: 0.051008
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.309215
 >> iter 2000, loss: 4.462003
 >> iter 3000, loss: 1.796474
 >> iter 4000, loss: 0.773034
 >> iter 5000, loss: 0.392746
 >> iter 6000, loss: 0.222416
 >> iter 7000, loss: 0.144530
 >> iter 8000, loss: 0.109926
 >> iter 9000, loss: 0.099093
 >> iter 10000, loss: 0.095096
   Number of active neurons: 10
 >> iter 11000, loss: 0.096742
 >> iter 12000, loss: 0.087987
 >> iter 13000, loss: 0.068956
 >> iter 14000, loss: 0.065899
 >> iter 15000, loss: 0.070436
 >> iter 16000, loss: 0.077447
 >> iter 17000, loss: 0.065482
 >> iter 18000, loss: 0.071731
 >> iter 19000, loss: 0.086589
 >> iter 20000, loss: 0.079040
   Number of active neurons: 8
 >> iter 21000, loss: 0.082758
 >> iter 22000, loss: 0.080214
 >> iter 23000, loss: 0.062852
 >> iter 24000, loss: 0.077268
 >> iter 25000, loss: 0.072840
 >> iter 26000, loss: 0.059558
 >> iter 27000, loss: 0.047661
 >> iter 28000, loss: 0.062564
 >> iter 29000, loss: 0.053005
 >> iter 30000, loss: 0.056698
   Number of active neurons: 7
 >> iter 31000, loss: 0.070703
 >> iter 32000, loss: 0.055378
 >> iter 33000, loss: 0.062580
 >> iter 34000, loss: 0.063626
 >> iter 35000, loss: 0.053433
 >> iter 36000, loss: 0.057814
 >> iter 37000, loss: 0.041944
 >> iter 38000, loss: 0.038207
 >> iter 39000, loss: 0.044602
 >> iter 40000, loss: 0.050943
   Number of active neurons: 5
 >> iter 41000, loss: 0.060451
 >> iter 42000, loss: 0.057974
 >> iter 43000, loss: 0.080264
 >> iter 44000, loss: 0.051786
 >> iter 45000, loss: 0.071584
 >> iter 46000, loss: 0.055412
 >> iter 47000, loss: 0.076422
 >> iter 48000, loss: 0.052183
 >> iter 49000, loss: 0.075952
 >> iter 50000, loss: 0.057223
   Number of active neurons: 5
 >> iter 51000, loss: 0.044197
 >> iter 52000, loss: 0.039392
 >> iter 53000, loss: 0.048112
 >> iter 54000, loss: 0.041675
 >> iter 55000, loss: 0.056369
 >> iter 56000, loss: 0.045664
 >> iter 57000, loss: 0.038249
 >> iter 58000, loss: 0.045753
 >> iter 59000, loss: 0.060528
 >> iter 60000, loss: 0.056592
   Number of active neurons: 5
 >> iter 61000, loss: 0.052865
 >> iter 62000, loss: 0.047627
 >> iter 63000, loss: 0.066502
 >> iter 64000, loss: 0.047773
 >> iter 65000, loss: 0.060681
 >> iter 66000, loss: 0.067074
 >> iter 67000, loss: 0.053102
 >> iter 68000, loss: 0.065697
 >> iter 69000, loss: 0.067388
 >> iter 70000, loss: 0.069328
   Number of active neurons: 4
 >> iter 71000, loss: 0.062937
 >> iter 72000, loss: 0.054420
 >> iter 73000, loss: 0.054171
 >> iter 74000, loss: 0.049584
 >> iter 75000, loss: 0.043894
 >> iter 76000, loss: 0.045945
 >> iter 77000, loss: 0.058452
 >> iter 78000, loss: 0.042179
 >> iter 79000, loss: 0.054884
 >> iter 80000, loss: 0.046778
   Number of active neurons: 2
 >> iter 81000, loss: 0.043185
 >> iter 82000, loss: 0.039881
 >> iter 83000, loss: 0.043169
 >> iter 84000, loss: 0.028753
 >> iter 85000, loss: 0.041421
 >> iter 86000, loss: 0.045609
 >> iter 87000, loss: 0.045677
 >> iter 88000, loss: 0.037783
 >> iter 89000, loss: 0.046193
 >> iter 90000, loss: 0.064132
   Number of active neurons: 2
 >> iter 91000, loss: 0.052367
 >> iter 92000, loss: 0.051391
 >> iter 93000, loss: 0.042528
 >> iter 94000, loss: 0.039746
 >> iter 95000, loss: 0.038639
 >> iter 96000, loss: 0.044921
 >> iter 97000, loss: 0.039431
 >> iter 98000, loss: 0.036643
 >> iter 99000, loss: 0.035931
 >> iter 100000, loss: 0.048952
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 11.317519
 >> iter 2000, loss: 4.477221
 >> iter 3000, loss: 1.800489
 >> iter 4000, loss: 0.759780
 >> iter 5000, loss: 0.373240
 >> iter 6000, loss: 0.209851
 >> iter 7000, loss: 0.147524
 >> iter 8000, loss: 0.113588
 >> iter 9000, loss: 0.115167
 >> iter 10000, loss: 0.095487
   Number of active neurons: 9
 >> iter 11000, loss: 0.069766
 >> iter 12000, loss: 0.083371
 >> iter 13000, loss: 0.089759
 >> iter 14000, loss: 0.077437
 >> iter 15000, loss: 0.060957
 >> iter 16000, loss: 0.060408
 >> iter 17000, loss: 0.065267
 >> iter 18000, loss: 0.066408
 >> iter 19000, loss: 0.062197
 >> iter 20000, loss: 0.064317
   Number of active neurons: 7
 >> iter 21000, loss: 0.068525
 >> iter 22000, loss: 0.067618
 >> iter 23000, loss: 0.088889
 >> iter 24000, loss: 0.060147
 >> iter 25000, loss: 0.066154
 >> iter 26000, loss: 0.073296
 >> iter 27000, loss: 0.066233
 >> iter 28000, loss: 0.053840
 >> iter 29000, loss: 0.055106
 >> iter 30000, loss: 0.058789
   Number of active neurons: 7
 >> iter 31000, loss: 0.082640
 >> iter 32000, loss: 0.064332
 >> iter 33000, loss: 0.054923
 >> iter 34000, loss: 0.069680
 >> iter 35000, loss: 0.050749
 >> iter 36000, loss: 0.051375
 >> iter 37000, loss: 0.063237
 >> iter 38000, loss: 0.059343
 >> iter 39000, loss: 0.080982
 >> iter 40000, loss: 0.064430
   Number of active neurons: 4
 >> iter 41000, loss: 0.057359
 >> iter 42000, loss: 0.036967
 >> iter 43000, loss: 0.038788
 >> iter 44000, loss: 0.064261
 >> iter 45000, loss: 0.046233
 >> iter 46000, loss: 0.035158
 >> iter 47000, loss: 0.045337
 >> iter 48000, loss: 0.053423
 >> iter 49000, loss: 0.061592
 >> iter 50000, loss: 0.048873
   Number of active neurons: 4
 >> iter 51000, loss: 0.056737
 >> iter 52000, loss: 0.042434
 >> iter 53000, loss: 0.042883
 >> iter 54000, loss: 0.035566
 >> iter 55000, loss: 0.044892
 >> iter 56000, loss: 0.039883
 >> iter 57000, loss: 0.047117
 >> iter 58000, loss: 0.033453
 >> iter 59000, loss: 0.037083
 >> iter 60000, loss: 0.042116
   Number of active neurons: 4
 >> iter 61000, loss: 0.032669
 >> iter 62000, loss: 0.031534
 >> iter 63000, loss: 0.053022
 >> iter 64000, loss: 0.047458
 >> iter 65000, loss: 0.056563
 >> iter 66000, loss: 0.067158
 >> iter 67000, loss: 0.056977
 >> iter 68000, loss: 0.051581
 >> iter 69000, loss: 0.036313
 >> iter 70000, loss: 0.034122
   Number of active neurons: 4
 >> iter 71000, loss: 0.033648
 >> iter 72000, loss: 0.038229
 >> iter 73000, loss: 0.042530
 >> iter 74000, loss: 0.039265
 >> iter 75000, loss: 0.034678
 >> iter 76000, loss: 0.051407
 >> iter 77000, loss: 0.036670
 >> iter 78000, loss: 0.038889
 >> iter 79000, loss: 0.040013
 >> iter 80000, loss: 0.047947
   Number of active neurons: 3
 >> iter 81000, loss: 0.041757
 >> iter 82000, loss: 0.044872
 >> iter 83000, loss: 0.034263
 >> iter 84000, loss: 0.033352
 >> iter 85000, loss: 0.061571
 >> iter 86000, loss: 0.050919
 >> iter 87000, loss: 0.053925
 >> iter 88000, loss: 0.059042
 >> iter 89000, loss: 0.042558
 >> iter 90000, loss: 0.045644
   Number of active neurons: 3
 >> iter 91000, loss: 0.043433
 >> iter 92000, loss: 0.045287
 >> iter 93000, loss: 0.043632
 >> iter 94000, loss: 0.051716
 >> iter 95000, loss: 0.044761
 >> iter 96000, loss: 0.048195
 >> iter 97000, loss: 0.033237
 >> iter 98000, loss: 0.031405
 >> iter 99000, loss: 0.033099
 >> iter 100000, loss: 0.027900
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.382735
 >> iter 2000, loss: 4.540328
 >> iter 3000, loss: 1.837308
 >> iter 4000, loss: 0.816093
 >> iter 5000, loss: 0.372867
 >> iter 6000, loss: 0.219300
 >> iter 7000, loss: 0.140881
 >> iter 8000, loss: 0.109956
 >> iter 9000, loss: 0.095198
 >> iter 10000, loss: 0.084105
   Number of active neurons: 9
 >> iter 11000, loss: 0.067569
 >> iter 12000, loss: 0.072502
 >> iter 13000, loss: 0.078080
 >> iter 14000, loss: 0.073532
 >> iter 15000, loss: 0.105285
 >> iter 16000, loss: 0.086912
 >> iter 17000, loss: 0.078333
 >> iter 18000, loss: 0.067454
 >> iter 19000, loss: 0.061061
 >> iter 20000, loss: 0.051684
   Number of active neurons: 7
 >> iter 21000, loss: 0.052801
 >> iter 22000, loss: 0.058312
 >> iter 23000, loss: 0.047171
 >> iter 24000, loss: 0.061426
 >> iter 25000, loss: 0.060026
 >> iter 26000, loss: 0.061143
 >> iter 27000, loss: 0.067846
 >> iter 28000, loss: 0.084039
 >> iter 29000, loss: 0.060722
 >> iter 30000, loss: 0.051049
   Number of active neurons: 5
 >> iter 31000, loss: 0.046903
 >> iter 32000, loss: 0.039673
 >> iter 33000, loss: 0.035945
 >> iter 34000, loss: 0.036365
 >> iter 35000, loss: 0.067853
 >> iter 36000, loss: 0.065644
 >> iter 37000, loss: 0.047030
 >> iter 38000, loss: 0.040806
 >> iter 39000, loss: 0.050876
 >> iter 40000, loss: 0.057082
   Number of active neurons: 5
 >> iter 41000, loss: 0.057600
 >> iter 42000, loss: 0.050728
 >> iter 43000, loss: 0.043299
 >> iter 44000, loss: 0.067205
 >> iter 45000, loss: 0.058516
 >> iter 46000, loss: 0.066876
 >> iter 47000, loss: 0.049775
 >> iter 48000, loss: 0.034342
 >> iter 49000, loss: 0.031221
 >> iter 50000, loss: 0.053522
   Number of active neurons: 2
 >> iter 51000, loss: 0.049100
 >> iter 52000, loss: 0.054725
 >> iter 53000, loss: 0.046551
 >> iter 54000, loss: 0.035988
 >> iter 55000, loss: 0.052816
 >> iter 56000, loss: 0.051406
 >> iter 57000, loss: 0.084194
 >> iter 58000, loss: 0.049823
 >> iter 59000, loss: 0.042135
 >> iter 60000, loss: 0.054366
   Number of active neurons: 2
 >> iter 61000, loss: 0.041138
 >> iter 62000, loss: 0.040791
 >> iter 63000, loss: 0.051769
 >> iter 64000, loss: 0.039904
 >> iter 65000, loss: 0.038825
 >> iter 66000, loss: 0.055492
 >> iter 67000, loss: 0.049312
 >> iter 68000, loss: 0.049004
 >> iter 69000, loss: 0.050988
 >> iter 70000, loss: 0.044499
   Number of active neurons: 2
 >> iter 71000, loss: 0.042086
 >> iter 72000, loss: 0.031536
 >> iter 73000, loss: 0.044315
 >> iter 74000, loss: 0.041879
 >> iter 75000, loss: 0.046465
 >> iter 76000, loss: 0.043235
 >> iter 77000, loss: 0.045214
 >> iter 78000, loss: 0.046693
 >> iter 79000, loss: 0.052936
 >> iter 80000, loss: 0.040210
   Number of active neurons: 2
 >> iter 81000, loss: 0.061515
 >> iter 82000, loss: 0.040768
 >> iter 83000, loss: 0.059171
 >> iter 84000, loss: 0.055187
 >> iter 85000, loss: 0.051998
 >> iter 86000, loss: 0.055593
 >> iter 87000, loss: 0.057682
 >> iter 88000, loss: 0.040741
 >> iter 89000, loss: 0.060338
 >> iter 90000, loss: 0.047157
   Number of active neurons: 2
 >> iter 91000, loss: 0.047982
 >> iter 92000, loss: 0.040889
 >> iter 93000, loss: 0.042109
 >> iter 94000, loss: 0.044512
 >> iter 95000, loss: 0.043035
 >> iter 96000, loss: 0.041010
 >> iter 97000, loss: 0.033704
 >> iter 98000, loss: 0.041116
 >> iter 99000, loss: 0.044965
 >> iter 100000, loss: 0.038652
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.247398
 >> iter 2000, loss: 4.439176
 >> iter 3000, loss: 1.730299
 >> iter 4000, loss: 0.722630
 >> iter 5000, loss: 0.320626
 >> iter 6000, loss: 0.220071
 >> iter 7000, loss: 0.140013
 >> iter 8000, loss: 0.100673
 >> iter 9000, loss: 0.092465
 >> iter 10000, loss: 0.078131
   Number of active neurons: 6
 >> iter 11000, loss: 0.057801
 >> iter 12000, loss: 0.071647
 >> iter 13000, loss: 0.061029
 >> iter 14000, loss: 0.061369
 >> iter 15000, loss: 0.063807
 >> iter 16000, loss: 0.073442
 >> iter 17000, loss: 0.048421
 >> iter 18000, loss: 0.056616
 >> iter 19000, loss: 0.057929
 >> iter 20000, loss: 0.065747
   Number of active neurons: 6
 >> iter 21000, loss: 0.081911
 >> iter 22000, loss: 0.061420
 >> iter 23000, loss: 0.065310
 >> iter 24000, loss: 0.074772
 >> iter 25000, loss: 0.060251
 >> iter 26000, loss: 0.047248
 >> iter 27000, loss: 0.071114
 >> iter 28000, loss: 0.060587
 >> iter 29000, loss: 0.052675
 >> iter 30000, loss: 0.055592
   Number of active neurons: 5
 >> iter 31000, loss: 0.053169
 >> iter 32000, loss: 0.041734
 >> iter 33000, loss: 0.046940
 >> iter 34000, loss: 0.049274
 >> iter 35000, loss: 0.044499
 >> iter 36000, loss: 0.053489
 >> iter 37000, loss: 0.063966
 >> iter 38000, loss: 0.059635
 >> iter 39000, loss: 0.055948
 >> iter 40000, loss: 0.040027
   Number of active neurons: 3
 >> iter 41000, loss: 0.059768
 >> iter 42000, loss: 0.057672
 >> iter 43000, loss: 0.056350
 >> iter 44000, loss: 0.045801
 >> iter 45000, loss: 0.035966
 >> iter 46000, loss: 0.046816
 >> iter 47000, loss: 0.048411
 >> iter 48000, loss: 0.064002
 >> iter 49000, loss: 0.053882
 >> iter 50000, loss: 0.038279
   Number of active neurons: 3
 >> iter 51000, loss: 0.041180
 >> iter 52000, loss: 0.043468
 >> iter 53000, loss: 0.042181
 >> iter 54000, loss: 0.035009
 >> iter 55000, loss: 0.033055
 >> iter 56000, loss: 0.039619
 >> iter 57000, loss: 0.036688
 >> iter 58000, loss: 0.048153
 >> iter 59000, loss: 0.054864
 >> iter 60000, loss: 0.040752
   Number of active neurons: 3
 >> iter 61000, loss: 0.035604
 >> iter 62000, loss: 0.046963
 >> iter 63000, loss: 0.058477
 >> iter 64000, loss: 0.047189
 >> iter 65000, loss: 0.042123
 >> iter 66000, loss: 0.039566
 >> iter 67000, loss: 0.033525
 >> iter 68000, loss: 0.056844
 >> iter 69000, loss: 0.038353
 >> iter 70000, loss: 0.057192
   Number of active neurons: 3
 >> iter 71000, loss: 0.044226
 >> iter 72000, loss: 0.056560
 >> iter 73000, loss: 0.043592
 >> iter 74000, loss: 0.043272
 >> iter 75000, loss: 0.053622
 >> iter 76000, loss: 0.054658
 >> iter 77000, loss: 0.051179
 >> iter 78000, loss: 0.043806
 >> iter 79000, loss: 0.055933
 >> iter 80000, loss: 0.045273
   Number of active neurons: 3
 >> iter 81000, loss: 0.040417
 >> iter 82000, loss: 0.047114
 >> iter 83000, loss: 0.040267
 >> iter 84000, loss: 0.054112
 >> iter 85000, loss: 0.041385
 >> iter 86000, loss: 0.056052
 >> iter 87000, loss: 0.038998
 >> iter 88000, loss: 0.042483
 >> iter 89000, loss: 0.038499
 >> iter 90000, loss: 0.049914
   Number of active neurons: 3
 >> iter 91000, loss: 0.067870
 >> iter 92000, loss: 0.050979
 >> iter 93000, loss: 0.054743
 >> iter 94000, loss: 0.037740
 >> iter 95000, loss: 0.034448
 >> iter 96000, loss: 0.044403
 >> iter 97000, loss: 0.065946
 >> iter 98000, loss: 0.051081
 >> iter 99000, loss: 0.050818
 >> iter 100000, loss: 0.059234
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

