 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.8
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.914867
 >> iter 2000, loss: 9.763671
 >> iter 3000, loss: 4.060332
 >> iter 4000, loss: 1.798741
 >> iter 5000, loss: 0.892669
 >> iter 6000, loss: 0.438875
 >> iter 7000, loss: 0.539478
 >> iter 8000, loss: 0.215015
 >> iter 9000, loss: 0.239347
 >> iter 10000, loss: 0.106314
   Number of active neurons: 10
 >> iter 11000, loss: 0.086085
 >> iter 12000, loss: 0.039886
 >> iter 13000, loss: 0.126381
 >> iter 14000, loss: 0.057619
 >> iter 15000, loss: 0.025724
 >> iter 16000, loss: 0.054614
 >> iter 17000, loss: 0.025568
 >> iter 18000, loss: 0.012490
 >> iter 19000, loss: 0.016183
 >> iter 20000, loss: 0.058829
   Number of active neurons: 10
 >> iter 21000, loss: 0.044053
 >> iter 22000, loss: 0.050035
 >> iter 23000, loss: 0.090909
 >> iter 24000, loss: 0.040153
 >> iter 25000, loss: 0.026950
 >> iter 26000, loss: 0.014176
 >> iter 27000, loss: 0.008296
 >> iter 28000, loss: 0.005262
 >> iter 29000, loss: 0.024440
 >> iter 30000, loss: 0.189105
   Number of active neurons: 10
 >> iter 31000, loss: 0.094777
 >> iter 32000, loss: 0.083088
 >> iter 33000, loss: 0.063727
 >> iter 34000, loss: 0.026302
 >> iter 35000, loss: 0.041713
 >> iter 36000, loss: 0.017739
 >> iter 37000, loss: 0.008634
 >> iter 38000, loss: 0.005242
 >> iter 39000, loss: 0.003851
 >> iter 40000, loss: 0.005215
   Number of active neurons: 10
 >> iter 41000, loss: 0.003652
 >> iter 42000, loss: 0.002822
 >> iter 43000, loss: 0.003863
 >> iter 44000, loss: 0.002791
 >> iter 45000, loss: 0.019841
 >> iter 46000, loss: 0.141293
 >> iter 47000, loss: 0.064069
 >> iter 48000, loss: 0.025628
 >> iter 49000, loss: 0.010901
 >> iter 50000, loss: 0.052529
   Number of active neurons: 10
 >> iter 51000, loss: 0.021045
 >> iter 52000, loss: 0.009233
 >> iter 53000, loss: 0.005510
 >> iter 54000, loss: 0.003288
 >> iter 55000, loss: 0.002319
 >> iter 56000, loss: 0.001911
 >> iter 57000, loss: 0.001897
 >> iter 58000, loss: 0.001751
 >> iter 59000, loss: 0.002324
 >> iter 60000, loss: 0.003175
   Number of active neurons: 10
 >> iter 61000, loss: 0.040780
 >> iter 62000, loss: 0.026058
 >> iter 63000, loss: 0.010839
 >> iter 64000, loss: 0.006849
 >> iter 65000, loss: 0.003361
 >> iter 66000, loss: 0.078177
 >> iter 67000, loss: 0.030619
 >> iter 68000, loss: 0.043853
 >> iter 69000, loss: 0.018025
 >> iter 70000, loss: 0.007989
   Number of active neurons: 10
 >> iter 71000, loss: 0.003973
 >> iter 72000, loss: 0.038856
 >> iter 73000, loss: 0.015691
 >> iter 74000, loss: 0.006925
 >> iter 75000, loss: 0.006361
 >> iter 76000, loss: 0.012971
 >> iter 77000, loss: 0.005844
 >> iter 78000, loss: 0.003173
 >> iter 79000, loss: 0.002113
 >> iter 80000, loss: 0.001639
   Number of active neurons: 10
 >> iter 81000, loss: 0.001535
 >> iter 82000, loss: 0.001487
 >> iter 83000, loss: 0.001289
 >> iter 84000, loss: 0.001245
 >> iter 85000, loss: 0.001140
 >> iter 86000, loss: 0.001252
 >> iter 87000, loss: 0.001146
 >> iter 88000, loss: 0.015583
 >> iter 89000, loss: 0.006488
 >> iter 90000, loss: 0.003102
   Number of active neurons: 10
 >> iter 91000, loss: 0.001833
 >> iter 92000, loss: 0.001319
 >> iter 93000, loss: 0.003785
 >> iter 94000, loss: 0.002168
 >> iter 95000, loss: 0.001605
 >> iter 96000, loss: 0.001157
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.026132
 >> iter 2000, loss: 9.701096
 >> iter 3000, loss: 4.349575
 >> iter 4000, loss: 1.993327
 >> iter 5000, loss: 0.802777
 >> iter 6000, loss: 0.368566
 >> iter 7000, loss: 0.242912
 >> iter 8000, loss: 0.104636
 >> iter 9000, loss: 0.226304
 >> iter 10000, loss: 0.137355
   Number of active neurons: 10
 >> iter 11000, loss: 0.083739
 >> iter 12000, loss: 0.040883
 >> iter 13000, loss: 0.035338
 >> iter 14000, loss: 0.018415
 >> iter 15000, loss: 0.272758
 >> iter 16000, loss: 0.120849
 >> iter 17000, loss: 0.089148
 >> iter 18000, loss: 0.037667
 >> iter 19000, loss: 0.017976
 >> iter 20000, loss: 0.010709
   Number of active neurons: 10
 >> iter 21000, loss: 0.007828
 >> iter 22000, loss: 0.023042
 >> iter 23000, loss: 0.012067
 >> iter 24000, loss: 0.006727
 >> iter 25000, loss: 0.086403
 >> iter 26000, loss: 0.034659
 >> iter 27000, loss: 0.015246
 >> iter 28000, loss: 0.010281
 >> iter 29000, loss: 0.006052
 >> iter 30000, loss: 0.004098
   Number of active neurons: 10
 >> iter 31000, loss: 0.014014
 >> iter 32000, loss: 0.006948
 >> iter 33000, loss: 0.004118
 >> iter 34000, loss: 0.002958
 >> iter 35000, loss: 0.002810
 >> iter 36000, loss: 0.002266
 >> iter 37000, loss: 0.002005
 >> iter 38000, loss: 0.002177
 >> iter 39000, loss: 0.001840
 >> iter 40000, loss: 0.001879
   Number of active neurons: 10
 >> iter 41000, loss: 0.001806
 >> iter 42000, loss: 0.001706
 >> iter 43000, loss: 0.002405
 >> iter 44000, loss: 0.002274
 >> iter 45000, loss: 0.001744
 >> iter 46000, loss: 0.001802
 >> iter 47000, loss: 0.002866
 >> iter 48000, loss: 0.072560
 >> iter 49000, loss: 0.028280
 >> iter 50000, loss: 0.011789
   Number of active neurons: 10
 >> iter 51000, loss: 0.005372
 >> iter 52000, loss: 0.006135
 >> iter 53000, loss: 0.005999
 >> iter 54000, loss: 0.003158
 >> iter 55000, loss: 0.002397
 >> iter 56000, loss: 0.001668
 >> iter 57000, loss: 0.097641
 >> iter 58000, loss: 0.037036
 >> iter 59000, loss: 0.014686
 >> iter 60000, loss: 0.006446
   Number of active neurons: 10
 >> iter 61000, loss: 0.003229
 >> iter 62000, loss: 0.002972
 >> iter 63000, loss: 0.001838
 >> iter 64000, loss: 0.003025
 >> iter 65000, loss: 0.004340
 >> iter 66000, loss: 0.127860
 >> iter 67000, loss: 0.048846
 >> iter 68000, loss: 0.019583
 >> iter 69000, loss: 0.008339
 >> iter 70000, loss: 0.003957
   Number of active neurons: 10
 >> iter 71000, loss: 0.007321
 >> iter 72000, loss: 0.003588
 >> iter 73000, loss: 0.002281
 >> iter 74000, loss: 0.001622
 >> iter 75000, loss: 0.001403
 >> iter 76000, loss: 0.001392
 >> iter 77000, loss: 0.001238
 >> iter 78000, loss: 0.001230
 >> iter 79000, loss: 0.020478
 >> iter 80000, loss: 0.074826
   Number of active neurons: 10
 >> iter 81000, loss: 0.028502
 >> iter 82000, loss: 0.012336
 >> iter 83000, loss: 0.005265
 >> iter 84000, loss: 0.002878
 >> iter 85000, loss: 0.001982
 >> iter 86000, loss: 0.001442
 >> iter 87000, loss: 0.014154
 >> iter 88000, loss: 0.006053
 >> iter 89000, loss: 0.003377
 >> iter 90000, loss: 0.002056
   Number of active neurons: 10
 >> iter 91000, loss: 0.001505
 >> iter 92000, loss: 0.001514
 >> iter 93000, loss: 0.001222
 >> iter 94000, loss: 0.001062
 >> iter 95000, loss: 0.001051
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.611428
 >> iter 2000, loss: 9.833225
 >> iter 3000, loss: 4.457426
 >> iter 4000, loss: 2.175400
 >> iter 5000, loss: 1.270202
 >> iter 6000, loss: 0.718741
 >> iter 7000, loss: 0.391439
 >> iter 8000, loss: 0.314459
 >> iter 9000, loss: 0.390725
 >> iter 10000, loss: 0.227761
   Number of active neurons: 10
 >> iter 11000, loss: 0.278537
 >> iter 12000, loss: 0.148520
 >> iter 13000, loss: 0.069772
 >> iter 14000, loss: 0.067615
 >> iter 15000, loss: 0.058630
 >> iter 16000, loss: 0.028363
 >> iter 17000, loss: 0.085567
 >> iter 18000, loss: 0.111886
 >> iter 19000, loss: 0.048945
 >> iter 20000, loss: 0.025552
   Number of active neurons: 10
 >> iter 21000, loss: 0.120732
 >> iter 22000, loss: 0.146627
 >> iter 23000, loss: 0.086145
 >> iter 24000, loss: 0.046729
 >> iter 25000, loss: 0.021031
 >> iter 26000, loss: 0.014888
 >> iter 27000, loss: 0.134337
 >> iter 28000, loss: 0.266961
 >> iter 29000, loss: 0.112026
 >> iter 30000, loss: 0.050607
   Number of active neurons: 10
 >> iter 31000, loss: 0.022376
 >> iter 32000, loss: 0.011140
 >> iter 33000, loss: 0.006656
 >> iter 34000, loss: 0.004841
 >> iter 35000, loss: 0.004937
 >> iter 36000, loss: 0.004072
 >> iter 37000, loss: 0.003053
 >> iter 38000, loss: 0.148928
 >> iter 39000, loss: 0.066471
 >> iter 40000, loss: 0.041693
   Number of active neurons: 10
 >> iter 41000, loss: 0.022824
 >> iter 42000, loss: 0.010109
 >> iter 43000, loss: 0.011049
 >> iter 44000, loss: 0.029165
 >> iter 45000, loss: 0.015050
 >> iter 46000, loss: 0.007197
 >> iter 47000, loss: 0.004020
 >> iter 48000, loss: 0.013413
 >> iter 49000, loss: 0.026213
 >> iter 50000, loss: 0.070039
   Number of active neurons: 10
 >> iter 51000, loss: 0.029501
 >> iter 52000, loss: 0.014200
 >> iter 53000, loss: 0.006621
 >> iter 54000, loss: 0.012021
 >> iter 55000, loss: 0.009708
 >> iter 56000, loss: 0.006289
 >> iter 57000, loss: 0.018505
 >> iter 58000, loss: 0.008500
 >> iter 59000, loss: 0.006505
 >> iter 60000, loss: 0.006785
   Number of active neurons: 10
 >> iter 61000, loss: 0.039376
 >> iter 62000, loss: 0.097436
 >> iter 63000, loss: 0.038119
 >> iter 64000, loss: 0.015854
 >> iter 65000, loss: 0.007290
 >> iter 66000, loss: 0.080857
 >> iter 67000, loss: 0.031246
 >> iter 68000, loss: 0.013687
 >> iter 69000, loss: 0.006272
 >> iter 70000, loss: 0.033210
   Number of active neurons: 10
 >> iter 71000, loss: 0.013633
 >> iter 72000, loss: 0.006198
 >> iter 73000, loss: 0.003318
 >> iter 74000, loss: 0.002462
 >> iter 75000, loss: 0.001918
 >> iter 76000, loss: 0.001528
 >> iter 77000, loss: 0.004155
 >> iter 78000, loss: 0.002509
 >> iter 79000, loss: 0.003785
 >> iter 80000, loss: 0.002623
   Number of active neurons: 10
 >> iter 81000, loss: 0.001699
 >> iter 82000, loss: 0.001278
 >> iter 83000, loss: 0.001137
 >> iter 84000, loss: 0.001069
 >> iter 85000, loss: 0.001174
 >> iter 86000, loss: 0.028561
 >> iter 87000, loss: 0.022928
 >> iter 88000, loss: 0.011417
 >> iter 89000, loss: 0.005925
 >> iter 90000, loss: 0.003082
   Number of active neurons: 10
 >> iter 91000, loss: 0.003555
 >> iter 92000, loss: 0.002737
 >> iter 93000, loss: 0.001646
 >> iter 94000, loss: 0.001344
 >> iter 95000, loss: 0.001266
 >> iter 96000, loss: 0.001027
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.472267
 >> iter 2000, loss: 9.335543
 >> iter 3000, loss: 4.917666
 >> iter 4000, loss: 2.255442
 >> iter 5000, loss: 0.988233
 >> iter 6000, loss: 0.463325
 >> iter 7000, loss: 0.242798
 >> iter 8000, loss: 0.123131
 >> iter 9000, loss: 0.126607
 >> iter 10000, loss: 0.112152
   Number of active neurons: 10
 >> iter 11000, loss: 0.120853
 >> iter 12000, loss: 0.249756
 >> iter 13000, loss: 0.178453
 >> iter 14000, loss: 0.183365
 >> iter 15000, loss: 0.112326
 >> iter 16000, loss: 0.172533
 >> iter 17000, loss: 0.103946
 >> iter 18000, loss: 0.062420
 >> iter 19000, loss: 0.059878
 >> iter 20000, loss: 0.128087
   Number of active neurons: 10
 >> iter 21000, loss: 0.052302
 >> iter 22000, loss: 0.050608
 >> iter 23000, loss: 0.150604
 >> iter 24000, loss: 0.061133
 >> iter 25000, loss: 0.073320
 >> iter 26000, loss: 0.031171
 >> iter 27000, loss: 0.014328
 >> iter 28000, loss: 0.007799
 >> iter 29000, loss: 0.004912
 >> iter 30000, loss: 0.003581
   Number of active neurons: 10
 >> iter 31000, loss: 0.090605
 >> iter 32000, loss: 0.068387
 >> iter 33000, loss: 0.047408
 >> iter 34000, loss: 0.022631
 >> iter 35000, loss: 0.034989
 >> iter 36000, loss: 0.024179
 >> iter 37000, loss: 0.067256
 >> iter 38000, loss: 0.028403
 >> iter 39000, loss: 0.012752
 >> iter 40000, loss: 0.010966
   Number of active neurons: 10
 >> iter 41000, loss: 0.006077
 >> iter 42000, loss: 0.003765
 >> iter 43000, loss: 0.004329
 >> iter 44000, loss: 0.019729
 >> iter 45000, loss: 0.008868
 >> iter 46000, loss: 0.039302
 >> iter 47000, loss: 0.074029
 >> iter 48000, loss: 0.029572
 >> iter 49000, loss: 0.013315
 >> iter 50000, loss: 0.008097
   Number of active neurons: 10
 >> iter 51000, loss: 0.114372
 >> iter 52000, loss: 0.044043
 >> iter 53000, loss: 0.057478
 >> iter 54000, loss: 0.139541
 >> iter 55000, loss: 0.054575
 >> iter 56000, loss: 0.022540
 >> iter 57000, loss: 0.010358
 >> iter 58000, loss: 0.005530
 >> iter 59000, loss: 0.003591
 >> iter 60000, loss: 0.002655
   Number of active neurons: 10
 >> iter 61000, loss: 0.002168
 >> iter 62000, loss: 0.001911
 >> iter 63000, loss: 0.001755
 >> iter 64000, loss: 0.001776
 >> iter 65000, loss: 0.001658
 >> iter 66000, loss: 0.001850
 >> iter 67000, loss: 0.139526
 >> iter 68000, loss: 0.138007
 >> iter 69000, loss: 0.054119
 >> iter 70000, loss: 0.023458
   Number of active neurons: 10
 >> iter 71000, loss: 0.010168
 >> iter 72000, loss: 0.005112
 >> iter 73000, loss: 0.003224
 >> iter 74000, loss: 0.002540
 >> iter 75000, loss: 0.002011
 >> iter 76000, loss: 0.001995
 >> iter 77000, loss: 0.001628
 >> iter 78000, loss: 0.001447
 >> iter 79000, loss: 0.001278
 >> iter 80000, loss: 0.001220
   Number of active neurons: 10
 >> iter 81000, loss: 0.001131
 >> iter 82000, loss: 0.001121
 >> iter 83000, loss: 0.001244
 >> iter 84000, loss: 0.001183
 >> iter 85000, loss: 0.001092
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.791150
 >> iter 2000, loss: 9.461342
 >> iter 3000, loss: 4.315055
 >> iter 4000, loss: 2.071164
 >> iter 5000, loss: 1.121713
 >> iter 6000, loss: 0.703667
 >> iter 7000, loss: 0.441940
 >> iter 8000, loss: 0.443307
 >> iter 9000, loss: 0.230565
 >> iter 10000, loss: 0.220740
   Number of active neurons: 10
 >> iter 11000, loss: 0.189952
 >> iter 12000, loss: 0.137009
 >> iter 13000, loss: 0.058796
 >> iter 14000, loss: 0.301110
 >> iter 15000, loss: 0.134957
 >> iter 16000, loss: 0.088203
 >> iter 17000, loss: 0.049406
 >> iter 18000, loss: 0.075337
 >> iter 19000, loss: 0.039210
 >> iter 20000, loss: 0.023973
   Number of active neurons: 10
 >> iter 21000, loss: 0.014122
 >> iter 22000, loss: 0.069392
 >> iter 23000, loss: 0.226898
 >> iter 24000, loss: 0.164920
 >> iter 25000, loss: 0.098497
 >> iter 26000, loss: 0.041562
 >> iter 27000, loss: 0.043011
 >> iter 28000, loss: 0.019626
 >> iter 29000, loss: 0.013186
 >> iter 30000, loss: 0.008207
   Number of active neurons: 10
 >> iter 31000, loss: 0.079284
 >> iter 32000, loss: 0.043540
 >> iter 33000, loss: 0.020113
 >> iter 34000, loss: 0.125044
 >> iter 35000, loss: 0.090733
 >> iter 36000, loss: 0.235185
 >> iter 37000, loss: 0.097710
 >> iter 38000, loss: 0.039440
 >> iter 39000, loss: 0.017560
 >> iter 40000, loss: 0.008689
   Number of active neurons: 10
 >> iter 41000, loss: 0.005171
 >> iter 42000, loss: 0.170879
 >> iter 43000, loss: 0.072176
 >> iter 44000, loss: 0.029688
 >> iter 45000, loss: 0.053073
 >> iter 46000, loss: 0.070573
 >> iter 47000, loss: 0.088762
 >> iter 48000, loss: 0.142407
 >> iter 49000, loss: 0.056607
 >> iter 50000, loss: 0.059985
   Number of active neurons: 10
 >> iter 51000, loss: 0.025823
 >> iter 52000, loss: 0.117164
 >> iter 53000, loss: 0.046446
 >> iter 54000, loss: 0.061164
 >> iter 55000, loss: 0.025166
 >> iter 56000, loss: 0.011016
 >> iter 57000, loss: 0.008524
 >> iter 58000, loss: 0.005817
 >> iter 59000, loss: 0.003881
 >> iter 60000, loss: 0.040448
   Number of active neurons: 10
 >> iter 61000, loss: 0.020501
 >> iter 62000, loss: 0.081370
 >> iter 63000, loss: 0.036684
 >> iter 64000, loss: 0.016834
 >> iter 65000, loss: 0.023740
 >> iter 66000, loss: 0.056150
 >> iter 67000, loss: 0.022935
 >> iter 68000, loss: 0.011377
 >> iter 69000, loss: 0.006178
 >> iter 70000, loss: 0.008314
   Number of active neurons: 10
 >> iter 71000, loss: 0.004646
 >> iter 72000, loss: 0.003039
 >> iter 73000, loss: 0.002392
 >> iter 74000, loss: 0.001940
 >> iter 75000, loss: 0.001733
 >> iter 76000, loss: 0.001560
 >> iter 77000, loss: 0.001425
 >> iter 78000, loss: 0.001391
 >> iter 79000, loss: 0.002903
 >> iter 80000, loss: 0.016085
   Number of active neurons: 10
 >> iter 81000, loss: 0.084733
 >> iter 82000, loss: 0.064662
 >> iter 83000, loss: 0.075041
 >> iter 84000, loss: 0.105853
 >> iter 85000, loss: 0.041243
 >> iter 86000, loss: 0.017627
 >> iter 87000, loss: 0.007992
 >> iter 88000, loss: 0.129573
 >> iter 89000, loss: 0.049493
 >> iter 90000, loss: 0.019704
   Number of active neurons: 10
 >> iter 91000, loss: 0.008597
 >> iter 92000, loss: 0.071702
 >> iter 93000, loss: 0.028772
 >> iter 94000, loss: 0.012457
 >> iter 95000, loss: 0.006186
 >> iter 96000, loss: 0.003594
 >> iter 97000, loss: 0.076437
 >> iter 98000, loss: 0.029953
 >> iter 99000, loss: 0.012450
 >> iter 100000, loss: 0.005847
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.875724
 >> iter 2000, loss: 9.537748
 >> iter 3000, loss: 4.307281
 >> iter 4000, loss: 2.407970
 >> iter 5000, loss: 1.545247
 >> iter 6000, loss: 0.918433
 >> iter 7000, loss: 0.780331
 >> iter 8000, loss: 0.426664
 >> iter 9000, loss: 0.267225
 >> iter 10000, loss: 0.234235
   Number of active neurons: 10
 >> iter 11000, loss: 0.131869
 >> iter 12000, loss: 0.231919
 >> iter 13000, loss: 0.190892
 >> iter 14000, loss: 0.241591
 >> iter 15000, loss: 0.129228
 >> iter 16000, loss: 0.058722
 >> iter 17000, loss: 0.074615
 >> iter 18000, loss: 0.035486
 >> iter 19000, loss: 0.036971
 >> iter 20000, loss: 0.190376
   Number of active neurons: 10
 >> iter 21000, loss: 0.078857
 >> iter 22000, loss: 0.055774
 >> iter 23000, loss: 0.043142
 >> iter 24000, loss: 0.020023
 >> iter 25000, loss: 0.010216
 >> iter 26000, loss: 0.129377
 >> iter 27000, loss: 0.057526
 >> iter 28000, loss: 0.081674
 >> iter 29000, loss: 0.129354
 >> iter 30000, loss: 0.115434
   Number of active neurons: 10
 >> iter 31000, loss: 0.047233
 >> iter 32000, loss: 0.052658
 >> iter 33000, loss: 0.130155
 >> iter 34000, loss: 0.063234
 >> iter 35000, loss: 0.035373
 >> iter 36000, loss: 0.048853
 >> iter 37000, loss: 0.021223
 >> iter 38000, loss: 0.191203
 >> iter 39000, loss: 0.176912
 >> iter 40000, loss: 0.068031
   Number of active neurons: 10
 >> iter 41000, loss: 0.039068
 >> iter 42000, loss: 0.043239
 >> iter 43000, loss: 0.020432
 >> iter 44000, loss: 0.013271
 >> iter 45000, loss: 0.032417
 >> iter 46000, loss: 0.023915
 >> iter 47000, loss: 0.028518
 >> iter 48000, loss: 0.013766
 >> iter 49000, loss: 0.006916
 >> iter 50000, loss: 0.006271
   Number of active neurons: 10
 >> iter 51000, loss: 0.008009
 >> iter 52000, loss: 0.004164
 >> iter 53000, loss: 0.002761
 >> iter 54000, loss: 0.003120
 >> iter 55000, loss: 0.002751
 >> iter 56000, loss: 0.002106
 >> iter 57000, loss: 0.098697
 >> iter 58000, loss: 0.038281
 >> iter 59000, loss: 0.015458
 >> iter 60000, loss: 0.006855
   Number of active neurons: 10
 >> iter 61000, loss: 0.003537
 >> iter 62000, loss: 0.002400
 >> iter 63000, loss: 0.004127
 >> iter 64000, loss: 0.007652
 >> iter 65000, loss: 0.017292
 >> iter 66000, loss: 0.007130
 >> iter 67000, loss: 0.003540
 >> iter 68000, loss: 0.006610
 >> iter 69000, loss: 0.083944
 >> iter 70000, loss: 0.036674
   Number of active neurons: 10
 >> iter 71000, loss: 0.014677
 >> iter 72000, loss: 0.008119
 >> iter 73000, loss: 0.057343
 >> iter 74000, loss: 0.025985
 >> iter 75000, loss: 0.019755
 >> iter 76000, loss: 0.008217
 >> iter 77000, loss: 0.003896
 >> iter 78000, loss: 0.002216
 >> iter 79000, loss: 0.027162
 >> iter 80000, loss: 0.089150
   Number of active neurons: 10
 >> iter 81000, loss: 0.034775
 >> iter 82000, loss: 0.013902
 >> iter 83000, loss: 0.017224
 >> iter 84000, loss: 0.007362
 >> iter 85000, loss: 0.003554
 >> iter 86000, loss: 0.103857
 >> iter 87000, loss: 0.134914
 >> iter 88000, loss: 0.057597
 >> iter 89000, loss: 0.025595
 >> iter 90000, loss: 0.011490
   Number of active neurons: 10
 >> iter 91000, loss: 0.007420
 >> iter 92000, loss: 0.035903
 >> iter 93000, loss: 0.014985
 >> iter 94000, loss: 0.006711
 >> iter 95000, loss: 0.003330
 >> iter 96000, loss: 0.002376
 >> iter 97000, loss: 0.007290
 >> iter 98000, loss: 0.038937
 >> iter 99000, loss: 0.056960
 >> iter 100000, loss: 0.026735
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.707781
 >> iter 2000, loss: 9.989373
 >> iter 3000, loss: 4.378627
 >> iter 4000, loss: 2.018285
 >> iter 5000, loss: 0.955066
 >> iter 6000, loss: 0.650080
 >> iter 7000, loss: 0.376078
 >> iter 8000, loss: 0.229569
 >> iter 9000, loss: 0.114828
 >> iter 10000, loss: 0.122832
   Number of active neurons: 10
 >> iter 11000, loss: 0.233529
 >> iter 12000, loss: 0.190601
 >> iter 13000, loss: 0.124042
 >> iter 14000, loss: 0.103393
 >> iter 15000, loss: 0.077470
 >> iter 16000, loss: 0.056723
 >> iter 17000, loss: 0.636234
 >> iter 18000, loss: 0.336595
 >> iter 19000, loss: 0.159868
 >> iter 20000, loss: 0.093252
   Number of active neurons: 10
 >> iter 21000, loss: 0.040027
 >> iter 22000, loss: 0.094766
 >> iter 23000, loss: 0.060367
 >> iter 24000, loss: 0.062540
 >> iter 25000, loss: 0.040571
 >> iter 26000, loss: 0.044447
 >> iter 27000, loss: 0.040733
 >> iter 28000, loss: 0.020022
 >> iter 29000, loss: 0.014222
 >> iter 30000, loss: 0.007734
   Number of active neurons: 10
 >> iter 31000, loss: 0.005033
 >> iter 32000, loss: 0.003643
 >> iter 33000, loss: 0.017280
 >> iter 34000, loss: 0.014099
 >> iter 35000, loss: 0.006933
 >> iter 36000, loss: 0.053145
 >> iter 37000, loss: 0.092847
 >> iter 38000, loss: 0.191916
 >> iter 39000, loss: 0.074367
 >> iter 40000, loss: 0.029877
   Number of active neurons: 10
 >> iter 41000, loss: 0.155971
 >> iter 42000, loss: 0.112964
 >> iter 43000, loss: 0.044338
 >> iter 44000, loss: 0.018535
 >> iter 45000, loss: 0.048338
 >> iter 46000, loss: 0.020030
 >> iter 47000, loss: 0.039003
 >> iter 48000, loss: 0.017465
 >> iter 49000, loss: 0.008414
 >> iter 50000, loss: 0.013563
   Number of active neurons: 10
 >> iter 51000, loss: 0.006431
 >> iter 52000, loss: 0.004084
 >> iter 53000, loss: 0.003065
 >> iter 54000, loss: 0.063609
 >> iter 55000, loss: 0.024989
 >> iter 56000, loss: 0.010535
 >> iter 57000, loss: 0.005104
 >> iter 58000, loss: 0.040973
 >> iter 59000, loss: 0.016711
 >> iter 60000, loss: 0.007394
   Number of active neurons: 10
 >> iter 61000, loss: 0.061006
 >> iter 62000, loss: 0.024266
 >> iter 63000, loss: 0.010190
 >> iter 64000, loss: 0.008508
 >> iter 65000, loss: 0.016472
 >> iter 66000, loss: 0.007619
 >> iter 67000, loss: 0.004034
 >> iter 68000, loss: 0.002550
 >> iter 69000, loss: 0.001922
 >> iter 70000, loss: 0.002114
   Number of active neurons: 10
 >> iter 71000, loss: 0.001742
 >> iter 72000, loss: 0.001462
 >> iter 73000, loss: 0.045267
 >> iter 74000, loss: 0.018251
 >> iter 75000, loss: 0.007717
 >> iter 76000, loss: 0.004113
 >> iter 77000, loss: 0.012566
 >> iter 78000, loss: 0.005352
 >> iter 79000, loss: 0.002943
 >> iter 80000, loss: 0.001763
   Number of active neurons: 10
 >> iter 81000, loss: 0.001489
 >> iter 82000, loss: 0.001200
 >> iter 83000, loss: 0.001045
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.625446
 >> iter 2000, loss: 9.256299
 >> iter 3000, loss: 3.800416
 >> iter 4000, loss: 1.670928
 >> iter 5000, loss: 0.739044
 >> iter 6000, loss: 0.340858
 >> iter 7000, loss: 0.457118
 >> iter 8000, loss: 0.269290
 >> iter 9000, loss: 0.119934
 >> iter 10000, loss: 0.109470
   Number of active neurons: 10
 >> iter 11000, loss: 0.081859
 >> iter 12000, loss: 0.158932
 >> iter 13000, loss: 0.321893
 >> iter 14000, loss: 0.136924
 >> iter 15000, loss: 0.080319
 >> iter 16000, loss: 0.040968
 >> iter 17000, loss: 0.034792
 >> iter 18000, loss: 0.025490
 >> iter 19000, loss: 0.015145
 >> iter 20000, loss: 0.010602
   Number of active neurons: 10
 >> iter 21000, loss: 0.007226
 >> iter 22000, loss: 0.005294
 >> iter 23000, loss: 0.032887
 >> iter 24000, loss: 0.015504
 >> iter 25000, loss: 0.008899
 >> iter 26000, loss: 0.077276
 >> iter 27000, loss: 0.189415
 >> iter 28000, loss: 0.075238
 >> iter 29000, loss: 0.031086
 >> iter 30000, loss: 0.014124
   Number of active neurons: 10
 >> iter 31000, loss: 0.049340
 >> iter 32000, loss: 0.021542
 >> iter 33000, loss: 0.072191
 >> iter 34000, loss: 0.033287
 >> iter 35000, loss: 0.055535
 >> iter 36000, loss: 0.023575
 >> iter 37000, loss: 0.011794
 >> iter 38000, loss: 0.037462
 >> iter 39000, loss: 0.016376
 >> iter 40000, loss: 0.008244
   Number of active neurons: 10
 >> iter 41000, loss: 0.004687
 >> iter 42000, loss: 0.003281
 >> iter 43000, loss: 0.069129
 >> iter 44000, loss: 0.030286
 >> iter 45000, loss: 0.012799
 >> iter 46000, loss: 0.006373
 >> iter 47000, loss: 0.004102
 >> iter 48000, loss: 0.002790
 >> iter 49000, loss: 0.002748
 >> iter 50000, loss: 0.002291
   Number of active neurons: 10
 >> iter 51000, loss: 0.002046
 >> iter 52000, loss: 0.001755
 >> iter 53000, loss: 0.001651
 >> iter 54000, loss: 0.001556
 >> iter 55000, loss: 0.002370
 >> iter 56000, loss: 0.006657
 >> iter 57000, loss: 0.003781
 >> iter 58000, loss: 0.057104
 >> iter 59000, loss: 0.022428
 >> iter 60000, loss: 0.039154
   Number of active neurons: 10
 >> iter 61000, loss: 0.028934
 >> iter 62000, loss: 0.040196
 >> iter 63000, loss: 0.016029
 >> iter 64000, loss: 0.007017
 >> iter 65000, loss: 0.003659
 >> iter 66000, loss: 0.002232
 >> iter 67000, loss: 0.001719
 >> iter 68000, loss: 0.005300
 >> iter 69000, loss: 0.002794
 >> iter 70000, loss: 0.080092
   Number of active neurons: 10
 >> iter 71000, loss: 0.088931
 >> iter 72000, loss: 0.034348
 >> iter 73000, loss: 0.014165
 >> iter 74000, loss: 0.006548
 >> iter 75000, loss: 0.003633
 >> iter 76000, loss: 0.016282
 >> iter 77000, loss: 0.007523
 >> iter 78000, loss: 0.004581
 >> iter 79000, loss: 0.002631
 >> iter 80000, loss: 0.001959
   Number of active neurons: 10
 >> iter 81000, loss: 0.001648
 >> iter 82000, loss: 0.001548
 >> iter 83000, loss: 0.001377
 >> iter 84000, loss: 0.001488
 >> iter 85000, loss: 0.001324
 >> iter 86000, loss: 0.001321
 >> iter 87000, loss: 0.001406
 >> iter 88000, loss: 0.001179
 >> iter 89000, loss: 0.001787
 >> iter 90000, loss: 0.001415
   Number of active neurons: 10
 >> iter 91000, loss: 0.001353
 >> iter 92000, loss: 0.001192
 >> iter 93000, loss: 0.005220
 >> iter 94000, loss: 0.002495
 >> iter 95000, loss: 0.135422
 >> iter 96000, loss: 0.051013
 >> iter 97000, loss: 0.023237
 >> iter 98000, loss: 0.009433
 >> iter 99000, loss: 0.004332
 >> iter 100000, loss: 0.037655
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.763386
 >> iter 2000, loss: 9.613753
 >> iter 3000, loss: 4.940900
 >> iter 4000, loss: 2.498540
 >> iter 5000, loss: 1.203788
 >> iter 6000, loss: 0.677630
 >> iter 7000, loss: 0.459307
 >> iter 8000, loss: 0.322384
 >> iter 9000, loss: 0.250307
 >> iter 10000, loss: 0.164503
   Number of active neurons: 10
 >> iter 11000, loss: 0.109231
 >> iter 12000, loss: 0.103710
 >> iter 13000, loss: 0.149606
 >> iter 14000, loss: 0.097930
 >> iter 15000, loss: 0.128106
 >> iter 16000, loss: 0.206386
 >> iter 17000, loss: 0.109320
 >> iter 18000, loss: 0.046211
 >> iter 19000, loss: 0.101266
 >> iter 20000, loss: 0.061574
   Number of active neurons: 10
 >> iter 21000, loss: 0.026908
 >> iter 22000, loss: 0.083844
 >> iter 23000, loss: 0.072939
 >> iter 24000, loss: 0.031129
 >> iter 25000, loss: 0.031829
 >> iter 26000, loss: 0.035326
 >> iter 27000, loss: 0.091986
 >> iter 28000, loss: 0.061150
 >> iter 29000, loss: 0.135629
 >> iter 30000, loss: 0.111247
   Number of active neurons: 10
 >> iter 31000, loss: 0.095743
 >> iter 32000, loss: 0.067813
 >> iter 33000, loss: 0.028624
 >> iter 34000, loss: 0.013376
 >> iter 35000, loss: 0.008141
 >> iter 36000, loss: 0.057478
 >> iter 37000, loss: 0.023744
 >> iter 38000, loss: 0.017650
 >> iter 39000, loss: 0.023872
 >> iter 40000, loss: 0.010783
   Number of active neurons: 10
 >> iter 41000, loss: 0.038687
 >> iter 42000, loss: 0.076359
 >> iter 43000, loss: 0.032020
 >> iter 44000, loss: 0.023577
 >> iter 45000, loss: 0.015031
 >> iter 46000, loss: 0.007465
 >> iter 47000, loss: 0.004736
 >> iter 48000, loss: 0.003118
 >> iter 49000, loss: 0.002299
 >> iter 50000, loss: 0.065142
   Number of active neurons: 10
 >> iter 51000, loss: 0.076820
 >> iter 52000, loss: 0.041951
 >> iter 53000, loss: 0.091863
 >> iter 54000, loss: 0.036009
 >> iter 55000, loss: 0.018296
 >> iter 56000, loss: 0.008244
 >> iter 57000, loss: 0.017152
 >> iter 58000, loss: 0.037691
 >> iter 59000, loss: 0.015565
 >> iter 60000, loss: 0.007047
   Number of active neurons: 10
 >> iter 61000, loss: 0.003936
 >> iter 62000, loss: 0.003111
 >> iter 63000, loss: 0.002173
 >> iter 64000, loss: 0.002381
 >> iter 65000, loss: 0.024097
 >> iter 66000, loss: 0.040848
 >> iter 67000, loss: 0.020323
 >> iter 68000, loss: 0.008825
 >> iter 69000, loss: 0.004520
 >> iter 70000, loss: 0.004123
   Number of active neurons: 10
 >> iter 71000, loss: 0.002606
 >> iter 72000, loss: 0.001890
 >> iter 73000, loss: 0.001494
 >> iter 74000, loss: 0.001336
 >> iter 75000, loss: 0.001300
 >> iter 76000, loss: 0.001192
 >> iter 77000, loss: 0.001118
 >> iter 78000, loss: 0.142773
 >> iter 79000, loss: 0.053506
 >> iter 80000, loss: 0.020623
   Number of active neurons: 10
 >> iter 81000, loss: 0.008453
 >> iter 82000, loss: 0.003848
 >> iter 83000, loss: 0.002194
 >> iter 84000, loss: 0.001897
 >> iter 85000, loss: 0.001442
 >> iter 86000, loss: 0.120482
 >> iter 87000, loss: 0.045565
 >> iter 88000, loss: 0.105573
 >> iter 89000, loss: 0.040297
 >> iter 90000, loss: 0.016826
   Number of active neurons: 10
 >> iter 91000, loss: 0.026083
 >> iter 92000, loss: 0.010974
 >> iter 93000, loss: 0.005354
 >> iter 94000, loss: 0.005394
 >> iter 95000, loss: 0.002870
 >> iter 96000, loss: 0.002002
 >> iter 97000, loss: 0.001616
 >> iter 98000, loss: 0.001417
 >> iter 99000, loss: 0.004675
 >> iter 100000, loss: 0.026677
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.519220
 >> iter 2000, loss: 8.799189
 >> iter 3000, loss: 4.336242
 >> iter 4000, loss: 1.839975
 >> iter 5000, loss: 1.002668
 >> iter 6000, loss: 0.597690
 >> iter 7000, loss: 0.361533
 >> iter 8000, loss: 0.291546
 >> iter 9000, loss: 0.184387
 >> iter 10000, loss: 0.109747
   Number of active neurons: 10
 >> iter 11000, loss: 0.053384
 >> iter 12000, loss: 0.149616
 >> iter 13000, loss: 0.170196
 >> iter 14000, loss: 0.083340
 >> iter 15000, loss: 0.038243
 >> iter 16000, loss: 0.019316
 >> iter 17000, loss: 0.011178
 >> iter 18000, loss: 0.025307
 >> iter 19000, loss: 0.012639
 >> iter 20000, loss: 0.007504
   Number of active neurons: 10
 >> iter 21000, loss: 0.005304
 >> iter 22000, loss: 0.019691
 >> iter 23000, loss: 0.132367
 >> iter 24000, loss: 0.053749
 >> iter 25000, loss: 0.050607
 >> iter 26000, loss: 0.021852
 >> iter 27000, loss: 0.010883
 >> iter 28000, loss: 0.006547
 >> iter 29000, loss: 0.004672
 >> iter 30000, loss: 0.067150
   Number of active neurons: 10
 >> iter 31000, loss: 0.028201
 >> iter 32000, loss: 0.020851
 >> iter 33000, loss: 0.010149
 >> iter 34000, loss: 0.005562
 >> iter 35000, loss: 0.014004
 >> iter 36000, loss: 0.006979
 >> iter 37000, loss: 0.048917
 >> iter 38000, loss: 0.048503
 >> iter 39000, loss: 0.021357
 >> iter 40000, loss: 0.009628
   Number of active neurons: 10
 >> iter 41000, loss: 0.006580
 >> iter 42000, loss: 0.004629
 >> iter 43000, loss: 0.003361
 >> iter 44000, loss: 0.002712
 >> iter 45000, loss: 0.066643
 >> iter 46000, loss: 0.026075
 >> iter 47000, loss: 0.010975
 >> iter 48000, loss: 0.005333
 >> iter 49000, loss: 0.005978
 >> iter 50000, loss: 0.016883
   Number of active neurons: 10
 >> iter 51000, loss: 0.011431
 >> iter 52000, loss: 0.005331
 >> iter 53000, loss: 0.002995
 >> iter 54000, loss: 0.002029
 >> iter 55000, loss: 0.001748
 >> iter 56000, loss: 0.023761
 >> iter 57000, loss: 0.009840
 >> iter 58000, loss: 0.013252
 >> iter 59000, loss: 0.006325
 >> iter 60000, loss: 0.107374
   Number of active neurons: 10
 >> iter 61000, loss: 0.118931
 >> iter 62000, loss: 0.068065
 >> iter 63000, loss: 0.031289
 >> iter 64000, loss: 0.013294
 >> iter 65000, loss: 0.035185
 >> iter 66000, loss: 0.053767
 >> iter 67000, loss: 0.022302
 >> iter 68000, loss: 0.009980
 >> iter 69000, loss: 0.005171
 >> iter 70000, loss: 0.028016
   Number of active neurons: 10
 >> iter 71000, loss: 0.016623
 >> iter 72000, loss: 0.008010
 >> iter 73000, loss: 0.004196
 >> iter 74000, loss: 0.002565
 >> iter 75000, loss: 0.002159
 >> iter 76000, loss: 0.001833
 >> iter 77000, loss: 0.001601
 >> iter 78000, loss: 0.001666
 >> iter 79000, loss: 0.005031
 >> iter 80000, loss: 0.002620
   Number of active neurons: 10
 >> iter 81000, loss: 0.003227
 >> iter 82000, loss: 0.038544
 >> iter 83000, loss: 0.070165
 >> iter 84000, loss: 0.029063
 >> iter 85000, loss: 0.011743
 >> iter 86000, loss: 0.005799
 >> iter 87000, loss: 0.002929
 >> iter 88000, loss: 0.001857
 >> iter 89000, loss: 0.002304
 >> iter 90000, loss: 0.001901
   Number of active neurons: 10
 >> iter 91000, loss: 0.002038
 >> iter 92000, loss: 0.002020
 >> iter 93000, loss: 0.001545
 >> iter 94000, loss: 0.001279
 >> iter 95000, loss: 0.001155
 >> iter 96000, loss: 0.001121
 >> iter 97000, loss: 0.001017
 >> iter 98000, loss: 0.001449
 >> iter 99000, loss: 0.002023
 >> iter 100000, loss: 0.001349
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.526032
 >> iter 2000, loss: 9.742262
 >> iter 3000, loss: 4.534303
 >> iter 4000, loss: 2.308937
 >> iter 5000, loss: 1.207771
 >> iter 6000, loss: 0.865037
 >> iter 7000, loss: 0.505034
 >> iter 8000, loss: 0.421025
 >> iter 9000, loss: 0.503604
 >> iter 10000, loss: 0.206714
   Number of active neurons: 10
 >> iter 11000, loss: 0.197659
 >> iter 12000, loss: 0.178075
 >> iter 13000, loss: 0.129285
 >> iter 14000, loss: 0.139014
 >> iter 15000, loss: 0.058415
 >> iter 16000, loss: 0.072508
 >> iter 17000, loss: 0.075221
 >> iter 18000, loss: 0.039001
 >> iter 19000, loss: 0.046968
 >> iter 20000, loss: 0.033633
   Number of active neurons: 10
 >> iter 21000, loss: 0.205652
 >> iter 22000, loss: 0.186777
 >> iter 23000, loss: 0.074598
 >> iter 24000, loss: 0.063216
 >> iter 25000, loss: 0.030048
 >> iter 26000, loss: 0.059996
 >> iter 27000, loss: 0.037892
 >> iter 28000, loss: 0.016844
 >> iter 29000, loss: 0.009635
 >> iter 30000, loss: 0.044934
   Number of active neurons: 10
 >> iter 31000, loss: 0.019839
 >> iter 32000, loss: 0.009504
 >> iter 33000, loss: 0.005602
 >> iter 34000, loss: 0.004427
 >> iter 35000, loss: 0.009488
 >> iter 36000, loss: 0.005338
 >> iter 37000, loss: 0.003915
 >> iter 38000, loss: 0.003735
 >> iter 39000, loss: 0.028924
 >> iter 40000, loss: 0.180469
   Number of active neurons: 10
 >> iter 41000, loss: 0.069972
 >> iter 42000, loss: 0.098074
 >> iter 43000, loss: 0.085492
 >> iter 44000, loss: 0.036468
 >> iter 45000, loss: 0.058125
 >> iter 46000, loss: 0.024352
 >> iter 47000, loss: 0.021481
 >> iter 48000, loss: 0.010459
 >> iter 49000, loss: 0.031961
 >> iter 50000, loss: 0.024629
   Number of active neurons: 10
 >> iter 51000, loss: 0.012024
 >> iter 52000, loss: 0.008573
 >> iter 53000, loss: 0.004780
 >> iter 54000, loss: 0.003463
 >> iter 55000, loss: 0.002617
 >> iter 56000, loss: 0.002048
 >> iter 57000, loss: 0.059724
 >> iter 58000, loss: 0.031477
 >> iter 59000, loss: 0.012874
 >> iter 60000, loss: 0.025902
   Number of active neurons: 10
 >> iter 61000, loss: 0.010739
 >> iter 62000, loss: 0.007719
 >> iter 63000, loss: 0.004978
 >> iter 64000, loss: 0.003230
 >> iter 65000, loss: 0.002206
 >> iter 66000, loss: 0.001764
 >> iter 67000, loss: 0.004127
 >> iter 68000, loss: 0.002983
 >> iter 69000, loss: 0.002035
 >> iter 70000, loss: 0.001568
   Number of active neurons: 10
 >> iter 71000, loss: 0.001289
 >> iter 72000, loss: 0.001159
 >> iter 73000, loss: 0.008326
 >> iter 74000, loss: 0.067661
 >> iter 75000, loss: 0.025908
 >> iter 76000, loss: 0.010949
 >> iter 77000, loss: 0.005139
 >> iter 78000, loss: 0.002854
 >> iter 79000, loss: 0.050573
 >> iter 80000, loss: 0.019934
   Number of active neurons: 10
 >> iter 81000, loss: 0.008406
 >> iter 82000, loss: 0.004126
 >> iter 83000, loss: 0.002484
 >> iter 84000, loss: 0.001726
 >> iter 85000, loss: 0.001581
 >> iter 86000, loss: 0.001286
 >> iter 87000, loss: 0.001545
 >> iter 88000, loss: 0.020754
 >> iter 89000, loss: 0.008310
 >> iter 90000, loss: 0.003663
   Number of active neurons: 10
 >> iter 91000, loss: 0.001991
 >> iter 92000, loss: 0.023677
 >> iter 93000, loss: 0.009892
 >> iter 94000, loss: 0.004413
 >> iter 95000, loss: 0.002432
 >> iter 96000, loss: 0.001911
 >> iter 97000, loss: 0.057532
 >> iter 98000, loss: 0.022254
 >> iter 99000, loss: 0.009300
 >> iter 100000, loss: 0.004322
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.564724
 >> iter 2000, loss: 10.265449
 >> iter 3000, loss: 4.711760
 >> iter 4000, loss: 2.078044
 >> iter 5000, loss: 1.174314
 >> iter 6000, loss: 0.768597
 >> iter 7000, loss: 0.416165
 >> iter 8000, loss: 0.233660
 >> iter 9000, loss: 0.239235
 >> iter 10000, loss: 0.227945
   Number of active neurons: 10
 >> iter 11000, loss: 0.435632
 >> iter 12000, loss: 0.184672
 >> iter 13000, loss: 0.111661
 >> iter 14000, loss: 0.048036
 >> iter 15000, loss: 0.060636
 >> iter 16000, loss: 0.030385
 >> iter 17000, loss: 0.018767
 >> iter 18000, loss: 0.084527
 >> iter 19000, loss: 0.039309
 >> iter 20000, loss: 0.018403
   Number of active neurons: 10
 >> iter 21000, loss: 0.015314
 >> iter 22000, loss: 0.090836
 >> iter 23000, loss: 0.057508
 >> iter 24000, loss: 0.066887
 >> iter 25000, loss: 0.028441
 >> iter 26000, loss: 0.019413
 >> iter 27000, loss: 0.010948
 >> iter 28000, loss: 0.006609
 >> iter 29000, loss: 0.004507
 >> iter 30000, loss: 0.008000
   Number of active neurons: 10
 >> iter 31000, loss: 0.011884
 >> iter 32000, loss: 0.006681
 >> iter 33000, loss: 0.004329
 >> iter 34000, loss: 0.004522
 >> iter 35000, loss: 0.004605
 >> iter 36000, loss: 0.006180
 >> iter 37000, loss: 0.017490
 >> iter 38000, loss: 0.008157
 >> iter 39000, loss: 0.064589
 >> iter 40000, loss: 0.027517
   Number of active neurons: 10
 >> iter 41000, loss: 0.011709
 >> iter 42000, loss: 0.005659
 >> iter 43000, loss: 0.050852
 >> iter 44000, loss: 0.020209
 >> iter 45000, loss: 0.008881
 >> iter 46000, loss: 0.006418
 >> iter 47000, loss: 0.003588
 >> iter 48000, loss: 0.002656
 >> iter 49000, loss: 0.002288
 >> iter 50000, loss: 0.004947
   Number of active neurons: 10
 >> iter 51000, loss: 0.004639
 >> iter 52000, loss: 0.003191
 >> iter 53000, loss: 0.002425
 >> iter 54000, loss: 0.001622
 >> iter 55000, loss: 0.001524
 >> iter 56000, loss: 0.001721
 >> iter 57000, loss: 0.003432
 >> iter 58000, loss: 0.002064
 >> iter 59000, loss: 0.001532
 >> iter 60000, loss: 0.028065
   Number of active neurons: 10
 >> iter 61000, loss: 0.028886
 >> iter 62000, loss: 0.065100
 >> iter 63000, loss: 0.049377
 >> iter 64000, loss: 0.030692
 >> iter 65000, loss: 0.012832
 >> iter 66000, loss: 0.005566
 >> iter 67000, loss: 0.003199
 >> iter 68000, loss: 0.002170
 >> iter 69000, loss: 0.001972
 >> iter 70000, loss: 0.003044
   Number of active neurons: 10
 >> iter 71000, loss: 0.001888
 >> iter 72000, loss: 0.002624
 >> iter 73000, loss: 0.001913
 >> iter 74000, loss: 0.002178
 >> iter 75000, loss: 0.001568
 >> iter 76000, loss: 0.001942
 >> iter 77000, loss: 0.001490
 >> iter 78000, loss: 0.001796
 >> iter 79000, loss: 0.001323
 >> iter 80000, loss: 0.001519
   Number of active neurons: 10
 >> iter 81000, loss: 0.001399
 >> iter 82000, loss: 0.001150
 >> iter 83000, loss: 0.001086
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.602446
 >> iter 2000, loss: 9.701142
 >> iter 3000, loss: 4.406552
 >> iter 4000, loss: 2.210298
 >> iter 5000, loss: 1.215497
 >> iter 6000, loss: 0.640891
 >> iter 7000, loss: 0.516442
 >> iter 8000, loss: 0.340398
 >> iter 9000, loss: 0.357015
 >> iter 10000, loss: 0.194845
   Number of active neurons: 10
 >> iter 11000, loss: 0.284594
 >> iter 12000, loss: 0.119640
 >> iter 13000, loss: 0.194222
 >> iter 14000, loss: 0.118509
 >> iter 15000, loss: 0.050458
 >> iter 16000, loss: 0.041114
 >> iter 17000, loss: 0.147799
 >> iter 18000, loss: 0.093374
 >> iter 19000, loss: 0.069827
 >> iter 20000, loss: 0.091389
   Number of active neurons: 10
 >> iter 21000, loss: 0.109378
 >> iter 22000, loss: 0.312477
 >> iter 23000, loss: 0.135975
 >> iter 24000, loss: 0.059180
 >> iter 25000, loss: 0.080220
 >> iter 26000, loss: 0.039841
 >> iter 27000, loss: 0.271858
 >> iter 28000, loss: 0.159311
 >> iter 29000, loss: 0.066406
 >> iter 30000, loss: 0.034838
   Number of active neurons: 10
 >> iter 31000, loss: 0.016591
 >> iter 32000, loss: 0.009554
 >> iter 33000, loss: 0.136397
 >> iter 34000, loss: 0.054299
 >> iter 35000, loss: 0.060663
 >> iter 36000, loss: 0.027057
 >> iter 37000, loss: 0.021681
 >> iter 38000, loss: 0.019020
 >> iter 39000, loss: 0.009881
 >> iter 40000, loss: 0.006679
   Number of active neurons: 10
 >> iter 41000, loss: 0.007603
 >> iter 42000, loss: 0.005135
 >> iter 43000, loss: 0.004106
 >> iter 44000, loss: 0.003201
 >> iter 45000, loss: 0.048810
 >> iter 46000, loss: 0.019876
 >> iter 47000, loss: 0.035112
 >> iter 48000, loss: 0.076172
 >> iter 49000, loss: 0.030381
 >> iter 50000, loss: 0.068628
   Number of active neurons: 10
 >> iter 51000, loss: 0.028119
 >> iter 52000, loss: 0.012110
 >> iter 53000, loss: 0.006281
 >> iter 54000, loss: 0.003688
 >> iter 55000, loss: 0.011674
 >> iter 56000, loss: 0.005792
 >> iter 57000, loss: 0.014959
 >> iter 58000, loss: 0.036308
 >> iter 59000, loss: 0.015046
 >> iter 60000, loss: 0.060216
   Number of active neurons: 10
 >> iter 61000, loss: 0.024371
 >> iter 62000, loss: 0.010792
 >> iter 63000, loss: 0.043517
 >> iter 64000, loss: 0.018103
 >> iter 65000, loss: 0.127480
 >> iter 66000, loss: 0.048979
 >> iter 67000, loss: 0.019352
 >> iter 68000, loss: 0.074293
 >> iter 69000, loss: 0.053096
 >> iter 70000, loss: 0.167122
   Number of active neurons: 10
 >> iter 71000, loss: 0.064920
 >> iter 72000, loss: 0.025847
 >> iter 73000, loss: 0.011131
 >> iter 74000, loss: 0.005555
 >> iter 75000, loss: 0.003252
 >> iter 76000, loss: 0.042129
 >> iter 77000, loss: 0.018760
 >> iter 78000, loss: 0.008405
 >> iter 79000, loss: 0.005165
 >> iter 80000, loss: 0.003186
   Number of active neurons: 10
 >> iter 81000, loss: 0.004725
 >> iter 82000, loss: 0.091998
 >> iter 83000, loss: 0.058968
 >> iter 84000, loss: 0.023559
 >> iter 85000, loss: 0.010005
 >> iter 86000, loss: 0.004900
 >> iter 87000, loss: 0.002892
 >> iter 88000, loss: 0.002159
 >> iter 89000, loss: 0.001781
 >> iter 90000, loss: 0.001570
   Number of active neurons: 10
 >> iter 91000, loss: 0.001437
 >> iter 92000, loss: 0.021978
 >> iter 93000, loss: 0.009155
 >> iter 94000, loss: 0.004345
 >> iter 95000, loss: 0.002488
 >> iter 96000, loss: 0.001709
 >> iter 97000, loss: 0.001425
 >> iter 98000, loss: 0.021693
 >> iter 99000, loss: 0.009408
 >> iter 100000, loss: 0.017915
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.814815
 >> iter 2000, loss: 9.417439
 >> iter 3000, loss: 4.354877
 >> iter 4000, loss: 2.178008
 >> iter 5000, loss: 1.107884
 >> iter 6000, loss: 0.558369
 >> iter 7000, loss: 0.248916
 >> iter 8000, loss: 0.239523
 >> iter 9000, loss: 0.212164
 >> iter 10000, loss: 0.153264
   Number of active neurons: 10
 >> iter 11000, loss: 0.112517
 >> iter 12000, loss: 0.150453
 >> iter 13000, loss: 0.200537
 >> iter 14000, loss: 0.081702
 >> iter 15000, loss: 0.231204
 >> iter 16000, loss: 0.162860
 >> iter 17000, loss: 0.099453
 >> iter 18000, loss: 0.042994
 >> iter 19000, loss: 0.080330
 >> iter 20000, loss: 0.069537
   Number of active neurons: 10
 >> iter 21000, loss: 0.208828
 >> iter 22000, loss: 0.148342
 >> iter 23000, loss: 0.071554
 >> iter 24000, loss: 0.073374
 >> iter 25000, loss: 0.209232
 >> iter 26000, loss: 0.094667
 >> iter 27000, loss: 0.071207
 >> iter 28000, loss: 0.034779
 >> iter 29000, loss: 0.031262
 >> iter 30000, loss: 0.014407
   Number of active neurons: 10
 >> iter 31000, loss: 0.008195
 >> iter 32000, loss: 0.005002
 >> iter 33000, loss: 0.057916
 >> iter 34000, loss: 0.023449
 >> iter 35000, loss: 0.011279
 >> iter 36000, loss: 0.046445
 >> iter 37000, loss: 0.214749
 >> iter 38000, loss: 0.082933
 >> iter 39000, loss: 0.040379
 >> iter 40000, loss: 0.074282
   Number of active neurons: 10
 >> iter 41000, loss: 0.031961
 >> iter 42000, loss: 0.013784
 >> iter 43000, loss: 0.006926
 >> iter 44000, loss: 0.004034
 >> iter 45000, loss: 0.002987
 >> iter 46000, loss: 0.002395
 >> iter 47000, loss: 0.002176
 >> iter 48000, loss: 0.002042
 >> iter 49000, loss: 0.007151
 >> iter 50000, loss: 0.004101
   Number of active neurons: 10
 >> iter 51000, loss: 0.002521
 >> iter 52000, loss: 0.001950
 >> iter 53000, loss: 0.001795
 >> iter 54000, loss: 0.001613
 >> iter 55000, loss: 0.001525
 >> iter 56000, loss: 0.001663
 >> iter 57000, loss: 0.001370
 >> iter 58000, loss: 0.001301
 >> iter 59000, loss: 0.001257
 >> iter 60000, loss: 0.001271
   Number of active neurons: 10
 >> iter 61000, loss: 0.001093
 >> iter 62000, loss: 0.001101
 >> iter 63000, loss: 0.001019
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.996905
 >> iter 2000, loss: 9.420083
 >> iter 3000, loss: 4.276934
 >> iter 4000, loss: 1.808612
 >> iter 5000, loss: 0.986759
 >> iter 6000, loss: 0.728643
 >> iter 7000, loss: 0.353622
 >> iter 8000, loss: 0.230027
 >> iter 9000, loss: 0.328869
 >> iter 10000, loss: 0.236466
   Number of active neurons: 10
 >> iter 11000, loss: 0.110392
 >> iter 12000, loss: 0.081455
 >> iter 13000, loss: 0.104092
 >> iter 14000, loss: 0.154162
 >> iter 15000, loss: 0.064672
 >> iter 16000, loss: 0.029718
 >> iter 17000, loss: 0.014924
 >> iter 18000, loss: 0.008954
 >> iter 19000, loss: 0.012583
 >> iter 20000, loss: 0.007501
   Number of active neurons: 10
 >> iter 21000, loss: 0.051433
 >> iter 22000, loss: 0.052709
 >> iter 23000, loss: 0.022659
 >> iter 24000, loss: 0.019219
 >> iter 25000, loss: 0.014177
 >> iter 26000, loss: 0.007538
 >> iter 27000, loss: 0.004989
 >> iter 28000, loss: 0.005789
 >> iter 29000, loss: 0.004714
 >> iter 30000, loss: 0.003256
   Number of active neurons: 10
 >> iter 31000, loss: 0.010619
 >> iter 32000, loss: 0.017740
 >> iter 33000, loss: 0.008549
 >> iter 34000, loss: 0.004464
 >> iter 35000, loss: 0.006035
 >> iter 36000, loss: 0.053865
 >> iter 37000, loss: 0.026662
 >> iter 38000, loss: 0.046668
 >> iter 39000, loss: 0.018889
 >> iter 40000, loss: 0.013328
   Number of active neurons: 10
 >> iter 41000, loss: 0.008181
 >> iter 42000, loss: 0.034908
 >> iter 43000, loss: 0.014391
 >> iter 44000, loss: 0.006730
 >> iter 45000, loss: 0.005459
 >> iter 46000, loss: 0.007055
 >> iter 47000, loss: 0.003829
 >> iter 48000, loss: 0.003891
 >> iter 49000, loss: 0.003190
 >> iter 50000, loss: 0.002080
   Number of active neurons: 10
 >> iter 51000, loss: 0.004700
 >> iter 52000, loss: 0.002670
 >> iter 53000, loss: 0.001860
 >> iter 54000, loss: 0.001736
 >> iter 55000, loss: 0.001444
 >> iter 56000, loss: 0.001304
 >> iter 57000, loss: 0.001612
 >> iter 58000, loss: 0.002664
 >> iter 59000, loss: 0.002126
 >> iter 60000, loss: 0.005700
   Number of active neurons: 10
 >> iter 61000, loss: 0.003427
 >> iter 62000, loss: 0.014798
 >> iter 63000, loss: 0.117547
 >> iter 64000, loss: 0.044551
 >> iter 65000, loss: 0.017401
 >> iter 66000, loss: 0.007588
 >> iter 67000, loss: 0.004066
 >> iter 68000, loss: 0.002380
 >> iter 69000, loss: 0.001884
 >> iter 70000, loss: 0.001607
   Number of active neurons: 10
 >> iter 71000, loss: 0.023044
 >> iter 72000, loss: 0.014039
 >> iter 73000, loss: 0.006939
 >> iter 74000, loss: 0.003463
 >> iter 75000, loss: 0.002124
 >> iter 76000, loss: 0.025856
 >> iter 77000, loss: 0.082146
 >> iter 78000, loss: 0.031404
 >> iter 79000, loss: 0.013281
 >> iter 80000, loss: 0.005908
   Number of active neurons: 10
 >> iter 81000, loss: 0.002933
 >> iter 82000, loss: 0.002599
 >> iter 83000, loss: 0.032497
 >> iter 84000, loss: 0.024321
 >> iter 85000, loss: 0.075313
 >> iter 86000, loss: 0.028955
 >> iter 87000, loss: 0.011573
 >> iter 88000, loss: 0.005613
 >> iter 89000, loss: 0.002971
 >> iter 90000, loss: 0.001854
   Number of active neurons: 10
 >> iter 91000, loss: 0.001422
 >> iter 92000, loss: 0.040921
 >> iter 93000, loss: 0.016139
 >> iter 94000, loss: 0.007264
 >> iter 95000, loss: 0.003696
 >> iter 96000, loss: 0.025274
 >> iter 97000, loss: 0.010720
 >> iter 98000, loss: 0.004859
 >> iter 99000, loss: 0.002752
 >> iter 100000, loss: 0.002824
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.773007
 >> iter 2000, loss: 9.931450
 >> iter 3000, loss: 4.371456
 >> iter 4000, loss: 1.946798
 >> iter 5000, loss: 1.034948
 >> iter 6000, loss: 0.739719
 >> iter 7000, loss: 0.581420
 >> iter 8000, loss: 0.285499
 >> iter 9000, loss: 0.447111
 >> iter 10000, loss: 0.226726
   Number of active neurons: 10
 >> iter 11000, loss: 0.108619
 >> iter 12000, loss: 0.105453
 >> iter 13000, loss: 0.109636
 >> iter 14000, loss: 0.095023
 >> iter 15000, loss: 0.053312
 >> iter 16000, loss: 0.027025
 >> iter 17000, loss: 0.027171
 >> iter 18000, loss: 0.013708
 >> iter 19000, loss: 0.008650
 >> iter 20000, loss: 0.059433
   Number of active neurons: 10
 >> iter 21000, loss: 0.091334
 >> iter 22000, loss: 0.054794
 >> iter 23000, loss: 0.041691
 >> iter 24000, loss: 0.019788
 >> iter 25000, loss: 0.024230
 >> iter 26000, loss: 0.174248
 >> iter 27000, loss: 0.067997
 >> iter 28000, loss: 0.070211
 >> iter 29000, loss: 0.053927
 >> iter 30000, loss: 0.026366
   Number of active neurons: 10
 >> iter 31000, loss: 0.021172
 >> iter 32000, loss: 0.266929
 >> iter 33000, loss: 0.210935
 >> iter 34000, loss: 0.083228
 >> iter 35000, loss: 0.034188
 >> iter 36000, loss: 0.041909
 >> iter 37000, loss: 0.057653
 >> iter 38000, loss: 0.024492
 >> iter 39000, loss: 0.011357
 >> iter 40000, loss: 0.010867
   Number of active neurons: 10
 >> iter 41000, loss: 0.005953
 >> iter 42000, loss: 0.004558
 >> iter 43000, loss: 0.063354
 >> iter 44000, loss: 0.100245
 >> iter 45000, loss: 0.039582
 >> iter 46000, loss: 0.017204
 >> iter 47000, loss: 0.009191
 >> iter 48000, loss: 0.020264
 >> iter 49000, loss: 0.009205
 >> iter 50000, loss: 0.004710
   Number of active neurons: 10
 >> iter 51000, loss: 0.003013
 >> iter 52000, loss: 0.002225
 >> iter 53000, loss: 0.011242
 >> iter 54000, loss: 0.064495
 >> iter 55000, loss: 0.025138
 >> iter 56000, loss: 0.067857
 >> iter 57000, loss: 0.028286
 >> iter 58000, loss: 0.012640
 >> iter 59000, loss: 0.005920
 >> iter 60000, loss: 0.003090
   Number of active neurons: 10
 >> iter 61000, loss: 0.069161
 >> iter 62000, loss: 0.027087
 >> iter 63000, loss: 0.011206
 >> iter 64000, loss: 0.005501
 >> iter 65000, loss: 0.003722
 >> iter 66000, loss: 0.002330
 >> iter 67000, loss: 0.001692
 >> iter 68000, loss: 0.001448
 >> iter 69000, loss: 0.008486
 >> iter 70000, loss: 0.004174
   Number of active neurons: 10
 >> iter 71000, loss: 0.002319
 >> iter 72000, loss: 0.001588
 >> iter 73000, loss: 0.001518
 >> iter 74000, loss: 0.001214
 >> iter 75000, loss: 0.001131
 >> iter 76000, loss: 0.001341
 >> iter 77000, loss: 0.001736
 >> iter 78000, loss: 0.007405
 >> iter 79000, loss: 0.054889
 >> iter 80000, loss: 0.021429
   Number of active neurons: 10
 >> iter 81000, loss: 0.011883
 >> iter 82000, loss: 0.005133
 >> iter 83000, loss: 0.052509
 >> iter 84000, loss: 0.060843
 >> iter 85000, loss: 0.039207
 >> iter 86000, loss: 0.015931
 >> iter 87000, loss: 0.061077
 >> iter 88000, loss: 0.024841
 >> iter 89000, loss: 0.010366
 >> iter 90000, loss: 0.004973
   Number of active neurons: 10
 >> iter 91000, loss: 0.003980
 >> iter 92000, loss: 0.004696
 >> iter 93000, loss: 0.002691
 >> iter 94000, loss: 0.001889
 >> iter 95000, loss: 0.198426
 >> iter 96000, loss: 0.076451
 >> iter 97000, loss: 0.029849
 >> iter 98000, loss: 0.012250
 >> iter 99000, loss: 0.005758
 >> iter 100000, loss: 0.004466
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.853984
 >> iter 2000, loss: 9.409720
 >> iter 3000, loss: 4.426269
 >> iter 4000, loss: 1.873452
 >> iter 5000, loss: 1.193696
 >> iter 6000, loss: 0.592847
 >> iter 7000, loss: 0.446813
 >> iter 8000, loss: 0.233420
 >> iter 9000, loss: 0.232935
 >> iter 10000, loss: 0.158361
   Number of active neurons: 10
 >> iter 11000, loss: 0.209863
 >> iter 12000, loss: 0.121348
 >> iter 13000, loss: 0.262583
 >> iter 14000, loss: 0.293648
 >> iter 15000, loss: 0.267665
 >> iter 16000, loss: 0.108553
 >> iter 17000, loss: 0.067461
 >> iter 18000, loss: 0.095119
 >> iter 19000, loss: 0.087628
 >> iter 20000, loss: 0.062068
   Number of active neurons: 10
 >> iter 21000, loss: 0.130262
 >> iter 22000, loss: 0.052087
 >> iter 23000, loss: 0.022726
 >> iter 24000, loss: 0.018183
 >> iter 25000, loss: 0.009040
 >> iter 26000, loss: 0.008069
 >> iter 27000, loss: 0.247194
 >> iter 28000, loss: 0.104855
 >> iter 29000, loss: 0.109490
 >> iter 30000, loss: 0.044726
   Number of active neurons: 10
 >> iter 31000, loss: 0.020338
 >> iter 32000, loss: 0.009872
 >> iter 33000, loss: 0.005740
 >> iter 34000, loss: 0.003826
 >> iter 35000, loss: 0.165159
 >> iter 36000, loss: 0.176010
 >> iter 37000, loss: 0.125959
 >> iter 38000, loss: 0.055226
 >> iter 39000, loss: 0.195368
 >> iter 40000, loss: 0.225577
   Number of active neurons: 10
 >> iter 41000, loss: 0.123990
 >> iter 42000, loss: 0.134233
 >> iter 43000, loss: 0.087762
 >> iter 44000, loss: 0.071783
 >> iter 45000, loss: 0.029942
 >> iter 46000, loss: 0.014019
 >> iter 47000, loss: 0.015481
 >> iter 48000, loss: 0.034857
 >> iter 49000, loss: 0.016376
 >> iter 50000, loss: 0.008236
   Number of active neurons: 10
 >> iter 51000, loss: 0.005065
 >> iter 52000, loss: 0.077436
 >> iter 53000, loss: 0.031073
 >> iter 54000, loss: 0.013178
 >> iter 55000, loss: 0.006543
 >> iter 56000, loss: 0.003800
 >> iter 57000, loss: 0.024559
 >> iter 58000, loss: 0.010368
 >> iter 59000, loss: 0.005355
 >> iter 60000, loss: 0.003026
   Number of active neurons: 10
 >> iter 61000, loss: 0.008778
 >> iter 62000, loss: 0.037104
 >> iter 63000, loss: 0.020919
 >> iter 64000, loss: 0.009030
 >> iter 65000, loss: 0.080323
 >> iter 66000, loss: 0.031502
 >> iter 67000, loss: 0.013276
 >> iter 68000, loss: 0.061260
 >> iter 69000, loss: 0.024784
 >> iter 70000, loss: 0.058220
   Number of active neurons: 10
 >> iter 71000, loss: 0.041444
 >> iter 72000, loss: 0.017205
 >> iter 73000, loss: 0.008358
 >> iter 74000, loss: 0.005445
 >> iter 75000, loss: 0.003326
 >> iter 76000, loss: 0.113657
 >> iter 77000, loss: 0.043884
 >> iter 78000, loss: 0.020035
 >> iter 79000, loss: 0.008758
 >> iter 80000, loss: 0.092851
   Number of active neurons: 10
 >> iter 81000, loss: 0.035767
 >> iter 82000, loss: 0.016347
 >> iter 83000, loss: 0.007397
 >> iter 84000, loss: 0.004035
 >> iter 85000, loss: 0.003082
 >> iter 86000, loss: 0.002252
 >> iter 87000, loss: 0.001961
 >> iter 88000, loss: 0.001901
 >> iter 89000, loss: 0.002142
 >> iter 90000, loss: 0.002119
   Number of active neurons: 10
 >> iter 91000, loss: 0.001720
 >> iter 92000, loss: 0.002304
 >> iter 93000, loss: 0.054402
 >> iter 94000, loss: 0.021058
 >> iter 95000, loss: 0.008659
 >> iter 96000, loss: 0.003997
 >> iter 97000, loss: 0.046536
 >> iter 98000, loss: 0.035780
 >> iter 99000, loss: 0.014125
 >> iter 100000, loss: 0.006471
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.029434
 >> iter 2000, loss: 10.905813
 >> iter 3000, loss: 4.747245
 >> iter 4000, loss: 2.131111
 >> iter 5000, loss: 0.837219
 >> iter 6000, loss: 0.376832
 >> iter 7000, loss: 0.180331
 >> iter 8000, loss: 0.082815
 >> iter 9000, loss: 0.092371
 >> iter 10000, loss: 0.171840
   Number of active neurons: 10
 >> iter 11000, loss: 0.074839
 >> iter 12000, loss: 0.077730
 >> iter 13000, loss: 0.119353
 >> iter 14000, loss: 0.049503
 >> iter 15000, loss: 0.024159
 >> iter 16000, loss: 0.013377
 >> iter 17000, loss: 0.066940
 >> iter 18000, loss: 0.035335
 >> iter 19000, loss: 0.063857
 >> iter 20000, loss: 0.027613
   Number of active neurons: 10
 >> iter 21000, loss: 0.017321
 >> iter 22000, loss: 0.010214
 >> iter 23000, loss: 0.006269
 >> iter 24000, loss: 0.004720
 >> iter 25000, loss: 0.004702
 >> iter 26000, loss: 0.003554
 >> iter 27000, loss: 0.030318
 >> iter 28000, loss: 0.014843
 >> iter 29000, loss: 0.007399
 >> iter 30000, loss: 0.004527
   Number of active neurons: 10
 >> iter 31000, loss: 0.003533
 >> iter 32000, loss: 0.003489
 >> iter 33000, loss: 0.009469
 >> iter 34000, loss: 0.107789
 >> iter 35000, loss: 0.058372
 >> iter 36000, loss: 0.040374
 >> iter 37000, loss: 0.048120
 >> iter 38000, loss: 0.020415
 >> iter 39000, loss: 0.035102
 >> iter 40000, loss: 0.018218
   Number of active neurons: 10
 >> iter 41000, loss: 0.010446
 >> iter 42000, loss: 0.005947
 >> iter 43000, loss: 0.003753
 >> iter 44000, loss: 0.002818
 >> iter 45000, loss: 0.002545
 >> iter 46000, loss: 0.002375
 >> iter 47000, loss: 0.002131
 >> iter 48000, loss: 0.001920
 >> iter 49000, loss: 0.001870
 >> iter 50000, loss: 0.001724
   Number of active neurons: 10
 >> iter 51000, loss: 0.022269
 >> iter 52000, loss: 0.010410
 >> iter 53000, loss: 0.008564
 >> iter 54000, loss: 0.011248
 >> iter 55000, loss: 0.005097
 >> iter 56000, loss: 0.002766
 >> iter 57000, loss: 0.072276
 >> iter 58000, loss: 0.027822
 >> iter 59000, loss: 0.011409
 >> iter 60000, loss: 0.005121
   Number of active neurons: 10
 >> iter 61000, loss: 0.002821
 >> iter 62000, loss: 0.002044
 >> iter 63000, loss: 0.001768
 >> iter 64000, loss: 0.001441
 >> iter 65000, loss: 0.008454
 >> iter 66000, loss: 0.004003
 >> iter 67000, loss: 0.002386
 >> iter 68000, loss: 0.001711
 >> iter 69000, loss: 0.004119
 >> iter 70000, loss: 0.005698
   Number of active neurons: 10
 >> iter 71000, loss: 0.003145
 >> iter 72000, loss: 0.002435
 >> iter 73000, loss: 0.001605
 >> iter 74000, loss: 0.025326
 >> iter 75000, loss: 0.010424
 >> iter 76000, loss: 0.004767
 >> iter 77000, loss: 0.102118
 >> iter 78000, loss: 0.039011
 >> iter 79000, loss: 0.015455
 >> iter 80000, loss: 0.006767
   Number of active neurons: 10
 >> iter 81000, loss: 0.008964
 >> iter 82000, loss: 0.004426
 >> iter 83000, loss: 0.002803
 >> iter 84000, loss: 0.001942
 >> iter 85000, loss: 0.001790
 >> iter 86000, loss: 0.001565
 >> iter 87000, loss: 0.001378
 >> iter 88000, loss: 0.029963
 >> iter 89000, loss: 0.012439
 >> iter 90000, loss: 0.011749
   Number of active neurons: 10
 >> iter 91000, loss: 0.005871
 >> iter 92000, loss: 0.003581
 >> iter 93000, loss: 0.002108
 >> iter 94000, loss: 0.001401
 >> iter 95000, loss: 0.001174
 >> iter 96000, loss: 0.001714
 >> iter 97000, loss: 0.001211
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.243703
 >> iter 2000, loss: 10.526572
 >> iter 3000, loss: 4.728749
 >> iter 4000, loss: 2.283782
 >> iter 5000, loss: 0.964253
 >> iter 6000, loss: 0.520811
 >> iter 7000, loss: 0.409662
 >> iter 8000, loss: 0.191968
 >> iter 9000, loss: 0.119790
 >> iter 10000, loss: 0.056784
   Number of active neurons: 10
 >> iter 11000, loss: 0.030499
 >> iter 12000, loss: 0.092830
 >> iter 13000, loss: 0.056509
 >> iter 14000, loss: 0.029831
 >> iter 15000, loss: 0.016475
 >> iter 16000, loss: 0.010909
 >> iter 17000, loss: 0.200929
 >> iter 18000, loss: 0.101344
 >> iter 19000, loss: 0.076848
 >> iter 20000, loss: 0.113675
   Number of active neurons: 10
 >> iter 21000, loss: 0.049840
 >> iter 22000, loss: 0.022965
 >> iter 23000, loss: 0.012484
 >> iter 24000, loss: 0.008607
 >> iter 25000, loss: 0.128152
 >> iter 26000, loss: 0.052502
 >> iter 27000, loss: 0.023523
 >> iter 28000, loss: 0.012216
 >> iter 29000, loss: 0.007737
 >> iter 30000, loss: 0.005951
   Number of active neurons: 10
 >> iter 31000, loss: 0.004773
 >> iter 32000, loss: 0.004266
 >> iter 33000, loss: 0.003438
 >> iter 34000, loss: 0.002971
 >> iter 35000, loss: 0.002791
 >> iter 36000, loss: 0.067538
 >> iter 37000, loss: 0.027122
 >> iter 38000, loss: 0.012542
 >> iter 39000, loss: 0.006579
 >> iter 40000, loss: 0.010733
   Number of active neurons: 10
 >> iter 41000, loss: 0.009906
 >> iter 42000, loss: 0.172728
 >> iter 43000, loss: 0.081164
 >> iter 44000, loss: 0.068200
 >> iter 45000, loss: 0.027106
 >> iter 46000, loss: 0.011918
 >> iter 47000, loss: 0.006108
 >> iter 48000, loss: 0.004015
 >> iter 49000, loss: 0.003037
 >> iter 50000, loss: 0.002582
   Number of active neurons: 10
 >> iter 51000, loss: 0.002341
 >> iter 52000, loss: 0.002218
 >> iter 53000, loss: 0.136521
 >> iter 54000, loss: 0.070138
 >> iter 55000, loss: 0.027708
 >> iter 56000, loss: 0.013645
 >> iter 57000, loss: 0.006731
 >> iter 58000, loss: 0.007911
 >> iter 59000, loss: 0.004492
 >> iter 60000, loss: 0.003100
   Number of active neurons: 10
 >> iter 61000, loss: 0.003144
 >> iter 62000, loss: 0.022287
 >> iter 63000, loss: 0.010251
 >> iter 64000, loss: 0.007048
 >> iter 65000, loss: 0.004021
 >> iter 66000, loss: 0.002906
 >> iter 67000, loss: 0.002386
 >> iter 68000, loss: 0.001966
 >> iter 69000, loss: 0.001686
 >> iter 70000, loss: 0.001728
   Number of active neurons: 10
 >> iter 71000, loss: 0.001738
 >> iter 72000, loss: 0.016243
 >> iter 73000, loss: 0.007305
 >> iter 74000, loss: 0.003694
 >> iter 75000, loss: 0.002498
 >> iter 76000, loss: 0.002002
 >> iter 77000, loss: 0.001717
 >> iter 78000, loss: 0.001767
 >> iter 79000, loss: 0.001538
 >> iter 80000, loss: 0.001348
   Number of active neurons: 10
 >> iter 81000, loss: 0.001247
 >> iter 82000, loss: 0.001373
 >> iter 83000, loss: 0.001324
 >> iter 84000, loss: 0.001310
 >> iter 85000, loss: 0.001311
 >> iter 86000, loss: 0.022242
 >> iter 87000, loss: 0.009648
 >> iter 88000, loss: 0.004326
 >> iter 89000, loss: 0.002499
 >> iter 90000, loss: 0.001650
   Number of active neurons: 10
 >> iter 91000, loss: 0.001276
 >> iter 92000, loss: 0.001131
 >> iter 93000, loss: 0.001048
 >> iter 94000, loss: 0.001080
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.788158
 >> iter 2000, loss: 9.588282
 >> iter 3000, loss: 4.184191
 >> iter 4000, loss: 2.076743
 >> iter 5000, loss: 1.143439
 >> iter 6000, loss: 0.469961
 >> iter 7000, loss: 0.311943
 >> iter 8000, loss: 0.436095
 >> iter 9000, loss: 0.204825
 >> iter 10000, loss: 0.355340
   Number of active neurons: 10
 >> iter 11000, loss: 0.243039
 >> iter 12000, loss: 0.218612
 >> iter 13000, loss: 0.092773
 >> iter 14000, loss: 0.100119
 >> iter 15000, loss: 0.122367
 >> iter 16000, loss: 0.136486
 >> iter 17000, loss: 0.111939
 >> iter 18000, loss: 0.047517
 >> iter 19000, loss: 0.128525
 >> iter 20000, loss: 0.090411
   Number of active neurons: 10
 >> iter 21000, loss: 0.038043
 >> iter 22000, loss: 0.067898
 >> iter 23000, loss: 0.117228
 >> iter 24000, loss: 0.370675
 >> iter 25000, loss: 0.150764
 >> iter 26000, loss: 0.060512
 >> iter 27000, loss: 0.027744
 >> iter 28000, loss: 0.026765
 >> iter 29000, loss: 0.013233
 >> iter 30000, loss: 0.007532
   Number of active neurons: 10
 >> iter 31000, loss: 0.036804
 >> iter 32000, loss: 0.028680
 >> iter 33000, loss: 0.015793
 >> iter 34000, loss: 0.049501
 >> iter 35000, loss: 0.042545
 >> iter 36000, loss: 0.022865
 >> iter 37000, loss: 0.026555
 >> iter 38000, loss: 0.012155
 >> iter 39000, loss: 0.007136
 >> iter 40000, loss: 0.044753
   Number of active neurons: 10
 >> iter 41000, loss: 0.018950
 >> iter 42000, loss: 0.012483
 >> iter 43000, loss: 0.006231
 >> iter 44000, loss: 0.003647
 >> iter 45000, loss: 0.002739
 >> iter 46000, loss: 0.002712
 >> iter 47000, loss: 0.005319
 >> iter 48000, loss: 0.003257
 >> iter 49000, loss: 0.002216
 >> iter 50000, loss: 0.047360
   Number of active neurons: 10
 >> iter 51000, loss: 0.018822
 >> iter 52000, loss: 0.017260
 >> iter 53000, loss: 0.043097
 >> iter 54000, loss: 0.017768
 >> iter 55000, loss: 0.007649
 >> iter 56000, loss: 0.003839
 >> iter 57000, loss: 0.024093
 >> iter 58000, loss: 0.015857
 >> iter 59000, loss: 0.009211
 >> iter 60000, loss: 0.005558
   Number of active neurons: 10
 >> iter 61000, loss: 0.003617
 >> iter 62000, loss: 0.008537
 >> iter 63000, loss: 0.082900
 >> iter 64000, loss: 0.037963
 >> iter 65000, loss: 0.014982
 >> iter 66000, loss: 0.037360
 >> iter 67000, loss: 0.024815
 >> iter 68000, loss: 0.011545
 >> iter 69000, loss: 0.006045
 >> iter 70000, loss: 0.012596
   Number of active neurons: 10
 >> iter 71000, loss: 0.005617
 >> iter 72000, loss: 0.003126
 >> iter 73000, loss: 0.001986
 >> iter 74000, loss: 0.036655
 >> iter 75000, loss: 0.110108
 >> iter 76000, loss: 0.042183
 >> iter 77000, loss: 0.019897
 >> iter 78000, loss: 0.035113
 >> iter 79000, loss: 0.017431
 >> iter 80000, loss: 0.007630
   Number of active neurons: 10
 >> iter 81000, loss: 0.003940
 >> iter 82000, loss: 0.002327
 >> iter 83000, loss: 0.001687
 >> iter 84000, loss: 0.011530
 >> iter 85000, loss: 0.010439
 >> iter 86000, loss: 0.004860
 >> iter 87000, loss: 0.002795
 >> iter 88000, loss: 0.001964
 >> iter 89000, loss: 0.001476
 >> iter 90000, loss: 0.004878
   Number of active neurons: 10
 >> iter 91000, loss: 0.002364
 >> iter 92000, loss: 0.001457
 >> iter 93000, loss: 0.001096
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

