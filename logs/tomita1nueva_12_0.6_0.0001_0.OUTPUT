 > Problema: tomita1nueva
 > Args:
   - Hidden size: 12
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.990200
 >> iter 2000, loss: 4.089083
 >> iter 3000, loss: 1.533464
 >> iter 4000, loss: 0.590252
 >> iter 5000, loss: 0.240112
 >> iter 6000, loss: 0.122581
 >> iter 7000, loss: 0.078163
 >> iter 8000, loss: 0.055142
 >> iter 9000, loss: 0.039900
 >> iter 10000, loss: 0.032711
   Number of active neurons: 5
 >> iter 11000, loss: 0.036561
 >> iter 12000, loss: 0.037506
 >> iter 13000, loss: 0.031771
 >> iter 14000, loss: 0.031165
 >> iter 15000, loss: 0.030791
 >> iter 16000, loss: 0.028923
 >> iter 17000, loss: 0.043465
 >> iter 18000, loss: 0.038121
 >> iter 19000, loss: 0.031339
 >> iter 20000, loss: 0.032352
   Number of active neurons: 3
 >> iter 21000, loss: 0.029113
 >> iter 22000, loss: 0.027497
 >> iter 23000, loss: 0.027468
 >> iter 24000, loss: 0.024043
 >> iter 25000, loss: 0.022997
 >> iter 26000, loss: 0.036761
 >> iter 27000, loss: 0.032823
 >> iter 28000, loss: 0.027730
 >> iter 29000, loss: 0.034007
 >> iter 30000, loss: 0.026588
   Number of active neurons: 2
 >> iter 31000, loss: 0.023817
 >> iter 32000, loss: 0.022329
 >> iter 33000, loss: 0.021509
 >> iter 34000, loss: 0.022348
 >> iter 35000, loss: 0.026367
 >> iter 36000, loss: 0.024467
 >> iter 37000, loss: 0.026538
 >> iter 38000, loss: 0.022823
 >> iter 39000, loss: 0.030404
 >> iter 40000, loss: 0.024820
   Number of active neurons: 2
 >> iter 41000, loss: 0.024282
 >> iter 42000, loss: 0.022197
 >> iter 43000, loss: 0.024146
 >> iter 44000, loss: 0.023534
 >> iter 45000, loss: 0.037452
 >> iter 46000, loss: 0.026396
 >> iter 47000, loss: 0.021606
 >> iter 48000, loss: 0.021243
 >> iter 49000, loss: 0.026627
 >> iter 50000, loss: 0.022216
   Number of active neurons: 2
 >> iter 51000, loss: 0.030317
 >> iter 52000, loss: 0.025067
 >> iter 53000, loss: 0.023063
 >> iter 54000, loss: 0.035905
 >> iter 55000, loss: 0.028228
 >> iter 56000, loss: 0.028325
 >> iter 57000, loss: 0.023149
 >> iter 58000, loss: 0.033885
 >> iter 59000, loss: 0.026230
 >> iter 60000, loss: 0.032138
   Number of active neurons: 2
 >> iter 61000, loss: 0.033205
 >> iter 62000, loss: 0.037614
 >> iter 63000, loss: 0.030507
 >> iter 64000, loss: 0.031519
 >> iter 65000, loss: 0.026554
 >> iter 66000, loss: 0.025231
 >> iter 67000, loss: 0.023278
 >> iter 68000, loss: 0.022153
 >> iter 69000, loss: 0.025912
 >> iter 70000, loss: 0.022436
   Number of active neurons: 2
 >> iter 71000, loss: 0.023259
 >> iter 72000, loss: 0.035763
 >> iter 73000, loss: 0.026486
 >> iter 74000, loss: 0.030665
 >> iter 75000, loss: 0.039682
 >> iter 76000, loss: 0.027471
 >> iter 77000, loss: 0.030407
 >> iter 78000, loss: 0.031119
 >> iter 79000, loss: 0.028348
 >> iter 80000, loss: 0.031417
   Number of active neurons: 2
 >> iter 81000, loss: 0.028713
 >> iter 82000, loss: 0.024527
 >> iter 83000, loss: 0.021430
 >> iter 84000, loss: 0.020151
 >> iter 85000, loss: 0.019655
 >> iter 86000, loss: 0.024145
 >> iter 87000, loss: 0.021386
 >> iter 88000, loss: 0.040027
 >> iter 89000, loss: 0.027639
 >> iter 90000, loss: 0.024532
   Number of active neurons: 1
 >> iter 91000, loss: 0.040914
 >> iter 92000, loss: 0.028557
 >> iter 93000, loss: 0.021806
 >> iter 94000, loss: 0.021187
 >> iter 95000, loss: 0.033763
 >> iter 96000, loss: 0.026120
 >> iter 97000, loss: 0.023538
 >> iter 98000, loss: 0.025417
 >> iter 99000, loss: 0.021424
 >> iter 100000, loss: 0.022852
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.003132
 >> iter 2000, loss: 4.159604
 >> iter 3000, loss: 1.557353
 >> iter 4000, loss: 0.603679
 >> iter 5000, loss: 0.243201
 >> iter 6000, loss: 0.114099
 >> iter 7000, loss: 0.069706
 >> iter 8000, loss: 0.047932
 >> iter 9000, loss: 0.037594
 >> iter 10000, loss: 0.044826
   Number of active neurons: 6
 >> iter 11000, loss: 0.035877
 >> iter 12000, loss: 0.030546
 >> iter 13000, loss: 0.036794
 >> iter 14000, loss: 0.030935
 >> iter 15000, loss: 0.028038
 >> iter 16000, loss: 0.026472
 >> iter 17000, loss: 0.032805
 >> iter 18000, loss: 0.031052
 >> iter 19000, loss: 0.027815
 >> iter 20000, loss: 0.029679
   Number of active neurons: 2
 >> iter 21000, loss: 0.034827
 >> iter 22000, loss: 0.026606
 >> iter 23000, loss: 0.022918
 >> iter 24000, loss: 0.029658
 >> iter 25000, loss: 0.024271
 >> iter 26000, loss: 0.023353
 >> iter 27000, loss: 0.022627
 >> iter 28000, loss: 0.020050
 >> iter 29000, loss: 0.023418
 >> iter 30000, loss: 0.020893
   Number of active neurons: 2
 >> iter 31000, loss: 0.019886
 >> iter 32000, loss: 0.020488
 >> iter 33000, loss: 0.024244
 >> iter 34000, loss: 0.021314
 >> iter 35000, loss: 0.024774
 >> iter 36000, loss: 0.022003
 >> iter 37000, loss: 0.022697
 >> iter 38000, loss: 0.027459
 >> iter 39000, loss: 0.024021
 >> iter 40000, loss: 0.023379
   Number of active neurons: 2
 >> iter 41000, loss: 0.025697
 >> iter 42000, loss: 0.024587
 >> iter 43000, loss: 0.023394
 >> iter 44000, loss: 0.022404
 >> iter 45000, loss: 0.022223
 >> iter 46000, loss: 0.020391
 >> iter 47000, loss: 0.020511
 >> iter 48000, loss: 0.028671
 >> iter 49000, loss: 0.037918
 >> iter 50000, loss: 0.028580
   Number of active neurons: 2
 >> iter 51000, loss: 0.025079
 >> iter 52000, loss: 0.021565
 >> iter 53000, loss: 0.019564
 >> iter 54000, loss: 0.020104
 >> iter 55000, loss: 0.025589
 >> iter 56000, loss: 0.022722
 >> iter 57000, loss: 0.032318
 >> iter 58000, loss: 0.026410
 >> iter 59000, loss: 0.025530
 >> iter 60000, loss: 0.023903
   Number of active neurons: 2
 >> iter 61000, loss: 0.022680
 >> iter 62000, loss: 0.020462
 >> iter 63000, loss: 0.025465
 >> iter 64000, loss: 0.023926
 >> iter 65000, loss: 0.022996
 >> iter 66000, loss: 0.020664
 >> iter 67000, loss: 0.023581
 >> iter 68000, loss: 0.021641
 >> iter 69000, loss: 0.023982
 >> iter 70000, loss: 0.030012
   Number of active neurons: 2
 >> iter 71000, loss: 0.025072
 >> iter 72000, loss: 0.024889
 >> iter 73000, loss: 0.034067
 >> iter 74000, loss: 0.031879
 >> iter 75000, loss: 0.035523
 >> iter 76000, loss: 0.037197
 >> iter 77000, loss: 0.025746
 >> iter 78000, loss: 0.027316
 >> iter 79000, loss: 0.024868
 >> iter 80000, loss: 0.035314
   Number of active neurons: 2
 >> iter 81000, loss: 0.029578
 >> iter 82000, loss: 0.024450
 >> iter 83000, loss: 0.036723
 >> iter 84000, loss: 0.039665
 >> iter 85000, loss: 0.029309
 >> iter 86000, loss: 0.025264
 >> iter 87000, loss: 0.031014
 >> iter 88000, loss: 0.023775
 >> iter 89000, loss: 0.045646
 >> iter 90000, loss: 0.032855
   Number of active neurons: 2
 >> iter 91000, loss: 0.028403
 >> iter 92000, loss: 0.036827
 >> iter 93000, loss: 0.030022
 >> iter 94000, loss: 0.023135
 >> iter 95000, loss: 0.027266
 >> iter 96000, loss: 0.022879
 >> iter 97000, loss: 0.022751
 >> iter 98000, loss: 0.025961
 >> iter 99000, loss: 0.023076
 >> iter 100000, loss: 0.021830
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.915288
 >> iter 2000, loss: 4.057648
 >> iter 3000, loss: 1.526936
 >> iter 4000, loss: 0.583212
 >> iter 5000, loss: 0.236408
 >> iter 6000, loss: 0.126769
 >> iter 7000, loss: 0.065784
 >> iter 8000, loss: 0.042497
 >> iter 9000, loss: 0.035959
 >> iter 10000, loss: 0.033402
   Number of active neurons: 4
 >> iter 11000, loss: 0.030323
 >> iter 12000, loss: 0.031076
 >> iter 13000, loss: 0.029798
 >> iter 14000, loss: 0.025987
 >> iter 15000, loss: 0.024947
 >> iter 16000, loss: 0.030942
 >> iter 17000, loss: 0.026269
 >> iter 18000, loss: 0.027590
 >> iter 19000, loss: 0.034189
 >> iter 20000, loss: 0.027510
   Number of active neurons: 3
 >> iter 21000, loss: 0.025980
 >> iter 22000, loss: 0.027645
 >> iter 23000, loss: 0.027253
 >> iter 24000, loss: 0.026680
 >> iter 25000, loss: 0.028682
 >> iter 26000, loss: 0.028476
 >> iter 27000, loss: 0.036398
 >> iter 28000, loss: 0.037663
 >> iter 29000, loss: 0.029078
 >> iter 30000, loss: 0.024473
   Number of active neurons: 3
 >> iter 31000, loss: 0.035576
 >> iter 32000, loss: 0.028460
 >> iter 33000, loss: 0.027485
 >> iter 34000, loss: 0.025020
 >> iter 35000, loss: 0.023603
 >> iter 36000, loss: 0.023637
 >> iter 37000, loss: 0.045490
 >> iter 38000, loss: 0.030997
 >> iter 39000, loss: 0.059266
 >> iter 40000, loss: 0.045681
   Number of active neurons: 2
 >> iter 41000, loss: 0.031925
 >> iter 42000, loss: 0.041835
 >> iter 43000, loss: 0.030255
 >> iter 44000, loss: 0.026742
 >> iter 45000, loss: 0.024441
 >> iter 46000, loss: 0.035517
 >> iter 47000, loss: 0.028121
 >> iter 48000, loss: 0.026380
 >> iter 49000, loss: 0.045020
 >> iter 50000, loss: 0.049278
   Number of active neurons: 2
 >> iter 51000, loss: 0.037733
 >> iter 52000, loss: 0.028935
 >> iter 53000, loss: 0.023110
 >> iter 54000, loss: 0.021107
 >> iter 55000, loss: 0.024555
 >> iter 56000, loss: 0.022319
 >> iter 57000, loss: 0.021002
 >> iter 58000, loss: 0.023400
 >> iter 59000, loss: 0.031106
 >> iter 60000, loss: 0.027454
   Number of active neurons: 2
 >> iter 61000, loss: 0.029426
 >> iter 62000, loss: 0.040769
 >> iter 63000, loss: 0.036959
 >> iter 64000, loss: 0.057548
 >> iter 65000, loss: 0.038154
 >> iter 66000, loss: 0.027604
 >> iter 67000, loss: 0.023369
 >> iter 68000, loss: 0.021753
 >> iter 69000, loss: 0.021326
 >> iter 70000, loss: 0.020945
   Number of active neurons: 1
 >> iter 71000, loss: 0.021130
 >> iter 72000, loss: 0.019646
 >> iter 73000, loss: 0.021515
 >> iter 74000, loss: 0.019732
 >> iter 75000, loss: 0.020015
 >> iter 76000, loss: 0.018894
 >> iter 77000, loss: 0.020013
 >> iter 78000, loss: 0.023132
 >> iter 79000, loss: 0.019596
 >> iter 80000, loss: 0.019135
   Number of active neurons: 1
 >> iter 81000, loss: 0.020955
 >> iter 82000, loss: 0.035801
 >> iter 83000, loss: 0.023743
 >> iter 84000, loss: 0.024317
 >> iter 85000, loss: 0.022081
 >> iter 86000, loss: 0.021907
 >> iter 87000, loss: 0.023693
 >> iter 88000, loss: 0.024481
 >> iter 89000, loss: 0.021646
 >> iter 90000, loss: 0.020032
   Number of active neurons: 1
 >> iter 91000, loss: 0.017841
 >> iter 92000, loss: 0.017074
 >> iter 93000, loss: 0.022221
 >> iter 94000, loss: 0.018641
 >> iter 95000, loss: 0.016495
 >> iter 96000, loss: 0.017323
 >> iter 97000, loss: 0.019599
 >> iter 98000, loss: 0.016107
 >> iter 99000, loss: 0.016718
 >> iter 100000, loss: 0.018421
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.946685
 >> iter 2000, loss: 4.076260
 >> iter 3000, loss: 1.522037
 >> iter 4000, loss: 0.585113
 >> iter 5000, loss: 0.236548
 >> iter 6000, loss: 0.114087
 >> iter 7000, loss: 0.065220
 >> iter 8000, loss: 0.043656
 >> iter 9000, loss: 0.033480
 >> iter 10000, loss: 0.029871
   Number of active neurons: 4
 >> iter 11000, loss: 0.028762
 >> iter 12000, loss: 0.027697
 >> iter 13000, loss: 0.029434
 >> iter 14000, loss: 0.030536
 >> iter 15000, loss: 0.027801
 >> iter 16000, loss: 0.026132
 >> iter 17000, loss: 0.031693
 >> iter 18000, loss: 0.027991
 >> iter 19000, loss: 0.025709
 >> iter 20000, loss: 0.030142
   Number of active neurons: 3
 >> iter 21000, loss: 0.026858
 >> iter 22000, loss: 0.024429
 >> iter 23000, loss: 0.023249
 >> iter 24000, loss: 0.024587
 >> iter 25000, loss: 0.027214
 >> iter 26000, loss: 0.035403
 >> iter 27000, loss: 0.030838
 >> iter 28000, loss: 0.032227
 >> iter 29000, loss: 0.038355
 >> iter 30000, loss: 0.038567
   Number of active neurons: 3
 >> iter 31000, loss: 0.029834
 >> iter 32000, loss: 0.027941
 >> iter 33000, loss: 0.027204
 >> iter 34000, loss: 0.024851
 >> iter 35000, loss: 0.024799
 >> iter 36000, loss: 0.026275
 >> iter 37000, loss: 0.027873
 >> iter 38000, loss: 0.026520
 >> iter 39000, loss: 0.025434
 >> iter 40000, loss: 0.025118
   Number of active neurons: 3
 >> iter 41000, loss: 0.028234
 >> iter 42000, loss: 0.024023
 >> iter 43000, loss: 0.024850
 >> iter 44000, loss: 0.031565
 >> iter 45000, loss: 0.034022
 >> iter 46000, loss: 0.033539
 >> iter 47000, loss: 0.041190
 >> iter 48000, loss: 0.035580
 >> iter 49000, loss: 0.028166
 >> iter 50000, loss: 0.024235
   Number of active neurons: 2
 >> iter 51000, loss: 0.022165
 >> iter 52000, loss: 0.022456
 >> iter 53000, loss: 0.024879
 >> iter 54000, loss: 0.029289
 >> iter 55000, loss: 0.024113
 >> iter 56000, loss: 0.023841
 >> iter 57000, loss: 0.021792
 >> iter 58000, loss: 0.039592
 >> iter 59000, loss: 0.027744
 >> iter 60000, loss: 0.021891
   Number of active neurons: 1
 >> iter 61000, loss: 0.020446
 >> iter 62000, loss: 0.019630
 >> iter 63000, loss: 0.018711
 >> iter 64000, loss: 0.022428
 >> iter 65000, loss: 0.021255
 >> iter 66000, loss: 0.019189
 >> iter 67000, loss: 0.018647
 >> iter 68000, loss: 0.020616
 >> iter 69000, loss: 0.018603
 >> iter 70000, loss: 0.018545
   Number of active neurons: 1
 >> iter 71000, loss: 0.017839
 >> iter 72000, loss: 0.016649
 >> iter 73000, loss: 0.018710
 >> iter 74000, loss: 0.019953
 >> iter 75000, loss: 0.017732
 >> iter 76000, loss: 0.021775
 >> iter 77000, loss: 0.022007
 >> iter 78000, loss: 0.023523
 >> iter 79000, loss: 0.025499
 >> iter 80000, loss: 0.020780
   Number of active neurons: 1
 >> iter 81000, loss: 0.017234
 >> iter 82000, loss: 0.016946
 >> iter 83000, loss: 0.016502
 >> iter 84000, loss: 0.039914
 >> iter 85000, loss: 0.035113
 >> iter 86000, loss: 0.024988
 >> iter 87000, loss: 0.022734
 >> iter 88000, loss: 0.019201
 >> iter 89000, loss: 0.025873
 >> iter 90000, loss: 0.020605
   Number of active neurons: 1
 >> iter 91000, loss: 0.029377
 >> iter 92000, loss: 0.029094
 >> iter 93000, loss: 0.021778
 >> iter 94000, loss: 0.018094
 >> iter 95000, loss: 0.020398
 >> iter 96000, loss: 0.017177
 >> iter 97000, loss: 0.017702
 >> iter 98000, loss: 0.017210
 >> iter 99000, loss: 0.024752
 >> iter 100000, loss: 0.019576
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.997454
 >> iter 2000, loss: 4.087116
 >> iter 3000, loss: 1.547499
 >> iter 4000, loss: 0.609418
 >> iter 5000, loss: 0.265269
 >> iter 6000, loss: 0.118589
 >> iter 7000, loss: 0.063417
 >> iter 8000, loss: 0.046099
 >> iter 9000, loss: 0.038374
 >> iter 10000, loss: 0.059477
   Number of active neurons: 5
 >> iter 11000, loss: 0.051129
 >> iter 12000, loss: 0.035947
 >> iter 13000, loss: 0.033588
 >> iter 14000, loss: 0.030173
 >> iter 15000, loss: 0.029578
 >> iter 16000, loss: 0.027670
 >> iter 17000, loss: 0.037064
 >> iter 18000, loss: 0.030726
 >> iter 19000, loss: 0.029256
 >> iter 20000, loss: 0.044520
   Number of active neurons: 3
 >> iter 21000, loss: 0.031415
 >> iter 22000, loss: 0.033180
 >> iter 23000, loss: 0.032389
 >> iter 24000, loss: 0.025681
 >> iter 25000, loss: 0.024272
 >> iter 26000, loss: 0.024065
 >> iter 27000, loss: 0.030786
 >> iter 28000, loss: 0.025369
 >> iter 29000, loss: 0.037863
 >> iter 30000, loss: 0.030194
   Number of active neurons: 2
 >> iter 31000, loss: 0.028969
 >> iter 32000, loss: 0.023979
 >> iter 33000, loss: 0.036004
 >> iter 34000, loss: 0.032365
 >> iter 35000, loss: 0.029462
 >> iter 36000, loss: 0.022936
 >> iter 37000, loss: 0.019582
 >> iter 38000, loss: 0.022715
 >> iter 39000, loss: 0.020096
 >> iter 40000, loss: 0.022928
   Number of active neurons: 1
 >> iter 41000, loss: 0.024680
 >> iter 42000, loss: 0.019242
 >> iter 43000, loss: 0.024635
 >> iter 44000, loss: 0.019119
 >> iter 45000, loss: 0.016801
 >> iter 46000, loss: 0.016194
 >> iter 47000, loss: 0.020198
 >> iter 48000, loss: 0.028012
 >> iter 49000, loss: 0.022021
 >> iter 50000, loss: 0.018792
   Number of active neurons: 1
 >> iter 51000, loss: 0.021791
 >> iter 52000, loss: 0.022493
 >> iter 53000, loss: 0.020178
 >> iter 54000, loss: 0.018145
 >> iter 55000, loss: 0.025097
 >> iter 56000, loss: 0.020556
 >> iter 57000, loss: 0.029179
 >> iter 58000, loss: 0.019897
 >> iter 59000, loss: 0.017098
 >> iter 60000, loss: 0.018415
   Number of active neurons: 1
 >> iter 61000, loss: 0.038132
 >> iter 62000, loss: 0.024103
 >> iter 63000, loss: 0.025037
 >> iter 64000, loss: 0.023396
 >> iter 65000, loss: 0.020881
 >> iter 66000, loss: 0.019969
 >> iter 67000, loss: 0.022560
 >> iter 68000, loss: 0.018194
 >> iter 69000, loss: 0.018874
 >> iter 70000, loss: 0.016794
   Number of active neurons: 1
 >> iter 71000, loss: 0.016287
 >> iter 72000, loss: 0.018071
 >> iter 73000, loss: 0.017205
 >> iter 74000, loss: 0.019615
 >> iter 75000, loss: 0.018238
 >> iter 76000, loss: 0.023678
 >> iter 77000, loss: 0.018576
 >> iter 78000, loss: 0.019119
 >> iter 79000, loss: 0.018456
 >> iter 80000, loss: 0.016033
   Number of active neurons: 1
 >> iter 81000, loss: 0.018194
 >> iter 82000, loss: 0.017086
 >> iter 83000, loss: 0.017207
 >> iter 84000, loss: 0.022478
 >> iter 85000, loss: 0.018931
 >> iter 86000, loss: 0.019402
 >> iter 87000, loss: 0.016723
 >> iter 88000, loss: 0.015651
 >> iter 89000, loss: 0.019452
 >> iter 90000, loss: 0.018466
   Number of active neurons: 1
 >> iter 91000, loss: 0.016863
 >> iter 92000, loss: 0.016083
 >> iter 93000, loss: 0.043765
 >> iter 94000, loss: 0.028385
 >> iter 95000, loss: 0.029346
 >> iter 96000, loss: 0.026067
 >> iter 97000, loss: 0.021397
 >> iter 98000, loss: 0.017781
 >> iter 99000, loss: 0.025252
 >> iter 100000, loss: 0.020886
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.933561
 >> iter 2000, loss: 4.103280
 >> iter 3000, loss: 1.539212
 >> iter 4000, loss: 0.589531
 >> iter 5000, loss: 0.240105
 >> iter 6000, loss: 0.114550
 >> iter 7000, loss: 0.062787
 >> iter 8000, loss: 0.043532
 >> iter 9000, loss: 0.033642
 >> iter 10000, loss: 0.040207
   Number of active neurons: 4
 >> iter 11000, loss: 0.032783
 >> iter 12000, loss: 0.028092
 >> iter 13000, loss: 0.026355
 >> iter 14000, loss: 0.026325
 >> iter 15000, loss: 0.026279
 >> iter 16000, loss: 0.025292
 >> iter 17000, loss: 0.037184
 >> iter 18000, loss: 0.028719
 >> iter 19000, loss: 0.027257
 >> iter 20000, loss: 0.026761
   Number of active neurons: 3
 >> iter 21000, loss: 0.033739
 >> iter 22000, loss: 0.027076
 >> iter 23000, loss: 0.024321
 >> iter 24000, loss: 0.022141
 >> iter 25000, loss: 0.021563
 >> iter 26000, loss: 0.024423
 >> iter 27000, loss: 0.028829
 >> iter 28000, loss: 0.027551
 >> iter 29000, loss: 0.022956
 >> iter 30000, loss: 0.026811
   Number of active neurons: 2
 >> iter 31000, loss: 0.028555
 >> iter 32000, loss: 0.026920
 >> iter 33000, loss: 0.025088
 >> iter 34000, loss: 0.022465
 >> iter 35000, loss: 0.021422
 >> iter 36000, loss: 0.028632
 >> iter 37000, loss: 0.025927
 >> iter 38000, loss: 0.023166
 >> iter 39000, loss: 0.024197
 >> iter 40000, loss: 0.021084
   Number of active neurons: 2
 >> iter 41000, loss: 0.023302
 >> iter 42000, loss: 0.021145
 >> iter 43000, loss: 0.024921
 >> iter 44000, loss: 0.022369
 >> iter 45000, loss: 0.022392
 >> iter 46000, loss: 0.019678
 >> iter 47000, loss: 0.024371
 >> iter 48000, loss: 0.022339
 >> iter 49000, loss: 0.023149
 >> iter 50000, loss: 0.022659
   Number of active neurons: 2
 >> iter 51000, loss: 0.021092
 >> iter 52000, loss: 0.025431
 >> iter 53000, loss: 0.028723
 >> iter 54000, loss: 0.024441
 >> iter 55000, loss: 0.024115
 >> iter 56000, loss: 0.023284
 >> iter 57000, loss: 0.021892
 >> iter 58000, loss: 0.019625
 >> iter 59000, loss: 0.023764
 >> iter 60000, loss: 0.030327
   Number of active neurons: 2
 >> iter 61000, loss: 0.028054
 >> iter 62000, loss: 0.037240
 >> iter 63000, loss: 0.026813
 >> iter 64000, loss: 0.022008
 >> iter 65000, loss: 0.027389
 >> iter 66000, loss: 0.027489
 >> iter 67000, loss: 0.022647
 >> iter 68000, loss: 0.033689
 >> iter 69000, loss: 0.028362
 >> iter 70000, loss: 0.023734
   Number of active neurons: 2
 >> iter 71000, loss: 0.025814
 >> iter 72000, loss: 0.030475
 >> iter 73000, loss: 0.024175
 >> iter 74000, loss: 0.035896
 >> iter 75000, loss: 0.027428
 >> iter 76000, loss: 0.023223
 >> iter 77000, loss: 0.025211
 >> iter 78000, loss: 0.028803
 >> iter 79000, loss: 0.025265
 >> iter 80000, loss: 0.029445
   Number of active neurons: 2
 >> iter 81000, loss: 0.031692
 >> iter 82000, loss: 0.024277
 >> iter 83000, loss: 0.023067
 >> iter 84000, loss: 0.025294
 >> iter 85000, loss: 0.042976
 >> iter 86000, loss: 0.030432
 >> iter 87000, loss: 0.023834
 >> iter 88000, loss: 0.022215
 >> iter 89000, loss: 0.020837
 >> iter 90000, loss: 0.021849
   Number of active neurons: 2
 >> iter 91000, loss: 0.022589
 >> iter 92000, loss: 0.042819
 >> iter 93000, loss: 0.029609
 >> iter 94000, loss: 0.035564
 >> iter 95000, loss: 0.029619
 >> iter 96000, loss: 0.024934
 >> iter 97000, loss: 0.027967
 >> iter 98000, loss: 0.022613
 >> iter 99000, loss: 0.023086
 >> iter 100000, loss: 0.034217
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.965850
 >> iter 2000, loss: 4.075451
 >> iter 3000, loss: 1.523156
 >> iter 4000, loss: 0.584068
 >> iter 5000, loss: 0.242183
 >> iter 6000, loss: 0.123792
 >> iter 7000, loss: 0.064811
 >> iter 8000, loss: 0.055294
 >> iter 9000, loss: 0.042157
 >> iter 10000, loss: 0.035013
   Number of active neurons: 4
 >> iter 11000, loss: 0.042302
 >> iter 12000, loss: 0.037662
 >> iter 13000, loss: 0.032222
 >> iter 14000, loss: 0.028513
 >> iter 15000, loss: 0.027661
 >> iter 16000, loss: 0.028097
 >> iter 17000, loss: 0.025628
 >> iter 18000, loss: 0.030384
 >> iter 19000, loss: 0.027353
 >> iter 20000, loss: 0.027093
   Number of active neurons: 4
 >> iter 21000, loss: 0.028546
 >> iter 22000, loss: 0.028373
 >> iter 23000, loss: 0.029847
 >> iter 24000, loss: 0.027137
 >> iter 25000, loss: 0.043818
 >> iter 26000, loss: 0.030390
 >> iter 27000, loss: 0.030876
 >> iter 28000, loss: 0.027388
 >> iter 29000, loss: 0.024999
 >> iter 30000, loss: 0.025116
   Number of active neurons: 3
 >> iter 31000, loss: 0.023183
 >> iter 32000, loss: 0.023926
 >> iter 33000, loss: 0.027648
 >> iter 34000, loss: 0.024691
 >> iter 35000, loss: 0.027342
 >> iter 36000, loss: 0.028523
 >> iter 37000, loss: 0.026536
 >> iter 38000, loss: 0.023971
 >> iter 39000, loss: 0.023506
 >> iter 40000, loss: 0.030641
   Number of active neurons: 3
 >> iter 41000, loss: 0.043759
 >> iter 42000, loss: 0.034257
 >> iter 43000, loss: 0.043157
 >> iter 44000, loss: 0.032629
 >> iter 45000, loss: 0.031699
 >> iter 46000, loss: 0.032012
 >> iter 47000, loss: 0.029134
 >> iter 48000, loss: 0.023700
 >> iter 49000, loss: 0.023891
 >> iter 50000, loss: 0.022914
   Number of active neurons: 2
 >> iter 51000, loss: 0.024469
 >> iter 52000, loss: 0.024642
 >> iter 53000, loss: 0.026464
 >> iter 54000, loss: 0.026165
 >> iter 55000, loss: 0.024310
 >> iter 56000, loss: 0.024990
 >> iter 57000, loss: 0.022668
 >> iter 58000, loss: 0.023798
 >> iter 59000, loss: 0.043115
 >> iter 60000, loss: 0.030236
   Number of active neurons: 2
 >> iter 61000, loss: 0.024691
 >> iter 62000, loss: 0.027455
 >> iter 63000, loss: 0.024650
 >> iter 64000, loss: 0.022574
 >> iter 65000, loss: 0.022831
 >> iter 66000, loss: 0.026508
 >> iter 67000, loss: 0.035035
 >> iter 68000, loss: 0.025822
 >> iter 69000, loss: 0.023789
 >> iter 70000, loss: 0.024087
   Number of active neurons: 2
 >> iter 71000, loss: 0.021293
 >> iter 72000, loss: 0.021528
 >> iter 73000, loss: 0.026407
 >> iter 74000, loss: 0.020386
 >> iter 75000, loss: 0.020203
 >> iter 76000, loss: 0.026994
 >> iter 77000, loss: 0.024154
 >> iter 78000, loss: 0.019201
 >> iter 79000, loss: 0.017631
 >> iter 80000, loss: 0.059459
   Number of active neurons: 1
 >> iter 81000, loss: 0.033569
 >> iter 82000, loss: 0.022889
 >> iter 83000, loss: 0.020710
 >> iter 84000, loss: 0.022893
 >> iter 85000, loss: 0.020118
 >> iter 86000, loss: 0.018414
 >> iter 87000, loss: 0.021555
 >> iter 88000, loss: 0.017438
 >> iter 89000, loss: 0.018049
 >> iter 90000, loss: 0.020642
   Number of active neurons: 1
 >> iter 91000, loss: 0.025712
 >> iter 92000, loss: 0.019182
 >> iter 93000, loss: 0.031199
 >> iter 94000, loss: 0.028979
 >> iter 95000, loss: 0.031433
 >> iter 96000, loss: 0.032652
 >> iter 97000, loss: 0.023407
 >> iter 98000, loss: 0.021496
 >> iter 99000, loss: 0.021829
 >> iter 100000, loss: 0.018815
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.961804
 >> iter 2000, loss: 4.078404
 >> iter 3000, loss: 1.526901
 >> iter 4000, loss: 0.585590
 >> iter 5000, loss: 0.240669
 >> iter 6000, loss: 0.118639
 >> iter 7000, loss: 0.063771
 >> iter 8000, loss: 0.040459
 >> iter 9000, loss: 0.031677
 >> iter 10000, loss: 0.031616
   Number of active neurons: 3
 >> iter 11000, loss: 0.044224
 >> iter 12000, loss: 0.049199
 >> iter 13000, loss: 0.032253
 >> iter 14000, loss: 0.031692
 >> iter 15000, loss: 0.028144
 >> iter 16000, loss: 0.027519
 >> iter 17000, loss: 0.034591
 >> iter 18000, loss: 0.027495
 >> iter 19000, loss: 0.028105
 >> iter 20000, loss: 0.026117
   Number of active neurons: 3
 >> iter 21000, loss: 0.024185
 >> iter 22000, loss: 0.023035
 >> iter 23000, loss: 0.026581
 >> iter 24000, loss: 0.022964
 >> iter 25000, loss: 0.021664
 >> iter 26000, loss: 0.026891
 >> iter 27000, loss: 0.024239
 >> iter 28000, loss: 0.027122
 >> iter 29000, loss: 0.024269
 >> iter 30000, loss: 0.024983
   Number of active neurons: 3
 >> iter 31000, loss: 0.026050
 >> iter 32000, loss: 0.024416
 >> iter 33000, loss: 0.025167
 >> iter 34000, loss: 0.041465
 >> iter 35000, loss: 0.032976
 >> iter 36000, loss: 0.028870
 >> iter 37000, loss: 0.030307
 >> iter 38000, loss: 0.025218
 >> iter 39000, loss: 0.023736
 >> iter 40000, loss: 0.026016
   Number of active neurons: 3
 >> iter 41000, loss: 0.052654
 >> iter 42000, loss: 0.040312
 >> iter 43000, loss: 0.033874
 >> iter 44000, loss: 0.034898
 >> iter 45000, loss: 0.026005
 >> iter 46000, loss: 0.024804
 >> iter 47000, loss: 0.023819
 >> iter 48000, loss: 0.022425
 >> iter 49000, loss: 0.023903
 >> iter 50000, loss: 0.026072
   Number of active neurons: 3
 >> iter 51000, loss: 0.037149
 >> iter 52000, loss: 0.030536
 >> iter 53000, loss: 0.029511
 >> iter 54000, loss: 0.043605
 >> iter 55000, loss: 0.039848
 >> iter 56000, loss: 0.029110
 >> iter 57000, loss: 0.024311
 >> iter 58000, loss: 0.032981
 >> iter 59000, loss: 0.028900
 >> iter 60000, loss: 0.025353
   Number of active neurons: 3
 >> iter 61000, loss: 0.023604
 >> iter 62000, loss: 0.027063
 >> iter 63000, loss: 0.030526
 >> iter 64000, loss: 0.026423
 >> iter 65000, loss: 0.025296
 >> iter 66000, loss: 0.023388
 >> iter 67000, loss: 0.026506
 >> iter 68000, loss: 0.030763
 >> iter 69000, loss: 0.029258
 >> iter 70000, loss: 0.030336
   Number of active neurons: 3
 >> iter 71000, loss: 0.028020
 >> iter 72000, loss: 0.026691
 >> iter 73000, loss: 0.025852
 >> iter 74000, loss: 0.033197
 >> iter 75000, loss: 0.027000
 >> iter 76000, loss: 0.026685
 >> iter 77000, loss: 0.024581
 >> iter 78000, loss: 0.045429
 >> iter 79000, loss: 0.030833
 >> iter 80000, loss: 0.026262
   Number of active neurons: 2
 >> iter 81000, loss: 0.029520
 >> iter 82000, loss: 0.024212
 >> iter 83000, loss: 0.024075
 >> iter 84000, loss: 0.021625
 >> iter 85000, loss: 0.024062
 >> iter 86000, loss: 0.023606
 >> iter 87000, loss: 0.023497
 >> iter 88000, loss: 0.022272
 >> iter 89000, loss: 0.019198
 >> iter 90000, loss: 0.022402
   Number of active neurons: 1
 >> iter 91000, loss: 0.021560
 >> iter 92000, loss: 0.021795
 >> iter 93000, loss: 0.049105
 >> iter 94000, loss: 0.030350
 >> iter 95000, loss: 0.022556
 >> iter 96000, loss: 0.020556
 >> iter 97000, loss: 0.033061
 >> iter 98000, loss: 0.025406
 >> iter 99000, loss: 0.022869
 >> iter 100000, loss: 0.017923
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.951804
 >> iter 2000, loss: 4.075569
 >> iter 3000, loss: 1.531999
 >> iter 4000, loss: 0.584143
 >> iter 5000, loss: 0.235657
 >> iter 6000, loss: 0.108658
 >> iter 7000, loss: 0.060794
 >> iter 8000, loss: 0.042260
 >> iter 9000, loss: 0.039535
 >> iter 10000, loss: 0.035762
   Number of active neurons: 4
 >> iter 11000, loss: 0.045699
 >> iter 12000, loss: 0.034198
 >> iter 13000, loss: 0.031630
 >> iter 14000, loss: 0.027800
 >> iter 15000, loss: 0.052029
 >> iter 16000, loss: 0.036524
 >> iter 17000, loss: 0.026653
 >> iter 18000, loss: 0.026571
 >> iter 19000, loss: 0.027422
 >> iter 20000, loss: 0.026278
   Number of active neurons: 2
 >> iter 21000, loss: 0.024197
 >> iter 22000, loss: 0.029856
 >> iter 23000, loss: 0.024209
 >> iter 24000, loss: 0.024758
 >> iter 25000, loss: 0.028799
 >> iter 26000, loss: 0.035112
 >> iter 27000, loss: 0.027254
 >> iter 28000, loss: 0.024977
 >> iter 29000, loss: 0.022414
 >> iter 30000, loss: 0.020900
   Number of active neurons: 2
 >> iter 31000, loss: 0.020447
 >> iter 32000, loss: 0.019413
 >> iter 33000, loss: 0.020903
 >> iter 34000, loss: 0.020307
 >> iter 35000, loss: 0.033054
 >> iter 36000, loss: 0.026251
 >> iter 37000, loss: 0.030776
 >> iter 38000, loss: 0.029868
 >> iter 39000, loss: 0.030729
 >> iter 40000, loss: 0.023951
   Number of active neurons: 2
 >> iter 41000, loss: 0.024231
 >> iter 42000, loss: 0.021401
 >> iter 43000, loss: 0.020801
 >> iter 44000, loss: 0.029768
 >> iter 45000, loss: 0.035816
 >> iter 46000, loss: 0.027436
 >> iter 47000, loss: 0.022033
 >> iter 48000, loss: 0.020602
 >> iter 49000, loss: 0.020992
 >> iter 50000, loss: 0.024397
   Number of active neurons: 2
 >> iter 51000, loss: 0.021292
 >> iter 52000, loss: 0.022860
 >> iter 53000, loss: 0.032064
 >> iter 54000, loss: 0.034217
 >> iter 55000, loss: 0.037624
 >> iter 56000, loss: 0.026189
 >> iter 57000, loss: 0.021220
 >> iter 58000, loss: 0.022035
 >> iter 59000, loss: 0.025881
 >> iter 60000, loss: 0.021719
   Number of active neurons: 2
 >> iter 61000, loss: 0.027509
 >> iter 62000, loss: 0.026219
 >> iter 63000, loss: 0.022395
 >> iter 64000, loss: 0.023211
 >> iter 65000, loss: 0.031161
 >> iter 66000, loss: 0.035896
 >> iter 67000, loss: 0.026483
 >> iter 68000, loss: 0.021927
 >> iter 69000, loss: 0.027714
 >> iter 70000, loss: 0.023327
   Number of active neurons: 2
 >> iter 71000, loss: 0.027345
 >> iter 72000, loss: 0.022459
 >> iter 73000, loss: 0.023313
 >> iter 74000, loss: 0.022830
 >> iter 75000, loss: 0.021481
 >> iter 76000, loss: 0.024361
 >> iter 77000, loss: 0.049894
 >> iter 78000, loss: 0.033179
 >> iter 79000, loss: 0.028161
 >> iter 80000, loss: 0.024491
   Number of active neurons: 2
 >> iter 81000, loss: 0.022278
 >> iter 82000, loss: 0.034252
 >> iter 83000, loss: 0.033907
 >> iter 84000, loss: 0.029608
 >> iter 85000, loss: 0.031167
 >> iter 86000, loss: 0.050700
 >> iter 87000, loss: 0.031383
 >> iter 88000, loss: 0.028487
 >> iter 89000, loss: 0.027473
 >> iter 90000, loss: 0.034236
   Number of active neurons: 1
 >> iter 91000, loss: 0.026099
 >> iter 92000, loss: 0.030323
 >> iter 93000, loss: 0.023555
 >> iter 94000, loss: 0.025271
 >> iter 95000, loss: 0.021603
 >> iter 96000, loss: 0.019652
 >> iter 97000, loss: 0.019989
 >> iter 98000, loss: 0.025169
 >> iter 99000, loss: 0.022286
 >> iter 100000, loss: 0.019403
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 10.904467
 >> iter 2000, loss: 4.047435
 >> iter 3000, loss: 1.533755
 >> iter 4000, loss: 0.585708
 >> iter 5000, loss: 0.245321
 >> iter 6000, loss: 0.112109
 >> iter 7000, loss: 0.062467
 >> iter 8000, loss: 0.041009
 >> iter 9000, loss: 0.033686
 >> iter 10000, loss: 0.033595
   Number of active neurons: 3
 >> iter 11000, loss: 0.029201
 >> iter 12000, loss: 0.027842
 >> iter 13000, loss: 0.025204
 >> iter 14000, loss: 0.022725
 >> iter 15000, loss: 0.022899
 >> iter 16000, loss: 0.027738
 >> iter 17000, loss: 0.032268
 >> iter 18000, loss: 0.026020
 >> iter 19000, loss: 0.022866
 >> iter 20000, loss: 0.023163
   Number of active neurons: 3
 >> iter 21000, loss: 0.032958
 >> iter 22000, loss: 0.027173
 >> iter 23000, loss: 0.024152
 >> iter 24000, loss: 0.022935
 >> iter 25000, loss: 0.028813
 >> iter 26000, loss: 0.026545
 >> iter 27000, loss: 0.026940
 >> iter 28000, loss: 0.025293
 >> iter 29000, loss: 0.029098
 >> iter 30000, loss: 0.029521
   Number of active neurons: 3
 >> iter 31000, loss: 0.024796
 >> iter 32000, loss: 0.024083
 >> iter 33000, loss: 0.032367
 >> iter 34000, loss: 0.033810
 >> iter 35000, loss: 0.029749
 >> iter 36000, loss: 0.024069
 >> iter 37000, loss: 0.026403
 >> iter 38000, loss: 0.024357
 >> iter 39000, loss: 0.023765
 >> iter 40000, loss: 0.023560
   Number of active neurons: 3
 >> iter 41000, loss: 0.023983
 >> iter 42000, loss: 0.025061
 >> iter 43000, loss: 0.035319
 >> iter 44000, loss: 0.024748
 >> iter 45000, loss: 0.025249
 >> iter 46000, loss: 0.022518
 >> iter 47000, loss: 0.024758
 >> iter 48000, loss: 0.022395
 >> iter 49000, loss: 0.022387
 >> iter 50000, loss: 0.021290
   Number of active neurons: 2
 >> iter 51000, loss: 0.022936
 >> iter 52000, loss: 0.021578
 >> iter 53000, loss: 0.027915
 >> iter 54000, loss: 0.025471
 >> iter 55000, loss: 0.022065
 >> iter 56000, loss: 0.024627
 >> iter 57000, loss: 0.023003
 >> iter 58000, loss: 0.023744
 >> iter 59000, loss: 0.024213
 >> iter 60000, loss: 0.020026
   Number of active neurons: 2
 >> iter 61000, loss: 0.022050
 >> iter 62000, loss: 0.021312
 >> iter 63000, loss: 0.028429
 >> iter 64000, loss: 0.023369
 >> iter 65000, loss: 0.022076
 >> iter 66000, loss: 0.022335
 >> iter 67000, loss: 0.021876
 >> iter 68000, loss: 0.021399
 >> iter 69000, loss: 0.020435
 >> iter 70000, loss: 0.028455
   Number of active neurons: 2
 >> iter 71000, loss: 0.027023
 >> iter 72000, loss: 0.023132
 >> iter 73000, loss: 0.029839
 >> iter 74000, loss: 0.027561
 >> iter 75000, loss: 0.024962
 >> iter 76000, loss: 0.036073
 >> iter 77000, loss: 0.024728
 >> iter 78000, loss: 0.026509
 >> iter 79000, loss: 0.051048
 >> iter 80000, loss: 0.032705
   Number of active neurons: 2
 >> iter 81000, loss: 0.026757
 >> iter 82000, loss: 0.023268
 >> iter 83000, loss: 0.024061
 >> iter 84000, loss: 0.024230
 >> iter 85000, loss: 0.045759
 >> iter 86000, loss: 0.036961
 >> iter 87000, loss: 0.028852
 >> iter 88000, loss: 0.025483
 >> iter 89000, loss: 0.044862
 >> iter 90000, loss: 0.033449
   Number of active neurons: 2
 >> iter 91000, loss: 0.037044
 >> iter 92000, loss: 0.026404
 >> iter 93000, loss: 0.027304
 >> iter 94000, loss: 0.039942
 >> iter 95000, loss: 0.028062
 >> iter 96000, loss: 0.031700
 >> iter 97000, loss: 0.026316
 >> iter 98000, loss: 0.022635
 >> iter 99000, loss: 0.025063
 >> iter 100000, loss: 0.039582
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 10.892483
 >> iter 2000, loss: 4.043881
 >> iter 3000, loss: 1.520118
 >> iter 4000, loss: 0.589768
 >> iter 5000, loss: 0.241377
 >> iter 6000, loss: 0.110768
 >> iter 7000, loss: 0.083376
 >> iter 8000, loss: 0.050076
 >> iter 9000, loss: 0.037199
 >> iter 10000, loss: 0.034777
   Number of active neurons: 4
 >> iter 11000, loss: 0.040378
 >> iter 12000, loss: 0.030084
 >> iter 13000, loss: 0.026935
 >> iter 14000, loss: 0.032892
 >> iter 15000, loss: 0.034866
 >> iter 16000, loss: 0.026638
 >> iter 17000, loss: 0.026108
 >> iter 18000, loss: 0.025317
 >> iter 19000, loss: 0.024529
 >> iter 20000, loss: 0.025831
   Number of active neurons: 3
 >> iter 21000, loss: 0.030039
 >> iter 22000, loss: 0.030087
 >> iter 23000, loss: 0.036651
 >> iter 24000, loss: 0.029432
 >> iter 25000, loss: 0.028481
 >> iter 26000, loss: 0.025647
 >> iter 27000, loss: 0.027341
 >> iter 28000, loss: 0.031274
 >> iter 29000, loss: 0.027445
 >> iter 30000, loss: 0.030672
   Number of active neurons: 2
 >> iter 31000, loss: 0.025624
 >> iter 32000, loss: 0.023011
 >> iter 33000, loss: 0.024519
 >> iter 34000, loss: 0.031560
 >> iter 35000, loss: 0.023660
 >> iter 36000, loss: 0.023047
 >> iter 37000, loss: 0.021526
 >> iter 38000, loss: 0.021089
 >> iter 39000, loss: 0.020943
 >> iter 40000, loss: 0.021606
   Number of active neurons: 2
 >> iter 41000, loss: 0.021066
 >> iter 42000, loss: 0.021639
 >> iter 43000, loss: 0.023577
 >> iter 44000, loss: 0.036519
 >> iter 45000, loss: 0.033533
 >> iter 46000, loss: 0.037541
 >> iter 47000, loss: 0.026637
 >> iter 48000, loss: 0.021388
 >> iter 49000, loss: 0.021818
 >> iter 50000, loss: 0.021034
   Number of active neurons: 2
 >> iter 51000, loss: 0.019307
 >> iter 52000, loss: 0.025929
 >> iter 53000, loss: 0.022875
 >> iter 54000, loss: 0.021236
 >> iter 55000, loss: 0.025698
 >> iter 56000, loss: 0.031598
 >> iter 57000, loss: 0.023383
 >> iter 58000, loss: 0.020954
 >> iter 59000, loss: 0.025559
 >> iter 60000, loss: 0.023023
   Number of active neurons: 1
 >> iter 61000, loss: 0.020393
 >> iter 62000, loss: 0.051673
 >> iter 63000, loss: 0.035513
 >> iter 64000, loss: 0.025799
 >> iter 65000, loss: 0.021537
 >> iter 66000, loss: 0.020408
 >> iter 67000, loss: 0.022665
 >> iter 68000, loss: 0.020235
 >> iter 69000, loss: 0.036735
 >> iter 70000, loss: 0.026515
   Number of active neurons: 1
 >> iter 71000, loss: 0.020138
 >> iter 72000, loss: 0.018025
 >> iter 73000, loss: 0.019832
 >> iter 74000, loss: 0.016589
 >> iter 75000, loss: 0.021284
 >> iter 76000, loss: 0.020188
 >> iter 77000, loss: 0.033478
 >> iter 78000, loss: 0.023791
 >> iter 79000, loss: 0.022476
 >> iter 80000, loss: 0.044582
   Number of active neurons: 1
 >> iter 81000, loss: 0.027901
 >> iter 82000, loss: 0.026225
 >> iter 83000, loss: 0.021123
 >> iter 84000, loss: 0.023901
 >> iter 85000, loss: 0.022647
 >> iter 86000, loss: 0.018391
 >> iter 87000, loss: 0.019875
 >> iter 88000, loss: 0.016788
 >> iter 89000, loss: 0.033662
 >> iter 90000, loss: 0.023886
   Number of active neurons: 1
 >> iter 91000, loss: 0.020527
 >> iter 92000, loss: 0.017985
 >> iter 93000, loss: 0.018188
 >> iter 94000, loss: 0.017500
 >> iter 95000, loss: 0.017644
 >> iter 96000, loss: 0.023904
 >> iter 97000, loss: 0.020439
 >> iter 98000, loss: 0.017974
 >> iter 99000, loss: 0.019362
 >> iter 100000, loss: 0.021769
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.969293
 >> iter 2000, loss: 4.081831
 >> iter 3000, loss: 1.528256
 >> iter 4000, loss: 0.592406
 >> iter 5000, loss: 0.252995
 >> iter 6000, loss: 0.120632
 >> iter 7000, loss: 0.075615
 >> iter 8000, loss: 0.048602
 >> iter 9000, loss: 0.035819
 >> iter 10000, loss: 0.033445
   Number of active neurons: 5
 >> iter 11000, loss: 0.035839
 >> iter 12000, loss: 0.042020
 >> iter 13000, loss: 0.033162
 >> iter 14000, loss: 0.032149
 >> iter 15000, loss: 0.033192
 >> iter 16000, loss: 0.033731
 >> iter 17000, loss: 0.037844
 >> iter 18000, loss: 0.031235
 >> iter 19000, loss: 0.047094
 >> iter 20000, loss: 0.033373
   Number of active neurons: 2
 >> iter 21000, loss: 0.026350
 >> iter 22000, loss: 0.023336
 >> iter 23000, loss: 0.032707
 >> iter 24000, loss: 0.027837
 >> iter 25000, loss: 0.024535
 >> iter 26000, loss: 0.022421
 >> iter 27000, loss: 0.032035
 >> iter 28000, loss: 0.025652
 >> iter 29000, loss: 0.024208
 >> iter 30000, loss: 0.021352
   Number of active neurons: 1
 >> iter 31000, loss: 0.020346
 >> iter 32000, loss: 0.022023
 >> iter 33000, loss: 0.021793
 >> iter 34000, loss: 0.019605
 >> iter 35000, loss: 0.027275
 >> iter 36000, loss: 0.022241
 >> iter 37000, loss: 0.020503
 >> iter 38000, loss: 0.017854
 >> iter 39000, loss: 0.020633
 >> iter 40000, loss: 0.019798
   Number of active neurons: 1
 >> iter 41000, loss: 0.017260
 >> iter 42000, loss: 0.021818
 >> iter 43000, loss: 0.019629
 >> iter 44000, loss: 0.028383
 >> iter 45000, loss: 0.030974
 >> iter 46000, loss: 0.023266
 >> iter 47000, loss: 0.026428
 >> iter 48000, loss: 0.029399
 >> iter 49000, loss: 0.024277
 >> iter 50000, loss: 0.030644
   Number of active neurons: 1
 >> iter 51000, loss: 0.024817
 >> iter 52000, loss: 0.020032
 >> iter 53000, loss: 0.046002
 >> iter 54000, loss: 0.027120
 >> iter 55000, loss: 0.023023
 >> iter 56000, loss: 0.018603
 >> iter 57000, loss: 0.017155
 >> iter 58000, loss: 0.016939
 >> iter 59000, loss: 0.027155
 >> iter 60000, loss: 0.020053
   Number of active neurons: 1
 >> iter 61000, loss: 0.022715
 >> iter 62000, loss: 0.022486
 >> iter 63000, loss: 0.021644
 >> iter 64000, loss: 0.033986
 >> iter 65000, loss: 0.022515
 >> iter 66000, loss: 0.025753
 >> iter 67000, loss: 0.026323
 >> iter 68000, loss: 0.021249
 >> iter 69000, loss: 0.027232
 >> iter 70000, loss: 0.021456
   Number of active neurons: 1
 >> iter 71000, loss: 0.020662
 >> iter 72000, loss: 0.020422
 >> iter 73000, loss: 0.034021
 >> iter 74000, loss: 0.037673
 >> iter 75000, loss: 0.028225
 >> iter 76000, loss: 0.025996
 >> iter 77000, loss: 0.019428
 >> iter 78000, loss: 0.017648
 >> iter 79000, loss: 0.020718
 >> iter 80000, loss: 0.017473
   Number of active neurons: 1
 >> iter 81000, loss: 0.016278
 >> iter 82000, loss: 0.018425
 >> iter 83000, loss: 0.016801
 >> iter 84000, loss: 0.016890
 >> iter 85000, loss: 0.016948
 >> iter 86000, loss: 0.016874
 >> iter 87000, loss: 0.023061
 >> iter 88000, loss: 0.022705
 >> iter 89000, loss: 0.021060
 >> iter 90000, loss: 0.019403
   Number of active neurons: 1
 >> iter 91000, loss: 0.017249
 >> iter 92000, loss: 0.016208
 >> iter 93000, loss: 0.015537
 >> iter 94000, loss: 0.017086
 >> iter 95000, loss: 0.019335
 >> iter 96000, loss: 0.023933
 >> iter 97000, loss: 0.018907
 >> iter 98000, loss: 0.019862
 >> iter 99000, loss: 0.029921
 >> iter 100000, loss: 0.027007
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.936605
 >> iter 2000, loss: 4.071230
 >> iter 3000, loss: 1.528924
 >> iter 4000, loss: 0.587809
 >> iter 5000, loss: 0.246737
 >> iter 6000, loss: 0.111183
 >> iter 7000, loss: 0.069365
 >> iter 8000, loss: 0.044974
 >> iter 9000, loss: 0.038958
 >> iter 10000, loss: 0.033715
   Number of active neurons: 6
 >> iter 11000, loss: 0.034151
 >> iter 12000, loss: 0.030221
 >> iter 13000, loss: 0.029197
 >> iter 14000, loss: 0.035565
 >> iter 15000, loss: 0.039175
 >> iter 16000, loss: 0.029565
 >> iter 17000, loss: 0.029392
 >> iter 18000, loss: 0.027780
 >> iter 19000, loss: 0.037711
 >> iter 20000, loss: 0.031250
   Number of active neurons: 3
 >> iter 21000, loss: 0.026345
 >> iter 22000, loss: 0.024663
 >> iter 23000, loss: 0.028834
 >> iter 24000, loss: 0.027327
 >> iter 25000, loss: 0.027507
 >> iter 26000, loss: 0.026099
 >> iter 27000, loss: 0.024076
 >> iter 28000, loss: 0.027803
 >> iter 29000, loss: 0.024387
 >> iter 30000, loss: 0.027575
   Number of active neurons: 2
 >> iter 31000, loss: 0.035990
 >> iter 32000, loss: 0.028716
 >> iter 33000, loss: 0.029756
 >> iter 34000, loss: 0.035601
 >> iter 35000, loss: 0.027180
 >> iter 36000, loss: 0.021820
 >> iter 37000, loss: 0.022406
 >> iter 38000, loss: 0.022189
 >> iter 39000, loss: 0.035964
 >> iter 40000, loss: 0.026324
   Number of active neurons: 2
 >> iter 41000, loss: 0.033774
 >> iter 42000, loss: 0.032147
 >> iter 43000, loss: 0.028712
 >> iter 44000, loss: 0.024248
 >> iter 45000, loss: 0.029085
 >> iter 46000, loss: 0.045066
 >> iter 47000, loss: 0.028877
 >> iter 48000, loss: 0.023420
 >> iter 49000, loss: 0.020333
 >> iter 50000, loss: 0.025085
   Number of active neurons: 2
 >> iter 51000, loss: 0.022430
 >> iter 52000, loss: 0.020055
 >> iter 53000, loss: 0.020767
 >> iter 54000, loss: 0.025633
 >> iter 55000, loss: 0.022189
 >> iter 56000, loss: 0.023593
 >> iter 57000, loss: 0.058002
 >> iter 58000, loss: 0.046310
 >> iter 59000, loss: 0.029819
 >> iter 60000, loss: 0.024076
   Number of active neurons: 2
 >> iter 61000, loss: 0.024201
 >> iter 62000, loss: 0.040170
 >> iter 63000, loss: 0.031061
 >> iter 64000, loss: 0.025351
 >> iter 65000, loss: 0.021531
 >> iter 66000, loss: 0.021482
 >> iter 67000, loss: 0.021102
 >> iter 68000, loss: 0.025558
 >> iter 69000, loss: 0.028225
 >> iter 70000, loss: 0.028091
   Number of active neurons: 2
 >> iter 71000, loss: 0.029141
 >> iter 72000, loss: 0.024167
 >> iter 73000, loss: 0.023446
 >> iter 74000, loss: 0.053876
 >> iter 75000, loss: 0.033951
 >> iter 76000, loss: 0.033386
 >> iter 77000, loss: 0.036704
 >> iter 78000, loss: 0.027301
 >> iter 79000, loss: 0.023157
 >> iter 80000, loss: 0.022421
   Number of active neurons: 2
 >> iter 81000, loss: 0.023309
 >> iter 82000, loss: 0.021779
 >> iter 83000, loss: 0.023999
 >> iter 84000, loss: 0.019886
 >> iter 85000, loss: 0.023626
 >> iter 86000, loss: 0.021365
 >> iter 87000, loss: 0.036469
 >> iter 88000, loss: 0.025651
 >> iter 89000, loss: 0.029997
 >> iter 90000, loss: 0.022728
   Number of active neurons: 1
 >> iter 91000, loss: 0.019532
 >> iter 92000, loss: 0.020556
 >> iter 93000, loss: 0.018313
 >> iter 94000, loss: 0.017036
 >> iter 95000, loss: 0.018062
 >> iter 96000, loss: 0.016445
 >> iter 97000, loss: 0.020176
 >> iter 98000, loss: 0.018068
 >> iter 99000, loss: 0.018341
 >> iter 100000, loss: 0.016197
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.934692
 >> iter 2000, loss: 4.070343
 >> iter 3000, loss: 1.522646
 >> iter 4000, loss: 0.596070
 >> iter 5000, loss: 0.238324
 >> iter 6000, loss: 0.108499
 >> iter 7000, loss: 0.067887
 >> iter 8000, loss: 0.044837
 >> iter 9000, loss: 0.035175
 >> iter 10000, loss: 0.032452
   Number of active neurons: 6
 >> iter 11000, loss: 0.036090
 >> iter 12000, loss: 0.032272
 >> iter 13000, loss: 0.032731
 >> iter 14000, loss: 0.059581
 >> iter 15000, loss: 0.043955
 >> iter 16000, loss: 0.038512
 >> iter 17000, loss: 0.030042
 >> iter 18000, loss: 0.027944
 >> iter 19000, loss: 0.031580
 >> iter 20000, loss: 0.034586
   Number of active neurons: 3
 >> iter 21000, loss: 0.038024
 >> iter 22000, loss: 0.032442
 >> iter 23000, loss: 0.027512
 >> iter 24000, loss: 0.033908
 >> iter 25000, loss: 0.028236
 >> iter 26000, loss: 0.024172
 >> iter 27000, loss: 0.046414
 >> iter 28000, loss: 0.033067
 >> iter 29000, loss: 0.034031
 >> iter 30000, loss: 0.029601
   Number of active neurons: 3
 >> iter 31000, loss: 0.027095
 >> iter 32000, loss: 0.024929
 >> iter 33000, loss: 0.024770
 >> iter 34000, loss: 0.022844
 >> iter 35000, loss: 0.024793
 >> iter 36000, loss: 0.024121
 >> iter 37000, loss: 0.021932
 >> iter 38000, loss: 0.022309
 >> iter 39000, loss: 0.037460
 >> iter 40000, loss: 0.041126
   Number of active neurons: 2
 >> iter 41000, loss: 0.030744
 >> iter 42000, loss: 0.032544
 >> iter 43000, loss: 0.024612
 >> iter 44000, loss: 0.027226
 >> iter 45000, loss: 0.024692
 >> iter 46000, loss: 0.027652
 >> iter 47000, loss: 0.022554
 >> iter 48000, loss: 0.021436
 >> iter 49000, loss: 0.023663
 >> iter 50000, loss: 0.024976
   Number of active neurons: 1
 >> iter 51000, loss: 0.019899
 >> iter 52000, loss: 0.017700
 >> iter 53000, loss: 0.017374
 >> iter 54000, loss: 0.018249
 >> iter 55000, loss: 0.017857
 >> iter 56000, loss: 0.018781
 >> iter 57000, loss: 0.019541
 >> iter 58000, loss: 0.020893
 >> iter 59000, loss: 0.021972
 >> iter 60000, loss: 0.018367
   Number of active neurons: 1
 >> iter 61000, loss: 0.023265
 >> iter 62000, loss: 0.025519
 >> iter 63000, loss: 0.026114
 >> iter 64000, loss: 0.023791
 >> iter 65000, loss: 0.022850
 >> iter 66000, loss: 0.018684
 >> iter 67000, loss: 0.018174
 >> iter 68000, loss: 0.018995
 >> iter 69000, loss: 0.016324
 >> iter 70000, loss: 0.016645
   Number of active neurons: 1
 >> iter 71000, loss: 0.021490
 >> iter 72000, loss: 0.026989
 >> iter 73000, loss: 0.019751
 >> iter 74000, loss: 0.029516
 >> iter 75000, loss: 0.022062
 >> iter 76000, loss: 0.018668
 >> iter 77000, loss: 0.018683
 >> iter 78000, loss: 0.017611
 >> iter 79000, loss: 0.054114
 >> iter 80000, loss: 0.036414
   Number of active neurons: 1
 >> iter 81000, loss: 0.028346
 >> iter 82000, loss: 0.021121
 >> iter 83000, loss: 0.019687
 >> iter 84000, loss: 0.023281
 >> iter 85000, loss: 0.021042
 >> iter 86000, loss: 0.019287
 >> iter 87000, loss: 0.017192
 >> iter 88000, loss: 0.016360
 >> iter 89000, loss: 0.018360
 >> iter 90000, loss: 0.017029
   Number of active neurons: 1
 >> iter 91000, loss: 0.017265
 >> iter 92000, loss: 0.020941
 >> iter 93000, loss: 0.017689
 >> iter 94000, loss: 0.036395
 >> iter 95000, loss: 0.025866
 >> iter 96000, loss: 0.021280
 >> iter 97000, loss: 0.020675
 >> iter 98000, loss: 0.042131
 >> iter 99000, loss: 0.039867
 >> iter 100000, loss: 0.030444
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.951420
 >> iter 2000, loss: 4.065441
 >> iter 3000, loss: 1.520417
 >> iter 4000, loss: 0.580275
 >> iter 5000, loss: 0.239197
 >> iter 6000, loss: 0.111897
 >> iter 7000, loss: 0.059943
 >> iter 8000, loss: 0.052006
 >> iter 9000, loss: 0.037373
 >> iter 10000, loss: 0.036588
   Number of active neurons: 4
 >> iter 11000, loss: 0.034769
 >> iter 12000, loss: 0.036015
 >> iter 13000, loss: 0.030887
 >> iter 14000, loss: 0.037136
 >> iter 15000, loss: 0.041576
 >> iter 16000, loss: 0.031689
 >> iter 17000, loss: 0.032540
 >> iter 18000, loss: 0.027069
 >> iter 19000, loss: 0.025024
 >> iter 20000, loss: 0.025433
   Number of active neurons: 2
 >> iter 21000, loss: 0.026076
 >> iter 22000, loss: 0.024076
 >> iter 23000, loss: 0.021966
 >> iter 24000, loss: 0.023547
 >> iter 25000, loss: 0.022936
 >> iter 26000, loss: 0.025945
 >> iter 27000, loss: 0.030250
 >> iter 28000, loss: 0.024612
 >> iter 29000, loss: 0.023073
 >> iter 30000, loss: 0.021212
   Number of active neurons: 2
 >> iter 31000, loss: 0.020248
 >> iter 32000, loss: 0.022168
 >> iter 33000, loss: 0.038235
 >> iter 34000, loss: 0.027401
 >> iter 35000, loss: 0.023236
 >> iter 36000, loss: 0.020057
 >> iter 37000, loss: 0.024319
 >> iter 38000, loss: 0.035084
 >> iter 39000, loss: 0.024829
 >> iter 40000, loss: 0.019719
   Number of active neurons: 1
 >> iter 41000, loss: 0.022732
 >> iter 42000, loss: 0.033919
 >> iter 43000, loss: 0.024919
 >> iter 44000, loss: 0.021553
 >> iter 45000, loss: 0.019430
 >> iter 46000, loss: 0.018963
 >> iter 47000, loss: 0.022821
 >> iter 48000, loss: 0.024384
 >> iter 49000, loss: 0.019545
 >> iter 50000, loss: 0.020511
   Number of active neurons: 1
 >> iter 51000, loss: 0.020872
 >> iter 52000, loss: 0.017644
 >> iter 53000, loss: 0.017156
 >> iter 54000, loss: 0.022433
 >> iter 55000, loss: 0.018122
 >> iter 56000, loss: 0.016929
 >> iter 57000, loss: 0.021217
 >> iter 58000, loss: 0.019435
 >> iter 59000, loss: 0.019572
 >> iter 60000, loss: 0.020514
   Number of active neurons: 1
 >> iter 61000, loss: 0.020747
 >> iter 62000, loss: 0.019838
 >> iter 63000, loss: 0.017570
 >> iter 64000, loss: 0.018744
 >> iter 65000, loss: 0.033629
 >> iter 66000, loss: 0.022106
 >> iter 67000, loss: 0.027060
 >> iter 68000, loss: 0.031656
 >> iter 69000, loss: 0.021149
 >> iter 70000, loss: 0.021778
   Number of active neurons: 1
 >> iter 71000, loss: 0.019770
 >> iter 72000, loss: 0.026703
 >> iter 73000, loss: 0.031469
 >> iter 74000, loss: 0.021111
 >> iter 75000, loss: 0.031989
 >> iter 76000, loss: 0.025330
 >> iter 77000, loss: 0.037566
 >> iter 78000, loss: 0.027159
 >> iter 79000, loss: 0.022971
 >> iter 80000, loss: 0.022388
   Number of active neurons: 1
 >> iter 81000, loss: 0.020347
 >> iter 82000, loss: 0.022728
 >> iter 83000, loss: 0.018330
 >> iter 84000, loss: 0.020124
 >> iter 85000, loss: 0.019322
 >> iter 86000, loss: 0.016611
 >> iter 87000, loss: 0.016540
 >> iter 88000, loss: 0.024253
 >> iter 89000, loss: 0.025880
 >> iter 90000, loss: 0.021564
   Number of active neurons: 1
 >> iter 91000, loss: 0.039032
 >> iter 92000, loss: 0.027266
 >> iter 93000, loss: 0.020636
 >> iter 94000, loss: 0.018380
 >> iter 95000, loss: 0.024654
 >> iter 96000, loss: 0.031406
 >> iter 97000, loss: 0.021724
 >> iter 98000, loss: 0.018114
 >> iter 99000, loss: 0.019458
 >> iter 100000, loss: 0.026828
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.960508
 >> iter 2000, loss: 4.108344
 >> iter 3000, loss: 1.537183
 >> iter 4000, loss: 0.595483
 >> iter 5000, loss: 0.239163
 >> iter 6000, loss: 0.112957
 >> iter 7000, loss: 0.061229
 >> iter 8000, loss: 0.040326
 >> iter 9000, loss: 0.038624
 >> iter 10000, loss: 0.033311
   Number of active neurons: 4
 >> iter 11000, loss: 0.037849
 >> iter 12000, loss: 0.031051
 >> iter 13000, loss: 0.027836
 >> iter 14000, loss: 0.031574
 >> iter 15000, loss: 0.036885
 >> iter 16000, loss: 0.035239
 >> iter 17000, loss: 0.030439
 >> iter 18000, loss: 0.030327
 >> iter 19000, loss: 0.028728
 >> iter 20000, loss: 0.024860
   Number of active neurons: 4
 >> iter 21000, loss: 0.026860
 >> iter 22000, loss: 0.032368
 >> iter 23000, loss: 0.055941
 >> iter 24000, loss: 0.047403
 >> iter 25000, loss: 0.034332
 >> iter 26000, loss: 0.027967
 >> iter 27000, loss: 0.024937
 >> iter 28000, loss: 0.023309
 >> iter 29000, loss: 0.022587
 >> iter 30000, loss: 0.028665
   Number of active neurons: 2
 >> iter 31000, loss: 0.033340
 >> iter 32000, loss: 0.025852
 >> iter 33000, loss: 0.024205
 >> iter 34000, loss: 0.021007
 >> iter 35000, loss: 0.026428
 >> iter 36000, loss: 0.021682
 >> iter 37000, loss: 0.021837
 >> iter 38000, loss: 0.021765
 >> iter 39000, loss: 0.020754
 >> iter 40000, loss: 0.021717
   Number of active neurons: 2
 >> iter 41000, loss: 0.020168
 >> iter 42000, loss: 0.020834
 >> iter 43000, loss: 0.020387
 >> iter 44000, loss: 0.019666
 >> iter 45000, loss: 0.024640
 >> iter 46000, loss: 0.022829
 >> iter 47000, loss: 0.025234
 >> iter 48000, loss: 0.024585
 >> iter 49000, loss: 0.023071
 >> iter 50000, loss: 0.030160
   Number of active neurons: 2
 >> iter 51000, loss: 0.049596
 >> iter 52000, loss: 0.031312
 >> iter 53000, loss: 0.032079
 >> iter 54000, loss: 0.032918
 >> iter 55000, loss: 0.033774
 >> iter 56000, loss: 0.028225
 >> iter 57000, loss: 0.025868
 >> iter 58000, loss: 0.024067
 >> iter 59000, loss: 0.022582
 >> iter 60000, loss: 0.020800
   Number of active neurons: 2
 >> iter 61000, loss: 0.021373
 >> iter 62000, loss: 0.026353
 >> iter 63000, loss: 0.028214
 >> iter 64000, loss: 0.025040
 >> iter 65000, loss: 0.021395
 >> iter 66000, loss: 0.035216
 >> iter 67000, loss: 0.037069
 >> iter 68000, loss: 0.026103
 >> iter 69000, loss: 0.026199
 >> iter 70000, loss: 0.023428
   Number of active neurons: 2
 >> iter 71000, loss: 0.022691
 >> iter 72000, loss: 0.028665
 >> iter 73000, loss: 0.023569
 >> iter 74000, loss: 0.023028
 >> iter 75000, loss: 0.023231
 >> iter 76000, loss: 0.024403
 >> iter 77000, loss: 0.025797
 >> iter 78000, loss: 0.022142
 >> iter 79000, loss: 0.022004
 >> iter 80000, loss: 0.020924
   Number of active neurons: 2
 >> iter 81000, loss: 0.030312
 >> iter 82000, loss: 0.022567
 >> iter 83000, loss: 0.027314
 >> iter 84000, loss: 0.033949
 >> iter 85000, loss: 0.027055
 >> iter 86000, loss: 0.023348
 >> iter 87000, loss: 0.022709
 >> iter 88000, loss: 0.021439
 >> iter 89000, loss: 0.020460
 >> iter 90000, loss: 0.020937
   Number of active neurons: 2
 >> iter 91000, loss: 0.020099
 >> iter 92000, loss: 0.030111
 >> iter 93000, loss: 0.024042
 >> iter 94000, loss: 0.026323
 >> iter 95000, loss: 0.023273
 >> iter 96000, loss: 0.034224
 >> iter 97000, loss: 0.035180
 >> iter 98000, loss: 0.027208
 >> iter 99000, loss: 0.037278
 >> iter 100000, loss: 0.028120
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.934541
 >> iter 2000, loss: 4.063618
 >> iter 3000, loss: 1.537470
 >> iter 4000, loss: 0.588062
 >> iter 5000, loss: 0.240478
 >> iter 6000, loss: 0.116168
 >> iter 7000, loss: 0.061487
 >> iter 8000, loss: 0.044722
 >> iter 9000, loss: 0.058604
 >> iter 10000, loss: 0.044978
   Number of active neurons: 4
 >> iter 11000, loss: 0.073172
 >> iter 12000, loss: 0.045028
 >> iter 13000, loss: 0.035472
 >> iter 14000, loss: 0.031763
 >> iter 15000, loss: 0.030872
 >> iter 16000, loss: 0.028220
 >> iter 17000, loss: 0.048490
 >> iter 18000, loss: 0.035239
 >> iter 19000, loss: 0.037912
 >> iter 20000, loss: 0.030340
   Number of active neurons: 2
 >> iter 21000, loss: 0.043440
 >> iter 22000, loss: 0.037899
 >> iter 23000, loss: 0.028883
 >> iter 24000, loss: 0.040070
 >> iter 25000, loss: 0.031728
 >> iter 26000, loss: 0.036793
 >> iter 27000, loss: 0.025722
 >> iter 28000, loss: 0.042675
 >> iter 29000, loss: 0.031135
 >> iter 30000, loss: 0.030882
   Number of active neurons: 2
 >> iter 31000, loss: 0.029490
 >> iter 32000, loss: 0.032027
 >> iter 33000, loss: 0.043534
 >> iter 34000, loss: 0.029175
 >> iter 35000, loss: 0.027057
 >> iter 36000, loss: 0.027628
 >> iter 37000, loss: 0.025419
 >> iter 38000, loss: 0.024254
 >> iter 39000, loss: 0.021231
 >> iter 40000, loss: 0.021318
   Number of active neurons: 2
 >> iter 41000, loss: 0.028069
 >> iter 42000, loss: 0.023852
 >> iter 43000, loss: 0.029635
 >> iter 44000, loss: 0.031048
 >> iter 45000, loss: 0.027786
 >> iter 46000, loss: 0.023071
 >> iter 47000, loss: 0.020679
 >> iter 48000, loss: 0.019731
 >> iter 49000, loss: 0.018298
 >> iter 50000, loss: 0.028443
   Number of active neurons: 1
 >> iter 51000, loss: 0.021274
 >> iter 52000, loss: 0.018768
 >> iter 53000, loss: 0.018644
 >> iter 54000, loss: 0.016533
 >> iter 55000, loss: 0.018360
 >> iter 56000, loss: 0.021901
 >> iter 57000, loss: 0.021893
 >> iter 58000, loss: 0.028650
 >> iter 59000, loss: 0.023555
 >> iter 60000, loss: 0.018049
   Number of active neurons: 1
 >> iter 61000, loss: 0.017032
 >> iter 62000, loss: 0.016609
 >> iter 63000, loss: 0.020031
 >> iter 64000, loss: 0.016883
 >> iter 65000, loss: 0.019774
 >> iter 66000, loss: 0.017596
 >> iter 67000, loss: 0.022108
 >> iter 68000, loss: 0.020160
 >> iter 69000, loss: 0.019736
 >> iter 70000, loss: 0.022275
   Number of active neurons: 1
 >> iter 71000, loss: 0.017973
 >> iter 72000, loss: 0.016690
 >> iter 73000, loss: 0.015736
 >> iter 74000, loss: 0.017192
 >> iter 75000, loss: 0.016430
 >> iter 76000, loss: 0.017762
 >> iter 77000, loss: 0.017757
 >> iter 78000, loss: 0.020519
 >> iter 79000, loss: 0.043545
 >> iter 80000, loss: 0.027450
   Number of active neurons: 1
 >> iter 81000, loss: 0.022047
 >> iter 82000, loss: 0.020851
 >> iter 83000, loss: 0.028948
 >> iter 84000, loss: 0.020795
 >> iter 85000, loss: 0.050296
 >> iter 86000, loss: 0.031328
 >> iter 87000, loss: 0.023077
 >> iter 88000, loss: 0.027927
 >> iter 89000, loss: 0.021188
 >> iter 90000, loss: 0.018178
   Number of active neurons: 1
 >> iter 91000, loss: 0.018494
 >> iter 92000, loss: 0.017124
 >> iter 93000, loss: 0.016239
 >> iter 94000, loss: 0.028007
 >> iter 95000, loss: 0.024426
 >> iter 96000, loss: 0.021819
 >> iter 97000, loss: 0.025365
 >> iter 98000, loss: 0.025142
 >> iter 99000, loss: 0.027222
 >> iter 100000, loss: 0.022438
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.990803
 >> iter 2000, loss: 4.142275
 >> iter 3000, loss: 1.569726
 >> iter 4000, loss: 0.599760
 >> iter 5000, loss: 0.244875
 >> iter 6000, loss: 0.117979
 >> iter 7000, loss: 0.067666
 >> iter 8000, loss: 0.045980
 >> iter 9000, loss: 0.035621
 >> iter 10000, loss: 0.034811
   Number of active neurons: 5
 >> iter 11000, loss: 0.036004
 >> iter 12000, loss: 0.034500
 >> iter 13000, loss: 0.044661
 >> iter 14000, loss: 0.039050
 >> iter 15000, loss: 0.036109
 >> iter 16000, loss: 0.028482
 >> iter 17000, loss: 0.028934
 >> iter 18000, loss: 0.026434
 >> iter 19000, loss: 0.031358
 >> iter 20000, loss: 0.030941
   Number of active neurons: 4
 >> iter 21000, loss: 0.027760
 >> iter 22000, loss: 0.025693
 >> iter 23000, loss: 0.027091
 >> iter 24000, loss: 0.037946
 >> iter 25000, loss: 0.034873
 >> iter 26000, loss: 0.038124
 >> iter 27000, loss: 0.028774
 >> iter 28000, loss: 0.025275
 >> iter 29000, loss: 0.023968
 >> iter 30000, loss: 0.057509
   Number of active neurons: 2
 >> iter 31000, loss: 0.046715
 >> iter 32000, loss: 0.035602
 >> iter 33000, loss: 0.030747
 >> iter 34000, loss: 0.025415
 >> iter 35000, loss: 0.025218
 >> iter 36000, loss: 0.024958
 >> iter 37000, loss: 0.022453
 >> iter 38000, loss: 0.030496
 >> iter 39000, loss: 0.027870
 >> iter 40000, loss: 0.023463
   Number of active neurons: 2
 >> iter 41000, loss: 0.022592
 >> iter 42000, loss: 0.021177
 >> iter 43000, loss: 0.031244
 >> iter 44000, loss: 0.041410
 >> iter 45000, loss: 0.029216
 >> iter 46000, loss: 0.028766
 >> iter 47000, loss: 0.038065
 >> iter 48000, loss: 0.038675
 >> iter 49000, loss: 0.040608
 >> iter 50000, loss: 0.033722
   Number of active neurons: 2
 >> iter 51000, loss: 0.026484
 >> iter 52000, loss: 0.028400
 >> iter 53000, loss: 0.030484
 >> iter 54000, loss: 0.024606
 >> iter 55000, loss: 0.023726
 >> iter 56000, loss: 0.020454
 >> iter 57000, loss: 0.021630
 >> iter 58000, loss: 0.024994
 >> iter 59000, loss: 0.024370
 >> iter 60000, loss: 0.021187
   Number of active neurons: 2
 >> iter 61000, loss: 0.024699
 >> iter 62000, loss: 0.024585
 >> iter 63000, loss: 0.020828
 >> iter 64000, loss: 0.019240
 >> iter 65000, loss: 0.022140
 >> iter 66000, loss: 0.023852
 >> iter 67000, loss: 0.020456
 >> iter 68000, loss: 0.019264
 >> iter 69000, loss: 0.024186
 >> iter 70000, loss: 0.026430
   Number of active neurons: 1
 >> iter 71000, loss: 0.023365
 >> iter 72000, loss: 0.020234
 >> iter 73000, loss: 0.020250
 >> iter 74000, loss: 0.019448
 >> iter 75000, loss: 0.030753
 >> iter 76000, loss: 0.026009
 >> iter 77000, loss: 0.022836
 >> iter 78000, loss: 0.020042
 >> iter 79000, loss: 0.040156
 >> iter 80000, loss: 0.025358
   Number of active neurons: 1
 >> iter 81000, loss: 0.020088
 >> iter 82000, loss: 0.022167
 >> iter 83000, loss: 0.018917
 >> iter 84000, loss: 0.021889
 >> iter 85000, loss: 0.020578
 >> iter 86000, loss: 0.019350
 >> iter 87000, loss: 0.019929
 >> iter 88000, loss: 0.019987
 >> iter 89000, loss: 0.016644
 >> iter 90000, loss: 0.016240
   Number of active neurons: 1
 >> iter 91000, loss: 0.023465
 >> iter 92000, loss: 0.022385
 >> iter 93000, loss: 0.022831
 >> iter 94000, loss: 0.019837
 >> iter 95000, loss: 0.021972
 >> iter 96000, loss: 0.022023
 >> iter 97000, loss: 0.028392
 >> iter 98000, loss: 0.024367
 >> iter 99000, loss: 0.021644
 >> iter 100000, loss: 0.029567
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.942015
 >> iter 2000, loss: 4.069499
 >> iter 3000, loss: 1.532611
 >> iter 4000, loss: 0.585594
 >> iter 5000, loss: 0.262886
 >> iter 6000, loss: 0.122173
 >> iter 7000, loss: 0.064103
 >> iter 8000, loss: 0.052995
 >> iter 9000, loss: 0.074564
 >> iter 10000, loss: 0.054797
   Number of active neurons: 5
 >> iter 11000, loss: 0.043405
 >> iter 12000, loss: 0.035459
 >> iter 13000, loss: 0.030372
 >> iter 14000, loss: 0.033002
 >> iter 15000, loss: 0.031426
 >> iter 16000, loss: 0.034652
 >> iter 17000, loss: 0.028166
 >> iter 18000, loss: 0.037255
 >> iter 19000, loss: 0.029427
 >> iter 20000, loss: 0.025973
   Number of active neurons: 2
 >> iter 21000, loss: 0.029512
 >> iter 22000, loss: 0.025758
 >> iter 23000, loss: 0.026730
 >> iter 24000, loss: 0.022650
 >> iter 25000, loss: 0.026603
 >> iter 26000, loss: 0.046200
 >> iter 27000, loss: 0.029366
 >> iter 28000, loss: 0.028395
 >> iter 29000, loss: 0.024169
 >> iter 30000, loss: 0.024526
   Number of active neurons: 2
 >> iter 31000, loss: 0.021288
 >> iter 32000, loss: 0.021455
 >> iter 33000, loss: 0.022783
 >> iter 34000, loss: 0.020541
 >> iter 35000, loss: 0.025774
 >> iter 36000, loss: 0.032309
 >> iter 37000, loss: 0.033055
 >> iter 38000, loss: 0.026539
 >> iter 39000, loss: 0.039962
 >> iter 40000, loss: 0.028226
   Number of active neurons: 2
 >> iter 41000, loss: 0.030336
 >> iter 42000, loss: 0.035528
 >> iter 43000, loss: 0.025854
 >> iter 44000, loss: 0.025154
 >> iter 45000, loss: 0.037197
 >> iter 46000, loss: 0.031396
 >> iter 47000, loss: 0.023799
 >> iter 48000, loss: 0.057384
 >> iter 49000, loss: 0.036024
 >> iter 50000, loss: 0.036657
   Number of active neurons: 2
 >> iter 51000, loss: 0.032430
 >> iter 52000, loss: 0.039694
 >> iter 53000, loss: 0.028033
 >> iter 54000, loss: 0.023556
 >> iter 55000, loss: 0.027852
 >> iter 56000, loss: 0.026975
 >> iter 57000, loss: 0.025150
 >> iter 58000, loss: 0.021871
 >> iter 59000, loss: 0.025294
 >> iter 60000, loss: 0.063903
   Number of active neurons: 1
 >> iter 61000, loss: 0.044961
 >> iter 62000, loss: 0.028964
 >> iter 63000, loss: 0.024104
 >> iter 64000, loss: 0.023490
 >> iter 65000, loss: 0.024618
 >> iter 66000, loss: 0.030118
 >> iter 67000, loss: 0.024354
 >> iter 68000, loss: 0.026256
 >> iter 69000, loss: 0.019481
 >> iter 70000, loss: 0.019075
   Number of active neurons: 1
 >> iter 71000, loss: 0.020886
 >> iter 72000, loss: 0.017796
 >> iter 73000, loss: 0.020880
 >> iter 74000, loss: 0.017586
 >> iter 75000, loss: 0.018071
 >> iter 76000, loss: 0.016812
 >> iter 77000, loss: 0.016680
 >> iter 78000, loss: 0.022256
 >> iter 79000, loss: 0.022477
 >> iter 80000, loss: 0.019095
   Number of active neurons: 1
 >> iter 81000, loss: 0.019682
 >> iter 82000, loss: 0.018572
 >> iter 83000, loss: 0.019353
 >> iter 84000, loss: 0.019527
 >> iter 85000, loss: 0.035493
 >> iter 86000, loss: 0.026125
 >> iter 87000, loss: 0.022099
 >> iter 88000, loss: 0.019891
 >> iter 89000, loss: 0.020958
 >> iter 90000, loss: 0.017083
   Number of active neurons: 1
 >> iter 91000, loss: 0.015719
 >> iter 92000, loss: 0.017555
 >> iter 93000, loss: 0.018494
 >> iter 94000, loss: 0.034670
 >> iter 95000, loss: 0.023189
 >> iter 96000, loss: 0.019719
 >> iter 97000, loss: 0.031372
 >> iter 98000, loss: 0.025234
 >> iter 99000, loss: 0.020338
 >> iter 100000, loss: 0.020673
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.993880
 >> iter 2000, loss: 4.083748
 >> iter 3000, loss: 1.536856
 >> iter 4000, loss: 0.585910
 >> iter 5000, loss: 0.241238
 >> iter 6000, loss: 0.105003
 >> iter 7000, loss: 0.064651
 >> iter 8000, loss: 0.044138
 >> iter 9000, loss: 0.037179
 >> iter 10000, loss: 0.042146
   Number of active neurons: 3
 >> iter 11000, loss: 0.033954
 >> iter 12000, loss: 0.039540
 >> iter 13000, loss: 0.032311
 >> iter 14000, loss: 0.027517
 >> iter 15000, loss: 0.025695
 >> iter 16000, loss: 0.024620
 >> iter 17000, loss: 0.023872
 >> iter 18000, loss: 0.025976
 >> iter 19000, loss: 0.026741
 >> iter 20000, loss: 0.025504
   Number of active neurons: 2
 >> iter 21000, loss: 0.034387
 >> iter 22000, loss: 0.028827
 >> iter 23000, loss: 0.023505
 >> iter 24000, loss: 0.023317
 >> iter 25000, loss: 0.032521
 >> iter 26000, loss: 0.024220
 >> iter 27000, loss: 0.021593
 >> iter 28000, loss: 0.022174
 >> iter 29000, loss: 0.024598
 >> iter 30000, loss: 0.021654
   Number of active neurons: 2
 >> iter 31000, loss: 0.020478
 >> iter 32000, loss: 0.020366
 >> iter 33000, loss: 0.022608
 >> iter 34000, loss: 0.030766
 >> iter 35000, loss: 0.023762
 >> iter 36000, loss: 0.023913
 >> iter 37000, loss: 0.024912
 >> iter 38000, loss: 0.022264
 >> iter 39000, loss: 0.028392
 >> iter 40000, loss: 0.023764
   Number of active neurons: 2
 >> iter 41000, loss: 0.031644
 >> iter 42000, loss: 0.048987
 >> iter 43000, loss: 0.032446
 >> iter 44000, loss: 0.026503
 >> iter 45000, loss: 0.023042
 >> iter 46000, loss: 0.026002
 >> iter 47000, loss: 0.021450
 >> iter 48000, loss: 0.020431
 >> iter 49000, loss: 0.021988
 >> iter 50000, loss: 0.020257
   Number of active neurons: 2
 >> iter 51000, loss: 0.021571
 >> iter 52000, loss: 0.024639
 >> iter 53000, loss: 0.027563
 >> iter 54000, loss: 0.022430
 >> iter 55000, loss: 0.024818
 >> iter 56000, loss: 0.021984
 >> iter 57000, loss: 0.024340
 >> iter 58000, loss: 0.021578
 >> iter 59000, loss: 0.019942
 >> iter 60000, loss: 0.025445
   Number of active neurons: 2
 >> iter 61000, loss: 0.039572
 >> iter 62000, loss: 0.040042
 >> iter 63000, loss: 0.033012
 >> iter 64000, loss: 0.024715
 >> iter 65000, loss: 0.023349
 >> iter 66000, loss: 0.028910
 >> iter 67000, loss: 0.023254
 >> iter 68000, loss: 0.020509
 >> iter 69000, loss: 0.020783
 >> iter 70000, loss: 0.021425
   Number of active neurons: 2
 >> iter 71000, loss: 0.020029
 >> iter 72000, loss: 0.020262
 >> iter 73000, loss: 0.019747
 >> iter 74000, loss: 0.035055
 >> iter 75000, loss: 0.029039
 >> iter 76000, loss: 0.031066
 >> iter 77000, loss: 0.025035
 >> iter 78000, loss: 0.021839
 >> iter 79000, loss: 0.021106
 >> iter 80000, loss: 0.020230
   Number of active neurons: 2
 >> iter 81000, loss: 0.024818
 >> iter 82000, loss: 0.024062
 >> iter 83000, loss: 0.020819
 >> iter 84000, loss: 0.024842
 >> iter 85000, loss: 0.022947
 >> iter 86000, loss: 0.029046
 >> iter 87000, loss: 0.045399
 >> iter 88000, loss: 0.030109
 >> iter 89000, loss: 0.023443
 >> iter 90000, loss: 0.029595
   Number of active neurons: 2
 >> iter 91000, loss: 0.026383
 >> iter 92000, loss: 0.022348
 >> iter 93000, loss: 0.030875
 >> iter 94000, loss: 0.026945
 >> iter 95000, loss: 0.023491
 >> iter 96000, loss: 0.024506
 >> iter 97000, loss: 0.020121
 >> iter 98000, loss: 0.023038
 >> iter 99000, loss: 0.048848
 >> iter 100000, loss: 0.032075
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

