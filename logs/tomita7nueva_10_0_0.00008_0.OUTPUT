 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 8e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.833616
 >> iter 2000, loss: 10.775865
 >> iter 3000, loss: 4.299780
 >> iter 4000, loss: 1.609680
 >> iter 5000, loss: 0.647401
 >> iter 6000, loss: 0.257266
 >> iter 7000, loss: 0.155135
 >> iter 8000, loss: 0.073906
 >> iter 9000, loss: 0.074868
 >> iter 10000, loss: 0.044001
   Number of active neurons: 5
 >> iter 11000, loss: 0.045215
 >> iter 12000, loss: 0.031846
 >> iter 13000, loss: 0.033177
 >> iter 14000, loss: 0.026448
 >> iter 15000, loss: 0.068965
 >> iter 16000, loss: 0.040218
 >> iter 17000, loss: 0.080589
 >> iter 18000, loss: 0.045769
 >> iter 19000, loss: 0.104397
 >> iter 20000, loss: 0.055593
   Number of active neurons: 5
 >> iter 21000, loss: 0.098912
 >> iter 22000, loss: 0.096871
 >> iter 23000, loss: 0.124753
 >> iter 24000, loss: 0.065369
 >> iter 25000, loss: 0.110372
 >> iter 26000, loss: 0.095408
 >> iter 27000, loss: 0.212285
 >> iter 28000, loss: 0.160171
 >> iter 29000, loss: 0.214316
 >> iter 30000, loss: 0.331582
   Number of active neurons: 4
 >> iter 31000, loss: 0.181794
 >> iter 32000, loss: 0.083624
 >> iter 33000, loss: 0.182115
 >> iter 34000, loss: 0.088466
 >> iter 35000, loss: 0.058151
 >> iter 36000, loss: 0.034721
 >> iter 37000, loss: 0.140583
 >> iter 38000, loss: 0.080017
 >> iter 39000, loss: 0.071059
 >> iter 40000, loss: 0.112341
   Number of active neurons: 4
 >> iter 41000, loss: 0.107443
 >> iter 42000, loss: 0.091139
 >> iter 43000, loss: 0.114882
 >> iter 44000, loss: 0.054967
 >> iter 45000, loss: 0.331615
 >> iter 46000, loss: 0.171682
 >> iter 47000, loss: 0.206138
 >> iter 48000, loss: 0.121546
 >> iter 49000, loss: 0.146509
 >> iter 50000, loss: 0.080962
   Number of active neurons: 4
 >> iter 51000, loss: 0.144023
 >> iter 52000, loss: 0.078494
 >> iter 53000, loss: 0.155724
 >> iter 54000, loss: 0.088983
 >> iter 55000, loss: 0.236165
 >> iter 56000, loss: 0.176518
 >> iter 57000, loss: 0.098615
 >> iter 58000, loss: 0.104455
 >> iter 59000, loss: 0.099014
 >> iter 60000, loss: 0.088980
   Number of active neurons: 4
 >> iter 61000, loss: 0.171360
 >> iter 62000, loss: 0.154130
 >> iter 63000, loss: 0.226537
 >> iter 64000, loss: 0.099026
 >> iter 65000, loss: 0.133804
 >> iter 66000, loss: 0.158142
 >> iter 67000, loss: 0.096078
 >> iter 68000, loss: 0.087589
 >> iter 69000, loss: 0.071277
 >> iter 70000, loss: 0.040741
   Number of active neurons: 4
 >> iter 71000, loss: 0.046816
 >> iter 72000, loss: 0.043091
 >> iter 73000, loss: 0.171919
 >> iter 74000, loss: 0.287245
 >> iter 75000, loss: 0.214398
 >> iter 76000, loss: 0.141194
 >> iter 77000, loss: 0.066344
 >> iter 78000, loss: 0.074955
 >> iter 79000, loss: 0.052668
 >> iter 80000, loss: 0.032161
   Number of active neurons: 4
 >> iter 81000, loss: 0.047906
 >> iter 82000, loss: 0.029402
 >> iter 83000, loss: 0.270568
 >> iter 84000, loss: 0.190757
 >> iter 85000, loss: 0.091860
 >> iter 86000, loss: 0.058866
 >> iter 87000, loss: 0.072176
 >> iter 88000, loss: 0.043604
 >> iter 89000, loss: 0.046423
 >> iter 90000, loss: 0.209670
   Number of active neurons: 4
 >> iter 91000, loss: 0.360096
 >> iter 92000, loss: 0.182528
 >> iter 93000, loss: 0.082603
 >> iter 94000, loss: 0.378628
 >> iter 95000, loss: 0.339604
 >> iter 96000, loss: 0.196148
 >> iter 97000, loss: 0.089370
 >> iter 98000, loss: 0.047591
 >> iter 99000, loss: 0.140015
 >> iter 100000, loss: 0.086757
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.00599988000241
   - Test - Long: 0.0349982500875
   - Test - Big: 0.00199998000021
   - Test - A: 40.4906339577
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.163098
 >> iter 2000, loss: 7.808576
 >> iter 3000, loss: 3.100759
 >> iter 4000, loss: 1.190047
 >> iter 5000, loss: 0.608740
 >> iter 6000, loss: 0.256094
 >> iter 7000, loss: 0.208190
 >> iter 8000, loss: 0.097321
 >> iter 9000, loss: 0.171193
 >> iter 10000, loss: 0.081771
   Number of active neurons: 8
 >> iter 11000, loss: 0.288640
 >> iter 12000, loss: 0.192070
 >> iter 13000, loss: 0.207090
 >> iter 14000, loss: 0.102646
 >> iter 15000, loss: 0.227047
 >> iter 16000, loss: 0.127663
 >> iter 17000, loss: 0.337318
 >> iter 18000, loss: 0.176086
 >> iter 19000, loss: 0.166617
 >> iter 20000, loss: 0.158721
   Number of active neurons: 8
 >> iter 21000, loss: 0.257625
 >> iter 22000, loss: 0.127341
 >> iter 23000, loss: 0.145447
 >> iter 24000, loss: 0.071357
 >> iter 25000, loss: 0.115974
 >> iter 26000, loss: 0.062101
 >> iter 27000, loss: 0.095576
 >> iter 28000, loss: 0.077990
 >> iter 29000, loss: 0.083957
 >> iter 30000, loss: 0.079760
   Number of active neurons: 6
 >> iter 31000, loss: 0.140475
 >> iter 32000, loss: 0.169475
 >> iter 33000, loss: 0.384477
 >> iter 34000, loss: 0.196867
 >> iter 35000, loss: 0.317071
 >> iter 36000, loss: 0.139200
 >> iter 37000, loss: 0.154591
 >> iter 38000, loss: 0.124054
 >> iter 39000, loss: 0.165700
 >> iter 40000, loss: 0.163667
   Number of active neurons: 5
 >> iter 41000, loss: 0.153431
 >> iter 42000, loss: 0.274986
 >> iter 43000, loss: 0.162447
 >> iter 44000, loss: 0.157357
 >> iter 45000, loss: 0.223088
 >> iter 46000, loss: 0.236127
 >> iter 47000, loss: 0.144545
 >> iter 48000, loss: 0.149029
 >> iter 49000, loss: 0.281736
 >> iter 50000, loss: 0.123487
   Number of active neurons: 5
 >> iter 51000, loss: 0.185718
 >> iter 52000, loss: 0.112684
 >> iter 53000, loss: 0.135875
 >> iter 54000, loss: 0.164945
 >> iter 55000, loss: 0.121259
 >> iter 56000, loss: 0.124632
 >> iter 57000, loss: 0.217145
 >> iter 58000, loss: 0.143092
 >> iter 59000, loss: 0.183349
 >> iter 60000, loss: 0.122943
   Number of active neurons: 5
 >> iter 61000, loss: 0.186835
 >> iter 62000, loss: 0.086280
 >> iter 63000, loss: 0.366199
 >> iter 64000, loss: 0.189884
 >> iter 65000, loss: 0.140705
 >> iter 66000, loss: 0.099565
 >> iter 67000, loss: 0.243719
 >> iter 68000, loss: 0.108937
 >> iter 69000, loss: 0.209266
 >> iter 70000, loss: 0.105720
   Number of active neurons: 5
 >> iter 71000, loss: 0.099476
 >> iter 72000, loss: 0.090015
 >> iter 73000, loss: 0.324637
 >> iter 74000, loss: 0.186854
 >> iter 75000, loss: 0.182142
 >> iter 76000, loss: 0.106692
 >> iter 77000, loss: 0.112037
 >> iter 78000, loss: 0.095485
 >> iter 79000, loss: 0.190208
 >> iter 80000, loss: 0.085446
   Number of active neurons: 5
 >> iter 81000, loss: 0.591996
 >> iter 82000, loss: 0.245194
 >> iter 83000, loss: 0.302014
 >> iter 84000, loss: 0.133727
 >> iter 85000, loss: 0.125377
 >> iter 86000, loss: 0.133237
 >> iter 87000, loss: 0.193316
 >> iter 88000, loss: 0.087863
 >> iter 89000, loss: 0.100995
 >> iter 90000, loss: 0.092919
   Number of active neurons: 4
 >> iter 91000, loss: 0.193269
 >> iter 92000, loss: 0.155420
 >> iter 93000, loss: 0.236449
 >> iter 94000, loss: 0.105430
 >> iter 95000, loss: 0.152009
 >> iter 96000, loss: 0.097622
 >> iter 97000, loss: 0.280369
 >> iter 98000, loss: 0.213673
 >> iter 99000, loss: 0.161790
 >> iter 100000, loss: 0.078429
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.029999400012
   - Test - Long: 0.0049997500125
   - Test - Big: 0.039999600004
   - Test - A: 45.5836277581
   - Test - B: 17.8521431905
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.824837
 >> iter 2000, loss: 8.050114
 >> iter 3000, loss: 3.030737
 >> iter 4000, loss: 1.192083
 >> iter 5000, loss: 0.572796
 >> iter 6000, loss: 0.343662
 >> iter 7000, loss: 0.228585
 >> iter 8000, loss: 0.198491
 >> iter 9000, loss: 0.129299
 >> iter 10000, loss: 0.111443
   Number of active neurons: 7
 >> iter 11000, loss: 0.237421
 >> iter 12000, loss: 0.152493
 >> iter 13000, loss: 0.155461
 >> iter 14000, loss: 0.117668
 >> iter 15000, loss: 0.270278
 >> iter 16000, loss: 0.126399
 >> iter 17000, loss: 0.305645
 >> iter 18000, loss: 0.144662
 >> iter 19000, loss: 0.173955
 >> iter 20000, loss: 0.159408
   Number of active neurons: 7
 >> iter 21000, loss: 0.289054
 >> iter 22000, loss: 0.132655
 >> iter 23000, loss: 0.238613
 >> iter 24000, loss: 0.113427
 >> iter 25000, loss: 0.267146
 >> iter 26000, loss: 0.119942
 >> iter 27000, loss: 0.255159
 >> iter 28000, loss: 0.298668
 >> iter 29000, loss: 0.190680
 >> iter 30000, loss: 0.239110
   Number of active neurons: 6
 >> iter 31000, loss: 0.289384
 >> iter 32000, loss: 0.201860
 >> iter 33000, loss: 0.309372
 >> iter 34000, loss: 0.137053
 >> iter 35000, loss: 0.164699
 >> iter 36000, loss: 0.143143
 >> iter 37000, loss: 0.224522
 >> iter 38000, loss: 0.101863
 >> iter 39000, loss: 0.480348
 >> iter 40000, loss: 0.203465
   Number of active neurons: 5
 >> iter 41000, loss: 0.282752
 >> iter 42000, loss: 0.136633
 >> iter 43000, loss: 0.382213
 >> iter 44000, loss: 0.180632
 >> iter 45000, loss: 0.201479
 >> iter 46000, loss: 0.104395
 >> iter 47000, loss: 0.206483
 >> iter 48000, loss: 0.096194
 >> iter 49000, loss: 0.198118
 >> iter 50000, loss: 0.091164
   Number of active neurons: 5
 >> iter 51000, loss: 0.339588
 >> iter 52000, loss: 0.160067
 >> iter 53000, loss: 0.307255
 >> iter 54000, loss: 0.135250
 >> iter 55000, loss: 0.238049
 >> iter 56000, loss: 0.368027
 >> iter 57000, loss: 0.323741
 >> iter 58000, loss: 0.142449
 >> iter 59000, loss: 0.211306
 >> iter 60000, loss: 0.096881
   Number of active neurons: 5
 >> iter 61000, loss: 0.139023
 >> iter 62000, loss: 0.069184
 >> iter 63000, loss: 0.167432
 >> iter 64000, loss: 0.079770
 >> iter 65000, loss: 0.132073
 >> iter 66000, loss: 0.064533
 >> iter 67000, loss: 0.339320
 >> iter 68000, loss: 0.148667
 >> iter 69000, loss: 0.181366
 >> iter 70000, loss: 0.097346
   Number of active neurons: 5
 >> iter 71000, loss: 0.113970
 >> iter 72000, loss: 0.058948
 >> iter 73000, loss: 0.232928
 >> iter 74000, loss: 0.135467
 >> iter 75000, loss: 0.111311
 >> iter 76000, loss: 0.057029
 >> iter 77000, loss: 0.594388
 >> iter 78000, loss: 0.244525
 >> iter 79000, loss: 0.214673
 >> iter 80000, loss: 0.098912
   Number of active neurons: 4
 >> iter 81000, loss: 0.234158
 >> iter 82000, loss: 0.241391
 >> iter 83000, loss: 0.109508
 >> iter 84000, loss: 0.145400
 >> iter 85000, loss: 0.119566
 >> iter 86000, loss: 0.059687
 >> iter 87000, loss: 0.136943
 >> iter 88000, loss: 0.068447
 >> iter 89000, loss: 0.158438
 >> iter 90000, loss: 0.073446
   Number of active neurons: 5
 >> iter 91000, loss: 0.272877
 >> iter 92000, loss: 0.118252
 >> iter 93000, loss: 0.101388
 >> iter 94000, loss: 0.053859
 >> iter 95000, loss: 0.088766
 >> iter 96000, loss: 0.068005
 >> iter 97000, loss: 0.181517
 >> iter 98000, loss: 0.171230
 >> iter 99000, loss: 0.195702
 >> iter 100000, loss: 0.125237
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0139997200056
   - Test - Long: 0.0
   - Test - Big: 0.0079999200008
   - Test - A: 57.8161455903
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.225258
 >> iter 2000, loss: 7.876846
 >> iter 3000, loss: 3.360099
 >> iter 4000, loss: 1.556994
 >> iter 5000, loss: 0.710344
 >> iter 6000, loss: 0.401435
 >> iter 7000, loss: 0.247493
 >> iter 8000, loss: 0.367672
 >> iter 9000, loss: 0.244448
 >> iter 10000, loss: 0.116213
   Number of active neurons: 7
 >> iter 11000, loss: 0.232971
 >> iter 12000, loss: 0.416849
 >> iter 13000, loss: 0.315134
 >> iter 14000, loss: 0.200501
 >> iter 15000, loss: 0.301398
 >> iter 16000, loss: 0.254483
 >> iter 17000, loss: 0.212547
 >> iter 18000, loss: 0.124169
 >> iter 19000, loss: 0.392085
 >> iter 20000, loss: 0.211553
   Number of active neurons: 7
 >> iter 21000, loss: 0.306347
 >> iter 22000, loss: 0.211516
 >> iter 23000, loss: 0.428571
 >> iter 24000, loss: 0.239790
 >> iter 25000, loss: 0.201285
 >> iter 26000, loss: 0.193719
 >> iter 27000, loss: 0.380736
 >> iter 28000, loss: 0.182048
 >> iter 29000, loss: 0.189444
 >> iter 30000, loss: 0.109165
   Number of active neurons: 7
 >> iter 31000, loss: 0.570981
 >> iter 32000, loss: 0.252483
 >> iter 33000, loss: 0.248123
 >> iter 34000, loss: 0.121753
 >> iter 35000, loss: 0.644113
 >> iter 36000, loss: 0.366818
 >> iter 37000, loss: 0.461709
 >> iter 38000, loss: 0.277925
 >> iter 39000, loss: 0.435263
 >> iter 40000, loss: 1.043700
   Number of active neurons: 6
 >> iter 41000, loss: 0.468590
 >> iter 42000, loss: 0.212652
 >> iter 43000, loss: 0.346482
 >> iter 44000, loss: 0.226457
 >> iter 45000, loss: 0.167987
 >> iter 46000, loss: 0.127026
 >> iter 47000, loss: 0.296650
 >> iter 48000, loss: 0.276496
 >> iter 49000, loss: 0.324005
 >> iter 50000, loss: 0.197710
   Number of active neurons: 5
 >> iter 51000, loss: 0.256492
 >> iter 52000, loss: 0.276562
 >> iter 53000, loss: 0.482671
 >> iter 54000, loss: 0.251205
 >> iter 55000, loss: 0.201737
 >> iter 56000, loss: 0.301625
 >> iter 57000, loss: 0.161618
 >> iter 58000, loss: 0.324497
 >> iter 59000, loss: 0.158547
 >> iter 60000, loss: 0.186743
   Number of active neurons: 4
 >> iter 61000, loss: 0.156200
 >> iter 62000, loss: 0.117710
 >> iter 63000, loss: 0.269168
 >> iter 64000, loss: 0.414924
 >> iter 65000, loss: 0.323324
 >> iter 66000, loss: 0.328277
 >> iter 67000, loss: 0.251432
 >> iter 68000, loss: 0.287936
 >> iter 69000, loss: 0.462104
 >> iter 70000, loss: 0.536911
   Number of active neurons: 4
 >> iter 71000, loss: 0.373227
 >> iter 72000, loss: 0.233597
 >> iter 73000, loss: 0.239877
 >> iter 74000, loss: 0.153048
 >> iter 75000, loss: 0.128508
 >> iter 76000, loss: 0.106312
 >> iter 77000, loss: 0.237661
 >> iter 78000, loss: 0.229686
 >> iter 79000, loss: 0.228832
 >> iter 80000, loss: 0.130435
   Number of active neurons: 4
 >> iter 81000, loss: 0.300865
 >> iter 82000, loss: 0.202616
 >> iter 83000, loss: 0.239947
 >> iter 84000, loss: 0.202339
 >> iter 85000, loss: 0.295230
 >> iter 86000, loss: 0.304285
 >> iter 87000, loss: 0.287327
 >> iter 88000, loss: 0.175930
 >> iter 89000, loss: 0.220989
 >> iter 90000, loss: 0.139962
   Number of active neurons: 4
 >> iter 91000, loss: 0.218749
 >> iter 92000, loss: 0.152489
 >> iter 93000, loss: 0.196246
 >> iter 94000, loss: 0.145876
 >> iter 95000, loss: 0.126563
 >> iter 96000, loss: 0.102915
 >> iter 97000, loss: 0.208225
 >> iter 98000, loss: 0.119146
 >> iter 99000, loss: 0.241578
 >> iter 100000, loss: 0.196253
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0259994800104
   - Test - Long: 0.0549972501375
   - Test - Big: 0.0849991500085
   - Test - A: 24.3917072195
   - Test - B: 19.00539964
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.532001
 >> iter 2000, loss: 9.918365
 >> iter 3000, loss: 4.670464
 >> iter 4000, loss: 1.809582
 >> iter 5000, loss: 0.690607
 >> iter 6000, loss: 0.337139
 >> iter 7000, loss: 0.453148
 >> iter 8000, loss: 0.208762
 >> iter 9000, loss: 0.271729
 >> iter 10000, loss: 0.194780
   Number of active neurons: 8
 >> iter 11000, loss: 0.112288
 >> iter 12000, loss: 0.067676
 >> iter 13000, loss: 0.042509
 >> iter 14000, loss: 0.137625
 >> iter 15000, loss: 0.070938
 >> iter 16000, loss: 0.252158
 >> iter 17000, loss: 0.114891
 >> iter 18000, loss: 0.242743
 >> iter 19000, loss: 0.271949
 >> iter 20000, loss: 0.468580
   Number of active neurons: 7
 >> iter 21000, loss: 0.220424
 >> iter 22000, loss: 0.219463
 >> iter 23000, loss: 0.101551
 >> iter 24000, loss: 0.572292
 >> iter 25000, loss: 0.361533
 >> iter 26000, loss: 0.351790
 >> iter 27000, loss: 0.254948
 >> iter 28000, loss: 0.205470
 >> iter 29000, loss: 0.324633
 >> iter 30000, loss: 0.205121
   Number of active neurons: 7
 >> iter 31000, loss: 0.261221
 >> iter 32000, loss: 0.218412
 >> iter 33000, loss: 0.267292
 >> iter 34000, loss: 0.125743
 >> iter 35000, loss: 0.639701
 >> iter 36000, loss: 0.291053
 >> iter 37000, loss: 0.354425
 >> iter 38000, loss: 0.155467
 >> iter 39000, loss: 0.625914
 >> iter 40000, loss: 0.269770
   Number of active neurons: 7
 >> iter 41000, loss: 0.498296
 >> iter 42000, loss: 0.268677
 >> iter 43000, loss: 0.246982
 >> iter 44000, loss: 0.145999
 >> iter 45000, loss: 0.400930
 >> iter 46000, loss: 0.171952
 >> iter 47000, loss: 0.195345
 >> iter 48000, loss: 0.160820
 >> iter 49000, loss: 0.133178
 >> iter 50000, loss: 0.123710
   Number of active neurons: 7
 >> iter 51000, loss: 0.126021
 >> iter 52000, loss: 0.305032
 >> iter 53000, loss: 0.208868
 >> iter 54000, loss: 0.145039
 >> iter 55000, loss: 0.265848
 >> iter 56000, loss: 0.154856
 >> iter 57000, loss: 0.227718
 >> iter 58000, loss: 0.365238
 >> iter 59000, loss: 0.259389
 >> iter 60000, loss: 0.143074
   Number of active neurons: 7
 >> iter 61000, loss: 0.214120
 >> iter 62000, loss: 0.151696
 >> iter 63000, loss: 0.185162
 >> iter 64000, loss: 0.096252
 >> iter 65000, loss: 0.211308
 >> iter 66000, loss: 0.111712
 >> iter 67000, loss: 0.175917
 >> iter 68000, loss: 0.203503
 >> iter 69000, loss: 0.165174
 >> iter 70000, loss: 0.085807
   Number of active neurons: 7
 >> iter 71000, loss: 0.116371
 >> iter 72000, loss: 0.119838
 >> iter 73000, loss: 0.431748
 >> iter 74000, loss: 0.227705
 >> iter 75000, loss: 0.285794
 >> iter 76000, loss: 0.126785
 >> iter 77000, loss: 0.231472
 >> iter 78000, loss: 0.194972
 >> iter 79000, loss: 0.281410
 >> iter 80000, loss: 0.226875
   Number of active neurons: 7
 >> iter 81000, loss: 0.297020
 >> iter 82000, loss: 0.196217
 >> iter 83000, loss: 0.239728
 >> iter 84000, loss: 0.113264
 >> iter 85000, loss: 0.153681
 >> iter 86000, loss: 0.073492
 >> iter 87000, loss: 0.147019
 >> iter 88000, loss: 0.072619
 >> iter 89000, loss: 0.122561
 >> iter 90000, loss: 0.187559
   Number of active neurons: 7
 >> iter 91000, loss: 0.110129
 >> iter 92000, loss: 0.069924
 >> iter 93000, loss: 0.110895
 >> iter 94000, loss: 0.074748
 >> iter 95000, loss: 0.236547
 >> iter 96000, loss: 0.118946
 >> iter 97000, loss: 0.241134
 >> iter 98000, loss: 0.108545
 >> iter 99000, loss: 0.104707
 >> iter 100000, loss: 0.267237
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 20.5852943137
   - Test - B: 14.8456769549
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.046204
 >> iter 2000, loss: 8.274588
 >> iter 3000, loss: 3.450044
 >> iter 4000, loss: 1.473363
 >> iter 5000, loss: 0.647447
 >> iter 6000, loss: 0.280533
 >> iter 7000, loss: 0.247290
 >> iter 8000, loss: 0.144554
 >> iter 9000, loss: 0.086457
 >> iter 10000, loss: 0.047846
   Number of active neurons: 6
 >> iter 11000, loss: 0.253532
 >> iter 12000, loss: 0.120131
 >> iter 13000, loss: 0.260791
 >> iter 14000, loss: 0.140275
 >> iter 15000, loss: 0.069927
 >> iter 16000, loss: 0.071097
 >> iter 17000, loss: 0.260025
 >> iter 18000, loss: 0.239940
 >> iter 19000, loss: 0.144608
 >> iter 20000, loss: 0.093486
   Number of active neurons: 6
 >> iter 21000, loss: 0.050906
 >> iter 22000, loss: 0.044958
 >> iter 23000, loss: 0.128344
 >> iter 24000, loss: 0.064441
 >> iter 25000, loss: 0.066060
 >> iter 26000, loss: 0.069172
 >> iter 27000, loss: 0.040332
 >> iter 28000, loss: 0.120079
 >> iter 29000, loss: 0.196199
 >> iter 30000, loss: 0.294022
   Number of active neurons: 6
 >> iter 31000, loss: 0.158469
 >> iter 32000, loss: 0.075978
 >> iter 33000, loss: 0.122163
 >> iter 34000, loss: 0.085719
 >> iter 35000, loss: 0.076488
 >> iter 36000, loss: 0.139735
 >> iter 37000, loss: 0.174995
 >> iter 38000, loss: 0.095696
 >> iter 39000, loss: 0.098206
 >> iter 40000, loss: 0.220263
   Number of active neurons: 6
 >> iter 41000, loss: 0.187067
 >> iter 42000, loss: 0.089699
 >> iter 43000, loss: 0.153046
 >> iter 44000, loss: 0.125500
 >> iter 45000, loss: 0.106359
 >> iter 46000, loss: 0.146644
 >> iter 47000, loss: 0.072487
 >> iter 48000, loss: 0.231538
 >> iter 49000, loss: 0.108271
 >> iter 50000, loss: 0.084233
   Number of active neurons: 5
 >> iter 51000, loss: 0.067556
 >> iter 52000, loss: 0.062070
 >> iter 53000, loss: 0.066256
 >> iter 54000, loss: 0.089393
 >> iter 55000, loss: 0.103673
 >> iter 56000, loss: 0.159232
 >> iter 57000, loss: 0.263714
 >> iter 58000, loss: 0.317406
 >> iter 59000, loss: 0.158114
 >> iter 60000, loss: 0.075891
   Number of active neurons: 5
 >> iter 61000, loss: 0.053009
 >> iter 62000, loss: 0.061681
 >> iter 63000, loss: 0.189819
 >> iter 64000, loss: 0.159242
 >> iter 65000, loss: 0.117550
 >> iter 66000, loss: 0.100658
 >> iter 67000, loss: 0.055216
 >> iter 68000, loss: 0.163341
 >> iter 69000, loss: 0.323645
 >> iter 70000, loss: 0.138651
   Number of active neurons: 5
 >> iter 71000, loss: 0.107706
 >> iter 72000, loss: 0.077978
 >> iter 73000, loss: 0.075799
 >> iter 74000, loss: 0.137936
 >> iter 75000, loss: 0.082797
 >> iter 76000, loss: 0.044917
 >> iter 77000, loss: 0.197540
 >> iter 78000, loss: 0.088503
 >> iter 79000, loss: 0.074177
 >> iter 80000, loss: 0.061457
   Number of active neurons: 5
 >> iter 81000, loss: 0.038718
 >> iter 82000, loss: 0.028066
 >> iter 83000, loss: 0.104318
 >> iter 84000, loss: 0.099626
 >> iter 85000, loss: 0.049197
 >> iter 86000, loss: 0.188084
 >> iter 87000, loss: 0.083918
 >> iter 88000, loss: 0.070511
 >> iter 89000, loss: 0.038899
 >> iter 90000, loss: 0.259186
   Number of active neurons: 5
 >> iter 91000, loss: 0.176568
 >> iter 92000, loss: 0.146035
 >> iter 93000, loss: 0.080650
 >> iter 94000, loss: 0.202209
 >> iter 95000, loss: 0.093550
 >> iter 96000, loss: 0.163027
 >> iter 97000, loss: 0.143445
 >> iter 98000, loss: 0.119864
 >> iter 99000, loss: 0.058572
 >> iter 100000, loss: 0.116854
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 13.9257382841
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 16.219825
 >> iter 2000, loss: 7.281990
 >> iter 3000, loss: 2.947498
 >> iter 4000, loss: 1.326494
 >> iter 5000, loss: 0.823293
 >> iter 6000, loss: 0.552828
 >> iter 7000, loss: 0.282488
 >> iter 8000, loss: 0.122901
 >> iter 9000, loss: 0.613206
 >> iter 10000, loss: 0.265569
   Number of active neurons: 5
 >> iter 11000, loss: 0.396633
 >> iter 12000, loss: 0.192511
 >> iter 13000, loss: 0.261237
 >> iter 14000, loss: 0.171587
 >> iter 15000, loss: 0.124473
 >> iter 16000, loss: 0.177136
 >> iter 17000, loss: 0.152876
 >> iter 18000, loss: 0.084080
 >> iter 19000, loss: 0.286380
 >> iter 20000, loss: 0.160749
   Number of active neurons: 5
 >> iter 21000, loss: 0.189145
 >> iter 22000, loss: 0.290164
 >> iter 23000, loss: 0.195642
 >> iter 24000, loss: 0.170234
 >> iter 25000, loss: 0.219282
 >> iter 26000, loss: 0.259576
 >> iter 27000, loss: 0.245058
 >> iter 28000, loss: 0.173007
 >> iter 29000, loss: 0.161986
 >> iter 30000, loss: 0.124128
   Number of active neurons: 5
 >> iter 31000, loss: 0.291211
 >> iter 32000, loss: 0.216157
 >> iter 33000, loss: 0.232384
 >> iter 34000, loss: 0.309302
 >> iter 35000, loss: 0.320504
 >> iter 36000, loss: 0.197077
 >> iter 37000, loss: 0.112493
 >> iter 38000, loss: 0.160398
 >> iter 39000, loss: 0.124412
 >> iter 40000, loss: 0.134501
   Number of active neurons: 5
 >> iter 41000, loss: 0.087314
 >> iter 42000, loss: 0.124770
 >> iter 43000, loss: 0.171079
 >> iter 44000, loss: 0.139911
 >> iter 45000, loss: 0.367914
 >> iter 46000, loss: 0.230869
 >> iter 47000, loss: 0.182302
 >> iter 48000, loss: 0.138014
 >> iter 49000, loss: 0.244629
 >> iter 50000, loss: 0.166754
   Number of active neurons: 5
 >> iter 51000, loss: 0.454383
 >> iter 52000, loss: 0.314829
 >> iter 53000, loss: 0.338980
 >> iter 54000, loss: 0.161101
 >> iter 55000, loss: 0.210772
 >> iter 56000, loss: 0.189000
 >> iter 57000, loss: 0.386141
 >> iter 58000, loss: 0.303666
 >> iter 59000, loss: 0.260128
 >> iter 60000, loss: 0.138824
   Number of active neurons: 5
 >> iter 61000, loss: 0.157755
 >> iter 62000, loss: 0.245277
 >> iter 63000, loss: 0.157779
 >> iter 64000, loss: 0.167722
 >> iter 65000, loss: 0.385010
 >> iter 66000, loss: 0.367801
 >> iter 67000, loss: 0.284162
 >> iter 68000, loss: 0.247204
 >> iter 69000, loss: 0.282587
 >> iter 70000, loss: 0.224219
   Number of active neurons: 5
 >> iter 71000, loss: 0.372041
 >> iter 72000, loss: 0.187909
 >> iter 73000, loss: 0.184454
 >> iter 74000, loss: 0.146207
 >> iter 75000, loss: 0.570454
 >> iter 76000, loss: 0.308647
 >> iter 77000, loss: 0.340350
 >> iter 78000, loss: 0.184893
 >> iter 79000, loss: 0.301614
 >> iter 80000, loss: 0.215282
   Number of active neurons: 6
 >> iter 81000, loss: 0.304814
 >> iter 82000, loss: 0.174840
 >> iter 83000, loss: 0.155946
 >> iter 84000, loss: 0.216288
 >> iter 85000, loss: 0.221231
 >> iter 86000, loss: 0.152520
 >> iter 87000, loss: 0.317686
 >> iter 88000, loss: 0.335835
 >> iter 89000, loss: 0.222452
 >> iter 90000, loss: 0.121699
   Number of active neurons: 6
 >> iter 91000, loss: 0.118233
 >> iter 92000, loss: 0.080656
 >> iter 93000, loss: 0.262638
 >> iter 94000, loss: 0.200503
 >> iter 95000, loss: 0.188890
 >> iter 96000, loss: 0.097524
 >> iter 97000, loss: 0.555349
 >> iter 98000, loss: 0.266092
 >> iter 99000, loss: 0.164162
 >> iter 100000, loss: 0.084204
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0119997600048
   - Test - Long: 0.01999900005
   - Test - Big: 0.00599994000061
   - Test - A: 25.0716618892
   - Test - B: 42.7171521899
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 16.091924
 >> iter 2000, loss: 6.741643
 >> iter 3000, loss: 2.592957
 >> iter 4000, loss: 1.000824
 >> iter 5000, loss: 0.420345
 >> iter 6000, loss: 0.288867
 >> iter 7000, loss: 0.315569
 >> iter 8000, loss: 0.177139
 >> iter 9000, loss: 0.231983
 >> iter 10000, loss: 0.182722
   Number of active neurons: 7
 >> iter 11000, loss: 0.178657
 >> iter 12000, loss: 0.084937
 >> iter 13000, loss: 0.197461
 >> iter 14000, loss: 0.092584
 >> iter 15000, loss: 0.282741
 >> iter 16000, loss: 0.145266
 >> iter 17000, loss: 0.136290
 >> iter 18000, loss: 0.116962
 >> iter 19000, loss: 0.137433
 >> iter 20000, loss: 0.101914
   Number of active neurons: 7
 >> iter 21000, loss: 0.158439
 >> iter 22000, loss: 0.077944
 >> iter 23000, loss: 0.112637
 >> iter 24000, loss: 0.096786
 >> iter 25000, loss: 0.252507
 >> iter 26000, loss: 0.114098
 >> iter 27000, loss: 0.087200
 >> iter 28000, loss: 0.180948
 >> iter 29000, loss: 0.206566
 >> iter 30000, loss: 0.318884
   Number of active neurons: 7
 >> iter 31000, loss: 0.141137
 >> iter 32000, loss: 0.302075
 >> iter 33000, loss: 0.190220
 >> iter 34000, loss: 0.194486
 >> iter 35000, loss: 0.279235
 >> iter 36000, loss: 0.123000
 >> iter 37000, loss: 0.238379
 >> iter 38000, loss: 0.108717
 >> iter 39000, loss: 0.249262
 >> iter 40000, loss: 0.112852
   Number of active neurons: 6
 >> iter 41000, loss: 0.152305
 >> iter 42000, loss: 0.075446
 >> iter 43000, loss: 0.124355
 >> iter 44000, loss: 0.108572
 >> iter 45000, loss: 0.101599
 >> iter 46000, loss: 0.054647
 >> iter 47000, loss: 0.100574
 >> iter 48000, loss: 0.075454
 >> iter 49000, loss: 0.349363
 >> iter 50000, loss: 0.151971
   Number of active neurons: 6
 >> iter 51000, loss: 0.213574
 >> iter 52000, loss: 0.130876
 >> iter 53000, loss: 0.324853
 >> iter 54000, loss: 0.155340
 >> iter 55000, loss: 0.154764
 >> iter 56000, loss: 0.102676
 >> iter 57000, loss: 0.129164
 >> iter 58000, loss: 0.083827
 >> iter 59000, loss: 0.050032
 >> iter 60000, loss: 0.418426
   Number of active neurons: 5
 >> iter 61000, loss: 0.189966
 >> iter 62000, loss: 0.151689
 >> iter 63000, loss: 0.106748
 >> iter 64000, loss: 0.063492
 >> iter 65000, loss: 0.064137
 >> iter 66000, loss: 0.127955
 >> iter 67000, loss: 0.061673
 >> iter 68000, loss: 0.117296
 >> iter 69000, loss: 0.060376
 >> iter 70000, loss: 0.037066
   Number of active neurons: 5
 >> iter 71000, loss: 0.081175
 >> iter 72000, loss: 0.061259
 >> iter 73000, loss: 0.133889
 >> iter 74000, loss: 0.098884
 >> iter 75000, loss: 0.176232
 >> iter 76000, loss: 0.107690
 >> iter 77000, loss: 0.116424
 >> iter 78000, loss: 0.109748
 >> iter 79000, loss: 0.167164
 >> iter 80000, loss: 0.102507
   Number of active neurons: 5
 >> iter 81000, loss: 0.159404
 >> iter 82000, loss: 0.168497
 >> iter 83000, loss: 0.095187
 >> iter 84000, loss: 0.079680
 >> iter 85000, loss: 0.049859
 >> iter 86000, loss: 0.082267
 >> iter 87000, loss: 0.082186
 >> iter 88000, loss: 0.043045
 >> iter 89000, loss: 0.091440
 >> iter 90000, loss: 0.171065
   Number of active neurons: 5
 >> iter 91000, loss: 0.084263
 >> iter 92000, loss: 0.074511
 >> iter 93000, loss: 0.226383
 >> iter 94000, loss: 0.126033
 >> iter 95000, loss: 0.091992
 >> iter 96000, loss: 0.086824
 >> iter 97000, loss: 0.146256
 >> iter 98000, loss: 0.213402
 >> iter 99000, loss: 0.213352
 >> iter 100000, loss: 0.095274
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 28.9514032398
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 16.378561
 >> iter 2000, loss: 7.244961
 >> iter 3000, loss: 2.768689
 >> iter 4000, loss: 1.051769
 >> iter 5000, loss: 0.476606
 >> iter 6000, loss: 0.203667
 >> iter 7000, loss: 0.174079
 >> iter 8000, loss: 0.090313
 >> iter 9000, loss: 0.086654
 >> iter 10000, loss: 0.051960
   Number of active neurons: 8
 >> iter 11000, loss: 0.085515
 >> iter 12000, loss: 0.052033
 >> iter 13000, loss: 0.132849
 >> iter 14000, loss: 0.133962
 >> iter 15000, loss: 0.101486
 >> iter 16000, loss: 0.056668
 >> iter 17000, loss: 0.074232
 >> iter 18000, loss: 0.061269
 >> iter 19000, loss: 0.186178
 >> iter 20000, loss: 0.102361
   Number of active neurons: 5
 >> iter 21000, loss: 0.111384
 >> iter 22000, loss: 0.068657
 >> iter 23000, loss: 0.184846
 >> iter 24000, loss: 0.093871
 >> iter 25000, loss: 0.073358
 >> iter 26000, loss: 0.160763
 >> iter 27000, loss: 0.101367
 >> iter 28000, loss: 0.080222
 >> iter 29000, loss: 0.107566
 >> iter 30000, loss: 0.056844
   Number of active neurons: 5
 >> iter 31000, loss: 0.035553
 >> iter 32000, loss: 0.186728
 >> iter 33000, loss: 0.094750
 >> iter 34000, loss: 0.086722
 >> iter 35000, loss: 0.046847
 >> iter 36000, loss: 0.175843
 >> iter 37000, loss: 0.090395
 >> iter 38000, loss: 0.198047
 >> iter 39000, loss: 0.141702
 >> iter 40000, loss: 0.243978
   Number of active neurons: 5
 >> iter 41000, loss: 0.189528
 >> iter 42000, loss: 0.144194
 >> iter 43000, loss: 0.134647
 >> iter 44000, loss: 0.135657
 >> iter 45000, loss: 0.150462
 >> iter 46000, loss: 0.072281
 >> iter 47000, loss: 0.180764
 >> iter 48000, loss: 0.097035
 >> iter 49000, loss: 0.073846
 >> iter 50000, loss: 0.091645
   Number of active neurons: 5
 >> iter 51000, loss: 0.090804
 >> iter 52000, loss: 0.128040
 >> iter 53000, loss: 0.167293
 >> iter 54000, loss: 0.110656
 >> iter 55000, loss: 0.090531
 >> iter 56000, loss: 0.115019
 >> iter 57000, loss: 0.108913
 >> iter 58000, loss: 0.055431
 >> iter 59000, loss: 0.063494
 >> iter 60000, loss: 0.070192
   Number of active neurons: 5
 >> iter 61000, loss: 0.060902
 >> iter 62000, loss: 0.047397
 >> iter 63000, loss: 0.054069
 >> iter 64000, loss: 0.061947
 >> iter 65000, loss: 0.035446
 >> iter 66000, loss: 0.083839
 >> iter 67000, loss: 0.043635
 >> iter 68000, loss: 0.033673
 >> iter 69000, loss: 0.085040
 >> iter 70000, loss: 0.112229
   Number of active neurons: 5
 >> iter 71000, loss: 0.080643
 >> iter 72000, loss: 0.069988
 >> iter 73000, loss: 0.039276
 >> iter 74000, loss: 0.171260
 >> iter 75000, loss: 0.114131
 >> iter 76000, loss: 0.056187
 >> iter 77000, loss: 0.076236
 >> iter 78000, loss: 0.040675
 >> iter 79000, loss: 0.131263
 >> iter 80000, loss: 0.087127
   Number of active neurons: 5
 >> iter 81000, loss: 0.051462
 >> iter 82000, loss: 0.200017
 >> iter 83000, loss: 0.114904
 >> iter 84000, loss: 0.055881
 >> iter 85000, loss: 0.131084
 >> iter 86000, loss: 0.061624
 >> iter 87000, loss: 0.036444
 >> iter 88000, loss: 0.136584
 >> iter 89000, loss: 0.063309
 >> iter 90000, loss: 0.068998
   Number of active neurons: 5
 >> iter 91000, loss: 0.038153
 >> iter 92000, loss: 0.056093
 >> iter 93000, loss: 0.150649
 >> iter 94000, loss: 0.068596
 >> iter 95000, loss: 0.245684
 >> iter 96000, loss: 0.105688
 >> iter 97000, loss: 0.055937
 >> iter 98000, loss: 0.080460
 >> iter 99000, loss: 0.193086
 >> iter 100000, loss: 0.101739
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 45.6702886474
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.057738
 >> iter 2000, loss: 7.472843
 >> iter 3000, loss: 2.885886
 >> iter 4000, loss: 1.173790
 >> iter 5000, loss: 0.470179
 >> iter 6000, loss: 0.230959
 >> iter 7000, loss: 0.110803
 >> iter 8000, loss: 0.088631
 >> iter 9000, loss: 0.070058
 >> iter 10000, loss: 0.044412
   Number of active neurons: 8
 >> iter 11000, loss: 0.092204
 >> iter 12000, loss: 0.072030
 >> iter 13000, loss: 0.086355
 >> iter 14000, loss: 0.071558
 >> iter 15000, loss: 0.061583
 >> iter 16000, loss: 0.039113
 >> iter 17000, loss: 0.094245
 >> iter 18000, loss: 0.057071
 >> iter 19000, loss: 0.079548
 >> iter 20000, loss: 0.045093
   Number of active neurons: 7
 >> iter 21000, loss: 0.074753
 >> iter 22000, loss: 0.061998
 >> iter 23000, loss: 0.046987
 >> iter 24000, loss: 0.118135
 >> iter 25000, loss: 0.074345
 >> iter 26000, loss: 0.055225
 >> iter 27000, loss: 0.088212
 >> iter 28000, loss: 0.049155
 >> iter 29000, loss: 0.235126
 >> iter 30000, loss: 0.123673
   Number of active neurons: 7
 >> iter 31000, loss: 0.107439
 >> iter 32000, loss: 0.055764
 >> iter 33000, loss: 0.051505
 >> iter 34000, loss: 0.041865
 >> iter 35000, loss: 0.285132
 >> iter 36000, loss: 0.125405
 >> iter 37000, loss: 0.083751
 >> iter 38000, loss: 0.046045
 >> iter 39000, loss: 0.128502
 >> iter 40000, loss: 0.096951
   Number of active neurons: 7
 >> iter 41000, loss: 0.079275
 >> iter 42000, loss: 0.070541
 >> iter 43000, loss: 0.065267
 >> iter 44000, loss: 0.080548
 >> iter 45000, loss: 0.057820
 >> iter 46000, loss: 0.126770
 >> iter 47000, loss: 0.064311
 >> iter 48000, loss: 0.215289
 >> iter 49000, loss: 0.123475
 >> iter 50000, loss: 0.060441
   Number of active neurons: 6
 >> iter 51000, loss: 0.065188
 >> iter 52000, loss: 0.105131
 >> iter 53000, loss: 0.054045
 >> iter 54000, loss: 0.100331
 >> iter 55000, loss: 0.051797
 >> iter 56000, loss: 0.176592
 >> iter 57000, loss: 0.083497
 >> iter 58000, loss: 0.074880
 >> iter 59000, loss: 0.103521
 >> iter 60000, loss: 0.054334
   Number of active neurons: 4
 >> iter 61000, loss: 0.175263
 >> iter 62000, loss: 0.080641
 >> iter 63000, loss: 0.106341
 >> iter 64000, loss: 0.350283
 >> iter 65000, loss: 0.393216
 >> iter 66000, loss: 0.251007
 >> iter 67000, loss: 0.110922
 >> iter 68000, loss: 0.075389
 >> iter 69000, loss: 0.043910
 >> iter 70000, loss: 0.059281
   Number of active neurons: 6
 >> iter 71000, loss: 0.093412
 >> iter 72000, loss: 0.210971
 >> iter 73000, loss: 0.189173
 >> iter 74000, loss: 0.084993
 >> iter 75000, loss: 0.045656
 >> iter 76000, loss: 0.097509
 >> iter 77000, loss: 0.310653
 >> iter 78000, loss: 0.137860
 >> iter 79000, loss: 0.105005
 >> iter 80000, loss: 0.117025
   Number of active neurons: 4
 >> iter 81000, loss: 0.057629
 >> iter 82000, loss: 0.073639
 >> iter 83000, loss: 0.040771
 >> iter 84000, loss: 0.072021
 >> iter 85000, loss: 0.039416
 >> iter 86000, loss: 0.100060
 >> iter 87000, loss: 0.091087
 >> iter 88000, loss: 0.095117
 >> iter 89000, loss: 0.094708
 >> iter 90000, loss: 0.058970
   Number of active neurons: 4
 >> iter 91000, loss: 0.147925
 >> iter 92000, loss: 0.068546
 >> iter 93000, loss: 0.148103
 >> iter 94000, loss: 0.071660
 >> iter 95000, loss: 0.039026
 >> iter 96000, loss: 0.040008
 >> iter 97000, loss: 0.064800
 >> iter 98000, loss: 0.061650
 >> iter 99000, loss: 0.116588
 >> iter 100000, loss: 0.080502
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.009999500025
   - Test - Big: 0.0
   - Test - A: 38.1307912806
   - Test - B: 0.00666622225185
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.433748
 >> iter 2000, loss: 7.446638
 >> iter 3000, loss: 2.861122
 >> iter 4000, loss: 1.095149
 >> iter 5000, loss: 0.466019
 >> iter 6000, loss: 0.293121
 >> iter 7000, loss: 0.192816
 >> iter 8000, loss: 0.303459
 >> iter 9000, loss: 0.213617
 >> iter 10000, loss: 0.311603
   Number of active neurons: 8
 >> iter 11000, loss: 0.276746
 >> iter 12000, loss: 0.325258
 >> iter 13000, loss: 0.299654
 >> iter 14000, loss: 0.184847
 >> iter 15000, loss: 0.147543
 >> iter 16000, loss: 0.217523
 >> iter 17000, loss: 0.154020
 >> iter 18000, loss: 0.117514
 >> iter 19000, loss: 0.118241
 >> iter 20000, loss: 0.349022
   Number of active neurons: 6
 >> iter 21000, loss: 0.178561
 >> iter 22000, loss: 0.084781
 >> iter 23000, loss: 0.190244
 >> iter 24000, loss: 0.088563
 >> iter 25000, loss: 0.135979
 >> iter 26000, loss: 0.076824
 >> iter 27000, loss: 0.158132
 >> iter 28000, loss: 0.076857
 >> iter 29000, loss: 0.179479
 >> iter 30000, loss: 0.084036
   Number of active neurons: 6
 >> iter 31000, loss: 0.141378
 >> iter 32000, loss: 0.132481
 >> iter 33000, loss: 0.124823
 >> iter 34000, loss: 0.063063
 >> iter 35000, loss: 0.113877
 >> iter 36000, loss: 0.057414
 >> iter 37000, loss: 0.137984
 >> iter 38000, loss: 0.123937
 >> iter 39000, loss: 0.085929
 >> iter 40000, loss: 0.078205
   Number of active neurons: 6
 >> iter 41000, loss: 0.097623
 >> iter 42000, loss: 0.088053
 >> iter 43000, loss: 0.081838
 >> iter 44000, loss: 0.100465
 >> iter 45000, loss: 0.062851
 >> iter 46000, loss: 0.062604
 >> iter 47000, loss: 0.070293
 >> iter 48000, loss: 0.051323
 >> iter 49000, loss: 0.196065
 >> iter 50000, loss: 0.098663
   Number of active neurons: 6
 >> iter 51000, loss: 0.113522
 >> iter 52000, loss: 0.096453
 >> iter 53000, loss: 0.215625
 >> iter 54000, loss: 0.095740
 >> iter 55000, loss: 0.165273
 >> iter 56000, loss: 0.076198
 >> iter 57000, loss: 0.126685
 >> iter 58000, loss: 0.060979
 >> iter 59000, loss: 0.132797
 >> iter 60000, loss: 0.167566
   Number of active neurons: 5
 >> iter 61000, loss: 0.133596
 >> iter 62000, loss: 0.067838
 >> iter 63000, loss: 0.091751
 >> iter 64000, loss: 0.122518
 >> iter 65000, loss: 0.251693
 >> iter 66000, loss: 0.106991
 >> iter 67000, loss: 0.147500
 >> iter 68000, loss: 0.069385
 >> iter 69000, loss: 0.195015
 >> iter 70000, loss: 0.132476
   Number of active neurons: 5
 >> iter 71000, loss: 0.195114
 >> iter 72000, loss: 0.210876
 >> iter 73000, loss: 0.115302
 >> iter 74000, loss: 0.056256
 >> iter 75000, loss: 0.199072
 >> iter 76000, loss: 0.093927
 >> iter 77000, loss: 0.140284
 >> iter 78000, loss: 0.090305
 >> iter 79000, loss: 0.127005
 >> iter 80000, loss: 0.110985
   Number of active neurons: 5
 >> iter 81000, loss: 0.112422
 >> iter 82000, loss: 0.179127
 >> iter 83000, loss: 0.163829
 >> iter 84000, loss: 0.075772
 >> iter 85000, loss: 0.313615
 >> iter 86000, loss: 0.267979
 >> iter 87000, loss: 0.267463
 >> iter 88000, loss: 0.148553
 >> iter 89000, loss: 0.189853
 >> iter 90000, loss: 0.086169
   Number of active neurons: 5
 >> iter 91000, loss: 0.225648
 >> iter 92000, loss: 0.118583
 >> iter 93000, loss: 0.224263
 >> iter 94000, loss: 0.098837
 >> iter 95000, loss: 0.087795
 >> iter 96000, loss: 0.084091
 >> iter 97000, loss: 0.170657
 >> iter 98000, loss: 0.078367
 >> iter 99000, loss: 0.260282
 >> iter 100000, loss: 0.122191
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 21.9985334311
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.306340
 >> iter 2000, loss: 7.236925
 >> iter 3000, loss: 2.913042
 >> iter 4000, loss: 1.240656
 >> iter 5000, loss: 0.542862
 >> iter 6000, loss: 0.248295
 >> iter 7000, loss: 0.220747
 >> iter 8000, loss: 0.126595
 >> iter 9000, loss: 0.077522
 >> iter 10000, loss: 0.060801
   Number of active neurons: 6
 >> iter 11000, loss: 0.118983
 >> iter 12000, loss: 0.234492
 >> iter 13000, loss: 0.262714
 >> iter 14000, loss: 0.127793
 >> iter 15000, loss: 0.277381
 >> iter 16000, loss: 0.122875
 >> iter 17000, loss: 0.612390
 >> iter 18000, loss: 0.340190
 >> iter 19000, loss: 0.583375
 >> iter 20000, loss: 0.337452
   Number of active neurons: 6
 >> iter 21000, loss: 0.589946
 >> iter 22000, loss: 0.370740
 >> iter 23000, loss: 0.260070
 >> iter 24000, loss: 0.171357
 >> iter 25000, loss: 0.612783
 >> iter 26000, loss: 0.383166
 >> iter 27000, loss: 0.538728
 >> iter 28000, loss: 0.288132
 >> iter 29000, loss: 0.223315
 >> iter 30000, loss: 0.151723
   Number of active neurons: 6
 >> iter 31000, loss: 1.394365
 >> iter 32000, loss: 0.548979
 >> iter 33000, loss: 0.277736
 >> iter 34000, loss: 0.176160
 >> iter 35000, loss: 0.229729
 >> iter 36000, loss: 0.120885
 >> iter 37000, loss: 0.449093
 >> iter 38000, loss: 0.193532
 >> iter 39000, loss: 0.252617
 >> iter 40000, loss: 0.133796
   Number of active neurons: 6
 >> iter 41000, loss: 0.620062
 >> iter 42000, loss: 0.260986
 >> iter 43000, loss: 0.545579
 >> iter 44000, loss: 0.229762
 >> iter 45000, loss: 0.547041
 >> iter 46000, loss: 0.229811
 >> iter 47000, loss: 0.625739
 >> iter 48000, loss: 0.343570
 >> iter 49000, loss: 0.385766
 >> iter 50000, loss: 0.197461
   Number of active neurons: 5
 >> iter 51000, loss: 0.362861
 >> iter 52000, loss: 0.204544
 >> iter 53000, loss: 0.467366
 >> iter 54000, loss: 0.362596
 >> iter 55000, loss: 0.241239
 >> iter 56000, loss: 1.098938
 >> iter 57000, loss: 0.585205
 >> iter 58000, loss: 0.291975
 >> iter 59000, loss: 0.481053
 >> iter 60000, loss: 0.205133
   Number of active neurons: 5
 >> iter 61000, loss: 0.400858
 >> iter 62000, loss: 0.226222
 >> iter 63000, loss: 0.437985
 >> iter 64000, loss: 0.207794
 >> iter 65000, loss: 0.453494
 >> iter 66000, loss: 0.315802
 >> iter 67000, loss: 0.326755
 >> iter 68000, loss: 0.387193
 >> iter 69000, loss: 0.499259
 >> iter 70000, loss: 0.368480
   Number of active neurons: 5
 >> iter 71000, loss: 0.523436
 >> iter 72000, loss: 0.359742
 >> iter 73000, loss: 0.304056
 >> iter 74000, loss: 0.530535
 >> iter 75000, loss: 0.456141
 >> iter 76000, loss: 0.364153
 >> iter 77000, loss: 0.601085
 >> iter 78000, loss: 0.261299
 >> iter 79000, loss: 0.209344
 >> iter 80000, loss: 0.106415
   Number of active neurons: 4
 >> iter 81000, loss: 0.321234
 >> iter 82000, loss: 0.139481
 >> iter 83000, loss: 0.785441
 >> iter 84000, loss: 0.492267
 >> iter 85000, loss: 0.236244
 >> iter 86000, loss: 0.163633
 >> iter 87000, loss: 0.166340
 >> iter 88000, loss: 0.224126
 >> iter 89000, loss: 0.736357
 >> iter 90000, loss: 0.506528
   Number of active neurons: 5
 >> iter 91000, loss: 0.575571
 >> iter 92000, loss: 0.310533
 >> iter 93000, loss: 0.266720
 >> iter 94000, loss: 0.243181
 >> iter 95000, loss: 0.483692
 >> iter 96000, loss: 0.288250
 >> iter 97000, loss: 0.212477
 >> iter 98000, loss: 0.096915
 >> iter 99000, loss: 0.415054
 >> iter 100000, loss: 0.293607
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0379992400152
   - Test - Long: 0.0849957502125
   - Test - Big: 0.125998740013
   - Test - A: 24.3983734418
   - Test - B: 51.9898673422
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.163770
 >> iter 2000, loss: 7.311481
 >> iter 3000, loss: 2.817454
 >> iter 4000, loss: 1.064243
 >> iter 5000, loss: 0.420123
 >> iter 6000, loss: 0.338610
 >> iter 7000, loss: 0.313240
 >> iter 8000, loss: 0.155431
 >> iter 9000, loss: 0.128068
 >> iter 10000, loss: 0.239113
   Number of active neurons: 8
 >> iter 11000, loss: 0.263503
 >> iter 12000, loss: 0.120112
 >> iter 13000, loss: 0.315468
 >> iter 14000, loss: 0.227989
 >> iter 15000, loss: 0.156254
 >> iter 16000, loss: 0.118848
 >> iter 17000, loss: 0.214590
 >> iter 18000, loss: 0.096974
 >> iter 19000, loss: 0.199939
 >> iter 20000, loss: 0.161939
   Number of active neurons: 8
 >> iter 21000, loss: 0.144950
 >> iter 22000, loss: 0.153364
 >> iter 23000, loss: 0.107277
 >> iter 24000, loss: 0.081947
 >> iter 25000, loss: 0.071286
 >> iter 26000, loss: 0.075096
 >> iter 27000, loss: 0.163525
 >> iter 28000, loss: 0.079021
 >> iter 29000, loss: 0.061031
 >> iter 30000, loss: 0.038500
   Number of active neurons: 8
 >> iter 31000, loss: 0.053441
 >> iter 32000, loss: 0.066741
 >> iter 33000, loss: 0.041894
 >> iter 34000, loss: 0.132794
 >> iter 35000, loss: 0.251764
 >> iter 36000, loss: 0.114300
 >> iter 37000, loss: 0.061647
 >> iter 38000, loss: 0.128066
 >> iter 39000, loss: 0.079280
 >> iter 40000, loss: 0.046166
   Number of active neurons: 7
 >> iter 41000, loss: 0.089854
 >> iter 42000, loss: 0.101044
 >> iter 43000, loss: 0.140848
 >> iter 44000, loss: 0.203518
 >> iter 45000, loss: 0.094516
 >> iter 46000, loss: 0.307677
 >> iter 47000, loss: 0.223142
 >> iter 48000, loss: 0.102103
 >> iter 49000, loss: 0.065649
 >> iter 50000, loss: 0.141818
   Number of active neurons: 6
 >> iter 51000, loss: 0.128096
 >> iter 52000, loss: 0.069393
 >> iter 53000, loss: 0.230452
 >> iter 54000, loss: 0.187129
 >> iter 55000, loss: 0.120985
 >> iter 56000, loss: 0.078591
 >> iter 57000, loss: 0.086036
 >> iter 58000, loss: 0.108926
 >> iter 59000, loss: 0.113249
 >> iter 60000, loss: 0.118418
   Number of active neurons: 6
 >> iter 61000, loss: 0.161215
 >> iter 62000, loss: 0.099005
 >> iter 63000, loss: 0.057669
 >> iter 64000, loss: 0.326070
 >> iter 65000, loss: 0.161620
 >> iter 66000, loss: 0.076019
 >> iter 67000, loss: 0.108532
 >> iter 68000, loss: 0.070758
 >> iter 69000, loss: 0.073727
 >> iter 70000, loss: 0.065523
   Number of active neurons: 6
 >> iter 71000, loss: 0.083705
 >> iter 72000, loss: 0.165989
 >> iter 73000, loss: 0.103261
 >> iter 74000, loss: 0.066809
 >> iter 75000, loss: 0.097546
 >> iter 76000, loss: 0.063713
 >> iter 77000, loss: 0.222674
 >> iter 78000, loss: 0.098794
 >> iter 79000, loss: 0.056262
 >> iter 80000, loss: 0.067335
   Number of active neurons: 6
 >> iter 81000, loss: 0.146312
 >> iter 82000, loss: 0.078889
 >> iter 83000, loss: 0.221510
 >> iter 84000, loss: 0.097061
 >> iter 85000, loss: 0.067564
 >> iter 86000, loss: 0.040145
 >> iter 87000, loss: 0.149331
 >> iter 88000, loss: 0.091257
 >> iter 89000, loss: 0.101526
 >> iter 90000, loss: 0.133117
   Number of active neurons: 6
 >> iter 91000, loss: 0.139942
 >> iter 92000, loss: 0.080629
 >> iter 93000, loss: 0.109745
 >> iter 94000, loss: 0.091286
 >> iter 95000, loss: 0.100912
 >> iter 96000, loss: 0.072176
 >> iter 97000, loss: 0.161974
 >> iter 98000, loss: 0.073985
 >> iter 99000, loss: 0.131570
 >> iter 100000, loss: 0.130228
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0119997600048
   - Test - Long: 0.0
   - Test - Big: 0.0029999700003
   - Test - A: 54.6363575762
   - Test - B: 25.9316045597
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.557303
 >> iter 2000, loss: 7.557854
 >> iter 3000, loss: 3.139557
 >> iter 4000, loss: 1.251962
 >> iter 5000, loss: 0.514535
 >> iter 6000, loss: 0.299742
 >> iter 7000, loss: 0.161021
 >> iter 8000, loss: 0.180216
 >> iter 9000, loss: 0.216875
 >> iter 10000, loss: 0.111134
   Number of active neurons: 7
 >> iter 11000, loss: 0.107349
 >> iter 12000, loss: 0.075834
 >> iter 13000, loss: 0.255403
 >> iter 14000, loss: 0.115463
 >> iter 15000, loss: 0.235648
 >> iter 16000, loss: 0.172830
 >> iter 17000, loss: 0.283858
 >> iter 18000, loss: 0.178795
 >> iter 19000, loss: 0.181409
 >> iter 20000, loss: 0.198676
   Number of active neurons: 6
 >> iter 21000, loss: 0.448434
 >> iter 22000, loss: 0.279116
 >> iter 23000, loss: 0.227987
 >> iter 24000, loss: 0.223749
 >> iter 25000, loss: 0.291930
 >> iter 26000, loss: 0.326458
 >> iter 27000, loss: 0.336553
 >> iter 28000, loss: 0.198180
 >> iter 29000, loss: 0.283695
 >> iter 30000, loss: 0.242303
   Number of active neurons: 5
 >> iter 31000, loss: 0.286066
 >> iter 32000, loss: 0.895749
 >> iter 33000, loss: 0.862202
 >> iter 34000, loss: 0.489790
 >> iter 35000, loss: 0.288850
 >> iter 36000, loss: 0.270254
 >> iter 37000, loss: 0.575990
 >> iter 38000, loss: 1.343660
 >> iter 39000, loss: 0.803485
 >> iter 40000, loss: 0.358575
   Number of active neurons: 6
 >> iter 41000, loss: 0.198307
 >> iter 42000, loss: 0.231622
 >> iter 43000, loss: 0.197729
 >> iter 44000, loss: 0.126698
 >> iter 45000, loss: 0.507253
 >> iter 46000, loss: 0.338464
 >> iter 47000, loss: 0.287196
 >> iter 48000, loss: 0.292727
 >> iter 49000, loss: 0.491386
 >> iter 50000, loss: 0.572708
   Number of active neurons: 6
 >> iter 51000, loss: 0.347885
 >> iter 52000, loss: 0.226163
 >> iter 53000, loss: 0.263429
 >> iter 54000, loss: 0.397779
 >> iter 55000, loss: 0.212483
 >> iter 56000, loss: 0.245618
 >> iter 57000, loss: 0.418056
 >> iter 58000, loss: 0.223831
 >> iter 59000, loss: 0.139986
 >> iter 60000, loss: 0.122832
   Number of active neurons: 5
 >> iter 61000, loss: 0.117047
 >> iter 62000, loss: 0.068289
 >> iter 63000, loss: 0.086513
 >> iter 64000, loss: 0.345196
 >> iter 65000, loss: 0.459200
 >> iter 66000, loss: 0.249124
 >> iter 67000, loss: 0.159149
 >> iter 68000, loss: 0.118368
 >> iter 69000, loss: 0.186220
 >> iter 70000, loss: 0.539293
   Number of active neurons: 4
 >> iter 71000, loss: 0.297525
 >> iter 72000, loss: 0.195199
 >> iter 73000, loss: 0.405301
 >> iter 74000, loss: 0.335587
 >> iter 75000, loss: 0.502221
 >> iter 76000, loss: 0.422098
 >> iter 77000, loss: 0.574263
 >> iter 78000, loss: 0.441019
 >> iter 79000, loss: 0.215518
 >> iter 80000, loss: 0.126960
   Number of active neurons: 5
 >> iter 81000, loss: 0.176397
 >> iter 82000, loss: 0.094004
 >> iter 83000, loss: 0.137769
 >> iter 84000, loss: 0.264989
 >> iter 85000, loss: 0.177966
 >> iter 86000, loss: 0.146674
 >> iter 87000, loss: 0.077278
 >> iter 88000, loss: 0.073302
 >> iter 89000, loss: 0.262740
 >> iter 90000, loss: 0.268622
   Number of active neurons: 5
 >> iter 91000, loss: 0.117745
 >> iter 92000, loss: 0.134714
 >> iter 93000, loss: 0.070469
 >> iter 94000, loss: 0.232479
 >> iter 95000, loss: 0.638728
 >> iter 96000, loss: 0.328890
 >> iter 97000, loss: 0.164264
 >> iter 98000, loss: 0.078435
 >> iter 99000, loss: 0.126892
 >> iter 100000, loss: 0.063180
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00599994000061
   - Test - A: 7.15952269849
   - Test - B: 44.9036730885
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.127495
 >> iter 2000, loss: 11.043103
 >> iter 3000, loss: 6.859128
 >> iter 4000, loss: 3.359190
 >> iter 5000, loss: 1.453312
 >> iter 6000, loss: 0.892451
 >> iter 7000, loss: 0.674845
 >> iter 8000, loss: 0.390287
 >> iter 9000, loss: 0.450222
 >> iter 10000, loss: 0.266600
   Number of active neurons: 9
 >> iter 11000, loss: 0.273951
 >> iter 12000, loss: 0.203151
 >> iter 13000, loss: 0.284209
 >> iter 14000, loss: 0.480914
 >> iter 15000, loss: 0.309737
 >> iter 16000, loss: 0.208707
 >> iter 17000, loss: 0.283280
 >> iter 18000, loss: 0.448305
 >> iter 19000, loss: 0.260124
 >> iter 20000, loss: 0.362248
   Number of active neurons: 8
 >> iter 21000, loss: 0.525666
 >> iter 22000, loss: 0.298329
 >> iter 23000, loss: 0.278322
 >> iter 24000, loss: 0.171485
 >> iter 25000, loss: 0.379174
 >> iter 26000, loss: 0.198130
 >> iter 27000, loss: 0.222644
 >> iter 28000, loss: 0.152524
 >> iter 29000, loss: 0.285883
 >> iter 30000, loss: 0.450699
   Number of active neurons: 8
 >> iter 31000, loss: 0.320866
 >> iter 32000, loss: 0.372264
 >> iter 33000, loss: 0.499061
 >> iter 34000, loss: 0.311891
 >> iter 35000, loss: 0.398153
 >> iter 36000, loss: 0.401464
 >> iter 37000, loss: 0.339596
 >> iter 38000, loss: 0.297919
 >> iter 39000, loss: 0.182250
 >> iter 40000, loss: 0.152929
   Number of active neurons: 8
 >> iter 41000, loss: 0.241611
 >> iter 42000, loss: 0.204683
 >> iter 43000, loss: 0.249201
 >> iter 44000, loss: 0.267530
 >> iter 45000, loss: 0.202141
 >> iter 46000, loss: 0.173502
 >> iter 47000, loss: 0.244670
 >> iter 48000, loss: 0.251773
 >> iter 49000, loss: 0.206962
 >> iter 50000, loss: 0.129337
   Number of active neurons: 7
 >> iter 51000, loss: 0.139450
 >> iter 52000, loss: 0.209631
 >> iter 53000, loss: 0.145662
 >> iter 54000, loss: 0.107168
 >> iter 55000, loss: 0.162970
 >> iter 56000, loss: 0.139644
 >> iter 57000, loss: 0.168192
 >> iter 58000, loss: 0.156709
 >> iter 59000, loss: 0.123872
 >> iter 60000, loss: 0.147610
   Number of active neurons: 6
 >> iter 61000, loss: 0.148057
 >> iter 62000, loss: 0.253542
 >> iter 63000, loss: 0.202366
 >> iter 64000, loss: 0.209419
 >> iter 65000, loss: 0.204520
 >> iter 66000, loss: 0.131682
 >> iter 67000, loss: 0.109913
 >> iter 68000, loss: 0.256080
 >> iter 69000, loss: 0.118635
 >> iter 70000, loss: 0.101110
   Number of active neurons: 6
 >> iter 71000, loss: 0.087565
 >> iter 72000, loss: 0.095957
 >> iter 73000, loss: 0.126822
 >> iter 74000, loss: 0.068515
 >> iter 75000, loss: 0.065783
 >> iter 76000, loss: 0.065968
 >> iter 77000, loss: 0.041303
 >> iter 78000, loss: 0.068219
 >> iter 79000, loss: 0.051626
 >> iter 80000, loss: 0.038464
   Number of active neurons: 5
 >> iter 81000, loss: 0.092958
 >> iter 82000, loss: 0.225707
 >> iter 83000, loss: 0.185346
 >> iter 84000, loss: 0.177677
 >> iter 85000, loss: 0.106504
 >> iter 86000, loss: 0.102653
 >> iter 87000, loss: 0.069859
 >> iter 88000, loss: 0.069128
 >> iter 89000, loss: 0.057089
 >> iter 90000, loss: 0.040066
   Number of active neurons: 5
 >> iter 91000, loss: 0.123870
 >> iter 92000, loss: 0.180501
 >> iter 93000, loss: 0.097886
 >> iter 94000, loss: 0.075190
 >> iter 95000, loss: 0.047424
 >> iter 96000, loss: 0.046039
 >> iter 97000, loss: 0.056513
 >> iter 98000, loss: 0.057721
 >> iter 99000, loss: 0.152218
 >> iter 100000, loss: 0.082451
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0619987600248
   - Test - Long: 0.049997500125
   - Test - Big: 0.0849991500085
   - Test - A: 40.2906472902
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.457957
 >> iter 2000, loss: 8.220569
 >> iter 3000, loss: 3.303347
 >> iter 4000, loss: 1.402979
 >> iter 5000, loss: 0.575624
 >> iter 6000, loss: 0.246626
 >> iter 7000, loss: 0.607433
 >> iter 8000, loss: 0.441599
 >> iter 9000, loss: 0.191606
 >> iter 10000, loss: 0.486556
   Number of active neurons: 6
 >> iter 11000, loss: 0.462413
 >> iter 12000, loss: 0.231296
 >> iter 13000, loss: 0.174577
 >> iter 14000, loss: 0.197942
 >> iter 15000, loss: 0.308278
 >> iter 16000, loss: 0.920314
 >> iter 17000, loss: 0.396513
 >> iter 18000, loss: 0.317064
 >> iter 19000, loss: 0.264808
 >> iter 20000, loss: 0.144119
   Number of active neurons: 6
 >> iter 21000, loss: 0.168833
 >> iter 22000, loss: 0.115746
 >> iter 23000, loss: 0.107004
 >> iter 24000, loss: 0.543113
 >> iter 25000, loss: 0.350716
 >> iter 26000, loss: 0.161138
 >> iter 27000, loss: 0.411648
 >> iter 28000, loss: 0.312418
 >> iter 29000, loss: 0.230036
 >> iter 30000, loss: 0.153869
   Number of active neurons: 6
 >> iter 31000, loss: 0.180595
 >> iter 32000, loss: 0.243770
 >> iter 33000, loss: 0.312122
 >> iter 34000, loss: 0.256597
 >> iter 35000, loss: 0.491602
 >> iter 36000, loss: 0.238078
 >> iter 37000, loss: 0.598168
 >> iter 38000, loss: 0.747173
 >> iter 39000, loss: 0.347314
 >> iter 40000, loss: 0.413030
   Number of active neurons: 5
 >> iter 41000, loss: 0.285645
 >> iter 42000, loss: 0.470553
 >> iter 43000, loss: 0.419667
 >> iter 44000, loss: 0.271029
 >> iter 45000, loss: 0.451667
 >> iter 46000, loss: 0.298325
 >> iter 47000, loss: 0.447759
 >> iter 48000, loss: 0.666274
 >> iter 49000, loss: 0.352466
 >> iter 50000, loss: 0.330985
   Number of active neurons: 4
 >> iter 51000, loss: 0.339173
 >> iter 52000, loss: 0.247390
 >> iter 53000, loss: 0.379453
 >> iter 54000, loss: 0.598913
 >> iter 55000, loss: 0.501467
 >> iter 56000, loss: 0.553267
 >> iter 57000, loss: 0.426635
 >> iter 58000, loss: 0.288842
 >> iter 59000, loss: 0.328276
 >> iter 60000, loss: 0.464421
   Number of active neurons: 4
 >> iter 61000, loss: 0.302436
 >> iter 62000, loss: 0.460936
 >> iter 63000, loss: 0.454864
 >> iter 64000, loss: 0.219736
 >> iter 65000, loss: 0.445902
 >> iter 66000, loss: 0.218820
 >> iter 67000, loss: 0.427035
 >> iter 68000, loss: 0.206439
 >> iter 69000, loss: 0.429081
 >> iter 70000, loss: 0.416862
   Number of active neurons: 4
 >> iter 71000, loss: 0.486910
 >> iter 72000, loss: 0.282699
 >> iter 73000, loss: 0.453299
 >> iter 74000, loss: 0.193301
 >> iter 75000, loss: 0.253537
 >> iter 76000, loss: 0.113988
 >> iter 77000, loss: 0.442880
 >> iter 78000, loss: 0.265973
 >> iter 79000, loss: 0.137274
 >> iter 80000, loss: 0.180461
   Number of active neurons: 4
 >> iter 81000, loss: 0.197074
 >> iter 82000, loss: 0.279846
 >> iter 83000, loss: 0.257414
 >> iter 84000, loss: 0.331147
 >> iter 85000, loss: 0.250160
 >> iter 86000, loss: 0.181705
 >> iter 87000, loss: 0.152014
 >> iter 88000, loss: 0.387532
 >> iter 89000, loss: 0.166444
 >> iter 90000, loss: 0.164329
   Number of active neurons: 4
 >> iter 91000, loss: 0.189297
 >> iter 92000, loss: 0.145024
 >> iter 93000, loss: 0.322362
 >> iter 94000, loss: 0.376095
 >> iter 95000, loss: 0.485531
 >> iter 96000, loss: 0.361972
 >> iter 97000, loss: 0.339433
 >> iter 98000, loss: 0.297542
 >> iter 99000, loss: 0.400994
 >> iter 100000, loss: 0.172094
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.019999600008
   - Test - Long: 0.0049997500125
   - Test - Big: 0.0209997900021
   - Test - A: 24.0850609959
   - Test - B: 0.0266648890074
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.383490
 >> iter 2000, loss: 8.353545
 >> iter 3000, loss: 3.153049
 >> iter 4000, loss: 1.458732
 >> iter 5000, loss: 0.751137
 >> iter 6000, loss: 0.439247
 >> iter 7000, loss: 0.244439
 >> iter 8000, loss: 0.586896
 >> iter 9000, loss: 0.306314
 >> iter 10000, loss: 0.136352
   Number of active neurons: 8
 >> iter 11000, loss: 0.107600
 >> iter 12000, loss: 0.226321
 >> iter 13000, loss: 0.121361
 >> iter 14000, loss: 0.163964
 >> iter 15000, loss: 0.082910
 >> iter 16000, loss: 0.375116
 >> iter 17000, loss: 0.166800
 >> iter 18000, loss: 0.143451
 >> iter 19000, loss: 0.151593
 >> iter 20000, loss: 0.107229
   Number of active neurons: 8
 >> iter 21000, loss: 0.153508
 >> iter 22000, loss: 0.084374
 >> iter 23000, loss: 0.049128
 >> iter 24000, loss: 0.088042
 >> iter 25000, loss: 0.116876
 >> iter 26000, loss: 0.096280
 >> iter 27000, loss: 0.058973
 >> iter 28000, loss: 0.140641
 >> iter 29000, loss: 0.130381
 >> iter 30000, loss: 0.165994
   Number of active neurons: 8
 >> iter 31000, loss: 0.100055
 >> iter 32000, loss: 0.090205
 >> iter 33000, loss: 0.096007
 >> iter 34000, loss: 0.142645
 >> iter 35000, loss: 0.083531
 >> iter 36000, loss: 0.157540
 >> iter 37000, loss: 0.228572
 >> iter 38000, loss: 0.157988
 >> iter 39000, loss: 0.105508
 >> iter 40000, loss: 0.224908
   Number of active neurons: 7
 >> iter 41000, loss: 0.191913
 >> iter 42000, loss: 0.153944
 >> iter 43000, loss: 0.359339
 >> iter 44000, loss: 0.169075
 >> iter 45000, loss: 0.150436
 >> iter 46000, loss: 0.096325
 >> iter 47000, loss: 0.104627
 >> iter 48000, loss: 0.299107
 >> iter 49000, loss: 0.135305
 >> iter 50000, loss: 0.167087
   Number of active neurons: 6
 >> iter 51000, loss: 0.409849
 >> iter 52000, loss: 0.177122
 >> iter 53000, loss: 0.141274
 >> iter 54000, loss: 0.104960
 >> iter 55000, loss: 0.108621
 >> iter 56000, loss: 0.123054
 >> iter 57000, loss: 0.428955
 >> iter 58000, loss: 0.183680
 >> iter 59000, loss: 0.138524
 >> iter 60000, loss: 0.436972
   Number of active neurons: 6
 >> iter 61000, loss: 0.225304
 >> iter 62000, loss: 0.133906
 >> iter 63000, loss: 0.236901
 >> iter 64000, loss: 0.125467
 >> iter 65000, loss: 0.103173
 >> iter 66000, loss: 0.084723
 >> iter 67000, loss: 0.077931
 >> iter 68000, loss: 0.100527
 >> iter 69000, loss: 0.154756
 >> iter 70000, loss: 0.167957
   Number of active neurons: 6
 >> iter 71000, loss: 0.274501
 >> iter 72000, loss: 0.178724
 >> iter 73000, loss: 0.320186
 >> iter 74000, loss: 0.158739
 >> iter 75000, loss: 0.249960
 >> iter 76000, loss: 0.148863
 >> iter 77000, loss: 0.342226
 >> iter 78000, loss: 0.294999
 >> iter 79000, loss: 0.378066
 >> iter 80000, loss: 0.568811
   Number of active neurons: 5
 >> iter 81000, loss: 0.655590
 >> iter 82000, loss: 0.275806
 >> iter 83000, loss: 0.299443
 >> iter 84000, loss: 0.275771
 >> iter 85000, loss: 0.124261
 >> iter 86000, loss: 0.290469
 >> iter 87000, loss: 0.129187
 >> iter 88000, loss: 0.178176
 >> iter 89000, loss: 0.085338
 >> iter 90000, loss: 0.303806
   Number of active neurons: 5
 >> iter 91000, loss: 0.132193
 >> iter 92000, loss: 0.296595
 >> iter 93000, loss: 0.346773
 >> iter 94000, loss: 0.424375
 >> iter 95000, loss: 0.183107
 >> iter 96000, loss: 0.158479
 >> iter 97000, loss: 0.326564
 >> iter 98000, loss: 0.318984
 >> iter 99000, loss: 0.222456
 >> iter 100000, loss: 0.217459
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.00599988000241
   - Test - Long: 0.01999900005
   - Test - Big: 0.0269997300027
   - Test - A: 19.3987067529
   - Test - B: 21.0652623158
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.364168
 >> iter 2000, loss: 7.826562
 >> iter 3000, loss: 2.931348
 >> iter 4000, loss: 1.099981
 >> iter 5000, loss: 0.441742
 >> iter 6000, loss: 0.180674
 >> iter 7000, loss: 0.099702
 >> iter 8000, loss: 0.059965
 >> iter 9000, loss: 0.086690
 >> iter 10000, loss: 0.088638
   Number of active neurons: 6
 >> iter 11000, loss: 0.050639
 >> iter 12000, loss: 0.098815
 >> iter 13000, loss: 0.100522
 >> iter 14000, loss: 0.133664
 >> iter 15000, loss: 0.069279
 >> iter 16000, loss: 0.127130
 >> iter 17000, loss: 0.073913
 >> iter 18000, loss: 0.064823
 >> iter 19000, loss: 0.047031
 >> iter 20000, loss: 0.170474
   Number of active neurons: 6
 >> iter 21000, loss: 0.118071
 >> iter 22000, loss: 0.064300
 >> iter 23000, loss: 0.044341
 >> iter 24000, loss: 0.034635
 >> iter 25000, loss: 0.083445
 >> iter 26000, loss: 0.231030
 >> iter 27000, loss: 0.104476
 >> iter 28000, loss: 0.152434
 >> iter 29000, loss: 0.104348
 >> iter 30000, loss: 0.062375
   Number of active neurons: 6
 >> iter 31000, loss: 0.060689
 >> iter 32000, loss: 0.156186
 >> iter 33000, loss: 0.072639
 >> iter 34000, loss: 0.091207
 >> iter 35000, loss: 0.071654
 >> iter 36000, loss: 0.040945
 >> iter 37000, loss: 0.065379
 >> iter 38000, loss: 0.081355
 >> iter 39000, loss: 0.042962
 >> iter 40000, loss: 0.129534
   Number of active neurons: 6
 >> iter 41000, loss: 0.071324
 >> iter 42000, loss: 0.113729
 >> iter 43000, loss: 0.160587
 >> iter 44000, loss: 0.083778
 >> iter 45000, loss: 0.132142
 >> iter 46000, loss: 0.173383
 >> iter 47000, loss: 0.111878
 >> iter 48000, loss: 0.056052
 >> iter 49000, loss: 0.049062
 >> iter 50000, loss: 0.101844
   Number of active neurons: 5
 >> iter 51000, loss: 0.051653
 >> iter 52000, loss: 0.097850
 >> iter 53000, loss: 0.049108
 >> iter 54000, loss: 0.127474
 >> iter 55000, loss: 0.101358
 >> iter 56000, loss: 0.050693
 >> iter 57000, loss: 0.092602
 >> iter 58000, loss: 0.077574
 >> iter 59000, loss: 0.233220
 >> iter 60000, loss: 0.115177
   Number of active neurons: 5
 >> iter 61000, loss: 0.092894
 >> iter 62000, loss: 0.101746
 >> iter 63000, loss: 0.051481
 >> iter 64000, loss: 0.155593
 >> iter 65000, loss: 0.149977
 >> iter 66000, loss: 0.070625
 >> iter 67000, loss: 0.059942
 >> iter 68000, loss: 0.072368
 >> iter 69000, loss: 0.064254
 >> iter 70000, loss: 0.089784
   Number of active neurons: 5
 >> iter 71000, loss: 0.046584
 >> iter 72000, loss: 0.101332
 >> iter 73000, loss: 0.166868
 >> iter 74000, loss: 0.329554
 >> iter 75000, loss: 0.223987
 >> iter 76000, loss: 0.098753
 >> iter 77000, loss: 0.096608
 >> iter 78000, loss: 0.049520
 >> iter 79000, loss: 0.115433
 >> iter 80000, loss: 0.056135
   Number of active neurons: 5
 >> iter 81000, loss: 0.055612
 >> iter 82000, loss: 0.051873
 >> iter 83000, loss: 0.040128
 >> iter 84000, loss: 0.055735
 >> iter 85000, loss: 0.033915
 >> iter 86000, loss: 0.089168
 >> iter 87000, loss: 0.082009
 >> iter 88000, loss: 0.142730
 >> iter 89000, loss: 0.065296
 >> iter 90000, loss: 0.046373
   Number of active neurons: 5
 >> iter 91000, loss: 0.114864
 >> iter 92000, loss: 0.054223
 >> iter 93000, loss: 0.119246
 >> iter 94000, loss: 0.056521
 >> iter 95000, loss: 0.088175
 >> iter 96000, loss: 0.044672
 >> iter 97000, loss: 0.066617
 >> iter 98000, loss: 0.036212
 >> iter 99000, loss: 0.302404
 >> iter 100000, loss: 0.290601
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.019999600008
   - Test - Long: 0.009999500025
   - Test - Big: 0.0159998400016
   - Test - A: 25.0716618892
   - Test - B: 0.00666622225185
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.590273
 >> iter 2000, loss: 9.599153
 >> iter 3000, loss: 3.733471
 >> iter 4000, loss: 1.481477
 >> iter 5000, loss: 0.578974
 >> iter 6000, loss: 0.233102
 >> iter 7000, loss: 0.112995
 >> iter 8000, loss: 0.097778
 >> iter 9000, loss: 0.084073
 >> iter 10000, loss: 0.049839
   Number of active neurons: 10
 >> iter 11000, loss: 0.069860
 >> iter 12000, loss: 0.044365
 >> iter 13000, loss: 0.072102
 >> iter 14000, loss: 0.045072
 >> iter 15000, loss: 0.075293
 >> iter 16000, loss: 0.053489
 >> iter 17000, loss: 0.094988
 >> iter 18000, loss: 0.052448
 >> iter 19000, loss: 0.042005
 >> iter 20000, loss: 0.067907
   Number of active neurons: 8
 >> iter 21000, loss: 0.104348
 >> iter 22000, loss: 0.145834
 >> iter 23000, loss: 0.071936
 >> iter 24000, loss: 0.149521
 >> iter 25000, loss: 0.073678
 >> iter 26000, loss: 0.090122
 >> iter 27000, loss: 0.055053
 >> iter 28000, loss: 0.083590
 >> iter 29000, loss: 0.122847
 >> iter 30000, loss: 0.076050
   Number of active neurons: 7
 >> iter 31000, loss: 0.047292
 >> iter 32000, loss: 0.202782
 >> iter 33000, loss: 0.094001
 >> iter 34000, loss: 0.190045
 >> iter 35000, loss: 0.093295
 >> iter 36000, loss: 0.156554
 >> iter 37000, loss: 0.077524
 >> iter 38000, loss: 0.252933
 >> iter 39000, loss: 0.111349
 >> iter 40000, loss: 0.091329
   Number of active neurons: 6
 >> iter 41000, loss: 0.048590
 >> iter 42000, loss: 0.186084
 >> iter 43000, loss: 0.083853
 >> iter 44000, loss: 0.078959
 >> iter 45000, loss: 0.043031
 >> iter 46000, loss: 0.540726
 >> iter 47000, loss: 0.350192
 >> iter 48000, loss: 0.179565
 >> iter 49000, loss: 0.087659
 >> iter 50000, loss: 0.063551
   Number of active neurons: 5
 >> iter 51000, loss: 0.132657
 >> iter 52000, loss: 0.121033
 >> iter 53000, loss: 0.098042
 >> iter 54000, loss: 0.127519
 >> iter 55000, loss: 0.064544
 >> iter 56000, loss: 0.142747
 >> iter 57000, loss: 0.196021
 >> iter 58000, loss: 0.114286
 >> iter 59000, loss: 0.142152
 >> iter 60000, loss: 0.068833
   Number of active neurons: 5
 >> iter 61000, loss: 0.114144
 >> iter 62000, loss: 0.055768
 >> iter 63000, loss: 0.121619
 >> iter 64000, loss: 0.184089
 >> iter 65000, loss: 0.118882
 >> iter 66000, loss: 0.057365
 >> iter 67000, loss: 0.125024
 >> iter 68000, loss: 0.059687
 >> iter 69000, loss: 0.094325
 >> iter 70000, loss: 0.170668
   Number of active neurons: 5
 >> iter 71000, loss: 0.120028
 >> iter 72000, loss: 0.057795
 >> iter 73000, loss: 0.191289
 >> iter 74000, loss: 0.084870
 >> iter 75000, loss: 0.211840
 >> iter 76000, loss: 0.101571
 >> iter 77000, loss: 0.084043
 >> iter 78000, loss: 0.045094
 >> iter 79000, loss: 0.184708
 >> iter 80000, loss: 0.099785
   Number of active neurons: 5
 >> iter 81000, loss: 0.051018
 >> iter 82000, loss: 0.073533
 >> iter 83000, loss: 0.040093
 >> iter 84000, loss: 0.148832
 >> iter 85000, loss: 0.108433
 >> iter 86000, loss: 0.053086
 >> iter 87000, loss: 0.084374
 >> iter 88000, loss: 0.043072
 >> iter 89000, loss: 0.436729
 >> iter 90000, loss: 0.180173
   Number of active neurons: 5
 >> iter 91000, loss: 0.142026
 >> iter 92000, loss: 0.067300
 >> iter 93000, loss: 0.114559
 >> iter 94000, loss: 0.056399
 >> iter 95000, loss: 0.143005
 >> iter 96000, loss: 0.093232
 >> iter 97000, loss: 0.117992
 >> iter 98000, loss: 0.057369
 >> iter 99000, loss: 0.100375
 >> iter 100000, loss: 0.091886
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.00599988000241
   - Test - Long: 0.0049997500125
   - Test - Big: 0.00999990000101
   - Test - A: 58.1627891474
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.296753
 >> iter 2000, loss: 9.085658
 >> iter 3000, loss: 3.545077
 >> iter 4000, loss: 1.361529
 >> iter 5000, loss: 0.745845
 >> iter 6000, loss: 0.319506
 >> iter 7000, loss: 0.431872
 >> iter 8000, loss: 0.186034
 >> iter 9000, loss: 0.328411
 >> iter 10000, loss: 0.147702
   Number of active neurons: 7
 >> iter 11000, loss: 0.196269
 >> iter 12000, loss: 0.142995
 >> iter 13000, loss: 0.131645
 >> iter 14000, loss: 0.068624
 >> iter 15000, loss: 0.117870
 >> iter 16000, loss: 0.129950
 >> iter 17000, loss: 0.229676
 >> iter 18000, loss: 0.147479
 >> iter 19000, loss: 0.228200
 >> iter 20000, loss: 0.104511
   Number of active neurons: 7
 >> iter 21000, loss: 0.239317
 >> iter 22000, loss: 0.107408
 >> iter 23000, loss: 0.125856
 >> iter 24000, loss: 0.065059
 >> iter 25000, loss: 0.143034
 >> iter 26000, loss: 0.116543
 >> iter 27000, loss: 0.298881
 >> iter 28000, loss: 0.144370
 >> iter 29000, loss: 0.204366
 >> iter 30000, loss: 0.093944
   Number of active neurons: 6
 >> iter 31000, loss: 0.383305
 >> iter 32000, loss: 0.164907
 >> iter 33000, loss: 0.305796
 >> iter 34000, loss: 0.170489
 >> iter 35000, loss: 0.419503
 >> iter 36000, loss: 0.279190
 >> iter 37000, loss: 0.141947
 >> iter 38000, loss: 0.087009
 >> iter 39000, loss: 0.257209
 >> iter 40000, loss: 0.115139
   Number of active neurons: 6
 >> iter 41000, loss: 0.306203
 >> iter 42000, loss: 0.148847
 >> iter 43000, loss: 0.394510
 >> iter 44000, loss: 0.169696
 >> iter 45000, loss: 0.225472
 >> iter 46000, loss: 0.148341
 >> iter 47000, loss: 0.262891
 >> iter 48000, loss: 0.152881
 >> iter 49000, loss: 0.659991
 >> iter 50000, loss: 0.287209
   Number of active neurons: 6
 >> iter 51000, loss: 0.281830
 >> iter 52000, loss: 0.168247
 >> iter 53000, loss: 0.256333
 >> iter 54000, loss: 0.115671
 >> iter 55000, loss: 0.220252
 >> iter 56000, loss: 0.137888
 >> iter 57000, loss: 0.249924
 >> iter 58000, loss: 0.119842
 >> iter 59000, loss: 0.128248
 >> iter 60000, loss: 0.194886
   Number of active neurons: 6
 >> iter 61000, loss: 0.240244
 >> iter 62000, loss: 0.107909
 >> iter 63000, loss: 0.254036
 >> iter 64000, loss: 0.128423
 >> iter 65000, loss: 0.350443
 >> iter 66000, loss: 0.176367
 >> iter 67000, loss: 0.377679
 >> iter 68000, loss: 0.228398
 >> iter 69000, loss: 0.166583
 >> iter 70000, loss: 0.212103
   Number of active neurons: 6
 >> iter 71000, loss: 0.434378
 >> iter 72000, loss: 0.196149
 >> iter 73000, loss: 0.187853
 >> iter 74000, loss: 0.278628
 >> iter 75000, loss: 0.279569
 >> iter 76000, loss: 0.161236
 >> iter 77000, loss: 0.207896
 >> iter 78000, loss: 0.107964
 >> iter 79000, loss: 0.471309
 >> iter 80000, loss: 0.230642
   Number of active neurons: 6
 >> iter 81000, loss: 0.442074
 >> iter 82000, loss: 0.292093
 >> iter 83000, loss: 0.313512
 >> iter 84000, loss: 0.164483
 >> iter 85000, loss: 0.267097
 >> iter 86000, loss: 0.206877
 >> iter 87000, loss: 0.309350
 >> iter 88000, loss: 0.147601
 >> iter 89000, loss: 0.171702
 >> iter 90000, loss: 0.119441
   Number of active neurons: 5
 >> iter 91000, loss: 0.573430
 >> iter 92000, loss: 0.697384
 >> iter 93000, loss: 0.536121
 >> iter 94000, loss: 0.341980
 >> iter 95000, loss: 0.162002
 >> iter 96000, loss: 0.102597
 >> iter 97000, loss: 0.097508
 >> iter 98000, loss: 0.051532
 >> iter 99000, loss: 0.121098
 >> iter 100000, loss: 0.212666
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0039999600004
   - Test - A: 0.0
   - Test - B: 19.4587027531

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

