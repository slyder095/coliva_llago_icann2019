 > Problema: tomita1nueva
 > Args:
   - Hidden size: 4
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.906975
 >> iter 2000, loss: 4.056482
 >> iter 3000, loss: 1.521865
 >> iter 4000, loss: 0.577015
 >> iter 5000, loss: 0.234633
 >> iter 6000, loss: 0.104181
 >> iter 7000, loss: 0.053761
 >> iter 8000, loss: 0.034130
 >> iter 9000, loss: 0.027747
 >> iter 10000, loss: 0.025923
   Number of active neurons: 3
 >> iter 11000, loss: 0.028452
 >> iter 12000, loss: 0.025688
 >> iter 13000, loss: 0.023987
 >> iter 14000, loss: 0.026397
 >> iter 15000, loss: 0.031239
 >> iter 16000, loss: 0.029292
 >> iter 17000, loss: 0.031384
 >> iter 18000, loss: 0.030582
 >> iter 19000, loss: 0.026329
 >> iter 20000, loss: 0.039251
   Number of active neurons: 3
 >> iter 21000, loss: 0.029849
 >> iter 22000, loss: 0.025167
 >> iter 23000, loss: 0.023210
 >> iter 24000, loss: 0.026864
 >> iter 25000, loss: 0.026346
 >> iter 26000, loss: 0.025438
 >> iter 27000, loss: 0.026545
 >> iter 28000, loss: 0.023629
 >> iter 29000, loss: 0.023968
 >> iter 30000, loss: 0.041930
   Number of active neurons: 3
 >> iter 31000, loss: 0.035750
 >> iter 32000, loss: 0.027375
 >> iter 33000, loss: 0.025040
 >> iter 34000, loss: 0.027275
 >> iter 35000, loss: 0.025650
 >> iter 36000, loss: 0.023811
 >> iter 37000, loss: 0.023615
 >> iter 38000, loss: 0.022976
 >> iter 39000, loss: 0.021512
 >> iter 40000, loss: 0.020540
   Number of active neurons: 2
 >> iter 41000, loss: 0.022870
 >> iter 42000, loss: 0.035299
 >> iter 43000, loss: 0.025873
 >> iter 44000, loss: 0.029190
 >> iter 45000, loss: 0.024068
 >> iter 46000, loss: 0.020515
 >> iter 47000, loss: 0.019600
 >> iter 48000, loss: 0.021065
 >> iter 49000, loss: 0.026352
 >> iter 50000, loss: 0.026805
   Number of active neurons: 2
 >> iter 51000, loss: 0.024303
 >> iter 52000, loss: 0.023203
 >> iter 53000, loss: 0.022552
 >> iter 54000, loss: 0.022251
 >> iter 55000, loss: 0.019268
 >> iter 56000, loss: 0.020313
 >> iter 57000, loss: 0.022678
 >> iter 58000, loss: 0.020168
 >> iter 59000, loss: 0.021151
 >> iter 60000, loss: 0.025039
   Number of active neurons: 2
 >> iter 61000, loss: 0.022763
 >> iter 62000, loss: 0.024442
 >> iter 63000, loss: 0.024929
 >> iter 64000, loss: 0.022876
 >> iter 65000, loss: 0.022661
 >> iter 66000, loss: 0.020895
 >> iter 67000, loss: 0.030862
 >> iter 68000, loss: 0.026430
 >> iter 69000, loss: 0.037564
 >> iter 70000, loss: 0.035158
   Number of active neurons: 2
 >> iter 71000, loss: 0.026676
 >> iter 72000, loss: 0.023952
 >> iter 73000, loss: 0.029117
 >> iter 74000, loss: 0.023972
 >> iter 75000, loss: 0.022148
 >> iter 76000, loss: 0.022324
 >> iter 77000, loss: 0.024210
 >> iter 78000, loss: 0.020492
 >> iter 79000, loss: 0.032098
 >> iter 80000, loss: 0.025541
   Number of active neurons: 2
 >> iter 81000, loss: 0.021949
 >> iter 82000, loss: 0.021723
 >> iter 83000, loss: 0.022752
 >> iter 84000, loss: 0.024101
 >> iter 85000, loss: 0.023870
 >> iter 86000, loss: 0.022205
 >> iter 87000, loss: 0.023679
 >> iter 88000, loss: 0.021618
 >> iter 89000, loss: 0.021857
 >> iter 90000, loss: 0.026848
   Number of active neurons: 2
 >> iter 91000, loss: 0.024830
 >> iter 92000, loss: 0.032424
 >> iter 93000, loss: 0.024374
 >> iter 94000, loss: 0.024075
 >> iter 95000, loss: 0.023829
 >> iter 96000, loss: 0.023464
 >> iter 97000, loss: 0.032993
 >> iter 98000, loss: 0.028119
 >> iter 99000, loss: 0.023754
 >> iter 100000, loss: 0.021711
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.965784
 >> iter 2000, loss: 4.072600
 >> iter 3000, loss: 1.557395
 >> iter 4000, loss: 0.593998
 >> iter 5000, loss: 0.236387
 >> iter 6000, loss: 0.103396
 >> iter 7000, loss: 0.053763
 >> iter 8000, loss: 0.037716
 >> iter 9000, loss: 0.031917
 >> iter 10000, loss: 0.028850
   Number of active neurons: 3
 >> iter 11000, loss: 0.040498
 >> iter 12000, loss: 0.043570
 >> iter 13000, loss: 0.031314
 >> iter 14000, loss: 0.027453
 >> iter 15000, loss: 0.039384
 >> iter 16000, loss: 0.028495
 >> iter 17000, loss: 0.025727
 >> iter 18000, loss: 0.033710
 >> iter 19000, loss: 0.027416
 >> iter 20000, loss: 0.023107
   Number of active neurons: 2
 >> iter 21000, loss: 0.023227
 >> iter 22000, loss: 0.023360
 >> iter 23000, loss: 0.033486
 >> iter 24000, loss: 0.025911
 >> iter 25000, loss: 0.027852
 >> iter 26000, loss: 0.022195
 >> iter 27000, loss: 0.021979
 >> iter 28000, loss: 0.022428
 >> iter 29000, loss: 0.032157
 >> iter 30000, loss: 0.027680
   Number of active neurons: 2
 >> iter 31000, loss: 0.022557
 >> iter 32000, loss: 0.025867
 >> iter 33000, loss: 0.026739
 >> iter 34000, loss: 0.023595
 >> iter 35000, loss: 0.034106
 >> iter 36000, loss: 0.035397
 >> iter 37000, loss: 0.032057
 >> iter 38000, loss: 0.029842
 >> iter 39000, loss: 0.025471
 >> iter 40000, loss: 0.022038
   Number of active neurons: 2
 >> iter 41000, loss: 0.023633
 >> iter 42000, loss: 0.044966
 >> iter 43000, loss: 0.030738
 >> iter 44000, loss: 0.024693
 >> iter 45000, loss: 0.021421
 >> iter 46000, loss: 0.026615
 >> iter 47000, loss: 0.024777
 >> iter 48000, loss: 0.023100
 >> iter 49000, loss: 0.021245
 >> iter 50000, loss: 0.021987
   Number of active neurons: 2
 >> iter 51000, loss: 0.028083
 >> iter 52000, loss: 0.022479
 >> iter 53000, loss: 0.032004
 >> iter 54000, loss: 0.026757
 >> iter 55000, loss: 0.025071
 >> iter 56000, loss: 0.034812
 >> iter 57000, loss: 0.025452
 >> iter 58000, loss: 0.025446
 >> iter 59000, loss: 0.042684
 >> iter 60000, loss: 0.037564
   Number of active neurons: 1
 >> iter 61000, loss: 0.036145
 >> iter 62000, loss: 0.025474
 >> iter 63000, loss: 0.027775
 >> iter 64000, loss: 0.034842
 >> iter 65000, loss: 0.040078
 >> iter 66000, loss: 0.028034
 >> iter 67000, loss: 0.019843
 >> iter 68000, loss: 0.018205
 >> iter 69000, loss: 0.020716
 >> iter 70000, loss: 0.037140
   Number of active neurons: 1
 >> iter 71000, loss: 0.052097
 >> iter 72000, loss: 0.032380
 >> iter 73000, loss: 0.022873
 >> iter 74000, loss: 0.020907
 >> iter 75000, loss: 0.023359
 >> iter 76000, loss: 0.019936
 >> iter 77000, loss: 0.018635
 >> iter 78000, loss: 0.019690
 >> iter 79000, loss: 0.019985
 >> iter 80000, loss: 0.024637
   Number of active neurons: 1
 >> iter 81000, loss: 0.039530
 >> iter 82000, loss: 0.028151
 >> iter 83000, loss: 0.027376
 >> iter 84000, loss: 0.025007
 >> iter 85000, loss: 0.021174
 >> iter 86000, loss: 0.019713
 >> iter 87000, loss: 0.017023
 >> iter 88000, loss: 0.043065
 >> iter 89000, loss: 0.031051
 >> iter 90000, loss: 0.023573
   Number of active neurons: 1
 >> iter 91000, loss: 0.024949
 >> iter 92000, loss: 0.024177
 >> iter 93000, loss: 0.021142
 >> iter 94000, loss: 0.026587
 >> iter 95000, loss: 0.030486
 >> iter 96000, loss: 0.022289
 >> iter 97000, loss: 0.020581
 >> iter 98000, loss: 0.017068
 >> iter 99000, loss: 0.019345
 >> iter 100000, loss: 0.022985
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.054530
 >> iter 2000, loss: 4.108480
 >> iter 3000, loss: 1.533574
 >> iter 4000, loss: 0.593117
 >> iter 5000, loss: 0.263456
 >> iter 6000, loss: 0.114484
 >> iter 7000, loss: 0.057261
 >> iter 8000, loss: 0.035260
 >> iter 9000, loss: 0.032916
 >> iter 10000, loss: 0.026170
   Number of active neurons: 2
 >> iter 11000, loss: 0.022132
 >> iter 12000, loss: 0.028852
 >> iter 13000, loss: 0.025679
 >> iter 14000, loss: 0.021755
 >> iter 15000, loss: 0.023452
 >> iter 16000, loss: 0.020902
 >> iter 17000, loss: 0.026862
 >> iter 18000, loss: 0.053929
 >> iter 19000, loss: 0.049122
 >> iter 20000, loss: 0.045333
   Number of active neurons: 2
 >> iter 21000, loss: 0.029357
 >> iter 22000, loss: 0.023406
 >> iter 23000, loss: 0.049444
 >> iter 24000, loss: 0.043951
 >> iter 25000, loss: 0.031961
 >> iter 26000, loss: 0.027813
 >> iter 27000, loss: 0.026520
 >> iter 28000, loss: 0.026391
 >> iter 29000, loss: 0.025905
 >> iter 30000, loss: 0.026450
   Number of active neurons: 2
 >> iter 31000, loss: 0.028642
 >> iter 32000, loss: 0.023539
 >> iter 33000, loss: 0.045527
 >> iter 34000, loss: 0.032230
 >> iter 35000, loss: 0.025078
 >> iter 36000, loss: 0.040800
 >> iter 37000, loss: 0.030465
 >> iter 38000, loss: 0.033241
 >> iter 39000, loss: 0.035248
 >> iter 40000, loss: 0.026217
   Number of active neurons: 2
 >> iter 41000, loss: 0.031569
 >> iter 42000, loss: 0.025981
 >> iter 43000, loss: 0.024496
 >> iter 44000, loss: 0.021876
 >> iter 45000, loss: 0.034977
 >> iter 46000, loss: 0.027521
 >> iter 47000, loss: 0.021691
 >> iter 48000, loss: 0.022771
 >> iter 49000, loss: 0.023528
 >> iter 50000, loss: 0.022206
   Number of active neurons: 1
 >> iter 51000, loss: 0.018669
 >> iter 52000, loss: 0.019795
 >> iter 53000, loss: 0.017417
 >> iter 54000, loss: 0.016292
 >> iter 55000, loss: 0.016476
 >> iter 56000, loss: 0.020574
 >> iter 57000, loss: 0.022776
 >> iter 58000, loss: 0.018384
 >> iter 59000, loss: 0.020208
 >> iter 60000, loss: 0.018303
   Number of active neurons: 1
 >> iter 61000, loss: 0.018696
 >> iter 62000, loss: 0.018489
 >> iter 63000, loss: 0.018948
 >> iter 64000, loss: 0.028755
 >> iter 65000, loss: 0.019965
 >> iter 66000, loss: 0.019219
 >> iter 67000, loss: 0.017271
 >> iter 68000, loss: 0.021146
 >> iter 69000, loss: 0.018900
 >> iter 70000, loss: 0.019274
   Number of active neurons: 1
 >> iter 71000, loss: 0.018105
 >> iter 72000, loss: 0.016500
 >> iter 73000, loss: 0.024090
 >> iter 74000, loss: 0.019658
 >> iter 75000, loss: 0.017065
 >> iter 76000, loss: 0.017329
 >> iter 77000, loss: 0.016362
 >> iter 78000, loss: 0.023260
 >> iter 79000, loss: 0.019068
 >> iter 80000, loss: 0.020274
   Number of active neurons: 1
 >> iter 81000, loss: 0.018173
 >> iter 82000, loss: 0.020041
 >> iter 83000, loss: 0.027327
 >> iter 84000, loss: 0.030071
 >> iter 85000, loss: 0.021963
 >> iter 86000, loss: 0.018792
 >> iter 87000, loss: 0.018048
 >> iter 88000, loss: 0.019591
 >> iter 89000, loss: 0.041930
 >> iter 90000, loss: 0.026168
   Number of active neurons: 1
 >> iter 91000, loss: 0.035650
 >> iter 92000, loss: 0.025927
 >> iter 93000, loss: 0.023845
 >> iter 94000, loss: 0.022747
 >> iter 95000, loss: 0.018826
 >> iter 96000, loss: 0.019511
 >> iter 97000, loss: 0.019305
 >> iter 98000, loss: 0.015936
 >> iter 99000, loss: 0.016001
 >> iter 100000, loss: 0.018590
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.996558
 >> iter 2000, loss: 4.087107
 >> iter 3000, loss: 1.537111
 >> iter 4000, loss: 0.583502
 >> iter 5000, loss: 0.236512
 >> iter 6000, loss: 0.122006
 >> iter 7000, loss: 0.070473
 >> iter 8000, loss: 0.044433
 >> iter 9000, loss: 0.036123
 >> iter 10000, loss: 0.035087
   Number of active neurons: 2
 >> iter 11000, loss: 0.032211
 >> iter 12000, loss: 0.043873
 >> iter 13000, loss: 0.031000
 >> iter 14000, loss: 0.025540
 >> iter 15000, loss: 0.029267
 >> iter 16000, loss: 0.052918
 >> iter 17000, loss: 0.036956
 >> iter 18000, loss: 0.031588
 >> iter 19000, loss: 0.035518
 >> iter 20000, loss: 0.035639
   Number of active neurons: 2
 >> iter 21000, loss: 0.028171
 >> iter 22000, loss: 0.022405
 >> iter 23000, loss: 0.031378
 >> iter 24000, loss: 0.023236
 >> iter 25000, loss: 0.033122
 >> iter 26000, loss: 0.025211
 >> iter 27000, loss: 0.023790
 >> iter 28000, loss: 0.024238
 >> iter 29000, loss: 0.028208
 >> iter 30000, loss: 0.043408
   Number of active neurons: 2
 >> iter 31000, loss: 0.030214
 >> iter 32000, loss: 0.027823
 >> iter 33000, loss: 0.026583
 >> iter 34000, loss: 0.022278
 >> iter 35000, loss: 0.026168
 >> iter 36000, loss: 0.025485
 >> iter 37000, loss: 0.022140
 >> iter 38000, loss: 0.021423
 >> iter 39000, loss: 0.023734
 >> iter 40000, loss: 0.028132
   Number of active neurons: 2
 >> iter 41000, loss: 0.029238
 >> iter 42000, loss: 0.024825
 >> iter 43000, loss: 0.041180
 >> iter 44000, loss: 0.034611
 >> iter 45000, loss: 0.025904
 >> iter 46000, loss: 0.022995
 >> iter 47000, loss: 0.024707
 >> iter 48000, loss: 0.036556
 >> iter 49000, loss: 0.033985
 >> iter 50000, loss: 0.025064
   Number of active neurons: 1
 >> iter 51000, loss: 0.023847
 >> iter 52000, loss: 0.024243
 >> iter 53000, loss: 0.024563
 >> iter 54000, loss: 0.029887
 >> iter 55000, loss: 0.024551
 >> iter 56000, loss: 0.022799
 >> iter 57000, loss: 0.024007
 >> iter 58000, loss: 0.019993
 >> iter 59000, loss: 0.017927
 >> iter 60000, loss: 0.028024
   Number of active neurons: 1
 >> iter 61000, loss: 0.022340
 >> iter 62000, loss: 0.018678
 >> iter 63000, loss: 0.019796
 >> iter 64000, loss: 0.020372
 >> iter 65000, loss: 0.018342
 >> iter 66000, loss: 0.018706
 >> iter 67000, loss: 0.024588
 >> iter 68000, loss: 0.019728
 >> iter 69000, loss: 0.019260
 >> iter 70000, loss: 0.018836
   Number of active neurons: 1
 >> iter 71000, loss: 0.026723
 >> iter 72000, loss: 0.032525
 >> iter 73000, loss: 0.021233
 >> iter 74000, loss: 0.019180
 >> iter 75000, loss: 0.030927
 >> iter 76000, loss: 0.021859
 >> iter 77000, loss: 0.021786
 >> iter 78000, loss: 0.020658
 >> iter 79000, loss: 0.029540
 >> iter 80000, loss: 0.023441
   Number of active neurons: 1
 >> iter 81000, loss: 0.020259
 >> iter 82000, loss: 0.018560
 >> iter 83000, loss: 0.016425
 >> iter 84000, loss: 0.024884
 >> iter 85000, loss: 0.019782
 >> iter 86000, loss: 0.017689
 >> iter 87000, loss: 0.017332
 >> iter 88000, loss: 0.016077
 >> iter 89000, loss: 0.022708
 >> iter 90000, loss: 0.018936
   Number of active neurons: 1
 >> iter 91000, loss: 0.017433
 >> iter 92000, loss: 0.020188
 >> iter 93000, loss: 0.018161
 >> iter 94000, loss: 0.019168
 >> iter 95000, loss: 0.018681
 >> iter 96000, loss: 0.019762
 >> iter 97000, loss: 0.017695
 >> iter 98000, loss: 0.018863
 >> iter 99000, loss: 0.017806
 >> iter 100000, loss: 0.019310
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.950659
 >> iter 2000, loss: 4.064438
 >> iter 3000, loss: 1.519637
 >> iter 4000, loss: 0.578630
 >> iter 5000, loss: 0.254985
 >> iter 6000, loss: 0.107558
 >> iter 7000, loss: 0.062286
 >> iter 8000, loss: 0.046006
 >> iter 9000, loss: 0.033290
 >> iter 10000, loss: 0.030375
   Number of active neurons: 4
 >> iter 11000, loss: 0.031745
 >> iter 12000, loss: 0.026405
 >> iter 13000, loss: 0.029032
 >> iter 14000, loss: 0.029444
 >> iter 15000, loss: 0.026106
 >> iter 16000, loss: 0.027724
 >> iter 17000, loss: 0.027449
 >> iter 18000, loss: 0.036816
 >> iter 19000, loss: 0.030565
 >> iter 20000, loss: 0.028684
   Number of active neurons: 4
 >> iter 21000, loss: 0.027865
 >> iter 22000, loss: 0.033442
 >> iter 23000, loss: 0.030687
 >> iter 24000, loss: 0.030195
 >> iter 25000, loss: 0.026085
 >> iter 26000, loss: 0.024680
 >> iter 27000, loss: 0.025447
 >> iter 28000, loss: 0.024763
 >> iter 29000, loss: 0.023892
 >> iter 30000, loss: 0.042229
   Number of active neurons: 4
 >> iter 31000, loss: 0.031451
 >> iter 32000, loss: 0.028893
 >> iter 33000, loss: 0.034175
 >> iter 34000, loss: 0.027633
 >> iter 35000, loss: 0.025854
 >> iter 36000, loss: 0.024599
 >> iter 37000, loss: 0.029581
 >> iter 38000, loss: 0.026717
 >> iter 39000, loss: 0.039488
 >> iter 40000, loss: 0.038967
   Number of active neurons: 3
 >> iter 41000, loss: 0.030528
 >> iter 42000, loss: 0.025666
 >> iter 43000, loss: 0.024256
 >> iter 44000, loss: 0.024104
 >> iter 45000, loss: 0.023966
 >> iter 46000, loss: 0.032105
 >> iter 47000, loss: 0.038987
 >> iter 48000, loss: 0.027184
 >> iter 49000, loss: 0.034374
 >> iter 50000, loss: 0.026560
   Number of active neurons: 3
 >> iter 51000, loss: 0.023779
 >> iter 52000, loss: 0.026601
 >> iter 53000, loss: 0.029856
 >> iter 54000, loss: 0.029435
 >> iter 55000, loss: 0.028937
 >> iter 56000, loss: 0.026875
 >> iter 57000, loss: 0.025473
 >> iter 58000, loss: 0.022898
 >> iter 59000, loss: 0.024508
 >> iter 60000, loss: 0.024613
   Number of active neurons: 2
 >> iter 61000, loss: 0.029205
 >> iter 62000, loss: 0.026828
 >> iter 63000, loss: 0.023084
 >> iter 64000, loss: 0.022052
 >> iter 65000, loss: 0.020928
 >> iter 66000, loss: 0.027161
 >> iter 67000, loss: 0.026588
 >> iter 68000, loss: 0.022087
 >> iter 69000, loss: 0.034195
 >> iter 70000, loss: 0.027609
   Number of active neurons: 2
 >> iter 71000, loss: 0.023504
 >> iter 72000, loss: 0.021096
 >> iter 73000, loss: 0.024795
 >> iter 74000, loss: 0.024852
 >> iter 75000, loss: 0.027200
 >> iter 76000, loss: 0.023762
 >> iter 77000, loss: 0.038530
 >> iter 78000, loss: 0.041309
 >> iter 79000, loss: 0.031157
 >> iter 80000, loss: 0.029863
   Number of active neurons: 2
 >> iter 81000, loss: 0.028992
 >> iter 82000, loss: 0.023249
 >> iter 83000, loss: 0.025616
 >> iter 84000, loss: 0.022666
 >> iter 85000, loss: 0.021924
 >> iter 86000, loss: 0.021672
 >> iter 87000, loss: 0.019387
 >> iter 88000, loss: 0.027249
 >> iter 89000, loss: 0.026696
 >> iter 90000, loss: 0.023770
   Number of active neurons: 2
 >> iter 91000, loss: 0.028981
 >> iter 92000, loss: 0.023983
 >> iter 93000, loss: 0.021550
 >> iter 94000, loss: 0.020198
 >> iter 95000, loss: 0.024188
 >> iter 96000, loss: 0.036337
 >> iter 97000, loss: 0.026137
 >> iter 98000, loss: 0.024283
 >> iter 99000, loss: 0.038698
 >> iter 100000, loss: 0.028765
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.968741
 >> iter 2000, loss: 4.065815
 >> iter 3000, loss: 1.519855
 >> iter 4000, loss: 0.578951
 >> iter 5000, loss: 0.232952
 >> iter 6000, loss: 0.110576
 >> iter 7000, loss: 0.056813
 >> iter 8000, loss: 0.048491
 >> iter 9000, loss: 0.032141
 >> iter 10000, loss: 0.032647
   Number of active neurons: 3
 >> iter 11000, loss: 0.041012
 >> iter 12000, loss: 0.030847
 >> iter 13000, loss: 0.028416
 >> iter 14000, loss: 0.026134
 >> iter 15000, loss: 0.041996
 >> iter 16000, loss: 0.031662
 >> iter 17000, loss: 0.026093
 >> iter 18000, loss: 0.024217
 >> iter 19000, loss: 0.034164
 >> iter 20000, loss: 0.034158
   Number of active neurons: 3
 >> iter 21000, loss: 0.027167
 >> iter 22000, loss: 0.037891
 >> iter 23000, loss: 0.030295
 >> iter 24000, loss: 0.027964
 >> iter 25000, loss: 0.024375
 >> iter 26000, loss: 0.028331
 >> iter 27000, loss: 0.023616
 >> iter 28000, loss: 0.021365
 >> iter 29000, loss: 0.028126
 >> iter 30000, loss: 0.024300
   Number of active neurons: 2
 >> iter 31000, loss: 0.023455
 >> iter 32000, loss: 0.022205
 >> iter 33000, loss: 0.020557
 >> iter 34000, loss: 0.022086
 >> iter 35000, loss: 0.025972
 >> iter 36000, loss: 0.039583
 >> iter 37000, loss: 0.030672
 >> iter 38000, loss: 0.028153
 >> iter 39000, loss: 0.021622
 >> iter 40000, loss: 0.022337
   Number of active neurons: 1
 >> iter 41000, loss: 0.053611
 >> iter 42000, loss: 0.033007
 >> iter 43000, loss: 0.024178
 >> iter 44000, loss: 0.021595
 >> iter 45000, loss: 0.025965
 >> iter 46000, loss: 0.021808
 >> iter 47000, loss: 0.019077
 >> iter 48000, loss: 0.017511
 >> iter 49000, loss: 0.026601
 >> iter 50000, loss: 0.024814
   Number of active neurons: 1
 >> iter 51000, loss: 0.022185
 >> iter 52000, loss: 0.021525
 >> iter 53000, loss: 0.018229
 >> iter 54000, loss: 0.023462
 >> iter 55000, loss: 0.020134
 >> iter 56000, loss: 0.018770
 >> iter 57000, loss: 0.020899
 >> iter 58000, loss: 0.018261
 >> iter 59000, loss: 0.015610
 >> iter 60000, loss: 0.017779
   Number of active neurons: 1
 >> iter 61000, loss: 0.020015
 >> iter 62000, loss: 0.042351
 >> iter 63000, loss: 0.027974
 >> iter 64000, loss: 0.025088
 >> iter 65000, loss: 0.034700
 >> iter 66000, loss: 0.024525
 >> iter 67000, loss: 0.028747
 >> iter 68000, loss: 0.026528
 >> iter 69000, loss: 0.030548
 >> iter 70000, loss: 0.025657
   Number of active neurons: 1
 >> iter 71000, loss: 0.020764
 >> iter 72000, loss: 0.026173
 >> iter 73000, loss: 0.021188
 >> iter 74000, loss: 0.021083
 >> iter 75000, loss: 0.017904
 >> iter 76000, loss: 0.018419
 >> iter 77000, loss: 0.030560
 >> iter 78000, loss: 0.023629
 >> iter 79000, loss: 0.019602
 >> iter 80000, loss: 0.019789
   Number of active neurons: 1
 >> iter 81000, loss: 0.037934
 >> iter 82000, loss: 0.026795
 >> iter 83000, loss: 0.019103
 >> iter 84000, loss: 0.019121
 >> iter 85000, loss: 0.020563
 >> iter 86000, loss: 0.018861
 >> iter 87000, loss: 0.019407
 >> iter 88000, loss: 0.024113
 >> iter 89000, loss: 0.018846
 >> iter 90000, loss: 0.019267
   Number of active neurons: 1
 >> iter 91000, loss: 0.019102
 >> iter 92000, loss: 0.034632
 >> iter 93000, loss: 0.025469
 >> iter 94000, loss: 0.034114
 >> iter 95000, loss: 0.022316
 >> iter 96000, loss: 0.023836
 >> iter 97000, loss: 0.019211
 >> iter 98000, loss: 0.019298
 >> iter 99000, loss: 0.024567
 >> iter 100000, loss: 0.057291
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.987541
 >> iter 2000, loss: 4.087778
 >> iter 3000, loss: 1.535250
 >> iter 4000, loss: 0.609169
 >> iter 5000, loss: 0.257752
 >> iter 6000, loss: 0.111662
 >> iter 7000, loss: 0.061105
 >> iter 8000, loss: 0.037241
 >> iter 9000, loss: 0.029086
 >> iter 10000, loss: 0.026273
   Number of active neurons: 2
 >> iter 11000, loss: 0.022292
 >> iter 12000, loss: 0.021574
 >> iter 13000, loss: 0.038020
 >> iter 14000, loss: 0.026922
 >> iter 15000, loss: 0.024165
 >> iter 16000, loss: 0.020159
 >> iter 17000, loss: 0.024496
 >> iter 18000, loss: 0.023026
 >> iter 19000, loss: 0.021399
 >> iter 20000, loss: 0.019975
   Number of active neurons: 2
 >> iter 21000, loss: 0.020296
 >> iter 22000, loss: 0.020113
 >> iter 23000, loss: 0.029330
 >> iter 24000, loss: 0.039683
 >> iter 25000, loss: 0.029552
 >> iter 26000, loss: 0.032864
 >> iter 27000, loss: 0.027277
 >> iter 28000, loss: 0.027648
 >> iter 29000, loss: 0.041119
 >> iter 30000, loss: 0.044628
   Number of active neurons: 2
 >> iter 31000, loss: 0.029118
 >> iter 32000, loss: 0.030464
 >> iter 33000, loss: 0.024740
 >> iter 34000, loss: 0.034369
 >> iter 35000, loss: 0.028756
 >> iter 36000, loss: 0.026786
 >> iter 37000, loss: 0.023485
 >> iter 38000, loss: 0.021824
 >> iter 39000, loss: 0.024103
 >> iter 40000, loss: 0.031951
   Number of active neurons: 2
 >> iter 41000, loss: 0.031414
 >> iter 42000, loss: 0.025602
 >> iter 43000, loss: 0.026716
 >> iter 44000, loss: 0.026899
 >> iter 45000, loss: 0.022478
 >> iter 46000, loss: 0.024575
 >> iter 47000, loss: 0.036866
 >> iter 48000, loss: 0.051998
 >> iter 49000, loss: 0.032578
 >> iter 50000, loss: 0.027438
   Number of active neurons: 2
 >> iter 51000, loss: 0.024606
 >> iter 52000, loss: 0.039143
 >> iter 53000, loss: 0.027398
 >> iter 54000, loss: 0.025381
 >> iter 55000, loss: 0.057228
 >> iter 56000, loss: 0.036281
 >> iter 57000, loss: 0.028333
 >> iter 58000, loss: 0.041012
 >> iter 59000, loss: 0.034572
 >> iter 60000, loss: 0.025757
   Number of active neurons: 2
 >> iter 61000, loss: 0.022633
 >> iter 62000, loss: 0.024115
 >> iter 63000, loss: 0.028673
 >> iter 64000, loss: 0.024117
 >> iter 65000, loss: 0.029776
 >> iter 66000, loss: 0.027954
 >> iter 67000, loss: 0.028733
 >> iter 68000, loss: 0.023944
 >> iter 69000, loss: 0.023289
 >> iter 70000, loss: 0.021071
   Number of active neurons: 1
 >> iter 71000, loss: 0.026038
 >> iter 72000, loss: 0.030540
 >> iter 73000, loss: 0.026074
 >> iter 74000, loss: 0.023291
 >> iter 75000, loss: 0.019252
 >> iter 76000, loss: 0.020131
 >> iter 77000, loss: 0.020304
 >> iter 78000, loss: 0.028767
 >> iter 79000, loss: 0.026928
 >> iter 80000, loss: 0.027419
   Number of active neurons: 1
 >> iter 81000, loss: 0.023462
 >> iter 82000, loss: 0.018793
 >> iter 83000, loss: 0.019067
 >> iter 84000, loss: 0.033912
 >> iter 85000, loss: 0.022998
 >> iter 86000, loss: 0.028499
 >> iter 87000, loss: 0.037626
 >> iter 88000, loss: 0.025440
 >> iter 89000, loss: 0.023149
 >> iter 90000, loss: 0.019151
   Number of active neurons: 1
 >> iter 91000, loss: 0.022362
 >> iter 92000, loss: 0.031958
 >> iter 93000, loss: 0.022661
 >> iter 94000, loss: 0.019476
 >> iter 95000, loss: 0.017517
 >> iter 96000, loss: 0.043628
 >> iter 97000, loss: 0.026083
 >> iter 98000, loss: 0.023513
 >> iter 99000, loss: 0.021034
 >> iter 100000, loss: 0.023359
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.930373
 >> iter 2000, loss: 4.051658
 >> iter 3000, loss: 1.525117
 >> iter 4000, loss: 0.583702
 >> iter 5000, loss: 0.234090
 >> iter 6000, loss: 0.101665
 >> iter 7000, loss: 0.065506
 >> iter 8000, loss: 0.036287
 >> iter 9000, loss: 0.035285
 >> iter 10000, loss: 0.038503
   Number of active neurons: 2
 >> iter 11000, loss: 0.051895
 >> iter 12000, loss: 0.044363
 >> iter 13000, loss: 0.031766
 >> iter 14000, loss: 0.024221
 >> iter 15000, loss: 0.032263
 >> iter 16000, loss: 0.026939
 >> iter 17000, loss: 0.025516
 >> iter 18000, loss: 0.021078
 >> iter 19000, loss: 0.024977
 >> iter 20000, loss: 0.021212
   Number of active neurons: 2
 >> iter 21000, loss: 0.022903
 >> iter 22000, loss: 0.021375
 >> iter 23000, loss: 0.021369
 >> iter 24000, loss: 0.020234
 >> iter 25000, loss: 0.022082
 >> iter 26000, loss: 0.020962
 >> iter 27000, loss: 0.019614
 >> iter 28000, loss: 0.022930
 >> iter 29000, loss: 0.024510
 >> iter 30000, loss: 0.021650
   Number of active neurons: 2
 >> iter 31000, loss: 0.028682
 >> iter 32000, loss: 0.050739
 >> iter 33000, loss: 0.048872
 >> iter 34000, loss: 0.030637
 >> iter 35000, loss: 0.024961
 >> iter 36000, loss: 0.026630
 >> iter 37000, loss: 0.036560
 >> iter 38000, loss: 0.026210
 >> iter 39000, loss: 0.029315
 >> iter 40000, loss: 0.026281
   Number of active neurons: 2
 >> iter 41000, loss: 0.022695
 >> iter 42000, loss: 0.029801
 >> iter 43000, loss: 0.025447
 >> iter 44000, loss: 0.023805
 >> iter 45000, loss: 0.023697
 >> iter 46000, loss: 0.021037
 >> iter 47000, loss: 0.023307
 >> iter 48000, loss: 0.024986
 >> iter 49000, loss: 0.021860
 >> iter 50000, loss: 0.022370
   Number of active neurons: 2
 >> iter 51000, loss: 0.025180
 >> iter 52000, loss: 0.022469
 >> iter 53000, loss: 0.078329
 >> iter 54000, loss: 0.042023
 >> iter 55000, loss: 0.029176
 >> iter 56000, loss: 0.027275
 >> iter 57000, loss: 0.023185
 >> iter 58000, loss: 0.033413
 >> iter 59000, loss: 0.024876
 >> iter 60000, loss: 0.025634
   Number of active neurons: 2
 >> iter 61000, loss: 0.024312
 >> iter 62000, loss: 0.035398
 >> iter 63000, loss: 0.034119
 >> iter 64000, loss: 0.026035
 >> iter 65000, loss: 0.032288
 >> iter 66000, loss: 0.025964
 >> iter 67000, loss: 0.024351
 >> iter 68000, loss: 0.022446
 >> iter 69000, loss: 0.025608
 >> iter 70000, loss: 0.030219
   Number of active neurons: 2
 >> iter 71000, loss: 0.026526
 >> iter 72000, loss: 0.024651
 >> iter 73000, loss: 0.022431
 >> iter 74000, loss: 0.021519
 >> iter 75000, loss: 0.020156
 >> iter 76000, loss: 0.023205
 >> iter 77000, loss: 0.020411
 >> iter 78000, loss: 0.020735
 >> iter 79000, loss: 0.019197
 >> iter 80000, loss: 0.017574
   Number of active neurons: 1
 >> iter 81000, loss: 0.019995
 >> iter 82000, loss: 0.034292
 >> iter 83000, loss: 0.024796
 >> iter 84000, loss: 0.021579
 >> iter 85000, loss: 0.021298
 >> iter 86000, loss: 0.019669
 >> iter 87000, loss: 0.028326
 >> iter 88000, loss: 0.021370
 >> iter 89000, loss: 0.019702
 >> iter 90000, loss: 0.018338
   Number of active neurons: 1
 >> iter 91000, loss: 0.017479
 >> iter 92000, loss: 0.019727
 >> iter 93000, loss: 0.017636
 >> iter 94000, loss: 0.020519
 >> iter 95000, loss: 0.023417
 >> iter 96000, loss: 0.018382
 >> iter 97000, loss: 0.022120
 >> iter 98000, loss: 0.035911
 >> iter 99000, loss: 0.043497
 >> iter 100000, loss: 0.028717
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.967473
 >> iter 2000, loss: 4.068786
 >> iter 3000, loss: 1.525319
 >> iter 4000, loss: 0.579134
 >> iter 5000, loss: 0.230437
 >> iter 6000, loss: 0.113854
 >> iter 7000, loss: 0.059250
 >> iter 8000, loss: 0.036085
 >> iter 9000, loss: 0.027877
 >> iter 10000, loss: 0.026375
   Number of active neurons: 3
 >> iter 11000, loss: 0.033360
 >> iter 12000, loss: 0.029399
 >> iter 13000, loss: 0.026702
 >> iter 14000, loss: 0.023128
 >> iter 15000, loss: 0.022570
 >> iter 16000, loss: 0.032442
 >> iter 17000, loss: 0.053963
 >> iter 18000, loss: 0.032645
 >> iter 19000, loss: 0.032800
 >> iter 20000, loss: 0.027024
   Number of active neurons: 2
 >> iter 21000, loss: 0.022696
 >> iter 22000, loss: 0.029756
 >> iter 23000, loss: 0.029435
 >> iter 24000, loss: 0.022904
 >> iter 25000, loss: 0.022273
 >> iter 26000, loss: 0.020954
 >> iter 27000, loss: 0.021108
 >> iter 28000, loss: 0.020935
 >> iter 29000, loss: 0.025539
 >> iter 30000, loss: 0.029648
   Number of active neurons: 2
 >> iter 31000, loss: 0.026820
 >> iter 32000, loss: 0.023612
 >> iter 33000, loss: 0.021998
 >> iter 34000, loss: 0.038865
 >> iter 35000, loss: 0.031762
 >> iter 36000, loss: 0.024977
 >> iter 37000, loss: 0.022220
 >> iter 38000, loss: 0.020452
 >> iter 39000, loss: 0.033084
 >> iter 40000, loss: 0.030949
   Number of active neurons: 2
 >> iter 41000, loss: 0.063471
 >> iter 42000, loss: 0.036581
 >> iter 43000, loss: 0.031652
 >> iter 44000, loss: 0.023903
 >> iter 45000, loss: 0.026701
 >> iter 46000, loss: 0.026554
 >> iter 47000, loss: 0.023758
 >> iter 48000, loss: 0.031687
 >> iter 49000, loss: 0.025208
 >> iter 50000, loss: 0.022263
   Number of active neurons: 2
 >> iter 51000, loss: 0.021641
 >> iter 52000, loss: 0.021551
 >> iter 53000, loss: 0.022035
 >> iter 54000, loss: 0.023344
 >> iter 55000, loss: 0.024161
 >> iter 56000, loss: 0.030577
 >> iter 57000, loss: 0.028464
 >> iter 58000, loss: 0.022457
 >> iter 59000, loss: 0.025866
 >> iter 60000, loss: 0.021980
   Number of active neurons: 2
 >> iter 61000, loss: 0.028279
 >> iter 62000, loss: 0.024403
 >> iter 63000, loss: 0.028412
 >> iter 64000, loss: 0.024168
 >> iter 65000, loss: 0.023432
 >> iter 66000, loss: 0.023250
 >> iter 67000, loss: 0.020444
 >> iter 68000, loss: 0.019805
 >> iter 69000, loss: 0.022566
 >> iter 70000, loss: 0.044946
   Number of active neurons: 2
 >> iter 71000, loss: 0.077300
 >> iter 72000, loss: 0.043014
 >> iter 73000, loss: 0.033735
 >> iter 74000, loss: 0.029955
 >> iter 75000, loss: 0.029377
 >> iter 76000, loss: 0.039087
 >> iter 77000, loss: 0.026958
 >> iter 78000, loss: 0.024313
 >> iter 79000, loss: 0.047736
 >> iter 80000, loss: 0.036172
   Number of active neurons: 2
 >> iter 81000, loss: 0.026947
 >> iter 82000, loss: 0.024001
 >> iter 83000, loss: 0.021831
 >> iter 84000, loss: 0.021262
 >> iter 85000, loss: 0.021854
 >> iter 86000, loss: 0.021521
 >> iter 87000, loss: 0.023028
 >> iter 88000, loss: 0.020924
 >> iter 89000, loss: 0.018592
 >> iter 90000, loss: 0.019973
   Number of active neurons: 1
 >> iter 91000, loss: 0.024224
 >> iter 92000, loss: 0.030779
 >> iter 93000, loss: 0.024677
 >> iter 94000, loss: 0.020617
 >> iter 95000, loss: 0.020022
 >> iter 96000, loss: 0.017466
 >> iter 97000, loss: 0.022054
 >> iter 98000, loss: 0.021870
 >> iter 99000, loss: 0.020589
 >> iter 100000, loss: 0.018815
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.950800
 >> iter 2000, loss: 4.067971
 >> iter 3000, loss: 1.518859
 >> iter 4000, loss: 0.595472
 >> iter 5000, loss: 0.244784
 >> iter 6000, loss: 0.111606
 >> iter 7000, loss: 0.057239
 >> iter 8000, loss: 0.038303
 >> iter 9000, loss: 0.029737
 >> iter 10000, loss: 0.025532
   Number of active neurons: 3
 >> iter 11000, loss: 0.059802
 >> iter 12000, loss: 0.041243
 >> iter 13000, loss: 0.032918
 >> iter 14000, loss: 0.038639
 >> iter 15000, loss: 0.030621
 >> iter 16000, loss: 0.029587
 >> iter 17000, loss: 0.034666
 >> iter 18000, loss: 0.039903
 >> iter 19000, loss: 0.036928
 >> iter 20000, loss: 0.045474
   Number of active neurons: 2
 >> iter 21000, loss: 0.032941
 >> iter 22000, loss: 0.023937
 >> iter 23000, loss: 0.020535
 >> iter 24000, loss: 0.057098
 >> iter 25000, loss: 0.036416
 >> iter 26000, loss: 0.035006
 >> iter 27000, loss: 0.031656
 >> iter 28000, loss: 0.031830
 >> iter 29000, loss: 0.023312
 >> iter 30000, loss: 0.021232
   Number of active neurons: 2
 >> iter 31000, loss: 0.024946
 >> iter 32000, loss: 0.032149
 >> iter 33000, loss: 0.024070
 >> iter 34000, loss: 0.022572
 >> iter 35000, loss: 0.028963
 >> iter 36000, loss: 0.022685
 >> iter 37000, loss: 0.026888
 >> iter 38000, loss: 0.023079
 >> iter 39000, loss: 0.021927
 >> iter 40000, loss: 0.020440
   Number of active neurons: 2
 >> iter 41000, loss: 0.022940
 >> iter 42000, loss: 0.022821
 >> iter 43000, loss: 0.024475
 >> iter 44000, loss: 0.022030
 >> iter 45000, loss: 0.023172
 >> iter 46000, loss: 0.022528
 >> iter 47000, loss: 0.031239
 >> iter 48000, loss: 0.023229
 >> iter 49000, loss: 0.042718
 >> iter 50000, loss: 0.031356
   Number of active neurons: 2
 >> iter 51000, loss: 0.026764
 >> iter 52000, loss: 0.023241
 >> iter 53000, loss: 0.026021
 >> iter 54000, loss: 0.023941
 >> iter 55000, loss: 0.026735
 >> iter 56000, loss: 0.025701
 >> iter 57000, loss: 0.037517
 >> iter 58000, loss: 0.035537
 >> iter 59000, loss: 0.027198
 >> iter 60000, loss: 0.024639
   Number of active neurons: 2
 >> iter 61000, loss: 0.023537
 >> iter 62000, loss: 0.023823
 >> iter 63000, loss: 0.021761
 >> iter 64000, loss: 0.019989
 >> iter 65000, loss: 0.034724
 >> iter 66000, loss: 0.027963
 >> iter 67000, loss: 0.029504
 >> iter 68000, loss: 0.045167
 >> iter 69000, loss: 0.031265
 >> iter 70000, loss: 0.026071
   Number of active neurons: 2
 >> iter 71000, loss: 0.021958
 >> iter 72000, loss: 0.030646
 >> iter 73000, loss: 0.030687
 >> iter 74000, loss: 0.027316
 >> iter 75000, loss: 0.024692
 >> iter 76000, loss: 0.022691
 >> iter 77000, loss: 0.020297
 >> iter 78000, loss: 0.023856
 >> iter 79000, loss: 0.037465
 >> iter 80000, loss: 0.027661
   Number of active neurons: 2
 >> iter 81000, loss: 0.022686
 >> iter 82000, loss: 0.022636
 >> iter 83000, loss: 0.023866
 >> iter 84000, loss: 0.021833
 >> iter 85000, loss: 0.021692
 >> iter 86000, loss: 0.023057
 >> iter 87000, loss: 0.022371
 >> iter 88000, loss: 0.026238
 >> iter 89000, loss: 0.038868
 >> iter 90000, loss: 0.026456
   Number of active neurons: 2
 >> iter 91000, loss: 0.026716
 >> iter 92000, loss: 0.023524
 >> iter 93000, loss: 0.041333
 >> iter 94000, loss: 0.027693
 >> iter 95000, loss: 0.024253
 >> iter 96000, loss: 0.030846
 >> iter 97000, loss: 0.023255
 >> iter 98000, loss: 0.038820
 >> iter 99000, loss: 0.028351
 >> iter 100000, loss: 0.021910
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.952314
 >> iter 2000, loss: 4.067745
 >> iter 3000, loss: 1.526329
 >> iter 4000, loss: 0.585724
 >> iter 5000, loss: 0.232578
 >> iter 6000, loss: 0.113238
 >> iter 7000, loss: 0.101067
 >> iter 8000, loss: 0.051971
 >> iter 9000, loss: 0.038820
 >> iter 10000, loss: 0.037288
   Number of active neurons: 3
 >> iter 11000, loss: 0.037860
 >> iter 12000, loss: 0.029527
 >> iter 13000, loss: 0.027070
 >> iter 14000, loss: 0.026370
 >> iter 15000, loss: 0.041736
 >> iter 16000, loss: 0.030197
 >> iter 17000, loss: 0.036647
 >> iter 18000, loss: 0.028174
 >> iter 19000, loss: 0.024855
 >> iter 20000, loss: 0.025596
   Number of active neurons: 3
 >> iter 21000, loss: 0.024729
 >> iter 22000, loss: 0.026232
 >> iter 23000, loss: 0.027303
 >> iter 24000, loss: 0.024131
 >> iter 25000, loss: 0.031848
 >> iter 26000, loss: 0.026677
 >> iter 27000, loss: 0.029828
 >> iter 28000, loss: 0.024781
 >> iter 29000, loss: 0.024093
 >> iter 30000, loss: 0.022167
   Number of active neurons: 2
 >> iter 31000, loss: 0.022376
 >> iter 32000, loss: 0.022042
 >> iter 33000, loss: 0.027527
 >> iter 34000, loss: 0.022214
 >> iter 35000, loss: 0.024492
 >> iter 36000, loss: 0.048561
 >> iter 37000, loss: 0.036242
 >> iter 38000, loss: 0.030775
 >> iter 39000, loss: 0.027384
 >> iter 40000, loss: 0.053715
   Number of active neurons: 2
 >> iter 41000, loss: 0.033846
 >> iter 42000, loss: 0.026715
 >> iter 43000, loss: 0.028339
 >> iter 44000, loss: 0.024985
 >> iter 45000, loss: 0.024713
 >> iter 46000, loss: 0.023729
 >> iter 47000, loss: 0.023295
 >> iter 48000, loss: 0.021414
 >> iter 49000, loss: 0.020140
 >> iter 50000, loss: 0.022465
   Number of active neurons: 2
 >> iter 51000, loss: 0.029971
 >> iter 52000, loss: 0.023367
 >> iter 53000, loss: 0.048989
 >> iter 54000, loss: 0.031401
 >> iter 55000, loss: 0.024468
 >> iter 56000, loss: 0.040453
 >> iter 57000, loss: 0.034565
 >> iter 58000, loss: 0.026041
 >> iter 59000, loss: 0.021677
 >> iter 60000, loss: 0.023170
   Number of active neurons: 1
 >> iter 61000, loss: 0.021689
 >> iter 62000, loss: 0.024310
 >> iter 63000, loss: 0.035009
 >> iter 64000, loss: 0.035169
 >> iter 65000, loss: 0.045623
 >> iter 66000, loss: 0.029884
 >> iter 67000, loss: 0.032832
 >> iter 68000, loss: 0.023628
 >> iter 69000, loss: 0.020409
 >> iter 70000, loss: 0.019828
   Number of active neurons: 1
 >> iter 71000, loss: 0.020761
 >> iter 72000, loss: 0.019967
 >> iter 73000, loss: 0.023446
 >> iter 74000, loss: 0.026978
 >> iter 75000, loss: 0.025187
 >> iter 76000, loss: 0.019238
 >> iter 77000, loss: 0.026577
 >> iter 78000, loss: 0.021386
 >> iter 79000, loss: 0.021448
 >> iter 80000, loss: 0.030095
   Number of active neurons: 1
 >> iter 81000, loss: 0.022488
 >> iter 82000, loss: 0.020160
 >> iter 83000, loss: 0.022440
 >> iter 84000, loss: 0.019575
 >> iter 85000, loss: 0.017772
 >> iter 86000, loss: 0.019726
 >> iter 87000, loss: 0.019394
 >> iter 88000, loss: 0.017480
 >> iter 89000, loss: 0.023491
 >> iter 90000, loss: 0.022425
   Number of active neurons: 1
 >> iter 91000, loss: 0.019738
 >> iter 92000, loss: 0.016862
 >> iter 93000, loss: 0.015632
 >> iter 94000, loss: 0.019307
 >> iter 95000, loss: 0.019648
 >> iter 96000, loss: 0.020826
 >> iter 97000, loss: 0.019468
 >> iter 98000, loss: 0.020164
 >> iter 99000, loss: 0.017885
 >> iter 100000, loss: 0.016204
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.006317
 >> iter 2000, loss: 4.091326
 >> iter 3000, loss: 1.526623
 >> iter 4000, loss: 0.581416
 >> iter 5000, loss: 0.231531
 >> iter 6000, loss: 0.104952
 >> iter 7000, loss: 0.055566
 >> iter 8000, loss: 0.039010
 >> iter 9000, loss: 0.031293
 >> iter 10000, loss: 0.027735
   Number of active neurons: 3
 >> iter 11000, loss: 0.038441
 >> iter 12000, loss: 0.032620
 >> iter 13000, loss: 0.030673
 >> iter 14000, loss: 0.031931
 >> iter 15000, loss: 0.028100
 >> iter 16000, loss: 0.027642
 >> iter 17000, loss: 0.025295
 >> iter 18000, loss: 0.024015
 >> iter 19000, loss: 0.022831
 >> iter 20000, loss: 0.023107
   Number of active neurons: 3
 >> iter 21000, loss: 0.027451
 >> iter 22000, loss: 0.030521
 >> iter 23000, loss: 0.029308
 >> iter 24000, loss: 0.025746
 >> iter 25000, loss: 0.024192
 >> iter 26000, loss: 0.026313
 >> iter 27000, loss: 0.028395
 >> iter 28000, loss: 0.024129
 >> iter 29000, loss: 0.025024
 >> iter 30000, loss: 0.023856
   Number of active neurons: 2
 >> iter 31000, loss: 0.028995
 >> iter 32000, loss: 0.043526
 >> iter 33000, loss: 0.029881
 >> iter 34000, loss: 0.024739
 >> iter 35000, loss: 0.024536
 >> iter 36000, loss: 0.023456
 >> iter 37000, loss: 0.023356
 >> iter 38000, loss: 0.027789
 >> iter 39000, loss: 0.024623
 >> iter 40000, loss: 0.021477
   Number of active neurons: 2
 >> iter 41000, loss: 0.032976
 >> iter 42000, loss: 0.026252
 >> iter 43000, loss: 0.025602
 >> iter 44000, loss: 0.025906
 >> iter 45000, loss: 0.029033
 >> iter 46000, loss: 0.022859
 >> iter 47000, loss: 0.031982
 >> iter 48000, loss: 0.024778
 >> iter 49000, loss: 0.029344
 >> iter 50000, loss: 0.025219
   Number of active neurons: 2
 >> iter 51000, loss: 0.045313
 >> iter 52000, loss: 0.033135
 >> iter 53000, loss: 0.024369
 >> iter 54000, loss: 0.025949
 >> iter 55000, loss: 0.033513
 >> iter 56000, loss: 0.025447
 >> iter 57000, loss: 0.026936
 >> iter 58000, loss: 0.025935
 >> iter 59000, loss: 0.021046
 >> iter 60000, loss: 0.019509
   Number of active neurons: 1
 >> iter 61000, loss: 0.017796
 >> iter 62000, loss: 0.020859
 >> iter 63000, loss: 0.022567
 >> iter 64000, loss: 0.022559
 >> iter 65000, loss: 0.019966
 >> iter 66000, loss: 0.019513
 >> iter 67000, loss: 0.028539
 >> iter 68000, loss: 0.051012
 >> iter 69000, loss: 0.030633
 >> iter 70000, loss: 0.027136
   Number of active neurons: 1
 >> iter 71000, loss: 0.021859
 >> iter 72000, loss: 0.018060
 >> iter 73000, loss: 0.020022
 >> iter 74000, loss: 0.017971
 >> iter 75000, loss: 0.019486
 >> iter 76000, loss: 0.024140
 >> iter 77000, loss: 0.020488
 >> iter 78000, loss: 0.020364
 >> iter 79000, loss: 0.022292
 >> iter 80000, loss: 0.022435
   Number of active neurons: 1
 >> iter 81000, loss: 0.018807
 >> iter 82000, loss: 0.019506
 >> iter 83000, loss: 0.018351
 >> iter 84000, loss: 0.026098
 >> iter 85000, loss: 0.025211
 >> iter 86000, loss: 0.020435
 >> iter 87000, loss: 0.031113
 >> iter 88000, loss: 0.025760
 >> iter 89000, loss: 0.020301
 >> iter 90000, loss: 0.021479
   Number of active neurons: 1
 >> iter 91000, loss: 0.031390
 >> iter 92000, loss: 0.026720
 >> iter 93000, loss: 0.022162
 >> iter 94000, loss: 0.030335
 >> iter 95000, loss: 0.048237
 >> iter 96000, loss: 0.031836
 >> iter 97000, loss: 0.035669
 >> iter 98000, loss: 0.026706
 >> iter 99000, loss: 0.019020
 >> iter 100000, loss: 0.020875
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.036749
 >> iter 2000, loss: 4.099158
 >> iter 3000, loss: 1.529869
 >> iter 4000, loss: 0.582605
 >> iter 5000, loss: 0.231722
 >> iter 6000, loss: 0.101026
 >> iter 7000, loss: 0.051703
 >> iter 8000, loss: 0.034102
 >> iter 9000, loss: 0.030775
 >> iter 10000, loss: 0.027079
   Number of active neurons: 3
 >> iter 11000, loss: 0.025223
 >> iter 12000, loss: 0.024050
 >> iter 13000, loss: 0.028440
 >> iter 14000, loss: 0.024292
 >> iter 15000, loss: 0.026303
 >> iter 16000, loss: 0.028921
 >> iter 17000, loss: 0.038553
 >> iter 18000, loss: 0.028862
 >> iter 19000, loss: 0.027412
 >> iter 20000, loss: 0.027958
   Number of active neurons: 3
 >> iter 21000, loss: 0.027893
 >> iter 22000, loss: 0.023575
 >> iter 23000, loss: 0.035749
 >> iter 24000, loss: 0.028794
 >> iter 25000, loss: 0.024165
 >> iter 26000, loss: 0.033641
 >> iter 27000, loss: 0.026746
 >> iter 28000, loss: 0.024513
 >> iter 29000, loss: 0.023317
 >> iter 30000, loss: 0.031315
   Number of active neurons: 3
 >> iter 31000, loss: 0.030254
 >> iter 32000, loss: 0.024601
 >> iter 33000, loss: 0.041864
 >> iter 34000, loss: 0.031358
 >> iter 35000, loss: 0.032449
 >> iter 36000, loss: 0.043707
 >> iter 37000, loss: 0.035057
 >> iter 38000, loss: 0.032413
 >> iter 39000, loss: 0.027086
 >> iter 40000, loss: 0.027556
   Number of active neurons: 2
 >> iter 41000, loss: 0.028303
 >> iter 42000, loss: 0.023310
 >> iter 43000, loss: 0.022886
 >> iter 44000, loss: 0.027112
 >> iter 45000, loss: 0.024872
 >> iter 46000, loss: 0.024744
 >> iter 47000, loss: 0.021458
 >> iter 48000, loss: 0.021760
 >> iter 49000, loss: 0.022102
 >> iter 50000, loss: 0.028530
   Number of active neurons: 2
 >> iter 51000, loss: 0.025449
 >> iter 52000, loss: 0.029579
 >> iter 53000, loss: 0.025814
 >> iter 54000, loss: 0.026974
 >> iter 55000, loss: 0.023066
 >> iter 56000, loss: 0.027119
 >> iter 57000, loss: 0.021983
 >> iter 58000, loss: 0.025248
 >> iter 59000, loss: 0.022309
 >> iter 60000, loss: 0.029841
   Number of active neurons: 2
 >> iter 61000, loss: 0.024852
 >> iter 62000, loss: 0.045100
 >> iter 63000, loss: 0.029361
 >> iter 64000, loss: 0.024226
 >> iter 65000, loss: 0.020895
 >> iter 66000, loss: 0.023306
 >> iter 67000, loss: 0.023330
 >> iter 68000, loss: 0.020742
 >> iter 69000, loss: 0.026393
 >> iter 70000, loss: 0.021505
   Number of active neurons: 1
 >> iter 71000, loss: 0.060675
 >> iter 72000, loss: 0.037071
 >> iter 73000, loss: 0.029589
 >> iter 74000, loss: 0.027342
 >> iter 75000, loss: 0.021994
 >> iter 76000, loss: 0.022592
 >> iter 77000, loss: 0.021536
 >> iter 78000, loss: 0.018248
 >> iter 79000, loss: 0.016198
 >> iter 80000, loss: 0.017110
   Number of active neurons: 1
 >> iter 81000, loss: 0.016886
 >> iter 82000, loss: 0.018476
 >> iter 83000, loss: 0.022698
 >> iter 84000, loss: 0.019744
 >> iter 85000, loss: 0.076105
 >> iter 86000, loss: 0.048999
 >> iter 87000, loss: 0.053101
 >> iter 88000, loss: 0.031850
 >> iter 89000, loss: 0.028035
 >> iter 90000, loss: 0.024585
   Number of active neurons: 1
 >> iter 91000, loss: 0.026631
 >> iter 92000, loss: 0.020239
 >> iter 93000, loss: 0.018859
 >> iter 94000, loss: 0.017851
 >> iter 95000, loss: 0.023300
 >> iter 96000, loss: 0.023624
 >> iter 97000, loss: 0.019120
 >> iter 98000, loss: 0.019826
 >> iter 99000, loss: 0.024835
 >> iter 100000, loss: 0.037012
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.182909
 >> iter 2000, loss: 4.148288
 >> iter 3000, loss: 1.563704
 >> iter 4000, loss: 0.593735
 >> iter 5000, loss: 0.237918
 >> iter 6000, loss: 0.100225
 >> iter 7000, loss: 0.051146
 >> iter 8000, loss: 0.035910
 >> iter 9000, loss: 0.027045
 >> iter 10000, loss: 0.028502
   Number of active neurons: 2
 >> iter 11000, loss: 0.030989
 >> iter 12000, loss: 0.025054
 >> iter 13000, loss: 0.021821
 >> iter 14000, loss: 0.021912
 >> iter 15000, loss: 0.021110
 >> iter 16000, loss: 0.021616
 >> iter 17000, loss: 0.023498
 >> iter 18000, loss: 0.054088
 >> iter 19000, loss: 0.036227
 >> iter 20000, loss: 0.026827
   Number of active neurons: 2
 >> iter 21000, loss: 0.023687
 >> iter 22000, loss: 0.021449
 >> iter 23000, loss: 0.023405
 >> iter 24000, loss: 0.040062
 >> iter 25000, loss: 0.042588
 >> iter 26000, loss: 0.028617
 >> iter 27000, loss: 0.030261
 >> iter 28000, loss: 0.027703
 >> iter 29000, loss: 0.022574
 >> iter 30000, loss: 0.021085
   Number of active neurons: 2
 >> iter 31000, loss: 0.022681
 >> iter 32000, loss: 0.033486
 >> iter 33000, loss: 0.025414
 >> iter 34000, loss: 0.034771
 >> iter 35000, loss: 0.026034
 >> iter 36000, loss: 0.062586
 >> iter 37000, loss: 0.037065
 >> iter 38000, loss: 0.032303
 >> iter 39000, loss: 0.026161
 >> iter 40000, loss: 0.022384
   Number of active neurons: 2
 >> iter 41000, loss: 0.030502
 >> iter 42000, loss: 0.027960
 >> iter 43000, loss: 0.031412
 >> iter 44000, loss: 0.024828
 >> iter 45000, loss: 0.024834
 >> iter 46000, loss: 0.046925
 >> iter 47000, loss: 0.030254
 >> iter 48000, loss: 0.022981
 >> iter 49000, loss: 0.024668
 >> iter 50000, loss: 0.025632
   Number of active neurons: 1
 >> iter 51000, loss: 0.031878
 >> iter 52000, loss: 0.053226
 >> iter 53000, loss: 0.032450
 >> iter 54000, loss: 0.025665
 >> iter 55000, loss: 0.023523
 >> iter 56000, loss: 0.021089
 >> iter 57000, loss: 0.018996
 >> iter 58000, loss: 0.017139
 >> iter 59000, loss: 0.018467
 >> iter 60000, loss: 0.021471
   Number of active neurons: 1
 >> iter 61000, loss: 0.022876
 >> iter 62000, loss: 0.018435
 >> iter 63000, loss: 0.019948
 >> iter 64000, loss: 0.018770
 >> iter 65000, loss: 0.020463
 >> iter 66000, loss: 0.033311
 >> iter 67000, loss: 0.022657
 >> iter 68000, loss: 0.018540
 >> iter 69000, loss: 0.017315
 >> iter 70000, loss: 0.018960
   Number of active neurons: 1
 >> iter 71000, loss: 0.019623
 >> iter 72000, loss: 0.019597
 >> iter 73000, loss: 0.018797
 >> iter 74000, loss: 0.042551
 >> iter 75000, loss: 0.042978
 >> iter 76000, loss: 0.033087
 >> iter 77000, loss: 0.038168
 >> iter 78000, loss: 0.029215
 >> iter 79000, loss: 0.020668
 >> iter 80000, loss: 0.022577
   Number of active neurons: 1
 >> iter 81000, loss: 0.036058
 >> iter 82000, loss: 0.028863
 >> iter 83000, loss: 0.029891
 >> iter 84000, loss: 0.021534
 >> iter 85000, loss: 0.019191
 >> iter 86000, loss: 0.018860
 >> iter 87000, loss: 0.018653
 >> iter 88000, loss: 0.022401
 >> iter 89000, loss: 0.019110
 >> iter 90000, loss: 0.021971
   Number of active neurons: 1
 >> iter 91000, loss: 0.019745
 >> iter 92000, loss: 0.017219
 >> iter 93000, loss: 0.018625
 >> iter 94000, loss: 0.018285
 >> iter 95000, loss: 0.020665
 >> iter 96000, loss: 0.020917
 >> iter 97000, loss: 0.022247
 >> iter 98000, loss: 0.019988
 >> iter 99000, loss: 0.023019
 >> iter 100000, loss: 0.018290
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.953621
 >> iter 2000, loss: 4.072833
 >> iter 3000, loss: 1.537015
 >> iter 4000, loss: 0.584391
 >> iter 5000, loss: 0.237871
 >> iter 6000, loss: 0.104234
 >> iter 7000, loss: 0.058064
 >> iter 8000, loss: 0.037363
 >> iter 9000, loss: 0.026742
 >> iter 10000, loss: 0.030396
   Number of active neurons: 3
 >> iter 11000, loss: 0.028991
 >> iter 12000, loss: 0.024257
 >> iter 13000, loss: 0.024220
 >> iter 14000, loss: 0.022776
 >> iter 15000, loss: 0.027626
 >> iter 16000, loss: 0.023566
 >> iter 17000, loss: 0.021390
 >> iter 18000, loss: 0.022426
 >> iter 19000, loss: 0.024136
 >> iter 20000, loss: 0.021840
   Number of active neurons: 2
 >> iter 21000, loss: 0.019705
 >> iter 22000, loss: 0.040500
 >> iter 23000, loss: 0.027286
 >> iter 24000, loss: 0.028968
 >> iter 25000, loss: 0.026304
 >> iter 26000, loss: 0.022936
 >> iter 27000, loss: 0.023532
 >> iter 28000, loss: 0.049468
 >> iter 29000, loss: 0.031101
 >> iter 30000, loss: 0.024669
   Number of active neurons: 2
 >> iter 31000, loss: 0.024511
 >> iter 32000, loss: 0.025066
 >> iter 33000, loss: 0.021899
 >> iter 34000, loss: 0.022186
 >> iter 35000, loss: 0.023163
 >> iter 36000, loss: 0.023303
 >> iter 37000, loss: 0.023186
 >> iter 38000, loss: 0.022657
 >> iter 39000, loss: 0.027545
 >> iter 40000, loss: 0.025660
   Number of active neurons: 2
 >> iter 41000, loss: 0.022163
 >> iter 42000, loss: 0.028897
 >> iter 43000, loss: 0.027810
 >> iter 44000, loss: 0.022801
 >> iter 45000, loss: 0.021464
 >> iter 46000, loss: 0.019705
 >> iter 47000, loss: 0.025583
 >> iter 48000, loss: 0.022269
 >> iter 49000, loss: 0.022735
 >> iter 50000, loss: 0.021342
   Number of active neurons: 2
 >> iter 51000, loss: 0.026391
 >> iter 52000, loss: 0.025620
 >> iter 53000, loss: 0.023684
 >> iter 54000, loss: 0.020923
 >> iter 55000, loss: 0.022017
 >> iter 56000, loss: 0.024708
 >> iter 57000, loss: 0.023380
 >> iter 58000, loss: 0.048667
 >> iter 59000, loss: 0.041770
 >> iter 60000, loss: 0.031141
   Number of active neurons: 2
 >> iter 61000, loss: 0.034370
 >> iter 62000, loss: 0.028827
 >> iter 63000, loss: 0.050862
 >> iter 64000, loss: 0.032307
 >> iter 65000, loss: 0.025832
 >> iter 66000, loss: 0.025848
 >> iter 67000, loss: 0.022963
 >> iter 68000, loss: 0.024634
 >> iter 69000, loss: 0.040150
 >> iter 70000, loss: 0.030990
   Number of active neurons: 2
 >> iter 71000, loss: 0.023856
 >> iter 72000, loss: 0.022617
 >> iter 73000, loss: 0.026276
 >> iter 74000, loss: 0.059944
 >> iter 75000, loss: 0.035199
 >> iter 76000, loss: 0.050233
 >> iter 77000, loss: 0.040633
 >> iter 78000, loss: 0.028089
 >> iter 79000, loss: 0.024657
 >> iter 80000, loss: 0.029020
   Number of active neurons: 2
 >> iter 81000, loss: 0.025953
 >> iter 82000, loss: 0.031317
 >> iter 83000, loss: 0.024778
 >> iter 84000, loss: 0.020456
 >> iter 85000, loss: 0.020769
 >> iter 86000, loss: 0.020356
 >> iter 87000, loss: 0.043760
 >> iter 88000, loss: 0.048326
 >> iter 89000, loss: 0.033164
 >> iter 90000, loss: 0.027961
   Number of active neurons: 2
 >> iter 91000, loss: 0.040924
 >> iter 92000, loss: 0.028206
 >> iter 93000, loss: 0.024807
 >> iter 94000, loss: 0.029631
 >> iter 95000, loss: 0.042600
 >> iter 96000, loss: 0.033442
 >> iter 97000, loss: 0.025889
 >> iter 98000, loss: 0.023582
 >> iter 99000, loss: 0.023442
 >> iter 100000, loss: 0.023178
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.031488
 >> iter 2000, loss: 4.095223
 >> iter 3000, loss: 1.540817
 >> iter 4000, loss: 0.589440
 >> iter 5000, loss: 0.236128
 >> iter 6000, loss: 0.104897
 >> iter 7000, loss: 0.055073
 >> iter 8000, loss: 0.040767
 >> iter 9000, loss: 0.044116
 >> iter 10000, loss: 0.033442
   Number of active neurons: 3
 >> iter 11000, loss: 0.028521
 >> iter 12000, loss: 0.034912
 >> iter 13000, loss: 0.028882
 >> iter 14000, loss: 0.026404
 >> iter 15000, loss: 0.027569
 >> iter 16000, loss: 0.026581
 >> iter 17000, loss: 0.027007
 >> iter 18000, loss: 0.029086
 >> iter 19000, loss: 0.026899
 >> iter 20000, loss: 0.050871
   Number of active neurons: 2
 >> iter 21000, loss: 0.041817
 >> iter 22000, loss: 0.053739
 >> iter 23000, loss: 0.043922
 >> iter 24000, loss: 0.032168
 >> iter 25000, loss: 0.025585
 >> iter 26000, loss: 0.021548
 >> iter 27000, loss: 0.025258
 >> iter 28000, loss: 0.022535
 >> iter 29000, loss: 0.022495
 >> iter 30000, loss: 0.022284
   Number of active neurons: 1
 >> iter 31000, loss: 0.023711
 >> iter 32000, loss: 0.023136
 >> iter 33000, loss: 0.025833
 >> iter 34000, loss: 0.032655
 >> iter 35000, loss: 0.023547
 >> iter 36000, loss: 0.018615
 >> iter 37000, loss: 0.016844
 >> iter 38000, loss: 0.046604
 >> iter 39000, loss: 0.028087
 >> iter 40000, loss: 0.023121
   Number of active neurons: 1
 >> iter 41000, loss: 0.025880
 >> iter 42000, loss: 0.026613
 >> iter 43000, loss: 0.020653
 >> iter 44000, loss: 0.019193
 >> iter 45000, loss: 0.020978
 >> iter 46000, loss: 0.018312
 >> iter 47000, loss: 0.018885
 >> iter 48000, loss: 0.017088
 >> iter 49000, loss: 0.020651
 >> iter 50000, loss: 0.023896
   Number of active neurons: 1
 >> iter 51000, loss: 0.020289
 >> iter 52000, loss: 0.017278
 >> iter 53000, loss: 0.016246
 >> iter 54000, loss: 0.023729
 >> iter 55000, loss: 0.019727
 >> iter 56000, loss: 0.038179
 >> iter 57000, loss: 0.043474
 >> iter 58000, loss: 0.027003
 >> iter 59000, loss: 0.020219
 >> iter 60000, loss: 0.019707
   Number of active neurons: 1
 >> iter 61000, loss: 0.021936
 >> iter 62000, loss: 0.019475
 >> iter 63000, loss: 0.024479
 >> iter 64000, loss: 0.021361
 >> iter 65000, loss: 0.020404
 >> iter 66000, loss: 0.017162
 >> iter 67000, loss: 0.018886
 >> iter 68000, loss: 0.018288
 >> iter 69000, loss: 0.018457
 >> iter 70000, loss: 0.018044
   Number of active neurons: 1
 >> iter 71000, loss: 0.021602
 >> iter 72000, loss: 0.032167
 >> iter 73000, loss: 0.021873
 >> iter 74000, loss: 0.021264
 >> iter 75000, loss: 0.018764
 >> iter 76000, loss: 0.017548
 >> iter 77000, loss: 0.027465
 >> iter 78000, loss: 0.029213
 >> iter 79000, loss: 0.023322
 >> iter 80000, loss: 0.026878
   Number of active neurons: 1
 >> iter 81000, loss: 0.020249
 >> iter 82000, loss: 0.020846
 >> iter 83000, loss: 0.017854
 >> iter 84000, loss: 0.022318
 >> iter 85000, loss: 0.023215
 >> iter 86000, loss: 0.019322
 >> iter 87000, loss: 0.020295
 >> iter 88000, loss: 0.023387
 >> iter 89000, loss: 0.023504
 >> iter 90000, loss: 0.023975
   Number of active neurons: 1
 >> iter 91000, loss: 0.036914
 >> iter 92000, loss: 0.037180
 >> iter 93000, loss: 0.024200
 >> iter 94000, loss: 0.021591
 >> iter 95000, loss: 0.018256
 >> iter 96000, loss: 0.017312
 >> iter 97000, loss: 0.021842
 >> iter 98000, loss: 0.018383
 >> iter 99000, loss: 0.020161
 >> iter 100000, loss: 0.016681
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.875919
 >> iter 2000, loss: 4.047094
 >> iter 3000, loss: 1.513249
 >> iter 4000, loss: 0.575676
 >> iter 5000, loss: 0.226451
 >> iter 6000, loss: 0.100335
 >> iter 7000, loss: 0.052335
 >> iter 8000, loss: 0.041779
 >> iter 9000, loss: 0.034399
 >> iter 10000, loss: 0.028557
   Number of active neurons: 3
 >> iter 11000, loss: 0.025982
 >> iter 12000, loss: 0.048460
 >> iter 13000, loss: 0.036372
 >> iter 14000, loss: 0.028481
 >> iter 15000, loss: 0.025225
 >> iter 16000, loss: 0.030073
 >> iter 17000, loss: 0.032163
 >> iter 18000, loss: 0.032306
 >> iter 19000, loss: 0.027860
 >> iter 20000, loss: 0.025323
   Number of active neurons: 3
 >> iter 21000, loss: 0.032607
 >> iter 22000, loss: 0.026360
 >> iter 23000, loss: 0.025074
 >> iter 24000, loss: 0.024242
 >> iter 25000, loss: 0.026325
 >> iter 26000, loss: 0.026095
 >> iter 27000, loss: 0.027706
 >> iter 28000, loss: 0.027612
 >> iter 29000, loss: 0.026287
 >> iter 30000, loss: 0.022972
   Number of active neurons: 2
 >> iter 31000, loss: 0.021288
 >> iter 32000, loss: 0.025712
 >> iter 33000, loss: 0.025873
 >> iter 34000, loss: 0.021982
 >> iter 35000, loss: 0.025988
 >> iter 36000, loss: 0.024866
 >> iter 37000, loss: 0.022607
 >> iter 38000, loss: 0.020680
 >> iter 39000, loss: 0.037169
 >> iter 40000, loss: 0.034889
   Number of active neurons: 2
 >> iter 41000, loss: 0.024608
 >> iter 42000, loss: 0.022663
 >> iter 43000, loss: 0.025951
 >> iter 44000, loss: 0.026461
 >> iter 45000, loss: 0.023300
 >> iter 46000, loss: 0.022479
 >> iter 47000, loss: 0.021256
 >> iter 48000, loss: 0.023837
 >> iter 49000, loss: 0.021914
 >> iter 50000, loss: 0.027056
   Number of active neurons: 2
 >> iter 51000, loss: 0.034285
 >> iter 52000, loss: 0.026418
 >> iter 53000, loss: 0.022121
 >> iter 54000, loss: 0.027471
 >> iter 55000, loss: 0.022542
 >> iter 56000, loss: 0.025797
 >> iter 57000, loss: 0.030524
 >> iter 58000, loss: 0.024114
 >> iter 59000, loss: 0.034590
 >> iter 60000, loss: 0.025498
   Number of active neurons: 2
 >> iter 61000, loss: 0.023606
 >> iter 62000, loss: 0.024204
 >> iter 63000, loss: 0.039384
 >> iter 64000, loss: 0.031651
 >> iter 65000, loss: 0.025834
 >> iter 66000, loss: 0.025060
 >> iter 67000, loss: 0.023233
 >> iter 68000, loss: 0.026124
 >> iter 69000, loss: 0.024153
 >> iter 70000, loss: 0.020354
   Number of active neurons: 1
 >> iter 71000, loss: 0.023128
 >> iter 72000, loss: 0.022890
 >> iter 73000, loss: 0.029565
 >> iter 74000, loss: 0.022162
 >> iter 75000, loss: 0.019229
 >> iter 76000, loss: 0.017699
 >> iter 77000, loss: 0.031990
 >> iter 78000, loss: 0.025869
 >> iter 79000, loss: 0.059554
 >> iter 80000, loss: 0.057708
   Number of active neurons: 1
 >> iter 81000, loss: 0.032241
 >> iter 82000, loss: 0.023156
 >> iter 83000, loss: 0.020959
 >> iter 84000, loss: 0.017668
 >> iter 85000, loss: 0.018582
 >> iter 86000, loss: 0.019091
 >> iter 87000, loss: 0.016976
 >> iter 88000, loss: 0.016716
 >> iter 89000, loss: 0.026146
 >> iter 90000, loss: 0.022054
   Number of active neurons: 1
 >> iter 91000, loss: 0.026302
 >> iter 92000, loss: 0.019209
 >> iter 93000, loss: 0.017417
 >> iter 94000, loss: 0.016730
 >> iter 95000, loss: 0.019509
 >> iter 96000, loss: 0.058770
 >> iter 97000, loss: 0.033556
 >> iter 98000, loss: 0.023610
 >> iter 99000, loss: 0.027498
 >> iter 100000, loss: 0.019796
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.028704
 >> iter 2000, loss: 4.091928
 >> iter 3000, loss: 1.544269
 >> iter 4000, loss: 0.592707
 >> iter 5000, loss: 0.243940
 >> iter 6000, loss: 0.109583
 >> iter 7000, loss: 0.054254
 >> iter 8000, loss: 0.034395
 >> iter 9000, loss: 0.060902
 >> iter 10000, loss: 0.054939
   Number of active neurons: 2
 >> iter 11000, loss: 0.034969
 >> iter 12000, loss: 0.027000
 >> iter 13000, loss: 0.031676
 >> iter 14000, loss: 0.036728
 >> iter 15000, loss: 0.026518
 >> iter 16000, loss: 0.024063
 >> iter 17000, loss: 0.024183
 >> iter 18000, loss: 0.020733
 >> iter 19000, loss: 0.021922
 >> iter 20000, loss: 0.023243
   Number of active neurons: 1
 >> iter 21000, loss: 0.020662
 >> iter 22000, loss: 0.026584
 >> iter 23000, loss: 0.029632
 >> iter 24000, loss: 0.021131
 >> iter 25000, loss: 0.018461
 >> iter 26000, loss: 0.017391
 >> iter 27000, loss: 0.018290
 >> iter 28000, loss: 0.018641
 >> iter 29000, loss: 0.017459
 >> iter 30000, loss: 0.016653
   Number of active neurons: 1
 >> iter 31000, loss: 0.016422
 >> iter 32000, loss: 0.020955
 >> iter 33000, loss: 0.025318
 >> iter 34000, loss: 0.020337
 >> iter 35000, loss: 0.048535
 >> iter 36000, loss: 0.030305
 >> iter 37000, loss: 0.022868
 >> iter 38000, loss: 0.022571
 >> iter 39000, loss: 0.020151
 >> iter 40000, loss: 0.018045
   Number of active neurons: 1
 >> iter 41000, loss: 0.021924
 >> iter 42000, loss: 0.021022
 >> iter 43000, loss: 0.017592
 >> iter 44000, loss: 0.025133
 >> iter 45000, loss: 0.026847
 >> iter 46000, loss: 0.027197
 >> iter 47000, loss: 0.021606
 >> iter 48000, loss: 0.026034
 >> iter 49000, loss: 0.059467
 >> iter 50000, loss: 0.039079
   Number of active neurons: 1
 >> iter 51000, loss: 0.027285
 >> iter 52000, loss: 0.023003
 >> iter 53000, loss: 0.018196
 >> iter 54000, loss: 0.024858
 >> iter 55000, loss: 0.021852
 >> iter 56000, loss: 0.038159
 >> iter 57000, loss: 0.028292
 >> iter 58000, loss: 0.021190
 >> iter 59000, loss: 0.019373
 >> iter 60000, loss: 0.023908
   Number of active neurons: 1
 >> iter 61000, loss: 0.021010
 >> iter 62000, loss: 0.019521
 >> iter 63000, loss: 0.017696
 >> iter 64000, loss: 0.019742
 >> iter 65000, loss: 0.019412
 >> iter 66000, loss: 0.017609
 >> iter 67000, loss: 0.018132
 >> iter 68000, loss: 0.018490
 >> iter 69000, loss: 0.020733
 >> iter 70000, loss: 0.022085
   Number of active neurons: 1
 >> iter 71000, loss: 0.018853
 >> iter 72000, loss: 0.017869
 >> iter 73000, loss: 0.032857
 >> iter 74000, loss: 0.026175
 >> iter 75000, loss: 0.020381
 >> iter 76000, loss: 0.028480
 >> iter 77000, loss: 0.020825
 >> iter 78000, loss: 0.020157
 >> iter 79000, loss: 0.019181
 >> iter 80000, loss: 0.016969
   Number of active neurons: 1
 >> iter 81000, loss: 0.018626
 >> iter 82000, loss: 0.024638
 >> iter 83000, loss: 0.021051
 >> iter 84000, loss: 0.018462
 >> iter 85000, loss: 0.019900
 >> iter 86000, loss: 0.016226
 >> iter 87000, loss: 0.021855
 >> iter 88000, loss: 0.017752
 >> iter 89000, loss: 0.018390
 >> iter 90000, loss: 0.047247
   Number of active neurons: 1
 >> iter 91000, loss: 0.030999
 >> iter 92000, loss: 0.025510
 >> iter 93000, loss: 0.022552
 >> iter 94000, loss: 0.023252
 >> iter 95000, loss: 0.032120
 >> iter 96000, loss: 0.027415
 >> iter 97000, loss: 0.020775
 >> iter 98000, loss: 0.024204
 >> iter 99000, loss: 0.023699
 >> iter 100000, loss: 0.019432
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.917951
 >> iter 2000, loss: 4.072748
 >> iter 3000, loss: 1.522782
 >> iter 4000, loss: 0.581708
 >> iter 5000, loss: 0.231763
 >> iter 6000, loss: 0.104948
 >> iter 7000, loss: 0.069207
 >> iter 8000, loss: 0.040692
 >> iter 9000, loss: 0.036505
 >> iter 10000, loss: 0.029204
   Number of active neurons: 3
 >> iter 11000, loss: 0.120289
 >> iter 12000, loss: 0.064621
 >> iter 13000, loss: 0.046756
 >> iter 14000, loss: 0.033848
 >> iter 15000, loss: 0.028535
 >> iter 16000, loss: 0.023989
 >> iter 17000, loss: 0.028907
 >> iter 18000, loss: 0.030719
 >> iter 19000, loss: 0.073623
 >> iter 20000, loss: 0.051848
   Number of active neurons: 3
 >> iter 21000, loss: 0.034155
 >> iter 22000, loss: 0.034670
 >> iter 23000, loss: 0.031961
 >> iter 24000, loss: 0.027914
 >> iter 25000, loss: 0.049569
 >> iter 26000, loss: 0.034741
 >> iter 27000, loss: 0.028287
 >> iter 28000, loss: 0.028333
 >> iter 29000, loss: 0.027903
 >> iter 30000, loss: 0.028450
   Number of active neurons: 2
 >> iter 31000, loss: 0.026660
 >> iter 32000, loss: 0.031732
 >> iter 33000, loss: 0.025426
 >> iter 34000, loss: 0.043811
 >> iter 35000, loss: 0.029176
 >> iter 36000, loss: 0.026563
 >> iter 37000, loss: 0.022756
 >> iter 38000, loss: 0.024618
 >> iter 39000, loss: 0.021038
 >> iter 40000, loss: 0.020044
   Number of active neurons: 1
 >> iter 41000, loss: 0.018341
 >> iter 42000, loss: 0.017884
 >> iter 43000, loss: 0.018393
 >> iter 44000, loss: 0.017921
 >> iter 45000, loss: 0.028970
 >> iter 46000, loss: 0.022017
 >> iter 47000, loss: 0.027352
 >> iter 48000, loss: 0.024231
 >> iter 49000, loss: 0.028883
 >> iter 50000, loss: 0.022556
   Number of active neurons: 1
 >> iter 51000, loss: 0.030553
 >> iter 52000, loss: 0.024316
 >> iter 53000, loss: 0.018752
 >> iter 54000, loss: 0.020451
 >> iter 55000, loss: 0.018366
 >> iter 56000, loss: 0.019684
 >> iter 57000, loss: 0.021094
 >> iter 58000, loss: 0.019368
 >> iter 59000, loss: 0.019321
 >> iter 60000, loss: 0.021674
   Number of active neurons: 1
 >> iter 61000, loss: 0.018500
 >> iter 62000, loss: 0.017795
 >> iter 63000, loss: 0.018999
 >> iter 64000, loss: 0.018017
 >> iter 65000, loss: 0.017761
 >> iter 66000, loss: 0.016132
 >> iter 67000, loss: 0.018808
 >> iter 68000, loss: 0.023672
 >> iter 69000, loss: 0.020225
 >> iter 70000, loss: 0.019855
   Number of active neurons: 1
 >> iter 71000, loss: 0.018147
 >> iter 72000, loss: 0.018239
 >> iter 73000, loss: 0.019927
 >> iter 74000, loss: 0.020288
 >> iter 75000, loss: 0.018130
 >> iter 76000, loss: 0.017274
 >> iter 77000, loss: 0.028131
 >> iter 78000, loss: 0.023124
 >> iter 79000, loss: 0.036770
 >> iter 80000, loss: 0.025212
   Number of active neurons: 1
 >> iter 81000, loss: 0.019615
 >> iter 82000, loss: 0.027648
 >> iter 83000, loss: 0.021073
 >> iter 84000, loss: 0.022535
 >> iter 85000, loss: 0.021684
 >> iter 86000, loss: 0.021806
 >> iter 87000, loss: 0.019240
 >> iter 88000, loss: 0.017689
 >> iter 89000, loss: 0.020674
 >> iter 90000, loss: 0.017059
   Number of active neurons: 1
 >> iter 91000, loss: 0.080043
 >> iter 92000, loss: 0.042621
 >> iter 93000, loss: 0.026795
 >> iter 94000, loss: 0.022060
 >> iter 95000, loss: 0.024043
 >> iter 96000, loss: 0.019898
 >> iter 97000, loss: 0.020668
 >> iter 98000, loss: 0.018109
 >> iter 99000, loss: 0.017264
 >> iter 100000, loss: 0.017828
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.959997
 >> iter 2000, loss: 4.096523
 >> iter 3000, loss: 1.544425
 >> iter 4000, loss: 0.589671
 >> iter 5000, loss: 0.240622
 >> iter 6000, loss: 0.110252
 >> iter 7000, loss: 0.055939
 >> iter 8000, loss: 0.043637
 >> iter 9000, loss: 0.033086
 >> iter 10000, loss: 0.042457
   Number of active neurons: 3
 >> iter 11000, loss: 0.041504
 >> iter 12000, loss: 0.040957
 >> iter 13000, loss: 0.044896
 >> iter 14000, loss: 0.034736
 >> iter 15000, loss: 0.029096
 >> iter 16000, loss: 0.027870
 >> iter 17000, loss: 0.027821
 >> iter 18000, loss: 0.023867
 >> iter 19000, loss: 0.025274
 >> iter 20000, loss: 0.033234
   Number of active neurons: 2
 >> iter 21000, loss: 0.026777
 >> iter 22000, loss: 0.024140
 >> iter 23000, loss: 0.024176
 >> iter 24000, loss: 0.021401
 >> iter 25000, loss: 0.027869
 >> iter 26000, loss: 0.022945
 >> iter 27000, loss: 0.028987
 >> iter 28000, loss: 0.026135
 >> iter 29000, loss: 0.021349
 >> iter 30000, loss: 0.021964
   Number of active neurons: 1
 >> iter 31000, loss: 0.035955
 >> iter 32000, loss: 0.024239
 >> iter 33000, loss: 0.019554
 >> iter 34000, loss: 0.017350
 >> iter 35000, loss: 0.017396
 >> iter 36000, loss: 0.036741
 >> iter 37000, loss: 0.026906
 >> iter 38000, loss: 0.021295
 >> iter 39000, loss: 0.039841
 >> iter 40000, loss: 0.029560
   Number of active neurons: 1
 >> iter 41000, loss: 0.021646
 >> iter 42000, loss: 0.030889
 >> iter 43000, loss: 0.027106
 >> iter 44000, loss: 0.021530
 >> iter 45000, loss: 0.020100
 >> iter 46000, loss: 0.016974
 >> iter 47000, loss: 0.016540
 >> iter 48000, loss: 0.019009
 >> iter 49000, loss: 0.026696
 >> iter 50000, loss: 0.035600
   Number of active neurons: 1
 >> iter 51000, loss: 0.025180
 >> iter 52000, loss: 0.020462
 >> iter 53000, loss: 0.017599
 >> iter 54000, loss: 0.019395
 >> iter 55000, loss: 0.017360
 >> iter 56000, loss: 0.025751
 >> iter 57000, loss: 0.021281
 >> iter 58000, loss: 0.021090
 >> iter 59000, loss: 0.017222
 >> iter 60000, loss: 0.039145
   Number of active neurons: 1
 >> iter 61000, loss: 0.026346
 >> iter 62000, loss: 0.023209
 >> iter 63000, loss: 0.020186
 >> iter 64000, loss: 0.018314
 >> iter 65000, loss: 0.018699
 >> iter 66000, loss: 0.034199
 >> iter 67000, loss: 0.039170
 >> iter 68000, loss: 0.026844
 >> iter 69000, loss: 0.053611
 >> iter 70000, loss: 0.031317
   Number of active neurons: 1
 >> iter 71000, loss: 0.022128
 >> iter 72000, loss: 0.018662
 >> iter 73000, loss: 0.036966
 >> iter 74000, loss: 0.026804
 >> iter 75000, loss: 0.024201
 >> iter 76000, loss: 0.019775
 >> iter 77000, loss: 0.025064
 >> iter 78000, loss: 0.025365
 >> iter 79000, loss: 0.021192
 >> iter 80000, loss: 0.018567
   Number of active neurons: 1
 >> iter 81000, loss: 0.017460
 >> iter 82000, loss: 0.018684
 >> iter 83000, loss: 0.019734
 >> iter 84000, loss: 0.016065
 >> iter 85000, loss: 0.020413
 >> iter 86000, loss: 0.020690
 >> iter 87000, loss: 0.019387
 >> iter 88000, loss: 0.041613
 >> iter 89000, loss: 0.030895
 >> iter 90000, loss: 0.030231
   Number of active neurons: 1
 >> iter 91000, loss: 0.021258
 >> iter 92000, loss: 0.019235
 >> iter 93000, loss: 0.017282
 >> iter 94000, loss: 0.025310
 >> iter 95000, loss: 0.020391
 >> iter 96000, loss: 0.066620
 >> iter 97000, loss: 0.036820
 >> iter 98000, loss: 0.024101
 >> iter 99000, loss: 0.023242
 >> iter 100000, loss: 0.019834
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

