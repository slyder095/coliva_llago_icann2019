 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.9
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.073116
 >> iter 2000, loss: 10.357123
 >> iter 3000, loss: 4.844873
 >> iter 4000, loss: 2.064383
 >> iter 5000, loss: 1.004252
 >> iter 6000, loss: 0.415318
 >> iter 7000, loss: 0.295287
 >> iter 8000, loss: 0.184129
 >> iter 9000, loss: 0.287759
 >> iter 10000, loss: 0.128986
   Number of active neurons: 10
 >> iter 11000, loss: 0.137913
 >> iter 12000, loss: 0.184797
 >> iter 13000, loss: 0.214025
 >> iter 14000, loss: 0.090763
 >> iter 15000, loss: 0.206279
 >> iter 16000, loss: 0.163889
 >> iter 17000, loss: 0.068650
 >> iter 18000, loss: 0.031684
 >> iter 19000, loss: 0.017088
 >> iter 20000, loss: 0.010547
   Number of active neurons: 10
 >> iter 21000, loss: 0.010066
 >> iter 22000, loss: 0.048623
 >> iter 23000, loss: 0.031924
 >> iter 24000, loss: 0.014829
 >> iter 25000, loss: 0.008706
 >> iter 26000, loss: 0.006359
 >> iter 27000, loss: 0.004664
 >> iter 28000, loss: 0.004087
 >> iter 29000, loss: 0.032437
 >> iter 30000, loss: 0.016106
   Number of active neurons: 10
 >> iter 31000, loss: 0.062812
 >> iter 32000, loss: 0.057597
 >> iter 33000, loss: 0.024840
 >> iter 34000, loss: 0.011516
 >> iter 35000, loss: 0.006299
 >> iter 36000, loss: 0.004853
 >> iter 37000, loss: 0.034037
 >> iter 38000, loss: 0.061981
 >> iter 39000, loss: 0.027105
 >> iter 40000, loss: 0.148037
   Number of active neurons: 10
 >> iter 41000, loss: 0.057297
 >> iter 42000, loss: 0.033897
 >> iter 43000, loss: 0.014592
 >> iter 44000, loss: 0.058606
 >> iter 45000, loss: 0.028391
 >> iter 46000, loss: 0.012678
 >> iter 47000, loss: 0.047893
 >> iter 48000, loss: 0.020635
 >> iter 49000, loss: 0.010240
 >> iter 50000, loss: 0.005785
   Number of active neurons: 10
 >> iter 51000, loss: 0.009270
 >> iter 52000, loss: 0.009867
 >> iter 53000, loss: 0.005237
 >> iter 54000, loss: 0.004652
 >> iter 55000, loss: 0.003929
 >> iter 56000, loss: 0.002750
 >> iter 57000, loss: 0.002280
 >> iter 58000, loss: 0.002400
 >> iter 59000, loss: 0.002078
 >> iter 60000, loss: 0.002018
   Number of active neurons: 10
 >> iter 61000, loss: 0.001885
 >> iter 62000, loss: 0.001991
 >> iter 63000, loss: 0.001691
 >> iter 64000, loss: 0.001561
 >> iter 65000, loss: 0.002218
 >> iter 66000, loss: 0.001784
 >> iter 67000, loss: 0.001488
 >> iter 68000, loss: 0.003397
 >> iter 69000, loss: 0.022016
 >> iter 70000, loss: 0.008975
   Number of active neurons: 10
 >> iter 71000, loss: 0.004105
 >> iter 72000, loss: 0.002315
 >> iter 73000, loss: 0.003900
 >> iter 74000, loss: 0.002504
 >> iter 75000, loss: 0.037814
 >> iter 76000, loss: 0.015200
 >> iter 77000, loss: 0.006594
 >> iter 78000, loss: 0.003392
 >> iter 79000, loss: 0.003004
 >> iter 80000, loss: 0.002452
   Number of active neurons: 10
 >> iter 81000, loss: 0.002179
 >> iter 82000, loss: 0.002137
 >> iter 83000, loss: 0.004975
 >> iter 84000, loss: 0.006923
 >> iter 85000, loss: 0.003187
 >> iter 86000, loss: 0.027310
 >> iter 87000, loss: 0.011207
 >> iter 88000, loss: 0.004982
 >> iter 89000, loss: 0.002754
 >> iter 90000, loss: 0.001763
   Number of active neurons: 10
 >> iter 91000, loss: 0.001315
 >> iter 92000, loss: 0.094149
 >> iter 93000, loss: 0.035919
 >> iter 94000, loss: 0.209644
 >> iter 95000, loss: 0.078998
 >> iter 96000, loss: 0.034269
 >> iter 97000, loss: 0.018281
 >> iter 98000, loss: 0.031789
 >> iter 99000, loss: 0.012804
 >> iter 100000, loss: 0.005682
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.109257
 >> iter 2000, loss: 10.551647
 >> iter 3000, loss: 5.412920
 >> iter 4000, loss: 2.572111
 >> iter 5000, loss: 1.490717
 >> iter 6000, loss: 0.874330
 >> iter 7000, loss: 0.502522
 >> iter 8000, loss: 0.594021
 >> iter 9000, loss: 0.369363
 >> iter 10000, loss: 0.517743
   Number of active neurons: 10
 >> iter 11000, loss: 0.335459
 >> iter 12000, loss: 0.250084
 >> iter 13000, loss: 0.218227
 >> iter 14000, loss: 0.117991
 >> iter 15000, loss: 0.115336
 >> iter 16000, loss: 0.065168
 >> iter 17000, loss: 0.040988
 >> iter 18000, loss: 0.050939
 >> iter 19000, loss: 0.039273
 >> iter 20000, loss: 0.019528
   Number of active neurons: 10
 >> iter 21000, loss: 0.024635
 >> iter 22000, loss: 0.090047
 >> iter 23000, loss: 0.187531
 >> iter 24000, loss: 0.139105
 >> iter 25000, loss: 0.061525
 >> iter 26000, loss: 0.189708
 >> iter 27000, loss: 0.150238
 >> iter 28000, loss: 0.062051
 >> iter 29000, loss: 0.094122
 >> iter 30000, loss: 0.076854
   Number of active neurons: 10
 >> iter 31000, loss: 0.100062
 >> iter 32000, loss: 0.041693
 >> iter 33000, loss: 0.133090
 >> iter 34000, loss: 0.054634
 >> iter 35000, loss: 0.112776
 >> iter 36000, loss: 0.055429
 >> iter 37000, loss: 0.032526
 >> iter 38000, loss: 0.015402
 >> iter 39000, loss: 0.051317
 >> iter 40000, loss: 0.036574
   Number of active neurons: 10
 >> iter 41000, loss: 0.016340
 >> iter 42000, loss: 0.009958
 >> iter 43000, loss: 0.011032
 >> iter 44000, loss: 0.065466
 >> iter 45000, loss: 0.027604
 >> iter 46000, loss: 0.012789
 >> iter 47000, loss: 0.030577
 >> iter 48000, loss: 0.106252
 >> iter 49000, loss: 0.042154
 >> iter 50000, loss: 0.198817
   Number of active neurons: 10
 >> iter 51000, loss: 0.160826
 >> iter 52000, loss: 0.066139
 >> iter 53000, loss: 0.047633
 >> iter 54000, loss: 0.020423
 >> iter 55000, loss: 0.009774
 >> iter 56000, loss: 0.009963
 >> iter 57000, loss: 0.008139
 >> iter 58000, loss: 0.007299
 >> iter 59000, loss: 0.074586
 >> iter 60000, loss: 0.030230
   Number of active neurons: 10
 >> iter 61000, loss: 0.012946
 >> iter 62000, loss: 0.033831
 >> iter 63000, loss: 0.014326
 >> iter 64000, loss: 0.008987
 >> iter 65000, loss: 0.004958
 >> iter 66000, loss: 0.009777
 >> iter 67000, loss: 0.007291
 >> iter 68000, loss: 0.003755
 >> iter 69000, loss: 0.006305
 >> iter 70000, loss: 0.003407
   Number of active neurons: 10
 >> iter 71000, loss: 0.002318
 >> iter 72000, loss: 0.001888
 >> iter 73000, loss: 0.012804
 >> iter 74000, loss: 0.005586
 >> iter 75000, loss: 0.002934
 >> iter 76000, loss: 0.032185
 >> iter 77000, loss: 0.026317
 >> iter 78000, loss: 0.070674
 >> iter 79000, loss: 0.027920
 >> iter 80000, loss: 0.093201
   Number of active neurons: 10
 >> iter 81000, loss: 0.069814
 >> iter 82000, loss: 0.027967
 >> iter 83000, loss: 0.011991
 >> iter 84000, loss: 0.006131
 >> iter 85000, loss: 0.003623
 >> iter 86000, loss: 0.002557
 >> iter 87000, loss: 0.003287
 >> iter 88000, loss: 0.141598
 >> iter 89000, loss: 0.104982
 >> iter 90000, loss: 0.040788
   Number of active neurons: 10
 >> iter 91000, loss: 0.017522
 >> iter 92000, loss: 0.019543
 >> iter 93000, loss: 0.060723
 >> iter 94000, loss: 0.024291
 >> iter 95000, loss: 0.038282
 >> iter 96000, loss: 0.015881
 >> iter 97000, loss: 0.070128
 >> iter 98000, loss: 0.027849
 >> iter 99000, loss: 0.011845
 >> iter 100000, loss: 0.005804
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.213178
 >> iter 2000, loss: 10.446771
 >> iter 3000, loss: 5.250517
 >> iter 4000, loss: 2.720540
 >> iter 5000, loss: 1.595971
 >> iter 6000, loss: 0.756203
 >> iter 7000, loss: 0.578618
 >> iter 8000, loss: 0.540325
 >> iter 9000, loss: 0.329394
 >> iter 10000, loss: 0.231022
   Number of active neurons: 10
 >> iter 11000, loss: 0.276708
 >> iter 12000, loss: 0.202829
 >> iter 13000, loss: 0.126766
 >> iter 14000, loss: 0.102586
 >> iter 15000, loss: 0.173148
 >> iter 16000, loss: 0.077473
 >> iter 17000, loss: 0.144556
 >> iter 18000, loss: 0.143984
 >> iter 19000, loss: 0.114757
 >> iter 20000, loss: 0.067856
   Number of active neurons: 10
 >> iter 21000, loss: 0.035426
 >> iter 22000, loss: 0.159203
 >> iter 23000, loss: 0.178112
 >> iter 24000, loss: 0.104261
 >> iter 25000, loss: 0.077244
 >> iter 26000, loss: 0.040486
 >> iter 27000, loss: 0.074367
 >> iter 28000, loss: 0.081954
 >> iter 29000, loss: 0.236737
 >> iter 30000, loss: 0.093418
   Number of active neurons: 10
 >> iter 31000, loss: 0.048598
 >> iter 32000, loss: 0.108263
 >> iter 33000, loss: 0.044267
 >> iter 34000, loss: 0.028904
 >> iter 35000, loss: 0.013697
 >> iter 36000, loss: 0.008682
 >> iter 37000, loss: 0.005910
 >> iter 38000, loss: 0.019523
 >> iter 39000, loss: 0.012053
 >> iter 40000, loss: 0.006397
   Number of active neurons: 10
 >> iter 41000, loss: 0.052027
 >> iter 42000, loss: 0.024913
 >> iter 43000, loss: 0.012171
 >> iter 44000, loss: 0.006455
 >> iter 45000, loss: 0.140846
 >> iter 46000, loss: 0.067755
 >> iter 47000, loss: 0.102059
 >> iter 48000, loss: 0.118540
 >> iter 49000, loss: 0.048175
 >> iter 50000, loss: 0.020266
   Number of active neurons: 10
 >> iter 51000, loss: 0.009578
 >> iter 52000, loss: 0.005470
 >> iter 53000, loss: 0.012745
 >> iter 54000, loss: 0.006970
 >> iter 55000, loss: 0.004378
 >> iter 56000, loss: 0.003259
 >> iter 57000, loss: 0.019509
 >> iter 58000, loss: 0.008993
 >> iter 59000, loss: 0.008793
 >> iter 60000, loss: 0.004459
   Number of active neurons: 10
 >> iter 61000, loss: 0.020574
 >> iter 62000, loss: 0.009638
 >> iter 63000, loss: 0.005401
 >> iter 64000, loss: 0.005749
 >> iter 65000, loss: 0.089840
 >> iter 66000, loss: 0.063492
 >> iter 67000, loss: 0.025115
 >> iter 68000, loss: 0.044686
 >> iter 69000, loss: 0.019420
 >> iter 70000, loss: 0.008648
   Number of active neurons: 10
 >> iter 71000, loss: 0.004510
 >> iter 72000, loss: 0.003808
 >> iter 73000, loss: 0.003719
 >> iter 74000, loss: 0.003531
 >> iter 75000, loss: 0.002289
 >> iter 76000, loss: 0.013874
 >> iter 77000, loss: 0.009708
 >> iter 78000, loss: 0.021283
 >> iter 79000, loss: 0.010447
 >> iter 80000, loss: 0.004674
   Number of active neurons: 10
 >> iter 81000, loss: 0.044657
 >> iter 82000, loss: 0.017678
 >> iter 83000, loss: 0.010183
 >> iter 84000, loss: 0.048690
 >> iter 85000, loss: 0.029030
 >> iter 86000, loss: 0.067956
 >> iter 87000, loss: 0.037391
 >> iter 88000, loss: 0.014977
 >> iter 89000, loss: 0.006650
 >> iter 90000, loss: 0.003458
   Number of active neurons: 10
 >> iter 91000, loss: 0.002526
 >> iter 92000, loss: 0.002091
 >> iter 93000, loss: 0.007288
 >> iter 94000, loss: 0.020275
 >> iter 95000, loss: 0.012113
 >> iter 96000, loss: 0.005591
 >> iter 97000, loss: 0.003084
 >> iter 98000, loss: 0.003652
 >> iter 99000, loss: 0.002636
 >> iter 100000, loss: 0.003514
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.864723
 >> iter 2000, loss: 9.550246
 >> iter 3000, loss: 4.501623
 >> iter 4000, loss: 2.097145
 >> iter 5000, loss: 1.188192
 >> iter 6000, loss: 0.694722
 >> iter 7000, loss: 0.617450
 >> iter 8000, loss: 0.282810
 >> iter 9000, loss: 0.200499
 >> iter 10000, loss: 0.199782
   Number of active neurons: 10
 >> iter 11000, loss: 0.118394
 >> iter 12000, loss: 0.136431
 >> iter 13000, loss: 0.095049
 >> iter 14000, loss: 0.133201
 >> iter 15000, loss: 0.080472
 >> iter 16000, loss: 0.078585
 >> iter 17000, loss: 0.112813
 >> iter 18000, loss: 0.092433
 >> iter 19000, loss: 0.120977
 >> iter 20000, loss: 0.051322
   Number of active neurons: 10
 >> iter 21000, loss: 0.024188
 >> iter 22000, loss: 0.015817
 >> iter 23000, loss: 0.009892
 >> iter 24000, loss: 0.006477
 >> iter 25000, loss: 0.005186
 >> iter 26000, loss: 0.007287
 >> iter 27000, loss: 0.005392
 >> iter 28000, loss: 0.004296
 >> iter 29000, loss: 0.003829
 >> iter 30000, loss: 0.008212
   Number of active neurons: 10
 >> iter 31000, loss: 0.005109
 >> iter 32000, loss: 0.027068
 >> iter 33000, loss: 0.012921
 >> iter 34000, loss: 0.012509
 >> iter 35000, loss: 0.007563
 >> iter 36000, loss: 0.156604
 >> iter 37000, loss: 0.060173
 >> iter 38000, loss: 0.041760
 >> iter 39000, loss: 0.019161
 >> iter 40000, loss: 0.033292
   Number of active neurons: 10
 >> iter 41000, loss: 0.014390
 >> iter 42000, loss: 0.006629
 >> iter 43000, loss: 0.003762
 >> iter 44000, loss: 0.002757
 >> iter 45000, loss: 0.003044
 >> iter 46000, loss: 0.002254
 >> iter 47000, loss: 0.001903
 >> iter 48000, loss: 0.133054
 >> iter 49000, loss: 0.052248
 >> iter 50000, loss: 0.021328
   Number of active neurons: 10
 >> iter 51000, loss: 0.009403
 >> iter 52000, loss: 0.005002
 >> iter 53000, loss: 0.003159
 >> iter 54000, loss: 0.002919
 >> iter 55000, loss: 0.004541
 >> iter 56000, loss: 0.002767
 >> iter 57000, loss: 0.002022
 >> iter 58000, loss: 0.001985
 >> iter 59000, loss: 0.001688
 >> iter 60000, loss: 0.002207
   Number of active neurons: 10
 >> iter 61000, loss: 0.001731
 >> iter 62000, loss: 0.001573
 >> iter 63000, loss: 0.001555
 >> iter 64000, loss: 0.001401
 >> iter 65000, loss: 0.074509
 >> iter 66000, loss: 0.032331
 >> iter 67000, loss: 0.013207
 >> iter 68000, loss: 0.005817
 >> iter 69000, loss: 0.003094
 >> iter 70000, loss: 0.001943
   Number of active neurons: 10
 >> iter 71000, loss: 0.002698
 >> iter 72000, loss: 0.062929
 >> iter 73000, loss: 0.025653
 >> iter 74000, loss: 0.010439
 >> iter 75000, loss: 0.004843
 >> iter 76000, loss: 0.002736
 >> iter 77000, loss: 0.001985
 >> iter 78000, loss: 0.001730
 >> iter 79000, loss: 0.001500
 >> iter 80000, loss: 0.001279
   Number of active neurons: 10
 >> iter 81000, loss: 0.021371
 >> iter 82000, loss: 0.008886
 >> iter 83000, loss: 0.004143
 >> iter 84000, loss: 0.002226
 >> iter 85000, loss: 0.001593
 >> iter 86000, loss: 0.001280
 >> iter 87000, loss: 0.001161
 >> iter 88000, loss: 0.001147
 >> iter 89000, loss: 0.001126
 >> iter 90000, loss: 0.025898
   Number of active neurons: 10
 >> iter 91000, loss: 0.011724
 >> iter 92000, loss: 0.039593
 >> iter 93000, loss: 0.016354
 >> iter 94000, loss: 0.006910
 >> iter 95000, loss: 0.003750
 >> iter 96000, loss: 0.002402
 >> iter 97000, loss: 0.008970
 >> iter 98000, loss: 0.058196
 >> iter 99000, loss: 0.022543
 >> iter 100000, loss: 0.009315
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.120828
 >> iter 2000, loss: 10.097554
 >> iter 3000, loss: 4.653971
 >> iter 4000, loss: 2.190588
 >> iter 5000, loss: 1.182022
 >> iter 6000, loss: 0.623731
 >> iter 7000, loss: 0.325258
 >> iter 8000, loss: 0.343318
 >> iter 9000, loss: 0.152145
 >> iter 10000, loss: 0.142158
   Number of active neurons: 10
 >> iter 11000, loss: 0.140078
 >> iter 12000, loss: 0.107561
 >> iter 13000, loss: 0.048008
 >> iter 14000, loss: 0.093698
 >> iter 15000, loss: 0.073989
 >> iter 16000, loss: 0.076231
 >> iter 17000, loss: 0.054279
 >> iter 18000, loss: 0.092525
 >> iter 19000, loss: 0.039738
 >> iter 20000, loss: 0.034821
   Number of active neurons: 10
 >> iter 21000, loss: 0.017480
 >> iter 22000, loss: 0.079908
 >> iter 23000, loss: 0.033432
 >> iter 24000, loss: 0.018794
 >> iter 25000, loss: 0.010246
 >> iter 26000, loss: 0.006238
 >> iter 27000, loss: 0.019164
 >> iter 28000, loss: 0.020531
 >> iter 29000, loss: 0.011616
 >> iter 30000, loss: 0.014810
   Number of active neurons: 10
 >> iter 31000, loss: 0.007929
 >> iter 32000, loss: 0.069164
 >> iter 33000, loss: 0.032215
 >> iter 34000, loss: 0.014305
 >> iter 35000, loss: 0.102145
 >> iter 36000, loss: 0.039670
 >> iter 37000, loss: 0.016323
 >> iter 38000, loss: 0.009959
 >> iter 39000, loss: 0.005476
 >> iter 40000, loss: 0.003362
   Number of active neurons: 10
 >> iter 41000, loss: 0.014000
 >> iter 42000, loss: 0.007358
 >> iter 43000, loss: 0.004005
 >> iter 44000, loss: 0.002698
 >> iter 45000, loss: 0.004648
 >> iter 46000, loss: 0.003256
 >> iter 47000, loss: 0.002733
 >> iter 48000, loss: 0.003637
 >> iter 49000, loss: 0.007147
 >> iter 50000, loss: 0.065962
   Number of active neurons: 10
 >> iter 51000, loss: 0.115175
 >> iter 52000, loss: 0.055640
 >> iter 53000, loss: 0.022613
 >> iter 54000, loss: 0.009652
 >> iter 55000, loss: 0.023045
 >> iter 56000, loss: 0.011495
 >> iter 57000, loss: 0.006683
 >> iter 58000, loss: 0.007358
 >> iter 59000, loss: 0.003916
 >> iter 60000, loss: 0.003081
   Number of active neurons: 10
 >> iter 61000, loss: 0.027539
 >> iter 62000, loss: 0.051373
 >> iter 63000, loss: 0.081766
 >> iter 64000, loss: 0.032464
 >> iter 65000, loss: 0.025310
 >> iter 66000, loss: 0.016444
 >> iter 67000, loss: 0.009683
 >> iter 68000, loss: 0.005287
 >> iter 69000, loss: 0.003451
 >> iter 70000, loss: 0.002861
   Number of active neurons: 10
 >> iter 71000, loss: 0.002035
 >> iter 72000, loss: 0.001682
 >> iter 73000, loss: 0.002562
 >> iter 74000, loss: 0.012067
 >> iter 75000, loss: 0.009946
 >> iter 76000, loss: 0.004673
 >> iter 77000, loss: 0.002686
 >> iter 78000, loss: 0.001886
 >> iter 79000, loss: 0.001404
 >> iter 80000, loss: 0.001267
   Number of active neurons: 10
 >> iter 81000, loss: 0.001244
 >> iter 82000, loss: 0.006173
 >> iter 83000, loss: 0.003256
 >> iter 84000, loss: 0.004245
 >> iter 85000, loss: 0.002215
 >> iter 86000, loss: 0.001495
 >> iter 87000, loss: 0.001478
 >> iter 88000, loss: 0.001157
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.995652
 >> iter 2000, loss: 11.133884
 >> iter 3000, loss: 5.621734
 >> iter 4000, loss: 2.681995
 >> iter 5000, loss: 1.108495
 >> iter 6000, loss: 0.915389
 >> iter 7000, loss: 0.488012
 >> iter 8000, loss: 0.359908
 >> iter 9000, loss: 0.350919
 >> iter 10000, loss: 0.167049
   Number of active neurons: 10
 >> iter 11000, loss: 0.163964
 >> iter 12000, loss: 0.070289
 >> iter 13000, loss: 0.142208
 >> iter 14000, loss: 0.068693
 >> iter 15000, loss: 0.144610
 >> iter 16000, loss: 0.060887
 >> iter 17000, loss: 0.238822
 >> iter 18000, loss: 0.140022
 >> iter 19000, loss: 0.078073
 >> iter 20000, loss: 0.183236
   Number of active neurons: 10
 >> iter 21000, loss: 0.074295
 >> iter 22000, loss: 0.032178
 >> iter 23000, loss: 0.016165
 >> iter 24000, loss: 0.012264
 >> iter 25000, loss: 0.008156
 >> iter 26000, loss: 0.005567
 >> iter 27000, loss: 0.015182
 >> iter 28000, loss: 0.008192
 >> iter 29000, loss: 0.004890
 >> iter 30000, loss: 0.003679
   Number of active neurons: 10
 >> iter 31000, loss: 0.005046
 >> iter 32000, loss: 0.003917
 >> iter 33000, loss: 0.017551
 >> iter 34000, loss: 0.010630
 >> iter 35000, loss: 0.013363
 >> iter 36000, loss: 0.007082
 >> iter 37000, loss: 0.004827
 >> iter 38000, loss: 0.057630
 >> iter 39000, loss: 0.024821
 >> iter 40000, loss: 0.078656
   Number of active neurons: 10
 >> iter 41000, loss: 0.031844
 >> iter 42000, loss: 0.014105
 >> iter 43000, loss: 0.007120
 >> iter 44000, loss: 0.013920
 >> iter 45000, loss: 0.010527
 >> iter 46000, loss: 0.005557
 >> iter 47000, loss: 0.117774
 >> iter 48000, loss: 0.046976
 >> iter 49000, loss: 0.019865
 >> iter 50000, loss: 0.028490
   Number of active neurons: 10
 >> iter 51000, loss: 0.013485
 >> iter 52000, loss: 0.006900
 >> iter 53000, loss: 0.004191
 >> iter 54000, loss: 0.003295
 >> iter 55000, loss: 0.012078
 >> iter 56000, loss: 0.005980
 >> iter 57000, loss: 0.003760
 >> iter 58000, loss: 0.065023
 >> iter 59000, loss: 0.199482
 >> iter 60000, loss: 0.076590
   Number of active neurons: 10
 >> iter 61000, loss: 0.030868
 >> iter 62000, loss: 0.014219
 >> iter 63000, loss: 0.007390
 >> iter 64000, loss: 0.004181
 >> iter 65000, loss: 0.003399
 >> iter 66000, loss: 0.002825
 >> iter 67000, loss: 0.002450
 >> iter 68000, loss: 0.002559
 >> iter 69000, loss: 0.001962
 >> iter 70000, loss: 0.001709
   Number of active neurons: 10
 >> iter 71000, loss: 0.001801
 >> iter 72000, loss: 0.001605
 >> iter 73000, loss: 0.011870
 >> iter 74000, loss: 0.005660
 >> iter 75000, loss: 0.034016
 >> iter 76000, loss: 0.013700
 >> iter 77000, loss: 0.006096
 >> iter 78000, loss: 0.280031
 >> iter 79000, loss: 0.105471
 >> iter 80000, loss: 0.040326
   Number of active neurons: 10
 >> iter 81000, loss: 0.016200
 >> iter 82000, loss: 0.007104
 >> iter 83000, loss: 0.003747
 >> iter 84000, loss: 0.002799
 >> iter 85000, loss: 0.002111
 >> iter 86000, loss: 0.001673
 >> iter 87000, loss: 0.002842
 >> iter 88000, loss: 0.002369
 >> iter 89000, loss: 0.014690
 >> iter 90000, loss: 0.006211
   Number of active neurons: 10
 >> iter 91000, loss: 0.003679
 >> iter 92000, loss: 0.002156
 >> iter 93000, loss: 0.002663
 >> iter 94000, loss: 0.001936
 >> iter 95000, loss: 0.001523
 >> iter 96000, loss: 0.001488
 >> iter 97000, loss: 0.001409
 >> iter 98000, loss: 0.052297
 >> iter 99000, loss: 0.020201
 >> iter 100000, loss: 0.014816
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.355996
 >> iter 2000, loss: 10.491518
 >> iter 3000, loss: 4.848445
 >> iter 4000, loss: 2.323969
 >> iter 5000, loss: 1.009215
 >> iter 6000, loss: 0.587181
 >> iter 7000, loss: 0.310267
 >> iter 8000, loss: 0.201932
 >> iter 9000, loss: 0.207585
 >> iter 10000, loss: 0.211372
   Number of active neurons: 10
 >> iter 11000, loss: 0.165797
 >> iter 12000, loss: 0.214307
 >> iter 13000, loss: 0.115680
 >> iter 14000, loss: 0.164525
 >> iter 15000, loss: 0.075518
 >> iter 16000, loss: 0.155331
 >> iter 17000, loss: 0.126168
 >> iter 18000, loss: 0.090944
 >> iter 19000, loss: 0.040292
 >> iter 20000, loss: 0.022113
   Number of active neurons: 10
 >> iter 21000, loss: 0.012219
 >> iter 22000, loss: 0.008457
 >> iter 23000, loss: 0.028100
 >> iter 24000, loss: 0.061508
 >> iter 25000, loss: 0.027360
 >> iter 26000, loss: 0.018695
 >> iter 27000, loss: 0.009599
 >> iter 28000, loss: 0.006278
 >> iter 29000, loss: 0.067051
 >> iter 30000, loss: 0.028098
   Number of active neurons: 10
 >> iter 31000, loss: 0.013312
 >> iter 32000, loss: 0.008195
 >> iter 33000, loss: 0.005097
 >> iter 34000, loss: 0.003687
 >> iter 35000, loss: 0.005880
 >> iter 36000, loss: 0.005723
 >> iter 37000, loss: 0.004928
 >> iter 38000, loss: 0.007471
 >> iter 39000, loss: 0.005738
 >> iter 40000, loss: 0.007507
   Number of active neurons: 10
 >> iter 41000, loss: 0.005155
 >> iter 42000, loss: 0.044873
 >> iter 43000, loss: 0.019084
 >> iter 44000, loss: 0.008392
 >> iter 45000, loss: 0.004406
 >> iter 46000, loss: 0.002999
 >> iter 47000, loss: 0.002195
 >> iter 48000, loss: 0.001947
 >> iter 49000, loss: 0.019348
 >> iter 50000, loss: 0.009043
   Number of active neurons: 10
 >> iter 51000, loss: 0.050956
 >> iter 52000, loss: 0.086814
 >> iter 53000, loss: 0.034375
 >> iter 54000, loss: 0.014534
 >> iter 55000, loss: 0.006901
 >> iter 56000, loss: 0.003892
 >> iter 57000, loss: 0.002825
 >> iter 58000, loss: 0.002201
 >> iter 59000, loss: 0.001928
 >> iter 60000, loss: 0.001655
   Number of active neurons: 10
 >> iter 61000, loss: 0.002165
 >> iter 62000, loss: 0.001856
 >> iter 63000, loss: 0.001525
 >> iter 64000, loss: 0.001394
 >> iter 65000, loss: 0.001366
 >> iter 66000, loss: 0.001334
 >> iter 67000, loss: 0.012578
 >> iter 68000, loss: 0.005491
 >> iter 69000, loss: 0.003459
 >> iter 70000, loss: 0.002750
   Number of active neurons: 10
 >> iter 71000, loss: 0.002416
 >> iter 72000, loss: 0.075540
 >> iter 73000, loss: 0.031909
 >> iter 74000, loss: 0.012644
 >> iter 75000, loss: 0.005499
 >> iter 76000, loss: 0.016501
 >> iter 77000, loss: 0.032516
 >> iter 78000, loss: 0.018076
 >> iter 79000, loss: 0.007926
 >> iter 80000, loss: 0.003678
   Number of active neurons: 10
 >> iter 81000, loss: 0.002024
 >> iter 82000, loss: 0.001468
 >> iter 83000, loss: 0.001387
 >> iter 84000, loss: 0.005420
 >> iter 85000, loss: 0.002777
 >> iter 86000, loss: 0.003446
 >> iter 87000, loss: 0.001937
 >> iter 88000, loss: 0.001369
 >> iter 89000, loss: 0.001279
 >> iter 90000, loss: 0.001033
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.289058
 >> iter 2000, loss: 10.816626
 >> iter 3000, loss: 5.675571
 >> iter 4000, loss: 2.823880
 >> iter 5000, loss: 1.342483
 >> iter 6000, loss: 1.155007
 >> iter 7000, loss: 0.557158
 >> iter 8000, loss: 0.508060
 >> iter 9000, loss: 0.616471
 >> iter 10000, loss: 0.394138
   Number of active neurons: 10
 >> iter 11000, loss: 0.200144
 >> iter 12000, loss: 0.119429
 >> iter 13000, loss: 0.156688
 >> iter 14000, loss: 0.087988
 >> iter 15000, loss: 0.219659
 >> iter 16000, loss: 0.140873
 >> iter 17000, loss: 0.069164
 >> iter 18000, loss: 0.040478
 >> iter 19000, loss: 0.347226
 >> iter 20000, loss: 0.209723
   Number of active neurons: 10
 >> iter 21000, loss: 0.154817
 >> iter 22000, loss: 0.153692
 >> iter 23000, loss: 0.073808
 >> iter 24000, loss: 0.084633
 >> iter 25000, loss: 0.075370
 >> iter 26000, loss: 0.089496
 >> iter 27000, loss: 0.068086
 >> iter 28000, loss: 0.030023
 >> iter 29000, loss: 0.031856
 >> iter 30000, loss: 0.016612
   Number of active neurons: 10
 >> iter 31000, loss: 0.010935
 >> iter 32000, loss: 0.054941
 >> iter 33000, loss: 0.023272
 >> iter 34000, loss: 0.109402
 >> iter 35000, loss: 0.044821
 >> iter 36000, loss: 0.019894
 >> iter 37000, loss: 0.010474
 >> iter 38000, loss: 0.249886
 >> iter 39000, loss: 0.098694
 >> iter 40000, loss: 0.043270
   Number of active neurons: 10
 >> iter 41000, loss: 0.048318
 >> iter 42000, loss: 0.034374
 >> iter 43000, loss: 0.017794
 >> iter 44000, loss: 0.015881
 >> iter 45000, loss: 0.016867
 >> iter 46000, loss: 0.055642
 >> iter 47000, loss: 0.104197
 >> iter 48000, loss: 0.049359
 >> iter 49000, loss: 0.124523
 >> iter 50000, loss: 0.049222
   Number of active neurons: 10
 >> iter 51000, loss: 0.020623
 >> iter 52000, loss: 0.010432
 >> iter 53000, loss: 0.006462
 >> iter 54000, loss: 0.004627
 >> iter 55000, loss: 0.004739
 >> iter 56000, loss: 0.091053
 >> iter 57000, loss: 0.037621
 >> iter 58000, loss: 0.016494
 >> iter 59000, loss: 0.008353
 >> iter 60000, loss: 0.004951
   Number of active neurons: 10
 >> iter 61000, loss: 0.003720
 >> iter 62000, loss: 0.003046
 >> iter 63000, loss: 0.002904
 >> iter 64000, loss: 0.002506
 >> iter 65000, loss: 0.008298
 >> iter 66000, loss: 0.088106
 >> iter 67000, loss: 0.034384
 >> iter 68000, loss: 0.015035
 >> iter 69000, loss: 0.011383
 >> iter 70000, loss: 0.006049
   Number of active neurons: 10
 >> iter 71000, loss: 0.004061
 >> iter 72000, loss: 0.019151
 >> iter 73000, loss: 0.008891
 >> iter 74000, loss: 0.005100
 >> iter 75000, loss: 0.003171
 >> iter 76000, loss: 0.002566
 >> iter 77000, loss: 0.002112
 >> iter 78000, loss: 0.013210
 >> iter 79000, loss: 0.152127
 >> iter 80000, loss: 0.087500
   Number of active neurons: 10
 >> iter 81000, loss: 0.040142
 >> iter 82000, loss: 0.016748
 >> iter 83000, loss: 0.007825
 >> iter 84000, loss: 0.004333
 >> iter 85000, loss: 0.002950
 >> iter 86000, loss: 0.013118
 >> iter 87000, loss: 0.010686
 >> iter 88000, loss: 0.008622
 >> iter 89000, loss: 0.005371
 >> iter 90000, loss: 0.003294
   Number of active neurons: 10
 >> iter 91000, loss: 0.008131
 >> iter 92000, loss: 0.004566
 >> iter 93000, loss: 0.003679
 >> iter 94000, loss: 0.002796
 >> iter 95000, loss: 0.002163
 >> iter 96000, loss: 0.001608
 >> iter 97000, loss: 0.001914
 >> iter 98000, loss: 0.003316
 >> iter 99000, loss: 0.023035
 >> iter 100000, loss: 0.009725
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.251827
 >> iter 2000, loss: 10.953952
 >> iter 3000, loss: 5.640945
 >> iter 4000, loss: 2.493740
 >> iter 5000, loss: 1.202096
 >> iter 6000, loss: 0.914215
 >> iter 7000, loss: 0.679496
 >> iter 8000, loss: 0.358737
 >> iter 9000, loss: 0.381474
 >> iter 10000, loss: 0.252351
   Number of active neurons: 10
 >> iter 11000, loss: 0.226189
 >> iter 12000, loss: 0.152573
 >> iter 13000, loss: 0.110809
 >> iter 14000, loss: 0.131417
 >> iter 15000, loss: 0.094639
 >> iter 16000, loss: 0.275001
 >> iter 17000, loss: 0.254260
 >> iter 18000, loss: 0.132893
 >> iter 19000, loss: 0.207367
 >> iter 20000, loss: 0.090171
   Number of active neurons: 10
 >> iter 21000, loss: 0.039706
 >> iter 22000, loss: 0.071589
 >> iter 23000, loss: 0.118503
 >> iter 24000, loss: 0.080565
 >> iter 25000, loss: 0.048019
 >> iter 26000, loss: 0.034673
 >> iter 27000, loss: 0.166600
 >> iter 28000, loss: 0.080233
 >> iter 29000, loss: 0.039374
 >> iter 30000, loss: 0.098911
   Number of active neurons: 10
 >> iter 31000, loss: 0.074721
 >> iter 32000, loss: 0.073293
 >> iter 33000, loss: 0.076787
 >> iter 34000, loss: 0.032882
 >> iter 35000, loss: 0.101402
 >> iter 36000, loss: 0.111710
 >> iter 37000, loss: 0.046487
 >> iter 38000, loss: 0.020060
 >> iter 39000, loss: 0.010041
 >> iter 40000, loss: 0.058215
   Number of active neurons: 10
 >> iter 41000, loss: 0.052106
 >> iter 42000, loss: 0.108634
 >> iter 43000, loss: 0.143176
 >> iter 44000, loss: 0.071226
 >> iter 45000, loss: 0.048784
 >> iter 46000, loss: 0.080107
 >> iter 47000, loss: 0.099469
 >> iter 48000, loss: 0.039324
 >> iter 49000, loss: 0.081633
 >> iter 50000, loss: 0.043548
   Number of active neurons: 10
 >> iter 51000, loss: 0.018351
 >> iter 52000, loss: 0.012630
 >> iter 53000, loss: 0.007348
 >> iter 54000, loss: 0.058738
 >> iter 55000, loss: 0.166690
 >> iter 56000, loss: 0.073615
 >> iter 57000, loss: 0.029817
 >> iter 58000, loss: 0.016087
 >> iter 59000, loss: 0.143471
 >> iter 60000, loss: 0.055156
   Number of active neurons: 10
 >> iter 61000, loss: 0.022969
 >> iter 62000, loss: 0.010185
 >> iter 63000, loss: 0.005285
 >> iter 64000, loss: 0.025027
 >> iter 65000, loss: 0.011198
 >> iter 66000, loss: 0.005601
 >> iter 67000, loss: 0.003370
 >> iter 68000, loss: 0.013465
 >> iter 69000, loss: 0.006524
 >> iter 70000, loss: 0.005867
   Number of active neurons: 10
 >> iter 71000, loss: 0.163340
 >> iter 72000, loss: 0.063011
 >> iter 73000, loss: 0.025298
 >> iter 74000, loss: 0.016098
 >> iter 75000, loss: 0.007495
 >> iter 76000, loss: 0.005016
 >> iter 77000, loss: 0.004616
 >> iter 78000, loss: 0.002844
 >> iter 79000, loss: 0.030778
 >> iter 80000, loss: 0.012939
   Number of active neurons: 10
 >> iter 81000, loss: 0.005917
 >> iter 82000, loss: 0.024220
 >> iter 83000, loss: 0.010327
 >> iter 84000, loss: 0.004908
 >> iter 85000, loss: 0.002729
 >> iter 86000, loss: 0.002471
 >> iter 87000, loss: 0.001649
 >> iter 88000, loss: 0.001354
 >> iter 89000, loss: 0.001172
 >> iter 90000, loss: 0.001817
   Number of active neurons: 10
 >> iter 91000, loss: 0.001289
 >> iter 92000, loss: 0.028869
 >> iter 93000, loss: 0.011520
 >> iter 94000, loss: 0.005206
 >> iter 95000, loss: 0.002580
 >> iter 96000, loss: 0.001832
 >> iter 97000, loss: 0.020453
 >> iter 98000, loss: 0.008302
 >> iter 99000, loss: 0.003750
 >> iter 100000, loss: 0.002099
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.015094
 >> iter 2000, loss: 10.054325
 >> iter 3000, loss: 4.559985
 >> iter 4000, loss: 2.101918
 >> iter 5000, loss: 1.137081
 >> iter 6000, loss: 0.838433
 >> iter 7000, loss: 0.605303
 >> iter 8000, loss: 0.306553
 >> iter 9000, loss: 0.246676
 >> iter 10000, loss: 0.217935
   Number of active neurons: 10
 >> iter 11000, loss: 0.138608
 >> iter 12000, loss: 0.063207
 >> iter 13000, loss: 0.057068
 >> iter 14000, loss: 0.044737
 >> iter 15000, loss: 0.129639
 >> iter 16000, loss: 0.060076
 >> iter 17000, loss: 0.096391
 >> iter 18000, loss: 0.188875
 >> iter 19000, loss: 0.117277
 >> iter 20000, loss: 0.073362
   Number of active neurons: 10
 >> iter 21000, loss: 0.032937
 >> iter 22000, loss: 0.016034
 >> iter 23000, loss: 0.150804
 >> iter 24000, loss: 0.060443
 >> iter 25000, loss: 0.086898
 >> iter 26000, loss: 0.037442
 >> iter 27000, loss: 0.031939
 >> iter 28000, loss: 0.169956
 >> iter 29000, loss: 0.083480
 >> iter 30000, loss: 0.131375
   Number of active neurons: 10
 >> iter 31000, loss: 0.058240
 >> iter 32000, loss: 0.034423
 >> iter 33000, loss: 0.021089
 >> iter 34000, loss: 0.043799
 >> iter 35000, loss: 0.019828
 >> iter 36000, loss: 0.023145
 >> iter 37000, loss: 0.011008
 >> iter 38000, loss: 0.042941
 >> iter 39000, loss: 0.022412
 >> iter 40000, loss: 0.071695
   Number of active neurons: 10
 >> iter 41000, loss: 0.092575
 >> iter 42000, loss: 0.090638
 >> iter 43000, loss: 0.038261
 >> iter 44000, loss: 0.016638
 >> iter 45000, loss: 0.008250
 >> iter 46000, loss: 0.004836
 >> iter 47000, loss: 0.003830
 >> iter 48000, loss: 0.004467
 >> iter 49000, loss: 0.003360
 >> iter 50000, loss: 0.004400
   Number of active neurons: 10
 >> iter 51000, loss: 0.003934
 >> iter 52000, loss: 0.022413
 >> iter 53000, loss: 0.010294
 >> iter 54000, loss: 0.004966
 >> iter 55000, loss: 0.003072
 >> iter 56000, loss: 0.002449
 >> iter 57000, loss: 0.002099
 >> iter 58000, loss: 0.003051
 >> iter 59000, loss: 0.002363
 >> iter 60000, loss: 0.003328
   Number of active neurons: 10
 >> iter 61000, loss: 0.002121
 >> iter 62000, loss: 0.001766
 >> iter 63000, loss: 0.001451
 >> iter 64000, loss: 0.001536
 >> iter 65000, loss: 0.001459
 >> iter 66000, loss: 0.001412
 >> iter 67000, loss: 0.005256
 >> iter 68000, loss: 0.002691
 >> iter 69000, loss: 0.008037
 >> iter 70000, loss: 0.009533
   Number of active neurons: 10
 >> iter 71000, loss: 0.053378
 >> iter 72000, loss: 0.020819
 >> iter 73000, loss: 0.059714
 >> iter 74000, loss: 0.023307
 >> iter 75000, loss: 0.044807
 >> iter 76000, loss: 0.025820
 >> iter 77000, loss: 0.107559
 >> iter 78000, loss: 0.111854
 >> iter 79000, loss: 0.074225
 >> iter 80000, loss: 0.030781
   Number of active neurons: 10
 >> iter 81000, loss: 0.013247
 >> iter 82000, loss: 0.009219
 >> iter 83000, loss: 0.005847
 >> iter 84000, loss: 0.003613
 >> iter 85000, loss: 0.002686
 >> iter 86000, loss: 0.002142
 >> iter 87000, loss: 0.002164
 >> iter 88000, loss: 0.002024
 >> iter 89000, loss: 0.018666
 >> iter 90000, loss: 0.008494
   Number of active neurons: 10
 >> iter 91000, loss: 0.004044
 >> iter 92000, loss: 0.002448
 >> iter 93000, loss: 0.001799
 >> iter 94000, loss: 0.001538
 >> iter 95000, loss: 0.001279
 >> iter 96000, loss: 0.001242
 >> iter 97000, loss: 0.001154
 >> iter 98000, loss: 0.001143
 >> iter 99000, loss: 0.001180
 >> iter 100000, loss: 0.001155
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.998634
 >> iter 2000, loss: 10.084809
 >> iter 3000, loss: 4.501313
 >> iter 4000, loss: 2.015684
 >> iter 5000, loss: 0.972782
 >> iter 6000, loss: 0.547777
 >> iter 7000, loss: 0.326158
 >> iter 8000, loss: 0.227480
 >> iter 9000, loss: 0.125195
 >> iter 10000, loss: 0.081945
   Number of active neurons: 10
 >> iter 11000, loss: 0.042057
 >> iter 12000, loss: 0.023717
 >> iter 13000, loss: 0.097489
 >> iter 14000, loss: 0.047615
 >> iter 15000, loss: 0.100063
 >> iter 16000, loss: 0.043125
 >> iter 17000, loss: 0.109397
 >> iter 18000, loss: 0.106137
 >> iter 19000, loss: 0.044480
 >> iter 20000, loss: 0.022661
   Number of active neurons: 10
 >> iter 21000, loss: 0.012399
 >> iter 22000, loss: 0.008229
 >> iter 23000, loss: 0.006062
 >> iter 24000, loss: 0.078591
 >> iter 25000, loss: 0.048251
 >> iter 26000, loss: 0.021118
 >> iter 27000, loss: 0.172117
 >> iter 28000, loss: 0.073773
 >> iter 29000, loss: 0.030993
 >> iter 30000, loss: 0.014604
   Number of active neurons: 10
 >> iter 31000, loss: 0.008355
 >> iter 32000, loss: 0.005640
 >> iter 33000, loss: 0.007194
 >> iter 34000, loss: 0.078085
 >> iter 35000, loss: 0.085531
 >> iter 36000, loss: 0.082025
 >> iter 37000, loss: 0.033745
 >> iter 38000, loss: 0.054699
 >> iter 39000, loss: 0.169147
 >> iter 40000, loss: 0.081158
   Number of active neurons: 10
 >> iter 41000, loss: 0.052680
 >> iter 42000, loss: 0.023135
 >> iter 43000, loss: 0.040084
 >> iter 44000, loss: 0.019389
 >> iter 45000, loss: 0.011637
 >> iter 46000, loss: 0.007741
 >> iter 47000, loss: 0.006598
 >> iter 48000, loss: 0.004925
 >> iter 49000, loss: 0.003872
 >> iter 50000, loss: 0.003077
   Number of active neurons: 10
 >> iter 51000, loss: 0.002757
 >> iter 52000, loss: 0.002584
 >> iter 53000, loss: 0.002312
 >> iter 54000, loss: 0.002081
 >> iter 55000, loss: 0.002042
 >> iter 56000, loss: 0.003890
 >> iter 57000, loss: 0.002887
 >> iter 58000, loss: 0.033644
 >> iter 59000, loss: 0.017473
 >> iter 60000, loss: 0.007712
   Number of active neurons: 10
 >> iter 61000, loss: 0.003995
 >> iter 62000, loss: 0.003396
 >> iter 63000, loss: 0.002411
 >> iter 64000, loss: 0.002139
 >> iter 65000, loss: 0.002186
 >> iter 66000, loss: 0.001722
 >> iter 67000, loss: 0.005333
 >> iter 68000, loss: 0.003020
 >> iter 69000, loss: 0.002248
 >> iter 70000, loss: 0.001779
   Number of active neurons: 10
 >> iter 71000, loss: 0.001442
 >> iter 72000, loss: 0.004553
 >> iter 73000, loss: 0.004175
 >> iter 74000, loss: 0.002627
 >> iter 75000, loss: 0.034798
 >> iter 76000, loss: 0.013855
 >> iter 77000, loss: 0.006659
 >> iter 78000, loss: 0.003257
 >> iter 79000, loss: 0.002147
 >> iter 80000, loss: 0.001631
   Number of active neurons: 10
 >> iter 81000, loss: 0.001333
 >> iter 82000, loss: 0.001231
 >> iter 83000, loss: 0.015941
 >> iter 84000, loss: 0.006617
 >> iter 85000, loss: 0.003113
 >> iter 86000, loss: 0.001806
 >> iter 87000, loss: 0.001394
 >> iter 88000, loss: 0.003020
 >> iter 89000, loss: 0.050302
 >> iter 90000, loss: 0.019353
   Number of active neurons: 10
 >> iter 91000, loss: 0.007867
 >> iter 92000, loss: 0.003635
 >> iter 93000, loss: 0.002578
 >> iter 94000, loss: 0.001742
 >> iter 95000, loss: 0.001444
 >> iter 96000, loss: 0.001180
 >> iter 97000, loss: 0.001049
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.055811
 >> iter 2000, loss: 10.400984
 >> iter 3000, loss: 5.307937
 >> iter 4000, loss: 2.529045
 >> iter 5000, loss: 1.433935
 >> iter 6000, loss: 0.908219
 >> iter 7000, loss: 0.424855
 >> iter 8000, loss: 0.399607
 >> iter 9000, loss: 0.309146
 >> iter 10000, loss: 0.328927
   Number of active neurons: 10
 >> iter 11000, loss: 0.274755
 >> iter 12000, loss: 0.330739
 >> iter 13000, loss: 0.139662
 >> iter 14000, loss: 0.085770
 >> iter 15000, loss: 0.102639
 >> iter 16000, loss: 0.089304
 >> iter 17000, loss: 0.091639
 >> iter 18000, loss: 0.059340
 >> iter 19000, loss: 0.032719
 >> iter 20000, loss: 0.016720
   Number of active neurons: 10
 >> iter 21000, loss: 0.075843
 >> iter 22000, loss: 0.032849
 >> iter 23000, loss: 0.029014
 >> iter 24000, loss: 0.014577
 >> iter 25000, loss: 0.037392
 >> iter 26000, loss: 0.018088
 >> iter 27000, loss: 0.127010
 >> iter 28000, loss: 0.065738
 >> iter 29000, loss: 0.038663
 >> iter 30000, loss: 0.019012
   Number of active neurons: 10
 >> iter 31000, loss: 0.010427
 >> iter 32000, loss: 0.067637
 >> iter 33000, loss: 0.077574
 >> iter 34000, loss: 0.067631
 >> iter 35000, loss: 0.029424
 >> iter 36000, loss: 0.016594
 >> iter 37000, loss: 0.008740
 >> iter 38000, loss: 0.014746
 >> iter 39000, loss: 0.064884
 >> iter 40000, loss: 0.034037
   Number of active neurons: 10
 >> iter 41000, loss: 0.014856
 >> iter 42000, loss: 0.007186
 >> iter 43000, loss: 0.116524
 >> iter 44000, loss: 0.047515
 >> iter 45000, loss: 0.019910
 >> iter 46000, loss: 0.037558
 >> iter 47000, loss: 0.017984
 >> iter 48000, loss: 0.087906
 >> iter 49000, loss: 0.035340
 >> iter 50000, loss: 0.016525
   Number of active neurons: 10
 >> iter 51000, loss: 0.008277
 >> iter 52000, loss: 0.006467
 >> iter 53000, loss: 0.013995
 >> iter 54000, loss: 0.006600
 >> iter 55000, loss: 0.022752
 >> iter 56000, loss: 0.015664
 >> iter 57000, loss: 0.008104
 >> iter 58000, loss: 0.006159
 >> iter 59000, loss: 0.003623
 >> iter 60000, loss: 0.016602
   Number of active neurons: 10
 >> iter 61000, loss: 0.007874
 >> iter 62000, loss: 0.004283
 >> iter 63000, loss: 0.056603
 >> iter 64000, loss: 0.022509
 >> iter 65000, loss: 0.009801
 >> iter 66000, loss: 0.085781
 >> iter 67000, loss: 0.034618
 >> iter 68000, loss: 0.022262
 >> iter 69000, loss: 0.010053
 >> iter 70000, loss: 0.004964
   Number of active neurons: 10
 >> iter 71000, loss: 0.003323
 >> iter 72000, loss: 0.002405
 >> iter 73000, loss: 0.002001
 >> iter 74000, loss: 0.001582
 >> iter 75000, loss: 0.001550
 >> iter 76000, loss: 0.001571
 >> iter 77000, loss: 0.001386
 >> iter 78000, loss: 0.001234
 >> iter 79000, loss: 0.001234
 >> iter 80000, loss: 0.002618
   Number of active neurons: 10
 >> iter 81000, loss: 0.006206
 >> iter 82000, loss: 0.003091
 >> iter 83000, loss: 0.002040
 >> iter 84000, loss: 0.001404
 >> iter 85000, loss: 0.001146
 >> iter 86000, loss: 0.001104
 >> iter 87000, loss: 0.001138
 >> iter 88000, loss: 0.065040
 >> iter 89000, loss: 0.025014
 >> iter 90000, loss: 0.009849
   Number of active neurons: 10
 >> iter 91000, loss: 0.018676
 >> iter 92000, loss: 0.007669
 >> iter 93000, loss: 0.007341
 >> iter 94000, loss: 0.004218
 >> iter 95000, loss: 0.002485
 >> iter 96000, loss: 0.002874
 >> iter 97000, loss: 0.001827
 >> iter 98000, loss: 0.001234
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.166461
 >> iter 2000, loss: 10.663484
 >> iter 3000, loss: 4.944562
 >> iter 4000, loss: 2.136929
 >> iter 5000, loss: 1.051212
 >> iter 6000, loss: 0.565591
 >> iter 7000, loss: 0.417987
 >> iter 8000, loss: 0.246666
 >> iter 9000, loss: 0.132348
 >> iter 10000, loss: 0.061280
   Number of active neurons: 10
 >> iter 11000, loss: 0.115322
 >> iter 12000, loss: 0.071160
 >> iter 13000, loss: 0.137898
 >> iter 14000, loss: 0.095243
 >> iter 15000, loss: 0.069943
 >> iter 16000, loss: 0.297034
 >> iter 17000, loss: 0.128446
 >> iter 18000, loss: 0.056402
 >> iter 19000, loss: 0.081226
 >> iter 20000, loss: 0.102323
   Number of active neurons: 10
 >> iter 21000, loss: 0.044742
 >> iter 22000, loss: 0.029671
 >> iter 23000, loss: 0.175460
 >> iter 24000, loss: 0.074637
 >> iter 25000, loss: 0.038097
 >> iter 26000, loss: 0.018978
 >> iter 27000, loss: 0.012809
 >> iter 28000, loss: 0.044937
 >> iter 29000, loss: 0.038866
 >> iter 30000, loss: 0.128062
   Number of active neurons: 10
 >> iter 31000, loss: 0.052070
 >> iter 32000, loss: 0.217100
 >> iter 33000, loss: 0.086799
 >> iter 34000, loss: 0.097243
 >> iter 35000, loss: 0.148647
 >> iter 36000, loss: 0.061413
 >> iter 37000, loss: 0.029968
 >> iter 38000, loss: 0.014156
 >> iter 39000, loss: 0.008387
 >> iter 40000, loss: 0.122471
   Number of active neurons: 10
 >> iter 41000, loss: 0.049322
 >> iter 42000, loss: 0.021572
 >> iter 43000, loss: 0.010274
 >> iter 44000, loss: 0.006355
 >> iter 45000, loss: 0.004226
 >> iter 46000, loss: 0.003502
 >> iter 47000, loss: 0.002944
 >> iter 48000, loss: 0.002670
 >> iter 49000, loss: 0.024717
 >> iter 50000, loss: 0.038638
   Number of active neurons: 10
 >> iter 51000, loss: 0.054961
 >> iter 52000, loss: 0.022256
 >> iter 53000, loss: 0.012617
 >> iter 54000, loss: 0.006447
 >> iter 55000, loss: 0.004577
 >> iter 56000, loss: 0.003122
 >> iter 57000, loss: 0.002749
 >> iter 58000, loss: 0.021441
 >> iter 59000, loss: 0.009825
 >> iter 60000, loss: 0.005008
   Number of active neurons: 10
 >> iter 61000, loss: 0.003156
 >> iter 62000, loss: 0.079549
 >> iter 63000, loss: 0.032520
 >> iter 64000, loss: 0.014289
 >> iter 65000, loss: 0.014787
 >> iter 66000, loss: 0.064058
 >> iter 67000, loss: 0.025266
 >> iter 68000, loss: 0.011016
 >> iter 69000, loss: 0.019173
 >> iter 70000, loss: 0.022938
   Number of active neurons: 10
 >> iter 71000, loss: 0.010129
 >> iter 72000, loss: 0.005499
 >> iter 73000, loss: 0.003325
 >> iter 74000, loss: 0.002279
 >> iter 75000, loss: 0.015369
 >> iter 76000, loss: 0.006661
 >> iter 77000, loss: 0.003648
 >> iter 78000, loss: 0.152550
 >> iter 79000, loss: 0.057367
 >> iter 80000, loss: 0.022237
   Number of active neurons: 10
 >> iter 81000, loss: 0.010886
 >> iter 82000, loss: 0.004959
 >> iter 83000, loss: 0.002754
 >> iter 84000, loss: 0.001873
 >> iter 85000, loss: 0.001835
 >> iter 86000, loss: 0.001482
 >> iter 87000, loss: 0.001546
 >> iter 88000, loss: 0.001265
 >> iter 89000, loss: 0.001535
 >> iter 90000, loss: 0.001244
   Number of active neurons: 10
 >> iter 91000, loss: 0.001305
 >> iter 92000, loss: 0.002677
 >> iter 93000, loss: 0.001662
 >> iter 94000, loss: 0.001236
 >> iter 95000, loss: 0.001444
 >> iter 96000, loss: 0.002511
 >> iter 97000, loss: 0.002937
 >> iter 98000, loss: 0.001642
 >> iter 99000, loss: 0.001241
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.999018
 >> iter 2000, loss: 10.305990
 >> iter 3000, loss: 5.392203
 >> iter 4000, loss: 2.447569
 >> iter 5000, loss: 1.507522
 >> iter 6000, loss: 1.023930
 >> iter 7000, loss: 0.553868
 >> iter 8000, loss: 0.622637
 >> iter 9000, loss: 0.707355
 >> iter 10000, loss: 0.341979
   Number of active neurons: 10
 >> iter 11000, loss: 0.205871
 >> iter 12000, loss: 0.105780
 >> iter 13000, loss: 0.384347
 >> iter 14000, loss: 0.251662
 >> iter 15000, loss: 0.231528
 >> iter 16000, loss: 0.207856
 >> iter 17000, loss: 0.219998
 >> iter 18000, loss: 0.122776
 >> iter 19000, loss: 0.215086
 >> iter 20000, loss: 0.165822
   Number of active neurons: 10
 >> iter 21000, loss: 0.122648
 >> iter 22000, loss: 0.111777
 >> iter 23000, loss: 0.115552
 >> iter 24000, loss: 0.124759
 >> iter 25000, loss: 0.051876
 >> iter 26000, loss: 0.023899
 >> iter 27000, loss: 0.088093
 >> iter 28000, loss: 0.124042
 >> iter 29000, loss: 0.102981
 >> iter 30000, loss: 0.158769
   Number of active neurons: 10
 >> iter 31000, loss: 0.065186
 >> iter 32000, loss: 0.077556
 >> iter 33000, loss: 0.077485
 >> iter 34000, loss: 0.033004
 >> iter 35000, loss: 0.019204
 >> iter 36000, loss: 0.064824
 >> iter 37000, loss: 0.027833
 >> iter 38000, loss: 0.056655
 >> iter 39000, loss: 0.057366
 >> iter 40000, loss: 0.042726
   Number of active neurons: 10
 >> iter 41000, loss: 0.018382
 >> iter 42000, loss: 0.009067
 >> iter 43000, loss: 0.040821
 >> iter 44000, loss: 0.136947
 >> iter 45000, loss: 0.115882
 >> iter 46000, loss: 0.050892
 >> iter 47000, loss: 0.026496
 >> iter 48000, loss: 0.012679
 >> iter 49000, loss: 0.006652
 >> iter 50000, loss: 0.013912
   Number of active neurons: 10
 >> iter 51000, loss: 0.016854
 >> iter 52000, loss: 0.010472
 >> iter 53000, loss: 0.057908
 >> iter 54000, loss: 0.023277
 >> iter 55000, loss: 0.010234
 >> iter 56000, loss: 0.005201
 >> iter 57000, loss: 0.014301
 >> iter 58000, loss: 0.007161
 >> iter 59000, loss: 0.017150
 >> iter 60000, loss: 0.008362
   Number of active neurons: 10
 >> iter 61000, loss: 0.004572
 >> iter 62000, loss: 0.003048
 >> iter 63000, loss: 0.125480
 >> iter 64000, loss: 0.048408
 >> iter 65000, loss: 0.057410
 >> iter 66000, loss: 0.032007
 >> iter 67000, loss: 0.013646
 >> iter 68000, loss: 0.006405
 >> iter 69000, loss: 0.080351
 >> iter 70000, loss: 0.038248
   Number of active neurons: 10
 >> iter 71000, loss: 0.020710
 >> iter 72000, loss: 0.009130
 >> iter 73000, loss: 0.004862
 >> iter 74000, loss: 0.015122
 >> iter 75000, loss: 0.007125
 >> iter 76000, loss: 0.109295
 >> iter 77000, loss: 0.043701
 >> iter 78000, loss: 0.077986
 >> iter 79000, loss: 0.031293
 >> iter 80000, loss: 0.039089
   Number of active neurons: 10
 >> iter 81000, loss: 0.060257
 >> iter 82000, loss: 0.024522
 >> iter 83000, loss: 0.010817
 >> iter 84000, loss: 0.047407
 >> iter 85000, loss: 0.019136
 >> iter 86000, loss: 0.009704
 >> iter 87000, loss: 0.005485
 >> iter 88000, loss: 0.003483
 >> iter 89000, loss: 0.004500
 >> iter 90000, loss: 0.002914
   Number of active neurons: 10
 >> iter 91000, loss: 0.002261
 >> iter 92000, loss: 0.003322
 >> iter 93000, loss: 0.002153
 >> iter 94000, loss: 0.001878
 >> iter 95000, loss: 0.001516
 >> iter 96000, loss: 0.001257
 >> iter 97000, loss: 0.001158
 >> iter 98000, loss: 0.001139
 >> iter 99000, loss: 0.001044
 >> iter 100000, loss: 0.001066
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.929953
 >> iter 2000, loss: 10.189905
 >> iter 3000, loss: 4.707118
 >> iter 4000, loss: 2.407429
 >> iter 5000, loss: 1.197676
 >> iter 6000, loss: 0.764352
 >> iter 7000, loss: 0.393687
 >> iter 8000, loss: 0.395017
 >> iter 9000, loss: 0.306229
 >> iter 10000, loss: 0.416769
   Number of active neurons: 10
 >> iter 11000, loss: 0.538515
 >> iter 12000, loss: 0.250060
 >> iter 13000, loss: 0.236207
 >> iter 14000, loss: 0.147937
 >> iter 15000, loss: 0.256188
 >> iter 16000, loss: 0.219454
 >> iter 17000, loss: 0.157898
 >> iter 18000, loss: 0.154661
 >> iter 19000, loss: 0.106956
 >> iter 20000, loss: 0.059272
   Number of active neurons: 10
 >> iter 21000, loss: 0.560256
 >> iter 22000, loss: 0.244453
 >> iter 23000, loss: 0.226522
 >> iter 24000, loss: 0.126904
 >> iter 25000, loss: 0.090514
 >> iter 26000, loss: 0.070835
 >> iter 27000, loss: 0.077572
 >> iter 28000, loss: 0.060425
 >> iter 29000, loss: 0.145300
 >> iter 30000, loss: 0.116021
   Number of active neurons: 10
 >> iter 31000, loss: 0.049230
 >> iter 32000, loss: 0.023985
 >> iter 33000, loss: 0.146235
 >> iter 34000, loss: 0.072404
 >> iter 35000, loss: 0.114535
 >> iter 36000, loss: 0.052980
 >> iter 37000, loss: 0.051703
 >> iter 38000, loss: 0.025678
 >> iter 39000, loss: 0.028085
 >> iter 40000, loss: 0.079436
   Number of active neurons: 10
 >> iter 41000, loss: 0.032878
 >> iter 42000, loss: 0.048417
 >> iter 43000, loss: 0.021113
 >> iter 44000, loss: 0.010512
 >> iter 45000, loss: 0.032233
 >> iter 46000, loss: 0.013976
 >> iter 47000, loss: 0.050928
 >> iter 48000, loss: 0.053849
 >> iter 49000, loss: 0.025207
 >> iter 50000, loss: 0.025227
   Number of active neurons: 10
 >> iter 51000, loss: 0.019650
 >> iter 52000, loss: 0.009162
 >> iter 53000, loss: 0.039155
 >> iter 54000, loss: 0.016879
 >> iter 55000, loss: 0.008233
 >> iter 56000, loss: 0.028324
 >> iter 57000, loss: 0.016695
 >> iter 58000, loss: 0.008250
 >> iter 59000, loss: 0.005601
 >> iter 60000, loss: 0.003523
   Number of active neurons: 10
 >> iter 61000, loss: 0.102441
 >> iter 62000, loss: 0.040183
 >> iter 63000, loss: 0.016946
 >> iter 64000, loss: 0.009099
 >> iter 65000, loss: 0.013552
 >> iter 66000, loss: 0.006353
 >> iter 67000, loss: 0.003566
 >> iter 68000, loss: 0.002392
 >> iter 69000, loss: 0.135852
 >> iter 70000, loss: 0.067616
   Number of active neurons: 10
 >> iter 71000, loss: 0.035432
 >> iter 72000, loss: 0.039286
 >> iter 73000, loss: 0.015796
 >> iter 74000, loss: 0.019898
 >> iter 75000, loss: 0.010537
 >> iter 76000, loss: 0.005515
 >> iter 77000, loss: 0.003263
 >> iter 78000, loss: 0.002237
 >> iter 79000, loss: 0.001896
 >> iter 80000, loss: 0.004141
   Number of active neurons: 10
 >> iter 81000, loss: 0.168421
 >> iter 82000, loss: 0.063383
 >> iter 83000, loss: 0.024597
 >> iter 84000, loss: 0.025741
 >> iter 85000, loss: 0.010912
 >> iter 86000, loss: 0.005398
 >> iter 87000, loss: 0.059574
 >> iter 88000, loss: 0.043134
 >> iter 89000, loss: 0.017749
 >> iter 90000, loss: 0.008562
   Number of active neurons: 10
 >> iter 91000, loss: 0.004693
 >> iter 92000, loss: 0.003003
 >> iter 93000, loss: 0.002240
 >> iter 94000, loss: 0.003669
 >> iter 95000, loss: 0.067034
 >> iter 96000, loss: 0.028011
 >> iter 97000, loss: 0.011608
 >> iter 98000, loss: 0.005511
 >> iter 99000, loss: 0.045120
 >> iter 100000, loss: 0.048662
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.173887
 >> iter 2000, loss: 10.514570
 >> iter 3000, loss: 5.242324
 >> iter 4000, loss: 2.538592
 >> iter 5000, loss: 1.474122
 >> iter 6000, loss: 0.724609
 >> iter 7000, loss: 0.370602
 >> iter 8000, loss: 0.166322
 >> iter 9000, loss: 0.188257
 >> iter 10000, loss: 0.228089
   Number of active neurons: 10
 >> iter 11000, loss: 0.120167
 >> iter 12000, loss: 0.256826
 >> iter 13000, loss: 0.126448
 >> iter 14000, loss: 0.105473
 >> iter 15000, loss: 0.312320
 >> iter 16000, loss: 0.251943
 >> iter 17000, loss: 0.142075
 >> iter 18000, loss: 0.221421
 >> iter 19000, loss: 0.170936
 >> iter 20000, loss: 0.071326
   Number of active neurons: 10
 >> iter 21000, loss: 0.032464
 >> iter 22000, loss: 0.017170
 >> iter 23000, loss: 0.034474
 >> iter 24000, loss: 0.017447
 >> iter 25000, loss: 0.010558
 >> iter 26000, loss: 0.009300
 >> iter 27000, loss: 0.006822
 >> iter 28000, loss: 0.005205
 >> iter 29000, loss: 0.004627
 >> iter 30000, loss: 0.004139
   Number of active neurons: 10
 >> iter 31000, loss: 0.005499
 >> iter 32000, loss: 0.004480
 >> iter 33000, loss: 0.004822
 >> iter 34000, loss: 0.003579
 >> iter 35000, loss: 0.134126
 >> iter 36000, loss: 0.123564
 >> iter 37000, loss: 0.048140
 >> iter 38000, loss: 0.019742
 >> iter 39000, loss: 0.009143
 >> iter 40000, loss: 0.006896
   Number of active neurons: 10
 >> iter 41000, loss: 0.006892
 >> iter 42000, loss: 0.004203
 >> iter 43000, loss: 0.004851
 >> iter 44000, loss: 0.020142
 >> iter 45000, loss: 0.037002
 >> iter 46000, loss: 0.015504
 >> iter 47000, loss: 0.008507
 >> iter 48000, loss: 0.009873
 >> iter 49000, loss: 0.005295
 >> iter 50000, loss: 0.003390
   Number of active neurons: 10
 >> iter 51000, loss: 0.002606
 >> iter 52000, loss: 0.002371
 >> iter 53000, loss: 0.002681
 >> iter 54000, loss: 0.002097
 >> iter 55000, loss: 0.027899
 >> iter 56000, loss: 0.011816
 >> iter 57000, loss: 0.137236
 >> iter 58000, loss: 0.353646
 >> iter 59000, loss: 0.134433
 >> iter 60000, loss: 0.059157
   Number of active neurons: 10
 >> iter 61000, loss: 0.057513
 >> iter 62000, loss: 0.024097
 >> iter 63000, loss: 0.017307
 >> iter 64000, loss: 0.030920
 >> iter 65000, loss: 0.013437
 >> iter 66000, loss: 0.032246
 >> iter 67000, loss: 0.013922
 >> iter 68000, loss: 0.051154
 >> iter 69000, loss: 0.037392
 >> iter 70000, loss: 0.015937
   Number of active neurons: 10
 >> iter 71000, loss: 0.007533
 >> iter 72000, loss: 0.004383
 >> iter 73000, loss: 0.003124
 >> iter 74000, loss: 0.002399
 >> iter 75000, loss: 0.023381
 >> iter 76000, loss: 0.010107
 >> iter 77000, loss: 0.092553
 >> iter 78000, loss: 0.038316
 >> iter 79000, loss: 0.015748
 >> iter 80000, loss: 0.007445
   Number of active neurons: 10
 >> iter 81000, loss: 0.028484
 >> iter 82000, loss: 0.018789
 >> iter 83000, loss: 0.008631
 >> iter 84000, loss: 0.017743
 >> iter 85000, loss: 0.008124
 >> iter 86000, loss: 0.004758
 >> iter 87000, loss: 0.003277
 >> iter 88000, loss: 0.002456
 >> iter 89000, loss: 0.002626
 >> iter 90000, loss: 0.002084
   Number of active neurons: 10
 >> iter 91000, loss: 0.001836
 >> iter 92000, loss: 0.001808
 >> iter 93000, loss: 0.049367
 >> iter 94000, loss: 0.019562
 >> iter 95000, loss: 0.008432
 >> iter 96000, loss: 0.004792
 >> iter 97000, loss: 0.003374
 >> iter 98000, loss: 0.002177
 >> iter 99000, loss: 0.001787
 >> iter 100000, loss: 0.002228
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.854249
 >> iter 2000, loss: 10.336158
 >> iter 3000, loss: 4.818594
 >> iter 4000, loss: 2.143284
 >> iter 5000, loss: 1.123729
 >> iter 6000, loss: 0.688966
 >> iter 7000, loss: 0.379710
 >> iter 8000, loss: 0.371568
 >> iter 9000, loss: 0.211036
 >> iter 10000, loss: 0.171491
   Number of active neurons: 10
 >> iter 11000, loss: 0.084961
 >> iter 12000, loss: 0.168003
 >> iter 13000, loss: 0.131508
 >> iter 14000, loss: 0.066610
 >> iter 15000, loss: 0.229592
 >> iter 16000, loss: 0.241603
 >> iter 17000, loss: 0.134864
 >> iter 18000, loss: 0.072108
 >> iter 19000, loss: 0.069601
 >> iter 20000, loss: 0.034201
   Number of active neurons: 10
 >> iter 21000, loss: 0.214290
 >> iter 22000, loss: 0.086185
 >> iter 23000, loss: 0.036696
 >> iter 24000, loss: 0.017606
 >> iter 25000, loss: 0.011702
 >> iter 26000, loss: 0.053201
 >> iter 27000, loss: 0.029825
 >> iter 28000, loss: 0.017129
 >> iter 29000, loss: 0.009808
 >> iter 30000, loss: 0.014687
   Number of active neurons: 10
 >> iter 31000, loss: 0.034333
 >> iter 32000, loss: 0.015022
 >> iter 33000, loss: 0.008672
 >> iter 34000, loss: 0.005403
 >> iter 35000, loss: 0.065648
 >> iter 36000, loss: 0.041333
 >> iter 37000, loss: 0.017834
 >> iter 38000, loss: 0.034976
 >> iter 39000, loss: 0.101992
 >> iter 40000, loss: 0.040866
   Number of active neurons: 10
 >> iter 41000, loss: 0.017656
 >> iter 42000, loss: 0.009282
 >> iter 43000, loss: 0.006521
 >> iter 44000, loss: 0.006938
 >> iter 45000, loss: 0.011157
 >> iter 46000, loss: 0.006024
 >> iter 47000, loss: 0.004075
 >> iter 48000, loss: 0.003065
 >> iter 49000, loss: 0.008893
 >> iter 50000, loss: 0.020957
   Number of active neurons: 10
 >> iter 51000, loss: 0.011039
 >> iter 52000, loss: 0.005802
 >> iter 53000, loss: 0.003372
 >> iter 54000, loss: 0.003371
 >> iter 55000, loss: 0.002439
 >> iter 56000, loss: 0.002164
 >> iter 57000, loss: 0.001837
 >> iter 58000, loss: 0.001641
 >> iter 59000, loss: 0.001766
 >> iter 60000, loss: 0.001788
   Number of active neurons: 10
 >> iter 61000, loss: 0.001540
 >> iter 62000, loss: 0.002059
 >> iter 63000, loss: 0.001653
 >> iter 64000, loss: 0.056394
 >> iter 65000, loss: 0.021647
 >> iter 66000, loss: 0.009319
 >> iter 67000, loss: 0.004413
 >> iter 68000, loss: 0.016006
 >> iter 69000, loss: 0.173950
 >> iter 70000, loss: 0.066224
   Number of active neurons: 10
 >> iter 71000, loss: 0.025973
 >> iter 72000, loss: 0.011358
 >> iter 73000, loss: 0.005831
 >> iter 74000, loss: 0.003453
 >> iter 75000, loss: 0.002507
 >> iter 76000, loss: 0.002072
 >> iter 77000, loss: 0.002041
 >> iter 78000, loss: 0.100278
 >> iter 79000, loss: 0.140374
 >> iter 80000, loss: 0.056148
   Number of active neurons: 10
 >> iter 81000, loss: 0.022458
 >> iter 82000, loss: 0.009774
 >> iter 83000, loss: 0.004921
 >> iter 84000, loss: 0.003231
 >> iter 85000, loss: 0.002723
 >> iter 86000, loss: 0.002152
 >> iter 87000, loss: 0.001945
 >> iter 88000, loss: 0.022243
 >> iter 89000, loss: 0.009410
 >> iter 90000, loss: 0.004831
   Number of active neurons: 10
 >> iter 91000, loss: 0.002985
 >> iter 92000, loss: 0.002406
 >> iter 93000, loss: 0.168341
 >> iter 94000, loss: 0.064235
 >> iter 95000, loss: 0.026661
 >> iter 96000, loss: 0.011157
 >> iter 97000, loss: 0.025137
 >> iter 98000, loss: 0.010900
 >> iter 99000, loss: 0.041732
 >> iter 100000, loss: 0.060404
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.092360
 >> iter 2000, loss: 10.260862
 >> iter 3000, loss: 5.319589
 >> iter 4000, loss: 2.515643
 >> iter 5000, loss: 1.498090
 >> iter 6000, loss: 0.958639
 >> iter 7000, loss: 0.787188
 >> iter 8000, loss: 0.370001
 >> iter 9000, loss: 0.184194
 >> iter 10000, loss: 0.251459
   Number of active neurons: 10
 >> iter 11000, loss: 0.196931
 >> iter 12000, loss: 0.198831
 >> iter 13000, loss: 0.084615
 >> iter 14000, loss: 0.319168
 >> iter 15000, loss: 0.464737
 >> iter 16000, loss: 0.541193
 >> iter 17000, loss: 0.265182
 >> iter 18000, loss: 0.107021
 >> iter 19000, loss: 0.115640
 >> iter 20000, loss: 0.091114
   Number of active neurons: 10
 >> iter 21000, loss: 0.056008
 >> iter 22000, loss: 0.060689
 >> iter 23000, loss: 0.031872
 >> iter 24000, loss: 0.047710
 >> iter 25000, loss: 0.114808
 >> iter 26000, loss: 0.166113
 >> iter 27000, loss: 0.090528
 >> iter 28000, loss: 0.115816
 >> iter 29000, loss: 0.184061
 >> iter 30000, loss: 0.107375
   Number of active neurons: 10
 >> iter 31000, loss: 0.097751
 >> iter 32000, loss: 0.179958
 >> iter 33000, loss: 0.077334
 >> iter 34000, loss: 0.058153
 >> iter 35000, loss: 0.230279
 >> iter 36000, loss: 0.122154
 >> iter 37000, loss: 0.050058
 >> iter 38000, loss: 0.021954
 >> iter 39000, loss: 0.025728
 >> iter 40000, loss: 0.016023
   Number of active neurons: 10
 >> iter 41000, loss: 0.053407
 >> iter 42000, loss: 0.070155
 >> iter 43000, loss: 0.035711
 >> iter 44000, loss: 0.097112
 >> iter 45000, loss: 0.090575
 >> iter 46000, loss: 0.037351
 >> iter 47000, loss: 0.016928
 >> iter 48000, loss: 0.010553
 >> iter 49000, loss: 0.052693
 >> iter 50000, loss: 0.022079
   Number of active neurons: 10
 >> iter 51000, loss: 0.010732
 >> iter 52000, loss: 0.006115
 >> iter 53000, loss: 0.093932
 >> iter 54000, loss: 0.038493
 >> iter 55000, loss: 0.061499
 >> iter 56000, loss: 0.076555
 >> iter 57000, loss: 0.036248
 >> iter 58000, loss: 0.113783
 >> iter 59000, loss: 0.062788
 >> iter 60000, loss: 0.026933
   Number of active neurons: 10
 >> iter 61000, loss: 0.013079
 >> iter 62000, loss: 0.008209
 >> iter 63000, loss: 0.004863
 >> iter 64000, loss: 0.008880
 >> iter 65000, loss: 0.012560
 >> iter 66000, loss: 0.006271
 >> iter 67000, loss: 0.020140
 >> iter 68000, loss: 0.009413
 >> iter 69000, loss: 0.005212
 >> iter 70000, loss: 0.003381
   Number of active neurons: 10
 >> iter 71000, loss: 0.002694
 >> iter 72000, loss: 0.001948
 >> iter 73000, loss: 0.019438
 >> iter 74000, loss: 0.017960
 >> iter 75000, loss: 0.482714
 >> iter 76000, loss: 0.183205
 >> iter 77000, loss: 0.070106
 >> iter 78000, loss: 0.098961
 >> iter 79000, loss: 0.040015
 >> iter 80000, loss: 0.017340
   Number of active neurons: 10
 >> iter 81000, loss: 0.022460
 >> iter 82000, loss: 0.013503
 >> iter 83000, loss: 0.014205
 >> iter 84000, loss: 0.027373
 >> iter 85000, loss: 0.027767
 >> iter 86000, loss: 0.167449
 >> iter 87000, loss: 0.117285
 >> iter 88000, loss: 0.051797
 >> iter 89000, loss: 0.061439
 >> iter 90000, loss: 0.025706
   Number of active neurons: 10
 >> iter 91000, loss: 0.081118
 >> iter 92000, loss: 0.039431
 >> iter 93000, loss: 0.020367
 >> iter 94000, loss: 0.013207
 >> iter 95000, loss: 0.006559
 >> iter 96000, loss: 0.003789
 >> iter 97000, loss: 0.002649
 >> iter 98000, loss: 0.002101
 >> iter 99000, loss: 0.001798
 >> iter 100000, loss: 0.001635
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.956646
 >> iter 2000, loss: 9.937075
 >> iter 3000, loss: 4.788055
 >> iter 4000, loss: 2.149524
 >> iter 5000, loss: 1.088087
 >> iter 6000, loss: 0.710071
 >> iter 7000, loss: 0.491321
 >> iter 8000, loss: 0.263623
 >> iter 9000, loss: 0.240772
 >> iter 10000, loss: 0.148505
   Number of active neurons: 10
 >> iter 11000, loss: 0.117582
 >> iter 12000, loss: 0.105422
 >> iter 13000, loss: 0.046975
 >> iter 14000, loss: 0.120403
 >> iter 15000, loss: 0.052674
 >> iter 16000, loss: 0.025545
 >> iter 17000, loss: 0.084443
 >> iter 18000, loss: 0.036994
 >> iter 19000, loss: 0.042518
 >> iter 20000, loss: 0.049976
   Number of active neurons: 10
 >> iter 21000, loss: 0.024591
 >> iter 22000, loss: 0.012769
 >> iter 23000, loss: 0.101506
 >> iter 24000, loss: 0.294524
 >> iter 25000, loss: 0.116695
 >> iter 26000, loss: 0.050628
 >> iter 27000, loss: 0.028544
 >> iter 28000, loss: 0.019681
 >> iter 29000, loss: 0.011395
 >> iter 30000, loss: 0.022601
   Number of active neurons: 10
 >> iter 31000, loss: 0.084547
 >> iter 32000, loss: 0.034815
 >> iter 33000, loss: 0.023640
 >> iter 34000, loss: 0.083093
 >> iter 35000, loss: 0.046797
 >> iter 36000, loss: 0.105901
 >> iter 37000, loss: 0.058495
 >> iter 38000, loss: 0.024775
 >> iter 39000, loss: 0.012009
 >> iter 40000, loss: 0.006585
   Number of active neurons: 10
 >> iter 41000, loss: 0.004726
 >> iter 42000, loss: 0.003558
 >> iter 43000, loss: 0.002954
 >> iter 44000, loss: 0.002884
 >> iter 45000, loss: 0.004186
 >> iter 46000, loss: 0.003350
 >> iter 47000, loss: 0.051944
 >> iter 48000, loss: 0.024458
 >> iter 49000, loss: 0.010850
 >> iter 50000, loss: 0.011053
   Number of active neurons: 10
 >> iter 51000, loss: 0.021621
 >> iter 52000, loss: 0.022119
 >> iter 53000, loss: 0.011399
 >> iter 54000, loss: 0.058409
 >> iter 55000, loss: 0.023864
 >> iter 56000, loss: 0.012103
 >> iter 57000, loss: 0.005780
 >> iter 58000, loss: 0.003276
 >> iter 59000, loss: 0.002329
 >> iter 60000, loss: 0.002221
   Number of active neurons: 10
 >> iter 61000, loss: 0.001892
 >> iter 62000, loss: 0.001665
 >> iter 63000, loss: 0.001591
 >> iter 64000, loss: 0.001625
 >> iter 65000, loss: 0.001562
 >> iter 66000, loss: 0.001447
 >> iter 67000, loss: 0.001574
 >> iter 68000, loss: 0.001700
 >> iter 69000, loss: 0.001495
 >> iter 70000, loss: 0.001261
   Number of active neurons: 10
 >> iter 71000, loss: 0.001164
 >> iter 72000, loss: 0.001105
 >> iter 73000, loss: 0.001072
 >> iter 74000, loss: 0.020506
 >> iter 75000, loss: 0.013447
 >> iter 76000, loss: 0.005728
 >> iter 77000, loss: 0.003429
 >> iter 78000, loss: 0.085297
 >> iter 79000, loss: 0.032396
 >> iter 80000, loss: 0.012807
   Number of active neurons: 10
 >> iter 81000, loss: 0.011789
 >> iter 82000, loss: 0.005198
 >> iter 83000, loss: 0.003862
 >> iter 84000, loss: 0.002304
 >> iter 85000, loss: 0.002456
 >> iter 86000, loss: 0.003147
 >> iter 87000, loss: 0.001846
 >> iter 88000, loss: 0.001510
 >> iter 89000, loss: 0.001817
 >> iter 90000, loss: 0.001685
   Number of active neurons: 10
 >> iter 91000, loss: 0.001592
 >> iter 92000, loss: 0.010113
 >> iter 93000, loss: 0.004794
 >> iter 94000, loss: 0.139087
 >> iter 95000, loss: 0.088228
 >> iter 96000, loss: 0.034292
 >> iter 97000, loss: 0.013553
 >> iter 98000, loss: 0.005875
 >> iter 99000, loss: 0.029831
 >> iter 100000, loss: 0.012681
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.157530
 >> iter 2000, loss: 10.382451
 >> iter 3000, loss: 4.890333
 >> iter 4000, loss: 2.722849
 >> iter 5000, loss: 1.488652
 >> iter 6000, loss: 0.858362
 >> iter 7000, loss: 0.434598
 >> iter 8000, loss: 0.319441
 >> iter 9000, loss: 0.247035
 >> iter 10000, loss: 0.125816
   Number of active neurons: 10
 >> iter 11000, loss: 0.196515
 >> iter 12000, loss: 0.137014
 >> iter 13000, loss: 0.092462
 >> iter 14000, loss: 0.059973
 >> iter 15000, loss: 0.199614
 >> iter 16000, loss: 0.099555
 >> iter 17000, loss: 0.044205
 >> iter 18000, loss: 0.075361
 >> iter 19000, loss: 0.103385
 >> iter 20000, loss: 0.063430
   Number of active neurons: 10
 >> iter 21000, loss: 0.028149
 >> iter 22000, loss: 0.100092
 >> iter 23000, loss: 0.085583
 >> iter 24000, loss: 0.211048
 >> iter 25000, loss: 0.096756
 >> iter 26000, loss: 0.043776
 >> iter 27000, loss: 0.033452
 >> iter 28000, loss: 0.018805
 >> iter 29000, loss: 0.010189
 >> iter 30000, loss: 0.007206
   Number of active neurons: 10
 >> iter 31000, loss: 0.005754
 >> iter 32000, loss: 0.004845
 >> iter 33000, loss: 0.004344
 >> iter 34000, loss: 0.003638
 >> iter 35000, loss: 0.007380
 >> iter 36000, loss: 0.057382
 >> iter 37000, loss: 0.023115
 >> iter 38000, loss: 0.010599
 >> iter 39000, loss: 0.006018
 >> iter 40000, loss: 0.007167
   Number of active neurons: 10
 >> iter 41000, loss: 0.019108
 >> iter 42000, loss: 0.008752
 >> iter 43000, loss: 0.007156
 >> iter 44000, loss: 0.116815
 >> iter 45000, loss: 0.045093
 >> iter 46000, loss: 0.018632
 >> iter 47000, loss: 0.057429
 >> iter 48000, loss: 0.025262
 >> iter 49000, loss: 0.058328
 >> iter 50000, loss: 0.024021
   Number of active neurons: 10
 >> iter 51000, loss: 0.051378
 >> iter 52000, loss: 0.106689
 >> iter 53000, loss: 0.044540
 >> iter 54000, loss: 0.018547
 >> iter 55000, loss: 0.008885
 >> iter 56000, loss: 0.004972
 >> iter 57000, loss: 0.003730
 >> iter 58000, loss: 0.002763
 >> iter 59000, loss: 0.002327
 >> iter 60000, loss: 0.002341
   Number of active neurons: 10
 >> iter 61000, loss: 0.002505
 >> iter 62000, loss: 0.041276
 >> iter 63000, loss: 0.016490
 >> iter 64000, loss: 0.007243
 >> iter 65000, loss: 0.004218
 >> iter 66000, loss: 0.048121
 >> iter 67000, loss: 0.020180
 >> iter 68000, loss: 0.008732
 >> iter 69000, loss: 0.004546
 >> iter 70000, loss: 0.016570
   Number of active neurons: 10
 >> iter 71000, loss: 0.007552
 >> iter 72000, loss: 0.004767
 >> iter 73000, loss: 0.003343
 >> iter 74000, loss: 0.002378
 >> iter 75000, loss: 0.001871
 >> iter 76000, loss: 0.001783
 >> iter 77000, loss: 0.002408
 >> iter 78000, loss: 0.034327
 >> iter 79000, loss: 0.013903
 >> iter 80000, loss: 0.007185
   Number of active neurons: 10
 >> iter 81000, loss: 0.039625
 >> iter 82000, loss: 0.016597
 >> iter 83000, loss: 0.007698
 >> iter 84000, loss: 0.005872
 >> iter 85000, loss: 0.003288
 >> iter 86000, loss: 0.002681
 >> iter 87000, loss: 0.002524
 >> iter 88000, loss: 0.001887
 >> iter 89000, loss: 0.001596
 >> iter 90000, loss: 0.001488
   Number of active neurons: 10
 >> iter 91000, loss: 0.001312
 >> iter 92000, loss: 0.001178
 >> iter 93000, loss: 0.001255
 >> iter 94000, loss: 0.001138
 >> iter 95000, loss: 0.001190
 >> iter 96000, loss: 0.001125
 >> iter 97000, loss: 0.001065
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

