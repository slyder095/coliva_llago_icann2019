 > Problema: tomita4nueva
 > Args:
   - Hidden size: 4
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.470507
 >> iter 2000, loss: 9.996948
 >> iter 3000, loss: 4.796283
 >> iter 4000, loss: 2.163866
 >> iter 5000, loss: 1.142373
 >> iter 6000, loss: 0.698718
 >> iter 7000, loss: 0.380319
 >> iter 8000, loss: 0.317261
 >> iter 9000, loss: 0.301293
 >> iter 10000, loss: 0.440478
   Number of active neurons: 4
 >> iter 11000, loss: 0.244660
 >> iter 12000, loss: 0.296274
 >> iter 13000, loss: 0.383279
 >> iter 14000, loss: 0.238216
 >> iter 15000, loss: 0.279913
 >> iter 16000, loss: 0.247713
 >> iter 17000, loss: 0.404682
 >> iter 18000, loss: 0.302849
 >> iter 19000, loss: 0.374617
 >> iter 20000, loss: 0.308660
   Number of active neurons: 3
 >> iter 21000, loss: 0.356680
 >> iter 22000, loss: 0.286294
 >> iter 23000, loss: 0.217555
 >> iter 24000, loss: 0.344385
 >> iter 25000, loss: 0.280612
 >> iter 26000, loss: 0.285483
 >> iter 27000, loss: 0.279741
 >> iter 28000, loss: 0.263244
 >> iter 29000, loss: 0.195187
 >> iter 30000, loss: 0.246820
   Number of active neurons: 3
 >> iter 31000, loss: 0.212222
 >> iter 32000, loss: 0.331453
 >> iter 33000, loss: 0.203587
 >> iter 34000, loss: 0.183889
 >> iter 35000, loss: 0.312319
 >> iter 36000, loss: 0.326789
 >> iter 37000, loss: 0.171050
 >> iter 38000, loss: 0.252774
 >> iter 39000, loss: 0.161775
 >> iter 40000, loss: 0.224080
   Number of active neurons: 3
 >> iter 41000, loss: 0.154287
 >> iter 42000, loss: 0.121057
 >> iter 43000, loss: 0.259616
 >> iter 44000, loss: 0.296170
 >> iter 45000, loss: 0.183914
 >> iter 46000, loss: 0.181024
 >> iter 47000, loss: 0.139969
 >> iter 48000, loss: 0.289829
 >> iter 49000, loss: 0.157550
 >> iter 50000, loss: 0.267548
   Number of active neurons: 3
 >> iter 51000, loss: 0.232044
 >> iter 52000, loss: 0.326714
 >> iter 53000, loss: 0.191317
 >> iter 54000, loss: 0.199887
 >> iter 55000, loss: 0.319827
 >> iter 56000, loss: 0.192794
 >> iter 57000, loss: 0.337741
 >> iter 58000, loss: 0.259294
 >> iter 59000, loss: 0.204900
 >> iter 60000, loss: 0.143753
   Number of active neurons: 3
 >> iter 61000, loss: 0.217757
 >> iter 62000, loss: 0.264337
 >> iter 63000, loss: 0.189164
 >> iter 64000, loss: 0.198711
 >> iter 65000, loss: 0.319953
 >> iter 66000, loss: 0.420685
 >> iter 67000, loss: 0.488225
 >> iter 68000, loss: 0.355537
 >> iter 69000, loss: 0.269745
 >> iter 70000, loss: 0.246053
   Number of active neurons: 3
 >> iter 71000, loss: 0.164488
 >> iter 72000, loss: 0.122049
 >> iter 73000, loss: 0.341275
 >> iter 74000, loss: 0.172244
 >> iter 75000, loss: 0.337307
 >> iter 76000, loss: 0.548562
 >> iter 77000, loss: 0.297203
 >> iter 78000, loss: 0.298390
 >> iter 79000, loss: 0.299816
 >> iter 80000, loss: 0.224665
   Number of active neurons: 3
 >> iter 81000, loss: 0.180891
 >> iter 82000, loss: 0.140820
 >> iter 83000, loss: 0.104617
 >> iter 84000, loss: 0.148461
 >> iter 85000, loss: 0.157954
 >> iter 86000, loss: 0.198379
 >> iter 87000, loss: 0.359710
 >> iter 88000, loss: 0.308538
 >> iter 89000, loss: 0.407901
 >> iter 90000, loss: 0.246178
   Number of active neurons: 3
 >> iter 91000, loss: 0.241278
 >> iter 92000, loss: 0.191002
 >> iter 93000, loss: 0.265475
 >> iter 94000, loss: 0.178874
 >> iter 95000, loss: 0.218035
 >> iter 96000, loss: 0.273830
 >> iter 97000, loss: 0.282914
 >> iter 98000, loss: 0.195146
 >> iter 99000, loss: 0.159817
 >> iter 100000, loss: 0.272406
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.171081
 >> iter 2000, loss: 10.850431
 >> iter 3000, loss: 6.064128
 >> iter 4000, loss: 3.128892
 >> iter 5000, loss: 1.737987
 >> iter 6000, loss: 1.105927
 >> iter 7000, loss: 0.863003
 >> iter 8000, loss: 0.630720
 >> iter 9000, loss: 0.663464
 >> iter 10000, loss: 0.541519
   Number of active neurons: 4
 >> iter 11000, loss: 0.645745
 >> iter 12000, loss: 0.644067
 >> iter 13000, loss: 0.556862
 >> iter 14000, loss: 0.509205
 >> iter 15000, loss: 0.499308
 >> iter 16000, loss: 0.435024
 >> iter 17000, loss: 0.309944
 >> iter 18000, loss: 0.626322
 >> iter 19000, loss: 0.485381
 >> iter 20000, loss: 0.574184
   Number of active neurons: 4
 >> iter 21000, loss: 0.615086
 >> iter 22000, loss: 0.361723
 >> iter 23000, loss: 0.623027
 >> iter 24000, loss: 0.608717
 >> iter 25000, loss: 0.570012
 >> iter 26000, loss: 0.321588
 >> iter 27000, loss: 0.405100
 >> iter 28000, loss: 0.437581
 >> iter 29000, loss: 0.431200
 >> iter 30000, loss: 0.573311
   Number of active neurons: 4
 >> iter 31000, loss: 0.558981
 >> iter 32000, loss: 0.623627
 >> iter 33000, loss: 0.693749
 >> iter 34000, loss: 0.470706
 >> iter 35000, loss: 0.587423
 >> iter 36000, loss: 0.498480
 >> iter 37000, loss: 0.492739
 >> iter 38000, loss: 0.425742
 >> iter 39000, loss: 0.502401
 >> iter 40000, loss: 0.447942
   Number of active neurons: 4
 >> iter 41000, loss: 0.404008
 >> iter 42000, loss: 0.250437
 >> iter 43000, loss: 0.352848
 >> iter 44000, loss: 0.396444
 >> iter 45000, loss: 0.453711
 >> iter 46000, loss: 0.396818
 >> iter 47000, loss: 0.419279
 >> iter 48000, loss: 0.340229
 >> iter 49000, loss: 0.330069
 >> iter 50000, loss: 0.633820
   Number of active neurons: 4
 >> iter 51000, loss: 0.374090
 >> iter 52000, loss: 0.517242
 >> iter 53000, loss: 0.452197
 >> iter 54000, loss: 0.421660
 >> iter 55000, loss: 0.455706
 >> iter 56000, loss: 0.498214
 >> iter 57000, loss: 0.333539
 >> iter 58000, loss: 0.450064
 >> iter 59000, loss: 0.422434
 >> iter 60000, loss: 0.334014
   Number of active neurons: 4
 >> iter 61000, loss: 0.294446
 >> iter 62000, loss: 0.365941
 >> iter 63000, loss: 0.366988
 >> iter 64000, loss: 0.724959
 >> iter 65000, loss: 0.763595
 >> iter 66000, loss: 0.460565
 >> iter 67000, loss: 0.443422
 >> iter 68000, loss: 0.340954
 >> iter 69000, loss: 0.314866
 >> iter 70000, loss: 0.327127
   Number of active neurons: 4
 >> iter 71000, loss: 0.389381
 >> iter 72000, loss: 0.580279
 >> iter 73000, loss: 0.449721
 >> iter 74000, loss: 0.605856
 >> iter 75000, loss: 0.452482
 >> iter 76000, loss: 0.404867
 >> iter 77000, loss: 0.255193
 >> iter 78000, loss: 0.223179
 >> iter 79000, loss: 0.300350
 >> iter 80000, loss: 0.265993
   Number of active neurons: 4
 >> iter 81000, loss: 0.317956
 >> iter 82000, loss: 0.345528
 >> iter 83000, loss: 0.218012
 >> iter 84000, loss: 0.350908
 >> iter 85000, loss: 0.363072
 >> iter 86000, loss: 0.401939
 >> iter 87000, loss: 0.380834
 >> iter 88000, loss: 0.410216
 >> iter 89000, loss: 0.242584
 >> iter 90000, loss: 0.499481
   Number of active neurons: 4
 >> iter 91000, loss: 0.403902
 >> iter 92000, loss: 0.366879
 >> iter 93000, loss: 0.253989
 >> iter 94000, loss: 0.261818
 >> iter 95000, loss: 0.211641
 >> iter 96000, loss: 0.203906
 >> iter 97000, loss: 0.331777
 >> iter 98000, loss: 0.338772
 >> iter 99000, loss: 0.355454
 >> iter 100000, loss: 0.458677
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.794889
 >> iter 2000, loss: 11.403529
 >> iter 3000, loss: 5.730140
 >> iter 4000, loss: 2.969801
 >> iter 5000, loss: 1.718228
 >> iter 6000, loss: 1.058645
 >> iter 7000, loss: 0.592761
 >> iter 8000, loss: 0.336423
 >> iter 9000, loss: 0.462379
 >> iter 10000, loss: 0.390596
   Number of active neurons: 4
 >> iter 11000, loss: 0.290435
 >> iter 12000, loss: 0.632777
 >> iter 13000, loss: 0.509718
 >> iter 14000, loss: 0.281895
 >> iter 15000, loss: 0.557500
 >> iter 16000, loss: 0.400807
 >> iter 17000, loss: 0.383889
 >> iter 18000, loss: 0.419208
 >> iter 19000, loss: 0.380376
 >> iter 20000, loss: 0.281367
   Number of active neurons: 4
 >> iter 21000, loss: 0.295946
 >> iter 22000, loss: 0.403872
 >> iter 23000, loss: 0.360485
 >> iter 24000, loss: 0.497286
 >> iter 25000, loss: 0.310801
 >> iter 26000, loss: 0.331928
 >> iter 27000, loss: 0.329629
 >> iter 28000, loss: 0.306957
 >> iter 29000, loss: 0.395429
 >> iter 30000, loss: 0.462389
   Number of active neurons: 4
 >> iter 31000, loss: 0.310989
 >> iter 32000, loss: 0.377281
 >> iter 33000, loss: 0.222640
 >> iter 34000, loss: 0.221924
 >> iter 35000, loss: 0.540869
 >> iter 36000, loss: 0.283965
 >> iter 37000, loss: 0.202263
 >> iter 38000, loss: 0.270647
 >> iter 39000, loss: 0.367803
 >> iter 40000, loss: 0.275250
   Number of active neurons: 4
 >> iter 41000, loss: 0.337745
 >> iter 42000, loss: 0.310458
 >> iter 43000, loss: 0.325292
 >> iter 44000, loss: 0.296566
 >> iter 45000, loss: 0.372603
 >> iter 46000, loss: 0.201653
 >> iter 47000, loss: 0.236417
 >> iter 48000, loss: 0.245803
 >> iter 49000, loss: 0.210980
 >> iter 50000, loss: 0.230211
   Number of active neurons: 4
 >> iter 51000, loss: 0.207276
 >> iter 52000, loss: 0.239194
 >> iter 53000, loss: 0.313003
 >> iter 54000, loss: 0.700187
 >> iter 55000, loss: 0.396709
 >> iter 56000, loss: 0.373073
 >> iter 57000, loss: 0.298819
 >> iter 58000, loss: 0.256782
 >> iter 59000, loss: 0.199857
 >> iter 60000, loss: 0.331166
   Number of active neurons: 4
 >> iter 61000, loss: 0.255816
 >> iter 62000, loss: 0.367523
 >> iter 63000, loss: 0.233388
 >> iter 64000, loss: 0.214558
 >> iter 65000, loss: 0.235628
 >> iter 66000, loss: 0.183354
 >> iter 67000, loss: 0.212750
 >> iter 68000, loss: 0.157498
 >> iter 69000, loss: 0.316432
 >> iter 70000, loss: 0.147518
   Number of active neurons: 4
 >> iter 71000, loss: 0.152315
 >> iter 72000, loss: 0.223466
 >> iter 73000, loss: 0.265829
 >> iter 74000, loss: 0.240294
 >> iter 75000, loss: 0.361427
 >> iter 76000, loss: 0.298763
 >> iter 77000, loss: 0.225139
 >> iter 78000, loss: 0.149588
 >> iter 79000, loss: 0.196834
 >> iter 80000, loss: 0.111952
   Number of active neurons: 3
 >> iter 81000, loss: 0.107980
 >> iter 82000, loss: 0.269256
 >> iter 83000, loss: 0.434069
 >> iter 84000, loss: 0.268826
 >> iter 85000, loss: 0.183959
 >> iter 86000, loss: 0.211772
 >> iter 87000, loss: 0.130956
 >> iter 88000, loss: 0.171407
 >> iter 89000, loss: 0.115886
 >> iter 90000, loss: 0.126072
   Number of active neurons: 3
 >> iter 91000, loss: 0.113404
 >> iter 92000, loss: 0.060965
 >> iter 93000, loss: 0.207756
 >> iter 94000, loss: 0.249342
 >> iter 95000, loss: 0.195198
 >> iter 96000, loss: 0.102427
 >> iter 97000, loss: 0.255813
 >> iter 98000, loss: 0.273267
 >> iter 99000, loss: 0.387790
 >> iter 100000, loss: 0.237210
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.464640
 >> iter 2000, loss: 11.357626
 >> iter 3000, loss: 6.010499
 >> iter 4000, loss: 2.680074
 >> iter 5000, loss: 1.354963
 >> iter 6000, loss: 0.801315
 >> iter 7000, loss: 0.639752
 >> iter 8000, loss: 0.750753
 >> iter 9000, loss: 0.413868
 >> iter 10000, loss: 0.406273
   Number of active neurons: 3
 >> iter 11000, loss: 0.244608
 >> iter 12000, loss: 0.267261
 >> iter 13000, loss: 0.272208
 >> iter 14000, loss: 0.198562
 >> iter 15000, loss: 0.370277
 >> iter 16000, loss: 0.317272
 >> iter 17000, loss: 0.359301
 >> iter 18000, loss: 0.324937
 >> iter 19000, loss: 0.344207
 >> iter 20000, loss: 0.284152
   Number of active neurons: 3
 >> iter 21000, loss: 0.245052
 >> iter 22000, loss: 0.322614
 >> iter 23000, loss: 0.261813
 >> iter 24000, loss: 0.310258
 >> iter 25000, loss: 0.189751
 >> iter 26000, loss: 0.364887
 >> iter 27000, loss: 0.240615
 >> iter 28000, loss: 0.187155
 >> iter 29000, loss: 0.326256
 >> iter 30000, loss: 0.423069
   Number of active neurons: 3
 >> iter 31000, loss: 0.357608
 >> iter 32000, loss: 0.254011
 >> iter 33000, loss: 0.376353
 >> iter 34000, loss: 0.511953
 >> iter 35000, loss: 0.243527
 >> iter 36000, loss: 0.255252
 >> iter 37000, loss: 0.338736
 >> iter 38000, loss: 0.310060
 >> iter 39000, loss: 0.260941
 >> iter 40000, loss: 0.239748
   Number of active neurons: 3
 >> iter 41000, loss: 0.240309
 >> iter 42000, loss: 0.297005
 >> iter 43000, loss: 0.350469
 >> iter 44000, loss: 0.418961
 >> iter 45000, loss: 0.401656
 >> iter 46000, loss: 0.430336
 >> iter 47000, loss: 0.360471
 >> iter 48000, loss: 0.217174
 >> iter 49000, loss: 0.273584
 >> iter 50000, loss: 0.387841
   Number of active neurons: 3
 >> iter 51000, loss: 0.271617
 >> iter 52000, loss: 0.296338
 >> iter 53000, loss: 0.254691
 >> iter 54000, loss: 0.197699
 >> iter 55000, loss: 0.256592
 >> iter 56000, loss: 0.307032
 >> iter 57000, loss: 0.380461
 >> iter 58000, loss: 0.406495
 >> iter 59000, loss: 0.379238
 >> iter 60000, loss: 0.414874
   Number of active neurons: 3
 >> iter 61000, loss: 0.281085
 >> iter 62000, loss: 0.252700
 >> iter 63000, loss: 0.216865
 >> iter 64000, loss: 0.160582
 >> iter 65000, loss: 0.154091
 >> iter 66000, loss: 0.128957
 >> iter 67000, loss: 0.198212
 >> iter 68000, loss: 0.281568
 >> iter 69000, loss: 0.141492
 >> iter 70000, loss: 0.366597
   Number of active neurons: 3
 >> iter 71000, loss: 0.298588
 >> iter 72000, loss: 0.351275
 >> iter 73000, loss: 0.398180
 >> iter 74000, loss: 0.254844
 >> iter 75000, loss: 0.178555
 >> iter 76000, loss: 0.288485
 >> iter 77000, loss: 0.278424
 >> iter 78000, loss: 0.225094
 >> iter 79000, loss: 0.335608
 >> iter 80000, loss: 0.314891
   Number of active neurons: 3
 >> iter 81000, loss: 0.191297
 >> iter 82000, loss: 0.296541
 >> iter 83000, loss: 0.330322
 >> iter 84000, loss: 0.267725
 >> iter 85000, loss: 0.148275
 >> iter 86000, loss: 0.286267
 >> iter 87000, loss: 0.265059
 >> iter 88000, loss: 0.369166
 >> iter 89000, loss: 0.285625
 >> iter 90000, loss: 0.197860
   Number of active neurons: 3
 >> iter 91000, loss: 0.217670
 >> iter 92000, loss: 0.319354
 >> iter 93000, loss: 0.312432
 >> iter 94000, loss: 0.386243
 >> iter 95000, loss: 0.387763
 >> iter 96000, loss: 0.183054
 >> iter 97000, loss: 0.182068
 >> iter 98000, loss: 0.146120
 >> iter 99000, loss: 0.191376
 >> iter 100000, loss: 0.183225
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.637178
 >> iter 2000, loss: 10.410819
 >> iter 3000, loss: 5.267362
 >> iter 4000, loss: 2.962877
 >> iter 5000, loss: 1.636407
 >> iter 6000, loss: 0.983783
 >> iter 7000, loss: 0.658242
 >> iter 8000, loss: 0.491879
 >> iter 9000, loss: 0.426912
 >> iter 10000, loss: 0.311275
   Number of active neurons: 4
 >> iter 11000, loss: 0.249395
 >> iter 12000, loss: 0.495171
 >> iter 13000, loss: 0.274741
 >> iter 14000, loss: 0.313916
 >> iter 15000, loss: 0.382437
 >> iter 16000, loss: 0.228742
 >> iter 17000, loss: 0.309126
 >> iter 18000, loss: 0.297681
 >> iter 19000, loss: 0.446937
 >> iter 20000, loss: 0.354595
   Number of active neurons: 4
 >> iter 21000, loss: 0.288822
 >> iter 22000, loss: 0.278937
 >> iter 23000, loss: 0.325042
 >> iter 24000, loss: 0.355528
 >> iter 25000, loss: 0.217608
 >> iter 26000, loss: 0.635742
 >> iter 27000, loss: 0.553146
 >> iter 28000, loss: 0.375384
 >> iter 29000, loss: 0.463803
 >> iter 30000, loss: 0.376959
   Number of active neurons: 4
 >> iter 31000, loss: 0.389074
 >> iter 32000, loss: 0.366386
 >> iter 33000, loss: 0.464539
 >> iter 34000, loss: 0.256101
 >> iter 35000, loss: 0.317881
 >> iter 36000, loss: 0.461614
 >> iter 37000, loss: 0.590548
 >> iter 38000, loss: 0.560554
 >> iter 39000, loss: 0.374791
 >> iter 40000, loss: 0.238799
   Number of active neurons: 4
 >> iter 41000, loss: 0.402578
 >> iter 42000, loss: 0.248564
 >> iter 43000, loss: 0.225935
 >> iter 44000, loss: 0.212435
 >> iter 45000, loss: 0.179255
 >> iter 46000, loss: 0.329714
 >> iter 47000, loss: 0.426837
 >> iter 48000, loss: 0.340122
 >> iter 49000, loss: 0.194709
 >> iter 50000, loss: 0.468343
   Number of active neurons: 4
 >> iter 51000, loss: 0.393702
 >> iter 52000, loss: 0.288652
 >> iter 53000, loss: 0.423021
 >> iter 54000, loss: 0.227156
 >> iter 55000, loss: 0.198414
 >> iter 56000, loss: 0.196054
 >> iter 57000, loss: 0.320969
 >> iter 58000, loss: 0.311746
 >> iter 59000, loss: 0.325820
 >> iter 60000, loss: 0.227545
   Number of active neurons: 3
 >> iter 61000, loss: 0.226772
 >> iter 62000, loss: 0.168514
 >> iter 63000, loss: 0.271821
 >> iter 64000, loss: 0.251547
 >> iter 65000, loss: 0.464713
 >> iter 66000, loss: 0.438286
 >> iter 67000, loss: 0.415928
 >> iter 68000, loss: 0.289431
 >> iter 69000, loss: 0.296712
 >> iter 70000, loss: 0.191144
   Number of active neurons: 3
 >> iter 71000, loss: 0.168932
 >> iter 72000, loss: 0.201694
 >> iter 73000, loss: 0.277708
 >> iter 74000, loss: 0.212048
 >> iter 75000, loss: 0.284793
 >> iter 76000, loss: 0.441366
 >> iter 77000, loss: 0.235694
 >> iter 78000, loss: 0.201373
 >> iter 79000, loss: 0.166246
 >> iter 80000, loss: 0.309463
   Number of active neurons: 3
 >> iter 81000, loss: 0.160047
 >> iter 82000, loss: 0.414321
 >> iter 83000, loss: 0.195452
 >> iter 84000, loss: 0.211948
 >> iter 85000, loss: 0.295375
 >> iter 86000, loss: 0.396796
 >> iter 87000, loss: 0.430432
 >> iter 88000, loss: 0.386716
 >> iter 89000, loss: 0.270587
 >> iter 90000, loss: 0.282621
   Number of active neurons: 3
 >> iter 91000, loss: 0.237746
 >> iter 92000, loss: 0.251109
 >> iter 93000, loss: 0.348586
 >> iter 94000, loss: 0.240192
 >> iter 95000, loss: 0.333805
 >> iter 96000, loss: 0.156208
 >> iter 97000, loss: 0.170233
 >> iter 98000, loss: 0.223615
 >> iter 99000, loss: 0.123399
 >> iter 100000, loss: 0.208809
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.623250
 >> iter 2000, loss: 9.753247
 >> iter 3000, loss: 4.557380
 >> iter 4000, loss: 2.297667
 >> iter 5000, loss: 1.169289
 >> iter 6000, loss: 0.670091
 >> iter 7000, loss: 0.621916
 >> iter 8000, loss: 0.409125
 >> iter 9000, loss: 0.528702
 >> iter 10000, loss: 0.302688
   Number of active neurons: 3
 >> iter 11000, loss: 0.261466
 >> iter 12000, loss: 0.288823
 >> iter 13000, loss: 0.268106
 >> iter 14000, loss: 0.282114
 >> iter 15000, loss: 0.301196
 >> iter 16000, loss: 0.240311
 >> iter 17000, loss: 0.576221
 >> iter 18000, loss: 0.526442
 >> iter 19000, loss: 0.342681
 >> iter 20000, loss: 0.306405
   Number of active neurons: 3
 >> iter 21000, loss: 0.273062
 >> iter 22000, loss: 0.378606
 >> iter 23000, loss: 0.368230
 >> iter 24000, loss: 0.372934
 >> iter 25000, loss: 0.270602
 >> iter 26000, loss: 0.236186
 >> iter 27000, loss: 0.251207
 >> iter 28000, loss: 0.286913
 >> iter 29000, loss: 0.493888
 >> iter 30000, loss: 0.360338
   Number of active neurons: 3
 >> iter 31000, loss: 0.421502
 >> iter 32000, loss: 0.246943
 >> iter 33000, loss: 0.311976
 >> iter 34000, loss: 0.233078
 >> iter 35000, loss: 0.191912
 >> iter 36000, loss: 0.219852
 >> iter 37000, loss: 0.323602
 >> iter 38000, loss: 0.380755
 >> iter 39000, loss: 0.332908
 >> iter 40000, loss: 0.211716
   Number of active neurons: 3
 >> iter 41000, loss: 0.178578
 >> iter 42000, loss: 0.173586
 >> iter 43000, loss: 0.224835
 >> iter 44000, loss: 0.343188
 >> iter 45000, loss: 0.279980
 >> iter 46000, loss: 0.310359
 >> iter 47000, loss: 0.305753
 >> iter 48000, loss: 0.479236
 >> iter 49000, loss: 0.317263
 >> iter 50000, loss: 0.236486
   Number of active neurons: 3
 >> iter 51000, loss: 0.199100
 >> iter 52000, loss: 0.319441
 >> iter 53000, loss: 0.328542
 >> iter 54000, loss: 0.377247
 >> iter 55000, loss: 0.226353
 >> iter 56000, loss: 0.148520
 >> iter 57000, loss: 0.118282
 >> iter 58000, loss: 0.119429
 >> iter 59000, loss: 0.175635
 >> iter 60000, loss: 0.318422
   Number of active neurons: 3
 >> iter 61000, loss: 0.374091
 >> iter 62000, loss: 0.411473
 >> iter 63000, loss: 0.594801
 >> iter 64000, loss: 0.366790
 >> iter 65000, loss: 0.318234
 >> iter 66000, loss: 0.196045
 >> iter 67000, loss: 0.145438
 >> iter 68000, loss: 0.203339
 >> iter 69000, loss: 0.123101
 >> iter 70000, loss: 0.194263
   Number of active neurons: 3
 >> iter 71000, loss: 0.211470
 >> iter 72000, loss: 0.164821
 >> iter 73000, loss: 0.204815
 >> iter 74000, loss: 0.301239
 >> iter 75000, loss: 0.383154
 >> iter 76000, loss: 0.313583
 >> iter 77000, loss: 0.270843
 >> iter 78000, loss: 0.193334
 >> iter 79000, loss: 0.231040
 >> iter 80000, loss: 0.189386
   Number of active neurons: 3
 >> iter 81000, loss: 0.162035
 >> iter 82000, loss: 0.310573
 >> iter 83000, loss: 0.338252
 >> iter 84000, loss: 0.381717
 >> iter 85000, loss: 0.236956
 >> iter 86000, loss: 0.305126
 >> iter 87000, loss: 0.397436
 >> iter 88000, loss: 0.280624
 >> iter 89000, loss: 0.239917
 >> iter 90000, loss: 0.226475
   Number of active neurons: 3
 >> iter 91000, loss: 0.230864
 >> iter 92000, loss: 0.247354
 >> iter 93000, loss: 0.156359
 >> iter 94000, loss: 0.239290
 >> iter 95000, loss: 0.453926
 >> iter 96000, loss: 0.367073
 >> iter 97000, loss: 0.203289
 >> iter 98000, loss: 0.280338
 >> iter 99000, loss: 0.247401
 >> iter 100000, loss: 0.261991
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.986030
 >> iter 2000, loss: 13.422853
 >> iter 3000, loss: 8.881499
 >> iter 4000, loss: 4.825414
 >> iter 5000, loss: 2.655116
 >> iter 6000, loss: 1.284528
 >> iter 7000, loss: 0.969794
 >> iter 8000, loss: 0.769799
 >> iter 9000, loss: 0.648137
 >> iter 10000, loss: 0.752531
   Number of active neurons: 4
 >> iter 11000, loss: 0.677709
 >> iter 12000, loss: 0.572195
 >> iter 13000, loss: 0.418576
 >> iter 14000, loss: 0.566830
 >> iter 15000, loss: 0.400034
 >> iter 16000, loss: 0.375222
 >> iter 17000, loss: 0.344393
 >> iter 18000, loss: 0.416584
 >> iter 19000, loss: 0.495414
 >> iter 20000, loss: 0.411002
   Number of active neurons: 4
 >> iter 21000, loss: 0.339134
 >> iter 22000, loss: 0.576852
 >> iter 23000, loss: 0.370981
 >> iter 24000, loss: 0.448506
 >> iter 25000, loss: 0.547133
 >> iter 26000, loss: 0.421283
 >> iter 27000, loss: 0.343473
 >> iter 28000, loss: 0.544316
 >> iter 29000, loss: 0.504627
 >> iter 30000, loss: 0.418279
   Number of active neurons: 4
 >> iter 31000, loss: 0.373236
 >> iter 32000, loss: 0.513562
 >> iter 33000, loss: 0.529516
 >> iter 34000, loss: 0.429124
 >> iter 35000, loss: 0.488723
 >> iter 36000, loss: 0.495365
 >> iter 37000, loss: 0.320879
 >> iter 38000, loss: 0.497928
 >> iter 39000, loss: 0.343591
 >> iter 40000, loss: 0.462599
   Number of active neurons: 4
 >> iter 41000, loss: 0.636510
 >> iter 42000, loss: 0.502413
 >> iter 43000, loss: 0.343500
 >> iter 44000, loss: 0.624258
 >> iter 45000, loss: 0.572459
 >> iter 46000, loss: 0.618254
 >> iter 47000, loss: 0.392374
 >> iter 48000, loss: 0.497617
 >> iter 49000, loss: 0.434713
 >> iter 50000, loss: 0.255641
   Number of active neurons: 4
 >> iter 51000, loss: 0.428515
 >> iter 52000, loss: 0.304952
 >> iter 53000, loss: 0.349179
 >> iter 54000, loss: 0.488114
 >> iter 55000, loss: 0.599678
 >> iter 56000, loss: 0.443642
 >> iter 57000, loss: 0.477358
 >> iter 58000, loss: 0.511383
 >> iter 59000, loss: 0.568996
 >> iter 60000, loss: 0.375488
   Number of active neurons: 4
 >> iter 61000, loss: 0.348798
 >> iter 62000, loss: 0.566543
 >> iter 63000, loss: 0.492172
 >> iter 64000, loss: 0.421716
 >> iter 65000, loss: 0.552814
 >> iter 66000, loss: 0.599386
 >> iter 67000, loss: 0.416022
 >> iter 68000, loss: 0.441503
 >> iter 69000, loss: 0.432522
 >> iter 70000, loss: 0.428527
   Number of active neurons: 4
 >> iter 71000, loss: 0.373892
 >> iter 72000, loss: 0.405133
 >> iter 73000, loss: 0.364893
 >> iter 74000, loss: 0.334575
 >> iter 75000, loss: 0.372432
 >> iter 76000, loss: 0.578526
 >> iter 77000, loss: 0.418462
 >> iter 78000, loss: 0.426672
 >> iter 79000, loss: 0.423777
 >> iter 80000, loss: 0.238100
   Number of active neurons: 4
 >> iter 81000, loss: 0.170821
 >> iter 82000, loss: 0.180210
 >> iter 83000, loss: 0.303182
 >> iter 84000, loss: 0.581520
 >> iter 85000, loss: 0.476277
 >> iter 86000, loss: 0.261045
 >> iter 87000, loss: 0.438656
 >> iter 88000, loss: 0.431918
 >> iter 89000, loss: 0.487310
 >> iter 90000, loss: 0.376364
   Number of active neurons: 4
 >> iter 91000, loss: 0.305553
 >> iter 92000, loss: 0.321221
 >> iter 93000, loss: 0.477953
 >> iter 94000, loss: 0.477406
 >> iter 95000, loss: 0.426197
 >> iter 96000, loss: 0.407261
 >> iter 97000, loss: 0.275958
 >> iter 98000, loss: 0.612604
 >> iter 99000, loss: 0.354408
 >> iter 100000, loss: 0.333407
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.619998
 >> iter 2000, loss: 9.520601
 >> iter 3000, loss: 4.507973
 >> iter 4000, loss: 2.019405
 >> iter 5000, loss: 1.139663
 >> iter 6000, loss: 0.652706
 >> iter 7000, loss: 0.374686
 >> iter 8000, loss: 0.275616
 >> iter 9000, loss: 0.275762
 >> iter 10000, loss: 0.229170
   Number of active neurons: 3
 >> iter 11000, loss: 0.299112
 >> iter 12000, loss: 0.369792
 >> iter 13000, loss: 0.331823
 >> iter 14000, loss: 0.222615
 >> iter 15000, loss: 0.325635
 >> iter 16000, loss: 0.490729
 >> iter 17000, loss: 0.273464
 >> iter 18000, loss: 0.237616
 >> iter 19000, loss: 0.282456
 >> iter 20000, loss: 0.268779
   Number of active neurons: 3
 >> iter 21000, loss: 0.269832
 >> iter 22000, loss: 0.349602
 >> iter 23000, loss: 0.233243
 >> iter 24000, loss: 0.213347
 >> iter 25000, loss: 0.165047
 >> iter 26000, loss: 0.127612
 >> iter 27000, loss: 0.366924
 >> iter 28000, loss: 0.237013
 >> iter 29000, loss: 0.184091
 >> iter 30000, loss: 0.200275
   Number of active neurons: 3
 >> iter 31000, loss: 0.232746
 >> iter 32000, loss: 0.386335
 >> iter 33000, loss: 0.272906
 >> iter 34000, loss: 0.284909
 >> iter 35000, loss: 0.201915
 >> iter 36000, loss: 0.189950
 >> iter 37000, loss: 0.176792
 >> iter 38000, loss: 0.186958
 >> iter 39000, loss: 0.660696
 >> iter 40000, loss: 0.352632
   Number of active neurons: 3
 >> iter 41000, loss: 0.359303
 >> iter 42000, loss: 0.287493
 >> iter 43000, loss: 0.391937
 >> iter 44000, loss: 0.261537
 >> iter 45000, loss: 0.189398
 >> iter 46000, loss: 0.237004
 >> iter 47000, loss: 0.145431
 >> iter 48000, loss: 0.168023
 >> iter 49000, loss: 0.200418
 >> iter 50000, loss: 0.127815
   Number of active neurons: 3
 >> iter 51000, loss: 0.215432
 >> iter 52000, loss: 0.222116
 >> iter 53000, loss: 0.167058
 >> iter 54000, loss: 0.285066
 >> iter 55000, loss: 0.223841
 >> iter 56000, loss: 0.240193
 >> iter 57000, loss: 0.136201
 >> iter 58000, loss: 0.346679
 >> iter 59000, loss: 0.282740
 >> iter 60000, loss: 0.200596
   Number of active neurons: 3
 >> iter 61000, loss: 0.167792
 >> iter 62000, loss: 0.187146
 >> iter 63000, loss: 0.163096
 >> iter 64000, loss: 0.165258
 >> iter 65000, loss: 0.232061
 >> iter 66000, loss: 0.241545
 >> iter 67000, loss: 0.245156
 >> iter 68000, loss: 0.322217
 >> iter 69000, loss: 0.463032
 >> iter 70000, loss: 0.346522
   Number of active neurons: 3
 >> iter 71000, loss: 0.190690
 >> iter 72000, loss: 0.167779
 >> iter 73000, loss: 0.162265
 >> iter 74000, loss: 0.126775
 >> iter 75000, loss: 0.170796
 >> iter 76000, loss: 0.106685
 >> iter 77000, loss: 0.181369
 >> iter 78000, loss: 0.203017
 >> iter 79000, loss: 0.174448
 >> iter 80000, loss: 0.181291
   Number of active neurons: 3
 >> iter 81000, loss: 0.237531
 >> iter 82000, loss: 0.477571
 >> iter 83000, loss: 0.334878
 >> iter 84000, loss: 0.342505
 >> iter 85000, loss: 0.331258
 >> iter 86000, loss: 0.325679
 >> iter 87000, loss: 0.329237
 >> iter 88000, loss: 0.346955
 >> iter 89000, loss: 0.306284
 >> iter 90000, loss: 0.305905
   Number of active neurons: 3
 >> iter 91000, loss: 0.170637
 >> iter 92000, loss: 0.195425
 >> iter 93000, loss: 0.236765
 >> iter 94000, loss: 0.291999
 >> iter 95000, loss: 0.151072
 >> iter 96000, loss: 0.281555
 >> iter 97000, loss: 0.376884
 >> iter 98000, loss: 0.353279
 >> iter 99000, loss: 0.289912
 >> iter 100000, loss: 0.206207
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 20.524759
 >> iter 2000, loss: 18.054282
 >> iter 3000, loss: 17.068463
 >> iter 4000, loss: 16.779359
 >> iter 5000, loss: 16.602165
 >> iter 6000, loss: 16.598188
 >> iter 7000, loss: 16.539946
 >> iter 8000, loss: 16.570970
 >> iter 9000, loss: 16.532183
 >> iter 10000, loss: 16.115703
   Number of active neurons: 1
 >> iter 11000, loss: 11.415857
 >> iter 12000, loss: 6.310364
 >> iter 13000, loss: 3.418124
 >> iter 14000, loss: 2.194945
 >> iter 15000, loss: 1.283637
 >> iter 16000, loss: 0.809173
 >> iter 17000, loss: 0.658917
 >> iter 18000, loss: 0.762558
 >> iter 19000, loss: 0.665085
 >> iter 20000, loss: 0.458562
   Number of active neurons: 4
 >> iter 21000, loss: 0.581185
 >> iter 22000, loss: 0.528901
 >> iter 23000, loss: 0.791589
 >> iter 24000, loss: 0.565041
 >> iter 25000, loss: 0.405307
 >> iter 26000, loss: 0.418318
 >> iter 27000, loss: 0.679571
 >> iter 28000, loss: 0.697973
 >> iter 29000, loss: 0.649676
 >> iter 30000, loss: 0.436268
   Number of active neurons: 4
 >> iter 31000, loss: 0.367300
 >> iter 32000, loss: 0.474235
 >> iter 33000, loss: 0.537371
 >> iter 34000, loss: 0.592433
 >> iter 35000, loss: 0.533357
 >> iter 36000, loss: 0.468624
 >> iter 37000, loss: 0.448708
 >> iter 38000, loss: 0.531883
 >> iter 39000, loss: 0.450316
 >> iter 40000, loss: 0.313755
   Number of active neurons: 4
 >> iter 41000, loss: 0.598354
 >> iter 42000, loss: 0.360507
 >> iter 43000, loss: 0.541612
 >> iter 44000, loss: 0.369958
 >> iter 45000, loss: 0.339734
 >> iter 46000, loss: 0.454351
 >> iter 47000, loss: 0.507900
 >> iter 48000, loss: 0.627432
 >> iter 49000, loss: 0.562937
 >> iter 50000, loss: 0.546817
   Number of active neurons: 4
 >> iter 51000, loss: 0.610800
 >> iter 52000, loss: 0.497531
 >> iter 53000, loss: 0.448467
 >> iter 54000, loss: 0.549066
 >> iter 55000, loss: 0.634181
 >> iter 56000, loss: 0.383328
 >> iter 57000, loss: 0.414552
 >> iter 58000, loss: 0.403233
 >> iter 59000, loss: 0.581721
 >> iter 60000, loss: 0.529418
   Number of active neurons: 4
 >> iter 61000, loss: 0.456844
 >> iter 62000, loss: 0.451686
 >> iter 63000, loss: 0.445367
 >> iter 64000, loss: 0.303124
 >> iter 65000, loss: 0.418138
 >> iter 66000, loss: 0.351914
 >> iter 67000, loss: 0.475911
 >> iter 68000, loss: 0.464131
 >> iter 69000, loss: 0.524151
 >> iter 70000, loss: 0.374516
   Number of active neurons: 4
 >> iter 71000, loss: 0.266092
 >> iter 72000, loss: 0.394766
 >> iter 73000, loss: 0.574343
 >> iter 74000, loss: 0.615421
 >> iter 75000, loss: 0.458195
 >> iter 76000, loss: 0.436967
 >> iter 77000, loss: 0.452700
 >> iter 78000, loss: 0.473634
 >> iter 79000, loss: 0.463362
 >> iter 80000, loss: 0.372253
   Number of active neurons: 4
 >> iter 81000, loss: 0.578774
 >> iter 82000, loss: 0.365797
 >> iter 83000, loss: 0.474847
 >> iter 84000, loss: 0.343689
 >> iter 85000, loss: 0.366574
 >> iter 86000, loss: 0.340533
 >> iter 87000, loss: 0.381392
 >> iter 88000, loss: 0.513018
 >> iter 89000, loss: 0.441474
 >> iter 90000, loss: 0.335798
   Number of active neurons: 4
 >> iter 91000, loss: 0.333079
 >> iter 92000, loss: 0.544579
 >> iter 93000, loss: 0.409136
 >> iter 94000, loss: 0.352387
 >> iter 95000, loss: 0.393184
 >> iter 96000, loss: 0.293971
 >> iter 97000, loss: 0.434735
 >> iter 98000, loss: 0.280963
 >> iter 99000, loss: 0.271790
 >> iter 100000, loss: 0.327544
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524760
 >> iter 2000, loss: 18.054282
 >> iter 3000, loss: 17.068462
 >> iter 4000, loss: 16.779363
 >> iter 5000, loss: 16.602167
 >> iter 6000, loss: 16.598184
 >> iter 7000, loss: 16.539943
 >> iter 8000, loss: 16.570968
 >> iter 9000, loss: 16.532181
 >> iter 10000, loss: 16.581926
   Number of active neurons: 0
 >> iter 11000, loss: 16.532518
 >> iter 12000, loss: 16.591970
 >> iter 13000, loss: 16.533414
 >> iter 14000, loss: 16.598204
 >> iter 15000, loss: 16.533571
 >> iter 16000, loss: 16.603671
 >> iter 17000, loss: 16.535597
 >> iter 18000, loss: 16.598725
 >> iter 19000, loss: 16.535939
 >> iter 20000, loss: 16.602351
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 16.535955
 >> iter 22000, loss: 16.246475
 >> iter 23000, loss: 12.146171
 >> iter 24000, loss: 6.386389
 >> iter 25000, loss: 3.598573
 >> iter 26000, loss: 2.025906
 >> iter 27000, loss: 1.261811
 >> iter 28000, loss: 0.968513
 >> iter 29000, loss: 0.795314
 >> iter 30000, loss: 0.614641
   Number of active neurons: 4
 >> iter 31000, loss: 0.414186
 >> iter 32000, loss: 0.577168
 >> iter 33000, loss: 0.478621
 >> iter 34000, loss: 0.467235
 >> iter 35000, loss: 0.595072
 >> iter 36000, loss: 0.417452
 >> iter 37000, loss: 0.475595
 >> iter 38000, loss: 0.492954
 >> iter 39000, loss: 0.398086
 >> iter 40000, loss: 0.383743
   Number of active neurons: 4
 >> iter 41000, loss: 0.480592
 >> iter 42000, loss: 0.533727
 >> iter 43000, loss: 0.533175
 >> iter 44000, loss: 0.457460
 >> iter 45000, loss: 0.319476
 >> iter 46000, loss: 0.246309
 >> iter 47000, loss: 0.313904
 >> iter 48000, loss: 0.384439
 >> iter 49000, loss: 0.272490
 >> iter 50000, loss: 0.446287
   Number of active neurons: 4
 >> iter 51000, loss: 0.508989
 >> iter 52000, loss: 0.487815
 >> iter 53000, loss: 0.467311
 >> iter 54000, loss: 0.387071
 >> iter 55000, loss: 0.516439
 >> iter 56000, loss: 0.503164
 >> iter 57000, loss: 0.351852
 >> iter 58000, loss: 0.387735
 >> iter 59000, loss: 0.539636
 >> iter 60000, loss: 0.373382
   Number of active neurons: 4
 >> iter 61000, loss: 0.301219
 >> iter 62000, loss: 0.248373
 >> iter 63000, loss: 0.485393
 >> iter 64000, loss: 0.313427
 >> iter 65000, loss: 0.401871
 >> iter 66000, loss: 0.399205
 >> iter 67000, loss: 0.580353
 >> iter 68000, loss: 0.575611
 >> iter 69000, loss: 0.497436
 >> iter 70000, loss: 0.726093
   Number of active neurons: 4
 >> iter 71000, loss: 0.650770
 >> iter 72000, loss: 0.467918
 >> iter 73000, loss: 0.407420
 >> iter 74000, loss: 0.318874
 >> iter 75000, loss: 0.666857
 >> iter 76000, loss: 0.511063
 >> iter 77000, loss: 0.384470
 >> iter 78000, loss: 0.283924
 >> iter 79000, loss: 0.404272
 >> iter 80000, loss: 0.502031
   Number of active neurons: 4
 >> iter 81000, loss: 0.471471
 >> iter 82000, loss: 0.461357
 >> iter 83000, loss: 0.598465
 >> iter 84000, loss: 0.476878
 >> iter 85000, loss: 0.442345
 >> iter 86000, loss: 0.317427
 >> iter 87000, loss: 0.289470
 >> iter 88000, loss: 0.355079
 >> iter 89000, loss: 0.546095
 >> iter 90000, loss: 0.523300
   Number of active neurons: 4
 >> iter 91000, loss: 0.329367
 >> iter 92000, loss: 0.420525
 >> iter 93000, loss: 0.350765
 >> iter 94000, loss: 0.385120
 >> iter 95000, loss: 0.477157
 >> iter 96000, loss: 0.339115
 >> iter 97000, loss: 0.256566
 >> iter 98000, loss: 0.317992
 >> iter 99000, loss: 0.526580
 >> iter 100000, loss: 0.398120
   Number of active neurons: 4
 >> iter 101000, loss: 0.542055
 >> iter 102000, loss: 0.298467
 >> iter 103000, loss: 0.310664
 >> iter 104000, loss: 0.306189
 >> iter 105000, loss: 0.309290
 >> iter 106000, loss: 0.320397
 >> iter 107000, loss: 0.295482
 >> iter 108000, loss: 0.263139
 >> iter 109000, loss: 0.512046
 >> iter 110000, loss: 0.327678
   Number of active neurons: 4
 >> iter 111000, loss: 0.321792
 >> iter 112000, loss: 0.224674
 >> iter 113000, loss: 0.232331
 >> iter 114000, loss: 0.424691
 >> iter 115000, loss: 0.325482
 >> iter 116000, loss: 0.447623
 >> iter 117000, loss: 0.378150
 >> iter 118000, loss: 0.637764
 >> iter 119000, loss: 0.507701
 >> iter 120000, loss: 0.348684
   Number of active neurons: 4
 >> iter 121000, loss: 0.259981
 >> iter 122000, loss: 0.477740
 >> iter 123000, loss: 0.310909
 >> iter 124000, loss: 0.359400
 >> iter 125000, loss: 0.538750
 >> iter 126000, loss: 0.376087
 >> iter 127000, loss: 0.451587
 >> iter 128000, loss: 0.354013
 >> iter 129000, loss: 0.251566
 >> iter 130000, loss: 0.520060
   Number of active neurons: 4
 >> iter 131000, loss: 0.551939
 >> iter 132000, loss: 0.386073
 >> iter 133000, loss: 0.320988
 >> iter 134000, loss: 0.481590
 >> iter 135000, loss: 0.522215
 >> iter 136000, loss: 0.389912
 >> iter 137000, loss: 0.307478
 >> iter 138000, loss: 0.361856
 >> iter 139000, loss: 0.384215
 >> iter 140000, loss: 0.448405
   Number of active neurons: 4
 >> iter 141000, loss: 0.288043
 >> iter 142000, loss: 0.281082
 >> iter 143000, loss: 0.222646
 >> iter 144000, loss: 0.224894
 >> iter 145000, loss: 0.204131
 >> iter 146000, loss: 0.320707
 >> iter 147000, loss: 0.440922
 >> iter 148000, loss: 0.391610
 >> iter 149000, loss: 0.321535
 >> iter 150000, loss: 0.317678
   Number of active neurons: 4
 >> iter 151000, loss: 0.213584
 >> iter 152000, loss: 0.298828
 >> iter 153000, loss: 0.179454
 >> iter 154000, loss: 0.149102
 >> iter 155000, loss: 0.251999
 >> iter 156000, loss: 0.251356
 >> iter 157000, loss: 0.470421
 >> iter 158000, loss: 0.391806
 >> iter 159000, loss: 0.336119
 >> iter 160000, loss: 0.499441
   Number of active neurons: 4
 >> iter 161000, loss: 0.630472
 >> iter 162000, loss: 0.354171
 >> iter 163000, loss: 0.191947
 >> iter 164000, loss: 0.320665
 >> iter 165000, loss: 0.278586
 >> iter 166000, loss: 0.289006
 >> iter 167000, loss: 0.353281
 >> iter 168000, loss: 0.237123
 >> iter 169000, loss: 0.349275
 >> iter 170000, loss: 0.342684
   Number of active neurons: 4
 >> iter 171000, loss: 0.381322
 >> iter 172000, loss: 0.335658
 >> iter 173000, loss: 0.312925
 >> iter 174000, loss: 0.395773
 >> iter 175000, loss: 0.500625
 >> iter 176000, loss: 0.330422
 >> iter 177000, loss: 0.372386
 >> iter 178000, loss: 0.294771
 >> iter 179000, loss: 0.361492
 >> iter 180000, loss: 0.293631
   Number of active neurons: 4
 >> iter 181000, loss: 0.414201
 >> iter 182000, loss: 0.495834
 >> iter 183000, loss: 0.289233
 >> iter 184000, loss: 0.290041
 >> iter 185000, loss: 0.310587
 >> iter 186000, loss: 0.269176
 >> iter 187000, loss: 0.242373
 >> iter 188000, loss: 0.317501
 >> iter 189000, loss: 0.293621
 >> iter 190000, loss: 0.400635
   Number of active neurons: 4
 >> iter 191000, loss: 0.319038
 >> iter 192000, loss: 0.244678
 >> iter 193000, loss: 0.459383
 >> iter 194000, loss: 0.375245
 >> iter 195000, loss: 0.271513
 >> iter 196000, loss: 0.480058
 >> iter 197000, loss: 0.308507
 >> iter 198000, loss: 0.418670
 >> iter 199000, loss: 0.540375
 >> iter 200000, loss: 0.537411
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.792836
 >> iter 2000, loss: 11.712266
 >> iter 3000, loss: 6.179479
 >> iter 4000, loss: 3.188202
 >> iter 5000, loss: 1.876684
 >> iter 6000, loss: 1.100329
 >> iter 7000, loss: 0.860416
 >> iter 8000, loss: 0.743366
 >> iter 9000, loss: 0.665680
 >> iter 10000, loss: 0.718397
   Number of active neurons: 4
 >> iter 11000, loss: 0.507848
 >> iter 12000, loss: 0.514632
 >> iter 13000, loss: 0.304380
 >> iter 14000, loss: 0.474489
 >> iter 15000, loss: 0.569556
 >> iter 16000, loss: 0.410557
 >> iter 17000, loss: 0.352483
 >> iter 18000, loss: 0.442990
 >> iter 19000, loss: 0.523858
 >> iter 20000, loss: 0.389697
   Number of active neurons: 4
 >> iter 21000, loss: 0.616739
 >> iter 22000, loss: 0.523642
 >> iter 23000, loss: 0.542507
 >> iter 24000, loss: 0.496512
 >> iter 25000, loss: 0.333734
 >> iter 26000, loss: 0.325888
 >> iter 27000, loss: 0.368255
 >> iter 28000, loss: 0.415442
 >> iter 29000, loss: 0.261691
 >> iter 30000, loss: 0.410812
   Number of active neurons: 4
 >> iter 31000, loss: 0.428103
 >> iter 32000, loss: 0.296651
 >> iter 33000, loss: 0.744971
 >> iter 34000, loss: 0.499146
 >> iter 35000, loss: 0.530952
 >> iter 36000, loss: 0.757492
 >> iter 37000, loss: 0.529055
 >> iter 38000, loss: 0.433222
 >> iter 39000, loss: 0.333034
 >> iter 40000, loss: 0.649212
   Number of active neurons: 4
 >> iter 41000, loss: 0.550279
 >> iter 42000, loss: 0.505729
 >> iter 43000, loss: 0.595829
 >> iter 44000, loss: 0.528039
 >> iter 45000, loss: 0.337652
 >> iter 46000, loss: 0.372276
 >> iter 47000, loss: 0.433262
 >> iter 48000, loss: 0.503143
 >> iter 49000, loss: 0.467483
 >> iter 50000, loss: 0.378426
   Number of active neurons: 4
 >> iter 51000, loss: 0.391562
 >> iter 52000, loss: 0.337149
 >> iter 53000, loss: 0.287240
 >> iter 54000, loss: 0.463242
 >> iter 55000, loss: 0.501724
 >> iter 56000, loss: 0.354250
 >> iter 57000, loss: 0.292855
 >> iter 58000, loss: 0.304762
 >> iter 59000, loss: 0.272495
 >> iter 60000, loss: 0.276710
   Number of active neurons: 4
 >> iter 61000, loss: 0.455254
 >> iter 62000, loss: 0.355418
 >> iter 63000, loss: 0.471328
 >> iter 64000, loss: 0.526879
 >> iter 65000, loss: 0.309260
 >> iter 66000, loss: 0.576665
 >> iter 67000, loss: 0.522499
 >> iter 68000, loss: 0.354600
 >> iter 69000, loss: 0.436923
 >> iter 70000, loss: 0.629465
   Number of active neurons: 4
 >> iter 71000, loss: 0.359561
 >> iter 72000, loss: 0.572033
 >> iter 73000, loss: 0.345764
 >> iter 74000, loss: 0.228012
 >> iter 75000, loss: 0.356638
 >> iter 76000, loss: 0.337028
 >> iter 77000, loss: 0.393918
 >> iter 78000, loss: 0.389914
 >> iter 79000, loss: 0.467436
 >> iter 80000, loss: 0.445730
   Number of active neurons: 4
 >> iter 81000, loss: 0.309599
 >> iter 82000, loss: 0.328679
 >> iter 83000, loss: 0.325721
 >> iter 84000, loss: 0.378865
 >> iter 85000, loss: 0.500867
 >> iter 86000, loss: 0.573300
 >> iter 87000, loss: 0.406552
 >> iter 88000, loss: 0.278459
 >> iter 89000, loss: 0.380062
 >> iter 90000, loss: 0.382512
   Number of active neurons: 4
 >> iter 91000, loss: 0.491386
 >> iter 92000, loss: 0.364593
 >> iter 93000, loss: 0.262863
 >> iter 94000, loss: 0.260831
 >> iter 95000, loss: 0.304168
 >> iter 96000, loss: 0.339866
 >> iter 97000, loss: 0.285842
 >> iter 98000, loss: 0.330004
 >> iter 99000, loss: 0.357428
 >> iter 100000, loss: 0.226798
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.338158
 >> iter 2000, loss: 11.668752
 >> iter 3000, loss: 7.695927
 >> iter 4000, loss: 3.677140
 >> iter 5000, loss: 1.852205
 >> iter 6000, loss: 1.028154
 >> iter 7000, loss: 0.626317
 >> iter 8000, loss: 0.367930
 >> iter 9000, loss: 0.459647
 >> iter 10000, loss: 0.281516
   Number of active neurons: 4
 >> iter 11000, loss: 0.361776
 >> iter 12000, loss: 0.441806
 >> iter 13000, loss: 0.293265
 >> iter 14000, loss: 0.500431
 >> iter 15000, loss: 0.383277
 >> iter 16000, loss: 0.210749
 >> iter 17000, loss: 0.297000
 >> iter 18000, loss: 0.342831
 >> iter 19000, loss: 0.427471
 >> iter 20000, loss: 0.358928
   Number of active neurons: 4
 >> iter 21000, loss: 0.203760
 >> iter 22000, loss: 0.189884
 >> iter 23000, loss: 0.219787
 >> iter 24000, loss: 0.162293
 >> iter 25000, loss: 0.172345
 >> iter 26000, loss: 0.281900
 >> iter 27000, loss: 0.538570
 >> iter 28000, loss: 0.368902
 >> iter 29000, loss: 0.302907
 >> iter 30000, loss: 0.429594
   Number of active neurons: 4
 >> iter 31000, loss: 0.408033
 >> iter 32000, loss: 0.410474
 >> iter 33000, loss: 0.306363
 >> iter 34000, loss: 0.541873
 >> iter 35000, loss: 0.294252
 >> iter 36000, loss: 0.352716
 >> iter 37000, loss: 0.285808
 >> iter 38000, loss: 0.337547
 >> iter 39000, loss: 0.304071
 >> iter 40000, loss: 0.379773
   Number of active neurons: 4
 >> iter 41000, loss: 0.221898
 >> iter 42000, loss: 0.157206
 >> iter 43000, loss: 0.198612
 >> iter 44000, loss: 0.237989
 >> iter 45000, loss: 0.352359
 >> iter 46000, loss: 0.235678
 >> iter 47000, loss: 0.335268
 >> iter 48000, loss: 0.230960
 >> iter 49000, loss: 0.242476
 >> iter 50000, loss: 0.198823
   Number of active neurons: 3
 >> iter 51000, loss: 0.287116
 >> iter 52000, loss: 0.308049
 >> iter 53000, loss: 0.340264
 >> iter 54000, loss: 0.310275
 >> iter 55000, loss: 0.167573
 >> iter 56000, loss: 0.137539
 >> iter 57000, loss: 0.171392
 >> iter 58000, loss: 0.297843
 >> iter 59000, loss: 0.201212
 >> iter 60000, loss: 0.240130
   Number of active neurons: 3
 >> iter 61000, loss: 0.201702
 >> iter 62000, loss: 0.190899
 >> iter 63000, loss: 0.325697
 >> iter 64000, loss: 0.207592
 >> iter 65000, loss: 0.291192
 >> iter 66000, loss: 0.232402
 >> iter 67000, loss: 0.189288
 >> iter 68000, loss: 0.214025
 >> iter 69000, loss: 0.389169
 >> iter 70000, loss: 0.268965
   Number of active neurons: 3
 >> iter 71000, loss: 0.305851
 >> iter 72000, loss: 0.162606
 >> iter 73000, loss: 0.269120
 >> iter 74000, loss: 0.126464
 >> iter 75000, loss: 0.283600
 >> iter 76000, loss: 0.282794
 >> iter 77000, loss: 0.274989
 >> iter 78000, loss: 0.249212
 >> iter 79000, loss: 0.379412
 >> iter 80000, loss: 0.235916
   Number of active neurons: 3
 >> iter 81000, loss: 0.134711
 >> iter 82000, loss: 0.414483
 >> iter 83000, loss: 0.228214
 >> iter 84000, loss: 0.236898
 >> iter 85000, loss: 0.370784
 >> iter 86000, loss: 0.369026
 >> iter 87000, loss: 0.306132
 >> iter 88000, loss: 0.359112
 >> iter 89000, loss: 0.161804
 >> iter 90000, loss: 0.239075
   Number of active neurons: 3
 >> iter 91000, loss: 0.207198
 >> iter 92000, loss: 0.410764
 >> iter 93000, loss: 0.211461
 >> iter 94000, loss: 0.275117
 >> iter 95000, loss: 0.188922
 >> iter 96000, loss: 0.332404
 >> iter 97000, loss: 0.279663
 >> iter 98000, loss: 0.364931
 >> iter 99000, loss: 0.337215
 >> iter 100000, loss: 0.291714
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.265144
 >> iter 2000, loss: 12.471649
 >> iter 3000, loss: 6.896023
 >> iter 4000, loss: 3.085144
 >> iter 5000, loss: 1.944991
 >> iter 6000, loss: 1.011963
 >> iter 7000, loss: 0.559109
 >> iter 8000, loss: 0.393881
 >> iter 9000, loss: 0.201734
 >> iter 10000, loss: 0.252165
   Number of active neurons: 4
 >> iter 11000, loss: 0.420419
 >> iter 12000, loss: 0.291784
 >> iter 13000, loss: 0.524452
 >> iter 14000, loss: 0.530756
 >> iter 15000, loss: 0.624078
 >> iter 16000, loss: 0.453466
 >> iter 17000, loss: 0.340744
 >> iter 18000, loss: 0.304030
 >> iter 19000, loss: 0.299019
 >> iter 20000, loss: 0.339970
   Number of active neurons: 4
 >> iter 21000, loss: 0.369564
 >> iter 22000, loss: 0.191685
 >> iter 23000, loss: 0.398363
 >> iter 24000, loss: 0.289425
 >> iter 25000, loss: 0.309586
 >> iter 26000, loss: 0.438019
 >> iter 27000, loss: 0.377959
 >> iter 28000, loss: 0.249742
 >> iter 29000, loss: 0.174493
 >> iter 30000, loss: 0.246968
   Number of active neurons: 4
 >> iter 31000, loss: 0.299615
 >> iter 32000, loss: 0.237053
 >> iter 33000, loss: 0.402368
 >> iter 34000, loss: 0.347164
 >> iter 35000, loss: 0.349481
 >> iter 36000, loss: 0.192883
 >> iter 37000, loss: 0.342414
 >> iter 38000, loss: 0.314693
 >> iter 39000, loss: 0.305990
 >> iter 40000, loss: 0.276064
   Number of active neurons: 3
 >> iter 41000, loss: 0.208432
 >> iter 42000, loss: 0.245663
 >> iter 43000, loss: 0.202937
 >> iter 44000, loss: 0.282018
 >> iter 45000, loss: 0.190728
 >> iter 46000, loss: 0.260943
 >> iter 47000, loss: 0.420893
 >> iter 48000, loss: 0.432676
 >> iter 49000, loss: 0.304030
 >> iter 50000, loss: 0.202252
   Number of active neurons: 3
 >> iter 51000, loss: 0.174329
 >> iter 52000, loss: 0.156394
 >> iter 53000, loss: 0.293244
 >> iter 54000, loss: 0.347648
 >> iter 55000, loss: 0.234686
 >> iter 56000, loss: 0.339687
 >> iter 57000, loss: 0.305011
 >> iter 58000, loss: 0.171309
 >> iter 59000, loss: 0.104997
 >> iter 60000, loss: 0.132144
   Number of active neurons: 3
 >> iter 61000, loss: 0.279764
 >> iter 62000, loss: 0.274971
 >> iter 63000, loss: 0.392773
 >> iter 64000, loss: 0.256524
 >> iter 65000, loss: 0.308452
 >> iter 66000, loss: 0.258649
 >> iter 67000, loss: 0.258859
 >> iter 68000, loss: 0.288775
 >> iter 69000, loss: 0.190741
 >> iter 70000, loss: 0.259571
   Number of active neurons: 3
 >> iter 71000, loss: 0.227449
 >> iter 72000, loss: 0.152764
 >> iter 73000, loss: 0.224524
 >> iter 74000, loss: 0.293035
 >> iter 75000, loss: 0.298500
 >> iter 76000, loss: 0.234495
 >> iter 77000, loss: 0.205249
 >> iter 78000, loss: 0.304192
 >> iter 79000, loss: 0.242167
 >> iter 80000, loss: 0.300059
   Number of active neurons: 3
 >> iter 81000, loss: 0.262883
 >> iter 82000, loss: 0.248046
 >> iter 83000, loss: 0.217213
 >> iter 84000, loss: 0.345523
 >> iter 85000, loss: 0.289667
 >> iter 86000, loss: 0.180163
 >> iter 87000, loss: 0.164527
 >> iter 88000, loss: 0.338573
 >> iter 89000, loss: 0.368631
 >> iter 90000, loss: 0.289999
   Number of active neurons: 3
 >> iter 91000, loss: 0.373304
 >> iter 92000, loss: 0.286654
 >> iter 93000, loss: 0.250943
 >> iter 94000, loss: 0.249679
 >> iter 95000, loss: 0.143211
 >> iter 96000, loss: 0.203922
 >> iter 97000, loss: 0.280773
 >> iter 98000, loss: 0.272341
 >> iter 99000, loss: 0.256997
 >> iter 100000, loss: 0.190961
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.905172
 >> iter 2000, loss: 11.295354
 >> iter 3000, loss: 6.460480
 >> iter 4000, loss: 2.940631
 >> iter 5000, loss: 1.487443
 >> iter 6000, loss: 0.827856
 >> iter 7000, loss: 0.599470
 >> iter 8000, loss: 0.294963
 >> iter 9000, loss: 0.433960
 >> iter 10000, loss: 0.253479
   Number of active neurons: 4
 >> iter 11000, loss: 0.185241
 >> iter 12000, loss: 0.254258
 >> iter 13000, loss: 0.241748
 >> iter 14000, loss: 0.308778
 >> iter 15000, loss: 0.246762
 >> iter 16000, loss: 0.273049
 >> iter 17000, loss: 0.164086
 >> iter 18000, loss: 0.222815
 >> iter 19000, loss: 0.264253
 >> iter 20000, loss: 0.185507
   Number of active neurons: 3
 >> iter 21000, loss: 0.345431
 >> iter 22000, loss: 0.240543
 >> iter 23000, loss: 0.213638
 >> iter 24000, loss: 0.205887
 >> iter 25000, loss: 0.233463
 >> iter 26000, loss: 0.291438
 >> iter 27000, loss: 0.204617
 >> iter 28000, loss: 0.260472
 >> iter 29000, loss: 0.413594
 >> iter 30000, loss: 0.280943
   Number of active neurons: 3
 >> iter 31000, loss: 0.317580
 >> iter 32000, loss: 0.193535
 >> iter 33000, loss: 0.152330
 >> iter 34000, loss: 0.171720
 >> iter 35000, loss: 0.178747
 >> iter 36000, loss: 0.341153
 >> iter 37000, loss: 0.213189
 >> iter 38000, loss: 0.312371
 >> iter 39000, loss: 0.445991
 >> iter 40000, loss: 0.204519
   Number of active neurons: 3
 >> iter 41000, loss: 0.122457
 >> iter 42000, loss: 0.122907
 >> iter 43000, loss: 0.188428
 >> iter 44000, loss: 0.303755
 >> iter 45000, loss: 0.231242
 >> iter 46000, loss: 0.200358
 >> iter 47000, loss: 0.201596
 >> iter 48000, loss: 0.190113
 >> iter 49000, loss: 0.315448
 >> iter 50000, loss: 0.313817
   Number of active neurons: 3
 >> iter 51000, loss: 0.200182
 >> iter 52000, loss: 0.250338
 >> iter 53000, loss: 0.209982
 >> iter 54000, loss: 0.409854
 >> iter 55000, loss: 0.327024
 >> iter 56000, loss: 0.295976
 >> iter 57000, loss: 0.254101
 >> iter 58000, loss: 0.211352
 >> iter 59000, loss: 0.284323
 >> iter 60000, loss: 0.391087
   Number of active neurons: 3
 >> iter 61000, loss: 0.244137
 >> iter 62000, loss: 0.130160
 >> iter 63000, loss: 0.317785
 >> iter 64000, loss: 0.336034
 >> iter 65000, loss: 0.224288
 >> iter 66000, loss: 0.254201
 >> iter 67000, loss: 0.189955
 >> iter 68000, loss: 0.147767
 >> iter 69000, loss: 0.204331
 >> iter 70000, loss: 0.349579
   Number of active neurons: 3
 >> iter 71000, loss: 0.254513
 >> iter 72000, loss: 0.157135
 >> iter 73000, loss: 0.250742
 >> iter 74000, loss: 0.346315
 >> iter 75000, loss: 0.217142
 >> iter 76000, loss: 0.155578
 >> iter 77000, loss: 0.421645
 >> iter 78000, loss: 0.411782
 >> iter 79000, loss: 0.236358
 >> iter 80000, loss: 0.377823
   Number of active neurons: 3
 >> iter 81000, loss: 0.256032
 >> iter 82000, loss: 0.212684
 >> iter 83000, loss: 0.281765
 >> iter 84000, loss: 0.178753
 >> iter 85000, loss: 0.179913
 >> iter 86000, loss: 0.408871
 >> iter 87000, loss: 0.273536
 >> iter 88000, loss: 0.326928
 >> iter 89000, loss: 0.211613
 >> iter 90000, loss: 0.422292
   Number of active neurons: 3
 >> iter 91000, loss: 0.329576
 >> iter 92000, loss: 0.193741
 >> iter 93000, loss: 0.177089
 >> iter 94000, loss: 0.311133
 >> iter 95000, loss: 0.163727
 >> iter 96000, loss: 0.178753
 >> iter 97000, loss: 0.277135
 >> iter 98000, loss: 0.278916
 >> iter 99000, loss: 0.216679
 >> iter 100000, loss: 0.134186
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.432391
 >> iter 2000, loss: 10.254517
 >> iter 3000, loss: 4.983870
 >> iter 4000, loss: 2.418779
 >> iter 5000, loss: 1.592375
 >> iter 6000, loss: 1.104109
 >> iter 7000, loss: 0.764483
 >> iter 8000, loss: 0.781902
 >> iter 9000, loss: 0.626255
 >> iter 10000, loss: 0.389544
   Number of active neurons: 4
 >> iter 11000, loss: 0.269733
 >> iter 12000, loss: 0.316080
 >> iter 13000, loss: 0.644503
 >> iter 14000, loss: 0.513689
 >> iter 15000, loss: 0.334444
 >> iter 16000, loss: 0.401116
 >> iter 17000, loss: 0.410191
 >> iter 18000, loss: 0.392064
 >> iter 19000, loss: 0.550245
 >> iter 20000, loss: 0.752315
   Number of active neurons: 4
 >> iter 21000, loss: 0.795330
 >> iter 22000, loss: 0.619862
 >> iter 23000, loss: 0.659685
 >> iter 24000, loss: 0.553766
 >> iter 25000, loss: 0.257130
 >> iter 26000, loss: 0.320255
 >> iter 27000, loss: 0.410863
 >> iter 28000, loss: 0.329418
 >> iter 29000, loss: 0.534956
 >> iter 30000, loss: 0.550929
   Number of active neurons: 4
 >> iter 31000, loss: 0.522833
 >> iter 32000, loss: 0.500742
 >> iter 33000, loss: 0.359367
 >> iter 34000, loss: 0.497356
 >> iter 35000, loss: 0.424725
 >> iter 36000, loss: 0.468613
 >> iter 37000, loss: 0.458157
 >> iter 38000, loss: 0.448153
 >> iter 39000, loss: 0.454552
 >> iter 40000, loss: 0.445220
   Number of active neurons: 4
 >> iter 41000, loss: 0.679940
 >> iter 42000, loss: 0.771760
 >> iter 43000, loss: 0.584749
 >> iter 44000, loss: 0.568663
 >> iter 45000, loss: 0.375051
 >> iter 46000, loss: 0.481287
 >> iter 47000, loss: 0.392423
 >> iter 48000, loss: 0.399136
 >> iter 49000, loss: 0.464255
 >> iter 50000, loss: 0.327025
   Number of active neurons: 4
 >> iter 51000, loss: 0.327467
 >> iter 52000, loss: 0.744883
 >> iter 53000, loss: 0.591707
 >> iter 54000, loss: 0.638945
 >> iter 55000, loss: 0.379220
 >> iter 56000, loss: 0.480322
 >> iter 57000, loss: 0.348026
 >> iter 58000, loss: 0.577258
 >> iter 59000, loss: 0.335679
 >> iter 60000, loss: 0.322956
   Number of active neurons: 4
 >> iter 61000, loss: 0.326497
 >> iter 62000, loss: 0.223782
 >> iter 63000, loss: 0.391900
 >> iter 64000, loss: 0.363510
 >> iter 65000, loss: 0.414681
 >> iter 66000, loss: 0.535354
 >> iter 67000, loss: 0.580129
 >> iter 68000, loss: 0.315881
 >> iter 69000, loss: 0.368083
 >> iter 70000, loss: 0.347572
   Number of active neurons: 4
 >> iter 71000, loss: 0.525583
 >> iter 72000, loss: 0.316509
 >> iter 73000, loss: 0.245446
 >> iter 74000, loss: 0.318175
 >> iter 75000, loss: 0.606708
 >> iter 76000, loss: 0.416244
 >> iter 77000, loss: 0.318703
 >> iter 78000, loss: 0.357055
 >> iter 79000, loss: 0.390067
 >> iter 80000, loss: 0.397220
   Number of active neurons: 4
 >> iter 81000, loss: 0.705305
 >> iter 82000, loss: 0.540333
 >> iter 83000, loss: 0.471309
 >> iter 84000, loss: 0.361429
 >> iter 85000, loss: 0.364279
 >> iter 86000, loss: 0.375837
 >> iter 87000, loss: 0.595745
 >> iter 88000, loss: 0.525817
 >> iter 89000, loss: 0.492626
 >> iter 90000, loss: 0.448093
   Number of active neurons: 4
 >> iter 91000, loss: 0.363341
 >> iter 92000, loss: 0.260999
 >> iter 93000, loss: 0.293450
 >> iter 94000, loss: 0.425402
 >> iter 95000, loss: 0.303946
 >> iter 96000, loss: 0.501331
 >> iter 97000, loss: 0.472035
 >> iter 98000, loss: 0.238971
 >> iter 99000, loss: 0.409442
 >> iter 100000, loss: 0.335907
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524758
 >> iter 2000, loss: 18.054278
 >> iter 3000, loss: 17.068461
 >> iter 4000, loss: 16.779362
 >> iter 5000, loss: 16.602167
 >> iter 6000, loss: 16.336689
 >> iter 7000, loss: 12.432700
 >> iter 8000, loss: 7.493739
 >> iter 9000, loss: 3.725508
 >> iter 10000, loss: 2.101116
   Number of active neurons: 4
 >> iter 11000, loss: 1.280984
 >> iter 12000, loss: 0.724810
 >> iter 13000, loss: 0.394445
 >> iter 14000, loss: 0.522709
 >> iter 15000, loss: 0.431156
 >> iter 16000, loss: 0.410340
 >> iter 17000, loss: 0.483793
 >> iter 18000, loss: 0.423691
 >> iter 19000, loss: 0.312982
 >> iter 20000, loss: 0.201747
   Number of active neurons: 4
 >> iter 21000, loss: 0.318228
 >> iter 22000, loss: 0.276826
 >> iter 23000, loss: 0.288943
 >> iter 24000, loss: 0.182662
 >> iter 25000, loss: 0.357944
 >> iter 26000, loss: 0.313165
 >> iter 27000, loss: 0.363946
 >> iter 28000, loss: 0.390648
 >> iter 29000, loss: 0.384554
 >> iter 30000, loss: 0.278636
   Number of active neurons: 4
 >> iter 31000, loss: 0.490955
 >> iter 32000, loss: 0.279283
 >> iter 33000, loss: 0.474351
 >> iter 34000, loss: 0.354151
 >> iter 35000, loss: 0.444140
 >> iter 36000, loss: 0.360177
 >> iter 37000, loss: 0.262016
 >> iter 38000, loss: 0.294018
 >> iter 39000, loss: 0.257435
 >> iter 40000, loss: 0.230720
   Number of active neurons: 4
 >> iter 41000, loss: 0.319794
 >> iter 42000, loss: 0.355459
 >> iter 43000, loss: 0.399063
 >> iter 44000, loss: 0.375362
 >> iter 45000, loss: 0.372780
 >> iter 46000, loss: 0.294094
 >> iter 47000, loss: 0.235416
 >> iter 48000, loss: 0.158165
 >> iter 49000, loss: 0.192987
 >> iter 50000, loss: 0.275646
   Number of active neurons: 3
 >> iter 51000, loss: 0.197595
 >> iter 52000, loss: 0.206072
 >> iter 53000, loss: 0.356161
 >> iter 54000, loss: 0.239256
 >> iter 55000, loss: 0.237401
 >> iter 56000, loss: 0.160115
 >> iter 57000, loss: 0.169104
 >> iter 58000, loss: 0.272452
 >> iter 59000, loss: 0.265025
 >> iter 60000, loss: 0.327209
   Number of active neurons: 3
 >> iter 61000, loss: 0.295684
 >> iter 62000, loss: 0.328201
 >> iter 63000, loss: 0.331598
 >> iter 64000, loss: 0.400031
 >> iter 65000, loss: 0.187527
 >> iter 66000, loss: 0.129882
 >> iter 67000, loss: 0.255237
 >> iter 68000, loss: 0.238734
 >> iter 69000, loss: 0.178356
 >> iter 70000, loss: 0.377474
   Number of active neurons: 3
 >> iter 71000, loss: 0.276633
 >> iter 72000, loss: 0.212708
 >> iter 73000, loss: 0.193868
 >> iter 74000, loss: 0.273801
 >> iter 75000, loss: 0.493279
 >> iter 76000, loss: 0.291955
 >> iter 77000, loss: 0.272097
 >> iter 78000, loss: 0.242941
 >> iter 79000, loss: 0.467557
 >> iter 80000, loss: 0.267489
   Number of active neurons: 3
 >> iter 81000, loss: 0.235022
 >> iter 82000, loss: 0.353737
 >> iter 83000, loss: 0.235536
 >> iter 84000, loss: 0.128624
 >> iter 85000, loss: 0.145397
 >> iter 86000, loss: 0.202454
 >> iter 87000, loss: 0.162661
 >> iter 88000, loss: 0.185812
 >> iter 89000, loss: 0.255765
 >> iter 90000, loss: 0.259182
   Number of active neurons: 3
 >> iter 91000, loss: 0.316625
 >> iter 92000, loss: 0.227769
 >> iter 93000, loss: 0.147310
 >> iter 94000, loss: 0.117745
 >> iter 95000, loss: 0.280964
 >> iter 96000, loss: 0.158759
 >> iter 97000, loss: 0.167090
 >> iter 98000, loss: 0.245751
 >> iter 99000, loss: 0.163023
 >> iter 100000, loss: 0.199566
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 20.524756
 >> iter 2000, loss: 16.388499
 >> iter 3000, loss: 9.817067
 >> iter 4000, loss: 4.811040
 >> iter 5000, loss: 2.476493
 >> iter 6000, loss: 1.100988
 >> iter 7000, loss: 0.682266
 >> iter 8000, loss: 0.414915
 >> iter 9000, loss: 0.473522
 >> iter 10000, loss: 0.454293
   Number of active neurons: 4
 >> iter 11000, loss: 0.352313
 >> iter 12000, loss: 0.278294
 >> iter 13000, loss: 0.293242
 >> iter 14000, loss: 0.286456
 >> iter 15000, loss: 0.205004
 >> iter 16000, loss: 0.350982
 >> iter 17000, loss: 0.421392
 >> iter 18000, loss: 0.387986
 >> iter 19000, loss: 0.259602
 >> iter 20000, loss: 0.438618
   Number of active neurons: 4
 >> iter 21000, loss: 0.313515
 >> iter 22000, loss: 0.179824
 >> iter 23000, loss: 0.328476
 >> iter 24000, loss: 0.518462
 >> iter 25000, loss: 0.405213
 >> iter 26000, loss: 0.319294
 >> iter 27000, loss: 0.224835
 >> iter 28000, loss: 0.252630
 >> iter 29000, loss: 0.155377
 >> iter 30000, loss: 0.242127
   Number of active neurons: 4
 >> iter 31000, loss: 0.195811
 >> iter 32000, loss: 0.238155
 >> iter 33000, loss: 0.324528
 >> iter 34000, loss: 0.464797
 >> iter 35000, loss: 0.260464
 >> iter 36000, loss: 0.256496
 >> iter 37000, loss: 0.274165
 >> iter 38000, loss: 0.222998
 >> iter 39000, loss: 0.314783
 >> iter 40000, loss: 0.203547
   Number of active neurons: 3
 >> iter 41000, loss: 0.221830
 >> iter 42000, loss: 0.173384
 >> iter 43000, loss: 0.256385
 >> iter 44000, loss: 0.244319
 >> iter 45000, loss: 0.311931
 >> iter 46000, loss: 0.432468
 >> iter 47000, loss: 0.388228
 >> iter 48000, loss: 0.545290
 >> iter 49000, loss: 0.354501
 >> iter 50000, loss: 0.462131
   Number of active neurons: 3
 >> iter 51000, loss: 0.257562
 >> iter 52000, loss: 0.341958
 >> iter 53000, loss: 0.322163
 >> iter 54000, loss: 0.197955
 >> iter 55000, loss: 0.279747
 >> iter 56000, loss: 0.246421
 >> iter 57000, loss: 0.147302
 >> iter 58000, loss: 0.274691
 >> iter 59000, loss: 0.169521
 >> iter 60000, loss: 0.144129
   Number of active neurons: 3
 >> iter 61000, loss: 0.154594
 >> iter 62000, loss: 0.188380
 >> iter 63000, loss: 0.213648
 >> iter 64000, loss: 0.194918
 >> iter 65000, loss: 0.200720
 >> iter 66000, loss: 0.208847
 >> iter 67000, loss: 0.254644
 >> iter 68000, loss: 0.228153
 >> iter 69000, loss: 0.144423
 >> iter 70000, loss: 0.166305
   Number of active neurons: 3
 >> iter 71000, loss: 0.237970
 >> iter 72000, loss: 0.263712
 >> iter 73000, loss: 0.312975
 >> iter 74000, loss: 0.338151
 >> iter 75000, loss: 0.331883
 >> iter 76000, loss: 0.321787
 >> iter 77000, loss: 0.264500
 >> iter 78000, loss: 0.203524
 >> iter 79000, loss: 0.166002
 >> iter 80000, loss: 0.282347
   Number of active neurons: 3
 >> iter 81000, loss: 0.172804
 >> iter 82000, loss: 0.385214
 >> iter 83000, loss: 0.270098
 >> iter 84000, loss: 0.329856
 >> iter 85000, loss: 0.195301
 >> iter 86000, loss: 0.402179
 >> iter 87000, loss: 0.261684
 >> iter 88000, loss: 0.177199
 >> iter 89000, loss: 0.131566
 >> iter 90000, loss: 0.175652
   Number of active neurons: 3
 >> iter 91000, loss: 0.206904
 >> iter 92000, loss: 0.237633
 >> iter 93000, loss: 0.370766
 >> iter 94000, loss: 0.207691
 >> iter 95000, loss: 0.142956
 >> iter 96000, loss: 0.148065
 >> iter 97000, loss: 0.131796
 >> iter 98000, loss: 0.180963
 >> iter 99000, loss: 0.272686
 >> iter 100000, loss: 0.280924
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.304858
 >> iter 2000, loss: 10.509362
 >> iter 3000, loss: 4.868880
 >> iter 4000, loss: 2.318680
 >> iter 5000, loss: 1.420696
 >> iter 6000, loss: 0.850691
 >> iter 7000, loss: 0.507940
 >> iter 8000, loss: 0.302740
 >> iter 9000, loss: 0.789629
 >> iter 10000, loss: 0.517543
   Number of active neurons: 4
 >> iter 11000, loss: 0.567499
 >> iter 12000, loss: 0.414813
 >> iter 13000, loss: 0.413469
 >> iter 14000, loss: 0.375137
 >> iter 15000, loss: 0.557075
 >> iter 16000, loss: 0.298557
 >> iter 17000, loss: 0.438296
 >> iter 18000, loss: 0.313247
 >> iter 19000, loss: 0.406873
 >> iter 20000, loss: 0.257665
   Number of active neurons: 4
 >> iter 21000, loss: 0.347122
 >> iter 22000, loss: 0.266195
 >> iter 23000, loss: 0.724207
 >> iter 24000, loss: 0.555611
 >> iter 25000, loss: 0.464932
 >> iter 26000, loss: 0.499928
 >> iter 27000, loss: 0.486101
 >> iter 28000, loss: 0.314270
 >> iter 29000, loss: 0.324080
 >> iter 30000, loss: 0.457467
   Number of active neurons: 4
 >> iter 31000, loss: 0.456802
 >> iter 32000, loss: 0.506422
 >> iter 33000, loss: 0.286458
 >> iter 34000, loss: 0.326149
 >> iter 35000, loss: 0.245057
 >> iter 36000, loss: 0.403725
 >> iter 37000, loss: 0.335169
 >> iter 38000, loss: 0.284514
 >> iter 39000, loss: 0.191759
 >> iter 40000, loss: 0.297003
   Number of active neurons: 4
 >> iter 41000, loss: 0.393807
 >> iter 42000, loss: 0.369393
 >> iter 43000, loss: 0.193194
 >> iter 44000, loss: 0.436968
 >> iter 45000, loss: 0.400517
 >> iter 46000, loss: 0.360566
 >> iter 47000, loss: 0.541242
 >> iter 48000, loss: 0.422176
 >> iter 49000, loss: 0.230176
 >> iter 50000, loss: 0.369757
   Number of active neurons: 4
 >> iter 51000, loss: 0.461590
 >> iter 52000, loss: 0.320487
 >> iter 53000, loss: 0.199114
 >> iter 54000, loss: 0.283592
 >> iter 55000, loss: 0.294795
 >> iter 56000, loss: 0.317557
 >> iter 57000, loss: 0.445009
 >> iter 58000, loss: 0.303700
 >> iter 59000, loss: 0.340383
 >> iter 60000, loss: 0.432187
   Number of active neurons: 4
 >> iter 61000, loss: 0.339581
 >> iter 62000, loss: 0.288603
 >> iter 63000, loss: 0.322225
 >> iter 64000, loss: 0.491328
 >> iter 65000, loss: 0.449300
 >> iter 66000, loss: 0.322776
 >> iter 67000, loss: 0.445187
 >> iter 68000, loss: 0.407051
 >> iter 69000, loss: 0.401968
 >> iter 70000, loss: 0.331161
   Number of active neurons: 4
 >> iter 71000, loss: 0.212255
 >> iter 72000, loss: 0.355159
 >> iter 73000, loss: 0.424671
 >> iter 74000, loss: 0.384962
 >> iter 75000, loss: 0.185630
 >> iter 76000, loss: 0.185570
 >> iter 77000, loss: 0.231189
 >> iter 78000, loss: 0.154619
 >> iter 79000, loss: 0.180825
 >> iter 80000, loss: 0.142227
   Number of active neurons: 4
 >> iter 81000, loss: 0.217470
 >> iter 82000, loss: 0.418053
 >> iter 83000, loss: 0.376393
 >> iter 84000, loss: 0.274098
 >> iter 85000, loss: 0.153389
 >> iter 86000, loss: 0.263144
 >> iter 87000, loss: 0.341475
 >> iter 88000, loss: 0.260449
 >> iter 89000, loss: 0.303389
 >> iter 90000, loss: 0.354245
   Number of active neurons: 4
 >> iter 91000, loss: 0.345222
 >> iter 92000, loss: 0.324191
 >> iter 93000, loss: 0.316898
 >> iter 94000, loss: 0.303133
 >> iter 95000, loss: 0.304015
 >> iter 96000, loss: 0.232759
 >> iter 97000, loss: 0.271655
 >> iter 98000, loss: 0.219447
 >> iter 99000, loss: 0.278940
 >> iter 100000, loss: 0.374684
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.268831
 >> iter 2000, loss: 10.224194
 >> iter 3000, loss: 5.173508
 >> iter 4000, loss: 2.649846
 >> iter 5000, loss: 1.274063
 >> iter 6000, loss: 0.647701
 >> iter 7000, loss: 0.491036
 >> iter 8000, loss: 0.455113
 >> iter 9000, loss: 0.583821
 >> iter 10000, loss: 0.657162
   Number of active neurons: 4
 >> iter 11000, loss: 0.520777
 >> iter 12000, loss: 0.373995
 >> iter 13000, loss: 0.366318
 >> iter 14000, loss: 0.335472
 >> iter 15000, loss: 0.469711
 >> iter 16000, loss: 0.343362
 >> iter 17000, loss: 0.271570
 >> iter 18000, loss: 0.287185
 >> iter 19000, loss: 0.147948
 >> iter 20000, loss: 0.644000
   Number of active neurons: 4
 >> iter 21000, loss: 0.399616
 >> iter 22000, loss: 0.376200
 >> iter 23000, loss: 0.258918
 >> iter 24000, loss: 0.476921
 >> iter 25000, loss: 0.299755
 >> iter 26000, loss: 0.309731
 >> iter 27000, loss: 0.360509
 >> iter 28000, loss: 0.219383
 >> iter 29000, loss: 0.327156
 >> iter 30000, loss: 0.304153
   Number of active neurons: 4
 >> iter 31000, loss: 0.205972
 >> iter 32000, loss: 0.372316
 >> iter 33000, loss: 0.279414
 >> iter 34000, loss: 0.256284
 >> iter 35000, loss: 0.153201
 >> iter 36000, loss: 0.272802
 >> iter 37000, loss: 0.273704
 >> iter 38000, loss: 0.428010
 >> iter 39000, loss: 0.270381
 >> iter 40000, loss: 0.438301
   Number of active neurons: 4
 >> iter 41000, loss: 0.247292
 >> iter 42000, loss: 0.269485
 >> iter 43000, loss: 0.453504
 >> iter 44000, loss: 0.242715
 >> iter 45000, loss: 0.293644
 >> iter 46000, loss: 0.440028
 >> iter 47000, loss: 0.585859
 >> iter 48000, loss: 0.359051
 >> iter 49000, loss: 0.395632
 >> iter 50000, loss: 0.392194
   Number of active neurons: 4
 >> iter 51000, loss: 0.233418
 >> iter 52000, loss: 0.356570
 >> iter 53000, loss: 0.257534
 >> iter 54000, loss: 0.397445
 >> iter 55000, loss: 0.324277
 >> iter 56000, loss: 0.201567
 >> iter 57000, loss: 0.214673
 >> iter 58000, loss: 0.325708
 >> iter 59000, loss: 0.233765
 >> iter 60000, loss: 0.403878
   Number of active neurons: 4
 >> iter 61000, loss: 0.378390
 >> iter 62000, loss: 0.357082
 >> iter 63000, loss: 0.317526
 >> iter 64000, loss: 0.363225
 >> iter 65000, loss: 0.163035
 >> iter 66000, loss: 0.260604
 >> iter 67000, loss: 0.182376
 >> iter 68000, loss: 0.439833
 >> iter 69000, loss: 0.244953
 >> iter 70000, loss: 0.217261
   Number of active neurons: 4
 >> iter 71000, loss: 0.193179
 >> iter 72000, loss: 0.374239
 >> iter 73000, loss: 0.260547
 >> iter 74000, loss: 0.130909
 >> iter 75000, loss: 0.204535
 >> iter 76000, loss: 0.148609
 >> iter 77000, loss: 0.193113
 >> iter 78000, loss: 0.292149
 >> iter 79000, loss: 0.321405
 >> iter 80000, loss: 0.295243
   Number of active neurons: 4
 >> iter 81000, loss: 0.247799
 >> iter 82000, loss: 0.457728
 >> iter 83000, loss: 0.293513
 >> iter 84000, loss: 0.173154
 >> iter 85000, loss: 0.102471
 >> iter 86000, loss: 0.135860
 >> iter 87000, loss: 0.235453
 >> iter 88000, loss: 0.217338
 >> iter 89000, loss: 0.232629
 >> iter 90000, loss: 0.222696
   Number of active neurons: 3
 >> iter 91000, loss: 0.223401
 >> iter 92000, loss: 0.371630
 >> iter 93000, loss: 0.290928
 >> iter 94000, loss: 0.281729
 >> iter 95000, loss: 0.234674
 >> iter 96000, loss: 0.162968
 >> iter 97000, loss: 0.174478
 >> iter 98000, loss: 0.116794
 >> iter 99000, loss: 0.158340
 >> iter 100000, loss: 0.119267
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.430982
 >> iter 2000, loss: 9.559712
 >> iter 3000, loss: 4.033680
 >> iter 4000, loss: 2.033772
 >> iter 5000, loss: 1.191461
 >> iter 6000, loss: 0.623174
 >> iter 7000, loss: 0.359835
 >> iter 8000, loss: 0.385954
 >> iter 9000, loss: 0.292391
 >> iter 10000, loss: 0.366531
   Number of active neurons: 4
 >> iter 11000, loss: 0.356256
 >> iter 12000, loss: 0.307274
 >> iter 13000, loss: 0.220293
 >> iter 14000, loss: 0.308539
 >> iter 15000, loss: 0.340854
 >> iter 16000, loss: 0.328042
 >> iter 17000, loss: 0.287966
 >> iter 18000, loss: 0.264438
 >> iter 19000, loss: 0.265531
 >> iter 20000, loss: 0.156893
   Number of active neurons: 3
 >> iter 21000, loss: 0.350716
 >> iter 22000, loss: 0.219442
 >> iter 23000, loss: 0.382449
 >> iter 24000, loss: 0.241102
 >> iter 25000, loss: 0.175799
 >> iter 26000, loss: 0.398571
 >> iter 27000, loss: 0.217868
 >> iter 28000, loss: 0.183119
 >> iter 29000, loss: 0.287183
 >> iter 30000, loss: 0.197909
   Number of active neurons: 3
 >> iter 31000, loss: 0.189863
 >> iter 32000, loss: 0.368678
 >> iter 33000, loss: 0.314965
 >> iter 34000, loss: 0.287100
 >> iter 35000, loss: 0.262327
 >> iter 36000, loss: 0.307859
 >> iter 37000, loss: 0.257248
 >> iter 38000, loss: 0.150225
 >> iter 39000, loss: 0.194822
 >> iter 40000, loss: 0.231006
   Number of active neurons: 3
 >> iter 41000, loss: 0.311537
 >> iter 42000, loss: 0.206500
 >> iter 43000, loss: 0.134944
 >> iter 44000, loss: 0.212228
 >> iter 45000, loss: 0.168928
 >> iter 46000, loss: 0.235888
 >> iter 47000, loss: 0.308367
 >> iter 48000, loss: 0.166461
 >> iter 49000, loss: 0.112553
 >> iter 50000, loss: 0.198127
   Number of active neurons: 3
 >> iter 51000, loss: 0.226542
 >> iter 52000, loss: 0.358102
 >> iter 53000, loss: 0.220433
 >> iter 54000, loss: 0.290725
 >> iter 55000, loss: 0.204198
 >> iter 56000, loss: 0.294572
 >> iter 57000, loss: 0.319515
 >> iter 58000, loss: 0.170780
 >> iter 59000, loss: 0.165593
 >> iter 60000, loss: 0.366746
   Number of active neurons: 3
 >> iter 61000, loss: 0.323303
 >> iter 62000, loss: 0.172675
 >> iter 63000, loss: 0.393961
 >> iter 64000, loss: 0.321464
 >> iter 65000, loss: 0.251211
 >> iter 66000, loss: 0.142182
 >> iter 67000, loss: 0.191459
 >> iter 68000, loss: 0.149435
 >> iter 69000, loss: 0.211908
 >> iter 70000, loss: 0.258764
   Number of active neurons: 3
 >> iter 71000, loss: 0.240230
 >> iter 72000, loss: 0.392302
 >> iter 73000, loss: 0.387827
 >> iter 74000, loss: 0.314006
 >> iter 75000, loss: 0.186361
 >> iter 76000, loss: 0.233956
 >> iter 77000, loss: 0.286727
 >> iter 78000, loss: 0.197605
 >> iter 79000, loss: 0.327700
 >> iter 80000, loss: 0.156317
   Number of active neurons: 3
 >> iter 81000, loss: 0.343359
 >> iter 82000, loss: 0.200621
 >> iter 83000, loss: 0.279892
 >> iter 84000, loss: 0.232696
 >> iter 85000, loss: 0.245356
 >> iter 86000, loss: 0.247970
 >> iter 87000, loss: 0.231887
 >> iter 88000, loss: 0.318520
 >> iter 89000, loss: 0.263253
 >> iter 90000, loss: 0.145165
   Number of active neurons: 3
 >> iter 91000, loss: 0.311331
 >> iter 92000, loss: 0.229097
 >> iter 93000, loss: 0.239159
 >> iter 94000, loss: 0.195168
 >> iter 95000, loss: 0.198011
 >> iter 96000, loss: 0.380651
 >> iter 97000, loss: 0.350529
 >> iter 98000, loss: 0.198096
 >> iter 99000, loss: 0.404327
 >> iter 100000, loss: 0.281158
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

