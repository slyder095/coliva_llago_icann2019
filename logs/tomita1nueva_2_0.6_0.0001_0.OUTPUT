 > Problema: tomita1nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.000701
 >> iter 2000, loss: 4.101471
 >> iter 3000, loss: 1.543102
 >> iter 4000, loss: 0.594640
 >> iter 5000, loss: 0.249489
 >> iter 6000, loss: 0.113403
 >> iter 7000, loss: 0.056393
 >> iter 8000, loss: 0.033528
 >> iter 9000, loss: 0.027620
 >> iter 10000, loss: 0.039692
   Number of active neurons: 1
 >> iter 11000, loss: 0.027951
 >> iter 12000, loss: 0.023256
 >> iter 13000, loss: 0.021286
 >> iter 14000, loss: 0.021392
 >> iter 15000, loss: 0.020155
 >> iter 16000, loss: 0.030597
 >> iter 17000, loss: 0.031817
 >> iter 18000, loss: 0.022753
 >> iter 19000, loss: 0.023003
 >> iter 20000, loss: 0.018318
   Number of active neurons: 1
 >> iter 21000, loss: 0.019026
 >> iter 22000, loss: 0.018320
 >> iter 23000, loss: 0.017073
 >> iter 24000, loss: 0.020967
 >> iter 25000, loss: 0.019049
 >> iter 26000, loss: 0.024925
 >> iter 27000, loss: 0.018908
 >> iter 28000, loss: 0.018162
 >> iter 29000, loss: 0.035770
 >> iter 30000, loss: 0.025496
   Number of active neurons: 1
 >> iter 31000, loss: 0.020597
 >> iter 32000, loss: 0.019257
 >> iter 33000, loss: 0.028841
 >> iter 34000, loss: 0.019283
 >> iter 35000, loss: 0.020400
 >> iter 36000, loss: 0.022282
 >> iter 37000, loss: 0.022250
 >> iter 38000, loss: 0.017731
 >> iter 39000, loss: 0.016352
 >> iter 40000, loss: 0.019107
   Number of active neurons: 1
 >> iter 41000, loss: 0.017604
 >> iter 42000, loss: 0.017900
 >> iter 43000, loss: 0.018563
 >> iter 44000, loss: 0.018263
 >> iter 45000, loss: 0.017836
 >> iter 46000, loss: 0.015871
 >> iter 47000, loss: 0.018583
 >> iter 48000, loss: 0.016975
 >> iter 49000, loss: 0.019330
 >> iter 50000, loss: 0.019107
   Number of active neurons: 1
 >> iter 51000, loss: 0.020286
 >> iter 52000, loss: 0.017858
 >> iter 53000, loss: 0.019936
 >> iter 54000, loss: 0.041143
 >> iter 55000, loss: 0.032626
 >> iter 56000, loss: 0.024052
 >> iter 57000, loss: 0.019204
 >> iter 58000, loss: 0.019435
 >> iter 59000, loss: 0.017691
 >> iter 60000, loss: 0.033256
   Number of active neurons: 1
 >> iter 61000, loss: 0.024793
 >> iter 62000, loss: 0.023241
 >> iter 63000, loss: 0.021464
 >> iter 64000, loss: 0.018895
 >> iter 65000, loss: 0.025724
 >> iter 66000, loss: 0.019063
 >> iter 67000, loss: 0.017434
 >> iter 68000, loss: 0.019357
 >> iter 69000, loss: 0.029185
 >> iter 70000, loss: 0.022566
   Number of active neurons: 1
 >> iter 71000, loss: 0.019272
 >> iter 72000, loss: 0.047264
 >> iter 73000, loss: 0.029883
 >> iter 74000, loss: 0.021035
 >> iter 75000, loss: 0.020401
 >> iter 76000, loss: 0.019434
 >> iter 77000, loss: 0.017702
 >> iter 78000, loss: 0.062961
 >> iter 79000, loss: 0.051661
 >> iter 80000, loss: 0.031765
   Number of active neurons: 1
 >> iter 81000, loss: 0.030880
 >> iter 82000, loss: 0.023059
 >> iter 83000, loss: 0.021388
 >> iter 84000, loss: 0.018142
 >> iter 85000, loss: 0.017741
 >> iter 86000, loss: 0.018482
 >> iter 87000, loss: 0.025411
 >> iter 88000, loss: 0.022990
 >> iter 89000, loss: 0.018529
 >> iter 90000, loss: 0.017828
   Number of active neurons: 1
 >> iter 91000, loss: 0.018837
 >> iter 92000, loss: 0.018182
 >> iter 93000, loss: 0.018466
 >> iter 94000, loss: 0.022399
 >> iter 95000, loss: 0.021645
 >> iter 96000, loss: 0.018470
 >> iter 97000, loss: 0.020624
 >> iter 98000, loss: 0.017022
 >> iter 99000, loss: 0.042351
 >> iter 100000, loss: 0.025664
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.048916
 >> iter 2000, loss: 4.102938
 >> iter 3000, loss: 1.556993
 >> iter 4000, loss: 0.591926
 >> iter 5000, loss: 0.266189
 >> iter 6000, loss: 0.114855
 >> iter 7000, loss: 0.059876
 >> iter 8000, loss: 0.038334
 >> iter 9000, loss: 0.029910
 >> iter 10000, loss: 0.024929
   Number of active neurons: 2
 >> iter 11000, loss: 0.022571
 >> iter 12000, loss: 0.021485
 >> iter 13000, loss: 0.024875
 >> iter 14000, loss: 0.021440
 >> iter 15000, loss: 0.021058
 >> iter 16000, loss: 0.027495
 >> iter 17000, loss: 0.028034
 >> iter 18000, loss: 0.022851
 >> iter 19000, loss: 0.023000
 >> iter 20000, loss: 0.021055
   Number of active neurons: 1
 >> iter 21000, loss: 0.020866
 >> iter 22000, loss: 0.019564
 >> iter 23000, loss: 0.024444
 >> iter 24000, loss: 0.020886
 >> iter 25000, loss: 0.018589
 >> iter 26000, loss: 0.018038
 >> iter 27000, loss: 0.019644
 >> iter 28000, loss: 0.025319
 >> iter 29000, loss: 0.032010
 >> iter 30000, loss: 0.020900
   Number of active neurons: 1
 >> iter 31000, loss: 0.017430
 >> iter 32000, loss: 0.019608
 >> iter 33000, loss: 0.017357
 >> iter 34000, loss: 0.015392
 >> iter 35000, loss: 0.018371
 >> iter 36000, loss: 0.016921
 >> iter 37000, loss: 0.018941
 >> iter 38000, loss: 0.020973
 >> iter 39000, loss: 0.017442
 >> iter 40000, loss: 0.017369
   Number of active neurons: 1
 >> iter 41000, loss: 0.016331
 >> iter 42000, loss: 0.018067
 >> iter 43000, loss: 0.018016
 >> iter 44000, loss: 0.027266
 >> iter 45000, loss: 0.025662
 >> iter 46000, loss: 0.022717
 >> iter 47000, loss: 0.020512
 >> iter 48000, loss: 0.016598
 >> iter 49000, loss: 0.038629
 >> iter 50000, loss: 0.033158
   Number of active neurons: 1
 >> iter 51000, loss: 0.024572
 >> iter 52000, loss: 0.024848
 >> iter 53000, loss: 0.020461
 >> iter 54000, loss: 0.024819
 >> iter 55000, loss: 0.030535
 >> iter 56000, loss: 0.022206
 >> iter 57000, loss: 0.022971
 >> iter 58000, loss: 0.024161
 >> iter 59000, loss: 0.024708
 >> iter 60000, loss: 0.019112
   Number of active neurons: 1
 >> iter 61000, loss: 0.017482
 >> iter 62000, loss: 0.026563
 >> iter 63000, loss: 0.022948
 >> iter 64000, loss: 0.020163
 >> iter 65000, loss: 0.033363
 >> iter 66000, loss: 0.035750
 >> iter 67000, loss: 0.023762
 >> iter 68000, loss: 0.021078
 >> iter 69000, loss: 0.029835
 >> iter 70000, loss: 0.023702
   Number of active neurons: 1
 >> iter 71000, loss: 0.021989
 >> iter 72000, loss: 0.026698
 >> iter 73000, loss: 0.020443
 >> iter 74000, loss: 0.018645
 >> iter 75000, loss: 0.025326
 >> iter 76000, loss: 0.025539
 >> iter 77000, loss: 0.032642
 >> iter 78000, loss: 0.023649
 >> iter 79000, loss: 0.019187
 >> iter 80000, loss: 0.018290
   Number of active neurons: 1
 >> iter 81000, loss: 0.027713
 >> iter 82000, loss: 0.039686
 >> iter 83000, loss: 0.027372
 >> iter 84000, loss: 0.020161
 >> iter 85000, loss: 0.017531
 >> iter 86000, loss: 0.016846
 >> iter 87000, loss: 0.022367
 >> iter 88000, loss: 0.018296
 >> iter 89000, loss: 0.017413
 >> iter 90000, loss: 0.018739
   Number of active neurons: 1
 >> iter 91000, loss: 0.017832
 >> iter 92000, loss: 0.024067
 >> iter 93000, loss: 0.019645
 >> iter 94000, loss: 0.017635
 >> iter 95000, loss: 0.016146
 >> iter 96000, loss: 0.020391
 >> iter 97000, loss: 0.022643
 >> iter 98000, loss: 0.023191
 >> iter 99000, loss: 0.019578
 >> iter 100000, loss: 0.034521
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.227870
 >> iter 2000, loss: 4.171456
 >> iter 3000, loss: 1.557241
 >> iter 4000, loss: 0.593208
 >> iter 5000, loss: 0.235394
 >> iter 6000, loss: 0.101746
 >> iter 7000, loss: 0.051996
 >> iter 8000, loss: 0.035622
 >> iter 9000, loss: 0.035652
 >> iter 10000, loss: 0.039632
   Number of active neurons: 2
 >> iter 11000, loss: 0.037210
 >> iter 12000, loss: 0.026500
 >> iter 13000, loss: 0.026297
 >> iter 14000, loss: 0.027807
 >> iter 15000, loss: 0.023108
 >> iter 16000, loss: 0.022133
 >> iter 17000, loss: 0.020434
 >> iter 18000, loss: 0.020897
 >> iter 19000, loss: 0.036709
 >> iter 20000, loss: 0.037575
   Number of active neurons: 2
 >> iter 21000, loss: 0.028462
 >> iter 22000, loss: 0.060685
 >> iter 23000, loss: 0.040646
 >> iter 24000, loss: 0.027694
 >> iter 25000, loss: 0.025208
 >> iter 26000, loss: 0.023459
 >> iter 27000, loss: 0.020015
 >> iter 28000, loss: 0.023538
 >> iter 29000, loss: 0.023553
 >> iter 30000, loss: 0.020444
   Number of active neurons: 2
 >> iter 31000, loss: 0.024867
 >> iter 32000, loss: 0.021339
 >> iter 33000, loss: 0.030373
 >> iter 34000, loss: 0.061775
 >> iter 35000, loss: 0.039237
 >> iter 36000, loss: 0.055664
 >> iter 37000, loss: 0.033942
 >> iter 38000, loss: 0.026762
 >> iter 39000, loss: 0.028853
 >> iter 40000, loss: 0.038952
   Number of active neurons: 2
 >> iter 41000, loss: 0.045622
 >> iter 42000, loss: 0.034314
 >> iter 43000, loss: 0.030195
 >> iter 44000, loss: 0.026587
 >> iter 45000, loss: 0.026364
 >> iter 46000, loss: 0.022621
 >> iter 47000, loss: 0.021997
 >> iter 48000, loss: 0.029672
 >> iter 49000, loss: 0.024807
 >> iter 50000, loss: 0.021610
   Number of active neurons: 2
 >> iter 51000, loss: 0.022229
 >> iter 52000, loss: 0.020819
 >> iter 53000, loss: 0.036711
 >> iter 54000, loss: 0.039642
 >> iter 55000, loss: 0.043728
 >> iter 56000, loss: 0.040236
 >> iter 57000, loss: 0.029193
 >> iter 58000, loss: 0.023048
 >> iter 59000, loss: 0.024009
 >> iter 60000, loss: 0.020919
   Number of active neurons: 1
 >> iter 61000, loss: 0.023251
 >> iter 62000, loss: 0.020308
 >> iter 63000, loss: 0.018392
 >> iter 64000, loss: 0.017961
 >> iter 65000, loss: 0.017820
 >> iter 66000, loss: 0.020944
 >> iter 67000, loss: 0.020401
 >> iter 68000, loss: 0.018091
 >> iter 69000, loss: 0.021920
 >> iter 70000, loss: 0.018644
   Number of active neurons: 1
 >> iter 71000, loss: 0.039452
 >> iter 72000, loss: 0.028057
 >> iter 73000, loss: 0.021757
 >> iter 74000, loss: 0.020546
 >> iter 75000, loss: 0.018552
 >> iter 76000, loss: 0.030273
 >> iter 77000, loss: 0.021808
 >> iter 78000, loss: 0.020486
 >> iter 79000, loss: 0.018239
 >> iter 80000, loss: 0.017089
   Number of active neurons: 1
 >> iter 81000, loss: 0.017064
 >> iter 82000, loss: 0.016253
 >> iter 83000, loss: 0.025243
 >> iter 84000, loss: 0.019774
 >> iter 85000, loss: 0.018325
 >> iter 86000, loss: 0.017053
 >> iter 87000, loss: 0.017740
 >> iter 88000, loss: 0.019027
 >> iter 89000, loss: 0.033111
 >> iter 90000, loss: 0.026205
   Number of active neurons: 1
 >> iter 91000, loss: 0.019866
 >> iter 92000, loss: 0.038346
 >> iter 93000, loss: 0.032962
 >> iter 94000, loss: 0.030716
 >> iter 95000, loss: 0.022431
 >> iter 96000, loss: 0.029864
 >> iter 97000, loss: 0.021611
 >> iter 98000, loss: 0.019862
 >> iter 99000, loss: 0.018604
 >> iter 100000, loss: 0.018494
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.020802
 >> iter 2000, loss: 4.097564
 >> iter 3000, loss: 1.528799
 >> iter 4000, loss: 0.581379
 >> iter 5000, loss: 0.232109
 >> iter 6000, loss: 0.101844
 >> iter 7000, loss: 0.058512
 >> iter 8000, loss: 0.044315
 >> iter 9000, loss: 0.031382
 >> iter 10000, loss: 0.025536
   Number of active neurons: 2
 >> iter 11000, loss: 0.022939
 >> iter 12000, loss: 0.021632
 >> iter 13000, loss: 0.054194
 >> iter 14000, loss: 0.036565
 >> iter 15000, loss: 0.026408
 >> iter 16000, loss: 0.022179
 >> iter 17000, loss: 0.020876
 >> iter 18000, loss: 0.019940
 >> iter 19000, loss: 0.035651
 >> iter 20000, loss: 0.026348
   Number of active neurons: 1
 >> iter 21000, loss: 0.026431
 >> iter 22000, loss: 0.026769
 >> iter 23000, loss: 0.025289
 >> iter 24000, loss: 0.020287
 >> iter 25000, loss: 0.030157
 >> iter 26000, loss: 0.021390
 >> iter 27000, loss: 0.024007
 >> iter 28000, loss: 0.018634
 >> iter 29000, loss: 0.018237
 >> iter 30000, loss: 0.016500
   Number of active neurons: 1
 >> iter 31000, loss: 0.018517
 >> iter 32000, loss: 0.020971
 >> iter 33000, loss: 0.018549
 >> iter 34000, loss: 0.020217
 >> iter 35000, loss: 0.017752
 >> iter 36000, loss: 0.018589
 >> iter 37000, loss: 0.018797
 >> iter 38000, loss: 0.021210
 >> iter 39000, loss: 0.028440
 >> iter 40000, loss: 0.023667
   Number of active neurons: 1
 >> iter 41000, loss: 0.030096
 >> iter 42000, loss: 0.027019
 >> iter 43000, loss: 0.028124
 >> iter 44000, loss: 0.025288
 >> iter 45000, loss: 0.025895
 >> iter 46000, loss: 0.024961
 >> iter 47000, loss: 0.034283
 >> iter 48000, loss: 0.024994
 >> iter 49000, loss: 0.020809
 >> iter 50000, loss: 0.020771
   Number of active neurons: 1
 >> iter 51000, loss: 0.019376
 >> iter 52000, loss: 0.016894
 >> iter 53000, loss: 0.016513
 >> iter 54000, loss: 0.016328
 >> iter 55000, loss: 0.019119
 >> iter 56000, loss: 0.037566
 >> iter 57000, loss: 0.023475
 >> iter 58000, loss: 0.020983
 >> iter 59000, loss: 0.017692
 >> iter 60000, loss: 0.020501
   Number of active neurons: 1
 >> iter 61000, loss: 0.043259
 >> iter 62000, loss: 0.033831
 >> iter 63000, loss: 0.027719
 >> iter 64000, loss: 0.024039
 >> iter 65000, loss: 0.018658
 >> iter 66000, loss: 0.026099
 >> iter 67000, loss: 0.041525
 >> iter 68000, loss: 0.025535
 >> iter 69000, loss: 0.029567
 >> iter 70000, loss: 0.027402
   Number of active neurons: 1
 >> iter 71000, loss: 0.024252
 >> iter 72000, loss: 0.051374
 >> iter 73000, loss: 0.033491
 >> iter 74000, loss: 0.023954
 >> iter 75000, loss: 0.020789
 >> iter 76000, loss: 0.019482
 >> iter 77000, loss: 0.020587
 >> iter 78000, loss: 0.018414
 >> iter 79000, loss: 0.019802
 >> iter 80000, loss: 0.020147
   Number of active neurons: 1
 >> iter 81000, loss: 0.032647
 >> iter 82000, loss: 0.021197
 >> iter 83000, loss: 0.040766
 >> iter 84000, loss: 0.028148
 >> iter 85000, loss: 0.024148
 >> iter 86000, loss: 0.026547
 >> iter 87000, loss: 0.021616
 >> iter 88000, loss: 0.020435
 >> iter 89000, loss: 0.018921
 >> iter 90000, loss: 0.017931
   Number of active neurons: 1
 >> iter 91000, loss: 0.020257
 >> iter 92000, loss: 0.017152
 >> iter 93000, loss: 0.019421
 >> iter 94000, loss: 0.017576
 >> iter 95000, loss: 0.019629
 >> iter 96000, loss: 0.028175
 >> iter 97000, loss: 0.020848
 >> iter 98000, loss: 0.017442
 >> iter 99000, loss: 0.016810
 >> iter 100000, loss: 0.016263
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.138376
 >> iter 2000, loss: 4.147308
 >> iter 3000, loss: 1.546593
 >> iter 4000, loss: 0.587781
 >> iter 5000, loss: 0.236618
 >> iter 6000, loss: 0.103001
 >> iter 7000, loss: 0.052477
 >> iter 8000, loss: 0.032715
 >> iter 9000, loss: 0.029838
 >> iter 10000, loss: 0.026433
   Number of active neurons: 2
 >> iter 11000, loss: 0.025316
 >> iter 12000, loss: 0.021893
 >> iter 13000, loss: 0.020057
 >> iter 14000, loss: 0.020455
 >> iter 15000, loss: 0.030205
 >> iter 16000, loss: 0.026829
 >> iter 17000, loss: 0.025791
 >> iter 18000, loss: 0.025708
 >> iter 19000, loss: 0.021142
 >> iter 20000, loss: 0.023064
   Number of active neurons: 2
 >> iter 21000, loss: 0.023971
 >> iter 22000, loss: 0.022467
 >> iter 23000, loss: 0.020034
 >> iter 24000, loss: 0.019621
 >> iter 25000, loss: 0.020841
 >> iter 26000, loss: 0.021282
 >> iter 27000, loss: 0.023154
 >> iter 28000, loss: 0.022487
 >> iter 29000, loss: 0.020824
 >> iter 30000, loss: 0.020717
   Number of active neurons: 2
 >> iter 31000, loss: 0.040130
 >> iter 32000, loss: 0.030612
 >> iter 33000, loss: 0.025521
 >> iter 34000, loss: 0.021662
 >> iter 35000, loss: 0.022222
 >> iter 36000, loss: 0.020893
 >> iter 37000, loss: 0.022653
 >> iter 38000, loss: 0.019867
 >> iter 39000, loss: 0.022849
 >> iter 40000, loss: 0.021834
   Number of active neurons: 2
 >> iter 41000, loss: 0.020295
 >> iter 42000, loss: 0.043032
 >> iter 43000, loss: 0.029952
 >> iter 44000, loss: 0.024653
 >> iter 45000, loss: 0.022630
 >> iter 46000, loss: 0.022068
 >> iter 47000, loss: 0.024997
 >> iter 48000, loss: 0.024566
 >> iter 49000, loss: 0.021876
 >> iter 50000, loss: 0.025245
   Number of active neurons: 2
 >> iter 51000, loss: 0.022960
 >> iter 52000, loss: 0.025006
 >> iter 53000, loss: 0.020294
 >> iter 54000, loss: 0.020743
 >> iter 55000, loss: 0.033291
 >> iter 56000, loss: 0.025346
 >> iter 57000, loss: 0.025538
 >> iter 58000, loss: 0.031903
 >> iter 59000, loss: 0.028008
 >> iter 60000, loss: 0.030895
   Number of active neurons: 2
 >> iter 61000, loss: 0.027928
 >> iter 62000, loss: 0.023934
 >> iter 63000, loss: 0.022741
 >> iter 64000, loss: 0.024018
 >> iter 65000, loss: 0.024044
 >> iter 66000, loss: 0.021625
 >> iter 67000, loss: 0.042989
 >> iter 68000, loss: 0.035259
 >> iter 69000, loss: 0.033187
 >> iter 70000, loss: 0.027886
   Number of active neurons: 2
 >> iter 71000, loss: 0.053727
 >> iter 72000, loss: 0.033728
 >> iter 73000, loss: 0.042470
 >> iter 74000, loss: 0.030416
 >> iter 75000, loss: 0.025325
 >> iter 76000, loss: 0.023269
 >> iter 77000, loss: 0.041876
 >> iter 78000, loss: 0.030150
 >> iter 79000, loss: 0.031406
 >> iter 80000, loss: 0.033371
   Number of active neurons: 2
 >> iter 81000, loss: 0.025998
 >> iter 82000, loss: 0.027385
 >> iter 83000, loss: 0.032393
 >> iter 84000, loss: 0.025683
 >> iter 85000, loss: 0.038861
 >> iter 86000, loss: 0.029380
 >> iter 87000, loss: 0.026315
 >> iter 88000, loss: 0.050478
 >> iter 89000, loss: 0.031079
 >> iter 90000, loss: 0.025226
   Number of active neurons: 2
 >> iter 91000, loss: 0.030716
 >> iter 92000, loss: 0.024037
 >> iter 93000, loss: 0.022146
 >> iter 94000, loss: 0.024698
 >> iter 95000, loss: 0.025479
 >> iter 96000, loss: 0.026780
 >> iter 97000, loss: 0.025745
 >> iter 98000, loss: 0.022756
 >> iter 99000, loss: 0.021479
 >> iter 100000, loss: 0.026825
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.180619
 >> iter 2000, loss: 4.156646
 >> iter 3000, loss: 1.552486
 >> iter 4000, loss: 0.619485
 >> iter 5000, loss: 0.244586
 >> iter 6000, loss: 0.151489
 >> iter 7000, loss: 0.071117
 >> iter 8000, loss: 0.052719
 >> iter 9000, loss: 0.037603
 >> iter 10000, loss: 0.027644
   Number of active neurons: 1
 >> iter 11000, loss: 0.023304
 >> iter 12000, loss: 0.021360
 >> iter 13000, loss: 0.020631
 >> iter 14000, loss: 0.017994
 >> iter 15000, loss: 0.069204
 >> iter 16000, loss: 0.039075
 >> iter 17000, loss: 0.027300
 >> iter 18000, loss: 0.022577
 >> iter 19000, loss: 0.020124
 >> iter 20000, loss: 0.017525
   Number of active neurons: 1
 >> iter 21000, loss: 0.018142
 >> iter 22000, loss: 0.017051
 >> iter 23000, loss: 0.035860
 >> iter 24000, loss: 0.024316
 >> iter 25000, loss: 0.027853
 >> iter 26000, loss: 0.024523
 >> iter 27000, loss: 0.032107
 >> iter 28000, loss: 0.021990
 >> iter 29000, loss: 0.023455
 >> iter 30000, loss: 0.018414
   Number of active neurons: 1
 >> iter 31000, loss: 0.025142
 >> iter 32000, loss: 0.023810
 >> iter 33000, loss: 0.024514
 >> iter 34000, loss: 0.019880
 >> iter 35000, loss: 0.016861
 >> iter 36000, loss: 0.017162
 >> iter 37000, loss: 0.034208
 >> iter 38000, loss: 0.027268
 >> iter 39000, loss: 0.022903
 >> iter 40000, loss: 0.017647
   Number of active neurons: 1
 >> iter 41000, loss: 0.027262
 >> iter 42000, loss: 0.019440
 >> iter 43000, loss: 0.021893
 >> iter 44000, loss: 0.018527
 >> iter 45000, loss: 0.016846
 >> iter 46000, loss: 0.016598
 >> iter 47000, loss: 0.018924
 >> iter 48000, loss: 0.018725
 >> iter 49000, loss: 0.016428
 >> iter 50000, loss: 0.021644
   Number of active neurons: 1
 >> iter 51000, loss: 0.024910
 >> iter 52000, loss: 0.019868
 >> iter 53000, loss: 0.018477
 >> iter 54000, loss: 0.016668
 >> iter 55000, loss: 0.022684
 >> iter 56000, loss: 0.028869
 >> iter 57000, loss: 0.022770
 >> iter 58000, loss: 0.028725
 >> iter 59000, loss: 0.022062
 >> iter 60000, loss: 0.022797
   Number of active neurons: 1
 >> iter 61000, loss: 0.061900
 >> iter 62000, loss: 0.035236
 >> iter 63000, loss: 0.024071
 >> iter 64000, loss: 0.041644
 >> iter 65000, loss: 0.025369
 >> iter 66000, loss: 0.023078
 >> iter 67000, loss: 0.019525
 >> iter 68000, loss: 0.017818
 >> iter 69000, loss: 0.017643
 >> iter 70000, loss: 0.018990
   Number of active neurons: 1
 >> iter 71000, loss: 0.023137
 >> iter 72000, loss: 0.021844
 >> iter 73000, loss: 0.020407
 >> iter 74000, loss: 0.025312
 >> iter 75000, loss: 0.022670
 >> iter 76000, loss: 0.019186
 >> iter 77000, loss: 0.018175
 >> iter 78000, loss: 0.017997
 >> iter 79000, loss: 0.020905
 >> iter 80000, loss: 0.017388
   Number of active neurons: 1
 >> iter 81000, loss: 0.020225
 >> iter 82000, loss: 0.021359
 >> iter 83000, loss: 0.035690
 >> iter 84000, loss: 0.026031
 >> iter 85000, loss: 0.021652
 >> iter 86000, loss: 0.019878
 >> iter 87000, loss: 0.021006
 >> iter 88000, loss: 0.019114
 >> iter 89000, loss: 0.017938
 >> iter 90000, loss: 0.019539
   Number of active neurons: 1
 >> iter 91000, loss: 0.018074
 >> iter 92000, loss: 0.019288
 >> iter 93000, loss: 0.019633
 >> iter 94000, loss: 0.017314
 >> iter 95000, loss: 0.015218
 >> iter 96000, loss: 0.021288
 >> iter 97000, loss: 0.022620
 >> iter 98000, loss: 0.028896
 >> iter 99000, loss: 0.021206
 >> iter 100000, loss: 0.024061
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.123795
 >> iter 2000, loss: 4.153493
 >> iter 3000, loss: 1.563955
 >> iter 4000, loss: 0.592653
 >> iter 5000, loss: 0.239782
 >> iter 6000, loss: 0.103292
 >> iter 7000, loss: 0.052475
 >> iter 8000, loss: 0.046267
 >> iter 9000, loss: 0.035357
 >> iter 10000, loss: 0.028354
   Number of active neurons: 2
 >> iter 11000, loss: 0.026807
 >> iter 12000, loss: 0.023624
 >> iter 13000, loss: 0.020858
 >> iter 14000, loss: 0.022570
 >> iter 15000, loss: 0.023779
 >> iter 16000, loss: 0.022641
 >> iter 17000, loss: 0.027132
 >> iter 18000, loss: 0.028106
 >> iter 19000, loss: 0.023984
 >> iter 20000, loss: 0.024799
   Number of active neurons: 2
 >> iter 21000, loss: 0.021386
 >> iter 22000, loss: 0.022475
 >> iter 23000, loss: 0.020758
 >> iter 24000, loss: 0.021954
 >> iter 25000, loss: 0.026626
 >> iter 26000, loss: 0.039024
 >> iter 27000, loss: 0.046810
 >> iter 28000, loss: 0.030590
 >> iter 29000, loss: 0.036906
 >> iter 30000, loss: 0.028861
   Number of active neurons: 2
 >> iter 31000, loss: 0.025109
 >> iter 32000, loss: 0.023497
 >> iter 33000, loss: 0.021881
 >> iter 34000, loss: 0.025356
 >> iter 35000, loss: 0.033494
 >> iter 36000, loss: 0.031198
 >> iter 37000, loss: 0.024389
 >> iter 38000, loss: 0.031607
 >> iter 39000, loss: 0.023843
 >> iter 40000, loss: 0.021166
   Number of active neurons: 2
 >> iter 41000, loss: 0.032048
 >> iter 42000, loss: 0.026962
 >> iter 43000, loss: 0.026950
 >> iter 44000, loss: 0.023394
 >> iter 45000, loss: 0.024194
 >> iter 46000, loss: 0.021568
 >> iter 47000, loss: 0.023489
 >> iter 48000, loss: 0.022591
 >> iter 49000, loss: 0.021014
 >> iter 50000, loss: 0.019971
   Number of active neurons: 1
 >> iter 51000, loss: 0.018820
 >> iter 52000, loss: 0.028874
 >> iter 53000, loss: 0.029070
 >> iter 54000, loss: 0.021565
 >> iter 55000, loss: 0.024290
 >> iter 56000, loss: 0.024656
 >> iter 57000, loss: 0.020904
 >> iter 58000, loss: 0.018479
 >> iter 59000, loss: 0.016931
 >> iter 60000, loss: 0.018269
   Number of active neurons: 1
 >> iter 61000, loss: 0.018703
 >> iter 62000, loss: 0.019746
 >> iter 63000, loss: 0.025334
 >> iter 64000, loss: 0.021448
 >> iter 65000, loss: 0.022779
 >> iter 66000, loss: 0.019938
 >> iter 67000, loss: 0.029279
 >> iter 68000, loss: 0.021830
 >> iter 69000, loss: 0.039938
 >> iter 70000, loss: 0.033277
   Number of active neurons: 1
 >> iter 71000, loss: 0.027781
 >> iter 72000, loss: 0.021606
 >> iter 73000, loss: 0.026515
 >> iter 74000, loss: 0.025695
 >> iter 75000, loss: 0.029141
 >> iter 76000, loss: 0.030382
 >> iter 77000, loss: 0.021014
 >> iter 78000, loss: 0.017397
 >> iter 79000, loss: 0.018014
 >> iter 80000, loss: 0.018426
   Number of active neurons: 1
 >> iter 81000, loss: 0.017769
 >> iter 82000, loss: 0.017528
 >> iter 83000, loss: 0.022010
 >> iter 84000, loss: 0.021022
 >> iter 85000, loss: 0.024050
 >> iter 86000, loss: 0.020987
 >> iter 87000, loss: 0.038569
 >> iter 88000, loss: 0.028367
 >> iter 89000, loss: 0.022663
 >> iter 90000, loss: 0.019319
   Number of active neurons: 1
 >> iter 91000, loss: 0.018188
 >> iter 92000, loss: 0.017358
 >> iter 93000, loss: 0.016651
 >> iter 94000, loss: 0.017898
 >> iter 95000, loss: 0.016208
 >> iter 96000, loss: 0.018407
 >> iter 97000, loss: 0.017548
 >> iter 98000, loss: 0.029014
 >> iter 99000, loss: 0.025531
 >> iter 100000, loss: 0.021622
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.147877
 >> iter 2000, loss: 4.145235
 >> iter 3000, loss: 1.566728
 >> iter 4000, loss: 0.593294
 >> iter 5000, loss: 0.239437
 >> iter 6000, loss: 0.105879
 >> iter 7000, loss: 0.056278
 >> iter 8000, loss: 0.039566
 >> iter 9000, loss: 0.033096
 >> iter 10000, loss: 0.025784
   Number of active neurons: 2
 >> iter 11000, loss: 0.022660
 >> iter 12000, loss: 0.020701
 >> iter 13000, loss: 0.021884
 >> iter 14000, loss: 0.025138
 >> iter 15000, loss: 0.022560
 >> iter 16000, loss: 0.020945
 >> iter 17000, loss: 0.027227
 >> iter 18000, loss: 0.027558
 >> iter 19000, loss: 0.023690
 >> iter 20000, loss: 0.019841
   Number of active neurons: 2
 >> iter 21000, loss: 0.019481
 >> iter 22000, loss: 0.035363
 >> iter 23000, loss: 0.027850
 >> iter 24000, loss: 0.027813
 >> iter 25000, loss: 0.022588
 >> iter 26000, loss: 0.021957
 >> iter 27000, loss: 0.022773
 >> iter 28000, loss: 0.020115
 >> iter 29000, loss: 0.018675
 >> iter 30000, loss: 0.022780
   Number of active neurons: 1
 >> iter 31000, loss: 0.020605
 >> iter 32000, loss: 0.021718
 >> iter 33000, loss: 0.022197
 >> iter 34000, loss: 0.032290
 >> iter 35000, loss: 0.028280
 >> iter 36000, loss: 0.022703
 >> iter 37000, loss: 0.019672
 >> iter 38000, loss: 0.018459
 >> iter 39000, loss: 0.021652
 >> iter 40000, loss: 0.018646
   Number of active neurons: 1
 >> iter 41000, loss: 0.024619
 >> iter 42000, loss: 0.063485
 >> iter 43000, loss: 0.039653
 >> iter 44000, loss: 0.034404
 >> iter 45000, loss: 0.023617
 >> iter 46000, loss: 0.019977
 >> iter 47000, loss: 0.019944
 >> iter 48000, loss: 0.020135
 >> iter 49000, loss: 0.021036
 >> iter 50000, loss: 0.019157
   Number of active neurons: 1
 >> iter 51000, loss: 0.020735
 >> iter 52000, loss: 0.020019
 >> iter 53000, loss: 0.018437
 >> iter 54000, loss: 0.018239
 >> iter 55000, loss: 0.020112
 >> iter 56000, loss: 0.019195
 >> iter 57000, loss: 0.019455
 >> iter 58000, loss: 0.019650
 >> iter 59000, loss: 0.018930
 >> iter 60000, loss: 0.021703
   Number of active neurons: 1
 >> iter 61000, loss: 0.028388
 >> iter 62000, loss: 0.019853
 >> iter 63000, loss: 0.018914
 >> iter 64000, loss: 0.025884
 >> iter 65000, loss: 0.021810
 >> iter 66000, loss: 0.020493
 >> iter 67000, loss: 0.018029
 >> iter 68000, loss: 0.018213
 >> iter 69000, loss: 0.018508
 >> iter 70000, loss: 0.033299
   Number of active neurons: 1
 >> iter 71000, loss: 0.032811
 >> iter 72000, loss: 0.025359
 >> iter 73000, loss: 0.019465
 >> iter 74000, loss: 0.035046
 >> iter 75000, loss: 0.026019
 >> iter 76000, loss: 0.031814
 >> iter 77000, loss: 0.031930
 >> iter 78000, loss: 0.022569
 >> iter 79000, loss: 0.018905
 >> iter 80000, loss: 0.019307
   Number of active neurons: 1
 >> iter 81000, loss: 0.017356
 >> iter 82000, loss: 0.017118
 >> iter 83000, loss: 0.017304
 >> iter 84000, loss: 0.017253
 >> iter 85000, loss: 0.025654
 >> iter 86000, loss: 0.035966
 >> iter 87000, loss: 0.026557
 >> iter 88000, loss: 0.030804
 >> iter 89000, loss: 0.037322
 >> iter 90000, loss: 0.025039
   Number of active neurons: 1
 >> iter 91000, loss: 0.025549
 >> iter 92000, loss: 0.021526
 >> iter 93000, loss: 0.017491
 >> iter 94000, loss: 0.018983
 >> iter 95000, loss: 0.019581
 >> iter 96000, loss: 0.022287
 >> iter 97000, loss: 0.022619
 >> iter 98000, loss: 0.018517
 >> iter 99000, loss: 0.017789
 >> iter 100000, loss: 0.018784
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.146253
 >> iter 2000, loss: 4.149426
 >> iter 3000, loss: 1.566568
 >> iter 4000, loss: 0.594158
 >> iter 5000, loss: 0.238198
 >> iter 6000, loss: 0.108293
 >> iter 7000, loss: 0.065466
 >> iter 8000, loss: 0.036848
 >> iter 9000, loss: 0.025050
 >> iter 10000, loss: 0.021749
   Number of active neurons: 1
 >> iter 11000, loss: 0.020005
 >> iter 12000, loss: 0.018025
 >> iter 13000, loss: 0.017294
 >> iter 14000, loss: 0.024468
 >> iter 15000, loss: 0.019447
 >> iter 16000, loss: 0.031822
 >> iter 17000, loss: 0.035760
 >> iter 18000, loss: 0.026201
 >> iter 19000, loss: 0.043767
 >> iter 20000, loss: 0.028165
   Number of active neurons: 1
 >> iter 21000, loss: 0.026159
 >> iter 22000, loss: 0.019476
 >> iter 23000, loss: 0.018327
 >> iter 24000, loss: 0.018432
 >> iter 25000, loss: 0.021510
 >> iter 26000, loss: 0.018262
 >> iter 27000, loss: 0.020006
 >> iter 28000, loss: 0.025935
 >> iter 29000, loss: 0.034915
 >> iter 30000, loss: 0.027853
   Number of active neurons: 1
 >> iter 31000, loss: 0.021625
 >> iter 32000, loss: 0.018783
 >> iter 33000, loss: 0.018875
 >> iter 34000, loss: 0.016585
 >> iter 35000, loss: 0.022017
 >> iter 36000, loss: 0.017753
 >> iter 37000, loss: 0.016059
 >> iter 38000, loss: 0.022037
 >> iter 39000, loss: 0.021693
 >> iter 40000, loss: 0.035238
   Number of active neurons: 1
 >> iter 41000, loss: 0.034334
 >> iter 42000, loss: 0.023144
 >> iter 43000, loss: 0.019910
 >> iter 44000, loss: 0.017267
 >> iter 45000, loss: 0.017973
 >> iter 46000, loss: 0.015677
 >> iter 47000, loss: 0.018681
 >> iter 48000, loss: 0.022493
 >> iter 49000, loss: 0.027768
 >> iter 50000, loss: 0.022375
   Number of active neurons: 1
 >> iter 51000, loss: 0.026984
 >> iter 52000, loss: 0.021362
 >> iter 53000, loss: 0.021208
 >> iter 54000, loss: 0.017740
 >> iter 55000, loss: 0.020463
 >> iter 56000, loss: 0.019164
 >> iter 57000, loss: 0.026205
 >> iter 58000, loss: 0.021510
 >> iter 59000, loss: 0.022246
 >> iter 60000, loss: 0.018270
   Number of active neurons: 1
 >> iter 61000, loss: 0.024856
 >> iter 62000, loss: 0.019773
 >> iter 63000, loss: 0.017342
 >> iter 64000, loss: 0.037100
 >> iter 65000, loss: 0.025589
 >> iter 66000, loss: 0.019769
 >> iter 67000, loss: 0.018578
 >> iter 68000, loss: 0.018764
 >> iter 69000, loss: 0.020565
 >> iter 70000, loss: 0.019190
   Number of active neurons: 1
 >> iter 71000, loss: 0.023311
 >> iter 72000, loss: 0.017941
 >> iter 73000, loss: 0.031336
 >> iter 74000, loss: 0.023815
 >> iter 75000, loss: 0.041705
 >> iter 76000, loss: 0.047330
 >> iter 77000, loss: 0.028015
 >> iter 78000, loss: 0.021055
 >> iter 79000, loss: 0.031629
 >> iter 80000, loss: 0.022665
   Number of active neurons: 1
 >> iter 81000, loss: 0.020832
 >> iter 82000, loss: 0.019444
 >> iter 83000, loss: 0.017382
 >> iter 84000, loss: 0.017288
 >> iter 85000, loss: 0.018392
 >> iter 86000, loss: 0.026098
 >> iter 87000, loss: 0.032219
 >> iter 88000, loss: 0.023548
 >> iter 89000, loss: 0.019337
 >> iter 90000, loss: 0.017870
   Number of active neurons: 1
 >> iter 91000, loss: 0.018581
 >> iter 92000, loss: 0.018177
 >> iter 93000, loss: 0.016110
 >> iter 94000, loss: 0.035140
 >> iter 95000, loss: 0.031361
 >> iter 96000, loss: 0.023507
 >> iter 97000, loss: 0.017982
 >> iter 98000, loss: 0.019370
 >> iter 99000, loss: 0.016663
 >> iter 100000, loss: 0.019185
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.980599
 >> iter 2000, loss: 4.076858
 >> iter 3000, loss: 1.522930
 >> iter 4000, loss: 0.576930
 >> iter 5000, loss: 0.228657
 >> iter 6000, loss: 0.105610
 >> iter 7000, loss: 0.054201
 >> iter 8000, loss: 0.034477
 >> iter 9000, loss: 0.029345
 >> iter 10000, loss: 0.026040
   Number of active neurons: 2
 >> iter 11000, loss: 0.025483
 >> iter 12000, loss: 0.023768
 >> iter 13000, loss: 0.039458
 >> iter 14000, loss: 0.032725
 >> iter 15000, loss: 0.029868
 >> iter 16000, loss: 0.026589
 >> iter 17000, loss: 0.022954
 >> iter 18000, loss: 0.029846
 >> iter 19000, loss: 0.026210
 >> iter 20000, loss: 0.041311
   Number of active neurons: 2
 >> iter 21000, loss: 0.031410
 >> iter 22000, loss: 0.025630
 >> iter 23000, loss: 0.022748
 >> iter 24000, loss: 0.035075
 >> iter 25000, loss: 0.047273
 >> iter 26000, loss: 0.035254
 >> iter 27000, loss: 0.025575
 >> iter 28000, loss: 0.027461
 >> iter 29000, loss: 0.022576
 >> iter 30000, loss: 0.021071
   Number of active neurons: 1
 >> iter 31000, loss: 0.023871
 >> iter 32000, loss: 0.022357
 >> iter 33000, loss: 0.022506
 >> iter 34000, loss: 0.024755
 >> iter 35000, loss: 0.019437
 >> iter 36000, loss: 0.018083
 >> iter 37000, loss: 0.020782
 >> iter 38000, loss: 0.019135
 >> iter 39000, loss: 0.017328
 >> iter 40000, loss: 0.017365
   Number of active neurons: 1
 >> iter 41000, loss: 0.025370
 >> iter 42000, loss: 0.025995
 >> iter 43000, loss: 0.020591
 >> iter 44000, loss: 0.018815
 >> iter 45000, loss: 0.018064
 >> iter 46000, loss: 0.020538
 >> iter 47000, loss: 0.020513
 >> iter 48000, loss: 0.017455
 >> iter 49000, loss: 0.017866
 >> iter 50000, loss: 0.016618
   Number of active neurons: 1
 >> iter 51000, loss: 0.017023
 >> iter 52000, loss: 0.021605
 >> iter 53000, loss: 0.018644
 >> iter 54000, loss: 0.017336
 >> iter 55000, loss: 0.019220
 >> iter 56000, loss: 0.025218
 >> iter 57000, loss: 0.023254
 >> iter 58000, loss: 0.018548
 >> iter 59000, loss: 0.028236
 >> iter 60000, loss: 0.022477
   Number of active neurons: 1
 >> iter 61000, loss: 0.018895
 >> iter 62000, loss: 0.018668
 >> iter 63000, loss: 0.018895
 >> iter 64000, loss: 0.017044
 >> iter 65000, loss: 0.018359
 >> iter 66000, loss: 0.018390
 >> iter 67000, loss: 0.020331
 >> iter 68000, loss: 0.030224
 >> iter 69000, loss: 0.035212
 >> iter 70000, loss: 0.024988
   Number of active neurons: 1
 >> iter 71000, loss: 0.018964
 >> iter 72000, loss: 0.016638
 >> iter 73000, loss: 0.019040
 >> iter 74000, loss: 0.024144
 >> iter 75000, loss: 0.031634
 >> iter 76000, loss: 0.022688
 >> iter 77000, loss: 0.021546
 >> iter 78000, loss: 0.028996
 >> iter 79000, loss: 0.023399
 >> iter 80000, loss: 0.020000
   Number of active neurons: 1
 >> iter 81000, loss: 0.033810
 >> iter 82000, loss: 0.022637
 >> iter 83000, loss: 0.022357
 >> iter 84000, loss: 0.019388
 >> iter 85000, loss: 0.021120
 >> iter 86000, loss: 0.021059
 >> iter 87000, loss: 0.039838
 >> iter 88000, loss: 0.025313
 >> iter 89000, loss: 0.020206
 >> iter 90000, loss: 0.019496
   Number of active neurons: 1
 >> iter 91000, loss: 0.024098
 >> iter 92000, loss: 0.026737
 >> iter 93000, loss: 0.019195
 >> iter 94000, loss: 0.019341
 >> iter 95000, loss: 0.021849
 >> iter 96000, loss: 0.023825
 >> iter 97000, loss: 0.020432
 >> iter 98000, loss: 0.038827
 >> iter 99000, loss: 0.026318
 >> iter 100000, loss: 0.020078
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.030806
 >> iter 2000, loss: 4.097587
 >> iter 3000, loss: 1.531818
 >> iter 4000, loss: 0.583044
 >> iter 5000, loss: 0.229248
 >> iter 6000, loss: 0.099046
 >> iter 7000, loss: 0.062893
 >> iter 8000, loss: 0.038132
 >> iter 9000, loss: 0.029226
 >> iter 10000, loss: 0.025466
   Number of active neurons: 2
 >> iter 11000, loss: 0.039991
 >> iter 12000, loss: 0.027335
 >> iter 13000, loss: 0.022503
 >> iter 14000, loss: 0.023230
 >> iter 15000, loss: 0.021238
 >> iter 16000, loss: 0.021357
 >> iter 17000, loss: 0.037097
 >> iter 18000, loss: 0.029201
 >> iter 19000, loss: 0.025484
 >> iter 20000, loss: 0.024903
   Number of active neurons: 2
 >> iter 21000, loss: 0.023110
 >> iter 22000, loss: 0.020878
 >> iter 23000, loss: 0.022544
 >> iter 24000, loss: 0.022421
 >> iter 25000, loss: 0.022654
 >> iter 26000, loss: 0.024478
 >> iter 27000, loss: 0.026075
 >> iter 28000, loss: 0.024212
 >> iter 29000, loss: 0.035596
 >> iter 30000, loss: 0.024277
   Number of active neurons: 1
 >> iter 31000, loss: 0.022359
 >> iter 32000, loss: 0.022577
 >> iter 33000, loss: 0.022554
 >> iter 34000, loss: 0.023312
 >> iter 35000, loss: 0.034203
 >> iter 36000, loss: 0.029060
 >> iter 37000, loss: 0.022943
 >> iter 38000, loss: 0.024178
 >> iter 39000, loss: 0.020880
 >> iter 40000, loss: 0.020053
   Number of active neurons: 1
 >> iter 41000, loss: 0.022163
 >> iter 42000, loss: 0.018333
 >> iter 43000, loss: 0.023457
 >> iter 44000, loss: 0.020235
 >> iter 45000, loss: 0.019128
 >> iter 46000, loss: 0.016729
 >> iter 47000, loss: 0.031111
 >> iter 48000, loss: 0.058204
 >> iter 49000, loss: 0.033360
 >> iter 50000, loss: 0.021921
   Number of active neurons: 1
 >> iter 51000, loss: 0.024719
 >> iter 52000, loss: 0.022985
 >> iter 53000, loss: 0.020569
 >> iter 54000, loss: 0.018777
 >> iter 55000, loss: 0.018013
 >> iter 56000, loss: 0.035583
 >> iter 57000, loss: 0.033200
 >> iter 58000, loss: 0.022181
 >> iter 59000, loss: 0.022386
 >> iter 60000, loss: 0.045755
   Number of active neurons: 1
 >> iter 61000, loss: 0.028726
 >> iter 62000, loss: 0.028988
 >> iter 63000, loss: 0.024365
 >> iter 64000, loss: 0.020739
 >> iter 65000, loss: 0.021484
 >> iter 66000, loss: 0.019234
 >> iter 67000, loss: 0.016799
 >> iter 68000, loss: 0.021038
 >> iter 69000, loss: 0.021017
 >> iter 70000, loss: 0.027171
   Number of active neurons: 1
 >> iter 71000, loss: 0.024025
 >> iter 72000, loss: 0.037544
 >> iter 73000, loss: 0.026503
 >> iter 74000, loss: 0.022821
 >> iter 75000, loss: 0.022040
 >> iter 76000, loss: 0.019117
 >> iter 77000, loss: 0.022688
 >> iter 78000, loss: 0.020080
 >> iter 79000, loss: 0.019027
 >> iter 80000, loss: 0.030315
   Number of active neurons: 1
 >> iter 81000, loss: 0.028793
 >> iter 82000, loss: 0.031121
 >> iter 83000, loss: 0.028138
 >> iter 84000, loss: 0.023870
 >> iter 85000, loss: 0.019439
 >> iter 86000, loss: 0.024509
 >> iter 87000, loss: 0.021261
 >> iter 88000, loss: 0.022645
 >> iter 89000, loss: 0.026736
 >> iter 90000, loss: 0.020486
   Number of active neurons: 1
 >> iter 91000, loss: 0.020912
 >> iter 92000, loss: 0.029859
 >> iter 93000, loss: 0.021630
 >> iter 94000, loss: 0.020520
 >> iter 95000, loss: 0.021254
 >> iter 96000, loss: 0.018251
 >> iter 97000, loss: 0.019893
 >> iter 98000, loss: 0.023481
 >> iter 99000, loss: 0.021539
 >> iter 100000, loss: 0.025391
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.997167
 >> iter 2000, loss: 4.091435
 >> iter 3000, loss: 1.525588
 >> iter 4000, loss: 0.587399
 >> iter 5000, loss: 0.236200
 >> iter 6000, loss: 0.103065
 >> iter 7000, loss: 0.054591
 >> iter 8000, loss: 0.033679
 >> iter 9000, loss: 0.026177
 >> iter 10000, loss: 0.028296
   Number of active neurons: 2
 >> iter 11000, loss: 0.022837
 >> iter 12000, loss: 0.040433
 >> iter 13000, loss: 0.029299
 >> iter 14000, loss: 0.029135
 >> iter 15000, loss: 0.024090
 >> iter 16000, loss: 0.022276
 >> iter 17000, loss: 0.023452
 >> iter 18000, loss: 0.021214
 >> iter 19000, loss: 0.023981
 >> iter 20000, loss: 0.021923
   Number of active neurons: 2
 >> iter 21000, loss: 0.042795
 >> iter 22000, loss: 0.029365
 >> iter 23000, loss: 0.023034
 >> iter 24000, loss: 0.034000
 >> iter 25000, loss: 0.038259
 >> iter 26000, loss: 0.029060
 >> iter 27000, loss: 0.037640
 >> iter 28000, loss: 0.026204
 >> iter 29000, loss: 0.032791
 >> iter 30000, loss: 0.025686
   Number of active neurons: 2
 >> iter 31000, loss: 0.022691
 >> iter 32000, loss: 0.021304
 >> iter 33000, loss: 0.030172
 >> iter 34000, loss: 0.023669
 >> iter 35000, loss: 0.023277
 >> iter 36000, loss: 0.021765
 >> iter 37000, loss: 0.030165
 >> iter 38000, loss: 0.024580
 >> iter 39000, loss: 0.025050
 >> iter 40000, loss: 0.024157
   Number of active neurons: 2
 >> iter 41000, loss: 0.024314
 >> iter 42000, loss: 0.021993
 >> iter 43000, loss: 0.024291
 >> iter 44000, loss: 0.024596
 >> iter 45000, loss: 0.024148
 >> iter 46000, loss: 0.021720
 >> iter 47000, loss: 0.020254
 >> iter 48000, loss: 0.020992
 >> iter 49000, loss: 0.022685
 >> iter 50000, loss: 0.020055
   Number of active neurons: 1
 >> iter 51000, loss: 0.019788
 >> iter 52000, loss: 0.017059
 >> iter 53000, loss: 0.020096
 >> iter 54000, loss: 0.019024
 >> iter 55000, loss: 0.025534
 >> iter 56000, loss: 0.018627
 >> iter 57000, loss: 0.017181
 >> iter 58000, loss: 0.018741
 >> iter 59000, loss: 0.020517
 >> iter 60000, loss: 0.018186
   Number of active neurons: 1
 >> iter 61000, loss: 0.019013
 >> iter 62000, loss: 0.021406
 >> iter 63000, loss: 0.020276
 >> iter 64000, loss: 0.025608
 >> iter 65000, loss: 0.021031
 >> iter 66000, loss: 0.034765
 >> iter 67000, loss: 0.024796
 >> iter 68000, loss: 0.018761
 >> iter 69000, loss: 0.017859
 >> iter 70000, loss: 0.021252
   Number of active neurons: 1
 >> iter 71000, loss: 0.031221
 >> iter 72000, loss: 0.024653
 >> iter 73000, loss: 0.030268
 >> iter 74000, loss: 0.035161
 >> iter 75000, loss: 0.038917
 >> iter 76000, loss: 0.026249
 >> iter 77000, loss: 0.020311
 >> iter 78000, loss: 0.018431
 >> iter 79000, loss: 0.030912
 >> iter 80000, loss: 0.038261
   Number of active neurons: 1
 >> iter 81000, loss: 0.025721
 >> iter 82000, loss: 0.022203
 >> iter 83000, loss: 0.030472
 >> iter 84000, loss: 0.029607
 >> iter 85000, loss: 0.022400
 >> iter 86000, loss: 0.024297
 >> iter 87000, loss: 0.022115
 >> iter 88000, loss: 0.032549
 >> iter 89000, loss: 0.021821
 >> iter 90000, loss: 0.020110
   Number of active neurons: 1
 >> iter 91000, loss: 0.018936
 >> iter 92000, loss: 0.018914
 >> iter 93000, loss: 0.029342
 >> iter 94000, loss: 0.030295
 >> iter 95000, loss: 0.021079
 >> iter 96000, loss: 0.021188
 >> iter 97000, loss: 0.018910
 >> iter 98000, loss: 0.018659
 >> iter 99000, loss: 0.021760
 >> iter 100000, loss: 0.042852
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.971656
 >> iter 2000, loss: 4.074244
 >> iter 3000, loss: 1.522497
 >> iter 4000, loss: 0.582532
 >> iter 5000, loss: 0.231171
 >> iter 6000, loss: 0.099741
 >> iter 7000, loss: 0.055050
 >> iter 8000, loss: 0.041350
 >> iter 9000, loss: 0.039949
 >> iter 10000, loss: 0.034612
   Number of active neurons: 2
 >> iter 11000, loss: 0.027231
 >> iter 12000, loss: 0.022974
 >> iter 13000, loss: 0.024738
 >> iter 14000, loss: 0.020751
 >> iter 15000, loss: 0.062258
 >> iter 16000, loss: 0.037679
 >> iter 17000, loss: 0.027787
 >> iter 18000, loss: 0.029317
 >> iter 19000, loss: 0.029596
 >> iter 20000, loss: 0.023745
   Number of active neurons: 2
 >> iter 21000, loss: 0.022137
 >> iter 22000, loss: 0.022016
 >> iter 23000, loss: 0.021863
 >> iter 24000, loss: 0.022049
 >> iter 25000, loss: 0.020861
 >> iter 26000, loss: 0.030442
 >> iter 27000, loss: 0.025433
 >> iter 28000, loss: 0.023045
 >> iter 29000, loss: 0.026864
 >> iter 30000, loss: 0.028190
   Number of active neurons: 2
 >> iter 31000, loss: 0.029230
 >> iter 32000, loss: 0.060399
 >> iter 33000, loss: 0.043408
 >> iter 34000, loss: 0.027263
 >> iter 35000, loss: 0.025664
 >> iter 36000, loss: 0.047956
 >> iter 37000, loss: 0.035512
 >> iter 38000, loss: 0.027292
 >> iter 39000, loss: 0.023902
 >> iter 40000, loss: 0.020788
   Number of active neurons: 1
 >> iter 41000, loss: 0.019067
 >> iter 42000, loss: 0.020261
 >> iter 43000, loss: 0.024233
 >> iter 44000, loss: 0.019200
 >> iter 45000, loss: 0.019269
 >> iter 46000, loss: 0.022424
 >> iter 47000, loss: 0.019088
 >> iter 48000, loss: 0.021705
 >> iter 49000, loss: 0.022166
 >> iter 50000, loss: 0.019501
   Number of active neurons: 1
 >> iter 51000, loss: 0.043056
 >> iter 52000, loss: 0.034831
 >> iter 53000, loss: 0.037166
 >> iter 54000, loss: 0.025683
 >> iter 55000, loss: 0.020845
 >> iter 56000, loss: 0.020440
 >> iter 57000, loss: 0.017218
 >> iter 58000, loss: 0.015788
 >> iter 59000, loss: 0.016740
 >> iter 60000, loss: 0.019520
   Number of active neurons: 1
 >> iter 61000, loss: 0.036285
 >> iter 62000, loss: 0.029177
 >> iter 63000, loss: 0.024031
 >> iter 64000, loss: 0.018271
 >> iter 65000, loss: 0.021111
 >> iter 66000, loss: 0.018713
 >> iter 67000, loss: 0.024678
 >> iter 68000, loss: 0.018612
 >> iter 69000, loss: 0.021089
 >> iter 70000, loss: 0.020194
   Number of active neurons: 1
 >> iter 71000, loss: 0.021077
 >> iter 72000, loss: 0.021521
 >> iter 73000, loss: 0.019725
 >> iter 74000, loss: 0.021090
 >> iter 75000, loss: 0.019551
 >> iter 76000, loss: 0.017425
 >> iter 77000, loss: 0.016599
 >> iter 78000, loss: 0.019595
 >> iter 79000, loss: 0.016576
 >> iter 80000, loss: 0.018345
   Number of active neurons: 1
 >> iter 81000, loss: 0.022792
 >> iter 82000, loss: 0.024351
 >> iter 83000, loss: 0.030945
 >> iter 84000, loss: 0.047219
 >> iter 85000, loss: 0.040408
 >> iter 86000, loss: 0.024620
 >> iter 87000, loss: 0.020121
 >> iter 88000, loss: 0.024499
 >> iter 89000, loss: 0.021743
 >> iter 90000, loss: 0.018200
   Number of active neurons: 1
 >> iter 91000, loss: 0.019021
 >> iter 92000, loss: 0.019046
 >> iter 93000, loss: 0.018847
 >> iter 94000, loss: 0.025155
 >> iter 95000, loss: 0.025375
 >> iter 96000, loss: 0.020297
 >> iter 97000, loss: 0.017329
 >> iter 98000, loss: 0.017635
 >> iter 99000, loss: 0.018184
 >> iter 100000, loss: 0.020934
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.239567
 >> iter 2000, loss: 4.196948
 >> iter 3000, loss: 1.570953
 >> iter 4000, loss: 0.614960
 >> iter 5000, loss: 0.250455
 >> iter 6000, loss: 0.125812
 >> iter 7000, loss: 0.062426
 >> iter 8000, loss: 0.036051
 >> iter 9000, loss: 0.027066
 >> iter 10000, loss: 0.030160
   Number of active neurons: 2
 >> iter 11000, loss: 0.027202
 >> iter 12000, loss: 0.027189
 >> iter 13000, loss: 0.026248
 >> iter 14000, loss: 0.022218
 >> iter 15000, loss: 0.020958
 >> iter 16000, loss: 0.020691
 >> iter 17000, loss: 0.019283
 >> iter 18000, loss: 0.019079
 >> iter 19000, loss: 0.020032
 >> iter 20000, loss: 0.020533
   Number of active neurons: 1
 >> iter 21000, loss: 0.030000
 >> iter 22000, loss: 0.021868
 >> iter 23000, loss: 0.029213
 >> iter 24000, loss: 0.020641
 >> iter 25000, loss: 0.024350
 >> iter 26000, loss: 0.028236
 >> iter 27000, loss: 0.026155
 >> iter 28000, loss: 0.019381
 >> iter 29000, loss: 0.023461
 >> iter 30000, loss: 0.047256
   Number of active neurons: 1
 >> iter 31000, loss: 0.036838
 >> iter 32000, loss: 0.024151
 >> iter 33000, loss: 0.019036
 >> iter 34000, loss: 0.017870
 >> iter 35000, loss: 0.016666
 >> iter 36000, loss: 0.029228
 >> iter 37000, loss: 0.023864
 >> iter 38000, loss: 0.030547
 >> iter 39000, loss: 0.022479
 >> iter 40000, loss: 0.024290
   Number of active neurons: 1
 >> iter 41000, loss: 0.019373
 >> iter 42000, loss: 0.018083
 >> iter 43000, loss: 0.018390
 >> iter 44000, loss: 0.018543
 >> iter 45000, loss: 0.021674
 >> iter 46000, loss: 0.020621
 >> iter 47000, loss: 0.022537
 >> iter 48000, loss: 0.033864
 >> iter 49000, loss: 0.028742
 >> iter 50000, loss: 0.020096
   Number of active neurons: 1
 >> iter 51000, loss: 0.020735
 >> iter 52000, loss: 0.030820
 >> iter 53000, loss: 0.023681
 >> iter 54000, loss: 0.023512
 >> iter 55000, loss: 0.019656
 >> iter 56000, loss: 0.017075
 >> iter 57000, loss: 0.017739
 >> iter 58000, loss: 0.018095
 >> iter 59000, loss: 0.020450
 >> iter 60000, loss: 0.019577
   Number of active neurons: 1
 >> iter 61000, loss: 0.017497
 >> iter 62000, loss: 0.025205
 >> iter 63000, loss: 0.027826
 >> iter 64000, loss: 0.030912
 >> iter 65000, loss: 0.021241
 >> iter 66000, loss: 0.030943
 >> iter 67000, loss: 0.036715
 >> iter 68000, loss: 0.027225
 >> iter 69000, loss: 0.024320
 >> iter 70000, loss: 0.024835
   Number of active neurons: 1
 >> iter 71000, loss: 0.021034
 >> iter 72000, loss: 0.019998
 >> iter 73000, loss: 0.022980
 >> iter 74000, loss: 0.018379
 >> iter 75000, loss: 0.017784
 >> iter 76000, loss: 0.017559
 >> iter 77000, loss: 0.018050
 >> iter 78000, loss: 0.019819
 >> iter 79000, loss: 0.022645
 >> iter 80000, loss: 0.023119
   Number of active neurons: 1
 >> iter 81000, loss: 0.037053
 >> iter 82000, loss: 0.024860
 >> iter 83000, loss: 0.025241
 >> iter 84000, loss: 0.019368
 >> iter 85000, loss: 0.029830
 >> iter 86000, loss: 0.023545
 >> iter 87000, loss: 0.022739
 >> iter 88000, loss: 0.021012
 >> iter 89000, loss: 0.017666
 >> iter 90000, loss: 0.027502
   Number of active neurons: 1
 >> iter 91000, loss: 0.022672
 >> iter 92000, loss: 0.018773
 >> iter 93000, loss: 0.017797
 >> iter 94000, loss: 0.021277
 >> iter 95000, loss: 0.021624
 >> iter 96000, loss: 0.021628
 >> iter 97000, loss: 0.021858
 >> iter 98000, loss: 0.021116
 >> iter 99000, loss: 0.020620
 >> iter 100000, loss: 0.018668
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.038604
 >> iter 2000, loss: 4.108978
 >> iter 3000, loss: 1.536668
 >> iter 4000, loss: 0.584743
 >> iter 5000, loss: 0.232255
 >> iter 6000, loss: 0.106056
 >> iter 7000, loss: 0.052319
 >> iter 8000, loss: 0.039678
 >> iter 9000, loss: 0.027976
 >> iter 10000, loss: 0.029239
   Number of active neurons: 2
 >> iter 11000, loss: 0.029561
 >> iter 12000, loss: 0.024704
 >> iter 13000, loss: 0.023239
 >> iter 14000, loss: 0.042853
 >> iter 15000, loss: 0.031995
 >> iter 16000, loss: 0.036824
 >> iter 17000, loss: 0.030592
 >> iter 18000, loss: 0.031378
 >> iter 19000, loss: 0.025623
 >> iter 20000, loss: 0.023898
   Number of active neurons: 2
 >> iter 21000, loss: 0.021408
 >> iter 22000, loss: 0.021340
 >> iter 23000, loss: 0.026956
 >> iter 24000, loss: 0.035937
 >> iter 25000, loss: 0.025075
 >> iter 26000, loss: 0.029361
 >> iter 27000, loss: 0.029697
 >> iter 28000, loss: 0.022413
 >> iter 29000, loss: 0.023155
 >> iter 30000, loss: 0.021487
   Number of active neurons: 2
 >> iter 31000, loss: 0.020214
 >> iter 32000, loss: 0.023352
 >> iter 33000, loss: 0.028307
 >> iter 34000, loss: 0.023541
 >> iter 35000, loss: 0.021720
 >> iter 36000, loss: 0.022814
 >> iter 37000, loss: 0.020181
 >> iter 38000, loss: 0.025555
 >> iter 39000, loss: 0.024283
 >> iter 40000, loss: 0.021822
   Number of active neurons: 1
 >> iter 41000, loss: 0.019171
 >> iter 42000, loss: 0.019804
 >> iter 43000, loss: 0.033250
 >> iter 44000, loss: 0.022801
 >> iter 45000, loss: 0.019817
 >> iter 46000, loss: 0.026276
 >> iter 47000, loss: 0.035192
 >> iter 48000, loss: 0.036308
 >> iter 49000, loss: 0.023496
 >> iter 50000, loss: 0.030378
   Number of active neurons: 1
 >> iter 51000, loss: 0.021093
 >> iter 52000, loss: 0.018694
 >> iter 53000, loss: 0.019544
 >> iter 54000, loss: 0.017425
 >> iter 55000, loss: 0.015746
 >> iter 56000, loss: 0.017991
 >> iter 57000, loss: 0.017274
 >> iter 58000, loss: 0.019261
 >> iter 59000, loss: 0.016535
 >> iter 60000, loss: 0.022017
   Number of active neurons: 1
 >> iter 61000, loss: 0.029501
 >> iter 62000, loss: 0.047092
 >> iter 63000, loss: 0.028888
 >> iter 64000, loss: 0.026924
 >> iter 65000, loss: 0.019642
 >> iter 66000, loss: 0.022323
 >> iter 67000, loss: 0.020515
 >> iter 68000, loss: 0.031487
 >> iter 69000, loss: 0.023241
 >> iter 70000, loss: 0.022837
   Number of active neurons: 1
 >> iter 71000, loss: 0.024188
 >> iter 72000, loss: 0.019574
 >> iter 73000, loss: 0.017171
 >> iter 74000, loss: 0.020351
 >> iter 75000, loss: 0.021301
 >> iter 76000, loss: 0.018241
 >> iter 77000, loss: 0.025190
 >> iter 78000, loss: 0.023015
 >> iter 79000, loss: 0.021820
 >> iter 80000, loss: 0.023401
   Number of active neurons: 1
 >> iter 81000, loss: 0.018594
 >> iter 82000, loss: 0.017343
 >> iter 83000, loss: 0.034912
 >> iter 84000, loss: 0.034573
 >> iter 85000, loss: 0.026646
 >> iter 86000, loss: 0.020570
 >> iter 87000, loss: 0.018686
 >> iter 88000, loss: 0.017003
 >> iter 89000, loss: 0.016096
 >> iter 90000, loss: 0.022274
   Number of active neurons: 1
 >> iter 91000, loss: 0.023328
 >> iter 92000, loss: 0.021253
 >> iter 93000, loss: 0.018223
 >> iter 94000, loss: 0.042338
 >> iter 95000, loss: 0.028290
 >> iter 96000, loss: 0.037209
 >> iter 97000, loss: 0.024736
 >> iter 98000, loss: 0.031633
 >> iter 99000, loss: 0.029716
 >> iter 100000, loss: 0.023958
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.047970
 >> iter 2000, loss: 4.105506
 >> iter 3000, loss: 1.532071
 >> iter 4000, loss: 0.581093
 >> iter 5000, loss: 0.233150
 >> iter 6000, loss: 0.103322
 >> iter 7000, loss: 0.054386
 >> iter 8000, loss: 0.035816
 >> iter 9000, loss: 0.028832
 >> iter 10000, loss: 0.039586
   Number of active neurons: 2
 >> iter 11000, loss: 0.027108
 >> iter 12000, loss: 0.027628
 >> iter 13000, loss: 0.029678
 >> iter 14000, loss: 0.033561
 >> iter 15000, loss: 0.028139
 >> iter 16000, loss: 0.026417
 >> iter 17000, loss: 0.026320
 >> iter 18000, loss: 0.025439
 >> iter 19000, loss: 0.021603
 >> iter 20000, loss: 0.021290
   Number of active neurons: 2
 >> iter 21000, loss: 0.024953
 >> iter 22000, loss: 0.021138
 >> iter 23000, loss: 0.027267
 >> iter 24000, loss: 0.025393
 >> iter 25000, loss: 0.027849
 >> iter 26000, loss: 0.047879
 >> iter 27000, loss: 0.030934
 >> iter 28000, loss: 0.029717
 >> iter 29000, loss: 0.023901
 >> iter 30000, loss: 0.024428
   Number of active neurons: 2
 >> iter 31000, loss: 0.023243
 >> iter 32000, loss: 0.029694
 >> iter 33000, loss: 0.023612
 >> iter 34000, loss: 0.021970
 >> iter 35000, loss: 0.022752
 >> iter 36000, loss: 0.040249
 >> iter 37000, loss: 0.028107
 >> iter 38000, loss: 0.038050
 >> iter 39000, loss: 0.026712
 >> iter 40000, loss: 0.026607
   Number of active neurons: 2
 >> iter 41000, loss: 0.023173
 >> iter 42000, loss: 0.022265
 >> iter 43000, loss: 0.020631
 >> iter 44000, loss: 0.029379
 >> iter 45000, loss: 0.021923
 >> iter 46000, loss: 0.024570
 >> iter 47000, loss: 0.023986
 >> iter 48000, loss: 0.020295
 >> iter 49000, loss: 0.024971
 >> iter 50000, loss: 0.033883
   Number of active neurons: 1
 >> iter 51000, loss: 0.022714
 >> iter 52000, loss: 0.022011
 >> iter 53000, loss: 0.021791
 >> iter 54000, loss: 0.023526
 >> iter 55000, loss: 0.020728
 >> iter 56000, loss: 0.019596
 >> iter 57000, loss: 0.038124
 >> iter 58000, loss: 0.029826
 >> iter 59000, loss: 0.025254
 >> iter 60000, loss: 0.019881
   Number of active neurons: 1
 >> iter 61000, loss: 0.059591
 >> iter 62000, loss: 0.033185
 >> iter 63000, loss: 0.024360
 >> iter 64000, loss: 0.020701
 >> iter 65000, loss: 0.024571
 >> iter 66000, loss: 0.020741
 >> iter 67000, loss: 0.020993
 >> iter 68000, loss: 0.018437
 >> iter 69000, loss: 0.018475
 >> iter 70000, loss: 0.025234
   Number of active neurons: 1
 >> iter 71000, loss: 0.020649
 >> iter 72000, loss: 0.017485
 >> iter 73000, loss: 0.017140
 >> iter 74000, loss: 0.019686
 >> iter 75000, loss: 0.018264
 >> iter 76000, loss: 0.028630
 >> iter 77000, loss: 0.021352
 >> iter 78000, loss: 0.026738
 >> iter 79000, loss: 0.023719
 >> iter 80000, loss: 0.035055
   Number of active neurons: 1
 >> iter 81000, loss: 0.024586
 >> iter 82000, loss: 0.019887
 >> iter 83000, loss: 0.057062
 >> iter 84000, loss: 0.034341
 >> iter 85000, loss: 0.023600
 >> iter 86000, loss: 0.019468
 >> iter 87000, loss: 0.018156
 >> iter 88000, loss: 0.018362
 >> iter 89000, loss: 0.033876
 >> iter 90000, loss: 0.023915
   Number of active neurons: 1
 >> iter 91000, loss: 0.019676
 >> iter 92000, loss: 0.020746
 >> iter 93000, loss: 0.020339
 >> iter 94000, loss: 0.019344
 >> iter 95000, loss: 0.018159
 >> iter 96000, loss: 0.016975
 >> iter 97000, loss: 0.021104
 >> iter 98000, loss: 0.019723
 >> iter 99000, loss: 0.031199
 >> iter 100000, loss: 0.022492
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.085168
 >> iter 2000, loss: 4.127320
 >> iter 3000, loss: 1.545574
 >> iter 4000, loss: 0.588685
 >> iter 5000, loss: 0.243281
 >> iter 6000, loss: 0.106976
 >> iter 7000, loss: 0.052729
 >> iter 8000, loss: 0.034295
 >> iter 9000, loss: 0.025588
 >> iter 10000, loss: 0.019663
   Number of active neurons: 1
 >> iter 11000, loss: 0.023510
 >> iter 12000, loss: 0.023309
 >> iter 13000, loss: 0.019041
 >> iter 14000, loss: 0.026776
 >> iter 15000, loss: 0.024327
 >> iter 16000, loss: 0.020919
 >> iter 17000, loss: 0.019268
 >> iter 18000, loss: 0.024319
 >> iter 19000, loss: 0.019700
 >> iter 20000, loss: 0.016665
   Number of active neurons: 1
 >> iter 21000, loss: 0.019167
 >> iter 22000, loss: 0.018339
 >> iter 23000, loss: 0.020474
 >> iter 24000, loss: 0.017974
 >> iter 25000, loss: 0.027963
 >> iter 26000, loss: 0.026827
 >> iter 27000, loss: 0.020656
 >> iter 28000, loss: 0.017224
 >> iter 29000, loss: 0.019124
 >> iter 30000, loss: 0.029534
   Number of active neurons: 1
 >> iter 31000, loss: 0.026281
 >> iter 32000, loss: 0.024024
 >> iter 33000, loss: 0.021059
 >> iter 34000, loss: 0.018313
 >> iter 35000, loss: 0.019486
 >> iter 36000, loss: 0.021339
 >> iter 37000, loss: 0.020966
 >> iter 38000, loss: 0.029281
 >> iter 39000, loss: 0.022769
 >> iter 40000, loss: 0.024044
   Number of active neurons: 1
 >> iter 41000, loss: 0.023310
 >> iter 42000, loss: 0.018224
 >> iter 43000, loss: 0.022192
 >> iter 44000, loss: 0.018516
 >> iter 45000, loss: 0.019861
 >> iter 46000, loss: 0.024240
 >> iter 47000, loss: 0.024623
 >> iter 48000, loss: 0.020440
 >> iter 49000, loss: 0.017606
 >> iter 50000, loss: 0.016869
   Number of active neurons: 1
 >> iter 51000, loss: 0.016422
 >> iter 52000, loss: 0.041580
 >> iter 53000, loss: 0.028762
 >> iter 54000, loss: 0.024664
 >> iter 55000, loss: 0.020621
 >> iter 56000, loss: 0.026542
 >> iter 57000, loss: 0.030875
 >> iter 58000, loss: 0.022082
 >> iter 59000, loss: 0.021922
 >> iter 60000, loss: 0.019306
   Number of active neurons: 1
 >> iter 61000, loss: 0.017784
 >> iter 62000, loss: 0.018440
 >> iter 63000, loss: 0.018401
 >> iter 64000, loss: 0.044508
 >> iter 65000, loss: 0.026887
 >> iter 66000, loss: 0.022433
 >> iter 67000, loss: 0.020380
 >> iter 68000, loss: 0.023126
 >> iter 69000, loss: 0.022393
 >> iter 70000, loss: 0.034835
   Number of active neurons: 1
 >> iter 71000, loss: 0.026802
 >> iter 72000, loss: 0.031384
 >> iter 73000, loss: 0.035386
 >> iter 74000, loss: 0.024906
 >> iter 75000, loss: 0.019734
 >> iter 76000, loss: 0.020840
 >> iter 77000, loss: 0.017589
 >> iter 78000, loss: 0.016114
 >> iter 79000, loss: 0.030633
 >> iter 80000, loss: 0.033038
   Number of active neurons: 1
 >> iter 81000, loss: 0.024323
 >> iter 82000, loss: 0.021250
 >> iter 83000, loss: 0.019122
 >> iter 84000, loss: 0.018028
 >> iter 85000, loss: 0.020015
 >> iter 86000, loss: 0.017004
 >> iter 87000, loss: 0.018087
 >> iter 88000, loss: 0.020131
 >> iter 89000, loss: 0.018105
 >> iter 90000, loss: 0.022654
   Number of active neurons: 1
 >> iter 91000, loss: 0.020419
 >> iter 92000, loss: 0.017001
 >> iter 93000, loss: 0.017001
 >> iter 94000, loss: 0.020551
 >> iter 95000, loss: 0.019027
 >> iter 96000, loss: 0.026810
 >> iter 97000, loss: 0.035266
 >> iter 98000, loss: 0.024690
 >> iter 99000, loss: 0.022642
 >> iter 100000, loss: 0.017943
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.177464
 >> iter 2000, loss: 4.155895
 >> iter 3000, loss: 1.562764
 >> iter 4000, loss: 0.600734
 >> iter 5000, loss: 0.240966
 >> iter 6000, loss: 0.103506
 >> iter 7000, loss: 0.053890
 >> iter 8000, loss: 0.034287
 >> iter 9000, loss: 0.035179
 >> iter 10000, loss: 0.027146
   Number of active neurons: 2
 >> iter 11000, loss: 0.027447
 >> iter 12000, loss: 0.022307
 >> iter 13000, loss: 0.020529
 >> iter 14000, loss: 0.020510
 >> iter 15000, loss: 0.020367
 >> iter 16000, loss: 0.021510
 >> iter 17000, loss: 0.023837
 >> iter 18000, loss: 0.025697
 >> iter 19000, loss: 0.024744
 >> iter 20000, loss: 0.019495
   Number of active neurons: 1
 >> iter 21000, loss: 0.029680
 >> iter 22000, loss: 0.021873
 >> iter 23000, loss: 0.019731
 >> iter 24000, loss: 0.046968
 >> iter 25000, loss: 0.028687
 >> iter 26000, loss: 0.021377
 >> iter 27000, loss: 0.021119
 >> iter 28000, loss: 0.020414
 >> iter 29000, loss: 0.018062
 >> iter 30000, loss: 0.021051
   Number of active neurons: 1
 >> iter 31000, loss: 0.027746
 >> iter 32000, loss: 0.019983
 >> iter 33000, loss: 0.017583
 >> iter 34000, loss: 0.032247
 >> iter 35000, loss: 0.027348
 >> iter 36000, loss: 0.024219
 >> iter 37000, loss: 0.028875
 >> iter 38000, loss: 0.021098
 >> iter 39000, loss: 0.019653
 >> iter 40000, loss: 0.029800
   Number of active neurons: 1
 >> iter 41000, loss: 0.022244
 >> iter 42000, loss: 0.021112
 >> iter 43000, loss: 0.017055
 >> iter 44000, loss: 0.020538
 >> iter 45000, loss: 0.017373
 >> iter 46000, loss: 0.018318
 >> iter 47000, loss: 0.026191
 >> iter 48000, loss: 0.020418
 >> iter 49000, loss: 0.018166
 >> iter 50000, loss: 0.028833
   Number of active neurons: 1
 >> iter 51000, loss: 0.026661
 >> iter 52000, loss: 0.024259
 >> iter 53000, loss: 0.023551
 >> iter 54000, loss: 0.025396
 >> iter 55000, loss: 0.021514
 >> iter 56000, loss: 0.017762
 >> iter 57000, loss: 0.019901
 >> iter 58000, loss: 0.018248
 >> iter 59000, loss: 0.022734
 >> iter 60000, loss: 0.018104
   Number of active neurons: 1
 >> iter 61000, loss: 0.018039
 >> iter 62000, loss: 0.036094
 >> iter 63000, loss: 0.027414
 >> iter 64000, loss: 0.021942
 >> iter 65000, loss: 0.018748
 >> iter 66000, loss: 0.019220
 >> iter 67000, loss: 0.017804
 >> iter 68000, loss: 0.026246
 >> iter 69000, loss: 0.019624
 >> iter 70000, loss: 0.018036
   Number of active neurons: 1
 >> iter 71000, loss: 0.017596
 >> iter 72000, loss: 0.017026
 >> iter 73000, loss: 0.016874
 >> iter 74000, loss: 0.023388
 >> iter 75000, loss: 0.018965
 >> iter 76000, loss: 0.021666
 >> iter 77000, loss: 0.024744
 >> iter 78000, loss: 0.021144
 >> iter 79000, loss: 0.021569
 >> iter 80000, loss: 0.017705
   Number of active neurons: 1
 >> iter 81000, loss: 0.016567
 >> iter 82000, loss: 0.018042
 >> iter 83000, loss: 0.018451
 >> iter 84000, loss: 0.019444
 >> iter 85000, loss: 0.019311
 >> iter 86000, loss: 0.022600
 >> iter 87000, loss: 0.046093
 >> iter 88000, loss: 0.038614
 >> iter 89000, loss: 0.038082
 >> iter 90000, loss: 0.025977
   Number of active neurons: 1
 >> iter 91000, loss: 0.022631
 >> iter 92000, loss: 0.019481
 >> iter 93000, loss: 0.022437
 >> iter 94000, loss: 0.048877
 >> iter 95000, loss: 0.030798
 >> iter 96000, loss: 0.024859
 >> iter 97000, loss: 0.033088
 >> iter 98000, loss: 0.024068
 >> iter 99000, loss: 0.020683
 >> iter 100000, loss: 0.025357
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.037222
 >> iter 2000, loss: 4.100239
 >> iter 3000, loss: 1.529207
 >> iter 4000, loss: 0.582889
 >> iter 5000, loss: 0.230017
 >> iter 6000, loss: 0.099936
 >> iter 7000, loss: 0.051244
 >> iter 8000, loss: 0.050802
 >> iter 9000, loss: 0.033850
 >> iter 10000, loss: 0.029404
   Number of active neurons: 2
 >> iter 11000, loss: 0.023641
 >> iter 12000, loss: 0.024114
 >> iter 13000, loss: 0.030492
 >> iter 14000, loss: 0.023970
 >> iter 15000, loss: 0.027668
 >> iter 16000, loss: 0.023716
 >> iter 17000, loss: 0.032092
 >> iter 18000, loss: 0.024278
 >> iter 19000, loss: 0.023611
 >> iter 20000, loss: 0.029686
   Number of active neurons: 2
 >> iter 21000, loss: 0.033937
 >> iter 22000, loss: 0.026837
 >> iter 23000, loss: 0.024726
 >> iter 24000, loss: 0.022356
 >> iter 25000, loss: 0.034320
 >> iter 26000, loss: 0.027777
 >> iter 27000, loss: 0.025609
 >> iter 28000, loss: 0.030445
 >> iter 29000, loss: 0.032466
 >> iter 30000, loss: 0.024678
   Number of active neurons: 2
 >> iter 31000, loss: 0.025165
 >> iter 32000, loss: 0.032317
 >> iter 33000, loss: 0.027982
 >> iter 34000, loss: 0.023650
 >> iter 35000, loss: 0.029013
 >> iter 36000, loss: 0.027911
 >> iter 37000, loss: 0.024274
 >> iter 38000, loss: 0.028799
 >> iter 39000, loss: 0.024594
 >> iter 40000, loss: 0.023388
   Number of active neurons: 2
 >> iter 41000, loss: 0.024755
 >> iter 42000, loss: 0.023341
 >> iter 43000, loss: 0.022991
 >> iter 44000, loss: 0.023963
 >> iter 45000, loss: 0.040765
 >> iter 46000, loss: 0.030842
 >> iter 47000, loss: 0.025829
 >> iter 48000, loss: 0.023218
 >> iter 49000, loss: 0.025973
 >> iter 50000, loss: 0.021823
   Number of active neurons: 2
 >> iter 51000, loss: 0.024848
 >> iter 52000, loss: 0.021773
 >> iter 53000, loss: 0.020830
 >> iter 54000, loss: 0.034338
 >> iter 55000, loss: 0.029711
 >> iter 56000, loss: 0.025519
 >> iter 57000, loss: 0.023104
 >> iter 58000, loss: 0.020912
 >> iter 59000, loss: 0.019557
 >> iter 60000, loss: 0.026157
   Number of active neurons: 1
 >> iter 61000, loss: 0.025665
 >> iter 62000, loss: 0.021808
 >> iter 63000, loss: 0.019482
 >> iter 64000, loss: 0.018399
 >> iter 65000, loss: 0.035182
 >> iter 66000, loss: 0.023755
 >> iter 67000, loss: 0.020611
 >> iter 68000, loss: 0.017695
 >> iter 69000, loss: 0.017892
 >> iter 70000, loss: 0.017060
   Number of active neurons: 1
 >> iter 71000, loss: 0.029078
 >> iter 72000, loss: 0.020713
 >> iter 73000, loss: 0.036385
 >> iter 74000, loss: 0.026136
 >> iter 75000, loss: 0.020541
 >> iter 76000, loss: 0.020556
 >> iter 77000, loss: 0.019253
 >> iter 78000, loss: 0.024041
 >> iter 79000, loss: 0.023379
 >> iter 80000, loss: 0.021493
   Number of active neurons: 1
 >> iter 81000, loss: 0.018075
 >> iter 82000, loss: 0.015986
 >> iter 83000, loss: 0.018514
 >> iter 84000, loss: 0.022494
 >> iter 85000, loss: 0.019270
 >> iter 86000, loss: 0.059838
 >> iter 87000, loss: 0.033394
 >> iter 88000, loss: 0.025394
 >> iter 89000, loss: 0.020252
 >> iter 90000, loss: 0.017589
   Number of active neurons: 1
 >> iter 91000, loss: 0.026096
 >> iter 92000, loss: 0.038404
 >> iter 93000, loss: 0.024412
 >> iter 94000, loss: 0.033997
 >> iter 95000, loss: 0.024357
 >> iter 96000, loss: 0.021125
 >> iter 97000, loss: 0.019458
 >> iter 98000, loss: 0.018652
 >> iter 99000, loss: 0.026533
 >> iter 100000, loss: 0.019760
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.023650
 >> iter 2000, loss: 4.089726
 >> iter 3000, loss: 1.525636
 >> iter 4000, loss: 0.588302
 >> iter 5000, loss: 0.234061
 >> iter 6000, loss: 0.101187
 >> iter 7000, loss: 0.051455
 >> iter 8000, loss: 0.030863
 >> iter 9000, loss: 0.025361
 >> iter 10000, loss: 0.023434
   Number of active neurons: 2
 >> iter 11000, loss: 0.023217
 >> iter 12000, loss: 0.030926
 >> iter 13000, loss: 0.028081
 >> iter 14000, loss: 0.022913
 >> iter 15000, loss: 0.021457
 >> iter 16000, loss: 0.020788
 >> iter 17000, loss: 0.021035
 >> iter 18000, loss: 0.020508
 >> iter 19000, loss: 0.038847
 >> iter 20000, loss: 0.026608
   Number of active neurons: 2
 >> iter 21000, loss: 0.022801
 >> iter 22000, loss: 0.023341
 >> iter 23000, loss: 0.024796
 >> iter 24000, loss: 0.021451
 >> iter 25000, loss: 0.020293
 >> iter 26000, loss: 0.021883
 >> iter 27000, loss: 0.021237
 >> iter 28000, loss: 0.022207
 >> iter 29000, loss: 0.020730
 >> iter 30000, loss: 0.024639
   Number of active neurons: 2
 >> iter 31000, loss: 0.032026
 >> iter 32000, loss: 0.022624
 >> iter 33000, loss: 0.020917
 >> iter 34000, loss: 0.028039
 >> iter 35000, loss: 0.022432
 >> iter 36000, loss: 0.024295
 >> iter 37000, loss: 0.021362
 >> iter 38000, loss: 0.020789
 >> iter 39000, loss: 0.020685
 >> iter 40000, loss: 0.019543
   Number of active neurons: 2
 >> iter 41000, loss: 0.020701
 >> iter 42000, loss: 0.019845
 >> iter 43000, loss: 0.023079
 >> iter 44000, loss: 0.020657
 >> iter 45000, loss: 0.022243
 >> iter 46000, loss: 0.023760
 >> iter 47000, loss: 0.024746
 >> iter 48000, loss: 0.023299
 >> iter 49000, loss: 0.028556
 >> iter 50000, loss: 0.024462
   Number of active neurons: 2
 >> iter 51000, loss: 0.022306
 >> iter 52000, loss: 0.020484
 >> iter 53000, loss: 0.019708
 >> iter 54000, loss: 0.020862
 >> iter 55000, loss: 0.020268
 >> iter 56000, loss: 0.025651
 >> iter 57000, loss: 0.021991
 >> iter 58000, loss: 0.061779
 >> iter 59000, loss: 0.043274
 >> iter 60000, loss: 0.034206
   Number of active neurons: 2
 >> iter 61000, loss: 0.028514
 >> iter 62000, loss: 0.026000
 >> iter 63000, loss: 0.022592
 >> iter 64000, loss: 0.027888
 >> iter 65000, loss: 0.032542
 >> iter 66000, loss: 0.028435
 >> iter 67000, loss: 0.021688
 >> iter 68000, loss: 0.020012
 >> iter 69000, loss: 0.023182
 >> iter 70000, loss: 0.021733
   Number of active neurons: 2
 >> iter 71000, loss: 0.021422
 >> iter 72000, loss: 0.023684
 >> iter 73000, loss: 0.022548
 >> iter 74000, loss: 0.030182
 >> iter 75000, loss: 0.029888
 >> iter 76000, loss: 0.022998
 >> iter 77000, loss: 0.025759
 >> iter 78000, loss: 0.039926
 >> iter 79000, loss: 0.027775
 >> iter 80000, loss: 0.056292
   Number of active neurons: 2
 >> iter 81000, loss: 0.039972
 >> iter 82000, loss: 0.043929
 >> iter 83000, loss: 0.038849
 >> iter 84000, loss: 0.029343
 >> iter 85000, loss: 0.043450
 >> iter 86000, loss: 0.034683
 >> iter 87000, loss: 0.034990
 >> iter 88000, loss: 0.027891
 >> iter 89000, loss: 0.055648
 >> iter 90000, loss: 0.031422
   Number of active neurons: 1
 >> iter 91000, loss: 0.023149
 >> iter 92000, loss: 0.020633
 >> iter 93000, loss: 0.021274
 >> iter 94000, loss: 0.018366
 >> iter 95000, loss: 0.017059
 >> iter 96000, loss: 0.027229
 >> iter 97000, loss: 0.032698
 >> iter 98000, loss: 0.041828
 >> iter 99000, loss: 0.028422
 >> iter 100000, loss: 0.020901
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

