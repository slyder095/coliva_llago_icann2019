 > Problema: tomita4nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.907949
 >> iter 2000, loss: 8.794564
 >> iter 3000, loss: 4.988514
 >> iter 4000, loss: 2.528210
 >> iter 5000, loss: 1.032638
 >> iter 6000, loss: 0.397351
 >> iter 7000, loss: 0.162407
 >> iter 8000, loss: 0.068305
 >> iter 9000, loss: 0.045074
 >> iter 10000, loss: 0.022580
   Number of active neurons: 2
 >> iter 11000, loss: 0.020191
 >> iter 12000, loss: 0.012004
 >> iter 13000, loss: 0.017224
 >> iter 14000, loss: 0.010120
 >> iter 15000, loss: 0.014008
 >> iter 16000, loss: 0.008385
 >> iter 17000, loss: 0.020335
 >> iter 18000, loss: 0.010439
 >> iter 19000, loss: 0.021796
 >> iter 20000, loss: 0.010781
   Number of active neurons: 2
 >> iter 21000, loss: 0.024470
 >> iter 22000, loss: 0.011643
 >> iter 23000, loss: 0.029182
 >> iter 24000, loss: 0.013327
 >> iter 25000, loss: 0.031163
 >> iter 26000, loss: 0.014017
 >> iter 27000, loss: 0.031859
 >> iter 28000, loss: 0.014231
 >> iter 29000, loss: 0.032345
 >> iter 30000, loss: 0.014375
   Number of active neurons: 2
 >> iter 31000, loss: 0.032380
 >> iter 32000, loss: 0.014349
 >> iter 33000, loss: 0.032380
 >> iter 34000, loss: 0.014321
 >> iter 35000, loss: 0.032405
 >> iter 36000, loss: 0.014351
 >> iter 37000, loss: 0.032620
 >> iter 38000, loss: 0.014441
 >> iter 39000, loss: 0.031499
 >> iter 40000, loss: 0.013882
   Number of active neurons: 2
 >> iter 41000, loss: 0.031276
 >> iter 42000, loss: 0.013793
 >> iter 43000, loss: 0.031290
 >> iter 44000, loss: 0.013827
 >> iter 45000, loss: 0.037173
 >> iter 46000, loss: 0.015834
 >> iter 47000, loss: 0.021019
 >> iter 48000, loss: 0.009845
 >> iter 49000, loss: 0.026139
 >> iter 50000, loss: 0.011754
   Number of active neurons: 2
 >> iter 51000, loss: 0.028109
 >> iter 52000, loss: 0.012504
 >> iter 53000, loss: 0.029006
 >> iter 54000, loss: 0.012844
 >> iter 55000, loss: 0.029457
 >> iter 56000, loss: 0.013011
 >> iter 57000, loss: 0.036768
 >> iter 58000, loss: 0.015580
 >> iter 59000, loss: 0.027856
 >> iter 60000, loss: 0.012336
   Number of active neurons: 2
 >> iter 61000, loss: 0.027341
 >> iter 62000, loss: 0.012174
 >> iter 63000, loss: 0.027662
 >> iter 64000, loss: 0.012306
 >> iter 65000, loss: 0.028146
 >> iter 66000, loss: 0.012482
 >> iter 67000, loss: 0.038042
 >> iter 68000, loss: 0.016112
 >> iter 69000, loss: 0.007888
 >> iter 70000, loss: 0.004653
   Number of active neurons: 2
 >> iter 71000, loss: 0.023427
 >> iter 72000, loss: 0.010445
 >> iter 73000, loss: 0.023161
 >> iter 74000, loss: 0.010388
 >> iter 75000, loss: 0.024423
 >> iter 76000, loss: 0.010891
 >> iter 77000, loss: 0.025564
 >> iter 78000, loss: 0.011348
 >> iter 79000, loss: 0.026372
 >> iter 80000, loss: 0.011674
   Number of active neurons: 2
 >> iter 81000, loss: 0.027128
 >> iter 82000, loss: 0.011964
 >> iter 83000, loss: 0.045865
 >> iter 84000, loss: 0.019265
 >> iter 85000, loss: 0.009183
 >> iter 86000, loss: 0.005209
 >> iter 87000, loss: 0.003625
 >> iter 88000, loss: 0.002862
 >> iter 89000, loss: 0.022076
 >> iter 90000, loss: 0.009737
   Number of active neurons: 2
 >> iter 91000, loss: 0.024143
 >> iter 92000, loss: 0.010574
 >> iter 93000, loss: 0.022937
 >> iter 94000, loss: 0.010179
 >> iter 95000, loss: 0.024832
 >> iter 96000, loss: 0.010930
 >> iter 97000, loss: 0.025323
 >> iter 98000, loss: 0.011148
 >> iter 99000, loss: 0.026166
 >> iter 100000, loss: 0.011481
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0269997300027
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.692538
 >> iter 2000, loss: 6.922864
 >> iter 3000, loss: 2.696053
 >> iter 4000, loss: 1.078167
 >> iter 5000, loss: 0.501028
 >> iter 6000, loss: 0.236823
 >> iter 7000, loss: 0.121531
 >> iter 8000, loss: 0.054380
 >> iter 9000, loss: 0.041605
 >> iter 10000, loss: 0.021785
   Number of active neurons: 2
 >> iter 11000, loss: 0.028803
 >> iter 12000, loss: 0.015782
 >> iter 13000, loss: 0.028987
 >> iter 14000, loss: 0.015113
 >> iter 15000, loss: 0.027990
 >> iter 16000, loss: 0.014230
 >> iter 17000, loss: 0.026981
 >> iter 18000, loss: 0.013260
 >> iter 19000, loss: 0.011542
 >> iter 20000, loss: 0.007026
   Number of active neurons: 2
 >> iter 21000, loss: 0.009589
 >> iter 22000, loss: 0.005946
 >> iter 23000, loss: 0.020731
 >> iter 24000, loss: 0.009885
 >> iter 25000, loss: 0.022258
 >> iter 26000, loss: 0.010330
 >> iter 27000, loss: 0.068351
 >> iter 28000, loss: 0.027447
 >> iter 29000, loss: 0.075706
 >> iter 30000, loss: 0.030324
   Number of active neurons: 2
 >> iter 31000, loss: 0.030887
 >> iter 32000, loss: 0.013603
 >> iter 33000, loss: 0.022101
 >> iter 34000, loss: 0.010248
 >> iter 35000, loss: 0.021395
 >> iter 36000, loss: 0.009895
 >> iter 37000, loss: 0.021696
 >> iter 38000, loss: 0.009933
 >> iter 39000, loss: 0.055252
 >> iter 40000, loss: 0.022451
   Number of active neurons: 2
 >> iter 41000, loss: 0.028475
 >> iter 42000, loss: 0.012588
 >> iter 43000, loss: 0.025189
 >> iter 44000, loss: 0.011230
 >> iter 45000, loss: 0.005969
 >> iter 46000, loss: 0.003866
 >> iter 47000, loss: 0.003012
 >> iter 48000, loss: 0.002565
 >> iter 49000, loss: 0.002350
 >> iter 50000, loss: 0.002160
   Number of active neurons: 2
 >> iter 51000, loss: 0.028991
 >> iter 52000, loss: 0.011942
 >> iter 53000, loss: 0.015615
 >> iter 54000, loss: 0.007019
 >> iter 55000, loss: 0.003815
 >> iter 56000, loss: 0.002546
 >> iter 57000, loss: 0.002051
 >> iter 58000, loss: 0.001793
 >> iter 59000, loss: 0.001679
 >> iter 60000, loss: 0.001571
   Number of active neurons: 2
 >> iter 61000, loss: 0.001518
 >> iter 62000, loss: 0.001441
 >> iter 63000, loss: 0.001404
 >> iter 64000, loss: 0.001339
 >> iter 65000, loss: 0.001309
 >> iter 66000, loss: 0.001253
 >> iter 67000, loss: 0.001233
 >> iter 68000, loss: 0.001185
 >> iter 69000, loss: 0.001176
 >> iter 70000, loss: 0.001122
   Number of active neurons: 2
 >> iter 71000, loss: 0.001106
 >> iter 72000, loss: 0.001060
 >> iter 73000, loss: 0.001044
 >> iter 74000, loss: 0.001005
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.637847
 >> iter 2000, loss: 6.673082
 >> iter 3000, loss: 2.507151
 >> iter 4000, loss: 0.946456
 >> iter 5000, loss: 0.365382
 >> iter 6000, loss: 0.147402
 >> iter 7000, loss: 0.065003
 >> iter 8000, loss: 0.032780
 >> iter 9000, loss: 0.019871
 >> iter 10000, loss: 0.014025
   Number of active neurons: 2
 >> iter 11000, loss: 0.011272
 >> iter 12000, loss: 0.009543
 >> iter 13000, loss: 0.008523
 >> iter 14000, loss: 0.007641
 >> iter 15000, loss: 0.007056
 >> iter 16000, loss: 0.006459
 >> iter 17000, loss: 0.006053
 >> iter 18000, loss: 0.005608
 >> iter 19000, loss: 0.005305
 >> iter 20000, loss: 0.004953
   Number of active neurons: 2
 >> iter 21000, loss: 0.004717
 >> iter 22000, loss: 0.004435
 >> iter 23000, loss: 0.004247
 >> iter 24000, loss: 0.004014
 >> iter 25000, loss: 0.003860
 >> iter 26000, loss: 0.003665
 >> iter 27000, loss: 0.003540
 >> iter 28000, loss: 0.003368
 >> iter 29000, loss: 0.003265
 >> iter 30000, loss: 0.003119
   Number of active neurons: 2
 >> iter 31000, loss: 0.003031
 >> iter 32000, loss: 0.002900
 >> iter 33000, loss: 0.002826
 >> iter 34000, loss: 0.002710
 >> iter 35000, loss: 0.002649
 >> iter 36000, loss: 0.002544
 >> iter 37000, loss: 0.002493
 >> iter 38000, loss: 0.002396
 >> iter 39000, loss: 0.002353
 >> iter 40000, loss: 0.002265
   Number of active neurons: 2
 >> iter 41000, loss: 0.002226
 >> iter 42000, loss: 0.002148
 >> iter 43000, loss: 0.002112
 >> iter 44000, loss: 0.002040
 >> iter 45000, loss: 0.002010
 >> iter 46000, loss: 0.001944
 >> iter 47000, loss: 0.001916
 >> iter 48000, loss: 0.001856
 >> iter 49000, loss: 0.001831
 >> iter 50000, loss: 0.001774
   Number of active neurons: 2
 >> iter 51000, loss: 0.001752
 >> iter 52000, loss: 0.001700
 >> iter 53000, loss: 0.001681
 >> iter 54000, loss: 0.001632
 >> iter 55000, loss: 0.001616
 >> iter 56000, loss: 0.001568
 >> iter 57000, loss: 0.001555
 >> iter 58000, loss: 0.001509
 >> iter 59000, loss: 0.001498
 >> iter 60000, loss: 0.001455
   Number of active neurons: 2
 >> iter 61000, loss: 0.001444
 >> iter 62000, loss: 0.001404
 >> iter 63000, loss: 0.001396
 >> iter 64000, loss: 0.001358
 >> iter 65000, loss: 0.001351
 >> iter 66000, loss: 0.001314
 >> iter 67000, loss: 0.001307
 >> iter 68000, loss: 0.001272
 >> iter 69000, loss: 0.001267
 >> iter 70000, loss: 0.001234
   Number of active neurons: 2
 >> iter 71000, loss: 0.001228
 >> iter 72000, loss: 0.001196
 >> iter 73000, loss: 0.001191
 >> iter 74000, loss: 0.001161
 >> iter 75000, loss: 0.001156
 >> iter 76000, loss: 0.001128
 >> iter 77000, loss: 0.001124
 >> iter 78000, loss: 0.001096
 >> iter 79000, loss: 0.001093
 >> iter 80000, loss: 0.001067
   Number of active neurons: 2
 >> iter 81000, loss: 0.001064
 >> iter 82000, loss: 0.001039
 >> iter 83000, loss: 0.001036
 >> iter 84000, loss: 0.001013
 >> iter 85000, loss: 0.001011
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.654077
 >> iter 2000, loss: 8.496993
 >> iter 3000, loss: 4.010332
 >> iter 4000, loss: 1.918295
 >> iter 5000, loss: 0.820236
 >> iter 6000, loss: 0.322844
 >> iter 7000, loss: 0.150083
 >> iter 8000, loss: 0.063885
 >> iter 9000, loss: 0.051468
 >> iter 10000, loss: 0.025086
   Number of active neurons: 2
 >> iter 11000, loss: 0.036028
 >> iter 12000, loss: 0.018145
 >> iter 13000, loss: 0.032774
 >> iter 14000, loss: 0.016231
 >> iter 15000, loss: 0.031632
 >> iter 16000, loss: 0.015349
 >> iter 17000, loss: 0.031031
 >> iter 18000, loss: 0.014812
 >> iter 19000, loss: 0.030660
 >> iter 20000, loss: 0.014443
   Number of active neurons: 2
 >> iter 21000, loss: 0.030402
 >> iter 22000, loss: 0.014177
 >> iter 23000, loss: 0.030220
 >> iter 24000, loss: 0.013974
 >> iter 25000, loss: 0.030089
 >> iter 26000, loss: 0.013817
 >> iter 27000, loss: 0.030005
 >> iter 28000, loss: 0.013693
 >> iter 29000, loss: 0.029968
 >> iter 30000, loss: 0.013604
   Number of active neurons: 2
 >> iter 31000, loss: 0.030004
 >> iter 32000, loss: 0.013546
 >> iter 33000, loss: 0.030127
 >> iter 34000, loss: 0.013529
 >> iter 35000, loss: 0.030373
 >> iter 36000, loss: 0.013599
 >> iter 37000, loss: 0.065746
 >> iter 38000, loss: 0.026870
 >> iter 39000, loss: 0.012666
 >> iter 40000, loss: 0.006902
   Number of active neurons: 2
 >> iter 41000, loss: 0.015551
 >> iter 42000, loss: 0.007871
 >> iter 43000, loss: 0.015022
 >> iter 44000, loss: 0.007589
 >> iter 45000, loss: 0.021883
 >> iter 46000, loss: 0.010110
 >> iter 47000, loss: 0.027283
 >> iter 48000, loss: 0.012126
 >> iter 49000, loss: 0.028076
 >> iter 50000, loss: 0.012435
   Number of active neurons: 2
 >> iter 51000, loss: 0.028361
 >> iter 52000, loss: 0.012545
 >> iter 53000, loss: 0.028963
 >> iter 54000, loss: 0.012833
 >> iter 55000, loss: 0.039875
 >> iter 56000, loss: 0.016840
 >> iter 57000, loss: 0.008183
 >> iter 58000, loss: 0.004781
 >> iter 59000, loss: 0.021019
 >> iter 60000, loss: 0.009554
   Number of active neurons: 2
 >> iter 61000, loss: 0.022995
 >> iter 62000, loss: 0.010319
 >> iter 63000, loss: 0.025296
 >> iter 64000, loss: 0.011212
 >> iter 65000, loss: 0.026575
 >> iter 66000, loss: 0.011725
 >> iter 67000, loss: 0.026927
 >> iter 68000, loss: 0.011880
 >> iter 69000, loss: 0.027628
 >> iter 70000, loss: 0.012213
   Number of active neurons: 2
 >> iter 71000, loss: 0.062587
 >> iter 72000, loss: 0.025555
 >> iter 73000, loss: 0.011608
 >> iter 74000, loss: 0.006185
 >> iter 75000, loss: 0.006236
 >> iter 76000, loss: 0.004010
 >> iter 77000, loss: 0.022516
 >> iter 78000, loss: 0.010056
 >> iter 79000, loss: 0.025024
 >> iter 80000, loss: 0.011026
   Number of active neurons: 2
 >> iter 81000, loss: 0.025610
 >> iter 82000, loss: 0.011276
 >> iter 83000, loss: 0.026122
 >> iter 84000, loss: 0.011486
 >> iter 85000, loss: 0.037763
 >> iter 86000, loss: 0.015780
 >> iter 87000, loss: 0.007537
 >> iter 88000, loss: 0.004324
 >> iter 89000, loss: 0.022008
 >> iter 90000, loss: 0.009730
   Number of active neurons: 2
 >> iter 91000, loss: 0.015870
 >> iter 92000, loss: 0.007476
 >> iter 93000, loss: 0.022614
 >> iter 94000, loss: 0.010015
 >> iter 95000, loss: 0.023143
 >> iter 96000, loss: 0.010247
 >> iter 97000, loss: 0.024430
 >> iter 98000, loss: 0.010763
 >> iter 99000, loss: 0.024798
 >> iter 100000, loss: 0.010928
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0229997700023
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.018535
 >> iter 2000, loss: 6.210385
 >> iter 3000, loss: 2.323357
 >> iter 4000, loss: 0.877252
 >> iter 5000, loss: 0.339160
 >> iter 6000, loss: 0.137302
 >> iter 7000, loss: 0.060985
 >> iter 8000, loss: 0.031071
 >> iter 9000, loss: 0.019073
 >> iter 10000, loss: 0.013583
   Number of active neurons: 2
 >> iter 11000, loss: 0.010998
 >> iter 12000, loss: 0.009335
 >> iter 13000, loss: 0.008371
 >> iter 14000, loss: 0.007504
 >> iter 15000, loss: 0.006946
 >> iter 16000, loss: 0.006353
 >> iter 17000, loss: 0.005977
 >> iter 18000, loss: 0.005530
 >> iter 19000, loss: 0.005236
 >> iter 20000, loss: 0.004881
   Number of active neurons: 2
 >> iter 21000, loss: 0.004736
 >> iter 22000, loss: 0.004455
 >> iter 23000, loss: 0.004253
 >> iter 24000, loss: 0.004000
 >> iter 25000, loss: 0.003838
 >> iter 26000, loss: 0.003632
 >> iter 27000, loss: 0.003506
 >> iter 28000, loss: 0.003328
 >> iter 29000, loss: 0.003227
 >> iter 30000, loss: 0.003078
   Number of active neurons: 2
 >> iter 31000, loss: 0.003007
 >> iter 32000, loss: 0.002877
 >> iter 33000, loss: 0.002803
 >> iter 34000, loss: 0.002682
 >> iter 35000, loss: 0.002622
 >> iter 36000, loss: 0.002515
 >> iter 37000, loss: 0.002521
 >> iter 38000, loss: 0.002433
 >> iter 39000, loss: 0.002386
 >> iter 40000, loss: 0.002284
   Number of active neurons: 2
 >> iter 41000, loss: 0.002238
 >> iter 42000, loss: 0.002150
 >> iter 43000, loss: 0.002111
 >> iter 44000, loss: 0.002032
 >> iter 45000, loss: 0.002000
 >> iter 46000, loss: 0.001930
 >> iter 47000, loss: 0.001902
 >> iter 48000, loss: 0.001838
 >> iter 49000, loss: 0.001814
 >> iter 50000, loss: 0.001755
   Number of active neurons: 2
 >> iter 51000, loss: 0.001743
 >> iter 52000, loss: 0.001690
 >> iter 53000, loss: 0.001672
 >> iter 54000, loss: 0.001619
 >> iter 55000, loss: 0.001603
 >> iter 56000, loss: 0.001553
 >> iter 57000, loss: 0.001543
 >> iter 58000, loss: 0.001496
 >> iter 59000, loss: 0.001486
 >> iter 60000, loss: 0.001440
   Number of active neurons: 2
 >> iter 61000, loss: 0.001457
 >> iter 62000, loss: 0.001423
 >> iter 63000, loss: 0.001416
 >> iter 64000, loss: 0.001371
 >> iter 65000, loss: 0.001362
 >> iter 66000, loss: 0.001319
 >> iter 67000, loss: 0.001310
 >> iter 68000, loss: 0.001272
 >> iter 69000, loss: 0.001265
 >> iter 70000, loss: 0.001229
   Number of active neurons: 2
 >> iter 71000, loss: 0.001223
 >> iter 72000, loss: 0.001188
 >> iter 73000, loss: 0.001183
 >> iter 74000, loss: 0.001151
 >> iter 75000, loss: 0.001148
 >> iter 76000, loss: 0.001118
 >> iter 77000, loss: 0.001117
 >> iter 78000, loss: 0.001087
 >> iter 79000, loss: 0.001085
 >> iter 80000, loss: 0.001057
   Number of active neurons: 2
 >> iter 81000, loss: 0.001066
 >> iter 82000, loss: 0.001041
 >> iter 83000, loss: 0.001039
 >> iter 84000, loss: 0.001013
 >> iter 85000, loss: 0.001010
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.080263
 >> iter 2000, loss: 6.459614
 >> iter 3000, loss: 2.431890
 >> iter 4000, loss: 0.918344
 >> iter 5000, loss: 0.390342
 >> iter 6000, loss: 0.156641
 >> iter 7000, loss: 0.103751
 >> iter 8000, loss: 0.047185
 >> iter 9000, loss: 0.061589
 >> iter 10000, loss: 0.029573
   Number of active neurons: 2
 >> iter 11000, loss: 0.056615
 >> iter 12000, loss: 0.026480
 >> iter 13000, loss: 0.038053
 >> iter 14000, loss: 0.018739
 >> iter 15000, loss: 0.050332
 >> iter 16000, loss: 0.022634
 >> iter 17000, loss: 0.053234
 >> iter 18000, loss: 0.023264
 >> iter 19000, loss: 0.053279
 >> iter 20000, loss: 0.022945
   Number of active neurons: 2
 >> iter 21000, loss: 0.050602
 >> iter 22000, loss: 0.021681
 >> iter 23000, loss: 0.036415
 >> iter 24000, loss: 0.016219
 >> iter 25000, loss: 0.008586
 >> iter 26000, loss: 0.005541
 >> iter 27000, loss: 0.030953
 >> iter 28000, loss: 0.013646
 >> iter 29000, loss: 0.007123
 >> iter 30000, loss: 0.004562
   Number of active neurons: 2
 >> iter 31000, loss: 0.040636
 >> iter 32000, loss: 0.016882
 >> iter 33000, loss: 0.008024
 >> iter 34000, loss: 0.004638
 >> iter 35000, loss: 0.021052
 >> iter 36000, loss: 0.009399
 >> iter 37000, loss: 0.005030
 >> iter 38000, loss: 0.003317
 >> iter 39000, loss: 0.002635
 >> iter 40000, loss: 0.002302
   Number of active neurons: 2
 >> iter 41000, loss: 0.002216
 >> iter 42000, loss: 0.002095
 >> iter 43000, loss: 0.002002
 >> iter 44000, loss: 0.001895
 >> iter 45000, loss: 0.001824
 >> iter 46000, loss: 0.001741
 >> iter 47000, loss: 0.001686
 >> iter 48000, loss: 0.001618
 >> iter 49000, loss: 0.001574
 >> iter 50000, loss: 0.001515
   Number of active neurons: 2
 >> iter 51000, loss: 0.001478
 >> iter 52000, loss: 0.001427
 >> iter 53000, loss: 0.001421
 >> iter 54000, loss: 0.001382
 >> iter 55000, loss: 0.001355
 >> iter 56000, loss: 0.001306
 >> iter 57000, loss: 0.001279
 >> iter 58000, loss: 0.001235
 >> iter 59000, loss: 0.001212
 >> iter 60000, loss: 0.001173
   Number of active neurons: 2
 >> iter 61000, loss: 0.001153
 >> iter 62000, loss: 0.001117
 >> iter 63000, loss: 0.001101
 >> iter 64000, loss: 0.001068
 >> iter 65000, loss: 0.001054
 >> iter 66000, loss: 0.001023
 >> iter 67000, loss: 0.001010
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.051116
 >> iter 2000, loss: 6.297543
 >> iter 3000, loss: 2.357971
 >> iter 4000, loss: 0.890860
 >> iter 5000, loss: 0.344650
 >> iter 6000, loss: 0.139640
 >> iter 7000, loss: 0.062075
 >> iter 8000, loss: 0.031652
 >> iter 9000, loss: 0.019427
 >> iter 10000, loss: 0.013833
   Number of active neurons: 2
 >> iter 11000, loss: 0.011184
 >> iter 12000, loss: 0.009489
 >> iter 13000, loss: 0.008491
 >> iter 14000, loss: 0.007611
 >> iter 15000, loss: 0.007035
 >> iter 16000, loss: 0.006436
 >> iter 17000, loss: 0.006037
 >> iter 18000, loss: 0.005588
 >> iter 19000, loss: 0.005293
 >> iter 20000, loss: 0.004937
   Number of active neurons: 2
 >> iter 21000, loss: 0.004708
 >> iter 22000, loss: 0.004421
 >> iter 23000, loss: 0.004240
 >> iter 24000, loss: 0.004003
 >> iter 25000, loss: 0.003855
 >> iter 26000, loss: 0.003655
 >> iter 27000, loss: 0.003538
 >> iter 28000, loss: 0.003362
 >> iter 29000, loss: 0.003261
 >> iter 30000, loss: 0.003112
   Number of active neurons: 2
 >> iter 31000, loss: 0.003043
 >> iter 32000, loss: 0.002912
 >> iter 33000, loss: 0.002836
 >> iter 34000, loss: 0.002713
 >> iter 35000, loss: 0.002651
 >> iter 36000, loss: 0.002542
 >> iter 37000, loss: 0.002493
 >> iter 38000, loss: 0.002393
 >> iter 39000, loss: 0.002362
 >> iter 40000, loss: 0.002272
   Number of active neurons: 2
 >> iter 41000, loss: 0.002232
 >> iter 42000, loss: 0.002150
 >> iter 43000, loss: 0.002114
 >> iter 44000, loss: 0.002039
 >> iter 45000, loss: 0.002014
 >> iter 46000, loss: 0.001945
 >> iter 47000, loss: 0.001919
 >> iter 48000, loss: 0.001855
 >> iter 49000, loss: 0.001839
 >> iter 50000, loss: 0.001781
   Number of active neurons: 2
 >> iter 51000, loss: 0.001759
 >> iter 52000, loss: 0.001703
 >> iter 53000, loss: 0.001684
 >> iter 54000, loss: 0.001632
 >> iter 55000, loss: 0.001622
 >> iter 56000, loss: 0.001572
 >> iter 57000, loss: 0.001559
 >> iter 58000, loss: 0.001511
 >> iter 59000, loss: 0.001501
 >> iter 60000, loss: 0.001455
   Number of active neurons: 2
 >> iter 61000, loss: 0.001453
 >> iter 62000, loss: 0.001413
 >> iter 63000, loss: 0.001405
 >> iter 64000, loss: 0.001363
 >> iter 65000, loss: 0.001356
 >> iter 66000, loss: 0.001316
 >> iter 67000, loss: 0.001310
 >> iter 68000, loss: 0.001274
 >> iter 69000, loss: 0.001277
 >> iter 70000, loss: 0.001243
   Number of active neurons: 2
 >> iter 71000, loss: 0.001238
 >> iter 72000, loss: 0.001203
 >> iter 73000, loss: 0.001197
 >> iter 74000, loss: 0.001165
 >> iter 75000, loss: 0.001160
 >> iter 76000, loss: 0.001130
 >> iter 77000, loss: 0.001128
 >> iter 78000, loss: 0.001099
 >> iter 79000, loss: 0.001097
 >> iter 80000, loss: 0.001068
   Number of active neurons: 2
 >> iter 81000, loss: 0.001069
 >> iter 82000, loss: 0.001042
 >> iter 83000, loss: 0.001040
 >> iter 84000, loss: 0.001015
 >> iter 85000, loss: 0.001014
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.773822
 >> iter 2000, loss: 9.265198
 >> iter 3000, loss: 5.188004
 >> iter 4000, loss: 2.605552
 >> iter 5000, loss: 1.128916
 >> iter 6000, loss: 0.440879
 >> iter 7000, loss: 0.197946
 >> iter 8000, loss: 0.083525
 >> iter 9000, loss: 0.040974
 >> iter 10000, loss: 0.021653
   Number of active neurons: 2
 >> iter 11000, loss: 0.030566
 >> iter 12000, loss: 0.016339
 >> iter 13000, loss: 0.030514
 >> iter 14000, loss: 0.015550
 >> iter 15000, loss: 0.031057
 >> iter 16000, loss: 0.015272
 >> iter 17000, loss: 0.032231
 >> iter 18000, loss: 0.015385
 >> iter 19000, loss: 0.031328
 >> iter 20000, loss: 0.014811
   Number of active neurons: 2
 >> iter 21000, loss: 0.032538
 >> iter 22000, loss: 0.015082
 >> iter 23000, loss: 0.032630
 >> iter 24000, loss: 0.014980
 >> iter 25000, loss: 0.032785
 >> iter 26000, loss: 0.014926
 >> iter 27000, loss: 0.033094
 >> iter 28000, loss: 0.014944
 >> iter 29000, loss: 0.033248
 >> iter 30000, loss: 0.014928
   Number of active neurons: 2
 >> iter 31000, loss: 0.033155
 >> iter 32000, loss: 0.014828
 >> iter 33000, loss: 0.033038
 >> iter 34000, loss: 0.014742
 >> iter 35000, loss: 0.032945
 >> iter 36000, loss: 0.014697
 >> iter 37000, loss: 0.032926
 >> iter 38000, loss: 0.014678
 >> iter 39000, loss: 0.032353
 >> iter 40000, loss: 0.014344
   Number of active neurons: 2
 >> iter 41000, loss: 0.032183
 >> iter 42000, loss: 0.014301
 >> iter 43000, loss: 0.032229
 >> iter 44000, loss: 0.014333
 >> iter 45000, loss: 0.031446
 >> iter 46000, loss: 0.013915
 >> iter 47000, loss: 0.031346
 >> iter 48000, loss: 0.013917
 >> iter 49000, loss: 0.031594
 >> iter 50000, loss: 0.014074
   Number of active neurons: 2
 >> iter 51000, loss: 0.030454
 >> iter 52000, loss: 0.013496
 >> iter 53000, loss: 0.030460
 >> iter 54000, loss: 0.013529
 >> iter 55000, loss: 0.031002
 >> iter 56000, loss: 0.013912
 >> iter 57000, loss: 0.026757
 >> iter 58000, loss: 0.012093
 >> iter 59000, loss: 0.029282
 >> iter 60000, loss: 0.013028
   Number of active neurons: 2
 >> iter 61000, loss: 0.030472
 >> iter 62000, loss: 0.013930
 >> iter 63000, loss: 0.010336
 >> iter 64000, loss: 0.005815
 >> iter 65000, loss: 0.027072
 >> iter 66000, loss: 0.012044
 >> iter 67000, loss: 0.047359
 >> iter 68000, loss: 0.019652
 >> iter 69000, loss: 0.009236
 >> iter 70000, loss: 0.005168
   Number of active neurons: 2
 >> iter 71000, loss: 0.003570
 >> iter 72000, loss: 0.002820
 >> iter 73000, loss: 0.022038
 >> iter 74000, loss: 0.009710
 >> iter 75000, loss: 0.009342
 >> iter 76000, loss: 0.004955
 >> iter 77000, loss: 0.017287
 >> iter 78000, loss: 0.007922
 >> iter 79000, loss: 0.026000
 >> iter 80000, loss: 0.011220
   Number of active neurons: 2
 >> iter 81000, loss: 0.027695
 >> iter 82000, loss: 0.011916
 >> iter 83000, loss: 0.028455
 >> iter 84000, loss: 0.012258
 >> iter 85000, loss: 0.046956
 >> iter 86000, loss: 0.019281
 >> iter 87000, loss: 0.008895
 >> iter 88000, loss: 0.004867
 >> iter 89000, loss: 0.003294
 >> iter 90000, loss: 0.002573
   Number of active neurons: 2
 >> iter 91000, loss: 0.021872
 >> iter 92000, loss: 0.009515
 >> iter 93000, loss: 0.166120
 >> iter 94000, loss: 0.063498
 >> iter 95000, loss: 0.025430
 >> iter 96000, loss: 0.011151
 >> iter 97000, loss: 0.007175
 >> iter 98000, loss: 0.004253
 >> iter 99000, loss: 0.023271
 >> iter 100000, loss: 0.010245
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0239997600024
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.847350
 >> iter 2000, loss: 6.278736
 >> iter 3000, loss: 2.344015
 >> iter 4000, loss: 0.887095
 >> iter 5000, loss: 0.339847
 >> iter 6000, loss: 0.136094
 >> iter 7000, loss: 0.058547
 >> iter 8000, loss: 0.028593
 >> iter 9000, loss: 0.016706
 >> iter 10000, loss: 0.011512
   Number of active neurons: 2
 >> iter 11000, loss: 0.009099
 >> iter 12000, loss: 0.007669
 >> iter 13000, loss: 0.006825
 >> iter 14000, loss: 0.006127
 >> iter 15000, loss: 0.005656
 >> iter 16000, loss: 0.005187
 >> iter 17000, loss: 0.004863
 >> iter 18000, loss: 0.004513
 >> iter 19000, loss: 0.004273
 >> iter 20000, loss: 0.003994
   Number of active neurons: 2
 >> iter 21000, loss: 0.003809
 >> iter 22000, loss: 0.003584
 >> iter 23000, loss: 0.003436
 >> iter 24000, loss: 0.003250
 >> iter 25000, loss: 0.003131
 >> iter 26000, loss: 0.002973
 >> iter 27000, loss: 0.002878
 >> iter 28000, loss: 0.002737
 >> iter 29000, loss: 0.002659
 >> iter 30000, loss: 0.002539
   Number of active neurons: 2
 >> iter 31000, loss: 0.002472
 >> iter 32000, loss: 0.002365
 >> iter 33000, loss: 0.002309
 >> iter 34000, loss: 0.002213
 >> iter 35000, loss: 0.002168
 >> iter 36000, loss: 0.002081
 >> iter 37000, loss: 0.002043
 >> iter 38000, loss: 0.001965
 >> iter 39000, loss: 0.001932
 >> iter 40000, loss: 0.001860
   Number of active neurons: 2
 >> iter 41000, loss: 0.001830
 >> iter 42000, loss: 0.001766
 >> iter 43000, loss: 0.001739
 >> iter 44000, loss: 0.001680
 >> iter 45000, loss: 0.001657
 >> iter 46000, loss: 0.001602
 >> iter 47000, loss: 0.001582
 >> iter 48000, loss: 0.001531
 >> iter 49000, loss: 0.001513
 >> iter 50000, loss: 0.001466
   Number of active neurons: 2
 >> iter 51000, loss: 0.001450
 >> iter 52000, loss: 0.001406
 >> iter 53000, loss: 0.001393
 >> iter 54000, loss: 0.001351
 >> iter 55000, loss: 0.001340
 >> iter 56000, loss: 0.001300
 >> iter 57000, loss: 0.001291
 >> iter 58000, loss: 0.001253
 >> iter 59000, loss: 0.001246
 >> iter 60000, loss: 0.001209
   Number of active neurons: 2
 >> iter 61000, loss: 0.001203
 >> iter 62000, loss: 0.001168
 >> iter 63000, loss: 0.001164
 >> iter 64000, loss: 0.001131
 >> iter 65000, loss: 0.001129
 >> iter 66000, loss: 0.001095
 >> iter 67000, loss: 0.001093
 >> iter 68000, loss: 0.001063
 >> iter 69000, loss: 0.001061
 >> iter 70000, loss: 0.001031
   Number of active neurons: 2
 >> iter 71000, loss: 0.001029
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.377771
 >> iter 2000, loss: 5.944117
 >> iter 3000, loss: 2.220161
 >> iter 4000, loss: 0.876865
 >> iter 5000, loss: 0.336401
 >> iter 6000, loss: 0.134424
 >> iter 7000, loss: 0.058112
 >> iter 8000, loss: 0.028554
 >> iter 9000, loss: 0.016799
 >> iter 10000, loss: 0.011605
   Number of active neurons: 2
 >> iter 11000, loss: 0.009204
 >> iter 12000, loss: 0.007746
 >> iter 13000, loss: 0.006905
 >> iter 14000, loss: 0.006184
 >> iter 15000, loss: 0.005716
 >> iter 16000, loss: 0.005230
 >> iter 17000, loss: 0.004911
 >> iter 18000, loss: 0.004548
 >> iter 19000, loss: 0.004312
 >> iter 20000, loss: 0.004024
   Number of active neurons: 2
 >> iter 21000, loss: 0.003842
 >> iter 22000, loss: 0.003610
 >> iter 23000, loss: 0.003465
 >> iter 24000, loss: 0.003272
 >> iter 25000, loss: 0.003156
 >> iter 26000, loss: 0.002993
 >> iter 27000, loss: 0.002900
 >> iter 28000, loss: 0.002756
 >> iter 29000, loss: 0.002679
 >> iter 30000, loss: 0.002555
   Number of active neurons: 2
 >> iter 31000, loss: 0.002491
 >> iter 32000, loss: 0.002380
 >> iter 33000, loss: 0.002326
 >> iter 34000, loss: 0.002227
 >> iter 35000, loss: 0.002184
 >> iter 36000, loss: 0.002094
 >> iter 37000, loss: 0.002058
 >> iter 38000, loss: 0.001977
 >> iter 39000, loss: 0.001945
 >> iter 40000, loss: 0.001871
   Number of active neurons: 2
 >> iter 41000, loss: 0.001843
 >> iter 42000, loss: 0.001776
 >> iter 43000, loss: 0.001751
 >> iter 44000, loss: 0.001690
 >> iter 45000, loss: 0.001668
 >> iter 46000, loss: 0.001612
 >> iter 47000, loss: 0.001592
 >> iter 48000, loss: 0.001540
 >> iter 49000, loss: 0.001523
 >> iter 50000, loss: 0.001474
   Number of active neurons: 2
 >> iter 51000, loss: 0.001459
 >> iter 52000, loss: 0.001414
 >> iter 53000, loss: 0.001402
 >> iter 54000, loss: 0.001359
 >> iter 55000, loss: 0.001349
 >> iter 56000, loss: 0.001307
 >> iter 57000, loss: 0.001299
 >> iter 58000, loss: 0.001259
 >> iter 59000, loss: 0.001254
 >> iter 60000, loss: 0.001216
   Number of active neurons: 2
 >> iter 61000, loss: 0.001210
 >> iter 62000, loss: 0.001174
 >> iter 63000, loss: 0.001171
 >> iter 64000, loss: 0.001137
 >> iter 65000, loss: 0.001136
 >> iter 66000, loss: 0.001101
 >> iter 67000, loss: 0.001100
 >> iter 68000, loss: 0.001068
 >> iter 69000, loss: 0.001067
 >> iter 70000, loss: 0.001036
   Number of active neurons: 2
 >> iter 71000, loss: 0.001036
 >> iter 72000, loss: 0.001006
 >> iter 73000, loss: 0.001006
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.574284
 >> iter 2000, loss: 7.773297
 >> iter 3000, loss: 3.173644
 >> iter 4000, loss: 1.256736
 >> iter 5000, loss: 0.493741
 >> iter 6000, loss: 0.192880
 >> iter 7000, loss: 0.093432
 >> iter 8000, loss: 0.041136
 >> iter 9000, loss: 0.020798
 >> iter 10000, loss: 0.012336
   Number of active neurons: 2
 >> iter 11000, loss: 0.008755
 >> iter 12000, loss: 0.006807
 >> iter 13000, loss: 0.005787
 >> iter 14000, loss: 0.005032
 >> iter 15000, loss: 0.004563
 >> iter 16000, loss: 0.004115
 >> iter 17000, loss: 0.003821
 >> iter 18000, loss: 0.003505
 >> iter 19000, loss: 0.003297
 >> iter 20000, loss: 0.003055
   Number of active neurons: 2
 >> iter 21000, loss: 0.002898
 >> iter 22000, loss: 0.002708
 >> iter 23000, loss: 0.002585
 >> iter 24000, loss: 0.002432
 >> iter 25000, loss: 0.002333
 >> iter 26000, loss: 0.002207
 >> iter 27000, loss: 0.002127
 >> iter 28000, loss: 0.002018
 >> iter 29000, loss: 0.001952
 >> iter 30000, loss: 0.001861
   Number of active neurons: 2
 >> iter 31000, loss: 0.001805
 >> iter 32000, loss: 0.001724
 >> iter 33000, loss: 0.001678
 >> iter 34000, loss: 0.001607
 >> iter 35000, loss: 0.001568
 >> iter 36000, loss: 0.001505
 >> iter 37000, loss: 0.001472
 >> iter 38000, loss: 0.001414
 >> iter 39000, loss: 0.001386
 >> iter 40000, loss: 0.001334
   Number of active neurons: 2
 >> iter 41000, loss: 0.001309
 >> iter 42000, loss: 0.001263
 >> iter 43000, loss: 0.001241
 >> iter 44000, loss: 0.001199
 >> iter 45000, loss: 0.001179
 >> iter 46000, loss: 0.001141
 >> iter 47000, loss: 0.001123
 >> iter 48000, loss: 0.001088
 >> iter 49000, loss: 0.001071
 >> iter 50000, loss: 0.001039
   Number of active neurons: 2
 >> iter 51000, loss: 0.001025
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.600429
 >> iter 2000, loss: 5.968248
 >> iter 3000, loss: 2.233798
 >> iter 4000, loss: 0.844294
 >> iter 5000, loss: 0.327105
 >> iter 6000, loss: 0.132932
 >> iter 7000, loss: 0.059447
 >> iter 8000, loss: 0.030560
 >> iter 9000, loss: 0.018940
 >> iter 10000, loss: 0.013579
   Number of active neurons: 2
 >> iter 11000, loss: 0.011040
 >> iter 12000, loss: 0.009386
 >> iter 13000, loss: 0.008421
 >> iter 14000, loss: 0.007552
 >> iter 15000, loss: 0.006994
 >> iter 16000, loss: 0.006397
 >> iter 17000, loss: 0.006013
 >> iter 18000, loss: 0.005563
 >> iter 19000, loss: 0.005275
 >> iter 20000, loss: 0.004917
   Number of active neurons: 2
 >> iter 21000, loss: 0.004701
 >> iter 22000, loss: 0.004411
 >> iter 23000, loss: 0.004229
 >> iter 24000, loss: 0.003989
 >> iter 25000, loss: 0.003887
 >> iter 26000, loss: 0.003690
 >> iter 27000, loss: 0.003560
 >> iter 28000, loss: 0.003372
 >> iter 29000, loss: 0.003266
 >> iter 30000, loss: 0.003110
   Number of active neurons: 2
 >> iter 31000, loss: 0.003023
 >> iter 32000, loss: 0.002886
 >> iter 33000, loss: 0.002821
 >> iter 34000, loss: 0.002700
 >> iter 35000, loss: 0.002642
 >> iter 36000, loss: 0.002532
 >> iter 37000, loss: 0.002529
 >> iter 38000, loss: 0.002436
 >> iter 39000, loss: 0.002391
 >> iter 40000, loss: 0.002288
   Number of active neurons: 2
 >> iter 41000, loss: 0.002244
 >> iter 42000, loss: 0.002155
 >> iter 43000, loss: 0.002119
 >> iter 44000, loss: 0.002039
 >> iter 45000, loss: 0.002009
 >> iter 46000, loss: 0.001937
 >> iter 47000, loss: 0.001912
 >> iter 48000, loss: 0.001847
 >> iter 49000, loss: 0.001835
 >> iter 50000, loss: 0.001776
   Number of active neurons: 2
 >> iter 51000, loss: 0.001756
 >> iter 52000, loss: 0.001697
 >> iter 53000, loss: 0.001679
 >> iter 54000, loss: 0.001625
 >> iter 55000, loss: 0.001613
 >> iter 56000, loss: 0.001561
 >> iter 57000, loss: 0.001551
 >> iter 58000, loss: 0.001502
 >> iter 59000, loss: 0.001494
 >> iter 60000, loss: 0.001448
   Number of active neurons: 2
 >> iter 61000, loss: 0.001443
 >> iter 62000, loss: 0.001400
 >> iter 63000, loss: 0.001393
 >> iter 64000, loss: 0.001351
 >> iter 65000, loss: 0.001356
 >> iter 66000, loss: 0.001317
 >> iter 67000, loss: 0.001311
 >> iter 68000, loss: 0.001272
 >> iter 69000, loss: 0.001266
 >> iter 70000, loss: 0.001228
   Number of active neurons: 2
 >> iter 71000, loss: 0.001224
 >> iter 72000, loss: 0.001189
 >> iter 73000, loss: 0.001205
 >> iter 74000, loss: 0.001178
 >> iter 75000, loss: 0.001174
 >> iter 76000, loss: 0.001140
 >> iter 77000, loss: 0.001134
 >> iter 78000, loss: 0.001101
 >> iter 79000, loss: 0.001097
 >> iter 80000, loss: 0.001066
   Number of active neurons: 2
 >> iter 81000, loss: 0.001063
 >> iter 82000, loss: 0.001034
 >> iter 83000, loss: 0.001032
 >> iter 84000, loss: 0.001006
 >> iter 85000, loss: 0.001005
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.423046
 >> iter 2000, loss: 6.105666
 >> iter 3000, loss: 2.315410
 >> iter 4000, loss: 0.873345
 >> iter 5000, loss: 0.336193
 >> iter 6000, loss: 0.134682
 >> iter 7000, loss: 0.058519
 >> iter 8000, loss: 0.028825
 >> iter 9000, loss: 0.016956
 >> iter 10000, loss: 0.011662
   Number of active neurons: 2
 >> iter 11000, loss: 0.009185
 >> iter 12000, loss: 0.007688
 >> iter 13000, loss: 0.006804
 >> iter 14000, loss: 0.006074
 >> iter 15000, loss: 0.005581
 >> iter 16000, loss: 0.005099
 >> iter 17000, loss: 0.004763
 >> iter 18000, loss: 0.004410
 >> iter 19000, loss: 0.004162
 >> iter 20000, loss: 0.003885
   Number of active neurons: 2
 >> iter 21000, loss: 0.003693
 >> iter 22000, loss: 0.003473
 >> iter 23000, loss: 0.003321
 >> iter 24000, loss: 0.003139
 >> iter 25000, loss: 0.003016
 >> iter 26000, loss: 0.002864
 >> iter 27000, loss: 0.002766
 >> iter 28000, loss: 0.002631
 >> iter 29000, loss: 0.002550
 >> iter 30000, loss: 0.002436
   Number of active neurons: 2
 >> iter 31000, loss: 0.002367
 >> iter 32000, loss: 0.002265
 >> iter 33000, loss: 0.002207
 >> iter 34000, loss: 0.002117
 >> iter 35000, loss: 0.002069
 >> iter 36000, loss: 0.001988
 >> iter 37000, loss: 0.001948
 >> iter 38000, loss: 0.001876
 >> iter 39000, loss: 0.001840
 >> iter 40000, loss: 0.001774
   Number of active neurons: 2
 >> iter 41000, loss: 0.001741
 >> iter 42000, loss: 0.001683
 >> iter 43000, loss: 0.001654
 >> iter 44000, loss: 0.001600
 >> iter 45000, loss: 0.001575
 >> iter 46000, loss: 0.001525
 >> iter 47000, loss: 0.001503
 >> iter 48000, loss: 0.001457
 >> iter 49000, loss: 0.001436
 >> iter 50000, loss: 0.001394
   Number of active neurons: 2
 >> iter 51000, loss: 0.001376
 >> iter 52000, loss: 0.001337
 >> iter 53000, loss: 0.001321
 >> iter 54000, loss: 0.001284
 >> iter 55000, loss: 0.001271
 >> iter 56000, loss: 0.001236
 >> iter 57000, loss: 0.001224
 >> iter 58000, loss: 0.001190
 >> iter 59000, loss: 0.001182
 >> iter 60000, loss: 0.001148
   Number of active neurons: 2
 >> iter 61000, loss: 0.001140
 >> iter 62000, loss: 0.001109
 >> iter 63000, loss: 0.001104
 >> iter 64000, loss: 0.001074
 >> iter 65000, loss: 0.001069
 >> iter 66000, loss: 0.001040
 >> iter 67000, loss: 0.001035
 >> iter 68000, loss: 0.001009
 >> iter 69000, loss: 0.001005
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.476596
 >> iter 2000, loss: 6.025750
 >> iter 3000, loss: 2.255638
 >> iter 4000, loss: 0.852229
 >> iter 5000, loss: 0.329818
 >> iter 6000, loss: 0.133728
 >> iter 7000, loss: 0.059704
 >> iter 8000, loss: 0.030516
 >> iter 9000, loss: 0.018774
 >> iter 10000, loss: 0.013382
   Number of active neurons: 2
 >> iter 11000, loss: 0.012541
 >> iter 12000, loss: 0.009822
 >> iter 13000, loss: 0.008444
 >> iter 14000, loss: 0.007431
 >> iter 15000, loss: 0.006812
 >> iter 16000, loss: 0.006208
 >> iter 17000, loss: 0.005825
 >> iter 18000, loss: 0.005388
 >> iter 19000, loss: 0.005127
 >> iter 20000, loss: 0.004783
   Number of active neurons: 2
 >> iter 21000, loss: 0.004554
 >> iter 22000, loss: 0.004271
 >> iter 23000, loss: 0.004321
 >> iter 24000, loss: 0.004035
 >> iter 25000, loss: 0.003850
 >> iter 26000, loss: 0.003626
 >> iter 27000, loss: 0.003488
 >> iter 28000, loss: 0.003301
 >> iter 29000, loss: 0.003192
 >> iter 30000, loss: 0.003037
   Number of active neurons: 2
 >> iter 31000, loss: 0.002947
 >> iter 32000, loss: 0.002811
 >> iter 33000, loss: 0.002740
 >> iter 34000, loss: 0.002621
 >> iter 35000, loss: 0.002662
 >> iter 36000, loss: 0.002562
 >> iter 37000, loss: 0.002503
 >> iter 38000, loss: 0.002389
 >> iter 39000, loss: 0.002337
 >> iter 40000, loss: 0.002236
   Number of active neurons: 2
 >> iter 41000, loss: 0.002192
 >> iter 42000, loss: 0.002105
 >> iter 43000, loss: 0.002067
 >> iter 44000, loss: 0.001988
 >> iter 45000, loss: 0.001956
 >> iter 46000, loss: 0.001886
 >> iter 47000, loss: 0.001858
 >> iter 48000, loss: 0.001794
 >> iter 49000, loss: 0.001791
 >> iter 50000, loss: 0.001738
   Number of active neurons: 2
 >> iter 51000, loss: 0.001717
 >> iter 52000, loss: 0.001659
 >> iter 53000, loss: 0.001638
 >> iter 54000, loss: 0.001584
 >> iter 55000, loss: 0.001567
 >> iter 56000, loss: 0.001516
 >> iter 57000, loss: 0.001506
 >> iter 58000, loss: 0.001459
 >> iter 59000, loss: 0.001449
 >> iter 60000, loss: 0.001403
   Number of active neurons: 2
 >> iter 61000, loss: 0.001465
 >> iter 62000, loss: 0.001430
 >> iter 63000, loss: 0.001419
 >> iter 64000, loss: 0.001371
 >> iter 65000, loss: 0.001359
 >> iter 66000, loss: 0.001314
 >> iter 67000, loss: 0.001303
 >> iter 68000, loss: 0.001263
 >> iter 69000, loss: 0.001255
 >> iter 70000, loss: 0.001217
   Number of active neurons: 2
 >> iter 71000, loss: 0.001209
 >> iter 72000, loss: 0.001173
 >> iter 73000, loss: 0.001166
 >> iter 74000, loss: 0.001133
 >> iter 75000, loss: 0.001127
 >> iter 76000, loss: 0.001096
 >> iter 77000, loss: 0.001091
 >> iter 78000, loss: 0.001061
 >> iter 79000, loss: 0.001057
 >> iter 80000, loss: 0.001028
   Number of active neurons: 2
 >> iter 81000, loss: 0.001026
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00599994000061
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.910111
 >> iter 2000, loss: 6.331232
 >> iter 3000, loss: 2.368743
 >> iter 4000, loss: 0.943261
 >> iter 5000, loss: 0.362139
 >> iter 6000, loss: 0.144588
 >> iter 7000, loss: 0.062591
 >> iter 8000, loss: 0.030739
 >> iter 9000, loss: 0.018112
 >> iter 10000, loss: 0.012495
   Number of active neurons: 2
 >> iter 11000, loss: 0.009922
 >> iter 12000, loss: 0.008339
 >> iter 13000, loss: 0.007439
 >> iter 14000, loss: 0.006655
 >> iter 15000, loss: 0.006156
 >> iter 16000, loss: 0.005628
 >> iter 17000, loss: 0.005286
 >> iter 18000, loss: 0.004893
 >> iter 19000, loss: 0.004640
 >> iter 20000, loss: 0.004327
   Number of active neurons: 2
 >> iter 21000, loss: 0.004132
 >> iter 22000, loss: 0.003879
 >> iter 23000, loss: 0.003725
 >> iter 24000, loss: 0.003515
 >> iter 25000, loss: 0.003391
 >> iter 26000, loss: 0.003213
 >> iter 27000, loss: 0.003114
 >> iter 28000, loss: 0.002956
 >> iter 29000, loss: 0.002874
 >> iter 30000, loss: 0.002739
   Number of active neurons: 2
 >> iter 31000, loss: 0.002670
 >> iter 32000, loss: 0.002549
 >> iter 33000, loss: 0.002491
 >> iter 34000, loss: 0.002384
 >> iter 35000, loss: 0.002337
 >> iter 36000, loss: 0.002240
 >> iter 37000, loss: 0.002201
 >> iter 38000, loss: 0.002112
 >> iter 39000, loss: 0.002079
 >> iter 40000, loss: 0.001997
   Number of active neurons: 2
 >> iter 41000, loss: 0.001967
 >> iter 42000, loss: 0.001895
 >> iter 43000, loss: 0.001868
 >> iter 44000, loss: 0.001801
 >> iter 45000, loss: 0.001778
 >> iter 46000, loss: 0.001716
 >> iter 47000, loss: 0.001696
 >> iter 48000, loss: 0.001639
 >> iter 49000, loss: 0.001620
 >> iter 50000, loss: 0.001567
   Number of active neurons: 2
 >> iter 51000, loss: 0.001552
 >> iter 52000, loss: 0.001502
 >> iter 53000, loss: 0.001489
 >> iter 54000, loss: 0.001442
 >> iter 55000, loss: 0.001432
 >> iter 56000, loss: 0.001387
 >> iter 57000, loss: 0.001378
 >> iter 58000, loss: 0.001335
 >> iter 59000, loss: 0.001329
 >> iter 60000, loss: 0.001287
   Number of active neurons: 2
 >> iter 61000, loss: 0.001282
 >> iter 62000, loss: 0.001243
 >> iter 63000, loss: 0.001240
 >> iter 64000, loss: 0.001202
 >> iter 65000, loss: 0.001203
 >> iter 66000, loss: 0.001164
 >> iter 67000, loss: 0.001164
 >> iter 68000, loss: 0.001129
 >> iter 69000, loss: 0.001129
 >> iter 70000, loss: 0.001094
   Number of active neurons: 2
 >> iter 71000, loss: 0.001094
 >> iter 72000, loss: 0.001061
 >> iter 73000, loss: 0.001062
 >> iter 74000, loss: 0.001031
 >> iter 75000, loss: 0.001031
 >> iter 76000, loss: 0.001001
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.570451
 >> iter 2000, loss: 5.936723
 >> iter 3000, loss: 2.220131
 >> iter 4000, loss: 0.838397
 >> iter 5000, loss: 0.324407
 >> iter 6000, loss: 0.131591
 >> iter 7000, loss: 0.058691
 >> iter 8000, loss: 0.030086
 >> iter 9000, loss: 0.018606
 >> iter 10000, loss: 0.013328
   Number of active neurons: 2
 >> iter 11000, loss: 0.010844
 >> iter 12000, loss: 0.009224
 >> iter 13000, loss: 0.008288
 >> iter 14000, loss: 0.007436
 >> iter 15000, loss: 0.006890
 >> iter 16000, loss: 0.006304
 >> iter 17000, loss: 0.005943
 >> iter 18000, loss: 0.005501
 >> iter 19000, loss: 0.005207
 >> iter 20000, loss: 0.004853
   Number of active neurons: 2
 >> iter 21000, loss: 0.004658
 >> iter 22000, loss: 0.004377
 >> iter 23000, loss: 0.004190
 >> iter 24000, loss: 0.003950
 >> iter 25000, loss: 0.003801
 >> iter 26000, loss: 0.003602
 >> iter 27000, loss: 0.003579
 >> iter 28000, loss: 0.003404
 >> iter 29000, loss: 0.003285
 >> iter 30000, loss: 0.003116
   Number of active neurons: 2
 >> iter 31000, loss: 0.003018
 >> iter 32000, loss: 0.002876
 >> iter 33000, loss: 0.002798
 >> iter 34000, loss: 0.002675
 >> iter 35000, loss: 0.002613
 >> iter 36000, loss: 0.002504
 >> iter 37000, loss: 0.002455
 >> iter 38000, loss: 0.002356
 >> iter 39000, loss: 0.002329
 >> iter 40000, loss: 0.002241
   Number of active neurons: 2
 >> iter 41000, loss: 0.002203
 >> iter 42000, loss: 0.002120
 >> iter 43000, loss: 0.002085
 >> iter 44000, loss: 0.002009
 >> iter 45000, loss: 0.001989
 >> iter 46000, loss: 0.001921
 >> iter 47000, loss: 0.001895
 >> iter 48000, loss: 0.001830
 >> iter 49000, loss: 0.001809
 >> iter 50000, loss: 0.001750
   Number of active neurons: 2
 >> iter 51000, loss: 0.001735
 >> iter 52000, loss: 0.001680
 >> iter 53000, loss: 0.001663
 >> iter 54000, loss: 0.001610
 >> iter 55000, loss: 0.001624
 >> iter 56000, loss: 0.001582
 >> iter 57000, loss: 0.001568
 >> iter 58000, loss: 0.001516
 >> iter 59000, loss: 0.001502
 >> iter 60000, loss: 0.001452
   Number of active neurons: 2
 >> iter 61000, loss: 0.001440
 >> iter 62000, loss: 0.001396
 >> iter 63000, loss: 0.001387
 >> iter 64000, loss: 0.001345
 >> iter 65000, loss: 0.001338
 >> iter 66000, loss: 0.001298
 >> iter 67000, loss: 0.001293
 >> iter 68000, loss: 0.001256
 >> iter 69000, loss: 0.001259
 >> iter 70000, loss: 0.001225
   Number of active neurons: 2
 >> iter 71000, loss: 0.001220
 >> iter 72000, loss: 0.001185
 >> iter 73000, loss: 0.001180
 >> iter 74000, loss: 0.001148
 >> iter 75000, loss: 0.001146
 >> iter 76000, loss: 0.001117
 >> iter 77000, loss: 0.001113
 >> iter 78000, loss: 0.001083
 >> iter 79000, loss: 0.001087
 >> iter 80000, loss: 0.001060
   Number of active neurons: 2
 >> iter 81000, loss: 0.001058
 >> iter 82000, loss: 0.001030
 >> iter 83000, loss: 0.001027
 >> iter 84000, loss: 0.001002
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.985841
 >> iter 2000, loss: 6.253606
 >> iter 3000, loss: 2.340797
 >> iter 4000, loss: 0.884123
 >> iter 5000, loss: 0.341911
 >> iter 6000, loss: 0.138451
 >> iter 7000, loss: 0.061498
 >> iter 8000, loss: 0.031330
 >> iter 9000, loss: 0.019217
 >> iter 10000, loss: 0.013679
   Number of active neurons: 2
 >> iter 11000, loss: 0.011063
 >> iter 12000, loss: 0.009387
 >> iter 13000, loss: 0.008406
 >> iter 14000, loss: 0.007536
 >> iter 15000, loss: 0.006972
 >> iter 16000, loss: 0.006378
 >> iter 17000, loss: 0.005986
 >> iter 18000, loss: 0.005540
 >> iter 19000, loss: 0.005253
 >> iter 20000, loss: 0.004899
   Number of active neurons: 2
 >> iter 21000, loss: 0.004670
 >> iter 22000, loss: 0.004386
 >> iter 23000, loss: 0.004243
 >> iter 24000, loss: 0.004014
 >> iter 25000, loss: 0.003855
 >> iter 26000, loss: 0.003648
 >> iter 27000, loss: 0.003520
 >> iter 28000, loss: 0.003341
 >> iter 29000, loss: 0.003238
 >> iter 30000, loss: 0.003089
   Number of active neurons: 2
 >> iter 31000, loss: 0.003009
 >> iter 32000, loss: 0.002877
 >> iter 33000, loss: 0.002804
 >> iter 34000, loss: 0.002685
 >> iter 35000, loss: 0.002655
 >> iter 36000, loss: 0.002556
 >> iter 37000, loss: 0.002503
 >> iter 38000, loss: 0.002398
 >> iter 39000, loss: 0.002351
 >> iter 40000, loss: 0.002257
   Number of active neurons: 2
 >> iter 41000, loss: 0.002216
 >> iter 42000, loss: 0.002134
 >> iter 43000, loss: 0.002099
 >> iter 44000, loss: 0.002024
 >> iter 45000, loss: 0.002005
 >> iter 46000, loss: 0.001939
 >> iter 47000, loss: 0.001911
 >> iter 48000, loss: 0.001847
 >> iter 49000, loss: 0.001822
 >> iter 50000, loss: 0.001762
   Number of active neurons: 2
 >> iter 51000, loss: 0.001745
 >> iter 52000, loss: 0.001691
 >> iter 53000, loss: 0.001673
 >> iter 54000, loss: 0.001621
 >> iter 55000, loss: 0.001620
 >> iter 56000, loss: 0.001573
 >> iter 57000, loss: 0.001559
 >> iter 58000, loss: 0.001510
 >> iter 59000, loss: 0.001497
 >> iter 60000, loss: 0.001451
   Number of active neurons: 2
 >> iter 61000, loss: 0.001440
 >> iter 62000, loss: 0.001397
 >> iter 63000, loss: 0.001390
 >> iter 64000, loss: 0.001350
 >> iter 65000, loss: 0.001350
 >> iter 66000, loss: 0.001313
 >> iter 67000, loss: 0.001305
 >> iter 68000, loss: 0.001269
 >> iter 69000, loss: 0.001263
 >> iter 70000, loss: 0.001228
   Number of active neurons: 2
 >> iter 71000, loss: 0.001226
 >> iter 72000, loss: 0.001193
 >> iter 73000, loss: 0.001188
 >> iter 74000, loss: 0.001157
 >> iter 75000, loss: 0.001153
 >> iter 76000, loss: 0.001123
 >> iter 77000, loss: 0.001121
 >> iter 78000, loss: 0.001092
 >> iter 79000, loss: 0.001092
 >> iter 80000, loss: 0.001064
   Number of active neurons: 2
 >> iter 81000, loss: 0.001062
 >> iter 82000, loss: 0.001035
 >> iter 83000, loss: 0.001037
 >> iter 84000, loss: 0.001013
 >> iter 85000, loss: 0.001011
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.203182
 >> iter 2000, loss: 5.954624
 >> iter 3000, loss: 2.224527
 >> iter 4000, loss: 0.839755
 >> iter 5000, loss: 0.322600
 >> iter 6000, loss: 0.129594
 >> iter 7000, loss: 0.056356
 >> iter 8000, loss: 0.027934
 >> iter 9000, loss: 0.016627
 >> iter 10000, loss: 0.011585
   Number of active neurons: 2
 >> iter 11000, loss: 0.009257
 >> iter 12000, loss: 0.007811
 >> iter 13000, loss: 0.006985
 >> iter 14000, loss: 0.006257
 >> iter 15000, loss: 0.005795
 >> iter 16000, loss: 0.005301
 >> iter 17000, loss: 0.004983
 >> iter 18000, loss: 0.004613
 >> iter 19000, loss: 0.004379
 >> iter 20000, loss: 0.004084
   Number of active neurons: 2
 >> iter 21000, loss: 0.003903
 >> iter 22000, loss: 0.003665
 >> iter 23000, loss: 0.003521
 >> iter 24000, loss: 0.003324
 >> iter 25000, loss: 0.003208
 >> iter 26000, loss: 0.003040
 >> iter 27000, loss: 0.002948
 >> iter 28000, loss: 0.002800
 >> iter 29000, loss: 0.002724
 >> iter 30000, loss: 0.002596
   Number of active neurons: 2
 >> iter 31000, loss: 0.002532
 >> iter 32000, loss: 0.002418
 >> iter 33000, loss: 0.002365
 >> iter 34000, loss: 0.002263
 >> iter 35000, loss: 0.002220
 >> iter 36000, loss: 0.002128
 >> iter 37000, loss: 0.002093
 >> iter 38000, loss: 0.002009
 >> iter 39000, loss: 0.001978
 >> iter 40000, loss: 0.001901
   Number of active neurons: 2
 >> iter 41000, loss: 0.001873
 >> iter 42000, loss: 0.001805
 >> iter 43000, loss: 0.001780
 >> iter 44000, loss: 0.001717
 >> iter 45000, loss: 0.001696
 >> iter 46000, loss: 0.001638
 >> iter 47000, loss: 0.001619
 >> iter 48000, loss: 0.001565
 >> iter 49000, loss: 0.001548
 >> iter 50000, loss: 0.001498
   Number of active neurons: 2
 >> iter 51000, loss: 0.001483
 >> iter 52000, loss: 0.001437
 >> iter 53000, loss: 0.001425
 >> iter 54000, loss: 0.001381
 >> iter 55000, loss: 0.001371
 >> iter 56000, loss: 0.001328
 >> iter 57000, loss: 0.001320
 >> iter 58000, loss: 0.001280
 >> iter 59000, loss: 0.001274
 >> iter 60000, loss: 0.001235
   Number of active neurons: 2
 >> iter 61000, loss: 0.001230
 >> iter 62000, loss: 0.001193
 >> iter 63000, loss: 0.001190
 >> iter 64000, loss: 0.001155
 >> iter 65000, loss: 0.001155
 >> iter 66000, loss: 0.001118
 >> iter 67000, loss: 0.001118
 >> iter 68000, loss: 0.001085
 >> iter 69000, loss: 0.001085
 >> iter 70000, loss: 0.001053
   Number of active neurons: 2
 >> iter 71000, loss: 0.001053
 >> iter 72000, loss: 0.001021
 >> iter 73000, loss: 0.001022
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.405830
 >> iter 2000, loss: 5.965705
 >> iter 3000, loss: 2.227176
 >> iter 4000, loss: 0.838574
 >> iter 5000, loss: 0.322374
 >> iter 6000, loss: 0.129201
 >> iter 7000, loss: 0.056442
 >> iter 8000, loss: 0.028126
 >> iter 9000, loss: 0.016889
 >> iter 10000, loss: 0.011840
   Number of active neurons: 2
 >> iter 11000, loss: 0.009515
 >> iter 12000, loss: 0.008054
 >> iter 13000, loss: 0.007218
 >> iter 14000, loss: 0.006476
 >> iter 15000, loss: 0.006002
 >> iter 16000, loss: 0.005496
 >> iter 17000, loss: 0.005168
 >> iter 18000, loss: 0.004788
 >> iter 19000, loss: 0.004544
 >> iter 20000, loss: 0.004241
   Number of active neurons: 2
 >> iter 21000, loss: 0.004052
 >> iter 22000, loss: 0.003807
 >> iter 23000, loss: 0.003656
 >> iter 24000, loss: 0.003452
 >> iter 25000, loss: 0.003331
 >> iter 26000, loss: 0.003158
 >> iter 27000, loss: 0.003060
 >> iter 28000, loss: 0.002907
 >> iter 29000, loss: 0.002826
 >> iter 30000, loss: 0.002695
   Number of active neurons: 2
 >> iter 31000, loss: 0.002627
 >> iter 32000, loss: 0.002509
 >> iter 33000, loss: 0.002452
 >> iter 34000, loss: 0.002348
 >> iter 35000, loss: 0.002301
 >> iter 36000, loss: 0.002207
 >> iter 37000, loss: 0.002168
 >> iter 38000, loss: 0.002082
 >> iter 39000, loss: 0.002048
 >> iter 40000, loss: 0.001969
   Number of active neurons: 2
 >> iter 41000, loss: 0.001939
 >> iter 42000, loss: 0.001869
 >> iter 43000, loss: 0.001842
 >> iter 44000, loss: 0.001777
 >> iter 45000, loss: 0.001754
 >> iter 46000, loss: 0.001694
 >> iter 47000, loss: 0.001673
 >> iter 48000, loss: 0.001618
 >> iter 49000, loss: 0.001599
 >> iter 50000, loss: 0.001548
   Number of active neurons: 2
 >> iter 51000, loss: 0.001532
 >> iter 52000, loss: 0.001484
 >> iter 53000, loss: 0.001471
 >> iter 54000, loss: 0.001426
 >> iter 55000, loss: 0.001415
 >> iter 56000, loss: 0.001371
 >> iter 57000, loss: 0.001362
 >> iter 58000, loss: 0.001320
 >> iter 59000, loss: 0.001314
 >> iter 60000, loss: 0.001273
   Number of active neurons: 2
 >> iter 61000, loss: 0.001267
 >> iter 62000, loss: 0.001230
 >> iter 63000, loss: 0.001227
 >> iter 64000, loss: 0.001190
 >> iter 65000, loss: 0.001190
 >> iter 66000, loss: 0.001152
 >> iter 67000, loss: 0.001152
 >> iter 68000, loss: 0.001118
 >> iter 69000, loss: 0.001117
 >> iter 70000, loss: 0.001084
   Number of active neurons: 2
 >> iter 71000, loss: 0.001084
 >> iter 72000, loss: 0.001051
 >> iter 73000, loss: 0.001052
 >> iter 74000, loss: 0.001022
 >> iter 75000, loss: 0.001021
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.879249
 >> iter 2000, loss: 6.233279
 >> iter 3000, loss: 2.333390
 >> iter 4000, loss: 0.881269
 >> iter 5000, loss: 0.340731
 >> iter 6000, loss: 0.137913
 >> iter 7000, loss: 0.061206
 >> iter 8000, loss: 0.031147
 >> iter 9000, loss: 0.019080
 >> iter 10000, loss: 0.013571
   Number of active neurons: 2
 >> iter 11000, loss: 0.010969
 >> iter 12000, loss: 0.009306
 >> iter 13000, loss: 0.008334
 >> iter 14000, loss: 0.007471
 >> iter 15000, loss: 0.006907
 >> iter 16000, loss: 0.006319
 >> iter 17000, loss: 0.005946
 >> iter 18000, loss: 0.005507
 >> iter 19000, loss: 0.005206
 >> iter 20000, loss: 0.004853
   Number of active neurons: 2
 >> iter 21000, loss: 0.004626
 >> iter 22000, loss: 0.004345
 >> iter 23000, loss: 0.004173
 >> iter 24000, loss: 0.003942
 >> iter 25000, loss: 0.003790
 >> iter 26000, loss: 0.003593
 >> iter 27000, loss: 0.003514
 >> iter 28000, loss: 0.003352
 >> iter 29000, loss: 0.003244
 >> iter 30000, loss: 0.003089
   Number of active neurons: 2
 >> iter 31000, loss: 0.002994
 >> iter 32000, loss: 0.002858
 >> iter 33000, loss: 0.002781
 >> iter 34000, loss: 0.002662
 >> iter 35000, loss: 0.002601
 >> iter 36000, loss: 0.002495
 >> iter 37000, loss: 0.002496
 >> iter 38000, loss: 0.002412
 >> iter 39000, loss: 0.002366
 >> iter 40000, loss: 0.002268
   Number of active neurons: 2
 >> iter 41000, loss: 0.002222
 >> iter 42000, loss: 0.002136
 >> iter 43000, loss: 0.002096
 >> iter 44000, loss: 0.002019
 >> iter 45000, loss: 0.001986
 >> iter 46000, loss: 0.001917
 >> iter 47000, loss: 0.001887
 >> iter 48000, loss: 0.001824
 >> iter 49000, loss: 0.001798
 >> iter 50000, loss: 0.001740
   Number of active neurons: 2
 >> iter 51000, loss: 0.001721
 >> iter 52000, loss: 0.001667
 >> iter 53000, loss: 0.001652
 >> iter 54000, loss: 0.001602
 >> iter 55000, loss: 0.001587
 >> iter 56000, loss: 0.001538
 >> iter 57000, loss: 0.001557
 >> iter 58000, loss: 0.001522
 >> iter 59000, loss: 0.001511
 >> iter 60000, loss: 0.001463
   Number of active neurons: 2
 >> iter 61000, loss: 0.001448
 >> iter 62000, loss: 0.001403
 >> iter 63000, loss: 0.001392
 >> iter 64000, loss: 0.001350
 >> iter 65000, loss: 0.001341
 >> iter 66000, loss: 0.001301
 >> iter 67000, loss: 0.001292
 >> iter 68000, loss: 0.001256
 >> iter 69000, loss: 0.001249
 >> iter 70000, loss: 0.001214
   Number of active neurons: 2
 >> iter 71000, loss: 0.001208
 >> iter 72000, loss: 0.001175
 >> iter 73000, loss: 0.001170
 >> iter 74000, loss: 0.001140
 >> iter 75000, loss: 0.001142
 >> iter 76000, loss: 0.001114
 >> iter 77000, loss: 0.001110
 >> iter 78000, loss: 0.001081
 >> iter 79000, loss: 0.001077
 >> iter 80000, loss: 0.001049
   Number of active neurons: 2
 >> iter 81000, loss: 0.001046
 >> iter 82000, loss: 0.001020
 >> iter 83000, loss: 0.001024
 >> iter 84000, loss: 0.001001
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

