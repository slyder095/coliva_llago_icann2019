 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.4
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.843254
 >> iter 2000, loss: 9.839124
 >> iter 3000, loss: 4.154970
 >> iter 4000, loss: 1.707797
 >> iter 5000, loss: 0.696508
 >> iter 6000, loss: 0.267957
 >> iter 7000, loss: 0.106664
 >> iter 8000, loss: 0.081411
 >> iter 9000, loss: 0.075427
 >> iter 10000, loss: 0.103849
   Number of active neurons: 10
 >> iter 11000, loss: 0.062340
 >> iter 12000, loss: 0.037267
 >> iter 13000, loss: 0.043023
 >> iter 14000, loss: 0.024557
 >> iter 15000, loss: 0.012468
 >> iter 16000, loss: 0.013507
 >> iter 17000, loss: 0.041971
 >> iter 18000, loss: 0.092651
 >> iter 19000, loss: 0.040812
 >> iter 20000, loss: 0.018271
   Number of active neurons: 10
 >> iter 21000, loss: 0.059443
 >> iter 22000, loss: 0.025096
 >> iter 23000, loss: 0.011808
 >> iter 24000, loss: 0.006525
 >> iter 25000, loss: 0.004829
 >> iter 26000, loss: 0.003648
 >> iter 27000, loss: 0.003039
 >> iter 28000, loss: 0.002649
 >> iter 29000, loss: 0.002382
 >> iter 30000, loss: 0.002861
   Number of active neurons: 10
 >> iter 31000, loss: 0.002325
 >> iter 32000, loss: 0.002309
 >> iter 33000, loss: 0.001999
 >> iter 34000, loss: 0.001900
 >> iter 35000, loss: 0.016809
 >> iter 36000, loss: 0.047205
 >> iter 37000, loss: 0.019102
 >> iter 38000, loss: 0.008393
 >> iter 39000, loss: 0.005049
 >> iter 40000, loss: 0.003715
   Number of active neurons: 10
 >> iter 41000, loss: 0.002616
 >> iter 42000, loss: 0.056069
 >> iter 43000, loss: 0.043600
 >> iter 44000, loss: 0.017374
 >> iter 45000, loss: 0.007467
 >> iter 46000, loss: 0.003704
 >> iter 47000, loss: 0.041887
 >> iter 48000, loss: 0.016727
 >> iter 49000, loss: 0.007319
 >> iter 50000, loss: 0.003768
   Number of active neurons: 10
 >> iter 51000, loss: 0.002432
 >> iter 52000, loss: 0.001808
 >> iter 53000, loss: 0.001569
 >> iter 54000, loss: 0.001398
 >> iter 55000, loss: 0.001363
 >> iter 56000, loss: 0.001255
 >> iter 57000, loss: 0.040792
 >> iter 58000, loss: 0.016025
 >> iter 59000, loss: 0.006785
 >> iter 60000, loss: 0.003577
   Number of active neurons: 10
 >> iter 61000, loss: 0.036754
 >> iter 62000, loss: 0.014440
 >> iter 63000, loss: 0.006181
 >> iter 64000, loss: 0.003102
 >> iter 65000, loss: 0.001942
 >> iter 66000, loss: 0.019206
 >> iter 67000, loss: 0.020224
 >> iter 68000, loss: 0.008276
 >> iter 69000, loss: 0.003905
 >> iter 70000, loss: 0.002159
   Number of active neurons: 10
 >> iter 71000, loss: 0.001474
 >> iter 72000, loss: 0.001741
 >> iter 73000, loss: 0.001351
 >> iter 74000, loss: 0.001933
 >> iter 75000, loss: 0.005608
 >> iter 76000, loss: 0.006932
 >> iter 77000, loss: 0.003441
 >> iter 78000, loss: 0.001992
 >> iter 79000, loss: 0.001421
 >> iter 80000, loss: 0.001156
   Number of active neurons: 10
 >> iter 81000, loss: 0.020189
 >> iter 82000, loss: 0.009879
 >> iter 83000, loss: 0.004316
 >> iter 84000, loss: 0.002133
 >> iter 85000, loss: 0.001464
 >> iter 86000, loss: 0.016300
 >> iter 87000, loss: 0.006733
 >> iter 88000, loss: 0.003060
 >> iter 89000, loss: 0.001657
 >> iter 90000, loss: 0.001091
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.929999
 >> iter 2000, loss: 8.338295
 >> iter 3000, loss: 3.480111
 >> iter 4000, loss: 1.477483
 >> iter 5000, loss: 0.674024
 >> iter 6000, loss: 0.322612
 >> iter 7000, loss: 0.138828
 >> iter 8000, loss: 0.199775
 >> iter 9000, loss: 0.084041
 >> iter 10000, loss: 0.037661
   Number of active neurons: 10
 >> iter 11000, loss: 0.060253
 >> iter 12000, loss: 0.125610
 >> iter 13000, loss: 0.095190
 >> iter 14000, loss: 0.126845
 >> iter 15000, loss: 0.067781
 >> iter 16000, loss: 0.030907
 >> iter 17000, loss: 0.058604
 >> iter 18000, loss: 0.152332
 >> iter 19000, loss: 0.062706
 >> iter 20000, loss: 0.092454
   Number of active neurons: 10
 >> iter 21000, loss: 0.053925
 >> iter 22000, loss: 0.024266
 >> iter 23000, loss: 0.063304
 >> iter 24000, loss: 0.038957
 >> iter 25000, loss: 0.105864
 >> iter 26000, loss: 0.043547
 >> iter 27000, loss: 0.019045
 >> iter 28000, loss: 0.009364
 >> iter 29000, loss: 0.005538
 >> iter 30000, loss: 0.019919
   Number of active neurons: 10
 >> iter 31000, loss: 0.046898
 >> iter 32000, loss: 0.060798
 >> iter 33000, loss: 0.046332
 >> iter 34000, loss: 0.019554
 >> iter 35000, loss: 0.060921
 >> iter 36000, loss: 0.025121
 >> iter 37000, loss: 0.011231
 >> iter 38000, loss: 0.005912
 >> iter 39000, loss: 0.003677
 >> iter 40000, loss: 0.002645
   Number of active neurons: 10
 >> iter 41000, loss: 0.002194
 >> iter 42000, loss: 0.002016
 >> iter 43000, loss: 0.026436
 >> iter 44000, loss: 0.011080
 >> iter 45000, loss: 0.086938
 >> iter 46000, loss: 0.034603
 >> iter 47000, loss: 0.015634
 >> iter 48000, loss: 0.007442
 >> iter 49000, loss: 0.004183
 >> iter 50000, loss: 0.002765
   Number of active neurons: 10
 >> iter 51000, loss: 0.023391
 >> iter 52000, loss: 0.057950
 >> iter 53000, loss: 0.023204
 >> iter 54000, loss: 0.037987
 >> iter 55000, loss: 0.023565
 >> iter 56000, loss: 0.010224
 >> iter 57000, loss: 0.005208
 >> iter 58000, loss: 0.003110
 >> iter 59000, loss: 0.002491
 >> iter 60000, loss: 0.057961
   Number of active neurons: 10
 >> iter 61000, loss: 0.049169
 >> iter 62000, loss: 0.020049
 >> iter 63000, loss: 0.008784
 >> iter 64000, loss: 0.004534
 >> iter 65000, loss: 0.020777
 >> iter 66000, loss: 0.052753
 >> iter 67000, loss: 0.020853
 >> iter 68000, loss: 0.028766
 >> iter 69000, loss: 0.011978
 >> iter 70000, loss: 0.005615
   Number of active neurons: 10
 >> iter 71000, loss: 0.003237
 >> iter 72000, loss: 0.002205
 >> iter 73000, loss: 0.001865
 >> iter 74000, loss: 0.001615
 >> iter 75000, loss: 0.001467
 >> iter 76000, loss: 0.001331
 >> iter 77000, loss: 0.001252
 >> iter 78000, loss: 0.011797
 >> iter 79000, loss: 0.005208
 >> iter 80000, loss: 0.002749
   Number of active neurons: 10
 >> iter 81000, loss: 0.001766
 >> iter 82000, loss: 0.001374
 >> iter 83000, loss: 0.001201
 >> iter 84000, loss: 0.001160
 >> iter 85000, loss: 0.001054
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.156720
 >> iter 2000, loss: 9.010323
 >> iter 3000, loss: 3.849392
 >> iter 4000, loss: 1.524246
 >> iter 5000, loss: 0.646047
 >> iter 6000, loss: 0.280773
 >> iter 7000, loss: 0.117230
 >> iter 8000, loss: 0.052296
 >> iter 9000, loss: 0.059898
 >> iter 10000, loss: 0.027129
   Number of active neurons: 10
 >> iter 11000, loss: 0.036485
 >> iter 12000, loss: 0.016911
 >> iter 13000, loss: 0.108945
 >> iter 14000, loss: 0.045729
 >> iter 15000, loss: 0.020340
 >> iter 16000, loss: 0.010101
 >> iter 17000, loss: 0.006030
 >> iter 18000, loss: 0.004225
 >> iter 19000, loss: 0.008855
 >> iter 20000, loss: 0.047994
   Number of active neurons: 10
 >> iter 21000, loss: 0.046735
 >> iter 22000, loss: 0.048632
 >> iter 23000, loss: 0.021966
 >> iter 24000, loss: 0.010467
 >> iter 25000, loss: 0.005826
 >> iter 26000, loss: 0.003883
 >> iter 27000, loss: 0.003068
 >> iter 28000, loss: 0.002469
 >> iter 29000, loss: 0.002244
 >> iter 30000, loss: 0.002305
   Number of active neurons: 10
 >> iter 31000, loss: 0.003240
 >> iter 32000, loss: 0.055432
 >> iter 33000, loss: 0.023516
 >> iter 34000, loss: 0.010418
 >> iter 35000, loss: 0.005278
 >> iter 36000, loss: 0.003090
 >> iter 37000, loss: 0.002197
 >> iter 38000, loss: 0.001821
 >> iter 39000, loss: 0.001542
 >> iter 40000, loss: 0.001402
   Number of active neurons: 10
 >> iter 41000, loss: 0.001301
 >> iter 42000, loss: 0.001254
 >> iter 43000, loss: 0.013675
 >> iter 44000, loss: 0.006139
 >> iter 45000, loss: 0.003107
 >> iter 46000, loss: 0.002043
 >> iter 47000, loss: 0.001680
 >> iter 48000, loss: 0.001286
 >> iter 49000, loss: 0.006389
 >> iter 50000, loss: 0.003110
   Number of active neurons: 10
 >> iter 51000, loss: 0.001823
 >> iter 52000, loss: 0.001268
 >> iter 53000, loss: 0.001104
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.344365
 >> iter 2000, loss: 8.823970
 >> iter 3000, loss: 3.856595
 >> iter 4000, loss: 1.525279
 >> iter 5000, loss: 0.776471
 >> iter 6000, loss: 0.414573
 >> iter 7000, loss: 0.275138
 >> iter 8000, loss: 0.181355
 >> iter 9000, loss: 0.134510
 >> iter 10000, loss: 0.099874
   Number of active neurons: 10
 >> iter 11000, loss: 0.079675
 >> iter 12000, loss: 0.089784
 >> iter 13000, loss: 0.062920
 >> iter 14000, loss: 0.087490
 >> iter 15000, loss: 0.037610
 >> iter 16000, loss: 0.023546
 >> iter 17000, loss: 0.023069
 >> iter 18000, loss: 0.011456
 >> iter 19000, loss: 0.044330
 >> iter 20000, loss: 0.019438
   Number of active neurons: 10
 >> iter 21000, loss: 0.009846
 >> iter 22000, loss: 0.005956
 >> iter 23000, loss: 0.013254
 >> iter 24000, loss: 0.026278
 >> iter 25000, loss: 0.037842
 >> iter 26000, loss: 0.016428
 >> iter 27000, loss: 0.027992
 >> iter 28000, loss: 0.012338
 >> iter 29000, loss: 0.006381
 >> iter 30000, loss: 0.003970
   Number of active neurons: 10
 >> iter 31000, loss: 0.003013
 >> iter 32000, loss: 0.002545
 >> iter 33000, loss: 0.002312
 >> iter 34000, loss: 0.002871
 >> iter 35000, loss: 0.002214
 >> iter 36000, loss: 0.001951
 >> iter 37000, loss: 0.001826
 >> iter 38000, loss: 0.015957
 >> iter 39000, loss: 0.039396
 >> iter 40000, loss: 0.039576
   Number of active neurons: 10
 >> iter 41000, loss: 0.016826
 >> iter 42000, loss: 0.023230
 >> iter 43000, loss: 0.009749
 >> iter 44000, loss: 0.004777
 >> iter 45000, loss: 0.002720
 >> iter 46000, loss: 0.001870
 >> iter 47000, loss: 0.001548
 >> iter 48000, loss: 0.001358
 >> iter 49000, loss: 0.001292
 >> iter 50000, loss: 0.001215
   Number of active neurons: 10
 >> iter 51000, loss: 0.081253
 >> iter 52000, loss: 0.031179
 >> iter 53000, loss: 0.012559
 >> iter 54000, loss: 0.005589
 >> iter 55000, loss: 0.002952
 >> iter 56000, loss: 0.001885
 >> iter 57000, loss: 0.001489
 >> iter 58000, loss: 0.001271
 >> iter 59000, loss: 0.001193
 >> iter 60000, loss: 0.001105
   Number of active neurons: 10
 >> iter 61000, loss: 0.001104
 >> iter 62000, loss: 0.001033
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.938896
 >> iter 2000, loss: 9.195439
 >> iter 3000, loss: 3.961436
 >> iter 4000, loss: 1.649981
 >> iter 5000, loss: 0.652385
 >> iter 6000, loss: 0.271273
 >> iter 7000, loss: 0.123298
 >> iter 8000, loss: 0.056050
 >> iter 9000, loss: 0.056902
 >> iter 10000, loss: 0.049495
   Number of active neurons: 10
 >> iter 11000, loss: 0.034442
 >> iter 12000, loss: 0.050246
 >> iter 13000, loss: 0.024266
 >> iter 14000, loss: 0.013715
 >> iter 15000, loss: 0.024289
 >> iter 16000, loss: 0.013155
 >> iter 17000, loss: 0.018634
 >> iter 18000, loss: 0.010005
 >> iter 19000, loss: 0.027840
 >> iter 20000, loss: 0.013133
   Number of active neurons: 10
 >> iter 21000, loss: 0.032937
 >> iter 22000, loss: 0.015331
 >> iter 23000, loss: 0.008315
 >> iter 24000, loss: 0.005284
 >> iter 25000, loss: 0.003844
 >> iter 26000, loss: 0.003115
 >> iter 27000, loss: 0.003085
 >> iter 28000, loss: 0.002530
 >> iter 29000, loss: 0.002792
 >> iter 30000, loss: 0.002405
   Number of active neurons: 10
 >> iter 31000, loss: 0.003350
 >> iter 32000, loss: 0.002495
 >> iter 33000, loss: 0.002214
 >> iter 34000, loss: 0.002036
 >> iter 35000, loss: 0.002014
 >> iter 36000, loss: 0.001742
 >> iter 37000, loss: 0.001950
 >> iter 38000, loss: 0.001655
 >> iter 39000, loss: 0.001547
 >> iter 40000, loss: 0.001443
   Number of active neurons: 10
 >> iter 41000, loss: 0.001404
 >> iter 42000, loss: 0.001297
 >> iter 43000, loss: 0.001236
 >> iter 44000, loss: 0.001219
 >> iter 45000, loss: 0.001261
 >> iter 46000, loss: 0.001871
 >> iter 47000, loss: 0.002385
 >> iter 48000, loss: 0.001725
 >> iter 49000, loss: 0.001573
 >> iter 50000, loss: 0.001321
   Number of active neurons: 10
 >> iter 51000, loss: 0.018938
 >> iter 52000, loss: 0.007839
 >> iter 53000, loss: 0.003820
 >> iter 54000, loss: 0.002199
 >> iter 55000, loss: 0.001554
 >> iter 56000, loss: 0.001223
 >> iter 57000, loss: 0.001072
 >> iter 58000, loss: 0.001065
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 15.964355
 >> iter 2000, loss: 7.847934
 >> iter 3000, loss: 3.206357
 >> iter 4000, loss: 1.325680
 >> iter 5000, loss: 0.604708
 >> iter 6000, loss: 0.242181
 >> iter 7000, loss: 0.129628
 >> iter 8000, loss: 0.057852
 >> iter 9000, loss: 0.049182
 >> iter 10000, loss: 0.088467
   Number of active neurons: 10
 >> iter 11000, loss: 0.089264
 >> iter 12000, loss: 0.051468
 >> iter 13000, loss: 0.031081
 >> iter 14000, loss: 0.015619
 >> iter 15000, loss: 0.010278
 >> iter 16000, loss: 0.006905
 >> iter 17000, loss: 0.006156
 >> iter 18000, loss: 0.026355
 >> iter 19000, loss: 0.012629
 >> iter 20000, loss: 0.062195
   Number of active neurons: 10
 >> iter 21000, loss: 0.026833
 >> iter 22000, loss: 0.012425
 >> iter 23000, loss: 0.007184
 >> iter 24000, loss: 0.004972
 >> iter 25000, loss: 0.024603
 >> iter 26000, loss: 0.095015
 >> iter 27000, loss: 0.039281
 >> iter 28000, loss: 0.017971
 >> iter 29000, loss: 0.009845
 >> iter 30000, loss: 0.005617
   Number of active neurons: 10
 >> iter 31000, loss: 0.003868
 >> iter 32000, loss: 0.003006
 >> iter 33000, loss: 0.002629
 >> iter 34000, loss: 0.002432
 >> iter 35000, loss: 0.002347
 >> iter 36000, loss: 0.002083
 >> iter 37000, loss: 0.014800
 >> iter 38000, loss: 0.006761
 >> iter 39000, loss: 0.003697
 >> iter 40000, loss: 0.002480
   Number of active neurons: 10
 >> iter 41000, loss: 0.002060
 >> iter 42000, loss: 0.001743
 >> iter 43000, loss: 0.001677
 >> iter 44000, loss: 0.001608
 >> iter 45000, loss: 0.001536
 >> iter 46000, loss: 0.006572
 >> iter 47000, loss: 0.003638
 >> iter 48000, loss: 0.002245
 >> iter 49000, loss: 0.001924
 >> iter 50000, loss: 0.001496
   Number of active neurons: 10
 >> iter 51000, loss: 0.001366
 >> iter 52000, loss: 0.001226
 >> iter 53000, loss: 0.012842
 >> iter 54000, loss: 0.006056
 >> iter 55000, loss: 0.003194
 >> iter 56000, loss: 0.002031
 >> iter 57000, loss: 0.001501
 >> iter 58000, loss: 0.001393
 >> iter 59000, loss: 0.001249
 >> iter 60000, loss: 0.001228
   Number of active neurons: 10
 >> iter 61000, loss: 0.001394
 >> iter 62000, loss: 0.001142
 >> iter 63000, loss: 0.001056
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.397973
 >> iter 2000, loss: 10.436579
 >> iter 3000, loss: 4.982377
 >> iter 4000, loss: 2.291336
 >> iter 5000, loss: 0.966256
 >> iter 6000, loss: 0.493121
 >> iter 7000, loss: 0.337704
 >> iter 8000, loss: 0.228681
 >> iter 9000, loss: 0.184749
 >> iter 10000, loss: 0.168141
   Number of active neurons: 10
 >> iter 11000, loss: 0.094903
 >> iter 12000, loss: 0.042243
 >> iter 13000, loss: 0.110687
 >> iter 14000, loss: 0.064380
 >> iter 15000, loss: 0.111386
 >> iter 16000, loss: 0.054545
 >> iter 17000, loss: 0.023868
 >> iter 18000, loss: 0.011448
 >> iter 19000, loss: 0.006253
 >> iter 20000, loss: 0.017194
   Number of active neurons: 10
 >> iter 21000, loss: 0.009491
 >> iter 22000, loss: 0.005033
 >> iter 23000, loss: 0.003132
 >> iter 24000, loss: 0.002404
 >> iter 25000, loss: 0.001890
 >> iter 26000, loss: 0.019757
 >> iter 27000, loss: 0.008635
 >> iter 28000, loss: 0.004168
 >> iter 29000, loss: 0.002414
 >> iter 30000, loss: 0.002010
   Number of active neurons: 10
 >> iter 31000, loss: 0.022219
 >> iter 32000, loss: 0.009264
 >> iter 33000, loss: 0.017187
 >> iter 34000, loss: 0.007279
 >> iter 35000, loss: 0.003587
 >> iter 36000, loss: 0.002105
 >> iter 37000, loss: 0.013418
 >> iter 38000, loss: 0.026669
 >> iter 39000, loss: 0.028777
 >> iter 40000, loss: 0.011674
   Number of active neurons: 10
 >> iter 41000, loss: 0.005195
 >> iter 42000, loss: 0.002804
 >> iter 43000, loss: 0.001801
 >> iter 44000, loss: 0.001391
 >> iter 45000, loss: 0.001129
 >> iter 46000, loss: 0.020391
 >> iter 47000, loss: 0.008647
 >> iter 48000, loss: 0.003939
 >> iter 49000, loss: 0.002142
 >> iter 50000, loss: 0.001460
   Number of active neurons: 10
 >> iter 51000, loss: 0.001144
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.320398
 >> iter 2000, loss: 9.093828
 >> iter 3000, loss: 3.936538
 >> iter 4000, loss: 1.684714
 >> iter 5000, loss: 0.696950
 >> iter 6000, loss: 0.343483
 >> iter 7000, loss: 0.176968
 >> iter 8000, loss: 0.103945
 >> iter 9000, loss: 0.060536
 >> iter 10000, loss: 0.084399
   Number of active neurons: 10
 >> iter 11000, loss: 0.075496
 >> iter 12000, loss: 0.043476
 >> iter 13000, loss: 0.041928
 >> iter 14000, loss: 0.081958
 >> iter 15000, loss: 0.102548
 >> iter 16000, loss: 0.058725
 >> iter 17000, loss: 0.026512
 >> iter 18000, loss: 0.016463
 >> iter 19000, loss: 0.046279
 >> iter 20000, loss: 0.021508
   Number of active neurons: 10
 >> iter 21000, loss: 0.083705
 >> iter 22000, loss: 0.034729
 >> iter 23000, loss: 0.015787
 >> iter 24000, loss: 0.008759
 >> iter 25000, loss: 0.005807
 >> iter 26000, loss: 0.004664
 >> iter 27000, loss: 0.054487
 >> iter 28000, loss: 0.041269
 >> iter 29000, loss: 0.018427
 >> iter 30000, loss: 0.009097
   Number of active neurons: 10
 >> iter 31000, loss: 0.005974
 >> iter 32000, loss: 0.004185
 >> iter 33000, loss: 0.012061
 >> iter 34000, loss: 0.006091
 >> iter 35000, loss: 0.003831
 >> iter 36000, loss: 0.039498
 >> iter 37000, loss: 0.045285
 >> iter 38000, loss: 0.018747
 >> iter 39000, loss: 0.009579
 >> iter 40000, loss: 0.038393
   Number of active neurons: 10
 >> iter 41000, loss: 0.016865
 >> iter 42000, loss: 0.042733
 >> iter 43000, loss: 0.020275
 >> iter 44000, loss: 0.045347
 >> iter 45000, loss: 0.018896
 >> iter 46000, loss: 0.008741
 >> iter 47000, loss: 0.004822
 >> iter 48000, loss: 0.003242
 >> iter 49000, loss: 0.002712
 >> iter 50000, loss: 0.010731
   Number of active neurons: 10
 >> iter 51000, loss: 0.005594
 >> iter 52000, loss: 0.003327
 >> iter 53000, loss: 0.002494
 >> iter 54000, loss: 0.002364
 >> iter 55000, loss: 0.007892
 >> iter 56000, loss: 0.003847
 >> iter 57000, loss: 0.002347
 >> iter 58000, loss: 0.001679
 >> iter 59000, loss: 0.001848
 >> iter 60000, loss: 0.001969
   Number of active neurons: 10
 >> iter 61000, loss: 0.001678
 >> iter 62000, loss: 0.001465
 >> iter 63000, loss: 0.001356
 >> iter 64000, loss: 0.001189
 >> iter 65000, loss: 0.001133
 >> iter 66000, loss: 0.001248
 >> iter 67000, loss: 0.021439
 >> iter 68000, loss: 0.009043
 >> iter 69000, loss: 0.004197
 >> iter 70000, loss: 0.176965
   Number of active neurons: 10
 >> iter 71000, loss: 0.069900
 >> iter 72000, loss: 0.027515
 >> iter 73000, loss: 0.011600
 >> iter 74000, loss: 0.013352
 >> iter 75000, loss: 0.036463
 >> iter 76000, loss: 0.022173
 >> iter 77000, loss: 0.009851
 >> iter 78000, loss: 0.005012
 >> iter 79000, loss: 0.003360
 >> iter 80000, loss: 0.002487
   Number of active neurons: 10
 >> iter 81000, loss: 0.002274
 >> iter 82000, loss: 0.016523
 >> iter 83000, loss: 0.009195
 >> iter 84000, loss: 0.004726
 >> iter 85000, loss: 0.002779
 >> iter 86000, loss: 0.002154
 >> iter 87000, loss: 0.007730
 >> iter 88000, loss: 0.003783
 >> iter 89000, loss: 0.002233
 >> iter 90000, loss: 0.001642
   Number of active neurons: 10
 >> iter 91000, loss: 0.001431
 >> iter 92000, loss: 0.001275
 >> iter 93000, loss: 0.001243
 >> iter 94000, loss: 0.001151
 >> iter 95000, loss: 0.001086
 >> iter 96000, loss: 0.001014
 >> iter 97000, loss: 0.001008
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.837902
 >> iter 2000, loss: 8.716428
 >> iter 3000, loss: 3.882984
 >> iter 4000, loss: 1.738000
 >> iter 5000, loss: 0.788487
 >> iter 6000, loss: 0.515273
 >> iter 7000, loss: 0.304160
 >> iter 8000, loss: 0.181418
 >> iter 9000, loss: 0.135006
 >> iter 10000, loss: 0.061280
   Number of active neurons: 10
 >> iter 11000, loss: 0.049726
 >> iter 12000, loss: 0.041217
 >> iter 13000, loss: 0.055985
 >> iter 14000, loss: 0.091264
 >> iter 15000, loss: 0.125206
 >> iter 16000, loss: 0.052707
 >> iter 17000, loss: 0.024264
 >> iter 18000, loss: 0.111287
 >> iter 19000, loss: 0.053367
 >> iter 20000, loss: 0.023251
   Number of active neurons: 10
 >> iter 21000, loss: 0.056485
 >> iter 22000, loss: 0.024885
 >> iter 23000, loss: 0.012660
 >> iter 24000, loss: 0.007205
 >> iter 25000, loss: 0.005008
 >> iter 26000, loss: 0.034424
 >> iter 27000, loss: 0.071838
 >> iter 28000, loss: 0.043999
 >> iter 29000, loss: 0.019326
 >> iter 30000, loss: 0.009284
   Number of active neurons: 10
 >> iter 31000, loss: 0.005378
 >> iter 32000, loss: 0.003695
 >> iter 33000, loss: 0.003015
 >> iter 34000, loss: 0.002571
 >> iter 35000, loss: 0.002308
 >> iter 36000, loss: 0.013112
 >> iter 37000, loss: 0.015792
 >> iter 38000, loss: 0.007864
 >> iter 39000, loss: 0.004539
 >> iter 40000, loss: 0.002919
   Number of active neurons: 10
 >> iter 41000, loss: 0.042072
 >> iter 42000, loss: 0.058175
 >> iter 43000, loss: 0.023472
 >> iter 44000, loss: 0.010243
 >> iter 45000, loss: 0.005276
 >> iter 46000, loss: 0.003261
 >> iter 47000, loss: 0.002486
 >> iter 48000, loss: 0.002093
 >> iter 49000, loss: 0.034673
 >> iter 50000, loss: 0.020305
   Number of active neurons: 10
 >> iter 51000, loss: 0.008867
 >> iter 52000, loss: 0.004450
 >> iter 53000, loss: 0.002776
 >> iter 54000, loss: 0.002022
 >> iter 55000, loss: 0.002395
 >> iter 56000, loss: 0.001930
 >> iter 57000, loss: 0.018565
 >> iter 58000, loss: 0.007888
 >> iter 59000, loss: 0.003885
 >> iter 60000, loss: 0.002313
   Number of active neurons: 10
 >> iter 61000, loss: 0.001727
 >> iter 62000, loss: 0.001423
 >> iter 63000, loss: 0.001316
 >> iter 64000, loss: 0.001184
 >> iter 65000, loss: 0.001157
 >> iter 66000, loss: 0.001089
 >> iter 67000, loss: 0.001075
 >> iter 68000, loss: 0.001017
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455180
   Number of active neurons: 0
 >> iter 1000, loss: 16.011299
 >> iter 2000, loss: 8.713425
 >> iter 3000, loss: 3.778365
 >> iter 4000, loss: 1.583302
 >> iter 5000, loss: 0.677553
 >> iter 6000, loss: 0.313509
 >> iter 7000, loss: 0.141788
 >> iter 8000, loss: 0.079931
 >> iter 9000, loss: 0.052260
 >> iter 10000, loss: 0.085452
   Number of active neurons: 10
 >> iter 11000, loss: 0.042686
 >> iter 12000, loss: 0.085003
 >> iter 13000, loss: 0.080643
 >> iter 14000, loss: 0.036129
 >> iter 15000, loss: 0.018814
 >> iter 16000, loss: 0.036729
 >> iter 17000, loss: 0.018301
 >> iter 18000, loss: 0.010553
 >> iter 19000, loss: 0.007383
 >> iter 20000, loss: 0.005688
   Number of active neurons: 10
 >> iter 21000, loss: 0.021716
 >> iter 22000, loss: 0.029119
 >> iter 23000, loss: 0.013826
 >> iter 24000, loss: 0.036382
 >> iter 25000, loss: 0.019022
 >> iter 26000, loss: 0.010970
 >> iter 27000, loss: 0.016907
 >> iter 28000, loss: 0.038518
 >> iter 29000, loss: 0.017070
 >> iter 30000, loss: 0.009000
   Number of active neurons: 10
 >> iter 31000, loss: 0.020280
 >> iter 32000, loss: 0.040951
 >> iter 33000, loss: 0.017798
 >> iter 34000, loss: 0.008805
 >> iter 35000, loss: 0.005247
 >> iter 36000, loss: 0.003834
 >> iter 37000, loss: 0.023406
 >> iter 38000, loss: 0.066077
 >> iter 39000, loss: 0.061037
 >> iter 40000, loss: 0.025167
   Number of active neurons: 10
 >> iter 41000, loss: 0.011683
 >> iter 42000, loss: 0.006601
 >> iter 43000, loss: 0.004443
 >> iter 44000, loss: 0.003346
 >> iter 45000, loss: 0.002836
 >> iter 46000, loss: 0.034550
 >> iter 47000, loss: 0.014878
 >> iter 48000, loss: 0.007454
 >> iter 49000, loss: 0.089341
 >> iter 50000, loss: 0.060868
   Number of active neurons: 10
 >> iter 51000, loss: 0.079430
 >> iter 52000, loss: 0.031963
 >> iter 53000, loss: 0.013960
 >> iter 54000, loss: 0.007149
 >> iter 55000, loss: 0.004449
 >> iter 56000, loss: 0.010370
 >> iter 57000, loss: 0.005464
 >> iter 58000, loss: 0.003494
 >> iter 59000, loss: 0.011707
 >> iter 60000, loss: 0.005821
   Number of active neurons: 10
 >> iter 61000, loss: 0.003489
 >> iter 62000, loss: 0.002563
 >> iter 63000, loss: 0.002200
 >> iter 64000, loss: 0.001943
 >> iter 65000, loss: 0.001848
 >> iter 66000, loss: 0.001789
 >> iter 67000, loss: 0.001680
 >> iter 68000, loss: 0.001596
 >> iter 69000, loss: 0.001646
 >> iter 70000, loss: 0.001616
   Number of active neurons: 10
 >> iter 71000, loss: 0.001504
 >> iter 72000, loss: 0.057818
 >> iter 73000, loss: 0.023034
 >> iter 74000, loss: 0.009900
 >> iter 75000, loss: 0.004840
 >> iter 76000, loss: 0.002955
 >> iter 77000, loss: 0.002168
 >> iter 78000, loss: 0.001847
 >> iter 79000, loss: 0.001678
 >> iter 80000, loss: 0.001523
   Number of active neurons: 10
 >> iter 81000, loss: 0.001467
 >> iter 82000, loss: 0.001384
 >> iter 83000, loss: 0.005583
 >> iter 84000, loss: 0.025928
 >> iter 85000, loss: 0.010812
 >> iter 86000, loss: 0.005055
 >> iter 87000, loss: 0.028058
 >> iter 88000, loss: 0.014009
 >> iter 89000, loss: 0.006679
 >> iter 90000, loss: 0.003513
   Number of active neurons: 10
 >> iter 91000, loss: 0.002241
 >> iter 92000, loss: 0.001713
 >> iter 93000, loss: 0.001523
 >> iter 94000, loss: 0.001407
 >> iter 95000, loss: 0.001341
 >> iter 96000, loss: 0.001257
 >> iter 97000, loss: 0.001195
 >> iter 98000, loss: 0.001155
 >> iter 99000, loss: 0.001431
 >> iter 100000, loss: 0.001264
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.904693
 >> iter 2000, loss: 8.632721
 >> iter 3000, loss: 3.739336
 >> iter 4000, loss: 1.518373
 >> iter 5000, loss: 0.719417
 >> iter 6000, loss: 0.290422
 >> iter 7000, loss: 0.155706
 >> iter 8000, loss: 0.125347
 >> iter 9000, loss: 0.075372
 >> iter 10000, loss: 0.037427
   Number of active neurons: 10
 >> iter 11000, loss: 0.026046
 >> iter 12000, loss: 0.118695
 >> iter 13000, loss: 0.056043
 >> iter 14000, loss: 0.099062
 >> iter 15000, loss: 0.044612
 >> iter 16000, loss: 0.094310
 >> iter 17000, loss: 0.091973
 >> iter 18000, loss: 0.039050
 >> iter 19000, loss: 0.018751
 >> iter 20000, loss: 0.055866
   Number of active neurons: 10
 >> iter 21000, loss: 0.074049
 >> iter 22000, loss: 0.034524
 >> iter 23000, loss: 0.016541
 >> iter 24000, loss: 0.056372
 >> iter 25000, loss: 0.024988
 >> iter 26000, loss: 0.012156
 >> iter 27000, loss: 0.007276
 >> iter 28000, loss: 0.005654
 >> iter 29000, loss: 0.040956
 >> iter 30000, loss: 0.017657
   Number of active neurons: 10
 >> iter 31000, loss: 0.040139
 >> iter 32000, loss: 0.054058
 >> iter 33000, loss: 0.093559
 >> iter 34000, loss: 0.041167
 >> iter 35000, loss: 0.017950
 >> iter 36000, loss: 0.009208
 >> iter 37000, loss: 0.005530
 >> iter 38000, loss: 0.004937
 >> iter 39000, loss: 0.016196
 >> iter 40000, loss: 0.008283
   Number of active neurons: 10
 >> iter 41000, loss: 0.005249
 >> iter 42000, loss: 0.012272
 >> iter 43000, loss: 0.006383
 >> iter 44000, loss: 0.003923
 >> iter 45000, loss: 0.002980
 >> iter 46000, loss: 0.002596
 >> iter 47000, loss: 0.002461
 >> iter 48000, loss: 0.002114
 >> iter 49000, loss: 0.002005
 >> iter 50000, loss: 0.035881
   Number of active neurons: 10
 >> iter 51000, loss: 0.014889
 >> iter 52000, loss: 0.006915
 >> iter 53000, loss: 0.004061
 >> iter 54000, loss: 0.002812
 >> iter 55000, loss: 0.002322
 >> iter 56000, loss: 0.002024
 >> iter 57000, loss: 0.001884
 >> iter 58000, loss: 0.001718
 >> iter 59000, loss: 0.001676
 >> iter 60000, loss: 0.021569
   Number of active neurons: 10
 >> iter 61000, loss: 0.027952
 >> iter 62000, loss: 0.013964
 >> iter 63000, loss: 0.006652
 >> iter 64000, loss: 0.003686
 >> iter 65000, loss: 0.002438
 >> iter 66000, loss: 0.002068
 >> iter 67000, loss: 0.001799
 >> iter 68000, loss: 0.001536
 >> iter 69000, loss: 0.001485
 >> iter 70000, loss: 0.001420
   Number of active neurons: 10
 >> iter 71000, loss: 0.001348
 >> iter 72000, loss: 0.001284
 >> iter 73000, loss: 0.001320
 >> iter 74000, loss: 0.001247
 >> iter 75000, loss: 0.001237
 >> iter 76000, loss: 0.001195
 >> iter 77000, loss: 0.001253
 >> iter 78000, loss: 0.001249
 >> iter 79000, loss: 0.001193
 >> iter 80000, loss: 0.001097
   Number of active neurons: 10
 >> iter 81000, loss: 0.001314
 >> iter 82000, loss: 0.002538
 >> iter 83000, loss: 0.035315
 >> iter 84000, loss: 0.016959
 >> iter 85000, loss: 0.011702
 >> iter 86000, loss: 0.080130
 >> iter 87000, loss: 0.031642
 >> iter 88000, loss: 0.012898
 >> iter 89000, loss: 0.006019
 >> iter 90000, loss: 0.003322
   Number of active neurons: 10
 >> iter 91000, loss: 0.002258
 >> iter 92000, loss: 0.001724
 >> iter 93000, loss: 0.022540
 >> iter 94000, loss: 0.009652
 >> iter 95000, loss: 0.004681
 >> iter 96000, loss: 0.002756
 >> iter 97000, loss: 0.001996
 >> iter 98000, loss: 0.001768
 >> iter 99000, loss: 0.001481
 >> iter 100000, loss: 0.001311
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.441262
 >> iter 2000, loss: 8.911836
 >> iter 3000, loss: 3.964602
 >> iter 4000, loss: 1.603507
 >> iter 5000, loss: 0.627913
 >> iter 6000, loss: 0.275144
 >> iter 7000, loss: 0.166000
 >> iter 8000, loss: 0.072993
 >> iter 9000, loss: 0.056322
 >> iter 10000, loss: 0.028719
   Number of active neurons: 10
 >> iter 11000, loss: 0.017305
 >> iter 12000, loss: 0.017540
 >> iter 13000, loss: 0.011548
 >> iter 14000, loss: 0.028778
 >> iter 15000, loss: 0.015777
 >> iter 16000, loss: 0.012378
 >> iter 17000, loss: 0.008470
 >> iter 18000, loss: 0.006372
 >> iter 19000, loss: 0.028538
 >> iter 20000, loss: 0.013617
   Number of active neurons: 10
 >> iter 21000, loss: 0.007736
 >> iter 22000, loss: 0.005305
 >> iter 23000, loss: 0.004339
 >> iter 24000, loss: 0.003660
 >> iter 25000, loss: 0.003427
 >> iter 26000, loss: 0.003120
 >> iter 27000, loss: 0.003046
 >> iter 28000, loss: 0.002819
 >> iter 29000, loss: 0.002669
 >> iter 30000, loss: 0.025413
   Number of active neurons: 10
 >> iter 31000, loss: 0.078775
 >> iter 32000, loss: 0.096367
 >> iter 33000, loss: 0.060479
 >> iter 34000, loss: 0.024858
 >> iter 35000, loss: 0.011549
 >> iter 36000, loss: 0.007006
 >> iter 37000, loss: 0.089908
 >> iter 38000, loss: 0.076545
 >> iter 39000, loss: 0.030749
 >> iter 40000, loss: 0.013524
   Number of active neurons: 10
 >> iter 41000, loss: 0.007091
 >> iter 42000, loss: 0.019803
 >> iter 43000, loss: 0.014527
 >> iter 44000, loss: 0.018222
 >> iter 45000, loss: 0.072166
 >> iter 46000, loss: 0.029339
 >> iter 47000, loss: 0.013292
 >> iter 48000, loss: 0.007135
 >> iter 49000, loss: 0.004711
 >> iter 50000, loss: 0.003647
   Number of active neurons: 10
 >> iter 51000, loss: 0.003167
 >> iter 52000, loss: 0.002860
 >> iter 53000, loss: 0.002661
 >> iter 54000, loss: 0.002495
 >> iter 55000, loss: 0.002383
 >> iter 56000, loss: 0.002259
 >> iter 57000, loss: 0.002155
 >> iter 58000, loss: 0.002050
 >> iter 59000, loss: 0.001981
 >> iter 60000, loss: 0.001889
   Number of active neurons: 10
 >> iter 61000, loss: 0.001835
 >> iter 62000, loss: 0.001883
 >> iter 63000, loss: 0.001766
 >> iter 64000, loss: 0.001777
 >> iter 65000, loss: 0.001687
 >> iter 66000, loss: 0.001608
 >> iter 67000, loss: 0.002512
 >> iter 68000, loss: 0.010806
 >> iter 69000, loss: 0.005157
 >> iter 70000, loss: 0.002973
   Number of active neurons: 10
 >> iter 71000, loss: 0.002034
 >> iter 72000, loss: 0.001636
 >> iter 73000, loss: 0.001479
 >> iter 74000, loss: 0.001388
 >> iter 75000, loss: 0.001297
 >> iter 76000, loss: 0.001228
 >> iter 77000, loss: 0.001222
 >> iter 78000, loss: 0.001168
 >> iter 79000, loss: 0.001150
 >> iter 80000, loss: 0.021283
   Number of active neurons: 10
 >> iter 81000, loss: 0.008582
 >> iter 82000, loss: 0.039748
 >> iter 83000, loss: 0.015633
 >> iter 84000, loss: 0.006608
 >> iter 85000, loss: 0.003277
 >> iter 86000, loss: 0.001982
 >> iter 87000, loss: 0.001488
 >> iter 88000, loss: 0.001268
 >> iter 89000, loss: 0.001175
 >> iter 90000, loss: 0.001114
   Number of active neurons: 10
 >> iter 91000, loss: 0.001077
 >> iter 92000, loss: 0.001042
 >> iter 93000, loss: 0.001020
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.260049
 >> iter 2000, loss: 9.098008
 >> iter 3000, loss: 4.464857
 >> iter 4000, loss: 2.066274
 >> iter 5000, loss: 1.017809
 >> iter 6000, loss: 0.516991
 >> iter 7000, loss: 0.236672
 >> iter 8000, loss: 0.128142
 >> iter 9000, loss: 0.165091
 >> iter 10000, loss: 0.179693
   Number of active neurons: 10
 >> iter 11000, loss: 0.153746
 >> iter 12000, loss: 0.208444
 >> iter 13000, loss: 0.239149
 >> iter 14000, loss: 0.124249
 >> iter 15000, loss: 0.088529
 >> iter 16000, loss: 0.037833
 >> iter 17000, loss: 0.026237
 >> iter 18000, loss: 0.028932
 >> iter 19000, loss: 0.013770
 >> iter 20000, loss: 0.007539
   Number of active neurons: 10
 >> iter 21000, loss: 0.004936
 >> iter 22000, loss: 0.003929
 >> iter 23000, loss: 0.047367
 >> iter 24000, loss: 0.019928
 >> iter 25000, loss: 0.022139
 >> iter 26000, loss: 0.234897
 >> iter 27000, loss: 0.091952
 >> iter 28000, loss: 0.036739
 >> iter 29000, loss: 0.054632
 >> iter 30000, loss: 0.045617
   Number of active neurons: 10
 >> iter 31000, loss: 0.030868
 >> iter 32000, loss: 0.013925
 >> iter 33000, loss: 0.038716
 >> iter 34000, loss: 0.030612
 >> iter 35000, loss: 0.060815
 >> iter 36000, loss: 0.025099
 >> iter 37000, loss: 0.011299
 >> iter 38000, loss: 0.021210
 >> iter 39000, loss: 0.009673
 >> iter 40000, loss: 0.005422
   Number of active neurons: 10
 >> iter 41000, loss: 0.003479
 >> iter 42000, loss: 0.003465
 >> iter 43000, loss: 0.035321
 >> iter 44000, loss: 0.071707
 >> iter 45000, loss: 0.049788
 >> iter 46000, loss: 0.020171
 >> iter 47000, loss: 0.009009
 >> iter 48000, loss: 0.021355
 >> iter 49000, loss: 0.009409
 >> iter 50000, loss: 0.032795
   Number of active neurons: 10
 >> iter 51000, loss: 0.023361
 >> iter 52000, loss: 0.038052
 >> iter 53000, loss: 0.119082
 >> iter 54000, loss: 0.050846
 >> iter 55000, loss: 0.021154
 >> iter 56000, loss: 0.014865
 >> iter 57000, loss: 0.007476
 >> iter 58000, loss: 0.004111
 >> iter 59000, loss: 0.002744
 >> iter 60000, loss: 0.006684
   Number of active neurons: 10
 >> iter 61000, loss: 0.003788
 >> iter 62000, loss: 0.013177
 >> iter 63000, loss: 0.011521
 >> iter 64000, loss: 0.012360
 >> iter 65000, loss: 0.027634
 >> iter 66000, loss: 0.011728
 >> iter 67000, loss: 0.005531
 >> iter 68000, loss: 0.003064
 >> iter 69000, loss: 0.002209
 >> iter 70000, loss: 0.073840
   Number of active neurons: 10
 >> iter 71000, loss: 0.029406
 >> iter 72000, loss: 0.012287
 >> iter 73000, loss: 0.009149
 >> iter 74000, loss: 0.135580
 >> iter 75000, loss: 0.053398
 >> iter 76000, loss: 0.021874
 >> iter 77000, loss: 0.034860
 >> iter 78000, loss: 0.022790
 >> iter 79000, loss: 0.011330
 >> iter 80000, loss: 0.009581
   Number of active neurons: 10
 >> iter 81000, loss: 0.004919
 >> iter 82000, loss: 0.029078
 >> iter 83000, loss: 0.012347
 >> iter 84000, loss: 0.005915
 >> iter 85000, loss: 0.003444
 >> iter 86000, loss: 0.002832
 >> iter 87000, loss: 0.002038
 >> iter 88000, loss: 0.001737
 >> iter 89000, loss: 0.028389
 >> iter 90000, loss: 0.011607
   Number of active neurons: 10
 >> iter 91000, loss: 0.005259
 >> iter 92000, loss: 0.002837
 >> iter 93000, loss: 0.001874
 >> iter 94000, loss: 0.001442
 >> iter 95000, loss: 0.001254
 >> iter 96000, loss: 0.001121
 >> iter 97000, loss: 0.001065
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.064223
 >> iter 2000, loss: 9.486966
 >> iter 3000, loss: 4.385477
 >> iter 4000, loss: 1.861323
 >> iter 5000, loss: 0.710616
 >> iter 6000, loss: 0.365351
 >> iter 7000, loss: 0.149040
 >> iter 8000, loss: 0.092359
 >> iter 9000, loss: 0.075438
 >> iter 10000, loss: 0.033593
   Number of active neurons: 10
 >> iter 11000, loss: 0.016444
 >> iter 12000, loss: 0.147093
 >> iter 13000, loss: 0.062154
 >> iter 14000, loss: 0.027168
 >> iter 15000, loss: 0.013579
 >> iter 16000, loss: 0.007799
 >> iter 17000, loss: 0.005483
 >> iter 18000, loss: 0.004150
 >> iter 19000, loss: 0.003608
 >> iter 20000, loss: 0.002988
   Number of active neurons: 10
 >> iter 21000, loss: 0.002871
 >> iter 22000, loss: 0.002699
 >> iter 23000, loss: 0.002464
 >> iter 24000, loss: 0.027586
 >> iter 25000, loss: 0.011898
 >> iter 26000, loss: 0.005848
 >> iter 27000, loss: 0.003621
 >> iter 28000, loss: 0.002619
 >> iter 29000, loss: 0.012384
 >> iter 30000, loss: 0.051135
   Number of active neurons: 10
 >> iter 31000, loss: 0.060477
 >> iter 32000, loss: 0.031566
 >> iter 33000, loss: 0.013860
 >> iter 34000, loss: 0.006733
 >> iter 35000, loss: 0.003932
 >> iter 36000, loss: 0.002876
 >> iter 37000, loss: 0.002352
 >> iter 38000, loss: 0.002097
 >> iter 39000, loss: 0.001871
 >> iter 40000, loss: 0.001726
   Number of active neurons: 10
 >> iter 41000, loss: 0.003295
 >> iter 42000, loss: 0.002275
 >> iter 43000, loss: 0.042516
 >> iter 44000, loss: 0.016811
 >> iter 45000, loss: 0.007744
 >> iter 46000, loss: 0.003794
 >> iter 47000, loss: 0.002233
 >> iter 48000, loss: 0.001722
 >> iter 49000, loss: 0.019963
 >> iter 50000, loss: 0.008343
   Number of active neurons: 10
 >> iter 51000, loss: 0.003912
 >> iter 52000, loss: 0.002182
 >> iter 53000, loss: 0.013247
 >> iter 54000, loss: 0.005940
 >> iter 55000, loss: 0.003224
 >> iter 56000, loss: 0.001949
 >> iter 57000, loss: 0.001382
 >> iter 58000, loss: 0.021741
 >> iter 59000, loss: 0.009057
 >> iter 60000, loss: 0.004222
   Number of active neurons: 10
 >> iter 61000, loss: 0.002413
 >> iter 62000, loss: 0.001576
 >> iter 63000, loss: 0.001253
 >> iter 64000, loss: 0.001066
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.519312
 >> iter 2000, loss: 9.243848
 >> iter 3000, loss: 4.443580
 >> iter 4000, loss: 1.796314
 >> iter 5000, loss: 0.804338
 >> iter 6000, loss: 0.425767
 >> iter 7000, loss: 0.323731
 >> iter 8000, loss: 0.139057
 >> iter 9000, loss: 0.060702
 >> iter 10000, loss: 0.072711
   Number of active neurons: 10
 >> iter 11000, loss: 0.032628
 >> iter 12000, loss: 0.055052
 >> iter 13000, loss: 0.084527
 >> iter 14000, loss: 0.035713
 >> iter 15000, loss: 0.016860
 >> iter 16000, loss: 0.009245
 >> iter 17000, loss: 0.006135
 >> iter 18000, loss: 0.166883
 >> iter 19000, loss: 0.067299
 >> iter 20000, loss: 0.029086
   Number of active neurons: 10
 >> iter 21000, loss: 0.014231
 >> iter 22000, loss: 0.008032
 >> iter 23000, loss: 0.005506
 >> iter 24000, loss: 0.004158
 >> iter 25000, loss: 0.003486
 >> iter 26000, loss: 0.002954
 >> iter 27000, loss: 0.013786
 >> iter 28000, loss: 0.017125
 >> iter 29000, loss: 0.008088
 >> iter 30000, loss: 0.004480
   Number of active neurons: 10
 >> iter 31000, loss: 0.003059
 >> iter 32000, loss: 0.013573
 >> iter 33000, loss: 0.006683
 >> iter 34000, loss: 0.003763
 >> iter 35000, loss: 0.002695
 >> iter 36000, loss: 0.002149
 >> iter 37000, loss: 0.002056
 >> iter 38000, loss: 0.001769
 >> iter 39000, loss: 0.001692
 >> iter 40000, loss: 0.001549
   Number of active neurons: 10
 >> iter 41000, loss: 0.022425
 >> iter 42000, loss: 0.009383
 >> iter 43000, loss: 0.004514
 >> iter 44000, loss: 0.043118
 >> iter 45000, loss: 0.119720
 >> iter 46000, loss: 0.090158
 >> iter 47000, loss: 0.043676
 >> iter 48000, loss: 0.018284
 >> iter 49000, loss: 0.008645
 >> iter 50000, loss: 0.004607
   Number of active neurons: 10
 >> iter 51000, loss: 0.002961
 >> iter 52000, loss: 0.002370
 >> iter 53000, loss: 0.002034
 >> iter 54000, loss: 0.001971
 >> iter 55000, loss: 0.001711
 >> iter 56000, loss: 0.001491
 >> iter 57000, loss: 0.017700
 >> iter 58000, loss: 0.007609
 >> iter 59000, loss: 0.030759
 >> iter 60000, loss: 0.018620
   Number of active neurons: 10
 >> iter 61000, loss: 0.030497
 >> iter 62000, loss: 0.012584
 >> iter 63000, loss: 0.005729
 >> iter 64000, loss: 0.003066
 >> iter 65000, loss: 0.002066
 >> iter 66000, loss: 0.001614
 >> iter 67000, loss: 0.001388
 >> iter 68000, loss: 0.001293
 >> iter 69000, loss: 0.001207
 >> iter 70000, loss: 0.001129
   Number of active neurons: 10
 >> iter 71000, loss: 0.001089
 >> iter 72000, loss: 0.001062
 >> iter 73000, loss: 0.001031
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.720400
 >> iter 2000, loss: 9.529395
 >> iter 3000, loss: 4.791665
 >> iter 4000, loss: 1.897532
 >> iter 5000, loss: 0.717684
 >> iter 6000, loss: 0.302867
 >> iter 7000, loss: 0.172626
 >> iter 8000, loss: 0.070900
 >> iter 9000, loss: 0.038420
 >> iter 10000, loss: 0.019122
   Number of active neurons: 10
 >> iter 11000, loss: 0.035016
 >> iter 12000, loss: 0.083730
 >> iter 13000, loss: 0.035769
 >> iter 14000, loss: 0.016550
 >> iter 15000, loss: 0.008847
 >> iter 16000, loss: 0.005590
 >> iter 17000, loss: 0.005103
 >> iter 18000, loss: 0.003992
 >> iter 19000, loss: 0.006851
 >> iter 20000, loss: 0.004880
   Number of active neurons: 10
 >> iter 21000, loss: 0.008504
 >> iter 22000, loss: 0.004727
 >> iter 23000, loss: 0.004067
 >> iter 24000, loss: 0.002829
 >> iter 25000, loss: 0.002251
 >> iter 26000, loss: 0.001842
 >> iter 27000, loss: 0.001718
 >> iter 28000, loss: 0.001758
 >> iter 29000, loss: 0.001587
 >> iter 30000, loss: 0.001445
   Number of active neurons: 10
 >> iter 31000, loss: 0.009920
 >> iter 32000, loss: 0.005737
 >> iter 33000, loss: 0.003173
 >> iter 34000, loss: 0.001991
 >> iter 35000, loss: 0.001510
 >> iter 36000, loss: 0.001278
 >> iter 37000, loss: 0.001230
 >> iter 38000, loss: 0.001111
 >> iter 39000, loss: 0.001066
 >> iter 40000, loss: 0.001032
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.134327
 >> iter 2000, loss: 8.842537
 >> iter 3000, loss: 3.754499
 >> iter 4000, loss: 1.581375
 >> iter 5000, loss: 0.639299
 >> iter 6000, loss: 0.278290
 >> iter 7000, loss: 0.111763
 >> iter 8000, loss: 0.047502
 >> iter 9000, loss: 0.040510
 >> iter 10000, loss: 0.176524
   Number of active neurons: 10
 >> iter 11000, loss: 0.134810
 >> iter 12000, loss: 0.067567
 >> iter 13000, loss: 0.041907
 >> iter 14000, loss: 0.020468
 >> iter 15000, loss: 0.039386
 >> iter 16000, loss: 0.033487
 >> iter 17000, loss: 0.052303
 >> iter 18000, loss: 0.055704
 >> iter 19000, loss: 0.062428
 >> iter 20000, loss: 0.026119
   Number of active neurons: 10
 >> iter 21000, loss: 0.012289
 >> iter 22000, loss: 0.031243
 >> iter 23000, loss: 0.052406
 >> iter 24000, loss: 0.021806
 >> iter 25000, loss: 0.010750
 >> iter 26000, loss: 0.005771
 >> iter 27000, loss: 0.003905
 >> iter 28000, loss: 0.046249
 >> iter 29000, loss: 0.019000
 >> iter 30000, loss: 0.044619
   Number of active neurons: 10
 >> iter 31000, loss: 0.037896
 >> iter 32000, loss: 0.055211
 >> iter 33000, loss: 0.045365
 >> iter 34000, loss: 0.039268
 >> iter 35000, loss: 0.026423
 >> iter 36000, loss: 0.011644
 >> iter 37000, loss: 0.005811
 >> iter 38000, loss: 0.003520
 >> iter 39000, loss: 0.034757
 >> iter 40000, loss: 0.014667
   Number of active neurons: 10
 >> iter 41000, loss: 0.010777
 >> iter 42000, loss: 0.005367
 >> iter 43000, loss: 0.003269
 >> iter 44000, loss: 0.002317
 >> iter 45000, loss: 0.001917
 >> iter 46000, loss: 0.001826
 >> iter 47000, loss: 0.001696
 >> iter 48000, loss: 0.001535
 >> iter 49000, loss: 0.001470
 >> iter 50000, loss: 0.001353
   Number of active neurons: 10
 >> iter 51000, loss: 0.001312
 >> iter 52000, loss: 0.001208
 >> iter 53000, loss: 0.001233
 >> iter 54000, loss: 0.001183
 >> iter 55000, loss: 0.001143
 >> iter 56000, loss: 0.001099
 >> iter 57000, loss: 0.001066
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.092155
 >> iter 2000, loss: 8.502057
 >> iter 3000, loss: 3.605902
 >> iter 4000, loss: 1.567272
 >> iter 5000, loss: 0.715796
 >> iter 6000, loss: 0.293306
 >> iter 7000, loss: 0.173309
 >> iter 8000, loss: 0.107424
 >> iter 9000, loss: 0.057310
 >> iter 10000, loss: 0.041272
   Number of active neurons: 10
 >> iter 11000, loss: 0.046910
 >> iter 12000, loss: 0.024055
 >> iter 13000, loss: 0.039826
 >> iter 14000, loss: 0.018860
 >> iter 15000, loss: 0.040568
 >> iter 16000, loss: 0.018309
 >> iter 17000, loss: 0.018780
 >> iter 18000, loss: 0.010752
 >> iter 19000, loss: 0.014183
 >> iter 20000, loss: 0.007364
   Number of active neurons: 10
 >> iter 21000, loss: 0.005124
 >> iter 22000, loss: 0.062845
 >> iter 23000, loss: 0.026403
 >> iter 24000, loss: 0.016395
 >> iter 25000, loss: 0.008264
 >> iter 26000, loss: 0.004897
 >> iter 27000, loss: 0.003576
 >> iter 28000, loss: 0.002770
 >> iter 29000, loss: 0.002609
 >> iter 30000, loss: 0.002306
   Number of active neurons: 10
 >> iter 31000, loss: 0.002042
 >> iter 32000, loss: 0.001913
 >> iter 33000, loss: 0.001827
 >> iter 34000, loss: 0.001638
 >> iter 35000, loss: 0.001608
 >> iter 36000, loss: 0.001462
 >> iter 37000, loss: 0.010473
 >> iter 38000, loss: 0.004784
 >> iter 39000, loss: 0.015822
 >> iter 40000, loss: 0.008509
   Number of active neurons: 10
 >> iter 41000, loss: 0.024042
 >> iter 42000, loss: 0.019115
 >> iter 43000, loss: 0.015325
 >> iter 44000, loss: 0.052463
 >> iter 45000, loss: 0.021270
 >> iter 46000, loss: 0.008848
 >> iter 47000, loss: 0.004269
 >> iter 48000, loss: 0.002463
 >> iter 49000, loss: 0.024724
 >> iter 50000, loss: 0.010691
   Number of active neurons: 10
 >> iter 51000, loss: 0.005056
 >> iter 52000, loss: 0.002835
 >> iter 53000, loss: 0.002675
 >> iter 54000, loss: 0.002130
 >> iter 55000, loss: 0.001640
 >> iter 56000, loss: 0.020284
 >> iter 57000, loss: 0.008808
 >> iter 58000, loss: 0.004873
 >> iter 59000, loss: 0.002551
 >> iter 60000, loss: 0.001596
   Number of active neurons: 10
 >> iter 61000, loss: 0.001253
 >> iter 62000, loss: 0.001023
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.051472
 >> iter 2000, loss: 8.367091
 >> iter 3000, loss: 3.430852
 >> iter 4000, loss: 1.332185
 >> iter 5000, loss: 0.571079
 >> iter 6000, loss: 0.222375
 >> iter 7000, loss: 0.134627
 >> iter 8000, loss: 0.090187
 >> iter 9000, loss: 0.073219
 >> iter 10000, loss: 0.032351
   Number of active neurons: 10
 >> iter 11000, loss: 0.049954
 >> iter 12000, loss: 0.022569
 >> iter 13000, loss: 0.036591
 >> iter 14000, loss: 0.046605
 >> iter 15000, loss: 0.029149
 >> iter 16000, loss: 0.014738
 >> iter 17000, loss: 0.008401
 >> iter 18000, loss: 0.005429
 >> iter 19000, loss: 0.004127
 >> iter 20000, loss: 0.003347
   Number of active neurons: 10
 >> iter 21000, loss: 0.002945
 >> iter 22000, loss: 0.002652
 >> iter 23000, loss: 0.002503
 >> iter 24000, loss: 0.002229
 >> iter 25000, loss: 0.002355
 >> iter 26000, loss: 0.002081
 >> iter 27000, loss: 0.001955
 >> iter 28000, loss: 0.001778
 >> iter 29000, loss: 0.001742
 >> iter 30000, loss: 0.008931
   Number of active neurons: 10
 >> iter 31000, loss: 0.004435
 >> iter 32000, loss: 0.002710
 >> iter 33000, loss: 0.002036
 >> iter 34000, loss: 0.001695
 >> iter 35000, loss: 0.001490
 >> iter 36000, loss: 0.001347
 >> iter 37000, loss: 0.001372
 >> iter 38000, loss: 0.001250
 >> iter 39000, loss: 0.001226
 >> iter 40000, loss: 0.001139
   Number of active neurons: 10
 >> iter 41000, loss: 0.001144
 >> iter 42000, loss: 0.001068
 >> iter 43000, loss: 0.001050
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.456064
 >> iter 2000, loss: 8.427628
 >> iter 3000, loss: 3.697085
 >> iter 4000, loss: 1.643727
 >> iter 5000, loss: 0.701352
 >> iter 6000, loss: 0.398720
 >> iter 7000, loss: 0.157869
 >> iter 8000, loss: 0.154300
 >> iter 9000, loss: 0.079385
 >> iter 10000, loss: 0.051898
   Number of active neurons: 10
 >> iter 11000, loss: 0.037083
 >> iter 12000, loss: 0.019780
 >> iter 13000, loss: 0.010773
 >> iter 14000, loss: 0.042605
 >> iter 15000, loss: 0.028391
 >> iter 16000, loss: 0.013182
 >> iter 17000, loss: 0.006821
 >> iter 18000, loss: 0.004084
 >> iter 19000, loss: 0.002998
 >> iter 20000, loss: 0.002406
   Number of active neurons: 10
 >> iter 21000, loss: 0.002105
 >> iter 22000, loss: 0.010699
 >> iter 23000, loss: 0.005041
 >> iter 24000, loss: 0.002788
 >> iter 25000, loss: 0.001924
 >> iter 26000, loss: 0.001521
 >> iter 27000, loss: 0.001333
 >> iter 28000, loss: 0.001224
 >> iter 29000, loss: 0.001156
 >> iter 30000, loss: 0.001066
   Number of active neurons: 10
 >> iter 31000, loss: 0.001025
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

