 > Problema: tomita6nueva
 > Args:
   - Hidden size: 12
   - Noise level: 0.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.603489
 >> iter 2000, loss: 15.091319
 >> iter 3000, loss: 13.760773
 >> iter 4000, loss: 13.264554
 >> iter 5000, loss: 13.061491
 >> iter 6000, loss: 12.989760
 >> iter 7000, loss: 12.950497
 >> iter 8000, loss: 12.944660
 >> iter 9000, loss: 12.930552
 >> iter 10000, loss: 12.937089
   Number of active neurons: 4
 >> iter 11000, loss: 12.925280
 >> iter 12000, loss: 12.924267
 >> iter 13000, loss: 12.418553
 >> iter 14000, loss: 5.215847
 >> iter 15000, loss: 1.968361
 >> iter 16000, loss: 0.745538
 >> iter 17000, loss: 0.289048
 >> iter 18000, loss: 0.117642
 >> iter 19000, loss: 0.052413
 >> iter 20000, loss: 0.026934
   Number of active neurons: 12
 >> iter 21000, loss: 0.016465
 >> iter 22000, loss: 0.011804
 >> iter 23000, loss: 0.009426
 >> iter 24000, loss: 0.008051
 >> iter 25000, loss: 0.007099
 >> iter 26000, loss: 0.006409
 >> iter 27000, loss: 0.005837
 >> iter 28000, loss: 0.005384
 >> iter 29000, loss: 0.004979
 >> iter 30000, loss: 0.004647
   Number of active neurons: 12
 >> iter 31000, loss: 0.004338
 >> iter 32000, loss: 0.004083
 >> iter 33000, loss: 0.003841
 >> iter 34000, loss: 0.003638
 >> iter 35000, loss: 0.003442
 >> iter 36000, loss: 0.003278
 >> iter 37000, loss: 0.003115
 >> iter 38000, loss: 0.002981
 >> iter 39000, loss: 0.002845
 >> iter 40000, loss: 0.002733
   Number of active neurons: 12
 >> iter 41000, loss: 0.002616
 >> iter 42000, loss: 0.002520
 >> iter 43000, loss: 0.002419
 >> iter 44000, loss: 0.002337
 >> iter 45000, loss: 0.002250
 >> iter 46000, loss: 0.002179
 >> iter 47000, loss: 0.002102
 >> iter 48000, loss: 0.002040
 >> iter 49000, loss: 0.001971
 >> iter 50000, loss: 0.001917
   Number of active neurons: 12
 >> iter 51000, loss: 0.001855
 >> iter 52000, loss: 0.001807
 >> iter 53000, loss: 0.001751
 >> iter 54000, loss: 0.001709
 >> iter 55000, loss: 0.001658
 >> iter 56000, loss: 0.001621
 >> iter 57000, loss: 0.001574
 >> iter 58000, loss: 0.001541
 >> iter 59000, loss: 0.001498
 >> iter 60000, loss: 0.001469
   Number of active neurons: 12
 >> iter 61000, loss: 0.001429
 >> iter 62000, loss: 0.001402
 >> iter 63000, loss: 0.001365
 >> iter 64000, loss: 0.001341
 >> iter 65000, loss: 0.001307
 >> iter 66000, loss: 0.001285
 >> iter 67000, loss: 0.001254
 >> iter 68000, loss: 0.001233
 >> iter 69000, loss: 0.001205
 >> iter 70000, loss: 0.001185
   Number of active neurons: 12
 >> iter 71000, loss: 0.001159
 >> iter 72000, loss: 0.001141
 >> iter 73000, loss: 0.001116
 >> iter 74000, loss: 0.001100
 >> iter 75000, loss: 0.001076
 >> iter 76000, loss: 0.001061
 >> iter 77000, loss: 0.001039
 >> iter 78000, loss: 0.001026
 >> iter 79000, loss: 0.001004
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.618082
 >> iter 2000, loss: 15.113342
 >> iter 3000, loss: 13.783694
 >> iter 4000, loss: 13.286372
 >> iter 5000, loss: 13.079294
 >> iter 6000, loss: 13.003216
 >> iter 7000, loss: 12.960233
 >> iter 8000, loss: 12.951674
 >> iter 9000, loss: 12.935578
 >> iter 10000, loss: 12.940339
   Number of active neurons: 5
 >> iter 11000, loss: 12.925228
 >> iter 12000, loss: 12.304343
 >> iter 13000, loss: 6.199255
 >> iter 14000, loss: 2.341649
 >> iter 15000, loss: 0.892075
 >> iter 16000, loss: 0.348485
 >> iter 17000, loss: 0.143268
 >> iter 18000, loss: 0.064602
 >> iter 19000, loss: 0.033566
 >> iter 20000, loss: 0.020640
   Number of active neurons: 12
 >> iter 21000, loss: 0.014768
 >> iter 22000, loss: 0.011746
 >> iter 23000, loss: 0.009940
 >> iter 24000, loss: 0.008727
 >> iter 25000, loss: 0.007809
 >> iter 26000, loss: 0.007089
 >> iter 27000, loss: 0.006485
 >> iter 28000, loss: 0.005989
 >> iter 29000, loss: 0.005550
 >> iter 30000, loss: 0.005177
   Number of active neurons: 12
 >> iter 31000, loss: 0.004840
 >> iter 32000, loss: 0.004551
 >> iter 33000, loss: 0.004286
 >> iter 34000, loss: 0.004056
 >> iter 35000, loss: 0.003841
 >> iter 36000, loss: 0.003654
 >> iter 37000, loss: 0.003475
 >> iter 38000, loss: 0.003322
 >> iter 39000, loss: 0.003171
 >> iter 40000, loss: 0.003043
   Number of active neurons: 12
 >> iter 41000, loss: 0.002914
 >> iter 42000, loss: 0.002804
 >> iter 43000, loss: 0.002694
 >> iter 44000, loss: 0.002599
 >> iter 45000, loss: 0.002503
 >> iter 46000, loss: 0.002422
 >> iter 47000, loss: 0.002336
 >> iter 48000, loss: 0.002265
 >> iter 49000, loss: 0.002190
 >> iter 50000, loss: 0.002127
   Number of active neurons: 12
 >> iter 51000, loss: 0.002059
 >> iter 52000, loss: 0.002003
 >> iter 53000, loss: 0.001941
 >> iter 54000, loss: 0.001893
 >> iter 55000, loss: 0.001837
 >> iter 56000, loss: 0.001793
 >> iter 57000, loss: 0.001742
 >> iter 58000, loss: 0.001703
 >> iter 59000, loss: 0.001657
 >> iter 60000, loss: 0.001622
   Number of active neurons: 12
 >> iter 61000, loss: 0.001578
 >> iter 62000, loss: 0.001547
 >> iter 63000, loss: 0.001506
 >> iter 64000, loss: 0.001478
 >> iter 65000, loss: 0.001441
 >> iter 66000, loss: 0.001415
 >> iter 67000, loss: 0.001381
 >> iter 68000, loss: 0.001357
 >> iter 69000, loss: 0.001325
 >> iter 70000, loss: 0.001303
   Number of active neurons: 12
 >> iter 71000, loss: 0.001274
 >> iter 72000, loss: 0.001253
 >> iter 73000, loss: 0.001226
 >> iter 74000, loss: 0.001208
 >> iter 75000, loss: 0.001181
 >> iter 76000, loss: 0.001164
 >> iter 77000, loss: 0.001140
 >> iter 78000, loss: 0.001124
 >> iter 79000, loss: 0.001101
 >> iter 80000, loss: 0.001086
   Number of active neurons: 12
 >> iter 81000, loss: 0.001065
 >> iter 82000, loss: 0.001051
 >> iter 83000, loss: 0.001030
 >> iter 84000, loss: 0.001017
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.628480
 >> iter 2000, loss: 15.126269
 >> iter 3000, loss: 13.798896
 >> iter 4000, loss: 13.303149
 >> iter 5000, loss: 13.100350
 >> iter 6000, loss: 13.023132
 >> iter 7000, loss: 12.979879
 >> iter 8000, loss: 12.968178
 >> iter 9000, loss: 12.952413
 >> iter 10000, loss: 12.956075
   Number of active neurons: 5
 >> iter 11000, loss: 12.944125
 >> iter 12000, loss: 12.943811
 >> iter 13000, loss: 12.639114
 >> iter 14000, loss: 6.987355
 >> iter 15000, loss: 2.666412
 >> iter 16000, loss: 1.008006
 >> iter 17000, loss: 0.388042
 >> iter 18000, loss: 0.155425
 >> iter 19000, loss: 0.067206
 >> iter 20000, loss: 0.032978
   Number of active neurons: 11
 >> iter 21000, loss: 0.019138
 >> iter 22000, loss: 0.013112
 >> iter 23000, loss: 0.010175
 >> iter 24000, loss: 0.008522
 >> iter 25000, loss: 0.007447
 >> iter 26000, loss: 0.006666
 >> iter 27000, loss: 0.006054
 >> iter 28000, loss: 0.005553
 >> iter 29000, loss: 0.005131
 >> iter 30000, loss: 0.004767
   Number of active neurons: 11
 >> iter 31000, loss: 0.004451
 >> iter 32000, loss: 0.004174
 >> iter 33000, loss: 0.003929
 >> iter 34000, loss: 0.003710
 >> iter 35000, loss: 0.003513
 >> iter 36000, loss: 0.003335
 >> iter 37000, loss: 0.003174
 >> iter 38000, loss: 0.003028
 >> iter 39000, loss: 0.002894
 >> iter 40000, loss: 0.002772
   Number of active neurons: 11
 >> iter 41000, loss: 0.002658
 >> iter 42000, loss: 0.002554
 >> iter 43000, loss: 0.002457
 >> iter 44000, loss: 0.002367
 >> iter 45000, loss: 0.002284
 >> iter 46000, loss: 0.002205
 >> iter 47000, loss: 0.002132
 >> iter 48000, loss: 0.002063
 >> iter 49000, loss: 0.001999
 >> iter 50000, loss: 0.001938
   Number of active neurons: 11
 >> iter 51000, loss: 0.001881
 >> iter 52000, loss: 0.001826
 >> iter 53000, loss: 0.001775
 >> iter 54000, loss: 0.001728
 >> iter 55000, loss: 0.001681
 >> iter 56000, loss: 0.001638
 >> iter 57000, loss: 0.001596
 >> iter 58000, loss: 0.001557
 >> iter 59000, loss: 0.001519
 >> iter 60000, loss: 0.001484
   Number of active neurons: 11
 >> iter 61000, loss: 0.001448
 >> iter 62000, loss: 0.001417
 >> iter 63000, loss: 0.001384
 >> iter 64000, loss: 0.001355
 >> iter 65000, loss: 0.001325
 >> iter 66000, loss: 0.001299
 >> iter 67000, loss: 0.001271
 >> iter 68000, loss: 0.001247
 >> iter 69000, loss: 0.001221
 >> iter 70000, loss: 0.001198
   Number of active neurons: 11
 >> iter 71000, loss: 0.001175
 >> iter 72000, loss: 0.001154
 >> iter 73000, loss: 0.001132
 >> iter 74000, loss: 0.001112
 >> iter 75000, loss: 0.001092
 >> iter 76000, loss: 0.001074
 >> iter 77000, loss: 0.001055
 >> iter 78000, loss: 0.001038
 >> iter 79000, loss: 0.001020
 >> iter 80000, loss: 0.001004
   Number of active neurons: 11
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.604211
 >> iter 2000, loss: 15.083070
 >> iter 3000, loss: 13.751612
 >> iter 4000, loss: 13.257674
 >> iter 5000, loss: 13.059468
 >> iter 6000, loss: 12.989116
 >> iter 7000, loss: 12.952141
 >> iter 8000, loss: 12.945985
 >> iter 9000, loss: 12.932982
 >> iter 10000, loss: 12.938933
   Number of active neurons: 4
 >> iter 11000, loss: 12.927674
 >> iter 12000, loss: 12.926607
 >> iter 13000, loss: 12.617314
 >> iter 14000, loss: 6.757307
 >> iter 15000, loss: 2.576424
 >> iter 16000, loss: 0.979061
 >> iter 17000, loss: 0.380053
 >> iter 18000, loss: 0.154665
 >> iter 19000, loss: 0.068508
 >> iter 20000, loss: 0.034904
   Number of active neurons: 12
 >> iter 21000, loss: 0.020983
 >> iter 22000, loss: 0.014885
 >> iter 23000, loss: 0.011721
 >> iter 24000, loss: 0.009979
 >> iter 25000, loss: 0.008721
 >> iter 26000, loss: 0.007883
 >> iter 27000, loss: 0.007131
 >> iter 28000, loss: 0.006595
 >> iter 29000, loss: 0.006065
 >> iter 30000, loss: 0.005678
   Number of active neurons: 12
 >> iter 31000, loss: 0.005277
 >> iter 32000, loss: 0.004983
 >> iter 33000, loss: 0.004669
 >> iter 34000, loss: 0.004438
 >> iter 35000, loss: 0.004183
 >> iter 36000, loss: 0.003999
 >> iter 37000, loss: 0.003787
 >> iter 38000, loss: 0.003636
 >> iter 39000, loss: 0.003458
 >> iter 40000, loss: 0.003334
   Number of active neurons: 12
 >> iter 41000, loss: 0.003182
 >> iter 42000, loss: 0.003076
 >> iter 43000, loss: 0.002944
 >> iter 44000, loss: 0.002855
 >> iter 45000, loss: 0.002740
 >> iter 46000, loss: 0.002664
 >> iter 47000, loss: 0.002562
 >> iter 48000, loss: 0.002495
 >> iter 49000, loss: 0.002404
 >> iter 50000, loss: 0.002346
   Number of active neurons: 12
 >> iter 51000, loss: 0.002264
 >> iter 52000, loss: 0.002214
 >> iter 53000, loss: 0.002139
 >> iter 54000, loss: 0.002096
 >> iter 55000, loss: 0.002026
 >> iter 56000, loss: 0.001988
 >> iter 57000, loss: 0.001925
 >> iter 58000, loss: 0.001891
 >> iter 59000, loss: 0.001834
 >> iter 60000, loss: 0.001803
   Number of active neurons: 12
 >> iter 61000, loss: 0.001750
 >> iter 62000, loss: 0.001722
 >> iter 63000, loss: 0.001673
 >> iter 64000, loss: 0.001648
 >> iter 65000, loss: 0.001603
 >> iter 66000, loss: 0.001581
 >> iter 67000, loss: 0.001539
 >> iter 68000, loss: 0.001518
 >> iter 69000, loss: 0.001479
 >> iter 70000, loss: 0.001460
   Number of active neurons: 12
 >> iter 71000, loss: 0.001424
 >> iter 72000, loss: 0.001406
 >> iter 73000, loss: 0.001372
 >> iter 74000, loss: 0.001356
 >> iter 75000, loss: 0.001324
 >> iter 76000, loss: 0.001310
 >> iter 77000, loss: 0.001279
 >> iter 78000, loss: 0.001266
 >> iter 79000, loss: 0.001238
 >> iter 80000, loss: 0.001226
   Number of active neurons: 12
 >> iter 81000, loss: 0.001198
 >> iter 82000, loss: 0.001187
 >> iter 83000, loss: 0.001161
 >> iter 84000, loss: 0.001151
 >> iter 85000, loss: 0.001126
 >> iter 86000, loss: 0.001117
 >> iter 87000, loss: 0.001094
 >> iter 88000, loss: 0.001085
 >> iter 89000, loss: 0.001063
 >> iter 90000, loss: 0.001054
   Number of active neurons: 12
 >> iter 91000, loss: 0.001033
 >> iter 92000, loss: 0.001026
 >> iter 93000, loss: 0.001006
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.623484
 >> iter 2000, loss: 15.126872
 >> iter 3000, loss: 13.797244
 >> iter 4000, loss: 13.297732
 >> iter 5000, loss: 13.087003
 >> iter 6000, loss: 13.007025
 >> iter 7000, loss: 12.960189
 >> iter 8000, loss: 12.948386
 >> iter 9000, loss: 12.930183
 >> iter 10000, loss: 12.933420
   Number of active neurons: 3
 >> iter 11000, loss: 12.919199
 >> iter 12000, loss: 12.912717
 >> iter 13000, loss: 11.303396
 >> iter 14000, loss: 4.330866
 >> iter 15000, loss: 1.618819
 >> iter 16000, loss: 0.610471
 >> iter 17000, loss: 0.235138
 >> iter 18000, loss: 0.094696
 >> iter 19000, loss: 0.166338
 >> iter 20000, loss: 0.070139
   Number of active neurons: 12
 >> iter 21000, loss: 0.032524
 >> iter 22000, loss: 0.017533
 >> iter 23000, loss: 0.011156
 >> iter 24000, loss: 0.008250
 >> iter 25000, loss: 0.006678
 >> iter 26000, loss: 0.005763
 >> iter 27000, loss: 0.005093
 >> iter 28000, loss: 0.004627
 >> iter 29000, loss: 0.004214
 >> iter 30000, loss: 0.003906
   Number of active neurons: 12
 >> iter 31000, loss: 0.003609
 >> iter 32000, loss: 0.003385
 >> iter 33000, loss: 0.003159
 >> iter 34000, loss: 0.002988
 >> iter 35000, loss: 0.002808
 >> iter 36000, loss: 0.002674
 >> iter 37000, loss: 0.002526
 >> iter 38000, loss: 0.002419
 >> iter 39000, loss: 0.002296
 >> iter 40000, loss: 0.002209
   Number of active neurons: 12
 >> iter 41000, loss: 0.002104
 >> iter 42000, loss: 0.002031
 >> iter 43000, loss: 0.001941
 >> iter 44000, loss: 0.001879
 >> iter 45000, loss: 0.001801
 >> iter 46000, loss: 0.001748
 >> iter 47000, loss: 0.001679
 >> iter 48000, loss: 0.001633
 >> iter 49000, loss: 0.001573
 >> iter 50000, loss: 0.001533
   Number of active neurons: 12
 >> iter 51000, loss: 0.001479
 >> iter 52000, loss: 0.001444
 >> iter 53000, loss: 0.001394
 >> iter 54000, loss: 0.001364
 >> iter 55000, loss: 0.001319
 >> iter 56000, loss: 0.001293
 >> iter 57000, loss: 0.001252
 >> iter 58000, loss: 0.001228
 >> iter 59000, loss: 0.001192
 >> iter 60000, loss: 0.001170
   Number of active neurons: 12
 >> iter 61000, loss: 0.001136
 >> iter 62000, loss: 0.001117
 >> iter 63000, loss: 0.001085
 >> iter 64000, loss: 0.001067
 >> iter 65000, loss: 0.001039
 >> iter 66000, loss: 0.001023
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.620925
 >> iter 2000, loss: 15.113258
 >> iter 3000, loss: 13.780503
 >> iter 4000, loss: 13.282961
 >> iter 5000, loss: 13.082236
 >> iter 6000, loss: 13.011226
 >> iter 7000, loss: 12.974611
 >> iter 8000, loss: 12.968276
 >> iter 9000, loss: 12.955263
 >> iter 10000, loss: 12.959035
   Number of active neurons: 6
 >> iter 11000, loss: 12.944709
 >> iter 12000, loss: 12.853146
 >> iter 13000, loss: 8.131770
 >> iter 14000, loss: 3.065149
 >> iter 15000, loss: 1.159932
 >> iter 16000, loss: 0.447249
 >> iter 17000, loss: 0.179658
 >> iter 18000, loss: 0.078075
 >> iter 19000, loss: 0.038608
 >> iter 20000, loss: 0.022635
   Number of active neurons: 11
 >> iter 21000, loss: 0.015643
 >> iter 22000, loss: 0.012245
 >> iter 23000, loss: 0.010300
 >> iter 24000, loss: 0.009060
 >> iter 25000, loss: 0.008126
 >> iter 26000, loss: 0.007418
 >> iter 27000, loss: 0.006812
 >> iter 28000, loss: 0.006326
 >> iter 29000, loss: 0.005882
 >> iter 30000, loss: 0.005518
   Number of active neurons: 12
 >> iter 31000, loss: 0.005175
 >> iter 32000, loss: 0.004892
 >> iter 33000, loss: 0.004620
 >> iter 34000, loss: 0.004392
 >> iter 35000, loss: 0.004171
 >> iter 36000, loss: 0.003985
 >> iter 37000, loss: 0.003800
 >> iter 38000, loss: 0.003646
 >> iter 39000, loss: 0.003490
 >> iter 40000, loss: 0.003361
   Number of active neurons: 12
 >> iter 41000, loss: 0.003227
 >> iter 42000, loss: 0.003115
 >> iter 43000, loss: 0.002999
 >> iter 44000, loss: 0.002902
 >> iter 45000, loss: 0.002802
 >> iter 46000, loss: 0.002717
 >> iter 47000, loss: 0.002628
 >> iter 48000, loss: 0.002553
 >> iter 49000, loss: 0.002474
 >> iter 50000, loss: 0.002409
   Number of active neurons: 12
 >> iter 51000, loss: 0.002337
 >> iter 52000, loss: 0.002279
 >> iter 53000, loss: 0.002213
 >> iter 54000, loss: 0.002162
 >> iter 55000, loss: 0.002103
 >> iter 56000, loss: 0.002056
 >> iter 57000, loss: 0.002002
 >> iter 58000, loss: 0.001961
 >> iter 59000, loss: 0.001911
 >> iter 60000, loss: 0.001873
   Number of active neurons: 12
 >> iter 61000, loss: 0.001827
 >> iter 62000, loss: 0.001793
 >> iter 63000, loss: 0.001750
 >> iter 64000, loss: 0.001719
 >> iter 65000, loss: 0.001680
 >> iter 66000, loss: 0.001650
 >> iter 67000, loss: 0.001615
 >> iter 68000, loss: 0.001588
 >> iter 69000, loss: 0.001555
 >> iter 70000, loss: 0.001529
   Number of active neurons: 12
 >> iter 71000, loss: 0.001498
 >> iter 72000, loss: 0.001475
 >> iter 73000, loss: 0.001446
 >> iter 74000, loss: 0.001425
 >> iter 75000, loss: 0.001397
 >> iter 76000, loss: 0.001377
 >> iter 77000, loss: 0.001352
 >> iter 78000, loss: 0.001333
 >> iter 79000, loss: 0.001309
 >> iter 80000, loss: 0.001291
   Number of active neurons: 12
 >> iter 81000, loss: 0.001269
 >> iter 82000, loss: 0.001253
 >> iter 83000, loss: 0.001231
 >> iter 84000, loss: 0.001216
 >> iter 85000, loss: 0.001195
 >> iter 86000, loss: 0.001181
 >> iter 87000, loss: 0.001161
 >> iter 88000, loss: 0.001148
 >> iter 89000, loss: 0.001129
 >> iter 90000, loss: 0.001117
   Number of active neurons: 12
 >> iter 91000, loss: 0.001099
 >> iter 92000, loss: 0.001087
 >> iter 93000, loss: 0.001070
 >> iter 94000, loss: 0.001059
 >> iter 95000, loss: 0.001043
 >> iter 96000, loss: 0.001033
 >> iter 97000, loss: 0.001017
 >> iter 98000, loss: 0.001008
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.642601
 >> iter 2000, loss: 15.123213
 >> iter 3000, loss: 13.788775
 >> iter 4000, loss: 13.291567
 >> iter 5000, loss: 13.086007
 >> iter 6000, loss: 13.009431
 >> iter 7000, loss: 12.965129
 >> iter 8000, loss: 12.954541
 >> iter 9000, loss: 12.936508
 >> iter 10000, loss: 12.939888
   Number of active neurons: 5
 >> iter 11000, loss: 12.925496
 >> iter 12000, loss: 12.925696
 >> iter 13000, loss: 12.414079
 >> iter 14000, loss: 5.147845
 >> iter 15000, loss: 1.929704
 >> iter 16000, loss: 3.160074
 >> iter 17000, loss: 3.005518
 >> iter 18000, loss: 1.142034
 >> iter 19000, loss: 0.438659
 >> iter 20000, loss: 0.177630
   Number of active neurons: 12
 >> iter 21000, loss: 0.075427
 >> iter 22000, loss: 0.035270
 >> iter 23000, loss: 0.021421
 >> iter 24000, loss: 0.014332
 >> iter 25000, loss: 0.009942
 >> iter 26000, loss: 0.007599
 >> iter 27000, loss: 0.006142
 >> iter 28000, loss: 0.005302
 >> iter 29000, loss: 0.004617
 >> iter 30000, loss: 0.004159
   Number of active neurons: 12
 >> iter 31000, loss: 0.003742
 >> iter 32000, loss: 0.003454
 >> iter 33000, loss: 0.003168
 >> iter 34000, loss: 0.002966
 >> iter 35000, loss: 0.002755
 >> iter 36000, loss: 0.002607
 >> iter 37000, loss: 0.002444
 >> iter 38000, loss: 0.002330
 >> iter 39000, loss: 0.002200
 >> iter 40000, loss: 0.002110
   Number of active neurons: 12
 >> iter 41000, loss: 0.002003
 >> iter 42000, loss: 0.001930
 >> iter 43000, loss: 0.001840
 >> iter 44000, loss: 0.001780
 >> iter 45000, loss: 0.001703
 >> iter 46000, loss: 0.001654
 >> iter 47000, loss: 0.001586
 >> iter 48000, loss: 0.001544
 >> iter 49000, loss: 0.001485
 >> iter 50000, loss: 0.001449
   Number of active neurons: 12
 >> iter 51000, loss: 0.001397
 >> iter 52000, loss: 0.001366
 >> iter 53000, loss: 0.001318
 >> iter 54000, loss: 0.001292
 >> iter 55000, loss: 0.001248
 >> iter 56000, loss: 0.001226
 >> iter 57000, loss: 0.001186
 >> iter 58000, loss: 0.001166
 >> iter 59000, loss: 0.001130
 >> iter 60000, loss: 0.001115
   Number of active neurons: 12
 >> iter 61000, loss: 0.001080
 >> iter 62000, loss: 0.001066
 >> iter 63000, loss: 0.001033
 >> iter 64000, loss: 0.001021
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.647654
 >> iter 2000, loss: 15.132062
 >> iter 3000, loss: 13.796992
 >> iter 4000, loss: 13.295130
 >> iter 5000, loss: 13.086891
 >> iter 6000, loss: 13.010103
 >> iter 7000, loss: 12.969290
 >> iter 8000, loss: 12.960988
 >> iter 9000, loss: 12.947171
 >> iter 10000, loss: 12.950701
   Number of active neurons: 5
 >> iter 11000, loss: 12.902030
 >> iter 12000, loss: 12.239390
 >> iter 13000, loss: 8.748752
 >> iter 14000, loss: 3.293234
 >> iter 15000, loss: 1.241930
 >> iter 16000, loss: 0.476112
 >> iter 17000, loss: 0.188967
 >> iter 18000, loss: 0.080343
 >> iter 19000, loss: 0.038326
 >> iter 20000, loss: 0.021533
   Number of active neurons: 12
 >> iter 21000, loss: 0.014287
 >> iter 22000, loss: 0.010879
 >> iter 23000, loss: 0.008977
 >> iter 24000, loss: 0.007811
 >> iter 25000, loss: 0.006945
 >> iter 26000, loss: 0.006307
 >> iter 27000, loss: 0.005759
 >> iter 28000, loss: 0.005328
 >> iter 29000, loss: 0.004935
 >> iter 30000, loss: 0.004615
   Number of active neurons: 12
 >> iter 31000, loss: 0.004316
 >> iter 32000, loss: 0.004068
 >> iter 33000, loss: 0.003833
 >> iter 34000, loss: 0.003635
 >> iter 35000, loss: 0.003444
 >> iter 36000, loss: 0.003283
 >> iter 37000, loss: 0.003125
 >> iter 38000, loss: 0.002993
 >> iter 39000, loss: 0.002860
 >> iter 40000, loss: 0.002749
   Number of active neurons: 12
 >> iter 41000, loss: 0.002635
 >> iter 42000, loss: 0.002540
 >> iter 43000, loss: 0.002442
 >> iter 44000, loss: 0.002360
 >> iter 45000, loss: 0.002275
 >> iter 46000, loss: 0.002204
 >> iter 47000, loss: 0.002129
 >> iter 48000, loss: 0.002066
 >> iter 49000, loss: 0.002000
 >> iter 50000, loss: 0.001945
   Number of active neurons: 12
 >> iter 51000, loss: 0.001885
 >> iter 52000, loss: 0.001836
 >> iter 53000, loss: 0.001782
 >> iter 54000, loss: 0.001739
 >> iter 55000, loss: 0.001689
 >> iter 56000, loss: 0.001651
 >> iter 57000, loss: 0.001606
 >> iter 58000, loss: 0.001571
 >> iter 59000, loss: 0.001530
 >> iter 60000, loss: 0.001499
   Number of active neurons: 12
 >> iter 61000, loss: 0.001461
 >> iter 62000, loss: 0.001433
 >> iter 63000, loss: 0.001397
 >> iter 64000, loss: 0.001372
 >> iter 65000, loss: 0.001339
 >> iter 66000, loss: 0.001316
 >> iter 67000, loss: 0.001285
 >> iter 68000, loss: 0.001264
 >> iter 69000, loss: 0.001235
 >> iter 70000, loss: 0.001216
   Number of active neurons: 12
 >> iter 71000, loss: 0.001189
 >> iter 72000, loss: 0.001172
 >> iter 73000, loss: 0.001147
 >> iter 74000, loss: 0.001130
 >> iter 75000, loss: 0.001107
 >> iter 76000, loss: 0.001092
 >> iter 77000, loss: 0.001070
 >> iter 78000, loss: 0.001056
 >> iter 79000, loss: 0.001035
 >> iter 80000, loss: 0.001022
   Number of active neurons: 12
 >> iter 81000, loss: 0.001002
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.605406
 >> iter 2000, loss: 15.092504
 >> iter 3000, loss: 13.768469
 >> iter 4000, loss: 13.278945
 >> iter 5000, loss: 13.081008
 >> iter 6000, loss: 13.008908
 >> iter 7000, loss: 12.968959
 >> iter 8000, loss: 12.960797
 >> iter 9000, loss: 12.944889
 >> iter 10000, loss: 12.949692
   Number of active neurons: 6
 >> iter 11000, loss: 12.936134
 >> iter 12000, loss: 12.941062
 >> iter 13000, loss: 12.928510
 >> iter 14000, loss: 12.934824
 >> iter 15000, loss: 12.918127
 >> iter 16000, loss: 11.363402
 >> iter 17000, loss: 4.356945
 >> iter 18000, loss: 1.647107
 >> iter 19000, loss: 0.632029
 >> iter 20000, loss: 0.253091
   Number of active neurons: 10
 >> iter 21000, loss: 0.107734
 >> iter 22000, loss: 0.051130
 >> iter 23000, loss: 0.028357
 >> iter 24000, loss: 0.018588
 >> iter 25000, loss: 0.013954
 >> iter 26000, loss: 0.011423
 >> iter 27000, loss: 0.009849
 >> iter 28000, loss: 0.008728
 >> iter 29000, loss: 0.007877
 >> iter 30000, loss: 0.007177
   Number of active neurons: 11
 >> iter 31000, loss: 0.006602
 >> iter 32000, loss: 0.006101
 >> iter 33000, loss: 0.005681
 >> iter 34000, loss: 0.005300
 >> iter 35000, loss: 0.004977
 >> iter 36000, loss: 0.004678
 >> iter 37000, loss: 0.004421
 >> iter 38000, loss: 0.004181
 >> iter 39000, loss: 0.003972
 >> iter 40000, loss: 0.003776
   Number of active neurons: 11
 >> iter 41000, loss: 0.003603
 >> iter 42000, loss: 0.003437
 >> iter 43000, loss: 0.003293
 >> iter 44000, loss: 0.003152
 >> iter 45000, loss: 0.003030
 >> iter 46000, loss: 0.002909
 >> iter 47000, loss: 0.002803
 >> iter 48000, loss: 0.002697
 >> iter 49000, loss: 0.002606
 >> iter 50000, loss: 0.002514
   Number of active neurons: 11
 >> iter 51000, loss: 0.002433
 >> iter 52000, loss: 0.002351
 >> iter 53000, loss: 0.002280
 >> iter 54000, loss: 0.002208
 >> iter 55000, loss: 0.002144
 >> iter 56000, loss: 0.002080
 >> iter 57000, loss: 0.002023
 >> iter 58000, loss: 0.001965
 >> iter 59000, loss: 0.001914
 >> iter 60000, loss: 0.001863
   Number of active neurons: 11
 >> iter 61000, loss: 0.001816
 >> iter 62000, loss: 0.001769
 >> iter 63000, loss: 0.001726
 >> iter 64000, loss: 0.001683
 >> iter 65000, loss: 0.001645
 >> iter 66000, loss: 0.001605
 >> iter 67000, loss: 0.001570
 >> iter 68000, loss: 0.001534
 >> iter 69000, loss: 0.001502
 >> iter 70000, loss: 0.001467
   Number of active neurons: 11
 >> iter 71000, loss: 0.001439
 >> iter 72000, loss: 0.001407
 >> iter 73000, loss: 0.001380
 >> iter 74000, loss: 0.001351
 >> iter 75000, loss: 0.001325
 >> iter 76000, loss: 0.001299
 >> iter 77000, loss: 0.001275
 >> iter 78000, loss: 0.001251
 >> iter 79000, loss: 0.001228
 >> iter 80000, loss: 0.001205
   Number of active neurons: 12
 >> iter 81000, loss: 0.001184
 >> iter 82000, loss: 0.001163
 >> iter 83000, loss: 0.001143
 >> iter 84000, loss: 0.001124
 >> iter 85000, loss: 0.001105
 >> iter 86000, loss: 0.001087
 >> iter 87000, loss: 0.001069
 >> iter 88000, loss: 0.001052
 >> iter 89000, loss: 0.001035
 >> iter 90000, loss: 0.001019
   Number of active neurons: 12
 >> iter 91000, loss: 0.001003
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.631067
 >> iter 2000, loss: 15.105130
 >> iter 3000, loss: 13.764449
 >> iter 4000, loss: 13.265348
 >> iter 5000, loss: 13.066840
 >> iter 6000, loss: 12.996086
 >> iter 7000, loss: 12.960425
 >> iter 8000, loss: 12.954116
 >> iter 9000, loss: 12.942341
 >> iter 10000, loss: 12.947840
   Number of active neurons: 5
 >> iter 11000, loss: 12.937836
 >> iter 12000, loss: 12.936690
 >> iter 13000, loss: 12.649653
 >> iter 14000, loss: 6.388472
 >> iter 15000, loss: 2.399160
 >> iter 16000, loss: 0.907857
 >> iter 17000, loss: 0.349328
 >> iter 18000, loss: 0.139548
 >> iter 19000, loss: 0.059982
 >> iter 20000, loss: 0.029194
   Number of active neurons: 12
 >> iter 21000, loss: 0.016771
 >> iter 22000, loss: 0.011413
 >> iter 23000, loss: 0.008807
 >> iter 24000, loss: 0.007372
 >> iter 25000, loss: 0.006430
 >> iter 26000, loss: 0.005763
 >> iter 27000, loss: 0.005227
 >> iter 28000, loss: 0.004804
 >> iter 29000, loss: 0.004433
 >> iter 30000, loss: 0.004127
   Number of active neurons: 12
 >> iter 31000, loss: 0.003847
 >> iter 32000, loss: 0.003614
 >> iter 33000, loss: 0.003395
 >> iter 34000, loss: 0.003212
 >> iter 35000, loss: 0.003035
 >> iter 36000, loss: 0.002888
 >> iter 37000, loss: 0.002742
 >> iter 38000, loss: 0.002622
 >> iter 39000, loss: 0.002499
 >> iter 40000, loss: 0.002399
   Number of active neurons: 12
 >> iter 41000, loss: 0.002294
 >> iter 42000, loss: 0.002209
 >> iter 43000, loss: 0.002119
 >> iter 44000, loss: 0.002046
 >> iter 45000, loss: 0.001967
 >> iter 46000, loss: 0.001906
 >> iter 47000, loss: 0.001834
 >> iter 48000, loss: 0.001781
 >> iter 49000, loss: 0.001718
 >> iter 50000, loss: 0.001672
   Number of active neurons: 12
 >> iter 51000, loss: 0.001615
 >> iter 52000, loss: 0.001574
 >> iter 53000, loss: 0.001522
 >> iter 54000, loss: 0.001487
 >> iter 55000, loss: 0.001439
 >> iter 56000, loss: 0.001408
 >> iter 57000, loss: 0.001365
 >> iter 58000, loss: 0.001336
 >> iter 59000, loss: 0.001297
 >> iter 60000, loss: 0.001272
   Number of active neurons: 12
 >> iter 61000, loss: 0.001236
 >> iter 62000, loss: 0.001213
 >> iter 63000, loss: 0.001180
 >> iter 64000, loss: 0.001159
 >> iter 65000, loss: 0.001128
 >> iter 66000, loss: 0.001109
 >> iter 67000, loss: 0.001081
 >> iter 68000, loss: 0.001063
 >> iter 69000, loss: 0.001037
 >> iter 70000, loss: 0.001020
   Number of active neurons: 12
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.609620
 >> iter 2000, loss: 15.086339
 >> iter 3000, loss: 13.749608
 >> iter 4000, loss: 13.253245
 >> iter 5000, loss: 13.053076
 >> iter 6000, loss: 12.982963
 >> iter 7000, loss: 12.945127
 >> iter 8000, loss: 12.938593
 >> iter 9000, loss: 12.924442
 >> iter 10000, loss: 12.923694
   Number of active neurons: 4
 >> iter 11000, loss: 12.459452
 >> iter 12000, loss: 5.497312
 >> iter 13000, loss: 2.069237
 >> iter 14000, loss: 0.784366
 >> iter 15000, loss: 0.304185
 >> iter 16000, loss: 0.123659
 >> iter 17000, loss: 0.054996
 >> iter 18000, loss: 0.028091
 >> iter 19000, loss: 0.017092
 >> iter 20000, loss: 0.012152
   Number of active neurons: 12
 >> iter 21000, loss: 0.009686
 >> iter 22000, loss: 0.008226
 >> iter 23000, loss: 0.007258
 >> iter 24000, loss: 0.006532
 >> iter 25000, loss: 0.005956
 >> iter 26000, loss: 0.005477
 >> iter 27000, loss: 0.005072
 >> iter 28000, loss: 0.004724
 >> iter 29000, loss: 0.004417
 >> iter 30000, loss: 0.004151
   Number of active neurons: 12
 >> iter 31000, loss: 0.003908
 >> iter 32000, loss: 0.003698
 >> iter 33000, loss: 0.003503
 >> iter 34000, loss: 0.003332
 >> iter 35000, loss: 0.003171
 >> iter 36000, loss: 0.003030
 >> iter 37000, loss: 0.002895
 >> iter 38000, loss: 0.002778
 >> iter 39000, loss: 0.002662
 >> iter 40000, loss: 0.002564
   Number of active neurons: 12
 >> iter 41000, loss: 0.002464
 >> iter 42000, loss: 0.002379
 >> iter 43000, loss: 0.002291
 >> iter 44000, loss: 0.002218
 >> iter 45000, loss: 0.002141
 >> iter 46000, loss: 0.002077
 >> iter 47000, loss: 0.002009
 >> iter 48000, loss: 0.001952
 >> iter 49000, loss: 0.001892
 >> iter 50000, loss: 0.001842
   Number of active neurons: 12
 >> iter 51000, loss: 0.001787
 >> iter 52000, loss: 0.001742
 >> iter 53000, loss: 0.001692
 >> iter 54000, loss: 0.001653
 >> iter 55000, loss: 0.001606
 >> iter 56000, loss: 0.001572
 >> iter 57000, loss: 0.001529
 >> iter 58000, loss: 0.001498
 >> iter 59000, loss: 0.001459
 >> iter 60000, loss: 0.001431
   Number of active neurons: 12
 >> iter 61000, loss: 0.001395
 >> iter 62000, loss: 0.001369
 >> iter 63000, loss: 0.001335
 >> iter 64000, loss: 0.001314
 >> iter 65000, loss: 0.001281
 >> iter 66000, loss: 0.001261
 >> iter 67000, loss: 0.001231
 >> iter 68000, loss: 0.001212
 >> iter 69000, loss: 0.001185
 >> iter 70000, loss: 0.001167
   Number of active neurons: 12
 >> iter 71000, loss: 0.001141
 >> iter 72000, loss: 0.001125
 >> iter 73000, loss: 0.001101
 >> iter 74000, loss: 0.001087
 >> iter 75000, loss: 0.001063
 >> iter 76000, loss: 0.001050
 >> iter 77000, loss: 0.001028
 >> iter 78000, loss: 0.001016
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0159998400016
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.624038
 >> iter 2000, loss: 15.138141
 >> iter 3000, loss: 13.817132
 >> iter 4000, loss: 13.321120
 >> iter 5000, loss: 13.111108
 >> iter 6000, loss: 13.028947
 >> iter 7000, loss: 12.979592
 >> iter 8000, loss: 12.963326
 >> iter 9000, loss: 12.936747
 >> iter 10000, loss: 11.846240
   Number of active neurons: 12
 >> iter 11000, loss: 4.524574
 >> iter 12000, loss: 1.706092
 >> iter 13000, loss: 0.651916
 >> iter 14000, loss: 0.256562
 >> iter 15000, loss: 0.107280
 >> iter 16000, loss: 0.049689
 >> iter 17000, loss: 0.026880
 >> iter 18000, loss: 0.017131
 >> iter 19000, loss: 0.012665
 >> iter 20000, loss: 0.010214
   Number of active neurons: 12
 >> iter 21000, loss: 0.008761
 >> iter 22000, loss: 0.007693
 >> iter 23000, loss: 0.006925
 >> iter 24000, loss: 0.006267
 >> iter 25000, loss: 0.005753
 >> iter 26000, loss: 0.005285
 >> iter 27000, loss: 0.004908
 >> iter 28000, loss: 0.004555
 >> iter 29000, loss: 0.004268
 >> iter 30000, loss: 0.003989
   Number of active neurons: 12
 >> iter 31000, loss: 0.003764
 >> iter 32000, loss: 0.003540
 >> iter 33000, loss: 0.003358
 >> iter 34000, loss: 0.003174
 >> iter 35000, loss: 0.003024
 >> iter 36000, loss: 0.002872
 >> iter 37000, loss: 0.002746
 >> iter 38000, loss: 0.002618
 >> iter 39000, loss: 0.002513
 >> iter 40000, loss: 0.002403
   Number of active neurons: 12
 >> iter 41000, loss: 0.002313
 >> iter 42000, loss: 0.002218
 >> iter 43000, loss: 0.002140
 >> iter 44000, loss: 0.002058
 >> iter 45000, loss: 0.001990
 >> iter 46000, loss: 0.001917
 >> iter 47000, loss: 0.001859
 >> iter 48000, loss: 0.001794
 >> iter 49000, loss: 0.001743
 >> iter 50000, loss: 0.001685
   Number of active neurons: 12
 >> iter 51000, loss: 0.001639
 >> iter 52000, loss: 0.001587
 >> iter 53000, loss: 0.001545
 >> iter 54000, loss: 0.001500
 >> iter 55000, loss: 0.001462
 >> iter 56000, loss: 0.001421
 >> iter 57000, loss: 0.001387
 >> iter 58000, loss: 0.001349
 >> iter 59000, loss: 0.001318
 >> iter 60000, loss: 0.001287
   Number of active neurons: 12
 >> iter 61000, loss: 0.001256
 >> iter 62000, loss: 0.001228
 >> iter 63000, loss: 0.001199
 >> iter 64000, loss: 0.001175
 >> iter 65000, loss: 0.001147
 >> iter 66000, loss: 0.001124
 >> iter 67000, loss: 0.001098
 >> iter 68000, loss: 0.001078
 >> iter 69000, loss: 0.001054
 >> iter 70000, loss: 0.001035
   Number of active neurons: 12
 >> iter 71000, loss: 0.001013
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.619909
 >> iter 2000, loss: 15.107055
 >> iter 3000, loss: 13.772224
 >> iter 4000, loss: 13.273640
 >> iter 5000, loss: 13.074081
 >> iter 6000, loss: 13.002293
 >> iter 7000, loss: 12.965635
 >> iter 8000, loss: 12.958171
 >> iter 9000, loss: 12.945431
 >> iter 10000, loss: 12.949649
   Number of active neurons: 5
 >> iter 11000, loss: 12.938562
 >> iter 12000, loss: 12.903310
 >> iter 13000, loss: 12.284679
 >> iter 14000, loss: 6.021906
 >> iter 15000, loss: 2.285001
 >> iter 16000, loss: 0.863717
 >> iter 17000, loss: 0.332556
 >> iter 18000, loss: 0.133541
 >> iter 19000, loss: 0.057991
 >> iter 20000, loss: 0.028773
   Number of active neurons: 12
 >> iter 21000, loss: 0.016869
 >> iter 22000, loss: 0.011745
 >> iter 23000, loss: 0.009163
 >> iter 24000, loss: 0.007770
 >> iter 25000, loss: 0.006787
 >> iter 26000, loss: 0.006131
 >> iter 27000, loss: 0.005551
 >> iter 28000, loss: 0.005136
 >> iter 29000, loss: 0.004725
 >> iter 30000, loss: 0.004426
   Number of active neurons: 12
 >> iter 31000, loss: 0.004112
 >> iter 32000, loss: 0.003885
 >> iter 33000, loss: 0.003638
 >> iter 34000, loss: 0.003459
 >> iter 35000, loss: 0.003260
 >> iter 36000, loss: 0.003116
 >> iter 37000, loss: 0.002951
 >> iter 38000, loss: 0.002834
 >> iter 39000, loss: 0.002695
 >> iter 40000, loss: 0.002598
   Number of active neurons: 12
 >> iter 41000, loss: 0.002478
 >> iter 42000, loss: 0.002396
 >> iter 43000, loss: 0.002293
 >> iter 44000, loss: 0.002222
 >> iter 45000, loss: 0.002133
 >> iter 46000, loss: 0.002073
 >> iter 47000, loss: 0.001992
 >> iter 48000, loss: 0.001940
 >> iter 49000, loss: 0.001870
 >> iter 50000, loss: 0.001824
   Number of active neurons: 12
 >> iter 51000, loss: 0.001760
 >> iter 52000, loss: 0.001720
 >> iter 53000, loss: 0.001661
 >> iter 54000, loss: 0.001627
 >> iter 55000, loss: 0.001574
 >> iter 56000, loss: 0.001543
 >> iter 57000, loss: 0.001495
 >> iter 58000, loss: 0.001467
 >> iter 59000, loss: 0.001423
 >> iter 60000, loss: 0.001399
   Number of active neurons: 12
 >> iter 61000, loss: 0.001358
 >> iter 62000, loss: 0.001336
 >> iter 63000, loss: 0.001298
 >> iter 64000, loss: 0.001278
 >> iter 65000, loss: 0.001243
 >> iter 66000, loss: 0.001224
 >> iter 67000, loss: 0.001193
 >> iter 68000, loss: 0.001176
 >> iter 69000, loss: 0.001147
 >> iter 70000, loss: 0.001130
   Number of active neurons: 12
 >> iter 71000, loss: 0.001104
 >> iter 72000, loss: 0.001088
 >> iter 73000, loss: 0.001063
 >> iter 74000, loss: 0.001050
 >> iter 75000, loss: 0.001026
 >> iter 76000, loss: 0.001014
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.614180
 >> iter 2000, loss: 15.124542
 >> iter 3000, loss: 13.795496
 >> iter 4000, loss: 13.296978
 >> iter 5000, loss: 13.091115
 >> iter 6000, loss: 13.016405
 >> iter 7000, loss: 12.974718
 >> iter 8000, loss: 12.964848
 >> iter 9000, loss: 12.948668
 >> iter 10000, loss: 12.950973
   Number of active neurons: 5
 >> iter 11000, loss: 12.934245
 >> iter 12000, loss: 12.389051
 >> iter 13000, loss: 4.885322
 >> iter 14000, loss: 1.853797
 >> iter 15000, loss: 0.702125
 >> iter 16000, loss: 0.274007
 >> iter 17000, loss: 0.112340
 >> iter 18000, loss: 0.049747
 >> iter 19000, loss: 0.025186
 >> iter 20000, loss: 0.015152
   Number of active neurons: 12
 >> iter 21000, loss: 0.010688
 >> iter 22000, loss: 0.008517
 >> iter 23000, loss: 0.007201
 >> iter 24000, loss: 0.006467
 >> iter 25000, loss: 0.005758
 >> iter 26000, loss: 0.005341
 >> iter 27000, loss: 0.004839
 >> iter 28000, loss: 0.004573
 >> iter 29000, loss: 0.004189
 >> iter 30000, loss: 0.004065
   Number of active neurons: 12
 >> iter 31000, loss: 0.003719
 >> iter 32000, loss: 0.003659
 >> iter 33000, loss: 0.003346
 >> iter 34000, loss: 0.003224
 >> iter 35000, loss: 0.002995
 >> iter 36000, loss: 0.003006
 >> iter 37000, loss: 0.002765
 >> iter 38000, loss: 0.002758
 >> iter 39000, loss: 0.002546
 >> iter 40000, loss: 0.002453
   Number of active neurons: 12
 >> iter 41000, loss: 0.002315
 >> iter 42000, loss: 0.002421
 >> iter 43000, loss: 0.002217
 >> iter 44000, loss: 0.002202
 >> iter 45000, loss: 0.002052
 >> iter 46000, loss: 0.001974
 >> iter 47000, loss: 0.001884
 >> iter 48000, loss: 0.001948
 >> iter 49000, loss: 0.001812
 >> iter 50000, loss: 0.002103
   Number of active neurons: 12
 >> iter 51000, loss: 0.001989
 >> iter 52000, loss: 0.001904
 >> iter 53000, loss: 0.001833
 >> iter 54000, loss: 0.001702
 >> iter 55000, loss: 0.001604
 >> iter 56000, loss: 0.001535
 >> iter 57000, loss: 0.001473
 >> iter 58000, loss: 0.001429
 >> iter 59000, loss: 0.001382
 >> iter 60000, loss: 0.001349
   Number of active neurons: 12
 >> iter 61000, loss: 0.001309
 >> iter 62000, loss: 0.001281
 >> iter 63000, loss: 0.001245
 >> iter 64000, loss: 0.001223
 >> iter 65000, loss: 0.001190
 >> iter 66000, loss: 0.001182
 >> iter 67000, loss: 0.001145
 >> iter 68000, loss: 0.001298
 >> iter 69000, loss: 0.001211
 >> iter 70000, loss: 0.001149
   Number of active neurons: 12
 >> iter 71000, loss: 0.001104
 >> iter 72000, loss: 0.001075
 >> iter 73000, loss: 0.001045
 >> iter 74000, loss: 0.001026
 >> iter 75000, loss: 0.001001
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.601369
 >> iter 2000, loss: 15.098857
 >> iter 3000, loss: 13.771979
 >> iter 4000, loss: 13.277031
 >> iter 5000, loss: 13.079324
 >> iter 6000, loss: 13.009022
 >> iter 7000, loss: 12.973602
 >> iter 8000, loss: 12.967534
 >> iter 9000, loss: 12.955666
 >> iter 10000, loss: 12.960175
   Number of active neurons: 6
 >> iter 11000, loss: 12.946556
 >> iter 12000, loss: 12.647008
 >> iter 13000, loss: 7.883896
 >> iter 14000, loss: 2.966460
 >> iter 15000, loss: 1.160357
 >> iter 16000, loss: 0.446689
 >> iter 17000, loss: 0.178613
 >> iter 18000, loss: 0.077033
 >> iter 19000, loss: 0.037572
 >> iter 20000, loss: 0.021681
   Number of active neurons: 12
 >> iter 21000, loss: 0.014746
 >> iter 22000, loss: 0.011440
 >> iter 23000, loss: 0.009538
 >> iter 24000, loss: 0.008370
 >> iter 25000, loss: 0.007467
 >> iter 26000, loss: 0.006810
 >> iter 27000, loss: 0.006225
 >> iter 28000, loss: 0.005781
 >> iter 29000, loss: 0.005351
 >> iter 30000, loss: 0.005021
   Number of active neurons: 12
 >> iter 31000, loss: 0.004686
 >> iter 32000, loss: 0.004431
 >> iter 33000, loss: 0.004164
 >> iter 34000, loss: 0.003961
 >> iter 35000, loss: 0.003744
 >> iter 36000, loss: 0.003579
 >> iter 37000, loss: 0.003398
 >> iter 38000, loss: 0.003261
 >> iter 39000, loss: 0.003108
 >> iter 40000, loss: 0.002995
   Number of active neurons: 12
 >> iter 41000, loss: 0.002862
 >> iter 42000, loss: 0.002764
 >> iter 43000, loss: 0.002650
 >> iter 44000, loss: 0.002566
 >> iter 45000, loss: 0.002466
 >> iter 46000, loss: 0.002394
 >> iter 47000, loss: 0.002304
 >> iter 48000, loss: 0.002241
 >> iter 49000, loss: 0.002162
 >> iter 50000, loss: 0.002107
   Number of active neurons: 12
 >> iter 51000, loss: 0.002036
 >> iter 52000, loss: 0.001986
 >> iter 53000, loss: 0.001921
 >> iter 54000, loss: 0.001878
 >> iter 55000, loss: 0.001819
 >> iter 56000, loss: 0.001781
 >> iter 57000, loss: 0.001728
 >> iter 58000, loss: 0.001693
 >> iter 59000, loss: 0.001645
 >> iter 60000, loss: 0.001613
   Number of active neurons: 12
 >> iter 61000, loss: 0.001568
 >> iter 62000, loss: 0.001539
 >> iter 63000, loss: 0.001498
 >> iter 64000, loss: 0.001472
 >> iter 65000, loss: 0.001434
 >> iter 66000, loss: 0.001409
 >> iter 67000, loss: 0.001376
 >> iter 68000, loss: 0.001353
 >> iter 69000, loss: 0.001322
 >> iter 70000, loss: 0.001299
   Number of active neurons: 12
 >> iter 71000, loss: 0.001271
 >> iter 72000, loss: 0.001250
 >> iter 73000, loss: 0.001224
 >> iter 74000, loss: 0.001205
 >> iter 75000, loss: 0.001180
 >> iter 76000, loss: 0.001163
 >> iter 77000, loss: 0.001139
 >> iter 78000, loss: 0.001123
 >> iter 79000, loss: 0.001101
 >> iter 80000, loss: 0.001086
   Number of active neurons: 12
 >> iter 81000, loss: 0.001065
 >> iter 82000, loss: 0.001051
 >> iter 83000, loss: 0.001031
 >> iter 84000, loss: 0.001018
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.644883
 >> iter 2000, loss: 15.129678
 >> iter 3000, loss: 13.788062
 >> iter 4000, loss: 13.283261
 >> iter 5000, loss: 13.081239
 >> iter 6000, loss: 13.007048
 >> iter 7000, loss: 12.970323
 >> iter 8000, loss: 12.961772
 >> iter 9000, loss: 12.949198
 >> iter 10000, loss: 12.952561
   Number of active neurons: 5
 >> iter 11000, loss: 12.941995
 >> iter 12000, loss: 12.944704
 >> iter 13000, loss: 12.932781
 >> iter 14000, loss: 12.687546
 >> iter 15000, loss: 11.307226
 >> iter 16000, loss: 7.086151
 >> iter 17000, loss: 2.784410
 >> iter 18000, loss: 1.371478
 >> iter 19000, loss: 0.529866
 >> iter 20000, loss: 0.210133
   Number of active neurons: 12
 >> iter 21000, loss: 0.087527
 >> iter 22000, loss: 0.040417
 >> iter 23000, loss: 0.021246
 >> iter 24000, loss: 0.013376
 >> iter 25000, loss: 0.072206
 >> iter 26000, loss: 0.031649
 >> iter 27000, loss: 0.025529
 >> iter 28000, loss: 0.013466
 >> iter 29000, loss: 0.008412
 >> iter 30000, loss: 0.006183
   Number of active neurons: 12
 >> iter 31000, loss: 0.005050
 >> iter 32000, loss: 0.004410
 >> iter 33000, loss: 0.003968
 >> iter 34000, loss: 0.003647
 >> iter 35000, loss: 0.003383
 >> iter 36000, loss: 0.003163
 >> iter 37000, loss: 0.002976
 >> iter 38000, loss: 0.002805
 >> iter 39000, loss: 0.002664
 >> iter 40000, loss: 0.002524
   Number of active neurons: 12
 >> iter 41000, loss: 0.002415
 >> iter 42000, loss: 0.002294
 >> iter 43000, loss: 0.002206
 >> iter 44000, loss: 0.002103
 >> iter 45000, loss: 0.002031
 >> iter 46000, loss: 0.001942
 >> iter 47000, loss: 0.001880
 >> iter 48000, loss: 0.001803
 >> iter 49000, loss: 0.001751
 >> iter 50000, loss: 0.001683
   Number of active neurons: 12
 >> iter 51000, loss: 0.001638
 >> iter 52000, loss: 0.001577
 >> iter 53000, loss: 0.001537
 >> iter 54000, loss: 0.001483
 >> iter 55000, loss: 0.001449
 >> iter 56000, loss: 0.001400
 >> iter 57000, loss: 0.001370
 >> iter 58000, loss: 0.001326
 >> iter 59000, loss: 0.001300
 >> iter 60000, loss: 0.001259
   Number of active neurons: 12
 >> iter 61000, loss: 0.001236
 >> iter 62000, loss: 0.001199
 >> iter 63000, loss: 0.001177
 >> iter 64000, loss: 0.001144
 >> iter 65000, loss: 0.001124
 >> iter 66000, loss: 0.001093
 >> iter 67000, loss: 0.001075
 >> iter 68000, loss: 0.001047
 >> iter 69000, loss: 0.001031
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.622930
 >> iter 2000, loss: 15.097749
 >> iter 3000, loss: 13.758866
 >> iter 4000, loss: 13.260957
 >> iter 5000, loss: 13.062873
 >> iter 6000, loss: 12.993897
 >> iter 7000, loss: 12.958737
 >> iter 8000, loss: 12.953974
 >> iter 9000, loss: 12.942151
 >> iter 10000, loss: 12.949073
   Number of active neurons: 5
 >> iter 11000, loss: 12.938682
 >> iter 12000, loss: 12.945138
 >> iter 13000, loss: 12.935302
 >> iter 14000, loss: 12.941433
 >> iter 15000, loss: 12.877480
 >> iter 16000, loss: 10.998604
 >> iter 17000, loss: 4.163890
 >> iter 18000, loss: 1.563850
 >> iter 19000, loss: 0.594967
 >> iter 20000, loss: 0.232793
   Number of active neurons: 12
 >> iter 21000, loss: 0.096608
 >> iter 22000, loss: 0.044390
 >> iter 23000, loss: 0.023886
 >> iter 24000, loss: 0.015241
 >> iter 25000, loss: 0.011346
 >> iter 26000, loss: 0.009236
 >> iter 27000, loss: 0.008013
 >> iter 28000, loss: 0.007104
 >> iter 29000, loss: 0.006468
 >> iter 30000, loss: 0.005900
   Number of active neurons: 12
 >> iter 31000, loss: 0.005476
 >> iter 32000, loss: 0.005064
 >> iter 33000, loss: 0.004754
 >> iter 34000, loss: 0.004437
 >> iter 35000, loss: 0.004199
 >> iter 36000, loss: 0.003946
 >> iter 37000, loss: 0.003758
 >> iter 38000, loss: 0.003552
 >> iter 39000, loss: 0.003399
 >> iter 40000, loss: 0.003229
   Number of active neurons: 12
 >> iter 41000, loss: 0.003102
 >> iter 42000, loss: 0.002957
 >> iter 43000, loss: 0.002851
 >> iter 44000, loss: 0.002727
 >> iter 45000, loss: 0.002637
 >> iter 46000, loss: 0.002529
 >> iter 47000, loss: 0.002453
 >> iter 48000, loss: 0.002358
 >> iter 49000, loss: 0.002292
 >> iter 50000, loss: 0.002208
   Number of active neurons: 12
 >> iter 51000, loss: 0.002150
 >> iter 52000, loss: 0.002075
 >> iter 53000, loss: 0.002023
 >> iter 54000, loss: 0.001958
 >> iter 55000, loss: 0.001911
 >> iter 56000, loss: 0.001852
 >> iter 57000, loss: 0.001811
 >> iter 58000, loss: 0.001757
 >> iter 59000, loss: 0.001720
 >> iter 60000, loss: 0.001671
   Number of active neurons: 12
 >> iter 61000, loss: 0.001637
 >> iter 62000, loss: 0.001593
 >> iter 63000, loss: 0.001562
 >> iter 64000, loss: 0.001522
 >> iter 65000, loss: 0.001494
 >> iter 66000, loss: 0.001457
 >> iter 67000, loss: 0.001430
 >> iter 68000, loss: 0.001396
 >> iter 69000, loss: 0.001372
 >> iter 70000, loss: 0.001340
   Number of active neurons: 12
 >> iter 71000, loss: 0.001318
 >> iter 72000, loss: 0.001289
 >> iter 73000, loss: 0.001269
 >> iter 74000, loss: 0.001241
 >> iter 75000, loss: 0.001223
 >> iter 76000, loss: 0.001197
 >> iter 77000, loss: 0.001180
 >> iter 78000, loss: 0.001156
 >> iter 79000, loss: 0.001139
 >> iter 80000, loss: 0.001117
   Number of active neurons: 12
 >> iter 81000, loss: 0.001102
 >> iter 82000, loss: 0.001081
 >> iter 83000, loss: 0.001066
 >> iter 84000, loss: 0.001047
 >> iter 85000, loss: 0.001033
 >> iter 86000, loss: 0.001015
 >> iter 87000, loss: 0.001002
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.595728
 >> iter 2000, loss: 15.088802
 >> iter 3000, loss: 13.761172
 >> iter 4000, loss: 13.266117
 >> iter 5000, loss: 13.063154
 >> iter 6000, loss: 12.990425
 >> iter 7000, loss: 12.949999
 >> iter 8000, loss: 12.943672
 >> iter 9000, loss: 12.928938
 >> iter 10000, loss: 12.935580
   Number of active neurons: 3
 >> iter 11000, loss: 12.923404
 >> iter 12000, loss: 12.929577
 >> iter 13000, loss: 12.918029
 >> iter 14000, loss: 12.880419
 >> iter 15000, loss: 10.109946
 >> iter 16000, loss: 3.836656
 >> iter 17000, loss: 1.450558
 >> iter 18000, loss: 0.557685
 >> iter 19000, loss: 0.222420
 >> iter 20000, loss: 0.095344
   Number of active neurons: 12
 >> iter 21000, loss: 0.046083
 >> iter 22000, loss: 0.026305
 >> iter 23000, loss: 0.017718
 >> iter 24000, loss: 0.013641
 >> iter 25000, loss: 0.011336
 >> iter 26000, loss: 0.009901
 >> iter 27000, loss: 0.008833
 >> iter 28000, loss: 0.008042
 >> iter 29000, loss: 0.007358
 >> iter 30000, loss: 0.006818
   Number of active neurons: 12
 >> iter 31000, loss: 0.006318
 >> iter 32000, loss: 0.005919
 >> iter 33000, loss: 0.005536
 >> iter 34000, loss: 0.005227
 >> iter 35000, loss: 0.004924
 >> iter 36000, loss: 0.004679
 >> iter 37000, loss: 0.004430
 >> iter 38000, loss: 0.004233
 >> iter 39000, loss: 0.004025
 >> iter 40000, loss: 0.003863
   Number of active neurons: 12
 >> iter 41000, loss: 0.003688
 >> iter 42000, loss: 0.003549
 >> iter 43000, loss: 0.003400
 >> iter 44000, loss: 0.003282
 >> iter 45000, loss: 0.003153
 >> iter 46000, loss: 0.003053
 >> iter 47000, loss: 0.002938
 >> iter 48000, loss: 0.002851
 >> iter 49000, loss: 0.002750
 >> iter 50000, loss: 0.002674
   Number of active neurons: 12
 >> iter 51000, loss: 0.002584
 >> iter 52000, loss: 0.002517
 >> iter 53000, loss: 0.002435
 >> iter 54000, loss: 0.002377
 >> iter 55000, loss: 0.002303
 >> iter 56000, loss: 0.002251
 >> iter 57000, loss: 0.002184
 >> iter 58000, loss: 0.002138
 >> iter 59000, loss: 0.002077
 >> iter 60000, loss: 0.002035
   Number of active neurons: 12
 >> iter 61000, loss: 0.001979
 >> iter 62000, loss: 0.001941
 >> iter 63000, loss: 0.001889
 >> iter 64000, loss: 0.001854
 >> iter 65000, loss: 0.001808
 >> iter 66000, loss: 0.001775
 >> iter 67000, loss: 0.001733
 >> iter 68000, loss: 0.001703
 >> iter 69000, loss: 0.001664
 >> iter 70000, loss: 0.001635
   Number of active neurons: 12
 >> iter 71000, loss: 0.001599
 >> iter 72000, loss: 0.001572
 >> iter 73000, loss: 0.001539
 >> iter 74000, loss: 0.001515
 >> iter 75000, loss: 0.001483
 >> iter 76000, loss: 0.001461
 >> iter 77000, loss: 0.001431
 >> iter 78000, loss: 0.001411
 >> iter 79000, loss: 0.001382
 >> iter 80000, loss: 0.001364
   Number of active neurons: 12
 >> iter 81000, loss: 0.001337
 >> iter 82000, loss: 0.001320
 >> iter 83000, loss: 0.001294
 >> iter 84000, loss: 0.001278
 >> iter 85000, loss: 0.001254
 >> iter 86000, loss: 0.001239
 >> iter 87000, loss: 0.001216
 >> iter 88000, loss: 0.001202
 >> iter 89000, loss: 0.001180
 >> iter 90000, loss: 0.001167
   Number of active neurons: 12
 >> iter 91000, loss: 0.001146
 >> iter 92000, loss: 0.001134
 >> iter 93000, loss: 0.001114
 >> iter 94000, loss: 0.001103
 >> iter 95000, loss: 0.001084
 >> iter 96000, loss: 0.001073
 >> iter 97000, loss: 0.001055
 >> iter 98000, loss: 0.001045
 >> iter 99000, loss: 0.001027
 >> iter 100000, loss: 0.001018
   Number of active neurons: 12
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0049999500005
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.614319
 >> iter 2000, loss: 15.097497
 >> iter 3000, loss: 13.760993
 >> iter 4000, loss: 13.264301
 >> iter 5000, loss: 13.067355
 >> iter 6000, loss: 12.996842
 >> iter 7000, loss: 12.961364
 >> iter 8000, loss: 12.954634
 >> iter 9000, loss: 12.942954
 >> iter 10000, loss: 12.947891
   Number of active neurons: 5
 >> iter 11000, loss: 12.937442
 >> iter 12000, loss: 12.870188
 >> iter 13000, loss: 10.146781
 >> iter 14000, loss: 3.863721
 >> iter 15000, loss: 1.455922
 >> iter 16000, loss: 0.555896
 >> iter 17000, loss: 0.218986
 >> iter 18000, loss: 0.091672
 >> iter 19000, loss: 0.042827
 >> iter 20000, loss: 0.023344
   Number of active neurons: 12
 >> iter 21000, loss: 0.015153
 >> iter 22000, loss: 0.011302
 >> iter 23000, loss: 0.009285
 >> iter 24000, loss: 0.008006
 >> iter 25000, loss: 0.007138
 >> iter 26000, loss: 0.006446
 >> iter 27000, loss: 0.005913
 >> iter 28000, loss: 0.005443
 >> iter 29000, loss: 0.005065
 >> iter 30000, loss: 0.004715
   Number of active neurons: 12
 >> iter 31000, loss: 0.004430
 >> iter 32000, loss: 0.004157
 >> iter 33000, loss: 0.003936
 >> iter 34000, loss: 0.003716
 >> iter 35000, loss: 0.003537
 >> iter 36000, loss: 0.003358
 >> iter 37000, loss: 0.003210
 >> iter 38000, loss: 0.003061
 >> iter 39000, loss: 0.002939
 >> iter 40000, loss: 0.002813
   Number of active neurons: 12
 >> iter 41000, loss: 0.002708
 >> iter 42000, loss: 0.002600
 >> iter 43000, loss: 0.002511
 >> iter 44000, loss: 0.002416
 >> iter 45000, loss: 0.002340
 >> iter 46000, loss: 0.002257
 >> iter 47000, loss: 0.002190
 >> iter 48000, loss: 0.002116
 >> iter 49000, loss: 0.002058
 >> iter 50000, loss: 0.001992
   Number of active neurons: 12
 >> iter 51000, loss: 0.001940
 >> iter 52000, loss: 0.001881
 >> iter 53000, loss: 0.001834
 >> iter 54000, loss: 0.001782
 >> iter 55000, loss: 0.001739
 >> iter 56000, loss: 0.001693
 >> iter 57000, loss: 0.001653
 >> iter 58000, loss: 0.001612
 >> iter 59000, loss: 0.001576
 >> iter 60000, loss: 0.001538
   Number of active neurons: 12
 >> iter 61000, loss: 0.001505
 >> iter 62000, loss: 0.001470
 >> iter 63000, loss: 0.001440
 >> iter 64000, loss: 0.001408
 >> iter 65000, loss: 0.001380
 >> iter 66000, loss: 0.001351
 >> iter 67000, loss: 0.001325
 >> iter 68000, loss: 0.001298
 >> iter 69000, loss: 0.001274
 >> iter 70000, loss: 0.001248
   Number of active neurons: 12
 >> iter 71000, loss: 0.001227
 >> iter 72000, loss: 0.001203
 >> iter 73000, loss: 0.001183
 >> iter 74000, loss: 0.001161
 >> iter 75000, loss: 0.001142
 >> iter 76000, loss: 0.001122
 >> iter 77000, loss: 0.001104
 >> iter 78000, loss: 0.001085
 >> iter 79000, loss: 0.001068
 >> iter 80000, loss: 0.001050
   Number of active neurons: 12
 >> iter 81000, loss: 0.001034
 >> iter 82000, loss: 0.001017
 >> iter 83000, loss: 0.001003
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.611066
 >> iter 2000, loss: 15.116882
 >> iter 3000, loss: 13.791668
 >> iter 4000, loss: 13.299257
 >> iter 5000, loss: 13.096076
 >> iter 6000, loss: 13.018591
 >> iter 7000, loss: 12.973754
 >> iter 8000, loss: 12.961748
 >> iter 9000, loss: 12.943493
 >> iter 10000, loss: 12.939657
   Number of active neurons: 5
 >> iter 11000, loss: 11.287837
 >> iter 12000, loss: 4.306902
 >> iter 13000, loss: 1.628265
 >> iter 14000, loss: 0.625551
 >> iter 15000, loss: 0.249070
 >> iter 16000, loss: 0.106306
 >> iter 17000, loss: 0.051062
 >> iter 18000, loss: 0.028829
 >> iter 19000, loss: 0.019261
 >> iter 20000, loss: 0.014675
   Number of active neurons: 12
 >> iter 21000, loss: 0.012143
 >> iter 22000, loss: 0.010544
 >> iter 23000, loss: 0.009382
 >> iter 24000, loss: 0.008506
 >> iter 25000, loss: 0.007767
 >> iter 26000, loss: 0.007170
 >> iter 27000, loss: 0.006637
 >> iter 28000, loss: 0.006199
 >> iter 29000, loss: 0.005792
 >> iter 30000, loss: 0.005453
   Number of active neurons: 12
 >> iter 31000, loss: 0.005129
 >> iter 32000, loss: 0.004860
 >> iter 33000, loss: 0.004598
 >> iter 34000, loss: 0.004380
 >> iter 35000, loss: 0.004161
 >> iter 36000, loss: 0.003982
 >> iter 37000, loss: 0.003797
 >> iter 38000, loss: 0.003648
 >> iter 39000, loss: 0.003490
 >> iter 40000, loss: 0.003364
   Number of active neurons: 12
 >> iter 41000, loss: 0.003226
 >> iter 42000, loss: 0.003117
 >> iter 43000, loss: 0.002998
 >> iter 44000, loss: 0.002903
 >> iter 45000, loss: 0.002798
 >> iter 46000, loss: 0.002715
 >> iter 47000, loss: 0.002621
 >> iter 48000, loss: 0.002549
 >> iter 49000, loss: 0.002465
 >> iter 50000, loss: 0.002401
   Number of active neurons: 12
 >> iter 51000, loss: 0.002325
 >> iter 52000, loss: 0.002268
 >> iter 53000, loss: 0.002198
 >> iter 54000, loss: 0.002148
 >> iter 55000, loss: 0.002085
 >> iter 56000, loss: 0.002040
 >> iter 57000, loss: 0.001981
 >> iter 58000, loss: 0.001942
 >> iter 59000, loss: 0.001888
 >> iter 60000, loss: 0.001852
   Number of active neurons: 12
 >> iter 61000, loss: 0.001802
 >> iter 62000, loss: 0.001770
 >> iter 63000, loss: 0.001722
 >> iter 64000, loss: 0.001693
 >> iter 65000, loss: 0.001650
 >> iter 66000, loss: 0.001623
 >> iter 67000, loss: 0.001584
 >> iter 68000, loss: 0.001559
 >> iter 69000, loss: 0.001522
 >> iter 70000, loss: 0.001498
   Number of active neurons: 12
 >> iter 71000, loss: 0.001464
 >> iter 72000, loss: 0.001442
 >> iter 73000, loss: 0.001410
 >> iter 74000, loss: 0.001391
 >> iter 75000, loss: 0.001360
 >> iter 76000, loss: 0.001342
 >> iter 77000, loss: 0.001313
 >> iter 78000, loss: 0.001297
 >> iter 79000, loss: 0.001269
 >> iter 80000, loss: 0.001254
   Number of active neurons: 12
 >> iter 81000, loss: 0.001228
 >> iter 82000, loss: 0.001214
 >> iter 83000, loss: 0.001189
 >> iter 84000, loss: 0.001176
 >> iter 85000, loss: 0.001153
 >> iter 86000, loss: 0.001140
 >> iter 87000, loss: 0.001118
 >> iter 88000, loss: 0.001107
 >> iter 89000, loss: 0.001085
 >> iter 90000, loss: 0.001075
   Number of active neurons: 12
 >> iter 91000, loss: 0.001055
 >> iter 92000, loss: 0.001045
 >> iter 93000, loss: 0.001026
 >> iter 94000, loss: 0.001016
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

