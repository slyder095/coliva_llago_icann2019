 > Problema: tomita2nueva
 > Args:
   - Hidden size: 12
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.471436
 >> iter 2000, loss: 4.473234
 >> iter 3000, loss: 1.740649
 >> iter 4000, loss: 0.731243
 >> iter 5000, loss: 0.329890
 >> iter 6000, loss: 0.168080
 >> iter 7000, loss: 0.114639
 >> iter 8000, loss: 0.107999
 >> iter 9000, loss: 0.088604
 >> iter 10000, loss: 0.080508
   Number of active neurons: 7
 >> iter 11000, loss: 0.063058
 >> iter 12000, loss: 0.071572
 >> iter 13000, loss: 0.060883
 >> iter 14000, loss: 0.061937
 >> iter 15000, loss: 0.074110
 >> iter 16000, loss: 0.076320
 >> iter 17000, loss: 0.068503
 >> iter 18000, loss: 0.046210
 >> iter 19000, loss: 0.073198
 >> iter 20000, loss: 0.052741
   Number of active neurons: 6
 >> iter 21000, loss: 0.055427
 >> iter 22000, loss: 0.043011
 >> iter 23000, loss: 0.053431
 >> iter 24000, loss: 0.045664
 >> iter 25000, loss: 0.045402
 >> iter 26000, loss: 0.049232
 >> iter 27000, loss: 0.050231
 >> iter 28000, loss: 0.049589
 >> iter 29000, loss: 0.057681
 >> iter 30000, loss: 0.046926
   Number of active neurons: 5
 >> iter 31000, loss: 0.075419
 >> iter 32000, loss: 0.054223
 >> iter 33000, loss: 0.050401
 >> iter 34000, loss: 0.040977
 >> iter 35000, loss: 0.043241
 >> iter 36000, loss: 0.037575
 >> iter 37000, loss: 0.037325
 >> iter 38000, loss: 0.049056
 >> iter 39000, loss: 0.041325
 >> iter 40000, loss: 0.043915
   Number of active neurons: 4
 >> iter 41000, loss: 0.039956
 >> iter 42000, loss: 0.047406
 >> iter 43000, loss: 0.052145
 >> iter 44000, loss: 0.049181
 >> iter 45000, loss: 0.066309
 >> iter 46000, loss: 0.065436
 >> iter 47000, loss: 0.064363
 >> iter 48000, loss: 0.047934
 >> iter 49000, loss: 0.058373
 >> iter 50000, loss: 0.049679
   Number of active neurons: 4
 >> iter 51000, loss: 0.070856
 >> iter 52000, loss: 0.070291
 >> iter 53000, loss: 0.049062
 >> iter 54000, loss: 0.044383
 >> iter 55000, loss: 0.057769
 >> iter 56000, loss: 0.051306
 >> iter 57000, loss: 0.046688
 >> iter 58000, loss: 0.042658
 >> iter 59000, loss: 0.054534
 >> iter 60000, loss: 0.051330
   Number of active neurons: 3
 >> iter 61000, loss: 0.041888
 >> iter 62000, loss: 0.042341
 >> iter 63000, loss: 0.038544
 >> iter 64000, loss: 0.042944
 >> iter 65000, loss: 0.040607
 >> iter 66000, loss: 0.048662
 >> iter 67000, loss: 0.038106
 >> iter 68000, loss: 0.035726
 >> iter 69000, loss: 0.036615
 >> iter 70000, loss: 0.046392
   Number of active neurons: 3
 >> iter 71000, loss: 0.060906
 >> iter 72000, loss: 0.046489
 >> iter 73000, loss: 0.042510
 >> iter 74000, loss: 0.035184
 >> iter 75000, loss: 0.061792
 >> iter 76000, loss: 0.057146
 >> iter 77000, loss: 0.060733
 >> iter 78000, loss: 0.050139
 >> iter 79000, loss: 0.038534
 >> iter 80000, loss: 0.048861
   Number of active neurons: 3
 >> iter 81000, loss: 0.070700
 >> iter 82000, loss: 0.049840
 >> iter 83000, loss: 0.046337
 >> iter 84000, loss: 0.042953
 >> iter 85000, loss: 0.054005
 >> iter 86000, loss: 0.057131
 >> iter 87000, loss: 0.051917
 >> iter 88000, loss: 0.048594
 >> iter 89000, loss: 0.062673
 >> iter 90000, loss: 0.058842
   Number of active neurons: 3
 >> iter 91000, loss: 0.044763
 >> iter 92000, loss: 0.063464
 >> iter 93000, loss: 0.073463
 >> iter 94000, loss: 0.065633
 >> iter 95000, loss: 0.053580
 >> iter 96000, loss: 0.042719
 >> iter 97000, loss: 0.034519
 >> iter 98000, loss: 0.042688
 >> iter 99000, loss: 0.042631
 >> iter 100000, loss: 0.046006
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.300780
 >> iter 2000, loss: 4.405191
 >> iter 3000, loss: 1.735568
 >> iter 4000, loss: 0.718989
 >> iter 5000, loss: 0.338039
 >> iter 6000, loss: 0.195634
 >> iter 7000, loss: 0.117839
 >> iter 8000, loss: 0.086286
 >> iter 9000, loss: 0.085901
 >> iter 10000, loss: 0.070978
   Number of active neurons: 8
 >> iter 11000, loss: 0.081034
 >> iter 12000, loss: 0.077033
 >> iter 13000, loss: 0.060900
 >> iter 14000, loss: 0.060624
 >> iter 15000, loss: 0.065005
 >> iter 16000, loss: 0.067872
 >> iter 17000, loss: 0.056829
 >> iter 18000, loss: 0.061552
 >> iter 19000, loss: 0.050668
 >> iter 20000, loss: 0.050769
   Number of active neurons: 7
 >> iter 21000, loss: 0.064673
 >> iter 22000, loss: 0.054421
 >> iter 23000, loss: 0.080462
 >> iter 24000, loss: 0.058557
 >> iter 25000, loss: 0.052008
 >> iter 26000, loss: 0.059913
 >> iter 27000, loss: 0.061405
 >> iter 28000, loss: 0.064210
 >> iter 29000, loss: 0.061573
 >> iter 30000, loss: 0.047947
   Number of active neurons: 5
 >> iter 31000, loss: 0.048384
 >> iter 32000, loss: 0.058991
 >> iter 33000, loss: 0.044515
 >> iter 34000, loss: 0.049055
 >> iter 35000, loss: 0.047271
 >> iter 36000, loss: 0.045092
 >> iter 37000, loss: 0.038010
 >> iter 38000, loss: 0.036296
 >> iter 39000, loss: 0.059841
 >> iter 40000, loss: 0.049543
   Number of active neurons: 5
 >> iter 41000, loss: 0.043713
 >> iter 42000, loss: 0.037389
 >> iter 43000, loss: 0.043101
 >> iter 44000, loss: 0.045195
 >> iter 45000, loss: 0.056168
 >> iter 46000, loss: 0.060029
 >> iter 47000, loss: 0.060753
 >> iter 48000, loss: 0.050092
 >> iter 49000, loss: 0.067244
 >> iter 50000, loss: 0.052505
   Number of active neurons: 4
 >> iter 51000, loss: 0.042997
 >> iter 52000, loss: 0.055518
 >> iter 53000, loss: 0.055500
 >> iter 54000, loss: 0.048923
 >> iter 55000, loss: 0.043812
 >> iter 56000, loss: 0.035224
 >> iter 57000, loss: 0.035662
 >> iter 58000, loss: 0.048440
 >> iter 59000, loss: 0.043422
 >> iter 60000, loss: 0.051433
   Number of active neurons: 4
 >> iter 61000, loss: 0.053784
 >> iter 62000, loss: 0.060779
 >> iter 63000, loss: 0.047106
 >> iter 64000, loss: 0.057876
 >> iter 65000, loss: 0.058303
 >> iter 66000, loss: 0.063393
 >> iter 67000, loss: 0.072544
 >> iter 68000, loss: 0.060641
 >> iter 69000, loss: 0.048939
 >> iter 70000, loss: 0.049504
   Number of active neurons: 3
 >> iter 71000, loss: 0.066381
 >> iter 72000, loss: 0.043170
 >> iter 73000, loss: 0.039302
 >> iter 74000, loss: 0.055357
 >> iter 75000, loss: 0.054038
 >> iter 76000, loss: 0.058917
 >> iter 77000, loss: 0.054509
 >> iter 78000, loss: 0.048245
 >> iter 79000, loss: 0.039420
 >> iter 80000, loss: 0.054527
   Number of active neurons: 3
 >> iter 81000, loss: 0.051417
 >> iter 82000, loss: 0.060654
 >> iter 83000, loss: 0.053292
 >> iter 84000, loss: 0.054828
 >> iter 85000, loss: 0.050649
 >> iter 86000, loss: 0.040517
 >> iter 87000, loss: 0.045961
 >> iter 88000, loss: 0.036884
 >> iter 89000, loss: 0.045944
 >> iter 90000, loss: 0.058252
   Number of active neurons: 3
 >> iter 91000, loss: 0.044548
 >> iter 92000, loss: 0.044090
 >> iter 93000, loss: 0.051427
 >> iter 94000, loss: 0.051725
 >> iter 95000, loss: 0.036164
 >> iter 96000, loss: 0.058130
 >> iter 97000, loss: 0.053028
 >> iter 98000, loss: 0.051716
 >> iter 99000, loss: 0.045127
 >> iter 100000, loss: 0.039102
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.332584
 >> iter 2000, loss: 4.377863
 >> iter 3000, loss: 1.736548
 >> iter 4000, loss: 0.717763
 >> iter 5000, loss: 0.312765
 >> iter 6000, loss: 0.186490
 >> iter 7000, loss: 0.115350
 >> iter 8000, loss: 0.104068
 >> iter 9000, loss: 0.070562
 >> iter 10000, loss: 0.065201
   Number of active neurons: 8
 >> iter 11000, loss: 0.068948
 >> iter 12000, loss: 0.052476
 >> iter 13000, loss: 0.046117
 >> iter 14000, loss: 0.054724
 >> iter 15000, loss: 0.054437
 >> iter 16000, loss: 0.059401
 >> iter 17000, loss: 0.060390
 >> iter 18000, loss: 0.056003
 >> iter 19000, loss: 0.067779
 >> iter 20000, loss: 0.080096
   Number of active neurons: 6
 >> iter 21000, loss: 0.061381
 >> iter 22000, loss: 0.058278
 >> iter 23000, loss: 0.063625
 >> iter 24000, loss: 0.078145
 >> iter 25000, loss: 0.063443
 >> iter 26000, loss: 0.052730
 >> iter 27000, loss: 0.042314
 >> iter 28000, loss: 0.046029
 >> iter 29000, loss: 0.061710
 >> iter 30000, loss: 0.065982
   Number of active neurons: 6
 >> iter 31000, loss: 0.066781
 >> iter 32000, loss: 0.047144
 >> iter 33000, loss: 0.043721
 >> iter 34000, loss: 0.046517
 >> iter 35000, loss: 0.055052
 >> iter 36000, loss: 0.054706
 >> iter 37000, loss: 0.057800
 >> iter 38000, loss: 0.080530
 >> iter 39000, loss: 0.059632
 >> iter 40000, loss: 0.065050
   Number of active neurons: 5
 >> iter 41000, loss: 0.058702
 >> iter 42000, loss: 0.043984
 >> iter 43000, loss: 0.055129
 >> iter 44000, loss: 0.051004
 >> iter 45000, loss: 0.042474
 >> iter 46000, loss: 0.046113
 >> iter 47000, loss: 0.052824
 >> iter 48000, loss: 0.055058
 >> iter 49000, loss: 0.048183
 >> iter 50000, loss: 0.046290
   Number of active neurons: 5
 >> iter 51000, loss: 0.050416
 >> iter 52000, loss: 0.071415
 >> iter 53000, loss: 0.069861
 >> iter 54000, loss: 0.057473
 >> iter 55000, loss: 0.068485
 >> iter 56000, loss: 0.048933
 >> iter 57000, loss: 0.076195
 >> iter 58000, loss: 0.049178
 >> iter 59000, loss: 0.043812
 >> iter 60000, loss: 0.050851
   Number of active neurons: 3
 >> iter 61000, loss: 0.058790
 >> iter 62000, loss: 0.050164
 >> iter 63000, loss: 0.044548
 >> iter 64000, loss: 0.042764
 >> iter 65000, loss: 0.051744
 >> iter 66000, loss: 0.055660
 >> iter 67000, loss: 0.044204
 >> iter 68000, loss: 0.032639
 >> iter 69000, loss: 0.033498
 >> iter 70000, loss: 0.041095
   Number of active neurons: 2
 >> iter 71000, loss: 0.046796
 >> iter 72000, loss: 0.046059
 >> iter 73000, loss: 0.061196
 >> iter 74000, loss: 0.049036
 >> iter 75000, loss: 0.055782
 >> iter 76000, loss: 0.064748
 >> iter 77000, loss: 0.067867
 >> iter 78000, loss: 0.083102
 >> iter 79000, loss: 0.064063
 >> iter 80000, loss: 0.048019
   Number of active neurons: 2
 >> iter 81000, loss: 0.034568
 >> iter 82000, loss: 0.035403
 >> iter 83000, loss: 0.042005
 >> iter 84000, loss: 0.037001
 >> iter 85000, loss: 0.053574
 >> iter 86000, loss: 0.055946
 >> iter 87000, loss: 0.053561
 >> iter 88000, loss: 0.045401
 >> iter 89000, loss: 0.049967
 >> iter 90000, loss: 0.040485
   Number of active neurons: 2
 >> iter 91000, loss: 0.031682
 >> iter 92000, loss: 0.034443
 >> iter 93000, loss: 0.035039
 >> iter 94000, loss: 0.042832
 >> iter 95000, loss: 0.030748
 >> iter 96000, loss: 0.043329
 >> iter 97000, loss: 0.035054
 >> iter 98000, loss: 0.039520
 >> iter 99000, loss: 0.047599
 >> iter 100000, loss: 0.036233
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 11.314271
 >> iter 2000, loss: 4.356966
 >> iter 3000, loss: 1.704287
 >> iter 4000, loss: 0.703663
 >> iter 5000, loss: 0.334425
 >> iter 6000, loss: 0.168473
 >> iter 7000, loss: 0.136495
 >> iter 8000, loss: 0.077337
 >> iter 9000, loss: 0.056644
 >> iter 10000, loss: 0.057926
   Number of active neurons: 7
 >> iter 11000, loss: 0.054074
 >> iter 12000, loss: 0.104670
 >> iter 13000, loss: 0.076195
 >> iter 14000, loss: 0.073599
 >> iter 15000, loss: 0.079474
 >> iter 16000, loss: 0.094296
 >> iter 17000, loss: 0.084119
 >> iter 18000, loss: 0.058562
 >> iter 19000, loss: 0.051897
 >> iter 20000, loss: 0.053912
   Number of active neurons: 5
 >> iter 21000, loss: 0.073986
 >> iter 22000, loss: 0.073515
 >> iter 23000, loss: 0.048618
 >> iter 24000, loss: 0.048788
 >> iter 25000, loss: 0.062591
 >> iter 26000, loss: 0.056872
 >> iter 27000, loss: 0.055454
 >> iter 28000, loss: 0.082984
 >> iter 29000, loss: 0.061333
 >> iter 30000, loss: 0.050427
   Number of active neurons: 5
 >> iter 31000, loss: 0.069091
 >> iter 32000, loss: 0.049206
 >> iter 33000, loss: 0.076782
 >> iter 34000, loss: 0.073721
 >> iter 35000, loss: 0.059449
 >> iter 36000, loss: 0.069482
 >> iter 37000, loss: 0.043246
 >> iter 38000, loss: 0.062870
 >> iter 39000, loss: 0.054697
 >> iter 40000, loss: 0.064654
   Number of active neurons: 4
 >> iter 41000, loss: 0.069092
 >> iter 42000, loss: 0.062500
 >> iter 43000, loss: 0.047562
 >> iter 44000, loss: 0.046893
 >> iter 45000, loss: 0.041651
 >> iter 46000, loss: 0.058663
 >> iter 47000, loss: 0.043380
 >> iter 48000, loss: 0.057168
 >> iter 49000, loss: 0.045644
 >> iter 50000, loss: 0.045047
   Number of active neurons: 4
 >> iter 51000, loss: 0.039930
 >> iter 52000, loss: 0.047520
 >> iter 53000, loss: 0.052019
 >> iter 54000, loss: 0.055815
 >> iter 55000, loss: 0.050820
 >> iter 56000, loss: 0.048841
 >> iter 57000, loss: 0.038856
 >> iter 58000, loss: 0.040805
 >> iter 59000, loss: 0.039078
 >> iter 60000, loss: 0.045484
   Number of active neurons: 4
 >> iter 61000, loss: 0.036380
 >> iter 62000, loss: 0.046140
 >> iter 63000, loss: 0.040057
 >> iter 64000, loss: 0.045463
 >> iter 65000, loss: 0.052383
 >> iter 66000, loss: 0.062490
 >> iter 67000, loss: 0.071285
 >> iter 68000, loss: 0.061329
 >> iter 69000, loss: 0.057519
 >> iter 70000, loss: 0.049001
   Number of active neurons: 4
 >> iter 71000, loss: 0.043880
 >> iter 72000, loss: 0.052866
 >> iter 73000, loss: 0.064813
 >> iter 74000, loss: 0.051574
 >> iter 75000, loss: 0.065234
 >> iter 76000, loss: 0.057497
 >> iter 77000, loss: 0.041103
 >> iter 78000, loss: 0.038033
 >> iter 79000, loss: 0.051124
 >> iter 80000, loss: 0.051585
   Number of active neurons: 3
 >> iter 81000, loss: 0.044293
 >> iter 82000, loss: 0.031291
 >> iter 83000, loss: 0.041014
 >> iter 84000, loss: 0.050381
 >> iter 85000, loss: 0.061285
 >> iter 86000, loss: 0.060851
 >> iter 87000, loss: 0.051789
 >> iter 88000, loss: 0.042923
 >> iter 89000, loss: 0.041829
 >> iter 90000, loss: 0.035424
   Number of active neurons: 3
 >> iter 91000, loss: 0.037179
 >> iter 92000, loss: 0.030659
 >> iter 93000, loss: 0.041351
 >> iter 94000, loss: 0.054526
 >> iter 95000, loss: 0.077810
 >> iter 96000, loss: 0.046396
 >> iter 97000, loss: 0.051168
 >> iter 98000, loss: 0.045716
 >> iter 99000, loss: 0.033423
 >> iter 100000, loss: 0.042128
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.326099
 >> iter 2000, loss: 4.385062
 >> iter 3000, loss: 1.725592
 >> iter 4000, loss: 0.705947
 >> iter 5000, loss: 0.304002
 >> iter 6000, loss: 0.186731
 >> iter 7000, loss: 0.130444
 >> iter 8000, loss: 0.094917
 >> iter 9000, loss: 0.112713
 >> iter 10000, loss: 0.081524
   Number of active neurons: 8
 >> iter 11000, loss: 0.078113
 >> iter 12000, loss: 0.086676
 >> iter 13000, loss: 0.073825
 >> iter 14000, loss: 0.084101
 >> iter 15000, loss: 0.066520
 >> iter 16000, loss: 0.066294
 >> iter 17000, loss: 0.066695
 >> iter 18000, loss: 0.070355
 >> iter 19000, loss: 0.050030
 >> iter 20000, loss: 0.064105
   Number of active neurons: 7
 >> iter 21000, loss: 0.087769
 >> iter 22000, loss: 0.065936
 >> iter 23000, loss: 0.056743
 >> iter 24000, loss: 0.061831
 >> iter 25000, loss: 0.054853
 >> iter 26000, loss: 0.058179
 >> iter 27000, loss: 0.074618
 >> iter 28000, loss: 0.052396
 >> iter 29000, loss: 0.055537
 >> iter 30000, loss: 0.062336
   Number of active neurons: 6
 >> iter 31000, loss: 0.056010
 >> iter 32000, loss: 0.055219
 >> iter 33000, loss: 0.045899
 >> iter 34000, loss: 0.052828
 >> iter 35000, loss: 0.057305
 >> iter 36000, loss: 0.057333
 >> iter 37000, loss: 0.050302
 >> iter 38000, loss: 0.041655
 >> iter 39000, loss: 0.051025
 >> iter 40000, loss: 0.057117
   Number of active neurons: 5
 >> iter 41000, loss: 0.050387
 >> iter 42000, loss: 0.043277
 >> iter 43000, loss: 0.040320
 >> iter 44000, loss: 0.045467
 >> iter 45000, loss: 0.041031
 >> iter 46000, loss: 0.053019
 >> iter 47000, loss: 0.055422
 >> iter 48000, loss: 0.059159
 >> iter 49000, loss: 0.055011
 >> iter 50000, loss: 0.060179
   Number of active neurons: 3
 >> iter 51000, loss: 0.050352
 >> iter 52000, loss: 0.053651
 >> iter 53000, loss: 0.039617
 >> iter 54000, loss: 0.050878
 >> iter 55000, loss: 0.049041
 >> iter 56000, loss: 0.040265
 >> iter 57000, loss: 0.045027
 >> iter 58000, loss: 0.054018
 >> iter 59000, loss: 0.040934
 >> iter 60000, loss: 0.063263
   Number of active neurons: 3
 >> iter 61000, loss: 0.057718
 >> iter 62000, loss: 0.037485
 >> iter 63000, loss: 0.046275
 >> iter 64000, loss: 0.050778
 >> iter 65000, loss: 0.049308
 >> iter 66000, loss: 0.043703
 >> iter 67000, loss: 0.038449
 >> iter 68000, loss: 0.049612
 >> iter 69000, loss: 0.066961
 >> iter 70000, loss: 0.051100
   Number of active neurons: 3
 >> iter 71000, loss: 0.054708
 >> iter 72000, loss: 0.042423
 >> iter 73000, loss: 0.049136
 >> iter 74000, loss: 0.061225
 >> iter 75000, loss: 0.046909
 >> iter 76000, loss: 0.047722
 >> iter 77000, loss: 0.057589
 >> iter 78000, loss: 0.039808
 >> iter 79000, loss: 0.079210
 >> iter 80000, loss: 0.047514
   Number of active neurons: 3
 >> iter 81000, loss: 0.046771
 >> iter 82000, loss: 0.053978
 >> iter 83000, loss: 0.045446
 >> iter 84000, loss: 0.047156
 >> iter 85000, loss: 0.051765
 >> iter 86000, loss: 0.058436
 >> iter 87000, loss: 0.047503
 >> iter 88000, loss: 0.043137
 >> iter 89000, loss: 0.060197
 >> iter 90000, loss: 0.045798
   Number of active neurons: 3
 >> iter 91000, loss: 0.043987
 >> iter 92000, loss: 0.034613
 >> iter 93000, loss: 0.035118
 >> iter 94000, loss: 0.040296
 >> iter 95000, loss: 0.039409
 >> iter 96000, loss: 0.055492
 >> iter 97000, loss: 0.052418
 >> iter 98000, loss: 0.057888
 >> iter 99000, loss: 0.043192
 >> iter 100000, loss: 0.042437
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.302933
 >> iter 2000, loss: 4.398716
 >> iter 3000, loss: 1.720432
 >> iter 4000, loss: 0.697254
 >> iter 5000, loss: 0.324417
 >> iter 6000, loss: 0.174350
 >> iter 7000, loss: 0.112150
 >> iter 8000, loss: 0.109327
 >> iter 9000, loss: 0.080732
 >> iter 10000, loss: 0.061333
   Number of active neurons: 8
 >> iter 11000, loss: 0.073716
 >> iter 12000, loss: 0.072375
 >> iter 13000, loss: 0.072446
 >> iter 14000, loss: 0.059428
 >> iter 15000, loss: 0.058093
 >> iter 16000, loss: 0.041972
 >> iter 17000, loss: 0.049779
 >> iter 18000, loss: 0.054038
 >> iter 19000, loss: 0.051962
 >> iter 20000, loss: 0.057772
   Number of active neurons: 7
 >> iter 21000, loss: 0.077566
 >> iter 22000, loss: 0.078859
 >> iter 23000, loss: 0.063889
 >> iter 24000, loss: 0.052019
 >> iter 25000, loss: 0.067906
 >> iter 26000, loss: 0.068034
 >> iter 27000, loss: 0.058654
 >> iter 28000, loss: 0.047324
 >> iter 29000, loss: 0.062928
 >> iter 30000, loss: 0.065831
   Number of active neurons: 7
 >> iter 31000, loss: 0.054758
 >> iter 32000, loss: 0.048790
 >> iter 33000, loss: 0.048458
 >> iter 34000, loss: 0.048160
 >> iter 35000, loss: 0.051879
 >> iter 36000, loss: 0.055065
 >> iter 37000, loss: 0.069150
 >> iter 38000, loss: 0.051919
 >> iter 39000, loss: 0.046871
 >> iter 40000, loss: 0.060842
   Number of active neurons: 5
 >> iter 41000, loss: 0.043203
 >> iter 42000, loss: 0.046040
 >> iter 43000, loss: 0.059652
 >> iter 44000, loss: 0.051673
 >> iter 45000, loss: 0.039573
 >> iter 46000, loss: 0.046435
 >> iter 47000, loss: 0.048467
 >> iter 48000, loss: 0.078647
 >> iter 49000, loss: 0.076063
 >> iter 50000, loss: 0.063469
   Number of active neurons: 5
 >> iter 51000, loss: 0.056521
 >> iter 52000, loss: 0.049469
 >> iter 53000, loss: 0.064058
 >> iter 54000, loss: 0.053583
 >> iter 55000, loss: 0.044934
 >> iter 56000, loss: 0.036944
 >> iter 57000, loss: 0.041902
 >> iter 58000, loss: 0.035073
 >> iter 59000, loss: 0.045380
 >> iter 60000, loss: 0.047227
   Number of active neurons: 4
 >> iter 61000, loss: 0.059524
 >> iter 62000, loss: 0.055476
 >> iter 63000, loss: 0.045257
 >> iter 64000, loss: 0.055854
 >> iter 65000, loss: 0.058312
 >> iter 66000, loss: 0.045187
 >> iter 67000, loss: 0.042625
 >> iter 68000, loss: 0.041701
 >> iter 69000, loss: 0.034201
 >> iter 70000, loss: 0.035652
   Number of active neurons: 4
 >> iter 71000, loss: 0.038062
 >> iter 72000, loss: 0.052839
 >> iter 73000, loss: 0.056867
 >> iter 74000, loss: 0.045020
 >> iter 75000, loss: 0.075153
 >> iter 76000, loss: 0.065112
 >> iter 77000, loss: 0.047157
 >> iter 78000, loss: 0.034850
 >> iter 79000, loss: 0.053533
 >> iter 80000, loss: 0.066498
   Number of active neurons: 4
 >> iter 81000, loss: 0.045232
 >> iter 82000, loss: 0.034376
 >> iter 83000, loss: 0.034435
 >> iter 84000, loss: 0.059696
 >> iter 85000, loss: 0.046360
 >> iter 86000, loss: 0.042071
 >> iter 87000, loss: 0.053365
 >> iter 88000, loss: 0.038418
 >> iter 89000, loss: 0.036193
 >> iter 90000, loss: 0.030162
   Number of active neurons: 4
 >> iter 91000, loss: 0.056623
 >> iter 92000, loss: 0.055172
 >> iter 93000, loss: 0.046265
 >> iter 94000, loss: 0.049225
 >> iter 95000, loss: 0.064101
 >> iter 96000, loss: 0.052500
 >> iter 97000, loss: 0.042169
 >> iter 98000, loss: 0.042986
 >> iter 99000, loss: 0.049105
 >> iter 100000, loss: 0.057410
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.406192
 >> iter 2000, loss: 4.455597
 >> iter 3000, loss: 1.769408
 >> iter 4000, loss: 0.738970
 >> iter 5000, loss: 0.347548
 >> iter 6000, loss: 0.182250
 >> iter 7000, loss: 0.122025
 >> iter 8000, loss: 0.081901
 >> iter 9000, loss: 0.106147
 >> iter 10000, loss: 0.079399
   Number of active neurons: 7
 >> iter 11000, loss: 0.073282
 >> iter 12000, loss: 0.060819
 >> iter 13000, loss: 0.084592
 >> iter 14000, loss: 0.085949
 >> iter 15000, loss: 0.069039
 >> iter 16000, loss: 0.073774
 >> iter 17000, loss: 0.067602
 >> iter 18000, loss: 0.074908
 >> iter 19000, loss: 0.061490
 >> iter 20000, loss: 0.064266
   Number of active neurons: 7
 >> iter 21000, loss: 0.055144
 >> iter 22000, loss: 0.049822
 >> iter 23000, loss: 0.044731
 >> iter 24000, loss: 0.064782
 >> iter 25000, loss: 0.071623
 >> iter 26000, loss: 0.047086
 >> iter 27000, loss: 0.044754
 >> iter 28000, loss: 0.050642
 >> iter 29000, loss: 0.053215
 >> iter 30000, loss: 0.054463
   Number of active neurons: 5
 >> iter 31000, loss: 0.056995
 >> iter 32000, loss: 0.042594
 >> iter 33000, loss: 0.087500
 >> iter 34000, loss: 0.069263
 >> iter 35000, loss: 0.060571
 >> iter 36000, loss: 0.071056
 >> iter 37000, loss: 0.048632
 >> iter 38000, loss: 0.049520
 >> iter 39000, loss: 0.043223
 >> iter 40000, loss: 0.045968
   Number of active neurons: 4
 >> iter 41000, loss: 0.048231
 >> iter 42000, loss: 0.048939
 >> iter 43000, loss: 0.041693
 >> iter 44000, loss: 0.049327
 >> iter 45000, loss: 0.037321
 >> iter 46000, loss: 0.034258
 >> iter 47000, loss: 0.046619
 >> iter 48000, loss: 0.053731
 >> iter 49000, loss: 0.068586
 >> iter 50000, loss: 0.063597
   Number of active neurons: 4
 >> iter 51000, loss: 0.043436
 >> iter 52000, loss: 0.046095
 >> iter 53000, loss: 0.049456
 >> iter 54000, loss: 0.038058
 >> iter 55000, loss: 0.061718
 >> iter 56000, loss: 0.043968
 >> iter 57000, loss: 0.039338
 >> iter 58000, loss: 0.052994
 >> iter 59000, loss: 0.047408
 >> iter 60000, loss: 0.045092
   Number of active neurons: 4
 >> iter 61000, loss: 0.054363
 >> iter 62000, loss: 0.043644
 >> iter 63000, loss: 0.047450
 >> iter 64000, loss: 0.044055
 >> iter 65000, loss: 0.063119
 >> iter 66000, loss: 0.046845
 >> iter 67000, loss: 0.052370
 >> iter 68000, loss: 0.038812
 >> iter 69000, loss: 0.062415
 >> iter 70000, loss: 0.045505
   Number of active neurons: 4
 >> iter 71000, loss: 0.069521
 >> iter 72000, loss: 0.053144
 >> iter 73000, loss: 0.042826
 >> iter 74000, loss: 0.039682
 >> iter 75000, loss: 0.065330
 >> iter 76000, loss: 0.054966
 >> iter 77000, loss: 0.070825
 >> iter 78000, loss: 0.056719
 >> iter 79000, loss: 0.065486
 >> iter 80000, loss: 0.059825
   Number of active neurons: 4
 >> iter 81000, loss: 0.053848
 >> iter 82000, loss: 0.039869
 >> iter 83000, loss: 0.039571
 >> iter 84000, loss: 0.048545
 >> iter 85000, loss: 0.049393
 >> iter 86000, loss: 0.053429
 >> iter 87000, loss: 0.052369
 >> iter 88000, loss: 0.052162
 >> iter 89000, loss: 0.047983
 >> iter 90000, loss: 0.052313
   Number of active neurons: 4
 >> iter 91000, loss: 0.071789
 >> iter 92000, loss: 0.071986
 >> iter 93000, loss: 0.088757
 >> iter 94000, loss: 0.060773
 >> iter 95000, loss: 0.053205
 >> iter 96000, loss: 0.047816
 >> iter 97000, loss: 0.050561
 >> iter 98000, loss: 0.041692
 >> iter 99000, loss: 0.036735
 >> iter 100000, loss: 0.041226
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.346342
 >> iter 2000, loss: 4.459330
 >> iter 3000, loss: 1.776515
 >> iter 4000, loss: 0.746978
 >> iter 5000, loss: 0.356693
 >> iter 6000, loss: 0.194536
 >> iter 7000, loss: 0.149566
 >> iter 8000, loss: 0.126646
 >> iter 9000, loss: 0.093822
 >> iter 10000, loss: 0.106387
   Number of active neurons: 11
 >> iter 11000, loss: 0.106349
 >> iter 12000, loss: 0.094581
 >> iter 13000, loss: 0.078504
 >> iter 14000, loss: 0.066962
 >> iter 15000, loss: 0.074320
 >> iter 16000, loss: 0.077193
 >> iter 17000, loss: 0.088892
 >> iter 18000, loss: 0.077410
 >> iter 19000, loss: 0.067633
 >> iter 20000, loss: 0.056966
   Number of active neurons: 9
 >> iter 21000, loss: 0.091253
 >> iter 22000, loss: 0.082817
 >> iter 23000, loss: 0.089904
 >> iter 24000, loss: 0.060598
 >> iter 25000, loss: 0.053012
 >> iter 26000, loss: 0.064706
 >> iter 27000, loss: 0.048349
 >> iter 28000, loss: 0.062429
 >> iter 29000, loss: 0.051131
 >> iter 30000, loss: 0.045592
   Number of active neurons: 6
 >> iter 31000, loss: 0.045028
 >> iter 32000, loss: 0.064010
 >> iter 33000, loss: 0.053461
 >> iter 34000, loss: 0.064271
 >> iter 35000, loss: 0.049475
 >> iter 36000, loss: 0.059142
 >> iter 37000, loss: 0.068568
 >> iter 38000, loss: 0.068841
 >> iter 39000, loss: 0.050105
 >> iter 40000, loss: 0.044311
   Number of active neurons: 4
 >> iter 41000, loss: 0.046483
 >> iter 42000, loss: 0.050259
 >> iter 43000, loss: 0.046358
 >> iter 44000, loss: 0.046913
 >> iter 45000, loss: 0.046884
 >> iter 46000, loss: 0.051693
 >> iter 47000, loss: 0.042936
 >> iter 48000, loss: 0.048219
 >> iter 49000, loss: 0.050990
 >> iter 50000, loss: 0.060539
   Number of active neurons: 4
 >> iter 51000, loss: 0.044019
 >> iter 52000, loss: 0.063447
 >> iter 53000, loss: 0.057466
 >> iter 54000, loss: 0.065208
 >> iter 55000, loss: 0.053154
 >> iter 56000, loss: 0.052316
 >> iter 57000, loss: 0.041884
 >> iter 58000, loss: 0.049014
 >> iter 59000, loss: 0.050906
 >> iter 60000, loss: 0.037067
   Number of active neurons: 4
 >> iter 61000, loss: 0.030994
 >> iter 62000, loss: 0.059422
 >> iter 63000, loss: 0.048221
 >> iter 64000, loss: 0.058833
 >> iter 65000, loss: 0.051871
 >> iter 66000, loss: 0.040695
 >> iter 67000, loss: 0.042178
 >> iter 68000, loss: 0.044730
 >> iter 69000, loss: 0.056183
 >> iter 70000, loss: 0.042495
   Number of active neurons: 4
 >> iter 71000, loss: 0.039314
 >> iter 72000, loss: 0.054862
 >> iter 73000, loss: 0.053648
 >> iter 74000, loss: 0.064252
 >> iter 75000, loss: 0.055750
 >> iter 76000, loss: 0.047161
 >> iter 77000, loss: 0.054698
 >> iter 78000, loss: 0.046007
 >> iter 79000, loss: 0.052307
 >> iter 80000, loss: 0.048836
   Number of active neurons: 4
 >> iter 81000, loss: 0.041274
 >> iter 82000, loss: 0.055346
 >> iter 83000, loss: 0.042516
 >> iter 84000, loss: 0.053240
 >> iter 85000, loss: 0.039456
 >> iter 86000, loss: 0.057984
 >> iter 87000, loss: 0.046687
 >> iter 88000, loss: 0.057746
 >> iter 89000, loss: 0.055596
 >> iter 90000, loss: 0.040829
   Number of active neurons: 4
 >> iter 91000, loss: 0.034441
 >> iter 92000, loss: 0.041442
 >> iter 93000, loss: 0.041178
 >> iter 94000, loss: 0.044636
 >> iter 95000, loss: 0.049233
 >> iter 96000, loss: 0.048270
 >> iter 97000, loss: 0.045511
 >> iter 98000, loss: 0.033504
 >> iter 99000, loss: 0.034849
 >> iter 100000, loss: 0.034569
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.396948
 >> iter 2000, loss: 4.431969
 >> iter 3000, loss: 1.785658
 >> iter 4000, loss: 0.759905
 >> iter 5000, loss: 0.351398
 >> iter 6000, loss: 0.190648
 >> iter 7000, loss: 0.131938
 >> iter 8000, loss: 0.088669
 >> iter 9000, loss: 0.083667
 >> iter 10000, loss: 0.088884
   Number of active neurons: 9
 >> iter 11000, loss: 0.088769
 >> iter 12000, loss: 0.090223
 >> iter 13000, loss: 0.102141
 >> iter 14000, loss: 0.086301
 >> iter 15000, loss: 0.072141
 >> iter 16000, loss: 0.072689
 >> iter 17000, loss: 0.077047
 >> iter 18000, loss: 0.073857
 >> iter 19000, loss: 0.075151
 >> iter 20000, loss: 0.074191
   Number of active neurons: 8
 >> iter 21000, loss: 0.092303
 >> iter 22000, loss: 0.079986
 >> iter 23000, loss: 0.064393
 >> iter 24000, loss: 0.071967
 >> iter 25000, loss: 0.079225
 >> iter 26000, loss: 0.073617
 >> iter 27000, loss: 0.065829
 >> iter 28000, loss: 0.048420
 >> iter 29000, loss: 0.084402
 >> iter 30000, loss: 0.061394
   Number of active neurons: 7
 >> iter 31000, loss: 0.069306
 >> iter 32000, loss: 0.055200
 >> iter 33000, loss: 0.039819
 >> iter 34000, loss: 0.044033
 >> iter 35000, loss: 0.046905
 >> iter 36000, loss: 0.051667
 >> iter 37000, loss: 0.048738
 >> iter 38000, loss: 0.043470
 >> iter 39000, loss: 0.067118
 >> iter 40000, loss: 0.053433
   Number of active neurons: 5
 >> iter 41000, loss: 0.046079
 >> iter 42000, loss: 0.069809
 >> iter 43000, loss: 0.052792
 >> iter 44000, loss: 0.048631
 >> iter 45000, loss: 0.059934
 >> iter 46000, loss: 0.060817
 >> iter 47000, loss: 0.053235
 >> iter 48000, loss: 0.058573
 >> iter 49000, loss: 0.054924
 >> iter 50000, loss: 0.047473
   Number of active neurons: 5
 >> iter 51000, loss: 0.062121
 >> iter 52000, loss: 0.042690
 >> iter 53000, loss: 0.067113
 >> iter 54000, loss: 0.069803
 >> iter 55000, loss: 0.055715
 >> iter 56000, loss: 0.050884
 >> iter 57000, loss: 0.041915
 >> iter 58000, loss: 0.041593
 >> iter 59000, loss: 0.037243
 >> iter 60000, loss: 0.041427
   Number of active neurons: 4
 >> iter 61000, loss: 0.049615
 >> iter 62000, loss: 0.054374
 >> iter 63000, loss: 0.044392
 >> iter 64000, loss: 0.042427
 >> iter 65000, loss: 0.049455
 >> iter 66000, loss: 0.065334
 >> iter 67000, loss: 0.064231
 >> iter 68000, loss: 0.045071
 >> iter 69000, loss: 0.045306
 >> iter 70000, loss: 0.061046
   Number of active neurons: 4
 >> iter 71000, loss: 0.042598
 >> iter 72000, loss: 0.036785
 >> iter 73000, loss: 0.041525
 >> iter 74000, loss: 0.055727
 >> iter 75000, loss: 0.043878
 >> iter 76000, loss: 0.041385
 >> iter 77000, loss: 0.039670
 >> iter 78000, loss: 0.063772
 >> iter 79000, loss: 0.048007
 >> iter 80000, loss: 0.036254
   Number of active neurons: 3
 >> iter 81000, loss: 0.043521
 >> iter 82000, loss: 0.056731
 >> iter 83000, loss: 0.061608
 >> iter 84000, loss: 0.050419
 >> iter 85000, loss: 0.044968
 >> iter 86000, loss: 0.037275
 >> iter 87000, loss: 0.037376
 >> iter 88000, loss: 0.034604
 >> iter 89000, loss: 0.035162
 >> iter 90000, loss: 0.062953
   Number of active neurons: 2
 >> iter 91000, loss: 0.042204
 >> iter 92000, loss: 0.041234
 >> iter 93000, loss: 0.032111
 >> iter 94000, loss: 0.044122
 >> iter 95000, loss: 0.038022
 >> iter 96000, loss: 0.068519
 >> iter 97000, loss: 0.051367
 >> iter 98000, loss: 0.034759
 >> iter 99000, loss: 0.044461
 >> iter 100000, loss: 0.054494
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 11.391970
 >> iter 2000, loss: 4.467595
 >> iter 3000, loss: 1.831082
 >> iter 4000, loss: 0.762878
 >> iter 5000, loss: 0.354718
 >> iter 6000, loss: 0.199896
 >> iter 7000, loss: 0.124030
 >> iter 8000, loss: 0.100399
 >> iter 9000, loss: 0.094951
 >> iter 10000, loss: 0.110812
   Number of active neurons: 10
 >> iter 11000, loss: 0.082974
 >> iter 12000, loss: 0.088862
 >> iter 13000, loss: 0.070304
 >> iter 14000, loss: 0.074924
 >> iter 15000, loss: 0.063319
 >> iter 16000, loss: 0.095978
 >> iter 17000, loss: 0.083974
 >> iter 18000, loss: 0.063655
 >> iter 19000, loss: 0.073116
 >> iter 20000, loss: 0.074348
   Number of active neurons: 7
 >> iter 21000, loss: 0.056262
 >> iter 22000, loss: 0.046920
 >> iter 23000, loss: 0.055927
 >> iter 24000, loss: 0.047192
 >> iter 25000, loss: 0.047406
 >> iter 26000, loss: 0.048468
 >> iter 27000, loss: 0.046278
 >> iter 28000, loss: 0.049083
 >> iter 29000, loss: 0.047252
 >> iter 30000, loss: 0.040885
   Number of active neurons: 5
 >> iter 31000, loss: 0.080867
 >> iter 32000, loss: 0.057296
 >> iter 33000, loss: 0.054505
 >> iter 34000, loss: 0.047055
 >> iter 35000, loss: 0.061477
 >> iter 36000, loss: 0.043534
 >> iter 37000, loss: 0.041909
 >> iter 38000, loss: 0.041923
 >> iter 39000, loss: 0.050033
 >> iter 40000, loss: 0.040321
   Number of active neurons: 4
 >> iter 41000, loss: 0.036756
 >> iter 42000, loss: 0.068409
 >> iter 43000, loss: 0.059446
 >> iter 44000, loss: 0.058006
 >> iter 45000, loss: 0.078076
 >> iter 46000, loss: 0.060064
 >> iter 47000, loss: 0.050778
 >> iter 48000, loss: 0.056459
 >> iter 49000, loss: 0.040268
 >> iter 50000, loss: 0.035266
   Number of active neurons: 4
 >> iter 51000, loss: 0.047660
 >> iter 52000, loss: 0.035837
 >> iter 53000, loss: 0.043107
 >> iter 54000, loss: 0.060450
 >> iter 55000, loss: 0.054024
 >> iter 56000, loss: 0.050156
 >> iter 57000, loss: 0.038321
 >> iter 58000, loss: 0.030193
 >> iter 59000, loss: 0.038281
 >> iter 60000, loss: 0.036428
   Number of active neurons: 3
 >> iter 61000, loss: 0.044262
 >> iter 62000, loss: 0.040023
 >> iter 63000, loss: 0.033883
 >> iter 64000, loss: 0.047746
 >> iter 65000, loss: 0.055728
 >> iter 66000, loss: 0.050348
 >> iter 67000, loss: 0.037640
 >> iter 68000, loss: 0.063687
 >> iter 69000, loss: 0.079474
 >> iter 70000, loss: 0.063107
   Number of active neurons: 3
 >> iter 71000, loss: 0.050147
 >> iter 72000, loss: 0.035110
 >> iter 73000, loss: 0.029359
 >> iter 74000, loss: 0.050248
 >> iter 75000, loss: 0.054657
 >> iter 76000, loss: 0.046445
 >> iter 77000, loss: 0.048796
 >> iter 78000, loss: 0.041481
 >> iter 79000, loss: 0.045839
 >> iter 80000, loss: 0.031700
   Number of active neurons: 3
 >> iter 81000, loss: 0.042200
 >> iter 82000, loss: 0.048057
 >> iter 83000, loss: 0.043185
 >> iter 84000, loss: 0.038561
 >> iter 85000, loss: 0.047253
 >> iter 86000, loss: 0.057778
 >> iter 87000, loss: 0.047870
 >> iter 88000, loss: 0.044241
 >> iter 89000, loss: 0.068263
 >> iter 90000, loss: 0.069922
   Number of active neurons: 3
 >> iter 91000, loss: 0.047138
 >> iter 92000, loss: 0.044869
 >> iter 93000, loss: 0.043536
 >> iter 94000, loss: 0.038968
 >> iter 95000, loss: 0.040606
 >> iter 96000, loss: 0.035564
 >> iter 97000, loss: 0.038642
 >> iter 98000, loss: 0.042519
 >> iter 99000, loss: 0.034497
 >> iter 100000, loss: 0.049653
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.341010
 >> iter 2000, loss: 4.403367
 >> iter 3000, loss: 1.741314
 >> iter 4000, loss: 0.719965
 >> iter 5000, loss: 0.340829
 >> iter 6000, loss: 0.206354
 >> iter 7000, loss: 0.154216
 >> iter 8000, loss: 0.093969
 >> iter 9000, loss: 0.081013
 >> iter 10000, loss: 0.068013
   Number of active neurons: 8
 >> iter 11000, loss: 0.077629
 >> iter 12000, loss: 0.080622
 >> iter 13000, loss: 0.070725
 >> iter 14000, loss: 0.056940
 >> iter 15000, loss: 0.049953
 >> iter 16000, loss: 0.059025
 >> iter 17000, loss: 0.056992
 >> iter 18000, loss: 0.058676
 >> iter 19000, loss: 0.063946
 >> iter 20000, loss: 0.083803
   Number of active neurons: 6
 >> iter 21000, loss: 0.063661
 >> iter 22000, loss: 0.058473
 >> iter 23000, loss: 0.063516
 >> iter 24000, loss: 0.051284
 >> iter 25000, loss: 0.046683
 >> iter 26000, loss: 0.040352
 >> iter 27000, loss: 0.038903
 >> iter 28000, loss: 0.049519
 >> iter 29000, loss: 0.039945
 >> iter 30000, loss: 0.042810
   Number of active neurons: 4
 >> iter 31000, loss: 0.046867
 >> iter 32000, loss: 0.055825
 >> iter 33000, loss: 0.055538
 >> iter 34000, loss: 0.067135
 >> iter 35000, loss: 0.050400
 >> iter 36000, loss: 0.050724
 >> iter 37000, loss: 0.066515
 >> iter 38000, loss: 0.061926
 >> iter 39000, loss: 0.055347
 >> iter 40000, loss: 0.043091
   Number of active neurons: 4
 >> iter 41000, loss: 0.043283
 >> iter 42000, loss: 0.047106
 >> iter 43000, loss: 0.039161
 >> iter 44000, loss: 0.030183
 >> iter 45000, loss: 0.041483
 >> iter 46000, loss: 0.053746
 >> iter 47000, loss: 0.059418
 >> iter 48000, loss: 0.055768
 >> iter 49000, loss: 0.037569
 >> iter 50000, loss: 0.031901
   Number of active neurons: 4
 >> iter 51000, loss: 0.032428
 >> iter 52000, loss: 0.039496
 >> iter 53000, loss: 0.050840
 >> iter 54000, loss: 0.049038
 >> iter 55000, loss: 0.041617
 >> iter 56000, loss: 0.054168
 >> iter 57000, loss: 0.050289
 >> iter 58000, loss: 0.039797
 >> iter 59000, loss: 0.047605
 >> iter 60000, loss: 0.038395
   Number of active neurons: 3
 >> iter 61000, loss: 0.046528
 >> iter 62000, loss: 0.048305
 >> iter 63000, loss: 0.045280
 >> iter 64000, loss: 0.046935
 >> iter 65000, loss: 0.045416
 >> iter 66000, loss: 0.038601
 >> iter 67000, loss: 0.043963
 >> iter 68000, loss: 0.047432
 >> iter 69000, loss: 0.052488
 >> iter 70000, loss: 0.049107
   Number of active neurons: 3
 >> iter 71000, loss: 0.057224
 >> iter 72000, loss: 0.053332
 >> iter 73000, loss: 0.053073
 >> iter 74000, loss: 0.043413
 >> iter 75000, loss: 0.069507
 >> iter 76000, loss: 0.065050
 >> iter 77000, loss: 0.056375
 >> iter 78000, loss: 0.042737
 >> iter 79000, loss: 0.043854
 >> iter 80000, loss: 0.058140
   Number of active neurons: 3
 >> iter 81000, loss: 0.067439
 >> iter 82000, loss: 0.057723
 >> iter 83000, loss: 0.061594
 >> iter 84000, loss: 0.048547
 >> iter 85000, loss: 0.036080
 >> iter 86000, loss: 0.042331
 >> iter 87000, loss: 0.044643
 >> iter 88000, loss: 0.050656
 >> iter 89000, loss: 0.046727
 >> iter 90000, loss: 0.051022
   Number of active neurons: 3
 >> iter 91000, loss: 0.050728
 >> iter 92000, loss: 0.052185
 >> iter 93000, loss: 0.049783
 >> iter 94000, loss: 0.046728
 >> iter 95000, loss: 0.032584
 >> iter 96000, loss: 0.052412
 >> iter 97000, loss: 0.054039
 >> iter 98000, loss: 0.049138
 >> iter 99000, loss: 0.051444
 >> iter 100000, loss: 0.040365
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.318196
 >> iter 2000, loss: 4.449284
 >> iter 3000, loss: 1.764955
 >> iter 4000, loss: 0.732985
 >> iter 5000, loss: 0.345605
 >> iter 6000, loss: 0.186360
 >> iter 7000, loss: 0.137297
 >> iter 8000, loss: 0.100214
 >> iter 9000, loss: 0.091618
 >> iter 10000, loss: 0.079524
   Number of active neurons: 9
 >> iter 11000, loss: 0.092898
 >> iter 12000, loss: 0.090355
 >> iter 13000, loss: 0.077821
 >> iter 14000, loss: 0.068302
 >> iter 15000, loss: 0.071306
 >> iter 16000, loss: 0.072010
 >> iter 17000, loss: 0.062994
 >> iter 18000, loss: 0.059455
 >> iter 19000, loss: 0.082558
 >> iter 20000, loss: 0.079485
   Number of active neurons: 9
 >> iter 21000, loss: 0.069911
 >> iter 22000, loss: 0.057126
 >> iter 23000, loss: 0.050992
 >> iter 24000, loss: 0.043434
 >> iter 25000, loss: 0.066743
 >> iter 26000, loss: 0.059153
 >> iter 27000, loss: 0.053713
 >> iter 28000, loss: 0.069263
 >> iter 29000, loss: 0.043573
 >> iter 30000, loss: 0.056431
   Number of active neurons: 6
 >> iter 31000, loss: 0.059631
 >> iter 32000, loss: 0.055994
 >> iter 33000, loss: 0.045220
 >> iter 34000, loss: 0.042845
 >> iter 35000, loss: 0.046677
 >> iter 36000, loss: 0.060709
 >> iter 37000, loss: 0.051047
 >> iter 38000, loss: 0.037110
 >> iter 39000, loss: 0.034155
 >> iter 40000, loss: 0.050179
   Number of active neurons: 6
 >> iter 41000, loss: 0.038650
 >> iter 42000, loss: 0.051446
 >> iter 43000, loss: 0.045436
 >> iter 44000, loss: 0.047208
 >> iter 45000, loss: 0.053138
 >> iter 46000, loss: 0.040277
 >> iter 47000, loss: 0.040542
 >> iter 48000, loss: 0.040029
 >> iter 49000, loss: 0.042376
 >> iter 50000, loss: 0.048418
   Number of active neurons: 2
 >> iter 51000, loss: 0.043196
 >> iter 52000, loss: 0.036644
 >> iter 53000, loss: 0.050878
 >> iter 54000, loss: 0.053884
 >> iter 55000, loss: 0.063904
 >> iter 56000, loss: 0.044834
 >> iter 57000, loss: 0.035411
 >> iter 58000, loss: 0.059626
 >> iter 59000, loss: 0.042735
 >> iter 60000, loss: 0.043324
   Number of active neurons: 2
 >> iter 61000, loss: 0.056429
 >> iter 62000, loss: 0.064119
 >> iter 63000, loss: 0.048961
 >> iter 64000, loss: 0.047678
 >> iter 65000, loss: 0.041479
 >> iter 66000, loss: 0.048031
 >> iter 67000, loss: 0.044140
 >> iter 68000, loss: 0.041950
 >> iter 69000, loss: 0.053147
 >> iter 70000, loss: 0.034833
   Number of active neurons: 2
 >> iter 71000, loss: 0.042487
 >> iter 72000, loss: 0.060157
 >> iter 73000, loss: 0.047744
 >> iter 74000, loss: 0.050689
 >> iter 75000, loss: 0.050438
 >> iter 76000, loss: 0.044685
 >> iter 77000, loss: 0.048997
 >> iter 78000, loss: 0.037153
 >> iter 79000, loss: 0.048735
 >> iter 80000, loss: 0.048352
   Number of active neurons: 2
 >> iter 81000, loss: 0.042797
 >> iter 82000, loss: 0.044406
 >> iter 83000, loss: 0.035384
 >> iter 84000, loss: 0.030021
 >> iter 85000, loss: 0.043857
 >> iter 86000, loss: 0.028902
 >> iter 87000, loss: 0.035106
 >> iter 88000, loss: 0.034270
 >> iter 89000, loss: 0.032820
 >> iter 90000, loss: 0.032198
   Number of active neurons: 2
 >> iter 91000, loss: 0.039694
 >> iter 92000, loss: 0.028499
 >> iter 93000, loss: 0.053465
 >> iter 94000, loss: 0.054632
 >> iter 95000, loss: 0.044648
 >> iter 96000, loss: 0.042650
 >> iter 97000, loss: 0.031797
 >> iter 98000, loss: 0.030752
 >> iter 99000, loss: 0.028541
 >> iter 100000, loss: 0.040469
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.308978
 >> iter 2000, loss: 4.401831
 >> iter 3000, loss: 1.723851
 >> iter 4000, loss: 0.701106
 >> iter 5000, loss: 0.327448
 >> iter 6000, loss: 0.187093
 >> iter 7000, loss: 0.117399
 >> iter 8000, loss: 0.103637
 >> iter 9000, loss: 0.074695
 >> iter 10000, loss: 0.076024
   Number of active neurons: 7
 >> iter 11000, loss: 0.072898
 >> iter 12000, loss: 0.079750
 >> iter 13000, loss: 0.067603
 >> iter 14000, loss: 0.064268
 >> iter 15000, loss: 0.068800
 >> iter 16000, loss: 0.058767
 >> iter 17000, loss: 0.090602
 >> iter 18000, loss: 0.073378
 >> iter 19000, loss: 0.052163
 >> iter 20000, loss: 0.060909
   Number of active neurons: 7
 >> iter 21000, loss: 0.042204
 >> iter 22000, loss: 0.051993
 >> iter 23000, loss: 0.049277
 >> iter 24000, loss: 0.043248
 >> iter 25000, loss: 0.062397
 >> iter 26000, loss: 0.069619
 >> iter 27000, loss: 0.058616
 >> iter 28000, loss: 0.063242
 >> iter 29000, loss: 0.044355
 >> iter 30000, loss: 0.061118
   Number of active neurons: 5
 >> iter 31000, loss: 0.043750
 >> iter 32000, loss: 0.042461
 >> iter 33000, loss: 0.043699
 >> iter 34000, loss: 0.053808
 >> iter 35000, loss: 0.055961
 >> iter 36000, loss: 0.045802
 >> iter 37000, loss: 0.049493
 >> iter 38000, loss: 0.054772
 >> iter 39000, loss: 0.057733
 >> iter 40000, loss: 0.066272
   Number of active neurons: 5
 >> iter 41000, loss: 0.059010
 >> iter 42000, loss: 0.069847
 >> iter 43000, loss: 0.044126
 >> iter 44000, loss: 0.062910
 >> iter 45000, loss: 0.076729
 >> iter 46000, loss: 0.051716
 >> iter 47000, loss: 0.067824
 >> iter 48000, loss: 0.049164
 >> iter 49000, loss: 0.047302
 >> iter 50000, loss: 0.043723
   Number of active neurons: 3
 >> iter 51000, loss: 0.042570
 >> iter 52000, loss: 0.031129
 >> iter 53000, loss: 0.049913
 >> iter 54000, loss: 0.050031
 >> iter 55000, loss: 0.045833
 >> iter 56000, loss: 0.053000
 >> iter 57000, loss: 0.044772
 >> iter 58000, loss: 0.064485
 >> iter 59000, loss: 0.062055
 >> iter 60000, loss: 0.051815
   Number of active neurons: 3
 >> iter 61000, loss: 0.059177
 >> iter 62000, loss: 0.051336
 >> iter 63000, loss: 0.045462
 >> iter 64000, loss: 0.036397
 >> iter 65000, loss: 0.032851
 >> iter 66000, loss: 0.047406
 >> iter 67000, loss: 0.047021
 >> iter 68000, loss: 0.040897
 >> iter 69000, loss: 0.042711
 >> iter 70000, loss: 0.053878
   Number of active neurons: 3
 >> iter 71000, loss: 0.057408
 >> iter 72000, loss: 0.065716
 >> iter 73000, loss: 0.052617
 >> iter 74000, loss: 0.045241
 >> iter 75000, loss: 0.040075
 >> iter 76000, loss: 0.058755
 >> iter 77000, loss: 0.066657
 >> iter 78000, loss: 0.074264
 >> iter 79000, loss: 0.053964
 >> iter 80000, loss: 0.041968
   Number of active neurons: 3
 >> iter 81000, loss: 0.057517
 >> iter 82000, loss: 0.050942
 >> iter 83000, loss: 0.049664
 >> iter 84000, loss: 0.039683
 >> iter 85000, loss: 0.038981
 >> iter 86000, loss: 0.052104
 >> iter 87000, loss: 0.042741
 >> iter 88000, loss: 0.047362
 >> iter 89000, loss: 0.046607
 >> iter 90000, loss: 0.050403
   Number of active neurons: 3
 >> iter 91000, loss: 0.062790
 >> iter 92000, loss: 0.059016
 >> iter 93000, loss: 0.043860
 >> iter 94000, loss: 0.055019
 >> iter 95000, loss: 0.047640
 >> iter 96000, loss: 0.043519
 >> iter 97000, loss: 0.037295
 >> iter 98000, loss: 0.043955
 >> iter 99000, loss: 0.052305
 >> iter 100000, loss: 0.040979
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.300642
 >> iter 2000, loss: 4.375434
 >> iter 3000, loss: 1.697099
 >> iter 4000, loss: 0.696002
 >> iter 5000, loss: 0.320571
 >> iter 6000, loss: 0.207158
 >> iter 7000, loss: 0.123482
 >> iter 8000, loss: 0.094855
 >> iter 9000, loss: 0.082314
 >> iter 10000, loss: 0.069351
   Number of active neurons: 6
 >> iter 11000, loss: 0.056872
 >> iter 12000, loss: 0.065043
 >> iter 13000, loss: 0.069409
 >> iter 14000, loss: 0.058211
 >> iter 15000, loss: 0.051098
 >> iter 16000, loss: 0.046870
 >> iter 17000, loss: 0.068364
 >> iter 18000, loss: 0.064427
 >> iter 19000, loss: 0.060673
 >> iter 20000, loss: 0.055465
   Number of active neurons: 5
 >> iter 21000, loss: 0.086583
 >> iter 22000, loss: 0.058420
 >> iter 23000, loss: 0.060636
 >> iter 24000, loss: 0.054788
 >> iter 25000, loss: 0.051110
 >> iter 26000, loss: 0.048151
 >> iter 27000, loss: 0.048148
 >> iter 28000, loss: 0.045680
 >> iter 29000, loss: 0.046359
 >> iter 30000, loss: 0.052292
   Number of active neurons: 4
 >> iter 31000, loss: 0.050375
 >> iter 32000, loss: 0.047314
 >> iter 33000, loss: 0.035462
 >> iter 34000, loss: 0.058547
 >> iter 35000, loss: 0.048154
 >> iter 36000, loss: 0.051734
 >> iter 37000, loss: 0.042497
 >> iter 38000, loss: 0.052423
 >> iter 39000, loss: 0.057763
 >> iter 40000, loss: 0.043411
   Number of active neurons: 4
 >> iter 41000, loss: 0.034595
 >> iter 42000, loss: 0.052445
 >> iter 43000, loss: 0.046382
 >> iter 44000, loss: 0.037441
 >> iter 45000, loss: 0.051130
 >> iter 46000, loss: 0.055547
 >> iter 47000, loss: 0.064171
 >> iter 48000, loss: 0.055832
 >> iter 49000, loss: 0.042866
 >> iter 50000, loss: 0.041900
   Number of active neurons: 4
 >> iter 51000, loss: 0.073732
 >> iter 52000, loss: 0.055644
 >> iter 53000, loss: 0.052177
 >> iter 54000, loss: 0.048444
 >> iter 55000, loss: 0.056768
 >> iter 56000, loss: 0.066881
 >> iter 57000, loss: 0.049803
 >> iter 58000, loss: 0.060910
 >> iter 59000, loss: 0.062479
 >> iter 60000, loss: 0.045723
   Number of active neurons: 4
 >> iter 61000, loss: 0.048880
 >> iter 62000, loss: 0.052567
 >> iter 63000, loss: 0.060920
 >> iter 64000, loss: 0.079193
 >> iter 65000, loss: 0.065405
 >> iter 66000, loss: 0.053642
 >> iter 67000, loss: 0.046102
 >> iter 68000, loss: 0.056600
 >> iter 69000, loss: 0.048967
 >> iter 70000, loss: 0.054802
   Number of active neurons: 3
 >> iter 71000, loss: 0.057884
 >> iter 72000, loss: 0.048636
 >> iter 73000, loss: 0.059376
 >> iter 74000, loss: 0.061130
 >> iter 75000, loss: 0.061344
 >> iter 76000, loss: 0.052885
 >> iter 77000, loss: 0.050727
 >> iter 78000, loss: 0.039342
 >> iter 79000, loss: 0.060937
 >> iter 80000, loss: 0.046520
   Number of active neurons: 3
 >> iter 81000, loss: 0.039525
 >> iter 82000, loss: 0.039646
 >> iter 83000, loss: 0.029989
 >> iter 84000, loss: 0.034267
 >> iter 85000, loss: 0.034772
 >> iter 86000, loss: 0.035747
 >> iter 87000, loss: 0.040876
 >> iter 88000, loss: 0.030726
 >> iter 89000, loss: 0.037126
 >> iter 90000, loss: 0.046159
   Number of active neurons: 3
 >> iter 91000, loss: 0.043881
 >> iter 92000, loss: 0.039166
 >> iter 93000, loss: 0.038591
 >> iter 94000, loss: 0.038183
 >> iter 95000, loss: 0.037969
 >> iter 96000, loss: 0.041517
 >> iter 97000, loss: 0.054720
 >> iter 98000, loss: 0.056331
 >> iter 99000, loss: 0.066201
 >> iter 100000, loss: 0.051309
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.352140
 >> iter 2000, loss: 4.459631
 >> iter 3000, loss: 1.725651
 >> iter 4000, loss: 0.723327
 >> iter 5000, loss: 0.384364
 >> iter 6000, loss: 0.202747
 >> iter 7000, loss: 0.119457
 >> iter 8000, loss: 0.083271
 >> iter 9000, loss: 0.083043
 >> iter 10000, loss: 0.071752
   Number of active neurons: 8
 >> iter 11000, loss: 0.058153
 >> iter 12000, loss: 0.058601
 >> iter 13000, loss: 0.070732
 >> iter 14000, loss: 0.056564
 >> iter 15000, loss: 0.049252
 >> iter 16000, loss: 0.064586
 >> iter 17000, loss: 0.055480
 >> iter 18000, loss: 0.073066
 >> iter 19000, loss: 0.068878
 >> iter 20000, loss: 0.067998
   Number of active neurons: 6
 >> iter 21000, loss: 0.055137
 >> iter 22000, loss: 0.059771
 >> iter 23000, loss: 0.054437
 >> iter 24000, loss: 0.047601
 >> iter 25000, loss: 0.054234
 >> iter 26000, loss: 0.039819
 >> iter 27000, loss: 0.038844
 >> iter 28000, loss: 0.050526
 >> iter 29000, loss: 0.059557
 >> iter 30000, loss: 0.052973
   Number of active neurons: 6
 >> iter 31000, loss: 0.045469
 >> iter 32000, loss: 0.043425
 >> iter 33000, loss: 0.060818
 >> iter 34000, loss: 0.057426
 >> iter 35000, loss: 0.070406
 >> iter 36000, loss: 0.075976
 >> iter 37000, loss: 0.053328
 >> iter 38000, loss: 0.042198
 >> iter 39000, loss: 0.036307
 >> iter 40000, loss: 0.052154
   Number of active neurons: 5
 >> iter 41000, loss: 0.040591
 >> iter 42000, loss: 0.053662
 >> iter 43000, loss: 0.074654
 >> iter 44000, loss: 0.057022
 >> iter 45000, loss: 0.054690
 >> iter 46000, loss: 0.049315
 >> iter 47000, loss: 0.047745
 >> iter 48000, loss: 0.067857
 >> iter 49000, loss: 0.044987
 >> iter 50000, loss: 0.041604
   Number of active neurons: 3
 >> iter 51000, loss: 0.051140
 >> iter 52000, loss: 0.043541
 >> iter 53000, loss: 0.041925
 >> iter 54000, loss: 0.052557
 >> iter 55000, loss: 0.046004
 >> iter 56000, loss: 0.045862
 >> iter 57000, loss: 0.049954
 >> iter 58000, loss: 0.050303
 >> iter 59000, loss: 0.061611
 >> iter 60000, loss: 0.049841
   Number of active neurons: 3
 >> iter 61000, loss: 0.055611
 >> iter 62000, loss: 0.044700
 >> iter 63000, loss: 0.052621
 >> iter 64000, loss: 0.047641
 >> iter 65000, loss: 0.061188
 >> iter 66000, loss: 0.061148
 >> iter 67000, loss: 0.068540
 >> iter 68000, loss: 0.057308
 >> iter 69000, loss: 0.039712
 >> iter 70000, loss: 0.034940
   Number of active neurons: 3
 >> iter 71000, loss: 0.046471
 >> iter 72000, loss: 0.060121
 >> iter 73000, loss: 0.045108
 >> iter 74000, loss: 0.045097
 >> iter 75000, loss: 0.039849
 >> iter 76000, loss: 0.043679
 >> iter 77000, loss: 0.051554
 >> iter 78000, loss: 0.049854
 >> iter 79000, loss: 0.048631
 >> iter 80000, loss: 0.056157
   Number of active neurons: 3
 >> iter 81000, loss: 0.058515
 >> iter 82000, loss: 0.050896
 >> iter 83000, loss: 0.054294
 >> iter 84000, loss: 0.047175
 >> iter 85000, loss: 0.056565
 >> iter 86000, loss: 0.041824
 >> iter 87000, loss: 0.039053
 >> iter 88000, loss: 0.048858
 >> iter 89000, loss: 0.040877
 >> iter 90000, loss: 0.033674
   Number of active neurons: 3
 >> iter 91000, loss: 0.035704
 >> iter 92000, loss: 0.034789
 >> iter 93000, loss: 0.040127
 >> iter 94000, loss: 0.054156
 >> iter 95000, loss: 0.040791
 >> iter 96000, loss: 0.054201
 >> iter 97000, loss: 0.053360
 >> iter 98000, loss: 0.062619
 >> iter 99000, loss: 0.050067
 >> iter 100000, loss: 0.035410
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 11.295297
 >> iter 2000, loss: 4.443356
 >> iter 3000, loss: 1.751489
 >> iter 4000, loss: 0.728100
 >> iter 5000, loss: 0.349181
 >> iter 6000, loss: 0.190900
 >> iter 7000, loss: 0.123269
 >> iter 8000, loss: 0.100893
 >> iter 9000, loss: 0.080108
 >> iter 10000, loss: 0.078421
   Number of active neurons: 7
 >> iter 11000, loss: 0.072164
 >> iter 12000, loss: 0.071239
 >> iter 13000, loss: 0.059170
 >> iter 14000, loss: 0.078254
 >> iter 15000, loss: 0.074527
 >> iter 16000, loss: 0.062900
 >> iter 17000, loss: 0.052407
 >> iter 18000, loss: 0.046052
 >> iter 19000, loss: 0.062266
 >> iter 20000, loss: 0.064369
   Number of active neurons: 7
 >> iter 21000, loss: 0.069195
 >> iter 22000, loss: 0.057340
 >> iter 23000, loss: 0.058122
 >> iter 24000, loss: 0.048527
 >> iter 25000, loss: 0.065376
 >> iter 26000, loss: 0.057796
 >> iter 27000, loss: 0.051163
 >> iter 28000, loss: 0.056908
 >> iter 29000, loss: 0.063323
 >> iter 30000, loss: 0.055437
   Number of active neurons: 7
 >> iter 31000, loss: 0.062933
 >> iter 32000, loss: 0.045470
 >> iter 33000, loss: 0.043328
 >> iter 34000, loss: 0.053448
 >> iter 35000, loss: 0.049045
 >> iter 36000, loss: 0.057515
 >> iter 37000, loss: 0.057872
 >> iter 38000, loss: 0.060399
 >> iter 39000, loss: 0.061529
 >> iter 40000, loss: 0.066776
   Number of active neurons: 5
 >> iter 41000, loss: 0.067513
 >> iter 42000, loss: 0.065237
 >> iter 43000, loss: 0.053520
 >> iter 44000, loss: 0.049387
 >> iter 45000, loss: 0.054700
 >> iter 46000, loss: 0.049835
 >> iter 47000, loss: 0.056105
 >> iter 48000, loss: 0.055812
 >> iter 49000, loss: 0.042895
 >> iter 50000, loss: 0.034515
   Number of active neurons: 4
 >> iter 51000, loss: 0.034599
 >> iter 52000, loss: 0.031097
 >> iter 53000, loss: 0.076935
 >> iter 54000, loss: 0.057950
 >> iter 55000, loss: 0.077996
 >> iter 56000, loss: 0.063104
 >> iter 57000, loss: 0.063127
 >> iter 58000, loss: 0.044339
 >> iter 59000, loss: 0.034470
 >> iter 60000, loss: 0.041334
   Number of active neurons: 4
 >> iter 61000, loss: 0.080642
 >> iter 62000, loss: 0.067657
 >> iter 63000, loss: 0.059073
 >> iter 64000, loss: 0.054656
 >> iter 65000, loss: 0.052342
 >> iter 66000, loss: 0.044032
 >> iter 67000, loss: 0.047918
 >> iter 68000, loss: 0.048336
 >> iter 69000, loss: 0.047463
 >> iter 70000, loss: 0.057267
   Number of active neurons: 4
 >> iter 71000, loss: 0.066985
 >> iter 72000, loss: 0.042971
 >> iter 73000, loss: 0.043769
 >> iter 74000, loss: 0.064422
 >> iter 75000, loss: 0.050026
 >> iter 76000, loss: 0.051303
 >> iter 77000, loss: 0.054531
 >> iter 78000, loss: 0.050479
 >> iter 79000, loss: 0.063253
 >> iter 80000, loss: 0.047706
   Number of active neurons: 4
 >> iter 81000, loss: 0.047061
 >> iter 82000, loss: 0.049186
 >> iter 83000, loss: 0.048400
 >> iter 84000, loss: 0.046301
 >> iter 85000, loss: 0.041740
 >> iter 86000, loss: 0.037846
 >> iter 87000, loss: 0.070612
 >> iter 88000, loss: 0.073454
 >> iter 89000, loss: 0.051919
 >> iter 90000, loss: 0.035189
   Number of active neurons: 4
 >> iter 91000, loss: 0.044361
 >> iter 92000, loss: 0.050772
 >> iter 93000, loss: 0.043735
 >> iter 94000, loss: 0.039881
 >> iter 95000, loss: 0.042137
 >> iter 96000, loss: 0.049117
 >> iter 97000, loss: 0.040474
 >> iter 98000, loss: 0.045831
 >> iter 99000, loss: 0.059204
 >> iter 100000, loss: 0.064575
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.410557
 >> iter 2000, loss: 4.497992
 >> iter 3000, loss: 1.775959
 >> iter 4000, loss: 0.730326
 >> iter 5000, loss: 0.328973
 >> iter 6000, loss: 0.175888
 >> iter 7000, loss: 0.148060
 >> iter 8000, loss: 0.102415
 >> iter 9000, loss: 0.110888
 >> iter 10000, loss: 0.088065
   Number of active neurons: 7
 >> iter 11000, loss: 0.089214
 >> iter 12000, loss: 0.112945
 >> iter 13000, loss: 0.075139
 >> iter 14000, loss: 0.058257
 >> iter 15000, loss: 0.063404
 >> iter 16000, loss: 0.065977
 >> iter 17000, loss: 0.076725
 >> iter 18000, loss: 0.060849
 >> iter 19000, loss: 0.067937
 >> iter 20000, loss: 0.052325
   Number of active neurons: 7
 >> iter 21000, loss: 0.040128
 >> iter 22000, loss: 0.048800
 >> iter 23000, loss: 0.041976
 >> iter 24000, loss: 0.045343
 >> iter 25000, loss: 0.043927
 >> iter 26000, loss: 0.035118
 >> iter 27000, loss: 0.053097
 >> iter 28000, loss: 0.034310
 >> iter 29000, loss: 0.062341
 >> iter 30000, loss: 0.053344
   Number of active neurons: 4
 >> iter 31000, loss: 0.068154
 >> iter 32000, loss: 0.063050
 >> iter 33000, loss: 0.060792
 >> iter 34000, loss: 0.050794
 >> iter 35000, loss: 0.046198
 >> iter 36000, loss: 0.046323
 >> iter 37000, loss: 0.065972
 >> iter 38000, loss: 0.061152
 >> iter 39000, loss: 0.057099
 >> iter 40000, loss: 0.051121
   Number of active neurons: 4
 >> iter 41000, loss: 0.048735
 >> iter 42000, loss: 0.036154
 >> iter 43000, loss: 0.063784
 >> iter 44000, loss: 0.046469
 >> iter 45000, loss: 0.040709
 >> iter 46000, loss: 0.048274
 >> iter 47000, loss: 0.053916
 >> iter 48000, loss: 0.065137
 >> iter 49000, loss: 0.054962
 >> iter 50000, loss: 0.070393
   Number of active neurons: 4
 >> iter 51000, loss: 0.049021
 >> iter 52000, loss: 0.055700
 >> iter 53000, loss: 0.068485
 >> iter 54000, loss: 0.047449
 >> iter 55000, loss: 0.050024
 >> iter 56000, loss: 0.057436
 >> iter 57000, loss: 0.056485
 >> iter 58000, loss: 0.046585
 >> iter 59000, loss: 0.042346
 >> iter 60000, loss: 0.052385
   Number of active neurons: 3
 >> iter 61000, loss: 0.054068
 >> iter 62000, loss: 0.053174
 >> iter 63000, loss: 0.045788
 >> iter 64000, loss: 0.056437
 >> iter 65000, loss: 0.048707
 >> iter 66000, loss: 0.069782
 >> iter 67000, loss: 0.068619
 >> iter 68000, loss: 0.048915
 >> iter 69000, loss: 0.045350
 >> iter 70000, loss: 0.065246
   Number of active neurons: 3
 >> iter 71000, loss: 0.050672
 >> iter 72000, loss: 0.057428
 >> iter 73000, loss: 0.058968
 >> iter 74000, loss: 0.051203
 >> iter 75000, loss: 0.066601
 >> iter 76000, loss: 0.059885
 >> iter 77000, loss: 0.057521
 >> iter 78000, loss: 0.053662
 >> iter 79000, loss: 0.057596
 >> iter 80000, loss: 0.041999
   Number of active neurons: 3
 >> iter 81000, loss: 0.043642
 >> iter 82000, loss: 0.059628
 >> iter 83000, loss: 0.050872
 >> iter 84000, loss: 0.055854
 >> iter 85000, loss: 0.062569
 >> iter 86000, loss: 0.052720
 >> iter 87000, loss: 0.051082
 >> iter 88000, loss: 0.041030
 >> iter 89000, loss: 0.044349
 >> iter 90000, loss: 0.037971
   Number of active neurons: 3
 >> iter 91000, loss: 0.033025
 >> iter 92000, loss: 0.042936
 >> iter 93000, loss: 0.032502
 >> iter 94000, loss: 0.026827
 >> iter 95000, loss: 0.035626
 >> iter 96000, loss: 0.045922
 >> iter 97000, loss: 0.039008
 >> iter 98000, loss: 0.048463
 >> iter 99000, loss: 0.054657
 >> iter 100000, loss: 0.053110
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.341496
 >> iter 2000, loss: 4.412331
 >> iter 3000, loss: 1.762643
 >> iter 4000, loss: 0.718502
 >> iter 5000, loss: 0.324238
 >> iter 6000, loss: 0.158353
 >> iter 7000, loss: 0.104563
 >> iter 8000, loss: 0.102560
 >> iter 9000, loss: 0.083979
 >> iter 10000, loss: 0.119242
   Number of active neurons: 7
 >> iter 11000, loss: 0.083334
 >> iter 12000, loss: 0.072903
 >> iter 13000, loss: 0.091535
 >> iter 14000, loss: 0.077268
 >> iter 15000, loss: 0.072775
 >> iter 16000, loss: 0.056716
 >> iter 17000, loss: 0.064933
 >> iter 18000, loss: 0.073109
 >> iter 19000, loss: 0.075222
 >> iter 20000, loss: 0.055565
   Number of active neurons: 6
 >> iter 21000, loss: 0.051205
 >> iter 22000, loss: 0.057485
 >> iter 23000, loss: 0.086465
 >> iter 24000, loss: 0.058410
 >> iter 25000, loss: 0.064079
 >> iter 26000, loss: 0.048366
 >> iter 27000, loss: 0.040895
 >> iter 28000, loss: 0.054410
 >> iter 29000, loss: 0.037626
 >> iter 30000, loss: 0.061446
   Number of active neurons: 4
 >> iter 31000, loss: 0.055998
 >> iter 32000, loss: 0.046467
 >> iter 33000, loss: 0.044514
 >> iter 34000, loss: 0.072860
 >> iter 35000, loss: 0.054214
 >> iter 36000, loss: 0.048653
 >> iter 37000, loss: 0.042705
 >> iter 38000, loss: 0.046594
 >> iter 39000, loss: 0.056100
 >> iter 40000, loss: 0.065090
   Number of active neurons: 4
 >> iter 41000, loss: 0.050364
 >> iter 42000, loss: 0.048433
 >> iter 43000, loss: 0.046183
 >> iter 44000, loss: 0.059719
 >> iter 45000, loss: 0.063470
 >> iter 46000, loss: 0.055952
 >> iter 47000, loss: 0.063055
 >> iter 48000, loss: 0.055222
 >> iter 49000, loss: 0.042444
 >> iter 50000, loss: 0.040235
   Number of active neurons: 4
 >> iter 51000, loss: 0.057718
 >> iter 52000, loss: 0.050545
 >> iter 53000, loss: 0.044293
 >> iter 54000, loss: 0.056917
 >> iter 55000, loss: 0.049976
 >> iter 56000, loss: 0.044738
 >> iter 57000, loss: 0.059305
 >> iter 58000, loss: 0.049543
 >> iter 59000, loss: 0.051857
 >> iter 60000, loss: 0.047042
   Number of active neurons: 4
 >> iter 61000, loss: 0.040602
 >> iter 62000, loss: 0.054406
 >> iter 63000, loss: 0.041416
 >> iter 64000, loss: 0.042853
 >> iter 65000, loss: 0.045671
 >> iter 66000, loss: 0.051371
 >> iter 67000, loss: 0.047166
 >> iter 68000, loss: 0.063730
 >> iter 69000, loss: 0.052423
 >> iter 70000, loss: 0.034162
   Number of active neurons: 4
 >> iter 71000, loss: 0.058442
 >> iter 72000, loss: 0.047003
 >> iter 73000, loss: 0.035806
 >> iter 74000, loss: 0.040805
 >> iter 75000, loss: 0.041243
 >> iter 76000, loss: 0.039457
 >> iter 77000, loss: 0.043189
 >> iter 78000, loss: 0.037497
 >> iter 79000, loss: 0.055693
 >> iter 80000, loss: 0.055044
   Number of active neurons: 4
 >> iter 81000, loss: 0.038012
 >> iter 82000, loss: 0.050504
 >> iter 83000, loss: 0.049592
 >> iter 84000, loss: 0.052968
 >> iter 85000, loss: 0.057188
 >> iter 86000, loss: 0.045852
 >> iter 87000, loss: 0.034857
 >> iter 88000, loss: 0.054492
 >> iter 89000, loss: 0.056788
 >> iter 90000, loss: 0.048337
   Number of active neurons: 3
 >> iter 91000, loss: 0.060284
 >> iter 92000, loss: 0.045685
 >> iter 93000, loss: 0.036578
 >> iter 94000, loss: 0.053692
 >> iter 95000, loss: 0.048966
 >> iter 96000, loss: 0.058674
 >> iter 97000, loss: 0.051196
 >> iter 98000, loss: 0.039835
 >> iter 99000, loss: 0.062538
 >> iter 100000, loss: 0.044207
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.282432
 >> iter 2000, loss: 4.359449
 >> iter 3000, loss: 1.739533
 >> iter 4000, loss: 0.731081
 >> iter 5000, loss: 0.336433
 >> iter 6000, loss: 0.178603
 >> iter 7000, loss: 0.129736
 >> iter 8000, loss: 0.094788
 >> iter 9000, loss: 0.102592
 >> iter 10000, loss: 0.085236
   Number of active neurons: 8
 >> iter 11000, loss: 0.085337
 >> iter 12000, loss: 0.062277
 >> iter 13000, loss: 0.090305
 >> iter 14000, loss: 0.072940
 >> iter 15000, loss: 0.069872
 >> iter 16000, loss: 0.056487
 >> iter 17000, loss: 0.053935
 >> iter 18000, loss: 0.068615
 >> iter 19000, loss: 0.065822
 >> iter 20000, loss: 0.049923
   Number of active neurons: 8
 >> iter 21000, loss: 0.057544
 >> iter 22000, loss: 0.057516
 >> iter 23000, loss: 0.054238
 >> iter 24000, loss: 0.063319
 >> iter 25000, loss: 0.069385
 >> iter 26000, loss: 0.066515
 >> iter 27000, loss: 0.054472
 >> iter 28000, loss: 0.051703
 >> iter 29000, loss: 0.064343
 >> iter 30000, loss: 0.050593
   Number of active neurons: 6
 >> iter 31000, loss: 0.061428
 >> iter 32000, loss: 0.073667
 >> iter 33000, loss: 0.089341
 >> iter 34000, loss: 0.058585
 >> iter 35000, loss: 0.042195
 >> iter 36000, loss: 0.044661
 >> iter 37000, loss: 0.071592
 >> iter 38000, loss: 0.060826
 >> iter 39000, loss: 0.061274
 >> iter 40000, loss: 0.053304
   Number of active neurons: 5
 >> iter 41000, loss: 0.053663
 >> iter 42000, loss: 0.046558
 >> iter 43000, loss: 0.036019
 >> iter 44000, loss: 0.054875
 >> iter 45000, loss: 0.046413
 >> iter 46000, loss: 0.059368
 >> iter 47000, loss: 0.045831
 >> iter 48000, loss: 0.062319
 >> iter 49000, loss: 0.060724
 >> iter 50000, loss: 0.043566
   Number of active neurons: 5
 >> iter 51000, loss: 0.039567
 >> iter 52000, loss: 0.070409
 >> iter 53000, loss: 0.062396
 >> iter 54000, loss: 0.049188
 >> iter 55000, loss: 0.055331
 >> iter 56000, loss: 0.050500
 >> iter 57000, loss: 0.041598
 >> iter 58000, loss: 0.050145
 >> iter 59000, loss: 0.046074
 >> iter 60000, loss: 0.041459
   Number of active neurons: 4
 >> iter 61000, loss: 0.057873
 >> iter 62000, loss: 0.046559
 >> iter 63000, loss: 0.044313
 >> iter 64000, loss: 0.054089
 >> iter 65000, loss: 0.052955
 >> iter 66000, loss: 0.052764
 >> iter 67000, loss: 0.059862
 >> iter 68000, loss: 0.057047
 >> iter 69000, loss: 0.069918
 >> iter 70000, loss: 0.056718
   Number of active neurons: 4
 >> iter 71000, loss: 0.066895
 >> iter 72000, loss: 0.058401
 >> iter 73000, loss: 0.049524
 >> iter 74000, loss: 0.075615
 >> iter 75000, loss: 0.052525
 >> iter 76000, loss: 0.049513
 >> iter 77000, loss: 0.042563
 >> iter 78000, loss: 0.040456
 >> iter 79000, loss: 0.075807
 >> iter 80000, loss: 0.059385
   Number of active neurons: 4
 >> iter 81000, loss: 0.060241
 >> iter 82000, loss: 0.039158
 >> iter 83000, loss: 0.036188
 >> iter 84000, loss: 0.055614
 >> iter 85000, loss: 0.044127
 >> iter 86000, loss: 0.040418
 >> iter 87000, loss: 0.052220
 >> iter 88000, loss: 0.039497
 >> iter 89000, loss: 0.034825
 >> iter 90000, loss: 0.037889
   Number of active neurons: 3
 >> iter 91000, loss: 0.047023
 >> iter 92000, loss: 0.043478
 >> iter 93000, loss: 0.035326
 >> iter 94000, loss: 0.039300
 >> iter 95000, loss: 0.053546
 >> iter 96000, loss: 0.060188
 >> iter 97000, loss: 0.043912
 >> iter 98000, loss: 0.031537
 >> iter 99000, loss: 0.033633
 >> iter 100000, loss: 0.041626
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.202860
 >> iter 2000, loss: 4.319411
 >> iter 3000, loss: 1.683496
 >> iter 4000, loss: 0.661204
 >> iter 5000, loss: 0.302548
 >> iter 6000, loss: 0.179793
 >> iter 7000, loss: 0.119254
 >> iter 8000, loss: 0.076995
 >> iter 9000, loss: 0.080330
 >> iter 10000, loss: 0.092470
   Number of active neurons: 6
 >> iter 11000, loss: 0.057760
 >> iter 12000, loss: 0.065197
 >> iter 13000, loss: 0.067498
 >> iter 14000, loss: 0.060259
 >> iter 15000, loss: 0.067688
 >> iter 16000, loss: 0.063103
 >> iter 17000, loss: 0.060047
 >> iter 18000, loss: 0.058609
 >> iter 19000, loss: 0.048750
 >> iter 20000, loss: 0.048835
   Number of active neurons: 5
 >> iter 21000, loss: 0.044736
 >> iter 22000, loss: 0.040599
 >> iter 23000, loss: 0.075586
 >> iter 24000, loss: 0.056359
 >> iter 25000, loss: 0.074930
 >> iter 26000, loss: 0.059775
 >> iter 27000, loss: 0.058703
 >> iter 28000, loss: 0.062260
 >> iter 29000, loss: 0.050393
 >> iter 30000, loss: 0.052765
   Number of active neurons: 4
 >> iter 31000, loss: 0.042149
 >> iter 32000, loss: 0.054181
 >> iter 33000, loss: 0.052349
 >> iter 34000, loss: 0.038023
 >> iter 35000, loss: 0.062507
 >> iter 36000, loss: 0.055753
 >> iter 37000, loss: 0.054715
 >> iter 38000, loss: 0.048280
 >> iter 39000, loss: 0.050240
 >> iter 40000, loss: 0.056174
   Number of active neurons: 4
 >> iter 41000, loss: 0.058542
 >> iter 42000, loss: 0.060610
 >> iter 43000, loss: 0.069900
 >> iter 44000, loss: 0.057803
 >> iter 45000, loss: 0.042014
 >> iter 46000, loss: 0.037588
 >> iter 47000, loss: 0.046285
 >> iter 48000, loss: 0.050706
 >> iter 49000, loss: 0.046552
 >> iter 50000, loss: 0.043676
   Number of active neurons: 4
 >> iter 51000, loss: 0.046063
 >> iter 52000, loss: 0.036134
 >> iter 53000, loss: 0.030910
 >> iter 54000, loss: 0.045356
 >> iter 55000, loss: 0.051025
 >> iter 56000, loss: 0.040677
 >> iter 57000, loss: 0.047316
 >> iter 58000, loss: 0.039726
 >> iter 59000, loss: 0.053539
 >> iter 60000, loss: 0.069268
   Number of active neurons: 3
 >> iter 61000, loss: 0.078574
 >> iter 62000, loss: 0.068063
 >> iter 63000, loss: 0.069301
 >> iter 64000, loss: 0.059230
 >> iter 65000, loss: 0.051131
 >> iter 66000, loss: 0.063812
 >> iter 67000, loss: 0.051821
 >> iter 68000, loss: 0.037402
 >> iter 69000, loss: 0.040138
 >> iter 70000, loss: 0.039637
   Number of active neurons: 2
 >> iter 71000, loss: 0.041602
 >> iter 72000, loss: 0.040397
 >> iter 73000, loss: 0.062820
 >> iter 74000, loss: 0.065041
 >> iter 75000, loss: 0.055976
 >> iter 76000, loss: 0.040703
 >> iter 77000, loss: 0.039141
 >> iter 78000, loss: 0.036813
 >> iter 79000, loss: 0.037187
 >> iter 80000, loss: 0.065902
   Number of active neurons: 2
 >> iter 81000, loss: 0.049828
 >> iter 82000, loss: 0.039524
 >> iter 83000, loss: 0.038610
 >> iter 84000, loss: 0.031460
 >> iter 85000, loss: 0.040106
 >> iter 86000, loss: 0.060469
 >> iter 87000, loss: 0.068799
 >> iter 88000, loss: 0.057471
 >> iter 89000, loss: 0.059978
 >> iter 90000, loss: 0.043763
   Number of active neurons: 2
 >> iter 91000, loss: 0.036958
 >> iter 92000, loss: 0.047597
 >> iter 93000, loss: 0.037017
 >> iter 94000, loss: 0.031667
 >> iter 95000, loss: 0.035471
 >> iter 96000, loss: 0.038829
 >> iter 97000, loss: 0.035510
 >> iter 98000, loss: 0.038909
 >> iter 99000, loss: 0.029917
 >> iter 100000, loss: 0.024621
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

