 > Problema: tomita1nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.751822
 >> iter 2000, loss: 3.976211
 >> iter 3000, loss: 1.480736
 >> iter 4000, loss: 0.561181
 >> iter 5000, loss: 0.222953
 >> iter 6000, loss: 0.097696
 >> iter 7000, loss: 0.051927
 >> iter 8000, loss: 0.034557
 >> iter 9000, loss: 0.028547
 >> iter 10000, loss: 0.025879
   Number of active neurons: 5
 >> iter 11000, loss: 0.025338
 >> iter 12000, loss: 0.024689
 >> iter 13000, loss: 0.024891
 >> iter 14000, loss: 0.024480
 >> iter 15000, loss: 0.024720
 >> iter 16000, loss: 0.024248
 >> iter 17000, loss: 0.024248
 >> iter 18000, loss: 0.023540
 >> iter 19000, loss: 0.023288
 >> iter 20000, loss: 0.022443
   Number of active neurons: 3
 >> iter 21000, loss: 0.022078
 >> iter 22000, loss: 0.021277
 >> iter 23000, loss: 0.021048
 >> iter 24000, loss: 0.020370
 >> iter 25000, loss: 0.020194
 >> iter 26000, loss: 0.019543
 >> iter 27000, loss: 0.019349
 >> iter 28000, loss: 0.018712
 >> iter 29000, loss: 0.018567
 >> iter 30000, loss: 0.018049
   Number of active neurons: 2
 >> iter 31000, loss: 0.018068
 >> iter 32000, loss: 0.017692
 >> iter 33000, loss: 0.017809
 >> iter 34000, loss: 0.017498
 >> iter 35000, loss: 0.017671
 >> iter 36000, loss: 0.017373
 >> iter 37000, loss: 0.017565
 >> iter 38000, loss: 0.017276
 >> iter 39000, loss: 0.017490
 >> iter 40000, loss: 0.017204
   Number of active neurons: 2
 >> iter 41000, loss: 0.017425
 >> iter 42000, loss: 0.017160
 >> iter 43000, loss: 0.017370
 >> iter 44000, loss: 0.017124
 >> iter 45000, loss: 0.017346
 >> iter 46000, loss: 0.017096
 >> iter 47000, loss: 0.017320
 >> iter 48000, loss: 0.017088
 >> iter 49000, loss: 0.017318
 >> iter 50000, loss: 0.017082
   Number of active neurons: 2
 >> iter 51000, loss: 0.017317
 >> iter 52000, loss: 0.017095
 >> iter 53000, loss: 0.017318
 >> iter 54000, loss: 0.017136
 >> iter 55000, loss: 0.017328
 >> iter 56000, loss: 0.017165
 >> iter 57000, loss: 0.017371
 >> iter 58000, loss: 0.017190
 >> iter 59000, loss: 0.017410
 >> iter 60000, loss: 0.017243
   Number of active neurons: 2
 >> iter 61000, loss: 0.017451
 >> iter 62000, loss: 0.017304
 >> iter 63000, loss: 0.017500
 >> iter 64000, loss: 0.017314
 >> iter 65000, loss: 0.017515
 >> iter 66000, loss: 0.017354
 >> iter 67000, loss: 0.017552
 >> iter 68000, loss: 0.017419
 >> iter 69000, loss: 0.017578
 >> iter 70000, loss: 0.017434
   Number of active neurons: 2
 >> iter 71000, loss: 0.017624
 >> iter 72000, loss: 0.017492
 >> iter 73000, loss: 0.017670
 >> iter 74000, loss: 0.017527
 >> iter 75000, loss: 0.017708
 >> iter 76000, loss: 0.017563
 >> iter 77000, loss: 0.017736
 >> iter 78000, loss: 0.017585
 >> iter 79000, loss: 0.017788
 >> iter 80000, loss: 0.017622
   Number of active neurons: 2
 >> iter 81000, loss: 0.017844
 >> iter 82000, loss: 0.017660
 >> iter 83000, loss: 0.017895
 >> iter 84000, loss: 0.017697
 >> iter 85000, loss: 0.017928
 >> iter 86000, loss: 0.017733
 >> iter 87000, loss: 0.017972
 >> iter 88000, loss: 0.017777
 >> iter 89000, loss: 0.018011
 >> iter 90000, loss: 0.017835
   Number of active neurons: 2
 >> iter 91000, loss: 0.018062
 >> iter 92000, loss: 0.017895
 >> iter 93000, loss: 0.018123
 >> iter 94000, loss: 0.017948
 >> iter 95000, loss: 0.018203
 >> iter 96000, loss: 0.018007
 >> iter 97000, loss: 0.018270
 >> iter 98000, loss: 0.018069
 >> iter 99000, loss: 0.018342
 >> iter 100000, loss: 0.018161
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.750277
 >> iter 2000, loss: 3.975414
 >> iter 3000, loss: 1.480000
 >> iter 4000, loss: 0.560438
 >> iter 5000, loss: 0.221902
 >> iter 6000, loss: 0.096677
 >> iter 7000, loss: 0.050638
 >> iter 8000, loss: 0.033178
 >> iter 9000, loss: 0.026989
 >> iter 10000, loss: 0.024338
   Number of active neurons: 4
 >> iter 11000, loss: 0.023708
 >> iter 12000, loss: 0.023141
 >> iter 13000, loss: 0.023271
 >> iter 14000, loss: 0.022909
 >> iter 15000, loss: 0.023055
 >> iter 16000, loss: 0.022604
 >> iter 17000, loss: 0.022567
 >> iter 18000, loss: 0.022022
 >> iter 19000, loss: 0.021979
 >> iter 20000, loss: 0.021581
   Number of active neurons: 3
 >> iter 21000, loss: 0.021695
 >> iter 22000, loss: 0.021432
 >> iter 23000, loss: 0.021650
 >> iter 24000, loss: 0.021438
 >> iter 25000, loss: 0.021699
 >> iter 26000, loss: 0.021519
 >> iter 27000, loss: 0.021779
 >> iter 28000, loss: 0.021610
 >> iter 29000, loss: 0.021851
 >> iter 30000, loss: 0.021680
   Number of active neurons: 3
 >> iter 31000, loss: 0.021908
 >> iter 32000, loss: 0.021718
 >> iter 33000, loss: 0.021907
 >> iter 34000, loss: 0.021679
 >> iter 35000, loss: 0.021799
 >> iter 36000, loss: 0.021455
 >> iter 37000, loss: 0.021313
 >> iter 38000, loss: 0.020609
 >> iter 39000, loss: 0.020195
 >> iter 40000, loss: 0.019235
   Number of active neurons: 1
 >> iter 41000, loss: 0.018611
 >> iter 42000, loss: 0.017736
 >> iter 43000, loss: 0.017275
 >> iter 44000, loss: 0.016659
 >> iter 45000, loss: 0.016439
 >> iter 46000, loss: 0.016020
 >> iter 47000, loss: 0.015940
 >> iter 48000, loss: 0.015632
 >> iter 49000, loss: 0.015628
 >> iter 50000, loss: 0.015365
   Number of active neurons: 1
 >> iter 51000, loss: 0.015404
 >> iter 52000, loss: 0.015179
 >> iter 53000, loss: 0.015229
 >> iter 54000, loss: 0.015043
 >> iter 55000, loss: 0.015085
 >> iter 56000, loss: 0.014915
 >> iter 57000, loss: 0.014979
 >> iter 58000, loss: 0.014800
 >> iter 59000, loss: 0.014882
 >> iter 60000, loss: 0.014714
   Number of active neurons: 1
 >> iter 61000, loss: 0.014792
 >> iter 62000, loss: 0.014636
 >> iter 63000, loss: 0.014722
 >> iter 64000, loss: 0.014559
 >> iter 65000, loss: 0.014657
 >> iter 66000, loss: 0.014503
 >> iter 67000, loss: 0.014597
 >> iter 68000, loss: 0.014464
 >> iter 69000, loss: 0.014550
 >> iter 70000, loss: 0.014411
   Number of active neurons: 1
 >> iter 71000, loss: 0.014508
 >> iter 72000, loss: 0.014380
 >> iter 73000, loss: 0.014474
 >> iter 74000, loss: 0.014342
 >> iter 75000, loss: 0.014444
 >> iter 76000, loss: 0.014314
 >> iter 77000, loss: 0.014414
 >> iter 78000, loss: 0.014281
 >> iter 79000, loss: 0.014405
 >> iter 80000, loss: 0.014262
   Number of active neurons: 1
 >> iter 81000, loss: 0.014402
 >> iter 82000, loss: 0.014246
 >> iter 83000, loss: 0.014395
 >> iter 84000, loss: 0.014228
 >> iter 85000, loss: 0.014376
 >> iter 86000, loss: 0.014211
 >> iter 87000, loss: 0.014364
 >> iter 88000, loss: 0.014197
 >> iter 89000, loss: 0.014348
 >> iter 90000, loss: 0.014193
   Number of active neurons: 1
 >> iter 91000, loss: 0.014338
 >> iter 92000, loss: 0.014189
 >> iter 93000, loss: 0.014334
 >> iter 94000, loss: 0.014176
 >> iter 95000, loss: 0.014342
 >> iter 96000, loss: 0.014166
 >> iter 97000, loss: 0.014338
 >> iter 98000, loss: 0.014156
 >> iter 99000, loss: 0.014336
 >> iter 100000, loss: 0.014167
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.686958
 >> iter 2000, loss: 3.953345
 >> iter 3000, loss: 1.473192
 >> iter 4000, loss: 0.559211
 >> iter 5000, loss: 0.222463
 >> iter 6000, loss: 0.097317
 >> iter 7000, loss: 0.050763
 >> iter 8000, loss: 0.032682
 >> iter 9000, loss: 0.025927
 >> iter 10000, loss: 0.022850
   Number of active neurons: 3
 >> iter 11000, loss: 0.021867
 >> iter 12000, loss: 0.021086
 >> iter 13000, loss: 0.021095
 >> iter 14000, loss: 0.020733
 >> iter 15000, loss: 0.020932
 >> iter 16000, loss: 0.020660
 >> iter 17000, loss: 0.020848
 >> iter 18000, loss: 0.020575
 >> iter 19000, loss: 0.020756
 >> iter 20000, loss: 0.020492
   Number of active neurons: 2
 >> iter 21000, loss: 0.020611
 >> iter 22000, loss: 0.020250
 >> iter 23000, loss: 0.020256
 >> iter 24000, loss: 0.019692
 >> iter 25000, loss: 0.019536
 >> iter 26000, loss: 0.018995
 >> iter 27000, loss: 0.018899
 >> iter 28000, loss: 0.018506
 >> iter 29000, loss: 0.018553
 >> iter 30000, loss: 0.018277
   Number of active neurons: 2
 >> iter 31000, loss: 0.018406
 >> iter 32000, loss: 0.018180
 >> iter 33000, loss: 0.018341
 >> iter 34000, loss: 0.018141
 >> iter 35000, loss: 0.018330
 >> iter 36000, loss: 0.018129
 >> iter 37000, loss: 0.018329
 >> iter 38000, loss: 0.018132
 >> iter 39000, loss: 0.018348
 >> iter 40000, loss: 0.018153
   Number of active neurons: 2
 >> iter 41000, loss: 0.018371
 >> iter 42000, loss: 0.018191
 >> iter 43000, loss: 0.018400
 >> iter 44000, loss: 0.018240
 >> iter 45000, loss: 0.018448
 >> iter 46000, loss: 0.018289
 >> iter 47000, loss: 0.018497
 >> iter 48000, loss: 0.018351
 >> iter 49000, loss: 0.018560
 >> iter 50000, loss: 0.018407
   Number of active neurons: 2
 >> iter 51000, loss: 0.018617
 >> iter 52000, loss: 0.018473
 >> iter 53000, loss: 0.018661
 >> iter 54000, loss: 0.018540
 >> iter 55000, loss: 0.018688
 >> iter 56000, loss: 0.018560
 >> iter 57000, loss: 0.018697
 >> iter 58000, loss: 0.018520
 >> iter 59000, loss: 0.018624
 >> iter 60000, loss: 0.018396
   Number of active neurons: 1
 >> iter 61000, loss: 0.018357
 >> iter 62000, loss: 0.017875
 >> iter 63000, loss: 0.017576
 >> iter 64000, loss: 0.017006
 >> iter 65000, loss: 0.016712
 >> iter 66000, loss: 0.016201
 >> iter 67000, loss: 0.016024
 >> iter 68000, loss: 0.015683
 >> iter 69000, loss: 0.015610
 >> iter 70000, loss: 0.015346
   Number of active neurons: 1
 >> iter 71000, loss: 0.015344
 >> iter 72000, loss: 0.015134
 >> iter 73000, loss: 0.015160
 >> iter 74000, loss: 0.014969
 >> iter 75000, loss: 0.015019
 >> iter 76000, loss: 0.014843
 >> iter 77000, loss: 0.014902
 >> iter 78000, loss: 0.014733
 >> iter 79000, loss: 0.014824
 >> iter 80000, loss: 0.014650
   Number of active neurons: 1
 >> iter 81000, loss: 0.014761
 >> iter 82000, loss: 0.014579
 >> iter 83000, loss: 0.014705
 >> iter 84000, loss: 0.014515
 >> iter 85000, loss: 0.014643
 >> iter 86000, loss: 0.014458
 >> iter 87000, loss: 0.014593
 >> iter 88000, loss: 0.014410
 >> iter 89000, loss: 0.014546
 >> iter 90000, loss: 0.014376
   Number of active neurons: 1
 >> iter 91000, loss: 0.014509
 >> iter 92000, loss: 0.014347
 >> iter 93000, loss: 0.014481
 >> iter 94000, loss: 0.014312
 >> iter 95000, loss: 0.014469
 >> iter 96000, loss: 0.014283
 >> iter 97000, loss: 0.014448
 >> iter 98000, loss: 0.014257
 >> iter 99000, loss: 0.014430
 >> iter 100000, loss: 0.014254
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.717565
 >> iter 2000, loss: 3.962026
 >> iter 3000, loss: 1.474636
 >> iter 4000, loss: 0.558847
 >> iter 5000, loss: 0.222376
 >> iter 6000, loss: 0.098195
 >> iter 7000, loss: 0.052913
 >> iter 8000, loss: 0.035754
 >> iter 9000, loss: 0.029699
 >> iter 10000, loss: 0.026848
   Number of active neurons: 4
 >> iter 11000, loss: 0.025934
 >> iter 12000, loss: 0.024815
 >> iter 13000, loss: 0.024495
 >> iter 14000, loss: 0.023661
 >> iter 15000, loss: 0.023442
 >> iter 16000, loss: 0.022668
 >> iter 17000, loss: 0.022413
 >> iter 18000, loss: 0.021576
 >> iter 19000, loss: 0.021134
 >> iter 20000, loss: 0.020161
   Number of active neurons: 2
 >> iter 21000, loss: 0.019686
 >> iter 22000, loss: 0.018862
 >> iter 23000, loss: 0.018659
 >> iter 24000, loss: 0.018130
 >> iter 25000, loss: 0.018168
 >> iter 26000, loss: 0.017802
 >> iter 27000, loss: 0.017926
 >> iter 28000, loss: 0.017623
 >> iter 29000, loss: 0.017775
 >> iter 30000, loss: 0.017497
   Number of active neurons: 2
 >> iter 31000, loss: 0.017671
 >> iter 32000, loss: 0.017407
 >> iter 33000, loss: 0.017594
 >> iter 34000, loss: 0.017345
 >> iter 35000, loss: 0.017554
 >> iter 36000, loss: 0.017304
 >> iter 37000, loss: 0.017519
 >> iter 38000, loss: 0.017275
 >> iter 39000, loss: 0.017506
 >> iter 40000, loss: 0.017267
   Number of active neurons: 2
 >> iter 41000, loss: 0.017502
 >> iter 42000, loss: 0.017287
 >> iter 43000, loss: 0.017510
 >> iter 44000, loss: 0.017319
 >> iter 45000, loss: 0.017549
 >> iter 46000, loss: 0.017362
 >> iter 47000, loss: 0.017558
 >> iter 48000, loss: 0.017364
 >> iter 49000, loss: 0.017583
 >> iter 50000, loss: 0.017399
   Number of active neurons: 2
 >> iter 51000, loss: 0.017626
 >> iter 52000, loss: 0.017433
 >> iter 53000, loss: 0.017636
 >> iter 54000, loss: 0.017498
 >> iter 55000, loss: 0.017676
 >> iter 56000, loss: 0.017545
 >> iter 57000, loss: 0.017731
 >> iter 58000, loss: 0.017571
 >> iter 59000, loss: 0.017767
 >> iter 60000, loss: 0.017612
   Number of active neurons: 2
 >> iter 61000, loss: 0.017794
 >> iter 62000, loss: 0.017648
 >> iter 63000, loss: 0.017831
 >> iter 64000, loss: 0.017671
 >> iter 65000, loss: 0.017866
 >> iter 66000, loss: 0.017713
 >> iter 67000, loss: 0.017897
 >> iter 68000, loss: 0.017770
 >> iter 69000, loss: 0.017940
 >> iter 70000, loss: 0.017803
   Number of active neurons: 2
 >> iter 71000, loss: 0.017985
 >> iter 72000, loss: 0.017860
 >> iter 73000, loss: 0.018036
 >> iter 74000, loss: 0.017907
 >> iter 75000, loss: 0.018091
 >> iter 76000, loss: 0.017965
 >> iter 77000, loss: 0.018145
 >> iter 78000, loss: 0.018016
 >> iter 79000, loss: 0.018228
 >> iter 80000, loss: 0.018086
   Number of active neurons: 2
 >> iter 81000, loss: 0.018316
 >> iter 82000, loss: 0.018159
 >> iter 83000, loss: 0.018400
 >> iter 84000, loss: 0.018231
 >> iter 85000, loss: 0.018466
 >> iter 86000, loss: 0.018300
 >> iter 87000, loss: 0.018538
 >> iter 88000, loss: 0.018370
 >> iter 89000, loss: 0.018598
 >> iter 90000, loss: 0.018442
   Number of active neurons: 2
 >> iter 91000, loss: 0.018652
 >> iter 92000, loss: 0.018495
 >> iter 93000, loss: 0.018684
 >> iter 94000, loss: 0.018500
 >> iter 95000, loss: 0.018681
 >> iter 96000, loss: 0.018438
 >> iter 97000, loss: 0.018562
 >> iter 98000, loss: 0.018208
 >> iter 99000, loss: 0.018080
 >> iter 100000, loss: 0.017475
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.768474
 >> iter 2000, loss: 3.983084
 >> iter 3000, loss: 1.484544
 >> iter 4000, loss: 0.563692
 >> iter 5000, loss: 0.224813
 >> iter 6000, loss: 0.099195
 >> iter 7000, loss: 0.052948
 >> iter 8000, loss: 0.035011
 >> iter 9000, loss: 0.028459
 >> iter 10000, loss: 0.025328
   Number of active neurons: 3
 >> iter 11000, loss: 0.024345
 >> iter 12000, loss: 0.023274
 >> iter 13000, loss: 0.022965
 >> iter 14000, loss: 0.022074
 >> iter 15000, loss: 0.021803
 >> iter 16000, loss: 0.021084
 >> iter 17000, loss: 0.021043
 >> iter 18000, loss: 0.020600
 >> iter 19000, loss: 0.020710
 >> iter 20000, loss: 0.020452
   Number of active neurons: 3
 >> iter 21000, loss: 0.020695
 >> iter 22000, loss: 0.020475
 >> iter 23000, loss: 0.020735
 >> iter 24000, loss: 0.020534
 >> iter 25000, loss: 0.020822
 >> iter 26000, loss: 0.020627
 >> iter 27000, loss: 0.020895
 >> iter 28000, loss: 0.020700
 >> iter 29000, loss: 0.020952
 >> iter 30000, loss: 0.020759
   Number of active neurons: 3
 >> iter 31000, loss: 0.021017
 >> iter 32000, loss: 0.020826
 >> iter 33000, loss: 0.021086
 >> iter 34000, loss: 0.020904
 >> iter 35000, loss: 0.021182
 >> iter 36000, loss: 0.020990
 >> iter 37000, loss: 0.021271
 >> iter 38000, loss: 0.021078
 >> iter 39000, loss: 0.021369
 >> iter 40000, loss: 0.021174
   Number of active neurons: 3
 >> iter 41000, loss: 0.021455
 >> iter 42000, loss: 0.021268
 >> iter 43000, loss: 0.021521
 >> iter 44000, loss: 0.021339
 >> iter 45000, loss: 0.021556
 >> iter 46000, loss: 0.021341
 >> iter 47000, loss: 0.021494
 >> iter 48000, loss: 0.021217
 >> iter 49000, loss: 0.021172
 >> iter 50000, loss: 0.020614
   Number of active neurons: 2
 >> iter 51000, loss: 0.020438
 >> iter 52000, loss: 0.019906
 >> iter 53000, loss: 0.019759
 >> iter 54000, loss: 0.019386
 >> iter 55000, loss: 0.019320
 >> iter 56000, loss: 0.019014
 >> iter 57000, loss: 0.018955
 >> iter 58000, loss: 0.018536
 >> iter 59000, loss: 0.018218
 >> iter 60000, loss: 0.017584
   Number of active neurons: 1
 >> iter 61000, loss: 0.017220
 >> iter 62000, loss: 0.016642
 >> iter 63000, loss: 0.016397
 >> iter 64000, loss: 0.015978
 >> iter 65000, loss: 0.015884
 >> iter 66000, loss: 0.015578
 >> iter 67000, loss: 0.015554
 >> iter 68000, loss: 0.015325
 >> iter 69000, loss: 0.015332
 >> iter 70000, loss: 0.015125
   Number of active neurons: 1
 >> iter 71000, loss: 0.015163
 >> iter 72000, loss: 0.014983
 >> iter 73000, loss: 0.015031
 >> iter 74000, loss: 0.014857
 >> iter 75000, loss: 0.014921
 >> iter 76000, loss: 0.014756
 >> iter 77000, loss: 0.014824
 >> iter 78000, loss: 0.014661
 >> iter 79000, loss: 0.014759
 >> iter 80000, loss: 0.014590
   Number of active neurons: 1
 >> iter 81000, loss: 0.014706
 >> iter 82000, loss: 0.014528
 >> iter 83000, loss: 0.014658
 >> iter 84000, loss: 0.014472
 >> iter 85000, loss: 0.014602
 >> iter 86000, loss: 0.014421
 >> iter 87000, loss: 0.014559
 >> iter 88000, loss: 0.014378
 >> iter 89000, loss: 0.014516
 >> iter 90000, loss: 0.014349
   Number of active neurons: 1
 >> iter 91000, loss: 0.014484
 >> iter 92000, loss: 0.014323
 >> iter 93000, loss: 0.014460
 >> iter 94000, loss: 0.014292
 >> iter 95000, loss: 0.014450
 >> iter 96000, loss: 0.014266
 >> iter 97000, loss: 0.014431
 >> iter 98000, loss: 0.014243
 >> iter 99000, loss: 0.014416
 >> iter 100000, loss: 0.014241
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.685364
 >> iter 2000, loss: 3.950872
 >> iter 3000, loss: 1.470773
 >> iter 4000, loss: 0.557092
 >> iter 5000, loss: 0.221011
 >> iter 6000, loss: 0.096943
 >> iter 7000, loss: 0.051676
 >> iter 8000, loss: 0.034756
 >> iter 9000, loss: 0.028945
 >> iter 10000, loss: 0.026530
   Number of active neurons: 5
 >> iter 11000, loss: 0.026080
 >> iter 12000, loss: 0.025579
 >> iter 13000, loss: 0.025829
 >> iter 14000, loss: 0.025539
 >> iter 15000, loss: 0.025839
 >> iter 16000, loss: 0.025538
 >> iter 17000, loss: 0.025753
 >> iter 18000, loss: 0.025320
 >> iter 19000, loss: 0.025285
 >> iter 20000, loss: 0.024699
   Number of active neurons: 2
 >> iter 21000, loss: 0.024555
 >> iter 22000, loss: 0.023989
 >> iter 23000, loss: 0.023867
 >> iter 24000, loss: 0.023187
 >> iter 25000, loss: 0.022672
 >> iter 26000, loss: 0.021669
 >> iter 27000, loss: 0.021115
 >> iter 28000, loss: 0.020339
 >> iter 29000, loss: 0.020099
 >> iter 30000, loss: 0.019647
   Number of active neurons: 2
 >> iter 31000, loss: 0.019633
 >> iter 32000, loss: 0.019327
 >> iter 33000, loss: 0.019394
 >> iter 34000, loss: 0.019139
 >> iter 35000, loss: 0.019225
 >> iter 36000, loss: 0.018945
 >> iter 37000, loss: 0.018983
 >> iter 38000, loss: 0.018621
 >> iter 39000, loss: 0.018436
 >> iter 40000, loss: 0.017781
   Number of active neurons: 1
 >> iter 41000, loss: 0.017461
 >> iter 42000, loss: 0.016827
 >> iter 43000, loss: 0.016562
 >> iter 44000, loss: 0.016096
 >> iter 45000, loss: 0.015983
 >> iter 46000, loss: 0.015641
 >> iter 47000, loss: 0.015619
 >> iter 48000, loss: 0.015353
 >> iter 49000, loss: 0.015382
 >> iter 50000, loss: 0.015144
   Number of active neurons: 1
 >> iter 51000, loss: 0.015204
 >> iter 52000, loss: 0.014995
 >> iter 53000, loss: 0.015060
 >> iter 54000, loss: 0.014886
 >> iter 55000, loss: 0.014940
 >> iter 56000, loss: 0.014781
 >> iter 57000, loss: 0.014854
 >> iter 58000, loss: 0.014684
 >> iter 59000, loss: 0.014775
 >> iter 60000, loss: 0.014614
   Number of active neurons: 1
 >> iter 61000, loss: 0.014699
 >> iter 62000, loss: 0.014550
 >> iter 63000, loss: 0.014641
 >> iter 64000, loss: 0.014484
 >> iter 65000, loss: 0.014588
 >> iter 66000, loss: 0.014438
 >> iter 67000, loss: 0.014537
 >> iter 68000, loss: 0.014408
 >> iter 69000, loss: 0.014498
 >> iter 70000, loss: 0.014363
   Number of active neurons: 1
 >> iter 71000, loss: 0.014464
 >> iter 72000, loss: 0.014338
 >> iter 73000, loss: 0.014436
 >> iter 74000, loss: 0.014307
 >> iter 75000, loss: 0.014411
 >> iter 76000, loss: 0.014283
 >> iter 77000, loss: 0.014385
 >> iter 78000, loss: 0.014254
 >> iter 79000, loss: 0.014381
 >> iter 80000, loss: 0.014239
   Number of active neurons: 1
 >> iter 81000, loss: 0.014380
 >> iter 82000, loss: 0.014226
 >> iter 83000, loss: 0.014377
 >> iter 84000, loss: 0.014211
 >> iter 85000, loss: 0.014360
 >> iter 86000, loss: 0.014196
 >> iter 87000, loss: 0.014350
 >> iter 88000, loss: 0.014184
 >> iter 89000, loss: 0.014336
 >> iter 90000, loss: 0.014182
   Number of active neurons: 1
 >> iter 91000, loss: 0.014328
 >> iter 92000, loss: 0.014179
 >> iter 93000, loss: 0.014325
 >> iter 94000, loss: 0.014168
 >> iter 95000, loss: 0.014334
 >> iter 96000, loss: 0.014159
 >> iter 97000, loss: 0.014332
 >> iter 98000, loss: 0.014150
 >> iter 99000, loss: 0.014330
 >> iter 100000, loss: 0.014161
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.769416
 >> iter 2000, loss: 3.982958
 >> iter 3000, loss: 1.483947
 >> iter 4000, loss: 0.563242
 >> iter 5000, loss: 0.224333
 >> iter 6000, loss: 0.098709
 >> iter 7000, loss: 0.052408
 >> iter 8000, loss: 0.034574
 >> iter 9000, loss: 0.028039
 >> iter 10000, loss: 0.024951
   Number of active neurons: 3
 >> iter 11000, loss: 0.023877
 >> iter 12000, loss: 0.022837
 >> iter 13000, loss: 0.022537
 >> iter 14000, loss: 0.021791
 >> iter 15000, loss: 0.021533
 >> iter 16000, loss: 0.020713
 >> iter 17000, loss: 0.020379
 >> iter 18000, loss: 0.019595
 >> iter 19000, loss: 0.019333
 >> iter 20000, loss: 0.018674
   Number of active neurons: 2
 >> iter 21000, loss: 0.018534
 >> iter 22000, loss: 0.018036
 >> iter 23000, loss: 0.018080
 >> iter 24000, loss: 0.017709
 >> iter 25000, loss: 0.017851
 >> iter 26000, loss: 0.017546
 >> iter 27000, loss: 0.017714
 >> iter 28000, loss: 0.017437
 >> iter 29000, loss: 0.017612
 >> iter 30000, loss: 0.017348
   Number of active neurons: 2
 >> iter 31000, loss: 0.017538
 >> iter 32000, loss: 0.017283
 >> iter 33000, loss: 0.017481
 >> iter 34000, loss: 0.017238
 >> iter 35000, loss: 0.017457
 >> iter 36000, loss: 0.017211
 >> iter 37000, loss: 0.017433
 >> iter 38000, loss: 0.017192
 >> iter 39000, loss: 0.017429
 >> iter 40000, loss: 0.017191
   Number of active neurons: 2
 >> iter 41000, loss: 0.017431
 >> iter 42000, loss: 0.017215
 >> iter 43000, loss: 0.017442
 >> iter 44000, loss: 0.017248
 >> iter 45000, loss: 0.017481
 >> iter 46000, loss: 0.017291
 >> iter 47000, loss: 0.017522
 >> iter 48000, loss: 0.017322
 >> iter 49000, loss: 0.017533
 >> iter 50000, loss: 0.017342
   Number of active neurons: 2
 >> iter 51000, loss: 0.017570
 >> iter 52000, loss: 0.017401
 >> iter 53000, loss: 0.017599
 >> iter 54000, loss: 0.017448
 >> iter 55000, loss: 0.017627
 >> iter 56000, loss: 0.017499
 >> iter 57000, loss: 0.017690
 >> iter 58000, loss: 0.017533
 >> iter 59000, loss: 0.017731
 >> iter 60000, loss: 0.017577
   Number of active neurons: 2
 >> iter 61000, loss: 0.017760
 >> iter 62000, loss: 0.017614
 >> iter 63000, loss: 0.017797
 >> iter 64000, loss: 0.017637
 >> iter 65000, loss: 0.017831
 >> iter 66000, loss: 0.017677
 >> iter 67000, loss: 0.017860
 >> iter 68000, loss: 0.017732
 >> iter 69000, loss: 0.017901
 >> iter 70000, loss: 0.017762
   Number of active neurons: 2
 >> iter 71000, loss: 0.017943
 >> iter 72000, loss: 0.017817
 >> iter 73000, loss: 0.017992
 >> iter 74000, loss: 0.017861
 >> iter 75000, loss: 0.018044
 >> iter 76000, loss: 0.017915
 >> iter 77000, loss: 0.018095
 >> iter 78000, loss: 0.017963
 >> iter 79000, loss: 0.018174
 >> iter 80000, loss: 0.018030
   Number of active neurons: 2
 >> iter 81000, loss: 0.018260
 >> iter 82000, loss: 0.018100
 >> iter 83000, loss: 0.018342
 >> iter 84000, loss: 0.018170
 >> iter 85000, loss: 0.018407
 >> iter 86000, loss: 0.018239
 >> iter 87000, loss: 0.018480
 >> iter 88000, loss: 0.018312
 >> iter 89000, loss: 0.018544
 >> iter 90000, loss: 0.018391
   Number of active neurons: 2
 >> iter 91000, loss: 0.018609
 >> iter 92000, loss: 0.018459
 >> iter 93000, loss: 0.018664
 >> iter 94000, loss: 0.018493
 >> iter 95000, loss: 0.018703
 >> iter 96000, loss: 0.018489
 >> iter 97000, loss: 0.018668
 >> iter 98000, loss: 0.018407
 >> iter 99000, loss: 0.018520
 >> iter 100000, loss: 0.018120
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.704300
 >> iter 2000, loss: 3.960358
 >> iter 3000, loss: 1.476309
 >> iter 4000, loss: 0.561015
 >> iter 5000, loss: 0.224047
 >> iter 6000, loss: 0.099216
 >> iter 7000, loss: 0.053150
 >> iter 8000, loss: 0.035480
 >> iter 9000, loss: 0.028917
 >> iter 10000, loss: 0.025848
   Number of active neurons: 3
 >> iter 11000, loss: 0.024746
 >> iter 12000, loss: 0.023751
 >> iter 13000, loss: 0.023405
 >> iter 14000, loss: 0.022665
 >> iter 15000, loss: 0.022469
 >> iter 16000, loss: 0.021912
 >> iter 17000, loss: 0.021854
 >> iter 18000, loss: 0.021372
 >> iter 19000, loss: 0.021187
 >> iter 20000, loss: 0.020571
   Number of active neurons: 2
 >> iter 21000, loss: 0.020346
 >> iter 22000, loss: 0.019812
 >> iter 23000, loss: 0.019740
 >> iter 24000, loss: 0.019377
 >> iter 25000, loss: 0.019443
 >> iter 26000, loss: 0.019178
 >> iter 27000, loss: 0.019283
 >> iter 28000, loss: 0.019046
 >> iter 29000, loss: 0.019135
 >> iter 30000, loss: 0.018879
   Number of active neurons: 1
 >> iter 31000, loss: 0.018920
 >> iter 32000, loss: 0.018586
 >> iter 33000, loss: 0.018407
 >> iter 34000, loss: 0.017784
 >> iter 35000, loss: 0.017467
 >> iter 36000, loss: 0.016839
 >> iter 37000, loss: 0.016576
 >> iter 38000, loss: 0.016086
 >> iter 39000, loss: 0.015985
 >> iter 40000, loss: 0.015624
   Number of active neurons: 1
 >> iter 41000, loss: 0.015614
 >> iter 42000, loss: 0.015331
 >> iter 43000, loss: 0.015362
 >> iter 44000, loss: 0.015129
 >> iter 45000, loss: 0.015186
 >> iter 46000, loss: 0.014971
 >> iter 47000, loss: 0.015044
 >> iter 48000, loss: 0.014850
 >> iter 49000, loss: 0.014936
 >> iter 50000, loss: 0.014744
   Number of active neurons: 1
 >> iter 51000, loss: 0.014841
 >> iter 52000, loss: 0.014664
 >> iter 53000, loss: 0.014757
 >> iter 54000, loss: 0.014607
 >> iter 55000, loss: 0.014683
 >> iter 56000, loss: 0.014543
 >> iter 57000, loss: 0.014633
 >> iter 58000, loss: 0.014480
 >> iter 59000, loss: 0.014584
 >> iter 60000, loss: 0.014438
   Number of active neurons: 1
 >> iter 61000, loss: 0.014535
 >> iter 62000, loss: 0.014398
 >> iter 63000, loss: 0.014500
 >> iter 64000, loss: 0.014353
 >> iter 65000, loss: 0.014466
 >> iter 66000, loss: 0.014325
 >> iter 67000, loss: 0.014432
 >> iter 68000, loss: 0.014311
 >> iter 69000, loss: 0.014408
 >> iter 70000, loss: 0.014279
   Number of active neurons: 1
 >> iter 71000, loss: 0.014386
 >> iter 72000, loss: 0.014266
 >> iter 73000, loss: 0.014368
 >> iter 74000, loss: 0.014244
 >> iter 75000, loss: 0.014353
 >> iter 76000, loss: 0.014229
 >> iter 77000, loss: 0.014335
 >> iter 78000, loss: 0.014208
 >> iter 79000, loss: 0.014337
 >> iter 80000, loss: 0.014199
   Number of active neurons: 1
 >> iter 81000, loss: 0.014343
 >> iter 82000, loss: 0.014191
 >> iter 83000, loss: 0.014344
 >> iter 84000, loss: 0.014181
 >> iter 85000, loss: 0.014332
 >> iter 86000, loss: 0.014170
 >> iter 87000, loss: 0.014326
 >> iter 88000, loss: 0.014162
 >> iter 89000, loss: 0.014315
 >> iter 90000, loss: 0.014163
   Number of active neurons: 1
 >> iter 91000, loss: 0.014310
 >> iter 92000, loss: 0.014163
 >> iter 93000, loss: 0.014310
 >> iter 94000, loss: 0.014153
 >> iter 95000, loss: 0.014321
 >> iter 96000, loss: 0.014146
 >> iter 97000, loss: 0.014320
 >> iter 98000, loss: 0.014139
 >> iter 99000, loss: 0.014320
 >> iter 100000, loss: 0.014152
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.723999
 >> iter 2000, loss: 3.964380
 >> iter 3000, loss: 1.474626
 >> iter 4000, loss: 0.557373
 >> iter 5000, loss: 0.219852
 >> iter 6000, loss: 0.095160
 >> iter 7000, loss: 0.049586
 >> iter 8000, loss: 0.032519
 >> iter 9000, loss: 0.026599
 >> iter 10000, loss: 0.024106
   Number of active neurons: 4
 >> iter 11000, loss: 0.023551
 >> iter 12000, loss: 0.023030
 >> iter 13000, loss: 0.023251
 >> iter 14000, loss: 0.022984
 >> iter 15000, loss: 0.023269
 >> iter 16000, loss: 0.023033
 >> iter 17000, loss: 0.023311
 >> iter 18000, loss: 0.023041
 >> iter 19000, loss: 0.023227
 >> iter 20000, loss: 0.022893
   Number of active neurons: 3
 >> iter 21000, loss: 0.022901
 >> iter 22000, loss: 0.022348
 >> iter 23000, loss: 0.022240
 >> iter 24000, loss: 0.021698
 >> iter 25000, loss: 0.021687
 >> iter 26000, loss: 0.021298
 >> iter 27000, loss: 0.021358
 >> iter 28000, loss: 0.021001
 >> iter 29000, loss: 0.020992
 >> iter 30000, loss: 0.020455
   Number of active neurons: 2
 >> iter 31000, loss: 0.020257
 >> iter 32000, loss: 0.019701
 >> iter 33000, loss: 0.019560
 >> iter 34000, loss: 0.019146
 >> iter 35000, loss: 0.019183
 >> iter 36000, loss: 0.018894
 >> iter 37000, loss: 0.019025
 >> iter 38000, loss: 0.018793
 >> iter 39000, loss: 0.018971
 >> iter 40000, loss: 0.018760
   Number of active neurons: 2
 >> iter 41000, loss: 0.018946
 >> iter 42000, loss: 0.018754
 >> iter 43000, loss: 0.018926
 >> iter 44000, loss: 0.018746
 >> iter 45000, loss: 0.018900
 >> iter 46000, loss: 0.018702
 >> iter 47000, loss: 0.018821
 >> iter 48000, loss: 0.018594
 >> iter 49000, loss: 0.018644
 >> iter 50000, loss: 0.018282
   Number of active neurons: 1
 >> iter 51000, loss: 0.018046
 >> iter 52000, loss: 0.017446
 >> iter 53000, loss: 0.017141
 >> iter 54000, loss: 0.016583
 >> iter 55000, loss: 0.016321
 >> iter 56000, loss: 0.015919
 >> iter 57000, loss: 0.015813
 >> iter 58000, loss: 0.015506
 >> iter 59000, loss: 0.015492
 >> iter 60000, loss: 0.015250
   Number of active neurons: 1
 >> iter 61000, loss: 0.015268
 >> iter 62000, loss: 0.015065
 >> iter 63000, loss: 0.015111
 >> iter 64000, loss: 0.014914
 >> iter 65000, loss: 0.014983
 >> iter 66000, loss: 0.014802
 >> iter 67000, loss: 0.014873
 >> iter 68000, loss: 0.014719
 >> iter 69000, loss: 0.014787
 >> iter 70000, loss: 0.014630
   Number of active neurons: 1
 >> iter 71000, loss: 0.014712
 >> iter 72000, loss: 0.014568
 >> iter 73000, loss: 0.014649
 >> iter 74000, loss: 0.014504
 >> iter 75000, loss: 0.014595
 >> iter 76000, loss: 0.014453
 >> iter 77000, loss: 0.014543
 >> iter 78000, loss: 0.014401
 >> iter 79000, loss: 0.014517
 >> iter 80000, loss: 0.014366
   Number of active neurons: 1
 >> iter 81000, loss: 0.014498
 >> iter 82000, loss: 0.014335
 >> iter 83000, loss: 0.014478
 >> iter 84000, loss: 0.014305
 >> iter 85000, loss: 0.014448
 >> iter 86000, loss: 0.014277
 >> iter 87000, loss: 0.014426
 >> iter 88000, loss: 0.014254
 >> iter 89000, loss: 0.014401
 >> iter 90000, loss: 0.014242
   Number of active neurons: 1
 >> iter 91000, loss: 0.014384
 >> iter 92000, loss: 0.014231
 >> iter 93000, loss: 0.014374
 >> iter 94000, loss: 0.014213
 >> iter 95000, loss: 0.014376
 >> iter 96000, loss: 0.014197
 >> iter 97000, loss: 0.014368
 >> iter 98000, loss: 0.014183
 >> iter 99000, loss: 0.014361
 >> iter 100000, loss: 0.014190
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.700426
 >> iter 2000, loss: 3.957649
 >> iter 3000, loss: 1.474177
 >> iter 4000, loss: 0.558845
 >> iter 5000, loss: 0.221811
 >> iter 6000, loss: 0.096812
 >> iter 7000, loss: 0.050732
 >> iter 8000, loss: 0.033001
 >> iter 9000, loss: 0.026481
 >> iter 10000, loss: 0.023311
   Number of active neurons: 3
 >> iter 11000, loss: 0.022168
 >> iter 12000, loss: 0.021120
 >> iter 13000, loss: 0.020958
 >> iter 14000, loss: 0.020470
 >> iter 15000, loss: 0.020665
 >> iter 16000, loss: 0.020396
 >> iter 17000, loss: 0.020637
 >> iter 18000, loss: 0.020383
 >> iter 19000, loss: 0.020621
 >> iter 20000, loss: 0.020415
   Number of active neurons: 3
 >> iter 21000, loss: 0.020680
 >> iter 22000, loss: 0.020483
 >> iter 23000, loss: 0.020743
 >> iter 24000, loss: 0.020536
 >> iter 25000, loss: 0.020826
 >> iter 26000, loss: 0.020641
 >> iter 27000, loss: 0.020911
 >> iter 28000, loss: 0.020722
 >> iter 29000, loss: 0.020970
 >> iter 30000, loss: 0.020778
   Number of active neurons: 3
 >> iter 31000, loss: 0.021026
 >> iter 32000, loss: 0.020830
 >> iter 33000, loss: 0.021069
 >> iter 34000, loss: 0.020870
 >> iter 35000, loss: 0.021110
 >> iter 36000, loss: 0.020882
 >> iter 37000, loss: 0.021094
 >> iter 38000, loss: 0.020832
 >> iter 39000, loss: 0.021000
 >> iter 40000, loss: 0.020668
   Number of active neurons: 2
 >> iter 41000, loss: 0.020682
 >> iter 42000, loss: 0.020123
 >> iter 43000, loss: 0.019974
 >> iter 44000, loss: 0.019458
 >> iter 45000, loss: 0.019361
 >> iter 46000, loss: 0.018981
 >> iter 47000, loss: 0.019036
 >> iter 48000, loss: 0.018787
 >> iter 49000, loss: 0.018923
 >> iter 50000, loss: 0.018717
   Number of active neurons: 2
 >> iter 51000, loss: 0.018887
 >> iter 52000, loss: 0.018713
 >> iter 53000, loss: 0.018877
 >> iter 54000, loss: 0.018737
 >> iter 55000, loss: 0.018869
 >> iter 56000, loss: 0.018730
 >> iter 57000, loss: 0.018860
 >> iter 58000, loss: 0.018680
 >> iter 59000, loss: 0.018788
 >> iter 60000, loss: 0.018570
   Number of active neurons: 1
 >> iter 61000, loss: 0.018589
 >> iter 62000, loss: 0.018221
 >> iter 63000, loss: 0.017939
 >> iter 64000, loss: 0.017346
 >> iter 65000, loss: 0.017043
 >> iter 66000, loss: 0.016481
 >> iter 67000, loss: 0.016250
 >> iter 68000, loss: 0.015864
 >> iter 69000, loss: 0.015759
 >> iter 70000, loss: 0.015470
   Number of active neurons: 1
 >> iter 71000, loss: 0.015450
 >> iter 72000, loss: 0.015226
 >> iter 73000, loss: 0.015241
 >> iter 74000, loss: 0.015042
 >> iter 75000, loss: 0.015085
 >> iter 76000, loss: 0.014903
 >> iter 77000, loss: 0.014957
 >> iter 78000, loss: 0.014783
 >> iter 79000, loss: 0.014871
 >> iter 80000, loss: 0.014693
   Number of active neurons: 1
 >> iter 81000, loss: 0.014801
 >> iter 82000, loss: 0.014616
 >> iter 83000, loss: 0.014739
 >> iter 84000, loss: 0.014547
 >> iter 85000, loss: 0.014672
 >> iter 86000, loss: 0.014485
 >> iter 87000, loss: 0.014619
 >> iter 88000, loss: 0.014434
 >> iter 89000, loss: 0.014568
 >> iter 90000, loss: 0.014397
   Number of active neurons: 1
 >> iter 91000, loss: 0.014528
 >> iter 92000, loss: 0.014365
 >> iter 93000, loss: 0.014498
 >> iter 94000, loss: 0.014328
 >> iter 95000, loss: 0.014483
 >> iter 96000, loss: 0.014296
 >> iter 97000, loss: 0.014460
 >> iter 98000, loss: 0.014269
 >> iter 99000, loss: 0.014441
 >> iter 100000, loss: 0.014264
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.727601
 >> iter 2000, loss: 3.967230
 >> iter 3000, loss: 1.478018
 >> iter 4000, loss: 0.561203
 >> iter 5000, loss: 0.223992
 >> iter 6000, loss: 0.099129
 >> iter 7000, loss: 0.053059
 >> iter 8000, loss: 0.035199
 >> iter 9000, loss: 0.028453
 >> iter 10000, loss: 0.025077
   Number of active neurons: 3
 >> iter 11000, loss: 0.023761
 >> iter 12000, loss: 0.022567
 >> iter 13000, loss: 0.022193
 >> iter 14000, loss: 0.021339
 >> iter 15000, loss: 0.021028
 >> iter 16000, loss: 0.020229
 >> iter 17000, loss: 0.019974
 >> iter 18000, loss: 0.019243
 >> iter 19000, loss: 0.019037
 >> iter 20000, loss: 0.018427
   Number of active neurons: 2
 >> iter 21000, loss: 0.018354
 >> iter 22000, loss: 0.017915
 >> iter 23000, loss: 0.017997
 >> iter 24000, loss: 0.017652
 >> iter 25000, loss: 0.017810
 >> iter 26000, loss: 0.017517
 >> iter 27000, loss: 0.017693
 >> iter 28000, loss: 0.017422
 >> iter 29000, loss: 0.017602
 >> iter 30000, loss: 0.017344
   Number of active neurons: 2
 >> iter 31000, loss: 0.017536
 >> iter 32000, loss: 0.017288
 >> iter 33000, loss: 0.017488
 >> iter 34000, loss: 0.017252
 >> iter 35000, loss: 0.017472
 >> iter 36000, loss: 0.017234
 >> iter 37000, loss: 0.017458
 >> iter 38000, loss: 0.017225
 >> iter 39000, loss: 0.017464
 >> iter 40000, loss: 0.017235
   Number of active neurons: 2
 >> iter 41000, loss: 0.017476
 >> iter 42000, loss: 0.017270
 >> iter 43000, loss: 0.017498
 >> iter 44000, loss: 0.017316
 >> iter 45000, loss: 0.017548
 >> iter 46000, loss: 0.017337
 >> iter 47000, loss: 0.017545
 >> iter 48000, loss: 0.017365
 >> iter 49000, loss: 0.017590
 >> iter 50000, loss: 0.017413
   Number of active neurons: 2
 >> iter 51000, loss: 0.017614
 >> iter 52000, loss: 0.017441
 >> iter 53000, loss: 0.017651
 >> iter 54000, loss: 0.017514
 >> iter 55000, loss: 0.017690
 >> iter 56000, loss: 0.017558
 >> iter 57000, loss: 0.017743
 >> iter 58000, loss: 0.017583
 >> iter 59000, loss: 0.017779
 >> iter 60000, loss: 0.017625
   Number of active neurons: 2
 >> iter 61000, loss: 0.017806
 >> iter 62000, loss: 0.017662
 >> iter 63000, loss: 0.017845
 >> iter 64000, loss: 0.017687
 >> iter 65000, loss: 0.017882
 >> iter 66000, loss: 0.017731
 >> iter 67000, loss: 0.017915
 >> iter 68000, loss: 0.017789
 >> iter 69000, loss: 0.017960
 >> iter 70000, loss: 0.017825
   Number of active neurons: 2
 >> iter 71000, loss: 0.018008
 >> iter 72000, loss: 0.017885
 >> iter 73000, loss: 0.018062
 >> iter 74000, loss: 0.017935
 >> iter 75000, loss: 0.018119
 >> iter 76000, loss: 0.017995
 >> iter 77000, loss: 0.018176
 >> iter 78000, loss: 0.018048
 >> iter 79000, loss: 0.018260
 >> iter 80000, loss: 0.018121
   Number of active neurons: 2
 >> iter 81000, loss: 0.018351
 >> iter 82000, loss: 0.018195
 >> iter 83000, loss: 0.018436
 >> iter 84000, loss: 0.018268
 >> iter 85000, loss: 0.018502
 >> iter 86000, loss: 0.018336
 >> iter 87000, loss: 0.018572
 >> iter 88000, loss: 0.018403
 >> iter 89000, loss: 0.018627
 >> iter 90000, loss: 0.018469
   Number of active neurons: 2
 >> iter 91000, loss: 0.018670
 >> iter 92000, loss: 0.018506
 >> iter 93000, loss: 0.018682
 >> iter 94000, loss: 0.018483
 >> iter 95000, loss: 0.018637
 >> iter 96000, loss: 0.018362
 >> iter 97000, loss: 0.018403
 >> iter 98000, loss: 0.017878
 >> iter 99000, loss: 0.017649
 >> iter 100000, loss: 0.017048
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.729326
 >> iter 2000, loss: 3.966962
 >> iter 3000, loss: 1.476420
 >> iter 4000, loss: 0.558723
 >> iter 5000, loss: 0.221115
 >> iter 6000, loss: 0.096234
 >> iter 7000, loss: 0.050438
 >> iter 8000, loss: 0.032961
 >> iter 9000, loss: 0.026670
 >> iter 10000, loss: 0.023672
   Number of active neurons: 3
 >> iter 11000, loss: 0.022761
 >> iter 12000, loss: 0.021798
 >> iter 13000, loss: 0.021638
 >> iter 14000, loss: 0.020954
 >> iter 15000, loss: 0.020933
 >> iter 16000, loss: 0.020460
 >> iter 17000, loss: 0.020630
 >> iter 18000, loss: 0.020316
 >> iter 19000, loss: 0.020559
 >> iter 20000, loss: 0.020325
   Number of active neurons: 3
 >> iter 21000, loss: 0.020568
 >> iter 22000, loss: 0.020318
 >> iter 23000, loss: 0.020583
 >> iter 24000, loss: 0.020361
 >> iter 25000, loss: 0.020625
 >> iter 26000, loss: 0.020403
 >> iter 27000, loss: 0.020672
 >> iter 28000, loss: 0.020478
 >> iter 29000, loss: 0.020733
 >> iter 30000, loss: 0.020523
   Number of active neurons: 3
 >> iter 31000, loss: 0.020780
 >> iter 32000, loss: 0.020587
 >> iter 33000, loss: 0.020831
 >> iter 34000, loss: 0.020627
 >> iter 35000, loss: 0.020864
 >> iter 36000, loss: 0.020626
 >> iter 37000, loss: 0.020833
 >> iter 38000, loss: 0.020559
 >> iter 39000, loss: 0.020725
 >> iter 40000, loss: 0.020388
   Number of active neurons: 2
 >> iter 41000, loss: 0.020436
 >> iter 42000, loss: 0.019889
 >> iter 43000, loss: 0.019733
 >> iter 44000, loss: 0.019208
 >> iter 45000, loss: 0.019095
 >> iter 46000, loss: 0.018684
 >> iter 47000, loss: 0.018726
 >> iter 48000, loss: 0.018458
 >> iter 49000, loss: 0.018589
 >> iter 50000, loss: 0.018370
   Number of active neurons: 2
 >> iter 51000, loss: 0.018544
 >> iter 52000, loss: 0.018361
 >> iter 53000, loss: 0.018535
 >> iter 54000, loss: 0.018394
 >> iter 55000, loss: 0.018549
 >> iter 56000, loss: 0.018423
 >> iter 57000, loss: 0.018596
 >> iter 58000, loss: 0.018451
 >> iter 59000, loss: 0.018640
 >> iter 60000, loss: 0.018503
   Number of active neurons: 2
 >> iter 61000, loss: 0.018677
 >> iter 62000, loss: 0.018549
 >> iter 63000, loss: 0.018721
 >> iter 64000, loss: 0.018573
 >> iter 65000, loss: 0.018743
 >> iter 66000, loss: 0.018590
 >> iter 67000, loss: 0.018726
 >> iter 68000, loss: 0.018571
 >> iter 69000, loss: 0.018648
 >> iter 70000, loss: 0.018426
   Number of active neurons: 1
 >> iter 71000, loss: 0.018395
 >> iter 72000, loss: 0.017930
 >> iter 73000, loss: 0.017616
 >> iter 74000, loss: 0.017057
 >> iter 75000, loss: 0.016746
 >> iter 76000, loss: 0.016239
 >> iter 77000, loss: 0.016048
 >> iter 78000, loss: 0.015689
 >> iter 79000, loss: 0.015640
 >> iter 80000, loss: 0.015359
   Number of active neurons: 1
 >> iter 81000, loss: 0.015387
 >> iter 82000, loss: 0.015138
 >> iter 83000, loss: 0.015208
 >> iter 84000, loss: 0.014973
 >> iter 85000, loss: 0.015061
 >> iter 86000, loss: 0.014842
 >> iter 87000, loss: 0.014947
 >> iter 88000, loss: 0.014737
 >> iter 89000, loss: 0.014848
 >> iter 90000, loss: 0.014656
   Number of active neurons: 1
 >> iter 91000, loss: 0.014768
 >> iter 92000, loss: 0.014587
 >> iter 93000, loss: 0.014704
 >> iter 94000, loss: 0.014519
 >> iter 95000, loss: 0.014661
 >> iter 96000, loss: 0.014461
 >> iter 97000, loss: 0.014613
 >> iter 98000, loss: 0.014411
 >> iter 99000, loss: 0.014573
 >> iter 100000, loss: 0.014386
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.667744
 >> iter 2000, loss: 3.946931
 >> iter 3000, loss: 1.470770
 >> iter 4000, loss: 0.557944
 >> iter 5000, loss: 0.221584
 >> iter 6000, loss: 0.097017
 >> iter 7000, loss: 0.051052
 >> iter 8000, loss: 0.033588
 >> iter 9000, loss: 0.027226
 >> iter 10000, loss: 0.024322
   Number of active neurons: 3
 >> iter 11000, loss: 0.023279
 >> iter 12000, loss: 0.022369
 >> iter 13000, loss: 0.022193
 >> iter 14000, loss: 0.021718
 >> iter 15000, loss: 0.021768
 >> iter 16000, loss: 0.021397
 >> iter 17000, loss: 0.021441
 >> iter 18000, loss: 0.020973
 >> iter 19000, loss: 0.020782
 >> iter 20000, loss: 0.020210
   Number of active neurons: 2
 >> iter 21000, loss: 0.020027
 >> iter 22000, loss: 0.019556
 >> iter 23000, loss: 0.019538
 >> iter 24000, loss: 0.019216
 >> iter 25000, loss: 0.019314
 >> iter 26000, loss: 0.019072
 >> iter 27000, loss: 0.019200
 >> iter 28000, loss: 0.018984
 >> iter 29000, loss: 0.019099
 >> iter 30000, loss: 0.018873
   Number of active neurons: 1
 >> iter 31000, loss: 0.018959
 >> iter 32000, loss: 0.018685
 >> iter 33000, loss: 0.018682
 >> iter 34000, loss: 0.018206
 >> iter 35000, loss: 0.017906
 >> iter 36000, loss: 0.017275
 >> iter 37000, loss: 0.016971
 >> iter 38000, loss: 0.016395
 >> iter 39000, loss: 0.016222
 >> iter 40000, loss: 0.015805
   Number of active neurons: 1
 >> iter 41000, loss: 0.015756
 >> iter 42000, loss: 0.015443
 >> iter 43000, loss: 0.015454
 >> iter 44000, loss: 0.015205
 >> iter 45000, loss: 0.015251
 >> iter 46000, loss: 0.015027
 >> iter 47000, loss: 0.015093
 >> iter 48000, loss: 0.014895
 >> iter 49000, loss: 0.014976
 >> iter 50000, loss: 0.014780
   Number of active neurons: 1
 >> iter 51000, loss: 0.014874
 >> iter 52000, loss: 0.014695
 >> iter 53000, loss: 0.014784
 >> iter 54000, loss: 0.014633
 >> iter 55000, loss: 0.014706
 >> iter 56000, loss: 0.014565
 >> iter 57000, loss: 0.014653
 >> iter 58000, loss: 0.014498
 >> iter 59000, loss: 0.014602
 >> iter 60000, loss: 0.014454
   Number of active neurons: 1
 >> iter 61000, loss: 0.014550
 >> iter 62000, loss: 0.014411
 >> iter 63000, loss: 0.014513
 >> iter 64000, loss: 0.014365
 >> iter 65000, loss: 0.014477
 >> iter 66000, loss: 0.014336
 >> iter 67000, loss: 0.014441
 >> iter 68000, loss: 0.014319
 >> iter 69000, loss: 0.014416
 >> iter 70000, loss: 0.014287
   Number of active neurons: 1
 >> iter 71000, loss: 0.014393
 >> iter 72000, loss: 0.014272
 >> iter 73000, loss: 0.014374
 >> iter 74000, loss: 0.014250
 >> iter 75000, loss: 0.014358
 >> iter 76000, loss: 0.014234
 >> iter 77000, loss: 0.014339
 >> iter 78000, loss: 0.014212
 >> iter 79000, loss: 0.014341
 >> iter 80000, loss: 0.014203
   Number of active neurons: 1
 >> iter 81000, loss: 0.014346
 >> iter 82000, loss: 0.014194
 >> iter 83000, loss: 0.014347
 >> iter 84000, loss: 0.014184
 >> iter 85000, loss: 0.014335
 >> iter 86000, loss: 0.014172
 >> iter 87000, loss: 0.014328
 >> iter 88000, loss: 0.014164
 >> iter 89000, loss: 0.014317
 >> iter 90000, loss: 0.014164
   Number of active neurons: 1
 >> iter 91000, loss: 0.014312
 >> iter 92000, loss: 0.014164
 >> iter 93000, loss: 0.014311
 >> iter 94000, loss: 0.014155
 >> iter 95000, loss: 0.014322
 >> iter 96000, loss: 0.014147
 >> iter 97000, loss: 0.014321
 >> iter 98000, loss: 0.014140
 >> iter 99000, loss: 0.014321
 >> iter 100000, loss: 0.014153
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.697081
 >> iter 2000, loss: 3.956686
 >> iter 3000, loss: 1.474176
 >> iter 4000, loss: 0.559590
 >> iter 5000, loss: 0.222998
 >> iter 6000, loss: 0.098518
 >> iter 7000, loss: 0.052783
 >> iter 8000, loss: 0.035454
 >> iter 9000, loss: 0.029271
 >> iter 10000, loss: 0.026515
   Number of active neurons: 3
 >> iter 11000, loss: 0.025625
 >> iter 12000, loss: 0.024593
 >> iter 13000, loss: 0.024104
 >> iter 14000, loss: 0.023147
 >> iter 15000, loss: 0.022825
 >> iter 16000, loss: 0.022222
 >> iter 17000, loss: 0.022243
 >> iter 18000, loss: 0.021911
 >> iter 19000, loss: 0.022074
 >> iter 20000, loss: 0.021855
   Number of active neurons: 3
 >> iter 21000, loss: 0.022049
 >> iter 22000, loss: 0.021836
 >> iter 23000, loss: 0.022025
 >> iter 24000, loss: 0.021776
 >> iter 25000, loss: 0.021912
 >> iter 26000, loss: 0.021590
 >> iter 27000, loss: 0.021506
 >> iter 28000, loss: 0.020889
 >> iter 29000, loss: 0.020598
 >> iter 30000, loss: 0.019948
   Number of active neurons: 1
 >> iter 31000, loss: 0.019657
 >> iter 32000, loss: 0.019007
 >> iter 33000, loss: 0.018550
 >> iter 34000, loss: 0.017796
 >> iter 35000, loss: 0.017387
 >> iter 36000, loss: 0.016745
 >> iter 37000, loss: 0.016515
 >> iter 38000, loss: 0.016064
 >> iter 39000, loss: 0.015989
 >> iter 40000, loss: 0.015647
   Number of active neurons: 1
 >> iter 41000, loss: 0.015649
 >> iter 42000, loss: 0.015374
 >> iter 43000, loss: 0.015410
 >> iter 44000, loss: 0.015178
 >> iter 45000, loss: 0.015235
 >> iter 46000, loss: 0.015020
 >> iter 47000, loss: 0.015091
 >> iter 48000, loss: 0.014895
 >> iter 49000, loss: 0.014979
 >> iter 50000, loss: 0.014784
   Number of active neurons: 1
 >> iter 51000, loss: 0.014879
 >> iter 52000, loss: 0.014700
 >> iter 53000, loss: 0.014790
 >> iter 54000, loss: 0.014638
 >> iter 55000, loss: 0.014712
 >> iter 56000, loss: 0.014570
 >> iter 57000, loss: 0.014659
 >> iter 58000, loss: 0.014503
 >> iter 59000, loss: 0.014606
 >> iter 60000, loss: 0.014458
   Number of active neurons: 1
 >> iter 61000, loss: 0.014554
 >> iter 62000, loss: 0.014415
 >> iter 63000, loss: 0.014516
 >> iter 64000, loss: 0.014368
 >> iter 65000, loss: 0.014480
 >> iter 66000, loss: 0.014339
 >> iter 67000, loss: 0.014444
 >> iter 68000, loss: 0.014322
 >> iter 69000, loss: 0.014418
 >> iter 70000, loss: 0.014289
   Number of active neurons: 1
 >> iter 71000, loss: 0.014395
 >> iter 72000, loss: 0.014274
 >> iter 73000, loss: 0.014376
 >> iter 74000, loss: 0.014251
 >> iter 75000, loss: 0.014359
 >> iter 76000, loss: 0.014235
 >> iter 77000, loss: 0.014341
 >> iter 78000, loss: 0.014213
 >> iter 79000, loss: 0.014342
 >> iter 80000, loss: 0.014204
   Number of active neurons: 1
 >> iter 81000, loss: 0.014347
 >> iter 82000, loss: 0.014195
 >> iter 83000, loss: 0.014348
 >> iter 84000, loss: 0.014185
 >> iter 85000, loss: 0.014335
 >> iter 86000, loss: 0.014173
 >> iter 87000, loss: 0.014329
 >> iter 88000, loss: 0.014165
 >> iter 89000, loss: 0.014318
 >> iter 90000, loss: 0.014165
   Number of active neurons: 1
 >> iter 91000, loss: 0.014312
 >> iter 92000, loss: 0.014165
 >> iter 93000, loss: 0.014312
 >> iter 94000, loss: 0.014155
 >> iter 95000, loss: 0.014323
 >> iter 96000, loss: 0.014148
 >> iter 97000, loss: 0.014321
 >> iter 98000, loss: 0.014141
 >> iter 99000, loss: 0.014321
 >> iter 100000, loss: 0.014153
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.742711
 >> iter 2000, loss: 3.972345
 >> iter 3000, loss: 1.479412
 >> iter 4000, loss: 0.561121
 >> iter 5000, loss: 0.223414
 >> iter 6000, loss: 0.098561
 >> iter 7000, loss: 0.052750
 >> iter 8000, loss: 0.035081
 >> iter 9000, loss: 0.028634
 >> iter 10000, loss: 0.025589
   Number of active neurons: 3
 >> iter 11000, loss: 0.024573
 >> iter 12000, loss: 0.023517
 >> iter 13000, loss: 0.023246
 >> iter 14000, loss: 0.022504
 >> iter 15000, loss: 0.022368
 >> iter 16000, loss: 0.021695
 >> iter 17000, loss: 0.021551
 >> iter 18000, loss: 0.020934
 >> iter 19000, loss: 0.020912
 >> iter 20000, loss: 0.020490
   Number of active neurons: 2
 >> iter 21000, loss: 0.020562
 >> iter 22000, loss: 0.020177
 >> iter 23000, loss: 0.020239
 >> iter 24000, loss: 0.019784
 >> iter 25000, loss: 0.019673
 >> iter 26000, loss: 0.019082
 >> iter 27000, loss: 0.018948
 >> iter 28000, loss: 0.018443
 >> iter 29000, loss: 0.018426
 >> iter 30000, loss: 0.018079
   Number of active neurons: 2
 >> iter 31000, loss: 0.018151
 >> iter 32000, loss: 0.017873
 >> iter 33000, loss: 0.018020
 >> iter 34000, loss: 0.017796
 >> iter 35000, loss: 0.017975
 >> iter 36000, loss: 0.017736
 >> iter 37000, loss: 0.017930
 >> iter 38000, loss: 0.017719
 >> iter 39000, loss: 0.017933
 >> iter 40000, loss: 0.017720
   Number of active neurons: 2
 >> iter 41000, loss: 0.017932
 >> iter 42000, loss: 0.017731
 >> iter 43000, loss: 0.017930
 >> iter 44000, loss: 0.017747
 >> iter 45000, loss: 0.017947
 >> iter 46000, loss: 0.017761
 >> iter 47000, loss: 0.017961
 >> iter 48000, loss: 0.017790
 >> iter 49000, loss: 0.017994
 >> iter 50000, loss: 0.017816
   Number of active neurons: 2
 >> iter 51000, loss: 0.018026
 >> iter 52000, loss: 0.017861
 >> iter 53000, loss: 0.018058
 >> iter 54000, loss: 0.017924
 >> iter 55000, loss: 0.018095
 >> iter 56000, loss: 0.017972
 >> iter 57000, loss: 0.018158
 >> iter 58000, loss: 0.018014
 >> iter 59000, loss: 0.018215
 >> iter 60000, loss: 0.018080
   Number of active neurons: 2
 >> iter 61000, loss: 0.018269
 >> iter 62000, loss: 0.018145
 >> iter 63000, loss: 0.018337
 >> iter 64000, loss: 0.018201
 >> iter 65000, loss: 0.018404
 >> iter 66000, loss: 0.018275
 >> iter 67000, loss: 0.018466
 >> iter 68000, loss: 0.018362
 >> iter 69000, loss: 0.018535
 >> iter 70000, loss: 0.018418
   Number of active neurons: 2
 >> iter 71000, loss: 0.018595
 >> iter 72000, loss: 0.018484
 >> iter 73000, loss: 0.018642
 >> iter 74000, loss: 0.018514
 >> iter 75000, loss: 0.018658
 >> iter 76000, loss: 0.018508
 >> iter 77000, loss: 0.018609
 >> iter 78000, loss: 0.018407
 >> iter 79000, loss: 0.018456
 >> iter 80000, loss: 0.018055
   Number of active neurons: 1
 >> iter 81000, loss: 0.017810
 >> iter 82000, loss: 0.017221
 >> iter 83000, loss: 0.016961
 >> iter 84000, loss: 0.016383
 >> iter 85000, loss: 0.016197
 >> iter 86000, loss: 0.015773
 >> iter 87000, loss: 0.015727
 >> iter 88000, loss: 0.015403
 >> iter 89000, loss: 0.015427
 >> iter 90000, loss: 0.015169
   Number of active neurons: 1
 >> iter 91000, loss: 0.015225
 >> iter 92000, loss: 0.015001
 >> iter 93000, loss: 0.015080
 >> iter 94000, loss: 0.014863
 >> iter 95000, loss: 0.014976
 >> iter 96000, loss: 0.014752
 >> iter 97000, loss: 0.014881
 >> iter 98000, loss: 0.014659
 >> iter 99000, loss: 0.014802
 >> iter 100000, loss: 0.014599
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.714398
 >> iter 2000, loss: 3.964927
 >> iter 3000, loss: 1.479166
 >> iter 4000, loss: 0.563306
 >> iter 5000, loss: 0.226134
 >> iter 6000, loss: 0.101353
 >> iter 7000, loss: 0.055429
 >> iter 8000, loss: 0.037825
 >> iter 9000, loss: 0.031301
 >> iter 10000, loss: 0.028065
   Number of active neurons: 2
 >> iter 11000, loss: 0.026554
 >> iter 12000, loss: 0.024995
 >> iter 13000, loss: 0.024061
 >> iter 14000, loss: 0.022744
 >> iter 15000, loss: 0.021949
 >> iter 16000, loss: 0.020910
 >> iter 17000, loss: 0.020489
 >> iter 18000, loss: 0.019874
 >> iter 19000, loss: 0.019781
 >> iter 20000, loss: 0.019432
   Number of active neurons: 2
 >> iter 21000, loss: 0.019487
 >> iter 22000, loss: 0.019230
 >> iter 23000, loss: 0.019349
 >> iter 24000, loss: 0.019117
 >> iter 25000, loss: 0.019256
 >> iter 26000, loss: 0.019033
 >> iter 27000, loss: 0.019146
 >> iter 28000, loss: 0.018900
 >> iter 29000, loss: 0.018947
 >> iter 30000, loss: 0.018627
   Number of active neurons: 1
 >> iter 31000, loss: 0.018486
 >> iter 32000, loss: 0.017867
 >> iter 33000, loss: 0.017540
 >> iter 34000, loss: 0.016922
 >> iter 35000, loss: 0.016644
 >> iter 36000, loss: 0.016144
 >> iter 37000, loss: 0.016025
 >> iter 38000, loss: 0.015658
 >> iter 39000, loss: 0.015646
 >> iter 40000, loss: 0.015351
   Number of active neurons: 1
 >> iter 41000, loss: 0.015389
 >> iter 42000, loss: 0.015141
 >> iter 43000, loss: 0.015199
 >> iter 44000, loss: 0.014986
 >> iter 45000, loss: 0.015059
 >> iter 46000, loss: 0.014857
 >> iter 47000, loss: 0.014941
 >> iter 48000, loss: 0.014756
 >> iter 49000, loss: 0.014850
 >> iter 50000, loss: 0.014665
   Number of active neurons: 1
 >> iter 51000, loss: 0.014768
 >> iter 52000, loss: 0.014596
 >> iter 53000, loss: 0.014694
 >> iter 54000, loss: 0.014549
 >> iter 55000, loss: 0.014628
 >> iter 56000, loss: 0.014493
 >> iter 57000, loss: 0.014587
 >> iter 58000, loss: 0.014436
 >> iter 59000, loss: 0.014544
 >> iter 60000, loss: 0.014401
   Number of active neurons: 1
 >> iter 61000, loss: 0.014500
 >> iter 62000, loss: 0.014366
 >> iter 63000, loss: 0.014470
 >> iter 64000, loss: 0.014326
 >> iter 65000, loss: 0.014440
 >> iter 66000, loss: 0.014302
 >> iter 67000, loss: 0.014409
 >> iter 68000, loss: 0.014290
 >> iter 69000, loss: 0.014389
 >> iter 70000, loss: 0.014261
   Number of active neurons: 1
 >> iter 71000, loss: 0.014369
 >> iter 72000, loss: 0.014251
 >> iter 73000, loss: 0.014354
 >> iter 74000, loss: 0.014231
 >> iter 75000, loss: 0.014340
 >> iter 76000, loss: 0.014218
 >> iter 77000, loss: 0.014324
 >> iter 78000, loss: 0.014198
 >> iter 79000, loss: 0.014328
 >> iter 80000, loss: 0.014191
   Number of active neurons: 1
 >> iter 81000, loss: 0.014335
 >> iter 82000, loss: 0.014184
 >> iter 83000, loss: 0.014338
 >> iter 84000, loss: 0.014175
 >> iter 85000, loss: 0.014326
 >> iter 86000, loss: 0.014165
 >> iter 87000, loss: 0.014321
 >> iter 88000, loss: 0.014157
 >> iter 89000, loss: 0.014311
 >> iter 90000, loss: 0.014159
   Number of active neurons: 1
 >> iter 91000, loss: 0.014306
 >> iter 92000, loss: 0.014159
 >> iter 93000, loss: 0.014307
 >> iter 94000, loss: 0.014150
 >> iter 95000, loss: 0.014318
 >> iter 96000, loss: 0.014144
 >> iter 97000, loss: 0.014318
 >> iter 98000, loss: 0.014137
 >> iter 99000, loss: 0.014318
 >> iter 100000, loss: 0.014150
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.739531
 >> iter 2000, loss: 3.971684
 >> iter 3000, loss: 1.479156
 >> iter 4000, loss: 0.560783
 >> iter 5000, loss: 0.222911
 >> iter 6000, loss: 0.097928
 >> iter 7000, loss: 0.052080
 >> iter 8000, loss: 0.034655
 >> iter 9000, loss: 0.028411
 >> iter 10000, loss: 0.025547
   Number of active neurons: 3
 >> iter 11000, loss: 0.024569
 >> iter 12000, loss: 0.023444
 >> iter 13000, loss: 0.022941
 >> iter 14000, loss: 0.022029
 >> iter 15000, loss: 0.021792
 >> iter 16000, loss: 0.021273
 >> iter 17000, loss: 0.021376
 >> iter 18000, loss: 0.021079
 >> iter 19000, loss: 0.021280
 >> iter 20000, loss: 0.021064
   Number of active neurons: 3
 >> iter 21000, loss: 0.021286
 >> iter 22000, loss: 0.021076
 >> iter 23000, loss: 0.021313
 >> iter 24000, loss: 0.021095
 >> iter 25000, loss: 0.021334
 >> iter 26000, loss: 0.021117
 >> iter 27000, loss: 0.021324
 >> iter 28000, loss: 0.021088
 >> iter 29000, loss: 0.021235
 >> iter 30000, loss: 0.020944
   Number of active neurons: 2
 >> iter 31000, loss: 0.021000
 >> iter 32000, loss: 0.020503
 >> iter 33000, loss: 0.020328
 >> iter 34000, loss: 0.019791
 >> iter 35000, loss: 0.019664
 >> iter 36000, loss: 0.019224
 >> iter 37000, loss: 0.019255
 >> iter 38000, loss: 0.018954
 >> iter 39000, loss: 0.019089
 >> iter 40000, loss: 0.018850
   Number of active neurons: 2
 >> iter 41000, loss: 0.019017
 >> iter 42000, loss: 0.018811
 >> iter 43000, loss: 0.018974
 >> iter 44000, loss: 0.018786
 >> iter 45000, loss: 0.018931
 >> iter 46000, loss: 0.018726
 >> iter 47000, loss: 0.018834
 >> iter 48000, loss: 0.018596
 >> iter 49000, loss: 0.018628
 >> iter 50000, loss: 0.018217
   Number of active neurons: 1
 >> iter 51000, loss: 0.017946
 >> iter 52000, loss: 0.017343
 >> iter 53000, loss: 0.017033
 >> iter 54000, loss: 0.016486
 >> iter 55000, loss: 0.016246
 >> iter 56000, loss: 0.015863
 >> iter 57000, loss: 0.015770
 >> iter 58000, loss: 0.015473
 >> iter 59000, loss: 0.015466
 >> iter 60000, loss: 0.015229
   Number of active neurons: 1
 >> iter 61000, loss: 0.015251
 >> iter 62000, loss: 0.015050
 >> iter 63000, loss: 0.015099
 >> iter 64000, loss: 0.014903
 >> iter 65000, loss: 0.014974
 >> iter 66000, loss: 0.014794
 >> iter 67000, loss: 0.014866
 >> iter 68000, loss: 0.014713
 >> iter 69000, loss: 0.014781
 >> iter 70000, loss: 0.014625
   Number of active neurons: 1
 >> iter 71000, loss: 0.014707
 >> iter 72000, loss: 0.014564
 >> iter 73000, loss: 0.014645
 >> iter 74000, loss: 0.014500
 >> iter 75000, loss: 0.014591
 >> iter 76000, loss: 0.014450
 >> iter 77000, loss: 0.014540
 >> iter 78000, loss: 0.014398
 >> iter 79000, loss: 0.014514
 >> iter 80000, loss: 0.014363
   Number of active neurons: 1
 >> iter 81000, loss: 0.014496
 >> iter 82000, loss: 0.014333
 >> iter 83000, loss: 0.014476
 >> iter 84000, loss: 0.014303
 >> iter 85000, loss: 0.014446
 >> iter 86000, loss: 0.014276
 >> iter 87000, loss: 0.014424
 >> iter 88000, loss: 0.014253
 >> iter 89000, loss: 0.014400
 >> iter 90000, loss: 0.014241
   Number of active neurons: 1
 >> iter 91000, loss: 0.014383
 >> iter 92000, loss: 0.014230
 >> iter 93000, loss: 0.014373
 >> iter 94000, loss: 0.014212
 >> iter 95000, loss: 0.014376
 >> iter 96000, loss: 0.014197
 >> iter 97000, loss: 0.014367
 >> iter 98000, loss: 0.014183
 >> iter 99000, loss: 0.014361
 >> iter 100000, loss: 0.014190
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.743941
 >> iter 2000, loss: 3.973407
 >> iter 3000, loss: 1.480281
 >> iter 4000, loss: 0.562035
 >> iter 5000, loss: 0.224282
 >> iter 6000, loss: 0.099394
 >> iter 7000, loss: 0.053627
 >> iter 8000, loss: 0.036295
 >> iter 9000, loss: 0.030130
 >> iter 10000, loss: 0.027239
   Number of active neurons: 3
 >> iter 11000, loss: 0.026136
 >> iter 12000, loss: 0.024866
 >> iter 13000, loss: 0.024186
 >> iter 14000, loss: 0.023031
 >> iter 15000, loss: 0.022502
 >> iter 16000, loss: 0.021701
 >> iter 17000, loss: 0.021541
 >> iter 18000, loss: 0.021034
 >> iter 19000, loss: 0.020989
 >> iter 20000, loss: 0.020513
   Number of active neurons: 2
 >> iter 21000, loss: 0.020312
 >> iter 22000, loss: 0.019696
 >> iter 23000, loss: 0.019510
 >> iter 24000, loss: 0.018998
 >> iter 25000, loss: 0.018982
 >> iter 26000, loss: 0.018650
 >> iter 27000, loss: 0.018748
 >> iter 28000, loss: 0.018503
 >> iter 29000, loss: 0.018643
 >> iter 30000, loss: 0.018433
   Number of active neurons: 2
 >> iter 31000, loss: 0.018601
 >> iter 32000, loss: 0.018408
 >> iter 33000, loss: 0.018588
 >> iter 34000, loss: 0.018409
 >> iter 35000, loss: 0.018609
 >> iter 36000, loss: 0.018424
 >> iter 37000, loss: 0.018631
 >> iter 38000, loss: 0.018448
 >> iter 39000, loss: 0.018667
 >> iter 40000, loss: 0.018485
   Number of active neurons: 2
 >> iter 41000, loss: 0.018700
 >> iter 42000, loss: 0.018528
 >> iter 43000, loss: 0.018728
 >> iter 44000, loss: 0.018569
 >> iter 45000, loss: 0.018755
 >> iter 46000, loss: 0.018586
 >> iter 47000, loss: 0.018750
 >> iter 48000, loss: 0.018572
 >> iter 49000, loss: 0.018700
 >> iter 50000, loss: 0.018468
   Number of active neurons: 1
 >> iter 51000, loss: 0.018525
 >> iter 52000, loss: 0.018142
 >> iter 53000, loss: 0.017879
 >> iter 54000, loss: 0.017315
 >> iter 55000, loss: 0.016999
 >> iter 56000, loss: 0.016461
 >> iter 57000, loss: 0.016230
 >> iter 58000, loss: 0.015826
 >> iter 59000, loss: 0.015743
 >> iter 60000, loss: 0.015450
   Number of active neurons: 1
 >> iter 61000, loss: 0.015433
 >> iter 62000, loss: 0.015203
 >> iter 63000, loss: 0.015229
 >> iter 64000, loss: 0.015017
 >> iter 65000, loss: 0.015074
 >> iter 66000, loss: 0.014884
 >> iter 67000, loss: 0.014947
 >> iter 68000, loss: 0.014786
 >> iter 69000, loss: 0.014848
 >> iter 70000, loss: 0.014686
   Number of active neurons: 1
 >> iter 71000, loss: 0.014764
 >> iter 72000, loss: 0.014616
 >> iter 73000, loss: 0.014693
 >> iter 74000, loss: 0.014545
 >> iter 75000, loss: 0.014633
 >> iter 76000, loss: 0.014489
 >> iter 77000, loss: 0.014576
 >> iter 78000, loss: 0.014431
 >> iter 79000, loss: 0.014545
 >> iter 80000, loss: 0.014392
   Number of active neurons: 1
 >> iter 81000, loss: 0.014522
 >> iter 82000, loss: 0.014357
 >> iter 83000, loss: 0.014499
 >> iter 84000, loss: 0.014325
 >> iter 85000, loss: 0.014466
 >> iter 86000, loss: 0.014294
 >> iter 87000, loss: 0.014441
 >> iter 88000, loss: 0.014269
 >> iter 89000, loss: 0.014415
 >> iter 90000, loss: 0.014255
   Number of active neurons: 1
 >> iter 91000, loss: 0.014396
 >> iter 92000, loss: 0.014242
 >> iter 93000, loss: 0.014384
 >> iter 94000, loss: 0.014222
 >> iter 95000, loss: 0.014385
 >> iter 96000, loss: 0.014205
 >> iter 97000, loss: 0.014375
 >> iter 98000, loss: 0.014190
 >> iter 99000, loss: 0.014368
 >> iter 100000, loss: 0.014196
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.772301
 >> iter 2000, loss: 3.984667
 >> iter 3000, loss: 1.484658
 >> iter 4000, loss: 0.563223
 >> iter 5000, loss: 0.223821
 >> iter 6000, loss: 0.097892
 >> iter 7000, loss: 0.051278
 >> iter 8000, loss: 0.033102
 >> iter 9000, loss: 0.026316
 >> iter 10000, loss: 0.023131
   Number of active neurons: 3
 >> iter 11000, loss: 0.022067
 >> iter 12000, loss: 0.021097
 >> iter 13000, loss: 0.021004
 >> iter 14000, loss: 0.020518
 >> iter 15000, loss: 0.020692
 >> iter 16000, loss: 0.020356
 >> iter 17000, loss: 0.020598
 >> iter 18000, loss: 0.020312
 >> iter 19000, loss: 0.020560
 >> iter 20000, loss: 0.020309
   Number of active neurons: 3
 >> iter 21000, loss: 0.020547
 >> iter 22000, loss: 0.020259
 >> iter 23000, loss: 0.020451
 >> iter 24000, loss: 0.020139
 >> iter 25000, loss: 0.020341
 >> iter 26000, loss: 0.020036
 >> iter 27000, loss: 0.020192
 >> iter 28000, loss: 0.019850
 >> iter 29000, loss: 0.019915
 >> iter 30000, loss: 0.019416
   Number of active neurons: 2
 >> iter 31000, loss: 0.019276
 >> iter 32000, loss: 0.018727
 >> iter 33000, loss: 0.018622
 >> iter 34000, loss: 0.018176
 >> iter 35000, loss: 0.018229
 >> iter 36000, loss: 0.017916
 >> iter 37000, loss: 0.018028
 >> iter 38000, loss: 0.017751
 >> iter 39000, loss: 0.017933
 >> iter 40000, loss: 0.017695
   Number of active neurons: 2
 >> iter 41000, loss: 0.017886
 >> iter 42000, loss: 0.017656
 >> iter 43000, loss: 0.017850
 >> iter 44000, loss: 0.017661
 >> iter 45000, loss: 0.017861
 >> iter 46000, loss: 0.017669
 >> iter 47000, loss: 0.017866
 >> iter 48000, loss: 0.017686
 >> iter 49000, loss: 0.017887
 >> iter 50000, loss: 0.017699
   Number of active neurons: 2
 >> iter 51000, loss: 0.017904
 >> iter 52000, loss: 0.017728
 >> iter 53000, loss: 0.017920
 >> iter 54000, loss: 0.017775
 >> iter 55000, loss: 0.017940
 >> iter 56000, loss: 0.017806
 >> iter 57000, loss: 0.017986
 >> iter 58000, loss: 0.017831
 >> iter 59000, loss: 0.018026
 >> iter 60000, loss: 0.017879
   Number of active neurons: 2
 >> iter 61000, loss: 0.018062
 >> iter 62000, loss: 0.017927
 >> iter 63000, loss: 0.018114
 >> iter 64000, loss: 0.017966
 >> iter 65000, loss: 0.018167
 >> iter 66000, loss: 0.018027
 >> iter 67000, loss: 0.018217
 >> iter 68000, loss: 0.018105
 >> iter 69000, loss: 0.018282
 >> iter 70000, loss: 0.018160
   Number of active neurons: 2
 >> iter 71000, loss: 0.018348
 >> iter 72000, loss: 0.018239
 >> iter 73000, loss: 0.018419
 >> iter 74000, loss: 0.018305
 >> iter 75000, loss: 0.018490
 >> iter 76000, loss: 0.018376
 >> iter 77000, loss: 0.018551
 >> iter 78000, loss: 0.018429
 >> iter 79000, loss: 0.018626
 >> iter 80000, loss: 0.018484
   Number of active neurons: 2
 >> iter 81000, loss: 0.018682
 >> iter 82000, loss: 0.018510
 >> iter 83000, loss: 0.018690
 >> iter 84000, loss: 0.018475
 >> iter 85000, loss: 0.018599
 >> iter 86000, loss: 0.018323
 >> iter 87000, loss: 0.018277
 >> iter 88000, loss: 0.017711
 >> iter 89000, loss: 0.017449
 >> iter 90000, loss: 0.016866
   Number of active neurons: 1
 >> iter 91000, loss: 0.016599
 >> iter 92000, loss: 0.016097
 >> iter 93000, loss: 0.015970
 >> iter 94000, loss: 0.015601
 >> iter 95000, loss: 0.015601
 >> iter 96000, loss: 0.015292
 >> iter 97000, loss: 0.015355
 >> iter 98000, loss: 0.015081
 >> iter 99000, loss: 0.015181
 >> iter 100000, loss: 0.014944
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.739879
 >> iter 2000, loss: 3.970972
 >> iter 3000, loss: 1.478119
 >> iter 4000, loss: 0.559900
 >> iter 5000, loss: 0.222189
 >> iter 6000, loss: 0.097495
 >> iter 7000, loss: 0.051934
 >> iter 8000, loss: 0.034853
 >> iter 9000, loss: 0.028897
 >> iter 10000, loss: 0.026343
   Number of active neurons: 4
 >> iter 11000, loss: 0.025716
 >> iter 12000, loss: 0.025037
 >> iter 13000, loss: 0.024966
 >> iter 14000, loss: 0.024277
 >> iter 15000, loss: 0.023978
 >> iter 16000, loss: 0.023038
 >> iter 17000, loss: 0.022516
 >> iter 18000, loss: 0.021566
 >> iter 19000, loss: 0.021033
 >> iter 20000, loss: 0.020196
   Number of active neurons: 2
 >> iter 21000, loss: 0.019854
 >> iter 22000, loss: 0.019271
 >> iter 23000, loss: 0.019198
 >> iter 24000, loss: 0.018832
 >> iter 25000, loss: 0.018920
 >> iter 26000, loss: 0.018663
 >> iter 27000, loss: 0.018806
 >> iter 28000, loss: 0.018595
 >> iter 29000, loss: 0.018753
 >> iter 30000, loss: 0.018561
   Number of active neurons: 2
 >> iter 31000, loss: 0.018737
 >> iter 32000, loss: 0.018555
 >> iter 33000, loss: 0.018738
 >> iter 34000, loss: 0.018567
 >> iter 35000, loss: 0.018766
 >> iter 36000, loss: 0.018586
 >> iter 37000, loss: 0.018788
 >> iter 38000, loss: 0.018606
 >> iter 39000, loss: 0.018814
 >> iter 40000, loss: 0.018626
   Number of active neurons: 2
 >> iter 41000, loss: 0.018819
 >> iter 42000, loss: 0.018631
 >> iter 43000, loss: 0.018789
 >> iter 44000, loss: 0.018592
 >> iter 45000, loss: 0.018701
 >> iter 46000, loss: 0.018447
 >> iter 47000, loss: 0.018440
 >> iter 48000, loss: 0.017951
 >> iter 49000, loss: 0.017663
 >> iter 50000, loss: 0.017070
   Number of active neurons: 1
 >> iter 51000, loss: 0.016783
 >> iter 52000, loss: 0.016253
 >> iter 53000, loss: 0.016076
 >> iter 54000, loss: 0.015722
 >> iter 55000, loss: 0.015642
 >> iter 56000, loss: 0.015383
 >> iter 57000, loss: 0.015379
 >> iter 58000, loss: 0.015149
 >> iter 59000, loss: 0.015191
 >> iter 60000, loss: 0.014991
   Number of active neurons: 1
 >> iter 61000, loss: 0.015042
 >> iter 62000, loss: 0.014864
 >> iter 63000, loss: 0.014930
 >> iter 64000, loss: 0.014750
 >> iter 65000, loss: 0.014834
 >> iter 66000, loss: 0.014666
 >> iter 67000, loss: 0.014747
 >> iter 68000, loss: 0.014603
 >> iter 69000, loss: 0.014679
 >> iter 70000, loss: 0.014531
   Number of active neurons: 1
 >> iter 71000, loss: 0.014620
 >> iter 72000, loss: 0.014483
 >> iter 73000, loss: 0.014570
 >> iter 74000, loss: 0.014431
 >> iter 75000, loss: 0.014526
 >> iter 76000, loss: 0.014390
 >> iter 77000, loss: 0.014484
 >> iter 78000, loss: 0.014347
 >> iter 79000, loss: 0.014466
 >> iter 80000, loss: 0.014319
   Number of active neurons: 1
 >> iter 81000, loss: 0.014454
 >> iter 82000, loss: 0.014294
 >> iter 83000, loss: 0.014441
 >> iter 84000, loss: 0.014270
 >> iter 85000, loss: 0.014415
 >> iter 86000, loss: 0.014247
 >> iter 87000, loss: 0.014398
 >> iter 88000, loss: 0.014229
 >> iter 89000, loss: 0.014377
 >> iter 90000, loss: 0.014220
   Number of active neurons: 1
 >> iter 91000, loss: 0.014363
 >> iter 92000, loss: 0.014212
 >> iter 93000, loss: 0.014356
 >> iter 94000, loss: 0.014196
 >> iter 95000, loss: 0.014361
 >> iter 96000, loss: 0.014183
 >> iter 97000, loss: 0.014354
 >> iter 98000, loss: 0.014171
 >> iter 99000, loss: 0.014350
 >> iter 100000, loss: 0.014179
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

