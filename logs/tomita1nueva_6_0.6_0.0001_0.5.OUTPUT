 > Problema: tomita1nueva
 > Args:
   - Hidden size: 6
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.978302
 >> iter 2000, loss: 4.082473
 >> iter 3000, loss: 1.528297
 >> iter 4000, loss: 0.579089
 >> iter 5000, loss: 0.231801
 >> iter 6000, loss: 0.109673
 >> iter 7000, loss: 0.055765
 >> iter 8000, loss: 0.033375
 >> iter 9000, loss: 0.038219
 >> iter 10000, loss: 0.027611
   Number of active neurons: 2
 >> iter 11000, loss: 0.040109
 >> iter 12000, loss: 0.038563
 >> iter 13000, loss: 0.029861
 >> iter 14000, loss: 0.035659
 >> iter 15000, loss: 0.029205
 >> iter 16000, loss: 0.024651
 >> iter 17000, loss: 0.021851
 >> iter 18000, loss: 0.024379
 >> iter 19000, loss: 0.021061
 >> iter 20000, loss: 0.021116
   Number of active neurons: 2
 >> iter 21000, loss: 0.021049
 >> iter 22000, loss: 0.021851
 >> iter 23000, loss: 0.032739
 >> iter 24000, loss: 0.029841
 >> iter 25000, loss: 0.034509
 >> iter 26000, loss: 0.027835
 >> iter 27000, loss: 0.026347
 >> iter 28000, loss: 0.022808
 >> iter 29000, loss: 0.024647
 >> iter 30000, loss: 0.022908
   Number of active neurons: 2
 >> iter 31000, loss: 0.022035
 >> iter 32000, loss: 0.033190
 >> iter 33000, loss: 0.025644
 >> iter 34000, loss: 0.023851
 >> iter 35000, loss: 0.022249
 >> iter 36000, loss: 0.020490
 >> iter 37000, loss: 0.024803
 >> iter 38000, loss: 0.022262
 >> iter 39000, loss: 0.030932
 >> iter 40000, loss: 0.025909
   Number of active neurons: 2
 >> iter 41000, loss: 0.022227
 >> iter 42000, loss: 0.027163
 >> iter 43000, loss: 0.023721
 >> iter 44000, loss: 0.032755
 >> iter 45000, loss: 0.024712
 >> iter 46000, loss: 0.023665
 >> iter 47000, loss: 0.021341
 >> iter 48000, loss: 0.021222
 >> iter 49000, loss: 0.022876
 >> iter 50000, loss: 0.044746
   Number of active neurons: 2
 >> iter 51000, loss: 0.030136
 >> iter 52000, loss: 0.026077
 >> iter 53000, loss: 0.024912
 >> iter 54000, loss: 0.024921
 >> iter 55000, loss: 0.022265
 >> iter 56000, loss: 0.030569
 >> iter 57000, loss: 0.026389
 >> iter 58000, loss: 0.026022
 >> iter 59000, loss: 0.026220
 >> iter 60000, loss: 0.029394
   Number of active neurons: 2
 >> iter 61000, loss: 0.034454
 >> iter 62000, loss: 0.026387
 >> iter 63000, loss: 0.025353
 >> iter 64000, loss: 0.026986
 >> iter 65000, loss: 0.022876
 >> iter 66000, loss: 0.042065
 >> iter 67000, loss: 0.026764
 >> iter 68000, loss: 0.023489
 >> iter 69000, loss: 0.019090
 >> iter 70000, loss: 0.032065
   Number of active neurons: 1
 >> iter 71000, loss: 0.033749
 >> iter 72000, loss: 0.026949
 >> iter 73000, loss: 0.020631
 >> iter 74000, loss: 0.036260
 >> iter 75000, loss: 0.024152
 >> iter 76000, loss: 0.037821
 >> iter 77000, loss: 0.028412
 >> iter 78000, loss: 0.024490
 >> iter 79000, loss: 0.024115
 >> iter 80000, loss: 0.022725
   Number of active neurons: 1
 >> iter 81000, loss: 0.030739
 >> iter 82000, loss: 0.022066
 >> iter 83000, loss: 0.034731
 >> iter 84000, loss: 0.027268
 >> iter 85000, loss: 0.021208
 >> iter 86000, loss: 0.024423
 >> iter 87000, loss: 0.019023
 >> iter 88000, loss: 0.019563
 >> iter 89000, loss: 0.020698
 >> iter 90000, loss: 0.023916
   Number of active neurons: 1
 >> iter 91000, loss: 0.028695
 >> iter 92000, loss: 0.028703
 >> iter 93000, loss: 0.025005
 >> iter 94000, loss: 0.026452
 >> iter 95000, loss: 0.028633
 >> iter 96000, loss: 0.022043
 >> iter 97000, loss: 0.020806
 >> iter 98000, loss: 0.018133
 >> iter 99000, loss: 0.016880
 >> iter 100000, loss: 0.021322
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.041247
 >> iter 2000, loss: 4.099303
 >> iter 3000, loss: 1.532845
 >> iter 4000, loss: 0.587456
 >> iter 5000, loss: 0.237164
 >> iter 6000, loss: 0.105311
 >> iter 7000, loss: 0.060222
 >> iter 8000, loss: 0.056508
 >> iter 9000, loss: 0.075451
 >> iter 10000, loss: 0.058379
   Number of active neurons: 3
 >> iter 11000, loss: 0.043334
 >> iter 12000, loss: 0.032273
 >> iter 13000, loss: 0.026754
 >> iter 14000, loss: 0.027611
 >> iter 15000, loss: 0.031424
 >> iter 16000, loss: 0.025343
 >> iter 17000, loss: 0.028217
 >> iter 18000, loss: 0.030544
 >> iter 19000, loss: 0.024607
 >> iter 20000, loss: 0.051457
   Number of active neurons: 2
 >> iter 21000, loss: 0.032703
 >> iter 22000, loss: 0.031136
 >> iter 23000, loss: 0.026907
 >> iter 24000, loss: 0.031861
 >> iter 25000, loss: 0.034019
 >> iter 26000, loss: 0.026534
 >> iter 27000, loss: 0.024521
 >> iter 28000, loss: 0.025841
 >> iter 29000, loss: 0.023900
 >> iter 30000, loss: 0.022556
   Number of active neurons: 1
 >> iter 31000, loss: 0.020136
 >> iter 32000, loss: 0.019744
 >> iter 33000, loss: 0.020336
 >> iter 34000, loss: 0.025866
 >> iter 35000, loss: 0.035505
 >> iter 36000, loss: 0.029579
 >> iter 37000, loss: 0.022621
 >> iter 38000, loss: 0.025427
 >> iter 39000, loss: 0.034477
 >> iter 40000, loss: 0.041880
   Number of active neurons: 1
 >> iter 41000, loss: 0.072597
 >> iter 42000, loss: 0.036994
 >> iter 43000, loss: 0.028416
 >> iter 44000, loss: 0.023069
 >> iter 45000, loss: 0.019862
 >> iter 46000, loss: 0.025862
 >> iter 47000, loss: 0.021512
 >> iter 48000, loss: 0.022341
 >> iter 49000, loss: 0.019499
 >> iter 50000, loss: 0.016657
   Number of active neurons: 1
 >> iter 51000, loss: 0.015741
 >> iter 52000, loss: 0.026774
 >> iter 53000, loss: 0.021992
 >> iter 54000, loss: 0.022014
 >> iter 55000, loss: 0.024023
 >> iter 56000, loss: 0.019241
 >> iter 57000, loss: 0.018105
 >> iter 58000, loss: 0.018073
 >> iter 59000, loss: 0.018920
 >> iter 60000, loss: 0.020861
   Number of active neurons: 1
 >> iter 61000, loss: 0.019469
 >> iter 62000, loss: 0.027619
 >> iter 63000, loss: 0.022717
 >> iter 64000, loss: 0.018621
 >> iter 65000, loss: 0.017495
 >> iter 66000, loss: 0.019442
 >> iter 67000, loss: 0.017552
 >> iter 68000, loss: 0.016701
 >> iter 69000, loss: 0.033665
 >> iter 70000, loss: 0.023698
   Number of active neurons: 1
 >> iter 71000, loss: 0.030542
 >> iter 72000, loss: 0.021640
 >> iter 73000, loss: 0.018783
 >> iter 74000, loss: 0.018191
 >> iter 75000, loss: 0.017829
 >> iter 76000, loss: 0.018420
 >> iter 77000, loss: 0.025556
 >> iter 78000, loss: 0.025809
 >> iter 79000, loss: 0.021028
 >> iter 80000, loss: 0.019505
   Number of active neurons: 1
 >> iter 81000, loss: 0.031405
 >> iter 82000, loss: 0.030174
 >> iter 83000, loss: 0.023208
 >> iter 84000, loss: 0.020057
 >> iter 85000, loss: 0.020335
 >> iter 86000, loss: 0.031820
 >> iter 87000, loss: 0.026684
 >> iter 88000, loss: 0.020641
 >> iter 89000, loss: 0.021757
 >> iter 90000, loss: 0.024347
   Number of active neurons: 1
 >> iter 91000, loss: 0.020174
 >> iter 92000, loss: 0.020535
 >> iter 93000, loss: 0.018783
 >> iter 94000, loss: 0.026103
 >> iter 95000, loss: 0.023111
 >> iter 96000, loss: 0.019427
 >> iter 97000, loss: 0.021224
 >> iter 98000, loss: 0.032552
 >> iter 99000, loss: 0.045541
 >> iter 100000, loss: 0.028438
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.860414
 >> iter 2000, loss: 4.034465
 >> iter 3000, loss: 1.513321
 >> iter 4000, loss: 0.575925
 >> iter 5000, loss: 0.234909
 >> iter 6000, loss: 0.118521
 >> iter 7000, loss: 0.062680
 >> iter 8000, loss: 0.043607
 >> iter 9000, loss: 0.035692
 >> iter 10000, loss: 0.029574
   Number of active neurons: 3
 >> iter 11000, loss: 0.028595
 >> iter 12000, loss: 0.024805
 >> iter 13000, loss: 0.023503
 >> iter 14000, loss: 0.024360
 >> iter 15000, loss: 0.038535
 >> iter 16000, loss: 0.027498
 >> iter 17000, loss: 0.031947
 >> iter 18000, loss: 0.026957
 >> iter 19000, loss: 0.025512
 >> iter 20000, loss: 0.023240
   Number of active neurons: 3
 >> iter 21000, loss: 0.034742
 >> iter 22000, loss: 0.027946
 >> iter 23000, loss: 0.032929
 >> iter 24000, loss: 0.027780
 >> iter 25000, loss: 0.023667
 >> iter 26000, loss: 0.024664
 >> iter 27000, loss: 0.023974
 >> iter 28000, loss: 0.026503
 >> iter 29000, loss: 0.026372
 >> iter 30000, loss: 0.023797
   Number of active neurons: 3
 >> iter 31000, loss: 0.026294
 >> iter 32000, loss: 0.033822
 >> iter 33000, loss: 0.027082
 >> iter 34000, loss: 0.025151
 >> iter 35000, loss: 0.032428
 >> iter 36000, loss: 0.026781
 >> iter 37000, loss: 0.026420
 >> iter 38000, loss: 0.023733
 >> iter 39000, loss: 0.032341
 >> iter 40000, loss: 0.025609
   Number of active neurons: 3
 >> iter 41000, loss: 0.025497
 >> iter 42000, loss: 0.023362
 >> iter 43000, loss: 0.059476
 >> iter 44000, loss: 0.048040
 >> iter 45000, loss: 0.034985
 >> iter 46000, loss: 0.039025
 >> iter 47000, loss: 0.048186
 >> iter 48000, loss: 0.036511
 >> iter 49000, loss: 0.033297
 >> iter 50000, loss: 0.028623
   Number of active neurons: 2
 >> iter 51000, loss: 0.027013
 >> iter 52000, loss: 0.022278
 >> iter 53000, loss: 0.022452
 >> iter 54000, loss: 0.021676
 >> iter 55000, loss: 0.025608
 >> iter 56000, loss: 0.024028
 >> iter 57000, loss: 0.020647
 >> iter 58000, loss: 0.019630
 >> iter 59000, loss: 0.019250
 >> iter 60000, loss: 0.019095
   Number of active neurons: 1
 >> iter 61000, loss: 0.020620
 >> iter 62000, loss: 0.018172
 >> iter 63000, loss: 0.032386
 >> iter 64000, loss: 0.039435
 >> iter 65000, loss: 0.039203
 >> iter 66000, loss: 0.035645
 >> iter 67000, loss: 0.038029
 >> iter 68000, loss: 0.026254
 >> iter 69000, loss: 0.021433
 >> iter 70000, loss: 0.017478
   Number of active neurons: 1
 >> iter 71000, loss: 0.022549
 >> iter 72000, loss: 0.035340
 >> iter 73000, loss: 0.055864
 >> iter 74000, loss: 0.031326
 >> iter 75000, loss: 0.022112
 >> iter 76000, loss: 0.020225
 >> iter 77000, loss: 0.025642
 >> iter 78000, loss: 0.021071
 >> iter 79000, loss: 0.018801
 >> iter 80000, loss: 0.017352
   Number of active neurons: 1
 >> iter 81000, loss: 0.021208
 >> iter 82000, loss: 0.019772
 >> iter 83000, loss: 0.019640
 >> iter 84000, loss: 0.020441
 >> iter 85000, loss: 0.050104
 >> iter 86000, loss: 0.044498
 >> iter 87000, loss: 0.027673
 >> iter 88000, loss: 0.021259
 >> iter 89000, loss: 0.018986
 >> iter 90000, loss: 0.021595
   Number of active neurons: 1
 >> iter 91000, loss: 0.020549
 >> iter 92000, loss: 0.017990
 >> iter 93000, loss: 0.018111
 >> iter 94000, loss: 0.018367
 >> iter 95000, loss: 0.017103
 >> iter 96000, loss: 0.016559
 >> iter 97000, loss: 0.020336
 >> iter 98000, loss: 0.021608
 >> iter 99000, loss: 0.024210
 >> iter 100000, loss: 0.018908
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.936756
 >> iter 2000, loss: 4.058436
 >> iter 3000, loss: 1.513484
 >> iter 4000, loss: 0.578177
 >> iter 5000, loss: 0.233429
 >> iter 6000, loss: 0.111235
 >> iter 7000, loss: 0.059894
 >> iter 8000, loss: 0.053245
 >> iter 9000, loss: 0.042911
 >> iter 10000, loss: 0.032540
   Number of active neurons: 3
 >> iter 11000, loss: 0.028860
 >> iter 12000, loss: 0.039476
 >> iter 13000, loss: 0.030151
 >> iter 14000, loss: 0.027590
 >> iter 15000, loss: 0.030114
 >> iter 16000, loss: 0.025181
 >> iter 17000, loss: 0.025834
 >> iter 18000, loss: 0.023289
 >> iter 19000, loss: 0.048146
 >> iter 20000, loss: 0.031371
   Number of active neurons: 2
 >> iter 21000, loss: 0.028274
 >> iter 22000, loss: 0.026775
 >> iter 23000, loss: 0.024022
 >> iter 24000, loss: 0.024403
 >> iter 25000, loss: 0.021111
 >> iter 26000, loss: 0.020910
 >> iter 27000, loss: 0.021222
 >> iter 28000, loss: 0.022605
 >> iter 29000, loss: 0.023452
 >> iter 30000, loss: 0.021060
   Number of active neurons: 2
 >> iter 31000, loss: 0.025001
 >> iter 32000, loss: 0.024804
 >> iter 33000, loss: 0.028965
 >> iter 34000, loss: 0.025410
 >> iter 35000, loss: 0.029176
 >> iter 36000, loss: 0.025883
 >> iter 37000, loss: 0.024255
 >> iter 38000, loss: 0.024387
 >> iter 39000, loss: 0.022228
 >> iter 40000, loss: 0.025363
   Number of active neurons: 2
 >> iter 41000, loss: 0.033465
 >> iter 42000, loss: 0.026428
 >> iter 43000, loss: 0.024603
 >> iter 44000, loss: 0.021334
 >> iter 45000, loss: 0.021551
 >> iter 46000, loss: 0.025495
 >> iter 47000, loss: 0.023524
 >> iter 48000, loss: 0.023005
 >> iter 49000, loss: 0.023116
 >> iter 50000, loss: 0.025440
   Number of active neurons: 2
 >> iter 51000, loss: 0.021998
 >> iter 52000, loss: 0.020881
 >> iter 53000, loss: 0.022505
 >> iter 54000, loss: 0.024929
 >> iter 55000, loss: 0.025460
 >> iter 56000, loss: 0.025119
 >> iter 57000, loss: 0.021462
 >> iter 58000, loss: 0.023875
 >> iter 59000, loss: 0.021002
 >> iter 60000, loss: 0.020298
   Number of active neurons: 2
 >> iter 61000, loss: 0.023274
 >> iter 62000, loss: 0.021985
 >> iter 63000, loss: 0.022337
 >> iter 64000, loss: 0.020347
 >> iter 65000, loss: 0.022668
 >> iter 66000, loss: 0.025026
 >> iter 67000, loss: 0.023188
 >> iter 68000, loss: 0.021619
 >> iter 69000, loss: 0.021415
 >> iter 70000, loss: 0.022326
   Number of active neurons: 2
 >> iter 71000, loss: 0.022441
 >> iter 72000, loss: 0.024381
 >> iter 73000, loss: 0.023429
 >> iter 74000, loss: 0.022962
 >> iter 75000, loss: 0.020945
 >> iter 76000, loss: 0.020807
 >> iter 77000, loss: 0.020532
 >> iter 78000, loss: 0.019038
 >> iter 79000, loss: 0.019302
 >> iter 80000, loss: 0.023813
   Number of active neurons: 2
 >> iter 81000, loss: 0.023843
 >> iter 82000, loss: 0.022401
 >> iter 83000, loss: 0.023084
 >> iter 84000, loss: 0.020828
 >> iter 85000, loss: 0.022839
 >> iter 86000, loss: 0.022098
 >> iter 87000, loss: 0.020018
 >> iter 88000, loss: 0.025029
 >> iter 89000, loss: 0.023256
 >> iter 90000, loss: 0.023332
   Number of active neurons: 2
 >> iter 91000, loss: 0.022750
 >> iter 92000, loss: 0.021555
 >> iter 93000, loss: 0.030342
 >> iter 94000, loss: 0.022574
 >> iter 95000, loss: 0.020681
 >> iter 96000, loss: 0.020518
 >> iter 97000, loss: 0.024120
 >> iter 98000, loss: 0.030388
 >> iter 99000, loss: 0.027007
 >> iter 100000, loss: 0.021692
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.878016
 >> iter 2000, loss: 4.036290
 >> iter 3000, loss: 1.531324
 >> iter 4000, loss: 0.582587
 >> iter 5000, loss: 0.238528
 >> iter 6000, loss: 0.109691
 >> iter 7000, loss: 0.068068
 >> iter 8000, loss: 0.047811
 >> iter 9000, loss: 0.037523
 >> iter 10000, loss: 0.037860
   Number of active neurons: 4
 >> iter 11000, loss: 0.030025
 >> iter 12000, loss: 0.028234
 >> iter 13000, loss: 0.030904
 >> iter 14000, loss: 0.032821
 >> iter 15000, loss: 0.032631
 >> iter 16000, loss: 0.030410
 >> iter 17000, loss: 0.026604
 >> iter 18000, loss: 0.025619
 >> iter 19000, loss: 0.025102
 >> iter 20000, loss: 0.024272
   Number of active neurons: 3
 >> iter 21000, loss: 0.026049
 >> iter 22000, loss: 0.028417
 >> iter 23000, loss: 0.032308
 >> iter 24000, loss: 0.032803
 >> iter 25000, loss: 0.026696
 >> iter 26000, loss: 0.023134
 >> iter 27000, loss: 0.027168
 >> iter 28000, loss: 0.023353
 >> iter 29000, loss: 0.024172
 >> iter 30000, loss: 0.022383
   Number of active neurons: 3
 >> iter 31000, loss: 0.023496
 >> iter 32000, loss: 0.024283
 >> iter 33000, loss: 0.035698
 >> iter 34000, loss: 0.039350
 >> iter 35000, loss: 0.043962
 >> iter 36000, loss: 0.038635
 >> iter 37000, loss: 0.030407
 >> iter 38000, loss: 0.027171
 >> iter 39000, loss: 0.024408
 >> iter 40000, loss: 0.032675
   Number of active neurons: 3
 >> iter 41000, loss: 0.026550
 >> iter 42000, loss: 0.029678
 >> iter 43000, loss: 0.027394
 >> iter 44000, loss: 0.024673
 >> iter 45000, loss: 0.030468
 >> iter 46000, loss: 0.027651
 >> iter 47000, loss: 0.023232
 >> iter 48000, loss: 0.032883
 >> iter 49000, loss: 0.029420
 >> iter 50000, loss: 0.023349
   Number of active neurons: 2
 >> iter 51000, loss: 0.020724
 >> iter 52000, loss: 0.027185
 >> iter 53000, loss: 0.021907
 >> iter 54000, loss: 0.023033
 >> iter 55000, loss: 0.030351
 >> iter 56000, loss: 0.025744
 >> iter 57000, loss: 0.024016
 >> iter 58000, loss: 0.031392
 >> iter 59000, loss: 0.025140
 >> iter 60000, loss: 0.058811
   Number of active neurons: 2
 >> iter 61000, loss: 0.037794
 >> iter 62000, loss: 0.027361
 >> iter 63000, loss: 0.036404
 >> iter 64000, loss: 0.047142
 >> iter 65000, loss: 0.051978
 >> iter 66000, loss: 0.032022
 >> iter 67000, loss: 0.026842
 >> iter 68000, loss: 0.022916
 >> iter 69000, loss: 0.023600
 >> iter 70000, loss: 0.024735
   Number of active neurons: 2
 >> iter 71000, loss: 0.024846
 >> iter 72000, loss: 0.025075
 >> iter 73000, loss: 0.024115
 >> iter 74000, loss: 0.021526
 >> iter 75000, loss: 0.021075
 >> iter 76000, loss: 0.023247
 >> iter 77000, loss: 0.024744
 >> iter 78000, loss: 0.021442
 >> iter 79000, loss: 0.025250
 >> iter 80000, loss: 0.028082
   Number of active neurons: 2
 >> iter 81000, loss: 0.028235
 >> iter 82000, loss: 0.026337
 >> iter 83000, loss: 0.021917
 >> iter 84000, loss: 0.019620
 >> iter 85000, loss: 0.024427
 >> iter 86000, loss: 0.022732
 >> iter 87000, loss: 0.029365
 >> iter 88000, loss: 0.028237
 >> iter 89000, loss: 0.032352
 >> iter 90000, loss: 0.025413
   Number of active neurons: 1
 >> iter 91000, loss: 0.021206
 >> iter 92000, loss: 0.021249
 >> iter 93000, loss: 0.020074
 >> iter 94000, loss: 0.023605
 >> iter 95000, loss: 0.021669
 >> iter 96000, loss: 0.033680
 >> iter 97000, loss: 0.028761
 >> iter 98000, loss: 0.023255
 >> iter 99000, loss: 0.027005
 >> iter 100000, loss: 0.022215
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.937748
 >> iter 2000, loss: 4.073177
 >> iter 3000, loss: 1.532377
 >> iter 4000, loss: 0.591000
 >> iter 5000, loss: 0.239468
 >> iter 6000, loss: 0.103549
 >> iter 7000, loss: 0.062900
 >> iter 8000, loss: 0.055254
 >> iter 9000, loss: 0.043104
 >> iter 10000, loss: 0.031738
   Number of active neurons: 4
 >> iter 11000, loss: 0.038658
 >> iter 12000, loss: 0.035573
 >> iter 13000, loss: 0.069248
 >> iter 14000, loss: 0.043140
 >> iter 15000, loss: 0.033696
 >> iter 16000, loss: 0.042428
 >> iter 17000, loss: 0.031795
 >> iter 18000, loss: 0.032360
 >> iter 19000, loss: 0.033509
 >> iter 20000, loss: 0.046733
   Number of active neurons: 3
 >> iter 21000, loss: 0.101519
 >> iter 22000, loss: 0.065455
 >> iter 23000, loss: 0.039212
 >> iter 24000, loss: 0.033993
 >> iter 25000, loss: 0.027787
 >> iter 26000, loss: 0.024314
 >> iter 27000, loss: 0.024931
 >> iter 28000, loss: 0.023341
 >> iter 29000, loss: 0.023963
 >> iter 30000, loss: 0.022792
   Number of active neurons: 2
 >> iter 31000, loss: 0.023085
 >> iter 32000, loss: 0.022939
 >> iter 33000, loss: 0.038131
 >> iter 34000, loss: 0.029194
 >> iter 35000, loss: 0.023817
 >> iter 36000, loss: 0.026716
 >> iter 37000, loss: 0.028618
 >> iter 38000, loss: 0.026785
 >> iter 39000, loss: 0.024090
 >> iter 40000, loss: 0.023959
   Number of active neurons: 1
 >> iter 41000, loss: 0.023665
 >> iter 42000, loss: 0.020381
 >> iter 43000, loss: 0.018838
 >> iter 44000, loss: 0.023826
 >> iter 45000, loss: 0.023654
 >> iter 46000, loss: 0.057251
 >> iter 47000, loss: 0.032444
 >> iter 48000, loss: 0.024704
 >> iter 49000, loss: 0.020452
 >> iter 50000, loss: 0.019070
   Number of active neurons: 1
 >> iter 51000, loss: 0.022959
 >> iter 52000, loss: 0.024745
 >> iter 53000, loss: 0.022073
 >> iter 54000, loss: 0.017542
 >> iter 55000, loss: 0.016980
 >> iter 56000, loss: 0.020224
 >> iter 57000, loss: 0.022336
 >> iter 58000, loss: 0.018653
 >> iter 59000, loss: 0.016325
 >> iter 60000, loss: 0.020896
   Number of active neurons: 1
 >> iter 61000, loss: 0.018209
 >> iter 62000, loss: 0.018305
 >> iter 63000, loss: 0.018197
 >> iter 64000, loss: 0.018345
 >> iter 65000, loss: 0.021388
 >> iter 66000, loss: 0.020710
 >> iter 67000, loss: 0.017759
 >> iter 68000, loss: 0.016265
 >> iter 69000, loss: 0.016499
 >> iter 70000, loss: 0.022226
   Number of active neurons: 1
 >> iter 71000, loss: 0.019343
 >> iter 72000, loss: 0.016395
 >> iter 73000, loss: 0.021763
 >> iter 74000, loss: 0.018402
 >> iter 75000, loss: 0.022454
 >> iter 76000, loss: 0.018057
 >> iter 77000, loss: 0.026199
 >> iter 78000, loss: 0.023697
 >> iter 79000, loss: 0.032036
 >> iter 80000, loss: 0.023318
   Number of active neurons: 1
 >> iter 81000, loss: 0.018687
 >> iter 82000, loss: 0.017859
 >> iter 83000, loss: 0.020206
 >> iter 84000, loss: 0.020028
 >> iter 85000, loss: 0.019212
 >> iter 86000, loss: 0.018905
 >> iter 87000, loss: 0.043196
 >> iter 88000, loss: 0.025700
 >> iter 89000, loss: 0.020169
 >> iter 90000, loss: 0.024286
   Number of active neurons: 1
 >> iter 91000, loss: 0.022627
 >> iter 92000, loss: 0.028791
 >> iter 93000, loss: 0.029631
 >> iter 94000, loss: 0.021052
 >> iter 95000, loss: 0.018328
 >> iter 96000, loss: 0.017601
 >> iter 97000, loss: 0.024954
 >> iter 98000, loss: 0.020309
 >> iter 99000, loss: 0.017435
 >> iter 100000, loss: 0.018544
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.060623
 >> iter 2000, loss: 4.109917
 >> iter 3000, loss: 1.575207
 >> iter 4000, loss: 0.598913
 >> iter 5000, loss: 0.242159
 >> iter 6000, loss: 0.104157
 >> iter 7000, loss: 0.055667
 >> iter 8000, loss: 0.042405
 >> iter 9000, loss: 0.040149
 >> iter 10000, loss: 0.030579
   Number of active neurons: 3
 >> iter 11000, loss: 0.031383
 >> iter 12000, loss: 0.027343
 >> iter 13000, loss: 0.031058
 >> iter 14000, loss: 0.027321
 >> iter 15000, loss: 0.024114
 >> iter 16000, loss: 0.023784
 >> iter 17000, loss: 0.027205
 >> iter 18000, loss: 0.025151
 >> iter 19000, loss: 0.025011
 >> iter 20000, loss: 0.045645
   Number of active neurons: 2
 >> iter 21000, loss: 0.029970
 >> iter 22000, loss: 0.028960
 >> iter 23000, loss: 0.024280
 >> iter 24000, loss: 0.023324
 >> iter 25000, loss: 0.034063
 >> iter 26000, loss: 0.026889
 >> iter 27000, loss: 0.023188
 >> iter 28000, loss: 0.025052
 >> iter 29000, loss: 0.022087
 >> iter 30000, loss: 0.020417
   Number of active neurons: 2
 >> iter 31000, loss: 0.024973
 >> iter 32000, loss: 0.023924
 >> iter 33000, loss: 0.022513
 >> iter 34000, loss: 0.019789
 >> iter 35000, loss: 0.029730
 >> iter 36000, loss: 0.026575
 >> iter 37000, loss: 0.022319
 >> iter 38000, loss: 0.018456
 >> iter 39000, loss: 0.022909
 >> iter 40000, loss: 0.025135
   Number of active neurons: 1
 >> iter 41000, loss: 0.022103
 >> iter 42000, loss: 0.021861
 >> iter 43000, loss: 0.017880
 >> iter 44000, loss: 0.026861
 >> iter 45000, loss: 0.020786
 >> iter 46000, loss: 0.035095
 >> iter 47000, loss: 0.027762
 >> iter 48000, loss: 0.026226
 >> iter 49000, loss: 0.028578
 >> iter 50000, loss: 0.039870
   Number of active neurons: 1
 >> iter 51000, loss: 0.027502
 >> iter 52000, loss: 0.029051
 >> iter 53000, loss: 0.022485
 >> iter 54000, loss: 0.017492
 >> iter 55000, loss: 0.017919
 >> iter 56000, loss: 0.020362
 >> iter 57000, loss: 0.027534
 >> iter 58000, loss: 0.019760
 >> iter 59000, loss: 0.018376
 >> iter 60000, loss: 0.021360
   Number of active neurons: 1
 >> iter 61000, loss: 0.018342
 >> iter 62000, loss: 0.017858
 >> iter 63000, loss: 0.017832
 >> iter 64000, loss: 0.019404
 >> iter 65000, loss: 0.027400
 >> iter 66000, loss: 0.020604
 >> iter 67000, loss: 0.021532
 >> iter 68000, loss: 0.018238
 >> iter 69000, loss: 0.021817
 >> iter 70000, loss: 0.019411
   Number of active neurons: 1
 >> iter 71000, loss: 0.017464
 >> iter 72000, loss: 0.015797
 >> iter 73000, loss: 0.028758
 >> iter 74000, loss: 0.033597
 >> iter 75000, loss: 0.022450
 >> iter 76000, loss: 0.023231
 >> iter 77000, loss: 0.021625
 >> iter 78000, loss: 0.021412
 >> iter 79000, loss: 0.024535
 >> iter 80000, loss: 0.022498
   Number of active neurons: 1
 >> iter 81000, loss: 0.024312
 >> iter 82000, loss: 0.019175
 >> iter 83000, loss: 0.033169
 >> iter 84000, loss: 0.026259
 >> iter 85000, loss: 0.020128
 >> iter 86000, loss: 0.021224
 >> iter 87000, loss: 0.019571
 >> iter 88000, loss: 0.017995
 >> iter 89000, loss: 0.017586
 >> iter 90000, loss: 0.027690
   Number of active neurons: 1
 >> iter 91000, loss: 0.023883
 >> iter 92000, loss: 0.022559
 >> iter 93000, loss: 0.025272
 >> iter 94000, loss: 0.019914
 >> iter 95000, loss: 0.036500
 >> iter 96000, loss: 0.026859
 >> iter 97000, loss: 0.022654
 >> iter 98000, loss: 0.018482
 >> iter 99000, loss: 0.016664
 >> iter 100000, loss: 0.017095
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.005374
 >> iter 2000, loss: 4.087645
 >> iter 3000, loss: 1.533026
 >> iter 4000, loss: 0.585531
 >> iter 5000, loss: 0.238922
 >> iter 6000, loss: 0.110294
 >> iter 7000, loss: 0.061280
 >> iter 8000, loss: 0.038131
 >> iter 9000, loss: 0.036105
 >> iter 10000, loss: 0.030216
   Number of active neurons: 4
 >> iter 11000, loss: 0.038334
 >> iter 12000, loss: 0.029309
 >> iter 13000, loss: 0.030424
 >> iter 14000, loss: 0.029247
 >> iter 15000, loss: 0.028042
 >> iter 16000, loss: 0.027985
 >> iter 17000, loss: 0.030844
 >> iter 18000, loss: 0.030335
 >> iter 19000, loss: 0.030552
 >> iter 20000, loss: 0.026361
   Number of active neurons: 4
 >> iter 21000, loss: 0.025878
 >> iter 22000, loss: 0.028668
 >> iter 23000, loss: 0.064908
 >> iter 24000, loss: 0.044903
 >> iter 25000, loss: 0.035015
 >> iter 26000, loss: 0.029190
 >> iter 27000, loss: 0.027027
 >> iter 28000, loss: 0.024169
 >> iter 29000, loss: 0.038217
 >> iter 30000, loss: 0.028451
   Number of active neurons: 3
 >> iter 31000, loss: 0.025560
 >> iter 32000, loss: 0.039667
 >> iter 33000, loss: 0.034477
 >> iter 34000, loss: 0.028310
 >> iter 35000, loss: 0.032113
 >> iter 36000, loss: 0.075020
 >> iter 37000, loss: 0.056144
 >> iter 38000, loss: 0.039598
 >> iter 39000, loss: 0.029525
 >> iter 40000, loss: 0.025048
   Number of active neurons: 2
 >> iter 41000, loss: 0.029805
 >> iter 42000, loss: 0.025708
 >> iter 43000, loss: 0.042580
 >> iter 44000, loss: 0.032190
 >> iter 45000, loss: 0.026587
 >> iter 46000, loss: 0.024793
 >> iter 47000, loss: 0.022242
 >> iter 48000, loss: 0.020310
 >> iter 49000, loss: 0.020485
 >> iter 50000, loss: 0.019601
   Number of active neurons: 2
 >> iter 51000, loss: 0.025629
 >> iter 52000, loss: 0.024210
 >> iter 53000, loss: 0.022534
 >> iter 54000, loss: 0.022907
 >> iter 55000, loss: 0.020849
 >> iter 56000, loss: 0.028988
 >> iter 57000, loss: 0.023246
 >> iter 58000, loss: 0.021712
 >> iter 59000, loss: 0.019690
 >> iter 60000, loss: 0.020804
   Number of active neurons: 1
 >> iter 61000, loss: 0.022141
 >> iter 62000, loss: 0.018170
 >> iter 63000, loss: 0.020430
 >> iter 64000, loss: 0.021735
 >> iter 65000, loss: 0.020146
 >> iter 66000, loss: 0.018118
 >> iter 67000, loss: 0.017126
 >> iter 68000, loss: 0.019336
 >> iter 69000, loss: 0.041933
 >> iter 70000, loss: 0.028479
   Number of active neurons: 1
 >> iter 71000, loss: 0.024911
 >> iter 72000, loss: 0.025765
 >> iter 73000, loss: 0.021357
 >> iter 74000, loss: 0.018007
 >> iter 75000, loss: 0.029595
 >> iter 76000, loss: 0.021973
 >> iter 77000, loss: 0.021423
 >> iter 78000, loss: 0.020354
 >> iter 79000, loss: 0.017885
 >> iter 80000, loss: 0.016836
   Number of active neurons: 1
 >> iter 81000, loss: 0.022178
 >> iter 82000, loss: 0.021142
 >> iter 83000, loss: 0.017932
 >> iter 84000, loss: 0.016004
 >> iter 85000, loss: 0.018944
 >> iter 86000, loss: 0.024665
 >> iter 87000, loss: 0.050149
 >> iter 88000, loss: 0.035039
 >> iter 89000, loss: 0.025695
 >> iter 90000, loss: 0.023422
   Number of active neurons: 1
 >> iter 91000, loss: 0.019559
 >> iter 92000, loss: 0.016902
 >> iter 93000, loss: 0.017808
 >> iter 94000, loss: 0.019034
 >> iter 95000, loss: 0.019185
 >> iter 96000, loss: 0.025235
 >> iter 97000, loss: 0.019395
 >> iter 98000, loss: 0.020628
 >> iter 99000, loss: 0.020526
 >> iter 100000, loss: 0.016746
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.029194
 >> iter 2000, loss: 4.093060
 >> iter 3000, loss: 1.529642
 >> iter 4000, loss: 0.582184
 >> iter 5000, loss: 0.232416
 >> iter 6000, loss: 0.106953
 >> iter 7000, loss: 0.060984
 >> iter 8000, loss: 0.040787
 >> iter 9000, loss: 0.032979
 >> iter 10000, loss: 0.031508
   Number of active neurons: 4
 >> iter 11000, loss: 0.034723
 >> iter 12000, loss: 0.031946
 >> iter 13000, loss: 0.029841
 >> iter 14000, loss: 0.026636
 >> iter 15000, loss: 0.030433
 >> iter 16000, loss: 0.026933
 >> iter 17000, loss: 0.028545
 >> iter 18000, loss: 0.025931
 >> iter 19000, loss: 0.025385
 >> iter 20000, loss: 0.026999
   Number of active neurons: 3
 >> iter 21000, loss: 0.023313
 >> iter 22000, loss: 0.024406
 >> iter 23000, loss: 0.031998
 >> iter 24000, loss: 0.026289
 >> iter 25000, loss: 0.026809
 >> iter 26000, loss: 0.023311
 >> iter 27000, loss: 0.025314
 >> iter 28000, loss: 0.022154
 >> iter 29000, loss: 0.022360
 >> iter 30000, loss: 0.023059
   Number of active neurons: 2
 >> iter 31000, loss: 0.040734
 >> iter 32000, loss: 0.032746
 >> iter 33000, loss: 0.027133
 >> iter 34000, loss: 0.023296
 >> iter 35000, loss: 0.025265
 >> iter 36000, loss: 0.030663
 >> iter 37000, loss: 0.024216
 >> iter 38000, loss: 0.025554
 >> iter 39000, loss: 0.022092
 >> iter 40000, loss: 0.021338
   Number of active neurons: 2
 >> iter 41000, loss: 0.031440
 >> iter 42000, loss: 0.024692
 >> iter 43000, loss: 0.024256
 >> iter 44000, loss: 0.023744
 >> iter 45000, loss: 0.056649
 >> iter 46000, loss: 0.033539
 >> iter 47000, loss: 0.026777
 >> iter 48000, loss: 0.037291
 >> iter 49000, loss: 0.027747
 >> iter 50000, loss: 0.022951
   Number of active neurons: 2
 >> iter 51000, loss: 0.023219
 >> iter 52000, loss: 0.020068
 >> iter 53000, loss: 0.021611
 >> iter 54000, loss: 0.024913
 >> iter 55000, loss: 0.023823
 >> iter 56000, loss: 0.023638
 >> iter 57000, loss: 0.023166
 >> iter 58000, loss: 0.032990
 >> iter 59000, loss: 0.025881
 >> iter 60000, loss: 0.022017
   Number of active neurons: 2
 >> iter 61000, loss: 0.020548
 >> iter 62000, loss: 0.020972
 >> iter 63000, loss: 0.022063
 >> iter 64000, loss: 0.022915
 >> iter 65000, loss: 0.021751
 >> iter 66000, loss: 0.021059
 >> iter 67000, loss: 0.035702
 >> iter 68000, loss: 0.031722
 >> iter 69000, loss: 0.028596
 >> iter 70000, loss: 0.022277
   Number of active neurons: 2
 >> iter 71000, loss: 0.024957
 >> iter 72000, loss: 0.023169
 >> iter 73000, loss: 0.024186
 >> iter 74000, loss: 0.028798
 >> iter 75000, loss: 0.024259
 >> iter 76000, loss: 0.024187
 >> iter 77000, loss: 0.025966
 >> iter 78000, loss: 0.021566
 >> iter 79000, loss: 0.021380
 >> iter 80000, loss: 0.023067
   Number of active neurons: 2
 >> iter 81000, loss: 0.026590
 >> iter 82000, loss: 0.022752
 >> iter 83000, loss: 0.026290
 >> iter 84000, loss: 0.049734
 >> iter 85000, loss: 0.044594
 >> iter 86000, loss: 0.029110
 >> iter 87000, loss: 0.023215
 >> iter 88000, loss: 0.025760
 >> iter 89000, loss: 0.028195
 >> iter 90000, loss: 0.024705
   Number of active neurons: 2
 >> iter 91000, loss: 0.020934
 >> iter 92000, loss: 0.020234
 >> iter 93000, loss: 0.020793
 >> iter 94000, loss: 0.025033
 >> iter 95000, loss: 0.029126
 >> iter 96000, loss: 0.025907
 >> iter 97000, loss: 0.022529
 >> iter 98000, loss: 0.021697
 >> iter 99000, loss: 0.033843
 >> iter 100000, loss: 0.025004
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 10.999588
 >> iter 2000, loss: 4.085480
 >> iter 3000, loss: 1.535186
 >> iter 4000, loss: 0.585239
 >> iter 5000, loss: 0.234709
 >> iter 6000, loss: 0.103967
 >> iter 7000, loss: 0.055228
 >> iter 8000, loss: 0.037673
 >> iter 9000, loss: 0.031504
 >> iter 10000, loss: 0.027093
   Number of active neurons: 3
 >> iter 11000, loss: 0.029246
 >> iter 12000, loss: 0.030739
 >> iter 13000, loss: 0.037463
 >> iter 14000, loss: 0.029694
 >> iter 15000, loss: 0.039887
 >> iter 16000, loss: 0.042843
 >> iter 17000, loss: 0.031522
 >> iter 18000, loss: 0.028301
 >> iter 19000, loss: 0.024712
 >> iter 20000, loss: 0.027142
   Number of active neurons: 3
 >> iter 21000, loss: 0.029997
 >> iter 22000, loss: 0.031515
 >> iter 23000, loss: 0.041903
 >> iter 24000, loss: 0.040299
 >> iter 25000, loss: 0.036555
 >> iter 26000, loss: 0.036040
 >> iter 27000, loss: 0.027654
 >> iter 28000, loss: 0.027253
 >> iter 29000, loss: 0.030447
 >> iter 30000, loss: 0.028129
   Number of active neurons: 3
 >> iter 31000, loss: 0.026250
 >> iter 32000, loss: 0.023394
 >> iter 33000, loss: 0.024312
 >> iter 34000, loss: 0.022559
 >> iter 35000, loss: 0.028621
 >> iter 36000, loss: 0.038613
 >> iter 37000, loss: 0.029087
 >> iter 38000, loss: 0.023269
 >> iter 39000, loss: 0.026548
 >> iter 40000, loss: 0.024833
   Number of active neurons: 2
 >> iter 41000, loss: 0.030329
 >> iter 42000, loss: 0.050510
 >> iter 43000, loss: 0.033862
 >> iter 44000, loss: 0.033530
 >> iter 45000, loss: 0.025111
 >> iter 46000, loss: 0.052789
 >> iter 47000, loss: 0.038638
 >> iter 48000, loss: 0.027147
 >> iter 49000, loss: 0.021836
 >> iter 50000, loss: 0.032281
   Number of active neurons: 1
 >> iter 51000, loss: 0.024463
 >> iter 52000, loss: 0.028039
 >> iter 53000, loss: 0.021533
 >> iter 54000, loss: 0.018514
 >> iter 55000, loss: 0.022784
 >> iter 56000, loss: 0.021636
 >> iter 57000, loss: 0.022817
 >> iter 58000, loss: 0.019940
 >> iter 59000, loss: 0.019625
 >> iter 60000, loss: 0.020961
   Number of active neurons: 1
 >> iter 61000, loss: 0.020786
 >> iter 62000, loss: 0.020452
 >> iter 63000, loss: 0.017652
 >> iter 64000, loss: 0.017702
 >> iter 65000, loss: 0.017165
 >> iter 66000, loss: 0.018104
 >> iter 67000, loss: 0.029944
 >> iter 68000, loss: 0.026422
 >> iter 69000, loss: 0.028287
 >> iter 70000, loss: 0.019806
   Number of active neurons: 1
 >> iter 71000, loss: 0.018486
 >> iter 72000, loss: 0.019712
 >> iter 73000, loss: 0.018065
 >> iter 74000, loss: 0.028126
 >> iter 75000, loss: 0.021191
 >> iter 76000, loss: 0.018245
 >> iter 77000, loss: 0.021297
 >> iter 78000, loss: 0.024562
 >> iter 79000, loss: 0.027295
 >> iter 80000, loss: 0.021871
   Number of active neurons: 1
 >> iter 81000, loss: 0.017785
 >> iter 82000, loss: 0.019906
 >> iter 83000, loss: 0.018226
 >> iter 84000, loss: 0.017546
 >> iter 85000, loss: 0.020100
 >> iter 86000, loss: 0.017074
 >> iter 87000, loss: 0.021382
 >> iter 88000, loss: 0.017912
 >> iter 89000, loss: 0.016975
 >> iter 90000, loss: 0.016955
   Number of active neurons: 1
 >> iter 91000, loss: 0.020969
 >> iter 92000, loss: 0.018048
 >> iter 93000, loss: 0.022689
 >> iter 94000, loss: 0.026057
 >> iter 95000, loss: 0.027096
 >> iter 96000, loss: 0.020668
 >> iter 97000, loss: 0.021683
 >> iter 98000, loss: 0.026799
 >> iter 99000, loss: 0.021980
 >> iter 100000, loss: 0.017142
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.989702
 >> iter 2000, loss: 4.076022
 >> iter 3000, loss: 1.520608
 >> iter 4000, loss: 0.581544
 >> iter 5000, loss: 0.232576
 >> iter 6000, loss: 0.104748
 >> iter 7000, loss: 0.053147
 >> iter 8000, loss: 0.034867
 >> iter 9000, loss: 0.028095
 >> iter 10000, loss: 0.024616
   Number of active neurons: 3
 >> iter 11000, loss: 0.023939
 >> iter 12000, loss: 0.025656
 >> iter 13000, loss: 0.026816
 >> iter 14000, loss: 0.024783
 >> iter 15000, loss: 0.022284
 >> iter 16000, loss: 0.034782
 >> iter 17000, loss: 0.032430
 >> iter 18000, loss: 0.026362
 >> iter 19000, loss: 0.027648
 >> iter 20000, loss: 0.023417
   Number of active neurons: 3
 >> iter 21000, loss: 0.025324
 >> iter 22000, loss: 0.026764
 >> iter 23000, loss: 0.024923
 >> iter 24000, loss: 0.035246
 >> iter 25000, loss: 0.026816
 >> iter 26000, loss: 0.025373
 >> iter 27000, loss: 0.026213
 >> iter 28000, loss: 0.034780
 >> iter 29000, loss: 0.028310
 >> iter 30000, loss: 0.030782
   Number of active neurons: 3
 >> iter 31000, loss: 0.025173
 >> iter 32000, loss: 0.025027
 >> iter 33000, loss: 0.025132
 >> iter 34000, loss: 0.031278
 >> iter 35000, loss: 0.032096
 >> iter 36000, loss: 0.026715
 >> iter 37000, loss: 0.025567
 >> iter 38000, loss: 0.026689
 >> iter 39000, loss: 0.025191
 >> iter 40000, loss: 0.022645
   Number of active neurons: 3
 >> iter 41000, loss: 0.044066
 >> iter 42000, loss: 0.032494
 >> iter 43000, loss: 0.026449
 >> iter 44000, loss: 0.028621
 >> iter 45000, loss: 0.028389
 >> iter 46000, loss: 0.024951
 >> iter 47000, loss: 0.024204
 >> iter 48000, loss: 0.023795
 >> iter 49000, loss: 0.026986
 >> iter 50000, loss: 0.022585
   Number of active neurons: 2
 >> iter 51000, loss: 0.026431
 >> iter 52000, loss: 0.023858
 >> iter 53000, loss: 0.072117
 >> iter 54000, loss: 0.041699
 >> iter 55000, loss: 0.029298
 >> iter 56000, loss: 0.029852
 >> iter 57000, loss: 0.024277
 >> iter 58000, loss: 0.022621
 >> iter 59000, loss: 0.026697
 >> iter 60000, loss: 0.025262
   Number of active neurons: 2
 >> iter 61000, loss: 0.034983
 >> iter 62000, loss: 0.025373
 >> iter 63000, loss: 0.033860
 >> iter 64000, loss: 0.024200
 >> iter 65000, loss: 0.035490
 >> iter 66000, loss: 0.029006
 >> iter 67000, loss: 0.025749
 >> iter 68000, loss: 0.023234
 >> iter 69000, loss: 0.027596
 >> iter 70000, loss: 0.023589
   Number of active neurons: 2
 >> iter 71000, loss: 0.034595
 >> iter 72000, loss: 0.029005
 >> iter 73000, loss: 0.026129
 >> iter 74000, loss: 0.025612
 >> iter 75000, loss: 0.030296
 >> iter 76000, loss: 0.026225
 >> iter 77000, loss: 0.023366
 >> iter 78000, loss: 0.020672
 >> iter 79000, loss: 0.033404
 >> iter 80000, loss: 0.028918
   Number of active neurons: 2
 >> iter 81000, loss: 0.026750
 >> iter 82000, loss: 0.025228
 >> iter 83000, loss: 0.023701
 >> iter 84000, loss: 0.024773
 >> iter 85000, loss: 0.025708
 >> iter 86000, loss: 0.023117
 >> iter 87000, loss: 0.023314
 >> iter 88000, loss: 0.026223
 >> iter 89000, loss: 0.033232
 >> iter 90000, loss: 0.026084
   Number of active neurons: 2
 >> iter 91000, loss: 0.023697
 >> iter 92000, loss: 0.024825
 >> iter 93000, loss: 0.022524
 >> iter 94000, loss: 0.025946
 >> iter 95000, loss: 0.023252
 >> iter 96000, loss: 0.023166
 >> iter 97000, loss: 0.019881
 >> iter 98000, loss: 0.019303
 >> iter 99000, loss: 0.019827
 >> iter 100000, loss: 0.025248
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.966957
 >> iter 2000, loss: 4.084768
 >> iter 3000, loss: 1.533241
 >> iter 4000, loss: 0.583741
 >> iter 5000, loss: 0.233257
 >> iter 6000, loss: 0.119102
 >> iter 7000, loss: 0.064151
 >> iter 8000, loss: 0.045433
 >> iter 9000, loss: 0.038212
 >> iter 10000, loss: 0.031334
   Number of active neurons: 4
 >> iter 11000, loss: 0.030334
 >> iter 12000, loss: 0.038456
 >> iter 13000, loss: 0.033317
 >> iter 14000, loss: 0.027106
 >> iter 15000, loss: 0.026252
 >> iter 16000, loss: 0.029509
 >> iter 17000, loss: 0.026098
 >> iter 18000, loss: 0.025803
 >> iter 19000, loss: 0.027334
 >> iter 20000, loss: 0.023184
   Number of active neurons: 3
 >> iter 21000, loss: 0.025103
 >> iter 22000, loss: 0.023099
 >> iter 23000, loss: 0.023605
 >> iter 24000, loss: 0.022361
 >> iter 25000, loss: 0.021497
 >> iter 26000, loss: 0.023493
 >> iter 27000, loss: 0.024297
 >> iter 28000, loss: 0.063596
 >> iter 29000, loss: 0.046886
 >> iter 30000, loss: 0.030063
   Number of active neurons: 2
 >> iter 31000, loss: 0.025268
 >> iter 32000, loss: 0.021167
 >> iter 33000, loss: 0.022147
 >> iter 34000, loss: 0.029186
 >> iter 35000, loss: 0.035200
 >> iter 36000, loss: 0.025105
 >> iter 37000, loss: 0.025530
 >> iter 38000, loss: 0.021978
 >> iter 39000, loss: 0.024457
 >> iter 40000, loss: 0.022450
   Number of active neurons: 2
 >> iter 41000, loss: 0.022361
 >> iter 42000, loss: 0.023515
 >> iter 43000, loss: 0.023081
 >> iter 44000, loss: 0.022532
 >> iter 45000, loss: 0.027993
 >> iter 46000, loss: 0.022763
 >> iter 47000, loss: 0.021533
 >> iter 48000, loss: 0.024747
 >> iter 49000, loss: 0.023192
 >> iter 50000, loss: 0.020370
   Number of active neurons: 2
 >> iter 51000, loss: 0.020711
 >> iter 52000, loss: 0.021707
 >> iter 53000, loss: 0.020386
 >> iter 54000, loss: 0.020462
 >> iter 55000, loss: 0.022071
 >> iter 56000, loss: 0.026249
 >> iter 57000, loss: 0.026259
 >> iter 58000, loss: 0.022020
 >> iter 59000, loss: 0.030170
 >> iter 60000, loss: 0.022153
   Number of active neurons: 2
 >> iter 61000, loss: 0.059820
 >> iter 62000, loss: 0.038102
 >> iter 63000, loss: 0.028048
 >> iter 64000, loss: 0.021997
 >> iter 65000, loss: 0.031649
 >> iter 66000, loss: 0.040379
 >> iter 67000, loss: 0.028777
 >> iter 68000, loss: 0.024406
 >> iter 69000, loss: 0.025419
 >> iter 70000, loss: 0.021145
   Number of active neurons: 2
 >> iter 71000, loss: 0.020604
 >> iter 72000, loss: 0.024943
 >> iter 73000, loss: 0.024658
 >> iter 74000, loss: 0.031375
 >> iter 75000, loss: 0.026233
 >> iter 76000, loss: 0.023975
 >> iter 77000, loss: 0.026397
 >> iter 78000, loss: 0.024081
 >> iter 79000, loss: 0.019963
 >> iter 80000, loss: 0.019231
   Number of active neurons: 2
 >> iter 81000, loss: 0.031212
 >> iter 82000, loss: 0.024643
 >> iter 83000, loss: 0.024654
 >> iter 84000, loss: 0.023735
 >> iter 85000, loss: 0.025524
 >> iter 86000, loss: 0.022175
 >> iter 87000, loss: 0.023180
 >> iter 88000, loss: 0.022417
 >> iter 89000, loss: 0.020767
 >> iter 90000, loss: 0.021126
   Number of active neurons: 2
 >> iter 91000, loss: 0.021639
 >> iter 92000, loss: 0.019715
 >> iter 93000, loss: 0.026221
 >> iter 94000, loss: 0.038998
 >> iter 95000, loss: 0.030581
 >> iter 96000, loss: 0.037234
 >> iter 97000, loss: 0.031204
 >> iter 98000, loss: 0.024271
 >> iter 99000, loss: 0.020622
 >> iter 100000, loss: 0.021603
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.894609
 >> iter 2000, loss: 4.048722
 >> iter 3000, loss: 1.519211
 >> iter 4000, loss: 0.576765
 >> iter 5000, loss: 0.235034
 >> iter 6000, loss: 0.107794
 >> iter 7000, loss: 0.055854
 >> iter 8000, loss: 0.039412
 >> iter 9000, loss: 0.031652
 >> iter 10000, loss: 0.029178
   Number of active neurons: 4
 >> iter 11000, loss: 0.034820
 >> iter 12000, loss: 0.030611
 >> iter 13000, loss: 0.031296
 >> iter 14000, loss: 0.027758
 >> iter 15000, loss: 0.029208
 >> iter 16000, loss: 0.031996
 >> iter 17000, loss: 0.029565
 >> iter 18000, loss: 0.029831
 >> iter 19000, loss: 0.026865
 >> iter 20000, loss: 0.024583
   Number of active neurons: 3
 >> iter 21000, loss: 0.036766
 >> iter 22000, loss: 0.028865
 >> iter 23000, loss: 0.027100
 >> iter 24000, loss: 0.025783
 >> iter 25000, loss: 0.023000
 >> iter 26000, loss: 0.023925
 >> iter 27000, loss: 0.024759
 >> iter 28000, loss: 0.023488
 >> iter 29000, loss: 0.023666
 >> iter 30000, loss: 0.023939
   Number of active neurons: 3
 >> iter 31000, loss: 0.026952
 >> iter 32000, loss: 0.026379
 >> iter 33000, loss: 0.026395
 >> iter 34000, loss: 0.023542
 >> iter 35000, loss: 0.028402
 >> iter 36000, loss: 0.026947
 >> iter 37000, loss: 0.024748
 >> iter 38000, loss: 0.049705
 >> iter 39000, loss: 0.034630
 >> iter 40000, loss: 0.030280
   Number of active neurons: 3
 >> iter 41000, loss: 0.026221
 >> iter 42000, loss: 0.036345
 >> iter 43000, loss: 0.028929
 >> iter 44000, loss: 0.028755
 >> iter 45000, loss: 0.028082
 >> iter 46000, loss: 0.031954
 >> iter 47000, loss: 0.025934
 >> iter 48000, loss: 0.035797
 >> iter 49000, loss: 0.029394
 >> iter 50000, loss: 0.028484
   Number of active neurons: 3
 >> iter 51000, loss: 0.026424
 >> iter 52000, loss: 0.031671
 >> iter 53000, loss: 0.028379
 >> iter 54000, loss: 0.025073
 >> iter 55000, loss: 0.045386
 >> iter 56000, loss: 0.036363
 >> iter 57000, loss: 0.032190
 >> iter 58000, loss: 0.029057
 >> iter 59000, loss: 0.026388
 >> iter 60000, loss: 0.028136
   Number of active neurons: 3
 >> iter 61000, loss: 0.024832
 >> iter 62000, loss: 0.024242
 >> iter 63000, loss: 0.026445
 >> iter 64000, loss: 0.025230
 >> iter 65000, loss: 0.024053
 >> iter 66000, loss: 0.024616
 >> iter 67000, loss: 0.026182
 >> iter 68000, loss: 0.035246
 >> iter 69000, loss: 0.027122
 >> iter 70000, loss: 0.027649
   Number of active neurons: 3
 >> iter 71000, loss: 0.023750
 >> iter 72000, loss: 0.028795
 >> iter 73000, loss: 0.024564
 >> iter 74000, loss: 0.023526
 >> iter 75000, loss: 0.022654
 >> iter 76000, loss: 0.020968
 >> iter 77000, loss: 0.022978
 >> iter 78000, loss: 0.036446
 >> iter 79000, loss: 0.030680
 >> iter 80000, loss: 0.024366
   Number of active neurons: 1
 >> iter 81000, loss: 0.023539
 >> iter 82000, loss: 0.021727
 >> iter 83000, loss: 0.026929
 >> iter 84000, loss: 0.023089
 >> iter 85000, loss: 0.019451
 >> iter 86000, loss: 0.019103
 >> iter 87000, loss: 0.017684
 >> iter 88000, loss: 0.020674
 >> iter 89000, loss: 0.022752
 >> iter 90000, loss: 0.053907
   Number of active neurons: 1
 >> iter 91000, loss: 0.030936
 >> iter 92000, loss: 0.024698
 >> iter 93000, loss: 0.020521
 >> iter 94000, loss: 0.018699
 >> iter 95000, loss: 0.017763
 >> iter 96000, loss: 0.033382
 >> iter 97000, loss: 0.026421
 >> iter 98000, loss: 0.020515
 >> iter 99000, loss: 0.019726
 >> iter 100000, loss: 0.020553
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.963271
 >> iter 2000, loss: 4.082645
 >> iter 3000, loss: 1.528604
 >> iter 4000, loss: 0.581042
 >> iter 5000, loss: 0.234297
 >> iter 6000, loss: 0.102375
 >> iter 7000, loss: 0.066936
 >> iter 8000, loss: 0.041185
 >> iter 9000, loss: 0.032880
 >> iter 10000, loss: 0.031725
   Number of active neurons: 4
 >> iter 11000, loss: 0.028494
 >> iter 12000, loss: 0.028329
 >> iter 13000, loss: 0.029329
 >> iter 14000, loss: 0.029794
 >> iter 15000, loss: 0.030139
 >> iter 16000, loss: 0.027028
 >> iter 17000, loss: 0.033364
 >> iter 18000, loss: 0.029776
 >> iter 19000, loss: 0.028385
 >> iter 20000, loss: 0.030054
   Number of active neurons: 4
 >> iter 21000, loss: 0.033481
 >> iter 22000, loss: 0.032184
 >> iter 23000, loss: 0.032133
 >> iter 24000, loss: 0.027039
 >> iter 25000, loss: 0.029745
 >> iter 26000, loss: 0.025914
 >> iter 27000, loss: 0.027257
 >> iter 28000, loss: 0.026976
 >> iter 29000, loss: 0.024119
 >> iter 30000, loss: 0.025513
   Number of active neurons: 3
 >> iter 31000, loss: 0.025850
 >> iter 32000, loss: 0.022854
 >> iter 33000, loss: 0.045712
 >> iter 34000, loss: 0.030245
 >> iter 35000, loss: 0.025870
 >> iter 36000, loss: 0.026897
 >> iter 37000, loss: 0.029946
 >> iter 38000, loss: 0.031369
 >> iter 39000, loss: 0.041299
 >> iter 40000, loss: 0.030026
   Number of active neurons: 3
 >> iter 41000, loss: 0.027177
 >> iter 42000, loss: 0.027278
 >> iter 43000, loss: 0.025498
 >> iter 44000, loss: 0.028246
 >> iter 45000, loss: 0.025560
 >> iter 46000, loss: 0.039965
 >> iter 47000, loss: 0.028210
 >> iter 48000, loss: 0.026243
 >> iter 49000, loss: 0.024298
 >> iter 50000, loss: 0.022795
   Number of active neurons: 3
 >> iter 51000, loss: 0.029250
 >> iter 52000, loss: 0.028126
 >> iter 53000, loss: 0.024047
 >> iter 54000, loss: 0.024176
 >> iter 55000, loss: 0.028576
 >> iter 56000, loss: 0.026751
 >> iter 57000, loss: 0.024601
 >> iter 58000, loss: 0.025252
 >> iter 59000, loss: 0.027938
 >> iter 60000, loss: 0.024317
   Number of active neurons: 2
 >> iter 61000, loss: 0.023361
 >> iter 62000, loss: 0.023897
 >> iter 63000, loss: 0.021680
 >> iter 64000, loss: 0.020805
 >> iter 65000, loss: 0.024104
 >> iter 66000, loss: 0.023590
 >> iter 67000, loss: 0.021839
 >> iter 68000, loss: 0.020849
 >> iter 69000, loss: 0.020849
 >> iter 70000, loss: 0.023046
   Number of active neurons: 2
 >> iter 71000, loss: 0.020570
 >> iter 72000, loss: 0.022177
 >> iter 73000, loss: 0.027706
 >> iter 74000, loss: 0.023000
 >> iter 75000, loss: 0.023876
 >> iter 76000, loss: 0.022190
 >> iter 77000, loss: 0.025172
 >> iter 78000, loss: 0.049870
 >> iter 79000, loss: 0.036325
 >> iter 80000, loss: 0.035123
   Number of active neurons: 2
 >> iter 81000, loss: 0.026229
 >> iter 82000, loss: 0.025746
 >> iter 83000, loss: 0.028764
 >> iter 84000, loss: 0.026649
 >> iter 85000, loss: 0.022819
 >> iter 86000, loss: 0.020161
 >> iter 87000, loss: 0.020879
 >> iter 88000, loss: 0.037251
 >> iter 89000, loss: 0.029000
 >> iter 90000, loss: 0.042626
   Number of active neurons: 2
 >> iter 91000, loss: 0.037272
 >> iter 92000, loss: 0.046158
 >> iter 93000, loss: 0.033143
 >> iter 94000, loss: 0.025736
 >> iter 95000, loss: 0.030097
 >> iter 96000, loss: 0.025848
 >> iter 97000, loss: 0.021862
 >> iter 98000, loss: 0.032030
 >> iter 99000, loss: 0.039215
 >> iter 100000, loss: 0.025269
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.991834
 >> iter 2000, loss: 4.075536
 >> iter 3000, loss: 1.517319
 >> iter 4000, loss: 0.580483
 >> iter 5000, loss: 0.231803
 >> iter 6000, loss: 0.099831
 >> iter 7000, loss: 0.050941
 >> iter 8000, loss: 0.033433
 >> iter 9000, loss: 0.030603
 >> iter 10000, loss: 0.025317
   Number of active neurons: 2
 >> iter 11000, loss: 0.022486
 >> iter 12000, loss: 0.033443
 >> iter 13000, loss: 0.029931
 >> iter 14000, loss: 0.027495
 >> iter 15000, loss: 0.023979
 >> iter 16000, loss: 0.019746
 >> iter 17000, loss: 0.023042
 >> iter 18000, loss: 0.026075
 >> iter 19000, loss: 0.022509
 >> iter 20000, loss: 0.023388
   Number of active neurons: 2
 >> iter 21000, loss: 0.020535
 >> iter 22000, loss: 0.030919
 >> iter 23000, loss: 0.026152
 >> iter 24000, loss: 0.026831
 >> iter 25000, loss: 0.021521
 >> iter 26000, loss: 0.037348
 >> iter 27000, loss: 0.026931
 >> iter 28000, loss: 0.024398
 >> iter 29000, loss: 0.023177
 >> iter 30000, loss: 0.021014
   Number of active neurons: 2
 >> iter 31000, loss: 0.021853
 >> iter 32000, loss: 0.052757
 >> iter 33000, loss: 0.037855
 >> iter 34000, loss: 0.027966
 >> iter 35000, loss: 0.024897
 >> iter 36000, loss: 0.021127
 >> iter 37000, loss: 0.019766
 >> iter 38000, loss: 0.020743
 >> iter 39000, loss: 0.033059
 >> iter 40000, loss: 0.025800
   Number of active neurons: 2
 >> iter 41000, loss: 0.024209
 >> iter 42000, loss: 0.023387
 >> iter 43000, loss: 0.025139
 >> iter 44000, loss: 0.024578
 >> iter 45000, loss: 0.027917
 >> iter 46000, loss: 0.022314
 >> iter 47000, loss: 0.023199
 >> iter 48000, loss: 0.020194
 >> iter 49000, loss: 0.019626
 >> iter 50000, loss: 0.022791
   Number of active neurons: 2
 >> iter 51000, loss: 0.021972
 >> iter 52000, loss: 0.025353
 >> iter 53000, loss: 0.025140
 >> iter 54000, loss: 0.038502
 >> iter 55000, loss: 0.029435
 >> iter 56000, loss: 0.024518
 >> iter 57000, loss: 0.027370
 >> iter 58000, loss: 0.022989
 >> iter 59000, loss: 0.021924
 >> iter 60000, loss: 0.020308
   Number of active neurons: 2
 >> iter 61000, loss: 0.027283
 >> iter 62000, loss: 0.027695
 >> iter 63000, loss: 0.021964
 >> iter 64000, loss: 0.020441
 >> iter 65000, loss: 0.024436
 >> iter 66000, loss: 0.025067
 >> iter 67000, loss: 0.026056
 >> iter 68000, loss: 0.022102
 >> iter 69000, loss: 0.023432
 >> iter 70000, loss: 0.031172
   Number of active neurons: 1
 >> iter 71000, loss: 0.036809
 >> iter 72000, loss: 0.026221
 >> iter 73000, loss: 0.023034
 >> iter 74000, loss: 0.041032
 >> iter 75000, loss: 0.048147
 >> iter 76000, loss: 0.030741
 >> iter 77000, loss: 0.021455
 >> iter 78000, loss: 0.017895
 >> iter 79000, loss: 0.018244
 >> iter 80000, loss: 0.017806
   Number of active neurons: 1
 >> iter 81000, loss: 0.023165
 >> iter 82000, loss: 0.020074
 >> iter 83000, loss: 0.017267
 >> iter 84000, loss: 0.018897
 >> iter 85000, loss: 0.016942
 >> iter 86000, loss: 0.022931
 >> iter 87000, loss: 0.023302
 >> iter 88000, loss: 0.021156
 >> iter 89000, loss: 0.019850
 >> iter 90000, loss: 0.016626
   Number of active neurons: 1
 >> iter 91000, loss: 0.017423
 >> iter 92000, loss: 0.017323
 >> iter 93000, loss: 0.020843
 >> iter 94000, loss: 0.031042
 >> iter 95000, loss: 0.025256
 >> iter 96000, loss: 0.021874
 >> iter 97000, loss: 0.017916
 >> iter 98000, loss: 0.016938
 >> iter 99000, loss: 0.038869
 >> iter 100000, loss: 0.026649
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.862780
 >> iter 2000, loss: 4.030103
 >> iter 3000, loss: 1.506064
 >> iter 4000, loss: 0.577397
 >> iter 5000, loss: 0.226441
 >> iter 6000, loss: 0.098353
 >> iter 7000, loss: 0.057620
 >> iter 8000, loss: 0.040347
 >> iter 9000, loss: 0.031336
 >> iter 10000, loss: 0.025287
   Number of active neurons: 3
 >> iter 11000, loss: 0.025638
 >> iter 12000, loss: 0.025379
 >> iter 13000, loss: 0.025331
 >> iter 14000, loss: 0.022371
 >> iter 15000, loss: 0.023817
 >> iter 16000, loss: 0.028056
 >> iter 17000, loss: 0.027572
 >> iter 18000, loss: 0.027180
 >> iter 19000, loss: 0.027713
 >> iter 20000, loss: 0.029392
   Number of active neurons: 3
 >> iter 21000, loss: 0.027731
 >> iter 22000, loss: 0.035853
 >> iter 23000, loss: 0.028574
 >> iter 24000, loss: 0.027786
 >> iter 25000, loss: 0.024981
 >> iter 26000, loss: 0.037890
 >> iter 27000, loss: 0.047334
 >> iter 28000, loss: 0.038776
 >> iter 29000, loss: 0.029017
 >> iter 30000, loss: 0.027081
   Number of active neurons: 2
 >> iter 31000, loss: 0.024785
 >> iter 32000, loss: 0.021493
 >> iter 33000, loss: 0.021501
 >> iter 34000, loss: 0.031939
 >> iter 35000, loss: 0.023935
 >> iter 36000, loss: 0.022237
 >> iter 37000, loss: 0.022484
 >> iter 38000, loss: 0.028906
 >> iter 39000, loss: 0.026090
 >> iter 40000, loss: 0.024237
   Number of active neurons: 2
 >> iter 41000, loss: 0.030046
 >> iter 42000, loss: 0.023707
 >> iter 43000, loss: 0.021476
 >> iter 44000, loss: 0.020762
 >> iter 45000, loss: 0.025693
 >> iter 46000, loss: 0.024356
 >> iter 47000, loss: 0.028959
 >> iter 48000, loss: 0.027293
 >> iter 49000, loss: 0.025158
 >> iter 50000, loss: 0.033700
   Number of active neurons: 2
 >> iter 51000, loss: 0.027710
 >> iter 52000, loss: 0.022476
 >> iter 53000, loss: 0.021301
 >> iter 54000, loss: 0.023093
 >> iter 55000, loss: 0.025461
 >> iter 56000, loss: 0.024213
 >> iter 57000, loss: 0.027469
 >> iter 58000, loss: 0.025088
 >> iter 59000, loss: 0.023282
 >> iter 60000, loss: 0.033920
   Number of active neurons: 2
 >> iter 61000, loss: 0.036741
 >> iter 62000, loss: 0.025504
 >> iter 63000, loss: 0.022565
 >> iter 64000, loss: 0.032159
 >> iter 65000, loss: 0.026723
 >> iter 66000, loss: 0.031406
 >> iter 67000, loss: 0.024214
 >> iter 68000, loss: 0.028843
 >> iter 69000, loss: 0.024747
 >> iter 70000, loss: 0.022552
   Number of active neurons: 2
 >> iter 71000, loss: 0.021234
 >> iter 72000, loss: 0.021240
 >> iter 73000, loss: 0.024509
 >> iter 74000, loss: 0.021905
 >> iter 75000, loss: 0.023687
 >> iter 76000, loss: 0.026082
 >> iter 77000, loss: 0.021871
 >> iter 78000, loss: 0.018835
 >> iter 79000, loss: 0.026041
 >> iter 80000, loss: 0.020322
   Number of active neurons: 1
 >> iter 81000, loss: 0.018060
 >> iter 82000, loss: 0.056490
 >> iter 83000, loss: 0.037026
 >> iter 84000, loss: 0.025568
 >> iter 85000, loss: 0.028274
 >> iter 86000, loss: 0.021213
 >> iter 87000, loss: 0.018946
 >> iter 88000, loss: 0.029577
 >> iter 89000, loss: 0.024995
 >> iter 90000, loss: 0.020952
   Number of active neurons: 1
 >> iter 91000, loss: 0.021951
 >> iter 92000, loss: 0.019260
 >> iter 93000, loss: 0.017219
 >> iter 94000, loss: 0.022332
 >> iter 95000, loss: 0.020613
 >> iter 96000, loss: 0.017211
 >> iter 97000, loss: 0.026951
 >> iter 98000, loss: 0.020870
 >> iter 99000, loss: 0.018567
 >> iter 100000, loss: 0.022126
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.050740
 >> iter 2000, loss: 4.119056
 >> iter 3000, loss: 1.539146
 >> iter 4000, loss: 0.585882
 >> iter 5000, loss: 0.239424
 >> iter 6000, loss: 0.104983
 >> iter 7000, loss: 0.058108
 >> iter 8000, loss: 0.047483
 >> iter 9000, loss: 0.034654
 >> iter 10000, loss: 0.031620
   Number of active neurons: 5
 >> iter 11000, loss: 0.035804
 >> iter 12000, loss: 0.036712
 >> iter 13000, loss: 0.032908
 >> iter 14000, loss: 0.030970
 >> iter 15000, loss: 0.028101
 >> iter 16000, loss: 0.027452
 >> iter 17000, loss: 0.029355
 >> iter 18000, loss: 0.027259
 >> iter 19000, loss: 0.026475
 >> iter 20000, loss: 0.026493
   Number of active neurons: 4
 >> iter 21000, loss: 0.026015
 >> iter 22000, loss: 0.025143
 >> iter 23000, loss: 0.026959
 >> iter 24000, loss: 0.023690
 >> iter 25000, loss: 0.024678
 >> iter 26000, loss: 0.032245
 >> iter 27000, loss: 0.027489
 >> iter 28000, loss: 0.027235
 >> iter 29000, loss: 0.030648
 >> iter 30000, loss: 0.035235
   Number of active neurons: 3
 >> iter 31000, loss: 0.026114
 >> iter 32000, loss: 0.024115
 >> iter 33000, loss: 0.031085
 >> iter 34000, loss: 0.030529
 >> iter 35000, loss: 0.026255
 >> iter 36000, loss: 0.024886
 >> iter 37000, loss: 0.027598
 >> iter 38000, loss: 0.027844
 >> iter 39000, loss: 0.028661
 >> iter 40000, loss: 0.030162
   Number of active neurons: 3
 >> iter 41000, loss: 0.038220
 >> iter 42000, loss: 0.035044
 >> iter 43000, loss: 0.027567
 >> iter 44000, loss: 0.026540
 >> iter 45000, loss: 0.027082
 >> iter 46000, loss: 0.025446
 >> iter 47000, loss: 0.026310
 >> iter 48000, loss: 0.025107
 >> iter 49000, loss: 0.025225
 >> iter 50000, loss: 0.025013
   Number of active neurons: 3
 >> iter 51000, loss: 0.058522
 >> iter 52000, loss: 0.043082
 >> iter 53000, loss: 0.050635
 >> iter 54000, loss: 0.034424
 >> iter 55000, loss: 0.028308
 >> iter 56000, loss: 0.029823
 >> iter 57000, loss: 0.029083
 >> iter 58000, loss: 0.031520
 >> iter 59000, loss: 0.029335
 >> iter 60000, loss: 0.026074
   Number of active neurons: 3
 >> iter 61000, loss: 0.023588
 >> iter 62000, loss: 0.022811
 >> iter 63000, loss: 0.046488
 >> iter 64000, loss: 0.035764
 >> iter 65000, loss: 0.029125
 >> iter 66000, loss: 0.030822
 >> iter 67000, loss: 0.025197
 >> iter 68000, loss: 0.039905
 >> iter 69000, loss: 0.030430
 >> iter 70000, loss: 0.024725
   Number of active neurons: 2
 >> iter 71000, loss: 0.025775
 >> iter 72000, loss: 0.029958
 >> iter 73000, loss: 0.031904
 >> iter 74000, loss: 0.023644
 >> iter 75000, loss: 0.020208
 >> iter 76000, loss: 0.020312
 >> iter 77000, loss: 0.021630
 >> iter 78000, loss: 0.025117
 >> iter 79000, loss: 0.023787
 >> iter 80000, loss: 0.020630
   Number of active neurons: 2
 >> iter 81000, loss: 0.023877
 >> iter 82000, loss: 0.023060
 >> iter 83000, loss: 0.026193
 >> iter 84000, loss: 0.021439
 >> iter 85000, loss: 0.021049
 >> iter 86000, loss: 0.020067
 >> iter 87000, loss: 0.022221
 >> iter 88000, loss: 0.021121
 >> iter 89000, loss: 0.023385
 >> iter 90000, loss: 0.036780
   Number of active neurons: 2
 >> iter 91000, loss: 0.033021
 >> iter 92000, loss: 0.025580
 >> iter 93000, loss: 0.026288
 >> iter 94000, loss: 0.022732
 >> iter 95000, loss: 0.021730
 >> iter 96000, loss: 0.021384
 >> iter 97000, loss: 0.023100
 >> iter 98000, loss: 0.021059
 >> iter 99000, loss: 0.023495
 >> iter 100000, loss: 0.026986
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.925809
 >> iter 2000, loss: 4.057548
 >> iter 3000, loss: 1.518406
 >> iter 4000, loss: 0.587252
 >> iter 5000, loss: 0.247816
 >> iter 6000, loss: 0.107233
 >> iter 7000, loss: 0.056667
 >> iter 8000, loss: 0.034567
 >> iter 9000, loss: 0.028884
 >> iter 10000, loss: 0.025843
   Number of active neurons: 3
 >> iter 11000, loss: 0.033691
 >> iter 12000, loss: 0.027413
 >> iter 13000, loss: 0.024864
 >> iter 14000, loss: 0.024620
 >> iter 15000, loss: 0.026366
 >> iter 16000, loss: 0.025313
 >> iter 17000, loss: 0.026643
 >> iter 18000, loss: 0.022666
 >> iter 19000, loss: 0.027279
 >> iter 20000, loss: 0.031604
   Number of active neurons: 2
 >> iter 21000, loss: 0.027387
 >> iter 22000, loss: 0.022587
 >> iter 23000, loss: 0.037811
 >> iter 24000, loss: 0.030486
 >> iter 25000, loss: 0.026943
 >> iter 26000, loss: 0.027373
 >> iter 27000, loss: 0.022806
 >> iter 28000, loss: 0.020961
 >> iter 29000, loss: 0.026646
 >> iter 30000, loss: 0.023620
   Number of active neurons: 2
 >> iter 31000, loss: 0.023724
 >> iter 32000, loss: 0.025261
 >> iter 33000, loss: 0.034070
 >> iter 34000, loss: 0.024714
 >> iter 35000, loss: 0.027569
 >> iter 36000, loss: 0.025131
 >> iter 37000, loss: 0.021436
 >> iter 38000, loss: 0.028242
 >> iter 39000, loss: 0.022740
 >> iter 40000, loss: 0.032102
   Number of active neurons: 2
 >> iter 41000, loss: 0.025892
 >> iter 42000, loss: 0.022051
 >> iter 43000, loss: 0.026461
 >> iter 44000, loss: 0.022906
 >> iter 45000, loss: 0.027361
 >> iter 46000, loss: 0.023327
 >> iter 47000, loss: 0.021280
 >> iter 48000, loss: 0.022032
 >> iter 49000, loss: 0.020922
 >> iter 50000, loss: 0.021867
   Number of active neurons: 2
 >> iter 51000, loss: 0.028478
 >> iter 52000, loss: 0.023108
 >> iter 53000, loss: 0.021948
 >> iter 54000, loss: 0.025475
 >> iter 55000, loss: 0.024840
 >> iter 56000, loss: 0.025260
 >> iter 57000, loss: 0.022373
 >> iter 58000, loss: 0.020533
 >> iter 59000, loss: 0.021421
 >> iter 60000, loss: 0.020099
   Number of active neurons: 2
 >> iter 61000, loss: 0.033399
 >> iter 62000, loss: 0.028161
 >> iter 63000, loss: 0.023316
 >> iter 64000, loss: 0.020821
 >> iter 65000, loss: 0.025612
 >> iter 66000, loss: 0.021590
 >> iter 67000, loss: 0.020740
 >> iter 68000, loss: 0.023332
 >> iter 69000, loss: 0.023077
 >> iter 70000, loss: 0.021116
   Number of active neurons: 2
 >> iter 71000, loss: 0.023654
 >> iter 72000, loss: 0.026729
 >> iter 73000, loss: 0.023103
 >> iter 74000, loss: 0.020663
 >> iter 75000, loss: 0.021237
 >> iter 76000, loss: 0.024269
 >> iter 77000, loss: 0.021534
 >> iter 78000, loss: 0.027464
 >> iter 79000, loss: 0.038071
 >> iter 80000, loss: 0.027493
   Number of active neurons: 2
 >> iter 81000, loss: 0.026319
 >> iter 82000, loss: 0.023837
 >> iter 83000, loss: 0.022600
 >> iter 84000, loss: 0.025872
 >> iter 85000, loss: 0.023222
 >> iter 86000, loss: 0.024998
 >> iter 87000, loss: 0.024463
 >> iter 88000, loss: 0.022682
 >> iter 89000, loss: 0.021572
 >> iter 90000, loss: 0.020398
   Number of active neurons: 2
 >> iter 91000, loss: 0.027260
 >> iter 92000, loss: 0.027392
 >> iter 93000, loss: 0.025985
 >> iter 94000, loss: 0.021845
 >> iter 95000, loss: 0.020922
 >> iter 96000, loss: 0.020863
 >> iter 97000, loss: 0.023867
 >> iter 98000, loss: 0.020590
 >> iter 99000, loss: 0.025112
 >> iter 100000, loss: 0.022522
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.992628
 >> iter 2000, loss: 4.085723
 >> iter 3000, loss: 1.528673
 >> iter 4000, loss: 0.580630
 >> iter 5000, loss: 0.252530
 >> iter 6000, loss: 0.113392
 >> iter 7000, loss: 0.062987
 >> iter 8000, loss: 0.042574
 >> iter 9000, loss: 0.031881
 >> iter 10000, loss: 0.029989
   Number of active neurons: 4
 >> iter 11000, loss: 0.035083
 >> iter 12000, loss: 0.031910
 >> iter 13000, loss: 0.027486
 >> iter 14000, loss: 0.034025
 >> iter 15000, loss: 0.029832
 >> iter 16000, loss: 0.032763
 >> iter 17000, loss: 0.028067
 >> iter 18000, loss: 0.036461
 >> iter 19000, loss: 0.031555
 >> iter 20000, loss: 0.028309
   Number of active neurons: 4
 >> iter 21000, loss: 0.028716
 >> iter 22000, loss: 0.025710
 >> iter 23000, loss: 0.024633
 >> iter 24000, loss: 0.029752
 >> iter 25000, loss: 0.027703
 >> iter 26000, loss: 0.031821
 >> iter 27000, loss: 0.029173
 >> iter 28000, loss: 0.031345
 >> iter 29000, loss: 0.044584
 >> iter 30000, loss: 0.030251
   Number of active neurons: 2
 >> iter 31000, loss: 0.025470
 >> iter 32000, loss: 0.022517
 >> iter 33000, loss: 0.031251
 >> iter 34000, loss: 0.032405
 >> iter 35000, loss: 0.024163
 >> iter 36000, loss: 0.022019
 >> iter 37000, loss: 0.038244
 >> iter 38000, loss: 0.028539
 >> iter 39000, loss: 0.025696
 >> iter 40000, loss: 0.021155
   Number of active neurons: 1
 >> iter 41000, loss: 0.025155
 >> iter 42000, loss: 0.027013
 >> iter 43000, loss: 0.028607
 >> iter 44000, loss: 0.025144
 >> iter 45000, loss: 0.024100
 >> iter 46000, loss: 0.021680
 >> iter 47000, loss: 0.033076
 >> iter 48000, loss: 0.021965
 >> iter 49000, loss: 0.024864
 >> iter 50000, loss: 0.031267
   Number of active neurons: 1
 >> iter 51000, loss: 0.024190
 >> iter 52000, loss: 0.019118
 >> iter 53000, loss: 0.020629
 >> iter 54000, loss: 0.017613
 >> iter 55000, loss: 0.026383
 >> iter 56000, loss: 0.025601
 >> iter 57000, loss: 0.021464
 >> iter 58000, loss: 0.019360
 >> iter 59000, loss: 0.017980
 >> iter 60000, loss: 0.019421
   Number of active neurons: 1
 >> iter 61000, loss: 0.040473
 >> iter 62000, loss: 0.029948
 >> iter 63000, loss: 0.021513
 >> iter 64000, loss: 0.020438
 >> iter 65000, loss: 0.020744
 >> iter 66000, loss: 0.021589
 >> iter 67000, loss: 0.025202
 >> iter 68000, loss: 0.021658
 >> iter 69000, loss: 0.022626
 >> iter 70000, loss: 0.023003
   Number of active neurons: 1
 >> iter 71000, loss: 0.018575
 >> iter 72000, loss: 0.018585
 >> iter 73000, loss: 0.036880
 >> iter 74000, loss: 0.023860
 >> iter 75000, loss: 0.018187
 >> iter 76000, loss: 0.017851
 >> iter 77000, loss: 0.017566
 >> iter 78000, loss: 0.021373
 >> iter 79000, loss: 0.021922
 >> iter 80000, loss: 0.020768
   Number of active neurons: 1
 >> iter 81000, loss: 0.021929
 >> iter 82000, loss: 0.025975
 >> iter 83000, loss: 0.021996
 >> iter 84000, loss: 0.018002
 >> iter 85000, loss: 0.019401
 >> iter 86000, loss: 0.025546
 >> iter 87000, loss: 0.022913
 >> iter 88000, loss: 0.019584
 >> iter 89000, loss: 0.020304
 >> iter 90000, loss: 0.018840
   Number of active neurons: 1
 >> iter 91000, loss: 0.030383
 >> iter 92000, loss: 0.023099
 >> iter 93000, loss: 0.022205
 >> iter 94000, loss: 0.020272
 >> iter 95000, loss: 0.018023
 >> iter 96000, loss: 0.019276
 >> iter 97000, loss: 0.021176
 >> iter 98000, loss: 0.021577
 >> iter 99000, loss: 0.019466
 >> iter 100000, loss: 0.017582
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.028941
 >> iter 2000, loss: 4.108333
 >> iter 3000, loss: 1.564222
 >> iter 4000, loss: 0.606978
 >> iter 5000, loss: 0.245731
 >> iter 6000, loss: 0.106710
 >> iter 7000, loss: 0.065576
 >> iter 8000, loss: 0.041320
 >> iter 9000, loss: 0.037702
 >> iter 10000, loss: 0.028480
   Number of active neurons: 3
 >> iter 11000, loss: 0.024996
 >> iter 12000, loss: 0.026597
 >> iter 13000, loss: 0.034884
 >> iter 14000, loss: 0.046739
 >> iter 15000, loss: 0.033831
 >> iter 16000, loss: 0.027575
 >> iter 17000, loss: 0.029132
 >> iter 18000, loss: 0.026569
 >> iter 19000, loss: 0.026605
 >> iter 20000, loss: 0.025063
   Number of active neurons: 3
 >> iter 21000, loss: 0.024276
 >> iter 22000, loss: 0.023152
 >> iter 23000, loss: 0.025979
 >> iter 24000, loss: 0.028380
 >> iter 25000, loss: 0.034827
 >> iter 26000, loss: 0.028216
 >> iter 27000, loss: 0.024144
 >> iter 28000, loss: 0.023561
 >> iter 29000, loss: 0.025322
 >> iter 30000, loss: 0.022914
   Number of active neurons: 2
 >> iter 31000, loss: 0.022873
 >> iter 32000, loss: 0.019030
 >> iter 33000, loss: 0.024860
 >> iter 34000, loss: 0.029293
 >> iter 35000, loss: 0.025397
 >> iter 36000, loss: 0.022288
 >> iter 37000, loss: 0.021885
 >> iter 38000, loss: 0.021443
 >> iter 39000, loss: 0.022202
 >> iter 40000, loss: 0.021462
   Number of active neurons: 2
 >> iter 41000, loss: 0.026116
 >> iter 42000, loss: 0.023177
 >> iter 43000, loss: 0.024924
 >> iter 44000, loss: 0.033324
 >> iter 45000, loss: 0.025858
 >> iter 46000, loss: 0.022180
 >> iter 47000, loss: 0.020708
 >> iter 48000, loss: 0.026615
 >> iter 49000, loss: 0.024251
 >> iter 50000, loss: 0.019965
   Number of active neurons: 2
 >> iter 51000, loss: 0.019025
 >> iter 52000, loss: 0.021224
 >> iter 53000, loss: 0.020928
 >> iter 54000, loss: 0.020279
 >> iter 55000, loss: 0.021390
 >> iter 56000, loss: 0.025509
 >> iter 57000, loss: 0.024873
 >> iter 58000, loss: 0.021849
 >> iter 59000, loss: 0.020642
 >> iter 60000, loss: 0.022482
   Number of active neurons: 2
 >> iter 61000, loss: 0.022227
 >> iter 62000, loss: 0.025784
 >> iter 63000, loss: 0.024408
 >> iter 64000, loss: 0.024775
 >> iter 65000, loss: 0.032733
 >> iter 66000, loss: 0.027487
 >> iter 67000, loss: 0.022000
 >> iter 68000, loss: 0.023262
 >> iter 69000, loss: 0.020694
 >> iter 70000, loss: 0.021903
   Number of active neurons: 2
 >> iter 71000, loss: 0.019610
 >> iter 72000, loss: 0.020164
 >> iter 73000, loss: 0.021082
 >> iter 74000, loss: 0.022290
 >> iter 75000, loss: 0.021501
 >> iter 76000, loss: 0.022661
 >> iter 77000, loss: 0.030293
 >> iter 78000, loss: 0.025888
 >> iter 79000, loss: 0.021703
 >> iter 80000, loss: 0.020560
   Number of active neurons: 2
 >> iter 81000, loss: 0.030582
 >> iter 82000, loss: 0.024147
 >> iter 83000, loss: 0.027985
 >> iter 84000, loss: 0.030372
 >> iter 85000, loss: 0.023943
 >> iter 86000, loss: 0.022348
 >> iter 87000, loss: 0.023006
 >> iter 88000, loss: 0.025676
 >> iter 89000, loss: 0.020918
 >> iter 90000, loss: 0.030868
   Number of active neurons: 2
 >> iter 91000, loss: 0.025137
 >> iter 92000, loss: 0.021717
 >> iter 93000, loss: 0.035357
 >> iter 94000, loss: 0.026924
 >> iter 95000, loss: 0.022088
 >> iter 96000, loss: 0.023699
 >> iter 97000, loss: 0.024204
 >> iter 98000, loss: 0.020835
 >> iter 99000, loss: 0.020035
 >> iter 100000, loss: 0.021688
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

