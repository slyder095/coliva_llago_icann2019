 > Problema: tomita1nueva
 > Args:
   - Hidden size: 14
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 10.902328
 >> iter 2000, loss: 4.063161
 >> iter 3000, loss: 1.522015
 >> iter 4000, loss: 0.581197
 >> iter 5000, loss: 0.240210
 >> iter 6000, loss: 0.110622
 >> iter 7000, loss: 0.075767
 >> iter 8000, loss: 0.048814
 >> iter 9000, loss: 0.039465
 >> iter 10000, loss: 0.032080
   Number of active neurons: 5
 >> iter 11000, loss: 0.033385
 >> iter 12000, loss: 0.036593
 >> iter 13000, loss: 0.046098
 >> iter 14000, loss: 0.033517
 >> iter 15000, loss: 0.030883
 >> iter 16000, loss: 0.033926
 >> iter 17000, loss: 0.027496
 >> iter 18000, loss: 0.027433
 >> iter 19000, loss: 0.029231
 >> iter 20000, loss: 0.028791
   Number of active neurons: 4
 >> iter 21000, loss: 0.025990
 >> iter 22000, loss: 0.026924
 >> iter 23000, loss: 0.030052
 >> iter 24000, loss: 0.028369
 >> iter 25000, loss: 0.026169
 >> iter 26000, loss: 0.028680
 >> iter 27000, loss: 0.028786
 >> iter 28000, loss: 0.024849
 >> iter 29000, loss: 0.025558
 >> iter 30000, loss: 0.025046
   Number of active neurons: 4
 >> iter 31000, loss: 0.025466
 >> iter 32000, loss: 0.028999
 >> iter 33000, loss: 0.024908
 >> iter 34000, loss: 0.024533
 >> iter 35000, loss: 0.040218
 >> iter 36000, loss: 0.028552
 >> iter 37000, loss: 0.025956
 >> iter 38000, loss: 0.022721
 >> iter 39000, loss: 0.023320
 >> iter 40000, loss: 0.025672
   Number of active neurons: 3
 >> iter 41000, loss: 0.029412
 >> iter 42000, loss: 0.027242
 >> iter 43000, loss: 0.025028
 >> iter 44000, loss: 0.021687
 >> iter 45000, loss: 0.030436
 >> iter 46000, loss: 0.037775
 >> iter 47000, loss: 0.035147
 >> iter 48000, loss: 0.026305
 >> iter 49000, loss: 0.030226
 >> iter 50000, loss: 0.027472
   Number of active neurons: 3
 >> iter 51000, loss: 0.041354
 >> iter 52000, loss: 0.030899
 >> iter 53000, loss: 0.025710
 >> iter 54000, loss: 0.030783
 >> iter 55000, loss: 0.024596
 >> iter 56000, loss: 0.025395
 >> iter 57000, loss: 0.028311
 >> iter 58000, loss: 0.026611
 >> iter 59000, loss: 0.023908
 >> iter 60000, loss: 0.029457
   Number of active neurons: 3
 >> iter 61000, loss: 0.025388
 >> iter 62000, loss: 0.028839
 >> iter 63000, loss: 0.026310
 >> iter 64000, loss: 0.025772
 >> iter 65000, loss: 0.028734
 >> iter 66000, loss: 0.024679
 >> iter 67000, loss: 0.023478
 >> iter 68000, loss: 0.023791
 >> iter 69000, loss: 0.035674
 >> iter 70000, loss: 0.026819
   Number of active neurons: 2
 >> iter 71000, loss: 0.023264
 >> iter 72000, loss: 0.033605
 >> iter 73000, loss: 0.039335
 >> iter 74000, loss: 0.034191
 >> iter 75000, loss: 0.027859
 >> iter 76000, loss: 0.023792
 >> iter 77000, loss: 0.026356
 >> iter 78000, loss: 0.038289
 >> iter 79000, loss: 0.027282
 >> iter 80000, loss: 0.023317
   Number of active neurons: 2
 >> iter 81000, loss: 0.022545
 >> iter 82000, loss: 0.027269
 >> iter 83000, loss: 0.030023
 >> iter 84000, loss: 0.037766
 >> iter 85000, loss: 0.036833
 >> iter 86000, loss: 0.027522
 >> iter 87000, loss: 0.037585
 >> iter 88000, loss: 0.027198
 >> iter 89000, loss: 0.023030
 >> iter 90000, loss: 0.021569
   Number of active neurons: 2
 >> iter 91000, loss: 0.022236
 >> iter 92000, loss: 0.021305
 >> iter 93000, loss: 0.027266
 >> iter 94000, loss: 0.037777
 >> iter 95000, loss: 0.048602
 >> iter 96000, loss: 0.034966
 >> iter 97000, loss: 0.024915
 >> iter 98000, loss: 0.023596
 >> iter 99000, loss: 0.023108
 >> iter 100000, loss: 0.024068
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.931402
 >> iter 2000, loss: 4.065079
 >> iter 3000, loss: 1.529929
 >> iter 4000, loss: 0.586885
 >> iter 5000, loss: 0.240035
 >> iter 6000, loss: 0.109436
 >> iter 7000, loss: 0.062593
 >> iter 8000, loss: 0.048906
 >> iter 9000, loss: 0.035622
 >> iter 10000, loss: 0.034965
   Number of active neurons: 4
 >> iter 11000, loss: 0.036553
 >> iter 12000, loss: 0.029893
 >> iter 13000, loss: 0.026318
 >> iter 14000, loss: 0.026887
 >> iter 15000, loss: 0.026815
 >> iter 16000, loss: 0.031524
 >> iter 17000, loss: 0.032978
 >> iter 18000, loss: 0.030453
 >> iter 19000, loss: 0.029879
 >> iter 20000, loss: 0.031398
   Number of active neurons: 3
 >> iter 21000, loss: 0.029410
 >> iter 22000, loss: 0.027434
 >> iter 23000, loss: 0.027660
 >> iter 24000, loss: 0.024530
 >> iter 25000, loss: 0.027842
 >> iter 26000, loss: 0.031459
 >> iter 27000, loss: 0.028492
 >> iter 28000, loss: 0.026183
 >> iter 29000, loss: 0.026592
 >> iter 30000, loss: 0.025220
   Number of active neurons: 3
 >> iter 31000, loss: 0.025581
 >> iter 32000, loss: 0.034137
 >> iter 33000, loss: 0.027526
 >> iter 34000, loss: 0.026051
 >> iter 35000, loss: 0.027645
 >> iter 36000, loss: 0.031447
 >> iter 37000, loss: 0.027613
 >> iter 38000, loss: 0.025321
 >> iter 39000, loss: 0.023327
 >> iter 40000, loss: 0.020620
   Number of active neurons: 2
 >> iter 41000, loss: 0.019613
 >> iter 42000, loss: 0.022195
 >> iter 43000, loss: 0.025423
 >> iter 44000, loss: 0.034431
 >> iter 45000, loss: 0.028191
 >> iter 46000, loss: 0.036544
 >> iter 47000, loss: 0.031002
 >> iter 48000, loss: 0.023594
 >> iter 49000, loss: 0.029002
 >> iter 50000, loss: 0.029727
   Number of active neurons: 2
 >> iter 51000, loss: 0.027677
 >> iter 52000, loss: 0.021998
 >> iter 53000, loss: 0.023457
 >> iter 54000, loss: 0.023059
 >> iter 55000, loss: 0.023939
 >> iter 56000, loss: 0.043965
 >> iter 57000, loss: 0.027811
 >> iter 58000, loss: 0.021271
 >> iter 59000, loss: 0.019324
 >> iter 60000, loss: 0.017736
   Number of active neurons: 1
 >> iter 61000, loss: 0.018740
 >> iter 62000, loss: 0.017903
 >> iter 63000, loss: 0.016380
 >> iter 64000, loss: 0.017705
 >> iter 65000, loss: 0.029006
 >> iter 66000, loss: 0.028114
 >> iter 67000, loss: 0.020366
 >> iter 68000, loss: 0.025852
 >> iter 69000, loss: 0.021930
 >> iter 70000, loss: 0.025292
   Number of active neurons: 1
 >> iter 71000, loss: 0.032273
 >> iter 72000, loss: 0.022437
 >> iter 73000, loss: 0.020509
 >> iter 74000, loss: 0.019476
 >> iter 75000, loss: 0.017756
 >> iter 76000, loss: 0.017389
 >> iter 77000, loss: 0.033420
 >> iter 78000, loss: 0.022374
 >> iter 79000, loss: 0.023134
 >> iter 80000, loss: 0.018708
   Number of active neurons: 1
 >> iter 81000, loss: 0.026492
 >> iter 82000, loss: 0.035125
 >> iter 83000, loss: 0.027175
 >> iter 84000, loss: 0.034465
 >> iter 85000, loss: 0.026439
 >> iter 86000, loss: 0.022721
 >> iter 87000, loss: 0.018738
 >> iter 88000, loss: 0.023565
 >> iter 89000, loss: 0.023577
 >> iter 90000, loss: 0.019962
   Number of active neurons: 1
 >> iter 91000, loss: 0.017779
 >> iter 92000, loss: 0.017074
 >> iter 93000, loss: 0.020120
 >> iter 94000, loss: 0.030867
 >> iter 95000, loss: 0.023147
 >> iter 96000, loss: 0.023278
 >> iter 97000, loss: 0.029233
 >> iter 98000, loss: 0.040345
 >> iter 99000, loss: 0.039890
 >> iter 100000, loss: 0.026299
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.930390
 >> iter 2000, loss: 4.073998
 >> iter 3000, loss: 1.551318
 >> iter 4000, loss: 0.594184
 >> iter 5000, loss: 0.239547
 >> iter 6000, loss: 0.108144
 >> iter 7000, loss: 0.056999
 >> iter 8000, loss: 0.053045
 >> iter 9000, loss: 0.039880
 >> iter 10000, loss: 0.032040
   Number of active neurons: 4
 >> iter 11000, loss: 0.034770
 >> iter 12000, loss: 0.027063
 >> iter 13000, loss: 0.025773
 >> iter 14000, loss: 0.029359
 >> iter 15000, loss: 0.026381
 >> iter 16000, loss: 0.025569
 >> iter 17000, loss: 0.040915
 >> iter 18000, loss: 0.032842
 >> iter 19000, loss: 0.027165
 >> iter 20000, loss: 0.034694
   Number of active neurons: 3
 >> iter 21000, loss: 0.026829
 >> iter 22000, loss: 0.023983
 >> iter 23000, loss: 0.023703
 >> iter 24000, loss: 0.023166
 >> iter 25000, loss: 0.025288
 >> iter 26000, loss: 0.027467
 >> iter 27000, loss: 0.025708
 >> iter 28000, loss: 0.028078
 >> iter 29000, loss: 0.024856
 >> iter 30000, loss: 0.022317
   Number of active neurons: 3
 >> iter 31000, loss: 0.031346
 >> iter 32000, loss: 0.027558
 >> iter 33000, loss: 0.023785
 >> iter 34000, loss: 0.024164
 >> iter 35000, loss: 0.027169
 >> iter 36000, loss: 0.027035
 >> iter 37000, loss: 0.023750
 >> iter 38000, loss: 0.026221
 >> iter 39000, loss: 0.023590
 >> iter 40000, loss: 0.023295
   Number of active neurons: 3
 >> iter 41000, loss: 0.027334
 >> iter 42000, loss: 0.025980
 >> iter 43000, loss: 0.024047
 >> iter 44000, loss: 0.027126
 >> iter 45000, loss: 0.028120
 >> iter 46000, loss: 0.025001
 >> iter 47000, loss: 0.042660
 >> iter 48000, loss: 0.037622
 >> iter 49000, loss: 0.028896
 >> iter 50000, loss: 0.025822
   Number of active neurons: 3
 >> iter 51000, loss: 0.023673
 >> iter 52000, loss: 0.025568
 >> iter 53000, loss: 0.024927
 >> iter 54000, loss: 0.029543
 >> iter 55000, loss: 0.032595
 >> iter 56000, loss: 0.025364
 >> iter 57000, loss: 0.024460
 >> iter 58000, loss: 0.027189
 >> iter 59000, loss: 0.032030
 >> iter 60000, loss: 0.043980
   Number of active neurons: 3
 >> iter 61000, loss: 0.030703
 >> iter 62000, loss: 0.049034
 >> iter 63000, loss: 0.059812
 >> iter 64000, loss: 0.036408
 >> iter 65000, loss: 0.032918
 >> iter 66000, loss: 0.026529
 >> iter 67000, loss: 0.026662
 >> iter 68000, loss: 0.023368
 >> iter 69000, loss: 0.025980
 >> iter 70000, loss: 0.025309
   Number of active neurons: 2
 >> iter 71000, loss: 0.037998
 >> iter 72000, loss: 0.027154
 >> iter 73000, loss: 0.024533
 >> iter 74000, loss: 0.022203
 >> iter 75000, loss: 0.040025
 >> iter 76000, loss: 0.030067
 >> iter 77000, loss: 0.024316
 >> iter 78000, loss: 0.037773
 >> iter 79000, loss: 0.031131
 >> iter 80000, loss: 0.024407
   Number of active neurons: 2
 >> iter 81000, loss: 0.023644
 >> iter 82000, loss: 0.026388
 >> iter 83000, loss: 0.023085
 >> iter 84000, loss: 0.021131
 >> iter 85000, loss: 0.035837
 >> iter 86000, loss: 0.026337
 >> iter 87000, loss: 0.023253
 >> iter 88000, loss: 0.021084
 >> iter 89000, loss: 0.023163
 >> iter 90000, loss: 0.021632
   Number of active neurons: 2
 >> iter 91000, loss: 0.020357
 >> iter 92000, loss: 0.019038
 >> iter 93000, loss: 0.038805
 >> iter 94000, loss: 0.027256
 >> iter 95000, loss: 0.022562
 >> iter 96000, loss: 0.026012
 >> iter 97000, loss: 0.025022
 >> iter 98000, loss: 0.022653
 >> iter 99000, loss: 0.025496
 >> iter 100000, loss: 0.026219
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.949383
 >> iter 2000, loss: 4.067448
 >> iter 3000, loss: 1.526108
 >> iter 4000, loss: 0.584682
 >> iter 5000, loss: 0.243587
 >> iter 6000, loss: 0.110907
 >> iter 7000, loss: 0.060681
 >> iter 8000, loss: 0.048231
 >> iter 9000, loss: 0.036920
 >> iter 10000, loss: 0.032645
   Number of active neurons: 5
 >> iter 11000, loss: 0.030012
 >> iter 12000, loss: 0.030139
 >> iter 13000, loss: 0.030012
 >> iter 14000, loss: 0.029167
 >> iter 15000, loss: 0.028531
 >> iter 16000, loss: 0.026796
 >> iter 17000, loss: 0.028025
 >> iter 18000, loss: 0.032960
 >> iter 19000, loss: 0.032815
 >> iter 20000, loss: 0.031604
   Number of active neurons: 4
 >> iter 21000, loss: 0.029169
 >> iter 22000, loss: 0.028476
 >> iter 23000, loss: 0.028554
 >> iter 24000, loss: 0.027938
 >> iter 25000, loss: 0.025140
 >> iter 26000, loss: 0.026028
 >> iter 27000, loss: 0.026016
 >> iter 28000, loss: 0.031963
 >> iter 29000, loss: 0.026953
 >> iter 30000, loss: 0.026062
   Number of active neurons: 3
 >> iter 31000, loss: 0.026103
 >> iter 32000, loss: 0.024769
 >> iter 33000, loss: 0.027128
 >> iter 34000, loss: 0.029476
 >> iter 35000, loss: 0.035756
 >> iter 36000, loss: 0.027109
 >> iter 37000, loss: 0.025812
 >> iter 38000, loss: 0.024520
 >> iter 39000, loss: 0.024535
 >> iter 40000, loss: 0.032371
   Number of active neurons: 3
 >> iter 41000, loss: 0.039785
 >> iter 42000, loss: 0.030513
 >> iter 43000, loss: 0.024873
 >> iter 44000, loss: 0.027683
 >> iter 45000, loss: 0.025397
 >> iter 46000, loss: 0.023755
 >> iter 47000, loss: 0.029792
 >> iter 48000, loss: 0.026748
 >> iter 49000, loss: 0.036463
 >> iter 50000, loss: 0.028242
   Number of active neurons: 2
 >> iter 51000, loss: 0.025753
 >> iter 52000, loss: 0.022080
 >> iter 53000, loss: 0.021045
 >> iter 54000, loss: 0.025467
 >> iter 55000, loss: 0.023709
 >> iter 56000, loss: 0.020479
 >> iter 57000, loss: 0.035758
 >> iter 58000, loss: 0.030747
 >> iter 59000, loss: 0.026848
 >> iter 60000, loss: 0.025700
   Number of active neurons: 2
 >> iter 61000, loss: 0.021898
 >> iter 62000, loss: 0.022825
 >> iter 63000, loss: 0.021419
 >> iter 64000, loss: 0.021537
 >> iter 65000, loss: 0.020929
 >> iter 66000, loss: 0.023842
 >> iter 67000, loss: 0.020382
 >> iter 68000, loss: 0.021204
 >> iter 69000, loss: 0.027570
 >> iter 70000, loss: 0.022686
   Number of active neurons: 2
 >> iter 71000, loss: 0.024669
 >> iter 72000, loss: 0.029574
 >> iter 73000, loss: 0.027088
 >> iter 74000, loss: 0.033229
 >> iter 75000, loss: 0.026019
 >> iter 76000, loss: 0.028316
 >> iter 77000, loss: 0.023643
 >> iter 78000, loss: 0.030723
 >> iter 79000, loss: 0.026093
 >> iter 80000, loss: 0.024574
   Number of active neurons: 2
 >> iter 81000, loss: 0.021967
 >> iter 82000, loss: 0.024197
 >> iter 83000, loss: 0.022152
 >> iter 84000, loss: 0.021771
 >> iter 85000, loss: 0.021005
 >> iter 86000, loss: 0.020896
 >> iter 87000, loss: 0.024889
 >> iter 88000, loss: 0.020493
 >> iter 89000, loss: 0.020492
 >> iter 90000, loss: 0.020272
   Number of active neurons: 2
 >> iter 91000, loss: 0.024595
 >> iter 92000, loss: 0.030735
 >> iter 93000, loss: 0.029508
 >> iter 94000, loss: 0.024910
 >> iter 95000, loss: 0.024777
 >> iter 96000, loss: 0.021089
 >> iter 97000, loss: 0.022479
 >> iter 98000, loss: 0.021664
 >> iter 99000, loss: 0.025670
 >> iter 100000, loss: 0.022338
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.954721
 >> iter 2000, loss: 4.088993
 >> iter 3000, loss: 1.530073
 >> iter 4000, loss: 0.586290
 >> iter 5000, loss: 0.239953
 >> iter 6000, loss: 0.122808
 >> iter 7000, loss: 0.066827
 >> iter 8000, loss: 0.047915
 >> iter 9000, loss: 0.037799
 >> iter 10000, loss: 0.032366
   Number of active neurons: 5
 >> iter 11000, loss: 0.048262
 >> iter 12000, loss: 0.038586
 >> iter 13000, loss: 0.030652
 >> iter 14000, loss: 0.030679
 >> iter 15000, loss: 0.038481
 >> iter 16000, loss: 0.031497
 >> iter 17000, loss: 0.028274
 >> iter 18000, loss: 0.028132
 >> iter 19000, loss: 0.031348
 >> iter 20000, loss: 0.026508
   Number of active neurons: 4
 >> iter 21000, loss: 0.024149
 >> iter 22000, loss: 0.034416
 >> iter 23000, loss: 0.032561
 >> iter 24000, loss: 0.026807
 >> iter 25000, loss: 0.028059
 >> iter 26000, loss: 0.025722
 >> iter 27000, loss: 0.023455
 >> iter 28000, loss: 0.023979
 >> iter 29000, loss: 0.023705
 >> iter 30000, loss: 0.029803
   Number of active neurons: 2
 >> iter 31000, loss: 0.027749
 >> iter 32000, loss: 0.022052
 >> iter 33000, loss: 0.021924
 >> iter 34000, loss: 0.020116
 >> iter 35000, loss: 0.018835
 >> iter 36000, loss: 0.029264
 >> iter 37000, loss: 0.024529
 >> iter 38000, loss: 0.020430
 >> iter 39000, loss: 0.055551
 >> iter 40000, loss: 0.033785
   Number of active neurons: 2
 >> iter 41000, loss: 0.026718
 >> iter 42000, loss: 0.023388
 >> iter 43000, loss: 0.022489
 >> iter 44000, loss: 0.021252
 >> iter 45000, loss: 0.030084
 >> iter 46000, loss: 0.036861
 >> iter 47000, loss: 0.071618
 >> iter 48000, loss: 0.038568
 >> iter 49000, loss: 0.028402
 >> iter 50000, loss: 0.024492
   Number of active neurons: 2
 >> iter 51000, loss: 0.025594
 >> iter 52000, loss: 0.021087
 >> iter 53000, loss: 0.023087
 >> iter 54000, loss: 0.021024
 >> iter 55000, loss: 0.022255
 >> iter 56000, loss: 0.021165
 >> iter 57000, loss: 0.026145
 >> iter 58000, loss: 0.026728
 >> iter 59000, loss: 0.021756
 >> iter 60000, loss: 0.038898
   Number of active neurons: 2
 >> iter 61000, loss: 0.028718
 >> iter 62000, loss: 0.024309
 >> iter 63000, loss: 0.025681
 >> iter 64000, loss: 0.023179
 >> iter 65000, loss: 0.024248
 >> iter 66000, loss: 0.021562
 >> iter 67000, loss: 0.021394
 >> iter 68000, loss: 0.036396
 >> iter 69000, loss: 0.028014
 >> iter 70000, loss: 0.022904
   Number of active neurons: 2
 >> iter 71000, loss: 0.030684
 >> iter 72000, loss: 0.023426
 >> iter 73000, loss: 0.024778
 >> iter 74000, loss: 0.023056
 >> iter 75000, loss: 0.024505
 >> iter 76000, loss: 0.021139
 >> iter 77000, loss: 0.020606
 >> iter 78000, loss: 0.026732
 >> iter 79000, loss: 0.029018
 >> iter 80000, loss: 0.029048
   Number of active neurons: 2
 >> iter 81000, loss: 0.027014
 >> iter 82000, loss: 0.023490
 >> iter 83000, loss: 0.021092
 >> iter 84000, loss: 0.022013
 >> iter 85000, loss: 0.031869
 >> iter 86000, loss: 0.053054
 >> iter 87000, loss: 0.042257
 >> iter 88000, loss: 0.029421
 >> iter 89000, loss: 0.056401
 >> iter 90000, loss: 0.039701
   Number of active neurons: 2
 >> iter 91000, loss: 0.035664
 >> iter 92000, loss: 0.026461
 >> iter 93000, loss: 0.024743
 >> iter 94000, loss: 0.031327
 >> iter 95000, loss: 0.025822
 >> iter 96000, loss: 0.023827
 >> iter 97000, loss: 0.028000
 >> iter 98000, loss: 0.022719
 >> iter 99000, loss: 0.020710
 >> iter 100000, loss: 0.028519
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.909000
 >> iter 2000, loss: 4.063529
 >> iter 3000, loss: 1.518459
 >> iter 4000, loss: 0.584000
 >> iter 5000, loss: 0.251785
 >> iter 6000, loss: 0.113067
 >> iter 7000, loss: 0.062693
 >> iter 8000, loss: 0.044608
 >> iter 9000, loss: 0.039382
 >> iter 10000, loss: 0.030775
   Number of active neurons: 4
 >> iter 11000, loss: 0.026899
 >> iter 12000, loss: 0.032788
 >> iter 13000, loss: 0.028781
 >> iter 14000, loss: 0.025964
 >> iter 15000, loss: 0.029003
 >> iter 16000, loss: 0.025174
 >> iter 17000, loss: 0.024189
 >> iter 18000, loss: 0.025390
 >> iter 19000, loss: 0.031205
 >> iter 20000, loss: 0.026326
   Number of active neurons: 3
 >> iter 21000, loss: 0.034566
 >> iter 22000, loss: 0.028057
 >> iter 23000, loss: 0.027238
 >> iter 24000, loss: 0.028217
 >> iter 25000, loss: 0.025770
 >> iter 26000, loss: 0.029400
 >> iter 27000, loss: 0.025201
 >> iter 28000, loss: 0.025888
 >> iter 29000, loss: 0.024401
 >> iter 30000, loss: 0.025185
   Number of active neurons: 3
 >> iter 31000, loss: 0.028317
 >> iter 32000, loss: 0.026149
 >> iter 33000, loss: 0.029032
 >> iter 34000, loss: 0.025838
 >> iter 35000, loss: 0.024936
 >> iter 36000, loss: 0.022800
 >> iter 37000, loss: 0.025553
 >> iter 38000, loss: 0.026094
 >> iter 39000, loss: 0.024123
 >> iter 40000, loss: 0.020883
   Number of active neurons: 2
 >> iter 41000, loss: 0.031993
 >> iter 42000, loss: 0.038200
 >> iter 43000, loss: 0.028943
 >> iter 44000, loss: 0.026325
 >> iter 45000, loss: 0.027527
 >> iter 46000, loss: 0.025969
 >> iter 47000, loss: 0.023479
 >> iter 48000, loss: 0.023974
 >> iter 49000, loss: 0.022226
 >> iter 50000, loss: 0.027393
   Number of active neurons: 2
 >> iter 51000, loss: 0.023115
 >> iter 52000, loss: 0.023372
 >> iter 53000, loss: 0.033401
 >> iter 54000, loss: 0.025861
 >> iter 55000, loss: 0.027384
 >> iter 56000, loss: 0.027592
 >> iter 57000, loss: 0.023385
 >> iter 58000, loss: 0.021017
 >> iter 59000, loss: 0.020813
 >> iter 60000, loss: 0.025280
   Number of active neurons: 2
 >> iter 61000, loss: 0.025995
 >> iter 62000, loss: 0.031740
 >> iter 63000, loss: 0.023446
 >> iter 64000, loss: 0.024680
 >> iter 65000, loss: 0.022868
 >> iter 66000, loss: 0.021196
 >> iter 67000, loss: 0.021539
 >> iter 68000, loss: 0.019154
 >> iter 69000, loss: 0.020989
 >> iter 70000, loss: 0.031068
   Number of active neurons: 1
 >> iter 71000, loss: 0.023794
 >> iter 72000, loss: 0.021109
 >> iter 73000, loss: 0.038718
 >> iter 74000, loss: 0.025225
 >> iter 75000, loss: 0.024576
 >> iter 76000, loss: 0.018482
 >> iter 77000, loss: 0.017639
 >> iter 78000, loss: 0.018165
 >> iter 79000, loss: 0.031451
 >> iter 80000, loss: 0.023599
   Number of active neurons: 1
 >> iter 81000, loss: 0.028311
 >> iter 82000, loss: 0.019974
 >> iter 83000, loss: 0.019389
 >> iter 84000, loss: 0.017633
 >> iter 85000, loss: 0.017035
 >> iter 86000, loss: 0.018377
 >> iter 87000, loss: 0.016606
 >> iter 88000, loss: 0.033635
 >> iter 89000, loss: 0.029429
 >> iter 90000, loss: 0.026601
   Number of active neurons: 1
 >> iter 91000, loss: 0.020415
 >> iter 92000, loss: 0.018092
 >> iter 93000, loss: 0.017814
 >> iter 94000, loss: 0.019233
 >> iter 95000, loss: 0.031250
 >> iter 96000, loss: 0.022016
 >> iter 97000, loss: 0.020975
 >> iter 98000, loss: 0.021854
 >> iter 99000, loss: 0.019684
 >> iter 100000, loss: 0.020667
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 10.884777
 >> iter 2000, loss: 4.069482
 >> iter 3000, loss: 1.542343
 >> iter 4000, loss: 0.584442
 >> iter 5000, loss: 0.237715
 >> iter 6000, loss: 0.111638
 >> iter 7000, loss: 0.062256
 >> iter 8000, loss: 0.041589
 >> iter 9000, loss: 0.032923
 >> iter 10000, loss: 0.031357
   Number of active neurons: 5
 >> iter 11000, loss: 0.031171
 >> iter 12000, loss: 0.030743
 >> iter 13000, loss: 0.037657
 >> iter 14000, loss: 0.036927
 >> iter 15000, loss: 0.044393
 >> iter 16000, loss: 0.035781
 >> iter 17000, loss: 0.030713
 >> iter 18000, loss: 0.030797
 >> iter 19000, loss: 0.031822
 >> iter 20000, loss: 0.030875
   Number of active neurons: 4
 >> iter 21000, loss: 0.029346
 >> iter 22000, loss: 0.025610
 >> iter 23000, loss: 0.025429
 >> iter 24000, loss: 0.026559
 >> iter 25000, loss: 0.029655
 >> iter 26000, loss: 0.035141
 >> iter 27000, loss: 0.047906
 >> iter 28000, loss: 0.032899
 >> iter 29000, loss: 0.026341
 >> iter 30000, loss: 0.059139
   Number of active neurons: 2
 >> iter 31000, loss: 0.035530
 >> iter 32000, loss: 0.026631
 >> iter 33000, loss: 0.023851
 >> iter 34000, loss: 0.022975
 >> iter 35000, loss: 0.050189
 >> iter 36000, loss: 0.036476
 >> iter 37000, loss: 0.030730
 >> iter 38000, loss: 0.024234
 >> iter 39000, loss: 0.021894
 >> iter 40000, loss: 0.021763
   Number of active neurons: 2
 >> iter 41000, loss: 0.031019
 >> iter 42000, loss: 0.032984
 >> iter 43000, loss: 0.028828
 >> iter 44000, loss: 0.028185
 >> iter 45000, loss: 0.023172
 >> iter 46000, loss: 0.020459
 >> iter 47000, loss: 0.027055
 >> iter 48000, loss: 0.023658
 >> iter 49000, loss: 0.023547
 >> iter 50000, loss: 0.021322
   Number of active neurons: 1
 >> iter 51000, loss: 0.022860
 >> iter 52000, loss: 0.019767
 >> iter 53000, loss: 0.019286
 >> iter 54000, loss: 0.022024
 >> iter 55000, loss: 0.020480
 >> iter 56000, loss: 0.022894
 >> iter 57000, loss: 0.020828
 >> iter 58000, loss: 0.020268
 >> iter 59000, loss: 0.017728
 >> iter 60000, loss: 0.024923
   Number of active neurons: 1
 >> iter 61000, loss: 0.024712
 >> iter 62000, loss: 0.027090
 >> iter 63000, loss: 0.022349
 >> iter 64000, loss: 0.021306
 >> iter 65000, loss: 0.018474
 >> iter 66000, loss: 0.021072
 >> iter 67000, loss: 0.024477
 >> iter 68000, loss: 0.019859
 >> iter 69000, loss: 0.024447
 >> iter 70000, loss: 0.018209
   Number of active neurons: 1
 >> iter 71000, loss: 0.019501
 >> iter 72000, loss: 0.017085
 >> iter 73000, loss: 0.027048
 >> iter 74000, loss: 0.042068
 >> iter 75000, loss: 0.027022
 >> iter 76000, loss: 0.027780
 >> iter 77000, loss: 0.020983
 >> iter 78000, loss: 0.018456
 >> iter 79000, loss: 0.016192
 >> iter 80000, loss: 0.017608
   Number of active neurons: 1
 >> iter 81000, loss: 0.019686
 >> iter 82000, loss: 0.029436
 >> iter 83000, loss: 0.020903
 >> iter 84000, loss: 0.017860
 >> iter 85000, loss: 0.018024
 >> iter 86000, loss: 0.018493
 >> iter 87000, loss: 0.017293
 >> iter 88000, loss: 0.019626
 >> iter 89000, loss: 0.022079
 >> iter 90000, loss: 0.026260
   Number of active neurons: 1
 >> iter 91000, loss: 0.022226
 >> iter 92000, loss: 0.031175
 >> iter 93000, loss: 0.022835
 >> iter 94000, loss: 0.025986
 >> iter 95000, loss: 0.020688
 >> iter 96000, loss: 0.017544
 >> iter 97000, loss: 0.018854
 >> iter 98000, loss: 0.016372
 >> iter 99000, loss: 0.017629
 >> iter 100000, loss: 0.018130
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.990680
 >> iter 2000, loss: 4.089945
 >> iter 3000, loss: 1.528470
 >> iter 4000, loss: 0.595474
 >> iter 5000, loss: 0.244516
 >> iter 6000, loss: 0.111112
 >> iter 7000, loss: 0.065894
 >> iter 8000, loss: 0.052630
 >> iter 9000, loss: 0.039569
 >> iter 10000, loss: 0.032539
   Number of active neurons: 5
 >> iter 11000, loss: 0.032986
 >> iter 12000, loss: 0.030462
 >> iter 13000, loss: 0.028514
 >> iter 14000, loss: 0.028214
 >> iter 15000, loss: 0.029135
 >> iter 16000, loss: 0.029070
 >> iter 17000, loss: 0.046082
 >> iter 18000, loss: 0.031681
 >> iter 19000, loss: 0.030671
 >> iter 20000, loss: 0.028543
   Number of active neurons: 3
 >> iter 21000, loss: 0.026596
 >> iter 22000, loss: 0.029000
 >> iter 23000, loss: 0.025287
 >> iter 24000, loss: 0.027271
 >> iter 25000, loss: 0.026581
 >> iter 26000, loss: 0.025454
 >> iter 27000, loss: 0.024938
 >> iter 28000, loss: 0.022541
 >> iter 29000, loss: 0.022685
 >> iter 30000, loss: 0.027371
   Number of active neurons: 3
 >> iter 31000, loss: 0.024834
 >> iter 32000, loss: 0.024318
 >> iter 33000, loss: 0.022854
 >> iter 34000, loss: 0.032082
 >> iter 35000, loss: 0.030517
 >> iter 36000, loss: 0.028118
 >> iter 37000, loss: 0.025414
 >> iter 38000, loss: 0.025793
 >> iter 39000, loss: 0.023407
 >> iter 40000, loss: 0.023092
   Number of active neurons: 2
 >> iter 41000, loss: 0.021790
 >> iter 42000, loss: 0.031011
 >> iter 43000, loss: 0.024503
 >> iter 44000, loss: 0.022507
 >> iter 45000, loss: 0.024577
 >> iter 46000, loss: 0.022938
 >> iter 47000, loss: 0.023195
 >> iter 48000, loss: 0.020857
 >> iter 49000, loss: 0.020876
 >> iter 50000, loss: 0.025137
   Number of active neurons: 2
 >> iter 51000, loss: 0.022798
 >> iter 52000, loss: 0.023034
 >> iter 53000, loss: 0.020992
 >> iter 54000, loss: 0.022462
 >> iter 55000, loss: 0.022704
 >> iter 56000, loss: 0.021894
 >> iter 57000, loss: 0.020528
 >> iter 58000, loss: 0.020062
 >> iter 59000, loss: 0.022992
 >> iter 60000, loss: 0.021201
   Number of active neurons: 2
 >> iter 61000, loss: 0.021103
 >> iter 62000, loss: 0.037907
 >> iter 63000, loss: 0.026546
 >> iter 64000, loss: 0.029217
 >> iter 65000, loss: 0.024795
 >> iter 66000, loss: 0.022988
 >> iter 67000, loss: 0.021427
 >> iter 68000, loss: 0.022832
 >> iter 69000, loss: 0.054457
 >> iter 70000, loss: 0.042371
   Number of active neurons: 2
 >> iter 71000, loss: 0.030959
 >> iter 72000, loss: 0.023973
 >> iter 73000, loss: 0.036020
 >> iter 74000, loss: 0.025748
 >> iter 75000, loss: 0.024222
 >> iter 76000, loss: 0.023059
 >> iter 77000, loss: 0.021414
 >> iter 78000, loss: 0.024415
 >> iter 79000, loss: 0.022982
 >> iter 80000, loss: 0.032415
   Number of active neurons: 2
 >> iter 81000, loss: 0.028362
 >> iter 82000, loss: 0.024309
 >> iter 83000, loss: 0.022946
 >> iter 84000, loss: 0.020583
 >> iter 85000, loss: 0.020429
 >> iter 86000, loss: 0.023322
 >> iter 87000, loss: 0.026128
 >> iter 88000, loss: 0.030991
 >> iter 89000, loss: 0.038998
 >> iter 90000, loss: 0.028650
   Number of active neurons: 2
 >> iter 91000, loss: 0.027880
 >> iter 92000, loss: 0.046130
 >> iter 93000, loss: 0.029337
 >> iter 94000, loss: 0.026648
 >> iter 95000, loss: 0.031535
 >> iter 96000, loss: 0.025851
 >> iter 97000, loss: 0.024298
 >> iter 98000, loss: 0.038902
 >> iter 99000, loss: 0.027380
 >> iter 100000, loss: 0.026493
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.921455
 >> iter 2000, loss: 4.050314
 >> iter 3000, loss: 1.522785
 >> iter 4000, loss: 0.581434
 >> iter 5000, loss: 0.235309
 >> iter 6000, loss: 0.105998
 >> iter 7000, loss: 0.057575
 >> iter 8000, loss: 0.046894
 >> iter 9000, loss: 0.036472
 >> iter 10000, loss: 0.029995
   Number of active neurons: 4
 >> iter 11000, loss: 0.034116
 >> iter 12000, loss: 0.037879
 >> iter 13000, loss: 0.032186
 >> iter 14000, loss: 0.026146
 >> iter 15000, loss: 0.027418
 >> iter 16000, loss: 0.025830
 >> iter 17000, loss: 0.024784
 >> iter 18000, loss: 0.027820
 >> iter 19000, loss: 0.025507
 >> iter 20000, loss: 0.025346
   Number of active neurons: 3
 >> iter 21000, loss: 0.029689
 >> iter 22000, loss: 0.089384
 >> iter 23000, loss: 0.051273
 >> iter 24000, loss: 0.031920
 >> iter 25000, loss: 0.026006
 >> iter 26000, loss: 0.023906
 >> iter 27000, loss: 0.028170
 >> iter 28000, loss: 0.027731
 >> iter 29000, loss: 0.023243
 >> iter 30000, loss: 0.021703
   Number of active neurons: 2
 >> iter 31000, loss: 0.023318
 >> iter 32000, loss: 0.033710
 >> iter 33000, loss: 0.029308
 >> iter 34000, loss: 0.027264
 >> iter 35000, loss: 0.025340
 >> iter 36000, loss: 0.026013
 >> iter 37000, loss: 0.025858
 >> iter 38000, loss: 0.033917
 >> iter 39000, loss: 0.032413
 >> iter 40000, loss: 0.026815
   Number of active neurons: 2
 >> iter 41000, loss: 0.023093
 >> iter 42000, loss: 0.021692
 >> iter 43000, loss: 0.021924
 >> iter 44000, loss: 0.021852
 >> iter 45000, loss: 0.028486
 >> iter 46000, loss: 0.024063
 >> iter 47000, loss: 0.023319
 >> iter 48000, loss: 0.024176
 >> iter 49000, loss: 0.022121
 >> iter 50000, loss: 0.032958
   Number of active neurons: 2
 >> iter 51000, loss: 0.026243
 >> iter 52000, loss: 0.025514
 >> iter 53000, loss: 0.020839
 >> iter 54000, loss: 0.032215
 >> iter 55000, loss: 0.027255
 >> iter 56000, loss: 0.030121
 >> iter 57000, loss: 0.023643
 >> iter 58000, loss: 0.031272
 >> iter 59000, loss: 0.026200
 >> iter 60000, loss: 0.027341
   Number of active neurons: 1
 >> iter 61000, loss: 0.025559
 >> iter 62000, loss: 0.020138
 >> iter 63000, loss: 0.018200
 >> iter 64000, loss: 0.023770
 >> iter 65000, loss: 0.021476
 >> iter 66000, loss: 0.019273
 >> iter 67000, loss: 0.024156
 >> iter 68000, loss: 0.022986
 >> iter 69000, loss: 0.026038
 >> iter 70000, loss: 0.024450
   Number of active neurons: 1
 >> iter 71000, loss: 0.021282
 >> iter 72000, loss: 0.019431
 >> iter 73000, loss: 0.019697
 >> iter 74000, loss: 0.018024
 >> iter 75000, loss: 0.018004
 >> iter 76000, loss: 0.017382
 >> iter 77000, loss: 0.016028
 >> iter 78000, loss: 0.022174
 >> iter 79000, loss: 0.022298
 >> iter 80000, loss: 0.020563
   Number of active neurons: 1
 >> iter 81000, loss: 0.025246
 >> iter 82000, loss: 0.020725
 >> iter 83000, loss: 0.023685
 >> iter 84000, loss: 0.021719
 >> iter 85000, loss: 0.029146
 >> iter 86000, loss: 0.023702
 >> iter 87000, loss: 0.024169
 >> iter 88000, loss: 0.033241
 >> iter 89000, loss: 0.024788
 >> iter 90000, loss: 0.023711
   Number of active neurons: 1
 >> iter 91000, loss: 0.019781
 >> iter 92000, loss: 0.018883
 >> iter 93000, loss: 0.017446
 >> iter 94000, loss: 0.022134
 >> iter 95000, loss: 0.019521
 >> iter 96000, loss: 0.017477
 >> iter 97000, loss: 0.024825
 >> iter 98000, loss: 0.022018
 >> iter 99000, loss: 0.028271
 >> iter 100000, loss: 0.030095
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.961114
 >> iter 2000, loss: 4.078644
 >> iter 3000, loss: 1.534905
 >> iter 4000, loss: 0.587786
 >> iter 5000, loss: 0.251125
 >> iter 6000, loss: 0.135315
 >> iter 7000, loss: 0.069597
 >> iter 8000, loss: 0.044780
 >> iter 9000, loss: 0.040305
 >> iter 10000, loss: 0.035536
   Number of active neurons: 5
 >> iter 11000, loss: 0.031618
 >> iter 12000, loss: 0.038717
 >> iter 13000, loss: 0.031748
 >> iter 14000, loss: 0.028753
 >> iter 15000, loss: 0.025946
 >> iter 16000, loss: 0.027654
 >> iter 17000, loss: 0.027157
 >> iter 18000, loss: 0.029853
 >> iter 19000, loss: 0.027708
 >> iter 20000, loss: 0.026569
   Number of active neurons: 3
 >> iter 21000, loss: 0.026027
 >> iter 22000, loss: 0.052025
 >> iter 23000, loss: 0.045977
 >> iter 24000, loss: 0.058964
 >> iter 25000, loss: 0.037380
 >> iter 26000, loss: 0.058808
 >> iter 27000, loss: 0.038807
 >> iter 28000, loss: 0.042704
 >> iter 29000, loss: 0.032225
 >> iter 30000, loss: 0.026915
   Number of active neurons: 3
 >> iter 31000, loss: 0.030789
 >> iter 32000, loss: 0.036689
 >> iter 33000, loss: 0.035818
 >> iter 34000, loss: 0.028325
 >> iter 35000, loss: 0.039197
 >> iter 36000, loss: 0.033276
 >> iter 37000, loss: 0.028983
 >> iter 38000, loss: 0.027593
 >> iter 39000, loss: 0.027350
 >> iter 40000, loss: 0.031150
   Number of active neurons: 2
 >> iter 41000, loss: 0.027001
 >> iter 42000, loss: 0.023156
 >> iter 43000, loss: 0.022460
 >> iter 44000, loss: 0.026959
 >> iter 45000, loss: 0.046577
 >> iter 46000, loss: 0.033091
 >> iter 47000, loss: 0.032763
 >> iter 48000, loss: 0.031262
 >> iter 49000, loss: 0.025938
 >> iter 50000, loss: 0.024440
   Number of active neurons: 1
 >> iter 51000, loss: 0.022804
 >> iter 52000, loss: 0.020109
 >> iter 53000, loss: 0.018793
 >> iter 54000, loss: 0.020901
 >> iter 55000, loss: 0.019381
 >> iter 56000, loss: 0.047245
 >> iter 57000, loss: 0.029362
 >> iter 58000, loss: 0.022526
 >> iter 59000, loss: 0.021351
 >> iter 60000, loss: 0.026114
   Number of active neurons: 1
 >> iter 61000, loss: 0.028232
 >> iter 62000, loss: 0.034567
 >> iter 63000, loss: 0.025847
 >> iter 64000, loss: 0.038172
 >> iter 65000, loss: 0.036908
 >> iter 66000, loss: 0.035839
 >> iter 67000, loss: 0.036753
 >> iter 68000, loss: 0.026652
 >> iter 69000, loss: 0.026802
 >> iter 70000, loss: 0.040749
   Number of active neurons: 1
 >> iter 71000, loss: 0.034561
 >> iter 72000, loss: 0.025982
 >> iter 73000, loss: 0.030066
 >> iter 74000, loss: 0.030738
 >> iter 75000, loss: 0.026027
 >> iter 76000, loss: 0.028471
 >> iter 77000, loss: 0.035595
 >> iter 78000, loss: 0.022794
 >> iter 79000, loss: 0.022190
 >> iter 80000, loss: 0.038902
   Number of active neurons: 1
 >> iter 81000, loss: 0.041901
 >> iter 82000, loss: 0.026879
 >> iter 83000, loss: 0.021027
 >> iter 84000, loss: 0.019846
 >> iter 85000, loss: 0.019292
 >> iter 86000, loss: 0.018047
 >> iter 87000, loss: 0.019086
 >> iter 88000, loss: 0.027088
 >> iter 89000, loss: 0.020889
 >> iter 90000, loss: 0.026136
   Number of active neurons: 1
 >> iter 91000, loss: 0.024146
 >> iter 92000, loss: 0.018329
 >> iter 93000, loss: 0.018602
 >> iter 94000, loss: 0.023642
 >> iter 95000, loss: 0.021408
 >> iter 96000, loss: 0.018026
 >> iter 97000, loss: 0.020035
 >> iter 98000, loss: 0.026458
 >> iter 99000, loss: 0.026805
 >> iter 100000, loss: 0.023815
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.970074
 >> iter 2000, loss: 4.093787
 >> iter 3000, loss: 1.534951
 >> iter 4000, loss: 0.591951
 >> iter 5000, loss: 0.242809
 >> iter 6000, loss: 0.111185
 >> iter 7000, loss: 0.061243
 >> iter 8000, loss: 0.041024
 >> iter 9000, loss: 0.034029
 >> iter 10000, loss: 0.031948
   Number of active neurons: 4
 >> iter 11000, loss: 0.029907
 >> iter 12000, loss: 0.030675
 >> iter 13000, loss: 0.028547
 >> iter 14000, loss: 0.026063
 >> iter 15000, loss: 0.040990
 >> iter 16000, loss: 0.038866
 >> iter 17000, loss: 0.031067
 >> iter 18000, loss: 0.025922
 >> iter 19000, loss: 0.043183
 >> iter 20000, loss: 0.030996
   Number of active neurons: 2
 >> iter 21000, loss: 0.025957
 >> iter 22000, loss: 0.026873
 >> iter 23000, loss: 0.022793
 >> iter 24000, loss: 0.020807
 >> iter 25000, loss: 0.024850
 >> iter 26000, loss: 0.022547
 >> iter 27000, loss: 0.035842
 >> iter 28000, loss: 0.026600
 >> iter 29000, loss: 0.024570
 >> iter 30000, loss: 0.024277
   Number of active neurons: 2
 >> iter 31000, loss: 0.025048
 >> iter 32000, loss: 0.029982
 >> iter 33000, loss: 0.023303
 >> iter 34000, loss: 0.032296
 >> iter 35000, loss: 0.038609
 >> iter 36000, loss: 0.027600
 >> iter 37000, loss: 0.026467
 >> iter 38000, loss: 0.022447
 >> iter 39000, loss: 0.027662
 >> iter 40000, loss: 0.031060
   Number of active neurons: 2
 >> iter 41000, loss: 0.036022
 >> iter 42000, loss: 0.028280
 >> iter 43000, loss: 0.064462
 >> iter 44000, loss: 0.041640
 >> iter 45000, loss: 0.037426
 >> iter 46000, loss: 0.026349
 >> iter 47000, loss: 0.025375
 >> iter 48000, loss: 0.023227
 >> iter 49000, loss: 0.028794
 >> iter 50000, loss: 0.032006
   Number of active neurons: 2
 >> iter 51000, loss: 0.023882
 >> iter 52000, loss: 0.039684
 >> iter 53000, loss: 0.030355
 >> iter 54000, loss: 0.025532
 >> iter 55000, loss: 0.026232
 >> iter 56000, loss: 0.021641
 >> iter 57000, loss: 0.019695
 >> iter 58000, loss: 0.018898
 >> iter 59000, loss: 0.017966
 >> iter 60000, loss: 0.025388
   Number of active neurons: 1
 >> iter 61000, loss: 0.022537
 >> iter 62000, loss: 0.030785
 >> iter 63000, loss: 0.026450
 >> iter 64000, loss: 0.022422
 >> iter 65000, loss: 0.021449
 >> iter 66000, loss: 0.018798
 >> iter 67000, loss: 0.023850
 >> iter 68000, loss: 0.020483
 >> iter 69000, loss: 0.018492
 >> iter 70000, loss: 0.019691
   Number of active neurons: 1
 >> iter 71000, loss: 0.031144
 >> iter 72000, loss: 0.023991
 >> iter 73000, loss: 0.020862
 >> iter 74000, loss: 0.030925
 >> iter 75000, loss: 0.028741
 >> iter 76000, loss: 0.028949
 >> iter 77000, loss: 0.022627
 >> iter 78000, loss: 0.025845
 >> iter 79000, loss: 0.037656
 >> iter 80000, loss: 0.024338
   Number of active neurons: 1
 >> iter 81000, loss: 0.019397
 >> iter 82000, loss: 0.020194
 >> iter 83000, loss: 0.018944
 >> iter 84000, loss: 0.017635
 >> iter 85000, loss: 0.017971
 >> iter 86000, loss: 0.026316
 >> iter 87000, loss: 0.024362
 >> iter 88000, loss: 0.021045
 >> iter 89000, loss: 0.026075
 >> iter 90000, loss: 0.029783
   Number of active neurons: 1
 >> iter 91000, loss: 0.024993
 >> iter 92000, loss: 0.021419
 >> iter 93000, loss: 0.021620
 >> iter 94000, loss: 0.018288
 >> iter 95000, loss: 0.023757
 >> iter 96000, loss: 0.021459
 >> iter 97000, loss: 0.028496
 >> iter 98000, loss: 0.021367
 >> iter 99000, loss: 0.024909
 >> iter 100000, loss: 0.036125
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 10.892819
 >> iter 2000, loss: 4.063479
 >> iter 3000, loss: 1.524568
 >> iter 4000, loss: 0.587206
 >> iter 5000, loss: 0.263698
 >> iter 6000, loss: 0.118856
 >> iter 7000, loss: 0.067601
 >> iter 8000, loss: 0.052384
 >> iter 9000, loss: 0.041572
 >> iter 10000, loss: 0.042802
   Number of active neurons: 6
 >> iter 11000, loss: 0.037904
 >> iter 12000, loss: 0.046292
 >> iter 13000, loss: 0.034679
 >> iter 14000, loss: 0.033950
 >> iter 15000, loss: 0.031440
 >> iter 16000, loss: 0.028271
 >> iter 17000, loss: 0.035045
 >> iter 18000, loss: 0.028288
 >> iter 19000, loss: 0.029769
 >> iter 20000, loss: 0.028642
   Number of active neurons: 4
 >> iter 21000, loss: 0.030597
 >> iter 22000, loss: 0.031253
 >> iter 23000, loss: 0.035527
 >> iter 24000, loss: 0.027813
 >> iter 25000, loss: 0.024942
 >> iter 26000, loss: 0.029047
 >> iter 27000, loss: 0.035220
 >> iter 28000, loss: 0.054859
 >> iter 29000, loss: 0.034501
 >> iter 30000, loss: 0.040818
   Number of active neurons: 2
 >> iter 31000, loss: 0.028865
 >> iter 32000, loss: 0.032647
 >> iter 33000, loss: 0.031065
 >> iter 34000, loss: 0.026070
 >> iter 35000, loss: 0.027569
 >> iter 36000, loss: 0.022823
 >> iter 37000, loss: 0.026825
 >> iter 38000, loss: 0.022610
 >> iter 39000, loss: 0.022255
 >> iter 40000, loss: 0.024975
   Number of active neurons: 2
 >> iter 41000, loss: 0.028179
 >> iter 42000, loss: 0.022005
 >> iter 43000, loss: 0.029331
 >> iter 44000, loss: 0.026397
 >> iter 45000, loss: 0.023339
 >> iter 46000, loss: 0.025175
 >> iter 47000, loss: 0.030325
 >> iter 48000, loss: 0.022964
 >> iter 49000, loss: 0.031928
 >> iter 50000, loss: 0.026207
   Number of active neurons: 2
 >> iter 51000, loss: 0.050340
 >> iter 52000, loss: 0.032134
 >> iter 53000, loss: 0.024394
 >> iter 54000, loss: 0.022871
 >> iter 55000, loss: 0.024433
 >> iter 56000, loss: 0.022020
 >> iter 57000, loss: 0.025492
 >> iter 58000, loss: 0.022138
 >> iter 59000, loss: 0.025029
 >> iter 60000, loss: 0.028668
   Number of active neurons: 2
 >> iter 61000, loss: 0.025085
 >> iter 62000, loss: 0.023971
 >> iter 63000, loss: 0.022843
 >> iter 64000, loss: 0.041653
 >> iter 65000, loss: 0.034501
 >> iter 66000, loss: 0.024719
 >> iter 67000, loss: 0.026271
 >> iter 68000, loss: 0.028063
 >> iter 69000, loss: 0.024957
 >> iter 70000, loss: 0.023527
   Number of active neurons: 2
 >> iter 71000, loss: 0.022574
 >> iter 72000, loss: 0.021263
 >> iter 73000, loss: 0.021739
 >> iter 74000, loss: 0.024103
 >> iter 75000, loss: 0.024573
 >> iter 76000, loss: 0.022441
 >> iter 77000, loss: 0.020174
 >> iter 78000, loss: 0.022762
 >> iter 79000, loss: 0.020913
 >> iter 80000, loss: 0.034887
   Number of active neurons: 2
 >> iter 81000, loss: 0.030679
 >> iter 82000, loss: 0.033186
 >> iter 83000, loss: 0.026020
 >> iter 84000, loss: 0.027933
 >> iter 85000, loss: 0.022923
 >> iter 86000, loss: 0.026044
 >> iter 87000, loss: 0.027422
 >> iter 88000, loss: 0.032379
 >> iter 89000, loss: 0.025992
 >> iter 90000, loss: 0.025021
   Number of active neurons: 1
 >> iter 91000, loss: 0.021741
 >> iter 92000, loss: 0.024349
 >> iter 93000, loss: 0.019662
 >> iter 94000, loss: 0.019610
 >> iter 95000, loss: 0.016441
 >> iter 96000, loss: 0.017579
 >> iter 97000, loss: 0.022423
 >> iter 98000, loss: 0.019421
 >> iter 99000, loss: 0.023886
 >> iter 100000, loss: 0.031454
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.938770
 >> iter 2000, loss: 4.092621
 >> iter 3000, loss: 1.537570
 >> iter 4000, loss: 0.594127
 >> iter 5000, loss: 0.242392
 >> iter 6000, loss: 0.109398
 >> iter 7000, loss: 0.059640
 >> iter 8000, loss: 0.039659
 >> iter 9000, loss: 0.037399
 >> iter 10000, loss: 0.031816
   Number of active neurons: 4
 >> iter 11000, loss: 0.031858
 >> iter 12000, loss: 0.031765
 >> iter 13000, loss: 0.028008
 >> iter 14000, loss: 0.033818
 >> iter 15000, loss: 0.028161
 >> iter 16000, loss: 0.033626
 >> iter 17000, loss: 0.030179
 >> iter 18000, loss: 0.033313
 >> iter 19000, loss: 0.034882
 >> iter 20000, loss: 0.028517
   Number of active neurons: 3
 >> iter 21000, loss: 0.029940
 >> iter 22000, loss: 0.027326
 >> iter 23000, loss: 0.030591
 >> iter 24000, loss: 0.043142
 >> iter 25000, loss: 0.030772
 >> iter 26000, loss: 0.056820
 >> iter 27000, loss: 0.035681
 >> iter 28000, loss: 0.033043
 >> iter 29000, loss: 0.029273
 >> iter 30000, loss: 0.027351
   Number of active neurons: 3
 >> iter 31000, loss: 0.024386
 >> iter 32000, loss: 0.023279
 >> iter 33000, loss: 0.026841
 >> iter 34000, loss: 0.029687
 >> iter 35000, loss: 0.027049
 >> iter 36000, loss: 0.030353
 >> iter 37000, loss: 0.024590
 >> iter 38000, loss: 0.048433
 >> iter 39000, loss: 0.033031
 >> iter 40000, loss: 0.027193
   Number of active neurons: 2
 >> iter 41000, loss: 0.023919
 >> iter 42000, loss: 0.025808
 >> iter 43000, loss: 0.027816
 >> iter 44000, loss: 0.023436
 >> iter 45000, loss: 0.035135
 >> iter 46000, loss: 0.027176
 >> iter 47000, loss: 0.031770
 >> iter 48000, loss: 0.025467
 >> iter 49000, loss: 0.022252
 >> iter 50000, loss: 0.027514
   Number of active neurons: 2
 >> iter 51000, loss: 0.030475
 >> iter 52000, loss: 0.024789
 >> iter 53000, loss: 0.021106
 >> iter 54000, loss: 0.019904
 >> iter 55000, loss: 0.029787
 >> iter 56000, loss: 0.025861
 >> iter 57000, loss: 0.022874
 >> iter 58000, loss: 0.024094
 >> iter 59000, loss: 0.019544
 >> iter 60000, loss: 0.018924
   Number of active neurons: 1
 >> iter 61000, loss: 0.021273
 >> iter 62000, loss: 0.027113
 >> iter 63000, loss: 0.020140
 >> iter 64000, loss: 0.021218
 >> iter 65000, loss: 0.040197
 >> iter 66000, loss: 0.027074
 >> iter 67000, loss: 0.021301
 >> iter 68000, loss: 0.031653
 >> iter 69000, loss: 0.025670
 >> iter 70000, loss: 0.020418
   Number of active neurons: 1
 >> iter 71000, loss: 0.018601
 >> iter 72000, loss: 0.018087
 >> iter 73000, loss: 0.017709
 >> iter 74000, loss: 0.016078
 >> iter 75000, loss: 0.017329
 >> iter 76000, loss: 0.030765
 >> iter 77000, loss: 0.055156
 >> iter 78000, loss: 0.030762
 >> iter 79000, loss: 0.021816
 >> iter 80000, loss: 0.024129
   Number of active neurons: 1
 >> iter 81000, loss: 0.021256
 >> iter 82000, loss: 0.019949
 >> iter 83000, loss: 0.025737
 >> iter 84000, loss: 0.021538
 >> iter 85000, loss: 0.018796
 >> iter 86000, loss: 0.018695
 >> iter 87000, loss: 0.018018
 >> iter 88000, loss: 0.021474
 >> iter 89000, loss: 0.017815
 >> iter 90000, loss: 0.018925
   Number of active neurons: 1
 >> iter 91000, loss: 0.020308
 >> iter 92000, loss: 0.022419
 >> iter 93000, loss: 0.024429
 >> iter 94000, loss: 0.019551
 >> iter 95000, loss: 0.039478
 >> iter 96000, loss: 0.057142
 >> iter 97000, loss: 0.039748
 >> iter 98000, loss: 0.026216
 >> iter 99000, loss: 0.021515
 >> iter 100000, loss: 0.019457
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.920097
 >> iter 2000, loss: 4.056822
 >> iter 3000, loss: 1.518939
 >> iter 4000, loss: 0.585836
 >> iter 5000, loss: 0.239703
 >> iter 6000, loss: 0.106726
 >> iter 7000, loss: 0.062365
 >> iter 8000, loss: 0.039860
 >> iter 9000, loss: 0.034715
 >> iter 10000, loss: 0.026336
   Number of active neurons: 3
 >> iter 11000, loss: 0.028035
 >> iter 12000, loss: 0.060864
 >> iter 13000, loss: 0.038942
 >> iter 14000, loss: 0.043521
 >> iter 15000, loss: 0.030569
 >> iter 16000, loss: 0.026442
 >> iter 17000, loss: 0.036251
 >> iter 18000, loss: 0.029406
 >> iter 19000, loss: 0.028605
 >> iter 20000, loss: 0.025431
   Number of active neurons: 3
 >> iter 21000, loss: 0.032154
 >> iter 22000, loss: 0.028307
 >> iter 23000, loss: 0.031653
 >> iter 24000, loss: 0.031333
 >> iter 25000, loss: 0.030731
 >> iter 26000, loss: 0.027178
 >> iter 27000, loss: 0.024022
 >> iter 28000, loss: 0.028571
 >> iter 29000, loss: 0.045447
 >> iter 30000, loss: 0.034020
   Number of active neurons: 3
 >> iter 31000, loss: 0.029852
 >> iter 32000, loss: 0.025848
 >> iter 33000, loss: 0.028941
 >> iter 34000, loss: 0.025559
 >> iter 35000, loss: 0.025990
 >> iter 36000, loss: 0.031404
 >> iter 37000, loss: 0.024064
 >> iter 38000, loss: 0.024484
 >> iter 39000, loss: 0.023199
 >> iter 40000, loss: 0.027350
   Number of active neurons: 2
 >> iter 41000, loss: 0.024084
 >> iter 42000, loss: 0.032914
 >> iter 43000, loss: 0.051517
 >> iter 44000, loss: 0.034347
 >> iter 45000, loss: 0.028199
 >> iter 46000, loss: 0.037759
 >> iter 47000, loss: 0.027219
 >> iter 48000, loss: 0.025405
 >> iter 49000, loss: 0.028918
 >> iter 50000, loss: 0.031541
   Number of active neurons: 2
 >> iter 51000, loss: 0.029505
 >> iter 52000, loss: 0.028285
 >> iter 53000, loss: 0.029309
 >> iter 54000, loss: 0.023937
 >> iter 55000, loss: 0.020159
 >> iter 56000, loss: 0.019983
 >> iter 57000, loss: 0.021780
 >> iter 58000, loss: 0.019869
 >> iter 59000, loss: 0.023820
 >> iter 60000, loss: 0.022239
   Number of active neurons: 1
 >> iter 61000, loss: 0.019879
 >> iter 62000, loss: 0.022945
 >> iter 63000, loss: 0.019518
 >> iter 64000, loss: 0.018861
 >> iter 65000, loss: 0.020140
 >> iter 66000, loss: 0.018338
 >> iter 67000, loss: 0.022266
 >> iter 68000, loss: 0.020765
 >> iter 69000, loss: 0.017526
 >> iter 70000, loss: 0.020905
   Number of active neurons: 1
 >> iter 71000, loss: 0.019068
 >> iter 72000, loss: 0.026143
 >> iter 73000, loss: 0.019944
 >> iter 74000, loss: 0.027881
 >> iter 75000, loss: 0.023767
 >> iter 76000, loss: 0.017910
 >> iter 77000, loss: 0.017071
 >> iter 78000, loss: 0.016725
 >> iter 79000, loss: 0.019851
 >> iter 80000, loss: 0.026006
   Number of active neurons: 1
 >> iter 81000, loss: 0.028712
 >> iter 82000, loss: 0.020911
 >> iter 83000, loss: 0.017887
 >> iter 84000, loss: 0.018295
 >> iter 85000, loss: 0.016549
 >> iter 86000, loss: 0.021096
 >> iter 87000, loss: 0.025182
 >> iter 88000, loss: 0.018235
 >> iter 89000, loss: 0.040376
 >> iter 90000, loss: 0.032767
   Number of active neurons: 1
 >> iter 91000, loss: 0.029527
 >> iter 92000, loss: 0.022059
 >> iter 93000, loss: 0.023215
 >> iter 94000, loss: 0.025458
 >> iter 95000, loss: 0.020488
 >> iter 96000, loss: 0.019051
 >> iter 97000, loss: 0.025027
 >> iter 98000, loss: 0.020842
 >> iter 99000, loss: 0.019652
 >> iter 100000, loss: 0.031260
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 10.929854
 >> iter 2000, loss: 4.085891
 >> iter 3000, loss: 1.533930
 >> iter 4000, loss: 0.595785
 >> iter 5000, loss: 0.246284
 >> iter 6000, loss: 0.110152
 >> iter 7000, loss: 0.070004
 >> iter 8000, loss: 0.045271
 >> iter 9000, loss: 0.047386
 >> iter 10000, loss: 0.036567
   Number of active neurons: 4
 >> iter 11000, loss: 0.040595
 >> iter 12000, loss: 0.030076
 >> iter 13000, loss: 0.028889
 >> iter 14000, loss: 0.031135
 >> iter 15000, loss: 0.028418
 >> iter 16000, loss: 0.035332
 >> iter 17000, loss: 0.031911
 >> iter 18000, loss: 0.028087
 >> iter 19000, loss: 0.027136
 >> iter 20000, loss: 0.026592
   Number of active neurons: 4
 >> iter 21000, loss: 0.025924
 >> iter 22000, loss: 0.031317
 >> iter 23000, loss: 0.027319
 >> iter 24000, loss: 0.023340
 >> iter 25000, loss: 0.024819
 >> iter 26000, loss: 0.024854
 >> iter 27000, loss: 0.026428
 >> iter 28000, loss: 0.026301
 >> iter 29000, loss: 0.022720
 >> iter 30000, loss: 0.020189
   Number of active neurons: 2
 >> iter 31000, loss: 0.021118
 >> iter 32000, loss: 0.020633
 >> iter 33000, loss: 0.021719
 >> iter 34000, loss: 0.020692
 >> iter 35000, loss: 0.022016
 >> iter 36000, loss: 0.022108
 >> iter 37000, loss: 0.020413
 >> iter 38000, loss: 0.022634
 >> iter 39000, loss: 0.021338
 >> iter 40000, loss: 0.020992
   Number of active neurons: 2
 >> iter 41000, loss: 0.023023
 >> iter 42000, loss: 0.022458
 >> iter 43000, loss: 0.033064
 >> iter 44000, loss: 0.028163
 >> iter 45000, loss: 0.022692
 >> iter 46000, loss: 0.037891
 >> iter 47000, loss: 0.027467
 >> iter 48000, loss: 0.026805
 >> iter 49000, loss: 0.023264
 >> iter 50000, loss: 0.024555
   Number of active neurons: 2
 >> iter 51000, loss: 0.022293
 >> iter 52000, loss: 0.021237
 >> iter 53000, loss: 0.028260
 >> iter 54000, loss: 0.024969
 >> iter 55000, loss: 0.028441
 >> iter 56000, loss: 0.022827
 >> iter 57000, loss: 0.025607
 >> iter 58000, loss: 0.024082
 >> iter 59000, loss: 0.023446
 >> iter 60000, loss: 0.026662
   Number of active neurons: 2
 >> iter 61000, loss: 0.021777
 >> iter 62000, loss: 0.021890
 >> iter 63000, loss: 0.019865
 >> iter 64000, loss: 0.020945
 >> iter 65000, loss: 0.029079
 >> iter 66000, loss: 0.022178
 >> iter 67000, loss: 0.024341
 >> iter 68000, loss: 0.022325
 >> iter 69000, loss: 0.025870
 >> iter 70000, loss: 0.024424
   Number of active neurons: 2
 >> iter 71000, loss: 0.049888
 >> iter 72000, loss: 0.031944
 >> iter 73000, loss: 0.057140
 >> iter 74000, loss: 0.034108
 >> iter 75000, loss: 0.037730
 >> iter 76000, loss: 0.027674
 >> iter 77000, loss: 0.027662
 >> iter 78000, loss: 0.023029
 >> iter 79000, loss: 0.030218
 >> iter 80000, loss: 0.026371
   Number of active neurons: 2
 >> iter 81000, loss: 0.022779
 >> iter 82000, loss: 0.021136
 >> iter 83000, loss: 0.025743
 >> iter 84000, loss: 0.023426
 >> iter 85000, loss: 0.021990
 >> iter 86000, loss: 0.024667
 >> iter 87000, loss: 0.022982
 >> iter 88000, loss: 0.024703
 >> iter 89000, loss: 0.029860
 >> iter 90000, loss: 0.035528
   Number of active neurons: 2
 >> iter 91000, loss: 0.043410
 >> iter 92000, loss: 0.030614
 >> iter 93000, loss: 0.026183
 >> iter 94000, loss: 0.023664
 >> iter 95000, loss: 0.024702
 >> iter 96000, loss: 0.020550
 >> iter 97000, loss: 0.022074
 >> iter 98000, loss: 0.022415
 >> iter 99000, loss: 0.025036
 >> iter 100000, loss: 0.043455
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 10.913233
 >> iter 2000, loss: 4.055988
 >> iter 3000, loss: 1.539042
 >> iter 4000, loss: 0.586486
 >> iter 5000, loss: 0.242086
 >> iter 6000, loss: 0.113680
 >> iter 7000, loss: 0.065692
 >> iter 8000, loss: 0.048843
 >> iter 9000, loss: 0.039865
 >> iter 10000, loss: 0.038449
   Number of active neurons: 5
 >> iter 11000, loss: 0.032696
 >> iter 12000, loss: 0.042592
 >> iter 13000, loss: 0.032404
 >> iter 14000, loss: 0.028718
 >> iter 15000, loss: 0.029700
 >> iter 16000, loss: 0.030959
 >> iter 17000, loss: 0.027923
 >> iter 18000, loss: 0.026475
 >> iter 19000, loss: 0.034128
 >> iter 20000, loss: 0.030369
   Number of active neurons: 3
 >> iter 21000, loss: 0.035782
 >> iter 22000, loss: 0.042553
 >> iter 23000, loss: 0.030909
 >> iter 24000, loss: 0.027954
 >> iter 25000, loss: 0.035120
 >> iter 26000, loss: 0.026463
 >> iter 27000, loss: 0.022770
 >> iter 28000, loss: 0.021329
 >> iter 29000, loss: 0.021164
 >> iter 30000, loss: 0.028225
   Number of active neurons: 2
 >> iter 31000, loss: 0.022501
 >> iter 32000, loss: 0.020728
 >> iter 33000, loss: 0.022430
 >> iter 34000, loss: 0.023543
 >> iter 35000, loss: 0.021340
 >> iter 36000, loss: 0.030396
 >> iter 37000, loss: 0.026353
 >> iter 38000, loss: 0.026795
 >> iter 39000, loss: 0.021197
 >> iter 40000, loss: 0.025663
   Number of active neurons: 1
 >> iter 41000, loss: 0.020921
 >> iter 42000, loss: 0.026899
 >> iter 43000, loss: 0.024853
 >> iter 44000, loss: 0.031255
 >> iter 45000, loss: 0.026836
 >> iter 46000, loss: 0.032029
 >> iter 47000, loss: 0.024121
 >> iter 48000, loss: 0.020781
 >> iter 49000, loss: 0.028366
 >> iter 50000, loss: 0.023078
   Number of active neurons: 1
 >> iter 51000, loss: 0.018724
 >> iter 52000, loss: 0.016268
 >> iter 53000, loss: 0.016068
 >> iter 54000, loss: 0.018024
 >> iter 55000, loss: 0.032671
 >> iter 56000, loss: 0.023860
 >> iter 57000, loss: 0.022388
 >> iter 58000, loss: 0.026217
 >> iter 59000, loss: 0.022232
 >> iter 60000, loss: 0.024602
   Number of active neurons: 1
 >> iter 61000, loss: 0.021457
 >> iter 62000, loss: 0.031310
 >> iter 63000, loss: 0.027972
 >> iter 64000, loss: 0.025490
 >> iter 65000, loss: 0.039017
 >> iter 66000, loss: 0.027927
 >> iter 67000, loss: 0.020372
 >> iter 68000, loss: 0.019177
 >> iter 69000, loss: 0.017103
 >> iter 70000, loss: 0.030630
   Number of active neurons: 1
 >> iter 71000, loss: 0.023079
 >> iter 72000, loss: 0.030941
 >> iter 73000, loss: 0.027518
 >> iter 74000, loss: 0.024644
 >> iter 75000, loss: 0.019789
 >> iter 76000, loss: 0.046804
 >> iter 77000, loss: 0.028125
 >> iter 78000, loss: 0.024563
 >> iter 79000, loss: 0.019173
 >> iter 80000, loss: 0.020224
   Number of active neurons: 1
 >> iter 81000, loss: 0.017775
 >> iter 82000, loss: 0.017711
 >> iter 83000, loss: 0.021808
 >> iter 84000, loss: 0.036045
 >> iter 85000, loss: 0.024633
 >> iter 86000, loss: 0.022985
 >> iter 87000, loss: 0.018953
 >> iter 88000, loss: 0.024335
 >> iter 89000, loss: 0.033566
 >> iter 90000, loss: 0.023492
   Number of active neurons: 1
 >> iter 91000, loss: 0.018963
 >> iter 92000, loss: 0.017850
 >> iter 93000, loss: 0.016606
 >> iter 94000, loss: 0.018045
 >> iter 95000, loss: 0.018111
 >> iter 96000, loss: 0.019298
 >> iter 97000, loss: 0.021299
 >> iter 98000, loss: 0.018479
 >> iter 99000, loss: 0.024205
 >> iter 100000, loss: 0.036617
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.903827
 >> iter 2000, loss: 4.049446
 >> iter 3000, loss: 1.528763
 >> iter 4000, loss: 0.592036
 >> iter 5000, loss: 0.242429
 >> iter 6000, loss: 0.106944
 >> iter 7000, loss: 0.060864
 >> iter 8000, loss: 0.041211
 >> iter 9000, loss: 0.031426
 >> iter 10000, loss: 0.028757
   Number of active neurons: 4
 >> iter 11000, loss: 0.032603
 >> iter 12000, loss: 0.036559
 >> iter 13000, loss: 0.037539
 >> iter 14000, loss: 0.028009
 >> iter 15000, loss: 0.028726
 >> iter 16000, loss: 0.026485
 >> iter 17000, loss: 0.026263
 >> iter 18000, loss: 0.024826
 >> iter 19000, loss: 0.026798
 >> iter 20000, loss: 0.024499
   Number of active neurons: 3
 >> iter 21000, loss: 0.029997
 >> iter 22000, loss: 0.025122
 >> iter 23000, loss: 0.024960
 >> iter 24000, loss: 0.024392
 >> iter 25000, loss: 0.029954
 >> iter 26000, loss: 0.029930
 >> iter 27000, loss: 0.027587
 >> iter 28000, loss: 0.024448
 >> iter 29000, loss: 0.028958
 >> iter 30000, loss: 0.025956
   Number of active neurons: 3
 >> iter 31000, loss: 0.027672
 >> iter 32000, loss: 0.027159
 >> iter 33000, loss: 0.024938
 >> iter 34000, loss: 0.022708
 >> iter 35000, loss: 0.064609
 >> iter 36000, loss: 0.038297
 >> iter 37000, loss: 0.031483
 >> iter 38000, loss: 0.033710
 >> iter 39000, loss: 0.027380
 >> iter 40000, loss: 0.024948
   Number of active neurons: 3
 >> iter 41000, loss: 0.036161
 >> iter 42000, loss: 0.026444
 >> iter 43000, loss: 0.022976
 >> iter 44000, loss: 0.022622
 >> iter 45000, loss: 0.023075
 >> iter 46000, loss: 0.022570
 >> iter 47000, loss: 0.021120
 >> iter 48000, loss: 0.026424
 >> iter 49000, loss: 0.024007
 >> iter 50000, loss: 0.023156
   Number of active neurons: 2
 >> iter 51000, loss: 0.025654
 >> iter 52000, loss: 0.022084
 >> iter 53000, loss: 0.024042
 >> iter 54000, loss: 0.020982
 >> iter 55000, loss: 0.022312
 >> iter 56000, loss: 0.021095
 >> iter 57000, loss: 0.026038
 >> iter 58000, loss: 0.025168
 >> iter 59000, loss: 0.023074
 >> iter 60000, loss: 0.021218
   Number of active neurons: 2
 >> iter 61000, loss: 0.022059
 >> iter 62000, loss: 0.022248
 >> iter 63000, loss: 0.024520
 >> iter 64000, loss: 0.022587
 >> iter 65000, loss: 0.038829
 >> iter 66000, loss: 0.031223
 >> iter 67000, loss: 0.026942
 >> iter 68000, loss: 0.023312
 >> iter 69000, loss: 0.021993
 >> iter 70000, loss: 0.020461
   Number of active neurons: 2
 >> iter 71000, loss: 0.031090
 >> iter 72000, loss: 0.025281
 >> iter 73000, loss: 0.023887
 >> iter 74000, loss: 0.029278
 >> iter 75000, loss: 0.043153
 >> iter 76000, loss: 0.034057
 >> iter 77000, loss: 0.032083
 >> iter 78000, loss: 0.026243
 >> iter 79000, loss: 0.034816
 >> iter 80000, loss: 0.026537
   Number of active neurons: 2
 >> iter 81000, loss: 0.023815
 >> iter 82000, loss: 0.032793
 >> iter 83000, loss: 0.026322
 >> iter 84000, loss: 0.024310
 >> iter 85000, loss: 0.026870
 >> iter 86000, loss: 0.024104
 >> iter 87000, loss: 0.069868
 >> iter 88000, loss: 0.047914
 >> iter 89000, loss: 0.031399
 >> iter 90000, loss: 0.023812
   Number of active neurons: 2
 >> iter 91000, loss: 0.024854
 >> iter 92000, loss: 0.023843
 >> iter 93000, loss: 0.028185
 >> iter 94000, loss: 0.042148
 >> iter 95000, loss: 0.043118
 >> iter 96000, loss: 0.028730
 >> iter 97000, loss: 0.023844
 >> iter 98000, loss: 0.023702
 >> iter 99000, loss: 0.027802
 >> iter 100000, loss: 0.046513
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.919214
 >> iter 2000, loss: 4.053059
 >> iter 3000, loss: 1.526033
 >> iter 4000, loss: 0.586061
 >> iter 5000, loss: 0.242752
 >> iter 6000, loss: 0.114727
 >> iter 7000, loss: 0.065627
 >> iter 8000, loss: 0.045675
 >> iter 9000, loss: 0.035174
 >> iter 10000, loss: 0.029089
   Number of active neurons: 4
 >> iter 11000, loss: 0.028452
 >> iter 12000, loss: 0.034255
 >> iter 13000, loss: 0.028187
 >> iter 14000, loss: 0.029040
 >> iter 15000, loss: 0.026828
 >> iter 16000, loss: 0.027235
 >> iter 17000, loss: 0.025505
 >> iter 18000, loss: 0.030314
 >> iter 19000, loss: 0.026861
 >> iter 20000, loss: 0.026883
   Number of active neurons: 3
 >> iter 21000, loss: 0.024534
 >> iter 22000, loss: 0.030840
 >> iter 23000, loss: 0.031863
 >> iter 24000, loss: 0.028941
 >> iter 25000, loss: 0.026702
 >> iter 26000, loss: 0.022409
 >> iter 27000, loss: 0.022550
 >> iter 28000, loss: 0.040330
 >> iter 29000, loss: 0.030447
 >> iter 30000, loss: 0.023926
   Number of active neurons: 2
 >> iter 31000, loss: 0.026703
 >> iter 32000, loss: 0.022171
 >> iter 33000, loss: 0.024942
 >> iter 34000, loss: 0.023006
 >> iter 35000, loss: 0.020172
 >> iter 36000, loss: 0.028062
 >> iter 37000, loss: 0.025459
 >> iter 38000, loss: 0.022620
 >> iter 39000, loss: 0.020666
 >> iter 40000, loss: 0.020163
   Number of active neurons: 2
 >> iter 41000, loss: 0.044084
 >> iter 42000, loss: 0.029643
 >> iter 43000, loss: 0.028492
 >> iter 44000, loss: 0.028011
 >> iter 45000, loss: 0.037975
 >> iter 46000, loss: 0.025559
 >> iter 47000, loss: 0.024395
 >> iter 48000, loss: 0.024380
 >> iter 49000, loss: 0.023133
 >> iter 50000, loss: 0.035364
   Number of active neurons: 2
 >> iter 51000, loss: 0.026916
 >> iter 52000, loss: 0.023586
 >> iter 53000, loss: 0.024592
 >> iter 54000, loss: 0.021229
 >> iter 55000, loss: 0.020205
 >> iter 56000, loss: 0.021128
 >> iter 57000, loss: 0.021219
 >> iter 58000, loss: 0.021464
 >> iter 59000, loss: 0.020901
 >> iter 60000, loss: 0.024410
   Number of active neurons: 2
 >> iter 61000, loss: 0.033168
 >> iter 62000, loss: 0.025970
 >> iter 63000, loss: 0.023885
 >> iter 64000, loss: 0.039686
 >> iter 65000, loss: 0.026763
 >> iter 66000, loss: 0.022306
 >> iter 67000, loss: 0.030473
 >> iter 68000, loss: 0.025102
 >> iter 69000, loss: 0.023231
 >> iter 70000, loss: 0.020289
   Number of active neurons: 2
 >> iter 71000, loss: 0.026269
 >> iter 72000, loss: 0.026037
 >> iter 73000, loss: 0.024123
 >> iter 74000, loss: 0.020495
 >> iter 75000, loss: 0.021638
 >> iter 76000, loss: 0.027596
 >> iter 77000, loss: 0.037090
 >> iter 78000, loss: 0.047032
 >> iter 79000, loss: 0.029732
 >> iter 80000, loss: 0.023966
   Number of active neurons: 2
 >> iter 81000, loss: 0.023690
 >> iter 82000, loss: 0.021353
 >> iter 83000, loss: 0.021025
 >> iter 84000, loss: 0.025015
 >> iter 85000, loss: 0.025234
 >> iter 86000, loss: 0.022026
 >> iter 87000, loss: 0.021245
 >> iter 88000, loss: 0.019519
 >> iter 89000, loss: 0.034889
 >> iter 90000, loss: 0.025131
   Number of active neurons: 2
 >> iter 91000, loss: 0.023923
 >> iter 92000, loss: 0.026517
 >> iter 93000, loss: 0.024115
 >> iter 94000, loss: 0.041518
 >> iter 95000, loss: 0.033110
 >> iter 96000, loss: 0.024370
 >> iter 97000, loss: 0.039477
 >> iter 98000, loss: 0.026683
 >> iter 99000, loss: 0.025688
 >> iter 100000, loss: 0.023642
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.941218
 >> iter 2000, loss: 4.080844
 >> iter 3000, loss: 1.531711
 >> iter 4000, loss: 0.592951
 >> iter 5000, loss: 0.238249
 >> iter 6000, loss: 0.108761
 >> iter 7000, loss: 0.056913
 >> iter 8000, loss: 0.048990
 >> iter 9000, loss: 0.038092
 >> iter 10000, loss: 0.037399
   Number of active neurons: 5
 >> iter 11000, loss: 0.029281
 >> iter 12000, loss: 0.030411
 >> iter 13000, loss: 0.033729
 >> iter 14000, loss: 0.034543
 >> iter 15000, loss: 0.030840
 >> iter 16000, loss: 0.026741
 >> iter 17000, loss: 0.024650
 >> iter 18000, loss: 0.025314
 >> iter 19000, loss: 0.024966
 >> iter 20000, loss: 0.031382
   Number of active neurons: 3
 >> iter 21000, loss: 0.036092
 >> iter 22000, loss: 0.028926
 >> iter 23000, loss: 0.026543
 >> iter 24000, loss: 0.025822
 >> iter 25000, loss: 0.024491
 >> iter 26000, loss: 0.023721
 >> iter 27000, loss: 0.023338
 >> iter 28000, loss: 0.021790
 >> iter 29000, loss: 0.020737
 >> iter 30000, loss: 0.033362
   Number of active neurons: 2
 >> iter 31000, loss: 0.024836
 >> iter 32000, loss: 0.023715
 >> iter 33000, loss: 0.055625
 >> iter 34000, loss: 0.033694
 >> iter 35000, loss: 0.039181
 >> iter 36000, loss: 0.027630
 >> iter 37000, loss: 0.025653
 >> iter 38000, loss: 0.021681
 >> iter 39000, loss: 0.022051
 >> iter 40000, loss: 0.023832
   Number of active neurons: 2
 >> iter 41000, loss: 0.028123
 >> iter 42000, loss: 0.024707
 >> iter 43000, loss: 0.023131
 >> iter 44000, loss: 0.023572
 >> iter 45000, loss: 0.024318
 >> iter 46000, loss: 0.024005
 >> iter 47000, loss: 0.027215
 >> iter 48000, loss: 0.025213
 >> iter 49000, loss: 0.020970
 >> iter 50000, loss: 0.026460
   Number of active neurons: 2
 >> iter 51000, loss: 0.023430
 >> iter 52000, loss: 0.022533
 >> iter 53000, loss: 0.021951
 >> iter 54000, loss: 0.021187
 >> iter 55000, loss: 0.021130
 >> iter 56000, loss: 0.022766
 >> iter 57000, loss: 0.021770
 >> iter 58000, loss: 0.020457
 >> iter 59000, loss: 0.025049
 >> iter 60000, loss: 0.046428
   Number of active neurons: 2
 >> iter 61000, loss: 0.030561
 >> iter 62000, loss: 0.026976
 >> iter 63000, loss: 0.031536
 >> iter 64000, loss: 0.025079
 >> iter 65000, loss: 0.022696
 >> iter 66000, loss: 0.020349
 >> iter 67000, loss: 0.023221
 >> iter 68000, loss: 0.024565
 >> iter 69000, loss: 0.021112
 >> iter 70000, loss: 0.021070
   Number of active neurons: 2
 >> iter 71000, loss: 0.021787
 >> iter 72000, loss: 0.024349
 >> iter 73000, loss: 0.028085
 >> iter 74000, loss: 0.028914
 >> iter 75000, loss: 0.030793
 >> iter 76000, loss: 0.025139
 >> iter 77000, loss: 0.023558
 >> iter 78000, loss: 0.022243
 >> iter 79000, loss: 0.025393
 >> iter 80000, loss: 0.025436
   Number of active neurons: 2
 >> iter 81000, loss: 0.022694
 >> iter 82000, loss: 0.024816
 >> iter 83000, loss: 0.023149
 >> iter 84000, loss: 0.020418
 >> iter 85000, loss: 0.023978
 >> iter 86000, loss: 0.023355
 >> iter 87000, loss: 0.020925
 >> iter 88000, loss: 0.020080
 >> iter 89000, loss: 0.032004
 >> iter 90000, loss: 0.024541
   Number of active neurons: 2
 >> iter 91000, loss: 0.026778
 >> iter 92000, loss: 0.022242
 >> iter 93000, loss: 0.031314
 >> iter 94000, loss: 0.024056
 >> iter 95000, loss: 0.025019
 >> iter 96000, loss: 0.029422
 >> iter 97000, loss: 0.036780
 >> iter 98000, loss: 0.030804
 >> iter 99000, loss: 0.026240
 >> iter 100000, loss: 0.021905
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.897624
 >> iter 2000, loss: 4.040443
 >> iter 3000, loss: 1.524059
 >> iter 4000, loss: 0.590599
 >> iter 5000, loss: 0.238336
 >> iter 6000, loss: 0.114856
 >> iter 7000, loss: 0.064555
 >> iter 8000, loss: 0.045615
 >> iter 9000, loss: 0.038689
 >> iter 10000, loss: 0.036076
   Number of active neurons: 3
 >> iter 11000, loss: 0.042059
 >> iter 12000, loss: 0.031387
 >> iter 13000, loss: 0.030724
 >> iter 14000, loss: 0.029648
 >> iter 15000, loss: 0.029151
 >> iter 16000, loss: 0.032899
 >> iter 17000, loss: 0.039603
 >> iter 18000, loss: 0.033564
 >> iter 19000, loss: 0.029614
 >> iter 20000, loss: 0.025036
   Number of active neurons: 3
 >> iter 21000, loss: 0.029851
 >> iter 22000, loss: 0.032142
 >> iter 23000, loss: 0.026395
 >> iter 24000, loss: 0.026275
 >> iter 25000, loss: 0.024389
 >> iter 26000, loss: 0.025520
 >> iter 27000, loss: 0.031433
 >> iter 28000, loss: 0.038495
 >> iter 29000, loss: 0.032147
 >> iter 30000, loss: 0.035006
   Number of active neurons: 1
 >> iter 31000, loss: 0.026205
 >> iter 32000, loss: 0.022049
 >> iter 33000, loss: 0.048443
 >> iter 34000, loss: 0.074965
 >> iter 35000, loss: 0.041126
 >> iter 36000, loss: 0.025607
 >> iter 37000, loss: 0.020270
 >> iter 38000, loss: 0.020415
 >> iter 39000, loss: 0.029937
 >> iter 40000, loss: 0.021671
   Number of active neurons: 1
 >> iter 41000, loss: 0.035635
 >> iter 42000, loss: 0.024770
 >> iter 43000, loss: 0.019652
 >> iter 44000, loss: 0.021819
 >> iter 45000, loss: 0.019563
 >> iter 46000, loss: 0.019190
 >> iter 47000, loss: 0.019980
 >> iter 48000, loss: 0.017895
 >> iter 49000, loss: 0.019203
 >> iter 50000, loss: 0.022271
   Number of active neurons: 1
 >> iter 51000, loss: 0.018123
 >> iter 52000, loss: 0.017279
 >> iter 53000, loss: 0.018615
 >> iter 54000, loss: 0.020281
 >> iter 55000, loss: 0.018648
 >> iter 56000, loss: 0.025246
 >> iter 57000, loss: 0.019878
 >> iter 58000, loss: 0.021156
 >> iter 59000, loss: 0.017845
 >> iter 60000, loss: 0.017188
   Number of active neurons: 1
 >> iter 61000, loss: 0.016710
 >> iter 62000, loss: 0.016886
 >> iter 63000, loss: 0.017149
 >> iter 64000, loss: 0.034467
 >> iter 65000, loss: 0.045265
 >> iter 66000, loss: 0.030008
 >> iter 67000, loss: 0.022985
 >> iter 68000, loss: 0.023600
 >> iter 69000, loss: 0.024946
 >> iter 70000, loss: 0.019800
   Number of active neurons: 1
 >> iter 71000, loss: 0.017191
 >> iter 72000, loss: 0.016604
 >> iter 73000, loss: 0.022570
 >> iter 74000, loss: 0.021597
 >> iter 75000, loss: 0.029754
 >> iter 76000, loss: 0.028760
 >> iter 77000, loss: 0.021867
 >> iter 78000, loss: 0.019480
 >> iter 79000, loss: 0.017481
 >> iter 80000, loss: 0.017765
   Number of active neurons: 1
 >> iter 81000, loss: 0.018127
 >> iter 82000, loss: 0.025652
 >> iter 83000, loss: 0.024826
 >> iter 84000, loss: 0.019472
 >> iter 85000, loss: 0.023979
 >> iter 86000, loss: 0.018865
 >> iter 87000, loss: 0.021474
 >> iter 88000, loss: 0.019415
 >> iter 89000, loss: 0.023885
 >> iter 90000, loss: 0.019854
   Number of active neurons: 1
 >> iter 91000, loss: 0.035831
 >> iter 92000, loss: 0.034765
 >> iter 93000, loss: 0.023003
 >> iter 94000, loss: 0.021730
 >> iter 95000, loss: 0.020651
 >> iter 96000, loss: 0.017249
 >> iter 97000, loss: 0.024925
 >> iter 98000, loss: 0.047783
 >> iter 99000, loss: 0.034673
 >> iter 100000, loss: 0.025812
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

