 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.5
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.066135
 >> iter 2000, loss: 7.764254
 >> iter 3000, loss: 3.174091
 >> iter 4000, loss: 1.299859
 >> iter 5000, loss: 0.495944
 >> iter 6000, loss: 0.234305
 >> iter 7000, loss: 0.096122
 >> iter 8000, loss: 0.044724
 >> iter 9000, loss: 0.022054
 >> iter 10000, loss: 0.016367
   Number of active neurons: 10
 >> iter 11000, loss: 0.010149
 >> iter 12000, loss: 0.007439
 >> iter 13000, loss: 0.012813
 >> iter 14000, loss: 0.007782
 >> iter 15000, loss: 0.005505
 >> iter 16000, loss: 0.004928
 >> iter 17000, loss: 0.004288
 >> iter 18000, loss: 0.003835
 >> iter 19000, loss: 0.003474
 >> iter 20000, loss: 0.003132
   Number of active neurons: 10
 >> iter 21000, loss: 0.003094
 >> iter 22000, loss: 0.002688
 >> iter 23000, loss: 0.002815
 >> iter 24000, loss: 0.003010
 >> iter 25000, loss: 0.002393
 >> iter 26000, loss: 0.002225
 >> iter 27000, loss: 0.002540
 >> iter 28000, loss: 0.002286
 >> iter 29000, loss: 0.002920
 >> iter 30000, loss: 0.002555
   Number of active neurons: 10
 >> iter 31000, loss: 0.025337
 >> iter 32000, loss: 0.033274
 >> iter 33000, loss: 0.013879
 >> iter 34000, loss: 0.008249
 >> iter 35000, loss: 0.004292
 >> iter 36000, loss: 0.003251
 >> iter 37000, loss: 0.006680
 >> iter 38000, loss: 0.067223
 >> iter 39000, loss: 0.026181
 >> iter 40000, loss: 0.010651
   Number of active neurons: 10
 >> iter 41000, loss: 0.004876
 >> iter 42000, loss: 0.002700
 >> iter 43000, loss: 0.002012
 >> iter 44000, loss: 0.001738
 >> iter 45000, loss: 0.001424
 >> iter 46000, loss: 0.001284
 >> iter 47000, loss: 0.002728
 >> iter 48000, loss: 0.001953
 >> iter 49000, loss: 0.020806
 >> iter 50000, loss: 0.009150
   Number of active neurons: 10
 >> iter 51000, loss: 0.004134
 >> iter 52000, loss: 0.002553
 >> iter 53000, loss: 0.001721
 >> iter 54000, loss: 0.002109
 >> iter 55000, loss: 0.001623
 >> iter 56000, loss: 0.001295
 >> iter 57000, loss: 0.001107
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 17.102009
 >> iter 2000, loss: 7.782761
 >> iter 3000, loss: 3.063045
 >> iter 4000, loss: 1.426440
 >> iter 5000, loss: 0.540713
 >> iter 6000, loss: 0.281095
 >> iter 7000, loss: 0.111331
 >> iter 8000, loss: 0.145939
 >> iter 9000, loss: 0.100312
 >> iter 10000, loss: 0.042307
   Number of active neurons: 10
 >> iter 11000, loss: 0.065909
 >> iter 12000, loss: 0.038354
 >> iter 13000, loss: 0.034239
 >> iter 14000, loss: 0.099554
 >> iter 15000, loss: 0.044903
 >> iter 16000, loss: 0.075936
 >> iter 17000, loss: 0.098349
 >> iter 18000, loss: 0.063793
 >> iter 19000, loss: 0.056439
 >> iter 20000, loss: 0.025378
   Number of active neurons: 10
 >> iter 21000, loss: 0.012190
 >> iter 22000, loss: 0.006744
 >> iter 23000, loss: 0.004655
 >> iter 24000, loss: 0.003484
 >> iter 25000, loss: 0.003252
 >> iter 26000, loss: 0.002771
 >> iter 27000, loss: 0.002498
 >> iter 28000, loss: 0.002133
 >> iter 29000, loss: 0.001932
 >> iter 30000, loss: 0.001744
   Number of active neurons: 10
 >> iter 31000, loss: 0.001711
 >> iter 32000, loss: 0.001620
 >> iter 33000, loss: 0.001492
 >> iter 34000, loss: 0.001314
 >> iter 35000, loss: 0.033134
 >> iter 36000, loss: 0.060030
 >> iter 37000, loss: 0.023546
 >> iter 38000, loss: 0.010083
 >> iter 39000, loss: 0.057095
 >> iter 40000, loss: 0.065950
   Number of active neurons: 10
 >> iter 41000, loss: 0.026118
 >> iter 42000, loss: 0.011696
 >> iter 43000, loss: 0.021216
 >> iter 44000, loss: 0.009832
 >> iter 45000, loss: 0.022075
 >> iter 46000, loss: 0.070847
 >> iter 47000, loss: 0.027554
 >> iter 48000, loss: 0.036490
 >> iter 49000, loss: 0.074066
 >> iter 50000, loss: 0.029171
   Number of active neurons: 10
 >> iter 51000, loss: 0.012394
 >> iter 52000, loss: 0.005908
 >> iter 53000, loss: 0.005399
 >> iter 54000, loss: 0.040750
 >> iter 55000, loss: 0.017378
 >> iter 56000, loss: 0.007907
 >> iter 57000, loss: 0.004182
 >> iter 58000, loss: 0.002731
 >> iter 59000, loss: 0.002013
 >> iter 60000, loss: 0.001665
   Number of active neurons: 10
 >> iter 61000, loss: 0.001531
 >> iter 62000, loss: 0.001444
 >> iter 63000, loss: 0.001368
 >> iter 64000, loss: 0.014495
 >> iter 65000, loss: 0.006168
 >> iter 66000, loss: 0.004258
 >> iter 67000, loss: 0.002274
 >> iter 68000, loss: 0.050243
 >> iter 69000, loss: 0.033777
 >> iter 70000, loss: 0.013234
   Number of active neurons: 10
 >> iter 71000, loss: 0.005814
 >> iter 72000, loss: 0.003057
 >> iter 73000, loss: 0.054733
 >> iter 74000, loss: 0.021472
 >> iter 75000, loss: 0.009059
 >> iter 76000, loss: 0.004314
 >> iter 77000, loss: 0.002468
 >> iter 78000, loss: 0.001713
 >> iter 79000, loss: 0.001404
 >> iter 80000, loss: 0.001223
   Number of active neurons: 10
 >> iter 81000, loss: 0.001105
 >> iter 82000, loss: 0.001043
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.033703
 >> iter 2000, loss: 7.674822
 >> iter 3000, loss: 3.063372
 >> iter 4000, loss: 1.364187
 >> iter 5000, loss: 0.649454
 >> iter 6000, loss: 0.320469
 >> iter 7000, loss: 0.262882
 >> iter 8000, loss: 0.282849
 >> iter 9000, loss: 0.116332
 >> iter 10000, loss: 0.088249
   Number of active neurons: 10
 >> iter 11000, loss: 0.221309
 >> iter 12000, loss: 0.089331
 >> iter 13000, loss: 0.133142
 >> iter 14000, loss: 0.067631
 >> iter 15000, loss: 0.030365
 >> iter 16000, loss: 0.024566
 >> iter 17000, loss: 0.213804
 >> iter 18000, loss: 0.097717
 >> iter 19000, loss: 0.042439
 >> iter 20000, loss: 0.040529
   Number of active neurons: 10
 >> iter 21000, loss: 0.072631
 >> iter 22000, loss: 0.029987
 >> iter 23000, loss: 0.013666
 >> iter 24000, loss: 0.007303
 >> iter 25000, loss: 0.004557
 >> iter 26000, loss: 0.003311
 >> iter 27000, loss: 0.003110
 >> iter 28000, loss: 0.010334
 >> iter 29000, loss: 0.019806
 >> iter 30000, loss: 0.135221
   Number of active neurons: 10
 >> iter 31000, loss: 0.052260
 >> iter 32000, loss: 0.021217
 >> iter 33000, loss: 0.010507
 >> iter 34000, loss: 0.064067
 >> iter 35000, loss: 0.270904
 >> iter 36000, loss: 0.105510
 >> iter 37000, loss: 0.042490
 >> iter 38000, loss: 0.136553
 >> iter 39000, loss: 0.053411
 >> iter 40000, loss: 0.208577
   Number of active neurons: 10
 >> iter 41000, loss: 0.081214
 >> iter 42000, loss: 0.035490
 >> iter 43000, loss: 0.015494
 >> iter 44000, loss: 0.007652
 >> iter 45000, loss: 0.004440
 >> iter 46000, loss: 0.003173
 >> iter 47000, loss: 0.002549
 >> iter 48000, loss: 0.002126
 >> iter 49000, loss: 0.001874
 >> iter 50000, loss: 0.001723
   Number of active neurons: 10
 >> iter 51000, loss: 0.001620
 >> iter 52000, loss: 0.001500
 >> iter 53000, loss: 0.001482
 >> iter 54000, loss: 0.001385
 >> iter 55000, loss: 0.001280
 >> iter 56000, loss: 0.001234
 >> iter 57000, loss: 0.001193
 >> iter 58000, loss: 0.001133
 >> iter 59000, loss: 0.001248
 >> iter 60000, loss: 0.001091
   Number of active neurons: 10
 >> iter 61000, loss: 0.001024
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.237514
 >> iter 2000, loss: 8.321515
 >> iter 3000, loss: 3.538477
 >> iter 4000, loss: 1.394413
 >> iter 5000, loss: 0.719324
 >> iter 6000, loss: 0.447839
 >> iter 7000, loss: 0.206656
 >> iter 8000, loss: 0.166659
 >> iter 9000, loss: 0.120411
 >> iter 10000, loss: 0.054618
   Number of active neurons: 10
 >> iter 11000, loss: 0.041658
 >> iter 12000, loss: 0.018698
 >> iter 13000, loss: 0.060943
 >> iter 14000, loss: 0.049617
 >> iter 15000, loss: 0.070147
 >> iter 16000, loss: 0.029532
 >> iter 17000, loss: 0.013757
 >> iter 18000, loss: 0.007544
 >> iter 19000, loss: 0.004677
 >> iter 20000, loss: 0.003388
   Number of active neurons: 10
 >> iter 21000, loss: 0.197013
 >> iter 22000, loss: 0.086073
 >> iter 23000, loss: 0.059028
 >> iter 24000, loss: 0.070660
 >> iter 25000, loss: 0.082996
 >> iter 26000, loss: 0.033370
 >> iter 27000, loss: 0.017961
 >> iter 28000, loss: 0.008593
 >> iter 29000, loss: 0.132124
 >> iter 30000, loss: 0.052162
   Number of active neurons: 10
 >> iter 31000, loss: 0.021442
 >> iter 32000, loss: 0.009666
 >> iter 33000, loss: 0.005085
 >> iter 34000, loss: 0.003176
 >> iter 35000, loss: 0.002350
 >> iter 36000, loss: 0.001905
 >> iter 37000, loss: 0.001700
 >> iter 38000, loss: 0.001570
 >> iter 39000, loss: 0.001510
 >> iter 40000, loss: 0.001378
   Number of active neurons: 10
 >> iter 41000, loss: 0.001228
 >> iter 42000, loss: 0.001157
 >> iter 43000, loss: 0.001085
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.300044
 >> iter 2000, loss: 8.088734
 >> iter 3000, loss: 3.231189
 >> iter 4000, loss: 1.632630
 >> iter 5000, loss: 0.650671
 >> iter 6000, loss: 0.248528
 >> iter 7000, loss: 0.198547
 >> iter 8000, loss: 0.319404
 >> iter 9000, loss: 0.194387
 >> iter 10000, loss: 0.078596
   Number of active neurons: 10
 >> iter 11000, loss: 0.203160
 >> iter 12000, loss: 0.090300
 >> iter 13000, loss: 0.086243
 >> iter 14000, loss: 0.161813
 >> iter 15000, loss: 0.096407
 >> iter 16000, loss: 0.044132
 >> iter 17000, loss: 0.020363
 >> iter 18000, loss: 0.010715
 >> iter 19000, loss: 0.027198
 >> iter 20000, loss: 0.012211
   Number of active neurons: 10
 >> iter 21000, loss: 0.006613
 >> iter 22000, loss: 0.004109
 >> iter 23000, loss: 0.030965
 >> iter 24000, loss: 0.015347
 >> iter 25000, loss: 0.007403
 >> iter 26000, loss: 0.004193
 >> iter 27000, loss: 0.002969
 >> iter 28000, loss: 0.002282
 >> iter 29000, loss: 0.001935
 >> iter 30000, loss: 0.001691
   Number of active neurons: 10
 >> iter 31000, loss: 0.001549
 >> iter 32000, loss: 0.006531
 >> iter 33000, loss: 0.003406
 >> iter 34000, loss: 0.002087
 >> iter 35000, loss: 0.002266
 >> iter 36000, loss: 0.001660
 >> iter 37000, loss: 0.001311
 >> iter 38000, loss: 0.059596
 >> iter 39000, loss: 0.022885
 >> iter 40000, loss: 0.009219
   Number of active neurons: 10
 >> iter 41000, loss: 0.004188
 >> iter 42000, loss: 0.002288
 >> iter 43000, loss: 0.001522
 >> iter 44000, loss: 0.007672
 >> iter 45000, loss: 0.003662
 >> iter 46000, loss: 0.092037
 >> iter 47000, loss: 0.070195
 >> iter 48000, loss: 0.032040
 >> iter 49000, loss: 0.014400
 >> iter 50000, loss: 0.006160
   Number of active neurons: 10
 >> iter 51000, loss: 0.003022
 >> iter 52000, loss: 0.001800
 >> iter 53000, loss: 0.001328
 >> iter 54000, loss: 0.001242
 >> iter 55000, loss: 0.001098
 >> iter 56000, loss: 0.006067
 >> iter 57000, loss: 0.002822
 >> iter 58000, loss: 0.001637
 >> iter 59000, loss: 0.001131
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.052625
 >> iter 2000, loss: 6.739548
 >> iter 3000, loss: 2.887524
 >> iter 4000, loss: 1.146589
 >> iter 5000, loss: 0.513711
 >> iter 6000, loss: 0.330027
 >> iter 7000, loss: 0.146146
 >> iter 8000, loss: 0.221908
 >> iter 9000, loss: 0.092463
 >> iter 10000, loss: 0.044843
   Number of active neurons: 9
 >> iter 11000, loss: 0.282352
 >> iter 12000, loss: 0.286671
 >> iter 13000, loss: 0.218593
 >> iter 14000, loss: 0.229507
 >> iter 15000, loss: 0.338627
 >> iter 16000, loss: 0.132388
 >> iter 17000, loss: 0.085859
 >> iter 18000, loss: 0.036699
 >> iter 19000, loss: 0.049930
 >> iter 20000, loss: 0.085831
   Number of active neurons: 10
 >> iter 21000, loss: 0.050313
 >> iter 22000, loss: 0.044614
 >> iter 23000, loss: 0.021455
 >> iter 24000, loss: 0.012757
 >> iter 25000, loss: 0.007957
 >> iter 26000, loss: 0.043543
 >> iter 27000, loss: 0.060499
 >> iter 28000, loss: 0.025119
 >> iter 29000, loss: 0.082214
 >> iter 30000, loss: 0.032741
   Number of active neurons: 10
 >> iter 31000, loss: 0.014241
 >> iter 32000, loss: 0.007713
 >> iter 33000, loss: 0.032377
 >> iter 34000, loss: 0.014014
 >> iter 35000, loss: 0.007700
 >> iter 36000, loss: 0.004404
 >> iter 37000, loss: 0.002975
 >> iter 38000, loss: 0.002630
 >> iter 39000, loss: 0.002305
 >> iter 40000, loss: 0.002088
   Number of active neurons: 10
 >> iter 41000, loss: 0.002292
 >> iter 42000, loss: 0.007882
 >> iter 43000, loss: 0.078608
 >> iter 44000, loss: 0.081534
 >> iter 45000, loss: 0.033540
 >> iter 46000, loss: 0.013534
 >> iter 47000, loss: 0.006624
 >> iter 48000, loss: 0.003375
 >> iter 49000, loss: 0.005742
 >> iter 50000, loss: 0.112554
   Number of active neurons: 10
 >> iter 51000, loss: 0.044284
 >> iter 52000, loss: 0.017505
 >> iter 53000, loss: 0.007427
 >> iter 54000, loss: 0.003672
 >> iter 55000, loss: 0.002216
 >> iter 56000, loss: 0.001624
 >> iter 57000, loss: 0.001519
 >> iter 58000, loss: 0.019777
 >> iter 59000, loss: 0.098781
 >> iter 60000, loss: 0.037953
   Number of active neurons: 10
 >> iter 61000, loss: 0.150471
 >> iter 62000, loss: 0.105668
 >> iter 63000, loss: 0.042886
 >> iter 64000, loss: 0.017495
 >> iter 65000, loss: 0.043283
 >> iter 66000, loss: 0.018592
 >> iter 67000, loss: 0.008476
 >> iter 68000, loss: 0.004565
 >> iter 69000, loss: 0.003147
 >> iter 70000, loss: 0.002384
   Number of active neurons: 10
 >> iter 71000, loss: 0.002146
 >> iter 72000, loss: 0.049639
 >> iter 73000, loss: 0.019569
 >> iter 74000, loss: 0.008388
 >> iter 75000, loss: 0.004187
 >> iter 76000, loss: 0.002699
 >> iter 77000, loss: 0.025422
 >> iter 78000, loss: 0.010450
 >> iter 79000, loss: 0.004831
 >> iter 80000, loss: 0.054257
   Number of active neurons: 10
 >> iter 81000, loss: 0.021030
 >> iter 82000, loss: 0.008736
 >> iter 83000, loss: 0.011842
 >> iter 84000, loss: 0.037354
 >> iter 85000, loss: 0.014808
 >> iter 86000, loss: 0.006463
 >> iter 87000, loss: 0.133935
 >> iter 88000, loss: 0.060232
 >> iter 89000, loss: 0.024004
 >> iter 90000, loss: 0.010305
   Number of active neurons: 10
 >> iter 91000, loss: 0.005104
 >> iter 92000, loss: 0.003049
 >> iter 93000, loss: 0.002144
 >> iter 94000, loss: 0.001727
 >> iter 95000, loss: 0.001532
 >> iter 96000, loss: 0.001379
 >> iter 97000, loss: 0.001287
 >> iter 98000, loss: 0.001175
 >> iter 99000, loss: 0.001420
 >> iter 100000, loss: 0.001236
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.971292
 >> iter 2000, loss: 7.274898
 >> iter 3000, loss: 2.989400
 >> iter 4000, loss: 1.134004
 >> iter 5000, loss: 0.697059
 >> iter 6000, loss: 0.657039
 >> iter 7000, loss: 0.516027
 >> iter 8000, loss: 0.265039
 >> iter 9000, loss: 0.105842
 >> iter 10000, loss: 0.134396
   Number of active neurons: 10
 >> iter 11000, loss: 0.124769
 >> iter 12000, loss: 0.058354
 >> iter 13000, loss: 0.025334
 >> iter 14000, loss: 0.096008
 >> iter 15000, loss: 0.039203
 >> iter 16000, loss: 0.017444
 >> iter 17000, loss: 0.009305
 >> iter 18000, loss: 0.008850
 >> iter 19000, loss: 0.005899
 >> iter 20000, loss: 0.003673
   Number of active neurons: 10
 >> iter 21000, loss: 0.046699
 >> iter 22000, loss: 0.026772
 >> iter 23000, loss: 0.039641
 >> iter 24000, loss: 0.016469
 >> iter 25000, loss: 0.036635
 >> iter 26000, loss: 0.015106
 >> iter 27000, loss: 0.007014
 >> iter 28000, loss: 0.003917
 >> iter 29000, loss: 0.002660
 >> iter 30000, loss: 0.002226
   Number of active neurons: 10
 >> iter 31000, loss: 0.068431
 >> iter 32000, loss: 0.028622
 >> iter 33000, loss: 0.150670
 >> iter 34000, loss: 0.061812
 >> iter 35000, loss: 0.026219
 >> iter 36000, loss: 0.023990
 >> iter 37000, loss: 0.147208
 >> iter 38000, loss: 0.079950
 >> iter 39000, loss: 0.032200
 >> iter 40000, loss: 0.013888
   Number of active neurons: 10
 >> iter 41000, loss: 0.006938
 >> iter 42000, loss: 0.004107
 >> iter 43000, loss: 0.002927
 >> iter 44000, loss: 0.008285
 >> iter 45000, loss: 0.005695
 >> iter 46000, loss: 0.003345
 >> iter 47000, loss: 0.015641
 >> iter 48000, loss: 0.088485
 >> iter 49000, loss: 0.034190
 >> iter 50000, loss: 0.037943
   Number of active neurons: 10
 >> iter 51000, loss: 0.075319
 >> iter 52000, loss: 0.134608
 >> iter 53000, loss: 0.059413
 >> iter 54000, loss: 0.023796
 >> iter 55000, loss: 0.010552
 >> iter 56000, loss: 0.005280
 >> iter 57000, loss: 0.003199
 >> iter 58000, loss: 0.014907
 >> iter 59000, loss: 0.006652
 >> iter 60000, loss: 0.003587
   Number of active neurons: 10
 >> iter 61000, loss: 0.002287
 >> iter 62000, loss: 0.053964
 >> iter 63000, loss: 0.021103
 >> iter 64000, loss: 0.008920
 >> iter 65000, loss: 0.004787
 >> iter 66000, loss: 0.002652
 >> iter 67000, loss: 0.001804
 >> iter 68000, loss: 0.001440
 >> iter 69000, loss: 0.056225
 >> iter 70000, loss: 0.057835
   Number of active neurons: 10
 >> iter 71000, loss: 0.022478
 >> iter 72000, loss: 0.195361
 >> iter 73000, loss: 0.155974
 >> iter 74000, loss: 0.067561
 >> iter 75000, loss: 0.027092
 >> iter 76000, loss: 0.011939
 >> iter 77000, loss: 0.005888
 >> iter 78000, loss: 0.003506
 >> iter 79000, loss: 0.002490
 >> iter 80000, loss: 0.004741
   Number of active neurons: 10
 >> iter 81000, loss: 0.018032
 >> iter 82000, loss: 0.007844
 >> iter 83000, loss: 0.003979
 >> iter 84000, loss: 0.002347
 >> iter 85000, loss: 0.001729
 >> iter 86000, loss: 0.001396
 >> iter 87000, loss: 0.001264
 >> iter 88000, loss: 0.001172
 >> iter 89000, loss: 0.001156
 >> iter 90000, loss: 0.001029
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.130677
 >> iter 2000, loss: 7.574100
 >> iter 3000, loss: 3.145562
 >> iter 4000, loss: 1.314876
 >> iter 5000, loss: 0.518246
 >> iter 6000, loss: 0.253319
 >> iter 7000, loss: 0.129099
 >> iter 8000, loss: 0.052862
 >> iter 9000, loss: 0.113067
 >> iter 10000, loss: 0.079495
   Number of active neurons: 10
 >> iter 11000, loss: 0.049966
 >> iter 12000, loss: 0.158232
 >> iter 13000, loss: 0.094128
 >> iter 14000, loss: 0.045727
 >> iter 15000, loss: 0.020031
 >> iter 16000, loss: 0.015163
 >> iter 17000, loss: 0.007894
 >> iter 18000, loss: 0.004947
 >> iter 19000, loss: 0.003564
 >> iter 20000, loss: 0.156678
   Number of active neurons: 10
 >> iter 21000, loss: 0.060790
 >> iter 22000, loss: 0.024814
 >> iter 23000, loss: 0.046389
 >> iter 24000, loss: 0.019965
 >> iter 25000, loss: 0.009390
 >> iter 26000, loss: 0.005230
 >> iter 27000, loss: 0.003809
 >> iter 28000, loss: 0.011299
 >> iter 29000, loss: 0.005714
 >> iter 30000, loss: 0.003598
   Number of active neurons: 10
 >> iter 31000, loss: 0.057771
 >> iter 32000, loss: 0.023000
 >> iter 33000, loss: 0.009567
 >> iter 34000, loss: 0.004481
 >> iter 35000, loss: 0.011933
 >> iter 36000, loss: 0.005518
 >> iter 37000, loss: 0.002991
 >> iter 38000, loss: 0.002008
 >> iter 39000, loss: 0.001890
 >> iter 40000, loss: 0.001498
   Number of active neurons: 10
 >> iter 41000, loss: 0.001315
 >> iter 42000, loss: 0.001336
 >> iter 43000, loss: 0.001109
 >> iter 44000, loss: 0.001027
 >> iter 45000, loss: 0.049822
 >> iter 46000, loss: 0.064166
 >> iter 47000, loss: 0.077083
 >> iter 48000, loss: 0.029575
 >> iter 49000, loss: 0.120859
 >> iter 50000, loss: 0.046637
   Number of active neurons: 10
 >> iter 51000, loss: 0.050342
 >> iter 52000, loss: 0.020338
 >> iter 53000, loss: 0.008925
 >> iter 54000, loss: 0.004494
 >> iter 55000, loss: 0.003242
 >> iter 56000, loss: 0.002433
 >> iter 57000, loss: 0.001858
 >> iter 58000, loss: 0.001544
 >> iter 59000, loss: 0.002178
 >> iter 60000, loss: 0.001588
   Number of active neurons: 10
 >> iter 61000, loss: 0.037916
 >> iter 62000, loss: 0.015186
 >> iter 63000, loss: 0.006549
 >> iter 64000, loss: 0.066878
 >> iter 65000, loss: 0.111753
 >> iter 66000, loss: 0.043531
 >> iter 67000, loss: 0.080262
 >> iter 68000, loss: 0.031387
 >> iter 69000, loss: 0.013134
 >> iter 70000, loss: 0.006088
   Number of active neurons: 10
 >> iter 71000, loss: 0.003438
 >> iter 72000, loss: 0.002238
 >> iter 73000, loss: 0.001764
 >> iter 74000, loss: 0.001426
 >> iter 75000, loss: 0.001278
 >> iter 76000, loss: 0.001154
 >> iter 77000, loss: 0.001083
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 16.957986
 >> iter 2000, loss: 7.353447
 >> iter 3000, loss: 3.172034
 >> iter 4000, loss: 1.243081
 >> iter 5000, loss: 0.504921
 >> iter 6000, loss: 0.233789
 >> iter 7000, loss: 0.150924
 >> iter 8000, loss: 0.256360
 >> iter 9000, loss: 0.223269
 >> iter 10000, loss: 0.089356
   Number of active neurons: 10
 >> iter 11000, loss: 0.037049
 >> iter 12000, loss: 0.055589
 >> iter 13000, loss: 0.046566
 >> iter 14000, loss: 0.050367
 >> iter 15000, loss: 0.021825
 >> iter 16000, loss: 0.031412
 >> iter 17000, loss: 0.014371
 >> iter 18000, loss: 0.007362
 >> iter 19000, loss: 0.004547
 >> iter 20000, loss: 0.003178
   Number of active neurons: 10
 >> iter 21000, loss: 0.002647
 >> iter 22000, loss: 0.002213
 >> iter 23000, loss: 0.002040
 >> iter 24000, loss: 0.001771
 >> iter 25000, loss: 0.001585
 >> iter 26000, loss: 0.052838
 >> iter 27000, loss: 0.099150
 >> iter 28000, loss: 0.038929
 >> iter 29000, loss: 0.015722
 >> iter 30000, loss: 0.007141
   Number of active neurons: 10
 >> iter 31000, loss: 0.006903
 >> iter 32000, loss: 0.003676
 >> iter 33000, loss: 0.103121
 >> iter 34000, loss: 0.139180
 >> iter 35000, loss: 0.054043
 >> iter 36000, loss: 0.022201
 >> iter 37000, loss: 0.010610
 >> iter 38000, loss: 0.066970
 >> iter 39000, loss: 0.128030
 >> iter 40000, loss: 0.051030
   Number of active neurons: 10
 >> iter 41000, loss: 0.020986
 >> iter 42000, loss: 0.010465
 >> iter 43000, loss: 0.005650
 >> iter 44000, loss: 0.034169
 >> iter 45000, loss: 0.014871
 >> iter 46000, loss: 0.007072
 >> iter 47000, loss: 0.003995
 >> iter 48000, loss: 0.002741
 >> iter 49000, loss: 0.002102
 >> iter 50000, loss: 0.001726
   Number of active neurons: 10
 >> iter 51000, loss: 0.001538
 >> iter 52000, loss: 0.001398
 >> iter 53000, loss: 0.001293
 >> iter 54000, loss: 0.001212
 >> iter 55000, loss: 0.001122
 >> iter 56000, loss: 0.001042
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.987736
 >> iter 2000, loss: 7.870163
 >> iter 3000, loss: 3.168057
 >> iter 4000, loss: 1.187373
 >> iter 5000, loss: 0.461022
 >> iter 6000, loss: 0.378438
 >> iter 7000, loss: 0.275395
 >> iter 8000, loss: 0.152673
 >> iter 9000, loss: 0.132437
 >> iter 10000, loss: 0.098320
   Number of active neurons: 10
 >> iter 11000, loss: 0.115415
 >> iter 12000, loss: 0.101550
 >> iter 13000, loss: 0.042031
 >> iter 14000, loss: 0.018632
 >> iter 15000, loss: 0.035536
 >> iter 16000, loss: 0.015608
 >> iter 17000, loss: 0.007815
 >> iter 18000, loss: 0.004611
 >> iter 19000, loss: 0.003477
 >> iter 20000, loss: 0.085601
   Number of active neurons: 10
 >> iter 21000, loss: 0.209248
 >> iter 22000, loss: 0.083187
 >> iter 23000, loss: 0.033477
 >> iter 24000, loss: 0.014415
 >> iter 25000, loss: 0.007302
 >> iter 26000, loss: 0.004279
 >> iter 27000, loss: 0.002901
 >> iter 28000, loss: 0.002267
 >> iter 29000, loss: 0.001878
 >> iter 30000, loss: 0.001667
   Number of active neurons: 10
 >> iter 31000, loss: 0.001532
 >> iter 32000, loss: 0.091607
 >> iter 33000, loss: 0.052713
 >> iter 34000, loss: 0.059665
 >> iter 35000, loss: 0.023482
 >> iter 36000, loss: 0.009888
 >> iter 37000, loss: 0.004808
 >> iter 38000, loss: 0.005297
 >> iter 39000, loss: 0.024925
 >> iter 40000, loss: 0.010623
   Number of active neurons: 10
 >> iter 41000, loss: 0.013917
 >> iter 42000, loss: 0.006734
 >> iter 43000, loss: 0.003599
 >> iter 44000, loss: 0.002585
 >> iter 45000, loss: 0.001830
 >> iter 46000, loss: 0.108667
 >> iter 47000, loss: 0.041558
 >> iter 48000, loss: 0.016966
 >> iter 49000, loss: 0.007360
 >> iter 50000, loss: 0.003708
   Number of active neurons: 10
 >> iter 51000, loss: 0.002291
 >> iter 52000, loss: 0.001672
 >> iter 53000, loss: 0.001463
 >> iter 54000, loss: 0.001303
 >> iter 55000, loss: 0.001176
 >> iter 56000, loss: 0.001100
 >> iter 57000, loss: 0.001001
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.994037
 >> iter 2000, loss: 7.872503
 >> iter 3000, loss: 3.275161
 >> iter 4000, loss: 1.315765
 >> iter 5000, loss: 0.759302
 >> iter 6000, loss: 0.401085
 >> iter 7000, loss: 0.292622
 >> iter 8000, loss: 0.182551
 >> iter 9000, loss: 0.075196
 >> iter 10000, loss: 0.034461
   Number of active neurons: 10
 >> iter 11000, loss: 0.036270
 >> iter 12000, loss: 0.186566
 >> iter 13000, loss: 0.074791
 >> iter 14000, loss: 0.031985
 >> iter 15000, loss: 0.035734
 >> iter 16000, loss: 0.050112
 >> iter 17000, loss: 0.022627
 >> iter 18000, loss: 0.028817
 >> iter 19000, loss: 0.013881
 >> iter 20000, loss: 0.007832
   Number of active neurons: 10
 >> iter 21000, loss: 0.004949
 >> iter 22000, loss: 0.003929
 >> iter 23000, loss: 0.007217
 >> iter 24000, loss: 0.067526
 >> iter 25000, loss: 0.043583
 >> iter 26000, loss: 0.018130
 >> iter 27000, loss: 0.008532
 >> iter 28000, loss: 0.008265
 >> iter 29000, loss: 0.004948
 >> iter 30000, loss: 0.003375
   Number of active neurons: 10
 >> iter 31000, loss: 0.002654
 >> iter 32000, loss: 0.002330
 >> iter 33000, loss: 0.002234
 >> iter 34000, loss: 0.002919
 >> iter 35000, loss: 0.002531
 >> iter 36000, loss: 0.018441
 >> iter 37000, loss: 0.009558
 >> iter 38000, loss: 0.004647
 >> iter 39000, loss: 0.002852
 >> iter 40000, loss: 0.002027
   Number of active neurons: 10
 >> iter 41000, loss: 0.001659
 >> iter 42000, loss: 0.001506
 >> iter 43000, loss: 0.001428
 >> iter 44000, loss: 0.001374
 >> iter 45000, loss: 0.011267
 >> iter 46000, loss: 0.008885
 >> iter 47000, loss: 0.010201
 >> iter 48000, loss: 0.019123
 >> iter 49000, loss: 0.007933
 >> iter 50000, loss: 0.003758
   Number of active neurons: 10
 >> iter 51000, loss: 0.016600
 >> iter 52000, loss: 0.009431
 >> iter 53000, loss: 0.004864
 >> iter 54000, loss: 0.002573
 >> iter 55000, loss: 0.001698
 >> iter 56000, loss: 0.001314
 >> iter 57000, loss: 0.001165
 >> iter 58000, loss: 0.001134
 >> iter 59000, loss: 0.001133
 >> iter 60000, loss: 0.001034
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.121581
 >> iter 2000, loss: 7.724242
 >> iter 3000, loss: 3.493518
 >> iter 4000, loss: 1.398379
 >> iter 5000, loss: 0.532705
 >> iter 6000, loss: 0.361928
 >> iter 7000, loss: 0.215232
 >> iter 8000, loss: 0.248359
 >> iter 9000, loss: 0.202052
 >> iter 10000, loss: 0.147366
   Number of active neurons: 10
 >> iter 11000, loss: 0.205351
 >> iter 12000, loss: 0.197971
 >> iter 13000, loss: 0.079253
 >> iter 14000, loss: 0.127916
 >> iter 15000, loss: 0.052425
 >> iter 16000, loss: 0.048748
 >> iter 17000, loss: 0.021658
 >> iter 18000, loss: 0.043044
 >> iter 19000, loss: 0.080503
 >> iter 20000, loss: 0.034268
   Number of active neurons: 10
 >> iter 21000, loss: 0.016503
 >> iter 22000, loss: 0.008482
 >> iter 23000, loss: 0.005140
 >> iter 24000, loss: 0.175212
 >> iter 25000, loss: 0.067338
 >> iter 26000, loss: 0.027593
 >> iter 27000, loss: 0.037460
 >> iter 28000, loss: 0.016037
 >> iter 29000, loss: 0.007608
 >> iter 30000, loss: 0.004492
   Number of active neurons: 10
 >> iter 31000, loss: 0.002954
 >> iter 32000, loss: 0.002352
 >> iter 33000, loss: 0.002453
 >> iter 34000, loss: 0.001940
 >> iter 35000, loss: 0.002133
 >> iter 36000, loss: 0.001672
 >> iter 37000, loss: 0.001445
 >> iter 38000, loss: 0.001302
 >> iter 39000, loss: 0.001508
 >> iter 40000, loss: 0.001270
   Number of active neurons: 10
 >> iter 41000, loss: 0.001143
 >> iter 42000, loss: 0.046203
 >> iter 43000, loss: 0.017967
 >> iter 44000, loss: 0.007518
 >> iter 45000, loss: 0.015287
 >> iter 46000, loss: 0.006639
 >> iter 47000, loss: 0.003208
 >> iter 48000, loss: 0.001930
 >> iter 49000, loss: 0.001377
 >> iter 50000, loss: 0.001232
   Number of active neurons: 10
 >> iter 51000, loss: 0.085384
 >> iter 52000, loss: 0.032237
 >> iter 53000, loss: 0.012810
 >> iter 54000, loss: 0.005688
 >> iter 55000, loss: 0.002775
 >> iter 56000, loss: 0.001719
 >> iter 57000, loss: 0.001304
 >> iter 58000, loss: 0.001286
 >> iter 59000, loss: 0.001179
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.052218
 >> iter 2000, loss: 7.520576
 >> iter 3000, loss: 3.079968
 >> iter 4000, loss: 1.336136
 >> iter 5000, loss: 0.676142
 >> iter 6000, loss: 0.381114
 >> iter 7000, loss: 0.321080
 >> iter 8000, loss: 0.549547
 >> iter 9000, loss: 0.265361
 >> iter 10000, loss: 0.105304
   Number of active neurons: 10
 >> iter 11000, loss: 0.203952
 >> iter 12000, loss: 0.118737
 >> iter 13000, loss: 0.048856
 >> iter 14000, loss: 0.030234
 >> iter 15000, loss: 0.014472
 >> iter 16000, loss: 0.074239
 >> iter 17000, loss: 0.170419
 >> iter 18000, loss: 0.080442
 >> iter 19000, loss: 0.087810
 >> iter 20000, loss: 0.109488
   Number of active neurons: 10
 >> iter 21000, loss: 0.193137
 >> iter 22000, loss: 0.139474
 >> iter 23000, loss: 0.113392
 >> iter 24000, loss: 0.219921
 >> iter 25000, loss: 0.087067
 >> iter 26000, loss: 0.036059
 >> iter 27000, loss: 0.016597
 >> iter 28000, loss: 0.008690
 >> iter 29000, loss: 0.006219
 >> iter 30000, loss: 0.030051
   Number of active neurons: 10
 >> iter 31000, loss: 0.015569
 >> iter 32000, loss: 0.008773
 >> iter 33000, loss: 0.005098
 >> iter 34000, loss: 0.006467
 >> iter 35000, loss: 0.003862
 >> iter 36000, loss: 0.002835
 >> iter 37000, loss: 0.033508
 >> iter 38000, loss: 0.025250
 >> iter 39000, loss: 0.031386
 >> iter 40000, loss: 0.013083
   Number of active neurons: 10
 >> iter 41000, loss: 0.035930
 >> iter 42000, loss: 0.014804
 >> iter 43000, loss: 0.006951
 >> iter 44000, loss: 0.003790
 >> iter 45000, loss: 0.002594
 >> iter 46000, loss: 0.002481
 >> iter 47000, loss: 0.002107
 >> iter 48000, loss: 0.001896
 >> iter 49000, loss: 0.001640
 >> iter 50000, loss: 0.001491
   Number of active neurons: 10
 >> iter 51000, loss: 0.001424
 >> iter 52000, loss: 0.001300
 >> iter 53000, loss: 0.001232
 >> iter 54000, loss: 0.001161
 >> iter 55000, loss: 0.001120
 >> iter 56000, loss: 0.001644
 >> iter 57000, loss: 0.011588
 >> iter 58000, loss: 0.005056
 >> iter 59000, loss: 0.243882
 >> iter 60000, loss: 0.092326
   Number of active neurons: 10
 >> iter 61000, loss: 0.036084
 >> iter 62000, loss: 0.014933
 >> iter 63000, loss: 0.006985
 >> iter 64000, loss: 0.003957
 >> iter 65000, loss: 0.002624
 >> iter 66000, loss: 0.002035
 >> iter 67000, loss: 0.001830
 >> iter 68000, loss: 0.013568
 >> iter 69000, loss: 0.006116
 >> iter 70000, loss: 0.003184
   Number of active neurons: 10
 >> iter 71000, loss: 0.002058
 >> iter 72000, loss: 0.097212
 >> iter 73000, loss: 0.037671
 >> iter 74000, loss: 0.015457
 >> iter 75000, loss: 0.007105
 >> iter 76000, loss: 0.025335
 >> iter 77000, loss: 0.010699
 >> iter 78000, loss: 0.007125
 >> iter 79000, loss: 0.005299
 >> iter 80000, loss: 0.002926
   Number of active neurons: 10
 >> iter 81000, loss: 0.002054
 >> iter 82000, loss: 0.001611
 >> iter 83000, loss: 0.001461
 >> iter 84000, loss: 0.001294
 >> iter 85000, loss: 0.001206
 >> iter 86000, loss: 0.010915
 >> iter 87000, loss: 0.005324
 >> iter 88000, loss: 0.002694
 >> iter 89000, loss: 0.011600
 >> iter 90000, loss: 0.383073
   Number of active neurons: 10
 >> iter 91000, loss: 0.143718
 >> iter 92000, loss: 0.054824
 >> iter 93000, loss: 0.021708
 >> iter 94000, loss: 0.009191
 >> iter 95000, loss: 0.097828
 >> iter 96000, loss: 0.037303
 >> iter 97000, loss: 0.029459
 >> iter 98000, loss: 0.015664
 >> iter 99000, loss: 0.007008
 >> iter 100000, loss: 0.034825
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.655554
 >> iter 2000, loss: 7.825158
 >> iter 3000, loss: 3.134580
 >> iter 4000, loss: 1.493455
 >> iter 5000, loss: 0.573091
 >> iter 6000, loss: 0.431305
 >> iter 7000, loss: 0.449947
 >> iter 8000, loss: 0.209331
 >> iter 9000, loss: 0.159283
 >> iter 10000, loss: 0.279262
   Number of active neurons: 10
 >> iter 11000, loss: 0.121721
 >> iter 12000, loss: 0.050386
 >> iter 13000, loss: 0.032750
 >> iter 14000, loss: 0.015462
 >> iter 15000, loss: 0.008832
 >> iter 16000, loss: 0.265630
 >> iter 17000, loss: 0.104099
 >> iter 18000, loss: 0.042503
 >> iter 19000, loss: 0.026610
 >> iter 20000, loss: 0.086199
   Number of active neurons: 10
 >> iter 21000, loss: 0.035435
 >> iter 22000, loss: 0.033296
 >> iter 23000, loss: 0.070944
 >> iter 24000, loss: 0.030426
 >> iter 25000, loss: 0.013487
 >> iter 26000, loss: 0.007575
 >> iter 27000, loss: 0.004517
 >> iter 28000, loss: 0.003220
 >> iter 29000, loss: 0.002564
 >> iter 30000, loss: 0.002282
   Number of active neurons: 10
 >> iter 31000, loss: 0.002035
 >> iter 32000, loss: 0.086162
 >> iter 33000, loss: 0.072423
 >> iter 34000, loss: 0.032246
 >> iter 35000, loss: 0.013884
 >> iter 36000, loss: 0.006749
 >> iter 37000, loss: 0.014222
 >> iter 38000, loss: 0.006641
 >> iter 39000, loss: 0.010045
 >> iter 40000, loss: 0.004940
   Number of active neurons: 10
 >> iter 41000, loss: 0.042496
 >> iter 42000, loss: 0.017079
 >> iter 43000, loss: 0.009798
 >> iter 44000, loss: 0.015396
 >> iter 45000, loss: 0.007099
 >> iter 46000, loss: 0.045332
 >> iter 47000, loss: 0.018037
 >> iter 48000, loss: 0.007815
 >> iter 49000, loss: 0.005769
 >> iter 50000, loss: 0.003199
   Number of active neurons: 10
 >> iter 51000, loss: 0.002197
 >> iter 52000, loss: 0.028887
 >> iter 53000, loss: 0.011871
 >> iter 54000, loss: 0.005467
 >> iter 55000, loss: 0.002996
 >> iter 56000, loss: 0.002147
 >> iter 57000, loss: 0.001642
 >> iter 58000, loss: 0.001408
 >> iter 59000, loss: 0.001283
 >> iter 60000, loss: 0.001171
   Number of active neurons: 10
 >> iter 61000, loss: 0.008893
 >> iter 62000, loss: 0.004090
 >> iter 63000, loss: 0.002261
 >> iter 64000, loss: 0.001540
 >> iter 65000, loss: 0.001300
 >> iter 66000, loss: 0.048917
 >> iter 67000, loss: 0.018802
 >> iter 68000, loss: 0.007698
 >> iter 69000, loss: 0.003554
 >> iter 70000, loss: 0.001958
   Number of active neurons: 10
 >> iter 71000, loss: 0.001341
 >> iter 72000, loss: 0.001089
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.812213
 >> iter 2000, loss: 7.460410
 >> iter 3000, loss: 3.329165
 >> iter 4000, loss: 1.526285
 >> iter 5000, loss: 0.637296
 >> iter 6000, loss: 0.315998
 >> iter 7000, loss: 0.161338
 >> iter 8000, loss: 0.311685
 >> iter 9000, loss: 0.135925
 >> iter 10000, loss: 0.089333
   Number of active neurons: 10
 >> iter 11000, loss: 0.102410
 >> iter 12000, loss: 0.066040
 >> iter 13000, loss: 0.039790
 >> iter 14000, loss: 0.031010
 >> iter 15000, loss: 0.014849
 >> iter 16000, loss: 0.007802
 >> iter 17000, loss: 0.005058
 >> iter 18000, loss: 0.008126
 >> iter 19000, loss: 0.004658
 >> iter 20000, loss: 0.003400
   Number of active neurons: 10
 >> iter 21000, loss: 0.006043
 >> iter 22000, loss: 0.003716
 >> iter 23000, loss: 0.031131
 >> iter 24000, loss: 0.012868
 >> iter 25000, loss: 0.015071
 >> iter 26000, loss: 0.056482
 >> iter 27000, loss: 0.099560
 >> iter 28000, loss: 0.089334
 >> iter 29000, loss: 0.036346
 >> iter 30000, loss: 0.015162
   Number of active neurons: 10
 >> iter 31000, loss: 0.034659
 >> iter 32000, loss: 0.016306
 >> iter 33000, loss: 0.007604
 >> iter 34000, loss: 0.004281
 >> iter 35000, loss: 0.002952
 >> iter 36000, loss: 0.002476
 >> iter 37000, loss: 0.002032
 >> iter 38000, loss: 0.003132
 >> iter 39000, loss: 0.002689
 >> iter 40000, loss: 0.002148
   Number of active neurons: 10
 >> iter 41000, loss: 0.001852
 >> iter 42000, loss: 0.001723
 >> iter 43000, loss: 0.001448
 >> iter 44000, loss: 0.001335
 >> iter 45000, loss: 0.001161
 >> iter 46000, loss: 0.001119
 >> iter 47000, loss: 0.001054
 >> iter 48000, loss: 0.001082
 >> iter 49000, loss: 0.001050
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.918689
 >> iter 2000, loss: 7.636718
 >> iter 3000, loss: 2.964267
 >> iter 4000, loss: 1.494856
 >> iter 5000, loss: 0.584582
 >> iter 6000, loss: 0.272707
 >> iter 7000, loss: 0.111511
 >> iter 8000, loss: 0.089517
 >> iter 9000, loss: 0.109035
 >> iter 10000, loss: 0.047407
   Number of active neurons: 10
 >> iter 11000, loss: 0.035731
 >> iter 12000, loss: 0.147261
 >> iter 13000, loss: 0.122242
 >> iter 14000, loss: 0.055619
 >> iter 15000, loss: 0.082659
 >> iter 16000, loss: 0.034351
 >> iter 17000, loss: 0.015741
 >> iter 18000, loss: 0.020478
 >> iter 19000, loss: 0.011211
 >> iter 20000, loss: 0.076557
   Number of active neurons: 10
 >> iter 21000, loss: 0.030682
 >> iter 22000, loss: 0.013601
 >> iter 23000, loss: 0.006754
 >> iter 24000, loss: 0.004037
 >> iter 25000, loss: 0.003057
 >> iter 26000, loss: 0.002425
 >> iter 27000, loss: 0.040892
 >> iter 28000, loss: 0.016624
 >> iter 29000, loss: 0.125161
 >> iter 30000, loss: 0.071182
   Number of active neurons: 10
 >> iter 31000, loss: 0.045650
 >> iter 32000, loss: 0.018927
 >> iter 33000, loss: 0.008746
 >> iter 34000, loss: 0.004803
 >> iter 35000, loss: 0.003302
 >> iter 36000, loss: 0.002504
 >> iter 37000, loss: 0.002078
 >> iter 38000, loss: 0.001861
 >> iter 39000, loss: 0.001768
 >> iter 40000, loss: 0.001590
   Number of active neurons: 10
 >> iter 41000, loss: 0.001475
 >> iter 42000, loss: 0.001433
 >> iter 43000, loss: 0.001571
 >> iter 44000, loss: 0.051806
 >> iter 45000, loss: 0.020690
 >> iter 46000, loss: 0.008759
 >> iter 47000, loss: 0.005435
 >> iter 48000, loss: 0.003045
 >> iter 49000, loss: 0.002050
 >> iter 50000, loss: 0.001614
   Number of active neurons: 10
 >> iter 51000, loss: 0.001432
 >> iter 52000, loss: 0.001270
 >> iter 53000, loss: 0.113461
 >> iter 54000, loss: 0.043709
 >> iter 55000, loss: 0.018547
 >> iter 56000, loss: 0.008140
 >> iter 57000, loss: 0.004132
 >> iter 58000, loss: 0.002518
 >> iter 59000, loss: 0.001855
 >> iter 60000, loss: 0.029955
   Number of active neurons: 10
 >> iter 61000, loss: 0.012087
 >> iter 62000, loss: 0.005271
 >> iter 63000, loss: 0.002758
 >> iter 64000, loss: 0.001720
 >> iter 65000, loss: 0.001308
 >> iter 66000, loss: 0.010963
 >> iter 67000, loss: 0.007082
 >> iter 68000, loss: 0.003325
 >> iter 69000, loss: 0.001842
 >> iter 70000, loss: 0.001634
   Number of active neurons: 10
 >> iter 71000, loss: 0.001161
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.472359
 >> iter 2000, loss: 8.752428
 >> iter 3000, loss: 3.419135
 >> iter 4000, loss: 1.404649
 >> iter 5000, loss: 0.708043
 >> iter 6000, loss: 0.271614
 >> iter 7000, loss: 0.126002
 >> iter 8000, loss: 0.077634
 >> iter 9000, loss: 0.032891
 >> iter 10000, loss: 0.015033
   Number of active neurons: 10
 >> iter 11000, loss: 0.008185
 >> iter 12000, loss: 0.006047
 >> iter 13000, loss: 0.004007
 >> iter 14000, loss: 0.003911
 >> iter 15000, loss: 0.066117
 >> iter 16000, loss: 0.028660
 >> iter 17000, loss: 0.012619
 >> iter 18000, loss: 0.078337
 >> iter 19000, loss: 0.030796
 >> iter 20000, loss: 0.026302
   Number of active neurons: 10
 >> iter 21000, loss: 0.032281
 >> iter 22000, loss: 0.076504
 >> iter 23000, loss: 0.031113
 >> iter 24000, loss: 0.014615
 >> iter 25000, loss: 0.127264
 >> iter 26000, loss: 0.050156
 >> iter 27000, loss: 0.020383
 >> iter 28000, loss: 0.009278
 >> iter 29000, loss: 0.005190
 >> iter 30000, loss: 0.003267
   Number of active neurons: 10
 >> iter 31000, loss: 0.002489
 >> iter 32000, loss: 0.002131
 >> iter 33000, loss: 0.002240
 >> iter 34000, loss: 0.015448
 >> iter 35000, loss: 0.052738
 >> iter 36000, loss: 0.076912
 >> iter 37000, loss: 0.032059
 >> iter 38000, loss: 0.119709
 >> iter 39000, loss: 0.046779
 >> iter 40000, loss: 0.019510
   Number of active neurons: 10
 >> iter 41000, loss: 0.009076
 >> iter 42000, loss: 0.045194
 >> iter 43000, loss: 0.018404
 >> iter 44000, loss: 0.008341
 >> iter 45000, loss: 0.006972
 >> iter 46000, loss: 0.004115
 >> iter 47000, loss: 0.002653
 >> iter 48000, loss: 0.002048
 >> iter 49000, loss: 0.001698
 >> iter 50000, loss: 0.001522
   Number of active neurons: 10
 >> iter 51000, loss: 0.001412
 >> iter 52000, loss: 0.001318
 >> iter 53000, loss: 0.001162
 >> iter 54000, loss: 0.001059
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.880538
 >> iter 2000, loss: 7.064704
 >> iter 3000, loss: 2.946760
 >> iter 4000, loss: 1.421394
 >> iter 5000, loss: 0.583123
 >> iter 6000, loss: 0.532913
 >> iter 7000, loss: 0.287340
 >> iter 8000, loss: 0.239714
 >> iter 9000, loss: 0.157285
 >> iter 10000, loss: 0.067964
   Number of active neurons: 10
 >> iter 11000, loss: 0.063315
 >> iter 12000, loss: 0.227767
 >> iter 13000, loss: 0.089908
 >> iter 14000, loss: 0.053290
 >> iter 15000, loss: 0.023303
 >> iter 16000, loss: 0.055295
 >> iter 17000, loss: 0.092186
 >> iter 18000, loss: 0.087328
 >> iter 19000, loss: 0.036093
 >> iter 20000, loss: 0.016379
   Number of active neurons: 10
 >> iter 21000, loss: 0.019183
 >> iter 22000, loss: 0.110661
 >> iter 23000, loss: 0.043710
 >> iter 24000, loss: 0.018483
 >> iter 25000, loss: 0.083897
 >> iter 26000, loss: 0.033729
 >> iter 27000, loss: 0.014720
 >> iter 28000, loss: 0.008358
 >> iter 29000, loss: 0.015827
 >> iter 30000, loss: 0.007494
   Number of active neurons: 10
 >> iter 31000, loss: 0.004186
 >> iter 32000, loss: 0.002811
 >> iter 33000, loss: 0.007690
 >> iter 34000, loss: 0.006773
 >> iter 35000, loss: 0.022249
 >> iter 36000, loss: 0.009422
 >> iter 37000, loss: 0.004530
 >> iter 38000, loss: 0.002637
 >> iter 39000, loss: 0.099544
 >> iter 40000, loss: 0.155196
   Number of active neurons: 10
 >> iter 41000, loss: 0.059052
 >> iter 42000, loss: 0.023340
 >> iter 43000, loss: 0.010009
 >> iter 44000, loss: 0.005249
 >> iter 45000, loss: 0.002974
 >> iter 46000, loss: 0.002086
 >> iter 47000, loss: 0.007116
 >> iter 48000, loss: 0.003531
 >> iter 49000, loss: 0.002114
 >> iter 50000, loss: 0.001581
   Number of active neurons: 10
 >> iter 51000, loss: 0.001323
 >> iter 52000, loss: 0.014652
 >> iter 53000, loss: 0.010935
 >> iter 54000, loss: 0.062982
 >> iter 55000, loss: 0.061718
 >> iter 56000, loss: 0.163991
 >> iter 57000, loss: 0.072239
 >> iter 58000, loss: 0.028590
 >> iter 59000, loss: 0.012300
 >> iter 60000, loss: 0.005918
   Number of active neurons: 10
 >> iter 61000, loss: 0.003377
 >> iter 62000, loss: 0.002377
 >> iter 63000, loss: 0.002824
 >> iter 64000, loss: 0.002025
 >> iter 65000, loss: 0.049267
 >> iter 66000, loss: 0.041476
 >> iter 67000, loss: 0.016562
 >> iter 68000, loss: 0.007252
 >> iter 69000, loss: 0.003585
 >> iter 70000, loss: 0.002167
   Number of active neurons: 10
 >> iter 71000, loss: 0.001588
 >> iter 72000, loss: 0.001302
 >> iter 73000, loss: 0.001158
 >> iter 74000, loss: 0.001054
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.027861
 >> iter 2000, loss: 9.173195
 >> iter 3000, loss: 4.073145
 >> iter 4000, loss: 1.862873
 >> iter 5000, loss: 0.855135
 >> iter 6000, loss: 0.396795
 >> iter 7000, loss: 0.165025
 >> iter 8000, loss: 0.076786
 >> iter 9000, loss: 0.146947
 >> iter 10000, loss: 0.286973
   Number of active neurons: 10
 >> iter 11000, loss: 0.112515
 >> iter 12000, loss: 0.160848
 >> iter 13000, loss: 0.077476
 >> iter 14000, loss: 0.087885
 >> iter 15000, loss: 0.101108
 >> iter 16000, loss: 0.228721
 >> iter 17000, loss: 0.226510
 >> iter 18000, loss: 0.154761
 >> iter 19000, loss: 0.081459
 >> iter 20000, loss: 0.036688
   Number of active neurons: 10
 >> iter 21000, loss: 0.051798
 >> iter 22000, loss: 0.022177
 >> iter 23000, loss: 0.013095
 >> iter 24000, loss: 0.064370
 >> iter 25000, loss: 0.055275
 >> iter 26000, loss: 0.045290
 >> iter 27000, loss: 0.018844
 >> iter 28000, loss: 0.026940
 >> iter 29000, loss: 0.017401
 >> iter 30000, loss: 0.182467
   Number of active neurons: 10
 >> iter 31000, loss: 0.071218
 >> iter 32000, loss: 0.029119
 >> iter 33000, loss: 0.237019
 >> iter 34000, loss: 0.120759
 >> iter 35000, loss: 0.047980
 >> iter 36000, loss: 0.020510
 >> iter 37000, loss: 0.009882
 >> iter 38000, loss: 0.005508
 >> iter 39000, loss: 0.003940
 >> iter 40000, loss: 0.006551
   Number of active neurons: 10
 >> iter 41000, loss: 0.003826
 >> iter 42000, loss: 0.002698
 >> iter 43000, loss: 0.002180
 >> iter 44000, loss: 0.031763
 >> iter 45000, loss: 0.171176
 >> iter 46000, loss: 0.067020
 >> iter 47000, loss: 0.027552
 >> iter 48000, loss: 0.012784
 >> iter 49000, loss: 0.048985
 >> iter 50000, loss: 0.209275
   Number of active neurons: 10
 >> iter 51000, loss: 0.082526
 >> iter 52000, loss: 0.033583
 >> iter 53000, loss: 0.014809
 >> iter 54000, loss: 0.007429
 >> iter 55000, loss: 0.016328
 >> iter 56000, loss: 0.007807
 >> iter 57000, loss: 0.034230
 >> iter 58000, loss: 0.037038
 >> iter 59000, loss: 0.015912
 >> iter 60000, loss: 0.007797
   Number of active neurons: 10
 >> iter 61000, loss: 0.004616
 >> iter 62000, loss: 0.003247
 >> iter 63000, loss: 0.046478
 >> iter 64000, loss: 0.018915
 >> iter 65000, loss: 0.012212
 >> iter 66000, loss: 0.006060
 >> iter 67000, loss: 0.003473
 >> iter 68000, loss: 0.002383
 >> iter 69000, loss: 0.001886
 >> iter 70000, loss: 0.126042
   Number of active neurons: 10
 >> iter 71000, loss: 0.047693
 >> iter 72000, loss: 0.018754
 >> iter 73000, loss: 0.237833
 >> iter 74000, loss: 0.090500
 >> iter 75000, loss: 0.035550
 >> iter 76000, loss: 0.014942
 >> iter 77000, loss: 0.007205
 >> iter 78000, loss: 0.004095
 >> iter 79000, loss: 0.002819
 >> iter 80000, loss: 0.002200
   Number of active neurons: 10
 >> iter 81000, loss: 0.002372
 >> iter 82000, loss: 0.022546
 >> iter 83000, loss: 0.009820
 >> iter 84000, loss: 0.005389
 >> iter 85000, loss: 0.020435
 >> iter 86000, loss: 0.009853
 >> iter 87000, loss: 0.007136
 >> iter 88000, loss: 0.005753
 >> iter 89000, loss: 0.003158
 >> iter 90000, loss: 0.002134
   Number of active neurons: 10
 >> iter 91000, loss: 0.001674
 >> iter 92000, loss: 0.001370
 >> iter 93000, loss: 0.001238
 >> iter 94000, loss: 0.003015
 >> iter 95000, loss: 0.001792
 >> iter 96000, loss: 0.001286
 >> iter 97000, loss: 0.001086
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.604619
 >> iter 2000, loss: 7.341608
 >> iter 3000, loss: 3.044557
 >> iter 4000, loss: 1.317202
 >> iter 5000, loss: 0.521049
 >> iter 6000, loss: 0.324163
 >> iter 7000, loss: 0.300998
 >> iter 8000, loss: 0.119200
 >> iter 9000, loss: 0.085958
 >> iter 10000, loss: 0.078887
   Number of active neurons: 10
 >> iter 11000, loss: 0.033752
 >> iter 12000, loss: 0.083453
 >> iter 13000, loss: 0.120342
 >> iter 14000, loss: 0.088250
 >> iter 15000, loss: 0.036698
 >> iter 16000, loss: 0.016781
 >> iter 17000, loss: 0.028058
 >> iter 18000, loss: 0.012970
 >> iter 19000, loss: 0.030517
 >> iter 20000, loss: 0.013218
   Number of active neurons: 10
 >> iter 21000, loss: 0.042989
 >> iter 22000, loss: 0.026478
 >> iter 23000, loss: 0.049618
 >> iter 24000, loss: 0.129459
 >> iter 25000, loss: 0.050211
 >> iter 26000, loss: 0.020433
 >> iter 27000, loss: 0.010542
 >> iter 28000, loss: 0.005327
 >> iter 29000, loss: 0.003329
 >> iter 30000, loss: 0.014113
   Number of active neurons: 10
 >> iter 31000, loss: 0.076604
 >> iter 32000, loss: 0.030292
 >> iter 33000, loss: 0.012951
 >> iter 34000, loss: 0.005988
 >> iter 35000, loss: 0.003290
 >> iter 36000, loss: 0.002200
 >> iter 37000, loss: 0.001723
 >> iter 38000, loss: 0.001444
 >> iter 39000, loss: 0.001284
 >> iter 40000, loss: 0.001252
   Number of active neurons: 10
 >> iter 41000, loss: 0.001158
 >> iter 42000, loss: 0.001078
 >> iter 43000, loss: 0.001012
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

