 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 16.480321
 >> iter 2000, loss: 9.356838
 >> iter 3000, loss: 5.148989
 >> iter 4000, loss: 2.772324
 >> iter 5000, loss: 1.484698
 >> iter 6000, loss: 1.011393
 >> iter 7000, loss: 0.719348
 >> iter 8000, loss: 0.522361
 >> iter 9000, loss: 0.380931
 >> iter 10000, loss: 0.407450
   Number of active neurons: 6
 >> iter 11000, loss: 0.362865
 >> iter 12000, loss: 0.418679
 >> iter 13000, loss: 0.459947
 >> iter 14000, loss: 0.365816
 >> iter 15000, loss: 0.501424
 >> iter 16000, loss: 0.352992
 >> iter 17000, loss: 0.321565
 >> iter 18000, loss: 0.334965
 >> iter 19000, loss: 0.311046
 >> iter 20000, loss: 0.354013
   Number of active neurons: 6
 >> iter 21000, loss: 0.375858
 >> iter 22000, loss: 0.413613
 >> iter 23000, loss: 0.442941
 >> iter 24000, loss: 0.430977
 >> iter 25000, loss: 0.352603
 >> iter 26000, loss: 0.456558
 >> iter 27000, loss: 0.371120
 >> iter 28000, loss: 0.390506
 >> iter 29000, loss: 0.415074
 >> iter 30000, loss: 0.400277
   Number of active neurons: 6
 >> iter 31000, loss: 0.352999
 >> iter 32000, loss: 0.382128
 >> iter 33000, loss: 0.358306
 >> iter 34000, loss: 0.367801
 >> iter 35000, loss: 0.482228
 >> iter 36000, loss: 0.483049
 >> iter 37000, loss: 0.431799
 >> iter 38000, loss: 0.409855
 >> iter 39000, loss: 0.423656
 >> iter 40000, loss: 0.358202
   Number of active neurons: 6
 >> iter 41000, loss: 0.418777
 >> iter 42000, loss: 0.544932
 >> iter 43000, loss: 0.616584
 >> iter 44000, loss: 0.556853
 >> iter 45000, loss: 0.473949
 >> iter 46000, loss: 0.446706
 >> iter 47000, loss: 0.562325
 >> iter 48000, loss: 0.513585
 >> iter 49000, loss: 0.612846
 >> iter 50000, loss: 0.405268
   Number of active neurons: 6
 >> iter 51000, loss: 0.398472
 >> iter 52000, loss: 0.424182
 >> iter 53000, loss: 0.454527
 >> iter 54000, loss: 0.425938
 >> iter 55000, loss: 0.419754
 >> iter 56000, loss: 0.584102
 >> iter 57000, loss: 0.533456
 >> iter 58000, loss: 0.540870
 >> iter 59000, loss: 0.547990
 >> iter 60000, loss: 0.478113
   Number of active neurons: 6
 >> iter 61000, loss: 0.498320
 >> iter 62000, loss: 0.509255
 >> iter 63000, loss: 0.409782
 >> iter 64000, loss: 0.486813
 >> iter 65000, loss: 0.579516
 >> iter 66000, loss: 0.337305
 >> iter 67000, loss: 0.324111
 >> iter 68000, loss: 0.529395
 >> iter 69000, loss: 0.686290
 >> iter 70000, loss: 0.600193
   Number of active neurons: 6
 >> iter 71000, loss: 0.605516
 >> iter 72000, loss: 0.497712
 >> iter 73000, loss: 0.571985
 >> iter 74000, loss: 0.454090
 >> iter 75000, loss: 0.343005
 >> iter 76000, loss: 0.378513
 >> iter 77000, loss: 0.404078
 >> iter 78000, loss: 0.536209
 >> iter 79000, loss: 0.390720
 >> iter 80000, loss: 0.543403
   Number of active neurons: 6
 >> iter 81000, loss: 0.467899
 >> iter 82000, loss: 0.473361
 >> iter 83000, loss: 0.453009
 >> iter 84000, loss: 0.406645
 >> iter 85000, loss: 0.464552
 >> iter 86000, loss: 0.523849
 >> iter 87000, loss: 0.556760
 >> iter 88000, loss: 0.515610
 >> iter 89000, loss: 0.452278
 >> iter 90000, loss: 0.433548
   Number of active neurons: 5
 >> iter 91000, loss: 0.550013
 >> iter 92000, loss: 0.445239
 >> iter 93000, loss: 0.405232
 >> iter 94000, loss: 0.547735
 >> iter 95000, loss: 0.366889
 >> iter 96000, loss: 0.417164
 >> iter 97000, loss: 0.419818
 >> iter 98000, loss: 0.421070
 >> iter 99000, loss: 0.531518
 >> iter 100000, loss: 0.452422
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.346869
 >> iter 2000, loss: 11.341523
 >> iter 3000, loss: 7.347705
 >> iter 4000, loss: 4.452140
 >> iter 5000, loss: 2.703160
 >> iter 6000, loss: 1.730868
 >> iter 7000, loss: 1.229473
 >> iter 8000, loss: 0.980006
 >> iter 9000, loss: 0.823744
 >> iter 10000, loss: 0.789791
   Number of active neurons: 7
 >> iter 11000, loss: 0.708211
 >> iter 12000, loss: 0.699086
 >> iter 13000, loss: 0.573010
 >> iter 14000, loss: 0.543160
 >> iter 15000, loss: 0.456752
 >> iter 16000, loss: 0.416670
 >> iter 17000, loss: 0.542814
 >> iter 18000, loss: 0.437625
 >> iter 19000, loss: 0.606656
 >> iter 20000, loss: 0.512513
   Number of active neurons: 7
 >> iter 21000, loss: 0.393225
 >> iter 22000, loss: 0.299079
 >> iter 23000, loss: 0.377269
 >> iter 24000, loss: 0.437913
 >> iter 25000, loss: 0.263626
 >> iter 26000, loss: 0.409823
 >> iter 27000, loss: 0.563367
 >> iter 28000, loss: 0.491299
 >> iter 29000, loss: 0.457703
 >> iter 30000, loss: 0.463408
   Number of active neurons: 6
 >> iter 31000, loss: 0.402297
 >> iter 32000, loss: 0.274713
 >> iter 33000, loss: 0.250661
 >> iter 34000, loss: 0.264227
 >> iter 35000, loss: 0.351882
 >> iter 36000, loss: 0.273454
 >> iter 37000, loss: 0.365276
 >> iter 38000, loss: 0.327849
 >> iter 39000, loss: 0.438304
 >> iter 40000, loss: 0.374463
   Number of active neurons: 6
 >> iter 41000, loss: 0.318207
 >> iter 42000, loss: 0.291211
 >> iter 43000, loss: 0.387842
 >> iter 44000, loss: 0.319321
 >> iter 45000, loss: 0.429067
 >> iter 46000, loss: 0.475476
 >> iter 47000, loss: 0.388377
 >> iter 48000, loss: 0.268687
 >> iter 49000, loss: 0.386122
 >> iter 50000, loss: 0.416580
   Number of active neurons: 6
 >> iter 51000, loss: 0.361337
 >> iter 52000, loss: 0.364897
 >> iter 53000, loss: 0.311479
 >> iter 54000, loss: 0.239414
 >> iter 55000, loss: 0.326589
 >> iter 56000, loss: 0.271877
 >> iter 57000, loss: 0.255205
 >> iter 58000, loss: 0.290243
 >> iter 59000, loss: 0.265366
 >> iter 60000, loss: 0.237711
   Number of active neurons: 6
 >> iter 61000, loss: 0.247992
 >> iter 62000, loss: 0.250085
 >> iter 63000, loss: 0.236529
 >> iter 64000, loss: 0.380233
 >> iter 65000, loss: 0.305102
 >> iter 66000, loss: 0.328907
 >> iter 67000, loss: 0.418962
 >> iter 68000, loss: 0.332518
 >> iter 69000, loss: 0.332107
 >> iter 70000, loss: 0.296734
   Number of active neurons: 6
 >> iter 71000, loss: 0.290876
 >> iter 72000, loss: 0.221195
 >> iter 73000, loss: 0.199953
 >> iter 74000, loss: 0.306419
 >> iter 75000, loss: 0.211432
 >> iter 76000, loss: 0.166658
 >> iter 77000, loss: 0.240919
 >> iter 78000, loss: 0.292700
 >> iter 79000, loss: 0.450057
 >> iter 80000, loss: 0.213055
   Number of active neurons: 6
 >> iter 81000, loss: 0.198445
 >> iter 82000, loss: 0.230856
 >> iter 83000, loss: 0.243001
 >> iter 84000, loss: 0.199436
 >> iter 85000, loss: 0.322789
 >> iter 86000, loss: 0.280605
 >> iter 87000, loss: 0.216023
 >> iter 88000, loss: 0.245331
 >> iter 89000, loss: 0.157651
 >> iter 90000, loss: 0.169652
   Number of active neurons: 6
 >> iter 91000, loss: 0.251797
 >> iter 92000, loss: 0.212054
 >> iter 93000, loss: 0.200989
 >> iter 94000, loss: 0.245491
 >> iter 95000, loss: 0.375706
 >> iter 96000, loss: 0.297237
 >> iter 97000, loss: 0.376885
 >> iter 98000, loss: 0.349684
 >> iter 99000, loss: 0.276631
 >> iter 100000, loss: 0.241434
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.017814
 >> iter 2000, loss: 10.415734
 >> iter 3000, loss: 6.235252
 >> iter 4000, loss: 3.526044
 >> iter 5000, loss: 2.126689
 >> iter 6000, loss: 1.425016
 >> iter 7000, loss: 1.018903
 >> iter 8000, loss: 0.809808
 >> iter 9000, loss: 0.627458
 >> iter 10000, loss: 0.404198
   Number of active neurons: 6
 >> iter 11000, loss: 0.338342
 >> iter 12000, loss: 0.316371
 >> iter 13000, loss: 0.386682
 >> iter 14000, loss: 0.357780
 >> iter 15000, loss: 0.433681
 >> iter 16000, loss: 0.469209
 >> iter 17000, loss: 0.385687
 >> iter 18000, loss: 0.428595
 >> iter 19000, loss: 0.364782
 >> iter 20000, loss: 0.460985
   Number of active neurons: 6
 >> iter 21000, loss: 0.438135
 >> iter 22000, loss: 0.400191
 >> iter 23000, loss: 0.410030
 >> iter 24000, loss: 0.491095
 >> iter 25000, loss: 0.466920
 >> iter 26000, loss: 0.383093
 >> iter 27000, loss: 0.420867
 >> iter 28000, loss: 0.385892
 >> iter 29000, loss: 0.379660
 >> iter 30000, loss: 0.300870
   Number of active neurons: 5
 >> iter 31000, loss: 0.438737
 >> iter 32000, loss: 0.457674
 >> iter 33000, loss: 0.501526
 >> iter 34000, loss: 0.335892
 >> iter 35000, loss: 0.362221
 >> iter 36000, loss: 0.366045
 >> iter 37000, loss: 0.374878
 >> iter 38000, loss: 0.382528
 >> iter 39000, loss: 0.529016
 >> iter 40000, loss: 0.577775
   Number of active neurons: 5
 >> iter 41000, loss: 0.393220
 >> iter 42000, loss: 0.489687
 >> iter 43000, loss: 0.562651
 >> iter 44000, loss: 0.551286
 >> iter 45000, loss: 0.647037
 >> iter 46000, loss: 0.589034
 >> iter 47000, loss: 0.464162
 >> iter 48000, loss: 0.531115
 >> iter 49000, loss: 0.485778
 >> iter 50000, loss: 0.468928
   Number of active neurons: 4
 >> iter 51000, loss: 0.385469
 >> iter 52000, loss: 0.338598
 >> iter 53000, loss: 0.391794
 >> iter 54000, loss: 0.426816
 >> iter 55000, loss: 0.440234
 >> iter 56000, loss: 0.412673
 >> iter 57000, loss: 0.416394
 >> iter 58000, loss: 0.427377
 >> iter 59000, loss: 0.517419
 >> iter 60000, loss: 0.534994
   Number of active neurons: 4
 >> iter 61000, loss: 0.573623
 >> iter 62000, loss: 0.772972
 >> iter 63000, loss: 0.589546
 >> iter 64000, loss: 0.547589
 >> iter 65000, loss: 0.459355
 >> iter 66000, loss: 0.438734
 >> iter 67000, loss: 0.657101
 >> iter 68000, loss: 0.486010
 >> iter 69000, loss: 0.528715
 >> iter 70000, loss: 0.445245
   Number of active neurons: 4
 >> iter 71000, loss: 0.519316
 >> iter 72000, loss: 0.678422
 >> iter 73000, loss: 0.579214
 >> iter 74000, loss: 0.588227
 >> iter 75000, loss: 0.529694
 >> iter 76000, loss: 0.435075
 >> iter 77000, loss: 0.413367
 >> iter 78000, loss: 0.483502
 >> iter 79000, loss: 0.574776
 >> iter 80000, loss: 0.608676
   Number of active neurons: 4
 >> iter 81000, loss: 0.537627
 >> iter 82000, loss: 0.539194
 >> iter 83000, loss: 0.506094
 >> iter 84000, loss: 0.441333
 >> iter 85000, loss: 0.399468
 >> iter 86000, loss: 0.437029
 >> iter 87000, loss: 0.372030
 >> iter 88000, loss: 0.464683
 >> iter 89000, loss: 0.522438
 >> iter 90000, loss: 0.618774
   Number of active neurons: 4
 >> iter 91000, loss: 0.570258
 >> iter 92000, loss: 0.405141
 >> iter 93000, loss: 0.675284
 >> iter 94000, loss: 0.567137
 >> iter 95000, loss: 0.770971
 >> iter 96000, loss: 0.539022
 >> iter 97000, loss: 0.643291
 >> iter 98000, loss: 0.467488
 >> iter 99000, loss: 0.484805
 >> iter 100000, loss: 0.585256
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.073436
 >> iter 2000, loss: 10.899994
 >> iter 3000, loss: 7.016904
 >> iter 4000, loss: 4.048825
 >> iter 5000, loss: 2.507558
 >> iter 6000, loss: 1.860472
 >> iter 7000, loss: 1.411801
 >> iter 8000, loss: 1.103731
 >> iter 9000, loss: 0.883871
 >> iter 10000, loss: 0.689480
   Number of active neurons: 5
 >> iter 11000, loss: 0.723772
 >> iter 12000, loss: 0.640244
 >> iter 13000, loss: 0.586351
 >> iter 14000, loss: 0.719491
 >> iter 15000, loss: 0.593040
 >> iter 16000, loss: 0.684084
 >> iter 17000, loss: 0.585972
 >> iter 18000, loss: 0.473925
 >> iter 19000, loss: 0.556261
 >> iter 20000, loss: 0.766717
   Number of active neurons: 5
 >> iter 21000, loss: 0.804945
 >> iter 22000, loss: 0.741122
 >> iter 23000, loss: 0.559785
 >> iter 24000, loss: 0.549247
 >> iter 25000, loss: 0.576921
 >> iter 26000, loss: 0.555015
 >> iter 27000, loss: 0.726230
 >> iter 28000, loss: 0.640122
 >> iter 29000, loss: 0.478051
 >> iter 30000, loss: 0.452884
   Number of active neurons: 5
 >> iter 31000, loss: 0.521868
 >> iter 32000, loss: 0.452563
 >> iter 33000, loss: 0.394994
 >> iter 34000, loss: 0.462395
 >> iter 35000, loss: 0.470567
 >> iter 36000, loss: 0.471897
 >> iter 37000, loss: 0.458345
 >> iter 38000, loss: 0.567119
 >> iter 39000, loss: 0.572117
 >> iter 40000, loss: 0.482735
   Number of active neurons: 5
 >> iter 41000, loss: 0.573400
 >> iter 42000, loss: 0.698929
 >> iter 43000, loss: 0.539243
 >> iter 44000, loss: 0.579361
 >> iter 45000, loss: 0.587023
 >> iter 46000, loss: 0.493040
 >> iter 47000, loss: 0.456977
 >> iter 48000, loss: 0.436111
 >> iter 49000, loss: 0.387077
 >> iter 50000, loss: 0.371885
   Number of active neurons: 5
 >> iter 51000, loss: 0.306049
 >> iter 52000, loss: 0.280078
 >> iter 53000, loss: 0.392480
 >> iter 54000, loss: 0.477149
 >> iter 55000, loss: 0.522980
 >> iter 56000, loss: 0.480465
 >> iter 57000, loss: 0.534237
 >> iter 58000, loss: 0.417189
 >> iter 59000, loss: 0.389415
 >> iter 60000, loss: 0.474601
   Number of active neurons: 5
 >> iter 61000, loss: 0.484369
 >> iter 62000, loss: 0.532200
 >> iter 63000, loss: 0.557476
 >> iter 64000, loss: 0.480888
 >> iter 65000, loss: 0.652111
 >> iter 66000, loss: 0.441512
 >> iter 67000, loss: 0.458389
 >> iter 68000, loss: 0.558792
 >> iter 69000, loss: 0.551773
 >> iter 70000, loss: 0.401792
   Number of active neurons: 5
 >> iter 71000, loss: 0.445021
 >> iter 72000, loss: 0.526305
 >> iter 73000, loss: 0.457660
 >> iter 74000, loss: 0.466418
 >> iter 75000, loss: 0.350880
 >> iter 76000, loss: 0.425821
 >> iter 77000, loss: 0.548401
 >> iter 78000, loss: 0.449364
 >> iter 79000, loss: 0.408090
 >> iter 80000, loss: 0.428431
   Number of active neurons: 5
 >> iter 81000, loss: 0.420747
 >> iter 82000, loss: 0.508220
 >> iter 83000, loss: 0.500545
 >> iter 84000, loss: 0.409397
 >> iter 85000, loss: 0.446605
 >> iter 86000, loss: 0.453553
 >> iter 87000, loss: 0.411788
 >> iter 88000, loss: 0.424604
 >> iter 89000, loss: 0.523426
 >> iter 90000, loss: 0.522599
   Number of active neurons: 5
 >> iter 91000, loss: 0.380448
 >> iter 92000, loss: 0.498897
 >> iter 93000, loss: 0.396692
 >> iter 94000, loss: 0.404835
 >> iter 95000, loss: 0.492688
 >> iter 96000, loss: 0.468076
 >> iter 97000, loss: 0.448935
 >> iter 98000, loss: 0.462565
 >> iter 99000, loss: 0.515271
 >> iter 100000, loss: 0.406097
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.529857
 >> iter 2000, loss: 9.589752
 >> iter 3000, loss: 5.529639
 >> iter 4000, loss: 2.981466
 >> iter 5000, loss: 1.987497
 >> iter 6000, loss: 1.149760
 >> iter 7000, loss: 0.841358
 >> iter 8000, loss: 0.732536
 >> iter 9000, loss: 0.743612
 >> iter 10000, loss: 0.649011
   Number of active neurons: 7
 >> iter 11000, loss: 0.630184
 >> iter 12000, loss: 0.527468
 >> iter 13000, loss: 0.507392
 >> iter 14000, loss: 0.737757
 >> iter 15000, loss: 0.508046
 >> iter 16000, loss: 0.436802
 >> iter 17000, loss: 0.428751
 >> iter 18000, loss: 0.349856
 >> iter 19000, loss: 0.419855
 >> iter 20000, loss: 0.495210
   Number of active neurons: 7
 >> iter 21000, loss: 0.478238
 >> iter 22000, loss: 0.460475
 >> iter 23000, loss: 0.583198
 >> iter 24000, loss: 0.535054
 >> iter 25000, loss: 0.454510
 >> iter 26000, loss: 0.337273
 >> iter 27000, loss: 0.331264
 >> iter 28000, loss: 0.358846
 >> iter 29000, loss: 0.351632
 >> iter 30000, loss: 0.341887
   Number of active neurons: 7
 >> iter 31000, loss: 0.480019
 >> iter 32000, loss: 0.444535
 >> iter 33000, loss: 0.405119
 >> iter 34000, loss: 0.354059
 >> iter 35000, loss: 0.398729
 >> iter 36000, loss: 0.399420
 >> iter 37000, loss: 0.305529
 >> iter 38000, loss: 0.338632
 >> iter 39000, loss: 0.335750
 >> iter 40000, loss: 0.314891
   Number of active neurons: 7
 >> iter 41000, loss: 0.353983
 >> iter 42000, loss: 0.316794
 >> iter 43000, loss: 0.445500
 >> iter 44000, loss: 0.458733
 >> iter 45000, loss: 0.479285
 >> iter 46000, loss: 0.402224
 >> iter 47000, loss: 0.364057
 >> iter 48000, loss: 0.411286
 >> iter 49000, loss: 0.505975
 >> iter 50000, loss: 0.377333
   Number of active neurons: 7
 >> iter 51000, loss: 0.393927
 >> iter 52000, loss: 0.264601
 >> iter 53000, loss: 0.358019
 >> iter 54000, loss: 0.297829
 >> iter 55000, loss: 0.395901
 >> iter 56000, loss: 0.338163
 >> iter 57000, loss: 0.377274
 >> iter 58000, loss: 0.302009
 >> iter 59000, loss: 0.290377
 >> iter 60000, loss: 0.302541
   Number of active neurons: 7
 >> iter 61000, loss: 0.293066
 >> iter 62000, loss: 0.234660
 >> iter 63000, loss: 0.269413
 >> iter 64000, loss: 0.330568
 >> iter 65000, loss: 0.391504
 >> iter 66000, loss: 0.361837
 >> iter 67000, loss: 0.356645
 >> iter 68000, loss: 0.311543
 >> iter 69000, loss: 0.351182
 >> iter 70000, loss: 0.361429
   Number of active neurons: 7
 >> iter 71000, loss: 0.485641
 >> iter 72000, loss: 0.410419
 >> iter 73000, loss: 0.450094
 >> iter 74000, loss: 0.414260
 >> iter 75000, loss: 0.439862
 >> iter 76000, loss: 0.367857
 >> iter 77000, loss: 0.304734
 >> iter 78000, loss: 0.339794
 >> iter 79000, loss: 0.329876
 >> iter 80000, loss: 0.342594
   Number of active neurons: 7
 >> iter 81000, loss: 0.362272
 >> iter 82000, loss: 0.347703
 >> iter 83000, loss: 0.308800
 >> iter 84000, loss: 0.321037
 >> iter 85000, loss: 0.321772
 >> iter 86000, loss: 0.343476
 >> iter 87000, loss: 0.341964
 >> iter 88000, loss: 0.318527
 >> iter 89000, loss: 0.340925
 >> iter 90000, loss: 0.378746
   Number of active neurons: 7
 >> iter 91000, loss: 0.354860
 >> iter 92000, loss: 0.294019
 >> iter 93000, loss: 0.255279
 >> iter 94000, loss: 0.276427
 >> iter 95000, loss: 0.317934
 >> iter 96000, loss: 0.288802
 >> iter 97000, loss: 0.345805
 >> iter 98000, loss: 0.434965
 >> iter 99000, loss: 0.368027
 >> iter 100000, loss: 0.259602
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.037535
 >> iter 2000, loss: 10.315285
 >> iter 3000, loss: 6.657295
 >> iter 4000, loss: 3.497159
 >> iter 5000, loss: 2.047717
 >> iter 6000, loss: 1.352923
 >> iter 7000, loss: 0.971180
 >> iter 8000, loss: 0.893468
 >> iter 9000, loss: 0.761742
 >> iter 10000, loss: 0.615704
   Number of active neurons: 6
 >> iter 11000, loss: 0.520940
 >> iter 12000, loss: 0.486727
 >> iter 13000, loss: 0.423953
 >> iter 14000, loss: 0.505101
 >> iter 15000, loss: 0.499642
 >> iter 16000, loss: 0.492423
 >> iter 17000, loss: 0.450574
 >> iter 18000, loss: 0.452909
 >> iter 19000, loss: 0.460823
 >> iter 20000, loss: 0.484497
   Number of active neurons: 9
 >> iter 21000, loss: 0.402159
 >> iter 22000, loss: 0.432261
 >> iter 23000, loss: 0.468824
 >> iter 24000, loss: 0.264086
 >> iter 25000, loss: 0.393674
 >> iter 26000, loss: 0.452044
 >> iter 27000, loss: 0.590915
 >> iter 28000, loss: 0.477239
 >> iter 29000, loss: 0.399442
 >> iter 30000, loss: 0.417249
   Number of active neurons: 5
 >> iter 31000, loss: 0.428380
 >> iter 32000, loss: 0.395342
 >> iter 33000, loss: 0.335591
 >> iter 34000, loss: 0.304681
 >> iter 35000, loss: 0.433163
 >> iter 36000, loss: 0.424774
 >> iter 37000, loss: 0.463691
 >> iter 38000, loss: 0.452094
 >> iter 39000, loss: 0.359213
 >> iter 40000, loss: 0.322712
   Number of active neurons: 5
 >> iter 41000, loss: 0.439655
 >> iter 42000, loss: 0.507957
 >> iter 43000, loss: 0.441295
 >> iter 44000, loss: 0.310999
 >> iter 45000, loss: 0.332922
 >> iter 46000, loss: 0.455537
 >> iter 47000, loss: 0.464746
 >> iter 48000, loss: 0.343660
 >> iter 49000, loss: 0.419165
 >> iter 50000, loss: 0.298323
   Number of active neurons: 5
 >> iter 51000, loss: 0.341584
 >> iter 52000, loss: 0.367680
 >> iter 53000, loss: 0.415931
 >> iter 54000, loss: 0.407008
 >> iter 55000, loss: 0.397726
 >> iter 56000, loss: 0.441646
 >> iter 57000, loss: 0.450559
 >> iter 58000, loss: 0.414173
 >> iter 59000, loss: 0.454126
 >> iter 60000, loss: 0.400370
   Number of active neurons: 5
 >> iter 61000, loss: 0.434671
 >> iter 62000, loss: 0.487518
 >> iter 63000, loss: 0.505521
 >> iter 64000, loss: 0.366523
 >> iter 65000, loss: 0.364769
 >> iter 66000, loss: 0.406612
 >> iter 67000, loss: 0.447480
 >> iter 68000, loss: 0.485197
 >> iter 69000, loss: 0.516056
 >> iter 70000, loss: 0.381315
   Number of active neurons: 5
 >> iter 71000, loss: 0.444197
 >> iter 72000, loss: 0.391839
 >> iter 73000, loss: 0.518708
 >> iter 74000, loss: 0.434365
 >> iter 75000, loss: 0.465786
 >> iter 76000, loss: 0.440679
 >> iter 77000, loss: 0.505125
 >> iter 78000, loss: 0.297569
 >> iter 79000, loss: 0.311026
 >> iter 80000, loss: 0.509793
   Number of active neurons: 5
 >> iter 81000, loss: 0.463038
 >> iter 82000, loss: 0.437008
 >> iter 83000, loss: 0.369311
 >> iter 84000, loss: 0.328367
 >> iter 85000, loss: 0.316162
 >> iter 86000, loss: 0.407569
 >> iter 87000, loss: 0.357158
 >> iter 88000, loss: 0.387443
 >> iter 89000, loss: 0.297583
 >> iter 90000, loss: 0.410081
   Number of active neurons: 5
 >> iter 91000, loss: 0.337437
 >> iter 92000, loss: 0.261335
 >> iter 93000, loss: 0.323497
 >> iter 94000, loss: 0.400485
 >> iter 95000, loss: 0.423019
 >> iter 96000, loss: 0.299982
 >> iter 97000, loss: 0.371986
 >> iter 98000, loss: 0.391808
 >> iter 99000, loss: 0.449875
 >> iter 100000, loss: 0.543966
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.981731
 >> iter 2000, loss: 10.307297
 >> iter 3000, loss: 7.673643
 >> iter 4000, loss: 5.916826
 >> iter 5000, loss: 4.891635
 >> iter 6000, loss: 4.228011
 >> iter 7000, loss: 3.910622
 >> iter 8000, loss: 3.643687
 >> iter 9000, loss: 3.736115
 >> iter 10000, loss: 3.572623
   Number of active neurons: 5
 >> iter 11000, loss: 3.525358
 >> iter 12000, loss: 3.471849
 >> iter 13000, loss: 3.440768
 >> iter 14000, loss: 3.470164
 >> iter 15000, loss: 3.490220
 >> iter 16000, loss: 3.450366
 >> iter 17000, loss: 3.350351
 >> iter 18000, loss: 3.376756
 >> iter 19000, loss: 3.317955
 >> iter 20000, loss: 3.359062
   Number of active neurons: 5
 >> iter 21000, loss: 3.310140
 >> iter 22000, loss: 3.249823
 >> iter 23000, loss: 3.371051
 >> iter 24000, loss: 2.969589
 >> iter 25000, loss: 2.152483
 >> iter 26000, loss: 1.409342
 >> iter 27000, loss: 1.047580
 >> iter 28000, loss: 0.825571
 >> iter 29000, loss: 0.810808
 >> iter 30000, loss: 0.614044
   Number of active neurons: 5
 >> iter 31000, loss: 0.752056
 >> iter 32000, loss: 0.721047
 >> iter 33000, loss: 0.593172
 >> iter 34000, loss: 0.638204
 >> iter 35000, loss: 0.506694
 >> iter 36000, loss: 0.583804
 >> iter 37000, loss: 0.471938
 >> iter 38000, loss: 0.444844
 >> iter 39000, loss: 0.538899
 >> iter 40000, loss: 0.601762
   Number of active neurons: 5
 >> iter 41000, loss: 0.631233
 >> iter 42000, loss: 0.564728
 >> iter 43000, loss: 0.529505
 >> iter 44000, loss: 0.525324
 >> iter 45000, loss: 0.420465
 >> iter 46000, loss: 0.443199
 >> iter 47000, loss: 0.570012
 >> iter 48000, loss: 0.528449
 >> iter 49000, loss: 0.511308
 >> iter 50000, loss: 0.584649
   Number of active neurons: 5
 >> iter 51000, loss: 0.594914
 >> iter 52000, loss: 0.433297
 >> iter 53000, loss: 0.633253
 >> iter 54000, loss: 0.655894
 >> iter 55000, loss: 0.757855
 >> iter 56000, loss: 0.650461
 >> iter 57000, loss: 0.741746
 >> iter 58000, loss: 0.608926
 >> iter 59000, loss: 0.447723
 >> iter 60000, loss: 0.396011
   Number of active neurons: 5
 >> iter 61000, loss: 0.418967
 >> iter 62000, loss: 0.528756
 >> iter 63000, loss: 0.548869
 >> iter 64000, loss: 0.531342
 >> iter 65000, loss: 0.475352
 >> iter 66000, loss: 0.513291
 >> iter 67000, loss: 0.566318
 >> iter 68000, loss: 0.569944
 >> iter 69000, loss: 0.395810
 >> iter 70000, loss: 0.473423
   Number of active neurons: 5
 >> iter 71000, loss: 0.632518
 >> iter 72000, loss: 0.443653
 >> iter 73000, loss: 0.481692
 >> iter 74000, loss: 0.462766
 >> iter 75000, loss: 0.673177
 >> iter 76000, loss: 0.670687
 >> iter 77000, loss: 0.577023
 >> iter 78000, loss: 0.514205
 >> iter 79000, loss: 0.381571
 >> iter 80000, loss: 0.430961
   Number of active neurons: 5
 >> iter 81000, loss: 0.430494
 >> iter 82000, loss: 0.493138
 >> iter 83000, loss: 0.377837
 >> iter 84000, loss: 0.428764
 >> iter 85000, loss: 0.766597
 >> iter 86000, loss: 0.702684
 >> iter 87000, loss: 0.625193
 >> iter 88000, loss: 0.573699
 >> iter 89000, loss: 0.516418
 >> iter 90000, loss: 0.680359
   Number of active neurons: 5
 >> iter 91000, loss: 0.557241
 >> iter 92000, loss: 0.629079
 >> iter 93000, loss: 0.430535
 >> iter 94000, loss: 0.604618
 >> iter 95000, loss: 0.550356
 >> iter 96000, loss: 0.507654
 >> iter 97000, loss: 0.514525
 >> iter 98000, loss: 0.541275
 >> iter 99000, loss: 0.445377
 >> iter 100000, loss: 0.449991
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.511147
 >> iter 2000, loss: 10.542687
 >> iter 3000, loss: 6.094728
 >> iter 4000, loss: 3.577305
 >> iter 5000, loss: 2.471604
 >> iter 6000, loss: 1.615423
 >> iter 7000, loss: 1.083274
 >> iter 8000, loss: 0.940556
 >> iter 9000, loss: 0.835026
 >> iter 10000, loss: 0.741023
   Number of active neurons: 5
 >> iter 11000, loss: 0.688637
 >> iter 12000, loss: 0.583884
 >> iter 13000, loss: 0.668720
 >> iter 14000, loss: 0.588285
 >> iter 15000, loss: 0.687441
 >> iter 16000, loss: 0.686189
 >> iter 17000, loss: 0.783721
 >> iter 18000, loss: 0.620242
 >> iter 19000, loss: 0.510127
 >> iter 20000, loss: 0.426360
   Number of active neurons: 4
 >> iter 21000, loss: 0.414743
 >> iter 22000, loss: 0.476092
 >> iter 23000, loss: 0.494785
 >> iter 24000, loss: 0.385750
 >> iter 25000, loss: 0.411622
 >> iter 26000, loss: 0.499486
 >> iter 27000, loss: 0.491787
 >> iter 28000, loss: 0.534425
 >> iter 29000, loss: 0.549657
 >> iter 30000, loss: 0.506210
   Number of active neurons: 4
 >> iter 31000, loss: 0.661075
 >> iter 32000, loss: 0.575216
 >> iter 33000, loss: 0.655734
 >> iter 34000, loss: 0.519110
 >> iter 35000, loss: 0.444290
 >> iter 36000, loss: 0.610733
 >> iter 37000, loss: 0.538518
 >> iter 38000, loss: 0.442152
 >> iter 39000, loss: 0.564200
 >> iter 40000, loss: 0.568855
   Number of active neurons: 4
 >> iter 41000, loss: 0.577022
 >> iter 42000, loss: 0.447421
 >> iter 43000, loss: 0.412010
 >> iter 44000, loss: 0.460821
 >> iter 45000, loss: 0.553436
 >> iter 46000, loss: 0.596710
 >> iter 47000, loss: 0.655903
 >> iter 48000, loss: 0.482268
 >> iter 49000, loss: 0.432618
 >> iter 50000, loss: 0.530617
   Number of active neurons: 4
 >> iter 51000, loss: 0.593207
 >> iter 52000, loss: 0.611050
 >> iter 53000, loss: 0.575753
 >> iter 54000, loss: 0.747750
 >> iter 55000, loss: 0.644624
 >> iter 56000, loss: 0.547343
 >> iter 57000, loss: 0.504969
 >> iter 58000, loss: 0.419086
 >> iter 59000, loss: 0.451190
 >> iter 60000, loss: 0.427547
   Number of active neurons: 4
 >> iter 61000, loss: 0.567105
 >> iter 62000, loss: 0.630789
 >> iter 63000, loss: 0.599006
 >> iter 64000, loss: 0.514319
 >> iter 65000, loss: 0.487693
 >> iter 66000, loss: 0.469889
 >> iter 67000, loss: 0.445397
 >> iter 68000, loss: 0.537766
 >> iter 69000, loss: 0.605877
 >> iter 70000, loss: 0.588744
   Number of active neurons: 4
 >> iter 71000, loss: 0.513578
 >> iter 72000, loss: 0.513087
 >> iter 73000, loss: 0.528848
 >> iter 74000, loss: 0.556999
 >> iter 75000, loss: 0.548331
 >> iter 76000, loss: 0.573341
 >> iter 77000, loss: 0.619253
 >> iter 78000, loss: 0.556515
 >> iter 79000, loss: 0.426694
 >> iter 80000, loss: 0.513179
   Number of active neurons: 4
 >> iter 81000, loss: 0.372396
 >> iter 82000, loss: 0.551987
 >> iter 83000, loss: 0.459026
 >> iter 84000, loss: 0.567346
 >> iter 85000, loss: 0.558002
 >> iter 86000, loss: 0.421528
 >> iter 87000, loss: 0.558504
 >> iter 88000, loss: 0.668283
 >> iter 89000, loss: 0.522679
 >> iter 90000, loss: 0.528617
   Number of active neurons: 4
 >> iter 91000, loss: 0.592057
 >> iter 92000, loss: 0.523083
 >> iter 93000, loss: 0.548540
 >> iter 94000, loss: 0.407097
 >> iter 95000, loss: 0.576938
 >> iter 96000, loss: 0.575170
 >> iter 97000, loss: 0.575326
 >> iter 98000, loss: 0.581987
 >> iter 99000, loss: 0.461646
 >> iter 100000, loss: 0.448021
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.948681
 >> iter 2000, loss: 10.307227
 >> iter 3000, loss: 5.507261
 >> iter 4000, loss: 2.384030
 >> iter 5000, loss: 1.073741
 >> iter 6000, loss: 0.649028
 >> iter 7000, loss: 0.424918
 >> iter 8000, loss: 0.335843
 >> iter 9000, loss: 0.234702
 >> iter 10000, loss: 0.212824
   Number of active neurons: 8
 >> iter 11000, loss: 0.251748
 >> iter 12000, loss: 0.196325
 >> iter 13000, loss: 0.200141
 >> iter 14000, loss: 0.200045
 >> iter 15000, loss: 0.186900
 >> iter 16000, loss: 0.174231
 >> iter 17000, loss: 0.236764
 >> iter 18000, loss: 0.289981
 >> iter 19000, loss: 0.206596
 >> iter 20000, loss: 0.199833
   Number of active neurons: 8
 >> iter 21000, loss: 0.181643
 >> iter 22000, loss: 0.247197
 >> iter 23000, loss: 0.180535
 >> iter 24000, loss: 0.241430
 >> iter 25000, loss: 0.284010
 >> iter 26000, loss: 0.340532
 >> iter 27000, loss: 0.380908
 >> iter 28000, loss: 0.232999
 >> iter 29000, loss: 0.261793
 >> iter 30000, loss: 0.206506
   Number of active neurons: 8
 >> iter 31000, loss: 0.216940
 >> iter 32000, loss: 0.285223
 >> iter 33000, loss: 0.301441
 >> iter 34000, loss: 0.266701
 >> iter 35000, loss: 0.205544
 >> iter 36000, loss: 0.204343
 >> iter 37000, loss: 0.154574
 >> iter 38000, loss: 0.174906
 >> iter 39000, loss: 0.139267
 >> iter 40000, loss: 0.126297
   Number of active neurons: 7
 >> iter 41000, loss: 0.209380
 >> iter 42000, loss: 0.225015
 >> iter 43000, loss: 0.293899
 >> iter 44000, loss: 0.224939
 >> iter 45000, loss: 0.253219
 >> iter 46000, loss: 0.314866
 >> iter 47000, loss: 0.276320
 >> iter 48000, loss: 0.258064
 >> iter 49000, loss: 0.296712
 >> iter 50000, loss: 0.254199
   Number of active neurons: 7
 >> iter 51000, loss: 0.222601
 >> iter 52000, loss: 0.182740
 >> iter 53000, loss: 0.198208
 >> iter 54000, loss: 0.190747
 >> iter 55000, loss: 0.193642
 >> iter 56000, loss: 0.238844
 >> iter 57000, loss: 0.251052
 >> iter 58000, loss: 0.378610
 >> iter 59000, loss: 0.252929
 >> iter 60000, loss: 0.223005
   Number of active neurons: 7
 >> iter 61000, loss: 0.233213
 >> iter 62000, loss: 0.242939
 >> iter 63000, loss: 0.278765
 >> iter 64000, loss: 0.312138
 >> iter 65000, loss: 0.354479
 >> iter 66000, loss: 0.274197
 >> iter 67000, loss: 0.385190
 >> iter 68000, loss: 0.313278
 >> iter 69000, loss: 0.277684
 >> iter 70000, loss: 0.270334
   Number of active neurons: 7
 >> iter 71000, loss: 0.239616
 >> iter 72000, loss: 0.257771
 >> iter 73000, loss: 0.303105
 >> iter 74000, loss: 0.379154
 >> iter 75000, loss: 0.280872
 >> iter 76000, loss: 0.308496
 >> iter 77000, loss: 0.250853
 >> iter 78000, loss: 0.321465
 >> iter 79000, loss: 0.320900
 >> iter 80000, loss: 0.248313
   Number of active neurons: 7
 >> iter 81000, loss: 0.271449
 >> iter 82000, loss: 0.245655
 >> iter 83000, loss: 0.218418
 >> iter 84000, loss: 0.203315
 >> iter 85000, loss: 0.261708
 >> iter 86000, loss: 0.176081
 >> iter 87000, loss: 0.321868
 >> iter 88000, loss: 0.239784
 >> iter 89000, loss: 0.236802
 >> iter 90000, loss: 0.373986
   Number of active neurons: 7
 >> iter 91000, loss: 0.306276
 >> iter 92000, loss: 0.278269
 >> iter 93000, loss: 0.266196
 >> iter 94000, loss: 0.334433
 >> iter 95000, loss: 0.223069
 >> iter 96000, loss: 0.250404
 >> iter 97000, loss: 0.267453
 >> iter 98000, loss: 0.308466
 >> iter 99000, loss: 0.243408
 >> iter 100000, loss: 0.297604
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.367258
 >> iter 2000, loss: 10.342122
 >> iter 3000, loss: 6.734422
 >> iter 4000, loss: 3.835387
 >> iter 5000, loss: 2.323739
 >> iter 6000, loss: 1.473387
 >> iter 7000, loss: 0.931592
 >> iter 8000, loss: 0.726774
 >> iter 9000, loss: 0.639382
 >> iter 10000, loss: 0.580838
   Number of active neurons: 8
 >> iter 11000, loss: 0.642633
 >> iter 12000, loss: 0.479764
 >> iter 13000, loss: 0.531906
 >> iter 14000, loss: 0.500669
 >> iter 15000, loss: 0.453695
 >> iter 16000, loss: 0.384662
 >> iter 17000, loss: 0.528593
 >> iter 18000, loss: 0.536365
 >> iter 19000, loss: 0.480157
 >> iter 20000, loss: 0.483922
   Number of active neurons: 8
 >> iter 21000, loss: 0.461700
 >> iter 22000, loss: 0.522315
 >> iter 23000, loss: 0.607767
 >> iter 24000, loss: 0.509799
 >> iter 25000, loss: 0.407813
 >> iter 26000, loss: 0.456702
 >> iter 27000, loss: 0.479995
 >> iter 28000, loss: 0.415197
 >> iter 29000, loss: 0.454872
 >> iter 30000, loss: 0.377300
   Number of active neurons: 7
 >> iter 31000, loss: 0.491980
 >> iter 32000, loss: 0.516152
 >> iter 33000, loss: 0.464622
 >> iter 34000, loss: 0.354388
 >> iter 35000, loss: 0.486357
 >> iter 36000, loss: 0.485270
 >> iter 37000, loss: 0.564067
 >> iter 38000, loss: 0.457611
 >> iter 39000, loss: 0.401281
 >> iter 40000, loss: 0.444286
   Number of active neurons: 7
 >> iter 41000, loss: 0.433833
 >> iter 42000, loss: 0.533779
 >> iter 43000, loss: 0.672234
 >> iter 44000, loss: 0.612196
 >> iter 45000, loss: 0.537228
 >> iter 46000, loss: 0.560738
 >> iter 47000, loss: 0.486334
 >> iter 48000, loss: 0.455729
 >> iter 49000, loss: 0.468665
 >> iter 50000, loss: 0.578337
   Number of active neurons: 4
 >> iter 51000, loss: 0.588340
 >> iter 52000, loss: 0.546013
 >> iter 53000, loss: 0.549065
 >> iter 54000, loss: 0.445447
 >> iter 55000, loss: 0.470572
 >> iter 56000, loss: 0.348977
 >> iter 57000, loss: 0.398262
 >> iter 58000, loss: 0.306907
 >> iter 59000, loss: 0.332882
 >> iter 60000, loss: 0.367586
   Number of active neurons: 4
 >> iter 61000, loss: 0.428137
 >> iter 62000, loss: 0.422301
 >> iter 63000, loss: 0.362420
 >> iter 64000, loss: 0.460163
 >> iter 65000, loss: 0.415912
 >> iter 66000, loss: 0.389602
 >> iter 67000, loss: 0.438372
 >> iter 68000, loss: 0.600403
 >> iter 69000, loss: 0.633137
 >> iter 70000, loss: 0.470475
   Number of active neurons: 4
 >> iter 71000, loss: 0.523224
 >> iter 72000, loss: 0.550408
 >> iter 73000, loss: 0.442937
 >> iter 74000, loss: 0.419861
 >> iter 75000, loss: 0.477686
 >> iter 76000, loss: 0.486543
 >> iter 77000, loss: 0.476044
 >> iter 78000, loss: 0.490141
 >> iter 79000, loss: 0.412144
 >> iter 80000, loss: 0.541335
   Number of active neurons: 6
 >> iter 81000, loss: 0.597742
 >> iter 82000, loss: 0.629015
 >> iter 83000, loss: 0.547083
 >> iter 84000, loss: 0.544867
 >> iter 85000, loss: 0.460575
 >> iter 86000, loss: 0.334749
 >> iter 87000, loss: 0.394386
 >> iter 88000, loss: 0.379129
 >> iter 89000, loss: 0.432002
 >> iter 90000, loss: 0.472697
   Number of active neurons: 4
 >> iter 91000, loss: 0.389700
 >> iter 92000, loss: 0.426148
 >> iter 93000, loss: 0.500358
 >> iter 94000, loss: 0.410328
 >> iter 95000, loss: 0.433415
 >> iter 96000, loss: 0.462821
 >> iter 97000, loss: 0.322073
 >> iter 98000, loss: 0.366063
 >> iter 99000, loss: 0.499270
 >> iter 100000, loss: 0.511913
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.926525
 >> iter 2000, loss: 9.975058
 >> iter 3000, loss: 6.560555
 >> iter 4000, loss: 4.008146
 >> iter 5000, loss: 2.119350
 >> iter 6000, loss: 1.188093
 >> iter 7000, loss: 0.807939
 >> iter 8000, loss: 0.586286
 >> iter 9000, loss: 0.388376
 >> iter 10000, loss: 0.360578
   Number of active neurons: 7
 >> iter 11000, loss: 0.390520
 >> iter 12000, loss: 0.220794
 >> iter 13000, loss: 0.220452
 >> iter 14000, loss: 0.322571
 >> iter 15000, loss: 0.246215
 >> iter 16000, loss: 0.209353
 >> iter 17000, loss: 0.201250
 >> iter 18000, loss: 0.337599
 >> iter 19000, loss: 0.377204
 >> iter 20000, loss: 0.277251
   Number of active neurons: 7
 >> iter 21000, loss: 0.424966
 >> iter 22000, loss: 0.284185
 >> iter 23000, loss: 0.413158
 >> iter 24000, loss: 0.341265
 >> iter 25000, loss: 0.261284
 >> iter 26000, loss: 0.329387
 >> iter 27000, loss: 0.391394
 >> iter 28000, loss: 0.253013
 >> iter 29000, loss: 0.311628
 >> iter 30000, loss: 0.329033
   Number of active neurons: 7
 >> iter 31000, loss: 0.274374
 >> iter 32000, loss: 0.303235
 >> iter 33000, loss: 0.290141
 >> iter 34000, loss: 0.228567
 >> iter 35000, loss: 0.316645
 >> iter 36000, loss: 0.484057
 >> iter 37000, loss: 0.241958
 >> iter 38000, loss: 0.242054
 >> iter 39000, loss: 0.205566
 >> iter 40000, loss: 0.236767
   Number of active neurons: 7
 >> iter 41000, loss: 0.250977
 >> iter 42000, loss: 0.356794
 >> iter 43000, loss: 0.340072
 >> iter 44000, loss: 0.347087
 >> iter 45000, loss: 0.257045
 >> iter 46000, loss: 0.245144
 >> iter 47000, loss: 0.415917
 >> iter 48000, loss: 0.323098
 >> iter 49000, loss: 0.314109
 >> iter 50000, loss: 0.300807
   Number of active neurons: 7
 >> iter 51000, loss: 0.344049
 >> iter 52000, loss: 0.259718
 >> iter 53000, loss: 0.297744
 >> iter 54000, loss: 0.366740
 >> iter 55000, loss: 0.313214
 >> iter 56000, loss: 0.388356
 >> iter 57000, loss: 0.304764
 >> iter 58000, loss: 0.240160
 >> iter 59000, loss: 0.231822
 >> iter 60000, loss: 0.358645
   Number of active neurons: 7
 >> iter 61000, loss: 0.346453
 >> iter 62000, loss: 0.467605
 >> iter 63000, loss: 0.291331
 >> iter 64000, loss: 0.407699
 >> iter 65000, loss: 0.301164
 >> iter 66000, loss: 0.262586
 >> iter 67000, loss: 0.267857
 >> iter 68000, loss: 0.170369
 >> iter 69000, loss: 0.286195
 >> iter 70000, loss: 0.344117
   Number of active neurons: 7
 >> iter 71000, loss: 0.232864
 >> iter 72000, loss: 0.323397
 >> iter 73000, loss: 0.294544
 >> iter 74000, loss: 0.354205
 >> iter 75000, loss: 0.276560
 >> iter 76000, loss: 0.272162
 >> iter 77000, loss: 0.299755
 >> iter 78000, loss: 0.277692
 >> iter 79000, loss: 0.325559
 >> iter 80000, loss: 0.388298
   Number of active neurons: 6
 >> iter 81000, loss: 0.459805
 >> iter 82000, loss: 0.419067
 >> iter 83000, loss: 0.355440
 >> iter 84000, loss: 0.464488
 >> iter 85000, loss: 0.373339
 >> iter 86000, loss: 0.317318
 >> iter 87000, loss: 0.371055
 >> iter 88000, loss: 0.255741
 >> iter 89000, loss: 0.284553
 >> iter 90000, loss: 0.367971
   Number of active neurons: 5
 >> iter 91000, loss: 0.273414
 >> iter 92000, loss: 0.351765
 >> iter 93000, loss: 0.332444
 >> iter 94000, loss: 0.377127
 >> iter 95000, loss: 0.304314
 >> iter 96000, loss: 0.230188
 >> iter 97000, loss: 0.328422
 >> iter 98000, loss: 0.477120
 >> iter 99000, loss: 0.384562
 >> iter 100000, loss: 0.360820
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 16.951318
 >> iter 2000, loss: 10.001357
 >> iter 3000, loss: 5.631479
 >> iter 4000, loss: 3.338070
 >> iter 5000, loss: 1.965824
 >> iter 6000, loss: 1.444346
 >> iter 7000, loss: 1.066295
 >> iter 8000, loss: 0.705184
 >> iter 9000, loss: 0.597344
 >> iter 10000, loss: 0.448730
   Number of active neurons: 6
 >> iter 11000, loss: 0.392477
 >> iter 12000, loss: 0.600231
 >> iter 13000, loss: 0.486897
 >> iter 14000, loss: 0.497960
 >> iter 15000, loss: 0.573119
 >> iter 16000, loss: 0.460149
 >> iter 17000, loss: 0.309696
 >> iter 18000, loss: 0.417786
 >> iter 19000, loss: 0.581552
 >> iter 20000, loss: 0.494087
   Number of active neurons: 6
 >> iter 21000, loss: 0.526562
 >> iter 22000, loss: 0.541871
 >> iter 23000, loss: 0.571428
 >> iter 24000, loss: 0.453065
 >> iter 25000, loss: 0.418009
 >> iter 26000, loss: 0.495884
 >> iter 27000, loss: 0.501995
 >> iter 28000, loss: 0.351179
 >> iter 29000, loss: 0.526427
 >> iter 30000, loss: 0.609902
   Number of active neurons: 5
 >> iter 31000, loss: 0.597804
 >> iter 32000, loss: 0.531175
 >> iter 33000, loss: 0.400739
 >> iter 34000, loss: 0.321676
 >> iter 35000, loss: 0.429383
 >> iter 36000, loss: 0.556165
 >> iter 37000, loss: 0.445749
 >> iter 38000, loss: 0.591705
 >> iter 39000, loss: 0.433812
 >> iter 40000, loss: 0.685649
   Number of active neurons: 5
 >> iter 41000, loss: 0.632978
 >> iter 42000, loss: 0.472526
 >> iter 43000, loss: 0.424064
 >> iter 44000, loss: 0.371923
 >> iter 45000, loss: 0.313662
 >> iter 46000, loss: 0.542274
 >> iter 47000, loss: 0.519789
 >> iter 48000, loss: 0.389904
 >> iter 49000, loss: 0.379361
 >> iter 50000, loss: 0.428930
   Number of active neurons: 4
 >> iter 51000, loss: 0.483625
 >> iter 52000, loss: 0.416002
 >> iter 53000, loss: 0.453945
 >> iter 54000, loss: 0.502254
 >> iter 55000, loss: 0.383466
 >> iter 56000, loss: 0.389625
 >> iter 57000, loss: 0.543971
 >> iter 58000, loss: 0.537878
 >> iter 59000, loss: 0.454360
 >> iter 60000, loss: 0.548646
   Number of active neurons: 4
 >> iter 61000, loss: 0.483745
 >> iter 62000, loss: 0.445426
 >> iter 63000, loss: 0.591188
 >> iter 64000, loss: 0.530356
 >> iter 65000, loss: 0.543382
 >> iter 66000, loss: 0.528960
 >> iter 67000, loss: 0.544589
 >> iter 68000, loss: 0.490641
 >> iter 69000, loss: 0.552873
 >> iter 70000, loss: 0.543259
   Number of active neurons: 4
 >> iter 71000, loss: 0.486066
 >> iter 72000, loss: 0.508413
 >> iter 73000, loss: 0.569764
 >> iter 74000, loss: 0.496188
 >> iter 75000, loss: 0.425436
 >> iter 76000, loss: 0.504398
 >> iter 77000, loss: 0.546045
 >> iter 78000, loss: 0.510296
 >> iter 79000, loss: 0.484113
 >> iter 80000, loss: 0.530754
   Number of active neurons: 4
 >> iter 81000, loss: 0.501068
 >> iter 82000, loss: 0.440938
 >> iter 83000, loss: 0.390326
 >> iter 84000, loss: 0.518114
 >> iter 85000, loss: 0.625927
 >> iter 86000, loss: 0.438971
 >> iter 87000, loss: 0.444805
 >> iter 88000, loss: 0.352245
 >> iter 89000, loss: 0.443648
 >> iter 90000, loss: 0.611830
   Number of active neurons: 4
 >> iter 91000, loss: 0.637816
 >> iter 92000, loss: 0.567513
 >> iter 93000, loss: 0.609355
 >> iter 94000, loss: 0.469445
 >> iter 95000, loss: 0.483444
 >> iter 96000, loss: 0.498651
 >> iter 97000, loss: 0.522837
 >> iter 98000, loss: 0.489879
 >> iter 99000, loss: 0.462540
 >> iter 100000, loss: 0.535670
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.332865
 >> iter 2000, loss: 10.612199
 >> iter 3000, loss: 7.795810
 >> iter 4000, loss: 4.587456
 >> iter 5000, loss: 2.266239
 >> iter 6000, loss: 1.138527
 >> iter 7000, loss: 0.768244
 >> iter 8000, loss: 0.519705
 >> iter 9000, loss: 0.342625
 >> iter 10000, loss: 0.269095
   Number of active neurons: 8
 >> iter 11000, loss: 0.208561
 >> iter 12000, loss: 0.195052
 >> iter 13000, loss: 0.233947
 >> iter 14000, loss: 0.239257
 >> iter 15000, loss: 0.256187
 >> iter 16000, loss: 0.221782
 >> iter 17000, loss: 0.214286
 >> iter 18000, loss: 0.157621
 >> iter 19000, loss: 0.242657
 >> iter 20000, loss: 0.240481
   Number of active neurons: 7
 >> iter 21000, loss: 0.133267
 >> iter 22000, loss: 0.222799
 >> iter 23000, loss: 0.155970
 >> iter 24000, loss: 0.148327
 >> iter 25000, loss: 0.305310
 >> iter 26000, loss: 0.255744
 >> iter 27000, loss: 0.278305
 >> iter 28000, loss: 0.267833
 >> iter 29000, loss: 0.272823
 >> iter 30000, loss: 0.279364
   Number of active neurons: 7
 >> iter 31000, loss: 0.242522
 >> iter 32000, loss: 0.245569
 >> iter 33000, loss: 0.309507
 >> iter 34000, loss: 0.225275
 >> iter 35000, loss: 0.303149
 >> iter 36000, loss: 0.247216
 >> iter 37000, loss: 0.283113
 >> iter 38000, loss: 0.251950
 >> iter 39000, loss: 0.227806
 >> iter 40000, loss: 0.296548
   Number of active neurons: 6
 >> iter 41000, loss: 0.285531
 >> iter 42000, loss: 0.230369
 >> iter 43000, loss: 0.157524
 >> iter 44000, loss: 0.195567
 >> iter 45000, loss: 0.267449
 >> iter 46000, loss: 0.211259
 >> iter 47000, loss: 0.279732
 >> iter 48000, loss: 0.228486
 >> iter 49000, loss: 0.184620
 >> iter 50000, loss: 0.218144
   Number of active neurons: 5
 >> iter 51000, loss: 0.198470
 >> iter 52000, loss: 0.247612
 >> iter 53000, loss: 0.274719
 >> iter 54000, loss: 0.204064
 >> iter 55000, loss: 0.193674
 >> iter 56000, loss: 0.183344
 >> iter 57000, loss: 0.192465
 >> iter 58000, loss: 0.261033
 >> iter 59000, loss: 0.205745
 >> iter 60000, loss: 0.260478
   Number of active neurons: 5
 >> iter 61000, loss: 0.217315
 >> iter 62000, loss: 0.175593
 >> iter 63000, loss: 0.195499
 >> iter 64000, loss: 0.288013
 >> iter 65000, loss: 0.264472
 >> iter 66000, loss: 0.213925
 >> iter 67000, loss: 0.146643
 >> iter 68000, loss: 0.177813
 >> iter 69000, loss: 0.253063
 >> iter 70000, loss: 0.246712
   Number of active neurons: 5
 >> iter 71000, loss: 0.201012
 >> iter 72000, loss: 0.191835
 >> iter 73000, loss: 0.230905
 >> iter 74000, loss: 0.206225
 >> iter 75000, loss: 0.243344
 >> iter 76000, loss: 0.203639
 >> iter 77000, loss: 0.329863
 >> iter 78000, loss: 0.249261
 >> iter 79000, loss: 0.236781
 >> iter 80000, loss: 0.186105
   Number of active neurons: 5
 >> iter 81000, loss: 0.290692
 >> iter 82000, loss: 0.169944
 >> iter 83000, loss: 0.151301
 >> iter 84000, loss: 0.123366
 >> iter 85000, loss: 0.133581
 >> iter 86000, loss: 0.248163
 >> iter 87000, loss: 0.216726
 >> iter 88000, loss: 0.314571
 >> iter 89000, loss: 0.260979
 >> iter 90000, loss: 0.230644
   Number of active neurons: 5
 >> iter 91000, loss: 0.179107
 >> iter 92000, loss: 0.226561
 >> iter 93000, loss: 0.157008
 >> iter 94000, loss: 0.206539
 >> iter 95000, loss: 0.301275
 >> iter 96000, loss: 0.260787
 >> iter 97000, loss: 0.260180
 >> iter 98000, loss: 0.235829
 >> iter 99000, loss: 0.167217
 >> iter 100000, loss: 0.212879
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 18.870545
 >> iter 2000, loss: 11.330175
 >> iter 3000, loss: 6.678911
 >> iter 4000, loss: 3.092548
 >> iter 5000, loss: 1.703015
 >> iter 6000, loss: 0.777958
 >> iter 7000, loss: 0.403901
 >> iter 8000, loss: 0.346035
 >> iter 9000, loss: 0.432935
 >> iter 10000, loss: 0.303618
   Number of active neurons: 10
 >> iter 11000, loss: 0.407304
 >> iter 12000, loss: 0.279564
 >> iter 13000, loss: 0.274756
 >> iter 14000, loss: 0.384425
 >> iter 15000, loss: 0.333935
 >> iter 16000, loss: 0.350655
 >> iter 17000, loss: 0.334423
 >> iter 18000, loss: 0.308980
 >> iter 19000, loss: 0.210446
 >> iter 20000, loss: 0.297477
   Number of active neurons: 10
 >> iter 21000, loss: 0.292951
 >> iter 22000, loss: 0.312224
 >> iter 23000, loss: 0.387467
 >> iter 24000, loss: 0.301168
 >> iter 25000, loss: 0.344110
 >> iter 26000, loss: 0.313939
 >> iter 27000, loss: 0.308352
 >> iter 28000, loss: 0.290478
 >> iter 29000, loss: 0.313221
 >> iter 30000, loss: 0.244734
   Number of active neurons: 9
 >> iter 31000, loss: 0.264813
 >> iter 32000, loss: 0.211354
 >> iter 33000, loss: 0.229877
 >> iter 34000, loss: 0.203104
 >> iter 35000, loss: 0.330171
 >> iter 36000, loss: 0.340775
 >> iter 37000, loss: 0.320571
 >> iter 38000, loss: 0.329283
 >> iter 39000, loss: 0.286046
 >> iter 40000, loss: 0.238017
   Number of active neurons: 9
 >> iter 41000, loss: 0.358075
 >> iter 42000, loss: 0.337264
 >> iter 43000, loss: 0.348146
 >> iter 44000, loss: 0.307864
 >> iter 45000, loss: 0.245272
 >> iter 46000, loss: 0.429448
 >> iter 47000, loss: 0.315872
 >> iter 48000, loss: 0.223499
 >> iter 49000, loss: 0.214267
 >> iter 50000, loss: 0.231988
   Number of active neurons: 9
 >> iter 51000, loss: 0.250087
 >> iter 52000, loss: 0.227313
 >> iter 53000, loss: 0.235291
 >> iter 54000, loss: 0.388648
 >> iter 55000, loss: 0.292795
 >> iter 56000, loss: 0.221806
 >> iter 57000, loss: 0.239159
 >> iter 58000, loss: 0.187146
 >> iter 59000, loss: 0.201110
 >> iter 60000, loss: 0.206242
   Number of active neurons: 9
 >> iter 61000, loss: 0.265199
 >> iter 62000, loss: 0.194469
 >> iter 63000, loss: 0.401715
 >> iter 64000, loss: 0.302941
 >> iter 65000, loss: 0.293994
 >> iter 66000, loss: 0.206052
 >> iter 67000, loss: 0.205556
 >> iter 68000, loss: 0.355718
 >> iter 69000, loss: 0.427950
 >> iter 70000, loss: 0.281293
   Number of active neurons: 9
 >> iter 71000, loss: 0.261410
 >> iter 72000, loss: 0.305508
 >> iter 73000, loss: 0.425527
 >> iter 74000, loss: 0.304598
 >> iter 75000, loss: 0.334182
 >> iter 76000, loss: 0.286088
 >> iter 77000, loss: 0.248201
 >> iter 78000, loss: 0.356661
 >> iter 79000, loss: 0.287676
 >> iter 80000, loss: 0.341275
   Number of active neurons: 9
 >> iter 81000, loss: 0.228558
 >> iter 82000, loss: 0.199998
 >> iter 83000, loss: 0.278368
 >> iter 84000, loss: 0.320104
 >> iter 85000, loss: 0.376755
 >> iter 86000, loss: 0.341819
 >> iter 87000, loss: 0.239726
 >> iter 88000, loss: 0.331045
 >> iter 89000, loss: 0.383888
 >> iter 90000, loss: 0.243005
   Number of active neurons: 8
 >> iter 91000, loss: 0.235886
 >> iter 92000, loss: 0.288869
 >> iter 93000, loss: 0.337542
 >> iter 94000, loss: 0.362047
 >> iter 95000, loss: 0.411059
 >> iter 96000, loss: 0.277045
 >> iter 97000, loss: 0.271073
 >> iter 98000, loss: 0.274884
 >> iter 99000, loss: 0.273293
 >> iter 100000, loss: 0.266443
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.942932
 >> iter 2000, loss: 11.907576
 >> iter 3000, loss: 8.035089
 >> iter 4000, loss: 4.180962
 >> iter 5000, loss: 1.975408
 >> iter 6000, loss: 1.120619
 >> iter 7000, loss: 0.611234
 >> iter 8000, loss: 0.424248
 >> iter 9000, loss: 0.347954
 >> iter 10000, loss: 0.390789
   Number of active neurons: 9
 >> iter 11000, loss: 0.382990
 >> iter 12000, loss: 0.293768
 >> iter 13000, loss: 0.478718
 >> iter 14000, loss: 0.365317
 >> iter 15000, loss: 0.378996
 >> iter 16000, loss: 0.278919
 >> iter 17000, loss: 0.360221
 >> iter 18000, loss: 0.328556
 >> iter 19000, loss: 0.272929
 >> iter 20000, loss: 0.375325
   Number of active neurons: 9
 >> iter 21000, loss: 0.306300
 >> iter 22000, loss: 0.210847
 >> iter 23000, loss: 0.228132
 >> iter 24000, loss: 0.191627
 >> iter 25000, loss: 0.316879
 >> iter 26000, loss: 0.351004
 >> iter 27000, loss: 0.312715
 >> iter 28000, loss: 0.276829
 >> iter 29000, loss: 0.324977
 >> iter 30000, loss: 0.294716
   Number of active neurons: 9
 >> iter 31000, loss: 0.320997
 >> iter 32000, loss: 0.248478
 >> iter 33000, loss: 0.271329
 >> iter 34000, loss: 0.261251
 >> iter 35000, loss: 0.286410
 >> iter 36000, loss: 0.233849
 >> iter 37000, loss: 0.343302
 >> iter 38000, loss: 0.248092
 >> iter 39000, loss: 0.139361
 >> iter 40000, loss: 0.181925
   Number of active neurons: 8
 >> iter 41000, loss: 0.217762
 >> iter 42000, loss: 0.183011
 >> iter 43000, loss: 0.225072
 >> iter 44000, loss: 0.244508
 >> iter 45000, loss: 0.244113
 >> iter 46000, loss: 0.328530
 >> iter 47000, loss: 0.311482
 >> iter 48000, loss: 0.336448
 >> iter 49000, loss: 0.194424
 >> iter 50000, loss: 0.267986
   Number of active neurons: 8
 >> iter 51000, loss: 0.327805
 >> iter 52000, loss: 0.293786
 >> iter 53000, loss: 0.204331
 >> iter 54000, loss: 0.249563
 >> iter 55000, loss: 0.223505
 >> iter 56000, loss: 0.242580
 >> iter 57000, loss: 0.262528
 >> iter 58000, loss: 0.215127
 >> iter 59000, loss: 0.218865
 >> iter 60000, loss: 0.247572
   Number of active neurons: 8
 >> iter 61000, loss: 0.276311
 >> iter 62000, loss: 0.287079
 >> iter 63000, loss: 0.345169
 >> iter 64000, loss: 0.270212
 >> iter 65000, loss: 0.212011
 >> iter 66000, loss: 0.171218
 >> iter 67000, loss: 0.259895
 >> iter 68000, loss: 0.469754
 >> iter 69000, loss: 0.365791
 >> iter 70000, loss: 0.416461
   Number of active neurons: 8
 >> iter 71000, loss: 0.330721
 >> iter 72000, loss: 0.255833
 >> iter 73000, loss: 0.273567
 >> iter 74000, loss: 0.212290
 >> iter 75000, loss: 0.197533
 >> iter 76000, loss: 0.214598
 >> iter 77000, loss: 0.322435
 >> iter 78000, loss: 0.173328
 >> iter 79000, loss: 0.205570
 >> iter 80000, loss: 0.233161
   Number of active neurons: 8
 >> iter 81000, loss: 0.242580
 >> iter 82000, loss: 0.213237
 >> iter 83000, loss: 0.289410
 >> iter 84000, loss: 0.304977
 >> iter 85000, loss: 0.255957
 >> iter 86000, loss: 0.234737
 >> iter 87000, loss: 0.314082
 >> iter 88000, loss: 0.347575
 >> iter 89000, loss: 0.341074
 >> iter 90000, loss: 0.260355
   Number of active neurons: 7
 >> iter 91000, loss: 0.263838
 >> iter 92000, loss: 0.264815
 >> iter 93000, loss: 0.230740
 >> iter 94000, loss: 0.208298
 >> iter 95000, loss: 0.272564
 >> iter 96000, loss: 0.276253
 >> iter 97000, loss: 0.215708
 >> iter 98000, loss: 0.303579
 >> iter 99000, loss: 0.268590
 >> iter 100000, loss: 0.243406
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.112586
 >> iter 2000, loss: 10.458830
 >> iter 3000, loss: 7.199880
 >> iter 4000, loss: 4.899680
 >> iter 5000, loss: 3.402717
 >> iter 6000, loss: 2.872226
 >> iter 7000, loss: 2.713832
 >> iter 8000, loss: 2.570657
 >> iter 9000, loss: 2.106156
 >> iter 10000, loss: 1.626263
   Number of active neurons: 8
 >> iter 11000, loss: 1.275963
 >> iter 12000, loss: 0.836809
 >> iter 13000, loss: 0.822729
 >> iter 14000, loss: 0.689017
 >> iter 15000, loss: 0.565915
 >> iter 16000, loss: 0.613166
 >> iter 17000, loss: 0.503829
 >> iter 18000, loss: 0.456100
 >> iter 19000, loss: 0.423502
 >> iter 20000, loss: 0.604087
   Number of active neurons: 7
 >> iter 21000, loss: 0.652186
 >> iter 22000, loss: 0.537674
 >> iter 23000, loss: 0.615490
 >> iter 24000, loss: 0.562560
 >> iter 25000, loss: 0.543798
 >> iter 26000, loss: 0.432403
 >> iter 27000, loss: 0.417801
 >> iter 28000, loss: 0.362968
 >> iter 29000, loss: 0.400324
 >> iter 30000, loss: 0.306482
   Number of active neurons: 6
 >> iter 31000, loss: 0.383166
 >> iter 32000, loss: 0.388401
 >> iter 33000, loss: 0.442119
 >> iter 34000, loss: 0.442728
 >> iter 35000, loss: 0.351278
 >> iter 36000, loss: 0.435571
 >> iter 37000, loss: 0.403065
 >> iter 38000, loss: 0.357118
 >> iter 39000, loss: 0.234718
 >> iter 40000, loss: 0.322313
   Number of active neurons: 6
 >> iter 41000, loss: 0.339826
 >> iter 42000, loss: 0.272529
 >> iter 43000, loss: 0.232492
 >> iter 44000, loss: 0.254641
 >> iter 45000, loss: 0.252779
 >> iter 46000, loss: 0.182565
 >> iter 47000, loss: 0.223231
 >> iter 48000, loss: 0.203739
 >> iter 49000, loss: 0.233489
 >> iter 50000, loss: 0.210486
   Number of active neurons: 6
 >> iter 51000, loss: 0.197872
 >> iter 52000, loss: 0.260339
 >> iter 53000, loss: 0.251502
 >> iter 54000, loss: 0.359555
 >> iter 55000, loss: 0.270580
 >> iter 56000, loss: 0.314140
 >> iter 57000, loss: 0.287797
 >> iter 58000, loss: 0.293720
 >> iter 59000, loss: 0.289348
 >> iter 60000, loss: 0.306769
   Number of active neurons: 6
 >> iter 61000, loss: 0.286538
 >> iter 62000, loss: 0.196540
 >> iter 63000, loss: 0.239589
 >> iter 64000, loss: 0.250020
 >> iter 65000, loss: 0.246403
 >> iter 66000, loss: 0.263190
 >> iter 67000, loss: 0.309974
 >> iter 68000, loss: 0.214013
 >> iter 69000, loss: 0.282103
 >> iter 70000, loss: 0.199155
   Number of active neurons: 6
 >> iter 71000, loss: 0.255146
 >> iter 72000, loss: 0.502336
 >> iter 73000, loss: 0.443007
 >> iter 74000, loss: 0.409254
 >> iter 75000, loss: 0.344621
 >> iter 76000, loss: 0.360717
 >> iter 77000, loss: 0.359128
 >> iter 78000, loss: 0.322070
 >> iter 79000, loss: 0.408268
 >> iter 80000, loss: 0.328333
   Number of active neurons: 5
 >> iter 81000, loss: 0.283409
 >> iter 82000, loss: 0.362972
 >> iter 83000, loss: 0.278701
 >> iter 84000, loss: 0.232057
 >> iter 85000, loss: 0.221270
 >> iter 86000, loss: 0.188319
 >> iter 87000, loss: 0.324828
 >> iter 88000, loss: 0.282544
 >> iter 89000, loss: 0.242299
 >> iter 90000, loss: 0.339480
   Number of active neurons: 4
 >> iter 91000, loss: 0.329328
 >> iter 92000, loss: 0.238534
 >> iter 93000, loss: 0.381437
 >> iter 94000, loss: 0.323640
 >> iter 95000, loss: 0.254957
 >> iter 96000, loss: 0.296609
 >> iter 97000, loss: 0.360174
 >> iter 98000, loss: 0.355662
 >> iter 99000, loss: 0.237286
 >> iter 100000, loss: 0.250501
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.543470
 >> iter 2000, loss: 9.962049
 >> iter 3000, loss: 6.165151
 >> iter 4000, loss: 3.547289
 >> iter 5000, loss: 2.309803
 >> iter 6000, loss: 1.590897
 >> iter 7000, loss: 1.145709
 >> iter 8000, loss: 0.937314
 >> iter 9000, loss: 0.757999
 >> iter 10000, loss: 0.561333
   Number of active neurons: 5
 >> iter 11000, loss: 0.537682
 >> iter 12000, loss: 0.580194
 >> iter 13000, loss: 0.518022
 >> iter 14000, loss: 0.345946
 >> iter 15000, loss: 0.294644
 >> iter 16000, loss: 0.244444
 >> iter 17000, loss: 0.395338
 >> iter 18000, loss: 0.569295
 >> iter 19000, loss: 0.474067
 >> iter 20000, loss: 0.319525
   Number of active neurons: 5
 >> iter 21000, loss: 0.387991
 >> iter 22000, loss: 0.443385
 >> iter 23000, loss: 0.478505
 >> iter 24000, loss: 0.370897
 >> iter 25000, loss: 0.325218
 >> iter 26000, loss: 0.298059
 >> iter 27000, loss: 0.324424
 >> iter 28000, loss: 0.467791
 >> iter 29000, loss: 0.358143
 >> iter 30000, loss: 0.299607
   Number of active neurons: 5
 >> iter 31000, loss: 0.338022
 >> iter 32000, loss: 0.324331
 >> iter 33000, loss: 0.473027
 >> iter 34000, loss: 0.438770
 >> iter 35000, loss: 0.530672
 >> iter 36000, loss: 0.582062
 >> iter 37000, loss: 0.550214
 >> iter 38000, loss: 0.442369
 >> iter 39000, loss: 0.436208
 >> iter 40000, loss: 0.656771
   Number of active neurons: 5
 >> iter 41000, loss: 0.594452
 >> iter 42000, loss: 0.661788
 >> iter 43000, loss: 0.570161
 >> iter 44000, loss: 0.555313
 >> iter 45000, loss: 0.537585
 >> iter 46000, loss: 0.543796
 >> iter 47000, loss: 0.526425
 >> iter 48000, loss: 0.517588
 >> iter 49000, loss: 0.696935
 >> iter 50000, loss: 0.594119
   Number of active neurons: 5
 >> iter 51000, loss: 0.544592
 >> iter 52000, loss: 0.427587
 >> iter 53000, loss: 0.461852
 >> iter 54000, loss: 0.517751
 >> iter 55000, loss: 0.458345
 >> iter 56000, loss: 0.422266
 >> iter 57000, loss: 0.435115
 >> iter 58000, loss: 0.404696
 >> iter 59000, loss: 0.469884
 >> iter 60000, loss: 0.574569
   Number of active neurons: 5
 >> iter 61000, loss: 0.596700
 >> iter 62000, loss: 0.704887
 >> iter 63000, loss: 0.612368
 >> iter 64000, loss: 0.664061
 >> iter 65000, loss: 0.543525
 >> iter 66000, loss: 0.613186
 >> iter 67000, loss: 0.652076
 >> iter 68000, loss: 0.551320
 >> iter 69000, loss: 0.697401
 >> iter 70000, loss: 0.668570
   Number of active neurons: 4
 >> iter 71000, loss: 0.479034
 >> iter 72000, loss: 0.400885
 >> iter 73000, loss: 0.586719
 >> iter 74000, loss: 0.578663
 >> iter 75000, loss: 0.475227
 >> iter 76000, loss: 0.461011
 >> iter 77000, loss: 0.629140
 >> iter 78000, loss: 0.728869
 >> iter 79000, loss: 0.796435
 >> iter 80000, loss: 0.804820
   Number of active neurons: 5
 >> iter 81000, loss: 0.850477
 >> iter 82000, loss: 0.558295
 >> iter 83000, loss: 0.522113
 >> iter 84000, loss: 0.716839
 >> iter 85000, loss: 0.605713
 >> iter 86000, loss: 0.630847
 >> iter 87000, loss: 0.601573
 >> iter 88000, loss: 0.579753
 >> iter 89000, loss: 0.503373
 >> iter 90000, loss: 0.546905
   Number of active neurons: 4
 >> iter 91000, loss: 0.528064
 >> iter 92000, loss: 0.447050
 >> iter 93000, loss: 0.471828
 >> iter 94000, loss: 0.464889
 >> iter 95000, loss: 0.436397
 >> iter 96000, loss: 0.634526
 >> iter 97000, loss: 0.688628
 >> iter 98000, loss: 0.552630
 >> iter 99000, loss: 0.688231
 >> iter 100000, loss: 0.508900
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.827983
 >> iter 2000, loss: 10.525029
 >> iter 3000, loss: 7.577437
 >> iter 4000, loss: 5.924873
 >> iter 5000, loss: 4.932095
 >> iter 6000, loss: 3.924121
 >> iter 7000, loss: 2.794486
 >> iter 8000, loss: 2.053845
 >> iter 9000, loss: 1.428572
 >> iter 10000, loss: 0.898959
   Number of active neurons: 8
 >> iter 11000, loss: 0.793594
 >> iter 12000, loss: 0.685374
 >> iter 13000, loss: 0.700044
 >> iter 14000, loss: 0.431999
 >> iter 15000, loss: 0.575075
 >> iter 16000, loss: 0.504281
 >> iter 17000, loss: 0.438918
 >> iter 18000, loss: 0.374793
 >> iter 19000, loss: 0.364475
 >> iter 20000, loss: 0.417358
   Number of active neurons: 6
 >> iter 21000, loss: 0.438226
 >> iter 22000, loss: 0.448701
 >> iter 23000, loss: 0.300589
 >> iter 24000, loss: 0.321150
 >> iter 25000, loss: 0.341009
 >> iter 26000, loss: 0.465193
 >> iter 27000, loss: 0.460206
 >> iter 28000, loss: 0.325834
 >> iter 29000, loss: 0.304962
 >> iter 30000, loss: 0.304723
   Number of active neurons: 6
 >> iter 31000, loss: 0.449058
 >> iter 32000, loss: 0.405598
 >> iter 33000, loss: 0.445851
 >> iter 34000, loss: 0.309469
 >> iter 35000, loss: 0.279305
 >> iter 36000, loss: 0.228655
 >> iter 37000, loss: 0.322891
 >> iter 38000, loss: 0.321220
 >> iter 39000, loss: 0.294495
 >> iter 40000, loss: 0.277643
   Number of active neurons: 4
 >> iter 41000, loss: 0.276476
 >> iter 42000, loss: 0.387943
 >> iter 43000, loss: 0.425960
 >> iter 44000, loss: 0.310607
 >> iter 45000, loss: 0.347097
 >> iter 46000, loss: 0.392357
 >> iter 47000, loss: 0.299387
 >> iter 48000, loss: 0.473314
 >> iter 49000, loss: 0.374115
 >> iter 50000, loss: 0.361490
   Number of active neurons: 4
 >> iter 51000, loss: 0.377765
 >> iter 52000, loss: 0.447288
 >> iter 53000, loss: 0.411353
 >> iter 54000, loss: 0.514753
 >> iter 55000, loss: 0.389977
 >> iter 56000, loss: 0.488569
 >> iter 57000, loss: 0.535301
 >> iter 58000, loss: 0.430900
 >> iter 59000, loss: 0.355369
 >> iter 60000, loss: 0.320124
   Number of active neurons: 4
 >> iter 61000, loss: 0.289103
 >> iter 62000, loss: 0.396161
 >> iter 63000, loss: 0.385281
 >> iter 64000, loss: 0.377857
 >> iter 65000, loss: 0.522393
 >> iter 66000, loss: 0.413217
 >> iter 67000, loss: 0.325953
 >> iter 68000, loss: 0.415895
 >> iter 69000, loss: 0.440228
 >> iter 70000, loss: 0.349175
   Number of active neurons: 4
 >> iter 71000, loss: 0.339579
 >> iter 72000, loss: 0.454668
 >> iter 73000, loss: 0.337261
 >> iter 74000, loss: 0.430829
 >> iter 75000, loss: 0.407081
 >> iter 76000, loss: 0.301113
 >> iter 77000, loss: 0.301894
 >> iter 78000, loss: 0.428661
 >> iter 79000, loss: 0.354981
 >> iter 80000, loss: 0.269402
   Number of active neurons: 4
 >> iter 81000, loss: 0.437116
 >> iter 82000, loss: 0.504142
 >> iter 83000, loss: 0.489504
 >> iter 84000, loss: 0.402231
 >> iter 85000, loss: 0.420135
 >> iter 86000, loss: 0.332411
 >> iter 87000, loss: 0.297992
 >> iter 88000, loss: 0.277793
 >> iter 89000, loss: 0.245657
 >> iter 90000, loss: 0.262925
   Number of active neurons: 4
 >> iter 91000, loss: 0.333666
 >> iter 92000, loss: 0.622217
 >> iter 93000, loss: 0.337351
 >> iter 94000, loss: 0.346191
 >> iter 95000, loss: 0.363611
 >> iter 96000, loss: 0.371812
 >> iter 97000, loss: 0.360762
 >> iter 98000, loss: 0.408195
 >> iter 99000, loss: 0.402320
 >> iter 100000, loss: 0.519588
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.839299
 >> iter 2000, loss: 9.429287
 >> iter 3000, loss: 5.578690
 >> iter 4000, loss: 3.250438
 >> iter 5000, loss: 1.820637
 >> iter 6000, loss: 1.464512
 >> iter 7000, loss: 1.137838
 >> iter 8000, loss: 1.007391
 >> iter 9000, loss: 0.860780
 >> iter 10000, loss: 0.709278
   Number of active neurons: 6
 >> iter 11000, loss: 0.570241
 >> iter 12000, loss: 0.485131
 >> iter 13000, loss: 0.554533
 >> iter 14000, loss: 0.457822
 >> iter 15000, loss: 0.542734
 >> iter 16000, loss: 0.449845
 >> iter 17000, loss: 0.461577
 >> iter 18000, loss: 0.602797
 >> iter 19000, loss: 0.494669
 >> iter 20000, loss: 0.387771
   Number of active neurons: 6
 >> iter 21000, loss: 0.493188
 >> iter 22000, loss: 0.647035
 >> iter 23000, loss: 0.444833
 >> iter 24000, loss: 0.398264
 >> iter 25000, loss: 0.364236
 >> iter 26000, loss: 0.345936
 >> iter 27000, loss: 0.481945
 >> iter 28000, loss: 0.598532
 >> iter 29000, loss: 0.538829
 >> iter 30000, loss: 0.369872
   Number of active neurons: 6
 >> iter 31000, loss: 0.422305
 >> iter 32000, loss: 0.349388
 >> iter 33000, loss: 0.414897
 >> iter 34000, loss: 0.408715
 >> iter 35000, loss: 0.647857
 >> iter 36000, loss: 0.537610
 >> iter 37000, loss: 0.620356
 >> iter 38000, loss: 0.741489
 >> iter 39000, loss: 0.518047
 >> iter 40000, loss: 0.438978
   Number of active neurons: 6
 >> iter 41000, loss: 0.450249
 >> iter 42000, loss: 0.697740
 >> iter 43000, loss: 0.802242
 >> iter 44000, loss: 0.518622
 >> iter 45000, loss: 0.571417
 >> iter 46000, loss: 0.543763
 >> iter 47000, loss: 0.484303
 >> iter 48000, loss: 0.468869
 >> iter 49000, loss: 0.488790
 >> iter 50000, loss: 0.638875
   Number of active neurons: 7
 >> iter 51000, loss: 0.644475
 >> iter 52000, loss: 0.600196
 >> iter 53000, loss: 0.382548
 >> iter 54000, loss: 0.487542
 >> iter 55000, loss: 0.398264
 >> iter 56000, loss: 0.388064
 >> iter 57000, loss: 0.472120
 >> iter 58000, loss: 0.599129
 >> iter 59000, loss: 0.649720
 >> iter 60000, loss: 0.572732
   Number of active neurons: 5
 >> iter 61000, loss: 0.417535
 >> iter 62000, loss: 0.359083
 >> iter 63000, loss: 0.441934
 >> iter 64000, loss: 0.474864
 >> iter 65000, loss: 0.563105
 >> iter 66000, loss: 0.426113
 >> iter 67000, loss: 0.532180
 >> iter 68000, loss: 0.490786
 >> iter 69000, loss: 0.568109
 >> iter 70000, loss: 0.488488
   Number of active neurons: 5
 >> iter 71000, loss: 0.394975
 >> iter 72000, loss: 0.519272
 >> iter 73000, loss: 0.516797
 >> iter 74000, loss: 0.468140
 >> iter 75000, loss: 0.338819
 >> iter 76000, loss: 0.393480
 >> iter 77000, loss: 0.557180
 >> iter 78000, loss: 0.437189
 >> iter 79000, loss: 0.439234
 >> iter 80000, loss: 0.505561
   Number of active neurons: 5
 >> iter 81000, loss: 0.508444
 >> iter 82000, loss: 0.635767
 >> iter 83000, loss: 0.625328
 >> iter 84000, loss: 0.525962
 >> iter 85000, loss: 0.560544
 >> iter 86000, loss: 0.577289
 >> iter 87000, loss: 0.511083
 >> iter 88000, loss: 0.439917
 >> iter 89000, loss: 0.610449
 >> iter 90000, loss: 0.544297
   Number of active neurons: 5
 >> iter 91000, loss: 0.570832
 >> iter 92000, loss: 0.754086
 >> iter 93000, loss: 0.512391
 >> iter 94000, loss: 0.447726
 >> iter 95000, loss: 0.607166
 >> iter 96000, loss: 0.740320
 >> iter 97000, loss: 0.605344
 >> iter 98000, loss: 0.676516
 >> iter 99000, loss: 0.666484
 >> iter 100000, loss: 0.743832
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.902487
 >> iter 2000, loss: 9.703468
 >> iter 3000, loss: 5.518378
 >> iter 4000, loss: 3.090219
 >> iter 5000, loss: 1.697107
 >> iter 6000, loss: 0.971145
 >> iter 7000, loss: 0.651894
 >> iter 8000, loss: 0.495337
 >> iter 9000, loss: 0.408443
 >> iter 10000, loss: 0.358229
   Number of active neurons: 7
 >> iter 11000, loss: 0.296279
 >> iter 12000, loss: 0.266692
 >> iter 13000, loss: 0.225071
 >> iter 14000, loss: 0.184651
 >> iter 15000, loss: 0.231423
 >> iter 16000, loss: 0.274393
 >> iter 17000, loss: 0.462771
 >> iter 18000, loss: 0.341493
 >> iter 19000, loss: 0.267520
 >> iter 20000, loss: 0.234399
   Number of active neurons: 7
 >> iter 21000, loss: 0.330856
 >> iter 22000, loss: 0.366109
 >> iter 23000, loss: 0.420755
 >> iter 24000, loss: 0.286830
 >> iter 25000, loss: 0.161668
 >> iter 26000, loss: 0.145570
 >> iter 27000, loss: 0.264859
 >> iter 28000, loss: 0.244348
 >> iter 29000, loss: 0.267753
 >> iter 30000, loss: 0.220212
   Number of active neurons: 7
 >> iter 31000, loss: 0.206143
 >> iter 32000, loss: 0.181259
 >> iter 33000, loss: 0.208530
 >> iter 34000, loss: 0.164821
 >> iter 35000, loss: 0.147665
 >> iter 36000, loss: 0.180146
 >> iter 37000, loss: 0.209782
 >> iter 38000, loss: 0.213272
 >> iter 39000, loss: 0.246751
 >> iter 40000, loss: 0.243163
   Number of active neurons: 6
 >> iter 41000, loss: 0.267667
 >> iter 42000, loss: 0.325891
 >> iter 43000, loss: 0.267185
 >> iter 44000, loss: 0.262925
 >> iter 45000, loss: 0.202069
 >> iter 46000, loss: 0.242343
 >> iter 47000, loss: 0.203379
 >> iter 48000, loss: 0.272190
 >> iter 49000, loss: 0.279961
 >> iter 50000, loss: 0.372759
   Number of active neurons: 6
 >> iter 51000, loss: 0.388252
 >> iter 52000, loss: 0.280794
 >> iter 53000, loss: 0.164992
 >> iter 54000, loss: 0.230160
 >> iter 55000, loss: 0.252048
 >> iter 56000, loss: 0.242428
 >> iter 57000, loss: 0.300422
 >> iter 58000, loss: 0.228663
 >> iter 59000, loss: 0.308730
 >> iter 60000, loss: 0.219948
   Number of active neurons: 6
 >> iter 61000, loss: 0.235988
 >> iter 62000, loss: 0.223042
 >> iter 63000, loss: 0.223094
 >> iter 64000, loss: 0.262494
 >> iter 65000, loss: 0.217724
 >> iter 66000, loss: 0.167699
 >> iter 67000, loss: 0.208163
 >> iter 68000, loss: 0.324088
 >> iter 69000, loss: 0.302086
 >> iter 70000, loss: 0.230316
   Number of active neurons: 6
 >> iter 71000, loss: 0.307022
 >> iter 72000, loss: 0.298001
 >> iter 73000, loss: 0.301423
 >> iter 74000, loss: 0.231558
 >> iter 75000, loss: 0.257287
 >> iter 76000, loss: 0.232501
 >> iter 77000, loss: 0.196124
 >> iter 78000, loss: 0.216135
 >> iter 79000, loss: 0.234008
 >> iter 80000, loss: 0.238286
   Number of active neurons: 6
 >> iter 81000, loss: 0.256518
 >> iter 82000, loss: 0.278434
 >> iter 83000, loss: 0.230241
 >> iter 84000, loss: 0.229081
 >> iter 85000, loss: 0.201422
 >> iter 86000, loss: 0.196818
 >> iter 87000, loss: 0.250719
 >> iter 88000, loss: 0.210232
 >> iter 89000, loss: 0.316583
 >> iter 90000, loss: 0.236906
   Number of active neurons: 6
 >> iter 91000, loss: 0.256104
 >> iter 92000, loss: 0.204093
 >> iter 93000, loss: 0.347541
 >> iter 94000, loss: 0.308666
 >> iter 95000, loss: 0.224521
 >> iter 96000, loss: 0.262760
 >> iter 97000, loss: 0.365011
 >> iter 98000, loss: 0.407867
 >> iter 99000, loss: 0.300418
 >> iter 100000, loss: 0.213549
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

