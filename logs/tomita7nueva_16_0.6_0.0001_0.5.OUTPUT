 > Problema: tomita7nueva
 > Args:
   - Hidden size: 16
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.601120
 >> iter 2000, loss: 9.704744
 >> iter 3000, loss: 5.516213
 >> iter 4000, loss: 2.383972
 >> iter 5000, loss: 1.123041
 >> iter 6000, loss: 0.732211
 >> iter 7000, loss: 0.486817
 >> iter 8000, loss: 0.337457
 >> iter 9000, loss: 0.323813
 >> iter 10000, loss: 0.215962
   Number of active neurons: 9
 >> iter 11000, loss: 0.377479
 >> iter 12000, loss: 0.453218
 >> iter 13000, loss: 0.398581
 >> iter 14000, loss: 0.329896
 >> iter 15000, loss: 0.367535
 >> iter 16000, loss: 0.299840
 >> iter 17000, loss: 0.227211
 >> iter 18000, loss: 0.232203
 >> iter 19000, loss: 0.462716
 >> iter 20000, loss: 0.522147
   Number of active neurons: 9
 >> iter 21000, loss: 0.425196
 >> iter 22000, loss: 0.430785
 >> iter 23000, loss: 0.396302
 >> iter 24000, loss: 0.424687
 >> iter 25000, loss: 0.465971
 >> iter 26000, loss: 0.311944
 >> iter 27000, loss: 0.343458
 >> iter 28000, loss: 0.268664
 >> iter 29000, loss: 0.228581
 >> iter 30000, loss: 0.254825
   Number of active neurons: 9
 >> iter 31000, loss: 0.298117
 >> iter 32000, loss: 0.559416
 >> iter 33000, loss: 0.379091
 >> iter 34000, loss: 0.312053
 >> iter 35000, loss: 0.463440
 >> iter 36000, loss: 0.304135
 >> iter 37000, loss: 0.470094
 >> iter 38000, loss: 0.346481
 >> iter 39000, loss: 0.511645
 >> iter 40000, loss: 0.452593
   Number of active neurons: 9
 >> iter 41000, loss: 0.363173
 >> iter 42000, loss: 0.336734
 >> iter 43000, loss: 0.366388
 >> iter 44000, loss: 0.442827
 >> iter 45000, loss: 0.460034
 >> iter 46000, loss: 0.499874
 >> iter 47000, loss: 0.309082
 >> iter 48000, loss: 0.381038
 >> iter 49000, loss: 0.376873
 >> iter 50000, loss: 0.350564
   Number of active neurons: 9
 >> iter 51000, loss: 0.240634
 >> iter 52000, loss: 0.257304
 >> iter 53000, loss: 0.233905
 >> iter 54000, loss: 0.355543
 >> iter 55000, loss: 0.303927
 >> iter 56000, loss: 0.425011
 >> iter 57000, loss: 0.280345
 >> iter 58000, loss: 0.317840
 >> iter 59000, loss: 0.212252
 >> iter 60000, loss: 0.257749
   Number of active neurons: 9
 >> iter 61000, loss: 0.379276
 >> iter 62000, loss: 0.401046
 >> iter 63000, loss: 0.472408
 >> iter 64000, loss: 0.351793
 >> iter 65000, loss: 0.350894
 >> iter 66000, loss: 0.337279
 >> iter 67000, loss: 0.310953
 >> iter 68000, loss: 0.296589
 >> iter 69000, loss: 0.364242
 >> iter 70000, loss: 0.385766
   Number of active neurons: 9
 >> iter 71000, loss: 0.348557
 >> iter 72000, loss: 0.337111
 >> iter 73000, loss: 0.320002
 >> iter 74000, loss: 0.264791
 >> iter 75000, loss: 0.304711
 >> iter 76000, loss: 0.284518
 >> iter 77000, loss: 0.346222
 >> iter 78000, loss: 0.345877
 >> iter 79000, loss: 0.355280
 >> iter 80000, loss: 0.437340
   Number of active neurons: 9
 >> iter 81000, loss: 0.439068
 >> iter 82000, loss: 0.297409
 >> iter 83000, loss: 0.312829
 >> iter 84000, loss: 0.331348
 >> iter 85000, loss: 0.327810
 >> iter 86000, loss: 0.284600
 >> iter 87000, loss: 0.372251
 >> iter 88000, loss: 0.210170
 >> iter 89000, loss: 0.349809
 >> iter 90000, loss: 0.271276
   Number of active neurons: 9
 >> iter 91000, loss: 0.346659
 >> iter 92000, loss: 0.329709
 >> iter 93000, loss: 0.361875
 >> iter 94000, loss: 0.267031
 >> iter 95000, loss: 0.287998
 >> iter 96000, loss: 0.263501
 >> iter 97000, loss: 0.328432
 >> iter 98000, loss: 0.341173
 >> iter 99000, loss: 0.312414
 >> iter 100000, loss: 0.280955
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.249507
 >> iter 2000, loss: 11.570592
 >> iter 3000, loss: 6.676599
 >> iter 4000, loss: 3.147651
 >> iter 5000, loss: 1.450340
 >> iter 6000, loss: 0.862907
 >> iter 7000, loss: 0.548766
 >> iter 8000, loss: 0.407051
 >> iter 9000, loss: 0.432232
 >> iter 10000, loss: 0.413424
   Number of active neurons: 11
 >> iter 11000, loss: 0.395026
 >> iter 12000, loss: 0.421057
 >> iter 13000, loss: 0.301087
 >> iter 14000, loss: 0.421913
 >> iter 15000, loss: 0.281889
 >> iter 16000, loss: 0.323202
 >> iter 17000, loss: 0.282766
 >> iter 18000, loss: 0.245316
 >> iter 19000, loss: 0.283394
 >> iter 20000, loss: 0.305965
   Number of active neurons: 10
 >> iter 21000, loss: 0.281594
 >> iter 22000, loss: 0.365427
 >> iter 23000, loss: 0.388313
 >> iter 24000, loss: 0.367756
 >> iter 25000, loss: 0.284210
 >> iter 26000, loss: 0.368890
 >> iter 27000, loss: 0.448522
 >> iter 28000, loss: 0.321578
 >> iter 29000, loss: 0.308282
 >> iter 30000, loss: 0.268347
   Number of active neurons: 9
 >> iter 31000, loss: 0.404755
 >> iter 32000, loss: 0.382342
 >> iter 33000, loss: 0.360171
 >> iter 34000, loss: 0.284651
 >> iter 35000, loss: 0.393192
 >> iter 36000, loss: 0.297505
 >> iter 37000, loss: 0.323602
 >> iter 38000, loss: 0.280129
 >> iter 39000, loss: 0.390928
 >> iter 40000, loss: 0.459531
   Number of active neurons: 9
 >> iter 41000, loss: 0.319562
 >> iter 42000, loss: 0.278254
 >> iter 43000, loss: 0.280113
 >> iter 44000, loss: 0.219169
 >> iter 45000, loss: 0.324237
 >> iter 46000, loss: 0.336946
 >> iter 47000, loss: 0.363842
 >> iter 48000, loss: 0.336628
 >> iter 49000, loss: 0.254791
 >> iter 50000, loss: 0.339388
   Number of active neurons: 9
 >> iter 51000, loss: 0.286559
 >> iter 52000, loss: 0.414301
 >> iter 53000, loss: 0.445266
 >> iter 54000, loss: 0.406585
 >> iter 55000, loss: 0.433174
 >> iter 56000, loss: 0.334200
 >> iter 57000, loss: 0.316093
 >> iter 58000, loss: 0.229028
 >> iter 59000, loss: 0.360683
 >> iter 60000, loss: 0.382280
   Number of active neurons: 9
 >> iter 61000, loss: 0.288270
 >> iter 62000, loss: 0.291183
 >> iter 63000, loss: 0.222758
 >> iter 64000, loss: 0.281404
 >> iter 65000, loss: 0.308920
 >> iter 66000, loss: 0.358202
 >> iter 67000, loss: 0.306714
 >> iter 68000, loss: 0.263708
 >> iter 69000, loss: 0.480864
 >> iter 70000, loss: 0.358287
   Number of active neurons: 9
 >> iter 71000, loss: 0.335572
 >> iter 72000, loss: 0.332187
 >> iter 73000, loss: 0.337034
 >> iter 74000, loss: 0.345352
 >> iter 75000, loss: 0.369788
 >> iter 76000, loss: 0.351025
 >> iter 77000, loss: 0.278834
 >> iter 78000, loss: 0.418154
 >> iter 79000, loss: 0.427451
 >> iter 80000, loss: 0.372321
   Number of active neurons: 8
 >> iter 81000, loss: 0.379668
 >> iter 82000, loss: 0.309394
 >> iter 83000, loss: 0.358121
 >> iter 84000, loss: 0.372824
 >> iter 85000, loss: 0.378191
 >> iter 86000, loss: 0.282726
 >> iter 87000, loss: 0.355519
 >> iter 88000, loss: 0.569135
 >> iter 89000, loss: 0.338149
 >> iter 90000, loss: 0.260825
   Number of active neurons: 7
 >> iter 91000, loss: 0.198779
 >> iter 92000, loss: 0.231273
 >> iter 93000, loss: 0.325161
 >> iter 94000, loss: 0.408437
 >> iter 95000, loss: 0.325892
 >> iter 96000, loss: 0.308475
 >> iter 97000, loss: 0.259314
 >> iter 98000, loss: 0.235761
 >> iter 99000, loss: 0.268459
 >> iter 100000, loss: 0.378423
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.997683
 >> iter 2000, loss: 10.424002
 >> iter 3000, loss: 6.775383
 >> iter 4000, loss: 3.133931
 >> iter 5000, loss: 1.522726
 >> iter 6000, loss: 0.835525
 >> iter 7000, loss: 0.559484
 >> iter 8000, loss: 0.424369
 >> iter 9000, loss: 0.417669
 >> iter 10000, loss: 0.324294
   Number of active neurons: 10
 >> iter 11000, loss: 0.282439
 >> iter 12000, loss: 0.285333
 >> iter 13000, loss: 0.295966
 >> iter 14000, loss: 0.279583
 >> iter 15000, loss: 0.249764
 >> iter 16000, loss: 0.308511
 >> iter 17000, loss: 0.275105
 >> iter 18000, loss: 0.237093
 >> iter 19000, loss: 0.294966
 >> iter 20000, loss: 0.250322
   Number of active neurons: 10
 >> iter 21000, loss: 0.157946
 >> iter 22000, loss: 0.117915
 >> iter 23000, loss: 0.228408
 >> iter 24000, loss: 0.247166
 >> iter 25000, loss: 0.206811
 >> iter 26000, loss: 0.295661
 >> iter 27000, loss: 0.192287
 >> iter 28000, loss: 0.202361
 >> iter 29000, loss: 0.208057
 >> iter 30000, loss: 0.192466
   Number of active neurons: 9
 >> iter 31000, loss: 0.307505
 >> iter 32000, loss: 0.257231
 >> iter 33000, loss: 0.261853
 >> iter 34000, loss: 0.296307
 >> iter 35000, loss: 0.233418
 >> iter 36000, loss: 0.276416
 >> iter 37000, loss: 0.244964
 >> iter 38000, loss: 0.256212
 >> iter 39000, loss: 0.224137
 >> iter 40000, loss: 0.256865
   Number of active neurons: 7
 >> iter 41000, loss: 0.289371
 >> iter 42000, loss: 0.329840
 >> iter 43000, loss: 0.247955
 >> iter 44000, loss: 0.269420
 >> iter 45000, loss: 0.175393
 >> iter 46000, loss: 0.312798
 >> iter 47000, loss: 0.315839
 >> iter 48000, loss: 0.305350
 >> iter 49000, loss: 0.304251
 >> iter 50000, loss: 0.263808
   Number of active neurons: 7
 >> iter 51000, loss: 0.250963
 >> iter 52000, loss: 0.227986
 >> iter 53000, loss: 0.188484
 >> iter 54000, loss: 0.267480
 >> iter 55000, loss: 0.232694
 >> iter 56000, loss: 0.292050
 >> iter 57000, loss: 0.264410
 >> iter 58000, loss: 0.301276
 >> iter 59000, loss: 0.235497
 >> iter 60000, loss: 0.194879
   Number of active neurons: 6
 >> iter 61000, loss: 0.219879
 >> iter 62000, loss: 0.319074
 >> iter 63000, loss: 0.297982
 >> iter 64000, loss: 0.280039
 >> iter 65000, loss: 0.242826
 >> iter 66000, loss: 0.297412
 >> iter 67000, loss: 0.296470
 >> iter 68000, loss: 0.287246
 >> iter 69000, loss: 0.263321
 >> iter 70000, loss: 0.239311
   Number of active neurons: 6
 >> iter 71000, loss: 0.334072
 >> iter 72000, loss: 0.214622
 >> iter 73000, loss: 0.263667
 >> iter 74000, loss: 0.159362
 >> iter 75000, loss: 0.235200
 >> iter 76000, loss: 0.247369
 >> iter 77000, loss: 0.210938
 >> iter 78000, loss: 0.207881
 >> iter 79000, loss: 0.196597
 >> iter 80000, loss: 0.197638
   Number of active neurons: 6
 >> iter 81000, loss: 0.146033
 >> iter 82000, loss: 0.191632
 >> iter 83000, loss: 0.251824
 >> iter 84000, loss: 0.268552
 >> iter 85000, loss: 0.250208
 >> iter 86000, loss: 0.273851
 >> iter 87000, loss: 0.279523
 >> iter 88000, loss: 0.203662
 >> iter 89000, loss: 0.228191
 >> iter 90000, loss: 0.303615
   Number of active neurons: 6
 >> iter 91000, loss: 0.243177
 >> iter 92000, loss: 0.176562
 >> iter 93000, loss: 0.212915
 >> iter 94000, loss: 0.244033
 >> iter 95000, loss: 0.173365
 >> iter 96000, loss: 0.172865
 >> iter 97000, loss: 0.215189
 >> iter 98000, loss: 0.201107
 >> iter 99000, loss: 0.226965
 >> iter 100000, loss: 0.277637
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.577222
 >> iter 2000, loss: 11.541460
 >> iter 3000, loss: 7.666504
 >> iter 4000, loss: 5.129944
 >> iter 5000, loss: 3.529286
 >> iter 6000, loss: 2.271685
 >> iter 7000, loss: 1.392478
 >> iter 8000, loss: 1.207843
 >> iter 9000, loss: 0.959587
 >> iter 10000, loss: 0.832792
   Number of active neurons: 9
 >> iter 11000, loss: 0.793805
 >> iter 12000, loss: 0.734488
 >> iter 13000, loss: 0.734802
 >> iter 14000, loss: 0.784235
 >> iter 15000, loss: 0.740000
 >> iter 16000, loss: 0.731143
 >> iter 17000, loss: 0.735956
 >> iter 18000, loss: 0.815934
 >> iter 19000, loss: 1.061695
 >> iter 20000, loss: 0.855375
   Number of active neurons: 8
 >> iter 21000, loss: 0.661949
 >> iter 22000, loss: 0.734057
 >> iter 23000, loss: 0.608912
 >> iter 24000, loss: 0.630960
 >> iter 25000, loss: 0.684189
 >> iter 26000, loss: 0.741964
 >> iter 27000, loss: 0.566926
 >> iter 28000, loss: 0.544353
 >> iter 29000, loss: 0.702847
 >> iter 30000, loss: 0.867577
   Number of active neurons: 11
 >> iter 31000, loss: 0.783283
 >> iter 32000, loss: 0.604294
 >> iter 33000, loss: 0.721106
 >> iter 34000, loss: 0.566354
 >> iter 35000, loss: 0.528676
 >> iter 36000, loss: 0.559280
 >> iter 37000, loss: 0.433119
 >> iter 38000, loss: 0.522878
 >> iter 39000, loss: 0.568217
 >> iter 40000, loss: 0.489908
   Number of active neurons: 7
 >> iter 41000, loss: 0.517957
 >> iter 42000, loss: 0.443029
 >> iter 43000, loss: 0.579337
 >> iter 44000, loss: 0.541831
 >> iter 45000, loss: 0.585046
 >> iter 46000, loss: 0.395645
 >> iter 47000, loss: 0.471075
 >> iter 48000, loss: 0.473915
 >> iter 49000, loss: 0.493724
 >> iter 50000, loss: 0.471287
   Number of active neurons: 6
 >> iter 51000, loss: 0.690144
 >> iter 52000, loss: 0.677848
 >> iter 53000, loss: 0.774868
 >> iter 54000, loss: 0.491900
 >> iter 55000, loss: 0.521621
 >> iter 56000, loss: 0.629403
 >> iter 57000, loss: 0.702952
 >> iter 58000, loss: 0.618791
 >> iter 59000, loss: 0.627614
 >> iter 60000, loss: 0.458612
   Number of active neurons: 7
 >> iter 61000, loss: 0.560003
 >> iter 62000, loss: 0.703697
 >> iter 63000, loss: 0.509406
 >> iter 64000, loss: 0.478928
 >> iter 65000, loss: 0.502043
 >> iter 66000, loss: 0.452919
 >> iter 67000, loss: 0.580439
 >> iter 68000, loss: 0.447222
 >> iter 69000, loss: 0.496424
 >> iter 70000, loss: 0.432479
   Number of active neurons: 6
 >> iter 71000, loss: 0.494326
 >> iter 72000, loss: 0.482884
 >> iter 73000, loss: 0.426757
 >> iter 74000, loss: 0.464422
 >> iter 75000, loss: 0.370553
 >> iter 76000, loss: 0.371318
 >> iter 77000, loss: 0.504399
 >> iter 78000, loss: 0.486911
 >> iter 79000, loss: 0.437042
 >> iter 80000, loss: 0.490158
   Number of active neurons: 5
 >> iter 81000, loss: 0.531407
 >> iter 82000, loss: 0.413850
 >> iter 83000, loss: 0.411622
 >> iter 84000, loss: 0.407904
 >> iter 85000, loss: 0.397806
 >> iter 86000, loss: 0.328710
 >> iter 87000, loss: 0.338504
 >> iter 88000, loss: 0.276415
 >> iter 89000, loss: 0.434883
 >> iter 90000, loss: 0.446550
   Number of active neurons: 5
 >> iter 91000, loss: 0.418798
 >> iter 92000, loss: 0.333770
 >> iter 93000, loss: 0.328592
 >> iter 94000, loss: 0.347355
 >> iter 95000, loss: 0.304634
 >> iter 96000, loss: 0.250847
 >> iter 97000, loss: 0.412972
 >> iter 98000, loss: 0.314309
 >> iter 99000, loss: 0.430972
 >> iter 100000, loss: 0.490264
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.668476
 >> iter 2000, loss: 9.509691
 >> iter 3000, loss: 5.051874
 >> iter 4000, loss: 2.724358
 >> iter 5000, loss: 1.376198
 >> iter 6000, loss: 0.813298
 >> iter 7000, loss: 0.594975
 >> iter 8000, loss: 0.472048
 >> iter 9000, loss: 0.504484
 >> iter 10000, loss: 0.461792
   Number of active neurons: 9
 >> iter 11000, loss: 0.352876
 >> iter 12000, loss: 0.333975
 >> iter 13000, loss: 0.257813
 >> iter 14000, loss: 0.321557
 >> iter 15000, loss: 0.284855
 >> iter 16000, loss: 0.375272
 >> iter 17000, loss: 0.430913
 >> iter 18000, loss: 0.319605
 >> iter 19000, loss: 0.222655
 >> iter 20000, loss: 0.227403
   Number of active neurons: 9
 >> iter 21000, loss: 0.250344
 >> iter 22000, loss: 0.178016
 >> iter 23000, loss: 0.251996
 >> iter 24000, loss: 0.388789
 >> iter 25000, loss: 0.317877
 >> iter 26000, loss: 0.389267
 >> iter 27000, loss: 0.400107
 >> iter 28000, loss: 0.287143
 >> iter 29000, loss: 0.331403
 >> iter 30000, loss: 0.341882
   Number of active neurons: 9
 >> iter 31000, loss: 0.394795
 >> iter 32000, loss: 0.340937
 >> iter 33000, loss: 0.318581
 >> iter 34000, loss: 0.381449
 >> iter 35000, loss: 0.412885
 >> iter 36000, loss: 0.301416
 >> iter 37000, loss: 0.390864
 >> iter 38000, loss: 0.414030
 >> iter 39000, loss: 0.278965
 >> iter 40000, loss: 0.201427
   Number of active neurons: 9
 >> iter 41000, loss: 0.209926
 >> iter 42000, loss: 0.228969
 >> iter 43000, loss: 0.304264
 >> iter 44000, loss: 0.404086
 >> iter 45000, loss: 0.402608
 >> iter 46000, loss: 0.360614
 >> iter 47000, loss: 0.352335
 >> iter 48000, loss: 0.237860
 >> iter 49000, loss: 0.382503
 >> iter 50000, loss: 0.402679
   Number of active neurons: 12
 >> iter 51000, loss: 0.317816
 >> iter 52000, loss: 0.307113
 >> iter 53000, loss: 0.280534
 >> iter 54000, loss: 0.276926
 >> iter 55000, loss: 0.210438
 >> iter 56000, loss: 0.339398
 >> iter 57000, loss: 0.422424
 >> iter 58000, loss: 0.300265
 >> iter 59000, loss: 0.412372
 >> iter 60000, loss: 0.364005
   Number of active neurons: 9
 >> iter 61000, loss: 0.277532
 >> iter 62000, loss: 0.199780
 >> iter 63000, loss: 0.255186
 >> iter 64000, loss: 0.323754
 >> iter 65000, loss: 0.341403
 >> iter 66000, loss: 0.404402
 >> iter 67000, loss: 0.319657
 >> iter 68000, loss: 0.258148
 >> iter 69000, loss: 0.290133
 >> iter 70000, loss: 0.271071
   Number of active neurons: 8
 >> iter 71000, loss: 0.206104
 >> iter 72000, loss: 0.243669
 >> iter 73000, loss: 0.311770
 >> iter 74000, loss: 0.192649
 >> iter 75000, loss: 0.283998
 >> iter 76000, loss: 0.497030
 >> iter 77000, loss: 0.467428
 >> iter 78000, loss: 0.345489
 >> iter 79000, loss: 0.334011
 >> iter 80000, loss: 0.297353
   Number of active neurons: 8
 >> iter 81000, loss: 0.250578
 >> iter 82000, loss: 0.250434
 >> iter 83000, loss: 0.170619
 >> iter 84000, loss: 0.211635
 >> iter 85000, loss: 0.284554
 >> iter 86000, loss: 0.346170
 >> iter 87000, loss: 0.397716
 >> iter 88000, loss: 0.247120
 >> iter 89000, loss: 0.229103
 >> iter 90000, loss: 0.192518
   Number of active neurons: 8
 >> iter 91000, loss: 0.237010
 >> iter 92000, loss: 0.306853
 >> iter 93000, loss: 0.253392
 >> iter 94000, loss: 0.267739
 >> iter 95000, loss: 0.311633
 >> iter 96000, loss: 0.229345
 >> iter 97000, loss: 0.283216
 >> iter 98000, loss: 0.328114
 >> iter 99000, loss: 0.380770
 >> iter 100000, loss: 0.331880
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.079563
 >> iter 2000, loss: 9.653208
 >> iter 3000, loss: 4.804773
 >> iter 4000, loss: 2.383568
 >> iter 5000, loss: 1.185107
 >> iter 6000, loss: 0.690414
 >> iter 7000, loss: 0.529057
 >> iter 8000, loss: 0.482745
 >> iter 9000, loss: 0.491918
 >> iter 10000, loss: 0.315896
   Number of active neurons: 9
 >> iter 11000, loss: 0.258788
 >> iter 12000, loss: 0.303016
 >> iter 13000, loss: 0.250612
 >> iter 14000, loss: 0.275401
 >> iter 15000, loss: 0.284061
 >> iter 16000, loss: 0.246864
 >> iter 17000, loss: 0.260644
 >> iter 18000, loss: 0.253269
 >> iter 19000, loss: 0.237584
 >> iter 20000, loss: 0.329223
   Number of active neurons: 8
 >> iter 21000, loss: 0.323820
 >> iter 22000, loss: 0.273333
 >> iter 23000, loss: 0.287284
 >> iter 24000, loss: 0.248301
 >> iter 25000, loss: 0.208589
 >> iter 26000, loss: 0.229594
 >> iter 27000, loss: 0.314599
 >> iter 28000, loss: 0.234865
 >> iter 29000, loss: 0.253847
 >> iter 30000, loss: 0.231471
   Number of active neurons: 7
 >> iter 31000, loss: 0.170931
 >> iter 32000, loss: 0.193144
 >> iter 33000, loss: 0.255253
 >> iter 34000, loss: 0.305842
 >> iter 35000, loss: 0.265401
 >> iter 36000, loss: 0.186218
 >> iter 37000, loss: 0.213591
 >> iter 38000, loss: 0.200508
 >> iter 39000, loss: 0.198403
 >> iter 40000, loss: 0.177084
   Number of active neurons: 7
 >> iter 41000, loss: 0.246350
 >> iter 42000, loss: 0.187194
 >> iter 43000, loss: 0.200370
 >> iter 44000, loss: 0.269061
 >> iter 45000, loss: 0.171834
 >> iter 46000, loss: 0.228694
 >> iter 47000, loss: 0.233699
 >> iter 48000, loss: 0.220896
 >> iter 49000, loss: 0.255911
 >> iter 50000, loss: 0.273543
   Number of active neurons: 7
 >> iter 51000, loss: 0.250812
 >> iter 52000, loss: 0.207132
 >> iter 53000, loss: 0.163465
 >> iter 54000, loss: 0.224188
 >> iter 55000, loss: 0.200270
 >> iter 56000, loss: 0.151731
 >> iter 57000, loss: 0.192872
 >> iter 58000, loss: 0.127236
 >> iter 59000, loss: 0.258826
 >> iter 60000, loss: 0.250644
   Number of active neurons: 7
 >> iter 61000, loss: 0.297628
 >> iter 62000, loss: 0.174862
 >> iter 63000, loss: 0.121108
 >> iter 64000, loss: 0.134786
 >> iter 65000, loss: 0.182643
 >> iter 66000, loss: 0.223010
 >> iter 67000, loss: 0.294088
 >> iter 68000, loss: 0.216201
 >> iter 69000, loss: 0.229333
 >> iter 70000, loss: 0.132757
   Number of active neurons: 7
 >> iter 71000, loss: 0.138957
 >> iter 72000, loss: 0.112186
 >> iter 73000, loss: 0.158407
 >> iter 74000, loss: 0.181587
 >> iter 75000, loss: 0.173369
 >> iter 76000, loss: 0.174875
 >> iter 77000, loss: 0.222195
 >> iter 78000, loss: 0.190544
 >> iter 79000, loss: 0.222249
 >> iter 80000, loss: 0.223721
   Number of active neurons: 7
 >> iter 81000, loss: 0.241795
 >> iter 82000, loss: 0.158383
 >> iter 83000, loss: 0.149689
 >> iter 84000, loss: 0.221580
 >> iter 85000, loss: 0.185788
 >> iter 86000, loss: 0.178868
 >> iter 87000, loss: 0.220891
 >> iter 88000, loss: 0.319366
 >> iter 89000, loss: 0.229884
 >> iter 90000, loss: 0.135958
   Number of active neurons: 7
 >> iter 91000, loss: 0.290562
 >> iter 92000, loss: 0.221558
 >> iter 93000, loss: 0.136161
 >> iter 94000, loss: 0.170100
 >> iter 95000, loss: 0.230253
 >> iter 96000, loss: 0.154137
 >> iter 97000, loss: 0.257566
 >> iter 98000, loss: 0.258955
 >> iter 99000, loss: 0.214407
 >> iter 100000, loss: 0.202996
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.625879
 >> iter 2000, loss: 9.766942
 >> iter 3000, loss: 5.803373
 >> iter 4000, loss: 3.237490
 >> iter 5000, loss: 1.984923
 >> iter 6000, loss: 1.305054
 >> iter 7000, loss: 0.833067
 >> iter 8000, loss: 0.607045
 >> iter 9000, loss: 0.626803
 >> iter 10000, loss: 0.582022
   Number of active neurons: 8
 >> iter 11000, loss: 0.721772
 >> iter 12000, loss: 0.555663
 >> iter 13000, loss: 0.588025
 >> iter 14000, loss: 0.469304
 >> iter 15000, loss: 0.278973
 >> iter 16000, loss: 0.311610
 >> iter 17000, loss: 0.425881
 >> iter 18000, loss: 0.677029
 >> iter 19000, loss: 0.621455
 >> iter 20000, loss: 0.481165
   Number of active neurons: 7
 >> iter 21000, loss: 0.557875
 >> iter 22000, loss: 0.481891
 >> iter 23000, loss: 0.400597
 >> iter 24000, loss: 0.503085
 >> iter 25000, loss: 0.623592
 >> iter 26000, loss: 0.623649
 >> iter 27000, loss: 0.500780
 >> iter 28000, loss: 0.326259
 >> iter 29000, loss: 0.540805
 >> iter 30000, loss: 0.543826
   Number of active neurons: 6
 >> iter 31000, loss: 0.382879
 >> iter 32000, loss: 0.496864
 >> iter 33000, loss: 0.369311
 >> iter 34000, loss: 0.730200
 >> iter 35000, loss: 0.517191
 >> iter 36000, loss: 0.481411
 >> iter 37000, loss: 0.566767
 >> iter 38000, loss: 0.403766
 >> iter 39000, loss: 0.485669
 >> iter 40000, loss: 0.477325
   Number of active neurons: 5
 >> iter 41000, loss: 0.429556
 >> iter 42000, loss: 0.586982
 >> iter 43000, loss: 0.557499
 >> iter 44000, loss: 0.661651
 >> iter 45000, loss: 0.543343
 >> iter 46000, loss: 0.521268
 >> iter 47000, loss: 0.470151
 >> iter 48000, loss: 0.455545
 >> iter 49000, loss: 0.568927
 >> iter 50000, loss: 0.532569
   Number of active neurons: 6
 >> iter 51000, loss: 0.613937
 >> iter 52000, loss: 0.522635
 >> iter 53000, loss: 0.429614
 >> iter 54000, loss: 0.478818
 >> iter 55000, loss: 0.467465
 >> iter 56000, loss: 0.534474
 >> iter 57000, loss: 0.572758
 >> iter 58000, loss: 0.514249
 >> iter 59000, loss: 0.449330
 >> iter 60000, loss: 0.439612
   Number of active neurons: 5
 >> iter 61000, loss: 0.579173
 >> iter 62000, loss: 0.572649
 >> iter 63000, loss: 0.429979
 >> iter 64000, loss: 0.466912
 >> iter 65000, loss: 0.559822
 >> iter 66000, loss: 0.601523
 >> iter 67000, loss: 0.717839
 >> iter 68000, loss: 0.746435
 >> iter 69000, loss: 0.686693
 >> iter 70000, loss: 0.743883
   Number of active neurons: 5
 >> iter 71000, loss: 0.586748
 >> iter 72000, loss: 0.639616
 >> iter 73000, loss: 0.758454
 >> iter 74000, loss: 0.639757
 >> iter 75000, loss: 0.686812
 >> iter 76000, loss: 0.679153
 >> iter 77000, loss: 0.586522
 >> iter 78000, loss: 0.360786
 >> iter 79000, loss: 0.566367
 >> iter 80000, loss: 0.651390
   Number of active neurons: 5
 >> iter 81000, loss: 0.620437
 >> iter 82000, loss: 0.625901
 >> iter 83000, loss: 0.626046
 >> iter 84000, loss: 0.730846
 >> iter 85000, loss: 0.591089
 >> iter 86000, loss: 0.725080
 >> iter 87000, loss: 0.781149
 >> iter 88000, loss: 0.743593
 >> iter 89000, loss: 0.821186
 >> iter 90000, loss: 0.702967
   Number of active neurons: 5
 >> iter 91000, loss: 0.704124
 >> iter 92000, loss: 0.659213
 >> iter 93000, loss: 0.711088
 >> iter 94000, loss: 0.432749
 >> iter 95000, loss: 0.587437
 >> iter 96000, loss: 0.623329
 >> iter 97000, loss: 0.689856
 >> iter 98000, loss: 0.551344
 >> iter 99000, loss: 0.665782
 >> iter 100000, loss: 0.675054
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.516166
 >> iter 2000, loss: 9.848812
 >> iter 3000, loss: 6.674972
 >> iter 4000, loss: 3.259801
 >> iter 5000, loss: 1.536693
 >> iter 6000, loss: 0.717932
 >> iter 7000, loss: 0.500864
 >> iter 8000, loss: 0.298170
 >> iter 9000, loss: 0.253676
 >> iter 10000, loss: 0.215722
   Number of active neurons: 9
 >> iter 11000, loss: 0.300794
 >> iter 12000, loss: 0.198889
 >> iter 13000, loss: 0.273419
 >> iter 14000, loss: 0.198125
 >> iter 15000, loss: 0.193551
 >> iter 16000, loss: 0.268220
 >> iter 17000, loss: 0.282723
 >> iter 18000, loss: 0.184445
 >> iter 19000, loss: 0.244999
 >> iter 20000, loss: 0.264661
   Number of active neurons: 9
 >> iter 21000, loss: 0.301377
 >> iter 22000, loss: 0.229351
 >> iter 23000, loss: 0.236195
 >> iter 24000, loss: 0.415368
 >> iter 25000, loss: 0.372625
 >> iter 26000, loss: 0.244889
 >> iter 27000, loss: 0.261452
 >> iter 28000, loss: 0.360599
 >> iter 29000, loss: 0.245143
 >> iter 30000, loss: 0.312981
   Number of active neurons: 9
 >> iter 31000, loss: 0.294715
 >> iter 32000, loss: 0.285968
 >> iter 33000, loss: 0.293285
 >> iter 34000, loss: 0.335069
 >> iter 35000, loss: 0.463258
 >> iter 36000, loss: 0.391354
 >> iter 37000, loss: 0.230131
 >> iter 38000, loss: 0.281388
 >> iter 39000, loss: 0.215309
 >> iter 40000, loss: 0.226300
   Number of active neurons: 9
 >> iter 41000, loss: 0.181517
 >> iter 42000, loss: 0.199153
 >> iter 43000, loss: 0.222735
 >> iter 44000, loss: 0.240867
 >> iter 45000, loss: 0.275939
 >> iter 46000, loss: 0.262798
 >> iter 47000, loss: 0.216774
 >> iter 48000, loss: 0.274704
 >> iter 49000, loss: 0.270524
 >> iter 50000, loss: 0.282773
   Number of active neurons: 9
 >> iter 51000, loss: 0.231381
 >> iter 52000, loss: 0.305305
 >> iter 53000, loss: 0.200432
 >> iter 54000, loss: 0.240551
 >> iter 55000, loss: 0.341950
 >> iter 56000, loss: 0.209132
 >> iter 57000, loss: 0.216766
 >> iter 58000, loss: 0.265666
 >> iter 59000, loss: 0.283562
 >> iter 60000, loss: 0.287021
   Number of active neurons: 9
 >> iter 61000, loss: 0.304557
 >> iter 62000, loss: 0.316304
 >> iter 63000, loss: 0.242259
 >> iter 64000, loss: 0.209471
 >> iter 65000, loss: 0.268960
 >> iter 66000, loss: 0.222601
 >> iter 67000, loss: 0.301282
 >> iter 68000, loss: 0.222524
 >> iter 69000, loss: 0.217329
 >> iter 70000, loss: 0.125217
   Number of active neurons: 9
 >> iter 71000, loss: 0.277859
 >> iter 72000, loss: 0.185282
 >> iter 73000, loss: 0.199376
 >> iter 74000, loss: 0.233800
 >> iter 75000, loss: 0.273419
 >> iter 76000, loss: 0.239090
 >> iter 77000, loss: 0.244083
 >> iter 78000, loss: 0.288444
 >> iter 79000, loss: 0.296330
 >> iter 80000, loss: 0.235827
   Number of active neurons: 9
 >> iter 81000, loss: 0.496093
 >> iter 82000, loss: 0.321419
 >> iter 83000, loss: 0.308598
 >> iter 84000, loss: 0.251507
 >> iter 85000, loss: 0.239054
 >> iter 86000, loss: 0.243499
 >> iter 87000, loss: 0.186049
 >> iter 88000, loss: 0.309047
 >> iter 89000, loss: 0.363077
 >> iter 90000, loss: 0.283924
   Number of active neurons: 9
 >> iter 91000, loss: 0.265139
 >> iter 92000, loss: 0.182001
 >> iter 93000, loss: 0.237030
 >> iter 94000, loss: 0.325377
 >> iter 95000, loss: 0.206714
 >> iter 96000, loss: 0.210561
 >> iter 97000, loss: 0.227939
 >> iter 98000, loss: 0.239597
 >> iter 99000, loss: 0.227444
 >> iter 100000, loss: 0.171205
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.383295
 >> iter 2000, loss: 10.324182
 >> iter 3000, loss: 6.325882
 >> iter 4000, loss: 3.073167
 >> iter 5000, loss: 1.588386
 >> iter 6000, loss: 0.913894
 >> iter 7000, loss: 0.476879
 >> iter 8000, loss: 0.380311
 >> iter 9000, loss: 0.396500
 >> iter 10000, loss: 0.404867
   Number of active neurons: 10
 >> iter 11000, loss: 0.288794
 >> iter 12000, loss: 0.318246
 >> iter 13000, loss: 0.290901
 >> iter 14000, loss: 0.324973
 >> iter 15000, loss: 0.366670
 >> iter 16000, loss: 0.442402
 >> iter 17000, loss: 0.364751
 >> iter 18000, loss: 0.438911
 >> iter 19000, loss: 0.389629
 >> iter 20000, loss: 0.360028
   Number of active neurons: 9
 >> iter 21000, loss: 0.332375
 >> iter 22000, loss: 0.370900
 >> iter 23000, loss: 0.314267
 >> iter 24000, loss: 0.302646
 >> iter 25000, loss: 0.334737
 >> iter 26000, loss: 0.313569
 >> iter 27000, loss: 0.428983
 >> iter 28000, loss: 0.423460
 >> iter 29000, loss: 0.319456
 >> iter 30000, loss: 0.351822
   Number of active neurons: 7
 >> iter 31000, loss: 0.234869
 >> iter 32000, loss: 0.302412
 >> iter 33000, loss: 0.284069
 >> iter 34000, loss: 0.322714
 >> iter 35000, loss: 0.347519
 >> iter 36000, loss: 0.248436
 >> iter 37000, loss: 0.289165
 >> iter 38000, loss: 0.278572
 >> iter 39000, loss: 0.274419
 >> iter 40000, loss: 0.243502
   Number of active neurons: 7
 >> iter 41000, loss: 0.176359
 >> iter 42000, loss: 0.314097
 >> iter 43000, loss: 0.362147
 >> iter 44000, loss: 0.278793
 >> iter 45000, loss: 0.206320
 >> iter 46000, loss: 0.235877
 >> iter 47000, loss: 0.239283
 >> iter 48000, loss: 0.317132
 >> iter 49000, loss: 0.262487
 >> iter 50000, loss: 0.313956
   Number of active neurons: 7
 >> iter 51000, loss: 0.303306
 >> iter 52000, loss: 0.301686
 >> iter 53000, loss: 0.242852
 >> iter 54000, loss: 0.207923
 >> iter 55000, loss: 0.251599
 >> iter 56000, loss: 0.381338
 >> iter 57000, loss: 0.330913
 >> iter 58000, loss: 0.260953
 >> iter 59000, loss: 0.263721
 >> iter 60000, loss: 0.231491
   Number of active neurons: 7
 >> iter 61000, loss: 0.439785
 >> iter 62000, loss: 0.365631
 >> iter 63000, loss: 0.282099
 >> iter 64000, loss: 0.261938
 >> iter 65000, loss: 0.291790
 >> iter 66000, loss: 0.338217
 >> iter 67000, loss: 0.295989
 >> iter 68000, loss: 0.310623
 >> iter 69000, loss: 0.212807
 >> iter 70000, loss: 0.338851
   Number of active neurons: 7
 >> iter 71000, loss: 0.409561
 >> iter 72000, loss: 0.286267
 >> iter 73000, loss: 0.320005
 >> iter 74000, loss: 0.318385
 >> iter 75000, loss: 0.315379
 >> iter 76000, loss: 0.299567
 >> iter 77000, loss: 0.281145
 >> iter 78000, loss: 0.236654
 >> iter 79000, loss: 0.298480
 >> iter 80000, loss: 0.301113
   Number of active neurons: 7
 >> iter 81000, loss: 0.327866
 >> iter 82000, loss: 0.282009
 >> iter 83000, loss: 0.286609
 >> iter 84000, loss: 0.337840
 >> iter 85000, loss: 0.412284
 >> iter 86000, loss: 0.324965
 >> iter 87000, loss: 0.303693
 >> iter 88000, loss: 0.384147
 >> iter 89000, loss: 0.428705
 >> iter 90000, loss: 0.445278
   Number of active neurons: 7
 >> iter 91000, loss: 0.448178
 >> iter 92000, loss: 0.392092
 >> iter 93000, loss: 0.464901
 >> iter 94000, loss: 0.432518
 >> iter 95000, loss: 0.366454
 >> iter 96000, loss: 0.308830
 >> iter 97000, loss: 0.373127
 >> iter 98000, loss: 0.345744
 >> iter 99000, loss: 0.403923
 >> iter 100000, loss: 0.310454
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.881810
 >> iter 2000, loss: 10.389770
 >> iter 3000, loss: 7.283685
 >> iter 4000, loss: 5.050133
 >> iter 5000, loss: 3.103546
 >> iter 6000, loss: 1.870680
 >> iter 7000, loss: 1.299718
 >> iter 8000, loss: 0.956591
 >> iter 9000, loss: 0.749198
 >> iter 10000, loss: 0.703623
   Number of active neurons: 13
 >> iter 11000, loss: 0.717434
 >> iter 12000, loss: 0.768313
 >> iter 13000, loss: 0.672733
 >> iter 14000, loss: 0.520687
 >> iter 15000, loss: 0.640920
 >> iter 16000, loss: 0.671663
 >> iter 17000, loss: 0.538224
 >> iter 18000, loss: 0.508372
 >> iter 19000, loss: 0.478547
 >> iter 20000, loss: 0.496396
   Number of active neurons: 11
 >> iter 21000, loss: 0.354376
 >> iter 22000, loss: 0.436328
 >> iter 23000, loss: 0.495751
 >> iter 24000, loss: 0.430377
 >> iter 25000, loss: 0.400798
 >> iter 26000, loss: 0.291817
 >> iter 27000, loss: 0.557436
 >> iter 28000, loss: 0.383585
 >> iter 29000, loss: 0.768161
 >> iter 30000, loss: 0.546661
   Number of active neurons: 10
 >> iter 31000, loss: 0.593636
 >> iter 32000, loss: 0.481184
 >> iter 33000, loss: 0.417314
 >> iter 34000, loss: 0.578990
 >> iter 35000, loss: 0.517953
 >> iter 36000, loss: 0.701715
 >> iter 37000, loss: 0.572602
 >> iter 38000, loss: 0.547265
 >> iter 39000, loss: 0.498296
 >> iter 40000, loss: 0.606437
   Number of active neurons: 10
 >> iter 41000, loss: 0.610391
 >> iter 42000, loss: 0.645875
 >> iter 43000, loss: 0.668183
 >> iter 44000, loss: 0.587405
 >> iter 45000, loss: 0.622659
 >> iter 46000, loss: 0.495425
 >> iter 47000, loss: 0.516784
 >> iter 48000, loss: 0.384730
 >> iter 49000, loss: 0.405304
 >> iter 50000, loss: 0.467773
   Number of active neurons: 9
 >> iter 51000, loss: 0.495024
 >> iter 52000, loss: 0.511635
 >> iter 53000, loss: 0.436598
 >> iter 54000, loss: 0.698315
 >> iter 55000, loss: 0.537098
 >> iter 56000, loss: 0.551905
 >> iter 57000, loss: 0.649920
 >> iter 58000, loss: 0.550544
 >> iter 59000, loss: 0.728027
 >> iter 60000, loss: 0.545501
   Number of active neurons: 9
 >> iter 61000, loss: 0.604900
 >> iter 62000, loss: 0.559266
 >> iter 63000, loss: 0.610933
 >> iter 64000, loss: 0.682180
 >> iter 65000, loss: 0.584461
 >> iter 66000, loss: 0.569532
 >> iter 67000, loss: 0.635672
 >> iter 68000, loss: 0.583282
 >> iter 69000, loss: 0.562889
 >> iter 70000, loss: 0.524443
   Number of active neurons: 8
 >> iter 71000, loss: 0.605068
 >> iter 72000, loss: 0.422533
 >> iter 73000, loss: 0.583033
 >> iter 74000, loss: 0.719228
 >> iter 75000, loss: 0.667392
 >> iter 76000, loss: 0.707720
 >> iter 77000, loss: 0.646854
 >> iter 78000, loss: 0.545592
 >> iter 79000, loss: 0.583815
 >> iter 80000, loss: 0.677975
   Number of active neurons: 9
 >> iter 81000, loss: 0.736837
 >> iter 82000, loss: 0.639363
 >> iter 83000, loss: 0.837321
 >> iter 84000, loss: 0.742878
 >> iter 85000, loss: 0.737926
 >> iter 86000, loss: 0.839725
 >> iter 87000, loss: 0.778904
 >> iter 88000, loss: 0.711305
 >> iter 89000, loss: 0.617469
 >> iter 90000, loss: 0.523832
   Number of active neurons: 7
 >> iter 91000, loss: 0.607787
 >> iter 92000, loss: 0.573400
 >> iter 93000, loss: 0.517763
 >> iter 94000, loss: 0.428746
 >> iter 95000, loss: 0.477617
 >> iter 96000, loss: 0.526097
 >> iter 97000, loss: 0.629509
 >> iter 98000, loss: 0.554589
 >> iter 99000, loss: 0.559369
 >> iter 100000, loss: 0.581848
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 14.425704953
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.955352
 >> iter 2000, loss: 9.567650
 >> iter 3000, loss: 5.201319
 >> iter 4000, loss: 2.743242
 >> iter 5000, loss: 1.583311
 >> iter 6000, loss: 1.074977
 >> iter 7000, loss: 0.922992
 >> iter 8000, loss: 0.853366
 >> iter 9000, loss: 0.835650
 >> iter 10000, loss: 0.673004
   Number of active neurons: 7
 >> iter 11000, loss: 0.513889
 >> iter 12000, loss: 0.639741
 >> iter 13000, loss: 0.610998
 >> iter 14000, loss: 0.606481
 >> iter 15000, loss: 0.525864
 >> iter 16000, loss: 0.567715
 >> iter 17000, loss: 0.493281
 >> iter 18000, loss: 0.509839
 >> iter 19000, loss: 0.604155
 >> iter 20000, loss: 0.568159
   Number of active neurons: 8
 >> iter 21000, loss: 0.657382
 >> iter 22000, loss: 0.543809
 >> iter 23000, loss: 0.471068
 >> iter 24000, loss: 0.598214
 >> iter 25000, loss: 0.651678
 >> iter 26000, loss: 0.567706
 >> iter 27000, loss: 0.551863
 >> iter 28000, loss: 0.463166
 >> iter 29000, loss: 0.485713
 >> iter 30000, loss: 0.398635
   Number of active neurons: 6
 >> iter 31000, loss: 0.428215
 >> iter 32000, loss: 0.386400
 >> iter 33000, loss: 0.466668
 >> iter 34000, loss: 0.363973
 >> iter 35000, loss: 0.396905
 >> iter 36000, loss: 0.402619
 >> iter 37000, loss: 0.537327
 >> iter 38000, loss: 0.545613
 >> iter 39000, loss: 0.403531
 >> iter 40000, loss: 0.351363
   Number of active neurons: 6
 >> iter 41000, loss: 0.355954
 >> iter 42000, loss: 0.391711
 >> iter 43000, loss: 0.466778
 >> iter 44000, loss: 0.518378
 >> iter 45000, loss: 0.487114
 >> iter 46000, loss: 0.403595
 >> iter 47000, loss: 0.462257
 >> iter 48000, loss: 0.626926
 >> iter 49000, loss: 0.544950
 >> iter 50000, loss: 0.493475
   Number of active neurons: 6
 >> iter 51000, loss: 0.439346
 >> iter 52000, loss: 0.541995
 >> iter 53000, loss: 0.559543
 >> iter 54000, loss: 0.422644
 >> iter 55000, loss: 0.616270
 >> iter 56000, loss: 0.505998
 >> iter 57000, loss: 0.501922
 >> iter 58000, loss: 0.359748
 >> iter 59000, loss: 0.318239
 >> iter 60000, loss: 0.287982
   Number of active neurons: 6
 >> iter 61000, loss: 0.366701
 >> iter 62000, loss: 0.683688
 >> iter 63000, loss: 0.501127
 >> iter 64000, loss: 0.643207
 >> iter 65000, loss: 0.460846
 >> iter 66000, loss: 0.498755
 >> iter 67000, loss: 0.423407
 >> iter 68000, loss: 0.398094
 >> iter 69000, loss: 0.329981
 >> iter 70000, loss: 0.380488
   Number of active neurons: 6
 >> iter 71000, loss: 0.324621
 >> iter 72000, loss: 0.429829
 >> iter 73000, loss: 0.474077
 >> iter 74000, loss: 0.525713
 >> iter 75000, loss: 0.493986
 >> iter 76000, loss: 0.524136
 >> iter 77000, loss: 0.503078
 >> iter 78000, loss: 0.459676
 >> iter 79000, loss: 0.478360
 >> iter 80000, loss: 0.443143
   Number of active neurons: 6
 >> iter 81000, loss: 0.381199
 >> iter 82000, loss: 0.339669
 >> iter 83000, loss: 0.366514
 >> iter 84000, loss: 0.430201
 >> iter 85000, loss: 0.461661
 >> iter 86000, loss: 0.512088
 >> iter 87000, loss: 0.522601
 >> iter 88000, loss: 0.454383
 >> iter 89000, loss: 0.393595
 >> iter 90000, loss: 0.618854
   Number of active neurons: 6
 >> iter 91000, loss: 0.484091
 >> iter 92000, loss: 0.495747
 >> iter 93000, loss: 0.490312
 >> iter 94000, loss: 0.522359
 >> iter 95000, loss: 0.460194
 >> iter 96000, loss: 0.549812
 >> iter 97000, loss: 0.571769
 >> iter 98000, loss: 0.559831
 >> iter 99000, loss: 0.501902
 >> iter 100000, loss: 0.431183
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.554030
 >> iter 2000, loss: 9.850428
 >> iter 3000, loss: 4.914787
 >> iter 4000, loss: 2.374827
 >> iter 5000, loss: 1.246977
 >> iter 6000, loss: 0.760468
 >> iter 7000, loss: 0.530554
 >> iter 8000, loss: 0.402651
 >> iter 9000, loss: 0.420423
 >> iter 10000, loss: 0.355218
   Number of active neurons: 10
 >> iter 11000, loss: 0.366904
 >> iter 12000, loss: 0.367295
 >> iter 13000, loss: 0.411168
 >> iter 14000, loss: 0.307868
 >> iter 15000, loss: 0.363478
 >> iter 16000, loss: 0.361854
 >> iter 17000, loss: 0.384860
 >> iter 18000, loss: 0.313060
 >> iter 19000, loss: 0.346470
 >> iter 20000, loss: 0.433508
   Number of active neurons: 10
 >> iter 21000, loss: 0.345149
 >> iter 22000, loss: 0.297405
 >> iter 23000, loss: 0.344119
 >> iter 24000, loss: 0.396198
 >> iter 25000, loss: 0.287798
 >> iter 26000, loss: 0.456522
 >> iter 27000, loss: 0.513183
 >> iter 28000, loss: 0.278415
 >> iter 29000, loss: 0.328577
 >> iter 30000, loss: 0.257650
   Number of active neurons: 9
 >> iter 31000, loss: 0.287981
 >> iter 32000, loss: 0.305458
 >> iter 33000, loss: 0.430104
 >> iter 34000, loss: 0.373886
 >> iter 35000, loss: 0.315094
 >> iter 36000, loss: 0.258896
 >> iter 37000, loss: 0.245103
 >> iter 38000, loss: 0.216207
 >> iter 39000, loss: 0.260571
 >> iter 40000, loss: 0.228124
   Number of active neurons: 9
 >> iter 41000, loss: 0.267650
 >> iter 42000, loss: 0.321613
 >> iter 43000, loss: 0.298809
 >> iter 44000, loss: 0.322333
 >> iter 45000, loss: 0.215099
 >> iter 46000, loss: 0.387275
 >> iter 47000, loss: 0.360289
 >> iter 48000, loss: 0.254841
 >> iter 49000, loss: 0.245805
 >> iter 50000, loss: 0.289859
   Number of active neurons: 9
 >> iter 51000, loss: 0.266357
 >> iter 52000, loss: 0.282947
 >> iter 53000, loss: 0.207790
 >> iter 54000, loss: 0.285412
 >> iter 55000, loss: 0.321001
 >> iter 56000, loss: 0.340701
 >> iter 57000, loss: 0.261932
 >> iter 58000, loss: 0.222846
 >> iter 59000, loss: 0.399534
 >> iter 60000, loss: 0.331005
   Number of active neurons: 9
 >> iter 61000, loss: 0.358802
 >> iter 62000, loss: 0.283044
 >> iter 63000, loss: 0.359667
 >> iter 64000, loss: 0.368283
 >> iter 65000, loss: 0.328436
 >> iter 66000, loss: 0.286312
 >> iter 67000, loss: 0.307791
 >> iter 68000, loss: 0.301757
 >> iter 69000, loss: 0.271872
 >> iter 70000, loss: 0.272620
   Number of active neurons: 9
 >> iter 71000, loss: 0.217388
 >> iter 72000, loss: 0.173817
 >> iter 73000, loss: 0.284178
 >> iter 74000, loss: 0.336665
 >> iter 75000, loss: 0.268775
 >> iter 76000, loss: 0.334057
 >> iter 77000, loss: 0.344359
 >> iter 78000, loss: 0.315378
 >> iter 79000, loss: 0.263617
 >> iter 80000, loss: 0.185398
   Number of active neurons: 9
 >> iter 81000, loss: 0.232922
 >> iter 82000, loss: 0.247271
 >> iter 83000, loss: 0.319318
 >> iter 84000, loss: 0.273859
 >> iter 85000, loss: 0.292411
 >> iter 86000, loss: 0.285252
 >> iter 87000, loss: 0.288808
 >> iter 88000, loss: 0.201759
 >> iter 89000, loss: 0.265734
 >> iter 90000, loss: 0.280808
   Number of active neurons: 8
 >> iter 91000, loss: 0.265288
 >> iter 92000, loss: 0.232572
 >> iter 93000, loss: 0.300436
 >> iter 94000, loss: 0.390321
 >> iter 95000, loss: 0.281778
 >> iter 96000, loss: 0.338736
 >> iter 97000, loss: 0.256811
 >> iter 98000, loss: 0.276684
 >> iter 99000, loss: 0.222757
 >> iter 100000, loss: 0.242635
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.527019
 >> iter 2000, loss: 9.482885
 >> iter 3000, loss: 4.637419
 >> iter 4000, loss: 2.519530
 >> iter 5000, loss: 1.954310
 >> iter 6000, loss: 1.494802
 >> iter 7000, loss: 0.955564
 >> iter 8000, loss: 0.772208
 >> iter 9000, loss: 0.659469
 >> iter 10000, loss: 0.477289
   Number of active neurons: 5
 >> iter 11000, loss: 0.662709
 >> iter 12000, loss: 0.589668
 >> iter 13000, loss: 0.382026
 >> iter 14000, loss: 0.450177
 >> iter 15000, loss: 0.665287
 >> iter 16000, loss: 0.609478
 >> iter 17000, loss: 0.596267
 >> iter 18000, loss: 0.595499
 >> iter 19000, loss: 0.680355
 >> iter 20000, loss: 0.506629
   Number of active neurons: 5
 >> iter 21000, loss: 0.413771
 >> iter 22000, loss: 0.544102
 >> iter 23000, loss: 0.603883
 >> iter 24000, loss: 0.587309
 >> iter 25000, loss: 0.523213
 >> iter 26000, loss: 0.585830
 >> iter 27000, loss: 0.668318
 >> iter 28000, loss: 0.612656
 >> iter 29000, loss: 0.616775
 >> iter 30000, loss: 0.704307
   Number of active neurons: 5
 >> iter 31000, loss: 0.615558
 >> iter 32000, loss: 0.586336
 >> iter 33000, loss: 0.694390
 >> iter 34000, loss: 0.480589
 >> iter 35000, loss: 0.403377
 >> iter 36000, loss: 0.336505
 >> iter 37000, loss: 0.434400
 >> iter 38000, loss: 0.407022
 >> iter 39000, loss: 0.435935
 >> iter 40000, loss: 0.429859
   Number of active neurons: 5
 >> iter 41000, loss: 0.478243
 >> iter 42000, loss: 0.425025
 >> iter 43000, loss: 0.611190
 >> iter 44000, loss: 0.716769
 >> iter 45000, loss: 0.630172
 >> iter 46000, loss: 0.609564
 >> iter 47000, loss: 0.552420
 >> iter 48000, loss: 0.588796
 >> iter 49000, loss: 0.660983
 >> iter 50000, loss: 0.541832
   Number of active neurons: 5
 >> iter 51000, loss: 0.554955
 >> iter 52000, loss: 0.448741
 >> iter 53000, loss: 0.586907
 >> iter 54000, loss: 0.534575
 >> iter 55000, loss: 0.545858
 >> iter 56000, loss: 0.624517
 >> iter 57000, loss: 0.459679
 >> iter 58000, loss: 0.491963
 >> iter 59000, loss: 0.538915
 >> iter 60000, loss: 0.565832
   Number of active neurons: 5
 >> iter 61000, loss: 0.488526
 >> iter 62000, loss: 0.447742
 >> iter 63000, loss: 0.459703
 >> iter 64000, loss: 0.488229
 >> iter 65000, loss: 0.461715
 >> iter 66000, loss: 0.555187
 >> iter 67000, loss: 0.785315
 >> iter 68000, loss: 0.565202
 >> iter 69000, loss: 0.525949
 >> iter 70000, loss: 0.460653
   Number of active neurons: 5
 >> iter 71000, loss: 0.477969
 >> iter 72000, loss: 0.446879
 >> iter 73000, loss: 0.499920
 >> iter 74000, loss: 0.438001
 >> iter 75000, loss: 0.685130
 >> iter 76000, loss: 0.584716
 >> iter 77000, loss: 0.617800
 >> iter 78000, loss: 0.652837
 >> iter 79000, loss: 0.544637
 >> iter 80000, loss: 0.530901
   Number of active neurons: 5
 >> iter 81000, loss: 0.630123
 >> iter 82000, loss: 0.595844
 >> iter 83000, loss: 0.603034
 >> iter 84000, loss: 0.578651
 >> iter 85000, loss: 0.653480
 >> iter 86000, loss: 0.608275
 >> iter 87000, loss: 0.593374
 >> iter 88000, loss: 0.607123
 >> iter 89000, loss: 0.663098
 >> iter 90000, loss: 0.616931
   Number of active neurons: 5
 >> iter 91000, loss: 0.674306
 >> iter 92000, loss: 0.578962
 >> iter 93000, loss: 0.569594
 >> iter 94000, loss: 0.613061
 >> iter 95000, loss: 0.568603
 >> iter 96000, loss: 0.565449
 >> iter 97000, loss: 0.595085
 >> iter 98000, loss: 0.492444
 >> iter 99000, loss: 0.428098
 >> iter 100000, loss: 0.469197
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.901268
 >> iter 2000, loss: 10.252865
 >> iter 3000, loss: 5.029032
 >> iter 4000, loss: 2.083071
 >> iter 5000, loss: 0.925354
 >> iter 6000, loss: 0.502188
 >> iter 7000, loss: 0.410066
 >> iter 8000, loss: 0.262597
 >> iter 9000, loss: 0.227728
 >> iter 10000, loss: 0.237851
   Number of active neurons: 9
 >> iter 11000, loss: 0.323064
 >> iter 12000, loss: 0.242837
 >> iter 13000, loss: 0.286257
 >> iter 14000, loss: 0.332087
 >> iter 15000, loss: 0.270910
 >> iter 16000, loss: 0.305713
 >> iter 17000, loss: 0.305882
 >> iter 18000, loss: 0.283374
 >> iter 19000, loss: 0.219865
 >> iter 20000, loss: 0.204884
   Number of active neurons: 8
 >> iter 21000, loss: 0.228595
 >> iter 22000, loss: 0.316771
 >> iter 23000, loss: 0.203148
 >> iter 24000, loss: 0.394542
 >> iter 25000, loss: 0.297571
 >> iter 26000, loss: 0.283604
 >> iter 27000, loss: 0.267153
 >> iter 28000, loss: 0.278461
 >> iter 29000, loss: 0.286822
 >> iter 30000, loss: 0.329342
   Number of active neurons: 8
 >> iter 31000, loss: 0.385116
 >> iter 32000, loss: 0.250957
 >> iter 33000, loss: 0.314622
 >> iter 34000, loss: 0.287927
 >> iter 35000, loss: 0.258433
 >> iter 36000, loss: 0.252479
 >> iter 37000, loss: 0.210349
 >> iter 38000, loss: 0.196874
 >> iter 39000, loss: 0.279839
 >> iter 40000, loss: 0.273941
   Number of active neurons: 8
 >> iter 41000, loss: 0.174357
 >> iter 42000, loss: 0.253005
 >> iter 43000, loss: 0.280754
 >> iter 44000, loss: 0.210253
 >> iter 45000, loss: 0.277602
 >> iter 46000, loss: 0.242672
 >> iter 47000, loss: 0.207201
 >> iter 48000, loss: 0.187923
 >> iter 49000, loss: 0.215129
 >> iter 50000, loss: 0.317219
   Number of active neurons: 8
 >> iter 51000, loss: 0.301678
 >> iter 52000, loss: 0.279860
 >> iter 53000, loss: 0.260299
 >> iter 54000, loss: 0.300776
 >> iter 55000, loss: 0.224688
 >> iter 56000, loss: 0.262119
 >> iter 57000, loss: 0.194751
 >> iter 58000, loss: 0.233459
 >> iter 59000, loss: 0.225219
 >> iter 60000, loss: 0.179128
   Number of active neurons: 8
 >> iter 61000, loss: 0.236107
 >> iter 62000, loss: 0.180465
 >> iter 63000, loss: 0.241125
 >> iter 64000, loss: 0.181975
 >> iter 65000, loss: 0.266590
 >> iter 66000, loss: 0.240221
 >> iter 67000, loss: 0.224211
 >> iter 68000, loss: 0.156472
 >> iter 69000, loss: 0.213478
 >> iter 70000, loss: 0.216555
   Number of active neurons: 8
 >> iter 71000, loss: 0.239752
 >> iter 72000, loss: 0.336224
 >> iter 73000, loss: 0.314503
 >> iter 74000, loss: 0.278424
 >> iter 75000, loss: 0.260473
 >> iter 76000, loss: 0.292494
 >> iter 77000, loss: 0.317103
 >> iter 78000, loss: 0.251731
 >> iter 79000, loss: 0.220366
 >> iter 80000, loss: 0.202649
   Number of active neurons: 8
 >> iter 81000, loss: 0.301896
 >> iter 82000, loss: 0.302722
 >> iter 83000, loss: 0.200475
 >> iter 84000, loss: 0.174721
 >> iter 85000, loss: 0.171093
 >> iter 86000, loss: 0.196942
 >> iter 87000, loss: 0.188973
 >> iter 88000, loss: 0.264446
 >> iter 89000, loss: 0.257334
 >> iter 90000, loss: 0.306544
   Number of active neurons: 8
 >> iter 91000, loss: 0.230277
 >> iter 92000, loss: 0.190266
 >> iter 93000, loss: 0.278294
 >> iter 94000, loss: 0.298860
 >> iter 95000, loss: 0.287882
 >> iter 96000, loss: 0.340773
 >> iter 97000, loss: 0.282644
 >> iter 98000, loss: 0.261915
 >> iter 99000, loss: 0.323559
 >> iter 100000, loss: 0.226817
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.843249
 >> iter 2000, loss: 9.864632
 >> iter 3000, loss: 6.752208
 >> iter 4000, loss: 4.141240
 >> iter 5000, loss: 2.266782
 >> iter 6000, loss: 1.375433
 >> iter 7000, loss: 0.915768
 >> iter 8000, loss: 0.653366
 >> iter 9000, loss: 0.593639
 >> iter 10000, loss: 0.405579
   Number of active neurons: 7
 >> iter 11000, loss: 0.572710
 >> iter 12000, loss: 0.439439
 >> iter 13000, loss: 0.369877
 >> iter 14000, loss: 0.313902
 >> iter 15000, loss: 0.467030
 >> iter 16000, loss: 0.438965
 >> iter 17000, loss: 0.443066
 >> iter 18000, loss: 0.561978
 >> iter 19000, loss: 0.495018
 >> iter 20000, loss: 0.396527
   Number of active neurons: 7
 >> iter 21000, loss: 0.256479
 >> iter 22000, loss: 0.213816
 >> iter 23000, loss: 0.261461
 >> iter 24000, loss: 0.285183
 >> iter 25000, loss: 0.203925
 >> iter 26000, loss: 0.264906
 >> iter 27000, loss: 0.224595
 >> iter 28000, loss: 0.382781
 >> iter 29000, loss: 0.315350
 >> iter 30000, loss: 0.279023
   Number of active neurons: 7
 >> iter 31000, loss: 0.259529
 >> iter 32000, loss: 0.295336
 >> iter 33000, loss: 0.255118
 >> iter 34000, loss: 0.221237
 >> iter 35000, loss: 0.184044
 >> iter 36000, loss: 0.281355
 >> iter 37000, loss: 0.285597
 >> iter 38000, loss: 0.280549
 >> iter 39000, loss: 0.257112
 >> iter 40000, loss: 0.324120
   Number of active neurons: 7
 >> iter 41000, loss: 0.311184
 >> iter 42000, loss: 0.236387
 >> iter 43000, loss: 0.276361
 >> iter 44000, loss: 0.278779
 >> iter 45000, loss: 0.256314
 >> iter 46000, loss: 0.171051
 >> iter 47000, loss: 0.311460
 >> iter 48000, loss: 0.207720
 >> iter 49000, loss: 0.218572
 >> iter 50000, loss: 0.235864
   Number of active neurons: 7
 >> iter 51000, loss: 0.178960
 >> iter 52000, loss: 0.274045
 >> iter 53000, loss: 0.281065
 >> iter 54000, loss: 0.321275
 >> iter 55000, loss: 0.360029
 >> iter 56000, loss: 0.301624
 >> iter 57000, loss: 0.313413
 >> iter 58000, loss: 0.311334
 >> iter 59000, loss: 0.280340
 >> iter 60000, loss: 0.272776
   Number of active neurons: 7
 >> iter 61000, loss: 0.296578
 >> iter 62000, loss: 0.289608
 >> iter 63000, loss: 0.241898
 >> iter 64000, loss: 0.330390
 >> iter 65000, loss: 0.253189
 >> iter 66000, loss: 0.337054
 >> iter 67000, loss: 0.238379
 >> iter 68000, loss: 0.208659
 >> iter 69000, loss: 0.246434
 >> iter 70000, loss: 0.290221
   Number of active neurons: 7
 >> iter 71000, loss: 0.309148
 >> iter 72000, loss: 0.251461
 >> iter 73000, loss: 0.277165
 >> iter 74000, loss: 0.249222
 >> iter 75000, loss: 0.283106
 >> iter 76000, loss: 0.217995
 >> iter 77000, loss: 0.262682
 >> iter 78000, loss: 0.299011
 >> iter 79000, loss: 0.281316
 >> iter 80000, loss: 0.232098
   Number of active neurons: 7
 >> iter 81000, loss: 0.242252
 >> iter 82000, loss: 0.263439
 >> iter 83000, loss: 0.267878
 >> iter 84000, loss: 0.289585
 >> iter 85000, loss: 0.324886
 >> iter 86000, loss: 0.342791
 >> iter 87000, loss: 0.295314
 >> iter 88000, loss: 0.259403
 >> iter 89000, loss: 0.212550
 >> iter 90000, loss: 0.179674
   Number of active neurons: 7
 >> iter 91000, loss: 0.202371
 >> iter 92000, loss: 0.228181
 >> iter 93000, loss: 0.239393
 >> iter 94000, loss: 0.226858
 >> iter 95000, loss: 0.337029
 >> iter 96000, loss: 0.341668
 >> iter 97000, loss: 0.415756
 >> iter 98000, loss: 0.310856
 >> iter 99000, loss: 0.256284
 >> iter 100000, loss: 0.261662
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.652004
 >> iter 2000, loss: 10.049710
 >> iter 3000, loss: 5.071831
 >> iter 4000, loss: 2.304720
 >> iter 5000, loss: 1.059126
 >> iter 6000, loss: 0.658496
 >> iter 7000, loss: 0.449601
 >> iter 8000, loss: 0.316805
 >> iter 9000, loss: 0.412783
 >> iter 10000, loss: 0.400929
   Number of active neurons: 10
 >> iter 11000, loss: 0.303789
 >> iter 12000, loss: 0.445888
 >> iter 13000, loss: 0.359599
 >> iter 14000, loss: 0.407840
 >> iter 15000, loss: 0.405893
 >> iter 16000, loss: 0.384614
 >> iter 17000, loss: 0.237997
 >> iter 18000, loss: 0.289504
 >> iter 19000, loss: 0.344153
 >> iter 20000, loss: 0.298155
   Number of active neurons: 9
 >> iter 21000, loss: 0.318793
 >> iter 22000, loss: 0.339920
 >> iter 23000, loss: 0.385818
 >> iter 24000, loss: 0.262101
 >> iter 25000, loss: 0.268831
 >> iter 26000, loss: 0.355630
 >> iter 27000, loss: 0.368018
 >> iter 28000, loss: 0.238760
 >> iter 29000, loss: 0.307846
 >> iter 30000, loss: 0.349513
   Number of active neurons: 9
 >> iter 31000, loss: 0.230944
 >> iter 32000, loss: 0.194058
 >> iter 33000, loss: 0.234168
 >> iter 34000, loss: 0.261541
 >> iter 35000, loss: 0.238621
 >> iter 36000, loss: 0.378682
 >> iter 37000, loss: 0.284734
 >> iter 38000, loss: 0.270722
 >> iter 39000, loss: 0.327913
 >> iter 40000, loss: 0.322095
   Number of active neurons: 9
 >> iter 41000, loss: 0.362104
 >> iter 42000, loss: 0.382165
 >> iter 43000, loss: 0.335351
 >> iter 44000, loss: 0.287394
 >> iter 45000, loss: 0.272242
 >> iter 46000, loss: 0.247799
 >> iter 47000, loss: 0.238703
 >> iter 48000, loss: 0.308120
 >> iter 49000, loss: 0.371067
 >> iter 50000, loss: 0.281732
   Number of active neurons: 9
 >> iter 51000, loss: 0.211335
 >> iter 52000, loss: 0.284884
 >> iter 53000, loss: 0.324341
 >> iter 54000, loss: 0.471539
 >> iter 55000, loss: 0.287765
 >> iter 56000, loss: 0.310314
 >> iter 57000, loss: 0.330683
 >> iter 58000, loss: 0.254713
 >> iter 59000, loss: 0.375751
 >> iter 60000, loss: 0.437526
   Number of active neurons: 9
 >> iter 61000, loss: 0.331890
 >> iter 62000, loss: 0.363116
 >> iter 63000, loss: 0.289899
 >> iter 64000, loss: 0.306181
 >> iter 65000, loss: 0.307318
 >> iter 66000, loss: 0.257459
 >> iter 67000, loss: 0.273274
 >> iter 68000, loss: 0.243871
 >> iter 69000, loss: 0.412185
 >> iter 70000, loss: 0.337350
   Number of active neurons: 9
 >> iter 71000, loss: 0.284921
 >> iter 72000, loss: 0.248074
 >> iter 73000, loss: 0.306451
 >> iter 74000, loss: 0.282009
 >> iter 75000, loss: 0.260490
 >> iter 76000, loss: 0.279971
 >> iter 77000, loss: 0.338959
 >> iter 78000, loss: 0.343006
 >> iter 79000, loss: 0.381320
 >> iter 80000, loss: 0.275326
   Number of active neurons: 9
 >> iter 81000, loss: 0.316972
 >> iter 82000, loss: 0.314394
 >> iter 83000, loss: 0.272344
 >> iter 84000, loss: 0.288025
 >> iter 85000, loss: 0.429833
 >> iter 86000, loss: 0.340195
 >> iter 87000, loss: 0.217078
 >> iter 88000, loss: 0.325465
 >> iter 89000, loss: 0.331870
 >> iter 90000, loss: 0.292859
   Number of active neurons: 8
 >> iter 91000, loss: 0.232998
 >> iter 92000, loss: 0.276514
 >> iter 93000, loss: 0.219551
 >> iter 94000, loss: 0.261843
 >> iter 95000, loss: 0.258091
 >> iter 96000, loss: 0.314177
 >> iter 97000, loss: 0.205978
 >> iter 98000, loss: 0.272597
 >> iter 99000, loss: 0.393440
 >> iter 100000, loss: 0.350858
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.725865
 >> iter 2000, loss: 8.790982
 >> iter 3000, loss: 4.193123
 >> iter 4000, loss: 2.133476
 >> iter 5000, loss: 1.207545
 >> iter 6000, loss: 0.685233
 >> iter 7000, loss: 0.520963
 >> iter 8000, loss: 0.396908
 >> iter 9000, loss: 0.487098
 >> iter 10000, loss: 0.374890
   Number of active neurons: 7
 >> iter 11000, loss: 0.296719
 >> iter 12000, loss: 0.293510
 >> iter 13000, loss: 0.252148
 >> iter 14000, loss: 0.281267
 >> iter 15000, loss: 0.312407
 >> iter 16000, loss: 0.272517
 >> iter 17000, loss: 0.366128
 >> iter 18000, loss: 0.254027
 >> iter 19000, loss: 0.371283
 >> iter 20000, loss: 0.423317
   Number of active neurons: 7
 >> iter 21000, loss: 0.317376
 >> iter 22000, loss: 0.261331
 >> iter 23000, loss: 0.211940
 >> iter 24000, loss: 0.273594
 >> iter 25000, loss: 0.282062
 >> iter 26000, loss: 0.288125
 >> iter 27000, loss: 0.289162
 >> iter 28000, loss: 0.243776
 >> iter 29000, loss: 0.282094
 >> iter 30000, loss: 0.382131
   Number of active neurons: 7
 >> iter 31000, loss: 0.341784
 >> iter 32000, loss: 0.283616
 >> iter 33000, loss: 0.213430
 >> iter 34000, loss: 0.179097
 >> iter 35000, loss: 0.278058
 >> iter 36000, loss: 0.256632
 >> iter 37000, loss: 0.252637
 >> iter 38000, loss: 0.216287
 >> iter 39000, loss: 0.196221
 >> iter 40000, loss: 0.226844
   Number of active neurons: 6
 >> iter 41000, loss: 0.183987
 >> iter 42000, loss: 0.257045
 >> iter 43000, loss: 0.343204
 >> iter 44000, loss: 0.255004
 >> iter 45000, loss: 0.358090
 >> iter 46000, loss: 0.340842
 >> iter 47000, loss: 0.318879
 >> iter 48000, loss: 0.298192
 >> iter 49000, loss: 0.237401
 >> iter 50000, loss: 0.242165
   Number of active neurons: 6
 >> iter 51000, loss: 0.229171
 >> iter 52000, loss: 0.167275
 >> iter 53000, loss: 0.194822
 >> iter 54000, loss: 0.270973
 >> iter 55000, loss: 0.207869
 >> iter 56000, loss: 0.212250
 >> iter 57000, loss: 0.285261
 >> iter 58000, loss: 0.253080
 >> iter 59000, loss: 0.294255
 >> iter 60000, loss: 0.243440
   Number of active neurons: 6
 >> iter 61000, loss: 0.225384
 >> iter 62000, loss: 0.242957
 >> iter 63000, loss: 0.203071
 >> iter 64000, loss: 0.279018
 >> iter 65000, loss: 0.269129
 >> iter 66000, loss: 0.255885
 >> iter 67000, loss: 0.317489
 >> iter 68000, loss: 0.310671
 >> iter 69000, loss: 0.243665
 >> iter 70000, loss: 0.205002
   Number of active neurons: 6
 >> iter 71000, loss: 0.191350
 >> iter 72000, loss: 0.183798
 >> iter 73000, loss: 0.176436
 >> iter 74000, loss: 0.277141
 >> iter 75000, loss: 0.254790
 >> iter 76000, loss: 0.339396
 >> iter 77000, loss: 0.399904
 >> iter 78000, loss: 0.342013
 >> iter 79000, loss: 0.287212
 >> iter 80000, loss: 0.267108
   Number of active neurons: 6
 >> iter 81000, loss: 0.259404
 >> iter 82000, loss: 0.225357
 >> iter 83000, loss: 0.160863
 >> iter 84000, loss: 0.216888
 >> iter 85000, loss: 0.179230
 >> iter 86000, loss: 0.201956
 >> iter 87000, loss: 0.197681
 >> iter 88000, loss: 0.237072
 >> iter 89000, loss: 0.319564
 >> iter 90000, loss: 0.237729
   Number of active neurons: 6
 >> iter 91000, loss: 0.278714
 >> iter 92000, loss: 0.268789
 >> iter 93000, loss: 0.231054
 >> iter 94000, loss: 0.230349
 >> iter 95000, loss: 0.247305
 >> iter 96000, loss: 0.229663
 >> iter 97000, loss: 0.244990
 >> iter 98000, loss: 0.318639
 >> iter 99000, loss: 0.315549
 >> iter 100000, loss: 0.292289
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.779753
 >> iter 2000, loss: 9.721369
 >> iter 3000, loss: 5.757424
 >> iter 4000, loss: 3.150776
 >> iter 5000, loss: 1.866489
 >> iter 6000, loss: 1.099005
 >> iter 7000, loss: 0.838640
 >> iter 8000, loss: 0.586427
 >> iter 9000, loss: 0.496693
 >> iter 10000, loss: 0.508182
   Number of active neurons: 8
 >> iter 11000, loss: 0.557993
 >> iter 12000, loss: 0.476728
 >> iter 13000, loss: 0.490069
 >> iter 14000, loss: 0.499783
 >> iter 15000, loss: 0.569042
 >> iter 16000, loss: 0.448638
 >> iter 17000, loss: 0.433758
 >> iter 18000, loss: 0.291937
 >> iter 19000, loss: 0.329837
 >> iter 20000, loss: 0.464339
   Number of active neurons: 8
 >> iter 21000, loss: 0.332622
 >> iter 22000, loss: 0.392117
 >> iter 23000, loss: 0.318934
 >> iter 24000, loss: 0.307104
 >> iter 25000, loss: 0.445056
 >> iter 26000, loss: 0.343428
 >> iter 27000, loss: 0.229864
 >> iter 28000, loss: 0.225034
 >> iter 29000, loss: 0.368909
 >> iter 30000, loss: 0.312239
   Number of active neurons: 8
 >> iter 31000, loss: 0.347673
 >> iter 32000, loss: 0.285537
 >> iter 33000, loss: 0.358277
 >> iter 34000, loss: 0.253682
 >> iter 35000, loss: 0.264916
 >> iter 36000, loss: 0.305022
 >> iter 37000, loss: 0.253693
 >> iter 38000, loss: 0.286664
 >> iter 39000, loss: 0.468611
 >> iter 40000, loss: 0.461006
   Number of active neurons: 8
 >> iter 41000, loss: 0.363511
 >> iter 42000, loss: 0.417722
 >> iter 43000, loss: 0.429496
 >> iter 44000, loss: 0.362879
 >> iter 45000, loss: 0.349073
 >> iter 46000, loss: 0.329861
 >> iter 47000, loss: 0.392728
 >> iter 48000, loss: 0.423627
 >> iter 49000, loss: 0.579491
 >> iter 50000, loss: 0.547229
   Number of active neurons: 8
 >> iter 51000, loss: 0.765621
 >> iter 52000, loss: 0.426798
 >> iter 53000, loss: 0.473787
 >> iter 54000, loss: 0.438349
 >> iter 55000, loss: 0.349409
 >> iter 56000, loss: 0.409256
 >> iter 57000, loss: 0.514795
 >> iter 58000, loss: 0.392268
 >> iter 59000, loss: 0.378974
 >> iter 60000, loss: 0.298349
   Number of active neurons: 9
 >> iter 61000, loss: 0.492001
 >> iter 62000, loss: 0.511044
 >> iter 63000, loss: 0.476449
 >> iter 64000, loss: 0.384238
 >> iter 65000, loss: 0.343731
 >> iter 66000, loss: 0.377763
 >> iter 67000, loss: 0.403829
 >> iter 68000, loss: 0.376051
 >> iter 69000, loss: 0.340104
 >> iter 70000, loss: 0.381671
   Number of active neurons: 8
 >> iter 71000, loss: 0.335839
 >> iter 72000, loss: 0.478136
 >> iter 73000, loss: 0.496164
 >> iter 74000, loss: 0.536895
 >> iter 75000, loss: 0.410299
 >> iter 76000, loss: 0.402241
 >> iter 77000, loss: 0.553449
 >> iter 78000, loss: 0.416126
 >> iter 79000, loss: 0.383572
 >> iter 80000, loss: 0.447161
   Number of active neurons: 8
 >> iter 81000, loss: 0.546157
 >> iter 82000, loss: 0.350817
 >> iter 83000, loss: 0.315690
 >> iter 84000, loss: 0.318390
 >> iter 85000, loss: 0.224648
 >> iter 86000, loss: 0.365038
 >> iter 87000, loss: 0.464537
 >> iter 88000, loss: 0.492165
 >> iter 89000, loss: 0.407599
 >> iter 90000, loss: 0.332647
   Number of active neurons: 8
 >> iter 91000, loss: 0.277994
 >> iter 92000, loss: 0.266090
 >> iter 93000, loss: 0.445041
 >> iter 94000, loss: 0.387828
 >> iter 95000, loss: 0.376785
 >> iter 96000, loss: 0.342581
 >> iter 97000, loss: 0.314589
 >> iter 98000, loss: 0.373537
 >> iter 99000, loss: 0.389315
 >> iter 100000, loss: 0.371315
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.527095
 >> iter 2000, loss: 9.130712
 >> iter 3000, loss: 4.731956
 >> iter 4000, loss: 2.833813
 >> iter 5000, loss: 1.777498
 >> iter 6000, loss: 1.545444
 >> iter 7000, loss: 1.216316
 >> iter 8000, loss: 0.991064
 >> iter 9000, loss: 0.860486
 >> iter 10000, loss: 0.901510
   Number of active neurons: 5
 >> iter 11000, loss: 0.704010
 >> iter 12000, loss: 0.553242
 >> iter 13000, loss: 0.651424
 >> iter 14000, loss: 0.685276
 >> iter 15000, loss: 0.590176
 >> iter 16000, loss: 0.829283
 >> iter 17000, loss: 0.663292
 >> iter 18000, loss: 0.577465
 >> iter 19000, loss: 0.670921
 >> iter 20000, loss: 0.702210
   Number of active neurons: 5
 >> iter 21000, loss: 0.580595
 >> iter 22000, loss: 0.667977
 >> iter 23000, loss: 0.631569
 >> iter 24000, loss: 0.566531
 >> iter 25000, loss: 0.541063
 >> iter 26000, loss: 0.635166
 >> iter 27000, loss: 0.746253
 >> iter 28000, loss: 0.669006
 >> iter 29000, loss: 0.528202
 >> iter 30000, loss: 0.596476
   Number of active neurons: 5
 >> iter 31000, loss: 0.638497
 >> iter 32000, loss: 0.546081
 >> iter 33000, loss: 0.539673
 >> iter 34000, loss: 0.645170
 >> iter 35000, loss: 0.514478
 >> iter 36000, loss: 0.455245
 >> iter 37000, loss: 0.477798
 >> iter 38000, loss: 0.574967
 >> iter 39000, loss: 0.561117
 >> iter 40000, loss: 0.604484
   Number of active neurons: 5
 >> iter 41000, loss: 0.611522
 >> iter 42000, loss: 0.553100
 >> iter 43000, loss: 0.551385
 >> iter 44000, loss: 0.622619
 >> iter 45000, loss: 0.575863
 >> iter 46000, loss: 0.577956
 >> iter 47000, loss: 0.501255
 >> iter 48000, loss: 0.390265
 >> iter 49000, loss: 0.390880
 >> iter 50000, loss: 0.470653
   Number of active neurons: 5
 >> iter 51000, loss: 0.494298
 >> iter 52000, loss: 0.600271
 >> iter 53000, loss: 0.660745
 >> iter 54000, loss: 0.614700
 >> iter 55000, loss: 0.554571
 >> iter 56000, loss: 0.438210
 >> iter 57000, loss: 0.458974
 >> iter 58000, loss: 0.590736
 >> iter 59000, loss: 0.476233
 >> iter 60000, loss: 0.532527
   Number of active neurons: 5
 >> iter 61000, loss: 0.499424
 >> iter 62000, loss: 0.408588
 >> iter 63000, loss: 0.379529
 >> iter 64000, loss: 0.568591
 >> iter 65000, loss: 0.499789
 >> iter 66000, loss: 0.457159
 >> iter 67000, loss: 0.625263
 >> iter 68000, loss: 0.592398
 >> iter 69000, loss: 0.626026
 >> iter 70000, loss: 0.570407
   Number of active neurons: 4
 >> iter 71000, loss: 0.707971
 >> iter 72000, loss: 0.690110
 >> iter 73000, loss: 0.665045
 >> iter 74000, loss: 0.579473
 >> iter 75000, loss: 0.551401
 >> iter 76000, loss: 0.630296
 >> iter 77000, loss: 0.506321
 >> iter 78000, loss: 0.545659
 >> iter 79000, loss: 0.577716
 >> iter 80000, loss: 0.508916
   Number of active neurons: 4
 >> iter 81000, loss: 0.563643
 >> iter 82000, loss: 0.621661
 >> iter 83000, loss: 0.563803
 >> iter 84000, loss: 0.500063
 >> iter 85000, loss: 0.616930
 >> iter 86000, loss: 0.657526
 >> iter 87000, loss: 0.758656
 >> iter 88000, loss: 0.602969
 >> iter 89000, loss: 0.598422
 >> iter 90000, loss: 0.574579
   Number of active neurons: 4
 >> iter 91000, loss: 0.551789
 >> iter 92000, loss: 0.732372
 >> iter 93000, loss: 0.444674
 >> iter 94000, loss: 0.567707
 >> iter 95000, loss: 0.513545
 >> iter 96000, loss: 0.574623
 >> iter 97000, loss: 0.579657
 >> iter 98000, loss: 0.602343
 >> iter 99000, loss: 0.632649
 >> iter 100000, loss: 0.859800
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.648882
 >> iter 2000, loss: 10.431732
 >> iter 3000, loss: 5.783744
 >> iter 4000, loss: 3.306634
 >> iter 5000, loss: 2.025232
 >> iter 6000, loss: 1.493163
 >> iter 7000, loss: 1.121343
 >> iter 8000, loss: 0.621711
 >> iter 9000, loss: 0.673240
 >> iter 10000, loss: 0.600270
   Number of active neurons: 9
 >> iter 11000, loss: 0.560489
 >> iter 12000, loss: 0.592792
 >> iter 13000, loss: 0.614454
 >> iter 14000, loss: 0.539920
 >> iter 15000, loss: 0.482503
 >> iter 16000, loss: 0.447268
 >> iter 17000, loss: 0.361208
 >> iter 18000, loss: 0.447371
 >> iter 19000, loss: 0.505827
 >> iter 20000, loss: 0.475601
   Number of active neurons: 8
 >> iter 21000, loss: 0.454654
 >> iter 22000, loss: 0.365440
 >> iter 23000, loss: 0.475600
 >> iter 24000, loss: 0.474909
 >> iter 25000, loss: 0.389961
 >> iter 26000, loss: 0.319884
 >> iter 27000, loss: 0.389335
 >> iter 28000, loss: 0.388004
 >> iter 29000, loss: 0.365919
 >> iter 30000, loss: 0.485617
   Number of active neurons: 7
 >> iter 31000, loss: 0.466936
 >> iter 32000, loss: 0.447501
 >> iter 33000, loss: 0.369783
 >> iter 34000, loss: 0.380338
 >> iter 35000, loss: 0.374341
 >> iter 36000, loss: 0.398481
 >> iter 37000, loss: 0.355795
 >> iter 38000, loss: 0.363010
 >> iter 39000, loss: 0.444065
 >> iter 40000, loss: 0.408650
   Number of active neurons: 7
 >> iter 41000, loss: 0.299992
 >> iter 42000, loss: 0.275067
 >> iter 43000, loss: 0.468651
 >> iter 44000, loss: 0.419635
 >> iter 45000, loss: 0.274803
 >> iter 46000, loss: 0.318880
 >> iter 47000, loss: 0.310529
 >> iter 48000, loss: 0.310130
 >> iter 49000, loss: 0.272753
 >> iter 50000, loss: 0.362566
   Number of active neurons: 5
 >> iter 51000, loss: 0.339374
 >> iter 52000, loss: 0.317891
 >> iter 53000, loss: 0.411397
 >> iter 54000, loss: 0.343098
 >> iter 55000, loss: 0.360254
 >> iter 56000, loss: 0.331389
 >> iter 57000, loss: 0.385810
 >> iter 58000, loss: 0.254937
 >> iter 59000, loss: 0.284702
 >> iter 60000, loss: 0.189329
   Number of active neurons: 5
 >> iter 61000, loss: 0.440681
 >> iter 62000, loss: 0.346213
 >> iter 63000, loss: 0.457839
 >> iter 64000, loss: 0.294895
 >> iter 65000, loss: 0.314925
 >> iter 66000, loss: 0.261911
 >> iter 67000, loss: 0.388484
 >> iter 68000, loss: 0.347186
 >> iter 69000, loss: 0.387084
 >> iter 70000, loss: 0.309792
   Number of active neurons: 5
 >> iter 71000, loss: 0.306944
 >> iter 72000, loss: 0.346898
 >> iter 73000, loss: 0.442731
 >> iter 74000, loss: 0.375218
 >> iter 75000, loss: 0.435774
 >> iter 76000, loss: 0.455566
 >> iter 77000, loss: 0.373662
 >> iter 78000, loss: 0.317563
 >> iter 79000, loss: 0.301828
 >> iter 80000, loss: 0.379438
   Number of active neurons: 4
 >> iter 81000, loss: 0.247678
 >> iter 82000, loss: 0.339862
 >> iter 83000, loss: 0.459150
 >> iter 84000, loss: 0.283524
 >> iter 85000, loss: 0.266006
 >> iter 86000, loss: 0.248798
 >> iter 87000, loss: 0.242130
 >> iter 88000, loss: 0.346699
 >> iter 89000, loss: 0.363797
 >> iter 90000, loss: 0.246391
   Number of active neurons: 5
 >> iter 91000, loss: 0.325612
 >> iter 92000, loss: 0.312015
 >> iter 93000, loss: 0.328507
 >> iter 94000, loss: 0.305704
 >> iter 95000, loss: 0.392086
 >> iter 96000, loss: 0.372914
 >> iter 97000, loss: 0.324304
 >> iter 98000, loss: 0.348698
 >> iter 99000, loss: 0.353531
 >> iter 100000, loss: 0.304560
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

