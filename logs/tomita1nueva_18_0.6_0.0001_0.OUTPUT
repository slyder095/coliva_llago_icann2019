 > Problema: tomita1nueva
 > Args:
   - Hidden size: 18
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.993572
 >> iter 2000, loss: 4.099085
 >> iter 3000, loss: 1.556558
 >> iter 4000, loss: 0.599599
 >> iter 5000, loss: 0.244590
 >> iter 6000, loss: 0.112850
 >> iter 7000, loss: 0.069077
 >> iter 8000, loss: 0.045807
 >> iter 9000, loss: 0.036293
 >> iter 10000, loss: 0.036355
   Number of active neurons: 5
 >> iter 11000, loss: 0.033533
 >> iter 12000, loss: 0.031582
 >> iter 13000, loss: 0.032607
 >> iter 14000, loss: 0.029242
 >> iter 15000, loss: 0.030827
 >> iter 16000, loss: 0.029541
 >> iter 17000, loss: 0.028478
 >> iter 18000, loss: 0.027889
 >> iter 19000, loss: 0.035743
 >> iter 20000, loss: 0.031027
   Number of active neurons: 3
 >> iter 21000, loss: 0.027543
 >> iter 22000, loss: 0.025048
 >> iter 23000, loss: 0.024543
 >> iter 24000, loss: 0.026810
 >> iter 25000, loss: 0.061750
 >> iter 26000, loss: 0.040587
 >> iter 27000, loss: 0.057184
 >> iter 28000, loss: 0.034516
 >> iter 29000, loss: 0.026349
 >> iter 30000, loss: 0.024095
   Number of active neurons: 2
 >> iter 31000, loss: 0.029562
 >> iter 32000, loss: 0.023574
 >> iter 33000, loss: 0.021135
 >> iter 34000, loss: 0.020910
 >> iter 35000, loss: 0.020853
 >> iter 36000, loss: 0.020231
 >> iter 37000, loss: 0.021363
 >> iter 38000, loss: 0.023111
 >> iter 39000, loss: 0.052148
 >> iter 40000, loss: 0.031357
   Number of active neurons: 2
 >> iter 41000, loss: 0.024648
 >> iter 42000, loss: 0.020846
 >> iter 43000, loss: 0.021290
 >> iter 44000, loss: 0.020674
 >> iter 45000, loss: 0.024006
 >> iter 46000, loss: 0.027942
 >> iter 47000, loss: 0.028759
 >> iter 48000, loss: 0.024858
 >> iter 49000, loss: 0.021382
 >> iter 50000, loss: 0.021721
   Number of active neurons: 2
 >> iter 51000, loss: 0.023261
 >> iter 52000, loss: 0.040851
 >> iter 53000, loss: 0.084214
 >> iter 54000, loss: 0.048664
 >> iter 55000, loss: 0.030202
 >> iter 56000, loss: 0.023412
 >> iter 57000, loss: 0.026504
 >> iter 58000, loss: 0.022070
 >> iter 59000, loss: 0.029502
 >> iter 60000, loss: 0.055489
   Number of active neurons: 2
 >> iter 61000, loss: 0.044851
 >> iter 62000, loss: 0.038692
 >> iter 63000, loss: 0.048403
 >> iter 64000, loss: 0.033257
 >> iter 65000, loss: 0.043667
 >> iter 66000, loss: 0.029297
 >> iter 67000, loss: 0.025565
 >> iter 68000, loss: 0.021852
 >> iter 69000, loss: 0.020924
 >> iter 70000, loss: 0.027571
   Number of active neurons: 2
 >> iter 71000, loss: 0.024609
 >> iter 72000, loss: 0.023994
 >> iter 73000, loss: 0.024828
 >> iter 74000, loss: 0.023158
 >> iter 75000, loss: 0.021079
 >> iter 76000, loss: 0.020725
 >> iter 77000, loss: 0.032087
 >> iter 78000, loss: 0.025976
 >> iter 79000, loss: 0.022556
 >> iter 80000, loss: 0.021185
   Number of active neurons: 1
 >> iter 81000, loss: 0.025589
 >> iter 82000, loss: 0.027343
 >> iter 83000, loss: 0.028485
 >> iter 84000, loss: 0.021828
 >> iter 85000, loss: 0.021104
 >> iter 86000, loss: 0.020043
 >> iter 87000, loss: 0.019458
 >> iter 88000, loss: 0.027590
 >> iter 89000, loss: 0.020626
 >> iter 90000, loss: 0.019555
   Number of active neurons: 1
 >> iter 91000, loss: 0.034908
 >> iter 92000, loss: 0.044095
 >> iter 93000, loss: 0.037556
 >> iter 94000, loss: 0.024043
 >> iter 95000, loss: 0.021799
 >> iter 96000, loss: 0.020354
 >> iter 97000, loss: 0.018716
 >> iter 98000, loss: 0.017568
 >> iter 99000, loss: 0.016952
 >> iter 100000, loss: 0.020162
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.949422
 >> iter 2000, loss: 4.092267
 >> iter 3000, loss: 1.535911
 >> iter 4000, loss: 0.592607
 >> iter 5000, loss: 0.240135
 >> iter 6000, loss: 0.111839
 >> iter 7000, loss: 0.061016
 >> iter 8000, loss: 0.040340
 >> iter 9000, loss: 0.049063
 >> iter 10000, loss: 0.050873
   Number of active neurons: 4
 >> iter 11000, loss: 0.037248
 >> iter 12000, loss: 0.030205
 >> iter 13000, loss: 0.039114
 >> iter 14000, loss: 0.034299
 >> iter 15000, loss: 0.027806
 >> iter 16000, loss: 0.024663
 >> iter 17000, loss: 0.024200
 >> iter 18000, loss: 0.057191
 >> iter 19000, loss: 0.036662
 >> iter 20000, loss: 0.032274
   Number of active neurons: 3
 >> iter 21000, loss: 0.029833
 >> iter 22000, loss: 0.025870
 >> iter 23000, loss: 0.025051
 >> iter 24000, loss: 0.029386
 >> iter 25000, loss: 0.027266
 >> iter 26000, loss: 0.024183
 >> iter 27000, loss: 0.024232
 >> iter 28000, loss: 0.025475
 >> iter 29000, loss: 0.029740
 >> iter 30000, loss: 0.026634
   Number of active neurons: 3
 >> iter 31000, loss: 0.030054
 >> iter 32000, loss: 0.026874
 >> iter 33000, loss: 0.025401
 >> iter 34000, loss: 0.025948
 >> iter 35000, loss: 0.040690
 >> iter 36000, loss: 0.031854
 >> iter 37000, loss: 0.026167
 >> iter 38000, loss: 0.033875
 >> iter 39000, loss: 0.035454
 >> iter 40000, loss: 0.029342
   Number of active neurons: 3
 >> iter 41000, loss: 0.028558
 >> iter 42000, loss: 0.025643
 >> iter 43000, loss: 0.025599
 >> iter 44000, loss: 0.024775
 >> iter 45000, loss: 0.023268
 >> iter 46000, loss: 0.024226
 >> iter 47000, loss: 0.032946
 >> iter 48000, loss: 0.025345
 >> iter 49000, loss: 0.023330
 >> iter 50000, loss: 0.022932
   Number of active neurons: 2
 >> iter 51000, loss: 0.038414
 >> iter 52000, loss: 0.051429
 >> iter 53000, loss: 0.036498
 >> iter 54000, loss: 0.042345
 >> iter 55000, loss: 0.028153
 >> iter 56000, loss: 0.024617
 >> iter 57000, loss: 0.025341
 >> iter 58000, loss: 0.026620
 >> iter 59000, loss: 0.023446
 >> iter 60000, loss: 0.023140
   Number of active neurons: 2
 >> iter 61000, loss: 0.021753
 >> iter 62000, loss: 0.033135
 >> iter 63000, loss: 0.027285
 >> iter 64000, loss: 0.021882
 >> iter 65000, loss: 0.022322
 >> iter 66000, loss: 0.023540
 >> iter 67000, loss: 0.026516
 >> iter 68000, loss: 0.025968
 >> iter 69000, loss: 0.028453
 >> iter 70000, loss: 0.024596
   Number of active neurons: 1
 >> iter 71000, loss: 0.031221
 >> iter 72000, loss: 0.033850
 >> iter 73000, loss: 0.036144
 >> iter 74000, loss: 0.030630
 >> iter 75000, loss: 0.022319
 >> iter 76000, loss: 0.019403
 >> iter 77000, loss: 0.027631
 >> iter 78000, loss: 0.020489
 >> iter 79000, loss: 0.022500
 >> iter 80000, loss: 0.018505
   Number of active neurons: 1
 >> iter 81000, loss: 0.018339
 >> iter 82000, loss: 0.032081
 >> iter 83000, loss: 0.050487
 >> iter 84000, loss: 0.039661
 >> iter 85000, loss: 0.025346
 >> iter 86000, loss: 0.023923
 >> iter 87000, loss: 0.025260
 >> iter 88000, loss: 0.019417
 >> iter 89000, loss: 0.016687
 >> iter 90000, loss: 0.035122
   Number of active neurons: 1
 >> iter 91000, loss: 0.025072
 >> iter 92000, loss: 0.023932
 >> iter 93000, loss: 0.018109
 >> iter 94000, loss: 0.024915
 >> iter 95000, loss: 0.019741
 >> iter 96000, loss: 0.016888
 >> iter 97000, loss: 0.025057
 >> iter 98000, loss: 0.027887
 >> iter 99000, loss: 0.026473
 >> iter 100000, loss: 0.019190
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 10.904401
 >> iter 2000, loss: 4.054344
 >> iter 3000, loss: 1.519419
 >> iter 4000, loss: 0.585497
 >> iter 5000, loss: 0.239962
 >> iter 6000, loss: 0.111397
 >> iter 7000, loss: 0.072256
 >> iter 8000, loss: 0.046077
 >> iter 9000, loss: 0.037380
 >> iter 10000, loss: 0.036208
   Number of active neurons: 4
 >> iter 11000, loss: 0.032299
 >> iter 12000, loss: 0.032636
 >> iter 13000, loss: 0.027994
 >> iter 14000, loss: 0.049792
 >> iter 15000, loss: 0.034638
 >> iter 16000, loss: 0.032978
 >> iter 17000, loss: 0.030147
 >> iter 18000, loss: 0.026769
 >> iter 19000, loss: 0.023832
 >> iter 20000, loss: 0.025109
   Number of active neurons: 3
 >> iter 21000, loss: 0.026333
 >> iter 22000, loss: 0.023822
 >> iter 23000, loss: 0.023491
 >> iter 24000, loss: 0.022357
 >> iter 25000, loss: 0.021381
 >> iter 26000, loss: 0.020702
 >> iter 27000, loss: 0.021370
 >> iter 28000, loss: 0.029201
 >> iter 29000, loss: 0.023265
 >> iter 30000, loss: 0.021805
   Number of active neurons: 2
 >> iter 31000, loss: 0.051836
 >> iter 32000, loss: 0.032737
 >> iter 33000, loss: 0.024771
 >> iter 34000, loss: 0.023740
 >> iter 35000, loss: 0.022414
 >> iter 36000, loss: 0.021340
 >> iter 37000, loss: 0.024046
 >> iter 38000, loss: 0.027134
 >> iter 39000, loss: 0.029557
 >> iter 40000, loss: 0.025162
   Number of active neurons: 2
 >> iter 41000, loss: 0.021284
 >> iter 42000, loss: 0.021954
 >> iter 43000, loss: 0.022583
 >> iter 44000, loss: 0.024619
 >> iter 45000, loss: 0.022867
 >> iter 46000, loss: 0.020735
 >> iter 47000, loss: 0.019904
 >> iter 48000, loss: 0.021538
 >> iter 49000, loss: 0.024625
 >> iter 50000, loss: 0.032768
   Number of active neurons: 2
 >> iter 51000, loss: 0.025933
 >> iter 52000, loss: 0.031378
 >> iter 53000, loss: 0.026050
 >> iter 54000, loss: 0.022586
 >> iter 55000, loss: 0.021320
 >> iter 56000, loss: 0.023716
 >> iter 57000, loss: 0.024190
 >> iter 58000, loss: 0.030874
 >> iter 59000, loss: 0.028653
 >> iter 60000, loss: 0.025918
   Number of active neurons: 2
 >> iter 61000, loss: 0.023147
 >> iter 62000, loss: 0.033360
 >> iter 63000, loss: 0.026181
 >> iter 64000, loss: 0.023290
 >> iter 65000, loss: 0.021830
 >> iter 66000, loss: 0.022699
 >> iter 67000, loss: 0.034456
 >> iter 68000, loss: 0.025275
 >> iter 69000, loss: 0.030269
 >> iter 70000, loss: 0.025717
   Number of active neurons: 2
 >> iter 71000, loss: 0.027780
 >> iter 72000, loss: 0.027285
 >> iter 73000, loss: 0.027831
 >> iter 74000, loss: 0.021871
 >> iter 75000, loss: 0.023089
 >> iter 76000, loss: 0.029662
 >> iter 77000, loss: 0.023230
 >> iter 78000, loss: 0.025293
 >> iter 79000, loss: 0.023191
 >> iter 80000, loss: 0.024031
   Number of active neurons: 2
 >> iter 81000, loss: 0.028522
 >> iter 82000, loss: 0.035953
 >> iter 83000, loss: 0.029061
 >> iter 84000, loss: 0.024076
 >> iter 85000, loss: 0.022066
 >> iter 86000, loss: 0.022878
 >> iter 87000, loss: 0.021235
 >> iter 88000, loss: 0.021000
 >> iter 89000, loss: 0.020876
 >> iter 90000, loss: 0.020595
   Number of active neurons: 2
 >> iter 91000, loss: 0.028344
 >> iter 92000, loss: 0.023125
 >> iter 93000, loss: 0.020790
 >> iter 94000, loss: 0.021889
 >> iter 95000, loss: 0.020752
 >> iter 96000, loss: 0.022180
 >> iter 97000, loss: 0.027910
 >> iter 98000, loss: 0.021909
 >> iter 99000, loss: 0.018014
 >> iter 100000, loss: 0.016779
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.003547
 >> iter 2000, loss: 4.097077
 >> iter 3000, loss: 1.541091
 >> iter 4000, loss: 0.591938
 >> iter 5000, loss: 0.241527
 >> iter 6000, loss: 0.109694
 >> iter 7000, loss: 0.075024
 >> iter 8000, loss: 0.046159
 >> iter 9000, loss: 0.038925
 >> iter 10000, loss: 0.036339
   Number of active neurons: 5
 >> iter 11000, loss: 0.033122
 >> iter 12000, loss: 0.038455
 >> iter 13000, loss: 0.051510
 >> iter 14000, loss: 0.037404
 >> iter 15000, loss: 0.072216
 >> iter 16000, loss: 0.048458
 >> iter 17000, loss: 0.037346
 >> iter 18000, loss: 0.039062
 >> iter 19000, loss: 0.037353
 >> iter 20000, loss: 0.034050
   Number of active neurons: 5
 >> iter 21000, loss: 0.033085
 >> iter 22000, loss: 0.035233
 >> iter 23000, loss: 0.029092
 >> iter 24000, loss: 0.034999
 >> iter 25000, loss: 0.037935
 >> iter 26000, loss: 0.031225
 >> iter 27000, loss: 0.028219
 >> iter 28000, loss: 0.027681
 >> iter 29000, loss: 0.027348
 >> iter 30000, loss: 0.027981
   Number of active neurons: 3
 >> iter 31000, loss: 0.027214
 >> iter 32000, loss: 0.030153
 >> iter 33000, loss: 0.041647
 >> iter 34000, loss: 0.032369
 >> iter 35000, loss: 0.040474
 >> iter 36000, loss: 0.059748
 >> iter 37000, loss: 0.038260
 >> iter 38000, loss: 0.036828
 >> iter 39000, loss: 0.031319
 >> iter 40000, loss: 0.026079
   Number of active neurons: 2
 >> iter 41000, loss: 0.029568
 >> iter 42000, loss: 0.026848
 >> iter 43000, loss: 0.022864
 >> iter 44000, loss: 0.025605
 >> iter 45000, loss: 0.030633
 >> iter 46000, loss: 0.023578
 >> iter 47000, loss: 0.022922
 >> iter 48000, loss: 0.025207
 >> iter 49000, loss: 0.035082
 >> iter 50000, loss: 0.028240
   Number of active neurons: 2
 >> iter 51000, loss: 0.022478
 >> iter 52000, loss: 0.024431
 >> iter 53000, loss: 0.029852
 >> iter 54000, loss: 0.025902
 >> iter 55000, loss: 0.026822
 >> iter 56000, loss: 0.022121
 >> iter 57000, loss: 0.019193
 >> iter 58000, loss: 0.033898
 >> iter 59000, loss: 0.024374
 >> iter 60000, loss: 0.023946
   Number of active neurons: 1
 >> iter 61000, loss: 0.021252
 >> iter 62000, loss: 0.020260
 >> iter 63000, loss: 0.023935
 >> iter 64000, loss: 0.021762
 >> iter 65000, loss: 0.018676
 >> iter 66000, loss: 0.018614
 >> iter 67000, loss: 0.019715
 >> iter 68000, loss: 0.021358
 >> iter 69000, loss: 0.018345
 >> iter 70000, loss: 0.017205
   Number of active neurons: 1
 >> iter 71000, loss: 0.019545
 >> iter 72000, loss: 0.023459
 >> iter 73000, loss: 0.036428
 >> iter 74000, loss: 0.030425
 >> iter 75000, loss: 0.023892
 >> iter 76000, loss: 0.019493
 >> iter 77000, loss: 0.036361
 >> iter 78000, loss: 0.031590
 >> iter 79000, loss: 0.023196
 >> iter 80000, loss: 0.019567
   Number of active neurons: 1
 >> iter 81000, loss: 0.062322
 >> iter 82000, loss: 0.032917
 >> iter 83000, loss: 0.024328
 >> iter 84000, loss: 0.019270
 >> iter 85000, loss: 0.019170
 >> iter 86000, loss: 0.046124
 >> iter 87000, loss: 0.034935
 >> iter 88000, loss: 0.025941
 >> iter 89000, loss: 0.032430
 >> iter 90000, loss: 0.022218
   Number of active neurons: 1
 >> iter 91000, loss: 0.032093
 >> iter 92000, loss: 0.023058
 >> iter 93000, loss: 0.032122
 >> iter 94000, loss: 0.043560
 >> iter 95000, loss: 0.034142
 >> iter 96000, loss: 0.025275
 >> iter 97000, loss: 0.025318
 >> iter 98000, loss: 0.024739
 >> iter 99000, loss: 0.019942
 >> iter 100000, loss: 0.018016
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.998764
 >> iter 2000, loss: 4.115957
 >> iter 3000, loss: 1.542427
 >> iter 4000, loss: 0.597103
 >> iter 5000, loss: 0.246717
 >> iter 6000, loss: 0.112111
 >> iter 7000, loss: 0.065852
 >> iter 8000, loss: 0.048091
 >> iter 9000, loss: 0.043768
 >> iter 10000, loss: 0.036135
   Number of active neurons: 5
 >> iter 11000, loss: 0.042741
 >> iter 12000, loss: 0.034057
 >> iter 13000, loss: 0.035651
 >> iter 14000, loss: 0.039418
 >> iter 15000, loss: 0.038139
 >> iter 16000, loss: 0.030503
 >> iter 17000, loss: 0.041408
 >> iter 18000, loss: 0.033103
 >> iter 19000, loss: 0.031401
 >> iter 20000, loss: 0.031759
   Number of active neurons: 4
 >> iter 21000, loss: 0.037947
 >> iter 22000, loss: 0.029367
 >> iter 23000, loss: 0.036871
 >> iter 24000, loss: 0.029726
 >> iter 25000, loss: 0.033658
 >> iter 26000, loss: 0.030618
 >> iter 27000, loss: 0.026171
 >> iter 28000, loss: 0.026953
 >> iter 29000, loss: 0.026203
 >> iter 30000, loss: 0.025852
   Number of active neurons: 3
 >> iter 31000, loss: 0.026238
 >> iter 32000, loss: 0.032346
 >> iter 33000, loss: 0.030789
 >> iter 34000, loss: 0.033018
 >> iter 35000, loss: 0.030909
 >> iter 36000, loss: 0.025543
 >> iter 37000, loss: 0.026919
 >> iter 38000, loss: 0.027763
 >> iter 39000, loss: 0.029319
 >> iter 40000, loss: 0.026715
   Number of active neurons: 3
 >> iter 41000, loss: 0.025433
 >> iter 42000, loss: 0.024613
 >> iter 43000, loss: 0.035335
 >> iter 44000, loss: 0.038882
 >> iter 45000, loss: 0.030427
 >> iter 46000, loss: 0.036907
 >> iter 47000, loss: 0.029440
 >> iter 48000, loss: 0.031474
 >> iter 49000, loss: 0.030402
 >> iter 50000, loss: 0.033321
   Number of active neurons: 3
 >> iter 51000, loss: 0.029469
 >> iter 52000, loss: 0.038796
 >> iter 53000, loss: 0.029025
 >> iter 54000, loss: 0.025209
 >> iter 55000, loss: 0.029300
 >> iter 56000, loss: 0.025640
 >> iter 57000, loss: 0.027795
 >> iter 58000, loss: 0.027367
 >> iter 59000, loss: 0.025842
 >> iter 60000, loss: 0.034912
   Number of active neurons: 2
 >> iter 61000, loss: 0.040010
 >> iter 62000, loss: 0.029191
 >> iter 63000, loss: 0.025673
 >> iter 64000, loss: 0.026196
 >> iter 65000, loss: 0.022465
 >> iter 66000, loss: 0.023053
 >> iter 67000, loss: 0.027670
 >> iter 68000, loss: 0.023683
 >> iter 69000, loss: 0.022845
 >> iter 70000, loss: 0.046780
   Number of active neurons: 1
 >> iter 71000, loss: 0.030136
 >> iter 72000, loss: 0.028278
 >> iter 73000, loss: 0.021190
 >> iter 74000, loss: 0.026527
 >> iter 75000, loss: 0.020368
 >> iter 76000, loss: 0.022094
 >> iter 77000, loss: 0.019398
 >> iter 78000, loss: 0.017482
 >> iter 79000, loss: 0.033235
 >> iter 80000, loss: 0.024134
   Number of active neurons: 1
 >> iter 81000, loss: 0.018364
 >> iter 82000, loss: 0.019183
 >> iter 83000, loss: 0.020206
 >> iter 84000, loss: 0.024776
 >> iter 85000, loss: 0.023457
 >> iter 86000, loss: 0.020754
 >> iter 87000, loss: 0.019303
 >> iter 88000, loss: 0.023338
 >> iter 89000, loss: 0.018672
 >> iter 90000, loss: 0.017733
   Number of active neurons: 1
 >> iter 91000, loss: 0.019251
 >> iter 92000, loss: 0.026978
 >> iter 93000, loss: 0.023556
 >> iter 94000, loss: 0.019052
 >> iter 95000, loss: 0.020610
 >> iter 96000, loss: 0.015926
 >> iter 97000, loss: 0.029609
 >> iter 98000, loss: 0.034579
 >> iter 99000, loss: 0.025826
 >> iter 100000, loss: 0.034734
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.972085
 >> iter 2000, loss: 4.084228
 >> iter 3000, loss: 1.530477
 >> iter 4000, loss: 0.589901
 >> iter 5000, loss: 0.239482
 >> iter 6000, loss: 0.114663
 >> iter 7000, loss: 0.065256
 >> iter 8000, loss: 0.046613
 >> iter 9000, loss: 0.038984
 >> iter 10000, loss: 0.033744
   Number of active neurons: 7
 >> iter 11000, loss: 0.031503
 >> iter 12000, loss: 0.029986
 >> iter 13000, loss: 0.039481
 >> iter 14000, loss: 0.034617
 >> iter 15000, loss: 0.037294
 >> iter 16000, loss: 0.032949
 >> iter 17000, loss: 0.034095
 >> iter 18000, loss: 0.033251
 >> iter 19000, loss: 0.030631
 >> iter 20000, loss: 0.026848
   Number of active neurons: 3
 >> iter 21000, loss: 0.030201
 >> iter 22000, loss: 0.027576
 >> iter 23000, loss: 0.027016
 >> iter 24000, loss: 0.025555
 >> iter 25000, loss: 0.025081
 >> iter 26000, loss: 0.027202
 >> iter 27000, loss: 0.041353
 >> iter 28000, loss: 0.030657
 >> iter 29000, loss: 0.028362
 >> iter 30000, loss: 0.036802
   Number of active neurons: 3
 >> iter 31000, loss: 0.028322
 >> iter 32000, loss: 0.026499
 >> iter 33000, loss: 0.025763
 >> iter 34000, loss: 0.027187
 >> iter 35000, loss: 0.025049
 >> iter 36000, loss: 0.024374
 >> iter 37000, loss: 0.022855
 >> iter 38000, loss: 0.025194
 >> iter 39000, loss: 0.024259
 >> iter 40000, loss: 0.022833
   Number of active neurons: 2
 >> iter 41000, loss: 0.021648
 >> iter 42000, loss: 0.021022
 >> iter 43000, loss: 0.028893
 >> iter 44000, loss: 0.025352
 >> iter 45000, loss: 0.030131
 >> iter 46000, loss: 0.039401
 >> iter 47000, loss: 0.028169
 >> iter 48000, loss: 0.024772
 >> iter 49000, loss: 0.021768
 >> iter 50000, loss: 0.022635
   Number of active neurons: 1
 >> iter 51000, loss: 0.019351
 >> iter 52000, loss: 0.021262
 >> iter 53000, loss: 0.019698
 >> iter 54000, loss: 0.019039
 >> iter 55000, loss: 0.031074
 >> iter 56000, loss: 0.032348
 >> iter 57000, loss: 0.031248
 >> iter 58000, loss: 0.022544
 >> iter 59000, loss: 0.035825
 >> iter 60000, loss: 0.034688
   Number of active neurons: 1
 >> iter 61000, loss: 0.022913
 >> iter 62000, loss: 0.023021
 >> iter 63000, loss: 0.021670
 >> iter 64000, loss: 0.026647
 >> iter 65000, loss: 0.022932
 >> iter 66000, loss: 0.020035
 >> iter 67000, loss: 0.018270
 >> iter 68000, loss: 0.016488
 >> iter 69000, loss: 0.017744
 >> iter 70000, loss: 0.016564
   Number of active neurons: 1
 >> iter 71000, loss: 0.031905
 >> iter 72000, loss: 0.025944
 >> iter 73000, loss: 0.021084
 >> iter 74000, loss: 0.017637
 >> iter 75000, loss: 0.016469
 >> iter 76000, loss: 0.022998
 >> iter 77000, loss: 0.024964
 >> iter 78000, loss: 0.032910
 >> iter 79000, loss: 0.023151
 >> iter 80000, loss: 0.028453
   Number of active neurons: 1
 >> iter 81000, loss: 0.021503
 >> iter 82000, loss: 0.020040
 >> iter 83000, loss: 0.023974
 >> iter 84000, loss: 0.020824
 >> iter 85000, loss: 0.019209
 >> iter 86000, loss: 0.017852
 >> iter 87000, loss: 0.017182
 >> iter 88000, loss: 0.030791
 >> iter 89000, loss: 0.021215
 >> iter 90000, loss: 0.018157
   Number of active neurons: 1
 >> iter 91000, loss: 0.016866
 >> iter 92000, loss: 0.016069
 >> iter 93000, loss: 0.016550
 >> iter 94000, loss: 0.038717
 >> iter 95000, loss: 0.034293
 >> iter 96000, loss: 0.032751
 >> iter 97000, loss: 0.025817
 >> iter 98000, loss: 0.030295
 >> iter 99000, loss: 0.022591
 >> iter 100000, loss: 0.019630
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.024086
 >> iter 2000, loss: 4.137780
 >> iter 3000, loss: 1.551084
 >> iter 4000, loss: 0.620729
 >> iter 5000, loss: 0.256019
 >> iter 6000, loss: 0.115884
 >> iter 7000, loss: 0.069510
 >> iter 8000, loss: 0.046080
 >> iter 9000, loss: 0.039286
 >> iter 10000, loss: 0.035296
   Number of active neurons: 7
 >> iter 11000, loss: 0.040655
 >> iter 12000, loss: 0.035741
 >> iter 13000, loss: 0.032630
 >> iter 14000, loss: 0.030697
 >> iter 15000, loss: 0.032578
 >> iter 16000, loss: 0.040982
 >> iter 17000, loss: 0.034368
 >> iter 18000, loss: 0.032170
 >> iter 19000, loss: 0.033439
 >> iter 20000, loss: 0.029595
   Number of active neurons: 3
 >> iter 21000, loss: 0.025968
 >> iter 22000, loss: 0.037279
 >> iter 23000, loss: 0.029238
 >> iter 24000, loss: 0.025504
 >> iter 25000, loss: 0.032164
 >> iter 26000, loss: 0.030513
 >> iter 27000, loss: 0.025895
 >> iter 28000, loss: 0.041296
 >> iter 29000, loss: 0.034051
 >> iter 30000, loss: 0.027000
   Number of active neurons: 2
 >> iter 31000, loss: 0.039957
 >> iter 32000, loss: 0.028823
 >> iter 33000, loss: 0.023505
 >> iter 34000, loss: 0.021189
 >> iter 35000, loss: 0.029047
 >> iter 36000, loss: 0.034647
 >> iter 37000, loss: 0.028127
 >> iter 38000, loss: 0.022461
 >> iter 39000, loss: 0.022124
 >> iter 40000, loss: 0.019003
   Number of active neurons: 1
 >> iter 41000, loss: 0.018055
 >> iter 42000, loss: 0.017668
 >> iter 43000, loss: 0.019202
 >> iter 44000, loss: 0.020307
 >> iter 45000, loss: 0.021723
 >> iter 46000, loss: 0.019452
 >> iter 47000, loss: 0.025879
 >> iter 48000, loss: 0.021358
 >> iter 49000, loss: 0.020424
 >> iter 50000, loss: 0.020192
   Number of active neurons: 1
 >> iter 51000, loss: 0.019872
 >> iter 52000, loss: 0.020755
 >> iter 53000, loss: 0.033213
 >> iter 54000, loss: 0.022512
 >> iter 55000, loss: 0.019628
 >> iter 56000, loss: 0.026524
 >> iter 57000, loss: 0.029811
 >> iter 58000, loss: 0.026181
 >> iter 59000, loss: 0.021433
 >> iter 60000, loss: 0.022040
   Number of active neurons: 1
 >> iter 61000, loss: 0.018275
 >> iter 62000, loss: 0.018022
 >> iter 63000, loss: 0.019895
 >> iter 64000, loss: 0.018211
 >> iter 65000, loss: 0.017357
 >> iter 66000, loss: 0.017225
 >> iter 67000, loss: 0.020261
 >> iter 68000, loss: 0.021004
 >> iter 69000, loss: 0.018975
 >> iter 70000, loss: 0.027620
   Number of active neurons: 1
 >> iter 71000, loss: 0.020478
 >> iter 72000, loss: 0.017660
 >> iter 73000, loss: 0.048580
 >> iter 74000, loss: 0.035363
 >> iter 75000, loss: 0.031747
 >> iter 76000, loss: 0.024422
 >> iter 77000, loss: 0.021308
 >> iter 78000, loss: 0.024999
 >> iter 79000, loss: 0.020119
 >> iter 80000, loss: 0.019485
   Number of active neurons: 1
 >> iter 81000, loss: 0.018984
 >> iter 82000, loss: 0.047900
 >> iter 83000, loss: 0.026938
 >> iter 84000, loss: 0.024493
 >> iter 85000, loss: 0.019319
 >> iter 86000, loss: 0.019835
 >> iter 87000, loss: 0.017897
 >> iter 88000, loss: 0.017326
 >> iter 89000, loss: 0.018990
 >> iter 90000, loss: 0.019109
   Number of active neurons: 1
 >> iter 91000, loss: 0.019484
 >> iter 92000, loss: 0.025034
 >> iter 93000, loss: 0.025254
 >> iter 94000, loss: 0.021789
 >> iter 95000, loss: 0.019082
 >> iter 96000, loss: 0.033710
 >> iter 97000, loss: 0.024469
 >> iter 98000, loss: 0.020386
 >> iter 99000, loss: 0.018453
 >> iter 100000, loss: 0.020761
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.986381
 >> iter 2000, loss: 4.103732
 >> iter 3000, loss: 1.548218
 >> iter 4000, loss: 0.593215
 >> iter 5000, loss: 0.241824
 >> iter 6000, loss: 0.125420
 >> iter 7000, loss: 0.072806
 >> iter 8000, loss: 0.052655
 >> iter 9000, loss: 0.043132
 >> iter 10000, loss: 0.036108
   Number of active neurons: 4
 >> iter 11000, loss: 0.031973
 >> iter 12000, loss: 0.044942
 >> iter 13000, loss: 0.035405
 >> iter 14000, loss: 0.054276
 >> iter 15000, loss: 0.037331
 >> iter 16000, loss: 0.033394
 >> iter 17000, loss: 0.030124
 >> iter 18000, loss: 0.052569
 >> iter 19000, loss: 0.039994
 >> iter 20000, loss: 0.030536
   Number of active neurons: 2
 >> iter 21000, loss: 0.026169
 >> iter 22000, loss: 0.025572
 >> iter 23000, loss: 0.028342
 >> iter 24000, loss: 0.022695
 >> iter 25000, loss: 0.026670
 >> iter 26000, loss: 0.023507
 >> iter 27000, loss: 0.026822
 >> iter 28000, loss: 0.023818
 >> iter 29000, loss: 0.022320
 >> iter 30000, loss: 0.021030
   Number of active neurons: 2
 >> iter 31000, loss: 0.023845
 >> iter 32000, loss: 0.023309
 >> iter 33000, loss: 0.020843
 >> iter 34000, loss: 0.021158
 >> iter 35000, loss: 0.020620
 >> iter 36000, loss: 0.024185
 >> iter 37000, loss: 0.023953
 >> iter 38000, loss: 0.025204
 >> iter 39000, loss: 0.023166
 >> iter 40000, loss: 0.020474
   Number of active neurons: 2
 >> iter 41000, loss: 0.020571
 >> iter 42000, loss: 0.022762
 >> iter 43000, loss: 0.027232
 >> iter 44000, loss: 0.024847
 >> iter 45000, loss: 0.021630
 >> iter 46000, loss: 0.025046
 >> iter 47000, loss: 0.023846
 >> iter 48000, loss: 0.022279
 >> iter 49000, loss: 0.026046
 >> iter 50000, loss: 0.031686
   Number of active neurons: 2
 >> iter 51000, loss: 0.027768
 >> iter 52000, loss: 0.024409
 >> iter 53000, loss: 0.020607
 >> iter 54000, loss: 0.028714
 >> iter 55000, loss: 0.022294
 >> iter 56000, loss: 0.022226
 >> iter 57000, loss: 0.021597
 >> iter 58000, loss: 0.024918
 >> iter 59000, loss: 0.025126
 >> iter 60000, loss: 0.021828
   Number of active neurons: 2
 >> iter 61000, loss: 0.035982
 >> iter 62000, loss: 0.046239
 >> iter 63000, loss: 0.032663
 >> iter 64000, loss: 0.026784
 >> iter 65000, loss: 0.022122
 >> iter 66000, loss: 0.020562
 >> iter 67000, loss: 0.022233
 >> iter 68000, loss: 0.030847
 >> iter 69000, loss: 0.024778
 >> iter 70000, loss: 0.020992
   Number of active neurons: 2
 >> iter 71000, loss: 0.034044
 >> iter 72000, loss: 0.035986
 >> iter 73000, loss: 0.035386
 >> iter 74000, loss: 0.026458
 >> iter 75000, loss: 0.023692
 >> iter 76000, loss: 0.021961
 >> iter 77000, loss: 0.024183
 >> iter 78000, loss: 0.023252
 >> iter 79000, loss: 0.034305
 >> iter 80000, loss: 0.028382
   Number of active neurons: 2
 >> iter 81000, loss: 0.031459
 >> iter 82000, loss: 0.026739
 >> iter 83000, loss: 0.022273
 >> iter 84000, loss: 0.023526
 >> iter 85000, loss: 0.022806
 >> iter 86000, loss: 0.026307
 >> iter 87000, loss: 0.023830
 >> iter 88000, loss: 0.027601
 >> iter 89000, loss: 0.023898
 >> iter 90000, loss: 0.026225
   Number of active neurons: 2
 >> iter 91000, loss: 0.029969
 >> iter 92000, loss: 0.024890
 >> iter 93000, loss: 0.021473
 >> iter 94000, loss: 0.022739
 >> iter 95000, loss: 0.027577
 >> iter 96000, loss: 0.023945
 >> iter 97000, loss: 0.041418
 >> iter 98000, loss: 0.032845
 >> iter 99000, loss: 0.030470
 >> iter 100000, loss: 0.041470
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.995551
 >> iter 2000, loss: 4.086599
 >> iter 3000, loss: 1.548987
 >> iter 4000, loss: 0.599645
 >> iter 5000, loss: 0.241980
 >> iter 6000, loss: 0.113738
 >> iter 7000, loss: 0.064970
 >> iter 8000, loss: 0.045735
 >> iter 9000, loss: 0.037509
 >> iter 10000, loss: 0.038689
   Number of active neurons: 6
 >> iter 11000, loss: 0.032738
 >> iter 12000, loss: 0.032971
 >> iter 13000, loss: 0.037872
 >> iter 14000, loss: 0.032580
 >> iter 15000, loss: 0.028169
 >> iter 16000, loss: 0.028486
 >> iter 17000, loss: 0.036335
 >> iter 18000, loss: 0.032606
 >> iter 19000, loss: 0.033186
 >> iter 20000, loss: 0.028877
   Number of active neurons: 4
 >> iter 21000, loss: 0.025082
 >> iter 22000, loss: 0.025463
 >> iter 23000, loss: 0.028561
 >> iter 24000, loss: 0.027049
 >> iter 25000, loss: 0.025904
 >> iter 26000, loss: 0.025408
 >> iter 27000, loss: 0.026582
 >> iter 28000, loss: 0.024304
 >> iter 29000, loss: 0.027944
 >> iter 30000, loss: 0.026114
   Number of active neurons: 3
 >> iter 31000, loss: 0.023797
 >> iter 32000, loss: 0.027648
 >> iter 33000, loss: 0.024995
 >> iter 34000, loss: 0.034843
 >> iter 35000, loss: 0.026582
 >> iter 36000, loss: 0.023804
 >> iter 37000, loss: 0.060846
 >> iter 38000, loss: 0.038467
 >> iter 39000, loss: 0.028269
 >> iter 40000, loss: 0.024597
   Number of active neurons: 2
 >> iter 41000, loss: 0.023053
 >> iter 42000, loss: 0.022145
 >> iter 43000, loss: 0.026645
 >> iter 44000, loss: 0.023819
 >> iter 45000, loss: 0.029325
 >> iter 46000, loss: 0.026312
 >> iter 47000, loss: 0.023146
 >> iter 48000, loss: 0.020660
 >> iter 49000, loss: 0.035806
 >> iter 50000, loss: 0.025783
   Number of active neurons: 2
 >> iter 51000, loss: 0.023759
 >> iter 52000, loss: 0.021589
 >> iter 53000, loss: 0.019922
 >> iter 54000, loss: 0.020347
 >> iter 55000, loss: 0.024372
 >> iter 56000, loss: 0.032153
 >> iter 57000, loss: 0.024744
 >> iter 58000, loss: 0.026515
 >> iter 59000, loss: 0.023761
 >> iter 60000, loss: 0.020941
   Number of active neurons: 2
 >> iter 61000, loss: 0.021625
 >> iter 62000, loss: 0.022779
 >> iter 63000, loss: 0.025117
 >> iter 64000, loss: 0.022503
 >> iter 65000, loss: 0.021055
 >> iter 66000, loss: 0.024063
 >> iter 67000, loss: 0.024124
 >> iter 68000, loss: 0.024545
 >> iter 69000, loss: 0.021704
 >> iter 70000, loss: 0.021491
   Number of active neurons: 2
 >> iter 71000, loss: 0.019754
 >> iter 72000, loss: 0.020385
 >> iter 73000, loss: 0.029848
 >> iter 74000, loss: 0.027543
 >> iter 75000, loss: 0.025659
 >> iter 76000, loss: 0.021715
 >> iter 77000, loss: 0.022675
 >> iter 78000, loss: 0.023600
 >> iter 79000, loss: 0.025137
 >> iter 80000, loss: 0.022768
   Number of active neurons: 2
 >> iter 81000, loss: 0.023780
 >> iter 82000, loss: 0.020982
 >> iter 83000, loss: 0.021178
 >> iter 84000, loss: 0.050771
 >> iter 85000, loss: 0.035421
 >> iter 86000, loss: 0.039057
 >> iter 87000, loss: 0.056936
 >> iter 88000, loss: 0.036517
 >> iter 89000, loss: 0.027981
 >> iter 90000, loss: 0.024881
   Number of active neurons: 2
 >> iter 91000, loss: 0.021936
 >> iter 92000, loss: 0.030884
 >> iter 93000, loss: 0.026369
 >> iter 94000, loss: 0.022486
 >> iter 95000, loss: 0.037349
 >> iter 96000, loss: 0.031743
 >> iter 97000, loss: 0.049759
 >> iter 98000, loss: 0.033543
 >> iter 99000, loss: 0.024350
 >> iter 100000, loss: 0.022270
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.882751
 >> iter 2000, loss: 4.059814
 >> iter 3000, loss: 1.521573
 >> iter 4000, loss: 0.580794
 >> iter 5000, loss: 0.235286
 >> iter 6000, loss: 0.106846
 >> iter 7000, loss: 0.056310
 >> iter 8000, loss: 0.038441
 >> iter 9000, loss: 0.038039
 >> iter 10000, loss: 0.031054
   Number of active neurons: 4
 >> iter 11000, loss: 0.028063
 >> iter 12000, loss: 0.030238
 >> iter 13000, loss: 0.036570
 >> iter 14000, loss: 0.029298
 >> iter 15000, loss: 0.029231
 >> iter 16000, loss: 0.027655
 >> iter 17000, loss: 0.026503
 >> iter 18000, loss: 0.027318
 >> iter 19000, loss: 0.031938
 >> iter 20000, loss: 0.031215
   Number of active neurons: 3
 >> iter 21000, loss: 0.027882
 >> iter 22000, loss: 0.026858
 >> iter 23000, loss: 0.025172
 >> iter 24000, loss: 0.028936
 >> iter 25000, loss: 0.026748
 >> iter 26000, loss: 0.024288
 >> iter 27000, loss: 0.023700
 >> iter 28000, loss: 0.023350
 >> iter 29000, loss: 0.027221
 >> iter 30000, loss: 0.025021
   Number of active neurons: 3
 >> iter 31000, loss: 0.028921
 >> iter 32000, loss: 0.028835
 >> iter 33000, loss: 0.029457
 >> iter 34000, loss: 0.030920
 >> iter 35000, loss: 0.026675
 >> iter 36000, loss: 0.027012
 >> iter 37000, loss: 0.024042
 >> iter 38000, loss: 0.023956
 >> iter 39000, loss: 0.030016
 >> iter 40000, loss: 0.025518
   Number of active neurons: 3
 >> iter 41000, loss: 0.025386
 >> iter 42000, loss: 0.024153
 >> iter 43000, loss: 0.023657
 >> iter 44000, loss: 0.031541
 >> iter 45000, loss: 0.026019
 >> iter 46000, loss: 0.025273
 >> iter 47000, loss: 0.026454
 >> iter 48000, loss: 0.027396
 >> iter 49000, loss: 0.026421
 >> iter 50000, loss: 0.024844
   Number of active neurons: 3
 >> iter 51000, loss: 0.027461
 >> iter 52000, loss: 0.026110
 >> iter 53000, loss: 0.026905
 >> iter 54000, loss: 0.034949
 >> iter 55000, loss: 0.028960
 >> iter 56000, loss: 0.025786
 >> iter 57000, loss: 0.025264
 >> iter 58000, loss: 0.038835
 >> iter 59000, loss: 0.028914
 >> iter 60000, loss: 0.024397
   Number of active neurons: 3
 >> iter 61000, loss: 0.023286
 >> iter 62000, loss: 0.043006
 >> iter 63000, loss: 0.033696
 >> iter 64000, loss: 0.030990
 >> iter 65000, loss: 0.027784
 >> iter 66000, loss: 0.026090
 >> iter 67000, loss: 0.021970
 >> iter 68000, loss: 0.028264
 >> iter 69000, loss: 0.023792
 >> iter 70000, loss: 0.022272
   Number of active neurons: 2
 >> iter 71000, loss: 0.029687
 >> iter 72000, loss: 0.031294
 >> iter 73000, loss: 0.024177
 >> iter 74000, loss: 0.020926
 >> iter 75000, loss: 0.040272
 >> iter 76000, loss: 0.027730
 >> iter 77000, loss: 0.022891
 >> iter 78000, loss: 0.023477
 >> iter 79000, loss: 0.023079
 >> iter 80000, loss: 0.029261
   Number of active neurons: 2
 >> iter 81000, loss: 0.026433
 >> iter 82000, loss: 0.024816
 >> iter 83000, loss: 0.023043
 >> iter 84000, loss: 0.031183
 >> iter 85000, loss: 0.025260
 >> iter 86000, loss: 0.027050
 >> iter 87000, loss: 0.023440
 >> iter 88000, loss: 0.021518
 >> iter 89000, loss: 0.019852
 >> iter 90000, loss: 0.019292
   Number of active neurons: 1
 >> iter 91000, loss: 0.019757
 >> iter 92000, loss: 0.034166
 >> iter 93000, loss: 0.028632
 >> iter 94000, loss: 0.036325
 >> iter 95000, loss: 0.025023
 >> iter 96000, loss: 0.023770
 >> iter 97000, loss: 0.025216
 >> iter 98000, loss: 0.021405
 >> iter 99000, loss: 0.022838
 >> iter 100000, loss: 0.024041
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.947204
 >> iter 2000, loss: 4.085765
 >> iter 3000, loss: 1.535609
 >> iter 4000, loss: 0.593512
 >> iter 5000, loss: 0.246213
 >> iter 6000, loss: 0.115383
 >> iter 7000, loss: 0.070131
 >> iter 8000, loss: 0.059112
 >> iter 9000, loss: 0.054849
 >> iter 10000, loss: 0.037518
   Number of active neurons: 5
 >> iter 11000, loss: 0.041938
 >> iter 12000, loss: 0.033462
 >> iter 13000, loss: 0.033387
 >> iter 14000, loss: 0.030529
 >> iter 15000, loss: 0.029371
 >> iter 16000, loss: 0.040091
 >> iter 17000, loss: 0.031850
 >> iter 18000, loss: 0.029332
 >> iter 19000, loss: 0.030892
 >> iter 20000, loss: 0.031476
   Number of active neurons: 4
 >> iter 21000, loss: 0.027176
 >> iter 22000, loss: 0.024737
 >> iter 23000, loss: 0.025709
 >> iter 24000, loss: 0.030971
 >> iter 25000, loss: 0.054478
 >> iter 26000, loss: 0.036603
 >> iter 27000, loss: 0.029023
 >> iter 28000, loss: 0.028780
 >> iter 29000, loss: 0.027741
 >> iter 30000, loss: 0.027523
   Number of active neurons: 4
 >> iter 31000, loss: 0.027071
 >> iter 32000, loss: 0.029498
 >> iter 33000, loss: 0.025999
 >> iter 34000, loss: 0.025475
 >> iter 35000, loss: 0.028430
 >> iter 36000, loss: 0.026813
 >> iter 37000, loss: 0.025360
 >> iter 38000, loss: 0.040305
 >> iter 39000, loss: 0.033246
 >> iter 40000, loss: 0.028524
   Number of active neurons: 2
 >> iter 41000, loss: 0.023831
 >> iter 42000, loss: 0.028467
 >> iter 43000, loss: 0.026967
 >> iter 44000, loss: 0.027378
 >> iter 45000, loss: 0.024811
 >> iter 46000, loss: 0.032619
 >> iter 47000, loss: 0.026966
 >> iter 48000, loss: 0.022394
 >> iter 49000, loss: 0.026621
 >> iter 50000, loss: 0.021930
   Number of active neurons: 2
 >> iter 51000, loss: 0.022744
 >> iter 52000, loss: 0.024327
 >> iter 53000, loss: 0.024359
 >> iter 54000, loss: 0.039451
 >> iter 55000, loss: 0.034797
 >> iter 56000, loss: 0.032290
 >> iter 57000, loss: 0.040924
 >> iter 58000, loss: 0.028746
 >> iter 59000, loss: 0.023364
 >> iter 60000, loss: 0.035970
   Number of active neurons: 2
 >> iter 61000, loss: 0.027720
 >> iter 62000, loss: 0.028098
 >> iter 63000, loss: 0.022373
 >> iter 64000, loss: 0.030933
 >> iter 65000, loss: 0.024793
 >> iter 66000, loss: 0.030144
 >> iter 67000, loss: 0.026808
 >> iter 68000, loss: 0.026356
 >> iter 69000, loss: 0.024296
 >> iter 70000, loss: 0.023907
   Number of active neurons: 2
 >> iter 71000, loss: 0.021189
 >> iter 72000, loss: 0.035587
 >> iter 73000, loss: 0.024944
 >> iter 74000, loss: 0.023893
 >> iter 75000, loss: 0.021990
 >> iter 76000, loss: 0.025945
 >> iter 77000, loss: 0.022100
 >> iter 78000, loss: 0.030249
 >> iter 79000, loss: 0.028078
 >> iter 80000, loss: 0.021678
   Number of active neurons: 1
 >> iter 81000, loss: 0.019948
 >> iter 82000, loss: 0.024994
 >> iter 83000, loss: 0.026002
 >> iter 84000, loss: 0.022111
 >> iter 85000, loss: 0.020142
 >> iter 86000, loss: 0.027423
 >> iter 87000, loss: 0.024892
 >> iter 88000, loss: 0.019960
 >> iter 89000, loss: 0.017941
 >> iter 90000, loss: 0.020475
   Number of active neurons: 1
 >> iter 91000, loss: 0.022715
 >> iter 92000, loss: 0.018659
 >> iter 93000, loss: 0.020068
 >> iter 94000, loss: 0.019537
 >> iter 95000, loss: 0.025163
 >> iter 96000, loss: 0.019599
 >> iter 97000, loss: 0.029310
 >> iter 98000, loss: 0.024170
 >> iter 99000, loss: 0.023253
 >> iter 100000, loss: 0.019257
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.011049
 >> iter 2000, loss: 4.106352
 >> iter 3000, loss: 1.550337
 >> iter 4000, loss: 0.601777
 >> iter 5000, loss: 0.253974
 >> iter 6000, loss: 0.119232
 >> iter 7000, loss: 0.064791
 >> iter 8000, loss: 0.055030
 >> iter 9000, loss: 0.040079
 >> iter 10000, loss: 0.036791
   Number of active neurons: 6
 >> iter 11000, loss: 0.035797
 >> iter 12000, loss: 0.032491
 >> iter 13000, loss: 0.028960
 >> iter 14000, loss: 0.029969
 >> iter 15000, loss: 0.035256
 >> iter 16000, loss: 0.031951
 >> iter 17000, loss: 0.029897
 >> iter 18000, loss: 0.030341
 >> iter 19000, loss: 0.030311
 >> iter 20000, loss: 0.029242
   Number of active neurons: 4
 >> iter 21000, loss: 0.031004
 >> iter 22000, loss: 0.041339
 >> iter 23000, loss: 0.036177
 >> iter 24000, loss: 0.033623
 >> iter 25000, loss: 0.030614
 >> iter 26000, loss: 0.030808
 >> iter 27000, loss: 0.033364
 >> iter 28000, loss: 0.027881
 >> iter 29000, loss: 0.024161
 >> iter 30000, loss: 0.023596
   Number of active neurons: 2
 >> iter 31000, loss: 0.023260
 >> iter 32000, loss: 0.038714
 >> iter 33000, loss: 0.026956
 >> iter 34000, loss: 0.025015
 >> iter 35000, loss: 0.025936
 >> iter 36000, loss: 0.034391
 >> iter 37000, loss: 0.026485
 >> iter 38000, loss: 0.022697
 >> iter 39000, loss: 0.026873
 >> iter 40000, loss: 0.027149
   Number of active neurons: 2
 >> iter 41000, loss: 0.026578
 >> iter 42000, loss: 0.021964
 >> iter 43000, loss: 0.023233
 >> iter 44000, loss: 0.020957
 >> iter 45000, loss: 0.033014
 >> iter 46000, loss: 0.045819
 >> iter 47000, loss: 0.029917
 >> iter 48000, loss: 0.042202
 >> iter 49000, loss: 0.027557
 >> iter 50000, loss: 0.024947
   Number of active neurons: 2
 >> iter 51000, loss: 0.025899
 >> iter 52000, loss: 0.025346
 >> iter 53000, loss: 0.021152
 >> iter 54000, loss: 0.021616
 >> iter 55000, loss: 0.021167
 >> iter 56000, loss: 0.020611
 >> iter 57000, loss: 0.030188
 >> iter 58000, loss: 0.023994
 >> iter 59000, loss: 0.020260
 >> iter 60000, loss: 0.022015
   Number of active neurons: 2
 >> iter 61000, loss: 0.022868
 >> iter 62000, loss: 0.029179
 >> iter 63000, loss: 0.023417
 >> iter 64000, loss: 0.023064
 >> iter 65000, loss: 0.021251
 >> iter 66000, loss: 0.021111
 >> iter 67000, loss: 0.021439
 >> iter 68000, loss: 0.023123
 >> iter 69000, loss: 0.024643
 >> iter 70000, loss: 0.023980
   Number of active neurons: 2
 >> iter 71000, loss: 0.022317
 >> iter 72000, loss: 0.026325
 >> iter 73000, loss: 0.037378
 >> iter 74000, loss: 0.026688
 >> iter 75000, loss: 0.021939
 >> iter 76000, loss: 0.022077
 >> iter 77000, loss: 0.022539
 >> iter 78000, loss: 0.020388
 >> iter 79000, loss: 0.024940
 >> iter 80000, loss: 0.036957
   Number of active neurons: 2
 >> iter 81000, loss: 0.028545
 >> iter 82000, loss: 0.024233
 >> iter 83000, loss: 0.022761
 >> iter 84000, loss: 0.023197
 >> iter 85000, loss: 0.023393
 >> iter 86000, loss: 0.026269
 >> iter 87000, loss: 0.034706
 >> iter 88000, loss: 0.030315
 >> iter 89000, loss: 0.038106
 >> iter 90000, loss: 0.026257
   Number of active neurons: 2
 >> iter 91000, loss: 0.025175
 >> iter 92000, loss: 0.022518
 >> iter 93000, loss: 0.027521
 >> iter 94000, loss: 0.032737
 >> iter 95000, loss: 0.035998
 >> iter 96000, loss: 0.025700
 >> iter 97000, loss: 0.031089
 >> iter 98000, loss: 0.024144
 >> iter 99000, loss: 0.022643
 >> iter 100000, loss: 0.023661
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.984305
 >> iter 2000, loss: 4.097065
 >> iter 3000, loss: 1.547517
 >> iter 4000, loss: 0.597043
 >> iter 5000, loss: 0.243252
 >> iter 6000, loss: 0.111186
 >> iter 7000, loss: 0.060610
 >> iter 8000, loss: 0.049511
 >> iter 9000, loss: 0.045487
 >> iter 10000, loss: 0.035402
   Number of active neurons: 5
 >> iter 11000, loss: 0.042098
 >> iter 12000, loss: 0.042506
 >> iter 13000, loss: 0.036696
 >> iter 14000, loss: 0.042151
 >> iter 15000, loss: 0.033328
 >> iter 16000, loss: 0.033720
 >> iter 17000, loss: 0.029288
 >> iter 18000, loss: 0.027912
 >> iter 19000, loss: 0.029642
 >> iter 20000, loss: 0.028926
   Number of active neurons: 5
 >> iter 21000, loss: 0.030788
 >> iter 22000, loss: 0.028039
 >> iter 23000, loss: 0.027053
 >> iter 24000, loss: 0.028033
 >> iter 25000, loss: 0.028078
 >> iter 26000, loss: 0.026088
 >> iter 27000, loss: 0.029503
 >> iter 28000, loss: 0.043306
 >> iter 29000, loss: 0.044986
 >> iter 30000, loss: 0.043515
   Number of active neurons: 2
 >> iter 31000, loss: 0.034217
 >> iter 32000, loss: 0.029844
 >> iter 33000, loss: 0.026166
 >> iter 34000, loss: 0.027021
 >> iter 35000, loss: 0.022804
 >> iter 36000, loss: 0.022811
 >> iter 37000, loss: 0.022164
 >> iter 38000, loss: 0.022853
 >> iter 39000, loss: 0.021045
 >> iter 40000, loss: 0.020504
   Number of active neurons: 2
 >> iter 41000, loss: 0.022013
 >> iter 42000, loss: 0.021586
 >> iter 43000, loss: 0.022996
 >> iter 44000, loss: 0.023502
 >> iter 45000, loss: 0.029557
 >> iter 46000, loss: 0.024916
 >> iter 47000, loss: 0.022585
 >> iter 48000, loss: 0.045795
 >> iter 49000, loss: 0.036279
 >> iter 50000, loss: 0.026895
   Number of active neurons: 1
 >> iter 51000, loss: 0.030070
 >> iter 52000, loss: 0.026677
 >> iter 53000, loss: 0.034636
 >> iter 54000, loss: 0.025380
 >> iter 55000, loss: 0.025251
 >> iter 56000, loss: 0.022760
 >> iter 57000, loss: 0.026485
 >> iter 58000, loss: 0.021226
 >> iter 59000, loss: 0.018128
 >> iter 60000, loss: 0.018267
   Number of active neurons: 1
 >> iter 61000, loss: 0.018876
 >> iter 62000, loss: 0.019023
 >> iter 63000, loss: 0.029189
 >> iter 64000, loss: 0.024302
 >> iter 65000, loss: 0.018195
 >> iter 66000, loss: 0.017082
 >> iter 67000, loss: 0.019541
 >> iter 68000, loss: 0.026148
 >> iter 69000, loss: 0.020590
 >> iter 70000, loss: 0.018288
   Number of active neurons: 1
 >> iter 71000, loss: 0.020047
 >> iter 72000, loss: 0.020369
 >> iter 73000, loss: 0.017675
 >> iter 74000, loss: 0.030683
 >> iter 75000, loss: 0.022058
 >> iter 76000, loss: 0.020536
 >> iter 77000, loss: 0.032735
 >> iter 78000, loss: 0.023506
 >> iter 79000, loss: 0.019381
 >> iter 80000, loss: 0.030560
   Number of active neurons: 1
 >> iter 81000, loss: 0.027952
 >> iter 82000, loss: 0.020224
 >> iter 83000, loss: 0.019038
 >> iter 84000, loss: 0.016392
 >> iter 85000, loss: 0.020027
 >> iter 86000, loss: 0.019414
 >> iter 87000, loss: 0.016873
 >> iter 88000, loss: 0.017526
 >> iter 89000, loss: 0.029543
 >> iter 90000, loss: 0.031979
   Number of active neurons: 1
 >> iter 91000, loss: 0.022891
 >> iter 92000, loss: 0.019082
 >> iter 93000, loss: 0.020445
 >> iter 94000, loss: 0.019083
 >> iter 95000, loss: 0.018842
 >> iter 96000, loss: 0.018961
 >> iter 97000, loss: 0.018956
 >> iter 98000, loss: 0.025748
 >> iter 99000, loss: 0.020320
 >> iter 100000, loss: 0.021047
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.950190
 >> iter 2000, loss: 4.072610
 >> iter 3000, loss: 1.524415
 >> iter 4000, loss: 0.590318
 >> iter 5000, loss: 0.248023
 >> iter 6000, loss: 0.109926
 >> iter 7000, loss: 0.076804
 >> iter 8000, loss: 0.047425
 >> iter 9000, loss: 0.035014
 >> iter 10000, loss: 0.034390
   Number of active neurons: 5
 >> iter 11000, loss: 0.032371
 >> iter 12000, loss: 0.029266
 >> iter 13000, loss: 0.029391
 >> iter 14000, loss: 0.026922
 >> iter 15000, loss: 0.027771
 >> iter 16000, loss: 0.029945
 >> iter 17000, loss: 0.028460
 >> iter 18000, loss: 0.025578
 >> iter 19000, loss: 0.028077
 >> iter 20000, loss: 0.040780
   Number of active neurons: 3
 >> iter 21000, loss: 0.031359
 >> iter 22000, loss: 0.026763
 >> iter 23000, loss: 0.025506
 >> iter 24000, loss: 0.022880
 >> iter 25000, loss: 0.029451
 >> iter 26000, loss: 0.023792
 >> iter 27000, loss: 0.024943
 >> iter 28000, loss: 0.023937
 >> iter 29000, loss: 0.039615
 >> iter 30000, loss: 0.029950
   Number of active neurons: 3
 >> iter 31000, loss: 0.024653
 >> iter 32000, loss: 0.026804
 >> iter 33000, loss: 0.040435
 >> iter 34000, loss: 0.046793
 >> iter 35000, loss: 0.035305
 >> iter 36000, loss: 0.028545
 >> iter 37000, loss: 0.029109
 >> iter 38000, loss: 0.024157
 >> iter 39000, loss: 0.029587
 >> iter 40000, loss: 0.035379
   Number of active neurons: 3
 >> iter 41000, loss: 0.027288
 >> iter 42000, loss: 0.023614
 >> iter 43000, loss: 0.027720
 >> iter 44000, loss: 0.025890
 >> iter 45000, loss: 0.025672
 >> iter 46000, loss: 0.024756
 >> iter 47000, loss: 0.027572
 >> iter 48000, loss: 0.029352
 >> iter 49000, loss: 0.026060
 >> iter 50000, loss: 0.024028
   Number of active neurons: 3
 >> iter 51000, loss: 0.027731
 >> iter 52000, loss: 0.025742
 >> iter 53000, loss: 0.024085
 >> iter 54000, loss: 0.031706
 >> iter 55000, loss: 0.025694
 >> iter 56000, loss: 0.022893
 >> iter 57000, loss: 0.028639
 >> iter 58000, loss: 0.031985
 >> iter 59000, loss: 0.025176
 >> iter 60000, loss: 0.034419
   Number of active neurons: 2
 >> iter 61000, loss: 0.026030
 >> iter 62000, loss: 0.033440
 >> iter 63000, loss: 0.025398
 >> iter 64000, loss: 0.033136
 >> iter 65000, loss: 0.024471
 >> iter 66000, loss: 0.023297
 >> iter 67000, loss: 0.024564
 >> iter 68000, loss: 0.033340
 >> iter 69000, loss: 0.034931
 >> iter 70000, loss: 0.029150
   Number of active neurons: 2
 >> iter 71000, loss: 0.025752
 >> iter 72000, loss: 0.044891
 >> iter 73000, loss: 0.030062
 >> iter 74000, loss: 0.029455
 >> iter 75000, loss: 0.025618
 >> iter 76000, loss: 0.043269
 >> iter 77000, loss: 0.030720
 >> iter 78000, loss: 0.023967
 >> iter 79000, loss: 0.023923
 >> iter 80000, loss: 0.025604
   Number of active neurons: 2
 >> iter 81000, loss: 0.030028
 >> iter 82000, loss: 0.028034
 >> iter 83000, loss: 0.023885
 >> iter 84000, loss: 0.028607
 >> iter 85000, loss: 0.025391
 >> iter 86000, loss: 0.022072
 >> iter 87000, loss: 0.027631
 >> iter 88000, loss: 0.022982
 >> iter 89000, loss: 0.026133
 >> iter 90000, loss: 0.023093
   Number of active neurons: 2
 >> iter 91000, loss: 0.045107
 >> iter 92000, loss: 0.029361
 >> iter 93000, loss: 0.030604
 >> iter 94000, loss: 0.028303
 >> iter 95000, loss: 0.022614
 >> iter 96000, loss: 0.022272
 >> iter 97000, loss: 0.021736
 >> iter 98000, loss: 0.019677
 >> iter 99000, loss: 0.019081
 >> iter 100000, loss: 0.018716
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.993060
 >> iter 2000, loss: 4.096421
 >> iter 3000, loss: 1.539673
 >> iter 4000, loss: 0.594546
 >> iter 5000, loss: 0.248983
 >> iter 6000, loss: 0.114665
 >> iter 7000, loss: 0.066449
 >> iter 8000, loss: 0.047662
 >> iter 9000, loss: 0.042115
 >> iter 10000, loss: 0.037379
   Number of active neurons: 7
 >> iter 11000, loss: 0.041499
 >> iter 12000, loss: 0.041056
 >> iter 13000, loss: 0.034750
 >> iter 14000, loss: 0.032626
 >> iter 15000, loss: 0.032599
 >> iter 16000, loss: 0.038866
 >> iter 17000, loss: 0.035661
 >> iter 18000, loss: 0.040228
 >> iter 19000, loss: 0.033941
 >> iter 20000, loss: 0.031370
   Number of active neurons: 6
 >> iter 21000, loss: 0.032609
 >> iter 22000, loss: 0.034139
 >> iter 23000, loss: 0.030846
 >> iter 24000, loss: 0.030685
 >> iter 25000, loss: 0.052452
 >> iter 26000, loss: 0.036322
 >> iter 27000, loss: 0.028675
 >> iter 28000, loss: 0.024780
 >> iter 29000, loss: 0.027877
 >> iter 30000, loss: 0.030483
   Number of active neurons: 2
 >> iter 31000, loss: 0.025757
 >> iter 32000, loss: 0.027011
 >> iter 33000, loss: 0.025444
 >> iter 34000, loss: 0.023768
 >> iter 35000, loss: 0.036197
 >> iter 36000, loss: 0.025026
 >> iter 37000, loss: 0.029856
 >> iter 38000, loss: 0.030652
 >> iter 39000, loss: 0.027295
 >> iter 40000, loss: 0.033949
   Number of active neurons: 2
 >> iter 41000, loss: 0.026164
 >> iter 42000, loss: 0.032137
 >> iter 43000, loss: 0.044256
 >> iter 44000, loss: 0.028865
 >> iter 45000, loss: 0.024588
 >> iter 46000, loss: 0.022468
 >> iter 47000, loss: 0.021823
 >> iter 48000, loss: 0.023083
 >> iter 49000, loss: 0.026165
 >> iter 50000, loss: 0.028120
   Number of active neurons: 2
 >> iter 51000, loss: 0.022891
 >> iter 52000, loss: 0.026219
 >> iter 53000, loss: 0.027108
 >> iter 54000, loss: 0.025612
 >> iter 55000, loss: 0.038089
 >> iter 56000, loss: 0.026916
 >> iter 57000, loss: 0.023721
 >> iter 58000, loss: 0.025119
 >> iter 59000, loss: 0.022610
 >> iter 60000, loss: 0.034967
   Number of active neurons: 2
 >> iter 61000, loss: 0.026280
 >> iter 62000, loss: 0.021785
 >> iter 63000, loss: 0.035631
 >> iter 64000, loss: 0.044030
 >> iter 65000, loss: 0.029955
 >> iter 66000, loss: 0.026565
 >> iter 67000, loss: 0.034071
 >> iter 68000, loss: 0.032318
 >> iter 69000, loss: 0.046467
 >> iter 70000, loss: 0.032410
   Number of active neurons: 1
 >> iter 71000, loss: 0.032368
 >> iter 72000, loss: 0.031632
 >> iter 73000, loss: 0.024256
 >> iter 74000, loss: 0.022314
 >> iter 75000, loss: 0.028783
 >> iter 76000, loss: 0.034471
 >> iter 77000, loss: 0.038916
 >> iter 78000, loss: 0.024685
 >> iter 79000, loss: 0.020757
 >> iter 80000, loss: 0.025799
   Number of active neurons: 1
 >> iter 81000, loss: 0.019901
 >> iter 82000, loss: 0.020489
 >> iter 83000, loss: 0.020022
 >> iter 84000, loss: 0.018271
 >> iter 85000, loss: 0.035325
 >> iter 86000, loss: 0.024322
 >> iter 87000, loss: 0.022287
 >> iter 88000, loss: 0.019873
 >> iter 89000, loss: 0.017783
 >> iter 90000, loss: 0.016834
   Number of active neurons: 1
 >> iter 91000, loss: 0.016961
 >> iter 92000, loss: 0.025410
 >> iter 93000, loss: 0.020718
 >> iter 94000, loss: 0.018110
 >> iter 95000, loss: 0.027070
 >> iter 96000, loss: 0.035267
 >> iter 97000, loss: 0.023772
 >> iter 98000, loss: 0.034117
 >> iter 99000, loss: 0.031023
 >> iter 100000, loss: 0.022554
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.898989
 >> iter 2000, loss: 4.067968
 >> iter 3000, loss: 1.540146
 >> iter 4000, loss: 0.600189
 >> iter 5000, loss: 0.246921
 >> iter 6000, loss: 0.124372
 >> iter 7000, loss: 0.066816
 >> iter 8000, loss: 0.049671
 >> iter 9000, loss: 0.042076
 >> iter 10000, loss: 0.037674
   Number of active neurons: 5
 >> iter 11000, loss: 0.035039
 >> iter 12000, loss: 0.048028
 >> iter 13000, loss: 0.035720
 >> iter 14000, loss: 0.028732
 >> iter 15000, loss: 0.030404
 >> iter 16000, loss: 0.024916
 >> iter 17000, loss: 0.025158
 >> iter 18000, loss: 0.024669
 >> iter 19000, loss: 0.024087
 >> iter 20000, loss: 0.031351
   Number of active neurons: 2
 >> iter 21000, loss: 0.027254
 >> iter 22000, loss: 0.029521
 >> iter 23000, loss: 0.033901
 >> iter 24000, loss: 0.031835
 >> iter 25000, loss: 0.026169
 >> iter 26000, loss: 0.024301
 >> iter 27000, loss: 0.039722
 >> iter 28000, loss: 0.026582
 >> iter 29000, loss: 0.024052
 >> iter 30000, loss: 0.030657
   Number of active neurons: 2
 >> iter 31000, loss: 0.029603
 >> iter 32000, loss: 0.044102
 >> iter 33000, loss: 0.033026
 >> iter 34000, loss: 0.028470
 >> iter 35000, loss: 0.031911
 >> iter 36000, loss: 0.024407
 >> iter 37000, loss: 0.022500
 >> iter 38000, loss: 0.022189
 >> iter 39000, loss: 0.028772
 >> iter 40000, loss: 0.023086
   Number of active neurons: 2
 >> iter 41000, loss: 0.021082
 >> iter 42000, loss: 0.028373
 >> iter 43000, loss: 0.026763
 >> iter 44000, loss: 0.035251
 >> iter 45000, loss: 0.033588
 >> iter 46000, loss: 0.032093
 >> iter 47000, loss: 0.023055
 >> iter 48000, loss: 0.020787
 >> iter 49000, loss: 0.039313
 >> iter 50000, loss: 0.028219
   Number of active neurons: 1
 >> iter 51000, loss: 0.023567
 >> iter 52000, loss: 0.019234
 >> iter 53000, loss: 0.018690
 >> iter 54000, loss: 0.022141
 >> iter 55000, loss: 0.021119
 >> iter 56000, loss: 0.019150
 >> iter 57000, loss: 0.017716
 >> iter 58000, loss: 0.017752
 >> iter 59000, loss: 0.034731
 >> iter 60000, loss: 0.046700
   Number of active neurons: 1
 >> iter 61000, loss: 0.029413
 >> iter 62000, loss: 0.032785
 >> iter 63000, loss: 0.023256
 >> iter 64000, loss: 0.021916
 >> iter 65000, loss: 0.019787
 >> iter 66000, loss: 0.019769
 >> iter 67000, loss: 0.018677
 >> iter 68000, loss: 0.026873
 >> iter 69000, loss: 0.022172
 >> iter 70000, loss: 0.020350
   Number of active neurons: 1
 >> iter 71000, loss: 0.022515
 >> iter 72000, loss: 0.020477
 >> iter 73000, loss: 0.024617
 >> iter 74000, loss: 0.021980
 >> iter 75000, loss: 0.019044
 >> iter 76000, loss: 0.018345
 >> iter 77000, loss: 0.018733
 >> iter 78000, loss: 0.030192
 >> iter 79000, loss: 0.028718
 >> iter 80000, loss: 0.022858
   Number of active neurons: 1
 >> iter 81000, loss: 0.032245
 >> iter 82000, loss: 0.021754
 >> iter 83000, loss: 0.032470
 >> iter 84000, loss: 0.025193
 >> iter 85000, loss: 0.021141
 >> iter 86000, loss: 0.021304
 >> iter 87000, loss: 0.019613
 >> iter 88000, loss: 0.019322
 >> iter 89000, loss: 0.023101
 >> iter 90000, loss: 0.018092
   Number of active neurons: 1
 >> iter 91000, loss: 0.018788
 >> iter 92000, loss: 0.017584
 >> iter 93000, loss: 0.020971
 >> iter 94000, loss: 0.022365
 >> iter 95000, loss: 0.020805
 >> iter 96000, loss: 0.019439
 >> iter 97000, loss: 0.016265
 >> iter 98000, loss: 0.018535
 >> iter 99000, loss: 0.019464
 >> iter 100000, loss: 0.019336
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.024544
 >> iter 2000, loss: 4.103356
 >> iter 3000, loss: 1.546927
 >> iter 4000, loss: 0.596994
 >> iter 5000, loss: 0.246311
 >> iter 6000, loss: 0.117087
 >> iter 7000, loss: 0.068465
 >> iter 8000, loss: 0.051977
 >> iter 9000, loss: 0.040168
 >> iter 10000, loss: 0.038047
   Number of active neurons: 5
 >> iter 11000, loss: 0.038951
 >> iter 12000, loss: 0.034221
 >> iter 13000, loss: 0.030671
 >> iter 14000, loss: 0.030785
 >> iter 15000, loss: 0.029322
 >> iter 16000, loss: 0.028300
 >> iter 17000, loss: 0.028886
 >> iter 18000, loss: 0.044359
 >> iter 19000, loss: 0.035546
 >> iter 20000, loss: 0.046824
   Number of active neurons: 4
 >> iter 21000, loss: 0.034242
 >> iter 22000, loss: 0.027966
 >> iter 23000, loss: 0.029036
 >> iter 24000, loss: 0.031484
 >> iter 25000, loss: 0.027838
 >> iter 26000, loss: 0.026347
 >> iter 27000, loss: 0.025029
 >> iter 28000, loss: 0.023652
 >> iter 29000, loss: 0.026382
 >> iter 30000, loss: 0.029006
   Number of active neurons: 3
 >> iter 31000, loss: 0.026602
 >> iter 32000, loss: 0.034309
 >> iter 33000, loss: 0.029791
 >> iter 34000, loss: 0.025456
 >> iter 35000, loss: 0.024685
 >> iter 36000, loss: 0.025685
 >> iter 37000, loss: 0.023531
 >> iter 38000, loss: 0.036619
 >> iter 39000, loss: 0.043160
 >> iter 40000, loss: 0.034967
   Number of active neurons: 3
 >> iter 41000, loss: 0.035017
 >> iter 42000, loss: 0.034359
 >> iter 43000, loss: 0.028163
 >> iter 44000, loss: 0.034437
 >> iter 45000, loss: 0.027671
 >> iter 46000, loss: 0.037015
 >> iter 47000, loss: 0.032121
 >> iter 48000, loss: 0.026324
 >> iter 49000, loss: 0.025065
 >> iter 50000, loss: 0.024771
   Number of active neurons: 3
 >> iter 51000, loss: 0.024087
 >> iter 52000, loss: 0.023464
 >> iter 53000, loss: 0.022874
 >> iter 54000, loss: 0.038256
 >> iter 55000, loss: 0.028428
 >> iter 56000, loss: 0.025165
 >> iter 57000, loss: 0.023150
 >> iter 58000, loss: 0.022999
 >> iter 59000, loss: 0.031139
 >> iter 60000, loss: 0.026912
   Number of active neurons: 1
 >> iter 61000, loss: 0.024108
 >> iter 62000, loss: 0.020116
 >> iter 63000, loss: 0.021046
 >> iter 64000, loss: 0.037866
 >> iter 65000, loss: 0.026953
 >> iter 66000, loss: 0.045756
 >> iter 67000, loss: 0.033482
 >> iter 68000, loss: 0.029561
 >> iter 69000, loss: 0.029531
 >> iter 70000, loss: 0.027031
   Number of active neurons: 1
 >> iter 71000, loss: 0.019202
 >> iter 72000, loss: 0.017647
 >> iter 73000, loss: 0.018496
 >> iter 74000, loss: 0.016473
 >> iter 75000, loss: 0.028265
 >> iter 76000, loss: 0.023444
 >> iter 77000, loss: 0.031347
 >> iter 78000, loss: 0.021815
 >> iter 79000, loss: 0.018228
 >> iter 80000, loss: 0.017263
   Number of active neurons: 1
 >> iter 81000, loss: 0.018646
 >> iter 82000, loss: 0.017303
 >> iter 83000, loss: 0.019039
 >> iter 84000, loss: 0.031368
 >> iter 85000, loss: 0.024901
 >> iter 86000, loss: 0.021999
 >> iter 87000, loss: 0.022189
 >> iter 88000, loss: 0.030269
 >> iter 89000, loss: 0.022692
 >> iter 90000, loss: 0.018823
   Number of active neurons: 1
 >> iter 91000, loss: 0.024142
 >> iter 92000, loss: 0.024191
 >> iter 93000, loss: 0.019920
 >> iter 94000, loss: 0.030041
 >> iter 95000, loss: 0.022944
 >> iter 96000, loss: 0.018955
 >> iter 97000, loss: 0.018118
 >> iter 98000, loss: 0.018726
 >> iter 99000, loss: 0.018160
 >> iter 100000, loss: 0.017007
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.954112
 >> iter 2000, loss: 4.078587
 >> iter 3000, loss: 1.543116
 >> iter 4000, loss: 0.591599
 >> iter 5000, loss: 0.241319
 >> iter 6000, loss: 0.113778
 >> iter 7000, loss: 0.062106
 >> iter 8000, loss: 0.042864
 >> iter 9000, loss: 0.037292
 >> iter 10000, loss: 0.031540
   Number of active neurons: 5
 >> iter 11000, loss: 0.037331
 >> iter 12000, loss: 0.033523
 >> iter 13000, loss: 0.030672
 >> iter 14000, loss: 0.030624
 >> iter 15000, loss: 0.034678
 >> iter 16000, loss: 0.029309
 >> iter 17000, loss: 0.028991
 >> iter 18000, loss: 0.038883
 >> iter 19000, loss: 0.033544
 >> iter 20000, loss: 0.030853
   Number of active neurons: 5
 >> iter 21000, loss: 0.042388
 >> iter 22000, loss: 0.035350
 >> iter 23000, loss: 0.030394
 >> iter 24000, loss: 0.028672
 >> iter 25000, loss: 0.027151
 >> iter 26000, loss: 0.025658
 >> iter 27000, loss: 0.027961
 >> iter 28000, loss: 0.033019
 >> iter 29000, loss: 0.029548
 >> iter 30000, loss: 0.029746
   Number of active neurons: 4
 >> iter 31000, loss: 0.026128
 >> iter 32000, loss: 0.027438
 >> iter 33000, loss: 0.024281
 >> iter 34000, loss: 0.027303
 >> iter 35000, loss: 0.031151
 >> iter 36000, loss: 0.025588
 >> iter 37000, loss: 0.026992
 >> iter 38000, loss: 0.025437
 >> iter 39000, loss: 0.035314
 >> iter 40000, loss: 0.027162
   Number of active neurons: 3
 >> iter 41000, loss: 0.027010
 >> iter 42000, loss: 0.026362
 >> iter 43000, loss: 0.026574
 >> iter 44000, loss: 0.024339
 >> iter 45000, loss: 0.022216
 >> iter 46000, loss: 0.027455
 >> iter 47000, loss: 0.030519
 >> iter 48000, loss: 0.025550
 >> iter 49000, loss: 0.026980
 >> iter 50000, loss: 0.025242
   Number of active neurons: 3
 >> iter 51000, loss: 0.025149
 >> iter 52000, loss: 0.025148
 >> iter 53000, loss: 0.024257
 >> iter 54000, loss: 0.024408
 >> iter 55000, loss: 0.031558
 >> iter 56000, loss: 0.054548
 >> iter 57000, loss: 0.036661
 >> iter 58000, loss: 0.027579
 >> iter 59000, loss: 0.025450
 >> iter 60000, loss: 0.024186
   Number of active neurons: 3
 >> iter 61000, loss: 0.029416
 >> iter 62000, loss: 0.026087
 >> iter 63000, loss: 0.023111
 >> iter 64000, loss: 0.025363
 >> iter 65000, loss: 0.046819
 >> iter 66000, loss: 0.038160
 >> iter 67000, loss: 0.028777
 >> iter 68000, loss: 0.027105
 >> iter 69000, loss: 0.036663
 >> iter 70000, loss: 0.027182
   Number of active neurons: 3
 >> iter 71000, loss: 0.027892
 >> iter 72000, loss: 0.024152
 >> iter 73000, loss: 0.024802
 >> iter 74000, loss: 0.023117
 >> iter 75000, loss: 0.023833
 >> iter 76000, loss: 0.026091
 >> iter 77000, loss: 0.027089
 >> iter 78000, loss: 0.026297
 >> iter 79000, loss: 0.027484
 >> iter 80000, loss: 0.023395
   Number of active neurons: 3
 >> iter 81000, loss: 0.053953
 >> iter 82000, loss: 0.038016
 >> iter 83000, loss: 0.035818
 >> iter 84000, loss: 0.028565
 >> iter 85000, loss: 0.038139
 >> iter 86000, loss: 0.028080
 >> iter 87000, loss: 0.033467
 >> iter 88000, loss: 0.028797
 >> iter 89000, loss: 0.025370
 >> iter 90000, loss: 0.036808
   Number of active neurons: 3
 >> iter 91000, loss: 0.028085
 >> iter 92000, loss: 0.024543
 >> iter 93000, loss: 0.023070
 >> iter 94000, loss: 0.023035
 >> iter 95000, loss: 0.022827
 >> iter 96000, loss: 0.030782
 >> iter 97000, loss: 0.025575
 >> iter 98000, loss: 0.045147
 >> iter 99000, loss: 0.032581
 >> iter 100000, loss: 0.027245
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.973139
 >> iter 2000, loss: 4.090546
 >> iter 3000, loss: 1.540356
 >> iter 4000, loss: 0.604321
 >> iter 5000, loss: 0.246483
 >> iter 6000, loss: 0.112670
 >> iter 7000, loss: 0.063066
 >> iter 8000, loss: 0.042424
 >> iter 9000, loss: 0.036804
 >> iter 10000, loss: 0.035553
   Number of active neurons: 5
 >> iter 11000, loss: 0.037279
 >> iter 12000, loss: 0.038086
 >> iter 13000, loss: 0.032213
 >> iter 14000, loss: 0.030022
 >> iter 15000, loss: 0.030864
 >> iter 16000, loss: 0.028136
 >> iter 17000, loss: 0.029627
 >> iter 18000, loss: 0.027211
 >> iter 19000, loss: 0.027146
 >> iter 20000, loss: 0.025161
   Number of active neurons: 4
 >> iter 21000, loss: 0.032364
 >> iter 22000, loss: 0.027462
 >> iter 23000, loss: 0.027853
 >> iter 24000, loss: 0.029147
 >> iter 25000, loss: 0.030063
 >> iter 26000, loss: 0.026736
 >> iter 27000, loss: 0.033667
 >> iter 28000, loss: 0.030740
 >> iter 29000, loss: 0.028680
 >> iter 30000, loss: 0.025946
   Number of active neurons: 4
 >> iter 31000, loss: 0.029200
 >> iter 32000, loss: 0.026030
 >> iter 33000, loss: 0.026718
 >> iter 34000, loss: 0.023583
 >> iter 35000, loss: 0.024773
 >> iter 36000, loss: 0.035210
 >> iter 37000, loss: 0.037632
 >> iter 38000, loss: 0.028047
 >> iter 39000, loss: 0.039924
 >> iter 40000, loss: 0.031429
   Number of active neurons: 2
 >> iter 41000, loss: 0.035636
 >> iter 42000, loss: 0.028942
 >> iter 43000, loss: 0.027237
 >> iter 44000, loss: 0.028088
 >> iter 45000, loss: 0.025337
 >> iter 46000, loss: 0.031047
 >> iter 47000, loss: 0.025487
 >> iter 48000, loss: 0.028686
 >> iter 49000, loss: 0.033017
 >> iter 50000, loss: 0.028340
   Number of active neurons: 2
 >> iter 51000, loss: 0.024468
 >> iter 52000, loss: 0.021257
 >> iter 53000, loss: 0.023112
 >> iter 54000, loss: 0.024300
 >> iter 55000, loss: 0.030629
 >> iter 56000, loss: 0.035811
 >> iter 57000, loss: 0.032193
 >> iter 58000, loss: 0.024941
 >> iter 59000, loss: 0.027704
 >> iter 60000, loss: 0.023298
   Number of active neurons: 2
 >> iter 61000, loss: 0.033182
 >> iter 62000, loss: 0.028147
 >> iter 63000, loss: 0.028865
 >> iter 64000, loss: 0.028604
 >> iter 65000, loss: 0.026069
 >> iter 66000, loss: 0.021008
 >> iter 67000, loss: 0.030603
 >> iter 68000, loss: 0.023401
 >> iter 69000, loss: 0.027555
 >> iter 70000, loss: 0.021778
   Number of active neurons: 1
 >> iter 71000, loss: 0.025559
 >> iter 72000, loss: 0.028098
 >> iter 73000, loss: 0.022492
 >> iter 74000, loss: 0.020240
 >> iter 75000, loss: 0.021064
 >> iter 76000, loss: 0.022708
 >> iter 77000, loss: 0.025150
 >> iter 78000, loss: 0.020089
 >> iter 79000, loss: 0.020041
 >> iter 80000, loss: 0.017818
   Number of active neurons: 1
 >> iter 81000, loss: 0.016806
 >> iter 82000, loss: 0.017008
 >> iter 83000, loss: 0.017963
 >> iter 84000, loss: 0.022097
 >> iter 85000, loss: 0.022396
 >> iter 86000, loss: 0.017746
 >> iter 87000, loss: 0.025763
 >> iter 88000, loss: 0.020221
 >> iter 89000, loss: 0.019165
 >> iter 90000, loss: 0.020316
   Number of active neurons: 1
 >> iter 91000, loss: 0.021385
 >> iter 92000, loss: 0.018250
 >> iter 93000, loss: 0.018077
 >> iter 94000, loss: 0.017881
 >> iter 95000, loss: 0.023644
 >> iter 96000, loss: 0.018509
 >> iter 97000, loss: 0.016020
 >> iter 98000, loss: 0.017827
 >> iter 99000, loss: 0.018568
 >> iter 100000, loss: 0.015784
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.991711
 >> iter 2000, loss: 4.098918
 >> iter 3000, loss: 1.537614
 >> iter 4000, loss: 0.592168
 >> iter 5000, loss: 0.242067
 >> iter 6000, loss: 0.117646
 >> iter 7000, loss: 0.071333
 >> iter 8000, loss: 0.050046
 >> iter 9000, loss: 0.052871
 >> iter 10000, loss: 0.039703
   Number of active neurons: 5
 >> iter 11000, loss: 0.033481
 >> iter 12000, loss: 0.030376
 >> iter 13000, loss: 0.030649
 >> iter 14000, loss: 0.044647
 >> iter 15000, loss: 0.033874
 >> iter 16000, loss: 0.031099
 >> iter 17000, loss: 0.043830
 >> iter 18000, loss: 0.037485
 >> iter 19000, loss: 0.032621
 >> iter 20000, loss: 0.033288
   Number of active neurons: 3
 >> iter 21000, loss: 0.037833
 >> iter 22000, loss: 0.030957
 >> iter 23000, loss: 0.036952
 >> iter 24000, loss: 0.028262
 >> iter 25000, loss: 0.025552
 >> iter 26000, loss: 0.025072
 >> iter 27000, loss: 0.023379
 >> iter 28000, loss: 0.023896
 >> iter 29000, loss: 0.029082
 >> iter 30000, loss: 0.041563
   Number of active neurons: 3
 >> iter 31000, loss: 0.030721
 >> iter 32000, loss: 0.026825
 >> iter 33000, loss: 0.027103
 >> iter 34000, loss: 0.025015
 >> iter 35000, loss: 0.043895
 >> iter 36000, loss: 0.032591
 >> iter 37000, loss: 0.036007
 >> iter 38000, loss: 0.030258
 >> iter 39000, loss: 0.029505
 >> iter 40000, loss: 0.037890
   Number of active neurons: 1
 >> iter 41000, loss: 0.028455
 >> iter 42000, loss: 0.021800
 >> iter 43000, loss: 0.023748
 >> iter 44000, loss: 0.025960
 >> iter 45000, loss: 0.020639
 >> iter 46000, loss: 0.021313
 >> iter 47000, loss: 0.019243
 >> iter 48000, loss: 0.017708
 >> iter 49000, loss: 0.019903
 >> iter 50000, loss: 0.025733
   Number of active neurons: 1
 >> iter 51000, loss: 0.025066
 >> iter 52000, loss: 0.021962
 >> iter 53000, loss: 0.020388
 >> iter 54000, loss: 0.019261
 >> iter 55000, loss: 0.017762
 >> iter 56000, loss: 0.020950
 >> iter 57000, loss: 0.017547
 >> iter 58000, loss: 0.017539
 >> iter 59000, loss: 0.018173
 >> iter 60000, loss: 0.027036
   Number of active neurons: 1
 >> iter 61000, loss: 0.023436
 >> iter 62000, loss: 0.020225
 >> iter 63000, loss: 0.017696
 >> iter 64000, loss: 0.017136
 >> iter 65000, loss: 0.018757
 >> iter 66000, loss: 0.021001
 >> iter 67000, loss: 0.019541
 >> iter 68000, loss: 0.017257
 >> iter 69000, loss: 0.015922
 >> iter 70000, loss: 0.035116
   Number of active neurons: 1
 >> iter 71000, loss: 0.023596
 >> iter 72000, loss: 0.024152
 >> iter 73000, loss: 0.020304
 >> iter 74000, loss: 0.019944
 >> iter 75000, loss: 0.017981
 >> iter 76000, loss: 0.019348
 >> iter 77000, loss: 0.017946
 >> iter 78000, loss: 0.016815
 >> iter 79000, loss: 0.025363
 >> iter 80000, loss: 0.020185
   Number of active neurons: 1
 >> iter 81000, loss: 0.018012
 >> iter 82000, loss: 0.019986
 >> iter 83000, loss: 0.021451
 >> iter 84000, loss: 0.017996
 >> iter 85000, loss: 0.015944
 >> iter 86000, loss: 0.019588
 >> iter 87000, loss: 0.043404
 >> iter 88000, loss: 0.041788
 >> iter 89000, loss: 0.030521
 >> iter 90000, loss: 0.022095
   Number of active neurons: 1
 >> iter 91000, loss: 0.020075
 >> iter 92000, loss: 0.019050
 >> iter 93000, loss: 0.017309
 >> iter 94000, loss: 0.047318
 >> iter 95000, loss: 0.029290
 >> iter 96000, loss: 0.020023
 >> iter 97000, loss: 0.017943
 >> iter 98000, loss: 0.023681
 >> iter 99000, loss: 0.019844
 >> iter 100000, loss: 0.018888
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

