 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.7
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.048080
 >> iter 2000, loss: 10.736447
 >> iter 3000, loss: 4.774410
 >> iter 4000, loss: 2.044930
 >> iter 5000, loss: 0.846432
 >> iter 6000, loss: 0.625107
 >> iter 7000, loss: 0.270308
 >> iter 8000, loss: 0.159546
 >> iter 9000, loss: 0.186180
 >> iter 10000, loss: 0.086230
   Number of active neurons: 10
 >> iter 11000, loss: 0.099718
 >> iter 12000, loss: 0.098818
 >> iter 13000, loss: 0.073033
 >> iter 14000, loss: 0.092871
 >> iter 15000, loss: 0.041067
 >> iter 16000, loss: 0.022119
 >> iter 17000, loss: 0.026146
 >> iter 18000, loss: 0.053447
 >> iter 19000, loss: 0.029424
 >> iter 20000, loss: 0.051099
   Number of active neurons: 10
 >> iter 21000, loss: 0.118798
 >> iter 22000, loss: 0.051134
 >> iter 23000, loss: 0.060610
 >> iter 24000, loss: 0.025717
 >> iter 25000, loss: 0.013128
 >> iter 26000, loss: 0.083790
 >> iter 27000, loss: 0.034649
 >> iter 28000, loss: 0.018121
 >> iter 29000, loss: 0.009511
 >> iter 30000, loss: 0.050268
   Number of active neurons: 10
 >> iter 31000, loss: 0.046046
 >> iter 32000, loss: 0.052193
 >> iter 33000, loss: 0.041294
 >> iter 34000, loss: 0.069574
 >> iter 35000, loss: 0.029237
 >> iter 36000, loss: 0.058022
 >> iter 37000, loss: 0.030608
 >> iter 38000, loss: 0.015384
 >> iter 39000, loss: 0.010035
 >> iter 40000, loss: 0.005805
   Number of active neurons: 10
 >> iter 41000, loss: 0.113115
 >> iter 42000, loss: 0.044611
 >> iter 43000, loss: 0.018509
 >> iter 44000, loss: 0.010438
 >> iter 45000, loss: 0.039306
 >> iter 46000, loss: 0.017655
 >> iter 47000, loss: 0.032469
 >> iter 48000, loss: 0.013953
 >> iter 49000, loss: 0.006765
 >> iter 50000, loss: 0.004185
   Number of active neurons: 10
 >> iter 51000, loss: 0.006872
 >> iter 52000, loss: 0.032161
 >> iter 53000, loss: 0.020619
 >> iter 54000, loss: 0.018652
 >> iter 55000, loss: 0.010009
 >> iter 56000, loss: 0.005324
 >> iter 57000, loss: 0.003369
 >> iter 58000, loss: 0.002578
 >> iter 59000, loss: 0.002431
 >> iter 60000, loss: 0.002119
   Number of active neurons: 10
 >> iter 61000, loss: 0.071177
 >> iter 62000, loss: 0.027667
 >> iter 63000, loss: 0.011382
 >> iter 64000, loss: 0.019168
 >> iter 65000, loss: 0.008128
 >> iter 66000, loss: 0.004024
 >> iter 67000, loss: 0.002893
 >> iter 68000, loss: 0.002021
 >> iter 69000, loss: 0.001744
 >> iter 70000, loss: 0.001541
   Number of active neurons: 10
 >> iter 71000, loss: 0.001542
 >> iter 72000, loss: 0.001433
 >> iter 73000, loss: 0.001294
 >> iter 74000, loss: 0.001243
 >> iter 75000, loss: 0.001440
 >> iter 76000, loss: 0.063138
 >> iter 77000, loss: 0.025058
 >> iter 78000, loss: 0.010228
 >> iter 79000, loss: 0.004744
 >> iter 80000, loss: 0.002737
   Number of active neurons: 10
 >> iter 81000, loss: 0.001839
 >> iter 82000, loss: 0.045672
 >> iter 83000, loss: 0.018641
 >> iter 84000, loss: 0.008026
 >> iter 85000, loss: 0.003851
 >> iter 86000, loss: 0.002796
 >> iter 87000, loss: 0.005341
 >> iter 88000, loss: 0.028429
 >> iter 89000, loss: 0.011358
 >> iter 90000, loss: 0.005034
   Number of active neurons: 10
 >> iter 91000, loss: 0.002709
 >> iter 92000, loss: 0.001803
 >> iter 93000, loss: 0.050397
 >> iter 94000, loss: 0.022014
 >> iter 95000, loss: 0.016901
 >> iter 96000, loss: 0.041000
 >> iter 97000, loss: 0.064508
 >> iter 98000, loss: 0.025277
 >> iter 99000, loss: 0.010556
 >> iter 100000, loss: 0.004940
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.747026
 >> iter 2000, loss: 10.484762
 >> iter 3000, loss: 4.777841
 >> iter 4000, loss: 2.253219
 >> iter 5000, loss: 1.134594
 >> iter 6000, loss: 0.632085
 >> iter 7000, loss: 0.301725
 >> iter 8000, loss: 0.183117
 >> iter 9000, loss: 0.281810
 >> iter 10000, loss: 0.149436
   Number of active neurons: 10
 >> iter 11000, loss: 0.103553
 >> iter 12000, loss: 0.089460
 >> iter 13000, loss: 0.092613
 >> iter 14000, loss: 0.054413
 >> iter 15000, loss: 0.027084
 >> iter 16000, loss: 0.020799
 >> iter 17000, loss: 0.045843
 >> iter 18000, loss: 0.132382
 >> iter 19000, loss: 0.095704
 >> iter 20000, loss: 0.111527
   Number of active neurons: 10
 >> iter 21000, loss: 0.050194
 >> iter 22000, loss: 0.024946
 >> iter 23000, loss: 0.074009
 >> iter 24000, loss: 0.060974
 >> iter 25000, loss: 0.051751
 >> iter 26000, loss: 0.022558
 >> iter 27000, loss: 0.011669
 >> iter 28000, loss: 0.010277
 >> iter 29000, loss: 0.167658
 >> iter 30000, loss: 0.126193
   Number of active neurons: 10
 >> iter 31000, loss: 0.069624
 >> iter 32000, loss: 0.074525
 >> iter 33000, loss: 0.032118
 >> iter 34000, loss: 0.082006
 >> iter 35000, loss: 0.084159
 >> iter 36000, loss: 0.035490
 >> iter 37000, loss: 0.016168
 >> iter 38000, loss: 0.009823
 >> iter 39000, loss: 0.007521
 >> iter 40000, loss: 0.005601
   Number of active neurons: 10
 >> iter 41000, loss: 0.004287
 >> iter 42000, loss: 0.003808
 >> iter 43000, loss: 0.009770
 >> iter 44000, loss: 0.023684
 >> iter 45000, loss: 0.019503
 >> iter 46000, loss: 0.009991
 >> iter 47000, loss: 0.005663
 >> iter 48000, loss: 0.042046
 >> iter 49000, loss: 0.030786
 >> iter 50000, loss: 0.019645
   Number of active neurons: 10
 >> iter 51000, loss: 0.009220
 >> iter 52000, loss: 0.004926
 >> iter 53000, loss: 0.005134
 >> iter 54000, loss: 0.003674
 >> iter 55000, loss: 0.003645
 >> iter 56000, loss: 0.002638
 >> iter 57000, loss: 0.002866
 >> iter 58000, loss: 0.024525
 >> iter 59000, loss: 0.261188
 >> iter 60000, loss: 0.153500
   Number of active neurons: 10
 >> iter 61000, loss: 0.059663
 >> iter 62000, loss: 0.023898
 >> iter 63000, loss: 0.010741
 >> iter 64000, loss: 0.022236
 >> iter 65000, loss: 0.039399
 >> iter 66000, loss: 0.027858
 >> iter 67000, loss: 0.077611
 >> iter 68000, loss: 0.149642
 >> iter 69000, loss: 0.059195
 >> iter 70000, loss: 0.041441
   Number of active neurons: 10
 >> iter 71000, loss: 0.017143
 >> iter 72000, loss: 0.051868
 >> iter 73000, loss: 0.021339
 >> iter 74000, loss: 0.009532
 >> iter 75000, loss: 0.022340
 >> iter 76000, loss: 0.035650
 >> iter 77000, loss: 0.014648
 >> iter 78000, loss: 0.011491
 >> iter 79000, loss: 0.006694
 >> iter 80000, loss: 0.050565
   Number of active neurons: 10
 >> iter 81000, loss: 0.021393
 >> iter 82000, loss: 0.009255
 >> iter 83000, loss: 0.004608
 >> iter 84000, loss: 0.028439
 >> iter 85000, loss: 0.012002
 >> iter 86000, loss: 0.005750
 >> iter 87000, loss: 0.009347
 >> iter 88000, loss: 0.016659
 >> iter 89000, loss: 0.007620
 >> iter 90000, loss: 0.004145
   Number of active neurons: 10
 >> iter 91000, loss: 0.002919
 >> iter 92000, loss: 0.006236
 >> iter 93000, loss: 0.013081
 >> iter 94000, loss: 0.005885
 >> iter 95000, loss: 0.003312
 >> iter 96000, loss: 0.003099
 >> iter 97000, loss: 0.021033
 >> iter 98000, loss: 0.009083
 >> iter 99000, loss: 0.014627
 >> iter 100000, loss: 0.104534
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.006551
 >> iter 2000, loss: 10.556797
 >> iter 3000, loss: 4.573086
 >> iter 4000, loss: 2.096316
 >> iter 5000, loss: 0.997491
 >> iter 6000, loss: 0.449312
 >> iter 7000, loss: 0.225903
 >> iter 8000, loss: 0.187771
 >> iter 9000, loss: 0.094624
 >> iter 10000, loss: 0.093922
   Number of active neurons: 10
 >> iter 11000, loss: 0.061623
 >> iter 12000, loss: 0.030937
 >> iter 13000, loss: 0.110771
 >> iter 14000, loss: 0.058692
 >> iter 15000, loss: 0.027565
 >> iter 16000, loss: 0.024572
 >> iter 17000, loss: 0.015172
 >> iter 18000, loss: 0.018982
 >> iter 19000, loss: 0.133784
 >> iter 20000, loss: 0.088020
   Number of active neurons: 10
 >> iter 21000, loss: 0.059077
 >> iter 22000, loss: 0.041954
 >> iter 23000, loss: 0.067143
 >> iter 24000, loss: 0.034301
 >> iter 25000, loss: 0.102235
 >> iter 26000, loss: 0.062952
 >> iter 27000, loss: 0.100853
 >> iter 28000, loss: 0.042020
 >> iter 29000, loss: 0.145713
 >> iter 30000, loss: 0.058055
   Number of active neurons: 10
 >> iter 31000, loss: 0.025034
 >> iter 32000, loss: 0.012311
 >> iter 33000, loss: 0.009333
 >> iter 34000, loss: 0.006848
 >> iter 35000, loss: 0.006145
 >> iter 36000, loss: 0.004875
 >> iter 37000, loss: 0.003751
 >> iter 38000, loss: 0.003378
 >> iter 39000, loss: 0.015700
 >> iter 40000, loss: 0.010869
   Number of active neurons: 10
 >> iter 41000, loss: 0.006009
 >> iter 42000, loss: 0.004629
 >> iter 43000, loss: 0.003573
 >> iter 44000, loss: 0.013542
 >> iter 45000, loss: 0.045355
 >> iter 46000, loss: 0.018735
 >> iter 47000, loss: 0.009859
 >> iter 48000, loss: 0.012155
 >> iter 49000, loss: 0.007118
 >> iter 50000, loss: 0.005964
   Number of active neurons: 10
 >> iter 51000, loss: 0.005583
 >> iter 52000, loss: 0.009407
 >> iter 53000, loss: 0.005289
 >> iter 54000, loss: 0.024085
 >> iter 55000, loss: 0.021878
 >> iter 56000, loss: 0.012650
 >> iter 57000, loss: 0.005939
 >> iter 58000, loss: 0.003431
 >> iter 59000, loss: 0.002452
 >> iter 60000, loss: 0.003946
   Number of active neurons: 10
 >> iter 61000, loss: 0.014008
 >> iter 62000, loss: 0.006853
 >> iter 63000, loss: 0.003914
 >> iter 64000, loss: 0.002501
 >> iter 65000, loss: 0.002029
 >> iter 66000, loss: 0.001779
 >> iter 67000, loss: 0.001646
 >> iter 68000, loss: 0.006497
 >> iter 69000, loss: 0.003339
 >> iter 70000, loss: 0.008547
   Number of active neurons: 10
 >> iter 71000, loss: 0.004653
 >> iter 72000, loss: 0.040995
 >> iter 73000, loss: 0.017431
 >> iter 74000, loss: 0.008883
 >> iter 75000, loss: 0.004638
 >> iter 76000, loss: 0.047703
 >> iter 77000, loss: 0.018920
 >> iter 78000, loss: 0.008150
 >> iter 79000, loss: 0.004117
 >> iter 80000, loss: 0.002611
   Number of active neurons: 10
 >> iter 81000, loss: 0.001911
 >> iter 82000, loss: 0.001811
 >> iter 83000, loss: 0.001644
 >> iter 84000, loss: 0.003252
 >> iter 85000, loss: 0.002248
 >> iter 86000, loss: 0.014177
 >> iter 87000, loss: 0.009153
 >> iter 88000, loss: 0.005435
 >> iter 89000, loss: 0.071931
 >> iter 90000, loss: 0.060312
   Number of active neurons: 10
 >> iter 91000, loss: 0.023331
 >> iter 92000, loss: 0.019963
 >> iter 93000, loss: 0.008554
 >> iter 94000, loss: 0.004050
 >> iter 95000, loss: 0.032805
 >> iter 96000, loss: 0.013156
 >> iter 97000, loss: 0.005949
 >> iter 98000, loss: 0.003275
 >> iter 99000, loss: 0.004806
 >> iter 100000, loss: 0.002635
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.008817
 >> iter 2000, loss: 10.911001
 >> iter 3000, loss: 4.555346
 >> iter 4000, loss: 1.929619
 >> iter 5000, loss: 0.919568
 >> iter 6000, loss: 0.399603
 >> iter 7000, loss: 0.256680
 >> iter 8000, loss: 0.163400
 >> iter 9000, loss: 0.097467
 >> iter 10000, loss: 0.069840
   Number of active neurons: 10
 >> iter 11000, loss: 0.119086
 >> iter 12000, loss: 0.093674
 >> iter 13000, loss: 0.064059
 >> iter 14000, loss: 0.082796
 >> iter 15000, loss: 0.036506
 >> iter 16000, loss: 0.024611
 >> iter 17000, loss: 0.079559
 >> iter 18000, loss: 0.053642
 >> iter 19000, loss: 0.091751
 >> iter 20000, loss: 0.038020
   Number of active neurons: 10
 >> iter 21000, loss: 0.018512
 >> iter 22000, loss: 0.009994
 >> iter 23000, loss: 0.006598
 >> iter 24000, loss: 0.005102
 >> iter 25000, loss: 0.004526
 >> iter 26000, loss: 0.003783
 >> iter 27000, loss: 0.003428
 >> iter 28000, loss: 0.004786
 >> iter 29000, loss: 0.003753
 >> iter 30000, loss: 0.042326
   Number of active neurons: 10
 >> iter 31000, loss: 0.018534
 >> iter 32000, loss: 0.008759
 >> iter 33000, loss: 0.024316
 >> iter 34000, loss: 0.018948
 >> iter 35000, loss: 0.008771
 >> iter 36000, loss: 0.005639
 >> iter 37000, loss: 0.004679
 >> iter 38000, loss: 0.003611
 >> iter 39000, loss: 0.003247
 >> iter 40000, loss: 0.003216
   Number of active neurons: 10
 >> iter 41000, loss: 0.003923
 >> iter 42000, loss: 0.015883
 >> iter 43000, loss: 0.009001
 >> iter 44000, loss: 0.004588
 >> iter 45000, loss: 0.002804
 >> iter 46000, loss: 0.002056
 >> iter 47000, loss: 0.002126
 >> iter 48000, loss: 0.184401
 >> iter 49000, loss: 0.069464
 >> iter 50000, loss: 0.029032
   Number of active neurons: 10
 >> iter 51000, loss: 0.059989
 >> iter 52000, loss: 0.056938
 >> iter 53000, loss: 0.022664
 >> iter 54000, loss: 0.009773
 >> iter 55000, loss: 0.006950
 >> iter 56000, loss: 0.005919
 >> iter 57000, loss: 0.003775
 >> iter 58000, loss: 0.002577
 >> iter 59000, loss: 0.002304
 >> iter 60000, loss: 0.001878
   Number of active neurons: 10
 >> iter 61000, loss: 0.002165
 >> iter 62000, loss: 0.010205
 >> iter 63000, loss: 0.004739
 >> iter 64000, loss: 0.102497
 >> iter 65000, loss: 0.039288
 >> iter 66000, loss: 0.015916
 >> iter 67000, loss: 0.007217
 >> iter 68000, loss: 0.003767
 >> iter 69000, loss: 0.002485
 >> iter 70000, loss: 0.003366
   Number of active neurons: 10
 >> iter 71000, loss: 0.002301
 >> iter 72000, loss: 0.003409
 >> iter 73000, loss: 0.002932
 >> iter 74000, loss: 0.002081
 >> iter 75000, loss: 0.001687
 >> iter 76000, loss: 0.001498
 >> iter 77000, loss: 0.001442
 >> iter 78000, loss: 0.027858
 >> iter 79000, loss: 0.011314
 >> iter 80000, loss: 0.004969
   Number of active neurons: 10
 >> iter 81000, loss: 0.095475
 >> iter 82000, loss: 0.036154
 >> iter 83000, loss: 0.014257
 >> iter 84000, loss: 0.006115
 >> iter 85000, loss: 0.043162
 >> iter 86000, loss: 0.016906
 >> iter 87000, loss: 0.007191
 >> iter 88000, loss: 0.006166
 >> iter 89000, loss: 0.003526
 >> iter 90000, loss: 0.002231
   Number of active neurons: 10
 >> iter 91000, loss: 0.057040
 >> iter 92000, loss: 0.022557
 >> iter 93000, loss: 0.009266
 >> iter 94000, loss: 0.004389
 >> iter 95000, loss: 0.002500
 >> iter 96000, loss: 0.001751
 >> iter 97000, loss: 0.032790
 >> iter 98000, loss: 0.013070
 >> iter 99000, loss: 0.077964
 >> iter 100000, loss: 0.029792
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.992059
 >> iter 2000, loss: 10.867289
 >> iter 3000, loss: 4.862219
 >> iter 4000, loss: 2.151839
 >> iter 5000, loss: 1.029587
 >> iter 6000, loss: 0.632029
 >> iter 7000, loss: 0.291175
 >> iter 8000, loss: 0.171648
 >> iter 9000, loss: 0.079960
 >> iter 10000, loss: 0.120175
   Number of active neurons: 10
 >> iter 11000, loss: 0.161557
 >> iter 12000, loss: 0.096370
 >> iter 13000, loss: 0.059985
 >> iter 14000, loss: 0.154026
 >> iter 15000, loss: 0.078138
 >> iter 16000, loss: 0.035276
 >> iter 17000, loss: 0.043077
 >> iter 18000, loss: 0.040040
 >> iter 19000, loss: 0.090020
 >> iter 20000, loss: 0.057984
   Number of active neurons: 10
 >> iter 21000, loss: 0.027280
 >> iter 22000, loss: 0.014222
 >> iter 23000, loss: 0.013073
 >> iter 24000, loss: 0.010760
 >> iter 25000, loss: 0.006956
 >> iter 26000, loss: 0.011281
 >> iter 27000, loss: 0.016635
 >> iter 28000, loss: 0.129565
 >> iter 29000, loss: 0.058298
 >> iter 30000, loss: 0.072233
   Number of active neurons: 10
 >> iter 31000, loss: 0.033597
 >> iter 32000, loss: 0.018204
 >> iter 33000, loss: 0.010045
 >> iter 34000, loss: 0.006334
 >> iter 35000, loss: 0.101822
 >> iter 36000, loss: 0.041374
 >> iter 37000, loss: 0.050197
 >> iter 38000, loss: 0.021420
 >> iter 39000, loss: 0.010405
 >> iter 40000, loss: 0.039399
   Number of active neurons: 10
 >> iter 41000, loss: 0.017233
 >> iter 42000, loss: 0.081913
 >> iter 43000, loss: 0.033215
 >> iter 44000, loss: 0.014759
 >> iter 45000, loss: 0.017485
 >> iter 46000, loss: 0.109462
 >> iter 47000, loss: 0.043296
 >> iter 48000, loss: 0.036469
 >> iter 49000, loss: 0.015507
 >> iter 50000, loss: 0.007809
   Number of active neurons: 10
 >> iter 51000, loss: 0.004486
 >> iter 52000, loss: 0.003320
 >> iter 53000, loss: 0.003859
 >> iter 54000, loss: 0.003905
 >> iter 55000, loss: 0.044008
 >> iter 56000, loss: 0.017813
 >> iter 57000, loss: 0.007985
 >> iter 58000, loss: 0.004314
 >> iter 59000, loss: 0.016162
 >> iter 60000, loss: 0.007539
   Number of active neurons: 10
 >> iter 61000, loss: 0.004211
 >> iter 62000, loss: 0.024443
 >> iter 63000, loss: 0.012289
 >> iter 64000, loss: 0.005795
 >> iter 65000, loss: 0.003391
 >> iter 66000, loss: 0.002314
 >> iter 67000, loss: 0.062646
 >> iter 68000, loss: 0.024745
 >> iter 69000, loss: 0.010506
 >> iter 70000, loss: 0.005608
   Number of active neurons: 10
 >> iter 71000, loss: 0.003331
 >> iter 72000, loss: 0.002274
 >> iter 73000, loss: 0.001779
 >> iter 74000, loss: 0.001666
 >> iter 75000, loss: 0.001716
 >> iter 76000, loss: 0.001654
 >> iter 77000, loss: 0.082349
 >> iter 78000, loss: 0.031486
 >> iter 79000, loss: 0.013909
 >> iter 80000, loss: 0.008769
   Number of active neurons: 10
 >> iter 81000, loss: 0.004966
 >> iter 82000, loss: 0.002852
 >> iter 83000, loss: 0.002277
 >> iter 84000, loss: 0.001731
 >> iter 85000, loss: 0.001472
 >> iter 86000, loss: 0.001351
 >> iter 87000, loss: 0.001320
 >> iter 88000, loss: 0.024661
 >> iter 89000, loss: 0.010185
 >> iter 90000, loss: 0.004662
   Number of active neurons: 10
 >> iter 91000, loss: 0.002773
 >> iter 92000, loss: 0.001869
 >> iter 93000, loss: 0.001612
 >> iter 94000, loss: 0.001376
 >> iter 95000, loss: 0.001512
 >> iter 96000, loss: 0.001290
 >> iter 97000, loss: 0.001197
 >> iter 98000, loss: 0.001174
 >> iter 99000, loss: 0.001111
 >> iter 100000, loss: 0.001084
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.836243
 >> iter 2000, loss: 10.205600
 >> iter 3000, loss: 4.652275
 >> iter 4000, loss: 1.843326
 >> iter 5000, loss: 1.010318
 >> iter 6000, loss: 0.677889
 >> iter 7000, loss: 0.317333
 >> iter 8000, loss: 0.306522
 >> iter 9000, loss: 0.140104
 >> iter 10000, loss: 0.083558
   Number of active neurons: 10
 >> iter 11000, loss: 0.048953
 >> iter 12000, loss: 0.027082
 >> iter 13000, loss: 0.081927
 >> iter 14000, loss: 0.192169
 >> iter 15000, loss: 0.087466
 >> iter 16000, loss: 0.043295
 >> iter 17000, loss: 0.041794
 >> iter 18000, loss: 0.020397
 >> iter 19000, loss: 0.025344
 >> iter 20000, loss: 0.053026
   Number of active neurons: 10
 >> iter 21000, loss: 0.236213
 >> iter 22000, loss: 0.165312
 >> iter 23000, loss: 0.072693
 >> iter 24000, loss: 0.063822
 >> iter 25000, loss: 0.101474
 >> iter 26000, loss: 0.118845
 >> iter 27000, loss: 0.056609
 >> iter 28000, loss: 0.038988
 >> iter 29000, loss: 0.018472
 >> iter 30000, loss: 0.012519
   Number of active neurons: 10
 >> iter 31000, loss: 0.049151
 >> iter 32000, loss: 0.026901
 >> iter 33000, loss: 0.028616
 >> iter 34000, loss: 0.015225
 >> iter 35000, loss: 0.033117
 >> iter 36000, loss: 0.039409
 >> iter 37000, loss: 0.246867
 >> iter 38000, loss: 0.096395
 >> iter 39000, loss: 0.039229
 >> iter 40000, loss: 0.017308
   Number of active neurons: 10
 >> iter 41000, loss: 0.009155
 >> iter 42000, loss: 0.024377
 >> iter 43000, loss: 0.062253
 >> iter 44000, loss: 0.045524
 >> iter 45000, loss: 0.020460
 >> iter 46000, loss: 0.069423
 >> iter 47000, loss: 0.028988
 >> iter 48000, loss: 0.023176
 >> iter 49000, loss: 0.010793
 >> iter 50000, loss: 0.005998
   Number of active neurons: 10
 >> iter 51000, loss: 0.044667
 >> iter 52000, loss: 0.018623
 >> iter 53000, loss: 0.008801
 >> iter 54000, loss: 0.054106
 >> iter 55000, loss: 0.022012
 >> iter 56000, loss: 0.009860
 >> iter 57000, loss: 0.028870
 >> iter 58000, loss: 0.021354
 >> iter 59000, loss: 0.049566
 >> iter 60000, loss: 0.021145
   Number of active neurons: 10
 >> iter 61000, loss: 0.010604
 >> iter 62000, loss: 0.005553
 >> iter 63000, loss: 0.064405
 >> iter 64000, loss: 0.025839
 >> iter 65000, loss: 0.014216
 >> iter 66000, loss: 0.007730
 >> iter 67000, loss: 0.159012
 >> iter 68000, loss: 0.061979
 >> iter 69000, loss: 0.055542
 >> iter 70000, loss: 0.025172
   Number of active neurons: 10
 >> iter 71000, loss: 0.011098
 >> iter 72000, loss: 0.006349
 >> iter 73000, loss: 0.004443
 >> iter 74000, loss: 0.003170
 >> iter 75000, loss: 0.016270
 >> iter 76000, loss: 0.007972
 >> iter 77000, loss: 0.018296
 >> iter 78000, loss: 0.008358
 >> iter 79000, loss: 0.004384
 >> iter 80000, loss: 0.002951
   Number of active neurons: 10
 >> iter 81000, loss: 0.002150
 >> iter 82000, loss: 0.001821
 >> iter 83000, loss: 0.001885
 >> iter 84000, loss: 0.001951
 >> iter 85000, loss: 0.001715
 >> iter 86000, loss: 0.003541
 >> iter 87000, loss: 0.002322
 >> iter 88000, loss: 0.001726
 >> iter 89000, loss: 0.001391
 >> iter 90000, loss: 0.001341
   Number of active neurons: 10
 >> iter 91000, loss: 0.043187
 >> iter 92000, loss: 0.017158
 >> iter 93000, loss: 0.007275
 >> iter 94000, loss: 0.003638
 >> iter 95000, loss: 0.002202
 >> iter 96000, loss: 0.001655
 >> iter 97000, loss: 0.001356
 >> iter 98000, loss: 0.001353
 >> iter 99000, loss: 0.001432
 >> iter 100000, loss: 0.001259
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.130201
 >> iter 2000, loss: 11.066826
 >> iter 3000, loss: 4.831871
 >> iter 4000, loss: 2.243502
 >> iter 5000, loss: 0.948622
 >> iter 6000, loss: 0.526484
 >> iter 7000, loss: 0.327557
 >> iter 8000, loss: 0.139208
 >> iter 9000, loss: 0.066912
 >> iter 10000, loss: 0.213264
   Number of active neurons: 10
 >> iter 11000, loss: 0.093416
 >> iter 12000, loss: 0.043722
 >> iter 13000, loss: 0.023372
 >> iter 14000, loss: 0.014092
 >> iter 15000, loss: 0.010940
 >> iter 16000, loss: 0.019889
 >> iter 17000, loss: 0.215939
 >> iter 18000, loss: 0.126366
 >> iter 19000, loss: 0.060063
 >> iter 20000, loss: 0.051123
   Number of active neurons: 10
 >> iter 21000, loss: 0.104684
 >> iter 22000, loss: 0.125246
 >> iter 23000, loss: 0.057390
 >> iter 24000, loss: 0.025710
 >> iter 25000, loss: 0.017700
 >> iter 26000, loss: 0.126580
 >> iter 27000, loss: 0.050628
 >> iter 28000, loss: 0.105043
 >> iter 29000, loss: 0.043590
 >> iter 30000, loss: 0.020096
   Number of active neurons: 10
 >> iter 31000, loss: 0.010723
 >> iter 32000, loss: 0.007703
 >> iter 33000, loss: 0.005476
 >> iter 34000, loss: 0.085366
 >> iter 35000, loss: 0.038027
 >> iter 36000, loss: 0.016652
 >> iter 37000, loss: 0.008739
 >> iter 38000, loss: 0.005528
 >> iter 39000, loss: 0.056950
 >> iter 40000, loss: 0.023526
   Number of active neurons: 10
 >> iter 41000, loss: 0.040963
 >> iter 42000, loss: 0.018410
 >> iter 43000, loss: 0.013910
 >> iter 44000, loss: 0.007550
 >> iter 45000, loss: 0.004563
 >> iter 46000, loss: 0.003296
 >> iter 47000, loss: 0.002747
 >> iter 48000, loss: 0.038947
 >> iter 49000, loss: 0.016164
 >> iter 50000, loss: 0.007500
   Number of active neurons: 10
 >> iter 51000, loss: 0.004335
 >> iter 52000, loss: 0.003137
 >> iter 53000, loss: 0.003874
 >> iter 54000, loss: 0.024486
 >> iter 55000, loss: 0.010587
 >> iter 56000, loss: 0.005912
 >> iter 57000, loss: 0.003540
 >> iter 58000, loss: 0.003419
 >> iter 59000, loss: 0.003740
 >> iter 60000, loss: 0.003910
   Number of active neurons: 10
 >> iter 61000, loss: 0.002533
 >> iter 62000, loss: 0.002493
 >> iter 63000, loss: 0.003264
 >> iter 64000, loss: 0.002350
 >> iter 65000, loss: 0.001846
 >> iter 66000, loss: 0.001758
 >> iter 67000, loss: 0.001969
 >> iter 68000, loss: 0.001600
 >> iter 69000, loss: 0.001525
 >> iter 70000, loss: 0.001402
   Number of active neurons: 10
 >> iter 71000, loss: 0.001354
 >> iter 72000, loss: 0.001278
 >> iter 73000, loss: 0.001272
 >> iter 74000, loss: 0.001194
 >> iter 75000, loss: 0.001240
 >> iter 76000, loss: 0.012441
 >> iter 77000, loss: 0.007857
 >> iter 78000, loss: 0.003756
 >> iter 79000, loss: 0.002303
 >> iter 80000, loss: 0.001827
   Number of active neurons: 10
 >> iter 81000, loss: 0.001424
 >> iter 82000, loss: 0.001632
 >> iter 83000, loss: 0.001488
 >> iter 84000, loss: 0.001268
 >> iter 85000, loss: 0.003822
 >> iter 86000, loss: 0.005475
 >> iter 87000, loss: 0.002816
 >> iter 88000, loss: 0.007809
 >> iter 89000, loss: 0.043143
 >> iter 90000, loss: 0.018221
   Number of active neurons: 10
 >> iter 91000, loss: 0.059683
 >> iter 92000, loss: 0.023744
 >> iter 93000, loss: 0.097220
 >> iter 94000, loss: 0.037589
 >> iter 95000, loss: 0.015287
 >> iter 96000, loss: 0.006843
 >> iter 97000, loss: 0.003625
 >> iter 98000, loss: 0.002284
 >> iter 99000, loss: 0.001762
 >> iter 100000, loss: 0.001549
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.318758
 >> iter 2000, loss: 10.864978
 >> iter 3000, loss: 4.641961
 >> iter 4000, loss: 1.981773
 >> iter 5000, loss: 0.892180
 >> iter 6000, loss: 0.590016
 >> iter 7000, loss: 0.328767
 >> iter 8000, loss: 0.171191
 >> iter 9000, loss: 0.094586
 >> iter 10000, loss: 0.162177
   Number of active neurons: 10
 >> iter 11000, loss: 0.140165
 >> iter 12000, loss: 0.076589
 >> iter 13000, loss: 0.159071
 >> iter 14000, loss: 0.066073
 >> iter 15000, loss: 0.062166
 >> iter 16000, loss: 0.065933
 >> iter 17000, loss: 0.038675
 >> iter 18000, loss: 0.041389
 >> iter 19000, loss: 0.042668
 >> iter 20000, loss: 0.023653
   Number of active neurons: 10
 >> iter 21000, loss: 0.015225
 >> iter 22000, loss: 0.009306
 >> iter 23000, loss: 0.008103
 >> iter 24000, loss: 0.007911
 >> iter 25000, loss: 0.084107
 >> iter 26000, loss: 0.035520
 >> iter 27000, loss: 0.017453
 >> iter 28000, loss: 0.009067
 >> iter 29000, loss: 0.005800
 >> iter 30000, loss: 0.016544
   Number of active neurons: 10
 >> iter 31000, loss: 0.063807
 >> iter 32000, loss: 0.032080
 >> iter 33000, loss: 0.029865
 >> iter 34000, loss: 0.013427
 >> iter 35000, loss: 0.007199
 >> iter 36000, loss: 0.007162
 >> iter 37000, loss: 0.046489
 >> iter 38000, loss: 0.022180
 >> iter 39000, loss: 0.010370
 >> iter 40000, loss: 0.006379
   Number of active neurons: 10
 >> iter 41000, loss: 0.099065
 >> iter 42000, loss: 0.039180
 >> iter 43000, loss: 0.016992
 >> iter 44000, loss: 0.008413
 >> iter 45000, loss: 0.004947
 >> iter 46000, loss: 0.003489
 >> iter 47000, loss: 0.002951
 >> iter 48000, loss: 0.002698
 >> iter 49000, loss: 0.058265
 >> iter 50000, loss: 0.023313
   Number of active neurons: 10
 >> iter 51000, loss: 0.010149
 >> iter 52000, loss: 0.005203
 >> iter 53000, loss: 0.005944
 >> iter 54000, loss: 0.004024
 >> iter 55000, loss: 0.002768
 >> iter 56000, loss: 0.002608
 >> iter 57000, loss: 0.002215
 >> iter 58000, loss: 0.002351
 >> iter 59000, loss: 0.003873
 >> iter 60000, loss: 0.017577
   Number of active neurons: 10
 >> iter 61000, loss: 0.011504
 >> iter 62000, loss: 0.005610
 >> iter 63000, loss: 0.003606
 >> iter 64000, loss: 0.026274
 >> iter 65000, loss: 0.010940
 >> iter 66000, loss: 0.005242
 >> iter 67000, loss: 0.019731
 >> iter 68000, loss: 0.122708
 >> iter 69000, loss: 0.047205
 >> iter 70000, loss: 0.109836
   Number of active neurons: 10
 >> iter 71000, loss: 0.145356
 >> iter 72000, loss: 0.058645
 >> iter 73000, loss: 0.024021
 >> iter 74000, loss: 0.010683
 >> iter 75000, loss: 0.005645
 >> iter 76000, loss: 0.003577
 >> iter 77000, loss: 0.005012
 >> iter 78000, loss: 0.003075
 >> iter 79000, loss: 0.002619
 >> iter 80000, loss: 0.002160
   Number of active neurons: 10
 >> iter 81000, loss: 0.002169
 >> iter 82000, loss: 0.049360
 >> iter 83000, loss: 0.019516
 >> iter 84000, loss: 0.008352
 >> iter 85000, loss: 0.004081
 >> iter 86000, loss: 0.002497
 >> iter 87000, loss: 0.002205
 >> iter 88000, loss: 0.002512
 >> iter 89000, loss: 0.002583
 >> iter 90000, loss: 0.001883
   Number of active neurons: 10
 >> iter 91000, loss: 0.007829
 >> iter 92000, loss: 0.047331
 >> iter 93000, loss: 0.018569
 >> iter 94000, loss: 0.007910
 >> iter 95000, loss: 0.003872
 >> iter 96000, loss: 0.002266
 >> iter 97000, loss: 0.002116
 >> iter 98000, loss: 0.001731
 >> iter 99000, loss: 0.001523
 >> iter 100000, loss: 0.001489
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.524934
 >> iter 2000, loss: 9.898106
 >> iter 3000, loss: 4.656287
 >> iter 4000, loss: 2.043105
 >> iter 5000, loss: 1.075296
 >> iter 6000, loss: 0.550904
 >> iter 7000, loss: 0.276013
 >> iter 8000, loss: 0.130981
 >> iter 9000, loss: 0.160811
 >> iter 10000, loss: 0.148710
   Number of active neurons: 10
 >> iter 11000, loss: 0.070426
 >> iter 12000, loss: 0.172489
 >> iter 13000, loss: 0.142132
 >> iter 14000, loss: 0.180967
 >> iter 15000, loss: 0.082562
 >> iter 16000, loss: 0.040126
 >> iter 17000, loss: 0.027914
 >> iter 18000, loss: 0.015510
 >> iter 19000, loss: 0.025600
 >> iter 20000, loss: 0.036267
   Number of active neurons: 10
 >> iter 21000, loss: 0.043680
 >> iter 22000, loss: 0.108380
 >> iter 23000, loss: 0.083637
 >> iter 24000, loss: 0.042156
 >> iter 25000, loss: 0.019182
 >> iter 26000, loss: 0.011182
 >> iter 27000, loss: 0.009172
 >> iter 28000, loss: 0.018992
 >> iter 29000, loss: 0.012161
 >> iter 30000, loss: 0.010041
   Number of active neurons: 10
 >> iter 31000, loss: 0.029838
 >> iter 32000, loss: 0.013930
 >> iter 33000, loss: 0.019862
 >> iter 34000, loss: 0.150592
 >> iter 35000, loss: 0.112054
 >> iter 36000, loss: 0.044379
 >> iter 37000, loss: 0.019827
 >> iter 38000, loss: 0.019662
 >> iter 39000, loss: 0.045668
 >> iter 40000, loss: 0.029806
   Number of active neurons: 10
 >> iter 41000, loss: 0.013259
 >> iter 42000, loss: 0.034192
 >> iter 43000, loss: 0.015212
 >> iter 44000, loss: 0.007508
 >> iter 45000, loss: 0.004711
 >> iter 46000, loss: 0.042486
 >> iter 47000, loss: 0.090102
 >> iter 48000, loss: 0.036263
 >> iter 49000, loss: 0.016714
 >> iter 50000, loss: 0.008187
   Number of active neurons: 10
 >> iter 51000, loss: 0.005782
 >> iter 52000, loss: 0.003894
 >> iter 53000, loss: 0.003028
 >> iter 54000, loss: 0.002450
 >> iter 55000, loss: 0.002329
 >> iter 56000, loss: 0.017210
 >> iter 57000, loss: 0.114079
 >> iter 58000, loss: 0.043742
 >> iter 59000, loss: 0.020679
 >> iter 60000, loss: 0.009396
   Number of active neurons: 10
 >> iter 61000, loss: 0.004664
 >> iter 62000, loss: 0.011944
 >> iter 63000, loss: 0.005978
 >> iter 64000, loss: 0.004526
 >> iter 65000, loss: 0.004655
 >> iter 66000, loss: 0.003278
 >> iter 67000, loss: 0.002263
 >> iter 68000, loss: 0.001796
 >> iter 69000, loss: 0.049332
 >> iter 70000, loss: 0.021871
   Number of active neurons: 10
 >> iter 71000, loss: 0.008962
 >> iter 72000, loss: 0.004277
 >> iter 73000, loss: 0.002780
 >> iter 74000, loss: 0.002000
 >> iter 75000, loss: 0.001678
 >> iter 76000, loss: 0.001413
 >> iter 77000, loss: 0.001318
 >> iter 78000, loss: 0.001511
 >> iter 79000, loss: 0.001331
 >> iter 80000, loss: 0.001536
   Number of active neurons: 10
 >> iter 81000, loss: 0.001310
 >> iter 82000, loss: 0.001250
 >> iter 83000, loss: 0.001244
 >> iter 84000, loss: 0.008441
 >> iter 85000, loss: 0.003906
 >> iter 86000, loss: 0.002188
 >> iter 87000, loss: 0.001496
 >> iter 88000, loss: 0.002099
 >> iter 89000, loss: 0.001685
 >> iter 90000, loss: 0.001266
   Number of active neurons: 10
 >> iter 91000, loss: 0.001176
 >> iter 92000, loss: 0.001104
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.725608
 >> iter 2000, loss: 9.742118
 >> iter 3000, loss: 4.067887
 >> iter 4000, loss: 1.671701
 >> iter 5000, loss: 0.809332
 >> iter 6000, loss: 0.380123
 >> iter 7000, loss: 0.450411
 >> iter 8000, loss: 0.310202
 >> iter 9000, loss: 0.261691
 >> iter 10000, loss: 0.215699
   Number of active neurons: 10
 >> iter 11000, loss: 0.106143
 >> iter 12000, loss: 0.050007
 >> iter 13000, loss: 0.042602
 >> iter 14000, loss: 0.024158
 >> iter 15000, loss: 0.015698
 >> iter 16000, loss: 0.012112
 >> iter 17000, loss: 0.082203
 >> iter 18000, loss: 0.071323
 >> iter 19000, loss: 0.035308
 >> iter 20000, loss: 0.066448
   Number of active neurons: 10
 >> iter 21000, loss: 0.099382
 >> iter 22000, loss: 0.051055
 >> iter 23000, loss: 0.059050
 >> iter 24000, loss: 0.027295
 >> iter 25000, loss: 0.032897
 >> iter 26000, loss: 0.041873
 >> iter 27000, loss: 0.019359
 >> iter 28000, loss: 0.022218
 >> iter 29000, loss: 0.024029
 >> iter 30000, loss: 0.059572
   Number of active neurons: 10
 >> iter 31000, loss: 0.026648
 >> iter 32000, loss: 0.013363
 >> iter 33000, loss: 0.007890
 >> iter 34000, loss: 0.007887
 >> iter 35000, loss: 0.008060
 >> iter 36000, loss: 0.005550
 >> iter 37000, loss: 0.004492
 >> iter 38000, loss: 0.003664
 >> iter 39000, loss: 0.003759
 >> iter 40000, loss: 0.043871
   Number of active neurons: 10
 >> iter 41000, loss: 0.026018
 >> iter 42000, loss: 0.082090
 >> iter 43000, loss: 0.032503
 >> iter 44000, loss: 0.014061
 >> iter 45000, loss: 0.007169
 >> iter 46000, loss: 0.004470
 >> iter 47000, loss: 0.009600
 >> iter 48000, loss: 0.022702
 >> iter 49000, loss: 0.010508
 >> iter 50000, loss: 0.005473
   Number of active neurons: 10
 >> iter 51000, loss: 0.005232
 >> iter 52000, loss: 0.014098
 >> iter 53000, loss: 0.009202
 >> iter 54000, loss: 0.005190
 >> iter 55000, loss: 0.003487
 >> iter 56000, loss: 0.002609
 >> iter 57000, loss: 0.002276
 >> iter 58000, loss: 0.015023
 >> iter 59000, loss: 0.065902
 >> iter 60000, loss: 0.070408
   Number of active neurons: 10
 >> iter 61000, loss: 0.027767
 >> iter 62000, loss: 0.076368
 >> iter 63000, loss: 0.037771
 >> iter 64000, loss: 0.016190
 >> iter 65000, loss: 0.007600
 >> iter 66000, loss: 0.005758
 >> iter 67000, loss: 0.003499
 >> iter 68000, loss: 0.002603
 >> iter 69000, loss: 0.002799
 >> iter 70000, loss: 0.029316
   Number of active neurons: 10
 >> iter 71000, loss: 0.012638
 >> iter 72000, loss: 0.006063
 >> iter 73000, loss: 0.005791
 >> iter 74000, loss: 0.003717
 >> iter 75000, loss: 0.002547
 >> iter 76000, loss: 0.002021
 >> iter 77000, loss: 0.001837
 >> iter 78000, loss: 0.001825
 >> iter 79000, loss: 0.010615
 >> iter 80000, loss: 0.005020
   Number of active neurons: 10
 >> iter 81000, loss: 0.004004
 >> iter 82000, loss: 0.002603
 >> iter 83000, loss: 0.003143
 >> iter 84000, loss: 0.002178
 >> iter 85000, loss: 0.001769
 >> iter 86000, loss: 0.002123
 >> iter 87000, loss: 0.002928
 >> iter 88000, loss: 0.002176
 >> iter 89000, loss: 0.001660
 >> iter 90000, loss: 0.001614
   Number of active neurons: 10
 >> iter 91000, loss: 0.001396
 >> iter 92000, loss: 0.001628
 >> iter 93000, loss: 0.001344
 >> iter 94000, loss: 0.001261
 >> iter 95000, loss: 0.001159
 >> iter 96000, loss: 0.001292
 >> iter 97000, loss: 0.001198
 >> iter 98000, loss: 0.001098
 >> iter 99000, loss: 0.001094
 >> iter 100000, loss: 0.001074
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.601108
 >> iter 2000, loss: 10.334798
 >> iter 3000, loss: 5.020759
 >> iter 4000, loss: 2.515758
 >> iter 5000, loss: 1.585498
 >> iter 6000, loss: 0.935190
 >> iter 7000, loss: 0.494969
 >> iter 8000, loss: 0.397605
 >> iter 9000, loss: 0.212746
 >> iter 10000, loss: 0.248470
   Number of active neurons: 10
 >> iter 11000, loss: 0.213225
 >> iter 12000, loss: 0.176872
 >> iter 13000, loss: 0.186486
 >> iter 14000, loss: 0.137190
 >> iter 15000, loss: 0.140519
 >> iter 16000, loss: 0.257955
 >> iter 17000, loss: 0.245103
 >> iter 18000, loss: 0.332746
 >> iter 19000, loss: 0.297271
 >> iter 20000, loss: 0.174440
   Number of active neurons: 10
 >> iter 21000, loss: 0.149247
 >> iter 22000, loss: 0.131086
 >> iter 23000, loss: 0.238448
 >> iter 24000, loss: 0.191213
 >> iter 25000, loss: 0.125994
 >> iter 26000, loss: 0.090389
 >> iter 27000, loss: 0.062707
 >> iter 28000, loss: 0.036483
 >> iter 29000, loss: 0.248989
 >> iter 30000, loss: 0.136393
   Number of active neurons: 10
 >> iter 31000, loss: 0.096857
 >> iter 32000, loss: 0.054729
 >> iter 33000, loss: 0.118564
 >> iter 34000, loss: 0.159170
 >> iter 35000, loss: 0.107063
 >> iter 36000, loss: 0.154215
 >> iter 37000, loss: 0.113797
 >> iter 38000, loss: 0.057689
 >> iter 39000, loss: 0.057319
 >> iter 40000, loss: 0.075074
   Number of active neurons: 10
 >> iter 41000, loss: 0.041779
 >> iter 42000, loss: 0.031129
 >> iter 43000, loss: 0.118330
 >> iter 44000, loss: 0.085804
 >> iter 45000, loss: 0.178559
 >> iter 46000, loss: 0.093182
 >> iter 47000, loss: 0.067954
 >> iter 48000, loss: 0.069158
 >> iter 49000, loss: 0.033385
 >> iter 50000, loss: 0.016873
   Number of active neurons: 10
 >> iter 51000, loss: 0.048439
 >> iter 52000, loss: 0.025620
 >> iter 53000, loss: 0.040732
 >> iter 54000, loss: 0.029464
 >> iter 55000, loss: 0.041084
 >> iter 56000, loss: 0.236331
 >> iter 57000, loss: 0.179465
 >> iter 58000, loss: 0.071727
 >> iter 59000, loss: 0.040096
 >> iter 60000, loss: 0.021743
   Number of active neurons: 10
 >> iter 61000, loss: 0.097584
 >> iter 62000, loss: 0.066447
 >> iter 63000, loss: 0.035817
 >> iter 64000, loss: 0.102022
 >> iter 65000, loss: 0.049703
 >> iter 66000, loss: 0.034552
 >> iter 67000, loss: 0.019522
 >> iter 68000, loss: 0.010113
 >> iter 69000, loss: 0.044348
 >> iter 70000, loss: 0.042313
   Number of active neurons: 10
 >> iter 71000, loss: 0.024818
 >> iter 72000, loss: 0.154033
 >> iter 73000, loss: 0.063293
 >> iter 74000, loss: 0.026766
 >> iter 75000, loss: 0.036978
 >> iter 76000, loss: 0.018154
 >> iter 77000, loss: 0.101107
 >> iter 78000, loss: 0.068140
 >> iter 79000, loss: 0.202494
 >> iter 80000, loss: 0.081156
   Number of active neurons: 10
 >> iter 81000, loss: 0.033697
 >> iter 82000, loss: 0.031280
 >> iter 83000, loss: 0.043076
 >> iter 84000, loss: 0.020769
 >> iter 85000, loss: 0.010345
 >> iter 86000, loss: 0.019583
 >> iter 87000, loss: 0.024816
 >> iter 88000, loss: 0.017581
 >> iter 89000, loss: 0.121151
 >> iter 90000, loss: 0.048737
   Number of active neurons: 10
 >> iter 91000, loss: 0.020217
 >> iter 92000, loss: 0.011123
 >> iter 93000, loss: 0.037731
 >> iter 94000, loss: 0.018849
 >> iter 95000, loss: 0.009339
 >> iter 96000, loss: 0.005406
 >> iter 97000, loss: 0.004085
 >> iter 98000, loss: 0.011115
 >> iter 99000, loss: 0.019834
 >> iter 100000, loss: 0.017627
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.798346
 >> iter 2000, loss: 11.125429
 >> iter 3000, loss: 5.220259
 >> iter 4000, loss: 2.369765
 >> iter 5000, loss: 1.172028
 >> iter 6000, loss: 0.674100
 >> iter 7000, loss: 0.398649
 >> iter 8000, loss: 0.183441
 >> iter 9000, loss: 0.081993
 >> iter 10000, loss: 0.085582
   Number of active neurons: 10
 >> iter 11000, loss: 0.363607
 >> iter 12000, loss: 0.169122
 >> iter 13000, loss: 0.190443
 >> iter 14000, loss: 0.173697
 >> iter 15000, loss: 0.097125
 >> iter 16000, loss: 0.046167
 >> iter 17000, loss: 0.102833
 >> iter 18000, loss: 0.092157
 >> iter 19000, loss: 0.041992
 >> iter 20000, loss: 0.025521
   Number of active neurons: 10
 >> iter 21000, loss: 0.015313
 >> iter 22000, loss: 0.013151
 >> iter 23000, loss: 0.172161
 >> iter 24000, loss: 0.071013
 >> iter 25000, loss: 0.031334
 >> iter 26000, loss: 0.082748
 >> iter 27000, loss: 0.086555
 >> iter 28000, loss: 0.118531
 >> iter 29000, loss: 0.055268
 >> iter 30000, loss: 0.027157
   Number of active neurons: 10
 >> iter 31000, loss: 0.014202
 >> iter 32000, loss: 0.008317
 >> iter 33000, loss: 0.006981
 >> iter 34000, loss: 0.005456
 >> iter 35000, loss: 0.127889
 >> iter 36000, loss: 0.108259
 >> iter 37000, loss: 0.066827
 >> iter 38000, loss: 0.028392
 >> iter 39000, loss: 0.086477
 >> iter 40000, loss: 0.046585
   Number of active neurons: 10
 >> iter 41000, loss: 0.021687
 >> iter 42000, loss: 0.013065
 >> iter 43000, loss: 0.011333
 >> iter 44000, loss: 0.009571
 >> iter 45000, loss: 0.006581
 >> iter 46000, loss: 0.010348
 >> iter 47000, loss: 0.012929
 >> iter 48000, loss: 0.058289
 >> iter 49000, loss: 0.036228
 >> iter 50000, loss: 0.015870
   Number of active neurons: 10
 >> iter 51000, loss: 0.051493
 >> iter 52000, loss: 0.056408
 >> iter 53000, loss: 0.023637
 >> iter 54000, loss: 0.039170
 >> iter 55000, loss: 0.017486
 >> iter 56000, loss: 0.009037
 >> iter 57000, loss: 0.025188
 >> iter 58000, loss: 0.034783
 >> iter 59000, loss: 0.015598
 >> iter 60000, loss: 0.030689
   Number of active neurons: 10
 >> iter 61000, loss: 0.014163
 >> iter 62000, loss: 0.059383
 >> iter 63000, loss: 0.024576
 >> iter 64000, loss: 0.011081
 >> iter 65000, loss: 0.007223
 >> iter 66000, loss: 0.005726
 >> iter 67000, loss: 0.030319
 >> iter 68000, loss: 0.013812
 >> iter 69000, loss: 0.008063
 >> iter 70000, loss: 0.005603
   Number of active neurons: 10
 >> iter 71000, loss: 0.032026
 >> iter 72000, loss: 0.016171
 >> iter 73000, loss: 0.007789
 >> iter 74000, loss: 0.004745
 >> iter 75000, loss: 0.003255
 >> iter 76000, loss: 0.003414
 >> iter 77000, loss: 0.002553
 >> iter 78000, loss: 0.003467
 >> iter 79000, loss: 0.061661
 >> iter 80000, loss: 0.024511
   Number of active neurons: 10
 >> iter 81000, loss: 0.010357
 >> iter 82000, loss: 0.006333
 >> iter 83000, loss: 0.003914
 >> iter 84000, loss: 0.002884
 >> iter 85000, loss: 0.002358
 >> iter 86000, loss: 0.002108
 >> iter 87000, loss: 0.002502
 >> iter 88000, loss: 0.002031
 >> iter 89000, loss: 0.002563
 >> iter 90000, loss: 0.002322
   Number of active neurons: 10
 >> iter 91000, loss: 0.002119
 >> iter 92000, loss: 0.001785
 >> iter 93000, loss: 0.001573
 >> iter 94000, loss: 0.003024
 >> iter 95000, loss: 0.001990
 >> iter 96000, loss: 0.001665
 >> iter 97000, loss: 0.001641
 >> iter 98000, loss: 0.001489
 >> iter 99000, loss: 0.001411
 >> iter 100000, loss: 0.001397
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.906861
 >> iter 2000, loss: 10.956725
 >> iter 3000, loss: 4.858697
 >> iter 4000, loss: 2.186889
 >> iter 5000, loss: 1.020591
 >> iter 6000, loss: 0.443888
 >> iter 7000, loss: 0.189114
 >> iter 8000, loss: 0.206312
 >> iter 9000, loss: 0.091441
 >> iter 10000, loss: 0.074877
   Number of active neurons: 10
 >> iter 11000, loss: 0.134205
 >> iter 12000, loss: 0.074227
 >> iter 13000, loss: 0.034973
 >> iter 14000, loss: 0.019556
 >> iter 15000, loss: 0.220297
 >> iter 16000, loss: 0.088661
 >> iter 17000, loss: 0.044740
 >> iter 18000, loss: 0.021347
 >> iter 19000, loss: 0.013878
 >> iter 20000, loss: 0.033173
   Number of active neurons: 10
 >> iter 21000, loss: 0.094067
 >> iter 22000, loss: 0.181204
 >> iter 23000, loss: 0.082025
 >> iter 24000, loss: 0.085014
 >> iter 25000, loss: 0.050017
 >> iter 26000, loss: 0.023515
 >> iter 27000, loss: 0.012353
 >> iter 28000, loss: 0.007720
 >> iter 29000, loss: 0.006186
 >> iter 30000, loss: 0.005063
   Number of active neurons: 10
 >> iter 31000, loss: 0.004414
 >> iter 32000, loss: 0.007427
 >> iter 33000, loss: 0.005359
 >> iter 34000, loss: 0.004534
 >> iter 35000, loss: 0.003668
 >> iter 36000, loss: 0.026521
 >> iter 37000, loss: 0.011903
 >> iter 38000, loss: 0.155600
 >> iter 39000, loss: 0.069160
 >> iter 40000, loss: 0.031666
   Number of active neurons: 10
 >> iter 41000, loss: 0.013494
 >> iter 42000, loss: 0.009236
 >> iter 43000, loss: 0.005153
 >> iter 44000, loss: 0.003469
 >> iter 45000, loss: 0.002843
 >> iter 46000, loss: 0.002802
 >> iter 47000, loss: 0.015862
 >> iter 48000, loss: 0.007285
 >> iter 49000, loss: 0.004385
 >> iter 50000, loss: 0.003406
   Number of active neurons: 10
 >> iter 51000, loss: 0.002578
 >> iter 52000, loss: 0.002278
 >> iter 53000, loss: 0.001930
 >> iter 54000, loss: 0.001784
 >> iter 55000, loss: 0.001843
 >> iter 56000, loss: 0.001661
 >> iter 57000, loss: 0.001569
 >> iter 58000, loss: 0.001803
 >> iter 59000, loss: 0.001556
 >> iter 60000, loss: 0.002356
   Number of active neurons: 10
 >> iter 61000, loss: 0.002685
 >> iter 62000, loss: 0.001861
 >> iter 63000, loss: 0.001542
 >> iter 64000, loss: 0.001385
 >> iter 65000, loss: 0.001381
 >> iter 66000, loss: 0.001257
 >> iter 67000, loss: 0.001204
 >> iter 68000, loss: 0.001176
 >> iter 69000, loss: 0.001465
 >> iter 70000, loss: 0.001308
   Number of active neurons: 10
 >> iter 71000, loss: 0.001197
 >> iter 72000, loss: 0.002675
 >> iter 73000, loss: 0.001779
 >> iter 74000, loss: 0.001481
 >> iter 75000, loss: 0.006367
 >> iter 76000, loss: 0.003280
 >> iter 77000, loss: 0.002008
 >> iter 78000, loss: 0.001449
 >> iter 79000, loss: 0.001183
 >> iter 80000, loss: 0.001066
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.123133
 >> iter 2000, loss: 11.530256
 >> iter 3000, loss: 4.962965
 >> iter 4000, loss: 2.053580
 >> iter 5000, loss: 1.121403
 >> iter 6000, loss: 0.518208
 >> iter 7000, loss: 0.467944
 >> iter 8000, loss: 0.206373
 >> iter 9000, loss: 0.114672
 >> iter 10000, loss: 0.061316
   Number of active neurons: 10
 >> iter 11000, loss: 0.048897
 >> iter 12000, loss: 0.073951
 >> iter 13000, loss: 0.035271
 >> iter 14000, loss: 0.020115
 >> iter 15000, loss: 0.070129
 >> iter 16000, loss: 0.033207
 >> iter 17000, loss: 0.017515
 >> iter 18000, loss: 0.062495
 >> iter 19000, loss: 0.072886
 >> iter 20000, loss: 0.031393
   Number of active neurons: 10
 >> iter 21000, loss: 0.019053
 >> iter 22000, loss: 0.014399
 >> iter 23000, loss: 0.023083
 >> iter 24000, loss: 0.013461
 >> iter 25000, loss: 0.007909
 >> iter 26000, loss: 0.005524
 >> iter 27000, loss: 0.028486
 >> iter 28000, loss: 0.012996
 >> iter 29000, loss: 0.011809
 >> iter 30000, loss: 0.007711
   Number of active neurons: 10
 >> iter 31000, loss: 0.052054
 >> iter 32000, loss: 0.022141
 >> iter 33000, loss: 0.010369
 >> iter 34000, loss: 0.079449
 >> iter 35000, loss: 0.090757
 >> iter 36000, loss: 0.038372
 >> iter 37000, loss: 0.016845
 >> iter 38000, loss: 0.009601
 >> iter 39000, loss: 0.012362
 >> iter 40000, loss: 0.006482
   Number of active neurons: 10
 >> iter 41000, loss: 0.005069
 >> iter 42000, loss: 0.019410
 >> iter 43000, loss: 0.009675
 >> iter 44000, loss: 0.005536
 >> iter 45000, loss: 0.003895
 >> iter 46000, loss: 0.074280
 >> iter 47000, loss: 0.031347
 >> iter 48000, loss: 0.013863
 >> iter 49000, loss: 0.006638
 >> iter 50000, loss: 0.003858
   Number of active neurons: 10
 >> iter 51000, loss: 0.006163
 >> iter 52000, loss: 0.003727
 >> iter 53000, loss: 0.003128
 >> iter 54000, loss: 0.002491
 >> iter 55000, loss: 0.002076
 >> iter 56000, loss: 0.014905
 >> iter 57000, loss: 0.007634
 >> iter 58000, loss: 0.032756
 >> iter 59000, loss: 0.013447
 >> iter 60000, loss: 0.009662
   Number of active neurons: 10
 >> iter 61000, loss: 0.004699
 >> iter 62000, loss: 0.002776
 >> iter 63000, loss: 0.002260
 >> iter 64000, loss: 0.001830
 >> iter 65000, loss: 0.001972
 >> iter 66000, loss: 0.001499
 >> iter 67000, loss: 0.001446
 >> iter 68000, loss: 0.001290
 >> iter 69000, loss: 0.001149
 >> iter 70000, loss: 0.029896
   Number of active neurons: 10
 >> iter 71000, loss: 0.039590
 >> iter 72000, loss: 0.015804
 >> iter 73000, loss: 0.006890
 >> iter 74000, loss: 0.003702
 >> iter 75000, loss: 0.002362
 >> iter 76000, loss: 0.001806
 >> iter 77000, loss: 0.003713
 >> iter 78000, loss: 0.002425
 >> iter 79000, loss: 0.001631
 >> iter 80000, loss: 0.001342
   Number of active neurons: 10
 >> iter 81000, loss: 0.001185
 >> iter 82000, loss: 0.001708
 >> iter 83000, loss: 0.001436
 >> iter 84000, loss: 0.001393
 >> iter 85000, loss: 0.004880
 >> iter 86000, loss: 0.003478
 >> iter 87000, loss: 0.002099
 >> iter 88000, loss: 0.002422
 >> iter 89000, loss: 0.001756
 >> iter 90000, loss: 0.001355
   Number of active neurons: 10
 >> iter 91000, loss: 0.001145
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.951479
 >> iter 2000, loss: 10.506286
 >> iter 3000, loss: 4.700654
 >> iter 4000, loss: 2.269060
 >> iter 5000, loss: 1.082340
 >> iter 6000, loss: 0.517551
 >> iter 7000, loss: 0.270258
 >> iter 8000, loss: 0.332260
 >> iter 9000, loss: 0.306255
 >> iter 10000, loss: 0.170588
   Number of active neurons: 10
 >> iter 11000, loss: 0.167556
 >> iter 12000, loss: 0.080462
 >> iter 13000, loss: 0.037578
 >> iter 14000, loss: 0.035322
 >> iter 15000, loss: 0.029887
 >> iter 16000, loss: 0.077400
 >> iter 17000, loss: 0.157628
 >> iter 18000, loss: 0.066638
 >> iter 19000, loss: 0.044030
 >> iter 20000, loss: 0.021275
   Number of active neurons: 10
 >> iter 21000, loss: 0.081099
 >> iter 22000, loss: 0.179808
 >> iter 23000, loss: 0.072506
 >> iter 24000, loss: 0.034524
 >> iter 25000, loss: 0.027545
 >> iter 26000, loss: 0.045433
 >> iter 27000, loss: 0.020428
 >> iter 28000, loss: 0.013158
 >> iter 29000, loss: 0.007993
 >> iter 30000, loss: 0.006890
   Number of active neurons: 10
 >> iter 31000, loss: 0.005759
 >> iter 32000, loss: 0.029317
 >> iter 33000, loss: 0.014877
 >> iter 34000, loss: 0.035784
 >> iter 35000, loss: 0.017437
 >> iter 36000, loss: 0.008903
 >> iter 37000, loss: 0.006145
 >> iter 38000, loss: 0.004220
 >> iter 39000, loss: 0.003611
 >> iter 40000, loss: 0.003150
   Number of active neurons: 10
 >> iter 41000, loss: 0.004056
 >> iter 42000, loss: 0.018149
 >> iter 43000, loss: 0.008565
 >> iter 44000, loss: 0.004840
 >> iter 45000, loss: 0.004173
 >> iter 46000, loss: 0.003100
 >> iter 47000, loss: 0.002787
 >> iter 48000, loss: 0.003118
 >> iter 49000, loss: 0.014280
 >> iter 50000, loss: 0.007620
   Number of active neurons: 10
 >> iter 51000, loss: 0.004212
 >> iter 52000, loss: 0.002677
 >> iter 53000, loss: 0.002206
 >> iter 54000, loss: 0.023051
 >> iter 55000, loss: 0.010226
 >> iter 56000, loss: 0.004911
 >> iter 57000, loss: 0.002909
 >> iter 58000, loss: 0.002067
 >> iter 59000, loss: 0.195690
 >> iter 60000, loss: 0.187293
   Number of active neurons: 10
 >> iter 61000, loss: 0.071098
 >> iter 62000, loss: 0.048049
 >> iter 63000, loss: 0.019232
 >> iter 64000, loss: 0.008709
 >> iter 65000, loss: 0.004661
 >> iter 66000, loss: 0.008344
 >> iter 67000, loss: 0.004766
 >> iter 68000, loss: 0.003184
 >> iter 69000, loss: 0.140588
 >> iter 70000, loss: 0.054611
   Number of active neurons: 10
 >> iter 71000, loss: 0.021476
 >> iter 72000, loss: 0.009252
 >> iter 73000, loss: 0.004845
 >> iter 74000, loss: 0.002916
 >> iter 75000, loss: 0.002733
 >> iter 76000, loss: 0.002265
 >> iter 77000, loss: 0.001948
 >> iter 78000, loss: 0.001743
 >> iter 79000, loss: 0.001609
 >> iter 80000, loss: 0.001665
   Number of active neurons: 10
 >> iter 81000, loss: 0.001573
 >> iter 82000, loss: 0.001507
 >> iter 83000, loss: 0.008848
 >> iter 84000, loss: 0.004414
 >> iter 85000, loss: 0.003127
 >> iter 86000, loss: 0.002078
 >> iter 87000, loss: 0.002592
 >> iter 88000, loss: 0.033228
 >> iter 89000, loss: 0.013402
 >> iter 90000, loss: 0.006036
   Number of active neurons: 10
 >> iter 91000, loss: 0.003157
 >> iter 92000, loss: 0.002060
 >> iter 93000, loss: 0.001496
 >> iter 94000, loss: 0.001319
 >> iter 95000, loss: 0.001237
 >> iter 96000, loss: 0.001163
 >> iter 97000, loss: 0.001225
 >> iter 98000, loss: 0.001266
 >> iter 99000, loss: 0.001172
 >> iter 100000, loss: 0.015392
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.928878
 >> iter 2000, loss: 11.025599
 >> iter 3000, loss: 4.980081
 >> iter 4000, loss: 2.217991
 >> iter 5000, loss: 0.964229
 >> iter 6000, loss: 0.498935
 >> iter 7000, loss: 0.231119
 >> iter 8000, loss: 0.184296
 >> iter 9000, loss: 0.086375
 >> iter 10000, loss: 0.104416
   Number of active neurons: 10
 >> iter 11000, loss: 0.047533
 >> iter 12000, loss: 0.069501
 >> iter 13000, loss: 0.066639
 >> iter 14000, loss: 0.054949
 >> iter 15000, loss: 0.053825
 >> iter 16000, loss: 0.224259
 >> iter 17000, loss: 0.132677
 >> iter 18000, loss: 0.089694
 >> iter 19000, loss: 0.039295
 >> iter 20000, loss: 0.019368
   Number of active neurons: 10
 >> iter 21000, loss: 0.227154
 >> iter 22000, loss: 0.138950
 >> iter 23000, loss: 0.061138
 >> iter 24000, loss: 0.036318
 >> iter 25000, loss: 0.018852
 >> iter 26000, loss: 0.013648
 >> iter 27000, loss: 0.008723
 >> iter 28000, loss: 0.026443
 >> iter 29000, loss: 0.044337
 >> iter 30000, loss: 0.019298
   Number of active neurons: 10
 >> iter 31000, loss: 0.029742
 >> iter 32000, loss: 0.015679
 >> iter 33000, loss: 0.008813
 >> iter 34000, loss: 0.005476
 >> iter 35000, loss: 0.022608
 >> iter 36000, loss: 0.010886
 >> iter 37000, loss: 0.022249
 >> iter 38000, loss: 0.010584
 >> iter 39000, loss: 0.006350
 >> iter 40000, loss: 0.006675
   Number of active neurons: 10
 >> iter 41000, loss: 0.005433
 >> iter 42000, loss: 0.006537
 >> iter 43000, loss: 0.004136
 >> iter 44000, loss: 0.003118
 >> iter 45000, loss: 0.003203
 >> iter 46000, loss: 0.003024
 >> iter 47000, loss: 0.002634
 >> iter 48000, loss: 0.002650
 >> iter 49000, loss: 0.002569
 >> iter 50000, loss: 0.056512
   Number of active neurons: 10
 >> iter 51000, loss: 0.022225
 >> iter 52000, loss: 0.009637
 >> iter 53000, loss: 0.007877
 >> iter 54000, loss: 0.004336
 >> iter 55000, loss: 0.059917
 >> iter 56000, loss: 0.023810
 >> iter 57000, loss: 0.010017
 >> iter 58000, loss: 0.004985
 >> iter 59000, loss: 0.003097
 >> iter 60000, loss: 0.002350
   Number of active neurons: 10
 >> iter 61000, loss: 0.001899
 >> iter 62000, loss: 0.001858
 >> iter 63000, loss: 0.001815
 >> iter 64000, loss: 0.002284
 >> iter 65000, loss: 0.034510
 >> iter 66000, loss: 0.013902
 >> iter 67000, loss: 0.006352
 >> iter 68000, loss: 0.003528
 >> iter 69000, loss: 0.002302
 >> iter 70000, loss: 0.001779
   Number of active neurons: 10
 >> iter 71000, loss: 0.001960
 >> iter 72000, loss: 0.001947
 >> iter 73000, loss: 0.001768
 >> iter 74000, loss: 0.001555
 >> iter 75000, loss: 0.001446
 >> iter 76000, loss: 0.001473
 >> iter 77000, loss: 0.001339
 >> iter 78000, loss: 0.037320
 >> iter 79000, loss: 0.015733
 >> iter 80000, loss: 0.006810
   Number of active neurons: 10
 >> iter 81000, loss: 0.004241
 >> iter 82000, loss: 0.002506
 >> iter 83000, loss: 0.001876
 >> iter 84000, loss: 0.001508
 >> iter 85000, loss: 0.001408
 >> iter 86000, loss: 0.001308
 >> iter 87000, loss: 0.001666
 >> iter 88000, loss: 0.001403
 >> iter 89000, loss: 0.001977
 >> iter 90000, loss: 0.001416
   Number of active neurons: 10
 >> iter 91000, loss: 0.001192
 >> iter 92000, loss: 0.056592
 >> iter 93000, loss: 0.021928
 >> iter 94000, loss: 0.009816
 >> iter 95000, loss: 0.004863
 >> iter 96000, loss: 0.032927
 >> iter 97000, loss: 0.013151
 >> iter 98000, loss: 0.008873
 >> iter 99000, loss: 0.004301
 >> iter 100000, loss: 0.002293
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.973172
 >> iter 2000, loss: 12.070304
 >> iter 3000, loss: 5.841014
 >> iter 4000, loss: 2.810599
 >> iter 5000, loss: 1.358127
 >> iter 6000, loss: 0.710546
 >> iter 7000, loss: 0.576049
 >> iter 8000, loss: 0.371043
 >> iter 9000, loss: 0.245594
 >> iter 10000, loss: 0.338121
   Number of active neurons: 10
 >> iter 11000, loss: 0.203419
 >> iter 12000, loss: 0.122379
 >> iter 13000, loss: 0.116437
 >> iter 14000, loss: 0.135861
 >> iter 15000, loss: 0.149858
 >> iter 16000, loss: 0.097552
 >> iter 17000, loss: 0.057767
 >> iter 18000, loss: 0.102819
 >> iter 19000, loss: 0.062001
 >> iter 20000, loss: 0.098540
   Number of active neurons: 10
 >> iter 21000, loss: 0.125219
 >> iter 22000, loss: 0.092956
 >> iter 23000, loss: 0.074112
 >> iter 24000, loss: 0.034853
 >> iter 25000, loss: 0.209572
 >> iter 26000, loss: 0.094441
 >> iter 27000, loss: 0.041784
 >> iter 28000, loss: 0.030413
 >> iter 29000, loss: 0.017375
 >> iter 30000, loss: 0.011647
   Number of active neurons: 10
 >> iter 31000, loss: 0.010283
 >> iter 32000, loss: 0.008708
 >> iter 33000, loss: 0.008142
 >> iter 34000, loss: 0.106294
 >> iter 35000, loss: 0.054386
 >> iter 36000, loss: 0.036858
 >> iter 37000, loss: 0.017658
 >> iter 38000, loss: 0.010563
 >> iter 39000, loss: 0.008692
 >> iter 40000, loss: 0.006487
   Number of active neurons: 10
 >> iter 41000, loss: 0.006011
 >> iter 42000, loss: 0.040535
 >> iter 43000, loss: 0.017905
 >> iter 44000, loss: 0.049945
 >> iter 45000, loss: 0.021614
 >> iter 46000, loss: 0.011150
 >> iter 47000, loss: 0.007804
 >> iter 48000, loss: 0.005741
 >> iter 49000, loss: 0.004656
 >> iter 50000, loss: 0.004613
   Number of active neurons: 10
 >> iter 51000, loss: 0.033335
 >> iter 52000, loss: 0.014577
 >> iter 53000, loss: 0.061321
 >> iter 54000, loss: 0.026663
 >> iter 55000, loss: 0.012515
 >> iter 56000, loss: 0.008715
 >> iter 57000, loss: 0.005684
 >> iter 58000, loss: 0.003883
 >> iter 59000, loss: 0.003548
 >> iter 60000, loss: 0.003148
   Number of active neurons: 10
 >> iter 61000, loss: 0.012674
 >> iter 62000, loss: 0.013440
 >> iter 63000, loss: 0.061058
 >> iter 64000, loss: 0.024720
 >> iter 65000, loss: 0.011073
 >> iter 66000, loss: 0.009427
 >> iter 67000, loss: 0.005273
 >> iter 68000, loss: 0.003882
 >> iter 69000, loss: 0.003098
 >> iter 70000, loss: 0.005741
   Number of active neurons: 10
 >> iter 71000, loss: 0.003963
 >> iter 72000, loss: 0.004040
 >> iter 73000, loss: 0.019876
 >> iter 74000, loss: 0.011796
 >> iter 75000, loss: 0.005993
 >> iter 76000, loss: 0.003986
 >> iter 77000, loss: 0.009430
 >> iter 78000, loss: 0.004870
 >> iter 79000, loss: 0.003578
 >> iter 80000, loss: 0.002856
   Number of active neurons: 10
 >> iter 81000, loss: 0.002931
 >> iter 82000, loss: 0.002304
 >> iter 83000, loss: 0.002172
 >> iter 84000, loss: 0.002072
 >> iter 85000, loss: 0.003565
 >> iter 86000, loss: 0.003463
 >> iter 87000, loss: 0.002865
 >> iter 88000, loss: 0.003817
 >> iter 89000, loss: 0.002756
 >> iter 90000, loss: 0.002228
   Number of active neurons: 10
 >> iter 91000, loss: 0.003390
 >> iter 92000, loss: 0.002554
 >> iter 93000, loss: 0.001884
 >> iter 94000, loss: 0.002091
 >> iter 95000, loss: 0.001882
 >> iter 96000, loss: 0.001666
 >> iter 97000, loss: 0.002053
 >> iter 98000, loss: 0.002046
 >> iter 99000, loss: 0.002045
 >> iter 100000, loss: 0.005170
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.853661
 >> iter 2000, loss: 10.677826
 >> iter 3000, loss: 4.527989
 >> iter 4000, loss: 1.844291
 >> iter 5000, loss: 0.777684
 >> iter 6000, loss: 0.345684
 >> iter 7000, loss: 0.179516
 >> iter 8000, loss: 0.200531
 >> iter 9000, loss: 0.091823
 >> iter 10000, loss: 0.188065
   Number of active neurons: 10
 >> iter 11000, loss: 0.158132
 >> iter 12000, loss: 0.210768
 >> iter 13000, loss: 0.173998
 >> iter 14000, loss: 0.108171
 >> iter 15000, loss: 0.059784
 >> iter 16000, loss: 0.037486
 >> iter 17000, loss: 0.086630
 >> iter 18000, loss: 0.041160
 >> iter 19000, loss: 0.019839
 >> iter 20000, loss: 0.014432
   Number of active neurons: 10
 >> iter 21000, loss: 0.012666
 >> iter 22000, loss: 0.012099
 >> iter 23000, loss: 0.022806
 >> iter 24000, loss: 0.011296
 >> iter 25000, loss: 0.006859
 >> iter 26000, loss: 0.057442
 >> iter 27000, loss: 0.031717
 >> iter 28000, loss: 0.076410
 >> iter 29000, loss: 0.089104
 >> iter 30000, loss: 0.064937
   Number of active neurons: 10
 >> iter 31000, loss: 0.030179
 >> iter 32000, loss: 0.023427
 >> iter 33000, loss: 0.011707
 >> iter 34000, loss: 0.007190
 >> iter 35000, loss: 0.005342
 >> iter 36000, loss: 0.005279
 >> iter 37000, loss: 0.005666
 >> iter 38000, loss: 0.005091
 >> iter 39000, loss: 0.004130
 >> iter 40000, loss: 0.051586
   Number of active neurons: 10
 >> iter 41000, loss: 0.021306
 >> iter 42000, loss: 0.009816
 >> iter 43000, loss: 0.007150
 >> iter 44000, loss: 0.005965
 >> iter 45000, loss: 0.004382
 >> iter 46000, loss: 0.007621
 >> iter 47000, loss: 0.016763
 >> iter 48000, loss: 0.014358
 >> iter 49000, loss: 0.007154
 >> iter 50000, loss: 0.004252
   Number of active neurons: 10
 >> iter 51000, loss: 0.028784
 >> iter 52000, loss: 0.012912
 >> iter 53000, loss: 0.044778
 >> iter 54000, loss: 0.018835
 >> iter 55000, loss: 0.008413
 >> iter 56000, loss: 0.004309
 >> iter 57000, loss: 0.024668
 >> iter 58000, loss: 0.059280
 >> iter 59000, loss: 0.023738
 >> iter 60000, loss: 0.010347
   Number of active neurons: 10
 >> iter 61000, loss: 0.005333
 >> iter 62000, loss: 0.005011
 >> iter 63000, loss: 0.003121
 >> iter 64000, loss: 0.002777
 >> iter 65000, loss: 0.018652
 >> iter 66000, loss: 0.023619
 >> iter 67000, loss: 0.010174
 >> iter 68000, loss: 0.005058
 >> iter 69000, loss: 0.003072
 >> iter 70000, loss: 0.002385
   Number of active neurons: 10
 >> iter 71000, loss: 0.001953
 >> iter 72000, loss: 0.001761
 >> iter 73000, loss: 0.001803
 >> iter 74000, loss: 0.001637
 >> iter 75000, loss: 0.001558
 >> iter 76000, loss: 0.001438
 >> iter 77000, loss: 0.001449
 >> iter 78000, loss: 0.001401
 >> iter 79000, loss: 0.001333
 >> iter 80000, loss: 0.001424
   Number of active neurons: 10
 >> iter 81000, loss: 0.001259
 >> iter 82000, loss: 0.001347
 >> iter 83000, loss: 0.001179
 >> iter 84000, loss: 0.001142
 >> iter 85000, loss: 0.001111
 >> iter 86000, loss: 0.001098
 >> iter 87000, loss: 0.001121
 >> iter 88000, loss: 0.003619
 >> iter 89000, loss: 0.002019
 >> iter 90000, loss: 0.002239
   Number of active neurons: 10
 >> iter 91000, loss: 0.006414
 >> iter 92000, loss: 0.003286
 >> iter 93000, loss: 0.001852
 >> iter 94000, loss: 0.001418
 >> iter 95000, loss: 0.028779
 >> iter 96000, loss: 0.013267
 >> iter 97000, loss: 0.005800
 >> iter 98000, loss: 0.002857
 >> iter 99000, loss: 0.001846
 >> iter 100000, loss: 0.001239
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.944098
 >> iter 2000, loss: 10.116347
 >> iter 3000, loss: 4.243002
 >> iter 4000, loss: 1.980951
 >> iter 5000, loss: 0.808461
 >> iter 6000, loss: 0.357673
 >> iter 7000, loss: 0.161675
 >> iter 8000, loss: 0.248262
 >> iter 9000, loss: 0.113076
 >> iter 10000, loss: 0.333756
   Number of active neurons: 10
 >> iter 11000, loss: 0.198735
 >> iter 12000, loss: 0.085372
 >> iter 13000, loss: 0.041968
 >> iter 14000, loss: 0.022326
 >> iter 15000, loss: 0.184972
 >> iter 16000, loss: 0.127974
 >> iter 17000, loss: 0.054434
 >> iter 18000, loss: 0.025997
 >> iter 19000, loss: 0.016233
 >> iter 20000, loss: 0.012560
   Number of active neurons: 10
 >> iter 21000, loss: 0.009974
 >> iter 22000, loss: 0.008335
 >> iter 23000, loss: 0.007210
 >> iter 24000, loss: 0.051165
 >> iter 25000, loss: 0.040299
 >> iter 26000, loss: 0.036333
 >> iter 27000, loss: 0.018414
 >> iter 28000, loss: 0.010893
 >> iter 29000, loss: 0.011910
 >> iter 30000, loss: 0.013029
   Number of active neurons: 10
 >> iter 31000, loss: 0.011565
 >> iter 32000, loss: 0.133184
 >> iter 33000, loss: 0.053017
 >> iter 34000, loss: 0.029053
 >> iter 35000, loss: 0.025962
 >> iter 36000, loss: 0.045431
 >> iter 37000, loss: 0.019710
 >> iter 38000, loss: 0.011642
 >> iter 39000, loss: 0.102204
 >> iter 40000, loss: 0.042883
   Number of active neurons: 10
 >> iter 41000, loss: 0.018252
 >> iter 42000, loss: 0.012715
 >> iter 43000, loss: 0.015078
 >> iter 44000, loss: 0.014827
 >> iter 45000, loss: 0.007777
 >> iter 46000, loss: 0.005212
 >> iter 47000, loss: 0.004584
 >> iter 48000, loss: 0.003437
 >> iter 49000, loss: 0.035051
 >> iter 50000, loss: 0.014846
   Number of active neurons: 10
 >> iter 51000, loss: 0.007292
 >> iter 52000, loss: 0.004415
 >> iter 53000, loss: 0.004478
 >> iter 54000, loss: 0.003561
 >> iter 55000, loss: 0.040603
 >> iter 56000, loss: 0.020528
 >> iter 57000, loss: 0.112792
 >> iter 58000, loss: 0.043410
 >> iter 59000, loss: 0.018414
 >> iter 60000, loss: 0.008775
   Number of active neurons: 10
 >> iter 61000, loss: 0.010304
 >> iter 62000, loss: 0.005675
 >> iter 63000, loss: 0.004250
 >> iter 64000, loss: 0.002956
 >> iter 65000, loss: 0.027503
 >> iter 66000, loss: 0.013117
 >> iter 67000, loss: 0.059152
 >> iter 68000, loss: 0.039251
 >> iter 69000, loss: 0.016498
 >> iter 70000, loss: 0.007514
   Number of active neurons: 10
 >> iter 71000, loss: 0.004214
 >> iter 72000, loss: 0.002962
 >> iter 73000, loss: 0.003252
 >> iter 74000, loss: 0.002391
 >> iter 75000, loss: 0.002087
 >> iter 76000, loss: 0.001872
 >> iter 77000, loss: 0.001765
 >> iter 78000, loss: 0.001690
 >> iter 79000, loss: 0.001752
 >> iter 80000, loss: 0.001622
   Number of active neurons: 10
 >> iter 81000, loss: 0.001650
 >> iter 82000, loss: 0.001564
 >> iter 83000, loss: 0.001724
 >> iter 84000, loss: 0.001471
 >> iter 85000, loss: 0.001519
 >> iter 86000, loss: 0.001416
 >> iter 87000, loss: 0.001400
 >> iter 88000, loss: 0.001385
 >> iter 89000, loss: 0.001343
 >> iter 90000, loss: 0.001289
   Number of active neurons: 10
 >> iter 91000, loss: 0.001278
 >> iter 92000, loss: 0.001429
 >> iter 93000, loss: 0.001493
 >> iter 94000, loss: 0.001221
 >> iter 95000, loss: 0.001394
 >> iter 96000, loss: 0.001227
 >> iter 97000, loss: 0.001182
 >> iter 98000, loss: 0.001261
 >> iter 99000, loss: 0.001119
 >> iter 100000, loss: 0.056665
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.052220
 >> iter 2000, loss: 11.196479
 >> iter 3000, loss: 5.259312
 >> iter 4000, loss: 2.246046
 >> iter 5000, loss: 0.945914
 >> iter 6000, loss: 0.475157
 >> iter 7000, loss: 0.262845
 >> iter 8000, loss: 0.128528
 >> iter 9000, loss: 0.172183
 >> iter 10000, loss: 0.237879
   Number of active neurons: 10
 >> iter 11000, loss: 0.143339
 >> iter 12000, loss: 0.243680
 >> iter 13000, loss: 0.140512
 >> iter 14000, loss: 0.066164
 >> iter 15000, loss: 0.073181
 >> iter 16000, loss: 0.089469
 >> iter 17000, loss: 0.040783
 >> iter 18000, loss: 0.085447
 >> iter 19000, loss: 0.042345
 >> iter 20000, loss: 0.021567
   Number of active neurons: 10
 >> iter 21000, loss: 0.013735
 >> iter 22000, loss: 0.026770
 >> iter 23000, loss: 0.015430
 >> iter 24000, loss: 0.008909
 >> iter 25000, loss: 0.021220
 >> iter 26000, loss: 0.042377
 >> iter 27000, loss: 0.109164
 >> iter 28000, loss: 0.063616
 >> iter 29000, loss: 0.245776
 >> iter 30000, loss: 0.097067
   Number of active neurons: 10
 >> iter 31000, loss: 0.087709
 >> iter 32000, loss: 0.048531
 >> iter 33000, loss: 0.023962
 >> iter 34000, loss: 0.012953
 >> iter 35000, loss: 0.008106
 >> iter 36000, loss: 0.005805
 >> iter 37000, loss: 0.004732
 >> iter 38000, loss: 0.004588
 >> iter 39000, loss: 0.004287
 >> iter 40000, loss: 0.009606
   Number of active neurons: 10
 >> iter 41000, loss: 0.007173
 >> iter 42000, loss: 0.007664
 >> iter 43000, loss: 0.005272
 >> iter 44000, loss: 0.041774
 >> iter 45000, loss: 0.018756
 >> iter 46000, loss: 0.008795
 >> iter 47000, loss: 0.014418
 >> iter 48000, loss: 0.063432
 >> iter 49000, loss: 0.025795
 >> iter 50000, loss: 0.011286
   Number of active neurons: 10
 >> iter 51000, loss: 0.005966
 >> iter 52000, loss: 0.003715
 >> iter 53000, loss: 0.002941
 >> iter 54000, loss: 0.003487
 >> iter 55000, loss: 0.002726
 >> iter 56000, loss: 0.002290
 >> iter 57000, loss: 0.141645
 >> iter 58000, loss: 0.053929
 >> iter 59000, loss: 0.029103
 >> iter 60000, loss: 0.012156
   Number of active neurons: 10
 >> iter 61000, loss: 0.005891
 >> iter 62000, loss: 0.015365
 >> iter 63000, loss: 0.007261
 >> iter 64000, loss: 0.003854
 >> iter 65000, loss: 0.006926
 >> iter 66000, loss: 0.003945
 >> iter 67000, loss: 0.003011
 >> iter 68000, loss: 0.044194
 >> iter 69000, loss: 0.034329
 >> iter 70000, loss: 0.014208
   Number of active neurons: 10
 >> iter 71000, loss: 0.006300
 >> iter 72000, loss: 0.003951
 >> iter 73000, loss: 0.002638
 >> iter 74000, loss: 0.093658
 >> iter 75000, loss: 0.097316
 >> iter 76000, loss: 0.069599
 >> iter 77000, loss: 0.027406
 >> iter 78000, loss: 0.011732
 >> iter 79000, loss: 0.013016
 >> iter 80000, loss: 0.016528
   Number of active neurons: 10
 >> iter 81000, loss: 0.007649
 >> iter 82000, loss: 0.004210
 >> iter 83000, loss: 0.010250
 >> iter 84000, loss: 0.005031
 >> iter 85000, loss: 0.003014
 >> iter 86000, loss: 0.002056
 >> iter 87000, loss: 0.001769
 >> iter 88000, loss: 0.002143
 >> iter 89000, loss: 0.002422
 >> iter 90000, loss: 0.003099
   Number of active neurons: 10
 >> iter 91000, loss: 0.002500
 >> iter 92000, loss: 0.002161
 >> iter 93000, loss: 0.021567
 >> iter 94000, loss: 0.009075
 >> iter 95000, loss: 0.004371
 >> iter 96000, loss: 0.002449
 >> iter 97000, loss: 0.001836
 >> iter 98000, loss: 0.118283
 >> iter 99000, loss: 0.071002
 >> iter 100000, loss: 0.041603
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

