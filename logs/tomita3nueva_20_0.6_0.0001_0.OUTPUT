 > Problema: tomita3nueva
 > Args:
   - Hidden size: 20
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.148005
 >> iter 2000, loss: 11.186966
 >> iter 3000, loss: 4.887560
 >> iter 4000, loss: 2.103113
 >> iter 5000, loss: 1.118642
 >> iter 6000, loss: 0.573206
 >> iter 7000, loss: 0.582609
 >> iter 8000, loss: 0.342817
 >> iter 9000, loss: 0.328838
 >> iter 10000, loss: 0.343198
   Number of active neurons: 11
 >> iter 11000, loss: 0.283756
 >> iter 12000, loss: 0.243379
 >> iter 13000, loss: 0.267100
 >> iter 14000, loss: 0.192981
 >> iter 15000, loss: 0.251968
 >> iter 16000, loss: 0.350227
 >> iter 17000, loss: 0.323091
 >> iter 18000, loss: 0.206554
 >> iter 19000, loss: 0.233343
 >> iter 20000, loss: 0.460128
   Number of active neurons: 9
 >> iter 21000, loss: 0.347347
 >> iter 22000, loss: 0.187526
 >> iter 23000, loss: 0.152943
 >> iter 24000, loss: 0.126014
 >> iter 25000, loss: 0.323339
 >> iter 26000, loss: 0.291304
 >> iter 27000, loss: 0.268377
 >> iter 28000, loss: 0.318825
 >> iter 29000, loss: 0.238181
 >> iter 30000, loss: 0.284076
   Number of active neurons: 9
 >> iter 31000, loss: 0.279147
 >> iter 32000, loss: 0.234595
 >> iter 33000, loss: 0.225107
 >> iter 34000, loss: 0.283434
 >> iter 35000, loss: 0.386458
 >> iter 36000, loss: 0.287465
 >> iter 37000, loss: 0.267531
 >> iter 38000, loss: 0.223608
 >> iter 39000, loss: 0.323083
 >> iter 40000, loss: 0.372073
   Number of active neurons: 7
 >> iter 41000, loss: 0.202060
 >> iter 42000, loss: 0.172023
 >> iter 43000, loss: 0.175531
 >> iter 44000, loss: 0.129438
 >> iter 45000, loss: 0.224902
 >> iter 46000, loss: 0.253415
 >> iter 47000, loss: 0.151851
 >> iter 48000, loss: 0.336639
 >> iter 49000, loss: 0.278846
 >> iter 50000, loss: 0.317347
   Number of active neurons: 7
 >> iter 51000, loss: 0.207355
 >> iter 52000, loss: 0.424973
 >> iter 53000, loss: 0.298042
 >> iter 54000, loss: 0.200952
 >> iter 55000, loss: 0.254868
 >> iter 56000, loss: 0.469892
 >> iter 57000, loss: 0.381406
 >> iter 58000, loss: 0.366571
 >> iter 59000, loss: 0.289651
 >> iter 60000, loss: 0.169526
   Number of active neurons: 7
 >> iter 61000, loss: 0.315247
 >> iter 62000, loss: 0.268915
 >> iter 63000, loss: 0.298720
 >> iter 64000, loss: 0.176128
 >> iter 65000, loss: 0.248103
 >> iter 66000, loss: 0.290571
 >> iter 67000, loss: 0.238081
 >> iter 68000, loss: 0.142950
 >> iter 69000, loss: 0.097466
 >> iter 70000, loss: 0.193166
   Number of active neurons: 6
 >> iter 71000, loss: 0.171302
 >> iter 72000, loss: 0.177579
 >> iter 73000, loss: 0.114273
 >> iter 74000, loss: 0.263807
 >> iter 75000, loss: 0.243711
 >> iter 76000, loss: 0.275112
 >> iter 77000, loss: 0.560695
 >> iter 78000, loss: 0.416109
 >> iter 79000, loss: 0.248782
 >> iter 80000, loss: 0.320676
   Number of active neurons: 5
 >> iter 81000, loss: 0.224814
 >> iter 82000, loss: 0.260862
 >> iter 83000, loss: 0.230817
 >> iter 84000, loss: 0.191892
 >> iter 85000, loss: 0.128573
 >> iter 86000, loss: 0.132880
 >> iter 87000, loss: 0.292751
 >> iter 88000, loss: 0.184396
 >> iter 89000, loss: 0.280791
 >> iter 90000, loss: 0.208203
   Number of active neurons: 5
 >> iter 91000, loss: 0.258648
 >> iter 92000, loss: 0.333483
 >> iter 93000, loss: 0.290224
 >> iter 94000, loss: 0.225403
 >> iter 95000, loss: 0.186434
 >> iter 96000, loss: 0.233823
 >> iter 97000, loss: 0.151014
 >> iter 98000, loss: 0.245554
 >> iter 99000, loss: 0.266291
 >> iter 100000, loss: 0.259674
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.836927
 >> iter 2000, loss: 10.459831
 >> iter 3000, loss: 4.672262
 >> iter 4000, loss: 2.158434
 >> iter 5000, loss: 1.076904
 >> iter 6000, loss: 0.742714
 >> iter 7000, loss: 0.809889
 >> iter 8000, loss: 0.570202
 >> iter 9000, loss: 0.489029
 >> iter 10000, loss: 0.460437
   Number of active neurons: 9
 >> iter 11000, loss: 0.474652
 >> iter 12000, loss: 0.409625
 >> iter 13000, loss: 0.514621
 >> iter 14000, loss: 0.323807
 >> iter 15000, loss: 0.382026
 >> iter 16000, loss: 0.337320
 >> iter 17000, loss: 0.356030
 >> iter 18000, loss: 0.369142
 >> iter 19000, loss: 0.341680
 >> iter 20000, loss: 0.267780
   Number of active neurons: 9
 >> iter 21000, loss: 0.366863
 >> iter 22000, loss: 0.377218
 >> iter 23000, loss: 0.234301
 >> iter 24000, loss: 0.359171
 >> iter 25000, loss: 0.340873
 >> iter 26000, loss: 0.391989
 >> iter 27000, loss: 0.332586
 >> iter 28000, loss: 0.434159
 >> iter 29000, loss: 0.563204
 >> iter 30000, loss: 0.398777
   Number of active neurons: 8
 >> iter 31000, loss: 0.332015
 >> iter 32000, loss: 0.409094
 >> iter 33000, loss: 0.550339
 >> iter 34000, loss: 0.386279
 >> iter 35000, loss: 0.373789
 >> iter 36000, loss: 0.472845
 >> iter 37000, loss: 0.420231
 >> iter 38000, loss: 0.343430
 >> iter 39000, loss: 0.333510
 >> iter 40000, loss: 0.238085
   Number of active neurons: 8
 >> iter 41000, loss: 0.302837
 >> iter 42000, loss: 0.227071
 >> iter 43000, loss: 0.262313
 >> iter 44000, loss: 0.337401
 >> iter 45000, loss: 0.243522
 >> iter 46000, loss: 0.378851
 >> iter 47000, loss: 0.359695
 >> iter 48000, loss: 0.264655
 >> iter 49000, loss: 0.539705
 >> iter 50000, loss: 0.323098
   Number of active neurons: 8
 >> iter 51000, loss: 0.300003
 >> iter 52000, loss: 0.317870
 >> iter 53000, loss: 0.329879
 >> iter 54000, loss: 0.278502
 >> iter 55000, loss: 0.259016
 >> iter 56000, loss: 0.450332
 >> iter 57000, loss: 0.369431
 >> iter 58000, loss: 0.286780
 >> iter 59000, loss: 0.221718
 >> iter 60000, loss: 0.177070
   Number of active neurons: 6
 >> iter 61000, loss: 0.210612
 >> iter 62000, loss: 0.330654
 >> iter 63000, loss: 0.278186
 >> iter 64000, loss: 0.291311
 >> iter 65000, loss: 0.262692
 >> iter 66000, loss: 0.226466
 >> iter 67000, loss: 0.366424
 >> iter 68000, loss: 0.336995
 >> iter 69000, loss: 0.364545
 >> iter 70000, loss: 0.216990
   Number of active neurons: 6
 >> iter 71000, loss: 0.193192
 >> iter 72000, loss: 0.211919
 >> iter 73000, loss: 0.151077
 >> iter 74000, loss: 0.215364
 >> iter 75000, loss: 0.245046
 >> iter 76000, loss: 0.184560
 >> iter 77000, loss: 0.142595
 >> iter 78000, loss: 0.134153
 >> iter 79000, loss: 0.171074
 >> iter 80000, loss: 0.185923
   Number of active neurons: 5
 >> iter 81000, loss: 0.229640
 >> iter 82000, loss: 0.147209
 >> iter 83000, loss: 0.140006
 >> iter 84000, loss: 0.165838
 >> iter 85000, loss: 0.170263
 >> iter 86000, loss: 0.211436
 >> iter 87000, loss: 0.217737
 >> iter 88000, loss: 0.184176
 >> iter 89000, loss: 0.146421
 >> iter 90000, loss: 0.164779
   Number of active neurons: 5
 >> iter 91000, loss: 0.211494
 >> iter 92000, loss: 0.279078
 >> iter 93000, loss: 0.226702
 >> iter 94000, loss: 0.306224
 >> iter 95000, loss: 0.282044
 >> iter 96000, loss: 0.277947
 >> iter 97000, loss: 0.256917
 >> iter 98000, loss: 0.168639
 >> iter 99000, loss: 0.365938
 >> iter 100000, loss: 0.250612
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.974957
 >> iter 2000, loss: 11.828060
 >> iter 3000, loss: 5.184598
 >> iter 4000, loss: 2.418302
 >> iter 5000, loss: 1.132150
 >> iter 6000, loss: 0.523454
 >> iter 7000, loss: 0.520789
 >> iter 8000, loss: 0.402103
 >> iter 9000, loss: 0.384468
 >> iter 10000, loss: 0.471243
   Number of active neurons: 10
 >> iter 11000, loss: 0.355547
 >> iter 12000, loss: 0.303392
 >> iter 13000, loss: 0.209324
 >> iter 14000, loss: 0.269160
 >> iter 15000, loss: 0.328265
 >> iter 16000, loss: 0.200022
 >> iter 17000, loss: 0.217268
 >> iter 18000, loss: 0.329454
 >> iter 19000, loss: 0.333733
 >> iter 20000, loss: 0.312245
   Number of active neurons: 10
 >> iter 21000, loss: 0.319961
 >> iter 22000, loss: 0.316390
 >> iter 23000, loss: 0.222016
 >> iter 24000, loss: 0.262306
 >> iter 25000, loss: 0.282816
 >> iter 26000, loss: 0.187022
 >> iter 27000, loss: 0.207947
 >> iter 28000, loss: 0.182014
 >> iter 29000, loss: 0.122136
 >> iter 30000, loss: 0.361262
   Number of active neurons: 10
 >> iter 31000, loss: 0.220423
 >> iter 32000, loss: 0.341334
 >> iter 33000, loss: 0.310589
 >> iter 34000, loss: 0.205898
 >> iter 35000, loss: 0.148979
 >> iter 36000, loss: 0.290942
 >> iter 37000, loss: 0.235105
 >> iter 38000, loss: 0.278690
 >> iter 39000, loss: 0.226482
 >> iter 40000, loss: 0.572447
   Number of active neurons: 8
 >> iter 41000, loss: 0.313023
 >> iter 42000, loss: 0.233004
 >> iter 43000, loss: 0.237851
 >> iter 44000, loss: 0.157161
 >> iter 45000, loss: 0.235593
 >> iter 46000, loss: 0.205103
 >> iter 47000, loss: 0.165632
 >> iter 48000, loss: 0.231237
 >> iter 49000, loss: 0.317612
 >> iter 50000, loss: 0.221732
   Number of active neurons: 6
 >> iter 51000, loss: 0.276764
 >> iter 52000, loss: 0.244955
 >> iter 53000, loss: 0.264893
 >> iter 54000, loss: 0.207205
 >> iter 55000, loss: 0.318939
 >> iter 56000, loss: 0.291114
 >> iter 57000, loss: 0.150792
 >> iter 58000, loss: 0.200396
 >> iter 59000, loss: 0.172300
 >> iter 60000, loss: 0.320868
   Number of active neurons: 6
 >> iter 61000, loss: 0.324445
 >> iter 62000, loss: 0.163265
 >> iter 63000, loss: 0.208812
 >> iter 64000, loss: 0.231414
 >> iter 65000, loss: 0.228767
 >> iter 66000, loss: 0.256742
 >> iter 67000, loss: 0.264302
 >> iter 68000, loss: 0.246749
 >> iter 69000, loss: 0.182515
 >> iter 70000, loss: 0.176458
   Number of active neurons: 6
 >> iter 71000, loss: 0.241592
 >> iter 72000, loss: 0.271878
 >> iter 73000, loss: 0.160721
 >> iter 74000, loss: 0.337124
 >> iter 75000, loss: 0.231087
 >> iter 76000, loss: 0.213685
 >> iter 77000, loss: 0.211604
 >> iter 78000, loss: 0.284848
 >> iter 79000, loss: 0.206458
 >> iter 80000, loss: 0.311716
   Number of active neurons: 5
 >> iter 81000, loss: 0.330865
 >> iter 82000, loss: 0.200399
 >> iter 83000, loss: 0.193127
 >> iter 84000, loss: 0.152192
 >> iter 85000, loss: 0.250141
 >> iter 86000, loss: 0.235142
 >> iter 87000, loss: 0.368146
 >> iter 88000, loss: 0.240643
 >> iter 89000, loss: 0.198430
 >> iter 90000, loss: 0.190943
   Number of active neurons: 4
 >> iter 91000, loss: 0.128637
 >> iter 92000, loss: 0.182390
 >> iter 93000, loss: 0.262552
 >> iter 94000, loss: 0.229432
 >> iter 95000, loss: 0.182107
 >> iter 96000, loss: 0.226662
 >> iter 97000, loss: 0.176274
 >> iter 98000, loss: 0.363423
 >> iter 99000, loss: 0.289513
 >> iter 100000, loss: 0.234827
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 19.361828
 >> iter 2000, loss: 11.502108
 >> iter 3000, loss: 4.982730
 >> iter 4000, loss: 2.260844
 >> iter 5000, loss: 1.074607
 >> iter 6000, loss: 0.589214
 >> iter 7000, loss: 0.571933
 >> iter 8000, loss: 0.498161
 >> iter 9000, loss: 0.387929
 >> iter 10000, loss: 0.258231
   Number of active neurons: 9
 >> iter 11000, loss: 0.330472
 >> iter 12000, loss: 0.240839
 >> iter 13000, loss: 0.208878
 >> iter 14000, loss: 0.199213
 >> iter 15000, loss: 0.256293
 >> iter 16000, loss: 0.292657
 >> iter 17000, loss: 0.252320
 >> iter 18000, loss: 0.216769
 >> iter 19000, loss: 0.237499
 >> iter 20000, loss: 0.207657
   Number of active neurons: 9
 >> iter 21000, loss: 0.202040
 >> iter 22000, loss: 0.244148
 >> iter 23000, loss: 0.343835
 >> iter 24000, loss: 0.299803
 >> iter 25000, loss: 0.358237
 >> iter 26000, loss: 0.350042
 >> iter 27000, loss: 0.265717
 >> iter 28000, loss: 0.205855
 >> iter 29000, loss: 0.146576
 >> iter 30000, loss: 0.130072
   Number of active neurons: 8
 >> iter 31000, loss: 0.254607
 >> iter 32000, loss: 0.245162
 >> iter 33000, loss: 0.219832
 >> iter 34000, loss: 0.325336
 >> iter 35000, loss: 0.195846
 >> iter 36000, loss: 0.189634
 >> iter 37000, loss: 0.312965
 >> iter 38000, loss: 0.209521
 >> iter 39000, loss: 0.156865
 >> iter 40000, loss: 0.192670
   Number of active neurons: 8
 >> iter 41000, loss: 0.157708
 >> iter 42000, loss: 0.229397
 >> iter 43000, loss: 0.194740
 >> iter 44000, loss: 0.219213
 >> iter 45000, loss: 0.372836
 >> iter 46000, loss: 0.293915
 >> iter 47000, loss: 0.283916
 >> iter 48000, loss: 0.304037
 >> iter 49000, loss: 0.333501
 >> iter 50000, loss: 0.260818
   Number of active neurons: 8
 >> iter 51000, loss: 0.317526
 >> iter 52000, loss: 0.220024
 >> iter 53000, loss: 0.220055
 >> iter 54000, loss: 0.268796
 >> iter 55000, loss: 0.249028
 >> iter 56000, loss: 0.224875
 >> iter 57000, loss: 0.339746
 >> iter 58000, loss: 0.235950
 >> iter 59000, loss: 0.171551
 >> iter 60000, loss: 0.182218
   Number of active neurons: 7
 >> iter 61000, loss: 0.147371
 >> iter 62000, loss: 0.257380
 >> iter 63000, loss: 0.209706
 >> iter 64000, loss: 0.131487
 >> iter 65000, loss: 0.347492
 >> iter 66000, loss: 0.277124
 >> iter 67000, loss: 0.197832
 >> iter 68000, loss: 0.310188
 >> iter 69000, loss: 0.275748
 >> iter 70000, loss: 0.193166
   Number of active neurons: 7
 >> iter 71000, loss: 0.191703
 >> iter 72000, loss: 0.209919
 >> iter 73000, loss: 0.250233
 >> iter 74000, loss: 0.229052
 >> iter 75000, loss: 0.188751
 >> iter 76000, loss: 0.194568
 >> iter 77000, loss: 0.213249
 >> iter 78000, loss: 0.205324
 >> iter 79000, loss: 0.180567
 >> iter 80000, loss: 0.112142
   Number of active neurons: 7
 >> iter 81000, loss: 0.237559
 >> iter 82000, loss: 0.260363
 >> iter 83000, loss: 0.302621
 >> iter 84000, loss: 0.284116
 >> iter 85000, loss: 0.322921
 >> iter 86000, loss: 0.170248
 >> iter 87000, loss: 0.210597
 >> iter 88000, loss: 0.225386
 >> iter 89000, loss: 0.168360
 >> iter 90000, loss: 0.270385
   Number of active neurons: 7
 >> iter 91000, loss: 0.220446
 >> iter 92000, loss: 0.134378
 >> iter 93000, loss: 0.146552
 >> iter 94000, loss: 0.151762
 >> iter 95000, loss: 0.184037
 >> iter 96000, loss: 0.276998
 >> iter 97000, loss: 0.258590
 >> iter 98000, loss: 0.205123
 >> iter 99000, loss: 0.186721
 >> iter 100000, loss: 0.239284
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.776024
 >> iter 2000, loss: 9.360326
 >> iter 3000, loss: 4.185026
 >> iter 4000, loss: 1.798963
 >> iter 5000, loss: 0.913443
 >> iter 6000, loss: 0.552966
 >> iter 7000, loss: 0.506053
 >> iter 8000, loss: 0.351237
 >> iter 9000, loss: 0.447870
 >> iter 10000, loss: 0.313310
   Number of active neurons: 7
 >> iter 11000, loss: 0.334426
 >> iter 12000, loss: 0.416605
 >> iter 13000, loss: 0.438064
 >> iter 14000, loss: 0.400084
 >> iter 15000, loss: 0.338070
 >> iter 16000, loss: 0.336197
 >> iter 17000, loss: 0.415301
 >> iter 18000, loss: 0.338116
 >> iter 19000, loss: 0.404906
 >> iter 20000, loss: 0.324126
   Number of active neurons: 7
 >> iter 21000, loss: 0.420991
 >> iter 22000, loss: 0.379089
 >> iter 23000, loss: 0.458396
 >> iter 24000, loss: 0.335341
 >> iter 25000, loss: 0.336088
 >> iter 26000, loss: 0.356648
 >> iter 27000, loss: 0.400809
 >> iter 28000, loss: 0.377776
 >> iter 29000, loss: 0.278826
 >> iter 30000, loss: 0.336077
   Number of active neurons: 7
 >> iter 31000, loss: 0.342868
 >> iter 32000, loss: 0.299282
 >> iter 33000, loss: 0.270668
 >> iter 34000, loss: 0.300201
 >> iter 35000, loss: 0.289485
 >> iter 36000, loss: 0.349288
 >> iter 37000, loss: 0.361971
 >> iter 38000, loss: 0.254516
 >> iter 39000, loss: 0.184221
 >> iter 40000, loss: 0.234911
   Number of active neurons: 7
 >> iter 41000, loss: 0.178746
 >> iter 42000, loss: 0.194484
 >> iter 43000, loss: 0.172096
 >> iter 44000, loss: 0.205493
 >> iter 45000, loss: 0.259607
 >> iter 46000, loss: 0.244298
 >> iter 47000, loss: 0.269870
 >> iter 48000, loss: 0.312191
 >> iter 49000, loss: 0.185503
 >> iter 50000, loss: 0.197502
   Number of active neurons: 6
 >> iter 51000, loss: 0.221209
 >> iter 52000, loss: 0.270710
 >> iter 53000, loss: 0.195446
 >> iter 54000, loss: 0.141790
 >> iter 55000, loss: 0.159625
 >> iter 56000, loss: 0.207995
 >> iter 57000, loss: 0.145941
 >> iter 58000, loss: 0.197777
 >> iter 59000, loss: 0.144712
 >> iter 60000, loss: 0.279336
   Number of active neurons: 6
 >> iter 61000, loss: 0.298069
 >> iter 62000, loss: 0.287976
 >> iter 63000, loss: 0.195121
 >> iter 64000, loss: 0.148186
 >> iter 65000, loss: 0.169046
 >> iter 66000, loss: 0.163416
 >> iter 67000, loss: 0.281453
 >> iter 68000, loss: 0.235329
 >> iter 69000, loss: 0.258572
 >> iter 70000, loss: 0.171652
   Number of active neurons: 5
 >> iter 71000, loss: 0.211769
 >> iter 72000, loss: 0.175143
 >> iter 73000, loss: 0.224513
 >> iter 74000, loss: 0.191578
 >> iter 75000, loss: 0.214411
 >> iter 76000, loss: 0.185795
 >> iter 77000, loss: 0.187408
 >> iter 78000, loss: 0.200968
 >> iter 79000, loss: 0.280498
 >> iter 80000, loss: 0.249526
   Number of active neurons: 4
 >> iter 81000, loss: 0.246938
 >> iter 82000, loss: 0.181878
 >> iter 83000, loss: 0.217821
 >> iter 84000, loss: 0.179702
 >> iter 85000, loss: 0.226454
 >> iter 86000, loss: 0.190633
 >> iter 87000, loss: 0.179516
 >> iter 88000, loss: 0.290806
 >> iter 89000, loss: 0.199745
 >> iter 90000, loss: 0.161106
   Number of active neurons: 4
 >> iter 91000, loss: 0.222897
 >> iter 92000, loss: 0.255001
 >> iter 93000, loss: 0.279063
 >> iter 94000, loss: 0.259530
 >> iter 95000, loss: 0.226343
 >> iter 96000, loss: 0.222134
 >> iter 97000, loss: 0.301669
 >> iter 98000, loss: 0.216934
 >> iter 99000, loss: 0.166655
 >> iter 100000, loss: 0.172404
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.242557
 >> iter 2000, loss: 11.349957
 >> iter 3000, loss: 5.952843
 >> iter 4000, loss: 2.910070
 >> iter 5000, loss: 1.513635
 >> iter 6000, loss: 0.922721
 >> iter 7000, loss: 0.785156
 >> iter 8000, loss: 0.655394
 >> iter 9000, loss: 0.613080
 >> iter 10000, loss: 0.537206
   Number of active neurons: 6
 >> iter 11000, loss: 0.462605
 >> iter 12000, loss: 0.543931
 >> iter 13000, loss: 0.378581
 >> iter 14000, loss: 0.396507
 >> iter 15000, loss: 0.391519
 >> iter 16000, loss: 0.320506
 >> iter 17000, loss: 0.637843
 >> iter 18000, loss: 0.473578
 >> iter 19000, loss: 0.393816
 >> iter 20000, loss: 0.521479
   Number of active neurons: 6
 >> iter 21000, loss: 0.428935
 >> iter 22000, loss: 0.368095
 >> iter 23000, loss: 0.453701
 >> iter 24000, loss: 0.406357
 >> iter 25000, loss: 0.347955
 >> iter 26000, loss: 0.500003
 >> iter 27000, loss: 0.353817
 >> iter 28000, loss: 0.422775
 >> iter 29000, loss: 0.400868
 >> iter 30000, loss: 0.368856
   Number of active neurons: 6
 >> iter 31000, loss: 0.393142
 >> iter 32000, loss: 0.345124
 >> iter 33000, loss: 0.479237
 >> iter 34000, loss: 0.367393
 >> iter 35000, loss: 0.355460
 >> iter 36000, loss: 0.345107
 >> iter 37000, loss: 0.322585
 >> iter 38000, loss: 0.296630
 >> iter 39000, loss: 0.363340
 >> iter 40000, loss: 0.528947
   Number of active neurons: 6
 >> iter 41000, loss: 0.516152
 >> iter 42000, loss: 0.318273
 >> iter 43000, loss: 0.248187
 >> iter 44000, loss: 0.280245
 >> iter 45000, loss: 0.716113
 >> iter 46000, loss: 0.640561
 >> iter 47000, loss: 0.698454
 >> iter 48000, loss: 0.501401
 >> iter 49000, loss: 0.375472
 >> iter 50000, loss: 0.417936
   Number of active neurons: 6
 >> iter 51000, loss: 0.487969
 >> iter 52000, loss: 0.477738
 >> iter 53000, loss: 0.491184
 >> iter 54000, loss: 0.281306
 >> iter 55000, loss: 0.320997
 >> iter 56000, loss: 0.412694
 >> iter 57000, loss: 0.329284
 >> iter 58000, loss: 0.460964
 >> iter 59000, loss: 0.326927
 >> iter 60000, loss: 0.307397
   Number of active neurons: 6
 >> iter 61000, loss: 0.360500
 >> iter 62000, loss: 0.400545
 >> iter 63000, loss: 0.419461
 >> iter 64000, loss: 0.267611
 >> iter 65000, loss: 0.363176
 >> iter 66000, loss: 0.376854
 >> iter 67000, loss: 0.372373
 >> iter 68000, loss: 0.336678
 >> iter 69000, loss: 0.286920
 >> iter 70000, loss: 0.258673
   Number of active neurons: 6
 >> iter 71000, loss: 0.376953
 >> iter 72000, loss: 0.367386
 >> iter 73000, loss: 0.499485
 >> iter 74000, loss: 0.332047
 >> iter 75000, loss: 0.353361
 >> iter 76000, loss: 0.426892
 >> iter 77000, loss: 0.330094
 >> iter 78000, loss: 0.432993
 >> iter 79000, loss: 0.528041
 >> iter 80000, loss: 0.486601
   Number of active neurons: 6
 >> iter 81000, loss: 0.447660
 >> iter 82000, loss: 0.374594
 >> iter 83000, loss: 0.367944
 >> iter 84000, loss: 0.407581
 >> iter 85000, loss: 0.595722
 >> iter 86000, loss: 0.496918
 >> iter 87000, loss: 0.356989
 >> iter 88000, loss: 0.456450
 >> iter 89000, loss: 0.507013
 >> iter 90000, loss: 0.499303
   Number of active neurons: 6
 >> iter 91000, loss: 0.404968
 >> iter 92000, loss: 0.363878
 >> iter 93000, loss: 0.439442
 >> iter 94000, loss: 0.464167
 >> iter 95000, loss: 0.324121
 >> iter 96000, loss: 0.469062
 >> iter 97000, loss: 0.309555
 >> iter 98000, loss: 0.347320
 >> iter 99000, loss: 0.487235
 >> iter 100000, loss: 0.412056
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.062282
 >> iter 2000, loss: 10.834309
 >> iter 3000, loss: 5.058452
 >> iter 4000, loss: 2.267340
 >> iter 5000, loss: 1.309926
 >> iter 6000, loss: 0.746936
 >> iter 7000, loss: 0.437314
 >> iter 8000, loss: 0.446988
 >> iter 9000, loss: 0.410405
 >> iter 10000, loss: 0.349718
   Number of active neurons: 10
 >> iter 11000, loss: 0.416607
 >> iter 12000, loss: 0.365701
 >> iter 13000, loss: 0.569530
 >> iter 14000, loss: 0.347218
 >> iter 15000, loss: 0.403914
 >> iter 16000, loss: 0.260749
 >> iter 17000, loss: 0.318023
 >> iter 18000, loss: 0.224814
 >> iter 19000, loss: 0.234354
 >> iter 20000, loss: 0.246327
   Number of active neurons: 10
 >> iter 21000, loss: 0.292487
 >> iter 22000, loss: 0.286751
 >> iter 23000, loss: 0.315951
 >> iter 24000, loss: 0.277407
 >> iter 25000, loss: 0.192869
 >> iter 26000, loss: 0.223072
 >> iter 27000, loss: 0.407278
 >> iter 28000, loss: 0.378741
 >> iter 29000, loss: 0.213089
 >> iter 30000, loss: 0.364505
   Number of active neurons: 9
 >> iter 31000, loss: 0.357898
 >> iter 32000, loss: 0.228071
 >> iter 33000, loss: 0.150891
 >> iter 34000, loss: 0.145190
 >> iter 35000, loss: 0.221054
 >> iter 36000, loss: 0.255232
 >> iter 37000, loss: 0.255397
 >> iter 38000, loss: 0.218736
 >> iter 39000, loss: 0.256767
 >> iter 40000, loss: 0.210613
   Number of active neurons: 9
 >> iter 41000, loss: 0.252770
 >> iter 42000, loss: 0.169482
 >> iter 43000, loss: 0.197046
 >> iter 44000, loss: 0.200378
 >> iter 45000, loss: 0.220831
 >> iter 46000, loss: 0.228133
 >> iter 47000, loss: 0.323405
 >> iter 48000, loss: 0.257120
 >> iter 49000, loss: 0.163794
 >> iter 50000, loss: 0.104427
   Number of active neurons: 5
 >> iter 51000, loss: 0.183841
 >> iter 52000, loss: 0.261149
 >> iter 53000, loss: 0.168502
 >> iter 54000, loss: 0.443199
 >> iter 55000, loss: 0.379554
 >> iter 56000, loss: 0.341130
 >> iter 57000, loss: 0.342527
 >> iter 58000, loss: 0.229740
 >> iter 59000, loss: 0.200983
 >> iter 60000, loss: 0.345354
   Number of active neurons: 5
 >> iter 61000, loss: 0.266532
 >> iter 62000, loss: 0.322899
 >> iter 63000, loss: 0.255744
 >> iter 64000, loss: 0.201734
 >> iter 65000, loss: 0.246738
 >> iter 66000, loss: 0.219320
 >> iter 67000, loss: 0.263602
 >> iter 68000, loss: 0.446775
 >> iter 69000, loss: 0.266785
 >> iter 70000, loss: 0.292201
   Number of active neurons: 5
 >> iter 71000, loss: 0.184482
 >> iter 72000, loss: 0.227161
 >> iter 73000, loss: 0.193310
 >> iter 74000, loss: 0.156180
 >> iter 75000, loss: 0.211713
 >> iter 76000, loss: 0.224041
 >> iter 77000, loss: 0.271325
 >> iter 78000, loss: 0.269039
 >> iter 79000, loss: 0.377206
 >> iter 80000, loss: 0.292185
   Number of active neurons: 5
 >> iter 81000, loss: 0.224818
 >> iter 82000, loss: 0.152977
 >> iter 83000, loss: 0.275043
 >> iter 84000, loss: 0.290711
 >> iter 85000, loss: 0.210931
 >> iter 86000, loss: 0.209257
 >> iter 87000, loss: 0.161460
 >> iter 88000, loss: 0.335652
 >> iter 89000, loss: 0.276069
 >> iter 90000, loss: 0.206371
   Number of active neurons: 5
 >> iter 91000, loss: 0.333172
 >> iter 92000, loss: 0.242143
 >> iter 93000, loss: 0.130634
 >> iter 94000, loss: 0.126562
 >> iter 95000, loss: 0.139142
 >> iter 96000, loss: 0.108545
 >> iter 97000, loss: 0.273703
 >> iter 98000, loss: 0.157968
 >> iter 99000, loss: 0.175164
 >> iter 100000, loss: 0.221399
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.124747
 >> iter 2000, loss: 13.571538
 >> iter 3000, loss: 7.229848
 >> iter 4000, loss: 3.434888
 >> iter 5000, loss: 1.827731
 >> iter 6000, loss: 1.255560
 >> iter 7000, loss: 1.223360
 >> iter 8000, loss: 0.989203
 >> iter 9000, loss: 0.914898
 >> iter 10000, loss: 0.589504
   Number of active neurons: 7
 >> iter 11000, loss: 0.650376
 >> iter 12000, loss: 0.622466
 >> iter 13000, loss: 0.792461
 >> iter 14000, loss: 0.653346
 >> iter 15000, loss: 0.505286
 >> iter 16000, loss: 0.487382
 >> iter 17000, loss: 0.318581
 >> iter 18000, loss: 0.416859
 >> iter 19000, loss: 0.614244
 >> iter 20000, loss: 0.410282
   Number of active neurons: 6
 >> iter 21000, loss: 0.637750
 >> iter 22000, loss: 0.485605
 >> iter 23000, loss: 0.331545
 >> iter 24000, loss: 0.378577
 >> iter 25000, loss: 0.478264
 >> iter 26000, loss: 0.447701
 >> iter 27000, loss: 0.428326
 >> iter 28000, loss: 0.466548
 >> iter 29000, loss: 0.516300
 >> iter 30000, loss: 0.594978
   Number of active neurons: 7
 >> iter 31000, loss: 0.557525
 >> iter 32000, loss: 0.529571
 >> iter 33000, loss: 0.602354
 >> iter 34000, loss: 0.450290
 >> iter 35000, loss: 0.355771
 >> iter 36000, loss: 0.451281
 >> iter 37000, loss: 0.521443
 >> iter 38000, loss: 0.594464
 >> iter 39000, loss: 0.762760
 >> iter 40000, loss: 0.630215
   Number of active neurons: 6
 >> iter 41000, loss: 0.743919
 >> iter 42000, loss: 0.593256
 >> iter 43000, loss: 0.594515
 >> iter 44000, loss: 0.391186
 >> iter 45000, loss: 0.391834
 >> iter 46000, loss: 0.376136
 >> iter 47000, loss: 0.397595
 >> iter 48000, loss: 0.447585
 >> iter 49000, loss: 0.458930
 >> iter 50000, loss: 0.341255
   Number of active neurons: 6
 >> iter 51000, loss: 0.572472
 >> iter 52000, loss: 0.584764
 >> iter 53000, loss: 0.426620
 >> iter 54000, loss: 0.540670
 >> iter 55000, loss: 0.488509
 >> iter 56000, loss: 0.561381
 >> iter 57000, loss: 0.371500
 >> iter 58000, loss: 0.519164
 >> iter 59000, loss: 0.575108
 >> iter 60000, loss: 0.488002
   Number of active neurons: 6
 >> iter 61000, loss: 0.529396
 >> iter 62000, loss: 0.410104
 >> iter 63000, loss: 0.532981
 >> iter 64000, loss: 0.551548
 >> iter 65000, loss: 0.445251
 >> iter 66000, loss: 0.513159
 >> iter 67000, loss: 0.521945
 >> iter 68000, loss: 0.499496
 >> iter 69000, loss: 0.544968
 >> iter 70000, loss: 0.466331
   Number of active neurons: 7
 >> iter 71000, loss: 0.706817
 >> iter 72000, loss: 0.526315
 >> iter 73000, loss: 0.586958
 >> iter 74000, loss: 0.533658
 >> iter 75000, loss: 0.451254
 >> iter 76000, loss: 0.261643
 >> iter 77000, loss: 0.285859
 >> iter 78000, loss: 0.335177
 >> iter 79000, loss: 0.431793
 >> iter 80000, loss: 0.361305
   Number of active neurons: 6
 >> iter 81000, loss: 0.406147
 >> iter 82000, loss: 0.418046
 >> iter 83000, loss: 0.432483
 >> iter 84000, loss: 0.374336
 >> iter 85000, loss: 0.525809
 >> iter 86000, loss: 0.482479
 >> iter 87000, loss: 0.429798
 >> iter 88000, loss: 0.405166
 >> iter 89000, loss: 0.394787
 >> iter 90000, loss: 0.333240
   Number of active neurons: 6
 >> iter 91000, loss: 0.616289
 >> iter 92000, loss: 0.555257
 >> iter 93000, loss: 0.469210
 >> iter 94000, loss: 0.319881
 >> iter 95000, loss: 0.646519
 >> iter 96000, loss: 0.467163
 >> iter 97000, loss: 0.273275
 >> iter 98000, loss: 0.598733
 >> iter 99000, loss: 0.542372
 >> iter 100000, loss: 0.390442
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.342385
 >> iter 2000, loss: 12.290359
 >> iter 3000, loss: 5.714675
 >> iter 4000, loss: 2.585299
 >> iter 5000, loss: 1.419340
 >> iter 6000, loss: 0.684232
 >> iter 7000, loss: 0.678986
 >> iter 8000, loss: 0.496710
 >> iter 9000, loss: 0.371192
 >> iter 10000, loss: 0.332458
   Number of active neurons: 11
 >> iter 11000, loss: 0.616163
 >> iter 12000, loss: 0.505695
 >> iter 13000, loss: 0.406399
 >> iter 14000, loss: 0.287165
 >> iter 15000, loss: 0.244666
 >> iter 16000, loss: 0.328982
 >> iter 17000, loss: 0.297781
 >> iter 18000, loss: 0.200538
 >> iter 19000, loss: 0.446213
 >> iter 20000, loss: 0.275619
   Number of active neurons: 11
 >> iter 21000, loss: 0.472180
 >> iter 22000, loss: 0.324573
 >> iter 23000, loss: 0.405772
 >> iter 24000, loss: 0.307513
 >> iter 25000, loss: 0.405176
 >> iter 26000, loss: 0.420893
 >> iter 27000, loss: 0.335929
 >> iter 28000, loss: 0.301130
 >> iter 29000, loss: 0.279436
 >> iter 30000, loss: 0.279634
   Number of active neurons: 10
 >> iter 31000, loss: 0.302573
 >> iter 32000, loss: 0.203729
 >> iter 33000, loss: 0.341383
 >> iter 34000, loss: 0.247516
 >> iter 35000, loss: 0.241581
 >> iter 36000, loss: 0.203730
 >> iter 37000, loss: 0.196322
 >> iter 38000, loss: 0.418684
 >> iter 39000, loss: 0.521123
 >> iter 40000, loss: 0.415215
   Number of active neurons: 10
 >> iter 41000, loss: 0.335771
 >> iter 42000, loss: 0.328871
 >> iter 43000, loss: 0.328382
 >> iter 44000, loss: 0.291366
 >> iter 45000, loss: 0.234298
 >> iter 46000, loss: 0.302723
 >> iter 47000, loss: 0.256970
 >> iter 48000, loss: 0.409478
 >> iter 49000, loss: 0.273549
 >> iter 50000, loss: 0.316866
   Number of active neurons: 10
 >> iter 51000, loss: 0.446622
 >> iter 52000, loss: 0.344869
 >> iter 53000, loss: 0.230397
 >> iter 54000, loss: 0.274849
 >> iter 55000, loss: 0.191973
 >> iter 56000, loss: 0.276236
 >> iter 57000, loss: 0.322960
 >> iter 58000, loss: 0.348186
 >> iter 59000, loss: 0.219291
 >> iter 60000, loss: 0.171892
   Number of active neurons: 9
 >> iter 61000, loss: 0.162915
 >> iter 62000, loss: 0.222098
 >> iter 63000, loss: 0.385268
 >> iter 64000, loss: 0.391672
 >> iter 65000, loss: 0.340839
 >> iter 66000, loss: 0.266918
 >> iter 67000, loss: 0.335769
 >> iter 68000, loss: 0.343272
 >> iter 69000, loss: 0.205025
 >> iter 70000, loss: 0.256396
   Number of active neurons: 9
 >> iter 71000, loss: 0.369774
 >> iter 72000, loss: 0.343097
 >> iter 73000, loss: 0.369551
 >> iter 74000, loss: 0.371286
 >> iter 75000, loss: 0.346099
 >> iter 76000, loss: 0.226702
 >> iter 77000, loss: 0.262133
 >> iter 78000, loss: 0.220065
 >> iter 79000, loss: 0.173695
 >> iter 80000, loss: 0.244980
   Number of active neurons: 9
 >> iter 81000, loss: 0.212332
 >> iter 82000, loss: 0.197893
 >> iter 83000, loss: 0.260967
 >> iter 84000, loss: 0.313827
 >> iter 85000, loss: 0.314201
 >> iter 86000, loss: 0.220695
 >> iter 87000, loss: 0.203982
 >> iter 88000, loss: 0.152747
 >> iter 89000, loss: 0.171046
 >> iter 90000, loss: 0.258686
   Number of active neurons: 9
 >> iter 91000, loss: 0.368732
 >> iter 92000, loss: 0.215631
 >> iter 93000, loss: 0.125702
 >> iter 94000, loss: 0.327548
 >> iter 95000, loss: 0.188330
 >> iter 96000, loss: 0.298835
 >> iter 97000, loss: 0.192710
 >> iter 98000, loss: 0.213799
 >> iter 99000, loss: 0.238276
 >> iter 100000, loss: 0.233923
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.055346
 >> iter 2000, loss: 10.789526
 >> iter 3000, loss: 5.001147
 >> iter 4000, loss: 2.081529
 >> iter 5000, loss: 1.133440
 >> iter 6000, loss: 0.929052
 >> iter 7000, loss: 0.743035
 >> iter 8000, loss: 0.562795
 >> iter 9000, loss: 0.523364
 >> iter 10000, loss: 0.433990
   Number of active neurons: 9
 >> iter 11000, loss: 0.342188
 >> iter 12000, loss: 0.368304
 >> iter 13000, loss: 0.582199
 >> iter 14000, loss: 0.362244
 >> iter 15000, loss: 0.333946
 >> iter 16000, loss: 0.388209
 >> iter 17000, loss: 0.371146
 >> iter 18000, loss: 0.370096
 >> iter 19000, loss: 0.344640
 >> iter 20000, loss: 0.257180
   Number of active neurons: 8
 >> iter 21000, loss: 0.336291
 >> iter 22000, loss: 0.321227
 >> iter 23000, loss: 0.573469
 >> iter 24000, loss: 0.574890
 >> iter 25000, loss: 0.454758
 >> iter 26000, loss: 0.303971
 >> iter 27000, loss: 0.314024
 >> iter 28000, loss: 0.249197
 >> iter 29000, loss: 0.406734
 >> iter 30000, loss: 0.283811
   Number of active neurons: 8
 >> iter 31000, loss: 0.258739
 >> iter 32000, loss: 0.412495
 >> iter 33000, loss: 0.374211
 >> iter 34000, loss: 0.367723
 >> iter 35000, loss: 0.393431
 >> iter 36000, loss: 0.289473
 >> iter 37000, loss: 0.243849
 >> iter 38000, loss: 0.312439
 >> iter 39000, loss: 0.310100
 >> iter 40000, loss: 0.244913
   Number of active neurons: 7
 >> iter 41000, loss: 0.223909
 >> iter 42000, loss: 0.196411
 >> iter 43000, loss: 0.227931
 >> iter 44000, loss: 0.173547
 >> iter 45000, loss: 0.359955
 >> iter 46000, loss: 0.342749
 >> iter 47000, loss: 0.259035
 >> iter 48000, loss: 0.185409
 >> iter 49000, loss: 0.239156
 >> iter 50000, loss: 0.175287
   Number of active neurons: 7
 >> iter 51000, loss: 0.236519
 >> iter 52000, loss: 0.304264
 >> iter 53000, loss: 0.346068
 >> iter 54000, loss: 0.266416
 >> iter 55000, loss: 0.186851
 >> iter 56000, loss: 0.179082
 >> iter 57000, loss: 0.302712
 >> iter 58000, loss: 0.197827
 >> iter 59000, loss: 0.234679
 >> iter 60000, loss: 0.226580
   Number of active neurons: 7
 >> iter 61000, loss: 0.296401
 >> iter 62000, loss: 0.214007
 >> iter 63000, loss: 0.174878
 >> iter 64000, loss: 0.242643
 >> iter 65000, loss: 0.267973
 >> iter 66000, loss: 0.179047
 >> iter 67000, loss: 0.218216
 >> iter 68000, loss: 0.168247
 >> iter 69000, loss: 0.185922
 >> iter 70000, loss: 0.264134
   Number of active neurons: 7
 >> iter 71000, loss: 0.170026
 >> iter 72000, loss: 0.181206
 >> iter 73000, loss: 0.146086
 >> iter 74000, loss: 0.209378
 >> iter 75000, loss: 0.153799
 >> iter 76000, loss: 0.174296
 >> iter 77000, loss: 0.358673
 >> iter 78000, loss: 0.206973
 >> iter 79000, loss: 0.450221
 >> iter 80000, loss: 0.317863
   Number of active neurons: 6
 >> iter 81000, loss: 0.233106
 >> iter 82000, loss: 0.278675
 >> iter 83000, loss: 0.250775
 >> iter 84000, loss: 0.283952
 >> iter 85000, loss: 0.191946
 >> iter 86000, loss: 0.137904
 >> iter 87000, loss: 0.401051
 >> iter 88000, loss: 0.379882
 >> iter 89000, loss: 0.251521
 >> iter 90000, loss: 0.191957
   Number of active neurons: 5
 >> iter 91000, loss: 0.349477
 >> iter 92000, loss: 0.265731
 >> iter 93000, loss: 0.382266
 >> iter 94000, loss: 0.265678
 >> iter 95000, loss: 0.293466
 >> iter 96000, loss: 0.211364
 >> iter 97000, loss: 0.255839
 >> iter 98000, loss: 0.197260
 >> iter 99000, loss: 0.232598
 >> iter 100000, loss: 0.199487
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.163679
 >> iter 2000, loss: 11.384332
 >> iter 3000, loss: 4.998625
 >> iter 4000, loss: 2.310392
 >> iter 5000, loss: 1.094186
 >> iter 6000, loss: 0.605032
 >> iter 7000, loss: 0.564452
 >> iter 8000, loss: 0.319365
 >> iter 9000, loss: 0.406869
 >> iter 10000, loss: 0.264142
   Number of active neurons: 11
 >> iter 11000, loss: 0.247545
 >> iter 12000, loss: 0.398919
 >> iter 13000, loss: 0.245844
 >> iter 14000, loss: 0.296664
 >> iter 15000, loss: 0.240119
 >> iter 16000, loss: 0.228804
 >> iter 17000, loss: 0.202732
 >> iter 18000, loss: 0.190701
 >> iter 19000, loss: 0.513230
 >> iter 20000, loss: 0.343983
   Number of active neurons: 10
 >> iter 21000, loss: 0.395382
 >> iter 22000, loss: 0.203993
 >> iter 23000, loss: 0.269591
 >> iter 24000, loss: 0.181183
 >> iter 25000, loss: 0.263344
 >> iter 26000, loss: 0.214514
 >> iter 27000, loss: 0.279128
 >> iter 28000, loss: 0.209008
 >> iter 29000, loss: 0.356655
 >> iter 30000, loss: 0.334328
   Number of active neurons: 9
 >> iter 31000, loss: 0.228764
 >> iter 32000, loss: 0.184453
 >> iter 33000, loss: 0.160387
 >> iter 34000, loss: 0.262126
 >> iter 35000, loss: 0.327245
 >> iter 36000, loss: 0.174948
 >> iter 37000, loss: 0.192674
 >> iter 38000, loss: 0.210004
 >> iter 39000, loss: 0.163322
 >> iter 40000, loss: 0.178581
   Number of active neurons: 7
 >> iter 41000, loss: 0.297578
 >> iter 42000, loss: 0.339627
 >> iter 43000, loss: 0.239167
 >> iter 44000, loss: 0.205288
 >> iter 45000, loss: 0.211833
 >> iter 46000, loss: 0.165984
 >> iter 47000, loss: 0.152604
 >> iter 48000, loss: 0.159330
 >> iter 49000, loss: 0.184793
 >> iter 50000, loss: 0.225591
   Number of active neurons: 7
 >> iter 51000, loss: 0.265207
 >> iter 52000, loss: 0.307426
 >> iter 53000, loss: 0.316003
 >> iter 54000, loss: 0.227811
 >> iter 55000, loss: 0.120032
 >> iter 56000, loss: 0.155457
 >> iter 57000, loss: 0.178444
 >> iter 58000, loss: 0.161554
 >> iter 59000, loss: 0.173157
 >> iter 60000, loss: 0.263488
   Number of active neurons: 6
 >> iter 61000, loss: 0.194201
 >> iter 62000, loss: 0.213614
 >> iter 63000, loss: 0.203100
 >> iter 64000, loss: 0.172840
 >> iter 65000, loss: 0.149156
 >> iter 66000, loss: 0.114940
 >> iter 67000, loss: 0.212672
 >> iter 68000, loss: 0.175370
 >> iter 69000, loss: 0.224015
 >> iter 70000, loss: 0.290709
   Number of active neurons: 6
 >> iter 71000, loss: 0.219364
 >> iter 72000, loss: 0.209561
 >> iter 73000, loss: 0.207016
 >> iter 74000, loss: 0.155578
 >> iter 75000, loss: 0.183242
 >> iter 76000, loss: 0.156975
 >> iter 77000, loss: 0.245580
 >> iter 78000, loss: 0.281410
 >> iter 79000, loss: 0.221854
 >> iter 80000, loss: 0.188329
   Number of active neurons: 6
 >> iter 81000, loss: 0.199009
 >> iter 82000, loss: 0.133864
 >> iter 83000, loss: 0.100391
 >> iter 84000, loss: 0.229582
 >> iter 85000, loss: 0.213166
 >> iter 86000, loss: 0.415013
 >> iter 87000, loss: 0.285834
 >> iter 88000, loss: 0.165437
 >> iter 89000, loss: 0.161700
 >> iter 90000, loss: 0.210564
   Number of active neurons: 5
 >> iter 91000, loss: 0.252174
 >> iter 92000, loss: 0.217019
 >> iter 93000, loss: 0.180147
 >> iter 94000, loss: 0.139471
 >> iter 95000, loss: 0.214751
 >> iter 96000, loss: 0.195999
 >> iter 97000, loss: 0.120868
 >> iter 98000, loss: 0.149066
 >> iter 99000, loss: 0.254438
 >> iter 100000, loss: 0.191261
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 18.954592
 >> iter 2000, loss: 12.449953
 >> iter 3000, loss: 5.905617
 >> iter 4000, loss: 2.706524
 >> iter 5000, loss: 1.213060
 >> iter 6000, loss: 0.747921
 >> iter 7000, loss: 0.579794
 >> iter 8000, loss: 0.475468
 >> iter 9000, loss: 0.393172
 >> iter 10000, loss: 0.436464
   Number of active neurons: 10
 >> iter 11000, loss: 0.434048
 >> iter 12000, loss: 0.393724
 >> iter 13000, loss: 0.262992
 >> iter 14000, loss: 0.289442
 >> iter 15000, loss: 0.362301
 >> iter 16000, loss: 0.319785
 >> iter 17000, loss: 0.295293
 >> iter 18000, loss: 0.380027
 >> iter 19000, loss: 0.362251
 >> iter 20000, loss: 0.239704
   Number of active neurons: 10
 >> iter 21000, loss: 0.271308
 >> iter 22000, loss: 0.449610
 >> iter 23000, loss: 0.354602
 >> iter 24000, loss: 0.368497
 >> iter 25000, loss: 0.336070
 >> iter 26000, loss: 0.227953
 >> iter 27000, loss: 0.411721
 >> iter 28000, loss: 0.349826
 >> iter 29000, loss: 0.268158
 >> iter 30000, loss: 0.267223
   Number of active neurons: 9
 >> iter 31000, loss: 0.276865
 >> iter 32000, loss: 0.394071
 >> iter 33000, loss: 0.293779
 >> iter 34000, loss: 0.319730
 >> iter 35000, loss: 0.313845
 >> iter 36000, loss: 0.212591
 >> iter 37000, loss: 0.502810
 >> iter 38000, loss: 0.262472
 >> iter 39000, loss: 0.297709
 >> iter 40000, loss: 0.197997
   Number of active neurons: 9
 >> iter 41000, loss: 0.238741
 >> iter 42000, loss: 0.320591
 >> iter 43000, loss: 0.402443
 >> iter 44000, loss: 0.371449
 >> iter 45000, loss: 0.273180
 >> iter 46000, loss: 0.232801
 >> iter 47000, loss: 0.279786
 >> iter 48000, loss: 0.262823
 >> iter 49000, loss: 0.141690
 >> iter 50000, loss: 0.185548
   Number of active neurons: 9
 >> iter 51000, loss: 0.351979
 >> iter 52000, loss: 0.239177
 >> iter 53000, loss: 0.357036
 >> iter 54000, loss: 0.311388
 >> iter 55000, loss: 0.209848
 >> iter 56000, loss: 0.201836
 >> iter 57000, loss: 0.197547
 >> iter 58000, loss: 0.208372
 >> iter 59000, loss: 0.294568
 >> iter 60000, loss: 0.220990
   Number of active neurons: 9
 >> iter 61000, loss: 0.265499
 >> iter 62000, loss: 0.344577
 >> iter 63000, loss: 0.218024
 >> iter 64000, loss: 0.176813
 >> iter 65000, loss: 0.162758
 >> iter 66000, loss: 0.170855
 >> iter 67000, loss: 0.235767
 >> iter 68000, loss: 0.363335
 >> iter 69000, loss: 0.275986
 >> iter 70000, loss: 0.234396
   Number of active neurons: 7
 >> iter 71000, loss: 0.211896
 >> iter 72000, loss: 0.164835
 >> iter 73000, loss: 0.161139
 >> iter 74000, loss: 0.153976
 >> iter 75000, loss: 0.266235
 >> iter 76000, loss: 0.192804
 >> iter 77000, loss: 0.186487
 >> iter 78000, loss: 0.302344
 >> iter 79000, loss: 0.268569
 >> iter 80000, loss: 0.151141
   Number of active neurons: 7
 >> iter 81000, loss: 0.220375
 >> iter 82000, loss: 0.291476
 >> iter 83000, loss: 0.199353
 >> iter 84000, loss: 0.293627
 >> iter 85000, loss: 0.193585
 >> iter 86000, loss: 0.324752
 >> iter 87000, loss: 0.248657
 >> iter 88000, loss: 0.286177
 >> iter 89000, loss: 0.273386
 >> iter 90000, loss: 0.200388
   Number of active neurons: 5
 >> iter 91000, loss: 0.228507
 >> iter 92000, loss: 0.307698
 >> iter 93000, loss: 0.235105
 >> iter 94000, loss: 0.167357
 >> iter 95000, loss: 0.163170
 >> iter 96000, loss: 0.210834
 >> iter 97000, loss: 0.189659
 >> iter 98000, loss: 0.141076
 >> iter 99000, loss: 0.129207
 >> iter 100000, loss: 0.146407
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.161851
 >> iter 2000, loss: 11.709023
 >> iter 3000, loss: 5.159324
 >> iter 4000, loss: 2.358433
 >> iter 5000, loss: 1.226901
 >> iter 6000, loss: 0.696609
 >> iter 7000, loss: 0.554501
 >> iter 8000, loss: 0.462007
 >> iter 9000, loss: 0.313840
 >> iter 10000, loss: 0.278746
   Number of active neurons: 10
 >> iter 11000, loss: 0.284533
 >> iter 12000, loss: 0.248307
 >> iter 13000, loss: 0.187132
 >> iter 14000, loss: 0.480788
 >> iter 15000, loss: 0.378483
 >> iter 16000, loss: 0.319368
 >> iter 17000, loss: 0.216139
 >> iter 18000, loss: 0.277640
 >> iter 19000, loss: 0.335027
 >> iter 20000, loss: 0.376446
   Number of active neurons: 9
 >> iter 21000, loss: 0.320199
 >> iter 22000, loss: 0.292706
 >> iter 23000, loss: 0.294233
 >> iter 24000, loss: 0.235649
 >> iter 25000, loss: 0.218539
 >> iter 26000, loss: 0.258043
 >> iter 27000, loss: 0.302509
 >> iter 28000, loss: 0.326952
 >> iter 29000, loss: 0.256228
 >> iter 30000, loss: 0.440367
   Number of active neurons: 9
 >> iter 31000, loss: 0.463694
 >> iter 32000, loss: 0.312713
 >> iter 33000, loss: 0.486870
 >> iter 34000, loss: 0.338803
 >> iter 35000, loss: 0.196357
 >> iter 36000, loss: 0.223521
 >> iter 37000, loss: 0.246802
 >> iter 38000, loss: 0.269419
 >> iter 39000, loss: 0.348487
 >> iter 40000, loss: 0.411582
   Number of active neurons: 9
 >> iter 41000, loss: 0.252831
 >> iter 42000, loss: 0.393675
 >> iter 43000, loss: 0.316870
 >> iter 44000, loss: 0.329894
 >> iter 45000, loss: 0.257868
 >> iter 46000, loss: 0.389491
 >> iter 47000, loss: 0.215764
 >> iter 48000, loss: 0.183569
 >> iter 49000, loss: 0.252298
 >> iter 50000, loss: 0.303486
   Number of active neurons: 9
 >> iter 51000, loss: 0.284907
 >> iter 52000, loss: 0.183503
 >> iter 53000, loss: 0.263344
 >> iter 54000, loss: 0.252912
 >> iter 55000, loss: 0.249673
 >> iter 56000, loss: 0.254003
 >> iter 57000, loss: 0.439399
 >> iter 58000, loss: 0.312813
 >> iter 59000, loss: 0.196622
 >> iter 60000, loss: 0.187345
   Number of active neurons: 7
 >> iter 61000, loss: 0.274562
 >> iter 62000, loss: 0.270979
 >> iter 63000, loss: 0.215692
 >> iter 64000, loss: 0.271396
 >> iter 65000, loss: 0.382382
 >> iter 66000, loss: 0.200611
 >> iter 67000, loss: 0.239411
 >> iter 68000, loss: 0.256156
 >> iter 69000, loss: 0.198413
 >> iter 70000, loss: 0.169776
   Number of active neurons: 6
 >> iter 71000, loss: 0.122873
 >> iter 72000, loss: 0.121981
 >> iter 73000, loss: 0.112262
 >> iter 74000, loss: 0.176158
 >> iter 75000, loss: 0.252577
 >> iter 76000, loss: 0.150990
 >> iter 77000, loss: 0.170097
 >> iter 78000, loss: 0.153728
 >> iter 79000, loss: 0.139135
 >> iter 80000, loss: 0.324103
   Number of active neurons: 6
 >> iter 81000, loss: 0.316926
 >> iter 82000, loss: 0.275087
 >> iter 83000, loss: 0.236734
 >> iter 84000, loss: 0.171639
 >> iter 85000, loss: 0.250201
 >> iter 86000, loss: 0.350166
 >> iter 87000, loss: 0.216763
 >> iter 88000, loss: 0.115841
 >> iter 89000, loss: 0.151482
 >> iter 90000, loss: 0.270936
   Number of active neurons: 6
 >> iter 91000, loss: 0.163527
 >> iter 92000, loss: 0.252181
 >> iter 93000, loss: 0.176484
 >> iter 94000, loss: 0.243827
 >> iter 95000, loss: 0.170874
 >> iter 96000, loss: 0.180860
 >> iter 97000, loss: 0.238560
 >> iter 98000, loss: 0.266133
 >> iter 99000, loss: 0.198025
 >> iter 100000, loss: 0.248955
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.921280
 >> iter 2000, loss: 11.111894
 >> iter 3000, loss: 5.035958
 >> iter 4000, loss: 2.115790
 >> iter 5000, loss: 1.201403
 >> iter 6000, loss: 0.834056
 >> iter 7000, loss: 0.507177
 >> iter 8000, loss: 0.708760
 >> iter 9000, loss: 0.613981
 >> iter 10000, loss: 0.551524
   Number of active neurons: 9
 >> iter 11000, loss: 0.405968
 >> iter 12000, loss: 0.500309
 >> iter 13000, loss: 0.564418
 >> iter 14000, loss: 0.334184
 >> iter 15000, loss: 0.388281
 >> iter 16000, loss: 0.274537
 >> iter 17000, loss: 0.380382
 >> iter 18000, loss: 0.269938
 >> iter 19000, loss: 0.296825
 >> iter 20000, loss: 0.407431
   Number of active neurons: 9
 >> iter 21000, loss: 0.444652
 >> iter 22000, loss: 0.368924
 >> iter 23000, loss: 0.363474
 >> iter 24000, loss: 0.644820
 >> iter 25000, loss: 0.408766
 >> iter 26000, loss: 0.300169
 >> iter 27000, loss: 0.490024
 >> iter 28000, loss: 0.428101
 >> iter 29000, loss: 0.336546
 >> iter 30000, loss: 0.390002
   Number of active neurons: 8
 >> iter 31000, loss: 0.411687
 >> iter 32000, loss: 0.344321
 >> iter 33000, loss: 0.422084
 >> iter 34000, loss: 0.420418
 >> iter 35000, loss: 0.455602
 >> iter 36000, loss: 0.316431
 >> iter 37000, loss: 0.315301
 >> iter 38000, loss: 0.260272
 >> iter 39000, loss: 0.331550
 >> iter 40000, loss: 0.411317
   Number of active neurons: 8
 >> iter 41000, loss: 0.351946
 >> iter 42000, loss: 0.315897
 >> iter 43000, loss: 0.276688
 >> iter 44000, loss: 0.310798
 >> iter 45000, loss: 0.333034
 >> iter 46000, loss: 0.293798
 >> iter 47000, loss: 0.216377
 >> iter 48000, loss: 0.313569
 >> iter 49000, loss: 0.230744
 >> iter 50000, loss: 0.328305
   Number of active neurons: 8
 >> iter 51000, loss: 0.367220
 >> iter 52000, loss: 0.438516
 >> iter 53000, loss: 0.283474
 >> iter 54000, loss: 0.204531
 >> iter 55000, loss: 0.274827
 >> iter 56000, loss: 0.188257
 >> iter 57000, loss: 0.151245
 >> iter 58000, loss: 0.219541
 >> iter 59000, loss: 0.132803
 >> iter 60000, loss: 0.157325
   Number of active neurons: 8
 >> iter 61000, loss: 0.139477
 >> iter 62000, loss: 0.246596
 >> iter 63000, loss: 0.213830
 >> iter 64000, loss: 0.191012
 >> iter 65000, loss: 0.144960
 >> iter 66000, loss: 0.215455
 >> iter 67000, loss: 0.180953
 >> iter 68000, loss: 0.172227
 >> iter 69000, loss: 0.217328
 >> iter 70000, loss: 0.145556
   Number of active neurons: 6
 >> iter 71000, loss: 0.264486
 >> iter 72000, loss: 0.297843
 >> iter 73000, loss: 0.359241
 >> iter 74000, loss: 0.230375
 >> iter 75000, loss: 0.190722
 >> iter 76000, loss: 0.176487
 >> iter 77000, loss: 0.205571
 >> iter 78000, loss: 0.212471
 >> iter 79000, loss: 0.178866
 >> iter 80000, loss: 0.179540
   Number of active neurons: 5
 >> iter 81000, loss: 0.310119
 >> iter 82000, loss: 0.275450
 >> iter 83000, loss: 0.225796
 >> iter 84000, loss: 0.389822
 >> iter 85000, loss: 0.359781
 >> iter 86000, loss: 0.246240
 >> iter 87000, loss: 0.145541
 >> iter 88000, loss: 0.143568
 >> iter 89000, loss: 0.242047
 >> iter 90000, loss: 0.285769
   Number of active neurons: 5
 >> iter 91000, loss: 0.166135
 >> iter 92000, loss: 0.159899
 >> iter 93000, loss: 0.252885
 >> iter 94000, loss: 0.151796
 >> iter 95000, loss: 0.168673
 >> iter 96000, loss: 0.157804
 >> iter 97000, loss: 0.346828
 >> iter 98000, loss: 0.292064
 >> iter 99000, loss: 0.211516
 >> iter 100000, loss: 0.172236
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.061948
 >> iter 2000, loss: 12.385583
 >> iter 3000, loss: 5.797368
 >> iter 4000, loss: 2.502524
 >> iter 5000, loss: 1.104787
 >> iter 6000, loss: 0.813427
 >> iter 7000, loss: 0.486581
 >> iter 8000, loss: 0.694147
 >> iter 9000, loss: 0.564211
 >> iter 10000, loss: 0.418477
   Number of active neurons: 9
 >> iter 11000, loss: 0.237939
 >> iter 12000, loss: 0.226023
 >> iter 13000, loss: 0.294173
 >> iter 14000, loss: 0.254400
 >> iter 15000, loss: 0.460582
 >> iter 16000, loss: 0.321264
 >> iter 17000, loss: 0.441085
 >> iter 18000, loss: 0.333966
 >> iter 19000, loss: 0.333440
 >> iter 20000, loss: 0.261366
   Number of active neurons: 7
 >> iter 21000, loss: 0.312474
 >> iter 22000, loss: 0.292649
 >> iter 23000, loss: 0.339995
 >> iter 24000, loss: 0.232009
 >> iter 25000, loss: 0.216700
 >> iter 26000, loss: 0.206414
 >> iter 27000, loss: 0.277369
 >> iter 28000, loss: 0.249308
 >> iter 29000, loss: 0.376039
 >> iter 30000, loss: 0.326120
   Number of active neurons: 6
 >> iter 31000, loss: 0.280992
 >> iter 32000, loss: 0.388055
 >> iter 33000, loss: 0.311431
 >> iter 34000, loss: 0.285898
 >> iter 35000, loss: 0.244268
 >> iter 36000, loss: 0.282597
 >> iter 37000, loss: 0.200917
 >> iter 38000, loss: 0.247007
 >> iter 39000, loss: 0.240009
 >> iter 40000, loss: 0.349531
   Number of active neurons: 6
 >> iter 41000, loss: 0.227975
 >> iter 42000, loss: 0.261093
 >> iter 43000, loss: 0.338490
 >> iter 44000, loss: 0.355931
 >> iter 45000, loss: 0.195473
 >> iter 46000, loss: 0.167684
 >> iter 47000, loss: 0.388869
 >> iter 48000, loss: 0.329543
 >> iter 49000, loss: 0.336107
 >> iter 50000, loss: 0.206837
   Number of active neurons: 6
 >> iter 51000, loss: 0.464413
 >> iter 52000, loss: 0.278791
 >> iter 53000, loss: 0.321407
 >> iter 54000, loss: 0.265540
 >> iter 55000, loss: 0.172659
 >> iter 56000, loss: 0.317753
 >> iter 57000, loss: 0.244384
 >> iter 58000, loss: 0.243714
 >> iter 59000, loss: 0.191437
 >> iter 60000, loss: 0.289677
   Number of active neurons: 6
 >> iter 61000, loss: 0.318478
 >> iter 62000, loss: 0.267214
 >> iter 63000, loss: 0.238355
 >> iter 64000, loss: 0.240418
 >> iter 65000, loss: 0.177137
 >> iter 66000, loss: 0.258559
 >> iter 67000, loss: 0.190708
 >> iter 68000, loss: 0.350710
 >> iter 69000, loss: 0.472825
 >> iter 70000, loss: 0.321227
   Number of active neurons: 6
 >> iter 71000, loss: 0.374116
 >> iter 72000, loss: 0.267596
 >> iter 73000, loss: 0.231282
 >> iter 74000, loss: 0.214522
 >> iter 75000, loss: 0.230500
 >> iter 76000, loss: 0.267230
 >> iter 77000, loss: 0.217418
 >> iter 78000, loss: 0.274324
 >> iter 79000, loss: 0.230869
 >> iter 80000, loss: 0.229672
   Number of active neurons: 6
 >> iter 81000, loss: 0.233853
 >> iter 82000, loss: 0.329437
 >> iter 83000, loss: 0.329252
 >> iter 84000, loss: 0.221228
 >> iter 85000, loss: 0.334137
 >> iter 86000, loss: 0.189060
 >> iter 87000, loss: 0.217545
 >> iter 88000, loss: 0.176512
 >> iter 89000, loss: 0.305851
 >> iter 90000, loss: 0.357306
   Number of active neurons: 6
 >> iter 91000, loss: 0.346425
 >> iter 92000, loss: 0.300985
 >> iter 93000, loss: 0.314736
 >> iter 94000, loss: 0.217718
 >> iter 95000, loss: 0.221174
 >> iter 96000, loss: 0.191294
 >> iter 97000, loss: 0.206471
 >> iter 98000, loss: 0.207766
 >> iter 99000, loss: 0.281675
 >> iter 100000, loss: 0.351396
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.081838
 >> iter 2000, loss: 11.984337
 >> iter 3000, loss: 5.678812
 >> iter 4000, loss: 2.775683
 >> iter 5000, loss: 1.652941
 >> iter 6000, loss: 1.038003
 >> iter 7000, loss: 0.798396
 >> iter 8000, loss: 0.590286
 >> iter 9000, loss: 0.531969
 >> iter 10000, loss: 0.612311
   Number of active neurons: 9
 >> iter 11000, loss: 0.603021
 >> iter 12000, loss: 0.558236
 >> iter 13000, loss: 0.451433
 >> iter 14000, loss: 0.477434
 >> iter 15000, loss: 0.472668
 >> iter 16000, loss: 0.552543
 >> iter 17000, loss: 0.462214
 >> iter 18000, loss: 0.319097
 >> iter 19000, loss: 0.440697
 >> iter 20000, loss: 0.438535
   Number of active neurons: 8
 >> iter 21000, loss: 0.513685
 >> iter 22000, loss: 0.500200
 >> iter 23000, loss: 0.686823
 >> iter 24000, loss: 0.470544
 >> iter 25000, loss: 0.592425
 >> iter 26000, loss: 0.709597
 >> iter 27000, loss: 0.498752
 >> iter 28000, loss: 0.570266
 >> iter 29000, loss: 0.520037
 >> iter 30000, loss: 0.312648
   Number of active neurons: 8
 >> iter 31000, loss: 0.302208
 >> iter 32000, loss: 0.293298
 >> iter 33000, loss: 0.251333
 >> iter 34000, loss: 0.224356
 >> iter 35000, loss: 0.416311
 >> iter 36000, loss: 0.444788
 >> iter 37000, loss: 0.259713
 >> iter 38000, loss: 0.308920
 >> iter 39000, loss: 0.219729
 >> iter 40000, loss: 0.368963
   Number of active neurons: 8
 >> iter 41000, loss: 0.426067
 >> iter 42000, loss: 0.327201
 >> iter 43000, loss: 0.328155
 >> iter 44000, loss: 0.199136
 >> iter 45000, loss: 0.449120
 >> iter 46000, loss: 0.368301
 >> iter 47000, loss: 0.351628
 >> iter 48000, loss: 0.247964
 >> iter 49000, loss: 0.395712
 >> iter 50000, loss: 0.445593
   Number of active neurons: 8
 >> iter 51000, loss: 0.437275
 >> iter 52000, loss: 0.532254
 >> iter 53000, loss: 0.638222
 >> iter 54000, loss: 0.382049
 >> iter 55000, loss: 0.298272
 >> iter 56000, loss: 0.307180
 >> iter 57000, loss: 0.249803
 >> iter 58000, loss: 0.226508
 >> iter 59000, loss: 0.355519
 >> iter 60000, loss: 0.486092
   Number of active neurons: 7
 >> iter 61000, loss: 0.313758
 >> iter 62000, loss: 0.409433
 >> iter 63000, loss: 0.389933
 >> iter 64000, loss: 0.452327
 >> iter 65000, loss: 0.400328
 >> iter 66000, loss: 0.263813
 >> iter 67000, loss: 0.318013
 >> iter 68000, loss: 0.470409
 >> iter 69000, loss: 0.393647
 >> iter 70000, loss: 0.387157
   Number of active neurons: 7
 >> iter 71000, loss: 0.308485
 >> iter 72000, loss: 0.366771
 >> iter 73000, loss: 0.344224
 >> iter 74000, loss: 0.479808
 >> iter 75000, loss: 0.386852
 >> iter 76000, loss: 0.409651
 >> iter 77000, loss: 0.293962
 >> iter 78000, loss: 0.380203
 >> iter 79000, loss: 0.268050
 >> iter 80000, loss: 0.275823
   Number of active neurons: 7
 >> iter 81000, loss: 0.345476
 >> iter 82000, loss: 0.260113
 >> iter 83000, loss: 0.489819
 >> iter 84000, loss: 0.402988
 >> iter 85000, loss: 0.417840
 >> iter 86000, loss: 0.461536
 >> iter 87000, loss: 0.318052
 >> iter 88000, loss: 0.259677
 >> iter 89000, loss: 0.297794
 >> iter 90000, loss: 0.318258
   Number of active neurons: 7
 >> iter 91000, loss: 0.272439
 >> iter 92000, loss: 0.421292
 >> iter 93000, loss: 0.267894
 >> iter 94000, loss: 0.411711
 >> iter 95000, loss: 0.367347
 >> iter 96000, loss: 0.274694
 >> iter 97000, loss: 0.264291
 >> iter 98000, loss: 0.383612
 >> iter 99000, loss: 0.303854
 >> iter 100000, loss: 0.257101
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.068980
 >> iter 2000, loss: 11.513550
 >> iter 3000, loss: 5.555632
 >> iter 4000, loss: 2.522755
 >> iter 5000, loss: 1.172191
 >> iter 6000, loss: 0.781702
 >> iter 7000, loss: 0.581847
 >> iter 8000, loss: 0.545823
 >> iter 9000, loss: 0.518021
 >> iter 10000, loss: 0.329548
   Number of active neurons: 9
 >> iter 11000, loss: 0.297033
 >> iter 12000, loss: 0.247589
 >> iter 13000, loss: 0.311082
 >> iter 14000, loss: 0.279889
 >> iter 15000, loss: 0.329706
 >> iter 16000, loss: 0.340839
 >> iter 17000, loss: 0.406801
 >> iter 18000, loss: 0.332254
 >> iter 19000, loss: 0.353169
 >> iter 20000, loss: 0.281767
   Number of active neurons: 9
 >> iter 21000, loss: 0.255878
 >> iter 22000, loss: 0.311374
 >> iter 23000, loss: 0.449440
 >> iter 24000, loss: 0.413358
 >> iter 25000, loss: 0.303944
 >> iter 26000, loss: 0.485731
 >> iter 27000, loss: 0.316573
 >> iter 28000, loss: 0.240328
 >> iter 29000, loss: 0.254099
 >> iter 30000, loss: 0.345673
   Number of active neurons: 9
 >> iter 31000, loss: 0.265297
 >> iter 32000, loss: 0.215158
 >> iter 33000, loss: 0.224492
 >> iter 34000, loss: 0.354823
 >> iter 35000, loss: 0.331327
 >> iter 36000, loss: 0.424629
 >> iter 37000, loss: 0.472506
 >> iter 38000, loss: 0.336131
 >> iter 39000, loss: 0.351890
 >> iter 40000, loss: 0.357144
   Number of active neurons: 9
 >> iter 41000, loss: 0.375296
 >> iter 42000, loss: 0.391079
 >> iter 43000, loss: 0.457560
 >> iter 44000, loss: 0.305319
 >> iter 45000, loss: 0.613665
 >> iter 46000, loss: 0.434573
 >> iter 47000, loss: 0.343548
 >> iter 48000, loss: 0.388998
 >> iter 49000, loss: 0.369914
 >> iter 50000, loss: 0.302808
   Number of active neurons: 9
 >> iter 51000, loss: 0.403853
 >> iter 52000, loss: 0.339452
 >> iter 53000, loss: 0.244303
 >> iter 54000, loss: 0.351021
 >> iter 55000, loss: 0.452370
 >> iter 56000, loss: 0.317289
 >> iter 57000, loss: 0.473751
 >> iter 58000, loss: 0.263309
 >> iter 59000, loss: 0.317204
 >> iter 60000, loss: 0.427499
   Number of active neurons: 9
 >> iter 61000, loss: 0.335611
 >> iter 62000, loss: 0.297386
 >> iter 63000, loss: 0.403609
 >> iter 64000, loss: 0.244968
 >> iter 65000, loss: 0.278003
 >> iter 66000, loss: 0.331118
 >> iter 67000, loss: 0.339206
 >> iter 68000, loss: 0.274396
 >> iter 69000, loss: 0.299451
 >> iter 70000, loss: 0.223393
   Number of active neurons: 9
 >> iter 71000, loss: 0.343907
 >> iter 72000, loss: 0.288102
 >> iter 73000, loss: 0.207994
 >> iter 74000, loss: 0.221817
 >> iter 75000, loss: 0.244474
 >> iter 76000, loss: 0.261960
 >> iter 77000, loss: 0.245673
 >> iter 78000, loss: 0.204361
 >> iter 79000, loss: 0.178929
 >> iter 80000, loss: 0.217764
   Number of active neurons: 8
 >> iter 81000, loss: 0.388538
 >> iter 82000, loss: 0.332873
 >> iter 83000, loss: 0.351954
 >> iter 84000, loss: 0.233310
 >> iter 85000, loss: 0.248792
 >> iter 86000, loss: 0.233041
 >> iter 87000, loss: 0.330484
 >> iter 88000, loss: 0.277600
 >> iter 89000, loss: 0.278630
 >> iter 90000, loss: 0.248745
   Number of active neurons: 7
 >> iter 91000, loss: 0.306609
 >> iter 92000, loss: 0.263100
 >> iter 93000, loss: 0.169358
 >> iter 94000, loss: 0.158366
 >> iter 95000, loss: 0.223401
 >> iter 96000, loss: 0.203489
 >> iter 97000, loss: 0.175957
 >> iter 98000, loss: 0.259224
 >> iter 99000, loss: 0.245631
 >> iter 100000, loss: 0.320415
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.158038
 >> iter 2000, loss: 10.514246
 >> iter 3000, loss: 4.555625
 >> iter 4000, loss: 1.905472
 >> iter 5000, loss: 1.022754
 >> iter 6000, loss: 0.522675
 >> iter 7000, loss: 0.385024
 >> iter 8000, loss: 0.268501
 >> iter 9000, loss: 0.177328
 >> iter 10000, loss: 0.209206
   Number of active neurons: 9
 >> iter 11000, loss: 0.274341
 >> iter 12000, loss: 0.268875
 >> iter 13000, loss: 0.237856
 >> iter 14000, loss: 0.199274
 >> iter 15000, loss: 0.308942
 >> iter 16000, loss: 0.332618
 >> iter 17000, loss: 0.299221
 >> iter 18000, loss: 0.273999
 >> iter 19000, loss: 0.221541
 >> iter 20000, loss: 0.221238
   Number of active neurons: 7
 >> iter 21000, loss: 0.237336
 >> iter 22000, loss: 0.210647
 >> iter 23000, loss: 0.139563
 >> iter 24000, loss: 0.148233
 >> iter 25000, loss: 0.261481
 >> iter 26000, loss: 0.234570
 >> iter 27000, loss: 0.256442
 >> iter 28000, loss: 0.214329
 >> iter 29000, loss: 0.270843
 >> iter 30000, loss: 0.199239
   Number of active neurons: 7
 >> iter 31000, loss: 0.358014
 >> iter 32000, loss: 0.295457
 >> iter 33000, loss: 0.263432
 >> iter 34000, loss: 0.145448
 >> iter 35000, loss: 0.198469
 >> iter 36000, loss: 0.178741
 >> iter 37000, loss: 0.161691
 >> iter 38000, loss: 0.141879
 >> iter 39000, loss: 0.149264
 >> iter 40000, loss: 0.175866
   Number of active neurons: 7
 >> iter 41000, loss: 0.186263
 >> iter 42000, loss: 0.192909
 >> iter 43000, loss: 0.184319
 >> iter 44000, loss: 0.166209
 >> iter 45000, loss: 0.139540
 >> iter 46000, loss: 0.279246
 >> iter 47000, loss: 0.244645
 >> iter 48000, loss: 0.193594
 >> iter 49000, loss: 0.217131
 >> iter 50000, loss: 0.152581
   Number of active neurons: 6
 >> iter 51000, loss: 0.100799
 >> iter 52000, loss: 0.236666
 >> iter 53000, loss: 0.235718
 >> iter 54000, loss: 0.258171
 >> iter 55000, loss: 0.218486
 >> iter 56000, loss: 0.166987
 >> iter 57000, loss: 0.190520
 >> iter 58000, loss: 0.241650
 >> iter 59000, loss: 0.246788
 >> iter 60000, loss: 0.236503
   Number of active neurons: 6
 >> iter 61000, loss: 0.177299
 >> iter 62000, loss: 0.209730
 >> iter 63000, loss: 0.175506
 >> iter 64000, loss: 0.199957
 >> iter 65000, loss: 0.208086
 >> iter 66000, loss: 0.209103
 >> iter 67000, loss: 0.188876
 >> iter 68000, loss: 0.155941
 >> iter 69000, loss: 0.325132
 >> iter 70000, loss: 0.263782
   Number of active neurons: 5
 >> iter 71000, loss: 0.383407
 >> iter 72000, loss: 0.257090
 >> iter 73000, loss: 0.264229
 >> iter 74000, loss: 0.157905
 >> iter 75000, loss: 0.197392
 >> iter 76000, loss: 0.116041
 >> iter 77000, loss: 0.267243
 >> iter 78000, loss: 0.270195
 >> iter 79000, loss: 0.386355
 >> iter 80000, loss: 0.314047
   Number of active neurons: 5
 >> iter 81000, loss: 0.169942
 >> iter 82000, loss: 0.211216
 >> iter 83000, loss: 0.227204
 >> iter 84000, loss: 0.236682
 >> iter 85000, loss: 0.201658
 >> iter 86000, loss: 0.209381
 >> iter 87000, loss: 0.185626
 >> iter 88000, loss: 0.131355
 >> iter 89000, loss: 0.271204
 >> iter 90000, loss: 0.203553
   Number of active neurons: 5
 >> iter 91000, loss: 0.199897
 >> iter 92000, loss: 0.169950
 >> iter 93000, loss: 0.264748
 >> iter 94000, loss: 0.302778
 >> iter 95000, loss: 0.337682
 >> iter 96000, loss: 0.183979
 >> iter 97000, loss: 0.211189
 >> iter 98000, loss: 0.273513
 >> iter 99000, loss: 0.221124
 >> iter 100000, loss: 0.200037
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.290974
 >> iter 2000, loss: 10.436390
 >> iter 3000, loss: 4.432026
 >> iter 4000, loss: 1.931278
 >> iter 5000, loss: 0.978250
 >> iter 6000, loss: 0.555350
 >> iter 7000, loss: 0.542427
 >> iter 8000, loss: 0.312062
 >> iter 9000, loss: 0.291147
 >> iter 10000, loss: 0.222818
   Number of active neurons: 10
 >> iter 11000, loss: 0.269426
 >> iter 12000, loss: 0.298924
 >> iter 13000, loss: 0.175086
 >> iter 14000, loss: 0.237169
 >> iter 15000, loss: 0.305707
 >> iter 16000, loss: 0.284574
 >> iter 17000, loss: 0.236678
 >> iter 18000, loss: 0.187824
 >> iter 19000, loss: 0.279579
 >> iter 20000, loss: 0.242197
   Number of active neurons: 10
 >> iter 21000, loss: 0.366065
 >> iter 22000, loss: 0.270035
 >> iter 23000, loss: 0.263351
 >> iter 24000, loss: 0.281636
 >> iter 25000, loss: 0.398179
 >> iter 26000, loss: 0.385288
 >> iter 27000, loss: 0.394874
 >> iter 28000, loss: 0.321790
 >> iter 29000, loss: 0.356238
 >> iter 30000, loss: 0.219593
   Number of active neurons: 9
 >> iter 31000, loss: 0.217883
 >> iter 32000, loss: 0.201947
 >> iter 33000, loss: 0.283465
 >> iter 34000, loss: 0.390128
 >> iter 35000, loss: 0.238736
 >> iter 36000, loss: 0.253725
 >> iter 37000, loss: 0.284428
 >> iter 38000, loss: 0.303563
 >> iter 39000, loss: 0.366799
 >> iter 40000, loss: 0.247362
   Number of active neurons: 9
 >> iter 41000, loss: 0.319462
 >> iter 42000, loss: 0.300872
 >> iter 43000, loss: 0.198214
 >> iter 44000, loss: 0.283049
 >> iter 45000, loss: 0.158944
 >> iter 46000, loss: 0.121668
 >> iter 47000, loss: 0.137953
 >> iter 48000, loss: 0.169989
 >> iter 49000, loss: 0.150874
 >> iter 50000, loss: 0.198536
   Number of active neurons: 8
 >> iter 51000, loss: 0.149911
 >> iter 52000, loss: 0.277454
 >> iter 53000, loss: 0.218806
 >> iter 54000, loss: 0.232370
 >> iter 55000, loss: 0.187323
 >> iter 56000, loss: 0.201975
 >> iter 57000, loss: 0.421879
 >> iter 58000, loss: 0.363199
 >> iter 59000, loss: 0.432653
 >> iter 60000, loss: 0.223093
   Number of active neurons: 7
 >> iter 61000, loss: 0.149608
 >> iter 62000, loss: 0.346107
 >> iter 63000, loss: 0.171558
 >> iter 64000, loss: 0.146548
 >> iter 65000, loss: 0.264536
 >> iter 66000, loss: 0.251283
 >> iter 67000, loss: 0.288391
 >> iter 68000, loss: 0.291511
 >> iter 69000, loss: 0.294333
 >> iter 70000, loss: 0.184404
   Number of active neurons: 7
 >> iter 71000, loss: 0.199237
 >> iter 72000, loss: 0.211569
 >> iter 73000, loss: 0.223626
 >> iter 74000, loss: 0.266708
 >> iter 75000, loss: 0.309109
 >> iter 76000, loss: 0.200431
 >> iter 77000, loss: 0.152031
 >> iter 78000, loss: 0.203687
 >> iter 79000, loss: 0.237801
 >> iter 80000, loss: 0.206755
   Number of active neurons: 6
 >> iter 81000, loss: 0.245440
 >> iter 82000, loss: 0.169852
 >> iter 83000, loss: 0.233084
 >> iter 84000, loss: 0.330360
 >> iter 85000, loss: 0.270682
 >> iter 86000, loss: 0.151240
 >> iter 87000, loss: 0.285640
 >> iter 88000, loss: 0.274216
 >> iter 89000, loss: 0.157642
 >> iter 90000, loss: 0.132571
   Number of active neurons: 6
 >> iter 91000, loss: 0.139108
 >> iter 92000, loss: 0.189082
 >> iter 93000, loss: 0.233270
 >> iter 94000, loss: 0.192700
 >> iter 95000, loss: 0.102493
 >> iter 96000, loss: 0.243110
 >> iter 97000, loss: 0.272727
 >> iter 98000, loss: 0.281676
 >> iter 99000, loss: 0.218076
 >> iter 100000, loss: 0.174941
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.107919
 >> iter 2000, loss: 10.949374
 >> iter 3000, loss: 4.914571
 >> iter 4000, loss: 2.076660
 >> iter 5000, loss: 1.084986
 >> iter 6000, loss: 0.750475
 >> iter 7000, loss: 0.410161
 >> iter 8000, loss: 0.526226
 >> iter 9000, loss: 0.381154
 >> iter 10000, loss: 0.351823
   Number of active neurons: 12
 >> iter 11000, loss: 0.379110
 >> iter 12000, loss: 0.307190
 >> iter 13000, loss: 0.265383
 >> iter 14000, loss: 0.311078
 >> iter 15000, loss: 0.502067
 >> iter 16000, loss: 0.412604
 >> iter 17000, loss: 0.422107
 >> iter 18000, loss: 0.330392
 >> iter 19000, loss: 0.232478
 >> iter 20000, loss: 0.315353
   Number of active neurons: 10
 >> iter 21000, loss: 0.267431
 >> iter 22000, loss: 0.197981
 >> iter 23000, loss: 0.200412
 >> iter 24000, loss: 0.160858
 >> iter 25000, loss: 0.212267
 >> iter 26000, loss: 0.266795
 >> iter 27000, loss: 0.248515
 >> iter 28000, loss: 0.395903
 >> iter 29000, loss: 0.266391
 >> iter 30000, loss: 0.199966
   Number of active neurons: 9
 >> iter 31000, loss: 0.242556
 >> iter 32000, loss: 0.202834
 >> iter 33000, loss: 0.311798
 >> iter 34000, loss: 0.216597
 >> iter 35000, loss: 0.292686
 >> iter 36000, loss: 0.424853
 >> iter 37000, loss: 0.260183
 >> iter 38000, loss: 0.300096
 >> iter 39000, loss: 0.358850
 >> iter 40000, loss: 0.264416
   Number of active neurons: 8
 >> iter 41000, loss: 0.252510
 >> iter 42000, loss: 0.283686
 >> iter 43000, loss: 0.316799
 >> iter 44000, loss: 0.323740
 >> iter 45000, loss: 0.413513
 >> iter 46000, loss: 0.385889
 >> iter 47000, loss: 0.293678
 >> iter 48000, loss: 0.224591
 >> iter 49000, loss: 0.237998
 >> iter 50000, loss: 0.334884
   Number of active neurons: 7
 >> iter 51000, loss: 0.286509
 >> iter 52000, loss: 0.292749
 >> iter 53000, loss: 0.249459
 >> iter 54000, loss: 0.267824
 >> iter 55000, loss: 0.243520
 >> iter 56000, loss: 0.204089
 >> iter 57000, loss: 0.293670
 >> iter 58000, loss: 0.175012
 >> iter 59000, loss: 0.291424
 >> iter 60000, loss: 0.191428
   Number of active neurons: 7
 >> iter 61000, loss: 0.267701
 >> iter 62000, loss: 0.312199
 >> iter 63000, loss: 0.286066
 >> iter 64000, loss: 0.201081
 >> iter 65000, loss: 0.157554
 >> iter 66000, loss: 0.208809
 >> iter 67000, loss: 0.331267
 >> iter 68000, loss: 0.278179
 >> iter 69000, loss: 0.238421
 >> iter 70000, loss: 0.168746
   Number of active neurons: 7
 >> iter 71000, loss: 0.443572
 >> iter 72000, loss: 0.242876
 >> iter 73000, loss: 0.283705
 >> iter 74000, loss: 0.310718
 >> iter 75000, loss: 0.328265
 >> iter 76000, loss: 0.192516
 >> iter 77000, loss: 0.206639
 >> iter 78000, loss: 0.179286
 >> iter 79000, loss: 0.374231
 >> iter 80000, loss: 0.306260
   Number of active neurons: 7
 >> iter 81000, loss: 0.348268
 >> iter 82000, loss: 0.303685
 >> iter 83000, loss: 0.366403
 >> iter 84000, loss: 0.208037
 >> iter 85000, loss: 0.229619
 >> iter 86000, loss: 0.412532
 >> iter 87000, loss: 0.322915
 >> iter 88000, loss: 0.161560
 >> iter 89000, loss: 0.296179
 >> iter 90000, loss: 0.255753
   Number of active neurons: 7
 >> iter 91000, loss: 0.239846
 >> iter 92000, loss: 0.217375
 >> iter 93000, loss: 0.165380
 >> iter 94000, loss: 0.197182
 >> iter 95000, loss: 0.205212
 >> iter 96000, loss: 0.251295
 >> iter 97000, loss: 0.214423
 >> iter 98000, loss: 0.205593
 >> iter 99000, loss: 0.130093
 >> iter 100000, loss: 0.204533
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

