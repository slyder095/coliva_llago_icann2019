 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.7
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.016727
 >> iter 2000, loss: 10.780578
 >> iter 3000, loss: 8.791743
 >> iter 4000, loss: 8.035530
 >> iter 5000, loss: 7.739239
 >> iter 6000, loss: 7.619855
 >> iter 7000, loss: 7.585732
 >> iter 8000, loss: 7.574645
 >> iter 9000, loss: 7.573083
 >> iter 10000, loss: 7.558355
   Number of active neurons: 10
 >> iter 11000, loss: 7.558119
 >> iter 12000, loss: 7.543399
 >> iter 13000, loss: 7.547910
 >> iter 14000, loss: 7.538747
 >> iter 15000, loss: 7.548856
 >> iter 16000, loss: 7.539858
 >> iter 17000, loss: 7.549093
 >> iter 18000, loss: 7.536266
 >> iter 19000, loss: 7.544144
 >> iter 20000, loss: 7.534570
   Number of active neurons: 9
 >> iter 21000, loss: 7.557145
 >> iter 22000, loss: 7.539806
 >> iter 23000, loss: 7.546346
 >> iter 24000, loss: 7.534577
 >> iter 25000, loss: 7.544013
 >> iter 26000, loss: 7.536453
 >> iter 27000, loss: 7.547747
 >> iter 28000, loss: 7.535368
 >> iter 29000, loss: 7.547075
 >> iter 30000, loss: 7.561491
   Number of active neurons: 10
 >> iter 31000, loss: 7.551521
 >> iter 32000, loss: 7.540170
 >> iter 33000, loss: 7.545334
 >> iter 34000, loss: 7.535934
 >> iter 35000, loss: 7.543598
 >> iter 36000, loss: 7.538712
 >> iter 37000, loss: 7.546262
 >> iter 38000, loss: 7.531169
 >> iter 39000, loss: 7.546341
 >> iter 40000, loss: 7.525974
   Number of active neurons: 10
 >> iter 41000, loss: 7.541015
 >> iter 42000, loss: 7.516537
 >> iter 43000, loss: 7.529604
 >> iter 44000, loss: 7.525075
 >> iter 45000, loss: 7.542155
 >> iter 46000, loss: 7.508315
 >> iter 47000, loss: 7.438560
 >> iter 48000, loss: 7.240138
 >> iter 49000, loss: 7.026726
 >> iter 50000, loss: 6.816907
   Number of active neurons: 10
 >> iter 51000, loss: 6.721549
 >> iter 52000, loss: 6.596577
 >> iter 53000, loss: 6.445361
 >> iter 54000, loss: 6.223354
 >> iter 55000, loss: 6.028597
 >> iter 56000, loss: 5.868034
 >> iter 57000, loss: 4.053743
 >> iter 58000, loss: 1.878634
 >> iter 59000, loss: 1.016186
 >> iter 60000, loss: 0.548857
   Number of active neurons: 10
 >> iter 61000, loss: 0.258278
 >> iter 62000, loss: 0.295979
 >> iter 63000, loss: 0.235528
 >> iter 64000, loss: 0.120939
 >> iter 65000, loss: 0.109515
 >> iter 66000, loss: 0.091130
 >> iter 67000, loss: 0.072167
 >> iter 68000, loss: 0.038416
 >> iter 69000, loss: 0.023607
 >> iter 70000, loss: 0.060203
   Number of active neurons: 10
 >> iter 71000, loss: 0.088186
 >> iter 72000, loss: 0.178225
 >> iter 73000, loss: 0.076536
 >> iter 74000, loss: 0.054307
 >> iter 75000, loss: 0.027478
 >> iter 76000, loss: 0.137838
 >> iter 77000, loss: 0.058053
 >> iter 78000, loss: 0.027527
 >> iter 79000, loss: 0.015436
 >> iter 80000, loss: 0.010718
   Number of active neurons: 10
 >> iter 81000, loss: 0.008428
 >> iter 82000, loss: 0.015687
 >> iter 83000, loss: 0.034918
 >> iter 84000, loss: 0.016674
 >> iter 85000, loss: 0.009989
 >> iter 86000, loss: 0.007021
 >> iter 87000, loss: 0.005882
 >> iter 88000, loss: 0.005127
 >> iter 89000, loss: 0.004667
 >> iter 90000, loss: 0.060922
   Number of active neurons: 10
 >> iter 91000, loss: 0.146795
 >> iter 92000, loss: 0.099438
 >> iter 93000, loss: 0.041009
 >> iter 94000, loss: 0.019150
 >> iter 95000, loss: 0.023568
 >> iter 96000, loss: 0.028355
 >> iter 97000, loss: 0.013749
 >> iter 98000, loss: 0.007849
 >> iter 99000, loss: 0.005429
 >> iter 100000, loss: 0.004495
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.882438
 >> iter 2000, loss: 10.780959
 >> iter 3000, loss: 8.896888
 >> iter 4000, loss: 8.116591
 >> iter 5000, loss: 7.836120
 >> iter 6000, loss: 7.708289
 >> iter 7000, loss: 7.661151
 >> iter 8000, loss: 7.654797
 >> iter 9000, loss: 7.641561
 >> iter 10000, loss: 7.626204
   Number of active neurons: 10
 >> iter 11000, loss: 7.655600
 >> iter 12000, loss: 7.630655
 >> iter 13000, loss: 7.628890
 >> iter 14000, loss: 7.619639
 >> iter 15000, loss: 7.618083
 >> iter 16000, loss: 7.615408
 >> iter 17000, loss: 7.619385
 >> iter 18000, loss: 7.610303
 >> iter 19000, loss: 7.623897
 >> iter 20000, loss: 7.602420
   Number of active neurons: 10
 >> iter 21000, loss: 7.515478
 >> iter 22000, loss: 7.254223
 >> iter 23000, loss: 6.943805
 >> iter 24000, loss: 6.640617
 >> iter 25000, loss: 6.411214
 >> iter 26000, loss: 6.237811
 >> iter 27000, loss: 6.154852
 >> iter 28000, loss: 6.003639
 >> iter 29000, loss: 5.960045
 >> iter 30000, loss: 5.803476
   Number of active neurons: 10
 >> iter 31000, loss: 5.624926
 >> iter 32000, loss: 5.402207
 >> iter 33000, loss: 2.980879
 >> iter 34000, loss: 1.433090
 >> iter 35000, loss: 0.743790
 >> iter 36000, loss: 0.465137
 >> iter 37000, loss: 0.285966
 >> iter 38000, loss: 0.189238
 >> iter 39000, loss: 0.162846
 >> iter 40000, loss: 0.143294
   Number of active neurons: 10
 >> iter 41000, loss: 0.126381
 >> iter 42000, loss: 0.082007
 >> iter 43000, loss: 0.094687
 >> iter 44000, loss: 0.094024
 >> iter 45000, loss: 0.101293
 >> iter 46000, loss: 0.235104
 >> iter 47000, loss: 0.152568
 >> iter 48000, loss: 0.077104
 >> iter 49000, loss: 0.110982
 >> iter 50000, loss: 0.050377
   Number of active neurons: 10
 >> iter 51000, loss: 0.025923
 >> iter 52000, loss: 0.051431
 >> iter 53000, loss: 0.068434
 >> iter 54000, loss: 0.055832
 >> iter 55000, loss: 0.034960
 >> iter 56000, loss: 0.032489
 >> iter 57000, loss: 0.028576
 >> iter 58000, loss: 0.247626
 >> iter 59000, loss: 0.101254
 >> iter 60000, loss: 0.044169
   Number of active neurons: 10
 >> iter 61000, loss: 0.022255
 >> iter 62000, loss: 0.013061
 >> iter 63000, loss: 0.009237
 >> iter 64000, loss: 0.023323
 >> iter 65000, loss: 0.105893
 >> iter 66000, loss: 0.044606
 >> iter 67000, loss: 0.023480
 >> iter 68000, loss: 0.012713
 >> iter 69000, loss: 0.008156
 >> iter 70000, loss: 0.006426
   Number of active neurons: 10
 >> iter 71000, loss: 0.032780
 >> iter 72000, loss: 0.026918
 >> iter 73000, loss: 0.013789
 >> iter 74000, loss: 0.008289
 >> iter 75000, loss: 0.012789
 >> iter 76000, loss: 0.023468
 >> iter 77000, loss: 0.011533
 >> iter 78000, loss: 0.006852
 >> iter 79000, loss: 0.004779
 >> iter 80000, loss: 0.004378
   Number of active neurons: 10
 >> iter 81000, loss: 0.003907
 >> iter 82000, loss: 0.003478
 >> iter 83000, loss: 0.003580
 >> iter 84000, loss: 0.009797
 >> iter 85000, loss: 0.005927
 >> iter 86000, loss: 0.034174
 >> iter 87000, loss: 0.014717
 >> iter 88000, loss: 0.007392
 >> iter 89000, loss: 0.059205
 >> iter 90000, loss: 0.024353
   Number of active neurons: 10
 >> iter 91000, loss: 0.015340
 >> iter 92000, loss: 0.007638
 >> iter 93000, loss: 0.006853
 >> iter 94000, loss: 0.028957
 >> iter 95000, loss: 0.012729
 >> iter 96000, loss: 0.045350
 >> iter 97000, loss: 0.040640
 >> iter 98000, loss: 0.017466
 >> iter 99000, loss: 0.008617
 >> iter 100000, loss: 0.066025
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.985195
 >> iter 2000, loss: 10.768946
 >> iter 3000, loss: 8.799999
 >> iter 4000, loss: 8.037326
 >> iter 5000, loss: 7.760051
 >> iter 6000, loss: 7.639208
 >> iter 7000, loss: 7.614811
 >> iter 8000, loss: 7.579089
 >> iter 9000, loss: 7.576049
 >> iter 10000, loss: 7.576262
   Number of active neurons: 10
 >> iter 11000, loss: 7.571899
 >> iter 12000, loss: 7.563876
 >> iter 13000, loss: 7.558605
 >> iter 14000, loss: 7.542933
 >> iter 15000, loss: 7.544485
 >> iter 16000, loss: 7.540077
 >> iter 17000, loss: 7.547222
 >> iter 18000, loss: 7.533109
 >> iter 19000, loss: 7.542366
 >> iter 20000, loss: 7.534482
   Number of active neurons: 10
 >> iter 21000, loss: 7.544677
 >> iter 22000, loss: 7.534039
 >> iter 23000, loss: 7.542969
 >> iter 24000, loss: 7.531822
 >> iter 25000, loss: 7.607603
 >> iter 26000, loss: 7.559059
 >> iter 27000, loss: 7.551953
 >> iter 28000, loss: 7.546042
 >> iter 29000, loss: 7.549513
 >> iter 30000, loss: 7.537072
   Number of active neurons: 10
 >> iter 31000, loss: 7.544519
 >> iter 32000, loss: 7.538727
 >> iter 33000, loss: 7.543054
 >> iter 34000, loss: 7.538488
 >> iter 35000, loss: 7.549755
 >> iter 36000, loss: 7.565053
 >> iter 37000, loss: 7.554614
 >> iter 38000, loss: 7.538253
 >> iter 39000, loss: 7.543410
 >> iter 40000, loss: 7.535131
   Number of active neurons: 9
 >> iter 41000, loss: 7.545952
 >> iter 42000, loss: 7.535729
 >> iter 43000, loss: 7.548540
 >> iter 44000, loss: 7.534379
 >> iter 45000, loss: 7.543374
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 46000, loss: 7.530724
 >> iter 47000, loss: 7.542507
 >> iter 48000, loss: 7.528655
 >> iter 49000, loss: 7.542709
 >> iter 50000, loss: 7.528246
   Number of active neurons: 9
 >> iter 51000, loss: 7.541488
 >> iter 52000, loss: 7.528439
 >> iter 53000, loss: 7.539673
 >> iter 54000, loss: 7.526483
 >> iter 55000, loss: 7.545088
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 56000, loss: 7.526771
 >> iter 57000, loss: 7.539107
 >> iter 58000, loss: 7.528384
 >> iter 59000, loss: 7.539888
 >> iter 60000, loss: 7.527823
   Number of active neurons: 9
 >> iter 61000, loss: 7.536818
 >> iter 62000, loss: 7.513196
 >> iter 63000, loss: 7.523336
 >> iter 64000, loss: 7.432533
 >> iter 65000, loss: 7.184137
 >> iter 66000, loss: 6.975826
 >> iter 67000, loss: 6.852997
 >> iter 68000, loss: 6.718927
 >> iter 69000, loss: 6.438004
 >> iter 70000, loss: 6.010111
   Number of active neurons: 10
 >> iter 71000, loss: 5.682178
 >> iter 72000, loss: 5.528131
 >> iter 73000, loss: 5.405875
 >> iter 74000, loss: 5.276754
 >> iter 75000, loss: 5.135112
 >> iter 76000, loss: 4.932938
 >> iter 77000, loss: 4.792407
 >> iter 78000, loss: 4.685270
 >> iter 79000, loss: 4.626458
 >> iter 80000, loss: 4.595688
   Number of active neurons: 10
 >> iter 81000, loss: 4.567451
 >> iter 82000, loss: 4.523542
 >> iter 83000, loss: 4.567579
 >> iter 84000, loss: 4.535002
 >> iter 85000, loss: 4.510406
 >> iter 86000, loss: 4.467743
 >> iter 87000, loss: 4.475249
 >> iter 88000, loss: 4.457534
 >> iter 89000, loss: 4.446745
 >> iter 90000, loss: 4.449041
   Number of active neurons: 10
 >> iter 91000, loss: 4.429966
 >> iter 92000, loss: 4.419945
 >> iter 93000, loss: 4.394778
 >> iter 94000, loss: 4.376075
 >> iter 95000, loss: 4.353932
 >> iter 96000, loss: 4.360190
 >> iter 97000, loss: 4.308441
 >> iter 98000, loss: 4.190408
 >> iter 99000, loss: 4.071645
 >> iter 100000, loss: 3.939610
   Number of active neurons: 10
 >> iter 101000, loss: 2.855224
 >> iter 102000, loss: 1.325037
 >> iter 103000, loss: 0.664629
 >> iter 104000, loss: 0.333310
 >> iter 105000, loss: 0.173818
 >> iter 106000, loss: 0.138741
 >> iter 107000, loss: 0.105665
 >> iter 108000, loss: 0.167430
 >> iter 109000, loss: 0.220679
 >> iter 110000, loss: 0.316726
   Number of active neurons: 10
 >> iter 111000, loss: 0.169571
 >> iter 112000, loss: 0.092496
 >> iter 113000, loss: 0.083673
 >> iter 114000, loss: 0.074259
 >> iter 115000, loss: 0.039416
 >> iter 116000, loss: 0.049065
 >> iter 117000, loss: 0.125768
 >> iter 118000, loss: 0.056746
 >> iter 119000, loss: 0.057000
 >> iter 120000, loss: 0.030660
   Number of active neurons: 10
 >> iter 121000, loss: 0.041665
 >> iter 122000, loss: 0.023067
 >> iter 123000, loss: 0.014775
 >> iter 124000, loss: 0.110439
 >> iter 125000, loss: 0.049208
 >> iter 126000, loss: 0.157400
 >> iter 127000, loss: 0.069940
 >> iter 128000, loss: 0.031598
 >> iter 129000, loss: 0.017854
 >> iter 130000, loss: 0.053329
   Number of active neurons: 10
 >> iter 131000, loss: 0.024550
 >> iter 132000, loss: 0.014015
 >> iter 133000, loss: 0.046129
 >> iter 134000, loss: 0.033181
 >> iter 135000, loss: 0.017633
 >> iter 136000, loss: 0.011028
 >> iter 137000, loss: 0.008043
 >> iter 138000, loss: 0.006898
 >> iter 139000, loss: 0.006171
 >> iter 140000, loss: 0.049655
   Number of active neurons: 10
 >> iter 141000, loss: 0.022220
 >> iter 142000, loss: 0.011800
 >> iter 143000, loss: 0.148531
 >> iter 144000, loss: 0.100177
 >> iter 145000, loss: 0.043122
 >> iter 146000, loss: 0.022227
 >> iter 147000, loss: 0.011909
 >> iter 148000, loss: 0.007930
 >> iter 149000, loss: 0.006425
 >> iter 150000, loss: 0.005548
   Number of active neurons: 10
 >> iter 151000, loss: 0.042579
 >> iter 152000, loss: 0.025997
 >> iter 153000, loss: 0.013107
 >> iter 154000, loss: 0.043688
 >> iter 155000, loss: 0.025077
 >> iter 156000, loss: 0.013154
 >> iter 157000, loss: 0.008120
 >> iter 158000, loss: 0.005840
 >> iter 159000, loss: 0.004871
 >> iter 160000, loss: 0.049593
   Number of active neurons: 10
 >> iter 161000, loss: 0.021307
 >> iter 162000, loss: 0.010556
 >> iter 163000, loss: 0.012697
 >> iter 164000, loss: 0.007291
 >> iter 165000, loss: 0.005366
 >> iter 166000, loss: 0.042852
 >> iter 167000, loss: 0.027306
 >> iter 168000, loss: 0.012583
 >> iter 169000, loss: 0.008172
 >> iter 170000, loss: 0.035154
   Number of active neurons: 10
 >> iter 171000, loss: 0.015548
 >> iter 172000, loss: 0.008107
 >> iter 173000, loss: 0.005213
 >> iter 174000, loss: 0.004316
 >> iter 175000, loss: 0.003721
 >> iter 176000, loss: 0.011935
 >> iter 177000, loss: 0.006370
 >> iter 178000, loss: 0.004331
 >> iter 179000, loss: 0.142348
 >> iter 180000, loss: 0.055774
   Number of active neurons: 10
 >> iter 181000, loss: 0.023099
 >> iter 182000, loss: 0.072066
 >> iter 183000, loss: 0.029037
 >> iter 184000, loss: 0.012963
 >> iter 185000, loss: 0.008319
 >> iter 186000, loss: 0.005280
 >> iter 187000, loss: 0.004256
 >> iter 188000, loss: 0.005564
 >> iter 189000, loss: 0.063410
 >> iter 190000, loss: 0.054304
   Number of active neurons: 10
 >> iter 191000, loss: 0.022178
 >> iter 192000, loss: 0.011178
 >> iter 193000, loss: 0.006257
 >> iter 194000, loss: 0.004423
 >> iter 195000, loss: 0.003802
 >> iter 196000, loss: 0.003289
 >> iter 197000, loss: 0.006047
 >> iter 198000, loss: 0.004030
 >> iter 199000, loss: 0.003246
 >> iter 200000, loss: 0.016810
   Number of active neurons: 10
 >> iter 201000, loss: 0.007911
 >> iter 202000, loss: 0.004717
 >> iter 203000, loss: 0.003402
 >> iter 204000, loss: 0.038040
 >> iter 205000, loss: 0.015810
 >> iter 206000, loss: 0.007600
 >> iter 207000, loss: 0.004672
 >> iter 208000, loss: 0.003415
 >> iter 209000, loss: 0.002825
 >> iter 210000, loss: 0.002987
   Number of active neurons: 10
 >> iter 211000, loss: 0.002645
 >> iter 212000, loss: 0.002532
 >> iter 213000, loss: 0.002853
 >> iter 214000, loss: 0.002549
 >> iter 215000, loss: 0.002449
 >> iter 216000, loss: 0.002229
 >> iter 217000, loss: 0.002356
 >> iter 218000, loss: 0.002170
 >> iter 219000, loss: 0.002095
 >> iter 220000, loss: 0.002066
   Number of active neurons: 10
 >> iter 221000, loss: 0.001998
 >> iter 222000, loss: 0.001977
 >> iter 223000, loss: 0.002817
 >> iter 224000, loss: 0.002203
 >> iter 225000, loss: 0.015717
 >> iter 226000, loss: 0.027928
 >> iter 227000, loss: 0.011804
 >> iter 228000, loss: 0.005540
 >> iter 229000, loss: 0.003266
 >> iter 230000, loss: 0.002464
   Number of active neurons: 10
 >> iter 231000, loss: 0.004169
 >> iter 232000, loss: 0.002630
 >> iter 233000, loss: 0.002089
 >> iter 234000, loss: 0.001844
 >> iter 235000, loss: 0.031782
 >> iter 236000, loss: 0.012952
 >> iter 237000, loss: 0.006050
 >> iter 238000, loss: 0.003385
 >> iter 239000, loss: 0.009455
 >> iter 240000, loss: 0.004603
   Number of active neurons: 10
 >> iter 241000, loss: 0.034381
 >> iter 242000, loss: 0.047734
 >> iter 243000, loss: 0.034792
 >> iter 244000, loss: 0.014061
 >> iter 245000, loss: 0.046515
 >> iter 246000, loss: 0.018640
 >> iter 247000, loss: 0.008129
 >> iter 248000, loss: 0.004155
 >> iter 249000, loss: 0.043215
 >> iter 250000, loss: 0.056785
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.905889
 >> iter 2000, loss: 10.726265
 >> iter 3000, loss: 8.822896
 >> iter 4000, loss: 8.062203
 >> iter 5000, loss: 7.776432
 >> iter 6000, loss: 7.659773
 >> iter 7000, loss: 7.620712
 >> iter 8000, loss: 7.596850
 >> iter 9000, loss: 7.524078
 >> iter 10000, loss: 7.350548
   Number of active neurons: 10
 >> iter 11000, loss: 7.060648
 >> iter 12000, loss: 6.830329
 >> iter 13000, loss: 6.563149
 >> iter 14000, loss: 6.253564
 >> iter 15000, loss: 5.889119
 >> iter 16000, loss: 5.336485
 >> iter 17000, loss: 2.901609
 >> iter 18000, loss: 1.569425
 >> iter 19000, loss: 0.823390
 >> iter 20000, loss: 0.584712
   Number of active neurons: 10
 >> iter 21000, loss: 0.689597
 >> iter 22000, loss: 0.456794
 >> iter 23000, loss: 0.255358
 >> iter 24000, loss: 0.323155
 >> iter 25000, loss: 0.160747
 >> iter 26000, loss: 0.246412
 >> iter 27000, loss: 0.132110
 >> iter 28000, loss: 0.205479
 >> iter 29000, loss: 0.111413
 >> iter 30000, loss: 0.103202
   Number of active neurons: 10
 >> iter 31000, loss: 0.112512
 >> iter 32000, loss: 0.119429
 >> iter 33000, loss: 0.117248
 >> iter 34000, loss: 0.072434
 >> iter 35000, loss: 0.103645
 >> iter 36000, loss: 0.129951
 >> iter 37000, loss: 0.067322
 >> iter 38000, loss: 0.199747
 >> iter 39000, loss: 0.344784
 >> iter 40000, loss: 0.147009
   Number of active neurons: 10
 >> iter 41000, loss: 0.096764
 >> iter 42000, loss: 0.045951
 >> iter 43000, loss: 0.116250
 >> iter 44000, loss: 0.060936
 >> iter 45000, loss: 0.030060
 >> iter 46000, loss: 0.017447
 >> iter 47000, loss: 0.012354
 >> iter 48000, loss: 0.053652
 >> iter 49000, loss: 0.025148
 >> iter 50000, loss: 0.053858
   Number of active neurons: 10
 >> iter 51000, loss: 0.025048
 >> iter 52000, loss: 0.032234
 >> iter 53000, loss: 0.035624
 >> iter 54000, loss: 0.049179
 >> iter 55000, loss: 0.037932
 >> iter 56000, loss: 0.041673
 >> iter 57000, loss: 0.022660
 >> iter 58000, loss: 0.172462
 >> iter 59000, loss: 0.069372
 >> iter 60000, loss: 0.030101
   Number of active neurons: 10
 >> iter 61000, loss: 0.020227
 >> iter 62000, loss: 0.011275
 >> iter 63000, loss: 0.007663
 >> iter 64000, loss: 0.025624
 >> iter 65000, loss: 0.012772
 >> iter 66000, loss: 0.007800
 >> iter 67000, loss: 0.053696
 >> iter 68000, loss: 0.023273
 >> iter 69000, loss: 0.137714
 >> iter 70000, loss: 0.054125
   Number of active neurons: 10
 >> iter 71000, loss: 0.107975
 >> iter 72000, loss: 0.043561
 >> iter 73000, loss: 0.105783
 >> iter 74000, loss: 0.077417
 >> iter 75000, loss: 0.123809
 >> iter 76000, loss: 0.104571
 >> iter 77000, loss: 0.049788
 >> iter 78000, loss: 0.036865
 >> iter 79000, loss: 0.018301
 >> iter 80000, loss: 0.010216
   Number of active neurons: 10
 >> iter 81000, loss: 0.007038
 >> iter 82000, loss: 0.005436
 >> iter 83000, loss: 0.017176
 >> iter 84000, loss: 0.009453
 >> iter 85000, loss: 0.006089
 >> iter 86000, loss: 0.004512
 >> iter 87000, loss: 0.003912
 >> iter 88000, loss: 0.236561
 >> iter 89000, loss: 0.090632
 >> iter 90000, loss: 0.072642
   Number of active neurons: 10
 >> iter 91000, loss: 0.029713
 >> iter 92000, loss: 0.030922
 >> iter 93000, loss: 0.014073
 >> iter 94000, loss: 0.007627
 >> iter 95000, loss: 0.005197
 >> iter 96000, loss: 0.004323
 >> iter 97000, loss: 0.003747
 >> iter 98000, loss: 0.003425
 >> iter 99000, loss: 0.003135
 >> iter 100000, loss: 0.003210
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.988804
 >> iter 2000, loss: 10.780597
 >> iter 3000, loss: 8.821706
 >> iter 4000, loss: 8.051953
 >> iter 5000, loss: 7.781467
 >> iter 6000, loss: 7.643499
 >> iter 7000, loss: 7.611698
 >> iter 8000, loss: 7.584906
 >> iter 9000, loss: 7.578198
 >> iter 10000, loss: 7.560862
   Number of active neurons: 10
 >> iter 11000, loss: 7.571504
 >> iter 12000, loss: 7.569606
 >> iter 13000, loss: 7.567581
 >> iter 14000, loss: 7.557602
 >> iter 15000, loss: 7.561947
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 7.552507
 >> iter 17000, loss: 7.559070
 >> iter 18000, loss: 7.549718
 >> iter 19000, loss: 7.561073
 >> iter 20000, loss: 7.553528
   Number of active neurons: 9
 >> iter 21000, loss: 7.565449
 >> iter 22000, loss: 7.553751
 >> iter 23000, loss: 7.561535
 >> iter 24000, loss: 7.552943
 >> iter 25000, loss: 7.561946
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 26000, loss: 7.558684
 >> iter 27000, loss: 7.560175
 >> iter 28000, loss: 7.552519
 >> iter 29000, loss: 7.559175
 >> iter 30000, loss: 7.550570
   Number of active neurons: 9
 >> iter 31000, loss: 7.558728
 >> iter 32000, loss: 7.553455
 >> iter 33000, loss: 7.551450
 >> iter 34000, loss: 7.520588
 >> iter 35000, loss: 7.276145
 >> iter 36000, loss: 6.984451
 >> iter 37000, loss: 6.728660
 >> iter 38000, loss: 6.433588
 >> iter 39000, loss: 6.048748
 >> iter 40000, loss: 4.114611
   Number of active neurons: 10
 >> iter 41000, loss: 1.987360
 >> iter 42000, loss: 1.138285
 >> iter 43000, loss: 0.665662
 >> iter 44000, loss: 0.327201
 >> iter 45000, loss: 0.278843
 >> iter 46000, loss: 0.198064
 >> iter 47000, loss: 0.165190
 >> iter 48000, loss: 0.111380
 >> iter 49000, loss: 0.059450
 >> iter 50000, loss: 0.079281
   Number of active neurons: 10
 >> iter 51000, loss: 0.157972
 >> iter 52000, loss: 0.078293
 >> iter 53000, loss: 0.053804
 >> iter 54000, loss: 0.048298
 >> iter 55000, loss: 0.027462
 >> iter 56000, loss: 0.058519
 >> iter 57000, loss: 0.060557
 >> iter 58000, loss: 0.129552
 >> iter 59000, loss: 0.087366
 >> iter 60000, loss: 0.057751
   Number of active neurons: 10
 >> iter 61000, loss: 0.051477
 >> iter 62000, loss: 0.115047
 >> iter 63000, loss: 0.069385
 >> iter 64000, loss: 0.063814
 >> iter 65000, loss: 0.031818
 >> iter 66000, loss: 0.031341
 >> iter 67000, loss: 0.019929
 >> iter 68000, loss: 0.028059
 >> iter 69000, loss: 0.090400
 >> iter 70000, loss: 0.067936
   Number of active neurons: 10
 >> iter 71000, loss: 0.075860
 >> iter 72000, loss: 0.033238
 >> iter 73000, loss: 0.052317
 >> iter 74000, loss: 0.042242
 >> iter 75000, loss: 0.121885
 >> iter 76000, loss: 0.059379
 >> iter 77000, loss: 0.032772
 >> iter 78000, loss: 0.067164
 >> iter 79000, loss: 0.029247
 >> iter 80000, loss: 0.094167
   Number of active neurons: 10
 >> iter 81000, loss: 0.066652
 >> iter 82000, loss: 0.029345
 >> iter 83000, loss: 0.015761
 >> iter 84000, loss: 0.009238
 >> iter 85000, loss: 0.006748
 >> iter 86000, loss: 0.005816
 >> iter 87000, loss: 0.004923
 >> iter 88000, loss: 0.004433
 >> iter 89000, loss: 0.005111
 >> iter 90000, loss: 0.004524
   Number of active neurons: 10
 >> iter 91000, loss: 0.004031
 >> iter 92000, loss: 0.004048
 >> iter 93000, loss: 0.026650
 >> iter 94000, loss: 0.012622
 >> iter 95000, loss: 0.048908
 >> iter 96000, loss: 0.020578
 >> iter 97000, loss: 0.017236
 >> iter 98000, loss: 0.008355
 >> iter 99000, loss: 0.011244
 >> iter 100000, loss: 0.006231
   Number of active neurons: 10
 >> iter 101000, loss: 0.004478
 >> iter 102000, loss: 0.003737
 >> iter 103000, loss: 0.057145
 >> iter 104000, loss: 0.028961
 >> iter 105000, loss: 0.012640
 >> iter 106000, loss: 0.007328
 >> iter 107000, loss: 0.004325
 >> iter 108000, loss: 0.006836
 >> iter 109000, loss: 0.084305
 >> iter 110000, loss: 0.032961
   Number of active neurons: 10
 >> iter 111000, loss: 0.013958
 >> iter 112000, loss: 0.006781
 >> iter 113000, loss: 0.004890
 >> iter 114000, loss: 0.003499
 >> iter 115000, loss: 0.002853
 >> iter 116000, loss: 0.003515
 >> iter 117000, loss: 0.026878
 >> iter 118000, loss: 0.014624
 >> iter 119000, loss: 0.022564
 >> iter 120000, loss: 0.009858
   Number of active neurons: 10
 >> iter 121000, loss: 0.005317
 >> iter 122000, loss: 0.003423
 >> iter 123000, loss: 0.002682
 >> iter 124000, loss: 0.002388
 >> iter 125000, loss: 0.002241
 >> iter 126000, loss: 0.002169
 >> iter 127000, loss: 0.002086
 >> iter 128000, loss: 0.001989
 >> iter 129000, loss: 0.001868
 >> iter 130000, loss: 0.002038
   Number of active neurons: 10
 >> iter 131000, loss: 0.002688
 >> iter 132000, loss: 0.002057
 >> iter 133000, loss: 0.001846
 >> iter 134000, loss: 0.001710
 >> iter 135000, loss: 0.003993
 >> iter 136000, loss: 0.002421
 >> iter 137000, loss: 0.001807
 >> iter 138000, loss: 0.002998
 >> iter 139000, loss: 0.002057
 >> iter 140000, loss: 0.028828
   Number of active neurons: 10
 >> iter 141000, loss: 0.011594
 >> iter 142000, loss: 0.005381
 >> iter 143000, loss: 0.002869
 >> iter 144000, loss: 0.074609
 >> iter 145000, loss: 0.028528
 >> iter 146000, loss: 0.011508
 >> iter 147000, loss: 0.005229
 >> iter 148000, loss: 0.003117
 >> iter 149000, loss: 0.017644
 >> iter 150000, loss: 0.075481
   Number of active neurons: 10
 >> iter 151000, loss: 0.028868
 >> iter 152000, loss: 0.031142
 >> iter 153000, loss: 0.012461
 >> iter 154000, loss: 0.005515
 >> iter 155000, loss: 0.003021
 >> iter 156000, loss: 0.002015
 >> iter 157000, loss: 0.001639
 >> iter 158000, loss: 0.001478
 >> iter 159000, loss: 0.003572
 >> iter 160000, loss: 0.031270
   Number of active neurons: 10
 >> iter 161000, loss: 0.012405
 >> iter 162000, loss: 0.005484
 >> iter 163000, loss: 0.002893
 >> iter 164000, loss: 0.001847
 >> iter 165000, loss: 0.139374
 >> iter 166000, loss: 0.052348
 >> iter 167000, loss: 0.027963
 >> iter 168000, loss: 0.011285
 >> iter 169000, loss: 0.005022
 >> iter 170000, loss: 0.002686
   Number of active neurons: 10
 >> iter 171000, loss: 0.001832
 >> iter 172000, loss: 0.001467
 >> iter 173000, loss: 0.001309
 >> iter 174000, loss: 0.001251
 >> iter 175000, loss: 0.001211
 >> iter 176000, loss: 0.001158
 >> iter 177000, loss: 0.001149
 >> iter 178000, loss: 0.001151
 >> iter 179000, loss: 0.001122
 >> iter 180000, loss: 0.001104
   Number of active neurons: 10
 >> iter 181000, loss: 0.001090
 >> iter 182000, loss: 0.001101
 >> iter 183000, loss: 0.001041
 >> iter 184000, loss: 0.001014
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.951621
 >> iter 2000, loss: 10.731175
 >> iter 3000, loss: 8.777147
 >> iter 4000, loss: 8.014240
 >> iter 5000, loss: 7.743320
 >> iter 6000, loss: 7.628887
 >> iter 7000, loss: 7.631669
 >> iter 8000, loss: 7.585183
 >> iter 9000, loss: 7.625871
 >> iter 10000, loss: 7.596300
   Number of active neurons: 10
 >> iter 11000, loss: 7.572640
 >> iter 12000, loss: 7.561688
 >> iter 13000, loss: 7.562383
 >> iter 14000, loss: 7.544896
 >> iter 15000, loss: 7.556173
 >> iter 16000, loss: 7.541328
 >> iter 17000, loss: 7.607361
 >> iter 18000, loss: 7.560466
 >> iter 19000, loss: 7.552897
 >> iter 20000, loss: 7.539016
   Number of active neurons: 8
 >> iter 21000, loss: 7.557423
 >> iter 22000, loss: 7.540842
 >> iter 23000, loss: 7.542752
 >> iter 24000, loss: 7.533868
 >> iter 25000, loss: 7.541134
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 7.530734
 >> iter 27000, loss: 7.534710
 >> iter 28000, loss: 7.507702
 >> iter 29000, loss: 7.369375
 >> iter 30000, loss: 7.084051
   Number of active neurons: 10
 >> iter 31000, loss: 6.934962
 >> iter 32000, loss: 6.716788
 >> iter 33000, loss: 6.412743
 >> iter 34000, loss: 6.129809
 >> iter 35000, loss: 5.878170
 >> iter 36000, loss: 5.674202
 >> iter 37000, loss: 5.523101
 >> iter 38000, loss: 4.692958
 >> iter 39000, loss: 2.182315
 >> iter 40000, loss: 1.212449
   Number of active neurons: 10
 >> iter 41000, loss: 0.606210
 >> iter 42000, loss: 0.325241
 >> iter 43000, loss: 0.329835
 >> iter 44000, loss: 0.285401
 >> iter 45000, loss: 0.199869
 >> iter 46000, loss: 0.209449
 >> iter 47000, loss: 0.200910
 >> iter 48000, loss: 0.206569
 >> iter 49000, loss: 0.107927
 >> iter 50000, loss: 0.060537
   Number of active neurons: 10
 >> iter 51000, loss: 0.092025
 >> iter 52000, loss: 0.082544
 >> iter 53000, loss: 0.040964
 >> iter 54000, loss: 0.051165
 >> iter 55000, loss: 0.027227
 >> iter 56000, loss: 0.046761
 >> iter 57000, loss: 0.038610
 >> iter 58000, loss: 0.020877
 >> iter 59000, loss: 0.027298
 >> iter 60000, loss: 0.062476
   Number of active neurons: 10
 >> iter 61000, loss: 0.029598
 >> iter 62000, loss: 0.017542
 >> iter 63000, loss: 0.011256
 >> iter 64000, loss: 0.038873
 >> iter 65000, loss: 0.081220
 >> iter 66000, loss: 0.035453
 >> iter 67000, loss: 0.017150
 >> iter 68000, loss: 0.044802
 >> iter 69000, loss: 0.210010
 >> iter 70000, loss: 0.082320
   Number of active neurons: 10
 >> iter 71000, loss: 0.034336
 >> iter 72000, loss: 0.017296
 >> iter 73000, loss: 0.055691
 >> iter 74000, loss: 0.057186
 >> iter 75000, loss: 0.025045
 >> iter 76000, loss: 0.012934
 >> iter 77000, loss: 0.008169
 >> iter 78000, loss: 0.006300
 >> iter 79000, loss: 0.006457
 >> iter 80000, loss: 0.005309
   Number of active neurons: 10
 >> iter 81000, loss: 0.006716
 >> iter 82000, loss: 0.006575
 >> iter 83000, loss: 0.012559
 >> iter 84000, loss: 0.007567
 >> iter 85000, loss: 0.016886
 >> iter 86000, loss: 0.010232
 >> iter 87000, loss: 0.012514
 >> iter 88000, loss: 0.086591
 >> iter 89000, loss: 0.034916
 >> iter 90000, loss: 0.016672
   Number of active neurons: 10
 >> iter 91000, loss: 0.008320
 >> iter 92000, loss: 0.006460
 >> iter 93000, loss: 0.044197
 >> iter 94000, loss: 0.041029
 >> iter 95000, loss: 0.017583
 >> iter 96000, loss: 0.009182
 >> iter 97000, loss: 0.005492
 >> iter 98000, loss: 0.004333
 >> iter 99000, loss: 0.003549
 >> iter 100000, loss: 0.003156
   Number of active neurons: 10
 >> iter 101000, loss: 0.002985
 >> iter 102000, loss: 0.002835
 >> iter 103000, loss: 0.002688
 >> iter 104000, loss: 0.002747
 >> iter 105000, loss: 0.002717
 >> iter 106000, loss: 0.002503
 >> iter 107000, loss: 0.002333
 >> iter 108000, loss: 0.002305
 >> iter 109000, loss: 0.002209
 >> iter 110000, loss: 0.002309
   Number of active neurons: 10
 >> iter 111000, loss: 0.002144
 >> iter 112000, loss: 0.002568
 >> iter 113000, loss: 0.146040
 >> iter 114000, loss: 0.056875
 >> iter 115000, loss: 0.022599
 >> iter 116000, loss: 0.010920
 >> iter 117000, loss: 0.008771
 >> iter 118000, loss: 0.004681
 >> iter 119000, loss: 0.003316
 >> iter 120000, loss: 0.002589
   Number of active neurons: 10
 >> iter 121000, loss: 0.002335
 >> iter 122000, loss: 0.002103
 >> iter 123000, loss: 0.019814
 >> iter 124000, loss: 0.008525
 >> iter 125000, loss: 0.004889
 >> iter 126000, loss: 0.028919
 >> iter 127000, loss: 0.012051
 >> iter 128000, loss: 0.026697
 >> iter 129000, loss: 0.011241
 >> iter 130000, loss: 0.005741
   Number of active neurons: 10
 >> iter 131000, loss: 0.003303
 >> iter 132000, loss: 0.002715
 >> iter 133000, loss: 0.006610
 >> iter 134000, loss: 0.003783
 >> iter 135000, loss: 0.002643
 >> iter 136000, loss: 0.002124
 >> iter 137000, loss: 0.002133
 >> iter 138000, loss: 0.001839
 >> iter 139000, loss: 0.001805
 >> iter 140000, loss: 0.001767
   Number of active neurons: 10
 >> iter 141000, loss: 0.001627
 >> iter 142000, loss: 0.001757
 >> iter 143000, loss: 0.001615
 >> iter 144000, loss: 0.002122
 >> iter 145000, loss: 0.011771
 >> iter 146000, loss: 0.005288
 >> iter 147000, loss: 0.003320
 >> iter 148000, loss: 0.025309
 >> iter 149000, loss: 0.010227
 >> iter 150000, loss: 0.005203
   Number of active neurons: 10
 >> iter 151000, loss: 0.003347
 >> iter 152000, loss: 0.002405
 >> iter 153000, loss: 0.001897
 >> iter 154000, loss: 0.001672
 >> iter 155000, loss: 0.001473
 >> iter 156000, loss: 0.001353
 >> iter 157000, loss: 0.001780
 >> iter 158000, loss: 0.001878
 >> iter 159000, loss: 0.001533
 >> iter 160000, loss: 0.001369
   Number of active neurons: 10
 >> iter 161000, loss: 0.001223
 >> iter 162000, loss: 0.001212
 >> iter 163000, loss: 0.001466
 >> iter 164000, loss: 0.001505
 >> iter 165000, loss: 0.001364
 >> iter 166000, loss: 0.001301
 >> iter 167000, loss: 0.001243
 >> iter 168000, loss: 0.001152
 >> iter 169000, loss: 0.001181
 >> iter 170000, loss: 0.001086
   Number of active neurons: 10
 >> iter 171000, loss: 0.001079
 >> iter 172000, loss: 0.001299
 >> iter 173000, loss: 0.001120
 >> iter 174000, loss: 0.001058
 >> iter 175000, loss: 0.001015
 >> iter 176000, loss: 0.001059
 >> iter 177000, loss: 0.001088
 >> iter 178000, loss: 0.001108
 >> iter 179000, loss: 0.001028
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.034141
 >> iter 2000, loss: 10.804610
 >> iter 3000, loss: 8.836031
 >> iter 4000, loss: 8.037900
 >> iter 5000, loss: 7.773576
 >> iter 6000, loss: 7.659117
 >> iter 7000, loss: 7.633833
 >> iter 8000, loss: 7.585748
 >> iter 9000, loss: 7.571400
 >> iter 10000, loss: 7.554677
   Number of active neurons: 9
 >> iter 11000, loss: 7.553767
 >> iter 12000, loss: 7.524970
 >> iter 13000, loss: 7.371597
 >> iter 14000, loss: 7.159830
 >> iter 15000, loss: 6.914848
 >> iter 16000, loss: 6.788803
 >> iter 17000, loss: 6.701512
 >> iter 18000, loss: 6.669720
 >> iter 19000, loss: 6.645320
 >> iter 20000, loss: 6.416210
   Number of active neurons: 10
 >> iter 21000, loss: 6.346739
 >> iter 22000, loss: 6.122791
 >> iter 23000, loss: 5.998458
 >> iter 24000, loss: 5.909734
 >> iter 25000, loss: 5.846222
 >> iter 26000, loss: 5.777747
 >> iter 27000, loss: 5.710539
 >> iter 28000, loss: 5.652897
 >> iter 29000, loss: 5.482267
 >> iter 30000, loss: 5.122443
   Number of active neurons: 10
 >> iter 31000, loss: 3.699823
 >> iter 32000, loss: 1.734289
 >> iter 33000, loss: 0.791871
 >> iter 34000, loss: 0.363394
 >> iter 35000, loss: 0.179671
 >> iter 36000, loss: 0.147908
 >> iter 37000, loss: 0.070845
 >> iter 38000, loss: 0.061883
 >> iter 39000, loss: 0.145914
 >> iter 40000, loss: 0.167183
   Number of active neurons: 10
 >> iter 41000, loss: 0.084296
 >> iter 42000, loss: 0.060140
 >> iter 43000, loss: 0.190787
 >> iter 44000, loss: 0.166196
 >> iter 45000, loss: 0.070674
 >> iter 46000, loss: 0.045977
 >> iter 47000, loss: 0.022753
 >> iter 48000, loss: 0.022344
 >> iter 49000, loss: 0.064628
 >> iter 50000, loss: 0.056590
   Number of active neurons: 10
 >> iter 51000, loss: 0.042342
 >> iter 52000, loss: 0.020721
 >> iter 53000, loss: 0.043865
 >> iter 54000, loss: 0.020839
 >> iter 55000, loss: 0.056681
 >> iter 56000, loss: 0.070288
 >> iter 57000, loss: 0.034887
 >> iter 58000, loss: 0.020014
 >> iter 59000, loss: 0.043672
 >> iter 60000, loss: 0.025569
   Number of active neurons: 10
 >> iter 61000, loss: 0.013437
 >> iter 62000, loss: 0.008021
 >> iter 63000, loss: 0.005757
 >> iter 64000, loss: 0.021939
 >> iter 65000, loss: 0.038662
 >> iter 66000, loss: 0.017102
 >> iter 67000, loss: 0.041473
 >> iter 68000, loss: 0.030578
 >> iter 69000, loss: 0.076324
 >> iter 70000, loss: 0.030729
   Number of active neurons: 10
 >> iter 71000, loss: 0.013647
 >> iter 72000, loss: 0.007175
 >> iter 73000, loss: 0.040599
 >> iter 74000, loss: 0.017326
 >> iter 75000, loss: 0.008654
 >> iter 76000, loss: 0.009212
 >> iter 77000, loss: 0.005956
 >> iter 78000, loss: 0.004159
 >> iter 79000, loss: 0.003454
 >> iter 80000, loss: 0.008344
   Number of active neurons: 10
 >> iter 81000, loss: 0.004907
 >> iter 82000, loss: 0.101672
 >> iter 83000, loss: 0.041435
 >> iter 84000, loss: 0.154016
 >> iter 85000, loss: 0.096694
 >> iter 86000, loss: 0.039056
 >> iter 87000, loss: 0.017228
 >> iter 88000, loss: 0.055190
 >> iter 89000, loss: 0.022988
 >> iter 90000, loss: 0.010843
   Number of active neurons: 10
 >> iter 91000, loss: 0.056032
 >> iter 92000, loss: 0.023320
 >> iter 93000, loss: 0.010906
 >> iter 94000, loss: 0.006495
 >> iter 95000, loss: 0.004554
 >> iter 96000, loss: 0.003532
 >> iter 97000, loss: 0.049388
 >> iter 98000, loss: 0.049888
 >> iter 99000, loss: 0.020447
 >> iter 100000, loss: 0.009734
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.182382
 >> iter 2000, loss: 10.859869
 >> iter 3000, loss: 8.946804
 >> iter 4000, loss: 8.104946
 >> iter 5000, loss: 7.792331
 >> iter 6000, loss: 7.671692
 >> iter 7000, loss: 7.641296
 >> iter 8000, loss: 7.609459
 >> iter 9000, loss: 7.597755
 >> iter 10000, loss: 7.583234
   Number of active neurons: 10
 >> iter 11000, loss: 7.589393
 >> iter 12000, loss: 7.580208
 >> iter 13000, loss: 7.588656
 >> iter 14000, loss: 7.578814
 >> iter 15000, loss: 7.583037
 >> iter 16000, loss: 7.577060
 >> iter 17000, loss: 7.582626
 >> iter 18000, loss: 7.574581
 >> iter 19000, loss: 7.585013
 >> iter 20000, loss: 7.575589
   Number of active neurons: 9
 >> iter 21000, loss: 7.578175
 >> iter 22000, loss: 7.575262
 >> iter 23000, loss: 7.577520
 >> iter 24000, loss: 7.568420
 >> iter 25000, loss: 7.576512
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 7.571361
 >> iter 27000, loss: 7.575362
 >> iter 28000, loss: 7.573060
 >> iter 29000, loss: 7.580443
 >> iter 30000, loss: 7.574621
   Number of active neurons: 9
 >> iter 31000, loss: 7.578439
 >> iter 32000, loss: 7.568147
 >> iter 33000, loss: 7.574517
 >> iter 34000, loss: 7.592353
 >> iter 35000, loss: 7.569297
 >> iter 36000, loss: 7.516176
 >> iter 37000, loss: 7.467708
 >> iter 38000, loss: 7.202951
 >> iter 39000, loss: 6.944000
 >> iter 40000, loss: 6.767876
   Number of active neurons: 10
 >> iter 41000, loss: 6.533624
 >> iter 42000, loss: 6.084398
 >> iter 43000, loss: 5.521542
 >> iter 44000, loss: 5.113189
 >> iter 45000, loss: 4.188857
 >> iter 46000, loss: 1.902237
 >> iter 47000, loss: 0.839695
 >> iter 48000, loss: 0.388117
 >> iter 49000, loss: 0.298514
 >> iter 50000, loss: 0.393807
   Number of active neurons: 10
 >> iter 51000, loss: 0.205792
 >> iter 52000, loss: 0.180701
 >> iter 53000, loss: 0.151517
 >> iter 54000, loss: 0.099781
 >> iter 55000, loss: 0.047499
 >> iter 56000, loss: 0.077451
 >> iter 57000, loss: 0.145441
 >> iter 58000, loss: 0.103390
 >> iter 59000, loss: 0.140852
 >> iter 60000, loss: 0.061189
   Number of active neurons: 10
 >> iter 61000, loss: 0.202056
 >> iter 62000, loss: 0.127476
 >> iter 63000, loss: 0.169032
 >> iter 64000, loss: 0.123644
 >> iter 65000, loss: 0.080001
 >> iter 66000, loss: 0.065894
 >> iter 67000, loss: 0.085962
 >> iter 68000, loss: 0.055506
 >> iter 69000, loss: 0.026349
 >> iter 70000, loss: 0.052863
   Number of active neurons: 10
 >> iter 71000, loss: 0.207068
 >> iter 72000, loss: 0.089781
 >> iter 73000, loss: 0.039547
 >> iter 74000, loss: 0.051521
 >> iter 75000, loss: 0.146762
 >> iter 76000, loss: 0.060840
 >> iter 77000, loss: 0.028243
 >> iter 78000, loss: 0.015813
 >> iter 79000, loss: 0.010786
 >> iter 80000, loss: 0.008129
   Number of active neurons: 10
 >> iter 81000, loss: 0.104908
 >> iter 82000, loss: 0.072046
 >> iter 83000, loss: 0.059456
 >> iter 84000, loss: 0.026088
 >> iter 85000, loss: 0.013181
 >> iter 86000, loss: 0.104938
 >> iter 87000, loss: 0.043577
 >> iter 88000, loss: 0.019315
 >> iter 89000, loss: 0.023244
 >> iter 90000, loss: 0.011456
   Number of active neurons: 10
 >> iter 91000, loss: 0.036371
 >> iter 92000, loss: 0.016392
 >> iter 93000, loss: 0.020497
 >> iter 94000, loss: 0.019101
 >> iter 95000, loss: 0.009592
 >> iter 96000, loss: 0.005898
 >> iter 97000, loss: 0.043768
 >> iter 98000, loss: 0.180271
 >> iter 99000, loss: 0.071866
 >> iter 100000, loss: 0.031202
   Number of active neurons: 10
 >> iter 101000, loss: 0.016348
 >> iter 102000, loss: 0.076606
 >> iter 103000, loss: 0.031573
 >> iter 104000, loss: 0.014639
 >> iter 105000, loss: 0.008122
 >> iter 106000, loss: 0.006064
 >> iter 107000, loss: 0.004794
 >> iter 108000, loss: 0.004478
 >> iter 109000, loss: 0.003816
 >> iter 110000, loss: 0.003810
   Number of active neurons: 10
 >> iter 111000, loss: 0.007340
 >> iter 112000, loss: 0.005568
 >> iter 113000, loss: 0.039742
 >> iter 114000, loss: 0.108260
 >> iter 115000, loss: 0.042505
 >> iter 116000, loss: 0.046174
 >> iter 117000, loss: 0.085031
 >> iter 118000, loss: 0.056026
 >> iter 119000, loss: 0.023264
 >> iter 120000, loss: 0.010820
   Number of active neurons: 10
 >> iter 121000, loss: 0.006096
 >> iter 122000, loss: 0.004484
 >> iter 123000, loss: 0.003466
 >> iter 124000, loss: 0.003027
 >> iter 125000, loss: 0.002825
 >> iter 126000, loss: 0.002739
 >> iter 127000, loss: 0.002658
 >> iter 128000, loss: 0.002492
 >> iter 129000, loss: 0.002453
 >> iter 130000, loss: 0.002371
   Number of active neurons: 10
 >> iter 131000, loss: 0.002295
 >> iter 132000, loss: 0.002218
 >> iter 133000, loss: 0.002139
 >> iter 134000, loss: 0.002634
 >> iter 135000, loss: 0.002559
 >> iter 136000, loss: 0.002140
 >> iter 137000, loss: 0.001914
 >> iter 138000, loss: 0.004784
 >> iter 139000, loss: 0.003016
 >> iter 140000, loss: 0.002367
   Number of active neurons: 10
 >> iter 141000, loss: 0.001973
 >> iter 142000, loss: 0.011229
 >> iter 143000, loss: 0.005350
 >> iter 144000, loss: 0.003039
 >> iter 145000, loss: 0.002131
 >> iter 146000, loss: 0.004835
 >> iter 147000, loss: 0.002735
 >> iter 148000, loss: 0.001983
 >> iter 149000, loss: 0.001694
 >> iter 150000, loss: 0.002682
   Number of active neurons: 10
 >> iter 151000, loss: 0.019910
 >> iter 152000, loss: 0.008258
 >> iter 153000, loss: 0.004189
 >> iter 154000, loss: 0.002377
 >> iter 155000, loss: 0.001703
 >> iter 156000, loss: 0.001502
 >> iter 157000, loss: 0.034015
 >> iter 158000, loss: 0.013592
 >> iter 159000, loss: 0.005854
 >> iter 160000, loss: 0.013199
   Number of active neurons: 10
 >> iter 161000, loss: 0.005711
 >> iter 162000, loss: 0.002888
 >> iter 163000, loss: 0.001942
 >> iter 164000, loss: 0.001557
 >> iter 165000, loss: 0.001352
 >> iter 166000, loss: 0.001283
 >> iter 167000, loss: 0.001302
 >> iter 168000, loss: 0.001310
 >> iter 169000, loss: 0.001178
 >> iter 170000, loss: 0.001121
   Number of active neurons: 10
 >> iter 171000, loss: 0.001124
 >> iter 172000, loss: 0.001068
 >> iter 173000, loss: 0.026177
 >> iter 174000, loss: 0.043586
 >> iter 175000, loss: 0.017068
 >> iter 176000, loss: 0.007249
 >> iter 177000, loss: 0.034068
 >> iter 178000, loss: 0.045290
 >> iter 179000, loss: 0.017605
 >> iter 180000, loss: 0.007362
   Number of active neurons: 10
 >> iter 181000, loss: 0.003514
 >> iter 182000, loss: 0.003671
 >> iter 183000, loss: 0.003840
 >> iter 184000, loss: 0.002275
 >> iter 185000, loss: 0.001844
 >> iter 186000, loss: 0.002944
 >> iter 187000, loss: 0.001954
 >> iter 188000, loss: 0.001428
 >> iter 189000, loss: 0.001256
 >> iter 190000, loss: 0.001138
   Number of active neurons: 10
 >> iter 191000, loss: 0.001049
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.023418
 >> iter 2000, loss: 10.833726
 >> iter 3000, loss: 8.843536
 >> iter 4000, loss: 8.079272
 >> iter 5000, loss: 7.820576
 >> iter 6000, loss: 7.681417
 >> iter 7000, loss: 7.647286
 >> iter 8000, loss: 7.606438
 >> iter 9000, loss: 7.593758
 >> iter 10000, loss: 7.582301
   Number of active neurons: 10
 >> iter 11000, loss: 7.586508
 >> iter 12000, loss: 7.576281
 >> iter 13000, loss: 7.584933
 >> iter 14000, loss: 7.577786
 >> iter 15000, loss: 7.580983
 >> iter 16000, loss: 7.569999
 >> iter 17000, loss: 7.578753
 >> iter 18000, loss: 7.569248
 >> iter 19000, loss: 7.575661
 >> iter 20000, loss: 7.584494
   Number of active neurons: 10
 >> iter 21000, loss: 7.527778
 >> iter 22000, loss: 7.326055
 >> iter 23000, loss: 7.119259
 >> iter 24000, loss: 6.877388
 >> iter 25000, loss: 6.678001
 >> iter 26000, loss: 6.313089
 >> iter 27000, loss: 6.048721
 >> iter 28000, loss: 5.756020
 >> iter 29000, loss: 5.481205
 >> iter 30000, loss: 4.678419
   Number of active neurons: 10
 >> iter 31000, loss: 4.263234
 >> iter 32000, loss: 3.905371
 >> iter 33000, loss: 4.001493
 >> iter 34000, loss: 2.478718
 >> iter 35000, loss: 1.208692
 >> iter 36000, loss: 0.640087
 >> iter 37000, loss: 0.552992
 >> iter 38000, loss: 0.258862
 >> iter 39000, loss: 0.328728
 >> iter 40000, loss: 0.163562
   Number of active neurons: 10
 >> iter 41000, loss: 0.161969
 >> iter 42000, loss: 0.145429
 >> iter 43000, loss: 0.089441
 >> iter 44000, loss: 0.052129
 >> iter 45000, loss: 0.030985
 >> iter 46000, loss: 0.024445
 >> iter 47000, loss: 0.018371
 >> iter 48000, loss: 0.044031
 >> iter 49000, loss: 0.034973
 >> iter 50000, loss: 0.024618
   Number of active neurons: 10
 >> iter 51000, loss: 0.015495
 >> iter 52000, loss: 0.073104
 >> iter 53000, loss: 0.034213
 >> iter 54000, loss: 0.024277
 >> iter 55000, loss: 0.100056
 >> iter 56000, loss: 0.079724
 >> iter 57000, loss: 0.037184
 >> iter 58000, loss: 0.020821
 >> iter 59000, loss: 0.013002
 >> iter 60000, loss: 0.034923
   Number of active neurons: 10
 >> iter 61000, loss: 0.049543
 >> iter 62000, loss: 0.061864
 >> iter 63000, loss: 0.037630
 >> iter 64000, loss: 0.020774
 >> iter 65000, loss: 0.053496
 >> iter 66000, loss: 0.023727
 >> iter 67000, loss: 0.012287
 >> iter 68000, loss: 0.021212
 >> iter 69000, loss: 0.025551
 >> iter 70000, loss: 0.164254
   Number of active neurons: 10
 >> iter 71000, loss: 0.069695
 >> iter 72000, loss: 0.202196
 >> iter 73000, loss: 0.079504
 >> iter 74000, loss: 0.064065
 >> iter 75000, loss: 0.054768
 >> iter 76000, loss: 0.046140
 >> iter 77000, loss: 0.021917
 >> iter 78000, loss: 0.023266
 >> iter 79000, loss: 0.012468
 >> iter 80000, loss: 0.008157
   Number of active neurons: 10
 >> iter 81000, loss: 0.006630
 >> iter 82000, loss: 0.009816
 >> iter 83000, loss: 0.007440
 >> iter 84000, loss: 0.022508
 >> iter 85000, loss: 0.019755
 >> iter 86000, loss: 0.011890
 >> iter 87000, loss: 0.007941
 >> iter 88000, loss: 0.005922
 >> iter 89000, loss: 0.037795
 >> iter 90000, loss: 0.016560
   Number of active neurons: 10
 >> iter 91000, loss: 0.008578
 >> iter 92000, loss: 0.033767
 >> iter 93000, loss: 0.198135
 >> iter 94000, loss: 0.076806
 >> iter 95000, loss: 0.033078
 >> iter 96000, loss: 0.091695
 >> iter 97000, loss: 0.039922
 >> iter 98000, loss: 0.018044
 >> iter 99000, loss: 0.009805
 >> iter 100000, loss: 0.006782
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.979206
 >> iter 2000, loss: 10.863828
 >> iter 3000, loss: 8.834108
 >> iter 4000, loss: 8.068371
 >> iter 5000, loss: 7.783202
 >> iter 6000, loss: 7.645996
 >> iter 7000, loss: 7.599459
 >> iter 8000, loss: 7.562751
 >> iter 9000, loss: 7.558133
 >> iter 10000, loss: 7.559859
   Number of active neurons: 10
 >> iter 11000, loss: 7.558207
 >> iter 12000, loss: 7.537808
 >> iter 13000, loss: 7.546636
 >> iter 14000, loss: 7.542563
 >> iter 15000, loss: 7.548130
 >> iter 16000, loss: 7.539512
 >> iter 17000, loss: 7.547262
 >> iter 18000, loss: 7.532948
 >> iter 19000, loss: 7.512691
 >> iter 20000, loss: 7.333064
   Number of active neurons: 10
 >> iter 21000, loss: 7.202159
 >> iter 22000, loss: 6.902571
 >> iter 23000, loss: 6.691542
 >> iter 24000, loss: 6.316572
 >> iter 25000, loss: 5.905146
 >> iter 26000, loss: 5.587677
 >> iter 27000, loss: 5.363471
 >> iter 28000, loss: 5.210174
 >> iter 29000, loss: 5.211753
 >> iter 30000, loss: 5.147509
   Number of active neurons: 10
 >> iter 31000, loss: 4.985124
 >> iter 32000, loss: 4.778214
 >> iter 33000, loss: 4.752557
 >> iter 34000, loss: 4.744919
 >> iter 35000, loss: 3.775706
 >> iter 36000, loss: 2.435787
 >> iter 37000, loss: 1.375475
 >> iter 38000, loss: 0.844740
 >> iter 39000, loss: 0.545555
 >> iter 40000, loss: 0.563262
   Number of active neurons: 10
 >> iter 41000, loss: 0.615990
 >> iter 42000, loss: 0.331500
 >> iter 43000, loss: 0.205447
 >> iter 44000, loss: 0.202134
 >> iter 45000, loss: 0.266859
 >> iter 46000, loss: 0.174035
 >> iter 47000, loss: 0.121136
 >> iter 48000, loss: 0.140465
 >> iter 49000, loss: 0.099126
 >> iter 50000, loss: 0.192560
   Number of active neurons: 10
 >> iter 51000, loss: 0.182161
 >> iter 52000, loss: 0.152973
 >> iter 53000, loss: 0.131235
 >> iter 54000, loss: 0.088200
 >> iter 55000, loss: 0.144383
 >> iter 56000, loss: 0.165650
 >> iter 57000, loss: 0.081034
 >> iter 58000, loss: 0.059353
 >> iter 59000, loss: 0.073483
 >> iter 60000, loss: 0.108636
   Number of active neurons: 10
 >> iter 61000, loss: 0.103412
 >> iter 62000, loss: 0.073400
 >> iter 63000, loss: 0.048959
 >> iter 64000, loss: 0.046755
 >> iter 65000, loss: 0.061932
 >> iter 66000, loss: 0.070897
 >> iter 67000, loss: 0.108491
 >> iter 68000, loss: 0.052175
 >> iter 69000, loss: 0.067178
 >> iter 70000, loss: 0.099561
   Number of active neurons: 10
 >> iter 71000, loss: 0.054761
 >> iter 72000, loss: 0.031572
 >> iter 73000, loss: 0.042118
 >> iter 74000, loss: 0.025302
 >> iter 75000, loss: 0.114412
 >> iter 76000, loss: 0.073210
 >> iter 77000, loss: 0.072867
 >> iter 78000, loss: 0.034932
 >> iter 79000, loss: 0.020161
 >> iter 80000, loss: 0.014647
   Number of active neurons: 10
 >> iter 81000, loss: 0.011746
 >> iter 82000, loss: 0.081213
 >> iter 83000, loss: 0.080993
 >> iter 84000, loss: 0.043233
 >> iter 85000, loss: 0.034674
 >> iter 86000, loss: 0.085232
 >> iter 87000, loss: 0.073329
 >> iter 88000, loss: 0.113403
 >> iter 89000, loss: 0.049556
 >> iter 90000, loss: 0.040594
   Number of active neurons: 10
 >> iter 91000, loss: 0.021366
 >> iter 92000, loss: 0.020172
 >> iter 93000, loss: 0.013175
 >> iter 94000, loss: 0.010204
 >> iter 95000, loss: 0.008989
 >> iter 96000, loss: 0.024061
 >> iter 97000, loss: 0.014330
 >> iter 98000, loss: 0.037587
 >> iter 99000, loss: 0.024339
 >> iter 100000, loss: 0.013708
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 15.980145
 >> iter 2000, loss: 10.799346
 >> iter 3000, loss: 8.868748
 >> iter 4000, loss: 8.073449
 >> iter 5000, loss: 7.766303
 >> iter 6000, loss: 7.631180
 >> iter 7000, loss: 7.595494
 >> iter 8000, loss: 7.569325
 >> iter 9000, loss: 7.567470
 >> iter 10000, loss: 7.551209
   Number of active neurons: 10
 >> iter 11000, loss: 7.556490
 >> iter 12000, loss: 7.602764
 >> iter 13000, loss: 7.569577
 >> iter 14000, loss: 7.545720
 >> iter 15000, loss: 7.546953
 >> iter 16000, loss: 7.537162
 >> iter 17000, loss: 7.546102
 >> iter 18000, loss: 7.536147
 >> iter 19000, loss: 7.545414
 >> iter 20000, loss: 7.532527
   Number of active neurons: 8
 >> iter 21000, loss: 7.542289
 >> iter 22000, loss: 7.526498
 >> iter 23000, loss: 7.533163
 >> iter 24000, loss: 7.530867
 >> iter 25000, loss: 7.549576
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 7.533322
 >> iter 27000, loss: 7.539865
 >> iter 28000, loss: 7.530717
 >> iter 29000, loss: 7.535415
 >> iter 30000, loss: 7.528940
   Number of active neurons: 8
 >> iter 31000, loss: 7.525301
 >> iter 32000, loss: 7.322592
 >> iter 33000, loss: 6.987480
 >> iter 34000, loss: 6.639917
 >> iter 35000, loss: 6.302321
 >> iter 36000, loss: 6.061726
 >> iter 37000, loss: 5.944874
 >> iter 38000, loss: 5.847050
 >> iter 39000, loss: 5.879347
 >> iter 40000, loss: 5.799417
   Number of active neurons: 10
 >> iter 41000, loss: 5.741941
 >> iter 42000, loss: 5.620952
 >> iter 43000, loss: 5.550934
 >> iter 44000, loss: 5.312042
 >> iter 45000, loss: 3.890896
 >> iter 46000, loss: 1.965827
 >> iter 47000, loss: 1.071440
 >> iter 48000, loss: 0.825372
 >> iter 49000, loss: 0.500192
 >> iter 50000, loss: 0.439876
   Number of active neurons: 10
 >> iter 51000, loss: 0.409983
 >> iter 52000, loss: 0.342035
 >> iter 53000, loss: 0.239202
 >> iter 54000, loss: 0.183526
 >> iter 55000, loss: 0.242557
 >> iter 56000, loss: 0.184761
 >> iter 57000, loss: 0.318004
 >> iter 58000, loss: 0.181758
 >> iter 59000, loss: 0.111980
 >> iter 60000, loss: 0.123547
   Number of active neurons: 10
 >> iter 61000, loss: 0.179196
 >> iter 62000, loss: 0.338691
 >> iter 63000, loss: 0.335447
 >> iter 64000, loss: 0.300215
 >> iter 65000, loss: 0.138765
 >> iter 66000, loss: 0.155914
 >> iter 67000, loss: 0.111342
 >> iter 68000, loss: 0.249860
 >> iter 69000, loss: 0.175236
 >> iter 70000, loss: 0.097635
   Number of active neurons: 10
 >> iter 71000, loss: 0.082048
 >> iter 72000, loss: 0.043464
 >> iter 73000, loss: 0.261857
 >> iter 74000, loss: 0.187722
 >> iter 75000, loss: 0.126792
 >> iter 76000, loss: 0.159670
 >> iter 77000, loss: 0.079810
 >> iter 78000, loss: 0.038134
 >> iter 79000, loss: 0.129277
 >> iter 80000, loss: 0.057063
   Number of active neurons: 10
 >> iter 81000, loss: 0.180613
 >> iter 82000, loss: 0.076241
 >> iter 83000, loss: 0.106120
 >> iter 84000, loss: 0.054888
 >> iter 85000, loss: 0.052472
 >> iter 86000, loss: 0.026137
 >> iter 87000, loss: 0.078190
 >> iter 88000, loss: 0.084891
 >> iter 89000, loss: 0.107954
 >> iter 90000, loss: 0.358057
   Number of active neurons: 10
 >> iter 91000, loss: 0.142214
 >> iter 92000, loss: 0.137921
 >> iter 93000, loss: 0.089700
 >> iter 94000, loss: 0.086657
 >> iter 95000, loss: 0.039936
 >> iter 96000, loss: 0.021832
 >> iter 97000, loss: 0.014899
 >> iter 98000, loss: 0.011579
 >> iter 99000, loss: 0.009820
 >> iter 100000, loss: 0.008838
   Number of active neurons: 10
 >> iter 101000, loss: 0.007993
 >> iter 102000, loss: 0.007659
 >> iter 103000, loss: 0.006994
 >> iter 104000, loss: 0.047117
 >> iter 105000, loss: 0.021947
 >> iter 106000, loss: 0.050689
 >> iter 107000, loss: 0.030347
 >> iter 108000, loss: 0.015000
 >> iter 109000, loss: 0.009178
 >> iter 110000, loss: 0.039420
   Number of active neurons: 10
 >> iter 111000, loss: 0.024665
 >> iter 112000, loss: 0.020414
 >> iter 113000, loss: 0.056513
 >> iter 114000, loss: 0.127441
 >> iter 115000, loss: 0.051310
 >> iter 116000, loss: 0.042696
 >> iter 117000, loss: 0.123920
 >> iter 118000, loss: 0.050225
 >> iter 119000, loss: 0.223836
 >> iter 120000, loss: 0.088135
   Number of active neurons: 10
 >> iter 121000, loss: 0.077976
 >> iter 122000, loss: 0.046018
 >> iter 123000, loss: 0.021107
 >> iter 124000, loss: 0.059044
 >> iter 125000, loss: 0.078427
 >> iter 126000, loss: 0.035069
 >> iter 127000, loss: 0.025771
 >> iter 128000, loss: 0.028045
 >> iter 129000, loss: 0.014226
 >> iter 130000, loss: 0.009207
   Number of active neurons: 10
 >> iter 131000, loss: 0.007680
 >> iter 132000, loss: 0.006854
 >> iter 133000, loss: 0.006228
 >> iter 134000, loss: 0.005296
 >> iter 135000, loss: 0.005033
 >> iter 136000, loss: 0.004514
 >> iter 137000, loss: 0.004352
 >> iter 138000, loss: 0.006345
 >> iter 139000, loss: 0.005443
 >> iter 140000, loss: 0.004452
   Number of active neurons: 10
 >> iter 141000, loss: 0.009059
 >> iter 142000, loss: 0.008228
 >> iter 143000, loss: 0.012496
 >> iter 144000, loss: 0.041052
 >> iter 145000, loss: 0.017905
 >> iter 146000, loss: 0.011984
 >> iter 147000, loss: 0.007400
 >> iter 148000, loss: 0.005079
 >> iter 149000, loss: 0.004326
 >> iter 150000, loss: 0.003981
   Number of active neurons: 10
 >> iter 151000, loss: 0.003624
 >> iter 152000, loss: 0.003742
 >> iter 153000, loss: 0.003451
 >> iter 154000, loss: 0.003206
 >> iter 155000, loss: 0.015523
 >> iter 156000, loss: 0.041343
 >> iter 157000, loss: 0.018616
 >> iter 158000, loss: 0.008993
 >> iter 159000, loss: 0.005446
 >> iter 160000, loss: 0.003891
   Number of active neurons: 10
 >> iter 161000, loss: 0.003491
 >> iter 162000, loss: 0.014980
 >> iter 163000, loss: 0.007416
 >> iter 164000, loss: 0.119460
 >> iter 165000, loss: 0.046325
 >> iter 166000, loss: 0.030970
 >> iter 167000, loss: 0.013298
 >> iter 168000, loss: 0.069439
 >> iter 169000, loss: 0.027500
 >> iter 170000, loss: 0.116477
   Number of active neurons: 10
 >> iter 171000, loss: 0.044864
 >> iter 172000, loss: 0.020487
 >> iter 173000, loss: 0.009290
 >> iter 174000, loss: 0.014921
 >> iter 175000, loss: 0.013441
 >> iter 176000, loss: 0.006773
 >> iter 177000, loss: 0.004217
 >> iter 178000, loss: 0.003437
 >> iter 179000, loss: 0.048021
 >> iter 180000, loss: 0.019482
   Number of active neurons: 10
 >> iter 181000, loss: 0.036963
 >> iter 182000, loss: 0.041128
 >> iter 183000, loss: 0.017060
 >> iter 184000, loss: 0.008380
 >> iter 185000, loss: 0.004980
 >> iter 186000, loss: 0.009322
 >> iter 187000, loss: 0.005470
 >> iter 188000, loss: 0.016858
 >> iter 189000, loss: 0.007905
 >> iter 190000, loss: 0.004492
   Number of active neurons: 10
 >> iter 191000, loss: 0.003186
 >> iter 192000, loss: 0.002587
 >> iter 193000, loss: 0.003457
 >> iter 194000, loss: 0.019466
 >> iter 195000, loss: 0.013025
 >> iter 196000, loss: 0.007960
 >> iter 197000, loss: 0.050995
 >> iter 198000, loss: 0.020420
 >> iter 199000, loss: 0.008974
 >> iter 200000, loss: 0.004847
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.000322
 >> iter 2000, loss: 10.792300
 >> iter 3000, loss: 8.810504
 >> iter 4000, loss: 8.010675
 >> iter 5000, loss: 7.718827
 >> iter 6000, loss: 7.602767
 >> iter 7000, loss: 7.563115
 >> iter 8000, loss: 7.533086
 >> iter 9000, loss: 7.534870
 >> iter 10000, loss: 7.520008
   Number of active neurons: 7
 >> iter 11000, loss: 7.526606
 >> iter 12000, loss: 7.514711
 >> iter 13000, loss: 7.526306
 >> iter 14000, loss: 7.515301
 >> iter 15000, loss: 7.527415
   Number of active neurons: 7
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 7.532627
 >> iter 17000, loss: 7.533874
 >> iter 18000, loss: 7.506596
 >> iter 19000, loss: 7.498341
 >> iter 20000, loss: 7.427319
   Number of active neurons: 10
 >> iter 21000, loss: 7.346780
 >> iter 22000, loss: 7.128142
 >> iter 23000, loss: 6.989989
 >> iter 24000, loss: 6.862060
 >> iter 25000, loss: 6.700920
 >> iter 26000, loss: 6.440381
 >> iter 27000, loss: 6.186684
 >> iter 28000, loss: 5.864971
 >> iter 29000, loss: 5.710410
 >> iter 30000, loss: 5.423628
   Number of active neurons: 10
 >> iter 31000, loss: 5.294564
 >> iter 32000, loss: 5.137478
 >> iter 33000, loss: 4.928650
 >> iter 34000, loss: 4.980874
 >> iter 35000, loss: 4.689100
 >> iter 36000, loss: 4.227743
 >> iter 37000, loss: 3.958633
 >> iter 38000, loss: 3.668842
 >> iter 39000, loss: 3.626202
 >> iter 40000, loss: 3.490725
   Number of active neurons: 10
 >> iter 41000, loss: 3.446799
 >> iter 42000, loss: 3.377646
 >> iter 43000, loss: 3.473365
 >> iter 44000, loss: 3.345805
 >> iter 45000, loss: 3.282876
 >> iter 46000, loss: 3.110937
 >> iter 47000, loss: 3.091748
 >> iter 48000, loss: 3.059784
 >> iter 49000, loss: 2.962907
 >> iter 50000, loss: 3.097662
   Number of active neurons: 10
 >> iter 51000, loss: 3.020091
 >> iter 52000, loss: 3.426095
 >> iter 53000, loss: 3.184666
 >> iter 54000, loss: 3.076477
 >> iter 55000, loss: 3.187877
 >> iter 56000, loss: 3.292179
 >> iter 57000, loss: 3.346809
 >> iter 58000, loss: 3.241206
 >> iter 59000, loss: 3.310995
 >> iter 60000, loss: 3.132341
   Number of active neurons: 10
 >> iter 61000, loss: 3.062138
 >> iter 62000, loss: 3.111714
 >> iter 63000, loss: 2.852429
 >> iter 64000, loss: 3.336503
 >> iter 65000, loss: 3.173904
 >> iter 66000, loss: 3.017563
 >> iter 67000, loss: 2.487751
 >> iter 68000, loss: 2.321123
 >> iter 69000, loss: 2.597960
 >> iter 70000, loss: 2.676157
   Number of active neurons: 10
 >> iter 71000, loss: 2.524436
 >> iter 72000, loss: 2.546739
 >> iter 73000, loss: 2.372687
 >> iter 74000, loss: 2.523358
 >> iter 75000, loss: 2.267456
 >> iter 76000, loss: 2.284182
 >> iter 77000, loss: 2.147500
 >> iter 78000, loss: 2.321453
 >> iter 79000, loss: 2.615128
 >> iter 80000, loss: 2.531324
   Number of active neurons: 10
 >> iter 81000, loss: 2.395128
 >> iter 82000, loss: 2.298994
 >> iter 83000, loss: 2.217101
 >> iter 84000, loss: 2.343063
 >> iter 85000, loss: 2.357306
 >> iter 86000, loss: 2.349342
 >> iter 87000, loss: 2.194223
 >> iter 88000, loss: 2.160406
 >> iter 89000, loss: 2.045163
 >> iter 90000, loss: 2.221142
   Number of active neurons: 10
 >> iter 91000, loss: 2.099280
 >> iter 92000, loss: 1.976964
 >> iter 93000, loss: 2.265670
 >> iter 94000, loss: 2.300395
 >> iter 95000, loss: 2.281923
 >> iter 96000, loss: 2.241347
 >> iter 97000, loss: 2.225047
 >> iter 98000, loss: 2.538363
 >> iter 99000, loss: 2.257625
 >> iter 100000, loss: 2.290137
   Number of active neurons: 10
 >> iter 101000, loss: 2.131449
 >> iter 102000, loss: 2.297051
 >> iter 103000, loss: 2.248180
 >> iter 104000, loss: 2.637280
 >> iter 105000, loss: 2.434542
 >> iter 106000, loss: 2.301015
 >> iter 107000, loss: 2.300401
 >> iter 108000, loss: 2.335204
 >> iter 109000, loss: 2.215478
 >> iter 110000, loss: 2.273289
   Number of active neurons: 10
 >> iter 111000, loss: 2.162488
 >> iter 112000, loss: 2.505364
 >> iter 113000, loss: 2.439486
 >> iter 114000, loss: 2.444993
 >> iter 115000, loss: 2.250629
 >> iter 116000, loss: 2.246673
 >> iter 117000, loss: 2.042534
 >> iter 118000, loss: 2.510390
 >> iter 119000, loss: 2.318174
 >> iter 120000, loss: 2.302360
   Number of active neurons: 10
 >> iter 121000, loss: 2.290040
 >> iter 122000, loss: 2.191465
 >> iter 123000, loss: 2.443659
 >> iter 124000, loss: 2.142619
 >> iter 125000, loss: 2.237237
 >> iter 126000, loss: 2.348401
 >> iter 127000, loss: 2.191554
 >> iter 128000, loss: 2.343933
 >> iter 129000, loss: 2.136294
 >> iter 130000, loss: 2.278511
   Number of active neurons: 10
 >> iter 131000, loss: 2.041210
 >> iter 132000, loss: 1.945686
 >> iter 133000, loss: 2.015985
 >> iter 134000, loss: 2.001012
 >> iter 135000, loss: 1.894431
 >> iter 136000, loss: 1.902226
 >> iter 137000, loss: 1.769375
 >> iter 138000, loss: 1.727675
 >> iter 139000, loss: 1.620512
 >> iter 140000, loss: 1.689539
   Number of active neurons: 10
 >> iter 141000, loss: 1.756496
 >> iter 142000, loss: 1.672341
 >> iter 143000, loss: 1.615273
 >> iter 144000, loss: 1.795941
 >> iter 145000, loss: 1.668747
 >> iter 146000, loss: 1.639863
 >> iter 147000, loss: 1.661875
 >> iter 148000, loss: 1.603257
 >> iter 149000, loss: 1.802708
 >> iter 150000, loss: 1.728060
   Number of active neurons: 10
 >> iter 151000, loss: 1.579733
 >> iter 152000, loss: 1.737672
 >> iter 153000, loss: 2.023054
 >> iter 154000, loss: 1.762306
 >> iter 155000, loss: 1.631974
 >> iter 156000, loss: 1.630336
 >> iter 157000, loss: 1.541211
 >> iter 158000, loss: 1.595075
 >> iter 159000, loss: 1.587555
 >> iter 160000, loss: 1.571232
   Number of active neurons: 10
 >> iter 161000, loss: 1.470649
 >> iter 162000, loss: 1.562412
 >> iter 163000, loss: 1.491612
 >> iter 164000, loss: 1.635380
 >> iter 165000, loss: 1.564294
 >> iter 166000, loss: 1.590336
 >> iter 167000, loss: 1.561979
 >> iter 168000, loss: 1.631541
 >> iter 169000, loss: 1.515801
 >> iter 170000, loss: 1.673236
   Number of active neurons: 10
 >> iter 171000, loss: 1.607872
 >> iter 172000, loss: 1.604501
 >> iter 173000, loss: 1.489003
 >> iter 174000, loss: 1.537527
 >> iter 175000, loss: 1.491362
 >> iter 176000, loss: 1.538468
 >> iter 177000, loss: 1.482116
 >> iter 178000, loss: 1.522236
 >> iter 179000, loss: 1.439631
 >> iter 180000, loss: 1.552461
   Number of active neurons: 10
 >> iter 181000, loss: 1.520377
 >> iter 182000, loss: 1.542096
 >> iter 183000, loss: 1.468976
 >> iter 184000, loss: 1.504984
 >> iter 185000, loss: 1.532215
 >> iter 186000, loss: 1.582881
 >> iter 187000, loss: 1.754228
 >> iter 188000, loss: 1.513490
 >> iter 189000, loss: 1.425955
 >> iter 190000, loss: 1.292730
   Number of active neurons: 10
 >> iter 191000, loss: 1.313246
 >> iter 192000, loss: 0.990887
 >> iter 193000, loss: 0.801573
 >> iter 194000, loss: 0.734502
 >> iter 195000, loss: 0.697910
 >> iter 196000, loss: 0.383514
 >> iter 197000, loss: 0.474261
 >> iter 198000, loss: 0.388494
 >> iter 199000, loss: 0.245391
 >> iter 200000, loss: 0.203666
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.029999400012
   - Test - Long: 0.0
   - Test - Big: 0.069999300007
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.990833
 >> iter 2000, loss: 10.830768
 >> iter 3000, loss: 8.846618
 >> iter 4000, loss: 8.069682
 >> iter 5000, loss: 7.770077
 >> iter 6000, loss: 7.657325
 >> iter 7000, loss: 7.612430
 >> iter 8000, loss: 7.580713
 >> iter 9000, loss: 7.590943
 >> iter 10000, loss: 7.568739
   Number of active neurons: 10
 >> iter 11000, loss: 7.569220
 >> iter 12000, loss: 7.573711
 >> iter 13000, loss: 7.573740
 >> iter 14000, loss: 7.562696
 >> iter 15000, loss: 7.567062
 >> iter 16000, loss: 7.561492
 >> iter 17000, loss: 7.569681
 >> iter 18000, loss: 7.558001
 >> iter 19000, loss: 7.563213
 >> iter 20000, loss: 7.555956
   Number of active neurons: 10
 >> iter 21000, loss: 7.563894
 >> iter 22000, loss: 7.557185
 >> iter 23000, loss: 7.561382
 >> iter 24000, loss: 7.555179
 >> iter 25000, loss: 7.560554
 >> iter 26000, loss: 7.549223
 >> iter 27000, loss: 7.555903
 >> iter 28000, loss: 7.550946
 >> iter 29000, loss: 7.559405
 >> iter 30000, loss: 7.553958
   Number of active neurons: 10
 >> iter 31000, loss: 7.558600
 >> iter 32000, loss: 7.551074
 >> iter 33000, loss: 7.560207
 >> iter 34000, loss: 7.547454
 >> iter 35000, loss: 7.545776
 >> iter 36000, loss: 7.521292
 >> iter 37000, loss: 7.336462
 >> iter 38000, loss: 7.082755
 >> iter 39000, loss: 6.879386
 >> iter 40000, loss: 6.765681
   Number of active neurons: 10
 >> iter 41000, loss: 6.622893
 >> iter 42000, loss: 6.397856
 >> iter 43000, loss: 6.171999
 >> iter 44000, loss: 5.993682
 >> iter 45000, loss: 5.814943
 >> iter 46000, loss: 5.672622
 >> iter 47000, loss: 5.542630
 >> iter 48000, loss: 5.512545
 >> iter 49000, loss: 5.425172
 >> iter 50000, loss: 5.322096
   Number of active neurons: 10
 >> iter 51000, loss: 5.254591
 >> iter 52000, loss: 5.109335
 >> iter 53000, loss: 5.186670
 >> iter 54000, loss: 5.097850
 >> iter 55000, loss: 5.067309
 >> iter 56000, loss: 5.016638
 >> iter 57000, loss: 5.008013
 >> iter 58000, loss: 4.982910
 >> iter 59000, loss: 4.961383
 >> iter 60000, loss: 4.786474
   Number of active neurons: 10
 >> iter 61000, loss: 4.684142
 >> iter 62000, loss: 4.552751
 >> iter 63000, loss: 4.457183
 >> iter 64000, loss: 3.894122
 >> iter 65000, loss: 2.258923
 >> iter 66000, loss: 1.208365
 >> iter 67000, loss: 0.628276
 >> iter 68000, loss: 0.534236
 >> iter 69000, loss: 0.394697
 >> iter 70000, loss: 0.440147
   Number of active neurons: 10
 >> iter 71000, loss: 0.302418
 >> iter 72000, loss: 0.204167
 >> iter 73000, loss: 0.134177
 >> iter 74000, loss: 0.081579
 >> iter 75000, loss: 0.308455
 >> iter 76000, loss: 0.176812
 >> iter 77000, loss: 0.122336
 >> iter 78000, loss: 0.084984
 >> iter 79000, loss: 0.154143
 >> iter 80000, loss: 0.166391
   Number of active neurons: 10
 >> iter 81000, loss: 0.092675
 >> iter 82000, loss: 0.073298
 >> iter 83000, loss: 0.041393
 >> iter 84000, loss: 0.098047
 >> iter 85000, loss: 0.093147
 >> iter 86000, loss: 0.091532
 >> iter 87000, loss: 0.105120
 >> iter 88000, loss: 0.080621
 >> iter 89000, loss: 0.084186
 >> iter 90000, loss: 0.075115
   Number of active neurons: 10
 >> iter 91000, loss: 0.049533
 >> iter 92000, loss: 0.035357
 >> iter 93000, loss: 0.030652
 >> iter 94000, loss: 0.141082
 >> iter 95000, loss: 0.132674
 >> iter 96000, loss: 0.137454
 >> iter 97000, loss: 0.313615
 >> iter 98000, loss: 0.184536
 >> iter 99000, loss: 0.083465
 >> iter 100000, loss: 0.047730
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.901127
 >> iter 2000, loss: 10.738833
 >> iter 3000, loss: 8.786810
 >> iter 4000, loss: 8.055581
 >> iter 5000, loss: 7.785589
 >> iter 6000, loss: 7.660765
 >> iter 7000, loss: 7.611029
 >> iter 8000, loss: 7.540630
 >> iter 9000, loss: 7.338282
 >> iter 10000, loss: 6.840546
   Number of active neurons: 10
 >> iter 11000, loss: 6.414522
 >> iter 12000, loss: 6.133132
 >> iter 13000, loss: 6.005782
 >> iter 14000, loss: 5.828387
 >> iter 15000, loss: 5.681713
 >> iter 16000, loss: 5.503715
 >> iter 17000, loss: 5.393367
 >> iter 18000, loss: 5.169266
 >> iter 19000, loss: 5.056125
 >> iter 20000, loss: 4.918557
   Number of active neurons: 10
 >> iter 21000, loss: 4.931374
 >> iter 22000, loss: 4.762230
 >> iter 23000, loss: 4.696713
 >> iter 24000, loss: 4.600022
 >> iter 25000, loss: 4.604766
 >> iter 26000, loss: 4.514440
 >> iter 27000, loss: 4.574064
 >> iter 28000, loss: 4.626613
 >> iter 29000, loss: 4.557783
 >> iter 30000, loss: 4.461650
   Number of active neurons: 10
 >> iter 31000, loss: 4.478884
 >> iter 32000, loss: 4.475213
 >> iter 33000, loss: 4.467975
 >> iter 34000, loss: 4.517444
 >> iter 35000, loss: 4.477199
 >> iter 36000, loss: 4.413196
 >> iter 37000, loss: 4.450651
 >> iter 38000, loss: 4.367500
 >> iter 39000, loss: 4.419420
 >> iter 40000, loss: 4.230282
   Number of active neurons: 10
 >> iter 41000, loss: 4.195145
 >> iter 42000, loss: 3.998230
 >> iter 43000, loss: 3.923435
 >> iter 44000, loss: 3.799974
 >> iter 45000, loss: 3.832153
 >> iter 46000, loss: 3.718278
 >> iter 47000, loss: 3.769796
 >> iter 48000, loss: 3.304014
 >> iter 49000, loss: 3.023195
 >> iter 50000, loss: 3.063144
   Number of active neurons: 10
 >> iter 51000, loss: 2.814782
 >> iter 52000, loss: 2.753753
 >> iter 53000, loss: 2.512873
 >> iter 54000, loss: 2.482298
 >> iter 55000, loss: 2.223372
 >> iter 56000, loss: 2.277681
 >> iter 57000, loss: 2.258075
 >> iter 58000, loss: 2.383573
 >> iter 59000, loss: 1.833530
 >> iter 60000, loss: 1.700184
   Number of active neurons: 10
 >> iter 61000, loss: 1.924514
 >> iter 62000, loss: 1.895762
 >> iter 63000, loss: 1.724129
 >> iter 64000, loss: 1.543071
 >> iter 65000, loss: 1.470276
 >> iter 66000, loss: 1.459218
 >> iter 67000, loss: 1.717499
 >> iter 68000, loss: 1.551525
 >> iter 69000, loss: 1.361045
 >> iter 70000, loss: 1.606775
   Number of active neurons: 10
 >> iter 71000, loss: 1.411367
 >> iter 72000, loss: 1.685430
 >> iter 73000, loss: 1.506121
 >> iter 74000, loss: 1.601051
 >> iter 75000, loss: 1.327624
 >> iter 76000, loss: 1.388603
 >> iter 77000, loss: 1.364893
 >> iter 78000, loss: 1.620507
 >> iter 79000, loss: 1.630514
 >> iter 80000, loss: 1.532545
   Number of active neurons: 10
 >> iter 81000, loss: 1.294464
 >> iter 82000, loss: 1.496684
 >> iter 83000, loss: 1.421686
 >> iter 84000, loss: 1.296125
 >> iter 85000, loss: 1.344687
 >> iter 86000, loss: 1.277458
 >> iter 87000, loss: 1.660108
 >> iter 88000, loss: 1.864284
 >> iter 89000, loss: 1.524278
 >> iter 90000, loss: 1.595161
   Number of active neurons: 10
 >> iter 91000, loss: 1.352750
 >> iter 92000, loss: 1.324929
 >> iter 93000, loss: 1.239838
 >> iter 94000, loss: 1.137873
 >> iter 95000, loss: 1.143230
 >> iter 96000, loss: 1.287735
 >> iter 97000, loss: 1.190383
 >> iter 98000, loss: 1.245522
 >> iter 99000, loss: 1.308560
 >> iter 100000, loss: 1.349968
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 2.22595548089
   - Test - Long: 15.5542222889
   - Test - Big: 2.10697893021
   - Test - A: 1.65988934071
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.093439
 >> iter 2000, loss: 10.769261
 >> iter 3000, loss: 8.764671
 >> iter 4000, loss: 8.014233
 >> iter 5000, loss: 7.749267
 >> iter 6000, loss: 7.629789
 >> iter 7000, loss: 7.595448
 >> iter 8000, loss: 7.567716
 >> iter 9000, loss: 7.565241
 >> iter 10000, loss: 7.560879
   Number of active neurons: 9
 >> iter 11000, loss: 7.563697
 >> iter 12000, loss: 7.552824
 >> iter 13000, loss: 7.565843
 >> iter 14000, loss: 7.554728
 >> iter 15000, loss: 7.547834
 >> iter 16000, loss: 7.546721
 >> iter 17000, loss: 7.547849
 >> iter 18000, loss: 7.290828
 >> iter 19000, loss: 7.073910
 >> iter 20000, loss: 6.890292
   Number of active neurons: 10
 >> iter 21000, loss: 6.739360
 >> iter 22000, loss: 6.481141
 >> iter 23000, loss: 6.221622
 >> iter 24000, loss: 6.025542
 >> iter 25000, loss: 5.780920
 >> iter 26000, loss: 5.601379
 >> iter 27000, loss: 5.444937
 >> iter 28000, loss: 3.582471
 >> iter 29000, loss: 1.560520
 >> iter 30000, loss: 0.616420
   Number of active neurons: 10
 >> iter 31000, loss: 0.270828
 >> iter 32000, loss: 0.170432
 >> iter 33000, loss: 0.116143
 >> iter 34000, loss: 0.078019
 >> iter 35000, loss: 0.040570
 >> iter 36000, loss: 0.140974
 >> iter 37000, loss: 0.062427
 >> iter 38000, loss: 0.030450
 >> iter 39000, loss: 0.020737
 >> iter 40000, loss: 0.024677
   Number of active neurons: 10
 >> iter 41000, loss: 0.015477
 >> iter 42000, loss: 0.010982
 >> iter 43000, loss: 0.010099
 >> iter 44000, loss: 0.024076
 >> iter 45000, loss: 0.021518
 >> iter 46000, loss: 0.013721
 >> iter 47000, loss: 0.008939
 >> iter 48000, loss: 0.006975
 >> iter 49000, loss: 0.006586
 >> iter 50000, loss: 0.005912
   Number of active neurons: 10
 >> iter 51000, loss: 0.005031
 >> iter 52000, loss: 0.005571
 >> iter 53000, loss: 0.004837
 >> iter 54000, loss: 0.020580
 >> iter 55000, loss: 0.042914
 >> iter 56000, loss: 0.021346
 >> iter 57000, loss: 0.010427
 >> iter 58000, loss: 0.008155
 >> iter 59000, loss: 0.286756
 >> iter 60000, loss: 0.145595
   Number of active neurons: 10
 >> iter 61000, loss: 0.058455
 >> iter 62000, loss: 0.024690
 >> iter 63000, loss: 0.012837
 >> iter 64000, loss: 0.007572
 >> iter 65000, loss: 0.005475
 >> iter 66000, loss: 0.029988
 >> iter 67000, loss: 0.033967
 >> iter 68000, loss: 0.018662
 >> iter 69000, loss: 0.089117
 >> iter 70000, loss: 0.040341
   Number of active neurons: 10
 >> iter 71000, loss: 0.017324
 >> iter 72000, loss: 0.008704
 >> iter 73000, loss: 0.005363
 >> iter 74000, loss: 0.004401
 >> iter 75000, loss: 0.003633
 >> iter 76000, loss: 0.003776
 >> iter 77000, loss: 0.003373
 >> iter 78000, loss: 0.003045
 >> iter 79000, loss: 0.002862
 >> iter 80000, loss: 0.002772
   Number of active neurons: 10
 >> iter 81000, loss: 0.002756
 >> iter 82000, loss: 0.036343
 >> iter 83000, loss: 0.016426
 >> iter 84000, loss: 0.007848
 >> iter 85000, loss: 0.004499
 >> iter 86000, loss: 0.003247
 >> iter 87000, loss: 0.002834
 >> iter 88000, loss: 0.095839
 >> iter 89000, loss: 0.036938
 >> iter 90000, loss: 0.015226
   Number of active neurons: 10
 >> iter 91000, loss: 0.007274
 >> iter 92000, loss: 0.004188
 >> iter 93000, loss: 0.003111
 >> iter 94000, loss: 0.002876
 >> iter 95000, loss: 0.002439
 >> iter 96000, loss: 0.002258
 >> iter 97000, loss: 0.002137
 >> iter 98000, loss: 0.002082
 >> iter 99000, loss: 0.002056
 >> iter 100000, loss: 0.001983
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.892558
 >> iter 2000, loss: 10.696725
 >> iter 3000, loss: 8.758512
 >> iter 4000, loss: 8.035097
 >> iter 5000, loss: 7.779057
 >> iter 6000, loss: 7.653239
 >> iter 7000, loss: 7.609030
 >> iter 8000, loss: 7.579173
 >> iter 9000, loss: 7.578247
 >> iter 10000, loss: 7.599924
   Number of active neurons: 9
 >> iter 11000, loss: 7.580237
 >> iter 12000, loss: 7.564734
 >> iter 13000, loss: 7.567348
 >> iter 14000, loss: 7.560906
 >> iter 15000, loss: 7.560586
 >> iter 16000, loss: 7.554155
 >> iter 17000, loss: 7.563179
 >> iter 18000, loss: 7.551681
 >> iter 19000, loss: 7.561071
 >> iter 20000, loss: 7.550317
   Number of active neurons: 9
 >> iter 21000, loss: 7.555441
 >> iter 22000, loss: 7.551502
 >> iter 23000, loss: 7.566600
 >> iter 24000, loss: 7.496918
 >> iter 25000, loss: 7.464298
 >> iter 26000, loss: 7.184016
 >> iter 27000, loss: 6.953708
 >> iter 28000, loss: 6.641628
 >> iter 29000, loss: 6.401437
 >> iter 30000, loss: 6.230741
   Number of active neurons: 10
 >> iter 31000, loss: 6.093088
 >> iter 32000, loss: 5.906028
 >> iter 33000, loss: 5.655754
 >> iter 34000, loss: 5.147675
 >> iter 35000, loss: 4.283993
 >> iter 36000, loss: 2.472152
 >> iter 37000, loss: 1.006214
 >> iter 38000, loss: 0.440523
 >> iter 39000, loss: 0.226585
 >> iter 40000, loss: 0.213644
   Number of active neurons: 10
 >> iter 41000, loss: 0.094321
 >> iter 42000, loss: 0.053488
 >> iter 43000, loss: 0.091867
 >> iter 44000, loss: 0.194295
 >> iter 45000, loss: 0.089696
 >> iter 46000, loss: 0.063474
 >> iter 47000, loss: 0.034640
 >> iter 48000, loss: 0.022486
 >> iter 49000, loss: 0.014260
 >> iter 50000, loss: 0.010715
   Number of active neurons: 10
 >> iter 51000, loss: 0.008995
 >> iter 52000, loss: 0.056686
 >> iter 53000, loss: 0.025306
 >> iter 54000, loss: 0.013254
 >> iter 55000, loss: 0.008889
 >> iter 56000, loss: 0.006876
 >> iter 57000, loss: 0.006102
 >> iter 58000, loss: 0.005193
 >> iter 59000, loss: 0.004931
 >> iter 60000, loss: 0.040302
   Number of active neurons: 10
 >> iter 61000, loss: 0.017584
 >> iter 62000, loss: 0.009499
 >> iter 63000, loss: 0.006147
 >> iter 64000, loss: 0.004792
 >> iter 65000, loss: 0.004258
 >> iter 66000, loss: 0.003808
 >> iter 67000, loss: 0.003515
 >> iter 68000, loss: 0.003311
 >> iter 69000, loss: 0.003343
 >> iter 70000, loss: 0.003355
   Number of active neurons: 10
 >> iter 71000, loss: 0.003002
 >> iter 72000, loss: 0.002888
 >> iter 73000, loss: 0.003082
 >> iter 74000, loss: 0.002739
 >> iter 75000, loss: 0.011277
 >> iter 76000, loss: 0.006429
 >> iter 77000, loss: 0.003886
 >> iter 78000, loss: 0.007902
 >> iter 79000, loss: 0.004363
 >> iter 80000, loss: 0.003015
   Number of active neurons: 10
 >> iter 81000, loss: 0.002470
 >> iter 82000, loss: 0.002429
 >> iter 83000, loss: 0.002165
 >> iter 84000, loss: 0.002267
 >> iter 85000, loss: 0.002251
 >> iter 86000, loss: 0.002001
 >> iter 87000, loss: 0.004617
 >> iter 88000, loss: 0.002933
 >> iter 89000, loss: 0.002399
 >> iter 90000, loss: 0.002693
   Number of active neurons: 10
 >> iter 91000, loss: 0.002109
 >> iter 92000, loss: 0.001849
 >> iter 93000, loss: 0.001743
 >> iter 94000, loss: 0.004761
 >> iter 95000, loss: 0.005554
 >> iter 96000, loss: 0.003221
 >> iter 97000, loss: 0.002681
 >> iter 98000, loss: 0.029566
 >> iter 99000, loss: 0.011951
 >> iter 100000, loss: 0.005434
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.987392
 >> iter 2000, loss: 10.841980
 >> iter 3000, loss: 8.832135
 >> iter 4000, loss: 8.030143
 >> iter 5000, loss: 7.731804
 >> iter 6000, loss: 7.616328
 >> iter 7000, loss: 7.590397
 >> iter 8000, loss: 7.558627
 >> iter 9000, loss: 7.552998
 >> iter 10000, loss: 7.552136
   Number of active neurons: 8
 >> iter 11000, loss: 7.549580
 >> iter 12000, loss: 7.537146
 >> iter 13000, loss: 7.544683
 >> iter 14000, loss: 7.542947
 >> iter 15000, loss: 7.543679
 >> iter 16000, loss: 7.568431
 >> iter 17000, loss: 7.559792
 >> iter 18000, loss: 7.540596
 >> iter 19000, loss: 7.573948
 >> iter 20000, loss: 7.541711
   Number of active neurons: 8
 >> iter 21000, loss: 7.543524
 >> iter 22000, loss: 7.534707
 >> iter 23000, loss: 7.540559
 >> iter 24000, loss: 7.531382
 >> iter 25000, loss: 7.545737
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 7.532332
 >> iter 27000, loss: 7.539806
 >> iter 28000, loss: 7.531879
 >> iter 29000, loss: 7.542053
 >> iter 30000, loss: 7.544407
   Number of active neurons: 8
 >> iter 31000, loss: 7.546126
 >> iter 32000, loss: 7.536369
 >> iter 33000, loss: 7.538513
 >> iter 34000, loss: 7.521489
 >> iter 35000, loss: 7.565411
 >> iter 36000, loss: 7.460547
 >> iter 37000, loss: 7.295593
 >> iter 38000, loss: 7.045861
 >> iter 39000, loss: 6.804921
 >> iter 40000, loss: 6.549986
   Number of active neurons: 10
 >> iter 41000, loss: 6.430250
 >> iter 42000, loss: 6.280585
 >> iter 43000, loss: 6.204049
 >> iter 44000, loss: 6.105038
 >> iter 45000, loss: 6.062406
 >> iter 46000, loss: 5.984435
 >> iter 47000, loss: 5.953812
 >> iter 48000, loss: 5.863096
 >> iter 49000, loss: 5.846612
 >> iter 50000, loss: 5.689487
   Number of active neurons: 10
 >> iter 51000, loss: 5.646672
 >> iter 52000, loss: 5.471064
 >> iter 53000, loss: 5.533210
 >> iter 54000, loss: 5.409074
 >> iter 55000, loss: 5.504951
 >> iter 56000, loss: 5.113681
 >> iter 57000, loss: 5.063028
 >> iter 58000, loss: 4.788538
 >> iter 59000, loss: 4.758609
 >> iter 60000, loss: 4.729828
   Number of active neurons: 10
 >> iter 61000, loss: 4.551358
 >> iter 62000, loss: 4.432406
 >> iter 63000, loss: 4.438869
 >> iter 64000, loss: 4.362615
 >> iter 65000, loss: 4.305612
 >> iter 66000, loss: 4.392047
 >> iter 67000, loss: 4.271548
 >> iter 68000, loss: 4.238897
 >> iter 69000, loss: 4.248920
 >> iter 70000, loss: 4.307608
   Number of active neurons: 10
 >> iter 71000, loss: 4.268753
 >> iter 72000, loss: 4.231751
 >> iter 73000, loss: 4.222842
 >> iter 74000, loss: 4.165877
 >> iter 75000, loss: 4.174532
 >> iter 76000, loss: 4.240109
 >> iter 77000, loss: 4.155005
 >> iter 78000, loss: 4.161849
 >> iter 79000, loss: 4.181413
 >> iter 80000, loss: 4.199452
   Number of active neurons: 10
 >> iter 81000, loss: 4.183229
 >> iter 82000, loss: 4.187589
 >> iter 83000, loss: 4.120230
 >> iter 84000, loss: 4.120954
 >> iter 85000, loss: 4.115892
 >> iter 86000, loss: 4.100640
 >> iter 87000, loss: 4.097055
 >> iter 88000, loss: 4.127991
 >> iter 89000, loss: 4.074484
 >> iter 90000, loss: 4.120065
   Number of active neurons: 10
 >> iter 91000, loss: 4.106803
 >> iter 92000, loss: 4.096398
 >> iter 93000, loss: 4.214417
 >> iter 94000, loss: 5.437085
 >> iter 95000, loss: 6.501436
 >> iter 96000, loss: 6.363300
 >> iter 97000, loss: 5.786740
 >> iter 98000, loss: 5.103952
 >> iter 99000, loss: 4.466953
 >> iter 100000, loss: 4.091076
   Number of active neurons: 10
 >> iter 101000, loss: 3.531107
 >> iter 102000, loss: 3.103432
 >> iter 103000, loss: 2.888443
 >> iter 104000, loss: 2.665606
 >> iter 105000, loss: 2.648732
 >> iter 106000, loss: 2.385239
 >> iter 107000, loss: 2.303483
 >> iter 108000, loss: 1.488464
 >> iter 109000, loss: 1.054178
 >> iter 110000, loss: 0.822353
   Number of active neurons: 10
 >> iter 111000, loss: 0.796784
 >> iter 112000, loss: 0.576896
 >> iter 113000, loss: 0.721471
 >> iter 114000, loss: 0.576202
 >> iter 115000, loss: 0.575216
 >> iter 116000, loss: 0.562501
 >> iter 117000, loss: 0.401696
 >> iter 118000, loss: 0.456231
 >> iter 119000, loss: 0.619024
 >> iter 120000, loss: 0.747159
   Number of active neurons: 10
 >> iter 121000, loss: 0.778047
 >> iter 122000, loss: 0.732481
 >> iter 123000, loss: 0.776340
 >> iter 124000, loss: 0.528659
 >> iter 125000, loss: 0.339799
 >> iter 126000, loss: 0.722272
 >> iter 127000, loss: 0.510369
 >> iter 128000, loss: 0.341043
 >> iter 129000, loss: 0.351439
 >> iter 130000, loss: 0.335200
   Number of active neurons: 10
 >> iter 131000, loss: 0.233915
 >> iter 132000, loss: 0.218730
 >> iter 133000, loss: 0.157407
 >> iter 134000, loss: 0.312674
 >> iter 135000, loss: 0.180254
 >> iter 136000, loss: 0.205652
 >> iter 137000, loss: 0.187400
 >> iter 138000, loss: 0.227318
 >> iter 139000, loss: 0.195103
 >> iter 140000, loss: 0.368794
   Number of active neurons: 10
 >> iter 141000, loss: 0.269341
 >> iter 142000, loss: 0.209422
 >> iter 143000, loss: 0.252088
 >> iter 144000, loss: 0.312676
 >> iter 145000, loss: 0.177311
 >> iter 146000, loss: 0.282187
 >> iter 147000, loss: 0.358273
 >> iter 148000, loss: 0.206258
 >> iter 149000, loss: 0.123985
 >> iter 150000, loss: 0.084883
   Number of active neurons: 10
 >> iter 151000, loss: 0.292235
 >> iter 152000, loss: 0.281306
 >> iter 153000, loss: 0.277552
 >> iter 154000, loss: 0.260596
 >> iter 155000, loss: 0.194484
 >> iter 156000, loss: 0.205954
 >> iter 157000, loss: 0.149763
 >> iter 158000, loss: 0.128166
 >> iter 159000, loss: 0.156835
 >> iter 160000, loss: 0.168072
   Number of active neurons: 10
 >> iter 161000, loss: 0.130535
 >> iter 162000, loss: 0.160515
 >> iter 163000, loss: 0.278382
 >> iter 164000, loss: 0.309125
 >> iter 165000, loss: 0.283393
 >> iter 166000, loss: 0.237677
 >> iter 167000, loss: 0.156610
 >> iter 168000, loss: 0.083838
 >> iter 169000, loss: 0.095702
 >> iter 170000, loss: 0.116075
   Number of active neurons: 10
 >> iter 171000, loss: 0.127710
 >> iter 172000, loss: 0.175974
 >> iter 173000, loss: 0.245897
 >> iter 174000, loss: 0.272459
 >> iter 175000, loss: 0.172064
 >> iter 176000, loss: 0.225748
 >> iter 177000, loss: 0.108024
 >> iter 178000, loss: 0.063939
 >> iter 179000, loss: 0.109105
 >> iter 180000, loss: 0.092240
   Number of active neurons: 10
 >> iter 181000, loss: 0.107884
 >> iter 182000, loss: 0.078755
 >> iter 183000, loss: 0.073751
 >> iter 184000, loss: 0.141784
 >> iter 185000, loss: 0.135398
 >> iter 186000, loss: 0.130271
 >> iter 187000, loss: 0.070704
 >> iter 188000, loss: 0.110284
 >> iter 189000, loss: 0.137301
 >> iter 190000, loss: 0.142134
   Number of active neurons: 10
 >> iter 191000, loss: 0.209391
 >> iter 192000, loss: 0.086042
 >> iter 193000, loss: 0.121786
 >> iter 194000, loss: 0.066809
 >> iter 195000, loss: 0.068475
 >> iter 196000, loss: 0.059707
 >> iter 197000, loss: 0.092798
 >> iter 198000, loss: 0.054255
 >> iter 199000, loss: 0.186546
 >> iter 200000, loss: 0.080330
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0029999700003
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.227853
 >> iter 2000, loss: 10.873914
 >> iter 3000, loss: 8.892667
 >> iter 4000, loss: 8.085072
 >> iter 5000, loss: 7.773733
 >> iter 6000, loss: 7.679488
 >> iter 7000, loss: 7.628165
 >> iter 8000, loss: 7.589724
 >> iter 9000, loss: 7.538323
 >> iter 10000, loss: 7.401209
   Number of active neurons: 10
 >> iter 11000, loss: 7.161923
 >> iter 12000, loss: 6.884407
 >> iter 13000, loss: 6.536598
 >> iter 14000, loss: 6.090060
 >> iter 15000, loss: 5.726711
 >> iter 16000, loss: 5.373577
 >> iter 17000, loss: 5.216487
 >> iter 18000, loss: 4.956496
 >> iter 19000, loss: 4.783137
 >> iter 20000, loss: 4.661253
   Number of active neurons: 10
 >> iter 21000, loss: 4.696455
 >> iter 22000, loss: 4.599765
 >> iter 23000, loss: 4.610886
 >> iter 24000, loss: 4.515196
 >> iter 25000, loss: 4.541339
 >> iter 26000, loss: 4.517652
 >> iter 27000, loss: 4.521692
 >> iter 28000, loss: 4.496401
 >> iter 29000, loss: 4.506982
 >> iter 30000, loss: 4.475936
   Number of active neurons: 10
 >> iter 31000, loss: 4.506282
 >> iter 32000, loss: 4.480600
 >> iter 33000, loss: 4.508176
 >> iter 34000, loss: 4.472671
 >> iter 35000, loss: 4.583564
 >> iter 36000, loss: 4.490565
 >> iter 37000, loss: 4.491238
 >> iter 38000, loss: 4.463403
 >> iter 39000, loss: 4.533623
 >> iter 40000, loss: 4.457791
   Number of active neurons: 10
 >> iter 41000, loss: 4.434742
 >> iter 42000, loss: 4.503532
 >> iter 43000, loss: 4.479053
 >> iter 44000, loss: 4.327073
 >> iter 45000, loss: 4.268467
 >> iter 46000, loss: 4.276212
 >> iter 47000, loss: 4.150950
 >> iter 48000, loss: 4.226676
 >> iter 49000, loss: 4.043054
 >> iter 50000, loss: 4.080799
   Number of active neurons: 10
 >> iter 51000, loss: 4.006517
 >> iter 52000, loss: 3.895723
 >> iter 53000, loss: 3.732113
 >> iter 54000, loss: 3.773923
 >> iter 55000, loss: 3.836798
 >> iter 56000, loss: 3.625593
 >> iter 57000, loss: 3.796411
 >> iter 58000, loss: 3.663876
 >> iter 59000, loss: 3.464474
 >> iter 60000, loss: 3.599382
   Number of active neurons: 10
 >> iter 61000, loss: 3.558166
 >> iter 62000, loss: 3.412480
 >> iter 63000, loss: 3.334117
 >> iter 64000, loss: 3.449506
 >> iter 65000, loss: 3.497135
 >> iter 66000, loss: 3.103481
 >> iter 67000, loss: 2.474669
 >> iter 68000, loss: 1.969923
 >> iter 69000, loss: 2.438560
 >> iter 70000, loss: 1.473159
   Number of active neurons: 10
 >> iter 71000, loss: 1.125365
 >> iter 72000, loss: 0.924302
 >> iter 73000, loss: 0.603687
 >> iter 74000, loss: 0.416649
 >> iter 75000, loss: 0.338799
 >> iter 76000, loss: 0.438366
 >> iter 77000, loss: 0.290463
 >> iter 78000, loss: 0.309177
 >> iter 79000, loss: 0.159761
 >> iter 80000, loss: 0.081765
   Number of active neurons: 10
 >> iter 81000, loss: 0.088777
 >> iter 82000, loss: 0.172146
 >> iter 83000, loss: 0.090385
 >> iter 84000, loss: 0.130326
 >> iter 85000, loss: 0.115175
 >> iter 86000, loss: 0.054225
 >> iter 87000, loss: 0.128696
 >> iter 88000, loss: 0.114763
 >> iter 89000, loss: 0.083111
 >> iter 90000, loss: 0.145440
   Number of active neurons: 10
 >> iter 91000, loss: 0.131474
 >> iter 92000, loss: 0.096280
 >> iter 93000, loss: 0.088020
 >> iter 94000, loss: 0.130680
 >> iter 95000, loss: 0.058613
 >> iter 96000, loss: 0.090758
 >> iter 97000, loss: 0.044342
 >> iter 98000, loss: 0.053625
 >> iter 99000, loss: 0.042832
 >> iter 100000, loss: 0.089710
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.094006
 >> iter 2000, loss: 10.828664
 >> iter 3000, loss: 8.872583
 >> iter 4000, loss: 8.086274
 >> iter 5000, loss: 7.786903
 >> iter 6000, loss: 7.662036
 >> iter 7000, loss: 7.626106
 >> iter 8000, loss: 7.595717
 >> iter 9000, loss: 7.589632
 >> iter 10000, loss: 7.583114
   Number of active neurons: 9
 >> iter 11000, loss: 7.584549
 >> iter 12000, loss: 7.610279
 >> iter 13000, loss: 7.595640
 >> iter 14000, loss: 7.583878
 >> iter 15000, loss: 7.583833
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 7.572916
 >> iter 17000, loss: 7.577346
 >> iter 18000, loss: 7.566448
 >> iter 19000, loss: 7.551306
 >> iter 20000, loss: 7.381050
   Number of active neurons: 10
 >> iter 21000, loss: 7.194103
 >> iter 22000, loss: 6.905609
 >> iter 23000, loss: 6.682888
 >> iter 24000, loss: 6.455372
 >> iter 25000, loss: 6.253443
 >> iter 26000, loss: 5.982262
 >> iter 27000, loss: 5.987209
 >> iter 28000, loss: 5.070783
 >> iter 29000, loss: 2.252371
 >> iter 30000, loss: 1.018672
   Number of active neurons: 10
 >> iter 31000, loss: 0.531514
 >> iter 32000, loss: 0.326624
 >> iter 33000, loss: 0.258493
 >> iter 34000, loss: 0.221900
 >> iter 35000, loss: 0.172978
 >> iter 36000, loss: 0.154639
 >> iter 37000, loss: 0.124684
 >> iter 38000, loss: 0.114378
 >> iter 39000, loss: 0.053910
 >> iter 40000, loss: 0.030836
   Number of active neurons: 10
 >> iter 41000, loss: 0.081595
 >> iter 42000, loss: 0.042280
 >> iter 43000, loss: 0.026715
 >> iter 44000, loss: 0.016208
 >> iter 45000, loss: 0.063508
 >> iter 46000, loss: 0.029572
 >> iter 47000, loss: 0.017011
 >> iter 48000, loss: 0.044584
 >> iter 49000, loss: 0.023020
 >> iter 50000, loss: 0.013000
   Number of active neurons: 10
 >> iter 51000, loss: 0.046468
 >> iter 52000, loss: 0.039675
 >> iter 53000, loss: 0.019709
 >> iter 54000, loss: 0.042695
 >> iter 55000, loss: 0.167847
 >> iter 56000, loss: 0.104437
 >> iter 57000, loss: 0.059617
 >> iter 58000, loss: 0.035557
 >> iter 59000, loss: 0.018524
 >> iter 60000, loss: 0.038724
   Number of active neurons: 10
 >> iter 61000, loss: 0.018217
 >> iter 62000, loss: 0.059093
 >> iter 63000, loss: 0.066929
 >> iter 64000, loss: 0.028798
 >> iter 65000, loss: 0.014265
 >> iter 66000, loss: 0.009032
 >> iter 67000, loss: 0.062629
 >> iter 68000, loss: 0.037873
 >> iter 69000, loss: 0.022256
 >> iter 70000, loss: 0.127607
   Number of active neurons: 10
 >> iter 71000, loss: 0.060740
 >> iter 72000, loss: 0.026399
 >> iter 73000, loss: 0.037046
 >> iter 74000, loss: 0.017587
 >> iter 75000, loss: 0.009721
 >> iter 76000, loss: 0.006877
 >> iter 77000, loss: 0.005284
 >> iter 78000, loss: 0.052978
 >> iter 79000, loss: 0.022151
 >> iter 80000, loss: 0.010768
   Number of active neurons: 10
 >> iter 81000, loss: 0.006271
 >> iter 82000, loss: 0.004475
 >> iter 83000, loss: 0.003931
 >> iter 84000, loss: 0.004656
 >> iter 85000, loss: 0.003943
 >> iter 86000, loss: 0.003225
 >> iter 87000, loss: 0.002935
 >> iter 88000, loss: 0.002938
 >> iter 89000, loss: 0.003032
 >> iter 90000, loss: 0.003481
   Number of active neurons: 10
 >> iter 91000, loss: 0.104473
 >> iter 92000, loss: 0.040770
 >> iter 93000, loss: 0.016880
 >> iter 94000, loss: 0.007902
 >> iter 95000, loss: 0.004712
 >> iter 96000, loss: 0.003312
 >> iter 97000, loss: 0.002764
 >> iter 98000, loss: 0.002589
 >> iter 99000, loss: 0.002247
 >> iter 100000, loss: 0.002368
   Number of active neurons: 10
 >> iter 101000, loss: 0.002366
 >> iter 102000, loss: 0.002095
 >> iter 103000, loss: 0.001976
 >> iter 104000, loss: 0.001861
 >> iter 105000, loss: 0.001844
 >> iter 106000, loss: 0.001886
 >> iter 107000, loss: 0.001824
 >> iter 108000, loss: 0.001965
 >> iter 109000, loss: 0.001969
 >> iter 110000, loss: 0.001850
   Number of active neurons: 10
 >> iter 111000, loss: 0.001833
 >> iter 112000, loss: 0.001752
 >> iter 113000, loss: 0.001619
 >> iter 114000, loss: 0.001488
 >> iter 115000, loss: 0.001438
 >> iter 116000, loss: 0.001448
 >> iter 117000, loss: 0.006246
 >> iter 118000, loss: 0.003289
 >> iter 119000, loss: 0.002236
 >> iter 120000, loss: 0.002185
   Number of active neurons: 10
 >> iter 121000, loss: 0.001659
 >> iter 122000, loss: 0.001486
 >> iter 123000, loss: 0.001370
 >> iter 124000, loss: 0.001490
 >> iter 125000, loss: 0.001365
 >> iter 126000, loss: 0.001291
 >> iter 127000, loss: 0.001197
 >> iter 128000, loss: 0.027383
 >> iter 129000, loss: 0.011182
 >> iter 130000, loss: 0.005069
   Number of active neurons: 10
 >> iter 131000, loss: 0.003744
 >> iter 132000, loss: 0.002197
 >> iter 133000, loss: 0.001748
 >> iter 134000, loss: 0.001367
 >> iter 135000, loss: 0.001249
 >> iter 136000, loss: 0.001200
 >> iter 137000, loss: 0.001138
 >> iter 138000, loss: 0.001182
 >> iter 139000, loss: 0.001220
 >> iter 140000, loss: 0.001232
   Number of active neurons: 10
 >> iter 141000, loss: 0.001342
 >> iter 142000, loss: 0.001165
 >> iter 143000, loss: 0.001078
 >> iter 144000, loss: 0.001625
 >> iter 145000, loss: 0.001199
 >> iter 146000, loss: 0.030336
 >> iter 147000, loss: 0.011990
 >> iter 148000, loss: 0.005149
 >> iter 149000, loss: 0.002636
 >> iter 150000, loss: 0.001730
   Number of active neurons: 10
 >> iter 151000, loss: 0.001299
 >> iter 152000, loss: 0.001167
 >> iter 153000, loss: 0.001061
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.062955
 >> iter 2000, loss: 10.790056
 >> iter 3000, loss: 8.762684
 >> iter 4000, loss: 7.989976
 >> iter 5000, loss: 7.718166
 >> iter 6000, loss: 7.600579
 >> iter 7000, loss: 7.566016
 >> iter 8000, loss: 7.537185
 >> iter 9000, loss: 7.664736
 >> iter 10000, loss: 7.575086
   Number of active neurons: 8
 >> iter 11000, loss: 7.553257
 >> iter 12000, loss: 7.528252
 >> iter 13000, loss: 7.525826
 >> iter 14000, loss: 7.519094
 >> iter 15000, loss: 7.525423
 >> iter 16000, loss: 7.544383
 >> iter 17000, loss: 7.496385
 >> iter 18000, loss: 7.352260
 >> iter 19000, loss: 7.064334
 >> iter 20000, loss: 6.631304
   Number of active neurons: 10
 >> iter 21000, loss: 6.284118
 >> iter 22000, loss: 6.080241
 >> iter 23000, loss: 5.929651
 >> iter 24000, loss: 5.837095
 >> iter 25000, loss: 5.807278
 >> iter 26000, loss: 5.763991
 >> iter 27000, loss: 5.781247
 >> iter 28000, loss: 5.767341
 >> iter 29000, loss: 5.729877
 >> iter 30000, loss: 5.639215
   Number of active neurons: 10
 >> iter 31000, loss: 5.607182
 >> iter 32000, loss: 5.596748
 >> iter 33000, loss: 5.590815
 >> iter 34000, loss: 5.517416
 >> iter 35000, loss: 5.577055
 >> iter 36000, loss: 5.497888
 >> iter 37000, loss: 5.907680
 >> iter 38000, loss: 5.719864
 >> iter 39000, loss: 5.941804
 >> iter 40000, loss: 5.547543
   Number of active neurons: 10
 >> iter 41000, loss: 5.320669
 >> iter 42000, loss: 5.293375
 >> iter 43000, loss: 5.097743
 >> iter 44000, loss: 4.921290
 >> iter 45000, loss: 4.962544
 >> iter 46000, loss: 4.864625
 >> iter 47000, loss: 4.756517
 >> iter 48000, loss: 4.596384
 >> iter 49000, loss: 3.215161
 >> iter 50000, loss: 1.446716
   Number of active neurons: 10
 >> iter 51000, loss: 0.801203
 >> iter 52000, loss: 0.683508
 >> iter 53000, loss: 0.392811
 >> iter 54000, loss: 0.272453
 >> iter 55000, loss: 0.180449
 >> iter 56000, loss: 0.089423
 >> iter 57000, loss: 0.122808
 >> iter 58000, loss: 0.242042
 >> iter 59000, loss: 0.267264
 >> iter 60000, loss: 0.155694
   Number of active neurons: 10
 >> iter 61000, loss: 0.093159
 >> iter 62000, loss: 0.118819
 >> iter 63000, loss: 0.085867
 >> iter 64000, loss: 0.111310
 >> iter 65000, loss: 0.097164
 >> iter 66000, loss: 0.097978
 >> iter 67000, loss: 0.056689
 >> iter 68000, loss: 0.031867
 >> iter 69000, loss: 0.126967
 >> iter 70000, loss: 0.152583
   Number of active neurons: 10
 >> iter 71000, loss: 0.079655
 >> iter 72000, loss: 0.040941
 >> iter 73000, loss: 0.098172
 >> iter 74000, loss: 0.045250
 >> iter 75000, loss: 0.030145
 >> iter 76000, loss: 0.062353
 >> iter 77000, loss: 0.043956
 >> iter 78000, loss: 0.056645
 >> iter 79000, loss: 0.067418
 >> iter 80000, loss: 0.042052
   Number of active neurons: 10
 >> iter 81000, loss: 0.083878
 >> iter 82000, loss: 0.057745
 >> iter 83000, loss: 0.027135
 >> iter 84000, loss: 0.015605
 >> iter 85000, loss: 0.058764
 >> iter 86000, loss: 0.051958
 >> iter 87000, loss: 0.037005
 >> iter 88000, loss: 0.060729
 >> iter 89000, loss: 0.033362
 >> iter 90000, loss: 0.020144
   Number of active neurons: 10
 >> iter 91000, loss: 0.073496
 >> iter 92000, loss: 0.031649
 >> iter 93000, loss: 0.016129
 >> iter 94000, loss: 0.010517
 >> iter 95000, loss: 0.045287
 >> iter 96000, loss: 0.022607
 >> iter 97000, loss: 0.012393
 >> iter 98000, loss: 0.009166
 >> iter 99000, loss: 0.007138
 >> iter 100000, loss: 0.006414
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

