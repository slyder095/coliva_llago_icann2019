 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.2
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.644939
 >> iter 2000, loss: 10.556487
 >> iter 3000, loss: 8.676306
 >> iter 4000, loss: 7.972351
 >> iter 5000, loss: 7.710440
 >> iter 6000, loss: 7.389850
 >> iter 7000, loss: 6.570477
 >> iter 8000, loss: 5.302043
 >> iter 9000, loss: 2.050637
 >> iter 10000, loss: 0.794392
   Number of active neurons: 10
 >> iter 11000, loss: 0.318299
 >> iter 12000, loss: 0.135939
 >> iter 13000, loss: 0.063000
 >> iter 14000, loss: 0.033434
 >> iter 15000, loss: 0.021171
 >> iter 16000, loss: 0.014913
 >> iter 17000, loss: 0.011806
 >> iter 18000, loss: 0.009756
 >> iter 19000, loss: 0.008213
 >> iter 20000, loss: 0.007308
   Number of active neurons: 10
 >> iter 21000, loss: 0.012974
 >> iter 22000, loss: 0.008486
 >> iter 23000, loss: 0.006382
 >> iter 24000, loss: 0.005358
 >> iter 25000, loss: 0.004652
 >> iter 26000, loss: 0.004200
 >> iter 27000, loss: 0.003888
 >> iter 28000, loss: 0.003681
 >> iter 29000, loss: 0.003384
 >> iter 30000, loss: 0.003170
   Number of active neurons: 10
 >> iter 31000, loss: 0.003051
 >> iter 32000, loss: 0.002919
 >> iter 33000, loss: 0.002709
 >> iter 34000, loss: 0.002539
 >> iter 35000, loss: 0.002458
 >> iter 36000, loss: 0.002395
 >> iter 37000, loss: 0.002274
 >> iter 38000, loss: 0.002151
 >> iter 39000, loss: 0.002077
 >> iter 40000, loss: 0.001991
   Number of active neurons: 10
 >> iter 41000, loss: 0.001948
 >> iter 42000, loss: 0.002804
 >> iter 43000, loss: 0.002320
 >> iter 44000, loss: 0.002055
 >> iter 45000, loss: 0.001855
 >> iter 46000, loss: 0.001733
 >> iter 47000, loss: 0.001631
 >> iter 48000, loss: 0.001573
 >> iter 49000, loss: 0.001498
 >> iter 50000, loss: 0.001462
   Number of active neurons: 10
 >> iter 51000, loss: 0.001407
 >> iter 52000, loss: 0.001370
 >> iter 53000, loss: 0.001341
 >> iter 54000, loss: 0.001288
 >> iter 55000, loss: 0.001270
 >> iter 56000, loss: 0.001242
 >> iter 57000, loss: 0.001212
 >> iter 58000, loss: 0.001187
 >> iter 59000, loss: 0.001137
 >> iter 60000, loss: 0.001121
   Number of active neurons: 10
 >> iter 61000, loss: 0.001095
 >> iter 62000, loss: 0.001054
 >> iter 63000, loss: 0.001042
 >> iter 64000, loss: 0.001019
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.552099
 >> iter 2000, loss: 10.512219
 >> iter 3000, loss: 8.651513
 >> iter 4000, loss: 7.834978
 >> iter 5000, loss: 6.996903
 >> iter 6000, loss: 5.965242
 >> iter 7000, loss: 3.003444
 >> iter 8000, loss: 1.139613
 >> iter 9000, loss: 0.439087
 >> iter 10000, loss: 0.175401
   Number of active neurons: 10
 >> iter 11000, loss: 0.075029
 >> iter 12000, loss: 0.035987
 >> iter 13000, loss: 0.020537
 >> iter 14000, loss: 0.013745
 >> iter 15000, loss: 0.010466
 >> iter 16000, loss: 0.008659
 >> iter 17000, loss: 0.007585
 >> iter 18000, loss: 0.006723
 >> iter 19000, loss: 0.006052
 >> iter 20000, loss: 0.005531
   Number of active neurons: 10
 >> iter 21000, loss: 0.005103
 >> iter 22000, loss: 0.004737
 >> iter 23000, loss: 0.004452
 >> iter 24000, loss: 0.004163
 >> iter 25000, loss: 0.003943
 >> iter 26000, loss: 0.003724
 >> iter 27000, loss: 0.003563
 >> iter 28000, loss: 0.003369
 >> iter 29000, loss: 0.003249
 >> iter 30000, loss: 0.043593
   Number of active neurons: 10
 >> iter 31000, loss: 0.018383
 >> iter 32000, loss: 0.008897
 >> iter 33000, loss: 0.005202
 >> iter 34000, loss: 0.003950
 >> iter 35000, loss: 0.003267
 >> iter 36000, loss: 0.002862
 >> iter 37000, loss: 0.002651
 >> iter 38000, loss: 0.002508
 >> iter 39000, loss: 0.002367
 >> iter 40000, loss: 0.002284
   Number of active neurons: 10
 >> iter 41000, loss: 0.002199
 >> iter 42000, loss: 0.002098
 >> iter 43000, loss: 0.002004
 >> iter 44000, loss: 0.001974
 >> iter 45000, loss: 0.001910
 >> iter 46000, loss: 0.001827
 >> iter 47000, loss: 0.001771
 >> iter 48000, loss: 0.001730
 >> iter 49000, loss: 0.001682
 >> iter 50000, loss: 0.001635
   Number of active neurons: 10
 >> iter 51000, loss: 0.001603
 >> iter 52000, loss: 0.001554
 >> iter 53000, loss: 0.001517
 >> iter 54000, loss: 0.001473
 >> iter 55000, loss: 0.001446
 >> iter 56000, loss: 0.001392
 >> iter 57000, loss: 0.001364
 >> iter 58000, loss: 0.001344
 >> iter 59000, loss: 0.001316
 >> iter 60000, loss: 0.001280
   Number of active neurons: 10
 >> iter 61000, loss: 0.001258
 >> iter 62000, loss: 0.001225
 >> iter 63000, loss: 0.001211
 >> iter 64000, loss: 0.001180
 >> iter 65000, loss: 0.001158
 >> iter 66000, loss: 0.001126
 >> iter 67000, loss: 0.001118
 >> iter 68000, loss: 0.001087
 >> iter 69000, loss: 0.001076
 >> iter 70000, loss: 0.001046
   Number of active neurons: 10
 >> iter 71000, loss: 0.001037
 >> iter 72000, loss: 0.001017
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.605742
 >> iter 2000, loss: 10.538618
 >> iter 3000, loss: 8.668927
 >> iter 4000, loss: 7.953828
 >> iter 5000, loss: 7.423492
 >> iter 6000, loss: 4.505419
 >> iter 7000, loss: 1.714058
 >> iter 8000, loss: 0.696137
 >> iter 9000, loss: 0.275815
 >> iter 10000, loss: 0.113573
   Number of active neurons: 10
 >> iter 11000, loss: 0.051273
 >> iter 12000, loss: 0.026635
 >> iter 13000, loss: 0.016253
 >> iter 14000, loss: 0.012602
 >> iter 15000, loss: 0.009801
 >> iter 16000, loss: 0.008091
 >> iter 17000, loss: 0.006998
 >> iter 18000, loss: 0.006239
 >> iter 19000, loss: 0.005631
 >> iter 20000, loss: 0.005154
   Number of active neurons: 10
 >> iter 21000, loss: 0.004812
 >> iter 22000, loss: 0.004449
 >> iter 23000, loss: 0.004176
 >> iter 24000, loss: 0.003890
 >> iter 25000, loss: 0.003670
 >> iter 26000, loss: 0.003473
 >> iter 27000, loss: 0.003303
 >> iter 28000, loss: 0.003104
 >> iter 29000, loss: 0.002973
 >> iter 30000, loss: 0.002848
   Number of active neurons: 10
 >> iter 31000, loss: 0.002721
 >> iter 32000, loss: 0.002617
 >> iter 33000, loss: 0.002510
 >> iter 34000, loss: 0.002378
 >> iter 35000, loss: 0.002299
 >> iter 36000, loss: 0.002191
 >> iter 37000, loss: 0.002133
 >> iter 38000, loss: 0.002111
 >> iter 39000, loss: 0.002005
 >> iter 40000, loss: 0.001956
   Number of active neurons: 10
 >> iter 41000, loss: 0.001869
 >> iter 42000, loss: 0.001811
 >> iter 43000, loss: 0.001771
 >> iter 44000, loss: 0.001723
 >> iter 45000, loss: 0.001714
 >> iter 46000, loss: 0.001631
 >> iter 47000, loss: 0.001590
 >> iter 48000, loss: 0.001554
 >> iter 49000, loss: 0.001516
 >> iter 50000, loss: 0.001474
   Number of active neurons: 10
 >> iter 51000, loss: 0.001434
 >> iter 52000, loss: 0.001383
 >> iter 53000, loss: 0.001378
 >> iter 54000, loss: 0.001328
 >> iter 55000, loss: 0.001303
 >> iter 56000, loss: 0.001273
 >> iter 57000, loss: 0.001239
 >> iter 58000, loss: 0.001221
 >> iter 59000, loss: 0.001201
 >> iter 60000, loss: 0.001186
   Number of active neurons: 10
 >> iter 61000, loss: 0.001169
 >> iter 62000, loss: 0.001173
 >> iter 63000, loss: 0.001133
 >> iter 64000, loss: 0.001090
 >> iter 65000, loss: 0.001069
 >> iter 66000, loss: 0.001074
 >> iter 67000, loss: 0.001049
 >> iter 68000, loss: 0.001027
 >> iter 69000, loss: 0.001005
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.578554
 >> iter 2000, loss: 10.505334
 >> iter 3000, loss: 8.631777
 >> iter 4000, loss: 7.918285
 >> iter 5000, loss: 7.658561
 >> iter 6000, loss: 7.554202
 >> iter 7000, loss: 7.519155
 >> iter 8000, loss: 7.383651
 >> iter 9000, loss: 6.639872
 >> iter 10000, loss: 5.808261
   Number of active neurons: 10
 >> iter 11000, loss: 2.892876
 >> iter 12000, loss: 1.117494
 >> iter 13000, loss: 0.441817
 >> iter 14000, loss: 0.181858
 >> iter 15000, loss: 0.082155
 >> iter 16000, loss: 0.042140
 >> iter 17000, loss: 0.026173
 >> iter 18000, loss: 0.018435
 >> iter 19000, loss: 0.014260
 >> iter 20000, loss: 0.011807
   Number of active neurons: 10
 >> iter 21000, loss: 0.010361
 >> iter 22000, loss: 0.009152
 >> iter 23000, loss: 0.008366
 >> iter 24000, loss: 0.007617
 >> iter 25000, loss: 0.007075
 >> iter 26000, loss: 0.006511
 >> iter 27000, loss: 0.006351
 >> iter 28000, loss: 0.005810
 >> iter 29000, loss: 0.005506
 >> iter 30000, loss: 0.005138
   Number of active neurons: 10
 >> iter 31000, loss: 0.004852
 >> iter 32000, loss: 0.004549
 >> iter 33000, loss: 0.004348
 >> iter 34000, loss: 0.004131
 >> iter 35000, loss: 0.003959
 >> iter 36000, loss: 0.003772
 >> iter 37000, loss: 0.003681
 >> iter 38000, loss: 0.003494
 >> iter 39000, loss: 0.003350
 >> iter 40000, loss: 0.003220
   Number of active neurons: 10
 >> iter 41000, loss: 0.003087
 >> iter 42000, loss: 0.002945
 >> iter 43000, loss: 0.002869
 >> iter 44000, loss: 0.002818
 >> iter 45000, loss: 0.002716
 >> iter 46000, loss: 0.002615
 >> iter 47000, loss: 0.002505
 >> iter 48000, loss: 0.002450
 >> iter 49000, loss: 0.002385
 >> iter 50000, loss: 0.002302
   Number of active neurons: 10
 >> iter 51000, loss: 0.002254
 >> iter 52000, loss: 0.002205
 >> iter 53000, loss: 0.002150
 >> iter 54000, loss: 0.002090
 >> iter 55000, loss: 0.002049
 >> iter 56000, loss: 0.001987
 >> iter 57000, loss: 0.001965
 >> iter 58000, loss: 0.001945
 >> iter 59000, loss: 0.001905
 >> iter 60000, loss: 0.001817
   Number of active neurons: 10
 >> iter 61000, loss: 0.001779
 >> iter 62000, loss: 0.001727
 >> iter 63000, loss: 0.001697
 >> iter 64000, loss: 0.001670
 >> iter 65000, loss: 0.001640
 >> iter 66000, loss: 0.001603
 >> iter 67000, loss: 0.001588
 >> iter 68000, loss: 0.001537
 >> iter 69000, loss: 0.001495
 >> iter 70000, loss: 0.001468
   Number of active neurons: 10
 >> iter 71000, loss: 0.001438
 >> iter 72000, loss: 0.001392
 >> iter 73000, loss: 0.001377
 >> iter 74000, loss: 0.001367
 >> iter 75000, loss: 0.001343
 >> iter 76000, loss: 0.001322
 >> iter 77000, loss: 0.001372
 >> iter 78000, loss: 0.001339
 >> iter 79000, loss: 0.001308
 >> iter 80000, loss: 0.001274
   Number of active neurons: 10
 >> iter 81000, loss: 0.001243
 >> iter 82000, loss: 0.001206
 >> iter 83000, loss: 0.001201
 >> iter 84000, loss: 0.001181
 >> iter 85000, loss: 0.001157
 >> iter 86000, loss: 0.001136
 >> iter 87000, loss: 0.001106
 >> iter 88000, loss: 0.001081
 >> iter 89000, loss: 0.001074
 >> iter 90000, loss: 0.001062
   Number of active neurons: 10
 >> iter 91000, loss: 0.001051
 >> iter 92000, loss: 0.001023
 >> iter 93000, loss: 0.001026
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.598261
 >> iter 2000, loss: 10.516382
 >> iter 3000, loss: 8.644084
 >> iter 4000, loss: 7.880203
 >> iter 5000, loss: 7.063651
 >> iter 6000, loss: 6.110621
 >> iter 7000, loss: 5.534941
 >> iter 8000, loss: 2.600864
 >> iter 9000, loss: 1.001296
 >> iter 10000, loss: 0.392762
   Number of active neurons: 10
 >> iter 11000, loss: 0.167990
 >> iter 12000, loss: 0.106127
 >> iter 13000, loss: 0.055773
 >> iter 14000, loss: 0.044451
 >> iter 15000, loss: 0.025556
 >> iter 16000, loss: 0.016888
 >> iter 17000, loss: 0.012964
 >> iter 18000, loss: 0.010497
 >> iter 19000, loss: 0.009341
 >> iter 20000, loss: 0.009168
   Number of active neurons: 10
 >> iter 21000, loss: 0.008041
 >> iter 22000, loss: 0.020999
 >> iter 23000, loss: 0.012080
 >> iter 24000, loss: 0.008090
 >> iter 25000, loss: 0.006234
 >> iter 26000, loss: 0.005208
 >> iter 27000, loss: 0.004701
 >> iter 28000, loss: 0.004295
 >> iter 29000, loss: 0.004926
 >> iter 30000, loss: 0.004308
   Number of active neurons: 10
 >> iter 31000, loss: 0.003934
 >> iter 32000, loss: 0.003564
 >> iter 33000, loss: 0.003347
 >> iter 34000, loss: 0.003171
 >> iter 35000, loss: 0.003013
 >> iter 36000, loss: 0.002870
 >> iter 37000, loss: 0.002756
 >> iter 38000, loss: 0.002635
 >> iter 39000, loss: 0.002535
 >> iter 40000, loss: 0.003344
   Number of active neurons: 10
 >> iter 41000, loss: 0.002909
 >> iter 42000, loss: 0.002643
 >> iter 43000, loss: 0.002440
 >> iter 44000, loss: 0.002321
 >> iter 45000, loss: 0.002255
 >> iter 46000, loss: 0.002122
 >> iter 47000, loss: 0.002050
 >> iter 48000, loss: 0.001985
 >> iter 49000, loss: 0.001925
 >> iter 50000, loss: 0.001834
   Number of active neurons: 10
 >> iter 51000, loss: 0.001772
 >> iter 52000, loss: 0.001714
 >> iter 53000, loss: 0.002579
 >> iter 54000, loss: 0.002071
 >> iter 55000, loss: 0.001876
 >> iter 56000, loss: 0.001737
 >> iter 57000, loss: 0.001676
 >> iter 58000, loss: 0.001589
 >> iter 59000, loss: 0.001536
 >> iter 60000, loss: 0.001495
   Number of active neurons: 10
 >> iter 61000, loss: 0.001457
 >> iter 62000, loss: 0.001466
 >> iter 63000, loss: 0.001406
 >> iter 64000, loss: 0.001365
 >> iter 65000, loss: 0.001349
 >> iter 66000, loss: 0.001311
 >> iter 67000, loss: 0.001274
 >> iter 68000, loss: 0.001246
 >> iter 69000, loss: 0.001279
 >> iter 70000, loss: 0.001221
   Number of active neurons: 10
 >> iter 71000, loss: 0.001189
 >> iter 72000, loss: 0.001161
 >> iter 73000, loss: 0.001152
 >> iter 74000, loss: 0.001118
 >> iter 75000, loss: 0.010506
 >> iter 76000, loss: 0.004646
 >> iter 77000, loss: 0.002429
 >> iter 78000, loss: 0.001593
 >> iter 79000, loss: 0.001281
 >> iter 80000, loss: 0.001124
   Number of active neurons: 10
 >> iter 81000, loss: 0.001059
 >> iter 82000, loss: 0.001143
 >> iter 83000, loss: 0.001121
 >> iter 84000, loss: 0.001076
 >> iter 85000, loss: 0.001050
 >> iter 86000, loss: 0.001013
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.667687
 >> iter 2000, loss: 10.567908
 >> iter 3000, loss: 8.679539
 >> iter 4000, loss: 7.962208
 >> iter 5000, loss: 7.553282
 >> iter 6000, loss: 6.756997
 >> iter 7000, loss: 5.897471
 >> iter 8000, loss: 5.222028
 >> iter 9000, loss: 4.502663
 >> iter 10000, loss: 1.813149
   Number of active neurons: 10
 >> iter 11000, loss: 0.695402
 >> iter 12000, loss: 0.271190
 >> iter 13000, loss: 0.116626
 >> iter 14000, loss: 0.051603
 >> iter 15000, loss: 0.026226
 >> iter 16000, loss: 0.015722
 >> iter 17000, loss: 0.011138
 >> iter 18000, loss: 0.008721
 >> iter 19000, loss: 0.007428
 >> iter 20000, loss: 0.006729
   Number of active neurons: 10
 >> iter 21000, loss: 0.006109
 >> iter 22000, loss: 0.005491
 >> iter 23000, loss: 0.021291
 >> iter 24000, loss: 0.012318
 >> iter 25000, loss: 0.007766
 >> iter 26000, loss: 0.005501
 >> iter 27000, loss: 0.004478
 >> iter 28000, loss: 0.003969
 >> iter 29000, loss: 0.003676
 >> iter 30000, loss: 0.003386
   Number of active neurons: 10
 >> iter 31000, loss: 0.003177
 >> iter 32000, loss: 0.003022
 >> iter 33000, loss: 0.002908
 >> iter 34000, loss: 0.002741
 >> iter 35000, loss: 0.002588
 >> iter 36000, loss: 0.002499
 >> iter 37000, loss: 0.002416
 >> iter 38000, loss: 0.002317
 >> iter 39000, loss: 0.002219
 >> iter 40000, loss: 0.002103
   Number of active neurons: 10
 >> iter 41000, loss: 0.002069
 >> iter 42000, loss: 0.002011
 >> iter 43000, loss: 0.001967
 >> iter 44000, loss: 0.001912
 >> iter 45000, loss: 0.001835
 >> iter 46000, loss: 0.001810
 >> iter 47000, loss: 0.001767
 >> iter 48000, loss: 0.001698
 >> iter 49000, loss: 0.001664
 >> iter 50000, loss: 0.001609
   Number of active neurons: 10
 >> iter 51000, loss: 0.001575
 >> iter 52000, loss: 0.001530
 >> iter 53000, loss: 0.001507
 >> iter 54000, loss: 0.001449
 >> iter 55000, loss: 0.001435
 >> iter 56000, loss: 0.001400
 >> iter 57000, loss: 0.001380
 >> iter 58000, loss: 0.001387
 >> iter 59000, loss: 0.001331
 >> iter 60000, loss: 0.001303
   Number of active neurons: 10
 >> iter 61000, loss: 0.001286
 >> iter 62000, loss: 0.001292
 >> iter 63000, loss: 0.001218
 >> iter 64000, loss: 0.001176
 >> iter 65000, loss: 0.001167
 >> iter 66000, loss: 0.001132
 >> iter 67000, loss: 0.001113
 >> iter 68000, loss: 0.001098
 >> iter 69000, loss: 0.001075
 >> iter 70000, loss: 0.001048
   Number of active neurons: 10
 >> iter 71000, loss: 0.001053
 >> iter 72000, loss: 0.001036
 >> iter 73000, loss: 0.001006
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 15.590030
 >> iter 2000, loss: 10.530515
 >> iter 3000, loss: 8.659856
 >> iter 4000, loss: 7.949311
 >> iter 5000, loss: 7.552132
 >> iter 6000, loss: 6.724534
 >> iter 7000, loss: 5.883918
 >> iter 8000, loss: 3.005529
 >> iter 9000, loss: 1.299541
 >> iter 10000, loss: 0.517885
   Number of active neurons: 10
 >> iter 11000, loss: 0.214434
 >> iter 12000, loss: 0.095009
 >> iter 13000, loss: 0.047549
 >> iter 14000, loss: 0.027686
 >> iter 15000, loss: 0.018911
 >> iter 16000, loss: 0.014490
 >> iter 17000, loss: 0.020004
 >> iter 18000, loss: 0.014554
 >> iter 19000, loss: 0.030630
 >> iter 20000, loss: 0.016876
   Number of active neurons: 10
 >> iter 21000, loss: 0.011051
 >> iter 22000, loss: 0.008404
 >> iter 23000, loss: 0.007090
 >> iter 24000, loss: 0.006281
 >> iter 25000, loss: 0.005724
 >> iter 26000, loss: 0.005366
 >> iter 27000, loss: 0.005000
 >> iter 28000, loss: 0.004680
 >> iter 29000, loss: 0.004409
 >> iter 30000, loss: 0.004177
   Number of active neurons: 10
 >> iter 31000, loss: 0.003922
 >> iter 32000, loss: 0.003750
 >> iter 33000, loss: 0.003548
 >> iter 34000, loss: 0.003427
 >> iter 35000, loss: 0.003459
 >> iter 36000, loss: 0.003207
 >> iter 37000, loss: 0.003035
 >> iter 38000, loss: 0.002913
 >> iter 39000, loss: 0.002813
 >> iter 40000, loss: 0.002703
   Number of active neurons: 10
 >> iter 41000, loss: 0.002603
 >> iter 42000, loss: 0.002576
 >> iter 43000, loss: 0.002495
 >> iter 44000, loss: 0.002873
 >> iter 45000, loss: 0.002625
 >> iter 46000, loss: 0.002436
 >> iter 47000, loss: 0.002292
 >> iter 48000, loss: 0.002189
 >> iter 49000, loss: 0.002138
 >> iter 50000, loss: 0.002050
   Number of active neurons: 10
 >> iter 51000, loss: 0.001980
 >> iter 52000, loss: 0.001935
 >> iter 53000, loss: 0.001864
 >> iter 54000, loss: 0.001823
 >> iter 55000, loss: 0.001773
 >> iter 56000, loss: 0.001726
 >> iter 57000, loss: 0.001682
 >> iter 58000, loss: 0.001653
 >> iter 59000, loss: 0.001670
 >> iter 60000, loss: 0.001596
   Number of active neurons: 10
 >> iter 61000, loss: 0.001638
 >> iter 62000, loss: 0.001571
 >> iter 63000, loss: 0.001514
 >> iter 64000, loss: 0.001465
 >> iter 65000, loss: 0.001455
 >> iter 66000, loss: 0.001419
 >> iter 67000, loss: 0.001391
 >> iter 68000, loss: 0.001359
 >> iter 69000, loss: 0.001337
 >> iter 70000, loss: 0.001297
   Number of active neurons: 10
 >> iter 71000, loss: 0.001368
 >> iter 72000, loss: 0.001290
 >> iter 73000, loss: 0.001251
 >> iter 74000, loss: 0.001223
 >> iter 75000, loss: 0.001213
 >> iter 76000, loss: 0.001252
 >> iter 77000, loss: 0.001188
 >> iter 78000, loss: 0.001155
 >> iter 79000, loss: 0.001141
 >> iter 80000, loss: 0.001113
   Number of active neurons: 10
 >> iter 81000, loss: 0.001109
 >> iter 82000, loss: 0.001081
 >> iter 83000, loss: 0.001073
 >> iter 84000, loss: 0.001068
 >> iter 85000, loss: 0.001046
 >> iter 86000, loss: 0.001025
 >> iter 87000, loss: 0.001003
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.563776
 >> iter 2000, loss: 10.500863
 >> iter 3000, loss: 8.628715
 >> iter 4000, loss: 7.919281
 >> iter 5000, loss: 7.668344
 >> iter 6000, loss: 7.564560
 >> iter 7000, loss: 7.320810
 >> iter 8000, loss: 6.541723
 >> iter 9000, loss: 4.132350
 >> iter 10000, loss: 1.563572
   Number of active neurons: 10
 >> iter 11000, loss: 0.596729
 >> iter 12000, loss: 0.234080
 >> iter 13000, loss: 0.096811
 >> iter 14000, loss: 0.043951
 >> iter 15000, loss: 0.023224
 >> iter 16000, loss: 0.014503
 >> iter 17000, loss: 0.010454
 >> iter 18000, loss: 0.008251
 >> iter 19000, loss: 0.006889
 >> iter 20000, loss: 0.006051
   Number of active neurons: 10
 >> iter 21000, loss: 0.005492
 >> iter 22000, loss: 0.004958
 >> iter 23000, loss: 0.004566
 >> iter 24000, loss: 0.004231
 >> iter 25000, loss: 0.003957
 >> iter 26000, loss: 0.003646
 >> iter 27000, loss: 0.003485
 >> iter 28000, loss: 0.003256
 >> iter 29000, loss: 0.003130
 >> iter 30000, loss: 0.002977
   Number of active neurons: 10
 >> iter 31000, loss: 0.002832
 >> iter 32000, loss: 0.002634
 >> iter 33000, loss: 0.002514
 >> iter 34000, loss: 0.002391
 >> iter 35000, loss: 0.002317
 >> iter 36000, loss: 0.002206
 >> iter 37000, loss: 0.002110
 >> iter 38000, loss: 0.002065
 >> iter 39000, loss: 0.001978
 >> iter 40000, loss: 0.001928
   Number of active neurons: 10
 >> iter 41000, loss: 0.001841
 >> iter 42000, loss: 0.001769
 >> iter 43000, loss: 0.001714
 >> iter 44000, loss: 0.001653
 >> iter 45000, loss: 0.001610
 >> iter 46000, loss: 0.001598
 >> iter 47000, loss: 0.001522
 >> iter 48000, loss: 0.001474
 >> iter 49000, loss: 0.001439
 >> iter 50000, loss: 0.033109
   Number of active neurons: 10
 >> iter 51000, loss: 0.013567
 >> iter 52000, loss: 0.006090
 >> iter 53000, loss: 0.003236
 >> iter 54000, loss: 0.002208
 >> iter 55000, loss: 0.001750
 >> iter 56000, loss: 0.001540
 >> iter 57000, loss: 0.001437
 >> iter 58000, loss: 0.001398
 >> iter 59000, loss: 0.001331
 >> iter 60000, loss: 0.001292
   Number of active neurons: 10
 >> iter 61000, loss: 0.001262
 >> iter 62000, loss: 0.001209
 >> iter 63000, loss: 0.001179
 >> iter 64000, loss: 0.001142
 >> iter 65000, loss: 0.001095
 >> iter 66000, loss: 0.001080
 >> iter 67000, loss: 0.001063
 >> iter 68000, loss: 0.001033
 >> iter 69000, loss: 0.001033
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.605034
 >> iter 2000, loss: 10.536594
 >> iter 3000, loss: 8.666171
 >> iter 4000, loss: 7.961805
 >> iter 5000, loss: 7.708063
 >> iter 6000, loss: 7.585237
 >> iter 7000, loss: 7.171084
 >> iter 8000, loss: 6.331621
 >> iter 9000, loss: 5.526053
 >> iter 10000, loss: 2.340681
   Number of active neurons: 10
 >> iter 11000, loss: 0.889498
 >> iter 12000, loss: 0.341117
 >> iter 13000, loss: 0.134783
 >> iter 14000, loss: 0.056995
 >> iter 15000, loss: 0.027088
 >> iter 16000, loss: 0.015195
 >> iter 17000, loss: 0.047378
 >> iter 18000, loss: 0.022734
 >> iter 19000, loss: 0.012518
 >> iter 20000, loss: 0.008319
   Number of active neurons: 10
 >> iter 21000, loss: 0.006384
 >> iter 22000, loss: 0.005394
 >> iter 23000, loss: 0.004750
 >> iter 24000, loss: 0.004369
 >> iter 25000, loss: 0.003985
 >> iter 26000, loss: 0.003726
 >> iter 27000, loss: 0.003732
 >> iter 28000, loss: 0.003888
 >> iter 29000, loss: 0.003495
 >> iter 30000, loss: 0.003189
   Number of active neurons: 10
 >> iter 31000, loss: 0.002942
 >> iter 32000, loss: 0.002871
 >> iter 33000, loss: 0.002680
 >> iter 34000, loss: 0.002577
 >> iter 35000, loss: 0.002429
 >> iter 36000, loss: 0.002387
 >> iter 37000, loss: 0.002237
 >> iter 38000, loss: 0.002153
 >> iter 39000, loss: 0.002064
 >> iter 40000, loss: 0.002015
   Number of active neurons: 10
 >> iter 41000, loss: 0.001953
 >> iter 42000, loss: 0.001903
 >> iter 43000, loss: 0.001809
 >> iter 44000, loss: 0.004038
 >> iter 45000, loss: 0.002829
 >> iter 46000, loss: 0.002261
 >> iter 47000, loss: 0.001946
 >> iter 48000, loss: 0.001786
 >> iter 49000, loss: 0.001656
 >> iter 50000, loss: 0.001575
   Number of active neurons: 10
 >> iter 51000, loss: 0.001544
 >> iter 52000, loss: 0.001468
 >> iter 53000, loss: 0.001410
 >> iter 54000, loss: 0.001382
 >> iter 55000, loss: 0.001335
 >> iter 56000, loss: 0.001328
 >> iter 57000, loss: 0.001266
 >> iter 58000, loss: 0.001251
 >> iter 59000, loss: 0.001223
 >> iter 60000, loss: 0.001199
   Number of active neurons: 10
 >> iter 61000, loss: 0.001170
 >> iter 62000, loss: 0.001128
 >> iter 63000, loss: 0.001112
 >> iter 64000, loss: 0.001108
 >> iter 65000, loss: 0.001083
 >> iter 66000, loss: 0.001089
 >> iter 67000, loss: 0.001092
 >> iter 68000, loss: 0.001054
 >> iter 69000, loss: 0.001008
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.612240
 >> iter 2000, loss: 10.533062
 >> iter 3000, loss: 8.653137
 >> iter 4000, loss: 7.942348
 >> iter 5000, loss: 7.687195
 >> iter 6000, loss: 7.570541
 >> iter 7000, loss: 7.540679
 >> iter 8000, loss: 7.511076
 >> iter 9000, loss: 7.435266
 >> iter 10000, loss: 7.033104
   Number of active neurons: 9
 >> iter 11000, loss: 5.615444
 >> iter 12000, loss: 2.125675
 >> iter 13000, loss: 0.803602
 >> iter 14000, loss: 0.309061
 >> iter 15000, loss: 0.123304
 >> iter 16000, loss: 0.052884
 >> iter 17000, loss: 0.025785
 >> iter 18000, loss: 0.016527
 >> iter 19000, loss: 0.010769
 >> iter 20000, loss: 0.008118
   Number of active neurons: 10
 >> iter 21000, loss: 0.006570
 >> iter 22000, loss: 0.005560
 >> iter 23000, loss: 0.004972
 >> iter 24000, loss: 0.093733
 >> iter 25000, loss: 0.038087
 >> iter 26000, loss: 0.017115
 >> iter 27000, loss: 0.009159
 >> iter 28000, loss: 0.005937
 >> iter 29000, loss: 0.004524
 >> iter 30000, loss: 0.003860
   Number of active neurons: 10
 >> iter 31000, loss: 0.003454
 >> iter 32000, loss: 0.003256
 >> iter 33000, loss: 0.002990
 >> iter 34000, loss: 0.002790
 >> iter 35000, loss: 0.002627
 >> iter 36000, loss: 0.002477
 >> iter 37000, loss: 0.002414
 >> iter 38000, loss: 0.002963
 >> iter 39000, loss: 0.002467
 >> iter 40000, loss: 0.002231
   Number of active neurons: 10
 >> iter 41000, loss: 0.002075
 >> iter 42000, loss: 0.012319
 >> iter 43000, loss: 0.005927
 >> iter 44000, loss: 0.005866
 >> iter 45000, loss: 0.003763
 >> iter 46000, loss: 0.002711
 >> iter 47000, loss: 0.002222
 >> iter 48000, loss: 0.001932
 >> iter 49000, loss: 0.001785
 >> iter 50000, loss: 0.001637
   Number of active neurons: 10
 >> iter 51000, loss: 0.001539
 >> iter 52000, loss: 0.001481
 >> iter 53000, loss: 0.001449
 >> iter 54000, loss: 0.001371
 >> iter 55000, loss: 0.001340
 >> iter 56000, loss: 0.001319
 >> iter 57000, loss: 0.002223
 >> iter 58000, loss: 0.001787
 >> iter 59000, loss: 0.001545
 >> iter 60000, loss: 0.001424
   Number of active neurons: 10
 >> iter 61000, loss: 0.001348
 >> iter 62000, loss: 0.001256
 >> iter 63000, loss: 0.001209
 >> iter 64000, loss: 0.001163
 >> iter 65000, loss: 0.001119
 >> iter 66000, loss: 0.001648
 >> iter 67000, loss: 0.001379
 >> iter 68000, loss: 0.001165
 >> iter 69000, loss: 0.001069
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.533723
 >> iter 2000, loss: 10.487258
 >> iter 3000, loss: 8.628037
 >> iter 4000, loss: 7.929958
 >> iter 5000, loss: 7.664000
 >> iter 6000, loss: 7.315328
 >> iter 7000, loss: 6.381807
 >> iter 8000, loss: 5.571198
 >> iter 9000, loss: 4.046689
 >> iter 10000, loss: 1.703492
   Number of active neurons: 10
 >> iter 11000, loss: 0.655910
 >> iter 12000, loss: 0.260278
 >> iter 13000, loss: 0.109314
 >> iter 14000, loss: 0.053909
 >> iter 15000, loss: 0.031384
 >> iter 16000, loss: 0.021460
 >> iter 17000, loss: 0.015531
 >> iter 18000, loss: 0.012058
 >> iter 19000, loss: 0.009776
 >> iter 20000, loss: 0.008565
   Number of active neurons: 10
 >> iter 21000, loss: 0.007765
 >> iter 22000, loss: 0.006815
 >> iter 23000, loss: 0.006069
 >> iter 24000, loss: 0.005552
 >> iter 25000, loss: 0.005194
 >> iter 26000, loss: 0.004787
 >> iter 27000, loss: 0.004416
 >> iter 28000, loss: 0.004264
 >> iter 29000, loss: 0.004008
 >> iter 30000, loss: 0.003721
   Number of active neurons: 10
 >> iter 31000, loss: 0.003539
 >> iter 32000, loss: 0.003403
 >> iter 33000, loss: 0.003504
 >> iter 34000, loss: 0.003302
 >> iter 35000, loss: 0.003129
 >> iter 36000, loss: 0.003383
 >> iter 37000, loss: 0.003058
 >> iter 38000, loss: 0.002870
 >> iter 39000, loss: 0.002735
 >> iter 40000, loss: 0.002524
   Number of active neurons: 10
 >> iter 41000, loss: 0.002431
 >> iter 42000, loss: 0.002328
 >> iter 43000, loss: 0.002276
 >> iter 44000, loss: 0.002163
 >> iter 45000, loss: 0.002132
 >> iter 46000, loss: 0.002057
 >> iter 47000, loss: 0.001988
 >> iter 48000, loss: 0.001969
 >> iter 49000, loss: 0.001897
 >> iter 50000, loss: 0.001821
   Number of active neurons: 10
 >> iter 51000, loss: 0.001754
 >> iter 52000, loss: 0.001711
 >> iter 53000, loss: 0.001636
 >> iter 54000, loss: 0.001636
 >> iter 55000, loss: 0.001615
 >> iter 56000, loss: 0.001563
 >> iter 57000, loss: 0.001526
 >> iter 58000, loss: 0.001555
 >> iter 59000, loss: 0.001509
 >> iter 60000, loss: 0.001469
   Number of active neurons: 10
 >> iter 61000, loss: 0.001435
 >> iter 62000, loss: 0.001379
 >> iter 63000, loss: 0.001321
 >> iter 64000, loss: 0.001312
 >> iter 65000, loss: 0.001294
 >> iter 66000, loss: 0.001271
 >> iter 67000, loss: 0.001231
 >> iter 68000, loss: 0.001218
 >> iter 69000, loss: 0.001177
 >> iter 70000, loss: 0.001182
   Number of active neurons: 10
 >> iter 71000, loss: 0.001157
 >> iter 72000, loss: 0.001124
 >> iter 73000, loss: 0.001094
 >> iter 74000, loss: 0.001123
 >> iter 75000, loss: 0.001073
 >> iter 76000, loss: 0.001054
 >> iter 77000, loss: 0.001049
 >> iter 78000, loss: 0.001052
 >> iter 79000, loss: 0.001006
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.603891
 >> iter 2000, loss: 10.556449
 >> iter 3000, loss: 8.677341
 >> iter 4000, loss: 7.959729
 >> iter 5000, loss: 7.697149
 >> iter 6000, loss: 7.337054
 >> iter 7000, loss: 4.709654
 >> iter 8000, loss: 1.787711
 >> iter 9000, loss: 0.699820
 >> iter 10000, loss: 0.274036
   Number of active neurons: 10
 >> iter 11000, loss: 0.112526
 >> iter 12000, loss: 0.050627
 >> iter 13000, loss: 0.026390
 >> iter 14000, loss: 0.016564
 >> iter 15000, loss: 0.011911
 >> iter 16000, loss: 0.009439
 >> iter 17000, loss: 0.008062
 >> iter 18000, loss: 0.007142
 >> iter 19000, loss: 0.006460
 >> iter 20000, loss: 0.005824
   Number of active neurons: 10
 >> iter 21000, loss: 0.005386
 >> iter 22000, loss: 0.005016
 >> iter 23000, loss: 0.004704
 >> iter 24000, loss: 0.004441
 >> iter 25000, loss: 0.004161
 >> iter 26000, loss: 0.003954
 >> iter 27000, loss: 0.003756
 >> iter 28000, loss: 0.003502
 >> iter 29000, loss: 0.003400
 >> iter 30000, loss: 0.003183
   Number of active neurons: 10
 >> iter 31000, loss: 0.003033
 >> iter 32000, loss: 0.002887
 >> iter 33000, loss: 0.002796
 >> iter 34000, loss: 0.002702
 >> iter 35000, loss: 0.002596
 >> iter 36000, loss: 0.002488
 >> iter 37000, loss: 0.002390
 >> iter 38000, loss: 0.002321
 >> iter 39000, loss: 0.002236
 >> iter 40000, loss: 0.002166
   Number of active neurons: 10
 >> iter 41000, loss: 0.002084
 >> iter 42000, loss: 0.002016
 >> iter 43000, loss: 0.002001
 >> iter 44000, loss: 0.001931
 >> iter 45000, loss: 0.001886
 >> iter 46000, loss: 0.001840
 >> iter 47000, loss: 0.001770
 >> iter 48000, loss: 0.001742
 >> iter 49000, loss: 0.001690
 >> iter 50000, loss: 0.001678
   Number of active neurons: 10
 >> iter 51000, loss: 0.001640
 >> iter 52000, loss: 0.001591
 >> iter 53000, loss: 0.001556
 >> iter 54000, loss: 0.001504
 >> iter 55000, loss: 0.001469
 >> iter 56000, loss: 0.001440
 >> iter 57000, loss: 0.001412
 >> iter 58000, loss: 0.001400
 >> iter 59000, loss: 0.001376
 >> iter 60000, loss: 0.001367
   Number of active neurons: 10
 >> iter 61000, loss: 0.001300
 >> iter 62000, loss: 0.001262
 >> iter 63000, loss: 0.001242
 >> iter 64000, loss: 0.001212
 >> iter 65000, loss: 0.001208
 >> iter 66000, loss: 0.001187
 >> iter 67000, loss: 0.001191
 >> iter 68000, loss: 0.001195
 >> iter 69000, loss: 0.001138
 >> iter 70000, loss: 0.001121
   Number of active neurons: 10
 >> iter 71000, loss: 0.001106
 >> iter 72000, loss: 0.001071
 >> iter 73000, loss: 0.001044
 >> iter 74000, loss: 0.001037
 >> iter 75000, loss: 0.001033
 >> iter 76000, loss: 0.001010
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.594347
 >> iter 2000, loss: 10.526091
 >> iter 3000, loss: 8.653327
 >> iter 4000, loss: 7.934067
 >> iter 5000, loss: 7.682583
 >> iter 6000, loss: 7.567579
 >> iter 7000, loss: 7.537068
 >> iter 8000, loss: 7.244200
 >> iter 9000, loss: 6.361462
 >> iter 10000, loss: 5.599214
   Number of active neurons: 10
 >> iter 11000, loss: 2.536174
 >> iter 12000, loss: 0.958750
 >> iter 13000, loss: 0.367383
 >> iter 14000, loss: 0.145412
 >> iter 15000, loss: 0.061825
 >> iter 16000, loss: 0.029459
 >> iter 17000, loss: 0.016606
 >> iter 18000, loss: 0.011051
 >> iter 19000, loss: 0.008515
 >> iter 20000, loss: 0.007126
   Number of active neurons: 10
 >> iter 21000, loss: 0.006166
 >> iter 22000, loss: 0.005507
 >> iter 23000, loss: 0.005006
 >> iter 24000, loss: 0.004553
 >> iter 25000, loss: 0.004223
 >> iter 26000, loss: 0.003892
 >> iter 27000, loss: 0.003647
 >> iter 28000, loss: 0.003513
 >> iter 29000, loss: 0.003371
 >> iter 30000, loss: 0.003137
   Number of active neurons: 10
 >> iter 31000, loss: 0.002963
 >> iter 32000, loss: 0.002783
 >> iter 33000, loss: 0.002636
 >> iter 34000, loss: 0.002504
 >> iter 35000, loss: 0.002392
 >> iter 36000, loss: 0.002289
 >> iter 37000, loss: 0.002184
 >> iter 38000, loss: 0.002094
 >> iter 39000, loss: 0.002007
 >> iter 40000, loss: 0.001934
   Number of active neurons: 10
 >> iter 41000, loss: 0.001887
 >> iter 42000, loss: 0.001791
 >> iter 43000, loss: 0.001725
 >> iter 44000, loss: 0.001681
 >> iter 45000, loss: 0.001640
 >> iter 46000, loss: 0.001586
 >> iter 47000, loss: 0.001567
 >> iter 48000, loss: 0.001490
 >> iter 49000, loss: 0.001452
 >> iter 50000, loss: 0.001419
   Number of active neurons: 10
 >> iter 51000, loss: 0.001366
 >> iter 52000, loss: 0.001333
 >> iter 53000, loss: 0.001301
 >> iter 54000, loss: 0.001272
 >> iter 55000, loss: 0.001244
 >> iter 56000, loss: 0.001197
 >> iter 57000, loss: 0.001180
 >> iter 58000, loss: 0.001160
 >> iter 59000, loss: 0.001131
 >> iter 60000, loss: 0.001101
   Number of active neurons: 10
 >> iter 61000, loss: 0.001078
 >> iter 62000, loss: 0.001047
 >> iter 63000, loss: 0.001036
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.626775
 >> iter 2000, loss: 10.536912
 >> iter 3000, loss: 8.647375
 >> iter 4000, loss: 7.822574
 >> iter 5000, loss: 6.806139
 >> iter 6000, loss: 3.319844
 >> iter 7000, loss: 1.252156
 >> iter 8000, loss: 0.478417
 >> iter 9000, loss: 0.188109
 >> iter 10000, loss: 0.078529
   Number of active neurons: 10
 >> iter 11000, loss: 0.036545
 >> iter 12000, loss: 0.019828
 >> iter 13000, loss: 0.012777
 >> iter 14000, loss: 0.009574
 >> iter 15000, loss: 0.007769
 >> iter 16000, loss: 0.006741
 >> iter 17000, loss: 0.006047
 >> iter 18000, loss: 0.005500
 >> iter 19000, loss: 0.005093
 >> iter 20000, loss: 0.004688
   Number of active neurons: 10
 >> iter 21000, loss: 0.004324
 >> iter 22000, loss: 0.004055
 >> iter 23000, loss: 0.003816
 >> iter 24000, loss: 0.003628
 >> iter 25000, loss: 0.003355
 >> iter 26000, loss: 0.003206
 >> iter 27000, loss: 0.003053
 >> iter 28000, loss: 0.002904
 >> iter 29000, loss: 0.002781
 >> iter 30000, loss: 0.002656
   Number of active neurons: 10
 >> iter 31000, loss: 0.002592
 >> iter 32000, loss: 0.002459
 >> iter 33000, loss: 0.002343
 >> iter 34000, loss: 0.002275
 >> iter 35000, loss: 0.002172
 >> iter 36000, loss: 0.002122
 >> iter 37000, loss: 0.002061
 >> iter 38000, loss: 0.001965
 >> iter 39000, loss: 0.001953
 >> iter 40000, loss: 0.001872
   Number of active neurons: 10
 >> iter 41000, loss: 0.002407
 >> iter 42000, loss: 0.002273
 >> iter 43000, loss: 0.002033
 >> iter 44000, loss: 0.001843
 >> iter 45000, loss: 0.001722
 >> iter 46000, loss: 0.001634
 >> iter 47000, loss: 0.001564
 >> iter 48000, loss: 0.001513
 >> iter 49000, loss: 0.001466
 >> iter 50000, loss: 0.001418
   Number of active neurons: 10
 >> iter 51000, loss: 0.001376
 >> iter 52000, loss: 0.001354
 >> iter 53000, loss: 0.001301
 >> iter 54000, loss: 0.001281
 >> iter 55000, loss: 0.001254
 >> iter 56000, loss: 0.001221
 >> iter 57000, loss: 0.001188
 >> iter 58000, loss: 0.001193
 >> iter 59000, loss: 0.001145
 >> iter 60000, loss: 0.001139
   Number of active neurons: 10
 >> iter 61000, loss: 0.001114
 >> iter 62000, loss: 0.001113
 >> iter 63000, loss: 0.001083
 >> iter 64000, loss: 0.001052
 >> iter 65000, loss: 0.001025
 >> iter 66000, loss: 0.001041
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.644565
 >> iter 2000, loss: 10.553689
 >> iter 3000, loss: 8.672309
 >> iter 4000, loss: 7.968083
 >> iter 5000, loss: 7.694059
 >> iter 6000, loss: 7.118493
 >> iter 7000, loss: 6.212559
 >> iter 8000, loss: 5.414986
 >> iter 9000, loss: 2.161054
 >> iter 10000, loss: 0.819242
   Number of active neurons: 10
 >> iter 11000, loss: 0.397929
 >> iter 12000, loss: 0.159567
 >> iter 13000, loss: 0.067583
 >> iter 14000, loss: 0.032105
 >> iter 15000, loss: 0.033739
 >> iter 16000, loss: 0.034913
 >> iter 17000, loss: 0.017559
 >> iter 18000, loss: 0.011265
 >> iter 19000, loss: 0.008096
 >> iter 20000, loss: 0.006279
   Number of active neurons: 10
 >> iter 21000, loss: 0.005252
 >> iter 22000, loss: 0.004708
 >> iter 23000, loss: 0.004202
 >> iter 24000, loss: 0.048423
 >> iter 25000, loss: 0.022645
 >> iter 26000, loss: 0.022525
 >> iter 27000, loss: 0.011107
 >> iter 28000, loss: 0.006588
 >> iter 29000, loss: 0.004626
 >> iter 30000, loss: 0.003676
   Number of active neurons: 10
 >> iter 31000, loss: 0.003176
 >> iter 32000, loss: 0.002857
 >> iter 33000, loss: 0.002636
 >> iter 34000, loss: 0.002453
 >> iter 35000, loss: 0.002305
 >> iter 36000, loss: 0.002177
 >> iter 37000, loss: 0.002071
 >> iter 38000, loss: 0.001978
 >> iter 39000, loss: 0.001889
 >> iter 40000, loss: 0.001854
   Number of active neurons: 10
 >> iter 41000, loss: 0.001813
 >> iter 42000, loss: 0.001746
 >> iter 43000, loss: 0.001653
 >> iter 44000, loss: 0.001582
 >> iter 45000, loss: 0.001525
 >> iter 46000, loss: 0.001472
 >> iter 47000, loss: 0.001428
 >> iter 48000, loss: 0.001392
 >> iter 49000, loss: 0.001338
 >> iter 50000, loss: 0.001296
   Number of active neurons: 10
 >> iter 51000, loss: 0.001262
 >> iter 52000, loss: 0.001225
 >> iter 53000, loss: 0.001201
 >> iter 54000, loss: 0.001168
 >> iter 55000, loss: 0.001134
 >> iter 56000, loss: 0.042137
 >> iter 57000, loss: 0.016886
 >> iter 58000, loss: 0.007470
 >> iter 59000, loss: 0.003757
 >> iter 60000, loss: 0.002316
   Number of active neurons: 10
 >> iter 61000, loss: 0.001720
 >> iter 62000, loss: 0.001466
 >> iter 63000, loss: 0.001330
 >> iter 64000, loss: 0.001249
 >> iter 65000, loss: 0.001181
 >> iter 66000, loss: 0.001117
 >> iter 67000, loss: 0.001088
 >> iter 68000, loss: 0.001043
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.572989
 >> iter 2000, loss: 10.530109
 >> iter 3000, loss: 8.665249
 >> iter 4000, loss: 7.958987
 >> iter 5000, loss: 7.685829
 >> iter 6000, loss: 7.143039
 >> iter 7000, loss: 6.164841
 >> iter 8000, loss: 3.968451
 >> iter 9000, loss: 1.505258
 >> iter 10000, loss: 0.576253
   Number of active neurons: 10
 >> iter 11000, loss: 0.229050
 >> iter 12000, loss: 0.096316
 >> iter 13000, loss: 0.045202
 >> iter 14000, loss: 0.024599
 >> iter 15000, loss: 0.015857
 >> iter 16000, loss: 0.011675
 >> iter 17000, loss: 0.009624
 >> iter 18000, loss: 0.008312
 >> iter 19000, loss: 0.007462
 >> iter 20000, loss: 0.006661
   Number of active neurons: 10
 >> iter 21000, loss: 0.006450
 >> iter 22000, loss: 0.005751
 >> iter 23000, loss: 0.005201
 >> iter 24000, loss: 0.004800
 >> iter 25000, loss: 0.004510
 >> iter 26000, loss: 0.004167
 >> iter 27000, loss: 0.004000
 >> iter 28000, loss: 0.003849
 >> iter 29000, loss: 0.003641
 >> iter 30000, loss: 0.003387
   Number of active neurons: 10
 >> iter 31000, loss: 0.003225
 >> iter 32000, loss: 0.003058
 >> iter 33000, loss: 0.002945
 >> iter 34000, loss: 0.002795
 >> iter 35000, loss: 0.002681
 >> iter 36000, loss: 0.002562
 >> iter 37000, loss: 0.004556
 >> iter 38000, loss: 0.004301
 >> iter 39000, loss: 0.003363
 >> iter 40000, loss: 0.002768
   Number of active neurons: 10
 >> iter 41000, loss: 0.002514
 >> iter 42000, loss: 0.002505
 >> iter 43000, loss: 0.002322
 >> iter 44000, loss: 0.002187
 >> iter 45000, loss: 0.002062
 >> iter 46000, loss: 0.002077
 >> iter 47000, loss: 0.001995
 >> iter 48000, loss: 0.001867
 >> iter 49000, loss: 0.001814
 >> iter 50000, loss: 0.001757
   Number of active neurons: 10
 >> iter 51000, loss: 0.001675
 >> iter 52000, loss: 0.001610
 >> iter 53000, loss: 0.001588
 >> iter 54000, loss: 0.001551
 >> iter 55000, loss: 0.001559
 >> iter 56000, loss: 0.001496
 >> iter 57000, loss: 0.001426
 >> iter 58000, loss: 0.001410
 >> iter 59000, loss: 0.001362
 >> iter 60000, loss: 0.001315
   Number of active neurons: 10
 >> iter 61000, loss: 0.001282
 >> iter 62000, loss: 0.001273
 >> iter 63000, loss: 0.001253
 >> iter 64000, loss: 0.001218
 >> iter 65000, loss: 0.001199
 >> iter 66000, loss: 0.001167
 >> iter 67000, loss: 0.001146
 >> iter 68000, loss: 0.001118
 >> iter 69000, loss: 0.001154
 >> iter 70000, loss: 0.001095
   Number of active neurons: 10
 >> iter 71000, loss: 0.001066
 >> iter 72000, loss: 0.001031
 >> iter 73000, loss: 0.001040
 >> iter 74000, loss: 0.001075
 >> iter 75000, loss: 0.001034
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.536279
 >> iter 2000, loss: 10.509298
 >> iter 3000, loss: 8.655193
 >> iter 4000, loss: 7.949885
 >> iter 5000, loss: 7.690032
 >> iter 6000, loss: 7.435358
 >> iter 7000, loss: 6.592076
 >> iter 8000, loss: 5.798643
 >> iter 9000, loss: 5.113141
 >> iter 10000, loss: 1.947885
   Number of active neurons: 10
 >> iter 11000, loss: 0.741525
 >> iter 12000, loss: 0.288475
 >> iter 13000, loss: 0.117861
 >> iter 14000, loss: 0.052462
 >> iter 15000, loss: 0.026938
 >> iter 16000, loss: 0.016321
 >> iter 17000, loss: 0.011665
 >> iter 18000, loss: 0.009559
 >> iter 19000, loss: 0.008246
 >> iter 20000, loss: 0.007031
   Number of active neurons: 10
 >> iter 21000, loss: 0.006300
 >> iter 22000, loss: 0.005666
 >> iter 23000, loss: 0.005246
 >> iter 24000, loss: 0.004996
 >> iter 25000, loss: 0.004561
 >> iter 26000, loss: 0.004242
 >> iter 27000, loss: 0.003947
 >> iter 28000, loss: 0.003706
 >> iter 29000, loss: 0.003557
 >> iter 30000, loss: 0.003397
   Number of active neurons: 10
 >> iter 31000, loss: 0.003337
 >> iter 32000, loss: 0.003099
 >> iter 33000, loss: 0.002974
 >> iter 34000, loss: 0.002819
 >> iter 35000, loss: 0.002698
 >> iter 36000, loss: 0.002955
 >> iter 37000, loss: 0.002721
 >> iter 38000, loss: 0.002521
 >> iter 39000, loss: 0.002408
 >> iter 40000, loss: 0.002276
   Number of active neurons: 10
 >> iter 41000, loss: 0.002189
 >> iter 42000, loss: 0.002105
 >> iter 43000, loss: 0.002048
 >> iter 44000, loss: 0.001987
 >> iter 45000, loss: 0.001923
 >> iter 46000, loss: 0.001850
 >> iter 47000, loss: 0.001809
 >> iter 48000, loss: 0.001740
 >> iter 49000, loss: 0.001705
 >> iter 50000, loss: 0.001672
   Number of active neurons: 10
 >> iter 51000, loss: 0.001630
 >> iter 52000, loss: 0.001585
 >> iter 53000, loss: 0.001542
 >> iter 54000, loss: 0.001500
 >> iter 55000, loss: 0.001493
 >> iter 56000, loss: 0.001467
 >> iter 57000, loss: 0.001440
 >> iter 58000, loss: 0.001396
 >> iter 59000, loss: 0.001376
 >> iter 60000, loss: 0.001327
   Number of active neurons: 10
 >> iter 61000, loss: 0.001303
 >> iter 62000, loss: 0.001271
 >> iter 63000, loss: 0.001244
 >> iter 64000, loss: 0.001224
 >> iter 65000, loss: 0.001199
 >> iter 66000, loss: 0.001184
 >> iter 67000, loss: 0.001163
 >> iter 68000, loss: 0.001157
 >> iter 69000, loss: 0.001146
 >> iter 70000, loss: 0.001115
   Number of active neurons: 10
 >> iter 71000, loss: 0.001091
 >> iter 72000, loss: 0.001065
 >> iter 73000, loss: 0.001045
 >> iter 74000, loss: 0.001035
 >> iter 75000, loss: 0.001026
 >> iter 76000, loss: 0.001015
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.541329
 >> iter 2000, loss: 10.500042
 >> iter 3000, loss: 8.633195
 >> iter 4000, loss: 7.805465
 >> iter 5000, loss: 6.767939
 >> iter 6000, loss: 2.592885
 >> iter 7000, loss: 0.983110
 >> iter 8000, loss: 0.377833
 >> iter 9000, loss: 0.149871
 >> iter 10000, loss: 0.063280
   Number of active neurons: 10
 >> iter 11000, loss: 0.029834
 >> iter 12000, loss: 0.016490
 >> iter 13000, loss: 0.010820
 >> iter 14000, loss: 0.008153
 >> iter 15000, loss: 0.006715
 >> iter 16000, loss: 0.005832
 >> iter 17000, loss: 0.005214
 >> iter 18000, loss: 0.004777
 >> iter 19000, loss: 0.004369
 >> iter 20000, loss: 0.004019
   Number of active neurons: 10
 >> iter 21000, loss: 0.003748
 >> iter 22000, loss: 0.003520
 >> iter 23000, loss: 0.003303
 >> iter 24000, loss: 0.003125
 >> iter 25000, loss: 0.002937
 >> iter 26000, loss: 0.002776
 >> iter 27000, loss: 0.002634
 >> iter 28000, loss: 0.002536
 >> iter 29000, loss: 0.002412
 >> iter 30000, loss: 0.002318
   Number of active neurons: 10
 >> iter 31000, loss: 0.002223
 >> iter 32000, loss: 0.002130
 >> iter 33000, loss: 0.002057
 >> iter 34000, loss: 0.001994
 >> iter 35000, loss: 0.001903
 >> iter 36000, loss: 0.001850
 >> iter 37000, loss: 0.001777
 >> iter 38000, loss: 0.001730
 >> iter 39000, loss: 0.001659
 >> iter 40000, loss: 0.001616
   Number of active neurons: 10
 >> iter 41000, loss: 0.001560
 >> iter 42000, loss: 0.001529
 >> iter 43000, loss: 0.001497
 >> iter 44000, loss: 0.001455
 >> iter 45000, loss: 0.001402
 >> iter 46000, loss: 0.001384
 >> iter 47000, loss: 0.001350
 >> iter 48000, loss: 0.001319
 >> iter 49000, loss: 0.001270
 >> iter 50000, loss: 0.001257
   Number of active neurons: 10
 >> iter 51000, loss: 0.001217
 >> iter 52000, loss: 0.001189
 >> iter 53000, loss: 0.001164
 >> iter 54000, loss: 0.001131
 >> iter 55000, loss: 0.001102
 >> iter 56000, loss: 0.001109
 >> iter 57000, loss: 0.001074
 >> iter 58000, loss: 0.001058
 >> iter 59000, loss: 0.001017
 >> iter 60000, loss: 0.001012
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.598898
 >> iter 2000, loss: 10.516472
 >> iter 3000, loss: 8.634870
 >> iter 4000, loss: 7.814043
 >> iter 5000, loss: 6.837683
 >> iter 6000, loss: 5.899340
 >> iter 7000, loss: 4.840927
 >> iter 8000, loss: 1.933853
 >> iter 9000, loss: 0.795572
 >> iter 10000, loss: 0.310990
   Number of active neurons: 10
 >> iter 11000, loss: 0.126921
 >> iter 12000, loss: 0.056260
 >> iter 13000, loss: 0.028609
 >> iter 14000, loss: 0.017247
 >> iter 15000, loss: 0.012140
 >> iter 16000, loss: 0.009526
 >> iter 17000, loss: 0.008130
 >> iter 18000, loss: 0.007150
 >> iter 19000, loss: 0.006414
 >> iter 20000, loss: 0.005793
   Number of active neurons: 10
 >> iter 21000, loss: 0.005293
 >> iter 22000, loss: 0.004908
 >> iter 23000, loss: 0.004601
 >> iter 24000, loss: 0.004272
 >> iter 25000, loss: 0.004016
 >> iter 26000, loss: 0.003769
 >> iter 27000, loss: 0.003592
 >> iter 28000, loss: 0.003404
 >> iter 29000, loss: 0.003242
 >> iter 30000, loss: 0.003105
   Number of active neurons: 10
 >> iter 31000, loss: 0.002964
 >> iter 32000, loss: 0.002835
 >> iter 33000, loss: 0.002695
 >> iter 34000, loss: 0.002567
 >> iter 35000, loss: 0.002488
 >> iter 36000, loss: 0.002377
 >> iter 37000, loss: 0.002306
 >> iter 38000, loss: 0.002221
 >> iter 39000, loss: 0.002140
 >> iter 40000, loss: 0.002080
   Number of active neurons: 10
 >> iter 41000, loss: 0.002024
 >> iter 42000, loss: 0.001971
 >> iter 43000, loss: 0.001948
 >> iter 44000, loss: 0.001878
 >> iter 45000, loss: 0.001813
 >> iter 46000, loss: 0.001772
 >> iter 47000, loss: 0.001730
 >> iter 48000, loss: 0.001680
 >> iter 49000, loss: 0.001642
 >> iter 50000, loss: 0.001591
   Number of active neurons: 10
 >> iter 51000, loss: 0.001561
 >> iter 52000, loss: 0.001512
 >> iter 53000, loss: 0.001487
 >> iter 54000, loss: 0.001452
 >> iter 55000, loss: 0.001422
 >> iter 56000, loss: 0.001385
 >> iter 57000, loss: 0.001357
 >> iter 58000, loss: 0.001326
 >> iter 59000, loss: 0.001302
 >> iter 60000, loss: 0.001274
   Number of active neurons: 10
 >> iter 61000, loss: 0.001251
 >> iter 62000, loss: 0.001232
 >> iter 63000, loss: 0.001207
 >> iter 64000, loss: 0.001179
 >> iter 65000, loss: 0.001157
 >> iter 66000, loss: 0.001191
 >> iter 67000, loss: 0.001153
 >> iter 68000, loss: 0.001121
 >> iter 69000, loss: 0.001106
 >> iter 70000, loss: 0.001073
   Number of active neurons: 10
 >> iter 71000, loss: 0.001057
 >> iter 72000, loss: 0.001042
 >> iter 73000, loss: 0.001023
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.562644
 >> iter 2000, loss: 10.515020
 >> iter 3000, loss: 8.652118
 >> iter 4000, loss: 7.944857
 >> iter 5000, loss: 7.691979
 >> iter 6000, loss: 7.586094
 >> iter 7000, loss: 7.553389
 >> iter 8000, loss: 7.063640
 >> iter 9000, loss: 6.137454
 >> iter 10000, loss: 5.575526
   Number of active neurons: 10
 >> iter 11000, loss: 5.167434
 >> iter 12000, loss: 4.703218
 >> iter 13000, loss: 2.345084
 >> iter 14000, loss: 0.894476
 >> iter 15000, loss: 0.348806
 >> iter 16000, loss: 0.160979
 >> iter 17000, loss: 0.071917
 >> iter 18000, loss: 0.035782
 >> iter 19000, loss: 0.021110
 >> iter 20000, loss: 0.019195
   Number of active neurons: 10
 >> iter 21000, loss: 0.013727
 >> iter 22000, loss: 0.010758
 >> iter 23000, loss: 0.009542
 >> iter 24000, loss: 0.008316
 >> iter 25000, loss: 0.007270
 >> iter 26000, loss: 0.006593
 >> iter 27000, loss: 0.006460
 >> iter 28000, loss: 0.005877
 >> iter 29000, loss: 0.005315
 >> iter 30000, loss: 0.005018
   Number of active neurons: 10
 >> iter 31000, loss: 0.004569
 >> iter 32000, loss: 0.004679
 >> iter 33000, loss: 0.004315
 >> iter 34000, loss: 0.004003
 >> iter 35000, loss: 0.003843
 >> iter 36000, loss: 0.003807
 >> iter 37000, loss: 0.003477
 >> iter 38000, loss: 0.003223
 >> iter 39000, loss: 0.003217
 >> iter 40000, loss: 0.003091
   Number of active neurons: 10
 >> iter 41000, loss: 0.002900
 >> iter 42000, loss: 0.002767
 >> iter 43000, loss: 0.002666
 >> iter 44000, loss: 0.022992
 >> iter 45000, loss: 0.010426
 >> iter 46000, loss: 0.005580
 >> iter 47000, loss: 0.003719
 >> iter 48000, loss: 0.002889
 >> iter 49000, loss: 0.002513
 >> iter 50000, loss: 0.002483
   Number of active neurons: 10
 >> iter 51000, loss: 0.002297
 >> iter 52000, loss: 0.002189
 >> iter 53000, loss: 0.002081
 >> iter 54000, loss: 0.002019
 >> iter 55000, loss: 0.002029
 >> iter 56000, loss: 0.002188
 >> iter 57000, loss: 0.001948
 >> iter 58000, loss: 0.001852
 >> iter 59000, loss: 0.001810
 >> iter 60000, loss: 0.001742
   Number of active neurons: 10
 >> iter 61000, loss: 0.001780
 >> iter 62000, loss: 0.001680
 >> iter 63000, loss: 0.001638
 >> iter 64000, loss: 0.001599
 >> iter 65000, loss: 0.001564
 >> iter 66000, loss: 0.001506
 >> iter 67000, loss: 0.001461
 >> iter 68000, loss: 0.001428
 >> iter 69000, loss: 0.001414
 >> iter 70000, loss: 0.001380
   Number of active neurons: 10
 >> iter 71000, loss: 0.001389
 >> iter 72000, loss: 0.001342
 >> iter 73000, loss: 0.001334
 >> iter 74000, loss: 0.001288
 >> iter 75000, loss: 0.001267
 >> iter 76000, loss: 0.001255
 >> iter 77000, loss: 0.001447
 >> iter 78000, loss: 0.001416
 >> iter 79000, loss: 0.001341
 >> iter 80000, loss: 0.001284
   Number of active neurons: 10
 >> iter 81000, loss: 0.001222
 >> iter 82000, loss: 0.001174
 >> iter 83000, loss: 0.001127
 >> iter 84000, loss: 0.001108
 >> iter 85000, loss: 0.001415
 >> iter 86000, loss: 0.001330
 >> iter 87000, loss: 0.001298
 >> iter 88000, loss: 0.001208
 >> iter 89000, loss: 0.001149
 >> iter 90000, loss: 0.001110
   Number of active neurons: 10
 >> iter 91000, loss: 0.001103
 >> iter 92000, loss: 0.001043
 >> iter 93000, loss: 0.001020
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

