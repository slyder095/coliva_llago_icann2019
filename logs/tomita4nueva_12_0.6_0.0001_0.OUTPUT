 > Problema: tomita4nueva
 > Args:
   - Hidden size: 12
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.946969
 >> iter 2000, loss: 8.993151
 >> iter 3000, loss: 4.191745
 >> iter 4000, loss: 1.992970
 >> iter 5000, loss: 1.153068
 >> iter 6000, loss: 0.834844
 >> iter 7000, loss: 0.552346
 >> iter 8000, loss: 0.388274
 >> iter 9000, loss: 0.313886
 >> iter 10000, loss: 0.240935
   Number of active neurons: 6
 >> iter 11000, loss: 0.291619
 >> iter 12000, loss: 0.479131
 >> iter 13000, loss: 0.324443
 >> iter 14000, loss: 0.612008
 >> iter 15000, loss: 0.559563
 >> iter 16000, loss: 0.338230
 >> iter 17000, loss: 0.305698
 >> iter 18000, loss: 0.251336
 >> iter 19000, loss: 0.257042
 >> iter 20000, loss: 0.160900
   Number of active neurons: 5
 >> iter 21000, loss: 0.159127
 >> iter 22000, loss: 0.403166
 >> iter 23000, loss: 0.334723
 >> iter 24000, loss: 0.387457
 >> iter 25000, loss: 0.365677
 >> iter 26000, loss: 0.291745
 >> iter 27000, loss: 0.257907
 >> iter 28000, loss: 0.355421
 >> iter 29000, loss: 0.338962
 >> iter 30000, loss: 0.231113
   Number of active neurons: 5
 >> iter 31000, loss: 0.232750
 >> iter 32000, loss: 0.226479
 >> iter 33000, loss: 0.303553
 >> iter 34000, loss: 0.348125
 >> iter 35000, loss: 0.269784
 >> iter 36000, loss: 0.211291
 >> iter 37000, loss: 0.275555
 >> iter 38000, loss: 0.395216
 >> iter 39000, loss: 0.270046
 >> iter 40000, loss: 0.213049
   Number of active neurons: 4
 >> iter 41000, loss: 0.250927
 >> iter 42000, loss: 0.199399
 >> iter 43000, loss: 0.201363
 >> iter 44000, loss: 0.141287
 >> iter 45000, loss: 0.151098
 >> iter 46000, loss: 0.307126
 >> iter 47000, loss: 0.254593
 >> iter 48000, loss: 0.252247
 >> iter 49000, loss: 0.281360
 >> iter 50000, loss: 0.232599
   Number of active neurons: 4
 >> iter 51000, loss: 0.252987
 >> iter 52000, loss: 0.285551
 >> iter 53000, loss: 0.204826
 >> iter 54000, loss: 0.194234
 >> iter 55000, loss: 0.283093
 >> iter 56000, loss: 0.232653
 >> iter 57000, loss: 0.186124
 >> iter 58000, loss: 0.279485
 >> iter 59000, loss: 0.171688
 >> iter 60000, loss: 0.210570
   Number of active neurons: 4
 >> iter 61000, loss: 0.308535
 >> iter 62000, loss: 0.309108
 >> iter 63000, loss: 0.372001
 >> iter 64000, loss: 0.368594
 >> iter 65000, loss: 0.493227
 >> iter 66000, loss: 0.478541
 >> iter 67000, loss: 0.357670
 >> iter 68000, loss: 0.311400
 >> iter 69000, loss: 0.176580
 >> iter 70000, loss: 0.282226
   Number of active neurons: 4
 >> iter 71000, loss: 0.369166
 >> iter 72000, loss: 0.339961
 >> iter 73000, loss: 0.342850
 >> iter 74000, loss: 0.311343
 >> iter 75000, loss: 0.214824
 >> iter 76000, loss: 0.225345
 >> iter 77000, loss: 0.178639
 >> iter 78000, loss: 0.260284
 >> iter 79000, loss: 0.138000
 >> iter 80000, loss: 0.175180
   Number of active neurons: 4
 >> iter 81000, loss: 0.203092
 >> iter 82000, loss: 0.264760
 >> iter 83000, loss: 0.226554
 >> iter 84000, loss: 0.202797
 >> iter 85000, loss: 0.250435
 >> iter 86000, loss: 0.122930
 >> iter 87000, loss: 0.198452
 >> iter 88000, loss: 0.213819
 >> iter 89000, loss: 0.137476
 >> iter 90000, loss: 0.134557
   Number of active neurons: 4
 >> iter 91000, loss: 0.164692
 >> iter 92000, loss: 0.164600
 >> iter 93000, loss: 0.090662
 >> iter 94000, loss: 0.244390
 >> iter 95000, loss: 0.170785
 >> iter 96000, loss: 0.205258
 >> iter 97000, loss: 0.214346
 >> iter 98000, loss: 0.213369
 >> iter 99000, loss: 0.368404
 >> iter 100000, loss: 0.420461
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.793280
 >> iter 2000, loss: 8.411644
 >> iter 3000, loss: 3.853977
 >> iter 4000, loss: 1.729393
 >> iter 5000, loss: 1.026869
 >> iter 6000, loss: 0.830422
 >> iter 7000, loss: 0.684411
 >> iter 8000, loss: 0.530971
 >> iter 9000, loss: 0.414407
 >> iter 10000, loss: 0.441304
   Number of active neurons: 4
 >> iter 11000, loss: 0.506121
 >> iter 12000, loss: 0.431998
 >> iter 13000, loss: 0.584613
 >> iter 14000, loss: 0.391420
 >> iter 15000, loss: 0.403943
 >> iter 16000, loss: 0.270452
 >> iter 17000, loss: 0.394867
 >> iter 18000, loss: 0.454298
 >> iter 19000, loss: 0.461996
 >> iter 20000, loss: 0.487166
   Number of active neurons: 4
 >> iter 21000, loss: 0.501430
 >> iter 22000, loss: 0.458625
 >> iter 23000, loss: 0.495353
 >> iter 24000, loss: 0.313374
 >> iter 25000, loss: 0.435870
 >> iter 26000, loss: 0.645950
 >> iter 27000, loss: 0.490028
 >> iter 28000, loss: 0.374637
 >> iter 29000, loss: 0.386496
 >> iter 30000, loss: 0.437496
   Number of active neurons: 4
 >> iter 31000, loss: 0.425510
 >> iter 32000, loss: 0.399471
 >> iter 33000, loss: 0.492835
 >> iter 34000, loss: 0.361319
 >> iter 35000, loss: 0.314738
 >> iter 36000, loss: 0.346647
 >> iter 37000, loss: 0.247873
 >> iter 38000, loss: 0.278595
 >> iter 39000, loss: 0.246873
 >> iter 40000, loss: 0.356285
   Number of active neurons: 4
 >> iter 41000, loss: 0.307234
 >> iter 42000, loss: 0.285786
 >> iter 43000, loss: 0.278516
 >> iter 44000, loss: 0.233003
 >> iter 45000, loss: 0.261292
 >> iter 46000, loss: 0.413885
 >> iter 47000, loss: 0.335424
 >> iter 48000, loss: 0.191599
 >> iter 49000, loss: 0.451563
 >> iter 50000, loss: 0.267830
   Number of active neurons: 3
 >> iter 51000, loss: 0.411437
 >> iter 52000, loss: 0.406079
 >> iter 53000, loss: 0.440779
 >> iter 54000, loss: 0.267133
 >> iter 55000, loss: 0.322555
 >> iter 56000, loss: 0.329703
 >> iter 57000, loss: 0.346059
 >> iter 58000, loss: 0.251894
 >> iter 59000, loss: 0.184095
 >> iter 60000, loss: 0.303768
   Number of active neurons: 3
 >> iter 61000, loss: 0.376848
 >> iter 62000, loss: 0.276689
 >> iter 63000, loss: 0.264471
 >> iter 64000, loss: 0.252502
 >> iter 65000, loss: 0.307985
 >> iter 66000, loss: 0.240296
 >> iter 67000, loss: 0.289761
 >> iter 68000, loss: 0.182962
 >> iter 69000, loss: 0.162860
 >> iter 70000, loss: 0.352935
   Number of active neurons: 3
 >> iter 71000, loss: 0.278354
 >> iter 72000, loss: 0.205168
 >> iter 73000, loss: 0.111137
 >> iter 74000, loss: 0.099461
 >> iter 75000, loss: 0.218906
 >> iter 76000, loss: 0.317268
 >> iter 77000, loss: 0.294105
 >> iter 78000, loss: 0.252730
 >> iter 79000, loss: 0.339406
 >> iter 80000, loss: 0.168577
   Number of active neurons: 3
 >> iter 81000, loss: 0.347127
 >> iter 82000, loss: 0.238970
 >> iter 83000, loss: 0.291834
 >> iter 84000, loss: 0.175054
 >> iter 85000, loss: 0.119838
 >> iter 86000, loss: 0.095364
 >> iter 87000, loss: 0.241515
 >> iter 88000, loss: 0.573368
 >> iter 89000, loss: 0.285317
 >> iter 90000, loss: 0.191209
   Number of active neurons: 3
 >> iter 91000, loss: 0.145473
 >> iter 92000, loss: 0.317709
 >> iter 93000, loss: 0.187783
 >> iter 94000, loss: 0.220960
 >> iter 95000, loss: 0.269870
 >> iter 96000, loss: 0.157590
 >> iter 97000, loss: 0.217469
 >> iter 98000, loss: 0.380998
 >> iter 99000, loss: 0.338349
 >> iter 100000, loss: 0.223743
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.570764
 >> iter 2000, loss: 9.519716
 >> iter 3000, loss: 4.598157
 >> iter 4000, loss: 2.051051
 >> iter 5000, loss: 1.189634
 >> iter 6000, loss: 0.687846
 >> iter 7000, loss: 0.589476
 >> iter 8000, loss: 0.515499
 >> iter 9000, loss: 0.465325
 >> iter 10000, loss: 0.447318
   Number of active neurons: 5
 >> iter 11000, loss: 0.342380
 >> iter 12000, loss: 0.259571
 >> iter 13000, loss: 0.381505
 >> iter 14000, loss: 0.373249
 >> iter 15000, loss: 0.282707
 >> iter 16000, loss: 0.338732
 >> iter 17000, loss: 0.368179
 >> iter 18000, loss: 0.266558
 >> iter 19000, loss: 0.281146
 >> iter 20000, loss: 0.409537
   Number of active neurons: 4
 >> iter 21000, loss: 0.253589
 >> iter 22000, loss: 0.305349
 >> iter 23000, loss: 0.339717
 >> iter 24000, loss: 0.228173
 >> iter 25000, loss: 0.482049
 >> iter 26000, loss: 0.305220
 >> iter 27000, loss: 0.175341
 >> iter 28000, loss: 0.263987
 >> iter 29000, loss: 0.433273
 >> iter 30000, loss: 0.259897
   Number of active neurons: 3
 >> iter 31000, loss: 0.345546
 >> iter 32000, loss: 0.306075
 >> iter 33000, loss: 0.441135
 >> iter 34000, loss: 0.472413
 >> iter 35000, loss: 0.286825
 >> iter 36000, loss: 0.412802
 >> iter 37000, loss: 0.405662
 >> iter 38000, loss: 0.369833
 >> iter 39000, loss: 0.217029
 >> iter 40000, loss: 0.217018
   Number of active neurons: 3
 >> iter 41000, loss: 0.305332
 >> iter 42000, loss: 0.335213
 >> iter 43000, loss: 0.352749
 >> iter 44000, loss: 0.281552
 >> iter 45000, loss: 0.192505
 >> iter 46000, loss: 0.315405
 >> iter 47000, loss: 0.353852
 >> iter 48000, loss: 0.281227
 >> iter 49000, loss: 0.222944
 >> iter 50000, loss: 0.357490
   Number of active neurons: 3
 >> iter 51000, loss: 0.415980
 >> iter 52000, loss: 0.254957
 >> iter 53000, loss: 0.377039
 >> iter 54000, loss: 0.315419
 >> iter 55000, loss: 0.489933
 >> iter 56000, loss: 0.523148
 >> iter 57000, loss: 0.246454
 >> iter 58000, loss: 0.168377
 >> iter 59000, loss: 0.349562
 >> iter 60000, loss: 0.197030
   Number of active neurons: 3
 >> iter 61000, loss: 0.349775
 >> iter 62000, loss: 0.216219
 >> iter 63000, loss: 0.389676
 >> iter 64000, loss: 0.402386
 >> iter 65000, loss: 0.559601
 >> iter 66000, loss: 0.517227
 >> iter 67000, loss: 0.301040
 >> iter 68000, loss: 0.168813
 >> iter 69000, loss: 0.209558
 >> iter 70000, loss: 0.330769
   Number of active neurons: 3
 >> iter 71000, loss: 0.224008
 >> iter 72000, loss: 0.336366
 >> iter 73000, loss: 0.395368
 >> iter 74000, loss: 0.260072
 >> iter 75000, loss: 0.257804
 >> iter 76000, loss: 0.252890
 >> iter 77000, loss: 0.491156
 >> iter 78000, loss: 0.264073
 >> iter 79000, loss: 0.256642
 >> iter 80000, loss: 0.455085
   Number of active neurons: 3
 >> iter 81000, loss: 0.322315
 >> iter 82000, loss: 0.590033
 >> iter 83000, loss: 0.408072
 >> iter 84000, loss: 0.298863
 >> iter 85000, loss: 0.270502
 >> iter 86000, loss: 0.328469
 >> iter 87000, loss: 0.532801
 >> iter 88000, loss: 0.318765
 >> iter 89000, loss: 0.244522
 >> iter 90000, loss: 0.240206
   Number of active neurons: 3
 >> iter 91000, loss: 0.155558
 >> iter 92000, loss: 0.259413
 >> iter 93000, loss: 0.267745
 >> iter 94000, loss: 0.197031
 >> iter 95000, loss: 0.223837
 >> iter 96000, loss: 0.282436
 >> iter 97000, loss: 0.196675
 >> iter 98000, loss: 0.245979
 >> iter 99000, loss: 0.284210
 >> iter 100000, loss: 0.188848
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.842997
 >> iter 2000, loss: 8.838591
 >> iter 3000, loss: 4.438681
 >> iter 4000, loss: 2.073557
 >> iter 5000, loss: 1.160323
 >> iter 6000, loss: 0.800287
 >> iter 7000, loss: 0.483811
 >> iter 8000, loss: 0.579597
 >> iter 9000, loss: 0.433748
 >> iter 10000, loss: 0.269520
   Number of active neurons: 5
 >> iter 11000, loss: 0.304733
 >> iter 12000, loss: 0.199624
 >> iter 13000, loss: 0.231420
 >> iter 14000, loss: 0.331896
 >> iter 15000, loss: 0.384035
 >> iter 16000, loss: 0.422124
 >> iter 17000, loss: 0.343604
 >> iter 18000, loss: 0.372695
 >> iter 19000, loss: 0.384120
 >> iter 20000, loss: 0.232153
   Number of active neurons: 4
 >> iter 21000, loss: 0.407384
 >> iter 22000, loss: 0.472457
 >> iter 23000, loss: 0.393039
 >> iter 24000, loss: 0.403870
 >> iter 25000, loss: 0.224682
 >> iter 26000, loss: 0.253830
 >> iter 27000, loss: 0.192611
 >> iter 28000, loss: 0.438049
 >> iter 29000, loss: 0.290487
 >> iter 30000, loss: 0.585237
   Number of active neurons: 4
 >> iter 31000, loss: 0.460210
 >> iter 32000, loss: 0.371810
 >> iter 33000, loss: 0.364681
 >> iter 34000, loss: 0.297182
 >> iter 35000, loss: 0.232791
 >> iter 36000, loss: 0.308480
 >> iter 37000, loss: 0.281594
 >> iter 38000, loss: 0.264725
 >> iter 39000, loss: 0.245116
 >> iter 40000, loss: 0.231097
   Number of active neurons: 4
 >> iter 41000, loss: 0.292710
 >> iter 42000, loss: 0.310353
 >> iter 43000, loss: 0.391914
 >> iter 44000, loss: 0.249964
 >> iter 45000, loss: 0.215943
 >> iter 46000, loss: 0.257307
 >> iter 47000, loss: 0.340786
 >> iter 48000, loss: 0.346408
 >> iter 49000, loss: 0.250741
 >> iter 50000, loss: 0.389931
   Number of active neurons: 3
 >> iter 51000, loss: 0.430516
 >> iter 52000, loss: 0.264921
 >> iter 53000, loss: 0.460144
 >> iter 54000, loss: 0.346837
 >> iter 55000, loss: 0.260801
 >> iter 56000, loss: 0.350767
 >> iter 57000, loss: 0.273377
 >> iter 58000, loss: 0.340647
 >> iter 59000, loss: 0.293869
 >> iter 60000, loss: 0.319379
   Number of active neurons: 3
 >> iter 61000, loss: 0.390441
 >> iter 62000, loss: 0.299966
 >> iter 63000, loss: 0.302785
 >> iter 64000, loss: 0.347689
 >> iter 65000, loss: 0.285408
 >> iter 66000, loss: 0.381464
 >> iter 67000, loss: 0.282661
 >> iter 68000, loss: 0.258721
 >> iter 69000, loss: 0.246253
 >> iter 70000, loss: 0.199315
   Number of active neurons: 3
 >> iter 71000, loss: 0.228748
 >> iter 72000, loss: 0.210292
 >> iter 73000, loss: 0.219763
 >> iter 74000, loss: 0.374000
 >> iter 75000, loss: 0.286885
 >> iter 76000, loss: 0.281860
 >> iter 77000, loss: 0.237276
 >> iter 78000, loss: 0.185357
 >> iter 79000, loss: 0.244028
 >> iter 80000, loss: 0.217401
   Number of active neurons: 3
 >> iter 81000, loss: 0.246862
 >> iter 82000, loss: 0.205034
 >> iter 83000, loss: 0.175734
 >> iter 84000, loss: 0.159772
 >> iter 85000, loss: 0.210607
 >> iter 86000, loss: 0.184551
 >> iter 87000, loss: 0.277949
 >> iter 88000, loss: 0.471821
 >> iter 89000, loss: 0.262369
 >> iter 90000, loss: 0.159864
   Number of active neurons: 3
 >> iter 91000, loss: 0.323674
 >> iter 92000, loss: 0.181928
 >> iter 93000, loss: 0.168740
 >> iter 94000, loss: 0.252290
 >> iter 95000, loss: 0.286606
 >> iter 96000, loss: 0.196276
 >> iter 97000, loss: 0.272864
 >> iter 98000, loss: 0.368121
 >> iter 99000, loss: 0.364489
 >> iter 100000, loss: 0.346421
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.622676
 >> iter 2000, loss: 8.740260
 >> iter 3000, loss: 4.080528
 >> iter 4000, loss: 2.061325
 >> iter 5000, loss: 1.088295
 >> iter 6000, loss: 0.677183
 >> iter 7000, loss: 0.504434
 >> iter 8000, loss: 0.476317
 >> iter 9000, loss: 0.428692
 >> iter 10000, loss: 0.487970
   Number of active neurons: 3
 >> iter 11000, loss: 0.283827
 >> iter 12000, loss: 0.391172
 >> iter 13000, loss: 0.384606
 >> iter 14000, loss: 0.255073
 >> iter 15000, loss: 0.259802
 >> iter 16000, loss: 0.227262
 >> iter 17000, loss: 0.179776
 >> iter 18000, loss: 0.235876
 >> iter 19000, loss: 0.249593
 >> iter 20000, loss: 0.169949
   Number of active neurons: 3
 >> iter 21000, loss: 0.152046
 >> iter 22000, loss: 0.210946
 >> iter 23000, loss: 0.250254
 >> iter 24000, loss: 0.442002
 >> iter 25000, loss: 0.233998
 >> iter 26000, loss: 0.213959
 >> iter 27000, loss: 0.179290
 >> iter 28000, loss: 0.417888
 >> iter 29000, loss: 0.226598
 >> iter 30000, loss: 0.437057
   Number of active neurons: 3
 >> iter 31000, loss: 0.300313
 >> iter 32000, loss: 0.282830
 >> iter 33000, loss: 0.290924
 >> iter 34000, loss: 0.196683
 >> iter 35000, loss: 0.350248
 >> iter 36000, loss: 0.308861
 >> iter 37000, loss: 0.233855
 >> iter 38000, loss: 0.175944
 >> iter 39000, loss: 0.308140
 >> iter 40000, loss: 0.273000
   Number of active neurons: 3
 >> iter 41000, loss: 0.296445
 >> iter 42000, loss: 0.390771
 >> iter 43000, loss: 0.283431
 >> iter 44000, loss: 0.354141
 >> iter 45000, loss: 0.337182
 >> iter 46000, loss: 0.305228
 >> iter 47000, loss: 0.255592
 >> iter 48000, loss: 0.380864
 >> iter 49000, loss: 0.300155
 >> iter 50000, loss: 0.289139
   Number of active neurons: 3
 >> iter 51000, loss: 0.297714
 >> iter 52000, loss: 0.250404
 >> iter 53000, loss: 0.233698
 >> iter 54000, loss: 0.176630
 >> iter 55000, loss: 0.340310
 >> iter 56000, loss: 0.317141
 >> iter 57000, loss: 0.340560
 >> iter 58000, loss: 0.176987
 >> iter 59000, loss: 0.266860
 >> iter 60000, loss: 0.337387
   Number of active neurons: 3
 >> iter 61000, loss: 0.160982
 >> iter 62000, loss: 0.250910
 >> iter 63000, loss: 0.493196
 >> iter 64000, loss: 0.392132
 >> iter 65000, loss: 0.270086
 >> iter 66000, loss: 0.170914
 >> iter 67000, loss: 0.291011
 >> iter 68000, loss: 0.442687
 >> iter 69000, loss: 0.448498
 >> iter 70000, loss: 0.369290
   Number of active neurons: 3
 >> iter 71000, loss: 0.341653
 >> iter 72000, loss: 0.214782
 >> iter 73000, loss: 0.140613
 >> iter 74000, loss: 0.289158
 >> iter 75000, loss: 0.440967
 >> iter 76000, loss: 0.316903
 >> iter 77000, loss: 0.199093
 >> iter 78000, loss: 0.400498
 >> iter 79000, loss: 0.336398
 >> iter 80000, loss: 0.287557
   Number of active neurons: 3
 >> iter 81000, loss: 0.200317
 >> iter 82000, loss: 0.169277
 >> iter 83000, loss: 0.091523
 >> iter 84000, loss: 0.124159
 >> iter 85000, loss: 0.197569
 >> iter 86000, loss: 0.158336
 >> iter 87000, loss: 0.291474
 >> iter 88000, loss: 0.240890
 >> iter 89000, loss: 0.286184
 >> iter 90000, loss: 0.254362
   Number of active neurons: 3
 >> iter 91000, loss: 0.268950
 >> iter 92000, loss: 0.194861
 >> iter 93000, loss: 0.195516
 >> iter 94000, loss: 0.100415
 >> iter 95000, loss: 0.225925
 >> iter 96000, loss: 0.199198
 >> iter 97000, loss: 0.187396
 >> iter 98000, loss: 0.331899
 >> iter 99000, loss: 0.208971
 >> iter 100000, loss: 0.292338
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.829444
 >> iter 2000, loss: 8.544352
 >> iter 3000, loss: 3.779648
 >> iter 4000, loss: 1.926059
 >> iter 5000, loss: 1.103574
 >> iter 6000, loss: 0.668588
 >> iter 7000, loss: 0.542313
 >> iter 8000, loss: 0.469645
 >> iter 9000, loss: 0.421039
 >> iter 10000, loss: 0.342376
   Number of active neurons: 5
 >> iter 11000, loss: 0.294628
 >> iter 12000, loss: 0.347849
 >> iter 13000, loss: 0.254856
 >> iter 14000, loss: 0.362119
 >> iter 15000, loss: 0.251419
 >> iter 16000, loss: 0.196425
 >> iter 17000, loss: 0.148624
 >> iter 18000, loss: 0.237789
 >> iter 19000, loss: 0.353471
 >> iter 20000, loss: 0.344465
   Number of active neurons: 5
 >> iter 21000, loss: 0.217335
 >> iter 22000, loss: 0.401952
 >> iter 23000, loss: 0.453543
 >> iter 24000, loss: 0.294903
 >> iter 25000, loss: 0.201725
 >> iter 26000, loss: 0.232206
 >> iter 27000, loss: 0.301649
 >> iter 28000, loss: 0.288887
 >> iter 29000, loss: 0.305527
 >> iter 30000, loss: 0.328862
   Number of active neurons: 5
 >> iter 31000, loss: 0.242683
 >> iter 32000, loss: 0.464813
 >> iter 33000, loss: 0.520147
 >> iter 34000, loss: 0.323247
 >> iter 35000, loss: 0.342055
 >> iter 36000, loss: 0.173959
 >> iter 37000, loss: 0.227053
 >> iter 38000, loss: 0.260875
 >> iter 39000, loss: 0.180405
 >> iter 40000, loss: 0.267100
   Number of active neurons: 4
 >> iter 41000, loss: 0.276480
 >> iter 42000, loss: 0.404570
 >> iter 43000, loss: 0.261923
 >> iter 44000, loss: 0.227898
 >> iter 45000, loss: 0.222491
 >> iter 46000, loss: 0.253727
 >> iter 47000, loss: 0.227630
 >> iter 48000, loss: 0.343224
 >> iter 49000, loss: 0.283872
 >> iter 50000, loss: 0.324216
   Number of active neurons: 3
 >> iter 51000, loss: 0.205855
 >> iter 52000, loss: 0.223561
 >> iter 53000, loss: 0.241216
 >> iter 54000, loss: 0.316313
 >> iter 55000, loss: 0.292064
 >> iter 56000, loss: 0.340228
 >> iter 57000, loss: 0.297789
 >> iter 58000, loss: 0.296513
 >> iter 59000, loss: 0.266272
 >> iter 60000, loss: 0.320556
   Number of active neurons: 3
 >> iter 61000, loss: 0.432599
 >> iter 62000, loss: 0.357865
 >> iter 63000, loss: 0.305506
 >> iter 64000, loss: 0.280880
 >> iter 65000, loss: 0.282303
 >> iter 66000, loss: 0.283621
 >> iter 67000, loss: 0.358553
 >> iter 68000, loss: 0.329654
 >> iter 69000, loss: 0.212631
 >> iter 70000, loss: 0.163812
   Number of active neurons: 3
 >> iter 71000, loss: 0.265005
 >> iter 72000, loss: 0.186733
 >> iter 73000, loss: 0.189592
 >> iter 74000, loss: 0.220117
 >> iter 75000, loss: 0.108341
 >> iter 76000, loss: 0.149198
 >> iter 77000, loss: 0.274182
 >> iter 78000, loss: 0.263247
 >> iter 79000, loss: 0.196696
 >> iter 80000, loss: 0.279712
   Number of active neurons: 3
 >> iter 81000, loss: 0.231727
 >> iter 82000, loss: 0.172061
 >> iter 83000, loss: 0.304810
 >> iter 84000, loss: 0.196898
 >> iter 85000, loss: 0.339002
 >> iter 86000, loss: 0.263144
 >> iter 87000, loss: 0.261632
 >> iter 88000, loss: 0.316400
 >> iter 89000, loss: 0.285888
 >> iter 90000, loss: 0.140910
   Number of active neurons: 3
 >> iter 91000, loss: 0.287266
 >> iter 92000, loss: 0.181285
 >> iter 93000, loss: 0.187288
 >> iter 94000, loss: 0.197090
 >> iter 95000, loss: 0.146134
 >> iter 96000, loss: 0.252033
 >> iter 97000, loss: 0.303506
 >> iter 98000, loss: 0.334450
 >> iter 99000, loss: 0.279329
 >> iter 100000, loss: 0.387193
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.308732
 >> iter 2000, loss: 9.707671
 >> iter 3000, loss: 4.255987
 >> iter 4000, loss: 2.057656
 >> iter 5000, loss: 0.939773
 >> iter 6000, loss: 0.549453
 >> iter 7000, loss: 0.379779
 >> iter 8000, loss: 0.347132
 >> iter 9000, loss: 0.281853
 >> iter 10000, loss: 0.271076
   Number of active neurons: 5
 >> iter 11000, loss: 0.327089
 >> iter 12000, loss: 0.355847
 >> iter 13000, loss: 0.250142
 >> iter 14000, loss: 0.298557
 >> iter 15000, loss: 0.272262
 >> iter 16000, loss: 0.404275
 >> iter 17000, loss: 0.382817
 >> iter 18000, loss: 0.378352
 >> iter 19000, loss: 0.308389
 >> iter 20000, loss: 0.240330
   Number of active neurons: 5
 >> iter 21000, loss: 0.306545
 >> iter 22000, loss: 0.341301
 >> iter 23000, loss: 0.310573
 >> iter 24000, loss: 0.291068
 >> iter 25000, loss: 0.438161
 >> iter 26000, loss: 0.234329
 >> iter 27000, loss: 0.263118
 >> iter 28000, loss: 0.284024
 >> iter 29000, loss: 0.309171
 >> iter 30000, loss: 0.291485
   Number of active neurons: 5
 >> iter 31000, loss: 0.369177
 >> iter 32000, loss: 0.347136
 >> iter 33000, loss: 0.190360
 >> iter 34000, loss: 0.312302
 >> iter 35000, loss: 0.209236
 >> iter 36000, loss: 0.226343
 >> iter 37000, loss: 0.322088
 >> iter 38000, loss: 0.354643
 >> iter 39000, loss: 0.224035
 >> iter 40000, loss: 0.194773
   Number of active neurons: 4
 >> iter 41000, loss: 0.148582
 >> iter 42000, loss: 0.194407
 >> iter 43000, loss: 0.223865
 >> iter 44000, loss: 0.184463
 >> iter 45000, loss: 0.231850
 >> iter 46000, loss: 0.145929
 >> iter 47000, loss: 0.166517
 >> iter 48000, loss: 0.173432
 >> iter 49000, loss: 0.201154
 >> iter 50000, loss: 0.203541
   Number of active neurons: 3
 >> iter 51000, loss: 0.130208
 >> iter 52000, loss: 0.136566
 >> iter 53000, loss: 0.293585
 >> iter 54000, loss: 0.290753
 >> iter 55000, loss: 0.197093
 >> iter 56000, loss: 0.225345
 >> iter 57000, loss: 0.160539
 >> iter 58000, loss: 0.238704
 >> iter 59000, loss: 0.164633
 >> iter 60000, loss: 0.320210
   Number of active neurons: 3
 >> iter 61000, loss: 0.229030
 >> iter 62000, loss: 0.182587
 >> iter 63000, loss: 0.195778
 >> iter 64000, loss: 0.218432
 >> iter 65000, loss: 0.199761
 >> iter 66000, loss: 0.235397
 >> iter 67000, loss: 0.189434
 >> iter 68000, loss: 0.276654
 >> iter 69000, loss: 0.370268
 >> iter 70000, loss: 0.539874
   Number of active neurons: 3
 >> iter 71000, loss: 0.488423
 >> iter 72000, loss: 0.329176
 >> iter 73000, loss: 0.260033
 >> iter 74000, loss: 0.367823
 >> iter 75000, loss: 0.225896
 >> iter 76000, loss: 0.269725
 >> iter 77000, loss: 0.143017
 >> iter 78000, loss: 0.221509
 >> iter 79000, loss: 0.222092
 >> iter 80000, loss: 0.323806
   Number of active neurons: 3
 >> iter 81000, loss: 0.220515
 >> iter 82000, loss: 0.261996
 >> iter 83000, loss: 0.280498
 >> iter 84000, loss: 0.172963
 >> iter 85000, loss: 0.270866
 >> iter 86000, loss: 0.240155
 >> iter 87000, loss: 0.310030
 >> iter 88000, loss: 0.184822
 >> iter 89000, loss: 0.342414
 >> iter 90000, loss: 0.259512
   Number of active neurons: 3
 >> iter 91000, loss: 0.323640
 >> iter 92000, loss: 0.213006
 >> iter 93000, loss: 0.215049
 >> iter 94000, loss: 0.250812
 >> iter 95000, loss: 0.357470
 >> iter 96000, loss: 0.284215
 >> iter 97000, loss: 0.204312
 >> iter 98000, loss: 0.275940
 >> iter 99000, loss: 0.373461
 >> iter 100000, loss: 0.428840
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.735752
 >> iter 2000, loss: 10.079153
 >> iter 3000, loss: 4.698292
 >> iter 4000, loss: 1.961722
 >> iter 5000, loss: 1.237292
 >> iter 6000, loss: 0.893768
 >> iter 7000, loss: 0.609266
 >> iter 8000, loss: 0.322395
 >> iter 9000, loss: 0.380694
 >> iter 10000, loss: 0.373728
   Number of active neurons: 6
 >> iter 11000, loss: 0.293697
 >> iter 12000, loss: 0.439889
 >> iter 13000, loss: 0.300503
 >> iter 14000, loss: 0.220141
 >> iter 15000, loss: 0.184999
 >> iter 16000, loss: 0.144147
 >> iter 17000, loss: 0.316872
 >> iter 18000, loss: 0.266882
 >> iter 19000, loss: 0.365712
 >> iter 20000, loss: 0.319720
   Number of active neurons: 6
 >> iter 21000, loss: 0.407739
 >> iter 22000, loss: 0.407674
 >> iter 23000, loss: 0.383973
 >> iter 24000, loss: 0.286297
 >> iter 25000, loss: 0.324624
 >> iter 26000, loss: 0.281503
 >> iter 27000, loss: 0.426349
 >> iter 28000, loss: 0.466852
 >> iter 29000, loss: 0.330076
 >> iter 30000, loss: 0.255765
   Number of active neurons: 5
 >> iter 31000, loss: 0.372471
 >> iter 32000, loss: 0.213216
 >> iter 33000, loss: 0.299429
 >> iter 34000, loss: 0.198014
 >> iter 35000, loss: 0.224605
 >> iter 36000, loss: 0.181212
 >> iter 37000, loss: 0.193354
 >> iter 38000, loss: 0.265814
 >> iter 39000, loss: 0.212196
 >> iter 40000, loss: 0.224576
   Number of active neurons: 4
 >> iter 41000, loss: 0.163069
 >> iter 42000, loss: 0.093021
 >> iter 43000, loss: 0.181779
 >> iter 44000, loss: 0.315601
 >> iter 45000, loss: 0.184893
 >> iter 46000, loss: 0.102252
 >> iter 47000, loss: 0.487528
 >> iter 48000, loss: 0.449833
 >> iter 49000, loss: 0.290790
 >> iter 50000, loss: 0.277820
   Number of active neurons: 4
 >> iter 51000, loss: 0.338206
 >> iter 52000, loss: 0.260946
 >> iter 53000, loss: 0.211632
 >> iter 54000, loss: 0.204236
 >> iter 55000, loss: 0.179687
 >> iter 56000, loss: 0.152549
 >> iter 57000, loss: 0.250145
 >> iter 58000, loss: 0.343233
 >> iter 59000, loss: 0.182739
 >> iter 60000, loss: 0.291234
   Number of active neurons: 4
 >> iter 61000, loss: 0.302435
 >> iter 62000, loss: 0.172490
 >> iter 63000, loss: 0.104552
 >> iter 64000, loss: 0.192091
 >> iter 65000, loss: 0.163580
 >> iter 66000, loss: 0.141104
 >> iter 67000, loss: 0.179509
 >> iter 68000, loss: 0.292213
 >> iter 69000, loss: 0.182705
 >> iter 70000, loss: 0.225361
   Number of active neurons: 4
 >> iter 71000, loss: 0.394307
 >> iter 72000, loss: 0.205404
 >> iter 73000, loss: 0.237651
 >> iter 74000, loss: 0.241741
 >> iter 75000, loss: 0.211129
 >> iter 76000, loss: 0.158942
 >> iter 77000, loss: 0.188039
 >> iter 78000, loss: 0.158783
 >> iter 79000, loss: 0.105021
 >> iter 80000, loss: 0.472121
   Number of active neurons: 4
 >> iter 81000, loss: 0.273119
 >> iter 82000, loss: 0.244642
 >> iter 83000, loss: 0.215543
 >> iter 84000, loss: 0.259651
 >> iter 85000, loss: 0.260141
 >> iter 86000, loss: 0.174228
 >> iter 87000, loss: 0.152399
 >> iter 88000, loss: 0.167263
 >> iter 89000, loss: 0.142570
 >> iter 90000, loss: 0.230347
   Number of active neurons: 4
 >> iter 91000, loss: 0.223674
 >> iter 92000, loss: 0.205681
 >> iter 93000, loss: 0.336122
 >> iter 94000, loss: 0.451832
 >> iter 95000, loss: 0.413829
 >> iter 96000, loss: 0.422344
 >> iter 97000, loss: 0.275828
 >> iter 98000, loss: 0.221365
 >> iter 99000, loss: 0.212515
 >> iter 100000, loss: 0.161484
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.168064
 >> iter 2000, loss: 7.970506
 >> iter 3000, loss: 3.603478
 >> iter 4000, loss: 1.666879
 >> iter 5000, loss: 1.074548
 >> iter 6000, loss: 0.610783
 >> iter 7000, loss: 0.691457
 >> iter 8000, loss: 0.503027
 >> iter 9000, loss: 0.382414
 >> iter 10000, loss: 0.235783
   Number of active neurons: 5
 >> iter 11000, loss: 0.222240
 >> iter 12000, loss: 0.246837
 >> iter 13000, loss: 0.250016
 >> iter 14000, loss: 0.584501
 >> iter 15000, loss: 0.662893
 >> iter 16000, loss: 0.543100
 >> iter 17000, loss: 0.376396
 >> iter 18000, loss: 0.321756
 >> iter 19000, loss: 0.431212
 >> iter 20000, loss: 0.222652
   Number of active neurons: 5
 >> iter 21000, loss: 0.246791
 >> iter 22000, loss: 0.275759
 >> iter 23000, loss: 0.260851
 >> iter 24000, loss: 0.295561
 >> iter 25000, loss: 0.268302
 >> iter 26000, loss: 0.378953
 >> iter 27000, loss: 0.730564
 >> iter 28000, loss: 0.426099
 >> iter 29000, loss: 0.336198
 >> iter 30000, loss: 0.367520
   Number of active neurons: 4
 >> iter 31000, loss: 0.212828
 >> iter 32000, loss: 0.411092
 >> iter 33000, loss: 0.300042
 >> iter 34000, loss: 0.168569
 >> iter 35000, loss: 0.339723
 >> iter 36000, loss: 0.308933
 >> iter 37000, loss: 0.273525
 >> iter 38000, loss: 0.307841
 >> iter 39000, loss: 0.147746
 >> iter 40000, loss: 0.266122
   Number of active neurons: 4
 >> iter 41000, loss: 0.226986
 >> iter 42000, loss: 0.306670
 >> iter 43000, loss: 0.176817
 >> iter 44000, loss: 0.294010
 >> iter 45000, loss: 0.306850
 >> iter 46000, loss: 0.278523
 >> iter 47000, loss: 0.190628
 >> iter 48000, loss: 0.198832
 >> iter 49000, loss: 0.336112
 >> iter 50000, loss: 0.236412
   Number of active neurons: 3
 >> iter 51000, loss: 0.286880
 >> iter 52000, loss: 0.161994
 >> iter 53000, loss: 0.239648
 >> iter 54000, loss: 0.253439
 >> iter 55000, loss: 0.221356
 >> iter 56000, loss: 0.189393
 >> iter 57000, loss: 0.270975
 >> iter 58000, loss: 0.473869
 >> iter 59000, loss: 0.323537
 >> iter 60000, loss: 0.406778
   Number of active neurons: 3
 >> iter 61000, loss: 0.334486
 >> iter 62000, loss: 0.327784
 >> iter 63000, loss: 0.208658
 >> iter 64000, loss: 0.148584
 >> iter 65000, loss: 0.300036
 >> iter 66000, loss: 0.326852
 >> iter 67000, loss: 0.448907
 >> iter 68000, loss: 0.390104
 >> iter 69000, loss: 0.241718
 >> iter 70000, loss: 0.197035
   Number of active neurons: 3
 >> iter 71000, loss: 0.428341
 >> iter 72000, loss: 0.240089
 >> iter 73000, loss: 0.271843
 >> iter 74000, loss: 0.191126
 >> iter 75000, loss: 0.316583
 >> iter 76000, loss: 0.229929
 >> iter 77000, loss: 0.181229
 >> iter 78000, loss: 0.308489
 >> iter 79000, loss: 0.396716
 >> iter 80000, loss: 0.240763
   Number of active neurons: 3
 >> iter 81000, loss: 0.391478
 >> iter 82000, loss: 0.284406
 >> iter 83000, loss: 0.277307
 >> iter 84000, loss: 0.266361
 >> iter 85000, loss: 0.136385
 >> iter 86000, loss: 0.197728
 >> iter 87000, loss: 0.218869
 >> iter 88000, loss: 0.261165
 >> iter 89000, loss: 0.156032
 >> iter 90000, loss: 0.132163
   Number of active neurons: 3
 >> iter 91000, loss: 0.211802
 >> iter 92000, loss: 0.166834
 >> iter 93000, loss: 0.169536
 >> iter 94000, loss: 0.214434
 >> iter 95000, loss: 0.216586
 >> iter 96000, loss: 0.287337
 >> iter 97000, loss: 0.218897
 >> iter 98000, loss: 0.178957
 >> iter 99000, loss: 0.179999
 >> iter 100000, loss: 0.202309
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.825211
 >> iter 2000, loss: 8.828188
 >> iter 3000, loss: 4.184639
 >> iter 4000, loss: 2.229830
 >> iter 5000, loss: 1.239065
 >> iter 6000, loss: 0.674726
 >> iter 7000, loss: 0.490040
 >> iter 8000, loss: 0.859963
 >> iter 9000, loss: 0.660938
 >> iter 10000, loss: 0.494494
   Number of active neurons: 5
 >> iter 11000, loss: 0.490291
 >> iter 12000, loss: 0.474452
 >> iter 13000, loss: 0.477666
 >> iter 14000, loss: 0.642644
 >> iter 15000, loss: 0.492938
 >> iter 16000, loss: 0.536145
 >> iter 17000, loss: 0.641153
 >> iter 18000, loss: 0.660307
 >> iter 19000, loss: 0.679429
 >> iter 20000, loss: 0.672730
   Number of active neurons: 5
 >> iter 21000, loss: 0.598348
 >> iter 22000, loss: 0.388083
 >> iter 23000, loss: 0.352046
 >> iter 24000, loss: 0.507043
 >> iter 25000, loss: 0.718840
 >> iter 26000, loss: 0.454596
 >> iter 27000, loss: 0.547284
 >> iter 28000, loss: 0.566604
 >> iter 29000, loss: 0.410491
 >> iter 30000, loss: 0.563317
   Number of active neurons: 5
 >> iter 31000, loss: 0.511062
 >> iter 32000, loss: 0.377686
 >> iter 33000, loss: 0.308520
 >> iter 34000, loss: 0.282535
 >> iter 35000, loss: 0.572690
 >> iter 36000, loss: 0.435949
 >> iter 37000, loss: 0.279493
 >> iter 38000, loss: 0.395418
 >> iter 39000, loss: 0.610011
 >> iter 40000, loss: 0.520321
   Number of active neurons: 4
 >> iter 41000, loss: 0.533536
 >> iter 42000, loss: 0.435127
 >> iter 43000, loss: 0.294948
 >> iter 44000, loss: 0.441770
 >> iter 45000, loss: 0.301879
 >> iter 46000, loss: 0.387982
 >> iter 47000, loss: 0.314997
 >> iter 48000, loss: 0.508339
 >> iter 49000, loss: 0.384720
 >> iter 50000, loss: 0.290019
   Number of active neurons: 4
 >> iter 51000, loss: 0.200957
 >> iter 52000, loss: 0.267667
 >> iter 53000, loss: 0.447138
 >> iter 54000, loss: 0.375889
 >> iter 55000, loss: 0.511453
 >> iter 56000, loss: 0.326522
 >> iter 57000, loss: 0.354770
 >> iter 58000, loss: 0.411647
 >> iter 59000, loss: 0.247859
 >> iter 60000, loss: 0.425619
   Number of active neurons: 4
 >> iter 61000, loss: 0.301599
 >> iter 62000, loss: 0.257849
 >> iter 63000, loss: 0.251681
 >> iter 64000, loss: 0.358159
 >> iter 65000, loss: 0.416080
 >> iter 66000, loss: 0.482707
 >> iter 67000, loss: 0.348653
 >> iter 68000, loss: 0.404405
 >> iter 69000, loss: 0.430831
 >> iter 70000, loss: 0.480475
   Number of active neurons: 4
 >> iter 71000, loss: 0.362305
 >> iter 72000, loss: 0.286075
 >> iter 73000, loss: 0.557864
 >> iter 74000, loss: 0.394116
 >> iter 75000, loss: 0.374681
 >> iter 76000, loss: 0.253886
 >> iter 77000, loss: 0.333170
 >> iter 78000, loss: 0.334753
 >> iter 79000, loss: 0.291562
 >> iter 80000, loss: 0.306581
   Number of active neurons: 4
 >> iter 81000, loss: 0.370306
 >> iter 82000, loss: 0.327666
 >> iter 83000, loss: 0.276099
 >> iter 84000, loss: 0.370614
 >> iter 85000, loss: 0.313190
 >> iter 86000, loss: 0.390663
 >> iter 87000, loss: 0.479672
 >> iter 88000, loss: 0.354063
 >> iter 89000, loss: 0.390895
 >> iter 90000, loss: 0.522012
   Number of active neurons: 4
 >> iter 91000, loss: 0.340281
 >> iter 92000, loss: 0.291841
 >> iter 93000, loss: 0.308649
 >> iter 94000, loss: 0.321936
 >> iter 95000, loss: 0.361737
 >> iter 96000, loss: 0.383427
 >> iter 97000, loss: 0.393844
 >> iter 98000, loss: 0.426926
 >> iter 99000, loss: 0.273737
 >> iter 100000, loss: 0.508580
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.942222
 >> iter 2000, loss: 8.585153
 >> iter 3000, loss: 4.161369
 >> iter 4000, loss: 1.868193
 >> iter 5000, loss: 1.187778
 >> iter 6000, loss: 0.650525
 >> iter 7000, loss: 0.810925
 >> iter 8000, loss: 0.402418
 >> iter 9000, loss: 0.417434
 >> iter 10000, loss: 0.323938
   Number of active neurons: 6
 >> iter 11000, loss: 0.295764
 >> iter 12000, loss: 0.357554
 >> iter 13000, loss: 0.284513
 >> iter 14000, loss: 0.280732
 >> iter 15000, loss: 0.356409
 >> iter 16000, loss: 0.390658
 >> iter 17000, loss: 0.501712
 >> iter 18000, loss: 0.364703
 >> iter 19000, loss: 0.280472
 >> iter 20000, loss: 0.341378
   Number of active neurons: 6
 >> iter 21000, loss: 0.480812
 >> iter 22000, loss: 0.417916
 >> iter 23000, loss: 0.539583
 >> iter 24000, loss: 0.585479
 >> iter 25000, loss: 0.405211
 >> iter 26000, loss: 0.224013
 >> iter 27000, loss: 0.230016
 >> iter 28000, loss: 0.362653
 >> iter 29000, loss: 0.326399
 >> iter 30000, loss: 0.231225
   Number of active neurons: 4
 >> iter 31000, loss: 0.360023
 >> iter 32000, loss: 0.228073
 >> iter 33000, loss: 0.150736
 >> iter 34000, loss: 0.402272
 >> iter 35000, loss: 0.403026
 >> iter 36000, loss: 0.466010
 >> iter 37000, loss: 0.273971
 >> iter 38000, loss: 0.429144
 >> iter 39000, loss: 0.406731
 >> iter 40000, loss: 0.362885
   Number of active neurons: 3
 >> iter 41000, loss: 0.291115
 >> iter 42000, loss: 0.495435
 >> iter 43000, loss: 0.292871
 >> iter 44000, loss: 0.187835
 >> iter 45000, loss: 0.352817
 >> iter 46000, loss: 0.387715
 >> iter 47000, loss: 0.262206
 >> iter 48000, loss: 0.180916
 >> iter 49000, loss: 0.196099
 >> iter 50000, loss: 0.197898
   Number of active neurons: 3
 >> iter 51000, loss: 0.250166
 >> iter 52000, loss: 0.267065
 >> iter 53000, loss: 0.213009
 >> iter 54000, loss: 0.318214
 >> iter 55000, loss: 0.264396
 >> iter 56000, loss: 0.362609
 >> iter 57000, loss: 0.394725
 >> iter 58000, loss: 0.415134
 >> iter 59000, loss: 0.307250
 >> iter 60000, loss: 0.278717
   Number of active neurons: 3
 >> iter 61000, loss: 0.248102
 >> iter 62000, loss: 0.214841
 >> iter 63000, loss: 0.300553
 >> iter 64000, loss: 0.350779
 >> iter 65000, loss: 0.385648
 >> iter 66000, loss: 0.224293
 >> iter 67000, loss: 0.310897
 >> iter 68000, loss: 0.303711
 >> iter 69000, loss: 0.232535
 >> iter 70000, loss: 0.243025
   Number of active neurons: 3
 >> iter 71000, loss: 0.224315
 >> iter 72000, loss: 0.188901
 >> iter 73000, loss: 0.279186
 >> iter 74000, loss: 0.270902
 >> iter 75000, loss: 0.355463
 >> iter 76000, loss: 0.300697
 >> iter 77000, loss: 0.190335
 >> iter 78000, loss: 0.212470
 >> iter 79000, loss: 0.166294
 >> iter 80000, loss: 0.223691
   Number of active neurons: 3
 >> iter 81000, loss: 0.139983
 >> iter 82000, loss: 0.416028
 >> iter 83000, loss: 0.351419
 >> iter 84000, loss: 0.262474
 >> iter 85000, loss: 0.190674
 >> iter 86000, loss: 0.170133
 >> iter 87000, loss: 0.111475
 >> iter 88000, loss: 0.164293
 >> iter 89000, loss: 0.237176
 >> iter 90000, loss: 0.199371
   Number of active neurons: 3
 >> iter 91000, loss: 0.259871
 >> iter 92000, loss: 0.212829
 >> iter 93000, loss: 0.169426
 >> iter 94000, loss: 0.229640
 >> iter 95000, loss: 0.180956
 >> iter 96000, loss: 0.368109
 >> iter 97000, loss: 0.204751
 >> iter 98000, loss: 0.209394
 >> iter 99000, loss: 0.223382
 >> iter 100000, loss: 0.443765
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.124252
 >> iter 2000, loss: 9.205122
 >> iter 3000, loss: 4.261544
 >> iter 4000, loss: 2.102167
 >> iter 5000, loss: 1.298488
 >> iter 6000, loss: 0.715137
 >> iter 7000, loss: 0.683725
 >> iter 8000, loss: 0.585611
 >> iter 9000, loss: 0.439623
 >> iter 10000, loss: 0.361381
   Number of active neurons: 5
 >> iter 11000, loss: 0.336804
 >> iter 12000, loss: 0.240875
 >> iter 13000, loss: 0.487655
 >> iter 14000, loss: 0.399507
 >> iter 15000, loss: 0.229264
 >> iter 16000, loss: 0.224915
 >> iter 17000, loss: 0.241629
 >> iter 18000, loss: 0.289660
 >> iter 19000, loss: 0.393885
 >> iter 20000, loss: 0.552945
   Number of active neurons: 5
 >> iter 21000, loss: 0.476441
 >> iter 22000, loss: 0.302306
 >> iter 23000, loss: 0.362541
 >> iter 24000, loss: 0.347323
 >> iter 25000, loss: 0.445046
 >> iter 26000, loss: 0.464136
 >> iter 27000, loss: 0.413905
 >> iter 28000, loss: 0.291657
 >> iter 29000, loss: 0.421072
 >> iter 30000, loss: 0.707199
   Number of active neurons: 5
 >> iter 31000, loss: 0.539519
 >> iter 32000, loss: 0.352235
 >> iter 33000, loss: 0.317761
 >> iter 34000, loss: 0.355469
 >> iter 35000, loss: 0.359115
 >> iter 36000, loss: 0.294919
 >> iter 37000, loss: 0.239710
 >> iter 38000, loss: 0.305854
 >> iter 39000, loss: 0.303659
 >> iter 40000, loss: 0.542145
   Number of active neurons: 4
 >> iter 41000, loss: 0.548488
 >> iter 42000, loss: 0.363275
 >> iter 43000, loss: 0.478620
 >> iter 44000, loss: 0.282301
 >> iter 45000, loss: 0.329214
 >> iter 46000, loss: 0.343088
 >> iter 47000, loss: 0.415130
 >> iter 48000, loss: 0.342054
 >> iter 49000, loss: 0.371606
 >> iter 50000, loss: 0.279107
   Number of active neurons: 4
 >> iter 51000, loss: 0.297383
 >> iter 52000, loss: 0.342933
 >> iter 53000, loss: 0.334616
 >> iter 54000, loss: 0.263351
 >> iter 55000, loss: 0.193767
 >> iter 56000, loss: 0.295859
 >> iter 57000, loss: 0.237516
 >> iter 58000, loss: 0.571755
 >> iter 59000, loss: 0.474217
 >> iter 60000, loss: 0.500699
   Number of active neurons: 3
 >> iter 61000, loss: 0.418570
 >> iter 62000, loss: 0.350968
 >> iter 63000, loss: 0.298568
 >> iter 64000, loss: 0.449917
 >> iter 65000, loss: 0.598653
 >> iter 66000, loss: 0.365903
 >> iter 67000, loss: 0.339200
 >> iter 68000, loss: 0.324223
 >> iter 69000, loss: 0.290985
 >> iter 70000, loss: 0.203702
   Number of active neurons: 3
 >> iter 71000, loss: 0.291334
 >> iter 72000, loss: 0.289973
 >> iter 73000, loss: 0.365778
 >> iter 74000, loss: 0.424318
 >> iter 75000, loss: 0.255351
 >> iter 76000, loss: 0.334960
 >> iter 77000, loss: 0.411844
 >> iter 78000, loss: 0.352376
 >> iter 79000, loss: 0.552331
 >> iter 80000, loss: 0.244672
   Number of active neurons: 3
 >> iter 81000, loss: 0.199588
 >> iter 82000, loss: 0.236810
 >> iter 83000, loss: 0.237327
 >> iter 84000, loss: 0.182336
 >> iter 85000, loss: 0.331399
 >> iter 86000, loss: 0.350623
 >> iter 87000, loss: 0.304625
 >> iter 88000, loss: 0.299319
 >> iter 89000, loss: 0.237956
 >> iter 90000, loss: 0.213062
   Number of active neurons: 3
 >> iter 91000, loss: 0.226659
 >> iter 92000, loss: 0.237675
 >> iter 93000, loss: 0.286662
 >> iter 94000, loss: 0.437853
 >> iter 95000, loss: 0.414904
 >> iter 96000, loss: 0.195627
 >> iter 97000, loss: 0.320775
 >> iter 98000, loss: 0.266156
 >> iter 99000, loss: 0.217636
 >> iter 100000, loss: 0.328014
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.721404
 >> iter 2000, loss: 8.572111
 >> iter 3000, loss: 4.051876
 >> iter 4000, loss: 1.838139
 >> iter 5000, loss: 0.946614
 >> iter 6000, loss: 0.736600
 >> iter 7000, loss: 0.633319
 >> iter 8000, loss: 0.464434
 >> iter 9000, loss: 0.435708
 >> iter 10000, loss: 0.423192
   Number of active neurons: 5
 >> iter 11000, loss: 0.540891
 >> iter 12000, loss: 0.498631
 >> iter 13000, loss: 0.226832
 >> iter 14000, loss: 0.166305
 >> iter 15000, loss: 0.289470
 >> iter 16000, loss: 0.293082
 >> iter 17000, loss: 0.297533
 >> iter 18000, loss: 0.438783
 >> iter 19000, loss: 0.327838
 >> iter 20000, loss: 0.318409
   Number of active neurons: 5
 >> iter 21000, loss: 0.282519
 >> iter 22000, loss: 0.314952
 >> iter 23000, loss: 0.413428
 >> iter 24000, loss: 0.274800
 >> iter 25000, loss: 0.266673
 >> iter 26000, loss: 0.197240
 >> iter 27000, loss: 0.201472
 >> iter 28000, loss: 0.316415
 >> iter 29000, loss: 0.429793
 >> iter 30000, loss: 0.303989
   Number of active neurons: 5
 >> iter 31000, loss: 0.373738
 >> iter 32000, loss: 0.282295
 >> iter 33000, loss: 0.282601
 >> iter 34000, loss: 0.183810
 >> iter 35000, loss: 0.423391
 >> iter 36000, loss: 0.372717
 >> iter 37000, loss: 0.188227
 >> iter 38000, loss: 0.303899
 >> iter 39000, loss: 0.287188
 >> iter 40000, loss: 0.153526
   Number of active neurons: 5
 >> iter 41000, loss: 0.203287
 >> iter 42000, loss: 0.303941
 >> iter 43000, loss: 0.366286
 >> iter 44000, loss: 0.344322
 >> iter 45000, loss: 0.405112
 >> iter 46000, loss: 0.240575
 >> iter 47000, loss: 0.339364
 >> iter 48000, loss: 0.281698
 >> iter 49000, loss: 0.192146
 >> iter 50000, loss: 0.111359
   Number of active neurons: 5
 >> iter 51000, loss: 0.262552
 >> iter 52000, loss: 0.224326
 >> iter 53000, loss: 0.185151
 >> iter 54000, loss: 0.129891
 >> iter 55000, loss: 0.204301
 >> iter 56000, loss: 0.356595
 >> iter 57000, loss: 0.240178
 >> iter 58000, loss: 0.255491
 >> iter 59000, loss: 0.304640
 >> iter 60000, loss: 0.304288
   Number of active neurons: 5
 >> iter 61000, loss: 0.325550
 >> iter 62000, loss: 0.208778
 >> iter 63000, loss: 0.280987
 >> iter 64000, loss: 0.198599
 >> iter 65000, loss: 0.161715
 >> iter 66000, loss: 0.286524
 >> iter 67000, loss: 0.316889
 >> iter 68000, loss: 0.177399
 >> iter 69000, loss: 0.254586
 >> iter 70000, loss: 0.433414
   Number of active neurons: 5
 >> iter 71000, loss: 0.409737
 >> iter 72000, loss: 0.318650
 >> iter 73000, loss: 0.402868
 >> iter 74000, loss: 0.211551
 >> iter 75000, loss: 0.161084
 >> iter 76000, loss: 0.325510
 >> iter 77000, loss: 0.298499
 >> iter 78000, loss: 0.426782
 >> iter 79000, loss: 0.385750
 >> iter 80000, loss: 0.223871
   Number of active neurons: 5
 >> iter 81000, loss: 0.200963
 >> iter 82000, loss: 0.174516
 >> iter 83000, loss: 0.318199
 >> iter 84000, loss: 0.276136
 >> iter 85000, loss: 0.407044
 >> iter 86000, loss: 0.447590
 >> iter 87000, loss: 0.238961
 >> iter 88000, loss: 0.350218
 >> iter 89000, loss: 0.291503
 >> iter 90000, loss: 0.155373
   Number of active neurons: 5
 >> iter 91000, loss: 0.111755
 >> iter 92000, loss: 0.187497
 >> iter 93000, loss: 0.442508
 >> iter 94000, loss: 0.243269
 >> iter 95000, loss: 0.138119
 >> iter 96000, loss: 0.112046
 >> iter 97000, loss: 0.295307
 >> iter 98000, loss: 0.206350
 >> iter 99000, loss: 0.217399
 >> iter 100000, loss: 0.304303
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.713448
 >> iter 2000, loss: 8.913503
 >> iter 3000, loss: 3.571023
 >> iter 4000, loss: 1.535432
 >> iter 5000, loss: 0.903110
 >> iter 6000, loss: 0.542799
 >> iter 7000, loss: 0.604210
 >> iter 8000, loss: 0.480587
 >> iter 9000, loss: 0.518680
 >> iter 10000, loss: 0.701859
   Number of active neurons: 6
 >> iter 11000, loss: 0.680737
 >> iter 12000, loss: 0.436490
 >> iter 13000, loss: 0.375256
 >> iter 14000, loss: 0.380864
 >> iter 15000, loss: 0.246301
 >> iter 16000, loss: 0.323801
 >> iter 17000, loss: 0.368939
 >> iter 18000, loss: 0.290641
 >> iter 19000, loss: 0.228039
 >> iter 20000, loss: 0.392566
   Number of active neurons: 6
 >> iter 21000, loss: 0.495060
 >> iter 22000, loss: 0.258937
 >> iter 23000, loss: 0.450016
 >> iter 24000, loss: 0.442410
 >> iter 25000, loss: 0.370614
 >> iter 26000, loss: 0.250900
 >> iter 27000, loss: 0.303486
 >> iter 28000, loss: 0.314005
 >> iter 29000, loss: 0.288952
 >> iter 30000, loss: 0.312239
   Number of active neurons: 4
 >> iter 31000, loss: 0.209334
 >> iter 32000, loss: 0.237461
 >> iter 33000, loss: 0.140137
 >> iter 34000, loss: 0.098945
 >> iter 35000, loss: 0.089494
 >> iter 36000, loss: 0.173244
 >> iter 37000, loss: 0.264465
 >> iter 38000, loss: 0.282031
 >> iter 39000, loss: 0.145928
 >> iter 40000, loss: 0.293219
   Number of active neurons: 4
 >> iter 41000, loss: 0.236257
 >> iter 42000, loss: 0.216850
 >> iter 43000, loss: 0.210520
 >> iter 44000, loss: 0.173833
 >> iter 45000, loss: 0.171893
 >> iter 46000, loss: 0.135165
 >> iter 47000, loss: 0.123778
 >> iter 48000, loss: 0.350033
 >> iter 49000, loss: 0.339703
 >> iter 50000, loss: 0.269091
   Number of active neurons: 4
 >> iter 51000, loss: 0.175770
 >> iter 52000, loss: 0.326792
 >> iter 53000, loss: 0.370775
 >> iter 54000, loss: 0.329323
 >> iter 55000, loss: 0.233959
 >> iter 56000, loss: 0.179189
 >> iter 57000, loss: 0.184073
 >> iter 58000, loss: 0.120996
 >> iter 59000, loss: 0.094161
 >> iter 60000, loss: 0.111416
   Number of active neurons: 4
 >> iter 61000, loss: 0.215811
 >> iter 62000, loss: 0.402656
 >> iter 63000, loss: 0.399729
 >> iter 64000, loss: 0.324156
 >> iter 65000, loss: 0.230202
 >> iter 66000, loss: 0.152785
 >> iter 67000, loss: 0.148577
 >> iter 68000, loss: 0.256433
 >> iter 69000, loss: 0.387839
 >> iter 70000, loss: 0.425887
   Number of active neurons: 4
 >> iter 71000, loss: 0.252081
 >> iter 72000, loss: 0.299102
 >> iter 73000, loss: 0.216767
 >> iter 74000, loss: 0.203720
 >> iter 75000, loss: 0.193752
 >> iter 76000, loss: 0.298787
 >> iter 77000, loss: 0.303162
 >> iter 78000, loss: 0.346831
 >> iter 79000, loss: 0.308401
 >> iter 80000, loss: 0.299267
   Number of active neurons: 4
 >> iter 81000, loss: 0.285827
 >> iter 82000, loss: 0.257765
 >> iter 83000, loss: 0.172737
 >> iter 84000, loss: 0.136714
 >> iter 85000, loss: 0.215505
 >> iter 86000, loss: 0.184644
 >> iter 87000, loss: 0.290609
 >> iter 88000, loss: 0.265733
 >> iter 89000, loss: 0.204381
 >> iter 90000, loss: 0.324188
   Number of active neurons: 4
 >> iter 91000, loss: 0.326483
 >> iter 92000, loss: 0.189533
 >> iter 93000, loss: 0.317005
 >> iter 94000, loss: 0.363627
 >> iter 95000, loss: 0.255957
 >> iter 96000, loss: 0.190034
 >> iter 97000, loss: 0.191324
 >> iter 98000, loss: 0.191263
 >> iter 99000, loss: 0.327982
 >> iter 100000, loss: 0.476438
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.968402
 >> iter 2000, loss: 8.850408
 >> iter 3000, loss: 4.348345
 >> iter 4000, loss: 1.993382
 >> iter 5000, loss: 1.131509
 >> iter 6000, loss: 0.609960
 >> iter 7000, loss: 0.401732
 >> iter 8000, loss: 0.338291
 >> iter 9000, loss: 0.237191
 >> iter 10000, loss: 0.329148
   Number of active neurons: 5
 >> iter 11000, loss: 0.342443
 >> iter 12000, loss: 0.392097
 >> iter 13000, loss: 0.525116
 >> iter 14000, loss: 0.385775
 >> iter 15000, loss: 0.276945
 >> iter 16000, loss: 0.167008
 >> iter 17000, loss: 0.256785
 >> iter 18000, loss: 0.233748
 >> iter 19000, loss: 0.456644
 >> iter 20000, loss: 0.313452
   Number of active neurons: 5
 >> iter 21000, loss: 0.205176
 >> iter 22000, loss: 0.656923
 >> iter 23000, loss: 0.443731
 >> iter 24000, loss: 0.308086
 >> iter 25000, loss: 0.224797
 >> iter 26000, loss: 0.297009
 >> iter 27000, loss: 0.462801
 >> iter 28000, loss: 0.376386
 >> iter 29000, loss: 0.242908
 >> iter 30000, loss: 0.317380
   Number of active neurons: 5
 >> iter 31000, loss: 0.577918
 >> iter 32000, loss: 0.427574
 >> iter 33000, loss: 0.381990
 >> iter 34000, loss: 0.247887
 >> iter 35000, loss: 0.337995
 >> iter 36000, loss: 0.371653
 >> iter 37000, loss: 0.343737
 >> iter 38000, loss: 0.303891
 >> iter 39000, loss: 0.330349
 >> iter 40000, loss: 0.216504
   Number of active neurons: 4
 >> iter 41000, loss: 0.320876
 >> iter 42000, loss: 0.404733
 >> iter 43000, loss: 0.456057
 >> iter 44000, loss: 0.389444
 >> iter 45000, loss: 0.438997
 >> iter 46000, loss: 0.377235
 >> iter 47000, loss: 0.408970
 >> iter 48000, loss: 0.381665
 >> iter 49000, loss: 0.307688
 >> iter 50000, loss: 0.216036
   Number of active neurons: 4
 >> iter 51000, loss: 0.230921
 >> iter 52000, loss: 0.221510
 >> iter 53000, loss: 0.344131
 >> iter 54000, loss: 0.288608
 >> iter 55000, loss: 0.202350
 >> iter 56000, loss: 0.464682
 >> iter 57000, loss: 0.548085
 >> iter 58000, loss: 0.271230
 >> iter 59000, loss: 0.343711
 >> iter 60000, loss: 0.238986
   Number of active neurons: 3
 >> iter 61000, loss: 0.318163
 >> iter 62000, loss: 0.418239
 >> iter 63000, loss: 0.373555
 >> iter 64000, loss: 0.357769
 >> iter 65000, loss: 0.193429
 >> iter 66000, loss: 0.383500
 >> iter 67000, loss: 0.231398
 >> iter 68000, loss: 0.345898
 >> iter 69000, loss: 0.234113
 >> iter 70000, loss: 0.309187
   Number of active neurons: 3
 >> iter 71000, loss: 0.320047
 >> iter 72000, loss: 0.379205
 >> iter 73000, loss: 0.313627
 >> iter 74000, loss: 0.339323
 >> iter 75000, loss: 0.321565
 >> iter 76000, loss: 0.350805
 >> iter 77000, loss: 0.256346
 >> iter 78000, loss: 0.249813
 >> iter 79000, loss: 0.450111
 >> iter 80000, loss: 0.395381
   Number of active neurons: 3
 >> iter 81000, loss: 0.321833
 >> iter 82000, loss: 0.247587
 >> iter 83000, loss: 0.304275
 >> iter 84000, loss: 0.331147
 >> iter 85000, loss: 0.321184
 >> iter 86000, loss: 0.322961
 >> iter 87000, loss: 0.273106
 >> iter 88000, loss: 0.164594
 >> iter 89000, loss: 0.177675
 >> iter 90000, loss: 0.221074
   Number of active neurons: 3
 >> iter 91000, loss: 0.169303
 >> iter 92000, loss: 0.154359
 >> iter 93000, loss: 0.152553
 >> iter 94000, loss: 0.134444
 >> iter 95000, loss: 0.323823
 >> iter 96000, loss: 0.304117
 >> iter 97000, loss: 0.183328
 >> iter 98000, loss: 0.108007
 >> iter 99000, loss: 0.147282
 >> iter 100000, loss: 0.247910
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.956707
 >> iter 2000, loss: 9.422544
 >> iter 3000, loss: 4.493997
 >> iter 4000, loss: 2.089438
 >> iter 5000, loss: 1.439933
 >> iter 6000, loss: 0.870995
 >> iter 7000, loss: 0.832533
 >> iter 8000, loss: 0.830229
 >> iter 9000, loss: 0.898074
 >> iter 10000, loss: 0.711798
   Number of active neurons: 4
 >> iter 11000, loss: 0.437405
 >> iter 12000, loss: 0.513632
 >> iter 13000, loss: 0.605661
 >> iter 14000, loss: 0.377301
 >> iter 15000, loss: 0.463102
 >> iter 16000, loss: 0.471852
 >> iter 17000, loss: 0.473095
 >> iter 18000, loss: 0.444784
 >> iter 19000, loss: 0.434458
 >> iter 20000, loss: 0.743212
   Number of active neurons: 4
 >> iter 21000, loss: 0.647292
 >> iter 22000, loss: 0.501125
 >> iter 23000, loss: 0.434835
 >> iter 24000, loss: 0.487614
 >> iter 25000, loss: 0.515079
 >> iter 26000, loss: 0.295799
 >> iter 27000, loss: 0.342264
 >> iter 28000, loss: 0.798107
 >> iter 29000, loss: 0.753532
 >> iter 30000, loss: 0.584530
   Number of active neurons: 4
 >> iter 31000, loss: 0.693628
 >> iter 32000, loss: 0.398006
 >> iter 33000, loss: 0.352820
 >> iter 34000, loss: 0.475639
 >> iter 35000, loss: 0.372301
 >> iter 36000, loss: 0.505440
 >> iter 37000, loss: 0.512254
 >> iter 38000, loss: 0.667507
 >> iter 39000, loss: 0.513123
 >> iter 40000, loss: 0.481437
   Number of active neurons: 4
 >> iter 41000, loss: 0.459958
 >> iter 42000, loss: 0.350314
 >> iter 43000, loss: 0.491272
 >> iter 44000, loss: 0.420806
 >> iter 45000, loss: 0.451735
 >> iter 46000, loss: 0.354609
 >> iter 47000, loss: 0.436084
 >> iter 48000, loss: 0.604323
 >> iter 49000, loss: 0.433845
 >> iter 50000, loss: 0.586547
   Number of active neurons: 4
 >> iter 51000, loss: 0.400926
 >> iter 52000, loss: 0.772604
 >> iter 53000, loss: 0.586657
 >> iter 54000, loss: 0.437404
 >> iter 55000, loss: 0.318510
 >> iter 56000, loss: 0.467038
 >> iter 57000, loss: 0.301709
 >> iter 58000, loss: 0.498244
 >> iter 59000, loss: 0.577636
 >> iter 60000, loss: 0.488497
   Number of active neurons: 4
 >> iter 61000, loss: 0.554854
 >> iter 62000, loss: 0.480390
 >> iter 63000, loss: 0.391338
 >> iter 64000, loss: 0.476020
 >> iter 65000, loss: 0.285084
 >> iter 66000, loss: 0.471433
 >> iter 67000, loss: 0.567865
 >> iter 68000, loss: 0.452979
 >> iter 69000, loss: 0.464949
 >> iter 70000, loss: 0.582308
   Number of active neurons: 4
 >> iter 71000, loss: 0.602255
 >> iter 72000, loss: 0.497893
 >> iter 73000, loss: 0.623681
 >> iter 74000, loss: 0.412078
 >> iter 75000, loss: 0.424011
 >> iter 76000, loss: 0.556085
 >> iter 77000, loss: 0.576238
 >> iter 78000, loss: 0.635896
 >> iter 79000, loss: 0.460852
 >> iter 80000, loss: 0.336535
   Number of active neurons: 4
 >> iter 81000, loss: 0.326614
 >> iter 82000, loss: 0.363140
 >> iter 83000, loss: 0.587876
 >> iter 84000, loss: 0.720496
 >> iter 85000, loss: 0.449453
 >> iter 86000, loss: 0.447062
 >> iter 87000, loss: 0.382545
 >> iter 88000, loss: 0.435448
 >> iter 89000, loss: 0.289864
 >> iter 90000, loss: 0.352938
   Number of active neurons: 4
 >> iter 91000, loss: 0.342681
 >> iter 92000, loss: 0.414214
 >> iter 93000, loss: 0.357931
 >> iter 94000, loss: 0.577371
 >> iter 95000, loss: 0.438491
 >> iter 96000, loss: 0.454730
 >> iter 97000, loss: 0.464849
 >> iter 98000, loss: 0.648166
 >> iter 99000, loss: 0.574287
 >> iter 100000, loss: 0.541989
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.901317
 >> iter 2000, loss: 9.338307
 >> iter 3000, loss: 4.177634
 >> iter 4000, loss: 2.084311
 >> iter 5000, loss: 1.037289
 >> iter 6000, loss: 0.506637
 >> iter 7000, loss: 0.645207
 >> iter 8000, loss: 0.346149
 >> iter 9000, loss: 0.278514
 >> iter 10000, loss: 0.250565
   Number of active neurons: 5
 >> iter 11000, loss: 0.360891
 >> iter 12000, loss: 0.577375
 >> iter 13000, loss: 0.378226
 >> iter 14000, loss: 0.325430
 >> iter 15000, loss: 0.339040
 >> iter 16000, loss: 0.279366
 >> iter 17000, loss: 0.336667
 >> iter 18000, loss: 0.217335
 >> iter 19000, loss: 0.230825
 >> iter 20000, loss: 0.311631
   Number of active neurons: 5
 >> iter 21000, loss: 0.236522
 >> iter 22000, loss: 0.201183
 >> iter 23000, loss: 0.162010
 >> iter 24000, loss: 0.121857
 >> iter 25000, loss: 0.166265
 >> iter 26000, loss: 0.346877
 >> iter 27000, loss: 0.192843
 >> iter 28000, loss: 0.148164
 >> iter 29000, loss: 0.186448
 >> iter 30000, loss: 0.396386
   Number of active neurons: 4
 >> iter 31000, loss: 0.378489
 >> iter 32000, loss: 0.250813
 >> iter 33000, loss: 0.212580
 >> iter 34000, loss: 0.308242
 >> iter 35000, loss: 0.235648
 >> iter 36000, loss: 0.265224
 >> iter 37000, loss: 0.284415
 >> iter 38000, loss: 0.244166
 >> iter 39000, loss: 0.326273
 >> iter 40000, loss: 0.238779
   Number of active neurons: 3
 >> iter 41000, loss: 0.244607
 >> iter 42000, loss: 0.173320
 >> iter 43000, loss: 0.263731
 >> iter 44000, loss: 0.179396
 >> iter 45000, loss: 0.260514
 >> iter 46000, loss: 0.189484
 >> iter 47000, loss: 0.137594
 >> iter 48000, loss: 0.300681
 >> iter 49000, loss: 0.192353
 >> iter 50000, loss: 0.253402
   Number of active neurons: 3
 >> iter 51000, loss: 0.154003
 >> iter 52000, loss: 0.215674
 >> iter 53000, loss: 0.264122
 >> iter 54000, loss: 0.402564
 >> iter 55000, loss: 0.208369
 >> iter 56000, loss: 0.172732
 >> iter 57000, loss: 0.204645
 >> iter 58000, loss: 0.345710
 >> iter 59000, loss: 0.262727
 >> iter 60000, loss: 0.148055
   Number of active neurons: 3
 >> iter 61000, loss: 0.093739
 >> iter 62000, loss: 0.156578
 >> iter 63000, loss: 0.359016
 >> iter 64000, loss: 0.165465
 >> iter 65000, loss: 0.207494
 >> iter 66000, loss: 0.439899
 >> iter 67000, loss: 0.488507
 >> iter 68000, loss: 0.321541
 >> iter 69000, loss: 0.147766
 >> iter 70000, loss: 0.327622
   Number of active neurons: 3
 >> iter 71000, loss: 0.295339
 >> iter 72000, loss: 0.210602
 >> iter 73000, loss: 0.260747
 >> iter 74000, loss: 0.288585
 >> iter 75000, loss: 0.198234
 >> iter 76000, loss: 0.467919
 >> iter 77000, loss: 0.219625
 >> iter 78000, loss: 0.148305
 >> iter 79000, loss: 0.226579
 >> iter 80000, loss: 0.247418
   Number of active neurons: 3
 >> iter 81000, loss: 0.160885
 >> iter 82000, loss: 0.278493
 >> iter 83000, loss: 0.133505
 >> iter 84000, loss: 0.145398
 >> iter 85000, loss: 0.226975
 >> iter 86000, loss: 0.282574
 >> iter 87000, loss: 0.439255
 >> iter 88000, loss: 0.349607
 >> iter 89000, loss: 0.392160
 >> iter 90000, loss: 0.289921
   Number of active neurons: 3
 >> iter 91000, loss: 0.314381
 >> iter 92000, loss: 0.364654
 >> iter 93000, loss: 0.291521
 >> iter 94000, loss: 0.248639
 >> iter 95000, loss: 0.155316
 >> iter 96000, loss: 0.266360
 >> iter 97000, loss: 0.325573
 >> iter 98000, loss: 0.226068
 >> iter 99000, loss: 0.349447
 >> iter 100000, loss: 0.201736
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.203644
 >> iter 2000, loss: 10.352768
 >> iter 3000, loss: 5.242253
 >> iter 4000, loss: 2.446076
 >> iter 5000, loss: 1.263438
 >> iter 6000, loss: 1.013195
 >> iter 7000, loss: 0.686027
 >> iter 8000, loss: 0.538229
 >> iter 9000, loss: 0.373556
 >> iter 10000, loss: 0.560740
   Number of active neurons: 8
 >> iter 11000, loss: 0.490072
 >> iter 12000, loss: 0.365460
 >> iter 13000, loss: 0.423551
 >> iter 14000, loss: 0.520310
 >> iter 15000, loss: 0.390928
 >> iter 16000, loss: 0.591390
 >> iter 17000, loss: 0.292843
 >> iter 18000, loss: 0.295212
 >> iter 19000, loss: 0.478972
 >> iter 20000, loss: 0.232345
   Number of active neurons: 6
 >> iter 21000, loss: 0.298140
 >> iter 22000, loss: 0.257398
 >> iter 23000, loss: 0.347367
 >> iter 24000, loss: 0.497178
 >> iter 25000, loss: 0.402747
 >> iter 26000, loss: 0.555635
 >> iter 27000, loss: 0.414253
 >> iter 28000, loss: 0.246320
 >> iter 29000, loss: 0.293259
 >> iter 30000, loss: 0.266327
   Number of active neurons: 5
 >> iter 31000, loss: 0.222670
 >> iter 32000, loss: 0.212035
 >> iter 33000, loss: 0.213662
 >> iter 34000, loss: 0.180316
 >> iter 35000, loss: 0.295419
 >> iter 36000, loss: 0.247603
 >> iter 37000, loss: 0.188276
 >> iter 38000, loss: 0.316253
 >> iter 39000, loss: 0.249136
 >> iter 40000, loss: 0.116488
   Number of active neurons: 3
 >> iter 41000, loss: 0.222124
 >> iter 42000, loss: 0.336113
 >> iter 43000, loss: 0.285077
 >> iter 44000, loss: 0.258854
 >> iter 45000, loss: 0.531647
 >> iter 46000, loss: 0.345592
 >> iter 47000, loss: 0.424987
 >> iter 48000, loss: 0.289962
 >> iter 49000, loss: 0.242398
 >> iter 50000, loss: 0.214762
   Number of active neurons: 3
 >> iter 51000, loss: 0.422442
 >> iter 52000, loss: 0.211327
 >> iter 53000, loss: 0.214009
 >> iter 54000, loss: 0.218480
 >> iter 55000, loss: 0.199638
 >> iter 56000, loss: 0.184440
 >> iter 57000, loss: 0.306051
 >> iter 58000, loss: 0.208840
 >> iter 59000, loss: 0.153357
 >> iter 60000, loss: 0.248197
   Number of active neurons: 3
 >> iter 61000, loss: 0.364364
 >> iter 62000, loss: 0.258970
 >> iter 63000, loss: 0.301917
 >> iter 64000, loss: 0.199995
 >> iter 65000, loss: 0.255771
 >> iter 66000, loss: 0.361484
 >> iter 67000, loss: 0.319340
 >> iter 68000, loss: 0.241299
 >> iter 69000, loss: 0.153737
 >> iter 70000, loss: 0.212630
   Number of active neurons: 3
 >> iter 71000, loss: 0.333941
 >> iter 72000, loss: 0.213457
 >> iter 73000, loss: 0.133677
 >> iter 74000, loss: 0.422159
 >> iter 75000, loss: 0.384085
 >> iter 76000, loss: 0.275046
 >> iter 77000, loss: 0.346962
 >> iter 78000, loss: 0.232622
 >> iter 79000, loss: 0.216399
 >> iter 80000, loss: 0.174310
   Number of active neurons: 3
 >> iter 81000, loss: 0.198418
 >> iter 82000, loss: 0.327172
 >> iter 83000, loss: 0.242092
 >> iter 84000, loss: 0.168403
 >> iter 85000, loss: 0.414369
 >> iter 86000, loss: 0.409695
 >> iter 87000, loss: 0.257450
 >> iter 88000, loss: 0.124091
 >> iter 89000, loss: 0.268061
 >> iter 90000, loss: 0.164056
   Number of active neurons: 3
 >> iter 91000, loss: 0.160599
 >> iter 92000, loss: 0.086417
 >> iter 93000, loss: 0.244687
 >> iter 94000, loss: 0.172311
 >> iter 95000, loss: 0.231995
 >> iter 96000, loss: 0.164229
 >> iter 97000, loss: 0.128552
 >> iter 98000, loss: 0.145040
 >> iter 99000, loss: 0.250083
 >> iter 100000, loss: 0.360848
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.791171
 >> iter 2000, loss: 9.475124
 >> iter 3000, loss: 4.177289
 >> iter 4000, loss: 2.080775
 >> iter 5000, loss: 1.083155
 >> iter 6000, loss: 0.793408
 >> iter 7000, loss: 0.488191
 >> iter 8000, loss: 0.293957
 >> iter 9000, loss: 0.404916
 >> iter 10000, loss: 0.392014
   Number of active neurons: 7
 >> iter 11000, loss: 0.420108
 >> iter 12000, loss: 0.381473
 >> iter 13000, loss: 0.237843
 >> iter 14000, loss: 0.352307
 >> iter 15000, loss: 0.251480
 >> iter 16000, loss: 0.332547
 >> iter 17000, loss: 0.407352
 >> iter 18000, loss: 0.352682
 >> iter 19000, loss: 0.525806
 >> iter 20000, loss: 0.313984
   Number of active neurons: 6
 >> iter 21000, loss: 0.301642
 >> iter 22000, loss: 0.218184
 >> iter 23000, loss: 0.234332
 >> iter 24000, loss: 0.426708
 >> iter 25000, loss: 0.380400
 >> iter 26000, loss: 0.321153
 >> iter 27000, loss: 0.525981
 >> iter 28000, loss: 0.365861
 >> iter 29000, loss: 0.369094
 >> iter 30000, loss: 0.317044
   Number of active neurons: 6
 >> iter 31000, loss: 0.238564
 >> iter 32000, loss: 0.218126
 >> iter 33000, loss: 0.392758
 >> iter 34000, loss: 0.212318
 >> iter 35000, loss: 0.271762
 >> iter 36000, loss: 0.381941
 >> iter 37000, loss: 0.378460
 >> iter 38000, loss: 0.254729
 >> iter 39000, loss: 0.315856
 >> iter 40000, loss: 0.357239
   Number of active neurons: 3
 >> iter 41000, loss: 0.394393
 >> iter 42000, loss: 0.298760
 >> iter 43000, loss: 0.318515
 >> iter 44000, loss: 0.389869
 >> iter 45000, loss: 0.327868
 >> iter 46000, loss: 0.238438
 >> iter 47000, loss: 0.312991
 >> iter 48000, loss: 0.334444
 >> iter 49000, loss: 0.245998
 >> iter 50000, loss: 0.346841
   Number of active neurons: 3
 >> iter 51000, loss: 0.241507
 >> iter 52000, loss: 0.258316
 >> iter 53000, loss: 0.270219
 >> iter 54000, loss: 0.290216
 >> iter 55000, loss: 0.352062
 >> iter 56000, loss: 0.236718
 >> iter 57000, loss: 0.198295
 >> iter 58000, loss: 0.307833
 >> iter 59000, loss: 0.184435
 >> iter 60000, loss: 0.125175
   Number of active neurons: 3
 >> iter 61000, loss: 0.342175
 >> iter 62000, loss: 0.305610
 >> iter 63000, loss: 0.228953
 >> iter 64000, loss: 0.254663
 >> iter 65000, loss: 0.130643
 >> iter 66000, loss: 0.136282
 >> iter 67000, loss: 0.107254
 >> iter 68000, loss: 0.259596
 >> iter 69000, loss: 0.224878
 >> iter 70000, loss: 0.234796
   Number of active neurons: 3
 >> iter 71000, loss: 0.240888
 >> iter 72000, loss: 0.138827
 >> iter 73000, loss: 0.267695
 >> iter 74000, loss: 0.332769
 >> iter 75000, loss: 0.340818
 >> iter 76000, loss: 0.253598
 >> iter 77000, loss: 0.206468
 >> iter 78000, loss: 0.259604
 >> iter 79000, loss: 0.227689
 >> iter 80000, loss: 0.202613
   Number of active neurons: 3
 >> iter 81000, loss: 0.112518
 >> iter 82000, loss: 0.196998
 >> iter 83000, loss: 0.277605
 >> iter 84000, loss: 0.180509
 >> iter 85000, loss: 0.250091
 >> iter 86000, loss: 0.384245
 >> iter 87000, loss: 0.271513
 >> iter 88000, loss: 0.290055
 >> iter 89000, loss: 0.197134
 >> iter 90000, loss: 0.168322
   Number of active neurons: 3
 >> iter 91000, loss: 0.104274
 >> iter 92000, loss: 0.346831
 >> iter 93000, loss: 0.205029
 >> iter 94000, loss: 0.301453
 >> iter 95000, loss: 0.388077
 >> iter 96000, loss: 0.377388
 >> iter 97000, loss: 0.308366
 >> iter 98000, loss: 0.307701
 >> iter 99000, loss: 0.362968
 >> iter 100000, loss: 0.199221
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.878504
 >> iter 2000, loss: 10.871263
 >> iter 3000, loss: 5.914198
 >> iter 4000, loss: 2.609740
 >> iter 5000, loss: 1.331993
 >> iter 6000, loss: 0.700791
 >> iter 7000, loss: 0.559018
 >> iter 8000, loss: 0.641327
 >> iter 9000, loss: 0.351169
 >> iter 10000, loss: 0.506344
   Number of active neurons: 6
 >> iter 11000, loss: 0.290376
 >> iter 12000, loss: 0.437985
 >> iter 13000, loss: 0.267590
 >> iter 14000, loss: 0.409111
 >> iter 15000, loss: 0.398903
 >> iter 16000, loss: 0.371257
 >> iter 17000, loss: 0.287995
 >> iter 18000, loss: 0.306400
 >> iter 19000, loss: 0.310984
 >> iter 20000, loss: 0.306038
   Number of active neurons: 5
 >> iter 21000, loss: 0.368101
 >> iter 22000, loss: 0.461839
 >> iter 23000, loss: 0.246680
 >> iter 24000, loss: 0.293538
 >> iter 25000, loss: 0.359691
 >> iter 26000, loss: 0.439693
 >> iter 27000, loss: 0.250328
 >> iter 28000, loss: 0.218423
 >> iter 29000, loss: 0.215288
 >> iter 30000, loss: 0.230331
   Number of active neurons: 3
 >> iter 31000, loss: 0.176455
 >> iter 32000, loss: 0.423392
 >> iter 33000, loss: 0.271655
 >> iter 34000, loss: 0.289367
 >> iter 35000, loss: 0.175123
 >> iter 36000, loss: 0.216272
 >> iter 37000, loss: 0.225645
 >> iter 38000, loss: 0.216081
 >> iter 39000, loss: 0.222805
 >> iter 40000, loss: 0.161578
   Number of active neurons: 3
 >> iter 41000, loss: 0.132397
 >> iter 42000, loss: 0.119770
 >> iter 43000, loss: 0.481343
 >> iter 44000, loss: 0.327721
 >> iter 45000, loss: 0.301827
 >> iter 46000, loss: 0.246594
 >> iter 47000, loss: 0.382522
 >> iter 48000, loss: 0.439196
 >> iter 49000, loss: 0.372678
 >> iter 50000, loss: 0.235751
   Number of active neurons: 3
 >> iter 51000, loss: 0.216491
 >> iter 52000, loss: 0.224867
 >> iter 53000, loss: 0.170284
 >> iter 54000, loss: 0.392225
 >> iter 55000, loss: 0.369444
 >> iter 56000, loss: 0.259786
 >> iter 57000, loss: 0.189051
 >> iter 58000, loss: 0.105698
 >> iter 59000, loss: 0.163522
 >> iter 60000, loss: 0.254837
   Number of active neurons: 3
 >> iter 61000, loss: 0.124805
 >> iter 62000, loss: 0.240981
 >> iter 63000, loss: 0.319494
 >> iter 64000, loss: 0.184740
 >> iter 65000, loss: 0.408620
 >> iter 66000, loss: 0.473406
 >> iter 67000, loss: 0.252786
 >> iter 68000, loss: 0.384358
 >> iter 69000, loss: 0.446762
 >> iter 70000, loss: 0.266051
   Number of active neurons: 3
 >> iter 71000, loss: 0.239996
 >> iter 72000, loss: 0.217669
 >> iter 73000, loss: 0.230359
 >> iter 74000, loss: 0.301314
 >> iter 75000, loss: 0.203714
 >> iter 76000, loss: 0.186784
 >> iter 77000, loss: 0.191973
 >> iter 78000, loss: 0.257044
 >> iter 79000, loss: 0.199261
 >> iter 80000, loss: 0.178640
   Number of active neurons: 3
 >> iter 81000, loss: 0.298769
 >> iter 82000, loss: 0.252564
 >> iter 83000, loss: 0.293304
 >> iter 84000, loss: 0.223607
 >> iter 85000, loss: 0.180553
 >> iter 86000, loss: 0.202118
 >> iter 87000, loss: 0.151900
 >> iter 88000, loss: 0.197472
 >> iter 89000, loss: 0.278064
 >> iter 90000, loss: 0.314619
   Number of active neurons: 3
 >> iter 91000, loss: 0.316417
 >> iter 92000, loss: 0.261681
 >> iter 93000, loss: 0.316647
 >> iter 94000, loss: 0.331909
 >> iter 95000, loss: 0.375396
 >> iter 96000, loss: 0.255246
 >> iter 97000, loss: 0.380030
 >> iter 98000, loss: 0.205965
 >> iter 99000, loss: 0.202446
 >> iter 100000, loss: 0.141922
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

