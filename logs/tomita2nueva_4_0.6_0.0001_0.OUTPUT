 > Problema: tomita2nueva
 > Args:
   - Hidden size: 4
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.475322
 >> iter 2000, loss: 4.411024
 >> iter 3000, loss: 1.723461
 >> iter 4000, loss: 0.682087
 >> iter 5000, loss: 0.306328
 >> iter 6000, loss: 0.151063
 >> iter 7000, loss: 0.079981
 >> iter 8000, loss: 0.076398
 >> iter 9000, loss: 0.062908
 >> iter 10000, loss: 0.045033
   Number of active neurons: 4
 >> iter 11000, loss: 0.044309
 >> iter 12000, loss: 0.061170
 >> iter 13000, loss: 0.057569
 >> iter 14000, loss: 0.073190
 >> iter 15000, loss: 0.062020
 >> iter 16000, loss: 0.057855
 >> iter 17000, loss: 0.046319
 >> iter 18000, loss: 0.046314
 >> iter 19000, loss: 0.057198
 >> iter 20000, loss: 0.060572
   Number of active neurons: 4
 >> iter 21000, loss: 0.053915
 >> iter 22000, loss: 0.041489
 >> iter 23000, loss: 0.070143
 >> iter 24000, loss: 0.049136
 >> iter 25000, loss: 0.038870
 >> iter 26000, loss: 0.035531
 >> iter 27000, loss: 0.039445
 >> iter 28000, loss: 0.046620
 >> iter 29000, loss: 0.056140
 >> iter 30000, loss: 0.050633
   Number of active neurons: 4
 >> iter 31000, loss: 0.043550
 >> iter 32000, loss: 0.060647
 >> iter 33000, loss: 0.072753
 >> iter 34000, loss: 0.050024
 >> iter 35000, loss: 0.045466
 >> iter 36000, loss: 0.039198
 >> iter 37000, loss: 0.048133
 >> iter 38000, loss: 0.061783
 >> iter 39000, loss: 0.059763
 >> iter 40000, loss: 0.083116
   Number of active neurons: 4
 >> iter 41000, loss: 0.056828
 >> iter 42000, loss: 0.049149
 >> iter 43000, loss: 0.057583
 >> iter 44000, loss: 0.058343
 >> iter 45000, loss: 0.061249
 >> iter 46000, loss: 0.053054
 >> iter 47000, loss: 0.054174
 >> iter 48000, loss: 0.065811
 >> iter 49000, loss: 0.053179
 >> iter 50000, loss: 0.051419
   Number of active neurons: 4
 >> iter 51000, loss: 0.057002
 >> iter 52000, loss: 0.060363
 >> iter 53000, loss: 0.062636
 >> iter 54000, loss: 0.050074
 >> iter 55000, loss: 0.037604
 >> iter 56000, loss: 0.055111
 >> iter 57000, loss: 0.041500
 >> iter 58000, loss: 0.052398
 >> iter 59000, loss: 0.069135
 >> iter 60000, loss: 0.069415
   Number of active neurons: 3
 >> iter 61000, loss: 0.047077
 >> iter 62000, loss: 0.056594
 >> iter 63000, loss: 0.058071
 >> iter 64000, loss: 0.069595
 >> iter 65000, loss: 0.067164
 >> iter 66000, loss: 0.065408
 >> iter 67000, loss: 0.076408
 >> iter 68000, loss: 0.060997
 >> iter 69000, loss: 0.050447
 >> iter 70000, loss: 0.041289
   Number of active neurons: 3
 >> iter 71000, loss: 0.062714
 >> iter 72000, loss: 0.092696
 >> iter 73000, loss: 0.074976
 >> iter 74000, loss: 0.057416
 >> iter 75000, loss: 0.041344
 >> iter 76000, loss: 0.045244
 >> iter 77000, loss: 0.040818
 >> iter 78000, loss: 0.031872
 >> iter 79000, loss: 0.043701
 >> iter 80000, loss: 0.080686
   Number of active neurons: 3
 >> iter 81000, loss: 0.067912
 >> iter 82000, loss: 0.052668
 >> iter 83000, loss: 0.077063
 >> iter 84000, loss: 0.057099
 >> iter 85000, loss: 0.070166
 >> iter 86000, loss: 0.050592
 >> iter 87000, loss: 0.051295
 >> iter 88000, loss: 0.037449
 >> iter 89000, loss: 0.039290
 >> iter 90000, loss: 0.032866
   Number of active neurons: 3
 >> iter 91000, loss: 0.040777
 >> iter 92000, loss: 0.038556
 >> iter 93000, loss: 0.035339
 >> iter 94000, loss: 0.029009
 >> iter 95000, loss: 0.037454
 >> iter 96000, loss: 0.050071
 >> iter 97000, loss: 0.041032
 >> iter 98000, loss: 0.044713
 >> iter 99000, loss: 0.035968
 >> iter 100000, loss: 0.042536
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 12.043038
 >> iter 2000, loss: 5.713151
 >> iter 3000, loss: 3.459145
 >> iter 4000, loss: 2.524927
 >> iter 5000, loss: 2.248504
 >> iter 6000, loss: 2.071700
 >> iter 7000, loss: 2.073406
 >> iter 8000, loss: 1.990378
 >> iter 9000, loss: 2.051514
 >> iter 10000, loss: 1.975074
   Number of active neurons: 2
 >> iter 11000, loss: 2.049660
 >> iter 12000, loss: 1.970118
 >> iter 13000, loss: 2.032490
 >> iter 14000, loss: 1.974194
 >> iter 15000, loss: 2.028195
   Number of active neurons: 2
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 1.963528
 >> iter 17000, loss: 2.004896
 >> iter 18000, loss: 1.928279
 >> iter 19000, loss: 2.006231
 >> iter 20000, loss: 1.931103
   Number of active neurons: 2
 >> iter 21000, loss: 1.986606
 >> iter 22000, loss: 1.918476
 >> iter 23000, loss: 1.971149
 >> iter 24000, loss: 1.920698
 >> iter 25000, loss: 1.987694
   Number of active neurons: 2
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 26000, loss: 1.931592
 >> iter 27000, loss: 1.989568
 >> iter 28000, loss: 1.935955
 >> iter 29000, loss: 2.002281
 >> iter 30000, loss: 1.932174
   Number of active neurons: 2
 >> iter 31000, loss: 1.989804
 >> iter 32000, loss: 1.937083
 >> iter 33000, loss: 1.983433
 >> iter 34000, loss: 1.925310
 >> iter 35000, loss: 1.992347
   Number of active neurons: 2
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 36000, loss: 1.944204
 >> iter 37000, loss: 2.014147
 >> iter 38000, loss: 1.950766
 >> iter 39000, loss: 1.985662
 >> iter 40000, loss: 1.937808
   Number of active neurons: 2
 >> iter 41000, loss: 1.987919
 >> iter 42000, loss: 1.934929
 >> iter 43000, loss: 1.973926
 >> iter 44000, loss: 1.933281
 >> iter 45000, loss: 1.991287
   Number of active neurons: 2
   SHOCK
   Setting new limit to 287500.0 iters...
 >> iter 46000, loss: 1.929308
 >> iter 47000, loss: 1.978878
 >> iter 48000, loss: 1.928288
 >> iter 49000, loss: 1.991618
 >> iter 50000, loss: 1.923149
   Number of active neurons: 2
 >> iter 51000, loss: 1.985083
 >> iter 52000, loss: 1.921021
 >> iter 53000, loss: 1.972908
 >> iter 54000, loss: 1.918037
 >> iter 55000, loss: 1.971397
   Number of active neurons: 2
   SHOCK
   Setting new limit to 293750.0 iters...
 >> iter 56000, loss: 1.921254
 >> iter 57000, loss: 1.961820
 >> iter 58000, loss: 1.926258
 >> iter 59000, loss: 1.977677
 >> iter 60000, loss: 1.923855
   Number of active neurons: 2
 >> iter 61000, loss: 1.988720
 >> iter 62000, loss: 1.931723
 >> iter 63000, loss: 1.984033
 >> iter 64000, loss: 1.913211
 >> iter 65000, loss: 1.968795
   Number of active neurons: 2
   SHOCK
   Setting new limit to 296875.0 iters...
 >> iter 66000, loss: 1.905075
 >> iter 67000, loss: 1.970962
 >> iter 68000, loss: 1.921130
 >> iter 69000, loss: 1.965879
 >> iter 70000, loss: 1.926976
   Number of active neurons: 2
 >> iter 71000, loss: 1.978366
 >> iter 72000, loss: 1.932137
 >> iter 73000, loss: 1.979041
 >> iter 74000, loss: 1.916518
 >> iter 75000, loss: 1.962567
   Number of active neurons: 2
   SHOCK
   Setting new limit to 298437.5 iters...
 >> iter 76000, loss: 1.908503
 >> iter 77000, loss: 1.981381
 >> iter 78000, loss: 1.940050
 >> iter 79000, loss: 1.973348
 >> iter 80000, loss: 1.929651
   Number of active neurons: 2
 >> iter 81000, loss: 1.958672
 >> iter 82000, loss: 1.900769
 >> iter 83000, loss: 1.947679
 >> iter 84000, loss: 1.914183
 >> iter 85000, loss: 1.967931
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299218.75 iters...
 >> iter 86000, loss: 1.928785
 >> iter 87000, loss: 1.943159
 >> iter 88000, loss: 1.904012
 >> iter 89000, loss: 1.957124
 >> iter 90000, loss: 1.904831
   Number of active neurons: 2
 >> iter 91000, loss: 1.968259
 >> iter 92000, loss: 1.908379
 >> iter 93000, loss: 1.944266
 >> iter 94000, loss: 1.903806
 >> iter 95000, loss: 1.960701
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299609.375 iters...
 >> iter 96000, loss: 1.912828
 >> iter 97000, loss: 1.938798
 >> iter 98000, loss: 1.898949
 >> iter 99000, loss: 1.924386
 >> iter 100000, loss: 1.906068
   Number of active neurons: 2
 >> iter 101000, loss: 1.949694
 >> iter 102000, loss: 1.912084
 >> iter 103000, loss: 1.965898
 >> iter 104000, loss: 1.916801
 >> iter 105000, loss: 1.958407
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299804.6875 iters...
 >> iter 106000, loss: 1.929442
 >> iter 107000, loss: 1.973210
 >> iter 108000, loss: 1.906404
 >> iter 109000, loss: 1.952343
 >> iter 110000, loss: 1.899522
   Number of active neurons: 2
 >> iter 111000, loss: 1.946974
 >> iter 112000, loss: 1.906371
 >> iter 113000, loss: 1.953149
 >> iter 114000, loss: 1.899129
 >> iter 115000, loss: 1.894459
 >> iter 116000, loss: 1.873240
 >> iter 117000, loss: 1.930085
 >> iter 118000, loss: 1.892053
 >> iter 119000, loss: 1.960775
 >> iter 120000, loss: 1.892444
   Number of active neurons: 2
 >> iter 121000, loss: 1.954398
 >> iter 122000, loss: 1.902841
 >> iter 123000, loss: 1.933467
 >> iter 124000, loss: 1.880276
 >> iter 125000, loss: 1.916750
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299902.34375 iters...
 >> iter 126000, loss: 1.884590
 >> iter 127000, loss: 1.957446
 >> iter 128000, loss: 1.896340
 >> iter 129000, loss: 1.953480
 >> iter 130000, loss: 1.893343
   Number of active neurons: 2
 >> iter 131000, loss: 1.951372
 >> iter 132000, loss: 1.899343
 >> iter 133000, loss: 1.948305
 >> iter 134000, loss: 1.898987
 >> iter 135000, loss: 1.944921
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299951.171875 iters...
 >> iter 136000, loss: 1.913244
 >> iter 137000, loss: 1.957044
 >> iter 138000, loss: 1.905626
 >> iter 139000, loss: 1.941132
 >> iter 140000, loss: 1.887750
   Number of active neurons: 2
 >> iter 141000, loss: 1.939406
 >> iter 142000, loss: 1.904289
 >> iter 143000, loss: 1.942184
 >> iter 144000, loss: 1.911153
 >> iter 145000, loss: 1.942249
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299975.585938 iters...
 >> iter 146000, loss: 1.903120
 >> iter 147000, loss: 1.948741
 >> iter 148000, loss: 1.904322
 >> iter 149000, loss: 1.945575
 >> iter 150000, loss: 1.892020
   Number of active neurons: 2
 >> iter 151000, loss: 1.952174
 >> iter 152000, loss: 1.905582
 >> iter 153000, loss: 1.967529
 >> iter 154000, loss: 1.903145
 >> iter 155000, loss: 1.975320
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299987.792969 iters...
 >> iter 156000, loss: 1.905220
 >> iter 157000, loss: 1.963997
 >> iter 158000, loss: 1.917926
 >> iter 159000, loss: 1.972557
 >> iter 160000, loss: 1.908151
   Number of active neurons: 2
 >> iter 161000, loss: 1.943803
 >> iter 162000, loss: 1.907102
 >> iter 163000, loss: 1.952320
 >> iter 164000, loss: 1.878027
 >> iter 165000, loss: 1.950376
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299993.896484 iters...
 >> iter 166000, loss: 1.886998
 >> iter 167000, loss: 1.963959
 >> iter 168000, loss: 1.911400
 >> iter 169000, loss: 1.970022
 >> iter 170000, loss: 1.887937
   Number of active neurons: 2
 >> iter 171000, loss: 1.948622
 >> iter 172000, loss: 1.904321
 >> iter 173000, loss: 1.962196
 >> iter 174000, loss: 1.904521
 >> iter 175000, loss: 1.950059
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299996.948242 iters...
 >> iter 176000, loss: 1.898841
 >> iter 177000, loss: 1.950389
 >> iter 178000, loss: 1.897084
 >> iter 179000, loss: 1.952326
 >> iter 180000, loss: 1.900910
   Number of active neurons: 2
 >> iter 181000, loss: 1.953773
 >> iter 182000, loss: 1.900945
 >> iter 183000, loss: 1.960754
 >> iter 184000, loss: 1.897522
 >> iter 185000, loss: 1.958623
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299998.474121 iters...
 >> iter 186000, loss: 1.910937
 >> iter 187000, loss: 1.955681
 >> iter 188000, loss: 1.895398
 >> iter 189000, loss: 1.942322
 >> iter 190000, loss: 1.912954
   Number of active neurons: 2
 >> iter 191000, loss: 1.940751
 >> iter 192000, loss: 1.894236
 >> iter 193000, loss: 1.961136
 >> iter 194000, loss: 1.896730
 >> iter 195000, loss: 1.955222
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299999.237061 iters...
 >> iter 196000, loss: 1.911969
 >> iter 197000, loss: 1.943904
 >> iter 198000, loss: 1.902707
 >> iter 199000, loss: 1.960967
 >> iter 200000, loss: 1.913693
   Number of active neurons: 2
 >> iter 201000, loss: 1.950020
 >> iter 202000, loss: 1.902868
 >> iter 203000, loss: 1.959161
 >> iter 204000, loss: 1.899212
 >> iter 205000, loss: 1.953168
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299999.61853 iters...
 >> iter 206000, loss: 1.908309
 >> iter 207000, loss: 1.964098
 >> iter 208000, loss: 1.912210
 >> iter 209000, loss: 1.975235
 >> iter 210000, loss: 1.902414
   Number of active neurons: 2
 >> iter 211000, loss: 1.935714
 >> iter 212000, loss: 1.883864
 >> iter 213000, loss: 1.946818
 >> iter 214000, loss: 1.905097
 >> iter 215000, loss: 1.962187
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299999.809265 iters...
 >> iter 216000, loss: 1.921834
 >> iter 217000, loss: 1.926529
 >> iter 218000, loss: 1.891716
 >> iter 219000, loss: 1.966005
 >> iter 220000, loss: 1.917016
   Number of active neurons: 2
 >> iter 221000, loss: 1.951545
 >> iter 222000, loss: 1.909174
 >> iter 223000, loss: 1.958414
 >> iter 224000, loss: 1.898617
 >> iter 225000, loss: 1.964466
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299999.904633 iters...
 >> iter 226000, loss: 1.913866
 >> iter 227000, loss: 1.954250
 >> iter 228000, loss: 1.884145
 >> iter 229000, loss: 1.939277
 >> iter 230000, loss: 1.894650
   Number of active neurons: 2
 >> iter 231000, loss: 1.944948
 >> iter 232000, loss: 1.870651
 >> iter 233000, loss: 1.945534
 >> iter 234000, loss: 1.902536
 >> iter 235000, loss: 1.958983
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299999.952316 iters...
 >> iter 236000, loss: 1.900818
 >> iter 237000, loss: 1.965174
 >> iter 238000, loss: 1.899925
 >> iter 239000, loss: 1.945682
 >> iter 240000, loss: 1.885496
   Number of active neurons: 2
 >> iter 241000, loss: 1.946804
 >> iter 242000, loss: 1.914226
 >> iter 243000, loss: 1.951908
 >> iter 244000, loss: 1.888124
 >> iter 245000, loss: 1.943916
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299999.976158 iters...
 >> iter 246000, loss: 1.899115
 >> iter 247000, loss: 1.950967
 >> iter 248000, loss: 1.887026
 >> iter 249000, loss: 1.949352
 >> iter 250000, loss: 1.876265
   Number of active neurons: 2
 >> iter 251000, loss: 1.952992
 >> iter 252000, loss: 1.896081
 >> iter 253000, loss: 1.949979
 >> iter 254000, loss: 1.886123
 >> iter 255000, loss: 1.931592
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299999.988079 iters...
 >> iter 256000, loss: 1.882303
 >> iter 257000, loss: 1.948009
 >> iter 258000, loss: 1.885230
 >> iter 259000, loss: 1.948642
 >> iter 260000, loss: 1.888173
   Number of active neurons: 2
 >> iter 261000, loss: 1.961868
 >> iter 262000, loss: 1.903524
 >> iter 263000, loss: 1.959735
 >> iter 264000, loss: 1.885857
 >> iter 265000, loss: 1.952881
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299999.99404 iters...
 >> iter 266000, loss: 1.912186
 >> iter 267000, loss: 1.931106
 >> iter 268000, loss: 1.897227
 >> iter 269000, loss: 1.959332
 >> iter 270000, loss: 1.893913
   Number of active neurons: 2
 >> iter 271000, loss: 1.948900
 >> iter 272000, loss: 1.906645
 >> iter 273000, loss: 1.950450
 >> iter 274000, loss: 1.872638
 >> iter 275000, loss: 1.947682
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299999.99702 iters...
 >> iter 276000, loss: 1.883856
 >> iter 277000, loss: 1.960511
 >> iter 278000, loss: 1.890099
 >> iter 279000, loss: 1.939145
 >> iter 280000, loss: 1.888614
   Number of active neurons: 2
 >> iter 281000, loss: 1.957964
 >> iter 282000, loss: 1.888019
 >> iter 283000, loss: 1.951377
 >> iter 284000, loss: 1.892559
 >> iter 285000, loss: 1.946942
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299999.99851 iters...
 >> iter 286000, loss: 1.889686
 >> iter 287000, loss: 1.959102
 >> iter 288000, loss: 1.889356
 >> iter 289000, loss: 1.954552
 >> iter 290000, loss: 1.878493
   Number of active neurons: 2
 >> iter 291000, loss: 1.935002
 >> iter 292000, loss: 1.884369
 >> iter 293000, loss: 1.944665
 >> iter 294000, loss: 1.891140
 >> iter 295000, loss: 1.963194
   Number of active neurons: 2
   SHOCK
   Setting new limit to 299999.999255 iters...
 >> iter 296000, loss: 1.881973
 >> iter 297000, loss: 1.951926
 >> iter 298000, loss: 1.889341
 >> iter 299000, loss: 1.961049
 >> iter 300000, loss: 1.880661
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.339256
 >> iter 2000, loss: 4.351104
 >> iter 3000, loss: 1.687352
 >> iter 4000, loss: 0.669058
 >> iter 5000, loss: 0.293311
 >> iter 6000, loss: 0.156574
 >> iter 7000, loss: 0.081987
 >> iter 8000, loss: 0.060586
 >> iter 9000, loss: 0.070978
 >> iter 10000, loss: 0.069488
   Number of active neurons: 3
 >> iter 11000, loss: 0.054501
 >> iter 12000, loss: 0.052955
 >> iter 13000, loss: 0.044785
 >> iter 14000, loss: 0.039244
 >> iter 15000, loss: 0.037462
 >> iter 16000, loss: 0.043015
 >> iter 17000, loss: 0.050796
 >> iter 18000, loss: 0.052065
 >> iter 19000, loss: 0.047600
 >> iter 20000, loss: 0.043880
   Number of active neurons: 3
 >> iter 21000, loss: 0.036762
 >> iter 22000, loss: 0.038556
 >> iter 23000, loss: 0.038946
 >> iter 24000, loss: 0.076133
 >> iter 25000, loss: 0.064481
 >> iter 26000, loss: 0.045023
 >> iter 27000, loss: 0.034983
 >> iter 28000, loss: 0.062209
 >> iter 29000, loss: 0.042566
 >> iter 30000, loss: 0.061473
   Number of active neurons: 3
 >> iter 31000, loss: 0.052581
 >> iter 32000, loss: 0.050016
 >> iter 33000, loss: 0.063278
 >> iter 34000, loss: 0.054902
 >> iter 35000, loss: 0.052869
 >> iter 36000, loss: 0.043929
 >> iter 37000, loss: 0.051890
 >> iter 38000, loss: 0.045009
 >> iter 39000, loss: 0.048812
 >> iter 40000, loss: 0.059644
   Number of active neurons: 3
 >> iter 41000, loss: 0.038365
 >> iter 42000, loss: 0.044014
 >> iter 43000, loss: 0.049652
 >> iter 44000, loss: 0.041311
 >> iter 45000, loss: 0.041754
 >> iter 46000, loss: 0.046057
 >> iter 47000, loss: 0.059379
 >> iter 48000, loss: 0.048097
 >> iter 49000, loss: 0.038102
 >> iter 50000, loss: 0.043573
   Number of active neurons: 3
 >> iter 51000, loss: 0.046790
 >> iter 52000, loss: 0.047490
 >> iter 53000, loss: 0.039382
 >> iter 54000, loss: 0.041730
 >> iter 55000, loss: 0.038085
 >> iter 56000, loss: 0.068148
 >> iter 57000, loss: 0.075946
 >> iter 58000, loss: 0.057664
 >> iter 59000, loss: 0.049593
 >> iter 60000, loss: 0.037352
   Number of active neurons: 3
 >> iter 61000, loss: 0.043878
 >> iter 62000, loss: 0.031302
 >> iter 63000, loss: 0.031594
 >> iter 64000, loss: 0.041446
 >> iter 65000, loss: 0.054448
 >> iter 66000, loss: 0.060293
 >> iter 67000, loss: 0.047134
 >> iter 68000, loss: 0.043495
 >> iter 69000, loss: 0.045419
 >> iter 70000, loss: 0.037127
   Number of active neurons: 3
 >> iter 71000, loss: 0.051251
 >> iter 72000, loss: 0.059009
 >> iter 73000, loss: 0.048397
 >> iter 74000, loss: 0.054680
 >> iter 75000, loss: 0.047466
 >> iter 76000, loss: 0.047413
 >> iter 77000, loss: 0.052109
 >> iter 78000, loss: 0.052331
 >> iter 79000, loss: 0.049959
 >> iter 80000, loss: 0.037960
   Number of active neurons: 3
 >> iter 81000, loss: 0.054967
 >> iter 82000, loss: 0.047725
 >> iter 83000, loss: 0.044242
 >> iter 84000, loss: 0.044306
 >> iter 85000, loss: 0.051182
 >> iter 86000, loss: 0.056072
 >> iter 87000, loss: 0.048838
 >> iter 88000, loss: 0.045751
 >> iter 89000, loss: 0.056448
 >> iter 90000, loss: 0.042835
   Number of active neurons: 3
 >> iter 91000, loss: 0.058006
 >> iter 92000, loss: 0.070836
 >> iter 93000, loss: 0.055769
 >> iter 94000, loss: 0.046613
 >> iter 95000, loss: 0.060301
 >> iter 96000, loss: 0.069796
 >> iter 97000, loss: 0.054599
 >> iter 98000, loss: 0.042293
 >> iter 99000, loss: 0.041517
 >> iter 100000, loss: 0.047607
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.724017
 >> iter 2000, loss: 4.473768
 >> iter 3000, loss: 1.721397
 >> iter 4000, loss: 0.683989
 >> iter 5000, loss: 0.312043
 >> iter 6000, loss: 0.145768
 >> iter 7000, loss: 0.087537
 >> iter 8000, loss: 0.059895
 >> iter 9000, loss: 0.053140
 >> iter 10000, loss: 0.055690
   Number of active neurons: 3
 >> iter 11000, loss: 0.059113
 >> iter 12000, loss: 0.063137
 >> iter 13000, loss: 0.049894
 >> iter 14000, loss: 0.049089
 >> iter 15000, loss: 0.042462
 >> iter 16000, loss: 0.076550
 >> iter 17000, loss: 0.068053
 >> iter 18000, loss: 0.076758
 >> iter 19000, loss: 0.056135
 >> iter 20000, loss: 0.055437
   Number of active neurons: 3
 >> iter 21000, loss: 0.057827
 >> iter 22000, loss: 0.048247
 >> iter 23000, loss: 0.042895
 >> iter 24000, loss: 0.041460
 >> iter 25000, loss: 0.040135
 >> iter 26000, loss: 0.033394
 >> iter 27000, loss: 0.058491
 >> iter 28000, loss: 0.051745
 >> iter 29000, loss: 0.046873
 >> iter 30000, loss: 0.044875
   Number of active neurons: 3
 >> iter 31000, loss: 0.041540
 >> iter 32000, loss: 0.061301
 >> iter 33000, loss: 0.059610
 >> iter 34000, loss: 0.049405
 >> iter 35000, loss: 0.054843
 >> iter 36000, loss: 0.035641
 >> iter 37000, loss: 0.076954
 >> iter 38000, loss: 0.058720
 >> iter 39000, loss: 0.051062
 >> iter 40000, loss: 0.056484
   Number of active neurons: 3
 >> iter 41000, loss: 0.050387
 >> iter 42000, loss: 0.065328
 >> iter 43000, loss: 0.046267
 >> iter 44000, loss: 0.056169
 >> iter 45000, loss: 0.073852
 >> iter 46000, loss: 0.049207
 >> iter 47000, loss: 0.047699
 >> iter 48000, loss: 0.053289
 >> iter 49000, loss: 0.058309
 >> iter 50000, loss: 0.049888
   Number of active neurons: 3
 >> iter 51000, loss: 0.047657
 >> iter 52000, loss: 0.048087
 >> iter 53000, loss: 0.049631
 >> iter 54000, loss: 0.044159
 >> iter 55000, loss: 0.060396
 >> iter 56000, loss: 0.063914
 >> iter 57000, loss: 0.048239
 >> iter 58000, loss: 0.050992
 >> iter 59000, loss: 0.046309
 >> iter 60000, loss: 0.043342
   Number of active neurons: 2
 >> iter 61000, loss: 0.047629
 >> iter 62000, loss: 0.035748
 >> iter 63000, loss: 0.052116
 >> iter 64000, loss: 0.056407
 >> iter 65000, loss: 0.055510
 >> iter 66000, loss: 0.038997
 >> iter 67000, loss: 0.074888
 >> iter 68000, loss: 0.051908
 >> iter 69000, loss: 0.053057
 >> iter 70000, loss: 0.043251
   Number of active neurons: 2
 >> iter 71000, loss: 0.060995
 >> iter 72000, loss: 0.048130
 >> iter 73000, loss: 0.040392
 >> iter 74000, loss: 0.045338
 >> iter 75000, loss: 0.047614
 >> iter 76000, loss: 0.034222
 >> iter 77000, loss: 0.036376
 >> iter 78000, loss: 0.035222
 >> iter 79000, loss: 0.038253
 >> iter 80000, loss: 0.038781
   Number of active neurons: 2
 >> iter 81000, loss: 0.048343
 >> iter 82000, loss: 0.044690
 >> iter 83000, loss: 0.046668
 >> iter 84000, loss: 0.064198
 >> iter 85000, loss: 0.061031
 >> iter 86000, loss: 0.037197
 >> iter 87000, loss: 0.048256
 >> iter 88000, loss: 0.065391
 >> iter 89000, loss: 0.054262
 >> iter 90000, loss: 0.040292
   Number of active neurons: 2
 >> iter 91000, loss: 0.046103
 >> iter 92000, loss: 0.063522
 >> iter 93000, loss: 0.051299
 >> iter 94000, loss: 0.040460
 >> iter 95000, loss: 0.050650
 >> iter 96000, loss: 0.058746
 >> iter 97000, loss: 0.039251
 >> iter 98000, loss: 0.028784
 >> iter 99000, loss: 0.033619
 >> iter 100000, loss: 0.056341
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.490617
 >> iter 2000, loss: 4.373772
 >> iter 3000, loss: 1.685437
 >> iter 4000, loss: 0.674100
 >> iter 5000, loss: 0.269727
 >> iter 6000, loss: 0.129715
 >> iter 7000, loss: 0.084164
 >> iter 8000, loss: 0.097437
 >> iter 9000, loss: 0.071666
 >> iter 10000, loss: 0.050660
   Number of active neurons: 4
 >> iter 11000, loss: 0.058965
 >> iter 12000, loss: 0.066522
 >> iter 13000, loss: 0.069557
 >> iter 14000, loss: 0.064050
 >> iter 15000, loss: 0.067295
 >> iter 16000, loss: 0.044734
 >> iter 17000, loss: 0.048389
 >> iter 18000, loss: 0.047210
 >> iter 19000, loss: 0.065847
 >> iter 20000, loss: 0.063142
   Number of active neurons: 4
 >> iter 21000, loss: 0.057579
 >> iter 22000, loss: 0.038850
 >> iter 23000, loss: 0.059702
 >> iter 24000, loss: 0.053766
 >> iter 25000, loss: 0.052363
 >> iter 26000, loss: 0.051972
 >> iter 27000, loss: 0.054994
 >> iter 28000, loss: 0.060442
 >> iter 29000, loss: 0.051474
 >> iter 30000, loss: 0.056141
   Number of active neurons: 4
 >> iter 31000, loss: 0.043361
 >> iter 32000, loss: 0.039959
 >> iter 33000, loss: 0.042845
 >> iter 34000, loss: 0.055639
 >> iter 35000, loss: 0.053693
 >> iter 36000, loss: 0.051934
 >> iter 37000, loss: 0.071903
 >> iter 38000, loss: 0.068944
 >> iter 39000, loss: 0.052973
 >> iter 40000, loss: 0.066509
   Number of active neurons: 4
 >> iter 41000, loss: 0.062550
 >> iter 42000, loss: 0.059000
 >> iter 43000, loss: 0.046682
 >> iter 44000, loss: 0.048305
 >> iter 45000, loss: 0.050279
 >> iter 46000, loss: 0.040460
 >> iter 47000, loss: 0.057135
 >> iter 48000, loss: 0.040145
 >> iter 49000, loss: 0.050488
 >> iter 50000, loss: 0.037098
   Number of active neurons: 4
 >> iter 51000, loss: 0.037940
 >> iter 52000, loss: 0.062120
 >> iter 53000, loss: 0.047180
 >> iter 54000, loss: 0.043433
 >> iter 55000, loss: 0.061293
 >> iter 56000, loss: 0.069131
 >> iter 57000, loss: 0.059826
 >> iter 58000, loss: 0.045096
 >> iter 59000, loss: 0.056531
 >> iter 60000, loss: 0.050941
   Number of active neurons: 4
 >> iter 61000, loss: 0.058429
 >> iter 62000, loss: 0.061964
 >> iter 63000, loss: 0.056628
 >> iter 64000, loss: 0.055658
 >> iter 65000, loss: 0.040030
 >> iter 66000, loss: 0.059930
 >> iter 67000, loss: 0.046586
 >> iter 68000, loss: 0.056153
 >> iter 69000, loss: 0.047270
 >> iter 70000, loss: 0.063253
   Number of active neurons: 3
 >> iter 71000, loss: 0.062972
 >> iter 72000, loss: 0.052495
 >> iter 73000, loss: 0.056647
 >> iter 74000, loss: 0.065033
 >> iter 75000, loss: 0.068359
 >> iter 76000, loss: 0.065901
 >> iter 77000, loss: 0.080628
 >> iter 78000, loss: 0.065060
 >> iter 79000, loss: 0.062264
 >> iter 80000, loss: 0.053813
   Number of active neurons: 3
 >> iter 81000, loss: 0.042058
 >> iter 82000, loss: 0.036925
 >> iter 83000, loss: 0.029277
 >> iter 84000, loss: 0.039360
 >> iter 85000, loss: 0.037477
 >> iter 86000, loss: 0.044162
 >> iter 87000, loss: 0.041244
 >> iter 88000, loss: 0.036872
 >> iter 89000, loss: 0.045089
 >> iter 90000, loss: 0.047759
   Number of active neurons: 2
 >> iter 91000, loss: 0.043961
 >> iter 92000, loss: 0.036563
 >> iter 93000, loss: 0.039910
 >> iter 94000, loss: 0.049258
 >> iter 95000, loss: 0.039588
 >> iter 96000, loss: 0.046998
 >> iter 97000, loss: 0.040081
 >> iter 98000, loss: 0.035854
 >> iter 99000, loss: 0.035423
 >> iter 100000, loss: 0.041937
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.538464
 >> iter 2000, loss: 4.396340
 >> iter 3000, loss: 1.706023
 >> iter 4000, loss: 0.701499
 >> iter 5000, loss: 0.310569
 >> iter 6000, loss: 0.164197
 >> iter 7000, loss: 0.092855
 >> iter 8000, loss: 0.056369
 >> iter 9000, loss: 0.053417
 >> iter 10000, loss: 0.050272
   Number of active neurons: 4
 >> iter 11000, loss: 0.062715
 >> iter 12000, loss: 0.051223
 >> iter 13000, loss: 0.049111
 >> iter 14000, loss: 0.051458
 >> iter 15000, loss: 0.062430
 >> iter 16000, loss: 0.082787
 >> iter 17000, loss: 0.055457
 >> iter 18000, loss: 0.046862
 >> iter 19000, loss: 0.041693
 >> iter 20000, loss: 0.041313
   Number of active neurons: 4
 >> iter 21000, loss: 0.057461
 >> iter 22000, loss: 0.065683
 >> iter 23000, loss: 0.068373
 >> iter 24000, loss: 0.066955
 >> iter 25000, loss: 0.058982
 >> iter 26000, loss: 0.047298
 >> iter 27000, loss: 0.079764
 >> iter 28000, loss: 0.055115
 >> iter 29000, loss: 0.070394
 >> iter 30000, loss: 0.046944
   Number of active neurons: 4
 >> iter 31000, loss: 0.067137
 >> iter 32000, loss: 0.054285
 >> iter 33000, loss: 0.040430
 >> iter 34000, loss: 0.033834
 >> iter 35000, loss: 0.032958
 >> iter 36000, loss: 0.031758
 >> iter 37000, loss: 0.038889
 >> iter 38000, loss: 0.044585
 >> iter 39000, loss: 0.063496
 >> iter 40000, loss: 0.053511
   Number of active neurons: 4
 >> iter 41000, loss: 0.059219
 >> iter 42000, loss: 0.077375
 >> iter 43000, loss: 0.067078
 >> iter 44000, loss: 0.045552
 >> iter 45000, loss: 0.040039
 >> iter 46000, loss: 0.048905
 >> iter 47000, loss: 0.034043
 >> iter 48000, loss: 0.037291
 >> iter 49000, loss: 0.056540
 >> iter 50000, loss: 0.057486
   Number of active neurons: 4
 >> iter 51000, loss: 0.055782
 >> iter 52000, loss: 0.038061
 >> iter 53000, loss: 0.047139
 >> iter 54000, loss: 0.043736
 >> iter 55000, loss: 0.052758
 >> iter 56000, loss: 0.075864
 >> iter 57000, loss: 0.066528
 >> iter 58000, loss: 0.057453
 >> iter 59000, loss: 0.044390
 >> iter 60000, loss: 0.059241
   Number of active neurons: 3
 >> iter 61000, loss: 0.047297
 >> iter 62000, loss: 0.038883
 >> iter 63000, loss: 0.050253
 >> iter 64000, loss: 0.044696
 >> iter 65000, loss: 0.052483
 >> iter 66000, loss: 0.035855
 >> iter 67000, loss: 0.058602
 >> iter 68000, loss: 0.047985
 >> iter 69000, loss: 0.062703
 >> iter 70000, loss: 0.047354
   Number of active neurons: 3
 >> iter 71000, loss: 0.052388
 >> iter 72000, loss: 0.039670
 >> iter 73000, loss: 0.041325
 >> iter 74000, loss: 0.046308
 >> iter 75000, loss: 0.039661
 >> iter 76000, loss: 0.036458
 >> iter 77000, loss: 0.048153
 >> iter 78000, loss: 0.075358
 >> iter 79000, loss: 0.049112
 >> iter 80000, loss: 0.055635
   Number of active neurons: 2
 >> iter 81000, loss: 0.035330
 >> iter 82000, loss: 0.036157
 >> iter 83000, loss: 0.028260
 >> iter 84000, loss: 0.052848
 >> iter 85000, loss: 0.064177
 >> iter 86000, loss: 0.060103
 >> iter 87000, loss: 0.052814
 >> iter 88000, loss: 0.046982
 >> iter 89000, loss: 0.051928
 >> iter 90000, loss: 0.045677
   Number of active neurons: 2
 >> iter 91000, loss: 0.052101
 >> iter 92000, loss: 0.039642
 >> iter 93000, loss: 0.038521
 >> iter 94000, loss: 0.046373
 >> iter 95000, loss: 0.042876
 >> iter 96000, loss: 0.041558
 >> iter 97000, loss: 0.042407
 >> iter 98000, loss: 0.055417
 >> iter 99000, loss: 0.041987
 >> iter 100000, loss: 0.034044
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.506359
 >> iter 2000, loss: 4.407794
 >> iter 3000, loss: 1.708009
 >> iter 4000, loss: 0.692967
 >> iter 5000, loss: 0.306673
 >> iter 6000, loss: 0.145725
 >> iter 7000, loss: 0.084163
 >> iter 8000, loss: 0.067563
 >> iter 9000, loss: 0.052787
 >> iter 10000, loss: 0.042227
   Number of active neurons: 4
 >> iter 11000, loss: 0.041570
 >> iter 12000, loss: 0.037105
 >> iter 13000, loss: 0.044175
 >> iter 14000, loss: 0.046545
 >> iter 15000, loss: 0.050490
 >> iter 16000, loss: 0.038070
 >> iter 17000, loss: 0.053560
 >> iter 18000, loss: 0.038949
 >> iter 19000, loss: 0.039420
 >> iter 20000, loss: 0.038303
   Number of active neurons: 3
 >> iter 21000, loss: 0.043539
 >> iter 22000, loss: 0.059877
 >> iter 23000, loss: 0.046511
 >> iter 24000, loss: 0.050175
 >> iter 25000, loss: 0.070768
 >> iter 26000, loss: 0.057741
 >> iter 27000, loss: 0.047081
 >> iter 28000, loss: 0.040819
 >> iter 29000, loss: 0.057475
 >> iter 30000, loss: 0.060087
   Number of active neurons: 3
 >> iter 31000, loss: 0.041673
 >> iter 32000, loss: 0.063306
 >> iter 33000, loss: 0.054066
 >> iter 34000, loss: 0.047560
 >> iter 35000, loss: 0.065602
 >> iter 36000, loss: 0.046991
 >> iter 37000, loss: 0.041648
 >> iter 38000, loss: 0.042812
 >> iter 39000, loss: 0.043223
 >> iter 40000, loss: 0.038425
   Number of active neurons: 3
 >> iter 41000, loss: 0.043577
 >> iter 42000, loss: 0.043064
 >> iter 43000, loss: 0.042300
 >> iter 44000, loss: 0.045059
 >> iter 45000, loss: 0.040067
 >> iter 46000, loss: 0.041746
 >> iter 47000, loss: 0.036568
 >> iter 48000, loss: 0.049656
 >> iter 49000, loss: 0.043074
 >> iter 50000, loss: 0.043781
   Number of active neurons: 3
 >> iter 51000, loss: 0.045380
 >> iter 52000, loss: 0.061344
 >> iter 53000, loss: 0.046514
 >> iter 54000, loss: 0.055690
 >> iter 55000, loss: 0.046438
 >> iter 56000, loss: 0.065844
 >> iter 57000, loss: 0.041575
 >> iter 58000, loss: 0.042148
 >> iter 59000, loss: 0.044753
 >> iter 60000, loss: 0.056471
   Number of active neurons: 2
 >> iter 61000, loss: 0.061232
 >> iter 62000, loss: 0.054901
 >> iter 63000, loss: 0.051117
 >> iter 64000, loss: 0.037786
 >> iter 65000, loss: 0.056625
 >> iter 66000, loss: 0.037979
 >> iter 67000, loss: 0.054735
 >> iter 68000, loss: 0.040332
 >> iter 69000, loss: 0.043787
 >> iter 70000, loss: 0.046035
   Number of active neurons: 2
 >> iter 71000, loss: 0.049619
 >> iter 72000, loss: 0.051000
 >> iter 73000, loss: 0.070205
 >> iter 74000, loss: 0.077817
 >> iter 75000, loss: 0.047703
 >> iter 76000, loss: 0.047168
 >> iter 77000, loss: 0.033718
 >> iter 78000, loss: 0.032332
 >> iter 79000, loss: 0.048678
 >> iter 80000, loss: 0.093399
   Number of active neurons: 2
 >> iter 81000, loss: 0.052843
 >> iter 82000, loss: 0.051204
 >> iter 83000, loss: 0.047194
 >> iter 84000, loss: 0.047370
 >> iter 85000, loss: 0.042507
 >> iter 86000, loss: 0.040388
 >> iter 87000, loss: 0.053447
 >> iter 88000, loss: 0.042554
 >> iter 89000, loss: 0.060249
 >> iter 90000, loss: 0.055966
   Number of active neurons: 2
 >> iter 91000, loss: 0.062351
 >> iter 92000, loss: 0.048615
 >> iter 93000, loss: 0.033462
 >> iter 94000, loss: 0.027602
 >> iter 95000, loss: 0.031468
 >> iter 96000, loss: 0.052301
 >> iter 97000, loss: 0.038078
 >> iter 98000, loss: 0.051833
 >> iter 99000, loss: 0.062899
 >> iter 100000, loss: 0.062459
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.439563
 >> iter 2000, loss: 4.361844
 >> iter 3000, loss: 1.671897
 >> iter 4000, loss: 0.656666
 >> iter 5000, loss: 0.275707
 >> iter 6000, loss: 0.146442
 >> iter 7000, loss: 0.117120
 >> iter 8000, loss: 0.074768
 >> iter 9000, loss: 0.062740
 >> iter 10000, loss: 0.057956
   Number of active neurons: 4
 >> iter 11000, loss: 0.048112
 >> iter 12000, loss: 0.050401
 >> iter 13000, loss: 0.049150
 >> iter 14000, loss: 0.055333
 >> iter 15000, loss: 0.053511
 >> iter 16000, loss: 0.040206
 >> iter 17000, loss: 0.047751
 >> iter 18000, loss: 0.048999
 >> iter 19000, loss: 0.045307
 >> iter 20000, loss: 0.072899
   Number of active neurons: 4
 >> iter 21000, loss: 0.052804
 >> iter 22000, loss: 0.053432
 >> iter 23000, loss: 0.055591
 >> iter 24000, loss: 0.047022
 >> iter 25000, loss: 0.052177
 >> iter 26000, loss: 0.043702
 >> iter 27000, loss: 0.046915
 >> iter 28000, loss: 0.049283
 >> iter 29000, loss: 0.041591
 >> iter 30000, loss: 0.044370
   Number of active neurons: 4
 >> iter 31000, loss: 0.056983
 >> iter 32000, loss: 0.044238
 >> iter 33000, loss: 0.042994
 >> iter 34000, loss: 0.057268
 >> iter 35000, loss: 0.041528
 >> iter 36000, loss: 0.057678
 >> iter 37000, loss: 0.053942
 >> iter 38000, loss: 0.052045
 >> iter 39000, loss: 0.052368
 >> iter 40000, loss: 0.054485
   Number of active neurons: 3
 >> iter 41000, loss: 0.046993
 >> iter 42000, loss: 0.042764
 >> iter 43000, loss: 0.033841
 >> iter 44000, loss: 0.040573
 >> iter 45000, loss: 0.040206
 >> iter 46000, loss: 0.034914
 >> iter 47000, loss: 0.032614
 >> iter 48000, loss: 0.036673
 >> iter 49000, loss: 0.060606
 >> iter 50000, loss: 0.062566
   Number of active neurons: 3
 >> iter 51000, loss: 0.060074
 >> iter 52000, loss: 0.065510
 >> iter 53000, loss: 0.051155
 >> iter 54000, loss: 0.060853
 >> iter 55000, loss: 0.055606
 >> iter 56000, loss: 0.042136
 >> iter 57000, loss: 0.053465
 >> iter 58000, loss: 0.040605
 >> iter 59000, loss: 0.036988
 >> iter 60000, loss: 0.050051
   Number of active neurons: 3
 >> iter 61000, loss: 0.046574
 >> iter 62000, loss: 0.040758
 >> iter 63000, loss: 0.043956
 >> iter 64000, loss: 0.054370
 >> iter 65000, loss: 0.048661
 >> iter 66000, loss: 0.041051
 >> iter 67000, loss: 0.069211
 >> iter 68000, loss: 0.048773
 >> iter 69000, loss: 0.037674
 >> iter 70000, loss: 0.045939
   Number of active neurons: 3
 >> iter 71000, loss: 0.045399
 >> iter 72000, loss: 0.050868
 >> iter 73000, loss: 0.061012
 >> iter 74000, loss: 0.056707
 >> iter 75000, loss: 0.048077
 >> iter 76000, loss: 0.051016
 >> iter 77000, loss: 0.044781
 >> iter 78000, loss: 0.047392
 >> iter 79000, loss: 0.039670
 >> iter 80000, loss: 0.038565
   Number of active neurons: 3
 >> iter 81000, loss: 0.043039
 >> iter 82000, loss: 0.046742
 >> iter 83000, loss: 0.039946
 >> iter 84000, loss: 0.039673
 >> iter 85000, loss: 0.039883
 >> iter 86000, loss: 0.045936
 >> iter 87000, loss: 0.058472
 >> iter 88000, loss: 0.068639
 >> iter 89000, loss: 0.042844
 >> iter 90000, loss: 0.051103
   Number of active neurons: 3
 >> iter 91000, loss: 0.056726
 >> iter 92000, loss: 0.050860
 >> iter 93000, loss: 0.058652
 >> iter 94000, loss: 0.039052
 >> iter 95000, loss: 0.040909
 >> iter 96000, loss: 0.042559
 >> iter 97000, loss: 0.034111
 >> iter 98000, loss: 0.043936
 >> iter 99000, loss: 0.036698
 >> iter 100000, loss: 0.035891
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.334161
 >> iter 2000, loss: 4.285870
 >> iter 3000, loss: 1.651295
 >> iter 4000, loss: 0.656944
 >> iter 5000, loss: 0.291184
 >> iter 6000, loss: 0.145809
 >> iter 7000, loss: 0.090077
 >> iter 8000, loss: 0.088615
 >> iter 9000, loss: 0.057985
 >> iter 10000, loss: 0.054745
   Number of active neurons: 3
 >> iter 11000, loss: 0.060100
 >> iter 12000, loss: 0.055276
 >> iter 13000, loss: 0.052164
 >> iter 14000, loss: 0.053709
 >> iter 15000, loss: 0.042700
 >> iter 16000, loss: 0.052153
 >> iter 17000, loss: 0.047969
 >> iter 18000, loss: 0.054799
 >> iter 19000, loss: 0.044904
 >> iter 20000, loss: 0.043601
   Number of active neurons: 3
 >> iter 21000, loss: 0.059515
 >> iter 22000, loss: 0.053875
 >> iter 23000, loss: 0.051436
 >> iter 24000, loss: 0.053118
 >> iter 25000, loss: 0.058561
 >> iter 26000, loss: 0.050558
 >> iter 27000, loss: 0.041812
 >> iter 28000, loss: 0.051507
 >> iter 29000, loss: 0.042189
 >> iter 30000, loss: 0.073059
   Number of active neurons: 3
 >> iter 31000, loss: 0.066619
 >> iter 32000, loss: 0.064716
 >> iter 33000, loss: 0.052650
 >> iter 34000, loss: 0.068549
 >> iter 35000, loss: 0.057701
 >> iter 36000, loss: 0.053738
 >> iter 37000, loss: 0.044390
 >> iter 38000, loss: 0.037335
 >> iter 39000, loss: 0.053690
 >> iter 40000, loss: 0.042146
   Number of active neurons: 3
 >> iter 41000, loss: 0.042623
 >> iter 42000, loss: 0.057606
 >> iter 43000, loss: 0.057734
 >> iter 44000, loss: 0.044768
 >> iter 45000, loss: 0.049845
 >> iter 46000, loss: 0.045920
 >> iter 47000, loss: 0.058769
 >> iter 48000, loss: 0.046431
 >> iter 49000, loss: 0.042088
 >> iter 50000, loss: 0.039239
   Number of active neurons: 3
 >> iter 51000, loss: 0.035549
 >> iter 52000, loss: 0.043535
 >> iter 53000, loss: 0.050903
 >> iter 54000, loss: 0.041716
 >> iter 55000, loss: 0.063948
 >> iter 56000, loss: 0.049736
 >> iter 57000, loss: 0.049806
 >> iter 58000, loss: 0.064338
 >> iter 59000, loss: 0.044347
 >> iter 60000, loss: 0.038895
   Number of active neurons: 3
 >> iter 61000, loss: 0.036572
 >> iter 62000, loss: 0.085720
 >> iter 63000, loss: 0.059655
 >> iter 64000, loss: 0.050431
 >> iter 65000, loss: 0.042417
 >> iter 66000, loss: 0.064939
 >> iter 67000, loss: 0.052955
 >> iter 68000, loss: 0.061984
 >> iter 69000, loss: 0.040019
 >> iter 70000, loss: 0.048011
   Number of active neurons: 3
 >> iter 71000, loss: 0.043957
 >> iter 72000, loss: 0.043693
 >> iter 73000, loss: 0.063072
 >> iter 74000, loss: 0.051648
 >> iter 75000, loss: 0.063255
 >> iter 76000, loss: 0.045819
 >> iter 77000, loss: 0.060292
 >> iter 78000, loss: 0.052064
 >> iter 79000, loss: 0.042510
 >> iter 80000, loss: 0.043031
   Number of active neurons: 3
 >> iter 81000, loss: 0.054403
 >> iter 82000, loss: 0.050930
 >> iter 83000, loss: 0.048388
 >> iter 84000, loss: 0.052124
 >> iter 85000, loss: 0.079341
 >> iter 86000, loss: 0.059293
 >> iter 87000, loss: 0.058827
 >> iter 88000, loss: 0.041741
 >> iter 89000, loss: 0.034425
 >> iter 90000, loss: 0.032423
   Number of active neurons: 3
 >> iter 91000, loss: 0.037725
 >> iter 92000, loss: 0.052351
 >> iter 93000, loss: 0.069809
 >> iter 94000, loss: 0.054784
 >> iter 95000, loss: 0.060766
 >> iter 96000, loss: 0.047136
 >> iter 97000, loss: 0.038373
 >> iter 98000, loss: 0.037453
 >> iter 99000, loss: 0.061189
 >> iter 100000, loss: 0.043845
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.317910
 >> iter 2000, loss: 4.335880
 >> iter 3000, loss: 1.679020
 >> iter 4000, loss: 0.680988
 >> iter 5000, loss: 0.302715
 >> iter 6000, loss: 0.147464
 >> iter 7000, loss: 0.095463
 >> iter 8000, loss: 0.064022
 >> iter 9000, loss: 0.071134
 >> iter 10000, loss: 0.075929
   Number of active neurons: 4
 >> iter 11000, loss: 0.068518
 >> iter 12000, loss: 0.072248
 >> iter 13000, loss: 0.074727
 >> iter 14000, loss: 0.069245
 >> iter 15000, loss: 0.047939
 >> iter 16000, loss: 0.067633
 >> iter 17000, loss: 0.066497
 >> iter 18000, loss: 0.061220
 >> iter 19000, loss: 0.049609
 >> iter 20000, loss: 0.041948
   Number of active neurons: 3
 >> iter 21000, loss: 0.040000
 >> iter 22000, loss: 0.063692
 >> iter 23000, loss: 0.046861
 >> iter 24000, loss: 0.040096
 >> iter 25000, loss: 0.048733
 >> iter 26000, loss: 0.040868
 >> iter 27000, loss: 0.054987
 >> iter 28000, loss: 0.053631
 >> iter 29000, loss: 0.036919
 >> iter 30000, loss: 0.041085
   Number of active neurons: 3
 >> iter 31000, loss: 0.038106
 >> iter 32000, loss: 0.034845
 >> iter 33000, loss: 0.039275
 >> iter 34000, loss: 0.040299
 >> iter 35000, loss: 0.042337
 >> iter 36000, loss: 0.055809
 >> iter 37000, loss: 0.035339
 >> iter 38000, loss: 0.039749
 >> iter 39000, loss: 0.050170
 >> iter 40000, loss: 0.064821
   Number of active neurons: 3
 >> iter 41000, loss: 0.056415
 >> iter 42000, loss: 0.052931
 >> iter 43000, loss: 0.049335
 >> iter 44000, loss: 0.042745
 >> iter 45000, loss: 0.042116
 >> iter 46000, loss: 0.044810
 >> iter 47000, loss: 0.043572
 >> iter 48000, loss: 0.040056
 >> iter 49000, loss: 0.036966
 >> iter 50000, loss: 0.041072
   Number of active neurons: 3
 >> iter 51000, loss: 0.040129
 >> iter 52000, loss: 0.037157
 >> iter 53000, loss: 0.046435
 >> iter 54000, loss: 0.050509
 >> iter 55000, loss: 0.054081
 >> iter 56000, loss: 0.046287
 >> iter 57000, loss: 0.049552
 >> iter 58000, loss: 0.053963
 >> iter 59000, loss: 0.064247
 >> iter 60000, loss: 0.050827
   Number of active neurons: 3
 >> iter 61000, loss: 0.044635
 >> iter 62000, loss: 0.059895
 >> iter 63000, loss: 0.054726
 >> iter 64000, loss: 0.050510
 >> iter 65000, loss: 0.051268
 >> iter 66000, loss: 0.064792
 >> iter 67000, loss: 0.061325
 >> iter 68000, loss: 0.049173
 >> iter 69000, loss: 0.037177
 >> iter 70000, loss: 0.043101
   Number of active neurons: 3
 >> iter 71000, loss: 0.054563
 >> iter 72000, loss: 0.075554
 >> iter 73000, loss: 0.050621
 >> iter 74000, loss: 0.045096
 >> iter 75000, loss: 0.067639
 >> iter 76000, loss: 0.051944
 >> iter 77000, loss: 0.040085
 >> iter 78000, loss: 0.035284
 >> iter 79000, loss: 0.036660
 >> iter 80000, loss: 0.042817
   Number of active neurons: 3
 >> iter 81000, loss: 0.056449
 >> iter 82000, loss: 0.046671
 >> iter 83000, loss: 0.057309
 >> iter 84000, loss: 0.044976
 >> iter 85000, loss: 0.049272
 >> iter 86000, loss: 0.058020
 >> iter 87000, loss: 0.056789
 >> iter 88000, loss: 0.054393
 >> iter 89000, loss: 0.037434
 >> iter 90000, loss: 0.053318
   Number of active neurons: 3
 >> iter 91000, loss: 0.049602
 >> iter 92000, loss: 0.051694
 >> iter 93000, loss: 0.046045
 >> iter 94000, loss: 0.040987
 >> iter 95000, loss: 0.050395
 >> iter 96000, loss: 0.042316
 >> iter 97000, loss: 0.037935
 >> iter 98000, loss: 0.029257
 >> iter 99000, loss: 0.035590
 >> iter 100000, loss: 0.029864
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.581985
 >> iter 2000, loss: 4.430710
 >> iter 3000, loss: 1.688735
 >> iter 4000, loss: 0.664039
 >> iter 5000, loss: 0.308619
 >> iter 6000, loss: 0.141689
 >> iter 7000, loss: 0.104798
 >> iter 8000, loss: 0.077376
 >> iter 9000, loss: 0.063528
 >> iter 10000, loss: 0.048728
   Number of active neurons: 3
 >> iter 11000, loss: 0.044239
 >> iter 12000, loss: 0.053631
 >> iter 13000, loss: 0.062985
 >> iter 14000, loss: 0.046926
 >> iter 15000, loss: 0.051265
 >> iter 16000, loss: 0.058288
 >> iter 17000, loss: 0.043723
 >> iter 18000, loss: 0.036038
 >> iter 19000, loss: 0.037456
 >> iter 20000, loss: 0.042475
   Number of active neurons: 3
 >> iter 21000, loss: 0.060059
 >> iter 22000, loss: 0.049939
 >> iter 23000, loss: 0.058242
 >> iter 24000, loss: 0.052926
 >> iter 25000, loss: 0.044327
 >> iter 26000, loss: 0.051904
 >> iter 27000, loss: 0.064610
 >> iter 28000, loss: 0.048983
 >> iter 29000, loss: 0.055753
 >> iter 30000, loss: 0.049604
   Number of active neurons: 3
 >> iter 31000, loss: 0.044578
 >> iter 32000, loss: 0.034084
 >> iter 33000, loss: 0.028701
 >> iter 34000, loss: 0.047078
 >> iter 35000, loss: 0.057303
 >> iter 36000, loss: 0.065551
 >> iter 37000, loss: 0.044964
 >> iter 38000, loss: 0.054745
 >> iter 39000, loss: 0.051962
 >> iter 40000, loss: 0.052845
   Number of active neurons: 3
 >> iter 41000, loss: 0.042309
 >> iter 42000, loss: 0.036117
 >> iter 43000, loss: 0.059659
 >> iter 44000, loss: 0.057993
 >> iter 45000, loss: 0.060494
 >> iter 46000, loss: 0.048789
 >> iter 47000, loss: 0.044707
 >> iter 48000, loss: 0.046273
 >> iter 49000, loss: 0.038326
 >> iter 50000, loss: 0.046011
   Number of active neurons: 3
 >> iter 51000, loss: 0.049297
 >> iter 52000, loss: 0.042500
 >> iter 53000, loss: 0.037582
 >> iter 54000, loss: 0.041267
 >> iter 55000, loss: 0.050658
 >> iter 56000, loss: 0.053139
 >> iter 57000, loss: 0.048080
 >> iter 58000, loss: 0.056976
 >> iter 59000, loss: 0.059011
 >> iter 60000, loss: 0.059753
   Number of active neurons: 3
 >> iter 61000, loss: 0.043776
 >> iter 62000, loss: 0.058500
 >> iter 63000, loss: 0.040462
 >> iter 64000, loss: 0.056341
 >> iter 65000, loss: 0.058287
 >> iter 66000, loss: 0.072589
 >> iter 67000, loss: 0.047474
 >> iter 68000, loss: 0.042406
 >> iter 69000, loss: 0.053215
 >> iter 70000, loss: 0.049593
   Number of active neurons: 3
 >> iter 71000, loss: 0.054114
 >> iter 72000, loss: 0.052167
 >> iter 73000, loss: 0.041771
 >> iter 74000, loss: 0.043110
 >> iter 75000, loss: 0.045940
 >> iter 76000, loss: 0.051610
 >> iter 77000, loss: 0.050539
 >> iter 78000, loss: 0.045393
 >> iter 79000, loss: 0.047569
 >> iter 80000, loss: 0.043686
   Number of active neurons: 2
 >> iter 81000, loss: 0.043617
 >> iter 82000, loss: 0.041121
 >> iter 83000, loss: 0.085296
 >> iter 84000, loss: 0.047354
 >> iter 85000, loss: 0.043857
 >> iter 86000, loss: 0.045777
 >> iter 87000, loss: 0.052940
 >> iter 88000, loss: 0.053455
 >> iter 89000, loss: 0.036442
 >> iter 90000, loss: 0.047281
   Number of active neurons: 2
 >> iter 91000, loss: 0.037736
 >> iter 92000, loss: 0.052880
 >> iter 93000, loss: 0.048464
 >> iter 94000, loss: 0.052641
 >> iter 95000, loss: 0.051981
 >> iter 96000, loss: 0.044696
 >> iter 97000, loss: 0.046510
 >> iter 98000, loss: 0.045931
 >> iter 99000, loss: 0.045253
 >> iter 100000, loss: 0.053158
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.698079
 >> iter 2000, loss: 4.533508
 >> iter 3000, loss: 1.763857
 >> iter 4000, loss: 0.699969
 >> iter 5000, loss: 0.292417
 >> iter 6000, loss: 0.176342
 >> iter 7000, loss: 0.101402
 >> iter 8000, loss: 0.080926
 >> iter 9000, loss: 0.067507
 >> iter 10000, loss: 0.055561
   Number of active neurons: 3
 >> iter 11000, loss: 0.054792
 >> iter 12000, loss: 0.057701
 >> iter 13000, loss: 0.055881
 >> iter 14000, loss: 0.050105
 >> iter 15000, loss: 0.041359
 >> iter 16000, loss: 0.040971
 >> iter 17000, loss: 0.067696
 >> iter 18000, loss: 0.072836
 >> iter 19000, loss: 0.067492
 >> iter 20000, loss: 0.057218
   Number of active neurons: 3
 >> iter 21000, loss: 0.052496
 >> iter 22000, loss: 0.053876
 >> iter 23000, loss: 0.053198
 >> iter 24000, loss: 0.044625
 >> iter 25000, loss: 0.042173
 >> iter 26000, loss: 0.037625
 >> iter 27000, loss: 0.035452
 >> iter 28000, loss: 0.047160
 >> iter 29000, loss: 0.058058
 >> iter 30000, loss: 0.047280
   Number of active neurons: 3
 >> iter 31000, loss: 0.056306
 >> iter 32000, loss: 0.062897
 >> iter 33000, loss: 0.064977
 >> iter 34000, loss: 0.060452
 >> iter 35000, loss: 0.063030
 >> iter 36000, loss: 0.041476
 >> iter 37000, loss: 0.078685
 >> iter 38000, loss: 0.060106
 >> iter 39000, loss: 0.043792
 >> iter 40000, loss: 0.083297
   Number of active neurons: 3
 >> iter 41000, loss: 0.085377
 >> iter 42000, loss: 0.064417
 >> iter 43000, loss: 0.056945
 >> iter 44000, loss: 0.070785
 >> iter 45000, loss: 0.068943
 >> iter 46000, loss: 0.046083
 >> iter 47000, loss: 0.043063
 >> iter 48000, loss: 0.039030
 >> iter 49000, loss: 0.037476
 >> iter 50000, loss: 0.055984
   Number of active neurons: 3
 >> iter 51000, loss: 0.060435
 >> iter 52000, loss: 0.051112
 >> iter 53000, loss: 0.054402
 >> iter 54000, loss: 0.060209
 >> iter 55000, loss: 0.057282
 >> iter 56000, loss: 0.044571
 >> iter 57000, loss: 0.046471
 >> iter 58000, loss: 0.048052
 >> iter 59000, loss: 0.057593
 >> iter 60000, loss: 0.049641
   Number of active neurons: 3
 >> iter 61000, loss: 0.046443
 >> iter 62000, loss: 0.033076
 >> iter 63000, loss: 0.041054
 >> iter 64000, loss: 0.044615
 >> iter 65000, loss: 0.083764
 >> iter 66000, loss: 0.057918
 >> iter 67000, loss: 0.052970
 >> iter 68000, loss: 0.047773
 >> iter 69000, loss: 0.084137
 >> iter 70000, loss: 0.055783
   Number of active neurons: 3
 >> iter 71000, loss: 0.058526
 >> iter 72000, loss: 0.041756
 >> iter 73000, loss: 0.038389
 >> iter 74000, loss: 0.059162
 >> iter 75000, loss: 0.048017
 >> iter 76000, loss: 0.061362
 >> iter 77000, loss: 0.051441
 >> iter 78000, loss: 0.060486
 >> iter 79000, loss: 0.052416
 >> iter 80000, loss: 0.042962
   Number of active neurons: 3
 >> iter 81000, loss: 0.039553
 >> iter 82000, loss: 0.061203
 >> iter 83000, loss: 0.055890
 >> iter 84000, loss: 0.056233
 >> iter 85000, loss: 0.048189
 >> iter 86000, loss: 0.055727
 >> iter 87000, loss: 0.059811
 >> iter 88000, loss: 0.049627
 >> iter 89000, loss: 0.038956
 >> iter 90000, loss: 0.045831
   Number of active neurons: 2
 >> iter 91000, loss: 0.039972
 >> iter 92000, loss: 0.041157
 >> iter 93000, loss: 0.034729
 >> iter 94000, loss: 0.027721
 >> iter 95000, loss: 0.047770
 >> iter 96000, loss: 0.046743
 >> iter 97000, loss: 0.031468
 >> iter 98000, loss: 0.049190
 >> iter 99000, loss: 0.060982
 >> iter 100000, loss: 0.047846
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.352738
 >> iter 2000, loss: 4.307496
 >> iter 3000, loss: 1.659000
 >> iter 4000, loss: 0.660028
 >> iter 5000, loss: 0.283176
 >> iter 6000, loss: 0.132192
 >> iter 7000, loss: 0.099152
 >> iter 8000, loss: 0.062535
 >> iter 9000, loss: 0.053668
 >> iter 10000, loss: 0.062255
   Number of active neurons: 4
 >> iter 11000, loss: 0.066116
 >> iter 12000, loss: 0.051129
 >> iter 13000, loss: 0.048016
 >> iter 14000, loss: 0.040870
 >> iter 15000, loss: 0.035348
 >> iter 16000, loss: 0.035261
 >> iter 17000, loss: 0.044908
 >> iter 18000, loss: 0.053279
 >> iter 19000, loss: 0.036488
 >> iter 20000, loss: 0.054544
   Number of active neurons: 4
 >> iter 21000, loss: 0.067477
 >> iter 22000, loss: 0.046724
 >> iter 23000, loss: 0.041248
 >> iter 24000, loss: 0.046910
 >> iter 25000, loss: 0.074045
 >> iter 26000, loss: 0.044262
 >> iter 27000, loss: 0.045413
 >> iter 28000, loss: 0.049659
 >> iter 29000, loss: 0.057021
 >> iter 30000, loss: 0.048097
   Number of active neurons: 3
 >> iter 31000, loss: 0.056461
 >> iter 32000, loss: 0.042047
 >> iter 33000, loss: 0.060900
 >> iter 34000, loss: 0.048361
 >> iter 35000, loss: 0.048278
 >> iter 36000, loss: 0.036056
 >> iter 37000, loss: 0.033767
 >> iter 38000, loss: 0.037327
 >> iter 39000, loss: 0.037648
 >> iter 40000, loss: 0.032895
   Number of active neurons: 3
 >> iter 41000, loss: 0.045962
 >> iter 42000, loss: 0.043210
 >> iter 43000, loss: 0.046041
 >> iter 44000, loss: 0.037779
 >> iter 45000, loss: 0.057409
 >> iter 46000, loss: 0.042646
 >> iter 47000, loss: 0.047820
 >> iter 48000, loss: 0.035825
 >> iter 49000, loss: 0.050987
 >> iter 50000, loss: 0.045885
   Number of active neurons: 3
 >> iter 51000, loss: 0.038124
 >> iter 52000, loss: 0.042531
 >> iter 53000, loss: 0.041509
 >> iter 54000, loss: 0.047064
 >> iter 55000, loss: 0.045189
 >> iter 56000, loss: 0.034251
 >> iter 57000, loss: 0.040863
 >> iter 58000, loss: 0.057193
 >> iter 59000, loss: 0.055129
 >> iter 60000, loss: 0.050394
   Number of active neurons: 3
 >> iter 61000, loss: 0.041282
 >> iter 62000, loss: 0.040321
 >> iter 63000, loss: 0.043609
 >> iter 64000, loss: 0.040247
 >> iter 65000, loss: 0.042973
 >> iter 66000, loss: 0.055142
 >> iter 67000, loss: 0.072535
 >> iter 68000, loss: 0.047944
 >> iter 69000, loss: 0.036923
 >> iter 70000, loss: 0.044629
   Number of active neurons: 3
 >> iter 71000, loss: 0.056970
 >> iter 72000, loss: 0.049148
 >> iter 73000, loss: 0.045472
 >> iter 74000, loss: 0.059262
 >> iter 75000, loss: 0.046546
 >> iter 76000, loss: 0.038500
 >> iter 77000, loss: 0.038693
 >> iter 78000, loss: 0.052821
 >> iter 79000, loss: 0.052556
 >> iter 80000, loss: 0.042755
   Number of active neurons: 3
 >> iter 81000, loss: 0.042205
 >> iter 82000, loss: 0.046000
 >> iter 83000, loss: 0.048287
 >> iter 84000, loss: 0.047558
 >> iter 85000, loss: 0.055741
 >> iter 86000, loss: 0.039658
 >> iter 87000, loss: 0.064003
 >> iter 88000, loss: 0.043814
 >> iter 89000, loss: 0.039454
 >> iter 90000, loss: 0.055559
   Number of active neurons: 2
 >> iter 91000, loss: 0.070148
 >> iter 92000, loss: 0.056829
 >> iter 93000, loss: 0.037088
 >> iter 94000, loss: 0.045216
 >> iter 95000, loss: 0.060002
 >> iter 96000, loss: 0.052995
 >> iter 97000, loss: 0.037146
 >> iter 98000, loss: 0.033829
 >> iter 99000, loss: 0.032029
 >> iter 100000, loss: 0.039043
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.448668
 >> iter 2000, loss: 4.369065
 >> iter 3000, loss: 1.680835
 >> iter 4000, loss: 0.672931
 >> iter 5000, loss: 0.299226
 >> iter 6000, loss: 0.178292
 >> iter 7000, loss: 0.092532
 >> iter 8000, loss: 0.055541
 >> iter 9000, loss: 0.071269
 >> iter 10000, loss: 0.055494
   Number of active neurons: 4
 >> iter 11000, loss: 0.055264
 >> iter 12000, loss: 0.051709
 >> iter 13000, loss: 0.043666
 >> iter 14000, loss: 0.041184
 >> iter 15000, loss: 0.050444
 >> iter 16000, loss: 0.047798
 >> iter 17000, loss: 0.044047
 >> iter 18000, loss: 0.039949
 >> iter 19000, loss: 0.051588
 >> iter 20000, loss: 0.059797
   Number of active neurons: 4
 >> iter 21000, loss: 0.044922
 >> iter 22000, loss: 0.055189
 >> iter 23000, loss: 0.049947
 >> iter 24000, loss: 0.047206
 >> iter 25000, loss: 0.041628
 >> iter 26000, loss: 0.062368
 >> iter 27000, loss: 0.054279
 >> iter 28000, loss: 0.064945
 >> iter 29000, loss: 0.075726
 >> iter 30000, loss: 0.078308
   Number of active neurons: 4
 >> iter 31000, loss: 0.046844
 >> iter 32000, loss: 0.072221
 >> iter 33000, loss: 0.059231
 >> iter 34000, loss: 0.048271
 >> iter 35000, loss: 0.082185
 >> iter 36000, loss: 0.059028
 >> iter 37000, loss: 0.064208
 >> iter 38000, loss: 0.048491
 >> iter 39000, loss: 0.040580
 >> iter 40000, loss: 0.042934
   Number of active neurons: 4
 >> iter 41000, loss: 0.041342
 >> iter 42000, loss: 0.070877
 >> iter 43000, loss: 0.061176
 >> iter 44000, loss: 0.045211
 >> iter 45000, loss: 0.049561
 >> iter 46000, loss: 0.040302
 >> iter 47000, loss: 0.056272
 >> iter 48000, loss: 0.046753
 >> iter 49000, loss: 0.053788
 >> iter 50000, loss: 0.043666
   Number of active neurons: 4
 >> iter 51000, loss: 0.043238
 >> iter 52000, loss: 0.052939
 >> iter 53000, loss: 0.045185
 >> iter 54000, loss: 0.076019
 >> iter 55000, loss: 0.073551
 >> iter 56000, loss: 0.052265
 >> iter 57000, loss: 0.052589
 >> iter 58000, loss: 0.057934
 >> iter 59000, loss: 0.075262
 >> iter 60000, loss: 0.055162
   Number of active neurons: 4
 >> iter 61000, loss: 0.042551
 >> iter 62000, loss: 0.050738
 >> iter 63000, loss: 0.058812
 >> iter 64000, loss: 0.063244
 >> iter 65000, loss: 0.049519
 >> iter 66000, loss: 0.045202
 >> iter 67000, loss: 0.043285
 >> iter 68000, loss: 0.046177
 >> iter 69000, loss: 0.045319
 >> iter 70000, loss: 0.045245
   Number of active neurons: 4
 >> iter 71000, loss: 0.057332
 >> iter 72000, loss: 0.057855
 >> iter 73000, loss: 0.066093
 >> iter 74000, loss: 0.052907
 >> iter 75000, loss: 0.059830
 >> iter 76000, loss: 0.047487
 >> iter 77000, loss: 0.040016
 >> iter 78000, loss: 0.068645
 >> iter 79000, loss: 0.062913
 >> iter 80000, loss: 0.062225
   Number of active neurons: 4
 >> iter 81000, loss: 0.044326
 >> iter 82000, loss: 0.043599
 >> iter 83000, loss: 0.043263
 >> iter 84000, loss: 0.051693
 >> iter 85000, loss: 0.059560
 >> iter 86000, loss: 0.055299
 >> iter 87000, loss: 0.058991
 >> iter 88000, loss: 0.047165
 >> iter 89000, loss: 0.063872
 >> iter 90000, loss: 0.055836
   Number of active neurons: 4
 >> iter 91000, loss: 0.054941
 >> iter 92000, loss: 0.062177
 >> iter 93000, loss: 0.058517
 >> iter 94000, loss: 0.048607
 >> iter 95000, loss: 0.042949
 >> iter 96000, loss: 0.051544
 >> iter 97000, loss: 0.070013
 >> iter 98000, loss: 0.056818
 >> iter 99000, loss: 0.055202
 >> iter 100000, loss: 0.041966
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.483807
 >> iter 2000, loss: 4.397956
 >> iter 3000, loss: 1.702313
 >> iter 4000, loss: 0.676548
 >> iter 5000, loss: 0.287430
 >> iter 6000, loss: 0.136320
 >> iter 7000, loss: 0.092134
 >> iter 8000, loss: 0.067560
 >> iter 9000, loss: 0.060536
 >> iter 10000, loss: 0.044344
   Number of active neurons: 4
 >> iter 11000, loss: 0.064586
 >> iter 12000, loss: 0.065650
 >> iter 13000, loss: 0.052912
 >> iter 14000, loss: 0.047689
 >> iter 15000, loss: 0.092467
 >> iter 16000, loss: 0.068251
 >> iter 17000, loss: 0.073952
 >> iter 18000, loss: 0.056077
 >> iter 19000, loss: 0.054200
 >> iter 20000, loss: 0.051438
   Number of active neurons: 4
 >> iter 21000, loss: 0.053560
 >> iter 22000, loss: 0.049034
 >> iter 23000, loss: 0.041717
 >> iter 24000, loss: 0.039435
 >> iter 25000, loss: 0.044752
 >> iter 26000, loss: 0.038460
 >> iter 27000, loss: 0.048749
 >> iter 28000, loss: 0.056943
 >> iter 29000, loss: 0.040486
 >> iter 30000, loss: 0.044590
   Number of active neurons: 4
 >> iter 31000, loss: 0.050597
 >> iter 32000, loss: 0.042925
 >> iter 33000, loss: 0.049502
 >> iter 34000, loss: 0.048883
 >> iter 35000, loss: 0.044043
 >> iter 36000, loss: 0.053396
 >> iter 37000, loss: 0.056487
 >> iter 38000, loss: 0.049042
 >> iter 39000, loss: 0.058463
 >> iter 40000, loss: 0.070510
   Number of active neurons: 4
 >> iter 41000, loss: 0.069782
 >> iter 42000, loss: 0.062502
 >> iter 43000, loss: 0.056462
 >> iter 44000, loss: 0.064474
 >> iter 45000, loss: 0.046139
 >> iter 46000, loss: 0.043425
 >> iter 47000, loss: 0.043139
 >> iter 48000, loss: 0.051918
 >> iter 49000, loss: 0.047911
 >> iter 50000, loss: 0.035808
   Number of active neurons: 4
 >> iter 51000, loss: 0.040655
 >> iter 52000, loss: 0.043525
 >> iter 53000, loss: 0.052308
 >> iter 54000, loss: 0.046819
 >> iter 55000, loss: 0.044487
 >> iter 56000, loss: 0.045347
 >> iter 57000, loss: 0.054435
 >> iter 58000, loss: 0.077185
 >> iter 59000, loss: 0.053033
 >> iter 60000, loss: 0.044341
   Number of active neurons: 4
 >> iter 61000, loss: 0.042748
 >> iter 62000, loss: 0.045108
 >> iter 63000, loss: 0.045150
 >> iter 64000, loss: 0.046175
 >> iter 65000, loss: 0.043355
 >> iter 66000, loss: 0.047335
 >> iter 67000, loss: 0.050246
 >> iter 68000, loss: 0.038225
 >> iter 69000, loss: 0.060627
 >> iter 70000, loss: 0.041907
   Number of active neurons: 3
 >> iter 71000, loss: 0.059562
 >> iter 72000, loss: 0.044427
 >> iter 73000, loss: 0.052204
 >> iter 74000, loss: 0.056514
 >> iter 75000, loss: 0.061085
 >> iter 76000, loss: 0.055415
 >> iter 77000, loss: 0.036513
 >> iter 78000, loss: 0.044096
 >> iter 79000, loss: 0.051512
 >> iter 80000, loss: 0.045783
   Number of active neurons: 3
 >> iter 81000, loss: 0.039158
 >> iter 82000, loss: 0.056547
 >> iter 83000, loss: 0.058858
 >> iter 84000, loss: 0.047802
 >> iter 85000, loss: 0.050229
 >> iter 86000, loss: 0.051197
 >> iter 87000, loss: 0.089148
 >> iter 88000, loss: 0.062645
 >> iter 89000, loss: 0.057769
 >> iter 90000, loss: 0.053445
   Number of active neurons: 3
 >> iter 91000, loss: 0.082448
 >> iter 92000, loss: 0.078012
 >> iter 93000, loss: 0.050242
 >> iter 94000, loss: 0.041052
 >> iter 95000, loss: 0.047848
 >> iter 96000, loss: 0.038043
 >> iter 97000, loss: 0.051890
 >> iter 98000, loss: 0.056159
 >> iter 99000, loss: 0.040715
 >> iter 100000, loss: 0.045534
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.380027
 >> iter 2000, loss: 4.363871
 >> iter 3000, loss: 1.681243
 >> iter 4000, loss: 0.651687
 >> iter 5000, loss: 0.289036
 >> iter 6000, loss: 0.141124
 >> iter 7000, loss: 0.085333
 >> iter 8000, loss: 0.066734
 >> iter 9000, loss: 0.051993
 >> iter 10000, loss: 0.071488
   Number of active neurons: 3
 >> iter 11000, loss: 0.069287
 >> iter 12000, loss: 0.053484
 >> iter 13000, loss: 0.045245
 >> iter 14000, loss: 0.046367
 >> iter 15000, loss: 0.037047
 >> iter 16000, loss: 0.053050
 >> iter 17000, loss: 0.038126
 >> iter 18000, loss: 0.031959
 >> iter 19000, loss: 0.042826
 >> iter 20000, loss: 0.043092
   Number of active neurons: 3
 >> iter 21000, loss: 0.037728
 >> iter 22000, loss: 0.043686
 >> iter 23000, loss: 0.036234
 >> iter 24000, loss: 0.056987
 >> iter 25000, loss: 0.057602
 >> iter 26000, loss: 0.056691
 >> iter 27000, loss: 0.060572
 >> iter 28000, loss: 0.050685
 >> iter 29000, loss: 0.052811
 >> iter 30000, loss: 0.037084
   Number of active neurons: 3
 >> iter 31000, loss: 0.034360
 >> iter 32000, loss: 0.041844
 >> iter 33000, loss: 0.040392
 >> iter 34000, loss: 0.037559
 >> iter 35000, loss: 0.050046
 >> iter 36000, loss: 0.048778
 >> iter 37000, loss: 0.049546
 >> iter 38000, loss: 0.042251
 >> iter 39000, loss: 0.057720
 >> iter 40000, loss: 0.034600
   Number of active neurons: 3
 >> iter 41000, loss: 0.048682
 >> iter 42000, loss: 0.063876
 >> iter 43000, loss: 0.054017
 >> iter 44000, loss: 0.041624
 >> iter 45000, loss: 0.040768
 >> iter 46000, loss: 0.052187
 >> iter 47000, loss: 0.037549
 >> iter 48000, loss: 0.030368
 >> iter 49000, loss: 0.058502
 >> iter 50000, loss: 0.046717
   Number of active neurons: 3
 >> iter 51000, loss: 0.057806
 >> iter 52000, loss: 0.064799
 >> iter 53000, loss: 0.062829
 >> iter 54000, loss: 0.045345
 >> iter 55000, loss: 0.050062
 >> iter 56000, loss: 0.034594
 >> iter 57000, loss: 0.044561
 >> iter 58000, loss: 0.038205
 >> iter 59000, loss: 0.038795
 >> iter 60000, loss: 0.047479
   Number of active neurons: 3
 >> iter 61000, loss: 0.046359
 >> iter 62000, loss: 0.044690
 >> iter 63000, loss: 0.042218
 >> iter 64000, loss: 0.043332
 >> iter 65000, loss: 0.054529
 >> iter 66000, loss: 0.050610
 >> iter 67000, loss: 0.038713
 >> iter 68000, loss: 0.042269
 >> iter 69000, loss: 0.048388
 >> iter 70000, loss: 0.039222
   Number of active neurons: 3
 >> iter 71000, loss: 0.053529
 >> iter 72000, loss: 0.038414
 >> iter 73000, loss: 0.048436
 >> iter 74000, loss: 0.057313
 >> iter 75000, loss: 0.050761
 >> iter 76000, loss: 0.036269
 >> iter 77000, loss: 0.040905
 >> iter 78000, loss: 0.054526
 >> iter 79000, loss: 0.047305
 >> iter 80000, loss: 0.058699
   Number of active neurons: 3
 >> iter 81000, loss: 0.055981
 >> iter 82000, loss: 0.055117
 >> iter 83000, loss: 0.039737
 >> iter 84000, loss: 0.044609
 >> iter 85000, loss: 0.052264
 >> iter 86000, loss: 0.038445
 >> iter 87000, loss: 0.056228
 >> iter 88000, loss: 0.055663
 >> iter 89000, loss: 0.045634
 >> iter 90000, loss: 0.042512
   Number of active neurons: 3
 >> iter 91000, loss: 0.050736
 >> iter 92000, loss: 0.036409
 >> iter 93000, loss: 0.040957
 >> iter 94000, loss: 0.048680
 >> iter 95000, loss: 0.039034
 >> iter 96000, loss: 0.036085
 >> iter 97000, loss: 0.052211
 >> iter 98000, loss: 0.046106
 >> iter 99000, loss: 0.049143
 >> iter 100000, loss: 0.039032
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.428067
 >> iter 2000, loss: 4.342587
 >> iter 3000, loss: 1.647571
 >> iter 4000, loss: 0.653790
 >> iter 5000, loss: 0.279961
 >> iter 6000, loss: 0.131767
 >> iter 7000, loss: 0.077869
 >> iter 8000, loss: 0.054135
 >> iter 9000, loss: 0.063090
 >> iter 10000, loss: 0.055893
   Number of active neurons: 3
 >> iter 11000, loss: 0.055158
 >> iter 12000, loss: 0.062606
 >> iter 13000, loss: 0.054398
 >> iter 14000, loss: 0.043713
 >> iter 15000, loss: 0.035940
 >> iter 16000, loss: 0.041647
 >> iter 17000, loss: 0.053846
 >> iter 18000, loss: 0.061852
 >> iter 19000, loss: 0.056013
 >> iter 20000, loss: 0.049169
   Number of active neurons: 3
 >> iter 21000, loss: 0.040030
 >> iter 22000, loss: 0.066888
 >> iter 23000, loss: 0.075822
 >> iter 24000, loss: 0.053070
 >> iter 25000, loss: 0.036047
 >> iter 26000, loss: 0.040264
 >> iter 27000, loss: 0.047240
 >> iter 28000, loss: 0.035916
 >> iter 29000, loss: 0.031507
 >> iter 30000, loss: 0.038441
   Number of active neurons: 3
 >> iter 31000, loss: 0.039542
 >> iter 32000, loss: 0.056316
 >> iter 33000, loss: 0.057600
 >> iter 34000, loss: 0.058588
 >> iter 35000, loss: 0.056064
 >> iter 36000, loss: 0.046202
 >> iter 37000, loss: 0.047120
 >> iter 38000, loss: 0.048062
 >> iter 39000, loss: 0.032978
 >> iter 40000, loss: 0.045222
   Number of active neurons: 3
 >> iter 41000, loss: 0.032846
 >> iter 42000, loss: 0.049611
 >> iter 43000, loss: 0.037138
 >> iter 44000, loss: 0.042437
 >> iter 45000, loss: 0.042938
 >> iter 46000, loss: 0.040765
 >> iter 47000, loss: 0.052655
 >> iter 48000, loss: 0.055066
 >> iter 49000, loss: 0.041026
 >> iter 50000, loss: 0.061693
   Number of active neurons: 3
 >> iter 51000, loss: 0.069989
 >> iter 52000, loss: 0.053822
 >> iter 53000, loss: 0.051280
 >> iter 54000, loss: 0.041761
 >> iter 55000, loss: 0.052665
 >> iter 56000, loss: 0.048964
 >> iter 57000, loss: 0.044813
 >> iter 58000, loss: 0.053825
 >> iter 59000, loss: 0.041064
 >> iter 60000, loss: 0.041125
   Number of active neurons: 3
 >> iter 61000, loss: 0.063791
 >> iter 62000, loss: 0.046768
 >> iter 63000, loss: 0.045430
 >> iter 64000, loss: 0.046756
 >> iter 65000, loss: 0.052784
 >> iter 66000, loss: 0.054203
 >> iter 67000, loss: 0.069166
 >> iter 68000, loss: 0.057517
 >> iter 69000, loss: 0.053901
 >> iter 70000, loss: 0.052114
   Number of active neurons: 3
 >> iter 71000, loss: 0.070515
 >> iter 72000, loss: 0.060963
 >> iter 73000, loss: 0.067642
 >> iter 74000, loss: 0.053311
 >> iter 75000, loss: 0.052734
 >> iter 76000, loss: 0.041238
 >> iter 77000, loss: 0.043519
 >> iter 78000, loss: 0.041223
 >> iter 79000, loss: 0.070492
 >> iter 80000, loss: 0.061316
   Number of active neurons: 3
 >> iter 81000, loss: 0.058988
 >> iter 82000, loss: 0.063298
 >> iter 83000, loss: 0.066956
 >> iter 84000, loss: 0.044116
 >> iter 85000, loss: 0.071497
 >> iter 86000, loss: 0.058460
 >> iter 87000, loss: 0.046089
 >> iter 88000, loss: 0.059286
 >> iter 89000, loss: 0.063329
 >> iter 90000, loss: 0.040645
   Number of active neurons: 3
 >> iter 91000, loss: 0.049070
 >> iter 92000, loss: 0.049846
 >> iter 93000, loss: 0.041502
 >> iter 94000, loss: 0.043234
 >> iter 95000, loss: 0.040721
 >> iter 96000, loss: 0.049718
 >> iter 97000, loss: 0.036056
 >> iter 98000, loss: 0.051711
 >> iter 99000, loss: 0.063140
 >> iter 100000, loss: 0.072226
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.369026
 >> iter 2000, loss: 4.335807
 >> iter 3000, loss: 1.646964
 >> iter 4000, loss: 0.641560
 >> iter 5000, loss: 0.266447
 >> iter 6000, loss: 0.140084
 >> iter 7000, loss: 0.095608
 >> iter 8000, loss: 0.081237
 >> iter 9000, loss: 0.066362
 >> iter 10000, loss: 0.050686
   Number of active neurons: 4
 >> iter 11000, loss: 0.049370
 >> iter 12000, loss: 0.053027
 >> iter 13000, loss: 0.057651
 >> iter 14000, loss: 0.065947
 >> iter 15000, loss: 0.046204
 >> iter 16000, loss: 0.052343
 >> iter 17000, loss: 0.062477
 >> iter 18000, loss: 0.049811
 >> iter 19000, loss: 0.060075
 >> iter 20000, loss: 0.051851
   Number of active neurons: 4
 >> iter 21000, loss: 0.066965
 >> iter 22000, loss: 0.057223
 >> iter 23000, loss: 0.046754
 >> iter 24000, loss: 0.058308
 >> iter 25000, loss: 0.048002
 >> iter 26000, loss: 0.044556
 >> iter 27000, loss: 0.065384
 >> iter 28000, loss: 0.059457
 >> iter 29000, loss: 0.062930
 >> iter 30000, loss: 0.059882
   Number of active neurons: 4
 >> iter 31000, loss: 0.041381
 >> iter 32000, loss: 0.046309
 >> iter 33000, loss: 0.049155
 >> iter 34000, loss: 0.043008
 >> iter 35000, loss: 0.044003
 >> iter 36000, loss: 0.044170
 >> iter 37000, loss: 0.034355
 >> iter 38000, loss: 0.043608
 >> iter 39000, loss: 0.072480
 >> iter 40000, loss: 0.048293
   Number of active neurons: 4
 >> iter 41000, loss: 0.035467
 >> iter 42000, loss: 0.036735
 >> iter 43000, loss: 0.042056
 >> iter 44000, loss: 0.039270
 >> iter 45000, loss: 0.050625
 >> iter 46000, loss: 0.065545
 >> iter 47000, loss: 0.051697
 >> iter 48000, loss: 0.047303
 >> iter 49000, loss: 0.048630
 >> iter 50000, loss: 0.045306
   Number of active neurons: 3
 >> iter 51000, loss: 0.037883
 >> iter 52000, loss: 0.039616
 >> iter 53000, loss: 0.051295
 >> iter 54000, loss: 0.049453
 >> iter 55000, loss: 0.043352
 >> iter 56000, loss: 0.040535
 >> iter 57000, loss: 0.041489
 >> iter 58000, loss: 0.048630
 >> iter 59000, loss: 0.050754
 >> iter 60000, loss: 0.041952
   Number of active neurons: 3
 >> iter 61000, loss: 0.043450
 >> iter 62000, loss: 0.042237
 >> iter 63000, loss: 0.045752
 >> iter 64000, loss: 0.040888
 >> iter 65000, loss: 0.035386
 >> iter 66000, loss: 0.045841
 >> iter 67000, loss: 0.043875
 >> iter 68000, loss: 0.041408
 >> iter 69000, loss: 0.059104
 >> iter 70000, loss: 0.055474
   Number of active neurons: 3
 >> iter 71000, loss: 0.063007
 >> iter 72000, loss: 0.050083
 >> iter 73000, loss: 0.037905
 >> iter 74000, loss: 0.043016
 >> iter 75000, loss: 0.042147
 >> iter 76000, loss: 0.052226
 >> iter 77000, loss: 0.039429
 >> iter 78000, loss: 0.041387
 >> iter 79000, loss: 0.055710
 >> iter 80000, loss: 0.040464
   Number of active neurons: 3
 >> iter 81000, loss: 0.054153
 >> iter 82000, loss: 0.049680
 >> iter 83000, loss: 0.042936
 >> iter 84000, loss: 0.036270
 >> iter 85000, loss: 0.046140
 >> iter 86000, loss: 0.062545
 >> iter 87000, loss: 0.045454
 >> iter 88000, loss: 0.037173
 >> iter 89000, loss: 0.036937
 >> iter 90000, loss: 0.035907
   Number of active neurons: 3
 >> iter 91000, loss: 0.049085
 >> iter 92000, loss: 0.057630
 >> iter 93000, loss: 0.049969
 >> iter 94000, loss: 0.048426
 >> iter 95000, loss: 0.046037
 >> iter 96000, loss: 0.041154
 >> iter 97000, loss: 0.055242
 >> iter 98000, loss: 0.043675
 >> iter 99000, loss: 0.030333
 >> iter 100000, loss: 0.033549
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.431980
 >> iter 2000, loss: 4.379627
 >> iter 3000, loss: 1.685260
 >> iter 4000, loss: 0.680448
 >> iter 5000, loss: 0.283944
 >> iter 6000, loss: 0.144937
 >> iter 7000, loss: 0.099975
 >> iter 8000, loss: 0.076202
 >> iter 9000, loss: 0.050236
 >> iter 10000, loss: 0.061074
   Number of active neurons: 4
 >> iter 11000, loss: 0.070764
 >> iter 12000, loss: 0.064484
 >> iter 13000, loss: 0.075107
 >> iter 14000, loss: 0.065198
 >> iter 15000, loss: 0.072171
 >> iter 16000, loss: 0.056125
 >> iter 17000, loss: 0.049537
 >> iter 18000, loss: 0.044019
 >> iter 19000, loss: 0.049607
 >> iter 20000, loss: 0.046903
   Number of active neurons: 4
 >> iter 21000, loss: 0.053783
 >> iter 22000, loss: 0.040129
 >> iter 23000, loss: 0.054554
 >> iter 24000, loss: 0.057189
 >> iter 25000, loss: 0.044126
 >> iter 26000, loss: 0.038641
 >> iter 27000, loss: 0.043444
 >> iter 28000, loss: 0.041957
 >> iter 29000, loss: 0.042992
 >> iter 30000, loss: 0.035895
   Number of active neurons: 4
 >> iter 31000, loss: 0.044692
 >> iter 32000, loss: 0.048635
 >> iter 33000, loss: 0.041358
 >> iter 34000, loss: 0.045551
 >> iter 35000, loss: 0.041029
 >> iter 36000, loss: 0.057705
 >> iter 37000, loss: 0.040816
 >> iter 38000, loss: 0.037505
 >> iter 39000, loss: 0.057031
 >> iter 40000, loss: 0.041200
   Number of active neurons: 4
 >> iter 41000, loss: 0.047066
 >> iter 42000, loss: 0.046140
 >> iter 43000, loss: 0.055898
 >> iter 44000, loss: 0.059373
 >> iter 45000, loss: 0.057197
 >> iter 46000, loss: 0.072791
 >> iter 47000, loss: 0.067139
 >> iter 48000, loss: 0.061937
 >> iter 49000, loss: 0.054443
 >> iter 50000, loss: 0.044250
   Number of active neurons: 3
 >> iter 51000, loss: 0.041773
 >> iter 52000, loss: 0.051046
 >> iter 53000, loss: 0.059155
 >> iter 54000, loss: 0.052047
 >> iter 55000, loss: 0.044675
 >> iter 56000, loss: 0.049429
 >> iter 57000, loss: 0.039833
 >> iter 58000, loss: 0.045830
 >> iter 59000, loss: 0.035007
 >> iter 60000, loss: 0.040364
   Number of active neurons: 3
 >> iter 61000, loss: 0.054159
 >> iter 62000, loss: 0.044083
 >> iter 63000, loss: 0.043024
 >> iter 64000, loss: 0.046188
 >> iter 65000, loss: 0.051848
 >> iter 66000, loss: 0.064338
 >> iter 67000, loss: 0.055470
 >> iter 68000, loss: 0.053662
 >> iter 69000, loss: 0.058241
 >> iter 70000, loss: 0.038778
   Number of active neurons: 3
 >> iter 71000, loss: 0.040761
 >> iter 72000, loss: 0.041427
 >> iter 73000, loss: 0.033267
 >> iter 74000, loss: 0.039413
 >> iter 75000, loss: 0.044819
 >> iter 76000, loss: 0.041516
 >> iter 77000, loss: 0.044742
 >> iter 78000, loss: 0.037974
 >> iter 79000, loss: 0.061783
 >> iter 80000, loss: 0.056622
   Number of active neurons: 3
 >> iter 81000, loss: 0.043526
 >> iter 82000, loss: 0.052947
 >> iter 83000, loss: 0.058160
 >> iter 84000, loss: 0.039065
 >> iter 85000, loss: 0.071354
 >> iter 86000, loss: 0.049015
 >> iter 87000, loss: 0.041617
 >> iter 88000, loss: 0.058537
 >> iter 89000, loss: 0.053454
 >> iter 90000, loss: 0.037764
   Number of active neurons: 3
 >> iter 91000, loss: 0.044323
 >> iter 92000, loss: 0.047079
 >> iter 93000, loss: 0.062572
 >> iter 94000, loss: 0.045726
 >> iter 95000, loss: 0.057928
 >> iter 96000, loss: 0.046475
 >> iter 97000, loss: 0.033825
 >> iter 98000, loss: 0.033726
 >> iter 99000, loss: 0.041557
 >> iter 100000, loss: 0.044781
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.674006
 >> iter 2000, loss: 4.484060
 >> iter 3000, loss: 1.745192
 >> iter 4000, loss: 0.692172
 >> iter 5000, loss: 0.286745
 >> iter 6000, loss: 0.134941
 >> iter 7000, loss: 0.093641
 >> iter 8000, loss: 0.088047
 >> iter 9000, loss: 0.077191
 >> iter 10000, loss: 0.049159
   Number of active neurons: 3
 >> iter 11000, loss: 0.055880
 >> iter 12000, loss: 0.040598
 >> iter 13000, loss: 0.050940
 >> iter 14000, loss: 0.045725
 >> iter 15000, loss: 0.041606
 >> iter 16000, loss: 0.040220
 >> iter 17000, loss: 0.061860
 >> iter 18000, loss: 0.063073
 >> iter 19000, loss: 0.057081
 >> iter 20000, loss: 0.067798
   Number of active neurons: 3
 >> iter 21000, loss: 0.056719
 >> iter 22000, loss: 0.042839
 >> iter 23000, loss: 0.047079
 >> iter 24000, loss: 0.043415
 >> iter 25000, loss: 0.053444
 >> iter 26000, loss: 0.053194
 >> iter 27000, loss: 0.040647
 >> iter 28000, loss: 0.046427
 >> iter 29000, loss: 0.054262
 >> iter 30000, loss: 0.047670
   Number of active neurons: 3
 >> iter 31000, loss: 0.050298
 >> iter 32000, loss: 0.047519
 >> iter 33000, loss: 0.043768
 >> iter 34000, loss: 0.041076
 >> iter 35000, loss: 0.046142
 >> iter 36000, loss: 0.048221
 >> iter 37000, loss: 0.035821
 >> iter 38000, loss: 0.048590
 >> iter 39000, loss: 0.035685
 >> iter 40000, loss: 0.047099
   Number of active neurons: 2
 >> iter 41000, loss: 0.040028
 >> iter 42000, loss: 0.047870
 >> iter 43000, loss: 0.049371
 >> iter 44000, loss: 0.051511
 >> iter 45000, loss: 0.044006
 >> iter 46000, loss: 0.052291
 >> iter 47000, loss: 0.057598
 >> iter 48000, loss: 0.039873
 >> iter 49000, loss: 0.041800
 >> iter 50000, loss: 0.054282
   Number of active neurons: 2
 >> iter 51000, loss: 0.033600
 >> iter 52000, loss: 0.029133
 >> iter 53000, loss: 0.040095
 >> iter 54000, loss: 0.064055
 >> iter 55000, loss: 0.041293
 >> iter 56000, loss: 0.046835
 >> iter 57000, loss: 0.044568
 >> iter 58000, loss: 0.046111
 >> iter 59000, loss: 0.058703
 >> iter 60000, loss: 0.055080
   Number of active neurons: 2
 >> iter 61000, loss: 0.047925
 >> iter 62000, loss: 0.047966
 >> iter 63000, loss: 0.051237
 >> iter 64000, loss: 0.056007
 >> iter 65000, loss: 0.059094
 >> iter 66000, loss: 0.050211
 >> iter 67000, loss: 0.056716
 >> iter 68000, loss: 0.039260
 >> iter 69000, loss: 0.060157
 >> iter 70000, loss: 0.047471
   Number of active neurons: 2
 >> iter 71000, loss: 0.040517
 >> iter 72000, loss: 0.033258
 >> iter 73000, loss: 0.042540
 >> iter 74000, loss: 0.039240
 >> iter 75000, loss: 0.044009
 >> iter 76000, loss: 0.046039
 >> iter 77000, loss: 0.049480
 >> iter 78000, loss: 0.065160
 >> iter 79000, loss: 0.044587
 >> iter 80000, loss: 0.053834
   Number of active neurons: 2
 >> iter 81000, loss: 0.052371
 >> iter 82000, loss: 0.047050
 >> iter 83000, loss: 0.040420
 >> iter 84000, loss: 0.052859
 >> iter 85000, loss: 0.041921
 >> iter 86000, loss: 0.032878
 >> iter 87000, loss: 0.039995
 >> iter 88000, loss: 0.041822
 >> iter 89000, loss: 0.036153
 >> iter 90000, loss: 0.037736
   Number of active neurons: 2
 >> iter 91000, loss: 0.039380
 >> iter 92000, loss: 0.041808
 >> iter 93000, loss: 0.051580
 >> iter 94000, loss: 0.058285
 >> iter 95000, loss: 0.044866
 >> iter 96000, loss: 0.048669
 >> iter 97000, loss: 0.031436
 >> iter 98000, loss: 0.039681
 >> iter 99000, loss: 0.065516
 >> iter 100000, loss: 0.051760
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

