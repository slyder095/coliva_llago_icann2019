 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 1e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.828511
 >> iter 2000, loss: 7.999566
 >> iter 3000, loss: 2.976478
 >> iter 4000, loss: 1.113089
 >> iter 5000, loss: 0.422629
 >> iter 6000, loss: 0.165887
 >> iter 7000, loss: 0.069941
 >> iter 8000, loss: 0.033489
 >> iter 9000, loss: 0.019408
 >> iter 10000, loss: 0.013589
   Number of active neurons: 10
 >> iter 11000, loss: 0.011087
 >> iter 12000, loss: 0.009764
 >> iter 13000, loss: 0.009067
 >> iter 14000, loss: 0.008540
 >> iter 15000, loss: 0.008212
 >> iter 16000, loss: 0.007897
 >> iter 17000, loss: 0.007695
 >> iter 18000, loss: 0.007472
 >> iter 19000, loss: 0.007334
 >> iter 20000, loss: 0.007165
   Number of active neurons: 10
 >> iter 21000, loss: 0.007071
 >> iter 22000, loss: 0.006942
 >> iter 23000, loss: 0.006865
 >> iter 24000, loss: 0.006758
 >> iter 25000, loss: 0.006695
 >> iter 26000, loss: 0.006602
 >> iter 27000, loss: 0.006550
 >> iter 28000, loss: 0.006473
 >> iter 29000, loss: 0.006430
 >> iter 30000, loss: 0.006365
   Number of active neurons: 10
 >> iter 31000, loss: 0.006333
 >> iter 32000, loss: 0.006265
 >> iter 33000, loss: 0.006236
 >> iter 34000, loss: 0.006177
 >> iter 35000, loss: 0.006148
 >> iter 36000, loss: 0.006092
 >> iter 37000, loss: 0.006071
 >> iter 38000, loss: 0.006017
 >> iter 39000, loss: 0.006003
 >> iter 40000, loss: 0.005957
   Number of active neurons: 10
 >> iter 41000, loss: 0.005938
 >> iter 42000, loss: 0.005897
 >> iter 43000, loss: 0.005878
 >> iter 44000, loss: 0.005843
 >> iter 45000, loss: 0.005828
 >> iter 46000, loss: 0.005792
 >> iter 47000, loss: 0.005775
 >> iter 48000, loss: 0.005748
 >> iter 49000, loss: 0.005728
 >> iter 50000, loss: 0.005706
   Number of active neurons: 10
 >> iter 51000, loss: 0.005683
 >> iter 52000, loss: 0.005672
 >> iter 53000, loss: 0.005642
 >> iter 54000, loss: 0.005635
 >> iter 55000, loss: 0.005609
 >> iter 56000, loss: 0.005604
 >> iter 57000, loss: 0.005581
 >> iter 58000, loss: 0.005572
 >> iter 59000, loss: 0.005550
 >> iter 60000, loss: 0.005544
   Number of active neurons: 9
 >> iter 61000, loss: 0.005520
 >> iter 62000, loss: 0.005510
 >> iter 63000, loss: 0.005492
 >> iter 64000, loss: 0.005481
 >> iter 65000, loss: 0.005464
 >> iter 66000, loss: 0.005454
 >> iter 67000, loss: 0.005437
 >> iter 68000, loss: 0.005428
 >> iter 69000, loss: 0.005408
 >> iter 70000, loss: 0.005400
   Number of active neurons: 9
 >> iter 71000, loss: 0.005393
 >> iter 72000, loss: 0.005372
 >> iter 73000, loss: 0.005375
 >> iter 74000, loss: 0.005345
 >> iter 75000, loss: 0.005355
 >> iter 76000, loss: 0.005328
 >> iter 77000, loss: 0.005336
 >> iter 78000, loss: 0.005305
 >> iter 79000, loss: 0.005318
 >> iter 80000, loss: 0.005278
   Number of active neurons: 9
 >> iter 81000, loss: 0.005298
 >> iter 82000, loss: 0.005255
 >> iter 83000, loss: 0.005278
 >> iter 84000, loss: 0.005228
 >> iter 85000, loss: 0.005261
 >> iter 86000, loss: 0.005206
 >> iter 87000, loss: 0.005236
 >> iter 88000, loss: 0.005184
 >> iter 89000, loss: 0.005210
 >> iter 90000, loss: 0.005159
   Number of active neurons: 9
 >> iter 91000, loss: 0.005183
 >> iter 92000, loss: 0.005129
 >> iter 93000, loss: 0.005155
 >> iter 94000, loss: 0.005095
 >> iter 95000, loss: 0.005131
 >> iter 96000, loss: 0.005061
 >> iter 97000, loss: 0.005096
 >> iter 98000, loss: 0.005026
 >> iter 99000, loss: 0.005064
 >> iter 100000, loss: 0.004990
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0733284447704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.231111
 >> iter 2000, loss: 7.231336
 >> iter 3000, loss: 3.048490
 >> iter 4000, loss: 1.147473
 >> iter 5000, loss: 0.436947
 >> iter 6000, loss: 0.171569
 >> iter 7000, loss: 0.353120
 >> iter 8000, loss: 0.141925
 >> iter 9000, loss: 0.060560
 >> iter 10000, loss: 0.029131
   Number of active neurons: 9
 >> iter 11000, loss: 0.016750
 >> iter 12000, loss: 0.011552
 >> iter 13000, loss: 0.009402
 >> iter 14000, loss: 0.008139
 >> iter 15000, loss: 0.007480
 >> iter 16000, loss: 0.006994
 >> iter 17000, loss: 0.006809
 >> iter 18000, loss: 0.006487
 >> iter 19000, loss: 0.006298
 >> iter 20000, loss: 0.006093
   Number of active neurons: 10
 >> iter 21000, loss: 0.006077
 >> iter 22000, loss: 0.005873
 >> iter 23000, loss: 0.005781
 >> iter 24000, loss: 0.005657
 >> iter 25000, loss: 0.005601
 >> iter 26000, loss: 0.008961
 >> iter 27000, loss: 0.006643
 >> iter 28000, loss: 0.005637
 >> iter 29000, loss: 0.005261
 >> iter 30000, loss: 0.005085
   Number of active neurons: 10
 >> iter 31000, loss: 0.005040
 >> iter 32000, loss: 0.004987
 >> iter 33000, loss: 0.004986
 >> iter 34000, loss: 0.004947
 >> iter 35000, loss: 0.004944
 >> iter 36000, loss: 0.004906
 >> iter 37000, loss: 0.004901
 >> iter 38000, loss: 0.004861
 >> iter 39000, loss: 0.004856
 >> iter 40000, loss: 0.004818
   Number of active neurons: 10
 >> iter 41000, loss: 0.004812
 >> iter 42000, loss: 0.004777
 >> iter 43000, loss: 0.004769
 >> iter 44000, loss: 0.004740
 >> iter 45000, loss: 0.069955
 >> iter 46000, loss: 0.028875
 >> iter 47000, loss: 0.013615
 >> iter 48000, loss: 0.007867
 >> iter 49000, loss: 0.005752
 >> iter 50000, loss: 0.004929
   Number of active neurons: 9
 >> iter 51000, loss: 0.004641
 >> iter 52000, loss: 0.004517
 >> iter 53000, loss: 0.004486
 >> iter 54000, loss: 0.004469
 >> iter 55000, loss: 0.004483
 >> iter 56000, loss: 0.004486
 >> iter 57000, loss: 0.004508
 >> iter 58000, loss: 0.004510
 >> iter 59000, loss: 0.004529
 >> iter 60000, loss: 0.004530
   Number of active neurons: 10
 >> iter 61000, loss: 0.004543
 >> iter 62000, loss: 0.004537
 >> iter 63000, loss: 0.004548
 >> iter 64000, loss: 0.004540
 >> iter 65000, loss: 0.004547
 >> iter 66000, loss: 0.004536
 >> iter 67000, loss: 0.004540
 >> iter 68000, loss: 0.004533
 >> iter 69000, loss: 0.004529
 >> iter 70000, loss: 0.004523
   Number of active neurons: 9
 >> iter 71000, loss: 0.004521
 >> iter 72000, loss: 0.004513
 >> iter 73000, loss: 0.004517
 >> iter 74000, loss: 0.004508
 >> iter 75000, loss: 0.004516
 >> iter 76000, loss: 0.004509
 >> iter 77000, loss: 0.004512
 >> iter 78000, loss: 0.004506
 >> iter 79000, loss: 0.004512
 >> iter 80000, loss: 0.004502
   Number of active neurons: 9
 >> iter 81000, loss: 0.004508
 >> iter 82000, loss: 0.004500
 >> iter 83000, loss: 0.004506
 >> iter 84000, loss: 0.004494
 >> iter 85000, loss: 0.004506
 >> iter 86000, loss: 0.004489
 >> iter 87000, loss: 0.004496
 >> iter 88000, loss: 0.004482
 >> iter 89000, loss: 0.004487
 >> iter 90000, loss: 0.004475
   Number of active neurons: 9
 >> iter 91000, loss: 0.004477
 >> iter 92000, loss: 0.004462
 >> iter 93000, loss: 0.004467
 >> iter 94000, loss: 0.004443
 >> iter 95000, loss: 0.004532
 >> iter 96000, loss: 0.004449
 >> iter 97000, loss: 0.004440
 >> iter 98000, loss: 0.004409
 >> iter 99000, loss: 0.098562
 >> iter 100000, loss: 0.182238
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0049997500125
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 5.15298980068
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.887508
 >> iter 2000, loss: 7.920400
 >> iter 3000, loss: 3.000408
 >> iter 4000, loss: 1.127102
 >> iter 5000, loss: 0.431066
 >> iter 6000, loss: 0.171236
 >> iter 7000, loss: 0.073592
 >> iter 8000, loss: 0.036065
 >> iter 9000, loss: 0.021325
 >> iter 10000, loss: 0.014980
   Number of active neurons: 10
 >> iter 11000, loss: 0.012119
 >> iter 12000, loss: 0.010456
 >> iter 13000, loss: 0.009518
 >> iter 14000, loss: 0.008748
 >> iter 15000, loss: 0.008247
 >> iter 16000, loss: 0.007829
 >> iter 17000, loss: 0.007507
 >> iter 18000, loss: 0.007150
 >> iter 19000, loss: 0.006922
 >> iter 20000, loss: 0.006658
   Number of active neurons: 10
 >> iter 21000, loss: 0.006505
 >> iter 22000, loss: 0.006308
 >> iter 23000, loss: 0.006206
 >> iter 24000, loss: 0.006048
 >> iter 25000, loss: 0.006016
 >> iter 26000, loss: 0.005866
 >> iter 27000, loss: 0.005816
 >> iter 28000, loss: 0.005711
 >> iter 29000, loss: 0.469877
 >> iter 30000, loss: 0.228439
   Number of active neurons: 10
 >> iter 31000, loss: 0.090714
 >> iter 32000, loss: 0.039100
 >> iter 33000, loss: 0.019603
 >> iter 34000, loss: 0.012037
 >> iter 35000, loss: 0.009010
 >> iter 36000, loss: 0.007689
 >> iter 37000, loss: 0.007066
 >> iter 38000, loss: 0.006699
 >> iter 39000, loss: 0.006481
 >> iter 40000, loss: 0.006299
   Number of active neurons: 9
 >> iter 41000, loss: 0.006175
 >> iter 42000, loss: 0.006045
 >> iter 43000, loss: 0.005960
 >> iter 44000, loss: 0.005857
 >> iter 45000, loss: 0.069911
 >> iter 46000, loss: 0.135739
 >> iter 47000, loss: 0.054159
 >> iter 48000, loss: 0.023713
 >> iter 49000, loss: 0.012392
 >> iter 50000, loss: 0.008067
   Number of active neurons: 9
 >> iter 51000, loss: 0.006472
 >> iter 52000, loss: 0.005785
 >> iter 53000, loss: 0.005568
 >> iter 54000, loss: 0.005405
 >> iter 55000, loss: 0.005390
 >> iter 56000, loss: 0.005306
 >> iter 57000, loss: 0.005328
 >> iter 58000, loss: 0.005259
 >> iter 59000, loss: 0.005289
 >> iter 60000, loss: 0.005215
   Number of active neurons: 8
 >> iter 61000, loss: 0.005237
 >> iter 62000, loss: 0.005157
 >> iter 63000, loss: 0.005189
 >> iter 64000, loss: 0.005110
 >> iter 65000, loss: 0.005144
 >> iter 66000, loss: 0.005061
 >> iter 67000, loss: 0.005100
 >> iter 68000, loss: 0.005018
 >> iter 69000, loss: 0.005056
 >> iter 70000, loss: 0.004977
   Number of active neurons: 8
 >> iter 71000, loss: 0.005019
 >> iter 72000, loss: 0.004935
 >> iter 73000, loss: 0.004980
 >> iter 74000, loss: 0.004888
 >> iter 75000, loss: 0.004944
 >> iter 76000, loss: 0.004849
 >> iter 77000, loss: 0.004903
 >> iter 78000, loss: 0.004811
 >> iter 79000, loss: 0.004869
 >> iter 80000, loss: 0.004774
   Number of active neurons: 8
 >> iter 81000, loss: 0.004831
 >> iter 82000, loss: 0.004742
 >> iter 83000, loss: 0.004802
 >> iter 84000, loss: 0.004711
 >> iter 85000, loss: 0.004773
 >> iter 86000, loss: 0.004684
 >> iter 87000, loss: 0.004742
 >> iter 88000, loss: 0.004660
 >> iter 89000, loss: 0.004715
 >> iter 90000, loss: 0.004640
   Number of active neurons: 8
 >> iter 91000, loss: 0.004692
 >> iter 92000, loss: 0.004618
 >> iter 93000, loss: 0.004675
 >> iter 94000, loss: 0.004599
 >> iter 95000, loss: 0.004662
 >> iter 96000, loss: 0.004578
 >> iter 97000, loss: 0.004642
 >> iter 98000, loss: 0.004559
 >> iter 99000, loss: 0.004631
 >> iter 100000, loss: 0.004540
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 4.53303113126
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.537156
 >> iter 2000, loss: 7.690495
 >> iter 3000, loss: 2.857495
 >> iter 4000, loss: 1.067358
 >> iter 5000, loss: 0.404480
 >> iter 6000, loss: 0.158319
 >> iter 7000, loss: 0.066348
 >> iter 8000, loss: 0.031532
 >> iter 9000, loss: 0.018043
 >> iter 10000, loss: 0.012544
   Number of active neurons: 10
 >> iter 11000, loss: 0.010137
 >> iter 12000, loss: 0.008928
 >> iter 13000, loss: 0.008243
 >> iter 14000, loss: 0.007777
 >> iter 15000, loss: 0.007438
 >> iter 16000, loss: 0.007158
 >> iter 17000, loss: 0.006939
 >> iter 18000, loss: 0.006739
 >> iter 19000, loss: 0.006580
 >> iter 20000, loss: 0.006426
   Number of active neurons: 9
 >> iter 21000, loss: 0.006314
 >> iter 22000, loss: 0.006194
 >> iter 23000, loss: 0.006103
 >> iter 24000, loss: 0.006002
 >> iter 25000, loss: 0.005933
 >> iter 26000, loss: 0.005852
 >> iter 27000, loss: 0.005801
 >> iter 28000, loss: 0.005730
 >> iter 29000, loss: 0.005693
 >> iter 30000, loss: 0.005630
   Number of active neurons: 9
 >> iter 31000, loss: 0.005604
 >> iter 32000, loss: 0.005541
 >> iter 33000, loss: 0.005519
 >> iter 34000, loss: 0.005464
 >> iter 35000, loss: 0.005450
 >> iter 36000, loss: 0.005397
 >> iter 37000, loss: 0.005391
 >> iter 38000, loss: 0.005339
 >> iter 39000, loss: 0.005342
 >> iter 40000, loss: 0.005292
   Number of active neurons: 9
 >> iter 41000, loss: 0.005295
 >> iter 42000, loss: 0.005246
 >> iter 43000, loss: 0.005249
 >> iter 44000, loss: 0.005204
 >> iter 45000, loss: 0.005212
 >> iter 46000, loss: 0.005161
 >> iter 47000, loss: 0.005170
 >> iter 48000, loss: 0.005125
 >> iter 49000, loss: 0.005127
 >> iter 50000, loss: 0.005079
   Number of active neurons: 9
 >> iter 51000, loss: 0.005082
 >> iter 52000, loss: 0.005047
 >> iter 53000, loss: 0.005042
 >> iter 54000, loss: 0.005009
 >> iter 55000, loss: 0.005007
 >> iter 56000, loss: 0.004977
 >> iter 57000, loss: 0.004979
 >> iter 58000, loss: 0.004946
 >> iter 59000, loss: 0.004947
 >> iter 60000, loss: 0.004919
   Number of active neurons: 9
 >> iter 61000, loss: 0.004921
 >> iter 62000, loss: 0.004891
 >> iter 63000, loss: 0.004898
 >> iter 64000, loss: 0.004870
 >> iter 65000, loss: 0.004879
 >> iter 66000, loss: 0.004853
 >> iter 67000, loss: 0.004861
 >> iter 68000, loss: 0.004840
 >> iter 69000, loss: 0.004843
 >> iter 70000, loss: 0.004827
   Number of active neurons: 9
 >> iter 71000, loss: 0.004833
 >> iter 72000, loss: 0.004816
 >> iter 73000, loss: 0.004826
 >> iter 74000, loss: 0.004807
 >> iter 75000, loss: 0.004819
 >> iter 76000, loss: 0.004805
 >> iter 77000, loss: 0.004809
 >> iter 78000, loss: 0.004794
 >> iter 79000, loss: 0.004799
 >> iter 80000, loss: 0.004778
   Number of active neurons: 9
 >> iter 81000, loss: 0.004783
 >> iter 82000, loss: 0.004765
 >> iter 83000, loss: 0.004767
 >> iter 84000, loss: 0.004747
 >> iter 85000, loss: 0.004756
 >> iter 86000, loss: 0.004736
 >> iter 87000, loss: 0.004740
 >> iter 88000, loss: 0.004725
 >> iter 89000, loss: 0.004724
 >> iter 90000, loss: 0.004716
   Number of active neurons: 9
 >> iter 91000, loss: 0.004713
 >> iter 92000, loss: 0.004704
 >> iter 93000, loss: 0.004704
 >> iter 94000, loss: 0.004694
 >> iter 95000, loss: 0.004702
 >> iter 96000, loss: 0.004685
 >> iter 97000, loss: 0.004695
 >> iter 98000, loss: 0.004678
 >> iter 99000, loss: 0.004691
 >> iter 100000, loss: 0.004673
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 3.90640623958
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.987041
 >> iter 2000, loss: 9.134515
 >> iter 3000, loss: 3.401987
 >> iter 4000, loss: 1.270216
 >> iter 5000, loss: 0.488703
 >> iter 6000, loss: 0.189881
 >> iter 7000, loss: 0.078222
 >> iter 8000, loss: 0.035866
 >> iter 9000, loss: 0.113397
 >> iter 10000, loss: 0.050241
   Number of active neurons: 9
 >> iter 11000, loss: 0.025033
 >> iter 12000, loss: 0.014889
 >> iter 13000, loss: 0.010734
 >> iter 14000, loss: 0.008828
 >> iter 15000, loss: 0.007926
 >> iter 16000, loss: 0.007355
 >> iter 17000, loss: 0.109414
 >> iter 18000, loss: 0.059167
 >> iter 19000, loss: 0.026943
 >> iter 20000, loss: 0.014507
   Number of active neurons: 9
 >> iter 21000, loss: 0.009656
 >> iter 22000, loss: 0.007656
 >> iter 23000, loss: 0.006740
 >> iter 24000, loss: 0.006282
 >> iter 25000, loss: 0.006018
 >> iter 26000, loss: 0.068637
 >> iter 27000, loss: 0.029420
 >> iter 28000, loss: 0.014701
 >> iter 29000, loss: 0.009143
 >> iter 30000, loss: 0.006980
   Number of active neurons: 7
 >> iter 31000, loss: 0.006112
 >> iter 32000, loss: 0.005716
 >> iter 33000, loss: 0.005521
 >> iter 34000, loss: 0.005401
 >> iter 35000, loss: 0.005311
 >> iter 36000, loss: 0.005249
 >> iter 37000, loss: 0.005185
 >> iter 38000, loss: 0.005140
 >> iter 39000, loss: 0.005088
 >> iter 40000, loss: 0.005052
   Number of active neurons: 7
 >> iter 41000, loss: 0.005000
 >> iter 42000, loss: 0.004971
 >> iter 43000, loss: 0.004923
 >> iter 44000, loss: 0.004904
 >> iter 45000, loss: 0.004864
 >> iter 46000, loss: 0.004844
 >> iter 47000, loss: 0.004804
 >> iter 48000, loss: 0.004795
 >> iter 49000, loss: 0.004753
 >> iter 50000, loss: 0.004741
   Number of active neurons: 8
 >> iter 51000, loss: 0.004704
 >> iter 52000, loss: 0.004702
 >> iter 53000, loss: 0.004663
 >> iter 54000, loss: 0.004662
 >> iter 55000, loss: 0.004626
 >> iter 56000, loss: 0.004627
 >> iter 57000, loss: 0.004599
 >> iter 58000, loss: 0.004598
 >> iter 59000, loss: 0.004570
 >> iter 60000, loss: 0.004572
   Number of active neurons: 8
 >> iter 61000, loss: 0.004563
 >> iter 62000, loss: 0.125230
 >> iter 63000, loss: 0.049662
 >> iter 64000, loss: 0.021521
 >> iter 65000, loss: 0.011078
 >> iter 66000, loss: 0.007155
 >> iter 67000, loss: 0.005678
 >> iter 68000, loss: 0.174067
 >> iter 69000, loss: 0.068131
 >> iter 70000, loss: 0.028797
   Number of active neurons: 7
 >> iter 71000, loss: 0.014094
 >> iter 72000, loss: 0.008567
 >> iter 73000, loss: 0.006421
 >> iter 74000, loss: 0.005582
 >> iter 75000, loss: 0.005207
 >> iter 76000, loss: 0.005053
 >> iter 77000, loss: 0.004944
 >> iter 78000, loss: 0.004907
 >> iter 79000, loss: 0.004849
 >> iter 80000, loss: 0.004836
   Number of active neurons: 8
 >> iter 81000, loss: 0.004793
 >> iter 82000, loss: 0.004788
 >> iter 83000, loss: 0.004746
 >> iter 84000, loss: 0.004738
 >> iter 85000, loss: 0.004700
 >> iter 86000, loss: 0.004692
 >> iter 87000, loss: 0.004649
 >> iter 88000, loss: 0.004646
 >> iter 89000, loss: 0.004599
 >> iter 90000, loss: 0.004603
   Number of active neurons: 8
 >> iter 91000, loss: 0.004557
 >> iter 92000, loss: 0.004565
 >> iter 93000, loss: 0.004524
 >> iter 94000, loss: 0.004534
 >> iter 95000, loss: 0.004503
 >> iter 96000, loss: 0.004508
 >> iter 97000, loss: 0.004478
 >> iter 98000, loss: 0.004487
 >> iter 99000, loss: 0.004461
 >> iter 100000, loss: 0.004469
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.00666622225185
   - Test - B: 5.53963069129
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.689890
 >> iter 2000, loss: 7.709864
 >> iter 3000, loss: 2.866689
 >> iter 4000, loss: 1.071691
 >> iter 5000, loss: 0.407073
 >> iter 6000, loss: 0.159864
 >> iter 7000, loss: 0.067631
 >> iter 8000, loss: 0.032480
 >> iter 9000, loss: 0.018993
 >> iter 10000, loss: 0.013329
   Number of active neurons: 10
 >> iter 11000, loss: 0.010967
 >> iter 12000, loss: 0.009636
 >> iter 13000, loss: 0.009000
 >> iter 14000, loss: 0.008438
 >> iter 15000, loss: 0.008151
 >> iter 16000, loss: 0.007794
 >> iter 17000, loss: 0.007629
 >> iter 18000, loss: 0.007364
 >> iter 19000, loss: 0.007258
 >> iter 20000, loss: 0.007048
   Number of active neurons: 10
 >> iter 21000, loss: 0.006985
 >> iter 22000, loss: 0.006809
 >> iter 23000, loss: 0.006760
 >> iter 24000, loss: 0.006604
 >> iter 25000, loss: 0.006571
 >> iter 26000, loss: 0.006433
 >> iter 27000, loss: 0.006412
 >> iter 28000, loss: 0.006291
 >> iter 29000, loss: 0.006280
 >> iter 30000, loss: 0.006172
   Number of active neurons: 10
 >> iter 31000, loss: 0.006168
 >> iter 32000, loss: 0.006060
 >> iter 33000, loss: 0.006053
 >> iter 34000, loss: 0.005955
 >> iter 35000, loss: 0.005946
 >> iter 36000, loss: 0.005859
 >> iter 37000, loss: 0.005856
 >> iter 38000, loss: 0.005773
 >> iter 39000, loss: 0.005777
 >> iter 40000, loss: 0.005700
   Number of active neurons: 10
 >> iter 41000, loss: 0.005704
 >> iter 42000, loss: 0.005631
 >> iter 43000, loss: 0.005637
 >> iter 44000, loss: 0.005568
 >> iter 45000, loss: 0.005579
 >> iter 46000, loss: 0.005507
 >> iter 47000, loss: 0.005519
 >> iter 48000, loss: 0.005458
 >> iter 49000, loss: 0.005467
 >> iter 50000, loss: 0.005414
   Number of active neurons: 10
 >> iter 51000, loss: 0.005420
 >> iter 52000, loss: 0.005380
 >> iter 53000, loss: 0.005381
 >> iter 54000, loss: 0.005342
 >> iter 55000, loss: 0.005344
 >> iter 56000, loss: 0.005306
 >> iter 57000, loss: 0.005311
 >> iter 58000, loss: 0.005271
 >> iter 59000, loss: 0.005274
 >> iter 60000, loss: 0.005234
   Number of active neurons: 10
 >> iter 61000, loss: 0.005239
 >> iter 62000, loss: 0.005199
 >> iter 63000, loss: 0.005210
 >> iter 64000, loss: 0.005173
 >> iter 65000, loss: 0.005183
 >> iter 66000, loss: 0.005150
 >> iter 67000, loss: 0.005157
 >> iter 68000, loss: 0.005125
 >> iter 69000, loss: 0.005126
 >> iter 70000, loss: 0.005099
   Number of active neurons: 10
 >> iter 71000, loss: 0.005110
 >> iter 72000, loss: 0.005075
 >> iter 73000, loss: 0.005091
 >> iter 74000, loss: 0.005055
 >> iter 75000, loss: 0.005072
 >> iter 76000, loss: 0.005041
 >> iter 77000, loss: 0.005051
 >> iter 78000, loss: 0.005020
 >> iter 79000, loss: 0.005030
 >> iter 80000, loss: 0.004999
   Number of active neurons: 9
 >> iter 81000, loss: 0.005010
 >> iter 82000, loss: 0.004983
 >> iter 83000, loss: 0.004993
 >> iter 84000, loss: 0.004963
 >> iter 85000, loss: 0.004979
 >> iter 86000, loss: 0.004949
 >> iter 87000, loss: 0.004960
 >> iter 88000, loss: 0.004936
 >> iter 89000, loss: 0.004944
 >> iter 90000, loss: 0.004921
   Number of active neurons: 9
 >> iter 91000, loss: 0.004929
 >> iter 92000, loss: 0.004906
 >> iter 93000, loss: 0.004916
 >> iter 94000, loss: 0.004893
 >> iter 95000, loss: 0.004911
 >> iter 96000, loss: 0.004881
 >> iter 97000, loss: 0.004899
 >> iter 98000, loss: 0.004868
 >> iter 99000, loss: 0.004888
 >> iter 100000, loss: 0.004852
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.504707
 >> iter 2000, loss: 7.409089
 >> iter 3000, loss: 2.763393
 >> iter 4000, loss: 1.036998
 >> iter 5000, loss: 0.396089
 >> iter 6000, loss: 0.156971
 >> iter 7000, loss: 0.067275
 >> iter 8000, loss: 0.032873
 >> iter 9000, loss: 0.019449
 >> iter 10000, loss: 0.013739
   Number of active neurons: 9
 >> iter 11000, loss: 0.011231
 >> iter 12000, loss: 0.009830
 >> iter 13000, loss: 0.009075
 >> iter 14000, loss: 0.008469
 >> iter 15000, loss: 0.008089
 >> iter 16000, loss: 0.007711
 >> iter 17000, loss: 0.007482
 >> iter 18000, loss: 0.007220
 >> iter 19000, loss: 0.007065
 >> iter 20000, loss: 0.006866
   Number of active neurons: 9
 >> iter 21000, loss: 0.006760
 >> iter 22000, loss: 0.006606
 >> iter 23000, loss: 0.006520
 >> iter 24000, loss: 0.006392
 >> iter 25000, loss: 0.006328
 >> iter 26000, loss: 0.006229
 >> iter 27000, loss: 0.006178
 >> iter 28000, loss: 0.006097
 >> iter 29000, loss: 0.006054
 >> iter 30000, loss: 0.005984
   Number of active neurons: 9
 >> iter 31000, loss: 0.005947
 >> iter 32000, loss: 0.005884
 >> iter 33000, loss: 0.005849
 >> iter 34000, loss: 0.005798
 >> iter 35000, loss: 0.005768
 >> iter 36000, loss: 0.005725
 >> iter 37000, loss: 0.005697
 >> iter 38000, loss: 0.005656
 >> iter 39000, loss: 0.005634
 >> iter 40000, loss: 0.005600
   Number of active neurons: 9
 >> iter 41000, loss: 0.005576
 >> iter 42000, loss: 0.005548
 >> iter 43000, loss: 0.005524
 >> iter 44000, loss: 0.005503
 >> iter 45000, loss: 0.005482
 >> iter 46000, loss: 0.005458
 >> iter 47000, loss: 0.005434
 >> iter 48000, loss: 0.005416
 >> iter 49000, loss: 0.005386
 >> iter 50000, loss: 0.005368
   Number of active neurons: 9
 >> iter 51000, loss: 0.005341
 >> iter 52000, loss: 0.005333
 >> iter 53000, loss: 0.005303
 >> iter 54000, loss: 0.005297
 >> iter 55000, loss: 0.005269
 >> iter 56000, loss: 0.005263
 >> iter 57000, loss: 0.005240
 >> iter 58000, loss: 0.005231
 >> iter 59000, loss: 0.005207
 >> iter 60000, loss: 0.005202
   Number of active neurons: 9
 >> iter 61000, loss: 0.005177
 >> iter 62000, loss: 0.005170
 >> iter 63000, loss: 0.005152
 >> iter 64000, loss: 0.005146
 >> iter 65000, loss: 0.005128
 >> iter 66000, loss: 0.005123
 >> iter 67000, loss: 0.005104
 >> iter 68000, loss: 0.005102
 >> iter 69000, loss: 0.005080
 >> iter 70000, loss: 0.005079
   Number of active neurons: 9
 >> iter 71000, loss: 0.005061
 >> iter 72000, loss: 0.005056
 >> iter 73000, loss: 0.005043
 >> iter 74000, loss: 0.005036
 >> iter 75000, loss: 0.005025
 >> iter 76000, loss: 0.005022
 >> iter 77000, loss: 0.005005
 >> iter 78000, loss: 0.005000
 >> iter 79000, loss: 0.004984
 >> iter 80000, loss: 0.004977
   Number of active neurons: 8
 >> iter 81000, loss: 0.004962
 >> iter 82000, loss: 0.004956
 >> iter 83000, loss: 0.004943
 >> iter 84000, loss: 0.004935
 >> iter 85000, loss: 0.004925
 >> iter 86000, loss: 0.004917
 >> iter 87000, loss: 0.004904
 >> iter 88000, loss: 0.004899
 >> iter 89000, loss: 0.004883
 >> iter 90000, loss: 0.004880
   Number of active neurons: 8
 >> iter 91000, loss: 0.004862
 >> iter 92000, loss: 0.004857
 >> iter 93000, loss: 0.004842
 >> iter 94000, loss: 0.004833
 >> iter 95000, loss: 0.004827
 >> iter 96000, loss: 0.004810
 >> iter 97000, loss: 0.004806
 >> iter 98000, loss: 0.004790
 >> iter 99000, loss: 0.004792
 >> iter 100000, loss: 0.004773
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 15.2789814012
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.728381
 >> iter 2000, loss: 7.820260
 >> iter 3000, loss: 2.908075
 >> iter 4000, loss: 1.084713
 >> iter 5000, loss: 0.410037
 >> iter 6000, loss: 0.159650
 >> iter 7000, loss: 0.066322
 >> iter 8000, loss: 0.031044
 >> iter 9000, loss: 0.017505
 >> iter 10000, loss: 0.011995
   Number of active neurons: 10
 >> iter 11000, loss: 0.009666
 >> iter 12000, loss: 0.008476
 >> iter 13000, loss: 0.007862
 >> iter 14000, loss: 0.007404
 >> iter 15000, loss: 0.007125
 >> iter 16000, loss: 0.006846
 >> iter 17000, loss: 0.006676
 >> iter 18000, loss: 0.006470
 >> iter 19000, loss: 0.006350
 >> iter 20000, loss: 0.006188
   Number of active neurons: 10
 >> iter 21000, loss: 0.006106
 >> iter 22000, loss: 0.005973
 >> iter 23000, loss: 0.005906
 >> iter 24000, loss: 0.005796
 >> iter 25000, loss: 0.005747
 >> iter 26000, loss: 0.005657
 >> iter 27000, loss: 0.005620
 >> iter 28000, loss: 0.005540
 >> iter 29000, loss: 0.005509
 >> iter 30000, loss: 0.005441
   Number of active neurons: 10
 >> iter 31000, loss: 0.005421
 >> iter 32000, loss: 0.005364
 >> iter 33000, loss: 0.005346
 >> iter 34000, loss: 0.005297
 >> iter 35000, loss: 0.005282
 >> iter 36000, loss: 0.005240
 >> iter 37000, loss: 0.005229
 >> iter 38000, loss: 0.005189
 >> iter 39000, loss: 0.005185
 >> iter 40000, loss: 0.005151
   Number of active neurons: 10
 >> iter 41000, loss: 0.005144
 >> iter 42000, loss: 0.005113
 >> iter 43000, loss: 0.005108
 >> iter 44000, loss: 0.005082
 >> iter 45000, loss: 0.005083
 >> iter 46000, loss: 0.005052
 >> iter 47000, loss: 0.005053
 >> iter 48000, loss: 0.005029
 >> iter 49000, loss: 0.005027
 >> iter 50000, loss: 0.005004
   Number of active neurons: 10
 >> iter 51000, loss: 0.005005
 >> iter 52000, loss: 0.004991
 >> iter 53000, loss: 0.004981
 >> iter 54000, loss: 0.004963
 >> iter 55000, loss: 0.004953
 >> iter 56000, loss: 0.004936
 >> iter 57000, loss: 0.004929
 >> iter 58000, loss: 0.004909
 >> iter 59000, loss: 0.004904
 >> iter 60000, loss: 0.004885
   Number of active neurons: 10
 >> iter 61000, loss: 0.004878
 >> iter 62000, loss: 0.004855
 >> iter 63000, loss: 0.004852
 >> iter 64000, loss: 0.004829
 >> iter 65000, loss: 0.004828
 >> iter 66000, loss: 0.004804
 >> iter 67000, loss: 0.004802
 >> iter 68000, loss: 0.004781
 >> iter 69000, loss: 0.004776
 >> iter 70000, loss: 0.004758
   Number of active neurons: 10
 >> iter 71000, loss: 0.004758
 >> iter 72000, loss: 0.004739
 >> iter 73000, loss: 0.004745
 >> iter 74000, loss: 0.004721
 >> iter 75000, loss: 0.004731
 >> iter 76000, loss: 0.004710
 >> iter 77000, loss: 0.004714
 >> iter 78000, loss: 0.004693
 >> iter 79000, loss: 0.004699
 >> iter 80000, loss: 0.004677
   Number of active neurons: 10
 >> iter 81000, loss: 0.004684
 >> iter 82000, loss: 0.004664
 >> iter 83000, loss: 0.004671
 >> iter 84000, loss: 0.004647
 >> iter 85000, loss: 0.004659
 >> iter 86000, loss: 0.004633
 >> iter 87000, loss: 0.004645
 >> iter 88000, loss: 0.004623
 >> iter 89000, loss: 0.004630
 >> iter 90000, loss: 0.004609
   Number of active neurons: 10
 >> iter 91000, loss: 0.004615
 >> iter 92000, loss: 0.004591
 >> iter 93000, loss: 0.004599
 >> iter 94000, loss: 0.004573
 >> iter 95000, loss: 0.004587
 >> iter 96000, loss: 0.004552
 >> iter 97000, loss: 0.004569
 >> iter 98000, loss: 0.004535
 >> iter 99000, loss: 0.004556
 >> iter 100000, loss: 0.004518
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 15.3323111793
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.479018
 >> iter 2000, loss: 8.366924
 >> iter 3000, loss: 3.122532
 >> iter 4000, loss: 1.173087
 >> iter 5000, loss: 0.449171
 >> iter 6000, loss: 0.178996
 >> iter 7000, loss: 0.077462
 >> iter 8000, loss: 0.038484
 >> iter 9000, loss: 0.023100
 >> iter 10000, loss: 0.016587
   Number of active neurons: 10
 >> iter 11000, loss: 0.013548
 >> iter 12000, loss: 0.011941
 >> iter 13000, loss: 0.010903
 >> iter 14000, loss: 0.010221
 >> iter 15000, loss: 0.009643
 >> iter 16000, loss: 0.009271
 >> iter 17000, loss: 0.008846
 >> iter 18000, loss: 0.008634
 >> iter 19000, loss: 0.008279
 >> iter 20000, loss: 0.008155
   Number of active neurons: 9
 >> iter 21000, loss: 0.007852
 >> iter 22000, loss: 0.007782
 >> iter 23000, loss: 0.007515
 >> iter 24000, loss: 0.007524
 >> iter 25000, loss: 0.007258
 >> iter 26000, loss: 0.007275
 >> iter 27000, loss: 0.007024
 >> iter 28000, loss: 0.007097
 >> iter 29000, loss: 0.006840
 >> iter 30000, loss: 0.006896
   Number of active neurons: 9
 >> iter 31000, loss: 0.006669
 >> iter 32000, loss: 0.006761
 >> iter 33000, loss: 0.006527
 >> iter 34000, loss: 0.006594
 >> iter 35000, loss: 0.006392
 >> iter 36000, loss: 0.006489
 >> iter 37000, loss: 0.006295
 >> iter 38000, loss: 0.006279
 >> iter 39000, loss: 0.006198
 >> iter 40000, loss: 0.006199
   Number of active neurons: 10
 >> iter 41000, loss: 0.006139
 >> iter 42000, loss: 0.005974
 >> iter 43000, loss: 0.006087
 >> iter 44000, loss: 0.005928
 >> iter 45000, loss: 0.006017
 >> iter 46000, loss: 0.005902
 >> iter 47000, loss: 0.005925
 >> iter 48000, loss: 0.005855
 >> iter 49000, loss: 0.007443
 >> iter 50000, loss: 0.053991
   Number of active neurons: 9
 >> iter 51000, loss: 0.024060
 >> iter 52000, loss: 0.012793
 >> iter 53000, loss: 0.008363
 >> iter 54000, loss: 0.006586
 >> iter 55000, loss: 0.006096
 >> iter 56000, loss: 0.005763
 >> iter 57000, loss: 0.005813
 >> iter 58000, loss: 0.005649
 >> iter 59000, loss: 0.005836
 >> iter 60000, loss: 0.005629
   Number of active neurons: 10
 >> iter 61000, loss: 0.005848
 >> iter 62000, loss: 0.005624
 >> iter 63000, loss: 0.005565
 >> iter 64000, loss: 0.005730
 >> iter 65000, loss: 0.005596
 >> iter 66000, loss: 0.005788
 >> iter 67000, loss: 0.005573
 >> iter 68000, loss: 0.005675
 >> iter 69000, loss: 0.005545
 >> iter 70000, loss: 0.005441
   Number of active neurons: 10
 >> iter 71000, loss: 0.173612
 >> iter 72000, loss: 0.070119
 >> iter 73000, loss: 0.030113
 >> iter 74000, loss: 0.014889
 >> iter 75000, loss: 0.009947
 >> iter 76000, loss: 0.007223
 >> iter 77000, loss: 0.006197
 >> iter 78000, loss: 0.005687
 >> iter 79000, loss: 0.006194
 >> iter 80000, loss: 0.005674
   Number of active neurons: 9
 >> iter 81000, loss: 0.005387
 >> iter 82000, loss: 0.005292
 >> iter 83000, loss: 0.005752
 >> iter 84000, loss: 0.005416
 >> iter 85000, loss: 0.005276
 >> iter 86000, loss: 0.010691
 >> iter 87000, loss: 0.007626
 >> iter 88000, loss: 0.006184
 >> iter 89000, loss: 0.013997
 >> iter 90000, loss: 0.008962
   Number of active neurons: 8
 >> iter 91000, loss: 0.013010
 >> iter 92000, loss: 0.036615
 >> iter 93000, loss: 0.017181
 >> iter 94000, loss: 0.009700
 >> iter 95000, loss: 0.007095
 >> iter 96000, loss: 0.005799
 >> iter 97000, loss: 0.005344
 >> iter 98000, loss: 0.005071
 >> iter 99000, loss: 0.005669
 >> iter 100000, loss: 0.005160
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.582382
 >> iter 2000, loss: 7.602520
 >> iter 3000, loss: 2.828916
 >> iter 4000, loss: 1.058446
 >> iter 5000, loss: 0.402522
 >> iter 6000, loss: 0.158335
 >> iter 7000, loss: 0.067145
 >> iter 8000, loss: 0.032310
 >> iter 9000, loss: 0.018928
 >> iter 10000, loss: 0.013259
   Number of active neurons: 10
 >> iter 11000, loss: 0.010917
 >> iter 12000, loss: 0.009560
 >> iter 13000, loss: 0.008940
 >> iter 14000, loss: 0.008353
 >> iter 15000, loss: 0.008085
 >> iter 16000, loss: 0.007703
 >> iter 17000, loss: 0.007561
 >> iter 18000, loss: 0.007271
 >> iter 19000, loss: 0.007186
 >> iter 20000, loss: 0.006953
   Number of active neurons: 10
 >> iter 21000, loss: 0.006914
 >> iter 22000, loss: 0.006724
 >> iter 23000, loss: 0.006710
 >> iter 24000, loss: 0.006543
 >> iter 25000, loss: 0.006543
 >> iter 26000, loss: 0.006394
 >> iter 27000, loss: 0.006401
 >> iter 28000, loss: 0.006277
 >> iter 29000, loss: 0.006288
 >> iter 30000, loss: 0.006183
   Number of active neurons: 10
 >> iter 31000, loss: 0.006197
 >> iter 32000, loss: 0.006105
 >> iter 33000, loss: 0.006119
 >> iter 34000, loss: 0.006045
 >> iter 35000, loss: 0.006055
 >> iter 36000, loss: 0.005988
 >> iter 37000, loss: 0.005999
 >> iter 38000, loss: 0.005938
 >> iter 39000, loss: 0.005953
 >> iter 40000, loss: 0.005899
   Number of active neurons: 9
 >> iter 41000, loss: 0.005911
 >> iter 42000, loss: 0.005863
 >> iter 43000, loss: 0.005871
 >> iter 44000, loss: 0.005829
 >> iter 45000, loss: 0.005837
 >> iter 46000, loss: 0.005791
 >> iter 47000, loss: 0.005798
 >> iter 48000, loss: 0.005764
 >> iter 49000, loss: 0.005766
 >> iter 50000, loss: 0.005737
   Number of active neurons: 9
 >> iter 51000, loss: 0.005736
 >> iter 52000, loss: 0.005717
 >> iter 53000, loss: 0.005705
 >> iter 54000, loss: 0.005684
 >> iter 55000, loss: 0.005670
 >> iter 56000, loss: 0.005647
 >> iter 57000, loss: 0.005637
 >> iter 58000, loss: 0.005617
 >> iter 59000, loss: 0.005604
 >> iter 60000, loss: 0.005577
   Number of active neurons: 9
 >> iter 61000, loss: 0.005571
 >> iter 62000, loss: 0.005541
 >> iter 63000, loss: 0.005542
 >> iter 64000, loss: 0.005512
 >> iter 65000, loss: 0.005512
 >> iter 66000, loss: 0.005481
 >> iter 67000, loss: 0.005482
 >> iter 68000, loss: 0.005448
 >> iter 69000, loss: 0.005444
 >> iter 70000, loss: 0.005412
   Number of active neurons: 9
 >> iter 71000, loss: 0.005419
 >> iter 72000, loss: 0.005378
 >> iter 73000, loss: 0.005391
 >> iter 74000, loss: 0.005346
 >> iter 75000, loss: 0.005363
 >> iter 76000, loss: 0.005324
 >> iter 77000, loss: 0.005335
 >> iter 78000, loss: 0.005295
 >> iter 79000, loss: 0.005309
 >> iter 80000, loss: 0.005264
   Number of active neurons: 9
 >> iter 81000, loss: 0.005280
 >> iter 82000, loss: 0.005238
 >> iter 83000, loss: 0.005254
 >> iter 84000, loss: 0.005206
 >> iter 85000, loss: 0.005227
 >> iter 86000, loss: 0.005175
 >> iter 87000, loss: 0.005193
 >> iter 88000, loss: 0.005148
 >> iter 89000, loss: 0.005158
 >> iter 90000, loss: 0.005114
   Number of active neurons: 9
 >> iter 91000, loss: 0.005125
 >> iter 92000, loss: 0.005081
 >> iter 93000, loss: 0.005095
 >> iter 94000, loss: 0.005049
 >> iter 95000, loss: 0.005074
 >> iter 96000, loss: 0.005017
 >> iter 97000, loss: 0.005043
 >> iter 98000, loss: 0.004985
 >> iter 99000, loss: 0.005019
 >> iter 100000, loss: 0.004960
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 11.1725884941
   - Test - B: 19.0920605293
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.968352
 >> iter 2000, loss: 8.819528
 >> iter 3000, loss: 3.351688
 >> iter 4000, loss: 1.263568
 >> iter 5000, loss: 0.522416
 >> iter 6000, loss: 0.207935
 >> iter 7000, loss: 0.092727
 >> iter 8000, loss: 0.044292
 >> iter 9000, loss: 0.025536
 >> iter 10000, loss: 0.016830
   Number of active neurons: 10
 >> iter 11000, loss: 0.013620
 >> iter 12000, loss: 0.011467
 >> iter 13000, loss: 0.058134
 >> iter 14000, loss: 0.028017
 >> iter 15000, loss: 0.023895
 >> iter 16000, loss: 0.014841
 >> iter 17000, loss: 0.010967
 >> iter 18000, loss: 0.009143
 >> iter 19000, loss: 0.011540
 >> iter 20000, loss: 0.009566
   Number of active neurons: 10
 >> iter 21000, loss: 0.008437
 >> iter 22000, loss: 0.007718
 >> iter 23000, loss: 0.007371
 >> iter 24000, loss: 0.007286
 >> iter 25000, loss: 0.007068
 >> iter 26000, loss: 0.006794
 >> iter 27000, loss: 0.006723
 >> iter 28000, loss: 0.006553
 >> iter 29000, loss: 0.006563
 >> iter 30000, loss: 0.006452
   Number of active neurons: 10
 >> iter 31000, loss: 0.006513
 >> iter 32000, loss: 0.006420
 >> iter 33000, loss: 0.010446
 >> iter 34000, loss: 0.008026
 >> iter 35000, loss: 0.063124
 >> iter 36000, loss: 0.027103
 >> iter 37000, loss: 0.014127
 >> iter 38000, loss: 0.008749
 >> iter 39000, loss: 0.006743
 >> iter 40000, loss: 0.005973
   Number of active neurons: 10
 >> iter 41000, loss: 0.005797
 >> iter 42000, loss: 0.005697
 >> iter 43000, loss: 0.005720
 >> iter 44000, loss: 0.005728
 >> iter 45000, loss: 0.060873
 >> iter 46000, loss: 0.026495
 >> iter 47000, loss: 0.015874
 >> iter 48000, loss: 0.009868
 >> iter 49000, loss: 0.007365
 >> iter 50000, loss: 0.006251
   Number of active neurons: 10
 >> iter 51000, loss: 0.005864
 >> iter 52000, loss: 0.005699
 >> iter 53000, loss: 0.005588
 >> iter 54000, loss: 0.005552
 >> iter 55000, loss: 0.053941
 >> iter 56000, loss: 0.024076
 >> iter 57000, loss: 0.012987
 >> iter 58000, loss: 0.008378
 >> iter 59000, loss: 0.008240
 >> iter 60000, loss: 0.006853
   Number of active neurons: 9
 >> iter 61000, loss: 0.006201
 >> iter 62000, loss: 0.005689
 >> iter 63000, loss: 0.005468
 >> iter 64000, loss: 0.005398
 >> iter 65000, loss: 0.024986
 >> iter 66000, loss: 0.013376
 >> iter 67000, loss: 0.008368
 >> iter 68000, loss: 0.006492
 >> iter 69000, loss: 0.007407
 >> iter 70000, loss: 0.006396
   Number of active neurons: 8
 >> iter 71000, loss: 0.005944
 >> iter 72000, loss: 0.005527
 >> iter 73000, loss: 0.005340
 >> iter 74000, loss: 0.005577
 >> iter 75000, loss: 0.005442
 >> iter 76000, loss: 0.005364
 >> iter 77000, loss: 0.005340
 >> iter 78000, loss: 0.005328
 >> iter 79000, loss: 0.005329
 >> iter 80000, loss: 0.005351
   Number of active neurons: 9
 >> iter 81000, loss: 0.005364
 >> iter 82000, loss: 0.005404
 >> iter 83000, loss: 0.005405
 >> iter 84000, loss: 0.005419
 >> iter 85000, loss: 0.005432
 >> iter 86000, loss: 0.005461
 >> iter 87000, loss: 0.005443
 >> iter 88000, loss: 0.005470
 >> iter 89000, loss: 0.005502
 >> iter 90000, loss: 0.005466
   Number of active neurons: 9
 >> iter 91000, loss: 0.005444
 >> iter 92000, loss: 0.005499
 >> iter 93000, loss: 0.005452
 >> iter 94000, loss: 0.005476
 >> iter 95000, loss: 0.005558
 >> iter 96000, loss: 0.005447
 >> iter 97000, loss: 0.005436
 >> iter 98000, loss: 0.005451
 >> iter 99000, loss: 0.005444
 >> iter 100000, loss: 0.005457
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0249987500625
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 6.95953603093
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.562386
 >> iter 2000, loss: 7.467151
 >> iter 3000, loss: 2.773234
 >> iter 4000, loss: 1.035348
 >> iter 5000, loss: 0.392199
 >> iter 6000, loss: 0.153339
 >> iter 7000, loss: 0.064287
 >> iter 8000, loss: 0.030529
 >> iter 9000, loss: 0.017593
 >> iter 10000, loss: 0.012264
   Number of active neurons: 10
 >> iter 11000, loss: 0.010038
 >> iter 12000, loss: 0.008845
 >> iter 13000, loss: 0.008280
 >> iter 14000, loss: 0.007782
 >> iter 15000, loss: 0.007549
 >> iter 16000, loss: 0.007218
 >> iter 17000, loss: 0.007093
 >> iter 18000, loss: 0.006841
 >> iter 19000, loss: 0.006772
 >> iter 20000, loss: 0.006568
   Number of active neurons: 10
 >> iter 21000, loss: 0.006541
 >> iter 22000, loss: 0.006369
 >> iter 23000, loss: 0.006361
 >> iter 24000, loss: 0.006209
 >> iter 25000, loss: 0.006213
 >> iter 26000, loss: 0.006078
 >> iter 27000, loss: 0.006087
 >> iter 28000, loss: 0.005967
 >> iter 29000, loss: 0.005981
 >> iter 30000, loss: 0.005878
   Number of active neurons: 9
 >> iter 31000, loss: 0.005899
 >> iter 32000, loss: 0.005806
 >> iter 33000, loss: 0.005824
 >> iter 34000, loss: 0.005743
 >> iter 35000, loss: 0.005758
 >> iter 36000, loss: 0.005685
 >> iter 37000, loss: 0.005703
 >> iter 38000, loss: 0.005630
 >> iter 39000, loss: 0.005651
 >> iter 40000, loss: 0.005585
   Number of active neurons: 9
 >> iter 41000, loss: 0.005596
 >> iter 42000, loss: 0.005538
 >> iter 43000, loss: 0.005545
 >> iter 44000, loss: 0.005493
 >> iter 45000, loss: 0.005501
 >> iter 46000, loss: 0.005446
 >> iter 47000, loss: 0.005450
 >> iter 48000, loss: 0.005405
 >> iter 49000, loss: 0.005405
 >> iter 50000, loss: 0.005364
   Number of active neurons: 9
 >> iter 51000, loss: 0.005363
 >> iter 52000, loss: 0.005331
 >> iter 53000, loss: 0.005323
 >> iter 54000, loss: 0.005291
 >> iter 55000, loss: 0.005285
 >> iter 56000, loss: 0.005255
 >> iter 57000, loss: 0.005251
 >> iter 58000, loss: 0.005218
 >> iter 59000, loss: 0.005213
 >> iter 60000, loss: 0.005182
   Number of active neurons: 9
 >> iter 61000, loss: 0.005177
 >> iter 62000, loss: 0.005144
 >> iter 63000, loss: 0.005146
 >> iter 64000, loss: 0.005114
 >> iter 65000, loss: 0.005109
 >> iter 66000, loss: 0.005076
 >> iter 67000, loss: 0.005074
 >> iter 68000, loss: 0.005043
 >> iter 69000, loss: 0.005038
 >> iter 70000, loss: 0.005011
   Number of active neurons: 9
 >> iter 71000, loss: 0.005012
 >> iter 72000, loss: 0.004981
 >> iter 73000, loss: 0.004986
 >> iter 74000, loss: 0.004954
 >> iter 75000, loss: 0.004960
 >> iter 76000, loss: 0.004934
 >> iter 77000, loss: 0.004935
 >> iter 78000, loss: 0.004910
 >> iter 79000, loss: 0.004912
 >> iter 80000, loss: 0.004883
   Number of active neurons: 9
 >> iter 81000, loss: 0.004886
 >> iter 82000, loss: 0.004862
 >> iter 83000, loss: 0.004864
 >> iter 84000, loss: 0.004837
 >> iter 85000, loss: 0.004840
 >> iter 86000, loss: 0.004814
 >> iter 87000, loss: 0.004811
 >> iter 88000, loss: 0.004794
 >> iter 89000, loss: 0.004786
 >> iter 90000, loss: 0.004775
   Number of active neurons: 9
 >> iter 91000, loss: 0.004766
 >> iter 92000, loss: 0.004759
 >> iter 93000, loss: 0.004750
 >> iter 94000, loss: 0.004744
 >> iter 95000, loss: 0.004746
 >> iter 96000, loss: 0.004731
 >> iter 97000, loss: 0.004735
 >> iter 98000, loss: 0.004722
 >> iter 99000, loss: 0.004729
 >> iter 100000, loss: 0.004717
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 9.11939204053
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.381335
 >> iter 2000, loss: 7.438966
 >> iter 3000, loss: 2.980790
 >> iter 4000, loss: 1.125831
 >> iter 5000, loss: 0.428322
 >> iter 6000, loss: 0.167358
 >> iter 7000, loss: 0.069385
 >> iter 8000, loss: 0.032061
 >> iter 9000, loss: 0.017601
 >> iter 10000, loss: 0.011683
   Number of active neurons: 10
 >> iter 11000, loss: 0.009172
 >> iter 12000, loss: 0.007915
 >> iter 13000, loss: 0.007273
 >> iter 14000, loss: 0.006826
 >> iter 15000, loss: 0.006557
 >> iter 16000, loss: 0.006314
 >> iter 17000, loss: 0.006169
 >> iter 18000, loss: 0.006019
 >> iter 19000, loss: 0.005938
 >> iter 20000, loss: 0.005839
   Number of active neurons: 10
 >> iter 21000, loss: 0.005792
 >> iter 22000, loss: 0.005727
 >> iter 23000, loss: 0.005687
 >> iter 24000, loss: 0.005640
 >> iter 25000, loss: 0.005603
 >> iter 26000, loss: 0.005569
 >> iter 27000, loss: 0.005531
 >> iter 28000, loss: 0.005500
 >> iter 29000, loss: 0.005466
 >> iter 30000, loss: 0.005438
   Number of active neurons: 10
 >> iter 31000, loss: 0.005411
 >> iter 32000, loss: 0.005387
 >> iter 33000, loss: 0.005361
 >> iter 34000, loss: 0.005342
 >> iter 35000, loss: 0.005316
 >> iter 36000, loss: 0.005300
 >> iter 37000, loss: 0.005275
 >> iter 38000, loss: 0.005258
 >> iter 39000, loss: 0.005240
 >> iter 40000, loss: 0.005230
   Number of active neurons: 10
 >> iter 41000, loss: 0.005208
 >> iter 42000, loss: 0.005198
 >> iter 43000, loss: 0.005174
 >> iter 44000, loss: 0.005169
 >> iter 45000, loss: 0.005150
 >> iter 46000, loss: 0.005144
 >> iter 47000, loss: 0.005126
 >> iter 48000, loss: 0.005130
 >> iter 49000, loss: 0.005104
 >> iter 50000, loss: 0.005115
   Number of active neurons: 10
 >> iter 51000, loss: 0.005084
 >> iter 52000, loss: 0.005108
 >> iter 53000, loss: 0.005068
 >> iter 54000, loss: 0.005096
 >> iter 55000, loss: 0.005053
 >> iter 56000, loss: 0.005087
 >> iter 57000, loss: 0.005042
 >> iter 58000, loss: 0.005077
 >> iter 59000, loss: 0.005028
 >> iter 60000, loss: 0.005068
   Number of active neurons: 10
 >> iter 61000, loss: 0.005018
 >> iter 62000, loss: 0.005053
 >> iter 63000, loss: 0.005006
 >> iter 64000, loss: 0.005046
 >> iter 65000, loss: 0.004995
 >> iter 66000, loss: 0.005035
 >> iter 67000, loss: 0.004980
 >> iter 68000, loss: 0.005019
 >> iter 69000, loss: 0.004960
 >> iter 70000, loss: 0.004998
   Number of active neurons: 10
 >> iter 71000, loss: 0.004945
 >> iter 72000, loss: 0.004977
 >> iter 73000, loss: 0.004928
 >> iter 74000, loss: 0.004946
 >> iter 75000, loss: 0.004903
 >> iter 76000, loss: 0.004920
 >> iter 77000, loss: 0.004871
 >> iter 78000, loss: 0.004887
 >> iter 79000, loss: 0.004842
 >> iter 80000, loss: 0.004854
   Number of active neurons: 9
 >> iter 81000, loss: 0.004810
 >> iter 82000, loss: 0.004820
 >> iter 83000, loss: 0.004778
 >> iter 84000, loss: 0.004782
 >> iter 85000, loss: 0.004748
 >> iter 86000, loss: 0.004750
 >> iter 87000, loss: 0.004719
 >> iter 88000, loss: 0.004723
 >> iter 89000, loss: 0.004693
 >> iter 90000, loss: 0.004698
   Number of active neurons: 8
 >> iter 91000, loss: 0.004671
 >> iter 92000, loss: 0.004672
 >> iter 93000, loss: 0.004653
 >> iter 94000, loss: 0.004647
 >> iter 95000, loss: 0.004641
 >> iter 96000, loss: 0.004622
 >> iter 97000, loss: 0.004620
 >> iter 98000, loss: 0.004597
 >> iter 99000, loss: 0.004602
 >> iter 100000, loss: 0.004578
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0666622225185
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.869911
 >> iter 2000, loss: 8.560416
 >> iter 3000, loss: 3.181631
 >> iter 4000, loss: 1.188179
 >> iter 5000, loss: 0.449601
 >> iter 6000, loss: 0.175341
 >> iter 7000, loss: 0.072927
 >> iter 8000, loss: 0.034178
 >> iter 9000, loss: 0.019212
 >> iter 10000, loss: 0.013117
   Number of active neurons: 10
 >> iter 11000, loss: 0.010470
 >> iter 12000, loss: 0.009150
 >> iter 13000, loss: 0.008413
 >> iter 14000, loss: 0.007924
 >> iter 15000, loss: 0.007570
 >> iter 16000, loss: 0.007274
 >> iter 17000, loss: 0.007145
 >> iter 18000, loss: 0.006872
 >> iter 19000, loss: 0.006683
 >> iter 20000, loss: 0.006536
   Number of active neurons: 9
 >> iter 21000, loss: 0.006390
 >> iter 22000, loss: 0.006264
 >> iter 23000, loss: 0.006154
 >> iter 24000, loss: 0.006047
 >> iter 25000, loss: 0.005988
 >> iter 26000, loss: 0.005880
 >> iter 27000, loss: 0.005812
 >> iter 28000, loss: 0.005739
 >> iter 29000, loss: 0.005677
 >> iter 30000, loss: 0.005606
   Number of active neurons: 10
 >> iter 31000, loss: 0.005558
 >> iter 32000, loss: 0.005495
 >> iter 33000, loss: 0.005453
 >> iter 34000, loss: 0.005400
 >> iter 35000, loss: 0.005360
 >> iter 36000, loss: 0.005316
 >> iter 37000, loss: 0.005279
 >> iter 38000, loss: 0.005236
 >> iter 39000, loss: 0.005204
 >> iter 40000, loss: 0.005163
   Number of active neurons: 9
 >> iter 41000, loss: 0.005134
 >> iter 42000, loss: 0.005096
 >> iter 43000, loss: 0.005067
 >> iter 44000, loss: 0.005029
 >> iter 45000, loss: 0.005008
 >> iter 46000, loss: 0.004966
 >> iter 47000, loss: 0.004946
 >> iter 48000, loss: 0.004908
 >> iter 49000, loss: 0.004892
 >> iter 50000, loss: 0.004854
   Number of active neurons: 9
 >> iter 51000, loss: 0.004844
 >> iter 52000, loss: 0.004815
 >> iter 53000, loss: 0.004801
 >> iter 54000, loss: 0.004770
 >> iter 55000, loss: 0.004761
 >> iter 56000, loss: 0.004727
 >> iter 57000, loss: 0.004728
 >> iter 58000, loss: 0.004688
 >> iter 59000, loss: 0.004695
 >> iter 60000, loss: 0.004657
   Number of active neurons: 9
 >> iter 61000, loss: 0.004667
 >> iter 62000, loss: 0.004621
 >> iter 63000, loss: 0.004640
 >> iter 64000, loss: 0.004590
 >> iter 65000, loss: 0.004617
 >> iter 66000, loss: 0.004561
 >> iter 67000, loss: 0.004593
 >> iter 68000, loss: 0.004541
 >> iter 69000, loss: 0.004565
 >> iter 70000, loss: 0.004511
   Number of active neurons: 9
 >> iter 71000, loss: 0.004540
 >> iter 72000, loss: 0.004485
 >> iter 73000, loss: 0.004516
 >> iter 74000, loss: 0.004458
 >> iter 75000, loss: 0.004489
 >> iter 76000, loss: 0.004433
 >> iter 77000, loss: 0.004459
 >> iter 78000, loss: 0.004403
 >> iter 79000, loss: 0.004431
 >> iter 80000, loss: 0.004375
   Number of active neurons: 9
 >> iter 81000, loss: 0.004404
 >> iter 82000, loss: 0.004351
 >> iter 83000, loss: 0.004380
 >> iter 84000, loss: 0.004325
 >> iter 85000, loss: 0.004359
 >> iter 86000, loss: 0.004303
 >> iter 87000, loss: 0.004330
 >> iter 88000, loss: 0.004281
 >> iter 89000, loss: 0.004305
 >> iter 90000, loss: 0.004261
   Number of active neurons: 9
 >> iter 91000, loss: 0.004283
 >> iter 92000, loss: 0.004239
 >> iter 93000, loss: 0.004265
 >> iter 94000, loss: 0.004218
 >> iter 95000, loss: 0.004252
 >> iter 96000, loss: 0.004198
 >> iter 97000, loss: 0.004228
 >> iter 98000, loss: 0.004170
 >> iter 99000, loss: 0.004202
 >> iter 100000, loss: 0.004141
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 4.45303646424
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.181634
 >> iter 2000, loss: 7.041048
 >> iter 3000, loss: 2.619406
 >> iter 4000, loss: 1.014425
 >> iter 5000, loss: 0.386294
 >> iter 6000, loss: 0.152437
 >> iter 7000, loss: 0.064817
 >> iter 8000, loss: 0.031453
 >> iter 9000, loss: 0.018432
 >> iter 10000, loss: 0.013025
   Number of active neurons: 10
 >> iter 11000, loss: 0.010615
 >> iter 12000, loss: 0.009351
 >> iter 13000, loss: 0.008626
 >> iter 14000, loss: 0.008103
 >> iter 15000, loss: 0.007733
 >> iter 16000, loss: 0.007413
 >> iter 17000, loss: 0.007171
 >> iter 18000, loss: 0.006942
 >> iter 19000, loss: 0.006763
 >> iter 20000, loss: 0.006584
   Number of active neurons: 10
 >> iter 21000, loss: 0.006456
 >> iter 22000, loss: 0.006311
 >> iter 23000, loss: 0.006210
 >> iter 24000, loss: 0.006087
 >> iter 25000, loss: 0.006008
 >> iter 26000, loss: 0.005898
 >> iter 27000, loss: 0.005836
 >> iter 28000, loss: 0.005741
 >> iter 29000, loss: 0.005694
 >> iter 30000, loss: 0.005606
   Number of active neurons: 8
 >> iter 31000, loss: 0.005584
 >> iter 32000, loss: 0.005488
 >> iter 33000, loss: 0.005483
 >> iter 34000, loss: 0.005385
 >> iter 35000, loss: 0.005389
 >> iter 36000, loss: 0.005293
 >> iter 37000, loss: 0.005298
 >> iter 38000, loss: 0.005202
 >> iter 39000, loss: 0.005230
 >> iter 40000, loss: 0.005128
   Number of active neurons: 7
 >> iter 41000, loss: 0.005160
 >> iter 42000, loss: 0.005059
 >> iter 43000, loss: 0.005101
 >> iter 44000, loss: 0.005001
 >> iter 45000, loss: 0.005045
 >> iter 46000, loss: 0.004936
 >> iter 47000, loss: 0.004984
 >> iter 48000, loss: 0.004884
 >> iter 49000, loss: 0.004928
 >> iter 50000, loss: 0.004830
   Number of active neurons: 7
 >> iter 51000, loss: 0.004877
 >> iter 52000, loss: 0.004789
 >> iter 53000, loss: 0.004808
 >> iter 54000, loss: 0.004732
 >> iter 55000, loss: 0.004766
 >> iter 56000, loss: 0.004690
 >> iter 57000, loss: 0.004733
 >> iter 58000, loss: 0.004655
 >> iter 59000, loss: 0.004701
 >> iter 60000, loss: 0.004627
   Number of active neurons: 7
 >> iter 61000, loss: 0.004664
 >> iter 62000, loss: 0.004590
 >> iter 63000, loss: 0.004633
 >> iter 64000, loss: 0.004561
 >> iter 65000, loss: 0.004607
 >> iter 66000, loss: 0.004536
 >> iter 67000, loss: 0.004581
 >> iter 68000, loss: 0.004516
 >> iter 69000, loss: 0.004556
 >> iter 70000, loss: 0.004495
   Number of active neurons: 7
 >> iter 71000, loss: 0.004539
 >> iter 72000, loss: 0.004476
 >> iter 73000, loss: 0.004523
 >> iter 74000, loss: 0.004457
 >> iter 75000, loss: 0.004506
 >> iter 76000, loss: 0.004443
 >> iter 77000, loss: 0.004486
 >> iter 78000, loss: 0.004424
 >> iter 79000, loss: 0.004471
 >> iter 80000, loss: 0.004406
   Number of active neurons: 7
 >> iter 81000, loss: 0.004456
 >> iter 82000, loss: 0.004393
 >> iter 83000, loss: 0.004441
 >> iter 84000, loss: 0.004376
 >> iter 85000, loss: 0.004432
 >> iter 86000, loss: 0.004364
 >> iter 87000, loss: 0.004427
 >> iter 88000, loss: 0.004355
 >> iter 89000, loss: 0.004406
 >> iter 90000, loss: 0.004342
   Number of active neurons: 7
 >> iter 91000, loss: 0.004388
 >> iter 92000, loss: 0.004327
 >> iter 93000, loss: 0.004374
 >> iter 94000, loss: 0.004313
 >> iter 95000, loss: 0.004367
 >> iter 96000, loss: 0.004299
 >> iter 97000, loss: 0.004350
 >> iter 98000, loss: 0.004289
 >> iter 99000, loss: 0.004343
 >> iter 100000, loss: 0.004282
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 5.09966002267
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.069794
 >> iter 2000, loss: 8.528327
 >> iter 3000, loss: 3.254458
 >> iter 4000, loss: 1.218992
 >> iter 5000, loss: 0.462819
 >> iter 6000, loss: 0.181246
 >> iter 7000, loss: 0.075807
 >> iter 8000, loss: 0.035703
 >> iter 9000, loss: 0.020148
 >> iter 10000, loss: 0.013724
   Number of active neurons: 10
 >> iter 11000, loss: 0.010941
 >> iter 12000, loss: 0.009483
 >> iter 13000, loss: 0.008698
 >> iter 14000, loss: 0.008117
 >> iter 15000, loss: 0.007746
 >> iter 16000, loss: 0.007398
 >> iter 17000, loss: 0.007168
 >> iter 18000, loss: 0.006922
 >> iter 19000, loss: 0.006760
 >> iter 20000, loss: 0.006572
   Number of active neurons: 9
 >> iter 21000, loss: 0.006455
 >> iter 22000, loss: 0.006312
 >> iter 23000, loss: 0.006219
 >> iter 24000, loss: 0.006105
 >> iter 25000, loss: 0.006030
 >> iter 26000, loss: 0.005935
 >> iter 27000, loss: 0.005871
 >> iter 28000, loss: 0.005790
 >> iter 29000, loss: 0.005734
 >> iter 30000, loss: 0.005667
   Number of active neurons: 8
 >> iter 31000, loss: 0.005619
 >> iter 32000, loss: 0.005564
 >> iter 33000, loss: 0.005517
 >> iter 34000, loss: 0.005475
 >> iter 35000, loss: 0.005431
 >> iter 36000, loss: 0.005402
 >> iter 37000, loss: 0.005360
 >> iter 38000, loss: 0.005339
 >> iter 39000, loss: 0.005295
 >> iter 40000, loss: 0.005286
   Number of active neurons: 8
 >> iter 41000, loss: 0.005233
 >> iter 42000, loss: 0.005233
 >> iter 43000, loss: 0.005175
 >> iter 44000, loss: 0.005184
 >> iter 45000, loss: 0.005125
 >> iter 46000, loss: 0.005132
 >> iter 47000, loss: 0.005067
 >> iter 48000, loss: 0.005073
 >> iter 49000, loss: 0.005006
 >> iter 50000, loss: 0.005003
   Number of active neurons: 8
 >> iter 51000, loss: 0.004944
 >> iter 52000, loss: 0.004938
 >> iter 53000, loss: 0.004881
 >> iter 54000, loss: 0.004865
 >> iter 55000, loss: 0.004817
 >> iter 56000, loss: 0.004803
 >> iter 57000, loss: 0.004765
 >> iter 58000, loss: 0.004755
 >> iter 59000, loss: 0.004720
 >> iter 60000, loss: 0.004715
   Number of active neurons: 9
 >> iter 61000, loss: 0.004681
 >> iter 62000, loss: 0.004672
 >> iter 63000, loss: 0.004646
 >> iter 64000, loss: 0.004640
 >> iter 65000, loss: 0.004617
 >> iter 66000, loss: 0.004614
 >> iter 67000, loss: 0.004593
 >> iter 68000, loss: 0.004596
 >> iter 69000, loss: 0.004571
 >> iter 70000, loss: 0.004577
   Number of active neurons: 9
 >> iter 71000, loss: 0.004557
 >> iter 72000, loss: 0.004561
 >> iter 73000, loss: 0.004546
 >> iter 74000, loss: 0.004547
 >> iter 75000, loss: 0.004533
 >> iter 76000, loss: 0.004538
 >> iter 77000, loss: 0.004520
 >> iter 78000, loss: 0.004527
 >> iter 79000, loss: 0.004512
 >> iter 80000, loss: 0.004518
   Number of active neurons: 9
 >> iter 81000, loss: 0.004506
 >> iter 82000, loss: 0.004512
 >> iter 83000, loss: 0.004499
 >> iter 84000, loss: 0.004502
 >> iter 85000, loss: 0.004492
 >> iter 86000, loss: 0.004497
 >> iter 87000, loss: 0.004482
 >> iter 88000, loss: 0.004491
 >> iter 89000, loss: 0.004470
 >> iter 90000, loss: 0.004484
   Number of active neurons: 9
 >> iter 91000, loss: 0.004460
 >> iter 92000, loss: 0.004476
 >> iter 93000, loss: 0.004450
 >> iter 94000, loss: 0.004461
 >> iter 95000, loss: 0.004440
 >> iter 96000, loss: 0.004439
 >> iter 97000, loss: 0.004420
 >> iter 98000, loss: 0.004417
 >> iter 99000, loss: 0.004406
 >> iter 100000, loss: 0.004401
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0039999600004
   - Test - A: 0.0
   - Test - B: 20.2119858676
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.807446
 >> iter 2000, loss: 8.123092
 >> iter 3000, loss: 3.352945
 >> iter 4000, loss: 1.319794
 >> iter 5000, loss: 0.501368
 >> iter 6000, loss: 0.205465
 >> iter 7000, loss: 0.140438
 >> iter 8000, loss: 0.060820
 >> iter 9000, loss: 0.030920
 >> iter 10000, loss: 0.018069
   Number of active neurons: 10
 >> iter 11000, loss: 0.013122
 >> iter 12000, loss: 0.010478
 >> iter 13000, loss: 0.009664
 >> iter 14000, loss: 0.008603
 >> iter 15000, loss: 0.008380
 >> iter 16000, loss: 0.007721
 >> iter 17000, loss: 0.007806
 >> iter 18000, loss: 0.007227
 >> iter 19000, loss: 0.007274
 >> iter 20000, loss: 0.006826
   Number of active neurons: 10
 >> iter 21000, loss: 0.007017
 >> iter 22000, loss: 0.006579
 >> iter 23000, loss: 0.006792
 >> iter 24000, loss: 0.006368
 >> iter 25000, loss: 0.006655
 >> iter 26000, loss: 0.006209
 >> iter 27000, loss: 0.007455
 >> iter 28000, loss: 0.006432
 >> iter 29000, loss: 0.006269
 >> iter 30000, loss: 0.005901
   Number of active neurons: 10
 >> iter 31000, loss: 0.008949
 >> iter 32000, loss: 0.006882
 >> iter 33000, loss: 0.006083
 >> iter 34000, loss: 0.005700
 >> iter 35000, loss: 0.005908
 >> iter 36000, loss: 0.005613
 >> iter 37000, loss: 0.005863
 >> iter 38000, loss: 0.005566
 >> iter 39000, loss: 0.005835
 >> iter 40000, loss: 0.005529
   Number of active neurons: 9
 >> iter 41000, loss: 0.005765
 >> iter 42000, loss: 0.005480
 >> iter 43000, loss: 0.005743
 >> iter 44000, loss: 0.005449
 >> iter 45000, loss: 0.005694
 >> iter 46000, loss: 0.005413
 >> iter 47000, loss: 0.005657
 >> iter 48000, loss: 0.005389
 >> iter 49000, loss: 0.005610
 >> iter 50000, loss: 0.005360
   Number of active neurons: 9
 >> iter 51000, loss: 0.005557
 >> iter 52000, loss: 0.005345
 >> iter 53000, loss: 0.005511
 >> iter 54000, loss: 0.005334
 >> iter 55000, loss: 0.005459
 >> iter 56000, loss: 0.005340
 >> iter 57000, loss: 0.005410
 >> iter 58000, loss: 0.005345
 >> iter 59000, loss: 0.005357
 >> iter 60000, loss: 0.005351
   Number of active neurons: 9
 >> iter 61000, loss: 0.005320
 >> iter 62000, loss: 0.005341
 >> iter 63000, loss: 0.005289
 >> iter 64000, loss: 0.005332
 >> iter 65000, loss: 0.005266
 >> iter 66000, loss: 0.005323
 >> iter 67000, loss: 0.005246
 >> iter 68000, loss: 0.005296
 >> iter 69000, loss: 0.005221
 >> iter 70000, loss: 0.005273
   Number of active neurons: 9
 >> iter 71000, loss: 0.005209
 >> iter 72000, loss: 0.005262
 >> iter 73000, loss: 0.005201
 >> iter 74000, loss: 0.005251
 >> iter 75000, loss: 0.005193
 >> iter 76000, loss: 0.005247
 >> iter 77000, loss: 0.005182
 >> iter 78000, loss: 0.005235
 >> iter 79000, loss: 0.005175
 >> iter 80000, loss: 0.005221
   Number of active neurons: 9
 >> iter 81000, loss: 0.005166
 >> iter 82000, loss: 0.005208
 >> iter 83000, loss: 0.005159
 >> iter 84000, loss: 0.005192
 >> iter 85000, loss: 0.005155
 >> iter 86000, loss: 0.005181
 >> iter 87000, loss: 0.005143
 >> iter 88000, loss: 0.005166
 >> iter 89000, loss: 0.005131
 >> iter 90000, loss: 0.005155
   Number of active neurons: 9
 >> iter 91000, loss: 0.005124
 >> iter 92000, loss: 0.005144
 >> iter 93000, loss: 0.005118
 >> iter 94000, loss: 0.005132
 >> iter 95000, loss: 0.005119
 >> iter 96000, loss: 0.005121
 >> iter 97000, loss: 0.005114
 >> iter 98000, loss: 0.005111
 >> iter 99000, loss: 0.005113
 >> iter 100000, loss: 0.005102
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 18.4587694154
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.433173
 >> iter 2000, loss: 7.273807
 >> iter 3000, loss: 2.704147
 >> iter 4000, loss: 1.011068
 >> iter 5000, loss: 0.384019
 >> iter 6000, loss: 0.150876
 >> iter 7000, loss: 0.063787
 >> iter 8000, loss: 0.030642
 >> iter 9000, loss: 0.017859
 >> iter 10000, loss: 0.012518
   Number of active neurons: 8
 >> iter 11000, loss: 0.010252
 >> iter 12000, loss: 0.008997
 >> iter 13000, loss: 0.008379
 >> iter 14000, loss: 0.007834
 >> iter 15000, loss: 0.007564
 >> iter 16000, loss: 0.007188
 >> iter 17000, loss: 0.007037
 >> iter 18000, loss: 0.006738
 >> iter 19000, loss: 0.006652
 >> iter 20000, loss: 0.006391
   Number of active neurons: 8
 >> iter 21000, loss: 0.006339
 >> iter 22000, loss: 0.006117
 >> iter 23000, loss: 0.006100
 >> iter 24000, loss: 0.005892
 >> iter 25000, loss: 0.005857
 >> iter 26000, loss: 0.005689
 >> iter 27000, loss: 0.005700
 >> iter 28000, loss: 0.005533
 >> iter 29000, loss: 0.005517
 >> iter 30000, loss: 0.005384
   Number of active neurons: 8
 >> iter 31000, loss: 0.005407
 >> iter 32000, loss: 0.005272
 >> iter 33000, loss: 0.005290
 >> iter 34000, loss: 0.005173
 >> iter 35000, loss: 0.005685
 >> iter 36000, loss: 0.005353
 >> iter 37000, loss: 0.005140
 >> iter 38000, loss: 0.004968
 >> iter 39000, loss: 0.004951
 >> iter 40000, loss: 0.004861
   Number of active neurons: 8
 >> iter 41000, loss: 0.004912
 >> iter 42000, loss: 0.004809
 >> iter 43000, loss: 0.004839
 >> iter 44000, loss: 0.004751
 >> iter 45000, loss: 0.004791
 >> iter 46000, loss: 0.004700
 >> iter 47000, loss: 0.004737
 >> iter 48000, loss: 0.004658
 >> iter 49000, loss: 0.004690
 >> iter 50000, loss: 0.004618
   Number of active neurons: 7
 >> iter 51000, loss: 0.004668
 >> iter 52000, loss: 0.004599
 >> iter 53000, loss: 0.004623
 >> iter 54000, loss: 0.004565
 >> iter 55000, loss: 0.004842
 >> iter 56000, loss: 0.004635
 >> iter 57000, loss: 0.004580
 >> iter 58000, loss: 0.004509
 >> iter 59000, loss: 0.004530
 >> iter 60000, loss: 0.004479
   Number of active neurons: 7
 >> iter 61000, loss: 0.004496
 >> iter 62000, loss: 0.004451
 >> iter 63000, loss: 0.004488
 >> iter 64000, loss: 0.004439
 >> iter 65000, loss: 0.004453
 >> iter 66000, loss: 0.004415
 >> iter 67000, loss: 0.084538
 >> iter 68000, loss: 0.034135
 >> iter 69000, loss: 0.015221
 >> iter 70000, loss: 0.008184
   Number of active neurons: 7
 >> iter 71000, loss: 0.005581
 >> iter 72000, loss: 0.004603
 >> iter 73000, loss: 0.004267
 >> iter 74000, loss: 0.004134
 >> iter 75000, loss: 0.004132
 >> iter 76000, loss: 0.004113
 >> iter 77000, loss: 0.004160
 >> iter 78000, loss: 0.004150
 >> iter 79000, loss: 0.004200
 >> iter 80000, loss: 0.004186
   Number of active neurons: 7
 >> iter 81000, loss: 0.004230
 >> iter 82000, loss: 0.004214
 >> iter 83000, loss: 0.004249
 >> iter 84000, loss: 0.004227
 >> iter 85000, loss: 0.004265
 >> iter 86000, loss: 0.004236
 >> iter 87000, loss: 0.004270
 >> iter 88000, loss: 0.004238
 >> iter 89000, loss: 0.004270
 >> iter 90000, loss: 0.004234
   Number of active neurons: 8
 >> iter 91000, loss: 0.004267
 >> iter 92000, loss: 0.004222
 >> iter 93000, loss: 0.004267
 >> iter 94000, loss: 0.004210
 >> iter 95000, loss: 0.004264
 >> iter 96000, loss: 0.004195
 >> iter 97000, loss: 0.004248
 >> iter 98000, loss: 0.004179
 >> iter 99000, loss: 0.004231
 >> iter 100000, loss: 0.004164
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0149992500375
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0599960002667
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.628291
 >> iter 2000, loss: 8.019173
 >> iter 3000, loss: 2.982160
 >> iter 4000, loss: 1.120152
 >> iter 5000, loss: 0.424611
 >> iter 6000, loss: 0.166207
 >> iter 7000, loss: 0.069625
 >> iter 8000, loss: 0.033034
 >> iter 9000, loss: 0.018859
 >> iter 10000, loss: 0.013069
   Number of active neurons: 10
 >> iter 11000, loss: 0.010528
 >> iter 12000, loss: 0.009245
 >> iter 13000, loss: 0.008508
 >> iter 14000, loss: 0.008005
 >> iter 15000, loss: 0.007631
 >> iter 16000, loss: 0.007331
 >> iter 17000, loss: 0.007081
 >> iter 18000, loss: 0.006870
 >> iter 19000, loss: 0.006686
 >> iter 20000, loss: 0.006532
   Number of active neurons: 10
 >> iter 21000, loss: 0.006389
 >> iter 22000, loss: 0.006276
 >> iter 23000, loss: 0.006150
 >> iter 24000, loss: 0.006062
 >> iter 25000, loss: 0.005955
 >> iter 26000, loss: 0.005889
 >> iter 27000, loss: 0.005792
 >> iter 28000, loss: 0.005744
 >> iter 29000, loss: 0.005657
 >> iter 30000, loss: 0.005623
   Number of active neurons: 10
 >> iter 31000, loss: 0.005547
 >> iter 32000, loss: 0.005518
 >> iter 33000, loss: 0.005445
 >> iter 34000, loss: 0.005426
 >> iter 35000, loss: 0.005354
 >> iter 36000, loss: 0.005333
 >> iter 37000, loss: 0.005269
 >> iter 38000, loss: 0.005254
 >> iter 39000, loss: 0.005195
 >> iter 40000, loss: 0.005190
   Number of active neurons: 10
 >> iter 41000, loss: 0.005128
 >> iter 42000, loss: 0.005129
 >> iter 43000, loss: 0.005063
 >> iter 44000, loss: 0.005067
 >> iter 45000, loss: 0.005005
 >> iter 46000, loss: 0.005004
 >> iter 47000, loss: 0.004948
 >> iter 48000, loss: 0.004954
 >> iter 49000, loss: 0.004904
 >> iter 50000, loss: 0.004907
   Number of active neurons: 10
 >> iter 51000, loss: 0.004875
 >> iter 52000, loss: 0.004884
 >> iter 53000, loss: 0.004804
 >> iter 54000, loss: 0.004817
 >> iter 55000, loss: 0.005072
 >> iter 56000, loss: 0.005596
 >> iter 57000, loss: 0.004890
 >> iter 58000, loss: 0.004678
 >> iter 59000, loss: 0.004590
 >> iter 60000, loss: 0.004609
   Number of active neurons: 9
 >> iter 61000, loss: 0.004982
 >> iter 62000, loss: 0.005074
 >> iter 63000, loss: 0.004636
 >> iter 64000, loss: 0.004519
 >> iter 65000, loss: 0.004480
 >> iter 66000, loss: 0.004511
 >> iter 67000, loss: 0.005026
 >> iter 68000, loss: 0.005252
 >> iter 69000, loss: 0.004639
 >> iter 70000, loss: 0.004460
   Number of active neurons: 8
 >> iter 71000, loss: 0.004567
 >> iter 72000, loss: 0.004531
 >> iter 73000, loss: 0.004433
 >> iter 74000, loss: 0.004436
 >> iter 75000, loss: 0.004725
 >> iter 76000, loss: 0.004631
 >> iter 77000, loss: 0.004454
 >> iter 78000, loss: 0.004428
 >> iter 79000, loss: 0.004715
 >> iter 80000, loss: 0.004604
   Number of active neurons: 8
 >> iter 81000, loss: 0.004424
 >> iter 82000, loss: 0.004392
 >> iter 83000, loss: 0.004713
 >> iter 84000, loss: 0.004595
 >> iter 85000, loss: 0.004367
 >> iter 86000, loss: 0.004317
 >> iter 87000, loss: 0.004658
 >> iter 88000, loss: 0.004506
 >> iter 89000, loss: 0.004315
 >> iter 90000, loss: 0.004279
   Number of active neurons: 8
 >> iter 91000, loss: 0.004708
 >> iter 92000, loss: 0.004489
 >> iter 93000, loss: 0.004280
 >> iter 94000, loss: 0.004228
 >> iter 95000, loss: 0.004728
 >> iter 96000, loss: 0.004457
 >> iter 97000, loss: 0.004246
 >> iter 98000, loss: 0.004181
 >> iter 99000, loss: 0.004729
 >> iter 100000, loss: 0.004430
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.643351
 >> iter 2000, loss: 8.089105
 >> iter 3000, loss: 3.011081
 >> iter 4000, loss: 1.126295
 >> iter 5000, loss: 0.427906
 >> iter 6000, loss: 0.167926
 >> iter 7000, loss: 0.070827
 >> iter 8000, loss: 0.033792
 >> iter 9000, loss: 0.019524
 >> iter 10000, loss: 0.013544
   Number of active neurons: 9
 >> iter 11000, loss: 0.011012
 >> iter 12000, loss: 0.009617
 >> iter 13000, loss: 0.008916
 >> iter 14000, loss: 0.008341
 >> iter 15000, loss: 0.008016
 >> iter 16000, loss: 0.007668
 >> iter 17000, loss: 0.007484
 >> iter 18000, loss: 0.007232
 >> iter 19000, loss: 0.007111
 >> iter 20000, loss: 0.006912
   Number of active neurons: 9
 >> iter 21000, loss: 0.006834
 >> iter 22000, loss: 0.006674
 >> iter 23000, loss: 0.006615
 >> iter 24000, loss: 0.006481
 >> iter 25000, loss: 0.006437
 >> iter 26000, loss: 0.006323
 >> iter 27000, loss: 0.006290
 >> iter 28000, loss: 0.006193
 >> iter 29000, loss: 0.006170
 >> iter 30000, loss: 0.006086
   Number of active neurons: 9
 >> iter 31000, loss: 0.006073
 >> iter 32000, loss: 0.005994
 >> iter 33000, loss: 0.005982
 >> iter 34000, loss: 0.005916
 >> iter 35000, loss: 0.005902
 >> iter 36000, loss: 0.005845
 >> iter 37000, loss: 0.005833
 >> iter 38000, loss: 0.005776
 >> iter 39000, loss: 0.005769
 >> iter 40000, loss: 0.005719
   Number of active neurons: 9
 >> iter 41000, loss: 0.005711
 >> iter 42000, loss: 0.005665
 >> iter 43000, loss: 0.005658
 >> iter 44000, loss: 0.005615
 >> iter 45000, loss: 0.005612
 >> iter 46000, loss: 0.005569
 >> iter 47000, loss: 0.005565
 >> iter 48000, loss: 0.005534
 >> iter 49000, loss: 0.005526
 >> iter 50000, loss: 0.005499
   Number of active neurons: 9
 >> iter 51000, loss: 0.005489
 >> iter 52000, loss: 0.005474
 >> iter 53000, loss: 0.005457
 >> iter 54000, loss: 0.005447
 >> iter 55000, loss: 0.005430
 >> iter 56000, loss: 0.005425
 >> iter 57000, loss: 0.005410
 >> iter 58000, loss: 0.005404
 >> iter 59000, loss: 0.005388
 >> iter 60000, loss: 0.005388
   Number of active neurons: 9
 >> iter 61000, loss: 0.005373
 >> iter 62000, loss: 0.005370
 >> iter 63000, loss: 0.005355
 >> iter 64000, loss: 0.005356
 >> iter 65000, loss: 0.005338
 >> iter 66000, loss: 0.005342
 >> iter 67000, loss: 0.005320
 >> iter 68000, loss: 0.005327
 >> iter 69000, loss: 0.005301
 >> iter 70000, loss: 0.005311
   Number of active neurons: 9
 >> iter 71000, loss: 0.005292
 >> iter 72000, loss: 0.005295
 >> iter 73000, loss: 0.005281
 >> iter 74000, loss: 0.005281
 >> iter 75000, loss: 0.005269
 >> iter 76000, loss: 0.005274
 >> iter 77000, loss: 0.005255
 >> iter 78000, loss: 0.005262
 >> iter 79000, loss: 0.005243
 >> iter 80000, loss: 0.005248
   Number of active neurons: 9
 >> iter 81000, loss: 0.005228
 >> iter 82000, loss: 0.005236
 >> iter 83000, loss: 0.005219
 >> iter 84000, loss: 0.005221
 >> iter 85000, loss: 0.005210
 >> iter 86000, loss: 0.005211
 >> iter 87000, loss: 0.005195
 >> iter 88000, loss: 0.005197
 >> iter 89000, loss: 0.005178
 >> iter 90000, loss: 0.005182
   Number of active neurons: 9
 >> iter 91000, loss: 0.005160
 >> iter 92000, loss: 0.005162
 >> iter 93000, loss: 0.005141
 >> iter 94000, loss: 0.005140
 >> iter 95000, loss: 0.005132
 >> iter 96000, loss: 0.005119
 >> iter 97000, loss: 0.005113
 >> iter 98000, loss: 0.005101
 >> iter 99000, loss: 0.005100
 >> iter 100000, loss: 0.005087
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 12.7791480568
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

