 > Problema: tomita6nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.821046
 >> iter 2000, loss: 15.287797
 >> iter 3000, loss: 13.875356
 >> iter 4000, loss: 13.350042
 >> iter 5000, loss: 13.140142
 >> iter 6000, loss: 13.072414
 >> iter 7000, loss: 13.026136
 >> iter 8000, loss: 13.011808
 >> iter 9000, loss: 13.003872
 >> iter 10000, loss: 13.004931
   Number of active neurons: 10
 >> iter 11000, loss: 12.983858
 >> iter 12000, loss: 12.992703
 >> iter 13000, loss: 12.982613
 >> iter 14000, loss: 12.987864
 >> iter 15000, loss: 12.975408
 >> iter 16000, loss: 12.982653
 >> iter 17000, loss: 12.976043
 >> iter 18000, loss: 12.975093
 >> iter 19000, loss: 12.961807
 >> iter 20000, loss: 12.975735
   Number of active neurons: 10
 >> iter 21000, loss: 12.962111
 >> iter 22000, loss: 12.977548
 >> iter 23000, loss: 12.963132
 >> iter 24000, loss: 12.974842
 >> iter 25000, loss: 12.938197
 >> iter 26000, loss: 12.263838
 >> iter 27000, loss: 11.481099
 >> iter 28000, loss: 11.014927
 >> iter 29000, loss: 10.214461
 >> iter 30000, loss: 9.448282
   Number of active neurons: 10
 >> iter 31000, loss: 8.221602
 >> iter 32000, loss: 6.905284
 >> iter 33000, loss: 5.321065
 >> iter 34000, loss: 4.498911
 >> iter 35000, loss: 3.633506
 >> iter 36000, loss: 3.029937
 >> iter 37000, loss: 2.915152
 >> iter 38000, loss: 2.655724
 >> iter 39000, loss: 2.475161
 >> iter 40000, loss: 2.636455
   Number of active neurons: 10
 >> iter 41000, loss: 1.703448
 >> iter 42000, loss: 1.080814
 >> iter 43000, loss: 0.875520
 >> iter 44000, loss: 0.672399
 >> iter 45000, loss: 0.403815
 >> iter 46000, loss: 0.198022
 >> iter 47000, loss: 0.264429
 >> iter 48000, loss: 0.142882
 >> iter 49000, loss: 0.118852
 >> iter 50000, loss: 0.325372
   Number of active neurons: 10
 >> iter 51000, loss: 0.283001
 >> iter 52000, loss: 0.182750
 >> iter 53000, loss: 0.123165
 >> iter 54000, loss: 0.079036
 >> iter 55000, loss: 0.116126
 >> iter 56000, loss: 0.058313
 >> iter 57000, loss: 0.177005
 >> iter 58000, loss: 0.253796
 >> iter 59000, loss: 0.211574
 >> iter 60000, loss: 0.170778
   Number of active neurons: 10
 >> iter 61000, loss: 0.248737
 >> iter 62000, loss: 0.105548
 >> iter 63000, loss: 0.107794
 >> iter 64000, loss: 0.068446
 >> iter 65000, loss: 0.105713
 >> iter 66000, loss: 0.149311
 >> iter 67000, loss: 0.065720
 >> iter 68000, loss: 0.081789
 >> iter 69000, loss: 0.041657
 >> iter 70000, loss: 0.260862
   Number of active neurons: 10
 >> iter 71000, loss: 0.363031
 >> iter 72000, loss: 0.148736
 >> iter 73000, loss: 0.065055
 >> iter 74000, loss: 0.032977
 >> iter 75000, loss: 0.024820
 >> iter 76000, loss: 0.036565
 >> iter 77000, loss: 0.079433
 >> iter 78000, loss: 0.036932
 >> iter 79000, loss: 0.021324
 >> iter 80000, loss: 0.013894
   Number of active neurons: 10
 >> iter 81000, loss: 0.017306
 >> iter 82000, loss: 0.011700
 >> iter 83000, loss: 0.091025
 >> iter 84000, loss: 0.068977
 >> iter 85000, loss: 0.033597
 >> iter 86000, loss: 0.184604
 >> iter 87000, loss: 0.091990
 >> iter 88000, loss: 0.044832
 >> iter 89000, loss: 0.034922
 >> iter 90000, loss: 0.231091
   Number of active neurons: 10
 >> iter 91000, loss: 0.187901
 >> iter 92000, loss: 0.077420
 >> iter 93000, loss: 0.035136
 >> iter 94000, loss: 0.019255
 >> iter 95000, loss: 0.012335
 >> iter 96000, loss: 0.028289
 >> iter 97000, loss: 0.192886
 >> iter 98000, loss: 0.077479
 >> iter 99000, loss: 0.209172
 >> iter 100000, loss: 0.139803
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.824976
 >> iter 2000, loss: 15.320334
 >> iter 3000, loss: 13.916504
 >> iter 4000, loss: 13.385851
 >> iter 5000, loss: 13.156809
 >> iter 6000, loss: 13.089393
 >> iter 7000, loss: 13.045532
 >> iter 8000, loss: 13.033334
 >> iter 9000, loss: 13.007146
 >> iter 10000, loss: 13.010451
   Number of active neurons: 9
 >> iter 11000, loss: 12.991807
 >> iter 12000, loss: 12.993705
 >> iter 13000, loss: 12.979682
 >> iter 14000, loss: 12.990567
 >> iter 15000, loss: 12.980354
 >> iter 16000, loss: 12.987221
 >> iter 17000, loss: 12.983389
 >> iter 18000, loss: 12.994610
 >> iter 19000, loss: 12.980824
 >> iter 20000, loss: 12.992738
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 8
 >> iter 21000, loss: 12.979745
 >> iter 22000, loss: 12.991626
 >> iter 23000, loss: 12.973845
 >> iter 24000, loss: 12.981444
 >> iter 25000, loss: 12.948805
 >> iter 26000, loss: 12.494346
 >> iter 27000, loss: 11.605526
 >> iter 28000, loss: 11.179200
 >> iter 29000, loss: 10.876774
 >> iter 30000, loss: 10.806005
   Number of active neurons: 10
 >> iter 31000, loss: 10.642462
 >> iter 32000, loss: 10.628375
 >> iter 33000, loss: 10.479062
 >> iter 34000, loss: 10.445606
 >> iter 35000, loss: 10.255776
 >> iter 36000, loss: 10.077827
 >> iter 37000, loss: 9.809372
 >> iter 38000, loss: 9.656177
 >> iter 39000, loss: 9.447942
 >> iter 40000, loss: 9.409928
   Number of active neurons: 10
 >> iter 41000, loss: 9.294333
 >> iter 42000, loss: 9.336434
 >> iter 43000, loss: 9.189222
 >> iter 44000, loss: 9.256983
 >> iter 45000, loss: 9.133049
 >> iter 46000, loss: 9.180309
 >> iter 47000, loss: 9.093539
 >> iter 48000, loss: 9.100569
 >> iter 49000, loss: 8.743927
 >> iter 50000, loss: 8.700110
   Number of active neurons: 10
 >> iter 51000, loss: 8.516799
 >> iter 52000, loss: 8.618840
 >> iter 53000, loss: 8.428254
 >> iter 54000, loss: 8.589153
 >> iter 55000, loss: 7.507633
 >> iter 56000, loss: 5.467626
 >> iter 57000, loss: 4.239126
 >> iter 58000, loss: 3.973884
 >> iter 59000, loss: 3.232726
 >> iter 60000, loss: 2.917437
   Number of active neurons: 10
 >> iter 61000, loss: 2.736251
 >> iter 62000, loss: 2.622573
 >> iter 63000, loss: 2.508068
 >> iter 64000, loss: 2.334728
 >> iter 65000, loss: 2.370863
 >> iter 66000, loss: 2.325257
 >> iter 67000, loss: 2.408280
 >> iter 68000, loss: 1.338911
 >> iter 69000, loss: 0.718292
 >> iter 70000, loss: 0.590376
   Number of active neurons: 10
 >> iter 71000, loss: 0.338215
 >> iter 72000, loss: 0.344177
 >> iter 73000, loss: 0.526848
 >> iter 74000, loss: 0.295654
 >> iter 75000, loss: 0.264045
 >> iter 76000, loss: 0.293940
 >> iter 77000, loss: 0.226791
 >> iter 78000, loss: 0.257034
 >> iter 79000, loss: 0.342504
 >> iter 80000, loss: 0.297953
   Number of active neurons: 10
 >> iter 81000, loss: 0.241901
 >> iter 82000, loss: 0.153792
 >> iter 83000, loss: 0.309414
 >> iter 84000, loss: 0.283984
 >> iter 85000, loss: 0.205125
 >> iter 86000, loss: 0.245768
 >> iter 87000, loss: 0.298504
 >> iter 88000, loss: 0.243439
 >> iter 89000, loss: 0.150318
 >> iter 90000, loss: 0.132382
   Number of active neurons: 10
 >> iter 91000, loss: 0.067555
 >> iter 92000, loss: 0.200388
 >> iter 93000, loss: 0.261257
 >> iter 94000, loss: 0.177406
 >> iter 95000, loss: 0.113357
 >> iter 96000, loss: 0.061286
 >> iter 97000, loss: 0.103883
 >> iter 98000, loss: 0.224276
 >> iter 99000, loss: 0.128609
 >> iter 100000, loss: 0.206162
   Number of active neurons: 10
 >> iter 101000, loss: 0.129794
 >> iter 102000, loss: 0.081104
 >> iter 103000, loss: 0.199322
 >> iter 104000, loss: 0.122479
 >> iter 105000, loss: 0.201654
 >> iter 106000, loss: 0.088649
 >> iter 107000, loss: 0.052058
 >> iter 108000, loss: 0.028249
 >> iter 109000, loss: 0.044871
 >> iter 110000, loss: 0.140847
   Number of active neurons: 10
 >> iter 111000, loss: 0.066657
 >> iter 112000, loss: 0.060046
 >> iter 113000, loss: 0.031362
 >> iter 114000, loss: 0.117927
 >> iter 115000, loss: 0.093744
 >> iter 116000, loss: 0.164789
 >> iter 117000, loss: 0.069938
 >> iter 118000, loss: 0.061814
 >> iter 119000, loss: 0.032444
 >> iter 120000, loss: 0.041709
   Number of active neurons: 10
 >> iter 121000, loss: 0.150017
 >> iter 122000, loss: 0.072414
 >> iter 123000, loss: 0.041558
 >> iter 124000, loss: 0.109785
 >> iter 125000, loss: 0.107453
 >> iter 126000, loss: 0.051834
 >> iter 127000, loss: 0.030223
 >> iter 128000, loss: 0.036660
 >> iter 129000, loss: 0.023939
 >> iter 130000, loss: 0.030650
   Number of active neurons: 10
 >> iter 131000, loss: 0.019671
 >> iter 132000, loss: 0.018994
 >> iter 133000, loss: 0.013982
 >> iter 134000, loss: 0.011169
 >> iter 135000, loss: 0.008767
 >> iter 136000, loss: 0.008165
 >> iter 137000, loss: 0.050994
 >> iter 138000, loss: 0.101260
 >> iter 139000, loss: 0.144127
 >> iter 140000, loss: 0.061294
   Number of active neurons: 10
 >> iter 141000, loss: 0.083961
 >> iter 142000, loss: 0.108411
 >> iter 143000, loss: 0.056261
 >> iter 144000, loss: 0.025877
 >> iter 145000, loss: 0.015175
 >> iter 146000, loss: 0.020955
 >> iter 147000, loss: 0.016338
 >> iter 148000, loss: 0.010840
 >> iter 149000, loss: 0.093499
 >> iter 150000, loss: 0.076321
   Number of active neurons: 10
 >> iter 151000, loss: 0.079835
 >> iter 152000, loss: 0.034348
 >> iter 153000, loss: 0.059222
 >> iter 154000, loss: 0.084375
 >> iter 155000, loss: 0.044735
 >> iter 156000, loss: 0.028264
 >> iter 157000, loss: 0.014971
 >> iter 158000, loss: 0.009525
 >> iter 159000, loss: 0.061886
 >> iter 160000, loss: 0.122585
   Number of active neurons: 10
 >> iter 161000, loss: 0.182491
 >> iter 162000, loss: 0.161429
 >> iter 163000, loss: 0.096261
 >> iter 164000, loss: 0.059911
 >> iter 165000, loss: 0.034856
 >> iter 166000, loss: 0.116371
 >> iter 167000, loss: 0.486310
 >> iter 168000, loss: 0.268090
 >> iter 169000, loss: 0.361335
 >> iter 170000, loss: 0.162188
   Number of active neurons: 10
 >> iter 171000, loss: 0.104840
 >> iter 172000, loss: 0.048234
 >> iter 173000, loss: 0.027964
 >> iter 174000, loss: 0.018669
 >> iter 175000, loss: 0.013585
 >> iter 176000, loss: 0.040089
 >> iter 177000, loss: 0.021663
 >> iter 178000, loss: 0.013453
 >> iter 179000, loss: 0.075499
 >> iter 180000, loss: 0.033557
   Number of active neurons: 10
 >> iter 181000, loss: 0.047870
 >> iter 182000, loss: 0.028467
 >> iter 183000, loss: 0.016264
 >> iter 184000, loss: 0.012458
 >> iter 185000, loss: 0.010998
 >> iter 186000, loss: 0.011313
 >> iter 187000, loss: 0.020395
 >> iter 188000, loss: 0.012399
 >> iter 189000, loss: 0.067373
 >> iter 190000, loss: 0.033040
   Number of active neurons: 10
 >> iter 191000, loss: 0.079435
 >> iter 192000, loss: 0.034508
 >> iter 193000, loss: 0.083887
 >> iter 194000, loss: 0.185243
 >> iter 195000, loss: 0.094997
 >> iter 196000, loss: 0.057099
 >> iter 197000, loss: 0.030535
 >> iter 198000, loss: 0.051619
 >> iter 199000, loss: 0.030177
 >> iter 200000, loss: 0.017974
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.865783
 >> iter 2000, loss: 15.298521
 >> iter 3000, loss: 13.892594
 >> iter 4000, loss: 13.361634
 >> iter 5000, loss: 13.148574
 >> iter 6000, loss: 13.072482
 >> iter 7000, loss: 13.029496
 >> iter 8000, loss: 13.023436
 >> iter 9000, loss: 13.006135
 >> iter 10000, loss: 13.011353
   Number of active neurons: 10
 >> iter 11000, loss: 12.996216
 >> iter 12000, loss: 13.002607
 >> iter 13000, loss: 12.989968
 >> iter 14000, loss: 13.001158
 >> iter 15000, loss: 12.990357
 >> iter 16000, loss: 12.997905
 >> iter 17000, loss: 12.993587
 >> iter 18000, loss: 12.999448
 >> iter 19000, loss: 12.988683
 >> iter 20000, loss: 12.995488
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 12.983430
 >> iter 22000, loss: 12.993220
 >> iter 23000, loss: 12.980088
 >> iter 24000, loss: 12.977621
 >> iter 25000, loss: 12.630480
 >> iter 26000, loss: 11.815569
 >> iter 27000, loss: 11.250546
 >> iter 28000, loss: 11.033899
 >> iter 29000, loss: 10.693802
 >> iter 30000, loss: 10.254741
   Number of active neurons: 10
 >> iter 31000, loss: 8.801656
 >> iter 32000, loss: 7.528910
 >> iter 33000, loss: 5.169292
 >> iter 34000, loss: 3.046363
 >> iter 35000, loss: 1.739181
 >> iter 36000, loss: 1.382276
 >> iter 37000, loss: 1.005122
 >> iter 38000, loss: 0.958176
 >> iter 39000, loss: 0.589149
 >> iter 40000, loss: 0.292136
   Number of active neurons: 10
 >> iter 41000, loss: 0.258248
 >> iter 42000, loss: 0.531751
 >> iter 43000, loss: 0.372804
 >> iter 44000, loss: 0.467616
 >> iter 45000, loss: 0.198626
 >> iter 46000, loss: 0.118309
 >> iter 47000, loss: 0.156570
 >> iter 48000, loss: 0.086661
 >> iter 49000, loss: 0.262110
 >> iter 50000, loss: 0.170522
   Number of active neurons: 10
 >> iter 51000, loss: 0.279372
 >> iter 52000, loss: 0.148312
 >> iter 53000, loss: 0.195238
 >> iter 54000, loss: 0.091439
 >> iter 55000, loss: 0.158895
 >> iter 56000, loss: 0.257897
 >> iter 57000, loss: 0.107865
 >> iter 58000, loss: 0.066895
 >> iter 59000, loss: 0.234502
 >> iter 60000, loss: 0.129961
   Number of active neurons: 10
 >> iter 61000, loss: 0.122421
 >> iter 62000, loss: 0.083612
 >> iter 63000, loss: 0.040708
 >> iter 64000, loss: 0.433468
 >> iter 65000, loss: 0.181127
 >> iter 66000, loss: 0.130895
 >> iter 67000, loss: 0.059146
 >> iter 68000, loss: 0.395683
 >> iter 69000, loss: 0.267245
 >> iter 70000, loss: 0.114918
   Number of active neurons: 10
 >> iter 71000, loss: 0.091063
 >> iter 72000, loss: 0.042695
 >> iter 73000, loss: 0.039334
 >> iter 74000, loss: 0.209246
 >> iter 75000, loss: 0.215626
 >> iter 76000, loss: 0.089395
 >> iter 77000, loss: 0.113067
 >> iter 78000, loss: 0.052757
 >> iter 79000, loss: 0.025990
 >> iter 80000, loss: 0.018721
   Number of active neurons: 10
 >> iter 81000, loss: 0.061523
 >> iter 82000, loss: 0.450544
 >> iter 83000, loss: 0.180357
 >> iter 84000, loss: 0.290160
 >> iter 85000, loss: 0.117099
 >> iter 86000, loss: 0.050834
 >> iter 87000, loss: 0.025789
 >> iter 88000, loss: 0.035147
 >> iter 89000, loss: 0.019234
 >> iter 90000, loss: 0.044589
   Number of active neurons: 10
 >> iter 91000, loss: 0.117518
 >> iter 92000, loss: 0.060074
 >> iter 93000, loss: 0.097811
 >> iter 94000, loss: 0.175614
 >> iter 95000, loss: 0.074837
 >> iter 96000, loss: 0.033282
 >> iter 97000, loss: 0.017277
 >> iter 98000, loss: 0.068787
 >> iter 99000, loss: 0.258377
 >> iter 100000, loss: 0.102763
   Number of active neurons: 10
 >> iter 101000, loss: 0.045759
 >> iter 102000, loss: 0.074132
 >> iter 103000, loss: 0.033285
 >> iter 104000, loss: 0.108147
 >> iter 105000, loss: 0.135628
 >> iter 106000, loss: 0.056524
 >> iter 107000, loss: 0.026105
 >> iter 108000, loss: 0.027266
 >> iter 109000, loss: 0.014629
 >> iter 110000, loss: 0.105061
   Number of active neurons: 10
 >> iter 111000, loss: 0.109256
 >> iter 112000, loss: 0.162372
 >> iter 113000, loss: 0.065113
 >> iter 114000, loss: 0.028658
 >> iter 115000, loss: 0.015820
 >> iter 116000, loss: 0.009666
 >> iter 117000, loss: 0.007299
 >> iter 118000, loss: 0.006001
 >> iter 119000, loss: 0.007717
 >> iter 120000, loss: 0.029872
   Number of active neurons: 10
 >> iter 121000, loss: 0.015653
 >> iter 122000, loss: 0.009256
 >> iter 123000, loss: 0.011548
 >> iter 124000, loss: 0.007223
 >> iter 125000, loss: 0.005241
 >> iter 126000, loss: 0.005029
 >> iter 127000, loss: 0.004423
 >> iter 128000, loss: 0.060742
 >> iter 129000, loss: 0.025060
 >> iter 130000, loss: 0.109350
   Number of active neurons: 10
 >> iter 131000, loss: 0.047875
 >> iter 132000, loss: 0.023864
 >> iter 133000, loss: 0.019638
 >> iter 134000, loss: 0.013101
 >> iter 135000, loss: 0.008883
 >> iter 136000, loss: 0.005727
 >> iter 137000, loss: 0.101300
 >> iter 138000, loss: 0.041042
 >> iter 139000, loss: 0.017701
 >> iter 140000, loss: 0.011135
   Number of active neurons: 10
 >> iter 141000, loss: 0.006676
 >> iter 142000, loss: 0.040546
 >> iter 143000, loss: 0.017465
 >> iter 144000, loss: 0.008921
 >> iter 145000, loss: 0.006144
 >> iter 146000, loss: 0.004527
 >> iter 147000, loss: 0.003916
 >> iter 148000, loss: 0.006010
 >> iter 149000, loss: 0.176110
 >> iter 150000, loss: 0.096392
   Number of active neurons: 10
 >> iter 151000, loss: 0.052631
 >> iter 152000, loss: 0.046946
 >> iter 153000, loss: 0.020570
 >> iter 154000, loss: 0.010609
 >> iter 155000, loss: 0.052030
 >> iter 156000, loss: 0.033235
 >> iter 157000, loss: 0.015280
 >> iter 158000, loss: 0.008412
 >> iter 159000, loss: 0.005768
 >> iter 160000, loss: 0.004695
   Number of active neurons: 10
 >> iter 161000, loss: 0.043227
 >> iter 162000, loss: 0.018557
 >> iter 163000, loss: 0.011626
 >> iter 164000, loss: 0.007123
 >> iter 165000, loss: 0.010071
 >> iter 166000, loss: 0.011256
 >> iter 167000, loss: 0.028311
 >> iter 168000, loss: 0.012583
 >> iter 169000, loss: 0.006685
 >> iter 170000, loss: 0.005696
   Number of active neurons: 10
 >> iter 171000, loss: 0.004181
 >> iter 172000, loss: 0.005744
 >> iter 173000, loss: 0.003933
 >> iter 174000, loss: 0.164102
 >> iter 175000, loss: 0.062742
 >> iter 176000, loss: 0.117545
 >> iter 177000, loss: 0.089109
 >> iter 178000, loss: 0.041715
 >> iter 179000, loss: 0.021242
 >> iter 180000, loss: 0.010138
   Number of active neurons: 10
 >> iter 181000, loss: 0.028085
 >> iter 182000, loss: 0.012903
 >> iter 183000, loss: 0.006720
 >> iter 184000, loss: 0.004712
 >> iter 185000, loss: 0.003900
 >> iter 186000, loss: 0.042796
 >> iter 187000, loss: 0.020649
 >> iter 188000, loss: 0.009398
 >> iter 189000, loss: 0.005153
 >> iter 190000, loss: 0.004422
   Number of active neurons: 10
 >> iter 191000, loss: 0.029097
 >> iter 192000, loss: 0.034519
 >> iter 193000, loss: 0.015215
 >> iter 194000, loss: 0.031573
 >> iter 195000, loss: 0.013337
 >> iter 196000, loss: 0.006685
 >> iter 197000, loss: 0.004081
 >> iter 198000, loss: 0.003078
 >> iter 199000, loss: 0.003576
 >> iter 200000, loss: 0.002821
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.889378
 >> iter 2000, loss: 15.315760
 >> iter 3000, loss: 13.917589
 >> iter 4000, loss: 13.387128
 >> iter 5000, loss: 13.177128
 >> iter 6000, loss: 13.109516
 >> iter 7000, loss: 13.062899
 >> iter 8000, loss: 13.052581
 >> iter 9000, loss: 13.044818
 >> iter 10000, loss: 13.054227
   Number of active neurons: 10
 >> iter 11000, loss: 13.039765
 >> iter 12000, loss: 13.040599
 >> iter 13000, loss: 13.035015
 >> iter 14000, loss: 13.037089
 >> iter 15000, loss: 13.032394
 >> iter 16000, loss: 13.039884
 >> iter 17000, loss: 13.037952
 >> iter 18000, loss: 13.035413
 >> iter 19000, loss: 13.025632
 >> iter 20000, loss: 13.035123
   Number of active neurons: 10
 >> iter 21000, loss: 13.028185
 >> iter 22000, loss: 13.040102
 >> iter 23000, loss: 13.031156
 >> iter 24000, loss: 13.037262
 >> iter 25000, loss: 13.014521
 >> iter 26000, loss: 13.014493
 >> iter 27000, loss: 12.856354
 >> iter 28000, loss: 12.023163
 >> iter 29000, loss: 11.378367
 >> iter 30000, loss: 11.157336
   Number of active neurons: 10
 >> iter 31000, loss: 10.936283
 >> iter 32000, loss: 10.838733
 >> iter 33000, loss: 10.587490
 >> iter 34000, loss: 10.523200
 >> iter 35000, loss: 10.389911
 >> iter 36000, loss: 10.217646
 >> iter 37000, loss: 9.553874
 >> iter 38000, loss: 8.897372
 >> iter 39000, loss: 8.468929
 >> iter 40000, loss: 7.334828
   Number of active neurons: 10
 >> iter 41000, loss: 5.850228
 >> iter 42000, loss: 5.050982
 >> iter 43000, loss: 3.903137
 >> iter 44000, loss: 3.293149
 >> iter 45000, loss: 2.378719
 >> iter 46000, loss: 2.104218
 >> iter 47000, loss: 1.744804
 >> iter 48000, loss: 1.515880
 >> iter 49000, loss: 1.392112
 >> iter 50000, loss: 1.404219
   Number of active neurons: 10
 >> iter 51000, loss: 1.009410
 >> iter 52000, loss: 0.882138
 >> iter 53000, loss: 1.030920
 >> iter 54000, loss: 1.074326
 >> iter 55000, loss: 0.690014
 >> iter 56000, loss: 0.677784
 >> iter 57000, loss: 0.439639
 >> iter 58000, loss: 0.315279
 >> iter 59000, loss: 0.392345
 >> iter 60000, loss: 0.593966
   Number of active neurons: 10
 >> iter 61000, loss: 0.798285
 >> iter 62000, loss: 0.680753
 >> iter 63000, loss: 0.406458
 >> iter 64000, loss: 0.278977
 >> iter 65000, loss: 0.478995
 >> iter 66000, loss: 0.504552
 >> iter 67000, loss: 0.335146
 >> iter 68000, loss: 0.342860
 >> iter 69000, loss: 0.434476
 >> iter 70000, loss: 0.476250
   Number of active neurons: 10
 >> iter 71000, loss: 0.563635
 >> iter 72000, loss: 0.601902
 >> iter 73000, loss: 0.617443
 >> iter 74000, loss: 0.502320
 >> iter 75000, loss: 0.418526
 >> iter 76000, loss: 0.303404
 >> iter 77000, loss: 0.367713
 >> iter 78000, loss: 0.425104
 >> iter 79000, loss: 0.293018
 >> iter 80000, loss: 0.433059
   Number of active neurons: 10
 >> iter 81000, loss: 0.218422
 >> iter 82000, loss: 0.106951
 >> iter 83000, loss: 0.069401
 >> iter 84000, loss: 0.187788
 >> iter 85000, loss: 0.176482
 >> iter 86000, loss: 0.136187
 >> iter 87000, loss: 0.110371
 >> iter 88000, loss: 0.330473
 >> iter 89000, loss: 0.196998
 >> iter 90000, loss: 0.109938
   Number of active neurons: 10
 >> iter 91000, loss: 0.166115
 >> iter 92000, loss: 0.117585
 >> iter 93000, loss: 0.142247
 >> iter 94000, loss: 0.183433
 >> iter 95000, loss: 0.217314
 >> iter 96000, loss: 0.135951
 >> iter 97000, loss: 0.271393
 >> iter 98000, loss: 0.112854
 >> iter 99000, loss: 0.091253
 >> iter 100000, loss: 0.099138
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0039999600004
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.824317
 >> iter 2000, loss: 15.307087
 >> iter 3000, loss: 13.920501
 >> iter 4000, loss: 13.382045
 >> iter 5000, loss: 13.158982
 >> iter 6000, loss: 13.076877
 >> iter 7000, loss: 13.039010
 >> iter 8000, loss: 13.036771
 >> iter 9000, loss: 13.016448
 >> iter 10000, loss: 13.021428
   Number of active neurons: 8
 >> iter 11000, loss: 13.012237
 >> iter 12000, loss: 13.012782
 >> iter 13000, loss: 13.010570
 >> iter 14000, loss: 13.010774
 >> iter 15000, loss: 13.008298
 >> iter 16000, loss: 13.009111
 >> iter 17000, loss: 12.998063
 >> iter 18000, loss: 12.890024
 >> iter 19000, loss: 11.978358
 >> iter 20000, loss: 11.393751
   Number of active neurons: 10
 >> iter 21000, loss: 10.952904
 >> iter 22000, loss: 10.758540
 >> iter 23000, loss: 10.551655
 >> iter 24000, loss: 10.496836
 >> iter 25000, loss: 10.307394
 >> iter 26000, loss: 10.158246
 >> iter 27000, loss: 9.753392
 >> iter 28000, loss: 9.401594
 >> iter 29000, loss: 8.515539
 >> iter 30000, loss: 7.800522
   Number of active neurons: 10
 >> iter 31000, loss: 4.622470
 >> iter 32000, loss: 2.734453
 >> iter 33000, loss: 1.959563
 >> iter 34000, loss: 1.307619
 >> iter 35000, loss: 0.786533
 >> iter 36000, loss: 0.577499
 >> iter 37000, loss: 0.450305
 >> iter 38000, loss: 0.468768
 >> iter 39000, loss: 0.374934
 >> iter 40000, loss: 0.294763
   Number of active neurons: 10
 >> iter 41000, loss: 0.147381
 >> iter 42000, loss: 0.205741
 >> iter 43000, loss: 0.332240
 >> iter 44000, loss: 0.257429
 >> iter 45000, loss: 0.216473
 >> iter 46000, loss: 0.382866
 >> iter 47000, loss: 0.313693
 >> iter 48000, loss: 0.398774
 >> iter 49000, loss: 0.459584
 >> iter 50000, loss: 0.352311
   Number of active neurons: 10
 >> iter 51000, loss: 0.188645
 >> iter 52000, loss: 0.317747
 >> iter 53000, loss: 0.231101
 >> iter 54000, loss: 0.277954
 >> iter 55000, loss: 0.316485
 >> iter 56000, loss: 0.300663
 >> iter 57000, loss: 0.165044
 >> iter 58000, loss: 0.247736
 >> iter 59000, loss: 0.171003
 >> iter 60000, loss: 0.111863
   Number of active neurons: 10
 >> iter 61000, loss: 0.056545
 >> iter 62000, loss: 0.056575
 >> iter 63000, loss: 0.030990
 >> iter 64000, loss: 0.021017
 >> iter 65000, loss: 0.028809
 >> iter 66000, loss: 0.392136
 >> iter 67000, loss: 0.214936
 >> iter 68000, loss: 0.237560
 >> iter 69000, loss: 0.246126
 >> iter 70000, loss: 0.234648
   Number of active neurons: 10
 >> iter 71000, loss: 0.322985
 >> iter 72000, loss: 0.476195
 >> iter 73000, loss: 0.226090
 >> iter 74000, loss: 0.128919
 >> iter 75000, loss: 0.171496
 >> iter 76000, loss: 0.075786
 >> iter 77000, loss: 0.127741
 >> iter 78000, loss: 0.126168
 >> iter 79000, loss: 0.294376
 >> iter 80000, loss: 0.246165
   Number of active neurons: 10
 >> iter 81000, loss: 0.201140
 >> iter 82000, loss: 0.151618
 >> iter 83000, loss: 0.200227
 >> iter 84000, loss: 0.088583
 >> iter 85000, loss: 0.098038
 >> iter 86000, loss: 0.169653
 >> iter 87000, loss: 0.075560
 >> iter 88000, loss: 0.039073
 >> iter 89000, loss: 0.046100
 >> iter 90000, loss: 0.077911
   Number of active neurons: 10
 >> iter 91000, loss: 0.037325
 >> iter 92000, loss: 0.020710
 >> iter 93000, loss: 0.044329
 >> iter 94000, loss: 0.095606
 >> iter 95000, loss: 0.154064
 >> iter 96000, loss: 0.083703
 >> iter 97000, loss: 0.054391
 >> iter 98000, loss: 0.029933
 >> iter 99000, loss: 0.081749
 >> iter 100000, loss: 0.037470
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.818088
 >> iter 2000, loss: 15.345574
 >> iter 3000, loss: 13.928794
 >> iter 4000, loss: 13.403079
 >> iter 5000, loss: 13.180066
 >> iter 6000, loss: 13.095799
 >> iter 7000, loss: 13.055480
 >> iter 8000, loss: 13.024162
 >> iter 9000, loss: 13.016594
 >> iter 10000, loss: 13.026790
   Number of active neurons: 10
 >> iter 11000, loss: 13.007988
 >> iter 12000, loss: 13.010581
 >> iter 13000, loss: 13.000093
 >> iter 14000, loss: 13.011506
 >> iter 15000, loss: 13.005601
 >> iter 16000, loss: 13.011264
 >> iter 17000, loss: 13.002389
 >> iter 18000, loss: 13.000416
 >> iter 19000, loss: 12.996712
 >> iter 20000, loss: 13.011165
   Number of active neurons: 10
 >> iter 21000, loss: 12.995747
 >> iter 22000, loss: 13.010826
 >> iter 23000, loss: 12.989750
 >> iter 24000, loss: 12.999367
 >> iter 25000, loss: 12.989123
 >> iter 26000, loss: 12.998060
 >> iter 27000, loss: 12.986798
 >> iter 28000, loss: 12.989353
 >> iter 29000, loss: 12.913395
 >> iter 30000, loss: 12.112460
   Number of active neurons: 10
 >> iter 31000, loss: 11.395809
 >> iter 32000, loss: 11.077186
 >> iter 33000, loss: 10.727916
 >> iter 34000, loss: 10.595759
 >> iter 35000, loss: 10.322958
 >> iter 36000, loss: 9.801936
 >> iter 37000, loss: 9.069849
 >> iter 38000, loss: 8.523814
 >> iter 39000, loss: 7.584859
 >> iter 40000, loss: 4.132787
   Number of active neurons: 10
 >> iter 41000, loss: 2.043599
 >> iter 42000, loss: 1.126373
 >> iter 43000, loss: 0.779703
 >> iter 44000, loss: 0.613297
 >> iter 45000, loss: 0.500525
 >> iter 46000, loss: 0.360105
 >> iter 47000, loss: 0.265050
 >> iter 48000, loss: 0.347343
 >> iter 49000, loss: 0.351366
 >> iter 50000, loss: 0.390602
   Number of active neurons: 10
 >> iter 51000, loss: 0.366274
 >> iter 52000, loss: 0.248715
 >> iter 53000, loss: 0.263690
 >> iter 54000, loss: 0.307135
 >> iter 55000, loss: 0.130708
 >> iter 56000, loss: 0.411218
 >> iter 57000, loss: 0.190381
 >> iter 58000, loss: 0.099622
 >> iter 59000, loss: 0.209729
 >> iter 60000, loss: 0.110486
   Number of active neurons: 10
 >> iter 61000, loss: 0.201199
 >> iter 62000, loss: 0.173575
 >> iter 63000, loss: 0.101500
 >> iter 64000, loss: 0.068396
 >> iter 65000, loss: 0.126456
 >> iter 66000, loss: 0.147657
 >> iter 67000, loss: 0.065253
 >> iter 68000, loss: 0.032477
 >> iter 69000, loss: 0.018626
 >> iter 70000, loss: 0.036083
   Number of active neurons: 10
 >> iter 71000, loss: 0.021606
 >> iter 72000, loss: 0.013948
 >> iter 73000, loss: 0.187663
 >> iter 74000, loss: 0.123523
 >> iter 75000, loss: 0.108016
 >> iter 76000, loss: 0.189171
 >> iter 77000, loss: 0.173436
 >> iter 78000, loss: 0.107076
 >> iter 79000, loss: 0.197713
 >> iter 80000, loss: 0.083679
   Number of active neurons: 10
 >> iter 81000, loss: 0.167258
 >> iter 82000, loss: 0.201021
 >> iter 83000, loss: 0.113264
 >> iter 84000, loss: 0.056711
 >> iter 85000, loss: 0.027921
 >> iter 86000, loss: 0.020247
 >> iter 87000, loss: 0.122412
 >> iter 88000, loss: 0.058227
 >> iter 89000, loss: 0.071896
 >> iter 90000, loss: 0.032007
   Number of active neurons: 10
 >> iter 91000, loss: 0.069231
 >> iter 92000, loss: 0.097165
 >> iter 93000, loss: 0.280565
 >> iter 94000, loss: 0.211826
 >> iter 95000, loss: 0.086429
 >> iter 96000, loss: 0.042579
 >> iter 97000, loss: 0.021183
 >> iter 98000, loss: 0.026575
 >> iter 99000, loss: 0.065062
 >> iter 100000, loss: 0.036850
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 18.830469
 >> iter 2000, loss: 15.304936
 >> iter 3000, loss: 13.913532
 >> iter 4000, loss: 13.380676
 >> iter 5000, loss: 13.160239
 >> iter 6000, loss: 13.067356
 >> iter 7000, loss: 13.022397
 >> iter 8000, loss: 13.004265
 >> iter 9000, loss: 12.984514
 >> iter 10000, loss: 12.983655
   Number of active neurons: 8
 >> iter 11000, loss: 12.974681
 >> iter 12000, loss: 12.981953
 >> iter 13000, loss: 12.967051
 >> iter 14000, loss: 12.977535
 >> iter 15000, loss: 12.964102
 >> iter 16000, loss: 12.945382
 >> iter 17000, loss: 12.358404
 >> iter 18000, loss: 11.599427
 >> iter 19000, loss: 11.077368
 >> iter 20000, loss: 10.548746
   Number of active neurons: 10
 >> iter 21000, loss: 9.682261
 >> iter 22000, loss: 9.069138
 >> iter 23000, loss: 7.856782
 >> iter 24000, loss: 5.636105
 >> iter 25000, loss: 3.532543
 >> iter 26000, loss: 2.429361
 >> iter 27000, loss: 1.243380
 >> iter 28000, loss: 1.105941
 >> iter 29000, loss: 0.850340
 >> iter 30000, loss: 0.676354
   Number of active neurons: 10
 >> iter 31000, loss: 0.403832
 >> iter 32000, loss: 0.555466
 >> iter 33000, loss: 0.265639
 >> iter 34000, loss: 0.397092
 >> iter 35000, loss: 0.204083
 >> iter 36000, loss: 0.338042
 >> iter 37000, loss: 0.209328
 >> iter 38000, loss: 0.253225
 >> iter 39000, loss: 0.118272
 >> iter 40000, loss: 0.172903
   Number of active neurons: 10
 >> iter 41000, loss: 0.179273
 >> iter 42000, loss: 0.264156
 >> iter 43000, loss: 0.193251
 >> iter 44000, loss: 0.576921
 >> iter 45000, loss: 0.303898
 >> iter 46000, loss: 0.157021
 >> iter 47000, loss: 0.075434
 >> iter 48000, loss: 0.086289
 >> iter 49000, loss: 0.053709
 >> iter 50000, loss: 0.461968
   Number of active neurons: 10
 >> iter 51000, loss: 0.380410
 >> iter 52000, loss: 0.222582
 >> iter 53000, loss: 0.144636
 >> iter 54000, loss: 0.066329
 >> iter 55000, loss: 0.180105
 >> iter 56000, loss: 0.208075
 >> iter 57000, loss: 0.100187
 >> iter 58000, loss: 0.078465
 >> iter 59000, loss: 0.174757
 >> iter 60000, loss: 0.087497
   Number of active neurons: 10
 >> iter 61000, loss: 0.062146
 >> iter 62000, loss: 0.155561
 >> iter 63000, loss: 0.100344
 >> iter 64000, loss: 0.051650
 >> iter 65000, loss: 0.133615
 >> iter 66000, loss: 0.876161
 >> iter 67000, loss: 0.345304
 >> iter 68000, loss: 0.140104
 >> iter 69000, loss: 0.077307
 >> iter 70000, loss: 0.114915
   Number of active neurons: 10
 >> iter 71000, loss: 0.050931
 >> iter 72000, loss: 0.025729
 >> iter 73000, loss: 0.031800
 >> iter 74000, loss: 0.402610
 >> iter 75000, loss: 0.162774
 >> iter 76000, loss: 0.186531
 >> iter 77000, loss: 0.079252
 >> iter 78000, loss: 0.058772
 >> iter 79000, loss: 0.079679
 >> iter 80000, loss: 0.037105
   Number of active neurons: 10
 >> iter 81000, loss: 0.019652
 >> iter 82000, loss: 0.013673
 >> iter 83000, loss: 0.010513
 >> iter 84000, loss: 0.015625
 >> iter 85000, loss: 0.068635
 >> iter 86000, loss: 0.145154
 >> iter 87000, loss: 0.079714
 >> iter 88000, loss: 0.144358
 >> iter 89000, loss: 0.316613
 >> iter 90000, loss: 0.534619
   Number of active neurons: 10
 >> iter 91000, loss: 0.236153
 >> iter 92000, loss: 0.097378
 >> iter 93000, loss: 0.049737
 >> iter 94000, loss: 0.025415
 >> iter 95000, loss: 0.015276
 >> iter 96000, loss: 0.011219
 >> iter 97000, loss: 0.009381
 >> iter 98000, loss: 0.008140
 >> iter 99000, loss: 0.007131
 >> iter 100000, loss: 0.016532
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.844689
 >> iter 2000, loss: 15.371260
 >> iter 3000, loss: 13.959648
 >> iter 4000, loss: 13.441224
 >> iter 5000, loss: 13.210191
 >> iter 6000, loss: 13.103890
 >> iter 7000, loss: 13.067235
 >> iter 8000, loss: 13.053824
 >> iter 9000, loss: 13.030877
 >> iter 10000, loss: 13.044579
   Number of active neurons: 9
 >> iter 11000, loss: 13.024540
 >> iter 12000, loss: 13.032167
 >> iter 13000, loss: 13.014301
 >> iter 14000, loss: 13.020744
 >> iter 15000, loss: 13.007059
 >> iter 16000, loss: 13.007785
 >> iter 17000, loss: 13.000501
 >> iter 18000, loss: 13.006138
 >> iter 19000, loss: 13.004170
 >> iter 20000, loss: 13.011338
   Number of active neurons: 10
 >> iter 21000, loss: 13.000505
 >> iter 22000, loss: 12.991696
 >> iter 23000, loss: 12.441143
 >> iter 24000, loss: 11.592534
 >> iter 25000, loss: 10.959628
 >> iter 26000, loss: 10.663193
 >> iter 27000, loss: 10.354765
 >> iter 28000, loss: 10.488027
 >> iter 29000, loss: 10.235966
 >> iter 30000, loss: 9.891603
   Number of active neurons: 10
 >> iter 31000, loss: 8.840417
 >> iter 32000, loss: 7.724427
 >> iter 33000, loss: 6.876118
 >> iter 34000, loss: 6.321524
 >> iter 35000, loss: 5.793728
 >> iter 36000, loss: 5.559169
 >> iter 37000, loss: 5.159074
 >> iter 38000, loss: 4.981969
 >> iter 39000, loss: 4.902609
 >> iter 40000, loss: 4.454870
   Number of active neurons: 10
 >> iter 41000, loss: 4.285946
 >> iter 42000, loss: 4.315096
 >> iter 43000, loss: 4.087086
 >> iter 44000, loss: 4.198399
 >> iter 45000, loss: 4.055854
 >> iter 46000, loss: 3.891542
 >> iter 47000, loss: 3.999737
 >> iter 48000, loss: 4.046690
 >> iter 49000, loss: 3.678746
 >> iter 50000, loss: 4.120447
   Number of active neurons: 10
 >> iter 51000, loss: 3.940901
 >> iter 52000, loss: 4.092099
 >> iter 53000, loss: 3.809007
 >> iter 54000, loss: 4.179031
 >> iter 55000, loss: 3.829861
 >> iter 56000, loss: 3.596000
 >> iter 57000, loss: 3.235333
 >> iter 58000, loss: 3.225001
 >> iter 59000, loss: 3.047879
 >> iter 60000, loss: 3.264363
   Number of active neurons: 10
 >> iter 61000, loss: 3.014997
 >> iter 62000, loss: 2.963422
 >> iter 63000, loss: 3.028881
 >> iter 64000, loss: 2.906246
 >> iter 65000, loss: 2.752441
 >> iter 66000, loss: 2.836532
 >> iter 67000, loss: 2.841210
 >> iter 68000, loss: 2.818024
 >> iter 69000, loss: 2.722783
 >> iter 70000, loss: 2.874052
   Number of active neurons: 10
 >> iter 71000, loss: 2.882907
 >> iter 72000, loss: 2.792276
 >> iter 73000, loss: 2.777271
 >> iter 74000, loss: 2.835410
 >> iter 75000, loss: 2.761253
 >> iter 76000, loss: 2.776065
 >> iter 77000, loss: 2.581934
 >> iter 78000, loss: 2.827576
 >> iter 79000, loss: 2.751288
 >> iter 80000, loss: 2.783016
   Number of active neurons: 10
 >> iter 81000, loss: 2.743499
 >> iter 82000, loss: 2.877053
 >> iter 83000, loss: 2.682499
 >> iter 84000, loss: 2.707630
 >> iter 85000, loss: 2.715310
 >> iter 86000, loss: 2.562765
 >> iter 87000, loss: 2.608114
 >> iter 88000, loss: 2.641448
 >> iter 89000, loss: 2.749063
 >> iter 90000, loss: 2.844927
   Number of active neurons: 10
 >> iter 91000, loss: 2.629467
 >> iter 92000, loss: 2.652660
 >> iter 93000, loss: 2.518032
 >> iter 94000, loss: 2.668208
 >> iter 95000, loss: 2.539670
 >> iter 96000, loss: 2.495756
 >> iter 97000, loss: 2.456230
 >> iter 98000, loss: 2.445316
 >> iter 99000, loss: 2.466120
 >> iter 100000, loss: 2.558854
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 4.61390772185
   - Test - Long: 24.6837658117
   - Test - Big: 4.47495525045
   - Test - A: 0.0
   - Test - B: 30.6646223585
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.818172
 >> iter 2000, loss: 15.306633
 >> iter 3000, loss: 13.894012
 >> iter 4000, loss: 13.358632
 >> iter 5000, loss: 13.138069
 >> iter 6000, loss: 13.067660
 >> iter 7000, loss: 13.023002
 >> iter 8000, loss: 13.010750
 >> iter 9000, loss: 12.992566
 >> iter 10000, loss: 13.001461
   Number of active neurons: 8
 >> iter 11000, loss: 12.984279
 >> iter 12000, loss: 12.988668
 >> iter 13000, loss: 12.975014
 >> iter 14000, loss: 12.985155
 >> iter 15000, loss: 12.977915
 >> iter 16000, loss: 12.979223
 >> iter 17000, loss: 12.975676
 >> iter 18000, loss: 12.957614
 >> iter 19000, loss: 12.924081
 >> iter 20000, loss: 12.636123
   Number of active neurons: 10
 >> iter 21000, loss: 11.718505
 >> iter 22000, loss: 11.190622
 >> iter 23000, loss: 10.764617
 >> iter 24000, loss: 10.612530
 >> iter 25000, loss: 10.403708
 >> iter 26000, loss: 9.914546
 >> iter 27000, loss: 9.349729
 >> iter 28000, loss: 9.160579
 >> iter 29000, loss: 8.668425
 >> iter 30000, loss: 8.478304
   Number of active neurons: 10
 >> iter 31000, loss: 8.288061
 >> iter 32000, loss: 8.233380
 >> iter 33000, loss: 7.414781
 >> iter 34000, loss: 6.869060
 >> iter 35000, loss: 6.189964
 >> iter 36000, loss: 6.061737
 >> iter 37000, loss: 4.313696
 >> iter 38000, loss: 2.217295
 >> iter 39000, loss: 1.067494
 >> iter 40000, loss: 0.771894
   Number of active neurons: 10
 >> iter 41000, loss: 0.838624
 >> iter 42000, loss: 0.577420
 >> iter 43000, loss: 0.510316
 >> iter 44000, loss: 0.577591
 >> iter 45000, loss: 0.628999
 >> iter 46000, loss: 0.382393
 >> iter 47000, loss: 0.400919
 >> iter 48000, loss: 0.180925
 >> iter 49000, loss: 0.154288
 >> iter 50000, loss: 0.179938
   Number of active neurons: 10
 >> iter 51000, loss: 0.197964
 >> iter 52000, loss: 0.153379
 >> iter 53000, loss: 0.074362
 >> iter 54000, loss: 0.150125
 >> iter 55000, loss: 0.334972
 >> iter 56000, loss: 0.149962
 >> iter 57000, loss: 0.089760
 >> iter 58000, loss: 0.133452
 >> iter 59000, loss: 0.184136
 >> iter 60000, loss: 0.104255
   Number of active neurons: 10
 >> iter 61000, loss: 0.119456
 >> iter 62000, loss: 0.090411
 >> iter 63000, loss: 0.066566
 >> iter 64000, loss: 0.095389
 >> iter 65000, loss: 0.064780
 >> iter 66000, loss: 0.120647
 >> iter 67000, loss: 0.187859
 >> iter 68000, loss: 0.258210
 >> iter 69000, loss: 0.249255
 >> iter 70000, loss: 0.109588
   Number of active neurons: 10
 >> iter 71000, loss: 0.074247
 >> iter 72000, loss: 0.365638
 >> iter 73000, loss: 0.221594
 >> iter 74000, loss: 0.109838
 >> iter 75000, loss: 0.074267
 >> iter 76000, loss: 0.078462
 >> iter 77000, loss: 0.336083
 >> iter 78000, loss: 0.134010
 >> iter 79000, loss: 0.065160
 >> iter 80000, loss: 0.040056
   Number of active neurons: 10
 >> iter 81000, loss: 0.026502
 >> iter 82000, loss: 0.131467
 >> iter 83000, loss: 0.083741
 >> iter 84000, loss: 0.203405
 >> iter 85000, loss: 0.083674
 >> iter 86000, loss: 0.052681
 >> iter 87000, loss: 0.032539
 >> iter 88000, loss: 0.209104
 >> iter 89000, loss: 0.113883
 >> iter 90000, loss: 0.049822
   Number of active neurons: 10
 >> iter 91000, loss: 0.067831
 >> iter 92000, loss: 0.124913
 >> iter 93000, loss: 0.130579
 >> iter 94000, loss: 0.070180
 >> iter 95000, loss: 0.058635
 >> iter 96000, loss: 0.033286
 >> iter 97000, loss: 0.017445
 >> iter 98000, loss: 0.022230
 >> iter 99000, loss: 0.028340
 >> iter 100000, loss: 0.014524
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.833138
 >> iter 2000, loss: 15.300283
 >> iter 3000, loss: 13.891243
 >> iter 4000, loss: 13.349360
 >> iter 5000, loss: 13.140949
 >> iter 6000, loss: 13.067456
 >> iter 7000, loss: 13.031318
 >> iter 8000, loss: 13.016644
 >> iter 9000, loss: 12.998272
 >> iter 10000, loss: 13.004182
   Number of active neurons: 9
 >> iter 11000, loss: 12.991315
 >> iter 12000, loss: 12.996238
 >> iter 13000, loss: 12.979040
 >> iter 14000, loss: 12.981985
 >> iter 15000, loss: 12.738284
 >> iter 16000, loss: 11.908889
 >> iter 17000, loss: 11.248126
 >> iter 18000, loss: 10.861622
 >> iter 19000, loss: 10.463877
 >> iter 20000, loss: 10.096106
   Number of active neurons: 10
 >> iter 21000, loss: 9.447128
 >> iter 22000, loss: 8.336555
 >> iter 23000, loss: 6.605310
 >> iter 24000, loss: 5.954383
 >> iter 25000, loss: 5.390488
 >> iter 26000, loss: 5.216476
 >> iter 27000, loss: 4.297997
 >> iter 28000, loss: 4.060802
 >> iter 29000, loss: 3.356894
 >> iter 30000, loss: 2.174982
   Number of active neurons: 10
 >> iter 31000, loss: 1.094237
 >> iter 32000, loss: 0.855348
 >> iter 33000, loss: 0.539304
 >> iter 34000, loss: 0.503739
 >> iter 35000, loss: 0.398999
 >> iter 36000, loss: 0.299060
 >> iter 37000, loss: 0.353826
 >> iter 38000, loss: 0.165641
 >> iter 39000, loss: 0.182924
 >> iter 40000, loss: 0.350553
   Number of active neurons: 10
 >> iter 41000, loss: 0.267619
 >> iter 42000, loss: 0.189672
 >> iter 43000, loss: 0.138429
 >> iter 44000, loss: 0.124815
 >> iter 45000, loss: 0.106868
 >> iter 46000, loss: 0.090926
 >> iter 47000, loss: 0.121847
 >> iter 48000, loss: 0.056088
 >> iter 49000, loss: 0.096062
 >> iter 50000, loss: 0.110618
   Number of active neurons: 10
 >> iter 51000, loss: 0.072163
 >> iter 52000, loss: 0.044241
 >> iter 53000, loss: 0.074343
 >> iter 54000, loss: 0.036407
 >> iter 55000, loss: 0.028430
 >> iter 56000, loss: 0.183619
 >> iter 57000, loss: 0.147447
 >> iter 58000, loss: 0.116189
 >> iter 59000, loss: 0.095199
 >> iter 60000, loss: 0.043484
   Number of active neurons: 10
 >> iter 61000, loss: 0.034676
 >> iter 62000, loss: 0.114899
 >> iter 63000, loss: 0.081447
 >> iter 64000, loss: 0.054702
 >> iter 65000, loss: 0.127534
 >> iter 66000, loss: 0.210635
 >> iter 67000, loss: 0.119958
 >> iter 68000, loss: 0.123715
 >> iter 69000, loss: 0.052909
 >> iter 70000, loss: 0.123398
   Number of active neurons: 10
 >> iter 71000, loss: 0.275932
 >> iter 72000, loss: 0.114549
 >> iter 73000, loss: 0.093048
 >> iter 74000, loss: 0.041460
 >> iter 75000, loss: 0.058110
 >> iter 76000, loss: 0.030496
 >> iter 77000, loss: 0.130485
 >> iter 78000, loss: 0.060199
 >> iter 79000, loss: 0.066225
 >> iter 80000, loss: 0.049137
   Number of active neurons: 10
 >> iter 81000, loss: 0.027935
 >> iter 82000, loss: 0.167313
 >> iter 83000, loss: 0.068594
 >> iter 84000, loss: 0.030922
 >> iter 85000, loss: 0.017054
 >> iter 86000, loss: 0.011041
 >> iter 87000, loss: 0.008876
 >> iter 88000, loss: 0.011347
 >> iter 89000, loss: 0.021640
 >> iter 90000, loss: 0.119810
   Number of active neurons: 10
 >> iter 91000, loss: 0.049252
 >> iter 92000, loss: 0.100515
 >> iter 93000, loss: 0.043135
 >> iter 94000, loss: 0.023537
 >> iter 95000, loss: 0.029104
 >> iter 96000, loss: 0.014849
 >> iter 97000, loss: 0.012435
 >> iter 98000, loss: 0.008381
 >> iter 99000, loss: 0.016394
 >> iter 100000, loss: 0.010976
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.823299
 >> iter 2000, loss: 15.289852
 >> iter 3000, loss: 13.909459
 >> iter 4000, loss: 13.393716
 >> iter 5000, loss: 13.175695
 >> iter 6000, loss: 13.097402
 >> iter 7000, loss: 13.053109
 >> iter 8000, loss: 13.045802
 >> iter 9000, loss: 13.041435
 >> iter 10000, loss: 13.045312
   Number of active neurons: 10
 >> iter 11000, loss: 13.029757
 >> iter 12000, loss: 13.033260
 >> iter 13000, loss: 13.024700
 >> iter 14000, loss: 13.036881
 >> iter 15000, loss: 13.029901
 >> iter 16000, loss: 13.024718
 >> iter 17000, loss: 13.019869
 >> iter 18000, loss: 13.023112
 >> iter 19000, loss: 13.006541
 >> iter 20000, loss: 13.014909
   Number of active neurons: 10
 >> iter 21000, loss: 12.770597
 >> iter 22000, loss: 11.946327
 >> iter 23000, loss: 11.337814
 >> iter 24000, loss: 11.134927
 >> iter 25000, loss: 10.922830
 >> iter 26000, loss: 10.592586
 >> iter 27000, loss: 9.852021
 >> iter 28000, loss: 8.564714
 >> iter 29000, loss: 7.103257
 >> iter 30000, loss: 6.350961
   Number of active neurons: 10
 >> iter 31000, loss: 6.067091
 >> iter 32000, loss: 5.726029
 >> iter 33000, loss: 5.730158
 >> iter 34000, loss: 6.204922
 >> iter 35000, loss: 5.143962
 >> iter 36000, loss: 3.691523
 >> iter 37000, loss: 2.522565
 >> iter 38000, loss: 2.206324
 >> iter 39000, loss: 1.234945
 >> iter 40000, loss: 0.943566
   Number of active neurons: 10
 >> iter 41000, loss: 0.897755
 >> iter 42000, loss: 0.697353
 >> iter 43000, loss: 0.716902
 >> iter 44000, loss: 0.569000
 >> iter 45000, loss: 0.558727
 >> iter 46000, loss: 0.417458
 >> iter 47000, loss: 0.368784
 >> iter 48000, loss: 0.490091
 >> iter 49000, loss: 0.443263
 >> iter 50000, loss: 0.284311
   Number of active neurons: 10
 >> iter 51000, loss: 0.564038
 >> iter 52000, loss: 0.518505
 >> iter 53000, loss: 0.667472
 >> iter 54000, loss: 0.382658
 >> iter 55000, loss: 0.275821
 >> iter 56000, loss: 0.256351
 >> iter 57000, loss: 0.264822
 >> iter 58000, loss: 0.322456
 >> iter 59000, loss: 0.301378
 >> iter 60000, loss: 0.211754
   Number of active neurons: 10
 >> iter 61000, loss: 0.560967
 >> iter 62000, loss: 0.682680
 >> iter 63000, loss: 0.516695
 >> iter 64000, loss: 0.303089
 >> iter 65000, loss: 0.162152
 >> iter 66000, loss: 0.274549
 >> iter 67000, loss: 0.247611
 >> iter 68000, loss: 0.193799
 >> iter 69000, loss: 0.095905
 >> iter 70000, loss: 0.105764
   Number of active neurons: 10
 >> iter 71000, loss: 0.102321
 >> iter 72000, loss: 0.105514
 >> iter 73000, loss: 0.086998
 >> iter 74000, loss: 0.172417
 >> iter 75000, loss: 0.109793
 >> iter 76000, loss: 0.204332
 >> iter 77000, loss: 0.217913
 >> iter 78000, loss: 0.103697
 >> iter 79000, loss: 0.177673
 >> iter 80000, loss: 0.097361
   Number of active neurons: 10
 >> iter 81000, loss: 0.053530
 >> iter 82000, loss: 0.032830
 >> iter 83000, loss: 0.026977
 >> iter 84000, loss: 0.125842
 >> iter 85000, loss: 0.335084
 >> iter 86000, loss: 0.429725
 >> iter 87000, loss: 0.405930
 >> iter 88000, loss: 0.404150
 >> iter 89000, loss: 0.213795
 >> iter 90000, loss: 0.235126
   Number of active neurons: 10
 >> iter 91000, loss: 0.552722
 >> iter 92000, loss: 0.920333
 >> iter 93000, loss: 0.862691
 >> iter 94000, loss: 0.500466
 >> iter 95000, loss: 0.303292
 >> iter 96000, loss: 0.192734
 >> iter 97000, loss: 0.195703
 >> iter 98000, loss: 0.121812
 >> iter 99000, loss: 0.141555
 >> iter 100000, loss: 0.076185
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0019999600008
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.841087
 >> iter 2000, loss: 15.279505
 >> iter 3000, loss: 13.897377
 >> iter 4000, loss: 13.382051
 >> iter 5000, loss: 13.173625
 >> iter 6000, loss: 13.094471
 >> iter 7000, loss: 13.051777
 >> iter 8000, loss: 13.045852
 >> iter 9000, loss: 13.031276
 >> iter 10000, loss: 13.033552
   Number of active neurons: 9
 >> iter 11000, loss: 13.015518
 >> iter 12000, loss: 13.024009
 >> iter 13000, loss: 13.016080
 >> iter 14000, loss: 13.020568
 >> iter 15000, loss: 13.015711
 >> iter 16000, loss: 13.021529
 >> iter 17000, loss: 13.013363
 >> iter 18000, loss: 13.021896
 >> iter 19000, loss: 13.011466
 >> iter 20000, loss: 13.015173
   Number of active neurons: 10
 >> iter 21000, loss: 12.999398
 >> iter 22000, loss: 13.014880
 >> iter 23000, loss: 13.008595
 >> iter 24000, loss: 13.014748
 >> iter 25000, loss: 12.999262
 >> iter 26000, loss: 13.013594
 >> iter 27000, loss: 12.997687
 >> iter 28000, loss: 13.009539
 >> iter 29000, loss: 12.999566
 >> iter 30000, loss: 13.000096
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 12.990972
 >> iter 32000, loss: 12.728777
 >> iter 33000, loss: 11.799725
 >> iter 34000, loss: 11.304733
 >> iter 35000, loss: 10.948851
 >> iter 36000, loss: 10.797821
 >> iter 37000, loss: 10.439643
 >> iter 38000, loss: 10.177474
 >> iter 39000, loss: 9.806806
 >> iter 40000, loss: 9.683895
   Number of active neurons: 10
 >> iter 41000, loss: 9.521057
 >> iter 42000, loss: 9.523248
 >> iter 43000, loss: 9.378786
 >> iter 44000, loss: 9.456864
 >> iter 45000, loss: 9.346817
 >> iter 46000, loss: 9.418757
 >> iter 47000, loss: 9.265319
 >> iter 48000, loss: 9.355710
 >> iter 49000, loss: 9.265118
 >> iter 50000, loss: 9.368411
   Number of active neurons: 10
 >> iter 51000, loss: 9.228550
 >> iter 52000, loss: 9.330809
 >> iter 53000, loss: 9.227226
 >> iter 54000, loss: 9.299649
 >> iter 55000, loss: 9.197719
 >> iter 56000, loss: 9.292742
 >> iter 57000, loss: 9.214650
 >> iter 58000, loss: 9.282157
 >> iter 59000, loss: 9.161866
 >> iter 60000, loss: 9.264168
   Number of active neurons: 10
 >> iter 61000, loss: 9.169787
 >> iter 62000, loss: 9.280073
 >> iter 63000, loss: 9.148752
 >> iter 64000, loss: 9.264012
 >> iter 65000, loss: 9.180762
 >> iter 66000, loss: 9.280535
 >> iter 67000, loss: 9.179091
 >> iter 68000, loss: 9.263041
 >> iter 69000, loss: 9.138238
 >> iter 70000, loss: 9.249500
   Number of active neurons: 10
 >> iter 71000, loss: 9.144919
 >> iter 72000, loss: 9.250267
 >> iter 73000, loss: 9.136674
 >> iter 74000, loss: 9.252372
 >> iter 75000, loss: 9.158490
 >> iter 76000, loss: 9.254241
 >> iter 77000, loss: 9.128978
 >> iter 78000, loss: 9.244435
 >> iter 79000, loss: 9.153206
 >> iter 80000, loss: 9.016928
   Number of active neurons: 10
 >> iter 81000, loss: 8.681828
 >> iter 82000, loss: 8.606873
 >> iter 83000, loss: 8.316079
 >> iter 84000, loss: 8.350273
 >> iter 85000, loss: 8.158263
 >> iter 86000, loss: 7.997001
 >> iter 87000, loss: 7.902445
 >> iter 88000, loss: 7.985270
 >> iter 89000, loss: 7.856274
 >> iter 90000, loss: 7.906547
   Number of active neurons: 10
 >> iter 91000, loss: 7.757870
 >> iter 92000, loss: 7.949308
 >> iter 93000, loss: 7.753118
 >> iter 94000, loss: 7.708493
 >> iter 95000, loss: 7.591400
 >> iter 96000, loss: 7.670967
 >> iter 97000, loss: 7.242664
 >> iter 98000, loss: 6.849668
 >> iter 99000, loss: 6.289239
 >> iter 100000, loss: 6.112678
   Number of active neurons: 10
 >> iter 101000, loss: 5.939357
 >> iter 102000, loss: 5.908207
 >> iter 103000, loss: 5.817614
 >> iter 104000, loss: 6.028122
 >> iter 105000, loss: 6.590676
 >> iter 106000, loss: 6.496023
 >> iter 107000, loss: 6.158925
 >> iter 108000, loss: 6.484797
 >> iter 109000, loss: 6.235424
 >> iter 110000, loss: 6.082761
   Number of active neurons: 10
 >> iter 111000, loss: 5.890970
 >> iter 112000, loss: 5.994405
 >> iter 113000, loss: 5.663910
 >> iter 114000, loss: 6.355223
 >> iter 115000, loss: 6.183064
 >> iter 116000, loss: 5.534510
 >> iter 117000, loss: 5.071989
 >> iter 118000, loss: 3.714074
 >> iter 119000, loss: 3.017440
 >> iter 120000, loss: 2.462228
   Number of active neurons: 10
 >> iter 121000, loss: 2.293729
 >> iter 122000, loss: 2.229024
 >> iter 123000, loss: 2.072618
 >> iter 124000, loss: 3.199207
 >> iter 125000, loss: 2.422785
 >> iter 126000, loss: 2.310679
 >> iter 127000, loss: 2.881622
 >> iter 128000, loss: 2.395157
 >> iter 129000, loss: 2.112553
 >> iter 130000, loss: 2.720523
   Number of active neurons: 10
 >> iter 131000, loss: 2.189914
 >> iter 132000, loss: 2.380450
 >> iter 133000, loss: 2.568945
 >> iter 134000, loss: 2.821948
 >> iter 135000, loss: 2.541861
 >> iter 136000, loss: 2.279511
 >> iter 137000, loss: 2.562854
 >> iter 138000, loss: 2.122815
 >> iter 139000, loss: 2.089240
 >> iter 140000, loss: 2.057168
   Number of active neurons: 10
 >> iter 141000, loss: 1.930760
 >> iter 142000, loss: 1.986526
 >> iter 143000, loss: 1.896085
 >> iter 144000, loss: 1.644790
 >> iter 145000, loss: 1.665992
 >> iter 146000, loss: 2.121700
 >> iter 147000, loss: 1.945983
 >> iter 148000, loss: 1.857654
 >> iter 149000, loss: 2.159901
 >> iter 150000, loss: 2.139323
   Number of active neurons: 10
 >> iter 151000, loss: 1.965476
 >> iter 152000, loss: 1.802997
 >> iter 153000, loss: 1.703836
 >> iter 154000, loss: 2.557948
 >> iter 155000, loss: 2.575340
 >> iter 156000, loss: 2.147627
 >> iter 157000, loss: 1.759584
 >> iter 158000, loss: 1.338578
 >> iter 159000, loss: 1.115892
 >> iter 160000, loss: 0.950396
   Number of active neurons: 10
 >> iter 161000, loss: 1.218332
 >> iter 162000, loss: 0.872332
 >> iter 163000, loss: 0.832385
 >> iter 164000, loss: 0.791979
 >> iter 165000, loss: 0.758063
 >> iter 166000, loss: 0.668508
 >> iter 167000, loss: 0.817198
 >> iter 168000, loss: 0.682850
 >> iter 169000, loss: 0.739653
 >> iter 170000, loss: 0.653160
   Number of active neurons: 10
 >> iter 171000, loss: 0.686094
 >> iter 172000, loss: 0.635900
 >> iter 173000, loss: 0.742194
 >> iter 174000, loss: 0.720842
 >> iter 175000, loss: 0.699453
 >> iter 176000, loss: 0.660301
 >> iter 177000, loss: 0.699260
 >> iter 178000, loss: 0.623811
 >> iter 179000, loss: 0.675142
 >> iter 180000, loss: 0.657027
   Number of active neurons: 10
 >> iter 181000, loss: 0.675876
 >> iter 182000, loss: 0.634481
 >> iter 183000, loss: 0.742311
 >> iter 184000, loss: 0.803873
 >> iter 185000, loss: 0.730708
 >> iter 186000, loss: 0.628635
 >> iter 187000, loss: 0.749306
 >> iter 188000, loss: 0.641871
 >> iter 189000, loss: 0.659592
 >> iter 190000, loss: 0.658028
   Number of active neurons: 10
 >> iter 191000, loss: 0.803930
 >> iter 192000, loss: 0.654986
 >> iter 193000, loss: 0.764373
 >> iter 194000, loss: 0.720255
 >> iter 195000, loss: 0.720963
 >> iter 196000, loss: 0.642572
 >> iter 197000, loss: 0.678699
 >> iter 198000, loss: 0.594506
 >> iter 199000, loss: 0.691096
 >> iter 200000, loss: 0.669701
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 1.17997640047
   - Test - Long: 10.2294885256
   - Test - Big: 1.05898941011
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.858688
 >> iter 2000, loss: 15.361251
 >> iter 3000, loss: 13.959628
 >> iter 4000, loss: 13.401024
 >> iter 5000, loss: 13.166360
 >> iter 6000, loss: 13.080118
 >> iter 7000, loss: 13.039795
 >> iter 8000, loss: 13.025234
 >> iter 9000, loss: 13.006547
 >> iter 10000, loss: 13.021434
   Number of active neurons: 10
 >> iter 11000, loss: 13.004325
 >> iter 12000, loss: 13.011580
 >> iter 13000, loss: 13.000911
 >> iter 14000, loss: 13.008145
 >> iter 15000, loss: 13.001485
 >> iter 16000, loss: 13.011346
 >> iter 17000, loss: 12.999553
 >> iter 18000, loss: 12.980893
 >> iter 19000, loss: 12.237348
 >> iter 20000, loss: 11.557644
   Number of active neurons: 10
 >> iter 21000, loss: 11.131495
 >> iter 22000, loss: 10.929568
 >> iter 23000, loss: 10.674620
 >> iter 24000, loss: 10.428461
 >> iter 25000, loss: 10.156067
 >> iter 26000, loss: 9.986560
 >> iter 27000, loss: 9.742065
 >> iter 28000, loss: 9.569042
 >> iter 29000, loss: 9.250087
 >> iter 30000, loss: 9.007811
   Number of active neurons: 10
 >> iter 31000, loss: 8.485635
 >> iter 32000, loss: 8.178551
 >> iter 33000, loss: 7.282888
 >> iter 34000, loss: 6.308861
 >> iter 35000, loss: 5.947205
 >> iter 36000, loss: 5.771173
 >> iter 37000, loss: 5.427455
 >> iter 38000, loss: 5.484939
 >> iter 39000, loss: 5.359653
 >> iter 40000, loss: 5.247223
   Number of active neurons: 10
 >> iter 41000, loss: 4.994795
 >> iter 42000, loss: 5.211755
 >> iter 43000, loss: 5.008584
 >> iter 44000, loss: 5.072428
 >> iter 45000, loss: 5.030313
 >> iter 46000, loss: 5.030596
 >> iter 47000, loss: 4.949538
 >> iter 48000, loss: 5.063936
 >> iter 49000, loss: 4.967674
 >> iter 50000, loss: 5.027554
   Number of active neurons: 10
 >> iter 51000, loss: 4.963463
 >> iter 52000, loss: 4.933890
 >> iter 53000, loss: 4.840597
 >> iter 54000, loss: 4.970960
 >> iter 55000, loss: 4.923182
 >> iter 56000, loss: 4.941390
 >> iter 57000, loss: 5.077739
 >> iter 58000, loss: 5.027045
 >> iter 59000, loss: 4.922539
 >> iter 60000, loss: 4.862583
   Number of active neurons: 10
 >> iter 61000, loss: 4.835094
 >> iter 62000, loss: 4.943189
 >> iter 63000, loss: 4.817012
 >> iter 64000, loss: 5.015879
 >> iter 65000, loss: 4.788028
 >> iter 66000, loss: 4.920720
 >> iter 67000, loss: 4.923742
 >> iter 68000, loss: 4.990041
 >> iter 69000, loss: 4.823707
 >> iter 70000, loss: 4.851987
   Number of active neurons: 10
 >> iter 71000, loss: 4.749186
 >> iter 72000, loss: 4.816858
 >> iter 73000, loss: 4.717424
 >> iter 74000, loss: 4.805061
 >> iter 75000, loss: 4.819264
 >> iter 76000, loss: 4.861500
 >> iter 77000, loss: 4.744768
 >> iter 78000, loss: 4.900780
 >> iter 79000, loss: 4.702041
 >> iter 80000, loss: 4.937531
   Number of active neurons: 10
 >> iter 81000, loss: 4.834688
 >> iter 82000, loss: 5.118641
 >> iter 83000, loss: 4.839714
 >> iter 84000, loss: 4.929621
 >> iter 85000, loss: 4.787007
 >> iter 86000, loss: 4.974818
 >> iter 87000, loss: 4.832428
 >> iter 88000, loss: 4.917220
 >> iter 89000, loss: 4.819308
 >> iter 90000, loss: 4.850961
   Number of active neurons: 10
 >> iter 91000, loss: 4.934153
 >> iter 92000, loss: 4.862544
 >> iter 93000, loss: 4.964463
 >> iter 94000, loss: 5.062597
 >> iter 95000, loss: 4.913712
 >> iter 96000, loss: 4.851573
 >> iter 97000, loss: 4.761474
 >> iter 98000, loss: 4.745436
 >> iter 99000, loss: 4.807025
 >> iter 100000, loss: 4.832865
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 9.15781684366
   - Test - Long: 28.6235688216
   - Test - Big: 9.0499095009
   - Test - A: 3.39310712619
   - Test - B: 11.4659022732
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.808798
 >> iter 2000, loss: 15.260619
 >> iter 3000, loss: 13.863278
 >> iter 4000, loss: 13.347051
 >> iter 5000, loss: 13.141860
 >> iter 6000, loss: 13.071154
 >> iter 7000, loss: 13.037058
 >> iter 8000, loss: 13.028421
 >> iter 9000, loss: 13.017225
 >> iter 10000, loss: 13.014951
   Number of active neurons: 10
 >> iter 11000, loss: 13.007823
 >> iter 12000, loss: 13.014893
 >> iter 13000, loss: 12.989523
 >> iter 14000, loss: 13.000511
 >> iter 15000, loss: 12.988238
 >> iter 16000, loss: 12.990963
 >> iter 17000, loss: 12.991328
 >> iter 18000, loss: 12.994252
 >> iter 19000, loss: 12.981980
 >> iter 20000, loss: 12.959219
   Number of active neurons: 10
 >> iter 21000, loss: 12.243772
 >> iter 22000, loss: 11.554507
 >> iter 23000, loss: 11.118755
 >> iter 24000, loss: 10.994848
 >> iter 25000, loss: 10.799752
 >> iter 26000, loss: 10.620747
 >> iter 27000, loss: 10.229952
 >> iter 28000, loss: 10.065047
 >> iter 29000, loss: 9.747520
 >> iter 30000, loss: 9.611646
   Number of active neurons: 10
 >> iter 31000, loss: 9.391959
 >> iter 32000, loss: 9.419185
 >> iter 33000, loss: 9.226586
 >> iter 34000, loss: 9.164649
 >> iter 35000, loss: 8.988910
 >> iter 36000, loss: 8.215476
 >> iter 37000, loss: 7.490432
 >> iter 38000, loss: 4.711650
 >> iter 39000, loss: 3.058535
 >> iter 40000, loss: 2.007810
   Number of active neurons: 10
 >> iter 41000, loss: 1.591874
 >> iter 42000, loss: 1.175359
 >> iter 43000, loss: 0.994937
 >> iter 44000, loss: 1.025008
 >> iter 45000, loss: 1.018891
 >> iter 46000, loss: 0.848098
 >> iter 47000, loss: 0.725382
 >> iter 48000, loss: 0.575033
 >> iter 49000, loss: 0.645865
 >> iter 50000, loss: 0.570474
   Number of active neurons: 10
 >> iter 51000, loss: 0.458560
 >> iter 52000, loss: 0.361918
 >> iter 53000, loss: 0.306725
 >> iter 54000, loss: 0.342439
 >> iter 55000, loss: 0.423034
 >> iter 56000, loss: 0.389748
 >> iter 57000, loss: 0.262770
 >> iter 58000, loss: 0.220925
 >> iter 59000, loss: 0.147013
 >> iter 60000, loss: 0.256302
   Number of active neurons: 10
 >> iter 61000, loss: 0.262292
 >> iter 62000, loss: 0.183261
 >> iter 63000, loss: 0.103398
 >> iter 64000, loss: 0.146902
 >> iter 65000, loss: 0.168075
 >> iter 66000, loss: 0.248352
 >> iter 67000, loss: 0.200929
 >> iter 68000, loss: 0.140202
 >> iter 69000, loss: 0.095250
 >> iter 70000, loss: 0.050763
   Number of active neurons: 10
 >> iter 71000, loss: 0.060369
 >> iter 72000, loss: 0.133404
 >> iter 73000, loss: 0.217625
 >> iter 74000, loss: 0.368979
 >> iter 75000, loss: 0.168592
 >> iter 76000, loss: 0.077312
 >> iter 77000, loss: 0.074011
 >> iter 78000, loss: 0.242715
 >> iter 79000, loss: 0.105317
 >> iter 80000, loss: 0.135287
   Number of active neurons: 10
 >> iter 81000, loss: 0.077804
 >> iter 82000, loss: 0.220240
 >> iter 83000, loss: 0.137904
 >> iter 84000, loss: 0.065010
 >> iter 85000, loss: 0.042487
 >> iter 86000, loss: 0.177512
 >> iter 87000, loss: 0.081361
 >> iter 88000, loss: 0.107957
 >> iter 89000, loss: 0.057828
 >> iter 90000, loss: 0.148535
   Number of active neurons: 10
 >> iter 91000, loss: 0.065366
 >> iter 92000, loss: 0.084129
 >> iter 93000, loss: 0.094374
 >> iter 94000, loss: 0.076249
 >> iter 95000, loss: 0.432817
 >> iter 96000, loss: 0.197005
 >> iter 97000, loss: 0.109691
 >> iter 98000, loss: 0.094913
 >> iter 99000, loss: 0.175788
 >> iter 100000, loss: 0.076641
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.871740
 >> iter 2000, loss: 15.329569
 >> iter 3000, loss: 13.919287
 >> iter 4000, loss: 13.394505
 >> iter 5000, loss: 13.191321
 >> iter 6000, loss: 13.109389
 >> iter 7000, loss: 13.056845
 >> iter 8000, loss: 13.052213
 >> iter 9000, loss: 13.035866
 >> iter 10000, loss: 13.033539
   Number of active neurons: 10
 >> iter 11000, loss: 13.015425
 >> iter 12000, loss: 13.021515
 >> iter 13000, loss: 13.011193
 >> iter 14000, loss: 13.016767
 >> iter 15000, loss: 13.006228
 >> iter 16000, loss: 13.018388
 >> iter 17000, loss: 13.012056
 >> iter 18000, loss: 13.013328
 >> iter 19000, loss: 13.004803
 >> iter 20000, loss: 13.014431
   Number of active neurons: 10
 >> iter 21000, loss: 12.994054
 >> iter 22000, loss: 12.841635
 >> iter 23000, loss: 11.908691
 >> iter 24000, loss: 11.351927
 >> iter 25000, loss: 10.954074
 >> iter 26000, loss: 10.612756
 >> iter 27000, loss: 9.992678
 >> iter 28000, loss: 8.933078
 >> iter 29000, loss: 7.895843
 >> iter 30000, loss: 7.147556
   Number of active neurons: 10
 >> iter 31000, loss: 6.506966
 >> iter 32000, loss: 6.209553
 >> iter 33000, loss: 5.965086
 >> iter 34000, loss: 5.919493
 >> iter 35000, loss: 5.857448
 >> iter 36000, loss: 5.818923
 >> iter 37000, loss: 5.875996
 >> iter 38000, loss: 5.907676
 >> iter 39000, loss: 5.997715
 >> iter 40000, loss: 5.758021
   Number of active neurons: 10
 >> iter 41000, loss: 5.747472
 >> iter 42000, loss: 5.666639
 >> iter 43000, loss: 5.356328
 >> iter 44000, loss: 4.759820
 >> iter 45000, loss: 4.244738
 >> iter 46000, loss: 3.911759
 >> iter 47000, loss: 3.059504
 >> iter 48000, loss: 1.561847
 >> iter 49000, loss: 1.056460
 >> iter 50000, loss: 0.528095
   Number of active neurons: 10
 >> iter 51000, loss: 0.381049
 >> iter 52000, loss: 0.377915
 >> iter 53000, loss: 0.264425
 >> iter 54000, loss: 0.166598
 >> iter 55000, loss: 0.212775
 >> iter 56000, loss: 0.217964
 >> iter 57000, loss: 0.498768
 >> iter 58000, loss: 0.505467
 >> iter 59000, loss: 0.494814
 >> iter 60000, loss: 0.341675
   Number of active neurons: 10
 >> iter 61000, loss: 0.155487
 >> iter 62000, loss: 0.203451
 >> iter 63000, loss: 0.154081
 >> iter 64000, loss: 0.224040
 >> iter 65000, loss: 0.181704
 >> iter 66000, loss: 0.355852
 >> iter 67000, loss: 0.175852
 >> iter 68000, loss: 0.238806
 >> iter 69000, loss: 0.194779
 >> iter 70000, loss: 0.292676
   Number of active neurons: 10
 >> iter 71000, loss: 0.197406
 >> iter 72000, loss: 0.225107
 >> iter 73000, loss: 0.187648
 >> iter 74000, loss: 0.328188
 >> iter 75000, loss: 0.240027
 >> iter 76000, loss: 0.263318
 >> iter 77000, loss: 0.177128
 >> iter 78000, loss: 0.106065
 >> iter 79000, loss: 0.080318
 >> iter 80000, loss: 0.132141
   Number of active neurons: 10
 >> iter 81000, loss: 0.212774
 >> iter 82000, loss: 0.092793
 >> iter 83000, loss: 0.078504
 >> iter 84000, loss: 0.142121
 >> iter 85000, loss: 0.130040
 >> iter 86000, loss: 0.069370
 >> iter 87000, loss: 0.042605
 >> iter 88000, loss: 0.027367
 >> iter 89000, loss: 0.026633
 >> iter 90000, loss: 0.052238
   Number of active neurons: 10
 >> iter 91000, loss: 0.044135
 >> iter 92000, loss: 0.024232
 >> iter 93000, loss: 0.050340
 >> iter 94000, loss: 0.030283
 >> iter 95000, loss: 0.017110
 >> iter 96000, loss: 0.394390
 >> iter 97000, loss: 0.157987
 >> iter 98000, loss: 0.066974
 >> iter 99000, loss: 0.062159
 >> iter 100000, loss: 0.105918
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.837272
 >> iter 2000, loss: 15.287955
 >> iter 3000, loss: 13.909777
 >> iter 4000, loss: 13.365897
 >> iter 5000, loss: 13.140200
 >> iter 6000, loss: 13.060175
 >> iter 7000, loss: 13.021938
 >> iter 8000, loss: 13.005854
 >> iter 9000, loss: 12.994015
 >> iter 10000, loss: 13.006680
   Number of active neurons: 10
 >> iter 11000, loss: 12.994606
 >> iter 12000, loss: 12.992110
 >> iter 13000, loss: 12.981200
 >> iter 14000, loss: 12.985716
 >> iter 15000, loss: 12.972345
 >> iter 16000, loss: 12.859945
 >> iter 17000, loss: 12.048357
 >> iter 18000, loss: 11.437661
 >> iter 19000, loss: 10.907437
 >> iter 20000, loss: 10.331816
   Number of active neurons: 10
 >> iter 21000, loss: 9.181041
 >> iter 22000, loss: 7.685502
 >> iter 23000, loss: 5.993720
 >> iter 24000, loss: 5.975293
 >> iter 25000, loss: 4.792818
 >> iter 26000, loss: 2.741045
 >> iter 27000, loss: 1.714476
 >> iter 28000, loss: 1.557865
 >> iter 29000, loss: 0.977161
 >> iter 30000, loss: 1.025534
   Number of active neurons: 10
 >> iter 31000, loss: 0.588006
 >> iter 32000, loss: 0.363554
 >> iter 33000, loss: 0.403429
 >> iter 34000, loss: 0.530063
 >> iter 35000, loss: 0.365403
 >> iter 36000, loss: 0.843563
 >> iter 37000, loss: 0.762481
 >> iter 38000, loss: 0.816615
 >> iter 39000, loss: 0.549608
 >> iter 40000, loss: 0.464988
   Number of active neurons: 10
 >> iter 41000, loss: 0.426440
 >> iter 42000, loss: 0.299244
 >> iter 43000, loss: 0.291119
 >> iter 44000, loss: 0.357139
 >> iter 45000, loss: 0.362706
 >> iter 46000, loss: 0.468710
 >> iter 47000, loss: 0.244058
 >> iter 48000, loss: 0.165826
 >> iter 49000, loss: 0.102509
 >> iter 50000, loss: 0.136169
   Number of active neurons: 10
 >> iter 51000, loss: 0.169702
 >> iter 52000, loss: 0.300274
 >> iter 53000, loss: 0.138460
 >> iter 54000, loss: 0.106368
 >> iter 55000, loss: 0.155950
 >> iter 56000, loss: 0.101659
 >> iter 57000, loss: 0.072349
 >> iter 58000, loss: 0.144520
 >> iter 59000, loss: 0.126578
 >> iter 60000, loss: 0.109872
   Number of active neurons: 10
 >> iter 61000, loss: 0.065320
 >> iter 62000, loss: 0.425158
 >> iter 63000, loss: 0.175558
 >> iter 64000, loss: 0.081769
 >> iter 65000, loss: 0.115460
 >> iter 66000, loss: 0.124919
 >> iter 67000, loss: 0.059158
 >> iter 68000, loss: 0.033313
 >> iter 69000, loss: 0.100706
 >> iter 70000, loss: 0.244138
   Number of active neurons: 10
 >> iter 71000, loss: 0.137991
 >> iter 72000, loss: 0.085085
 >> iter 73000, loss: 0.045235
 >> iter 74000, loss: 0.112007
 >> iter 75000, loss: 0.051427
 >> iter 76000, loss: 0.056801
 >> iter 77000, loss: 0.052425
 >> iter 78000, loss: 0.189617
 >> iter 79000, loss: 0.113009
 >> iter 80000, loss: 0.091254
   Number of active neurons: 10
 >> iter 81000, loss: 0.046050
 >> iter 82000, loss: 0.301571
 >> iter 83000, loss: 0.199736
 >> iter 84000, loss: 0.098167
 >> iter 85000, loss: 0.085936
 >> iter 86000, loss: 0.040267
 >> iter 87000, loss: 0.033756
 >> iter 88000, loss: 0.122719
 >> iter 89000, loss: 0.158958
 >> iter 90000, loss: 0.161713
   Number of active neurons: 10
 >> iter 91000, loss: 0.068691
 >> iter 92000, loss: 0.084415
 >> iter 93000, loss: 0.040536
 >> iter 94000, loss: 0.088323
 >> iter 95000, loss: 0.039684
 >> iter 96000, loss: 0.021953
 >> iter 97000, loss: 0.014771
 >> iter 98000, loss: 0.036132
 >> iter 99000, loss: 0.019993
 >> iter 100000, loss: 0.113772
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.803397
 >> iter 2000, loss: 15.257353
 >> iter 3000, loss: 13.868644
 >> iter 4000, loss: 13.367350
 >> iter 5000, loss: 13.149581
 >> iter 6000, loss: 13.068933
 >> iter 7000, loss: 13.031338
 >> iter 8000, loss: 13.030313
 >> iter 9000, loss: 13.010249
 >> iter 10000, loss: 13.009384
   Number of active neurons: 9
 >> iter 11000, loss: 13.008934
 >> iter 12000, loss: 13.006954
 >> iter 13000, loss: 12.996981
 >> iter 14000, loss: 13.007146
 >> iter 15000, loss: 13.006755
 >> iter 16000, loss: 13.018610
 >> iter 17000, loss: 13.009059
 >> iter 18000, loss: 13.009086
 >> iter 19000, loss: 13.005055
 >> iter 20000, loss: 13.010566
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 13.001059
 >> iter 22000, loss: 13.021964
 >> iter 23000, loss: 13.002120
 >> iter 24000, loss: 13.016397
 >> iter 25000, loss: 13.008421
 >> iter 26000, loss: 13.021934
 >> iter 27000, loss: 13.000682
 >> iter 28000, loss: 12.989687
 >> iter 29000, loss: 12.483722
 >> iter 30000, loss: 11.716021
   Number of active neurons: 10
 >> iter 31000, loss: 11.203774
 >> iter 32000, loss: 11.037719
 >> iter 33000, loss: 10.850216
 >> iter 34000, loss: 10.762343
 >> iter 35000, loss: 10.480542
 >> iter 36000, loss: 10.146729
 >> iter 37000, loss: 9.704422
 >> iter 38000, loss: 9.498463
 >> iter 39000, loss: 9.187942
 >> iter 40000, loss: 9.103616
   Number of active neurons: 10
 >> iter 41000, loss: 8.831781
 >> iter 42000, loss: 8.689599
 >> iter 43000, loss: 8.432369
 >> iter 44000, loss: 8.308652
 >> iter 45000, loss: 8.173117
 >> iter 46000, loss: 8.102561
 >> iter 47000, loss: 7.933371
 >> iter 48000, loss: 7.992505
 >> iter 49000, loss: 7.837991
 >> iter 50000, loss: 7.826676
   Number of active neurons: 10
 >> iter 51000, loss: 7.819688
 >> iter 52000, loss: 7.961997
 >> iter 53000, loss: 7.739676
 >> iter 54000, loss: 7.242159
 >> iter 55000, loss: 6.955403
 >> iter 56000, loss: 5.944987
 >> iter 57000, loss: 4.761802
 >> iter 58000, loss: 4.100840
 >> iter 59000, loss: 2.989154
 >> iter 60000, loss: 1.711041
   Number of active neurons: 10
 >> iter 61000, loss: 1.072161
 >> iter 62000, loss: 0.842782
 >> iter 63000, loss: 1.101128
 >> iter 64000, loss: 0.899597
 >> iter 65000, loss: 0.631469
 >> iter 66000, loss: 0.657600
 >> iter 67000, loss: 0.647550
 >> iter 68000, loss: 0.543781
 >> iter 69000, loss: 0.562591
 >> iter 70000, loss: 0.430950
   Number of active neurons: 10
 >> iter 71000, loss: 0.419187
 >> iter 72000, loss: 0.422367
 >> iter 73000, loss: 0.314931
 >> iter 74000, loss: 0.315413
 >> iter 75000, loss: 0.302718
 >> iter 76000, loss: 0.220469
 >> iter 77000, loss: 0.273622
 >> iter 78000, loss: 0.212945
 >> iter 79000, loss: 0.223189
 >> iter 80000, loss: 0.179608
   Number of active neurons: 10
 >> iter 81000, loss: 0.253445
 >> iter 82000, loss: 0.227800
 >> iter 83000, loss: 0.139211
 >> iter 84000, loss: 0.068949
 >> iter 85000, loss: 0.181357
 >> iter 86000, loss: 0.222502
 >> iter 87000, loss: 0.217919
 >> iter 88000, loss: 0.097792
 >> iter 89000, loss: 0.117194
 >> iter 90000, loss: 0.302555
   Number of active neurons: 10
 >> iter 91000, loss: 0.436831
 >> iter 92000, loss: 0.268379
 >> iter 93000, loss: 0.177181
 >> iter 94000, loss: 0.167632
 >> iter 95000, loss: 0.203059
 >> iter 96000, loss: 0.107183
 >> iter 97000, loss: 0.207494
 >> iter 98000, loss: 0.103714
 >> iter 99000, loss: 0.270316
 >> iter 100000, loss: 0.150836
   Number of active neurons: 10
 >> iter 101000, loss: 0.244609
 >> iter 102000, loss: 0.251203
 >> iter 103000, loss: 0.138629
 >> iter 104000, loss: 0.070867
 >> iter 105000, loss: 0.046652
 >> iter 106000, loss: 0.201041
 >> iter 107000, loss: 0.191158
 >> iter 108000, loss: 0.146734
 >> iter 109000, loss: 0.186087
 >> iter 110000, loss: 0.154996
   Number of active neurons: 10
 >> iter 111000, loss: 0.076063
 >> iter 112000, loss: 0.079916
 >> iter 113000, loss: 0.128324
 >> iter 114000, loss: 0.078705
 >> iter 115000, loss: 0.153003
 >> iter 116000, loss: 0.132627
 >> iter 117000, loss: 0.227128
 >> iter 118000, loss: 0.288232
 >> iter 119000, loss: 0.148245
 >> iter 120000, loss: 0.066804
   Number of active neurons: 10
 >> iter 121000, loss: 0.162942
 >> iter 122000, loss: 0.126960
 >> iter 123000, loss: 0.079000
 >> iter 124000, loss: 0.141341
 >> iter 125000, loss: 0.062807
 >> iter 126000, loss: 0.032863
 >> iter 127000, loss: 0.021045
 >> iter 128000, loss: 0.016057
 >> iter 129000, loss: 0.012527
 >> iter 130000, loss: 0.034488
   Number of active neurons: 10
 >> iter 131000, loss: 0.182056
 >> iter 132000, loss: 0.079771
 >> iter 133000, loss: 0.392300
 >> iter 134000, loss: 0.209476
 >> iter 135000, loss: 0.118606
 >> iter 136000, loss: 0.228696
 >> iter 137000, loss: 0.165978
 >> iter 138000, loss: 0.179227
 >> iter 139000, loss: 0.085013
 >> iter 140000, loss: 0.040588
   Number of active neurons: 10
 >> iter 141000, loss: 0.023005
 >> iter 142000, loss: 0.015823
 >> iter 143000, loss: 0.142603
 >> iter 144000, loss: 0.110548
 >> iter 145000, loss: 0.048205
 >> iter 146000, loss: 0.024547
 >> iter 147000, loss: 0.026165
 >> iter 148000, loss: 0.242157
 >> iter 149000, loss: 0.097052
 >> iter 150000, loss: 0.042756
   Number of active neurons: 10
 >> iter 151000, loss: 0.031493
 >> iter 152000, loss: 0.018084
 >> iter 153000, loss: 0.034271
 >> iter 154000, loss: 0.048659
 >> iter 155000, loss: 0.027156
 >> iter 156000, loss: 0.029420
 >> iter 157000, loss: 0.016439
 >> iter 158000, loss: 0.011018
 >> iter 159000, loss: 0.027039
 >> iter 160000, loss: 0.014542
   Number of active neurons: 10
 >> iter 161000, loss: 0.009739
 >> iter 162000, loss: 0.008235
 >> iter 163000, loss: 0.007161
 >> iter 164000, loss: 0.086266
 >> iter 165000, loss: 0.036326
 >> iter 166000, loss: 0.017606
 >> iter 167000, loss: 0.150140
 >> iter 168000, loss: 0.060254
 >> iter 169000, loss: 0.026460
 >> iter 170000, loss: 0.152938
   Number of active neurons: 10
 >> iter 171000, loss: 0.138762
 >> iter 172000, loss: 0.060017
 >> iter 173000, loss: 0.028099
 >> iter 174000, loss: 0.149415
 >> iter 175000, loss: 0.059931
 >> iter 176000, loss: 0.081099
 >> iter 177000, loss: 0.099372
 >> iter 178000, loss: 0.044255
 >> iter 179000, loss: 0.037015
 >> iter 180000, loss: 0.018592
   Number of active neurons: 10
 >> iter 181000, loss: 0.171608
 >> iter 182000, loss: 0.069473
 >> iter 183000, loss: 0.034737
 >> iter 184000, loss: 0.054709
 >> iter 185000, loss: 0.032594
 >> iter 186000, loss: 0.017738
 >> iter 187000, loss: 0.011587
 >> iter 188000, loss: 0.013924
 >> iter 189000, loss: 0.009158
 >> iter 190000, loss: 0.007537
   Number of active neurons: 10
 >> iter 191000, loss: 0.006353
 >> iter 192000, loss: 0.005882
 >> iter 193000, loss: 0.069130
 >> iter 194000, loss: 0.062748
 >> iter 195000, loss: 0.028041
 >> iter 196000, loss: 0.013931
 >> iter 197000, loss: 0.008496
 >> iter 198000, loss: 0.006342
 >> iter 199000, loss: 0.007459
 >> iter 200000, loss: 0.007720
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.822300
 >> iter 2000, loss: 15.317444
 >> iter 3000, loss: 13.910917
 >> iter 4000, loss: 13.380540
 >> iter 5000, loss: 13.158408
 >> iter 6000, loss: 13.074607
 >> iter 7000, loss: 13.039959
 >> iter 8000, loss: 13.030166
 >> iter 9000, loss: 13.004744
 >> iter 10000, loss: 13.022170
   Number of active neurons: 9
 >> iter 11000, loss: 13.007141
 >> iter 12000, loss: 13.019921
 >> iter 13000, loss: 13.003258
 >> iter 14000, loss: 13.013567
 >> iter 15000, loss: 13.001631
 >> iter 16000, loss: 13.003259
 >> iter 17000, loss: 13.004010
 >> iter 18000, loss: 13.007330
 >> iter 19000, loss: 12.996128
 >> iter 20000, loss: 12.727767
   Number of active neurons: 10
 >> iter 21000, loss: 11.828005
 >> iter 22000, loss: 11.294175
 >> iter 23000, loss: 10.785224
 >> iter 24000, loss: 10.186908
 >> iter 25000, loss: 9.555111
 >> iter 26000, loss: 9.252460
 >> iter 27000, loss: 8.905603
 >> iter 28000, loss: 8.776641
 >> iter 29000, loss: 8.420102
 >> iter 30000, loss: 8.113954
   Number of active neurons: 10
 >> iter 31000, loss: 7.680148
 >> iter 32000, loss: 7.495215
 >> iter 33000, loss: 6.993149
 >> iter 34000, loss: 6.344632
 >> iter 35000, loss: 5.594256
 >> iter 36000, loss: 5.384267
 >> iter 37000, loss: 8.129391
 >> iter 38000, loss: 7.693092
 >> iter 39000, loss: 5.641625
 >> iter 40000, loss: 4.382129
   Number of active neurons: 10
 >> iter 41000, loss: 3.588439
 >> iter 42000, loss: 3.212052
 >> iter 43000, loss: 2.817528
 >> iter 44000, loss: 2.699646
 >> iter 45000, loss: 2.750736
 >> iter 46000, loss: 2.357694
 >> iter 47000, loss: 2.118439
 >> iter 48000, loss: 1.969784
 >> iter 49000, loss: 1.865427
 >> iter 50000, loss: 1.242052
   Number of active neurons: 10
 >> iter 51000, loss: 1.447260
 >> iter 52000, loss: 0.879739
 >> iter 53000, loss: 0.528082
 >> iter 54000, loss: 0.783656
 >> iter 55000, loss: 0.898326
 >> iter 56000, loss: 0.775820
 >> iter 57000, loss: 0.486869
 >> iter 58000, loss: 0.432969
 >> iter 59000, loss: 0.345833
 >> iter 60000, loss: 0.282659
   Number of active neurons: 10
 >> iter 61000, loss: 0.220855
 >> iter 62000, loss: 0.134288
 >> iter 63000, loss: 0.298891
 >> iter 64000, loss: 0.184482
 >> iter 65000, loss: 0.187707
 >> iter 66000, loss: 0.153942
 >> iter 67000, loss: 0.217719
 >> iter 68000, loss: 0.147363
 >> iter 69000, loss: 0.404761
 >> iter 70000, loss: 0.256320
   Number of active neurons: 10
 >> iter 71000, loss: 0.128552
 >> iter 72000, loss: 0.108608
 >> iter 73000, loss: 0.116537
 >> iter 74000, loss: 0.088357
 >> iter 75000, loss: 0.053092
 >> iter 76000, loss: 0.035315
 >> iter 77000, loss: 0.033822
 >> iter 78000, loss: 0.051825
 >> iter 79000, loss: 0.040974
 >> iter 80000, loss: 0.024764
   Number of active neurons: 10
 >> iter 81000, loss: 0.058152
 >> iter 82000, loss: 0.037929
 >> iter 83000, loss: 0.080906
 >> iter 84000, loss: 0.057112
 >> iter 85000, loss: 0.083600
 >> iter 86000, loss: 0.125907
 >> iter 87000, loss: 0.063265
 >> iter 88000, loss: 0.086556
 >> iter 89000, loss: 0.082444
 >> iter 90000, loss: 0.062554
   Number of active neurons: 10
 >> iter 91000, loss: 0.260128
 >> iter 92000, loss: 0.198522
 >> iter 93000, loss: 0.243671
 >> iter 94000, loss: 0.147917
 >> iter 95000, loss: 0.170957
 >> iter 96000, loss: 0.144770
 >> iter 97000, loss: 0.121617
 >> iter 98000, loss: 0.054030
 >> iter 99000, loss: 0.039171
 >> iter 100000, loss: 0.023181
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.859018
 >> iter 2000, loss: 15.326892
 >> iter 3000, loss: 13.903378
 >> iter 4000, loss: 13.360098
 >> iter 5000, loss: 13.143434
 >> iter 6000, loss: 13.062311
 >> iter 7000, loss: 13.028801
 >> iter 8000, loss: 13.009292
 >> iter 9000, loss: 12.997689
 >> iter 10000, loss: 12.999995
   Number of active neurons: 9
 >> iter 11000, loss: 12.986657
 >> iter 12000, loss: 13.003916
 >> iter 13000, loss: 12.989388
 >> iter 14000, loss: 12.999229
 >> iter 15000, loss: 12.987310
 >> iter 16000, loss: 12.993488
 >> iter 17000, loss: 12.989961
 >> iter 18000, loss: 12.991984
 >> iter 19000, loss: 12.982078
 >> iter 20000, loss: 12.989431
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 12.973758
 >> iter 22000, loss: 12.982302
 >> iter 23000, loss: 12.967287
 >> iter 24000, loss: 12.963968
 >> iter 25000, loss: 12.402711
 >> iter 26000, loss: 11.636880
 >> iter 27000, loss: 11.128874
 >> iter 28000, loss: 10.958791
 >> iter 29000, loss: 10.727339
 >> iter 30000, loss: 10.511802
   Number of active neurons: 10
 >> iter 31000, loss: 10.241275
 >> iter 32000, loss: 9.747837
 >> iter 33000, loss: 8.814346
 >> iter 34000, loss: 8.366618
 >> iter 35000, loss: 7.917870
 >> iter 36000, loss: 7.352094
 >> iter 37000, loss: 7.094199
 >> iter 38000, loss: 6.752274
 >> iter 39000, loss: 6.566817
 >> iter 40000, loss: 6.363802
   Number of active neurons: 10
 >> iter 41000, loss: 6.321987
 >> iter 42000, loss: 6.088169
 >> iter 43000, loss: 5.972655
 >> iter 44000, loss: 5.837014
 >> iter 45000, loss: 5.913239
 >> iter 46000, loss: 5.954366
 >> iter 47000, loss: 6.070891
 >> iter 48000, loss: 6.076331
 >> iter 49000, loss: 6.100359
 >> iter 50000, loss: 5.953139
   Number of active neurons: 10
 >> iter 51000, loss: 5.936338
 >> iter 52000, loss: 5.909971
 >> iter 53000, loss: 5.959307
 >> iter 54000, loss: 5.737840
 >> iter 55000, loss: 5.804313
 >> iter 56000, loss: 5.941509
 >> iter 57000, loss: 6.063762
 >> iter 58000, loss: 6.093087
 >> iter 59000, loss: 6.156415
 >> iter 60000, loss: 5.975359
   Number of active neurons: 10
 >> iter 61000, loss: 6.372022
 >> iter 62000, loss: 6.190016
 >> iter 63000, loss: 6.150227
 >> iter 64000, loss: 6.184180
 >> iter 65000, loss: 6.104143
 >> iter 66000, loss: 5.951818
 >> iter 67000, loss: 5.967827
 >> iter 68000, loss: 6.025937
 >> iter 69000, loss: 6.011535
 >> iter 70000, loss: 5.964253
   Number of active neurons: 10
 >> iter 71000, loss: 6.358185
 >> iter 72000, loss: 6.040186
 >> iter 73000, loss: 5.996705
 >> iter 74000, loss: 5.912961
 >> iter 75000, loss: 5.918820
 >> iter 76000, loss: 5.714980
 >> iter 77000, loss: 5.685092
 >> iter 78000, loss: 5.736887
 >> iter 79000, loss: 5.645866
 >> iter 80000, loss: 5.229924
   Number of active neurons: 10
 >> iter 81000, loss: 5.036728
 >> iter 82000, loss: 4.946307
 >> iter 83000, loss: 4.844605
 >> iter 84000, loss: 4.984236
 >> iter 85000, loss: 4.752924
 >> iter 86000, loss: 4.818101
 >> iter 87000, loss: 4.737581
 >> iter 88000, loss: 4.669782
 >> iter 89000, loss: 4.574564
 >> iter 90000, loss: 4.663050
   Number of active neurons: 10
 >> iter 91000, loss: 4.746840
 >> iter 92000, loss: 4.739612
 >> iter 93000, loss: 4.741649
 >> iter 94000, loss: 4.690280
 >> iter 95000, loss: 4.567783
 >> iter 96000, loss: 4.634055
 >> iter 97000, loss: 4.487611
 >> iter 98000, loss: 4.514368
 >> iter 99000, loss: 4.687267
 >> iter 100000, loss: 4.612144
   Number of active neurons: 10
 >> iter 101000, loss: 4.426605
 >> iter 102000, loss: 4.450261
 >> iter 103000, loss: 4.839447
 >> iter 104000, loss: 5.299325
 >> iter 105000, loss: 5.591005
 >> iter 106000, loss: 5.250874
 >> iter 107000, loss: 4.734321
 >> iter 108000, loss: 4.976080
 >> iter 109000, loss: 5.188957
 >> iter 110000, loss: 4.772856
   Number of active neurons: 10
 >> iter 111000, loss: 4.480069
 >> iter 112000, loss: 3.890637
 >> iter 113000, loss: 3.741159
 >> iter 114000, loss: 3.750489
 >> iter 115000, loss: 3.341356
 >> iter 116000, loss: 3.345478
 >> iter 117000, loss: 3.354710
 >> iter 118000, loss: 3.178427
 >> iter 119000, loss: 3.620966
 >> iter 120000, loss: 3.596405
   Number of active neurons: 10
 >> iter 121000, loss: 3.450945
 >> iter 122000, loss: 3.340957
 >> iter 123000, loss: 3.374963
 >> iter 124000, loss: 3.374757
 >> iter 125000, loss: 3.250977
 >> iter 126000, loss: 3.180219
 >> iter 127000, loss: 3.527389
 >> iter 128000, loss: 3.743660
 >> iter 129000, loss: 3.705313
 >> iter 130000, loss: 3.652966
   Number of active neurons: 10
 >> iter 131000, loss: 3.983084
 >> iter 132000, loss: 3.623526
 >> iter 133000, loss: 3.305314
 >> iter 134000, loss: 3.436892
 >> iter 135000, loss: 3.349283
 >> iter 136000, loss: 3.226018
 >> iter 137000, loss: 3.296256
 >> iter 138000, loss: 3.232046
 >> iter 139000, loss: 3.205740
 >> iter 140000, loss: 3.101144
   Number of active neurons: 10
 >> iter 141000, loss: 3.279682
 >> iter 142000, loss: 3.292097
 >> iter 143000, loss: 3.144835
 >> iter 144000, loss: 3.396421
 >> iter 145000, loss: 3.416153
 >> iter 146000, loss: 3.153429
 >> iter 147000, loss: 3.247208
 >> iter 148000, loss: 2.910822
 >> iter 149000, loss: 2.949188
 >> iter 150000, loss: 2.973171
   Number of active neurons: 10
 >> iter 151000, loss: 3.120450
 >> iter 152000, loss: 2.909550
 >> iter 153000, loss: 3.091032
 >> iter 154000, loss: 2.974129
 >> iter 155000, loss: 3.221517
 >> iter 156000, loss: 2.917127
 >> iter 157000, loss: 2.883377
 >> iter 158000, loss: 2.827427
 >> iter 159000, loss: 2.972730
 >> iter 160000, loss: 2.762636
   Number of active neurons: 10
 >> iter 161000, loss: 2.760253
 >> iter 162000, loss: 2.992004
 >> iter 163000, loss: 3.037220
 >> iter 164000, loss: 2.961402
 >> iter 165000, loss: 2.828893
 >> iter 166000, loss: 2.774513
 >> iter 167000, loss: 2.888201
 >> iter 168000, loss: 2.903578
 >> iter 169000, loss: 2.984569
 >> iter 170000, loss: 2.960845
   Number of active neurons: 10
 >> iter 171000, loss: 2.868049
 >> iter 172000, loss: 2.716388
 >> iter 173000, loss: 2.799949
 >> iter 174000, loss: 2.778462
 >> iter 175000, loss: 3.045940
 >> iter 176000, loss: 2.934171
 >> iter 177000, loss: 3.022447
 >> iter 178000, loss: 3.403825
 >> iter 179000, loss: 3.505251
 >> iter 180000, loss: 3.030991
   Number of active neurons: 10
 >> iter 181000, loss: 2.868637
 >> iter 182000, loss: 2.800476
 >> iter 183000, loss: 2.835166
 >> iter 184000, loss: 2.719535
 >> iter 185000, loss: 2.681768
 >> iter 186000, loss: 2.697948
 >> iter 187000, loss: 2.768758
 >> iter 188000, loss: 2.646101
 >> iter 189000, loss: 2.559130
 >> iter 190000, loss: 2.638409
   Number of active neurons: 10
 >> iter 191000, loss: 3.242467
 >> iter 192000, loss: 3.050559
 >> iter 193000, loss: 2.987470
 >> iter 194000, loss: 2.954754
 >> iter 195000, loss: 2.928217
 >> iter 196000, loss: 2.956200
 >> iter 197000, loss: 2.831889
 >> iter 198000, loss: 2.669865
 >> iter 199000, loss: 2.855794
 >> iter 200000, loss: 2.757227
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 4.86790264195
   - Test - Long: 23.7038148093
   - Test - Big: 4.61695383046
   - Test - A: 0.0
   - Test - B: 8.43943737084
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.900399
 >> iter 2000, loss: 15.323623
 >> iter 3000, loss: 13.938223
 >> iter 4000, loss: 13.404243
 >> iter 5000, loss: 13.186636
 >> iter 6000, loss: 13.101193
 >> iter 7000, loss: 13.054755
 >> iter 8000, loss: 13.039914
 >> iter 9000, loss: 13.022286
 >> iter 10000, loss: 13.014402
   Number of active neurons: 10
 >> iter 11000, loss: 13.002062
 >> iter 12000, loss: 12.998699
 >> iter 13000, loss: 12.991675
 >> iter 14000, loss: 13.002468
 >> iter 15000, loss: 12.992484
 >> iter 16000, loss: 13.002288
 >> iter 17000, loss: 12.994008
 >> iter 18000, loss: 12.998459
 >> iter 19000, loss: 12.994833
 >> iter 20000, loss: 13.001578
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 8
 >> iter 21000, loss: 12.986369
 >> iter 22000, loss: 12.998059
 >> iter 23000, loss: 12.984984
 >> iter 24000, loss: 12.994984
 >> iter 25000, loss: 12.980559
 >> iter 26000, loss: 12.989167
 >> iter 27000, loss: 12.983333
 >> iter 28000, loss: 12.989179
 >> iter 29000, loss: 12.982605
 >> iter 30000, loss: 12.998209
   Number of active neurons: 8
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 8
 >> iter 31000, loss: 12.980519
 >> iter 32000, loss: 13.001130
 >> iter 33000, loss: 12.982597
 >> iter 34000, loss: 12.990565
 >> iter 35000, loss: 12.976675
 >> iter 36000, loss: 12.978576
 >> iter 37000, loss: 12.912544
 >> iter 38000, loss: 12.439927
 >> iter 39000, loss: 11.605035
 >> iter 40000, loss: 10.995148
   Number of active neurons: 10
 >> iter 41000, loss: 10.535927
 >> iter 42000, loss: 10.210485
 >> iter 43000, loss: 9.881245
 >> iter 44000, loss: 9.681385
 >> iter 45000, loss: 9.057228
 >> iter 46000, loss: 8.600516
 >> iter 47000, loss: 7.807904
 >> iter 48000, loss: 6.511315
 >> iter 49000, loss: 5.798422
 >> iter 50000, loss: 5.342751
   Number of active neurons: 10
 >> iter 51000, loss: 5.129418
 >> iter 52000, loss: 4.947961
 >> iter 53000, loss: 4.691752
 >> iter 54000, loss: 4.258016
 >> iter 55000, loss: 4.145496
 >> iter 56000, loss: 3.986361
 >> iter 57000, loss: 4.087659
 >> iter 58000, loss: 4.003519
 >> iter 59000, loss: 3.918358
 >> iter 60000, loss: 3.833846
   Number of active neurons: 10
 >> iter 61000, loss: 4.318898
 >> iter 62000, loss: 3.978781
 >> iter 63000, loss: 3.738397
 >> iter 64000, loss: 4.225187
 >> iter 65000, loss: 2.930312
 >> iter 66000, loss: 2.412504
 >> iter 67000, loss: 2.365591
 >> iter 68000, loss: 2.067741
 >> iter 69000, loss: 2.078456
 >> iter 70000, loss: 1.896518
   Number of active neurons: 10
 >> iter 71000, loss: 1.843461
 >> iter 72000, loss: 1.756213
 >> iter 73000, loss: 1.729015
 >> iter 74000, loss: 1.784492
 >> iter 75000, loss: 1.801990
 >> iter 76000, loss: 1.800627
 >> iter 77000, loss: 1.797229
 >> iter 78000, loss: 2.252418
 >> iter 79000, loss: 2.046376
 >> iter 80000, loss: 1.744560
   Number of active neurons: 10
 >> iter 81000, loss: 1.709634
 >> iter 82000, loss: 1.762290
 >> iter 83000, loss: 1.715583
 >> iter 84000, loss: 1.750432
 >> iter 85000, loss: 1.747437
 >> iter 86000, loss: 1.699608
 >> iter 87000, loss: 1.632698
 >> iter 88000, loss: 1.778350
 >> iter 89000, loss: 1.712722
 >> iter 90000, loss: 1.710170
   Number of active neurons: 10
 >> iter 91000, loss: 1.657017
 >> iter 92000, loss: 1.943153
 >> iter 93000, loss: 1.773687
 >> iter 94000, loss: 1.741429
 >> iter 95000, loss: 1.752160
 >> iter 96000, loss: 1.759825
 >> iter 97000, loss: 1.711558
 >> iter 98000, loss: 1.633163
 >> iter 99000, loss: 1.693826
 >> iter 100000, loss: 1.709411
   Number of active neurons: 10
 >> iter 101000, loss: 1.683969
 >> iter 102000, loss: 1.731962
 >> iter 103000, loss: 1.724373
 >> iter 104000, loss: 1.636566
 >> iter 105000, loss: 1.682980
 >> iter 106000, loss: 1.582226
 >> iter 107000, loss: 1.571320
 >> iter 108000, loss: 1.655467
 >> iter 109000, loss: 1.630575
 >> iter 110000, loss: 1.561836
   Number of active neurons: 10
 >> iter 111000, loss: 1.609086
 >> iter 112000, loss: 1.608990
 >> iter 113000, loss: 1.597873
 >> iter 114000, loss: 1.603820
 >> iter 115000, loss: 1.681311
 >> iter 116000, loss: 1.739786
 >> iter 117000, loss: 1.697570
 >> iter 118000, loss: 1.596796
 >> iter 119000, loss: 1.613705
 >> iter 120000, loss: 1.636561
   Number of active neurons: 10
 >> iter 121000, loss: 2.018103
 >> iter 122000, loss: 1.777670
 >> iter 123000, loss: 1.962090
 >> iter 124000, loss: 1.682437
 >> iter 125000, loss: 1.709604
 >> iter 126000, loss: 1.637721
 >> iter 127000, loss: 1.589982
 >> iter 128000, loss: 1.631667
 >> iter 129000, loss: 1.631817
 >> iter 130000, loss: 1.541864
   Number of active neurons: 10
 >> iter 131000, loss: 1.577692
 >> iter 132000, loss: 1.629784
 >> iter 133000, loss: 1.581429
 >> iter 134000, loss: 1.543876
 >> iter 135000, loss: 1.728112
 >> iter 136000, loss: 1.589974
 >> iter 137000, loss: 1.650804
 >> iter 138000, loss: 1.537555
 >> iter 139000, loss: 1.636003
 >> iter 140000, loss: 1.740678
   Number of active neurons: 10
 >> iter 141000, loss: 1.635633
 >> iter 142000, loss: 1.586390
 >> iter 143000, loss: 1.758711
 >> iter 144000, loss: 1.589005
 >> iter 145000, loss: 1.580779
 >> iter 146000, loss: 1.498510
 >> iter 147000, loss: 1.653642
 >> iter 148000, loss: 1.794342
 >> iter 149000, loss: 1.771225
 >> iter 150000, loss: 1.682496
   Number of active neurons: 10
 >> iter 151000, loss: 1.787605
 >> iter 152000, loss: 1.617960
 >> iter 153000, loss: 1.689133
 >> iter 154000, loss: 1.611439
 >> iter 155000, loss: 1.722179
 >> iter 156000, loss: 1.545878
 >> iter 157000, loss: 1.644390
 >> iter 158000, loss: 1.590979
 >> iter 159000, loss: 1.652564
 >> iter 160000, loss: 1.526497
   Number of active neurons: 10
 >> iter 161000, loss: 1.611599
 >> iter 162000, loss: 1.512075
 >> iter 163000, loss: 1.561201
 >> iter 164000, loss: 1.578838
 >> iter 165000, loss: 1.574528
 >> iter 166000, loss: 1.514066
 >> iter 167000, loss: 1.553109
 >> iter 168000, loss: 1.549630
 >> iter 169000, loss: 1.567270
 >> iter 170000, loss: 1.576988
   Number of active neurons: 10
 >> iter 171000, loss: 1.559791
 >> iter 172000, loss: 1.558024
 >> iter 173000, loss: 1.590826
 >> iter 174000, loss: 1.496825
 >> iter 175000, loss: 1.586577
 >> iter 176000, loss: 1.507261
 >> iter 177000, loss: 1.564450
 >> iter 178000, loss: 1.681819
 >> iter 179000, loss: 1.780416
 >> iter 180000, loss: 1.600420
   Number of active neurons: 10
 >> iter 181000, loss: 1.565055
 >> iter 182000, loss: 1.511204
 >> iter 183000, loss: 1.574664
 >> iter 184000, loss: 1.524459
 >> iter 185000, loss: 1.545677
 >> iter 186000, loss: 1.484524
 >> iter 187000, loss: 1.593153
 >> iter 188000, loss: 1.601502
 >> iter 189000, loss: 1.584907
 >> iter 190000, loss: 1.545599
   Number of active neurons: 10
 >> iter 191000, loss: 1.615483
 >> iter 192000, loss: 1.524688
 >> iter 193000, loss: 1.565817
 >> iter 194000, loss: 1.493646
 >> iter 195000, loss: 1.575898
 >> iter 196000, loss: 1.569535
 >> iter 197000, loss: 1.690038
 >> iter 198000, loss: 1.534075
 >> iter 199000, loss: 1.668365
 >> iter 200000, loss: 1.557755
   Number of active neurons: 10
 >> iter 201000, loss: 1.590555
 >> iter 202000, loss: 1.485130
 >> iter 203000, loss: 1.561523
 >> iter 204000, loss: 1.482276
 >> iter 205000, loss: 1.565853
 >> iter 206000, loss: 1.481094
 >> iter 207000, loss: 1.728454
 >> iter 208000, loss: 1.713980
 >> iter 209000, loss: 1.652985
 >> iter 210000, loss: 1.508027
   Number of active neurons: 10
 >> iter 211000, loss: 1.637786
 >> iter 212000, loss: 1.494581
 >> iter 213000, loss: 1.564258
 >> iter 214000, loss: 1.558278
 >> iter 215000, loss: 1.668288
 >> iter 216000, loss: 1.573968
 >> iter 217000, loss: 1.598419
 >> iter 218000, loss: 1.506587
 >> iter 219000, loss: 1.583200
 >> iter 220000, loss: 1.518954
   Number of active neurons: 10
 >> iter 221000, loss: 1.579711
 >> iter 222000, loss: 1.502571
 >> iter 223000, loss: 1.571305
 >> iter 224000, loss: 1.478551
 >> iter 225000, loss: 1.546207
 >> iter 226000, loss: 1.513884
 >> iter 227000, loss: 1.609664
 >> iter 228000, loss: 1.506366
 >> iter 229000, loss: 1.563273
 >> iter 230000, loss: 1.629422
   Number of active neurons: 10
 >> iter 231000, loss: 1.642221
 >> iter 232000, loss: 1.546178
 >> iter 233000, loss: 1.566802
 >> iter 234000, loss: 1.478417
 >> iter 235000, loss: 1.544333
 >> iter 236000, loss: 1.473329
 >> iter 237000, loss: 1.533712
 >> iter 238000, loss: 1.471725
 >> iter 239000, loss: 1.536906
 >> iter 240000, loss: 1.541984
   Number of active neurons: 10
 >> iter 241000, loss: 1.629007
 >> iter 242000, loss: 1.839555
 >> iter 243000, loss: 1.973072
 >> iter 244000, loss: 1.767333
 >> iter 245000, loss: 1.699859
 >> iter 246000, loss: 1.520748
 >> iter 247000, loss: 1.646606
 >> iter 248000, loss: 1.624933
 >> iter 249000, loss: 1.577161
 >> iter 250000, loss: 1.546907
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 3.05793884122
   - Test - Long: 22.4438778061
   - Test - Big: 3.08996910031
   - Test - A: 0.10665955603
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

