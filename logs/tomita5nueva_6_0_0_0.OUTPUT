 > Problema: tomita5nueva
 > Args:
   - Hidden size: 6
   - Noise level: 0.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.563164
 >> iter 2000, loss: 10.493763
 >> iter 3000, loss: 8.629395
 >> iter 4000, loss: 7.929248
 >> iter 5000, loss: 7.681162
 >> iter 6000, loss: 7.576641
 >> iter 7000, loss: 7.488355
 >> iter 8000, loss: 5.179645
 >> iter 9000, loss: 1.975079
 >> iter 10000, loss: 0.758866
   Number of active neurons: 6
 >> iter 11000, loss: 0.300430
 >> iter 12000, loss: 0.126249
 >> iter 13000, loss: 0.058921
 >> iter 14000, loss: 0.031924
 >> iter 15000, loss: 0.020443
 >> iter 16000, loss: 0.015019
 >> iter 17000, loss: 0.012120
 >> iter 18000, loss: 0.010307
 >> iter 19000, loss: 0.009050
 >> iter 20000, loss: 0.008084
   Number of active neurons: 6
 >> iter 21000, loss: 0.007315
 >> iter 22000, loss: 0.006673
 >> iter 23000, loss: 0.006129
 >> iter 24000, loss: 0.005663
 >> iter 25000, loss: 0.005256
 >> iter 26000, loss: 0.004903
 >> iter 27000, loss: 0.004586
 >> iter 28000, loss: 0.004309
 >> iter 29000, loss: 0.004056
 >> iter 30000, loss: 0.003834
   Number of active neurons: 6
 >> iter 31000, loss: 0.003628
 >> iter 32000, loss: 0.003447
 >> iter 33000, loss: 0.003276
 >> iter 34000, loss: 0.003126
 >> iter 35000, loss: 0.002983
 >> iter 36000, loss: 0.002857
 >> iter 37000, loss: 0.002734
 >> iter 38000, loss: 0.002627
 >> iter 39000, loss: 0.002521
 >> iter 40000, loss: 0.002429
   Number of active neurons: 6
 >> iter 41000, loss: 0.002337
 >> iter 42000, loss: 0.002258
 >> iter 43000, loss: 0.002177
 >> iter 44000, loss: 0.002108
 >> iter 45000, loss: 0.002036
 >> iter 46000, loss: 0.001976
 >> iter 47000, loss: 0.001912
 >> iter 48000, loss: 0.001858
 >> iter 49000, loss: 0.001801
 >> iter 50000, loss: 0.001753
   Number of active neurons: 6
 >> iter 51000, loss: 0.001702
 >> iter 52000, loss: 0.001659
 >> iter 53000, loss: 0.001613
 >> iter 54000, loss: 0.001574
 >> iter 55000, loss: 0.001532
 >> iter 56000, loss: 0.001497
 >> iter 57000, loss: 0.001459
 >> iter 58000, loss: 0.001427
 >> iter 59000, loss: 0.001391
 >> iter 60000, loss: 0.001363
   Number of active neurons: 6
 >> iter 61000, loss: 0.001330
 >> iter 62000, loss: 0.001304
 >> iter 63000, loss: 0.001274
 >> iter 64000, loss: 0.001250
 >> iter 65000, loss: 0.001222
 >> iter 66000, loss: 0.001200
 >> iter 67000, loss: 0.001174
 >> iter 68000, loss: 0.001154
 >> iter 69000, loss: 0.001129
 >> iter 70000, loss: 0.001111
   Number of active neurons: 6
 >> iter 71000, loss: 0.001088
 >> iter 72000, loss: 0.001071
 >> iter 73000, loss: 0.001049
 >> iter 74000, loss: 0.001034
 >> iter 75000, loss: 0.001014
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.571912
 >> iter 2000, loss: 10.478525
 >> iter 3000, loss: 8.604638
 >> iter 4000, loss: 7.897629
 >> iter 5000, loss: 7.648381
 >> iter 6000, loss: 7.481849
 >> iter 7000, loss: 6.884993
 >> iter 8000, loss: 6.294417
 >> iter 9000, loss: 5.786617
 >> iter 10000, loss: 5.411114
   Number of active neurons: 6
 >> iter 11000, loss: 4.887932
 >> iter 12000, loss: 4.368102
 >> iter 13000, loss: 3.942167
 >> iter 14000, loss: 3.453014
 >> iter 15000, loss: 3.251106
 >> iter 16000, loss: 3.302101
 >> iter 17000, loss: 3.545931
 >> iter 18000, loss: 4.707148
 >> iter 19000, loss: 4.873380
 >> iter 20000, loss: 4.520758
   Number of active neurons: 6
 >> iter 21000, loss: 4.313985
 >> iter 22000, loss: 1.761487
 >> iter 23000, loss: 0.700412
 >> iter 24000, loss: 0.289306
 >> iter 25000, loss: 0.130634
 >> iter 26000, loss: 0.066551
 >> iter 27000, loss: 0.040402
 >> iter 28000, loss: 0.028004
 >> iter 29000, loss: 0.022226
 >> iter 30000, loss: 0.018373
   Number of active neurons: 6
 >> iter 31000, loss: 0.016284
 >> iter 32000, loss: 0.014335
 >> iter 33000, loss: 0.013207
 >> iter 34000, loss: 0.011921
 >> iter 35000, loss: 0.011185
 >> iter 36000, loss: 0.010260
 >> iter 37000, loss: 0.009715
 >> iter 38000, loss: 0.008998
 >> iter 39000, loss: 0.008594
 >> iter 40000, loss: 0.008015
   Number of active neurons: 6
 >> iter 41000, loss: 0.007704
 >> iter 42000, loss: 0.007226
 >> iter 43000, loss: 0.006980
 >> iter 44000, loss: 0.006580
 >> iter 45000, loss: 0.006381
 >> iter 46000, loss: 0.006043
 >> iter 47000, loss: 0.005878
 >> iter 48000, loss: 0.005585
 >> iter 49000, loss: 0.005448
 >> iter 50000, loss: 0.005196
   Number of active neurons: 6
 >> iter 51000, loss: 0.005077
 >> iter 52000, loss: 0.004854
 >> iter 53000, loss: 0.004761
 >> iter 54000, loss: 0.004554
 >> iter 55000, loss: 0.004479
 >> iter 56000, loss: 0.004289
 >> iter 57000, loss: 0.004227
 >> iter 58000, loss: 0.004053
 >> iter 59000, loss: 0.004000
 >> iter 60000, loss: 0.003843
   Number of active neurons: 6
 >> iter 61000, loss: 0.003797
 >> iter 62000, loss: 0.003654
 >> iter 63000, loss: 0.003613
 >> iter 64000, loss: 0.003485
 >> iter 65000, loss: 0.003445
 >> iter 66000, loss: 0.003327
 >> iter 67000, loss: 0.003293
 >> iter 68000, loss: 0.003183
 >> iter 69000, loss: 0.003155
 >> iter 70000, loss: 0.003050
   Number of active neurons: 6
 >> iter 71000, loss: 0.003027
 >> iter 72000, loss: 0.002929
 >> iter 73000, loss: 0.002909
 >> iter 74000, loss: 0.002817
 >> iter 75000, loss: 0.002799
 >> iter 76000, loss: 0.002713
 >> iter 77000, loss: 0.002699
 >> iter 78000, loss: 0.002616
 >> iter 79000, loss: 0.002606
 >> iter 80000, loss: 0.002526
   Number of active neurons: 6
 >> iter 81000, loss: 0.002518
 >> iter 82000, loss: 0.002441
 >> iter 83000, loss: 0.002436
 >> iter 84000, loss: 0.002363
 >> iter 85000, loss: 0.002359
 >> iter 86000, loss: 0.002290
 >> iter 87000, loss: 0.002288
 >> iter 88000, loss: 0.002222
 >> iter 89000, loss: 0.002219
 >> iter 90000, loss: 0.002157
   Number of active neurons: 6
 >> iter 91000, loss: 0.002154
 >> iter 92000, loss: 0.002095
 >> iter 93000, loss: 0.002093
 >> iter 94000, loss: 0.002037
 >> iter 95000, loss: 0.002036
 >> iter 96000, loss: 0.001983
 >> iter 97000, loss: 0.001981
 >> iter 98000, loss: 0.001931
 >> iter 99000, loss: 0.001931
 >> iter 100000, loss: 0.001882
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.548756
 >> iter 2000, loss: 10.473230
 >> iter 3000, loss: 8.606970
 >> iter 4000, loss: 7.901811
 >> iter 5000, loss: 7.651894
 >> iter 6000, loss: 7.544408
 >> iter 7000, loss: 7.514298
 >> iter 8000, loss: 7.573730
 >> iter 9000, loss: 7.055247
 >> iter 10000, loss: 5.201928
   Number of active neurons: 6
 >> iter 11000, loss: 2.045627
 >> iter 12000, loss: 0.804012
 >> iter 13000, loss: 0.327162
 >> iter 14000, loss: 0.143136
 >> iter 15000, loss: 0.070454
 >> iter 16000, loss: 0.040452
 >> iter 17000, loss: 0.027187
 >> iter 18000, loss: 0.020616
 >> iter 19000, loss: 0.016939
 >> iter 20000, loss: 0.014566
   Number of active neurons: 6
 >> iter 21000, loss: 0.012879
 >> iter 22000, loss: 0.011585
 >> iter 23000, loss: 0.010535
 >> iter 24000, loss: 0.009675
 >> iter 25000, loss: 0.008934
 >> iter 26000, loss: 0.008310
 >> iter 27000, loss: 0.007756
 >> iter 28000, loss: 0.007282
 >> iter 29000, loss: 0.006847
 >> iter 30000, loss: 0.006475
   Number of active neurons: 6
 >> iter 31000, loss: 0.006126
 >> iter 32000, loss: 0.005827
 >> iter 33000, loss: 0.005541
 >> iter 34000, loss: 0.005295
 >> iter 35000, loss: 0.005055
 >> iter 36000, loss: 0.004849
 >> iter 37000, loss: 0.004646
 >> iter 38000, loss: 0.004471
 >> iter 39000, loss: 0.004296
 >> iter 40000, loss: 0.004146
   Number of active neurons: 6
 >> iter 41000, loss: 0.003995
 >> iter 42000, loss: 0.003864
 >> iter 43000, loss: 0.003731
 >> iter 44000, loss: 0.003617
 >> iter 45000, loss: 0.003500
 >> iter 46000, loss: 0.003400
 >> iter 47000, loss: 0.003296
 >> iter 48000, loss: 0.003205
 >> iter 49000, loss: 0.003114
 >> iter 50000, loss: 0.003032
   Number of active neurons: 6
 >> iter 51000, loss: 0.002951
 >> iter 52000, loss: 0.002877
 >> iter 53000, loss: 0.002802
 >> iter 54000, loss: 0.002736
 >> iter 55000, loss: 0.002668
 >> iter 56000, loss: 0.002608
 >> iter 57000, loss: 0.002546
 >> iter 58000, loss: 0.002492
 >> iter 59000, loss: 0.002440
 >> iter 60000, loss: 0.002386
   Number of active neurons: 6
 >> iter 61000, loss: 0.002338
 >> iter 62000, loss: 0.002287
 >> iter 63000, loss: 0.002244
 >> iter 64000, loss: 0.002197
 >> iter 65000, loss: 0.002157
 >> iter 66000, loss: 0.002113
 >> iter 67000, loss: 0.002076
 >> iter 68000, loss: 0.002035
 >> iter 69000, loss: 0.002001
 >> iter 70000, loss: 0.001963
   Number of active neurons: 6
 >> iter 71000, loss: 0.001931
 >> iter 72000, loss: 0.001896
 >> iter 73000, loss: 0.001866
 >> iter 74000, loss: 0.001833
 >> iter 75000, loss: 0.001805
 >> iter 76000, loss: 0.001774
 >> iter 77000, loss: 0.001748
 >> iter 78000, loss: 0.001719
 >> iter 79000, loss: 0.001694
 >> iter 80000, loss: 0.001667
   Number of active neurons: 6
 >> iter 81000, loss: 0.001644
 >> iter 82000, loss: 0.001618
 >> iter 83000, loss: 0.001596
 >> iter 84000, loss: 0.001571
 >> iter 85000, loss: 0.001551
 >> iter 86000, loss: 0.001528
 >> iter 87000, loss: 0.001508
 >> iter 88000, loss: 0.001487
 >> iter 89000, loss: 0.001468
 >> iter 90000, loss: 0.001448
   Number of active neurons: 6
 >> iter 91000, loss: 0.001430
 >> iter 92000, loss: 0.001410
 >> iter 93000, loss: 0.001393
 >> iter 94000, loss: 0.001375
 >> iter 95000, loss: 0.001360
 >> iter 96000, loss: 0.001341
 >> iter 97000, loss: 0.001328
 >> iter 98000, loss: 0.001308
 >> iter 99000, loss: 0.001296
 >> iter 100000, loss: 0.001278
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.591004
 >> iter 2000, loss: 10.502594
 >> iter 3000, loss: 8.628665
 >> iter 4000, loss: 7.920057
 >> iter 5000, loss: 7.666964
 >> iter 6000, loss: 7.549505
 >> iter 7000, loss: 7.143315
 >> iter 8000, loss: 3.380250
 >> iter 9000, loss: 1.291402
 >> iter 10000, loss: 0.501324
   Number of active neurons: 6
 >> iter 11000, loss: 0.202699
 >> iter 12000, loss: 0.088287
 >> iter 13000, loss: 0.043631
 >> iter 14000, loss: 0.025260
 >> iter 15000, loss: 0.017253
 >> iter 16000, loss: 0.013227
 >> iter 17000, loss: 0.011015
 >> iter 18000, loss: 0.009517
 >> iter 19000, loss: 0.008485
 >> iter 20000, loss: 0.007635
   Number of active neurons: 6
 >> iter 21000, loss: 0.006986
 >> iter 22000, loss: 0.006404
 >> iter 23000, loss: 0.005944
 >> iter 24000, loss: 0.005513
 >> iter 25000, loss: 0.005169
 >> iter 26000, loss: 0.004837
 >> iter 27000, loss: 0.004569
 >> iter 28000, loss: 0.004304
 >> iter 29000, loss: 0.004093
 >> iter 30000, loss: 0.003876
   Number of active neurons: 6
 >> iter 31000, loss: 0.003704
 >> iter 32000, loss: 0.003524
 >> iter 33000, loss: 0.003381
 >> iter 34000, loss: 0.003229
 >> iter 35000, loss: 0.003109
 >> iter 36000, loss: 0.002980
 >> iter 37000, loss: 0.002877
 >> iter 38000, loss: 0.002766
 >> iter 39000, loss: 0.002676
 >> iter 40000, loss: 0.002580
   Number of active neurons: 6
 >> iter 41000, loss: 0.002501
 >> iter 42000, loss: 0.002417
 >> iter 43000, loss: 0.002348
 >> iter 44000, loss: 0.002274
 >> iter 45000, loss: 0.002211
 >> iter 46000, loss: 0.002146
 >> iter 47000, loss: 0.002090
 >> iter 48000, loss: 0.002031
 >> iter 49000, loss: 0.001981
 >> iter 50000, loss: 0.001927
   Number of active neurons: 6
 >> iter 51000, loss: 0.001883
 >> iter 52000, loss: 0.001834
 >> iter 53000, loss: 0.001794
 >> iter 54000, loss: 0.001749
 >> iter 55000, loss: 0.001713
 >> iter 56000, loss: 0.001672
 >> iter 57000, loss: 0.001639
 >> iter 58000, loss: 0.001601
 >> iter 59000, loss: 0.001571
 >> iter 60000, loss: 0.001536
   Number of active neurons: 6
 >> iter 61000, loss: 0.001508
 >> iter 62000, loss: 0.001476
 >> iter 63000, loss: 0.001450
 >> iter 64000, loss: 0.001421
 >> iter 65000, loss: 0.001396
 >> iter 66000, loss: 0.001369
 >> iter 67000, loss: 0.001345
 >> iter 68000, loss: 0.001321
 >> iter 69000, loss: 0.001299
 >> iter 70000, loss: 0.001277
   Number of active neurons: 6
 >> iter 71000, loss: 0.001256
 >> iter 72000, loss: 0.001235
 >> iter 73000, loss: 0.001216
 >> iter 74000, loss: 0.001195
 >> iter 75000, loss: 0.001178
 >> iter 76000, loss: 0.001158
 >> iter 77000, loss: 0.001142
 >> iter 78000, loss: 0.001124
 >> iter 79000, loss: 0.001108
 >> iter 80000, loss: 0.001091
   Number of active neurons: 6
 >> iter 81000, loss: 0.001076
 >> iter 82000, loss: 0.001060
 >> iter 83000, loss: 0.001046
 >> iter 84000, loss: 0.001031
 >> iter 85000, loss: 0.001017
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.529612
 >> iter 2000, loss: 10.468047
 >> iter 3000, loss: 8.606950
 >> iter 4000, loss: 7.904692
 >> iter 5000, loss: 7.652263
 >> iter 6000, loss: 7.258631
 >> iter 7000, loss: 6.391397
 >> iter 8000, loss: 5.579149
 >> iter 9000, loss: 2.462949
 >> iter 10000, loss: 0.974040
   Number of active neurons: 6
 >> iter 11000, loss: 0.434645
 >> iter 12000, loss: 0.188317
 >> iter 13000, loss: 0.091589
 >> iter 14000, loss: 0.050115
 >> iter 15000, loss: 0.081861
 >> iter 16000, loss: 0.042686
 >> iter 17000, loss: 0.057227
 >> iter 18000, loss: 0.030974
 >> iter 19000, loss: 0.020704
 >> iter 20000, loss: 0.015501
   Number of active neurons: 6
 >> iter 21000, loss: 0.013136
 >> iter 22000, loss: 0.011320
 >> iter 23000, loss: 0.010469
 >> iter 24000, loss: 0.009393
 >> iter 25000, loss: 0.008898
 >> iter 26000, loss: 0.008107
 >> iter 27000, loss: 0.007780
 >> iter 28000, loss: 0.007151
 >> iter 29000, loss: 0.006916
 >> iter 30000, loss: 0.006396
   Number of active neurons: 6
 >> iter 31000, loss: 0.006222
 >> iter 32000, loss: 0.005788
 >> iter 33000, loss: 0.005656
 >> iter 34000, loss: 0.005282
 >> iter 35000, loss: 0.005181
 >> iter 36000, loss: 0.004858
 >> iter 37000, loss: 0.004778
 >> iter 38000, loss: 0.004496
 >> iter 39000, loss: 0.004433
 >> iter 40000, loss: 0.004185
   Number of active neurons: 6
 >> iter 41000, loss: 0.004134
 >> iter 42000, loss: 0.003931
 >> iter 43000, loss: 0.003871
 >> iter 44000, loss: 0.003708
 >> iter 45000, loss: 0.003639
 >> iter 46000, loss: 0.003495
 >> iter 47000, loss: 0.003435
 >> iter 48000, loss: 0.003303
 >> iter 49000, loss: 0.003250
 >> iter 50000, loss: 0.003131
   Number of active neurons: 6
 >> iter 51000, loss: 0.003086
 >> iter 52000, loss: 0.002976
 >> iter 53000, loss: 0.002936
 >> iter 54000, loss: 0.002835
 >> iter 55000, loss: 0.002800
 >> iter 56000, loss: 0.002707
 >> iter 57000, loss: 0.002677
 >> iter 58000, loss: 0.002592
 >> iter 59000, loss: 0.002563
 >> iter 60000, loss: 0.002485
   Number of active neurons: 6
 >> iter 61000, loss: 0.002459
 >> iter 62000, loss: 0.002386
 >> iter 63000, loss: 0.002362
 >> iter 64000, loss: 0.002296
 >> iter 65000, loss: 0.002272
 >> iter 66000, loss: 0.002210
 >> iter 67000, loss: 0.002188
 >> iter 68000, loss: 0.002130
 >> iter 69000, loss: 0.002111
 >> iter 70000, loss: 0.002057
   Number of active neurons: 6
 >> iter 71000, loss: 0.002039
 >> iter 72000, loss: 0.001988
 >> iter 73000, loss: 0.001973
 >> iter 74000, loss: 0.001924
 >> iter 75000, loss: 0.001910
 >> iter 76000, loss: 0.001863
 >> iter 77000, loss: 0.001851
 >> iter 78000, loss: 0.001807
 >> iter 79000, loss: 0.001796
 >> iter 80000, loss: 0.001754
   Number of active neurons: 6
 >> iter 81000, loss: 0.001743
 >> iter 82000, loss: 0.001703
 >> iter 83000, loss: 0.001693
 >> iter 84000, loss: 0.001655
 >> iter 85000, loss: 0.001646
 >> iter 86000, loss: 0.001610
 >> iter 87000, loss: 0.001602
 >> iter 88000, loss: 0.001567
 >> iter 89000, loss: 0.001559
 >> iter 90000, loss: 0.001526
   Number of active neurons: 6
 >> iter 91000, loss: 0.001518
 >> iter 92000, loss: 0.001487
 >> iter 93000, loss: 0.001480
 >> iter 94000, loss: 0.001450
 >> iter 95000, loss: 0.001443
 >> iter 96000, loss: 0.001415
 >> iter 97000, loss: 0.001408
 >> iter 98000, loss: 0.001381
 >> iter 99000, loss: 0.001375
 >> iter 100000, loss: 0.001350
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0179998200018
   - Test - A: 12.7458169455
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.582838
 >> iter 2000, loss: 10.488621
 >> iter 3000, loss: 8.614009
 >> iter 4000, loss: 7.902321
 >> iter 5000, loss: 7.578289
 >> iter 6000, loss: 6.900879
 >> iter 7000, loss: 3.733966
 >> iter 8000, loss: 1.445364
 >> iter 9000, loss: 0.570478
 >> iter 10000, loss: 0.236042
   Number of active neurons: 6
 >> iter 11000, loss: 0.106541
 >> iter 12000, loss: 0.054876
 >> iter 13000, loss: 0.033237
 >> iter 14000, loss: 0.023330
 >> iter 15000, loss: 0.018283
 >> iter 16000, loss: 0.015275
 >> iter 17000, loss: 0.013301
 >> iter 18000, loss: 0.011821
 >> iter 19000, loss: 0.010683
 >> iter 20000, loss: 0.009734
   Number of active neurons: 6
 >> iter 21000, loss: 0.008956
 >> iter 22000, loss: 0.008281
 >> iter 23000, loss: 0.007707
 >> iter 24000, loss: 0.007198
 >> iter 25000, loss: 0.006757
 >> iter 26000, loss: 0.006359
 >> iter 27000, loss: 0.006010
 >> iter 28000, loss: 0.005693
 >> iter 29000, loss: 0.005408
 >> iter 30000, loss: 0.005147
   Number of active neurons: 6
 >> iter 31000, loss: 0.004913
 >> iter 32000, loss: 0.004696
 >> iter 33000, loss: 0.004498
 >> iter 34000, loss: 0.004314
 >> iter 35000, loss: 0.004146
 >> iter 36000, loss: 0.003992
 >> iter 37000, loss: 0.003842
 >> iter 38000, loss: 0.003712
 >> iter 39000, loss: 0.003579
 >> iter 40000, loss: 0.003466
   Number of active neurons: 6
 >> iter 41000, loss: 0.003348
 >> iter 42000, loss: 0.003249
 >> iter 43000, loss: 0.003144
 >> iter 44000, loss: 0.003059
 >> iter 45000, loss: 0.002962
 >> iter 46000, loss: 0.002888
 >> iter 47000, loss: 0.002800
 >> iter 48000, loss: 0.002734
 >> iter 49000, loss: 0.002654
 >> iter 50000, loss: 0.002595
   Number of active neurons: 6
 >> iter 51000, loss: 0.002523
 >> iter 52000, loss: 0.002468
 >> iter 53000, loss: 0.002404
 >> iter 54000, loss: 0.002353
 >> iter 55000, loss: 0.002294
 >> iter 56000, loss: 0.002248
 >> iter 57000, loss: 0.002194
 >> iter 58000, loss: 0.002152
 >> iter 59000, loss: 0.002102
 >> iter 60000, loss: 0.002063
   Number of active neurons: 6
 >> iter 61000, loss: 0.002017
 >> iter 62000, loss: 0.001980
 >> iter 63000, loss: 0.001938
 >> iter 64000, loss: 0.001904
 >> iter 65000, loss: 0.001864
 >> iter 66000, loss: 0.001833
 >> iter 67000, loss: 0.001795
 >> iter 68000, loss: 0.001767
 >> iter 69000, loss: 0.001732
 >> iter 70000, loss: 0.001706
   Number of active neurons: 6
 >> iter 71000, loss: 0.001672
 >> iter 72000, loss: 0.001648
 >> iter 73000, loss: 0.001617
 >> iter 74000, loss: 0.001594
 >> iter 75000, loss: 0.001564
 >> iter 76000, loss: 0.001543
 >> iter 77000, loss: 0.001516
 >> iter 78000, loss: 0.001496
 >> iter 79000, loss: 0.001471
 >> iter 80000, loss: 0.001451
   Number of active neurons: 6
 >> iter 81000, loss: 0.001428
 >> iter 82000, loss: 0.001408
 >> iter 83000, loss: 0.001386
 >> iter 84000, loss: 0.001367
 >> iter 85000, loss: 0.001347
 >> iter 86000, loss: 0.001329
 >> iter 87000, loss: 0.001310
 >> iter 88000, loss: 0.001293
 >> iter 89000, loss: 0.001275
 >> iter 90000, loss: 0.001259
   Number of active neurons: 6
 >> iter 91000, loss: 0.001241
 >> iter 92000, loss: 0.001226
 >> iter 93000, loss: 0.001209
 >> iter 94000, loss: 0.001196
 >> iter 95000, loss: 0.001179
 >> iter 96000, loss: 0.001166
 >> iter 97000, loss: 0.001150
 >> iter 98000, loss: 0.001137
 >> iter 99000, loss: 0.001122
 >> iter 100000, loss: 0.001111
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 11.9125391641
   - Test - B: 0.1799880008
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.555484
 >> iter 2000, loss: 10.485895
 >> iter 3000, loss: 8.618960
 >> iter 4000, loss: 7.915134
 >> iter 5000, loss: 7.666446
 >> iter 6000, loss: 7.561872
 >> iter 7000, loss: 7.534383
 >> iter 8000, loss: 7.502910
 >> iter 9000, loss: 7.434206
 >> iter 10000, loss: 6.858292
   Number of active neurons: 6
 >> iter 11000, loss: 6.052653
 >> iter 12000, loss: 3.342880
 >> iter 13000, loss: 1.286832
 >> iter 14000, loss: 0.508627
 >> iter 15000, loss: 0.209334
 >> iter 16000, loss: 0.093567
 >> iter 17000, loss: 0.047869
 >> iter 18000, loss: 0.028824
 >> iter 19000, loss: 0.020298
 >> iter 20000, loss: 0.015898
   Number of active neurons: 6
 >> iter 21000, loss: 0.013483
 >> iter 22000, loss: 0.011789
 >> iter 23000, loss: 0.010657
 >> iter 24000, loss: 0.009673
 >> iter 25000, loss: 0.008965
 >> iter 26000, loss: 0.008277
 >> iter 27000, loss: 0.007772
 >> iter 28000, loss: 0.007255
 >> iter 29000, loss: 0.006875
 >> iter 30000, loss: 0.006464
   Number of active neurons: 6
 >> iter 31000, loss: 0.006165
 >> iter 32000, loss: 0.005834
 >> iter 33000, loss: 0.005592
 >> iter 34000, loss: 0.005315
 >> iter 35000, loss: 0.005118
 >> iter 36000, loss: 0.004883
 >> iter 37000, loss: 0.004717
 >> iter 38000, loss: 0.004515
 >> iter 39000, loss: 0.004374
 >> iter 40000, loss: 0.004198
   Number of active neurons: 6
 >> iter 41000, loss: 0.004076
 >> iter 42000, loss: 0.003923
 >> iter 43000, loss: 0.003817
 >> iter 44000, loss: 0.003681
 >> iter 45000, loss: 0.003588
 >> iter 46000, loss: 0.003469
 >> iter 47000, loss: 0.003385
 >> iter 48000, loss: 0.003277
 >> iter 49000, loss: 0.003204
 >> iter 50000, loss: 0.003107
   Number of active neurons: 6
 >> iter 51000, loss: 0.003042
 >> iter 52000, loss: 0.002952
 >> iter 53000, loss: 0.002895
 >> iter 54000, loss: 0.002811
 >> iter 55000, loss: 0.002761
 >> iter 56000, loss: 0.002684
 >> iter 57000, loss: 0.002639
 >> iter 58000, loss: 0.002568
 >> iter 59000, loss: 0.002527
 >> iter 60000, loss: 0.002462
   Number of active neurons: 6
 >> iter 61000, loss: 0.002423
 >> iter 62000, loss: 0.002363
 >> iter 63000, loss: 0.002327
 >> iter 64000, loss: 0.002273
 >> iter 65000, loss: 0.002239
 >> iter 66000, loss: 0.002187
 >> iter 67000, loss: 0.002156
 >> iter 68000, loss: 0.002109
 >> iter 69000, loss: 0.002079
 >> iter 70000, loss: 0.002038
   Number of active neurons: 6
 >> iter 71000, loss: 0.002008
 >> iter 72000, loss: 0.001968
 >> iter 73000, loss: 0.001943
 >> iter 74000, loss: 0.001904
 >> iter 75000, loss: 0.001881
 >> iter 76000, loss: 0.001844
 >> iter 77000, loss: 0.001822
 >> iter 78000, loss: 0.001787
 >> iter 79000, loss: 0.001767
 >> iter 80000, loss: 0.001734
   Number of active neurons: 6
 >> iter 81000, loss: 0.001714
 >> iter 82000, loss: 0.001684
 >> iter 83000, loss: 0.001666
 >> iter 84000, loss: 0.001635
 >> iter 85000, loss: 0.001620
 >> iter 86000, loss: 0.001590
 >> iter 87000, loss: 0.001576
 >> iter 88000, loss: 0.001547
 >> iter 89000, loss: 0.001533
 >> iter 90000, loss: 0.001507
   Number of active neurons: 6
 >> iter 91000, loss: 0.001493
 >> iter 92000, loss: 0.001469
 >> iter 93000, loss: 0.001455
 >> iter 94000, loss: 0.001431
 >> iter 95000, loss: 0.001419
 >> iter 96000, loss: 0.001397
 >> iter 97000, loss: 0.001384
 >> iter 98000, loss: 0.001364
 >> iter 99000, loss: 0.001351
 >> iter 100000, loss: 0.001333
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.525145
 >> iter 2000, loss: 10.468240
 >> iter 3000, loss: 8.603557
 >> iter 4000, loss: 7.898195
 >> iter 5000, loss: 7.649217
 >> iter 6000, loss: 7.460842
 >> iter 7000, loss: 6.327187
 >> iter 8000, loss: 2.432844
 >> iter 9000, loss: 0.956062
 >> iter 10000, loss: 0.375837
   Number of active neurons: 6
 >> iter 11000, loss: 0.156317
 >> iter 12000, loss: 0.071077
 >> iter 13000, loss: 0.037439
 >> iter 14000, loss: 0.023192
 >> iter 15000, loss: 0.016797
 >> iter 16000, loss: 0.013376
 >> iter 17000, loss: 0.011425
 >> iter 18000, loss: 0.010020
 >> iter 19000, loss: 0.009046
 >> iter 20000, loss: 0.008206
   Number of active neurons: 6
 >> iter 21000, loss: 0.007575
 >> iter 22000, loss: 0.006986
 >> iter 23000, loss: 0.006531
 >> iter 24000, loss: 0.006087
 >> iter 25000, loss: 0.005742
 >> iter 26000, loss: 0.005394
 >> iter 27000, loss: 0.005122
 >> iter 28000, loss: 0.004843
 >> iter 29000, loss: 0.004623
 >> iter 30000, loss: 0.004393
   Number of active neurons: 6
 >> iter 31000, loss: 0.004212
 >> iter 32000, loss: 0.004020
 >> iter 33000, loss: 0.003868
 >> iter 34000, loss: 0.003704
 >> iter 35000, loss: 0.003576
 >> iter 36000, loss: 0.003437
 >> iter 37000, loss: 0.003324
 >> iter 38000, loss: 0.003203
 >> iter 39000, loss: 0.003106
 >> iter 40000, loss: 0.002999
   Number of active neurons: 6
 >> iter 41000, loss: 0.002914
 >> iter 42000, loss: 0.002819
 >> iter 43000, loss: 0.002743
 >> iter 44000, loss: 0.002659
 >> iter 45000, loss: 0.002592
 >> iter 46000, loss: 0.002517
 >> iter 47000, loss: 0.002456
 >> iter 48000, loss: 0.002388
 >> iter 49000, loss: 0.002334
 >> iter 50000, loss: 0.002272
   Number of active neurons: 6
 >> iter 51000, loss: 0.002223
 >> iter 52000, loss: 0.002167
 >> iter 53000, loss: 0.002122
 >> iter 54000, loss: 0.002071
 >> iter 55000, loss: 0.002029
 >> iter 56000, loss: 0.001983
 >> iter 57000, loss: 0.001945
 >> iter 58000, loss: 0.001902
 >> iter 59000, loss: 0.001867
 >> iter 60000, loss: 0.001827
   Number of active neurons: 6
 >> iter 61000, loss: 0.001795
 >> iter 62000, loss: 0.001758
 >> iter 63000, loss: 0.001728
 >> iter 64000, loss: 0.001694
 >> iter 65000, loss: 0.001666
 >> iter 66000, loss: 0.001634
 >> iter 67000, loss: 0.001609
 >> iter 68000, loss: 0.001579
 >> iter 69000, loss: 0.001555
 >> iter 70000, loss: 0.001526
   Number of active neurons: 6
 >> iter 71000, loss: 0.001504
 >> iter 72000, loss: 0.001478
 >> iter 73000, loss: 0.001457
 >> iter 74000, loss: 0.001432
 >> iter 75000, loss: 0.001412
 >> iter 76000, loss: 0.001389
 >> iter 77000, loss: 0.001370
 >> iter 78000, loss: 0.001348
 >> iter 79000, loss: 0.001331
 >> iter 80000, loss: 0.001310
   Number of active neurons: 6
 >> iter 81000, loss: 0.001293
 >> iter 82000, loss: 0.001273
 >> iter 83000, loss: 0.001258
 >> iter 84000, loss: 0.001239
 >> iter 85000, loss: 0.001224
 >> iter 86000, loss: 0.001207
 >> iter 87000, loss: 0.001192
 >> iter 88000, loss: 0.001176
 >> iter 89000, loss: 0.001162
 >> iter 90000, loss: 0.001147
   Number of active neurons: 6
 >> iter 91000, loss: 0.001133
 >> iter 92000, loss: 0.001119
 >> iter 93000, loss: 0.001105
 >> iter 94000, loss: 0.001092
 >> iter 95000, loss: 0.001079
 >> iter 96000, loss: 0.001066
 >> iter 97000, loss: 0.001054
 >> iter 98000, loss: 0.001042
 >> iter 99000, loss: 0.001031
 >> iter 100000, loss: 0.001019
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 11.779214719
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.548473
 >> iter 2000, loss: 10.479014
 >> iter 3000, loss: 8.609502
 >> iter 4000, loss: 7.902056
 >> iter 5000, loss: 7.652610
 >> iter 6000, loss: 7.546116
 >> iter 7000, loss: 7.518670
 >> iter 8000, loss: 7.487141
 >> iter 9000, loss: 6.460250
 >> iter 10000, loss: 2.490231
   Number of active neurons: 6
 >> iter 11000, loss: 0.958540
 >> iter 12000, loss: 0.379705
 >> iter 13000, loss: 0.159845
 >> iter 14000, loss: 0.074761
 >> iter 15000, loss: 0.040799
 >> iter 16000, loss: 0.026331
 >> iter 17000, loss: 0.019605
 >> iter 18000, loss: 0.015982
 >> iter 19000, loss: 0.013782
 >> iter 20000, loss: 0.012224
   Number of active neurons: 6
 >> iter 21000, loss: 0.011063
 >> iter 22000, loss: 0.010109
 >> iter 23000, loss: 0.009334
 >> iter 24000, loss: 0.008656
 >> iter 25000, loss: 0.008088
 >> iter 26000, loss: 0.007575
 >> iter 27000, loss: 0.007137
 >> iter 28000, loss: 0.006734
 >> iter 29000, loss: 0.006387
 >> iter 30000, loss: 0.006060
   Number of active neurons: 6
 >> iter 31000, loss: 0.005778
 >> iter 32000, loss: 0.005509
 >> iter 33000, loss: 0.005274
 >> iter 34000, loss: 0.005048
 >> iter 35000, loss: 0.004851
 >> iter 36000, loss: 0.004660
 >> iter 37000, loss: 0.004490
 >> iter 38000, loss: 0.004326
 >> iter 39000, loss: 0.004178
 >> iter 40000, loss: 0.004036
   Number of active neurons: 6
 >> iter 41000, loss: 0.003906
 >> iter 42000, loss: 0.003782
 >> iter 43000, loss: 0.003667
 >> iter 44000, loss: 0.003558
 >> iter 45000, loss: 0.003455
 >> iter 46000, loss: 0.003359
 >> iter 47000, loss: 0.003266
 >> iter 48000, loss: 0.003180
 >> iter 49000, loss: 0.003096
 >> iter 50000, loss: 0.003018
   Number of active neurons: 6
 >> iter 51000, loss: 0.002943
 >> iter 52000, loss: 0.002873
 >> iter 53000, loss: 0.002804
 >> iter 54000, loss: 0.002740
 >> iter 55000, loss: 0.002677
 >> iter 56000, loss: 0.002619
 >> iter 57000, loss: 0.002561
 >> iter 58000, loss: 0.002508
 >> iter 59000, loss: 0.002455
 >> iter 60000, loss: 0.002406
   Number of active neurons: 6
 >> iter 61000, loss: 0.002357
 >> iter 62000, loss: 0.002312
 >> iter 63000, loss: 0.002266
 >> iter 64000, loss: 0.002225
 >> iter 65000, loss: 0.002182
 >> iter 66000, loss: 0.002144
 >> iter 67000, loss: 0.002104
 >> iter 68000, loss: 0.002068
 >> iter 69000, loss: 0.002031
 >> iter 70000, loss: 0.001998
   Number of active neurons: 6
 >> iter 71000, loss: 0.001963
 >> iter 72000, loss: 0.001932
 >> iter 73000, loss: 0.001899
 >> iter 74000, loss: 0.001871
 >> iter 75000, loss: 0.001840
 >> iter 76000, loss: 0.001813
 >> iter 77000, loss: 0.001783
 >> iter 78000, loss: 0.001758
 >> iter 79000, loss: 0.001730
 >> iter 80000, loss: 0.001706
   Number of active neurons: 6
 >> iter 81000, loss: 0.001680
 >> iter 82000, loss: 0.001658
 >> iter 83000, loss: 0.001632
 >> iter 84000, loss: 0.001612
 >> iter 85000, loss: 0.001588
 >> iter 86000, loss: 0.001568
 >> iter 87000, loss: 0.001545
 >> iter 88000, loss: 0.001527
 >> iter 89000, loss: 0.001505
 >> iter 90000, loss: 0.001488
   Number of active neurons: 6
 >> iter 91000, loss: 0.001466
 >> iter 92000, loss: 0.001451
 >> iter 93000, loss: 0.001430
 >> iter 94000, loss: 0.001415
 >> iter 95000, loss: 0.001395
 >> iter 96000, loss: 0.001381
 >> iter 97000, loss: 0.001362
 >> iter 98000, loss: 0.001349
 >> iter 99000, loss: 0.001331
 >> iter 100000, loss: 0.001318
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.591785
 >> iter 2000, loss: 10.492781
 >> iter 3000, loss: 8.617262
 >> iter 4000, loss: 7.896266
 >> iter 5000, loss: 7.400476
 >> iter 6000, loss: 4.673987
 >> iter 7000, loss: 1.787502
 >> iter 8000, loss: 0.688967
 >> iter 9000, loss: 0.273534
 >> iter 10000, loss: 0.115005
   Number of active neurons: 6
 >> iter 11000, loss: 0.053696
 >> iter 12000, loss: 0.029029
 >> iter 13000, loss: 0.018643
 >> iter 14000, loss: 0.013712
 >> iter 15000, loss: 0.011167
 >> iter 16000, loss: 0.009540
 >> iter 17000, loss: 0.008483
 >> iter 18000, loss: 0.007619
 >> iter 19000, loss: 0.006989
 >> iter 20000, loss: 0.006409
   Number of active neurons: 6
 >> iter 21000, loss: 0.005970
 >> iter 22000, loss: 0.005544
 >> iter 23000, loss: 0.005216
 >> iter 24000, loss: 0.004885
 >> iter 25000, loss: 0.004633
 >> iter 26000, loss: 0.004367
 >> iter 27000, loss: 0.004167
 >> iter 28000, loss: 0.003950
 >> iter 29000, loss: 0.003786
 >> iter 30000, loss: 0.003605
   Number of active neurons: 6
 >> iter 31000, loss: 0.003469
 >> iter 32000, loss: 0.003315
 >> iter 33000, loss: 0.003201
 >> iter 34000, loss: 0.003068
 >> iter 35000, loss: 0.002971
 >> iter 36000, loss: 0.002857
 >> iter 37000, loss: 0.002771
 >> iter 38000, loss: 0.002670
 >> iter 39000, loss: 0.002596
 >> iter 40000, loss: 0.002507
   Number of active neurons: 6
 >> iter 41000, loss: 0.002442
 >> iter 42000, loss: 0.002363
 >> iter 43000, loss: 0.002305
 >> iter 44000, loss: 0.002233
 >> iter 45000, loss: 0.002182
 >> iter 46000, loss: 0.002118
 >> iter 47000, loss: 0.002072
 >> iter 48000, loss: 0.002014
 >> iter 49000, loss: 0.001972
 >> iter 50000, loss: 0.001919
   Number of active neurons: 6
 >> iter 51000, loss: 0.001882
 >> iter 52000, loss: 0.001833
 >> iter 53000, loss: 0.001799
 >> iter 54000, loss: 0.001755
 >> iter 55000, loss: 0.001723
 >> iter 56000, loss: 0.001682
 >> iter 57000, loss: 0.001654
 >> iter 58000, loss: 0.001616
 >> iter 59000, loss: 0.001589
 >> iter 60000, loss: 0.001555
   Number of active neurons: 6
 >> iter 61000, loss: 0.001530
 >> iter 62000, loss: 0.001498
 >> iter 63000, loss: 0.001474
 >> iter 64000, loss: 0.001445
 >> iter 65000, loss: 0.001423
 >> iter 66000, loss: 0.001395
 >> iter 67000, loss: 0.001375
 >> iter 68000, loss: 0.001349
 >> iter 69000, loss: 0.001330
 >> iter 70000, loss: 0.001306
   Number of active neurons: 6
 >> iter 71000, loss: 0.001288
 >> iter 72000, loss: 0.001265
 >> iter 73000, loss: 0.001249
 >> iter 74000, loss: 0.001227
 >> iter 75000, loss: 0.001211
 >> iter 76000, loss: 0.001191
 >> iter 77000, loss: 0.001176
 >> iter 78000, loss: 0.001157
 >> iter 79000, loss: 0.001144
 >> iter 80000, loss: 0.001125
   Number of active neurons: 6
 >> iter 81000, loss: 0.001112
 >> iter 82000, loss: 0.001095
 >> iter 83000, loss: 0.001083
 >> iter 84000, loss: 0.001066
 >> iter 85000, loss: 0.001054
 >> iter 86000, loss: 0.001039
 >> iter 87000, loss: 0.001028
 >> iter 88000, loss: 0.001013
 >> iter 89000, loss: 0.001002
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 11.3392440504
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.549627
 >> iter 2000, loss: 10.476805
 >> iter 3000, loss: 8.611680
 >> iter 4000, loss: 7.910481
 >> iter 5000, loss: 7.662995
 >> iter 6000, loss: 7.555971
 >> iter 7000, loss: 7.549421
 >> iter 8000, loss: 7.211498
 >> iter 9000, loss: 4.642710
 >> iter 10000, loss: 1.762360
   Number of active neurons: 6
 >> iter 11000, loss: 0.675460
 >> iter 12000, loss: 0.266613
 >> iter 13000, loss: 0.111705
 >> iter 14000, loss: 0.051877
 >> iter 15000, loss: 0.028037
 >> iter 16000, loss: 0.017910
 >> iter 17000, loss: 0.013220
 >> iter 18000, loss: 0.010707
 >> iter 19000, loss: 0.009194
 >> iter 20000, loss: 0.008128
   Number of active neurons: 6
 >> iter 21000, loss: 0.007339
 >> iter 22000, loss: 0.006693
 >> iter 23000, loss: 0.006167
 >> iter 24000, loss: 0.005714
 >> iter 25000, loss: 0.005328
 >> iter 26000, loss: 0.004988
 >> iter 27000, loss: 0.004690
 >> iter 28000, loss: 0.004426
 >> iter 29000, loss: 0.004188
 >> iter 30000, loss: 0.003977
   Number of active neurons: 6
 >> iter 31000, loss: 0.003784
 >> iter 32000, loss: 0.003610
 >> iter 33000, loss: 0.003450
 >> iter 34000, loss: 0.003305
 >> iter 35000, loss: 0.003170
 >> iter 36000, loss: 0.003047
 >> iter 37000, loss: 0.002931
 >> iter 38000, loss: 0.002825
 >> iter 39000, loss: 0.002727
 >> iter 40000, loss: 0.002634
   Number of active neurons: 6
 >> iter 41000, loss: 0.002549
 >> iter 42000, loss: 0.002466
 >> iter 43000, loss: 0.002391
 >> iter 44000, loss: 0.002318
 >> iter 45000, loss: 0.002252
 >> iter 46000, loss: 0.002187
 >> iter 47000, loss: 0.002129
 >> iter 48000, loss: 0.002069
 >> iter 49000, loss: 0.002017
 >> iter 50000, loss: 0.001964
   Number of active neurons: 6
 >> iter 51000, loss: 0.001917
 >> iter 52000, loss: 0.001869
 >> iter 53000, loss: 0.001825
 >> iter 54000, loss: 0.001783
 >> iter 55000, loss: 0.001742
 >> iter 56000, loss: 0.001704
 >> iter 57000, loss: 0.001666
 >> iter 58000, loss: 0.001632
 >> iter 59000, loss: 0.001597
 >> iter 60000, loss: 0.001565
   Number of active neurons: 6
 >> iter 61000, loss: 0.001533
 >> iter 62000, loss: 0.001504
 >> iter 63000, loss: 0.001475
 >> iter 64000, loss: 0.001447
 >> iter 65000, loss: 0.001420
 >> iter 66000, loss: 0.001394
 >> iter 67000, loss: 0.001369
 >> iter 68000, loss: 0.001346
 >> iter 69000, loss: 0.001322
 >> iter 70000, loss: 0.001300
   Number of active neurons: 6
 >> iter 71000, loss: 0.001278
 >> iter 72000, loss: 0.001257
 >> iter 73000, loss: 0.001237
 >> iter 74000, loss: 0.001218
 >> iter 75000, loss: 0.001198
 >> iter 76000, loss: 0.001180
 >> iter 77000, loss: 0.001161
 >> iter 78000, loss: 0.001145
 >> iter 79000, loss: 0.001126
 >> iter 80000, loss: 0.001111
   Number of active neurons: 6
 >> iter 81000, loss: 0.001094
 >> iter 82000, loss: 0.001080
 >> iter 83000, loss: 0.001063
 >> iter 84000, loss: 0.001050
 >> iter 85000, loss: 0.001035
 >> iter 86000, loss: 0.001022
 >> iter 87000, loss: 0.001007
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.516104
 >> iter 2000, loss: 10.462447
 >> iter 3000, loss: 8.603650
 >> iter 4000, loss: 7.901308
 >> iter 5000, loss: 7.651608
 >> iter 6000, loss: 7.535951
 >> iter 7000, loss: 7.124169
 >> iter 8000, loss: 6.560267
 >> iter 9000, loss: 6.058975
 >> iter 10000, loss: 2.472379
   Number of active neurons: 6
 >> iter 11000, loss: 0.959469
 >> iter 12000, loss: 0.372462
 >> iter 13000, loss: 0.151357
 >> iter 14000, loss: 0.066056
 >> iter 15000, loss: 0.032791
 >> iter 16000, loss: 0.019139
 >> iter 17000, loss: 0.013206
 >> iter 18000, loss: 0.010234
 >> iter 19000, loss: 0.008609
 >> iter 20000, loss: 0.007511
   Number of active neurons: 6
 >> iter 21000, loss: 0.006761
 >> iter 22000, loss: 0.006167
 >> iter 23000, loss: 0.005739
 >> iter 24000, loss: 0.005275
 >> iter 25000, loss: 0.004913
 >> iter 26000, loss: 0.004600
 >> iter 27000, loss: 0.004362
 >> iter 28000, loss: 0.004083
 >> iter 29000, loss: 0.003866
 >> iter 30000, loss: 0.003659
   Number of active neurons: 6
 >> iter 31000, loss: 0.003496
 >> iter 32000, loss: 0.003315
 >> iter 33000, loss: 0.003177
 >> iter 34000, loss: 0.003036
 >> iter 35000, loss: 0.002923
 >> iter 36000, loss: 0.002796
 >> iter 37000, loss: 0.002695
 >> iter 38000, loss: 0.002593
 >> iter 39000, loss: 0.002505
 >> iter 40000, loss: 0.002415
   Number of active neurons: 6
 >> iter 41000, loss: 0.002338
 >> iter 42000, loss: 0.002259
 >> iter 43000, loss: 0.002191
 >> iter 44000, loss: 0.002122
 >> iter 45000, loss: 0.002063
 >> iter 46000, loss: 0.001999
 >> iter 47000, loss: 0.001948
 >> iter 48000, loss: 0.001891
 >> iter 49000, loss: 0.001844
 >> iter 50000, loss: 0.001792
   Number of active neurons: 6
 >> iter 51000, loss: 0.001752
 >> iter 52000, loss: 0.001704
 >> iter 53000, loss: 0.001668
 >> iter 54000, loss: 0.001625
 >> iter 55000, loss: 0.001591
 >> iter 56000, loss: 0.001552
 >> iter 57000, loss: 0.001521
 >> iter 58000, loss: 0.001485
 >> iter 59000, loss: 0.001457
 >> iter 60000, loss: 0.001423
   Number of active neurons: 6
 >> iter 61000, loss: 0.001398
 >> iter 62000, loss: 0.001367
 >> iter 63000, loss: 0.001343
 >> iter 64000, loss: 0.001314
 >> iter 65000, loss: 0.001292
 >> iter 66000, loss: 0.001266
 >> iter 67000, loss: 0.001246
 >> iter 68000, loss: 0.001221
 >> iter 69000, loss: 0.001203
 >> iter 70000, loss: 0.001179
   Number of active neurons: 6
 >> iter 71000, loss: 0.001162
 >> iter 72000, loss: 0.001139
 >> iter 73000, loss: 0.001124
 >> iter 74000, loss: 0.001102
 >> iter 75000, loss: 0.001088
 >> iter 76000, loss: 0.001067
 >> iter 77000, loss: 0.001053
 >> iter 78000, loss: 0.001034
 >> iter 79000, loss: 0.001022
 >> iter 80000, loss: 0.001003
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.545158
 >> iter 2000, loss: 10.464254
 >> iter 3000, loss: 8.597511
 >> iter 4000, loss: 7.894354
 >> iter 5000, loss: 7.645002
 >> iter 6000, loss: 7.303327
 >> iter 7000, loss: 6.421123
 >> iter 8000, loss: 4.156701
 >> iter 9000, loss: 1.626113
 >> iter 10000, loss: 0.648934
   Number of active neurons: 6
 >> iter 11000, loss: 0.272618
 >> iter 12000, loss: 0.125887
 >> iter 13000, loss: 0.066462
 >> iter 14000, loss: 0.045158
 >> iter 15000, loss: 0.030796
 >> iter 16000, loss: 0.060981
 >> iter 17000, loss: 0.033951
 >> iter 18000, loss: 0.022533
 >> iter 19000, loss: 0.017162
 >> iter 20000, loss: 0.014383
   Number of active neurons: 6
 >> iter 21000, loss: 0.012610
 >> iter 22000, loss: 0.011399
 >> iter 23000, loss: 0.010392
 >> iter 24000, loss: 0.009943
 >> iter 25000, loss: 0.009069
 >> iter 26000, loss: 0.008339
 >> iter 27000, loss: 0.007643
 >> iter 28000, loss: 0.007105
 >> iter 29000, loss: 0.006613
 >> iter 30000, loss: 0.006218
   Number of active neurons: 6
 >> iter 31000, loss: 0.005862
 >> iter 32000, loss: 0.005559
 >> iter 33000, loss: 0.005288
 >> iter 34000, loss: 0.005045
 >> iter 35000, loss: 0.004834
 >> iter 36000, loss: 0.004630
 >> iter 37000, loss: 0.004459
 >> iter 38000, loss: 0.004289
 >> iter 39000, loss: 0.004144
 >> iter 40000, loss: 0.003996
   Number of active neurons: 6
 >> iter 41000, loss: 0.003871
 >> iter 42000, loss: 0.003740
 >> iter 43000, loss: 0.003633
 >> iter 44000, loss: 0.003521
 >> iter 45000, loss: 0.003423
 >> iter 46000, loss: 0.003324
 >> iter 47000, loss: 0.003237
 >> iter 48000, loss: 0.003145
 >> iter 49000, loss: 0.003069
 >> iter 50000, loss: 0.002987
   Number of active neurons: 6
 >> iter 51000, loss: 0.002918
 >> iter 52000, loss: 0.002842
 >> iter 53000, loss: 0.002781
 >> iter 54000, loss: 0.002712
 >> iter 55000, loss: 0.002656
 >> iter 56000, loss: 0.002592
 >> iter 57000, loss: 0.002542
 >> iter 58000, loss: 0.002484
 >> iter 59000, loss: 0.002436
 >> iter 60000, loss: 0.002384
   Number of active neurons: 6
 >> iter 61000, loss: 0.002340
 >> iter 62000, loss: 0.002291
 >> iter 63000, loss: 0.002250
 >> iter 64000, loss: 0.002205
 >> iter 65000, loss: 0.002168
 >> iter 66000, loss: 0.002125
 >> iter 67000, loss: 0.002089
 >> iter 68000, loss: 0.002051
 >> iter 69000, loss: 0.002019
 >> iter 70000, loss: 0.001982
   Number of active neurons: 6
 >> iter 71000, loss: 0.001952
 >> iter 72000, loss: 0.001917
 >> iter 73000, loss: 0.001889
 >> iter 74000, loss: 0.001856
 >> iter 75000, loss: 0.001830
 >> iter 76000, loss: 0.001799
 >> iter 77000, loss: 0.001775
 >> iter 78000, loss: 0.001745
 >> iter 79000, loss: 0.001724
 >> iter 80000, loss: 0.001694
   Number of active neurons: 6
 >> iter 81000, loss: 0.001674
 >> iter 82000, loss: 0.001646
 >> iter 83000, loss: 0.001627
 >> iter 84000, loss: 0.001601
 >> iter 85000, loss: 0.001583
 >> iter 86000, loss: 0.001558
 >> iter 87000, loss: 0.001541
 >> iter 88000, loss: 0.001518
 >> iter 89000, loss: 0.001501
 >> iter 90000, loss: 0.001479
   Number of active neurons: 6
 >> iter 91000, loss: 0.001462
 >> iter 92000, loss: 0.001442
 >> iter 93000, loss: 0.001426
 >> iter 94000, loss: 0.001407
 >> iter 95000, loss: 0.001392
 >> iter 96000, loss: 0.001373
 >> iter 97000, loss: 0.001360
 >> iter 98000, loss: 0.001341
 >> iter 99000, loss: 0.001328
 >> iter 100000, loss: 0.001311
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.525065
 >> iter 2000, loss: 10.466819
 >> iter 3000, loss: 8.607626
 >> iter 4000, loss: 7.909022
 >> iter 5000, loss: 7.662293
 >> iter 6000, loss: 7.557607
 >> iter 7000, loss: 7.509509
 >> iter 8000, loss: 7.269611
 >> iter 9000, loss: 6.791428
 >> iter 10000, loss: 6.089087
   Number of active neurons: 6
 >> iter 11000, loss: 5.624465
 >> iter 12000, loss: 5.343274
 >> iter 13000, loss: 5.435374
 >> iter 14000, loss: 5.117772
 >> iter 15000, loss: 3.914141
 >> iter 16000, loss: 1.528438
 >> iter 17000, loss: 0.601165
 >> iter 18000, loss: 0.246022
 >> iter 19000, loss: 0.109470
 >> iter 20000, loss: 0.055022
   Number of active neurons: 6
 >> iter 21000, loss: 0.032785
 >> iter 22000, loss: 0.022533
 >> iter 23000, loss: 0.017666
 >> iter 24000, loss: 0.014654
 >> iter 25000, loss: 0.012883
 >> iter 26000, loss: 0.011419
 >> iter 27000, loss: 0.010427
 >> iter 28000, loss: 0.009496
 >> iter 29000, loss: 0.008827
 >> iter 30000, loss: 0.008162
   Number of active neurons: 6
 >> iter 31000, loss: 0.007676
 >> iter 32000, loss: 0.007176
 >> iter 33000, loss: 0.006801
 >> iter 34000, loss: 0.006407
 >> iter 35000, loss: 0.006108
 >> iter 36000, loss: 0.005788
 >> iter 37000, loss: 0.005543
 >> iter 38000, loss: 0.005280
 >> iter 39000, loss: 0.005076
 >> iter 40000, loss: 0.004852
   Number of active neurons: 6
 >> iter 41000, loss: 0.004683
 >> iter 42000, loss: 0.004487
 >> iter 43000, loss: 0.004342
 >> iter 44000, loss: 0.004173
 >> iter 45000, loss: 0.004046
 >> iter 46000, loss: 0.003902
 >> iter 47000, loss: 0.003790
 >> iter 48000, loss: 0.003662
 >> iter 49000, loss: 0.003564
 >> iter 50000, loss: 0.003451
   Number of active neurons: 6
 >> iter 51000, loss: 0.003364
 >> iter 52000, loss: 0.003263
 >> iter 53000, loss: 0.003185
 >> iter 54000, loss: 0.003096
 >> iter 55000, loss: 0.003024
 >> iter 56000, loss: 0.002947
 >> iter 57000, loss: 0.002879
 >> iter 58000, loss: 0.002809
 >> iter 59000, loss: 0.002747
 >> iter 60000, loss: 0.002685
   Number of active neurons: 6
 >> iter 61000, loss: 0.002627
 >> iter 62000, loss: 0.002569
 >> iter 63000, loss: 0.002516
 >> iter 64000, loss: 0.002464
 >> iter 65000, loss: 0.002415
 >> iter 66000, loss: 0.002366
 >> iter 67000, loss: 0.002320
 >> iter 68000, loss: 0.002278
 >> iter 69000, loss: 0.002235
 >> iter 70000, loss: 0.002193
   Number of active neurons: 6
 >> iter 71000, loss: 0.002153
 >> iter 72000, loss: 0.002115
 >> iter 73000, loss: 0.002078
 >> iter 74000, loss: 0.002043
 >> iter 75000, loss: 0.002008
 >> iter 76000, loss: 0.001976
 >> iter 77000, loss: 0.001942
 >> iter 78000, loss: 0.001913
 >> iter 79000, loss: 0.001882
 >> iter 80000, loss: 0.001854
   Number of active neurons: 6
 >> iter 81000, loss: 0.001824
 >> iter 82000, loss: 0.001798
 >> iter 83000, loss: 0.001770
 >> iter 84000, loss: 0.001745
 >> iter 85000, loss: 0.001720
 >> iter 86000, loss: 0.001695
 >> iter 87000, loss: 0.001672
 >> iter 88000, loss: 0.001649
 >> iter 89000, loss: 0.001626
 >> iter 90000, loss: 0.001605
   Number of active neurons: 6
 >> iter 91000, loss: 0.001583
 >> iter 92000, loss: 0.001563
 >> iter 93000, loss: 0.001542
 >> iter 94000, loss: 0.001523
 >> iter 95000, loss: 0.001503
 >> iter 96000, loss: 0.001485
 >> iter 97000, loss: 0.001466
 >> iter 98000, loss: 0.001449
 >> iter 99000, loss: 0.001430
 >> iter 100000, loss: 0.001415
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 15.494241
 >> iter 2000, loss: 10.450173
 >> iter 3000, loss: 8.594473
 >> iter 4000, loss: 7.881654
 >> iter 5000, loss: 7.206894
 >> iter 6000, loss: 6.434417
 >> iter 7000, loss: 5.725307
 >> iter 8000, loss: 5.086911
 >> iter 9000, loss: 4.655242
 >> iter 10000, loss: 1.885772
   Number of active neurons: 6
 >> iter 11000, loss: 0.749170
 >> iter 12000, loss: 0.312163
 >> iter 13000, loss: 0.143877
 >> iter 14000, loss: 0.073911
 >> iter 15000, loss: 0.042770
 >> iter 16000, loss: 0.028131
 >> iter 17000, loss: 0.022014
 >> iter 18000, loss: 0.017532
 >> iter 19000, loss: 0.015041
 >> iter 20000, loss: 0.013145
   Number of active neurons: 6
 >> iter 21000, loss: 0.011994
 >> iter 22000, loss: 0.010873
 >> iter 23000, loss: 0.010099
 >> iter 24000, loss: 0.009302
 >> iter 25000, loss: 0.008756
 >> iter 26000, loss: 0.008153
 >> iter 27000, loss: 0.007744
 >> iter 28000, loss: 0.007262
 >> iter 29000, loss: 0.006943
 >> iter 30000, loss: 0.006544
   Number of active neurons: 6
 >> iter 31000, loss: 0.006290
 >> iter 32000, loss: 0.005955
 >> iter 33000, loss: 0.005745
 >> iter 34000, loss: 0.005460
 >> iter 35000, loss: 0.005285
 >> iter 36000, loss: 0.005040
 >> iter 37000, loss: 0.004891
 >> iter 38000, loss: 0.004688
 >> iter 39000, loss: 0.004550
 >> iter 40000, loss: 0.004370
   Number of active neurons: 6
 >> iter 41000, loss: 0.004250
 >> iter 42000, loss: 0.004106
 >> iter 43000, loss: 0.004014
 >> iter 44000, loss: 0.003909
 >> iter 45000, loss: 0.003777
 >> iter 46000, loss: 0.003670
 >> iter 47000, loss: 0.003551
 >> iter 48000, loss: 0.003461
 >> iter 49000, loss: 0.003356
 >> iter 50000, loss: 0.003279
   Number of active neurons: 6
 >> iter 51000, loss: 0.003185
 >> iter 52000, loss: 0.003114
 >> iter 53000, loss: 0.003089
 >> iter 54000, loss: 0.003038
 >> iter 55000, loss: 0.002943
 >> iter 56000, loss: 0.002889
 >> iter 57000, loss: 0.002795
 >> iter 58000, loss: 0.002746
 >> iter 59000, loss: 0.002656
 >> iter 60000, loss: 0.002619
   Number of active neurons: 6
 >> iter 61000, loss: 0.002538
 >> iter 62000, loss: 0.002506
 >> iter 63000, loss: 0.002431
 >> iter 64000, loss: 0.002403
 >> iter 65000, loss: 0.002335
 >> iter 66000, loss: 0.002313
 >> iter 67000, loss: 0.002245
 >> iter 68000, loss: 0.002226
 >> iter 69000, loss: 0.002165
 >> iter 70000, loss: 0.002144
   Number of active neurons: 6
 >> iter 71000, loss: 0.002084
 >> iter 72000, loss: 0.002068
 >> iter 73000, loss: 0.002011
 >> iter 74000, loss: 0.001998
 >> iter 75000, loss: 0.001945
 >> iter 76000, loss: 0.001932
 >> iter 77000, loss: 0.001882
 >> iter 78000, loss: 0.001870
 >> iter 79000, loss: 0.001827
 >> iter 80000, loss: 0.001811
   Number of active neurons: 6
 >> iter 81000, loss: 0.001770
 >> iter 82000, loss: 0.001754
 >> iter 83000, loss: 0.001717
 >> iter 84000, loss: 0.001702
 >> iter 85000, loss: 0.001670
 >> iter 86000, loss: 0.001653
 >> iter 87000, loss: 0.001621
 >> iter 88000, loss: 0.001606
 >> iter 89000, loss: 0.001577
 >> iter 90000, loss: 0.001561
   Number of active neurons: 6
 >> iter 91000, loss: 0.001533
 >> iter 92000, loss: 0.001518
 >> iter 93000, loss: 0.001492
 >> iter 94000, loss: 0.001477
 >> iter 95000, loss: 0.001453
 >> iter 96000, loss: 0.001438
 >> iter 97000, loss: 0.001416
 >> iter 98000, loss: 0.001400
 >> iter 99000, loss: 0.001380
 >> iter 100000, loss: 0.001364
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.639038
 >> iter 2000, loss: 10.504906
 >> iter 3000, loss: 8.615585
 >> iter 4000, loss: 7.900870
 >> iter 5000, loss: 7.650722
 >> iter 6000, loss: 7.535105
 >> iter 7000, loss: 7.506809
 >> iter 8000, loss: 7.447110
 >> iter 9000, loss: 6.999163
 >> iter 10000, loss: 6.333331
   Number of active neurons: 6
 >> iter 11000, loss: 5.876002
 >> iter 12000, loss: 5.288440
 >> iter 13000, loss: 4.862686
 >> iter 14000, loss: 4.750292
 >> iter 15000, loss: 4.566338
 >> iter 16000, loss: 4.480645
 >> iter 17000, loss: 4.665888
 >> iter 18000, loss: 4.505983
 >> iter 19000, loss: 3.844403
 >> iter 20000, loss: 3.613658
   Number of active neurons: 6
 >> iter 21000, loss: 3.294043
 >> iter 22000, loss: 3.325073
 >> iter 23000, loss: 3.089126
 >> iter 24000, loss: 1.399673
 >> iter 25000, loss: 0.562836
 >> iter 26000, loss: 0.236013
 >> iter 27000, loss: 0.108833
 >> iter 28000, loss: 0.057465
 >> iter 29000, loss: 0.035984
 >> iter 30000, loss: 0.025831
   Number of active neurons: 6
 >> iter 31000, loss: 0.020726
 >> iter 32000, loss: 0.017511
 >> iter 33000, loss: 0.015481
 >> iter 34000, loss: 0.013845
 >> iter 35000, loss: 0.012672
 >> iter 36000, loss: 0.011600
 >> iter 37000, loss: 0.010794
 >> iter 38000, loss: 0.010013
 >> iter 39000, loss: 0.009418
 >> iter 40000, loss: 0.008819
   Number of active neurons: 6
 >> iter 41000, loss: 0.008360
 >> iter 42000, loss: 0.007884
 >> iter 43000, loss: 0.007519
 >> iter 44000, loss: 0.007131
 >> iter 45000, loss: 0.006835
 >> iter 46000, loss: 0.006512
 >> iter 47000, loss: 0.006266
 >> iter 48000, loss: 0.005991
 >> iter 49000, loss: 0.005785
 >> iter 50000, loss: 0.005548
   Number of active neurons: 6
 >> iter 51000, loss: 0.005374
 >> iter 52000, loss: 0.005168
 >> iter 53000, loss: 0.005018
 >> iter 54000, loss: 0.004836
 >> iter 55000, loss: 0.004706
 >> iter 56000, loss: 0.004545
 >> iter 57000, loss: 0.004432
 >> iter 58000, loss: 0.004286
 >> iter 59000, loss: 0.004187
 >> iter 60000, loss: 0.004057
   Number of active neurons: 6
 >> iter 61000, loss: 0.003968
 >> iter 62000, loss: 0.003851
 >> iter 63000, loss: 0.003771
 >> iter 64000, loss: 0.003665
 >> iter 65000, loss: 0.003593
 >> iter 66000, loss: 0.003496
 >> iter 67000, loss: 0.003432
 >> iter 68000, loss: 0.003341
 >> iter 69000, loss: 0.003284
 >> iter 70000, loss: 0.003200
   Number of active neurons: 6
 >> iter 71000, loss: 0.003149
 >> iter 72000, loss: 0.003071
 >> iter 73000, loss: 0.003024
 >> iter 74000, loss: 0.002951
 >> iter 75000, loss: 0.002909
 >> iter 76000, loss: 0.002840
 >> iter 77000, loss: 0.002802
 >> iter 78000, loss: 0.002738
 >> iter 79000, loss: 0.002702
 >> iter 80000, loss: 0.002643
   Number of active neurons: 6
 >> iter 81000, loss: 0.002610
 >> iter 82000, loss: 0.002553
 >> iter 83000, loss: 0.002524
 >> iter 84000, loss: 0.002470
 >> iter 85000, loss: 0.002443
 >> iter 86000, loss: 0.002393
 >> iter 87000, loss: 0.002367
 >> iter 88000, loss: 0.002320
 >> iter 89000, loss: 0.002295
 >> iter 90000, loss: 0.002251
   Number of active neurons: 6
 >> iter 91000, loss: 0.002228
 >> iter 92000, loss: 0.002186
 >> iter 93000, loss: 0.002164
 >> iter 94000, loss: 0.002125
 >> iter 95000, loss: 0.002104
 >> iter 96000, loss: 0.002067
 >> iter 97000, loss: 0.002048
 >> iter 98000, loss: 0.002013
 >> iter 99000, loss: 0.001995
 >> iter 100000, loss: 0.001961
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.572984
 >> iter 2000, loss: 10.483019
 >> iter 3000, loss: 8.608902
 >> iter 4000, loss: 7.898240
 >> iter 5000, loss: 7.586021
 >> iter 6000, loss: 6.941565
 >> iter 7000, loss: 6.237954
 >> iter 8000, loss: 4.184994
 >> iter 9000, loss: 1.641170
 >> iter 10000, loss: 0.666143
   Number of active neurons: 6
 >> iter 11000, loss: 0.276449
 >> iter 12000, loss: 0.125249
 >> iter 13000, loss: 0.065021
 >> iter 14000, loss: 0.040404
 >> iter 15000, loss: 0.028642
 >> iter 16000, loss: 0.022436
 >> iter 17000, loss: 0.018832
 >> iter 18000, loss: 0.016439
 >> iter 19000, loss: 0.014668
 >> iter 20000, loss: 0.013301
   Number of active neurons: 6
 >> iter 21000, loss: 0.012152
 >> iter 22000, loss: 0.011215
 >> iter 23000, loss: 0.010384
 >> iter 24000, loss: 0.009691
 >> iter 25000, loss: 0.009056
 >> iter 26000, loss: 0.008521
 >> iter 27000, loss: 0.008021
 >> iter 28000, loss: 0.007595
 >> iter 29000, loss: 0.007190
 >> iter 30000, loss: 0.006842
   Number of active neurons: 6
 >> iter 31000, loss: 0.006508
 >> iter 32000, loss: 0.006220
 >> iter 33000, loss: 0.005940
 >> iter 34000, loss: 0.005695
 >> iter 35000, loss: 0.005458
 >> iter 36000, loss: 0.005247
 >> iter 37000, loss: 0.005045
 >> iter 38000, loss: 0.004861
 >> iter 39000, loss: 0.004686
 >> iter 40000, loss: 0.004525
   Number of active neurons: 6
 >> iter 41000, loss: 0.004373
 >> iter 42000, loss: 0.004230
 >> iter 43000, loss: 0.004095
 >> iter 44000, loss: 0.003969
 >> iter 45000, loss: 0.003849
 >> iter 46000, loss: 0.003737
 >> iter 47000, loss: 0.003630
 >> iter 48000, loss: 0.003528
 >> iter 49000, loss: 0.003433
 >> iter 50000, loss: 0.003340
   Number of active neurons: 6
 >> iter 51000, loss: 0.003255
 >> iter 52000, loss: 0.003170
 >> iter 53000, loss: 0.003093
 >> iter 54000, loss: 0.003016
 >> iter 55000, loss: 0.002945
 >> iter 56000, loss: 0.002875
 >> iter 57000, loss: 0.002811
 >> iter 58000, loss: 0.002746
 >> iter 59000, loss: 0.002686
 >> iter 60000, loss: 0.002628
   Number of active neurons: 6
 >> iter 61000, loss: 0.002573
 >> iter 62000, loss: 0.002518
 >> iter 63000, loss: 0.002468
 >> iter 64000, loss: 0.002418
 >> iter 65000, loss: 0.002371
 >> iter 66000, loss: 0.002323
 >> iter 67000, loss: 0.002281
 >> iter 68000, loss: 0.002236
 >> iter 69000, loss: 0.002196
 >> iter 70000, loss: 0.002155
   Number of active neurons: 6
 >> iter 71000, loss: 0.002118
 >> iter 72000, loss: 0.002079
 >> iter 73000, loss: 0.002045
 >> iter 74000, loss: 0.002008
 >> iter 75000, loss: 0.001976
 >> iter 76000, loss: 0.001941
 >> iter 77000, loss: 0.001911
 >> iter 78000, loss: 0.001878
 >> iter 79000, loss: 0.001850
 >> iter 80000, loss: 0.001820
   Number of active neurons: 6
 >> iter 81000, loss: 0.001793
 >> iter 82000, loss: 0.001764
 >> iter 83000, loss: 0.001739
 >> iter 84000, loss: 0.001711
 >> iter 85000, loss: 0.001689
 >> iter 86000, loss: 0.001662
 >> iter 87000, loss: 0.001640
 >> iter 88000, loss: 0.001614
 >> iter 89000, loss: 0.001594
 >> iter 90000, loss: 0.001570
   Number of active neurons: 6
 >> iter 91000, loss: 0.001550
 >> iter 92000, loss: 0.001527
 >> iter 93000, loss: 0.001508
 >> iter 94000, loss: 0.001487
 >> iter 95000, loss: 0.001468
 >> iter 96000, loss: 0.001448
 >> iter 97000, loss: 0.001431
 >> iter 98000, loss: 0.001411
 >> iter 99000, loss: 0.001395
 >> iter 100000, loss: 0.001376
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.625701
 >> iter 2000, loss: 10.494065
 >> iter 3000, loss: 8.604009
 >> iter 4000, loss: 7.887869
 >> iter 5000, loss: 7.633834
 >> iter 6000, loss: 7.419798
 >> iter 7000, loss: 5.495691
 >> iter 8000, loss: 2.102354
 >> iter 9000, loss: 0.809957
 >> iter 10000, loss: 0.321833
   Number of active neurons: 6
 >> iter 11000, loss: 0.136184
 >> iter 12000, loss: 0.064094
 >> iter 13000, loss: 0.035148
 >> iter 14000, loss: 0.022694
 >> iter 15000, loss: 0.016810
 >> iter 16000, loss: 0.013601
 >> iter 17000, loss: 0.011611
 >> iter 18000, loss: 0.010208
 >> iter 19000, loss: 0.009135
 >> iter 20000, loss: 0.008280
   Number of active neurons: 6
 >> iter 21000, loss: 0.007563
 >> iter 22000, loss: 0.006970
 >> iter 23000, loss: 0.006448
 >> iter 24000, loss: 0.006012
 >> iter 25000, loss: 0.005614
 >> iter 26000, loss: 0.005283
 >> iter 27000, loss: 0.004970
 >> iter 28000, loss: 0.004711
 >> iter 29000, loss: 0.004460
 >> iter 30000, loss: 0.004251
   Number of active neurons: 6
 >> iter 31000, loss: 0.004044
 >> iter 32000, loss: 0.003874
 >> iter 33000, loss: 0.003699
 >> iter 34000, loss: 0.003558
 >> iter 35000, loss: 0.003410
 >> iter 36000, loss: 0.003290
 >> iter 37000, loss: 0.003161
 >> iter 38000, loss: 0.003059
 >> iter 39000, loss: 0.002946
 >> iter 40000, loss: 0.002859
   Number of active neurons: 6
 >> iter 41000, loss: 0.002758
 >> iter 42000, loss: 0.002682
 >> iter 43000, loss: 0.002593
 >> iter 44000, loss: 0.002526
 >> iter 45000, loss: 0.002445
 >> iter 46000, loss: 0.002387
 >> iter 47000, loss: 0.002314
 >> iter 48000, loss: 0.002261
 >> iter 49000, loss: 0.002195
 >> iter 50000, loss: 0.002148
   Number of active neurons: 6
 >> iter 51000, loss: 0.002087
 >> iter 52000, loss: 0.002045
 >> iter 53000, loss: 0.001990
 >> iter 54000, loss: 0.001952
 >> iter 55000, loss: 0.001901
 >> iter 56000, loss: 0.001867
 >> iter 57000, loss: 0.001819
 >> iter 58000, loss: 0.001789
 >> iter 59000, loss: 0.001744
 >> iter 60000, loss: 0.001716
   Number of active neurons: 6
 >> iter 61000, loss: 0.001675
 >> iter 62000, loss: 0.001650
 >> iter 63000, loss: 0.001610
 >> iter 64000, loss: 0.001588
 >> iter 65000, loss: 0.001551
 >> iter 66000, loss: 0.001530
 >> iter 67000, loss: 0.001495
 >> iter 68000, loss: 0.001476
 >> iter 69000, loss: 0.001443
 >> iter 70000, loss: 0.001426
   Number of active neurons: 6
 >> iter 71000, loss: 0.001395
 >> iter 72000, loss: 0.001379
 >> iter 73000, loss: 0.001349
 >> iter 74000, loss: 0.001334
 >> iter 75000, loss: 0.001307
 >> iter 76000, loss: 0.001292
 >> iter 77000, loss: 0.001267
 >> iter 78000, loss: 0.001253
 >> iter 79000, loss: 0.001229
 >> iter 80000, loss: 0.001216
   Number of active neurons: 6
 >> iter 81000, loss: 0.001193
 >> iter 82000, loss: 0.001182
 >> iter 83000, loss: 0.001160
 >> iter 84000, loss: 0.001149
 >> iter 85000, loss: 0.001128
 >> iter 86000, loss: 0.001117
 >> iter 87000, loss: 0.001097
 >> iter 88000, loss: 0.001088
 >> iter 89000, loss: 0.001068
 >> iter 90000, loss: 0.001060
   Number of active neurons: 6
 >> iter 91000, loss: 0.001041
 >> iter 92000, loss: 0.001033
 >> iter 93000, loss: 0.001015
 >> iter 94000, loss: 0.001008
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.563302
 >> iter 2000, loss: 10.480534
 >> iter 3000, loss: 8.611982
 >> iter 4000, loss: 7.907854
 >> iter 5000, loss: 7.658671
 >> iter 6000, loss: 7.547654
 >> iter 7000, loss: 7.397842
 >> iter 8000, loss: 6.472136
 >> iter 9000, loss: 5.596931
 >> iter 10000, loss: 2.581181
   Number of active neurons: 6
 >> iter 11000, loss: 1.037614
 >> iter 12000, loss: 0.507822
 >> iter 13000, loss: 0.216517
 >> iter 14000, loss: 0.157187
 >> iter 15000, loss: 0.076763
 >> iter 16000, loss: 0.043195
 >> iter 17000, loss: 0.029101
 >> iter 18000, loss: 0.021930
 >> iter 19000, loss: 0.018397
 >> iter 20000, loss: 0.015759
   Number of active neurons: 6
 >> iter 21000, loss: 0.014349
 >> iter 22000, loss: 0.012770
 >> iter 23000, loss: 0.011892
 >> iter 24000, loss: 0.010788
 >> iter 25000, loss: 0.010210
 >> iter 26000, loss: 0.009355
 >> iter 27000, loss: 0.009111
 >> iter 28000, loss: 0.008385
 >> iter 29000, loss: 0.008070
 >> iter 30000, loss: 0.007517
   Number of active neurons: 6
 >> iter 31000, loss: 0.007252
 >> iter 32000, loss: 0.006761
 >> iter 33000, loss: 0.006583
 >> iter 34000, loss: 0.006156
 >> iter 35000, loss: 0.006031
 >> iter 36000, loss: 0.005645
 >> iter 37000, loss: 0.005561
 >> iter 38000, loss: 0.005219
 >> iter 39000, loss: 0.005159
 >> iter 40000, loss: 0.004856
   Number of active neurons: 6
 >> iter 41000, loss: 0.004810
 >> iter 42000, loss: 0.004605
 >> iter 43000, loss: 0.004506
 >> iter 44000, loss: 0.004323
 >> iter 45000, loss: 0.004238
 >> iter 46000, loss: 0.004073
 >> iter 47000, loss: 0.004000
 >> iter 48000, loss: 0.003849
 >> iter 49000, loss: 0.003788
 >> iter 50000, loss: 0.003649
   Number of active neurons: 6
 >> iter 51000, loss: 0.003599
 >> iter 52000, loss: 0.003474
 >> iter 53000, loss: 0.003436
 >> iter 54000, loss: 0.003330
 >> iter 55000, loss: 0.003288
 >> iter 56000, loss: 0.003200
 >> iter 57000, loss: 0.003131
 >> iter 58000, loss: 0.003046
 >> iter 59000, loss: 0.002978
 >> iter 60000, loss: 0.002903
   Number of active neurons: 6
 >> iter 61000, loss: 0.002844
 >> iter 62000, loss: 0.002778
 >> iter 63000, loss: 0.002726
 >> iter 64000, loss: 0.002665
 >> iter 65000, loss: 0.002619
 >> iter 66000, loss: 0.002562
 >> iter 67000, loss: 0.002521
 >> iter 68000, loss: 0.002468
 >> iter 69000, loss: 0.002431
 >> iter 70000, loss: 0.002381
   Number of active neurons: 6
 >> iter 71000, loss: 0.002348
 >> iter 72000, loss: 0.002299
 >> iter 73000, loss: 0.002271
 >> iter 74000, loss: 0.002224
 >> iter 75000, loss: 0.002198
 >> iter 76000, loss: 0.002153
 >> iter 77000, loss: 0.002130
 >> iter 78000, loss: 0.002087
 >> iter 79000, loss: 0.002065
 >> iter 80000, loss: 0.002024
   Number of active neurons: 6
 >> iter 81000, loss: 0.002007
 >> iter 82000, loss: 0.001965
 >> iter 83000, loss: 0.001950
 >> iter 84000, loss: 0.001909
 >> iter 85000, loss: 0.001896
 >> iter 86000, loss: 0.001856
 >> iter 87000, loss: 0.001844
 >> iter 88000, loss: 0.001806
 >> iter 89000, loss: 0.001795
 >> iter 90000, loss: 0.001758
   Number of active neurons: 6
 >> iter 91000, loss: 0.001749
 >> iter 92000, loss: 0.001713
 >> iter 93000, loss: 0.001704
 >> iter 94000, loss: 0.001670
 >> iter 95000, loss: 0.001662
 >> iter 96000, loss: 0.001629
 >> iter 97000, loss: 0.001622
 >> iter 98000, loss: 0.001590
 >> iter 99000, loss: 0.001584
 >> iter 100000, loss: 0.001553
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.729262
 >> iter 2000, loss: 10.550990
 >> iter 3000, loss: 8.639503
 >> iter 4000, loss: 7.914331
 >> iter 5000, loss: 7.656640
 >> iter 6000, loss: 7.545873
 >> iter 7000, loss: 7.516129
 >> iter 8000, loss: 7.487868
 >> iter 9000, loss: 7.489412
 >> iter 10000, loss: 7.473334
   Number of active neurons: 4
 >> iter 11000, loss: 7.481082
 >> iter 12000, loss: 7.339687
 >> iter 13000, loss: 6.640338
 >> iter 14000, loss: 5.847576
 >> iter 15000, loss: 2.654671
 >> iter 16000, loss: 1.032787
 >> iter 17000, loss: 0.413541
 >> iter 18000, loss: 0.175365
 >> iter 19000, loss: 0.082485
 >> iter 20000, loss: 0.044588
   Number of active neurons: 6
 >> iter 21000, loss: 0.028443
 >> iter 22000, loss: 0.020612
 >> iter 23000, loss: 0.016559
 >> iter 24000, loss: 0.013923
 >> iter 25000, loss: 0.012250
 >> iter 26000, loss: 0.010868
 >> iter 27000, loss: 0.009893
 >> iter 28000, loss: 0.008989
 >> iter 29000, loss: 0.008329
 >> iter 30000, loss: 0.007671
   Number of active neurons: 6
 >> iter 31000, loss: 0.007190
 >> iter 32000, loss: 0.006691
 >> iter 33000, loss: 0.006324
 >> iter 34000, loss: 0.005930
 >> iter 35000, loss: 0.005644
 >> iter 36000, loss: 0.005326
 >> iter 37000, loss: 0.005093
 >> iter 38000, loss: 0.004838
 >> iter 39000, loss: 0.004644
 >> iter 40000, loss: 0.004431
   Number of active neurons: 6
 >> iter 41000, loss: 0.004263
 >> iter 42000, loss: 0.004087
 >> iter 43000, loss: 0.003940
 >> iter 44000, loss: 0.003800
 >> iter 45000, loss: 0.003661
 >> iter 46000, loss: 0.003542
 >> iter 47000, loss: 0.003420
 >> iter 48000, loss: 0.003316
 >> iter 49000, loss: 0.003208
 >> iter 50000, loss: 0.003117
   Number of active neurons: 6
 >> iter 51000, loss: 0.003023
 >> iter 52000, loss: 0.002940
 >> iter 53000, loss: 0.002857
 >> iter 54000, loss: 0.002782
 >> iter 55000, loss: 0.002709
 >> iter 56000, loss: 0.002641
 >> iter 57000, loss: 0.002574
 >> iter 58000, loss: 0.002513
 >> iter 59000, loss: 0.002453
 >> iter 60000, loss: 0.002397
   Number of active neurons: 6
 >> iter 61000, loss: 0.002343
 >> iter 62000, loss: 0.002291
 >> iter 63000, loss: 0.002241
 >> iter 64000, loss: 0.002194
 >> iter 65000, loss: 0.002148
 >> iter 66000, loss: 0.002105
 >> iter 67000, loss: 0.002062
 >> iter 68000, loss: 0.002023
 >> iter 69000, loss: 0.001983
 >> iter 70000, loss: 0.001947
   Number of active neurons: 6
 >> iter 71000, loss: 0.001910
 >> iter 72000, loss: 0.001877
 >> iter 73000, loss: 0.001842
 >> iter 74000, loss: 0.001811
 >> iter 75000, loss: 0.001779
 >> iter 76000, loss: 0.001750
 >> iter 77000, loss: 0.001721
 >> iter 78000, loss: 0.001693
 >> iter 79000, loss: 0.001666
 >> iter 80000, loss: 0.001639
   Number of active neurons: 6
 >> iter 81000, loss: 0.001614
 >> iter 82000, loss: 0.001589
 >> iter 83000, loss: 0.001565
 >> iter 84000, loss: 0.001541
 >> iter 85000, loss: 0.001520
 >> iter 86000, loss: 0.001497
 >> iter 87000, loss: 0.001477
 >> iter 88000, loss: 0.001455
 >> iter 89000, loss: 0.001435
 >> iter 90000, loss: 0.001415
   Number of active neurons: 6
 >> iter 91000, loss: 0.001396
 >> iter 92000, loss: 0.001377
 >> iter 93000, loss: 0.001360
 >> iter 94000, loss: 0.001341
 >> iter 95000, loss: 0.001325
 >> iter 96000, loss: 0.001308
 >> iter 97000, loss: 0.001291
 >> iter 98000, loss: 0.001276
 >> iter 99000, loss: 0.001259
 >> iter 100000, loss: 0.001245
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

