 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 4e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.755635
 >> iter 2000, loss: 8.431254
 >> iter 3000, loss: 3.283640
 >> iter 4000, loss: 1.286726
 >> iter 5000, loss: 0.492437
 >> iter 6000, loss: 0.196080
 >> iter 7000, loss: 0.086274
 >> iter 8000, loss: 0.257403
 >> iter 9000, loss: 0.112073
 >> iter 10000, loss: 0.055252
   Number of active neurons: 10
 >> iter 11000, loss: 0.033821
 >> iter 12000, loss: 0.024986
 >> iter 13000, loss: 0.021729
 >> iter 14000, loss: 0.266635
 >> iter 15000, loss: 0.121173
 >> iter 16000, loss: 0.261938
 >> iter 17000, loss: 0.114730
 >> iter 18000, loss: 0.055528
 >> iter 19000, loss: 0.033355
 >> iter 20000, loss: 0.024530
   Number of active neurons: 10
 >> iter 21000, loss: 0.021363
 >> iter 22000, loss: 0.180553
 >> iter 23000, loss: 0.080920
 >> iter 24000, loss: 0.342138
 >> iter 25000, loss: 0.183610
 >> iter 26000, loss: 0.081411
 >> iter 27000, loss: 0.042807
 >> iter 28000, loss: 0.028329
 >> iter 29000, loss: 0.046684
 >> iter 30000, loss: 0.237006
   Number of active neurons: 9
 >> iter 31000, loss: 0.102940
 >> iter 32000, loss: 0.175394
 >> iter 33000, loss: 0.140541
 >> iter 34000, loss: 0.064523
 >> iter 35000, loss: 0.036203
 >> iter 36000, loss: 0.024752
 >> iter 37000, loss: 0.052485
 >> iter 38000, loss: 0.117984
 >> iter 39000, loss: 0.104391
 >> iter 40000, loss: 0.332566
   Number of active neurons: 8
 >> iter 41000, loss: 0.154128
 >> iter 42000, loss: 0.123088
 >> iter 43000, loss: 0.110211
 >> iter 44000, loss: 0.088691
 >> iter 45000, loss: 0.045036
 >> iter 46000, loss: 0.051826
 >> iter 47000, loss: 0.039357
 >> iter 48000, loss: 0.024407
 >> iter 49000, loss: 0.023951
 >> iter 50000, loss: 0.019476
   Number of active neurons: 8
 >> iter 51000, loss: 0.029524
 >> iter 52000, loss: 0.020823
 >> iter 53000, loss: 0.058105
 >> iter 54000, loss: 0.039680
 >> iter 55000, loss: 0.186700
 >> iter 56000, loss: 0.120594
 >> iter 57000, loss: 0.058624
 >> iter 58000, loss: 0.032405
 >> iter 59000, loss: 0.023969
 >> iter 60000, loss: 0.019075
   Number of active neurons: 8
 >> iter 61000, loss: 0.079309
 >> iter 62000, loss: 0.039467
 >> iter 63000, loss: 0.024842
 >> iter 64000, loss: 0.083466
 >> iter 65000, loss: 0.041836
 >> iter 66000, loss: 0.133548
 >> iter 67000, loss: 0.061118
 >> iter 68000, loss: 0.064857
 >> iter 69000, loss: 0.040411
 >> iter 70000, loss: 0.089482
   Number of active neurons: 8
 >> iter 71000, loss: 0.043024
 >> iter 72000, loss: 0.025558
 >> iter 73000, loss: 0.027008
 >> iter 74000, loss: 0.078274
 >> iter 75000, loss: 0.042972
 >> iter 76000, loss: 0.024806
 >> iter 77000, loss: 0.068364
 >> iter 78000, loss: 0.034167
 >> iter 79000, loss: 0.027605
 >> iter 80000, loss: 0.019239
   Number of active neurons: 8
 >> iter 81000, loss: 0.027203
 >> iter 82000, loss: 0.024219
 >> iter 83000, loss: 0.021092
 >> iter 84000, loss: 0.202353
 >> iter 85000, loss: 0.093848
 >> iter 86000, loss: 0.144435
 >> iter 87000, loss: 0.065225
 >> iter 88000, loss: 0.097590
 >> iter 89000, loss: 0.046738
 >> iter 90000, loss: 0.187458
   Number of active neurons: 8
 >> iter 91000, loss: 0.105095
 >> iter 92000, loss: 0.322771
 >> iter 93000, loss: 0.181311
 >> iter 94000, loss: 0.162909
 >> iter 95000, loss: 0.127189
 >> iter 96000, loss: 0.096796
 >> iter 97000, loss: 0.135355
 >> iter 98000, loss: 0.082537
 >> iter 99000, loss: 0.095340
 >> iter 100000, loss: 0.065476
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 26.2915805613
   - Test - B: 14.399040064
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 15.990185
 >> iter 2000, loss: 7.031207
 >> iter 3000, loss: 2.685756
 >> iter 4000, loss: 1.044081
 >> iter 5000, loss: 0.490287
 >> iter 6000, loss: 0.211085
 >> iter 7000, loss: 0.152171
 >> iter 8000, loss: 0.071232
 >> iter 9000, loss: 0.112524
 >> iter 10000, loss: 0.069130
   Number of active neurons: 10
 >> iter 11000, loss: 0.037318
 >> iter 12000, loss: 0.024462
 >> iter 13000, loss: 0.107261
 >> iter 14000, loss: 0.051471
 >> iter 15000, loss: 0.208544
 >> iter 16000, loss: 0.105297
 >> iter 17000, loss: 0.148552
 >> iter 18000, loss: 0.067140
 >> iter 19000, loss: 0.160216
 >> iter 20000, loss: 0.072156
   Number of active neurons: 10
 >> iter 21000, loss: 0.093714
 >> iter 22000, loss: 0.046177
 >> iter 23000, loss: 0.174586
 >> iter 24000, loss: 0.078133
 >> iter 25000, loss: 0.135921
 >> iter 26000, loss: 0.062833
 >> iter 27000, loss: 0.034064
 >> iter 28000, loss: 0.022207
 >> iter 29000, loss: 0.246207
 >> iter 30000, loss: 0.104194
   Number of active neurons: 9
 >> iter 31000, loss: 0.200231
 >> iter 32000, loss: 0.106502
 >> iter 33000, loss: 0.071106
 >> iter 34000, loss: 0.036468
 >> iter 35000, loss: 0.121601
 >> iter 36000, loss: 0.055330
 >> iter 37000, loss: 0.098966
 >> iter 38000, loss: 0.047335
 >> iter 39000, loss: 0.048039
 >> iter 40000, loss: 0.026964
   Number of active neurons: 9
 >> iter 41000, loss: 0.051608
 >> iter 42000, loss: 0.118618
 >> iter 43000, loss: 0.286206
 >> iter 44000, loss: 0.126169
 >> iter 45000, loss: 0.158479
 >> iter 46000, loss: 0.070031
 >> iter 47000, loss: 0.237922
 >> iter 48000, loss: 0.290784
 >> iter 49000, loss: 0.191896
 >> iter 50000, loss: 0.083830
   Number of active neurons: 9
 >> iter 51000, loss: 0.226533
 >> iter 52000, loss: 0.096693
 >> iter 53000, loss: 0.113807
 >> iter 54000, loss: 0.052762
 >> iter 55000, loss: 0.062691
 >> iter 56000, loss: 0.032480
 >> iter 57000, loss: 0.149373
 >> iter 58000, loss: 0.385360
 >> iter 59000, loss: 0.159701
 >> iter 60000, loss: 0.135045
   Number of active neurons: 7
 >> iter 61000, loss: 0.081800
 >> iter 62000, loss: 0.039489
 >> iter 63000, loss: 0.411967
 >> iter 64000, loss: 0.167462
 >> iter 65000, loss: 0.072416
 >> iter 66000, loss: 0.036550
 >> iter 67000, loss: 0.165541
 >> iter 68000, loss: 0.077111
 >> iter 69000, loss: 0.321594
 >> iter 70000, loss: 0.132572
   Number of active neurons: 7
 >> iter 71000, loss: 0.136541
 >> iter 72000, loss: 0.061630
 >> iter 73000, loss: 0.032068
 >> iter 74000, loss: 0.020195
 >> iter 75000, loss: 0.015889
 >> iter 76000, loss: 0.092490
 >> iter 77000, loss: 0.099608
 >> iter 78000, loss: 0.046345
 >> iter 79000, loss: 0.308476
 >> iter 80000, loss: 0.152703
   Number of active neurons: 7
 >> iter 81000, loss: 0.384185
 >> iter 82000, loss: 0.220912
 >> iter 83000, loss: 0.258603
 >> iter 84000, loss: 0.112827
 >> iter 85000, loss: 0.144407
 >> iter 86000, loss: 0.064608
 >> iter 87000, loss: 0.033717
 >> iter 88000, loss: 0.020927
 >> iter 89000, loss: 0.057511
 >> iter 90000, loss: 0.029127
   Number of active neurons: 7
 >> iter 91000, loss: 0.097906
 >> iter 92000, loss: 0.045304
 >> iter 93000, loss: 0.134342
 >> iter 94000, loss: 0.059948
 >> iter 95000, loss: 0.054459
 >> iter 96000, loss: 0.028757
 >> iter 97000, loss: 0.092150
 >> iter 98000, loss: 0.043410
 >> iter 99000, loss: 0.038711
 >> iter 100000, loss: 0.022094
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0119998800012
   - Test - A: 18.2121191921
   - Test - B: 18.5787614159
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.351337
 >> iter 2000, loss: 8.378265
 >> iter 3000, loss: 3.378149
 >> iter 4000, loss: 1.348832
 >> iter 5000, loss: 0.682641
 >> iter 6000, loss: 0.293048
 >> iter 7000, loss: 0.916051
 >> iter 8000, loss: 0.474227
 >> iter 9000, loss: 0.236546
 >> iter 10000, loss: 0.162612
   Number of active neurons: 10
 >> iter 11000, loss: 0.145190
 >> iter 12000, loss: 0.111846
 >> iter 13000, loss: 0.180410
 >> iter 14000, loss: 0.122095
 >> iter 15000, loss: 0.086716
 >> iter 16000, loss: 0.066638
 >> iter 17000, loss: 0.085172
 >> iter 18000, loss: 0.058963
 >> iter 19000, loss: 0.082112
 >> iter 20000, loss: 0.120454
   Number of active neurons: 10
 >> iter 21000, loss: 0.132191
 >> iter 22000, loss: 0.098895
 >> iter 23000, loss: 0.089788
 >> iter 24000, loss: 0.058908
 >> iter 25000, loss: 0.042643
 >> iter 26000, loss: 0.202458
 >> iter 27000, loss: 0.130129
 >> iter 28000, loss: 0.067661
 >> iter 29000, loss: 0.113697
 >> iter 30000, loss: 0.067142
   Number of active neurons: 9
 >> iter 31000, loss: 0.171954
 >> iter 32000, loss: 0.207762
 >> iter 33000, loss: 0.102571
 >> iter 34000, loss: 0.086326
 >> iter 35000, loss: 0.077668
 >> iter 36000, loss: 0.047531
 >> iter 37000, loss: 0.082466
 >> iter 38000, loss: 0.041372
 >> iter 39000, loss: 0.161441
 >> iter 40000, loss: 0.070755
   Number of active neurons: 8
 >> iter 41000, loss: 0.137476
 >> iter 42000, loss: 0.060986
 >> iter 43000, loss: 0.069915
 >> iter 44000, loss: 0.071965
 >> iter 45000, loss: 0.072747
 >> iter 46000, loss: 0.043436
 >> iter 47000, loss: 0.041546
 >> iter 48000, loss: 0.038657
 >> iter 49000, loss: 0.085774
 >> iter 50000, loss: 0.045354
   Number of active neurons: 8
 >> iter 51000, loss: 0.038834
 >> iter 52000, loss: 0.023696
 >> iter 53000, loss: 0.066876
 >> iter 54000, loss: 0.051174
 >> iter 55000, loss: 0.065679
 >> iter 56000, loss: 0.045208
 >> iter 57000, loss: 0.118867
 >> iter 58000, loss: 0.066802
 >> iter 59000, loss: 0.098983
 >> iter 60000, loss: 0.054793
   Number of active neurons: 8
 >> iter 61000, loss: 0.082784
 >> iter 62000, loss: 0.061669
 >> iter 63000, loss: 0.095957
 >> iter 64000, loss: 0.045871
 >> iter 65000, loss: 0.037972
 >> iter 66000, loss: 0.118011
 >> iter 67000, loss: 0.114765
 >> iter 68000, loss: 0.059969
 >> iter 69000, loss: 0.045030
 >> iter 70000, loss: 0.043963
   Number of active neurons: 8
 >> iter 71000, loss: 0.104082
 >> iter 72000, loss: 0.049348
 >> iter 73000, loss: 0.072187
 >> iter 74000, loss: 0.117896
 >> iter 75000, loss: 0.072228
 >> iter 76000, loss: 0.037507
 >> iter 77000, loss: 0.110297
 >> iter 78000, loss: 0.076285
 >> iter 79000, loss: 0.079536
 >> iter 80000, loss: 0.054811
   Number of active neurons: 8
 >> iter 81000, loss: 0.050729
 >> iter 82000, loss: 0.031942
 >> iter 83000, loss: 0.058954
 >> iter 84000, loss: 0.032095
 >> iter 85000, loss: 0.105061
 >> iter 86000, loss: 0.142840
 >> iter 87000, loss: 0.080360
 >> iter 88000, loss: 0.047196
 >> iter 89000, loss: 0.116608
 >> iter 90000, loss: 0.088012
   Number of active neurons: 8
 >> iter 91000, loss: 0.070326
 >> iter 92000, loss: 0.056898
 >> iter 93000, loss: 0.039181
 >> iter 94000, loss: 0.029084
 >> iter 95000, loss: 0.096482
 >> iter 96000, loss: 0.047211
 >> iter 97000, loss: 0.179686
 >> iter 98000, loss: 0.104499
 >> iter 99000, loss: 0.108149
 >> iter 100000, loss: 0.173609
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0379992400152
   - Test - Long: 0.0
   - Test - Big: 0.0389996100039
   - Test - A: 26.3649090061
   - Test - B: 22.2985134324
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.909612
 >> iter 2000, loss: 7.686490
 >> iter 3000, loss: 2.983503
 >> iter 4000, loss: 1.117302
 >> iter 5000, loss: 0.424170
 >> iter 6000, loss: 0.196846
 >> iter 7000, loss: 0.172694
 >> iter 8000, loss: 0.111340
 >> iter 9000, loss: 0.102603
 >> iter 10000, loss: 0.192655
   Number of active neurons: 9
 >> iter 11000, loss: 0.085510
 >> iter 12000, loss: 0.112661
 >> iter 13000, loss: 0.079241
 >> iter 14000, loss: 0.106255
 >> iter 15000, loss: 0.061606
 >> iter 16000, loss: 0.073300
 >> iter 17000, loss: 0.063486
 >> iter 18000, loss: 0.033458
 >> iter 19000, loss: 0.066438
 >> iter 20000, loss: 0.111296
   Number of active neurons: 9
 >> iter 21000, loss: 0.060331
 >> iter 22000, loss: 0.031983
 >> iter 23000, loss: 0.056519
 >> iter 24000, loss: 0.073160
 >> iter 25000, loss: 0.086895
 >> iter 26000, loss: 0.055886
 >> iter 27000, loss: 0.029251
 >> iter 28000, loss: 0.077185
 >> iter 29000, loss: 0.037755
 >> iter 30000, loss: 0.069563
   Number of active neurons: 9
 >> iter 31000, loss: 0.035140
 >> iter 32000, loss: 0.055071
 >> iter 33000, loss: 0.039306
 >> iter 34000, loss: 0.072948
 >> iter 35000, loss: 0.036792
 >> iter 36000, loss: 0.078061
 >> iter 37000, loss: 0.039018
 >> iter 38000, loss: 0.093098
 >> iter 39000, loss: 0.044450
 >> iter 40000, loss: 0.205702
   Number of active neurons: 9
 >> iter 41000, loss: 0.088512
 >> iter 42000, loss: 0.125572
 >> iter 43000, loss: 0.058637
 >> iter 44000, loss: 0.093778
 >> iter 45000, loss: 0.045776
 >> iter 46000, loss: 0.143105
 >> iter 47000, loss: 0.064683
 >> iter 48000, loss: 0.057217
 >> iter 49000, loss: 0.031250
 >> iter 50000, loss: 0.045708
   Number of active neurons: 9
 >> iter 51000, loss: 0.026623
 >> iter 52000, loss: 0.045839
 >> iter 53000, loss: 0.035954
 >> iter 54000, loss: 0.021937
 >> iter 55000, loss: 0.016734
 >> iter 56000, loss: 0.124586
 >> iter 57000, loss: 0.056895
 >> iter 58000, loss: 0.161879
 >> iter 59000, loss: 0.137957
 >> iter 60000, loss: 0.062389
   Number of active neurons: 8
 >> iter 61000, loss: 0.033474
 >> iter 62000, loss: 0.356571
 >> iter 63000, loss: 0.148286
 >> iter 64000, loss: 0.103150
 >> iter 65000, loss: 0.049435
 >> iter 66000, loss: 0.028333
 >> iter 67000, loss: 0.020029
 >> iter 68000, loss: 0.183352
 >> iter 69000, loss: 0.080305
 >> iter 70000, loss: 0.040455
   Number of active neurons: 8
 >> iter 71000, loss: 0.025003
 >> iter 72000, loss: 0.018684
 >> iter 73000, loss: 0.016131
 >> iter 74000, loss: 0.014867
 >> iter 75000, loss: 0.014288
 >> iter 76000, loss: 0.275913
 >> iter 77000, loss: 0.115022
 >> iter 78000, loss: 0.053395
 >> iter 79000, loss: 0.029850
 >> iter 80000, loss: 0.020386
   Number of active neurons: 7
 >> iter 81000, loss: 0.016699
 >> iter 82000, loss: 0.014778
 >> iter 83000, loss: 0.014113
 >> iter 84000, loss: 0.524742
 >> iter 85000, loss: 0.212176
 >> iter 86000, loss: 0.090704
 >> iter 87000, loss: 0.043982
 >> iter 88000, loss: 0.025750
 >> iter 89000, loss: 0.018635
 >> iter 90000, loss: 0.131069
   Number of active neurons: 7
 >> iter 91000, loss: 0.170000
 >> iter 92000, loss: 0.073967
 >> iter 93000, loss: 0.038876
 >> iter 94000, loss: 0.199951
 >> iter 95000, loss: 0.086061
 >> iter 96000, loss: 0.041861
 >> iter 97000, loss: 0.025008
 >> iter 98000, loss: 0.018317
 >> iter 99000, loss: 0.015440
 >> iter 100000, loss: 0.024994
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 20.4453036464
   - Test - B: 16.065595627
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.543006
 >> iter 2000, loss: 7.068618
 >> iter 3000, loss: 2.652410
 >> iter 4000, loss: 0.995156
 >> iter 5000, loss: 0.393413
 >> iter 6000, loss: 0.157485
 >> iter 7000, loss: 0.076594
 >> iter 8000, loss: 0.038399
 >> iter 9000, loss: 0.054332
 >> iter 10000, loss: 0.029815
   Number of active neurons: 9
 >> iter 11000, loss: 0.220266
 >> iter 12000, loss: 0.098251
 >> iter 13000, loss: 0.048320
 >> iter 14000, loss: 0.027544
 >> iter 15000, loss: 0.065708
 >> iter 16000, loss: 0.034212
 >> iter 17000, loss: 0.073693
 >> iter 18000, loss: 0.037524
 >> iter 19000, loss: 0.048341
 >> iter 20000, loss: 0.028341
   Number of active neurons: 9
 >> iter 21000, loss: 0.101741
 >> iter 22000, loss: 0.054091
 >> iter 23000, loss: 0.101509
 >> iter 24000, loss: 0.048950
 >> iter 25000, loss: 0.253270
 >> iter 26000, loss: 0.107997
 >> iter 27000, loss: 0.129127
 >> iter 28000, loss: 0.077936
 >> iter 29000, loss: 0.103653
 >> iter 30000, loss: 0.049630
   Number of active neurons: 9
 >> iter 31000, loss: 0.062524
 >> iter 32000, loss: 0.033778
 >> iter 33000, loss: 0.099787
 >> iter 34000, loss: 0.047487
 >> iter 35000, loss: 0.130134
 >> iter 36000, loss: 0.059707
 >> iter 37000, loss: 0.243882
 >> iter 38000, loss: 0.103938
 >> iter 39000, loss: 0.100075
 >> iter 40000, loss: 0.047260
   Number of active neurons: 9
 >> iter 41000, loss: 0.216209
 >> iter 42000, loss: 0.092741
 >> iter 43000, loss: 0.078961
 >> iter 44000, loss: 0.039527
 >> iter 45000, loss: 0.062579
 >> iter 46000, loss: 0.032635
 >> iter 47000, loss: 0.045570
 >> iter 48000, loss: 0.036675
 >> iter 49000, loss: 0.127510
 >> iter 50000, loss: 0.058078
   Number of active neurons: 9
 >> iter 51000, loss: 0.031549
 >> iter 52000, loss: 0.040743
 >> iter 53000, loss: 0.023973
 >> iter 54000, loss: 0.114376
 >> iter 55000, loss: 0.051812
 >> iter 56000, loss: 0.027463
 >> iter 57000, loss: 0.081448
 >> iter 58000, loss: 0.039720
 >> iter 59000, loss: 0.059873
 >> iter 60000, loss: 0.030618
   Number of active neurons: 9
 >> iter 61000, loss: 0.115098
 >> iter 62000, loss: 0.058347
 >> iter 63000, loss: 0.031508
 >> iter 64000, loss: 0.041681
 >> iter 65000, loss: 0.024149
 >> iter 66000, loss: 0.038389
 >> iter 67000, loss: 0.199160
 >> iter 68000, loss: 0.085616
 >> iter 69000, loss: 0.224825
 >> iter 70000, loss: 0.097485
   Number of active neurons: 8
 >> iter 71000, loss: 0.047174
 >> iter 72000, loss: 0.061922
 >> iter 73000, loss: 0.077071
 >> iter 74000, loss: 0.038109
 >> iter 75000, loss: 0.051223
 >> iter 76000, loss: 0.027940
 >> iter 77000, loss: 0.020250
 >> iter 78000, loss: 0.026630
 >> iter 79000, loss: 0.018785
 >> iter 80000, loss: 0.024130
   Number of active neurons: 8
 >> iter 81000, loss: 0.017808
 >> iter 82000, loss: 0.022624
 >> iter 83000, loss: 0.043869
 >> iter 84000, loss: 0.029552
 >> iter 85000, loss: 0.056182
 >> iter 86000, loss: 0.071108
 >> iter 87000, loss: 0.090210
 >> iter 88000, loss: 0.070681
 >> iter 89000, loss: 0.034588
 >> iter 90000, loss: 0.043428
   Number of active neurons: 8
 >> iter 91000, loss: 0.070654
 >> iter 92000, loss: 0.036312
 >> iter 93000, loss: 0.052583
 >> iter 94000, loss: 0.027598
 >> iter 95000, loss: 0.018655
 >> iter 96000, loss: 0.016027
 >> iter 97000, loss: 0.014156
 >> iter 98000, loss: 0.041773
 >> iter 99000, loss: 0.023210
 >> iter 100000, loss: 0.052698
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.054794
 >> iter 2000, loss: 7.239476
 >> iter 3000, loss: 2.725593
 >> iter 4000, loss: 1.236479
 >> iter 5000, loss: 0.518827
 >> iter 6000, loss: 0.214336
 >> iter 7000, loss: 0.151254
 >> iter 8000, loss: 0.087953
 >> iter 9000, loss: 0.081671
 >> iter 10000, loss: 0.044506
   Number of active neurons: 10
 >> iter 11000, loss: 0.206523
 >> iter 12000, loss: 0.095681
 >> iter 13000, loss: 0.070907
 >> iter 14000, loss: 0.038535
 >> iter 15000, loss: 0.077396
 >> iter 16000, loss: 0.040790
 >> iter 17000, loss: 0.028730
 >> iter 18000, loss: 0.088431
 >> iter 19000, loss: 0.048520
 >> iter 20000, loss: 0.028809
   Number of active neurons: 10
 >> iter 21000, loss: 0.541994
 >> iter 22000, loss: 0.342128
 >> iter 23000, loss: 0.141858
 >> iter 24000, loss: 0.109340
 >> iter 25000, loss: 0.075981
 >> iter 26000, loss: 0.041787
 >> iter 27000, loss: 0.026530
 >> iter 28000, loss: 0.154164
 >> iter 29000, loss: 0.748027
 >> iter 30000, loss: 0.687681
   Number of active neurons: 10
 >> iter 31000, loss: 0.482227
 >> iter 32000, loss: 0.355890
 >> iter 33000, loss: 0.227552
 >> iter 34000, loss: 0.155751
 >> iter 35000, loss: 0.075212
 >> iter 36000, loss: 0.054564
 >> iter 37000, loss: 0.035387
 >> iter 38000, loss: 0.054776
 >> iter 39000, loss: 0.039646
 >> iter 40000, loss: 0.023188
   Number of active neurons: 10
 >> iter 41000, loss: 0.018123
 >> iter 42000, loss: 0.015508
 >> iter 43000, loss: 0.014514
 >> iter 44000, loss: 0.242019
 >> iter 45000, loss: 0.103087
 >> iter 46000, loss: 0.047789
 >> iter 47000, loss: 0.027434
 >> iter 48000, loss: 0.019652
 >> iter 49000, loss: 0.016936
 >> iter 50000, loss: 0.195231
   Number of active neurons: 10
 >> iter 51000, loss: 0.083299
 >> iter 52000, loss: 0.041041
 >> iter 53000, loss: 0.025330
 >> iter 54000, loss: 0.139284
 >> iter 55000, loss: 0.062788
 >> iter 56000, loss: 0.240601
 >> iter 57000, loss: 0.102265
 >> iter 58000, loss: 0.049191
 >> iter 59000, loss: 0.029041
 >> iter 60000, loss: 0.189367
   Number of active neurons: 10
 >> iter 61000, loss: 0.111989
 >> iter 62000, loss: 0.052277
 >> iter 63000, loss: 0.029838
 >> iter 64000, loss: 0.172717
 >> iter 65000, loss: 0.076339
 >> iter 66000, loss: 0.038652
 >> iter 67000, loss: 0.024419
 >> iter 68000, loss: 0.145069
 >> iter 69000, loss: 0.110822
 >> iter 70000, loss: 0.051996
   Number of active neurons: 10
 >> iter 71000, loss: 0.029788
 >> iter 72000, loss: 0.020959
 >> iter 73000, loss: 0.017433
 >> iter 74000, loss: 0.222850
 >> iter 75000, loss: 0.093489
 >> iter 76000, loss: 0.044061
 >> iter 77000, loss: 0.025710
 >> iter 78000, loss: 0.018639
 >> iter 79000, loss: 0.016060
 >> iter 80000, loss: 0.444738
   Number of active neurons: 9
 >> iter 81000, loss: 0.296636
 >> iter 82000, loss: 0.122784
 >> iter 83000, loss: 0.056821
 >> iter 84000, loss: 0.031311
 >> iter 85000, loss: 0.021478
 >> iter 86000, loss: 0.017260
 >> iter 87000, loss: 0.015617
 >> iter 88000, loss: 0.014641
 >> iter 89000, loss: 0.014358
 >> iter 90000, loss: 0.013974
   Number of active neurons: 9
 >> iter 91000, loss: 0.013822
 >> iter 92000, loss: 0.536779
 >> iter 93000, loss: 0.212387
 >> iter 94000, loss: 0.089039
 >> iter 95000, loss: 0.043011
 >> iter 96000, loss: 0.025428
 >> iter 97000, loss: 0.018889
 >> iter 98000, loss: 0.205222
 >> iter 99000, loss: 0.086781
 >> iter 100000, loss: 0.041458
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 18.3987734151
   - Test - B: 20.0119992001
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.472423
 >> iter 2000, loss: 7.113991
 >> iter 3000, loss: 2.675715
 >> iter 4000, loss: 0.997242
 >> iter 5000, loss: 0.421539
 >> iter 6000, loss: 0.166683
 >> iter 7000, loss: 0.117259
 >> iter 8000, loss: 0.054506
 >> iter 9000, loss: 0.100964
 >> iter 10000, loss: 0.048026
   Number of active neurons: 9
 >> iter 11000, loss: 0.027898
 >> iter 12000, loss: 0.019995
 >> iter 13000, loss: 0.017290
 >> iter 14000, loss: 0.015967
 >> iter 15000, loss: 0.015684
 >> iter 16000, loss: 0.029800
 >> iter 17000, loss: 0.019473
 >> iter 18000, loss: 0.016036
 >> iter 19000, loss: 0.015053
 >> iter 20000, loss: 0.014649
   Number of active neurons: 9
 >> iter 21000, loss: 0.014422
 >> iter 22000, loss: 0.105927
 >> iter 23000, loss: 0.048234
 >> iter 24000, loss: 0.035202
 >> iter 25000, loss: 0.022275
 >> iter 26000, loss: 0.022828
 >> iter 27000, loss: 0.017343
 >> iter 28000, loss: 0.052159
 >> iter 29000, loss: 0.026998
 >> iter 30000, loss: 0.017615
   Number of active neurons: 9
 >> iter 31000, loss: 0.014694
 >> iter 32000, loss: 0.105013
 >> iter 33000, loss: 0.047921
 >> iter 34000, loss: 0.026140
 >> iter 35000, loss: 0.018143
 >> iter 36000, loss: 0.029815
 >> iter 37000, loss: 0.019300
 >> iter 38000, loss: 0.033292
 >> iter 39000, loss: 0.020393
 >> iter 40000, loss: 0.056942
   Number of active neurons: 7
 >> iter 41000, loss: 0.029512
 >> iter 42000, loss: 0.046033
 >> iter 43000, loss: 0.025264
 >> iter 44000, loss: 0.079059
 >> iter 45000, loss: 0.038371
 >> iter 46000, loss: 0.050084
 >> iter 47000, loss: 0.027119
 >> iter 48000, loss: 0.047355
 >> iter 49000, loss: 0.025957
 >> iter 50000, loss: 0.017556
   Number of active neurons: 7
 >> iter 51000, loss: 0.053345
 >> iter 52000, loss: 0.027402
 >> iter 53000, loss: 0.017630
 >> iter 54000, loss: 0.017611
 >> iter 55000, loss: 0.014622
 >> iter 56000, loss: 0.025703
 >> iter 57000, loss: 0.088140
 >> iter 58000, loss: 0.040381
 >> iter 59000, loss: 0.022385
 >> iter 60000, loss: 0.161248
   Number of active neurons: 7
 >> iter 61000, loss: 0.069398
 >> iter 62000, loss: 0.034226
 >> iter 63000, loss: 0.020878
 >> iter 64000, loss: 0.056143
 >> iter 65000, loss: 0.028739
 >> iter 66000, loss: 0.077461
 >> iter 67000, loss: 0.036636
 >> iter 68000, loss: 0.032200
 >> iter 69000, loss: 0.063637
 >> iter 70000, loss: 0.031922
   Number of active neurons: 7
 >> iter 71000, loss: 0.019709
 >> iter 72000, loss: 0.022523
 >> iter 73000, loss: 0.016519
 >> iter 74000, loss: 0.071642
 >> iter 75000, loss: 0.034174
 >> iter 76000, loss: 0.020117
 >> iter 77000, loss: 0.014832
 >> iter 78000, loss: 0.115051
 >> iter 79000, loss: 0.077534
 >> iter 80000, loss: 0.036567
   Number of active neurons: 6
 >> iter 81000, loss: 0.055203
 >> iter 82000, loss: 0.028597
 >> iter 83000, loss: 0.018016
 >> iter 84000, loss: 0.013794
 >> iter 85000, loss: 0.368031
 >> iter 86000, loss: 0.148112
 >> iter 87000, loss: 0.064220
 >> iter 88000, loss: 0.032296
 >> iter 89000, loss: 0.020921
 >> iter 90000, loss: 0.015594
   Number of active neurons: 5
 >> iter 91000, loss: 0.070189
 >> iter 92000, loss: 0.033941
 >> iter 93000, loss: 0.051303
 >> iter 94000, loss: 0.083811
 >> iter 95000, loss: 0.038745
 >> iter 96000, loss: 0.032044
 >> iter 97000, loss: 0.019215
 >> iter 98000, loss: 0.068699
 >> iter 99000, loss: 0.033029
 >> iter 100000, loss: 0.019547
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 18.4921005266
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.406406
 >> iter 2000, loss: 8.396010
 >> iter 3000, loss: 3.369813
 >> iter 4000, loss: 1.300600
 >> iter 5000, loss: 0.495057
 >> iter 6000, loss: 0.358321
 >> iter 7000, loss: 0.163309
 >> iter 8000, loss: 0.212363
 >> iter 9000, loss: 0.092636
 >> iter 10000, loss: 0.045605
   Number of active neurons: 10
 >> iter 11000, loss: 0.105016
 >> iter 12000, loss: 0.049880
 >> iter 13000, loss: 0.029463
 >> iter 14000, loss: 0.020655
 >> iter 15000, loss: 0.109451
 >> iter 16000, loss: 0.051319
 >> iter 17000, loss: 0.049831
 >> iter 18000, loss: 0.027968
 >> iter 19000, loss: 0.023781
 >> iter 20000, loss: 0.017994
   Number of active neurons: 9
 >> iter 21000, loss: 0.076353
 >> iter 22000, loss: 0.038906
 >> iter 23000, loss: 0.029724
 >> iter 24000, loss: 0.020655
 >> iter 25000, loss: 0.017484
 >> iter 26000, loss: 0.016211
 >> iter 27000, loss: 0.016137
 >> iter 28000, loss: 0.015652
 >> iter 29000, loss: 0.052742
 >> iter 30000, loss: 0.029141
   Number of active neurons: 9
 >> iter 31000, loss: 0.020510
 >> iter 32000, loss: 0.017259
 >> iter 33000, loss: 0.016105
 >> iter 34000, loss: 0.015476
 >> iter 35000, loss: 0.015233
 >> iter 36000, loss: 0.014891
 >> iter 37000, loss: 0.014734
 >> iter 38000, loss: 0.014503
 >> iter 39000, loss: 0.014361
 >> iter 40000, loss: 0.014223
   Number of active neurons: 9
 >> iter 41000, loss: 0.242488
 >> iter 42000, loss: 0.099963
 >> iter 43000, loss: 0.046870
 >> iter 44000, loss: 0.027017
 >> iter 45000, loss: 0.019690
 >> iter 46000, loss: 0.016815
 >> iter 47000, loss: 0.015808
 >> iter 48000, loss: 0.015274
 >> iter 49000, loss: 0.015014
 >> iter 50000, loss: 0.014905
   Number of active neurons: 8
 >> iter 51000, loss: 0.014832
 >> iter 52000, loss: 0.014705
 >> iter 53000, loss: 0.212892
 >> iter 54000, loss: 0.088594
 >> iter 55000, loss: 0.045229
 >> iter 56000, loss: 0.025132
 >> iter 57000, loss: 0.018121
 >> iter 58000, loss: 0.015686
 >> iter 59000, loss: 0.015016
 >> iter 60000, loss: 0.014582
   Number of active neurons: 8
 >> iter 61000, loss: 0.083913
 >> iter 62000, loss: 0.040215
 >> iter 63000, loss: 0.024321
 >> iter 64000, loss: 0.018318
 >> iter 65000, loss: 0.139465
 >> iter 66000, loss: 0.148753
 >> iter 67000, loss: 0.140622
 >> iter 68000, loss: 0.082170
 >> iter 69000, loss: 0.039349
 >> iter 70000, loss: 0.023149
   Number of active neurons: 8
 >> iter 71000, loss: 0.041515
 >> iter 72000, loss: 0.023736
 >> iter 73000, loss: 0.017367
 >> iter 74000, loss: 0.015094
 >> iter 75000, loss: 0.014535
 >> iter 76000, loss: 0.014216
 >> iter 77000, loss: 0.091316
 >> iter 78000, loss: 0.042390
 >> iter 79000, loss: 0.024517
 >> iter 80000, loss: 0.017946
   Number of active neurons: 8
 >> iter 81000, loss: 0.015748
 >> iter 82000, loss: 0.014761
 >> iter 83000, loss: 0.177681
 >> iter 84000, loss: 0.075732
 >> iter 85000, loss: 0.037294
 >> iter 86000, loss: 0.022842
 >> iter 87000, loss: 0.017607
 >> iter 88000, loss: 0.015477
 >> iter 89000, loss: 0.014831
 >> iter 90000, loss: 0.014398
   Number of active neurons: 8
 >> iter 91000, loss: 0.377278
 >> iter 92000, loss: 0.150251
 >> iter 93000, loss: 0.065252
 >> iter 94000, loss: 0.033465
 >> iter 95000, loss: 0.021841
 >> iter 96000, loss: 0.017321
 >> iter 97000, loss: 0.015697
 >> iter 98000, loss: 0.014795
 >> iter 99000, loss: 0.014519
 >> iter 100000, loss: 0.014121
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 16.118925405
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.048061
 >> iter 2000, loss: 7.049882
 >> iter 3000, loss: 2.707794
 >> iter 4000, loss: 1.036087
 >> iter 5000, loss: 0.398285
 >> iter 6000, loss: 0.160390
 >> iter 7000, loss: 0.089031
 >> iter 8000, loss: 0.077461
 >> iter 9000, loss: 0.148447
 >> iter 10000, loss: 0.090512
   Number of active neurons: 9
 >> iter 11000, loss: 0.050920
 >> iter 12000, loss: 0.038546
 >> iter 13000, loss: 0.089769
 >> iter 14000, loss: 0.042514
 >> iter 15000, loss: 0.137297
 >> iter 16000, loss: 0.060149
 >> iter 17000, loss: 0.051621
 >> iter 18000, loss: 0.029996
 >> iter 19000, loss: 0.023150
 >> iter 20000, loss: 0.017149
   Number of active neurons: 9
 >> iter 21000, loss: 0.023243
 >> iter 22000, loss: 0.017495
 >> iter 23000, loss: 0.016130
 >> iter 24000, loss: 0.074982
 >> iter 25000, loss: 0.483654
 >> iter 26000, loss: 0.225890
 >> iter 27000, loss: 0.095168
 >> iter 28000, loss: 0.194801
 >> iter 29000, loss: 0.245038
 >> iter 30000, loss: 0.104726
   Number of active neurons: 9
 >> iter 31000, loss: 0.050658
 >> iter 32000, loss: 0.029538
 >> iter 33000, loss: 0.021462
 >> iter 34000, loss: 0.017929
 >> iter 35000, loss: 0.016608
 >> iter 36000, loss: 0.015704
 >> iter 37000, loss: 0.015514
 >> iter 38000, loss: 0.015052
 >> iter 39000, loss: 0.015023
 >> iter 40000, loss: 0.276667
   Number of active neurons: 9
 >> iter 41000, loss: 0.160522
 >> iter 42000, loss: 0.070151
 >> iter 43000, loss: 0.035655
 >> iter 44000, loss: 0.022265
 >> iter 45000, loss: 0.121778
 >> iter 46000, loss: 0.101141
 >> iter 47000, loss: 0.047186
 >> iter 48000, loss: 0.026491
 >> iter 49000, loss: 0.539521
 >> iter 50000, loss: 0.219891
   Number of active neurons: 9
 >> iter 51000, loss: 0.095267
 >> iter 52000, loss: 0.044835
 >> iter 53000, loss: 0.039615
 >> iter 54000, loss: 0.024293
 >> iter 55000, loss: 0.018026
 >> iter 56000, loss: 0.015381
 >> iter 57000, loss: 0.234421
 >> iter 58000, loss: 0.099707
 >> iter 59000, loss: 0.049669
 >> iter 60000, loss: 0.027617
   Number of active neurons: 8
 >> iter 61000, loss: 0.097195
 >> iter 62000, loss: 0.312041
 >> iter 63000, loss: 0.129835
 >> iter 64000, loss: 0.061809
 >> iter 65000, loss: 0.033455
 >> iter 66000, loss: 0.021504
 >> iter 67000, loss: 0.040180
 >> iter 68000, loss: 0.023403
 >> iter 69000, loss: 0.019977
 >> iter 70000, loss: 0.015689
   Number of active neurons: 8
 >> iter 71000, loss: 0.143768
 >> iter 72000, loss: 0.063595
 >> iter 73000, loss: 0.047177
 >> iter 74000, loss: 0.135699
 >> iter 75000, loss: 0.064898
 >> iter 76000, loss: 0.033479
 >> iter 77000, loss: 0.021296
 >> iter 78000, loss: 0.025450
 >> iter 79000, loss: 0.102856
 >> iter 80000, loss: 0.047012
   Number of active neurons: 8
 >> iter 81000, loss: 0.073096
 >> iter 82000, loss: 0.037047
 >> iter 83000, loss: 0.226343
 >> iter 84000, loss: 0.101544
 >> iter 85000, loss: 0.050908
 >> iter 86000, loss: 0.028909
 >> iter 87000, loss: 0.063654
 >> iter 88000, loss: 0.033179
 >> iter 89000, loss: 0.042324
 >> iter 90000, loss: 0.025627
   Number of active neurons: 8
 >> iter 91000, loss: 0.018087
 >> iter 92000, loss: 0.023044
 >> iter 93000, loss: 0.496277
 >> iter 94000, loss: 0.218586
 >> iter 95000, loss: 0.091521
 >> iter 96000, loss: 0.043568
 >> iter 97000, loss: 0.025282
 >> iter 98000, loss: 0.018633
 >> iter 99000, loss: 0.134281
 >> iter 100000, loss: 0.184015
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 16.3789080728
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.141586
 >> iter 2000, loss: 9.914972
 >> iter 3000, loss: 3.845530
 >> iter 4000, loss: 1.470066
 >> iter 5000, loss: 0.653513
 >> iter 6000, loss: 0.279073
 >> iter 7000, loss: 0.239741
 >> iter 8000, loss: 0.123455
 >> iter 9000, loss: 0.126959
 >> iter 10000, loss: 0.058006
   Number of active neurons: 9
 >> iter 11000, loss: 0.030882
 >> iter 12000, loss: 0.020596
 >> iter 13000, loss: 0.149054
 >> iter 14000, loss: 0.064854
 >> iter 15000, loss: 0.073472
 >> iter 16000, loss: 0.037028
 >> iter 17000, loss: 0.071959
 >> iter 18000, loss: 0.036253
 >> iter 19000, loss: 0.022586
 >> iter 20000, loss: 0.039126
   Number of active neurons: 9
 >> iter 21000, loss: 0.023766
 >> iter 22000, loss: 0.017651
 >> iter 23000, loss: 0.150704
 >> iter 24000, loss: 0.065867
 >> iter 25000, loss: 0.033599
 >> iter 26000, loss: 0.106897
 >> iter 27000, loss: 0.048444
 >> iter 28000, loss: 0.026239
 >> iter 29000, loss: 0.018239
 >> iter 30000, loss: 0.046140
   Number of active neurons: 9
 >> iter 31000, loss: 0.024806
 >> iter 32000, loss: 0.016787
 >> iter 33000, loss: 0.112622
 >> iter 34000, loss: 0.049453
 >> iter 35000, loss: 0.026202
 >> iter 36000, loss: 0.104857
 >> iter 37000, loss: 0.047612
 >> iter 38000, loss: 0.026045
 >> iter 39000, loss: 0.018158
 >> iter 40000, loss: 0.015081
   Number of active neurons: 9
 >> iter 41000, loss: 0.120630
 >> iter 42000, loss: 0.053080
 >> iter 43000, loss: 0.028081
 >> iter 44000, loss: 0.018874
 >> iter 45000, loss: 0.015360
 >> iter 46000, loss: 0.059326
 >> iter 47000, loss: 0.029450
 >> iter 48000, loss: 0.018708
 >> iter 49000, loss: 0.015035
 >> iter 50000, loss: 0.078852
   Number of active neurons: 7
 >> iter 51000, loss: 0.037276
 >> iter 52000, loss: 0.021965
 >> iter 53000, loss: 0.016585
 >> iter 54000, loss: 0.082530
 >> iter 55000, loss: 0.037879
 >> iter 56000, loss: 0.021505
 >> iter 57000, loss: 0.015728
 >> iter 58000, loss: 0.020638
 >> iter 59000, loss: 0.024199
 >> iter 60000, loss: 0.016651
   Number of active neurons: 7
 >> iter 61000, loss: 0.021786
 >> iter 62000, loss: 0.015533
 >> iter 63000, loss: 0.019893
 >> iter 64000, loss: 0.014554
 >> iter 65000, loss: 0.076187
 >> iter 66000, loss: 0.035134
 >> iter 67000, loss: 0.044220
 >> iter 68000, loss: 0.023276
 >> iter 69000, loss: 0.015681
 >> iter 70000, loss: 0.012995
   Number of active neurons: 7
 >> iter 71000, loss: 0.012308
 >> iter 72000, loss: 0.063968
 >> iter 73000, loss: 0.031185
 >> iter 74000, loss: 0.104862
 >> iter 75000, loss: 0.046471
 >> iter 76000, loss: 0.024548
 >> iter 77000, loss: 0.016612
 >> iter 78000, loss: 0.013237
 >> iter 79000, loss: 0.084424
 >> iter 80000, loss: 0.039331
   Number of active neurons: 7
 >> iter 81000, loss: 0.023101
 >> iter 82000, loss: 0.015991
 >> iter 83000, loss: 0.013461
 >> iter 84000, loss: 0.012023
 >> iter 85000, loss: 0.060276
 >> iter 86000, loss: 0.029284
 >> iter 87000, loss: 0.107729
 >> iter 88000, loss: 0.047095
 >> iter 89000, loss: 0.024489
 >> iter 90000, loss: 0.016044
   Number of active neurons: 6
 >> iter 91000, loss: 0.105733
 >> iter 92000, loss: 0.047042
 >> iter 93000, loss: 0.025190
 >> iter 94000, loss: 0.091674
 >> iter 95000, loss: 0.080123
 >> iter 96000, loss: 0.037739
 >> iter 97000, loss: 0.080156
 >> iter 98000, loss: 0.037501
 >> iter 99000, loss: 0.037901
 >> iter 100000, loss: 0.021463
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 16.065595627
   - Test - B: 14.0323978401
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.472160
 >> iter 2000, loss: 8.151138
 >> iter 3000, loss: 3.140235
 >> iter 4000, loss: 1.175989
 >> iter 5000, loss: 0.471588
 >> iter 6000, loss: 0.186389
 >> iter 7000, loss: 0.102575
 >> iter 8000, loss: 0.048668
 >> iter 9000, loss: 0.049346
 >> iter 10000, loss: 0.287408
   Number of active neurons: 10
 >> iter 11000, loss: 0.120830
 >> iter 12000, loss: 0.062109
 >> iter 13000, loss: 0.129762
 >> iter 14000, loss: 0.062158
 >> iter 15000, loss: 0.129089
 >> iter 16000, loss: 0.058797
 >> iter 17000, loss: 0.156399
 >> iter 18000, loss: 0.069746
 >> iter 19000, loss: 0.155675
 >> iter 20000, loss: 0.069280
   Number of active neurons: 10
 >> iter 21000, loss: 0.079893
 >> iter 22000, loss: 0.039820
 >> iter 23000, loss: 0.110867
 >> iter 24000, loss: 0.066482
 >> iter 25000, loss: 0.034398
 >> iter 26000, loss: 0.022338
 >> iter 27000, loss: 0.532313
 >> iter 28000, loss: 0.373715
 >> iter 29000, loss: 0.152636
 >> iter 30000, loss: 0.068418
   Number of active neurons: 9
 >> iter 31000, loss: 0.035802
 >> iter 32000, loss: 0.022938
 >> iter 33000, loss: 0.073968
 >> iter 34000, loss: 0.136846
 >> iter 35000, loss: 0.094822
 >> iter 36000, loss: 0.044609
 >> iter 37000, loss: 0.068301
 >> iter 38000, loss: 0.034631
 >> iter 39000, loss: 0.065194
 >> iter 40000, loss: 0.033098
   Number of active neurons: 6
 >> iter 41000, loss: 0.674025
 >> iter 42000, loss: 0.500341
 >> iter 43000, loss: 0.205540
 >> iter 44000, loss: 0.089115
 >> iter 45000, loss: 0.539599
 >> iter 46000, loss: 0.298212
 >> iter 47000, loss: 0.263703
 >> iter 48000, loss: 0.113533
 >> iter 49000, loss: 0.144847
 >> iter 50000, loss: 0.066000
   Number of active neurons: 6
 >> iter 51000, loss: 0.550854
 >> iter 52000, loss: 0.258855
 >> iter 53000, loss: 0.202266
 >> iter 54000, loss: 0.088486
 >> iter 55000, loss: 0.132545
 >> iter 56000, loss: 0.093317
 >> iter 57000, loss: 0.066766
 >> iter 58000, loss: 0.040280
 >> iter 59000, loss: 0.147020
 >> iter 60000, loss: 0.158336
   Number of active neurons: 6
 >> iter 61000, loss: 0.089039
 >> iter 62000, loss: 0.263443
 >> iter 63000, loss: 0.199180
 >> iter 64000, loss: 0.116858
 >> iter 65000, loss: 0.136930
 >> iter 66000, loss: 0.079766
 >> iter 67000, loss: 0.184335
 >> iter 68000, loss: 0.081875
 >> iter 69000, loss: 0.197660
 >> iter 70000, loss: 0.086576
   Number of active neurons: 6
 >> iter 71000, loss: 0.170451
 >> iter 72000, loss: 0.076626
 >> iter 73000, loss: 0.059740
 >> iter 74000, loss: 0.087604
 >> iter 75000, loss: 0.084871
 >> iter 76000, loss: 0.183152
 >> iter 77000, loss: 0.221066
 >> iter 78000, loss: 0.152094
 >> iter 79000, loss: 0.279112
 >> iter 80000, loss: 0.134496
   Number of active neurons: 6
 >> iter 81000, loss: 0.066348
 >> iter 82000, loss: 0.034510
 >> iter 83000, loss: 0.097976
 >> iter 84000, loss: 0.046211
 >> iter 85000, loss: 0.212023
 >> iter 86000, loss: 0.089894
 >> iter 87000, loss: 0.047412
 >> iter 88000, loss: 0.045673
 >> iter 89000, loss: 0.053582
 >> iter 90000, loss: 0.661520
   Number of active neurons: 6
 >> iter 91000, loss: 0.373893
 >> iter 92000, loss: 0.153565
 >> iter 93000, loss: 0.068755
 >> iter 94000, loss: 0.035717
 >> iter 95000, loss: 0.654398
 >> iter 96000, loss: 0.381455
 >> iter 97000, loss: 0.161202
 >> iter 98000, loss: 0.072133
 >> iter 99000, loss: 0.038116
 >> iter 100000, loss: 0.077616
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 17.4655022998
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.555287
 >> iter 2000, loss: 7.631118
 >> iter 3000, loss: 2.923988
 >> iter 4000, loss: 1.098510
 >> iter 5000, loss: 0.447211
 >> iter 6000, loss: 0.178702
 >> iter 7000, loss: 0.114977
 >> iter 8000, loss: 0.122076
 >> iter 9000, loss: 0.184058
 >> iter 10000, loss: 0.103413
   Number of active neurons: 10
 >> iter 11000, loss: 0.224877
 >> iter 12000, loss: 0.126767
 >> iter 13000, loss: 0.059287
 >> iter 14000, loss: 0.031852
 >> iter 15000, loss: 0.089264
 >> iter 16000, loss: 0.044354
 >> iter 17000, loss: 0.062055
 >> iter 18000, loss: 0.068561
 >> iter 19000, loss: 0.068388
 >> iter 20000, loss: 0.038721
   Number of active neurons: 9
 >> iter 21000, loss: 0.139503
 >> iter 22000, loss: 0.066372
 >> iter 23000, loss: 0.056580
 >> iter 24000, loss: 0.053578
 >> iter 25000, loss: 0.324193
 >> iter 26000, loss: 0.252378
 >> iter 27000, loss: 0.107146
 >> iter 28000, loss: 0.087435
 >> iter 29000, loss: 0.068946
 >> iter 30000, loss: 0.035313
   Number of active neurons: 7
 >> iter 31000, loss: 0.038116
 >> iter 32000, loss: 0.035061
 >> iter 33000, loss: 0.102507
 >> iter 34000, loss: 0.064590
 >> iter 35000, loss: 0.036918
 >> iter 36000, loss: 0.022224
 >> iter 37000, loss: 0.106836
 >> iter 38000, loss: 0.049452
 >> iter 39000, loss: 0.163090
 >> iter 40000, loss: 0.071876
   Number of active neurons: 7
 >> iter 41000, loss: 0.061284
 >> iter 42000, loss: 0.031978
 >> iter 43000, loss: 0.036548
 >> iter 44000, loss: 0.039562
 >> iter 45000, loss: 0.089774
 >> iter 46000, loss: 0.042568
 >> iter 47000, loss: 0.026568
 >> iter 48000, loss: 0.017556
 >> iter 49000, loss: 0.048016
 >> iter 50000, loss: 0.027054
   Number of active neurons: 7
 >> iter 51000, loss: 0.054031
 >> iter 52000, loss: 0.027856
 >> iter 53000, loss: 0.185791
 >> iter 54000, loss: 0.099322
 >> iter 55000, loss: 0.102466
 >> iter 56000, loss: 0.047966
 >> iter 57000, loss: 0.043374
 >> iter 58000, loss: 0.025543
 >> iter 59000, loss: 0.051685
 >> iter 60000, loss: 0.027885
   Number of active neurons: 7
 >> iter 61000, loss: 0.062820
 >> iter 62000, loss: 0.032000
 >> iter 63000, loss: 0.081919
 >> iter 64000, loss: 0.039819
 >> iter 65000, loss: 0.078667
 >> iter 66000, loss: 0.328917
 >> iter 67000, loss: 0.179970
 >> iter 68000, loss: 0.078064
 >> iter 69000, loss: 0.226953
 >> iter 70000, loss: 0.096757
   Number of active neurons: 7
 >> iter 71000, loss: 0.046553
 >> iter 72000, loss: 0.027518
 >> iter 73000, loss: 0.019580
 >> iter 74000, loss: 0.076472
 >> iter 75000, loss: 0.137776
 >> iter 76000, loss: 0.060886
 >> iter 77000, loss: 0.031600
 >> iter 78000, loss: 0.062493
 >> iter 79000, loss: 0.031905
 >> iter 80000, loss: 0.053223
   Number of active neurons: 7
 >> iter 81000, loss: 0.027939
 >> iter 82000, loss: 0.164447
 >> iter 83000, loss: 0.100466
 >> iter 84000, loss: 0.047619
 >> iter 85000, loss: 0.065708
 >> iter 86000, loss: 0.033770
 >> iter 87000, loss: 0.127780
 >> iter 88000, loss: 0.057103
 >> iter 89000, loss: 0.110837
 >> iter 90000, loss: 0.051735
   Number of active neurons: 6
 >> iter 91000, loss: 0.207081
 >> iter 92000, loss: 0.150686
 >> iter 93000, loss: 0.067283
 >> iter 94000, loss: 0.036032
 >> iter 95000, loss: 0.022272
 >> iter 96000, loss: 0.078387
 >> iter 97000, loss: 0.037635
 >> iter 98000, loss: 0.075972
 >> iter 99000, loss: 0.036992
 >> iter 100000, loss: 0.048716
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0149992500375
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.429494
 >> iter 2000, loss: 7.910577
 >> iter 3000, loss: 3.201488
 >> iter 4000, loss: 1.201107
 >> iter 5000, loss: 0.544085
 >> iter 6000, loss: 0.297358
 >> iter 7000, loss: 0.180392
 >> iter 8000, loss: 0.078569
 >> iter 9000, loss: 0.075341
 >> iter 10000, loss: 0.052806
   Number of active neurons: 8
 >> iter 11000, loss: 0.250238
 >> iter 12000, loss: 0.153078
 >> iter 13000, loss: 0.069219
 >> iter 14000, loss: 0.036070
 >> iter 15000, loss: 0.186519
 >> iter 16000, loss: 0.082096
 >> iter 17000, loss: 0.182640
 >> iter 18000, loss: 0.084130
 >> iter 19000, loss: 0.176077
 >> iter 20000, loss: 0.078675
   Number of active neurons: 8
 >> iter 21000, loss: 0.053626
 >> iter 22000, loss: 0.029387
 >> iter 23000, loss: 0.113738
 >> iter 24000, loss: 0.083177
 >> iter 25000, loss: 0.103190
 >> iter 26000, loss: 0.048962
 >> iter 27000, loss: 0.129945
 >> iter 28000, loss: 0.071385
 >> iter 29000, loss: 0.374511
 >> iter 30000, loss: 0.217912
   Number of active neurons: 9
 >> iter 31000, loss: 0.139135
 >> iter 32000, loss: 0.217604
 >> iter 33000, loss: 0.101908
 >> iter 34000, loss: 0.047696
 >> iter 35000, loss: 0.271731
 >> iter 36000, loss: 0.115745
 >> iter 37000, loss: 0.076034
 >> iter 38000, loss: 0.059807
 >> iter 39000, loss: 0.058446
 >> iter 40000, loss: 0.034124
   Number of active neurons: 8
 >> iter 41000, loss: 0.051681
 >> iter 42000, loss: 0.131653
 >> iter 43000, loss: 0.058827
 >> iter 44000, loss: 0.120982
 >> iter 45000, loss: 0.160169
 >> iter 46000, loss: 0.070274
 >> iter 47000, loss: 0.072514
 >> iter 48000, loss: 0.036258
 >> iter 49000, loss: 0.230857
 >> iter 50000, loss: 0.097277
   Number of active neurons: 8
 >> iter 51000, loss: 0.072423
 >> iter 52000, loss: 0.165859
 >> iter 53000, loss: 0.090224
 >> iter 54000, loss: 0.043566
 >> iter 55000, loss: 0.191094
 >> iter 56000, loss: 0.083252
 >> iter 57000, loss: 0.195295
 >> iter 58000, loss: 0.107586
 >> iter 59000, loss: 0.253016
 >> iter 60000, loss: 0.106937
   Number of active neurons: 8
 >> iter 61000, loss: 0.193169
 >> iter 62000, loss: 0.083536
 >> iter 63000, loss: 0.113946
 >> iter 64000, loss: 0.052442
 >> iter 65000, loss: 0.112364
 >> iter 66000, loss: 0.051273
 >> iter 67000, loss: 0.028038
 >> iter 68000, loss: 0.102732
 >> iter 69000, loss: 0.046891
 >> iter 70000, loss: 0.025550
   Number of active neurons: 7
 >> iter 71000, loss: 0.188798
 >> iter 72000, loss: 0.080380
 >> iter 73000, loss: 0.039069
 >> iter 74000, loss: 0.023195
 >> iter 75000, loss: 0.098005
 >> iter 76000, loss: 0.044979
 >> iter 77000, loss: 0.105708
 >> iter 78000, loss: 0.047489
 >> iter 79000, loss: 0.075547
 >> iter 80000, loss: 0.040884
   Number of active neurons: 7
 >> iter 81000, loss: 0.138872
 >> iter 82000, loss: 0.089475
 >> iter 83000, loss: 0.042316
 >> iter 84000, loss: 0.087195
 >> iter 85000, loss: 0.062754
 >> iter 86000, loss: 0.032229
 >> iter 87000, loss: 0.096780
 >> iter 88000, loss: 0.196956
 >> iter 89000, loss: 0.165455
 >> iter 90000, loss: 0.071398
   Number of active neurons: 7
 >> iter 91000, loss: 0.035333
 >> iter 92000, loss: 0.021772
 >> iter 93000, loss: 0.244477
 >> iter 94000, loss: 0.102104
 >> iter 95000, loss: 0.047229
 >> iter 96000, loss: 0.026084
 >> iter 97000, loss: 0.114516
 >> iter 98000, loss: 0.357953
 >> iter 99000, loss: 0.384351
 >> iter 100000, loss: 0.161047
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.00599988000241
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 22.0051996534
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.102795
 >> iter 2000, loss: 7.582155
 >> iter 3000, loss: 3.007228
 >> iter 4000, loss: 1.135314
 >> iter 5000, loss: 0.725762
 >> iter 6000, loss: 0.285843
 >> iter 7000, loss: 0.330979
 >> iter 8000, loss: 0.135112
 >> iter 9000, loss: 0.113835
 >> iter 10000, loss: 0.090533
   Number of active neurons: 9
 >> iter 11000, loss: 0.078756
 >> iter 12000, loss: 0.335517
 >> iter 13000, loss: 0.190644
 >> iter 14000, loss: 0.113708
 >> iter 15000, loss: 0.197272
 >> iter 16000, loss: 0.086296
 >> iter 17000, loss: 0.150175
 >> iter 18000, loss: 0.086540
 >> iter 19000, loss: 0.049643
 >> iter 20000, loss: 0.142209
   Number of active neurons: 9
 >> iter 21000, loss: 0.219570
 >> iter 22000, loss: 0.157224
 >> iter 23000, loss: 0.070364
 >> iter 24000, loss: 0.035421
 >> iter 25000, loss: 0.095951
 >> iter 26000, loss: 0.053574
 >> iter 27000, loss: 0.146125
 >> iter 28000, loss: 0.065567
 >> iter 29000, loss: 0.062192
 >> iter 30000, loss: 0.104843
   Number of active neurons: 9
 >> iter 31000, loss: 0.073606
 >> iter 32000, loss: 0.036573
 >> iter 33000, loss: 0.103414
 >> iter 34000, loss: 0.047539
 >> iter 35000, loss: 0.089031
 >> iter 36000, loss: 0.101967
 >> iter 37000, loss: 0.227136
 >> iter 38000, loss: 0.238214
 >> iter 39000, loss: 0.203420
 >> iter 40000, loss: 0.113554
   Number of active neurons: 9
 >> iter 41000, loss: 0.053352
 >> iter 42000, loss: 0.116905
 >> iter 43000, loss: 0.055052
 >> iter 44000, loss: 0.139052
 >> iter 45000, loss: 0.167140
 >> iter 46000, loss: 0.300307
 >> iter 47000, loss: 0.139304
 >> iter 48000, loss: 0.063378
 >> iter 49000, loss: 0.051776
 >> iter 50000, loss: 0.101885
   Number of active neurons: 9
 >> iter 51000, loss: 0.048559
 >> iter 52000, loss: 0.059990
 >> iter 53000, loss: 0.099110
 >> iter 54000, loss: 0.092771
 >> iter 55000, loss: 0.061108
 >> iter 56000, loss: 0.073230
 >> iter 57000, loss: 0.037679
 >> iter 58000, loss: 0.085871
 >> iter 59000, loss: 0.041186
 >> iter 60000, loss: 0.109330
   Number of active neurons: 8
 >> iter 61000, loss: 0.050566
 >> iter 62000, loss: 0.083872
 >> iter 63000, loss: 0.041354
 >> iter 64000, loss: 0.227598
 >> iter 65000, loss: 0.112550
 >> iter 66000, loss: 0.051741
 >> iter 67000, loss: 0.028314
 >> iter 68000, loss: 0.118640
 >> iter 69000, loss: 0.054739
 >> iter 70000, loss: 0.056121
   Number of active neurons: 7
 >> iter 71000, loss: 0.030365
 >> iter 72000, loss: 0.081565
 >> iter 73000, loss: 0.086113
 >> iter 74000, loss: 0.098131
 >> iter 75000, loss: 0.208274
 >> iter 76000, loss: 0.090565
 >> iter 77000, loss: 0.074697
 >> iter 78000, loss: 0.273298
 >> iter 79000, loss: 0.115763
 >> iter 80000, loss: 0.053556
   Number of active neurons: 7
 >> iter 81000, loss: 0.310127
 >> iter 82000, loss: 0.130934
 >> iter 83000, loss: 0.076903
 >> iter 84000, loss: 0.064448
 >> iter 85000, loss: 0.044501
 >> iter 86000, loss: 0.081448
 >> iter 87000, loss: 0.078881
 >> iter 88000, loss: 0.065660
 >> iter 89000, loss: 0.047607
 >> iter 90000, loss: 0.025412
   Number of active neurons: 6
 >> iter 91000, loss: 0.138402
 >> iter 92000, loss: 0.185250
 >> iter 93000, loss: 0.079995
 >> iter 94000, loss: 0.072114
 >> iter 95000, loss: 0.036700
 >> iter 96000, loss: 0.122846
 >> iter 97000, loss: 0.171212
 >> iter 98000, loss: 0.078051
 >> iter 99000, loss: 0.108620
 >> iter 100000, loss: 0.055424
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0559988800224
   - Test - Long: 0.01999900005
   - Test - Big: 0.0709992900071
   - Test - A: 0.0
   - Test - B: 21.0452636491
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.067350
 >> iter 2000, loss: 7.634530
 >> iter 3000, loss: 2.872379
 >> iter 4000, loss: 1.095770
 >> iter 5000, loss: 0.417861
 >> iter 6000, loss: 0.209702
 >> iter 7000, loss: 0.089748
 >> iter 8000, loss: 0.056766
 >> iter 9000, loss: 0.032079
 >> iter 10000, loss: 0.036037
   Number of active neurons: 9
 >> iter 11000, loss: 0.145441
 >> iter 12000, loss: 0.066223
 >> iter 13000, loss: 0.138613
 >> iter 14000, loss: 0.180252
 >> iter 15000, loss: 0.097793
 >> iter 16000, loss: 0.048474
 >> iter 17000, loss: 0.237180
 >> iter 18000, loss: 0.180831
 >> iter 19000, loss: 0.079859
 >> iter 20000, loss: 0.041842
   Number of active neurons: 9
 >> iter 21000, loss: 0.171930
 >> iter 22000, loss: 0.078490
 >> iter 23000, loss: 0.136199
 >> iter 24000, loss: 0.062889
 >> iter 25000, loss: 0.038875
 >> iter 26000, loss: 0.024775
 >> iter 27000, loss: 0.121418
 >> iter 28000, loss: 0.056310
 >> iter 29000, loss: 0.095184
 >> iter 30000, loss: 0.048340
   Number of active neurons: 9
 >> iter 31000, loss: 0.268712
 >> iter 32000, loss: 0.113063
 >> iter 33000, loss: 0.095637
 >> iter 34000, loss: 0.046038
 >> iter 35000, loss: 0.150758
 >> iter 36000, loss: 0.067630
 >> iter 37000, loss: 0.060015
 >> iter 38000, loss: 0.032178
 >> iter 39000, loss: 0.061095
 >> iter 40000, loss: 0.031650
   Number of active neurons: 9
 >> iter 41000, loss: 0.078680
 >> iter 42000, loss: 0.039290
 >> iter 43000, loss: 0.064939
 >> iter 44000, loss: 0.033251
 >> iter 45000, loss: 0.147980
 >> iter 46000, loss: 0.065653
 >> iter 47000, loss: 0.061347
 >> iter 48000, loss: 0.042124
 >> iter 49000, loss: 0.150210
 >> iter 50000, loss: 0.079084
   Number of active neurons: 9
 >> iter 51000, loss: 0.173713
 >> iter 52000, loss: 0.075465
 >> iter 53000, loss: 0.145591
 >> iter 54000, loss: 0.092315
 >> iter 55000, loss: 0.043882
 >> iter 56000, loss: 0.215665
 >> iter 57000, loss: 0.186035
 >> iter 58000, loss: 0.082176
 >> iter 59000, loss: 0.252197
 >> iter 60000, loss: 0.108271
   Number of active neurons: 9
 >> iter 61000, loss: 0.050706
 >> iter 62000, loss: 0.216767
 >> iter 63000, loss: 0.091474
 >> iter 64000, loss: 0.149977
 >> iter 65000, loss: 0.113824
 >> iter 66000, loss: 0.052607
 >> iter 67000, loss: 0.317302
 >> iter 68000, loss: 0.134785
 >> iter 69000, loss: 0.092830
 >> iter 70000, loss: 0.081624
   Number of active neurons: 9
 >> iter 71000, loss: 0.064498
 >> iter 72000, loss: 0.033012
 >> iter 73000, loss: 0.133168
 >> iter 74000, loss: 0.060013
 >> iter 75000, loss: 0.195213
 >> iter 76000, loss: 0.082973
 >> iter 77000, loss: 0.093974
 >> iter 78000, loss: 0.044807
 >> iter 79000, loss: 0.113061
 >> iter 80000, loss: 0.082874
   Number of active neurons: 9
 >> iter 81000, loss: 0.142955
 >> iter 82000, loss: 0.063146
 >> iter 83000, loss: 0.147959
 >> iter 84000, loss: 0.065061
 >> iter 85000, loss: 0.050727
 >> iter 86000, loss: 0.091704
 >> iter 87000, loss: 0.043882
 >> iter 88000, loss: 0.025332
 >> iter 89000, loss: 0.171151
 >> iter 90000, loss: 0.073883
   Number of active neurons: 8
 >> iter 91000, loss: 0.117844
 >> iter 92000, loss: 0.053472
 >> iter 93000, loss: 0.047545
 >> iter 94000, loss: 0.026459
 >> iter 95000, loss: 0.064357
 >> iter 96000, loss: 0.032061
 >> iter 97000, loss: 0.262619
 >> iter 98000, loss: 0.109030
 >> iter 99000, loss: 0.050305
 >> iter 100000, loss: 0.051249
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 18.4454369709
   - Test - B: 16.8322111859
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.160968
 >> iter 2000, loss: 6.876387
 >> iter 3000, loss: 2.567479
 >> iter 4000, loss: 0.965697
 >> iter 5000, loss: 0.373160
 >> iter 6000, loss: 0.152551
 >> iter 7000, loss: 0.071056
 >> iter 8000, loss: 0.039545
 >> iter 9000, loss: 0.028228
 >> iter 10000, loss: 0.022778
   Number of active neurons: 10
 >> iter 11000, loss: 0.021005
 >> iter 12000, loss: 0.019351
 >> iter 13000, loss: 0.018849
 >> iter 14000, loss: 0.017770
 >> iter 15000, loss: 0.017432
 >> iter 16000, loss: 0.159990
 >> iter 17000, loss: 0.070150
 >> iter 18000, loss: 0.036120
 >> iter 19000, loss: 0.102209
 >> iter 20000, loss: 0.047047
   Number of active neurons: 10
 >> iter 21000, loss: 0.027157
 >> iter 22000, loss: 0.144515
 >> iter 23000, loss: 0.064451
 >> iter 24000, loss: 0.118125
 >> iter 25000, loss: 0.054602
 >> iter 26000, loss: 0.154203
 >> iter 27000, loss: 0.069889
 >> iter 28000, loss: 0.036028
 >> iter 29000, loss: 0.154477
 >> iter 30000, loss: 0.067805
   Number of active neurons: 9
 >> iter 31000, loss: 0.071240
 >> iter 32000, loss: 0.036295
 >> iter 33000, loss: 0.055957
 >> iter 34000, loss: 0.206197
 >> iter 35000, loss: 0.099087
 >> iter 36000, loss: 0.046879
 >> iter 37000, loss: 0.158353
 >> iter 38000, loss: 0.069360
 >> iter 39000, loss: 0.037426
 >> iter 40000, loss: 0.110645
   Number of active neurons: 9
 >> iter 41000, loss: 0.129054
 >> iter 42000, loss: 0.058867
 >> iter 43000, loss: 0.090162
 >> iter 44000, loss: 0.044081
 >> iter 45000, loss: 0.074982
 >> iter 46000, loss: 0.038164
 >> iter 47000, loss: 0.095189
 >> iter 48000, loss: 0.045390
 >> iter 49000, loss: 0.027432
 >> iter 50000, loss: 0.029178
   Number of active neurons: 8
 >> iter 51000, loss: 0.029089
 >> iter 52000, loss: 0.019524
 >> iter 53000, loss: 0.051135
 >> iter 54000, loss: 0.027845
 >> iter 55000, loss: 0.019091
 >> iter 56000, loss: 0.408461
 >> iter 57000, loss: 0.174473
 >> iter 58000, loss: 0.075293
 >> iter 59000, loss: 0.214176
 >> iter 60000, loss: 0.092381
   Number of active neurons: 8
 >> iter 61000, loss: 0.082569
 >> iter 62000, loss: 0.040573
 >> iter 63000, loss: 0.034513
 >> iter 64000, loss: 0.074889
 >> iter 65000, loss: 0.071522
 >> iter 66000, loss: 0.035939
 >> iter 67000, loss: 0.210936
 >> iter 68000, loss: 0.089470
 >> iter 69000, loss: 0.055425
 >> iter 70000, loss: 0.029285
   Number of active neurons: 8
 >> iter 71000, loss: 0.067937
 >> iter 72000, loss: 0.073372
 >> iter 73000, loss: 0.075364
 >> iter 74000, loss: 0.037624
 >> iter 75000, loss: 0.049605
 >> iter 76000, loss: 0.068242
 >> iter 77000, loss: 0.215871
 >> iter 78000, loss: 0.096403
 >> iter 79000, loss: 0.045540
 >> iter 80000, loss: 0.028191
   Number of active neurons: 8
 >> iter 81000, loss: 0.076924
 >> iter 82000, loss: 0.040872
 >> iter 83000, loss: 0.023924
 >> iter 84000, loss: 0.077124
 >> iter 85000, loss: 0.054979
 >> iter 86000, loss: 0.028980
 >> iter 87000, loss: 0.038430
 >> iter 88000, loss: 0.105148
 >> iter 89000, loss: 0.065669
 >> iter 90000, loss: 0.032925
   Number of active neurons: 8
 >> iter 91000, loss: 0.030965
 >> iter 92000, loss: 0.028392
 >> iter 93000, loss: 0.019666
 >> iter 94000, loss: 0.055420
 >> iter 95000, loss: 0.047671
 >> iter 96000, loss: 0.026274
 >> iter 97000, loss: 0.025443
 >> iter 98000, loss: 0.094909
 >> iter 99000, loss: 0.070784
 >> iter 100000, loss: 0.034904
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 17.945470302
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.432222
 >> iter 2000, loss: 8.419625
 >> iter 3000, loss: 3.263718
 >> iter 4000, loss: 1.313089
 >> iter 5000, loss: 0.505241
 >> iter 6000, loss: 0.201650
 >> iter 7000, loss: 0.203543
 >> iter 8000, loss: 0.092287
 >> iter 9000, loss: 0.048094
 >> iter 10000, loss: 0.030457
   Number of active neurons: 9
 >> iter 11000, loss: 0.158070
 >> iter 12000, loss: 0.075856
 >> iter 13000, loss: 0.041595
 >> iter 14000, loss: 0.027656
 >> iter 15000, loss: 0.022771
 >> iter 16000, loss: 0.020213
 >> iter 17000, loss: 0.019819
 >> iter 18000, loss: 0.018934
 >> iter 19000, loss: 0.294371
 >> iter 20000, loss: 0.123861
   Number of active neurons: 9
 >> iter 21000, loss: 0.201163
 >> iter 22000, loss: 0.089424
 >> iter 23000, loss: 0.222611
 >> iter 24000, loss: 0.117816
 >> iter 25000, loss: 0.149339
 >> iter 26000, loss: 0.068962
 >> iter 27000, loss: 0.209756
 >> iter 28000, loss: 0.093429
 >> iter 29000, loss: 0.115165
 >> iter 30000, loss: 0.061335
   Number of active neurons: 9
 >> iter 31000, loss: 0.261833
 >> iter 32000, loss: 0.113895
 >> iter 33000, loss: 0.327283
 >> iter 34000, loss: 0.181656
 >> iter 35000, loss: 0.240958
 >> iter 36000, loss: 0.106882
 >> iter 37000, loss: 0.153287
 >> iter 38000, loss: 0.071029
 >> iter 39000, loss: 0.120204
 >> iter 40000, loss: 0.056876
   Number of active neurons: 9
 >> iter 41000, loss: 0.032815
 >> iter 42000, loss: 0.022851
 >> iter 43000, loss: 0.019839
 >> iter 44000, loss: 0.017770
 >> iter 45000, loss: 0.017335
 >> iter 46000, loss: 0.017100
 >> iter 47000, loss: 0.016324
 >> iter 48000, loss: 0.015869
 >> iter 49000, loss: 0.016167
 >> iter 50000, loss: 0.144766
   Number of active neurons: 8
 >> iter 51000, loss: 0.064174
 >> iter 52000, loss: 0.033737
 >> iter 53000, loss: 0.023039
 >> iter 54000, loss: 0.074884
 >> iter 55000, loss: 0.036976
 >> iter 56000, loss: 0.022841
 >> iter 57000, loss: 0.174999
 >> iter 58000, loss: 0.076999
 >> iter 59000, loss: 0.039925
 >> iter 60000, loss: 0.025586
   Number of active neurons: 8
 >> iter 61000, loss: 0.168373
 >> iter 62000, loss: 0.075142
 >> iter 63000, loss: 0.039549
 >> iter 64000, loss: 0.025777
 >> iter 65000, loss: 0.232073
 >> iter 66000, loss: 0.100814
 >> iter 67000, loss: 0.049972
 >> iter 68000, loss: 0.030010
 >> iter 69000, loss: 0.022389
 >> iter 70000, loss: 0.019042
   Number of active neurons: 6
 >> iter 71000, loss: 0.017781
 >> iter 72000, loss: 0.016904
 >> iter 73000, loss: 0.083848
 >> iter 74000, loss: 0.041866
 >> iter 75000, loss: 0.165227
 >> iter 76000, loss: 0.072230
 >> iter 77000, loss: 0.037740
 >> iter 78000, loss: 0.024498
 >> iter 79000, loss: 0.019924
 >> iter 80000, loss: 0.017919
   Number of active neurons: 6
 >> iter 81000, loss: 0.037308
 >> iter 82000, loss: 0.024420
 >> iter 83000, loss: 0.035389
 >> iter 84000, loss: 0.023698
 >> iter 85000, loss: 0.072054
 >> iter 86000, loss: 0.037095
 >> iter 87000, loss: 0.108717
 >> iter 88000, loss: 0.050945
 >> iter 89000, loss: 0.029511
 >> iter 90000, loss: 0.141091
   Number of active neurons: 6
 >> iter 91000, loss: 0.064025
 >> iter 92000, loss: 0.062480
 >> iter 93000, loss: 0.034199
 >> iter 94000, loss: 0.052052
 >> iter 95000, loss: 0.030927
 >> iter 96000, loss: 0.021351
 >> iter 97000, loss: 0.033979
 >> iter 98000, loss: 0.204459
 >> iter 99000, loss: 0.107516
 >> iter 100000, loss: 0.050871
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0019999600008
   - Test - Long: 0.0249987500625
   - Test - Big: 0.0309996900031
   - Test - A: 0.0
   - Test - B: 22.8584761016
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.344263
 >> iter 2000, loss: 8.262703
 >> iter 3000, loss: 3.151965
 >> iter 4000, loss: 1.179577
 >> iter 5000, loss: 0.475429
 >> iter 6000, loss: 0.199074
 >> iter 7000, loss: 0.109991
 >> iter 8000, loss: 0.052900
 >> iter 9000, loss: 0.167949
 >> iter 10000, loss: 0.077772
   Number of active neurons: 10
 >> iter 11000, loss: 0.059448
 >> iter 12000, loss: 0.033155
 >> iter 13000, loss: 0.093568
 >> iter 14000, loss: 0.048620
 >> iter 15000, loss: 0.093000
 >> iter 16000, loss: 0.047754
 >> iter 17000, loss: 0.181828
 >> iter 18000, loss: 0.080289
 >> iter 19000, loss: 0.058450
 >> iter 20000, loss: 0.033301
   Number of active neurons: 9
 >> iter 21000, loss: 0.134488
 >> iter 22000, loss: 0.089780
 >> iter 23000, loss: 0.080222
 >> iter 24000, loss: 0.043596
 >> iter 25000, loss: 0.026464
 >> iter 26000, loss: 0.047148
 >> iter 27000, loss: 0.102956
 >> iter 28000, loss: 0.049164
 >> iter 29000, loss: 0.040942
 >> iter 30000, loss: 0.025578
   Number of active neurons: 9
 >> iter 31000, loss: 0.097924
 >> iter 32000, loss: 0.048137
 >> iter 33000, loss: 0.040165
 >> iter 34000, loss: 0.088151
 >> iter 35000, loss: 0.112063
 >> iter 36000, loss: 0.054208
 >> iter 37000, loss: 0.047908
 >> iter 38000, loss: 0.026983
 >> iter 39000, loss: 0.094745
 >> iter 40000, loss: 0.045335
   Number of active neurons: 8
 >> iter 41000, loss: 0.117553
 >> iter 42000, loss: 0.192583
 >> iter 43000, loss: 0.149504
 >> iter 44000, loss: 0.067377
 >> iter 45000, loss: 0.108020
 >> iter 46000, loss: 0.052337
 >> iter 47000, loss: 0.116248
 >> iter 48000, loss: 0.140126
 >> iter 49000, loss: 0.062988
 >> iter 50000, loss: 0.032902
   Number of active neurons: 8
 >> iter 51000, loss: 0.206683
 >> iter 52000, loss: 0.095765
 >> iter 53000, loss: 0.105269
 >> iter 54000, loss: 0.049723
 >> iter 55000, loss: 0.248934
 >> iter 56000, loss: 0.105433
 >> iter 57000, loss: 0.049568
 >> iter 58000, loss: 0.028217
 >> iter 59000, loss: 0.068825
 >> iter 60000, loss: 0.035304
   Number of active neurons: 8
 >> iter 61000, loss: 0.102484
 >> iter 62000, loss: 0.047963
 >> iter 63000, loss: 0.096903
 >> iter 64000, loss: 0.046037
 >> iter 65000, loss: 0.026528
 >> iter 66000, loss: 0.032371
 >> iter 67000, loss: 0.149492
 >> iter 68000, loss: 0.065846
 >> iter 69000, loss: 0.033865
 >> iter 70000, loss: 0.021962
   Number of active neurons: 8
 >> iter 71000, loss: 0.017035
 >> iter 72000, loss: 0.084282
 >> iter 73000, loss: 0.040931
 >> iter 74000, loss: 0.024152
 >> iter 75000, loss: 0.017901
 >> iter 76000, loss: 0.102589
 >> iter 77000, loss: 0.117322
 >> iter 78000, loss: 0.071202
 >> iter 79000, loss: 0.035789
 >> iter 80000, loss: 0.021531
   Number of active neurons: 6
 >> iter 81000, loss: 0.016197
 >> iter 82000, loss: 0.013953
 >> iter 83000, loss: 0.013387
 >> iter 84000, loss: 0.058286
 >> iter 85000, loss: 0.030997
 >> iter 86000, loss: 0.019475
 >> iter 87000, loss: 0.093075
 >> iter 88000, loss: 0.042580
 >> iter 89000, loss: 0.024034
 >> iter 90000, loss: 0.016971
   Number of active neurons: 7
 >> iter 91000, loss: 0.022378
 >> iter 92000, loss: 0.016112
 >> iter 93000, loss: 0.014112
 >> iter 94000, loss: 0.016623
 >> iter 95000, loss: 0.290612
 >> iter 96000, loss: 0.204478
 >> iter 97000, loss: 0.087913
 >> iter 98000, loss: 0.041883
 >> iter 99000, loss: 0.024346
 >> iter 100000, loss: 0.017343
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 1.21325244984
   - Test - B: 10.1993200453
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.928099
 >> iter 2000, loss: 6.295742
 >> iter 3000, loss: 2.339712
 >> iter 4000, loss: 0.876062
 >> iter 5000, loss: 0.476125
 >> iter 6000, loss: 0.193599
 >> iter 7000, loss: 0.178252
 >> iter 8000, loss: 0.078372
 >> iter 9000, loss: 0.097047
 >> iter 10000, loss: 0.047282
   Number of active neurons: 9
 >> iter 11000, loss: 0.092190
 >> iter 12000, loss: 0.044750
 >> iter 13000, loss: 0.127991
 >> iter 14000, loss: 0.058787
 >> iter 15000, loss: 0.121907
 >> iter 16000, loss: 0.056861
 >> iter 17000, loss: 0.155209
 >> iter 18000, loss: 0.069004
 >> iter 19000, loss: 0.352403
 >> iter 20000, loss: 0.147512
   Number of active neurons: 9
 >> iter 21000, loss: 0.115564
 >> iter 22000, loss: 0.053858
 >> iter 23000, loss: 0.030353
 >> iter 24000, loss: 0.095728
 >> iter 25000, loss: 0.049786
 >> iter 26000, loss: 0.028302
 >> iter 27000, loss: 0.193906
 >> iter 28000, loss: 0.084040
 >> iter 29000, loss: 0.062344
 >> iter 30000, loss: 0.033746
   Number of active neurons: 9
 >> iter 31000, loss: 0.022463
 >> iter 32000, loss: 0.192784
 >> iter 33000, loss: 0.082385
 >> iter 34000, loss: 0.041608
 >> iter 35000, loss: 0.133891
 >> iter 36000, loss: 0.151053
 >> iter 37000, loss: 0.066905
 >> iter 38000, loss: 0.113906
 >> iter 39000, loss: 0.052146
 >> iter 40000, loss: 0.031721
   Number of active neurons: 7
 >> iter 41000, loss: 0.042119
 >> iter 42000, loss: 0.128716
 >> iter 43000, loss: 0.113685
 >> iter 44000, loss: 0.080520
 >> iter 45000, loss: 0.125649
 >> iter 46000, loss: 0.056316
 >> iter 47000, loss: 0.303130
 >> iter 48000, loss: 0.124436
 >> iter 49000, loss: 0.057057
 >> iter 50000, loss: 0.030257
   Number of active neurons: 8
 >> iter 51000, loss: 0.028859
 >> iter 52000, loss: 0.019471
 >> iter 53000, loss: 0.097922
 >> iter 54000, loss: 0.044780
 >> iter 55000, loss: 0.348562
 >> iter 56000, loss: 0.170478
 >> iter 57000, loss: 0.076230
 >> iter 58000, loss: 0.038754
 >> iter 59000, loss: 0.024938
 >> iter 60000, loss: 0.018290
   Number of active neurons: 7
 >> iter 61000, loss: 0.015166
 >> iter 62000, loss: 0.233158
 >> iter 63000, loss: 0.124929
 >> iter 64000, loss: 0.055198
 >> iter 65000, loss: 0.109118
 >> iter 66000, loss: 0.049415
 >> iter 67000, loss: 0.101802
 >> iter 68000, loss: 0.046204
 >> iter 69000, loss: 0.028896
 >> iter 70000, loss: 0.046820
   Number of active neurons: 6
 >> iter 71000, loss: 0.065241
 >> iter 72000, loss: 0.031820
 >> iter 73000, loss: 0.019392
 >> iter 74000, loss: 0.014287
 >> iter 75000, loss: 0.139524
 >> iter 76000, loss: 0.058747
 >> iter 77000, loss: 0.072085
 >> iter 78000, loss: 0.033899
 >> iter 79000, loss: 0.019774
 >> iter 80000, loss: 0.270725
   Number of active neurons: 6
 >> iter 81000, loss: 0.109457
 >> iter 82000, loss: 0.048948
 >> iter 83000, loss: 0.026326
 >> iter 84000, loss: 0.017576
 >> iter 85000, loss: 0.153257
 >> iter 86000, loss: 0.065982
 >> iter 87000, loss: 0.033098
 >> iter 88000, loss: 0.274781
 >> iter 89000, loss: 0.272375
 >> iter 90000, loss: 0.114208
   Number of active neurons: 6
 >> iter 91000, loss: 0.051327
 >> iter 92000, loss: 0.027438
 >> iter 93000, loss: 0.112898
 >> iter 94000, loss: 0.050644
 >> iter 95000, loss: 0.026794
 >> iter 96000, loss: 0.142402
 >> iter 97000, loss: 0.061146
 >> iter 98000, loss: 0.032037
 >> iter 99000, loss: 0.019460
 >> iter 100000, loss: 0.014533
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 33.9044063729
   - Test - B: 18.4454369709
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.416616
 >> iter 2000, loss: 8.158093
 >> iter 3000, loss: 3.038699
 >> iter 4000, loss: 1.135609
 >> iter 5000, loss: 0.432419
 >> iter 6000, loss: 0.171526
 >> iter 7000, loss: 0.240799
 >> iter 8000, loss: 0.125264
 >> iter 9000, loss: 0.059114
 >> iter 10000, loss: 0.033373
   Number of active neurons: 10
 >> iter 11000, loss: 0.219534
 >> iter 12000, loss: 0.156687
 >> iter 13000, loss: 0.071542
 >> iter 14000, loss: 0.038082
 >> iter 15000, loss: 0.165885
 >> iter 16000, loss: 0.075117
 >> iter 17000, loss: 0.039278
 >> iter 18000, loss: 0.025094
 >> iter 19000, loss: 0.019839
 >> iter 20000, loss: 0.034270
   Number of active neurons: 10
 >> iter 21000, loss: 0.022689
 >> iter 22000, loss: 0.033254
 >> iter 23000, loss: 0.022220
 >> iter 24000, loss: 0.183415
 >> iter 25000, loss: 0.079897
 >> iter 26000, loss: 0.039700
 >> iter 27000, loss: 0.025178
 >> iter 28000, loss: 0.019167
 >> iter 29000, loss: 0.102328
 >> iter 30000, loss: 0.047967
   Number of active neurons: 10
 >> iter 31000, loss: 0.027252
 >> iter 32000, loss: 0.019473
 >> iter 33000, loss: 0.201355
 >> iter 34000, loss: 0.086683
 >> iter 35000, loss: 0.043205
 >> iter 36000, loss: 0.025004
 >> iter 37000, loss: 0.096796
 >> iter 38000, loss: 0.045600
 >> iter 39000, loss: 0.103570
 >> iter 40000, loss: 0.049222
   Number of active neurons: 8
 >> iter 41000, loss: 0.038436
 >> iter 42000, loss: 0.023838
 >> iter 43000, loss: 0.174699
 >> iter 44000, loss: 0.076113
 >> iter 45000, loss: 0.037601
 >> iter 46000, loss: 0.022858
 >> iter 47000, loss: 0.017423
 >> iter 48000, loss: 0.209187
 >> iter 49000, loss: 0.190884
 >> iter 50000, loss: 0.084060
   Number of active neurons: 8
 >> iter 51000, loss: 0.041454
 >> iter 52000, loss: 0.024410
 >> iter 53000, loss: 0.017905
 >> iter 54000, loss: 0.016284
 >> iter 55000, loss: 0.089073
 >> iter 56000, loss: 0.042607
 >> iter 57000, loss: 0.024054
 >> iter 58000, loss: 0.124683
 >> iter 59000, loss: 0.055989
 >> iter 60000, loss: 0.077004
   Number of active neurons: 7
 >> iter 61000, loss: 0.037553
 >> iter 62000, loss: 0.022065
 >> iter 63000, loss: 0.039635
 >> iter 64000, loss: 0.023260
 >> iter 65000, loss: 0.016458
 >> iter 66000, loss: 0.013562
 >> iter 67000, loss: 0.015115
 >> iter 68000, loss: 0.215820
 >> iter 69000, loss: 0.088325
 >> iter 70000, loss: 0.040091
   Number of active neurons: 6
 >> iter 71000, loss: 0.022363
 >> iter 72000, loss: 0.015553
 >> iter 73000, loss: 0.013198
 >> iter 74000, loss: 0.022685
 >> iter 75000, loss: 0.022624
 >> iter 76000, loss: 0.015531
 >> iter 77000, loss: 0.013133
 >> iter 78000, loss: 0.080106
 >> iter 79000, loss: 0.036633
 >> iter 80000, loss: 0.020474
   Number of active neurons: 6
 >> iter 81000, loss: 0.014793
 >> iter 82000, loss: 0.035292
 >> iter 83000, loss: 0.020498
 >> iter 84000, loss: 0.014553
 >> iter 85000, loss: 0.012617
 >> iter 86000, loss: 0.128576
 >> iter 87000, loss: 0.056833
 >> iter 88000, loss: 0.028757
 >> iter 89000, loss: 0.092438
 >> iter 90000, loss: 0.062451
   Number of active neurons: 6
 >> iter 91000, loss: 0.186431
 >> iter 92000, loss: 0.103457
 >> iter 93000, loss: 0.091790
 >> iter 94000, loss: 0.042821
 >> iter 95000, loss: 0.023830
 >> iter 96000, loss: 0.015975
 >> iter 97000, loss: 0.013138
 >> iter 98000, loss: 0.027229
 >> iter 99000, loss: 0.182333
 >> iter 100000, loss: 0.083614
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 27.2848476768
   - Test - B: 12.5324978335

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

