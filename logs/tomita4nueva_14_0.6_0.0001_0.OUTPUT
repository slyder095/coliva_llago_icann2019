 > Problema: tomita4nueva
 > Args:
   - Hidden size: 14
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.373506
 >> iter 2000, loss: 9.541707
 >> iter 3000, loss: 4.389118
 >> iter 4000, loss: 1.936510
 >> iter 5000, loss: 0.924504
 >> iter 6000, loss: 0.925526
 >> iter 7000, loss: 0.672461
 >> iter 8000, loss: 0.427694
 >> iter 9000, loss: 0.370103
 >> iter 10000, loss: 0.444272
   Number of active neurons: 7
 >> iter 11000, loss: 0.496473
 >> iter 12000, loss: 0.299544
 >> iter 13000, loss: 0.337185
 >> iter 14000, loss: 0.516198
 >> iter 15000, loss: 0.338129
 >> iter 16000, loss: 0.334954
 >> iter 17000, loss: 0.563001
 >> iter 18000, loss: 0.478419
 >> iter 19000, loss: 0.490324
 >> iter 20000, loss: 0.303476
   Number of active neurons: 6
 >> iter 21000, loss: 0.246149
 >> iter 22000, loss: 0.262233
 >> iter 23000, loss: 0.194697
 >> iter 24000, loss: 0.326124
 >> iter 25000, loss: 0.239345
 >> iter 26000, loss: 0.247822
 >> iter 27000, loss: 0.384058
 >> iter 28000, loss: 0.293471
 >> iter 29000, loss: 0.193082
 >> iter 30000, loss: 0.240343
   Number of active neurons: 4
 >> iter 31000, loss: 0.133927
 >> iter 32000, loss: 0.140141
 >> iter 33000, loss: 0.437516
 >> iter 34000, loss: 0.483559
 >> iter 35000, loss: 0.240727
 >> iter 36000, loss: 0.281095
 >> iter 37000, loss: 0.300422
 >> iter 38000, loss: 0.358665
 >> iter 39000, loss: 0.320204
 >> iter 40000, loss: 0.311329
   Number of active neurons: 3
 >> iter 41000, loss: 0.158880
 >> iter 42000, loss: 0.326972
 >> iter 43000, loss: 0.326299
 >> iter 44000, loss: 0.220213
 >> iter 45000, loss: 0.272189
 >> iter 46000, loss: 0.160633
 >> iter 47000, loss: 0.354283
 >> iter 48000, loss: 0.321003
 >> iter 49000, loss: 0.322753
 >> iter 50000, loss: 0.231883
   Number of active neurons: 3
 >> iter 51000, loss: 0.262972
 >> iter 52000, loss: 0.169956
 >> iter 53000, loss: 0.130862
 >> iter 54000, loss: 0.138167
 >> iter 55000, loss: 0.212962
 >> iter 56000, loss: 0.323640
 >> iter 57000, loss: 0.168347
 >> iter 58000, loss: 0.184160
 >> iter 59000, loss: 0.126369
 >> iter 60000, loss: 0.139622
   Number of active neurons: 3
 >> iter 61000, loss: 0.267266
 >> iter 62000, loss: 0.149114
 >> iter 63000, loss: 0.345584
 >> iter 64000, loss: 0.269692
 >> iter 65000, loss: 0.199865
 >> iter 66000, loss: 0.196624
 >> iter 67000, loss: 0.252296
 >> iter 68000, loss: 0.364275
 >> iter 69000, loss: 0.323604
 >> iter 70000, loss: 0.181302
   Number of active neurons: 3
 >> iter 71000, loss: 0.163981
 >> iter 72000, loss: 0.219541
 >> iter 73000, loss: 0.269710
 >> iter 74000, loss: 0.296633
 >> iter 75000, loss: 0.559611
 >> iter 76000, loss: 0.313228
 >> iter 77000, loss: 0.449818
 >> iter 78000, loss: 0.246070
 >> iter 79000, loss: 0.268711
 >> iter 80000, loss: 0.363588
   Number of active neurons: 3
 >> iter 81000, loss: 0.295209
 >> iter 82000, loss: 0.439983
 >> iter 83000, loss: 0.279876
 >> iter 84000, loss: 0.205634
 >> iter 85000, loss: 0.281799
 >> iter 86000, loss: 0.213996
 >> iter 87000, loss: 0.181806
 >> iter 88000, loss: 0.160045
 >> iter 89000, loss: 0.298485
 >> iter 90000, loss: 0.192327
   Number of active neurons: 3
 >> iter 91000, loss: 0.235328
 >> iter 92000, loss: 0.461628
 >> iter 93000, loss: 0.370878
 >> iter 94000, loss: 0.275686
 >> iter 95000, loss: 0.208857
 >> iter 96000, loss: 0.167191
 >> iter 97000, loss: 0.245797
 >> iter 98000, loss: 0.166255
 >> iter 99000, loss: 0.139603
 >> iter 100000, loss: 0.231254
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.417566
 >> iter 2000, loss: 8.273529
 >> iter 3000, loss: 3.834188
 >> iter 4000, loss: 1.721899
 >> iter 5000, loss: 0.853499
 >> iter 6000, loss: 0.523220
 >> iter 7000, loss: 0.410800
 >> iter 8000, loss: 0.350222
 >> iter 9000, loss: 0.433487
 >> iter 10000, loss: 0.384774
   Number of active neurons: 7
 >> iter 11000, loss: 0.342037
 >> iter 12000, loss: 0.343413
 >> iter 13000, loss: 0.364397
 >> iter 14000, loss: 0.400592
 >> iter 15000, loss: 0.228217
 >> iter 16000, loss: 0.284915
 >> iter 17000, loss: 0.391157
 >> iter 18000, loss: 0.278425
 >> iter 19000, loss: 0.289647
 >> iter 20000, loss: 0.245782
   Number of active neurons: 6
 >> iter 21000, loss: 0.394568
 >> iter 22000, loss: 0.342309
 >> iter 23000, loss: 0.298531
 >> iter 24000, loss: 0.141689
 >> iter 25000, loss: 0.281536
 >> iter 26000, loss: 0.324187
 >> iter 27000, loss: 0.343368
 >> iter 28000, loss: 0.237130
 >> iter 29000, loss: 0.246928
 >> iter 30000, loss: 0.348965
   Number of active neurons: 4
 >> iter 31000, loss: 0.209356
 >> iter 32000, loss: 0.387803
 >> iter 33000, loss: 0.348902
 >> iter 34000, loss: 0.225056
 >> iter 35000, loss: 0.233189
 >> iter 36000, loss: 0.155342
 >> iter 37000, loss: 0.114964
 >> iter 38000, loss: 0.212663
 >> iter 39000, loss: 0.242190
 >> iter 40000, loss: 0.404434
   Number of active neurons: 4
 >> iter 41000, loss: 0.346348
 >> iter 42000, loss: 0.251018
 >> iter 43000, loss: 0.252961
 >> iter 44000, loss: 0.279421
 >> iter 45000, loss: 0.313484
 >> iter 46000, loss: 0.250617
 >> iter 47000, loss: 0.413229
 >> iter 48000, loss: 0.259323
 >> iter 49000, loss: 0.310955
 >> iter 50000, loss: 0.201611
   Number of active neurons: 4
 >> iter 51000, loss: 0.254753
 >> iter 52000, loss: 0.218788
 >> iter 53000, loss: 0.251122
 >> iter 54000, loss: 0.304105
 >> iter 55000, loss: 0.294229
 >> iter 56000, loss: 0.337603
 >> iter 57000, loss: 0.223783
 >> iter 58000, loss: 0.266852
 >> iter 59000, loss: 0.217610
 >> iter 60000, loss: 0.287531
   Number of active neurons: 4
 >> iter 61000, loss: 0.306266
 >> iter 62000, loss: 0.222861
 >> iter 63000, loss: 0.382255
 >> iter 64000, loss: 0.329270
 >> iter 65000, loss: 0.193873
 >> iter 66000, loss: 0.288823
 >> iter 67000, loss: 0.312850
 >> iter 68000, loss: 0.357024
 >> iter 69000, loss: 0.334797
 >> iter 70000, loss: 0.212837
   Number of active neurons: 4
 >> iter 71000, loss: 0.296991
 >> iter 72000, loss: 0.226613
 >> iter 73000, loss: 0.156063
 >> iter 74000, loss: 0.290669
 >> iter 75000, loss: 0.480715
 >> iter 76000, loss: 0.265443
 >> iter 77000, loss: 0.273973
 >> iter 78000, loss: 0.191162
 >> iter 79000, loss: 0.331499
 >> iter 80000, loss: 0.285018
   Number of active neurons: 4
 >> iter 81000, loss: 0.207454
 >> iter 82000, loss: 0.183219
 >> iter 83000, loss: 0.139204
 >> iter 84000, loss: 0.304073
 >> iter 85000, loss: 0.366299
 >> iter 86000, loss: 0.404929
 >> iter 87000, loss: 0.334853
 >> iter 88000, loss: 0.287679
 >> iter 89000, loss: 0.209129
 >> iter 90000, loss: 0.278218
   Number of active neurons: 4
 >> iter 91000, loss: 0.306010
 >> iter 92000, loss: 0.154203
 >> iter 93000, loss: 0.220308
 >> iter 94000, loss: 0.328056
 >> iter 95000, loss: 0.475028
 >> iter 96000, loss: 0.354932
 >> iter 97000, loss: 0.225904
 >> iter 98000, loss: 0.227340
 >> iter 99000, loss: 0.166213
 >> iter 100000, loss: 0.177544
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.521135
 >> iter 2000, loss: 8.402191
 >> iter 3000, loss: 3.686338
 >> iter 4000, loss: 1.796319
 >> iter 5000, loss: 0.884036
 >> iter 6000, loss: 0.511649
 >> iter 7000, loss: 0.461241
 >> iter 8000, loss: 0.447884
 >> iter 9000, loss: 0.375163
 >> iter 10000, loss: 0.247017
   Number of active neurons: 4
 >> iter 11000, loss: 0.276893
 >> iter 12000, loss: 0.416711
 >> iter 13000, loss: 0.341311
 >> iter 14000, loss: 0.543424
 >> iter 15000, loss: 0.286751
 >> iter 16000, loss: 0.317823
 >> iter 17000, loss: 0.288669
 >> iter 18000, loss: 0.355850
 >> iter 19000, loss: 0.432906
 >> iter 20000, loss: 0.287689
   Number of active neurons: 4
 >> iter 21000, loss: 0.380318
 >> iter 22000, loss: 0.273587
 >> iter 23000, loss: 0.199298
 >> iter 24000, loss: 0.196978
 >> iter 25000, loss: 0.291536
 >> iter 26000, loss: 0.308790
 >> iter 27000, loss: 0.363630
 >> iter 28000, loss: 0.381576
 >> iter 29000, loss: 0.371605
 >> iter 30000, loss: 0.317132
   Number of active neurons: 4
 >> iter 31000, loss: 0.316787
 >> iter 32000, loss: 0.461363
 >> iter 33000, loss: 0.264390
 >> iter 34000, loss: 0.249708
 >> iter 35000, loss: 0.146297
 >> iter 36000, loss: 0.487690
 >> iter 37000, loss: 0.258940
 >> iter 38000, loss: 0.365962
 >> iter 39000, loss: 0.321415
 >> iter 40000, loss: 0.253345
   Number of active neurons: 4
 >> iter 41000, loss: 0.202206
 >> iter 42000, loss: 0.238600
 >> iter 43000, loss: 0.163687
 >> iter 44000, loss: 0.170369
 >> iter 45000, loss: 0.361371
 >> iter 46000, loss: 0.255117
 >> iter 47000, loss: 0.430811
 >> iter 48000, loss: 0.265184
 >> iter 49000, loss: 0.251247
 >> iter 50000, loss: 0.283579
   Number of active neurons: 3
 >> iter 51000, loss: 0.396419
 >> iter 52000, loss: 0.412556
 >> iter 53000, loss: 0.425907
 >> iter 54000, loss: 0.418652
 >> iter 55000, loss: 0.391293
 >> iter 56000, loss: 0.279153
 >> iter 57000, loss: 0.391153
 >> iter 58000, loss: 0.342502
 >> iter 59000, loss: 0.339299
 >> iter 60000, loss: 0.340087
   Number of active neurons: 3
 >> iter 61000, loss: 0.369066
 >> iter 62000, loss: 0.248428
 >> iter 63000, loss: 0.223318
 >> iter 64000, loss: 0.292477
 >> iter 65000, loss: 0.301592
 >> iter 66000, loss: 0.272218
 >> iter 67000, loss: 0.161104
 >> iter 68000, loss: 0.113808
 >> iter 69000, loss: 0.336388
 >> iter 70000, loss: 0.283774
   Number of active neurons: 3
 >> iter 71000, loss: 0.213154
 >> iter 72000, loss: 0.310813
 >> iter 73000, loss: 0.239550
 >> iter 74000, loss: 0.222579
 >> iter 75000, loss: 0.206626
 >> iter 76000, loss: 0.141926
 >> iter 77000, loss: 0.349922
 >> iter 78000, loss: 0.248452
 >> iter 79000, loss: 0.173554
 >> iter 80000, loss: 0.277465
   Number of active neurons: 3
 >> iter 81000, loss: 0.289207
 >> iter 82000, loss: 0.185616
 >> iter 83000, loss: 0.098459
 >> iter 84000, loss: 0.215695
 >> iter 85000, loss: 0.300263
 >> iter 86000, loss: 0.229255
 >> iter 87000, loss: 0.172752
 >> iter 88000, loss: 0.158928
 >> iter 89000, loss: 0.149385
 >> iter 90000, loss: 0.159939
   Number of active neurons: 3
 >> iter 91000, loss: 0.265548
 >> iter 92000, loss: 0.199729
 >> iter 93000, loss: 0.258324
 >> iter 94000, loss: 0.341670
 >> iter 95000, loss: 0.227105
 >> iter 96000, loss: 0.318131
 >> iter 97000, loss: 0.252561
 >> iter 98000, loss: 0.266503
 >> iter 99000, loss: 0.173530
 >> iter 100000, loss: 0.108499
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.781102
 >> iter 2000, loss: 9.428135
 >> iter 3000, loss: 4.318597
 >> iter 4000, loss: 1.926195
 >> iter 5000, loss: 1.216330
 >> iter 6000, loss: 0.642437
 >> iter 7000, loss: 0.425081
 >> iter 8000, loss: 0.442396
 >> iter 9000, loss: 0.332026
 >> iter 10000, loss: 0.302245
   Number of active neurons: 7
 >> iter 11000, loss: 0.239999
 >> iter 12000, loss: 0.365717
 >> iter 13000, loss: 0.478035
 >> iter 14000, loss: 0.317246
 >> iter 15000, loss: 0.343485
 >> iter 16000, loss: 0.285555
 >> iter 17000, loss: 0.297536
 >> iter 18000, loss: 0.220382
 >> iter 19000, loss: 0.160995
 >> iter 20000, loss: 0.185735
   Number of active neurons: 6
 >> iter 21000, loss: 0.226615
 >> iter 22000, loss: 0.259277
 >> iter 23000, loss: 0.435628
 >> iter 24000, loss: 0.410265
 >> iter 25000, loss: 0.219927
 >> iter 26000, loss: 0.145212
 >> iter 27000, loss: 0.368434
 >> iter 28000, loss: 0.340335
 >> iter 29000, loss: 0.256019
 >> iter 30000, loss: 0.129720
   Number of active neurons: 5
 >> iter 31000, loss: 0.242428
 >> iter 32000, loss: 0.238641
 >> iter 33000, loss: 0.245849
 >> iter 34000, loss: 0.210273
 >> iter 35000, loss: 0.156207
 >> iter 36000, loss: 0.174396
 >> iter 37000, loss: 0.110138
 >> iter 38000, loss: 0.259779
 >> iter 39000, loss: 0.184493
 >> iter 40000, loss: 0.233845
   Number of active neurons: 5
 >> iter 41000, loss: 0.441598
 >> iter 42000, loss: 0.284758
 >> iter 43000, loss: 0.290395
 >> iter 44000, loss: 0.300764
 >> iter 45000, loss: 0.253834
 >> iter 46000, loss: 0.349409
 >> iter 47000, loss: 0.198950
 >> iter 48000, loss: 0.250208
 >> iter 49000, loss: 0.203618
 >> iter 50000, loss: 0.270810
   Number of active neurons: 4
 >> iter 51000, loss: 0.239119
 >> iter 52000, loss: 0.265842
 >> iter 53000, loss: 0.321705
 >> iter 54000, loss: 0.176829
 >> iter 55000, loss: 0.348954
 >> iter 56000, loss: 0.225988
 >> iter 57000, loss: 0.261139
 >> iter 58000, loss: 0.238524
 >> iter 59000, loss: 0.278192
 >> iter 60000, loss: 0.289495
   Number of active neurons: 4
 >> iter 61000, loss: 0.322512
 >> iter 62000, loss: 0.352229
 >> iter 63000, loss: 0.197814
 >> iter 64000, loss: 0.324862
 >> iter 65000, loss: 0.200397
 >> iter 66000, loss: 0.225223
 >> iter 67000, loss: 0.225128
 >> iter 68000, loss: 0.248128
 >> iter 69000, loss: 0.232649
 >> iter 70000, loss: 0.340317
   Number of active neurons: 4
 >> iter 71000, loss: 0.316156
 >> iter 72000, loss: 0.248870
 >> iter 73000, loss: 0.302357
 >> iter 74000, loss: 0.307652
 >> iter 75000, loss: 0.194482
 >> iter 76000, loss: 0.152500
 >> iter 77000, loss: 0.149730
 >> iter 78000, loss: 0.374918
 >> iter 79000, loss: 0.380247
 >> iter 80000, loss: 0.391674
   Number of active neurons: 3
 >> iter 81000, loss: 0.245028
 >> iter 82000, loss: 0.243719
 >> iter 83000, loss: 0.232864
 >> iter 84000, loss: 0.179872
 >> iter 85000, loss: 0.391318
 >> iter 86000, loss: 0.504713
 >> iter 87000, loss: 0.276180
 >> iter 88000, loss: 0.314435
 >> iter 89000, loss: 0.279727
 >> iter 90000, loss: 0.244517
   Number of active neurons: 3
 >> iter 91000, loss: 0.250662
 >> iter 92000, loss: 0.254821
 >> iter 93000, loss: 0.255285
 >> iter 94000, loss: 0.242667
 >> iter 95000, loss: 0.313494
 >> iter 96000, loss: 0.151344
 >> iter 97000, loss: 0.252945
 >> iter 98000, loss: 0.237710
 >> iter 99000, loss: 0.279721
 >> iter 100000, loss: 0.195730
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.083945
 >> iter 2000, loss: 9.026979
 >> iter 3000, loss: 4.055304
 >> iter 4000, loss: 1.743576
 >> iter 5000, loss: 1.018035
 >> iter 6000, loss: 0.671933
 >> iter 7000, loss: 0.411447
 >> iter 8000, loss: 0.331248
 >> iter 9000, loss: 0.375589
 >> iter 10000, loss: 0.461571
   Number of active neurons: 5
 >> iter 11000, loss: 0.621055
 >> iter 12000, loss: 0.539934
 >> iter 13000, loss: 0.457245
 >> iter 14000, loss: 0.379259
 >> iter 15000, loss: 0.307111
 >> iter 16000, loss: 0.303737
 >> iter 17000, loss: 0.338601
 >> iter 18000, loss: 0.339229
 >> iter 19000, loss: 0.260610
 >> iter 20000, loss: 0.320823
   Number of active neurons: 4
 >> iter 21000, loss: 0.403734
 >> iter 22000, loss: 0.557312
 >> iter 23000, loss: 0.427265
 >> iter 24000, loss: 0.501259
 >> iter 25000, loss: 0.396930
 >> iter 26000, loss: 0.584600
 >> iter 27000, loss: 0.487915
 >> iter 28000, loss: 0.337683
 >> iter 29000, loss: 0.311480
 >> iter 30000, loss: 0.509316
   Number of active neurons: 4
 >> iter 31000, loss: 0.326504
 >> iter 32000, loss: 0.441141
 >> iter 33000, loss: 0.304486
 >> iter 34000, loss: 0.310282
 >> iter 35000, loss: 0.402669
 >> iter 36000, loss: 0.458423
 >> iter 37000, loss: 0.556480
 >> iter 38000, loss: 0.462405
 >> iter 39000, loss: 0.582876
 >> iter 40000, loss: 0.401993
   Number of active neurons: 4
 >> iter 41000, loss: 0.358233
 >> iter 42000, loss: 0.383287
 >> iter 43000, loss: 0.575018
 >> iter 44000, loss: 0.278116
 >> iter 45000, loss: 0.226384
 >> iter 46000, loss: 0.221424
 >> iter 47000, loss: 0.396269
 >> iter 48000, loss: 0.416527
 >> iter 49000, loss: 0.364711
 >> iter 50000, loss: 0.286563
   Number of active neurons: 4
 >> iter 51000, loss: 0.322418
 >> iter 52000, loss: 0.247141
 >> iter 53000, loss: 0.206821
 >> iter 54000, loss: 0.344786
 >> iter 55000, loss: 0.379300
 >> iter 56000, loss: 0.341053
 >> iter 57000, loss: 0.227312
 >> iter 58000, loss: 0.288873
 >> iter 59000, loss: 0.345839
 >> iter 60000, loss: 0.566308
   Number of active neurons: 4
 >> iter 61000, loss: 0.449574
 >> iter 62000, loss: 0.322641
 >> iter 63000, loss: 0.376324
 >> iter 64000, loss: 0.245115
 >> iter 65000, loss: 0.373920
 >> iter 66000, loss: 0.306277
 >> iter 67000, loss: 0.399304
 >> iter 68000, loss: 0.426775
 >> iter 69000, loss: 0.373453
 >> iter 70000, loss: 0.523169
   Number of active neurons: 4
 >> iter 71000, loss: 0.368114
 >> iter 72000, loss: 0.311461
 >> iter 73000, loss: 0.253138
 >> iter 74000, loss: 0.264851
 >> iter 75000, loss: 0.261870
 >> iter 76000, loss: 0.267678
 >> iter 77000, loss: 0.137950
 >> iter 78000, loss: 0.220184
 >> iter 79000, loss: 0.259726
 >> iter 80000, loss: 0.152418
   Number of active neurons: 4
 >> iter 81000, loss: 0.311029
 >> iter 82000, loss: 0.256415
 >> iter 83000, loss: 0.147299
 >> iter 84000, loss: 0.224285
 >> iter 85000, loss: 0.242580
 >> iter 86000, loss: 0.193222
 >> iter 87000, loss: 0.414682
 >> iter 88000, loss: 0.503204
 >> iter 89000, loss: 0.365432
 >> iter 90000, loss: 0.447033
   Number of active neurons: 4
 >> iter 91000, loss: 0.323644
 >> iter 92000, loss: 0.301728
 >> iter 93000, loss: 0.291600
 >> iter 94000, loss: 0.302862
 >> iter 95000, loss: 0.318516
 >> iter 96000, loss: 0.301455
 >> iter 97000, loss: 0.297860
 >> iter 98000, loss: 0.300038
 >> iter 99000, loss: 0.343906
 >> iter 100000, loss: 0.268555
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.628425
 >> iter 2000, loss: 9.058126
 >> iter 3000, loss: 4.505017
 >> iter 4000, loss: 2.149130
 >> iter 5000, loss: 1.613509
 >> iter 6000, loss: 1.039427
 >> iter 7000, loss: 0.907321
 >> iter 8000, loss: 0.666021
 >> iter 9000, loss: 0.711731
 >> iter 10000, loss: 0.545335
   Number of active neurons: 5
 >> iter 11000, loss: 0.395702
 >> iter 12000, loss: 0.514188
 >> iter 13000, loss: 0.330148
 >> iter 14000, loss: 0.345797
 >> iter 15000, loss: 0.394326
 >> iter 16000, loss: 0.423027
 >> iter 17000, loss: 0.412739
 >> iter 18000, loss: 0.594019
 >> iter 19000, loss: 0.484898
 >> iter 20000, loss: 0.702124
   Number of active neurons: 5
 >> iter 21000, loss: 0.387609
 >> iter 22000, loss: 0.496659
 >> iter 23000, loss: 0.468807
 >> iter 24000, loss: 0.483145
 >> iter 25000, loss: 0.505497
 >> iter 26000, loss: 0.539011
 >> iter 27000, loss: 0.357484
 >> iter 28000, loss: 0.389356
 >> iter 29000, loss: 0.392721
 >> iter 30000, loss: 0.385942
   Number of active neurons: 4
 >> iter 31000, loss: 0.462248
 >> iter 32000, loss: 0.366906
 >> iter 33000, loss: 0.383871
 >> iter 34000, loss: 0.445237
 >> iter 35000, loss: 0.327019
 >> iter 36000, loss: 0.490857
 >> iter 37000, loss: 0.348303
 >> iter 38000, loss: 0.415930
 >> iter 39000, loss: 0.324174
 >> iter 40000, loss: 0.575626
   Number of active neurons: 4
 >> iter 41000, loss: 0.449833
 >> iter 42000, loss: 0.410205
 >> iter 43000, loss: 0.514653
 >> iter 44000, loss: 0.799743
 >> iter 45000, loss: 0.742265
 >> iter 46000, loss: 0.946466
 >> iter 47000, loss: 0.652220
 >> iter 48000, loss: 0.555575
 >> iter 49000, loss: 0.596430
 >> iter 50000, loss: 0.465428
   Number of active neurons: 4
 >> iter 51000, loss: 0.461282
 >> iter 52000, loss: 0.637649
 >> iter 53000, loss: 0.663542
 >> iter 54000, loss: 0.593934
 >> iter 55000, loss: 0.503129
 >> iter 56000, loss: 0.473717
 >> iter 57000, loss: 0.368880
 >> iter 58000, loss: 0.456882
 >> iter 59000, loss: 0.555606
 >> iter 60000, loss: 0.461814
   Number of active neurons: 3
 >> iter 61000, loss: 0.398406
 >> iter 62000, loss: 0.613723
 >> iter 63000, loss: 0.453796
 >> iter 64000, loss: 0.629046
 >> iter 65000, loss: 0.395544
 >> iter 66000, loss: 0.355785
 >> iter 67000, loss: 0.478010
 >> iter 68000, loss: 0.562966
 >> iter 69000, loss: 0.544497
 >> iter 70000, loss: 0.523533
   Number of active neurons: 3
 >> iter 71000, loss: 0.425433
 >> iter 72000, loss: 0.395462
 >> iter 73000, loss: 0.591350
 >> iter 74000, loss: 0.469010
 >> iter 75000, loss: 0.435169
 >> iter 76000, loss: 0.495891
 >> iter 77000, loss: 0.503454
 >> iter 78000, loss: 0.410935
 >> iter 79000, loss: 0.472010
 >> iter 80000, loss: 0.273100
   Number of active neurons: 3
 >> iter 81000, loss: 0.404639
 >> iter 82000, loss: 0.413658
 >> iter 83000, loss: 0.326961
 >> iter 84000, loss: 0.456841
 >> iter 85000, loss: 0.451858
 >> iter 86000, loss: 0.508986
 >> iter 87000, loss: 0.563621
 >> iter 88000, loss: 0.458351
 >> iter 89000, loss: 0.576650
 >> iter 90000, loss: 0.520054
   Number of active neurons: 3
 >> iter 91000, loss: 0.502371
 >> iter 92000, loss: 0.525641
 >> iter 93000, loss: 0.318583
 >> iter 94000, loss: 0.446992
 >> iter 95000, loss: 0.410990
 >> iter 96000, loss: 0.393497
 >> iter 97000, loss: 0.359546
 >> iter 98000, loss: 0.425519
 >> iter 99000, loss: 0.368116
 >> iter 100000, loss: 0.412119
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.706579
 >> iter 2000, loss: 8.652194
 >> iter 3000, loss: 3.786310
 >> iter 4000, loss: 1.741284
 >> iter 5000, loss: 0.948991
 >> iter 6000, loss: 0.829218
 >> iter 7000, loss: 0.758104
 >> iter 8000, loss: 0.596951
 >> iter 9000, loss: 0.434390
 >> iter 10000, loss: 0.345371
   Number of active neurons: 5
 >> iter 11000, loss: 0.273320
 >> iter 12000, loss: 0.296147
 >> iter 13000, loss: 0.352369
 >> iter 14000, loss: 0.291287
 >> iter 15000, loss: 0.259463
 >> iter 16000, loss: 0.372533
 >> iter 17000, loss: 0.325350
 >> iter 18000, loss: 0.408626
 >> iter 19000, loss: 0.298711
 >> iter 20000, loss: 0.392759
   Number of active neurons: 5
 >> iter 21000, loss: 0.376248
 >> iter 22000, loss: 0.211580
 >> iter 23000, loss: 0.237877
 >> iter 24000, loss: 0.490864
 >> iter 25000, loss: 0.461205
 >> iter 26000, loss: 0.230709
 >> iter 27000, loss: 0.305322
 >> iter 28000, loss: 0.405656
 >> iter 29000, loss: 0.496263
 >> iter 30000, loss: 0.300487
   Number of active neurons: 4
 >> iter 31000, loss: 0.392501
 >> iter 32000, loss: 0.445112
 >> iter 33000, loss: 0.333868
 >> iter 34000, loss: 0.260343
 >> iter 35000, loss: 0.256681
 >> iter 36000, loss: 0.215057
 >> iter 37000, loss: 0.310338
 >> iter 38000, loss: 0.203697
 >> iter 39000, loss: 0.263900
 >> iter 40000, loss: 0.314710
   Number of active neurons: 4
 >> iter 41000, loss: 0.225226
 >> iter 42000, loss: 0.289861
 >> iter 43000, loss: 0.485135
 >> iter 44000, loss: 0.369123
 >> iter 45000, loss: 0.219951
 >> iter 46000, loss: 0.333901
 >> iter 47000, loss: 0.201144
 >> iter 48000, loss: 0.199526
 >> iter 49000, loss: 0.235455
 >> iter 50000, loss: 0.210641
   Number of active neurons: 3
 >> iter 51000, loss: 0.266643
 >> iter 52000, loss: 0.282990
 >> iter 53000, loss: 0.337458
 >> iter 54000, loss: 0.333691
 >> iter 55000, loss: 0.401447
 >> iter 56000, loss: 0.316470
 >> iter 57000, loss: 0.302867
 >> iter 58000, loss: 0.328192
 >> iter 59000, loss: 0.284888
 >> iter 60000, loss: 0.228931
   Number of active neurons: 3
 >> iter 61000, loss: 0.280752
 >> iter 62000, loss: 0.347444
 >> iter 63000, loss: 0.302995
 >> iter 64000, loss: 0.227805
 >> iter 65000, loss: 0.236130
 >> iter 66000, loss: 0.411704
 >> iter 67000, loss: 0.378622
 >> iter 68000, loss: 0.355454
 >> iter 69000, loss: 0.273134
 >> iter 70000, loss: 0.307121
   Number of active neurons: 3
 >> iter 71000, loss: 0.422135
 >> iter 72000, loss: 0.334778
 >> iter 73000, loss: 0.397277
 >> iter 74000, loss: 0.218797
 >> iter 75000, loss: 0.253256
 >> iter 76000, loss: 0.234595
 >> iter 77000, loss: 0.338860
 >> iter 78000, loss: 0.275110
 >> iter 79000, loss: 0.210618
 >> iter 80000, loss: 0.268160
   Number of active neurons: 3
 >> iter 81000, loss: 0.207496
 >> iter 82000, loss: 0.213155
 >> iter 83000, loss: 0.139745
 >> iter 84000, loss: 0.329479
 >> iter 85000, loss: 0.300979
 >> iter 86000, loss: 0.353968
 >> iter 87000, loss: 0.367491
 >> iter 88000, loss: 0.330603
 >> iter 89000, loss: 0.240118
 >> iter 90000, loss: 0.243540
   Number of active neurons: 3
 >> iter 91000, loss: 0.285228
 >> iter 92000, loss: 0.325410
 >> iter 93000, loss: 0.326529
 >> iter 94000, loss: 0.172109
 >> iter 95000, loss: 0.161350
 >> iter 96000, loss: 0.148938
 >> iter 97000, loss: 0.334618
 >> iter 98000, loss: 0.341200
 >> iter 99000, loss: 0.199117
 >> iter 100000, loss: 0.282511
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.998476
 >> iter 2000, loss: 8.991542
 >> iter 3000, loss: 3.738290
 >> iter 4000, loss: 1.996878
 >> iter 5000, loss: 1.095252
 >> iter 6000, loss: 0.791562
 >> iter 7000, loss: 0.447017
 >> iter 8000, loss: 0.342115
 >> iter 9000, loss: 0.405593
 >> iter 10000, loss: 0.505758
   Number of active neurons: 6
 >> iter 11000, loss: 0.444788
 >> iter 12000, loss: 0.540355
 >> iter 13000, loss: 0.357769
 >> iter 14000, loss: 0.357558
 >> iter 15000, loss: 0.440136
 >> iter 16000, loss: 0.226440
 >> iter 17000, loss: 0.294326
 >> iter 18000, loss: 0.308147
 >> iter 19000, loss: 0.391379
 >> iter 20000, loss: 0.426797
   Number of active neurons: 5
 >> iter 21000, loss: 0.360825
 >> iter 22000, loss: 0.176274
 >> iter 23000, loss: 0.259791
 >> iter 24000, loss: 0.380015
 >> iter 25000, loss: 0.400033
 >> iter 26000, loss: 0.287894
 >> iter 27000, loss: 0.198347
 >> iter 28000, loss: 0.353430
 >> iter 29000, loss: 0.351004
 >> iter 30000, loss: 0.275848
   Number of active neurons: 5
 >> iter 31000, loss: 0.202044
 >> iter 32000, loss: 0.290867
 >> iter 33000, loss: 0.310104
 >> iter 34000, loss: 0.410155
 >> iter 35000, loss: 0.263759
 >> iter 36000, loss: 0.496655
 >> iter 37000, loss: 0.333078
 >> iter 38000, loss: 0.383332
 >> iter 39000, loss: 0.256884
 >> iter 40000, loss: 0.291239
   Number of active neurons: 4
 >> iter 41000, loss: 0.275555
 >> iter 42000, loss: 0.391055
 >> iter 43000, loss: 0.591431
 >> iter 44000, loss: 0.275699
 >> iter 45000, loss: 0.319664
 >> iter 46000, loss: 0.309044
 >> iter 47000, loss: 0.245900
 >> iter 48000, loss: 0.277921
 >> iter 49000, loss: 0.269116
 >> iter 50000, loss: 0.434419
   Number of active neurons: 4
 >> iter 51000, loss: 0.358120
 >> iter 52000, loss: 0.192822
 >> iter 53000, loss: 0.313909
 >> iter 54000, loss: 0.301787
 >> iter 55000, loss: 0.302703
 >> iter 56000, loss: 0.240058
 >> iter 57000, loss: 0.236082
 >> iter 58000, loss: 0.212086
 >> iter 59000, loss: 0.174215
 >> iter 60000, loss: 0.186187
   Number of active neurons: 4
 >> iter 61000, loss: 0.171209
 >> iter 62000, loss: 0.151367
 >> iter 63000, loss: 0.151430
 >> iter 64000, loss: 0.225867
 >> iter 65000, loss: 0.279544
 >> iter 66000, loss: 0.276332
 >> iter 67000, loss: 0.346423
 >> iter 68000, loss: 0.294856
 >> iter 69000, loss: 0.364347
 >> iter 70000, loss: 0.232788
   Number of active neurons: 4
 >> iter 71000, loss: 0.315530
 >> iter 72000, loss: 0.452729
 >> iter 73000, loss: 0.220051
 >> iter 74000, loss: 0.199770
 >> iter 75000, loss: 0.173176
 >> iter 76000, loss: 0.166086
 >> iter 77000, loss: 0.282129
 >> iter 78000, loss: 0.193225
 >> iter 79000, loss: 0.244007
 >> iter 80000, loss: 0.264909
   Number of active neurons: 4
 >> iter 81000, loss: 0.352533
 >> iter 82000, loss: 0.293828
 >> iter 83000, loss: 0.361618
 >> iter 84000, loss: 0.221411
 >> iter 85000, loss: 0.144116
 >> iter 86000, loss: 0.119171
 >> iter 87000, loss: 0.143765
 >> iter 88000, loss: 0.389159
 >> iter 89000, loss: 0.390711
 >> iter 90000, loss: 0.203275
   Number of active neurons: 4
 >> iter 91000, loss: 0.267609
 >> iter 92000, loss: 0.178764
 >> iter 93000, loss: 0.607374
 >> iter 94000, loss: 0.488761
 >> iter 95000, loss: 0.385458
 >> iter 96000, loss: 0.309483
 >> iter 97000, loss: 0.392050
 >> iter 98000, loss: 0.360985
 >> iter 99000, loss: 0.301671
 >> iter 100000, loss: 0.169491
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.780551
 >> iter 2000, loss: 9.223649
 >> iter 3000, loss: 4.704889
 >> iter 4000, loss: 2.400374
 >> iter 5000, loss: 1.212469
 >> iter 6000, loss: 0.816027
 >> iter 7000, loss: 0.682070
 >> iter 8000, loss: 0.565541
 >> iter 9000, loss: 0.487633
 >> iter 10000, loss: 0.304162
   Number of active neurons: 4
 >> iter 11000, loss: 0.412415
 >> iter 12000, loss: 0.437041
 >> iter 13000, loss: 0.235786
 >> iter 14000, loss: 0.438401
 >> iter 15000, loss: 0.496505
 >> iter 16000, loss: 0.341456
 >> iter 17000, loss: 0.280461
 >> iter 18000, loss: 0.359462
 >> iter 19000, loss: 0.388117
 >> iter 20000, loss: 0.375808
   Number of active neurons: 4
 >> iter 21000, loss: 0.283444
 >> iter 22000, loss: 0.393347
 >> iter 23000, loss: 0.502070
 >> iter 24000, loss: 0.377192
 >> iter 25000, loss: 0.268149
 >> iter 26000, loss: 0.201918
 >> iter 27000, loss: 0.231962
 >> iter 28000, loss: 0.370556
 >> iter 29000, loss: 0.356481
 >> iter 30000, loss: 0.404492
   Number of active neurons: 4
 >> iter 31000, loss: 0.335652
 >> iter 32000, loss: 0.290345
 >> iter 33000, loss: 0.538172
 >> iter 34000, loss: 0.419965
 >> iter 35000, loss: 0.328805
 >> iter 36000, loss: 0.178780
 >> iter 37000, loss: 0.317317
 >> iter 38000, loss: 0.545103
 >> iter 39000, loss: 0.335155
 >> iter 40000, loss: 0.420602
   Number of active neurons: 3
 >> iter 41000, loss: 0.333035
 >> iter 42000, loss: 0.467338
 >> iter 43000, loss: 0.327317
 >> iter 44000, loss: 0.440085
 >> iter 45000, loss: 0.408397
 >> iter 46000, loss: 0.312890
 >> iter 47000, loss: 0.271849
 >> iter 48000, loss: 0.230462
 >> iter 49000, loss: 0.198319
 >> iter 50000, loss: 0.228652
   Number of active neurons: 3
 >> iter 51000, loss: 0.300790
 >> iter 52000, loss: 0.231517
 >> iter 53000, loss: 0.366287
 >> iter 54000, loss: 0.327744
 >> iter 55000, loss: 0.174769
 >> iter 56000, loss: 0.298586
 >> iter 57000, loss: 0.413014
 >> iter 58000, loss: 0.385883
 >> iter 59000, loss: 0.378931
 >> iter 60000, loss: 0.193611
   Number of active neurons: 3
 >> iter 61000, loss: 0.231901
 >> iter 62000, loss: 0.218660
 >> iter 63000, loss: 0.220306
 >> iter 64000, loss: 0.193202
 >> iter 65000, loss: 0.289603
 >> iter 66000, loss: 0.549562
 >> iter 67000, loss: 0.375494
 >> iter 68000, loss: 0.352976
 >> iter 69000, loss: 0.307695
 >> iter 70000, loss: 0.335614
   Number of active neurons: 3
 >> iter 71000, loss: 0.168470
 >> iter 72000, loss: 0.347561
 >> iter 73000, loss: 0.338662
 >> iter 74000, loss: 0.311567
 >> iter 75000, loss: 0.345742
 >> iter 76000, loss: 0.471313
 >> iter 77000, loss: 0.239495
 >> iter 78000, loss: 0.229089
 >> iter 79000, loss: 0.310217
 >> iter 80000, loss: 0.283641
   Number of active neurons: 3
 >> iter 81000, loss: 0.385822
 >> iter 82000, loss: 0.350266
 >> iter 83000, loss: 0.200938
 >> iter 84000, loss: 0.244982
 >> iter 85000, loss: 0.192751
 >> iter 86000, loss: 0.180575
 >> iter 87000, loss: 0.422084
 >> iter 88000, loss: 0.334889
 >> iter 89000, loss: 0.202611
 >> iter 90000, loss: 0.195829
   Number of active neurons: 3
 >> iter 91000, loss: 0.212971
 >> iter 92000, loss: 0.431767
 >> iter 93000, loss: 0.264105
 >> iter 94000, loss: 0.246354
 >> iter 95000, loss: 0.163180
 >> iter 96000, loss: 0.291096
 >> iter 97000, loss: 0.318407
 >> iter 98000, loss: 0.162340
 >> iter 99000, loss: 0.242333
 >> iter 100000, loss: 0.358442
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.212579
 >> iter 2000, loss: 11.007669
 >> iter 3000, loss: 5.442971
 >> iter 4000, loss: 2.659325
 >> iter 5000, loss: 1.436974
 >> iter 6000, loss: 0.973863
 >> iter 7000, loss: 0.827176
 >> iter 8000, loss: 0.734096
 >> iter 9000, loss: 0.790765
 >> iter 10000, loss: 0.597740
   Number of active neurons: 7
 >> iter 11000, loss: 0.394522
 >> iter 12000, loss: 0.304202
 >> iter 13000, loss: 0.312861
 >> iter 14000, loss: 0.441587
 >> iter 15000, loss: 0.284609
 >> iter 16000, loss: 0.409801
 >> iter 17000, loss: 0.369513
 >> iter 18000, loss: 0.340744
 >> iter 19000, loss: 0.448627
 >> iter 20000, loss: 0.471309
   Number of active neurons: 5
 >> iter 21000, loss: 0.299944
 >> iter 22000, loss: 0.274320
 >> iter 23000, loss: 0.339899
 >> iter 24000, loss: 0.167333
 >> iter 25000, loss: 0.369898
 >> iter 26000, loss: 0.235900
 >> iter 27000, loss: 0.165548
 >> iter 28000, loss: 0.211631
 >> iter 29000, loss: 0.212639
 >> iter 30000, loss: 0.515714
   Number of active neurons: 4
 >> iter 31000, loss: 0.324356
 >> iter 32000, loss: 0.229966
 >> iter 33000, loss: 0.189483
 >> iter 34000, loss: 0.334005
 >> iter 35000, loss: 0.310134
 >> iter 36000, loss: 0.255486
 >> iter 37000, loss: 0.150721
 >> iter 38000, loss: 0.174923
 >> iter 39000, loss: 0.127277
 >> iter 40000, loss: 0.324267
   Number of active neurons: 4
 >> iter 41000, loss: 0.360514
 >> iter 42000, loss: 0.338893
 >> iter 43000, loss: 0.425393
 >> iter 44000, loss: 0.230720
 >> iter 45000, loss: 0.252860
 >> iter 46000, loss: 0.359624
 >> iter 47000, loss: 0.242128
 >> iter 48000, loss: 0.228604
 >> iter 49000, loss: 0.209146
 >> iter 50000, loss: 0.238925
   Number of active neurons: 4
 >> iter 51000, loss: 0.216790
 >> iter 52000, loss: 0.224845
 >> iter 53000, loss: 0.359760
 >> iter 54000, loss: 0.310280
 >> iter 55000, loss: 0.260859
 >> iter 56000, loss: 0.310417
 >> iter 57000, loss: 0.157541
 >> iter 58000, loss: 0.331058
 >> iter 59000, loss: 0.235656
 >> iter 60000, loss: 0.473446
   Number of active neurons: 4
 >> iter 61000, loss: 0.234823
 >> iter 62000, loss: 0.232892
 >> iter 63000, loss: 0.334128
 >> iter 64000, loss: 0.333026
 >> iter 65000, loss: 0.229011
 >> iter 66000, loss: 0.206202
 >> iter 67000, loss: 0.199202
 >> iter 68000, loss: 0.250633
 >> iter 69000, loss: 0.317999
 >> iter 70000, loss: 0.195247
   Number of active neurons: 3
 >> iter 71000, loss: 0.241726
 >> iter 72000, loss: 0.184586
 >> iter 73000, loss: 0.120722
 >> iter 74000, loss: 0.271621
 >> iter 75000, loss: 0.234000
 >> iter 76000, loss: 0.142481
 >> iter 77000, loss: 0.158675
 >> iter 78000, loss: 0.312542
 >> iter 79000, loss: 0.241389
 >> iter 80000, loss: 0.299286
   Number of active neurons: 3
 >> iter 81000, loss: 0.206017
 >> iter 82000, loss: 0.375076
 >> iter 83000, loss: 0.318471
 >> iter 84000, loss: 0.256554
 >> iter 85000, loss: 0.258186
 >> iter 86000, loss: 0.296523
 >> iter 87000, loss: 0.210457
 >> iter 88000, loss: 0.359757
 >> iter 89000, loss: 0.239289
 >> iter 90000, loss: 0.181897
   Number of active neurons: 3
 >> iter 91000, loss: 0.140730
 >> iter 92000, loss: 0.239595
 >> iter 93000, loss: 0.390681
 >> iter 94000, loss: 0.353888
 >> iter 95000, loss: 0.226156
 >> iter 96000, loss: 0.116824
 >> iter 97000, loss: 0.216863
 >> iter 98000, loss: 0.406934
 >> iter 99000, loss: 0.321266
 >> iter 100000, loss: 0.261957
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.642678
 >> iter 2000, loss: 9.086766
 >> iter 3000, loss: 3.855559
 >> iter 4000, loss: 1.862239
 >> iter 5000, loss: 1.067076
 >> iter 6000, loss: 0.541463
 >> iter 7000, loss: 0.475967
 >> iter 8000, loss: 0.368201
 >> iter 9000, loss: 0.427765
 >> iter 10000, loss: 0.376668
   Number of active neurons: 7
 >> iter 11000, loss: 0.318992
 >> iter 12000, loss: 0.380133
 >> iter 13000, loss: 0.319651
 >> iter 14000, loss: 0.328797
 >> iter 15000, loss: 0.293810
 >> iter 16000, loss: 0.192268
 >> iter 17000, loss: 0.321308
 >> iter 18000, loss: 0.291237
 >> iter 19000, loss: 0.387859
 >> iter 20000, loss: 0.273326
   Number of active neurons: 4
 >> iter 21000, loss: 0.301253
 >> iter 22000, loss: 0.473798
 >> iter 23000, loss: 0.310489
 >> iter 24000, loss: 0.353627
 >> iter 25000, loss: 0.286591
 >> iter 26000, loss: 0.350173
 >> iter 27000, loss: 0.293084
 >> iter 28000, loss: 0.332597
 >> iter 29000, loss: 0.193433
 >> iter 30000, loss: 0.278823
   Number of active neurons: 4
 >> iter 31000, loss: 0.179335
 >> iter 32000, loss: 0.181322
 >> iter 33000, loss: 0.398768
 >> iter 34000, loss: 0.360786
 >> iter 35000, loss: 0.236443
 >> iter 36000, loss: 0.221675
 >> iter 37000, loss: 0.252744
 >> iter 38000, loss: 0.309851
 >> iter 39000, loss: 0.274391
 >> iter 40000, loss: 0.226862
   Number of active neurons: 4
 >> iter 41000, loss: 0.374301
 >> iter 42000, loss: 0.196208
 >> iter 43000, loss: 0.178339
 >> iter 44000, loss: 0.404408
 >> iter 45000, loss: 0.314804
 >> iter 46000, loss: 0.166494
 >> iter 47000, loss: 0.285243
 >> iter 48000, loss: 0.315489
 >> iter 49000, loss: 0.337929
 >> iter 50000, loss: 0.196769
   Number of active neurons: 4
 >> iter 51000, loss: 0.246585
 >> iter 52000, loss: 0.271261
 >> iter 53000, loss: 0.363152
 >> iter 54000, loss: 0.295103
 >> iter 55000, loss: 0.244766
 >> iter 56000, loss: 0.271263
 >> iter 57000, loss: 0.250966
 >> iter 58000, loss: 0.245092
 >> iter 59000, loss: 0.221502
 >> iter 60000, loss: 0.140177
   Number of active neurons: 4
 >> iter 61000, loss: 0.166472
 >> iter 62000, loss: 0.226881
 >> iter 63000, loss: 0.166499
 >> iter 64000, loss: 0.221119
 >> iter 65000, loss: 0.297205
 >> iter 66000, loss: 0.305190
 >> iter 67000, loss: 0.337754
 >> iter 68000, loss: 0.221442
 >> iter 69000, loss: 0.444498
 >> iter 70000, loss: 0.283608
   Number of active neurons: 4
 >> iter 71000, loss: 0.240214
 >> iter 72000, loss: 0.224511
 >> iter 73000, loss: 0.283695
 >> iter 74000, loss: 0.264696
 >> iter 75000, loss: 0.292537
 >> iter 76000, loss: 0.256343
 >> iter 77000, loss: 0.205873
 >> iter 78000, loss: 0.174718
 >> iter 79000, loss: 0.213328
 >> iter 80000, loss: 0.146163
   Number of active neurons: 4
 >> iter 81000, loss: 0.220900
 >> iter 82000, loss: 0.213617
 >> iter 83000, loss: 0.244821
 >> iter 84000, loss: 0.187699
 >> iter 85000, loss: 0.202250
 >> iter 86000, loss: 0.142801
 >> iter 87000, loss: 0.402994
 >> iter 88000, loss: 0.247482
 >> iter 89000, loss: 0.165413
 >> iter 90000, loss: 0.166924
   Number of active neurons: 4
 >> iter 91000, loss: 0.210880
 >> iter 92000, loss: 0.198086
 >> iter 93000, loss: 0.311777
 >> iter 94000, loss: 0.319019
 >> iter 95000, loss: 0.308815
 >> iter 96000, loss: 0.167961
 >> iter 97000, loss: 0.246513
 >> iter 98000, loss: 0.113146
 >> iter 99000, loss: 0.193176
 >> iter 100000, loss: 0.165542
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.782977
 >> iter 2000, loss: 8.898684
 >> iter 3000, loss: 4.204913
 >> iter 4000, loss: 1.827158
 >> iter 5000, loss: 0.967062
 >> iter 6000, loss: 0.531947
 >> iter 7000, loss: 0.298865
 >> iter 8000, loss: 0.155487
 >> iter 9000, loss: 0.359903
 >> iter 10000, loss: 0.378080
   Number of active neurons: 4
 >> iter 11000, loss: 0.408909
 >> iter 12000, loss: 0.345516
 >> iter 13000, loss: 0.447447
 >> iter 14000, loss: 0.438336
 >> iter 15000, loss: 0.263716
 >> iter 16000, loss: 0.293862
 >> iter 17000, loss: 0.310456
 >> iter 18000, loss: 0.338406
 >> iter 19000, loss: 0.377897
 >> iter 20000, loss: 0.304546
   Number of active neurons: 4
 >> iter 21000, loss: 0.142475
 >> iter 22000, loss: 0.296065
 >> iter 23000, loss: 0.233714
 >> iter 24000, loss: 0.182624
 >> iter 25000, loss: 0.593054
 >> iter 26000, loss: 0.368506
 >> iter 27000, loss: 0.498487
 >> iter 28000, loss: 0.432162
 >> iter 29000, loss: 0.208517
 >> iter 30000, loss: 0.396702
   Number of active neurons: 4
 >> iter 31000, loss: 0.232811
 >> iter 32000, loss: 0.181808
 >> iter 33000, loss: 0.381507
 >> iter 34000, loss: 0.269004
 >> iter 35000, loss: 0.343537
 >> iter 36000, loss: 0.214629
 >> iter 37000, loss: 0.295773
 >> iter 38000, loss: 0.291177
 >> iter 39000, loss: 0.328828
 >> iter 40000, loss: 0.358779
   Number of active neurons: 3
 >> iter 41000, loss: 0.249032
 >> iter 42000, loss: 0.236403
 >> iter 43000, loss: 0.263524
 >> iter 44000, loss: 0.333843
 >> iter 45000, loss: 0.415283
 >> iter 46000, loss: 0.401654
 >> iter 47000, loss: 0.370979
 >> iter 48000, loss: 0.346235
 >> iter 49000, loss: 0.202307
 >> iter 50000, loss: 0.445944
   Number of active neurons: 3
 >> iter 51000, loss: 0.333223
 >> iter 52000, loss: 0.357998
 >> iter 53000, loss: 0.340076
 >> iter 54000, loss: 0.254242
 >> iter 55000, loss: 0.191212
 >> iter 56000, loss: 0.225898
 >> iter 57000, loss: 0.322679
 >> iter 58000, loss: 0.210951
 >> iter 59000, loss: 0.142372
 >> iter 60000, loss: 0.206396
   Number of active neurons: 3
 >> iter 61000, loss: 0.262478
 >> iter 62000, loss: 0.317713
 >> iter 63000, loss: 0.260079
 >> iter 64000, loss: 0.204107
 >> iter 65000, loss: 0.163716
 >> iter 66000, loss: 0.147772
 >> iter 67000, loss: 0.301810
 >> iter 68000, loss: 0.199642
 >> iter 69000, loss: 0.260199
 >> iter 70000, loss: 0.188768
   Number of active neurons: 3
 >> iter 71000, loss: 0.120500
 >> iter 72000, loss: 0.180033
 >> iter 73000, loss: 0.273622
 >> iter 74000, loss: 0.297478
 >> iter 75000, loss: 0.224656
 >> iter 76000, loss: 0.252694
 >> iter 77000, loss: 0.325021
 >> iter 78000, loss: 0.235222
 >> iter 79000, loss: 0.212097
 >> iter 80000, loss: 0.154957
   Number of active neurons: 3
 >> iter 81000, loss: 0.382473
 >> iter 82000, loss: 0.266832
 >> iter 83000, loss: 0.223457
 >> iter 84000, loss: 0.127327
 >> iter 85000, loss: 0.145631
 >> iter 86000, loss: 0.195309
 >> iter 87000, loss: 0.245113
 >> iter 88000, loss: 0.134487
 >> iter 89000, loss: 0.120965
 >> iter 90000, loss: 0.251912
   Number of active neurons: 3
 >> iter 91000, loss: 0.164046
 >> iter 92000, loss: 0.096583
 >> iter 93000, loss: 0.243719
 >> iter 94000, loss: 0.235549
 >> iter 95000, loss: 0.397650
 >> iter 96000, loss: 0.278321
 >> iter 97000, loss: 0.234218
 >> iter 98000, loss: 0.137751
 >> iter 99000, loss: 0.235187
 >> iter 100000, loss: 0.421717
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.985899
 >> iter 2000, loss: 8.818526
 >> iter 3000, loss: 3.828957
 >> iter 4000, loss: 1.911383
 >> iter 5000, loss: 1.044416
 >> iter 6000, loss: 0.835359
 >> iter 7000, loss: 0.653869
 >> iter 8000, loss: 0.367016
 >> iter 9000, loss: 0.478934
 >> iter 10000, loss: 0.412414
   Number of active neurons: 5
 >> iter 11000, loss: 0.255850
 >> iter 12000, loss: 0.293906
 >> iter 13000, loss: 0.314194
 >> iter 14000, loss: 0.322011
 >> iter 15000, loss: 0.251951
 >> iter 16000, loss: 0.259189
 >> iter 17000, loss: 0.339414
 >> iter 18000, loss: 0.389201
 >> iter 19000, loss: 0.202626
 >> iter 20000, loss: 0.290650
   Number of active neurons: 5
 >> iter 21000, loss: 0.369444
 >> iter 22000, loss: 0.222288
 >> iter 23000, loss: 0.231273
 >> iter 24000, loss: 0.256919
 >> iter 25000, loss: 0.284138
 >> iter 26000, loss: 0.233845
 >> iter 27000, loss: 0.283134
 >> iter 28000, loss: 0.350053
 >> iter 29000, loss: 0.324972
 >> iter 30000, loss: 0.261336
   Number of active neurons: 4
 >> iter 31000, loss: 0.162974
 >> iter 32000, loss: 0.213003
 >> iter 33000, loss: 0.233629
 >> iter 34000, loss: 0.164465
 >> iter 35000, loss: 0.248564
 >> iter 36000, loss: 0.387773
 >> iter 37000, loss: 0.291429
 >> iter 38000, loss: 0.376498
 >> iter 39000, loss: 0.274995
 >> iter 40000, loss: 0.378967
   Number of active neurons: 4
 >> iter 41000, loss: 0.335010
 >> iter 42000, loss: 0.262506
 >> iter 43000, loss: 0.197475
 >> iter 44000, loss: 0.199420
 >> iter 45000, loss: 0.254758
 >> iter 46000, loss: 0.462273
 >> iter 47000, loss: 0.396584
 >> iter 48000, loss: 0.264452
 >> iter 49000, loss: 0.169308
 >> iter 50000, loss: 0.157720
   Number of active neurons: 3
 >> iter 51000, loss: 0.144868
 >> iter 52000, loss: 0.278326
 >> iter 53000, loss: 0.229470
 >> iter 54000, loss: 0.175422
 >> iter 55000, loss: 0.178570
 >> iter 56000, loss: 0.170259
 >> iter 57000, loss: 0.212271
 >> iter 58000, loss: 0.292323
 >> iter 59000, loss: 0.191664
 >> iter 60000, loss: 0.128810
   Number of active neurons: 3
 >> iter 61000, loss: 0.452010
 >> iter 62000, loss: 0.298046
 >> iter 63000, loss: 0.195920
 >> iter 64000, loss: 0.232742
 >> iter 65000, loss: 0.375409
 >> iter 66000, loss: 0.269240
 >> iter 67000, loss: 0.307487
 >> iter 68000, loss: 0.280936
 >> iter 69000, loss: 0.362587
 >> iter 70000, loss: 0.422893
   Number of active neurons: 3
 >> iter 71000, loss: 0.403331
 >> iter 72000, loss: 0.313700
 >> iter 73000, loss: 0.159979
 >> iter 74000, loss: 0.142104
 >> iter 75000, loss: 0.094969
 >> iter 76000, loss: 0.191539
 >> iter 77000, loss: 0.202160
 >> iter 78000, loss: 0.199624
 >> iter 79000, loss: 0.141106
 >> iter 80000, loss: 0.214375
   Number of active neurons: 3
 >> iter 81000, loss: 0.186326
 >> iter 82000, loss: 0.185008
 >> iter 83000, loss: 0.222627
 >> iter 84000, loss: 0.402726
 >> iter 85000, loss: 0.249717
 >> iter 86000, loss: 0.196961
 >> iter 87000, loss: 0.184384
 >> iter 88000, loss: 0.153590
 >> iter 89000, loss: 0.390057
 >> iter 90000, loss: 0.190279
   Number of active neurons: 3
 >> iter 91000, loss: 0.174469
 >> iter 92000, loss: 0.181416
 >> iter 93000, loss: 0.210807
 >> iter 94000, loss: 0.326721
 >> iter 95000, loss: 0.271880
 >> iter 96000, loss: 0.237429
 >> iter 97000, loss: 0.422090
 >> iter 98000, loss: 0.380042
 >> iter 99000, loss: 0.477246
 >> iter 100000, loss: 0.302175
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.772772
 >> iter 2000, loss: 8.637672
 >> iter 3000, loss: 3.865859
 >> iter 4000, loss: 1.659553
 >> iter 5000, loss: 1.140998
 >> iter 6000, loss: 0.726497
 >> iter 7000, loss: 0.420047
 >> iter 8000, loss: 0.402119
 >> iter 9000, loss: 0.563322
 >> iter 10000, loss: 0.392689
   Number of active neurons: 6
 >> iter 11000, loss: 0.359077
 >> iter 12000, loss: 0.409520
 >> iter 13000, loss: 0.342106
 >> iter 14000, loss: 0.417251
 >> iter 15000, loss: 0.275800
 >> iter 16000, loss: 0.418704
 >> iter 17000, loss: 0.343629
 >> iter 18000, loss: 0.380738
 >> iter 19000, loss: 0.411078
 >> iter 20000, loss: 0.386997
   Number of active neurons: 6
 >> iter 21000, loss: 0.499885
 >> iter 22000, loss: 0.314890
 >> iter 23000, loss: 0.422943
 >> iter 24000, loss: 0.442068
 >> iter 25000, loss: 0.444038
 >> iter 26000, loss: 0.329244
 >> iter 27000, loss: 0.259562
 >> iter 28000, loss: 0.415627
 >> iter 29000, loss: 0.418690
 >> iter 30000, loss: 0.254538
   Number of active neurons: 6
 >> iter 31000, loss: 0.161237
 >> iter 32000, loss: 0.219045
 >> iter 33000, loss: 0.440495
 >> iter 34000, loss: 0.576406
 >> iter 35000, loss: 0.462125
 >> iter 36000, loss: 0.294308
 >> iter 37000, loss: 0.255602
 >> iter 38000, loss: 0.266744
 >> iter 39000, loss: 0.203811
 >> iter 40000, loss: 0.281480
   Number of active neurons: 6
 >> iter 41000, loss: 0.273787
 >> iter 42000, loss: 0.279384
 >> iter 43000, loss: 0.249154
 >> iter 44000, loss: 0.367578
 >> iter 45000, loss: 0.308718
 >> iter 46000, loss: 0.383386
 >> iter 47000, loss: 0.229236
 >> iter 48000, loss: 0.283119
 >> iter 49000, loss: 0.225023
 >> iter 50000, loss: 0.314300
   Number of active neurons: 4
 >> iter 51000, loss: 0.543063
 >> iter 52000, loss: 0.417454
 >> iter 53000, loss: 0.241319
 >> iter 54000, loss: 0.211764
 >> iter 55000, loss: 0.122740
 >> iter 56000, loss: 0.129210
 >> iter 57000, loss: 0.367309
 >> iter 58000, loss: 0.475656
 >> iter 59000, loss: 0.387526
 >> iter 60000, loss: 0.276804
   Number of active neurons: 4
 >> iter 61000, loss: 0.304332
 >> iter 62000, loss: 0.352510
 >> iter 63000, loss: 0.245224
 >> iter 64000, loss: 0.357253
 >> iter 65000, loss: 0.214872
 >> iter 66000, loss: 0.244880
 >> iter 67000, loss: 0.295188
 >> iter 68000, loss: 0.352355
 >> iter 69000, loss: 0.297359
 >> iter 70000, loss: 0.469425
   Number of active neurons: 4
 >> iter 71000, loss: 0.440245
 >> iter 72000, loss: 0.543183
 >> iter 73000, loss: 0.296857
 >> iter 74000, loss: 0.470510
 >> iter 75000, loss: 0.406186
 >> iter 76000, loss: 0.224823
 >> iter 77000, loss: 0.363266
 >> iter 78000, loss: 0.323195
 >> iter 79000, loss: 0.374485
 >> iter 80000, loss: 0.228915
   Number of active neurons: 4
 >> iter 81000, loss: 0.256565
 >> iter 82000, loss: 0.196695
 >> iter 83000, loss: 0.273392
 >> iter 84000, loss: 0.325786
 >> iter 85000, loss: 0.286841
 >> iter 86000, loss: 0.269159
 >> iter 87000, loss: 0.288606
 >> iter 88000, loss: 0.276009
 >> iter 89000, loss: 0.282217
 >> iter 90000, loss: 0.158696
   Number of active neurons: 4
 >> iter 91000, loss: 0.154351
 >> iter 92000, loss: 0.208693
 >> iter 93000, loss: 0.164809
 >> iter 94000, loss: 0.344956
 >> iter 95000, loss: 0.253947
 >> iter 96000, loss: 0.250375
 >> iter 97000, loss: 0.151430
 >> iter 98000, loss: 0.252589
 >> iter 99000, loss: 0.205345
 >> iter 100000, loss: 0.250706
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.369013
 >> iter 2000, loss: 8.505542
 >> iter 3000, loss: 4.252486
 >> iter 4000, loss: 1.880311
 >> iter 5000, loss: 1.094287
 >> iter 6000, loss: 0.703704
 >> iter 7000, loss: 0.648050
 >> iter 8000, loss: 0.493719
 >> iter 9000, loss: 0.592431
 >> iter 10000, loss: 0.660474
   Number of active neurons: 4
 >> iter 11000, loss: 0.484638
 >> iter 12000, loss: 0.326796
 >> iter 13000, loss: 0.433622
 >> iter 14000, loss: 0.437484
 >> iter 15000, loss: 0.515485
 >> iter 16000, loss: 0.354000
 >> iter 17000, loss: 0.409602
 >> iter 18000, loss: 0.411907
 >> iter 19000, loss: 0.360029
 >> iter 20000, loss: 0.434811
   Number of active neurons: 4
 >> iter 21000, loss: 0.555793
 >> iter 22000, loss: 0.641962
 >> iter 23000, loss: 0.499145
 >> iter 24000, loss: 0.514760
 >> iter 25000, loss: 0.816051
 >> iter 26000, loss: 0.618870
 >> iter 27000, loss: 0.556240
 >> iter 28000, loss: 0.570478
 >> iter 29000, loss: 0.457840
 >> iter 30000, loss: 0.462114
   Number of active neurons: 4
 >> iter 31000, loss: 0.265626
 >> iter 32000, loss: 0.319270
 >> iter 33000, loss: 0.511520
 >> iter 34000, loss: 0.611314
 >> iter 35000, loss: 0.574635
 >> iter 36000, loss: 0.454580
 >> iter 37000, loss: 0.425601
 >> iter 38000, loss: 0.547681
 >> iter 39000, loss: 0.621478
 >> iter 40000, loss: 0.543180
   Number of active neurons: 4
 >> iter 41000, loss: 0.720348
 >> iter 42000, loss: 0.615627
 >> iter 43000, loss: 0.468071
 >> iter 44000, loss: 0.592449
 >> iter 45000, loss: 0.535357
 >> iter 46000, loss: 0.537050
 >> iter 47000, loss: 0.527258
 >> iter 48000, loss: 0.487653
 >> iter 49000, loss: 0.526239
 >> iter 50000, loss: 0.683721
   Number of active neurons: 4
 >> iter 51000, loss: 0.671072
 >> iter 52000, loss: 0.550837
 >> iter 53000, loss: 0.458035
 >> iter 54000, loss: 0.435166
 >> iter 55000, loss: 0.497668
 >> iter 56000, loss: 0.251423
 >> iter 57000, loss: 0.295908
 >> iter 58000, loss: 0.626300
 >> iter 59000, loss: 0.413330
 >> iter 60000, loss: 0.330360
   Number of active neurons: 4
 >> iter 61000, loss: 0.374304
 >> iter 62000, loss: 0.317574
 >> iter 63000, loss: 0.555514
 >> iter 64000, loss: 0.729407
 >> iter 65000, loss: 0.546487
 >> iter 66000, loss: 0.433564
 >> iter 67000, loss: 0.460431
 >> iter 68000, loss: 0.494725
 >> iter 69000, loss: 0.459931
 >> iter 70000, loss: 0.560986
   Number of active neurons: 4
 >> iter 71000, loss: 0.562507
 >> iter 72000, loss: 0.385866
 >> iter 73000, loss: 0.557881
 >> iter 74000, loss: 0.357589
 >> iter 75000, loss: 0.516405
 >> iter 76000, loss: 0.451709
 >> iter 77000, loss: 0.398462
 >> iter 78000, loss: 0.452548
 >> iter 79000, loss: 0.610926
 >> iter 80000, loss: 0.617448
   Number of active neurons: 4
 >> iter 81000, loss: 0.441018
 >> iter 82000, loss: 0.343950
 >> iter 83000, loss: 0.250066
 >> iter 84000, loss: 0.462628
 >> iter 85000, loss: 0.439473
 >> iter 86000, loss: 0.417152
 >> iter 87000, loss: 0.366207
 >> iter 88000, loss: 0.428758
 >> iter 89000, loss: 0.416019
 >> iter 90000, loss: 0.606682
   Number of active neurons: 4
 >> iter 91000, loss: 0.417890
 >> iter 92000, loss: 0.401464
 >> iter 93000, loss: 0.282882
 >> iter 94000, loss: 0.421990
 >> iter 95000, loss: 0.472996
 >> iter 96000, loss: 0.341455
 >> iter 97000, loss: 0.293832
 >> iter 98000, loss: 0.498589
 >> iter 99000, loss: 0.435961
 >> iter 100000, loss: 0.370790
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.499388
 >> iter 2000, loss: 10.618151
 >> iter 3000, loss: 5.071081
 >> iter 4000, loss: 2.573972
 >> iter 5000, loss: 1.364346
 >> iter 6000, loss: 1.006822
 >> iter 7000, loss: 0.906076
 >> iter 8000, loss: 0.734545
 >> iter 9000, loss: 0.566659
 >> iter 10000, loss: 0.470817
   Number of active neurons: 9
 >> iter 11000, loss: 0.544130
 >> iter 12000, loss: 0.670520
 >> iter 13000, loss: 0.647391
 >> iter 14000, loss: 0.430870
 >> iter 15000, loss: 0.394573
 >> iter 16000, loss: 0.423321
 >> iter 17000, loss: 0.340768
 >> iter 18000, loss: 0.543355
 >> iter 19000, loss: 0.374803
 >> iter 20000, loss: 0.228335
   Number of active neurons: 6
 >> iter 21000, loss: 0.251782
 >> iter 22000, loss: 0.235649
 >> iter 23000, loss: 0.529528
 >> iter 24000, loss: 0.378817
 >> iter 25000, loss: 0.419601
 >> iter 26000, loss: 0.486162
 >> iter 27000, loss: 0.558914
 >> iter 28000, loss: 0.275702
 >> iter 29000, loss: 0.288673
 >> iter 30000, loss: 0.264432
   Number of active neurons: 5
 >> iter 31000, loss: 0.392062
 >> iter 32000, loss: 0.494184
 >> iter 33000, loss: 0.354173
 >> iter 34000, loss: 0.456693
 >> iter 35000, loss: 0.560009
 >> iter 36000, loss: 0.423689
 >> iter 37000, loss: 0.295205
 >> iter 38000, loss: 0.352615
 >> iter 39000, loss: 0.421301
 >> iter 40000, loss: 0.270937
   Number of active neurons: 5
 >> iter 41000, loss: 0.323780
 >> iter 42000, loss: 0.379678
 >> iter 43000, loss: 0.347675
 >> iter 44000, loss: 0.268182
 >> iter 45000, loss: 0.207035
 >> iter 46000, loss: 0.207095
 >> iter 47000, loss: 0.218715
 >> iter 48000, loss: 0.214687
 >> iter 49000, loss: 0.212093
 >> iter 50000, loss: 0.420088
   Number of active neurons: 5
 >> iter 51000, loss: 0.402809
 >> iter 52000, loss: 0.346573
 >> iter 53000, loss: 0.565456
 >> iter 54000, loss: 0.364180
 >> iter 55000, loss: 0.301651
 >> iter 56000, loss: 0.228829
 >> iter 57000, loss: 0.351696
 >> iter 58000, loss: 0.245118
 >> iter 59000, loss: 0.307169
 >> iter 60000, loss: 0.479847
   Number of active neurons: 4
 >> iter 61000, loss: 0.277827
 >> iter 62000, loss: 0.204102
 >> iter 63000, loss: 0.222041
 >> iter 64000, loss: 0.251048
 >> iter 65000, loss: 0.353583
 >> iter 66000, loss: 0.250830
 >> iter 67000, loss: 0.262671
 >> iter 68000, loss: 0.366101
 >> iter 69000, loss: 0.336150
 >> iter 70000, loss: 0.231944
   Number of active neurons: 4
 >> iter 71000, loss: 0.404563
 >> iter 72000, loss: 0.290162
 >> iter 73000, loss: 0.273873
 >> iter 74000, loss: 0.344608
 >> iter 75000, loss: 0.309849
 >> iter 76000, loss: 0.214691
 >> iter 77000, loss: 0.178287
 >> iter 78000, loss: 0.263417
 >> iter 79000, loss: 0.263313
 >> iter 80000, loss: 0.354606
   Number of active neurons: 4
 >> iter 81000, loss: 0.178487
 >> iter 82000, loss: 0.140086
 >> iter 83000, loss: 0.239187
 >> iter 84000, loss: 0.348973
 >> iter 85000, loss: 0.178049
 >> iter 86000, loss: 0.183724
 >> iter 87000, loss: 0.249586
 >> iter 88000, loss: 0.308294
 >> iter 89000, loss: 0.455155
 >> iter 90000, loss: 0.281544
   Number of active neurons: 3
 >> iter 91000, loss: 0.218922
 >> iter 92000, loss: 0.291043
 >> iter 93000, loss: 0.313037
 >> iter 94000, loss: 0.200983
 >> iter 95000, loss: 0.226320
 >> iter 96000, loss: 0.272620
 >> iter 97000, loss: 0.165156
 >> iter 98000, loss: 0.287224
 >> iter 99000, loss: 0.209681
 >> iter 100000, loss: 0.137292
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.970691
 >> iter 2000, loss: 8.958563
 >> iter 3000, loss: 4.038009
 >> iter 4000, loss: 1.972735
 >> iter 5000, loss: 0.945268
 >> iter 6000, loss: 0.696456
 >> iter 7000, loss: 0.347770
 >> iter 8000, loss: 0.483360
 >> iter 9000, loss: 0.445541
 >> iter 10000, loss: 0.434476
   Number of active neurons: 5
 >> iter 11000, loss: 0.457226
 >> iter 12000, loss: 0.262003
 >> iter 13000, loss: 0.194962
 >> iter 14000, loss: 0.152510
 >> iter 15000, loss: 0.417693
 >> iter 16000, loss: 0.343157
 >> iter 17000, loss: 0.268385
 >> iter 18000, loss: 0.338642
 >> iter 19000, loss: 0.335953
 >> iter 20000, loss: 0.258001
   Number of active neurons: 5
 >> iter 21000, loss: 0.267391
 >> iter 22000, loss: 0.330925
 >> iter 23000, loss: 0.432454
 >> iter 24000, loss: 0.520300
 >> iter 25000, loss: 0.424777
 >> iter 26000, loss: 0.520640
 >> iter 27000, loss: 0.430123
 >> iter 28000, loss: 0.378867
 >> iter 29000, loss: 0.389540
 >> iter 30000, loss: 0.427968
   Number of active neurons: 5
 >> iter 31000, loss: 0.303679
 >> iter 32000, loss: 0.323888
 >> iter 33000, loss: 0.309901
 >> iter 34000, loss: 0.383578
 >> iter 35000, loss: 0.369983
 >> iter 36000, loss: 0.466417
 >> iter 37000, loss: 0.358055
 >> iter 38000, loss: 0.350505
 >> iter 39000, loss: 0.397650
 >> iter 40000, loss: 0.490804
   Number of active neurons: 5
 >> iter 41000, loss: 0.380286
 >> iter 42000, loss: 0.503128
 >> iter 43000, loss: 0.465679
 >> iter 44000, loss: 0.487494
 >> iter 45000, loss: 0.507872
 >> iter 46000, loss: 0.242059
 >> iter 47000, loss: 0.196281
 >> iter 48000, loss: 0.492004
 >> iter 49000, loss: 0.385375
 >> iter 50000, loss: 0.270911
   Number of active neurons: 4
 >> iter 51000, loss: 0.444724
 >> iter 52000, loss: 0.534672
 >> iter 53000, loss: 0.304812
 >> iter 54000, loss: 0.271667
 >> iter 55000, loss: 0.318742
 >> iter 56000, loss: 0.363517
 >> iter 57000, loss: 0.691008
 >> iter 58000, loss: 0.342048
 >> iter 59000, loss: 0.208887
 >> iter 60000, loss: 0.137371
   Number of active neurons: 4
 >> iter 61000, loss: 0.230249
 >> iter 62000, loss: 0.149960
 >> iter 63000, loss: 0.137100
 >> iter 64000, loss: 0.231485
 >> iter 65000, loss: 0.306077
 >> iter 66000, loss: 0.294479
 >> iter 67000, loss: 0.246039
 >> iter 68000, loss: 0.206045
 >> iter 69000, loss: 0.229637
 >> iter 70000, loss: 0.462476
   Number of active neurons: 4
 >> iter 71000, loss: 0.275272
 >> iter 72000, loss: 0.166802
 >> iter 73000, loss: 0.318582
 >> iter 74000, loss: 0.284204
 >> iter 75000, loss: 0.205952
 >> iter 76000, loss: 0.360337
 >> iter 77000, loss: 0.280100
 >> iter 78000, loss: 0.147272
 >> iter 79000, loss: 0.244020
 >> iter 80000, loss: 0.347764
   Number of active neurons: 3
 >> iter 81000, loss: 0.336765
 >> iter 82000, loss: 0.474683
 >> iter 83000, loss: 0.327900
 >> iter 84000, loss: 0.276703
 >> iter 85000, loss: 0.225758
 >> iter 86000, loss: 0.151275
 >> iter 87000, loss: 0.136572
 >> iter 88000, loss: 0.123159
 >> iter 89000, loss: 0.191117
 >> iter 90000, loss: 0.198052
   Number of active neurons: 3
 >> iter 91000, loss: 0.217322
 >> iter 92000, loss: 0.308575
 >> iter 93000, loss: 0.206178
 >> iter 94000, loss: 0.205985
 >> iter 95000, loss: 0.172223
 >> iter 96000, loss: 0.335938
 >> iter 97000, loss: 0.423741
 >> iter 98000, loss: 0.361159
 >> iter 99000, loss: 0.169257
 >> iter 100000, loss: 0.159140
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.763433
 >> iter 2000, loss: 9.124859
 >> iter 3000, loss: 4.328906
 >> iter 4000, loss: 2.108481
 >> iter 5000, loss: 1.162998
 >> iter 6000, loss: 0.696197
 >> iter 7000, loss: 0.454117
 >> iter 8000, loss: 0.275094
 >> iter 9000, loss: 0.319032
 >> iter 10000, loss: 0.329083
   Number of active neurons: 3
 >> iter 11000, loss: 0.340277
 >> iter 12000, loss: 0.188140
 >> iter 13000, loss: 0.249874
 >> iter 14000, loss: 0.230425
 >> iter 15000, loss: 0.430274
 >> iter 16000, loss: 0.383407
 >> iter 17000, loss: 0.376871
 >> iter 18000, loss: 0.262130
 >> iter 19000, loss: 0.357810
 >> iter 20000, loss: 0.508951
   Number of active neurons: 3
 >> iter 21000, loss: 0.403275
 >> iter 22000, loss: 0.272156
 >> iter 23000, loss: 0.442703
 >> iter 24000, loss: 0.308648
 >> iter 25000, loss: 0.367890
 >> iter 26000, loss: 0.286457
 >> iter 27000, loss: 0.384465
 >> iter 28000, loss: 0.347243
 >> iter 29000, loss: 0.599957
 >> iter 30000, loss: 0.281787
   Number of active neurons: 3
 >> iter 31000, loss: 0.456565
 >> iter 32000, loss: 0.485323
 >> iter 33000, loss: 0.341621
 >> iter 34000, loss: 0.249823
 >> iter 35000, loss: 0.399051
 >> iter 36000, loss: 0.267900
 >> iter 37000, loss: 0.264904
 >> iter 38000, loss: 0.311194
 >> iter 39000, loss: 0.293960
 >> iter 40000, loss: 0.248074
   Number of active neurons: 3
 >> iter 41000, loss: 0.195798
 >> iter 42000, loss: 0.204992
 >> iter 43000, loss: 0.135508
 >> iter 44000, loss: 0.177206
 >> iter 45000, loss: 0.303904
 >> iter 46000, loss: 0.244205
 >> iter 47000, loss: 0.235240
 >> iter 48000, loss: 0.254555
 >> iter 49000, loss: 0.268376
 >> iter 50000, loss: 0.133337
   Number of active neurons: 3
 >> iter 51000, loss: 0.342854
 >> iter 52000, loss: 0.392617
 >> iter 53000, loss: 0.209360
 >> iter 54000, loss: 0.172100
 >> iter 55000, loss: 0.177260
 >> iter 56000, loss: 0.232553
 >> iter 57000, loss: 0.179463
 >> iter 58000, loss: 0.241961
 >> iter 59000, loss: 0.319798
 >> iter 60000, loss: 0.360855
   Number of active neurons: 3
 >> iter 61000, loss: 0.249776
 >> iter 62000, loss: 0.262249
 >> iter 63000, loss: 0.332793
 >> iter 64000, loss: 0.168051
 >> iter 65000, loss: 0.199872
 >> iter 66000, loss: 0.246102
 >> iter 67000, loss: 0.340211
 >> iter 68000, loss: 0.409035
 >> iter 69000, loss: 0.481283
 >> iter 70000, loss: 0.494695
   Number of active neurons: 3
 >> iter 71000, loss: 0.450635
 >> iter 72000, loss: 0.267047
 >> iter 73000, loss: 0.454605
 >> iter 74000, loss: 0.298627
 >> iter 75000, loss: 0.236496
 >> iter 76000, loss: 0.206782
 >> iter 77000, loss: 0.143933
 >> iter 78000, loss: 0.310868
 >> iter 79000, loss: 0.283761
 >> iter 80000, loss: 0.200753
   Number of active neurons: 3
 >> iter 81000, loss: 0.105163
 >> iter 82000, loss: 0.092150
 >> iter 83000, loss: 0.227284
 >> iter 84000, loss: 0.218918
 >> iter 85000, loss: 0.418247
 >> iter 86000, loss: 0.267761
 >> iter 87000, loss: 0.357595
 >> iter 88000, loss: 0.248585
 >> iter 89000, loss: 0.349747
 >> iter 90000, loss: 0.250507
   Number of active neurons: 3
 >> iter 91000, loss: 0.188772
 >> iter 92000, loss: 0.117701
 >> iter 93000, loss: 0.239273
 >> iter 94000, loss: 0.157638
 >> iter 95000, loss: 0.213856
 >> iter 96000, loss: 0.268062
 >> iter 97000, loss: 0.357703
 >> iter 98000, loss: 0.260207
 >> iter 99000, loss: 0.313953
 >> iter 100000, loss: 0.246615
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.819439
 >> iter 2000, loss: 8.912839
 >> iter 3000, loss: 4.220328
 >> iter 4000, loss: 2.304797
 >> iter 5000, loss: 1.392759
 >> iter 6000, loss: 0.723128
 >> iter 7000, loss: 0.547901
 >> iter 8000, loss: 0.672034
 >> iter 9000, loss: 0.595201
 >> iter 10000, loss: 0.605643
   Number of active neurons: 6
 >> iter 11000, loss: 0.712614
 >> iter 12000, loss: 0.580235
 >> iter 13000, loss: 0.531848
 >> iter 14000, loss: 0.485103
 >> iter 15000, loss: 0.681144
 >> iter 16000, loss: 0.907914
 >> iter 17000, loss: 0.750115
 >> iter 18000, loss: 0.725765
 >> iter 19000, loss: 0.432062
 >> iter 20000, loss: 0.379872
   Number of active neurons: 6
 >> iter 21000, loss: 0.540430
 >> iter 22000, loss: 0.449851
 >> iter 23000, loss: 0.539121
 >> iter 24000, loss: 0.559146
 >> iter 25000, loss: 0.630397
 >> iter 26000, loss: 0.791069
 >> iter 27000, loss: 0.536331
 >> iter 28000, loss: 0.552603
 >> iter 29000, loss: 0.473161
 >> iter 30000, loss: 0.503262
   Number of active neurons: 6
 >> iter 31000, loss: 0.315007
 >> iter 32000, loss: 0.627325
 >> iter 33000, loss: 0.351714
 >> iter 34000, loss: 0.508742
 >> iter 35000, loss: 0.460214
 >> iter 36000, loss: 0.453627
 >> iter 37000, loss: 0.346240
 >> iter 38000, loss: 0.306633
 >> iter 39000, loss: 0.311430
 >> iter 40000, loss: 0.421967
   Number of active neurons: 6
 >> iter 41000, loss: 0.445609
 >> iter 42000, loss: 0.328146
 >> iter 43000, loss: 0.325797
 >> iter 44000, loss: 0.305259
 >> iter 45000, loss: 0.610122
 >> iter 46000, loss: 0.328701
 >> iter 47000, loss: 0.356680
 >> iter 48000, loss: 0.540987
 >> iter 49000, loss: 0.742239
 >> iter 50000, loss: 0.454247
   Number of active neurons: 6
 >> iter 51000, loss: 0.430755
 >> iter 52000, loss: 0.425753
 >> iter 53000, loss: 0.531076
 >> iter 54000, loss: 0.588999
 >> iter 55000, loss: 0.427602
 >> iter 56000, loss: 0.427809
 >> iter 57000, loss: 0.428284
 >> iter 58000, loss: 0.505179
 >> iter 59000, loss: 0.602237
 >> iter 60000, loss: 0.371264
   Number of active neurons: 5
 >> iter 61000, loss: 0.427724
 >> iter 62000, loss: 0.410984
 >> iter 63000, loss: 0.588127
 >> iter 64000, loss: 0.731732
 >> iter 65000, loss: 0.551637
 >> iter 66000, loss: 0.482763
 >> iter 67000, loss: 0.394155
 >> iter 68000, loss: 0.545627
 >> iter 69000, loss: 0.402472
 >> iter 70000, loss: 0.405482
   Number of active neurons: 4
 >> iter 71000, loss: 0.503585
 >> iter 72000, loss: 0.425206
 >> iter 73000, loss: 0.457732
 >> iter 74000, loss: 0.524931
 >> iter 75000, loss: 0.521487
 >> iter 76000, loss: 0.667381
 >> iter 77000, loss: 0.454185
 >> iter 78000, loss: 0.333874
 >> iter 79000, loss: 0.334919
 >> iter 80000, loss: 0.358153
   Number of active neurons: 4
 >> iter 81000, loss: 0.287274
 >> iter 82000, loss: 0.484361
 >> iter 83000, loss: 0.333157
 >> iter 84000, loss: 0.392077
 >> iter 85000, loss: 0.510990
 >> iter 86000, loss: 0.376808
 >> iter 87000, loss: 0.272785
 >> iter 88000, loss: 0.268049
 >> iter 89000, loss: 0.297208
 >> iter 90000, loss: 0.511089
   Number of active neurons: 4
 >> iter 91000, loss: 0.414415
 >> iter 92000, loss: 0.556492
 >> iter 93000, loss: 0.566596
 >> iter 94000, loss: 0.467671
 >> iter 95000, loss: 0.327720
 >> iter 96000, loss: 0.365952
 >> iter 97000, loss: 0.326357
 >> iter 98000, loss: 0.196530
 >> iter 99000, loss: 0.418758
 >> iter 100000, loss: 0.375897
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.760300
 >> iter 2000, loss: 9.211719
 >> iter 3000, loss: 4.276379
 >> iter 4000, loss: 2.032396
 >> iter 5000, loss: 1.046340
 >> iter 6000, loss: 0.776136
 >> iter 7000, loss: 0.518923
 >> iter 8000, loss: 0.406985
 >> iter 9000, loss: 0.421827
 >> iter 10000, loss: 0.362780
   Number of active neurons: 4
 >> iter 11000, loss: 0.402167
 >> iter 12000, loss: 0.561945
 >> iter 13000, loss: 0.289426
 >> iter 14000, loss: 0.395795
 >> iter 15000, loss: 0.257071
 >> iter 16000, loss: 0.224601
 >> iter 17000, loss: 0.196358
 >> iter 18000, loss: 0.503315
 >> iter 19000, loss: 0.526125
 >> iter 20000, loss: 0.459442
   Number of active neurons: 4
 >> iter 21000, loss: 0.432751
 >> iter 22000, loss: 0.238323
 >> iter 23000, loss: 0.308661
 >> iter 24000, loss: 0.338585
 >> iter 25000, loss: 0.258394
 >> iter 26000, loss: 0.303066
 >> iter 27000, loss: 0.376982
 >> iter 28000, loss: 0.406420
 >> iter 29000, loss: 0.266196
 >> iter 30000, loss: 0.243849
   Number of active neurons: 4
 >> iter 31000, loss: 0.296863
 >> iter 32000, loss: 0.487894
 >> iter 33000, loss: 0.385277
 >> iter 34000, loss: 0.243810
 >> iter 35000, loss: 0.205098
 >> iter 36000, loss: 0.217833
 >> iter 37000, loss: 0.145430
 >> iter 38000, loss: 0.260431
 >> iter 39000, loss: 0.271646
 >> iter 40000, loss: 0.378973
   Number of active neurons: 3
 >> iter 41000, loss: 0.275745
 >> iter 42000, loss: 0.281328
 >> iter 43000, loss: 0.250540
 >> iter 44000, loss: 0.377620
 >> iter 45000, loss: 0.201476
 >> iter 46000, loss: 0.165140
 >> iter 47000, loss: 0.330228
 >> iter 48000, loss: 0.329600
 >> iter 49000, loss: 0.272215
 >> iter 50000, loss: 0.195404
   Number of active neurons: 3
 >> iter 51000, loss: 0.216589
 >> iter 52000, loss: 0.227226
 >> iter 53000, loss: 0.218738
 >> iter 54000, loss: 0.344470
 >> iter 55000, loss: 0.277720
 >> iter 56000, loss: 0.241955
 >> iter 57000, loss: 0.287962
 >> iter 58000, loss: 0.298805
 >> iter 59000, loss: 0.273566
 >> iter 60000, loss: 0.261715
   Number of active neurons: 3
 >> iter 61000, loss: 0.192773
 >> iter 62000, loss: 0.191638
 >> iter 63000, loss: 0.242024
 >> iter 64000, loss: 0.252429
 >> iter 65000, loss: 0.177475
 >> iter 66000, loss: 0.222742
 >> iter 67000, loss: 0.217923
 >> iter 68000, loss: 0.241196
 >> iter 69000, loss: 0.238269
 >> iter 70000, loss: 0.147270
   Number of active neurons: 3
 >> iter 71000, loss: 0.209898
 >> iter 72000, loss: 0.201163
 >> iter 73000, loss: 0.184182
 >> iter 74000, loss: 0.318604
 >> iter 75000, loss: 0.273555
 >> iter 76000, loss: 0.440834
 >> iter 77000, loss: 0.246985
 >> iter 78000, loss: 0.340712
 >> iter 79000, loss: 0.331226
 >> iter 80000, loss: 0.205070
   Number of active neurons: 3
 >> iter 81000, loss: 0.152704
 >> iter 82000, loss: 0.196484
 >> iter 83000, loss: 0.333673
 >> iter 84000, loss: 0.438970
 >> iter 85000, loss: 0.329349
 >> iter 86000, loss: 0.304880
 >> iter 87000, loss: 0.239397
 >> iter 88000, loss: 0.218941
 >> iter 89000, loss: 0.186329
 >> iter 90000, loss: 0.234666
   Number of active neurons: 3
 >> iter 91000, loss: 0.118784
 >> iter 92000, loss: 0.254911
 >> iter 93000, loss: 0.133729
 >> iter 94000, loss: 0.396900
 >> iter 95000, loss: 0.257813
 >> iter 96000, loss: 0.318035
 >> iter 97000, loss: 0.239824
 >> iter 98000, loss: 0.461427
 >> iter 99000, loss: 0.226011
 >> iter 100000, loss: 0.111035
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

