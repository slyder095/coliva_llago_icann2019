 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.659537
 >> iter 2000, loss: 10.032881
 >> iter 3000, loss: 6.823483
 >> iter 4000, loss: 3.655414
 >> iter 5000, loss: 1.879989
 >> iter 6000, loss: 1.153215
 >> iter 7000, loss: 0.706577
 >> iter 8000, loss: 0.630821
 >> iter 9000, loss: 0.592531
 >> iter 10000, loss: 0.539105
   Number of active neurons: 8
 >> iter 11000, loss: 0.462315
 >> iter 12000, loss: 0.404887
 >> iter 13000, loss: 0.400711
 >> iter 14000, loss: 0.359524
 >> iter 15000, loss: 0.406238
 >> iter 16000, loss: 0.315343
 >> iter 17000, loss: 0.302627
 >> iter 18000, loss: 0.268407
 >> iter 19000, loss: 0.259378
 >> iter 20000, loss: 0.393516
   Number of active neurons: 7
 >> iter 21000, loss: 0.337738
 >> iter 22000, loss: 0.277953
 >> iter 23000, loss: 0.292808
 >> iter 24000, loss: 0.411049
 >> iter 25000, loss: 0.436900
 >> iter 26000, loss: 0.242494
 >> iter 27000, loss: 0.302730
 >> iter 28000, loss: 0.355167
 >> iter 29000, loss: 0.291925
 >> iter 30000, loss: 0.339113
   Number of active neurons: 7
 >> iter 31000, loss: 0.353765
 >> iter 32000, loss: 0.280766
 >> iter 33000, loss: 0.354266
 >> iter 34000, loss: 0.340865
 >> iter 35000, loss: 0.364495
 >> iter 36000, loss: 0.288621
 >> iter 37000, loss: 0.336457
 >> iter 38000, loss: 0.295374
 >> iter 39000, loss: 0.306893
 >> iter 40000, loss: 0.317343
   Number of active neurons: 6
 >> iter 41000, loss: 0.330081
 >> iter 42000, loss: 0.265740
 >> iter 43000, loss: 0.272631
 >> iter 44000, loss: 0.305274
 >> iter 45000, loss: 0.305121
 >> iter 46000, loss: 0.240666
 >> iter 47000, loss: 0.366652
 >> iter 48000, loss: 0.248332
 >> iter 49000, loss: 0.337566
 >> iter 50000, loss: 0.252527
   Number of active neurons: 6
 >> iter 51000, loss: 0.324153
 >> iter 52000, loss: 0.235634
 >> iter 53000, loss: 0.177901
 >> iter 54000, loss: 0.176970
 >> iter 55000, loss: 0.208896
 >> iter 56000, loss: 0.226340
 >> iter 57000, loss: 0.231563
 >> iter 58000, loss: 0.219958
 >> iter 59000, loss: 0.255096
 >> iter 60000, loss: 0.262185
   Number of active neurons: 6
 >> iter 61000, loss: 0.306051
 >> iter 62000, loss: 0.216121
 >> iter 63000, loss: 0.278007
 >> iter 64000, loss: 0.293217
 >> iter 65000, loss: 0.287275
 >> iter 66000, loss: 0.245925
 >> iter 67000, loss: 0.249033
 >> iter 68000, loss: 0.380113
 >> iter 69000, loss: 0.289579
 >> iter 70000, loss: 0.416747
   Number of active neurons: 6
 >> iter 71000, loss: 0.338631
 >> iter 72000, loss: 0.330700
 >> iter 73000, loss: 0.229407
 >> iter 74000, loss: 0.343461
 >> iter 75000, loss: 0.299978
 >> iter 76000, loss: 0.226057
 >> iter 77000, loss: 0.221350
 >> iter 78000, loss: 0.261680
 >> iter 79000, loss: 0.312237
 >> iter 80000, loss: 0.217076
   Number of active neurons: 6
 >> iter 81000, loss: 0.200832
 >> iter 82000, loss: 0.180084
 >> iter 83000, loss: 0.176226
 >> iter 84000, loss: 0.257667
 >> iter 85000, loss: 0.319232
 >> iter 86000, loss: 0.248671
 >> iter 87000, loss: 0.199910
 >> iter 88000, loss: 0.268998
 >> iter 89000, loss: 0.298789
 >> iter 90000, loss: 0.207013
   Number of active neurons: 5
 >> iter 91000, loss: 0.262346
 >> iter 92000, loss: 0.252054
 >> iter 93000, loss: 0.170489
 >> iter 94000, loss: 0.174380
 >> iter 95000, loss: 0.241123
 >> iter 96000, loss: 0.159419
 >> iter 97000, loss: 0.157839
 >> iter 98000, loss: 0.207187
 >> iter 99000, loss: 0.197659
 >> iter 100000, loss: 0.170577
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.662555
 >> iter 2000, loss: 10.548798
 >> iter 3000, loss: 5.819591
 >> iter 4000, loss: 2.804236
 >> iter 5000, loss: 1.358768
 >> iter 6000, loss: 0.756332
 >> iter 7000, loss: 0.532105
 >> iter 8000, loss: 0.496324
 >> iter 9000, loss: 0.403718
 >> iter 10000, loss: 0.393270
   Number of active neurons: 5
 >> iter 11000, loss: 0.338199
 >> iter 12000, loss: 0.362588
 >> iter 13000, loss: 0.363755
 >> iter 14000, loss: 0.473283
 >> iter 15000, loss: 0.389893
 >> iter 16000, loss: 0.488162
 >> iter 17000, loss: 0.418908
 >> iter 18000, loss: 0.322453
 >> iter 19000, loss: 0.401547
 >> iter 20000, loss: 0.326406
   Number of active neurons: 5
 >> iter 21000, loss: 0.309226
 >> iter 22000, loss: 0.349165
 >> iter 23000, loss: 0.316435
 >> iter 24000, loss: 0.318727
 >> iter 25000, loss: 0.335664
 >> iter 26000, loss: 0.305334
 >> iter 27000, loss: 0.290763
 >> iter 28000, loss: 0.329760
 >> iter 29000, loss: 0.388724
 >> iter 30000, loss: 0.338572
   Number of active neurons: 5
 >> iter 31000, loss: 0.312700
 >> iter 32000, loss: 0.256832
 >> iter 33000, loss: 0.217628
 >> iter 34000, loss: 0.346556
 >> iter 35000, loss: 0.329053
 >> iter 36000, loss: 0.284335
 >> iter 37000, loss: 0.360874
 >> iter 38000, loss: 0.367773
 >> iter 39000, loss: 0.333176
 >> iter 40000, loss: 0.344441
   Number of active neurons: 5
 >> iter 41000, loss: 0.306588
 >> iter 42000, loss: 0.284605
 >> iter 43000, loss: 0.249590
 >> iter 44000, loss: 0.307512
 >> iter 45000, loss: 0.319234
 >> iter 46000, loss: 0.284983
 >> iter 47000, loss: 0.345544
 >> iter 48000, loss: 0.442014
 >> iter 49000, loss: 0.381492
 >> iter 50000, loss: 0.292243
   Number of active neurons: 5
 >> iter 51000, loss: 0.496884
 >> iter 52000, loss: 0.432786
 >> iter 53000, loss: 0.405491
 >> iter 54000, loss: 0.385667
 >> iter 55000, loss: 0.387828
 >> iter 56000, loss: 0.239516
 >> iter 57000, loss: 0.456910
 >> iter 58000, loss: 0.348652
 >> iter 59000, loss: 0.485700
 >> iter 60000, loss: 0.488609
   Number of active neurons: 4
 >> iter 61000, loss: 0.404697
 >> iter 62000, loss: 0.365239
 >> iter 63000, loss: 0.345823
 >> iter 64000, loss: 0.396157
 >> iter 65000, loss: 0.350234
 >> iter 66000, loss: 0.372157
 >> iter 67000, loss: 0.301625
 >> iter 68000, loss: 0.370645
 >> iter 69000, loss: 0.388601
 >> iter 70000, loss: 0.379468
   Number of active neurons: 4
 >> iter 71000, loss: 0.400856
 >> iter 72000, loss: 0.435950
 >> iter 73000, loss: 0.499200
 >> iter 74000, loss: 0.359482
 >> iter 75000, loss: 0.410547
 >> iter 76000, loss: 0.442116
 >> iter 77000, loss: 0.431527
 >> iter 78000, loss: 0.440164
 >> iter 79000, loss: 0.365280
 >> iter 80000, loss: 0.471943
   Number of active neurons: 4
 >> iter 81000, loss: 0.352801
 >> iter 82000, loss: 0.338385
 >> iter 83000, loss: 0.373856
 >> iter 84000, loss: 0.433897
 >> iter 85000, loss: 0.381759
 >> iter 86000, loss: 0.464290
 >> iter 87000, loss: 0.476148
 >> iter 88000, loss: 0.413157
 >> iter 89000, loss: 0.456366
 >> iter 90000, loss: 0.524030
   Number of active neurons: 4
 >> iter 91000, loss: 0.516542
 >> iter 92000, loss: 0.494120
 >> iter 93000, loss: 0.467189
 >> iter 94000, loss: 0.491784
 >> iter 95000, loss: 0.448876
 >> iter 96000, loss: 0.410599
 >> iter 97000, loss: 0.580643
 >> iter 98000, loss: 0.503163
 >> iter 99000, loss: 0.543139
 >> iter 100000, loss: 0.519320
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.828075
 >> iter 2000, loss: 9.702009
 >> iter 3000, loss: 5.264041
 >> iter 4000, loss: 2.718676
 >> iter 5000, loss: 1.529763
 >> iter 6000, loss: 0.870993
 >> iter 7000, loss: 0.635631
 >> iter 8000, loss: 0.406377
 >> iter 9000, loss: 0.403921
 >> iter 10000, loss: 0.487193
   Number of active neurons: 7
 >> iter 11000, loss: 0.468306
 >> iter 12000, loss: 0.331321
 >> iter 13000, loss: 0.304888
 >> iter 14000, loss: 0.347270
 >> iter 15000, loss: 0.290784
 >> iter 16000, loss: 0.377942
 >> iter 17000, loss: 0.377284
 >> iter 18000, loss: 0.352677
 >> iter 19000, loss: 0.311216
 >> iter 20000, loss: 0.506613
   Number of active neurons: 7
 >> iter 21000, loss: 0.388131
 >> iter 22000, loss: 0.420454
 >> iter 23000, loss: 0.498252
 >> iter 24000, loss: 0.522120
 >> iter 25000, loss: 0.440359
 >> iter 26000, loss: 0.512740
 >> iter 27000, loss: 0.693802
 >> iter 28000, loss: 0.459481
 >> iter 29000, loss: 0.412704
 >> iter 30000, loss: 0.468536
   Number of active neurons: 7
 >> iter 31000, loss: 0.476108
 >> iter 32000, loss: 0.438594
 >> iter 33000, loss: 0.471989
 >> iter 34000, loss: 0.501709
 >> iter 35000, loss: 0.459097
 >> iter 36000, loss: 0.527796
 >> iter 37000, loss: 0.496963
 >> iter 38000, loss: 0.456030
 >> iter 39000, loss: 0.368251
 >> iter 40000, loss: 0.520671
   Number of active neurons: 7
 >> iter 41000, loss: 0.415432
 >> iter 42000, loss: 0.300571
 >> iter 43000, loss: 0.475882
 >> iter 44000, loss: 0.355764
 >> iter 45000, loss: 0.576602
 >> iter 46000, loss: 0.445082
 >> iter 47000, loss: 0.473771
 >> iter 48000, loss: 0.498370
 >> iter 49000, loss: 0.431207
 >> iter 50000, loss: 0.346974
   Number of active neurons: 7
 >> iter 51000, loss: 0.491386
 >> iter 52000, loss: 0.415570
 >> iter 53000, loss: 0.304268
 >> iter 54000, loss: 0.363438
 >> iter 55000, loss: 0.334446
 >> iter 56000, loss: 0.344093
 >> iter 57000, loss: 0.381243
 >> iter 58000, loss: 0.310942
 >> iter 59000, loss: 0.304062
 >> iter 60000, loss: 0.379305
   Number of active neurons: 7
 >> iter 61000, loss: 0.522471
 >> iter 62000, loss: 0.461171
 >> iter 63000, loss: 0.428297
 >> iter 64000, loss: 0.466794
 >> iter 65000, loss: 0.384057
 >> iter 66000, loss: 0.483741
 >> iter 67000, loss: 0.565809
 >> iter 68000, loss: 0.403030
 >> iter 69000, loss: 0.358435
 >> iter 70000, loss: 0.317920
   Number of active neurons: 7
 >> iter 71000, loss: 0.288844
 >> iter 72000, loss: 0.287307
 >> iter 73000, loss: 0.322424
 >> iter 74000, loss: 0.354232
 >> iter 75000, loss: 0.418120
 >> iter 76000, loss: 0.566826
 >> iter 77000, loss: 0.405443
 >> iter 78000, loss: 0.397150
 >> iter 79000, loss: 0.374996
 >> iter 80000, loss: 0.368942
   Number of active neurons: 7
 >> iter 81000, loss: 0.428600
 >> iter 82000, loss: 0.371072
 >> iter 83000, loss: 0.388614
 >> iter 84000, loss: 0.329225
 >> iter 85000, loss: 0.299247
 >> iter 86000, loss: 0.360857
 >> iter 87000, loss: 0.315501
 >> iter 88000, loss: 0.324598
 >> iter 89000, loss: 0.410390
 >> iter 90000, loss: 0.411341
   Number of active neurons: 7
 >> iter 91000, loss: 0.277919
 >> iter 92000, loss: 0.276458
 >> iter 93000, loss: 0.370341
 >> iter 94000, loss: 0.310342
 >> iter 95000, loss: 0.305144
 >> iter 96000, loss: 0.426716
 >> iter 97000, loss: 0.365542
 >> iter 98000, loss: 0.311520
 >> iter 99000, loss: 0.416640
 >> iter 100000, loss: 0.309011
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.505771
 >> iter 2000, loss: 11.962130
 >> iter 3000, loss: 10.171508
 >> iter 4000, loss: 8.938559
 >> iter 5000, loss: 7.790427
 >> iter 6000, loss: 5.902197
 >> iter 7000, loss: 3.550792
 >> iter 8000, loss: 2.114254
 >> iter 9000, loss: 1.272255
 >> iter 10000, loss: 1.023120
   Number of active neurons: 7
 >> iter 11000, loss: 0.867035
 >> iter 12000, loss: 0.801964
 >> iter 13000, loss: 0.602543
 >> iter 14000, loss: 0.619538
 >> iter 15000, loss: 0.681706
 >> iter 16000, loss: 0.637868
 >> iter 17000, loss: 0.585193
 >> iter 18000, loss: 0.568076
 >> iter 19000, loss: 0.604401
 >> iter 20000, loss: 0.637746
   Number of active neurons: 5
 >> iter 21000, loss: 0.522018
 >> iter 22000, loss: 0.535817
 >> iter 23000, loss: 0.501131
 >> iter 24000, loss: 0.390972
 >> iter 25000, loss: 0.479512
 >> iter 26000, loss: 0.569034
 >> iter 27000, loss: 0.618573
 >> iter 28000, loss: 0.612205
 >> iter 29000, loss: 0.589883
 >> iter 30000, loss: 0.590889
   Number of active neurons: 5
 >> iter 31000, loss: 0.634580
 >> iter 32000, loss: 0.550468
 >> iter 33000, loss: 0.605994
 >> iter 34000, loss: 0.463184
 >> iter 35000, loss: 0.533596
 >> iter 36000, loss: 0.503115
 >> iter 37000, loss: 0.530549
 >> iter 38000, loss: 0.560598
 >> iter 39000, loss: 0.477768
 >> iter 40000, loss: 0.421060
   Number of active neurons: 4
 >> iter 41000, loss: 0.411756
 >> iter 42000, loss: 0.464302
 >> iter 43000, loss: 0.520593
 >> iter 44000, loss: 0.593321
 >> iter 45000, loss: 0.559085
 >> iter 46000, loss: 0.473007
 >> iter 47000, loss: 0.371547
 >> iter 48000, loss: 0.568523
 >> iter 49000, loss: 0.591369
 >> iter 50000, loss: 0.524870
   Number of active neurons: 4
 >> iter 51000, loss: 0.427980
 >> iter 52000, loss: 0.509251
 >> iter 53000, loss: 0.551598
 >> iter 54000, loss: 0.536291
 >> iter 55000, loss: 0.628496
 >> iter 56000, loss: 0.540688
 >> iter 57000, loss: 0.578600
 >> iter 58000, loss: 0.650773
 >> iter 59000, loss: 0.600205
 >> iter 60000, loss: 0.582254
   Number of active neurons: 4
 >> iter 61000, loss: 0.574871
 >> iter 62000, loss: 0.582674
 >> iter 63000, loss: 0.568121
 >> iter 64000, loss: 0.385512
 >> iter 65000, loss: 0.385813
 >> iter 66000, loss: 0.467233
 >> iter 67000, loss: 0.580508
 >> iter 68000, loss: 0.452404
 >> iter 69000, loss: 0.410608
 >> iter 70000, loss: 0.606582
   Number of active neurons: 4
 >> iter 71000, loss: 0.503220
 >> iter 72000, loss: 0.536619
 >> iter 73000, loss: 0.500848
 >> iter 74000, loss: 0.590126
 >> iter 75000, loss: 0.650988
 >> iter 76000, loss: 0.498052
 >> iter 77000, loss: 0.408339
 >> iter 78000, loss: 0.444795
 >> iter 79000, loss: 0.534945
 >> iter 80000, loss: 0.597686
   Number of active neurons: 5
 >> iter 81000, loss: 0.533453
 >> iter 82000, loss: 0.554019
 >> iter 83000, loss: 0.468715
 >> iter 84000, loss: 0.643795
 >> iter 85000, loss: 0.458809
 >> iter 86000, loss: 0.564933
 >> iter 87000, loss: 0.535110
 >> iter 88000, loss: 0.522095
 >> iter 89000, loss: 0.412839
 >> iter 90000, loss: 0.472366
   Number of active neurons: 4
 >> iter 91000, loss: 0.593353
 >> iter 92000, loss: 0.533169
 >> iter 93000, loss: 0.429948
 >> iter 94000, loss: 0.502301
 >> iter 95000, loss: 0.435095
 >> iter 96000, loss: 0.430911
 >> iter 97000, loss: 0.509323
 >> iter 98000, loss: 0.383815
 >> iter 99000, loss: 0.482436
 >> iter 100000, loss: 0.407383
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.938141
 >> iter 2000, loss: 11.430352
 >> iter 3000, loss: 7.875380
 >> iter 4000, loss: 4.830759
 >> iter 5000, loss: 3.030718
 >> iter 6000, loss: 1.406899
 >> iter 7000, loss: 1.107810
 >> iter 8000, loss: 0.714088
 >> iter 9000, loss: 0.617751
 >> iter 10000, loss: 0.557153
   Number of active neurons: 10
 >> iter 11000, loss: 0.333852
 >> iter 12000, loss: 0.352397
 >> iter 13000, loss: 0.258680
 >> iter 14000, loss: 0.193324
 >> iter 15000, loss: 0.200923
 >> iter 16000, loss: 0.224106
 >> iter 17000, loss: 0.186355
 >> iter 18000, loss: 0.197698
 >> iter 19000, loss: 0.259408
 >> iter 20000, loss: 0.237202
   Number of active neurons: 9
 >> iter 21000, loss: 0.301321
 >> iter 22000, loss: 0.235438
 >> iter 23000, loss: 0.226734
 >> iter 24000, loss: 0.189191
 >> iter 25000, loss: 0.255201
 >> iter 26000, loss: 0.271736
 >> iter 27000, loss: 0.240831
 >> iter 28000, loss: 0.346411
 >> iter 29000, loss: 0.259442
 >> iter 30000, loss: 0.313575
   Number of active neurons: 9
 >> iter 31000, loss: 0.304616
 >> iter 32000, loss: 0.273576
 >> iter 33000, loss: 0.260749
 >> iter 34000, loss: 0.282583
 >> iter 35000, loss: 0.289719
 >> iter 36000, loss: 0.401253
 >> iter 37000, loss: 0.293607
 >> iter 38000, loss: 0.360010
 >> iter 39000, loss: 0.293456
 >> iter 40000, loss: 0.342415
   Number of active neurons: 9
 >> iter 41000, loss: 0.329799
 >> iter 42000, loss: 0.271903
 >> iter 43000, loss: 0.275810
 >> iter 44000, loss: 0.232225
 >> iter 45000, loss: 0.175914
 >> iter 46000, loss: 0.214997
 >> iter 47000, loss: 0.179331
 >> iter 48000, loss: 0.206307
 >> iter 49000, loss: 0.278250
 >> iter 50000, loss: 0.286386
   Number of active neurons: 8
 >> iter 51000, loss: 0.184453
 >> iter 52000, loss: 0.319067
 >> iter 53000, loss: 0.446732
 >> iter 54000, loss: 0.441322
 >> iter 55000, loss: 0.344467
 >> iter 56000, loss: 0.310328
 >> iter 57000, loss: 0.451087
 >> iter 58000, loss: 0.380340
 >> iter 59000, loss: 0.313350
 >> iter 60000, loss: 0.256306
   Number of active neurons: 6
 >> iter 61000, loss: 0.217097
 >> iter 62000, loss: 0.348259
 >> iter 63000, loss: 0.316618
 >> iter 64000, loss: 0.306576
 >> iter 65000, loss: 0.319948
 >> iter 66000, loss: 0.380985
 >> iter 67000, loss: 0.372100
 >> iter 68000, loss: 0.295098
 >> iter 69000, loss: 0.214935
 >> iter 70000, loss: 0.308372
   Number of active neurons: 6
 >> iter 71000, loss: 0.278045
 >> iter 72000, loss: 0.264772
 >> iter 73000, loss: 0.339280
 >> iter 74000, loss: 0.222303
 >> iter 75000, loss: 0.245539
 >> iter 76000, loss: 0.230122
 >> iter 77000, loss: 0.267320
 >> iter 78000, loss: 0.258612
 >> iter 79000, loss: 0.458329
 >> iter 80000, loss: 0.361363
   Number of active neurons: 6
 >> iter 81000, loss: 0.378204
 >> iter 82000, loss: 0.396330
 >> iter 83000, loss: 0.428312
 >> iter 84000, loss: 0.430853
 >> iter 85000, loss: 0.310925
 >> iter 86000, loss: 0.223968
 >> iter 87000, loss: 0.312710
 >> iter 88000, loss: 0.396640
 >> iter 89000, loss: 0.312032
 >> iter 90000, loss: 0.256871
   Number of active neurons: 6
 >> iter 91000, loss: 0.234285
 >> iter 92000, loss: 0.242633
 >> iter 93000, loss: 0.230988
 >> iter 94000, loss: 0.245333
 >> iter 95000, loss: 0.252541
 >> iter 96000, loss: 0.259487
 >> iter 97000, loss: 0.206827
 >> iter 98000, loss: 0.221630
 >> iter 99000, loss: 0.303878
 >> iter 100000, loss: 0.283253
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.083050
 >> iter 2000, loss: 10.353666
 >> iter 3000, loss: 6.197366
 >> iter 4000, loss: 3.237445
 >> iter 5000, loss: 1.626748
 >> iter 6000, loss: 0.928024
 >> iter 7000, loss: 0.827956
 >> iter 8000, loss: 0.562355
 >> iter 9000, loss: 0.431154
 >> iter 10000, loss: 0.419221
   Number of active neurons: 7
 >> iter 11000, loss: 0.435123
 >> iter 12000, loss: 0.352724
 >> iter 13000, loss: 0.615614
 >> iter 14000, loss: 0.455449
 >> iter 15000, loss: 0.393318
 >> iter 16000, loss: 0.382263
 >> iter 17000, loss: 0.442739
 >> iter 18000, loss: 0.334871
 >> iter 19000, loss: 0.357733
 >> iter 20000, loss: 0.313365
   Number of active neurons: 7
 >> iter 21000, loss: 0.399119
 >> iter 22000, loss: 0.271308
 >> iter 23000, loss: 0.331709
 >> iter 24000, loss: 0.644365
 >> iter 25000, loss: 0.470891
 >> iter 26000, loss: 0.477380
 >> iter 27000, loss: 0.543141
 >> iter 28000, loss: 0.478438
 >> iter 29000, loss: 0.669657
 >> iter 30000, loss: 0.566524
   Number of active neurons: 7
 >> iter 31000, loss: 0.852937
 >> iter 32000, loss: 0.548368
 >> iter 33000, loss: 0.545166
 >> iter 34000, loss: 0.418907
 >> iter 35000, loss: 0.378867
 >> iter 36000, loss: 0.510061
 >> iter 37000, loss: 0.395986
 >> iter 38000, loss: 0.435998
 >> iter 39000, loss: 0.298479
 >> iter 40000, loss: 0.405746
   Number of active neurons: 7
 >> iter 41000, loss: 0.548320
 >> iter 42000, loss: 0.608136
 >> iter 43000, loss: 0.593968
 >> iter 44000, loss: 0.481733
 >> iter 45000, loss: 0.571565
 >> iter 46000, loss: 0.587311
 >> iter 47000, loss: 0.544961
 >> iter 48000, loss: 0.473024
 >> iter 49000, loss: 0.505175
 >> iter 50000, loss: 0.496749
   Number of active neurons: 7
 >> iter 51000, loss: 0.605069
 >> iter 52000, loss: 0.454414
 >> iter 53000, loss: 0.521878
 >> iter 54000, loss: 0.470437
 >> iter 55000, loss: 0.535386
 >> iter 56000, loss: 0.479700
 >> iter 57000, loss: 0.381111
 >> iter 58000, loss: 0.469081
 >> iter 59000, loss: 0.451801
 >> iter 60000, loss: 0.378837
   Number of active neurons: 7
 >> iter 61000, loss: 0.326075
 >> iter 62000, loss: 0.351871
 >> iter 63000, loss: 0.415656
 >> iter 64000, loss: 0.476342
 >> iter 65000, loss: 0.518194
 >> iter 66000, loss: 0.450673
 >> iter 67000, loss: 0.366605
 >> iter 68000, loss: 0.375064
 >> iter 69000, loss: 0.313711
 >> iter 70000, loss: 0.276924
   Number of active neurons: 6
 >> iter 71000, loss: 0.260613
 >> iter 72000, loss: 0.295666
 >> iter 73000, loss: 0.356365
 >> iter 74000, loss: 0.434820
 >> iter 75000, loss: 0.517247
 >> iter 76000, loss: 0.430834
 >> iter 77000, loss: 0.417708
 >> iter 78000, loss: 0.442145
 >> iter 79000, loss: 0.520513
 >> iter 80000, loss: 0.319307
   Number of active neurons: 6
 >> iter 81000, loss: 0.363523
 >> iter 82000, loss: 0.504456
 >> iter 83000, loss: 0.300313
 >> iter 84000, loss: 0.343231
 >> iter 85000, loss: 0.576889
 >> iter 86000, loss: 0.505462
 >> iter 87000, loss: 0.591403
 >> iter 88000, loss: 0.539426
 >> iter 89000, loss: 0.439961
 >> iter 90000, loss: 0.601516
   Number of active neurons: 6
 >> iter 91000, loss: 0.383000
 >> iter 92000, loss: 0.426546
 >> iter 93000, loss: 0.425053
 >> iter 94000, loss: 0.469288
 >> iter 95000, loss: 0.423080
 >> iter 96000, loss: 0.371879
 >> iter 97000, loss: 0.337763
 >> iter 98000, loss: 0.378710
 >> iter 99000, loss: 0.525879
 >> iter 100000, loss: 0.637975
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 17.160035
 >> iter 2000, loss: 11.204116
 >> iter 3000, loss: 7.591987
 >> iter 4000, loss: 3.882935
 >> iter 5000, loss: 1.961252
 >> iter 6000, loss: 1.059923
 >> iter 7000, loss: 0.928647
 >> iter 8000, loss: 0.576092
 >> iter 9000, loss: 0.488932
 >> iter 10000, loss: 0.492081
   Number of active neurons: 9
 >> iter 11000, loss: 0.446869
 >> iter 12000, loss: 0.364201
 >> iter 13000, loss: 0.460506
 >> iter 14000, loss: 0.359805
 >> iter 15000, loss: 0.316177
 >> iter 16000, loss: 0.303301
 >> iter 17000, loss: 0.329746
 >> iter 18000, loss: 0.300390
 >> iter 19000, loss: 0.280927
 >> iter 20000, loss: 0.360978
   Number of active neurons: 9
 >> iter 21000, loss: 0.437997
 >> iter 22000, loss: 0.333062
 >> iter 23000, loss: 0.266221
 >> iter 24000, loss: 0.259915
 >> iter 25000, loss: 0.227590
 >> iter 26000, loss: 0.266831
 >> iter 27000, loss: 0.307933
 >> iter 28000, loss: 0.271393
 >> iter 29000, loss: 0.215169
 >> iter 30000, loss: 0.246680
   Number of active neurons: 8
 >> iter 31000, loss: 0.290419
 >> iter 32000, loss: 0.402164
 >> iter 33000, loss: 0.302166
 >> iter 34000, loss: 0.256174
 >> iter 35000, loss: 0.254646
 >> iter 36000, loss: 0.235128
 >> iter 37000, loss: 0.266108
 >> iter 38000, loss: 0.218305
 >> iter 39000, loss: 0.298109
 >> iter 40000, loss: 0.341450
   Number of active neurons: 8
 >> iter 41000, loss: 0.336263
 >> iter 42000, loss: 0.314984
 >> iter 43000, loss: 0.382326
 >> iter 44000, loss: 0.282501
 >> iter 45000, loss: 0.263263
 >> iter 46000, loss: 0.279035
 >> iter 47000, loss: 0.188129
 >> iter 48000, loss: 0.265198
 >> iter 49000, loss: 0.250767
 >> iter 50000, loss: 0.283031
   Number of active neurons: 8
 >> iter 51000, loss: 0.301842
 >> iter 52000, loss: 0.327077
 >> iter 53000, loss: 0.365717
 >> iter 54000, loss: 0.289872
 >> iter 55000, loss: 0.293349
 >> iter 56000, loss: 0.315313
 >> iter 57000, loss: 0.263164
 >> iter 58000, loss: 0.279416
 >> iter 59000, loss: 0.266564
 >> iter 60000, loss: 0.217882
   Number of active neurons: 8
 >> iter 61000, loss: 0.249564
 >> iter 62000, loss: 0.201324
 >> iter 63000, loss: 0.406477
 >> iter 64000, loss: 0.391965
 >> iter 65000, loss: 0.271007
 >> iter 66000, loss: 0.224226
 >> iter 67000, loss: 0.242229
 >> iter 68000, loss: 0.396868
 >> iter 69000, loss: 0.376527
 >> iter 70000, loss: 0.219380
   Number of active neurons: 7
 >> iter 71000, loss: 0.293462
 >> iter 72000, loss: 0.275186
 >> iter 73000, loss: 0.336263
 >> iter 74000, loss: 0.315372
 >> iter 75000, loss: 0.374632
 >> iter 76000, loss: 0.277806
 >> iter 77000, loss: 0.267203
 >> iter 78000, loss: 0.268185
 >> iter 79000, loss: 0.277593
 >> iter 80000, loss: 0.329359
   Number of active neurons: 7
 >> iter 81000, loss: 0.297589
 >> iter 82000, loss: 0.226528
 >> iter 83000, loss: 0.271107
 >> iter 84000, loss: 0.212244
 >> iter 85000, loss: 0.212919
 >> iter 86000, loss: 0.240054
 >> iter 87000, loss: 0.289041
 >> iter 88000, loss: 0.319034
 >> iter 89000, loss: 0.265811
 >> iter 90000, loss: 0.313962
   Number of active neurons: 7
 >> iter 91000, loss: 0.260419
 >> iter 92000, loss: 0.263794
 >> iter 93000, loss: 0.281324
 >> iter 94000, loss: 0.324523
 >> iter 95000, loss: 0.365816
 >> iter 96000, loss: 0.357914
 >> iter 97000, loss: 0.327291
 >> iter 98000, loss: 0.326047
 >> iter 99000, loss: 0.261407
 >> iter 100000, loss: 0.220023
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.200256
 >> iter 2000, loss: 10.681048
 >> iter 3000, loss: 6.388579
 >> iter 4000, loss: 3.489594
 >> iter 5000, loss: 2.162160
 >> iter 6000, loss: 1.325298
 >> iter 7000, loss: 0.900089
 >> iter 8000, loss: 0.798841
 >> iter 9000, loss: 0.721940
 >> iter 10000, loss: 0.809249
   Number of active neurons: 6
 >> iter 11000, loss: 0.744298
 >> iter 12000, loss: 0.639282
 >> iter 13000, loss: 0.596488
 >> iter 14000, loss: 0.651008
 >> iter 15000, loss: 0.699209
 >> iter 16000, loss: 0.579575
 >> iter 17000, loss: 0.596138
 >> iter 18000, loss: 0.773519
 >> iter 19000, loss: 0.789690
 >> iter 20000, loss: 0.680979
   Number of active neurons: 5
 >> iter 21000, loss: 0.799020
 >> iter 22000, loss: 0.551318
 >> iter 23000, loss: 0.596202
 >> iter 24000, loss: 0.511718
 >> iter 25000, loss: 0.526097
 >> iter 26000, loss: 0.604823
 >> iter 27000, loss: 0.502929
 >> iter 28000, loss: 0.434467
 >> iter 29000, loss: 0.525188
 >> iter 30000, loss: 0.540403
   Number of active neurons: 5
 >> iter 31000, loss: 0.487455
 >> iter 32000, loss: 0.499383
 >> iter 33000, loss: 0.482448
 >> iter 34000, loss: 0.515439
 >> iter 35000, loss: 0.481542
 >> iter 36000, loss: 0.463376
 >> iter 37000, loss: 0.535975
 >> iter 38000, loss: 0.524344
 >> iter 39000, loss: 0.537105
 >> iter 40000, loss: 0.443341
   Number of active neurons: 5
 >> iter 41000, loss: 0.614877
 >> iter 42000, loss: 0.461651
 >> iter 43000, loss: 0.644214
 >> iter 44000, loss: 0.596668
 >> iter 45000, loss: 0.429895
 >> iter 46000, loss: 0.441226
 >> iter 47000, loss: 0.496195
 >> iter 48000, loss: 0.622506
 >> iter 49000, loss: 0.529136
 >> iter 50000, loss: 0.562119
   Number of active neurons: 4
 >> iter 51000, loss: 0.511693
 >> iter 52000, loss: 0.576679
 >> iter 53000, loss: 0.533218
 >> iter 54000, loss: 0.576733
 >> iter 55000, loss: 0.596547
 >> iter 56000, loss: 0.551348
 >> iter 57000, loss: 0.392525
 >> iter 58000, loss: 0.527351
 >> iter 59000, loss: 0.508993
 >> iter 60000, loss: 0.504055
   Number of active neurons: 4
 >> iter 61000, loss: 0.619500
 >> iter 62000, loss: 0.601292
 >> iter 63000, loss: 0.539894
 >> iter 64000, loss: 0.462805
 >> iter 65000, loss: 0.429566
 >> iter 66000, loss: 0.456991
 >> iter 67000, loss: 0.523569
 >> iter 68000, loss: 0.668239
 >> iter 69000, loss: 0.628749
 >> iter 70000, loss: 0.646654
   Number of active neurons: 4
 >> iter 71000, loss: 0.601557
 >> iter 72000, loss: 0.657967
 >> iter 73000, loss: 0.603845
 >> iter 74000, loss: 0.486348
 >> iter 75000, loss: 0.564279
 >> iter 76000, loss: 0.425269
 >> iter 77000, loss: 0.469545
 >> iter 78000, loss: 0.513703
 >> iter 79000, loss: 0.552995
 >> iter 80000, loss: 0.680079
   Number of active neurons: 4
 >> iter 81000, loss: 0.475244
 >> iter 82000, loss: 0.386355
 >> iter 83000, loss: 0.528798
 >> iter 84000, loss: 0.572896
 >> iter 85000, loss: 0.609617
 >> iter 86000, loss: 0.643685
 >> iter 87000, loss: 0.613754
 >> iter 88000, loss: 0.532698
 >> iter 89000, loss: 0.447408
 >> iter 90000, loss: 0.545081
   Number of active neurons: 4
 >> iter 91000, loss: 0.627159
 >> iter 92000, loss: 0.718582
 >> iter 93000, loss: 0.656343
 >> iter 94000, loss: 0.617335
 >> iter 95000, loss: 0.623075
 >> iter 96000, loss: 0.381350
 >> iter 97000, loss: 0.369072
 >> iter 98000, loss: 0.407796
 >> iter 99000, loss: 0.494789
 >> iter 100000, loss: 0.437993
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 21.2852476502
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.620870
 >> iter 2000, loss: 11.581131
 >> iter 3000, loss: 7.995715
 >> iter 4000, loss: 4.849812
 >> iter 5000, loss: 2.516865
 >> iter 6000, loss: 1.422167
 >> iter 7000, loss: 0.812716
 >> iter 8000, loss: 0.678908
 >> iter 9000, loss: 0.620349
 >> iter 10000, loss: 0.506693
   Number of active neurons: 10
 >> iter 11000, loss: 0.573601
 >> iter 12000, loss: 0.494633
 >> iter 13000, loss: 0.445770
 >> iter 14000, loss: 0.567785
 >> iter 15000, loss: 0.550273
 >> iter 16000, loss: 0.461046
 >> iter 17000, loss: 0.472887
 >> iter 18000, loss: 0.469819
 >> iter 19000, loss: 0.447371
 >> iter 20000, loss: 0.358599
   Number of active neurons: 9
 >> iter 21000, loss: 0.424518
 >> iter 22000, loss: 0.480492
 >> iter 23000, loss: 0.448937
 >> iter 24000, loss: 0.495739
 >> iter 25000, loss: 0.369894
 >> iter 26000, loss: 0.480151
 >> iter 27000, loss: 0.476109
 >> iter 28000, loss: 0.425272
 >> iter 29000, loss: 0.382718
 >> iter 30000, loss: 0.460084
   Number of active neurons: 9
 >> iter 31000, loss: 0.593058
 >> iter 32000, loss: 0.451685
 >> iter 33000, loss: 0.445760
 >> iter 34000, loss: 0.443482
 >> iter 35000, loss: 0.466040
 >> iter 36000, loss: 0.424485
 >> iter 37000, loss: 0.484099
 >> iter 38000, loss: 0.490857
 >> iter 39000, loss: 0.367408
 >> iter 40000, loss: 0.505657
   Number of active neurons: 8
 >> iter 41000, loss: 0.469949
 >> iter 42000, loss: 0.356625
 >> iter 43000, loss: 0.333832
 >> iter 44000, loss: 0.366582
 >> iter 45000, loss: 0.477286
 >> iter 46000, loss: 0.366175
 >> iter 47000, loss: 0.333108
 >> iter 48000, loss: 0.348677
 >> iter 49000, loss: 0.373817
 >> iter 50000, loss: 0.530920
   Number of active neurons: 8
 >> iter 51000, loss: 0.454239
 >> iter 52000, loss: 0.341720
 >> iter 53000, loss: 0.242778
 >> iter 54000, loss: 0.276450
 >> iter 55000, loss: 0.281855
 >> iter 56000, loss: 0.379350
 >> iter 57000, loss: 0.507916
 >> iter 58000, loss: 0.382187
 >> iter 59000, loss: 0.463483
 >> iter 60000, loss: 0.477987
   Number of active neurons: 7
 >> iter 61000, loss: 0.428525
 >> iter 62000, loss: 0.376319
 >> iter 63000, loss: 0.403250
 >> iter 64000, loss: 0.347833
 >> iter 65000, loss: 0.279805
 >> iter 66000, loss: 0.210011
 >> iter 67000, loss: 0.182526
 >> iter 68000, loss: 0.208568
 >> iter 69000, loss: 0.266755
 >> iter 70000, loss: 0.332788
   Number of active neurons: 7
 >> iter 71000, loss: 0.250146
 >> iter 72000, loss: 0.400888
 >> iter 73000, loss: 0.445925
 >> iter 74000, loss: 0.386525
 >> iter 75000, loss: 0.310943
 >> iter 76000, loss: 0.318339
 >> iter 77000, loss: 0.262568
 >> iter 78000, loss: 0.300991
 >> iter 79000, loss: 0.319488
 >> iter 80000, loss: 0.347143
   Number of active neurons: 7
 >> iter 81000, loss: 0.364195
 >> iter 82000, loss: 0.326586
 >> iter 83000, loss: 0.284608
 >> iter 84000, loss: 0.266348
 >> iter 85000, loss: 0.293447
 >> iter 86000, loss: 0.273325
 >> iter 87000, loss: 0.214951
 >> iter 88000, loss: 0.240084
 >> iter 89000, loss: 0.323608
 >> iter 90000, loss: 0.257382
   Number of active neurons: 7
 >> iter 91000, loss: 0.251321
 >> iter 92000, loss: 0.301329
 >> iter 93000, loss: 0.271407
 >> iter 94000, loss: 0.259664
 >> iter 95000, loss: 0.272058
 >> iter 96000, loss: 0.206741
 >> iter 97000, loss: 0.284859
 >> iter 98000, loss: 0.287019
 >> iter 99000, loss: 0.259457
 >> iter 100000, loss: 0.328454
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 8.37944137058
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.538060
 >> iter 2000, loss: 10.782855
 >> iter 3000, loss: 5.966876
 >> iter 4000, loss: 3.200406
 >> iter 5000, loss: 1.717124
 >> iter 6000, loss: 0.998664
 >> iter 7000, loss: 0.660972
 >> iter 8000, loss: 0.575580
 >> iter 9000, loss: 0.584501
 >> iter 10000, loss: 0.514005
   Number of active neurons: 5
 >> iter 11000, loss: 0.485736
 >> iter 12000, loss: 0.570458
 >> iter 13000, loss: 0.448554
 >> iter 14000, loss: 0.394438
 >> iter 15000, loss: 0.424519
 >> iter 16000, loss: 0.413574
 >> iter 17000, loss: 0.362291
 >> iter 18000, loss: 0.388130
 >> iter 19000, loss: 0.367418
 >> iter 20000, loss: 0.496021
   Number of active neurons: 5
 >> iter 21000, loss: 0.533810
 >> iter 22000, loss: 0.571226
 >> iter 23000, loss: 0.613458
 >> iter 24000, loss: 0.540448
 >> iter 25000, loss: 0.514134
 >> iter 26000, loss: 0.366419
 >> iter 27000, loss: 0.433139
 >> iter 28000, loss: 0.379713
 >> iter 29000, loss: 0.418175
 >> iter 30000, loss: 0.424000
   Number of active neurons: 5
 >> iter 31000, loss: 0.432103
 >> iter 32000, loss: 0.441291
 >> iter 33000, loss: 0.447529
 >> iter 34000, loss: 0.400085
 >> iter 35000, loss: 0.356234
 >> iter 36000, loss: 0.409748
 >> iter 37000, loss: 0.386370
 >> iter 38000, loss: 0.511929
 >> iter 39000, loss: 0.514401
 >> iter 40000, loss: 0.603356
   Number of active neurons: 5
 >> iter 41000, loss: 0.583543
 >> iter 42000, loss: 0.516327
 >> iter 43000, loss: 0.626484
 >> iter 44000, loss: 0.605373
 >> iter 45000, loss: 0.489496
 >> iter 46000, loss: 0.571617
 >> iter 47000, loss: 0.546630
 >> iter 48000, loss: 0.537001
 >> iter 49000, loss: 0.643226
 >> iter 50000, loss: 0.546332
   Number of active neurons: 4
 >> iter 51000, loss: 0.515856
 >> iter 52000, loss: 0.476533
 >> iter 53000, loss: 0.657300
 >> iter 54000, loss: 0.639784
 >> iter 55000, loss: 0.613379
 >> iter 56000, loss: 0.485052
 >> iter 57000, loss: 0.623815
 >> iter 58000, loss: 0.412953
 >> iter 59000, loss: 0.471729
 >> iter 60000, loss: 0.550047
   Number of active neurons: 4
 >> iter 61000, loss: 0.438483
 >> iter 62000, loss: 0.500772
 >> iter 63000, loss: 0.441602
 >> iter 64000, loss: 0.578278
 >> iter 65000, loss: 0.716866
 >> iter 66000, loss: 0.553753
 >> iter 67000, loss: 0.574646
 >> iter 68000, loss: 0.440721
 >> iter 69000, loss: 0.614988
 >> iter 70000, loss: 0.618279
   Number of active neurons: 5
 >> iter 71000, loss: 0.592940
 >> iter 72000, loss: 0.627890
 >> iter 73000, loss: 0.665248
 >> iter 74000, loss: 0.643562
 >> iter 75000, loss: 0.756591
 >> iter 76000, loss: 0.681673
 >> iter 77000, loss: 0.665600
 >> iter 78000, loss: 0.595993
 >> iter 79000, loss: 0.637206
 >> iter 80000, loss: 0.545160
   Number of active neurons: 4
 >> iter 81000, loss: 0.502512
 >> iter 82000, loss: 0.526589
 >> iter 83000, loss: 0.478584
 >> iter 84000, loss: 0.595595
 >> iter 85000, loss: 0.445897
 >> iter 86000, loss: 0.524709
 >> iter 87000, loss: 0.645044
 >> iter 88000, loss: 0.468904
 >> iter 89000, loss: 0.598912
 >> iter 90000, loss: 0.599228
   Number of active neurons: 4
 >> iter 91000, loss: 0.579325
 >> iter 92000, loss: 0.523289
 >> iter 93000, loss: 0.641350
 >> iter 94000, loss: 0.694391
 >> iter 95000, loss: 0.649792
 >> iter 96000, loss: 0.558524
 >> iter 97000, loss: 0.621484
 >> iter 98000, loss: 0.557921
 >> iter 99000, loss: 0.671597
 >> iter 100000, loss: 0.616530
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.985733
 >> iter 2000, loss: 11.450465
 >> iter 3000, loss: 7.749899
 >> iter 4000, loss: 5.253711
 >> iter 5000, loss: 3.805107
 >> iter 6000, loss: 2.694098
 >> iter 7000, loss: 1.762276
 >> iter 8000, loss: 1.260643
 >> iter 9000, loss: 0.840705
 >> iter 10000, loss: 0.693308
   Number of active neurons: 7
 >> iter 11000, loss: 0.886509
 >> iter 12000, loss: 0.653596
 >> iter 13000, loss: 0.624314
 >> iter 14000, loss: 0.450842
 >> iter 15000, loss: 0.555918
 >> iter 16000, loss: 0.502532
 >> iter 17000, loss: 0.561277
 >> iter 18000, loss: 0.484448
 >> iter 19000, loss: 0.492893
 >> iter 20000, loss: 0.497720
   Number of active neurons: 6
 >> iter 21000, loss: 0.453321
 >> iter 22000, loss: 0.662057
 >> iter 23000, loss: 0.578598
 >> iter 24000, loss: 0.440174
 >> iter 25000, loss: 0.474717
 >> iter 26000, loss: 0.524395
 >> iter 27000, loss: 0.588403
 >> iter 28000, loss: 0.648542
 >> iter 29000, loss: 0.591089
 >> iter 30000, loss: 0.464737
   Number of active neurons: 6
 >> iter 31000, loss: 0.413848
 >> iter 32000, loss: 0.365686
 >> iter 33000, loss: 0.451238
 >> iter 34000, loss: 0.498314
 >> iter 35000, loss: 0.579098
 >> iter 36000, loss: 0.539120
 >> iter 37000, loss: 0.522274
 >> iter 38000, loss: 0.488444
 >> iter 39000, loss: 0.465403
 >> iter 40000, loss: 0.474702
   Number of active neurons: 6
 >> iter 41000, loss: 0.497945
 >> iter 42000, loss: 0.573756
 >> iter 43000, loss: 0.623178
 >> iter 44000, loss: 0.562527
 >> iter 45000, loss: 0.630427
 >> iter 46000, loss: 0.663590
 >> iter 47000, loss: 0.612950
 >> iter 48000, loss: 0.485928
 >> iter 49000, loss: 0.568918
 >> iter 50000, loss: 0.544829
   Number of active neurons: 6
 >> iter 51000, loss: 0.604779
 >> iter 52000, loss: 0.648089
 >> iter 53000, loss: 0.505857
 >> iter 54000, loss: 0.618591
 >> iter 55000, loss: 0.448394
 >> iter 56000, loss: 0.360195
 >> iter 57000, loss: 0.484057
 >> iter 58000, loss: 0.574249
 >> iter 59000, loss: 0.650822
 >> iter 60000, loss: 0.572594
   Number of active neurons: 6
 >> iter 61000, loss: 0.537841
 >> iter 62000, loss: 0.593770
 >> iter 63000, loss: 0.470122
 >> iter 64000, loss: 0.355605
 >> iter 65000, loss: 0.386924
 >> iter 66000, loss: 0.508562
 >> iter 67000, loss: 0.321061
 >> iter 68000, loss: 0.509846
 >> iter 69000, loss: 0.629356
 >> iter 70000, loss: 0.709810
   Number of active neurons: 6
 >> iter 71000, loss: 0.625816
 >> iter 72000, loss: 0.617437
 >> iter 73000, loss: 0.520763
 >> iter 74000, loss: 0.538222
 >> iter 75000, loss: 0.670519
 >> iter 76000, loss: 0.768129
 >> iter 77000, loss: 0.602555
 >> iter 78000, loss: 0.575218
 >> iter 79000, loss: 0.560025
 >> iter 80000, loss: 0.625802
   Number of active neurons: 6
 >> iter 81000, loss: 0.656524
 >> iter 82000, loss: 0.519088
 >> iter 83000, loss: 0.554181
 >> iter 84000, loss: 0.552506
 >> iter 85000, loss: 0.909896
 >> iter 86000, loss: 0.698983
 >> iter 87000, loss: 0.571471
 >> iter 88000, loss: 0.585589
 >> iter 89000, loss: 0.676041
 >> iter 90000, loss: 0.613925
   Number of active neurons: 5
 >> iter 91000, loss: 0.626174
 >> iter 92000, loss: 0.487334
 >> iter 93000, loss: 0.660759
 >> iter 94000, loss: 0.684429
 >> iter 95000, loss: 0.591188
 >> iter 96000, loss: 0.609586
 >> iter 97000, loss: 0.552909
 >> iter 98000, loss: 0.588595
 >> iter 99000, loss: 0.537065
 >> iter 100000, loss: 0.438982
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.579786
 >> iter 2000, loss: 12.093681
 >> iter 3000, loss: 8.637440
 >> iter 4000, loss: 5.720987
 >> iter 5000, loss: 2.717734
 >> iter 6000, loss: 1.254165
 >> iter 7000, loss: 0.805093
 >> iter 8000, loss: 0.493528
 >> iter 9000, loss: 0.504163
 >> iter 10000, loss: 0.537918
   Number of active neurons: 10
 >> iter 11000, loss: 0.470520
 >> iter 12000, loss: 0.349429
 >> iter 13000, loss: 0.248414
 >> iter 14000, loss: 0.209637
 >> iter 15000, loss: 0.212979
 >> iter 16000, loss: 0.224549
 >> iter 17000, loss: 0.286164
 >> iter 18000, loss: 0.227536
 >> iter 19000, loss: 0.248726
 >> iter 20000, loss: 0.217858
   Number of active neurons: 8
 >> iter 21000, loss: 0.185144
 >> iter 22000, loss: 0.199928
 >> iter 23000, loss: 0.365950
 >> iter 24000, loss: 0.250506
 >> iter 25000, loss: 0.340190
 >> iter 26000, loss: 0.350944
 >> iter 27000, loss: 0.359823
 >> iter 28000, loss: 0.268211
 >> iter 29000, loss: 0.243628
 >> iter 30000, loss: 0.355544
   Number of active neurons: 8
 >> iter 31000, loss: 0.403259
 >> iter 32000, loss: 0.417687
 >> iter 33000, loss: 0.373191
 >> iter 34000, loss: 0.357840
 >> iter 35000, loss: 0.317951
 >> iter 36000, loss: 0.458331
 >> iter 37000, loss: 0.368873
 >> iter 38000, loss: 0.275668
 >> iter 39000, loss: 0.315555
 >> iter 40000, loss: 0.199024
   Number of active neurons: 8
 >> iter 41000, loss: 0.280509
 >> iter 42000, loss: 0.385763
 >> iter 43000, loss: 0.288573
 >> iter 44000, loss: 0.202693
 >> iter 45000, loss: 0.213987
 >> iter 46000, loss: 0.249549
 >> iter 47000, loss: 0.421151
 >> iter 48000, loss: 0.306133
 >> iter 49000, loss: 0.489719
 >> iter 50000, loss: 0.315658
   Number of active neurons: 7
 >> iter 51000, loss: 0.412892
 >> iter 52000, loss: 0.268623
 >> iter 53000, loss: 0.408338
 >> iter 54000, loss: 0.348565
 >> iter 55000, loss: 0.293253
 >> iter 56000, loss: 0.335497
 >> iter 57000, loss: 0.328831
 >> iter 58000, loss: 0.337384
 >> iter 59000, loss: 0.416226
 >> iter 60000, loss: 0.320453
   Number of active neurons: 7
 >> iter 61000, loss: 0.306156
 >> iter 62000, loss: 0.246121
 >> iter 63000, loss: 0.297214
 >> iter 64000, loss: 0.447887
 >> iter 65000, loss: 0.373485
 >> iter 66000, loss: 0.277071
 >> iter 67000, loss: 0.291598
 >> iter 68000, loss: 0.243740
 >> iter 69000, loss: 0.304966
 >> iter 70000, loss: 0.289729
   Number of active neurons: 7
 >> iter 71000, loss: 0.189706
 >> iter 72000, loss: 0.214660
 >> iter 73000, loss: 0.310903
 >> iter 74000, loss: 0.365967
 >> iter 75000, loss: 0.339517
 >> iter 76000, loss: 0.277232
 >> iter 77000, loss: 0.344288
 >> iter 78000, loss: 0.310175
 >> iter 79000, loss: 0.314426
 >> iter 80000, loss: 0.267171
   Number of active neurons: 7
 >> iter 81000, loss: 0.353548
 >> iter 82000, loss: 0.253229
 >> iter 83000, loss: 0.265988
 >> iter 84000, loss: 0.238114
 >> iter 85000, loss: 0.295962
 >> iter 86000, loss: 0.258629
 >> iter 87000, loss: 0.231549
 >> iter 88000, loss: 0.303624
 >> iter 89000, loss: 0.252171
 >> iter 90000, loss: 0.285000
   Number of active neurons: 7
 >> iter 91000, loss: 0.277472
 >> iter 92000, loss: 0.310139
 >> iter 93000, loss: 0.459180
 >> iter 94000, loss: 0.373603
 >> iter 95000, loss: 0.445773
 >> iter 96000, loss: 0.335398
 >> iter 97000, loss: 0.325971
 >> iter 98000, loss: 0.272690
 >> iter 99000, loss: 0.310919
 >> iter 100000, loss: 0.309938
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.217647
 >> iter 2000, loss: 11.636394
 >> iter 3000, loss: 7.623645
 >> iter 4000, loss: 4.556279
 >> iter 5000, loss: 2.606770
 >> iter 6000, loss: 1.511419
 >> iter 7000, loss: 1.095723
 >> iter 8000, loss: 0.730915
 >> iter 9000, loss: 0.496028
 >> iter 10000, loss: 0.389030
   Number of active neurons: 9
 >> iter 11000, loss: 0.396112
 >> iter 12000, loss: 0.312190
 >> iter 13000, loss: 0.253460
 >> iter 14000, loss: 0.262502
 >> iter 15000, loss: 0.317820
 >> iter 16000, loss: 0.233204
 >> iter 17000, loss: 0.208624
 >> iter 18000, loss: 0.252894
 >> iter 19000, loss: 0.326478
 >> iter 20000, loss: 0.300366
   Number of active neurons: 9
 >> iter 21000, loss: 0.190798
 >> iter 22000, loss: 0.267510
 >> iter 23000, loss: 0.223933
 >> iter 24000, loss: 0.255447
 >> iter 25000, loss: 0.288255
 >> iter 26000, loss: 0.243282
 >> iter 27000, loss: 0.252899
 >> iter 28000, loss: 0.242817
 >> iter 29000, loss: 0.223416
 >> iter 30000, loss: 0.171130
   Number of active neurons: 8
 >> iter 31000, loss: 0.282990
 >> iter 32000, loss: 0.336279
 >> iter 33000, loss: 0.279206
 >> iter 34000, loss: 0.220590
 >> iter 35000, loss: 0.220476
 >> iter 36000, loss: 0.254463
 >> iter 37000, loss: 0.284521
 >> iter 38000, loss: 0.214702
 >> iter 39000, loss: 0.185691
 >> iter 40000, loss: 0.202887
   Number of active neurons: 7
 >> iter 41000, loss: 0.252481
 >> iter 42000, loss: 0.337472
 >> iter 43000, loss: 0.314326
 >> iter 44000, loss: 0.276617
 >> iter 45000, loss: 0.306561
 >> iter 46000, loss: 0.231885
 >> iter 47000, loss: 0.216276
 >> iter 48000, loss: 0.344288
 >> iter 49000, loss: 0.251378
 >> iter 50000, loss: 0.350185
   Number of active neurons: 6
 >> iter 51000, loss: 0.292880
 >> iter 52000, loss: 0.253566
 >> iter 53000, loss: 0.263032
 >> iter 54000, loss: 0.293251
 >> iter 55000, loss: 0.316345
 >> iter 56000, loss: 0.357499
 >> iter 57000, loss: 0.353836
 >> iter 58000, loss: 0.280241
 >> iter 59000, loss: 0.259448
 >> iter 60000, loss: 0.308637
   Number of active neurons: 6
 >> iter 61000, loss: 0.324895
 >> iter 62000, loss: 0.376638
 >> iter 63000, loss: 0.373950
 >> iter 64000, loss: 0.300291
 >> iter 65000, loss: 0.337330
 >> iter 66000, loss: 0.340623
 >> iter 67000, loss: 0.358942
 >> iter 68000, loss: 0.456393
 >> iter 69000, loss: 0.338499
 >> iter 70000, loss: 0.339631
   Number of active neurons: 5
 >> iter 71000, loss: 0.337898
 >> iter 72000, loss: 0.270988
 >> iter 73000, loss: 0.303805
 >> iter 74000, loss: 0.413697
 >> iter 75000, loss: 0.443611
 >> iter 76000, loss: 0.298467
 >> iter 77000, loss: 0.275737
 >> iter 78000, loss: 0.271945
 >> iter 79000, loss: 0.237265
 >> iter 80000, loss: 0.296859
   Number of active neurons: 6
 >> iter 81000, loss: 0.408722
 >> iter 82000, loss: 0.460652
 >> iter 83000, loss: 0.436351
 >> iter 84000, loss: 0.353426
 >> iter 85000, loss: 0.363583
 >> iter 86000, loss: 0.308623
 >> iter 87000, loss: 0.336335
 >> iter 88000, loss: 0.373031
 >> iter 89000, loss: 0.390575
 >> iter 90000, loss: 0.354541
   Number of active neurons: 5
 >> iter 91000, loss: 0.237491
 >> iter 92000, loss: 0.346233
 >> iter 93000, loss: 0.268178
 >> iter 94000, loss: 0.317966
 >> iter 95000, loss: 0.364386
 >> iter 96000, loss: 0.307396
 >> iter 97000, loss: 0.331593
 >> iter 98000, loss: 0.310059
 >> iter 99000, loss: 0.279388
 >> iter 100000, loss: 0.380414
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.067550
 >> iter 2000, loss: 10.015908
 >> iter 3000, loss: 6.302229
 >> iter 4000, loss: 4.086181
 >> iter 5000, loss: 2.815721
 >> iter 6000, loss: 1.901304
 >> iter 7000, loss: 1.380805
 >> iter 8000, loss: 1.058116
 >> iter 9000, loss: 0.784194
 >> iter 10000, loss: 0.755433
   Number of active neurons: 5
 >> iter 11000, loss: 0.756053
 >> iter 12000, loss: 0.636808
 >> iter 13000, loss: 0.595023
 >> iter 14000, loss: 0.773042
 >> iter 15000, loss: 0.619704
 >> iter 16000, loss: 0.539323
 >> iter 17000, loss: 0.485378
 >> iter 18000, loss: 0.444613
 >> iter 19000, loss: 0.470188
 >> iter 20000, loss: 0.373301
   Number of active neurons: 5
 >> iter 21000, loss: 0.409757
 >> iter 22000, loss: 0.331383
 >> iter 23000, loss: 0.508604
 >> iter 24000, loss: 0.477384
 >> iter 25000, loss: 0.505731
 >> iter 26000, loss: 0.452056
 >> iter 27000, loss: 0.551590
 >> iter 28000, loss: 0.472569
 >> iter 29000, loss: 0.519391
 >> iter 30000, loss: 0.624636
   Number of active neurons: 5
 >> iter 31000, loss: 0.571228
 >> iter 32000, loss: 0.565364
 >> iter 33000, loss: 0.418603
 >> iter 34000, loss: 0.630404
 >> iter 35000, loss: 0.564104
 >> iter 36000, loss: 0.650288
 >> iter 37000, loss: 0.616086
 >> iter 38000, loss: 0.653524
 >> iter 39000, loss: 0.462099
 >> iter 40000, loss: 0.418218
   Number of active neurons: 5
 >> iter 41000, loss: 0.490360
 >> iter 42000, loss: 0.488381
 >> iter 43000, loss: 0.459989
 >> iter 44000, loss: 0.532287
 >> iter 45000, loss: 0.411723
 >> iter 46000, loss: 0.446456
 >> iter 47000, loss: 0.378533
 >> iter 48000, loss: 0.465472
 >> iter 49000, loss: 0.322107
 >> iter 50000, loss: 0.301101
   Number of active neurons: 5
 >> iter 51000, loss: 0.479167
 >> iter 52000, loss: 0.452212
 >> iter 53000, loss: 0.387695
 >> iter 54000, loss: 0.303159
 >> iter 55000, loss: 0.366741
 >> iter 56000, loss: 0.370412
 >> iter 57000, loss: 0.361585
 >> iter 58000, loss: 0.378476
 >> iter 59000, loss: 0.421440
 >> iter 60000, loss: 0.361663
   Number of active neurons: 5
 >> iter 61000, loss: 0.391535
 >> iter 62000, loss: 0.458381
 >> iter 63000, loss: 0.331104
 >> iter 64000, loss: 0.347572
 >> iter 65000, loss: 0.360964
 >> iter 66000, loss: 0.404566
 >> iter 67000, loss: 0.253874
 >> iter 68000, loss: 0.333745
 >> iter 69000, loss: 0.319967
 >> iter 70000, loss: 0.376287
   Number of active neurons: 5
 >> iter 71000, loss: 0.437993
 >> iter 72000, loss: 0.436111
 >> iter 73000, loss: 0.358268
 >> iter 74000, loss: 0.362645
 >> iter 75000, loss: 0.256077
 >> iter 76000, loss: 0.247503
 >> iter 77000, loss: 0.357552
 >> iter 78000, loss: 0.387426
 >> iter 79000, loss: 0.320862
 >> iter 80000, loss: 0.297535
   Number of active neurons: 4
 >> iter 81000, loss: 0.300866
 >> iter 82000, loss: 0.213810
 >> iter 83000, loss: 0.298427
 >> iter 84000, loss: 0.238727
 >> iter 85000, loss: 0.288199
 >> iter 86000, loss: 0.249549
 >> iter 87000, loss: 0.324056
 >> iter 88000, loss: 0.364218
 >> iter 89000, loss: 0.319435
 >> iter 90000, loss: 0.274947
   Number of active neurons: 4
 >> iter 91000, loss: 0.254107
 >> iter 92000, loss: 0.273959
 >> iter 93000, loss: 0.244125
 >> iter 94000, loss: 0.220948
 >> iter 95000, loss: 0.248333
 >> iter 96000, loss: 0.291826
 >> iter 97000, loss: 0.347780
 >> iter 98000, loss: 0.304818
 >> iter 99000, loss: 0.278473
 >> iter 100000, loss: 0.323776
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 17.171320
 >> iter 2000, loss: 11.154171
 >> iter 3000, loss: 7.346939
 >> iter 4000, loss: 4.157729
 >> iter 5000, loss: 2.280151
 >> iter 6000, loss: 1.391098
 >> iter 7000, loss: 1.124681
 >> iter 8000, loss: 0.951028
 >> iter 9000, loss: 0.916908
 >> iter 10000, loss: 0.664688
   Number of active neurons: 7
 >> iter 11000, loss: 0.634156
 >> iter 12000, loss: 0.879276
 >> iter 13000, loss: 0.866882
 >> iter 14000, loss: 0.630514
 >> iter 15000, loss: 0.576538
 >> iter 16000, loss: 0.531686
 >> iter 17000, loss: 0.611956
 >> iter 18000, loss: 0.599119
 >> iter 19000, loss: 0.687679
 >> iter 20000, loss: 0.537091
   Number of active neurons: 6
 >> iter 21000, loss: 0.398765
 >> iter 22000, loss: 0.372824
 >> iter 23000, loss: 0.483049
 >> iter 24000, loss: 0.420481
 >> iter 25000, loss: 0.539087
 >> iter 26000, loss: 0.532300
 >> iter 27000, loss: 0.587075
 >> iter 28000, loss: 0.523796
 >> iter 29000, loss: 0.610860
 >> iter 30000, loss: 0.650256
   Number of active neurons: 6
 >> iter 31000, loss: 0.606419
 >> iter 32000, loss: 0.503148
 >> iter 33000, loss: 0.465866
 >> iter 34000, loss: 0.591019
 >> iter 35000, loss: 0.615765
 >> iter 36000, loss: 0.544507
 >> iter 37000, loss: 0.532625
 >> iter 38000, loss: 0.433615
 >> iter 39000, loss: 0.400573
 >> iter 40000, loss: 0.536287
   Number of active neurons: 5
 >> iter 41000, loss: 0.380132
 >> iter 42000, loss: 0.434680
 >> iter 43000, loss: 0.439790
 >> iter 44000, loss: 0.572345
 >> iter 45000, loss: 0.427353
 >> iter 46000, loss: 0.330176
 >> iter 47000, loss: 0.407355
 >> iter 48000, loss: 0.456698
 >> iter 49000, loss: 0.465117
 >> iter 50000, loss: 0.624197
   Number of active neurons: 5
 >> iter 51000, loss: 0.499118
 >> iter 52000, loss: 0.457842
 >> iter 53000, loss: 0.314107
 >> iter 54000, loss: 0.324534
 >> iter 55000, loss: 0.517023
 >> iter 56000, loss: 0.622033
 >> iter 57000, loss: 0.731552
 >> iter 58000, loss: 0.678610
 >> iter 59000, loss: 0.582080
 >> iter 60000, loss: 0.528779
   Number of active neurons: 4
 >> iter 61000, loss: 0.440293
 >> iter 62000, loss: 0.385233
 >> iter 63000, loss: 0.581233
 >> iter 64000, loss: 0.501340
 >> iter 65000, loss: 0.501995
 >> iter 66000, loss: 0.525881
 >> iter 67000, loss: 0.574863
 >> iter 68000, loss: 0.451315
 >> iter 69000, loss: 0.615538
 >> iter 70000, loss: 0.601910
   Number of active neurons: 4
 >> iter 71000, loss: 0.533832
 >> iter 72000, loss: 0.416024
 >> iter 73000, loss: 0.393317
 >> iter 74000, loss: 0.526017
 >> iter 75000, loss: 0.604614
 >> iter 76000, loss: 0.573720
 >> iter 77000, loss: 0.481344
 >> iter 78000, loss: 0.524670
 >> iter 79000, loss: 0.638580
 >> iter 80000, loss: 0.499405
   Number of active neurons: 4
 >> iter 81000, loss: 0.411419
 >> iter 82000, loss: 0.457269
 >> iter 83000, loss: 0.501848
 >> iter 84000, loss: 0.639621
 >> iter 85000, loss: 0.572174
 >> iter 86000, loss: 0.548642
 >> iter 87000, loss: 0.504486
 >> iter 88000, loss: 0.369787
 >> iter 89000, loss: 0.408163
 >> iter 90000, loss: 0.522795
   Number of active neurons: 4
 >> iter 91000, loss: 0.411559
 >> iter 92000, loss: 0.522671
 >> iter 93000, loss: 0.644768
 >> iter 94000, loss: 0.693747
 >> iter 95000, loss: 0.515142
 >> iter 96000, loss: 0.647888
 >> iter 97000, loss: 0.479398
 >> iter 98000, loss: 0.672850
 >> iter 99000, loss: 0.570258
 >> iter 100000, loss: 0.528885
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.826197
 >> iter 2000, loss: 10.498182
 >> iter 3000, loss: 5.817807
 >> iter 4000, loss: 2.848960
 >> iter 5000, loss: 1.397765
 >> iter 6000, loss: 0.811019
 >> iter 7000, loss: 0.552475
 >> iter 8000, loss: 0.330082
 >> iter 9000, loss: 0.359381
 >> iter 10000, loss: 0.326190
   Number of active neurons: 8
 >> iter 11000, loss: 0.405207
 >> iter 12000, loss: 0.267328
 >> iter 13000, loss: 0.321801
 >> iter 14000, loss: 0.300817
 >> iter 15000, loss: 0.220492
 >> iter 16000, loss: 0.213970
 >> iter 17000, loss: 0.253723
 >> iter 18000, loss: 0.298933
 >> iter 19000, loss: 0.269594
 >> iter 20000, loss: 0.215547
   Number of active neurons: 8
 >> iter 21000, loss: 0.176313
 >> iter 22000, loss: 0.249319
 >> iter 23000, loss: 0.300104
 >> iter 24000, loss: 0.244934
 >> iter 25000, loss: 0.231855
 >> iter 26000, loss: 0.255397
 >> iter 27000, loss: 0.183445
 >> iter 28000, loss: 0.341270
 >> iter 29000, loss: 0.362227
 >> iter 30000, loss: 0.212853
   Number of active neurons: 8
 >> iter 31000, loss: 0.277815
 >> iter 32000, loss: 0.238380
 >> iter 33000, loss: 0.258116
 >> iter 34000, loss: 0.187705
 >> iter 35000, loss: 0.244525
 >> iter 36000, loss: 0.189622
 >> iter 37000, loss: 0.189345
 >> iter 38000, loss: 0.160968
 >> iter 39000, loss: 0.279922
 >> iter 40000, loss: 0.201281
   Number of active neurons: 8
 >> iter 41000, loss: 0.166212
 >> iter 42000, loss: 0.188252
 >> iter 43000, loss: 0.231422
 >> iter 44000, loss: 0.261024
 >> iter 45000, loss: 0.219152
 >> iter 46000, loss: 0.153990
 >> iter 47000, loss: 0.213064
 >> iter 48000, loss: 0.159145
 >> iter 49000, loss: 0.294037
 >> iter 50000, loss: 0.182412
   Number of active neurons: 8
 >> iter 51000, loss: 0.249331
 >> iter 52000, loss: 0.219380
 >> iter 53000, loss: 0.158913
 >> iter 54000, loss: 0.212334
 >> iter 55000, loss: 0.135830
 >> iter 56000, loss: 0.232154
 >> iter 57000, loss: 0.186318
 >> iter 58000, loss: 0.271402
 >> iter 59000, loss: 0.209857
 >> iter 60000, loss: 0.186825
   Number of active neurons: 6
 >> iter 61000, loss: 0.225203
 >> iter 62000, loss: 0.222475
 >> iter 63000, loss: 0.225806
 >> iter 64000, loss: 0.180936
 >> iter 65000, loss: 0.143317
 >> iter 66000, loss: 0.178078
 >> iter 67000, loss: 0.159811
 >> iter 68000, loss: 0.259402
 >> iter 69000, loss: 0.221340
 >> iter 70000, loss: 0.236431
   Number of active neurons: 6
 >> iter 71000, loss: 0.191895
 >> iter 72000, loss: 0.142216
 >> iter 73000, loss: 0.132897
 >> iter 74000, loss: 0.171189
 >> iter 75000, loss: 0.217796
 >> iter 76000, loss: 0.177537
 >> iter 77000, loss: 0.222242
 >> iter 78000, loss: 0.167505
 >> iter 79000, loss: 0.221063
 >> iter 80000, loss: 0.210580
   Number of active neurons: 6
 >> iter 81000, loss: 0.243765
 >> iter 82000, loss: 0.240822
 >> iter 83000, loss: 0.271544
 >> iter 84000, loss: 0.201097
 >> iter 85000, loss: 0.164193
 >> iter 86000, loss: 0.220345
 >> iter 87000, loss: 0.183062
 >> iter 88000, loss: 0.125099
 >> iter 89000, loss: 0.165278
 >> iter 90000, loss: 0.153972
   Number of active neurons: 6
 >> iter 91000, loss: 0.168587
 >> iter 92000, loss: 0.237055
 >> iter 93000, loss: 0.203031
 >> iter 94000, loss: 0.190024
 >> iter 95000, loss: 0.292504
 >> iter 96000, loss: 0.197873
 >> iter 97000, loss: 0.186720
 >> iter 98000, loss: 0.261232
 >> iter 99000, loss: 0.219251
 >> iter 100000, loss: 0.184973
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.218759
 >> iter 2000, loss: 9.484990
 >> iter 3000, loss: 5.212248
 >> iter 4000, loss: 2.714795
 >> iter 5000, loss: 1.502399
 >> iter 6000, loss: 1.101361
 >> iter 7000, loss: 0.824946
 >> iter 8000, loss: 0.945209
 >> iter 9000, loss: 0.764236
 >> iter 10000, loss: 0.693662
   Number of active neurons: 4
 >> iter 11000, loss: 0.599437
 >> iter 12000, loss: 0.600860
 >> iter 13000, loss: 0.536342
 >> iter 14000, loss: 0.573677
 >> iter 15000, loss: 0.622345
 >> iter 16000, loss: 0.400546
 >> iter 17000, loss: 0.418459
 >> iter 18000, loss: 0.493626
 >> iter 19000, loss: 0.448838
 >> iter 20000, loss: 0.444197
   Number of active neurons: 4
 >> iter 21000, loss: 0.429548
 >> iter 22000, loss: 0.480683
 >> iter 23000, loss: 0.494976
 >> iter 24000, loss: 0.541104
 >> iter 25000, loss: 0.531183
 >> iter 26000, loss: 0.454852
 >> iter 27000, loss: 0.469908
 >> iter 28000, loss: 0.414512
 >> iter 29000, loss: 0.369039
 >> iter 30000, loss: 0.386338
   Number of active neurons: 5
 >> iter 31000, loss: 0.349902
 >> iter 32000, loss: 0.397418
 >> iter 33000, loss: 0.391724
 >> iter 34000, loss: 0.507865
 >> iter 35000, loss: 0.387883
 >> iter 36000, loss: 0.514397
 >> iter 37000, loss: 0.495636
 >> iter 38000, loss: 0.488569
 >> iter 39000, loss: 0.605762
 >> iter 40000, loss: 0.541818
   Number of active neurons: 4
 >> iter 41000, loss: 0.412719
 >> iter 42000, loss: 0.361741
 >> iter 43000, loss: 0.499579
 >> iter 44000, loss: 0.402066
 >> iter 45000, loss: 0.539934
 >> iter 46000, loss: 0.489862
 >> iter 47000, loss: 0.373864
 >> iter 48000, loss: 0.457089
 >> iter 49000, loss: 0.557335
 >> iter 50000, loss: 0.536756
   Number of active neurons: 5
 >> iter 51000, loss: 0.550441
 >> iter 52000, loss: 0.473210
 >> iter 53000, loss: 0.459671
 >> iter 54000, loss: 0.486074
 >> iter 55000, loss: 0.371611
 >> iter 56000, loss: 0.354507
 >> iter 57000, loss: 0.435087
 >> iter 58000, loss: 0.468990
 >> iter 59000, loss: 0.402092
 >> iter 60000, loss: 0.524140
   Number of active neurons: 4
 >> iter 61000, loss: 0.628514
 >> iter 62000, loss: 0.557091
 >> iter 63000, loss: 0.499156
 >> iter 64000, loss: 0.564414
 >> iter 65000, loss: 0.546536
 >> iter 66000, loss: 0.552594
 >> iter 67000, loss: 0.681538
 >> iter 68000, loss: 0.590741
 >> iter 69000, loss: 0.506346
 >> iter 70000, loss: 0.392784
   Number of active neurons: 4
 >> iter 71000, loss: 0.506236
 >> iter 72000, loss: 0.476658
 >> iter 73000, loss: 0.482239
 >> iter 74000, loss: 0.544319
 >> iter 75000, loss: 0.475178
 >> iter 76000, loss: 0.736019
 >> iter 77000, loss: 0.589217
 >> iter 78000, loss: 0.523512
 >> iter 79000, loss: 0.624442
 >> iter 80000, loss: 0.495381
   Number of active neurons: 4
 >> iter 81000, loss: 0.620244
 >> iter 82000, loss: 0.640717
 >> iter 83000, loss: 0.575486
 >> iter 84000, loss: 0.565793
 >> iter 85000, loss: 0.544709
 >> iter 86000, loss: 0.553213
 >> iter 87000, loss: 0.441498
 >> iter 88000, loss: 0.557993
 >> iter 89000, loss: 0.577005
 >> iter 90000, loss: 0.557946
   Number of active neurons: 4
 >> iter 91000, loss: 0.508121
 >> iter 92000, loss: 0.610027
 >> iter 93000, loss: 0.554570
 >> iter 94000, loss: 0.562758
 >> iter 95000, loss: 0.434851
 >> iter 96000, loss: 0.568531
 >> iter 97000, loss: 0.601478
 >> iter 98000, loss: 0.531799
 >> iter 99000, loss: 0.593288
 >> iter 100000, loss: 0.678793
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.115534
 >> iter 2000, loss: 10.674658
 >> iter 3000, loss: 8.319803
 >> iter 4000, loss: 6.853736
 >> iter 5000, loss: 5.224520
 >> iter 6000, loss: 3.342482
 >> iter 7000, loss: 1.880077
 >> iter 8000, loss: 1.105256
 >> iter 9000, loss: 0.692795
 >> iter 10000, loss: 0.629605
   Number of active neurons: 7
 >> iter 11000, loss: 0.506771
 >> iter 12000, loss: 0.498721
 >> iter 13000, loss: 0.492708
 >> iter 14000, loss: 0.472891
 >> iter 15000, loss: 0.520574
 >> iter 16000, loss: 0.465189
 >> iter 17000, loss: 0.654124
 >> iter 18000, loss: 0.510291
 >> iter 19000, loss: 0.494787
 >> iter 20000, loss: 0.477197
   Number of active neurons: 7
 >> iter 21000, loss: 0.403892
 >> iter 22000, loss: 0.383339
 >> iter 23000, loss: 0.359704
 >> iter 24000, loss: 0.309360
 >> iter 25000, loss: 0.396537
 >> iter 26000, loss: 0.350295
 >> iter 27000, loss: 0.285003
 >> iter 28000, loss: 0.322791
 >> iter 29000, loss: 0.268075
 >> iter 30000, loss: 0.243974
   Number of active neurons: 7
 >> iter 31000, loss: 0.357847
 >> iter 32000, loss: 0.302233
 >> iter 33000, loss: 0.271778
 >> iter 34000, loss: 0.241273
 >> iter 35000, loss: 0.275976
 >> iter 36000, loss: 0.410551
 >> iter 37000, loss: 0.283675
 >> iter 38000, loss: 0.280501
 >> iter 39000, loss: 0.255880
 >> iter 40000, loss: 0.183634
   Number of active neurons: 6
 >> iter 41000, loss: 0.216589
 >> iter 42000, loss: 0.401536
 >> iter 43000, loss: 0.454614
 >> iter 44000, loss: 0.391099
 >> iter 45000, loss: 0.359463
 >> iter 46000, loss: 0.336827
 >> iter 47000, loss: 0.462112
 >> iter 48000, loss: 0.511942
 >> iter 49000, loss: 0.507338
 >> iter 50000, loss: 0.409802
   Number of active neurons: 6
 >> iter 51000, loss: 0.420768
 >> iter 52000, loss: 0.414824
 >> iter 53000, loss: 0.294569
 >> iter 54000, loss: 0.262752
 >> iter 55000, loss: 0.396702
 >> iter 56000, loss: 0.359973
 >> iter 57000, loss: 0.308280
 >> iter 58000, loss: 0.363550
 >> iter 59000, loss: 0.286111
 >> iter 60000, loss: 0.445754
   Number of active neurons: 5
 >> iter 61000, loss: 0.477029
 >> iter 62000, loss: 0.496750
 >> iter 63000, loss: 0.562224
 >> iter 64000, loss: 0.474491
 >> iter 65000, loss: 0.623049
 >> iter 66000, loss: 0.508471
 >> iter 67000, loss: 0.647057
 >> iter 68000, loss: 0.485826
 >> iter 69000, loss: 0.304854
 >> iter 70000, loss: 0.333392
   Number of active neurons: 5
 >> iter 71000, loss: 0.365290
 >> iter 72000, loss: 0.369982
 >> iter 73000, loss: 0.465522
 >> iter 74000, loss: 0.512532
 >> iter 75000, loss: 0.520218
 >> iter 76000, loss: 0.389914
 >> iter 77000, loss: 0.528711
 >> iter 78000, loss: 0.423109
 >> iter 79000, loss: 0.401300
 >> iter 80000, loss: 0.470946
   Number of active neurons: 5
 >> iter 81000, loss: 0.442707
 >> iter 82000, loss: 0.526737
 >> iter 83000, loss: 0.539771
 >> iter 84000, loss: 0.554174
 >> iter 85000, loss: 0.596322
 >> iter 86000, loss: 0.597682
 >> iter 87000, loss: 0.838852
 >> iter 88000, loss: 0.784348
 >> iter 89000, loss: 0.688773
 >> iter 90000, loss: 0.532088
   Number of active neurons: 5
 >> iter 91000, loss: 0.360453
 >> iter 92000, loss: 0.343801
 >> iter 93000, loss: 0.379542
 >> iter 94000, loss: 0.347794
 >> iter 95000, loss: 0.444250
 >> iter 96000, loss: 0.387980
 >> iter 97000, loss: 0.557854
 >> iter 98000, loss: 0.527076
 >> iter 99000, loss: 0.436794
 >> iter 100000, loss: 0.375468
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.441999
 >> iter 2000, loss: 10.501543
 >> iter 3000, loss: 6.989648
 >> iter 4000, loss: 3.965563
 >> iter 5000, loss: 2.063522
 >> iter 6000, loss: 1.071518
 >> iter 7000, loss: 0.656154
 >> iter 8000, loss: 0.593151
 >> iter 9000, loss: 0.441147
 >> iter 10000, loss: 0.490290
   Number of active neurons: 6
 >> iter 11000, loss: 0.333595
 >> iter 12000, loss: 0.290027
 >> iter 13000, loss: 0.341066
 >> iter 14000, loss: 0.372713
 >> iter 15000, loss: 0.358053
 >> iter 16000, loss: 0.300926
 >> iter 17000, loss: 0.290657
 >> iter 18000, loss: 0.302511
 >> iter 19000, loss: 0.192280
 >> iter 20000, loss: 0.369844
   Number of active neurons: 6
 >> iter 21000, loss: 0.329641
 >> iter 22000, loss: 0.511434
 >> iter 23000, loss: 0.380620
 >> iter 24000, loss: 0.343762
 >> iter 25000, loss: 0.375446
 >> iter 26000, loss: 0.250532
 >> iter 27000, loss: 0.324128
 >> iter 28000, loss: 0.273381
 >> iter 29000, loss: 0.298738
 >> iter 30000, loss: 0.394306
   Number of active neurons: 6
 >> iter 31000, loss: 0.341742
 >> iter 32000, loss: 0.275300
 >> iter 33000, loss: 0.181681
 >> iter 34000, loss: 0.238738
 >> iter 35000, loss: 0.245845
 >> iter 36000, loss: 0.375930
 >> iter 37000, loss: 0.277085
 >> iter 38000, loss: 0.316167
 >> iter 39000, loss: 0.241864
 >> iter 40000, loss: 0.276632
   Number of active neurons: 5
 >> iter 41000, loss: 0.341530
 >> iter 42000, loss: 0.406900
 >> iter 43000, loss: 0.326627
 >> iter 44000, loss: 0.257925
 >> iter 45000, loss: 0.200714
 >> iter 46000, loss: 0.224790
 >> iter 47000, loss: 0.340905
 >> iter 48000, loss: 0.368278
 >> iter 49000, loss: 0.242289
 >> iter 50000, loss: 0.260011
   Number of active neurons: 5
 >> iter 51000, loss: 0.386237
 >> iter 52000, loss: 0.399195
 >> iter 53000, loss: 0.362082
 >> iter 54000, loss: 0.286526
 >> iter 55000, loss: 0.411935
 >> iter 56000, loss: 0.331521
 >> iter 57000, loss: 0.354703
 >> iter 58000, loss: 0.228688
 >> iter 59000, loss: 0.290027
 >> iter 60000, loss: 0.297680
   Number of active neurons: 5
 >> iter 61000, loss: 0.295372
 >> iter 62000, loss: 0.308057
 >> iter 63000, loss: 0.322007
 >> iter 64000, loss: 0.239612
 >> iter 65000, loss: 0.268371
 >> iter 66000, loss: 0.258683
 >> iter 67000, loss: 0.365701
 >> iter 68000, loss: 0.236219
 >> iter 69000, loss: 0.190169
 >> iter 70000, loss: 0.215349
   Number of active neurons: 5
 >> iter 71000, loss: 0.314184
 >> iter 72000, loss: 0.334100
 >> iter 73000, loss: 0.299100
 >> iter 74000, loss: 0.364013
 >> iter 75000, loss: 0.367900
 >> iter 76000, loss: 0.265040
 >> iter 77000, loss: 0.235486
 >> iter 78000, loss: 0.257920
 >> iter 79000, loss: 0.254451
 >> iter 80000, loss: 0.225192
   Number of active neurons: 5
 >> iter 81000, loss: 0.198671
 >> iter 82000, loss: 0.276694
 >> iter 83000, loss: 0.211141
 >> iter 84000, loss: 0.325617
 >> iter 85000, loss: 0.371177
 >> iter 86000, loss: 0.333751
 >> iter 87000, loss: 0.231377
 >> iter 88000, loss: 0.393182
 >> iter 89000, loss: 0.236202
 >> iter 90000, loss: 0.298390
   Number of active neurons: 5
 >> iter 91000, loss: 0.322885
 >> iter 92000, loss: 0.306260
 >> iter 93000, loss: 0.295542
 >> iter 94000, loss: 0.334875
 >> iter 95000, loss: 0.224180
 >> iter 96000, loss: 0.200189
 >> iter 97000, loss: 0.235340
 >> iter 98000, loss: 0.301675
 >> iter 99000, loss: 0.256793
 >> iter 100000, loss: 0.338351
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.658620
 >> iter 2000, loss: 9.033539
 >> iter 3000, loss: 4.920263
 >> iter 4000, loss: 2.835262
 >> iter 5000, loss: 1.559105
 >> iter 6000, loss: 1.053998
 >> iter 7000, loss: 0.692864
 >> iter 8000, loss: 0.657576
 >> iter 9000, loss: 0.580610
 >> iter 10000, loss: 0.576092
   Number of active neurons: 6
 >> iter 11000, loss: 0.477679
 >> iter 12000, loss: 0.557043
 >> iter 13000, loss: 0.499374
 >> iter 14000, loss: 0.445601
 >> iter 15000, loss: 0.612326
 >> iter 16000, loss: 0.592320
 >> iter 17000, loss: 0.601570
 >> iter 18000, loss: 0.540089
 >> iter 19000, loss: 0.422419
 >> iter 20000, loss: 0.394836
   Number of active neurons: 6
 >> iter 21000, loss: 0.476094
 >> iter 22000, loss: 0.437943
 >> iter 23000, loss: 0.442868
 >> iter 24000, loss: 0.552152
 >> iter 25000, loss: 0.429772
 >> iter 26000, loss: 0.466961
 >> iter 27000, loss: 0.513166
 >> iter 28000, loss: 0.443393
 >> iter 29000, loss: 0.669759
 >> iter 30000, loss: 0.633865
   Number of active neurons: 6
 >> iter 31000, loss: 0.422515
 >> iter 32000, loss: 0.509720
 >> iter 33000, loss: 0.469546
 >> iter 34000, loss: 0.388792
 >> iter 35000, loss: 0.534889
 >> iter 36000, loss: 0.473864
 >> iter 37000, loss: 0.391523
 >> iter 38000, loss: 0.343393
 >> iter 39000, loss: 0.451532
 >> iter 40000, loss: 0.370801
   Number of active neurons: 6
 >> iter 41000, loss: 0.392854
 >> iter 42000, loss: 0.304103
 >> iter 43000, loss: 0.539529
 >> iter 44000, loss: 0.508282
 >> iter 45000, loss: 0.507498
 >> iter 46000, loss: 0.586792
 >> iter 47000, loss: 0.432616
 >> iter 48000, loss: 0.390835
 >> iter 49000, loss: 0.491443
 >> iter 50000, loss: 0.358857
   Number of active neurons: 6
 >> iter 51000, loss: 0.426856
 >> iter 52000, loss: 0.314096
 >> iter 53000, loss: 0.430425
 >> iter 54000, loss: 0.482941
 >> iter 55000, loss: 0.440441
 >> iter 56000, loss: 0.590671
 >> iter 57000, loss: 0.543599
 >> iter 58000, loss: 0.498911
 >> iter 59000, loss: 0.464033
 >> iter 60000, loss: 0.497198
   Number of active neurons: 6
 >> iter 61000, loss: 0.495011
 >> iter 62000, loss: 0.672299
 >> iter 63000, loss: 0.534873
 >> iter 64000, loss: 0.648238
 >> iter 65000, loss: 0.595301
 >> iter 66000, loss: 0.510701
 >> iter 67000, loss: 0.421476
 >> iter 68000, loss: 0.429941
 >> iter 69000, loss: 0.450321
 >> iter 70000, loss: 0.461249
   Number of active neurons: 6
 >> iter 71000, loss: 0.530509
 >> iter 72000, loss: 0.512356
 >> iter 73000, loss: 0.525897
 >> iter 74000, loss: 0.467991
 >> iter 75000, loss: 0.436945
 >> iter 76000, loss: 0.596488
 >> iter 77000, loss: 0.456629
 >> iter 78000, loss: 0.512184
 >> iter 79000, loss: 0.441345
 >> iter 80000, loss: 0.467830
   Number of active neurons: 5
 >> iter 81000, loss: 0.436600
 >> iter 82000, loss: 0.275395
 >> iter 83000, loss: 0.400989
 >> iter 84000, loss: 0.392486
 >> iter 85000, loss: 0.408373
 >> iter 86000, loss: 0.327372
 >> iter 87000, loss: 0.399696
 >> iter 88000, loss: 0.421124
 >> iter 89000, loss: 0.415334
 >> iter 90000, loss: 0.503345
   Number of active neurons: 5
 >> iter 91000, loss: 0.561060
 >> iter 92000, loss: 0.648042
 >> iter 93000, loss: 0.537623
 >> iter 94000, loss: 0.484117
 >> iter 95000, loss: 0.537489
 >> iter 96000, loss: 0.552950
 >> iter 97000, loss: 0.614086
 >> iter 98000, loss: 0.520094
 >> iter 99000, loss: 0.395773
 >> iter 100000, loss: 0.384142
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

