 > Problema: tomita1nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 4e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.714087
 >> iter 2000, loss: 3.955013
 >> iter 3000, loss: 1.465033
 >> iter 4000, loss: 0.547480
 >> iter 5000, loss: 0.209401
 >> iter 6000, loss: 0.084473
 >> iter 7000, loss: 0.038410
 >> iter 8000, loss: 0.021175
 >> iter 9000, loss: 0.014855
 >> iter 10000, loss: 0.012305
   Number of active neurons: 5
 >> iter 11000, loss: 0.011445
 >> iter 12000, loss: 0.010930
 >> iter 13000, loss: 0.010849
 >> iter 14000, loss: 0.010619
 >> iter 15000, loss: 0.010648
 >> iter 16000, loss: 0.010467
 >> iter 17000, loss: 0.010523
 >> iter 18000, loss: 0.010375
 >> iter 19000, loss: 0.010435
 >> iter 20000, loss: 0.010289
   Number of active neurons: 4
 >> iter 21000, loss: 0.010327
 >> iter 22000, loss: 0.010168
 >> iter 23000, loss: 0.010204
 >> iter 24000, loss: 0.010030
 >> iter 25000, loss: 0.010058
 >> iter 26000, loss: 0.009878
 >> iter 27000, loss: 0.009893
 >> iter 28000, loss: 0.009727
 >> iter 29000, loss: 0.009748
 >> iter 30000, loss: 0.009592
   Number of active neurons: 4
 >> iter 31000, loss: 0.009623
 >> iter 32000, loss: 0.009481
 >> iter 33000, loss: 0.009524
 >> iter 34000, loss: 0.009404
 >> iter 35000, loss: 0.009473
 >> iter 36000, loss: 0.009363
 >> iter 37000, loss: 0.009445
 >> iter 38000, loss: 0.009343
 >> iter 39000, loss: 0.009437
 >> iter 40000, loss: 0.009338
   Number of active neurons: 4
 >> iter 41000, loss: 0.009431
 >> iter 42000, loss: 0.009339
 >> iter 43000, loss: 0.009427
 >> iter 44000, loss: 0.009343
 >> iter 45000, loss: 0.009426
 >> iter 46000, loss: 0.009339
 >> iter 47000, loss: 0.009418
 >> iter 48000, loss: 0.009334
 >> iter 49000, loss: 0.009408
 >> iter 50000, loss: 0.009315
   Number of active neurons: 2
 >> iter 51000, loss: 0.009384
 >> iter 52000, loss: 0.009291
 >> iter 53000, loss: 0.009343
 >> iter 54000, loss: 0.009254
 >> iter 55000, loss: 0.009279
 >> iter 56000, loss: 0.009180
 >> iter 57000, loss: 0.009192
 >> iter 58000, loss: 0.009049
 >> iter 59000, loss: 0.009030
 >> iter 60000, loss: 0.008861
   Number of active neurons: 2
 >> iter 61000, loss: 0.008806
 >> iter 62000, loss: 0.008616
 >> iter 63000, loss: 0.008552
 >> iter 64000, loss: 0.008362
 >> iter 65000, loss: 0.008312
 >> iter 66000, loss: 0.008144
 >> iter 67000, loss: 0.008109
 >> iter 68000, loss: 0.007972
 >> iter 69000, loss: 0.007951
 >> iter 70000, loss: 0.007836
   Number of active neurons: 2
 >> iter 71000, loss: 0.007842
 >> iter 72000, loss: 0.007753
 >> iter 73000, loss: 0.007770
 >> iter 74000, loss: 0.007690
 >> iter 75000, loss: 0.007719
 >> iter 76000, loss: 0.007648
 >> iter 77000, loss: 0.007681
 >> iter 78000, loss: 0.007613
 >> iter 79000, loss: 0.007662
 >> iter 80000, loss: 0.007592
   Number of active neurons: 2
 >> iter 81000, loss: 0.007649
 >> iter 82000, loss: 0.007574
 >> iter 83000, loss: 0.007635
 >> iter 84000, loss: 0.007557
 >> iter 85000, loss: 0.007616
 >> iter 86000, loss: 0.007538
 >> iter 87000, loss: 0.007598
 >> iter 88000, loss: 0.007519
 >> iter 89000, loss: 0.007575
 >> iter 90000, loss: 0.007501
   Number of active neurons: 1
 >> iter 91000, loss: 0.007551
 >> iter 92000, loss: 0.007476
 >> iter 93000, loss: 0.007521
 >> iter 94000, loss: 0.007438
 >> iter 95000, loss: 0.007488
 >> iter 96000, loss: 0.007390
 >> iter 97000, loss: 0.007434
 >> iter 98000, loss: 0.007326
 >> iter 99000, loss: 0.007348
 >> iter 100000, loss: 0.007210
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.688411
 >> iter 2000, loss: 3.944407
 >> iter 3000, loss: 1.460661
 >> iter 4000, loss: 0.545524
 >> iter 5000, loss: 0.208410
 >> iter 6000, loss: 0.083739
 >> iter 7000, loss: 0.037732
 >> iter 8000, loss: 0.020498
 >> iter 9000, loss: 0.014224
 >> iter 10000, loss: 0.011669
   Number of active neurons: 5
 >> iter 11000, loss: 0.010808
 >> iter 12000, loss: 0.010256
 >> iter 13000, loss: 0.010171
 >> iter 14000, loss: 0.009925
 >> iter 15000, loss: 0.009974
 >> iter 16000, loss: 0.009793
 >> iter 17000, loss: 0.009863
 >> iter 18000, loss: 0.009694
 >> iter 19000, loss: 0.009758
 >> iter 20000, loss: 0.009605
   Number of active neurons: 4
 >> iter 21000, loss: 0.009673
 >> iter 22000, loss: 0.009528
 >> iter 23000, loss: 0.009604
 >> iter 24000, loss: 0.009452
 >> iter 25000, loss: 0.009521
 >> iter 26000, loss: 0.009370
 >> iter 27000, loss: 0.009439
 >> iter 28000, loss: 0.009299
 >> iter 29000, loss: 0.009367
 >> iter 30000, loss: 0.009229
   Number of active neurons: 4
 >> iter 31000, loss: 0.009296
 >> iter 32000, loss: 0.009153
 >> iter 33000, loss: 0.009207
 >> iter 34000, loss: 0.009060
 >> iter 35000, loss: 0.009121
 >> iter 36000, loss: 0.008973
 >> iter 37000, loss: 0.009039
 >> iter 38000, loss: 0.008904
 >> iter 39000, loss: 0.008986
 >> iter 40000, loss: 0.008859
   Number of active neurons: 4
 >> iter 41000, loss: 0.008945
 >> iter 42000, loss: 0.008831
 >> iter 43000, loss: 0.008909
 >> iter 44000, loss: 0.008803
 >> iter 45000, loss: 0.008881
 >> iter 46000, loss: 0.008770
 >> iter 47000, loss: 0.008841
 >> iter 48000, loss: 0.008733
 >> iter 49000, loss: 0.008798
 >> iter 50000, loss: 0.008674
   Number of active neurons: 2
 >> iter 51000, loss: 0.008701
 >> iter 52000, loss: 0.008548
 >> iter 53000, loss: 0.008553
 >> iter 54000, loss: 0.008390
 >> iter 55000, loss: 0.008355
 >> iter 56000, loss: 0.008185
 >> iter 57000, loss: 0.008160
 >> iter 58000, loss: 0.007966
 >> iter 59000, loss: 0.007926
 >> iter 60000, loss: 0.007735
   Number of active neurons: 2
 >> iter 61000, loss: 0.007701
 >> iter 62000, loss: 0.007527
 >> iter 63000, loss: 0.007498
 >> iter 64000, loss: 0.007328
 >> iter 65000, loss: 0.007325
 >> iter 66000, loss: 0.007186
 >> iter 67000, loss: 0.007203
 >> iter 68000, loss: 0.007097
 >> iter 69000, loss: 0.007124
 >> iter 70000, loss: 0.007025
   Number of active neurons: 2
 >> iter 71000, loss: 0.007067
 >> iter 72000, loss: 0.006979
 >> iter 73000, loss: 0.007025
 >> iter 74000, loss: 0.006939
 >> iter 75000, loss: 0.006992
 >> iter 76000, loss: 0.006908
 >> iter 77000, loss: 0.006962
 >> iter 78000, loss: 0.006878
 >> iter 79000, loss: 0.006946
 >> iter 80000, loss: 0.006856
   Number of active neurons: 2
 >> iter 81000, loss: 0.006935
 >> iter 82000, loss: 0.006836
 >> iter 83000, loss: 0.006923
 >> iter 84000, loss: 0.006816
 >> iter 85000, loss: 0.006903
 >> iter 86000, loss: 0.006797
 >> iter 87000, loss: 0.006888
 >> iter 88000, loss: 0.006780
 >> iter 89000, loss: 0.006870
 >> iter 90000, loss: 0.006769
   Number of active neurons: 2
 >> iter 91000, loss: 0.006856
 >> iter 92000, loss: 0.006758
 >> iter 93000, loss: 0.006847
 >> iter 94000, loss: 0.006744
 >> iter 95000, loss: 0.006846
 >> iter 96000, loss: 0.006732
 >> iter 97000, loss: 0.006838
 >> iter 98000, loss: 0.006720
 >> iter 99000, loss: 0.006829
 >> iter 100000, loss: 0.006718
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.769674
 >> iter 2000, loss: 3.974900
 >> iter 3000, loss: 1.472178
 >> iter 4000, loss: 0.549882
 >> iter 5000, loss: 0.209980
 >> iter 6000, loss: 0.084194
 >> iter 7000, loss: 0.037750
 >> iter 8000, loss: 0.020257
 >> iter 9000, loss: 0.013822
 >> iter 10000, loss: 0.011164
   Number of active neurons: 4
 >> iter 11000, loss: 0.010260
 >> iter 12000, loss: 0.009697
 >> iter 13000, loss: 0.009606
 >> iter 14000, loss: 0.009340
 >> iter 15000, loss: 0.009351
 >> iter 16000, loss: 0.009137
 >> iter 17000, loss: 0.009186
 >> iter 18000, loss: 0.009001
 >> iter 19000, loss: 0.009059
 >> iter 20000, loss: 0.008889
   Number of active neurons: 3
 >> iter 21000, loss: 0.008936
 >> iter 22000, loss: 0.008735
 >> iter 23000, loss: 0.008756
 >> iter 24000, loss: 0.008544
 >> iter 25000, loss: 0.008578
 >> iter 26000, loss: 0.008384
 >> iter 27000, loss: 0.008426
 >> iter 28000, loss: 0.008249
 >> iter 29000, loss: 0.008297
 >> iter 30000, loss: 0.008125
   Number of active neurons: 3
 >> iter 31000, loss: 0.008172
 >> iter 32000, loss: 0.008006
 >> iter 33000, loss: 0.008060
 >> iter 34000, loss: 0.007905
 >> iter 35000, loss: 0.007976
 >> iter 36000, loss: 0.007832
 >> iter 37000, loss: 0.007914
 >> iter 38000, loss: 0.007782
 >> iter 39000, loss: 0.007877
 >> iter 40000, loss: 0.007748
   Number of active neurons: 3
 >> iter 41000, loss: 0.007840
 >> iter 42000, loss: 0.007723
 >> iter 43000, loss: 0.007814
 >> iter 44000, loss: 0.007709
 >> iter 45000, loss: 0.007805
 >> iter 46000, loss: 0.007694
 >> iter 47000, loss: 0.007799
 >> iter 48000, loss: 0.007709
 >> iter 49000, loss: 0.007820
 >> iter 50000, loss: 0.007724
   Number of active neurons: 3
 >> iter 51000, loss: 0.007832
 >> iter 52000, loss: 0.007737
 >> iter 53000, loss: 0.007836
 >> iter 54000, loss: 0.007756
 >> iter 55000, loss: 0.007838
 >> iter 56000, loss: 0.007763
 >> iter 57000, loss: 0.007851
 >> iter 58000, loss: 0.007762
 >> iter 59000, loss: 0.007855
 >> iter 60000, loss: 0.007770
   Number of active neurons: 3
 >> iter 61000, loss: 0.007856
 >> iter 62000, loss: 0.007776
 >> iter 63000, loss: 0.007861
 >> iter 64000, loss: 0.007775
 >> iter 65000, loss: 0.007867
 >> iter 66000, loss: 0.007782
 >> iter 67000, loss: 0.007867
 >> iter 68000, loss: 0.007794
 >> iter 69000, loss: 0.007872
 >> iter 70000, loss: 0.007794
   Number of active neurons: 3
 >> iter 71000, loss: 0.007876
 >> iter 72000, loss: 0.007803
 >> iter 73000, loss: 0.007882
 >> iter 74000, loss: 0.007806
 >> iter 75000, loss: 0.007888
 >> iter 76000, loss: 0.007812
 >> iter 77000, loss: 0.007891
 >> iter 78000, loss: 0.007813
 >> iter 79000, loss: 0.007907
 >> iter 80000, loss: 0.007820
   Number of active neurons: 3
 >> iter 81000, loss: 0.007924
 >> iter 82000, loss: 0.007827
 >> iter 83000, loss: 0.007939
 >> iter 84000, loss: 0.007833
 >> iter 85000, loss: 0.007942
 >> iter 86000, loss: 0.007838
 >> iter 87000, loss: 0.007949
 >> iter 88000, loss: 0.007844
 >> iter 89000, loss: 0.007946
 >> iter 90000, loss: 0.007839
   Number of active neurons: 3
 >> iter 91000, loss: 0.007936
 >> iter 92000, loss: 0.007837
 >> iter 93000, loss: 0.007937
 >> iter 94000, loss: 0.007833
 >> iter 95000, loss: 0.007948
 >> iter 96000, loss: 0.007833
 >> iter 97000, loss: 0.007951
 >> iter 98000, loss: 0.007833
 >> iter 99000, loss: 0.007953
 >> iter 100000, loss: 0.007843
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.731664
 >> iter 2000, loss: 3.962909
 >> iter 3000, loss: 1.468788
 >> iter 4000, loss: 0.549480
 >> iter 5000, loss: 0.210587
 >> iter 6000, loss: 0.085236
 >> iter 7000, loss: 0.038874
 >> iter 8000, loss: 0.021407
 >> iter 9000, loss: 0.014886
 >> iter 10000, loss: 0.012173
   Number of active neurons: 4
 >> iter 11000, loss: 0.011168
 >> iter 12000, loss: 0.010558
 >> iter 13000, loss: 0.010396
 >> iter 14000, loss: 0.010138
 >> iter 15000, loss: 0.010141
 >> iter 16000, loss: 0.009970
 >> iter 17000, loss: 0.010007
 >> iter 18000, loss: 0.009863
 >> iter 19000, loss: 0.009912
 >> iter 20000, loss: 0.009780
   Number of active neurons: 4
 >> iter 21000, loss: 0.009812
 >> iter 22000, loss: 0.009665
 >> iter 23000, loss: 0.009695
 >> iter 24000, loss: 0.009539
 >> iter 25000, loss: 0.009569
 >> iter 26000, loss: 0.009421
 >> iter 27000, loss: 0.009448
 >> iter 28000, loss: 0.009312
 >> iter 29000, loss: 0.009343
 >> iter 30000, loss: 0.009217
   Number of active neurons: 3
 >> iter 31000, loss: 0.009254
 >> iter 32000, loss: 0.009129
 >> iter 33000, loss: 0.009161
 >> iter 34000, loss: 0.009031
 >> iter 35000, loss: 0.009047
 >> iter 36000, loss: 0.008887
 >> iter 37000, loss: 0.008887
 >> iter 38000, loss: 0.008716
 >> iter 39000, loss: 0.008718
 >> iter 40000, loss: 0.008548
   Number of active neurons: 2
 >> iter 41000, loss: 0.008546
 >> iter 42000, loss: 0.008379
 >> iter 43000, loss: 0.008359
 >> iter 44000, loss: 0.008188
 >> iter 45000, loss: 0.008161
 >> iter 46000, loss: 0.007997
 >> iter 47000, loss: 0.007985
 >> iter 48000, loss: 0.007844
 >> iter 49000, loss: 0.007845
 >> iter 50000, loss: 0.007710
   Number of active neurons: 2
 >> iter 51000, loss: 0.007722
 >> iter 52000, loss: 0.007609
 >> iter 53000, loss: 0.007632
 >> iter 54000, loss: 0.007546
 >> iter 55000, loss: 0.007571
 >> iter 56000, loss: 0.007498
 >> iter 57000, loss: 0.007536
 >> iter 58000, loss: 0.007462
 >> iter 59000, loss: 0.007511
 >> iter 60000, loss: 0.007443
   Number of active neurons: 2
 >> iter 61000, loss: 0.007490
 >> iter 62000, loss: 0.007429
 >> iter 63000, loss: 0.007480
 >> iter 64000, loss: 0.007414
 >> iter 65000, loss: 0.007471
 >> iter 66000, loss: 0.007409
 >> iter 67000, loss: 0.007463
 >> iter 68000, loss: 0.007412
 >> iter 69000, loss: 0.007460
 >> iter 70000, loss: 0.007405
   Number of active neurons: 2
 >> iter 71000, loss: 0.007458
 >> iter 72000, loss: 0.007408
 >> iter 73000, loss: 0.007458
 >> iter 74000, loss: 0.007406
 >> iter 75000, loss: 0.007459
 >> iter 76000, loss: 0.007407
 >> iter 77000, loss: 0.007458
 >> iter 78000, loss: 0.007404
 >> iter 79000, loss: 0.007466
 >> iter 80000, loss: 0.007407
   Number of active neurons: 2
 >> iter 81000, loss: 0.007476
 >> iter 82000, loss: 0.007410
 >> iter 83000, loss: 0.007482
 >> iter 84000, loss: 0.007411
 >> iter 85000, loss: 0.007481
 >> iter 86000, loss: 0.007410
 >> iter 87000, loss: 0.007481
 >> iter 88000, loss: 0.007409
 >> iter 89000, loss: 0.007477
 >> iter 90000, loss: 0.007410
   Number of active neurons: 2
 >> iter 91000, loss: 0.007474
 >> iter 92000, loss: 0.007409
 >> iter 93000, loss: 0.007470
 >> iter 94000, loss: 0.007399
 >> iter 95000, loss: 0.007467
 >> iter 96000, loss: 0.007386
 >> iter 97000, loss: 0.007453
 >> iter 98000, loss: 0.007367
 >> iter 99000, loss: 0.007433
 >> iter 100000, loss: 0.007350
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.689769
 >> iter 2000, loss: 3.944805
 >> iter 3000, loss: 1.460887
 >> iter 4000, loss: 0.545752
 >> iter 5000, loss: 0.208734
 >> iter 6000, loss: 0.083969
 >> iter 7000, loss: 0.037933
 >> iter 8000, loss: 0.020541
 >> iter 9000, loss: 0.014197
 >> iter 10000, loss: 0.011510
   Number of active neurons: 4
 >> iter 11000, loss: 0.010603
 >> iter 12000, loss: 0.009952
 >> iter 13000, loss: 0.009840
 >> iter 14000, loss: 0.009512
 >> iter 15000, loss: 0.009550
 >> iter 16000, loss: 0.009302
 >> iter 17000, loss: 0.009374
 >> iter 18000, loss: 0.009148
 >> iter 19000, loss: 0.009222
 >> iter 20000, loss: 0.009004
   Number of active neurons: 4
 >> iter 21000, loss: 0.009062
 >> iter 22000, loss: 0.008837
 >> iter 23000, loss: 0.008895
 >> iter 24000, loss: 0.008678
 >> iter 25000, loss: 0.008752
 >> iter 26000, loss: 0.008579
 >> iter 27000, loss: 0.008690
 >> iter 28000, loss: 0.008555
 >> iter 29000, loss: 0.008674
 >> iter 30000, loss: 0.008546
   Number of active neurons: 4
 >> iter 31000, loss: 0.008666
 >> iter 32000, loss: 0.008541
 >> iter 33000, loss: 0.008662
 >> iter 34000, loss: 0.008540
 >> iter 35000, loss: 0.008668
 >> iter 36000, loss: 0.008542
 >> iter 37000, loss: 0.008668
 >> iter 38000, loss: 0.008543
 >> iter 39000, loss: 0.008672
 >> iter 40000, loss: 0.008546
   Number of active neurons: 4
 >> iter 41000, loss: 0.008674
 >> iter 42000, loss: 0.008559
 >> iter 43000, loss: 0.008669
 >> iter 44000, loss: 0.008557
 >> iter 45000, loss: 0.008676
 >> iter 46000, loss: 0.008565
 >> iter 47000, loss: 0.008683
 >> iter 48000, loss: 0.008583
 >> iter 49000, loss: 0.008699
 >> iter 50000, loss: 0.008592
   Number of active neurons: 4
 >> iter 51000, loss: 0.008708
 >> iter 52000, loss: 0.008612
 >> iter 53000, loss: 0.008716
 >> iter 54000, loss: 0.008632
 >> iter 55000, loss: 0.008721
 >> iter 56000, loss: 0.008651
 >> iter 57000, loss: 0.008745
 >> iter 58000, loss: 0.008663
 >> iter 59000, loss: 0.008770
 >> iter 60000, loss: 0.008696
   Number of active neurons: 4
 >> iter 61000, loss: 0.008792
 >> iter 62000, loss: 0.008721
 >> iter 63000, loss: 0.008813
 >> iter 64000, loss: 0.008733
 >> iter 65000, loss: 0.008824
 >> iter 66000, loss: 0.008737
 >> iter 67000, loss: 0.008818
 >> iter 68000, loss: 0.008748
 >> iter 69000, loss: 0.008821
 >> iter 70000, loss: 0.008737
   Number of active neurons: 3
 >> iter 71000, loss: 0.008807
 >> iter 72000, loss: 0.008730
 >> iter 73000, loss: 0.008798
 >> iter 74000, loss: 0.008717
 >> iter 75000, loss: 0.008786
 >> iter 76000, loss: 0.008702
 >> iter 77000, loss: 0.008762
 >> iter 78000, loss: 0.008672
 >> iter 79000, loss: 0.008741
 >> iter 80000, loss: 0.008638
   Number of active neurons: 3
 >> iter 81000, loss: 0.008709
 >> iter 82000, loss: 0.008581
 >> iter 83000, loss: 0.008627
 >> iter 84000, loss: 0.008467
 >> iter 85000, loss: 0.008507
 >> iter 86000, loss: 0.008360
 >> iter 87000, loss: 0.008414
 >> iter 88000, loss: 0.008276
 >> iter 89000, loss: 0.008329
 >> iter 90000, loss: 0.008202
   Number of active neurons: 3
 >> iter 91000, loss: 0.008260
 >> iter 92000, loss: 0.008151
 >> iter 93000, loss: 0.008223
 >> iter 94000, loss: 0.008121
 >> iter 95000, loss: 0.008213
 >> iter 96000, loss: 0.008105
 >> iter 97000, loss: 0.008204
 >> iter 98000, loss: 0.008097
 >> iter 99000, loss: 0.008203
 >> iter 100000, loss: 0.008105
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.703679
 >> iter 2000, loss: 3.950709
 >> iter 3000, loss: 1.463330
 >> iter 4000, loss: 0.546795
 >> iter 5000, loss: 0.209099
 >> iter 6000, loss: 0.084198
 >> iter 7000, loss: 0.038075
 >> iter 8000, loss: 0.020751
 >> iter 9000, loss: 0.014350
 >> iter 10000, loss: 0.011684
   Number of active neurons: 4
 >> iter 11000, loss: 0.010738
 >> iter 12000, loss: 0.010132
 >> iter 13000, loss: 0.009980
 >> iter 14000, loss: 0.009669
 >> iter 15000, loss: 0.009627
 >> iter 16000, loss: 0.009366
 >> iter 17000, loss: 0.009344
 >> iter 18000, loss: 0.009124
 >> iter 19000, loss: 0.009135
 >> iter 20000, loss: 0.008970
   Number of active neurons: 3
 >> iter 21000, loss: 0.009010
 >> iter 22000, loss: 0.008868
 >> iter 23000, loss: 0.008930
 >> iter 24000, loss: 0.008797
 >> iter 25000, loss: 0.008867
 >> iter 26000, loss: 0.008727
 >> iter 27000, loss: 0.008768
 >> iter 28000, loss: 0.008621
 >> iter 29000, loss: 0.008664
 >> iter 30000, loss: 0.008525
   Number of active neurons: 3
 >> iter 31000, loss: 0.008576
 >> iter 32000, loss: 0.008440
 >> iter 33000, loss: 0.008491
 >> iter 34000, loss: 0.008351
 >> iter 35000, loss: 0.008397
 >> iter 36000, loss: 0.008247
 >> iter 37000, loss: 0.008294
 >> iter 38000, loss: 0.008147
 >> iter 39000, loss: 0.008202
 >> iter 40000, loss: 0.008065
   Number of active neurons: 3
 >> iter 41000, loss: 0.008132
 >> iter 42000, loss: 0.008014
 >> iter 43000, loss: 0.008081
 >> iter 44000, loss: 0.007977
 >> iter 45000, loss: 0.008051
 >> iter 46000, loss: 0.007947
 >> iter 47000, loss: 0.008020
 >> iter 48000, loss: 0.007923
 >> iter 49000, loss: 0.007998
 >> iter 50000, loss: 0.007896
   Number of active neurons: 2
 >> iter 51000, loss: 0.007969
 >> iter 52000, loss: 0.007869
 >> iter 53000, loss: 0.007919
 >> iter 54000, loss: 0.007816
 >> iter 55000, loss: 0.007847
 >> iter 56000, loss: 0.007748
 >> iter 57000, loss: 0.007773
 >> iter 58000, loss: 0.007643
 >> iter 59000, loss: 0.007670
 >> iter 60000, loss: 0.007545
   Number of active neurons: 2
 >> iter 61000, loss: 0.007570
 >> iter 62000, loss: 0.007440
 >> iter 63000, loss: 0.007451
 >> iter 64000, loss: 0.007314
 >> iter 65000, loss: 0.007336
 >> iter 66000, loss: 0.007207
 >> iter 67000, loss: 0.007229
 >> iter 68000, loss: 0.007111
 >> iter 69000, loss: 0.007128
 >> iter 70000, loss: 0.007016
   Number of active neurons: 2
 >> iter 71000, loss: 0.007051
 >> iter 72000, loss: 0.006956
 >> iter 73000, loss: 0.006998
 >> iter 74000, loss: 0.006909
 >> iter 75000, loss: 0.006960
 >> iter 76000, loss: 0.006875
 >> iter 77000, loss: 0.006928
 >> iter 78000, loss: 0.006844
 >> iter 79000, loss: 0.006913
 >> iter 80000, loss: 0.006823
   Number of active neurons: 2
 >> iter 81000, loss: 0.006903
 >> iter 82000, loss: 0.006805
 >> iter 83000, loss: 0.006893
 >> iter 84000, loss: 0.006787
 >> iter 85000, loss: 0.006875
 >> iter 86000, loss: 0.006770
 >> iter 87000, loss: 0.006862
 >> iter 88000, loss: 0.006756
 >> iter 89000, loss: 0.006847
 >> iter 90000, loss: 0.006747
   Number of active neurons: 2
 >> iter 91000, loss: 0.006835
 >> iter 92000, loss: 0.006739
 >> iter 93000, loss: 0.006828
 >> iter 94000, loss: 0.006726
 >> iter 95000, loss: 0.006829
 >> iter 96000, loss: 0.006717
 >> iter 97000, loss: 0.006823
 >> iter 98000, loss: 0.006707
 >> iter 99000, loss: 0.006817
 >> iter 100000, loss: 0.006707
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.737673
 >> iter 2000, loss: 3.962523
 >> iter 3000, loss: 1.467266
 >> iter 4000, loss: 0.547860
 >> iter 5000, loss: 0.209109
 >> iter 6000, loss: 0.083807
 >> iter 7000, loss: 0.037580
 >> iter 8000, loss: 0.020187
 >> iter 9000, loss: 0.013829
 >> iter 10000, loss: 0.011214
   Number of active neurons: 5
 >> iter 11000, loss: 0.010349
 >> iter 12000, loss: 0.009786
 >> iter 13000, loss: 0.009694
 >> iter 14000, loss: 0.009427
 >> iter 15000, loss: 0.009471
 >> iter 16000, loss: 0.009282
 >> iter 17000, loss: 0.009362
 >> iter 18000, loss: 0.009197
 >> iter 19000, loss: 0.009272
 >> iter 20000, loss: 0.009119
   Number of active neurons: 4
 >> iter 21000, loss: 0.009196
 >> iter 22000, loss: 0.009044
 >> iter 23000, loss: 0.009120
 >> iter 24000, loss: 0.008959
 >> iter 25000, loss: 0.009039
 >> iter 26000, loss: 0.008885
 >> iter 27000, loss: 0.008951
 >> iter 28000, loss: 0.008803
 >> iter 29000, loss: 0.008868
 >> iter 30000, loss: 0.008729
   Number of active neurons: 4
 >> iter 31000, loss: 0.008803
 >> iter 32000, loss: 0.008683
 >> iter 33000, loss: 0.008771
 >> iter 34000, loss: 0.008650
 >> iter 35000, loss: 0.008740
 >> iter 36000, loss: 0.008621
 >> iter 37000, loss: 0.008721
 >> iter 38000, loss: 0.008614
 >> iter 39000, loss: 0.008722
 >> iter 40000, loss: 0.008610
   Number of active neurons: 3
 >> iter 41000, loss: 0.008713
 >> iter 42000, loss: 0.008603
 >> iter 43000, loss: 0.008692
 >> iter 44000, loss: 0.008585
 >> iter 45000, loss: 0.008670
 >> iter 46000, loss: 0.008555
 >> iter 47000, loss: 0.008631
 >> iter 48000, loss: 0.008517
 >> iter 49000, loss: 0.008584
 >> iter 50000, loss: 0.008448
   Number of active neurons: 3
 >> iter 51000, loss: 0.008503
 >> iter 52000, loss: 0.008366
 >> iter 53000, loss: 0.008402
 >> iter 54000, loss: 0.008281
 >> iter 55000, loss: 0.008307
 >> iter 56000, loss: 0.008192
 >> iter 57000, loss: 0.008221
 >> iter 58000, loss: 0.008102
 >> iter 59000, loss: 0.008153
 >> iter 60000, loss: 0.008056
   Number of active neurons: 3
 >> iter 61000, loss: 0.008114
 >> iter 62000, loss: 0.008033
 >> iter 63000, loss: 0.008099
 >> iter 64000, loss: 0.008018
 >> iter 65000, loss: 0.008086
 >> iter 66000, loss: 0.008002
 >> iter 67000, loss: 0.008070
 >> iter 68000, loss: 0.008004
 >> iter 69000, loss: 0.008069
 >> iter 70000, loss: 0.008000
   Number of active neurons: 3
 >> iter 71000, loss: 0.008072
 >> iter 72000, loss: 0.008010
 >> iter 73000, loss: 0.008078
 >> iter 74000, loss: 0.008014
 >> iter 75000, loss: 0.008086
 >> iter 76000, loss: 0.008022
 >> iter 77000, loss: 0.008091
 >> iter 78000, loss: 0.008024
 >> iter 79000, loss: 0.008099
 >> iter 80000, loss: 0.008022
   Number of active neurons: 3
 >> iter 81000, loss: 0.008112
 >> iter 82000, loss: 0.008030
 >> iter 83000, loss: 0.008127
 >> iter 84000, loss: 0.008038
 >> iter 85000, loss: 0.008132
 >> iter 86000, loss: 0.008043
 >> iter 87000, loss: 0.008138
 >> iter 88000, loss: 0.008048
 >> iter 89000, loss: 0.008140
 >> iter 90000, loss: 0.008056
   Number of active neurons: 3
 >> iter 91000, loss: 0.008143
 >> iter 92000, loss: 0.008062
 >> iter 93000, loss: 0.008147
 >> iter 94000, loss: 0.008060
 >> iter 95000, loss: 0.008157
 >> iter 96000, loss: 0.008058
 >> iter 97000, loss: 0.008156
 >> iter 98000, loss: 0.008053
 >> iter 99000, loss: 0.008153
 >> iter 100000, loss: 0.008056
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.693404
 >> iter 2000, loss: 3.946718
 >> iter 3000, loss: 1.461747
 >> iter 4000, loss: 0.546201
 >> iter 5000, loss: 0.208957
 >> iter 6000, loss: 0.084387
 >> iter 7000, loss: 0.038492
 >> iter 8000, loss: 0.021347
 >> iter 9000, loss: 0.015128
 >> iter 10000, loss: 0.012658
   Number of active neurons: 6
 >> iter 11000, loss: 0.011854
 >> iter 12000, loss: 0.011354
 >> iter 13000, loss: 0.011297
 >> iter 14000, loss: 0.011071
 >> iter 15000, loss: 0.011112
 >> iter 16000, loss: 0.010918
 >> iter 17000, loss: 0.010962
 >> iter 18000, loss: 0.010768
 >> iter 19000, loss: 0.010794
 >> iter 20000, loss: 0.010617
   Number of active neurons: 4
 >> iter 21000, loss: 0.010642
 >> iter 22000, loss: 0.010450
 >> iter 23000, loss: 0.010458
 >> iter 24000, loss: 0.010257
 >> iter 25000, loss: 0.010278
 >> iter 26000, loss: 0.010093
 >> iter 27000, loss: 0.010109
 >> iter 28000, loss: 0.009934
 >> iter 29000, loss: 0.009950
 >> iter 30000, loss: 0.009779
   Number of active neurons: 4
 >> iter 31000, loss: 0.009800
 >> iter 32000, loss: 0.009642
 >> iter 33000, loss: 0.009670
 >> iter 34000, loss: 0.009519
 >> iter 35000, loss: 0.009563
 >> iter 36000, loss: 0.009419
 >> iter 37000, loss: 0.009473
 >> iter 38000, loss: 0.009344
 >> iter 39000, loss: 0.009420
 >> iter 40000, loss: 0.009306
   Number of active neurons: 4
 >> iter 41000, loss: 0.009392
 >> iter 42000, loss: 0.009292
 >> iter 43000, loss: 0.009378
 >> iter 44000, loss: 0.009291
 >> iter 45000, loss: 0.009377
 >> iter 46000, loss: 0.009291
 >> iter 47000, loss: 0.009376
 >> iter 48000, loss: 0.009295
 >> iter 49000, loss: 0.009379
 >> iter 50000, loss: 0.009293
   Number of active neurons: 4
 >> iter 51000, loss: 0.009377
 >> iter 52000, loss: 0.009294
 >> iter 53000, loss: 0.009365
 >> iter 54000, loss: 0.009293
 >> iter 55000, loss: 0.009345
 >> iter 56000, loss: 0.009270
 >> iter 57000, loss: 0.009322
 >> iter 58000, loss: 0.009229
 >> iter 59000, loss: 0.009278
 >> iter 60000, loss: 0.009177
   Number of active neurons: 2
 >> iter 61000, loss: 0.009205
 >> iter 62000, loss: 0.009095
 >> iter 63000, loss: 0.009107
 >> iter 64000, loss: 0.008959
 >> iter 65000, loss: 0.008922
 >> iter 66000, loss: 0.008722
 >> iter 67000, loss: 0.008649
 >> iter 68000, loss: 0.008463
 >> iter 69000, loss: 0.008399
 >> iter 70000, loss: 0.008225
   Number of active neurons: 2
 >> iter 71000, loss: 0.008173
 >> iter 72000, loss: 0.008015
 >> iter 73000, loss: 0.007978
 >> iter 74000, loss: 0.007849
 >> iter 75000, loss: 0.007844
 >> iter 76000, loss: 0.007742
 >> iter 77000, loss: 0.007754
 >> iter 78000, loss: 0.007666
 >> iter 79000, loss: 0.007702
 >> iter 80000, loss: 0.007619
   Number of active neurons: 2
 >> iter 81000, loss: 0.007670
 >> iter 82000, loss: 0.007587
 >> iter 83000, loss: 0.007647
 >> iter 84000, loss: 0.007564
 >> iter 85000, loss: 0.007625
 >> iter 86000, loss: 0.007545
 >> iter 87000, loss: 0.007610
 >> iter 88000, loss: 0.007532
 >> iter 89000, loss: 0.007596
 >> iter 90000, loss: 0.007525
   Number of active neurons: 2
 >> iter 91000, loss: 0.007587
 >> iter 92000, loss: 0.007519
 >> iter 93000, loss: 0.007579
 >> iter 94000, loss: 0.007507
 >> iter 95000, loss: 0.007577
 >> iter 96000, loss: 0.007496
 >> iter 97000, loss: 0.007567
 >> iter 98000, loss: 0.007482
 >> iter 99000, loss: 0.007555
 >> iter 100000, loss: 0.007476
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.712963
 >> iter 2000, loss: 3.955479
 >> iter 3000, loss: 1.465637
 >> iter 4000, loss: 0.547882
 >> iter 5000, loss: 0.209509
 >> iter 6000, loss: 0.084291
 >> iter 7000, loss: 0.037944
 >> iter 8000, loss: 0.020459
 >> iter 9000, loss: 0.013921
 >> iter 10000, loss: 0.011181
   Number of active neurons: 3
 >> iter 11000, loss: 0.010136
 >> iter 12000, loss: 0.009475
 >> iter 13000, loss: 0.009245
 >> iter 14000, loss: 0.008919
 >> iter 15000, loss: 0.008846
 >> iter 16000, loss: 0.008610
 >> iter 17000, loss: 0.008585
 >> iter 18000, loss: 0.008394
 >> iter 19000, loss: 0.008397
 >> iter 20000, loss: 0.008248
   Number of active neurons: 3
 >> iter 21000, loss: 0.008274
 >> iter 22000, loss: 0.008144
 >> iter 23000, loss: 0.008189
 >> iter 24000, loss: 0.008067
 >> iter 25000, loss: 0.008123
 >> iter 26000, loss: 0.008011
 >> iter 27000, loss: 0.008062
 >> iter 28000, loss: 0.007940
 >> iter 29000, loss: 0.007961
 >> iter 30000, loss: 0.007814
   Number of active neurons: 2
 >> iter 31000, loss: 0.007830
 >> iter 32000, loss: 0.007688
 >> iter 33000, loss: 0.007712
 >> iter 34000, loss: 0.007575
 >> iter 35000, loss: 0.007608
 >> iter 36000, loss: 0.007462
 >> iter 37000, loss: 0.007485
 >> iter 38000, loss: 0.007332
 >> iter 39000, loss: 0.007362
 >> iter 40000, loss: 0.007212
   Number of active neurons: 2
 >> iter 41000, loss: 0.007245
 >> iter 42000, loss: 0.007106
 >> iter 43000, loss: 0.007143
 >> iter 44000, loss: 0.007023
 >> iter 45000, loss: 0.007074
 >> iter 46000, loss: 0.006962
 >> iter 47000, loss: 0.007021
 >> iter 48000, loss: 0.006920
 >> iter 49000, loss: 0.006986
 >> iter 50000, loss: 0.006885
   Number of active neurons: 2
 >> iter 51000, loss: 0.006956
 >> iter 52000, loss: 0.006861
 >> iter 53000, loss: 0.006928
 >> iter 54000, loss: 0.006848
 >> iter 55000, loss: 0.006904
 >> iter 56000, loss: 0.006829
 >> iter 57000, loss: 0.006892
 >> iter 58000, loss: 0.006807
 >> iter 59000, loss: 0.006875
 >> iter 60000, loss: 0.006794
   Number of active neurons: 2
 >> iter 61000, loss: 0.006858
 >> iter 62000, loss: 0.006781
 >> iter 63000, loss: 0.006845
 >> iter 64000, loss: 0.006763
 >> iter 65000, loss: 0.006833
 >> iter 66000, loss: 0.006752
 >> iter 67000, loss: 0.006817
 >> iter 68000, loss: 0.006746
 >> iter 69000, loss: 0.006807
 >> iter 70000, loss: 0.006731
   Number of active neurons: 2
 >> iter 71000, loss: 0.006796
 >> iter 72000, loss: 0.006724
 >> iter 73000, loss: 0.006787
 >> iter 74000, loss: 0.006713
 >> iter 75000, loss: 0.006779
 >> iter 76000, loss: 0.006704
 >> iter 77000, loss: 0.006768
 >> iter 78000, loss: 0.006691
 >> iter 79000, loss: 0.006769
 >> iter 80000, loss: 0.006685
   Number of active neurons: 2
 >> iter 81000, loss: 0.006772
 >> iter 82000, loss: 0.006677
 >> iter 83000, loss: 0.006772
 >> iter 84000, loss: 0.006669
 >> iter 85000, loss: 0.006764
 >> iter 86000, loss: 0.006661
 >> iter 87000, loss: 0.006758
 >> iter 88000, loss: 0.006654
 >> iter 89000, loss: 0.006750
 >> iter 90000, loss: 0.006651
   Number of active neurons: 2
 >> iter 91000, loss: 0.006744
 >> iter 92000, loss: 0.006649
 >> iter 93000, loss: 0.006743
 >> iter 94000, loss: 0.006641
 >> iter 95000, loss: 0.006748
 >> iter 96000, loss: 0.006637
 >> iter 97000, loss: 0.006747
 >> iter 98000, loss: 0.006631
 >> iter 99000, loss: 0.006745
 >> iter 100000, loss: 0.006635
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.718806
 >> iter 2000, loss: 3.955789
 >> iter 3000, loss: 1.465116
 >> iter 4000, loss: 0.547522
 >> iter 5000, loss: 0.209533
 >> iter 6000, loss: 0.084649
 >> iter 7000, loss: 0.038663
 >> iter 8000, loss: 0.021438
 >> iter 9000, loss: 0.015170
 >> iter 10000, loss: 0.012617
   Number of active neurons: 6
 >> iter 11000, loss: 0.011792
 >> iter 12000, loss: 0.011266
 >> iter 13000, loss: 0.011201
 >> iter 14000, loss: 0.010952
 >> iter 15000, loss: 0.010981
 >> iter 16000, loss: 0.010765
 >> iter 17000, loss: 0.010801
 >> iter 18000, loss: 0.010601
 >> iter 19000, loss: 0.010636
 >> iter 20000, loss: 0.010443
   Number of active neurons: 4
 >> iter 21000, loss: 0.010464
 >> iter 22000, loss: 0.010256
 >> iter 23000, loss: 0.010259
 >> iter 24000, loss: 0.010025
 >> iter 25000, loss: 0.010010
 >> iter 26000, loss: 0.009767
 >> iter 27000, loss: 0.009733
 >> iter 28000, loss: 0.009504
 >> iter 29000, loss: 0.009474
 >> iter 30000, loss: 0.009265
   Number of active neurons: 3
 >> iter 31000, loss: 0.009260
 >> iter 32000, loss: 0.009080
 >> iter 33000, loss: 0.009102
 >> iter 34000, loss: 0.008953
 >> iter 35000, loss: 0.008997
 >> iter 36000, loss: 0.008847
 >> iter 37000, loss: 0.008891
 >> iter 38000, loss: 0.008747
 >> iter 39000, loss: 0.008799
 >> iter 40000, loss: 0.008653
   Number of active neurons: 3
 >> iter 41000, loss: 0.008690
 >> iter 42000, loss: 0.008534
 >> iter 43000, loss: 0.008553
 >> iter 44000, loss: 0.008396
 >> iter 45000, loss: 0.008416
 >> iter 46000, loss: 0.008264
 >> iter 47000, loss: 0.008286
 >> iter 48000, loss: 0.008145
 >> iter 49000, loss: 0.008173
 >> iter 50000, loss: 0.008040
   Number of active neurons: 2
 >> iter 51000, loss: 0.008080
 >> iter 52000, loss: 0.007960
 >> iter 53000, loss: 0.007995
 >> iter 54000, loss: 0.007891
 >> iter 55000, loss: 0.007911
 >> iter 56000, loss: 0.007807
 >> iter 57000, loss: 0.007818
 >> iter 58000, loss: 0.007678
 >> iter 59000, loss: 0.007676
 >> iter 60000, loss: 0.007541
   Number of active neurons: 2
 >> iter 61000, loss: 0.007543
 >> iter 62000, loss: 0.007422
 >> iter 63000, loss: 0.007431
 >> iter 64000, loss: 0.007310
 >> iter 65000, loss: 0.007328
 >> iter 66000, loss: 0.007222
 >> iter 67000, loss: 0.007249
 >> iter 68000, loss: 0.007167
 >> iter 69000, loss: 0.007190
 >> iter 70000, loss: 0.007105
   Number of active neurons: 2
 >> iter 71000, loss: 0.007143
 >> iter 72000, loss: 0.007072
 >> iter 73000, loss: 0.007114
 >> iter 74000, loss: 0.007045
 >> iter 75000, loss: 0.007093
 >> iter 76000, loss: 0.007027
 >> iter 77000, loss: 0.007076
 >> iter 78000, loss: 0.007009
 >> iter 79000, loss: 0.007073
 >> iter 80000, loss: 0.007001
   Number of active neurons: 2
 >> iter 81000, loss: 0.007073
 >> iter 82000, loss: 0.006995
 >> iter 83000, loss: 0.007073
 >> iter 84000, loss: 0.006986
 >> iter 85000, loss: 0.007054
 >> iter 86000, loss: 0.006966
 >> iter 87000, loss: 0.007044
 >> iter 88000, loss: 0.006960
 >> iter 89000, loss: 0.007038
 >> iter 90000, loss: 0.006960
   Number of active neurons: 2
 >> iter 91000, loss: 0.007035
 >> iter 92000, loss: 0.006961
 >> iter 93000, loss: 0.007035
 >> iter 94000, loss: 0.006956
 >> iter 95000, loss: 0.007041
 >> iter 96000, loss: 0.006953
 >> iter 97000, loss: 0.007041
 >> iter 98000, loss: 0.006949
 >> iter 99000, loss: 0.007041
 >> iter 100000, loss: 0.006955
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.728477
 >> iter 2000, loss: 3.959251
 >> iter 3000, loss: 1.466304
 >> iter 4000, loss: 0.547953
 >> iter 5000, loss: 0.209803
 >> iter 6000, loss: 0.084843
 >> iter 7000, loss: 0.038801
 >> iter 8000, loss: 0.021533
 >> iter 9000, loss: 0.015234
 >> iter 10000, loss: 0.012649
   Number of active neurons: 6
 >> iter 11000, loss: 0.011794
 >> iter 12000, loss: 0.011238
 >> iter 13000, loss: 0.011152
 >> iter 14000, loss: 0.010886
 >> iter 15000, loss: 0.010918
 >> iter 16000, loss: 0.010700
 >> iter 17000, loss: 0.010739
 >> iter 18000, loss: 0.010538
 >> iter 19000, loss: 0.010569
 >> iter 20000, loss: 0.010371
   Number of active neurons: 4
 >> iter 21000, loss: 0.010392
 >> iter 22000, loss: 0.010193
 >> iter 23000, loss: 0.010221
 >> iter 24000, loss: 0.010033
 >> iter 25000, loss: 0.010063
 >> iter 26000, loss: 0.009878
 >> iter 27000, loss: 0.009901
 >> iter 28000, loss: 0.009705
 >> iter 29000, loss: 0.009697
 >> iter 30000, loss: 0.009490
   Number of active neurons: 3
 >> iter 31000, loss: 0.009471
 >> iter 32000, loss: 0.009268
 >> iter 33000, loss: 0.009255
 >> iter 34000, loss: 0.009059
 >> iter 35000, loss: 0.009056
 >> iter 36000, loss: 0.008851
 >> iter 37000, loss: 0.008843
 >> iter 38000, loss: 0.008648
 >> iter 39000, loss: 0.008656
 >> iter 40000, loss: 0.008467
   Number of active neurons: 2
 >> iter 41000, loss: 0.008472
 >> iter 42000, loss: 0.008286
 >> iter 43000, loss: 0.008279
 >> iter 44000, loss: 0.008107
 >> iter 45000, loss: 0.008112
 >> iter 46000, loss: 0.007954
 >> iter 47000, loss: 0.007969
 >> iter 48000, loss: 0.007814
 >> iter 49000, loss: 0.007824
 >> iter 50000, loss: 0.007668
   Number of active neurons: 2
 >> iter 51000, loss: 0.007685
 >> iter 52000, loss: 0.007529
 >> iter 53000, loss: 0.007536
 >> iter 54000, loss: 0.007399
 >> iter 55000, loss: 0.007402
 >> iter 56000, loss: 0.007278
 >> iter 57000, loss: 0.007290
 >> iter 58000, loss: 0.007162
 >> iter 59000, loss: 0.007192
 >> iter 60000, loss: 0.007082
   Number of active neurons: 2
 >> iter 61000, loss: 0.007119
 >> iter 62000, loss: 0.007024
 >> iter 63000, loss: 0.007070
 >> iter 64000, loss: 0.006976
 >> iter 65000, loss: 0.007032
 >> iter 66000, loss: 0.006945
 >> iter 67000, loss: 0.006999
 >> iter 68000, loss: 0.006924
 >> iter 69000, loss: 0.006975
 >> iter 70000, loss: 0.006897
   Number of active neurons: 2
 >> iter 71000, loss: 0.006954
 >> iter 72000, loss: 0.006881
 >> iter 73000, loss: 0.006937
 >> iter 74000, loss: 0.006862
 >> iter 75000, loss: 0.006921
 >> iter 76000, loss: 0.006847
 >> iter 77000, loss: 0.006905
 >> iter 78000, loss: 0.006829
 >> iter 79000, loss: 0.006901
 >> iter 80000, loss: 0.006818
   Number of active neurons: 2
 >> iter 81000, loss: 0.006899
 >> iter 82000, loss: 0.006808
 >> iter 83000, loss: 0.006896
 >> iter 84000, loss: 0.006797
 >> iter 85000, loss: 0.006885
 >> iter 86000, loss: 0.006787
 >> iter 87000, loss: 0.006877
 >> iter 88000, loss: 0.006778
 >> iter 89000, loss: 0.006868
 >> iter 90000, loss: 0.006775
   Number of active neurons: 2
 >> iter 91000, loss: 0.006861
 >> iter 92000, loss: 0.006773
 >> iter 93000, loss: 0.006860
 >> iter 94000, loss: 0.006766
 >> iter 95000, loss: 0.006866
 >> iter 96000, loss: 0.006763
 >> iter 97000, loss: 0.006865
 >> iter 98000, loss: 0.006759
 >> iter 99000, loss: 0.006865
 >> iter 100000, loss: 0.006765
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.738536
 >> iter 2000, loss: 3.962847
 >> iter 3000, loss: 1.467700
 >> iter 4000, loss: 0.548502
 >> iter 5000, loss: 0.209977
 >> iter 6000, loss: 0.084800
 >> iter 7000, loss: 0.038641
 >> iter 8000, loss: 0.021254
 >> iter 9000, loss: 0.014891
 >> iter 10000, loss: 0.012259
   Number of active neurons: 6
 >> iter 11000, loss: 0.011398
 >> iter 12000, loss: 0.010820
 >> iter 13000, loss: 0.010726
 >> iter 14000, loss: 0.010441
 >> iter 15000, loss: 0.010458
 >> iter 16000, loss: 0.010227
 >> iter 17000, loss: 0.010273
 >> iter 18000, loss: 0.010068
 >> iter 19000, loss: 0.010111
 >> iter 20000, loss: 0.009907
   Number of active neurons: 4
 >> iter 21000, loss: 0.009920
 >> iter 22000, loss: 0.009698
 >> iter 23000, loss: 0.009712
 >> iter 24000, loss: 0.009499
 >> iter 25000, loss: 0.009518
 >> iter 26000, loss: 0.009303
 >> iter 27000, loss: 0.009311
 >> iter 28000, loss: 0.009108
 >> iter 29000, loss: 0.009112
 >> iter 30000, loss: 0.008920
   Number of active neurons: 3
 >> iter 31000, loss: 0.008936
 >> iter 32000, loss: 0.008762
 >> iter 33000, loss: 0.008789
 >> iter 34000, loss: 0.008635
 >> iter 35000, loss: 0.008682
 >> iter 36000, loss: 0.008529
 >> iter 37000, loss: 0.008568
 >> iter 38000, loss: 0.008406
 >> iter 39000, loss: 0.008446
 >> iter 40000, loss: 0.008287
   Number of active neurons: 3
 >> iter 41000, loss: 0.008332
 >> iter 42000, loss: 0.008193
 >> iter 43000, loss: 0.008238
 >> iter 44000, loss: 0.008110
 >> iter 45000, loss: 0.008156
 >> iter 46000, loss: 0.008026
 >> iter 47000, loss: 0.008087
 >> iter 48000, loss: 0.007990
 >> iter 49000, loss: 0.008070
 >> iter 50000, loss: 0.007978
   Number of active neurons: 3
 >> iter 51000, loss: 0.008065
 >> iter 52000, loss: 0.007981
 >> iter 53000, loss: 0.008062
 >> iter 54000, loss: 0.007995
 >> iter 55000, loss: 0.008063
 >> iter 56000, loss: 0.008001
 >> iter 57000, loss: 0.008075
 >> iter 58000, loss: 0.007994
 >> iter 59000, loss: 0.008070
 >> iter 60000, loss: 0.007999
   Number of active neurons: 3
 >> iter 61000, loss: 0.008075
 >> iter 62000, loss: 0.008011
 >> iter 63000, loss: 0.008087
 >> iter 64000, loss: 0.008015
 >> iter 65000, loss: 0.008096
 >> iter 66000, loss: 0.008025
 >> iter 67000, loss: 0.008099
 >> iter 68000, loss: 0.008040
 >> iter 69000, loss: 0.008107
 >> iter 70000, loss: 0.008042
   Number of active neurons: 3
 >> iter 71000, loss: 0.008113
 >> iter 72000, loss: 0.008053
 >> iter 73000, loss: 0.008121
 >> iter 74000, loss: 0.008058
 >> iter 75000, loss: 0.008129
 >> iter 76000, loss: 0.008065
 >> iter 77000, loss: 0.008134
 >> iter 78000, loss: 0.008068
 >> iter 79000, loss: 0.008151
 >> iter 80000, loss: 0.008078
   Number of active neurons: 3
 >> iter 81000, loss: 0.008170
 >> iter 82000, loss: 0.008088
 >> iter 83000, loss: 0.008186
 >> iter 84000, loss: 0.008097
 >> iter 85000, loss: 0.008192
 >> iter 86000, loss: 0.008105
 >> iter 87000, loss: 0.008203
 >> iter 88000, loss: 0.008115
 >> iter 89000, loss: 0.008211
 >> iter 90000, loss: 0.008131
   Number of active neurons: 3
 >> iter 91000, loss: 0.008223
 >> iter 92000, loss: 0.008146
 >> iter 93000, loss: 0.008237
 >> iter 94000, loss: 0.008155
 >> iter 95000, loss: 0.008259
 >> iter 96000, loss: 0.008167
 >> iter 97000, loss: 0.008273
 >> iter 98000, loss: 0.008178
 >> iter 99000, loss: 0.008288
 >> iter 100000, loss: 0.008201
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.681003
 >> iter 2000, loss: 3.942228
 >> iter 3000, loss: 1.460223
 >> iter 4000, loss: 0.545722
 >> iter 5000, loss: 0.208859
 >> iter 6000, loss: 0.084350
 >> iter 7000, loss: 0.038412
 >> iter 8000, loss: 0.021138
 >> iter 9000, loss: 0.014784
 >> iter 10000, loss: 0.012157
   Number of active neurons: 5
 >> iter 11000, loss: 0.011236
 >> iter 12000, loss: 0.010636
 >> iter 13000, loss: 0.010493
 >> iter 14000, loss: 0.010196
 >> iter 15000, loss: 0.010180
 >> iter 16000, loss: 0.009953
 >> iter 17000, loss: 0.009964
 >> iter 18000, loss: 0.009771
 >> iter 19000, loss: 0.009811
 >> iter 20000, loss: 0.009665
   Number of active neurons: 4
 >> iter 21000, loss: 0.009725
 >> iter 22000, loss: 0.009587
 >> iter 23000, loss: 0.009648
 >> iter 24000, loss: 0.009505
 >> iter 25000, loss: 0.009574
 >> iter 26000, loss: 0.009438
 >> iter 27000, loss: 0.009495
 >> iter 28000, loss: 0.009345
 >> iter 29000, loss: 0.009379
 >> iter 30000, loss: 0.009227
   Number of active neurons: 3
 >> iter 31000, loss: 0.009255
 >> iter 32000, loss: 0.009084
 >> iter 33000, loss: 0.009092
 >> iter 34000, loss: 0.008921
 >> iter 35000, loss: 0.008937
 >> iter 36000, loss: 0.008765
 >> iter 37000, loss: 0.008780
 >> iter 38000, loss: 0.008604
 >> iter 39000, loss: 0.008624
 >> iter 40000, loss: 0.008447
   Number of active neurons: 3
 >> iter 41000, loss: 0.008464
 >> iter 42000, loss: 0.008302
 >> iter 43000, loss: 0.008320
 >> iter 44000, loss: 0.008172
 >> iter 45000, loss: 0.008197
 >> iter 46000, loss: 0.008061
 >> iter 47000, loss: 0.008096
 >> iter 48000, loss: 0.007976
 >> iter 49000, loss: 0.008016
 >> iter 50000, loss: 0.007894
   Number of active neurons: 2
 >> iter 51000, loss: 0.007933
 >> iter 52000, loss: 0.007815
 >> iter 53000, loss: 0.007836
 >> iter 54000, loss: 0.007710
 >> iter 55000, loss: 0.007696
 >> iter 56000, loss: 0.007568
 >> iter 57000, loss: 0.007567
 >> iter 58000, loss: 0.007440
 >> iter 59000, loss: 0.007452
 >> iter 60000, loss: 0.007333
   Number of active neurons: 2
 >> iter 61000, loss: 0.007344
 >> iter 62000, loss: 0.007241
 >> iter 63000, loss: 0.007266
 >> iter 64000, loss: 0.007165
 >> iter 65000, loss: 0.007199
 >> iter 66000, loss: 0.007111
 >> iter 67000, loss: 0.007152
 >> iter 68000, loss: 0.007082
 >> iter 69000, loss: 0.007123
 >> iter 70000, loss: 0.007054
   Number of active neurons: 2
 >> iter 71000, loss: 0.007102
 >> iter 72000, loss: 0.007040
 >> iter 73000, loss: 0.007088
 >> iter 74000, loss: 0.007025
 >> iter 75000, loss: 0.007077
 >> iter 76000, loss: 0.007015
 >> iter 77000, loss: 0.007066
 >> iter 78000, loss: 0.007004
 >> iter 79000, loss: 0.007060
 >> iter 80000, loss: 0.006985
   Number of active neurons: 2
 >> iter 81000, loss: 0.007054
 >> iter 82000, loss: 0.006977
 >> iter 83000, loss: 0.007055
 >> iter 84000, loss: 0.006973
 >> iter 85000, loss: 0.007050
 >> iter 86000, loss: 0.006968
 >> iter 87000, loss: 0.007047
 >> iter 88000, loss: 0.006964
 >> iter 89000, loss: 0.007042
 >> iter 90000, loss: 0.006965
   Number of active neurons: 2
 >> iter 91000, loss: 0.007039
 >> iter 92000, loss: 0.006965
 >> iter 93000, loss: 0.007040
 >> iter 94000, loss: 0.006961
 >> iter 95000, loss: 0.007046
 >> iter 96000, loss: 0.006958
 >> iter 97000, loss: 0.007046
 >> iter 98000, loss: 0.006955
 >> iter 99000, loss: 0.007047
 >> iter 100000, loss: 0.006962
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.759545
 >> iter 2000, loss: 3.973678
 >> iter 3000, loss: 1.473196
 >> iter 4000, loss: 0.551561
 >> iter 5000, loss: 0.211858
 >> iter 6000, loss: 0.086232
 >> iter 7000, loss: 0.039807
 >> iter 8000, loss: 0.022332
 >> iter 9000, loss: 0.015836
 >> iter 10000, loss: 0.013128
   Number of active neurons: 5
 >> iter 11000, loss: 0.012132
 >> iter 12000, loss: 0.011487
 >> iter 13000, loss: 0.011267
 >> iter 14000, loss: 0.010910
 >> iter 15000, loss: 0.010816
 >> iter 16000, loss: 0.010534
 >> iter 17000, loss: 0.010480
 >> iter 18000, loss: 0.010248
 >> iter 19000, loss: 0.010224
 >> iter 20000, loss: 0.010040
   Number of active neurons: 3
 >> iter 21000, loss: 0.010035
 >> iter 22000, loss: 0.009852
 >> iter 23000, loss: 0.009842
 >> iter 24000, loss: 0.009651
 >> iter 25000, loss: 0.009632
 >> iter 26000, loss: 0.009426
 >> iter 27000, loss: 0.009397
 >> iter 28000, loss: 0.009198
 >> iter 29000, loss: 0.009166
 >> iter 30000, loss: 0.008989
   Number of active neurons: 3
 >> iter 31000, loss: 0.008982
 >> iter 32000, loss: 0.008828
 >> iter 33000, loss: 0.008844
 >> iter 34000, loss: 0.008721
 >> iter 35000, loss: 0.008764
 >> iter 36000, loss: 0.008653
 >> iter 37000, loss: 0.008711
 >> iter 38000, loss: 0.008609
 >> iter 39000, loss: 0.008678
 >> iter 40000, loss: 0.008580
   Number of active neurons: 2
 >> iter 41000, loss: 0.008650
 >> iter 42000, loss: 0.008559
 >> iter 43000, loss: 0.008624
 >> iter 44000, loss: 0.008540
 >> iter 45000, loss: 0.008600
 >> iter 46000, loss: 0.008513
 >> iter 47000, loss: 0.008567
 >> iter 48000, loss: 0.008480
 >> iter 49000, loss: 0.008529
 >> iter 50000, loss: 0.008431
   Number of active neurons: 2
 >> iter 51000, loss: 0.008472
 >> iter 52000, loss: 0.008359
 >> iter 53000, loss: 0.008362
 >> iter 54000, loss: 0.008235
 >> iter 55000, loss: 0.008216
 >> iter 56000, loss: 0.008097
 >> iter 57000, loss: 0.008092
 >> iter 58000, loss: 0.007972
 >> iter 59000, loss: 0.007976
 >> iter 60000, loss: 0.007861
   Number of active neurons: 2
 >> iter 61000, loss: 0.007866
 >> iter 62000, loss: 0.007771
 >> iter 63000, loss: 0.007791
 >> iter 64000, loss: 0.007702
 >> iter 65000, loss: 0.007735
 >> iter 66000, loss: 0.007656
 >> iter 67000, loss: 0.007689
 >> iter 68000, loss: 0.007625
 >> iter 69000, loss: 0.007655
 >> iter 70000, loss: 0.007588
   Number of active neurons: 1
 >> iter 71000, loss: 0.007623
 >> iter 72000, loss: 0.007561
 >> iter 73000, loss: 0.007593
 >> iter 74000, loss: 0.007527
 >> iter 75000, loss: 0.007558
 >> iter 76000, loss: 0.007490
 >> iter 77000, loss: 0.007515
 >> iter 78000, loss: 0.007440
 >> iter 79000, loss: 0.007469
 >> iter 80000, loss: 0.007382
   Number of active neurons: 1
 >> iter 81000, loss: 0.007407
 >> iter 82000, loss: 0.007290
 >> iter 83000, loss: 0.007278
 >> iter 84000, loss: 0.007125
 >> iter 85000, loss: 0.007101
 >> iter 86000, loss: 0.006954
 >> iter 87000, loss: 0.006939
 >> iter 88000, loss: 0.006800
 >> iter 89000, loss: 0.006788
 >> iter 90000, loss: 0.006655
   Number of active neurons: 1
 >> iter 91000, loss: 0.006640
 >> iter 92000, loss: 0.006519
 >> iter 93000, loss: 0.006516
 >> iter 94000, loss: 0.006407
 >> iter 95000, loss: 0.006425
 >> iter 96000, loss: 0.006319
 >> iter 97000, loss: 0.006348
 >> iter 98000, loss: 0.006248
 >> iter 99000, loss: 0.006286
 >> iter 100000, loss: 0.006197
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.736205
 >> iter 2000, loss: 3.962978
 >> iter 3000, loss: 1.468012
 >> iter 4000, loss: 0.548629
 >> iter 5000, loss: 0.209814
 >> iter 6000, loss: 0.084448
 >> iter 7000, loss: 0.038106
 >> iter 8000, loss: 0.020654
 >> iter 9000, loss: 0.014185
 >> iter 10000, loss: 0.011503
   Number of active neurons: 3
 >> iter 11000, loss: 0.010531
 >> iter 12000, loss: 0.009907
 >> iter 13000, loss: 0.009721
 >> iter 14000, loss: 0.009406
 >> iter 15000, loss: 0.009353
 >> iter 16000, loss: 0.009099
 >> iter 17000, loss: 0.009056
 >> iter 18000, loss: 0.008810
 >> iter 19000, loss: 0.008769
 >> iter 20000, loss: 0.008559
   Number of active neurons: 3
 >> iter 21000, loss: 0.008545
 >> iter 22000, loss: 0.008366
 >> iter 23000, loss: 0.008382
 >> iter 24000, loss: 0.008226
 >> iter 25000, loss: 0.008261
 >> iter 26000, loss: 0.008137
 >> iter 27000, loss: 0.008196
 >> iter 28000, loss: 0.008095
 >> iter 29000, loss: 0.008157
 >> iter 30000, loss: 0.008058
   Number of active neurons: 3
 >> iter 31000, loss: 0.008126
 >> iter 32000, loss: 0.008037
 >> iter 33000, loss: 0.008112
 >> iter 34000, loss: 0.008019
 >> iter 35000, loss: 0.008100
 >> iter 36000, loss: 0.008009
 >> iter 37000, loss: 0.008097
 >> iter 38000, loss: 0.008008
 >> iter 39000, loss: 0.008103
 >> iter 40000, loss: 0.008013
   Number of active neurons: 3
 >> iter 41000, loss: 0.008107
 >> iter 42000, loss: 0.008023
 >> iter 43000, loss: 0.008111
 >> iter 44000, loss: 0.008034
 >> iter 45000, loss: 0.008113
 >> iter 46000, loss: 0.008029
 >> iter 47000, loss: 0.008116
 >> iter 48000, loss: 0.008043
 >> iter 49000, loss: 0.008132
 >> iter 50000, loss: 0.008055
   Number of active neurons: 3
 >> iter 51000, loss: 0.008144
 >> iter 52000, loss: 0.008071
 >> iter 53000, loss: 0.008152
 >> iter 54000, loss: 0.008091
 >> iter 55000, loss: 0.008159
 >> iter 56000, loss: 0.008101
 >> iter 57000, loss: 0.008175
 >> iter 58000, loss: 0.008105
 >> iter 59000, loss: 0.008185
 >> iter 60000, loss: 0.008118
   Number of active neurons: 3
 >> iter 61000, loss: 0.008191
 >> iter 62000, loss: 0.008129
 >> iter 63000, loss: 0.008203
 >> iter 64000, loss: 0.008133
 >> iter 65000, loss: 0.008212
 >> iter 66000, loss: 0.008146
 >> iter 67000, loss: 0.008219
 >> iter 68000, loss: 0.008163
 >> iter 69000, loss: 0.008229
 >> iter 70000, loss: 0.008169
   Number of active neurons: 3
 >> iter 71000, loss: 0.008239
 >> iter 72000, loss: 0.008183
 >> iter 73000, loss: 0.008250
 >> iter 74000, loss: 0.008191
 >> iter 75000, loss: 0.008261
 >> iter 76000, loss: 0.008202
 >> iter 77000, loss: 0.008269
 >> iter 78000, loss: 0.008207
 >> iter 79000, loss: 0.008287
 >> iter 80000, loss: 0.008218
   Number of active neurons: 3
 >> iter 81000, loss: 0.008305
 >> iter 82000, loss: 0.008228
 >> iter 83000, loss: 0.008320
 >> iter 84000, loss: 0.008235
 >> iter 85000, loss: 0.008323
 >> iter 86000, loss: 0.008239
 >> iter 87000, loss: 0.008328
 >> iter 88000, loss: 0.008242
 >> iter 89000, loss: 0.008326
 >> iter 90000, loss: 0.008246
   Number of active neurons: 2
 >> iter 91000, loss: 0.008324
 >> iter 92000, loss: 0.008245
 >> iter 93000, loss: 0.008319
 >> iter 94000, loss: 0.008233
 >> iter 95000, loss: 0.008314
 >> iter 96000, loss: 0.008213
 >> iter 97000, loss: 0.008291
 >> iter 98000, loss: 0.008183
 >> iter 99000, loss: 0.008258
 >> iter 100000, loss: 0.008151
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.759461
 >> iter 2000, loss: 3.970846
 >> iter 3000, loss: 1.470534
 >> iter 4000, loss: 0.549266
 >> iter 5000, loss: 0.209875
 >> iter 6000, loss: 0.084307
 >> iter 7000, loss: 0.037945
 >> iter 8000, loss: 0.020477
 >> iter 9000, loss: 0.014064
 >> iter 10000, loss: 0.011415
   Number of active neurons: 5
 >> iter 11000, loss: 0.010528
 >> iter 12000, loss: 0.009960
 >> iter 13000, loss: 0.009864
 >> iter 14000, loss: 0.009602
 >> iter 15000, loss: 0.009636
 >> iter 16000, loss: 0.009437
 >> iter 17000, loss: 0.009493
 >> iter 18000, loss: 0.009319
 >> iter 19000, loss: 0.009389
 >> iter 20000, loss: 0.009244
   Number of active neurons: 4
 >> iter 21000, loss: 0.009316
 >> iter 22000, loss: 0.009161
 >> iter 23000, loss: 0.009219
 >> iter 24000, loss: 0.009045
 >> iter 25000, loss: 0.009103
 >> iter 26000, loss: 0.008941
 >> iter 27000, loss: 0.008993
 >> iter 28000, loss: 0.008830
 >> iter 29000, loss: 0.008863
 >> iter 30000, loss: 0.008696
   Number of active neurons: 3
 >> iter 31000, loss: 0.008725
 >> iter 32000, loss: 0.008555
 >> iter 33000, loss: 0.008580
 >> iter 34000, loss: 0.008416
 >> iter 35000, loss: 0.008452
 >> iter 36000, loss: 0.008291
 >> iter 37000, loss: 0.008332
 >> iter 38000, loss: 0.008175
 >> iter 39000, loss: 0.008225
 >> iter 40000, loss: 0.008081
   Number of active neurons: 3
 >> iter 41000, loss: 0.008144
 >> iter 42000, loss: 0.008019
 >> iter 43000, loss: 0.008086
 >> iter 44000, loss: 0.007982
 >> iter 45000, loss: 0.008060
 >> iter 46000, loss: 0.007961
 >> iter 47000, loss: 0.008043
 >> iter 48000, loss: 0.007956
 >> iter 49000, loss: 0.008043
 >> iter 50000, loss: 0.007948
   Number of active neurons: 3
 >> iter 51000, loss: 0.008030
 >> iter 52000, loss: 0.007943
 >> iter 53000, loss: 0.008024
 >> iter 54000, loss: 0.007956
 >> iter 55000, loss: 0.008025
 >> iter 56000, loss: 0.007956
 >> iter 57000, loss: 0.008025
 >> iter 58000, loss: 0.007946
 >> iter 59000, loss: 0.008027
 >> iter 60000, loss: 0.007955
   Number of active neurons: 3
 >> iter 61000, loss: 0.008031
 >> iter 62000, loss: 0.007964
 >> iter 63000, loss: 0.008040
 >> iter 64000, loss: 0.007968
 >> iter 65000, loss: 0.008050
 >> iter 66000, loss: 0.007981
 >> iter 67000, loss: 0.008056
 >> iter 68000, loss: 0.007999
 >> iter 69000, loss: 0.008059
 >> iter 70000, loss: 0.007991
   Number of active neurons: 3
 >> iter 71000, loss: 0.008064
 >> iter 72000, loss: 0.008006
 >> iter 73000, loss: 0.008077
 >> iter 74000, loss: 0.008016
 >> iter 75000, loss: 0.008089
 >> iter 76000, loss: 0.008027
 >> iter 77000, loss: 0.008097
 >> iter 78000, loss: 0.008031
 >> iter 79000, loss: 0.008115
 >> iter 80000, loss: 0.008042
   Number of active neurons: 3
 >> iter 81000, loss: 0.008133
 >> iter 82000, loss: 0.008052
 >> iter 83000, loss: 0.008148
 >> iter 84000, loss: 0.008059
 >> iter 85000, loss: 0.008154
 >> iter 86000, loss: 0.008066
 >> iter 87000, loss: 0.008163
 >> iter 88000, loss: 0.008073
 >> iter 89000, loss: 0.008168
 >> iter 90000, loss: 0.008086
   Number of active neurons: 3
 >> iter 91000, loss: 0.008176
 >> iter 92000, loss: 0.008097
 >> iter 93000, loss: 0.008186
 >> iter 94000, loss: 0.008102
 >> iter 95000, loss: 0.008203
 >> iter 96000, loss: 0.008108
 >> iter 97000, loss: 0.008211
 >> iter 98000, loss: 0.008112
 >> iter 99000, loss: 0.008218
 >> iter 100000, loss: 0.008127
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.709066
 >> iter 2000, loss: 3.952813
 >> iter 3000, loss: 1.464023
 >> iter 4000, loss: 0.546799
 >> iter 5000, loss: 0.208777
 >> iter 6000, loss: 0.083778
 >> iter 7000, loss: 0.037623
 >> iter 8000, loss: 0.020262
 >> iter 9000, loss: 0.013862
 >> iter 10000, loss: 0.011256
   Number of active neurons: 5
 >> iter 11000, loss: 0.010368
 >> iter 12000, loss: 0.009847
 >> iter 13000, loss: 0.009751
 >> iter 14000, loss: 0.009522
 >> iter 15000, loss: 0.009559
 >> iter 16000, loss: 0.009402
 >> iter 17000, loss: 0.009477
 >> iter 18000, loss: 0.009348
 >> iter 19000, loss: 0.009422
 >> iter 20000, loss: 0.009308
   Number of active neurons: 3
 >> iter 21000, loss: 0.009379
 >> iter 22000, loss: 0.009252
 >> iter 23000, loss: 0.009312
 >> iter 24000, loss: 0.009167
 >> iter 25000, loss: 0.009213
 >> iter 26000, loss: 0.009041
 >> iter 27000, loss: 0.009045
 >> iter 28000, loss: 0.008866
 >> iter 29000, loss: 0.008855
 >> iter 30000, loss: 0.008657
   Number of active neurons: 3
 >> iter 31000, loss: 0.008638
 >> iter 32000, loss: 0.008455
 >> iter 33000, loss: 0.008453
 >> iter 34000, loss: 0.008299
 >> iter 35000, loss: 0.008333
 >> iter 36000, loss: 0.008195
 >> iter 37000, loss: 0.008246
 >> iter 38000, loss: 0.008129
 >> iter 39000, loss: 0.008204
 >> iter 40000, loss: 0.008099
   Number of active neurons: 3
 >> iter 41000, loss: 0.008181
 >> iter 42000, loss: 0.008088
 >> iter 43000, loss: 0.008168
 >> iter 44000, loss: 0.008085
 >> iter 45000, loss: 0.008168
 >> iter 46000, loss: 0.008086
 >> iter 47000, loss: 0.008169
 >> iter 48000, loss: 0.008086
 >> iter 49000, loss: 0.008165
 >> iter 50000, loss: 0.008082
   Number of active neurons: 3
 >> iter 51000, loss: 0.008169
 >> iter 52000, loss: 0.008095
 >> iter 53000, loss: 0.008176
 >> iter 54000, loss: 0.008115
 >> iter 55000, loss: 0.008181
 >> iter 56000, loss: 0.008123
 >> iter 57000, loss: 0.008194
 >> iter 58000, loss: 0.008124
 >> iter 59000, loss: 0.008202
 >> iter 60000, loss: 0.008134
   Number of active neurons: 3
 >> iter 61000, loss: 0.008205
 >> iter 62000, loss: 0.008141
 >> iter 63000, loss: 0.008212
 >> iter 64000, loss: 0.008141
 >> iter 65000, loss: 0.008216
 >> iter 66000, loss: 0.008148
 >> iter 67000, loss: 0.008217
 >> iter 68000, loss: 0.008159
 >> iter 69000, loss: 0.008221
 >> iter 70000, loss: 0.008157
   Number of active neurons: 3
 >> iter 71000, loss: 0.008222
 >> iter 72000, loss: 0.008163
 >> iter 73000, loss: 0.008223
 >> iter 74000, loss: 0.008160
 >> iter 75000, loss: 0.008222
 >> iter 76000, loss: 0.008157
 >> iter 77000, loss: 0.008215
 >> iter 78000, loss: 0.008146
 >> iter 79000, loss: 0.008214
 >> iter 80000, loss: 0.008137
   Number of active neurons: 2
 >> iter 81000, loss: 0.008210
 >> iter 82000, loss: 0.008122
 >> iter 83000, loss: 0.008196
 >> iter 84000, loss: 0.008098
 >> iter 85000, loss: 0.008163
 >> iter 86000, loss: 0.008062
 >> iter 87000, loss: 0.008123
 >> iter 88000, loss: 0.008014
 >> iter 89000, loss: 0.008059
 >> iter 90000, loss: 0.007931
   Number of active neurons: 2
 >> iter 91000, loss: 0.007944
 >> iter 92000, loss: 0.007804
 >> iter 93000, loss: 0.007817
 >> iter 94000, loss: 0.007683
 >> iter 95000, loss: 0.007715
 >> iter 96000, loss: 0.007579
 >> iter 97000, loss: 0.007616
 >> iter 98000, loss: 0.007479
 >> iter 99000, loss: 0.007525
 >> iter 100000, loss: 0.007409
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.704061
 >> iter 2000, loss: 3.953339
 >> iter 3000, loss: 1.465723
 >> iter 4000, loss: 0.548740
 >> iter 5000, loss: 0.210679
 >> iter 6000, loss: 0.085620
 >> iter 7000, loss: 0.039346
 >> iter 8000, loss: 0.021902
 >> iter 9000, loss: 0.015385
 >> iter 10000, loss: 0.012661
   Number of active neurons: 3
 >> iter 11000, loss: 0.011606
 >> iter 12000, loss: 0.010915
 >> iter 13000, loss: 0.010640
 >> iter 14000, loss: 0.010236
 >> iter 15000, loss: 0.010083
 >> iter 16000, loss: 0.009750
 >> iter 17000, loss: 0.009624
 >> iter 18000, loss: 0.009331
 >> iter 19000, loss: 0.009235
 >> iter 20000, loss: 0.009002
   Number of active neurons: 3
 >> iter 21000, loss: 0.008953
 >> iter 22000, loss: 0.008769
 >> iter 23000, loss: 0.008770
 >> iter 24000, loss: 0.008627
 >> iter 25000, loss: 0.008666
 >> iter 26000, loss: 0.008554
 >> iter 27000, loss: 0.008609
 >> iter 28000, loss: 0.008514
 >> iter 29000, loss: 0.008576
 >> iter 30000, loss: 0.008490
   Number of active neurons: 3
 >> iter 31000, loss: 0.008560
 >> iter 32000, loss: 0.008479
 >> iter 33000, loss: 0.008553
 >> iter 34000, loss: 0.008477
 >> iter 35000, loss: 0.008559
 >> iter 36000, loss: 0.008479
 >> iter 37000, loss: 0.008564
 >> iter 38000, loss: 0.008482
 >> iter 39000, loss: 0.008573
 >> iter 40000, loss: 0.008490
   Number of active neurons: 3
 >> iter 41000, loss: 0.008579
 >> iter 42000, loss: 0.008501
 >> iter 43000, loss: 0.008585
 >> iter 44000, loss: 0.008515
 >> iter 45000, loss: 0.008595
 >> iter 46000, loss: 0.008524
 >> iter 47000, loss: 0.008603
 >> iter 48000, loss: 0.008537
 >> iter 49000, loss: 0.008616
 >> iter 50000, loss: 0.008544
   Number of active neurons: 3
 >> iter 51000, loss: 0.008623
 >> iter 52000, loss: 0.008556
 >> iter 53000, loss: 0.008627
 >> iter 54000, loss: 0.008571
 >> iter 55000, loss: 0.008626
 >> iter 56000, loss: 0.008570
 >> iter 57000, loss: 0.008629
 >> iter 58000, loss: 0.008560
 >> iter 59000, loss: 0.008621
 >> iter 60000, loss: 0.008551
   Number of active neurons: 2
 >> iter 61000, loss: 0.008599
 >> iter 62000, loss: 0.008527
 >> iter 63000, loss: 0.008569
 >> iter 64000, loss: 0.008482
 >> iter 65000, loss: 0.008518
 >> iter 66000, loss: 0.008413
 >> iter 67000, loss: 0.008400
 >> iter 68000, loss: 0.008273
 >> iter 69000, loss: 0.008250
 >> iter 70000, loss: 0.008124
   Number of active neurons: 1
 >> iter 71000, loss: 0.008112
 >> iter 72000, loss: 0.007996
 >> iter 73000, loss: 0.007979
 >> iter 74000, loss: 0.007860
 >> iter 75000, loss: 0.007847
 >> iter 76000, loss: 0.007740
 >> iter 77000, loss: 0.007735
 >> iter 78000, loss: 0.007633
 >> iter 79000, loss: 0.007641
 >> iter 80000, loss: 0.007535
   Number of active neurons: 1
 >> iter 81000, loss: 0.007545
 >> iter 82000, loss: 0.007420
 >> iter 83000, loss: 0.007402
 >> iter 84000, loss: 0.007239
 >> iter 85000, loss: 0.007203
 >> iter 86000, loss: 0.007046
 >> iter 87000, loss: 0.007021
 >> iter 88000, loss: 0.006874
 >> iter 89000, loss: 0.006853
 >> iter 90000, loss: 0.006713
   Number of active neurons: 1
 >> iter 91000, loss: 0.006693
 >> iter 92000, loss: 0.006570
 >> iter 93000, loss: 0.006565
 >> iter 94000, loss: 0.006454
 >> iter 95000, loss: 0.006470
 >> iter 96000, loss: 0.006362
 >> iter 97000, loss: 0.006389
 >> iter 98000, loss: 0.006288
 >> iter 99000, loss: 0.006324
 >> iter 100000, loss: 0.006234
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.779043
 >> iter 2000, loss: 3.977690
 >> iter 3000, loss: 1.473020
 >> iter 4000, loss: 0.550227
 >> iter 5000, loss: 0.210324
 >> iter 6000, loss: 0.084604
 >> iter 7000, loss: 0.038232
 >> iter 8000, loss: 0.020766
 >> iter 9000, loss: 0.014352
 >> iter 10000, loss: 0.011704
   Number of active neurons: 5
 >> iter 11000, loss: 0.010811
 >> iter 12000, loss: 0.010263
 >> iter 13000, loss: 0.010194
 >> iter 14000, loss: 0.009958
 >> iter 15000, loss: 0.010007
 >> iter 16000, loss: 0.009825
 >> iter 17000, loss: 0.009905
 >> iter 18000, loss: 0.009755
 >> iter 19000, loss: 0.009837
 >> iter 20000, loss: 0.009688
   Number of active neurons: 5
 >> iter 21000, loss: 0.009752
 >> iter 22000, loss: 0.009607
 >> iter 23000, loss: 0.009690
 >> iter 24000, loss: 0.009560
 >> iter 25000, loss: 0.009661
 >> iter 26000, loss: 0.009549
 >> iter 27000, loss: 0.009649
 >> iter 28000, loss: 0.009538
 >> iter 29000, loss: 0.009624
 >> iter 30000, loss: 0.009515
   Number of active neurons: 4
 >> iter 31000, loss: 0.009603
 >> iter 32000, loss: 0.009485
 >> iter 33000, loss: 0.009568
 >> iter 34000, loss: 0.009452
 >> iter 35000, loss: 0.009540
 >> iter 36000, loss: 0.009414
 >> iter 37000, loss: 0.009490
 >> iter 38000, loss: 0.009346
 >> iter 39000, loss: 0.009413
 >> iter 40000, loss: 0.009251
   Number of active neurons: 4
 >> iter 41000, loss: 0.009306
 >> iter 42000, loss: 0.009159
 >> iter 43000, loss: 0.009217
 >> iter 44000, loss: 0.009087
 >> iter 45000, loss: 0.009152
 >> iter 46000, loss: 0.009036
 >> iter 47000, loss: 0.009114
 >> iter 48000, loss: 0.009017
 >> iter 49000, loss: 0.009103
 >> iter 50000, loss: 0.009008
   Number of active neurons: 4
 >> iter 51000, loss: 0.009099
 >> iter 52000, loss: 0.009004
 >> iter 53000, loss: 0.009084
 >> iter 54000, loss: 0.009012
 >> iter 55000, loss: 0.009080
 >> iter 56000, loss: 0.009013
 >> iter 57000, loss: 0.009086
 >> iter 58000, loss: 0.009004
 >> iter 59000, loss: 0.009080
 >> iter 60000, loss: 0.008998
   Number of active neurons: 3
 >> iter 61000, loss: 0.009063
 >> iter 62000, loss: 0.008982
 >> iter 63000, loss: 0.009042
 >> iter 64000, loss: 0.008950
 >> iter 65000, loss: 0.009009
 >> iter 66000, loss: 0.008913
 >> iter 67000, loss: 0.008957
 >> iter 68000, loss: 0.008866
 >> iter 69000, loss: 0.008892
 >> iter 70000, loss: 0.008779
   Number of active neurons: 2
 >> iter 71000, loss: 0.008783
 >> iter 72000, loss: 0.008651
 >> iter 73000, loss: 0.008633
 >> iter 74000, loss: 0.008490
 >> iter 75000, loss: 0.008476
 >> iter 76000, loss: 0.008337
 >> iter 77000, loss: 0.008317
 >> iter 78000, loss: 0.008173
 >> iter 79000, loss: 0.008154
 >> iter 80000, loss: 0.007993
   Number of active neurons: 2
 >> iter 81000, loss: 0.007975
 >> iter 82000, loss: 0.007811
 >> iter 83000, loss: 0.007811
 >> iter 84000, loss: 0.007659
 >> iter 85000, loss: 0.007671
 >> iter 86000, loss: 0.007529
 >> iter 87000, loss: 0.007549
 >> iter 88000, loss: 0.007419
 >> iter 89000, loss: 0.007454
 >> iter 90000, loss: 0.007348
   Number of active neurons: 2
 >> iter 91000, loss: 0.007393
 >> iter 92000, loss: 0.007301
 >> iter 93000, loss: 0.007354
 >> iter 94000, loss: 0.007265
 >> iter 95000, loss: 0.007334
 >> iter 96000, loss: 0.007239
 >> iter 97000, loss: 0.007314
 >> iter 98000, loss: 0.007220
 >> iter 99000, loss: 0.007301
 >> iter 100000, loss: 0.007216
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 10.669271
 >> iter 2000, loss: 3.937865
 >> iter 3000, loss: 1.458544
 >> iter 4000, loss: 0.544965
 >> iter 5000, loss: 0.208348
 >> iter 6000, loss: 0.083806
 >> iter 7000, loss: 0.037792
 >> iter 8000, loss: 0.020441
 >> iter 9000, loss: 0.014032
 >> iter 10000, loss: 0.011365
   Number of active neurons: 4
 >> iter 11000, loss: 0.010431
 >> iter 12000, loss: 0.009827
 >> iter 13000, loss: 0.009692
 >> iter 14000, loss: 0.009398
 >> iter 15000, loss: 0.009373
 >> iter 16000, loss: 0.009118
 >> iter 17000, loss: 0.009111
 >> iter 18000, loss: 0.008884
 >> iter 19000, loss: 0.008895
 >> iter 20000, loss: 0.008708
   Number of active neurons: 3
 >> iter 21000, loss: 0.008738
 >> iter 22000, loss: 0.008571
 >> iter 23000, loss: 0.008622
 >> iter 24000, loss: 0.008455
 >> iter 25000, loss: 0.008507
 >> iter 26000, loss: 0.008353
 >> iter 27000, loss: 0.008405
 >> iter 28000, loss: 0.008260
 >> iter 29000, loss: 0.008304
 >> iter 30000, loss: 0.008156
   Number of active neurons: 3
 >> iter 31000, loss: 0.008200
 >> iter 32000, loss: 0.008060
 >> iter 33000, loss: 0.008110
 >> iter 34000, loss: 0.007984
 >> iter 35000, loss: 0.008053
 >> iter 36000, loss: 0.007939
 >> iter 37000, loss: 0.008019
 >> iter 38000, loss: 0.007915
 >> iter 39000, loss: 0.008005
 >> iter 40000, loss: 0.007907
   Number of active neurons: 3
 >> iter 41000, loss: 0.007994
 >> iter 42000, loss: 0.007894
 >> iter 43000, loss: 0.007961
 >> iter 44000, loss: 0.007867
 >> iter 45000, loss: 0.007953
 >> iter 46000, loss: 0.007868
 >> iter 47000, loss: 0.007961
 >> iter 48000, loss: 0.007884
 >> iter 49000, loss: 0.007978
 >> iter 50000, loss: 0.007897
   Number of active neurons: 3
 >> iter 51000, loss: 0.007992
 >> iter 52000, loss: 0.007916
 >> iter 53000, loss: 0.007990
 >> iter 54000, loss: 0.007922
 >> iter 55000, loss: 0.007996
 >> iter 56000, loss: 0.007942
 >> iter 57000, loss: 0.008023
 >> iter 58000, loss: 0.007956
 >> iter 59000, loss: 0.008041
 >> iter 60000, loss: 0.007975
   Number of active neurons: 3
 >> iter 61000, loss: 0.008051
 >> iter 62000, loss: 0.007988
 >> iter 63000, loss: 0.008063
 >> iter 64000, loss: 0.007992
 >> iter 65000, loss: 0.008073
 >> iter 66000, loss: 0.008003
 >> iter 67000, loss: 0.008077
 >> iter 68000, loss: 0.008019
 >> iter 69000, loss: 0.008086
 >> iter 70000, loss: 0.008022
   Number of active neurons: 3
 >> iter 71000, loss: 0.008094
 >> iter 72000, loss: 0.008035
 >> iter 73000, loss: 0.008104
 >> iter 74000, loss: 0.008041
 >> iter 75000, loss: 0.008113
 >> iter 76000, loss: 0.008050
 >> iter 77000, loss: 0.008120
 >> iter 78000, loss: 0.008055
 >> iter 79000, loss: 0.008138
 >> iter 80000, loss: 0.008066
   Number of active neurons: 3
 >> iter 81000, loss: 0.008158
 >> iter 82000, loss: 0.008078
 >> iter 83000, loss: 0.008176
 >> iter 84000, loss: 0.008088
 >> iter 85000, loss: 0.008184
 >> iter 86000, loss: 0.008098
 >> iter 87000, loss: 0.008196
 >> iter 88000, loss: 0.008109
 >> iter 89000, loss: 0.008206
 >> iter 90000, loss: 0.008126
   Number of active neurons: 3
 >> iter 91000, loss: 0.008219
 >> iter 92000, loss: 0.008143
 >> iter 93000, loss: 0.008236
 >> iter 94000, loss: 0.008155
 >> iter 95000, loss: 0.008259
 >> iter 96000, loss: 0.008168
 >> iter 97000, loss: 0.008276
 >> iter 98000, loss: 0.008181
 >> iter 99000, loss: 0.008293
 >> iter 100000, loss: 0.008207
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

