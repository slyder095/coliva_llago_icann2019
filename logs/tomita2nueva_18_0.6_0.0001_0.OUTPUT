 > Problema: tomita2nueva
 > Args:
   - Hidden size: 18
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.302820
 >> iter 2000, loss: 4.501319
 >> iter 3000, loss: 1.804049
 >> iter 4000, loss: 0.762706
 >> iter 5000, loss: 0.393085
 >> iter 6000, loss: 0.238972
 >> iter 7000, loss: 0.174814
 >> iter 8000, loss: 0.113707
 >> iter 9000, loss: 0.118233
 >> iter 10000, loss: 0.101231
   Number of active neurons: 10
 >> iter 11000, loss: 0.106578
 >> iter 12000, loss: 0.085404
 >> iter 13000, loss: 0.065795
 >> iter 14000, loss: 0.086695
 >> iter 15000, loss: 0.113163
 >> iter 16000, loss: 0.086689
 >> iter 17000, loss: 0.119949
 >> iter 18000, loss: 0.077230
 >> iter 19000, loss: 0.071114
 >> iter 20000, loss: 0.063223
   Number of active neurons: 9
 >> iter 21000, loss: 0.061555
 >> iter 22000, loss: 0.054500
 >> iter 23000, loss: 0.075079
 >> iter 24000, loss: 0.075450
 >> iter 25000, loss: 0.092501
 >> iter 26000, loss: 0.067618
 >> iter 27000, loss: 0.066769
 >> iter 28000, loss: 0.063354
 >> iter 29000, loss: 0.064010
 >> iter 30000, loss: 0.057971
   Number of active neurons: 7
 >> iter 31000, loss: 0.052288
 >> iter 32000, loss: 0.047928
 >> iter 33000, loss: 0.064573
 >> iter 34000, loss: 0.052293
 >> iter 35000, loss: 0.050418
 >> iter 36000, loss: 0.053606
 >> iter 37000, loss: 0.057076
 >> iter 38000, loss: 0.043858
 >> iter 39000, loss: 0.045236
 >> iter 40000, loss: 0.050497
   Number of active neurons: 6
 >> iter 41000, loss: 0.042214
 >> iter 42000, loss: 0.060918
 >> iter 43000, loss: 0.044438
 >> iter 44000, loss: 0.042875
 >> iter 45000, loss: 0.073199
 >> iter 46000, loss: 0.059121
 >> iter 47000, loss: 0.051693
 >> iter 48000, loss: 0.054351
 >> iter 49000, loss: 0.048638
 >> iter 50000, loss: 0.046410
   Number of active neurons: 4
 >> iter 51000, loss: 0.088677
 >> iter 52000, loss: 0.065840
 >> iter 53000, loss: 0.051645
 >> iter 54000, loss: 0.060049
 >> iter 55000, loss: 0.045305
 >> iter 56000, loss: 0.072477
 >> iter 57000, loss: 0.052179
 >> iter 58000, loss: 0.055877
 >> iter 59000, loss: 0.044335
 >> iter 60000, loss: 0.044408
   Number of active neurons: 3
 >> iter 61000, loss: 0.053228
 >> iter 62000, loss: 0.041011
 >> iter 63000, loss: 0.048228
 >> iter 64000, loss: 0.038412
 >> iter 65000, loss: 0.040010
 >> iter 66000, loss: 0.032709
 >> iter 67000, loss: 0.050698
 >> iter 68000, loss: 0.048311
 >> iter 69000, loss: 0.090680
 >> iter 70000, loss: 0.071088
   Number of active neurons: 3
 >> iter 71000, loss: 0.071641
 >> iter 72000, loss: 0.066413
 >> iter 73000, loss: 0.047177
 >> iter 74000, loss: 0.051026
 >> iter 75000, loss: 0.069057
 >> iter 76000, loss: 0.045404
 >> iter 77000, loss: 0.043140
 >> iter 78000, loss: 0.058500
 >> iter 79000, loss: 0.044085
 >> iter 80000, loss: 0.033148
   Number of active neurons: 3
 >> iter 81000, loss: 0.050109
 >> iter 82000, loss: 0.045929
 >> iter 83000, loss: 0.038679
 >> iter 84000, loss: 0.047346
 >> iter 85000, loss: 0.048943
 >> iter 86000, loss: 0.049901
 >> iter 87000, loss: 0.067188
 >> iter 88000, loss: 0.051059
 >> iter 89000, loss: 0.065787
 >> iter 90000, loss: 0.077463
   Number of active neurons: 2
 >> iter 91000, loss: 0.058661
 >> iter 92000, loss: 0.040613
 >> iter 93000, loss: 0.034458
 >> iter 94000, loss: 0.040954
 >> iter 95000, loss: 0.047253
 >> iter 96000, loss: 0.049546
 >> iter 97000, loss: 0.045836
 >> iter 98000, loss: 0.030723
 >> iter 99000, loss: 0.037411
 >> iter 100000, loss: 0.035748
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455190
   Number of active neurons: 0
 >> iter 1000, loss: 11.364485
 >> iter 2000, loss: 4.481061
 >> iter 3000, loss: 1.810602
 >> iter 4000, loss: 0.756042
 >> iter 5000, loss: 0.360908
 >> iter 6000, loss: 0.211192
 >> iter 7000, loss: 0.134046
 >> iter 8000, loss: 0.125690
 >> iter 9000, loss: 0.096570
 >> iter 10000, loss: 0.083244
   Number of active neurons: 9
 >> iter 11000, loss: 0.071029
 >> iter 12000, loss: 0.077117
 >> iter 13000, loss: 0.060573
 >> iter 14000, loss: 0.068080
 >> iter 15000, loss: 0.054516
 >> iter 16000, loss: 0.052211
 >> iter 17000, loss: 0.074264
 >> iter 18000, loss: 0.059264
 >> iter 19000, loss: 0.064757
 >> iter 20000, loss: 0.063276
   Number of active neurons: 9
 >> iter 21000, loss: 0.066122
 >> iter 22000, loss: 0.048228
 >> iter 23000, loss: 0.040085
 >> iter 24000, loss: 0.077806
 >> iter 25000, loss: 0.062145
 >> iter 26000, loss: 0.056307
 >> iter 27000, loss: 0.040618
 >> iter 28000, loss: 0.038878
 >> iter 29000, loss: 0.043833
 >> iter 30000, loss: 0.051446
   Number of active neurons: 6
 >> iter 31000, loss: 0.055407
 >> iter 32000, loss: 0.049271
 >> iter 33000, loss: 0.041601
 >> iter 34000, loss: 0.052526
 >> iter 35000, loss: 0.065844
 >> iter 36000, loss: 0.040743
 >> iter 37000, loss: 0.092967
 >> iter 38000, loss: 0.055756
 >> iter 39000, loss: 0.056204
 >> iter 40000, loss: 0.045898
   Number of active neurons: 5
 >> iter 41000, loss: 0.045408
 >> iter 42000, loss: 0.060408
 >> iter 43000, loss: 0.047335
 >> iter 44000, loss: 0.047611
 >> iter 45000, loss: 0.051907
 >> iter 46000, loss: 0.052349
 >> iter 47000, loss: 0.048235
 >> iter 48000, loss: 0.059352
 >> iter 49000, loss: 0.049465
 >> iter 50000, loss: 0.043988
   Number of active neurons: 3
 >> iter 51000, loss: 0.034866
 >> iter 52000, loss: 0.034664
 >> iter 53000, loss: 0.043187
 >> iter 54000, loss: 0.044058
 >> iter 55000, loss: 0.049486
 >> iter 56000, loss: 0.047467
 >> iter 57000, loss: 0.058175
 >> iter 58000, loss: 0.051638
 >> iter 59000, loss: 0.056653
 >> iter 60000, loss: 0.057077
   Number of active neurons: 3
 >> iter 61000, loss: 0.064491
 >> iter 62000, loss: 0.042968
 >> iter 63000, loss: 0.036515
 >> iter 64000, loss: 0.036421
 >> iter 65000, loss: 0.050889
 >> iter 66000, loss: 0.056645
 >> iter 67000, loss: 0.056002
 >> iter 68000, loss: 0.048877
 >> iter 69000, loss: 0.053800
 >> iter 70000, loss: 0.046883
   Number of active neurons: 3
 >> iter 71000, loss: 0.035147
 >> iter 72000, loss: 0.045227
 >> iter 73000, loss: 0.048103
 >> iter 74000, loss: 0.050076
 >> iter 75000, loss: 0.038614
 >> iter 76000, loss: 0.048888
 >> iter 77000, loss: 0.047276
 >> iter 78000, loss: 0.055297
 >> iter 79000, loss: 0.040914
 >> iter 80000, loss: 0.033282
   Number of active neurons: 3
 >> iter 81000, loss: 0.042256
 >> iter 82000, loss: 0.041802
 >> iter 83000, loss: 0.058974
 >> iter 84000, loss: 0.050366
 >> iter 85000, loss: 0.043812
 >> iter 86000, loss: 0.045893
 >> iter 87000, loss: 0.034715
 >> iter 88000, loss: 0.038361
 >> iter 89000, loss: 0.046103
 >> iter 90000, loss: 0.052153
   Number of active neurons: 3
 >> iter 91000, loss: 0.040130
 >> iter 92000, loss: 0.037403
 >> iter 93000, loss: 0.035699
 >> iter 94000, loss: 0.056068
 >> iter 95000, loss: 0.070188
 >> iter 96000, loss: 0.054726
 >> iter 97000, loss: 0.038661
 >> iter 98000, loss: 0.048913
 >> iter 99000, loss: 0.047341
 >> iter 100000, loss: 0.043157
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.351904
 >> iter 2000, loss: 4.438799
 >> iter 3000, loss: 1.825544
 >> iter 4000, loss: 0.745444
 >> iter 5000, loss: 0.370282
 >> iter 6000, loss: 0.244897
 >> iter 7000, loss: 0.140186
 >> iter 8000, loss: 0.113332
 >> iter 9000, loss: 0.085017
 >> iter 10000, loss: 0.080329
   Number of active neurons: 10
 >> iter 11000, loss: 0.087050
 >> iter 12000, loss: 0.077129
 >> iter 13000, loss: 0.067877
 >> iter 14000, loss: 0.065083
 >> iter 15000, loss: 0.056429
 >> iter 16000, loss: 0.079667
 >> iter 17000, loss: 0.082586
 >> iter 18000, loss: 0.071758
 >> iter 19000, loss: 0.082798
 >> iter 20000, loss: 0.056594
   Number of active neurons: 7
 >> iter 21000, loss: 0.059397
 >> iter 22000, loss: 0.078305
 >> iter 23000, loss: 0.056938
 >> iter 24000, loss: 0.061795
 >> iter 25000, loss: 0.063333
 >> iter 26000, loss: 0.052357
 >> iter 27000, loss: 0.062229
 >> iter 28000, loss: 0.066309
 >> iter 29000, loss: 0.062664
 >> iter 30000, loss: 0.052117
   Number of active neurons: 7
 >> iter 31000, loss: 0.061128
 >> iter 32000, loss: 0.046972
 >> iter 33000, loss: 0.048595
 >> iter 34000, loss: 0.057350
 >> iter 35000, loss: 0.045324
 >> iter 36000, loss: 0.057044
 >> iter 37000, loss: 0.052295
 >> iter 38000, loss: 0.054925
 >> iter 39000, loss: 0.050763
 >> iter 40000, loss: 0.055135
   Number of active neurons: 7
 >> iter 41000, loss: 0.057264
 >> iter 42000, loss: 0.075167
 >> iter 43000, loss: 0.063286
 >> iter 44000, loss: 0.046085
 >> iter 45000, loss: 0.040505
 >> iter 46000, loss: 0.060559
 >> iter 47000, loss: 0.086648
 >> iter 48000, loss: 0.060793
 >> iter 49000, loss: 0.048037
 >> iter 50000, loss: 0.095771
   Number of active neurons: 6
 >> iter 51000, loss: 0.086736
 >> iter 52000, loss: 0.065674
 >> iter 53000, loss: 0.052596
 >> iter 54000, loss: 0.042058
 >> iter 55000, loss: 0.043011
 >> iter 56000, loss: 0.060553
 >> iter 57000, loss: 0.054110
 >> iter 58000, loss: 0.048111
 >> iter 59000, loss: 0.046276
 >> iter 60000, loss: 0.059399
   Number of active neurons: 6
 >> iter 61000, loss: 0.057494
 >> iter 62000, loss: 0.042769
 >> iter 63000, loss: 0.074293
 >> iter 64000, loss: 0.070517
 >> iter 65000, loss: 0.065881
 >> iter 66000, loss: 0.055159
 >> iter 67000, loss: 0.050512
 >> iter 68000, loss: 0.051142
 >> iter 69000, loss: 0.043745
 >> iter 70000, loss: 0.054233
   Number of active neurons: 5
 >> iter 71000, loss: 0.047256
 >> iter 72000, loss: 0.041149
 >> iter 73000, loss: 0.044025
 >> iter 74000, loss: 0.044669
 >> iter 75000, loss: 0.039982
 >> iter 76000, loss: 0.065477
 >> iter 77000, loss: 0.059467
 >> iter 78000, loss: 0.079713
 >> iter 79000, loss: 0.058389
 >> iter 80000, loss: 0.062469
   Number of active neurons: 5
 >> iter 81000, loss: 0.082980
 >> iter 82000, loss: 0.058835
 >> iter 83000, loss: 0.042419
 >> iter 84000, loss: 0.056252
 >> iter 85000, loss: 0.048187
 >> iter 86000, loss: 0.045478
 >> iter 87000, loss: 0.039520
 >> iter 88000, loss: 0.039699
 >> iter 89000, loss: 0.035498
 >> iter 90000, loss: 0.046318
   Number of active neurons: 4
 >> iter 91000, loss: 0.036847
 >> iter 92000, loss: 0.040893
 >> iter 93000, loss: 0.045587
 >> iter 94000, loss: 0.048784
 >> iter 95000, loss: 0.040665
 >> iter 96000, loss: 0.056772
 >> iter 97000, loss: 0.045752
 >> iter 98000, loss: 0.060985
 >> iter 99000, loss: 0.052374
 >> iter 100000, loss: 0.043849
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 11.279655
 >> iter 2000, loss: 4.489201
 >> iter 3000, loss: 1.805482
 >> iter 4000, loss: 0.762163
 >> iter 5000, loss: 0.367915
 >> iter 6000, loss: 0.227768
 >> iter 7000, loss: 0.147133
 >> iter 8000, loss: 0.133181
 >> iter 9000, loss: 0.120961
 >> iter 10000, loss: 0.095822
   Number of active neurons: 9
 >> iter 11000, loss: 0.109880
 >> iter 12000, loss: 0.101106
 >> iter 13000, loss: 0.083322
 >> iter 14000, loss: 0.062243
 >> iter 15000, loss: 0.058011
 >> iter 16000, loss: 0.052038
 >> iter 17000, loss: 0.051294
 >> iter 18000, loss: 0.060006
 >> iter 19000, loss: 0.056529
 >> iter 20000, loss: 0.068628
   Number of active neurons: 8
 >> iter 21000, loss: 0.068639
 >> iter 22000, loss: 0.070796
 >> iter 23000, loss: 0.063308
 >> iter 24000, loss: 0.056758
 >> iter 25000, loss: 0.059185
 >> iter 26000, loss: 0.053023
 >> iter 27000, loss: 0.072606
 >> iter 28000, loss: 0.064269
 >> iter 29000, loss: 0.052022
 >> iter 30000, loss: 0.052335
   Number of active neurons: 8
 >> iter 31000, loss: 0.048855
 >> iter 32000, loss: 0.053949
 >> iter 33000, loss: 0.060969
 >> iter 34000, loss: 0.054482
 >> iter 35000, loss: 0.052733
 >> iter 36000, loss: 0.047739
 >> iter 37000, loss: 0.045578
 >> iter 38000, loss: 0.041970
 >> iter 39000, loss: 0.049956
 >> iter 40000, loss: 0.043659
   Number of active neurons: 8
 >> iter 41000, loss: 0.064381
 >> iter 42000, loss: 0.056261
 >> iter 43000, loss: 0.048694
 >> iter 44000, loss: 0.065298
 >> iter 45000, loss: 0.046519
 >> iter 46000, loss: 0.041558
 >> iter 47000, loss: 0.046928
 >> iter 48000, loss: 0.066125
 >> iter 49000, loss: 0.066550
 >> iter 50000, loss: 0.043247
   Number of active neurons: 4
 >> iter 51000, loss: 0.049310
 >> iter 52000, loss: 0.040443
 >> iter 53000, loss: 0.045175
 >> iter 54000, loss: 0.035114
 >> iter 55000, loss: 0.050339
 >> iter 56000, loss: 0.042728
 >> iter 57000, loss: 0.052270
 >> iter 58000, loss: 0.067515
 >> iter 59000, loss: 0.063385
 >> iter 60000, loss: 0.048447
   Number of active neurons: 2
 >> iter 61000, loss: 0.042192
 >> iter 62000, loss: 0.032633
 >> iter 63000, loss: 0.034048
 >> iter 64000, loss: 0.032321
 >> iter 65000, loss: 0.037651
 >> iter 66000, loss: 0.030479
 >> iter 67000, loss: 0.036976
 >> iter 68000, loss: 0.046599
 >> iter 69000, loss: 0.057246
 >> iter 70000, loss: 0.040006
   Number of active neurons: 2
 >> iter 71000, loss: 0.048606
 >> iter 72000, loss: 0.042546
 >> iter 73000, loss: 0.036100
 >> iter 74000, loss: 0.050452
 >> iter 75000, loss: 0.064274
 >> iter 76000, loss: 0.053311
 >> iter 77000, loss: 0.061950
 >> iter 78000, loss: 0.050159
 >> iter 79000, loss: 0.039229
 >> iter 80000, loss: 0.031648
   Number of active neurons: 2
 >> iter 81000, loss: 0.036302
 >> iter 82000, loss: 0.036103
 >> iter 83000, loss: 0.028427
 >> iter 84000, loss: 0.048396
 >> iter 85000, loss: 0.045503
 >> iter 86000, loss: 0.034024
 >> iter 87000, loss: 0.044700
 >> iter 88000, loss: 0.038288
 >> iter 89000, loss: 0.035858
 >> iter 90000, loss: 0.046951
   Number of active neurons: 2
 >> iter 91000, loss: 0.043588
 >> iter 92000, loss: 0.034491
 >> iter 93000, loss: 0.041298
 >> iter 94000, loss: 0.031695
 >> iter 95000, loss: 0.047789
 >> iter 96000, loss: 0.043463
 >> iter 97000, loss: 0.040119
 >> iter 98000, loss: 0.061704
 >> iter 99000, loss: 0.045022
 >> iter 100000, loss: 0.041900
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 11.284138
 >> iter 2000, loss: 4.439075
 >> iter 3000, loss: 1.763673
 >> iter 4000, loss: 0.771591
 >> iter 5000, loss: 0.349847
 >> iter 6000, loss: 0.200338
 >> iter 7000, loss: 0.131157
 >> iter 8000, loss: 0.116433
 >> iter 9000, loss: 0.100341
 >> iter 10000, loss: 0.083353
   Number of active neurons: 9
 >> iter 11000, loss: 0.086278
 >> iter 12000, loss: 0.077687
 >> iter 13000, loss: 0.059382
 >> iter 14000, loss: 0.061703
 >> iter 15000, loss: 0.061263
 >> iter 16000, loss: 0.073362
 >> iter 17000, loss: 0.063881
 >> iter 18000, loss: 0.056210
 >> iter 19000, loss: 0.050549
 >> iter 20000, loss: 0.053174
   Number of active neurons: 7
 >> iter 21000, loss: 0.069227
 >> iter 22000, loss: 0.052562
 >> iter 23000, loss: 0.048286
 >> iter 24000, loss: 0.046595
 >> iter 25000, loss: 0.042418
 >> iter 26000, loss: 0.056712
 >> iter 27000, loss: 0.061274
 >> iter 28000, loss: 0.070834
 >> iter 29000, loss: 0.053197
 >> iter 30000, loss: 0.053756
   Number of active neurons: 6
 >> iter 31000, loss: 0.058344
 >> iter 32000, loss: 0.064972
 >> iter 33000, loss: 0.050908
 >> iter 34000, loss: 0.042207
 >> iter 35000, loss: 0.056827
 >> iter 36000, loss: 0.054843
 >> iter 37000, loss: 0.069682
 >> iter 38000, loss: 0.069496
 >> iter 39000, loss: 0.051472
 >> iter 40000, loss: 0.056510
   Number of active neurons: 5
 >> iter 41000, loss: 0.046521
 >> iter 42000, loss: 0.053709
 >> iter 43000, loss: 0.051424
 >> iter 44000, loss: 0.045228
 >> iter 45000, loss: 0.052662
 >> iter 46000, loss: 0.045240
 >> iter 47000, loss: 0.042646
 >> iter 48000, loss: 0.044929
 >> iter 49000, loss: 0.059967
 >> iter 50000, loss: 0.045449
   Number of active neurons: 3
 >> iter 51000, loss: 0.044162
 >> iter 52000, loss: 0.036231
 >> iter 53000, loss: 0.042266
 >> iter 54000, loss: 0.043530
 >> iter 55000, loss: 0.047047
 >> iter 56000, loss: 0.031477
 >> iter 57000, loss: 0.046761
 >> iter 58000, loss: 0.048686
 >> iter 59000, loss: 0.055465
 >> iter 60000, loss: 0.040506
   Number of active neurons: 3
 >> iter 61000, loss: 0.043955
 >> iter 62000, loss: 0.048370
 >> iter 63000, loss: 0.037501
 >> iter 64000, loss: 0.036406
 >> iter 65000, loss: 0.040373
 >> iter 66000, loss: 0.053900
 >> iter 67000, loss: 0.057150
 >> iter 68000, loss: 0.041045
 >> iter 69000, loss: 0.046677
 >> iter 70000, loss: 0.036267
   Number of active neurons: 3
 >> iter 71000, loss: 0.043184
 >> iter 72000, loss: 0.043904
 >> iter 73000, loss: 0.048806
 >> iter 74000, loss: 0.045694
 >> iter 75000, loss: 0.059230
 >> iter 76000, loss: 0.066386
 >> iter 77000, loss: 0.055575
 >> iter 78000, loss: 0.080974
 >> iter 79000, loss: 0.070521
 >> iter 80000, loss: 0.057758
   Number of active neurons: 3
 >> iter 81000, loss: 0.046139
 >> iter 82000, loss: 0.050805
 >> iter 83000, loss: 0.047930
 >> iter 84000, loss: 0.037967
 >> iter 85000, loss: 0.040805
 >> iter 86000, loss: 0.052425
 >> iter 87000, loss: 0.037966
 >> iter 88000, loss: 0.042470
 >> iter 89000, loss: 0.049801
 >> iter 90000, loss: 0.046225
   Number of active neurons: 3
 >> iter 91000, loss: 0.046340
 >> iter 92000, loss: 0.045028
 >> iter 93000, loss: 0.038139
 >> iter 94000, loss: 0.035411
 >> iter 95000, loss: 0.036452
 >> iter 96000, loss: 0.034590
 >> iter 97000, loss: 0.039026
 >> iter 98000, loss: 0.062897
 >> iter 99000, loss: 0.044356
 >> iter 100000, loss: 0.060202
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.355268
 >> iter 2000, loss: 4.485651
 >> iter 3000, loss: 1.812376
 >> iter 4000, loss: 0.755472
 >> iter 5000, loss: 0.358362
 >> iter 6000, loss: 0.206635
 >> iter 7000, loss: 0.137331
 >> iter 8000, loss: 0.116841
 >> iter 9000, loss: 0.117444
 >> iter 10000, loss: 0.103530
   Number of active neurons: 10
 >> iter 11000, loss: 0.093483
 >> iter 12000, loss: 0.087270
 >> iter 13000, loss: 0.073500
 >> iter 14000, loss: 0.074206
 >> iter 15000, loss: 0.104055
 >> iter 16000, loss: 0.076365
 >> iter 17000, loss: 0.060581
 >> iter 18000, loss: 0.058316
 >> iter 19000, loss: 0.052327
 >> iter 20000, loss: 0.088165
   Number of active neurons: 9
 >> iter 21000, loss: 0.067170
 >> iter 22000, loss: 0.072004
 >> iter 23000, loss: 0.058158
 >> iter 24000, loss: 0.061938
 >> iter 25000, loss: 0.050044
 >> iter 26000, loss: 0.062852
 >> iter 27000, loss: 0.069598
 >> iter 28000, loss: 0.070122
 >> iter 29000, loss: 0.063951
 >> iter 30000, loss: 0.055844
   Number of active neurons: 7
 >> iter 31000, loss: 0.049283
 >> iter 32000, loss: 0.043646
 >> iter 33000, loss: 0.039697
 >> iter 34000, loss: 0.049519
 >> iter 35000, loss: 0.045076
 >> iter 36000, loss: 0.054973
 >> iter 37000, loss: 0.055225
 >> iter 38000, loss: 0.086424
 >> iter 39000, loss: 0.098466
 >> iter 40000, loss: 0.072893
   Number of active neurons: 6
 >> iter 41000, loss: 0.058520
 >> iter 42000, loss: 0.040343
 >> iter 43000, loss: 0.045794
 >> iter 44000, loss: 0.058937
 >> iter 45000, loss: 0.072585
 >> iter 46000, loss: 0.062033
 >> iter 47000, loss: 0.046502
 >> iter 48000, loss: 0.034859
 >> iter 49000, loss: 0.039802
 >> iter 50000, loss: 0.039965
   Number of active neurons: 5
 >> iter 51000, loss: 0.044757
 >> iter 52000, loss: 0.050396
 >> iter 53000, loss: 0.047886
 >> iter 54000, loss: 0.049465
 >> iter 55000, loss: 0.048551
 >> iter 56000, loss: 0.058107
 >> iter 57000, loss: 0.049016
 >> iter 58000, loss: 0.066051
 >> iter 59000, loss: 0.053898
 >> iter 60000, loss: 0.052397
   Number of active neurons: 5
 >> iter 61000, loss: 0.047420
 >> iter 62000, loss: 0.045975
 >> iter 63000, loss: 0.051673
 >> iter 64000, loss: 0.064063
 >> iter 65000, loss: 0.061087
 >> iter 66000, loss: 0.066351
 >> iter 67000, loss: 0.055891
 >> iter 68000, loss: 0.059673
 >> iter 69000, loss: 0.070977
 >> iter 70000, loss: 0.051134
   Number of active neurons: 5
 >> iter 71000, loss: 0.052996
 >> iter 72000, loss: 0.046371
 >> iter 73000, loss: 0.038656
 >> iter 74000, loss: 0.051365
 >> iter 75000, loss: 0.045846
 >> iter 76000, loss: 0.046912
 >> iter 77000, loss: 0.047575
 >> iter 78000, loss: 0.045429
 >> iter 79000, loss: 0.040007
 >> iter 80000, loss: 0.053508
   Number of active neurons: 4
 >> iter 81000, loss: 0.051582
 >> iter 82000, loss: 0.037053
 >> iter 83000, loss: 0.037508
 >> iter 84000, loss: 0.054905
 >> iter 85000, loss: 0.082279
 >> iter 86000, loss: 0.065256
 >> iter 87000, loss: 0.055012
 >> iter 88000, loss: 0.049411
 >> iter 89000, loss: 0.044309
 >> iter 90000, loss: 0.040265
   Number of active neurons: 3
 >> iter 91000, loss: 0.046674
 >> iter 92000, loss: 0.049269
 >> iter 93000, loss: 0.048527
 >> iter 94000, loss: 0.048226
 >> iter 95000, loss: 0.039319
 >> iter 96000, loss: 0.035527
 >> iter 97000, loss: 0.048148
 >> iter 98000, loss: 0.036797
 >> iter 99000, loss: 0.042955
 >> iter 100000, loss: 0.034921
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.344713
 >> iter 2000, loss: 4.495032
 >> iter 3000, loss: 1.833329
 >> iter 4000, loss: 0.802127
 >> iter 5000, loss: 0.393799
 >> iter 6000, loss: 0.227336
 >> iter 7000, loss: 0.172848
 >> iter 8000, loss: 0.161293
 >> iter 9000, loss: 0.123094
 >> iter 10000, loss: 0.091629
   Number of active neurons: 11
 >> iter 11000, loss: 0.086153
 >> iter 12000, loss: 0.115313
 >> iter 13000, loss: 0.085370
 >> iter 14000, loss: 0.110797
 >> iter 15000, loss: 0.094675
 >> iter 16000, loss: 0.086941
 >> iter 17000, loss: 0.095883
 >> iter 18000, loss: 0.076983
 >> iter 19000, loss: 0.063374
 >> iter 20000, loss: 0.057289
   Number of active neurons: 9
 >> iter 21000, loss: 0.062355
 >> iter 22000, loss: 0.056490
 >> iter 23000, loss: 0.059441
 >> iter 24000, loss: 0.043853
 >> iter 25000, loss: 0.046019
 >> iter 26000, loss: 0.042503
 >> iter 27000, loss: 0.051345
 >> iter 28000, loss: 0.051424
 >> iter 29000, loss: 0.074280
 >> iter 30000, loss: 0.060226
   Number of active neurons: 7
 >> iter 31000, loss: 0.071293
 >> iter 32000, loss: 0.051112
 >> iter 33000, loss: 0.063891
 >> iter 34000, loss: 0.046364
 >> iter 35000, loss: 0.053375
 >> iter 36000, loss: 0.060448
 >> iter 37000, loss: 0.048408
 >> iter 38000, loss: 0.048138
 >> iter 39000, loss: 0.067049
 >> iter 40000, loss: 0.046007
   Number of active neurons: 5
 >> iter 41000, loss: 0.045314
 >> iter 42000, loss: 0.050440
 >> iter 43000, loss: 0.063196
 >> iter 44000, loss: 0.045607
 >> iter 45000, loss: 0.044657
 >> iter 46000, loss: 0.055560
 >> iter 47000, loss: 0.060813
 >> iter 48000, loss: 0.048621
 >> iter 49000, loss: 0.052009
 >> iter 50000, loss: 0.044973
   Number of active neurons: 3
 >> iter 51000, loss: 0.045739
 >> iter 52000, loss: 0.063725
 >> iter 53000, loss: 0.058180
 >> iter 54000, loss: 0.051582
 >> iter 55000, loss: 0.044218
 >> iter 56000, loss: 0.039257
 >> iter 57000, loss: 0.036976
 >> iter 58000, loss: 0.056622
 >> iter 59000, loss: 0.052910
 >> iter 60000, loss: 0.052998
   Number of active neurons: 3
 >> iter 61000, loss: 0.039086
 >> iter 62000, loss: 0.038954
 >> iter 63000, loss: 0.051778
 >> iter 64000, loss: 0.050008
 >> iter 65000, loss: 0.045541
 >> iter 66000, loss: 0.047728
 >> iter 67000, loss: 0.047473
 >> iter 68000, loss: 0.058388
 >> iter 69000, loss: 0.053585
 >> iter 70000, loss: 0.047855
   Number of active neurons: 3
 >> iter 71000, loss: 0.055768
 >> iter 72000, loss: 0.051496
 >> iter 73000, loss: 0.046566
 >> iter 74000, loss: 0.060038
 >> iter 75000, loss: 0.062219
 >> iter 76000, loss: 0.047495
 >> iter 77000, loss: 0.053228
 >> iter 78000, loss: 0.054961
 >> iter 79000, loss: 0.047724
 >> iter 80000, loss: 0.040406
   Number of active neurons: 3
 >> iter 81000, loss: 0.047814
 >> iter 82000, loss: 0.043113
 >> iter 83000, loss: 0.067750
 >> iter 84000, loss: 0.049597
 >> iter 85000, loss: 0.035962
 >> iter 86000, loss: 0.031543
 >> iter 87000, loss: 0.049769
 >> iter 88000, loss: 0.043423
 >> iter 89000, loss: 0.035516
 >> iter 90000, loss: 0.046127
   Number of active neurons: 2
 >> iter 91000, loss: 0.035982
 >> iter 92000, loss: 0.050150
 >> iter 93000, loss: 0.045230
 >> iter 94000, loss: 0.063125
 >> iter 95000, loss: 0.045355
 >> iter 96000, loss: 0.037399
 >> iter 97000, loss: 0.033822
 >> iter 98000, loss: 0.040097
 >> iter 99000, loss: 0.039602
 >> iter 100000, loss: 0.029077
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.293376
 >> iter 2000, loss: 4.412035
 >> iter 3000, loss: 1.744526
 >> iter 4000, loss: 0.760781
 >> iter 5000, loss: 0.386734
 >> iter 6000, loss: 0.211963
 >> iter 7000, loss: 0.134968
 >> iter 8000, loss: 0.104937
 >> iter 9000, loss: 0.087320
 >> iter 10000, loss: 0.075790
   Number of active neurons: 10
 >> iter 11000, loss: 0.090766
 >> iter 12000, loss: 0.088793
 >> iter 13000, loss: 0.077288
 >> iter 14000, loss: 0.070892
 >> iter 15000, loss: 0.064496
 >> iter 16000, loss: 0.058678
 >> iter 17000, loss: 0.054815
 >> iter 18000, loss: 0.049923
 >> iter 19000, loss: 0.053133
 >> iter 20000, loss: 0.059735
   Number of active neurons: 8
 >> iter 21000, loss: 0.053164
 >> iter 22000, loss: 0.066585
 >> iter 23000, loss: 0.082902
 >> iter 24000, loss: 0.065222
 >> iter 25000, loss: 0.077124
 >> iter 26000, loss: 0.058966
 >> iter 27000, loss: 0.057084
 >> iter 28000, loss: 0.062607
 >> iter 29000, loss: 0.056513
 >> iter 30000, loss: 0.057959
   Number of active neurons: 5
 >> iter 31000, loss: 0.048373
 >> iter 32000, loss: 0.060873
 >> iter 33000, loss: 0.057547
 >> iter 34000, loss: 0.052364
 >> iter 35000, loss: 0.051500
 >> iter 36000, loss: 0.042700
 >> iter 37000, loss: 0.043684
 >> iter 38000, loss: 0.047355
 >> iter 39000, loss: 0.041869
 >> iter 40000, loss: 0.031239
   Number of active neurons: 5
 >> iter 41000, loss: 0.056122
 >> iter 42000, loss: 0.055102
 >> iter 43000, loss: 0.047402
 >> iter 44000, loss: 0.051816
 >> iter 45000, loss: 0.035994
 >> iter 46000, loss: 0.054080
 >> iter 47000, loss: 0.049247
 >> iter 48000, loss: 0.049523
 >> iter 49000, loss: 0.056678
 >> iter 50000, loss: 0.035166
   Number of active neurons: 4
 >> iter 51000, loss: 0.045520
 >> iter 52000, loss: 0.042191
 >> iter 53000, loss: 0.054213
 >> iter 54000, loss: 0.052085
 >> iter 55000, loss: 0.057974
 >> iter 56000, loss: 0.049539
 >> iter 57000, loss: 0.048030
 >> iter 58000, loss: 0.048757
 >> iter 59000, loss: 0.051947
 >> iter 60000, loss: 0.044719
   Number of active neurons: 3
 >> iter 61000, loss: 0.035646
 >> iter 62000, loss: 0.041328
 >> iter 63000, loss: 0.038629
 >> iter 64000, loss: 0.053136
 >> iter 65000, loss: 0.058844
 >> iter 66000, loss: 0.041280
 >> iter 67000, loss: 0.062273
 >> iter 68000, loss: 0.072089
 >> iter 69000, loss: 0.046565
 >> iter 70000, loss: 0.047609
   Number of active neurons: 2
 >> iter 71000, loss: 0.061133
 >> iter 72000, loss: 0.044221
 >> iter 73000, loss: 0.035869
 >> iter 74000, loss: 0.034973
 >> iter 75000, loss: 0.039310
 >> iter 76000, loss: 0.056360
 >> iter 77000, loss: 0.060154
 >> iter 78000, loss: 0.054637
 >> iter 79000, loss: 0.048905
 >> iter 80000, loss: 0.047352
   Number of active neurons: 2
 >> iter 81000, loss: 0.059220
 >> iter 82000, loss: 0.073883
 >> iter 83000, loss: 0.054785
 >> iter 84000, loss: 0.044443
 >> iter 85000, loss: 0.039165
 >> iter 86000, loss: 0.047747
 >> iter 87000, loss: 0.041628
 >> iter 88000, loss: 0.049317
 >> iter 89000, loss: 0.053902
 >> iter 90000, loss: 0.053810
   Number of active neurons: 2
 >> iter 91000, loss: 0.043487
 >> iter 92000, loss: 0.043906
 >> iter 93000, loss: 0.042683
 >> iter 94000, loss: 0.040895
 >> iter 95000, loss: 0.077053
 >> iter 96000, loss: 0.053962
 >> iter 97000, loss: 0.039444
 >> iter 98000, loss: 0.044922
 >> iter 99000, loss: 0.038121
 >> iter 100000, loss: 0.043303
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455162
   Number of active neurons: 0
 >> iter 1000, loss: 11.288054
 >> iter 2000, loss: 4.447075
 >> iter 3000, loss: 1.764447
 >> iter 4000, loss: 0.751076
 >> iter 5000, loss: 0.337850
 >> iter 6000, loss: 0.183507
 >> iter 7000, loss: 0.129554
 >> iter 8000, loss: 0.108897
 >> iter 9000, loss: 0.087074
 >> iter 10000, loss: 0.086989
   Number of active neurons: 9
 >> iter 11000, loss: 0.076715
 >> iter 12000, loss: 0.072545
 >> iter 13000, loss: 0.089528
 >> iter 14000, loss: 0.065534
 >> iter 15000, loss: 0.064636
 >> iter 16000, loss: 0.056592
 >> iter 17000, loss: 0.054253
 >> iter 18000, loss: 0.069469
 >> iter 19000, loss: 0.080131
 >> iter 20000, loss: 0.066352
   Number of active neurons: 7
 >> iter 21000, loss: 0.075030
 >> iter 22000, loss: 0.068628
 >> iter 23000, loss: 0.062380
 >> iter 24000, loss: 0.067467
 >> iter 25000, loss: 0.052894
 >> iter 26000, loss: 0.056851
 >> iter 27000, loss: 0.054175
 >> iter 28000, loss: 0.050193
 >> iter 29000, loss: 0.064727
 >> iter 30000, loss: 0.067437
   Number of active neurons: 6
 >> iter 31000, loss: 0.059547
 >> iter 32000, loss: 0.051634
 >> iter 33000, loss: 0.048643
 >> iter 34000, loss: 0.064598
 >> iter 35000, loss: 0.076324
 >> iter 36000, loss: 0.070924
 >> iter 37000, loss: 0.062770
 >> iter 38000, loss: 0.077515
 >> iter 39000, loss: 0.057257
 >> iter 40000, loss: 0.055658
   Number of active neurons: 6
 >> iter 41000, loss: 0.051830
 >> iter 42000, loss: 0.063716
 >> iter 43000, loss: 0.045634
 >> iter 44000, loss: 0.053363
 >> iter 45000, loss: 0.046972
 >> iter 46000, loss: 0.053978
 >> iter 47000, loss: 0.063264
 >> iter 48000, loss: 0.044899
 >> iter 49000, loss: 0.064842
 >> iter 50000, loss: 0.062200
   Number of active neurons: 6
 >> iter 51000, loss: 0.045914
 >> iter 52000, loss: 0.043370
 >> iter 53000, loss: 0.041657
 >> iter 54000, loss: 0.057617
 >> iter 55000, loss: 0.062340
 >> iter 56000, loss: 0.057664
 >> iter 57000, loss: 0.062978
 >> iter 58000, loss: 0.062170
 >> iter 59000, loss: 0.051270
 >> iter 60000, loss: 0.045725
   Number of active neurons: 4
 >> iter 61000, loss: 0.048435
 >> iter 62000, loss: 0.035759
 >> iter 63000, loss: 0.042259
 >> iter 64000, loss: 0.043410
 >> iter 65000, loss: 0.050012
 >> iter 66000, loss: 0.043060
 >> iter 67000, loss: 0.037449
 >> iter 68000, loss: 0.054141
 >> iter 69000, loss: 0.040356
 >> iter 70000, loss: 0.045371
   Number of active neurons: 4
 >> iter 71000, loss: 0.048475
 >> iter 72000, loss: 0.044827
 >> iter 73000, loss: 0.050161
 >> iter 74000, loss: 0.059626
 >> iter 75000, loss: 0.047770
 >> iter 76000, loss: 0.045431
 >> iter 77000, loss: 0.054935
 >> iter 78000, loss: 0.054316
 >> iter 79000, loss: 0.049343
 >> iter 80000, loss: 0.057982
   Number of active neurons: 4
 >> iter 81000, loss: 0.052563
 >> iter 82000, loss: 0.049219
 >> iter 83000, loss: 0.047105
 >> iter 84000, loss: 0.036645
 >> iter 85000, loss: 0.041607
 >> iter 86000, loss: 0.041727
 >> iter 87000, loss: 0.041044
 >> iter 88000, loss: 0.035581
 >> iter 89000, loss: 0.048812
 >> iter 90000, loss: 0.054000
   Number of active neurons: 3
 >> iter 91000, loss: 0.045805
 >> iter 92000, loss: 0.068062
 >> iter 93000, loss: 0.046492
 >> iter 94000, loss: 0.033165
 >> iter 95000, loss: 0.053712
 >> iter 96000, loss: 0.056146
 >> iter 97000, loss: 0.041039
 >> iter 98000, loss: 0.050411
 >> iter 99000, loss: 0.054043
 >> iter 100000, loss: 0.047701
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.327876
 >> iter 2000, loss: 4.480013
 >> iter 3000, loss: 1.775625
 >> iter 4000, loss: 0.756089
 >> iter 5000, loss: 0.383584
 >> iter 6000, loss: 0.198317
 >> iter 7000, loss: 0.138058
 >> iter 8000, loss: 0.102353
 >> iter 9000, loss: 0.078751
 >> iter 10000, loss: 0.078894
   Number of active neurons: 9
 >> iter 11000, loss: 0.080683
 >> iter 12000, loss: 0.063846
 >> iter 13000, loss: 0.091333
 >> iter 14000, loss: 0.080725
 >> iter 15000, loss: 0.085773
 >> iter 16000, loss: 0.075470
 >> iter 17000, loss: 0.072665
 >> iter 18000, loss: 0.073420
 >> iter 19000, loss: 0.060311
 >> iter 20000, loss: 0.052689
   Number of active neurons: 8
 >> iter 21000, loss: 0.060136
 >> iter 22000, loss: 0.058551
 >> iter 23000, loss: 0.060402
 >> iter 24000, loss: 0.059542
 >> iter 25000, loss: 0.053395
 >> iter 26000, loss: 0.038655
 >> iter 27000, loss: 0.042866
 >> iter 28000, loss: 0.060424
 >> iter 29000, loss: 0.066008
 >> iter 30000, loss: 0.066949
   Number of active neurons: 6
 >> iter 31000, loss: 0.055867
 >> iter 32000, loss: 0.056972
 >> iter 33000, loss: 0.062882
 >> iter 34000, loss: 0.046312
 >> iter 35000, loss: 0.060412
 >> iter 36000, loss: 0.060606
 >> iter 37000, loss: 0.045005
 >> iter 38000, loss: 0.049661
 >> iter 39000, loss: 0.039663
 >> iter 40000, loss: 0.046931
   Number of active neurons: 5
 >> iter 41000, loss: 0.050226
 >> iter 42000, loss: 0.049101
 >> iter 43000, loss: 0.038298
 >> iter 44000, loss: 0.042324
 >> iter 45000, loss: 0.050383
 >> iter 46000, loss: 0.066302
 >> iter 47000, loss: 0.051920
 >> iter 48000, loss: 0.057578
 >> iter 49000, loss: 0.062309
 >> iter 50000, loss: 0.051474
   Number of active neurons: 4
 >> iter 51000, loss: 0.033905
 >> iter 52000, loss: 0.037643
 >> iter 53000, loss: 0.044501
 >> iter 54000, loss: 0.046347
 >> iter 55000, loss: 0.053906
 >> iter 56000, loss: 0.045666
 >> iter 57000, loss: 0.055741
 >> iter 58000, loss: 0.046912
 >> iter 59000, loss: 0.046451
 >> iter 60000, loss: 0.042378
   Number of active neurons: 3
 >> iter 61000, loss: 0.047455
 >> iter 62000, loss: 0.036592
 >> iter 63000, loss: 0.040804
 >> iter 64000, loss: 0.047881
 >> iter 65000, loss: 0.044752
 >> iter 66000, loss: 0.066310
 >> iter 67000, loss: 0.053169
 >> iter 68000, loss: 0.039609
 >> iter 69000, loss: 0.032910
 >> iter 70000, loss: 0.035383
   Number of active neurons: 3
 >> iter 71000, loss: 0.029965
 >> iter 72000, loss: 0.041608
 >> iter 73000, loss: 0.045851
 >> iter 74000, loss: 0.050648
 >> iter 75000, loss: 0.045438
 >> iter 76000, loss: 0.036046
 >> iter 77000, loss: 0.052874
 >> iter 78000, loss: 0.043658
 >> iter 79000, loss: 0.046312
 >> iter 80000, loss: 0.058544
   Number of active neurons: 2
 >> iter 81000, loss: 0.049923
 >> iter 82000, loss: 0.042521
 >> iter 83000, loss: 0.041701
 >> iter 84000, loss: 0.043322
 >> iter 85000, loss: 0.042639
 >> iter 86000, loss: 0.052132
 >> iter 87000, loss: 0.055343
 >> iter 88000, loss: 0.056398
 >> iter 89000, loss: 0.053837
 >> iter 90000, loss: 0.032250
   Number of active neurons: 2
 >> iter 91000, loss: 0.048536
 >> iter 92000, loss: 0.061268
 >> iter 93000, loss: 0.052970
 >> iter 94000, loss: 0.055284
 >> iter 95000, loss: 0.060809
 >> iter 96000, loss: 0.044799
 >> iter 97000, loss: 0.034748
 >> iter 98000, loss: 0.027494
 >> iter 99000, loss: 0.027657
 >> iter 100000, loss: 0.045880
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455163
   Number of active neurons: 0
 >> iter 1000, loss: 11.329322
 >> iter 2000, loss: 4.457005
 >> iter 3000, loss: 1.765169
 >> iter 4000, loss: 0.738201
 >> iter 5000, loss: 0.340597
 >> iter 6000, loss: 0.201257
 >> iter 7000, loss: 0.132324
 >> iter 8000, loss: 0.090828
 >> iter 9000, loss: 0.086103
 >> iter 10000, loss: 0.075901
   Number of active neurons: 9
 >> iter 11000, loss: 0.066485
 >> iter 12000, loss: 0.076138
 >> iter 13000, loss: 0.060776
 >> iter 14000, loss: 0.060911
 >> iter 15000, loss: 0.072691
 >> iter 16000, loss: 0.055200
 >> iter 17000, loss: 0.050044
 >> iter 18000, loss: 0.054519
 >> iter 19000, loss: 0.055146
 >> iter 20000, loss: 0.053001
   Number of active neurons: 7
 >> iter 21000, loss: 0.057463
 >> iter 22000, loss: 0.056201
 >> iter 23000, loss: 0.050751
 >> iter 24000, loss: 0.055194
 >> iter 25000, loss: 0.052143
 >> iter 26000, loss: 0.050156
 >> iter 27000, loss: 0.042282
 >> iter 28000, loss: 0.061077
 >> iter 29000, loss: 0.068048
 >> iter 30000, loss: 0.051543
   Number of active neurons: 5
 >> iter 31000, loss: 0.046624
 >> iter 32000, loss: 0.048992
 >> iter 33000, loss: 0.053852
 >> iter 34000, loss: 0.052644
 >> iter 35000, loss: 0.055608
 >> iter 36000, loss: 0.039663
 >> iter 37000, loss: 0.060913
 >> iter 38000, loss: 0.065585
 >> iter 39000, loss: 0.051801
 >> iter 40000, loss: 0.046578
   Number of active neurons: 5
 >> iter 41000, loss: 0.050869
 >> iter 42000, loss: 0.040199
 >> iter 43000, loss: 0.047042
 >> iter 44000, loss: 0.042238
 >> iter 45000, loss: 0.049534
 >> iter 46000, loss: 0.056577
 >> iter 47000, loss: 0.063793
 >> iter 48000, loss: 0.083320
 >> iter 49000, loss: 0.062890
 >> iter 50000, loss: 0.046530
   Number of active neurons: 5
 >> iter 51000, loss: 0.051638
 >> iter 52000, loss: 0.050051
 >> iter 53000, loss: 0.065481
 >> iter 54000, loss: 0.048352
 >> iter 55000, loss: 0.064560
 >> iter 56000, loss: 0.047647
 >> iter 57000, loss: 0.040744
 >> iter 58000, loss: 0.055529
 >> iter 59000, loss: 0.047314
 >> iter 60000, loss: 0.068370
   Number of active neurons: 5
 >> iter 61000, loss: 0.086480
 >> iter 62000, loss: 0.061977
 >> iter 63000, loss: 0.055265
 >> iter 64000, loss: 0.069298
 >> iter 65000, loss: 0.066332
 >> iter 66000, loss: 0.058807
 >> iter 67000, loss: 0.059160
 >> iter 68000, loss: 0.047619
 >> iter 69000, loss: 0.078056
 >> iter 70000, loss: 0.050543
   Number of active neurons: 5
 >> iter 71000, loss: 0.043216
 >> iter 72000, loss: 0.051333
 >> iter 73000, loss: 0.050147
 >> iter 74000, loss: 0.059253
 >> iter 75000, loss: 0.051084
 >> iter 76000, loss: 0.066532
 >> iter 77000, loss: 0.058083
 >> iter 78000, loss: 0.063340
 >> iter 79000, loss: 0.057578
 >> iter 80000, loss: 0.049179
   Number of active neurons: 5
 >> iter 81000, loss: 0.063265
 >> iter 82000, loss: 0.045838
 >> iter 83000, loss: 0.066351
 >> iter 84000, loss: 0.063320
 >> iter 85000, loss: 0.050110
 >> iter 86000, loss: 0.061890
 >> iter 87000, loss: 0.055819
 >> iter 88000, loss: 0.050732
 >> iter 89000, loss: 0.039323
 >> iter 90000, loss: 0.039047
   Number of active neurons: 5
 >> iter 91000, loss: 0.074529
 >> iter 92000, loss: 0.062357
 >> iter 93000, loss: 0.048740
 >> iter 94000, loss: 0.048183
 >> iter 95000, loss: 0.049008
 >> iter 96000, loss: 0.041336
 >> iter 97000, loss: 0.037233
 >> iter 98000, loss: 0.044353
 >> iter 99000, loss: 0.035289
 >> iter 100000, loss: 0.033910
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 11.325684
 >> iter 2000, loss: 4.447784
 >> iter 3000, loss: 1.796046
 >> iter 4000, loss: 0.774404
 >> iter 5000, loss: 0.366504
 >> iter 6000, loss: 0.181969
 >> iter 7000, loss: 0.150061
 >> iter 8000, loss: 0.114147
 >> iter 9000, loss: 0.093681
 >> iter 10000, loss: 0.091529
   Number of active neurons: 8
 >> iter 11000, loss: 0.076332
 >> iter 12000, loss: 0.065897
 >> iter 13000, loss: 0.058800
 >> iter 14000, loss: 0.074434
 >> iter 15000, loss: 0.056021
 >> iter 16000, loss: 0.056109
 >> iter 17000, loss: 0.058514
 >> iter 18000, loss: 0.083232
 >> iter 19000, loss: 0.064614
 >> iter 20000, loss: 0.052904
   Number of active neurons: 7
 >> iter 21000, loss: 0.046998
 >> iter 22000, loss: 0.051023
 >> iter 23000, loss: 0.065147
 >> iter 24000, loss: 0.049228
 >> iter 25000, loss: 0.050400
 >> iter 26000, loss: 0.065879
 >> iter 27000, loss: 0.047983
 >> iter 28000, loss: 0.038881
 >> iter 29000, loss: 0.047112
 >> iter 30000, loss: 0.061534
   Number of active neurons: 4
 >> iter 31000, loss: 0.051282
 >> iter 32000, loss: 0.070383
 >> iter 33000, loss: 0.052858
 >> iter 34000, loss: 0.057130
 >> iter 35000, loss: 0.042519
 >> iter 36000, loss: 0.042009
 >> iter 37000, loss: 0.053768
 >> iter 38000, loss: 0.040827
 >> iter 39000, loss: 0.044075
 >> iter 40000, loss: 0.041031
   Number of active neurons: 3
 >> iter 41000, loss: 0.073011
 >> iter 42000, loss: 0.047128
 >> iter 43000, loss: 0.049462
 >> iter 44000, loss: 0.051279
 >> iter 45000, loss: 0.044361
 >> iter 46000, loss: 0.038270
 >> iter 47000, loss: 0.030865
 >> iter 48000, loss: 0.036846
 >> iter 49000, loss: 0.040962
 >> iter 50000, loss: 0.039557
   Number of active neurons: 3
 >> iter 51000, loss: 0.066268
 >> iter 52000, loss: 0.055565
 >> iter 53000, loss: 0.056356
 >> iter 54000, loss: 0.056796
 >> iter 55000, loss: 0.048440
 >> iter 56000, loss: 0.047618
 >> iter 57000, loss: 0.048783
 >> iter 58000, loss: 0.046188
 >> iter 59000, loss: 0.047948
 >> iter 60000, loss: 0.050630
   Number of active neurons: 3
 >> iter 61000, loss: 0.052369
 >> iter 62000, loss: 0.048674
 >> iter 63000, loss: 0.054105
 >> iter 64000, loss: 0.047942
 >> iter 65000, loss: 0.037846
 >> iter 66000, loss: 0.048089
 >> iter 67000, loss: 0.048757
 >> iter 68000, loss: 0.042193
 >> iter 69000, loss: 0.046492
 >> iter 70000, loss: 0.036611
   Number of active neurons: 3
 >> iter 71000, loss: 0.052669
 >> iter 72000, loss: 0.044226
 >> iter 73000, loss: 0.036234
 >> iter 74000, loss: 0.033219
 >> iter 75000, loss: 0.052748
 >> iter 76000, loss: 0.076879
 >> iter 77000, loss: 0.053772
 >> iter 78000, loss: 0.054346
 >> iter 79000, loss: 0.072879
 >> iter 80000, loss: 0.049030
   Number of active neurons: 3
 >> iter 81000, loss: 0.044782
 >> iter 82000, loss: 0.042515
 >> iter 83000, loss: 0.053682
 >> iter 84000, loss: 0.056048
 >> iter 85000, loss: 0.044741
 >> iter 86000, loss: 0.047391
 >> iter 87000, loss: 0.039661
 >> iter 88000, loss: 0.035426
 >> iter 89000, loss: 0.040484
 >> iter 90000, loss: 0.034526
   Number of active neurons: 3
 >> iter 91000, loss: 0.043599
 >> iter 92000, loss: 0.050110
 >> iter 93000, loss: 0.041361
 >> iter 94000, loss: 0.051518
 >> iter 95000, loss: 0.052981
 >> iter 96000, loss: 0.041832
 >> iter 97000, loss: 0.033431
 >> iter 98000, loss: 0.033685
 >> iter 99000, loss: 0.055600
 >> iter 100000, loss: 0.063805
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.352621
 >> iter 2000, loss: 4.506357
 >> iter 3000, loss: 1.833346
 >> iter 4000, loss: 0.832047
 >> iter 5000, loss: 0.383259
 >> iter 6000, loss: 0.203830
 >> iter 7000, loss: 0.176813
 >> iter 8000, loss: 0.153169
 >> iter 9000, loss: 0.138198
 >> iter 10000, loss: 0.085197
   Number of active neurons: 13
 >> iter 11000, loss: 0.085213
 >> iter 12000, loss: 0.083567
 >> iter 13000, loss: 0.090910
 >> iter 14000, loss: 0.074224
 >> iter 15000, loss: 0.087303
 >> iter 16000, loss: 0.081765
 >> iter 17000, loss: 0.066658
 >> iter 18000, loss: 0.054232
 >> iter 19000, loss: 0.071804
 >> iter 20000, loss: 0.062186
   Number of active neurons: 9
 >> iter 21000, loss: 0.057386
 >> iter 22000, loss: 0.055359
 >> iter 23000, loss: 0.069049
 >> iter 24000, loss: 0.064292
 >> iter 25000, loss: 0.063221
 >> iter 26000, loss: 0.053277
 >> iter 27000, loss: 0.054307
 >> iter 28000, loss: 0.050217
 >> iter 29000, loss: 0.052247
 >> iter 30000, loss: 0.057402
   Number of active neurons: 4
 >> iter 31000, loss: 0.071801
 >> iter 32000, loss: 0.045362
 >> iter 33000, loss: 0.043418
 >> iter 34000, loss: 0.045769
 >> iter 35000, loss: 0.044468
 >> iter 36000, loss: 0.043087
 >> iter 37000, loss: 0.045399
 >> iter 38000, loss: 0.045333
 >> iter 39000, loss: 0.040965
 >> iter 40000, loss: 0.055446
   Number of active neurons: 4
 >> iter 41000, loss: 0.056768
 >> iter 42000, loss: 0.052332
 >> iter 43000, loss: 0.052862
 >> iter 44000, loss: 0.058658
 >> iter 45000, loss: 0.048363
 >> iter 46000, loss: 0.058162
 >> iter 47000, loss: 0.040998
 >> iter 48000, loss: 0.039645
 >> iter 49000, loss: 0.036944
 >> iter 50000, loss: 0.043966
   Number of active neurons: 3
 >> iter 51000, loss: 0.039156
 >> iter 52000, loss: 0.038346
 >> iter 53000, loss: 0.042015
 >> iter 54000, loss: 0.037166
 >> iter 55000, loss: 0.032641
 >> iter 56000, loss: 0.049233
 >> iter 57000, loss: 0.042684
 >> iter 58000, loss: 0.068570
 >> iter 59000, loss: 0.061397
 >> iter 60000, loss: 0.050367
   Number of active neurons: 3
 >> iter 61000, loss: 0.041742
 >> iter 62000, loss: 0.037467
 >> iter 63000, loss: 0.038043
 >> iter 64000, loss: 0.046846
 >> iter 65000, loss: 0.057686
 >> iter 66000, loss: 0.045858
 >> iter 67000, loss: 0.046742
 >> iter 68000, loss: 0.049762
 >> iter 69000, loss: 0.042725
 >> iter 70000, loss: 0.068762
   Number of active neurons: 3
 >> iter 71000, loss: 0.047729
 >> iter 72000, loss: 0.048190
 >> iter 73000, loss: 0.041339
 >> iter 74000, loss: 0.041301
 >> iter 75000, loss: 0.061528
 >> iter 76000, loss: 0.049029
 >> iter 77000, loss: 0.046756
 >> iter 78000, loss: 0.040615
 >> iter 79000, loss: 0.037622
 >> iter 80000, loss: 0.040244
   Number of active neurons: 3
 >> iter 81000, loss: 0.036600
 >> iter 82000, loss: 0.041914
 >> iter 83000, loss: 0.042837
 >> iter 84000, loss: 0.037630
 >> iter 85000, loss: 0.061974
 >> iter 86000, loss: 0.060125
 >> iter 87000, loss: 0.039872
 >> iter 88000, loss: 0.044195
 >> iter 89000, loss: 0.031843
 >> iter 90000, loss: 0.043916
   Number of active neurons: 3
 >> iter 91000, loss: 0.035161
 >> iter 92000, loss: 0.040373
 >> iter 93000, loss: 0.047488
 >> iter 94000, loss: 0.053135
 >> iter 95000, loss: 0.052842
 >> iter 96000, loss: 0.043683
 >> iter 97000, loss: 0.034488
 >> iter 98000, loss: 0.042528
 >> iter 99000, loss: 0.042237
 >> iter 100000, loss: 0.039905
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.325195
 >> iter 2000, loss: 4.398822
 >> iter 3000, loss: 1.722074
 >> iter 4000, loss: 0.714685
 >> iter 5000, loss: 0.338215
 >> iter 6000, loss: 0.174556
 >> iter 7000, loss: 0.127833
 >> iter 8000, loss: 0.100762
 >> iter 9000, loss: 0.070033
 >> iter 10000, loss: 0.102896
   Number of active neurons: 8
 >> iter 11000, loss: 0.090877
 >> iter 12000, loss: 0.084102
 >> iter 13000, loss: 0.070012
 >> iter 14000, loss: 0.077617
 >> iter 15000, loss: 0.071408
 >> iter 16000, loss: 0.063632
 >> iter 17000, loss: 0.051638
 >> iter 18000, loss: 0.066915
 >> iter 19000, loss: 0.048742
 >> iter 20000, loss: 0.044313
   Number of active neurons: 7
 >> iter 21000, loss: 0.065630
 >> iter 22000, loss: 0.066814
 >> iter 23000, loss: 0.058300
 >> iter 24000, loss: 0.052566
 >> iter 25000, loss: 0.044903
 >> iter 26000, loss: 0.039917
 >> iter 27000, loss: 0.058136
 >> iter 28000, loss: 0.068936
 >> iter 29000, loss: 0.073636
 >> iter 30000, loss: 0.060123
   Number of active neurons: 6
 >> iter 31000, loss: 0.054185
 >> iter 32000, loss: 0.054412
 >> iter 33000, loss: 0.045839
 >> iter 34000, loss: 0.054109
 >> iter 35000, loss: 0.059909
 >> iter 36000, loss: 0.076131
 >> iter 37000, loss: 0.065242
 >> iter 38000, loss: 0.047597
 >> iter 39000, loss: 0.048667
 >> iter 40000, loss: 0.048885
   Number of active neurons: 5
 >> iter 41000, loss: 0.045036
 >> iter 42000, loss: 0.058064
 >> iter 43000, loss: 0.051966
 >> iter 44000, loss: 0.056685
 >> iter 45000, loss: 0.056469
 >> iter 46000, loss: 0.047164
 >> iter 47000, loss: 0.041095
 >> iter 48000, loss: 0.046974
 >> iter 49000, loss: 0.071572
 >> iter 50000, loss: 0.055314
   Number of active neurons: 5
 >> iter 51000, loss: 0.046646
 >> iter 52000, loss: 0.046138
 >> iter 53000, loss: 0.050776
 >> iter 54000, loss: 0.058027
 >> iter 55000, loss: 0.076165
 >> iter 56000, loss: 0.065521
 >> iter 57000, loss: 0.067271
 >> iter 58000, loss: 0.054025
 >> iter 59000, loss: 0.044061
 >> iter 60000, loss: 0.037594
   Number of active neurons: 3
 >> iter 61000, loss: 0.055251
 >> iter 62000, loss: 0.056028
 >> iter 63000, loss: 0.044247
 >> iter 64000, loss: 0.052014
 >> iter 65000, loss: 0.046480
 >> iter 66000, loss: 0.044183
 >> iter 67000, loss: 0.055753
 >> iter 68000, loss: 0.060109
 >> iter 69000, loss: 0.041402
 >> iter 70000, loss: 0.046796
   Number of active neurons: 3
 >> iter 71000, loss: 0.066016
 >> iter 72000, loss: 0.056844
 >> iter 73000, loss: 0.037862
 >> iter 74000, loss: 0.036454
 >> iter 75000, loss: 0.050016
 >> iter 76000, loss: 0.053455
 >> iter 77000, loss: 0.055190
 >> iter 78000, loss: 0.060469
 >> iter 79000, loss: 0.076737
 >> iter 80000, loss: 0.062964
   Number of active neurons: 3
 >> iter 81000, loss: 0.071066
 >> iter 82000, loss: 0.068939
 >> iter 83000, loss: 0.069062
 >> iter 84000, loss: 0.053927
 >> iter 85000, loss: 0.076289
 >> iter 86000, loss: 0.056035
 >> iter 87000, loss: 0.047356
 >> iter 88000, loss: 0.057638
 >> iter 89000, loss: 0.058665
 >> iter 90000, loss: 0.046099
   Number of active neurons: 3
 >> iter 91000, loss: 0.041909
 >> iter 92000, loss: 0.032283
 >> iter 93000, loss: 0.034142
 >> iter 94000, loss: 0.037038
 >> iter 95000, loss: 0.052547
 >> iter 96000, loss: 0.041811
 >> iter 97000, loss: 0.033322
 >> iter 98000, loss: 0.038788
 >> iter 99000, loss: 0.034758
 >> iter 100000, loss: 0.038491
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.365433
 >> iter 2000, loss: 4.469159
 >> iter 3000, loss: 1.828783
 >> iter 4000, loss: 0.783551
 >> iter 5000, loss: 0.364409
 >> iter 6000, loss: 0.186658
 >> iter 7000, loss: 0.127639
 >> iter 8000, loss: 0.125239
 >> iter 9000, loss: 0.094380
 >> iter 10000, loss: 0.100080
   Number of active neurons: 11
 >> iter 11000, loss: 0.069213
 >> iter 12000, loss: 0.110280
 >> iter 13000, loss: 0.090583
 >> iter 14000, loss: 0.070730
 >> iter 15000, loss: 0.060812
 >> iter 16000, loss: 0.077109
 >> iter 17000, loss: 0.077880
 >> iter 18000, loss: 0.064137
 >> iter 19000, loss: 0.067633
 >> iter 20000, loss: 0.078020
   Number of active neurons: 9
 >> iter 21000, loss: 0.095168
 >> iter 22000, loss: 0.080505
 >> iter 23000, loss: 0.070822
 >> iter 24000, loss: 0.051653
 >> iter 25000, loss: 0.047153
 >> iter 26000, loss: 0.068224
 >> iter 27000, loss: 0.056570
 >> iter 28000, loss: 0.067327
 >> iter 29000, loss: 0.048447
 >> iter 30000, loss: 0.070426
   Number of active neurons: 6
 >> iter 31000, loss: 0.049834
 >> iter 32000, loss: 0.059453
 >> iter 33000, loss: 0.054398
 >> iter 34000, loss: 0.043567
 >> iter 35000, loss: 0.067284
 >> iter 36000, loss: 0.055492
 >> iter 37000, loss: 0.039297
 >> iter 38000, loss: 0.046323
 >> iter 39000, loss: 0.053683
 >> iter 40000, loss: 0.068801
   Number of active neurons: 5
 >> iter 41000, loss: 0.073216
 >> iter 42000, loss: 0.063085
 >> iter 43000, loss: 0.047040
 >> iter 44000, loss: 0.049304
 >> iter 45000, loss: 0.053645
 >> iter 46000, loss: 0.073557
 >> iter 47000, loss: 0.066232
 >> iter 48000, loss: 0.068489
 >> iter 49000, loss: 0.054689
 >> iter 50000, loss: 0.047678
   Number of active neurons: 5
 >> iter 51000, loss: 0.057438
 >> iter 52000, loss: 0.047168
 >> iter 53000, loss: 0.052997
 >> iter 54000, loss: 0.044563
 >> iter 55000, loss: 0.062370
 >> iter 56000, loss: 0.058759
 >> iter 57000, loss: 0.044219
 >> iter 58000, loss: 0.065896
 >> iter 59000, loss: 0.049205
 >> iter 60000, loss: 0.043860
   Number of active neurons: 3
 >> iter 61000, loss: 0.040433
 >> iter 62000, loss: 0.056302
 >> iter 63000, loss: 0.038114
 >> iter 64000, loss: 0.045659
 >> iter 65000, loss: 0.046243
 >> iter 66000, loss: 0.053578
 >> iter 67000, loss: 0.064862
 >> iter 68000, loss: 0.045261
 >> iter 69000, loss: 0.050317
 >> iter 70000, loss: 0.052887
   Number of active neurons: 3
 >> iter 71000, loss: 0.035944
 >> iter 72000, loss: 0.048397
 >> iter 73000, loss: 0.042442
 >> iter 74000, loss: 0.059833
 >> iter 75000, loss: 0.056243
 >> iter 76000, loss: 0.059231
 >> iter 77000, loss: 0.043311
 >> iter 78000, loss: 0.060096
 >> iter 79000, loss: 0.068909
 >> iter 80000, loss: 0.044371
   Number of active neurons: 2
 >> iter 81000, loss: 0.054048
 >> iter 82000, loss: 0.058615
 >> iter 83000, loss: 0.039491
 >> iter 84000, loss: 0.041418
 >> iter 85000, loss: 0.043005
 >> iter 86000, loss: 0.055174
 >> iter 87000, loss: 0.038467
 >> iter 88000, loss: 0.030660
 >> iter 89000, loss: 0.040266
 >> iter 90000, loss: 0.056808
   Number of active neurons: 2
 >> iter 91000, loss: 0.046666
 >> iter 92000, loss: 0.039144
 >> iter 93000, loss: 0.034651
 >> iter 94000, loss: 0.035794
 >> iter 95000, loss: 0.043818
 >> iter 96000, loss: 0.050402
 >> iter 97000, loss: 0.034291
 >> iter 98000, loss: 0.044560
 >> iter 99000, loss: 0.053146
 >> iter 100000, loss: 0.043716
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 11.277296
 >> iter 2000, loss: 4.409738
 >> iter 3000, loss: 1.789325
 >> iter 4000, loss: 0.743664
 >> iter 5000, loss: 0.367718
 >> iter 6000, loss: 0.208124
 >> iter 7000, loss: 0.140738
 >> iter 8000, loss: 0.098051
 >> iter 9000, loss: 0.107240
 >> iter 10000, loss: 0.112815
   Number of active neurons: 8
 >> iter 11000, loss: 0.093590
 >> iter 12000, loss: 0.094053
 >> iter 13000, loss: 0.075058
 >> iter 14000, loss: 0.061598
 >> iter 15000, loss: 0.089740
 >> iter 16000, loss: 0.071576
 >> iter 17000, loss: 0.091339
 >> iter 18000, loss: 0.071246
 >> iter 19000, loss: 0.071805
 >> iter 20000, loss: 0.056517
   Number of active neurons: 7
 >> iter 21000, loss: 0.084855
 >> iter 22000, loss: 0.063885
 >> iter 23000, loss: 0.070440
 >> iter 24000, loss: 0.066702
 >> iter 25000, loss: 0.047938
 >> iter 26000, loss: 0.054945
 >> iter 27000, loss: 0.050655
 >> iter 28000, loss: 0.069970
 >> iter 29000, loss: 0.051241
 >> iter 30000, loss: 0.046148
   Number of active neurons: 6
 >> iter 31000, loss: 0.047110
 >> iter 32000, loss: 0.048033
 >> iter 33000, loss: 0.044706
 >> iter 34000, loss: 0.039401
 >> iter 35000, loss: 0.065551
 >> iter 36000, loss: 0.062520
 >> iter 37000, loss: 0.050090
 >> iter 38000, loss: 0.048116
 >> iter 39000, loss: 0.046729
 >> iter 40000, loss: 0.052792
   Number of active neurons: 6
 >> iter 41000, loss: 0.058959
 >> iter 42000, loss: 0.058763
 >> iter 43000, loss: 0.070043
 >> iter 44000, loss: 0.057549
 >> iter 45000, loss: 0.043372
 >> iter 46000, loss: 0.047862
 >> iter 47000, loss: 0.046261
 >> iter 48000, loss: 0.049195
 >> iter 49000, loss: 0.046373
 >> iter 50000, loss: 0.041026
   Number of active neurons: 5
 >> iter 51000, loss: 0.047281
 >> iter 52000, loss: 0.065966
 >> iter 53000, loss: 0.068140
 >> iter 54000, loss: 0.058916
 >> iter 55000, loss: 0.082071
 >> iter 56000, loss: 0.077342
 >> iter 57000, loss: 0.050547
 >> iter 58000, loss: 0.043472
 >> iter 59000, loss: 0.040799
 >> iter 60000, loss: 0.032996
   Number of active neurons: 4
 >> iter 61000, loss: 0.037052
 >> iter 62000, loss: 0.045982
 >> iter 63000, loss: 0.047598
 >> iter 64000, loss: 0.049710
 >> iter 65000, loss: 0.048839
 >> iter 66000, loss: 0.041522
 >> iter 67000, loss: 0.066082
 >> iter 68000, loss: 0.049680
 >> iter 69000, loss: 0.047856
 >> iter 70000, loss: 0.051416
   Number of active neurons: 4
 >> iter 71000, loss: 0.060997
 >> iter 72000, loss: 0.087690
 >> iter 73000, loss: 0.057986
 >> iter 74000, loss: 0.060014
 >> iter 75000, loss: 0.062859
 >> iter 76000, loss: 0.041812
 >> iter 77000, loss: 0.042678
 >> iter 78000, loss: 0.068686
 >> iter 79000, loss: 0.065518
 >> iter 80000, loss: 0.067652
   Number of active neurons: 4
 >> iter 81000, loss: 0.070723
 >> iter 82000, loss: 0.054235
 >> iter 83000, loss: 0.062192
 >> iter 84000, loss: 0.054232
 >> iter 85000, loss: 0.039909
 >> iter 86000, loss: 0.065234
 >> iter 87000, loss: 0.055906
 >> iter 88000, loss: 0.062686
 >> iter 89000, loss: 0.052988
 >> iter 90000, loss: 0.058132
   Number of active neurons: 4
 >> iter 91000, loss: 0.063544
 >> iter 92000, loss: 0.046851
 >> iter 93000, loss: 0.067132
 >> iter 94000, loss: 0.057210
 >> iter 95000, loss: 0.061356
 >> iter 96000, loss: 0.042235
 >> iter 97000, loss: 0.037052
 >> iter 98000, loss: 0.041435
 >> iter 99000, loss: 0.036793
 >> iter 100000, loss: 0.055168
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.326261
 >> iter 2000, loss: 4.489042
 >> iter 3000, loss: 1.837517
 >> iter 4000, loss: 0.808404
 >> iter 5000, loss: 0.380980
 >> iter 6000, loss: 0.214014
 >> iter 7000, loss: 0.148638
 >> iter 8000, loss: 0.099234
 >> iter 9000, loss: 0.105925
 >> iter 10000, loss: 0.095463
   Number of active neurons: 10
 >> iter 11000, loss: 0.087118
 >> iter 12000, loss: 0.080654
 >> iter 13000, loss: 0.073438
 >> iter 14000, loss: 0.087003
 >> iter 15000, loss: 0.088407
 >> iter 16000, loss: 0.100955
 >> iter 17000, loss: 0.094899
 >> iter 18000, loss: 0.072467
 >> iter 19000, loss: 0.073007
 >> iter 20000, loss: 0.051168
   Number of active neurons: 7
 >> iter 21000, loss: 0.056684
 >> iter 22000, loss: 0.064791
 >> iter 23000, loss: 0.053018
 >> iter 24000, loss: 0.051679
 >> iter 25000, loss: 0.058574
 >> iter 26000, loss: 0.052774
 >> iter 27000, loss: 0.052541
 >> iter 28000, loss: 0.069532
 >> iter 29000, loss: 0.082732
 >> iter 30000, loss: 0.047530
   Number of active neurons: 5
 >> iter 31000, loss: 0.050498
 >> iter 32000, loss: 0.066336
 >> iter 33000, loss: 0.069693
 >> iter 34000, loss: 0.047693
 >> iter 35000, loss: 0.050880
 >> iter 36000, loss: 0.055089
 >> iter 37000, loss: 0.057948
 >> iter 38000, loss: 0.055942
 >> iter 39000, loss: 0.056528
 >> iter 40000, loss: 0.059762
   Number of active neurons: 4
 >> iter 41000, loss: 0.038071
 >> iter 42000, loss: 0.047169
 >> iter 43000, loss: 0.046987
 >> iter 44000, loss: 0.053832
 >> iter 45000, loss: 0.061905
 >> iter 46000, loss: 0.055240
 >> iter 47000, loss: 0.046681
 >> iter 48000, loss: 0.049881
 >> iter 49000, loss: 0.052204
 >> iter 50000, loss: 0.071019
   Number of active neurons: 3
 >> iter 51000, loss: 0.055577
 >> iter 52000, loss: 0.064578
 >> iter 53000, loss: 0.065583
 >> iter 54000, loss: 0.048637
 >> iter 55000, loss: 0.051953
 >> iter 56000, loss: 0.072252
 >> iter 57000, loss: 0.066122
 >> iter 58000, loss: 0.051700
 >> iter 59000, loss: 0.047007
 >> iter 60000, loss: 0.045361
   Number of active neurons: 3
 >> iter 61000, loss: 0.051153
 >> iter 62000, loss: 0.041185
 >> iter 63000, loss: 0.044252
 >> iter 64000, loss: 0.052554
 >> iter 65000, loss: 0.049448
 >> iter 66000, loss: 0.043490
 >> iter 67000, loss: 0.041816
 >> iter 68000, loss: 0.041650
 >> iter 69000, loss: 0.057797
 >> iter 70000, loss: 0.046243
   Number of active neurons: 3
 >> iter 71000, loss: 0.046118
 >> iter 72000, loss: 0.040129
 >> iter 73000, loss: 0.032745
 >> iter 74000, loss: 0.032433
 >> iter 75000, loss: 0.041551
 >> iter 76000, loss: 0.037298
 >> iter 77000, loss: 0.033687
 >> iter 78000, loss: 0.051617
 >> iter 79000, loss: 0.053755
 >> iter 80000, loss: 0.052470
   Number of active neurons: 3
 >> iter 81000, loss: 0.061600
 >> iter 82000, loss: 0.050506
 >> iter 83000, loss: 0.058882
 >> iter 84000, loss: 0.054759
 >> iter 85000, loss: 0.036990
 >> iter 86000, loss: 0.041541
 >> iter 87000, loss: 0.042801
 >> iter 88000, loss: 0.047564
 >> iter 89000, loss: 0.045248
 >> iter 90000, loss: 0.055046
   Number of active neurons: 3
 >> iter 91000, loss: 0.059743
 >> iter 92000, loss: 0.061657
 >> iter 93000, loss: 0.058781
 >> iter 94000, loss: 0.051769
 >> iter 95000, loss: 0.051485
 >> iter 96000, loss: 0.045469
 >> iter 97000, loss: 0.043511
 >> iter 98000, loss: 0.046368
 >> iter 99000, loss: 0.045923
 >> iter 100000, loss: 0.062983
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.450053
 >> iter 2000, loss: 4.532151
 >> iter 3000, loss: 1.804970
 >> iter 4000, loss: 0.782232
 >> iter 5000, loss: 0.358146
 >> iter 6000, loss: 0.214938
 >> iter 7000, loss: 0.165478
 >> iter 8000, loss: 0.159036
 >> iter 9000, loss: 0.126218
 >> iter 10000, loss: 0.099896
   Number of active neurons: 10
 >> iter 11000, loss: 0.084802
 >> iter 12000, loss: 0.082070
 >> iter 13000, loss: 0.076279
 >> iter 14000, loss: 0.079441
 >> iter 15000, loss: 0.078445
 >> iter 16000, loss: 0.076674
 >> iter 17000, loss: 0.082195
 >> iter 18000, loss: 0.058034
 >> iter 19000, loss: 0.051633
 >> iter 20000, loss: 0.042334
   Number of active neurons: 7
 >> iter 21000, loss: 0.074866
 >> iter 22000, loss: 0.062755
 >> iter 23000, loss: 0.056539
 >> iter 24000, loss: 0.054175
 >> iter 25000, loss: 0.046205
 >> iter 26000, loss: 0.044228
 >> iter 27000, loss: 0.050370
 >> iter 28000, loss: 0.061882
 >> iter 29000, loss: 0.041248
 >> iter 30000, loss: 0.051617
   Number of active neurons: 5
 >> iter 31000, loss: 0.042407
 >> iter 32000, loss: 0.038231
 >> iter 33000, loss: 0.041379
 >> iter 34000, loss: 0.038455
 >> iter 35000, loss: 0.049869
 >> iter 36000, loss: 0.046966
 >> iter 37000, loss: 0.061202
 >> iter 38000, loss: 0.054323
 >> iter 39000, loss: 0.042155
 >> iter 40000, loss: 0.039388
   Number of active neurons: 5
 >> iter 41000, loss: 0.035839
 >> iter 42000, loss: 0.029796
 >> iter 43000, loss: 0.032067
 >> iter 44000, loss: 0.041296
 >> iter 45000, loss: 0.057048
 >> iter 46000, loss: 0.061910
 >> iter 47000, loss: 0.043639
 >> iter 48000, loss: 0.042854
 >> iter 49000, loss: 0.047575
 >> iter 50000, loss: 0.055371
   Number of active neurons: 4
 >> iter 51000, loss: 0.065153
 >> iter 52000, loss: 0.078195
 >> iter 53000, loss: 0.080191
 >> iter 54000, loss: 0.061253
 >> iter 55000, loss: 0.048941
 >> iter 56000, loss: 0.035364
 >> iter 57000, loss: 0.028886
 >> iter 58000, loss: 0.041012
 >> iter 59000, loss: 0.055533
 >> iter 60000, loss: 0.058145
   Number of active neurons: 2
 >> iter 61000, loss: 0.048442
 >> iter 62000, loss: 0.040138
 >> iter 63000, loss: 0.044265
 >> iter 64000, loss: 0.045492
 >> iter 65000, loss: 0.048712
 >> iter 66000, loss: 0.054643
 >> iter 67000, loss: 0.053206
 >> iter 68000, loss: 0.043325
 >> iter 69000, loss: 0.068940
 >> iter 70000, loss: 0.072607
   Number of active neurons: 2
 >> iter 71000, loss: 0.056530
 >> iter 72000, loss: 0.055745
 >> iter 73000, loss: 0.046276
 >> iter 74000, loss: 0.055700
 >> iter 75000, loss: 0.064758
 >> iter 76000, loss: 0.041771
 >> iter 77000, loss: 0.062313
 >> iter 78000, loss: 0.050856
 >> iter 79000, loss: 0.058897
 >> iter 80000, loss: 0.051389
   Number of active neurons: 2
 >> iter 81000, loss: 0.074507
 >> iter 82000, loss: 0.055188
 >> iter 83000, loss: 0.045238
 >> iter 84000, loss: 0.048144
 >> iter 85000, loss: 0.045976
 >> iter 86000, loss: 0.048626
 >> iter 87000, loss: 0.047506
 >> iter 88000, loss: 0.035111
 >> iter 89000, loss: 0.033817
 >> iter 90000, loss: 0.032149
   Number of active neurons: 2
 >> iter 91000, loss: 0.044467
 >> iter 92000, loss: 0.037775
 >> iter 93000, loss: 0.040809
 >> iter 94000, loss: 0.053081
 >> iter 95000, loss: 0.053736
 >> iter 96000, loss: 0.042743
 >> iter 97000, loss: 0.041200
 >> iter 98000, loss: 0.035611
 >> iter 99000, loss: 0.061919
 >> iter 100000, loss: 0.040294
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.309172
 >> iter 2000, loss: 4.431379
 >> iter 3000, loss: 1.767213
 >> iter 4000, loss: 0.748520
 >> iter 5000, loss: 0.341623
 >> iter 6000, loss: 0.198950
 >> iter 7000, loss: 0.148801
 >> iter 8000, loss: 0.128890
 >> iter 9000, loss: 0.127419
 >> iter 10000, loss: 0.081550
   Number of active neurons: 9
 >> iter 11000, loss: 0.079136
 >> iter 12000, loss: 0.083132
 >> iter 13000, loss: 0.065217
 >> iter 14000, loss: 0.077516
 >> iter 15000, loss: 0.110708
 >> iter 16000, loss: 0.077944
 >> iter 17000, loss: 0.085215
 >> iter 18000, loss: 0.066298
 >> iter 19000, loss: 0.067135
 >> iter 20000, loss: 0.068492
   Number of active neurons: 7
 >> iter 21000, loss: 0.052047
 >> iter 22000, loss: 0.070209
 >> iter 23000, loss: 0.058586
 >> iter 24000, loss: 0.060253
 >> iter 25000, loss: 0.070511
 >> iter 26000, loss: 0.063234
 >> iter 27000, loss: 0.046000
 >> iter 28000, loss: 0.045950
 >> iter 29000, loss: 0.048378
 >> iter 30000, loss: 0.042947
   Number of active neurons: 6
 >> iter 31000, loss: 0.063400
 >> iter 32000, loss: 0.058565
 >> iter 33000, loss: 0.056462
 >> iter 34000, loss: 0.067309
 >> iter 35000, loss: 0.049768
 >> iter 36000, loss: 0.045124
 >> iter 37000, loss: 0.053969
 >> iter 38000, loss: 0.049802
 >> iter 39000, loss: 0.052774
 >> iter 40000, loss: 0.055263
   Number of active neurons: 5
 >> iter 41000, loss: 0.047479
 >> iter 42000, loss: 0.060589
 >> iter 43000, loss: 0.061246
 >> iter 44000, loss: 0.051065
 >> iter 45000, loss: 0.039002
 >> iter 46000, loss: 0.047970
 >> iter 47000, loss: 0.036380
 >> iter 48000, loss: 0.048049
 >> iter 49000, loss: 0.045586
 >> iter 50000, loss: 0.044120
   Number of active neurons: 4
 >> iter 51000, loss: 0.073447
 >> iter 52000, loss: 0.065860
 >> iter 53000, loss: 0.051967
 >> iter 54000, loss: 0.072776
 >> iter 55000, loss: 0.052570
 >> iter 56000, loss: 0.064977
 >> iter 57000, loss: 0.050660
 >> iter 58000, loss: 0.039688
 >> iter 59000, loss: 0.044613
 >> iter 60000, loss: 0.042603
   Number of active neurons: 4
 >> iter 61000, loss: 0.045205
 >> iter 62000, loss: 0.059215
 >> iter 63000, loss: 0.044050
 >> iter 64000, loss: 0.037893
 >> iter 65000, loss: 0.055364
 >> iter 66000, loss: 0.066443
 >> iter 67000, loss: 0.066576
 >> iter 68000, loss: 0.065699
 >> iter 69000, loss: 0.046525
 >> iter 70000, loss: 0.064432
   Number of active neurons: 4
 >> iter 71000, loss: 0.052113
 >> iter 72000, loss: 0.047627
 >> iter 73000, loss: 0.046432
 >> iter 74000, loss: 0.057218
 >> iter 75000, loss: 0.067234
 >> iter 76000, loss: 0.052051
 >> iter 77000, loss: 0.042768
 >> iter 78000, loss: 0.068096
 >> iter 79000, loss: 0.053574
 >> iter 80000, loss: 0.038838
   Number of active neurons: 4
 >> iter 81000, loss: 0.071873
 >> iter 82000, loss: 0.080536
 >> iter 83000, loss: 0.058633
 >> iter 84000, loss: 0.040029
 >> iter 85000, loss: 0.037104
 >> iter 86000, loss: 0.039378
 >> iter 87000, loss: 0.032527
 >> iter 88000, loss: 0.045118
 >> iter 89000, loss: 0.048889
 >> iter 90000, loss: 0.072588
   Number of active neurons: 3
 >> iter 91000, loss: 0.060798
 >> iter 92000, loss: 0.057154
 >> iter 93000, loss: 0.040500
 >> iter 94000, loss: 0.042530
 >> iter 95000, loss: 0.029229
 >> iter 96000, loss: 0.030274
 >> iter 97000, loss: 0.041869
 >> iter 98000, loss: 0.046744
 >> iter 99000, loss: 0.047169
 >> iter 100000, loss: 0.041702
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.280227
 >> iter 2000, loss: 4.406015
 >> iter 3000, loss: 1.744142
 >> iter 4000, loss: 0.730948
 >> iter 5000, loss: 0.347276
 >> iter 6000, loss: 0.198289
 >> iter 7000, loss: 0.125855
 >> iter 8000, loss: 0.093264
 >> iter 9000, loss: 0.104022
 >> iter 10000, loss: 0.089184
   Number of active neurons: 9
 >> iter 11000, loss: 0.074274
 >> iter 12000, loss: 0.067025
 >> iter 13000, loss: 0.085624
 >> iter 14000, loss: 0.073834
 >> iter 15000, loss: 0.062445
 >> iter 16000, loss: 0.061839
 >> iter 17000, loss: 0.065317
 >> iter 18000, loss: 0.062613
 >> iter 19000, loss: 0.043471
 >> iter 20000, loss: 0.050933
   Number of active neurons: 9
 >> iter 21000, loss: 0.063720
 >> iter 22000, loss: 0.077809
 >> iter 23000, loss: 0.073740
 >> iter 24000, loss: 0.054783
 >> iter 25000, loss: 0.055198
 >> iter 26000, loss: 0.042833
 >> iter 27000, loss: 0.045591
 >> iter 28000, loss: 0.062158
 >> iter 29000, loss: 0.058510
 >> iter 30000, loss: 0.062150
   Number of active neurons: 7
 >> iter 31000, loss: 0.053503
 >> iter 32000, loss: 0.055119
 >> iter 33000, loss: 0.052012
 >> iter 34000, loss: 0.050718
 >> iter 35000, loss: 0.055312
 >> iter 36000, loss: 0.065388
 >> iter 37000, loss: 0.047084
 >> iter 38000, loss: 0.038324
 >> iter 39000, loss: 0.045247
 >> iter 40000, loss: 0.058759
   Number of active neurons: 5
 >> iter 41000, loss: 0.065785
 >> iter 42000, loss: 0.062898
 >> iter 43000, loss: 0.063867
 >> iter 44000, loss: 0.078258
 >> iter 45000, loss: 0.067732
 >> iter 46000, loss: 0.062594
 >> iter 47000, loss: 0.050847
 >> iter 48000, loss: 0.042709
 >> iter 49000, loss: 0.042472
 >> iter 50000, loss: 0.061966
   Number of active neurons: 4
 >> iter 51000, loss: 0.050466
 >> iter 52000, loss: 0.043918
 >> iter 53000, loss: 0.051679
 >> iter 54000, loss: 0.061131
 >> iter 55000, loss: 0.059022
 >> iter 56000, loss: 0.044446
 >> iter 57000, loss: 0.034590
 >> iter 58000, loss: 0.040443
 >> iter 59000, loss: 0.043746
 >> iter 60000, loss: 0.052916
   Number of active neurons: 3
 >> iter 61000, loss: 0.064956
 >> iter 62000, loss: 0.061348
 >> iter 63000, loss: 0.052095
 >> iter 64000, loss: 0.050142
 >> iter 65000, loss: 0.044334
 >> iter 66000, loss: 0.048535
 >> iter 67000, loss: 0.046653
 >> iter 68000, loss: 0.046640
 >> iter 69000, loss: 0.052574
 >> iter 70000, loss: 0.041704
   Number of active neurons: 3
 >> iter 71000, loss: 0.032888
 >> iter 72000, loss: 0.035318
 >> iter 73000, loss: 0.040058
 >> iter 74000, loss: 0.068444
 >> iter 75000, loss: 0.068854
 >> iter 76000, loss: 0.061604
 >> iter 77000, loss: 0.053241
 >> iter 78000, loss: 0.037896
 >> iter 79000, loss: 0.027742
 >> iter 80000, loss: 0.048628
   Number of active neurons: 2
 >> iter 81000, loss: 0.045676
 >> iter 82000, loss: 0.038087
 >> iter 83000, loss: 0.029662
 >> iter 84000, loss: 0.046159
 >> iter 85000, loss: 0.034566
 >> iter 86000, loss: 0.031664
 >> iter 87000, loss: 0.065046
 >> iter 88000, loss: 0.061499
 >> iter 89000, loss: 0.064270
 >> iter 90000, loss: 0.047993
   Number of active neurons: 2
 >> iter 91000, loss: 0.054443
 >> iter 92000, loss: 0.041007
 >> iter 93000, loss: 0.037454
 >> iter 94000, loss: 0.045012
 >> iter 95000, loss: 0.039327
 >> iter 96000, loss: 0.062369
 >> iter 97000, loss: 0.040876
 >> iter 98000, loss: 0.033798
 >> iter 99000, loss: 0.033414
 >> iter 100000, loss: 0.040605
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

