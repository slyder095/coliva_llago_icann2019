 > Problema: tomita7nueva
 > Args:
   - Hidden size: 14
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.571337
 >> iter 2000, loss: 10.278304
 >> iter 3000, loss: 6.640518
 >> iter 4000, loss: 3.485512
 >> iter 5000, loss: 2.053628
 >> iter 6000, loss: 1.395889
 >> iter 7000, loss: 0.997075
 >> iter 8000, loss: 0.769584
 >> iter 9000, loss: 0.744473
 >> iter 10000, loss: 0.544197
   Number of active neurons: 8
 >> iter 11000, loss: 0.460531
 >> iter 12000, loss: 0.472088
 >> iter 13000, loss: 0.690413
 >> iter 14000, loss: 0.523562
 >> iter 15000, loss: 0.556444
 >> iter 16000, loss: 0.476411
 >> iter 17000, loss: 0.429887
 >> iter 18000, loss: 0.447963
 >> iter 19000, loss: 0.477326
 >> iter 20000, loss: 0.477108
   Number of active neurons: 8
 >> iter 21000, loss: 0.562778
 >> iter 22000, loss: 0.424789
 >> iter 23000, loss: 0.336952
 >> iter 24000, loss: 0.414139
 >> iter 25000, loss: 0.395507
 >> iter 26000, loss: 0.318190
 >> iter 27000, loss: 0.314971
 >> iter 28000, loss: 0.331184
 >> iter 29000, loss: 0.401462
 >> iter 30000, loss: 0.352660
   Number of active neurons: 8
 >> iter 31000, loss: 0.321426
 >> iter 32000, loss: 0.297195
 >> iter 33000, loss: 0.368679
 >> iter 34000, loss: 0.358349
 >> iter 35000, loss: 0.402360
 >> iter 36000, loss: 0.370228
 >> iter 37000, loss: 0.267757
 >> iter 38000, loss: 0.303453
 >> iter 39000, loss: 0.325621
 >> iter 40000, loss: 0.313488
   Number of active neurons: 8
 >> iter 41000, loss: 0.378829
 >> iter 42000, loss: 0.295114
 >> iter 43000, loss: 0.306473
 >> iter 44000, loss: 0.320277
 >> iter 45000, loss: 0.250743
 >> iter 46000, loss: 0.191868
 >> iter 47000, loss: 0.319431
 >> iter 48000, loss: 0.481824
 >> iter 49000, loss: 0.521222
 >> iter 50000, loss: 0.314869
   Number of active neurons: 8
 >> iter 51000, loss: 0.468434
 >> iter 52000, loss: 0.472642
 >> iter 53000, loss: 0.395801
 >> iter 54000, loss: 0.302474
 >> iter 55000, loss: 0.270260
 >> iter 56000, loss: 0.322115
 >> iter 57000, loss: 0.292165
 >> iter 58000, loss: 0.285971
 >> iter 59000, loss: 0.277336
 >> iter 60000, loss: 0.251115
   Number of active neurons: 8
 >> iter 61000, loss: 0.297598
 >> iter 62000, loss: 0.237758
 >> iter 63000, loss: 0.319683
 >> iter 64000, loss: 0.250009
 >> iter 65000, loss: 0.257164
 >> iter 66000, loss: 0.188943
 >> iter 67000, loss: 0.279156
 >> iter 68000, loss: 0.308568
 >> iter 69000, loss: 0.248681
 >> iter 70000, loss: 0.234791
   Number of active neurons: 6
 >> iter 71000, loss: 0.261152
 >> iter 72000, loss: 0.204741
 >> iter 73000, loss: 0.209173
 >> iter 74000, loss: 0.222292
 >> iter 75000, loss: 0.359366
 >> iter 76000, loss: 0.386159
 >> iter 77000, loss: 0.387273
 >> iter 78000, loss: 0.303213
 >> iter 79000, loss: 0.225309
 >> iter 80000, loss: 0.251147
   Number of active neurons: 6
 >> iter 81000, loss: 0.217784
 >> iter 82000, loss: 0.214614
 >> iter 83000, loss: 0.233466
 >> iter 84000, loss: 0.179062
 >> iter 85000, loss: 0.278224
 >> iter 86000, loss: 0.252452
 >> iter 87000, loss: 0.230713
 >> iter 88000, loss: 0.225729
 >> iter 89000, loss: 0.255875
 >> iter 90000, loss: 0.258975
   Number of active neurons: 6
 >> iter 91000, loss: 0.337058
 >> iter 92000, loss: 0.300863
 >> iter 93000, loss: 0.206247
 >> iter 94000, loss: 0.276993
 >> iter 95000, loss: 0.217432
 >> iter 96000, loss: 0.255175
 >> iter 97000, loss: 0.324225
 >> iter 98000, loss: 0.323841
 >> iter 99000, loss: 0.282493
 >> iter 100000, loss: 0.259846
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.764239
 >> iter 2000, loss: 9.698937
 >> iter 3000, loss: 5.817802
 >> iter 4000, loss: 3.338340
 >> iter 5000, loss: 1.900335
 >> iter 6000, loss: 1.231087
 >> iter 7000, loss: 0.818868
 >> iter 8000, loss: 0.752343
 >> iter 9000, loss: 0.494760
 >> iter 10000, loss: 0.411820
   Number of active neurons: 7
 >> iter 11000, loss: 0.315636
 >> iter 12000, loss: 0.356454
 >> iter 13000, loss: 0.427042
 >> iter 14000, loss: 0.498590
 >> iter 15000, loss: 0.454410
 >> iter 16000, loss: 0.507579
 >> iter 17000, loss: 0.619724
 >> iter 18000, loss: 0.528504
 >> iter 19000, loss: 0.545635
 >> iter 20000, loss: 0.484821
   Number of active neurons: 7
 >> iter 21000, loss: 0.551983
 >> iter 22000, loss: 0.492489
 >> iter 23000, loss: 0.455789
 >> iter 24000, loss: 0.393681
 >> iter 25000, loss: 0.444368
 >> iter 26000, loss: 0.338731
 >> iter 27000, loss: 0.437591
 >> iter 28000, loss: 0.497427
 >> iter 29000, loss: 0.573159
 >> iter 30000, loss: 0.508693
   Number of active neurons: 7
 >> iter 31000, loss: 0.580109
 >> iter 32000, loss: 0.626400
 >> iter 33000, loss: 0.591341
 >> iter 34000, loss: 0.490394
 >> iter 35000, loss: 0.421286
 >> iter 36000, loss: 0.542737
 >> iter 37000, loss: 0.549838
 >> iter 38000, loss: 0.638768
 >> iter 39000, loss: 0.582224
 >> iter 40000, loss: 0.701125
   Number of active neurons: 7
 >> iter 41000, loss: 0.726802
 >> iter 42000, loss: 0.479872
 >> iter 43000, loss: 0.618840
 >> iter 44000, loss: 0.557084
 >> iter 45000, loss: 0.535089
 >> iter 46000, loss: 0.573544
 >> iter 47000, loss: 0.450654
 >> iter 48000, loss: 0.468607
 >> iter 49000, loss: 0.527034
 >> iter 50000, loss: 0.582361
   Number of active neurons: 7
 >> iter 51000, loss: 0.580910
 >> iter 52000, loss: 0.422011
 >> iter 53000, loss: 0.403584
 >> iter 54000, loss: 0.455980
 >> iter 55000, loss: 0.397474
 >> iter 56000, loss: 0.393730
 >> iter 57000, loss: 0.374887
 >> iter 58000, loss: 0.495895
 >> iter 59000, loss: 0.569524
 >> iter 60000, loss: 0.514516
   Number of active neurons: 7
 >> iter 61000, loss: 0.715682
 >> iter 62000, loss: 0.513824
 >> iter 63000, loss: 0.449655
 >> iter 64000, loss: 0.521875
 >> iter 65000, loss: 0.475644
 >> iter 66000, loss: 0.468119
 >> iter 67000, loss: 0.374306
 >> iter 68000, loss: 0.547195
 >> iter 69000, loss: 0.434228
 >> iter 70000, loss: 0.368864
   Number of active neurons: 6
 >> iter 71000, loss: 0.523284
 >> iter 72000, loss: 0.513562
 >> iter 73000, loss: 0.485229
 >> iter 74000, loss: 0.404598
 >> iter 75000, loss: 0.551099
 >> iter 76000, loss: 0.549667
 >> iter 77000, loss: 0.556829
 >> iter 78000, loss: 0.577048
 >> iter 79000, loss: 0.468995
 >> iter 80000, loss: 0.587488
   Number of active neurons: 6
 >> iter 81000, loss: 0.521241
 >> iter 82000, loss: 0.436955
 >> iter 83000, loss: 0.465155
 >> iter 84000, loss: 0.461525
 >> iter 85000, loss: 0.330471
 >> iter 86000, loss: 0.302631
 >> iter 87000, loss: 0.433116
 >> iter 88000, loss: 0.510474
 >> iter 89000, loss: 0.514522
 >> iter 90000, loss: 0.481287
   Number of active neurons: 6
 >> iter 91000, loss: 0.503239
 >> iter 92000, loss: 0.511054
 >> iter 93000, loss: 0.525342
 >> iter 94000, loss: 0.617668
 >> iter 95000, loss: 0.489325
 >> iter 96000, loss: 0.474527
 >> iter 97000, loss: 0.402763
 >> iter 98000, loss: 0.356718
 >> iter 99000, loss: 0.471063
 >> iter 100000, loss: 0.402007
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.568771
 >> iter 2000, loss: 9.786199
 >> iter 3000, loss: 5.638901
 >> iter 4000, loss: 2.984735
 >> iter 5000, loss: 1.690750
 >> iter 6000, loss: 0.993256
 >> iter 7000, loss: 0.736415
 >> iter 8000, loss: 0.755292
 >> iter 9000, loss: 0.652553
 >> iter 10000, loss: 0.463508
   Number of active neurons: 5
 >> iter 11000, loss: 0.445014
 >> iter 12000, loss: 0.359433
 >> iter 13000, loss: 0.474638
 >> iter 14000, loss: 0.501372
 >> iter 15000, loss: 0.457105
 >> iter 16000, loss: 0.430260
 >> iter 17000, loss: 0.363991
 >> iter 18000, loss: 0.424609
 >> iter 19000, loss: 0.454691
 >> iter 20000, loss: 0.361527
   Number of active neurons: 5
 >> iter 21000, loss: 0.405370
 >> iter 22000, loss: 0.406649
 >> iter 23000, loss: 0.526584
 >> iter 24000, loss: 0.431952
 >> iter 25000, loss: 0.338824
 >> iter 26000, loss: 0.371682
 >> iter 27000, loss: 0.502398
 >> iter 28000, loss: 0.608592
 >> iter 29000, loss: 0.594869
 >> iter 30000, loss: 0.428740
   Number of active neurons: 6
 >> iter 31000, loss: 0.439849
 >> iter 32000, loss: 0.391862
 >> iter 33000, loss: 0.452481
 >> iter 34000, loss: 0.408221
 >> iter 35000, loss: 0.453213
 >> iter 36000, loss: 0.450706
 >> iter 37000, loss: 0.508090
 >> iter 38000, loss: 0.468255
 >> iter 39000, loss: 0.392633
 >> iter 40000, loss: 0.511010
   Number of active neurons: 5
 >> iter 41000, loss: 0.491286
 >> iter 42000, loss: 0.489480
 >> iter 43000, loss: 0.319402
 >> iter 44000, loss: 0.433942
 >> iter 45000, loss: 0.409744
 >> iter 46000, loss: 0.301298
 >> iter 47000, loss: 0.421296
 >> iter 48000, loss: 0.514150
 >> iter 49000, loss: 0.457834
 >> iter 50000, loss: 0.489654
   Number of active neurons: 5
 >> iter 51000, loss: 0.588052
 >> iter 52000, loss: 0.657025
 >> iter 53000, loss: 0.575825
 >> iter 54000, loss: 0.521897
 >> iter 55000, loss: 0.440048
 >> iter 56000, loss: 0.434153
 >> iter 57000, loss: 0.415299
 >> iter 58000, loss: 0.446283
 >> iter 59000, loss: 0.391668
 >> iter 60000, loss: 0.339868
   Number of active neurons: 5
 >> iter 61000, loss: 0.474269
 >> iter 62000, loss: 0.501926
 >> iter 63000, loss: 0.466015
 >> iter 64000, loss: 0.577813
 >> iter 65000, loss: 0.544276
 >> iter 66000, loss: 0.485427
 >> iter 67000, loss: 0.496197
 >> iter 68000, loss: 0.559647
 >> iter 69000, loss: 0.507937
 >> iter 70000, loss: 0.575132
   Number of active neurons: 6
 >> iter 71000, loss: 0.562640
 >> iter 72000, loss: 0.613600
 >> iter 73000, loss: 0.627607
 >> iter 74000, loss: 0.639635
 >> iter 75000, loss: 0.697552
 >> iter 76000, loss: 0.740464
 >> iter 77000, loss: 0.678985
 >> iter 78000, loss: 0.574589
 >> iter 79000, loss: 0.636553
 >> iter 80000, loss: 0.597759
   Number of active neurons: 5
 >> iter 81000, loss: 0.544072
 >> iter 82000, loss: 0.409544
 >> iter 83000, loss: 0.427456
 >> iter 84000, loss: 0.373643
 >> iter 85000, loss: 0.468033
 >> iter 86000, loss: 0.579699
 >> iter 87000, loss: 0.511905
 >> iter 88000, loss: 0.491209
 >> iter 89000, loss: 0.554910
 >> iter 90000, loss: 0.725235
   Number of active neurons: 4
 >> iter 91000, loss: 0.713716
 >> iter 92000, loss: 0.597381
 >> iter 93000, loss: 0.501926
 >> iter 94000, loss: 0.675731
 >> iter 95000, loss: 0.533845
 >> iter 96000, loss: 0.543209
 >> iter 97000, loss: 0.715295
 >> iter 98000, loss: 0.591862
 >> iter 99000, loss: 0.469007
 >> iter 100000, loss: 0.640156
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.124889
 >> iter 2000, loss: 10.221942
 >> iter 3000, loss: 5.918969
 >> iter 4000, loss: 2.717073
 >> iter 5000, loss: 1.250258
 >> iter 6000, loss: 0.759757
 >> iter 7000, loss: 0.462346
 >> iter 8000, loss: 0.331459
 >> iter 9000, loss: 0.244383
 >> iter 10000, loss: 0.262530
   Number of active neurons: 9
 >> iter 11000, loss: 0.305332
 >> iter 12000, loss: 0.256055
 >> iter 13000, loss: 0.235559
 >> iter 14000, loss: 0.216301
 >> iter 15000, loss: 0.237361
 >> iter 16000, loss: 0.216569
 >> iter 17000, loss: 0.197416
 >> iter 18000, loss: 0.283324
 >> iter 19000, loss: 0.260225
 >> iter 20000, loss: 0.243489
   Number of active neurons: 8
 >> iter 21000, loss: 0.186391
 >> iter 22000, loss: 0.232399
 >> iter 23000, loss: 0.159622
 >> iter 24000, loss: 0.238360
 >> iter 25000, loss: 0.279900
 >> iter 26000, loss: 0.192650
 >> iter 27000, loss: 0.162069
 >> iter 28000, loss: 0.152942
 >> iter 29000, loss: 0.288097
 >> iter 30000, loss: 0.163849
   Number of active neurons: 8
 >> iter 31000, loss: 0.236501
 >> iter 32000, loss: 0.403179
 >> iter 33000, loss: 0.248917
 >> iter 34000, loss: 0.133155
 >> iter 35000, loss: 0.169453
 >> iter 36000, loss: 0.192944
 >> iter 37000, loss: 0.189414
 >> iter 38000, loss: 0.244186
 >> iter 39000, loss: 0.288202
 >> iter 40000, loss: 0.185557
   Number of active neurons: 7
 >> iter 41000, loss: 0.228967
 >> iter 42000, loss: 0.249824
 >> iter 43000, loss: 0.204340
 >> iter 44000, loss: 0.260609
 >> iter 45000, loss: 0.275061
 >> iter 46000, loss: 0.209246
 >> iter 47000, loss: 0.158366
 >> iter 48000, loss: 0.186503
 >> iter 49000, loss: 0.196643
 >> iter 50000, loss: 0.214399
   Number of active neurons: 7
 >> iter 51000, loss: 0.185375
 >> iter 52000, loss: 0.163548
 >> iter 53000, loss: 0.169106
 >> iter 54000, loss: 0.204435
 >> iter 55000, loss: 0.151877
 >> iter 56000, loss: 0.124975
 >> iter 57000, loss: 0.255957
 >> iter 58000, loss: 0.166344
 >> iter 59000, loss: 0.173437
 >> iter 60000, loss: 0.156312
   Number of active neurons: 6
 >> iter 61000, loss: 0.139567
 >> iter 62000, loss: 0.166008
 >> iter 63000, loss: 0.183941
 >> iter 64000, loss: 0.186449
 >> iter 65000, loss: 0.177552
 >> iter 66000, loss: 0.148420
 >> iter 67000, loss: 0.196810
 >> iter 68000, loss: 0.250924
 >> iter 69000, loss: 0.233731
 >> iter 70000, loss: 0.144411
   Number of active neurons: 6
 >> iter 71000, loss: 0.329173
 >> iter 72000, loss: 0.231756
 >> iter 73000, loss: 0.267603
 >> iter 74000, loss: 0.231287
 >> iter 75000, loss: 0.331892
 >> iter 76000, loss: 0.285964
 >> iter 77000, loss: 0.254744
 >> iter 78000, loss: 0.243125
 >> iter 79000, loss: 0.166210
 >> iter 80000, loss: 0.211097
   Number of active neurons: 5
 >> iter 81000, loss: 0.288387
 >> iter 82000, loss: 0.227391
 >> iter 83000, loss: 0.252932
 >> iter 84000, loss: 0.182706
 >> iter 85000, loss: 0.249159
 >> iter 86000, loss: 0.246010
 >> iter 87000, loss: 0.276910
 >> iter 88000, loss: 0.150075
 >> iter 89000, loss: 0.192885
 >> iter 90000, loss: 0.311354
   Number of active neurons: 5
 >> iter 91000, loss: 0.203750
 >> iter 92000, loss: 0.190585
 >> iter 93000, loss: 0.155657
 >> iter 94000, loss: 0.184707
 >> iter 95000, loss: 0.190432
 >> iter 96000, loss: 0.235190
 >> iter 97000, loss: 0.243172
 >> iter 98000, loss: 0.282949
 >> iter 99000, loss: 0.188181
 >> iter 100000, loss: 0.227393
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.019632
 >> iter 2000, loss: 10.030486
 >> iter 3000, loss: 5.941592
 >> iter 4000, loss: 3.490432
 >> iter 5000, loss: 2.307010
 >> iter 6000, loss: 1.625057
 >> iter 7000, loss: 1.258710
 >> iter 8000, loss: 0.828249
 >> iter 9000, loss: 0.749716
 >> iter 10000, loss: 0.757728
   Number of active neurons: 8
 >> iter 11000, loss: 0.842218
 >> iter 12000, loss: 0.697062
 >> iter 13000, loss: 0.655388
 >> iter 14000, loss: 0.841599
 >> iter 15000, loss: 0.740190
 >> iter 16000, loss: 1.007100
 >> iter 17000, loss: 0.784207
 >> iter 18000, loss: 0.789725
 >> iter 19000, loss: 0.613325
 >> iter 20000, loss: 0.814117
   Number of active neurons: 8
 >> iter 21000, loss: 0.695418
 >> iter 22000, loss: 0.561879
 >> iter 23000, loss: 0.549725
 >> iter 24000, loss: 0.574491
 >> iter 25000, loss: 0.517545
 >> iter 26000, loss: 0.376421
 >> iter 27000, loss: 0.521280
 >> iter 28000, loss: 0.402568
 >> iter 29000, loss: 0.389741
 >> iter 30000, loss: 0.422479
   Number of active neurons: 8
 >> iter 31000, loss: 0.415270
 >> iter 32000, loss: 0.483058
 >> iter 33000, loss: 0.547188
 >> iter 34000, loss: 0.514987
 >> iter 35000, loss: 0.477668
 >> iter 36000, loss: 0.420346
 >> iter 37000, loss: 0.359267
 >> iter 38000, loss: 0.391018
 >> iter 39000, loss: 0.373438
 >> iter 40000, loss: 0.462517
   Number of active neurons: 8
 >> iter 41000, loss: 0.598473
 >> iter 42000, loss: 0.586841
 >> iter 43000, loss: 0.601006
 >> iter 44000, loss: 0.439114
 >> iter 45000, loss: 0.441525
 >> iter 46000, loss: 0.461009
 >> iter 47000, loss: 0.463461
 >> iter 48000, loss: 0.531594
 >> iter 49000, loss: 0.588277
 >> iter 50000, loss: 0.441680
   Number of active neurons: 7
 >> iter 51000, loss: 0.526496
 >> iter 52000, loss: 0.572340
 >> iter 53000, loss: 0.438123
 >> iter 54000, loss: 0.407648
 >> iter 55000, loss: 0.497514
 >> iter 56000, loss: 0.384069
 >> iter 57000, loss: 0.429730
 >> iter 58000, loss: 0.549461
 >> iter 59000, loss: 0.664970
 >> iter 60000, loss: 0.515709
   Number of active neurons: 7
 >> iter 61000, loss: 0.472543
 >> iter 62000, loss: 0.358042
 >> iter 63000, loss: 0.489037
 >> iter 64000, loss: 0.472807
 >> iter 65000, loss: 0.472074
 >> iter 66000, loss: 0.470660
 >> iter 67000, loss: 0.488702
 >> iter 68000, loss: 0.579016
 >> iter 69000, loss: 0.528920
 >> iter 70000, loss: 0.479260
   Number of active neurons: 6
 >> iter 71000, loss: 0.449146
 >> iter 72000, loss: 0.782422
 >> iter 73000, loss: 0.819202
 >> iter 74000, loss: 0.801680
 >> iter 75000, loss: 0.811240
 >> iter 76000, loss: 0.706848
 >> iter 77000, loss: 0.623810
 >> iter 78000, loss: 0.624907
 >> iter 79000, loss: 0.475861
 >> iter 80000, loss: 0.518668
   Number of active neurons: 6
 >> iter 81000, loss: 0.525629
 >> iter 82000, loss: 0.457280
 >> iter 83000, loss: 0.665946
 >> iter 84000, loss: 0.619743
 >> iter 85000, loss: 0.465979
 >> iter 86000, loss: 0.549575
 >> iter 87000, loss: 0.554338
 >> iter 88000, loss: 0.563920
 >> iter 89000, loss: 0.458912
 >> iter 90000, loss: 0.533841
   Number of active neurons: 6
 >> iter 91000, loss: 0.492380
 >> iter 92000, loss: 0.464723
 >> iter 93000, loss: 0.690608
 >> iter 94000, loss: 0.599388
 >> iter 95000, loss: 0.607355
 >> iter 96000, loss: 0.607525
 >> iter 97000, loss: 0.511462
 >> iter 98000, loss: 0.438290
 >> iter 99000, loss: 0.339625
 >> iter 100000, loss: 0.405331
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.604419
 >> iter 2000, loss: 9.882023
 >> iter 3000, loss: 6.001908
 >> iter 4000, loss: 3.347553
 >> iter 5000, loss: 2.262067
 >> iter 6000, loss: 1.502688
 >> iter 7000, loss: 1.024226
 >> iter 8000, loss: 0.891369
 >> iter 9000, loss: 0.651623
 >> iter 10000, loss: 0.785301
   Number of active neurons: 9
 >> iter 11000, loss: 0.617033
 >> iter 12000, loss: 0.682325
 >> iter 13000, loss: 0.628162
 >> iter 14000, loss: 0.506330
 >> iter 15000, loss: 0.405434
 >> iter 16000, loss: 0.357083
 >> iter 17000, loss: 0.474045
 >> iter 18000, loss: 0.488768
 >> iter 19000, loss: 0.486624
 >> iter 20000, loss: 0.455129
   Number of active neurons: 9
 >> iter 21000, loss: 0.494542
 >> iter 22000, loss: 0.352428
 >> iter 23000, loss: 0.419025
 >> iter 24000, loss: 0.311889
 >> iter 25000, loss: 0.457178
 >> iter 26000, loss: 0.439689
 >> iter 27000, loss: 0.543878
 >> iter 28000, loss: 0.464461
 >> iter 29000, loss: 0.387403
 >> iter 30000, loss: 0.356603
   Number of active neurons: 8
 >> iter 31000, loss: 0.434343
 >> iter 32000, loss: 0.383450
 >> iter 33000, loss: 0.325270
 >> iter 34000, loss: 0.388607
 >> iter 35000, loss: 0.339353
 >> iter 36000, loss: 0.279150
 >> iter 37000, loss: 0.457083
 >> iter 38000, loss: 0.475985
 >> iter 39000, loss: 0.523937
 >> iter 40000, loss: 0.529414
   Number of active neurons: 8
 >> iter 41000, loss: 0.396417
 >> iter 42000, loss: 0.360292
 >> iter 43000, loss: 0.360784
 >> iter 44000, loss: 0.433456
 >> iter 45000, loss: 0.455598
 >> iter 46000, loss: 0.458987
 >> iter 47000, loss: 0.489050
 >> iter 48000, loss: 0.494851
 >> iter 49000, loss: 0.606315
 >> iter 50000, loss: 0.634853
   Number of active neurons: 7
 >> iter 51000, loss: 0.578901
 >> iter 52000, loss: 0.584791
 >> iter 53000, loss: 0.472144
 >> iter 54000, loss: 0.489171
 >> iter 55000, loss: 0.523473
 >> iter 56000, loss: 0.512300
 >> iter 57000, loss: 0.539761
 >> iter 58000, loss: 0.533302
 >> iter 59000, loss: 0.545155
 >> iter 60000, loss: 0.666409
   Number of active neurons: 6
 >> iter 61000, loss: 0.729687
 >> iter 62000, loss: 0.691534
 >> iter 63000, loss: 0.621638
 >> iter 64000, loss: 0.686185
 >> iter 65000, loss: 0.628098
 >> iter 66000, loss: 0.464090
 >> iter 67000, loss: 0.493947
 >> iter 68000, loss: 0.473800
 >> iter 69000, loss: 0.512250
 >> iter 70000, loss: 0.703321
   Number of active neurons: 6
 >> iter 71000, loss: 0.752360
 >> iter 72000, loss: 0.550989
 >> iter 73000, loss: 0.525746
 >> iter 74000, loss: 0.463912
 >> iter 75000, loss: 0.522922
 >> iter 76000, loss: 0.516118
 >> iter 77000, loss: 0.524328
 >> iter 78000, loss: 0.691975
 >> iter 79000, loss: 0.634028
 >> iter 80000, loss: 0.566315
   Number of active neurons: 6
 >> iter 81000, loss: 0.557771
 >> iter 82000, loss: 0.499995
 >> iter 83000, loss: 0.387093
 >> iter 84000, loss: 0.509659
 >> iter 85000, loss: 0.669443
 >> iter 86000, loss: 0.591342
 >> iter 87000, loss: 0.598012
 >> iter 88000, loss: 0.602730
 >> iter 89000, loss: 0.594356
 >> iter 90000, loss: 0.607207
   Number of active neurons: 6
 >> iter 91000, loss: 0.521713
 >> iter 92000, loss: 0.504081
 >> iter 93000, loss: 0.447726
 >> iter 94000, loss: 0.452575
 >> iter 95000, loss: 0.411632
 >> iter 96000, loss: 0.414411
 >> iter 97000, loss: 0.557003
 >> iter 98000, loss: 0.588753
 >> iter 99000, loss: 0.585136
 >> iter 100000, loss: 0.640824
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.00599988000241
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 24.4117058863
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.715917
 >> iter 2000, loss: 8.975711
 >> iter 3000, loss: 5.159477
 >> iter 4000, loss: 3.250302
 >> iter 5000, loss: 2.098922
 >> iter 6000, loss: 1.389818
 >> iter 7000, loss: 1.016138
 >> iter 8000, loss: 1.001901
 >> iter 9000, loss: 0.676233
 >> iter 10000, loss: 0.486953
   Number of active neurons: 6
 >> iter 11000, loss: 0.682859
 >> iter 12000, loss: 0.567496
 >> iter 13000, loss: 0.605780
 >> iter 14000, loss: 0.573754
 >> iter 15000, loss: 0.495612
 >> iter 16000, loss: 0.400840
 >> iter 17000, loss: 0.415991
 >> iter 18000, loss: 0.382849
 >> iter 19000, loss: 0.445717
 >> iter 20000, loss: 0.481614
   Number of active neurons: 6
 >> iter 21000, loss: 0.514831
 >> iter 22000, loss: 0.380382
 >> iter 23000, loss: 0.420427
 >> iter 24000, loss: 0.364182
 >> iter 25000, loss: 0.329834
 >> iter 26000, loss: 0.266830
 >> iter 27000, loss: 0.486042
 >> iter 28000, loss: 0.561621
 >> iter 29000, loss: 0.719936
 >> iter 30000, loss: 0.597209
   Number of active neurons: 6
 >> iter 31000, loss: 0.426857
 >> iter 32000, loss: 0.403072
 >> iter 33000, loss: 0.403074
 >> iter 34000, loss: 0.332462
 >> iter 35000, loss: 0.652242
 >> iter 36000, loss: 0.448108
 >> iter 37000, loss: 0.497648
 >> iter 38000, loss: 0.392152
 >> iter 39000, loss: 0.276617
 >> iter 40000, loss: 0.402477
   Number of active neurons: 6
 >> iter 41000, loss: 0.313957
 >> iter 42000, loss: 0.454335
 >> iter 43000, loss: 0.527326
 >> iter 44000, loss: 0.458338
 >> iter 45000, loss: 0.616411
 >> iter 46000, loss: 0.549142
 >> iter 47000, loss: 0.754545
 >> iter 48000, loss: 0.544173
 >> iter 49000, loss: 0.553495
 >> iter 50000, loss: 0.533673
   Number of active neurons: 6
 >> iter 51000, loss: 0.632963
 >> iter 52000, loss: 0.482497
 >> iter 53000, loss: 0.483236
 >> iter 54000, loss: 0.558830
 >> iter 55000, loss: 0.512440
 >> iter 56000, loss: 0.575731
 >> iter 57000, loss: 0.456740
 >> iter 58000, loss: 0.493184
 >> iter 59000, loss: 0.531342
 >> iter 60000, loss: 0.519234
   Number of active neurons: 6
 >> iter 61000, loss: 0.431232
 >> iter 62000, loss: 0.346797
 >> iter 63000, loss: 0.575014
 >> iter 64000, loss: 0.551204
 >> iter 65000, loss: 0.378891
 >> iter 66000, loss: 0.414486
 >> iter 67000, loss: 0.378567
 >> iter 68000, loss: 0.411166
 >> iter 69000, loss: 0.490463
 >> iter 70000, loss: 0.545791
   Number of active neurons: 6
 >> iter 71000, loss: 0.646955
 >> iter 72000, loss: 0.452125
 >> iter 73000, loss: 0.535490
 >> iter 74000, loss: 0.497503
 >> iter 75000, loss: 0.418285
 >> iter 76000, loss: 0.493234
 >> iter 77000, loss: 0.610540
 >> iter 78000, loss: 0.464160
 >> iter 79000, loss: 0.630248
 >> iter 80000, loss: 0.556768
   Number of active neurons: 5
 >> iter 81000, loss: 0.614812
 >> iter 82000, loss: 0.451990
 >> iter 83000, loss: 0.504788
 >> iter 84000, loss: 0.533032
 >> iter 85000, loss: 0.382361
 >> iter 86000, loss: 0.520849
 >> iter 87000, loss: 0.539235
 >> iter 88000, loss: 0.557384
 >> iter 89000, loss: 0.609726
 >> iter 90000, loss: 0.601414
   Number of active neurons: 7
 >> iter 91000, loss: 0.516522
 >> iter 92000, loss: 0.693356
 >> iter 93000, loss: 0.562670
 >> iter 94000, loss: 0.502659
 >> iter 95000, loss: 0.970831
 >> iter 96000, loss: 0.942786
 >> iter 97000, loss: 0.688344
 >> iter 98000, loss: 0.490690
 >> iter 99000, loss: 0.505056
 >> iter 100000, loss: 0.501984
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.154965
 >> iter 2000, loss: 9.505012
 >> iter 3000, loss: 5.351953
 >> iter 4000, loss: 3.073216
 >> iter 5000, loss: 1.685356
 >> iter 6000, loss: 0.969460
 >> iter 7000, loss: 0.801501
 >> iter 8000, loss: 0.620650
 >> iter 9000, loss: 0.470718
 >> iter 10000, loss: 0.609465
   Number of active neurons: 7
 >> iter 11000, loss: 0.656535
 >> iter 12000, loss: 0.478237
 >> iter 13000, loss: 0.431117
 >> iter 14000, loss: 0.363335
 >> iter 15000, loss: 0.404750
 >> iter 16000, loss: 0.464531
 >> iter 17000, loss: 0.603155
 >> iter 18000, loss: 0.402566
 >> iter 19000, loss: 0.421760
 >> iter 20000, loss: 0.508995
   Number of active neurons: 7
 >> iter 21000, loss: 0.454248
 >> iter 22000, loss: 0.564187
 >> iter 23000, loss: 0.577633
 >> iter 24000, loss: 0.369501
 >> iter 25000, loss: 0.485538
 >> iter 26000, loss: 0.343024
 >> iter 27000, loss: 0.432491
 >> iter 28000, loss: 0.374945
 >> iter 29000, loss: 0.356225
 >> iter 30000, loss: 0.447986
   Number of active neurons: 7
 >> iter 31000, loss: 0.462766
 >> iter 32000, loss: 0.596180
 >> iter 33000, loss: 0.701218
 >> iter 34000, loss: 0.435459
 >> iter 35000, loss: 0.662023
 >> iter 36000, loss: 0.546597
 >> iter 37000, loss: 0.511527
 >> iter 38000, loss: 0.442889
 >> iter 39000, loss: 0.380363
 >> iter 40000, loss: 0.326320
   Number of active neurons: 7
 >> iter 41000, loss: 0.343295
 >> iter 42000, loss: 0.429175
 >> iter 43000, loss: 0.295515
 >> iter 44000, loss: 0.302728
 >> iter 45000, loss: 0.308781
 >> iter 46000, loss: 0.361535
 >> iter 47000, loss: 0.267661
 >> iter 48000, loss: 0.244785
 >> iter 49000, loss: 0.366272
 >> iter 50000, loss: 0.400023
   Number of active neurons: 7
 >> iter 51000, loss: 0.474919
 >> iter 52000, loss: 0.425421
 >> iter 53000, loss: 0.527680
 >> iter 54000, loss: 0.471466
 >> iter 55000, loss: 0.469297
 >> iter 56000, loss: 0.354812
 >> iter 57000, loss: 0.352721
 >> iter 58000, loss: 0.289997
 >> iter 59000, loss: 0.362770
 >> iter 60000, loss: 0.389565
   Number of active neurons: 7
 >> iter 61000, loss: 0.395761
 >> iter 62000, loss: 0.377824
 >> iter 63000, loss: 0.475040
 >> iter 64000, loss: 0.522401
 >> iter 65000, loss: 0.448226
 >> iter 66000, loss: 0.366899
 >> iter 67000, loss: 0.575672
 >> iter 68000, loss: 0.497972
 >> iter 69000, loss: 0.400733
 >> iter 70000, loss: 0.501320
   Number of active neurons: 6
 >> iter 71000, loss: 0.578775
 >> iter 72000, loss: 0.470408
 >> iter 73000, loss: 0.514580
 >> iter 74000, loss: 0.393305
 >> iter 75000, loss: 0.334984
 >> iter 76000, loss: 0.259510
 >> iter 77000, loss: 0.328425
 >> iter 78000, loss: 0.440833
 >> iter 79000, loss: 0.345915
 >> iter 80000, loss: 0.338122
   Number of active neurons: 6
 >> iter 81000, loss: 0.419447
 >> iter 82000, loss: 0.474981
 >> iter 83000, loss: 0.464058
 >> iter 84000, loss: 0.501085
 >> iter 85000, loss: 0.484511
 >> iter 86000, loss: 0.514645
 >> iter 87000, loss: 0.540746
 >> iter 88000, loss: 0.511075
 >> iter 89000, loss: 0.558615
 >> iter 90000, loss: 0.490335
   Number of active neurons: 5
 >> iter 91000, loss: 0.411768
 >> iter 92000, loss: 0.416481
 >> iter 93000, loss: 0.417275
 >> iter 94000, loss: 0.377066
 >> iter 95000, loss: 0.520293
 >> iter 96000, loss: 0.399836
 >> iter 97000, loss: 0.366408
 >> iter 98000, loss: 0.411079
 >> iter 99000, loss: 0.418211
 >> iter 100000, loss: 0.488575
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.832844
 >> iter 2000, loss: 9.665942
 >> iter 3000, loss: 5.647995
 >> iter 4000, loss: 3.263000
 >> iter 5000, loss: 2.167586
 >> iter 6000, loss: 1.524303
 >> iter 7000, loss: 1.057220
 >> iter 8000, loss: 0.808185
 >> iter 9000, loss: 0.818881
 >> iter 10000, loss: 0.694544
   Number of active neurons: 9
 >> iter 11000, loss: 0.532591
 >> iter 12000, loss: 0.601814
 >> iter 13000, loss: 0.470894
 >> iter 14000, loss: 0.586676
 >> iter 15000, loss: 0.510302
 >> iter 16000, loss: 0.377835
 >> iter 17000, loss: 0.433098
 >> iter 18000, loss: 0.428637
 >> iter 19000, loss: 0.431357
 >> iter 20000, loss: 0.442490
   Number of active neurons: 8
 >> iter 21000, loss: 0.505400
 >> iter 22000, loss: 0.415141
 >> iter 23000, loss: 0.352000
 >> iter 24000, loss: 0.412866
 >> iter 25000, loss: 0.514882
 >> iter 26000, loss: 0.363447
 >> iter 27000, loss: 0.351174
 >> iter 28000, loss: 0.341945
 >> iter 29000, loss: 0.287569
 >> iter 30000, loss: 0.305886
   Number of active neurons: 8
 >> iter 31000, loss: 0.384318
 >> iter 32000, loss: 0.371827
 >> iter 33000, loss: 0.469199
 >> iter 34000, loss: 0.431669
 >> iter 35000, loss: 0.397490
 >> iter 36000, loss: 0.512778
 >> iter 37000, loss: 0.437015
 >> iter 38000, loss: 0.374376
 >> iter 39000, loss: 0.375676
 >> iter 40000, loss: 0.414144
   Number of active neurons: 8
 >> iter 41000, loss: 0.485599
 >> iter 42000, loss: 0.424237
 >> iter 43000, loss: 0.330182
 >> iter 44000, loss: 0.409027
 >> iter 45000, loss: 0.458095
 >> iter 46000, loss: 0.487542
 >> iter 47000, loss: 0.529787
 >> iter 48000, loss: 0.443511
 >> iter 49000, loss: 0.380326
 >> iter 50000, loss: 0.472205
   Number of active neurons: 8
 >> iter 51000, loss: 0.465959
 >> iter 52000, loss: 0.399879
 >> iter 53000, loss: 0.557155
 >> iter 54000, loss: 0.486203
 >> iter 55000, loss: 0.400347
 >> iter 56000, loss: 0.642593
 >> iter 57000, loss: 0.483219
 >> iter 58000, loss: 0.425198
 >> iter 59000, loss: 0.435667
 >> iter 60000, loss: 0.364465
   Number of active neurons: 7
 >> iter 61000, loss: 0.439882
 >> iter 62000, loss: 0.400681
 >> iter 63000, loss: 0.542083
 >> iter 64000, loss: 0.541391
 >> iter 65000, loss: 0.571785
 >> iter 66000, loss: 0.509388
 >> iter 67000, loss: 0.468594
 >> iter 68000, loss: 0.430038
 >> iter 69000, loss: 0.430810
 >> iter 70000, loss: 0.549727
   Number of active neurons: 7
 >> iter 71000, loss: 0.625326
 >> iter 72000, loss: 0.612625
 >> iter 73000, loss: 0.499761
 >> iter 74000, loss: 0.363064
 >> iter 75000, loss: 0.361140
 >> iter 76000, loss: 0.393187
 >> iter 77000, loss: 0.406669
 >> iter 78000, loss: 0.435704
 >> iter 79000, loss: 0.522572
 >> iter 80000, loss: 0.511969
   Number of active neurons: 7
 >> iter 81000, loss: 0.549145
 >> iter 82000, loss: 0.495645
 >> iter 83000, loss: 0.322026
 >> iter 84000, loss: 0.327171
 >> iter 85000, loss: 0.423637
 >> iter 86000, loss: 0.331794
 >> iter 87000, loss: 0.522343
 >> iter 88000, loss: 0.427453
 >> iter 89000, loss: 0.359365
 >> iter 90000, loss: 0.483939
   Number of active neurons: 6
 >> iter 91000, loss: 0.392529
 >> iter 92000, loss: 0.538245
 >> iter 93000, loss: 0.456051
 >> iter 94000, loss: 0.455616
 >> iter 95000, loss: 0.553892
 >> iter 96000, loss: 0.461975
 >> iter 97000, loss: 0.390593
 >> iter 98000, loss: 0.326930
 >> iter 99000, loss: 0.367720
 >> iter 100000, loss: 0.394235
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455163
   Number of active neurons: 0
 >> iter 1000, loss: 16.847660
 >> iter 2000, loss: 10.343144
 >> iter 3000, loss: 6.497949
 >> iter 4000, loss: 3.030708
 >> iter 5000, loss: 1.313611
 >> iter 6000, loss: 0.790467
 >> iter 7000, loss: 0.626053
 >> iter 8000, loss: 0.551278
 >> iter 9000, loss: 0.459634
 >> iter 10000, loss: 0.425461
   Number of active neurons: 12
 >> iter 11000, loss: 0.461143
 >> iter 12000, loss: 0.374653
 >> iter 13000, loss: 0.473993
 >> iter 14000, loss: 0.318800
 >> iter 15000, loss: 0.348912
 >> iter 16000, loss: 0.378972
 >> iter 17000, loss: 0.402040
 >> iter 18000, loss: 0.401948
 >> iter 19000, loss: 0.381356
 >> iter 20000, loss: 0.530007
   Number of active neurons: 12
 >> iter 21000, loss: 0.387445
 >> iter 22000, loss: 0.423233
 >> iter 23000, loss: 0.366311
 >> iter 24000, loss: 0.379271
 >> iter 25000, loss: 0.408028
 >> iter 26000, loss: 0.435598
 >> iter 27000, loss: 0.364430
 >> iter 28000, loss: 0.286285
 >> iter 29000, loss: 0.341776
 >> iter 30000, loss: 0.421542
   Number of active neurons: 11
 >> iter 31000, loss: 0.428699
 >> iter 32000, loss: 0.392790
 >> iter 33000, loss: 0.435912
 >> iter 34000, loss: 0.425475
 >> iter 35000, loss: 0.451002
 >> iter 36000, loss: 0.333465
 >> iter 37000, loss: 0.272295
 >> iter 38000, loss: 0.436749
 >> iter 39000, loss: 0.332074
 >> iter 40000, loss: 0.370692
   Number of active neurons: 11
 >> iter 41000, loss: 0.298006
 >> iter 42000, loss: 0.336859
 >> iter 43000, loss: 0.393211
 >> iter 44000, loss: 0.339388
 >> iter 45000, loss: 0.385850
 >> iter 46000, loss: 0.404017
 >> iter 47000, loss: 0.347745
 >> iter 48000, loss: 0.370250
 >> iter 49000, loss: 0.287955
 >> iter 50000, loss: 0.425471
   Number of active neurons: 10
 >> iter 51000, loss: 0.304344
 >> iter 52000, loss: 0.317223
 >> iter 53000, loss: 0.383589
 >> iter 54000, loss: 0.377950
 >> iter 55000, loss: 0.476451
 >> iter 56000, loss: 0.339855
 >> iter 57000, loss: 0.421597
 >> iter 58000, loss: 0.436627
 >> iter 59000, loss: 0.419848
 >> iter 60000, loss: 0.248731
   Number of active neurons: 10
 >> iter 61000, loss: 0.393417
 >> iter 62000, loss: 0.440680
 >> iter 63000, loss: 0.361461
 >> iter 64000, loss: 0.285865
 >> iter 65000, loss: 0.341803
 >> iter 66000, loss: 0.335673
 >> iter 67000, loss: 0.428199
 >> iter 68000, loss: 0.347589
 >> iter 69000, loss: 0.271204
 >> iter 70000, loss: 0.240957
   Number of active neurons: 9
 >> iter 71000, loss: 0.269673
 >> iter 72000, loss: 0.318785
 >> iter 73000, loss: 0.357791
 >> iter 74000, loss: 0.398704
 >> iter 75000, loss: 0.342135
 >> iter 76000, loss: 0.388161
 >> iter 77000, loss: 0.319007
 >> iter 78000, loss: 0.368770
 >> iter 79000, loss: 0.299631
 >> iter 80000, loss: 0.360434
   Number of active neurons: 9
 >> iter 81000, loss: 0.312245
 >> iter 82000, loss: 0.214225
 >> iter 83000, loss: 0.224723
 >> iter 84000, loss: 0.319818
 >> iter 85000, loss: 0.301424
 >> iter 86000, loss: 0.282350
 >> iter 87000, loss: 0.262576
 >> iter 88000, loss: 0.423302
 >> iter 89000, loss: 0.320231
 >> iter 90000, loss: 0.446394
   Number of active neurons: 9
 >> iter 91000, loss: 0.395527
 >> iter 92000, loss: 0.437983
 >> iter 93000, loss: 0.265503
 >> iter 94000, loss: 0.362417
 >> iter 95000, loss: 0.312672
 >> iter 96000, loss: 0.362288
 >> iter 97000, loss: 0.420733
 >> iter 98000, loss: 0.373446
 >> iter 99000, loss: 0.253602
 >> iter 100000, loss: 0.216109
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.239401
 >> iter 2000, loss: 10.309382
 >> iter 3000, loss: 5.880971
 >> iter 4000, loss: 3.093449
 >> iter 5000, loss: 1.900653
 >> iter 6000, loss: 1.283938
 >> iter 7000, loss: 1.053895
 >> iter 8000, loss: 0.912043
 >> iter 9000, loss: 0.627339
 >> iter 10000, loss: 0.505954
   Number of active neurons: 5
 >> iter 11000, loss: 0.566093
 >> iter 12000, loss: 0.514811
 >> iter 13000, loss: 0.648323
 >> iter 14000, loss: 0.738061
 >> iter 15000, loss: 0.527005
 >> iter 16000, loss: 0.370438
 >> iter 17000, loss: 0.464875
 >> iter 18000, loss: 0.409059
 >> iter 19000, loss: 0.501372
 >> iter 20000, loss: 0.524775
   Number of active neurons: 5
 >> iter 21000, loss: 0.497158
 >> iter 22000, loss: 0.413085
 >> iter 23000, loss: 0.359364
 >> iter 24000, loss: 0.266602
 >> iter 25000, loss: 0.301020
 >> iter 26000, loss: 0.376229
 >> iter 27000, loss: 0.476773
 >> iter 28000, loss: 0.409307
 >> iter 29000, loss: 0.414794
 >> iter 30000, loss: 0.428627
   Number of active neurons: 5
 >> iter 31000, loss: 0.375963
 >> iter 32000, loss: 0.388885
 >> iter 33000, loss: 0.442946
 >> iter 34000, loss: 0.500926
 >> iter 35000, loss: 0.464447
 >> iter 36000, loss: 0.404099
 >> iter 37000, loss: 0.550688
 >> iter 38000, loss: 0.433659
 >> iter 39000, loss: 0.457347
 >> iter 40000, loss: 0.464305
   Number of active neurons: 5
 >> iter 41000, loss: 0.407030
 >> iter 42000, loss: 0.471987
 >> iter 43000, loss: 0.417542
 >> iter 44000, loss: 0.352943
 >> iter 45000, loss: 0.436601
 >> iter 46000, loss: 0.461740
 >> iter 47000, loss: 0.463499
 >> iter 48000, loss: 0.482897
 >> iter 49000, loss: 0.339739
 >> iter 50000, loss: 0.390152
   Number of active neurons: 5
 >> iter 51000, loss: 0.399060
 >> iter 52000, loss: 0.327265
 >> iter 53000, loss: 0.449955
 >> iter 54000, loss: 0.496114
 >> iter 55000, loss: 0.415997
 >> iter 56000, loss: 0.442154
 >> iter 57000, loss: 0.466074
 >> iter 58000, loss: 0.358381
 >> iter 59000, loss: 0.280575
 >> iter 60000, loss: 0.294316
   Number of active neurons: 5
 >> iter 61000, loss: 0.374736
 >> iter 62000, loss: 0.273135
 >> iter 63000, loss: 0.423934
 >> iter 64000, loss: 0.341008
 >> iter 65000, loss: 0.509125
 >> iter 66000, loss: 0.294861
 >> iter 67000, loss: 0.326138
 >> iter 68000, loss: 0.304395
 >> iter 69000, loss: 0.392650
 >> iter 70000, loss: 0.509157
   Number of active neurons: 5
 >> iter 71000, loss: 0.494713
 >> iter 72000, loss: 0.404696
 >> iter 73000, loss: 0.360559
 >> iter 74000, loss: 0.368895
 >> iter 75000, loss: 0.359585
 >> iter 76000, loss: 0.342460
 >> iter 77000, loss: 0.439022
 >> iter 78000, loss: 0.339264
 >> iter 79000, loss: 0.341761
 >> iter 80000, loss: 0.330414
   Number of active neurons: 5
 >> iter 81000, loss: 0.319703
 >> iter 82000, loss: 0.323105
 >> iter 83000, loss: 0.378430
 >> iter 84000, loss: 0.244160
 >> iter 85000, loss: 0.328656
 >> iter 86000, loss: 0.452428
 >> iter 87000, loss: 0.449541
 >> iter 88000, loss: 0.446786
 >> iter 89000, loss: 0.331238
 >> iter 90000, loss: 0.251099
   Number of active neurons: 5
 >> iter 91000, loss: 0.257816
 >> iter 92000, loss: 0.366479
 >> iter 93000, loss: 0.490796
 >> iter 94000, loss: 0.365166
 >> iter 95000, loss: 0.383808
 >> iter 96000, loss: 0.331782
 >> iter 97000, loss: 0.347197
 >> iter 98000, loss: 0.646329
 >> iter 99000, loss: 0.478049
 >> iter 100000, loss: 0.394571
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.293460
 >> iter 2000, loss: 10.061503
 >> iter 3000, loss: 5.587271
 >> iter 4000, loss: 2.904026
 >> iter 5000, loss: 1.484447
 >> iter 6000, loss: 0.784326
 >> iter 7000, loss: 0.563119
 >> iter 8000, loss: 0.429526
 >> iter 9000, loss: 0.234439
 >> iter 10000, loss: 0.141813
   Number of active neurons: 6
 >> iter 11000, loss: 0.315168
 >> iter 12000, loss: 0.373306
 >> iter 13000, loss: 0.371303
 >> iter 14000, loss: 0.356574
 >> iter 15000, loss: 0.324785
 >> iter 16000, loss: 0.321868
 >> iter 17000, loss: 0.279790
 >> iter 18000, loss: 0.250389
 >> iter 19000, loss: 0.214661
 >> iter 20000, loss: 0.293769
   Number of active neurons: 6
 >> iter 21000, loss: 0.351047
 >> iter 22000, loss: 0.224170
 >> iter 23000, loss: 0.176219
 >> iter 24000, loss: 0.196836
 >> iter 25000, loss: 0.298347
 >> iter 26000, loss: 0.275727
 >> iter 27000, loss: 0.251413
 >> iter 28000, loss: 0.258403
 >> iter 29000, loss: 0.220215
 >> iter 30000, loss: 0.225037
   Number of active neurons: 6
 >> iter 31000, loss: 0.287895
 >> iter 32000, loss: 0.316633
 >> iter 33000, loss: 0.354316
 >> iter 34000, loss: 0.273162
 >> iter 35000, loss: 0.242555
 >> iter 36000, loss: 0.172896
 >> iter 37000, loss: 0.219128
 >> iter 38000, loss: 0.160844
 >> iter 39000, loss: 0.294438
 >> iter 40000, loss: 0.284308
   Number of active neurons: 4
 >> iter 41000, loss: 0.254143
 >> iter 42000, loss: 0.235441
 >> iter 43000, loss: 0.299387
 >> iter 44000, loss: 0.396138
 >> iter 45000, loss: 0.283599
 >> iter 46000, loss: 0.301642
 >> iter 47000, loss: 0.299114
 >> iter 48000, loss: 0.229090
 >> iter 49000, loss: 0.227998
 >> iter 50000, loss: 0.252311
   Number of active neurons: 4
 >> iter 51000, loss: 0.207099
 >> iter 52000, loss: 0.325967
 >> iter 53000, loss: 0.341366
 >> iter 54000, loss: 0.276439
 >> iter 55000, loss: 0.253892
 >> iter 56000, loss: 0.333598
 >> iter 57000, loss: 0.350414
 >> iter 58000, loss: 0.416877
 >> iter 59000, loss: 0.299952
 >> iter 60000, loss: 0.401019
   Number of active neurons: 4
 >> iter 61000, loss: 0.362548
 >> iter 62000, loss: 0.404233
 >> iter 63000, loss: 0.276774
 >> iter 64000, loss: 0.238503
 >> iter 65000, loss: 0.287672
 >> iter 66000, loss: 0.319451
 >> iter 67000, loss: 0.250009
 >> iter 68000, loss: 0.274845
 >> iter 69000, loss: 0.321548
 >> iter 70000, loss: 0.420970
   Number of active neurons: 4
 >> iter 71000, loss: 0.356390
 >> iter 72000, loss: 0.299695
 >> iter 73000, loss: 0.305170
 >> iter 74000, loss: 0.218407
 >> iter 75000, loss: 0.230932
 >> iter 76000, loss: 0.182716
 >> iter 77000, loss: 0.201573
 >> iter 78000, loss: 0.377171
 >> iter 79000, loss: 0.327723
 >> iter 80000, loss: 0.255081
   Number of active neurons: 4
 >> iter 81000, loss: 0.274036
 >> iter 82000, loss: 0.309240
 >> iter 83000, loss: 0.329591
 >> iter 84000, loss: 0.257362
 >> iter 85000, loss: 0.233264
 >> iter 86000, loss: 0.285888
 >> iter 87000, loss: 0.262382
 >> iter 88000, loss: 0.251877
 >> iter 89000, loss: 0.325371
 >> iter 90000, loss: 0.306719
   Number of active neurons: 4
 >> iter 91000, loss: 0.309475
 >> iter 92000, loss: 0.193831
 >> iter 93000, loss: 0.342382
 >> iter 94000, loss: 0.233809
 >> iter 95000, loss: 0.376280
 >> iter 96000, loss: 0.235436
 >> iter 97000, loss: 0.205632
 >> iter 98000, loss: 0.294826
 >> iter 99000, loss: 0.292086
 >> iter 100000, loss: 0.252956
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.882490
 >> iter 2000, loss: 9.337002
 >> iter 3000, loss: 4.640812
 >> iter 4000, loss: 2.209654
 >> iter 5000, loss: 1.259033
 >> iter 6000, loss: 0.784336
 >> iter 7000, loss: 0.561805
 >> iter 8000, loss: 0.397123
 >> iter 9000, loss: 0.313209
 >> iter 10000, loss: 0.328632
   Number of active neurons: 6
 >> iter 11000, loss: 0.436301
 >> iter 12000, loss: 0.309587
 >> iter 13000, loss: 0.261925
 >> iter 14000, loss: 0.335317
 >> iter 15000, loss: 0.276878
 >> iter 16000, loss: 0.240832
 >> iter 17000, loss: 0.234505
 >> iter 18000, loss: 0.274578
 >> iter 19000, loss: 0.211524
 >> iter 20000, loss: 0.276118
   Number of active neurons: 6
 >> iter 21000, loss: 0.279508
 >> iter 22000, loss: 0.337452
 >> iter 23000, loss: 0.270164
 >> iter 24000, loss: 0.182674
 >> iter 25000, loss: 0.265909
 >> iter 26000, loss: 0.237738
 >> iter 27000, loss: 0.262031
 >> iter 28000, loss: 0.198656
 >> iter 29000, loss: 0.172506
 >> iter 30000, loss: 0.220270
   Number of active neurons: 6
 >> iter 31000, loss: 0.182034
 >> iter 32000, loss: 0.286935
 >> iter 33000, loss: 0.268536
 >> iter 34000, loss: 0.215039
 >> iter 35000, loss: 0.236462
 >> iter 36000, loss: 0.224877
 >> iter 37000, loss: 0.210758
 >> iter 38000, loss: 0.199170
 >> iter 39000, loss: 0.130438
 >> iter 40000, loss: 0.131360
   Number of active neurons: 6
 >> iter 41000, loss: 0.215672
 >> iter 42000, loss: 0.146084
 >> iter 43000, loss: 0.169020
 >> iter 44000, loss: 0.179135
 >> iter 45000, loss: 0.267108
 >> iter 46000, loss: 0.229196
 >> iter 47000, loss: 0.260032
 >> iter 48000, loss: 0.220322
 >> iter 49000, loss: 0.205166
 >> iter 50000, loss: 0.194881
   Number of active neurons: 5
 >> iter 51000, loss: 0.299847
 >> iter 52000, loss: 0.243250
 >> iter 53000, loss: 0.267161
 >> iter 54000, loss: 0.212578
 >> iter 55000, loss: 0.253599
 >> iter 56000, loss: 0.240868
 >> iter 57000, loss: 0.240429
 >> iter 58000, loss: 0.254464
 >> iter 59000, loss: 0.271930
 >> iter 60000, loss: 0.237212
   Number of active neurons: 5
 >> iter 61000, loss: 0.279876
 >> iter 62000, loss: 0.302451
 >> iter 63000, loss: 0.253072
 >> iter 64000, loss: 0.181018
 >> iter 65000, loss: 0.290757
 >> iter 66000, loss: 0.209241
 >> iter 67000, loss: 0.319804
 >> iter 68000, loss: 0.229744
 >> iter 69000, loss: 0.204017
 >> iter 70000, loss: 0.244978
   Number of active neurons: 5
 >> iter 71000, loss: 0.308561
 >> iter 72000, loss: 0.199537
 >> iter 73000, loss: 0.201207
 >> iter 74000, loss: 0.211938
 >> iter 75000, loss: 0.146588
 >> iter 76000, loss: 0.180158
 >> iter 77000, loss: 0.197488
 >> iter 78000, loss: 0.241002
 >> iter 79000, loss: 0.167583
 >> iter 80000, loss: 0.177207
   Number of active neurons: 5
 >> iter 81000, loss: 0.178564
 >> iter 82000, loss: 0.245122
 >> iter 83000, loss: 0.173121
 >> iter 84000, loss: 0.230440
 >> iter 85000, loss: 0.353223
 >> iter 86000, loss: 0.256403
 >> iter 87000, loss: 0.199194
 >> iter 88000, loss: 0.247657
 >> iter 89000, loss: 0.237562
 >> iter 90000, loss: 0.142370
   Number of active neurons: 5
 >> iter 91000, loss: 0.176414
 >> iter 92000, loss: 0.149875
 >> iter 93000, loss: 0.248997
 >> iter 94000, loss: 0.258267
 >> iter 95000, loss: 0.197137
 >> iter 96000, loss: 0.251945
 >> iter 97000, loss: 0.206798
 >> iter 98000, loss: 0.261242
 >> iter 99000, loss: 0.202104
 >> iter 100000, loss: 0.161119
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.356845
 >> iter 2000, loss: 11.227405
 >> iter 3000, loss: 6.524805
 >> iter 4000, loss: 3.093143
 >> iter 5000, loss: 1.649121
 >> iter 6000, loss: 0.981621
 >> iter 7000, loss: 0.722668
 >> iter 8000, loss: 0.547653
 >> iter 9000, loss: 0.392663
 >> iter 10000, loss: 0.249215
   Number of active neurons: 4
 >> iter 11000, loss: 0.234255
 >> iter 12000, loss: 0.137109
 >> iter 13000, loss: 0.227656
 >> iter 14000, loss: 0.285185
 >> iter 15000, loss: 0.274647
 >> iter 16000, loss: 0.261329
 >> iter 17000, loss: 0.258768
 >> iter 18000, loss: 0.300227
 >> iter 19000, loss: 0.320301
 >> iter 20000, loss: 0.407896
   Number of active neurons: 4
 >> iter 21000, loss: 0.360327
 >> iter 22000, loss: 0.261606
 >> iter 23000, loss: 0.311130
 >> iter 24000, loss: 0.285460
 >> iter 25000, loss: 0.332361
 >> iter 26000, loss: 0.334353
 >> iter 27000, loss: 0.294643
 >> iter 28000, loss: 0.325142
 >> iter 29000, loss: 0.289243
 >> iter 30000, loss: 0.330538
   Number of active neurons: 4
 >> iter 31000, loss: 0.256289
 >> iter 32000, loss: 0.224261
 >> iter 33000, loss: 0.302703
 >> iter 34000, loss: 0.267131
 >> iter 35000, loss: 0.264176
 >> iter 36000, loss: 0.246228
 >> iter 37000, loss: 0.249611
 >> iter 38000, loss: 0.199417
 >> iter 39000, loss: 0.311835
 >> iter 40000, loss: 0.273056
   Number of active neurons: 4
 >> iter 41000, loss: 0.270552
 >> iter 42000, loss: 0.242065
 >> iter 43000, loss: 0.220311
 >> iter 44000, loss: 0.243361
 >> iter 45000, loss: 0.221030
 >> iter 46000, loss: 0.249835
 >> iter 47000, loss: 0.239834
 >> iter 48000, loss: 0.326760
 >> iter 49000, loss: 0.262673
 >> iter 50000, loss: 0.318572
   Number of active neurons: 4
 >> iter 51000, loss: 0.257442
 >> iter 52000, loss: 0.367064
 >> iter 53000, loss: 0.294706
 >> iter 54000, loss: 0.201945
 >> iter 55000, loss: 0.226665
 >> iter 56000, loss: 0.210550
 >> iter 57000, loss: 0.203620
 >> iter 58000, loss: 0.266716
 >> iter 59000, loss: 0.257508
 >> iter 60000, loss: 0.216272
   Number of active neurons: 4
 >> iter 61000, loss: 0.199716
 >> iter 62000, loss: 0.192127
 >> iter 63000, loss: 0.273236
 >> iter 64000, loss: 0.273348
 >> iter 65000, loss: 0.293352
 >> iter 66000, loss: 0.206893
 >> iter 67000, loss: 0.319072
 >> iter 68000, loss: 0.324178
 >> iter 69000, loss: 0.312392
 >> iter 70000, loss: 0.274750
   Number of active neurons: 4
 >> iter 71000, loss: 0.268213
 >> iter 72000, loss: 0.288879
 >> iter 73000, loss: 0.228143
 >> iter 74000, loss: 0.235990
 >> iter 75000, loss: 0.240771
 >> iter 76000, loss: 0.262033
 >> iter 77000, loss: 0.233985
 >> iter 78000, loss: 0.265705
 >> iter 79000, loss: 0.293508
 >> iter 80000, loss: 0.320508
   Number of active neurons: 4
 >> iter 81000, loss: 0.281996
 >> iter 82000, loss: 0.213855
 >> iter 83000, loss: 0.334532
 >> iter 84000, loss: 0.267099
 >> iter 85000, loss: 0.303911
 >> iter 86000, loss: 0.335258
 >> iter 87000, loss: 0.273033
 >> iter 88000, loss: 0.299399
 >> iter 89000, loss: 0.297431
 >> iter 90000, loss: 0.260597
   Number of active neurons: 4
 >> iter 91000, loss: 0.326894
 >> iter 92000, loss: 0.398515
 >> iter 93000, loss: 0.342375
 >> iter 94000, loss: 0.409992
 >> iter 95000, loss: 0.286951
 >> iter 96000, loss: 0.292721
 >> iter 97000, loss: 0.222820
 >> iter 98000, loss: 0.242695
 >> iter 99000, loss: 0.199837
 >> iter 100000, loss: 0.214108
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.914502
 >> iter 2000, loss: 9.085739
 >> iter 3000, loss: 4.381772
 >> iter 4000, loss: 2.403672
 >> iter 5000, loss: 1.335135
 >> iter 6000, loss: 0.729929
 >> iter 7000, loss: 0.718836
 >> iter 8000, loss: 0.528975
 >> iter 9000, loss: 0.518323
 >> iter 10000, loss: 0.334526
   Number of active neurons: 11
 >> iter 11000, loss: 0.428298
 >> iter 12000, loss: 0.368061
 >> iter 13000, loss: 0.360563
 >> iter 14000, loss: 0.377815
 >> iter 15000, loss: 0.340501
 >> iter 16000, loss: 0.285452
 >> iter 17000, loss: 0.310289
 >> iter 18000, loss: 0.391541
 >> iter 19000, loss: 0.399511
 >> iter 20000, loss: 0.355109
   Number of active neurons: 9
 >> iter 21000, loss: 0.366582
 >> iter 22000, loss: 0.404344
 >> iter 23000, loss: 0.291973
 >> iter 24000, loss: 0.287265
 >> iter 25000, loss: 0.388382
 >> iter 26000, loss: 0.336725
 >> iter 27000, loss: 0.280248
 >> iter 28000, loss: 0.218702
 >> iter 29000, loss: 0.271060
 >> iter 30000, loss: 0.254857
   Number of active neurons: 8
 >> iter 31000, loss: 0.291411
 >> iter 32000, loss: 0.254619
 >> iter 33000, loss: 0.271262
 >> iter 34000, loss: 0.308084
 >> iter 35000, loss: 0.358043
 >> iter 36000, loss: 0.441840
 >> iter 37000, loss: 0.335040
 >> iter 38000, loss: 0.322871
 >> iter 39000, loss: 0.293649
 >> iter 40000, loss: 0.318612
   Number of active neurons: 8
 >> iter 41000, loss: 0.297210
 >> iter 42000, loss: 0.280590
 >> iter 43000, loss: 0.409247
 >> iter 44000, loss: 0.357126
 >> iter 45000, loss: 0.311035
 >> iter 46000, loss: 0.207640
 >> iter 47000, loss: 0.228192
 >> iter 48000, loss: 0.242525
 >> iter 49000, loss: 0.225005
 >> iter 50000, loss: 0.275023
   Number of active neurons: 7
 >> iter 51000, loss: 0.339808
 >> iter 52000, loss: 0.328336
 >> iter 53000, loss: 0.370979
 >> iter 54000, loss: 0.399227
 >> iter 55000, loss: 0.283805
 >> iter 56000, loss: 0.252988
 >> iter 57000, loss: 0.333250
 >> iter 58000, loss: 0.410338
 >> iter 59000, loss: 0.361394
 >> iter 60000, loss: 0.247790
   Number of active neurons: 7
 >> iter 61000, loss: 0.367353
 >> iter 62000, loss: 0.320705
 >> iter 63000, loss: 0.273424
 >> iter 64000, loss: 0.311526
 >> iter 65000, loss: 0.322464
 >> iter 66000, loss: 0.328725
 >> iter 67000, loss: 0.276921
 >> iter 68000, loss: 0.213898
 >> iter 69000, loss: 0.257837
 >> iter 70000, loss: 0.301023
   Number of active neurons: 7
 >> iter 71000, loss: 0.326478
 >> iter 72000, loss: 0.290443
 >> iter 73000, loss: 0.529828
 >> iter 74000, loss: 0.382601
 >> iter 75000, loss: 0.419334
 >> iter 76000, loss: 0.465580
 >> iter 77000, loss: 0.395283
 >> iter 78000, loss: 0.340759
 >> iter 79000, loss: 0.293990
 >> iter 80000, loss: 0.253047
   Number of active neurons: 7
 >> iter 81000, loss: 0.328712
 >> iter 82000, loss: 0.244300
 >> iter 83000, loss: 0.249556
 >> iter 84000, loss: 0.326828
 >> iter 85000, loss: 0.349427
 >> iter 86000, loss: 0.244718
 >> iter 87000, loss: 0.316614
 >> iter 88000, loss: 0.273985
 >> iter 89000, loss: 0.343358
 >> iter 90000, loss: 0.295986
   Number of active neurons: 6
 >> iter 91000, loss: 0.409061
 >> iter 92000, loss: 0.395398
 >> iter 93000, loss: 0.403727
 >> iter 94000, loss: 0.371465
 >> iter 95000, loss: 0.348498
 >> iter 96000, loss: 0.253218
 >> iter 97000, loss: 0.309335
 >> iter 98000, loss: 0.379907
 >> iter 99000, loss: 0.318283
 >> iter 100000, loss: 0.362621
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.500061
 >> iter 2000, loss: 9.859528
 >> iter 3000, loss: 6.607345
 >> iter 4000, loss: 3.487195
 >> iter 5000, loss: 1.830532
 >> iter 6000, loss: 1.077532
 >> iter 7000, loss: 0.645654
 >> iter 8000, loss: 0.517546
 >> iter 9000, loss: 0.477547
 >> iter 10000, loss: 0.400665
   Number of active neurons: 8
 >> iter 11000, loss: 0.434572
 >> iter 12000, loss: 0.435642
 >> iter 13000, loss: 0.273463
 >> iter 14000, loss: 0.259361
 >> iter 15000, loss: 0.474211
 >> iter 16000, loss: 0.367691
 >> iter 17000, loss: 0.257665
 >> iter 18000, loss: 0.355483
 >> iter 19000, loss: 0.415683
 >> iter 20000, loss: 0.492348
   Number of active neurons: 8
 >> iter 21000, loss: 0.400156
 >> iter 22000, loss: 0.308047
 >> iter 23000, loss: 0.320027
 >> iter 24000, loss: 0.301675
 >> iter 25000, loss: 0.349213
 >> iter 26000, loss: 0.403987
 >> iter 27000, loss: 0.316986
 >> iter 28000, loss: 0.226892
 >> iter 29000, loss: 0.288998
 >> iter 30000, loss: 0.467231
   Number of active neurons: 8
 >> iter 31000, loss: 0.435287
 >> iter 32000, loss: 0.370609
 >> iter 33000, loss: 0.238066
 >> iter 34000, loss: 0.350257
 >> iter 35000, loss: 0.408968
 >> iter 36000, loss: 0.264105
 >> iter 37000, loss: 0.295473
 >> iter 38000, loss: 0.415900
 >> iter 39000, loss: 0.449169
 >> iter 40000, loss: 0.353549
   Number of active neurons: 8
 >> iter 41000, loss: 0.297059
 >> iter 42000, loss: 0.357220
 >> iter 43000, loss: 0.333612
 >> iter 44000, loss: 0.290304
 >> iter 45000, loss: 0.266755
 >> iter 46000, loss: 0.377813
 >> iter 47000, loss: 0.345832
 >> iter 48000, loss: 0.301335
 >> iter 49000, loss: 0.323464
 >> iter 50000, loss: 0.354176
   Number of active neurons: 8
 >> iter 51000, loss: 0.230757
 >> iter 52000, loss: 0.306618
 >> iter 53000, loss: 0.390749
 >> iter 54000, loss: 0.296890
 >> iter 55000, loss: 0.247885
 >> iter 56000, loss: 0.253482
 >> iter 57000, loss: 0.291955
 >> iter 58000, loss: 0.274712
 >> iter 59000, loss: 0.292042
 >> iter 60000, loss: 0.349097
   Number of active neurons: 8
 >> iter 61000, loss: 0.293790
 >> iter 62000, loss: 0.204323
 >> iter 63000, loss: 0.248068
 >> iter 64000, loss: 0.288814
 >> iter 65000, loss: 0.478671
 >> iter 66000, loss: 0.411112
 >> iter 67000, loss: 0.460279
 >> iter 68000, loss: 0.295870
 >> iter 69000, loss: 0.306462
 >> iter 70000, loss: 0.244240
   Number of active neurons: 8
 >> iter 71000, loss: 0.232570
 >> iter 72000, loss: 0.218140
 >> iter 73000, loss: 0.340223
 >> iter 74000, loss: 0.258763
 >> iter 75000, loss: 0.268158
 >> iter 76000, loss: 0.276353
 >> iter 77000, loss: 0.260229
 >> iter 78000, loss: 0.333781
 >> iter 79000, loss: 0.277825
 >> iter 80000, loss: 0.270637
   Number of active neurons: 8
 >> iter 81000, loss: 0.352712
 >> iter 82000, loss: 0.273825
 >> iter 83000, loss: 0.237764
 >> iter 84000, loss: 0.346484
 >> iter 85000, loss: 0.403677
 >> iter 86000, loss: 0.271048
 >> iter 87000, loss: 0.321664
 >> iter 88000, loss: 0.260282
 >> iter 89000, loss: 0.247150
 >> iter 90000, loss: 0.252439
   Number of active neurons: 8
 >> iter 91000, loss: 0.220330
 >> iter 92000, loss: 0.346188
 >> iter 93000, loss: 0.432879
 >> iter 94000, loss: 0.239371
 >> iter 95000, loss: 0.269199
 >> iter 96000, loss: 0.277123
 >> iter 97000, loss: 0.330418
 >> iter 98000, loss: 0.375081
 >> iter 99000, loss: 0.311930
 >> iter 100000, loss: 0.249735
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.947325
 >> iter 2000, loss: 10.291800
 >> iter 3000, loss: 7.638177
 >> iter 4000, loss: 5.459346
 >> iter 5000, loss: 3.386694
 >> iter 6000, loss: 2.089620
 >> iter 7000, loss: 1.449529
 >> iter 8000, loss: 0.983736
 >> iter 9000, loss: 0.858054
 >> iter 10000, loss: 0.928861
   Number of active neurons: 11
 >> iter 11000, loss: 0.834203
 >> iter 12000, loss: 0.716469
 >> iter 13000, loss: 0.789366
 >> iter 14000, loss: 0.684797
 >> iter 15000, loss: 0.543202
 >> iter 16000, loss: 0.652722
 >> iter 17000, loss: 0.580464
 >> iter 18000, loss: 0.551058
 >> iter 19000, loss: 0.630351
 >> iter 20000, loss: 0.545719
   Number of active neurons: 11
 >> iter 21000, loss: 0.677479
 >> iter 22000, loss: 0.949468
 >> iter 23000, loss: 0.838798
 >> iter 24000, loss: 0.651975
 >> iter 25000, loss: 0.545121
 >> iter 26000, loss: 0.759838
 >> iter 27000, loss: 0.630624
 >> iter 28000, loss: 0.547649
 >> iter 29000, loss: 0.742455
 >> iter 30000, loss: 0.522818
   Number of active neurons: 9
 >> iter 31000, loss: 0.578107
 >> iter 32000, loss: 0.518685
 >> iter 33000, loss: 0.559108
 >> iter 34000, loss: 0.624559
 >> iter 35000, loss: 0.670496
 >> iter 36000, loss: 0.687878
 >> iter 37000, loss: 0.759267
 >> iter 38000, loss: 0.724050
 >> iter 39000, loss: 0.719185
 >> iter 40000, loss: 0.684907
   Number of active neurons: 8
 >> iter 41000, loss: 0.632252
 >> iter 42000, loss: 0.561743
 >> iter 43000, loss: 0.581199
 >> iter 44000, loss: 0.493585
 >> iter 45000, loss: 0.480685
 >> iter 46000, loss: 0.560992
 >> iter 47000, loss: 0.671802
 >> iter 48000, loss: 0.518388
 >> iter 49000, loss: 0.562579
 >> iter 50000, loss: 0.512695
   Number of active neurons: 6
 >> iter 51000, loss: 0.602422
 >> iter 52000, loss: 0.574888
 >> iter 53000, loss: 0.376736
 >> iter 54000, loss: 0.634107
 >> iter 55000, loss: 0.719662
 >> iter 56000, loss: 0.760547
 >> iter 57000, loss: 0.778996
 >> iter 58000, loss: 0.672282
 >> iter 59000, loss: 0.618693
 >> iter 60000, loss: 0.578992
   Number of active neurons: 6
 >> iter 61000, loss: 0.759139
 >> iter 62000, loss: 0.594463
 >> iter 63000, loss: 0.681445
 >> iter 64000, loss: 0.578047
 >> iter 65000, loss: 0.680342
 >> iter 66000, loss: 0.562362
 >> iter 67000, loss: 0.477108
 >> iter 68000, loss: 0.470373
 >> iter 69000, loss: 0.546331
 >> iter 70000, loss: 0.564496
   Number of active neurons: 6
 >> iter 71000, loss: 0.675759
 >> iter 72000, loss: 0.669339
 >> iter 73000, loss: 0.725750
 >> iter 74000, loss: 0.898049
 >> iter 75000, loss: 0.679865
 >> iter 76000, loss: 0.858021
 >> iter 77000, loss: 0.829623
 >> iter 78000, loss: 0.591905
 >> iter 79000, loss: 0.484816
 >> iter 80000, loss: 0.489509
   Number of active neurons: 7
 >> iter 81000, loss: 0.705748
 >> iter 82000, loss: 0.605968
 >> iter 83000, loss: 0.616094
 >> iter 84000, loss: 0.731712
 >> iter 85000, loss: 0.594118
 >> iter 86000, loss: 0.644238
 >> iter 87000, loss: 0.665271
 >> iter 88000, loss: 0.525345
 >> iter 89000, loss: 0.817777
 >> iter 90000, loss: 0.580465
   Number of active neurons: 6
 >> iter 91000, loss: 0.554866
 >> iter 92000, loss: 0.587197
 >> iter 93000, loss: 0.539699
 >> iter 94000, loss: 0.692735
 >> iter 95000, loss: 0.630232
 >> iter 96000, loss: 0.640081
 >> iter 97000, loss: 0.717895
 >> iter 98000, loss: 0.642707
 >> iter 99000, loss: 0.619505
 >> iter 100000, loss: 0.723152
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.982886
 >> iter 2000, loss: 10.048787
 >> iter 3000, loss: 4.951181
 >> iter 4000, loss: 2.429137
 >> iter 5000, loss: 1.205359
 >> iter 6000, loss: 0.654997
 >> iter 7000, loss: 0.557587
 >> iter 8000, loss: 0.427330
 >> iter 9000, loss: 0.352320
 >> iter 10000, loss: 0.348119
   Number of active neurons: 7
 >> iter 11000, loss: 0.345367
 >> iter 12000, loss: 0.277695
 >> iter 13000, loss: 0.280197
 >> iter 14000, loss: 0.247293
 >> iter 15000, loss: 0.333252
 >> iter 16000, loss: 0.386486
 >> iter 17000, loss: 0.329277
 >> iter 18000, loss: 0.333144
 >> iter 19000, loss: 0.292133
 >> iter 20000, loss: 0.256301
   Number of active neurons: 7
 >> iter 21000, loss: 0.283291
 >> iter 22000, loss: 0.310692
 >> iter 23000, loss: 0.303153
 >> iter 24000, loss: 0.279767
 >> iter 25000, loss: 0.265270
 >> iter 26000, loss: 0.339421
 >> iter 27000, loss: 0.240719
 >> iter 28000, loss: 0.248363
 >> iter 29000, loss: 0.339722
 >> iter 30000, loss: 0.321931
   Number of active neurons: 7
 >> iter 31000, loss: 0.280127
 >> iter 32000, loss: 0.281304
 >> iter 33000, loss: 0.334817
 >> iter 34000, loss: 0.260074
 >> iter 35000, loss: 0.246625
 >> iter 36000, loss: 0.222665
 >> iter 37000, loss: 0.188027
 >> iter 38000, loss: 0.282197
 >> iter 39000, loss: 0.213374
 >> iter 40000, loss: 0.294158
   Number of active neurons: 7
 >> iter 41000, loss: 0.397434
 >> iter 42000, loss: 0.398642
 >> iter 43000, loss: 0.356159
 >> iter 44000, loss: 0.302125
 >> iter 45000, loss: 0.240132
 >> iter 46000, loss: 0.224238
 >> iter 47000, loss: 0.288111
 >> iter 48000, loss: 0.418256
 >> iter 49000, loss: 0.275295
 >> iter 50000, loss: 0.292553
   Number of active neurons: 6
 >> iter 51000, loss: 0.216618
 >> iter 52000, loss: 0.154550
 >> iter 53000, loss: 0.305151
 >> iter 54000, loss: 0.277053
 >> iter 55000, loss: 0.318648
 >> iter 56000, loss: 0.269220
 >> iter 57000, loss: 0.165603
 >> iter 58000, loss: 0.277233
 >> iter 59000, loss: 0.197265
 >> iter 60000, loss: 0.251116
   Number of active neurons: 6
 >> iter 61000, loss: 0.300574
 >> iter 62000, loss: 0.323323
 >> iter 63000, loss: 0.256784
 >> iter 64000, loss: 0.221107
 >> iter 65000, loss: 0.217069
 >> iter 66000, loss: 0.190267
 >> iter 67000, loss: 0.284836
 >> iter 68000, loss: 0.246780
 >> iter 69000, loss: 0.330415
 >> iter 70000, loss: 0.296435
   Number of active neurons: 6
 >> iter 71000, loss: 0.232145
 >> iter 72000, loss: 0.240219
 >> iter 73000, loss: 0.221310
 >> iter 74000, loss: 0.160087
 >> iter 75000, loss: 0.270748
 >> iter 76000, loss: 0.235384
 >> iter 77000, loss: 0.272926
 >> iter 78000, loss: 0.183813
 >> iter 79000, loss: 0.213959
 >> iter 80000, loss: 0.172519
   Number of active neurons: 6
 >> iter 81000, loss: 0.247820
 >> iter 82000, loss: 0.230568
 >> iter 83000, loss: 0.196515
 >> iter 84000, loss: 0.255852
 >> iter 85000, loss: 0.308887
 >> iter 86000, loss: 0.307291
 >> iter 87000, loss: 0.282954
 >> iter 88000, loss: 0.189757
 >> iter 89000, loss: 0.163571
 >> iter 90000, loss: 0.212661
   Number of active neurons: 6
 >> iter 91000, loss: 0.220065
 >> iter 92000, loss: 0.176530
 >> iter 93000, loss: 0.180204
 >> iter 94000, loss: 0.243604
 >> iter 95000, loss: 0.213528
 >> iter 96000, loss: 0.194742
 >> iter 97000, loss: 0.151620
 >> iter 98000, loss: 0.317784
 >> iter 99000, loss: 0.301725
 >> iter 100000, loss: 0.296833
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.517927
 >> iter 2000, loss: 9.600624
 >> iter 3000, loss: 5.537256
 >> iter 4000, loss: 2.560158
 >> iter 5000, loss: 1.291701
 >> iter 6000, loss: 0.637935
 >> iter 7000, loss: 0.444790
 >> iter 8000, loss: 0.300076
 >> iter 9000, loss: 0.339220
 >> iter 10000, loss: 0.313848
   Number of active neurons: 9
 >> iter 11000, loss: 0.245025
 >> iter 12000, loss: 0.281161
 >> iter 13000, loss: 0.408117
 >> iter 14000, loss: 0.297560
 >> iter 15000, loss: 0.229620
 >> iter 16000, loss: 0.245888
 >> iter 17000, loss: 0.239636
 >> iter 18000, loss: 0.298469
 >> iter 19000, loss: 0.247958
 >> iter 20000, loss: 0.150548
   Number of active neurons: 9
 >> iter 21000, loss: 0.358834
 >> iter 22000, loss: 0.333712
 >> iter 23000, loss: 0.283155
 >> iter 24000, loss: 0.301417
 >> iter 25000, loss: 0.338591
 >> iter 26000, loss: 0.240298
 >> iter 27000, loss: 0.355858
 >> iter 28000, loss: 0.302251
 >> iter 29000, loss: 0.310900
 >> iter 30000, loss: 0.265940
   Number of active neurons: 9
 >> iter 31000, loss: 0.354089
 >> iter 32000, loss: 0.366975
 >> iter 33000, loss: 0.298993
 >> iter 34000, loss: 0.311913
 >> iter 35000, loss: 0.375840
 >> iter 36000, loss: 0.363674
 >> iter 37000, loss: 0.305325
 >> iter 38000, loss: 0.179169
 >> iter 39000, loss: 0.377302
 >> iter 40000, loss: 0.299899
   Number of active neurons: 9
 >> iter 41000, loss: 0.271071
 >> iter 42000, loss: 0.288757
 >> iter 43000, loss: 0.225872
 >> iter 44000, loss: 0.271411
 >> iter 45000, loss: 0.228094
 >> iter 46000, loss: 0.264115
 >> iter 47000, loss: 0.232829
 >> iter 48000, loss: 0.220220
 >> iter 49000, loss: 0.258243
 >> iter 50000, loss: 0.235610
   Number of active neurons: 9
 >> iter 51000, loss: 0.216867
 >> iter 52000, loss: 0.182820
 >> iter 53000, loss: 0.436356
 >> iter 54000, loss: 0.306762
 >> iter 55000, loss: 0.356186
 >> iter 56000, loss: 0.270983
 >> iter 57000, loss: 0.250622
 >> iter 58000, loss: 0.219990
 >> iter 59000, loss: 0.311466
 >> iter 60000, loss: 0.288611
   Number of active neurons: 8
 >> iter 61000, loss: 0.311260
 >> iter 62000, loss: 0.314200
 >> iter 63000, loss: 0.287325
 >> iter 64000, loss: 0.259128
 >> iter 65000, loss: 0.239439
 >> iter 66000, loss: 0.309072
 >> iter 67000, loss: 0.286061
 >> iter 68000, loss: 0.268601
 >> iter 69000, loss: 0.332998
 >> iter 70000, loss: 0.238706
   Number of active neurons: 8
 >> iter 71000, loss: 0.259497
 >> iter 72000, loss: 0.177047
 >> iter 73000, loss: 0.210455
 >> iter 74000, loss: 0.246266
 >> iter 75000, loss: 0.215394
 >> iter 76000, loss: 0.223829
 >> iter 77000, loss: 0.172168
 >> iter 78000, loss: 0.178309
 >> iter 79000, loss: 0.312971
 >> iter 80000, loss: 0.293794
   Number of active neurons: 7
 >> iter 81000, loss: 0.269603
 >> iter 82000, loss: 0.203279
 >> iter 83000, loss: 0.157067
 >> iter 84000, loss: 0.194308
 >> iter 85000, loss: 0.259149
 >> iter 86000, loss: 0.272609
 >> iter 87000, loss: 0.429902
 >> iter 88000, loss: 0.287792
 >> iter 89000, loss: 0.246837
 >> iter 90000, loss: 0.171921
   Number of active neurons: 7
 >> iter 91000, loss: 0.179601
 >> iter 92000, loss: 0.305882
 >> iter 93000, loss: 0.369600
 >> iter 94000, loss: 0.246071
 >> iter 95000, loss: 0.284944
 >> iter 96000, loss: 0.216874
 >> iter 97000, loss: 0.340380
 >> iter 98000, loss: 0.297539
 >> iter 99000, loss: 0.281429
 >> iter 100000, loss: 0.345215
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.758429
 >> iter 2000, loss: 9.608520
 >> iter 3000, loss: 5.642465
 >> iter 4000, loss: 2.992603
 >> iter 5000, loss: 1.570218
 >> iter 6000, loss: 1.059522
 >> iter 7000, loss: 0.639972
 >> iter 8000, loss: 0.562120
 >> iter 9000, loss: 0.415127
 >> iter 10000, loss: 0.486430
   Number of active neurons: 9
 >> iter 11000, loss: 0.406102
 >> iter 12000, loss: 0.367841
 >> iter 13000, loss: 0.286665
 >> iter 14000, loss: 0.330612
 >> iter 15000, loss: 0.339386
 >> iter 16000, loss: 0.303503
 >> iter 17000, loss: 0.206396
 >> iter 18000, loss: 0.150263
 >> iter 19000, loss: 0.251743
 >> iter 20000, loss: 0.209769
   Number of active neurons: 8
 >> iter 21000, loss: 0.230605
 >> iter 22000, loss: 0.267276
 >> iter 23000, loss: 0.254395
 >> iter 24000, loss: 0.234671
 >> iter 25000, loss: 0.198635
 >> iter 26000, loss: 0.296237
 >> iter 27000, loss: 0.259447
 >> iter 28000, loss: 0.146265
 >> iter 29000, loss: 0.238564
 >> iter 30000, loss: 0.279118
   Number of active neurons: 8
 >> iter 31000, loss: 0.207930
 >> iter 32000, loss: 0.238975
 >> iter 33000, loss: 0.165713
 >> iter 34000, loss: 0.218603
 >> iter 35000, loss: 0.181275
 >> iter 36000, loss: 0.179962
 >> iter 37000, loss: 0.183136
 >> iter 38000, loss: 0.229573
 >> iter 39000, loss: 0.207783
 >> iter 40000, loss: 0.165346
   Number of active neurons: 8
 >> iter 41000, loss: 0.130805
 >> iter 42000, loss: 0.184746
 >> iter 43000, loss: 0.245016
 >> iter 44000, loss: 0.290334
 >> iter 45000, loss: 0.306623
 >> iter 46000, loss: 0.179556
 >> iter 47000, loss: 0.243229
 >> iter 48000, loss: 0.249248
 >> iter 49000, loss: 0.185684
 >> iter 50000, loss: 0.135830
   Number of active neurons: 7
 >> iter 51000, loss: 0.130588
 >> iter 52000, loss: 0.212298
 >> iter 53000, loss: 0.255857
 >> iter 54000, loss: 0.205982
 >> iter 55000, loss: 0.183522
 >> iter 56000, loss: 0.201829
 >> iter 57000, loss: 0.195870
 >> iter 58000, loss: 0.227757
 >> iter 59000, loss: 0.210611
 >> iter 60000, loss: 0.255647
   Number of active neurons: 6
 >> iter 61000, loss: 0.212494
 >> iter 62000, loss: 0.260996
 >> iter 63000, loss: 0.233043
 >> iter 64000, loss: 0.242038
 >> iter 65000, loss: 0.185577
 >> iter 66000, loss: 0.160953
 >> iter 67000, loss: 0.255954
 >> iter 68000, loss: 0.322397
 >> iter 69000, loss: 0.247198
 >> iter 70000, loss: 0.300186
   Number of active neurons: 6
 >> iter 71000, loss: 0.323338
 >> iter 72000, loss: 0.258568
 >> iter 73000, loss: 0.197020
 >> iter 74000, loss: 0.252129
 >> iter 75000, loss: 0.272212
 >> iter 76000, loss: 0.291000
 >> iter 77000, loss: 0.200259
 >> iter 78000, loss: 0.209368
 >> iter 79000, loss: 0.173950
 >> iter 80000, loss: 0.194072
   Number of active neurons: 6
 >> iter 81000, loss: 0.228879
 >> iter 82000, loss: 0.200806
 >> iter 83000, loss: 0.172907
 >> iter 84000, loss: 0.254030
 >> iter 85000, loss: 0.219366
 >> iter 86000, loss: 0.164463
 >> iter 87000, loss: 0.209290
 >> iter 88000, loss: 0.251963
 >> iter 89000, loss: 0.290684
 >> iter 90000, loss: 0.203531
   Number of active neurons: 6
 >> iter 91000, loss: 0.194559
 >> iter 92000, loss: 0.237805
 >> iter 93000, loss: 0.169959
 >> iter 94000, loss: 0.220752
 >> iter 95000, loss: 0.222808
 >> iter 96000, loss: 0.181468
 >> iter 97000, loss: 0.200707
 >> iter 98000, loss: 0.211051
 >> iter 99000, loss: 0.170673
 >> iter 100000, loss: 0.285110
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

