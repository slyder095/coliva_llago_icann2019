 > Problema: tomita4nueva
 > Args:
   - Hidden size: 8
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 20.524752
 >> iter 2000, loss: 16.955205
 >> iter 3000, loss: 11.317522
 >> iter 4000, loss: 5.468762
 >> iter 5000, loss: 2.976879
 >> iter 6000, loss: 1.379878
 >> iter 7000, loss: 0.823368
 >> iter 8000, loss: 0.549046
 >> iter 9000, loss: 0.674629
 >> iter 10000, loss: 0.615140
   Number of active neurons: 5
 >> iter 11000, loss: 0.553751
 >> iter 12000, loss: 0.495654
 >> iter 13000, loss: 0.381740
 >> iter 14000, loss: 0.456873
 >> iter 15000, loss: 0.712660
 >> iter 16000, loss: 0.329463
 >> iter 17000, loss: 0.359396
 >> iter 18000, loss: 0.318457
 >> iter 19000, loss: 0.305218
 >> iter 20000, loss: 0.268274
   Number of active neurons: 5
 >> iter 21000, loss: 0.385925
 >> iter 22000, loss: 0.422397
 >> iter 23000, loss: 0.322709
 >> iter 24000, loss: 0.225297
 >> iter 25000, loss: 0.455498
 >> iter 26000, loss: 0.444602
 >> iter 27000, loss: 0.327818
 >> iter 28000, loss: 0.308535
 >> iter 29000, loss: 0.500344
 >> iter 30000, loss: 0.368309
   Number of active neurons: 5
 >> iter 31000, loss: 0.430119
 >> iter 32000, loss: 0.320005
 >> iter 33000, loss: 0.369469
 >> iter 34000, loss: 0.306251
 >> iter 35000, loss: 0.363389
 >> iter 36000, loss: 0.343386
 >> iter 37000, loss: 0.431977
 >> iter 38000, loss: 0.467414
 >> iter 39000, loss: 0.349651
 >> iter 40000, loss: 0.301395
   Number of active neurons: 5
 >> iter 41000, loss: 0.140550
 >> iter 42000, loss: 0.350878
 >> iter 43000, loss: 0.241178
 >> iter 44000, loss: 0.345295
 >> iter 45000, loss: 0.314020
 >> iter 46000, loss: 0.352269
 >> iter 47000, loss: 0.468356
 >> iter 48000, loss: 0.375779
 >> iter 49000, loss: 0.364377
 >> iter 50000, loss: 0.615629
   Number of active neurons: 4
 >> iter 51000, loss: 0.487397
 >> iter 52000, loss: 0.422033
 >> iter 53000, loss: 0.306635
 >> iter 54000, loss: 0.310135
 >> iter 55000, loss: 0.273263
 >> iter 56000, loss: 0.310220
 >> iter 57000, loss: 0.173388
 >> iter 58000, loss: 0.357356
 >> iter 59000, loss: 0.504698
 >> iter 60000, loss: 0.601781
   Number of active neurons: 4
 >> iter 61000, loss: 0.511221
 >> iter 62000, loss: 0.337316
 >> iter 63000, loss: 0.293424
 >> iter 64000, loss: 0.265253
 >> iter 65000, loss: 0.371559
 >> iter 66000, loss: 0.332532
 >> iter 67000, loss: 0.290119
 >> iter 68000, loss: 0.530246
 >> iter 69000, loss: 0.464902
 >> iter 70000, loss: 0.344640
   Number of active neurons: 4
 >> iter 71000, loss: 0.302746
 >> iter 72000, loss: 0.466935
 >> iter 73000, loss: 0.382136
 >> iter 74000, loss: 0.340666
 >> iter 75000, loss: 0.191083
 >> iter 76000, loss: 0.273146
 >> iter 77000, loss: 0.430611
 >> iter 78000, loss: 0.419456
 >> iter 79000, loss: 0.413846
 >> iter 80000, loss: 0.286187
   Number of active neurons: 4
 >> iter 81000, loss: 0.265244
 >> iter 82000, loss: 0.316707
 >> iter 83000, loss: 0.263296
 >> iter 84000, loss: 0.230946
 >> iter 85000, loss: 0.268581
 >> iter 86000, loss: 0.435157
 >> iter 87000, loss: 0.335023
 >> iter 88000, loss: 0.186560
 >> iter 89000, loss: 0.395215
 >> iter 90000, loss: 0.202407
   Number of active neurons: 4
 >> iter 91000, loss: 0.302654
 >> iter 92000, loss: 0.479695
 >> iter 93000, loss: 0.527766
 >> iter 94000, loss: 0.448460
 >> iter 95000, loss: 0.352895
 >> iter 96000, loss: 0.329676
 >> iter 97000, loss: 0.196812
 >> iter 98000, loss: 0.182166
 >> iter 99000, loss: 0.390947
 >> iter 100000, loss: 0.368296
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.592732
 >> iter 2000, loss: 9.851228
 >> iter 3000, loss: 4.460531
 >> iter 4000, loss: 2.181281
 >> iter 5000, loss: 1.022910
 >> iter 6000, loss: 0.655387
 >> iter 7000, loss: 0.466611
 >> iter 8000, loss: 0.330768
 >> iter 9000, loss: 0.337952
 >> iter 10000, loss: 0.403927
   Number of active neurons: 3
 >> iter 11000, loss: 0.398958
 >> iter 12000, loss: 0.344797
 >> iter 13000, loss: 0.205718
 >> iter 14000, loss: 0.270393
 >> iter 15000, loss: 0.181599
 >> iter 16000, loss: 0.221229
 >> iter 17000, loss: 0.166672
 >> iter 18000, loss: 0.273718
 >> iter 19000, loss: 0.229609
 >> iter 20000, loss: 0.325386
   Number of active neurons: 3
 >> iter 21000, loss: 0.162105
 >> iter 22000, loss: 0.090802
 >> iter 23000, loss: 0.370665
 >> iter 24000, loss: 0.264491
 >> iter 25000, loss: 0.316132
 >> iter 26000, loss: 0.207518
 >> iter 27000, loss: 0.290482
 >> iter 28000, loss: 0.380739
 >> iter 29000, loss: 0.359363
 >> iter 30000, loss: 0.325894
   Number of active neurons: 3
 >> iter 31000, loss: 0.280720
 >> iter 32000, loss: 0.219294
 >> iter 33000, loss: 0.225165
 >> iter 34000, loss: 0.247415
 >> iter 35000, loss: 0.145078
 >> iter 36000, loss: 0.332351
 >> iter 37000, loss: 0.403224
 >> iter 38000, loss: 0.328074
 >> iter 39000, loss: 0.179564
 >> iter 40000, loss: 0.178867
   Number of active neurons: 3
 >> iter 41000, loss: 0.187525
 >> iter 42000, loss: 0.147001
 >> iter 43000, loss: 0.225269
 >> iter 44000, loss: 0.256125
 >> iter 45000, loss: 0.300777
 >> iter 46000, loss: 0.193637
 >> iter 47000, loss: 0.216729
 >> iter 48000, loss: 0.276488
 >> iter 49000, loss: 0.199431
 >> iter 50000, loss: 0.145983
   Number of active neurons: 3
 >> iter 51000, loss: 0.241257
 >> iter 52000, loss: 0.130690
 >> iter 53000, loss: 0.069482
 >> iter 54000, loss: 0.201039
 >> iter 55000, loss: 0.238753
 >> iter 56000, loss: 0.192470
 >> iter 57000, loss: 0.165687
 >> iter 58000, loss: 0.199089
 >> iter 59000, loss: 0.568002
 >> iter 60000, loss: 0.243188
   Number of active neurons: 3
 >> iter 61000, loss: 0.227184
 >> iter 62000, loss: 0.183384
 >> iter 63000, loss: 0.259846
 >> iter 64000, loss: 0.202625
 >> iter 65000, loss: 0.297345
 >> iter 66000, loss: 0.270255
 >> iter 67000, loss: 0.192463
 >> iter 68000, loss: 0.213483
 >> iter 69000, loss: 0.377694
 >> iter 70000, loss: 0.289855
   Number of active neurons: 3
 >> iter 71000, loss: 0.199354
 >> iter 72000, loss: 0.265348
 >> iter 73000, loss: 0.423093
 >> iter 74000, loss: 0.243654
 >> iter 75000, loss: 0.177329
 >> iter 76000, loss: 0.222449
 >> iter 77000, loss: 0.308684
 >> iter 78000, loss: 0.180284
 >> iter 79000, loss: 0.244685
 >> iter 80000, loss: 0.309639
   Number of active neurons: 3
 >> iter 81000, loss: 0.235876
 >> iter 82000, loss: 0.164985
 >> iter 83000, loss: 0.150042
 >> iter 84000, loss: 0.209622
 >> iter 85000, loss: 0.171081
 >> iter 86000, loss: 0.351101
 >> iter 87000, loss: 0.346328
 >> iter 88000, loss: 0.277135
 >> iter 89000, loss: 0.209016
 >> iter 90000, loss: 0.232083
   Number of active neurons: 3
 >> iter 91000, loss: 0.193600
 >> iter 92000, loss: 0.291918
 >> iter 93000, loss: 0.176575
 >> iter 94000, loss: 0.217129
 >> iter 95000, loss: 0.110643
 >> iter 96000, loss: 0.222398
 >> iter 97000, loss: 0.196117
 >> iter 98000, loss: 0.214053
 >> iter 99000, loss: 0.229588
 >> iter 100000, loss: 0.302019
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.218439
 >> iter 2000, loss: 9.925700
 >> iter 3000, loss: 4.343434
 >> iter 4000, loss: 1.905751
 >> iter 5000, loss: 1.020368
 >> iter 6000, loss: 0.576031
 >> iter 7000, loss: 0.436369
 >> iter 8000, loss: 0.304314
 >> iter 9000, loss: 0.456034
 >> iter 10000, loss: 0.533113
   Number of active neurons: 6
 >> iter 11000, loss: 0.470582
 >> iter 12000, loss: 0.272780
 >> iter 13000, loss: 0.208169
 >> iter 14000, loss: 0.374640
 >> iter 15000, loss: 0.283998
 >> iter 16000, loss: 0.281737
 >> iter 17000, loss: 0.243313
 >> iter 18000, loss: 0.156639
 >> iter 19000, loss: 0.174004
 >> iter 20000, loss: 0.418694
   Number of active neurons: 5
 >> iter 21000, loss: 0.463361
 >> iter 22000, loss: 0.505052
 >> iter 23000, loss: 0.268212
 >> iter 24000, loss: 0.226011
 >> iter 25000, loss: 0.210868
 >> iter 26000, loss: 0.141332
 >> iter 27000, loss: 0.121922
 >> iter 28000, loss: 0.260470
 >> iter 29000, loss: 0.286641
 >> iter 30000, loss: 0.370289
   Number of active neurons: 4
 >> iter 31000, loss: 0.345807
 >> iter 32000, loss: 0.447202
 >> iter 33000, loss: 0.414532
 >> iter 34000, loss: 0.338535
 >> iter 35000, loss: 0.257014
 >> iter 36000, loss: 0.331451
 >> iter 37000, loss: 0.271890
 >> iter 38000, loss: 0.242418
 >> iter 39000, loss: 0.253404
 >> iter 40000, loss: 0.205930
   Number of active neurons: 4
 >> iter 41000, loss: 0.350120
 >> iter 42000, loss: 0.334664
 >> iter 43000, loss: 0.332679
 >> iter 44000, loss: 0.231736
 >> iter 45000, loss: 0.117147
 >> iter 46000, loss: 0.188840
 >> iter 47000, loss: 0.248350
 >> iter 48000, loss: 0.227799
 >> iter 49000, loss: 0.244227
 >> iter 50000, loss: 0.296909
   Number of active neurons: 4
 >> iter 51000, loss: 0.381616
 >> iter 52000, loss: 0.203780
 >> iter 53000, loss: 0.237854
 >> iter 54000, loss: 0.195245
 >> iter 55000, loss: 0.249563
 >> iter 56000, loss: 0.209098
 >> iter 57000, loss: 0.313082
 >> iter 58000, loss: 0.217591
 >> iter 59000, loss: 0.213008
 >> iter 60000, loss: 0.503778
   Number of active neurons: 3
 >> iter 61000, loss: 0.416154
 >> iter 62000, loss: 0.312106
 >> iter 63000, loss: 0.170486
 >> iter 64000, loss: 0.118451
 >> iter 65000, loss: 0.180475
 >> iter 66000, loss: 0.147818
 >> iter 67000, loss: 0.139470
 >> iter 68000, loss: 0.112645
 >> iter 69000, loss: 0.304316
 >> iter 70000, loss: 0.410091
   Number of active neurons: 3
 >> iter 71000, loss: 0.353055
 >> iter 72000, loss: 0.449495
 >> iter 73000, loss: 0.245598
 >> iter 74000, loss: 0.430331
 >> iter 75000, loss: 0.284175
 >> iter 76000, loss: 0.163260
 >> iter 77000, loss: 0.095210
 >> iter 78000, loss: 0.142232
 >> iter 79000, loss: 0.097567
 >> iter 80000, loss: 0.151074
   Number of active neurons: 3
 >> iter 81000, loss: 0.203117
 >> iter 82000, loss: 0.221397
 >> iter 83000, loss: 0.194678
 >> iter 84000, loss: 0.277897
 >> iter 85000, loss: 0.196172
 >> iter 86000, loss: 0.167716
 >> iter 87000, loss: 0.143183
 >> iter 88000, loss: 0.276160
 >> iter 89000, loss: 0.187317
 >> iter 90000, loss: 0.132280
   Number of active neurons: 3
 >> iter 91000, loss: 0.288401
 >> iter 92000, loss: 0.231707
 >> iter 93000, loss: 0.370068
 >> iter 94000, loss: 0.301436
 >> iter 95000, loss: 0.327394
 >> iter 96000, loss: 0.277009
 >> iter 97000, loss: 0.324062
 >> iter 98000, loss: 0.218647
 >> iter 99000, loss: 0.260277
 >> iter 100000, loss: 0.355729
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 17.134729
 >> iter 2000, loss: 8.168781
 >> iter 3000, loss: 3.538109
 >> iter 4000, loss: 1.815447
 >> iter 5000, loss: 1.021777
 >> iter 6000, loss: 0.743477
 >> iter 7000, loss: 0.631011
 >> iter 8000, loss: 0.326313
 >> iter 9000, loss: 0.249818
 >> iter 10000, loss: 0.237568
   Number of active neurons: 5
 >> iter 11000, loss: 0.308260
 >> iter 12000, loss: 0.339392
 >> iter 13000, loss: 0.260011
 >> iter 14000, loss: 0.351850
 >> iter 15000, loss: 0.395821
 >> iter 16000, loss: 0.466601
 >> iter 17000, loss: 0.391753
 >> iter 18000, loss: 0.462081
 >> iter 19000, loss: 0.390921
 >> iter 20000, loss: 0.314224
   Number of active neurons: 4
 >> iter 21000, loss: 0.346951
 >> iter 22000, loss: 0.303389
 >> iter 23000, loss: 0.211270
 >> iter 24000, loss: 0.103949
 >> iter 25000, loss: 0.215811
 >> iter 26000, loss: 0.268682
 >> iter 27000, loss: 0.484946
 >> iter 28000, loss: 0.376217
 >> iter 29000, loss: 0.291073
 >> iter 30000, loss: 0.257750
   Number of active neurons: 4
 >> iter 31000, loss: 0.404224
 >> iter 32000, loss: 0.331022
 >> iter 33000, loss: 0.206464
 >> iter 34000, loss: 0.245657
 >> iter 35000, loss: 0.246024
 >> iter 36000, loss: 0.200253
 >> iter 37000, loss: 0.316298
 >> iter 38000, loss: 0.267917
 >> iter 39000, loss: 0.255281
 >> iter 40000, loss: 0.166753
   Number of active neurons: 4
 >> iter 41000, loss: 0.296274
 >> iter 42000, loss: 0.190567
 >> iter 43000, loss: 0.316680
 >> iter 44000, loss: 0.227086
 >> iter 45000, loss: 0.417224
 >> iter 46000, loss: 0.474754
 >> iter 47000, loss: 0.296723
 >> iter 48000, loss: 0.216517
 >> iter 49000, loss: 0.270967
 >> iter 50000, loss: 0.322284
   Number of active neurons: 3
 >> iter 51000, loss: 0.406273
 >> iter 52000, loss: 0.325239
 >> iter 53000, loss: 0.174890
 >> iter 54000, loss: 0.448672
 >> iter 55000, loss: 0.309346
 >> iter 56000, loss: 0.306521
 >> iter 57000, loss: 0.220882
 >> iter 58000, loss: 0.139625
 >> iter 59000, loss: 0.185332
 >> iter 60000, loss: 0.185284
   Number of active neurons: 3
 >> iter 61000, loss: 0.215770
 >> iter 62000, loss: 0.363770
 >> iter 63000, loss: 0.390182
 >> iter 64000, loss: 0.393505
 >> iter 65000, loss: 0.388158
 >> iter 66000, loss: 0.279316
 >> iter 67000, loss: 0.148612
 >> iter 68000, loss: 0.276810
 >> iter 69000, loss: 0.293964
 >> iter 70000, loss: 0.398525
   Number of active neurons: 3
 >> iter 71000, loss: 0.329682
 >> iter 72000, loss: 0.260354
 >> iter 73000, loss: 0.244722
 >> iter 74000, loss: 0.211978
 >> iter 75000, loss: 0.259858
 >> iter 76000, loss: 0.151889
 >> iter 77000, loss: 0.266457
 >> iter 78000, loss: 0.230094
 >> iter 79000, loss: 0.147996
 >> iter 80000, loss: 0.087237
   Number of active neurons: 3
 >> iter 81000, loss: 0.066004
 >> iter 82000, loss: 0.186761
 >> iter 83000, loss: 0.185325
 >> iter 84000, loss: 0.122379
 >> iter 85000, loss: 0.272364
 >> iter 86000, loss: 0.201646
 >> iter 87000, loss: 0.207065
 >> iter 88000, loss: 0.181827
 >> iter 89000, loss: 0.323814
 >> iter 90000, loss: 0.286939
   Number of active neurons: 3
 >> iter 91000, loss: 0.235844
 >> iter 92000, loss: 0.358974
 >> iter 93000, loss: 0.342265
 >> iter 94000, loss: 0.257702
 >> iter 95000, loss: 0.253704
 >> iter 96000, loss: 0.276651
 >> iter 97000, loss: 0.152676
 >> iter 98000, loss: 0.136253
 >> iter 99000, loss: 0.266158
 >> iter 100000, loss: 0.262856
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.514265
 >> iter 2000, loss: 8.848294
 >> iter 3000, loss: 3.964651
 >> iter 4000, loss: 1.891323
 >> iter 5000, loss: 0.991200
 >> iter 6000, loss: 0.615241
 >> iter 7000, loss: 0.445229
 >> iter 8000, loss: 0.532562
 >> iter 9000, loss: 0.489460
 >> iter 10000, loss: 0.440736
   Number of active neurons: 6
 >> iter 11000, loss: 0.422245
 >> iter 12000, loss: 0.363213
 >> iter 13000, loss: 0.350030
 >> iter 14000, loss: 0.293643
 >> iter 15000, loss: 0.358539
 >> iter 16000, loss: 0.423476
 >> iter 17000, loss: 0.278854
 >> iter 18000, loss: 0.218279
 >> iter 19000, loss: 0.254818
 >> iter 20000, loss: 0.399759
   Number of active neurons: 5
 >> iter 21000, loss: 0.230176
 >> iter 22000, loss: 0.214352
 >> iter 23000, loss: 0.401841
 >> iter 24000, loss: 0.202607
 >> iter 25000, loss: 0.296076
 >> iter 26000, loss: 0.350205
 >> iter 27000, loss: 0.416619
 >> iter 28000, loss: 0.309416
 >> iter 29000, loss: 0.210326
 >> iter 30000, loss: 0.149967
   Number of active neurons: 3
 >> iter 31000, loss: 0.146638
 >> iter 32000, loss: 0.181176
 >> iter 33000, loss: 0.309431
 >> iter 34000, loss: 0.294519
 >> iter 35000, loss: 0.342094
 >> iter 36000, loss: 0.283196
 >> iter 37000, loss: 0.156583
 >> iter 38000, loss: 0.294902
 >> iter 39000, loss: 0.365224
 >> iter 40000, loss: 0.295493
   Number of active neurons: 3
 >> iter 41000, loss: 0.403871
 >> iter 42000, loss: 0.262306
 >> iter 43000, loss: 0.266715
 >> iter 44000, loss: 0.284442
 >> iter 45000, loss: 0.240336
 >> iter 46000, loss: 0.294099
 >> iter 47000, loss: 0.256707
 >> iter 48000, loss: 0.302839
 >> iter 49000, loss: 0.406547
 >> iter 50000, loss: 0.302311
   Number of active neurons: 3
 >> iter 51000, loss: 0.192036
 >> iter 52000, loss: 0.220194
 >> iter 53000, loss: 0.329660
 >> iter 54000, loss: 0.245461
 >> iter 55000, loss: 0.262155
 >> iter 56000, loss: 0.273911
 >> iter 57000, loss: 0.419123
 >> iter 58000, loss: 0.407300
 >> iter 59000, loss: 0.300450
 >> iter 60000, loss: 0.401109
   Number of active neurons: 3
 >> iter 61000, loss: 0.443654
 >> iter 62000, loss: 0.373299
 >> iter 63000, loss: 0.252301
 >> iter 64000, loss: 0.310611
 >> iter 65000, loss: 0.306686
 >> iter 66000, loss: 0.221643
 >> iter 67000, loss: 0.193617
 >> iter 68000, loss: 0.236688
 >> iter 69000, loss: 0.272587
 >> iter 70000, loss: 0.485881
   Number of active neurons: 3
 >> iter 71000, loss: 0.425689
 >> iter 72000, loss: 0.237471
 >> iter 73000, loss: 0.249009
 >> iter 74000, loss: 0.388654
 >> iter 75000, loss: 0.315001
 >> iter 76000, loss: 0.273569
 >> iter 77000, loss: 0.283587
 >> iter 78000, loss: 0.303568
 >> iter 79000, loss: 0.238744
 >> iter 80000, loss: 0.326604
   Number of active neurons: 3
 >> iter 81000, loss: 0.467549
 >> iter 82000, loss: 0.300272
 >> iter 83000, loss: 0.263802
 >> iter 84000, loss: 0.251010
 >> iter 85000, loss: 0.266948
 >> iter 86000, loss: 0.281034
 >> iter 87000, loss: 0.141670
 >> iter 88000, loss: 0.159171
 >> iter 89000, loss: 0.179092
 >> iter 90000, loss: 0.108413
   Number of active neurons: 3
 >> iter 91000, loss: 0.192183
 >> iter 92000, loss: 0.176822
 >> iter 93000, loss: 0.175127
 >> iter 94000, loss: 0.240909
 >> iter 95000, loss: 0.230092
 >> iter 96000, loss: 0.236691
 >> iter 97000, loss: 0.335675
 >> iter 98000, loss: 0.246785
 >> iter 99000, loss: 0.338425
 >> iter 100000, loss: 0.227555
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.506218
 >> iter 2000, loss: 8.806355
 >> iter 3000, loss: 4.048250
 >> iter 4000, loss: 1.937014
 >> iter 5000, loss: 0.958813
 >> iter 6000, loss: 0.516184
 >> iter 7000, loss: 0.326309
 >> iter 8000, loss: 0.534942
 >> iter 9000, loss: 0.365575
 >> iter 10000, loss: 0.300675
   Number of active neurons: 5
 >> iter 11000, loss: 0.214002
 >> iter 12000, loss: 0.341951
 >> iter 13000, loss: 0.262779
 >> iter 14000, loss: 0.388903
 >> iter 15000, loss: 0.396909
 >> iter 16000, loss: 0.424000
 >> iter 17000, loss: 0.355407
 >> iter 18000, loss: 0.468228
 >> iter 19000, loss: 0.267948
 >> iter 20000, loss: 0.248488
   Number of active neurons: 5
 >> iter 21000, loss: 0.287489
 >> iter 22000, loss: 0.271820
 >> iter 23000, loss: 0.416670
 >> iter 24000, loss: 0.193918
 >> iter 25000, loss: 0.170195
 >> iter 26000, loss: 0.371837
 >> iter 27000, loss: 0.371380
 >> iter 28000, loss: 0.300483
 >> iter 29000, loss: 0.286715
 >> iter 30000, loss: 0.312421
   Number of active neurons: 4
 >> iter 31000, loss: 0.286978
 >> iter 32000, loss: 0.334066
 >> iter 33000, loss: 0.283551
 >> iter 34000, loss: 0.228429
 >> iter 35000, loss: 0.299144
 >> iter 36000, loss: 0.314866
 >> iter 37000, loss: 0.303303
 >> iter 38000, loss: 0.268257
 >> iter 39000, loss: 0.246381
 >> iter 40000, loss: 0.351365
   Number of active neurons: 4
 >> iter 41000, loss: 0.403148
 >> iter 42000, loss: 0.314884
 >> iter 43000, loss: 0.258391
 >> iter 44000, loss: 0.363858
 >> iter 45000, loss: 0.368012
 >> iter 46000, loss: 0.550020
 >> iter 47000, loss: 0.238182
 >> iter 48000, loss: 0.376628
 >> iter 49000, loss: 0.339773
 >> iter 50000, loss: 0.262582
   Number of active neurons: 4
 >> iter 51000, loss: 0.277417
 >> iter 52000, loss: 0.282630
 >> iter 53000, loss: 0.250677
 >> iter 54000, loss: 0.173732
 >> iter 55000, loss: 0.266558
 >> iter 56000, loss: 0.410429
 >> iter 57000, loss: 0.582055
 >> iter 58000, loss: 0.463956
 >> iter 59000, loss: 0.334727
 >> iter 60000, loss: 0.392126
   Number of active neurons: 4
 >> iter 61000, loss: 0.316002
 >> iter 62000, loss: 0.281365
 >> iter 63000, loss: 0.252338
 >> iter 64000, loss: 0.316854
 >> iter 65000, loss: 0.230600
 >> iter 66000, loss: 0.336968
 >> iter 67000, loss: 0.254171
 >> iter 68000, loss: 0.216013
 >> iter 69000, loss: 0.371836
 >> iter 70000, loss: 0.258477
   Number of active neurons: 4
 >> iter 71000, loss: 0.313779
 >> iter 72000, loss: 0.183280
 >> iter 73000, loss: 0.093938
 >> iter 74000, loss: 0.217568
 >> iter 75000, loss: 0.332288
 >> iter 76000, loss: 0.264688
 >> iter 77000, loss: 0.386158
 >> iter 78000, loss: 0.193786
 >> iter 79000, loss: 0.210834
 >> iter 80000, loss: 0.275807
   Number of active neurons: 3
 >> iter 81000, loss: 0.255441
 >> iter 82000, loss: 0.269438
 >> iter 83000, loss: 0.293803
 >> iter 84000, loss: 0.184288
 >> iter 85000, loss: 0.271521
 >> iter 86000, loss: 0.293354
 >> iter 87000, loss: 0.163218
 >> iter 88000, loss: 0.306785
 >> iter 89000, loss: 0.558425
 >> iter 90000, loss: 0.477018
   Number of active neurons: 3
 >> iter 91000, loss: 0.343024
 >> iter 92000, loss: 0.246181
 >> iter 93000, loss: 0.257722
 >> iter 94000, loss: 0.154791
 >> iter 95000, loss: 0.369435
 >> iter 96000, loss: 0.278426
 >> iter 97000, loss: 0.213343
 >> iter 98000, loss: 0.486916
 >> iter 99000, loss: 0.407501
 >> iter 100000, loss: 0.287101
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.035770
 >> iter 2000, loss: 9.776586
 >> iter 3000, loss: 4.254389
 >> iter 4000, loss: 1.928992
 >> iter 5000, loss: 0.908663
 >> iter 6000, loss: 0.830678
 >> iter 7000, loss: 0.637015
 >> iter 8000, loss: 0.318960
 >> iter 9000, loss: 0.344725
 >> iter 10000, loss: 0.257388
   Number of active neurons: 4
 >> iter 11000, loss: 0.374256
 >> iter 12000, loss: 0.323213
 >> iter 13000, loss: 0.310833
 >> iter 14000, loss: 0.358319
 >> iter 15000, loss: 0.461002
 >> iter 16000, loss: 0.270887
 >> iter 17000, loss: 0.363645
 >> iter 18000, loss: 0.241256
 >> iter 19000, loss: 0.230031
 >> iter 20000, loss: 0.333102
   Number of active neurons: 4
 >> iter 21000, loss: 0.269243
 >> iter 22000, loss: 0.301851
 >> iter 23000, loss: 0.377411
 >> iter 24000, loss: 0.231699
 >> iter 25000, loss: 0.318132
 >> iter 26000, loss: 0.280860
 >> iter 27000, loss: 0.423753
 >> iter 28000, loss: 0.325584
 >> iter 29000, loss: 0.384095
 >> iter 30000, loss: 0.265503
   Number of active neurons: 4
 >> iter 31000, loss: 0.183469
 >> iter 32000, loss: 0.255275
 >> iter 33000, loss: 0.161956
 >> iter 34000, loss: 0.256570
 >> iter 35000, loss: 0.241113
 >> iter 36000, loss: 0.178905
 >> iter 37000, loss: 0.132598
 >> iter 38000, loss: 0.120508
 >> iter 39000, loss: 0.153763
 >> iter 40000, loss: 0.253140
   Number of active neurons: 3
 >> iter 41000, loss: 0.187959
 >> iter 42000, loss: 0.158484
 >> iter 43000, loss: 0.164992
 >> iter 44000, loss: 0.117450
 >> iter 45000, loss: 0.212488
 >> iter 46000, loss: 0.231786
 >> iter 47000, loss: 0.370047
 >> iter 48000, loss: 0.331657
 >> iter 49000, loss: 0.151422
 >> iter 50000, loss: 0.244048
   Number of active neurons: 3
 >> iter 51000, loss: 0.360745
 >> iter 52000, loss: 0.244691
 >> iter 53000, loss: 0.121394
 >> iter 54000, loss: 0.158998
 >> iter 55000, loss: 0.188741
 >> iter 56000, loss: 0.184150
 >> iter 57000, loss: 0.181924
 >> iter 58000, loss: 0.123289
 >> iter 59000, loss: 0.199735
 >> iter 60000, loss: 0.231187
   Number of active neurons: 3
 >> iter 61000, loss: 0.331087
 >> iter 62000, loss: 0.224888
 >> iter 63000, loss: 0.235057
 >> iter 64000, loss: 0.196957
 >> iter 65000, loss: 0.196719
 >> iter 66000, loss: 0.463420
 >> iter 67000, loss: 0.417641
 >> iter 68000, loss: 0.439273
 >> iter 69000, loss: 0.211326
 >> iter 70000, loss: 0.319950
   Number of active neurons: 3
 >> iter 71000, loss: 0.292638
 >> iter 72000, loss: 0.177665
 >> iter 73000, loss: 0.353823
 >> iter 74000, loss: 0.319050
 >> iter 75000, loss: 0.372438
 >> iter 76000, loss: 0.218011
 >> iter 77000, loss: 0.142243
 >> iter 78000, loss: 0.197448
 >> iter 79000, loss: 0.177435
 >> iter 80000, loss: 0.340949
   Number of active neurons: 3
 >> iter 81000, loss: 0.245924
 >> iter 82000, loss: 0.291152
 >> iter 83000, loss: 0.474382
 >> iter 84000, loss: 0.359568
 >> iter 85000, loss: 0.283446
 >> iter 86000, loss: 0.267294
 >> iter 87000, loss: 0.293560
 >> iter 88000, loss: 0.327688
 >> iter 89000, loss: 0.317083
 >> iter 90000, loss: 0.264651
   Number of active neurons: 3
 >> iter 91000, loss: 0.175606
 >> iter 92000, loss: 0.233946
 >> iter 93000, loss: 0.227309
 >> iter 94000, loss: 0.311493
 >> iter 95000, loss: 0.445773
 >> iter 96000, loss: 0.379664
 >> iter 97000, loss: 0.287432
 >> iter 98000, loss: 0.209402
 >> iter 99000, loss: 0.213949
 >> iter 100000, loss: 0.228007
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.261595
 >> iter 2000, loss: 9.846681
 >> iter 3000, loss: 4.269476
 >> iter 4000, loss: 2.032149
 >> iter 5000, loss: 1.189496
 >> iter 6000, loss: 0.724907
 >> iter 7000, loss: 0.855199
 >> iter 8000, loss: 0.628322
 >> iter 9000, loss: 0.578428
 >> iter 10000, loss: 0.587948
   Number of active neurons: 4
 >> iter 11000, loss: 0.357709
 >> iter 12000, loss: 0.478848
 >> iter 13000, loss: 0.433289
 >> iter 14000, loss: 0.485488
 >> iter 15000, loss: 0.414559
 >> iter 16000, loss: 0.310410
 >> iter 17000, loss: 0.205679
 >> iter 18000, loss: 0.185834
 >> iter 19000, loss: 0.189754
 >> iter 20000, loss: 0.160751
   Number of active neurons: 3
 >> iter 21000, loss: 0.186448
 >> iter 22000, loss: 0.459668
 >> iter 23000, loss: 0.483537
 >> iter 24000, loss: 0.331676
 >> iter 25000, loss: 0.305385
 >> iter 26000, loss: 0.252018
 >> iter 27000, loss: 0.342561
 >> iter 28000, loss: 0.262305
 >> iter 29000, loss: 0.486309
 >> iter 30000, loss: 0.236109
   Number of active neurons: 3
 >> iter 31000, loss: 0.382708
 >> iter 32000, loss: 0.367756
 >> iter 33000, loss: 0.500110
 >> iter 34000, loss: 0.296391
 >> iter 35000, loss: 0.197718
 >> iter 36000, loss: 0.315337
 >> iter 37000, loss: 0.196730
 >> iter 38000, loss: 0.137619
 >> iter 39000, loss: 0.182086
 >> iter 40000, loss: 0.146986
   Number of active neurons: 3
 >> iter 41000, loss: 0.299538
 >> iter 42000, loss: 0.469673
 >> iter 43000, loss: 0.311143
 >> iter 44000, loss: 0.372212
 >> iter 45000, loss: 0.275083
 >> iter 46000, loss: 0.416674
 >> iter 47000, loss: 0.239806
 >> iter 48000, loss: 0.170540
 >> iter 49000, loss: 0.411545
 >> iter 50000, loss: 0.274088
   Number of active neurons: 3
 >> iter 51000, loss: 0.293179
 >> iter 52000, loss: 0.329522
 >> iter 53000, loss: 0.278179
 >> iter 54000, loss: 0.437318
 >> iter 55000, loss: 0.305308
 >> iter 56000, loss: 0.304095
 >> iter 57000, loss: 0.207505
 >> iter 58000, loss: 0.257754
 >> iter 59000, loss: 0.308045
 >> iter 60000, loss: 0.221186
   Number of active neurons: 3
 >> iter 61000, loss: 0.484943
 >> iter 62000, loss: 0.304570
 >> iter 63000, loss: 0.189006
 >> iter 64000, loss: 0.338399
 >> iter 65000, loss: 0.229753
 >> iter 66000, loss: 0.257725
 >> iter 67000, loss: 0.293586
 >> iter 68000, loss: 0.213789
 >> iter 69000, loss: 0.192799
 >> iter 70000, loss: 0.259196
   Number of active neurons: 3
 >> iter 71000, loss: 0.359915
 >> iter 72000, loss: 0.190848
 >> iter 73000, loss: 0.131232
 >> iter 74000, loss: 0.212120
 >> iter 75000, loss: 0.331711
 >> iter 76000, loss: 0.335278
 >> iter 77000, loss: 0.371447
 >> iter 78000, loss: 0.307981
 >> iter 79000, loss: 0.328246
 >> iter 80000, loss: 0.330935
   Number of active neurons: 3
 >> iter 81000, loss: 0.301775
 >> iter 82000, loss: 0.200946
 >> iter 83000, loss: 0.360313
 >> iter 84000, loss: 0.266640
 >> iter 85000, loss: 0.312018
 >> iter 86000, loss: 0.307854
 >> iter 87000, loss: 0.324808
 >> iter 88000, loss: 0.218793
 >> iter 89000, loss: 0.258388
 >> iter 90000, loss: 0.136289
   Number of active neurons: 3
 >> iter 91000, loss: 0.169162
 >> iter 92000, loss: 0.125673
 >> iter 93000, loss: 0.245786
 >> iter 94000, loss: 0.379584
 >> iter 95000, loss: 0.317181
 >> iter 96000, loss: 0.505497
 >> iter 97000, loss: 0.341163
 >> iter 98000, loss: 0.369288
 >> iter 99000, loss: 0.266022
 >> iter 100000, loss: 0.190326
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.094339
 >> iter 2000, loss: 9.158249
 >> iter 3000, loss: 3.781902
 >> iter 4000, loss: 1.878403
 >> iter 5000, loss: 1.006591
 >> iter 6000, loss: 0.458117
 >> iter 7000, loss: 0.600037
 >> iter 8000, loss: 0.298292
 >> iter 9000, loss: 0.386734
 >> iter 10000, loss: 0.501480
   Number of active neurons: 6
 >> iter 11000, loss: 0.595299
 >> iter 12000, loss: 0.364905
 >> iter 13000, loss: 0.245761
 >> iter 14000, loss: 0.155389
 >> iter 15000, loss: 0.348022
 >> iter 16000, loss: 0.250167
 >> iter 17000, loss: 0.284428
 >> iter 18000, loss: 0.275072
 >> iter 19000, loss: 0.192866
 >> iter 20000, loss: 0.160571
   Number of active neurons: 5
 >> iter 21000, loss: 0.237094
 >> iter 22000, loss: 0.313699
 >> iter 23000, loss: 0.304126
 >> iter 24000, loss: 0.474331
 >> iter 25000, loss: 0.341721
 >> iter 26000, loss: 0.251533
 >> iter 27000, loss: 0.311178
 >> iter 28000, loss: 0.343856
 >> iter 29000, loss: 0.367459
 >> iter 30000, loss: 0.302476
   Number of active neurons: 4
 >> iter 31000, loss: 0.364172
 >> iter 32000, loss: 0.192440
 >> iter 33000, loss: 0.284727
 >> iter 34000, loss: 0.245948
 >> iter 35000, loss: 0.250704
 >> iter 36000, loss: 0.252177
 >> iter 37000, loss: 0.268720
 >> iter 38000, loss: 0.264853
 >> iter 39000, loss: 0.198843
 >> iter 40000, loss: 0.319658
   Number of active neurons: 4
 >> iter 41000, loss: 0.231988
 >> iter 42000, loss: 0.196301
 >> iter 43000, loss: 0.252450
 >> iter 44000, loss: 0.307643
 >> iter 45000, loss: 0.204359
 >> iter 46000, loss: 0.175608
 >> iter 47000, loss: 0.407167
 >> iter 48000, loss: 0.275202
 >> iter 49000, loss: 0.200054
 >> iter 50000, loss: 0.226287
   Number of active neurons: 4
 >> iter 51000, loss: 0.234621
 >> iter 52000, loss: 0.255478
 >> iter 53000, loss: 0.182537
 >> iter 54000, loss: 0.255476
 >> iter 55000, loss: 0.327014
 >> iter 56000, loss: 0.290575
 >> iter 57000, loss: 0.294724
 >> iter 58000, loss: 0.175619
 >> iter 59000, loss: 0.170100
 >> iter 60000, loss: 0.251025
   Number of active neurons: 4
 >> iter 61000, loss: 0.279557
 >> iter 62000, loss: 0.258250
 >> iter 63000, loss: 0.181426
 >> iter 64000, loss: 0.215248
 >> iter 65000, loss: 0.376696
 >> iter 66000, loss: 0.224971
 >> iter 67000, loss: 0.347601
 >> iter 68000, loss: 0.260965
 >> iter 69000, loss: 0.276061
 >> iter 70000, loss: 0.245575
   Number of active neurons: 3
 >> iter 71000, loss: 0.143459
 >> iter 72000, loss: 0.225479
 >> iter 73000, loss: 0.405712
 >> iter 74000, loss: 0.440922
 >> iter 75000, loss: 0.228648
 >> iter 76000, loss: 0.120801
 >> iter 77000, loss: 0.069912
 >> iter 78000, loss: 0.381790
 >> iter 79000, loss: 0.195742
 >> iter 80000, loss: 0.238853
   Number of active neurons: 3
 >> iter 81000, loss: 0.172818
 >> iter 82000, loss: 0.200169
 >> iter 83000, loss: 0.307151
 >> iter 84000, loss: 0.364421
 >> iter 85000, loss: 0.507651
 >> iter 86000, loss: 0.258647
 >> iter 87000, loss: 0.161392
 >> iter 88000, loss: 0.321159
 >> iter 89000, loss: 0.273035
 >> iter 90000, loss: 0.133295
   Number of active neurons: 3
 >> iter 91000, loss: 0.098548
 >> iter 92000, loss: 0.129684
 >> iter 93000, loss: 0.229828
 >> iter 94000, loss: 0.126041
 >> iter 95000, loss: 0.355396
 >> iter 96000, loss: 0.377473
 >> iter 97000, loss: 0.341701
 >> iter 98000, loss: 0.156648
 >> iter 99000, loss: 0.185031
 >> iter 100000, loss: 0.332965
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.295299
 >> iter 2000, loss: 10.296747
 >> iter 3000, loss: 5.289829
 >> iter 4000, loss: 2.803959
 >> iter 5000, loss: 1.567327
 >> iter 6000, loss: 0.973350
 >> iter 7000, loss: 0.734846
 >> iter 8000, loss: 0.383373
 >> iter 9000, loss: 0.455955
 >> iter 10000, loss: 0.465302
   Number of active neurons: 5
 >> iter 11000, loss: 0.544188
 >> iter 12000, loss: 0.680547
 >> iter 13000, loss: 0.650619
 >> iter 14000, loss: 0.516053
 >> iter 15000, loss: 0.595116
 >> iter 16000, loss: 0.394168
 >> iter 17000, loss: 0.606618
 >> iter 18000, loss: 0.556259
 >> iter 19000, loss: 0.607453
 >> iter 20000, loss: 0.578799
   Number of active neurons: 4
 >> iter 21000, loss: 0.300098
 >> iter 22000, loss: 0.323343
 >> iter 23000, loss: 0.310674
 >> iter 24000, loss: 0.421143
 >> iter 25000, loss: 0.406715
 >> iter 26000, loss: 0.554117
 >> iter 27000, loss: 0.449848
 >> iter 28000, loss: 0.333558
 >> iter 29000, loss: 0.511888
 >> iter 30000, loss: 0.398241
   Number of active neurons: 4
 >> iter 31000, loss: 0.343638
 >> iter 32000, loss: 0.386483
 >> iter 33000, loss: 0.572575
 >> iter 34000, loss: 0.483355
 >> iter 35000, loss: 0.382228
 >> iter 36000, loss: 0.455918
 >> iter 37000, loss: 0.342414
 >> iter 38000, loss: 0.568125
 >> iter 39000, loss: 0.539955
 >> iter 40000, loss: 0.567365
   Number of active neurons: 4
 >> iter 41000, loss: 0.404168
 >> iter 42000, loss: 0.429717
 >> iter 43000, loss: 0.332292
 >> iter 44000, loss: 0.445200
 >> iter 45000, loss: 0.635775
 >> iter 46000, loss: 0.469865
 >> iter 47000, loss: 0.423335
 >> iter 48000, loss: 0.445717
 >> iter 49000, loss: 0.426894
 >> iter 50000, loss: 0.525322
   Number of active neurons: 4
 >> iter 51000, loss: 0.406936
 >> iter 52000, loss: 0.404332
 >> iter 53000, loss: 0.552927
 >> iter 54000, loss: 0.377940
 >> iter 55000, loss: 0.426806
 >> iter 56000, loss: 0.415633
 >> iter 57000, loss: 0.317698
 >> iter 58000, loss: 0.278888
 >> iter 59000, loss: 0.259205
 >> iter 60000, loss: 0.402936
   Number of active neurons: 4
 >> iter 61000, loss: 0.544508
 >> iter 62000, loss: 0.532494
 >> iter 63000, loss: 0.304535
 >> iter 64000, loss: 0.546776
 >> iter 65000, loss: 0.383752
 >> iter 66000, loss: 0.419181
 >> iter 67000, loss: 0.519060
 >> iter 68000, loss: 0.454235
 >> iter 69000, loss: 0.586669
 >> iter 70000, loss: 0.511569
   Number of active neurons: 3
 >> iter 71000, loss: 0.350405
 >> iter 72000, loss: 0.490226
 >> iter 73000, loss: 0.442238
 >> iter 74000, loss: 0.440035
 >> iter 75000, loss: 0.480212
 >> iter 76000, loss: 0.402116
 >> iter 77000, loss: 0.275887
 >> iter 78000, loss: 0.433795
 >> iter 79000, loss: 0.367129
 >> iter 80000, loss: 0.246814
   Number of active neurons: 3
 >> iter 81000, loss: 0.500466
 >> iter 82000, loss: 0.674655
 >> iter 83000, loss: 0.495160
 >> iter 84000, loss: 0.402322
 >> iter 85000, loss: 0.518344
 >> iter 86000, loss: 0.437782
 >> iter 87000, loss: 0.480759
 >> iter 88000, loss: 0.435930
 >> iter 89000, loss: 0.731834
 >> iter 90000, loss: 0.558185
   Number of active neurons: 3
 >> iter 91000, loss: 0.627063
 >> iter 92000, loss: 0.553336
 >> iter 93000, loss: 0.546315
 >> iter 94000, loss: 0.537169
 >> iter 95000, loss: 0.773487
 >> iter 96000, loss: 0.689552
 >> iter 97000, loss: 0.539492
 >> iter 98000, loss: 0.596351
 >> iter 99000, loss: 0.517072
 >> iter 100000, loss: 0.458479
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.508779
 >> iter 2000, loss: 8.467269
 >> iter 3000, loss: 4.026885
 >> iter 4000, loss: 1.924374
 >> iter 5000, loss: 1.345299
 >> iter 6000, loss: 0.864698
 >> iter 7000, loss: 0.501513
 >> iter 8000, loss: 0.635462
 >> iter 9000, loss: 0.542615
 >> iter 10000, loss: 0.424299
   Number of active neurons: 3
 >> iter 11000, loss: 0.383115
 >> iter 12000, loss: 0.305631
 >> iter 13000, loss: 0.337781
 >> iter 14000, loss: 0.330439
 >> iter 15000, loss: 0.236252
 >> iter 16000, loss: 0.214236
 >> iter 17000, loss: 0.382698
 >> iter 18000, loss: 0.319054
 >> iter 19000, loss: 0.395026
 >> iter 20000, loss: 0.314978
   Number of active neurons: 3
 >> iter 21000, loss: 0.250918
 >> iter 22000, loss: 0.377982
 >> iter 23000, loss: 0.458538
 >> iter 24000, loss: 0.413957
 >> iter 25000, loss: 0.380878
 >> iter 26000, loss: 0.288912
 >> iter 27000, loss: 0.271417
 >> iter 28000, loss: 0.238706
 >> iter 29000, loss: 0.284985
 >> iter 30000, loss: 0.208874
   Number of active neurons: 3
 >> iter 31000, loss: 0.174083
 >> iter 32000, loss: 0.350126
 >> iter 33000, loss: 0.281062
 >> iter 34000, loss: 0.489859
 >> iter 35000, loss: 0.229985
 >> iter 36000, loss: 0.227478
 >> iter 37000, loss: 0.540332
 >> iter 38000, loss: 0.499872
 >> iter 39000, loss: 0.329263
 >> iter 40000, loss: 0.226410
   Number of active neurons: 3
 >> iter 41000, loss: 0.136970
 >> iter 42000, loss: 0.373575
 >> iter 43000, loss: 0.318615
 >> iter 44000, loss: 0.256371
 >> iter 45000, loss: 0.231937
 >> iter 46000, loss: 0.302857
 >> iter 47000, loss: 0.343424
 >> iter 48000, loss: 0.502451
 >> iter 49000, loss: 0.348341
 >> iter 50000, loss: 0.237573
   Number of active neurons: 3
 >> iter 51000, loss: 0.369277
 >> iter 52000, loss: 0.342504
 >> iter 53000, loss: 0.221122
 >> iter 54000, loss: 0.155986
 >> iter 55000, loss: 0.205574
 >> iter 56000, loss: 0.329311
 >> iter 57000, loss: 0.249890
 >> iter 58000, loss: 0.137233
 >> iter 59000, loss: 0.250517
 >> iter 60000, loss: 0.315140
   Number of active neurons: 3
 >> iter 61000, loss: 0.239224
 >> iter 62000, loss: 0.161506
 >> iter 63000, loss: 0.255341
 >> iter 64000, loss: 0.145817
 >> iter 65000, loss: 0.240620
 >> iter 66000, loss: 0.230894
 >> iter 67000, loss: 0.323914
 >> iter 68000, loss: 0.201449
 >> iter 69000, loss: 0.292115
 >> iter 70000, loss: 0.242523
   Number of active neurons: 3
 >> iter 71000, loss: 0.258440
 >> iter 72000, loss: 0.445597
 >> iter 73000, loss: 0.435592
 >> iter 74000, loss: 0.506611
 >> iter 75000, loss: 0.355704
 >> iter 76000, loss: 0.355386
 >> iter 77000, loss: 0.329214
 >> iter 78000, loss: 0.343900
 >> iter 79000, loss: 0.374489
 >> iter 80000, loss: 0.226983
   Number of active neurons: 3
 >> iter 81000, loss: 0.260652
 >> iter 82000, loss: 0.195461
 >> iter 83000, loss: 0.269840
 >> iter 84000, loss: 0.199680
 >> iter 85000, loss: 0.139002
 >> iter 86000, loss: 0.105991
 >> iter 87000, loss: 0.104620
 >> iter 88000, loss: 0.268141
 >> iter 89000, loss: 0.224231
 >> iter 90000, loss: 0.271225
   Number of active neurons: 3
 >> iter 91000, loss: 0.303520
 >> iter 92000, loss: 0.270672
 >> iter 93000, loss: 0.215698
 >> iter 94000, loss: 0.136583
 >> iter 95000, loss: 0.135558
 >> iter 96000, loss: 0.113915
 >> iter 97000, loss: 0.303286
 >> iter 98000, loss: 0.407189
 >> iter 99000, loss: 0.309745
 >> iter 100000, loss: 0.149988
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.166553
 >> iter 2000, loss: 8.423182
 >> iter 3000, loss: 3.836801
 >> iter 4000, loss: 1.889851
 >> iter 5000, loss: 1.109992
 >> iter 6000, loss: 0.684284
 >> iter 7000, loss: 0.469628
 >> iter 8000, loss: 0.408585
 >> iter 9000, loss: 0.447072
 >> iter 10000, loss: 0.267549
   Number of active neurons: 3
 >> iter 11000, loss: 0.214963
 >> iter 12000, loss: 0.361030
 >> iter 13000, loss: 0.230523
 >> iter 14000, loss: 0.352393
 >> iter 15000, loss: 0.206294
 >> iter 16000, loss: 0.243591
 >> iter 17000, loss: 0.231941
 >> iter 18000, loss: 0.170928
 >> iter 19000, loss: 0.177879
 >> iter 20000, loss: 0.210355
   Number of active neurons: 3
 >> iter 21000, loss: 0.335567
 >> iter 22000, loss: 0.506048
 >> iter 23000, loss: 0.428801
 >> iter 24000, loss: 0.352623
 >> iter 25000, loss: 0.332268
 >> iter 26000, loss: 0.268020
 >> iter 27000, loss: 0.266641
 >> iter 28000, loss: 0.217806
 >> iter 29000, loss: 0.198462
 >> iter 30000, loss: 0.298222
   Number of active neurons: 3
 >> iter 31000, loss: 0.307515
 >> iter 32000, loss: 0.274796
 >> iter 33000, loss: 0.527477
 >> iter 34000, loss: 0.335100
 >> iter 35000, loss: 0.218833
 >> iter 36000, loss: 0.182736
 >> iter 37000, loss: 0.299943
 >> iter 38000, loss: 0.211506
 >> iter 39000, loss: 0.227282
 >> iter 40000, loss: 0.261893
   Number of active neurons: 3
 >> iter 41000, loss: 0.334452
 >> iter 42000, loss: 0.299564
 >> iter 43000, loss: 0.210161
 >> iter 44000, loss: 0.258532
 >> iter 45000, loss: 0.375601
 >> iter 46000, loss: 0.335676
 >> iter 47000, loss: 0.345638
 >> iter 48000, loss: 0.377508
 >> iter 49000, loss: 0.361329
 >> iter 50000, loss: 0.254216
   Number of active neurons: 3
 >> iter 51000, loss: 0.432734
 >> iter 52000, loss: 0.541206
 >> iter 53000, loss: 0.380849
 >> iter 54000, loss: 0.301055
 >> iter 55000, loss: 0.195470
 >> iter 56000, loss: 0.166637
 >> iter 57000, loss: 0.171308
 >> iter 58000, loss: 0.248681
 >> iter 59000, loss: 0.350530
 >> iter 60000, loss: 0.227769
   Number of active neurons: 3
 >> iter 61000, loss: 0.474934
 >> iter 62000, loss: 0.284394
 >> iter 63000, loss: 0.153312
 >> iter 64000, loss: 0.122142
 >> iter 65000, loss: 0.132323
 >> iter 66000, loss: 0.309046
 >> iter 67000, loss: 0.406106
 >> iter 68000, loss: 0.359083
 >> iter 69000, loss: 0.274104
 >> iter 70000, loss: 0.274139
   Number of active neurons: 3
 >> iter 71000, loss: 0.422872
 >> iter 72000, loss: 0.341932
 >> iter 73000, loss: 0.325336
 >> iter 74000, loss: 0.230477
 >> iter 75000, loss: 0.223474
 >> iter 76000, loss: 0.218687
 >> iter 77000, loss: 0.165915
 >> iter 78000, loss: 0.213788
 >> iter 79000, loss: 0.306957
 >> iter 80000, loss: 0.280117
   Number of active neurons: 3
 >> iter 81000, loss: 0.219736
 >> iter 82000, loss: 0.210740
 >> iter 83000, loss: 0.202417
 >> iter 84000, loss: 0.200786
 >> iter 85000, loss: 0.245058
 >> iter 86000, loss: 0.204782
 >> iter 87000, loss: 0.196364
 >> iter 88000, loss: 0.141222
 >> iter 89000, loss: 0.207118
 >> iter 90000, loss: 0.222476
   Number of active neurons: 3
 >> iter 91000, loss: 0.291921
 >> iter 92000, loss: 0.198042
 >> iter 93000, loss: 0.295120
 >> iter 94000, loss: 0.273705
 >> iter 95000, loss: 0.278507
 >> iter 96000, loss: 0.174987
 >> iter 97000, loss: 0.180134
 >> iter 98000, loss: 0.138051
 >> iter 99000, loss: 0.361311
 >> iter 100000, loss: 0.320129
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.932054
 >> iter 2000, loss: 9.006939
 >> iter 3000, loss: 4.163819
 >> iter 4000, loss: 1.992496
 >> iter 5000, loss: 1.194950
 >> iter 6000, loss: 0.887152
 >> iter 7000, loss: 0.656569
 >> iter 8000, loss: 0.756643
 >> iter 9000, loss: 0.611986
 >> iter 10000, loss: 0.448322
   Number of active neurons: 4
 >> iter 11000, loss: 0.441619
 >> iter 12000, loss: 0.582889
 >> iter 13000, loss: 0.582392
 >> iter 14000, loss: 0.481934
 >> iter 15000, loss: 0.570492
 >> iter 16000, loss: 0.442522
 >> iter 17000, loss: 0.489375
 >> iter 18000, loss: 0.559174
 >> iter 19000, loss: 0.545941
 >> iter 20000, loss: 0.540956
   Number of active neurons: 4
 >> iter 21000, loss: 0.599770
 >> iter 22000, loss: 0.371200
 >> iter 23000, loss: 0.417336
 >> iter 24000, loss: 0.356269
 >> iter 25000, loss: 0.627288
 >> iter 26000, loss: 0.454947
 >> iter 27000, loss: 0.492409
 >> iter 28000, loss: 0.636554
 >> iter 29000, loss: 0.415294
 >> iter 30000, loss: 0.357016
   Number of active neurons: 4
 >> iter 31000, loss: 0.340815
 >> iter 32000, loss: 0.594856
 >> iter 33000, loss: 0.554581
 >> iter 34000, loss: 0.385070
 >> iter 35000, loss: 0.278883
 >> iter 36000, loss: 0.478498
 >> iter 37000, loss: 0.463617
 >> iter 38000, loss: 0.271481
 >> iter 39000, loss: 0.329976
 >> iter 40000, loss: 0.574680
   Number of active neurons: 4
 >> iter 41000, loss: 0.444648
 >> iter 42000, loss: 0.413404
 >> iter 43000, loss: 0.451771
 >> iter 44000, loss: 0.466132
 >> iter 45000, loss: 0.303420
 >> iter 46000, loss: 0.553323
 >> iter 47000, loss: 0.376522
 >> iter 48000, loss: 0.381084
 >> iter 49000, loss: 0.327854
 >> iter 50000, loss: 0.240190
   Number of active neurons: 4
 >> iter 51000, loss: 0.357240
 >> iter 52000, loss: 0.512675
 >> iter 53000, loss: 0.453868
 >> iter 54000, loss: 0.450450
 >> iter 55000, loss: 0.546310
 >> iter 56000, loss: 0.382121
 >> iter 57000, loss: 0.207589
 >> iter 58000, loss: 0.396984
 >> iter 59000, loss: 0.210277
 >> iter 60000, loss: 0.355070
   Number of active neurons: 4
 >> iter 61000, loss: 0.356104
 >> iter 62000, loss: 0.437859
 >> iter 63000, loss: 0.336834
 >> iter 64000, loss: 0.246821
 >> iter 65000, loss: 0.354911
 >> iter 66000, loss: 0.398210
 >> iter 67000, loss: 0.447866
 >> iter 68000, loss: 0.390437
 >> iter 69000, loss: 0.327823
 >> iter 70000, loss: 0.420328
   Number of active neurons: 4
 >> iter 71000, loss: 0.475316
 >> iter 72000, loss: 0.499235
 >> iter 73000, loss: 0.534273
 >> iter 74000, loss: 0.438045
 >> iter 75000, loss: 0.244114
 >> iter 76000, loss: 0.313963
 >> iter 77000, loss: 0.328853
 >> iter 78000, loss: 0.366189
 >> iter 79000, loss: 0.497224
 >> iter 80000, loss: 0.599369
   Number of active neurons: 4
 >> iter 81000, loss: 0.659791
 >> iter 82000, loss: 0.444243
 >> iter 83000, loss: 0.563223
 >> iter 84000, loss: 0.448606
 >> iter 85000, loss: 0.412043
 >> iter 86000, loss: 0.426609
 >> iter 87000, loss: 0.339944
 >> iter 88000, loss: 0.388259
 >> iter 89000, loss: 0.255556
 >> iter 90000, loss: 0.437115
   Number of active neurons: 4
 >> iter 91000, loss: 0.489010
 >> iter 92000, loss: 0.515559
 >> iter 93000, loss: 0.738372
 >> iter 94000, loss: 0.366582
 >> iter 95000, loss: 0.219187
 >> iter 96000, loss: 0.310800
 >> iter 97000, loss: 0.526485
 >> iter 98000, loss: 0.433796
 >> iter 99000, loss: 0.350905
 >> iter 100000, loss: 0.472313
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.872076
 >> iter 2000, loss: 9.148872
 >> iter 3000, loss: 4.246181
 >> iter 4000, loss: 1.897091
 >> iter 5000, loss: 1.131628
 >> iter 6000, loss: 0.662453
 >> iter 7000, loss: 0.381070
 >> iter 8000, loss: 0.259563
 >> iter 9000, loss: 0.241087
 >> iter 10000, loss: 0.581287
   Number of active neurons: 4
 >> iter 11000, loss: 0.472036
 >> iter 12000, loss: 0.327558
 >> iter 13000, loss: 0.436417
 >> iter 14000, loss: 0.248418
 >> iter 15000, loss: 0.272011
 >> iter 16000, loss: 0.221810
 >> iter 17000, loss: 0.362464
 >> iter 18000, loss: 0.232974
 >> iter 19000, loss: 0.132327
 >> iter 20000, loss: 0.262983
   Number of active neurons: 4
 >> iter 21000, loss: 0.272990
 >> iter 22000, loss: 0.308462
 >> iter 23000, loss: 0.181556
 >> iter 24000, loss: 0.351015
 >> iter 25000, loss: 0.390815
 >> iter 26000, loss: 0.301596
 >> iter 27000, loss: 0.176274
 >> iter 28000, loss: 0.227762
 >> iter 29000, loss: 0.212498
 >> iter 30000, loss: 0.358912
   Number of active neurons: 4
 >> iter 31000, loss: 0.286550
 >> iter 32000, loss: 0.261458
 >> iter 33000, loss: 0.403067
 >> iter 34000, loss: 0.338104
 >> iter 35000, loss: 0.303103
 >> iter 36000, loss: 0.282983
 >> iter 37000, loss: 0.278897
 >> iter 38000, loss: 0.235308
 >> iter 39000, loss: 0.433997
 >> iter 40000, loss: 0.278243
   Number of active neurons: 3
 >> iter 41000, loss: 0.312845
 >> iter 42000, loss: 0.184407
 >> iter 43000, loss: 0.193126
 >> iter 44000, loss: 0.321243
 >> iter 45000, loss: 0.335546
 >> iter 46000, loss: 0.237888
 >> iter 47000, loss: 0.261785
 >> iter 48000, loss: 0.260543
 >> iter 49000, loss: 0.335731
 >> iter 50000, loss: 0.283142
   Number of active neurons: 3
 >> iter 51000, loss: 0.229443
 >> iter 52000, loss: 0.256926
 >> iter 53000, loss: 0.171520
 >> iter 54000, loss: 0.189363
 >> iter 55000, loss: 0.249426
 >> iter 56000, loss: 0.163968
 >> iter 57000, loss: 0.257698
 >> iter 58000, loss: 0.284448
 >> iter 59000, loss: 0.259151
 >> iter 60000, loss: 0.214315
   Number of active neurons: 3
 >> iter 61000, loss: 0.288852
 >> iter 62000, loss: 0.261378
 >> iter 63000, loss: 0.234678
 >> iter 64000, loss: 0.208082
 >> iter 65000, loss: 0.155780
 >> iter 66000, loss: 0.381077
 >> iter 67000, loss: 0.242057
 >> iter 68000, loss: 0.130543
 >> iter 69000, loss: 0.265333
 >> iter 70000, loss: 0.288217
   Number of active neurons: 3
 >> iter 71000, loss: 0.341662
 >> iter 72000, loss: 0.226942
 >> iter 73000, loss: 0.216127
 >> iter 74000, loss: 0.197057
 >> iter 75000, loss: 0.317563
 >> iter 76000, loss: 0.378548
 >> iter 77000, loss: 0.228523
 >> iter 78000, loss: 0.116713
 >> iter 79000, loss: 0.205813
 >> iter 80000, loss: 0.226860
   Number of active neurons: 3
 >> iter 81000, loss: 0.185109
 >> iter 82000, loss: 0.200089
 >> iter 83000, loss: 0.196313
 >> iter 84000, loss: 0.204171
 >> iter 85000, loss: 0.190480
 >> iter 86000, loss: 0.240670
 >> iter 87000, loss: 0.181811
 >> iter 88000, loss: 0.163583
 >> iter 89000, loss: 0.315211
 >> iter 90000, loss: 0.191216
   Number of active neurons: 3
 >> iter 91000, loss: 0.189180
 >> iter 92000, loss: 0.366984
 >> iter 93000, loss: 0.261542
 >> iter 94000, loss: 0.297050
 >> iter 95000, loss: 0.286113
 >> iter 96000, loss: 0.375744
 >> iter 97000, loss: 0.361777
 >> iter 98000, loss: 0.238727
 >> iter 99000, loss: 0.328861
 >> iter 100000, loss: 0.226094
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.679077
 >> iter 2000, loss: 8.350900
 >> iter 3000, loss: 3.637422
 >> iter 4000, loss: 1.758691
 >> iter 5000, loss: 0.959162
 >> iter 6000, loss: 0.558623
 >> iter 7000, loss: 0.648039
 >> iter 8000, loss: 0.458550
 >> iter 9000, loss: 0.310469
 >> iter 10000, loss: 0.505288
   Number of active neurons: 4
 >> iter 11000, loss: 0.537173
 >> iter 12000, loss: 0.322349
 >> iter 13000, loss: 0.288007
 >> iter 14000, loss: 0.193235
 >> iter 15000, loss: 0.360813
 >> iter 16000, loss: 0.354125
 >> iter 17000, loss: 0.503761
 >> iter 18000, loss: 0.344355
 >> iter 19000, loss: 0.354088
 >> iter 20000, loss: 0.263769
   Number of active neurons: 3
 >> iter 21000, loss: 0.238255
 >> iter 22000, loss: 0.214553
 >> iter 23000, loss: 0.256045
 >> iter 24000, loss: 0.265856
 >> iter 25000, loss: 0.268057
 >> iter 26000, loss: 0.351135
 >> iter 27000, loss: 0.294847
 >> iter 28000, loss: 0.255766
 >> iter 29000, loss: 0.288358
 >> iter 30000, loss: 0.377443
   Number of active neurons: 3
 >> iter 31000, loss: 0.387921
 >> iter 32000, loss: 0.402760
 >> iter 33000, loss: 0.276813
 >> iter 34000, loss: 0.205147
 >> iter 35000, loss: 0.216062
 >> iter 36000, loss: 0.261456
 >> iter 37000, loss: 0.177172
 >> iter 38000, loss: 0.261547
 >> iter 39000, loss: 0.268057
 >> iter 40000, loss: 0.316800
   Number of active neurons: 3
 >> iter 41000, loss: 0.389637
 >> iter 42000, loss: 0.394831
 >> iter 43000, loss: 0.227806
 >> iter 44000, loss: 0.239688
 >> iter 45000, loss: 0.488021
 >> iter 46000, loss: 0.288853
 >> iter 47000, loss: 0.225377
 >> iter 48000, loss: 0.275026
 >> iter 49000, loss: 0.290392
 >> iter 50000, loss: 0.397319
   Number of active neurons: 3
 >> iter 51000, loss: 0.467581
 >> iter 52000, loss: 0.349271
 >> iter 53000, loss: 0.337880
 >> iter 54000, loss: 0.230010
 >> iter 55000, loss: 0.229595
 >> iter 56000, loss: 0.221962
 >> iter 57000, loss: 0.218257
 >> iter 58000, loss: 0.269960
 >> iter 59000, loss: 0.297657
 >> iter 60000, loss: 0.208338
   Number of active neurons: 3
 >> iter 61000, loss: 0.272130
 >> iter 62000, loss: 0.285302
 >> iter 63000, loss: 0.203706
 >> iter 64000, loss: 0.207643
 >> iter 65000, loss: 0.175092
 >> iter 66000, loss: 0.272622
 >> iter 67000, loss: 0.403059
 >> iter 68000, loss: 0.295650
 >> iter 69000, loss: 0.295295
 >> iter 70000, loss: 0.148937
   Number of active neurons: 3
 >> iter 71000, loss: 0.390767
 >> iter 72000, loss: 0.180410
 >> iter 73000, loss: 0.392228
 >> iter 74000, loss: 0.229886
 >> iter 75000, loss: 0.320922
 >> iter 76000, loss: 0.285958
 >> iter 77000, loss: 0.277624
 >> iter 78000, loss: 0.249367
 >> iter 79000, loss: 0.277637
 >> iter 80000, loss: 0.224460
   Number of active neurons: 3
 >> iter 81000, loss: 0.440149
 >> iter 82000, loss: 0.368448
 >> iter 83000, loss: 0.171269
 >> iter 84000, loss: 0.174443
 >> iter 85000, loss: 0.213023
 >> iter 86000, loss: 0.212988
 >> iter 87000, loss: 0.219744
 >> iter 88000, loss: 0.205291
 >> iter 89000, loss: 0.372818
 >> iter 90000, loss: 0.246628
   Number of active neurons: 3
 >> iter 91000, loss: 0.303110
 >> iter 92000, loss: 0.331510
 >> iter 93000, loss: 0.177980
 >> iter 94000, loss: 0.146717
 >> iter 95000, loss: 0.221129
 >> iter 96000, loss: 0.196706
 >> iter 97000, loss: 0.149014
 >> iter 98000, loss: 0.125297
 >> iter 99000, loss: 0.137088
 >> iter 100000, loss: 0.237962
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.704203
 >> iter 2000, loss: 8.698793
 >> iter 3000, loss: 3.928993
 >> iter 4000, loss: 1.773057
 >> iter 5000, loss: 0.977638
 >> iter 6000, loss: 0.483795
 >> iter 7000, loss: 0.561096
 >> iter 8000, loss: 0.565018
 >> iter 9000, loss: 0.529708
 >> iter 10000, loss: 0.521487
   Number of active neurons: 4
 >> iter 11000, loss: 0.405818
 >> iter 12000, loss: 0.415056
 >> iter 13000, loss: 0.309384
 >> iter 14000, loss: 0.310039
 >> iter 15000, loss: 0.268549
 >> iter 16000, loss: 0.298798
 >> iter 17000, loss: 0.323202
 >> iter 18000, loss: 0.337252
 >> iter 19000, loss: 0.299355
 >> iter 20000, loss: 0.177148
   Number of active neurons: 4
 >> iter 21000, loss: 0.243919
 >> iter 22000, loss: 0.237375
 >> iter 23000, loss: 0.452489
 >> iter 24000, loss: 0.262787
 >> iter 25000, loss: 0.194520
 >> iter 26000, loss: 0.381179
 >> iter 27000, loss: 0.370717
 >> iter 28000, loss: 0.303572
 >> iter 29000, loss: 0.294142
 >> iter 30000, loss: 0.174547
   Number of active neurons: 4
 >> iter 31000, loss: 0.215168
 >> iter 32000, loss: 0.308428
 >> iter 33000, loss: 0.407018
 >> iter 34000, loss: 0.277442
 >> iter 35000, loss: 0.440170
 >> iter 36000, loss: 0.511548
 >> iter 37000, loss: 0.362354
 >> iter 38000, loss: 0.361176
 >> iter 39000, loss: 0.246764
 >> iter 40000, loss: 0.335535
   Number of active neurons: 4
 >> iter 41000, loss: 0.408628
 >> iter 42000, loss: 0.358961
 >> iter 43000, loss: 0.199088
 >> iter 44000, loss: 0.146128
 >> iter 45000, loss: 0.394609
 >> iter 46000, loss: 0.285699
 >> iter 47000, loss: 0.228103
 >> iter 48000, loss: 0.256191
 >> iter 49000, loss: 0.420199
 >> iter 50000, loss: 0.336743
   Number of active neurons: 4
 >> iter 51000, loss: 0.291075
 >> iter 52000, loss: 0.245517
 >> iter 53000, loss: 0.309634
 >> iter 54000, loss: 0.460810
 >> iter 55000, loss: 0.320611
 >> iter 56000, loss: 0.278681
 >> iter 57000, loss: 0.369936
 >> iter 58000, loss: 0.466830
 >> iter 59000, loss: 0.424197
 >> iter 60000, loss: 0.422416
   Number of active neurons: 4
 >> iter 61000, loss: 0.334426
 >> iter 62000, loss: 0.447491
 >> iter 63000, loss: 0.467399
 >> iter 64000, loss: 0.481109
 >> iter 65000, loss: 0.354868
 >> iter 66000, loss: 0.482052
 >> iter 67000, loss: 0.395686
 >> iter 68000, loss: 0.356927
 >> iter 69000, loss: 0.315476
 >> iter 70000, loss: 0.449413
   Number of active neurons: 3
 >> iter 71000, loss: 0.402102
 >> iter 72000, loss: 0.306213
 >> iter 73000, loss: 0.367347
 >> iter 74000, loss: 0.316300
 >> iter 75000, loss: 0.217570
 >> iter 76000, loss: 0.392118
 >> iter 77000, loss: 0.352559
 >> iter 78000, loss: 0.373986
 >> iter 79000, loss: 0.310283
 >> iter 80000, loss: 0.368014
   Number of active neurons: 3
 >> iter 81000, loss: 0.322705
 >> iter 82000, loss: 0.243653
 >> iter 83000, loss: 0.298155
 >> iter 84000, loss: 0.390626
 >> iter 85000, loss: 0.236083
 >> iter 86000, loss: 0.365150
 >> iter 87000, loss: 0.216074
 >> iter 88000, loss: 0.217237
 >> iter 89000, loss: 0.326214
 >> iter 90000, loss: 0.241047
   Number of active neurons: 3
 >> iter 91000, loss: 0.139979
 >> iter 92000, loss: 0.407475
 >> iter 93000, loss: 0.261435
 >> iter 94000, loss: 0.312402
 >> iter 95000, loss: 0.196480
 >> iter 96000, loss: 0.260873
 >> iter 97000, loss: 0.247178
 >> iter 98000, loss: 0.429346
 >> iter 99000, loss: 0.299002
 >> iter 100000, loss: 0.200974
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.763655
 >> iter 2000, loss: 8.964440
 >> iter 3000, loss: 3.875191
 >> iter 4000, loss: 1.872035
 >> iter 5000, loss: 0.897998
 >> iter 6000, loss: 0.493427
 >> iter 7000, loss: 0.416589
 >> iter 8000, loss: 0.389162
 >> iter 9000, loss: 0.358260
 >> iter 10000, loss: 0.308054
   Number of active neurons: 4
 >> iter 11000, loss: 0.566355
 >> iter 12000, loss: 0.459117
 >> iter 13000, loss: 0.392534
 >> iter 14000, loss: 0.366536
 >> iter 15000, loss: 0.373316
 >> iter 16000, loss: 0.201967
 >> iter 17000, loss: 0.278380
 >> iter 18000, loss: 0.439525
 >> iter 19000, loss: 0.237062
 >> iter 20000, loss: 0.397834
   Number of active neurons: 4
 >> iter 21000, loss: 0.227910
 >> iter 22000, loss: 0.225881
 >> iter 23000, loss: 0.318762
 >> iter 24000, loss: 0.227106
 >> iter 25000, loss: 0.143785
 >> iter 26000, loss: 0.222640
 >> iter 27000, loss: 0.237833
 >> iter 28000, loss: 0.189235
 >> iter 29000, loss: 0.184313
 >> iter 30000, loss: 0.153873
   Number of active neurons: 3
 >> iter 31000, loss: 0.282166
 >> iter 32000, loss: 0.203965
 >> iter 33000, loss: 0.254736
 >> iter 34000, loss: 0.210706
 >> iter 35000, loss: 0.227031
 >> iter 36000, loss: 0.341104
 >> iter 37000, loss: 0.285333
 >> iter 38000, loss: 0.327592
 >> iter 39000, loss: 0.215914
 >> iter 40000, loss: 0.187852
   Number of active neurons: 3
 >> iter 41000, loss: 0.154846
 >> iter 42000, loss: 0.210767
 >> iter 43000, loss: 0.223111
 >> iter 44000, loss: 0.172615
 >> iter 45000, loss: 0.270456
 >> iter 46000, loss: 0.262104
 >> iter 47000, loss: 0.223536
 >> iter 48000, loss: 0.162267
 >> iter 49000, loss: 0.175011
 >> iter 50000, loss: 0.202252
   Number of active neurons: 3
 >> iter 51000, loss: 0.233403
 >> iter 52000, loss: 0.214817
 >> iter 53000, loss: 0.142541
 >> iter 54000, loss: 0.145139
 >> iter 55000, loss: 0.168898
 >> iter 56000, loss: 0.256529
 >> iter 57000, loss: 0.227887
 >> iter 58000, loss: 0.305157
 >> iter 59000, loss: 0.508980
 >> iter 60000, loss: 0.298817
   Number of active neurons: 3
 >> iter 61000, loss: 0.233916
 >> iter 62000, loss: 0.177388
 >> iter 63000, loss: 0.195152
 >> iter 64000, loss: 0.384852
 >> iter 65000, loss: 0.323075
 >> iter 66000, loss: 0.431212
 >> iter 67000, loss: 0.255908
 >> iter 68000, loss: 0.191925
 >> iter 69000, loss: 0.159446
 >> iter 70000, loss: 0.293916
   Number of active neurons: 3
 >> iter 71000, loss: 0.312494
 >> iter 72000, loss: 0.339332
 >> iter 73000, loss: 0.204531
 >> iter 74000, loss: 0.235878
 >> iter 75000, loss: 0.244902
 >> iter 76000, loss: 0.168489
 >> iter 77000, loss: 0.146763
 >> iter 78000, loss: 0.231625
 >> iter 79000, loss: 0.107679
 >> iter 80000, loss: 0.219722
   Number of active neurons: 3
 >> iter 81000, loss: 0.327888
 >> iter 82000, loss: 0.284898
 >> iter 83000, loss: 0.155475
 >> iter 84000, loss: 0.129619
 >> iter 85000, loss: 0.280826
 >> iter 86000, loss: 0.208881
 >> iter 87000, loss: 0.298923
 >> iter 88000, loss: 0.226956
 >> iter 89000, loss: 0.160023
 >> iter 90000, loss: 0.199135
   Number of active neurons: 3
 >> iter 91000, loss: 0.149704
 >> iter 92000, loss: 0.255291
 >> iter 93000, loss: 0.312013
 >> iter 94000, loss: 0.473817
 >> iter 95000, loss: 0.251185
 >> iter 96000, loss: 0.227252
 >> iter 97000, loss: 0.128638
 >> iter 98000, loss: 0.198943
 >> iter 99000, loss: 0.242234
 >> iter 100000, loss: 0.124442
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.927859
 >> iter 2000, loss: 10.290560
 >> iter 3000, loss: 4.881665
 >> iter 4000, loss: 2.423798
 >> iter 5000, loss: 1.099538
 >> iter 6000, loss: 0.678714
 >> iter 7000, loss: 0.441227
 >> iter 8000, loss: 0.646880
 >> iter 9000, loss: 0.656284
 >> iter 10000, loss: 0.436862
   Number of active neurons: 5
 >> iter 11000, loss: 0.273337
 >> iter 12000, loss: 0.452461
 >> iter 13000, loss: 0.329802
 >> iter 14000, loss: 0.337140
 >> iter 15000, loss: 0.297531
 >> iter 16000, loss: 0.211540
 >> iter 17000, loss: 0.334058
 >> iter 18000, loss: 0.365786
 >> iter 19000, loss: 0.371932
 >> iter 20000, loss: 0.239682
   Number of active neurons: 5
 >> iter 21000, loss: 0.274568
 >> iter 22000, loss: 0.185580
 >> iter 23000, loss: 0.339946
 >> iter 24000, loss: 0.350811
 >> iter 25000, loss: 0.271628
 >> iter 26000, loss: 0.337913
 >> iter 27000, loss: 0.270670
 >> iter 28000, loss: 0.300847
 >> iter 29000, loss: 0.346398
 >> iter 30000, loss: 0.247049
   Number of active neurons: 4
 >> iter 31000, loss: 0.377918
 >> iter 32000, loss: 0.302146
 >> iter 33000, loss: 0.265967
 >> iter 34000, loss: 0.258420
 >> iter 35000, loss: 0.173863
 >> iter 36000, loss: 0.172037
 >> iter 37000, loss: 0.176549
 >> iter 38000, loss: 0.270114
 >> iter 39000, loss: 0.180924
 >> iter 40000, loss: 0.174561
   Number of active neurons: 4
 >> iter 41000, loss: 0.344167
 >> iter 42000, loss: 0.313847
 >> iter 43000, loss: 0.374698
 >> iter 44000, loss: 0.314258
 >> iter 45000, loss: 0.237351
 >> iter 46000, loss: 0.250459
 >> iter 47000, loss: 0.229504
 >> iter 48000, loss: 0.273077
 >> iter 49000, loss: 0.146071
 >> iter 50000, loss: 0.129127
   Number of active neurons: 4
 >> iter 51000, loss: 0.165604
 >> iter 52000, loss: 0.242222
 >> iter 53000, loss: 0.326363
 >> iter 54000, loss: 0.289506
 >> iter 55000, loss: 0.207612
 >> iter 56000, loss: 0.287921
 >> iter 57000, loss: 0.368278
 >> iter 58000, loss: 0.287580
 >> iter 59000, loss: 0.237366
 >> iter 60000, loss: 0.169161
   Number of active neurons: 3
 >> iter 61000, loss: 0.197502
 >> iter 62000, loss: 0.163146
 >> iter 63000, loss: 0.174028
 >> iter 64000, loss: 0.237634
 >> iter 65000, loss: 0.191351
 >> iter 66000, loss: 0.243311
 >> iter 67000, loss: 0.197264
 >> iter 68000, loss: 0.130418
 >> iter 69000, loss: 0.160769
 >> iter 70000, loss: 0.141613
   Number of active neurons: 3
 >> iter 71000, loss: 0.280589
 >> iter 72000, loss: 0.305449
 >> iter 73000, loss: 0.214789
 >> iter 74000, loss: 0.432679
 >> iter 75000, loss: 0.316636
 >> iter 76000, loss: 0.205595
 >> iter 77000, loss: 0.221318
 >> iter 78000, loss: 0.128576
 >> iter 79000, loss: 0.175089
 >> iter 80000, loss: 0.141880
   Number of active neurons: 3
 >> iter 81000, loss: 0.414748
 >> iter 82000, loss: 0.189419
 >> iter 83000, loss: 0.211127
 >> iter 84000, loss: 0.150161
 >> iter 85000, loss: 0.304597
 >> iter 86000, loss: 0.449641
 >> iter 87000, loss: 0.336688
 >> iter 88000, loss: 0.245856
 >> iter 89000, loss: 0.263302
 >> iter 90000, loss: 0.231439
   Number of active neurons: 3
 >> iter 91000, loss: 0.127527
 >> iter 92000, loss: 0.140498
 >> iter 93000, loss: 0.243037
 >> iter 94000, loss: 0.296750
 >> iter 95000, loss: 0.326260
 >> iter 96000, loss: 0.242339
 >> iter 97000, loss: 0.280612
 >> iter 98000, loss: 0.184106
 >> iter 99000, loss: 0.158215
 >> iter 100000, loss: 0.184154
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.617173
 >> iter 2000, loss: 9.105630
 >> iter 3000, loss: 3.984491
 >> iter 4000, loss: 2.213075
 >> iter 5000, loss: 1.547579
 >> iter 6000, loss: 0.925206
 >> iter 7000, loss: 0.757705
 >> iter 8000, loss: 0.496423
 >> iter 9000, loss: 0.566339
 >> iter 10000, loss: 0.607411
   Number of active neurons: 5
 >> iter 11000, loss: 0.378101
 >> iter 12000, loss: 0.422440
 >> iter 13000, loss: 0.321200
 >> iter 14000, loss: 0.259461
 >> iter 15000, loss: 0.314628
 >> iter 16000, loss: 0.499001
 >> iter 17000, loss: 0.383541
 >> iter 18000, loss: 0.480031
 >> iter 19000, loss: 0.369607
 >> iter 20000, loss: 0.550228
   Number of active neurons: 4
 >> iter 21000, loss: 0.318233
 >> iter 22000, loss: 0.464655
 >> iter 23000, loss: 0.510278
 >> iter 24000, loss: 0.488437
 >> iter 25000, loss: 0.522438
 >> iter 26000, loss: 0.383032
 >> iter 27000, loss: 0.474213
 >> iter 28000, loss: 0.447124
 >> iter 29000, loss: 0.582609
 >> iter 30000, loss: 0.419073
   Number of active neurons: 4
 >> iter 31000, loss: 0.340743
 >> iter 32000, loss: 0.437287
 >> iter 33000, loss: 0.308897
 >> iter 34000, loss: 0.421995
 >> iter 35000, loss: 0.776004
 >> iter 36000, loss: 0.510563
 >> iter 37000, loss: 0.382069
 >> iter 38000, loss: 0.421044
 >> iter 39000, loss: 0.422856
 >> iter 40000, loss: 0.415962
   Number of active neurons: 4
 >> iter 41000, loss: 0.375955
 >> iter 42000, loss: 0.267514
 >> iter 43000, loss: 0.357471
 >> iter 44000, loss: 0.500185
 >> iter 45000, loss: 0.401037
 >> iter 46000, loss: 0.513133
 >> iter 47000, loss: 0.437714
 >> iter 48000, loss: 0.312155
 >> iter 49000, loss: 0.377594
 >> iter 50000, loss: 0.393606
   Number of active neurons: 4
 >> iter 51000, loss: 0.325366
 >> iter 52000, loss: 0.469022
 >> iter 53000, loss: 0.509733
 >> iter 54000, loss: 0.450314
 >> iter 55000, loss: 0.342056
 >> iter 56000, loss: 0.286803
 >> iter 57000, loss: 0.288679
 >> iter 58000, loss: 0.267761
 >> iter 59000, loss: 0.279698
 >> iter 60000, loss: 0.409660
   Number of active neurons: 4
 >> iter 61000, loss: 0.555430
 >> iter 62000, loss: 0.292818
 >> iter 63000, loss: 0.238957
 >> iter 64000, loss: 0.294062
 >> iter 65000, loss: 0.310046
 >> iter 66000, loss: 0.539798
 >> iter 67000, loss: 0.476432
 >> iter 68000, loss: 0.525714
 >> iter 69000, loss: 0.390479
 >> iter 70000, loss: 0.537077
   Number of active neurons: 4
 >> iter 71000, loss: 0.446316
 >> iter 72000, loss: 0.326819
 >> iter 73000, loss: 0.325744
 >> iter 74000, loss: 0.233895
 >> iter 75000, loss: 0.201256
 >> iter 76000, loss: 0.179638
 >> iter 77000, loss: 0.248221
 >> iter 78000, loss: 0.417497
 >> iter 79000, loss: 0.242869
 >> iter 80000, loss: 0.348379
   Number of active neurons: 4
 >> iter 81000, loss: 0.463761
 >> iter 82000, loss: 0.383728
 >> iter 83000, loss: 0.224127
 >> iter 84000, loss: 0.239321
 >> iter 85000, loss: 0.372708
 >> iter 86000, loss: 0.566887
 >> iter 87000, loss: 0.330352
 >> iter 88000, loss: 0.364231
 >> iter 89000, loss: 0.357933
 >> iter 90000, loss: 0.261888
   Number of active neurons: 4
 >> iter 91000, loss: 0.297399
 >> iter 92000, loss: 0.240765
 >> iter 93000, loss: 0.285259
 >> iter 94000, loss: 0.469113
 >> iter 95000, loss: 0.241008
 >> iter 96000, loss: 0.277549
 >> iter 97000, loss: 0.295866
 >> iter 98000, loss: 0.267387
 >> iter 99000, loss: 0.324460
 >> iter 100000, loss: 0.209366
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.508161
 >> iter 2000, loss: 8.686405
 >> iter 3000, loss: 3.780236
 >> iter 4000, loss: 1.930595
 >> iter 5000, loss: 1.104911
 >> iter 6000, loss: 0.703416
 >> iter 7000, loss: 0.594855
 >> iter 8000, loss: 0.652771
 >> iter 9000, loss: 0.571933
 >> iter 10000, loss: 0.394126
   Number of active neurons: 3
 >> iter 11000, loss: 0.228809
 >> iter 12000, loss: 0.255525
 >> iter 13000, loss: 0.432397
 >> iter 14000, loss: 0.412432
 >> iter 15000, loss: 0.274094
 >> iter 16000, loss: 0.370562
 >> iter 17000, loss: 0.439185
 >> iter 18000, loss: 0.284923
 >> iter 19000, loss: 0.365493
 >> iter 20000, loss: 0.264546
   Number of active neurons: 3
 >> iter 21000, loss: 0.408403
 >> iter 22000, loss: 0.221202
 >> iter 23000, loss: 0.326577
 >> iter 24000, loss: 0.307202
 >> iter 25000, loss: 0.216739
 >> iter 26000, loss: 0.320398
 >> iter 27000, loss: 0.377747
 >> iter 28000, loss: 0.237871
 >> iter 29000, loss: 0.201489
 >> iter 30000, loss: 0.231575
   Number of active neurons: 3
 >> iter 31000, loss: 0.200379
 >> iter 32000, loss: 0.144205
 >> iter 33000, loss: 0.330196
 >> iter 34000, loss: 0.210772
 >> iter 35000, loss: 0.149969
 >> iter 36000, loss: 0.198537
 >> iter 37000, loss: 0.320259
 >> iter 38000, loss: 0.285104
 >> iter 39000, loss: 0.240836
 >> iter 40000, loss: 0.154360
   Number of active neurons: 3
 >> iter 41000, loss: 0.381734
 >> iter 42000, loss: 0.275489
 >> iter 43000, loss: 0.159978
 >> iter 44000, loss: 0.149338
 >> iter 45000, loss: 0.224906
 >> iter 46000, loss: 0.392475
 >> iter 47000, loss: 0.404910
 >> iter 48000, loss: 0.470396
 >> iter 49000, loss: 0.370058
 >> iter 50000, loss: 0.291464
   Number of active neurons: 3
 >> iter 51000, loss: 0.273073
 >> iter 52000, loss: 0.188932
 >> iter 53000, loss: 0.315543
 >> iter 54000, loss: 0.454781
 >> iter 55000, loss: 0.425513
 >> iter 56000, loss: 0.314433
 >> iter 57000, loss: 0.322017
 >> iter 58000, loss: 0.337325
 >> iter 59000, loss: 0.437786
 >> iter 60000, loss: 0.237059
   Number of active neurons: 3
 >> iter 61000, loss: 0.284837
 >> iter 62000, loss: 0.318336
 >> iter 63000, loss: 0.333343
 >> iter 64000, loss: 0.427282
 >> iter 65000, loss: 0.277202
 >> iter 66000, loss: 0.211389
 >> iter 67000, loss: 0.226084
 >> iter 68000, loss: 0.159891
 >> iter 69000, loss: 0.237615
 >> iter 70000, loss: 0.336538
   Number of active neurons: 3
 >> iter 71000, loss: 0.252791
 >> iter 72000, loss: 0.204947
 >> iter 73000, loss: 0.144847
 >> iter 74000, loss: 0.084848
 >> iter 75000, loss: 0.348414
 >> iter 76000, loss: 0.242356
 >> iter 77000, loss: 0.279092
 >> iter 78000, loss: 0.284400
 >> iter 79000, loss: 0.314807
 >> iter 80000, loss: 0.301232
   Number of active neurons: 3
 >> iter 81000, loss: 0.149952
 >> iter 82000, loss: 0.231946
 >> iter 83000, loss: 0.352754
 >> iter 84000, loss: 0.381052
 >> iter 85000, loss: 0.245116
 >> iter 86000, loss: 0.317444
 >> iter 87000, loss: 0.205934
 >> iter 88000, loss: 0.194068
 >> iter 89000, loss: 0.206661
 >> iter 90000, loss: 0.371092
   Number of active neurons: 3
 >> iter 91000, loss: 0.244887
 >> iter 92000, loss: 0.339284
 >> iter 93000, loss: 0.352618
 >> iter 94000, loss: 0.437263
 >> iter 95000, loss: 0.236824
 >> iter 96000, loss: 0.192465
 >> iter 97000, loss: 0.285621
 >> iter 98000, loss: 0.260181
 >> iter 99000, loss: 0.225164
 >> iter 100000, loss: 0.241634
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

