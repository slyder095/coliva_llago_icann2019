 > Problema: tomita1nueva
 > Args:
   - Hidden size: 6
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.050544
 >> iter 2000, loss: 4.103113
 >> iter 3000, loss: 1.532630
 >> iter 4000, loss: 0.582663
 >> iter 5000, loss: 0.234912
 >> iter 6000, loss: 0.104918
 >> iter 7000, loss: 0.068126
 >> iter 8000, loss: 0.039711
 >> iter 9000, loss: 0.029879
 >> iter 10000, loss: 0.026978
   Number of active neurons: 2
 >> iter 11000, loss: 0.024874
 >> iter 12000, loss: 0.024327
 >> iter 13000, loss: 0.023095
 >> iter 14000, loss: 0.025488
 >> iter 15000, loss: 0.030220
 >> iter 16000, loss: 0.029664
 >> iter 17000, loss: 0.027113
 >> iter 18000, loss: 0.022105
 >> iter 19000, loss: 0.021984
 >> iter 20000, loss: 0.021362
   Number of active neurons: 2
 >> iter 21000, loss: 0.021033
 >> iter 22000, loss: 0.024765
 >> iter 23000, loss: 0.027501
 >> iter 24000, loss: 0.026940
 >> iter 25000, loss: 0.023975
 >> iter 26000, loss: 0.031648
 >> iter 27000, loss: 0.048999
 >> iter 28000, loss: 0.035829
 >> iter 29000, loss: 0.026665
 >> iter 30000, loss: 0.024800
   Number of active neurons: 2
 >> iter 31000, loss: 0.023410
 >> iter 32000, loss: 0.027165
 >> iter 33000, loss: 0.032860
 >> iter 34000, loss: 0.025595
 >> iter 35000, loss: 0.022403
 >> iter 36000, loss: 0.021908
 >> iter 37000, loss: 0.022170
 >> iter 38000, loss: 0.023401
 >> iter 39000, loss: 0.023854
 >> iter 40000, loss: 0.022484
   Number of active neurons: 2
 >> iter 41000, loss: 0.020943
 >> iter 42000, loss: 0.028575
 >> iter 43000, loss: 0.023615
 >> iter 44000, loss: 0.029745
 >> iter 45000, loss: 0.026620
 >> iter 46000, loss: 0.026489
 >> iter 47000, loss: 0.023888
 >> iter 48000, loss: 0.025261
 >> iter 49000, loss: 0.023268
 >> iter 50000, loss: 0.021680
   Number of active neurons: 2
 >> iter 51000, loss: 0.021686
 >> iter 52000, loss: 0.020243
 >> iter 53000, loss: 0.021439
 >> iter 54000, loss: 0.025678
 >> iter 55000, loss: 0.024305
 >> iter 56000, loss: 0.022067
 >> iter 57000, loss: 0.023090
 >> iter 58000, loss: 0.021076
 >> iter 59000, loss: 0.023080
 >> iter 60000, loss: 0.032685
   Number of active neurons: 2
 >> iter 61000, loss: 0.024588
 >> iter 62000, loss: 0.024219
 >> iter 63000, loss: 0.020600
 >> iter 64000, loss: 0.019962
 >> iter 65000, loss: 0.025066
 >> iter 66000, loss: 0.022729
 >> iter 67000, loss: 0.022683
 >> iter 68000, loss: 0.028126
 >> iter 69000, loss: 0.024558
 >> iter 70000, loss: 0.021489
   Number of active neurons: 2
 >> iter 71000, loss: 0.019821
 >> iter 72000, loss: 0.027694
 >> iter 73000, loss: 0.026584
 >> iter 74000, loss: 0.023369
 >> iter 75000, loss: 0.020519
 >> iter 76000, loss: 0.027296
 >> iter 77000, loss: 0.023267
 >> iter 78000, loss: 0.022888
 >> iter 79000, loss: 0.023050
 >> iter 80000, loss: 0.023281
   Number of active neurons: 2
 >> iter 81000, loss: 0.022526
 >> iter 82000, loss: 0.022246
 >> iter 83000, loss: 0.021349
 >> iter 84000, loss: 0.048593
 >> iter 85000, loss: 0.034923
 >> iter 86000, loss: 0.025160
 >> iter 87000, loss: 0.034530
 >> iter 88000, loss: 0.027183
 >> iter 89000, loss: 0.038549
 >> iter 90000, loss: 0.031206
   Number of active neurons: 2
 >> iter 91000, loss: 0.026559
 >> iter 92000, loss: 0.025465
 >> iter 93000, loss: 0.025522
 >> iter 94000, loss: 0.021332
 >> iter 95000, loss: 0.023551
 >> iter 96000, loss: 0.022168
 >> iter 97000, loss: 0.038582
 >> iter 98000, loss: 0.026544
 >> iter 99000, loss: 0.024516
 >> iter 100000, loss: 0.025079
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.874507
 >> iter 2000, loss: 4.034994
 >> iter 3000, loss: 1.511978
 >> iter 4000, loss: 0.595926
 >> iter 5000, loss: 0.240909
 >> iter 6000, loss: 0.105557
 >> iter 7000, loss: 0.057481
 >> iter 8000, loss: 0.049095
 >> iter 9000, loss: 0.037914
 >> iter 10000, loss: 0.034803
   Number of active neurons: 4
 >> iter 11000, loss: 0.028810
 >> iter 12000, loss: 0.029549
 >> iter 13000, loss: 0.026476
 >> iter 14000, loss: 0.024667
 >> iter 15000, loss: 0.025549
 >> iter 16000, loss: 0.031213
 >> iter 17000, loss: 0.028869
 >> iter 18000, loss: 0.023845
 >> iter 19000, loss: 0.024058
 >> iter 20000, loss: 0.030121
   Number of active neurons: 2
 >> iter 21000, loss: 0.025057
 >> iter 22000, loss: 0.021783
 >> iter 23000, loss: 0.030565
 >> iter 24000, loss: 0.023719
 >> iter 25000, loss: 0.028124
 >> iter 26000, loss: 0.023736
 >> iter 27000, loss: 0.056644
 >> iter 28000, loss: 0.033564
 >> iter 29000, loss: 0.037183
 >> iter 30000, loss: 0.026182
   Number of active neurons: 2
 >> iter 31000, loss: 0.022225
 >> iter 32000, loss: 0.024558
 >> iter 33000, loss: 0.022843
 >> iter 34000, loss: 0.025883
 >> iter 35000, loss: 0.021567
 >> iter 36000, loss: 0.020227
 >> iter 37000, loss: 0.025664
 >> iter 38000, loss: 0.021046
 >> iter 39000, loss: 0.025734
 >> iter 40000, loss: 0.035012
   Number of active neurons: 2
 >> iter 41000, loss: 0.024486
 >> iter 42000, loss: 0.022194
 >> iter 43000, loss: 0.022367
 >> iter 44000, loss: 0.024240
 >> iter 45000, loss: 0.023834
 >> iter 46000, loss: 0.022017
 >> iter 47000, loss: 0.023817
 >> iter 48000, loss: 0.028307
 >> iter 49000, loss: 0.025415
 >> iter 50000, loss: 0.046020
   Number of active neurons: 1
 >> iter 51000, loss: 0.028396
 >> iter 52000, loss: 0.021820
 >> iter 53000, loss: 0.022667
 >> iter 54000, loss: 0.019777
 >> iter 55000, loss: 0.025446
 >> iter 56000, loss: 0.022202
 >> iter 57000, loss: 0.020925
 >> iter 58000, loss: 0.019919
 >> iter 59000, loss: 0.023611
 >> iter 60000, loss: 0.018844
   Number of active neurons: 1
 >> iter 61000, loss: 0.017431
 >> iter 62000, loss: 0.018493
 >> iter 63000, loss: 0.027027
 >> iter 64000, loss: 0.024793
 >> iter 65000, loss: 0.038605
 >> iter 66000, loss: 0.033682
 >> iter 67000, loss: 0.040189
 >> iter 68000, loss: 0.024865
 >> iter 69000, loss: 0.029863
 >> iter 70000, loss: 0.031706
   Number of active neurons: 1
 >> iter 71000, loss: 0.023225
 >> iter 72000, loss: 0.025626
 >> iter 73000, loss: 0.022228
 >> iter 74000, loss: 0.020220
 >> iter 75000, loss: 0.022055
 >> iter 76000, loss: 0.017911
 >> iter 77000, loss: 0.016233
 >> iter 78000, loss: 0.021345
 >> iter 79000, loss: 0.017608
 >> iter 80000, loss: 0.020604
   Number of active neurons: 1
 >> iter 81000, loss: 0.018809
 >> iter 82000, loss: 0.036784
 >> iter 83000, loss: 0.034144
 >> iter 84000, loss: 0.029059
 >> iter 85000, loss: 0.026709
 >> iter 86000, loss: 0.024181
 >> iter 87000, loss: 0.029458
 >> iter 88000, loss: 0.020349
 >> iter 89000, loss: 0.024738
 >> iter 90000, loss: 0.019323
   Number of active neurons: 1
 >> iter 91000, loss: 0.020864
 >> iter 92000, loss: 0.017213
 >> iter 93000, loss: 0.025483
 >> iter 94000, loss: 0.024425
 >> iter 95000, loss: 0.019170
 >> iter 96000, loss: 0.017053
 >> iter 97000, loss: 0.020512
 >> iter 98000, loss: 0.017337
 >> iter 99000, loss: 0.043747
 >> iter 100000, loss: 0.025672
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.944632
 >> iter 2000, loss: 4.089940
 >> iter 3000, loss: 1.528857
 >> iter 4000, loss: 0.587359
 >> iter 5000, loss: 0.239374
 >> iter 6000, loss: 0.116842
 >> iter 7000, loss: 0.061483
 >> iter 8000, loss: 0.049721
 >> iter 9000, loss: 0.036918
 >> iter 10000, loss: 0.034577
   Number of active neurons: 4
 >> iter 11000, loss: 0.030245
 >> iter 12000, loss: 0.027110
 >> iter 13000, loss: 0.024549
 >> iter 14000, loss: 0.024652
 >> iter 15000, loss: 0.025388
 >> iter 16000, loss: 0.022985
 >> iter 17000, loss: 0.026569
 >> iter 18000, loss: 0.024135
 >> iter 19000, loss: 0.024224
 >> iter 20000, loss: 0.023281
   Number of active neurons: 3
 >> iter 21000, loss: 0.030385
 >> iter 22000, loss: 0.028117
 >> iter 23000, loss: 0.027605
 >> iter 24000, loss: 0.029048
 >> iter 25000, loss: 0.027261
 >> iter 26000, loss: 0.026976
 >> iter 27000, loss: 0.024298
 >> iter 28000, loss: 0.023358
 >> iter 29000, loss: 0.024311
 >> iter 30000, loss: 0.039004
   Number of active neurons: 3
 >> iter 31000, loss: 0.034442
 >> iter 32000, loss: 0.026786
 >> iter 33000, loss: 0.028069
 >> iter 34000, loss: 0.029977
 >> iter 35000, loss: 0.029821
 >> iter 36000, loss: 0.027587
 >> iter 37000, loss: 0.028623
 >> iter 38000, loss: 0.025555
 >> iter 39000, loss: 0.025393
 >> iter 40000, loss: 0.035449
   Number of active neurons: 3
 >> iter 41000, loss: 0.028130
 >> iter 42000, loss: 0.027321
 >> iter 43000, loss: 0.026054
 >> iter 44000, loss: 0.023684
 >> iter 45000, loss: 0.043792
 >> iter 46000, loss: 0.031515
 >> iter 47000, loss: 0.026945
 >> iter 48000, loss: 0.025978
 >> iter 49000, loss: 0.023603
 >> iter 50000, loss: 0.024812
   Number of active neurons: 2
 >> iter 51000, loss: 0.024256
 >> iter 52000, loss: 0.022950
 >> iter 53000, loss: 0.026485
 >> iter 54000, loss: 0.050675
 >> iter 55000, loss: 0.033155
 >> iter 56000, loss: 0.033409
 >> iter 57000, loss: 0.030002
 >> iter 58000, loss: 0.023466
 >> iter 59000, loss: 0.054975
 >> iter 60000, loss: 0.032415
   Number of active neurons: 1
 >> iter 61000, loss: 0.024418
 >> iter 62000, loss: 0.024423
 >> iter 63000, loss: 0.020691
 >> iter 64000, loss: 0.022405
 >> iter 65000, loss: 0.019328
 >> iter 66000, loss: 0.028838
 >> iter 67000, loss: 0.022425
 >> iter 68000, loss: 0.019771
 >> iter 69000, loss: 0.021479
 >> iter 70000, loss: 0.017295
   Number of active neurons: 1
 >> iter 71000, loss: 0.023028
 >> iter 72000, loss: 0.027716
 >> iter 73000, loss: 0.022370
 >> iter 74000, loss: 0.018468
 >> iter 75000, loss: 0.019961
 >> iter 76000, loss: 0.031715
 >> iter 77000, loss: 0.027081
 >> iter 78000, loss: 0.022299
 >> iter 79000, loss: 0.017701
 >> iter 80000, loss: 0.020368
   Number of active neurons: 1
 >> iter 81000, loss: 0.016757
 >> iter 82000, loss: 0.017035
 >> iter 83000, loss: 0.030231
 >> iter 84000, loss: 0.023512
 >> iter 85000, loss: 0.024408
 >> iter 86000, loss: 0.030797
 >> iter 87000, loss: 0.020962
 >> iter 88000, loss: 0.017545
 >> iter 89000, loss: 0.041789
 >> iter 90000, loss: 0.025694
   Number of active neurons: 1
 >> iter 91000, loss: 0.023835
 >> iter 92000, loss: 0.039101
 >> iter 93000, loss: 0.026465
 >> iter 94000, loss: 0.030945
 >> iter 95000, loss: 0.023596
 >> iter 96000, loss: 0.027296
 >> iter 97000, loss: 0.025935
 >> iter 98000, loss: 0.021132
 >> iter 99000, loss: 0.022235
 >> iter 100000, loss: 0.018901
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.878561
 >> iter 2000, loss: 4.037099
 >> iter 3000, loss: 1.508564
 >> iter 4000, loss: 0.582573
 >> iter 5000, loss: 0.233399
 >> iter 6000, loss: 0.105249
 >> iter 7000, loss: 0.060065
 >> iter 8000, loss: 0.040730
 >> iter 9000, loss: 0.038379
 >> iter 10000, loss: 0.034062
   Number of active neurons: 3
 >> iter 11000, loss: 0.029783
 >> iter 12000, loss: 0.026592
 >> iter 13000, loss: 0.027331
 >> iter 14000, loss: 0.024202
 >> iter 15000, loss: 0.025101
 >> iter 16000, loss: 0.026172
 >> iter 17000, loss: 0.023639
 >> iter 18000, loss: 0.022635
 >> iter 19000, loss: 0.023626
 >> iter 20000, loss: 0.026191
   Number of active neurons: 2
 >> iter 21000, loss: 0.022097
 >> iter 22000, loss: 0.033235
 >> iter 23000, loss: 0.024808
 >> iter 24000, loss: 0.022792
 >> iter 25000, loss: 0.021072
 >> iter 26000, loss: 0.023709
 >> iter 27000, loss: 0.029139
 >> iter 28000, loss: 0.031060
 >> iter 29000, loss: 0.024444
 >> iter 30000, loss: 0.025428
   Number of active neurons: 2
 >> iter 31000, loss: 0.023575
 >> iter 32000, loss: 0.023289
 >> iter 33000, loss: 0.021575
 >> iter 34000, loss: 0.023014
 >> iter 35000, loss: 0.053225
 >> iter 36000, loss: 0.033722
 >> iter 37000, loss: 0.053341
 >> iter 38000, loss: 0.040341
 >> iter 39000, loss: 0.030883
 >> iter 40000, loss: 0.025475
   Number of active neurons: 2
 >> iter 41000, loss: 0.022882
 >> iter 42000, loss: 0.021232
 >> iter 43000, loss: 0.032604
 >> iter 44000, loss: 0.026736
 >> iter 45000, loss: 0.023989
 >> iter 46000, loss: 0.021806
 >> iter 47000, loss: 0.024417
 >> iter 48000, loss: 0.021188
 >> iter 49000, loss: 0.020122
 >> iter 50000, loss: 0.019795
   Number of active neurons: 1
 >> iter 51000, loss: 0.048974
 >> iter 52000, loss: 0.028304
 >> iter 53000, loss: 0.022902
 >> iter 54000, loss: 0.028855
 >> iter 55000, loss: 0.022189
 >> iter 56000, loss: 0.025647
 >> iter 57000, loss: 0.021381
 >> iter 58000, loss: 0.019492
 >> iter 59000, loss: 0.019465
 >> iter 60000, loss: 0.017607
   Number of active neurons: 1
 >> iter 61000, loss: 0.020360
 >> iter 62000, loss: 0.020370
 >> iter 63000, loss: 0.018326
 >> iter 64000, loss: 0.033286
 >> iter 65000, loss: 0.026119
 >> iter 66000, loss: 0.020540
 >> iter 67000, loss: 0.018728
 >> iter 68000, loss: 0.020690
 >> iter 69000, loss: 0.017698
 >> iter 70000, loss: 0.039654
   Number of active neurons: 1
 >> iter 71000, loss: 0.025637
 >> iter 72000, loss: 0.027521
 >> iter 73000, loss: 0.025452
 >> iter 74000, loss: 0.020150
 >> iter 75000, loss: 0.017997
 >> iter 76000, loss: 0.022822
 >> iter 77000, loss: 0.024102
 >> iter 78000, loss: 0.024302
 >> iter 79000, loss: 0.028321
 >> iter 80000, loss: 0.031818
   Number of active neurons: 1
 >> iter 81000, loss: 0.023565
 >> iter 82000, loss: 0.027206
 >> iter 83000, loss: 0.020038
 >> iter 84000, loss: 0.024715
 >> iter 85000, loss: 0.023222
 >> iter 86000, loss: 0.021661
 >> iter 87000, loss: 0.018315
 >> iter 88000, loss: 0.017077
 >> iter 89000, loss: 0.023866
 >> iter 90000, loss: 0.022409
   Number of active neurons: 1
 >> iter 91000, loss: 0.018674
 >> iter 92000, loss: 0.021331
 >> iter 93000, loss: 0.054728
 >> iter 94000, loss: 0.030708
 >> iter 95000, loss: 0.022756
 >> iter 96000, loss: 0.019426
 >> iter 97000, loss: 0.022384
 >> iter 98000, loss: 0.022116
 >> iter 99000, loss: 0.017932
 >> iter 100000, loss: 0.016493
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.946545
 >> iter 2000, loss: 4.064163
 >> iter 3000, loss: 1.521808
 >> iter 4000, loss: 0.584586
 >> iter 5000, loss: 0.233600
 >> iter 6000, loss: 0.102864
 >> iter 7000, loss: 0.057657
 >> iter 8000, loss: 0.042878
 >> iter 9000, loss: 0.036710
 >> iter 10000, loss: 0.028965
   Number of active neurons: 4
 >> iter 11000, loss: 0.026021
 >> iter 12000, loss: 0.029309
 >> iter 13000, loss: 0.031428
 >> iter 14000, loss: 0.028434
 >> iter 15000, loss: 0.027438
 >> iter 16000, loss: 0.025766
 >> iter 17000, loss: 0.024917
 >> iter 18000, loss: 0.028499
 >> iter 19000, loss: 0.028014
 >> iter 20000, loss: 0.025251
   Number of active neurons: 3
 >> iter 21000, loss: 0.023996
 >> iter 22000, loss: 0.023044
 >> iter 23000, loss: 0.023647
 >> iter 24000, loss: 0.024470
 >> iter 25000, loss: 0.028838
 >> iter 26000, loss: 0.030691
 >> iter 27000, loss: 0.025513
 >> iter 28000, loss: 0.023660
 >> iter 29000, loss: 0.023324
 >> iter 30000, loss: 0.022523
   Number of active neurons: 3
 >> iter 31000, loss: 0.027753
 >> iter 32000, loss: 0.035204
 >> iter 33000, loss: 0.030170
 >> iter 34000, loss: 0.024415
 >> iter 35000, loss: 0.024225
 >> iter 36000, loss: 0.030114
 >> iter 37000, loss: 0.026636
 >> iter 38000, loss: 0.025659
 >> iter 39000, loss: 0.027130
 >> iter 40000, loss: 0.028346
   Number of active neurons: 3
 >> iter 41000, loss: 0.023700
 >> iter 42000, loss: 0.022850
 >> iter 43000, loss: 0.037840
 >> iter 44000, loss: 0.046725
 >> iter 45000, loss: 0.032863
 >> iter 46000, loss: 0.030255
 >> iter 47000, loss: 0.030185
 >> iter 48000, loss: 0.046420
 >> iter 49000, loss: 0.033239
 >> iter 50000, loss: 0.027061
   Number of active neurons: 3
 >> iter 51000, loss: 0.025456
 >> iter 52000, loss: 0.032176
 >> iter 53000, loss: 0.026321
 >> iter 54000, loss: 0.029722
 >> iter 55000, loss: 0.023905
 >> iter 56000, loss: 0.022299
 >> iter 57000, loss: 0.022229
 >> iter 58000, loss: 0.024869
 >> iter 59000, loss: 0.040430
 >> iter 60000, loss: 0.027745
   Number of active neurons: 2
 >> iter 61000, loss: 0.023913
 >> iter 62000, loss: 0.023329
 >> iter 63000, loss: 0.050726
 >> iter 64000, loss: 0.034995
 >> iter 65000, loss: 0.033035
 >> iter 66000, loss: 0.024255
 >> iter 67000, loss: 0.021502
 >> iter 68000, loss: 0.041042
 >> iter 69000, loss: 0.028641
 >> iter 70000, loss: 0.023367
   Number of active neurons: 2
 >> iter 71000, loss: 0.035694
 >> iter 72000, loss: 0.037466
 >> iter 73000, loss: 0.034314
 >> iter 74000, loss: 0.026867
 >> iter 75000, loss: 0.023330
 >> iter 76000, loss: 0.023247
 >> iter 77000, loss: 0.024716
 >> iter 78000, loss: 0.025903
 >> iter 79000, loss: 0.033015
 >> iter 80000, loss: 0.037784
   Number of active neurons: 2
 >> iter 81000, loss: 0.030186
 >> iter 82000, loss: 0.026804
 >> iter 83000, loss: 0.021867
 >> iter 84000, loss: 0.023440
 >> iter 85000, loss: 0.036943
 >> iter 86000, loss: 0.027815
 >> iter 87000, loss: 0.033374
 >> iter 88000, loss: 0.035268
 >> iter 89000, loss: 0.028320
 >> iter 90000, loss: 0.024289
   Number of active neurons: 2
 >> iter 91000, loss: 0.021291
 >> iter 92000, loss: 0.024290
 >> iter 93000, loss: 0.040129
 >> iter 94000, loss: 0.028260
 >> iter 95000, loss: 0.025374
 >> iter 96000, loss: 0.023606
 >> iter 97000, loss: 0.021507
 >> iter 98000, loss: 0.021317
 >> iter 99000, loss: 0.023744
 >> iter 100000, loss: 0.040233
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.000785
 >> iter 2000, loss: 4.093063
 >> iter 3000, loss: 1.531877
 >> iter 4000, loss: 0.607876
 >> iter 5000, loss: 0.243451
 >> iter 6000, loss: 0.113564
 >> iter 7000, loss: 0.062304
 >> iter 8000, loss: 0.037646
 >> iter 9000, loss: 0.030817
 >> iter 10000, loss: 0.031263
   Number of active neurons: 3
 >> iter 11000, loss: 0.039341
 >> iter 12000, loss: 0.033633
 >> iter 13000, loss: 0.026670
 >> iter 14000, loss: 0.024715
 >> iter 15000, loss: 0.043890
 >> iter 16000, loss: 0.033185
 >> iter 17000, loss: 0.030701
 >> iter 18000, loss: 0.074351
 >> iter 19000, loss: 0.041766
 >> iter 20000, loss: 0.033408
   Number of active neurons: 3
 >> iter 21000, loss: 0.027373
 >> iter 22000, loss: 0.024861
 >> iter 23000, loss: 0.025179
 >> iter 24000, loss: 0.024450
 >> iter 25000, loss: 0.030443
 >> iter 26000, loss: 0.028399
 >> iter 27000, loss: 0.024966
 >> iter 28000, loss: 0.023531
 >> iter 29000, loss: 0.025272
 >> iter 30000, loss: 0.030863
   Number of active neurons: 3
 >> iter 31000, loss: 0.035384
 >> iter 32000, loss: 0.027168
 >> iter 33000, loss: 0.027992
 >> iter 34000, loss: 0.026874
 >> iter 35000, loss: 0.033016
 >> iter 36000, loss: 0.029252
 >> iter 37000, loss: 0.028251
 >> iter 38000, loss: 0.024769
 >> iter 39000, loss: 0.025298
 >> iter 40000, loss: 0.032969
   Number of active neurons: 3
 >> iter 41000, loss: 0.058289
 >> iter 42000, loss: 0.040397
 >> iter 43000, loss: 0.029787
 >> iter 44000, loss: 0.032874
 >> iter 45000, loss: 0.026637
 >> iter 46000, loss: 0.028190
 >> iter 47000, loss: 0.028816
 >> iter 48000, loss: 0.031190
 >> iter 49000, loss: 0.030880
 >> iter 50000, loss: 0.025564
   Number of active neurons: 3
 >> iter 51000, loss: 0.057737
 >> iter 52000, loss: 0.045142
 >> iter 53000, loss: 0.036726
 >> iter 54000, loss: 0.031274
 >> iter 55000, loss: 0.027313
 >> iter 56000, loss: 0.027640
 >> iter 57000, loss: 0.026006
 >> iter 58000, loss: 0.059283
 >> iter 59000, loss: 0.037573
 >> iter 60000, loss: 0.029717
   Number of active neurons: 3
 >> iter 61000, loss: 0.024907
 >> iter 62000, loss: 0.028952
 >> iter 63000, loss: 0.030732
 >> iter 64000, loss: 0.025008
 >> iter 65000, loss: 0.027571
 >> iter 66000, loss: 0.025168
 >> iter 67000, loss: 0.029342
 >> iter 68000, loss: 0.027791
 >> iter 69000, loss: 0.026676
 >> iter 70000, loss: 0.023243
   Number of active neurons: 1
 >> iter 71000, loss: 0.023494
 >> iter 72000, loss: 0.038110
 >> iter 73000, loss: 0.030883
 >> iter 74000, loss: 0.035654
 >> iter 75000, loss: 0.024530
 >> iter 76000, loss: 0.023993
 >> iter 77000, loss: 0.020716
 >> iter 78000, loss: 0.017510
 >> iter 79000, loss: 0.018858
 >> iter 80000, loss: 0.018673
   Number of active neurons: 1
 >> iter 81000, loss: 0.017211
 >> iter 82000, loss: 0.020077
 >> iter 83000, loss: 0.019629
 >> iter 84000, loss: 0.028229
 >> iter 85000, loss: 0.020244
 >> iter 86000, loss: 0.019980
 >> iter 87000, loss: 0.021038
 >> iter 88000, loss: 0.018030
 >> iter 89000, loss: 0.016820
 >> iter 90000, loss: 0.019500
   Number of active neurons: 1
 >> iter 91000, loss: 0.016583
 >> iter 92000, loss: 0.023652
 >> iter 93000, loss: 0.025925
 >> iter 94000, loss: 0.026824
 >> iter 95000, loss: 0.062208
 >> iter 96000, loss: 0.038972
 >> iter 97000, loss: 0.024756
 >> iter 98000, loss: 0.020921
 >> iter 99000, loss: 0.033879
 >> iter 100000, loss: 0.023111
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.925696
 >> iter 2000, loss: 4.052616
 >> iter 3000, loss: 1.518349
 >> iter 4000, loss: 0.589216
 >> iter 5000, loss: 0.236182
 >> iter 6000, loss: 0.108947
 >> iter 7000, loss: 0.057477
 >> iter 8000, loss: 0.042797
 >> iter 9000, loss: 0.061426
 >> iter 10000, loss: 0.048721
   Number of active neurons: 3
 >> iter 11000, loss: 0.038643
 >> iter 12000, loss: 0.032675
 >> iter 13000, loss: 0.026198
 >> iter 14000, loss: 0.024586
 >> iter 15000, loss: 0.036325
 >> iter 16000, loss: 0.028431
 >> iter 17000, loss: 0.037214
 >> iter 18000, loss: 0.034262
 >> iter 19000, loss: 0.029388
 >> iter 20000, loss: 0.025762
   Number of active neurons: 2
 >> iter 21000, loss: 0.023660
 >> iter 22000, loss: 0.027055
 >> iter 23000, loss: 0.023477
 >> iter 24000, loss: 0.027051
 >> iter 25000, loss: 0.023237
 >> iter 26000, loss: 0.024724
 >> iter 27000, loss: 0.023342
 >> iter 28000, loss: 0.024703
 >> iter 29000, loss: 0.030232
 >> iter 30000, loss: 0.027421
   Number of active neurons: 2
 >> iter 31000, loss: 0.023018
 >> iter 32000, loss: 0.028701
 >> iter 33000, loss: 0.025997
 >> iter 34000, loss: 0.024664
 >> iter 35000, loss: 0.035315
 >> iter 36000, loss: 0.026277
 >> iter 37000, loss: 0.037216
 >> iter 38000, loss: 0.028383
 >> iter 39000, loss: 0.031713
 >> iter 40000, loss: 0.022162
   Number of active neurons: 1
 >> iter 41000, loss: 0.022411
 >> iter 42000, loss: 0.022550
 >> iter 43000, loss: 0.021383
 >> iter 44000, loss: 0.019380
 >> iter 45000, loss: 0.023588
 >> iter 46000, loss: 0.020052
 >> iter 47000, loss: 0.023946
 >> iter 48000, loss: 0.025107
 >> iter 49000, loss: 0.025180
 >> iter 50000, loss: 0.019205
   Number of active neurons: 1
 >> iter 51000, loss: 0.017175
 >> iter 52000, loss: 0.020731
 >> iter 53000, loss: 0.023519
 >> iter 54000, loss: 0.022071
 >> iter 55000, loss: 0.029375
 >> iter 56000, loss: 0.022157
 >> iter 57000, loss: 0.036367
 >> iter 58000, loss: 0.023896
 >> iter 59000, loss: 0.018447
 >> iter 60000, loss: 0.016677
   Number of active neurons: 1
 >> iter 61000, loss: 0.033128
 >> iter 62000, loss: 0.024728
 >> iter 63000, loss: 0.020027
 >> iter 64000, loss: 0.044458
 >> iter 65000, loss: 0.028295
 >> iter 66000, loss: 0.027808
 >> iter 67000, loss: 0.021642
 >> iter 68000, loss: 0.031244
 >> iter 69000, loss: 0.029276
 >> iter 70000, loss: 0.020516
   Number of active neurons: 1
 >> iter 71000, loss: 0.020483
 >> iter 72000, loss: 0.019140
 >> iter 73000, loss: 0.018152
 >> iter 74000, loss: 0.022796
 >> iter 75000, loss: 0.027115
 >> iter 76000, loss: 0.020643
 >> iter 77000, loss: 0.018786
 >> iter 78000, loss: 0.018525
 >> iter 79000, loss: 0.015967
 >> iter 80000, loss: 0.016761
   Number of active neurons: 1
 >> iter 81000, loss: 0.020295
 >> iter 82000, loss: 0.023010
 >> iter 83000, loss: 0.020438
 >> iter 84000, loss: 0.021624
 >> iter 85000, loss: 0.027006
 >> iter 86000, loss: 0.022813
 >> iter 87000, loss: 0.027304
 >> iter 88000, loss: 0.020373
 >> iter 89000, loss: 0.018026
 >> iter 90000, loss: 0.018101
   Number of active neurons: 1
 >> iter 91000, loss: 0.020288
 >> iter 92000, loss: 0.016982
 >> iter 93000, loss: 0.019705
 >> iter 94000, loss: 0.018493
 >> iter 95000, loss: 0.017932
 >> iter 96000, loss: 0.020872
 >> iter 97000, loss: 0.019922
 >> iter 98000, loss: 0.019164
 >> iter 99000, loss: 0.020703
 >> iter 100000, loss: 0.023928
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.924081
 >> iter 2000, loss: 4.055211
 >> iter 3000, loss: 1.517204
 >> iter 4000, loss: 0.581953
 >> iter 5000, loss: 0.234576
 >> iter 6000, loss: 0.100112
 >> iter 7000, loss: 0.052265
 >> iter 8000, loss: 0.040363
 >> iter 9000, loss: 0.031997
 >> iter 10000, loss: 0.028547
   Number of active neurons: 3
 >> iter 11000, loss: 0.028157
 >> iter 12000, loss: 0.027472
 >> iter 13000, loss: 0.032072
 >> iter 14000, loss: 0.025746
 >> iter 15000, loss: 0.027429
 >> iter 16000, loss: 0.036859
 >> iter 17000, loss: 0.036725
 >> iter 18000, loss: 0.028317
 >> iter 19000, loss: 0.025884
 >> iter 20000, loss: 0.023905
   Number of active neurons: 3
 >> iter 21000, loss: 0.022566
 >> iter 22000, loss: 0.033732
 >> iter 23000, loss: 0.028354
 >> iter 24000, loss: 0.024846
 >> iter 25000, loss: 0.036771
 >> iter 26000, loss: 0.029863
 >> iter 27000, loss: 0.033885
 >> iter 28000, loss: 0.027584
 >> iter 29000, loss: 0.028960
 >> iter 30000, loss: 0.026691
   Number of active neurons: 2
 >> iter 31000, loss: 0.025857
 >> iter 32000, loss: 0.026583
 >> iter 33000, loss: 0.022853
 >> iter 34000, loss: 0.023143
 >> iter 35000, loss: 0.024395
 >> iter 36000, loss: 0.023575
 >> iter 37000, loss: 0.023470
 >> iter 38000, loss: 0.023000
 >> iter 39000, loss: 0.020998
 >> iter 40000, loss: 0.022401
   Number of active neurons: 2
 >> iter 41000, loss: 0.031878
 >> iter 42000, loss: 0.022606
 >> iter 43000, loss: 0.023799
 >> iter 44000, loss: 0.036859
 >> iter 45000, loss: 0.027366
 >> iter 46000, loss: 0.037270
 >> iter 47000, loss: 0.032254
 >> iter 48000, loss: 0.024527
 >> iter 49000, loss: 0.021295
 >> iter 50000, loss: 0.021187
   Number of active neurons: 2
 >> iter 51000, loss: 0.022987
 >> iter 52000, loss: 0.023211
 >> iter 53000, loss: 0.022104
 >> iter 54000, loss: 0.022132
 >> iter 55000, loss: 0.022990
 >> iter 56000, loss: 0.037243
 >> iter 57000, loss: 0.028190
 >> iter 58000, loss: 0.022971
 >> iter 59000, loss: 0.021735
 >> iter 60000, loss: 0.023643
   Number of active neurons: 2
 >> iter 61000, loss: 0.023888
 >> iter 62000, loss: 0.021923
 >> iter 63000, loss: 0.021559
 >> iter 64000, loss: 0.020512
 >> iter 65000, loss: 0.022027
 >> iter 66000, loss: 0.028353
 >> iter 67000, loss: 0.025332
 >> iter 68000, loss: 0.022121
 >> iter 69000, loss: 0.042718
 >> iter 70000, loss: 0.030754
   Number of active neurons: 2
 >> iter 71000, loss: 0.023557
 >> iter 72000, loss: 0.030739
 >> iter 73000, loss: 0.025481
 >> iter 74000, loss: 0.022018
 >> iter 75000, loss: 0.020208
 >> iter 76000, loss: 0.022610
 >> iter 77000, loss: 0.020923
 >> iter 78000, loss: 0.019740
 >> iter 79000, loss: 0.038907
 >> iter 80000, loss: 0.029272
   Number of active neurons: 2
 >> iter 81000, loss: 0.023638
 >> iter 82000, loss: 0.026161
 >> iter 83000, loss: 0.026997
 >> iter 84000, loss: 0.038615
 >> iter 85000, loss: 0.029803
 >> iter 86000, loss: 0.026642
 >> iter 87000, loss: 0.023575
 >> iter 88000, loss: 0.021229
 >> iter 89000, loss: 0.021518
 >> iter 90000, loss: 0.019971
   Number of active neurons: 1
 >> iter 91000, loss: 0.021484
 >> iter 92000, loss: 0.021073
 >> iter 93000, loss: 0.020818
 >> iter 94000, loss: 0.025997
 >> iter 95000, loss: 0.023980
 >> iter 96000, loss: 0.023278
 >> iter 97000, loss: 0.020505
 >> iter 98000, loss: 0.019250
 >> iter 99000, loss: 0.031653
 >> iter 100000, loss: 0.023712
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.976441
 >> iter 2000, loss: 4.071665
 >> iter 3000, loss: 1.524826
 >> iter 4000, loss: 0.583560
 >> iter 5000, loss: 0.245797
 >> iter 6000, loss: 0.107353
 >> iter 7000, loss: 0.056391
 >> iter 8000, loss: 0.053801
 >> iter 9000, loss: 0.040070
 >> iter 10000, loss: 0.031595
   Number of active neurons: 4
 >> iter 11000, loss: 0.028694
 >> iter 12000, loss: 0.028929
 >> iter 13000, loss: 0.027807
 >> iter 14000, loss: 0.034328
 >> iter 15000, loss: 0.028559
 >> iter 16000, loss: 0.027485
 >> iter 17000, loss: 0.025945
 >> iter 18000, loss: 0.030515
 >> iter 19000, loss: 0.026628
 >> iter 20000, loss: 0.025093
   Number of active neurons: 3
 >> iter 21000, loss: 0.023555
 >> iter 22000, loss: 0.027627
 >> iter 23000, loss: 0.034767
 >> iter 24000, loss: 0.032457
 >> iter 25000, loss: 0.026005
 >> iter 26000, loss: 0.026098
 >> iter 27000, loss: 0.026480
 >> iter 28000, loss: 0.024539
 >> iter 29000, loss: 0.026117
 >> iter 30000, loss: 0.024626
   Number of active neurons: 3
 >> iter 31000, loss: 0.034873
 >> iter 32000, loss: 0.027076
 >> iter 33000, loss: 0.024265
 >> iter 34000, loss: 0.022097
 >> iter 35000, loss: 0.034325
 >> iter 36000, loss: 0.030536
 >> iter 37000, loss: 0.026853
 >> iter 38000, loss: 0.025759
 >> iter 39000, loss: 0.025984
 >> iter 40000, loss: 0.031028
   Number of active neurons: 3
 >> iter 41000, loss: 0.027177
 >> iter 42000, loss: 0.024969
 >> iter 43000, loss: 0.021965
 >> iter 44000, loss: 0.026475
 >> iter 45000, loss: 0.024604
 >> iter 46000, loss: 0.026619
 >> iter 47000, loss: 0.023633
 >> iter 48000, loss: 0.027510
 >> iter 49000, loss: 0.024877
 >> iter 50000, loss: 0.023216
   Number of active neurons: 3
 >> iter 51000, loss: 0.027227
 >> iter 52000, loss: 0.023188
 >> iter 53000, loss: 0.023680
 >> iter 54000, loss: 0.022655
 >> iter 55000, loss: 0.025628
 >> iter 56000, loss: 0.024013
 >> iter 57000, loss: 0.027645
 >> iter 58000, loss: 0.024777
 >> iter 59000, loss: 0.024561
 >> iter 60000, loss: 0.024236
   Number of active neurons: 2
 >> iter 61000, loss: 0.022073
 >> iter 62000, loss: 0.023524
 >> iter 63000, loss: 0.027818
 >> iter 64000, loss: 0.026174
 >> iter 65000, loss: 0.023760
 >> iter 66000, loss: 0.022125
 >> iter 67000, loss: 0.019762
 >> iter 68000, loss: 0.024217
 >> iter 69000, loss: 0.023428
 >> iter 70000, loss: 0.020757
   Number of active neurons: 2
 >> iter 71000, loss: 0.021988
 >> iter 72000, loss: 0.022432
 >> iter 73000, loss: 0.028195
 >> iter 74000, loss: 0.026303
 >> iter 75000, loss: 0.023347
 >> iter 76000, loss: 0.028227
 >> iter 77000, loss: 0.025318
 >> iter 78000, loss: 0.023350
 >> iter 79000, loss: 0.023913
 >> iter 80000, loss: 0.034591
   Number of active neurons: 2
 >> iter 81000, loss: 0.025442
 >> iter 82000, loss: 0.021203
 >> iter 83000, loss: 0.023589
 >> iter 84000, loss: 0.023911
 >> iter 85000, loss: 0.024264
 >> iter 86000, loss: 0.023592
 >> iter 87000, loss: 0.030723
 >> iter 88000, loss: 0.025710
 >> iter 89000, loss: 0.022208
 >> iter 90000, loss: 0.022741
   Number of active neurons: 2
 >> iter 91000, loss: 0.023526
 >> iter 92000, loss: 0.022104
 >> iter 93000, loss: 0.034640
 >> iter 94000, loss: 0.026696
 >> iter 95000, loss: 0.024281
 >> iter 96000, loss: 0.026138
 >> iter 97000, loss: 0.023412
 >> iter 98000, loss: 0.020412
 >> iter 99000, loss: 0.021404
 >> iter 100000, loss: 0.020401
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.937008
 >> iter 2000, loss: 4.066092
 >> iter 3000, loss: 1.521964
 >> iter 4000, loss: 0.578905
 >> iter 5000, loss: 0.237306
 >> iter 6000, loss: 0.103466
 >> iter 7000, loss: 0.060716
 >> iter 8000, loss: 0.044144
 >> iter 9000, loss: 0.042869
 >> iter 10000, loss: 0.030075
   Number of active neurons: 4
 >> iter 11000, loss: 0.026338
 >> iter 12000, loss: 0.028954
 >> iter 13000, loss: 0.026935
 >> iter 14000, loss: 0.027321
 >> iter 15000, loss: 0.026859
 >> iter 16000, loss: 0.024361
 >> iter 17000, loss: 0.024177
 >> iter 18000, loss: 0.047642
 >> iter 19000, loss: 0.033923
 >> iter 20000, loss: 0.026141
   Number of active neurons: 3
 >> iter 21000, loss: 0.025592
 >> iter 22000, loss: 0.049269
 >> iter 23000, loss: 0.033418
 >> iter 24000, loss: 0.030130
 >> iter 25000, loss: 0.025968
 >> iter 26000, loss: 0.025510
 >> iter 27000, loss: 0.024789
 >> iter 28000, loss: 0.023147
 >> iter 29000, loss: 0.024106
 >> iter 30000, loss: 0.022674
   Number of active neurons: 2
 >> iter 31000, loss: 0.031429
 >> iter 32000, loss: 0.029602
 >> iter 33000, loss: 0.024881
 >> iter 34000, loss: 0.021777
 >> iter 35000, loss: 0.020664
 >> iter 36000, loss: 0.019515
 >> iter 37000, loss: 0.031682
 >> iter 38000, loss: 0.028113
 >> iter 39000, loss: 0.025365
 >> iter 40000, loss: 0.023455
   Number of active neurons: 2
 >> iter 41000, loss: 0.023018
 >> iter 42000, loss: 0.022851
 >> iter 43000, loss: 0.029541
 >> iter 44000, loss: 0.030773
 >> iter 45000, loss: 0.038026
 >> iter 46000, loss: 0.027185
 >> iter 47000, loss: 0.025306
 >> iter 48000, loss: 0.024018
 >> iter 49000, loss: 0.022294
 >> iter 50000, loss: 0.021065
   Number of active neurons: 2
 >> iter 51000, loss: 0.019408
 >> iter 52000, loss: 0.024426
 >> iter 53000, loss: 0.023227
 >> iter 54000, loss: 0.023768
 >> iter 55000, loss: 0.026917
 >> iter 56000, loss: 0.022885
 >> iter 57000, loss: 0.024518
 >> iter 58000, loss: 0.027270
 >> iter 59000, loss: 0.024984
 >> iter 60000, loss: 0.023059
   Number of active neurons: 2
 >> iter 61000, loss: 0.025891
 >> iter 62000, loss: 0.023423
 >> iter 63000, loss: 0.020978
 >> iter 64000, loss: 0.024052
 >> iter 65000, loss: 0.021270
 >> iter 66000, loss: 0.025307
 >> iter 67000, loss: 0.023050
 >> iter 68000, loss: 0.021988
 >> iter 69000, loss: 0.021650
 >> iter 70000, loss: 0.019734
   Number of active neurons: 2
 >> iter 71000, loss: 0.025633
 >> iter 72000, loss: 0.024755
 >> iter 73000, loss: 0.020968
 >> iter 74000, loss: 0.021956
 >> iter 75000, loss: 0.032022
 >> iter 76000, loss: 0.030805
 >> iter 77000, loss: 0.023458
 >> iter 78000, loss: 0.022461
 >> iter 79000, loss: 0.020304
 >> iter 80000, loss: 0.025298
   Number of active neurons: 2
 >> iter 81000, loss: 0.022282
 >> iter 82000, loss: 0.022662
 >> iter 83000, loss: 0.022396
 >> iter 84000, loss: 0.025555
 >> iter 85000, loss: 0.023244
 >> iter 86000, loss: 0.022789
 >> iter 87000, loss: 0.029998
 >> iter 88000, loss: 0.037191
 >> iter 89000, loss: 0.027815
 >> iter 90000, loss: 0.025228
   Number of active neurons: 2
 >> iter 91000, loss: 0.044442
 >> iter 92000, loss: 0.040214
 >> iter 93000, loss: 0.029633
 >> iter 94000, loss: 0.023406
 >> iter 95000, loss: 0.023583
 >> iter 96000, loss: 0.022852
 >> iter 97000, loss: 0.027835
 >> iter 98000, loss: 0.046109
 >> iter 99000, loss: 0.031133
 >> iter 100000, loss: 0.024752
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.939828
 >> iter 2000, loss: 4.065347
 >> iter 3000, loss: 1.526963
 >> iter 4000, loss: 0.586054
 >> iter 5000, loss: 0.236382
 >> iter 6000, loss: 0.104811
 >> iter 7000, loss: 0.059537
 >> iter 8000, loss: 0.045548
 >> iter 9000, loss: 0.034642
 >> iter 10000, loss: 0.028265
   Number of active neurons: 3
 >> iter 11000, loss: 0.025712
 >> iter 12000, loss: 0.029932
 >> iter 13000, loss: 0.028707
 >> iter 14000, loss: 0.034283
 >> iter 15000, loss: 0.030899
 >> iter 16000, loss: 0.038278
 >> iter 17000, loss: 0.030214
 >> iter 18000, loss: 0.025212
 >> iter 19000, loss: 0.024756
 >> iter 20000, loss: 0.023629
   Number of active neurons: 2
 >> iter 21000, loss: 0.028219
 >> iter 22000, loss: 0.030823
 >> iter 23000, loss: 0.030132
 >> iter 24000, loss: 0.025227
 >> iter 25000, loss: 0.024292
 >> iter 26000, loss: 0.022753
 >> iter 27000, loss: 0.023115
 >> iter 28000, loss: 0.021597
 >> iter 29000, loss: 0.020021
 >> iter 30000, loss: 0.020726
   Number of active neurons: 2
 >> iter 31000, loss: 0.020922
 >> iter 32000, loss: 0.022305
 >> iter 33000, loss: 0.024197
 >> iter 34000, loss: 0.020117
 >> iter 35000, loss: 0.021169
 >> iter 36000, loss: 0.031667
 >> iter 37000, loss: 0.026241
 >> iter 38000, loss: 0.023825
 >> iter 39000, loss: 0.021197
 >> iter 40000, loss: 0.023304
   Number of active neurons: 2
 >> iter 41000, loss: 0.023371
 >> iter 42000, loss: 0.020841
 >> iter 43000, loss: 0.020062
 >> iter 44000, loss: 0.022971
 >> iter 45000, loss: 0.025996
 >> iter 46000, loss: 0.023076
 >> iter 47000, loss: 0.026267
 >> iter 48000, loss: 0.025945
 >> iter 49000, loss: 0.024821
 >> iter 50000, loss: 0.027124
   Number of active neurons: 2
 >> iter 51000, loss: 0.021846
 >> iter 52000, loss: 0.036677
 >> iter 53000, loss: 0.028011
 >> iter 54000, loss: 0.034888
 >> iter 55000, loss: 0.025960
 >> iter 56000, loss: 0.024422
 >> iter 57000, loss: 0.032514
 >> iter 58000, loss: 0.024949
 >> iter 59000, loss: 0.023108
 >> iter 60000, loss: 0.025789
   Number of active neurons: 2
 >> iter 61000, loss: 0.025330
 >> iter 62000, loss: 0.020712
 >> iter 63000, loss: 0.020975
 >> iter 64000, loss: 0.021131
 >> iter 65000, loss: 0.023049
 >> iter 66000, loss: 0.025072
 >> iter 67000, loss: 0.029594
 >> iter 68000, loss: 0.025473
 >> iter 69000, loss: 0.022106
 >> iter 70000, loss: 0.022666
   Number of active neurons: 2
 >> iter 71000, loss: 0.021428
 >> iter 72000, loss: 0.021572
 >> iter 73000, loss: 0.022318
 >> iter 74000, loss: 0.020267
 >> iter 75000, loss: 0.021599
 >> iter 76000, loss: 0.026146
 >> iter 77000, loss: 0.026849
 >> iter 78000, loss: 0.021010
 >> iter 79000, loss: 0.035330
 >> iter 80000, loss: 0.025238
   Number of active neurons: 2
 >> iter 81000, loss: 0.025686
 >> iter 82000, loss: 0.024559
 >> iter 83000, loss: 0.025136
 >> iter 84000, loss: 0.024500
 >> iter 85000, loss: 0.022814
 >> iter 86000, loss: 0.022680
 >> iter 87000, loss: 0.021770
 >> iter 88000, loss: 0.039634
 >> iter 89000, loss: 0.029164
 >> iter 90000, loss: 0.026791
   Number of active neurons: 2
 >> iter 91000, loss: 0.022492
 >> iter 92000, loss: 0.027357
 >> iter 93000, loss: 0.052101
 >> iter 94000, loss: 0.064988
 >> iter 95000, loss: 0.037860
 >> iter 96000, loss: 0.027077
 >> iter 97000, loss: 0.023072
 >> iter 98000, loss: 0.032568
 >> iter 99000, loss: 0.026418
 >> iter 100000, loss: 0.023557
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.949257
 >> iter 2000, loss: 4.068275
 >> iter 3000, loss: 1.546642
 >> iter 4000, loss: 0.601115
 >> iter 5000, loss: 0.239782
 >> iter 6000, loss: 0.107893
 >> iter 7000, loss: 0.058949
 >> iter 8000, loss: 0.036888
 >> iter 9000, loss: 0.036610
 >> iter 10000, loss: 0.029197
   Number of active neurons: 4
 >> iter 11000, loss: 0.029406
 >> iter 12000, loss: 0.026063
 >> iter 13000, loss: 0.028151
 >> iter 14000, loss: 0.039853
 >> iter 15000, loss: 0.036233
 >> iter 16000, loss: 0.041572
 >> iter 17000, loss: 0.033861
 >> iter 18000, loss: 0.033868
 >> iter 19000, loss: 0.049177
 >> iter 20000, loss: 0.034394
   Number of active neurons: 4
 >> iter 21000, loss: 0.028186
 >> iter 22000, loss: 0.027988
 >> iter 23000, loss: 0.030745
 >> iter 24000, loss: 0.030950
 >> iter 25000, loss: 0.057045
 >> iter 26000, loss: 0.039110
 >> iter 27000, loss: 0.028036
 >> iter 28000, loss: 0.043192
 >> iter 29000, loss: 0.040442
 >> iter 30000, loss: 0.030816
   Number of active neurons: 2
 >> iter 31000, loss: 0.024136
 >> iter 32000, loss: 0.023488
 >> iter 33000, loss: 0.026183
 >> iter 34000, loss: 0.022556
 >> iter 35000, loss: 0.020559
 >> iter 36000, loss: 0.019554
 >> iter 37000, loss: 0.022594
 >> iter 38000, loss: 0.020197
 >> iter 39000, loss: 0.043020
 >> iter 40000, loss: 0.028811
   Number of active neurons: 2
 >> iter 41000, loss: 0.032772
 >> iter 42000, loss: 0.024052
 >> iter 43000, loss: 0.044727
 >> iter 44000, loss: 0.029694
 >> iter 45000, loss: 0.026103
 >> iter 46000, loss: 0.036923
 >> iter 47000, loss: 0.027360
 >> iter 48000, loss: 0.022740
 >> iter 49000, loss: 0.023474
 >> iter 50000, loss: 0.044130
   Number of active neurons: 2
 >> iter 51000, loss: 0.041288
 >> iter 52000, loss: 0.047257
 >> iter 53000, loss: 0.040213
 >> iter 54000, loss: 0.034637
 >> iter 55000, loss: 0.048497
 >> iter 56000, loss: 0.035192
 >> iter 57000, loss: 0.027188
 >> iter 58000, loss: 0.034963
 >> iter 59000, loss: 0.025452
 >> iter 60000, loss: 0.022119
   Number of active neurons: 1
 >> iter 61000, loss: 0.028413
 >> iter 62000, loss: 0.026834
 >> iter 63000, loss: 0.021607
 >> iter 64000, loss: 0.018195
 >> iter 65000, loss: 0.020649
 >> iter 66000, loss: 0.019888
 >> iter 67000, loss: 0.021968
 >> iter 68000, loss: 0.020950
 >> iter 69000, loss: 0.019378
 >> iter 70000, loss: 0.017560
   Number of active neurons: 1
 >> iter 71000, loss: 0.018033
 >> iter 72000, loss: 0.017767
 >> iter 73000, loss: 0.021426
 >> iter 74000, loss: 0.023085
 >> iter 75000, loss: 0.037762
 >> iter 76000, loss: 0.031777
 >> iter 77000, loss: 0.022157
 >> iter 78000, loss: 0.035634
 >> iter 79000, loss: 0.023120
 >> iter 80000, loss: 0.022538
   Number of active neurons: 1
 >> iter 81000, loss: 0.030865
 >> iter 82000, loss: 0.021529
 >> iter 83000, loss: 0.017605
 >> iter 84000, loss: 0.017664
 >> iter 85000, loss: 0.025490
 >> iter 86000, loss: 0.021582
 >> iter 87000, loss: 0.023690
 >> iter 88000, loss: 0.020620
 >> iter 89000, loss: 0.023472
 >> iter 90000, loss: 0.019158
   Number of active neurons: 1
 >> iter 91000, loss: 0.018914
 >> iter 92000, loss: 0.017161
 >> iter 93000, loss: 0.021587
 >> iter 94000, loss: 0.024962
 >> iter 95000, loss: 0.019668
 >> iter 96000, loss: 0.018173
 >> iter 97000, loss: 0.027210
 >> iter 98000, loss: 0.021171
 >> iter 99000, loss: 0.019762
 >> iter 100000, loss: 0.023925
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.966450
 >> iter 2000, loss: 4.081837
 >> iter 3000, loss: 1.525542
 >> iter 4000, loss: 0.588431
 >> iter 5000, loss: 0.235873
 >> iter 6000, loss: 0.114034
 >> iter 7000, loss: 0.067941
 >> iter 8000, loss: 0.051804
 >> iter 9000, loss: 0.063425
 >> iter 10000, loss: 0.043557
   Number of active neurons: 4
 >> iter 11000, loss: 0.031391
 >> iter 12000, loss: 0.027619
 >> iter 13000, loss: 0.027180
 >> iter 14000, loss: 0.027691
 >> iter 15000, loss: 0.025633
 >> iter 16000, loss: 0.032228
 >> iter 17000, loss: 0.026447
 >> iter 18000, loss: 0.032965
 >> iter 19000, loss: 0.025870
 >> iter 20000, loss: 0.024957
   Number of active neurons: 2
 >> iter 21000, loss: 0.024539
 >> iter 22000, loss: 0.037455
 >> iter 23000, loss: 0.029062
 >> iter 24000, loss: 0.036283
 >> iter 25000, loss: 0.031100
 >> iter 26000, loss: 0.024320
 >> iter 27000, loss: 0.023275
 >> iter 28000, loss: 0.034574
 >> iter 29000, loss: 0.026370
 >> iter 30000, loss: 0.023280
   Number of active neurons: 2
 >> iter 31000, loss: 0.023191
 >> iter 32000, loss: 0.023477
 >> iter 33000, loss: 0.021782
 >> iter 34000, loss: 0.024075
 >> iter 35000, loss: 0.022962
 >> iter 36000, loss: 0.035305
 >> iter 37000, loss: 0.026900
 >> iter 38000, loss: 0.026804
 >> iter 39000, loss: 0.036439
 >> iter 40000, loss: 0.031172
   Number of active neurons: 2
 >> iter 41000, loss: 0.026299
 >> iter 42000, loss: 0.025507
 >> iter 43000, loss: 0.023164
 >> iter 44000, loss: 0.020381
 >> iter 45000, loss: 0.027538
 >> iter 46000, loss: 0.023135
 >> iter 47000, loss: 0.025378
 >> iter 48000, loss: 0.023135
 >> iter 49000, loss: 0.022299
 >> iter 50000, loss: 0.019298
   Number of active neurons: 2
 >> iter 51000, loss: 0.023343
 >> iter 52000, loss: 0.028375
 >> iter 53000, loss: 0.022272
 >> iter 54000, loss: 0.022829
 >> iter 55000, loss: 0.022739
 >> iter 56000, loss: 0.022420
 >> iter 57000, loss: 0.020107
 >> iter 58000, loss: 0.023937
 >> iter 59000, loss: 0.022004
 >> iter 60000, loss: 0.022891
   Number of active neurons: 1
 >> iter 61000, loss: 0.021492
 >> iter 62000, loss: 0.021180
 >> iter 63000, loss: 0.029610
 >> iter 64000, loss: 0.028609
 >> iter 65000, loss: 0.022859
 >> iter 66000, loss: 0.022034
 >> iter 67000, loss: 0.019938
 >> iter 68000, loss: 0.019161
 >> iter 69000, loss: 0.018286
 >> iter 70000, loss: 0.019544
   Number of active neurons: 1
 >> iter 71000, loss: 0.019653
 >> iter 72000, loss: 0.022686
 >> iter 73000, loss: 0.032549
 >> iter 74000, loss: 0.022344
 >> iter 75000, loss: 0.020072
 >> iter 76000, loss: 0.027949
 >> iter 77000, loss: 0.045527
 >> iter 78000, loss: 0.029076
 >> iter 79000, loss: 0.024287
 >> iter 80000, loss: 0.022265
   Number of active neurons: 1
 >> iter 81000, loss: 0.020654
 >> iter 82000, loss: 0.047291
 >> iter 83000, loss: 0.042441
 >> iter 84000, loss: 0.028290
 >> iter 85000, loss: 0.021981
 >> iter 86000, loss: 0.018589
 >> iter 87000, loss: 0.019548
 >> iter 88000, loss: 0.017085
 >> iter 89000, loss: 0.016780
 >> iter 90000, loss: 0.028823
   Number of active neurons: 1
 >> iter 91000, loss: 0.024339
 >> iter 92000, loss: 0.028927
 >> iter 93000, loss: 0.022386
 >> iter 94000, loss: 0.025819
 >> iter 95000, loss: 0.020677
 >> iter 96000, loss: 0.027278
 >> iter 97000, loss: 0.027244
 >> iter 98000, loss: 0.021095
 >> iter 99000, loss: 0.018843
 >> iter 100000, loss: 0.017674
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.925916
 >> iter 2000, loss: 4.061885
 >> iter 3000, loss: 1.521571
 >> iter 4000, loss: 0.589869
 >> iter 5000, loss: 0.234772
 >> iter 6000, loss: 0.106524
 >> iter 7000, loss: 0.057341
 >> iter 8000, loss: 0.037878
 >> iter 9000, loss: 0.033754
 >> iter 10000, loss: 0.032723
   Number of active neurons: 4
 >> iter 11000, loss: 0.033503
 >> iter 12000, loss: 0.041865
 >> iter 13000, loss: 0.035089
 >> iter 14000, loss: 0.027670
 >> iter 15000, loss: 0.036363
 >> iter 16000, loss: 0.041909
 >> iter 17000, loss: 0.032315
 >> iter 18000, loss: 0.025891
 >> iter 19000, loss: 0.035982
 >> iter 20000, loss: 0.027650
   Number of active neurons: 2
 >> iter 21000, loss: 0.027542
 >> iter 22000, loss: 0.025524
 >> iter 23000, loss: 0.035355
 >> iter 24000, loss: 0.027628
 >> iter 25000, loss: 0.023378
 >> iter 26000, loss: 0.021444
 >> iter 27000, loss: 0.028899
 >> iter 28000, loss: 0.025749
 >> iter 29000, loss: 0.023102
 >> iter 30000, loss: 0.022766
   Number of active neurons: 2
 >> iter 31000, loss: 0.023113
 >> iter 32000, loss: 0.035245
 >> iter 33000, loss: 0.028142
 >> iter 34000, loss: 0.022372
 >> iter 35000, loss: 0.025555
 >> iter 36000, loss: 0.022025
 >> iter 37000, loss: 0.023759
 >> iter 38000, loss: 0.020425
 >> iter 39000, loss: 0.027116
 >> iter 40000, loss: 0.029998
   Number of active neurons: 2
 >> iter 41000, loss: 0.023068
 >> iter 42000, loss: 0.021591
 >> iter 43000, loss: 0.023477
 >> iter 44000, loss: 0.022617
 >> iter 45000, loss: 0.020920
 >> iter 46000, loss: 0.021598
 >> iter 47000, loss: 0.024604
 >> iter 48000, loss: 0.034431
 >> iter 49000, loss: 0.029788
 >> iter 50000, loss: 0.026227
   Number of active neurons: 2
 >> iter 51000, loss: 0.023579
 >> iter 52000, loss: 0.026949
 >> iter 53000, loss: 0.026520
 >> iter 54000, loss: 0.022787
 >> iter 55000, loss: 0.024752
 >> iter 56000, loss: 0.022853
 >> iter 57000, loss: 0.022370
 >> iter 58000, loss: 0.020903
 >> iter 59000, loss: 0.028814
 >> iter 60000, loss: 0.024382
   Number of active neurons: 2
 >> iter 61000, loss: 0.021637
 >> iter 62000, loss: 0.021892
 >> iter 63000, loss: 0.023998
 >> iter 64000, loss: 0.031654
 >> iter 65000, loss: 0.028078
 >> iter 66000, loss: 0.030849
 >> iter 67000, loss: 0.023887
 >> iter 68000, loss: 0.021291
 >> iter 69000, loss: 0.037466
 >> iter 70000, loss: 0.027104
   Number of active neurons: 2
 >> iter 71000, loss: 0.023709
 >> iter 72000, loss: 0.021999
 >> iter 73000, loss: 0.021474
 >> iter 74000, loss: 0.021862
 >> iter 75000, loss: 0.024396
 >> iter 76000, loss: 0.021619
 >> iter 77000, loss: 0.026707
 >> iter 78000, loss: 0.029692
 >> iter 79000, loss: 0.023242
 >> iter 80000, loss: 0.020557
   Number of active neurons: 1
 >> iter 81000, loss: 0.023412
 >> iter 82000, loss: 0.022720
 >> iter 83000, loss: 0.027321
 >> iter 84000, loss: 0.026342
 >> iter 85000, loss: 0.021811
 >> iter 86000, loss: 0.021762
 >> iter 87000, loss: 0.018839
 >> iter 88000, loss: 0.027437
 >> iter 89000, loss: 0.025057
 >> iter 90000, loss: 0.037949
   Number of active neurons: 1
 >> iter 91000, loss: 0.051210
 >> iter 92000, loss: 0.029994
 >> iter 93000, loss: 0.023823
 >> iter 94000, loss: 0.019826
 >> iter 95000, loss: 0.019731
 >> iter 96000, loss: 0.016935
 >> iter 97000, loss: 0.019713
 >> iter 98000, loss: 0.018825
 >> iter 99000, loss: 0.017934
 >> iter 100000, loss: 0.019309
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.018382
 >> iter 2000, loss: 4.100906
 >> iter 3000, loss: 1.540420
 >> iter 4000, loss: 0.592074
 >> iter 5000, loss: 0.240490
 >> iter 6000, loss: 0.107323
 >> iter 7000, loss: 0.062471
 >> iter 8000, loss: 0.042412
 >> iter 9000, loss: 0.032320
 >> iter 10000, loss: 0.027268
   Number of active neurons: 3
 >> iter 11000, loss: 0.035621
 >> iter 12000, loss: 0.030150
 >> iter 13000, loss: 0.034901
 >> iter 14000, loss: 0.027091
 >> iter 15000, loss: 0.026070
 >> iter 16000, loss: 0.028674
 >> iter 17000, loss: 0.026070
 >> iter 18000, loss: 0.028682
 >> iter 19000, loss: 0.027917
 >> iter 20000, loss: 0.025499
   Number of active neurons: 3
 >> iter 21000, loss: 0.029607
 >> iter 22000, loss: 0.025471
 >> iter 23000, loss: 0.030506
 >> iter 24000, loss: 0.026754
 >> iter 25000, loss: 0.033370
 >> iter 26000, loss: 0.031896
 >> iter 27000, loss: 0.027562
 >> iter 28000, loss: 0.026307
 >> iter 29000, loss: 0.024640
 >> iter 30000, loss: 0.024405
   Number of active neurons: 3
 >> iter 31000, loss: 0.023574
 >> iter 32000, loss: 0.044630
 >> iter 33000, loss: 0.035288
 >> iter 34000, loss: 0.028272
 >> iter 35000, loss: 0.028567
 >> iter 36000, loss: 0.025265
 >> iter 37000, loss: 0.022709
 >> iter 38000, loss: 0.020791
 >> iter 39000, loss: 0.027590
 >> iter 40000, loss: 0.024360
   Number of active neurons: 2
 >> iter 41000, loss: 0.022737
 >> iter 42000, loss: 0.032282
 >> iter 43000, loss: 0.048578
 >> iter 44000, loss: 0.034321
 >> iter 45000, loss: 0.028710
 >> iter 46000, loss: 0.036013
 >> iter 47000, loss: 0.028575
 >> iter 48000, loss: 0.022622
 >> iter 49000, loss: 0.023508
 >> iter 50000, loss: 0.022138
   Number of active neurons: 2
 >> iter 51000, loss: 0.046372
 >> iter 52000, loss: 0.032420
 >> iter 53000, loss: 0.031426
 >> iter 54000, loss: 0.025140
 >> iter 55000, loss: 0.026307
 >> iter 56000, loss: 0.023103
 >> iter 57000, loss: 0.021966
 >> iter 58000, loss: 0.041083
 >> iter 59000, loss: 0.027857
 >> iter 60000, loss: 0.023234
   Number of active neurons: 1
 >> iter 61000, loss: 0.019083
 >> iter 62000, loss: 0.019016
 >> iter 63000, loss: 0.031241
 >> iter 64000, loss: 0.024273
 >> iter 65000, loss: 0.020379
 >> iter 66000, loss: 0.018120
 >> iter 67000, loss: 0.029030
 >> iter 68000, loss: 0.025183
 >> iter 69000, loss: 0.021767
 >> iter 70000, loss: 0.018435
   Number of active neurons: 1
 >> iter 71000, loss: 0.022459
 >> iter 72000, loss: 0.022604
 >> iter 73000, loss: 0.020100
 >> iter 74000, loss: 0.017179
 >> iter 75000, loss: 0.023309
 >> iter 76000, loss: 0.018667
 >> iter 77000, loss: 0.020742
 >> iter 78000, loss: 0.019798
 >> iter 79000, loss: 0.017931
 >> iter 80000, loss: 0.018200
   Number of active neurons: 1
 >> iter 81000, loss: 0.018104
 >> iter 82000, loss: 0.019569
 >> iter 83000, loss: 0.021441
 >> iter 84000, loss: 0.019812
 >> iter 85000, loss: 0.016567
 >> iter 86000, loss: 0.021548
 >> iter 87000, loss: 0.018764
 >> iter 88000, loss: 0.017751
 >> iter 89000, loss: 0.016478
 >> iter 90000, loss: 0.018329
   Number of active neurons: 1
 >> iter 91000, loss: 0.017227
 >> iter 92000, loss: 0.038975
 >> iter 93000, loss: 0.024236
 >> iter 94000, loss: 0.021841
 >> iter 95000, loss: 0.022711
 >> iter 96000, loss: 0.027610
 >> iter 97000, loss: 0.020441
 >> iter 98000, loss: 0.024077
 >> iter 99000, loss: 0.021807
 >> iter 100000, loss: 0.024152
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.964014
 >> iter 2000, loss: 4.071332
 >> iter 3000, loss: 1.525197
 >> iter 4000, loss: 0.581167
 >> iter 5000, loss: 0.233392
 >> iter 6000, loss: 0.102905
 >> iter 7000, loss: 0.058045
 >> iter 8000, loss: 0.037858
 >> iter 9000, loss: 0.034479
 >> iter 10000, loss: 0.029521
   Number of active neurons: 4
 >> iter 11000, loss: 0.028645
 >> iter 12000, loss: 0.026469
 >> iter 13000, loss: 0.025466
 >> iter 14000, loss: 0.026502
 >> iter 15000, loss: 0.028458
 >> iter 16000, loss: 0.025864
 >> iter 17000, loss: 0.026101
 >> iter 18000, loss: 0.025894
 >> iter 19000, loss: 0.026463
 >> iter 20000, loss: 0.024935
   Number of active neurons: 3
 >> iter 21000, loss: 0.027764
 >> iter 22000, loss: 0.024251
 >> iter 23000, loss: 0.025674
 >> iter 24000, loss: 0.031388
 >> iter 25000, loss: 0.027283
 >> iter 26000, loss: 0.023434
 >> iter 27000, loss: 0.027268
 >> iter 28000, loss: 0.024217
 >> iter 29000, loss: 0.024961
 >> iter 30000, loss: 0.028452
   Number of active neurons: 3
 >> iter 31000, loss: 0.029551
 >> iter 32000, loss: 0.028198
 >> iter 33000, loss: 0.026114
 >> iter 34000, loss: 0.027610
 >> iter 35000, loss: 0.025718
 >> iter 36000, loss: 0.035201
 >> iter 37000, loss: 0.029724
 >> iter 38000, loss: 0.027624
 >> iter 39000, loss: 0.029583
 >> iter 40000, loss: 0.027623
   Number of active neurons: 3
 >> iter 41000, loss: 0.023500
 >> iter 42000, loss: 0.025784
 >> iter 43000, loss: 0.028149
 >> iter 44000, loss: 0.024696
 >> iter 45000, loss: 0.060196
 >> iter 46000, loss: 0.045270
 >> iter 47000, loss: 0.040062
 >> iter 48000, loss: 0.028075
 >> iter 49000, loss: 0.028423
 >> iter 50000, loss: 0.026188
   Number of active neurons: 3
 >> iter 51000, loss: 0.022825
 >> iter 52000, loss: 0.025299
 >> iter 53000, loss: 0.026613
 >> iter 54000, loss: 0.027879
 >> iter 55000, loss: 0.028173
 >> iter 56000, loss: 0.023455
 >> iter 57000, loss: 0.022139
 >> iter 58000, loss: 0.021717
 >> iter 59000, loss: 0.030104
 >> iter 60000, loss: 0.023679
   Number of active neurons: 2
 >> iter 61000, loss: 0.022016
 >> iter 62000, loss: 0.021967
 >> iter 63000, loss: 0.019855
 >> iter 64000, loss: 0.021625
 >> iter 65000, loss: 0.019769
 >> iter 66000, loss: 0.020404
 >> iter 67000, loss: 0.048387
 >> iter 68000, loss: 0.029918
 >> iter 69000, loss: 0.025635
 >> iter 70000, loss: 0.022923
   Number of active neurons: 2
 >> iter 71000, loss: 0.032400
 >> iter 72000, loss: 0.032034
 >> iter 73000, loss: 0.031413
 >> iter 74000, loss: 0.029003
 >> iter 75000, loss: 0.023416
 >> iter 76000, loss: 0.023213
 >> iter 77000, loss: 0.027039
 >> iter 78000, loss: 0.021906
 >> iter 79000, loss: 0.022142
 >> iter 80000, loss: 0.019886
   Number of active neurons: 2
 >> iter 81000, loss: 0.025479
 >> iter 82000, loss: 0.030940
 >> iter 83000, loss: 0.031271
 >> iter 84000, loss: 0.024706
 >> iter 85000, loss: 0.056824
 >> iter 86000, loss: 0.033523
 >> iter 87000, loss: 0.030606
 >> iter 88000, loss: 0.025779
 >> iter 89000, loss: 0.029490
 >> iter 90000, loss: 0.028665
   Number of active neurons: 2
 >> iter 91000, loss: 0.029463
 >> iter 92000, loss: 0.027180
 >> iter 93000, loss: 0.043023
 >> iter 94000, loss: 0.029640
 >> iter 95000, loss: 0.025823
 >> iter 96000, loss: 0.026447
 >> iter 97000, loss: 0.024474
 >> iter 98000, loss: 0.021144
 >> iter 99000, loss: 0.020295
 >> iter 100000, loss: 0.024145
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.924131
 >> iter 2000, loss: 4.072472
 >> iter 3000, loss: 1.532496
 >> iter 4000, loss: 0.585107
 >> iter 5000, loss: 0.242931
 >> iter 6000, loss: 0.114161
 >> iter 7000, loss: 0.062294
 >> iter 8000, loss: 0.041923
 >> iter 9000, loss: 0.033568
 >> iter 10000, loss: 0.031219
   Number of active neurons: 5
 >> iter 11000, loss: 0.030625
 >> iter 12000, loss: 0.029825
 >> iter 13000, loss: 0.029630
 >> iter 14000, loss: 0.026528
 >> iter 15000, loss: 0.026977
 >> iter 16000, loss: 0.049406
 >> iter 17000, loss: 0.036698
 >> iter 18000, loss: 0.029383
 >> iter 19000, loss: 0.028473
 >> iter 20000, loss: 0.027260
   Number of active neurons: 4
 >> iter 21000, loss: 0.030103
 >> iter 22000, loss: 0.025146
 >> iter 23000, loss: 0.026132
 >> iter 24000, loss: 0.024905
 >> iter 25000, loss: 0.024663
 >> iter 26000, loss: 0.023520
 >> iter 27000, loss: 0.024585
 >> iter 28000, loss: 0.023225
 >> iter 29000, loss: 0.071832
 >> iter 30000, loss: 0.040268
   Number of active neurons: 2
 >> iter 31000, loss: 0.030213
 >> iter 32000, loss: 0.027771
 >> iter 33000, loss: 0.027335
 >> iter 34000, loss: 0.022855
 >> iter 35000, loss: 0.021888
 >> iter 36000, loss: 0.021679
 >> iter 37000, loss: 0.024128
 >> iter 38000, loss: 0.021046
 >> iter 39000, loss: 0.024272
 >> iter 40000, loss: 0.023525
   Number of active neurons: 2
 >> iter 41000, loss: 0.023682
 >> iter 42000, loss: 0.026492
 >> iter 43000, loss: 0.022715
 >> iter 44000, loss: 0.033432
 >> iter 45000, loss: 0.025124
 >> iter 46000, loss: 0.024661
 >> iter 47000, loss: 0.031405
 >> iter 48000, loss: 0.027666
 >> iter 49000, loss: 0.023928
 >> iter 50000, loss: 0.023158
   Number of active neurons: 2
 >> iter 51000, loss: 0.022174
 >> iter 52000, loss: 0.029791
 >> iter 53000, loss: 0.024597
 >> iter 54000, loss: 0.021298
 >> iter 55000, loss: 0.020659
 >> iter 56000, loss: 0.019845
 >> iter 57000, loss: 0.034255
 >> iter 58000, loss: 0.032068
 >> iter 59000, loss: 0.025607
 >> iter 60000, loss: 0.023196
   Number of active neurons: 2
 >> iter 61000, loss: 0.029337
 >> iter 62000, loss: 0.029790
 >> iter 63000, loss: 0.024733
 >> iter 64000, loss: 0.021366
 >> iter 65000, loss: 0.038693
 >> iter 66000, loss: 0.049311
 >> iter 67000, loss: 0.033477
 >> iter 68000, loss: 0.043507
 >> iter 69000, loss: 0.034426
 >> iter 70000, loss: 0.025281
   Number of active neurons: 1
 >> iter 71000, loss: 0.024471
 >> iter 72000, loss: 0.019677
 >> iter 73000, loss: 0.020664
 >> iter 74000, loss: 0.020193
 >> iter 75000, loss: 0.019389
 >> iter 76000, loss: 0.025384
 >> iter 77000, loss: 0.020325
 >> iter 78000, loss: 0.028559
 >> iter 79000, loss: 0.022111
 >> iter 80000, loss: 0.033485
   Number of active neurons: 1
 >> iter 81000, loss: 0.022429
 >> iter 82000, loss: 0.020760
 >> iter 83000, loss: 0.022361
 >> iter 84000, loss: 0.025388
 >> iter 85000, loss: 0.024708
 >> iter 86000, loss: 0.029272
 >> iter 87000, loss: 0.024265
 >> iter 88000, loss: 0.021230
 >> iter 89000, loss: 0.021558
 >> iter 90000, loss: 0.020783
   Number of active neurons: 1
 >> iter 91000, loss: 0.024661
 >> iter 92000, loss: 0.019321
 >> iter 93000, loss: 0.027094
 >> iter 94000, loss: 0.019522
 >> iter 95000, loss: 0.018178
 >> iter 96000, loss: 0.019012
 >> iter 97000, loss: 0.017575
 >> iter 98000, loss: 0.021960
 >> iter 99000, loss: 0.030344
 >> iter 100000, loss: 0.021062
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.962605
 >> iter 2000, loss: 4.083632
 >> iter 3000, loss: 1.524459
 >> iter 4000, loss: 0.584897
 >> iter 5000, loss: 0.235818
 >> iter 6000, loss: 0.106633
 >> iter 7000, loss: 0.079361
 >> iter 8000, loss: 0.048902
 >> iter 9000, loss: 0.041104
 >> iter 10000, loss: 0.033448
   Number of active neurons: 4
 >> iter 11000, loss: 0.029894
 >> iter 12000, loss: 0.027814
 >> iter 13000, loss: 0.033039
 >> iter 14000, loss: 0.060418
 >> iter 15000, loss: 0.045962
 >> iter 16000, loss: 0.042436
 >> iter 17000, loss: 0.034494
 >> iter 18000, loss: 0.030000
 >> iter 19000, loss: 0.031351
 >> iter 20000, loss: 0.040004
   Number of active neurons: 2
 >> iter 21000, loss: 0.033120
 >> iter 22000, loss: 0.033788
 >> iter 23000, loss: 0.025976
 >> iter 24000, loss: 0.023630
 >> iter 25000, loss: 0.023352
 >> iter 26000, loss: 0.024913
 >> iter 27000, loss: 0.024333
 >> iter 28000, loss: 0.031239
 >> iter 29000, loss: 0.025474
 >> iter 30000, loss: 0.034706
   Number of active neurons: 1
 >> iter 31000, loss: 0.024365
 >> iter 32000, loss: 0.021220
 >> iter 33000, loss: 0.018249
 >> iter 34000, loss: 0.024506
 >> iter 35000, loss: 0.025045
 >> iter 36000, loss: 0.027647
 >> iter 37000, loss: 0.022090
 >> iter 38000, loss: 0.019251
 >> iter 39000, loss: 0.016953
 >> iter 40000, loss: 0.015444
   Number of active neurons: 1
 >> iter 41000, loss: 0.014918
 >> iter 42000, loss: 0.014808
 >> iter 43000, loss: 0.019764
 >> iter 44000, loss: 0.018617
 >> iter 45000, loss: 0.027276
 >> iter 46000, loss: 0.024455
 >> iter 47000, loss: 0.024074
 >> iter 48000, loss: 0.019218
 >> iter 49000, loss: 0.019074
 >> iter 50000, loss: 0.017523
   Number of active neurons: 1
 >> iter 51000, loss: 0.015321
 >> iter 52000, loss: 0.015931
 >> iter 53000, loss: 0.016902
 >> iter 54000, loss: 0.019276
 >> iter 55000, loss: 0.023634
 >> iter 56000, loss: 0.022934
 >> iter 57000, loss: 0.018925
 >> iter 58000, loss: 0.017114
 >> iter 59000, loss: 0.020825
 >> iter 60000, loss: 0.020464
   Number of active neurons: 1
 >> iter 61000, loss: 0.033347
 >> iter 62000, loss: 0.029608
 >> iter 63000, loss: 0.025988
 >> iter 64000, loss: 0.020302
 >> iter 65000, loss: 0.017254
 >> iter 66000, loss: 0.016381
 >> iter 67000, loss: 0.017751
 >> iter 68000, loss: 0.016946
 >> iter 69000, loss: 0.017491
 >> iter 70000, loss: 0.017561
   Number of active neurons: 1
 >> iter 71000, loss: 0.021517
 >> iter 72000, loss: 0.018419
 >> iter 73000, loss: 0.023289
 >> iter 74000, loss: 0.020613
 >> iter 75000, loss: 0.017948
 >> iter 76000, loss: 0.017423
 >> iter 77000, loss: 0.019988
 >> iter 78000, loss: 0.045833
 >> iter 79000, loss: 0.028119
 >> iter 80000, loss: 0.026427
   Number of active neurons: 1
 >> iter 81000, loss: 0.028938
 >> iter 82000, loss: 0.021959
 >> iter 83000, loss: 0.021233
 >> iter 84000, loss: 0.031683
 >> iter 85000, loss: 0.021302
 >> iter 86000, loss: 0.017760
 >> iter 87000, loss: 0.020124
 >> iter 88000, loss: 0.031215
 >> iter 89000, loss: 0.021919
 >> iter 90000, loss: 0.018805
   Number of active neurons: 1
 >> iter 91000, loss: 0.024385
 >> iter 92000, loss: 0.017941
 >> iter 93000, loss: 0.029813
 >> iter 94000, loss: 0.026553
 >> iter 95000, loss: 0.020030
 >> iter 96000, loss: 0.018009
 >> iter 97000, loss: 0.024935
 >> iter 98000, loss: 0.027053
 >> iter 99000, loss: 0.029449
 >> iter 100000, loss: 0.022679
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.934826
 >> iter 2000, loss: 4.123436
 >> iter 3000, loss: 1.546801
 >> iter 4000, loss: 0.590241
 >> iter 5000, loss: 0.236245
 >> iter 6000, loss: 0.104807
 >> iter 7000, loss: 0.092334
 >> iter 8000, loss: 0.050684
 >> iter 9000, loss: 0.041738
 >> iter 10000, loss: 0.044775
   Number of active neurons: 3
 >> iter 11000, loss: 0.031036
 >> iter 12000, loss: 0.027946
 >> iter 13000, loss: 0.025449
 >> iter 14000, loss: 0.023874
 >> iter 15000, loss: 0.024609
 >> iter 16000, loss: 0.023485
 >> iter 17000, loss: 0.020729
 >> iter 18000, loss: 0.031670
 >> iter 19000, loss: 0.024689
 >> iter 20000, loss: 0.024111
   Number of active neurons: 2
 >> iter 21000, loss: 0.023809
 >> iter 22000, loss: 0.020907
 >> iter 23000, loss: 0.030450
 >> iter 24000, loss: 0.045066
 >> iter 25000, loss: 0.036899
 >> iter 26000, loss: 0.029283
 >> iter 27000, loss: 0.025505
 >> iter 28000, loss: 0.028840
 >> iter 29000, loss: 0.043392
 >> iter 30000, loss: 0.041303
   Number of active neurons: 2
 >> iter 31000, loss: 0.033486
 >> iter 32000, loss: 0.041996
 >> iter 33000, loss: 0.030472
 >> iter 34000, loss: 0.025046
 >> iter 35000, loss: 0.023965
 >> iter 36000, loss: 0.022054
 >> iter 37000, loss: 0.024255
 >> iter 38000, loss: 0.022476
 >> iter 39000, loss: 0.021189
 >> iter 40000, loss: 0.023372
   Number of active neurons: 2
 >> iter 41000, loss: 0.021486
 >> iter 42000, loss: 0.023791
 >> iter 43000, loss: 0.023382
 >> iter 44000, loss: 0.022288
 >> iter 45000, loss: 0.021873
 >> iter 46000, loss: 0.021692
 >> iter 47000, loss: 0.024262
 >> iter 48000, loss: 0.036415
 >> iter 49000, loss: 0.024724
 >> iter 50000, loss: 0.022411
   Number of active neurons: 1
 >> iter 51000, loss: 0.020223
 >> iter 52000, loss: 0.041718
 >> iter 53000, loss: 0.028878
 >> iter 54000, loss: 0.029536
 >> iter 55000, loss: 0.024912
 >> iter 56000, loss: 0.019152
 >> iter 57000, loss: 0.017228
 >> iter 58000, loss: 0.017213
 >> iter 59000, loss: 0.020692
 >> iter 60000, loss: 0.017865
   Number of active neurons: 1
 >> iter 61000, loss: 0.017557
 >> iter 62000, loss: 0.016328
 >> iter 63000, loss: 0.016124
 >> iter 64000, loss: 0.024172
 >> iter 65000, loss: 0.021132
 >> iter 66000, loss: 0.019828
 >> iter 67000, loss: 0.018148
 >> iter 68000, loss: 0.026094
 >> iter 69000, loss: 0.022493
 >> iter 70000, loss: 0.019403
   Number of active neurons: 1
 >> iter 71000, loss: 0.017058
 >> iter 72000, loss: 0.044975
 >> iter 73000, loss: 0.034035
 >> iter 74000, loss: 0.047357
 >> iter 75000, loss: 0.030374
 >> iter 76000, loss: 0.021987
 >> iter 77000, loss: 0.021764
 >> iter 78000, loss: 0.022074
 >> iter 79000, loss: 0.032632
 >> iter 80000, loss: 0.025834
   Number of active neurons: 1
 >> iter 81000, loss: 0.020184
 >> iter 82000, loss: 0.018081
 >> iter 83000, loss: 0.018331
 >> iter 84000, loss: 0.016982
 >> iter 85000, loss: 0.017228
 >> iter 86000, loss: 0.017673
 >> iter 87000, loss: 0.021027
 >> iter 88000, loss: 0.020178
 >> iter 89000, loss: 0.018462
 >> iter 90000, loss: 0.017602
   Number of active neurons: 1
 >> iter 91000, loss: 0.019412
 >> iter 92000, loss: 0.026356
 >> iter 93000, loss: 0.026297
 >> iter 94000, loss: 0.023741
 >> iter 95000, loss: 0.032292
 >> iter 96000, loss: 0.023869
 >> iter 97000, loss: 0.022030
 >> iter 98000, loss: 0.019081
 >> iter 99000, loss: 0.020418
 >> iter 100000, loss: 0.017976
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.981161
 >> iter 2000, loss: 4.077218
 >> iter 3000, loss: 1.536873
 >> iter 4000, loss: 0.586505
 >> iter 5000, loss: 0.232815
 >> iter 6000, loss: 0.104694
 >> iter 7000, loss: 0.054048
 >> iter 8000, loss: 0.034377
 >> iter 9000, loss: 0.027838
 >> iter 10000, loss: 0.027091
   Number of active neurons: 3
 >> iter 11000, loss: 0.029487
 >> iter 12000, loss: 0.024699
 >> iter 13000, loss: 0.023794
 >> iter 14000, loss: 0.023936
 >> iter 15000, loss: 0.041786
 >> iter 16000, loss: 0.043467
 >> iter 17000, loss: 0.033982
 >> iter 18000, loss: 0.027377
 >> iter 19000, loss: 0.023835
 >> iter 20000, loss: 0.025105
   Number of active neurons: 2
 >> iter 21000, loss: 0.034826
 >> iter 22000, loss: 0.025468
 >> iter 23000, loss: 0.047708
 >> iter 24000, loss: 0.034357
 >> iter 25000, loss: 0.028882
 >> iter 26000, loss: 0.027692
 >> iter 27000, loss: 0.023978
 >> iter 28000, loss: 0.021602
 >> iter 29000, loss: 0.020111
 >> iter 30000, loss: 0.025079
   Number of active neurons: 2
 >> iter 31000, loss: 0.030942
 >> iter 32000, loss: 0.030871
 >> iter 33000, loss: 0.024011
 >> iter 34000, loss: 0.021079
 >> iter 35000, loss: 0.021341
 >> iter 36000, loss: 0.021683
 >> iter 37000, loss: 0.035108
 >> iter 38000, loss: 0.026393
 >> iter 39000, loss: 0.040522
 >> iter 40000, loss: 0.027598
   Number of active neurons: 2
 >> iter 41000, loss: 0.025354
 >> iter 42000, loss: 0.022993
 >> iter 43000, loss: 0.036824
 >> iter 44000, loss: 0.032994
 >> iter 45000, loss: 0.025131
 >> iter 46000, loss: 0.022563
 >> iter 47000, loss: 0.021831
 >> iter 48000, loss: 0.022294
 >> iter 49000, loss: 0.021954
 >> iter 50000, loss: 0.024280
   Number of active neurons: 2
 >> iter 51000, loss: 0.021660
 >> iter 52000, loss: 0.021249
 >> iter 53000, loss: 0.021811
 >> iter 54000, loss: 0.020536
 >> iter 55000, loss: 0.023710
 >> iter 56000, loss: 0.020343
 >> iter 57000, loss: 0.019773
 >> iter 58000, loss: 0.019925
 >> iter 59000, loss: 0.020938
 >> iter 60000, loss: 0.026316
   Number of active neurons: 1
 >> iter 61000, loss: 0.034438
 >> iter 62000, loss: 0.029262
 >> iter 63000, loss: 0.024452
 >> iter 64000, loss: 0.019715
 >> iter 65000, loss: 0.022807
 >> iter 66000, loss: 0.019324
 >> iter 67000, loss: 0.017628
 >> iter 68000, loss: 0.021012
 >> iter 69000, loss: 0.017736
 >> iter 70000, loss: 0.017664
   Number of active neurons: 1
 >> iter 71000, loss: 0.024359
 >> iter 72000, loss: 0.019844
 >> iter 73000, loss: 0.018336
 >> iter 74000, loss: 0.032308
 >> iter 75000, loss: 0.023533
 >> iter 76000, loss: 0.022570
 >> iter 77000, loss: 0.019755
 >> iter 78000, loss: 0.018209
 >> iter 79000, loss: 0.017530
 >> iter 80000, loss: 0.017905
   Number of active neurons: 1
 >> iter 81000, loss: 0.016872
 >> iter 82000, loss: 0.016803
 >> iter 83000, loss: 0.032414
 >> iter 84000, loss: 0.048723
 >> iter 85000, loss: 0.029184
 >> iter 86000, loss: 0.027097
 >> iter 87000, loss: 0.021714
 >> iter 88000, loss: 0.023694
 >> iter 89000, loss: 0.020355
 >> iter 90000, loss: 0.017150
   Number of active neurons: 1
 >> iter 91000, loss: 0.029198
 >> iter 92000, loss: 0.024462
 >> iter 93000, loss: 0.030190
 >> iter 94000, loss: 0.023068
 >> iter 95000, loss: 0.019210
 >> iter 96000, loss: 0.017410
 >> iter 97000, loss: 0.016995
 >> iter 98000, loss: 0.026483
 >> iter 99000, loss: 0.021154
 >> iter 100000, loss: 0.020500
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

