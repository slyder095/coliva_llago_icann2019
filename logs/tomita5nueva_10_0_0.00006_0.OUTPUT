 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 6e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.550441
 >> iter 2000, loss: 10.508400
 >> iter 3000, loss: 8.642462
 >> iter 4000, loss: 7.936482
 >> iter 5000, loss: 7.657560
 >> iter 6000, loss: 7.337514
 >> iter 7000, loss: 7.051817
 >> iter 8000, loss: 6.567246
 >> iter 9000, loss: 2.848976
 >> iter 10000, loss: 1.093241
   Number of active neurons: 7
 >> iter 11000, loss: 0.427029
 >> iter 12000, loss: 0.177039
 >> iter 13000, loss: 0.083889
 >> iter 14000, loss: 0.049361
 >> iter 15000, loss: 0.036712
 >> iter 16000, loss: 0.032043
 >> iter 17000, loss: 0.030589
 >> iter 18000, loss: 0.030196
 >> iter 19000, loss: 0.030298
 >> iter 20000, loss: 0.030402
   Number of active neurons: 7
 >> iter 21000, loss: 0.030652
 >> iter 22000, loss: 0.030764
 >> iter 23000, loss: 0.030977
 >> iter 24000, loss: 0.031068
 >> iter 25000, loss: 0.031195
 >> iter 26000, loss: 0.031199
 >> iter 27000, loss: 0.031193
 >> iter 28000, loss: 0.031090
 >> iter 29000, loss: 0.030999
 >> iter 30000, loss: 0.030877
   Number of active neurons: 7
 >> iter 31000, loss: 0.030799
 >> iter 32000, loss: 0.030690
 >> iter 33000, loss: 0.030633
 >> iter 34000, loss: 0.030496
 >> iter 35000, loss: 0.030356
 >> iter 36000, loss: 0.030161
 >> iter 37000, loss: 0.030011
 >> iter 38000, loss: 0.029836
 >> iter 39000, loss: 0.029723
 >> iter 40000, loss: 0.029578
   Number of active neurons: 7
 >> iter 41000, loss: 0.029490
 >> iter 42000, loss: 0.029337
 >> iter 43000, loss: 0.029244
 >> iter 44000, loss: 0.029087
 >> iter 45000, loss: 0.029004
 >> iter 46000, loss: 0.028872
 >> iter 47000, loss: 0.028806
 >> iter 48000, loss: 0.028671
 >> iter 49000, loss: 0.028604
 >> iter 50000, loss: 0.028433
   Number of active neurons: 6
 >> iter 51000, loss: 0.028319
 >> iter 52000, loss: 0.028118
 >> iter 53000, loss: 0.027926
 >> iter 54000, loss: 0.027678
 >> iter 55000, loss: 0.027441
 >> iter 56000, loss: 0.027225
 >> iter 57000, loss: 0.027015
 >> iter 58000, loss: 0.026839
 >> iter 59000, loss: 0.026637
 >> iter 60000, loss: 0.026481
   Number of active neurons: 7
 >> iter 61000, loss: 0.026281
 >> iter 62000, loss: 0.026146
 >> iter 63000, loss: 0.025997
 >> iter 64000, loss: 0.025920
 >> iter 65000, loss: 0.025808
 >> iter 66000, loss: 0.025761
 >> iter 67000, loss: 0.025670
 >> iter 68000, loss: 0.025646
 >> iter 69000, loss: 0.025567
 >> iter 70000, loss: 0.025552
   Number of active neurons: 7
 >> iter 71000, loss: 0.025481
 >> iter 72000, loss: 0.025479
 >> iter 73000, loss: 0.025399
 >> iter 74000, loss: 0.025366
 >> iter 75000, loss: 0.025257
 >> iter 76000, loss: 0.025201
 >> iter 77000, loss: 0.025073
 >> iter 78000, loss: 0.025053
 >> iter 79000, loss: 0.024969
 >> iter 80000, loss: 0.024981
   Number of active neurons: 7
 >> iter 81000, loss: 0.024916
 >> iter 82000, loss: 0.024953
 >> iter 83000, loss: 0.024890
 >> iter 84000, loss: 0.024941
 >> iter 85000, loss: 0.024880
 >> iter 86000, loss: 0.024943
 >> iter 87000, loss: 0.024878
 >> iter 88000, loss: 0.024943
 >> iter 89000, loss: 0.024879
 >> iter 90000, loss: 0.024946
   Number of active neurons: 7
 >> iter 91000, loss: 0.024877
 >> iter 92000, loss: 0.024951
 >> iter 93000, loss: 0.024875
 >> iter 94000, loss: 0.024946
 >> iter 95000, loss: 0.024882
 >> iter 96000, loss: 0.024945
 >> iter 97000, loss: 0.024880
 >> iter 98000, loss: 0.024942
 >> iter 99000, loss: 0.024875
 >> iter 100000, loss: 0.024933
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.590395
 >> iter 2000, loss: 10.502868
 >> iter 3000, loss: 8.631658
 >> iter 4000, loss: 7.916275
 >> iter 5000, loss: 7.685641
 >> iter 6000, loss: 7.714034
 >> iter 7000, loss: 7.472184
 >> iter 8000, loss: 6.010764
 >> iter 9000, loss: 3.454097
 >> iter 10000, loss: 1.377178
   Number of active neurons: 8
 >> iter 11000, loss: 0.567109
 >> iter 12000, loss: 0.267775
 >> iter 13000, loss: 0.142226
 >> iter 14000, loss: 0.089751
 >> iter 15000, loss: 0.074180
 >> iter 16000, loss: 0.058224
 >> iter 17000, loss: 0.090664
 >> iter 18000, loss: 0.091987
 >> iter 19000, loss: 0.502089
 >> iter 20000, loss: 0.324417
   Number of active neurons: 8
 >> iter 21000, loss: 0.403215
 >> iter 22000, loss: 0.257079
 >> iter 23000, loss: 0.450979
 >> iter 24000, loss: 0.201363
 >> iter 25000, loss: 0.189176
 >> iter 26000, loss: 0.327840
 >> iter 27000, loss: 0.446259
 >> iter 28000, loss: 0.218725
 >> iter 29000, loss: 0.114560
 >> iter 30000, loss: 0.071585
   Number of active neurons: 8
 >> iter 31000, loss: 0.127773
 >> iter 32000, loss: 0.076313
 >> iter 33000, loss: 4.693769
 >> iter 34000, loss: 3.285684
 >> iter 35000, loss: 1.252462
 >> iter 36000, loss: 0.488961
 >> iter 37000, loss: 0.203581
 >> iter 38000, loss: 0.096550
 >> iter 39000, loss: 0.056024
 >> iter 40000, loss: 0.040412
   Number of active neurons: 10
 >> iter 41000, loss: 0.034177
 >> iter 42000, loss: 0.031479
 >> iter 43000, loss: 0.030172
 >> iter 44000, loss: 0.029462
 >> iter 45000, loss: 0.029071
 >> iter 46000, loss: 0.028784
 >> iter 47000, loss: 0.028638
 >> iter 48000, loss: 0.028449
 >> iter 49000, loss: 0.028419
 >> iter 50000, loss: 0.028313
   Number of active neurons: 10
 >> iter 51000, loss: 0.028370
 >> iter 52000, loss: 0.028313
 >> iter 53000, loss: 0.028425
 >> iter 54000, loss: 0.028387
 >> iter 55000, loss: 0.028474
 >> iter 56000, loss: 0.028391
 >> iter 57000, loss: 0.028420
 >> iter 58000, loss: 0.028344
 >> iter 59000, loss: 0.028519
 >> iter 60000, loss: 0.028550
   Number of active neurons: 10
 >> iter 61000, loss: 0.028573
 >> iter 62000, loss: 0.028476
 >> iter 63000, loss: 0.028442
 >> iter 64000, loss: 0.028394
 >> iter 65000, loss: 0.028339
 >> iter 66000, loss: 0.028255
 >> iter 67000, loss: 0.028129
 >> iter 68000, loss: 0.028110
 >> iter 69000, loss: 0.028181
 >> iter 70000, loss: 0.028251
   Number of active neurons: 10
 >> iter 71000, loss: 0.028313
 >> iter 72000, loss: 0.028307
 >> iter 73000, loss: 0.028245
 >> iter 74000, loss: 0.028135
 >> iter 75000, loss: 0.028005
 >> iter 76000, loss: 0.027835
 >> iter 77000, loss: 0.027642
 >> iter 78000, loss: 0.027361
 >> iter 79000, loss: 0.027096
 >> iter 80000, loss: 0.026893
   Number of active neurons: 10
 >> iter 81000, loss: 0.026733
 >> iter 82000, loss: 0.026650
 >> iter 83000, loss: 0.026557
 >> iter 84000, loss: 0.026538
 >> iter 85000, loss: 0.026505
 >> iter 86000, loss: 0.026516
 >> iter 87000, loss: 0.026507
 >> iter 88000, loss: 0.026586
 >> iter 89000, loss: 0.026603
 >> iter 90000, loss: 0.026695
   Number of active neurons: 10
 >> iter 91000, loss: 0.026689
 >> iter 92000, loss: 0.026773
 >> iter 93000, loss: 0.026759
 >> iter 94000, loss: 0.026828
 >> iter 95000, loss: 0.026805
 >> iter 96000, loss: 0.026864
 >> iter 97000, loss: 0.026830
 >> iter 98000, loss: 0.026867
 >> iter 99000, loss: 0.026806
 >> iter 100000, loss: 0.026831
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.664347
 >> iter 2000, loss: 10.542816
 >> iter 3000, loss: 8.653804
 >> iter 4000, loss: 7.928915
 >> iter 5000, loss: 7.685748
 >> iter 6000, loss: 7.562757
 >> iter 7000, loss: 7.551654
 >> iter 8000, loss: 7.370432
 >> iter 9000, loss: 6.847486
 >> iter 10000, loss: 3.580132
   Number of active neurons: 7
 >> iter 11000, loss: 1.428586
 >> iter 12000, loss: 0.591150
 >> iter 13000, loss: 0.265205
 >> iter 14000, loss: 0.137962
 >> iter 15000, loss: 0.086783
 >> iter 16000, loss: 0.065352
 >> iter 17000, loss: 0.055749
 >> iter 18000, loss: 0.050993
 >> iter 19000, loss: 0.048497
 >> iter 20000, loss: 0.046947
   Number of active neurons: 7
 >> iter 21000, loss: 0.046010
 >> iter 22000, loss: 0.045278
 >> iter 23000, loss: 0.044707
 >> iter 24000, loss: 0.044168
 >> iter 25000, loss: 0.043666
 >> iter 26000, loss: 0.043272
 >> iter 27000, loss: 0.042725
 >> iter 28000, loss: 0.047000
 >> iter 29000, loss: 0.042817
 >> iter 30000, loss: 0.045143
   Number of active neurons: 7
 >> iter 31000, loss: 0.041778
 >> iter 32000, loss: 0.054542
 >> iter 33000, loss: 0.045261
 >> iter 34000, loss: 0.045213
 >> iter 35000, loss: 0.041609
 >> iter 36000, loss: 0.041133
 >> iter 37000, loss: 0.039838
 >> iter 38000, loss: 0.039416
 >> iter 39000, loss: 0.039013
 >> iter 40000, loss: 0.039311
   Number of active neurons: 7
 >> iter 41000, loss: 0.038888
 >> iter 42000, loss: 0.038735
 >> iter 43000, loss: 0.038560
 >> iter 44000, loss: 0.038622
 >> iter 45000, loss: 0.038443
 >> iter 46000, loss: 0.038461
 >> iter 47000, loss: 0.038327
 >> iter 48000, loss: 0.038345
 >> iter 49000, loss: 0.038272
 >> iter 50000, loss: 0.038278
   Number of active neurons: 7
 >> iter 51000, loss: 0.038227
 >> iter 52000, loss: 0.038226
 >> iter 53000, loss: 0.038195
 >> iter 54000, loss: 0.038190
 >> iter 55000, loss: 0.038146
 >> iter 56000, loss: 0.038077
 >> iter 57000, loss: 0.037941
 >> iter 58000, loss: 0.037874
 >> iter 59000, loss: 0.037780
 >> iter 60000, loss: 0.037764
   Number of active neurons: 7
 >> iter 61000, loss: 0.037720
 >> iter 62000, loss: 0.037728
 >> iter 63000, loss: 0.037700
 >> iter 64000, loss: 0.037734
 >> iter 65000, loss: 0.037711
 >> iter 66000, loss: 0.037729
 >> iter 67000, loss: 0.037706
 >> iter 68000, loss: 0.037733
 >> iter 69000, loss: 0.037683
 >> iter 70000, loss: 0.037647
   Number of active neurons: 7
 >> iter 71000, loss: 0.037508
 >> iter 72000, loss: 0.037454
 >> iter 73000, loss: 0.037298
 >> iter 74000, loss: 0.037264
 >> iter 75000, loss: 0.037146
 >> iter 76000, loss: 0.037161
 >> iter 77000, loss: 0.036970
 >> iter 78000, loss: 0.036863
 >> iter 79000, loss: 0.036633
 >> iter 80000, loss: 0.036558
   Number of active neurons: 7
 >> iter 81000, loss: 0.036398
 >> iter 82000, loss: 0.036425
 >> iter 83000, loss: 0.036355
 >> iter 84000, loss: 0.036396
 >> iter 85000, loss: 0.036338
 >> iter 86000, loss: 0.036368
 >> iter 87000, loss: 0.036309
 >> iter 88000, loss: 0.036323
 >> iter 89000, loss: 0.036262
 >> iter 90000, loss: 0.036270
   Number of active neurons: 7
 >> iter 91000, loss: 0.036206
 >> iter 92000, loss: 0.036226
 >> iter 93000, loss: 0.036154
 >> iter 94000, loss: 0.036169
 >> iter 95000, loss: 0.036122
 >> iter 96000, loss: 0.036121
 >> iter 97000, loss: 0.036084
 >> iter 98000, loss: 0.036090
 >> iter 99000, loss: 0.036038
 >> iter 100000, loss: 0.036058
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.543147
 >> iter 2000, loss: 10.500171
 >> iter 3000, loss: 8.632631
 >> iter 4000, loss: 7.935019
 >> iter 5000, loss: 7.700649
 >> iter 6000, loss: 7.392388
 >> iter 7000, loss: 6.184448
 >> iter 8000, loss: 2.455620
 >> iter 9000, loss: 0.945394
 >> iter 10000, loss: 0.378533
   Number of active neurons: 8
 >> iter 11000, loss: 0.166019
 >> iter 12000, loss: 0.085459
 >> iter 13000, loss: 0.054608
 >> iter 14000, loss: 0.042157
 >> iter 15000, loss: 0.037019
 >> iter 16000, loss: 0.034523
 >> iter 17000, loss: 0.033334
 >> iter 18000, loss: 0.032510
 >> iter 19000, loss: 0.032115
 >> iter 20000, loss: 0.031763
   Number of active neurons: 8
 >> iter 21000, loss: 0.031623
 >> iter 22000, loss: 0.031431
 >> iter 23000, loss: 0.031381
 >> iter 24000, loss: 0.031236
 >> iter 25000, loss: 0.031201
 >> iter 26000, loss: 0.031011
 >> iter 27000, loss: 0.030919
 >> iter 28000, loss: 0.030760
 >> iter 29000, loss: 0.030732
 >> iter 30000, loss: 0.030621
   Number of active neurons: 8
 >> iter 31000, loss: 0.030603
 >> iter 32000, loss: 0.030483
 >> iter 33000, loss: 0.030401
 >> iter 34000, loss: 0.030236
 >> iter 35000, loss: 0.030102
 >> iter 36000, loss: 0.029947
 >> iter 37000, loss: 0.029719
 >> iter 38000, loss: 0.029494
 >> iter 39000, loss: 0.029257
 >> iter 40000, loss: 0.029078
   Number of active neurons: 8
 >> iter 41000, loss: 0.028840
 >> iter 42000, loss: 0.028662
 >> iter 43000, loss: 0.028454
 >> iter 44000, loss: 0.028301
 >> iter 45000, loss: 0.028092
 >> iter 46000, loss: 0.027966
 >> iter 47000, loss: 0.027757
 >> iter 48000, loss: 0.027625
 >> iter 49000, loss: 0.027425
 >> iter 50000, loss: 0.027314
   Number of active neurons: 8
 >> iter 51000, loss: 0.027131
 >> iter 52000, loss: 0.027048
 >> iter 53000, loss: 0.026886
 >> iter 54000, loss: 0.026841
 >> iter 55000, loss: 0.026699
 >> iter 56000, loss: 0.026697
 >> iter 57000, loss: 0.026560
 >> iter 58000, loss: 0.026564
 >> iter 59000, loss: 0.026417
 >> iter 60000, loss: 0.026431
   Number of active neurons: 7
 >> iter 61000, loss: 0.026286
 >> iter 62000, loss: 0.026333
 >> iter 63000, loss: 0.026217
 >> iter 64000, loss: 0.026279
 >> iter 65000, loss: 0.026175
 >> iter 66000, loss: 0.026255
 >> iter 67000, loss: 0.026138
 >> iter 68000, loss: 0.026186
 >> iter 69000, loss: 0.026033
 >> iter 70000, loss: 0.026051
   Number of active neurons: 7
 >> iter 71000, loss: 0.025856
 >> iter 72000, loss: 0.025869
 >> iter 73000, loss: 0.025701
 >> iter 74000, loss: 0.025729
 >> iter 75000, loss: 0.025558
 >> iter 76000, loss: 0.025589
 >> iter 77000, loss: 0.025445
 >> iter 78000, loss: 0.025518
 >> iter 79000, loss: 0.025420
 >> iter 80000, loss: 0.025476
   Number of active neurons: 7
 >> iter 81000, loss: 0.025365
 >> iter 82000, loss: 0.025425
 >> iter 83000, loss: 0.025304
 >> iter 84000, loss: 0.025379
 >> iter 85000, loss: 0.025264
 >> iter 86000, loss: 0.025347
 >> iter 87000, loss: 0.025235
 >> iter 88000, loss: 0.025321
 >> iter 89000, loss: 0.025212
 >> iter 90000, loss: 0.025300
   Number of active neurons: 7
 >> iter 91000, loss: 0.025189
 >> iter 92000, loss: 0.025287
 >> iter 93000, loss: 0.025166
 >> iter 94000, loss: 0.025266
 >> iter 95000, loss: 0.025159
 >> iter 96000, loss: 0.025249
 >> iter 97000, loss: 0.025145
 >> iter 98000, loss: 0.025237
 >> iter 99000, loss: 0.025132
 >> iter 100000, loss: 0.025222
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.583685
 >> iter 2000, loss: 10.517435
 >> iter 3000, loss: 8.649767
 >> iter 4000, loss: 7.929372
 >> iter 5000, loss: 7.687717
 >> iter 6000, loss: 7.466190
 >> iter 7000, loss: 5.790779
 >> iter 8000, loss: 2.216673
 >> iter 9000, loss: 0.854306
 >> iter 10000, loss: 0.342833
   Number of active neurons: 6
 >> iter 11000, loss: 0.150498
 >> iter 12000, loss: 0.077399
 >> iter 13000, loss: 0.049489
 >> iter 14000, loss: 0.038598
 >> iter 15000, loss: 0.034324
 >> iter 16000, loss: 0.032474
 >> iter 17000, loss: 0.031702
 >> iter 18000, loss: 0.031198
 >> iter 19000, loss: 0.030993
 >> iter 20000, loss: 0.030744
   Number of active neurons: 6
 >> iter 21000, loss: 0.030629
 >> iter 22000, loss: 0.030431
 >> iter 23000, loss: 0.030312
 >> iter 24000, loss: 0.030127
 >> iter 25000, loss: 0.029992
 >> iter 26000, loss: 0.029803
 >> iter 27000, loss: 0.029645
 >> iter 28000, loss: 0.029406
 >> iter 29000, loss: 0.029111
 >> iter 30000, loss: 0.028790
   Number of active neurons: 5
 >> iter 31000, loss: 0.028495
 >> iter 32000, loss: 0.028216
 >> iter 33000, loss: 0.027985
 >> iter 34000, loss: 0.027757
 >> iter 35000, loss: 0.027537
 >> iter 36000, loss: 0.027310
 >> iter 37000, loss: 0.027127
 >> iter 38000, loss: 0.026985
 >> iter 39000, loss: 0.026850
 >> iter 40000, loss: 0.026758
   Number of active neurons: 5
 >> iter 41000, loss: 0.026656
 >> iter 42000, loss: 0.026586
 >> iter 43000, loss: 0.026503
 >> iter 44000, loss: 0.026447
 >> iter 45000, loss: 0.026372
 >> iter 46000, loss: 0.026326
 >> iter 47000, loss: 0.026254
 >> iter 48000, loss: 0.026209
 >> iter 49000, loss: 0.026146
 >> iter 50000, loss: 0.026110
   Number of active neurons: 5
 >> iter 51000, loss: 0.026050
 >> iter 52000, loss: 0.026019
 >> iter 53000, loss: 0.025952
 >> iter 54000, loss: 0.025945
 >> iter 55000, loss: 0.025863
 >> iter 56000, loss: 0.025868
 >> iter 57000, loss: 0.025781
 >> iter 58000, loss: 0.025798
 >> iter 59000, loss: 0.025708
 >> iter 60000, loss: 0.025730
   Number of active neurons: 5
 >> iter 61000, loss: 0.025642
 >> iter 62000, loss: 0.025664
 >> iter 63000, loss: 0.025578
 >> iter 64000, loss: 0.025608
 >> iter 65000, loss: 0.025522
 >> iter 66000, loss: 0.025553
 >> iter 67000, loss: 0.025467
 >> iter 68000, loss: 0.025503
 >> iter 69000, loss: 0.025417
 >> iter 70000, loss: 0.025452
   Number of active neurons: 5
 >> iter 71000, loss: 0.025369
 >> iter 72000, loss: 0.025408
 >> iter 73000, loss: 0.025327
 >> iter 74000, loss: 0.025350
 >> iter 75000, loss: 0.025247
 >> iter 76000, loss: 0.025265
 >> iter 77000, loss: 0.025168
 >> iter 78000, loss: 0.025201
 >> iter 79000, loss: 0.025116
 >> iter 80000, loss: 0.025116
   Number of active neurons: 5
 >> iter 81000, loss: 0.024993
 >> iter 82000, loss: 0.025008
 >> iter 83000, loss: 0.024899
 >> iter 84000, loss: 0.024937
 >> iter 85000, loss: 0.024837
 >> iter 86000, loss: 0.024860
 >> iter 87000, loss: 0.024729
 >> iter 88000, loss: 0.024759
 >> iter 89000, loss: 0.024653
 >> iter 90000, loss: 0.024706
   Number of active neurons: 5
 >> iter 91000, loss: 0.024612
 >> iter 92000, loss: 0.024683
 >> iter 93000, loss: 0.024593
 >> iter 94000, loss: 0.024666
 >> iter 95000, loss: 0.024591
 >> iter 96000, loss: 0.024659
 >> iter 97000, loss: 0.024586
 >> iter 98000, loss: 0.024653
 >> iter 99000, loss: 0.024581
 >> iter 100000, loss: 0.024646
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.597929
 >> iter 2000, loss: 10.520681
 >> iter 3000, loss: 8.644907
 >> iter 4000, loss: 7.929138
 >> iter 5000, loss: 7.702378
 >> iter 6000, loss: 7.741894
 >> iter 7000, loss: 7.546689
 >> iter 8000, loss: 6.741935
 >> iter 9000, loss: 3.368614
 >> iter 10000, loss: 1.605006
   Number of active neurons: 8
 >> iter 11000, loss: 0.986303
 >> iter 12000, loss: 0.727123
 >> iter 13000, loss: 0.383975
 >> iter 14000, loss: 0.164341
 >> iter 15000, loss: 0.350827
 >> iter 16000, loss: 0.243094
 >> iter 17000, loss: 0.125470
 >> iter 18000, loss: 0.076613
 >> iter 19000, loss: 0.056914
 >> iter 20000, loss: 0.047804
   Number of active neurons: 8
 >> iter 21000, loss: 0.044032
 >> iter 22000, loss: 0.041485
 >> iter 23000, loss: 0.040160
 >> iter 24000, loss: 0.038683
 >> iter 25000, loss: 0.037349
 >> iter 26000, loss: 0.035906
 >> iter 27000, loss: 0.334112
 >> iter 28000, loss: 0.148890
 >> iter 29000, loss: 0.077914
 >> iter 30000, loss: 0.050997
   Number of active neurons: 8
 >> iter 31000, loss: 0.040132
 >> iter 32000, loss: 0.072851
 >> iter 33000, loss: 0.046986
 >> iter 34000, loss: 0.050094
 >> iter 35000, loss: 0.037596
 >> iter 36000, loss: 0.034564
 >> iter 37000, loss: 0.032330
 >> iter 38000, loss: 0.032575
 >> iter 39000, loss: 0.031904
 >> iter 40000, loss: 0.059062
   Number of active neurons: 8
 >> iter 41000, loss: 0.042101
 >> iter 42000, loss: 0.069307
 >> iter 43000, loss: 0.045051
 >> iter 44000, loss: 0.085796
 >> iter 45000, loss: 0.051665
 >> iter 46000, loss: 0.039555
 >> iter 47000, loss: 0.034627
 >> iter 48000, loss: 0.099482
 >> iter 49000, loss: 0.057473
 >> iter 50000, loss: 0.074480
   Number of active neurons: 7
 >> iter 51000, loss: 0.048592
 >> iter 52000, loss: 0.058943
 >> iter 53000, loss: 0.042585
 >> iter 54000, loss: 0.068027
 >> iter 55000, loss: 0.045782
 >> iter 56000, loss: 0.075535
 >> iter 57000, loss: 0.048421
 >> iter 58000, loss: 0.065578
 >> iter 59000, loss: 0.044889
 >> iter 60000, loss: 0.058123
   Number of active neurons: 7
 >> iter 61000, loss: 0.042226
 >> iter 62000, loss: 0.079938
 >> iter 63000, loss: 0.050084
 >> iter 64000, loss: 0.075654
 >> iter 65000, loss: 0.048929
 >> iter 66000, loss: 0.058193
 >> iter 67000, loss: 0.041791
 >> iter 68000, loss: 0.036914
 >> iter 69000, loss: 0.033798
 >> iter 70000, loss: 0.033615
   Number of active neurons: 7
 >> iter 71000, loss: 0.032822
 >> iter 72000, loss: 0.033131
 >> iter 73000, loss: 0.032661
 >> iter 74000, loss: 0.032869
 >> iter 75000, loss: 0.032517
 >> iter 76000, loss: 0.032718
 >> iter 77000, loss: 0.032461
 >> iter 78000, loss: 0.032668
 >> iter 79000, loss: 0.032432
 >> iter 80000, loss: 0.032556
   Number of active neurons: 7
 >> iter 81000, loss: 0.032287
 >> iter 82000, loss: 0.032442
 >> iter 83000, loss: 0.032235
 >> iter 84000, loss: 0.032445
 >> iter 85000, loss: 0.032293
 >> iter 86000, loss: 0.032482
 >> iter 87000, loss: 0.032353
 >> iter 88000, loss: 0.032528
 >> iter 89000, loss: 0.032399
 >> iter 90000, loss: 0.031808
   Number of active neurons: 7
 >> iter 91000, loss: 0.030848
 >> iter 92000, loss: 0.030124
 >> iter 93000, loss: 0.029446
 >> iter 94000, loss: 0.029004
 >> iter 95000, loss: 0.028528
 >> iter 96000, loss: 0.028232
 >> iter 97000, loss: 0.027814
 >> iter 98000, loss: 0.027547
 >> iter 99000, loss: 0.027122
 >> iter 100000, loss: 0.026998
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.626546
 >> iter 2000, loss: 10.537507
 >> iter 3000, loss: 8.665520
 >> iter 4000, loss: 7.945843
 >> iter 5000, loss: 7.697124
 >> iter 6000, loss: 7.562269
 >> iter 7000, loss: 7.276117
 >> iter 8000, loss: 4.971386
 >> iter 9000, loss: 1.900946
 >> iter 10000, loss: 0.737453
   Number of active neurons: 7
 >> iter 11000, loss: 0.301465
 >> iter 12000, loss: 0.137028
 >> iter 13000, loss: 0.074233
 >> iter 14000, loss: 0.048825
 >> iter 15000, loss: 0.037772
 >> iter 16000, loss: 0.032786
 >> iter 17000, loss: 0.030678
 >> iter 18000, loss: 0.029787
 >> iter 19000, loss: 0.029529
 >> iter 20000, loss: 0.029493
   Number of active neurons: 7
 >> iter 21000, loss: 0.029584
 >> iter 22000, loss: 0.029705
 >> iter 23000, loss: 0.029931
 >> iter 24000, loss: 0.030135
 >> iter 25000, loss: 0.030217
 >> iter 26000, loss: 0.030278
 >> iter 27000, loss: 0.030226
 >> iter 28000, loss: 0.030178
 >> iter 29000, loss: 0.029998
 >> iter 30000, loss: 0.029871
   Number of active neurons: 7
 >> iter 31000, loss: 0.029650
 >> iter 32000, loss: 0.029513
 >> iter 33000, loss: 0.029313
 >> iter 34000, loss: 0.029190
 >> iter 35000, loss: 0.028996
 >> iter 36000, loss: 0.028861
 >> iter 37000, loss: 0.028660
 >> iter 38000, loss: 0.028524
 >> iter 39000, loss: 0.028324
 >> iter 40000, loss: 0.028176
   Number of active neurons: 7
 >> iter 41000, loss: 0.027977
 >> iter 42000, loss: 0.027792
 >> iter 43000, loss: 0.027564
 >> iter 44000, loss: 0.027382
 >> iter 45000, loss: 0.027193
 >> iter 46000, loss: 0.027049
 >> iter 47000, loss: 0.026866
 >> iter 48000, loss: 0.026707
 >> iter 49000, loss: 0.026561
 >> iter 50000, loss: 0.026444
   Number of active neurons: 7
 >> iter 51000, loss: 0.026331
 >> iter 52000, loss: 0.026239
 >> iter 53000, loss: 0.026132
 >> iter 54000, loss: 0.026065
 >> iter 55000, loss: 0.025939
 >> iter 56000, loss: 0.025875
 >> iter 57000, loss: 0.025748
 >> iter 58000, loss: 0.025704
 >> iter 59000, loss: 0.025552
 >> iter 60000, loss: 0.025504
   Number of active neurons: 7
 >> iter 61000, loss: 0.025377
 >> iter 62000, loss: 0.025372
 >> iter 63000, loss: 0.025278
 >> iter 64000, loss: 0.025311
 >> iter 65000, loss: 0.025228
 >> iter 66000, loss: 0.025275
 >> iter 67000, loss: 0.025188
 >> iter 68000, loss: 0.025243
 >> iter 69000, loss: 0.025144
 >> iter 70000, loss: 0.025139
   Number of active neurons: 7
 >> iter 71000, loss: 0.024968
 >> iter 72000, loss: 0.024954
 >> iter 73000, loss: 0.024798
 >> iter 74000, loss: 0.024792
 >> iter 75000, loss: 0.024638
 >> iter 76000, loss: 0.024640
 >> iter 77000, loss: 0.024509
 >> iter 78000, loss: 0.024539
 >> iter 79000, loss: 0.024429
 >> iter 80000, loss: 0.024470
   Number of active neurons: 7
 >> iter 81000, loss: 0.024361
 >> iter 82000, loss: 0.024416
 >> iter 83000, loss: 0.024295
 >> iter 84000, loss: 0.024329
 >> iter 85000, loss: 0.024169
 >> iter 86000, loss: 0.024217
 >> iter 87000, loss: 0.024071
 >> iter 88000, loss: 0.024139
 >> iter 89000, loss: 0.023999
 >> iter 90000, loss: 0.024076
   Number of active neurons: 7
 >> iter 91000, loss: 0.023930
 >> iter 92000, loss: 0.024016
 >> iter 93000, loss: 0.023858
 >> iter 94000, loss: 0.023939
 >> iter 95000, loss: 0.023782
 >> iter 96000, loss: 0.023850
 >> iter 97000, loss: 0.023677
 >> iter 98000, loss: 0.023731
 >> iter 99000, loss: 0.023542
 >> iter 100000, loss: 0.023573
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.583737
 >> iter 2000, loss: 10.509998
 >> iter 3000, loss: 8.642455
 >> iter 4000, loss: 7.921167
 >> iter 5000, loss: 7.672437
 >> iter 6000, loss: 7.545600
 >> iter 7000, loss: 7.269687
 >> iter 8000, loss: 6.116638
 >> iter 9000, loss: 2.351991
 >> iter 10000, loss: 0.904754
   Number of active neurons: 6
 >> iter 11000, loss: 0.361949
 >> iter 12000, loss: 0.157897
 >> iter 13000, loss: 0.080715
 >> iter 14000, loss: 0.051023
 >> iter 15000, loss: 0.039368
 >> iter 16000, loss: 0.034476
 >> iter 17000, loss: 0.032345
 >> iter 18000, loss: 0.031220
 >> iter 19000, loss: 0.030617
 >> iter 20000, loss: 0.030187
   Number of active neurons: 6
 >> iter 21000, loss: 0.029944
 >> iter 22000, loss: 0.029763
 >> iter 23000, loss: 0.029565
 >> iter 24000, loss: 0.029410
 >> iter 25000, loss: 0.029239
 >> iter 26000, loss: 0.029142
 >> iter 27000, loss: 0.029015
 >> iter 28000, loss: 0.028920
 >> iter 29000, loss: 0.028755
 >> iter 30000, loss: 0.028689
   Number of active neurons: 6
 >> iter 31000, loss: 0.028541
 >> iter 32000, loss: 0.028500
 >> iter 33000, loss: 0.028357
 >> iter 34000, loss: 0.028307
 >> iter 35000, loss: 0.028154
 >> iter 36000, loss: 0.028099
 >> iter 37000, loss: 0.027939
 >> iter 38000, loss: 0.027906
 >> iter 39000, loss: 0.027727
 >> iter 40000, loss: 0.027653
   Number of active neurons: 6
 >> iter 41000, loss: 0.027425
 >> iter 42000, loss: 0.027257
 >> iter 43000, loss: 0.027010
 >> iter 44000, loss: 0.026861
 >> iter 45000, loss: 0.026675
 >> iter 46000, loss: 0.026565
 >> iter 47000, loss: 0.026430
 >> iter 48000, loss: 0.026352
 >> iter 49000, loss: 0.026250
 >> iter 50000, loss: 0.026192
   Number of active neurons: 6
 >> iter 51000, loss: 0.026100
 >> iter 52000, loss: 0.026035
 >> iter 53000, loss: 0.025912
 >> iter 54000, loss: 0.025858
 >> iter 55000, loss: 0.025715
 >> iter 56000, loss: 0.025650
 >> iter 57000, loss: 0.025475
 >> iter 58000, loss: 0.025391
 >> iter 59000, loss: 0.025225
 >> iter 60000, loss: 0.025154
   Number of active neurons: 6
 >> iter 61000, loss: 0.025007
 >> iter 62000, loss: 0.024950
 >> iter 63000, loss: 0.024816
 >> iter 64000, loss: 0.024775
 >> iter 65000, loss: 0.024644
 >> iter 66000, loss: 0.024603
 >> iter 67000, loss: 0.024447
 >> iter 68000, loss: 0.024380
 >> iter 69000, loss: 0.024236
 >> iter 70000, loss: 0.024202
   Number of active neurons: 6
 >> iter 71000, loss: 0.024092
 >> iter 72000, loss: 0.024075
 >> iter 73000, loss: 0.023953
 >> iter 74000, loss: 0.023935
 >> iter 75000, loss: 0.023826
 >> iter 76000, loss: 0.023829
 >> iter 77000, loss: 0.023732
 >> iter 78000, loss: 0.023753
 >> iter 79000, loss: 0.023671
 >> iter 80000, loss: 0.023700
   Number of active neurons: 6
 >> iter 81000, loss: 0.023620
 >> iter 82000, loss: 0.023662
 >> iter 83000, loss: 0.023577
 >> iter 84000, loss: 0.023630
 >> iter 85000, loss: 0.023526
 >> iter 86000, loss: 0.023560
 >> iter 87000, loss: 0.023437
 >> iter 88000, loss: 0.023495
 >> iter 89000, loss: 0.023385
 >> iter 90000, loss: 0.023453
   Number of active neurons: 6
 >> iter 91000, loss: 0.023339
 >> iter 92000, loss: 0.023415
 >> iter 93000, loss: 0.023295
 >> iter 94000, loss: 0.023367
 >> iter 95000, loss: 0.023256
 >> iter 96000, loss: 0.023322
 >> iter 97000, loss: 0.023208
 >> iter 98000, loss: 0.023272
 >> iter 99000, loss: 0.023156
 >> iter 100000, loss: 0.023218
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.646684
 >> iter 2000, loss: 10.545392
 >> iter 3000, loss: 8.662742
 >> iter 4000, loss: 7.935503
 >> iter 5000, loss: 7.704368
 >> iter 6000, loss: 7.595132
 >> iter 7000, loss: 7.359689
 >> iter 8000, loss: 4.382559
 >> iter 9000, loss: 1.672372
 >> iter 10000, loss: 0.650444
   Number of active neurons: 7
 >> iter 11000, loss: 0.267355
 >> iter 12000, loss: 0.122998
 >> iter 13000, loss: 0.068318
 >> iter 14000, loss: 0.047094
 >> iter 15000, loss: 0.038806
 >> iter 16000, loss: 0.035210
 >> iter 17000, loss: 0.033607
 >> iter 18000, loss: 0.032572
 >> iter 19000, loss: 0.032005
 >> iter 20000, loss: 0.031424
   Number of active neurons: 6
 >> iter 21000, loss: 0.031044
 >> iter 22000, loss: 0.030602
 >> iter 23000, loss: 0.030348
 >> iter 24000, loss: 0.030019
 >> iter 25000, loss: 0.029859
 >> iter 26000, loss: 0.029611
 >> iter 27000, loss: 0.029476
 >> iter 28000, loss: 0.029260
 >> iter 29000, loss: 0.029156
 >> iter 30000, loss: 0.028990
   Number of active neurons: 6
 >> iter 31000, loss: 0.028911
 >> iter 32000, loss: 0.028762
 >> iter 33000, loss: 0.028694
 >> iter 34000, loss: 0.028584
 >> iter 35000, loss: 0.028516
 >> iter 36000, loss: 0.028388
 >> iter 37000, loss: 0.028293
 >> iter 38000, loss: 0.028170
 >> iter 39000, loss: 0.028067
 >> iter 40000, loss: 0.027983
   Number of active neurons: 6
 >> iter 41000, loss: 0.027929
 >> iter 42000, loss: 0.027883
 >> iter 43000, loss: 0.027843
 >> iter 44000, loss: 0.027790
 >> iter 45000, loss: 0.027734
 >> iter 46000, loss: 0.027698
 >> iter 47000, loss: 0.027645
 >> iter 48000, loss: 0.027575
 >> iter 49000, loss: 0.027483
 >> iter 50000, loss: 0.027417
   Number of active neurons: 6
 >> iter 51000, loss: 0.027334
 >> iter 52000, loss: 0.027266
 >> iter 53000, loss: 0.027170
 >> iter 54000, loss: 0.027146
 >> iter 55000, loss: 0.027048
 >> iter 56000, loss: 0.027046
 >> iter 57000, loss: 0.026932
 >> iter 58000, loss: 0.026929
 >> iter 59000, loss: 0.026772
 >> iter 60000, loss: 0.026771
   Number of active neurons: 6
 >> iter 61000, loss: 0.026633
 >> iter 62000, loss: 0.026654
 >> iter 63000, loss: 0.026522
 >> iter 64000, loss: 0.026556
 >> iter 65000, loss: 0.026418
 >> iter 66000, loss: 0.026448
 >> iter 67000, loss: 0.026304
 >> iter 68000, loss: 0.026339
 >> iter 69000, loss: 0.026189
 >> iter 70000, loss: 0.026219
   Number of active neurons: 6
 >> iter 71000, loss: 0.026069
 >> iter 72000, loss: 0.026099
 >> iter 73000, loss: 0.025945
 >> iter 74000, loss: 0.025969
 >> iter 75000, loss: 0.025805
 >> iter 76000, loss: 0.025819
 >> iter 77000, loss: 0.025640
 >> iter 78000, loss: 0.025643
 >> iter 79000, loss: 0.025460
 >> iter 80000, loss: 0.025436
   Number of active neurons: 5
 >> iter 81000, loss: 0.025209
 >> iter 82000, loss: 0.025164
 >> iter 83000, loss: 0.024954
 >> iter 84000, loss: 0.024941
 >> iter 85000, loss: 0.024766
 >> iter 86000, loss: 0.024795
 >> iter 87000, loss: 0.024643
 >> iter 88000, loss: 0.024691
 >> iter 89000, loss: 0.024555
 >> iter 90000, loss: 0.024614
   Number of active neurons: 6
 >> iter 91000, loss: 0.024479
 >> iter 92000, loss: 0.024549
 >> iter 93000, loss: 0.024415
 >> iter 94000, loss: 0.024483
 >> iter 95000, loss: 0.024359
 >> iter 96000, loss: 0.024393
 >> iter 97000, loss: 0.024233
 >> iter 98000, loss: 0.024268
 >> iter 99000, loss: 0.024128
 >> iter 100000, loss: 0.024177
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.553778
 >> iter 2000, loss: 10.495215
 >> iter 3000, loss: 8.625329
 >> iter 4000, loss: 7.896663
 >> iter 5000, loss: 7.689031
 >> iter 6000, loss: 7.476051
 >> iter 7000, loss: 4.978641
 >> iter 8000, loss: 1.903665
 >> iter 9000, loss: 0.739929
 >> iter 10000, loss: 0.302965
   Number of active neurons: 8
 >> iter 11000, loss: 0.138552
 >> iter 12000, loss: 0.075943
 >> iter 13000, loss: 0.051772
 >> iter 14000, loss: 0.042029
 >> iter 15000, loss: 0.038006
 >> iter 16000, loss: 0.036029
 >> iter 17000, loss: 0.035061
 >> iter 18000, loss: 0.034384
 >> iter 19000, loss: 0.034030
 >> iter 20000, loss: 0.033658
   Number of active neurons: 5
 >> iter 21000, loss: 0.033466
 >> iter 22000, loss: 0.033209
 >> iter 23000, loss: 0.033047
 >> iter 24000, loss: 0.032797
 >> iter 25000, loss: 0.032618
 >> iter 26000, loss: 0.032354
 >> iter 27000, loss: 0.032157
 >> iter 28000, loss: 0.031897
 >> iter 29000, loss: 0.031684
 >> iter 30000, loss: 0.031429
   Number of active neurons: 5
 >> iter 31000, loss: 0.031220
 >> iter 32000, loss: 0.031004
 >> iter 33000, loss: 0.030848
 >> iter 34000, loss: 0.030704
 >> iter 35000, loss: 0.030634
 >> iter 36000, loss: 0.030554
 >> iter 37000, loss: 0.030528
 >> iter 38000, loss: 0.030487
 >> iter 39000, loss: 0.030466
 >> iter 40000, loss: 0.030426
   Number of active neurons: 4
 >> iter 41000, loss: 0.030376
 >> iter 42000, loss: 0.030247
 >> iter 43000, loss: 0.030094
 >> iter 44000, loss: 0.029891
 >> iter 45000, loss: 0.029722
 >> iter 46000, loss: 0.029527
 >> iter 47000, loss: 0.029360
 >> iter 48000, loss: 0.029160
 >> iter 49000, loss: 0.028989
 >> iter 50000, loss: 0.028787
   Number of active neurons: 5
 >> iter 51000, loss: 0.028599
 >> iter 52000, loss: 0.028391
 >> iter 53000, loss: 0.028222
 >> iter 54000, loss: 0.028095
 >> iter 55000, loss: 0.027954
 >> iter 56000, loss: 0.027872
 >> iter 57000, loss: 0.027746
 >> iter 58000, loss: 0.027697
 >> iter 59000, loss: 0.027583
 >> iter 60000, loss: 0.027556
   Number of active neurons: 5
 >> iter 61000, loss: 0.027454
 >> iter 62000, loss: 0.027437
 >> iter 63000, loss: 0.027323
 >> iter 64000, loss: 0.027279
 >> iter 65000, loss: 0.027155
 >> iter 66000, loss: 0.027127
 >> iter 67000, loss: 0.027023
 >> iter 68000, loss: 0.027021
 >> iter 69000, loss: 0.026928
 >> iter 70000, loss: 0.026883
   Number of active neurons: 5
 >> iter 71000, loss: 0.026717
 >> iter 72000, loss: 0.026661
 >> iter 73000, loss: 0.026511
 >> iter 74000, loss: 0.026442
 >> iter 75000, loss: 0.026267
 >> iter 76000, loss: 0.026211
 >> iter 77000, loss: 0.026059
 >> iter 78000, loss: 0.026036
 >> iter 79000, loss: 0.025920
 >> iter 80000, loss: 0.025914
   Number of active neurons: 5
 >> iter 81000, loss: 0.025814
 >> iter 82000, loss: 0.025830
 >> iter 83000, loss: 0.025737
 >> iter 84000, loss: 0.025765
 >> iter 85000, loss: 0.025681
 >> iter 86000, loss: 0.025722
 >> iter 87000, loss: 0.025640
 >> iter 88000, loss: 0.025684
 >> iter 89000, loss: 0.025607
 >> iter 90000, loss: 0.025655
   Number of active neurons: 5
 >> iter 91000, loss: 0.025578
 >> iter 92000, loss: 0.025630
 >> iter 93000, loss: 0.025533
 >> iter 94000, loss: 0.025561
 >> iter 95000, loss: 0.025478
 >> iter 96000, loss: 0.025509
 >> iter 97000, loss: 0.025430
 >> iter 98000, loss: 0.025442
 >> iter 99000, loss: 0.025364
 >> iter 100000, loss: 0.025387
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.571026
 >> iter 2000, loss: 10.506781
 >> iter 3000, loss: 8.639807
 >> iter 4000, loss: 7.950105
 >> iter 5000, loss: 7.715081
 >> iter 6000, loss: 7.594620
 >> iter 7000, loss: 7.130094
 >> iter 8000, loss: 3.733056
 >> iter 9000, loss: 1.463508
 >> iter 10000, loss: 0.594023
   Number of active neurons: 7
 >> iter 11000, loss: 0.264031
 >> iter 12000, loss: 0.134107
 >> iter 13000, loss: 0.083458
 >> iter 14000, loss: 0.062028
 >> iter 15000, loss: 0.053075
 >> iter 16000, loss: 0.048220
 >> iter 17000, loss: 0.045878
 >> iter 18000, loss: 0.043911
 >> iter 19000, loss: 0.042884
 >> iter 20000, loss: 0.041686
   Number of active neurons: 7
 >> iter 21000, loss: 0.041113
 >> iter 22000, loss: 0.040345
 >> iter 23000, loss: 0.039990
 >> iter 24000, loss: 0.039423
 >> iter 25000, loss: 0.039178
 >> iter 26000, loss: 0.038708
 >> iter 27000, loss: 0.038489
 >> iter 28000, loss: 0.038042
 >> iter 29000, loss: 0.037807
 >> iter 30000, loss: 0.037359
   Number of active neurons: 7
 >> iter 31000, loss: 0.037139
 >> iter 32000, loss: 0.036751
 >> iter 33000, loss: 0.036656
 >> iter 34000, loss: 0.036422
 >> iter 35000, loss: 0.036414
 >> iter 36000, loss: 0.036243
 >> iter 37000, loss: 0.036198
 >> iter 38000, loss: 0.036035
 >> iter 39000, loss: 0.035958
 >> iter 40000, loss: 0.035773
   Number of active neurons: 7
 >> iter 41000, loss: 0.035688
 >> iter 42000, loss: 0.035509
 >> iter 43000, loss: 0.035465
 >> iter 44000, loss: 0.035357
 >> iter 45000, loss: 0.035321
 >> iter 46000, loss: 0.035187
 >> iter 47000, loss: 0.035123
 >> iter 48000, loss: 0.035001
 >> iter 49000, loss: 0.034998
 >> iter 50000, loss: 0.034891
   Number of active neurons: 7
 >> iter 51000, loss: 0.034886
 >> iter 52000, loss: 0.034775
 >> iter 53000, loss: 0.034821
 >> iter 54000, loss: 0.034690
 >> iter 55000, loss: 0.034775
 >> iter 56000, loss: 0.034600
 >> iter 57000, loss: 0.034592
 >> iter 58000, loss: 0.034325
 >> iter 59000, loss: 0.034265
 >> iter 60000, loss: 0.033950
   Number of active neurons: 6
 >> iter 61000, loss: 0.033769
 >> iter 62000, loss: 0.033316
 >> iter 63000, loss: 0.033007
 >> iter 64000, loss: 0.032596
 >> iter 65000, loss: 0.032354
 >> iter 66000, loss: 0.032022
 >> iter 67000, loss: 0.031825
 >> iter 68000, loss: 0.031579
 >> iter 69000, loss: 0.031486
 >> iter 70000, loss: 0.031333
   Number of active neurons: 6
 >> iter 71000, loss: 0.031293
 >> iter 72000, loss: 0.031179
 >> iter 73000, loss: 0.031167
 >> iter 74000, loss: 0.031073
 >> iter 75000, loss: 0.031081
 >> iter 76000, loss: 0.031006
 >> iter 77000, loss: 0.031024
 >> iter 78000, loss: 0.030959
 >> iter 79000, loss: 0.030986
 >> iter 80000, loss: 0.030921
   Number of active neurons: 6
 >> iter 81000, loss: 0.030941
 >> iter 82000, loss: 0.030894
 >> iter 83000, loss: 0.030926
 >> iter 84000, loss: 0.030867
 >> iter 85000, loss: 0.030909
 >> iter 86000, loss: 0.030853
 >> iter 87000, loss: 0.030905
 >> iter 88000, loss: 0.030848
 >> iter 89000, loss: 0.030888
 >> iter 90000, loss: 0.030840
   Number of active neurons: 6
 >> iter 91000, loss: 0.030864
 >> iter 92000, loss: 0.030801
 >> iter 93000, loss: 0.030829
 >> iter 94000, loss: 0.030765
 >> iter 95000, loss: 0.030803
 >> iter 96000, loss: 0.030757
 >> iter 97000, loss: 0.030790
 >> iter 98000, loss: 0.030748
 >> iter 99000, loss: 0.030758
 >> iter 100000, loss: 0.030714
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.553754
 >> iter 2000, loss: 10.478099
 >> iter 3000, loss: 8.608576
 >> iter 4000, loss: 7.899434
 >> iter 5000, loss: 7.642044
 >> iter 6000, loss: 7.646597
 >> iter 7000, loss: 7.957233
 >> iter 8000, loss: 7.878805
 >> iter 9000, loss: 7.932072
 >> iter 10000, loss: 8.733677
   Number of active neurons: 6
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 6
 >> iter 11000, loss: 6.713426
 >> iter 12000, loss: 2.754086
 >> iter 13000, loss: 1.092376
 >> iter 14000, loss: 0.458799
 >> iter 15000, loss: 0.342666
 >> iter 16000, loss: 0.168295
 >> iter 17000, loss: 0.096819
 >> iter 18000, loss: 0.073848
 >> iter 19000, loss: 0.070594
 >> iter 20000, loss: 0.055542
   Number of active neurons: 8
 >> iter 21000, loss: 0.052841
 >> iter 22000, loss: 0.047372
 >> iter 23000, loss: 0.045158
 >> iter 24000, loss: 0.043672
 >> iter 25000, loss: 0.043423
 >> iter 26000, loss: 0.042844
 >> iter 27000, loss: 0.043082
 >> iter 28000, loss: 0.042623
 >> iter 29000, loss: 0.043296
 >> iter 30000, loss: 0.042380
   Number of active neurons: 8
 >> iter 31000, loss: 0.043127
 >> iter 32000, loss: 0.106546
 >> iter 33000, loss: 0.099818
 >> iter 34000, loss: 0.247968
 >> iter 35000, loss: 0.120162
 >> iter 36000, loss: 0.108018
 >> iter 37000, loss: 0.153289
 >> iter 38000, loss: 0.113510
 >> iter 39000, loss: 0.300623
 >> iter 40000, loss: 0.175565
   Number of active neurons: 7
 >> iter 41000, loss: 0.194789
 >> iter 42000, loss: 0.104670
 >> iter 43000, loss: 0.158257
 >> iter 44000, loss: 0.113140
 >> iter 45000, loss: 0.219438
 >> iter 46000, loss: 0.123599
 >> iter 47000, loss: 0.072028
 >> iter 48000, loss: 0.052345
 >> iter 49000, loss: 0.044002
 >> iter 50000, loss: 0.039826
   Number of active neurons: 7
 >> iter 51000, loss: 0.038398
 >> iter 52000, loss: 0.036951
 >> iter 53000, loss: 0.037614
 >> iter 54000, loss: 0.035791
 >> iter 55000, loss: 0.036303
 >> iter 56000, loss: 0.034958
 >> iter 57000, loss: 0.060548
 >> iter 58000, loss: 0.042640
 >> iter 59000, loss: 0.034419
 >> iter 60000, loss: 0.029697
   Number of active neurons: 7
 >> iter 61000, loss: 0.027226
 >> iter 62000, loss: 0.025953
 >> iter 63000, loss: 0.025210
 >> iter 64000, loss: 0.024887
 >> iter 65000, loss: 0.024871
 >> iter 66000, loss: 0.025049
 >> iter 67000, loss: 0.025205
 >> iter 68000, loss: 0.025396
 >> iter 69000, loss: 0.025412
 >> iter 70000, loss: 0.025481
   Number of active neurons: 7
 >> iter 71000, loss: 0.025452
 >> iter 72000, loss: 0.025483
 >> iter 73000, loss: 0.025450
 >> iter 74000, loss: 0.025438
 >> iter 75000, loss: 0.025405
 >> iter 76000, loss: 0.025357
 >> iter 77000, loss: 0.025325
 >> iter 78000, loss: 0.025225
 >> iter 79000, loss: 0.025176
 >> iter 80000, loss: 0.025055
   Number of active neurons: 6
 >> iter 81000, loss: 0.025015
 >> iter 82000, loss: 0.024886
 >> iter 83000, loss: 0.024877
 >> iter 84000, loss: 0.024756
 >> iter 85000, loss: 0.024798
 >> iter 86000, loss: 0.024668
 >> iter 87000, loss: 0.024737
 >> iter 88000, loss: 0.024623
 >> iter 89000, loss: 0.024693
 >> iter 90000, loss: 0.024599
   Number of active neurons: 6
 >> iter 91000, loss: 0.024665
 >> iter 92000, loss: 0.024627
 >> iter 93000, loss: 0.024663
 >> iter 94000, loss: 0.024661
 >> iter 95000, loss: 0.024682
 >> iter 96000, loss: 0.024695
 >> iter 97000, loss: 0.024706
 >> iter 98000, loss: 0.024687
 >> iter 99000, loss: 0.024713
 >> iter 100000, loss: 0.024680
   Number of active neurons: 6
 >> iter 101000, loss: 0.024714
 >> iter 102000, loss: 0.024688
 >> iter 103000, loss: 0.024719
 >> iter 104000, loss: 0.024672
 >> iter 105000, loss: 0.024713
 >> iter 106000, loss: 0.024655
 >> iter 107000, loss: 0.024722
 >> iter 108000, loss: 0.024650
 >> iter 109000, loss: 0.024723
 >> iter 110000, loss: 0.024644
   Number of active neurons: 6
 >> iter 111000, loss: 0.024732
 >> iter 112000, loss: 0.024643
 >> iter 113000, loss: 0.024741
 >> iter 114000, loss: 0.024644
 >> iter 115000, loss: 0.024750
 >> iter 116000, loss: 0.024642
 >> iter 117000, loss: 0.024754
 >> iter 118000, loss: 0.024642
 >> iter 119000, loss: 0.024755
 >> iter 120000, loss: 0.024638
   Number of active neurons: 6
 >> iter 121000, loss: 0.024751
 >> iter 122000, loss: 0.024636
 >> iter 123000, loss: 0.024753
 >> iter 124000, loss: 0.024634
 >> iter 125000, loss: 0.024758
 >> iter 126000, loss: 0.024633
 >> iter 127000, loss: 0.024758
 >> iter 128000, loss: 0.024636
 >> iter 129000, loss: 0.024764
 >> iter 130000, loss: 0.024642
   Number of active neurons: 6
 >> iter 131000, loss: 0.024766
 >> iter 132000, loss: 0.024659
 >> iter 133000, loss: 0.024771
 >> iter 134000, loss: 0.024658
 >> iter 135000, loss: 0.024766
 >> iter 136000, loss: 0.024663
 >> iter 137000, loss: 0.024765
 >> iter 138000, loss: 0.024674
 >> iter 139000, loss: 0.024757
 >> iter 140000, loss: 0.024669
   Number of active neurons: 6
 >> iter 141000, loss: 0.024757
 >> iter 142000, loss: 0.024659
 >> iter 143000, loss: 0.024747
 >> iter 144000, loss: 0.024656
 >> iter 145000, loss: 0.024741
 >> iter 146000, loss: 0.024650
 >> iter 147000, loss: 0.024724
 >> iter 148000, loss: 0.024645
 >> iter 149000, loss: 0.024706
 >> iter 150000, loss: 0.024640
   Number of active neurons: 6
 >> iter 151000, loss: 0.024691
 >> iter 152000, loss: 0.024635
 >> iter 153000, loss: 0.024683
 >> iter 154000, loss: 0.024649
 >> iter 155000, loss: 0.024664
 >> iter 156000, loss: 0.024651
 >> iter 157000, loss: 0.024652
 >> iter 158000, loss: 0.024643
 >> iter 159000, loss: 0.024639
 >> iter 160000, loss: 0.024630
   Number of active neurons: 6
 >> iter 161000, loss: 0.024619
 >> iter 162000, loss: 0.024620
 >> iter 163000, loss: 0.024608
 >> iter 164000, loss: 0.024612
 >> iter 165000, loss: 0.024594
 >> iter 166000, loss: 0.024618
 >> iter 167000, loss: 0.024577
 >> iter 168000, loss: 0.024617
 >> iter 169000, loss: 0.024558
 >> iter 170000, loss: 0.024625
   Number of active neurons: 6
 >> iter 171000, loss: 0.024544
 >> iter 172000, loss: 0.024623
 >> iter 173000, loss: 0.024525
 >> iter 174000, loss: 0.024612
 >> iter 175000, loss: 0.024514
 >> iter 176000, loss: 0.024602
 >> iter 177000, loss: 0.024503
 >> iter 178000, loss: 0.024586
 >> iter 179000, loss: 0.024495
 >> iter 180000, loss: 0.024574
   Number of active neurons: 6
 >> iter 181000, loss: 0.024480
 >> iter 182000, loss: 0.024558
 >> iter 183000, loss: 0.024444
 >> iter 184000, loss: 0.024461
 >> iter 185000, loss: 0.024328
 >> iter 186000, loss: 0.024338
 >> iter 187000, loss: 0.024228
 >> iter 188000, loss: 0.024206
 >> iter 189000, loss: 0.024162
 >> iter 190000, loss: 0.024175
   Number of active neurons: 6
 >> iter 191000, loss: 0.024127
 >> iter 192000, loss: 0.024226
 >> iter 193000, loss: 0.024091
 >> iter 194000, loss: 0.024175
 >> iter 195000, loss: 0.024008
 >> iter 196000, loss: 0.024072
 >> iter 197000, loss: 0.023905
 >> iter 198000, loss: 0.024008
 >> iter 199000, loss: 0.023857
 >> iter 200000, loss: 0.023985
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.551757
 >> iter 2000, loss: 10.488342
 >> iter 3000, loss: 8.624159
 >> iter 4000, loss: 7.903429
 >> iter 5000, loss: 7.695349
 >> iter 6000, loss: 7.461147
 >> iter 7000, loss: 6.965168
 >> iter 8000, loss: 3.287436
 >> iter 9000, loss: 1.252153
 >> iter 10000, loss: 0.490723
   Number of active neurons: 7
 >> iter 11000, loss: 0.206307
 >> iter 12000, loss: 0.099352
 >> iter 13000, loss: 0.058849
 >> iter 14000, loss: 0.042965
 >> iter 15000, loss: 0.036487
 >> iter 16000, loss: 0.033406
 >> iter 17000, loss: 0.031924
 >> iter 18000, loss: 0.030918
 >> iter 19000, loss: 0.030352
 >> iter 20000, loss: 0.029813
   Number of active neurons: 5
 >> iter 21000, loss: 0.029487
 >> iter 22000, loss: 0.029128
 >> iter 23000, loss: 0.028882
 >> iter 24000, loss: 0.028593
 >> iter 25000, loss: 0.028417
 >> iter 26000, loss: 0.028230
 >> iter 27000, loss: 0.028102
 >> iter 28000, loss: 0.027946
 >> iter 29000, loss: 0.027787
 >> iter 30000, loss: 0.027614
   Number of active neurons: 5
 >> iter 31000, loss: 0.027420
 >> iter 32000, loss: 0.027238
 >> iter 33000, loss: 0.027092
 >> iter 34000, loss: 0.026949
 >> iter 35000, loss: 0.026838
 >> iter 36000, loss: 0.026725
 >> iter 37000, loss: 0.026630
 >> iter 38000, loss: 0.026548
 >> iter 39000, loss: 0.026457
 >> iter 40000, loss: 0.026392
   Number of active neurons: 5
 >> iter 41000, loss: 0.026312
 >> iter 42000, loss: 0.026251
 >> iter 43000, loss: 0.026181
 >> iter 44000, loss: 0.026127
 >> iter 45000, loss: 0.026064
 >> iter 46000, loss: 0.026012
 >> iter 47000, loss: 0.025945
 >> iter 48000, loss: 0.025882
 >> iter 49000, loss: 0.025815
 >> iter 50000, loss: 0.025748
   Number of active neurons: 5
 >> iter 51000, loss: 0.025662
 >> iter 52000, loss: 0.025583
 >> iter 53000, loss: 0.025490
 >> iter 54000, loss: 0.025425
 >> iter 55000, loss: 0.025317
 >> iter 56000, loss: 0.025258
 >> iter 57000, loss: 0.025145
 >> iter 58000, loss: 0.025080
 >> iter 59000, loss: 0.024948
 >> iter 60000, loss: 0.024867
   Number of active neurons: 5
 >> iter 61000, loss: 0.024724
 >> iter 62000, loss: 0.024628
 >> iter 63000, loss: 0.024446
 >> iter 64000, loss: 0.024323
 >> iter 65000, loss: 0.024145
 >> iter 66000, loss: 0.024071
 >> iter 67000, loss: 0.023943
 >> iter 68000, loss: 0.023920
 >> iter 69000, loss: 0.023823
 >> iter 70000, loss: 0.023822
   Number of active neurons: 5
 >> iter 71000, loss: 0.023743
 >> iter 72000, loss: 0.023762
 >> iter 73000, loss: 0.023690
 >> iter 74000, loss: 0.023720
 >> iter 75000, loss: 0.023651
 >> iter 76000, loss: 0.023688
 >> iter 77000, loss: 0.023618
 >> iter 78000, loss: 0.023658
 >> iter 79000, loss: 0.023561
 >> iter 80000, loss: 0.023579
   Number of active neurons: 5
 >> iter 81000, loss: 0.023490
 >> iter 82000, loss: 0.023541
 >> iter 83000, loss: 0.023453
 >> iter 84000, loss: 0.023515
 >> iter 85000, loss: 0.023424
 >> iter 86000, loss: 0.023491
 >> iter 87000, loss: 0.023392
 >> iter 88000, loss: 0.023458
 >> iter 89000, loss: 0.023354
 >> iter 90000, loss: 0.023421
   Number of active neurons: 5
 >> iter 91000, loss: 0.023310
 >> iter 92000, loss: 0.023381
 >> iter 93000, loss: 0.023263
 >> iter 94000, loss: 0.023330
 >> iter 95000, loss: 0.023221
 >> iter 96000, loss: 0.023283
 >> iter 97000, loss: 0.023171
 >> iter 98000, loss: 0.023232
 >> iter 99000, loss: 0.023118
 >> iter 100000, loss: 0.023178
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.564483
 >> iter 2000, loss: 10.510244
 >> iter 3000, loss: 8.644838
 >> iter 4000, loss: 7.935945
 >> iter 5000, loss: 7.726233
 >> iter 6000, loss: 7.671864
 >> iter 7000, loss: 7.163529
 >> iter 8000, loss: 2.976892
 >> iter 9000, loss: 1.152970
 >> iter 10000, loss: 0.464726
   Number of active neurons: 8
 >> iter 11000, loss: 0.205089
 >> iter 12000, loss: 0.106202
 >> iter 13000, loss: 0.068180
 >> iter 14000, loss: 0.052959
 >> iter 15000, loss: 0.046762
 >> iter 16000, loss: 0.043779
 >> iter 17000, loss: 0.042305
 >> iter 18000, loss: 0.041172
 >> iter 19000, loss: 0.040501
 >> iter 20000, loss: 0.039764
   Number of active neurons: 8
 >> iter 21000, loss: 0.039392
 >> iter 22000, loss: 0.038836
 >> iter 23000, loss: 0.038604
 >> iter 24000, loss: 0.038149
 >> iter 25000, loss: 0.038037
 >> iter 26000, loss: 0.037716
 >> iter 27000, loss: 0.037686
 >> iter 28000, loss: 0.037449
 >> iter 29000, loss: 0.037455
 >> iter 30000, loss: 0.037244
   Number of active neurons: 8
 >> iter 31000, loss: 0.037258
 >> iter 32000, loss: 0.037079
 >> iter 33000, loss: 0.037087
 >> iter 34000, loss: 0.036899
 >> iter 35000, loss: 0.036876
 >> iter 36000, loss: 0.036680
 >> iter 37000, loss: 0.036650
 >> iter 38000, loss: 0.036492
 >> iter 39000, loss: 0.036478
 >> iter 40000, loss: 0.036348
   Number of active neurons: 8
 >> iter 41000, loss: 0.036324
 >> iter 42000, loss: 0.036206
 >> iter 43000, loss: 0.036159
 >> iter 44000, loss: 0.036029
 >> iter 45000, loss: 0.035972
 >> iter 46000, loss: 0.035900
 >> iter 47000, loss: 0.035869
 >> iter 48000, loss: 0.035797
 >> iter 49000, loss: 0.035790
 >> iter 50000, loss: 0.035752
   Number of active neurons: 8
 >> iter 51000, loss: 0.035763
 >> iter 52000, loss: 0.035729
 >> iter 53000, loss: 0.035776
 >> iter 54000, loss: 0.035725
 >> iter 55000, loss: 0.035804
 >> iter 56000, loss: 0.035747
 >> iter 57000, loss: 0.035840
 >> iter 58000, loss: 0.035768
 >> iter 59000, loss: 0.035839
 >> iter 60000, loss: 0.035786
   Number of active neurons: 8
 >> iter 61000, loss: 0.035860
 >> iter 62000, loss: 0.035807
 >> iter 63000, loss: 0.035885
 >> iter 64000, loss: 0.035817
 >> iter 65000, loss: 0.035880
 >> iter 66000, loss: 0.035770
 >> iter 67000, loss: 0.035765
 >> iter 68000, loss: 0.035627
 >> iter 69000, loss: 0.035668
 >> iter 70000, loss: 0.035564
   Number of active neurons: 8
 >> iter 71000, loss: 0.035631
 >> iter 72000, loss: 0.035515
 >> iter 73000, loss: 0.035604
 >> iter 74000, loss: 0.035502
 >> iter 75000, loss: 0.035631
 >> iter 76000, loss: 0.035533
 >> iter 77000, loss: 0.035674
 >> iter 78000, loss: 0.035540
 >> iter 79000, loss: 0.035635
 >> iter 80000, loss: 0.035457
   Number of active neurons: 8
 >> iter 81000, loss: 0.035457
 >> iter 82000, loss: 0.035174
 >> iter 83000, loss: 0.035149
 >> iter 84000, loss: 0.034839
 >> iter 85000, loss: 0.034803
 >> iter 86000, loss: 0.034401
 >> iter 87000, loss: 0.034263
 >> iter 88000, loss: 0.033777
 >> iter 89000, loss: 0.033540
 >> iter 90000, loss: 0.032985
   Number of active neurons: 6
 >> iter 91000, loss: 0.032747
 >> iter 92000, loss: 0.032194
 >> iter 93000, loss: 0.031934
 >> iter 94000, loss: 0.031425
 >> iter 95000, loss: 0.031265
 >> iter 96000, loss: 0.030971
 >> iter 97000, loss: 0.030931
 >> iter 98000, loss: 0.030762
 >> iter 99000, loss: 0.030778
 >> iter 100000, loss: 0.030674
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.609443
 >> iter 2000, loss: 10.527613
 >> iter 3000, loss: 8.652553
 >> iter 4000, loss: 7.933428
 >> iter 5000, loss: 7.696884
 >> iter 6000, loss: 7.710536
 >> iter 7000, loss: 7.309772
 >> iter 8000, loss: 2.960407
 >> iter 9000, loss: 1.169080
 >> iter 10000, loss: 0.480271
   Number of active neurons: 8
 >> iter 11000, loss: 0.215720
 >> iter 12000, loss: 0.115212
 >> iter 13000, loss: 0.073267
 >> iter 14000, loss: 0.058659
 >> iter 15000, loss: 0.049753
 >> iter 16000, loss: 0.048043
 >> iter 17000, loss: 0.044429
 >> iter 18000, loss: 0.043546
 >> iter 19000, loss: 0.041947
 >> iter 20000, loss: 0.041674
   Number of active neurons: 7
 >> iter 21000, loss: 0.040828
 >> iter 22000, loss: 0.040643
 >> iter 23000, loss: 0.039901
 >> iter 24000, loss: 0.039755
 >> iter 25000, loss: 0.039107
 >> iter 26000, loss: 0.038980
 >> iter 27000, loss: 0.038296
 >> iter 28000, loss: 0.038090
 >> iter 29000, loss: 0.037266
 >> iter 30000, loss: 0.037040
   Number of active neurons: 7
 >> iter 31000, loss: 0.036237
 >> iter 32000, loss: 0.036108
 >> iter 33000, loss: 0.035354
 >> iter 34000, loss: 0.035275
 >> iter 35000, loss: 0.034572
 >> iter 36000, loss: 0.034519
 >> iter 37000, loss: 0.033834
 >> iter 38000, loss: 0.033766
 >> iter 39000, loss: 0.033116
 >> iter 40000, loss: 0.032997
   Number of active neurons: 7
 >> iter 41000, loss: 0.032357
 >> iter 42000, loss: 0.032197
 >> iter 43000, loss: 0.031677
 >> iter 44000, loss: 0.031569
 >> iter 45000, loss: 0.031132
 >> iter 46000, loss: 0.031064
 >> iter 47000, loss: 0.030693
 >> iter 48000, loss: 0.030653
 >> iter 49000, loss: 0.030342
 >> iter 50000, loss: 0.030300
   Number of active neurons: 7
 >> iter 51000, loss: 0.030030
 >> iter 52000, loss: 0.029986
 >> iter 53000, loss: 0.029770
 >> iter 54000, loss: 0.029679
 >> iter 55000, loss: 0.029551
 >> iter 56000, loss: 0.029319
 >> iter 57000, loss: 0.029289
 >> iter 58000, loss: 0.028951
 >> iter 59000, loss: 0.028993
 >> iter 60000, loss: 0.028624
   Number of active neurons: 7
 >> iter 61000, loss: 0.028761
 >> iter 62000, loss: 0.028374
 >> iter 63000, loss: 0.028345
 >> iter 64000, loss: 0.028113
 >> iter 65000, loss: 0.028095
 >> iter 66000, loss: 0.027958
 >> iter 67000, loss: 0.027947
 >> iter 68000, loss: 0.027869
 >> iter 69000, loss: 0.027845
 >> iter 70000, loss: 0.027777
   Number of active neurons: 7
 >> iter 71000, loss: 0.027737
 >> iter 72000, loss: 0.027677
 >> iter 73000, loss: 0.027626
 >> iter 74000, loss: 0.027555
 >> iter 75000, loss: 0.027487
 >> iter 76000, loss: 0.027380
 >> iter 77000, loss: 0.027286
 >> iter 78000, loss: 0.027192
 >> iter 79000, loss: 0.027115
 >> iter 80000, loss: 0.027054
   Number of active neurons: 7
 >> iter 81000, loss: 0.026987
 >> iter 82000, loss: 0.026953
 >> iter 83000, loss: 0.026897
 >> iter 84000, loss: 0.026870
 >> iter 85000, loss: 0.026818
 >> iter 86000, loss: 0.026799
 >> iter 87000, loss: 0.026747
 >> iter 88000, loss: 0.026707
 >> iter 89000, loss: 0.026629
 >> iter 90000, loss: 0.026598
   Number of active neurons: 7
 >> iter 91000, loss: 0.026522
 >> iter 92000, loss: 0.026510
 >> iter 93000, loss: 0.026456
 >> iter 94000, loss: 0.026449
 >> iter 95000, loss: 0.026411
 >> iter 96000, loss: 0.026423
 >> iter 97000, loss: 0.026382
 >> iter 98000, loss: 0.026402
 >> iter 99000, loss: 0.026367
 >> iter 100000, loss: 0.026376
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.584276
 >> iter 2000, loss: 10.499991
 >> iter 3000, loss: 8.625609
 >> iter 4000, loss: 7.897975
 >> iter 5000, loss: 7.658865
 >> iter 6000, loss: 7.111232
 >> iter 7000, loss: 2.778131
 >> iter 8000, loss: 1.066005
 >> iter 9000, loss: 0.422512
 >> iter 10000, loss: 0.180355
   Number of active neurons: 5
 >> iter 11000, loss: 0.088682
 >> iter 12000, loss: 0.053361
 >> iter 13000, loss: 0.039525
 >> iter 14000, loss: 0.033811
 >> iter 15000, loss: 0.031405
 >> iter 16000, loss: 0.030219
 >> iter 17000, loss: 0.029646
 >> iter 18000, loss: 0.029218
 >> iter 19000, loss: 0.028921
 >> iter 20000, loss: 0.028633
   Number of active neurons: 5
 >> iter 21000, loss: 0.028439
 >> iter 22000, loss: 0.028235
 >> iter 23000, loss: 0.028083
 >> iter 24000, loss: 0.027920
 >> iter 25000, loss: 0.027790
 >> iter 26000, loss: 0.027663
 >> iter 27000, loss: 0.027558
 >> iter 28000, loss: 0.027455
 >> iter 29000, loss: 0.027329
 >> iter 30000, loss: 0.027195
   Number of active neurons: 5
 >> iter 31000, loss: 0.027037
 >> iter 32000, loss: 0.026884
 >> iter 33000, loss: 0.026729
 >> iter 34000, loss: 0.026612
 >> iter 35000, loss: 0.026494
 >> iter 36000, loss: 0.026415
 >> iter 37000, loss: 0.026314
 >> iter 38000, loss: 0.026272
 >> iter 39000, loss: 0.026172
 >> iter 40000, loss: 0.026143
   Number of active neurons: 5
 >> iter 41000, loss: 0.026049
 >> iter 42000, loss: 0.026024
 >> iter 43000, loss: 0.025938
 >> iter 44000, loss: 0.025917
 >> iter 45000, loss: 0.025831
 >> iter 46000, loss: 0.025817
 >> iter 47000, loss: 0.025732
 >> iter 48000, loss: 0.025715
 >> iter 49000, loss: 0.025637
 >> iter 50000, loss: 0.025628
   Number of active neurons: 5
 >> iter 51000, loss: 0.025553
 >> iter 52000, loss: 0.025532
 >> iter 53000, loss: 0.025426
 >> iter 54000, loss: 0.025427
 >> iter 55000, loss: 0.025320
 >> iter 56000, loss: 0.025350
 >> iter 57000, loss: 0.025248
 >> iter 58000, loss: 0.025296
 >> iter 59000, loss: 0.025196
 >> iter 60000, loss: 0.025251
   Number of active neurons: 5
 >> iter 61000, loss: 0.025154
 >> iter 62000, loss: 0.025210
 >> iter 63000, loss: 0.025114
 >> iter 64000, loss: 0.025178
 >> iter 65000, loss: 0.025083
 >> iter 66000, loss: 0.025146
 >> iter 67000, loss: 0.025049
 >> iter 68000, loss: 0.025118
 >> iter 69000, loss: 0.025021
 >> iter 70000, loss: 0.025087
   Number of active neurons: 5
 >> iter 71000, loss: 0.024993
 >> iter 72000, loss: 0.025063
 >> iter 73000, loss: 0.024970
 >> iter 74000, loss: 0.025035
 >> iter 75000, loss: 0.024937
 >> iter 76000, loss: 0.024992
 >> iter 77000, loss: 0.024890
 >> iter 78000, loss: 0.024948
 >> iter 79000, loss: 0.024860
 >> iter 80000, loss: 0.024911
   Number of active neurons: 5
 >> iter 81000, loss: 0.024821
 >> iter 82000, loss: 0.024878
 >> iter 83000, loss: 0.024782
 >> iter 84000, loss: 0.024844
 >> iter 85000, loss: 0.024746
 >> iter 86000, loss: 0.024815
 >> iter 87000, loss: 0.024688
 >> iter 88000, loss: 0.024719
 >> iter 89000, loss: 0.024581
 >> iter 90000, loss: 0.024627
   Number of active neurons: 5
 >> iter 91000, loss: 0.024502
 >> iter 92000, loss: 0.024567
 >> iter 93000, loss: 0.024447
 >> iter 94000, loss: 0.024513
 >> iter 95000, loss: 0.024411
 >> iter 96000, loss: 0.024471
 >> iter 97000, loss: 0.024372
 >> iter 98000, loss: 0.024430
 >> iter 99000, loss: 0.024332
 >> iter 100000, loss: 0.024389
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.660925
 >> iter 2000, loss: 10.550163
 >> iter 3000, loss: 8.660053
 >> iter 4000, loss: 7.939553
 >> iter 5000, loss: 7.772737
 >> iter 6000, loss: 8.250014
 >> iter 7000, loss: 8.138748
 >> iter 8000, loss: 8.396062
 >> iter 9000, loss: 4.214970
 >> iter 10000, loss: 1.622445
   Number of active neurons: 8
 >> iter 11000, loss: 0.636528
 >> iter 12000, loss: 0.263159
 >> iter 13000, loss: 0.122620
 >> iter 14000, loss: 0.069840
 >> iter 15000, loss: 0.049116
 >> iter 16000, loss: 0.040918
 >> iter 17000, loss: 0.037279
 >> iter 18000, loss: 0.035594
 >> iter 19000, loss: 0.034803
 >> iter 20000, loss: 0.034052
   Number of active neurons: 8
 >> iter 21000, loss: 0.033841
 >> iter 22000, loss: 0.033349
 >> iter 23000, loss: 0.033304
 >> iter 24000, loss: 0.032930
 >> iter 25000, loss: 0.032876
 >> iter 26000, loss: 0.032544
 >> iter 27000, loss: 0.032572
 >> iter 28000, loss: 0.032258
 >> iter 29000, loss: 0.032276
 >> iter 30000, loss: 0.031891
   Number of active neurons: 8
 >> iter 31000, loss: 0.031885
 >> iter 32000, loss: 0.031491
 >> iter 33000, loss: 0.031505
 >> iter 34000, loss: 0.031152
 >> iter 35000, loss: 0.031181
 >> iter 36000, loss: 0.030886
 >> iter 37000, loss: 0.030884
 >> iter 38000, loss: 0.030568
 >> iter 39000, loss: 0.030454
 >> iter 40000, loss: 0.030167
   Number of active neurons: 8
 >> iter 41000, loss: 0.029761
 >> iter 42000, loss: 0.029514
 >> iter 43000, loss: 0.029105
 >> iter 44000, loss: 0.028966
 >> iter 45000, loss: 0.028645
 >> iter 46000, loss: 0.029179
 >> iter 47000, loss: 0.028146
 >> iter 48000, loss: 0.028597
 >> iter 49000, loss: 0.027616
 >> iter 50000, loss: 0.028051
   Number of active neurons: 8
 >> iter 51000, loss: 0.027248
 >> iter 52000, loss: 0.027471
 >> iter 53000, loss: 0.027039
 >> iter 54000, loss: 0.027056
 >> iter 55000, loss: 0.026916
 >> iter 56000, loss: 0.026998
 >> iter 57000, loss: 0.026755
 >> iter 58000, loss: 0.026803
 >> iter 59000, loss: 0.026407
 >> iter 60000, loss: 0.026367
   Number of active neurons: 8
 >> iter 61000, loss: 0.025823
 >> iter 62000, loss: 0.025804
 >> iter 63000, loss: 0.025328
 >> iter 64000, loss: 0.025455
 >> iter 65000, loss: 0.025043
 >> iter 66000, loss: 0.025251
 >> iter 67000, loss: 0.024872
 >> iter 68000, loss: 0.025092
 >> iter 69000, loss: 0.024725
 >> iter 70000, loss: 0.024977
   Number of active neurons: 8
 >> iter 71000, loss: 0.024646
 >> iter 72000, loss: 0.024910
 >> iter 73000, loss: 0.024609
 >> iter 74000, loss: 0.024875
 >> iter 75000, loss: 0.024586
 >> iter 76000, loss: 0.024857
 >> iter 77000, loss: 0.024580
 >> iter 78000, loss: 0.024846
 >> iter 79000, loss: 0.024578
 >> iter 80000, loss: 0.024801
   Number of active neurons: 8
 >> iter 81000, loss: 0.024502
 >> iter 82000, loss: 0.024750
 >> iter 83000, loss: 0.024446
 >> iter 84000, loss: 0.024725
 >> iter 85000, loss: 0.024419
 >> iter 86000, loss: 0.024713
 >> iter 87000, loss: 0.024402
 >> iter 88000, loss: 0.024733
 >> iter 89000, loss: 0.024401
 >> iter 90000, loss: 0.024745
   Number of active neurons: 8
 >> iter 91000, loss: 0.024404
 >> iter 92000, loss: 0.024783
 >> iter 93000, loss: 0.024417
 >> iter 94000, loss: 0.024847
 >> iter 95000, loss: 0.024438
 >> iter 96000, loss: 0.024910
 >> iter 97000, loss: 0.024468
 >> iter 98000, loss: 0.024858
 >> iter 99000, loss: 0.024494
 >> iter 100000, loss: 0.024795
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.565988
 >> iter 2000, loss: 10.499515
 >> iter 3000, loss: 8.629842
 >> iter 4000, loss: 7.930994
 >> iter 5000, loss: 7.682854
 >> iter 6000, loss: 7.329290
 >> iter 7000, loss: 6.077722
 >> iter 8000, loss: 2.475863
 >> iter 9000, loss: 0.988005
 >> iter 10000, loss: 0.415817
   Number of active neurons: 6
 >> iter 11000, loss: 0.195928
 >> iter 12000, loss: 0.108929
 >> iter 13000, loss: 0.074257
 >> iter 14000, loss: 0.058635
 >> iter 15000, loss: 0.051881
 >> iter 16000, loss: 0.047572
 >> iter 17000, loss: 0.045512
 >> iter 18000, loss: 0.043400
 >> iter 19000, loss: 0.042490
 >> iter 20000, loss: 0.041245
   Number of active neurons: 6
 >> iter 21000, loss: 0.040654
 >> iter 22000, loss: 0.142817
 >> iter 23000, loss: 0.079424
 >> iter 24000, loss: 0.055887
 >> iter 25000, loss: 0.046104
 >> iter 26000, loss: 0.044701
 >> iter 27000, loss: 0.041153
 >> iter 28000, loss: 1.130192
 >> iter 29000, loss: 0.464698
 >> iter 30000, loss: 0.207006
   Number of active neurons: 8
 >> iter 31000, loss: 0.112395
 >> iter 32000, loss: 0.078036
 >> iter 33000, loss: 0.061396
 >> iter 34000, loss: 0.054165
 >> iter 35000, loss: 0.048797
 >> iter 36000, loss: 0.047066
 >> iter 37000, loss: 0.053154
 >> iter 38000, loss: 0.047555
 >> iter 39000, loss: 0.060062
 >> iter 40000, loss: 0.229403
   Number of active neurons: 4
 >> iter 41000, loss: 0.140284
 >> iter 42000, loss: 0.231462
 >> iter 43000, loss: 0.177786
 >> iter 44000, loss: 0.197120
 >> iter 45000, loss: 0.360454
 >> iter 46000, loss: 0.326790
 >> iter 47000, loss: 0.277105
 >> iter 48000, loss: 0.600600
 >> iter 49000, loss: 0.257476
 >> iter 50000, loss: 0.132273
   Number of active neurons: 4
 >> iter 51000, loss: 0.090959
 >> iter 52000, loss: 0.187280
 >> iter 53000, loss: 0.141826
 >> iter 54000, loss: 0.202206
 >> iter 55000, loss: 0.161883
 >> iter 56000, loss: 0.108720
 >> iter 57000, loss: 0.070587
 >> iter 58000, loss: 0.060482
 >> iter 59000, loss: 0.269486
 >> iter 60000, loss: 0.137584
   Number of active neurons: 4
 >> iter 61000, loss: 0.116292
 >> iter 62000, loss: 0.192259
 >> iter 63000, loss: 0.495441
 >> iter 64000, loss: 0.308363
 >> iter 65000, loss: 0.206711
 >> iter 66000, loss: 0.153285
 >> iter 67000, loss: 0.149042
 >> iter 68000, loss: 0.109828
 >> iter 69000, loss: 0.068609
 >> iter 70000, loss: 0.064601
   Number of active neurons: 4
 >> iter 71000, loss: 0.118649
 >> iter 72000, loss: 0.085019
 >> iter 73000, loss: 0.104234
 >> iter 74000, loss: 0.070925
 >> iter 75000, loss: 0.050958
 >> iter 76000, loss: 0.171380
 >> iter 77000, loss: 0.339088
 >> iter 78000, loss: 0.188846
 >> iter 79000, loss: 0.110551
 >> iter 80000, loss: 0.528443
   Number of active neurons: 4
 >> iter 81000, loss: 0.419125
 >> iter 82000, loss: 0.224855
 >> iter 83000, loss: 0.158498
 >> iter 84000, loss: 0.135136
 >> iter 85000, loss: 0.077765
 >> iter 86000, loss: 0.100484
 >> iter 87000, loss: 0.064099
 >> iter 88000, loss: 0.084967
 >> iter 89000, loss: 0.065302
 >> iter 90000, loss: 0.209792
   Number of active neurons: 4
 >> iter 91000, loss: 0.107006
 >> iter 92000, loss: 0.257479
 >> iter 93000, loss: 0.172610
 >> iter 94000, loss: 0.116840
 >> iter 95000, loss: 0.562214
 >> iter 96000, loss: 0.320772
 >> iter 97000, loss: 0.174780
 >> iter 98000, loss: 0.308993
 >> iter 99000, loss: 0.245809
 >> iter 100000, loss: 0.136912
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.234988250587
   - Test - Big: 0.019999800002
   - Test - A: 13.8590760616
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.550619
 >> iter 2000, loss: 10.482093
 >> iter 3000, loss: 8.615327
 >> iter 4000, loss: 7.892985
 >> iter 5000, loss: 7.684305
 >> iter 6000, loss: 7.626336
 >> iter 7000, loss: 7.545185
 >> iter 8000, loss: 7.217410
 >> iter 9000, loss: 4.420462
 >> iter 10000, loss: 1.677165
   Number of active neurons: 7
 >> iter 11000, loss: 0.650234
 >> iter 12000, loss: 0.266654
 >> iter 13000, loss: 0.122864
 >> iter 14000, loss: 0.068238
 >> iter 15000, loss: 0.047260
 >> iter 16000, loss: 0.038750
 >> iter 17000, loss: 0.035285
 >> iter 18000, loss: 0.033449
 >> iter 19000, loss: 0.032539
 >> iter 20000, loss: 0.031716
   Number of active neurons: 6
 >> iter 21000, loss: 0.031237
 >> iter 22000, loss: 0.030674
 >> iter 23000, loss: 0.030274
 >> iter 24000, loss: 0.029790
 >> iter 25000, loss: 0.029510
 >> iter 26000, loss: 0.029169
 >> iter 27000, loss: 0.028956
 >> iter 28000, loss: 0.028625
 >> iter 29000, loss: 0.028396
 >> iter 30000, loss: 0.028077
   Number of active neurons: 6
 >> iter 31000, loss: 0.027810
 >> iter 32000, loss: 0.027518
 >> iter 33000, loss: 0.027338
 >> iter 34000, loss: 0.027134
 >> iter 35000, loss: 0.026996
 >> iter 36000, loss: 0.026825
 >> iter 37000, loss: 0.026688
 >> iter 38000, loss: 0.026535
 >> iter 39000, loss: 0.026404
 >> iter 40000, loss: 0.026283
   Number of active neurons: 5
 >> iter 41000, loss: 0.026178
 >> iter 42000, loss: 0.026081
 >> iter 43000, loss: 0.025994
 >> iter 44000, loss: 0.025916
 >> iter 45000, loss: 0.025842
 >> iter 46000, loss: 0.025778
 >> iter 47000, loss: 0.025709
 >> iter 48000, loss: 0.025645
 >> iter 49000, loss: 0.025577
 >> iter 50000, loss: 0.025486
   Number of active neurons: 5
 >> iter 51000, loss: 0.025390
 >> iter 52000, loss: 0.025306
 >> iter 53000, loss: 0.025207
 >> iter 54000, loss: 0.025123
 >> iter 55000, loss: 0.024969
 >> iter 56000, loss: 0.024880
 >> iter 57000, loss: 0.024731
 >> iter 58000, loss: 0.024663
 >> iter 59000, loss: 0.024513
 >> iter 60000, loss: 0.024451
   Number of active neurons: 5
 >> iter 61000, loss: 0.024285
 >> iter 62000, loss: 0.024222
 >> iter 63000, loss: 0.024068
 >> iter 64000, loss: 0.024023
 >> iter 65000, loss: 0.023851
 >> iter 66000, loss: 0.023750
 >> iter 67000, loss: 0.023543
 >> iter 68000, loss: 0.023475
 >> iter 69000, loss: 0.023324
 >> iter 70000, loss: 0.023311
   Number of active neurons: 5
 >> iter 71000, loss: 0.023199
 >> iter 72000, loss: 0.023223
 >> iter 73000, loss: 0.023130
 >> iter 74000, loss: 0.023172
 >> iter 75000, loss: 0.023086
 >> iter 76000, loss: 0.023141
 >> iter 77000, loss: 0.023056
 >> iter 78000, loss: 0.023120
 >> iter 79000, loss: 0.023038
 >> iter 80000, loss: 0.023102
   Number of active neurons: 5
 >> iter 81000, loss: 0.023006
 >> iter 82000, loss: 0.023068
 >> iter 83000, loss: 0.022951
 >> iter 84000, loss: 0.022991
 >> iter 85000, loss: 0.022833
 >> iter 86000, loss: 0.022881
 >> iter 87000, loss: 0.022731
 >> iter 88000, loss: 0.022794
 >> iter 89000, loss: 0.022652
 >> iter 90000, loss: 0.022725
   Number of active neurons: 5
 >> iter 91000, loss: 0.022580
 >> iter 92000, loss: 0.022661
 >> iter 93000, loss: 0.022511
 >> iter 94000, loss: 0.022592
 >> iter 95000, loss: 0.022451
 >> iter 96000, loss: 0.022530
 >> iter 97000, loss: 0.022383
 >> iter 98000, loss: 0.022465
 >> iter 99000, loss: 0.022314
 >> iter 100000, loss: 0.022396
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.628974
 >> iter 2000, loss: 10.518941
 >> iter 3000, loss: 8.636803
 >> iter 4000, loss: 7.922437
 >> iter 5000, loss: 7.759930
 >> iter 6000, loss: 7.602291
 >> iter 7000, loss: 3.941041
 >> iter 8000, loss: 1.499755
 >> iter 9000, loss: 0.585081
 >> iter 10000, loss: 0.242916
   Number of active neurons: 7
 >> iter 11000, loss: 0.114530
 >> iter 12000, loss: 0.065722
 >> iter 13000, loss: 0.046947
 >> iter 14000, loss: 0.039269
 >> iter 15000, loss: 0.036010
 >> iter 16000, loss: 0.034284
 >> iter 17000, loss: 0.033504
 >> iter 18000, loss: 0.032887
 >> iter 19000, loss: 0.032623
 >> iter 20000, loss: 0.032265
   Number of active neurons: 6
 >> iter 21000, loss: 0.032113
 >> iter 22000, loss: 0.031791
 >> iter 23000, loss: 0.031584
 >> iter 24000, loss: 0.031214
 >> iter 25000, loss: 0.030946
 >> iter 26000, loss: 0.030552
 >> iter 27000, loss: 0.030308
 >> iter 28000, loss: 0.029979
 >> iter 29000, loss: 0.029742
 >> iter 30000, loss: 0.029458
   Number of active neurons: 6
 >> iter 31000, loss: 0.029266
 >> iter 32000, loss: 0.029034
 >> iter 33000, loss: 0.028878
 >> iter 34000, loss: 0.028680
 >> iter 35000, loss: 0.028577
 >> iter 36000, loss: 0.028453
 >> iter 37000, loss: 0.028385
 >> iter 38000, loss: 0.028309
 >> iter 39000, loss: 0.028258
 >> iter 40000, loss: 0.028214
   Number of active neurons: 6
 >> iter 41000, loss: 0.028173
 >> iter 42000, loss: 0.028149
 >> iter 43000, loss: 0.028106
 >> iter 44000, loss: 0.028092
 >> iter 45000, loss: 0.028045
 >> iter 46000, loss: 0.028038
 >> iter 47000, loss: 0.027986
 >> iter 48000, loss: 0.027973
 >> iter 49000, loss: 0.027913
 >> iter 50000, loss: 0.027878
   Number of active neurons: 6
 >> iter 51000, loss: 0.027813
 >> iter 52000, loss: 0.027794
 >> iter 53000, loss: 0.027726
 >> iter 54000, loss: 0.027722
 >> iter 55000, loss: 0.027636
 >> iter 56000, loss: 0.027638
 >> iter 57000, loss: 0.027546
 >> iter 58000, loss: 0.027550
 >> iter 59000, loss: 0.027419
 >> iter 60000, loss: 0.027397
   Number of active neurons: 6
 >> iter 61000, loss: 0.027272
 >> iter 62000, loss: 0.027265
 >> iter 63000, loss: 0.027153
 >> iter 64000, loss: 0.027159
 >> iter 65000, loss: 0.027026
 >> iter 66000, loss: 0.026996
 >> iter 67000, loss: 0.026825
 >> iter 68000, loss: 0.026796
 >> iter 69000, loss: 0.026655
 >> iter 70000, loss: 0.026661
   Number of active neurons: 6
 >> iter 71000, loss: 0.026545
 >> iter 72000, loss: 0.026566
 >> iter 73000, loss: 0.026431
 >> iter 74000, loss: 0.026436
 >> iter 75000, loss: 0.026298
 >> iter 76000, loss: 0.026325
 >> iter 77000, loss: 0.026222
 >> iter 78000, loss: 0.026277
 >> iter 79000, loss: 0.026183
 >> iter 80000, loss: 0.026219
   Number of active neurons: 6
 >> iter 81000, loss: 0.026086
 >> iter 82000, loss: 0.026087
 >> iter 83000, loss: 0.025956
 >> iter 84000, loss: 0.026028
 >> iter 85000, loss: 0.025930
 >> iter 86000, loss: 0.026025
 >> iter 87000, loss: 0.025915
 >> iter 88000, loss: 0.026000
 >> iter 89000, loss: 0.025877
 >> iter 90000, loss: 0.025949
   Number of active neurons: 6
 >> iter 91000, loss: 0.025801
 >> iter 92000, loss: 0.025862
 >> iter 93000, loss: 0.025697
 >> iter 94000, loss: 0.025748
 >> iter 95000, loss: 0.025590
 >> iter 96000, loss: 0.025628
 >> iter 97000, loss: 0.025440
 >> iter 98000, loss: 0.025425
 >> iter 99000, loss: 0.025211
 >> iter 100000, loss: 0.025206
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

