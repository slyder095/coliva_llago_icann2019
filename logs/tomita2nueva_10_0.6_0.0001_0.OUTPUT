 > Problema: tomita2nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.380230
 >> iter 2000, loss: 4.413116
 >> iter 3000, loss: 1.720590
 >> iter 4000, loss: 0.721133
 >> iter 5000, loss: 0.332735
 >> iter 6000, loss: 0.173170
 >> iter 7000, loss: 0.108146
 >> iter 8000, loss: 0.083939
 >> iter 9000, loss: 0.063447
 >> iter 10000, loss: 0.056611
   Number of active neurons: 6
 >> iter 11000, loss: 0.077176
 >> iter 12000, loss: 0.075290
 >> iter 13000, loss: 0.064499
 >> iter 14000, loss: 0.058479
 >> iter 15000, loss: 0.065292
 >> iter 16000, loss: 0.053476
 >> iter 17000, loss: 0.068548
 >> iter 18000, loss: 0.064519
 >> iter 19000, loss: 0.059776
 >> iter 20000, loss: 0.052378
   Number of active neurons: 6
 >> iter 21000, loss: 0.049404
 >> iter 22000, loss: 0.068753
 >> iter 23000, loss: 0.048436
 >> iter 24000, loss: 0.044509
 >> iter 25000, loss: 0.051687
 >> iter 26000, loss: 0.057631
 >> iter 27000, loss: 0.064214
 >> iter 28000, loss: 0.065312
 >> iter 29000, loss: 0.060429
 >> iter 30000, loss: 0.053371
   Number of active neurons: 4
 >> iter 31000, loss: 0.079703
 >> iter 32000, loss: 0.062592
 >> iter 33000, loss: 0.041790
 >> iter 34000, loss: 0.048627
 >> iter 35000, loss: 0.058578
 >> iter 36000, loss: 0.062169
 >> iter 37000, loss: 0.061396
 >> iter 38000, loss: 0.060392
 >> iter 39000, loss: 0.058927
 >> iter 40000, loss: 0.046252
   Number of active neurons: 3
 >> iter 41000, loss: 0.039659
 >> iter 42000, loss: 0.065219
 >> iter 43000, loss: 0.081288
 >> iter 44000, loss: 0.046318
 >> iter 45000, loss: 0.069305
 >> iter 46000, loss: 0.067356
 >> iter 47000, loss: 0.063842
 >> iter 48000, loss: 0.058252
 >> iter 49000, loss: 0.044406
 >> iter 50000, loss: 0.053616
   Number of active neurons: 3
 >> iter 51000, loss: 0.048324
 >> iter 52000, loss: 0.078947
 >> iter 53000, loss: 0.059422
 >> iter 54000, loss: 0.062314
 >> iter 55000, loss: 0.046326
 >> iter 56000, loss: 0.044195
 >> iter 57000, loss: 0.038997
 >> iter 58000, loss: 0.041370
 >> iter 59000, loss: 0.038002
 >> iter 60000, loss: 0.032488
   Number of active neurons: 3
 >> iter 61000, loss: 0.054001
 >> iter 62000, loss: 0.062134
 >> iter 63000, loss: 0.062903
 >> iter 64000, loss: 0.055255
 >> iter 65000, loss: 0.045022
 >> iter 66000, loss: 0.056727
 >> iter 67000, loss: 0.072424
 >> iter 68000, loss: 0.071779
 >> iter 69000, loss: 0.059559
 >> iter 70000, loss: 0.047302
   Number of active neurons: 3
 >> iter 71000, loss: 0.046112
 >> iter 72000, loss: 0.043619
 >> iter 73000, loss: 0.051217
 >> iter 74000, loss: 0.042608
 >> iter 75000, loss: 0.045223
 >> iter 76000, loss: 0.053742
 >> iter 77000, loss: 0.040507
 >> iter 78000, loss: 0.035323
 >> iter 79000, loss: 0.037898
 >> iter 80000, loss: 0.045975
   Number of active neurons: 3
 >> iter 81000, loss: 0.044710
 >> iter 82000, loss: 0.051120
 >> iter 83000, loss: 0.066871
 >> iter 84000, loss: 0.045464
 >> iter 85000, loss: 0.032173
 >> iter 86000, loss: 0.056668
 >> iter 87000, loss: 0.042629
 >> iter 88000, loss: 0.062585
 >> iter 89000, loss: 0.053629
 >> iter 90000, loss: 0.055370
   Number of active neurons: 3
 >> iter 91000, loss: 0.045956
 >> iter 92000, loss: 0.041570
 >> iter 93000, loss: 0.060121
 >> iter 94000, loss: 0.066549
 >> iter 95000, loss: 0.057626
 >> iter 96000, loss: 0.054924
 >> iter 97000, loss: 0.044437
 >> iter 98000, loss: 0.044972
 >> iter 99000, loss: 0.054096
 >> iter 100000, loss: 0.060609
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.399567
 >> iter 2000, loss: 4.440611
 >> iter 3000, loss: 1.734355
 >> iter 4000, loss: 0.730284
 >> iter 5000, loss: 0.327660
 >> iter 6000, loss: 0.175749
 >> iter 7000, loss: 0.097193
 >> iter 8000, loss: 0.089223
 >> iter 9000, loss: 0.084195
 >> iter 10000, loss: 0.067117
   Number of active neurons: 6
 >> iter 11000, loss: 0.074123
 >> iter 12000, loss: 0.064690
 >> iter 13000, loss: 0.056909
 >> iter 14000, loss: 0.050274
 >> iter 15000, loss: 0.062174
 >> iter 16000, loss: 0.049704
 >> iter 17000, loss: 0.045785
 >> iter 18000, loss: 0.073868
 >> iter 19000, loss: 0.069477
 >> iter 20000, loss: 0.051864
   Number of active neurons: 5
 >> iter 21000, loss: 0.048037
 >> iter 22000, loss: 0.043679
 >> iter 23000, loss: 0.051508
 >> iter 24000, loss: 0.057896
 >> iter 25000, loss: 0.070578
 >> iter 26000, loss: 0.076676
 >> iter 27000, loss: 0.059675
 >> iter 28000, loss: 0.049455
 >> iter 29000, loss: 0.062548
 >> iter 30000, loss: 0.060125
   Number of active neurons: 5
 >> iter 31000, loss: 0.049536
 >> iter 32000, loss: 0.049822
 >> iter 33000, loss: 0.039888
 >> iter 34000, loss: 0.037275
 >> iter 35000, loss: 0.042481
 >> iter 36000, loss: 0.042733
 >> iter 37000, loss: 0.062159
 >> iter 38000, loss: 0.054558
 >> iter 39000, loss: 0.052645
 >> iter 40000, loss: 0.043342
   Number of active neurons: 4
 >> iter 41000, loss: 0.050659
 >> iter 42000, loss: 0.059733
 >> iter 43000, loss: 0.046185
 >> iter 44000, loss: 0.047686
 >> iter 45000, loss: 0.052436
 >> iter 46000, loss: 0.053853
 >> iter 47000, loss: 0.060000
 >> iter 48000, loss: 0.045788
 >> iter 49000, loss: 0.072199
 >> iter 50000, loss: 0.049528
   Number of active neurons: 4
 >> iter 51000, loss: 0.038877
 >> iter 52000, loss: 0.040799
 >> iter 53000, loss: 0.053372
 >> iter 54000, loss: 0.061395
 >> iter 55000, loss: 0.046646
 >> iter 56000, loss: 0.049889
 >> iter 57000, loss: 0.050706
 >> iter 58000, loss: 0.055860
 >> iter 59000, loss: 0.062682
 >> iter 60000, loss: 0.063106
   Number of active neurons: 4
 >> iter 61000, loss: 0.061249
 >> iter 62000, loss: 0.047291
 >> iter 63000, loss: 0.046401
 >> iter 64000, loss: 0.047897
 >> iter 65000, loss: 0.059390
 >> iter 66000, loss: 0.046085
 >> iter 67000, loss: 0.054160
 >> iter 68000, loss: 0.040648
 >> iter 69000, loss: 0.037539
 >> iter 70000, loss: 0.039620
   Number of active neurons: 3
 >> iter 71000, loss: 0.032725
 >> iter 72000, loss: 0.042262
 >> iter 73000, loss: 0.064680
 >> iter 74000, loss: 0.051119
 >> iter 75000, loss: 0.057343
 >> iter 76000, loss: 0.044639
 >> iter 77000, loss: 0.043537
 >> iter 78000, loss: 0.045873
 >> iter 79000, loss: 0.058217
 >> iter 80000, loss: 0.041931
   Number of active neurons: 2
 >> iter 81000, loss: 0.053146
 >> iter 82000, loss: 0.042088
 >> iter 83000, loss: 0.033997
 >> iter 84000, loss: 0.034721
 >> iter 85000, loss: 0.037537
 >> iter 86000, loss: 0.033487
 >> iter 87000, loss: 0.043504
 >> iter 88000, loss: 0.032334
 >> iter 89000, loss: 0.046692
 >> iter 90000, loss: 0.055806
   Number of active neurons: 2
 >> iter 91000, loss: 0.045331
 >> iter 92000, loss: 0.037215
 >> iter 93000, loss: 0.032352
 >> iter 94000, loss: 0.038309
 >> iter 95000, loss: 0.043069
 >> iter 96000, loss: 0.049037
 >> iter 97000, loss: 0.045079
 >> iter 98000, loss: 0.040818
 >> iter 99000, loss: 0.049106
 >> iter 100000, loss: 0.052106
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.499930
 >> iter 2000, loss: 4.507826
 >> iter 3000, loss: 1.783639
 >> iter 4000, loss: 0.750868
 >> iter 5000, loss: 0.350180
 >> iter 6000, loss: 0.193799
 >> iter 7000, loss: 0.109203
 >> iter 8000, loss: 0.084954
 >> iter 9000, loss: 0.090574
 >> iter 10000, loss: 0.072998
   Number of active neurons: 7
 >> iter 11000, loss: 0.075459
 >> iter 12000, loss: 0.067664
 >> iter 13000, loss: 0.064319
 >> iter 14000, loss: 0.048606
 >> iter 15000, loss: 0.047404
 >> iter 16000, loss: 0.051888
 >> iter 17000, loss: 0.060904
 >> iter 18000, loss: 0.072116
 >> iter 19000, loss: 0.061825
 >> iter 20000, loss: 0.094362
   Number of active neurons: 6
 >> iter 21000, loss: 0.073566
 >> iter 22000, loss: 0.055663
 >> iter 23000, loss: 0.053107
 >> iter 24000, loss: 0.053815
 >> iter 25000, loss: 0.061674
 >> iter 26000, loss: 0.056017
 >> iter 27000, loss: 0.041778
 >> iter 28000, loss: 0.044305
 >> iter 29000, loss: 0.051147
 >> iter 30000, loss: 0.073979
   Number of active neurons: 5
 >> iter 31000, loss: 0.054848
 >> iter 32000, loss: 0.082417
 >> iter 33000, loss: 0.059804
 >> iter 34000, loss: 0.059808
 >> iter 35000, loss: 0.058123
 >> iter 36000, loss: 0.071177
 >> iter 37000, loss: 0.064495
 >> iter 38000, loss: 0.063662
 >> iter 39000, loss: 0.046605
 >> iter 40000, loss: 0.047725
   Number of active neurons: 5
 >> iter 41000, loss: 0.055849
 >> iter 42000, loss: 0.047090
 >> iter 43000, loss: 0.055050
 >> iter 44000, loss: 0.049286
 >> iter 45000, loss: 0.078167
 >> iter 46000, loss: 0.064173
 >> iter 47000, loss: 0.069211
 >> iter 48000, loss: 0.053428
 >> iter 49000, loss: 0.039073
 >> iter 50000, loss: 0.055486
   Number of active neurons: 4
 >> iter 51000, loss: 0.039922
 >> iter 52000, loss: 0.045998
 >> iter 53000, loss: 0.035256
 >> iter 54000, loss: 0.043483
 >> iter 55000, loss: 0.047172
 >> iter 56000, loss: 0.054793
 >> iter 57000, loss: 0.063025
 >> iter 58000, loss: 0.061375
 >> iter 59000, loss: 0.086177
 >> iter 60000, loss: 0.057989
   Number of active neurons: 4
 >> iter 61000, loss: 0.051482
 >> iter 62000, loss: 0.052715
 >> iter 63000, loss: 0.048881
 >> iter 64000, loss: 0.050416
 >> iter 65000, loss: 0.053010
 >> iter 66000, loss: 0.057909
 >> iter 67000, loss: 0.044318
 >> iter 68000, loss: 0.054826
 >> iter 69000, loss: 0.051065
 >> iter 70000, loss: 0.042092
   Number of active neurons: 4
 >> iter 71000, loss: 0.035273
 >> iter 72000, loss: 0.033547
 >> iter 73000, loss: 0.045186
 >> iter 74000, loss: 0.063906
 >> iter 75000, loss: 0.043506
 >> iter 76000, loss: 0.045553
 >> iter 77000, loss: 0.064774
 >> iter 78000, loss: 0.049338
 >> iter 79000, loss: 0.049568
 >> iter 80000, loss: 0.057349
   Number of active neurons: 4
 >> iter 81000, loss: 0.061870
 >> iter 82000, loss: 0.055943
 >> iter 83000, loss: 0.039674
 >> iter 84000, loss: 0.042116
 >> iter 85000, loss: 0.039497
 >> iter 86000, loss: 0.048307
 >> iter 87000, loss: 0.039409
 >> iter 88000, loss: 0.048964
 >> iter 89000, loss: 0.042800
 >> iter 90000, loss: 0.038477
   Number of active neurons: 4
 >> iter 91000, loss: 0.078923
 >> iter 92000, loss: 0.053933
 >> iter 93000, loss: 0.058519
 >> iter 94000, loss: 0.058295
 >> iter 95000, loss: 0.070771
 >> iter 96000, loss: 0.054664
 >> iter 97000, loss: 0.049325
 >> iter 98000, loss: 0.060463
 >> iter 99000, loss: 0.060406
 >> iter 100000, loss: 0.068606
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.363390
 >> iter 2000, loss: 4.432427
 >> iter 3000, loss: 1.749346
 >> iter 4000, loss: 0.728358
 >> iter 5000, loss: 0.318469
 >> iter 6000, loss: 0.173629
 >> iter 7000, loss: 0.110115
 >> iter 8000, loss: 0.087304
 >> iter 9000, loss: 0.090998
 >> iter 10000, loss: 0.085777
   Number of active neurons: 7
 >> iter 11000, loss: 0.085709
 >> iter 12000, loss: 0.079114
 >> iter 13000, loss: 0.071447
 >> iter 14000, loss: 0.054595
 >> iter 15000, loss: 0.093189
 >> iter 16000, loss: 0.080491
 >> iter 17000, loss: 0.067407
 >> iter 18000, loss: 0.057873
 >> iter 19000, loss: 0.074367
 >> iter 20000, loss: 0.061464
   Number of active neurons: 7
 >> iter 21000, loss: 0.054866
 >> iter 22000, loss: 0.052745
 >> iter 23000, loss: 0.056988
 >> iter 24000, loss: 0.057686
 >> iter 25000, loss: 0.067397
 >> iter 26000, loss: 0.048650
 >> iter 27000, loss: 0.058888
 >> iter 28000, loss: 0.052157
 >> iter 29000, loss: 0.060923
 >> iter 30000, loss: 0.045109
   Number of active neurons: 5
 >> iter 31000, loss: 0.057255
 >> iter 32000, loss: 0.074301
 >> iter 33000, loss: 0.052485
 >> iter 34000, loss: 0.067732
 >> iter 35000, loss: 0.071608
 >> iter 36000, loss: 0.056523
 >> iter 37000, loss: 0.053791
 >> iter 38000, loss: 0.048289
 >> iter 39000, loss: 0.044518
 >> iter 40000, loss: 0.045639
   Number of active neurons: 5
 >> iter 41000, loss: 0.047247
 >> iter 42000, loss: 0.050016
 >> iter 43000, loss: 0.050128
 >> iter 44000, loss: 0.061047
 >> iter 45000, loss: 0.057475
 >> iter 46000, loss: 0.049944
 >> iter 47000, loss: 0.058417
 >> iter 48000, loss: 0.050808
 >> iter 49000, loss: 0.056209
 >> iter 50000, loss: 0.056806
   Number of active neurons: 5
 >> iter 51000, loss: 0.041524
 >> iter 52000, loss: 0.039051
 >> iter 53000, loss: 0.039326
 >> iter 54000, loss: 0.045995
 >> iter 55000, loss: 0.044794
 >> iter 56000, loss: 0.053706
 >> iter 57000, loss: 0.046335
 >> iter 58000, loss: 0.049123
 >> iter 59000, loss: 0.078773
 >> iter 60000, loss: 0.055421
   Number of active neurons: 4
 >> iter 61000, loss: 0.043113
 >> iter 62000, loss: 0.037295
 >> iter 63000, loss: 0.058539
 >> iter 64000, loss: 0.063472
 >> iter 65000, loss: 0.049507
 >> iter 66000, loss: 0.056621
 >> iter 67000, loss: 0.062718
 >> iter 68000, loss: 0.061918
 >> iter 69000, loss: 0.048356
 >> iter 70000, loss: 0.040708
   Number of active neurons: 3
 >> iter 71000, loss: 0.036240
 >> iter 72000, loss: 0.032292
 >> iter 73000, loss: 0.028481
 >> iter 74000, loss: 0.063419
 >> iter 75000, loss: 0.055065
 >> iter 76000, loss: 0.041193
 >> iter 77000, loss: 0.042301
 >> iter 78000, loss: 0.048164
 >> iter 79000, loss: 0.047772
 >> iter 80000, loss: 0.060951
   Number of active neurons: 3
 >> iter 81000, loss: 0.048230
 >> iter 82000, loss: 0.050812
 >> iter 83000, loss: 0.064808
 >> iter 84000, loss: 0.073070
 >> iter 85000, loss: 0.042529
 >> iter 86000, loss: 0.036023
 >> iter 87000, loss: 0.051879
 >> iter 88000, loss: 0.043769
 >> iter 89000, loss: 0.042923
 >> iter 90000, loss: 0.045025
   Number of active neurons: 3
 >> iter 91000, loss: 0.054909
 >> iter 92000, loss: 0.039598
 >> iter 93000, loss: 0.034963
 >> iter 94000, loss: 0.037697
 >> iter 95000, loss: 0.032422
 >> iter 96000, loss: 0.038146
 >> iter 97000, loss: 0.036666
 >> iter 98000, loss: 0.047742
 >> iter 99000, loss: 0.040003
 >> iter 100000, loss: 0.058688
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.335625
 >> iter 2000, loss: 4.344159
 >> iter 3000, loss: 1.690652
 >> iter 4000, loss: 0.675693
 >> iter 5000, loss: 0.315108
 >> iter 6000, loss: 0.171891
 >> iter 7000, loss: 0.113132
 >> iter 8000, loss: 0.091888
 >> iter 9000, loss: 0.074838
 >> iter 10000, loss: 0.057845
   Number of active neurons: 5
 >> iter 11000, loss: 0.056057
 >> iter 12000, loss: 0.056620
 >> iter 13000, loss: 0.049395
 >> iter 14000, loss: 0.078248
 >> iter 15000, loss: 0.092698
 >> iter 16000, loss: 0.083263
 >> iter 17000, loss: 0.069850
 >> iter 18000, loss: 0.053042
 >> iter 19000, loss: 0.043084
 >> iter 20000, loss: 0.068817
   Number of active neurons: 5
 >> iter 21000, loss: 0.092299
 >> iter 22000, loss: 0.061254
 >> iter 23000, loss: 0.052692
 >> iter 24000, loss: 0.062686
 >> iter 25000, loss: 0.056159
 >> iter 26000, loss: 0.049394
 >> iter 27000, loss: 0.071479
 >> iter 28000, loss: 0.051485
 >> iter 29000, loss: 0.052495
 >> iter 30000, loss: 0.051952
   Number of active neurons: 5
 >> iter 31000, loss: 0.040211
 >> iter 32000, loss: 0.049038
 >> iter 33000, loss: 0.048878
 >> iter 34000, loss: 0.044659
 >> iter 35000, loss: 0.037218
 >> iter 36000, loss: 0.047062
 >> iter 37000, loss: 0.058884
 >> iter 38000, loss: 0.043504
 >> iter 39000, loss: 0.039205
 >> iter 40000, loss: 0.037028
   Number of active neurons: 4
 >> iter 41000, loss: 0.028468
 >> iter 42000, loss: 0.036347
 >> iter 43000, loss: 0.059084
 >> iter 44000, loss: 0.049748
 >> iter 45000, loss: 0.051582
 >> iter 46000, loss: 0.047371
 >> iter 47000, loss: 0.060089
 >> iter 48000, loss: 0.051672
 >> iter 49000, loss: 0.053102
 >> iter 50000, loss: 0.062193
   Number of active neurons: 4
 >> iter 51000, loss: 0.046693
 >> iter 52000, loss: 0.056627
 >> iter 53000, loss: 0.063422
 >> iter 54000, loss: 0.047125
 >> iter 55000, loss: 0.043040
 >> iter 56000, loss: 0.057760
 >> iter 57000, loss: 0.050845
 >> iter 58000, loss: 0.040473
 >> iter 59000, loss: 0.052469
 >> iter 60000, loss: 0.046324
   Number of active neurons: 3
 >> iter 61000, loss: 0.034664
 >> iter 62000, loss: 0.037959
 >> iter 63000, loss: 0.050195
 >> iter 64000, loss: 0.041333
 >> iter 65000, loss: 0.049171
 >> iter 66000, loss: 0.046880
 >> iter 67000, loss: 0.064326
 >> iter 68000, loss: 0.047157
 >> iter 69000, loss: 0.053675
 >> iter 70000, loss: 0.065669
   Number of active neurons: 3
 >> iter 71000, loss: 0.051035
 >> iter 72000, loss: 0.049678
 >> iter 73000, loss: 0.052205
 >> iter 74000, loss: 0.050061
 >> iter 75000, loss: 0.052947
 >> iter 76000, loss: 0.050844
 >> iter 77000, loss: 0.051302
 >> iter 78000, loss: 0.054224
 >> iter 79000, loss: 0.050270
 >> iter 80000, loss: 0.046267
   Number of active neurons: 3
 >> iter 81000, loss: 0.046005
 >> iter 82000, loss: 0.057056
 >> iter 83000, loss: 0.070825
 >> iter 84000, loss: 0.059882
 >> iter 85000, loss: 0.048671
 >> iter 86000, loss: 0.044389
 >> iter 87000, loss: 0.040246
 >> iter 88000, loss: 0.041109
 >> iter 89000, loss: 0.050324
 >> iter 90000, loss: 0.048572
   Number of active neurons: 3
 >> iter 91000, loss: 0.059368
 >> iter 92000, loss: 0.054822
 >> iter 93000, loss: 0.059886
 >> iter 94000, loss: 0.041379
 >> iter 95000, loss: 0.033727
 >> iter 96000, loss: 0.047261
 >> iter 97000, loss: 0.040660
 >> iter 98000, loss: 0.056085
 >> iter 99000, loss: 0.052666
 >> iter 100000, loss: 0.062312
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 11.360074
 >> iter 2000, loss: 4.426467
 >> iter 3000, loss: 1.789057
 >> iter 4000, loss: 0.727413
 >> iter 5000, loss: 0.320425
 >> iter 6000, loss: 0.180736
 >> iter 7000, loss: 0.131835
 >> iter 8000, loss: 0.124644
 >> iter 9000, loss: 0.096086
 >> iter 10000, loss: 0.087520
   Number of active neurons: 8
 >> iter 11000, loss: 0.054506
 >> iter 12000, loss: 0.058954
 >> iter 13000, loss: 0.074120
 >> iter 14000, loss: 0.073040
 >> iter 15000, loss: 0.073561
 >> iter 16000, loss: 0.056193
 >> iter 17000, loss: 0.068059
 >> iter 18000, loss: 0.058945
 >> iter 19000, loss: 0.055775
 >> iter 20000, loss: 0.052434
   Number of active neurons: 8
 >> iter 21000, loss: 0.063010
 >> iter 22000, loss: 0.052135
 >> iter 23000, loss: 0.060315
 >> iter 24000, loss: 0.060290
 >> iter 25000, loss: 0.047999
 >> iter 26000, loss: 0.047283
 >> iter 27000, loss: 0.053050
 >> iter 28000, loss: 0.059783
 >> iter 29000, loss: 0.062459
 >> iter 30000, loss: 0.042644
   Number of active neurons: 5
 >> iter 31000, loss: 0.055707
 >> iter 32000, loss: 0.058900
 >> iter 33000, loss: 0.067967
 >> iter 34000, loss: 0.066167
 >> iter 35000, loss: 0.061652
 >> iter 36000, loss: 0.064413
 >> iter 37000, loss: 0.058115
 >> iter 38000, loss: 0.040016
 >> iter 39000, loss: 0.051440
 >> iter 40000, loss: 0.054961
   Number of active neurons: 4
 >> iter 41000, loss: 0.048890
 >> iter 42000, loss: 0.049533
 >> iter 43000, loss: 0.044648
 >> iter 44000, loss: 0.049560
 >> iter 45000, loss: 0.046855
 >> iter 46000, loss: 0.044675
 >> iter 47000, loss: 0.054281
 >> iter 48000, loss: 0.064242
 >> iter 49000, loss: 0.064135
 >> iter 50000, loss: 0.053727
   Number of active neurons: 4
 >> iter 51000, loss: 0.051965
 >> iter 52000, loss: 0.039597
 >> iter 53000, loss: 0.051214
 >> iter 54000, loss: 0.059092
 >> iter 55000, loss: 0.055516
 >> iter 56000, loss: 0.053260
 >> iter 57000, loss: 0.069073
 >> iter 58000, loss: 0.061576
 >> iter 59000, loss: 0.058966
 >> iter 60000, loss: 0.044076
   Number of active neurons: 4
 >> iter 61000, loss: 0.035674
 >> iter 62000, loss: 0.059495
 >> iter 63000, loss: 0.082312
 >> iter 64000, loss: 0.064492
 >> iter 65000, loss: 0.048070
 >> iter 66000, loss: 0.043461
 >> iter 67000, loss: 0.048930
 >> iter 68000, loss: 0.046745
 >> iter 69000, loss: 0.040298
 >> iter 70000, loss: 0.053672
   Number of active neurons: 4
 >> iter 71000, loss: 0.053790
 >> iter 72000, loss: 0.040185
 >> iter 73000, loss: 0.035980
 >> iter 74000, loss: 0.049827
 >> iter 75000, loss: 0.072581
 >> iter 76000, loss: 0.066913
 >> iter 77000, loss: 0.059539
 >> iter 78000, loss: 0.047546
 >> iter 79000, loss: 0.061631
 >> iter 80000, loss: 0.067369
   Number of active neurons: 4
 >> iter 81000, loss: 0.052094
 >> iter 82000, loss: 0.052423
 >> iter 83000, loss: 0.064296
 >> iter 84000, loss: 0.059534
 >> iter 85000, loss: 0.043974
 >> iter 86000, loss: 0.044922
 >> iter 87000, loss: 0.051630
 >> iter 88000, loss: 0.048976
 >> iter 89000, loss: 0.038908
 >> iter 90000, loss: 0.043852
   Number of active neurons: 4
 >> iter 91000, loss: 0.061351
 >> iter 92000, loss: 0.043641
 >> iter 93000, loss: 0.047065
 >> iter 94000, loss: 0.057880
 >> iter 95000, loss: 0.049099
 >> iter 96000, loss: 0.044411
 >> iter 97000, loss: 0.043598
 >> iter 98000, loss: 0.037154
 >> iter 99000, loss: 0.035128
 >> iter 100000, loss: 0.041885
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.343107
 >> iter 2000, loss: 4.413582
 >> iter 3000, loss: 1.699526
 >> iter 4000, loss: 0.691018
 >> iter 5000, loss: 0.312173
 >> iter 6000, loss: 0.194979
 >> iter 7000, loss: 0.120972
 >> iter 8000, loss: 0.078458
 >> iter 9000, loss: 0.070865
 >> iter 10000, loss: 0.079290
   Number of active neurons: 6
 >> iter 11000, loss: 0.068238
 >> iter 12000, loss: 0.066366
 >> iter 13000, loss: 0.046593
 >> iter 14000, loss: 0.050283
 >> iter 15000, loss: 0.058800
 >> iter 16000, loss: 0.052613
 >> iter 17000, loss: 0.083308
 >> iter 18000, loss: 0.067151
 >> iter 19000, loss: 0.066480
 >> iter 20000, loss: 0.091985
   Number of active neurons: 5
 >> iter 21000, loss: 0.064218
 >> iter 22000, loss: 0.066949
 >> iter 23000, loss: 0.070366
 >> iter 24000, loss: 0.044725
 >> iter 25000, loss: 0.047701
 >> iter 26000, loss: 0.048400
 >> iter 27000, loss: 0.044714
 >> iter 28000, loss: 0.044083
 >> iter 29000, loss: 0.059541
 >> iter 30000, loss: 0.059014
   Number of active neurons: 5
 >> iter 31000, loss: 0.042063
 >> iter 32000, loss: 0.045037
 >> iter 33000, loss: 0.040144
 >> iter 34000, loss: 0.049973
 >> iter 35000, loss: 0.057297
 >> iter 36000, loss: 0.067028
 >> iter 37000, loss: 0.060211
 >> iter 38000, loss: 0.049698
 >> iter 39000, loss: 0.035803
 >> iter 40000, loss: 0.054706
   Number of active neurons: 4
 >> iter 41000, loss: 0.043008
 >> iter 42000, loss: 0.071548
 >> iter 43000, loss: 0.056157
 >> iter 44000, loss: 0.061532
 >> iter 45000, loss: 0.047463
 >> iter 46000, loss: 0.053659
 >> iter 47000, loss: 0.048466
 >> iter 48000, loss: 0.049749
 >> iter 49000, loss: 0.038129
 >> iter 50000, loss: 0.051899
   Number of active neurons: 4
 >> iter 51000, loss: 0.045645
 >> iter 52000, loss: 0.043740
 >> iter 53000, loss: 0.045241
 >> iter 54000, loss: 0.051701
 >> iter 55000, loss: 0.042455
 >> iter 56000, loss: 0.033875
 >> iter 57000, loss: 0.057640
 >> iter 58000, loss: 0.056403
 >> iter 59000, loss: 0.055077
 >> iter 60000, loss: 0.040427
   Number of active neurons: 4
 >> iter 61000, loss: 0.038185
 >> iter 62000, loss: 0.033384
 >> iter 63000, loss: 0.037290
 >> iter 64000, loss: 0.050613
 >> iter 65000, loss: 0.043915
 >> iter 66000, loss: 0.041070
 >> iter 67000, loss: 0.042982
 >> iter 68000, loss: 0.049016
 >> iter 69000, loss: 0.038097
 >> iter 70000, loss: 0.040901
   Number of active neurons: 4
 >> iter 71000, loss: 0.039148
 >> iter 72000, loss: 0.037104
 >> iter 73000, loss: 0.040535
 >> iter 74000, loss: 0.035887
 >> iter 75000, loss: 0.063688
 >> iter 76000, loss: 0.071968
 >> iter 77000, loss: 0.072355
 >> iter 78000, loss: 0.066624
 >> iter 79000, loss: 0.052081
 >> iter 80000, loss: 0.041410
   Number of active neurons: 4
 >> iter 81000, loss: 0.066130
 >> iter 82000, loss: 0.055404
 >> iter 83000, loss: 0.052431
 >> iter 84000, loss: 0.057060
 >> iter 85000, loss: 0.045484
 >> iter 86000, loss: 0.035735
 >> iter 87000, loss: 0.037995
 >> iter 88000, loss: 0.047046
 >> iter 89000, loss: 0.049038
 >> iter 90000, loss: 0.036862
   Number of active neurons: 3
 >> iter 91000, loss: 0.032406
 >> iter 92000, loss: 0.034250
 >> iter 93000, loss: 0.046996
 >> iter 94000, loss: 0.041658
 >> iter 95000, loss: 0.040972
 >> iter 96000, loss: 0.046761
 >> iter 97000, loss: 0.038753
 >> iter 98000, loss: 0.048328
 >> iter 99000, loss: 0.046920
 >> iter 100000, loss: 0.038098
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.350472
 >> iter 2000, loss: 4.403068
 >> iter 3000, loss: 1.720245
 >> iter 4000, loss: 0.711960
 >> iter 5000, loss: 0.314813
 >> iter 6000, loss: 0.144244
 >> iter 7000, loss: 0.105285
 >> iter 8000, loss: 0.101024
 >> iter 9000, loss: 0.079754
 >> iter 10000, loss: 0.061651
   Number of active neurons: 7
 >> iter 11000, loss: 0.069721
 >> iter 12000, loss: 0.074504
 >> iter 13000, loss: 0.055281
 >> iter 14000, loss: 0.050837
 >> iter 15000, loss: 0.053056
 >> iter 16000, loss: 0.062286
 >> iter 17000, loss: 0.062903
 >> iter 18000, loss: 0.083160
 >> iter 19000, loss: 0.088878
 >> iter 20000, loss: 0.064866
   Number of active neurons: 5
 >> iter 21000, loss: 0.051868
 >> iter 22000, loss: 0.063544
 >> iter 23000, loss: 0.062587
 >> iter 24000, loss: 0.078533
 >> iter 25000, loss: 0.059069
 >> iter 26000, loss: 0.048482
 >> iter 27000, loss: 0.060683
 >> iter 28000, loss: 0.061592
 >> iter 29000, loss: 0.065441
 >> iter 30000, loss: 0.050662
   Number of active neurons: 4
 >> iter 31000, loss: 0.051721
 >> iter 32000, loss: 0.038682
 >> iter 33000, loss: 0.055400
 >> iter 34000, loss: 0.069919
 >> iter 35000, loss: 0.072952
 >> iter 36000, loss: 0.054770
 >> iter 37000, loss: 0.056710
 >> iter 38000, loss: 0.055611
 >> iter 39000, loss: 0.072393
 >> iter 40000, loss: 0.046127
   Number of active neurons: 4
 >> iter 41000, loss: 0.060217
 >> iter 42000, loss: 0.059536
 >> iter 43000, loss: 0.047603
 >> iter 44000, loss: 0.041793
 >> iter 45000, loss: 0.046265
 >> iter 46000, loss: 0.056313
 >> iter 47000, loss: 0.051854
 >> iter 48000, loss: 0.057460
 >> iter 49000, loss: 0.047943
 >> iter 50000, loss: 0.044585
   Number of active neurons: 4
 >> iter 51000, loss: 0.044108
 >> iter 52000, loss: 0.059256
 >> iter 53000, loss: 0.046710
 >> iter 54000, loss: 0.044497
 >> iter 55000, loss: 0.065104
 >> iter 56000, loss: 0.052814
 >> iter 57000, loss: 0.049351
 >> iter 58000, loss: 0.053925
 >> iter 59000, loss: 0.048173
 >> iter 60000, loss: 0.053651
   Number of active neurons: 3
 >> iter 61000, loss: 0.045857
 >> iter 62000, loss: 0.048693
 >> iter 63000, loss: 0.036499
 >> iter 64000, loss: 0.043398
 >> iter 65000, loss: 0.061833
 >> iter 66000, loss: 0.059995
 >> iter 67000, loss: 0.064928
 >> iter 68000, loss: 0.059072
 >> iter 69000, loss: 0.069042
 >> iter 70000, loss: 0.044306
   Number of active neurons: 2
 >> iter 71000, loss: 0.047377
 >> iter 72000, loss: 0.039836
 >> iter 73000, loss: 0.036303
 >> iter 74000, loss: 0.058734
 >> iter 75000, loss: 0.043348
 >> iter 76000, loss: 0.055277
 >> iter 77000, loss: 0.048916
 >> iter 78000, loss: 0.040654
 >> iter 79000, loss: 0.047200
 >> iter 80000, loss: 0.043828
   Number of active neurons: 2
 >> iter 81000, loss: 0.040153
 >> iter 82000, loss: 0.049311
 >> iter 83000, loss: 0.057322
 >> iter 84000, loss: 0.035624
 >> iter 85000, loss: 0.040474
 >> iter 86000, loss: 0.030680
 >> iter 87000, loss: 0.050599
 >> iter 88000, loss: 0.060904
 >> iter 89000, loss: 0.054471
 >> iter 90000, loss: 0.045263
   Number of active neurons: 2
 >> iter 91000, loss: 0.041378
 >> iter 92000, loss: 0.033911
 >> iter 93000, loss: 0.049225
 >> iter 94000, loss: 0.044074
 >> iter 95000, loss: 0.045001
 >> iter 96000, loss: 0.046444
 >> iter 97000, loss: 0.035833
 >> iter 98000, loss: 0.031633
 >> iter 99000, loss: 0.054809
 >> iter 100000, loss: 0.071362
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.318107
 >> iter 2000, loss: 4.389625
 >> iter 3000, loss: 1.734680
 >> iter 4000, loss: 0.713117
 >> iter 5000, loss: 0.314529
 >> iter 6000, loss: 0.180518
 >> iter 7000, loss: 0.119703
 >> iter 8000, loss: 0.106774
 >> iter 9000, loss: 0.090971
 >> iter 10000, loss: 0.079957
   Number of active neurons: 7
 >> iter 11000, loss: 0.066620
 >> iter 12000, loss: 0.078540
 >> iter 13000, loss: 0.069476
 >> iter 14000, loss: 0.063292
 >> iter 15000, loss: 0.059085
 >> iter 16000, loss: 0.042989
 >> iter 17000, loss: 0.071061
 >> iter 18000, loss: 0.062275
 >> iter 19000, loss: 0.070797
 >> iter 20000, loss: 0.077981
   Number of active neurons: 7
 >> iter 21000, loss: 0.049897
 >> iter 22000, loss: 0.039033
 >> iter 23000, loss: 0.066543
 >> iter 24000, loss: 0.067473
 >> iter 25000, loss: 0.063015
 >> iter 26000, loss: 0.065984
 >> iter 27000, loss: 0.059096
 >> iter 28000, loss: 0.065638
 >> iter 29000, loss: 0.053986
 >> iter 30000, loss: 0.052442
   Number of active neurons: 7
 >> iter 31000, loss: 0.061184
 >> iter 32000, loss: 0.060097
 >> iter 33000, loss: 0.063622
 >> iter 34000, loss: 0.068156
 >> iter 35000, loss: 0.059400
 >> iter 36000, loss: 0.061566
 >> iter 37000, loss: 0.053866
 >> iter 38000, loss: 0.048397
 >> iter 39000, loss: 0.047371
 >> iter 40000, loss: 0.036338
   Number of active neurons: 7
 >> iter 41000, loss: 0.050785
 >> iter 42000, loss: 0.048585
 >> iter 43000, loss: 0.058164
 >> iter 44000, loss: 0.042603
 >> iter 45000, loss: 0.045788
 >> iter 46000, loss: 0.039770
 >> iter 47000, loss: 0.063474
 >> iter 48000, loss: 0.066566
 >> iter 49000, loss: 0.054716
 >> iter 50000, loss: 0.047108
   Number of active neurons: 7
 >> iter 51000, loss: 0.068283
 >> iter 52000, loss: 0.064593
 >> iter 53000, loss: 0.057668
 >> iter 54000, loss: 0.052545
 >> iter 55000, loss: 0.047889
 >> iter 56000, loss: 0.048270
 >> iter 57000, loss: 0.039836
 >> iter 58000, loss: 0.041852
 >> iter 59000, loss: 0.038955
 >> iter 60000, loss: 0.042036
   Number of active neurons: 5
 >> iter 61000, loss: 0.051627
 >> iter 62000, loss: 0.052064
 >> iter 63000, loss: 0.048564
 >> iter 64000, loss: 0.043688
 >> iter 65000, loss: 0.041124
 >> iter 66000, loss: 0.039686
 >> iter 67000, loss: 0.044276
 >> iter 68000, loss: 0.064591
 >> iter 69000, loss: 0.051865
 >> iter 70000, loss: 0.068039
   Number of active neurons: 4
 >> iter 71000, loss: 0.054689
 >> iter 72000, loss: 0.042141
 >> iter 73000, loss: 0.040331
 >> iter 74000, loss: 0.037752
 >> iter 75000, loss: 0.047559
 >> iter 76000, loss: 0.057307
 >> iter 77000, loss: 0.058252
 >> iter 78000, loss: 0.068388
 >> iter 79000, loss: 0.055675
 >> iter 80000, loss: 0.050608
   Number of active neurons: 4
 >> iter 81000, loss: 0.065834
 >> iter 82000, loss: 0.065318
 >> iter 83000, loss: 0.053978
 >> iter 84000, loss: 0.046131
 >> iter 85000, loss: 0.053037
 >> iter 86000, loss: 0.051443
 >> iter 87000, loss: 0.044628
 >> iter 88000, loss: 0.049770
 >> iter 89000, loss: 0.062089
 >> iter 90000, loss: 0.039582
   Number of active neurons: 4
 >> iter 91000, loss: 0.041244
 >> iter 92000, loss: 0.050013
 >> iter 93000, loss: 0.056220
 >> iter 94000, loss: 0.044210
 >> iter 95000, loss: 0.041951
 >> iter 96000, loss: 0.046444
 >> iter 97000, loss: 0.053407
 >> iter 98000, loss: 0.066401
 >> iter 99000, loss: 0.065263
 >> iter 100000, loss: 0.057560
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.318294
 >> iter 2000, loss: 4.400198
 >> iter 3000, loss: 1.755154
 >> iter 4000, loss: 0.729363
 >> iter 5000, loss: 0.345650
 >> iter 6000, loss: 0.181818
 >> iter 7000, loss: 0.135978
 >> iter 8000, loss: 0.086553
 >> iter 9000, loss: 0.090378
 >> iter 10000, loss: 0.085456
   Number of active neurons: 8
 >> iter 11000, loss: 0.109504
 >> iter 12000, loss: 0.093804
 >> iter 13000, loss: 0.105330
 >> iter 14000, loss: 0.087481
 >> iter 15000, loss: 0.069185
 >> iter 16000, loss: 0.056603
 >> iter 17000, loss: 0.065219
 >> iter 18000, loss: 0.069552
 >> iter 19000, loss: 0.057943
 >> iter 20000, loss: 0.059430
   Number of active neurons: 7
 >> iter 21000, loss: 0.054706
 >> iter 22000, loss: 0.058387
 >> iter 23000, loss: 0.051696
 >> iter 24000, loss: 0.049905
 >> iter 25000, loss: 0.064350
 >> iter 26000, loss: 0.065333
 >> iter 27000, loss: 0.051297
 >> iter 28000, loss: 0.075996
 >> iter 29000, loss: 0.076424
 >> iter 30000, loss: 0.053681
   Number of active neurons: 7
 >> iter 31000, loss: 0.049705
 >> iter 32000, loss: 0.055403
 >> iter 33000, loss: 0.062614
 >> iter 34000, loss: 0.056229
 >> iter 35000, loss: 0.066649
 >> iter 36000, loss: 0.057797
 >> iter 37000, loss: 0.063768
 >> iter 38000, loss: 0.053764
 >> iter 39000, loss: 0.049806
 >> iter 40000, loss: 0.044286
   Number of active neurons: 5
 >> iter 41000, loss: 0.048773
 >> iter 42000, loss: 0.043816
 >> iter 43000, loss: 0.049425
 >> iter 44000, loss: 0.042914
 >> iter 45000, loss: 0.040369
 >> iter 46000, loss: 0.037167
 >> iter 47000, loss: 0.049176
 >> iter 48000, loss: 0.035561
 >> iter 49000, loss: 0.053683
 >> iter 50000, loss: 0.056993
   Number of active neurons: 4
 >> iter 51000, loss: 0.052623
 >> iter 52000, loss: 0.049802
 >> iter 53000, loss: 0.046256
 >> iter 54000, loss: 0.031945
 >> iter 55000, loss: 0.059159
 >> iter 56000, loss: 0.045224
 >> iter 57000, loss: 0.061983
 >> iter 58000, loss: 0.049892
 >> iter 59000, loss: 0.045517
 >> iter 60000, loss: 0.041334
   Number of active neurons: 4
 >> iter 61000, loss: 0.059481
 >> iter 62000, loss: 0.048909
 >> iter 63000, loss: 0.046948
 >> iter 64000, loss: 0.039268
 >> iter 65000, loss: 0.059794
 >> iter 66000, loss: 0.054032
 >> iter 67000, loss: 0.054431
 >> iter 68000, loss: 0.047031
 >> iter 69000, loss: 0.048879
 >> iter 70000, loss: 0.058038
   Number of active neurons: 4
 >> iter 71000, loss: 0.062182
 >> iter 72000, loss: 0.071635
 >> iter 73000, loss: 0.060431
 >> iter 74000, loss: 0.045434
 >> iter 75000, loss: 0.036197
 >> iter 76000, loss: 0.033446
 >> iter 77000, loss: 0.043848
 >> iter 78000, loss: 0.050310
 >> iter 79000, loss: 0.049686
 >> iter 80000, loss: 0.052061
   Number of active neurons: 4
 >> iter 81000, loss: 0.055361
 >> iter 82000, loss: 0.048547
 >> iter 83000, loss: 0.065836
 >> iter 84000, loss: 0.069094
 >> iter 85000, loss: 0.053366
 >> iter 86000, loss: 0.050951
 >> iter 87000, loss: 0.048626
 >> iter 88000, loss: 0.048244
 >> iter 89000, loss: 0.045102
 >> iter 90000, loss: 0.068927
   Number of active neurons: 3
 >> iter 91000, loss: 0.051883
 >> iter 92000, loss: 0.044343
 >> iter 93000, loss: 0.038520
 >> iter 94000, loss: 0.036359
 >> iter 95000, loss: 0.058735
 >> iter 96000, loss: 0.048418
 >> iter 97000, loss: 0.050909
 >> iter 98000, loss: 0.055632
 >> iter 99000, loss: 0.041065
 >> iter 100000, loss: 0.033533
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.406047
 >> iter 2000, loss: 4.407525
 >> iter 3000, loss: 1.743638
 >> iter 4000, loss: 0.698627
 >> iter 5000, loss: 0.336871
 >> iter 6000, loss: 0.165709
 >> iter 7000, loss: 0.111903
 >> iter 8000, loss: 0.097374
 >> iter 9000, loss: 0.076934
 >> iter 10000, loss: 0.060680
   Number of active neurons: 6
 >> iter 11000, loss: 0.060793
 >> iter 12000, loss: 0.050224
 >> iter 13000, loss: 0.046688
 >> iter 14000, loss: 0.065505
 >> iter 15000, loss: 0.056995
 >> iter 16000, loss: 0.051911
 >> iter 17000, loss: 0.060022
 >> iter 18000, loss: 0.055671
 >> iter 19000, loss: 0.059117
 >> iter 20000, loss: 0.058733
   Number of active neurons: 6
 >> iter 21000, loss: 0.097880
 >> iter 22000, loss: 0.063264
 >> iter 23000, loss: 0.065619
 >> iter 24000, loss: 0.048281
 >> iter 25000, loss: 0.048996
 >> iter 26000, loss: 0.066755
 >> iter 27000, loss: 0.057495
 >> iter 28000, loss: 0.056538
 >> iter 29000, loss: 0.053730
 >> iter 30000, loss: 0.046042
   Number of active neurons: 6
 >> iter 31000, loss: 0.040526
 >> iter 32000, loss: 0.038895
 >> iter 33000, loss: 0.035771
 >> iter 34000, loss: 0.037744
 >> iter 35000, loss: 0.043511
 >> iter 36000, loss: 0.049022
 >> iter 37000, loss: 0.038717
 >> iter 38000, loss: 0.072489
 >> iter 39000, loss: 0.057582
 >> iter 40000, loss: 0.061821
   Number of active neurons: 6
 >> iter 41000, loss: 0.053977
 >> iter 42000, loss: 0.049772
 >> iter 43000, loss: 0.068724
 >> iter 44000, loss: 0.061295
 >> iter 45000, loss: 0.043259
 >> iter 46000, loss: 0.054329
 >> iter 47000, loss: 0.059017
 >> iter 48000, loss: 0.049915
 >> iter 49000, loss: 0.043377
 >> iter 50000, loss: 0.046221
   Number of active neurons: 4
 >> iter 51000, loss: 0.038164
 >> iter 52000, loss: 0.035993
 >> iter 53000, loss: 0.047186
 >> iter 54000, loss: 0.041885
 >> iter 55000, loss: 0.041525
 >> iter 56000, loss: 0.047325
 >> iter 57000, loss: 0.052255
 >> iter 58000, loss: 0.056631
 >> iter 59000, loss: 0.059528
 >> iter 60000, loss: 0.043865
   Number of active neurons: 4
 >> iter 61000, loss: 0.054019
 >> iter 62000, loss: 0.044281
 >> iter 63000, loss: 0.058179
 >> iter 64000, loss: 0.045723
 >> iter 65000, loss: 0.041369
 >> iter 66000, loss: 0.045254
 >> iter 67000, loss: 0.058371
 >> iter 68000, loss: 0.057843
 >> iter 69000, loss: 0.043309
 >> iter 70000, loss: 0.051581
   Number of active neurons: 3
 >> iter 71000, loss: 0.064158
 >> iter 72000, loss: 0.047984
 >> iter 73000, loss: 0.044667
 >> iter 74000, loss: 0.055384
 >> iter 75000, loss: 0.050548
 >> iter 76000, loss: 0.065252
 >> iter 77000, loss: 0.044680
 >> iter 78000, loss: 0.046440
 >> iter 79000, loss: 0.059361
 >> iter 80000, loss: 0.043816
   Number of active neurons: 3
 >> iter 81000, loss: 0.043482
 >> iter 82000, loss: 0.064393
 >> iter 83000, loss: 0.045289
 >> iter 84000, loss: 0.061468
 >> iter 85000, loss: 0.046276
 >> iter 86000, loss: 0.046623
 >> iter 87000, loss: 0.054540
 >> iter 88000, loss: 0.046062
 >> iter 89000, loss: 0.049063
 >> iter 90000, loss: 0.074989
   Number of active neurons: 3
 >> iter 91000, loss: 0.062827
 >> iter 92000, loss: 0.052878
 >> iter 93000, loss: 0.062889
 >> iter 94000, loss: 0.047555
 >> iter 95000, loss: 0.043282
 >> iter 96000, loss: 0.059693
 >> iter 97000, loss: 0.051044
 >> iter 98000, loss: 0.044273
 >> iter 99000, loss: 0.052929
 >> iter 100000, loss: 0.043335
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.314078
 >> iter 2000, loss: 4.360780
 >> iter 3000, loss: 1.713295
 >> iter 4000, loss: 0.695906
 >> iter 5000, loss: 0.326460
 >> iter 6000, loss: 0.207790
 >> iter 7000, loss: 0.150589
 >> iter 8000, loss: 0.090779
 >> iter 9000, loss: 0.069211
 >> iter 10000, loss: 0.051712
   Number of active neurons: 7
 >> iter 11000, loss: 0.077969
 >> iter 12000, loss: 0.061576
 >> iter 13000, loss: 0.067962
 >> iter 14000, loss: 0.065179
 >> iter 15000, loss: 0.052001
 >> iter 16000, loss: 0.050769
 >> iter 17000, loss: 0.077586
 >> iter 18000, loss: 0.065308
 >> iter 19000, loss: 0.059124
 >> iter 20000, loss: 0.074991
   Number of active neurons: 7
 >> iter 21000, loss: 0.070563
 >> iter 22000, loss: 0.096850
 >> iter 23000, loss: 0.084847
 >> iter 24000, loss: 0.085639
 >> iter 25000, loss: 0.055656
 >> iter 26000, loss: 0.053354
 >> iter 27000, loss: 0.060138
 >> iter 28000, loss: 0.063037
 >> iter 29000, loss: 0.049985
 >> iter 30000, loss: 0.043319
   Number of active neurons: 7
 >> iter 31000, loss: 0.072627
 >> iter 32000, loss: 0.065627
 >> iter 33000, loss: 0.056553
 >> iter 34000, loss: 0.082564
 >> iter 35000, loss: 0.102406
 >> iter 36000, loss: 0.061108
 >> iter 37000, loss: 0.061125
 >> iter 38000, loss: 0.050024
 >> iter 39000, loss: 0.056524
 >> iter 40000, loss: 0.058656
   Number of active neurons: 6
 >> iter 41000, loss: 0.079260
 >> iter 42000, loss: 0.053016
 >> iter 43000, loss: 0.044592
 >> iter 44000, loss: 0.048755
 >> iter 45000, loss: 0.050684
 >> iter 46000, loss: 0.051828
 >> iter 47000, loss: 0.063237
 >> iter 48000, loss: 0.061873
 >> iter 49000, loss: 0.052294
 >> iter 50000, loss: 0.051192
   Number of active neurons: 5
 >> iter 51000, loss: 0.058493
 >> iter 52000, loss: 0.054124
 >> iter 53000, loss: 0.041718
 >> iter 54000, loss: 0.050905
 >> iter 55000, loss: 0.041006
 >> iter 56000, loss: 0.055654
 >> iter 57000, loss: 0.061154
 >> iter 58000, loss: 0.047113
 >> iter 59000, loss: 0.041296
 >> iter 60000, loss: 0.040529
   Number of active neurons: 4
 >> iter 61000, loss: 0.070918
 >> iter 62000, loss: 0.058026
 >> iter 63000, loss: 0.076339
 >> iter 64000, loss: 0.056201
 >> iter 65000, loss: 0.045006
 >> iter 66000, loss: 0.048731
 >> iter 67000, loss: 0.054615
 >> iter 68000, loss: 0.053319
 >> iter 69000, loss: 0.048994
 >> iter 70000, loss: 0.047348
   Number of active neurons: 3
 >> iter 71000, loss: 0.048712
 >> iter 72000, loss: 0.050819
 >> iter 73000, loss: 0.061938
 >> iter 74000, loss: 0.067946
 >> iter 75000, loss: 0.057938
 >> iter 76000, loss: 0.048529
 >> iter 77000, loss: 0.044402
 >> iter 78000, loss: 0.038959
 >> iter 79000, loss: 0.047884
 >> iter 80000, loss: 0.047483
   Number of active neurons: 3
 >> iter 81000, loss: 0.048973
 >> iter 82000, loss: 0.057655
 >> iter 83000, loss: 0.076389
 >> iter 84000, loss: 0.063571
 >> iter 85000, loss: 0.061149
 >> iter 86000, loss: 0.058814
 >> iter 87000, loss: 0.049024
 >> iter 88000, loss: 0.041115
 >> iter 89000, loss: 0.044891
 >> iter 90000, loss: 0.056951
   Number of active neurons: 3
 >> iter 91000, loss: 0.047436
 >> iter 92000, loss: 0.049498
 >> iter 93000, loss: 0.041506
 >> iter 94000, loss: 0.059916
 >> iter 95000, loss: 0.053476
 >> iter 96000, loss: 0.058366
 >> iter 97000, loss: 0.062215
 >> iter 98000, loss: 0.070153
 >> iter 99000, loss: 0.059044
 >> iter 100000, loss: 0.045655
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.335739
 >> iter 2000, loss: 4.372804
 >> iter 3000, loss: 1.717716
 >> iter 4000, loss: 0.730299
 >> iter 5000, loss: 0.317030
 >> iter 6000, loss: 0.174114
 >> iter 7000, loss: 0.103958
 >> iter 8000, loss: 0.091336
 >> iter 9000, loss: 0.071095
 >> iter 10000, loss: 0.072439
   Number of active neurons: 6
 >> iter 11000, loss: 0.071234
 >> iter 12000, loss: 0.065576
 >> iter 13000, loss: 0.066183
 >> iter 14000, loss: 0.064319
 >> iter 15000, loss: 0.046347
 >> iter 16000, loss: 0.060091
 >> iter 17000, loss: 0.051828
 >> iter 18000, loss: 0.050902
 >> iter 19000, loss: 0.039067
 >> iter 20000, loss: 0.041358
   Number of active neurons: 6
 >> iter 21000, loss: 0.054096
 >> iter 22000, loss: 0.077396
 >> iter 23000, loss: 0.060912
 >> iter 24000, loss: 0.055120
 >> iter 25000, loss: 0.067293
 >> iter 26000, loss: 0.050311
 >> iter 27000, loss: 0.054997
 >> iter 28000, loss: 0.055058
 >> iter 29000, loss: 0.048576
 >> iter 30000, loss: 0.040918
   Number of active neurons: 6
 >> iter 31000, loss: 0.059718
 >> iter 32000, loss: 0.045560
 >> iter 33000, loss: 0.037454
 >> iter 34000, loss: 0.041957
 >> iter 35000, loss: 0.054112
 >> iter 36000, loss: 0.043270
 >> iter 37000, loss: 0.048958
 >> iter 38000, loss: 0.047036
 >> iter 39000, loss: 0.053568
 >> iter 40000, loss: 0.044070
   Number of active neurons: 6
 >> iter 41000, loss: 0.058044
 >> iter 42000, loss: 0.047681
 >> iter 43000, loss: 0.075074
 >> iter 44000, loss: 0.068641
 >> iter 45000, loss: 0.057927
 >> iter 46000, loss: 0.060970
 >> iter 47000, loss: 0.045652
 >> iter 48000, loss: 0.047924
 >> iter 49000, loss: 0.061807
 >> iter 50000, loss: 0.051458
   Number of active neurons: 5
 >> iter 51000, loss: 0.054105
 >> iter 52000, loss: 0.050980
 >> iter 53000, loss: 0.066483
 >> iter 54000, loss: 0.055135
 >> iter 55000, loss: 0.057035
 >> iter 56000, loss: 0.051823
 >> iter 57000, loss: 0.046872
 >> iter 58000, loss: 0.040967
 >> iter 59000, loss: 0.038239
 >> iter 60000, loss: 0.049165
   Number of active neurons: 5
 >> iter 61000, loss: 0.049556
 >> iter 62000, loss: 0.050078
 >> iter 63000, loss: 0.058188
 >> iter 64000, loss: 0.051265
 >> iter 65000, loss: 0.071877
 >> iter 66000, loss: 0.057818
 >> iter 67000, loss: 0.063105
 >> iter 68000, loss: 0.060179
 >> iter 69000, loss: 0.062065
 >> iter 70000, loss: 0.074780
   Number of active neurons: 3
 >> iter 71000, loss: 0.054375
 >> iter 72000, loss: 0.044816
 >> iter 73000, loss: 0.039610
 >> iter 74000, loss: 0.052025
 >> iter 75000, loss: 0.064153
 >> iter 76000, loss: 0.045995
 >> iter 77000, loss: 0.055865
 >> iter 78000, loss: 0.040962
 >> iter 79000, loss: 0.041531
 >> iter 80000, loss: 0.035729
   Number of active neurons: 3
 >> iter 81000, loss: 0.072414
 >> iter 82000, loss: 0.055544
 >> iter 83000, loss: 0.041258
 >> iter 84000, loss: 0.038671
 >> iter 85000, loss: 0.050240
 >> iter 86000, loss: 0.067013
 >> iter 87000, loss: 0.052824
 >> iter 88000, loss: 0.045331
 >> iter 89000, loss: 0.042193
 >> iter 90000, loss: 0.055436
   Number of active neurons: 3
 >> iter 91000, loss: 0.038762
 >> iter 92000, loss: 0.045047
 >> iter 93000, loss: 0.036376
 >> iter 94000, loss: 0.042732
 >> iter 95000, loss: 0.076051
 >> iter 96000, loss: 0.050690
 >> iter 97000, loss: 0.059165
 >> iter 98000, loss: 0.050543
 >> iter 99000, loss: 0.061666
 >> iter 100000, loss: 0.048653
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 11.344975
 >> iter 2000, loss: 4.441007
 >> iter 3000, loss: 1.754961
 >> iter 4000, loss: 0.722964
 >> iter 5000, loss: 0.322321
 >> iter 6000, loss: 0.164521
 >> iter 7000, loss: 0.122937
 >> iter 8000, loss: 0.102052
 >> iter 9000, loss: 0.082027
 >> iter 10000, loss: 0.066620
   Number of active neurons: 7
 >> iter 11000, loss: 0.076662
 >> iter 12000, loss: 0.072306
 >> iter 13000, loss: 0.070159
 >> iter 14000, loss: 0.049649
 >> iter 15000, loss: 0.062221
 >> iter 16000, loss: 0.055342
 >> iter 17000, loss: 0.061740
 >> iter 18000, loss: 0.074077
 >> iter 19000, loss: 0.048974
 >> iter 20000, loss: 0.054769
   Number of active neurons: 7
 >> iter 21000, loss: 0.051385
 >> iter 22000, loss: 0.050289
 >> iter 23000, loss: 0.054280
 >> iter 24000, loss: 0.075006
 >> iter 25000, loss: 0.077254
 >> iter 26000, loss: 0.055472
 >> iter 27000, loss: 0.075334
 >> iter 28000, loss: 0.046380
 >> iter 29000, loss: 0.046257
 >> iter 30000, loss: 0.078636
   Number of active neurons: 7
 >> iter 31000, loss: 0.065989
 >> iter 32000, loss: 0.076273
 >> iter 33000, loss: 0.062637
 >> iter 34000, loss: 0.054991
 >> iter 35000, loss: 0.068135
 >> iter 36000, loss: 0.054968
 >> iter 37000, loss: 0.048480
 >> iter 38000, loss: 0.051619
 >> iter 39000, loss: 0.043836
 >> iter 40000, loss: 0.040466
   Number of active neurons: 5
 >> iter 41000, loss: 0.074900
 >> iter 42000, loss: 0.071559
 >> iter 43000, loss: 0.051397
 >> iter 44000, loss: 0.043906
 >> iter 45000, loss: 0.041806
 >> iter 46000, loss: 0.043655
 >> iter 47000, loss: 0.042258
 >> iter 48000, loss: 0.052177
 >> iter 49000, loss: 0.052540
 >> iter 50000, loss: 0.050923
   Number of active neurons: 4
 >> iter 51000, loss: 0.050425
 >> iter 52000, loss: 0.069021
 >> iter 53000, loss: 0.063561
 >> iter 54000, loss: 0.050234
 >> iter 55000, loss: 0.067083
 >> iter 56000, loss: 0.058622
 >> iter 57000, loss: 0.064829
 >> iter 58000, loss: 0.067867
 >> iter 59000, loss: 0.044894
 >> iter 60000, loss: 0.036317
   Number of active neurons: 3
 >> iter 61000, loss: 0.054044
 >> iter 62000, loss: 0.046612
 >> iter 63000, loss: 0.044948
 >> iter 64000, loss: 0.035904
 >> iter 65000, loss: 0.043018
 >> iter 66000, loss: 0.040803
 >> iter 67000, loss: 0.042201
 >> iter 68000, loss: 0.047217
 >> iter 69000, loss: 0.061226
 >> iter 70000, loss: 0.041837
   Number of active neurons: 3
 >> iter 71000, loss: 0.037696
 >> iter 72000, loss: 0.042828
 >> iter 73000, loss: 0.048757
 >> iter 74000, loss: 0.039645
 >> iter 75000, loss: 0.044970
 >> iter 76000, loss: 0.055842
 >> iter 77000, loss: 0.041804
 >> iter 78000, loss: 0.045624
 >> iter 79000, loss: 0.052772
 >> iter 80000, loss: 0.049943
   Number of active neurons: 3
 >> iter 81000, loss: 0.053705
 >> iter 82000, loss: 0.049679
 >> iter 83000, loss: 0.073208
 >> iter 84000, loss: 0.058078
 >> iter 85000, loss: 0.074480
 >> iter 86000, loss: 0.044585
 >> iter 87000, loss: 0.040800
 >> iter 88000, loss: 0.040404
 >> iter 89000, loss: 0.035333
 >> iter 90000, loss: 0.045878
   Number of active neurons: 3
 >> iter 91000, loss: 0.050325
 >> iter 92000, loss: 0.058969
 >> iter 93000, loss: 0.048863
 >> iter 94000, loss: 0.044992
 >> iter 95000, loss: 0.043284
 >> iter 96000, loss: 0.040510
 >> iter 97000, loss: 0.055295
 >> iter 98000, loss: 0.051103
 >> iter 99000, loss: 0.076468
 >> iter 100000, loss: 0.054663
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.450176
 >> iter 2000, loss: 4.456463
 >> iter 3000, loss: 1.750712
 >> iter 4000, loss: 0.738497
 >> iter 5000, loss: 0.349709
 >> iter 6000, loss: 0.196657
 >> iter 7000, loss: 0.126017
 >> iter 8000, loss: 0.093850
 >> iter 9000, loss: 0.084198
 >> iter 10000, loss: 0.074830
   Number of active neurons: 7
 >> iter 11000, loss: 0.073237
 >> iter 12000, loss: 0.063286
 >> iter 13000, loss: 0.075695
 >> iter 14000, loss: 0.058235
 >> iter 15000, loss: 0.071380
 >> iter 16000, loss: 0.062058
 >> iter 17000, loss: 0.069252
 >> iter 18000, loss: 0.073724
 >> iter 19000, loss: 0.065410
 >> iter 20000, loss: 0.069323
   Number of active neurons: 7
 >> iter 21000, loss: 0.056873
 >> iter 22000, loss: 0.071609
 >> iter 23000, loss: 0.075743
 >> iter 24000, loss: 0.052598
 >> iter 25000, loss: 0.081526
 >> iter 26000, loss: 0.067555
 >> iter 27000, loss: 0.053173
 >> iter 28000, loss: 0.041347
 >> iter 29000, loss: 0.037693
 >> iter 30000, loss: 0.042328
   Number of active neurons: 5
 >> iter 31000, loss: 0.046889
 >> iter 32000, loss: 0.044011
 >> iter 33000, loss: 0.047981
 >> iter 34000, loss: 0.044346
 >> iter 35000, loss: 0.053579
 >> iter 36000, loss: 0.042764
 >> iter 37000, loss: 0.065700
 >> iter 38000, loss: 0.060081
 >> iter 39000, loss: 0.052824
 >> iter 40000, loss: 0.059380
   Number of active neurons: 4
 >> iter 41000, loss: 0.061711
 >> iter 42000, loss: 0.042932
 >> iter 43000, loss: 0.074511
 >> iter 44000, loss: 0.055350
 >> iter 45000, loss: 0.044665
 >> iter 46000, loss: 0.057724
 >> iter 47000, loss: 0.074390
 >> iter 48000, loss: 0.054510
 >> iter 49000, loss: 0.043611
 >> iter 50000, loss: 0.045112
   Number of active neurons: 4
 >> iter 51000, loss: 0.048200
 >> iter 52000, loss: 0.062717
 >> iter 53000, loss: 0.049822
 >> iter 54000, loss: 0.041949
 >> iter 55000, loss: 0.053805
 >> iter 56000, loss: 0.047159
 >> iter 57000, loss: 0.043524
 >> iter 58000, loss: 0.036759
 >> iter 59000, loss: 0.058180
 >> iter 60000, loss: 0.057654
   Number of active neurons: 4
 >> iter 61000, loss: 0.041361
 >> iter 62000, loss: 0.049431
 >> iter 63000, loss: 0.041668
 >> iter 64000, loss: 0.037351
 >> iter 65000, loss: 0.050936
 >> iter 66000, loss: 0.046633
 >> iter 67000, loss: 0.041108
 >> iter 68000, loss: 0.065818
 >> iter 69000, loss: 0.056212
 >> iter 70000, loss: 0.048574
   Number of active neurons: 4
 >> iter 71000, loss: 0.049314
 >> iter 72000, loss: 0.041296
 >> iter 73000, loss: 0.052983
 >> iter 74000, loss: 0.040366
 >> iter 75000, loss: 0.041650
 >> iter 76000, loss: 0.035497
 >> iter 77000, loss: 0.039622
 >> iter 78000, loss: 0.045311
 >> iter 79000, loss: 0.044530
 >> iter 80000, loss: 0.038781
   Number of active neurons: 2
 >> iter 81000, loss: 0.034894
 >> iter 82000, loss: 0.052444
 >> iter 83000, loss: 0.039502
 >> iter 84000, loss: 0.050328
 >> iter 85000, loss: 0.040573
 >> iter 86000, loss: 0.043287
 >> iter 87000, loss: 0.044557
 >> iter 88000, loss: 0.044967
 >> iter 89000, loss: 0.067286
 >> iter 90000, loss: 0.051265
   Number of active neurons: 2
 >> iter 91000, loss: 0.032317
 >> iter 92000, loss: 0.040173
 >> iter 93000, loss: 0.050589
 >> iter 94000, loss: 0.044453
 >> iter 95000, loss: 0.036015
 >> iter 96000, loss: 0.031771
 >> iter 97000, loss: 0.042555
 >> iter 98000, loss: 0.044181
 >> iter 99000, loss: 0.038897
 >> iter 100000, loss: 0.043318
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.309750
 >> iter 2000, loss: 4.392308
 >> iter 3000, loss: 1.709685
 >> iter 4000, loss: 0.708982
 >> iter 5000, loss: 0.333718
 >> iter 6000, loss: 0.162646
 >> iter 7000, loss: 0.102672
 >> iter 8000, loss: 0.095916
 >> iter 9000, loss: 0.083084
 >> iter 10000, loss: 0.064031
   Number of active neurons: 7
 >> iter 11000, loss: 0.050248
 >> iter 12000, loss: 0.060220
 >> iter 13000, loss: 0.052696
 >> iter 14000, loss: 0.055199
 >> iter 15000, loss: 0.062084
 >> iter 16000, loss: 0.062373
 >> iter 17000, loss: 0.059444
 >> iter 18000, loss: 0.044568
 >> iter 19000, loss: 0.073315
 >> iter 20000, loss: 0.058577
   Number of active neurons: 6
 >> iter 21000, loss: 0.046781
 >> iter 22000, loss: 0.037067
 >> iter 23000, loss: 0.054316
 >> iter 24000, loss: 0.076520
 >> iter 25000, loss: 0.061446
 >> iter 26000, loss: 0.059188
 >> iter 27000, loss: 0.058655
 >> iter 28000, loss: 0.051248
 >> iter 29000, loss: 0.065622
 >> iter 30000, loss: 0.060871
   Number of active neurons: 5
 >> iter 31000, loss: 0.055365
 >> iter 32000, loss: 0.048974
 >> iter 33000, loss: 0.043752
 >> iter 34000, loss: 0.060368
 >> iter 35000, loss: 0.054965
 >> iter 36000, loss: 0.044373
 >> iter 37000, loss: 0.045001
 >> iter 38000, loss: 0.039698
 >> iter 39000, loss: 0.050131
 >> iter 40000, loss: 0.048756
   Number of active neurons: 5
 >> iter 41000, loss: 0.039788
 >> iter 42000, loss: 0.046703
 >> iter 43000, loss: 0.039116
 >> iter 44000, loss: 0.037678
 >> iter 45000, loss: 0.068705
 >> iter 46000, loss: 0.054718
 >> iter 47000, loss: 0.046676
 >> iter 48000, loss: 0.053229
 >> iter 49000, loss: 0.062310
 >> iter 50000, loss: 0.066162
   Number of active neurons: 5
 >> iter 51000, loss: 0.051646
 >> iter 52000, loss: 0.045739
 >> iter 53000, loss: 0.043558
 >> iter 54000, loss: 0.044584
 >> iter 55000, loss: 0.036870
 >> iter 56000, loss: 0.064023
 >> iter 57000, loss: 0.053239
 >> iter 58000, loss: 0.052693
 >> iter 59000, loss: 0.050599
 >> iter 60000, loss: 0.051308
   Number of active neurons: 4
 >> iter 61000, loss: 0.038919
 >> iter 62000, loss: 0.046115
 >> iter 63000, loss: 0.062685
 >> iter 64000, loss: 0.064070
 >> iter 65000, loss: 0.060574
 >> iter 66000, loss: 0.044665
 >> iter 67000, loss: 0.048345
 >> iter 68000, loss: 0.044777
 >> iter 69000, loss: 0.046371
 >> iter 70000, loss: 0.039259
   Number of active neurons: 3
 >> iter 71000, loss: 0.048373
 >> iter 72000, loss: 0.051406
 >> iter 73000, loss: 0.049701
 >> iter 74000, loss: 0.050007
 >> iter 75000, loss: 0.057153
 >> iter 76000, loss: 0.049082
 >> iter 77000, loss: 0.054524
 >> iter 78000, loss: 0.038167
 >> iter 79000, loss: 0.039309
 >> iter 80000, loss: 0.050466
   Number of active neurons: 3
 >> iter 81000, loss: 0.059692
 >> iter 82000, loss: 0.064293
 >> iter 83000, loss: 0.044250
 >> iter 84000, loss: 0.049106
 >> iter 85000, loss: 0.034082
 >> iter 86000, loss: 0.055112
 >> iter 87000, loss: 0.049757
 >> iter 88000, loss: 0.055344
 >> iter 89000, loss: 0.066195
 >> iter 90000, loss: 0.054130
   Number of active neurons: 2
 >> iter 91000, loss: 0.051061
 >> iter 92000, loss: 0.054425
 >> iter 93000, loss: 0.084419
 >> iter 94000, loss: 0.056813
 >> iter 95000, loss: 0.040269
 >> iter 96000, loss: 0.059389
 >> iter 97000, loss: 0.039976
 >> iter 98000, loss: 0.041140
 >> iter 99000, loss: 0.036547
 >> iter 100000, loss: 0.043933
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.423605
 >> iter 2000, loss: 4.448352
 >> iter 3000, loss: 1.742741
 >> iter 4000, loss: 0.744251
 >> iter 5000, loss: 0.331463
 >> iter 6000, loss: 0.169393
 >> iter 7000, loss: 0.122201
 >> iter 8000, loss: 0.087650
 >> iter 9000, loss: 0.067480
 >> iter 10000, loss: 0.063477
   Number of active neurons: 7
 >> iter 11000, loss: 0.082295
 >> iter 12000, loss: 0.080332
 >> iter 13000, loss: 0.076161
 >> iter 14000, loss: 0.057017
 >> iter 15000, loss: 0.056824
 >> iter 16000, loss: 0.042613
 >> iter 17000, loss: 0.060954
 >> iter 18000, loss: 0.057877
 >> iter 19000, loss: 0.061283
 >> iter 20000, loss: 0.061702
   Number of active neurons: 7
 >> iter 21000, loss: 0.067990
 >> iter 22000, loss: 0.051261
 >> iter 23000, loss: 0.057689
 >> iter 24000, loss: 0.057519
 >> iter 25000, loss: 0.084203
 >> iter 26000, loss: 0.061350
 >> iter 27000, loss: 0.048481
 >> iter 28000, loss: 0.042735
 >> iter 29000, loss: 0.051272
 >> iter 30000, loss: 0.048631
   Number of active neurons: 6
 >> iter 31000, loss: 0.045693
 >> iter 32000, loss: 0.052996
 >> iter 33000, loss: 0.052523
 >> iter 34000, loss: 0.065633
 >> iter 35000, loss: 0.050221
 >> iter 36000, loss: 0.061098
 >> iter 37000, loss: 0.048056
 >> iter 38000, loss: 0.051978
 >> iter 39000, loss: 0.038122
 >> iter 40000, loss: 0.044501
   Number of active neurons: 5
 >> iter 41000, loss: 0.064903
 >> iter 42000, loss: 0.055962
 >> iter 43000, loss: 0.052241
 >> iter 44000, loss: 0.038253
 >> iter 45000, loss: 0.054089
 >> iter 46000, loss: 0.049398
 >> iter 47000, loss: 0.049665
 >> iter 48000, loss: 0.046175
 >> iter 49000, loss: 0.042842
 >> iter 50000, loss: 0.051570
   Number of active neurons: 4
 >> iter 51000, loss: 0.042926
 >> iter 52000, loss: 0.050973
 >> iter 53000, loss: 0.063947
 >> iter 54000, loss: 0.049098
 >> iter 55000, loss: 0.053178
 >> iter 56000, loss: 0.041062
 >> iter 57000, loss: 0.051297
 >> iter 58000, loss: 0.045816
 >> iter 59000, loss: 0.058722
 >> iter 60000, loss: 0.040771
   Number of active neurons: 3
 >> iter 61000, loss: 0.046537
 >> iter 62000, loss: 0.041837
 >> iter 63000, loss: 0.053340
 >> iter 64000, loss: 0.033796
 >> iter 65000, loss: 0.051788
 >> iter 66000, loss: 0.048058
 >> iter 67000, loss: 0.054313
 >> iter 68000, loss: 0.048682
 >> iter 69000, loss: 0.052440
 >> iter 70000, loss: 0.066836
   Number of active neurons: 3
 >> iter 71000, loss: 0.056413
 >> iter 72000, loss: 0.043328
 >> iter 73000, loss: 0.031675
 >> iter 74000, loss: 0.034422
 >> iter 75000, loss: 0.050888
 >> iter 76000, loss: 0.053363
 >> iter 77000, loss: 0.040347
 >> iter 78000, loss: 0.031844
 >> iter 79000, loss: 0.031841
 >> iter 80000, loss: 0.051711
   Number of active neurons: 3
 >> iter 81000, loss: 0.036981
 >> iter 82000, loss: 0.037658
 >> iter 83000, loss: 0.062478
 >> iter 84000, loss: 0.056026
 >> iter 85000, loss: 0.044838
 >> iter 86000, loss: 0.046659
 >> iter 87000, loss: 0.049196
 >> iter 88000, loss: 0.030613
 >> iter 89000, loss: 0.031361
 >> iter 90000, loss: 0.031403
   Number of active neurons: 2
 >> iter 91000, loss: 0.031624
 >> iter 92000, loss: 0.033932
 >> iter 93000, loss: 0.034868
 >> iter 94000, loss: 0.049176
 >> iter 95000, loss: 0.047125
 >> iter 96000, loss: 0.043165
 >> iter 97000, loss: 0.052442
 >> iter 98000, loss: 0.048596
 >> iter 99000, loss: 0.044460
 >> iter 100000, loss: 0.048030
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.311964
 >> iter 2000, loss: 4.356719
 >> iter 3000, loss: 1.713224
 >> iter 4000, loss: 0.708046
 >> iter 5000, loss: 0.314291
 >> iter 6000, loss: 0.157298
 >> iter 7000, loss: 0.094633
 >> iter 8000, loss: 0.091959
 >> iter 9000, loss: 0.081330
 >> iter 10000, loss: 0.059045
   Number of active neurons: 6
 >> iter 11000, loss: 0.067744
 >> iter 12000, loss: 0.066571
 >> iter 13000, loss: 0.062589
 >> iter 14000, loss: 0.074054
 >> iter 15000, loss: 0.070506
 >> iter 16000, loss: 0.064514
 >> iter 17000, loss: 0.082113
 >> iter 18000, loss: 0.057546
 >> iter 19000, loss: 0.059588
 >> iter 20000, loss: 0.046680
   Number of active neurons: 6
 >> iter 21000, loss: 0.056649
 >> iter 22000, loss: 0.064901
 >> iter 23000, loss: 0.056954
 >> iter 24000, loss: 0.055603
 >> iter 25000, loss: 0.064962
 >> iter 26000, loss: 0.051359
 >> iter 27000, loss: 0.061115
 >> iter 28000, loss: 0.049917
 >> iter 29000, loss: 0.099333
 >> iter 30000, loss: 0.059523
   Number of active neurons: 6
 >> iter 31000, loss: 0.059154
 >> iter 32000, loss: 0.049785
 >> iter 33000, loss: 0.062769
 >> iter 34000, loss: 0.051964
 >> iter 35000, loss: 0.054605
 >> iter 36000, loss: 0.045085
 >> iter 37000, loss: 0.083376
 >> iter 38000, loss: 0.076837
 >> iter 39000, loss: 0.052110
 >> iter 40000, loss: 0.046711
   Number of active neurons: 4
 >> iter 41000, loss: 0.059787
 >> iter 42000, loss: 0.052956
 >> iter 43000, loss: 0.053489
 >> iter 44000, loss: 0.043544
 >> iter 45000, loss: 0.034695
 >> iter 46000, loss: 0.038567
 >> iter 47000, loss: 0.053839
 >> iter 48000, loss: 0.048068
 >> iter 49000, loss: 0.052125
 >> iter 50000, loss: 0.063498
   Number of active neurons: 3
 >> iter 51000, loss: 0.051404
 >> iter 52000, loss: 0.037491
 >> iter 53000, loss: 0.045769
 >> iter 54000, loss: 0.044290
 >> iter 55000, loss: 0.100942
 >> iter 56000, loss: 0.078525
 >> iter 57000, loss: 0.046758
 >> iter 58000, loss: 0.067848
 >> iter 59000, loss: 0.046780
 >> iter 60000, loss: 0.050885
   Number of active neurons: 2
 >> iter 61000, loss: 0.044296
 >> iter 62000, loss: 0.038307
 >> iter 63000, loss: 0.036091
 >> iter 64000, loss: 0.058755
 >> iter 65000, loss: 0.073500
 >> iter 66000, loss: 0.073524
 >> iter 67000, loss: 0.047197
 >> iter 68000, loss: 0.037842
 >> iter 69000, loss: 0.031752
 >> iter 70000, loss: 0.051599
   Number of active neurons: 2
 >> iter 71000, loss: 0.041144
 >> iter 72000, loss: 0.049058
 >> iter 73000, loss: 0.055611
 >> iter 74000, loss: 0.042781
 >> iter 75000, loss: 0.038342
 >> iter 76000, loss: 0.029113
 >> iter 77000, loss: 0.034964
 >> iter 78000, loss: 0.031788
 >> iter 79000, loss: 0.040127
 >> iter 80000, loss: 0.041830
   Number of active neurons: 2
 >> iter 81000, loss: 0.048142
 >> iter 82000, loss: 0.038450
 >> iter 83000, loss: 0.064266
 >> iter 84000, loss: 0.057058
 >> iter 85000, loss: 0.043649
 >> iter 86000, loss: 0.044546
 >> iter 87000, loss: 0.054190
 >> iter 88000, loss: 0.039144
 >> iter 89000, loss: 0.044994
 >> iter 90000, loss: 0.043853
   Number of active neurons: 2
 >> iter 91000, loss: 0.064140
 >> iter 92000, loss: 0.047366
 >> iter 93000, loss: 0.044620
 >> iter 94000, loss: 0.033546
 >> iter 95000, loss: 0.058143
 >> iter 96000, loss: 0.060626
 >> iter 97000, loss: 0.056036
 >> iter 98000, loss: 0.047446
 >> iter 99000, loss: 0.041097
 >> iter 100000, loss: 0.046792
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 11.296349
 >> iter 2000, loss: 4.386881
 >> iter 3000, loss: 1.738051
 >> iter 4000, loss: 0.734710
 >> iter 5000, loss: 0.335730
 >> iter 6000, loss: 0.165931
 >> iter 7000, loss: 0.108225
 >> iter 8000, loss: 0.085420
 >> iter 9000, loss: 0.077897
 >> iter 10000, loss: 0.064023
   Number of active neurons: 8
 >> iter 11000, loss: 0.079773
 >> iter 12000, loss: 0.083336
 >> iter 13000, loss: 0.067435
 >> iter 14000, loss: 0.055575
 >> iter 15000, loss: 0.054677
 >> iter 16000, loss: 0.053215
 >> iter 17000, loss: 0.046673
 >> iter 18000, loss: 0.061951
 >> iter 19000, loss: 0.069534
 >> iter 20000, loss: 0.050211
   Number of active neurons: 6
 >> iter 21000, loss: 0.053927
 >> iter 22000, loss: 0.063768
 >> iter 23000, loss: 0.071416
 >> iter 24000, loss: 0.056129
 >> iter 25000, loss: 0.038339
 >> iter 26000, loss: 0.054611
 >> iter 27000, loss: 0.045713
 >> iter 28000, loss: 0.051115
 >> iter 29000, loss: 0.049595
 >> iter 30000, loss: 0.052492
   Number of active neurons: 4
 >> iter 31000, loss: 0.050439
 >> iter 32000, loss: 0.048256
 >> iter 33000, loss: 0.050061
 >> iter 34000, loss: 0.040064
 >> iter 35000, loss: 0.039831
 >> iter 36000, loss: 0.040169
 >> iter 37000, loss: 0.037255
 >> iter 38000, loss: 0.034169
 >> iter 39000, loss: 0.041701
 >> iter 40000, loss: 0.042113
   Number of active neurons: 4
 >> iter 41000, loss: 0.069759
 >> iter 42000, loss: 0.056490
 >> iter 43000, loss: 0.070280
 >> iter 44000, loss: 0.049513
 >> iter 45000, loss: 0.044571
 >> iter 46000, loss: 0.046481
 >> iter 47000, loss: 0.046343
 >> iter 48000, loss: 0.042563
 >> iter 49000, loss: 0.040394
 >> iter 50000, loss: 0.045058
   Number of active neurons: 4
 >> iter 51000, loss: 0.055479
 >> iter 52000, loss: 0.045135
 >> iter 53000, loss: 0.044256
 >> iter 54000, loss: 0.039475
 >> iter 55000, loss: 0.051201
 >> iter 56000, loss: 0.045164
 >> iter 57000, loss: 0.043627
 >> iter 58000, loss: 0.050251
 >> iter 59000, loss: 0.044826
 >> iter 60000, loss: 0.040721
   Number of active neurons: 4
 >> iter 61000, loss: 0.044772
 >> iter 62000, loss: 0.059096
 >> iter 63000, loss: 0.045528
 >> iter 64000, loss: 0.035632
 >> iter 65000, loss: 0.037054
 >> iter 66000, loss: 0.037464
 >> iter 67000, loss: 0.028180
 >> iter 68000, loss: 0.052126
 >> iter 69000, loss: 0.054296
 >> iter 70000, loss: 0.065962
   Number of active neurons: 4
 >> iter 71000, loss: 0.058782
 >> iter 72000, loss: 0.039643
 >> iter 73000, loss: 0.054173
 >> iter 74000, loss: 0.040971
 >> iter 75000, loss: 0.045976
 >> iter 76000, loss: 0.046287
 >> iter 77000, loss: 0.043614
 >> iter 78000, loss: 0.040075
 >> iter 79000, loss: 0.049475
 >> iter 80000, loss: 0.042522
   Number of active neurons: 4
 >> iter 81000, loss: 0.070671
 >> iter 82000, loss: 0.054615
 >> iter 83000, loss: 0.050722
 >> iter 84000, loss: 0.047684
 >> iter 85000, loss: 0.051651
 >> iter 86000, loss: 0.050263
 >> iter 87000, loss: 0.059028
 >> iter 88000, loss: 0.050345
 >> iter 89000, loss: 0.050286
 >> iter 90000, loss: 0.059770
   Number of active neurons: 2
 >> iter 91000, loss: 0.057649
 >> iter 92000, loss: 0.046540
 >> iter 93000, loss: 0.042337
 >> iter 94000, loss: 0.042158
 >> iter 95000, loss: 0.036330
 >> iter 96000, loss: 0.047817
 >> iter 97000, loss: 0.055053
 >> iter 98000, loss: 0.047915
 >> iter 99000, loss: 0.036854
 >> iter 100000, loss: 0.026402
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.379773
 >> iter 2000, loss: 4.483539
 >> iter 3000, loss: 1.758250
 >> iter 4000, loss: 0.742544
 >> iter 5000, loss: 0.361760
 >> iter 6000, loss: 0.220814
 >> iter 7000, loss: 0.135980
 >> iter 8000, loss: 0.096777
 >> iter 9000, loss: 0.072423
 >> iter 10000, loss: 0.068718
   Number of active neurons: 7
 >> iter 11000, loss: 0.065807
 >> iter 12000, loss: 0.055442
 >> iter 13000, loss: 0.066683
 >> iter 14000, loss: 0.076502
 >> iter 15000, loss: 0.060400
 >> iter 16000, loss: 0.097446
 >> iter 17000, loss: 0.068278
 >> iter 18000, loss: 0.056200
 >> iter 19000, loss: 0.052602
 >> iter 20000, loss: 0.048993
   Number of active neurons: 6
 >> iter 21000, loss: 0.075663
 >> iter 22000, loss: 0.063859
 >> iter 23000, loss: 0.065342
 >> iter 24000, loss: 0.047929
 >> iter 25000, loss: 0.036514
 >> iter 26000, loss: 0.040335
 >> iter 27000, loss: 0.039705
 >> iter 28000, loss: 0.042456
 >> iter 29000, loss: 0.073209
 >> iter 30000, loss: 0.065813
   Number of active neurons: 6
 >> iter 31000, loss: 0.058535
 >> iter 32000, loss: 0.052028
 >> iter 33000, loss: 0.049876
 >> iter 34000, loss: 0.046490
 >> iter 35000, loss: 0.047894
 >> iter 36000, loss: 0.045013
 >> iter 37000, loss: 0.035689
 >> iter 38000, loss: 0.050747
 >> iter 39000, loss: 0.060407
 >> iter 40000, loss: 0.041149
   Number of active neurons: 4
 >> iter 41000, loss: 0.045618
 >> iter 42000, loss: 0.039982
 >> iter 43000, loss: 0.038451
 >> iter 44000, loss: 0.070150
 >> iter 45000, loss: 0.042113
 >> iter 46000, loss: 0.070911
 >> iter 47000, loss: 0.050042
 >> iter 48000, loss: 0.043301
 >> iter 49000, loss: 0.049372
 >> iter 50000, loss: 0.047672
   Number of active neurons: 4
 >> iter 51000, loss: 0.044918
 >> iter 52000, loss: 0.043042
 >> iter 53000, loss: 0.052153
 >> iter 54000, loss: 0.041363
 >> iter 55000, loss: 0.048108
 >> iter 56000, loss: 0.036291
 >> iter 57000, loss: 0.056600
 >> iter 58000, loss: 0.051167
 >> iter 59000, loss: 0.039125
 >> iter 60000, loss: 0.058088
   Number of active neurons: 3
 >> iter 61000, loss: 0.044352
 >> iter 62000, loss: 0.037896
 >> iter 63000, loss: 0.039192
 >> iter 64000, loss: 0.054807
 >> iter 65000, loss: 0.045799
 >> iter 66000, loss: 0.041201
 >> iter 67000, loss: 0.034626
 >> iter 68000, loss: 0.042756
 >> iter 69000, loss: 0.033437
 >> iter 70000, loss: 0.027652
   Number of active neurons: 2
 >> iter 71000, loss: 0.042193
 >> iter 72000, loss: 0.063128
 >> iter 73000, loss: 0.059538
 >> iter 74000, loss: 0.062469
 >> iter 75000, loss: 0.045868
 >> iter 76000, loss: 0.037801
 >> iter 77000, loss: 0.043927
 >> iter 78000, loss: 0.062876
 >> iter 79000, loss: 0.043683
 >> iter 80000, loss: 0.058342
   Number of active neurons: 2
 >> iter 81000, loss: 0.048309
 >> iter 82000, loss: 0.044996
 >> iter 83000, loss: 0.040192
 >> iter 84000, loss: 0.035065
 >> iter 85000, loss: 0.038239
 >> iter 86000, loss: 0.047929
 >> iter 87000, loss: 0.043185
 >> iter 88000, loss: 0.064383
 >> iter 89000, loss: 0.042784
 >> iter 90000, loss: 0.036023
   Number of active neurons: 2
 >> iter 91000, loss: 0.045617
 >> iter 92000, loss: 0.044945
 >> iter 93000, loss: 0.042259
 >> iter 94000, loss: 0.038723
 >> iter 95000, loss: 0.049625
 >> iter 96000, loss: 0.053158
 >> iter 97000, loss: 0.044660
 >> iter 98000, loss: 0.032247
 >> iter 99000, loss: 0.055085
 >> iter 100000, loss: 0.042733
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

