 > Problema: tomita6nueva
 > Args:
   - Hidden size: 4
   - Noise level: 0.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.664357
 >> iter 2000, loss: 15.085598
 >> iter 3000, loss: 13.737238
 >> iter 4000, loss: 13.239872
 >> iter 5000, loss: 13.043926
 >> iter 6000, loss: 12.975971
 >> iter 7000, loss: 12.941847
 >> iter 8000, loss: 12.936923
 >> iter 9000, loss: 12.925927
 >> iter 10000, loss: 12.931769
   Number of active neurons: 4
 >> iter 11000, loss: 12.922119
 >> iter 12000, loss: 12.917288
 >> iter 13000, loss: 12.582103
 >> iter 14000, loss: 11.429176
 >> iter 15000, loss: 10.813495
 >> iter 16000, loss: 10.511592
 >> iter 17000, loss: 10.310948
 >> iter 18000, loss: 10.221572
 >> iter 19000, loss: 10.135041
 >> iter 20000, loss: 10.119734
   Number of active neurons: 4
 >> iter 21000, loss: 10.053965
 >> iter 22000, loss: 10.068733
 >> iter 23000, loss: 10.016309
 >> iter 24000, loss: 10.042454
 >> iter 25000, loss: 9.993721
 >> iter 26000, loss: 10.019637
 >> iter 27000, loss: 9.976412
 >> iter 28000, loss: 10.009168
 >> iter 29000, loss: 9.968016
 >> iter 30000, loss: 10.000607
   Number of active neurons: 4
 >> iter 31000, loss: 9.956116
 >> iter 32000, loss: 9.995576
 >> iter 33000, loss: 9.957276
 >> iter 34000, loss: 9.989049
 >> iter 35000, loss: 9.948814
 >> iter 36000, loss: 9.981345
 >> iter 37000, loss: 9.939361
 >> iter 38000, loss: 9.978290
 >> iter 39000, loss: 9.932137
 >> iter 40000, loss: 9.976923
   Number of active neurons: 4
 >> iter 41000, loss: 9.929457
 >> iter 42000, loss: 9.975269
 >> iter 43000, loss: 9.924738
 >> iter 44000, loss: 9.978028
 >> iter 45000, loss: 9.923992
 >> iter 46000, loss: 9.978251
 >> iter 47000, loss: 9.922143
 >> iter 48000, loss: 9.975454
 >> iter 49000, loss: 9.922828
 >> iter 50000, loss: 9.977730
   Number of active neurons: 4
 >> iter 51000, loss: 9.923844
 >> iter 52000, loss: 9.974142
 >> iter 53000, loss: 9.912617
 >> iter 54000, loss: 9.970886
 >> iter 55000, loss: 9.905346
 >> iter 56000, loss: 9.968439
 >> iter 57000, loss: 9.904099
 >> iter 58000, loss: 9.967557
 >> iter 59000, loss: 9.905800
 >> iter 60000, loss: 9.965408
   Number of active neurons: 4
 >> iter 61000, loss: 9.905529
 >> iter 62000, loss: 9.967810
 >> iter 63000, loss: 9.904057
 >> iter 64000, loss: 9.968340
 >> iter 65000, loss: 9.906380
 >> iter 66000, loss: 9.969593
 >> iter 67000, loss: 9.906545
 >> iter 68000, loss: 9.965950
 >> iter 69000, loss: 9.908195
 >> iter 70000, loss: 9.963420
   Number of active neurons: 4
 >> iter 71000, loss: 9.907654
 >> iter 72000, loss: 9.963482
 >> iter 73000, loss: 9.906922
 >> iter 74000, loss: 9.965128
 >> iter 75000, loss: 9.904154
 >> iter 76000, loss: 9.963835
 >> iter 77000, loss: 9.909455
 >> iter 78000, loss: 9.963288
 >> iter 79000, loss: 9.900699
 >> iter 80000, loss: 9.960164
   Number of active neurons: 4
 >> iter 81000, loss: 9.901045
 >> iter 82000, loss: 9.962749
 >> iter 83000, loss: 9.906355
 >> iter 84000, loss: 9.967716
 >> iter 85000, loss: 9.907570
 >> iter 86000, loss: 9.967557
 >> iter 87000, loss: 9.909277
 >> iter 88000, loss: 9.969168
 >> iter 89000, loss: 9.913546
 >> iter 90000, loss: 9.975441
   Number of active neurons: 4
 >> iter 91000, loss: 9.914879
 >> iter 92000, loss: 9.974278
 >> iter 93000, loss: 9.912733
 >> iter 94000, loss: 9.972171
 >> iter 95000, loss: 9.917063
 >> iter 96000, loss: 9.971294
 >> iter 97000, loss: 9.917247
 >> iter 98000, loss: 9.972225
 >> iter 99000, loss: 9.913848
 >> iter 100000, loss: 9.965409
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 21.0495790084
   - Test - Long: 31.7634118294
   - Test - Big: 21.2467875321
   - Test - A: 32.5511632558
   - Test - B: 32.5911605893
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.655346
 >> iter 2000, loss: 15.092271
 >> iter 3000, loss: 13.741396
 >> iter 4000, loss: 13.244547
 >> iter 5000, loss: 13.045025
 >> iter 6000, loss: 12.977972
 >> iter 7000, loss: 12.941581
 >> iter 8000, loss: 12.937775
 >> iter 9000, loss: 12.925129
 >> iter 10000, loss: 12.932053
   Number of active neurons: 4
 >> iter 11000, loss: 12.921052
 >> iter 12000, loss: 12.860201
 >> iter 13000, loss: 12.353490
 >> iter 14000, loss: 11.698974
 >> iter 15000, loss: 11.332768
 >> iter 16000, loss: 10.780646
 >> iter 17000, loss: 4.990265
 >> iter 18000, loss: 1.938911
 >> iter 19000, loss: 0.757932
 >> iter 20000, loss: 0.332412
   Number of active neurons: 4
 >> iter 21000, loss: 0.146685
 >> iter 22000, loss: 0.073860
 >> iter 23000, loss: 0.043750
 >> iter 24000, loss: 0.030500
 >> iter 25000, loss: 0.023769
 >> iter 26000, loss: 0.020022
 >> iter 27000, loss: 0.017457
 >> iter 28000, loss: 0.015686
 >> iter 29000, loss: 0.014208
 >> iter 30000, loss: 0.013085
   Number of active neurons: 4
 >> iter 31000, loss: 0.012059
 >> iter 32000, loss: 0.011255
 >> iter 33000, loss: 0.010490
 >> iter 34000, loss: 0.009880
 >> iter 35000, loss: 0.009282
 >> iter 36000, loss: 0.008804
 >> iter 37000, loss: 0.008323
 >> iter 38000, loss: 0.007940
 >> iter 39000, loss: 0.007545
 >> iter 40000, loss: 0.007232
   Number of active neurons: 4
 >> iter 41000, loss: 0.006899
 >> iter 42000, loss: 0.006637
 >> iter 43000, loss: 0.006354
 >> iter 44000, loss: 0.006133
 >> iter 45000, loss: 0.005889
 >> iter 46000, loss: 0.005701
 >> iter 47000, loss: 0.005487
 >> iter 48000, loss: 0.005323
 >> iter 49000, loss: 0.005137
 >> iter 50000, loss: 0.004994
   Number of active neurons: 4
 >> iter 51000, loss: 0.004827
 >> iter 52000, loss: 0.004702
 >> iter 53000, loss: 0.004551
 >> iter 54000, loss: 0.004442
 >> iter 55000, loss: 0.004306
 >> iter 56000, loss: 0.004209
 >> iter 57000, loss: 0.004086
 >> iter 58000, loss: 0.004000
 >> iter 59000, loss: 0.003888
 >> iter 60000, loss: 0.003814
   Number of active neurons: 4
 >> iter 61000, loss: 0.003708
 >> iter 62000, loss: 0.003641
 >> iter 63000, loss: 0.003543
 >> iter 64000, loss: 0.003486
 >> iter 65000, loss: 0.003393
 >> iter 66000, loss: 0.003341
 >> iter 67000, loss: 0.003255
 >> iter 68000, loss: 0.003207
 >> iter 69000, loss: 0.003128
 >> iter 70000, loss: 0.003084
   Number of active neurons: 4
 >> iter 71000, loss: 0.003011
 >> iter 72000, loss: 0.002970
 >> iter 73000, loss: 0.002901
 >> iter 74000, loss: 0.002864
 >> iter 75000, loss: 0.002799
 >> iter 76000, loss: 0.002765
 >> iter 77000, loss: 0.002704
 >> iter 78000, loss: 0.002673
 >> iter 79000, loss: 0.002616
 >> iter 80000, loss: 0.002587
   Number of active neurons: 4
 >> iter 81000, loss: 0.002533
 >> iter 82000, loss: 0.002507
 >> iter 83000, loss: 0.002455
 >> iter 84000, loss: 0.002431
 >> iter 85000, loss: 0.002382
 >> iter 86000, loss: 0.002359
 >> iter 87000, loss: 0.002313
 >> iter 88000, loss: 0.002291
 >> iter 89000, loss: 0.002248
 >> iter 90000, loss: 0.002228
   Number of active neurons: 4
 >> iter 91000, loss: 0.002186
 >> iter 92000, loss: 0.002167
 >> iter 93000, loss: 0.002127
 >> iter 94000, loss: 0.002110
 >> iter 95000, loss: 0.002072
 >> iter 96000, loss: 0.002055
 >> iter 97000, loss: 0.002020
 >> iter 98000, loss: 0.002004
 >> iter 99000, loss: 0.001970
 >> iter 100000, loss: 0.001955
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.667643
 >> iter 2000, loss: 15.088455
 >> iter 3000, loss: 13.740813
 >> iter 4000, loss: 13.243818
 >> iter 5000, loss: 13.048074
 >> iter 6000, loss: 12.979298
 >> iter 7000, loss: 12.944794
 >> iter 8000, loss: 12.938770
 >> iter 9000, loss: 12.927578
 >> iter 10000, loss: 12.931908
   Number of active neurons: 4
 >> iter 11000, loss: 12.919265
 >> iter 12000, loss: 12.726667
 >> iter 13000, loss: 11.624786
 >> iter 14000, loss: 10.898296
 >> iter 15000, loss: 10.501364
 >> iter 16000, loss: 10.333689
 >> iter 17000, loss: 10.202952
 >> iter 18000, loss: 10.176901
 >> iter 19000, loss: 10.100487
 >> iter 20000, loss: 10.097601
   Number of active neurons: 4
 >> iter 21000, loss: 10.038713
 >> iter 22000, loss: 10.065642
 >> iter 23000, loss: 10.007785
 >> iter 24000, loss: 10.033853
 >> iter 25000, loss: 9.980541
 >> iter 26000, loss: 10.019825
 >> iter 27000, loss: 9.968333
 >> iter 28000, loss: 10.004559
 >> iter 29000, loss: 9.960254
 >> iter 30000, loss: 9.998369
   Number of active neurons: 4
 >> iter 31000, loss: 9.949198
 >> iter 32000, loss: 9.988299
 >> iter 33000, loss: 9.948214
 >> iter 34000, loss: 9.982990
 >> iter 35000, loss: 9.946268
 >> iter 36000, loss: 9.977966
 >> iter 37000, loss: 9.935682
 >> iter 38000, loss: 9.975676
 >> iter 39000, loss: 9.930312
 >> iter 40000, loss: 9.975353
   Number of active neurons: 4
 >> iter 41000, loss: 9.928370
 >> iter 42000, loss: 9.974334
 >> iter 43000, loss: 9.924160
 >> iter 44000, loss: 9.977713
 >> iter 45000, loss: 9.923840
 >> iter 46000, loss: 9.978679
 >> iter 47000, loss: 9.922450
 >> iter 48000, loss: 9.976927
 >> iter 49000, loss: 9.923740
 >> iter 50000, loss: 9.980878
   Number of active neurons: 4
 >> iter 51000, loss: 9.922958
 >> iter 52000, loss: 9.977061
 >> iter 53000, loss: 9.914308
 >> iter 54000, loss: 9.975255
 >> iter 55000, loss: 9.907290
 >> iter 56000, loss: 9.973544
 >> iter 57000, loss: 9.906782
 >> iter 58000, loss: 9.972975
 >> iter 59000, loss: 9.908107
 >> iter 60000, loss: 9.971600
   Number of active neurons: 4
 >> iter 61000, loss: 9.908798
 >> iter 62000, loss: 9.973900
 >> iter 63000, loss: 9.907469
 >> iter 64000, loss: 9.974789
 >> iter 65000, loss: 9.909543
 >> iter 66000, loss: 9.976269
 >> iter 67000, loss: 9.909790
 >> iter 68000, loss: 9.973015
 >> iter 69000, loss: 9.911519
 >> iter 70000, loss: 9.970537
   Number of active neurons: 4
 >> iter 71000, loss: 9.911846
 >> iter 72000, loss: 9.971723
 >> iter 73000, loss: 9.910840
 >> iter 74000, loss: 9.973053
 >> iter 75000, loss: 9.907873
 >> iter 76000, loss: 9.971970
 >> iter 77000, loss: 9.913454
 >> iter 78000, loss: 9.971521
 >> iter 79000, loss: 9.904498
 >> iter 80000, loss: 9.968388
   Number of active neurons: 4
 >> iter 81000, loss: 9.904909
 >> iter 82000, loss: 9.970827
 >> iter 83000, loss: 9.910343
 >> iter 84000, loss: 9.975849
 >> iter 85000, loss: 9.916731
 >> iter 86000, loss: 9.978246
 >> iter 87000, loss: 9.914300
 >> iter 88000, loss: 9.980742
 >> iter 89000, loss: 9.918656
 >> iter 90000, loss: 9.984257
   Number of active neurons: 4
 >> iter 91000, loss: 9.918957
 >> iter 92000, loss: 9.982564
 >> iter 93000, loss: 9.916647
 >> iter 94000, loss: 9.980218
 >> iter 95000, loss: 9.924836
 >> iter 96000, loss: 9.981067
 >> iter 97000, loss: 9.922217
 >> iter 98000, loss: 9.980853
 >> iter 99000, loss: 9.917825
 >> iter 100000, loss: 9.973623
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 21.0495790084
   - Test - Long: 31.7634118294
   - Test - Big: 21.2467875321
   - Test - A: 32.5511632558
   - Test - B: 32.5911605893
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.600044
 >> iter 2000, loss: 15.070136
 >> iter 3000, loss: 13.736959
 >> iter 4000, loss: 13.245883
 >> iter 5000, loss: 13.049084
 >> iter 6000, loss: 12.980053
 >> iter 7000, loss: 12.943202
 >> iter 8000, loss: 12.933339
 >> iter 9000, loss: 12.617122
 >> iter 10000, loss: 11.723659
   Number of active neurons: 4
 >> iter 11000, loss: 11.001585
 >> iter 12000, loss: 11.018951
 >> iter 13000, loss: 10.464152
 >> iter 14000, loss: 10.299018
 >> iter 15000, loss: 9.995885
 >> iter 16000, loss: 9.936340
 >> iter 17000, loss: 9.602705
 >> iter 18000, loss: 9.632072
 >> iter 19000, loss: 9.465550
 >> iter 20000, loss: 9.589311
   Number of active neurons: 4
 >> iter 21000, loss: 9.316722
 >> iter 22000, loss: 9.457879
 >> iter 23000, loss: 9.231082
 >> iter 24000, loss: 9.478366
 >> iter 25000, loss: 9.320062
 >> iter 26000, loss: 9.363137
 >> iter 27000, loss: 9.259367
 >> iter 28000, loss: 9.292873
 >> iter 29000, loss: 9.240276
 >> iter 30000, loss: 9.480256
   Number of active neurons: 4
 >> iter 31000, loss: 9.285074
 >> iter 32000, loss: 9.321092
 >> iter 33000, loss: 9.307531
 >> iter 34000, loss: 9.382913
 >> iter 35000, loss: 9.271681
 >> iter 36000, loss: 9.385718
 >> iter 37000, loss: 9.324716
 >> iter 38000, loss: 9.318942
 >> iter 39000, loss: 9.268437
 >> iter 40000, loss: 9.266004
   Number of active neurons: 4
 >> iter 41000, loss: 9.287518
 >> iter 42000, loss: 9.289400
 >> iter 43000, loss: 9.182837
 >> iter 44000, loss: 9.347589
 >> iter 45000, loss: 9.206172
 >> iter 46000, loss: 9.302397
 >> iter 47000, loss: 9.180437
 >> iter 48000, loss: 9.247366
 >> iter 49000, loss: 9.217963
 >> iter 50000, loss: 9.425679
   Number of active neurons: 4
 >> iter 51000, loss: 9.160488
 >> iter 52000, loss: 9.193784
 >> iter 53000, loss: 9.154564
 >> iter 54000, loss: 9.318271
 >> iter 55000, loss: 9.171789
 >> iter 56000, loss: 9.297486
 >> iter 57000, loss: 9.204291
 >> iter 58000, loss: 9.316142
 >> iter 59000, loss: 9.202640
 >> iter 60000, loss: 9.370280
   Number of active neurons: 4
 >> iter 61000, loss: 9.197952
 >> iter 62000, loss: 9.338793
 >> iter 63000, loss: 9.210470
 >> iter 64000, loss: 9.346118
 >> iter 65000, loss: 9.236197
 >> iter 66000, loss: 9.351655
 >> iter 67000, loss: 9.214498
 >> iter 68000, loss: 9.285093
 >> iter 69000, loss: 9.174660
 >> iter 70000, loss: 9.271346
   Number of active neurons: 4
 >> iter 71000, loss: 9.169857
 >> iter 72000, loss: 9.293483
 >> iter 73000, loss: 9.237742
 >> iter 74000, loss: 9.421747
 >> iter 75000, loss: 9.204165
 >> iter 76000, loss: 9.331736
 >> iter 77000, loss: 9.173703
 >> iter 78000, loss: 9.255420
 >> iter 79000, loss: 9.241410
 >> iter 80000, loss: 9.300047
   Number of active neurons: 4
 >> iter 81000, loss: 9.144002
 >> iter 82000, loss: 9.284663
 >> iter 83000, loss: 9.172599
 >> iter 84000, loss: 9.297495
 >> iter 85000, loss: 9.097071
 >> iter 86000, loss: 9.307758
 >> iter 87000, loss: 9.291861
 >> iter 88000, loss: 9.383875
 >> iter 89000, loss: 9.177951
 >> iter 90000, loss: 9.296686
   Number of active neurons: 4
 >> iter 91000, loss: 9.205017
 >> iter 92000, loss: 9.402578
 >> iter 93000, loss: 9.190091
 >> iter 94000, loss: 9.346674
 >> iter 95000, loss: 9.214920
 >> iter 96000, loss: 9.301773
 >> iter 97000, loss: 9.189419
 >> iter 98000, loss: 9.377135
 >> iter 99000, loss: 9.236720
 >> iter 100000, loss: 9.273763
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 12.395752085
   - Test - Long: 31.183440828
   - Test - Big: 12.4578754212
   - Test - A: 0.413305779615
   - Test - B: 31.6178921405
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.690268
 >> iter 2000, loss: 15.094421
 >> iter 3000, loss: 13.745256
 >> iter 4000, loss: 13.252733
 >> iter 5000, loss: 13.059472
 >> iter 6000, loss: 12.994772
 >> iter 7000, loss: 12.960542
 >> iter 8000, loss: 12.957393
 >> iter 9000, loss: 12.944692
 >> iter 10000, loss: 12.952223
   Number of active neurons: 4
 >> iter 11000, loss: 12.940230
 >> iter 12000, loss: 12.946828
 >> iter 13000, loss: 12.935518
 >> iter 14000, loss: 12.943920
 >> iter 15000, loss: 12.935423
 >> iter 16000, loss: 12.942022
 >> iter 17000, loss: 12.935099
 >> iter 18000, loss: 12.939082
 >> iter 19000, loss: 12.930761
 >> iter 20000, loss: 12.939474
   Number of active neurons: 4
 >> iter 21000, loss: 12.927448
 >> iter 22000, loss: 12.935001
 >> iter 23000, loss: 12.886316
 >> iter 24000, loss: 12.328732
 >> iter 25000, loss: 11.247971
 >> iter 26000, loss: 11.036529
 >> iter 27000, loss: 10.662873
 >> iter 28000, loss: 6.497251
 >> iter 29000, loss: 2.515929
 >> iter 30000, loss: 0.980668
   Number of active neurons: 4
 >> iter 31000, loss: 0.396563
 >> iter 32000, loss: 0.172124
 >> iter 33000, loss: 0.084131
 >> iter 34000, loss: 0.048192
 >> iter 35000, loss: 0.032414
 >> iter 36000, loss: 0.024737
 >> iter 37000, loss: 0.020442
 >> iter 38000, loss: 0.017692
 >> iter 39000, loss: 0.015729
 >> iter 40000, loss: 0.014212
   Number of active neurons: 4
 >> iter 41000, loss: 0.012994
 >> iter 42000, loss: 0.011968
 >> iter 43000, loss: 0.011105
 >> iter 44000, loss: 0.010352
 >> iter 45000, loss: 0.009703
 >> iter 46000, loss: 0.009125
 >> iter 47000, loss: 0.008612
 >> iter 48000, loss: 0.008153
 >> iter 49000, loss: 0.007744
 >> iter 50000, loss: 0.007371
   Number of active neurons: 4
 >> iter 51000, loss: 0.007035
 >> iter 52000, loss: 0.006722
 >> iter 53000, loss: 0.006445
 >> iter 54000, loss: 0.006177
 >> iter 55000, loss: 0.005947
 >> iter 56000, loss: 0.005715
 >> iter 57000, loss: 0.005518
 >> iter 58000, loss: 0.005317
 >> iter 59000, loss: 0.005148
 >> iter 60000, loss: 0.004970
   Number of active neurons: 4
 >> iter 61000, loss: 0.004825
 >> iter 62000, loss: 0.004665
 >> iter 63000, loss: 0.004537
 >> iter 64000, loss: 0.004395
 >> iter 65000, loss: 0.004282
 >> iter 66000, loss: 0.004155
 >> iter 67000, loss: 0.004055
 >> iter 68000, loss: 0.003939
 >> iter 69000, loss: 0.003851
 >> iter 70000, loss: 0.003744
   Number of active neurons: 4
 >> iter 71000, loss: 0.003665
 >> iter 72000, loss: 0.003568
 >> iter 73000, loss: 0.003496
 >> iter 74000, loss: 0.003407
 >> iter 75000, loss: 0.003341
 >> iter 76000, loss: 0.003259
 >> iter 77000, loss: 0.003200
 >> iter 78000, loss: 0.003125
 >> iter 79000, loss: 0.003070
 >> iter 80000, loss: 0.003000
   Number of active neurons: 4
 >> iter 81000, loss: 0.002950
 >> iter 82000, loss: 0.002886
 >> iter 83000, loss: 0.002839
 >> iter 84000, loss: 0.002778
 >> iter 85000, loss: 0.002736
 >> iter 86000, loss: 0.002681
 >> iter 87000, loss: 0.002640
 >> iter 88000, loss: 0.002588
 >> iter 89000, loss: 0.002550
 >> iter 90000, loss: 0.002502
   Number of active neurons: 4
 >> iter 91000, loss: 0.002466
 >> iter 92000, loss: 0.002421
 >> iter 93000, loss: 0.002388
 >> iter 94000, loss: 0.002345
 >> iter 95000, loss: 0.002315
 >> iter 96000, loss: 0.002274
 >> iter 97000, loss: 0.002245
 >> iter 98000, loss: 0.002207
 >> iter 99000, loss: 0.002179
 >> iter 100000, loss: 0.002144
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.633632
 >> iter 2000, loss: 15.084474
 >> iter 3000, loss: 13.741106
 >> iter 4000, loss: 13.247444
 >> iter 5000, loss: 13.048433
 >> iter 6000, loss: 12.981465
 >> iter 7000, loss: 12.943779
 >> iter 8000, loss: 12.940090
 >> iter 9000, loss: 12.926496
 >> iter 10000, loss: 12.934346
   Number of active neurons: 4
 >> iter 11000, loss: 12.922736
 >> iter 12000, loss: 12.929817
 >> iter 13000, loss: 12.919218
 >> iter 14000, loss: 12.923953
 >> iter 15000, loss: 12.670394
 >> iter 16000, loss: 12.078092
 >> iter 17000, loss: 11.078623
 >> iter 18000, loss: 10.381095
 >> iter 19000, loss: 9.768412
 >> iter 20000, loss: 9.717014
   Number of active neurons: 4
 >> iter 21000, loss: 9.345316
 >> iter 22000, loss: 9.482982
 >> iter 23000, loss: 8.996892
 >> iter 24000, loss: 9.165344
 >> iter 25000, loss: 8.890917
 >> iter 26000, loss: 9.075883
 >> iter 27000, loss: 8.828022
 >> iter 28000, loss: 9.107185
 >> iter 29000, loss: 8.726252
 >> iter 30000, loss: 8.946158
   Number of active neurons: 4
 >> iter 31000, loss: 8.540073
 >> iter 32000, loss: 8.683753
 >> iter 33000, loss: 8.540250
 >> iter 34000, loss: 8.659210
 >> iter 35000, loss: 8.549145
 >> iter 36000, loss: 8.825099
 >> iter 37000, loss: 8.643774
 >> iter 38000, loss: 8.590672
 >> iter 39000, loss: 8.550529
 >> iter 40000, loss: 8.536674
   Number of active neurons: 4
 >> iter 41000, loss: 8.524725
 >> iter 42000, loss: 8.734291
 >> iter 43000, loss: 8.547363
 >> iter 44000, loss: 8.612332
 >> iter 45000, loss: 8.505147
 >> iter 46000, loss: 8.606476
 >> iter 47000, loss: 8.225525
 >> iter 48000, loss: 8.383707
 >> iter 49000, loss: 8.387247
 >> iter 50000, loss: 8.457649
   Number of active neurons: 4
 >> iter 51000, loss: 8.494474
 >> iter 52000, loss: 8.687853
 >> iter 53000, loss: 8.306958
 >> iter 54000, loss: 8.548704
 >> iter 55000, loss: 8.413856
 >> iter 56000, loss: 8.492175
 >> iter 57000, loss: 8.361026
 >> iter 58000, loss: 8.596623
 >> iter 59000, loss: 8.027360
 >> iter 60000, loss: 8.277996
   Number of active neurons: 4
 >> iter 61000, loss: 8.230836
 >> iter 62000, loss: 8.354727
 >> iter 63000, loss: 8.160870
 >> iter 64000, loss: 8.385346
 >> iter 65000, loss: 8.103472
 >> iter 66000, loss: 8.151278
 >> iter 67000, loss: 7.931494
 >> iter 68000, loss: 8.133176
 >> iter 69000, loss: 7.886615
 >> iter 70000, loss: 8.177933
   Number of active neurons: 4
 >> iter 71000, loss: 7.948772
 >> iter 72000, loss: 8.118272
 >> iter 73000, loss: 8.015605
 >> iter 74000, loss: 8.116464
 >> iter 75000, loss: 7.996727
 >> iter 76000, loss: 8.341724
 >> iter 77000, loss: 8.048119
 >> iter 78000, loss: 8.202834
 >> iter 79000, loss: 8.084275
 >> iter 80000, loss: 8.308556
   Number of active neurons: 4
 >> iter 81000, loss: 8.117566
 >> iter 82000, loss: 8.036354
 >> iter 83000, loss: 7.912240
 >> iter 84000, loss: 8.062064
 >> iter 85000, loss: 7.749515
 >> iter 86000, loss: 8.061523
 >> iter 87000, loss: 7.796779
 >> iter 88000, loss: 8.104474
 >> iter 89000, loss: 7.802199
 >> iter 90000, loss: 7.954547
   Number of active neurons: 4
 >> iter 91000, loss: 7.813955
 >> iter 92000, loss: 7.826777
 >> iter 93000, loss: 7.473354
 >> iter 94000, loss: 7.702850
 >> iter 95000, loss: 7.102749
 >> iter 96000, loss: 7.428068
 >> iter 97000, loss: 7.276844
 >> iter 98000, loss: 7.422094
 >> iter 99000, loss: 6.970214
 >> iter 100000, loss: 7.255058
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 8.35783284334
   - Test - Long: 30.9684515774
   - Test - Big: 8.58991410086
   - Test - A: 0.0133324445037
   - Test - B: 10.6726218252
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.636293
 >> iter 2000, loss: 15.071904
 >> iter 3000, loss: 13.724937
 >> iter 4000, loss: 13.232113
 >> iter 5000, loss: 13.035915
 >> iter 6000, loss: 12.969791
 >> iter 7000, loss: 12.934203
 >> iter 8000, loss: 12.929741
 >> iter 9000, loss: 12.917089
 >> iter 10000, loss: 12.923074
   Number of active neurons: 3
 >> iter 11000, loss: 12.912125
 >> iter 12000, loss: 12.884316
 >> iter 13000, loss: 12.457573
 >> iter 14000, loss: 11.879628
 >> iter 15000, loss: 10.900941
 >> iter 16000, loss: 5.666824
 >> iter 17000, loss: 2.263641
 >> iter 18000, loss: 0.884284
 >> iter 19000, loss: 0.405888
 >> iter 20000, loss: 0.178548
   Number of active neurons: 4
 >> iter 21000, loss: 0.157302
 >> iter 22000, loss: 0.075778
 >> iter 23000, loss: 0.042513
 >> iter 24000, loss: 0.028727
 >> iter 25000, loss: 0.021835
 >> iter 26000, loss: 0.018143
 >> iter 27000, loss: 0.021297
 >> iter 28000, loss: 0.016445
 >> iter 29000, loss: 0.013738
 >> iter 30000, loss: 0.012226
   Number of active neurons: 4
 >> iter 31000, loss: 0.011016
 >> iter 32000, loss: 0.010220
 >> iter 33000, loss: 0.009436
 >> iter 34000, loss: 0.008893
 >> iter 35000, loss: 0.008305
 >> iter 36000, loss: 0.007898
 >> iter 37000, loss: 0.007429
 >> iter 38000, loss: 0.007114
 >> iter 39000, loss: 0.006729
 >> iter 40000, loss: 0.006478
   Number of active neurons: 4
 >> iter 41000, loss: 0.006153
 >> iter 42000, loss: 0.005945
 >> iter 43000, loss: 0.005669
 >> iter 44000, loss: 0.005496
 >> iter 45000, loss: 0.005258
 >> iter 46000, loss: 0.005113
 >> iter 47000, loss: 0.004902
 >> iter 48000, loss: 0.004777
 >> iter 49000, loss: 0.004592
 >> iter 50000, loss: 0.004486
   Number of active neurons: 4
 >> iter 51000, loss: 0.004318
 >> iter 52000, loss: 0.004226
 >> iter 53000, loss: 0.004075
 >> iter 54000, loss: 0.003996
 >> iter 55000, loss: 0.003858
 >> iter 56000, loss: 0.003789
 >> iter 57000, loss: 0.003664
 >> iter 58000, loss: 0.003603
 >> iter 59000, loss: 0.003490
 >> iter 60000, loss: 0.003434
   Number of active neurons: 4
 >> iter 61000, loss: 0.003330
 >> iter 62000, loss: 0.003281
 >> iter 63000, loss: 0.003184
 >> iter 64000, loss: 0.003140
 >> iter 65000, loss: 0.003052
 >> iter 66000, loss: 0.003010
 >> iter 67000, loss: 0.002931
 >> iter 68000, loss: 0.002892
 >> iter 69000, loss: 0.002819
 >> iter 70000, loss: 0.002782
   Number of active neurons: 4
 >> iter 71000, loss: 0.002714
 >> iter 72000, loss: 0.002681
 >> iter 73000, loss: 0.002616
 >> iter 74000, loss: 0.002588
 >> iter 75000, loss: 0.002526
 >> iter 76000, loss: 0.002501
 >> iter 77000, loss: 0.002443
 >> iter 78000, loss: 0.002419
 >> iter 79000, loss: 0.002364
 >> iter 80000, loss: 0.002343
   Number of active neurons: 4
 >> iter 81000, loss: 0.002291
 >> iter 82000, loss: 0.002270
 >> iter 83000, loss: 0.002221
 >> iter 84000, loss: 0.002203
 >> iter 85000, loss: 0.002155
 >> iter 86000, loss: 0.002139
 >> iter 87000, loss: 0.002093
 >> iter 88000, loss: 0.002079
 >> iter 89000, loss: 0.002035
 >> iter 90000, loss: 0.002022
   Number of active neurons: 4
 >> iter 91000, loss: 0.001980
 >> iter 92000, loss: 0.001968
 >> iter 93000, loss: 0.001929
 >> iter 94000, loss: 0.001917
 >> iter 95000, loss: 0.001879
 >> iter 96000, loss: 0.001869
 >> iter 97000, loss: 0.001833
 >> iter 98000, loss: 0.001823
 >> iter 99000, loss: 0.001789
 >> iter 100000, loss: 0.001779
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0119998800012
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.660041
 >> iter 2000, loss: 15.084032
 >> iter 3000, loss: 13.738680
 >> iter 4000, loss: 13.243505
 >> iter 5000, loss: 13.047901
 >> iter 6000, loss: 12.979629
 >> iter 7000, loss: 12.944931
 >> iter 8000, loss: 12.939479
 >> iter 9000, loss: 12.927854
 >> iter 10000, loss: 12.934101
   Number of active neurons: 4
 >> iter 11000, loss: 12.923945
 >> iter 12000, loss: 12.930099
 >> iter 13000, loss: 12.920503
 >> iter 14000, loss: 12.928245
 >> iter 15000, loss: 12.921096
 >> iter 16000, loss: 12.910699
 >> iter 17000, loss: 12.631012
 >> iter 18000, loss: 11.650960
 >> iter 19000, loss: 10.858207
 >> iter 20000, loss: 10.547489
   Number of active neurons: 4
 >> iter 21000, loss: 10.300412
 >> iter 22000, loss: 10.252210
 >> iter 23000, loss: 10.130698
 >> iter 24000, loss: 10.168648
 >> iter 25000, loss: 10.076771
 >> iter 26000, loss: 10.103955
 >> iter 27000, loss: 10.034106
 >> iter 28000, loss: 10.079912
 >> iter 29000, loss: 10.010417
 >> iter 30000, loss: 10.047886
   Number of active neurons: 4
 >> iter 31000, loss: 9.985540
 >> iter 32000, loss: 10.024757
 >> iter 33000, loss: 9.974044
 >> iter 34000, loss: 10.031671
 >> iter 35000, loss: 9.972346
 >> iter 36000, loss: 10.019909
 >> iter 37000, loss: 9.959937
 >> iter 38000, loss: 10.011654
 >> iter 39000, loss: 9.951322
 >> iter 40000, loss: 9.996166
   Number of active neurons: 4
 >> iter 41000, loss: 9.942289
 >> iter 42000, loss: 10.000571
 >> iter 43000, loss: 9.942173
 >> iter 44000, loss: 9.996457
 >> iter 45000, loss: 9.935925
 >> iter 46000, loss: 9.994498
 >> iter 47000, loss: 9.936501
 >> iter 48000, loss: 9.993492
 >> iter 49000, loss: 9.944217
 >> iter 50000, loss: 9.998802
   Number of active neurons: 4
 >> iter 51000, loss: 9.939320
 >> iter 52000, loss: 9.993192
 >> iter 53000, loss: 9.927198
 >> iter 54000, loss: 9.990302
 >> iter 55000, loss: 9.926471
 >> iter 56000, loss: 9.990220
 >> iter 57000, loss: 9.921115
 >> iter 58000, loss: 9.988091
 >> iter 59000, loss: 9.917553
 >> iter 60000, loss: 9.982716
   Number of active neurons: 4
 >> iter 61000, loss: 9.915930
 >> iter 62000, loss: 9.984380
 >> iter 63000, loss: 9.923376
 >> iter 64000, loss: 9.984774
 >> iter 65000, loss: 9.932479
 >> iter 66000, loss: 10.006254
 >> iter 67000, loss: 9.924519
 >> iter 68000, loss: 9.987792
 >> iter 69000, loss: 9.928406
 >> iter 70000, loss: 9.979818
   Number of active neurons: 4
 >> iter 71000, loss: 9.917740
 >> iter 72000, loss: 9.982267
 >> iter 73000, loss: 9.919721
 >> iter 74000, loss: 9.983610
 >> iter 75000, loss: 9.925251
 >> iter 76000, loss: 9.980637
 >> iter 77000, loss: 9.925985
 >> iter 78000, loss: 9.981556
 >> iter 79000, loss: 9.911372
 >> iter 80000, loss: 9.975914
   Number of active neurons: 4
 >> iter 81000, loss: 9.926163
 >> iter 82000, loss: 9.979184
 >> iter 83000, loss: 9.916467
 >> iter 84000, loss: 9.984863
 >> iter 85000, loss: 9.917860
 >> iter 86000, loss: 9.988551
 >> iter 87000, loss: 9.921186
 >> iter 88000, loss: 9.985920
 >> iter 89000, loss: 9.924053
 >> iter 90000, loss: 9.982976
   Number of active neurons: 4
 >> iter 91000, loss: 9.929454
 >> iter 92000, loss: 9.989265
 >> iter 93000, loss: 9.922450
 >> iter 94000, loss: 9.980001
 >> iter 95000, loss: 9.965243
 >> iter 96000, loss: 9.993224
 >> iter 97000, loss: 9.929621
 >> iter 98000, loss: 9.980863
 >> iter 99000, loss: 9.921388
 >> iter 100000, loss: 9.968708
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 21.0735785284
   - Test - Long: 31.7634118294
   - Test - Big: 21.2587874121
   - Test - A: 32.5511632558
   - Test - B: 32.5911605893
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.630022
 >> iter 2000, loss: 15.075881
 >> iter 3000, loss: 13.730177
 >> iter 4000, loss: 13.235021
 >> iter 5000, loss: 13.037745
 >> iter 6000, loss: 12.968951
 >> iter 7000, loss: 12.933182
 >> iter 8000, loss: 12.880638
 >> iter 9000, loss: 12.337483
 >> iter 10000, loss: 11.571861
   Number of active neurons: 4
 >> iter 11000, loss: 8.553937
 >> iter 12000, loss: 3.268350
 >> iter 13000, loss: 1.361287
 >> iter 14000, loss: 0.531871
 >> iter 15000, loss: 0.494265
 >> iter 16000, loss: 0.206074
 >> iter 17000, loss: 0.182106
 >> iter 18000, loss: 0.083227
 >> iter 19000, loss: 0.282354
 >> iter 20000, loss: 0.120200
   Number of active neurons: 4
 >> iter 21000, loss: 0.057314
 >> iter 22000, loss: 0.032287
 >> iter 23000, loss: 0.021949
 >> iter 24000, loss: 0.017003
 >> iter 25000, loss: 0.014447
 >> iter 26000, loss: 0.012750
 >> iter 27000, loss: 0.011591
 >> iter 28000, loss: 0.010612
 >> iter 29000, loss: 0.009865
 >> iter 30000, loss: 0.009161
   Number of active neurons: 4
 >> iter 31000, loss: 0.008611
 >> iter 32000, loss: 0.008077
 >> iter 33000, loss: 0.007645
 >> iter 34000, loss: 0.007218
 >> iter 35000, loss: 0.006876
 >> iter 36000, loss: 0.006521
 >> iter 37000, loss: 0.006246
 >> iter 38000, loss: 0.005945
 >> iter 39000, loss: 0.005718
 >> iter 40000, loss: 0.005462
   Number of active neurons: 4
 >> iter 41000, loss: 0.005274
 >> iter 42000, loss: 0.005050
 >> iter 43000, loss: 0.004888
 >> iter 44000, loss: 0.004695
 >> iter 45000, loss: 0.004556
 >> iter 46000, loss: 0.004384
 >> iter 47000, loss: 0.004264
 >> iter 48000, loss: 0.004113
 >> iter 49000, loss: 0.004006
 >> iter 50000, loss: 0.003873
   Number of active neurons: 4
 >> iter 51000, loss: 0.003776
 >> iter 52000, loss: 0.003657
 >> iter 53000, loss: 0.003571
 >> iter 54000, loss: 0.003464
 >> iter 55000, loss: 0.003389
 >> iter 56000, loss: 0.003290
 >> iter 57000, loss: 0.003222
 >> iter 58000, loss: 0.003132
 >> iter 59000, loss: 0.003070
 >> iter 60000, loss: 0.002988
   Number of active neurons: 4
 >> iter 61000, loss: 0.002934
 >> iter 62000, loss: 0.002858
 >> iter 63000, loss: 0.002807
 >> iter 64000, loss: 0.002737
 >> iter 65000, loss: 0.002691
 >> iter 66000, loss: 0.002625
 >> iter 67000, loss: 0.002583
 >> iter 68000, loss: 0.002522
 >> iter 69000, loss: 0.002484
 >> iter 70000, loss: 0.002427
   Number of active neurons: 4
 >> iter 71000, loss: 0.002392
 >> iter 72000, loss: 0.002339
 >> iter 73000, loss: 0.002306
 >> iter 74000, loss: 0.002257
 >> iter 75000, loss: 0.002227
 >> iter 76000, loss: 0.002181
 >> iter 77000, loss: 0.002153
 >> iter 78000, loss: 0.002109
 >> iter 79000, loss: 0.002082
 >> iter 80000, loss: 0.002041
   Number of active neurons: 4
 >> iter 81000, loss: 0.002017
 >> iter 82000, loss: 0.001978
 >> iter 83000, loss: 0.001955
 >> iter 84000, loss: 0.001919
 >> iter 85000, loss: 0.001897
 >> iter 86000, loss: 0.001863
 >> iter 87000, loss: 0.001842
 >> iter 88000, loss: 0.001810
 >> iter 89000, loss: 0.001790
 >> iter 90000, loss: 0.001760
   Number of active neurons: 4
 >> iter 91000, loss: 0.001742
 >> iter 92000, loss: 0.001712
 >> iter 93000, loss: 0.001695
 >> iter 94000, loss: 0.001667
 >> iter 95000, loss: 0.001651
 >> iter 96000, loss: 0.001625
 >> iter 97000, loss: 0.001610
 >> iter 98000, loss: 0.001584
 >> iter 99000, loss: 0.001570
 >> iter 100000, loss: 0.001545
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 27.131524565
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.633221
 >> iter 2000, loss: 15.053192
 >> iter 3000, loss: 13.709926
 >> iter 4000, loss: 13.220131
 >> iter 5000, loss: 13.026679
 >> iter 6000, loss: 12.961945
 >> iter 7000, loss: 12.927944
 >> iter 8000, loss: 12.923535
 >> iter 9000, loss: 12.909470
 >> iter 10000, loss: 12.597673
   Number of active neurons: 4
 >> iter 11000, loss: 11.769167
 >> iter 12000, loss: 11.023334
 >> iter 13000, loss: 10.640138
 >> iter 14000, loss: 10.530017
 >> iter 15000, loss: 9.973553
 >> iter 16000, loss: 9.933148
 >> iter 17000, loss: 9.642617
 >> iter 18000, loss: 9.608992
 >> iter 19000, loss: 9.498611
 >> iter 20000, loss: 9.472978
   Number of active neurons: 4
 >> iter 21000, loss: 9.403425
 >> iter 22000, loss: 9.582342
 >> iter 23000, loss: 9.451651
 >> iter 24000, loss: 9.476415
 >> iter 25000, loss: 9.365938
 >> iter 26000, loss: 9.489751
 >> iter 27000, loss: 9.312248
 >> iter 28000, loss: 9.384144
 >> iter 29000, loss: 9.249692
 >> iter 30000, loss: 9.308540
   Number of active neurons: 4
 >> iter 31000, loss: 9.249478
 >> iter 32000, loss: 9.406762
 >> iter 33000, loss: 9.224140
 >> iter 34000, loss: 9.330755
 >> iter 35000, loss: 9.237440
 >> iter 36000, loss: 9.358174
 >> iter 37000, loss: 9.214665
 >> iter 38000, loss: 9.343239
 >> iter 39000, loss: 9.164705
 >> iter 40000, loss: 9.190514
   Number of active neurons: 4
 >> iter 41000, loss: 9.165181
 >> iter 42000, loss: 9.297613
 >> iter 43000, loss: 9.210597
 >> iter 44000, loss: 9.284947
 >> iter 45000, loss: 9.136254
 >> iter 46000, loss: 9.299244
 >> iter 47000, loss: 9.254023
 >> iter 48000, loss: 9.367362
 >> iter 49000, loss: 9.099989
 >> iter 50000, loss: 9.211823
   Number of active neurons: 4
 >> iter 51000, loss: 9.171945
 >> iter 52000, loss: 9.369282
 >> iter 53000, loss: 9.274873
 >> iter 54000, loss: 9.394676
 >> iter 55000, loss: 9.280887
 >> iter 56000, loss: 9.463634
 >> iter 57000, loss: 9.292508
 >> iter 58000, loss: 9.312461
 >> iter 59000, loss: 9.171532
 >> iter 60000, loss: 9.308890
   Number of active neurons: 4
 >> iter 61000, loss: 9.124333
 >> iter 62000, loss: 9.140161
 >> iter 63000, loss: 9.092385
 >> iter 64000, loss: 9.194045
 >> iter 65000, loss: 9.091066
 >> iter 66000, loss: 9.368111
 >> iter 67000, loss: 9.322844
 >> iter 68000, loss: 9.379390
 >> iter 69000, loss: 9.142010
 >> iter 70000, loss: 9.311460
   Number of active neurons: 4
 >> iter 71000, loss: 9.215741
 >> iter 72000, loss: 9.295908
 >> iter 73000, loss: 9.125847
 >> iter 74000, loss: 9.221713
 >> iter 75000, loss: 9.150746
 >> iter 76000, loss: 9.188595
 >> iter 77000, loss: 9.226124
 >> iter 78000, loss: 9.346980
 >> iter 79000, loss: 9.971647
 >> iter 80000, loss: 10.882865
   Number of active neurons: 4
 >> iter 81000, loss: 10.869552
 >> iter 82000, loss: 11.084748
 >> iter 83000, loss: 10.813001
 >> iter 84000, loss: 10.977750
 >> iter 85000, loss: 10.979516
 >> iter 86000, loss: 9.906971
 >> iter 87000, loss: 9.437314
 >> iter 88000, loss: 9.508298
 >> iter 89000, loss: 9.331211
 >> iter 90000, loss: 9.400357
   Number of active neurons: 4
 >> iter 91000, loss: 9.168317
 >> iter 92000, loss: 9.301349
 >> iter 93000, loss: 9.168629
 >> iter 94000, loss: 9.362476
 >> iter 95000, loss: 9.199005
 >> iter 96000, loss: 9.405384
 >> iter 97000, loss: 9.246497
 >> iter 98000, loss: 9.362191
 >> iter 99000, loss: 9.219671
 >> iter 100000, loss: 9.381464
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 12.9457410852
   - Test - Long: 31.3334333283
   - Test - Big: 12.9568704313
   - Test - A: 8.95273648423
   - Test - B: 31.6178921405
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.692970
 >> iter 2000, loss: 15.091475
 >> iter 3000, loss: 13.726479
 >> iter 4000, loss: 13.226502
 >> iter 5000, loss: 13.028462
 >> iter 6000, loss: 12.962472
 >> iter 7000, loss: 12.927363
 >> iter 8000, loss: 12.924322
 >> iter 9000, loss: 12.912178
 >> iter 10000, loss: 12.920187
   Number of active neurons: 3
 >> iter 11000, loss: 12.909280
 >> iter 12000, loss: 12.915740
 >> iter 13000, loss: 12.886676
 >> iter 14000, loss: 10.354567
 >> iter 15000, loss: 3.965831
 >> iter 16000, loss: 1.519392
 >> iter 17000, loss: 0.595399
 >> iter 18000, loss: 0.246506
 >> iter 19000, loss: 0.111705
 >> iter 20000, loss: 0.058864
   Number of active neurons: 4
 >> iter 21000, loss: 0.036414
 >> iter 22000, loss: 0.026445
 >> iter 23000, loss: 0.021058
 >> iter 24000, loss: 0.018063
 >> iter 25000, loss: 0.015835
 >> iter 26000, loss: 0.014350
 >> iter 27000, loss: 0.013008
 >> iter 28000, loss: 0.012053
 >> iter 29000, loss: 0.011108
 >> iter 30000, loss: 0.010415
   Number of active neurons: 4
 >> iter 31000, loss: 0.009702
 >> iter 32000, loss: 0.009174
 >> iter 33000, loss: 0.008614
 >> iter 34000, loss: 0.008199
 >> iter 35000, loss: 0.007746
 >> iter 36000, loss: 0.007412
 >> iter 37000, loss: 0.007038
 >> iter 38000, loss: 0.006764
 >> iter 39000, loss: 0.006449
 >> iter 40000, loss: 0.006221
   Number of active neurons: 4
 >> iter 41000, loss: 0.005952
 >> iter 42000, loss: 0.005757
 >> iter 43000, loss: 0.005525
 >> iter 44000, loss: 0.005358
 >> iter 45000, loss: 0.005156
 >> iter 46000, loss: 0.005012
 >> iter 47000, loss: 0.004833
 >> iter 48000, loss: 0.004706
 >> iter 49000, loss: 0.004548
 >> iter 50000, loss: 0.004438
   Number of active neurons: 4
 >> iter 51000, loss: 0.004294
 >> iter 52000, loss: 0.004197
 >> iter 53000, loss: 0.004066
 >> iter 54000, loss: 0.003981
 >> iter 55000, loss: 0.003862
 >> iter 56000, loss: 0.003786
 >> iter 57000, loss: 0.003678
 >> iter 58000, loss: 0.003609
 >> iter 59000, loss: 0.003511
 >> iter 60000, loss: 0.003448
   Number of active neurons: 4
 >> iter 61000, loss: 0.003357
 >> iter 62000, loss: 0.003301
 >> iter 63000, loss: 0.003216
 >> iter 64000, loss: 0.003166
 >> iter 65000, loss: 0.003088
 >> iter 66000, loss: 0.003042
 >> iter 67000, loss: 0.002969
 >> iter 68000, loss: 0.002926
 >> iter 69000, loss: 0.002859
 >> iter 70000, loss: 0.002819
   Number of active neurons: 4
 >> iter 71000, loss: 0.002756
 >> iter 72000, loss: 0.002720
 >> iter 73000, loss: 0.002660
 >> iter 74000, loss: 0.002627
 >> iter 75000, loss: 0.002572
 >> iter 76000, loss: 0.002541
 >> iter 77000, loss: 0.002489
 >> iter 78000, loss: 0.002461
 >> iter 79000, loss: 0.002412
 >> iter 80000, loss: 0.002385
   Number of active neurons: 4
 >> iter 81000, loss: 0.002338
 >> iter 82000, loss: 0.002313
 >> iter 83000, loss: 0.002269
 >> iter 84000, loss: 0.002246
 >> iter 85000, loss: 0.002204
 >> iter 86000, loss: 0.002182
 >> iter 87000, loss: 0.002143
 >> iter 88000, loss: 0.002122
 >> iter 89000, loss: 0.002085
 >> iter 90000, loss: 0.002065
   Number of active neurons: 4
 >> iter 91000, loss: 0.002030
 >> iter 92000, loss: 0.002012
 >> iter 93000, loss: 0.001978
 >> iter 94000, loss: 0.001961
 >> iter 95000, loss: 0.001928
 >> iter 96000, loss: 0.001912
 >> iter 97000, loss: 0.001882
 >> iter 98000, loss: 0.001866
 >> iter 99000, loss: 0.001837
 >> iter 100000, loss: 0.001822
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.632072
 >> iter 2000, loss: 15.077393
 >> iter 3000, loss: 13.739254
 >> iter 4000, loss: 13.250171
 >> iter 5000, loss: 13.058033
 >> iter 6000, loss: 12.993357
 >> iter 7000, loss: 12.959197
 >> iter 8000, loss: 12.955548
 >> iter 9000, loss: 12.942783
 >> iter 10000, loss: 12.949499
   Number of active neurons: 4
 >> iter 11000, loss: 12.937196
 >> iter 12000, loss: 12.942738
 >> iter 13000, loss: 12.931357
 >> iter 14000, loss: 12.938638
 >> iter 15000, loss: 12.930061
 >> iter 16000, loss: 12.934792
 >> iter 17000, loss: 12.927909
 >> iter 18000, loss: 12.924168
 >> iter 19000, loss: 12.803655
 >> iter 20000, loss: 11.774970
   Number of active neurons: 4
 >> iter 21000, loss: 11.080562
 >> iter 22000, loss: 10.920894
 >> iter 23000, loss: 4.781098
 >> iter 24000, loss: 1.855678
 >> iter 25000, loss: 0.752952
 >> iter 26000, loss: 0.330484
 >> iter 27000, loss: 0.210119
 >> iter 28000, loss: 0.098439
 >> iter 29000, loss: 0.123463
 >> iter 30000, loss: 0.059561
   Number of active neurons: 4
 >> iter 31000, loss: 0.033744
 >> iter 32000, loss: 0.022855
 >> iter 33000, loss: 0.017554
 >> iter 34000, loss: 0.014792
 >> iter 35000, loss: 0.012913
 >> iter 36000, loss: 0.011695
 >> iter 37000, loss: 0.010621
 >> iter 38000, loss: 0.009865
 >> iter 39000, loss: 0.009106
 >> iter 40000, loss: 0.008567
   Number of active neurons: 4
 >> iter 41000, loss: 0.007988
 >> iter 42000, loss: 0.007580
 >> iter 43000, loss: 0.007121
 >> iter 44000, loss: 0.006803
 >> iter 45000, loss: 0.006426
 >> iter 46000, loss: 0.006175
 >> iter 47000, loss: 0.005855
 >> iter 48000, loss: 0.005652
 >> iter 49000, loss: 0.005378
 >> iter 50000, loss: 0.005213
   Number of active neurons: 4
 >> iter 51000, loss: 0.004973
 >> iter 52000, loss: 0.004835
 >> iter 53000, loss: 0.004626
 >> iter 54000, loss: 0.004507
 >> iter 55000, loss: 0.004322
 >> iter 56000, loss: 0.004221
 >> iter 57000, loss: 0.004057
 >> iter 58000, loss: 0.003967
 >> iter 59000, loss: 0.003821
 >> iter 60000, loss: 0.003741
   Number of active neurons: 4
 >> iter 61000, loss: 0.003610
 >> iter 62000, loss: 0.003538
 >> iter 63000, loss: 0.003420
 >> iter 64000, loss: 0.003355
 >> iter 65000, loss: 0.003250
 >> iter 66000, loss: 0.003190
 >> iter 67000, loss: 0.003096
 >> iter 68000, loss: 0.003041
 >> iter 69000, loss: 0.002957
 >> iter 70000, loss: 0.002905
   Number of active neurons: 4
 >> iter 71000, loss: 0.002829
 >> iter 72000, loss: 0.002781
 >> iter 73000, loss: 0.002710
 >> iter 74000, loss: 0.002668
 >> iter 75000, loss: 0.002601
 >> iter 76000, loss: 0.002563
 >> iter 77000, loss: 0.002500
 >> iter 78000, loss: 0.002466
 >> iter 79000, loss: 0.002407
 >> iter 80000, loss: 0.002377
   Number of active neurons: 4
 >> iter 81000, loss: 0.002321
 >> iter 82000, loss: 0.002293
 >> iter 83000, loss: 0.002241
 >> iter 84000, loss: 0.002216
 >> iter 85000, loss: 0.002167
 >> iter 86000, loss: 0.002144
 >> iter 87000, loss: 0.002097
 >> iter 88000, loss: 0.002077
 >> iter 89000, loss: 0.002032
 >> iter 90000, loss: 0.002014
   Number of active neurons: 4
 >> iter 91000, loss: 0.001971
 >> iter 92000, loss: 0.001954
 >> iter 93000, loss: 0.001913
 >> iter 94000, loss: 0.001898
 >> iter 95000, loss: 0.001859
 >> iter 96000, loss: 0.001845
 >> iter 97000, loss: 0.001808
 >> iter 98000, loss: 0.001795
 >> iter 99000, loss: 0.001759
 >> iter 100000, loss: 0.001748
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.628292
 >> iter 2000, loss: 15.071534
 >> iter 3000, loss: 13.731456
 >> iter 4000, loss: 13.238776
 >> iter 5000, loss: 13.043152
 >> iter 6000, loss: 12.975919
 >> iter 7000, loss: 12.939787
 >> iter 8000, loss: 12.934847
 >> iter 9000, loss: 12.920800
 >> iter 10000, loss: 12.927594
   Number of active neurons: 3
 >> iter 11000, loss: 12.914547
 >> iter 12000, loss: 12.921969
 >> iter 13000, loss: 12.909265
 >> iter 14000, loss: 12.919471
 >> iter 15000, loss: 12.908887
 >> iter 16000, loss: 12.917139
 >> iter 17000, loss: 12.869413
 >> iter 18000, loss: 12.244504
 >> iter 19000, loss: 11.098810
 >> iter 20000, loss: 9.985010
   Number of active neurons: 4
 >> iter 21000, loss: 9.393087
 >> iter 22000, loss: 9.296676
 >> iter 23000, loss: 8.538036
 >> iter 24000, loss: 8.338593
 >> iter 25000, loss: 7.500645
 >> iter 26000, loss: 5.107169
 >> iter 27000, loss: 2.081277
 >> iter 28000, loss: 0.855625
 >> iter 29000, loss: 0.372613
 >> iter 30000, loss: 0.180087
   Number of active neurons: 4
 >> iter 31000, loss: 0.100088
 >> iter 32000, loss: 0.064971
 >> iter 33000, loss: 0.047755
 >> iter 34000, loss: 0.038442
 >> iter 35000, loss: 0.032539
 >> iter 36000, loss: 0.028549
 >> iter 37000, loss: 0.025468
 >> iter 38000, loss: 0.023121
 >> iter 39000, loss: 0.021130
 >> iter 40000, loss: 0.019520
   Number of active neurons: 4
 >> iter 41000, loss: 0.018100
 >> iter 42000, loss: 0.016907
 >> iter 43000, loss: 0.015838
 >> iter 44000, loss: 0.014923
 >> iter 45000, loss: 0.014082
 >> iter 46000, loss: 0.013359
 >> iter 47000, loss: 0.012680
 >> iter 48000, loss: 0.012094
 >> iter 49000, loss: 0.011534
 >> iter 50000, loss: 0.011051
   Number of active neurons: 4
 >> iter 51000, loss: 0.010577
 >> iter 52000, loss: 0.010168
 >> iter 53000, loss: 0.009761
 >> iter 54000, loss: 0.009418
 >> iter 55000, loss: 0.009069
 >> iter 56000, loss: 0.008772
 >> iter 57000, loss: 0.008466
 >> iter 58000, loss: 0.008209
 >> iter 59000, loss: 0.007941
 >> iter 60000, loss: 0.007712
   Number of active neurons: 4
 >> iter 61000, loss: 0.007477
 >> iter 62000, loss: 0.007276
 >> iter 63000, loss: 0.007063
 >> iter 64000, loss: 0.006882
 >> iter 65000, loss: 0.006691
 >> iter 66000, loss: 0.006528
 >> iter 67000, loss: 0.006359
 >> iter 68000, loss: 0.006210
 >> iter 69000, loss: 0.006058
 >> iter 70000, loss: 0.005920
   Number of active neurons: 4
 >> iter 71000, loss: 0.005784
 >> iter 72000, loss: 0.005653
 >> iter 73000, loss: 0.005533
 >> iter 74000, loss: 0.005414
 >> iter 75000, loss: 0.005302
 >> iter 76000, loss: 0.005193
 >> iter 77000, loss: 0.005091
 >> iter 78000, loss: 0.004988
 >> iter 79000, loss: 0.004894
 >> iter 80000, loss: 0.004798
   Number of active neurons: 4
 >> iter 81000, loss: 0.004713
 >> iter 82000, loss: 0.004623
 >> iter 83000, loss: 0.004544
 >> iter 84000, loss: 0.004461
 >> iter 85000, loss: 0.004388
 >> iter 86000, loss: 0.004311
 >> iter 87000, loss: 0.004242
 >> iter 88000, loss: 0.004169
 >> iter 89000, loss: 0.004103
 >> iter 90000, loss: 0.004036
   Number of active neurons: 4
 >> iter 91000, loss: 0.003975
 >> iter 92000, loss: 0.003912
 >> iter 93000, loss: 0.003855
 >> iter 94000, loss: 0.003795
 >> iter 95000, loss: 0.003741
 >> iter 96000, loss: 0.003686
 >> iter 97000, loss: 0.003634
 >> iter 98000, loss: 0.003582
 >> iter 99000, loss: 0.003532
 >> iter 100000, loss: 0.003484
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.622969
 >> iter 2000, loss: 15.073861
 >> iter 3000, loss: 13.730877
 >> iter 4000, loss: 13.237524
 >> iter 5000, loss: 13.041018
 >> iter 6000, loss: 12.974573
 >> iter 7000, loss: 12.939234
 >> iter 8000, loss: 12.934140
 >> iter 9000, loss: 12.875472
 >> iter 10000, loss: 12.270207
   Number of active neurons: 4
 >> iter 11000, loss: 11.378322
 >> iter 12000, loss: 11.036207
 >> iter 13000, loss: 10.361323
 >> iter 14000, loss: 10.147421
 >> iter 15000, loss: 9.823120
 >> iter 16000, loss: 9.854825
 >> iter 17000, loss: 9.632778
 >> iter 18000, loss: 9.629282
 >> iter 19000, loss: 9.488354
 >> iter 20000, loss: 9.553948
   Number of active neurons: 4
 >> iter 21000, loss: 9.333441
 >> iter 22000, loss: 9.520526
 >> iter 23000, loss: 9.354437
 >> iter 24000, loss: 9.477343
 >> iter 25000, loss: 9.324490
 >> iter 26000, loss: 9.447131
 >> iter 27000, loss: 9.333183
 >> iter 28000, loss: 9.553427
 >> iter 29000, loss: 9.388581
 >> iter 30000, loss: 9.453733
   Number of active neurons: 4
 >> iter 31000, loss: 9.252451
 >> iter 32000, loss: 9.436018
 >> iter 33000, loss: 9.453330
 >> iter 34000, loss: 9.479039
 >> iter 35000, loss: 9.298613
 >> iter 36000, loss: 9.405305
 >> iter 37000, loss: 9.198770
 >> iter 38000, loss: 9.377780
 >> iter 39000, loss: 9.256765
 >> iter 40000, loss: 9.361112
   Number of active neurons: 4
 >> iter 41000, loss: 9.247219
 >> iter 42000, loss: 9.572014
 >> iter 43000, loss: 9.338584
 >> iter 44000, loss: 9.526069
 >> iter 45000, loss: 9.262639
 >> iter 46000, loss: 9.456038
 >> iter 47000, loss: 9.372025
 >> iter 48000, loss: 9.270612
 >> iter 49000, loss: 9.218866
 >> iter 50000, loss: 9.292424
   Number of active neurons: 4
 >> iter 51000, loss: 9.253460
 >> iter 52000, loss: 9.360011
 >> iter 53000, loss: 9.158504
 >> iter 54000, loss: 9.229257
 >> iter 55000, loss: 9.066376
 >> iter 56000, loss: 9.251311
 >> iter 57000, loss: 9.170527
 >> iter 58000, loss: 9.232197
 >> iter 59000, loss: 9.080385
 >> iter 60000, loss: 9.199118
   Number of active neurons: 4
 >> iter 61000, loss: 9.167141
 >> iter 62000, loss: 9.261364
 >> iter 63000, loss: 9.156280
 >> iter 64000, loss: 9.296580
 >> iter 65000, loss: 9.150645
 >> iter 66000, loss: 9.220616
 >> iter 67000, loss: 9.165365
 >> iter 68000, loss: 9.317734
 >> iter 69000, loss: 9.185091
 >> iter 70000, loss: 9.247869
   Number of active neurons: 4
 >> iter 71000, loss: 9.131979
 >> iter 72000, loss: 9.323284
 >> iter 73000, loss: 9.232286
 >> iter 74000, loss: 9.378649
 >> iter 75000, loss: 9.237791
 >> iter 76000, loss: 9.417023
 >> iter 77000, loss: 9.116777
 >> iter 78000, loss: 9.276858
 >> iter 79000, loss: 9.058065
 >> iter 80000, loss: 9.218532
   Number of active neurons: 4
 >> iter 81000, loss: 9.127754
 >> iter 82000, loss: 9.283503
 >> iter 83000, loss: 9.342896
 >> iter 84000, loss: 9.305072
 >> iter 85000, loss: 9.201322
 >> iter 86000, loss: 9.337606
 >> iter 87000, loss: 9.166728
 >> iter 88000, loss: 9.290737
 >> iter 89000, loss: 9.143566
 >> iter 90000, loss: 9.375181
   Number of active neurons: 4
 >> iter 91000, loss: 9.229443
 >> iter 92000, loss: 9.306557
 >> iter 93000, loss: 9.114787
 >> iter 94000, loss: 9.238069
 >> iter 95000, loss: 9.091281
 >> iter 96000, loss: 9.177793
 >> iter 97000, loss: 9.064537
 >> iter 98000, loss: 9.299035
 >> iter 99000, loss: 9.102693
 >> iter 100000, loss: 9.360099
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 13.2137357253
   - Test - Long: 31.8984050797
   - Test - Big: 13.2178678213
   - Test - A: 1.00659956003
   - Test - B: 31.6178921405
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.666457
 >> iter 2000, loss: 15.074610
 >> iter 3000, loss: 13.720297
 >> iter 4000, loss: 13.225498
 >> iter 5000, loss: 13.029399
 >> iter 6000, loss: 12.963632
 >> iter 7000, loss: 12.928737
 >> iter 8000, loss: 12.925188
 >> iter 9000, loss: 12.913262
 >> iter 10000, loss: 12.920417
   Number of active neurons: 3
 >> iter 11000, loss: 12.909953
 >> iter 12000, loss: 12.905220
 >> iter 13000, loss: 12.473448
 >> iter 14000, loss: 8.066693
 >> iter 15000, loss: 3.216923
 >> iter 16000, loss: 1.240573
 >> iter 17000, loss: 0.492907
 >> iter 18000, loss: 0.207242
 >> iter 19000, loss: 0.097138
 >> iter 20000, loss: 0.052741
   Number of active neurons: 4
 >> iter 21000, loss: 0.033520
 >> iter 22000, loss: 0.024709
 >> iter 23000, loss: 0.019947
 >> iter 24000, loss: 0.017187
 >> iter 25000, loss: 0.015149
 >> iter 26000, loss: 0.013743
 >> iter 27000, loss: 0.012498
 >> iter 28000, loss: 0.011586
 >> iter 29000, loss: 0.010694
 >> iter 30000, loss: 0.010036
   Number of active neurons: 4
 >> iter 31000, loss: 0.009355
 >> iter 32000, loss: 0.008854
 >> iter 33000, loss: 0.008317
 >> iter 34000, loss: 0.007923
 >> iter 35000, loss: 0.007487
 >> iter 36000, loss: 0.007171
 >> iter 37000, loss: 0.006807
 >> iter 38000, loss: 0.006550
 >> iter 39000, loss: 0.006242
 >> iter 40000, loss: 0.006030
   Number of active neurons: 4
 >> iter 41000, loss: 0.005764
 >> iter 42000, loss: 0.005583
 >> iter 43000, loss: 0.005354
 >> iter 44000, loss: 0.005199
 >> iter 45000, loss: 0.004999
 >> iter 46000, loss: 0.004867
 >> iter 47000, loss: 0.004687
 >> iter 48000, loss: 0.004571
 >> iter 49000, loss: 0.004413
 >> iter 50000, loss: 0.004312
   Number of active neurons: 4
 >> iter 51000, loss: 0.004167
 >> iter 52000, loss: 0.004079
 >> iter 53000, loss: 0.003947
 >> iter 54000, loss: 0.003870
 >> iter 55000, loss: 0.003750
 >> iter 56000, loss: 0.003681
 >> iter 57000, loss: 0.003572
 >> iter 58000, loss: 0.003510
 >> iter 59000, loss: 0.003410
 >> iter 60000, loss: 0.003354
   Number of active neurons: 4
 >> iter 61000, loss: 0.003262
 >> iter 62000, loss: 0.003211
 >> iter 63000, loss: 0.003125
 >> iter 64000, loss: 0.003079
 >> iter 65000, loss: 0.003001
 >> iter 66000, loss: 0.002958
 >> iter 67000, loss: 0.002887
 >> iter 68000, loss: 0.002846
 >> iter 69000, loss: 0.002780
 >> iter 70000, loss: 0.002741
   Number of active neurons: 4
 >> iter 71000, loss: 0.002681
 >> iter 72000, loss: 0.002646
 >> iter 73000, loss: 0.002588
 >> iter 74000, loss: 0.002557
 >> iter 75000, loss: 0.002502
 >> iter 76000, loss: 0.002473
 >> iter 77000, loss: 0.002421
 >> iter 78000, loss: 0.002395
 >> iter 79000, loss: 0.002346
 >> iter 80000, loss: 0.002322
   Number of active neurons: 4
 >> iter 81000, loss: 0.002275
 >> iter 82000, loss: 0.002252
 >> iter 83000, loss: 0.002207
 >> iter 84000, loss: 0.002187
 >> iter 85000, loss: 0.002144
 >> iter 86000, loss: 0.002125
 >> iter 87000, loss: 0.002084
 >> iter 88000, loss: 0.002067
 >> iter 89000, loss: 0.002028
 >> iter 90000, loss: 0.002012
   Number of active neurons: 4
 >> iter 91000, loss: 0.001974
 >> iter 92000, loss: 0.001959
 >> iter 93000, loss: 0.001924
 >> iter 94000, loss: 0.001909
 >> iter 95000, loss: 0.001876
 >> iter 96000, loss: 0.001862
 >> iter 97000, loss: 0.001831
 >> iter 98000, loss: 0.001817
 >> iter 99000, loss: 0.001787
 >> iter 100000, loss: 0.001774
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0179998200018
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.702926
 >> iter 2000, loss: 15.113637
 >> iter 3000, loss: 13.753205
 >> iter 4000, loss: 13.250818
 >> iter 5000, loss: 13.052016
 >> iter 6000, loss: 12.982991
 >> iter 7000, loss: 12.946969
 >> iter 8000, loss: 12.940892
 >> iter 9000, loss: 12.928032
 >> iter 10000, loss: 12.934038
   Number of active neurons: 3
 >> iter 11000, loss: 12.922573
 >> iter 12000, loss: 12.929620
 >> iter 13000, loss: 12.919135
 >> iter 14000, loss: 12.928576
 >> iter 15000, loss: 12.920684
 >> iter 16000, loss: 12.927742
 >> iter 17000, loss: 12.921413
 >> iter 18000, loss: 12.917196
 >> iter 19000, loss: 12.700794
 >> iter 20000, loss: 11.982645
   Number of active neurons: 4
 >> iter 21000, loss: 11.017532
 >> iter 22000, loss: 10.608745
 >> iter 23000, loss: 10.328028
 >> iter 24000, loss: 10.241559
 >> iter 25000, loss: 10.127610
 >> iter 26000, loss: 10.159072
 >> iter 27000, loss: 10.064217
 >> iter 28000, loss: 10.075504
 >> iter 29000, loss: 10.017586
 >> iter 30000, loss: 10.046797
   Number of active neurons: 4
 >> iter 31000, loss: 9.988527
 >> iter 32000, loss: 10.024745
 >> iter 33000, loss: 9.978143
 >> iter 34000, loss: 10.012353
 >> iter 35000, loss: 9.969642
 >> iter 36000, loss: 10.003965
 >> iter 37000, loss: 9.956007
 >> iter 38000, loss: 9.997653
 >> iter 39000, loss: 9.947005
 >> iter 40000, loss: 9.994697
   Number of active neurons: 4
 >> iter 41000, loss: 9.942487
 >> iter 42000, loss: 9.991879
 >> iter 43000, loss: 9.936578
 >> iter 44000, loss: 9.994025
 >> iter 45000, loss: 9.934816
 >> iter 46000, loss: 9.993749
 >> iter 47000, loss: 9.932149
 >> iter 48000, loss: 9.991237
 >> iter 49000, loss: 9.932479
 >> iter 50000, loss: 9.994273
   Number of active neurons: 4
 >> iter 51000, loss: 9.930843
 >> iter 52000, loss: 9.989820
 >> iter 53000, loss: 9.921520
 >> iter 54000, loss: 9.987648
 >> iter 55000, loss: 9.914441
 >> iter 56000, loss: 9.985463
 >> iter 57000, loss: 9.913132
 >> iter 58000, loss: 9.984594
 >> iter 59000, loss: 9.914649
 >> iter 60000, loss: 9.982588
   Number of active neurons: 4
 >> iter 61000, loss: 9.914308
 >> iter 62000, loss: 9.984994
 >> iter 63000, loss: 9.912760
 >> iter 64000, loss: 9.985773
 >> iter 65000, loss: 9.915061
 >> iter 66000, loss: 9.987063
 >> iter 67000, loss: 9.915131
 >> iter 68000, loss: 9.983636
 >> iter 69000, loss: 9.916773
 >> iter 70000, loss: 9.981234
   Number of active neurons: 4
 >> iter 71000, loss: 9.916159
 >> iter 72000, loss: 9.981278
 >> iter 73000, loss: 9.915393
 >> iter 74000, loss: 9.983083
 >> iter 75000, loss: 9.912594
 >> iter 76000, loss: 9.981831
 >> iter 77000, loss: 9.917845
 >> iter 78000, loss: 9.981347
 >> iter 79000, loss: 9.909039
 >> iter 80000, loss: 9.978242
   Number of active neurons: 4
 >> iter 81000, loss: 9.909345
 >> iter 82000, loss: 9.980874
 >> iter 83000, loss: 9.914617
 >> iter 84000, loss: 9.985859
 >> iter 85000, loss: 9.915794
 >> iter 86000, loss: 9.985719
 >> iter 87000, loss: 9.917473
 >> iter 88000, loss: 9.987363
 >> iter 89000, loss: 9.921706
 >> iter 90000, loss: 9.993649
   Number of active neurons: 4
 >> iter 91000, loss: 9.923010
 >> iter 92000, loss: 9.992517
 >> iter 93000, loss: 9.920836
 >> iter 94000, loss: 9.990425
 >> iter 95000, loss: 9.925137
 >> iter 96000, loss: 9.989558
 >> iter 97000, loss: 9.925297
 >> iter 98000, loss: 9.990502
 >> iter 99000, loss: 9.921872
 >> iter 100000, loss: 9.983700
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 21.0495790084
   - Test - Long: 31.7634118294
   - Test - Big: 21.2487875121
   - Test - A: 32.5511632558
   - Test - B: 32.5911605893
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.631642
 >> iter 2000, loss: 15.082466
 >> iter 3000, loss: 13.735680
 >> iter 4000, loss: 13.238365
 >> iter 5000, loss: 13.036840
 >> iter 6000, loss: 12.969015
 >> iter 7000, loss: 12.931027
 >> iter 8000, loss: 12.927403
 >> iter 9000, loss: 12.913660
 >> iter 10000, loss: 12.921883
   Number of active neurons: 3
 >> iter 11000, loss: 12.909974
 >> iter 12000, loss: 12.917805
 >> iter 13000, loss: 12.906667
 >> iter 14000, loss: 12.915371
 >> iter 15000, loss: 12.904226
 >> iter 16000, loss: 12.486542
 >> iter 17000, loss: 6.716237
 >> iter 18000, loss: 2.558853
 >> iter 19000, loss: 0.985927
 >> iter 20000, loss: 0.393240
   Number of active neurons: 4
 >> iter 21000, loss: 0.167558
 >> iter 22000, loss: 0.080320
 >> iter 23000, loss: 0.044958
 >> iter 24000, loss: 0.029992
 >> iter 25000, loss: 0.022642
 >> iter 26000, loss: 0.018829
 >> iter 27000, loss: 0.016235
 >> iter 28000, loss: 0.014589
 >> iter 29000, loss: 0.013135
 >> iter 30000, loss: 0.012134
   Number of active neurons: 4
 >> iter 31000, loss: 0.011127
 >> iter 32000, loss: 0.010425
 >> iter 33000, loss: 0.009671
 >> iter 34000, loss: 0.009148
 >> iter 35000, loss: 0.008555
 >> iter 36000, loss: 0.008151
 >> iter 37000, loss: 0.007671
 >> iter 38000, loss: 0.007353
 >> iter 39000, loss: 0.006954
 >> iter 40000, loss: 0.006699
   Number of active neurons: 4
 >> iter 41000, loss: 0.006360
 >> iter 42000, loss: 0.006148
 >> iter 43000, loss: 0.005859
 >> iter 44000, loss: 0.005682
 >> iter 45000, loss: 0.005432
 >> iter 46000, loss: 0.005284
 >> iter 47000, loss: 0.005061
 >> iter 48000, loss: 0.004934
 >> iter 49000, loss: 0.004739
 >> iter 50000, loss: 0.004631
   Number of active neurons: 4
 >> iter 51000, loss: 0.004454
 >> iter 52000, loss: 0.004361
 >> iter 53000, loss: 0.004200
 >> iter 54000, loss: 0.004121
 >> iter 55000, loss: 0.003974
 >> iter 56000, loss: 0.003905
 >> iter 57000, loss: 0.003772
 >> iter 58000, loss: 0.003711
 >> iter 59000, loss: 0.003590
 >> iter 60000, loss: 0.003535
   Number of active neurons: 4
 >> iter 61000, loss: 0.003424
 >> iter 62000, loss: 0.003375
 >> iter 63000, loss: 0.003271
 >> iter 64000, loss: 0.003228
 >> iter 65000, loss: 0.003134
 >> iter 66000, loss: 0.003093
 >> iter 67000, loss: 0.003008
 >> iter 68000, loss: 0.002969
 >> iter 69000, loss: 0.002891
 >> iter 70000, loss: 0.002854
   Number of active neurons: 4
 >> iter 71000, loss: 0.002782
 >> iter 72000, loss: 0.002750
 >> iter 73000, loss: 0.002680
 >> iter 74000, loss: 0.002653
 >> iter 75000, loss: 0.002586
 >> iter 76000, loss: 0.002562
 >> iter 77000, loss: 0.002499
 >> iter 78000, loss: 0.002477
 >> iter 79000, loss: 0.002418
 >> iter 80000, loss: 0.002397
   Number of active neurons: 4
 >> iter 81000, loss: 0.002341
 >> iter 82000, loss: 0.002322
 >> iter 83000, loss: 0.002269
 >> iter 84000, loss: 0.002252
 >> iter 85000, loss: 0.002201
 >> iter 86000, loss: 0.002186
 >> iter 87000, loss: 0.002136
 >> iter 88000, loss: 0.002124
 >> iter 89000, loss: 0.002076
 >> iter 90000, loss: 0.002064
   Number of active neurons: 4
 >> iter 91000, loss: 0.002020
 >> iter 92000, loss: 0.002008
 >> iter 93000, loss: 0.001966
 >> iter 94000, loss: 0.001955
 >> iter 95000, loss: 0.001915
 >> iter 96000, loss: 0.001905
 >> iter 97000, loss: 0.001868
 >> iter 98000, loss: 0.001857
 >> iter 99000, loss: 0.001822
 >> iter 100000, loss: 0.001812
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0169998300017
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.636440
 >> iter 2000, loss: 15.054097
 >> iter 3000, loss: 13.709801
 >> iter 4000, loss: 13.219910
 >> iter 5000, loss: 13.026270
 >> iter 6000, loss: 12.961829
 >> iter 7000, loss: 12.927590
 >> iter 8000, loss: 12.924393
 >> iter 9000, loss: 12.912679
 >> iter 10000, loss: 12.919135
   Number of active neurons: 3
 >> iter 11000, loss: 12.900122
 >> iter 12000, loss: 12.405203
 >> iter 13000, loss: 6.510211
 >> iter 14000, loss: 2.511023
 >> iter 15000, loss: 1.060314
 >> iter 16000, loss: 0.424986
 >> iter 17000, loss: 0.307133
 >> iter 18000, loss: 0.136776
 >> iter 19000, loss: 0.089450
 >> iter 20000, loss: 0.049800
   Number of active neurons: 4
 >> iter 21000, loss: 0.032028
 >> iter 22000, loss: 0.023839
 >> iter 23000, loss: 0.019240
 >> iter 24000, loss: 0.016617
 >> iter 25000, loss: 0.014630
 >> iter 26000, loss: 0.013299
 >> iter 27000, loss: 0.012088
 >> iter 28000, loss: 0.011227
 >> iter 29000, loss: 0.010360
 >> iter 30000, loss: 0.009737
   Number of active neurons: 4
 >> iter 31000, loss: 0.009073
 >> iter 32000, loss: 0.008598
 >> iter 33000, loss: 0.008074
 >> iter 34000, loss: 0.007700
 >> iter 35000, loss: 0.007274
 >> iter 36000, loss: 0.006974
 >> iter 37000, loss: 0.006619
 >> iter 38000, loss: 0.006374
 >> iter 39000, loss: 0.006073
 >> iter 40000, loss: 0.005871
   Number of active neurons: 4
 >> iter 41000, loss: 0.005611
 >> iter 42000, loss: 0.005438
 >> iter 43000, loss: 0.005214
 >> iter 44000, loss: 0.005066
 >> iter 45000, loss: 0.004870
 >> iter 46000, loss: 0.004744
 >> iter 47000, loss: 0.004568
 >> iter 48000, loss: 0.004457
 >> iter 49000, loss: 0.004302
 >> iter 50000, loss: 0.004206
   Number of active neurons: 4
 >> iter 51000, loss: 0.004063
 >> iter 52000, loss: 0.003979
 >> iter 53000, loss: 0.003849
 >> iter 54000, loss: 0.003776
 >> iter 55000, loss: 0.003657
 >> iter 56000, loss: 0.003592
 >> iter 57000, loss: 0.003484
 >> iter 58000, loss: 0.003426
 >> iter 59000, loss: 0.003327
 >> iter 60000, loss: 0.003274
   Number of active neurons: 4
 >> iter 61000, loss: 0.003183
 >> iter 62000, loss: 0.003135
 >> iter 63000, loss: 0.003050
 >> iter 64000, loss: 0.003007
 >> iter 65000, loss: 0.002929
 >> iter 66000, loss: 0.002888
 >> iter 67000, loss: 0.002818
 >> iter 68000, loss: 0.002779
 >> iter 69000, loss: 0.002715
 >> iter 70000, loss: 0.002677
   Number of active neurons: 4
 >> iter 71000, loss: 0.002618
 >> iter 72000, loss: 0.002584
 >> iter 73000, loss: 0.002527
 >> iter 74000, loss: 0.002498
 >> iter 75000, loss: 0.002443
 >> iter 76000, loss: 0.002416
 >> iter 77000, loss: 0.002365
 >> iter 78000, loss: 0.002340
 >> iter 79000, loss: 0.002291
 >> iter 80000, loss: 0.002268
   Number of active neurons: 4
 >> iter 81000, loss: 0.002222
 >> iter 82000, loss: 0.002200
 >> iter 83000, loss: 0.002156
 >> iter 84000, loss: 0.002137
 >> iter 85000, loss: 0.002095
 >> iter 86000, loss: 0.002077
 >> iter 87000, loss: 0.002036
 >> iter 88000, loss: 0.002020
 >> iter 89000, loss: 0.001981
 >> iter 90000, loss: 0.001966
   Number of active neurons: 4
 >> iter 91000, loss: 0.001929
 >> iter 92000, loss: 0.001915
 >> iter 93000, loss: 0.001880
 >> iter 94000, loss: 0.001866
 >> iter 95000, loss: 0.001833
 >> iter 96000, loss: 0.001820
 >> iter 97000, loss: 0.001789
 >> iter 98000, loss: 0.001776
 >> iter 99000, loss: 0.001747
 >> iter 100000, loss: 0.001734
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0689993100069
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.640301
 >> iter 2000, loss: 15.071212
 >> iter 3000, loss: 13.728588
 >> iter 4000, loss: 13.236810
 >> iter 5000, loss: 13.041564
 >> iter 6000, loss: 12.974930
 >> iter 7000, loss: 12.939999
 >> iter 8000, loss: 12.934497
 >> iter 9000, loss: 12.904004
 >> iter 10000, loss: 12.415568
   Number of active neurons: 4
 >> iter 11000, loss: 11.524485
 >> iter 12000, loss: 11.154798
 >> iter 13000, loss: 10.593806
 >> iter 14000, loss: 10.540309
 >> iter 15000, loss: 10.123060
 >> iter 16000, loss: 10.229294
 >> iter 17000, loss: 9.986150
 >> iter 18000, loss: 10.075712
 >> iter 19000, loss: 9.832240
 >> iter 20000, loss: 9.719294
   Number of active neurons: 4
 >> iter 21000, loss: 9.544628
 >> iter 22000, loss: 9.712776
 >> iter 23000, loss: 9.513185
 >> iter 24000, loss: 9.649583
 >> iter 25000, loss: 9.534513
 >> iter 26000, loss: 9.607699
 >> iter 27000, loss: 9.433160
 >> iter 28000, loss: 9.575375
 >> iter 29000, loss: 9.406064
 >> iter 30000, loss: 9.457458
   Number of active neurons: 4
 >> iter 31000, loss: 9.330712
 >> iter 32000, loss: 9.498329
 >> iter 33000, loss: 9.364832
 >> iter 34000, loss: 9.588418
 >> iter 35000, loss: 9.296055
 >> iter 36000, loss: 9.291369
 >> iter 37000, loss: 9.292365
 >> iter 38000, loss: 9.425061
 >> iter 39000, loss: 9.309688
 >> iter 40000, loss: 9.479182
   Number of active neurons: 4
 >> iter 41000, loss: 9.298765
 >> iter 42000, loss: 9.316677
 >> iter 43000, loss: 9.206046
 >> iter 44000, loss: 9.339752
 >> iter 45000, loss: 9.173522
 >> iter 46000, loss: 9.259439
 >> iter 47000, loss: 9.148520
 >> iter 48000, loss: 9.402305
 >> iter 49000, loss: 9.315028
 >> iter 50000, loss: 9.318547
   Number of active neurons: 4
 >> iter 51000, loss: 9.393602
 >> iter 52000, loss: 9.376804
 >> iter 53000, loss: 9.218947
 >> iter 54000, loss: 9.406654
 >> iter 55000, loss: 9.341965
 >> iter 56000, loss: 9.288624
 >> iter 57000, loss: 9.327847
 >> iter 58000, loss: 9.371964
 >> iter 59000, loss: 9.251536
 >> iter 60000, loss: 9.386555
   Number of active neurons: 4
 >> iter 61000, loss: 9.182704
 >> iter 62000, loss: 9.273284
 >> iter 63000, loss: 9.153228
 >> iter 64000, loss: 9.289769
 >> iter 65000, loss: 9.171370
 >> iter 66000, loss: 9.161060
 >> iter 67000, loss: 9.069936
 >> iter 68000, loss: 9.188495
 >> iter 69000, loss: 9.165864
 >> iter 70000, loss: 9.248912
   Number of active neurons: 4
 >> iter 71000, loss: 9.101905
 >> iter 72000, loss: 9.244075
 >> iter 73000, loss: 9.132786
 >> iter 74000, loss: 9.368114
 >> iter 75000, loss: 9.236173
 >> iter 76000, loss: 9.360756
 >> iter 77000, loss: 9.197299
 >> iter 78000, loss: 9.301972
 >> iter 79000, loss: 9.223804
 >> iter 80000, loss: 9.271375
   Number of active neurons: 4
 >> iter 81000, loss: 9.204113
 >> iter 82000, loss: 9.322882
 >> iter 83000, loss: 9.244268
 >> iter 84000, loss: 9.258602
 >> iter 85000, loss: 9.133312
 >> iter 86000, loss: 9.251889
 >> iter 87000, loss: 9.089132
 >> iter 88000, loss: 9.191370
 >> iter 89000, loss: 9.143108
 >> iter 90000, loss: 9.311776
   Number of active neurons: 4
 >> iter 91000, loss: 9.218957
 >> iter 92000, loss: 9.197806
 >> iter 93000, loss: 9.109268
 >> iter 94000, loss: 9.259808
 >> iter 95000, loss: 9.105159
 >> iter 96000, loss: 9.211570
 >> iter 97000, loss: 9.152838
 >> iter 98000, loss: 9.330402
 >> iter 99000, loss: 9.224689
 >> iter 100000, loss: 9.281872
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 13.2897342053
   - Test - Long: 31.3884305785
   - Test - Big: 13.2408675913
   - Test - A: 0.513299113392
   - Test - B: 31.6178921405
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.690255
 >> iter 2000, loss: 15.074096
 >> iter 3000, loss: 13.716318
 >> iter 4000, loss: 13.221121
 >> iter 5000, loss: 13.025623
 >> iter 6000, loss: 12.960864
 >> iter 7000, loss: 12.926428
 >> iter 8000, loss: 12.923664
 >> iter 9000, loss: 12.911836
 >> iter 10000, loss: 12.919749
   Number of active neurons: 3
 >> iter 11000, loss: 12.909104
 >> iter 12000, loss: 12.913052
 >> iter 13000, loss: 12.673737
 >> iter 14000, loss: 7.847688
 >> iter 15000, loss: 2.994542
 >> iter 16000, loss: 1.152839
 >> iter 17000, loss: 0.457815
 >> iter 18000, loss: 0.193848
 >> iter 19000, loss: 0.091459
 >> iter 20000, loss: 0.050554
   Number of active neurons: 4
 >> iter 21000, loss: 0.032929
 >> iter 22000, loss: 0.024759
 >> iter 23000, loss: 0.020213
 >> iter 24000, loss: 0.017529
 >> iter 25000, loss: 0.015506
 >> iter 26000, loss: 0.014093
 >> iter 27000, loss: 0.012828
 >> iter 28000, loss: 0.011896
 >> iter 29000, loss: 0.010993
 >> iter 30000, loss: 0.010309
   Number of active neurons: 4
 >> iter 31000, loss: 0.009620
 >> iter 32000, loss: 0.009097
 >> iter 33000, loss: 0.008553
 >> iter 34000, loss: 0.008141
 >> iter 35000, loss: 0.007698
 >> iter 36000, loss: 0.007367
 >> iter 37000, loss: 0.006999
 >> iter 38000, loss: 0.006726
 >> iter 39000, loss: 0.006417
 >> iter 40000, loss: 0.006190
   Number of active neurons: 4
 >> iter 41000, loss: 0.005924
 >> iter 42000, loss: 0.005730
 >> iter 43000, loss: 0.005500
 >> iter 44000, loss: 0.005334
 >> iter 45000, loss: 0.005133
 >> iter 46000, loss: 0.004990
 >> iter 47000, loss: 0.004812
 >> iter 48000, loss: 0.004687
 >> iter 49000, loss: 0.004529
 >> iter 50000, loss: 0.004420
   Number of active neurons: 4
 >> iter 51000, loss: 0.004276
 >> iter 52000, loss: 0.004180
 >> iter 53000, loss: 0.004049
 >> iter 54000, loss: 0.003965
 >> iter 55000, loss: 0.003846
 >> iter 56000, loss: 0.003771
 >> iter 57000, loss: 0.003662
 >> iter 58000, loss: 0.003595
 >> iter 59000, loss: 0.003495
 >> iter 60000, loss: 0.003434
   Number of active neurons: 4
 >> iter 61000, loss: 0.003343
 >> iter 62000, loss: 0.003288
 >> iter 63000, loss: 0.003202
 >> iter 64000, loss: 0.003154
 >> iter 65000, loss: 0.003074
 >> iter 66000, loss: 0.003030
 >> iter 67000, loss: 0.002956
 >> iter 68000, loss: 0.002915
 >> iter 69000, loss: 0.002846
 >> iter 70000, loss: 0.002808
   Number of active neurons: 4
 >> iter 71000, loss: 0.002743
 >> iter 72000, loss: 0.002709
 >> iter 73000, loss: 0.002648
 >> iter 74000, loss: 0.002617
 >> iter 75000, loss: 0.002559
 >> iter 76000, loss: 0.002531
 >> iter 77000, loss: 0.002477
 >> iter 78000, loss: 0.002450
 >> iter 79000, loss: 0.002400
 >> iter 80000, loss: 0.002374
   Number of active neurons: 4
 >> iter 81000, loss: 0.002327
 >> iter 82000, loss: 0.002303
 >> iter 83000, loss: 0.002258
 >> iter 84000, loss: 0.002236
 >> iter 85000, loss: 0.002193
 >> iter 86000, loss: 0.002173
 >> iter 87000, loss: 0.002132
 >> iter 88000, loss: 0.002113
 >> iter 89000, loss: 0.002074
 >> iter 90000, loss: 0.002056
   Number of active neurons: 4
 >> iter 91000, loss: 0.002020
 >> iter 92000, loss: 0.002003
 >> iter 93000, loss: 0.001968
 >> iter 94000, loss: 0.001952
 >> iter 95000, loss: 0.001918
 >> iter 96000, loss: 0.001903
 >> iter 97000, loss: 0.001872
 >> iter 98000, loss: 0.001857
 >> iter 99000, loss: 0.001827
 >> iter 100000, loss: 0.001813
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

