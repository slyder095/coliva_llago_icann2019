 > Problema: tomita3nueva
 > Args:
   - Hidden size: 4
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.496448
 >> iter 2000, loss: 15.745581
 >> iter 3000, loss: 14.737513
 >> iter 4000, loss: 13.965914
 >> iter 5000, loss: 13.849552
 >> iter 6000, loss: 13.143389
 >> iter 7000, loss: 11.985663
 >> iter 8000, loss: 10.801852
 >> iter 9000, loss: 10.344108
 >> iter 10000, loss: 9.775598
   Number of active neurons: 3
 >> iter 11000, loss: 9.755192
 >> iter 12000, loss: 9.456559
 >> iter 13000, loss: 9.625384
 >> iter 14000, loss: 9.341893
 >> iter 15000, loss: 9.441513
 >> iter 16000, loss: 9.067712
 >> iter 17000, loss: 7.844886
 >> iter 18000, loss: 6.583526
 >> iter 19000, loss: 4.769631
 >> iter 20000, loss: 3.611288
   Number of active neurons: 4
 >> iter 21000, loss: 3.177331
 >> iter 22000, loss: 2.390905
 >> iter 23000, loss: 1.615322
 >> iter 24000, loss: 1.130911
 >> iter 25000, loss: 0.811718
 >> iter 26000, loss: 0.596807
 >> iter 27000, loss: 0.669399
 >> iter 28000, loss: 0.526273
 >> iter 29000, loss: 0.337530
 >> iter 30000, loss: 0.259812
   Number of active neurons: 4
 >> iter 31000, loss: 0.410030
 >> iter 32000, loss: 0.303247
 >> iter 33000, loss: 0.363047
 >> iter 34000, loss: 0.319588
 >> iter 35000, loss: 0.363149
 >> iter 36000, loss: 0.339616
 >> iter 37000, loss: 0.327178
 >> iter 38000, loss: 0.399140
 >> iter 39000, loss: 0.381046
 >> iter 40000, loss: 0.337857
   Number of active neurons: 4
 >> iter 41000, loss: 0.267516
 >> iter 42000, loss: 0.241987
 >> iter 43000, loss: 0.208419
 >> iter 44000, loss: 0.248520
 >> iter 45000, loss: 0.268375
 >> iter 46000, loss: 0.379503
 >> iter 47000, loss: 0.343344
 >> iter 48000, loss: 0.221717
 >> iter 49000, loss: 0.263659
 >> iter 50000, loss: 0.365109
   Number of active neurons: 4
 >> iter 51000, loss: 0.362903
 >> iter 52000, loss: 0.278948
 >> iter 53000, loss: 0.214762
 >> iter 54000, loss: 0.334521
 >> iter 55000, loss: 0.375885
 >> iter 56000, loss: 0.318447
 >> iter 57000, loss: 0.325731
 >> iter 58000, loss: 0.272277
 >> iter 59000, loss: 0.390499
 >> iter 60000, loss: 0.493896
   Number of active neurons: 4
 >> iter 61000, loss: 0.456630
 >> iter 62000, loss: 0.404766
 >> iter 63000, loss: 0.494878
 >> iter 64000, loss: 0.344742
 >> iter 65000, loss: 0.289923
 >> iter 66000, loss: 0.286846
 >> iter 67000, loss: 0.274274
 >> iter 68000, loss: 0.298568
 >> iter 69000, loss: 0.342306
 >> iter 70000, loss: 0.358497
   Number of active neurons: 4
 >> iter 71000, loss: 0.563366
 >> iter 72000, loss: 0.490479
 >> iter 73000, loss: 0.354816
 >> iter 74000, loss: 0.323206
 >> iter 75000, loss: 0.240856
 >> iter 76000, loss: 0.289818
 >> iter 77000, loss: 0.243854
 >> iter 78000, loss: 0.273345
 >> iter 79000, loss: 0.327030
 >> iter 80000, loss: 0.203483
   Number of active neurons: 4
 >> iter 81000, loss: 0.218496
 >> iter 82000, loss: 0.431748
 >> iter 83000, loss: 0.440063
 >> iter 84000, loss: 0.291741
 >> iter 85000, loss: 0.378770
 >> iter 86000, loss: 0.497942
 >> iter 87000, loss: 0.371823
 >> iter 88000, loss: 0.361321
 >> iter 89000, loss: 0.328489
 >> iter 90000, loss: 0.203140
   Number of active neurons: 4
 >> iter 91000, loss: 0.294447
 >> iter 92000, loss: 0.301082
 >> iter 93000, loss: 0.364446
 >> iter 94000, loss: 0.408531
 >> iter 95000, loss: 0.403871
 >> iter 96000, loss: 0.435878
 >> iter 97000, loss: 0.330517
 >> iter 98000, loss: 0.310073
 >> iter 99000, loss: 0.243854
 >> iter 100000, loss: 0.381729
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 21.128754
 >> iter 2000, loss: 18.814848
 >> iter 3000, loss: 17.949898
 >> iter 4000, loss: 17.646805
 >> iter 5000, loss: 17.518601
 >> iter 6000, loss: 17.489517
 >> iter 7000, loss: 17.461453
 >> iter 8000, loss: 17.468087
 >> iter 9000, loss: 17.452693
 >> iter 10000, loss: 17.464687
   Number of active neurons: 0
 >> iter 11000, loss: 17.448629
 >> iter 12000, loss: 17.463661
 >> iter 13000, loss: 17.450073
 >> iter 14000, loss: 17.463729
 >> iter 15000, loss: 17.448759
 >> iter 16000, loss: 17.465580
 >> iter 17000, loss: 17.449689
 >> iter 18000, loss: 17.465422
 >> iter 19000, loss: 17.453755
 >> iter 20000, loss: 17.465505
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 17.455773
 >> iter 22000, loss: 17.465319
 >> iter 23000, loss: 17.456406
 >> iter 24000, loss: 17.465366
 >> iter 25000, loss: 17.456218
 >> iter 26000, loss: 17.465298
 >> iter 27000, loss: 17.454742
 >> iter 28000, loss: 17.465414
 >> iter 29000, loss: 17.452962
 >> iter 30000, loss: 17.465325
   Number of active neurons: 0
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 0
 >> iter 31000, loss: 17.453605
 >> iter 32000, loss: 17.465140
 >> iter 33000, loss: 17.454996
 >> iter 34000, loss: 17.464568
 >> iter 35000, loss: 17.456286
 >> iter 36000, loss: 17.463901
 >> iter 37000, loss: 17.456185
 >> iter 38000, loss: 17.462671
 >> iter 39000, loss: 17.456154
 >> iter 40000, loss: 17.459890
   Number of active neurons: 0
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 0
 >> iter 41000, loss: 17.456149
 >> iter 42000, loss: 17.455975
 >> iter 43000, loss: 17.456008
 >> iter 44000, loss: 17.454357
 >> iter 45000, loss: 17.455713
 >> iter 46000, loss: 17.451628
 >> iter 47000, loss: 17.454089
 >> iter 48000, loss: 17.451116
 >> iter 49000, loss: 17.452667
 >> iter 50000, loss: 17.453474
   Number of active neurons: 0
 >> iter 51000, loss: 17.451413
 >> iter 52000, loss: 17.450946
 >> iter 53000, loss: 17.448549
 >> iter 54000, loss: 17.454785
 >> iter 55000, loss: 17.446046
 >> iter 56000, loss: 17.458664
 >> iter 57000, loss: 17.448210
 >> iter 58000, loss: 17.460141
 >> iter 59000, loss: 17.443138
 >> iter 60000, loss: 17.458078
   Number of active neurons: 0
   SHOCK
   Setting new limit to 287500.0 iters...
   Number of active neurons: 0
 >> iter 61000, loss: 17.443123
 >> iter 62000, loss: 17.453952
 >> iter 63000, loss: 17.448643
 >> iter 64000, loss: 17.451978
 >> iter 65000, loss: 17.452108
 >> iter 66000, loss: 17.448857
 >> iter 67000, loss: 17.450274
 >> iter 68000, loss: 17.444185
 >> iter 69000, loss: 17.448447
 >> iter 70000, loss: 17.440344
   Number of active neurons: 0
 >> iter 71000, loss: 17.451062
 >> iter 72000, loss: 17.437056
 >> iter 73000, loss: 17.454775
 >> iter 74000, loss: 17.432100
 >> iter 75000, loss: 17.453164
   Number of active neurons: 0
   SHOCK
   Setting new limit to 293750.0 iters...
 >> iter 76000, loss: 17.432127
 >> iter 77000, loss: 17.450033
 >> iter 78000, loss: 17.433664
 >> iter 79000, loss: 17.449875
 >> iter 80000, loss: 17.437776
   Number of active neurons: 0
 >> iter 81000, loss: 17.455304
 >> iter 82000, loss: 17.436050
 >> iter 83000, loss: 17.457681
 >> iter 84000, loss: 17.439496
 >> iter 85000, loss: 17.459927
   Number of active neurons: 0
   SHOCK
   Setting new limit to 296875.0 iters...
 >> iter 86000, loss: 17.438394
 >> iter 87000, loss: 17.459256
 >> iter 88000, loss: 17.439496
 >> iter 89000, loss: 17.457920
 >> iter 90000, loss: 17.437475
   Number of active neurons: 0
 >> iter 91000, loss: 17.458540
 >> iter 92000, loss: 17.434804
 >> iter 93000, loss: 17.456802
 >> iter 94000, loss: 17.441982
 >> iter 95000, loss: 17.456522
   Number of active neurons: 0
   SHOCK
   Setting new limit to 298437.5 iters...
 >> iter 96000, loss: 17.439913
 >> iter 97000, loss: 17.459822
 >> iter 98000, loss: 17.435026
 >> iter 99000, loss: 17.457930
 >> iter 100000, loss: 17.437143
   Number of active neurons: 0
 >> iter 101000, loss: 17.455686
 >> iter 102000, loss: 17.434422
 >> iter 103000, loss: 17.456761
 >> iter 104000, loss: 17.436351
 >> iter 105000, loss: 17.457172
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299218.75 iters...
 >> iter 106000, loss: 17.436779
 >> iter 107000, loss: 17.453670
 >> iter 108000, loss: 17.440706
 >> iter 109000, loss: 17.453823
 >> iter 110000, loss: 17.441158
   Number of active neurons: 0
 >> iter 111000, loss: 17.453909
 >> iter 112000, loss: 17.441774
 >> iter 113000, loss: 17.450750
 >> iter 114000, loss: 17.441249
 >> iter 115000, loss: 17.448868
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299609.375 iters...
 >> iter 116000, loss: 17.441716
 >> iter 117000, loss: 17.450646
 >> iter 118000, loss: 17.440279
 >> iter 119000, loss: 17.450023
 >> iter 120000, loss: 17.440579
   Number of active neurons: 0
 >> iter 121000, loss: 17.447115
 >> iter 122000, loss: 17.439550
 >> iter 123000, loss: 17.445549
 >> iter 124000, loss: 17.440491
 >> iter 125000, loss: 17.448545
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299804.6875 iters...
 >> iter 126000, loss: 17.441721
 >> iter 127000, loss: 17.448746
 >> iter 128000, loss: 17.440537
 >> iter 129000, loss: 17.447755
 >> iter 130000, loss: 17.438074
   Number of active neurons: 0
 >> iter 131000, loss: 17.450295
 >> iter 132000, loss: 17.436533
 >> iter 133000, loss: 17.449707
 >> iter 134000, loss: 17.438251
 >> iter 135000, loss: 17.449419
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299902.34375 iters...
 >> iter 136000, loss: 17.441998
 >> iter 137000, loss: 17.448828
 >> iter 138000, loss: 17.441713
 >> iter 139000, loss: 17.447292
 >> iter 140000, loss: 17.444150
   Number of active neurons: 0
 >> iter 141000, loss: 17.442828
 >> iter 142000, loss: 17.444393
 >> iter 143000, loss: 17.444650
 >> iter 144000, loss: 17.444284
 >> iter 145000, loss: 17.449412
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299951.171875 iters...
 >> iter 146000, loss: 17.444160
 >> iter 147000, loss: 17.450538
 >> iter 148000, loss: 17.444734
 >> iter 149000, loss: 17.452825
 >> iter 150000, loss: 17.444613
   Number of active neurons: 0
 >> iter 151000, loss: 17.452344
 >> iter 152000, loss: 17.444023
 >> iter 153000, loss: 17.454187
 >> iter 154000, loss: 17.446389
 >> iter 155000, loss: 17.454042
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299975.585938 iters...
 >> iter 156000, loss: 17.446252
 >> iter 157000, loss: 17.453963
 >> iter 158000, loss: 17.446026
 >> iter 159000, loss: 17.454249
 >> iter 160000, loss: 17.446643
   Number of active neurons: 0
 >> iter 161000, loss: 17.453791
 >> iter 162000, loss: 17.446521
 >> iter 163000, loss: 17.453358
 >> iter 164000, loss: 17.446396
 >> iter 165000, loss: 17.452512
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299987.792969 iters...
 >> iter 166000, loss: 17.446073
 >> iter 167000, loss: 17.451457
 >> iter 168000, loss: 17.446066
 >> iter 169000, loss: 17.449311
 >> iter 170000, loss: 17.446325
   Number of active neurons: 0
 >> iter 171000, loss: 17.450325
 >> iter 172000, loss: 17.446266
 >> iter 173000, loss: 17.450704
 >> iter 174000, loss: 17.446297
 >> iter 175000, loss: 17.451241
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299993.896484 iters...
 >> iter 176000, loss: 17.446184
 >> iter 177000, loss: 17.449017
 >> iter 178000, loss: 17.446391
 >> iter 179000, loss: 17.450928
 >> iter 180000, loss: 17.446231
   Number of active neurons: 0
 >> iter 181000, loss: 17.451909
 >> iter 182000, loss: 17.445479
 >> iter 183000, loss: 17.451770
 >> iter 184000, loss: 17.445672
 >> iter 185000, loss: 17.452724
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299996.948242 iters...
 >> iter 186000, loss: 17.445644
 >> iter 187000, loss: 17.452699
 >> iter 188000, loss: 17.445423
 >> iter 189000, loss: 17.452554
 >> iter 190000, loss: 17.444259
   Number of active neurons: 0
 >> iter 191000, loss: 17.453036
 >> iter 192000, loss: 17.443156
 >> iter 193000, loss: 17.452832
 >> iter 194000, loss: 17.442293
 >> iter 195000, loss: 17.452912
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299998.474121 iters...
 >> iter 196000, loss: 17.443629
 >> iter 197000, loss: 17.452635
 >> iter 198000, loss: 17.442446
 >> iter 199000, loss: 17.452927
 >> iter 200000, loss: 17.443077
   Number of active neurons: 0
 >> iter 201000, loss: 17.452793
 >> iter 202000, loss: 17.444912
 >> iter 203000, loss: 17.452783
 >> iter 204000, loss: 17.444649
 >> iter 205000, loss: 17.452980
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.237061 iters...
 >> iter 206000, loss: 17.444528
 >> iter 207000, loss: 17.452548
 >> iter 208000, loss: 17.445530
 >> iter 209000, loss: 17.452897
 >> iter 210000, loss: 17.445766
   Number of active neurons: 0
 >> iter 211000, loss: 17.452665
 >> iter 212000, loss: 17.445630
 >> iter 213000, loss: 17.452094
 >> iter 214000, loss: 17.445432
 >> iter 215000, loss: 17.451801
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.61853 iters...
 >> iter 216000, loss: 17.445044
 >> iter 217000, loss: 17.451123
 >> iter 218000, loss: 17.445063
 >> iter 219000, loss: 17.449634
 >> iter 220000, loss: 17.443890
   Number of active neurons: 0
 >> iter 221000, loss: 17.450036
 >> iter 222000, loss: 17.443165
 >> iter 223000, loss: 17.450596
 >> iter 224000, loss: 17.441836
 >> iter 225000, loss: 17.451834
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.809265 iters...
 >> iter 226000, loss: 17.441234
 >> iter 227000, loss: 17.451936
 >> iter 228000, loss: 17.437180
 >> iter 229000, loss: 17.451868
 >> iter 230000, loss: 17.433903
   Number of active neurons: 0
 >> iter 231000, loss: 17.452171
 >> iter 232000, loss: 17.439346
 >> iter 233000, loss: 17.451721
 >> iter 234000, loss: 17.442297
 >> iter 235000, loss: 17.451735
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.904633 iters...
 >> iter 236000, loss: 17.443069
 >> iter 237000, loss: 17.452410
 >> iter 238000, loss: 17.442234
 >> iter 239000, loss: 17.452214
 >> iter 240000, loss: 17.438561
   Number of active neurons: 0
 >> iter 241000, loss: 17.452490
 >> iter 242000, loss: 17.439990
 >> iter 243000, loss: 17.452122
 >> iter 244000, loss: 17.436320
 >> iter 245000, loss: 17.451499
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.952316 iters...
 >> iter 246000, loss: 17.436117
 >> iter 247000, loss: 17.452968
 >> iter 248000, loss: 17.440552
 >> iter 249000, loss: 17.452825
 >> iter 250000, loss: 17.440267
   Number of active neurons: 0
 >> iter 251000, loss: 17.452493
 >> iter 252000, loss: 17.439697
 >> iter 253000, loss: 17.453284
 >> iter 254000, loss: 17.439415
 >> iter 255000, loss: 17.452984
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.976158 iters...
 >> iter 256000, loss: 17.440874
 >> iter 257000, loss: 17.452451
 >> iter 258000, loss: 17.439638
 >> iter 259000, loss: 17.451413
 >> iter 260000, loss: 17.439354
   Number of active neurons: 0
 >> iter 261000, loss: 17.448659
 >> iter 262000, loss: 17.439068
 >> iter 263000, loss: 17.446921
 >> iter 264000, loss: 17.440735
 >> iter 265000, loss: 17.448921
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.988079 iters...
 >> iter 266000, loss: 17.439559
 >> iter 267000, loss: 17.450332
 >> iter 268000, loss: 17.440946
 >> iter 269000, loss: 17.449794
 >> iter 270000, loss: 17.441024
   Number of active neurons: 0
 >> iter 271000, loss: 17.449493
 >> iter 272000, loss: 17.441932
 >> iter 273000, loss: 17.447150
 >> iter 274000, loss: 17.441943
 >> iter 275000, loss: 17.447957
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99404 iters...
 >> iter 276000, loss: 17.441807
 >> iter 277000, loss: 17.451319
 >> iter 278000, loss: 17.441501
 >> iter 279000, loss: 17.451390
 >> iter 280000, loss: 17.441373
   Number of active neurons: 0
 >> iter 281000, loss: 17.451410
 >> iter 282000, loss: 17.441360
 >> iter 283000, loss: 17.451753
 >> iter 284000, loss: 17.440589
 >> iter 285000, loss: 17.451195
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99702 iters...
 >> iter 286000, loss: 17.440113
 >> iter 287000, loss: 17.452142
 >> iter 288000, loss: 17.438519
 >> iter 289000, loss: 17.452251
 >> iter 290000, loss: 17.437611
   Number of active neurons: 0
 >> iter 291000, loss: 17.452173
 >> iter 292000, loss: 17.437705
 >> iter 293000, loss: 17.451753
 >> iter 294000, loss: 17.440267
 >> iter 295000, loss: 17.450156
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99851 iters...
 >> iter 296000, loss: 17.439547
 >> iter 297000, loss: 17.450595
 >> iter 298000, loss: 17.437966
 >> iter 299000, loss: 17.449371
 >> iter 300000, loss: 17.440566
   Number of active neurons: 0
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 48.6410271795
   - Test - Long: 92.6053697315
   - Test - Big: 49.4625053749
   - Test - A: 28.5580961269
   - Test - B: 30.8046130258
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.190542
 >> iter 2000, loss: 14.231235
 >> iter 3000, loss: 11.471209
 >> iter 4000, loss: 8.547296
 >> iter 5000, loss: 6.599039
 >> iter 6000, loss: 5.449671
 >> iter 7000, loss: 5.035353
 >> iter 8000, loss: 4.498911
 >> iter 9000, loss: 4.601847
 >> iter 10000, loss: 4.318453
   Number of active neurons: 4
 >> iter 11000, loss: 4.251783
 >> iter 12000, loss: 3.996883
 >> iter 13000, loss: 4.456611
 >> iter 14000, loss: 4.251080
 >> iter 15000, loss: 4.291588
 >> iter 16000, loss: 4.557764
 >> iter 17000, loss: 4.329885
 >> iter 18000, loss: 4.014437
 >> iter 19000, loss: 3.995961
 >> iter 20000, loss: 4.080016
   Number of active neurons: 4
 >> iter 21000, loss: 4.059108
 >> iter 22000, loss: 4.043534
 >> iter 23000, loss: 3.908888
 >> iter 24000, loss: 4.021463
 >> iter 25000, loss: 4.217633
 >> iter 26000, loss: 3.894350
 >> iter 27000, loss: 4.142276
 >> iter 28000, loss: 3.974211
 >> iter 29000, loss: 4.156652
 >> iter 30000, loss: 4.297809
   Number of active neurons: 4
 >> iter 31000, loss: 4.371611
 >> iter 32000, loss: 3.850384
 >> iter 33000, loss: 4.279059
 >> iter 34000, loss: 4.254179
 >> iter 35000, loss: 4.505119
 >> iter 36000, loss: 4.158991
 >> iter 37000, loss: 4.251214
 >> iter 38000, loss: 4.087389
 >> iter 39000, loss: 4.281287
 >> iter 40000, loss: 4.292644
   Number of active neurons: 4
 >> iter 41000, loss: 4.301158
 >> iter 42000, loss: 4.315802
 >> iter 43000, loss: 4.197340
 >> iter 44000, loss: 4.139090
 >> iter 45000, loss: 4.379782
 >> iter 46000, loss: 4.106149
 >> iter 47000, loss: 4.298016
 >> iter 48000, loss: 4.002991
 >> iter 49000, loss: 4.132856
 >> iter 50000, loss: 4.152082
   Number of active neurons: 4
 >> iter 51000, loss: 4.094484
 >> iter 52000, loss: 4.056094
 >> iter 53000, loss: 4.498675
 >> iter 54000, loss: 4.019058
 >> iter 55000, loss: 4.314208
 >> iter 56000, loss: 4.478221
 >> iter 57000, loss: 4.436880
 >> iter 58000, loss: 3.986213
 >> iter 59000, loss: 3.969273
 >> iter 60000, loss: 3.620853
   Number of active neurons: 4
 >> iter 61000, loss: 4.309606
 >> iter 62000, loss: 4.236453
 >> iter 63000, loss: 4.781590
 >> iter 64000, loss: 4.359486
 >> iter 65000, loss: 3.935369
 >> iter 66000, loss: 4.002019
 >> iter 67000, loss: 4.178563
 >> iter 68000, loss: 3.821347
 >> iter 69000, loss: 4.002238
 >> iter 70000, loss: 3.754118
   Number of active neurons: 4
 >> iter 71000, loss: 3.949117
 >> iter 72000, loss: 3.766500
 >> iter 73000, loss: 3.880071
 >> iter 74000, loss: 3.906657
 >> iter 75000, loss: 3.505897
 >> iter 76000, loss: 3.507242
 >> iter 77000, loss: 3.566107
 >> iter 78000, loss: 3.435628
 >> iter 79000, loss: 3.132103
 >> iter 80000, loss: 3.099937
   Number of active neurons: 4
 >> iter 81000, loss: 3.249751
 >> iter 82000, loss: 3.381503
 >> iter 83000, loss: 3.547190
 >> iter 84000, loss: 3.349738
 >> iter 85000, loss: 3.579914
 >> iter 86000, loss: 3.381028
 >> iter 87000, loss: 3.728066
 >> iter 88000, loss: 2.268381
 >> iter 89000, loss: 1.721767
 >> iter 90000, loss: 1.765841
   Number of active neurons: 4
 >> iter 91000, loss: 1.460171
 >> iter 92000, loss: 1.555879
 >> iter 93000, loss: 1.189464
 >> iter 94000, loss: 1.374857
 >> iter 95000, loss: 2.540639
 >> iter 96000, loss: 1.836279
 >> iter 97000, loss: 1.406984
 >> iter 98000, loss: 1.015809
 >> iter 99000, loss: 1.426888
 >> iter 100000, loss: 2.395673
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 2.21995560089
   - Test - Long: 0.674966251687
   - Test - Big: 2.44397556024
   - Test - A: 14.6256916206
   - Test - B: 12.8658089461
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.063206
 >> iter 2000, loss: 13.136961
 >> iter 3000, loss: 7.942420
 >> iter 4000, loss: 5.114977
 >> iter 5000, loss: 3.798261
 >> iter 6000, loss: 3.130496
 >> iter 7000, loss: 3.050797
 >> iter 8000, loss: 2.860301
 >> iter 9000, loss: 2.730985
 >> iter 10000, loss: 2.505168
   Number of active neurons: 4
 >> iter 11000, loss: 2.409340
 >> iter 12000, loss: 2.474407
 >> iter 13000, loss: 2.446074
 >> iter 14000, loss: 2.425950
 >> iter 15000, loss: 2.347126
 >> iter 16000, loss: 2.304274
 >> iter 17000, loss: 2.408666
 >> iter 18000, loss: 2.363365
 >> iter 19000, loss: 2.347357
 >> iter 20000, loss: 2.284907
   Number of active neurons: 4
 >> iter 21000, loss: 2.316525
 >> iter 22000, loss: 2.280836
 >> iter 23000, loss: 2.330389
 >> iter 24000, loss: 2.202992
 >> iter 25000, loss: 2.294995
 >> iter 26000, loss: 2.404773
 >> iter 27000, loss: 2.301290
 >> iter 28000, loss: 2.278782
 >> iter 29000, loss: 2.296326
 >> iter 30000, loss: 2.342803
   Number of active neurons: 4
 >> iter 31000, loss: 2.275489
 >> iter 32000, loss: 2.275353
 >> iter 33000, loss: 2.380275
 >> iter 34000, loss: 2.325476
 >> iter 35000, loss: 2.314662
 >> iter 36000, loss: 2.258200
 >> iter 37000, loss: 2.340713
 >> iter 38000, loss: 2.317500
 >> iter 39000, loss: 2.356834
 >> iter 40000, loss: 2.287556
   Number of active neurons: 4
 >> iter 41000, loss: 2.289327
 >> iter 42000, loss: 2.388750
 >> iter 43000, loss: 2.317944
 >> iter 44000, loss: 2.417515
 >> iter 45000, loss: 2.393021
 >> iter 46000, loss: 2.314775
 >> iter 47000, loss: 2.299180
 >> iter 48000, loss: 2.474199
 >> iter 49000, loss: 2.550498
 >> iter 50000, loss: 2.562833
   Number of active neurons: 4
 >> iter 51000, loss: 2.365314
 >> iter 52000, loss: 2.372772
 >> iter 53000, loss: 2.309400
 >> iter 54000, loss: 2.278121
 >> iter 55000, loss: 2.282365
 >> iter 56000, loss: 2.311469
 >> iter 57000, loss: 2.268547
 >> iter 58000, loss: 2.262152
 >> iter 59000, loss: 2.308414
 >> iter 60000, loss: 2.280454
   Number of active neurons: 4
 >> iter 61000, loss: 2.169477
 >> iter 62000, loss: 2.265895
 >> iter 63000, loss: 2.248906
 >> iter 64000, loss: 2.211697
 >> iter 65000, loss: 2.321703
 >> iter 66000, loss: 2.361071
 >> iter 67000, loss: 2.346075
 >> iter 68000, loss: 2.420576
 >> iter 69000, loss: 2.229136
 >> iter 70000, loss: 2.382408
   Number of active neurons: 4
 >> iter 71000, loss: 2.241668
 >> iter 72000, loss: 2.265146
 >> iter 73000, loss: 2.252625
 >> iter 74000, loss: 2.284514
 >> iter 75000, loss: 2.235746
 >> iter 76000, loss: 2.351712
 >> iter 77000, loss: 2.374216
 >> iter 78000, loss: 2.342654
 >> iter 79000, loss: 2.350056
 >> iter 80000, loss: 2.373310
   Number of active neurons: 4
 >> iter 81000, loss: 2.479164
 >> iter 82000, loss: 2.423521
 >> iter 83000, loss: 2.262335
 >> iter 84000, loss: 2.467519
 >> iter 85000, loss: 2.295164
 >> iter 86000, loss: 2.294589
 >> iter 87000, loss: 2.387202
 >> iter 88000, loss: 2.355234
 >> iter 89000, loss: 2.222404
 >> iter 90000, loss: 2.295563
   Number of active neurons: 4
 >> iter 91000, loss: 2.330102
 >> iter 92000, loss: 2.299091
 >> iter 93000, loss: 2.254389
 >> iter 94000, loss: 2.380430
 >> iter 95000, loss: 2.314366
 >> iter 96000, loss: 2.389460
 >> iter 97000, loss: 2.301317
 >> iter 98000, loss: 2.544361
 >> iter 99000, loss: 2.461026
 >> iter 100000, loss: 2.489575
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 2.0039599208
   - Test - Long: 0.574971251437
   - Test - Big: 2.15597844022
   - Test - A: 0.0
   - Test - B: 14.8456769549
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.281666
 >> iter 2000, loss: 12.447612
 >> iter 3000, loss: 8.791843
 >> iter 4000, loss: 6.963531
 >> iter 5000, loss: 4.745227
 >> iter 6000, loss: 2.344902
 >> iter 7000, loss: 1.175949
 >> iter 8000, loss: 0.917223
 >> iter 9000, loss: 0.663351
 >> iter 10000, loss: 0.450577
   Number of active neurons: 3
 >> iter 11000, loss: 0.590386
 >> iter 12000, loss: 0.454049
 >> iter 13000, loss: 0.537218
 >> iter 14000, loss: 0.592010
 >> iter 15000, loss: 0.449365
 >> iter 16000, loss: 0.466616
 >> iter 17000, loss: 0.508609
 >> iter 18000, loss: 0.417578
 >> iter 19000, loss: 0.513814
 >> iter 20000, loss: 0.427035
   Number of active neurons: 3
 >> iter 21000, loss: 0.326817
 >> iter 22000, loss: 0.336959
 >> iter 23000, loss: 0.463848
 >> iter 24000, loss: 0.380501
 >> iter 25000, loss: 0.369481
 >> iter 26000, loss: 0.299964
 >> iter 27000, loss: 0.461341
 >> iter 28000, loss: 0.293653
 >> iter 29000, loss: 0.590561
 >> iter 30000, loss: 0.526152
   Number of active neurons: 3
 >> iter 31000, loss: 0.623595
 >> iter 32000, loss: 0.632581
 >> iter 33000, loss: 0.658609
 >> iter 34000, loss: 0.598638
 >> iter 35000, loss: 0.368071
 >> iter 36000, loss: 0.260767
 >> iter 37000, loss: 0.259035
 >> iter 38000, loss: 0.285684
 >> iter 39000, loss: 0.418562
 >> iter 40000, loss: 0.802587
   Number of active neurons: 3
 >> iter 41000, loss: 0.470499
 >> iter 42000, loss: 0.785644
 >> iter 43000, loss: 0.470767
 >> iter 44000, loss: 0.311232
 >> iter 45000, loss: 0.505894
 >> iter 46000, loss: 0.313939
 >> iter 47000, loss: 0.355847
 >> iter 48000, loss: 0.279932
 >> iter 49000, loss: 0.530016
 >> iter 50000, loss: 0.452752
   Number of active neurons: 3
 >> iter 51000, loss: 0.375106
 >> iter 52000, loss: 0.452215
 >> iter 53000, loss: 0.406462
 >> iter 54000, loss: 0.434388
 >> iter 55000, loss: 0.569895
 >> iter 56000, loss: 0.336837
 >> iter 57000, loss: 0.360297
 >> iter 58000, loss: 0.402172
 >> iter 59000, loss: 0.434699
 >> iter 60000, loss: 0.388752
   Number of active neurons: 3
 >> iter 61000, loss: 0.273212
 >> iter 62000, loss: 0.313719
 >> iter 63000, loss: 0.416022
 >> iter 64000, loss: 0.391350
 >> iter 65000, loss: 0.593536
 >> iter 66000, loss: 0.446387
 >> iter 67000, loss: 0.466878
 >> iter 68000, loss: 0.370392
 >> iter 69000, loss: 0.439627
 >> iter 70000, loss: 0.440518
   Number of active neurons: 3
 >> iter 71000, loss: 0.399626
 >> iter 72000, loss: 0.412487
 >> iter 73000, loss: 0.417299
 >> iter 74000, loss: 0.358342
 >> iter 75000, loss: 0.384947
 >> iter 76000, loss: 0.311683
 >> iter 77000, loss: 0.407593
 >> iter 78000, loss: 0.568056
 >> iter 79000, loss: 0.525229
 >> iter 80000, loss: 0.356877
   Number of active neurons: 3
 >> iter 81000, loss: 0.407967
 >> iter 82000, loss: 0.388997
 >> iter 83000, loss: 0.296580
 >> iter 84000, loss: 0.395697
 >> iter 85000, loss: 0.539530
 >> iter 86000, loss: 0.409195
 >> iter 87000, loss: 0.328005
 >> iter 88000, loss: 0.421739
 >> iter 89000, loss: 0.293966
 >> iter 90000, loss: 0.349539
   Number of active neurons: 3
 >> iter 91000, loss: 0.357388
 >> iter 92000, loss: 0.323152
 >> iter 93000, loss: 0.270232
 >> iter 94000, loss: 0.435335
 >> iter 95000, loss: 0.418088
 >> iter 96000, loss: 0.396855
 >> iter 97000, loss: 0.352525
 >> iter 98000, loss: 0.354564
 >> iter 99000, loss: 0.480762
 >> iter 100000, loss: 0.370978
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.269986
 >> iter 2000, loss: 13.597525
 >> iter 3000, loss: 9.917390
 >> iter 4000, loss: 8.106333
 >> iter 5000, loss: 7.600965
 >> iter 6000, loss: 7.217332
 >> iter 7000, loss: 7.327186
 >> iter 8000, loss: 7.139082
 >> iter 9000, loss: 7.126521
 >> iter 10000, loss: 7.074295
   Number of active neurons: 4
 >> iter 11000, loss: 7.055211
 >> iter 12000, loss: 7.034474
 >> iter 13000, loss: 7.031933
 >> iter 14000, loss: 6.846470
 >> iter 15000, loss: 7.027182
 >> iter 16000, loss: 6.715557
 >> iter 17000, loss: 6.717420
 >> iter 18000, loss: 6.508207
 >> iter 19000, loss: 6.573493
 >> iter 20000, loss: 6.424156
   Number of active neurons: 4
 >> iter 21000, loss: 6.673756
 >> iter 22000, loss: 6.298323
 >> iter 23000, loss: 6.437067
 >> iter 24000, loss: 6.349184
 >> iter 25000, loss: 6.475799
 >> iter 26000, loss: 6.517388
 >> iter 27000, loss: 6.537987
 >> iter 28000, loss: 6.294809
 >> iter 29000, loss: 6.427630
 >> iter 30000, loss: 6.312161
   Number of active neurons: 4
 >> iter 31000, loss: 6.461039
 >> iter 32000, loss: 6.355139
 >> iter 33000, loss: 6.517346
 >> iter 34000, loss: 6.539002
 >> iter 35000, loss: 6.692376
 >> iter 36000, loss: 6.625134
 >> iter 37000, loss: 6.604601
 >> iter 38000, loss: 6.441571
 >> iter 39000, loss: 6.527007
 >> iter 40000, loss: 6.535269
   Number of active neurons: 4
 >> iter 41000, loss: 6.524038
 >> iter 42000, loss: 6.370138
 >> iter 43000, loss: 6.729672
 >> iter 44000, loss: 6.554899
 >> iter 45000, loss: 6.572018
 >> iter 46000, loss: 6.435991
 >> iter 47000, loss: 6.406616
 >> iter 48000, loss: 6.550984
 >> iter 49000, loss: 6.782045
 >> iter 50000, loss: 6.674297
   Number of active neurons: 4
 >> iter 51000, loss: 6.606255
 >> iter 52000, loss: 6.486697
 >> iter 53000, loss: 6.661436
 >> iter 54000, loss: 6.589804
 >> iter 55000, loss: 6.584289
 >> iter 56000, loss: 6.646912
 >> iter 57000, loss: 6.917459
 >> iter 58000, loss: 6.809930
 >> iter 59000, loss: 6.917247
 >> iter 60000, loss: 6.714832
   Number of active neurons: 4
 >> iter 61000, loss: 6.675127
 >> iter 62000, loss: 6.479426
 >> iter 63000, loss: 6.685859
 >> iter 64000, loss: 6.521739
 >> iter 65000, loss: 6.700294
 >> iter 66000, loss: 6.589013
 >> iter 67000, loss: 6.778382
 >> iter 68000, loss: 6.615317
 >> iter 69000, loss: 6.762965
 >> iter 70000, loss: 6.565988
   Number of active neurons: 4
 >> iter 71000, loss: 6.914700
 >> iter 72000, loss: 6.705585
 >> iter 73000, loss: 7.010740
 >> iter 74000, loss: 6.756250
 >> iter 75000, loss: 6.999722
 >> iter 76000, loss: 6.804691
 >> iter 77000, loss: 7.037152
 >> iter 78000, loss: 6.665178
 >> iter 79000, loss: 6.868566
 >> iter 80000, loss: 6.687062
   Number of active neurons: 4
 >> iter 81000, loss: 7.047627
 >> iter 82000, loss: 6.714656
 >> iter 83000, loss: 6.756055
 >> iter 84000, loss: 6.481391
 >> iter 85000, loss: 6.603103
 >> iter 86000, loss: 6.022956
 >> iter 87000, loss: 6.000984
 >> iter 88000, loss: 5.807295
 >> iter 89000, loss: 5.975223
 >> iter 90000, loss: 5.684557
   Number of active neurons: 4
 >> iter 91000, loss: 5.718308
 >> iter 92000, loss: 5.399180
 >> iter 93000, loss: 5.674978
 >> iter 94000, loss: 5.425510
 >> iter 95000, loss: 5.633401
 >> iter 96000, loss: 5.699810
 >> iter 97000, loss: 5.800692
 >> iter 98000, loss: 5.550916
 >> iter 99000, loss: 5.715036
 >> iter 100000, loss: 5.381950
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 9.29981400372
   - Test - Long: 1.98490075496
   - Test - Big: 9.11490885091
   - Test - A: 17.0521965202
   - Test - B: 3.31977868142
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.062570
 >> iter 2000, loss: 12.009427
 >> iter 3000, loss: 5.831356
 >> iter 4000, loss: 2.649057
 >> iter 5000, loss: 1.424186
 >> iter 6000, loss: 0.702573
 >> iter 7000, loss: 0.571990
 >> iter 8000, loss: 0.568312
 >> iter 9000, loss: 0.379419
 >> iter 10000, loss: 0.353021
   Number of active neurons: 4
 >> iter 11000, loss: 0.342623
 >> iter 12000, loss: 0.306095
 >> iter 13000, loss: 0.321741
 >> iter 14000, loss: 0.357104
 >> iter 15000, loss: 0.383511
 >> iter 16000, loss: 0.242534
 >> iter 17000, loss: 0.319496
 >> iter 18000, loss: 0.384155
 >> iter 19000, loss: 0.366885
 >> iter 20000, loss: 0.459615
   Number of active neurons: 4
 >> iter 21000, loss: 0.480954
 >> iter 22000, loss: 0.347629
 >> iter 23000, loss: 0.344361
 >> iter 24000, loss: 0.371734
 >> iter 25000, loss: 0.458666
 >> iter 26000, loss: 0.381066
 >> iter 27000, loss: 0.274466
 >> iter 28000, loss: 0.203432
 >> iter 29000, loss: 0.387697
 >> iter 30000, loss: 0.416304
   Number of active neurons: 4
 >> iter 31000, loss: 0.349307
 >> iter 32000, loss: 0.401651
 >> iter 33000, loss: 0.258305
 >> iter 34000, loss: 0.165031
 >> iter 35000, loss: 0.502412
 >> iter 36000, loss: 0.468462
 >> iter 37000, loss: 0.478568
 >> iter 38000, loss: 0.431278
 >> iter 39000, loss: 0.362333
 >> iter 40000, loss: 0.416584
   Number of active neurons: 4
 >> iter 41000, loss: 0.387479
 >> iter 42000, loss: 0.402561
 >> iter 43000, loss: 0.546806
 >> iter 44000, loss: 0.381405
 >> iter 45000, loss: 0.447573
 >> iter 46000, loss: 0.381992
 >> iter 47000, loss: 0.256331
 >> iter 48000, loss: 0.283629
 >> iter 49000, loss: 0.274820
 >> iter 50000, loss: 0.473733
   Number of active neurons: 4
 >> iter 51000, loss: 0.489917
 >> iter 52000, loss: 0.536154
 >> iter 53000, loss: 0.478231
 >> iter 54000, loss: 0.350004
 >> iter 55000, loss: 0.386748
 >> iter 56000, loss: 0.358888
 >> iter 57000, loss: 0.433520
 >> iter 58000, loss: 0.303672
 >> iter 59000, loss: 0.345553
 >> iter 60000, loss: 0.256683
   Number of active neurons: 4
 >> iter 61000, loss: 0.312653
 >> iter 62000, loss: 0.446928
 >> iter 63000, loss: 0.403528
 >> iter 64000, loss: 0.539844
 >> iter 65000, loss: 0.508199
 >> iter 66000, loss: 0.434991
 >> iter 67000, loss: 0.337968
 >> iter 68000, loss: 0.377986
 >> iter 69000, loss: 0.307003
 >> iter 70000, loss: 0.443788
   Number of active neurons: 4
 >> iter 71000, loss: 0.397999
 >> iter 72000, loss: 0.374563
 >> iter 73000, loss: 0.381745
 >> iter 74000, loss: 0.319325
 >> iter 75000, loss: 0.424438
 >> iter 76000, loss: 0.331743
 >> iter 77000, loss: 0.387119
 >> iter 78000, loss: 0.437439
 >> iter 79000, loss: 0.591568
 >> iter 80000, loss: 0.391726
   Number of active neurons: 4
 >> iter 81000, loss: 0.313529
 >> iter 82000, loss: 0.393577
 >> iter 83000, loss: 0.490727
 >> iter 84000, loss: 0.274057
 >> iter 85000, loss: 0.424301
 >> iter 86000, loss: 0.536929
 >> iter 87000, loss: 0.422099
 >> iter 88000, loss: 0.325764
 >> iter 89000, loss: 0.390315
 >> iter 90000, loss: 0.263956
   Number of active neurons: 4
 >> iter 91000, loss: 0.285529
 >> iter 92000, loss: 0.364658
 >> iter 93000, loss: 0.467187
 >> iter 94000, loss: 0.348224
 >> iter 95000, loss: 0.337196
 >> iter 96000, loss: 0.292050
 >> iter 97000, loss: 0.266427
 >> iter 98000, loss: 0.273350
 >> iter 99000, loss: 0.477936
 >> iter 100000, loss: 0.402655
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.307742
 >> iter 2000, loss: 14.361916
 >> iter 3000, loss: 10.884194
 >> iter 4000, loss: 9.126379
 >> iter 5000, loss: 8.679123
 >> iter 6000, loss: 8.317116
 >> iter 7000, loss: 8.222033
 >> iter 8000, loss: 7.835905
 >> iter 9000, loss: 7.797384
 >> iter 10000, loss: 6.294303
   Number of active neurons: 3
 >> iter 11000, loss: 5.448268
 >> iter 12000, loss: 4.822130
 >> iter 13000, loss: 4.585415
 >> iter 14000, loss: 4.481683
 >> iter 15000, loss: 4.464114
 >> iter 16000, loss: 4.311991
 >> iter 17000, loss: 3.614417
 >> iter 18000, loss: 3.044191
 >> iter 19000, loss: 2.588613
 >> iter 20000, loss: 2.558576
   Number of active neurons: 3
 >> iter 21000, loss: 2.527772
 >> iter 22000, loss: 2.410386
 >> iter 23000, loss: 2.395877
 >> iter 24000, loss: 2.371626
 >> iter 25000, loss: 2.457071
 >> iter 26000, loss: 2.337148
 >> iter 27000, loss: 2.428948
 >> iter 28000, loss: 2.247859
 >> iter 29000, loss: 2.313869
 >> iter 30000, loss: 2.308224
   Number of active neurons: 4
 >> iter 31000, loss: 2.283971
 >> iter 32000, loss: 2.195570
 >> iter 33000, loss: 2.352838
 >> iter 34000, loss: 2.234688
 >> iter 35000, loss: 2.203422
 >> iter 36000, loss: 2.294833
 >> iter 37000, loss: 2.363028
 >> iter 38000, loss: 2.401207
 >> iter 39000, loss: 2.422474
 >> iter 40000, loss: 2.336673
   Number of active neurons: 4
 >> iter 41000, loss: 2.377455
 >> iter 42000, loss: 2.354722
 >> iter 43000, loss: 2.362238
 >> iter 44000, loss: 2.379467
 >> iter 45000, loss: 2.356727
 >> iter 46000, loss: 2.311137
 >> iter 47000, loss: 2.402756
 >> iter 48000, loss: 2.336836
 >> iter 49000, loss: 2.294775
 >> iter 50000, loss: 2.269628
   Number of active neurons: 4
 >> iter 51000, loss: 2.202481
 >> iter 52000, loss: 2.231879
 >> iter 53000, loss: 2.402495
 >> iter 54000, loss: 2.376153
 >> iter 55000, loss: 2.285176
 >> iter 56000, loss: 2.366583
 >> iter 57000, loss: 2.384254
 >> iter 58000, loss: 2.413314
 >> iter 59000, loss: 2.351522
 >> iter 60000, loss: 2.264081
   Number of active neurons: 4
 >> iter 61000, loss: 2.274628
 >> iter 62000, loss: 2.343560
 >> iter 63000, loss: 2.378514
 >> iter 64000, loss: 2.339145
 >> iter 65000, loss: 2.203445
 >> iter 66000, loss: 2.285768
 >> iter 67000, loss: 2.290868
 >> iter 68000, loss: 2.529179
 >> iter 69000, loss: 2.451745
 >> iter 70000, loss: 2.400785
   Number of active neurons: 4
 >> iter 71000, loss: 2.346879
 >> iter 72000, loss: 2.293964
 >> iter 73000, loss: 2.440965
 >> iter 74000, loss: 2.327931
 >> iter 75000, loss: 2.252712
 >> iter 76000, loss: 2.324357
 >> iter 77000, loss: 2.308056
 >> iter 78000, loss: 2.389445
 >> iter 79000, loss: 2.437604
 >> iter 80000, loss: 2.503857
   Number of active neurons: 4
 >> iter 81000, loss: 2.410286
 >> iter 82000, loss: 2.498103
 >> iter 83000, loss: 2.297618
 >> iter 84000, loss: 2.432291
 >> iter 85000, loss: 2.347688
 >> iter 86000, loss: 2.393033
 >> iter 87000, loss: 2.529798
 >> iter 88000, loss: 2.397823
 >> iter 89000, loss: 2.332111
 >> iter 90000, loss: 2.510737
   Number of active neurons: 4
 >> iter 91000, loss: 2.367523
 >> iter 92000, loss: 2.458340
 >> iter 93000, loss: 2.351295
 >> iter 94000, loss: 2.277995
 >> iter 95000, loss: 2.373697
 >> iter 96000, loss: 2.372157
 >> iter 97000, loss: 2.282837
 >> iter 98000, loss: 2.206862
 >> iter 99000, loss: 2.296780
 >> iter 100000, loss: 2.352045
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 2.0039599208
   - Test - Long: 0.574971251437
   - Test - Big: 2.15597844022
   - Test - A: 0.0
   - Test - B: 14.8456769549
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.328551
 >> iter 2000, loss: 15.411103
 >> iter 3000, loss: 11.673190
 >> iter 4000, loss: 6.883553
 >> iter 5000, loss: 3.887768
 >> iter 6000, loss: 2.388598
 >> iter 7000, loss: 1.801683
 >> iter 8000, loss: 1.219527
 >> iter 9000, loss: 0.919882
 >> iter 10000, loss: 0.773769
   Number of active neurons: 4
 >> iter 11000, loss: 0.889345
 >> iter 12000, loss: 1.164983
 >> iter 13000, loss: 1.140062
 >> iter 14000, loss: 0.884030
 >> iter 15000, loss: 1.066146
 >> iter 16000, loss: 0.825433
 >> iter 17000, loss: 0.682781
 >> iter 18000, loss: 0.957736
 >> iter 19000, loss: 0.691969
 >> iter 20000, loss: 0.816432
   Number of active neurons: 4
 >> iter 21000, loss: 0.793895
 >> iter 22000, loss: 0.718478
 >> iter 23000, loss: 0.558757
 >> iter 24000, loss: 0.767948
 >> iter 25000, loss: 0.855898
 >> iter 26000, loss: 1.059384
 >> iter 27000, loss: 0.847893
 >> iter 28000, loss: 0.852762
 >> iter 29000, loss: 0.796376
 >> iter 30000, loss: 0.736182
   Number of active neurons: 4
 >> iter 31000, loss: 0.612093
 >> iter 32000, loss: 0.626726
 >> iter 33000, loss: 0.488843
 >> iter 34000, loss: 0.656605
 >> iter 35000, loss: 0.564368
 >> iter 36000, loss: 0.814316
 >> iter 37000, loss: 0.814581
 >> iter 38000, loss: 0.647514
 >> iter 39000, loss: 0.780297
 >> iter 40000, loss: 0.593154
   Number of active neurons: 4
 >> iter 41000, loss: 0.673224
 >> iter 42000, loss: 0.518823
 >> iter 43000, loss: 0.995238
 >> iter 44000, loss: 0.859648
 >> iter 45000, loss: 0.881717
 >> iter 46000, loss: 0.837402
 >> iter 47000, loss: 1.020791
 >> iter 48000, loss: 0.798714
 >> iter 49000, loss: 0.733229
 >> iter 50000, loss: 0.614321
   Number of active neurons: 4
 >> iter 51000, loss: 0.866505
 >> iter 52000, loss: 1.013828
 >> iter 53000, loss: 0.752909
 >> iter 54000, loss: 0.773655
 >> iter 55000, loss: 1.093387
 >> iter 56000, loss: 0.804434
 >> iter 57000, loss: 0.895688
 >> iter 58000, loss: 0.639705
 >> iter 59000, loss: 0.724586
 >> iter 60000, loss: 0.898592
   Number of active neurons: 4
 >> iter 61000, loss: 1.055966
 >> iter 62000, loss: 0.825827
 >> iter 63000, loss: 0.870006
 >> iter 64000, loss: 0.667045
 >> iter 65000, loss: 0.705752
 >> iter 66000, loss: 0.911110
 >> iter 67000, loss: 0.684482
 >> iter 68000, loss: 0.614629
 >> iter 69000, loss: 0.658954
 >> iter 70000, loss: 1.052948
   Number of active neurons: 4
 >> iter 71000, loss: 0.958221
 >> iter 72000, loss: 0.761818
 >> iter 73000, loss: 0.880370
 >> iter 74000, loss: 0.832622
 >> iter 75000, loss: 0.688938
 >> iter 76000, loss: 0.694801
 >> iter 77000, loss: 0.740100
 >> iter 78000, loss: 0.770725
 >> iter 79000, loss: 0.547997
 >> iter 80000, loss: 0.829429
   Number of active neurons: 4
 >> iter 81000, loss: 1.201983
 >> iter 82000, loss: 0.718896
 >> iter 83000, loss: 0.668504
 >> iter 84000, loss: 0.621033
 >> iter 85000, loss: 0.751693
 >> iter 86000, loss: 0.652393
 >> iter 87000, loss: 0.630639
 >> iter 88000, loss: 0.718243
 >> iter 89000, loss: 0.740453
 >> iter 90000, loss: 0.617486
   Number of active neurons: 4
 >> iter 91000, loss: 0.511664
 >> iter 92000, loss: 0.596467
 >> iter 93000, loss: 0.507752
 >> iter 94000, loss: 0.696047
 >> iter 95000, loss: 0.772778
 >> iter 96000, loss: 0.932816
 >> iter 97000, loss: 0.865070
 >> iter 98000, loss: 0.648476
 >> iter 99000, loss: 0.650090
 >> iter 100000, loss: 0.628652
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.339218
 >> iter 2000, loss: 15.666374
 >> iter 3000, loss: 13.996584
 >> iter 4000, loss: 12.545498
 >> iter 5000, loss: 11.291757
 >> iter 6000, loss: 9.923569
 >> iter 7000, loss: 9.686777
 >> iter 8000, loss: 8.865278
 >> iter 9000, loss: 9.001236
 >> iter 10000, loss: 8.525409
   Number of active neurons: 4
 >> iter 11000, loss: 7.370077
 >> iter 12000, loss: 5.535233
 >> iter 13000, loss: 3.949324
 >> iter 14000, loss: 3.162319
 >> iter 15000, loss: 2.900572
 >> iter 16000, loss: 2.645780
 >> iter 17000, loss: 2.837135
 >> iter 18000, loss: 2.549960
 >> iter 19000, loss: 2.720469
 >> iter 20000, loss: 2.427103
   Number of active neurons: 4
 >> iter 21000, loss: 2.556375
 >> iter 22000, loss: 2.654710
 >> iter 23000, loss: 2.701698
 >> iter 24000, loss: 2.425220
 >> iter 25000, loss: 2.289274
 >> iter 26000, loss: 2.410640
 >> iter 27000, loss: 2.434405
 >> iter 28000, loss: 2.465540
 >> iter 29000, loss: 2.592712
 >> iter 30000, loss: 2.497145
   Number of active neurons: 4
 >> iter 31000, loss: 2.529586
 >> iter 32000, loss: 2.489728
 >> iter 33000, loss: 2.456354
 >> iter 34000, loss: 2.313241
 >> iter 35000, loss: 2.502925
 >> iter 36000, loss: 2.528388
 >> iter 37000, loss: 2.557132
 >> iter 38000, loss: 2.586252
 >> iter 39000, loss: 2.443091
 >> iter 40000, loss: 2.390225
   Number of active neurons: 4
 >> iter 41000, loss: 2.478579
 >> iter 42000, loss: 2.530573
 >> iter 43000, loss: 2.455798
 >> iter 44000, loss: 2.523753
 >> iter 45000, loss: 2.306590
 >> iter 46000, loss: 2.232574
 >> iter 47000, loss: 2.492676
 >> iter 48000, loss: 2.312975
 >> iter 49000, loss: 2.424912
 >> iter 50000, loss: 2.201520
   Number of active neurons: 4
 >> iter 51000, loss: 2.155084
 >> iter 52000, loss: 2.237042
 >> iter 53000, loss: 2.267550
 >> iter 54000, loss: 2.122779
 >> iter 55000, loss: 2.254166
 >> iter 56000, loss: 2.157062
 >> iter 57000, loss: 2.413098
 >> iter 58000, loss: 2.453614
 >> iter 59000, loss: 2.328206
 >> iter 60000, loss: 2.318908
   Number of active neurons: 4
 >> iter 61000, loss: 2.395428
 >> iter 62000, loss: 2.241361
 >> iter 63000, loss: 2.169451
 >> iter 64000, loss: 2.298898
 >> iter 65000, loss: 2.328589
 >> iter 66000, loss: 2.506670
 >> iter 67000, loss: 2.492347
 >> iter 68000, loss: 2.354082
 >> iter 69000, loss: 2.484279
 >> iter 70000, loss: 2.350524
   Number of active neurons: 4
 >> iter 71000, loss: 2.438422
 >> iter 72000, loss: 2.368880
 >> iter 73000, loss: 2.276380
 >> iter 74000, loss: 2.456529
 >> iter 75000, loss: 2.483482
 >> iter 76000, loss: 2.334681
 >> iter 77000, loss: 2.375596
 >> iter 78000, loss: 2.312653
 >> iter 79000, loss: 2.142086
 >> iter 80000, loss: 2.643014
   Number of active neurons: 4
 >> iter 81000, loss: 2.523195
 >> iter 82000, loss: 2.579401
 >> iter 83000, loss: 2.480258
 >> iter 84000, loss: 2.529985
 >> iter 85000, loss: 2.299963
 >> iter 86000, loss: 2.358794
 >> iter 87000, loss: 2.215968
 >> iter 88000, loss: 2.433966
 >> iter 89000, loss: 2.658910
 >> iter 90000, loss: 2.738656
   Number of active neurons: 4
 >> iter 91000, loss: 2.267348
 >> iter 92000, loss: 2.302907
 >> iter 93000, loss: 2.384735
 >> iter 94000, loss: 2.369747
 >> iter 95000, loss: 2.342111
 >> iter 96000, loss: 2.375560
 >> iter 97000, loss: 2.268207
 >> iter 98000, loss: 2.507751
 >> iter 99000, loss: 2.291445
 >> iter 100000, loss: 2.513629
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.29999400012
   - Test - Long: 0.069996500175
   - Test - Big: 0.424995750042
   - Test - A: 0.0
   - Test - B: 14.3857076195
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.251072
 >> iter 2000, loss: 14.206752
 >> iter 3000, loss: 11.823246
 >> iter 4000, loss: 10.537949
 >> iter 5000, loss: 10.218668
 >> iter 6000, loss: 9.721410
 >> iter 7000, loss: 9.713444
 >> iter 8000, loss: 9.397024
 >> iter 9000, loss: 9.527230
 >> iter 10000, loss: 9.213458
   Number of active neurons: 3
 >> iter 11000, loss: 7.897422
 >> iter 12000, loss: 5.329692
 >> iter 13000, loss: 4.191711
 >> iter 14000, loss: 3.121477
 >> iter 15000, loss: 2.366447
 >> iter 16000, loss: 1.689445
 >> iter 17000, loss: 1.019664
 >> iter 18000, loss: 0.602939
 >> iter 19000, loss: 0.450003
 >> iter 20000, loss: 0.422665
   Number of active neurons: 4
 >> iter 21000, loss: 0.420090
 >> iter 22000, loss: 0.430305
 >> iter 23000, loss: 0.410853
 >> iter 24000, loss: 0.250846
 >> iter 25000, loss: 0.359153
 >> iter 26000, loss: 0.318797
 >> iter 27000, loss: 0.371554
 >> iter 28000, loss: 0.407255
 >> iter 29000, loss: 0.463853
 >> iter 30000, loss: 0.371679
   Number of active neurons: 4
 >> iter 31000, loss: 0.353165
 >> iter 32000, loss: 0.368421
 >> iter 33000, loss: 0.283447
 >> iter 34000, loss: 0.294275
 >> iter 35000, loss: 0.385929
 >> iter 36000, loss: 0.227545
 >> iter 37000, loss: 0.240491
 >> iter 38000, loss: 0.195502
 >> iter 39000, loss: 0.537676
 >> iter 40000, loss: 0.538852
   Number of active neurons: 4
 >> iter 41000, loss: 0.446392
 >> iter 42000, loss: 0.332902
 >> iter 43000, loss: 0.419392
 >> iter 44000, loss: 0.319910
 >> iter 45000, loss: 0.255984
 >> iter 46000, loss: 0.352931
 >> iter 47000, loss: 0.211891
 >> iter 48000, loss: 0.296085
 >> iter 49000, loss: 0.447384
 >> iter 50000, loss: 0.357331
   Number of active neurons: 4
 >> iter 51000, loss: 0.234955
 >> iter 52000, loss: 0.288274
 >> iter 53000, loss: 0.378035
 >> iter 54000, loss: 0.267648
 >> iter 55000, loss: 0.230115
 >> iter 56000, loss: 0.387332
 >> iter 57000, loss: 0.371556
 >> iter 58000, loss: 0.385363
 >> iter 59000, loss: 0.454032
 >> iter 60000, loss: 0.390310
   Number of active neurons: 4
 >> iter 61000, loss: 0.281339
 >> iter 62000, loss: 0.216670
 >> iter 63000, loss: 0.215619
 >> iter 64000, loss: 0.146493
 >> iter 65000, loss: 0.163787
 >> iter 66000, loss: 0.254614
 >> iter 67000, loss: 0.219442
 >> iter 68000, loss: 0.304720
 >> iter 69000, loss: 0.307536
 >> iter 70000, loss: 0.344723
   Number of active neurons: 4
 >> iter 71000, loss: 0.440291
 >> iter 72000, loss: 0.306950
 >> iter 73000, loss: 0.303317
 >> iter 74000, loss: 0.361476
 >> iter 75000, loss: 0.404099
 >> iter 76000, loss: 0.301183
 >> iter 77000, loss: 0.335337
 >> iter 78000, loss: 0.269276
 >> iter 79000, loss: 0.270497
 >> iter 80000, loss: 0.256364
   Number of active neurons: 4
 >> iter 81000, loss: 0.340357
 >> iter 82000, loss: 0.283101
 >> iter 83000, loss: 0.323695
 >> iter 84000, loss: 0.338811
 >> iter 85000, loss: 0.402904
 >> iter 86000, loss: 0.392643
 >> iter 87000, loss: 0.255754
 >> iter 88000, loss: 0.398223
 >> iter 89000, loss: 0.294529
 >> iter 90000, loss: 0.246285
   Number of active neurons: 4
 >> iter 91000, loss: 0.256868
 >> iter 92000, loss: 0.306949
 >> iter 93000, loss: 0.298320
 >> iter 94000, loss: 0.316754
 >> iter 95000, loss: 0.306373
 >> iter 96000, loss: 0.297499
 >> iter 97000, loss: 0.186561
 >> iter 98000, loss: 0.163628
 >> iter 99000, loss: 0.309122
 >> iter 100000, loss: 0.268546
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.224122
 >> iter 2000, loss: 10.407445
 >> iter 3000, loss: 4.795777
 >> iter 4000, loss: 2.413943
 >> iter 5000, loss: 1.516659
 >> iter 6000, loss: 0.760998
 >> iter 7000, loss: 0.691711
 >> iter 8000, loss: 0.503011
 >> iter 9000, loss: 0.490686
 >> iter 10000, loss: 0.548089
   Number of active neurons: 4
 >> iter 11000, loss: 0.416153
 >> iter 12000, loss: 0.501138
 >> iter 13000, loss: 0.442862
 >> iter 14000, loss: 0.467708
 >> iter 15000, loss: 0.520573
 >> iter 16000, loss: 0.271602
 >> iter 17000, loss: 0.316107
 >> iter 18000, loss: 0.227085
 >> iter 19000, loss: 0.269756
 >> iter 20000, loss: 0.585357
   Number of active neurons: 4
 >> iter 21000, loss: 0.473462
 >> iter 22000, loss: 0.483337
 >> iter 23000, loss: 0.584206
 >> iter 24000, loss: 0.390221
 >> iter 25000, loss: 0.549248
 >> iter 26000, loss: 0.497787
 >> iter 27000, loss: 0.430544
 >> iter 28000, loss: 0.411197
 >> iter 29000, loss: 0.338171
 >> iter 30000, loss: 0.376344
   Number of active neurons: 4
 >> iter 31000, loss: 0.411790
 >> iter 32000, loss: 0.350924
 >> iter 33000, loss: 0.387443
 >> iter 34000, loss: 0.362729
 >> iter 35000, loss: 0.389720
 >> iter 36000, loss: 0.456107
 >> iter 37000, loss: 0.544227
 >> iter 38000, loss: 0.377733
 >> iter 39000, loss: 0.275923
 >> iter 40000, loss: 0.406264
   Number of active neurons: 4
 >> iter 41000, loss: 0.429870
 >> iter 42000, loss: 0.334500
 >> iter 43000, loss: 0.477956
 >> iter 44000, loss: 0.469314
 >> iter 45000, loss: 0.493513
 >> iter 46000, loss: 0.326644
 >> iter 47000, loss: 0.486042
 >> iter 48000, loss: 0.358377
 >> iter 49000, loss: 0.321057
 >> iter 50000, loss: 0.360744
   Number of active neurons: 4
 >> iter 51000, loss: 0.208888
 >> iter 52000, loss: 0.192985
 >> iter 53000, loss: 0.286652
 >> iter 54000, loss: 0.415549
 >> iter 55000, loss: 0.380254
 >> iter 56000, loss: 0.266243
 >> iter 57000, loss: 0.267904
 >> iter 58000, loss: 0.386052
 >> iter 59000, loss: 0.334374
 >> iter 60000, loss: 0.388873
   Number of active neurons: 4
 >> iter 61000, loss: 0.265586
 >> iter 62000, loss: 0.313348
 >> iter 63000, loss: 0.548260
 >> iter 64000, loss: 0.403770
 >> iter 65000, loss: 0.286980
 >> iter 66000, loss: 0.261128
 >> iter 67000, loss: 0.329894
 >> iter 68000, loss: 0.401059
 >> iter 69000, loss: 0.339686
 >> iter 70000, loss: 0.190776
   Number of active neurons: 4
 >> iter 71000, loss: 0.288391
 >> iter 72000, loss: 0.366972
 >> iter 73000, loss: 0.318639
 >> iter 74000, loss: 0.370423
 >> iter 75000, loss: 0.444032
 >> iter 76000, loss: 0.301882
 >> iter 77000, loss: 0.277743
 >> iter 78000, loss: 0.260501
 >> iter 79000, loss: 0.385864
 >> iter 80000, loss: 0.235056
   Number of active neurons: 4
 >> iter 81000, loss: 0.489739
 >> iter 82000, loss: 0.465163
 >> iter 83000, loss: 0.349327
 >> iter 84000, loss: 0.257282
 >> iter 85000, loss: 0.214115
 >> iter 86000, loss: 0.256897
 >> iter 87000, loss: 0.223885
 >> iter 88000, loss: 0.274719
 >> iter 89000, loss: 0.306731
 >> iter 90000, loss: 0.285102
   Number of active neurons: 4
 >> iter 91000, loss: 0.375390
 >> iter 92000, loss: 0.498680
 >> iter 93000, loss: 0.466661
 >> iter 94000, loss: 0.314915
 >> iter 95000, loss: 0.316202
 >> iter 96000, loss: 0.293450
 >> iter 97000, loss: 0.370187
 >> iter 98000, loss: 0.390618
 >> iter 99000, loss: 0.302325
 >> iter 100000, loss: 0.250276
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 21.128756
 >> iter 2000, loss: 18.814849
 >> iter 3000, loss: 17.949898
 >> iter 4000, loss: 17.646805
 >> iter 5000, loss: 17.518601
 >> iter 6000, loss: 17.489517
 >> iter 7000, loss: 17.461453
 >> iter 8000, loss: 17.468087
 >> iter 9000, loss: 17.452693
 >> iter 10000, loss: 17.464687
   Number of active neurons: 0
 >> iter 11000, loss: 17.448629
 >> iter 12000, loss: 17.463661
 >> iter 13000, loss: 17.450072
 >> iter 14000, loss: 17.463729
 >> iter 15000, loss: 17.448758
 >> iter 16000, loss: 17.465579
 >> iter 17000, loss: 17.449689
 >> iter 18000, loss: 17.465422
 >> iter 19000, loss: 17.453755
 >> iter 20000, loss: 17.465505
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 17.455773
 >> iter 22000, loss: 17.465319
 >> iter 23000, loss: 17.456405
 >> iter 24000, loss: 17.465366
 >> iter 25000, loss: 17.456218
 >> iter 26000, loss: 17.465298
 >> iter 27000, loss: 17.454742
 >> iter 28000, loss: 17.465414
 >> iter 29000, loss: 17.452961
 >> iter 30000, loss: 17.465324
   Number of active neurons: 0
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 0
 >> iter 31000, loss: 17.453604
 >> iter 32000, loss: 17.465140
 >> iter 33000, loss: 17.454996
 >> iter 34000, loss: 17.464568
 >> iter 35000, loss: 17.456285
 >> iter 36000, loss: 17.463901
 >> iter 37000, loss: 17.456184
 >> iter 38000, loss: 17.462671
 >> iter 39000, loss: 17.456154
 >> iter 40000, loss: 17.459890
   Number of active neurons: 0
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 0
 >> iter 41000, loss: 17.456149
 >> iter 42000, loss: 17.455974
 >> iter 43000, loss: 17.456007
 >> iter 44000, loss: 17.454356
 >> iter 45000, loss: 17.455712
 >> iter 46000, loss: 17.451628
 >> iter 47000, loss: 17.454089
 >> iter 48000, loss: 17.451116
 >> iter 49000, loss: 17.452667
 >> iter 50000, loss: 17.453474
   Number of active neurons: 0
 >> iter 51000, loss: 17.451413
 >> iter 52000, loss: 17.450946
 >> iter 53000, loss: 17.448549
 >> iter 54000, loss: 17.454785
 >> iter 55000, loss: 17.446046
 >> iter 56000, loss: 17.458664
 >> iter 57000, loss: 17.448209
 >> iter 58000, loss: 17.460141
 >> iter 59000, loss: 17.443139
 >> iter 60000, loss: 17.458078
   Number of active neurons: 0
   SHOCK
   Setting new limit to 287500.0 iters...
   Number of active neurons: 0
 >> iter 61000, loss: 17.443124
 >> iter 62000, loss: 17.453952
 >> iter 63000, loss: 17.448643
 >> iter 64000, loss: 17.451978
 >> iter 65000, loss: 17.452108
 >> iter 66000, loss: 17.448857
 >> iter 67000, loss: 17.450274
 >> iter 68000, loss: 17.444185
 >> iter 69000, loss: 17.448448
 >> iter 70000, loss: 17.440344
   Number of active neurons: 0
 >> iter 71000, loss: 17.451062
 >> iter 72000, loss: 17.437056
 >> iter 73000, loss: 17.454775
 >> iter 74000, loss: 17.432099
 >> iter 75000, loss: 17.453164
   Number of active neurons: 0
   SHOCK
   Setting new limit to 293750.0 iters...
 >> iter 76000, loss: 17.432127
 >> iter 77000, loss: 17.450032
 >> iter 78000, loss: 17.433664
 >> iter 79000, loss: 17.449875
 >> iter 80000, loss: 17.437777
   Number of active neurons: 0
 >> iter 81000, loss: 17.455305
 >> iter 82000, loss: 17.436050
 >> iter 83000, loss: 17.457681
 >> iter 84000, loss: 17.439496
 >> iter 85000, loss: 17.459927
   Number of active neurons: 0
   SHOCK
   Setting new limit to 296875.0 iters...
 >> iter 86000, loss: 17.438394
 >> iter 87000, loss: 17.459256
 >> iter 88000, loss: 17.439496
 >> iter 89000, loss: 17.457920
 >> iter 90000, loss: 17.437475
   Number of active neurons: 0
 >> iter 91000, loss: 17.458540
 >> iter 92000, loss: 17.434804
 >> iter 93000, loss: 17.456802
 >> iter 94000, loss: 17.441982
 >> iter 95000, loss: 17.456522
   Number of active neurons: 0
   SHOCK
   Setting new limit to 298437.5 iters...
 >> iter 96000, loss: 17.439914
 >> iter 97000, loss: 17.459823
 >> iter 98000, loss: 17.435026
 >> iter 99000, loss: 17.457930
 >> iter 100000, loss: 17.437143
   Number of active neurons: 0
 >> iter 101000, loss: 17.455686
 >> iter 102000, loss: 17.434422
 >> iter 103000, loss: 17.456761
 >> iter 104000, loss: 17.436351
 >> iter 105000, loss: 17.457172
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299218.75 iters...
 >> iter 106000, loss: 17.436779
 >> iter 107000, loss: 17.453669
 >> iter 108000, loss: 17.440706
 >> iter 109000, loss: 17.453824
 >> iter 110000, loss: 17.441159
   Number of active neurons: 0
 >> iter 111000, loss: 17.453909
 >> iter 112000, loss: 17.441775
 >> iter 113000, loss: 17.450750
 >> iter 114000, loss: 17.441249
 >> iter 115000, loss: 17.448867
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299609.375 iters...
 >> iter 116000, loss: 17.441717
 >> iter 117000, loss: 17.450647
 >> iter 118000, loss: 17.440279
 >> iter 119000, loss: 17.450024
 >> iter 120000, loss: 17.440579
   Number of active neurons: 0
 >> iter 121000, loss: 17.447116
 >> iter 122000, loss: 17.439549
 >> iter 123000, loss: 17.445549
 >> iter 124000, loss: 17.440491
 >> iter 125000, loss: 17.448546
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299804.6875 iters...
 >> iter 126000, loss: 17.441722
 >> iter 127000, loss: 17.448746
 >> iter 128000, loss: 17.440538
 >> iter 129000, loss: 17.447756
 >> iter 130000, loss: 17.438074
   Number of active neurons: 0
 >> iter 131000, loss: 17.450295
 >> iter 132000, loss: 17.436533
 >> iter 133000, loss: 17.449707
 >> iter 134000, loss: 17.438250
 >> iter 135000, loss: 17.449419
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299902.34375 iters...
 >> iter 136000, loss: 17.441998
 >> iter 137000, loss: 17.448828
 >> iter 138000, loss: 17.441713
 >> iter 139000, loss: 17.447291
 >> iter 140000, loss: 17.444150
   Number of active neurons: 0
 >> iter 141000, loss: 17.442829
 >> iter 142000, loss: 17.444393
 >> iter 143000, loss: 17.444651
 >> iter 144000, loss: 17.444284
 >> iter 145000, loss: 17.449412
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299951.171875 iters...
 >> iter 146000, loss: 17.444160
 >> iter 147000, loss: 17.450538
 >> iter 148000, loss: 17.444734
 >> iter 149000, loss: 17.452825
 >> iter 150000, loss: 17.444613
   Number of active neurons: 0
 >> iter 151000, loss: 17.452344
 >> iter 152000, loss: 17.444022
 >> iter 153000, loss: 17.454187
 >> iter 154000, loss: 17.446389
 >> iter 155000, loss: 17.454042
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299975.585938 iters...
 >> iter 156000, loss: 17.446252
 >> iter 157000, loss: 17.453963
 >> iter 158000, loss: 17.446026
 >> iter 159000, loss: 17.454249
 >> iter 160000, loss: 17.446642
   Number of active neurons: 0
 >> iter 161000, loss: 17.453791
 >> iter 162000, loss: 17.446521
 >> iter 163000, loss: 17.453357
 >> iter 164000, loss: 17.446396
 >> iter 165000, loss: 17.452512
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299987.792969 iters...
 >> iter 166000, loss: 17.446073
 >> iter 167000, loss: 17.451457
 >> iter 168000, loss: 17.446066
 >> iter 169000, loss: 17.449311
 >> iter 170000, loss: 17.446325
   Number of active neurons: 0
 >> iter 171000, loss: 17.450324
 >> iter 172000, loss: 17.446266
 >> iter 173000, loss: 17.450704
 >> iter 174000, loss: 17.446297
 >> iter 175000, loss: 17.451241
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299993.896484 iters...
 >> iter 176000, loss: 17.446185
 >> iter 177000, loss: 17.449017
 >> iter 178000, loss: 17.446391
 >> iter 179000, loss: 17.450928
 >> iter 180000, loss: 17.446232
   Number of active neurons: 0
 >> iter 181000, loss: 17.451909
 >> iter 182000, loss: 17.445479
 >> iter 183000, loss: 17.451770
 >> iter 184000, loss: 17.445672
 >> iter 185000, loss: 17.452723
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299996.948242 iters...
 >> iter 186000, loss: 17.445644
 >> iter 187000, loss: 17.452698
 >> iter 188000, loss: 17.445424
 >> iter 189000, loss: 17.452555
 >> iter 190000, loss: 17.444260
   Number of active neurons: 0
 >> iter 191000, loss: 17.453037
 >> iter 192000, loss: 17.443156
 >> iter 193000, loss: 17.452832
 >> iter 194000, loss: 17.442293
 >> iter 195000, loss: 17.452912
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299998.474121 iters...
 >> iter 196000, loss: 17.443628
 >> iter 197000, loss: 17.452635
 >> iter 198000, loss: 17.442447
 >> iter 199000, loss: 17.452927
 >> iter 200000, loss: 17.443078
   Number of active neurons: 0
 >> iter 201000, loss: 17.452793
 >> iter 202000, loss: 17.444912
 >> iter 203000, loss: 17.452783
 >> iter 204000, loss: 17.444649
 >> iter 205000, loss: 17.452980
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.237061 iters...
 >> iter 206000, loss: 17.444528
 >> iter 207000, loss: 17.452548
 >> iter 208000, loss: 17.445530
 >> iter 209000, loss: 17.452897
 >> iter 210000, loss: 17.445766
   Number of active neurons: 0
 >> iter 211000, loss: 17.452665
 >> iter 212000, loss: 17.445630
 >> iter 213000, loss: 17.452094
 >> iter 214000, loss: 17.445432
 >> iter 215000, loss: 17.451801
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.61853 iters...
 >> iter 216000, loss: 17.445044
 >> iter 217000, loss: 17.451123
 >> iter 218000, loss: 17.445063
 >> iter 219000, loss: 17.449635
 >> iter 220000, loss: 17.443890
   Number of active neurons: 0
 >> iter 221000, loss: 17.450036
 >> iter 222000, loss: 17.443165
 >> iter 223000, loss: 17.450596
 >> iter 224000, loss: 17.441836
 >> iter 225000, loss: 17.451834
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.809265 iters...
 >> iter 226000, loss: 17.441234
 >> iter 227000, loss: 17.451936
 >> iter 228000, loss: 17.437180
 >> iter 229000, loss: 17.451868
 >> iter 230000, loss: 17.433902
   Number of active neurons: 0
 >> iter 231000, loss: 17.452171
 >> iter 232000, loss: 17.439346
 >> iter 233000, loss: 17.451721
 >> iter 234000, loss: 17.442296
 >> iter 235000, loss: 17.451735
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.904633 iters...
 >> iter 236000, loss: 17.443070
 >> iter 237000, loss: 17.452411
 >> iter 238000, loss: 17.442234
 >> iter 239000, loss: 17.452214
 >> iter 240000, loss: 17.438561
   Number of active neurons: 0
 >> iter 241000, loss: 17.452490
 >> iter 242000, loss: 17.439990
 >> iter 243000, loss: 17.452122
 >> iter 244000, loss: 17.436320
 >> iter 245000, loss: 17.451499
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.952316 iters...
 >> iter 246000, loss: 17.436117
 >> iter 247000, loss: 17.452968
 >> iter 248000, loss: 17.440552
 >> iter 249000, loss: 17.452824
 >> iter 250000, loss: 17.440266
   Number of active neurons: 0
 >> iter 251000, loss: 17.452492
 >> iter 252000, loss: 17.439697
 >> iter 253000, loss: 17.453283
 >> iter 254000, loss: 17.439415
 >> iter 255000, loss: 17.452984
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.976158 iters...
 >> iter 256000, loss: 17.440874
 >> iter 257000, loss: 17.452451
 >> iter 258000, loss: 17.439637
 >> iter 259000, loss: 17.451413
 >> iter 260000, loss: 17.439354
   Number of active neurons: 0
 >> iter 261000, loss: 17.448658
 >> iter 262000, loss: 17.439068
 >> iter 263000, loss: 17.446920
 >> iter 264000, loss: 17.440735
 >> iter 265000, loss: 17.448922
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.988079 iters...
 >> iter 266000, loss: 17.439559
 >> iter 267000, loss: 17.450332
 >> iter 268000, loss: 17.440946
 >> iter 269000, loss: 17.449793
 >> iter 270000, loss: 17.441024
   Number of active neurons: 0
 >> iter 271000, loss: 17.449493
 >> iter 272000, loss: 17.441932
 >> iter 273000, loss: 17.447150
 >> iter 274000, loss: 17.441942
 >> iter 275000, loss: 17.447957
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99404 iters...
 >> iter 276000, loss: 17.441807
 >> iter 277000, loss: 17.451319
 >> iter 278000, loss: 17.441501
 >> iter 279000, loss: 17.451389
 >> iter 280000, loss: 17.441373
   Number of active neurons: 0
 >> iter 281000, loss: 17.451410
 >> iter 282000, loss: 17.441360
 >> iter 283000, loss: 17.451753
 >> iter 284000, loss: 17.440589
 >> iter 285000, loss: 17.451195
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99702 iters...
 >> iter 286000, loss: 17.440113
 >> iter 287000, loss: 17.452142
 >> iter 288000, loss: 17.438519
 >> iter 289000, loss: 17.452251
 >> iter 290000, loss: 17.437612
   Number of active neurons: 0
 >> iter 291000, loss: 17.452173
 >> iter 292000, loss: 17.437705
 >> iter 293000, loss: 17.451753
 >> iter 294000, loss: 17.440267
 >> iter 295000, loss: 17.450156
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99851 iters...
 >> iter 296000, loss: 17.439548
 >> iter 297000, loss: 17.450595
 >> iter 298000, loss: 17.437966
 >> iter 299000, loss: 17.449371
 >> iter 300000, loss: 17.440566
   Number of active neurons: 0
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 48.6410271795
   - Test - Long: 92.6053697315
   - Test - Big: 49.4625053749
   - Test - A: 28.5580961269
   - Test - B: 30.8046130258
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.799215
 >> iter 2000, loss: 16.464301
 >> iter 3000, loss: 15.203289
 >> iter 4000, loss: 14.075116
 >> iter 5000, loss: 14.253137
 >> iter 6000, loss: 14.150061
 >> iter 7000, loss: 12.899957
 >> iter 8000, loss: 9.823481
 >> iter 9000, loss: 7.204721
 >> iter 10000, loss: 5.873864
   Number of active neurons: 4
 >> iter 11000, loss: 5.157681
 >> iter 12000, loss: 4.020438
 >> iter 13000, loss: 3.450996
 >> iter 14000, loss: 3.292228
 >> iter 15000, loss: 2.984955
 >> iter 16000, loss: 2.932663
 >> iter 17000, loss: 2.929223
 >> iter 18000, loss: 2.742408
 >> iter 19000, loss: 2.365539
 >> iter 20000, loss: 2.254947
   Number of active neurons: 4
 >> iter 21000, loss: 2.504475
 >> iter 22000, loss: 2.464939
 >> iter 23000, loss: 2.533827
 >> iter 24000, loss: 2.448586
 >> iter 25000, loss: 2.423840
 >> iter 26000, loss: 1.413961
 >> iter 27000, loss: 0.826019
 >> iter 28000, loss: 0.496158
 >> iter 29000, loss: 0.290400
 >> iter 30000, loss: 0.205260
   Number of active neurons: 4
 >> iter 31000, loss: 0.336379
 >> iter 32000, loss: 0.329521
 >> iter 33000, loss: 0.302681
 >> iter 34000, loss: 0.336363
 >> iter 35000, loss: 0.369636
 >> iter 36000, loss: 0.320209
 >> iter 37000, loss: 0.474097
 >> iter 38000, loss: 0.372771
 >> iter 39000, loss: 0.307262
 >> iter 40000, loss: 0.323820
   Number of active neurons: 4
 >> iter 41000, loss: 0.364385
 >> iter 42000, loss: 0.293756
 >> iter 43000, loss: 0.357104
 >> iter 44000, loss: 0.339043
 >> iter 45000, loss: 0.271872
 >> iter 46000, loss: 0.328364
 >> iter 47000, loss: 0.450530
 >> iter 48000, loss: 0.405450
 >> iter 49000, loss: 0.365154
 >> iter 50000, loss: 0.296817
   Number of active neurons: 4
 >> iter 51000, loss: 0.431363
 >> iter 52000, loss: 0.476514
 >> iter 53000, loss: 0.381028
 >> iter 54000, loss: 0.326044
 >> iter 55000, loss: 0.444829
 >> iter 56000, loss: 0.334395
 >> iter 57000, loss: 0.301766
 >> iter 58000, loss: 0.226399
 >> iter 59000, loss: 0.298385
 >> iter 60000, loss: 0.411575
   Number of active neurons: 4
 >> iter 61000, loss: 0.297340
 >> iter 62000, loss: 0.449432
 >> iter 63000, loss: 0.460494
 >> iter 64000, loss: 0.459393
 >> iter 65000, loss: 0.315265
 >> iter 66000, loss: 0.223517
 >> iter 67000, loss: 0.405826
 >> iter 68000, loss: 0.294392
 >> iter 69000, loss: 0.462769
 >> iter 70000, loss: 0.341208
   Number of active neurons: 4
 >> iter 71000, loss: 0.344456
 >> iter 72000, loss: 0.446775
 >> iter 73000, loss: 0.477700
 >> iter 74000, loss: 0.285656
 >> iter 75000, loss: 0.318858
 >> iter 76000, loss: 0.368568
 >> iter 77000, loss: 0.481359
 >> iter 78000, loss: 0.407550
 >> iter 79000, loss: 0.446927
 >> iter 80000, loss: 0.383078
   Number of active neurons: 4
 >> iter 81000, loss: 0.506110
 >> iter 82000, loss: 0.435229
 >> iter 83000, loss: 0.397016
 >> iter 84000, loss: 0.509357
 >> iter 85000, loss: 0.401293
 >> iter 86000, loss: 0.270237
 >> iter 87000, loss: 0.429756
 >> iter 88000, loss: 0.379130
 >> iter 89000, loss: 0.403917
 >> iter 90000, loss: 0.466790
   Number of active neurons: 4
 >> iter 91000, loss: 0.535798
 >> iter 92000, loss: 0.358151
 >> iter 93000, loss: 0.486684
 >> iter 94000, loss: 0.334370
 >> iter 95000, loss: 0.305242
 >> iter 96000, loss: 0.334472
 >> iter 97000, loss: 0.258387
 >> iter 98000, loss: 0.321027
 >> iter 99000, loss: 0.456094
 >> iter 100000, loss: 0.370280
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.764310
 >> iter 2000, loss: 12.215641
 >> iter 3000, loss: 8.427993
 >> iter 4000, loss: 6.501158
 >> iter 5000, loss: 5.966485
 >> iter 6000, loss: 5.834068
 >> iter 7000, loss: 5.832490
 >> iter 8000, loss: 5.505280
 >> iter 9000, loss: 5.332116
 >> iter 10000, loss: 5.032110
   Number of active neurons: 4
 >> iter 11000, loss: 3.019390
 >> iter 12000, loss: 2.007499
 >> iter 13000, loss: 1.281283
 >> iter 14000, loss: 0.773787
 >> iter 15000, loss: 0.593497
 >> iter 16000, loss: 0.477340
 >> iter 17000, loss: 0.800375
 >> iter 18000, loss: 0.563595
 >> iter 19000, loss: 0.466887
 >> iter 20000, loss: 0.468246
   Number of active neurons: 4
 >> iter 21000, loss: 0.599393
 >> iter 22000, loss: 0.823551
 >> iter 23000, loss: 0.666736
 >> iter 24000, loss: 0.642028
 >> iter 25000, loss: 0.702694
 >> iter 26000, loss: 0.564190
 >> iter 27000, loss: 0.617660
 >> iter 28000, loss: 0.547881
 >> iter 29000, loss: 0.406463
 >> iter 30000, loss: 0.409603
   Number of active neurons: 4
 >> iter 31000, loss: 0.625824
 >> iter 32000, loss: 0.533331
 >> iter 33000, loss: 0.476983
 >> iter 34000, loss: 0.556625
 >> iter 35000, loss: 0.532581
 >> iter 36000, loss: 0.377650
 >> iter 37000, loss: 0.602190
 >> iter 38000, loss: 0.486531
 >> iter 39000, loss: 0.489047
 >> iter 40000, loss: 0.515107
   Number of active neurons: 4
 >> iter 41000, loss: 0.461982
 >> iter 42000, loss: 0.505221
 >> iter 43000, loss: 0.457679
 >> iter 44000, loss: 0.554155
 >> iter 45000, loss: 0.458402
 >> iter 46000, loss: 0.567774
 >> iter 47000, loss: 0.390572
 >> iter 48000, loss: 0.341654
 >> iter 49000, loss: 0.351954
 >> iter 50000, loss: 0.564947
   Number of active neurons: 4
 >> iter 51000, loss: 0.636851
 >> iter 52000, loss: 0.458707
 >> iter 53000, loss: 0.500003
 >> iter 54000, loss: 0.439462
 >> iter 55000, loss: 0.354184
 >> iter 56000, loss: 0.290655
 >> iter 57000, loss: 0.348518
 >> iter 58000, loss: 0.423628
 >> iter 59000, loss: 0.368077
 >> iter 60000, loss: 0.342821
   Number of active neurons: 4
 >> iter 61000, loss: 0.448100
 >> iter 62000, loss: 0.529590
 >> iter 63000, loss: 0.513242
 >> iter 64000, loss: 0.585918
 >> iter 65000, loss: 0.513534
 >> iter 66000, loss: 0.635442
 >> iter 67000, loss: 0.415666
 >> iter 68000, loss: 0.428811
 >> iter 69000, loss: 0.350878
 >> iter 70000, loss: 0.472831
   Number of active neurons: 4
 >> iter 71000, loss: 0.556516
 >> iter 72000, loss: 0.506960
 >> iter 73000, loss: 0.388893
 >> iter 74000, loss: 0.444653
 >> iter 75000, loss: 0.471849
 >> iter 76000, loss: 0.483298
 >> iter 77000, loss: 0.512347
 >> iter 78000, loss: 0.455798
 >> iter 79000, loss: 0.441271
 >> iter 80000, loss: 0.471493
   Number of active neurons: 4
 >> iter 81000, loss: 0.510413
 >> iter 82000, loss: 0.469996
 >> iter 83000, loss: 0.323744
 >> iter 84000, loss: 0.366488
 >> iter 85000, loss: 0.599271
 >> iter 86000, loss: 0.575501
 >> iter 87000, loss: 0.485532
 >> iter 88000, loss: 0.373415
 >> iter 89000, loss: 0.464890
 >> iter 90000, loss: 0.409946
   Number of active neurons: 4
 >> iter 91000, loss: 0.605516
 >> iter 92000, loss: 0.429981
 >> iter 93000, loss: 0.567256
 >> iter 94000, loss: 0.498914
 >> iter 95000, loss: 0.540899
 >> iter 96000, loss: 0.611869
 >> iter 97000, loss: 0.393045
 >> iter 98000, loss: 0.376005
 >> iter 99000, loss: 0.345044
 >> iter 100000, loss: 0.330755
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.108886
 >> iter 2000, loss: 13.587104
 >> iter 3000, loss: 11.297534
 >> iter 4000, loss: 9.470570
 >> iter 5000, loss: 8.672340
 >> iter 6000, loss: 8.259525
 >> iter 7000, loss: 8.314866
 >> iter 8000, loss: 8.008501
 >> iter 9000, loss: 7.990811
 >> iter 10000, loss: 7.943473
   Number of active neurons: 3
 >> iter 11000, loss: 7.752032
 >> iter 12000, loss: 7.138736
 >> iter 13000, loss: 6.158053
 >> iter 14000, loss: 4.784274
 >> iter 15000, loss: 3.404554
 >> iter 16000, loss: 1.865320
 >> iter 17000, loss: 1.140714
 >> iter 18000, loss: 0.603490
 >> iter 19000, loss: 0.471466
 >> iter 20000, loss: 0.365622
   Number of active neurons: 4
 >> iter 21000, loss: 0.290922
 >> iter 22000, loss: 0.385162
 >> iter 23000, loss: 0.358628
 >> iter 24000, loss: 0.498840
 >> iter 25000, loss: 0.365512
 >> iter 26000, loss: 0.339381
 >> iter 27000, loss: 0.536179
 >> iter 28000, loss: 0.423700
 >> iter 29000, loss: 0.500767
 >> iter 30000, loss: 0.396582
   Number of active neurons: 4
 >> iter 31000, loss: 0.276625
 >> iter 32000, loss: 0.211625
 >> iter 33000, loss: 0.287787
 >> iter 34000, loss: 0.353694
 >> iter 35000, loss: 0.368430
 >> iter 36000, loss: 0.535940
 >> iter 37000, loss: 0.523005
 >> iter 38000, loss: 0.408353
 >> iter 39000, loss: 0.426001
 >> iter 40000, loss: 0.628315
   Number of active neurons: 4
 >> iter 41000, loss: 0.531802
 >> iter 42000, loss: 0.537567
 >> iter 43000, loss: 0.449848
 >> iter 44000, loss: 0.364397
 >> iter 45000, loss: 0.450335
 >> iter 46000, loss: 0.356481
 >> iter 47000, loss: 0.403577
 >> iter 48000, loss: 0.431445
 >> iter 49000, loss: 0.333858
 >> iter 50000, loss: 0.471164
   Number of active neurons: 4
 >> iter 51000, loss: 0.372623
 >> iter 52000, loss: 0.399796
 >> iter 53000, loss: 0.449870
 >> iter 54000, loss: 0.363058
 >> iter 55000, loss: 0.270664
 >> iter 56000, loss: 0.306263
 >> iter 57000, loss: 0.295941
 >> iter 58000, loss: 0.380753
 >> iter 59000, loss: 0.416098
 >> iter 60000, loss: 0.325234
   Number of active neurons: 4
 >> iter 61000, loss: 0.533702
 >> iter 62000, loss: 0.603962
 >> iter 63000, loss: 0.545611
 >> iter 64000, loss: 0.473199
 >> iter 65000, loss: 0.341997
 >> iter 66000, loss: 0.340678
 >> iter 67000, loss: 0.566497
 >> iter 68000, loss: 0.409090
 >> iter 69000, loss: 0.363747
 >> iter 70000, loss: 0.468854
   Number of active neurons: 4
 >> iter 71000, loss: 0.543810
 >> iter 72000, loss: 0.420982
 >> iter 73000, loss: 0.381796
 >> iter 74000, loss: 0.469094
 >> iter 75000, loss: 0.390641
 >> iter 76000, loss: 0.357987
 >> iter 77000, loss: 0.354531
 >> iter 78000, loss: 0.514008
 >> iter 79000, loss: 0.607601
 >> iter 80000, loss: 0.605822
   Number of active neurons: 4
 >> iter 81000, loss: 0.420548
 >> iter 82000, loss: 0.366196
 >> iter 83000, loss: 0.406800
 >> iter 84000, loss: 0.425516
 >> iter 85000, loss: 0.434511
 >> iter 86000, loss: 0.374300
 >> iter 87000, loss: 0.392869
 >> iter 88000, loss: 0.289981
 >> iter 89000, loss: 0.521394
 >> iter 90000, loss: 0.353403
   Number of active neurons: 4
 >> iter 91000, loss: 0.409462
 >> iter 92000, loss: 0.348568
 >> iter 93000, loss: 0.474008
 >> iter 94000, loss: 0.406688
 >> iter 95000, loss: 0.375357
 >> iter 96000, loss: 0.389711
 >> iter 97000, loss: 0.568969
 >> iter 98000, loss: 0.369307
 >> iter 99000, loss: 0.325866
 >> iter 100000, loss: 0.309523
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.943690
 >> iter 2000, loss: 16.636663
 >> iter 3000, loss: 15.069375
 >> iter 4000, loss: 10.504058
 >> iter 5000, loss: 8.201877
 >> iter 6000, loss: 6.778088
 >> iter 7000, loss: 6.428332
 >> iter 8000, loss: 5.930466
 >> iter 9000, loss: 5.841781
 >> iter 10000, loss: 5.580275
   Number of active neurons: 3
 >> iter 11000, loss: 4.973135
 >> iter 12000, loss: 3.754994
 >> iter 13000, loss: 3.194953
 >> iter 14000, loss: 2.775870
 >> iter 15000, loss: 2.684387
 >> iter 16000, loss: 2.436760
 >> iter 17000, loss: 2.394979
 >> iter 18000, loss: 2.362005
 >> iter 19000, loss: 2.376036
 >> iter 20000, loss: 2.226914
   Number of active neurons: 4
 >> iter 21000, loss: 2.332651
 >> iter 22000, loss: 2.290287
 >> iter 23000, loss: 2.225780
 >> iter 24000, loss: 2.322584
 >> iter 25000, loss: 2.419327
 >> iter 26000, loss: 2.432977
 >> iter 27000, loss: 2.373894
 >> iter 28000, loss: 2.259079
 >> iter 29000, loss: 2.368115
 >> iter 30000, loss: 2.301520
   Number of active neurons: 4
 >> iter 31000, loss: 2.289911
 >> iter 32000, loss: 2.303821
 >> iter 33000, loss: 2.335006
 >> iter 34000, loss: 2.356023
 >> iter 35000, loss: 2.289809
 >> iter 36000, loss: 2.212967
 >> iter 37000, loss: 2.173283
 >> iter 38000, loss: 2.229934
 >> iter 39000, loss: 2.219225
 >> iter 40000, loss: 2.323127
   Number of active neurons: 4
 >> iter 41000, loss: 2.578842
 >> iter 42000, loss: 2.379721
 >> iter 43000, loss: 2.203737
 >> iter 44000, loss: 2.352324
 >> iter 45000, loss: 2.300554
 >> iter 46000, loss: 2.359736
 >> iter 47000, loss: 2.320680
 >> iter 48000, loss: 2.341122
 >> iter 49000, loss: 2.364519
 >> iter 50000, loss: 2.289553
   Number of active neurons: 4
 >> iter 51000, loss: 2.194973
 >> iter 52000, loss: 2.562967
 >> iter 53000, loss: 2.378116
 >> iter 54000, loss: 2.386458
 >> iter 55000, loss: 2.380591
 >> iter 56000, loss: 2.361259
 >> iter 57000, loss: 2.245727
 >> iter 58000, loss: 2.268076
 >> iter 59000, loss: 2.319360
 >> iter 60000, loss: 2.374908
   Number of active neurons: 4
 >> iter 61000, loss: 2.245683
 >> iter 62000, loss: 2.305435
 >> iter 63000, loss: 2.435128
 >> iter 64000, loss: 2.404280
 >> iter 65000, loss: 2.423927
 >> iter 66000, loss: 2.417252
 >> iter 67000, loss: 2.234528
 >> iter 68000, loss: 2.324529
 >> iter 69000, loss: 2.310606
 >> iter 70000, loss: 2.436276
   Number of active neurons: 4
 >> iter 71000, loss: 2.303205
 >> iter 72000, loss: 2.510299
 >> iter 73000, loss: 2.389342
 >> iter 74000, loss: 2.547303
 >> iter 75000, loss: 2.383267
 >> iter 76000, loss: 2.387114
 >> iter 77000, loss: 2.282003
 >> iter 78000, loss: 2.335492
 >> iter 79000, loss: 2.171494
 >> iter 80000, loss: 2.261587
   Number of active neurons: 4
 >> iter 81000, loss: 2.367456
 >> iter 82000, loss: 2.420928
 >> iter 83000, loss: 2.259995
 >> iter 84000, loss: 2.298119
 >> iter 85000, loss: 2.301732
 >> iter 86000, loss: 2.497416
 >> iter 87000, loss: 2.403539
 >> iter 88000, loss: 2.396421
 >> iter 89000, loss: 2.304264
 >> iter 90000, loss: 2.311841
   Number of active neurons: 4
 >> iter 91000, loss: 2.283522
 >> iter 92000, loss: 2.456757
 >> iter 93000, loss: 2.252850
 >> iter 94000, loss: 2.291666
 >> iter 95000, loss: 2.345449
 >> iter 96000, loss: 2.348735
 >> iter 97000, loss: 2.285008
 >> iter 98000, loss: 2.289077
 >> iter 99000, loss: 2.296674
 >> iter 100000, loss: 2.276350
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 2.0039599208
   - Test - Long: 0.574971251437
   - Test - Big: 2.15597844022
   - Test - A: 0.0
   - Test - B: 14.8456769549
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.285539
 >> iter 2000, loss: 15.511086
 >> iter 3000, loss: 14.530666
 >> iter 4000, loss: 13.855783
 >> iter 5000, loss: 13.294653
 >> iter 6000, loss: 13.680047
 >> iter 7000, loss: 11.779147
 >> iter 8000, loss: 9.280569
 >> iter 9000, loss: 8.044693
 >> iter 10000, loss: 7.040529
   Number of active neurons: 4
 >> iter 11000, loss: 6.843744
 >> iter 12000, loss: 6.549903
 >> iter 13000, loss: 6.573182
 >> iter 14000, loss: 6.309238
 >> iter 15000, loss: 6.410697
 >> iter 16000, loss: 6.410854
 >> iter 17000, loss: 6.587399
 >> iter 18000, loss: 6.470417
 >> iter 19000, loss: 6.468828
 >> iter 20000, loss: 6.317030
   Number of active neurons: 4
 >> iter 21000, loss: 6.461091
 >> iter 22000, loss: 6.201232
 >> iter 23000, loss: 6.401628
 >> iter 24000, loss: 6.219184
 >> iter 25000, loss: 6.384004
 >> iter 26000, loss: 6.338983
 >> iter 27000, loss: 6.456351
 >> iter 28000, loss: 6.231027
 >> iter 29000, loss: 6.393807
 >> iter 30000, loss: 6.263159
   Number of active neurons: 4
 >> iter 31000, loss: 6.364894
 >> iter 32000, loss: 6.323204
 >> iter 33000, loss: 6.475527
 >> iter 34000, loss: 6.246043
 >> iter 35000, loss: 6.396830
 >> iter 36000, loss: 6.196550
 >> iter 37000, loss: 6.357422
 >> iter 38000, loss: 6.220192
 >> iter 39000, loss: 6.467799
 >> iter 40000, loss: 6.374221
   Number of active neurons: 4
 >> iter 41000, loss: 6.428944
 >> iter 42000, loss: 6.310612
 >> iter 43000, loss: 6.438526
 >> iter 44000, loss: 6.304175
 >> iter 45000, loss: 6.367659
 >> iter 46000, loss: 6.236475
 >> iter 47000, loss: 6.393023
 >> iter 48000, loss: 6.186514
 >> iter 49000, loss: 6.358289
 >> iter 50000, loss: 6.164662
   Number of active neurons: 4
 >> iter 51000, loss: 6.372435
 >> iter 52000, loss: 6.228261
 >> iter 53000, loss: 6.385681
 >> iter 54000, loss: 6.203589
 >> iter 55000, loss: 6.381850
 >> iter 56000, loss: 6.187375
 >> iter 57000, loss: 6.413584
 >> iter 58000, loss: 6.200288
 >> iter 59000, loss: 6.343383
 >> iter 60000, loss: 6.196105
   Number of active neurons: 4
 >> iter 61000, loss: 6.349592
 >> iter 62000, loss: 6.220758
 >> iter 63000, loss: 6.377867
 >> iter 64000, loss: 6.201370
 >> iter 65000, loss: 6.357347
 >> iter 66000, loss: 6.217046
 >> iter 67000, loss: 6.363026
 >> iter 68000, loss: 6.151748
 >> iter 69000, loss: 6.337763
 >> iter 70000, loss: 6.164873
   Number of active neurons: 4
 >> iter 71000, loss: 6.336178
 >> iter 72000, loss: 6.190646
 >> iter 73000, loss: 6.401542
 >> iter 74000, loss: 6.222811
 >> iter 75000, loss: 6.431141
 >> iter 76000, loss: 6.194148
 >> iter 77000, loss: 6.378924
 >> iter 78000, loss: 6.201515
 >> iter 79000, loss: 6.396813
 >> iter 80000, loss: 6.316673
   Number of active neurons: 4
 >> iter 81000, loss: 6.409704
 >> iter 82000, loss: 6.157137
 >> iter 83000, loss: 6.397769
 >> iter 84000, loss: 6.257387
 >> iter 85000, loss: 6.557533
 >> iter 86000, loss: 6.276780
 >> iter 87000, loss: 6.447022
 >> iter 88000, loss: 6.178443
 >> iter 89000, loss: 6.392042
 >> iter 90000, loss: 6.304572
   Number of active neurons: 4
 >> iter 91000, loss: 6.471756
 >> iter 92000, loss: 6.207536
 >> iter 93000, loss: 6.428389
 >> iter 94000, loss: 6.172874
 >> iter 95000, loss: 6.384388
 >> iter 96000, loss: 6.273042
 >> iter 97000, loss: 6.426725
 >> iter 98000, loss: 6.227130
 >> iter 99000, loss: 6.389953
 >> iter 100000, loss: 6.206662
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 9.46581068379
   - Test - Long: 1.89490525474
   - Test - Big: 9.16790832092
   - Test - A: 17.0521965202
   - Test - B: 0.659956002933
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.290708
 >> iter 2000, loss: 15.376425
 >> iter 3000, loss: 14.181219
 >> iter 4000, loss: 10.771988
 >> iter 5000, loss: 5.967350
 >> iter 6000, loss: 2.947512
 >> iter 7000, loss: 1.725368
 >> iter 8000, loss: 1.328754
 >> iter 9000, loss: 1.001499
 >> iter 10000, loss: 0.682518
   Number of active neurons: 4
 >> iter 11000, loss: 0.602598
 >> iter 12000, loss: 0.630253
 >> iter 13000, loss: 0.465991
 >> iter 14000, loss: 0.592487
 >> iter 15000, loss: 0.574114
 >> iter 16000, loss: 0.586309
 >> iter 17000, loss: 0.574679
 >> iter 18000, loss: 0.607175
 >> iter 19000, loss: 0.595379
 >> iter 20000, loss: 0.772878
   Number of active neurons: 4
 >> iter 21000, loss: 0.548738
 >> iter 22000, loss: 0.470158
 >> iter 23000, loss: 0.362446
 >> iter 24000, loss: 0.297884
 >> iter 25000, loss: 0.444908
 >> iter 26000, loss: 0.600598
 >> iter 27000, loss: 0.845542
 >> iter 28000, loss: 0.612063
 >> iter 29000, loss: 0.614793
 >> iter 30000, loss: 0.627717
   Number of active neurons: 4
 >> iter 31000, loss: 0.554089
 >> iter 32000, loss: 0.416960
 >> iter 33000, loss: 0.434081
 >> iter 34000, loss: 0.408320
 >> iter 35000, loss: 0.577316
 >> iter 36000, loss: 0.715739
 >> iter 37000, loss: 0.658527
 >> iter 38000, loss: 0.660767
 >> iter 39000, loss: 0.601804
 >> iter 40000, loss: 0.635921
   Number of active neurons: 4
 >> iter 41000, loss: 0.507024
 >> iter 42000, loss: 0.580172
 >> iter 43000, loss: 0.507428
 >> iter 44000, loss: 0.452074
 >> iter 45000, loss: 0.556077
 >> iter 46000, loss: 0.359019
 >> iter 47000, loss: 0.466618
 >> iter 48000, loss: 0.692341
 >> iter 49000, loss: 0.632938
 >> iter 50000, loss: 0.452582
   Number of active neurons: 4
 >> iter 51000, loss: 0.521541
 >> iter 52000, loss: 0.468432
 >> iter 53000, loss: 0.594111
 >> iter 54000, loss: 0.397234
 >> iter 55000, loss: 0.508937
 >> iter 56000, loss: 0.455873
 >> iter 57000, loss: 0.511557
 >> iter 58000, loss: 0.555627
 >> iter 59000, loss: 0.500242
 >> iter 60000, loss: 0.631478
   Number of active neurons: 4
 >> iter 61000, loss: 0.554700
 >> iter 62000, loss: 0.467178
 >> iter 63000, loss: 0.321811
 >> iter 64000, loss: 0.359309
 >> iter 65000, loss: 0.423831
 >> iter 66000, loss: 0.518361
 >> iter 67000, loss: 0.503892
 >> iter 68000, loss: 0.455709
 >> iter 69000, loss: 0.461317
 >> iter 70000, loss: 0.446549
   Number of active neurons: 4
 >> iter 71000, loss: 0.554313
 >> iter 72000, loss: 0.518593
 >> iter 73000, loss: 0.545441
 >> iter 74000, loss: 0.581321
 >> iter 75000, loss: 0.454316
 >> iter 76000, loss: 0.321033
 >> iter 77000, loss: 0.461920
 >> iter 78000, loss: 0.501413
 >> iter 79000, loss: 0.711961
 >> iter 80000, loss: 0.500053
   Number of active neurons: 4
 >> iter 81000, loss: 0.445953
 >> iter 82000, loss: 0.578935
 >> iter 83000, loss: 0.507781
 >> iter 84000, loss: 0.602478
 >> iter 85000, loss: 0.501261
 >> iter 86000, loss: 0.524976
 >> iter 87000, loss: 0.500766
 >> iter 88000, loss: 0.690172
 >> iter 89000, loss: 0.699651
 >> iter 90000, loss: 0.546701
   Number of active neurons: 4
 >> iter 91000, loss: 0.730926
 >> iter 92000, loss: 0.422094
 >> iter 93000, loss: 0.468710
 >> iter 94000, loss: 0.480287
 >> iter 95000, loss: 0.421571
 >> iter 96000, loss: 0.478280
 >> iter 97000, loss: 0.609953
 >> iter 98000, loss: 0.596967
 >> iter 99000, loss: 0.448209
 >> iter 100000, loss: 0.491938
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.073495
 >> iter 2000, loss: 10.765962
 >> iter 3000, loss: 5.055621
 >> iter 4000, loss: 2.564020
 >> iter 5000, loss: 1.551885
 >> iter 6000, loss: 0.889638
 >> iter 7000, loss: 0.842013
 >> iter 8000, loss: 0.590521
 >> iter 9000, loss: 0.730659
 >> iter 10000, loss: 0.539249
   Number of active neurons: 4
 >> iter 11000, loss: 0.519760
 >> iter 12000, loss: 0.520539
 >> iter 13000, loss: 0.434668
 >> iter 14000, loss: 0.503871
 >> iter 15000, loss: 0.523992
 >> iter 16000, loss: 0.579863
 >> iter 17000, loss: 0.391690
 >> iter 18000, loss: 0.383783
 >> iter 19000, loss: 0.400164
 >> iter 20000, loss: 0.329664
   Number of active neurons: 4
 >> iter 21000, loss: 0.498204
 >> iter 22000, loss: 0.480409
 >> iter 23000, loss: 0.376988
 >> iter 24000, loss: 0.431059
 >> iter 25000, loss: 0.420806
 >> iter 26000, loss: 0.401386
 >> iter 27000, loss: 0.381598
 >> iter 28000, loss: 0.470533
 >> iter 29000, loss: 0.449827
 >> iter 30000, loss: 0.492635
   Number of active neurons: 4
 >> iter 31000, loss: 0.354836
 >> iter 32000, loss: 0.366674
 >> iter 33000, loss: 0.311179
 >> iter 34000, loss: 0.429164
 >> iter 35000, loss: 0.348939
 >> iter 36000, loss: 0.351463
 >> iter 37000, loss: 0.440818
 >> iter 38000, loss: 0.321081
 >> iter 39000, loss: 0.369436
 >> iter 40000, loss: 0.498686
   Number of active neurons: 4
 >> iter 41000, loss: 0.535137
 >> iter 42000, loss: 0.430799
 >> iter 43000, loss: 0.405371
 >> iter 44000, loss: 0.455337
 >> iter 45000, loss: 0.374947
 >> iter 46000, loss: 0.330589
 >> iter 47000, loss: 0.347310
 >> iter 48000, loss: 0.294772
 >> iter 49000, loss: 0.393354
 >> iter 50000, loss: 0.357159
   Number of active neurons: 4
 >> iter 51000, loss: 0.319988
 >> iter 52000, loss: 0.307274
 >> iter 53000, loss: 0.305088
 >> iter 54000, loss: 0.374295
 >> iter 55000, loss: 0.382101
 >> iter 56000, loss: 0.280546
 >> iter 57000, loss: 0.334746
 >> iter 58000, loss: 0.466785
 >> iter 59000, loss: 0.417331
 >> iter 60000, loss: 0.345145
   Number of active neurons: 4
 >> iter 61000, loss: 0.370611
 >> iter 62000, loss: 0.422089
 >> iter 63000, loss: 0.485718
 >> iter 64000, loss: 0.480487
 >> iter 65000, loss: 0.458395
 >> iter 66000, loss: 0.438829
 >> iter 67000, loss: 0.496864
 >> iter 68000, loss: 0.407132
 >> iter 69000, loss: 0.262741
 >> iter 70000, loss: 0.382271
   Number of active neurons: 4
 >> iter 71000, loss: 0.375255
 >> iter 72000, loss: 0.290646
 >> iter 73000, loss: 0.288882
 >> iter 74000, loss: 0.287134
 >> iter 75000, loss: 0.284205
 >> iter 76000, loss: 0.384956
 >> iter 77000, loss: 0.553490
 >> iter 78000, loss: 0.407018
 >> iter 79000, loss: 0.451409
 >> iter 80000, loss: 0.369590
   Number of active neurons: 4
 >> iter 81000, loss: 0.399345
 >> iter 82000, loss: 0.385084
 >> iter 83000, loss: 0.307393
 >> iter 84000, loss: 0.332888
 >> iter 85000, loss: 0.267984
 >> iter 86000, loss: 0.412406
 >> iter 87000, loss: 0.348291
 >> iter 88000, loss: 0.426085
 >> iter 89000, loss: 0.424122
 >> iter 90000, loss: 0.331378
   Number of active neurons: 4
 >> iter 91000, loss: 0.246016
 >> iter 92000, loss: 0.356700
 >> iter 93000, loss: 0.251589
 >> iter 94000, loss: 0.371204
 >> iter 95000, loss: 0.408254
 >> iter 96000, loss: 0.288840
 >> iter 97000, loss: 0.338416
 >> iter 98000, loss: 0.315995
 >> iter 99000, loss: 0.398604
 >> iter 100000, loss: 0.335962
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

