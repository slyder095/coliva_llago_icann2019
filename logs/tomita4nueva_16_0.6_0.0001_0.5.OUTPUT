 > Problema: tomita4nueva
 > Args:
   - Hidden size: 16
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.615211
 >> iter 2000, loss: 9.162077
 >> iter 3000, loss: 3.982404
 >> iter 4000, loss: 1.962906
 >> iter 5000, loss: 0.895122
 >> iter 6000, loss: 0.514070
 >> iter 7000, loss: 0.314772
 >> iter 8000, loss: 0.383024
 >> iter 9000, loss: 0.460412
 >> iter 10000, loss: 0.576163
   Number of active neurons: 6
 >> iter 11000, loss: 0.482242
 >> iter 12000, loss: 0.343246
 >> iter 13000, loss: 0.414905
 >> iter 14000, loss: 0.366094
 >> iter 15000, loss: 0.413766
 >> iter 16000, loss: 0.419186
 >> iter 17000, loss: 0.381415
 >> iter 18000, loss: 0.431815
 >> iter 19000, loss: 0.313363
 >> iter 20000, loss: 0.268708
   Number of active neurons: 6
 >> iter 21000, loss: 0.159464
 >> iter 22000, loss: 0.392563
 >> iter 23000, loss: 0.461218
 >> iter 24000, loss: 0.508116
 >> iter 25000, loss: 0.390080
 >> iter 26000, loss: 0.280930
 >> iter 27000, loss: 0.201576
 >> iter 28000, loss: 0.385802
 >> iter 29000, loss: 0.421189
 >> iter 30000, loss: 0.417087
   Number of active neurons: 5
 >> iter 31000, loss: 0.302525
 >> iter 32000, loss: 0.388688
 >> iter 33000, loss: 0.227968
 >> iter 34000, loss: 0.268976
 >> iter 35000, loss: 0.181797
 >> iter 36000, loss: 0.197407
 >> iter 37000, loss: 0.346008
 >> iter 38000, loss: 0.276604
 >> iter 39000, loss: 0.294441
 >> iter 40000, loss: 0.265041
   Number of active neurons: 4
 >> iter 41000, loss: 0.152419
 >> iter 42000, loss: 0.408920
 >> iter 43000, loss: 0.341384
 >> iter 44000, loss: 0.236600
 >> iter 45000, loss: 0.203213
 >> iter 46000, loss: 0.289409
 >> iter 47000, loss: 0.324833
 >> iter 48000, loss: 0.164233
 >> iter 49000, loss: 0.175653
 >> iter 50000, loss: 0.260495
   Number of active neurons: 4
 >> iter 51000, loss: 0.217794
 >> iter 52000, loss: 0.154686
 >> iter 53000, loss: 0.354543
 >> iter 54000, loss: 0.333393
 >> iter 55000, loss: 0.392269
 >> iter 56000, loss: 0.351508
 >> iter 57000, loss: 0.398102
 >> iter 58000, loss: 0.502635
 >> iter 59000, loss: 0.365789
 >> iter 60000, loss: 0.237491
   Number of active neurons: 4
 >> iter 61000, loss: 0.198921
 >> iter 62000, loss: 0.242134
 >> iter 63000, loss: 0.163961
 >> iter 64000, loss: 0.179636
 >> iter 65000, loss: 0.159864
 >> iter 66000, loss: 0.208236
 >> iter 67000, loss: 0.219940
 >> iter 68000, loss: 0.260349
 >> iter 69000, loss: 0.224080
 >> iter 70000, loss: 0.212814
   Number of active neurons: 4
 >> iter 71000, loss: 0.297621
 >> iter 72000, loss: 0.249545
 >> iter 73000, loss: 0.324217
 >> iter 74000, loss: 0.247522
 >> iter 75000, loss: 0.200736
 >> iter 76000, loss: 0.306952
 >> iter 77000, loss: 0.289679
 >> iter 78000, loss: 0.353085
 >> iter 79000, loss: 0.343877
 >> iter 80000, loss: 0.257130
   Number of active neurons: 4
 >> iter 81000, loss: 0.141715
 >> iter 82000, loss: 0.151770
 >> iter 83000, loss: 0.285023
 >> iter 84000, loss: 0.156169
 >> iter 85000, loss: 0.423790
 >> iter 86000, loss: 0.427417
 >> iter 87000, loss: 0.261612
 >> iter 88000, loss: 0.215709
 >> iter 89000, loss: 0.115154
 >> iter 90000, loss: 0.471209
   Number of active neurons: 4
 >> iter 91000, loss: 0.462706
 >> iter 92000, loss: 0.364098
 >> iter 93000, loss: 0.182288
 >> iter 94000, loss: 0.199886
 >> iter 95000, loss: 0.158668
 >> iter 96000, loss: 0.236016
 >> iter 97000, loss: 0.298642
 >> iter 98000, loss: 0.265942
 >> iter 99000, loss: 0.354506
 >> iter 100000, loss: 0.265093
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.330725
 >> iter 2000, loss: 9.451821
 >> iter 3000, loss: 4.313584
 >> iter 4000, loss: 1.852013
 >> iter 5000, loss: 1.067121
 >> iter 6000, loss: 0.810337
 >> iter 7000, loss: 0.576897
 >> iter 8000, loss: 0.358775
 >> iter 9000, loss: 0.248234
 >> iter 10000, loss: 0.276489
   Number of active neurons: 7
 >> iter 11000, loss: 0.263601
 >> iter 12000, loss: 0.484926
 >> iter 13000, loss: 0.345386
 >> iter 14000, loss: 0.291048
 >> iter 15000, loss: 0.458457
 >> iter 16000, loss: 0.247842
 >> iter 17000, loss: 0.573042
 >> iter 18000, loss: 0.288001
 >> iter 19000, loss: 0.445521
 >> iter 20000, loss: 0.479248
   Number of active neurons: 7
 >> iter 21000, loss: 0.483924
 >> iter 22000, loss: 0.309742
 >> iter 23000, loss: 0.485278
 >> iter 24000, loss: 0.425557
 >> iter 25000, loss: 0.381407
 >> iter 26000, loss: 0.405951
 >> iter 27000, loss: 0.325822
 >> iter 28000, loss: 0.321192
 >> iter 29000, loss: 0.213258
 >> iter 30000, loss: 0.320502
   Number of active neurons: 5
 >> iter 31000, loss: 0.286802
 >> iter 32000, loss: 0.255678
 >> iter 33000, loss: 0.308258
 >> iter 34000, loss: 0.257306
 >> iter 35000, loss: 0.219712
 >> iter 36000, loss: 0.458924
 >> iter 37000, loss: 0.362859
 >> iter 38000, loss: 0.276326
 >> iter 39000, loss: 0.423602
 >> iter 40000, loss: 0.248316
   Number of active neurons: 5
 >> iter 41000, loss: 0.244587
 >> iter 42000, loss: 0.224002
 >> iter 43000, loss: 0.137687
 >> iter 44000, loss: 0.252617
 >> iter 45000, loss: 0.235698
 >> iter 46000, loss: 0.149034
 >> iter 47000, loss: 0.366397
 >> iter 48000, loss: 0.215624
 >> iter 49000, loss: 0.311369
 >> iter 50000, loss: 0.214878
   Number of active neurons: 3
 >> iter 51000, loss: 0.197497
 >> iter 52000, loss: 0.160893
 >> iter 53000, loss: 0.184152
 >> iter 54000, loss: 0.254743
 >> iter 55000, loss: 0.195026
 >> iter 56000, loss: 0.205278
 >> iter 57000, loss: 0.249880
 >> iter 58000, loss: 0.392401
 >> iter 59000, loss: 0.220282
 >> iter 60000, loss: 0.157478
   Number of active neurons: 3
 >> iter 61000, loss: 0.167712
 >> iter 62000, loss: 0.107776
 >> iter 63000, loss: 0.251910
 >> iter 64000, loss: 0.473728
 >> iter 65000, loss: 0.379523
 >> iter 66000, loss: 0.357284
 >> iter 67000, loss: 0.261106
 >> iter 68000, loss: 0.295522
 >> iter 69000, loss: 0.393498
 >> iter 70000, loss: 0.296438
   Number of active neurons: 3
 >> iter 71000, loss: 0.242006
 >> iter 72000, loss: 0.313237
 >> iter 73000, loss: 0.208823
 >> iter 74000, loss: 0.168190
 >> iter 75000, loss: 0.218863
 >> iter 76000, loss: 0.434353
 >> iter 77000, loss: 0.256383
 >> iter 78000, loss: 0.171710
 >> iter 79000, loss: 0.188666
 >> iter 80000, loss: 0.196608
   Number of active neurons: 3
 >> iter 81000, loss: 0.163397
 >> iter 82000, loss: 0.299681
 >> iter 83000, loss: 0.406071
 >> iter 84000, loss: 0.321966
 >> iter 85000, loss: 0.290213
 >> iter 86000, loss: 0.148934
 >> iter 87000, loss: 0.160240
 >> iter 88000, loss: 0.165493
 >> iter 89000, loss: 0.157715
 >> iter 90000, loss: 0.137867
   Number of active neurons: 3
 >> iter 91000, loss: 0.091223
 >> iter 92000, loss: 0.198241
 >> iter 93000, loss: 0.191282
 >> iter 94000, loss: 0.228870
 >> iter 95000, loss: 0.210038
 >> iter 96000, loss: 0.195790
 >> iter 97000, loss: 0.254298
 >> iter 98000, loss: 0.219343
 >> iter 99000, loss: 0.288104
 >> iter 100000, loss: 0.399971
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.167011
 >> iter 2000, loss: 7.738508
 >> iter 3000, loss: 3.306714
 >> iter 4000, loss: 1.594103
 >> iter 5000, loss: 0.958876
 >> iter 6000, loss: 0.673179
 >> iter 7000, loss: 0.423827
 >> iter 8000, loss: 0.421609
 >> iter 9000, loss: 0.336436
 >> iter 10000, loss: 0.384450
   Number of active neurons: 4
 >> iter 11000, loss: 0.426700
 >> iter 12000, loss: 0.441109
 >> iter 13000, loss: 0.401408
 >> iter 14000, loss: 0.366469
 >> iter 15000, loss: 0.264834
 >> iter 16000, loss: 0.283800
 >> iter 17000, loss: 0.360290
 >> iter 18000, loss: 0.253900
 >> iter 19000, loss: 0.276465
 >> iter 20000, loss: 0.188642
   Number of active neurons: 4
 >> iter 21000, loss: 0.238176
 >> iter 22000, loss: 0.171120
 >> iter 23000, loss: 0.445423
 >> iter 24000, loss: 0.311562
 >> iter 25000, loss: 0.489621
 >> iter 26000, loss: 0.460123
 >> iter 27000, loss: 0.349421
 >> iter 28000, loss: 0.317116
 >> iter 29000, loss: 0.317462
 >> iter 30000, loss: 0.315310
   Number of active neurons: 4
 >> iter 31000, loss: 0.350260
 >> iter 32000, loss: 0.399029
 >> iter 33000, loss: 0.219590
 >> iter 34000, loss: 0.273994
 >> iter 35000, loss: 0.240584
 >> iter 36000, loss: 0.232882
 >> iter 37000, loss: 0.281390
 >> iter 38000, loss: 0.322744
 >> iter 39000, loss: 0.498146
 >> iter 40000, loss: 0.434928
   Number of active neurons: 4
 >> iter 41000, loss: 0.278870
 >> iter 42000, loss: 0.237634
 >> iter 43000, loss: 0.290853
 >> iter 44000, loss: 0.234376
 >> iter 45000, loss: 0.246786
 >> iter 46000, loss: 0.245814
 >> iter 47000, loss: 0.188526
 >> iter 48000, loss: 0.172125
 >> iter 49000, loss: 0.196798
 >> iter 50000, loss: 0.224868
   Number of active neurons: 4
 >> iter 51000, loss: 0.223913
 >> iter 52000, loss: 0.254955
 >> iter 53000, loss: 0.322609
 >> iter 54000, loss: 0.185336
 >> iter 55000, loss: 0.100283
 >> iter 56000, loss: 0.352290
 >> iter 57000, loss: 0.196021
 >> iter 58000, loss: 0.218379
 >> iter 59000, loss: 0.187071
 >> iter 60000, loss: 0.324700
   Number of active neurons: 4
 >> iter 61000, loss: 0.335047
 >> iter 62000, loss: 0.268807
 >> iter 63000, loss: 0.176569
 >> iter 64000, loss: 0.340286
 >> iter 65000, loss: 0.191051
 >> iter 66000, loss: 0.185007
 >> iter 67000, loss: 0.170920
 >> iter 68000, loss: 0.222067
 >> iter 69000, loss: 0.269379
 >> iter 70000, loss: 0.187442
   Number of active neurons: 4
 >> iter 71000, loss: 0.344357
 >> iter 72000, loss: 0.378889
 >> iter 73000, loss: 0.232718
 >> iter 74000, loss: 0.189012
 >> iter 75000, loss: 0.173716
 >> iter 76000, loss: 0.107403
 >> iter 77000, loss: 0.132553
 >> iter 78000, loss: 0.279456
 >> iter 79000, loss: 0.270760
 >> iter 80000, loss: 0.379674
   Number of active neurons: 4
 >> iter 81000, loss: 0.251221
 >> iter 82000, loss: 0.162493
 >> iter 83000, loss: 0.283183
 >> iter 84000, loss: 0.175508
 >> iter 85000, loss: 0.197230
 >> iter 86000, loss: 0.251841
 >> iter 87000, loss: 0.348512
 >> iter 88000, loss: 0.349959
 >> iter 89000, loss: 0.211760
 >> iter 90000, loss: 0.295669
   Number of active neurons: 4
 >> iter 91000, loss: 0.280685
 >> iter 92000, loss: 0.235810
 >> iter 93000, loss: 0.161460
 >> iter 94000, loss: 0.240239
 >> iter 95000, loss: 0.221408
 >> iter 96000, loss: 0.225067
 >> iter 97000, loss: 0.176268
 >> iter 98000, loss: 0.260696
 >> iter 99000, loss: 0.367477
 >> iter 100000, loss: 0.232287
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 17.749878
 >> iter 2000, loss: 8.337675
 >> iter 3000, loss: 3.907256
 >> iter 4000, loss: 1.748158
 >> iter 5000, loss: 0.983868
 >> iter 6000, loss: 0.501535
 >> iter 7000, loss: 0.538659
 >> iter 8000, loss: 0.349681
 >> iter 9000, loss: 0.421505
 >> iter 10000, loss: 0.447296
   Number of active neurons: 4
 >> iter 11000, loss: 0.464293
 >> iter 12000, loss: 0.407872
 >> iter 13000, loss: 0.462746
 >> iter 14000, loss: 0.378672
 >> iter 15000, loss: 0.274003
 >> iter 16000, loss: 0.377476
 >> iter 17000, loss: 0.415742
 >> iter 18000, loss: 0.328801
 >> iter 19000, loss: 0.261484
 >> iter 20000, loss: 0.177954
   Number of active neurons: 4
 >> iter 21000, loss: 0.159485
 >> iter 22000, loss: 0.244009
 >> iter 23000, loss: 0.357305
 >> iter 24000, loss: 0.259330
 >> iter 25000, loss: 0.421915
 >> iter 26000, loss: 0.299486
 >> iter 27000, loss: 0.471679
 >> iter 28000, loss: 0.334685
 >> iter 29000, loss: 0.295568
 >> iter 30000, loss: 0.386861
   Number of active neurons: 4
 >> iter 31000, loss: 0.205677
 >> iter 32000, loss: 0.521174
 >> iter 33000, loss: 0.301217
 >> iter 34000, loss: 0.201833
 >> iter 35000, loss: 0.318931
 >> iter 36000, loss: 0.281742
 >> iter 37000, loss: 0.198597
 >> iter 38000, loss: 0.241677
 >> iter 39000, loss: 0.196618
 >> iter 40000, loss: 0.202051
   Number of active neurons: 3
 >> iter 41000, loss: 0.162273
 >> iter 42000, loss: 0.302134
 >> iter 43000, loss: 0.342310
 >> iter 44000, loss: 0.223349
 >> iter 45000, loss: 0.284070
 >> iter 46000, loss: 0.207073
 >> iter 47000, loss: 0.248988
 >> iter 48000, loss: 0.205665
 >> iter 49000, loss: 0.170288
 >> iter 50000, loss: 0.315357
   Number of active neurons: 3
 >> iter 51000, loss: 0.331255
 >> iter 52000, loss: 0.404936
 >> iter 53000, loss: 0.292656
 >> iter 54000, loss: 0.315254
 >> iter 55000, loss: 0.196899
 >> iter 56000, loss: 0.179177
 >> iter 57000, loss: 0.316183
 >> iter 58000, loss: 0.178693
 >> iter 59000, loss: 0.186353
 >> iter 60000, loss: 0.213782
   Number of active neurons: 3
 >> iter 61000, loss: 0.249645
 >> iter 62000, loss: 0.433109
 >> iter 63000, loss: 0.364636
 >> iter 64000, loss: 0.225385
 >> iter 65000, loss: 0.273867
 >> iter 66000, loss: 0.314502
 >> iter 67000, loss: 0.223510
 >> iter 68000, loss: 0.314408
 >> iter 69000, loss: 0.154332
 >> iter 70000, loss: 0.272225
   Number of active neurons: 3
 >> iter 71000, loss: 0.240733
 >> iter 72000, loss: 0.292222
 >> iter 73000, loss: 0.279255
 >> iter 74000, loss: 0.331300
 >> iter 75000, loss: 0.430557
 >> iter 76000, loss: 0.203520
 >> iter 77000, loss: 0.190346
 >> iter 78000, loss: 0.260742
 >> iter 79000, loss: 0.210366
 >> iter 80000, loss: 0.247670
   Number of active neurons: 3
 >> iter 81000, loss: 0.443679
 >> iter 82000, loss: 0.318134
 >> iter 83000, loss: 0.394993
 >> iter 84000, loss: 0.239642
 >> iter 85000, loss: 0.346804
 >> iter 86000, loss: 0.301690
 >> iter 87000, loss: 0.348053
 >> iter 88000, loss: 0.279385
 >> iter 89000, loss: 0.213133
 >> iter 90000, loss: 0.244260
   Number of active neurons: 3
 >> iter 91000, loss: 0.219347
 >> iter 92000, loss: 0.184840
 >> iter 93000, loss: 0.429253
 >> iter 94000, loss: 0.421852
 >> iter 95000, loss: 0.352109
 >> iter 96000, loss: 0.335843
 >> iter 97000, loss: 0.231547
 >> iter 98000, loss: 0.230833
 >> iter 99000, loss: 0.314728
 >> iter 100000, loss: 0.331325
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.656911
 >> iter 2000, loss: 10.137240
 >> iter 3000, loss: 4.957867
 >> iter 4000, loss: 2.269681
 >> iter 5000, loss: 1.210606
 >> iter 6000, loss: 0.702206
 >> iter 7000, loss: 0.579196
 >> iter 8000, loss: 0.438240
 >> iter 9000, loss: 0.639845
 >> iter 10000, loss: 0.390535
   Number of active neurons: 4
 >> iter 11000, loss: 0.405039
 >> iter 12000, loss: 0.496196
 >> iter 13000, loss: 0.390988
 >> iter 14000, loss: 0.530697
 >> iter 15000, loss: 0.371348
 >> iter 16000, loss: 0.451633
 >> iter 17000, loss: 0.320962
 >> iter 18000, loss: 0.343710
 >> iter 19000, loss: 0.424016
 >> iter 20000, loss: 0.310608
   Number of active neurons: 4
 >> iter 21000, loss: 0.395706
 >> iter 22000, loss: 0.274143
 >> iter 23000, loss: 0.300775
 >> iter 24000, loss: 0.322675
 >> iter 25000, loss: 0.207920
 >> iter 26000, loss: 0.287338
 >> iter 27000, loss: 0.383940
 >> iter 28000, loss: 0.476524
 >> iter 29000, loss: 0.388526
 >> iter 30000, loss: 0.296088
   Number of active neurons: 4
 >> iter 31000, loss: 0.292499
 >> iter 32000, loss: 0.440835
 >> iter 33000, loss: 0.368803
 >> iter 34000, loss: 0.396961
 >> iter 35000, loss: 0.303013
 >> iter 36000, loss: 0.344235
 >> iter 37000, loss: 0.299772
 >> iter 38000, loss: 0.297418
 >> iter 39000, loss: 0.456161
 >> iter 40000, loss: 0.326083
   Number of active neurons: 4
 >> iter 41000, loss: 0.272372
 >> iter 42000, loss: 0.290563
 >> iter 43000, loss: 0.372145
 >> iter 44000, loss: 0.360245
 >> iter 45000, loss: 0.347775
 >> iter 46000, loss: 0.435750
 >> iter 47000, loss: 0.240096
 >> iter 48000, loss: 0.416061
 >> iter 49000, loss: 0.505225
 >> iter 50000, loss: 0.376774
   Number of active neurons: 4
 >> iter 51000, loss: 0.387647
 >> iter 52000, loss: 0.587581
 >> iter 53000, loss: 0.445431
 >> iter 54000, loss: 0.374473
 >> iter 55000, loss: 0.404870
 >> iter 56000, loss: 0.303893
 >> iter 57000, loss: 0.171417
 >> iter 58000, loss: 0.171817
 >> iter 59000, loss: 0.219763
 >> iter 60000, loss: 0.298668
   Number of active neurons: 4
 >> iter 61000, loss: 0.277756
 >> iter 62000, loss: 0.156902
 >> iter 63000, loss: 0.536768
 >> iter 64000, loss: 0.440797
 >> iter 65000, loss: 0.256371
 >> iter 66000, loss: 0.471484
 >> iter 67000, loss: 0.410592
 >> iter 68000, loss: 0.293676
 >> iter 69000, loss: 0.290956
 >> iter 70000, loss: 0.397561
   Number of active neurons: 3
 >> iter 71000, loss: 0.458935
 >> iter 72000, loss: 0.465764
 >> iter 73000, loss: 0.408716
 >> iter 74000, loss: 0.238831
 >> iter 75000, loss: 0.281972
 >> iter 76000, loss: 0.232188
 >> iter 77000, loss: 0.226048
 >> iter 78000, loss: 0.292302
 >> iter 79000, loss: 0.367695
 >> iter 80000, loss: 0.301747
   Number of active neurons: 3
 >> iter 81000, loss: 0.279162
 >> iter 82000, loss: 0.214007
 >> iter 83000, loss: 0.241016
 >> iter 84000, loss: 0.332807
 >> iter 85000, loss: 0.214526
 >> iter 86000, loss: 0.267941
 >> iter 87000, loss: 0.186810
 >> iter 88000, loss: 0.176711
 >> iter 89000, loss: 0.185958
 >> iter 90000, loss: 0.304921
   Number of active neurons: 3
 >> iter 91000, loss: 0.396815
 >> iter 92000, loss: 0.266379
 >> iter 93000, loss: 0.348689
 >> iter 94000, loss: 0.233868
 >> iter 95000, loss: 0.238545
 >> iter 96000, loss: 0.271980
 >> iter 97000, loss: 0.192270
 >> iter 98000, loss: 0.239891
 >> iter 99000, loss: 0.477559
 >> iter 100000, loss: 0.277508
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 18.701416
 >> iter 2000, loss: 10.307873
 >> iter 3000, loss: 4.871811
 >> iter 4000, loss: 2.228929
 >> iter 5000, loss: 1.028030
 >> iter 6000, loss: 0.635866
 >> iter 7000, loss: 0.382946
 >> iter 8000, loss: 0.457245
 >> iter 9000, loss: 0.475920
 >> iter 10000, loss: 0.421474
   Number of active neurons: 10
 >> iter 11000, loss: 0.233478
 >> iter 12000, loss: 0.266950
 >> iter 13000, loss: 0.311381
 >> iter 14000, loss: 0.256946
 >> iter 15000, loss: 0.351947
 >> iter 16000, loss: 0.281934
 >> iter 17000, loss: 0.245779
 >> iter 18000, loss: 0.385800
 >> iter 19000, loss: 0.251251
 >> iter 20000, loss: 0.392885
   Number of active neurons: 7
 >> iter 21000, loss: 0.341901
 >> iter 22000, loss: 0.245973
 >> iter 23000, loss: 0.401010
 >> iter 24000, loss: 0.271317
 >> iter 25000, loss: 0.279696
 >> iter 26000, loss: 0.395313
 >> iter 27000, loss: 0.484022
 >> iter 28000, loss: 0.265674
 >> iter 29000, loss: 0.339874
 >> iter 30000, loss: 0.238677
   Number of active neurons: 5
 >> iter 31000, loss: 0.239498
 >> iter 32000, loss: 0.408956
 >> iter 33000, loss: 0.352703
 >> iter 34000, loss: 0.226725
 >> iter 35000, loss: 0.369472
 >> iter 36000, loss: 0.368387
 >> iter 37000, loss: 0.279139
 >> iter 38000, loss: 0.309949
 >> iter 39000, loss: 0.314699
 >> iter 40000, loss: 0.301996
   Number of active neurons: 4
 >> iter 41000, loss: 0.258782
 >> iter 42000, loss: 0.133136
 >> iter 43000, loss: 0.258046
 >> iter 44000, loss: 0.306075
 >> iter 45000, loss: 0.176611
 >> iter 46000, loss: 0.251353
 >> iter 47000, loss: 0.307361
 >> iter 48000, loss: 0.222641
 >> iter 49000, loss: 0.224954
 >> iter 50000, loss: 0.249190
   Number of active neurons: 4
 >> iter 51000, loss: 0.393185
 >> iter 52000, loss: 0.237615
 >> iter 53000, loss: 0.174158
 >> iter 54000, loss: 0.194790
 >> iter 55000, loss: 0.231693
 >> iter 56000, loss: 0.357789
 >> iter 57000, loss: 0.186259
 >> iter 58000, loss: 0.216419
 >> iter 59000, loss: 0.253861
 >> iter 60000, loss: 0.291032
   Number of active neurons: 4
 >> iter 61000, loss: 0.289362
 >> iter 62000, loss: 0.294229
 >> iter 63000, loss: 0.160212
 >> iter 64000, loss: 0.360035
 >> iter 65000, loss: 0.268600
 >> iter 66000, loss: 0.228401
 >> iter 67000, loss: 0.254908
 >> iter 68000, loss: 0.457856
 >> iter 69000, loss: 0.379790
 >> iter 70000, loss: 0.295035
   Number of active neurons: 4
 >> iter 71000, loss: 0.210631
 >> iter 72000, loss: 0.161566
 >> iter 73000, loss: 0.139451
 >> iter 74000, loss: 0.175841
 >> iter 75000, loss: 0.169699
 >> iter 76000, loss: 0.215560
 >> iter 77000, loss: 0.215038
 >> iter 78000, loss: 0.202175
 >> iter 79000, loss: 0.300353
 >> iter 80000, loss: 0.183385
   Number of active neurons: 3
 >> iter 81000, loss: 0.168628
 >> iter 82000, loss: 0.238143
 >> iter 83000, loss: 0.191541
 >> iter 84000, loss: 0.189932
 >> iter 85000, loss: 0.214676
 >> iter 86000, loss: 0.153143
 >> iter 87000, loss: 0.218055
 >> iter 88000, loss: 0.235750
 >> iter 89000, loss: 0.213684
 >> iter 90000, loss: 0.157421
   Number of active neurons: 3
 >> iter 91000, loss: 0.290561
 >> iter 92000, loss: 0.340080
 >> iter 93000, loss: 0.179443
 >> iter 94000, loss: 0.145266
 >> iter 95000, loss: 0.241493
 >> iter 96000, loss: 0.199327
 >> iter 97000, loss: 0.227819
 >> iter 98000, loss: 0.125753
 >> iter 99000, loss: 0.128388
 >> iter 100000, loss: 0.232167
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.700396
 >> iter 2000, loss: 9.121706
 >> iter 3000, loss: 4.069450
 >> iter 4000, loss: 1.808908
 >> iter 5000, loss: 0.819939
 >> iter 6000, loss: 0.527261
 >> iter 7000, loss: 0.484204
 >> iter 8000, loss: 0.368941
 >> iter 9000, loss: 0.288038
 >> iter 10000, loss: 0.356044
   Number of active neurons: 5
 >> iter 11000, loss: 0.380140
 >> iter 12000, loss: 0.244644
 >> iter 13000, loss: 0.290020
 >> iter 14000, loss: 0.406515
 >> iter 15000, loss: 0.321071
 >> iter 16000, loss: 0.474529
 >> iter 17000, loss: 0.572933
 >> iter 18000, loss: 0.307148
 >> iter 19000, loss: 0.453954
 >> iter 20000, loss: 0.318652
   Number of active neurons: 5
 >> iter 21000, loss: 0.249795
 >> iter 22000, loss: 0.172090
 >> iter 23000, loss: 0.269903
 >> iter 24000, loss: 0.335367
 >> iter 25000, loss: 0.511679
 >> iter 26000, loss: 0.349868
 >> iter 27000, loss: 0.291511
 >> iter 28000, loss: 0.169108
 >> iter 29000, loss: 0.226506
 >> iter 30000, loss: 0.159338
   Number of active neurons: 5
 >> iter 31000, loss: 0.393214
 >> iter 32000, loss: 0.320704
 >> iter 33000, loss: 0.238952
 >> iter 34000, loss: 0.368888
 >> iter 35000, loss: 0.172536
 >> iter 36000, loss: 0.227682
 >> iter 37000, loss: 0.207097
 >> iter 38000, loss: 0.148673
 >> iter 39000, loss: 0.173182
 >> iter 40000, loss: 0.111025
   Number of active neurons: 4
 >> iter 41000, loss: 0.182893
 >> iter 42000, loss: 0.287900
 >> iter 43000, loss: 0.233404
 >> iter 44000, loss: 0.333988
 >> iter 45000, loss: 0.344771
 >> iter 46000, loss: 0.334180
 >> iter 47000, loss: 0.278374
 >> iter 48000, loss: 0.462848
 >> iter 49000, loss: 0.370240
 >> iter 50000, loss: 0.282049
   Number of active neurons: 4
 >> iter 51000, loss: 0.212209
 >> iter 52000, loss: 0.252865
 >> iter 53000, loss: 0.276535
 >> iter 54000, loss: 0.223817
 >> iter 55000, loss: 0.235498
 >> iter 56000, loss: 0.262117
 >> iter 57000, loss: 0.278091
 >> iter 58000, loss: 0.200502
 >> iter 59000, loss: 0.361243
 >> iter 60000, loss: 0.197022
   Number of active neurons: 4
 >> iter 61000, loss: 0.337942
 >> iter 62000, loss: 0.379788
 >> iter 63000, loss: 0.589256
 >> iter 64000, loss: 0.546167
 >> iter 65000, loss: 0.456333
 >> iter 66000, loss: 0.286757
 >> iter 67000, loss: 0.338173
 >> iter 68000, loss: 0.311619
 >> iter 69000, loss: 0.328625
 >> iter 70000, loss: 0.330164
   Number of active neurons: 4
 >> iter 71000, loss: 0.195508
 >> iter 72000, loss: 0.273762
 >> iter 73000, loss: 0.195768
 >> iter 74000, loss: 0.193172
 >> iter 75000, loss: 0.258403
 >> iter 76000, loss: 0.509456
 >> iter 77000, loss: 0.348892
 >> iter 78000, loss: 0.301827
 >> iter 79000, loss: 0.209617
 >> iter 80000, loss: 0.218251
   Number of active neurons: 3
 >> iter 81000, loss: 0.410023
 >> iter 82000, loss: 0.473582
 >> iter 83000, loss: 0.348638
 >> iter 84000, loss: 0.319319
 >> iter 85000, loss: 0.337894
 >> iter 86000, loss: 0.257258
 >> iter 87000, loss: 0.251065
 >> iter 88000, loss: 0.269599
 >> iter 89000, loss: 0.149680
 >> iter 90000, loss: 0.144932
   Number of active neurons: 3
 >> iter 91000, loss: 0.290240
 >> iter 92000, loss: 0.157494
 >> iter 93000, loss: 0.145040
 >> iter 94000, loss: 0.104367
 >> iter 95000, loss: 0.279767
 >> iter 96000, loss: 0.246632
 >> iter 97000, loss: 0.344199
 >> iter 98000, loss: 0.172292
 >> iter 99000, loss: 0.251817
 >> iter 100000, loss: 0.238561
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 17.132513
 >> iter 2000, loss: 8.323110
 >> iter 3000, loss: 3.639256
 >> iter 4000, loss: 1.713834
 >> iter 5000, loss: 0.772348
 >> iter 6000, loss: 0.392824
 >> iter 7000, loss: 0.588641
 >> iter 8000, loss: 0.466933
 >> iter 9000, loss: 0.556483
 >> iter 10000, loss: 0.576880
   Number of active neurons: 4
 >> iter 11000, loss: 0.396399
 >> iter 12000, loss: 0.228718
 >> iter 13000, loss: 0.318679
 >> iter 14000, loss: 0.455622
 >> iter 15000, loss: 0.346759
 >> iter 16000, loss: 0.281548
 >> iter 17000, loss: 0.178419
 >> iter 18000, loss: 0.311905
 >> iter 19000, loss: 0.213542
 >> iter 20000, loss: 0.218711
   Number of active neurons: 4
 >> iter 21000, loss: 0.215767
 >> iter 22000, loss: 0.299778
 >> iter 23000, loss: 0.330132
 >> iter 24000, loss: 0.328174
 >> iter 25000, loss: 0.259402
 >> iter 26000, loss: 0.303515
 >> iter 27000, loss: 0.373692
 >> iter 28000, loss: 0.377577
 >> iter 29000, loss: 0.262537
 >> iter 30000, loss: 0.420160
   Number of active neurons: 4
 >> iter 31000, loss: 0.340010
 >> iter 32000, loss: 0.336148
 >> iter 33000, loss: 0.274304
 >> iter 34000, loss: 0.289050
 >> iter 35000, loss: 0.290180
 >> iter 36000, loss: 0.210849
 >> iter 37000, loss: 0.296033
 >> iter 38000, loss: 0.182150
 >> iter 39000, loss: 0.126400
 >> iter 40000, loss: 0.281519
   Number of active neurons: 3
 >> iter 41000, loss: 0.210743
 >> iter 42000, loss: 0.159024
 >> iter 43000, loss: 0.215464
 >> iter 44000, loss: 0.288276
 >> iter 45000, loss: 0.252771
 >> iter 46000, loss: 0.156501
 >> iter 47000, loss: 0.269973
 >> iter 48000, loss: 0.255919
 >> iter 49000, loss: 0.281037
 >> iter 50000, loss: 0.264436
   Number of active neurons: 3
 >> iter 51000, loss: 0.265282
 >> iter 52000, loss: 0.218121
 >> iter 53000, loss: 0.406227
 >> iter 54000, loss: 0.376025
 >> iter 55000, loss: 0.206531
 >> iter 56000, loss: 0.220322
 >> iter 57000, loss: 0.232201
 >> iter 58000, loss: 0.210777
 >> iter 59000, loss: 0.157170
 >> iter 60000, loss: 0.235139
   Number of active neurons: 3
 >> iter 61000, loss: 0.402387
 >> iter 62000, loss: 0.339620
 >> iter 63000, loss: 0.354880
 >> iter 64000, loss: 0.310322
 >> iter 65000, loss: 0.170948
 >> iter 66000, loss: 0.292784
 >> iter 67000, loss: 0.263641
 >> iter 68000, loss: 0.304137
 >> iter 69000, loss: 0.186022
 >> iter 70000, loss: 0.247889
   Number of active neurons: 3
 >> iter 71000, loss: 0.295386
 >> iter 72000, loss: 0.231543
 >> iter 73000, loss: 0.197798
 >> iter 74000, loss: 0.219399
 >> iter 75000, loss: 0.201123
 >> iter 76000, loss: 0.208941
 >> iter 77000, loss: 0.238890
 >> iter 78000, loss: 0.198675
 >> iter 79000, loss: 0.171869
 >> iter 80000, loss: 0.238056
   Number of active neurons: 3
 >> iter 81000, loss: 0.247644
 >> iter 82000, loss: 0.263080
 >> iter 83000, loss: 0.341459
 >> iter 84000, loss: 0.347982
 >> iter 85000, loss: 0.158306
 >> iter 86000, loss: 0.194343
 >> iter 87000, loss: 0.105468
 >> iter 88000, loss: 0.212270
 >> iter 89000, loss: 0.237701
 >> iter 90000, loss: 0.281143
   Number of active neurons: 3
 >> iter 91000, loss: 0.255117
 >> iter 92000, loss: 0.277864
 >> iter 93000, loss: 0.343634
 >> iter 94000, loss: 0.166481
 >> iter 95000, loss: 0.123791
 >> iter 96000, loss: 0.181148
 >> iter 97000, loss: 0.248462
 >> iter 98000, loss: 0.363386
 >> iter 99000, loss: 0.317065
 >> iter 100000, loss: 0.217095
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.734604
 >> iter 2000, loss: 9.243334
 >> iter 3000, loss: 4.671463
 >> iter 4000, loss: 2.737741
 >> iter 5000, loss: 1.514932
 >> iter 6000, loss: 0.931306
 >> iter 7000, loss: 0.651212
 >> iter 8000, loss: 0.378260
 >> iter 9000, loss: 0.518782
 >> iter 10000, loss: 0.392373
   Number of active neurons: 5
 >> iter 11000, loss: 0.330718
 >> iter 12000, loss: 0.392116
 >> iter 13000, loss: 0.377374
 >> iter 14000, loss: 0.573647
 >> iter 15000, loss: 0.354231
 >> iter 16000, loss: 0.369608
 >> iter 17000, loss: 0.392590
 >> iter 18000, loss: 0.335397
 >> iter 19000, loss: 0.356854
 >> iter 20000, loss: 0.557771
   Number of active neurons: 4
 >> iter 21000, loss: 0.353316
 >> iter 22000, loss: 0.502358
 >> iter 23000, loss: 0.297220
 >> iter 24000, loss: 0.230589
 >> iter 25000, loss: 0.236098
 >> iter 26000, loss: 0.311244
 >> iter 27000, loss: 0.236919
 >> iter 28000, loss: 0.349911
 >> iter 29000, loss: 0.449567
 >> iter 30000, loss: 0.423052
   Number of active neurons: 4
 >> iter 31000, loss: 0.342704
 >> iter 32000, loss: 0.211101
 >> iter 33000, loss: 0.195138
 >> iter 34000, loss: 0.389307
 >> iter 35000, loss: 0.324559
 >> iter 36000, loss: 0.232395
 >> iter 37000, loss: 0.234153
 >> iter 38000, loss: 0.235460
 >> iter 39000, loss: 0.380669
 >> iter 40000, loss: 0.222844
   Number of active neurons: 4
 >> iter 41000, loss: 0.249015
 >> iter 42000, loss: 0.254052
 >> iter 43000, loss: 0.258710
 >> iter 44000, loss: 0.259651
 >> iter 45000, loss: 0.217179
 >> iter 46000, loss: 0.313275
 >> iter 47000, loss: 0.316437
 >> iter 48000, loss: 0.398802
 >> iter 49000, loss: 0.254106
 >> iter 50000, loss: 0.530985
   Number of active neurons: 4
 >> iter 51000, loss: 0.323100
 >> iter 52000, loss: 0.422892
 >> iter 53000, loss: 0.251629
 >> iter 54000, loss: 0.156352
 >> iter 55000, loss: 0.241948
 >> iter 56000, loss: 0.199693
 >> iter 57000, loss: 0.176906
 >> iter 58000, loss: 0.175522
 >> iter 59000, loss: 0.284977
 >> iter 60000, loss: 0.325759
   Number of active neurons: 4
 >> iter 61000, loss: 0.357970
 >> iter 62000, loss: 0.304895
 >> iter 63000, loss: 0.301288
 >> iter 64000, loss: 0.202152
 >> iter 65000, loss: 0.151031
 >> iter 66000, loss: 0.218299
 >> iter 67000, loss: 0.368053
 >> iter 68000, loss: 0.302107
 >> iter 69000, loss: 0.259959
 >> iter 70000, loss: 0.281297
   Number of active neurons: 4
 >> iter 71000, loss: 0.344030
 >> iter 72000, loss: 0.357161
 >> iter 73000, loss: 0.179142
 >> iter 74000, loss: 0.095290
 >> iter 75000, loss: 0.160427
 >> iter 76000, loss: 0.243179
 >> iter 77000, loss: 0.276377
 >> iter 78000, loss: 0.312952
 >> iter 79000, loss: 0.251825
 >> iter 80000, loss: 0.235416
   Number of active neurons: 4
 >> iter 81000, loss: 0.295509
 >> iter 82000, loss: 0.174628
 >> iter 83000, loss: 0.236251
 >> iter 84000, loss: 0.324640
 >> iter 85000, loss: 0.289408
 >> iter 86000, loss: 0.263975
 >> iter 87000, loss: 0.246755
 >> iter 88000, loss: 0.161418
 >> iter 89000, loss: 0.194963
 >> iter 90000, loss: 0.233528
   Number of active neurons: 4
 >> iter 91000, loss: 0.213981
 >> iter 92000, loss: 0.249755
 >> iter 93000, loss: 0.209814
 >> iter 94000, loss: 0.185172
 >> iter 95000, loss: 0.216523
 >> iter 96000, loss: 0.264513
 >> iter 97000, loss: 0.161713
 >> iter 98000, loss: 0.439641
 >> iter 99000, loss: 0.334782
 >> iter 100000, loss: 0.167219
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.933205
 >> iter 2000, loss: 8.948525
 >> iter 3000, loss: 3.951045
 >> iter 4000, loss: 1.688149
 >> iter 5000, loss: 1.123376
 >> iter 6000, loss: 0.689185
 >> iter 7000, loss: 0.502394
 >> iter 8000, loss: 0.337988
 >> iter 9000, loss: 0.315415
 >> iter 10000, loss: 0.387702
   Number of active neurons: 3
 >> iter 11000, loss: 0.573730
 >> iter 12000, loss: 0.463813
 >> iter 13000, loss: 0.405414
 >> iter 14000, loss: 0.227016
 >> iter 15000, loss: 0.322632
 >> iter 16000, loss: 0.255682
 >> iter 17000, loss: 0.277327
 >> iter 18000, loss: 0.220585
 >> iter 19000, loss: 0.205439
 >> iter 20000, loss: 0.322090
   Number of active neurons: 3
 >> iter 21000, loss: 0.405873
 >> iter 22000, loss: 0.346014
 >> iter 23000, loss: 0.410205
 >> iter 24000, loss: 0.441191
 >> iter 25000, loss: 0.201631
 >> iter 26000, loss: 0.142585
 >> iter 27000, loss: 0.175089
 >> iter 28000, loss: 0.199559
 >> iter 29000, loss: 0.333913
 >> iter 30000, loss: 0.257369
   Number of active neurons: 3
 >> iter 31000, loss: 0.257090
 >> iter 32000, loss: 0.248226
 >> iter 33000, loss: 0.213334
 >> iter 34000, loss: 0.229269
 >> iter 35000, loss: 0.321317
 >> iter 36000, loss: 0.393279
 >> iter 37000, loss: 0.213921
 >> iter 38000, loss: 0.283892
 >> iter 39000, loss: 0.228939
 >> iter 40000, loss: 0.362439
   Number of active neurons: 3
 >> iter 41000, loss: 0.377974
 >> iter 42000, loss: 0.266359
 >> iter 43000, loss: 0.328215
 >> iter 44000, loss: 0.277601
 >> iter 45000, loss: 0.356333
 >> iter 46000, loss: 0.433403
 >> iter 47000, loss: 0.232683
 >> iter 48000, loss: 0.236238
 >> iter 49000, loss: 0.217892
 >> iter 50000, loss: 0.194939
   Number of active neurons: 3
 >> iter 51000, loss: 0.247173
 >> iter 52000, loss: 0.274880
 >> iter 53000, loss: 0.194165
 >> iter 54000, loss: 0.226437
 >> iter 55000, loss: 0.167607
 >> iter 56000, loss: 0.297831
 >> iter 57000, loss: 0.369171
 >> iter 58000, loss: 0.362119
 >> iter 59000, loss: 0.347085
 >> iter 60000, loss: 0.232233
   Number of active neurons: 3
 >> iter 61000, loss: 0.250849
 >> iter 62000, loss: 0.259108
 >> iter 63000, loss: 0.464515
 >> iter 64000, loss: 0.353579
 >> iter 65000, loss: 0.304831
 >> iter 66000, loss: 0.176907
 >> iter 67000, loss: 0.204982
 >> iter 68000, loss: 0.209469
 >> iter 69000, loss: 0.245830
 >> iter 70000, loss: 0.161056
   Number of active neurons: 3
 >> iter 71000, loss: 0.132727
 >> iter 72000, loss: 0.161596
 >> iter 73000, loss: 0.162134
 >> iter 74000, loss: 0.199899
 >> iter 75000, loss: 0.285028
 >> iter 76000, loss: 0.287779
 >> iter 77000, loss: 0.220003
 >> iter 78000, loss: 0.175650
 >> iter 79000, loss: 0.135299
 >> iter 80000, loss: 0.130715
   Number of active neurons: 3
 >> iter 81000, loss: 0.178405
 >> iter 82000, loss: 0.219885
 >> iter 83000, loss: 0.188206
 >> iter 84000, loss: 0.576683
 >> iter 85000, loss: 0.320152
 >> iter 86000, loss: 0.200863
 >> iter 87000, loss: 0.284770
 >> iter 88000, loss: 0.373816
 >> iter 89000, loss: 0.361260
 >> iter 90000, loss: 0.318980
   Number of active neurons: 3
 >> iter 91000, loss: 0.169458
 >> iter 92000, loss: 0.232233
 >> iter 93000, loss: 0.408808
 >> iter 94000, loss: 0.322281
 >> iter 95000, loss: 0.189915
 >> iter 96000, loss: 0.363547
 >> iter 97000, loss: 0.191284
 >> iter 98000, loss: 0.301476
 >> iter 99000, loss: 0.240172
 >> iter 100000, loss: 0.124711
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.993562
 >> iter 2000, loss: 9.301796
 >> iter 3000, loss: 4.399901
 >> iter 4000, loss: 2.245836
 >> iter 5000, loss: 1.356045
 >> iter 6000, loss: 1.010295
 >> iter 7000, loss: 0.585467
 >> iter 8000, loss: 0.429457
 >> iter 9000, loss: 0.621955
 >> iter 10000, loss: 0.332190
   Number of active neurons: 5
 >> iter 11000, loss: 0.492717
 >> iter 12000, loss: 0.396359
 >> iter 13000, loss: 0.500845
 >> iter 14000, loss: 0.379795
 >> iter 15000, loss: 0.287863
 >> iter 16000, loss: 0.222594
 >> iter 17000, loss: 0.250711
 >> iter 18000, loss: 0.197641
 >> iter 19000, loss: 0.285597
 >> iter 20000, loss: 0.210080
   Number of active neurons: 5
 >> iter 21000, loss: 0.274214
 >> iter 22000, loss: 0.428225
 >> iter 23000, loss: 0.412718
 >> iter 24000, loss: 0.277270
 >> iter 25000, loss: 0.250679
 >> iter 26000, loss: 0.281161
 >> iter 27000, loss: 0.145195
 >> iter 28000, loss: 0.231363
 >> iter 29000, loss: 0.296659
 >> iter 30000, loss: 0.239691
   Number of active neurons: 5
 >> iter 31000, loss: 0.322451
 >> iter 32000, loss: 0.615202
 >> iter 33000, loss: 0.425532
 >> iter 34000, loss: 0.208655
 >> iter 35000, loss: 0.239440
 >> iter 36000, loss: 0.287000
 >> iter 37000, loss: 0.212603
 >> iter 38000, loss: 0.190697
 >> iter 39000, loss: 0.226680
 >> iter 40000, loss: 0.320582
   Number of active neurons: 5
 >> iter 41000, loss: 0.436191
 >> iter 42000, loss: 0.319340
 >> iter 43000, loss: 0.287445
 >> iter 44000, loss: 0.305193
 >> iter 45000, loss: 0.257421
 >> iter 46000, loss: 0.299200
 >> iter 47000, loss: 0.524135
 >> iter 48000, loss: 0.332486
 >> iter 49000, loss: 0.248248
 >> iter 50000, loss: 0.178419
   Number of active neurons: 4
 >> iter 51000, loss: 0.150736
 >> iter 52000, loss: 0.203612
 >> iter 53000, loss: 0.219851
 >> iter 54000, loss: 0.439662
 >> iter 55000, loss: 0.330873
 >> iter 56000, loss: 0.344003
 >> iter 57000, loss: 0.188274
 >> iter 58000, loss: 0.197822
 >> iter 59000, loss: 0.188089
 >> iter 60000, loss: 0.365982
   Number of active neurons: 4
 >> iter 61000, loss: 0.392614
 >> iter 62000, loss: 0.349392
 >> iter 63000, loss: 0.202712
 >> iter 64000, loss: 0.158369
 >> iter 65000, loss: 0.165475
 >> iter 66000, loss: 0.268646
 >> iter 67000, loss: 0.243644
 >> iter 68000, loss: 0.159635
 >> iter 69000, loss: 0.215250
 >> iter 70000, loss: 0.247274
   Number of active neurons: 4
 >> iter 71000, loss: 0.285379
 >> iter 72000, loss: 0.327082
 >> iter 73000, loss: 0.208389
 >> iter 74000, loss: 0.337375
 >> iter 75000, loss: 0.353029
 >> iter 76000, loss: 0.188417
 >> iter 77000, loss: 0.250832
 >> iter 78000, loss: 0.183195
 >> iter 79000, loss: 0.316391
 >> iter 80000, loss: 0.213458
   Number of active neurons: 4
 >> iter 81000, loss: 0.173616
 >> iter 82000, loss: 0.212967
 >> iter 83000, loss: 0.199976
 >> iter 84000, loss: 0.152111
 >> iter 85000, loss: 0.247316
 >> iter 86000, loss: 0.206306
 >> iter 87000, loss: 0.291063
 >> iter 88000, loss: 0.238372
 >> iter 89000, loss: 0.180446
 >> iter 90000, loss: 0.264505
   Number of active neurons: 3
 >> iter 91000, loss: 0.273655
 >> iter 92000, loss: 0.220215
 >> iter 93000, loss: 0.203572
 >> iter 94000, loss: 0.371825
 >> iter 95000, loss: 0.226248
 >> iter 96000, loss: 0.121451
 >> iter 97000, loss: 0.142825
 >> iter 98000, loss: 0.223583
 >> iter 99000, loss: 0.231571
 >> iter 100000, loss: 0.201921
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.395113
 >> iter 2000, loss: 9.384217
 >> iter 3000, loss: 4.642007
 >> iter 4000, loss: 2.172987
 >> iter 5000, loss: 1.362571
 >> iter 6000, loss: 0.910751
 >> iter 7000, loss: 0.600752
 >> iter 8000, loss: 0.461324
 >> iter 9000, loss: 0.453446
 >> iter 10000, loss: 0.441182
   Number of active neurons: 4
 >> iter 11000, loss: 0.349656
 >> iter 12000, loss: 0.266733
 >> iter 13000, loss: 0.248983
 >> iter 14000, loss: 0.308054
 >> iter 15000, loss: 0.470140
 >> iter 16000, loss: 0.481056
 >> iter 17000, loss: 0.439028
 >> iter 18000, loss: 0.461719
 >> iter 19000, loss: 0.333431
 >> iter 20000, loss: 0.365861
   Number of active neurons: 4
 >> iter 21000, loss: 0.340033
 >> iter 22000, loss: 0.236570
 >> iter 23000, loss: 0.237269
 >> iter 24000, loss: 0.404489
 >> iter 25000, loss: 0.373916
 >> iter 26000, loss: 0.426240
 >> iter 27000, loss: 0.523913
 >> iter 28000, loss: 0.331759
 >> iter 29000, loss: 0.499565
 >> iter 30000, loss: 0.468843
   Number of active neurons: 3
 >> iter 31000, loss: 0.466139
 >> iter 32000, loss: 0.255806
 >> iter 33000, loss: 0.342695
 >> iter 34000, loss: 0.318750
 >> iter 35000, loss: 0.251972
 >> iter 36000, loss: 0.306048
 >> iter 37000, loss: 0.341425
 >> iter 38000, loss: 0.165321
 >> iter 39000, loss: 0.360158
 >> iter 40000, loss: 0.320822
   Number of active neurons: 3
 >> iter 41000, loss: 0.243866
 >> iter 42000, loss: 0.325073
 >> iter 43000, loss: 0.281015
 >> iter 44000, loss: 0.318998
 >> iter 45000, loss: 0.381469
 >> iter 46000, loss: 0.364824
 >> iter 47000, loss: 0.403534
 >> iter 48000, loss: 0.361618
 >> iter 49000, loss: 0.330224
 >> iter 50000, loss: 0.307912
   Number of active neurons: 3
 >> iter 51000, loss: 0.215146
 >> iter 52000, loss: 0.230311
 >> iter 53000, loss: 0.280171
 >> iter 54000, loss: 0.221656
 >> iter 55000, loss: 0.231937
 >> iter 56000, loss: 0.307542
 >> iter 57000, loss: 0.264521
 >> iter 58000, loss: 0.374482
 >> iter 59000, loss: 0.416752
 >> iter 60000, loss: 0.281306
   Number of active neurons: 3
 >> iter 61000, loss: 0.199397
 >> iter 62000, loss: 0.202897
 >> iter 63000, loss: 0.283624
 >> iter 64000, loss: 0.412670
 >> iter 65000, loss: 0.231085
 >> iter 66000, loss: 0.207056
 >> iter 67000, loss: 0.216420
 >> iter 68000, loss: 0.258629
 >> iter 69000, loss: 0.217713
 >> iter 70000, loss: 0.322988
   Number of active neurons: 3
 >> iter 71000, loss: 0.258696
 >> iter 72000, loss: 0.267180
 >> iter 73000, loss: 0.379753
 >> iter 74000, loss: 0.354188
 >> iter 75000, loss: 0.179545
 >> iter 76000, loss: 0.373903
 >> iter 77000, loss: 0.442714
 >> iter 78000, loss: 0.232164
 >> iter 79000, loss: 0.449241
 >> iter 80000, loss: 0.391318
   Number of active neurons: 3
 >> iter 81000, loss: 0.393270
 >> iter 82000, loss: 0.240446
 >> iter 83000, loss: 0.395749
 >> iter 84000, loss: 0.243845
 >> iter 85000, loss: 0.200844
 >> iter 86000, loss: 0.153097
 >> iter 87000, loss: 0.125262
 >> iter 88000, loss: 0.315995
 >> iter 89000, loss: 0.214843
 >> iter 90000, loss: 0.264190
   Number of active neurons: 3
 >> iter 91000, loss: 0.231234
 >> iter 92000, loss: 0.403316
 >> iter 93000, loss: 0.209253
 >> iter 94000, loss: 0.112763
 >> iter 95000, loss: 0.165824
 >> iter 96000, loss: 0.384310
 >> iter 97000, loss: 0.264626
 >> iter 98000, loss: 0.334264
 >> iter 99000, loss: 0.238971
 >> iter 100000, loss: 0.244717
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.395583
 >> iter 2000, loss: 8.638554
 >> iter 3000, loss: 4.049916
 >> iter 4000, loss: 1.865577
 >> iter 5000, loss: 1.187531
 >> iter 6000, loss: 0.853393
 >> iter 7000, loss: 0.577457
 >> iter 8000, loss: 0.434042
 >> iter 9000, loss: 0.390539
 >> iter 10000, loss: 0.279411
   Number of active neurons: 6
 >> iter 11000, loss: 0.303033
 >> iter 12000, loss: 0.409162
 >> iter 13000, loss: 0.439211
 >> iter 14000, loss: 0.347836
 >> iter 15000, loss: 0.426605
 >> iter 16000, loss: 0.394649
 >> iter 17000, loss: 0.260509
 >> iter 18000, loss: 0.483615
 >> iter 19000, loss: 0.484451
 >> iter 20000, loss: 0.534737
   Number of active neurons: 5
 >> iter 21000, loss: 0.591768
 >> iter 22000, loss: 0.498682
 >> iter 23000, loss: 0.410971
 >> iter 24000, loss: 0.211884
 >> iter 25000, loss: 0.280183
 >> iter 26000, loss: 0.188437
 >> iter 27000, loss: 0.590220
 >> iter 28000, loss: 0.378903
 >> iter 29000, loss: 0.290108
 >> iter 30000, loss: 0.449788
   Number of active neurons: 5
 >> iter 31000, loss: 0.440129
 >> iter 32000, loss: 0.355555
 >> iter 33000, loss: 0.343804
 >> iter 34000, loss: 0.261698
 >> iter 35000, loss: 0.495586
 >> iter 36000, loss: 0.468243
 >> iter 37000, loss: 0.343620
 >> iter 38000, loss: 0.202291
 >> iter 39000, loss: 0.238504
 >> iter 40000, loss: 0.206902
   Number of active neurons: 5
 >> iter 41000, loss: 0.267148
 >> iter 42000, loss: 0.227009
 >> iter 43000, loss: 0.225843
 >> iter 44000, loss: 0.380709
 >> iter 45000, loss: 0.522669
 >> iter 46000, loss: 0.361618
 >> iter 47000, loss: 0.203074
 >> iter 48000, loss: 0.353912
 >> iter 49000, loss: 0.206021
 >> iter 50000, loss: 0.271126
   Number of active neurons: 5
 >> iter 51000, loss: 0.257545
 >> iter 52000, loss: 0.285887
 >> iter 53000, loss: 0.415371
 >> iter 54000, loss: 0.484808
 >> iter 55000, loss: 0.454437
 >> iter 56000, loss: 0.282106
 >> iter 57000, loss: 0.295834
 >> iter 58000, loss: 0.226408
 >> iter 59000, loss: 0.228525
 >> iter 60000, loss: 0.196050
   Number of active neurons: 5
 >> iter 61000, loss: 0.241412
 >> iter 62000, loss: 0.406925
 >> iter 63000, loss: 0.443831
 >> iter 64000, loss: 0.321769
 >> iter 65000, loss: 0.297046
 >> iter 66000, loss: 0.240533
 >> iter 67000, loss: 0.344305
 >> iter 68000, loss: 0.499484
 >> iter 69000, loss: 0.369027
 >> iter 70000, loss: 0.216183
   Number of active neurons: 5
 >> iter 71000, loss: 0.327248
 >> iter 72000, loss: 0.290077
 >> iter 73000, loss: 0.201319
 >> iter 74000, loss: 0.204194
 >> iter 75000, loss: 0.353431
 >> iter 76000, loss: 0.386052
 >> iter 77000, loss: 0.357747
 >> iter 78000, loss: 0.317578
 >> iter 79000, loss: 0.296384
 >> iter 80000, loss: 0.418671
   Number of active neurons: 4
 >> iter 81000, loss: 0.309153
 >> iter 82000, loss: 0.396494
 >> iter 83000, loss: 0.213272
 >> iter 84000, loss: 0.168708
 >> iter 85000, loss: 0.248262
 >> iter 86000, loss: 0.226197
 >> iter 87000, loss: 0.220723
 >> iter 88000, loss: 0.277914
 >> iter 89000, loss: 0.229518
 >> iter 90000, loss: 0.343488
   Number of active neurons: 4
 >> iter 91000, loss: 0.306736
 >> iter 92000, loss: 0.383692
 >> iter 93000, loss: 0.376755
 >> iter 94000, loss: 0.359528
 >> iter 95000, loss: 0.170829
 >> iter 96000, loss: 0.343267
 >> iter 97000, loss: 0.384310
 >> iter 98000, loss: 0.437285
 >> iter 99000, loss: 0.288331
 >> iter 100000, loss: 0.201433
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.343806
 >> iter 2000, loss: 9.126822
 >> iter 3000, loss: 4.051339
 >> iter 4000, loss: 1.830651
 >> iter 5000, loss: 1.054395
 >> iter 6000, loss: 0.748879
 >> iter 7000, loss: 0.540878
 >> iter 8000, loss: 0.623869
 >> iter 9000, loss: 0.402811
 >> iter 10000, loss: 0.247475
   Number of active neurons: 4
 >> iter 11000, loss: 0.343395
 >> iter 12000, loss: 0.384372
 >> iter 13000, loss: 0.422407
 >> iter 14000, loss: 0.331480
 >> iter 15000, loss: 0.275262
 >> iter 16000, loss: 0.263870
 >> iter 17000, loss: 0.361302
 >> iter 18000, loss: 0.369889
 >> iter 19000, loss: 0.199764
 >> iter 20000, loss: 0.313088
   Number of active neurons: 4
 >> iter 21000, loss: 0.467690
 >> iter 22000, loss: 0.352786
 >> iter 23000, loss: 0.549177
 >> iter 24000, loss: 0.447853
 >> iter 25000, loss: 0.275442
 >> iter 26000, loss: 0.291844
 >> iter 27000, loss: 0.364032
 >> iter 28000, loss: 0.377214
 >> iter 29000, loss: 0.427900
 >> iter 30000, loss: 0.315825
   Number of active neurons: 4
 >> iter 31000, loss: 0.337126
 >> iter 32000, loss: 0.508038
 >> iter 33000, loss: 0.256226
 >> iter 34000, loss: 0.224891
 >> iter 35000, loss: 0.262158
 >> iter 36000, loss: 0.317532
 >> iter 37000, loss: 0.466808
 >> iter 38000, loss: 0.476589
 >> iter 39000, loss: 0.394693
 >> iter 40000, loss: 0.568692
   Number of active neurons: 4
 >> iter 41000, loss: 0.355604
 >> iter 42000, loss: 0.451245
 >> iter 43000, loss: 0.336379
 >> iter 44000, loss: 0.299465
 >> iter 45000, loss: 0.526331
 >> iter 46000, loss: 0.420567
 >> iter 47000, loss: 0.423912
 >> iter 48000, loss: 0.248880
 >> iter 49000, loss: 0.350325
 >> iter 50000, loss: 0.259008
   Number of active neurons: 4
 >> iter 51000, loss: 0.331098
 >> iter 52000, loss: 0.232835
 >> iter 53000, loss: 0.207024
 >> iter 54000, loss: 0.177684
 >> iter 55000, loss: 0.222487
 >> iter 56000, loss: 0.166544
 >> iter 57000, loss: 0.329618
 >> iter 58000, loss: 0.288210
 >> iter 59000, loss: 0.148269
 >> iter 60000, loss: 0.176774
   Number of active neurons: 4
 >> iter 61000, loss: 0.285234
 >> iter 62000, loss: 0.289289
 >> iter 63000, loss: 0.349199
 >> iter 64000, loss: 0.346931
 >> iter 65000, loss: 0.262339
 >> iter 66000, loss: 0.340563
 >> iter 67000, loss: 0.334316
 >> iter 68000, loss: 0.543263
 >> iter 69000, loss: 0.420008
 >> iter 70000, loss: 0.368965
   Number of active neurons: 3
 >> iter 71000, loss: 0.288424
 >> iter 72000, loss: 0.284378
 >> iter 73000, loss: 0.315795
 >> iter 74000, loss: 0.208607
 >> iter 75000, loss: 0.233870
 >> iter 76000, loss: 0.434370
 >> iter 77000, loss: 0.316069
 >> iter 78000, loss: 0.311177
 >> iter 79000, loss: 0.370943
 >> iter 80000, loss: 0.283438
   Number of active neurons: 3
 >> iter 81000, loss: 0.285750
 >> iter 82000, loss: 0.335076
 >> iter 83000, loss: 0.300660
 >> iter 84000, loss: 0.248556
 >> iter 85000, loss: 0.254833
 >> iter 86000, loss: 0.242585
 >> iter 87000, loss: 0.405734
 >> iter 88000, loss: 0.272214
 >> iter 89000, loss: 0.178937
 >> iter 90000, loss: 0.357484
   Number of active neurons: 3
 >> iter 91000, loss: 0.342049
 >> iter 92000, loss: 0.312335
 >> iter 93000, loss: 0.242119
 >> iter 94000, loss: 0.177708
 >> iter 95000, loss: 0.249174
 >> iter 96000, loss: 0.291583
 >> iter 97000, loss: 0.237489
 >> iter 98000, loss: 0.247537
 >> iter 99000, loss: 0.304569
 >> iter 100000, loss: 0.257656
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.758087
 >> iter 2000, loss: 8.440378
 >> iter 3000, loss: 3.871350
 >> iter 4000, loss: 1.730986
 >> iter 5000, loss: 1.021134
 >> iter 6000, loss: 0.509411
 >> iter 7000, loss: 0.380375
 >> iter 8000, loss: 0.434402
 >> iter 9000, loss: 0.387100
 >> iter 10000, loss: 0.273674
   Number of active neurons: 5
 >> iter 11000, loss: 0.363154
 >> iter 12000, loss: 0.343367
 >> iter 13000, loss: 0.395776
 >> iter 14000, loss: 0.550393
 >> iter 15000, loss: 0.526131
 >> iter 16000, loss: 0.341170
 >> iter 17000, loss: 0.347451
 >> iter 18000, loss: 0.420434
 >> iter 19000, loss: 0.232159
 >> iter 20000, loss: 0.254072
   Number of active neurons: 5
 >> iter 21000, loss: 0.311386
 >> iter 22000, loss: 0.223981
 >> iter 23000, loss: 0.229875
 >> iter 24000, loss: 0.250428
 >> iter 25000, loss: 0.223513
 >> iter 26000, loss: 0.236875
 >> iter 27000, loss: 0.284795
 >> iter 28000, loss: 0.382409
 >> iter 29000, loss: 0.535951
 >> iter 30000, loss: 0.430960
   Number of active neurons: 4
 >> iter 31000, loss: 0.519883
 >> iter 32000, loss: 0.442189
 >> iter 33000, loss: 0.525827
 >> iter 34000, loss: 0.265585
 >> iter 35000, loss: 0.271953
 >> iter 36000, loss: 0.190249
 >> iter 37000, loss: 0.297504
 >> iter 38000, loss: 0.254957
 >> iter 39000, loss: 0.156117
 >> iter 40000, loss: 0.359180
   Number of active neurons: 3
 >> iter 41000, loss: 0.266968
 >> iter 42000, loss: 0.457351
 >> iter 43000, loss: 0.396332
 >> iter 44000, loss: 0.249685
 >> iter 45000, loss: 0.188391
 >> iter 46000, loss: 0.320010
 >> iter 47000, loss: 0.308161
 >> iter 48000, loss: 0.240133
 >> iter 49000, loss: 0.223541
 >> iter 50000, loss: 0.299680
   Number of active neurons: 3
 >> iter 51000, loss: 0.336686
 >> iter 52000, loss: 0.236095
 >> iter 53000, loss: 0.403187
 >> iter 54000, loss: 0.207695
 >> iter 55000, loss: 0.184129
 >> iter 56000, loss: 0.205768
 >> iter 57000, loss: 0.392478
 >> iter 58000, loss: 0.301820
 >> iter 59000, loss: 0.229525
 >> iter 60000, loss: 0.213319
   Number of active neurons: 3
 >> iter 61000, loss: 0.162841
 >> iter 62000, loss: 0.153812
 >> iter 63000, loss: 0.168096
 >> iter 64000, loss: 0.279075
 >> iter 65000, loss: 0.335329
 >> iter 66000, loss: 0.165207
 >> iter 67000, loss: 0.498338
 >> iter 68000, loss: 0.659632
 >> iter 69000, loss: 0.406916
 >> iter 70000, loss: 0.378917
   Number of active neurons: 3
 >> iter 71000, loss: 0.264292
 >> iter 72000, loss: 0.273125
 >> iter 73000, loss: 0.198746
 >> iter 74000, loss: 0.262247
 >> iter 75000, loss: 0.393141
 >> iter 76000, loss: 0.294897
 >> iter 77000, loss: 0.143336
 >> iter 78000, loss: 0.200967
 >> iter 79000, loss: 0.236382
 >> iter 80000, loss: 0.295109
   Number of active neurons: 3
 >> iter 81000, loss: 0.305130
 >> iter 82000, loss: 0.336862
 >> iter 83000, loss: 0.422038
 >> iter 84000, loss: 0.257906
 >> iter 85000, loss: 0.370310
 >> iter 86000, loss: 0.367066
 >> iter 87000, loss: 0.208515
 >> iter 88000, loss: 0.139815
 >> iter 89000, loss: 0.298461
 >> iter 90000, loss: 0.369094
   Number of active neurons: 3
 >> iter 91000, loss: 0.216459
 >> iter 92000, loss: 0.231816
 >> iter 93000, loss: 0.141855
 >> iter 94000, loss: 0.344689
 >> iter 95000, loss: 0.248454
 >> iter 96000, loss: 0.153857
 >> iter 97000, loss: 0.337829
 >> iter 98000, loss: 0.217508
 >> iter 99000, loss: 0.113143
 >> iter 100000, loss: 0.157082
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.700963
 >> iter 2000, loss: 8.322922
 >> iter 3000, loss: 3.693195
 >> iter 4000, loss: 1.834057
 >> iter 5000, loss: 1.022977
 >> iter 6000, loss: 0.581405
 >> iter 7000, loss: 0.498545
 >> iter 8000, loss: 0.606461
 >> iter 9000, loss: 0.496850
 >> iter 10000, loss: 0.305161
   Number of active neurons: 4
 >> iter 11000, loss: 0.524973
 >> iter 12000, loss: 0.442179
 >> iter 13000, loss: 0.308940
 >> iter 14000, loss: 0.252345
 >> iter 15000, loss: 0.247174
 >> iter 16000, loss: 0.313484
 >> iter 17000, loss: 0.265317
 >> iter 18000, loss: 0.150319
 >> iter 19000, loss: 0.156948
 >> iter 20000, loss: 0.289185
   Number of active neurons: 4
 >> iter 21000, loss: 0.194863
 >> iter 22000, loss: 0.128409
 >> iter 23000, loss: 0.190022
 >> iter 24000, loss: 0.511939
 >> iter 25000, loss: 0.452769
 >> iter 26000, loss: 0.267687
 >> iter 27000, loss: 0.419791
 >> iter 28000, loss: 0.363205
 >> iter 29000, loss: 0.284865
 >> iter 30000, loss: 0.401662
   Number of active neurons: 4
 >> iter 31000, loss: 0.184706
 >> iter 32000, loss: 0.308301
 >> iter 33000, loss: 0.275182
 >> iter 34000, loss: 0.257962
 >> iter 35000, loss: 0.379696
 >> iter 36000, loss: 0.674320
 >> iter 37000, loss: 0.471895
 >> iter 38000, loss: 0.340353
 >> iter 39000, loss: 0.329429
 >> iter 40000, loss: 0.221901
   Number of active neurons: 3
 >> iter 41000, loss: 0.195462
 >> iter 42000, loss: 0.203753
 >> iter 43000, loss: 0.338037
 >> iter 44000, loss: 0.354731
 >> iter 45000, loss: 0.232614
 >> iter 46000, loss: 0.365965
 >> iter 47000, loss: 0.226078
 >> iter 48000, loss: 0.259912
 >> iter 49000, loss: 0.373341
 >> iter 50000, loss: 0.192056
   Number of active neurons: 3
 >> iter 51000, loss: 0.278359
 >> iter 52000, loss: 0.180244
 >> iter 53000, loss: 0.385667
 >> iter 54000, loss: 0.280021
 >> iter 55000, loss: 0.224415
 >> iter 56000, loss: 0.179177
 >> iter 57000, loss: 0.220074
 >> iter 58000, loss: 0.204860
 >> iter 59000, loss: 0.369666
 >> iter 60000, loss: 0.288092
   Number of active neurons: 3
 >> iter 61000, loss: 0.157803
 >> iter 62000, loss: 0.233502
 >> iter 63000, loss: 0.394522
 >> iter 64000, loss: 0.357577
 >> iter 65000, loss: 0.258866
 >> iter 66000, loss: 0.480508
 >> iter 67000, loss: 0.294056
 >> iter 68000, loss: 0.224994
 >> iter 69000, loss: 0.311150
 >> iter 70000, loss: 0.185132
   Number of active neurons: 3
 >> iter 71000, loss: 0.166024
 >> iter 72000, loss: 0.145310
 >> iter 73000, loss: 0.162317
 >> iter 74000, loss: 0.219739
 >> iter 75000, loss: 0.233705
 >> iter 76000, loss: 0.299046
 >> iter 77000, loss: 0.334761
 >> iter 78000, loss: 0.255560
 >> iter 79000, loss: 0.305573
 >> iter 80000, loss: 0.240879
   Number of active neurons: 3
 >> iter 81000, loss: 0.257503
 >> iter 82000, loss: 0.267583
 >> iter 83000, loss: 0.448696
 >> iter 84000, loss: 0.271394
 >> iter 85000, loss: 0.270976
 >> iter 86000, loss: 0.171624
 >> iter 87000, loss: 0.151387
 >> iter 88000, loss: 0.234737
 >> iter 89000, loss: 0.167029
 >> iter 90000, loss: 0.227756
   Number of active neurons: 3
 >> iter 91000, loss: 0.142312
 >> iter 92000, loss: 0.172947
 >> iter 93000, loss: 0.135353
 >> iter 94000, loss: 0.192432
 >> iter 95000, loss: 0.128780
 >> iter 96000, loss: 0.166687
 >> iter 97000, loss: 0.452993
 >> iter 98000, loss: 0.299445
 >> iter 99000, loss: 0.369508
 >> iter 100000, loss: 0.296851
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 17.693902
 >> iter 2000, loss: 9.576264
 >> iter 3000, loss: 4.398516
 >> iter 4000, loss: 2.138600
 >> iter 5000, loss: 1.104189
 >> iter 6000, loss: 0.655762
 >> iter 7000, loss: 0.431846
 >> iter 8000, loss: 0.384641
 >> iter 9000, loss: 0.389014
 >> iter 10000, loss: 0.373858
   Number of active neurons: 6
 >> iter 11000, loss: 0.373241
 >> iter 12000, loss: 0.386491
 >> iter 13000, loss: 0.342692
 >> iter 14000, loss: 0.440269
 >> iter 15000, loss: 0.357390
 >> iter 16000, loss: 0.344893
 >> iter 17000, loss: 0.399773
 >> iter 18000, loss: 0.372734
 >> iter 19000, loss: 0.391540
 >> iter 20000, loss: 0.344263
   Number of active neurons: 5
 >> iter 21000, loss: 0.308440
 >> iter 22000, loss: 0.252154
 >> iter 23000, loss: 0.278325
 >> iter 24000, loss: 0.280181
 >> iter 25000, loss: 0.308282
 >> iter 26000, loss: 0.339952
 >> iter 27000, loss: 0.471163
 >> iter 28000, loss: 0.546512
 >> iter 29000, loss: 0.462008
 >> iter 30000, loss: 0.506796
   Number of active neurons: 5
 >> iter 31000, loss: 0.382905
 >> iter 32000, loss: 0.284603
 >> iter 33000, loss: 0.234663
 >> iter 34000, loss: 0.336539
 >> iter 35000, loss: 0.382310
 >> iter 36000, loss: 0.284025
 >> iter 37000, loss: 0.343683
 >> iter 38000, loss: 0.215233
 >> iter 39000, loss: 0.429508
 >> iter 40000, loss: 0.290475
   Number of active neurons: 5
 >> iter 41000, loss: 0.193339
 >> iter 42000, loss: 0.421738
 >> iter 43000, loss: 0.478736
 >> iter 44000, loss: 0.428002
 >> iter 45000, loss: 0.310241
 >> iter 46000, loss: 0.258085
 >> iter 47000, loss: 0.174469
 >> iter 48000, loss: 0.183278
 >> iter 49000, loss: 0.153241
 >> iter 50000, loss: 0.286051
   Number of active neurons: 3
 >> iter 51000, loss: 0.333514
 >> iter 52000, loss: 0.248283
 >> iter 53000, loss: 0.223227
 >> iter 54000, loss: 0.239718
 >> iter 55000, loss: 0.284484
 >> iter 56000, loss: 0.483979
 >> iter 57000, loss: 0.368984
 >> iter 58000, loss: 0.290938
 >> iter 59000, loss: 0.197377
 >> iter 60000, loss: 0.254200
   Number of active neurons: 3
 >> iter 61000, loss: 0.359417
 >> iter 62000, loss: 0.268103
 >> iter 63000, loss: 0.245826
 >> iter 64000, loss: 0.286567
 >> iter 65000, loss: 0.256740
 >> iter 66000, loss: 0.231190
 >> iter 67000, loss: 0.187793
 >> iter 68000, loss: 0.294974
 >> iter 69000, loss: 0.328289
 >> iter 70000, loss: 0.297161
   Number of active neurons: 3
 >> iter 71000, loss: 0.511894
 >> iter 72000, loss: 0.334708
 >> iter 73000, loss: 0.218416
 >> iter 74000, loss: 0.300540
 >> iter 75000, loss: 0.304634
 >> iter 76000, loss: 0.372842
 >> iter 77000, loss: 0.226796
 >> iter 78000, loss: 0.267957
 >> iter 79000, loss: 0.287366
 >> iter 80000, loss: 0.168726
   Number of active neurons: 3
 >> iter 81000, loss: 0.302083
 >> iter 82000, loss: 0.294275
 >> iter 83000, loss: 0.287147
 >> iter 84000, loss: 0.230802
 >> iter 85000, loss: 0.354429
 >> iter 86000, loss: 0.171242
 >> iter 87000, loss: 0.222358
 >> iter 88000, loss: 0.173173
 >> iter 89000, loss: 0.444897
 >> iter 90000, loss: 0.395597
   Number of active neurons: 3
 >> iter 91000, loss: 0.355572
 >> iter 92000, loss: 0.365546
 >> iter 93000, loss: 0.357766
 >> iter 94000, loss: 0.407566
 >> iter 95000, loss: 0.238669
 >> iter 96000, loss: 0.154899
 >> iter 97000, loss: 0.245514
 >> iter 98000, loss: 0.192348
 >> iter 99000, loss: 0.179609
 >> iter 100000, loss: 0.228548
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.606745
 >> iter 2000, loss: 9.290744
 >> iter 3000, loss: 4.478802
 >> iter 4000, loss: 2.457522
 >> iter 5000, loss: 1.263741
 >> iter 6000, loss: 0.645728
 >> iter 7000, loss: 0.582259
 >> iter 8000, loss: 0.438913
 >> iter 9000, loss: 0.241635
 >> iter 10000, loss: 0.348172
   Number of active neurons: 5
 >> iter 11000, loss: 0.566825
 >> iter 12000, loss: 0.441157
 >> iter 13000, loss: 0.412549
 >> iter 14000, loss: 0.476665
 >> iter 15000, loss: 0.534033
 >> iter 16000, loss: 0.416440
 >> iter 17000, loss: 0.408076
 >> iter 18000, loss: 0.307075
 >> iter 19000, loss: 0.277021
 >> iter 20000, loss: 0.376646
   Number of active neurons: 5
 >> iter 21000, loss: 0.587241
 >> iter 22000, loss: 0.440867
 >> iter 23000, loss: 0.404717
 >> iter 24000, loss: 0.598725
 >> iter 25000, loss: 0.276705
 >> iter 26000, loss: 0.324723
 >> iter 27000, loss: 0.215841
 >> iter 28000, loss: 0.138267
 >> iter 29000, loss: 0.131714
 >> iter 30000, loss: 0.218754
   Number of active neurons: 4
 >> iter 31000, loss: 0.258351
 >> iter 32000, loss: 0.277908
 >> iter 33000, loss: 0.354993
 >> iter 34000, loss: 0.311210
 >> iter 35000, loss: 0.311383
 >> iter 36000, loss: 0.177255
 >> iter 37000, loss: 0.317636
 >> iter 38000, loss: 0.293280
 >> iter 39000, loss: 0.320215
 >> iter 40000, loss: 0.255251
   Number of active neurons: 4
 >> iter 41000, loss: 0.162502
 >> iter 42000, loss: 0.263165
 >> iter 43000, loss: 0.253359
 >> iter 44000, loss: 0.222319
 >> iter 45000, loss: 0.210839
 >> iter 46000, loss: 0.361329
 >> iter 47000, loss: 0.263962
 >> iter 48000, loss: 0.158597
 >> iter 49000, loss: 0.162243
 >> iter 50000, loss: 0.235297
   Number of active neurons: 4
 >> iter 51000, loss: 0.306931
 >> iter 52000, loss: 0.291661
 >> iter 53000, loss: 0.251052
 >> iter 54000, loss: 0.229987
 >> iter 55000, loss: 0.379146
 >> iter 56000, loss: 0.227499
 >> iter 57000, loss: 0.369091
 >> iter 58000, loss: 0.221140
 >> iter 59000, loss: 0.222364
 >> iter 60000, loss: 0.143060
   Number of active neurons: 4
 >> iter 61000, loss: 0.308712
 >> iter 62000, loss: 0.365485
 >> iter 63000, loss: 0.240376
 >> iter 64000, loss: 0.307693
 >> iter 65000, loss: 0.397490
 >> iter 66000, loss: 0.276434
 >> iter 67000, loss: 0.347617
 >> iter 68000, loss: 0.213694
 >> iter 69000, loss: 0.241027
 >> iter 70000, loss: 0.245674
   Number of active neurons: 4
 >> iter 71000, loss: 0.214861
 >> iter 72000, loss: 0.169764
 >> iter 73000, loss: 0.135000
 >> iter 74000, loss: 0.221686
 >> iter 75000, loss: 0.247829
 >> iter 76000, loss: 0.263814
 >> iter 77000, loss: 0.204630
 >> iter 78000, loss: 0.160237
 >> iter 79000, loss: 0.223789
 >> iter 80000, loss: 0.172965
   Number of active neurons: 4
 >> iter 81000, loss: 0.197585
 >> iter 82000, loss: 0.377053
 >> iter 83000, loss: 0.299982
 >> iter 84000, loss: 0.329075
 >> iter 85000, loss: 0.166381
 >> iter 86000, loss: 0.316259
 >> iter 87000, loss: 0.282377
 >> iter 88000, loss: 0.178332
 >> iter 89000, loss: 0.274888
 >> iter 90000, loss: 0.170883
   Number of active neurons: 4
 >> iter 91000, loss: 0.276378
 >> iter 92000, loss: 0.290538
 >> iter 93000, loss: 0.360087
 >> iter 94000, loss: 0.382303
 >> iter 95000, loss: 0.355945
 >> iter 96000, loss: 0.246257
 >> iter 97000, loss: 0.310246
 >> iter 98000, loss: 0.460205
 >> iter 99000, loss: 0.367794
 >> iter 100000, loss: 0.332210
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.640013
 >> iter 2000, loss: 9.232723
 >> iter 3000, loss: 4.188091
 >> iter 4000, loss: 2.173727
 >> iter 5000, loss: 1.192858
 >> iter 6000, loss: 0.721629
 >> iter 7000, loss: 0.481084
 >> iter 8000, loss: 0.504091
 >> iter 9000, loss: 0.523846
 >> iter 10000, loss: 0.444728
   Number of active neurons: 5
 >> iter 11000, loss: 0.418310
 >> iter 12000, loss: 0.328148
 >> iter 13000, loss: 0.446907
 >> iter 14000, loss: 0.433871
 >> iter 15000, loss: 0.310867
 >> iter 16000, loss: 0.516668
 >> iter 17000, loss: 0.305565
 >> iter 18000, loss: 0.371632
 >> iter 19000, loss: 0.348047
 >> iter 20000, loss: 0.459217
   Number of active neurons: 5
 >> iter 21000, loss: 0.405322
 >> iter 22000, loss: 0.303596
 >> iter 23000, loss: 0.229652
 >> iter 24000, loss: 0.293254
 >> iter 25000, loss: 0.398090
 >> iter 26000, loss: 0.383525
 >> iter 27000, loss: 0.466242
 >> iter 28000, loss: 0.498791
 >> iter 29000, loss: 0.443384
 >> iter 30000, loss: 0.259075
   Number of active neurons: 5
 >> iter 31000, loss: 0.272695
 >> iter 32000, loss: 0.273681
 >> iter 33000, loss: 0.252085
 >> iter 34000, loss: 0.256381
 >> iter 35000, loss: 0.376336
 >> iter 36000, loss: 0.360853
 >> iter 37000, loss: 0.453889
 >> iter 38000, loss: 0.624183
 >> iter 39000, loss: 0.438977
 >> iter 40000, loss: 0.430340
   Number of active neurons: 4
 >> iter 41000, loss: 0.580490
 >> iter 42000, loss: 0.401053
 >> iter 43000, loss: 0.433290
 >> iter 44000, loss: 0.472987
 >> iter 45000, loss: 0.258573
 >> iter 46000, loss: 0.324722
 >> iter 47000, loss: 0.419471
 >> iter 48000, loss: 0.201903
 >> iter 49000, loss: 0.112729
 >> iter 50000, loss: 0.179981
   Number of active neurons: 3
 >> iter 51000, loss: 0.196601
 >> iter 52000, loss: 0.247537
 >> iter 53000, loss: 0.261808
 >> iter 54000, loss: 0.420725
 >> iter 55000, loss: 0.385203
 >> iter 56000, loss: 0.247609
 >> iter 57000, loss: 0.187500
 >> iter 58000, loss: 0.275561
 >> iter 59000, loss: 0.383186
 >> iter 60000, loss: 0.377349
   Number of active neurons: 3
 >> iter 61000, loss: 0.371786
 >> iter 62000, loss: 0.527943
 >> iter 63000, loss: 0.283596
 >> iter 64000, loss: 0.249771
 >> iter 65000, loss: 0.275500
 >> iter 66000, loss: 0.307775
 >> iter 67000, loss: 0.340642
 >> iter 68000, loss: 0.320949
 >> iter 69000, loss: 0.251717
 >> iter 70000, loss: 0.199568
   Number of active neurons: 3
 >> iter 71000, loss: 0.270866
 >> iter 72000, loss: 0.345017
 >> iter 73000, loss: 0.242754
 >> iter 74000, loss: 0.209468
 >> iter 75000, loss: 0.230321
 >> iter 76000, loss: 0.206775
 >> iter 77000, loss: 0.117121
 >> iter 78000, loss: 0.306083
 >> iter 79000, loss: 0.361790
 >> iter 80000, loss: 0.233703
   Number of active neurons: 3
 >> iter 81000, loss: 0.284967
 >> iter 82000, loss: 0.302010
 >> iter 83000, loss: 0.242734
 >> iter 84000, loss: 0.230139
 >> iter 85000, loss: 0.219550
 >> iter 86000, loss: 0.379495
 >> iter 87000, loss: 0.181179
 >> iter 88000, loss: 0.153504
 >> iter 89000, loss: 0.254723
 >> iter 90000, loss: 0.224709
   Number of active neurons: 3
 >> iter 91000, loss: 0.320285
 >> iter 92000, loss: 0.362904
 >> iter 93000, loss: 0.253909
 >> iter 94000, loss: 0.454616
 >> iter 95000, loss: 0.306283
 >> iter 96000, loss: 0.321679
 >> iter 97000, loss: 0.409060
 >> iter 98000, loss: 0.246996
 >> iter 99000, loss: 0.204091
 >> iter 100000, loss: 0.334541
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.261192
 >> iter 2000, loss: 8.430226
 >> iter 3000, loss: 3.633578
 >> iter 4000, loss: 1.803128
 >> iter 5000, loss: 0.868560
 >> iter 6000, loss: 0.674527
 >> iter 7000, loss: 0.566178
 >> iter 8000, loss: 0.424166
 >> iter 9000, loss: 0.316634
 >> iter 10000, loss: 0.368862
   Number of active neurons: 3
 >> iter 11000, loss: 0.226480
 >> iter 12000, loss: 0.219884
 >> iter 13000, loss: 0.337816
 >> iter 14000, loss: 0.484076
 >> iter 15000, loss: 0.302593
 >> iter 16000, loss: 0.286189
 >> iter 17000, loss: 0.435819
 >> iter 18000, loss: 0.363047
 >> iter 19000, loss: 0.375766
 >> iter 20000, loss: 0.302067
   Number of active neurons: 3
 >> iter 21000, loss: 0.269853
 >> iter 22000, loss: 0.196769
 >> iter 23000, loss: 0.159818
 >> iter 24000, loss: 0.158294
 >> iter 25000, loss: 0.217172
 >> iter 26000, loss: 0.186374
 >> iter 27000, loss: 0.346497
 >> iter 28000, loss: 0.289260
 >> iter 29000, loss: 0.279693
 >> iter 30000, loss: 0.192177
   Number of active neurons: 3
 >> iter 31000, loss: 0.369293
 >> iter 32000, loss: 0.201124
 >> iter 33000, loss: 0.212673
 >> iter 34000, loss: 0.392750
 >> iter 35000, loss: 0.261190
 >> iter 36000, loss: 0.255874
 >> iter 37000, loss: 0.333530
 >> iter 38000, loss: 0.335201
 >> iter 39000, loss: 0.332498
 >> iter 40000, loss: 0.393328
   Number of active neurons: 3
 >> iter 41000, loss: 0.249379
 >> iter 42000, loss: 0.220715
 >> iter 43000, loss: 0.180167
 >> iter 44000, loss: 0.371878
 >> iter 45000, loss: 0.253499
 >> iter 46000, loss: 0.290681
 >> iter 47000, loss: 0.348440
 >> iter 48000, loss: 0.311759
 >> iter 49000, loss: 0.285122
 >> iter 50000, loss: 0.275555
   Number of active neurons: 3
 >> iter 51000, loss: 0.202227
 >> iter 52000, loss: 0.181327
 >> iter 53000, loss: 0.161532
 >> iter 54000, loss: 0.236264
 >> iter 55000, loss: 0.170879
 >> iter 56000, loss: 0.168424
 >> iter 57000, loss: 0.247262
 >> iter 58000, loss: 0.422999
 >> iter 59000, loss: 0.195401
 >> iter 60000, loss: 0.262671
   Number of active neurons: 3
 >> iter 61000, loss: 0.245897
 >> iter 62000, loss: 0.209912
 >> iter 63000, loss: 0.266004
 >> iter 64000, loss: 0.242986
 >> iter 65000, loss: 0.192579
 >> iter 66000, loss: 0.245088
 >> iter 67000, loss: 0.153675
 >> iter 68000, loss: 0.157563
 >> iter 69000, loss: 0.182647
 >> iter 70000, loss: 0.272609
   Number of active neurons: 3
 >> iter 71000, loss: 0.168813
 >> iter 72000, loss: 0.161559
 >> iter 73000, loss: 0.130036
 >> iter 74000, loss: 0.355858
 >> iter 75000, loss: 0.477402
 >> iter 76000, loss: 0.417141
 >> iter 77000, loss: 0.188328
 >> iter 78000, loss: 0.150188
 >> iter 79000, loss: 0.242242
 >> iter 80000, loss: 0.155045
   Number of active neurons: 3
 >> iter 81000, loss: 0.140608
 >> iter 82000, loss: 0.086371
 >> iter 83000, loss: 0.158252
 >> iter 84000, loss: 0.188389
 >> iter 85000, loss: 0.304464
 >> iter 86000, loss: 0.344376
 >> iter 87000, loss: 0.339749
 >> iter 88000, loss: 0.258649
 >> iter 89000, loss: 0.127001
 >> iter 90000, loss: 0.191796
   Number of active neurons: 3
 >> iter 91000, loss: 0.227000
 >> iter 92000, loss: 0.174389
 >> iter 93000, loss: 0.286699
 >> iter 94000, loss: 0.201520
 >> iter 95000, loss: 0.285814
 >> iter 96000, loss: 0.252547
 >> iter 97000, loss: 0.273927
 >> iter 98000, loss: 0.390593
 >> iter 99000, loss: 0.308128
 >> iter 100000, loss: 0.297287
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

