 > Problema: tomita6nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.1
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.607610
 >> iter 2000, loss: 15.089509
 >> iter 3000, loss: 13.751043
 >> iter 4000, loss: 13.257837
 >> iter 5000, loss: 13.063168
 >> iter 6000, loss: 12.994741
 >> iter 7000, loss: 12.959940
 >> iter 8000, loss: 12.953315
 >> iter 9000, loss: 12.940757
 >> iter 10000, loss: 12.949180
   Number of active neurons: 5
 >> iter 11000, loss: 12.940241
 >> iter 12000, loss: 12.943602
 >> iter 13000, loss: 12.756745
 >> iter 14000, loss: 12.093084
 >> iter 15000, loss: 8.174204
 >> iter 16000, loss: 3.123457
 >> iter 17000, loss: 1.195680
 >> iter 18000, loss: 0.465184
 >> iter 19000, loss: 0.188975
 >> iter 20000, loss: 0.083531
   Number of active neurons: 10
 >> iter 21000, loss: 0.072073
 >> iter 22000, loss: 0.037223
 >> iter 23000, loss: 0.022455
 >> iter 24000, loss: 0.015905
 >> iter 25000, loss: 0.012502
 >> iter 26000, loss: 0.051113
 >> iter 27000, loss: 0.026993
 >> iter 28000, loss: 0.015982
 >> iter 29000, loss: 0.011034
 >> iter 30000, loss: 0.008768
   Number of active neurons: 10
 >> iter 31000, loss: 0.007382
 >> iter 32000, loss: 0.006606
 >> iter 33000, loss: 0.005966
 >> iter 34000, loss: 0.005547
 >> iter 35000, loss: 0.005115
 >> iter 36000, loss: 0.004819
 >> iter 37000, loss: 0.004494
 >> iter 38000, loss: 0.004283
 >> iter 39000, loss: 0.004032
 >> iter 40000, loss: 0.003853
   Number of active neurons: 10
 >> iter 41000, loss: 0.003637
 >> iter 42000, loss: 0.003499
 >> iter 43000, loss: 0.003326
 >> iter 44000, loss: 0.003198
 >> iter 45000, loss: 0.003050
 >> iter 46000, loss: 0.002945
 >> iter 47000, loss: 0.002819
 >> iter 48000, loss: 0.002737
 >> iter 49000, loss: 0.002621
 >> iter 50000, loss: 0.002546
   Number of active neurons: 10
 >> iter 51000, loss: 0.002454
 >> iter 52000, loss: 0.002379
 >> iter 53000, loss: 0.002290
 >> iter 54000, loss: 0.002234
 >> iter 55000, loss: 0.002154
 >> iter 56000, loss: 0.002107
 >> iter 57000, loss: 0.002038
 >> iter 58000, loss: 0.001999
 >> iter 59000, loss: 0.001927
 >> iter 60000, loss: 0.001889
   Number of active neurons: 10
 >> iter 61000, loss: 0.001830
 >> iter 62000, loss: 0.001790
 >> iter 63000, loss: 0.001736
 >> iter 64000, loss: 0.001706
 >> iter 65000, loss: 0.001654
 >> iter 66000, loss: 0.001631
 >> iter 67000, loss: 0.001588
 >> iter 68000, loss: 0.001563
 >> iter 69000, loss: 0.001523
 >> iter 70000, loss: 0.001499
   Number of active neurons: 10
 >> iter 71000, loss: 0.001460
 >> iter 72000, loss: 0.001436
 >> iter 73000, loss: 0.001403
 >> iter 74000, loss: 0.001380
 >> iter 75000, loss: 0.001344
 >> iter 76000, loss: 0.001323
 >> iter 77000, loss: 0.001293
 >> iter 78000, loss: 0.001283
 >> iter 79000, loss: 0.001252
 >> iter 80000, loss: 0.001237
   Number of active neurons: 10
 >> iter 81000, loss: 0.001204
 >> iter 82000, loss: 0.001191
 >> iter 83000, loss: 0.001166
 >> iter 84000, loss: 0.001151
 >> iter 85000, loss: 0.001130
 >> iter 86000, loss: 0.001124
 >> iter 87000, loss: 0.001100
 >> iter 88000, loss: 0.001086
 >> iter 89000, loss: 0.001058
 >> iter 90000, loss: 0.001048
   Number of active neurons: 10
 >> iter 91000, loss: 0.001025
 >> iter 92000, loss: 0.001020
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.598991
 >> iter 2000, loss: 15.082579
 >> iter 3000, loss: 13.750586
 >> iter 4000, loss: 13.255664
 >> iter 5000, loss: 13.055068
 >> iter 6000, loss: 12.983384
 >> iter 7000, loss: 12.948079
 >> iter 8000, loss: 12.938664
 >> iter 9000, loss: 12.914434
 >> iter 10000, loss: 12.290136
   Number of active neurons: 7
 >> iter 11000, loss: 9.845904
 >> iter 12000, loss: 4.106627
 >> iter 13000, loss: 1.567418
 >> iter 14000, loss: 0.606250
 >> iter 15000, loss: 0.243354
 >> iter 16000, loss: 0.104709
 >> iter 17000, loss: 0.050657
 >> iter 18000, loss: 0.028840
 >> iter 19000, loss: 0.019173
 >> iter 20000, loss: 0.015647
   Number of active neurons: 10
 >> iter 21000, loss: 0.012631
 >> iter 22000, loss: 0.010706
 >> iter 23000, loss: 0.009366
 >> iter 24000, loss: 0.008344
 >> iter 25000, loss: 0.007588
 >> iter 26000, loss: 0.006942
 >> iter 27000, loss: 0.006404
 >> iter 28000, loss: 0.005994
 >> iter 29000, loss: 0.007582
 >> iter 30000, loss: 0.006464
   Number of active neurons: 10
 >> iter 31000, loss: 0.005506
 >> iter 32000, loss: 0.004965
 >> iter 33000, loss: 0.004536
 >> iter 34000, loss: 0.004815
 >> iter 35000, loss: 0.004307
 >> iter 36000, loss: 0.004005
 >> iter 37000, loss: 0.003671
 >> iter 38000, loss: 0.003475
 >> iter 39000, loss: 0.003286
 >> iter 40000, loss: 0.003174
   Number of active neurons: 10
 >> iter 41000, loss: 0.003018
 >> iter 42000, loss: 0.002916
 >> iter 43000, loss: 0.002812
 >> iter 44000, loss: 0.002679
 >> iter 45000, loss: 0.002586
 >> iter 46000, loss: 0.002508
 >> iter 47000, loss: 0.002419
 >> iter 48000, loss: 0.002336
 >> iter 49000, loss: 0.002269
 >> iter 50000, loss: 0.002201
   Number of active neurons: 10
 >> iter 51000, loss: 0.002137
 >> iter 52000, loss: 0.002081
 >> iter 53000, loss: 0.002024
 >> iter 54000, loss: 0.001987
 >> iter 55000, loss: 0.001913
 >> iter 56000, loss: 0.001949
 >> iter 57000, loss: 0.001842
 >> iter 58000, loss: 0.001784
 >> iter 59000, loss: 0.001754
 >> iter 60000, loss: 0.001703
   Number of active neurons: 10
 >> iter 61000, loss: 0.001661
 >> iter 62000, loss: 0.001626
 >> iter 63000, loss: 0.001608
 >> iter 64000, loss: 0.001549
 >> iter 65000, loss: 0.001510
 >> iter 66000, loss: 0.001472
 >> iter 67000, loss: 0.001467
 >> iter 68000, loss: 0.001473
 >> iter 69000, loss: 0.001411
 >> iter 70000, loss: 0.001375
   Number of active neurons: 10
 >> iter 71000, loss: 0.001352
 >> iter 72000, loss: 0.001319
 >> iter 73000, loss: 0.001285
 >> iter 74000, loss: 0.001282
 >> iter 75000, loss: 0.001250
 >> iter 76000, loss: 0.001216
 >> iter 77000, loss: 0.001197
 >> iter 78000, loss: 0.001174
 >> iter 79000, loss: 0.001167
 >> iter 80000, loss: 0.001144
   Number of active neurons: 10
 >> iter 81000, loss: 0.001132
 >> iter 82000, loss: 0.001110
 >> iter 83000, loss: 0.001106
 >> iter 84000, loss: 0.001078
 >> iter 85000, loss: 0.001057
 >> iter 86000, loss: 0.001038
 >> iter 87000, loss: 0.001032
 >> iter 88000, loss: 0.001025
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.632252
 >> iter 2000, loss: 15.105887
 >> iter 3000, loss: 13.768159
 >> iter 4000, loss: 13.267736
 >> iter 5000, loss: 13.073079
 >> iter 6000, loss: 13.003345
 >> iter 7000, loss: 12.970825
 >> iter 8000, loss: 12.966210
 >> iter 9000, loss: 12.948515
 >> iter 10000, loss: 12.470204
   Number of active neurons: 8
 >> iter 11000, loss: 8.514205
 >> iter 12000, loss: 3.338376
 >> iter 13000, loss: 1.267179
 >> iter 14000, loss: 0.484513
 >> iter 15000, loss: 0.188691
 >> iter 16000, loss: 0.076794
 >> iter 17000, loss: 0.034291
 >> iter 18000, loss: 0.017603
 >> iter 19000, loss: 0.010838
 >> iter 20000, loss: 0.007787
   Number of active neurons: 10
 >> iter 21000, loss: 0.006342
 >> iter 22000, loss: 0.005443
 >> iter 23000, loss: 0.004861
 >> iter 24000, loss: 0.004394
 >> iter 25000, loss: 0.004112
 >> iter 26000, loss: 0.003760
 >> iter 27000, loss: 0.003541
 >> iter 28000, loss: 0.003291
 >> iter 29000, loss: 0.003113
 >> iter 30000, loss: 0.002926
   Number of active neurons: 10
 >> iter 31000, loss: 0.002795
 >> iter 32000, loss: 0.002639
 >> iter 33000, loss: 0.002526
 >> iter 34000, loss: 0.002408
 >> iter 35000, loss: 0.002338
 >> iter 36000, loss: 0.002217
 >> iter 37000, loss: 0.002145
 >> iter 38000, loss: 0.002046
 >> iter 39000, loss: 0.001984
 >> iter 40000, loss: 0.001903
   Number of active neurons: 10
 >> iter 41000, loss: 0.001845
 >> iter 42000, loss: 0.001778
 >> iter 43000, loss: 0.001736
 >> iter 44000, loss: 0.001674
 >> iter 45000, loss: 0.001635
 >> iter 46000, loss: 0.001579
 >> iter 47000, loss: 0.001547
 >> iter 48000, loss: 0.001494
 >> iter 49000, loss: 0.001463
 >> iter 50000, loss: 0.001417
   Number of active neurons: 10
 >> iter 51000, loss: 0.001388
 >> iter 52000, loss: 0.001347
 >> iter 53000, loss: 0.001323
 >> iter 54000, loss: 0.001287
 >> iter 55000, loss: 0.001266
 >> iter 56000, loss: 0.001229
 >> iter 57000, loss: 0.001213
 >> iter 58000, loss: 0.001182
 >> iter 59000, loss: 0.001164
 >> iter 60000, loss: 0.001131
   Number of active neurons: 10
 >> iter 61000, loss: 0.001118
 >> iter 62000, loss: 0.001085
 >> iter 63000, loss: 0.001073
 >> iter 64000, loss: 0.001043
 >> iter 65000, loss: 0.001028
 >> iter 66000, loss: 0.001009
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.614727
 >> iter 2000, loss: 15.110705
 >> iter 3000, loss: 13.776375
 >> iter 4000, loss: 13.283547
 >> iter 5000, loss: 13.079541
 >> iter 6000, loss: 13.009395
 >> iter 7000, loss: 12.976502
 >> iter 8000, loss: 12.971503
 >> iter 9000, loss: 12.954036
 >> iter 10000, loss: 12.959635
   Number of active neurons: 6
 >> iter 11000, loss: 12.949026
 >> iter 12000, loss: 12.950393
 >> iter 13000, loss: 12.822753
 >> iter 14000, loss: 9.375096
 >> iter 15000, loss: 3.601379
 >> iter 16000, loss: 1.381976
 >> iter 17000, loss: 0.531058
 >> iter 18000, loss: 0.211293
 >> iter 19000, loss: 0.089961
 >> iter 20000, loss: 0.043050
   Number of active neurons: 10
 >> iter 21000, loss: 0.024338
 >> iter 22000, loss: 0.016339
 >> iter 23000, loss: 0.012325
 >> iter 24000, loss: 0.012056
 >> iter 25000, loss: 0.009858
 >> iter 26000, loss: 0.008382
 >> iter 27000, loss: 0.007351
 >> iter 28000, loss: 0.006655
 >> iter 29000, loss: 0.006034
 >> iter 30000, loss: 0.005574
   Number of active neurons: 10
 >> iter 31000, loss: 0.005172
 >> iter 32000, loss: 0.004838
 >> iter 33000, loss: 0.004532
 >> iter 34000, loss: 0.004277
 >> iter 35000, loss: 0.004040
 >> iter 36000, loss: 0.003844
 >> iter 37000, loss: 0.003641
 >> iter 38000, loss: 0.003475
 >> iter 39000, loss: 0.003314
 >> iter 40000, loss: 0.003183
   Number of active neurons: 10
 >> iter 41000, loss: 0.003046
 >> iter 42000, loss: 0.002950
 >> iter 43000, loss: 0.002844
 >> iter 44000, loss: 0.002769
 >> iter 45000, loss: 0.002639
 >> iter 46000, loss: 0.002554
 >> iter 47000, loss: 0.002463
 >> iter 48000, loss: 0.002383
 >> iter 49000, loss: 0.002301
 >> iter 50000, loss: 0.002236
   Number of active neurons: 10
 >> iter 51000, loss: 0.002173
 >> iter 52000, loss: 0.002106
 >> iter 53000, loss: 0.002035
 >> iter 54000, loss: 0.002001
 >> iter 55000, loss: 0.001944
 >> iter 56000, loss: 0.001888
 >> iter 57000, loss: 0.001837
 >> iter 58000, loss: 0.001800
 >> iter 59000, loss: 0.001865
 >> iter 60000, loss: 0.001811
   Number of active neurons: 10
 >> iter 61000, loss: 0.011967
 >> iter 62000, loss: 0.005868
 >> iter 63000, loss: 0.003389
 >> iter 64000, loss: 0.002414
 >> iter 65000, loss: 0.001990
 >> iter 66000, loss: 0.001811
 >> iter 67000, loss: 0.001701
 >> iter 68000, loss: 0.001640
 >> iter 69000, loss: 0.001576
 >> iter 70000, loss: 0.001539
   Number of active neurons: 10
 >> iter 71000, loss: 0.001486
 >> iter 72000, loss: 0.001464
 >> iter 73000, loss: 0.001419
 >> iter 74000, loss: 0.001395
 >> iter 75000, loss: 0.001359
 >> iter 76000, loss: 0.001341
 >> iter 77000, loss: 0.001302
 >> iter 78000, loss: 0.001275
 >> iter 79000, loss: 0.001241
 >> iter 80000, loss: 0.001228
   Number of active neurons: 10
 >> iter 81000, loss: 0.001197
 >> iter 82000, loss: 0.001183
 >> iter 83000, loss: 0.001149
 >> iter 84000, loss: 0.001136
 >> iter 85000, loss: 0.001114
 >> iter 86000, loss: 0.001101
 >> iter 87000, loss: 0.001075
 >> iter 88000, loss: 0.001064
 >> iter 89000, loss: 0.001038
 >> iter 90000, loss: 0.001029
   Number of active neurons: 10
 >> iter 91000, loss: 0.001008
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.645804
 >> iter 2000, loss: 15.112017
 >> iter 3000, loss: 13.769442
 >> iter 4000, loss: 13.274465
 >> iter 5000, loss: 13.075200
 >> iter 6000, loss: 13.008204
 >> iter 7000, loss: 12.976471
 >> iter 8000, loss: 12.971957
 >> iter 9000, loss: 12.960309
 >> iter 10000, loss: 12.966991
   Number of active neurons: 6
 >> iter 11000, loss: 12.957881
 >> iter 12000, loss: 12.960154
 >> iter 13000, loss: 12.953082
 >> iter 14000, loss: 12.914819
 >> iter 15000, loss: 11.731431
 >> iter 16000, loss: 4.963130
 >> iter 17000, loss: 1.930296
 >> iter 18000, loss: 0.767196
 >> iter 19000, loss: 0.303635
 >> iter 20000, loss: 0.127774
   Number of active neurons: 10
 >> iter 21000, loss: 0.059619
 >> iter 22000, loss: 0.032515
 >> iter 23000, loss: 0.020843
 >> iter 24000, loss: 0.015563
 >> iter 25000, loss: 0.012568
 >> iter 26000, loss: 0.010811
 >> iter 27000, loss: 0.009540
 >> iter 28000, loss: 0.008677
 >> iter 29000, loss: 0.007850
 >> iter 30000, loss: 0.007278
   Number of active neurons: 10
 >> iter 31000, loss: 0.006711
 >> iter 32000, loss: 0.006296
 >> iter 33000, loss: 0.005855
 >> iter 34000, loss: 0.005579
 >> iter 35000, loss: 0.005204
 >> iter 36000, loss: 0.004924
 >> iter 37000, loss: 0.004633
 >> iter 38000, loss: 0.004420
 >> iter 39000, loss: 0.004193
 >> iter 40000, loss: 0.004037
   Number of active neurons: 10
 >> iter 41000, loss: 0.003829
 >> iter 42000, loss: 0.003690
 >> iter 43000, loss: 0.003555
 >> iter 44000, loss: 0.003430
 >> iter 45000, loss: 0.003278
 >> iter 46000, loss: 0.003179
 >> iter 47000, loss: 0.003052
 >> iter 48000, loss: 0.002964
 >> iter 49000, loss: 0.002854
 >> iter 50000, loss: 0.166867
   Number of active neurons: 10
 >> iter 51000, loss: 0.063865
 >> iter 52000, loss: 0.025713
 >> iter 53000, loss: 0.011513
 >> iter 54000, loss: 0.006193
 >> iter 55000, loss: 0.004125
 >> iter 56000, loss: 0.003300
 >> iter 57000, loss: 0.002924
 >> iter 58000, loss: 0.002726
 >> iter 59000, loss: 0.002582
 >> iter 60000, loss: 0.002815
   Number of active neurons: 10
 >> iter 61000, loss: 0.002598
 >> iter 62000, loss: 0.002462
 >> iter 63000, loss: 0.002403
 >> iter 64000, loss: 0.002291
 >> iter 65000, loss: 0.002194
 >> iter 66000, loss: 0.002177
 >> iter 67000, loss: 0.002082
 >> iter 68000, loss: 0.002061
 >> iter 69000, loss: 0.001973
 >> iter 70000, loss: 0.001923
   Number of active neurons: 10
 >> iter 71000, loss: 0.001868
 >> iter 72000, loss: 0.001825
 >> iter 73000, loss: 0.001781
 >> iter 74000, loss: 0.001747
 >> iter 75000, loss: 0.001706
 >> iter 76000, loss: 0.001679
 >> iter 77000, loss: 0.001636
 >> iter 78000, loss: 0.001611
 >> iter 79000, loss: 0.001575
 >> iter 80000, loss: 0.001553
   Number of active neurons: 10
 >> iter 81000, loss: 0.001514
 >> iter 82000, loss: 0.001489
 >> iter 83000, loss: 0.001459
 >> iter 84000, loss: 0.001434
 >> iter 85000, loss: 0.001408
 >> iter 86000, loss: 0.001385
 >> iter 87000, loss: 0.001360
 >> iter 88000, loss: 0.001344
 >> iter 89000, loss: 0.001317
 >> iter 90000, loss: 0.001303
   Number of active neurons: 10
 >> iter 91000, loss: 0.001276
 >> iter 92000, loss: 0.001266
 >> iter 93000, loss: 0.001243
 >> iter 94000, loss: 0.001225
 >> iter 95000, loss: 0.001202
 >> iter 96000, loss: 0.001190
 >> iter 97000, loss: 0.001174
 >> iter 98000, loss: 0.001160
 >> iter 99000, loss: 0.001143
 >> iter 100000, loss: 0.001129
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.638120
 >> iter 2000, loss: 15.112300
 >> iter 3000, loss: 13.780773
 >> iter 4000, loss: 13.278861
 >> iter 5000, loss: 13.073141
 >> iter 6000, loss: 13.001728
 >> iter 7000, loss: 12.960811
 >> iter 8000, loss: 12.953658
 >> iter 9000, loss: 12.939161
 >> iter 10000, loss: 12.941729
   Number of active neurons: 3
 >> iter 11000, loss: 12.929782
 >> iter 12000, loss: 12.936462
 >> iter 13000, loss: 12.925511
 >> iter 14000, loss: 12.928457
 >> iter 15000, loss: 12.685484
 >> iter 16000, loss: 8.856685
 >> iter 17000, loss: 3.336799
 >> iter 18000, loss: 1.259652
 >> iter 19000, loss: 0.483855
 >> iter 20000, loss: 0.192814
   Number of active neurons: 10
 >> iter 21000, loss: 0.082538
 >> iter 22000, loss: 0.039887
 >> iter 23000, loss: 0.022671
 >> iter 24000, loss: 0.015362
 >> iter 25000, loss: 0.011832
 >> iter 26000, loss: 0.009833
 >> iter 27000, loss: 0.008543
 >> iter 28000, loss: 0.007601
 >> iter 29000, loss: 0.006879
 >> iter 30000, loss: 0.006282
   Number of active neurons: 10
 >> iter 31000, loss: 0.005792
 >> iter 32000, loss: 0.005390
 >> iter 33000, loss: 0.005044
 >> iter 34000, loss: 0.004722
 >> iter 35000, loss: 0.004442
 >> iter 36000, loss: 0.004203
 >> iter 37000, loss: 0.003985
 >> iter 38000, loss: 0.003768
 >> iter 39000, loss: 0.003590
 >> iter 40000, loss: 0.003400
   Number of active neurons: 10
 >> iter 41000, loss: 0.003255
 >> iter 42000, loss: 0.003113
 >> iter 43000, loss: 0.003004
 >> iter 44000, loss: 0.002867
 >> iter 45000, loss: 0.002755
 >> iter 46000, loss: 0.002655
 >> iter 47000, loss: 0.002571
 >> iter 48000, loss: 0.002472
 >> iter 49000, loss: 0.002406
 >> iter 50000, loss: 0.002307
   Number of active neurons: 10
 >> iter 51000, loss: 0.002236
 >> iter 52000, loss: 0.002152
 >> iter 53000, loss: 0.002092
 >> iter 54000, loss: 0.002027
 >> iter 55000, loss: 0.001979
 >> iter 56000, loss: 0.001914
 >> iter 57000, loss: 0.016288
 >> iter 58000, loss: 0.013820
 >> iter 59000, loss: 0.006643
 >> iter 60000, loss: 0.003848
   Number of active neurons: 10
 >> iter 61000, loss: 0.002711
 >> iter 62000, loss: 0.002228
 >> iter 63000, loss: 0.001984
 >> iter 64000, loss: 0.001846
 >> iter 65000, loss: 0.001750
 >> iter 66000, loss: 0.001678
 >> iter 67000, loss: 0.001621
 >> iter 68000, loss: 0.001560
 >> iter 69000, loss: 0.001514
 >> iter 70000, loss: 0.001466
   Number of active neurons: 10
 >> iter 71000, loss: 0.001434
 >> iter 72000, loss: 0.001396
 >> iter 73000, loss: 0.001358
 >> iter 74000, loss: 0.001326
 >> iter 75000, loss: 0.001297
 >> iter 76000, loss: 0.001268
 >> iter 77000, loss: 0.001237
 >> iter 78000, loss: 0.001210
 >> iter 79000, loss: 0.001188
 >> iter 80000, loss: 0.001167
   Number of active neurons: 10
 >> iter 81000, loss: 0.001143
 >> iter 82000, loss: 0.001118
 >> iter 83000, loss: 0.001099
 >> iter 84000, loss: 0.001079
 >> iter 85000, loss: 0.001064
 >> iter 86000, loss: 0.001040
 >> iter 87000, loss: 0.001029
 >> iter 88000, loss: 0.001006
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.618310
 >> iter 2000, loss: 15.117776
 >> iter 3000, loss: 13.780725
 >> iter 4000, loss: 13.283726
 >> iter 5000, loss: 13.077702
 >> iter 6000, loss: 12.999084
 >> iter 7000, loss: 12.962213
 >> iter 8000, loss: 12.898143
 >> iter 9000, loss: 12.338317
 >> iter 10000, loss: 7.825540
   Number of active neurons: 10
 >> iter 11000, loss: 2.950859
 >> iter 12000, loss: 1.189909
 >> iter 13000, loss: 0.457747
 >> iter 14000, loss: 0.182571
 >> iter 15000, loss: 0.078090
 >> iter 16000, loss: 0.037558
 >> iter 17000, loss: 0.021257
 >> iter 18000, loss: 0.014388
 >> iter 19000, loss: 0.010998
 >> iter 20000, loss: 0.009033
   Number of active neurons: 10
 >> iter 21000, loss: 0.007922
 >> iter 22000, loss: 0.007013
 >> iter 23000, loss: 0.006557
 >> iter 24000, loss: 0.005944
 >> iter 25000, loss: 0.005477
 >> iter 26000, loss: 0.005023
 >> iter 27000, loss: 0.004678
 >> iter 28000, loss: 0.004361
 >> iter 29000, loss: 0.004376
 >> iter 30000, loss: 0.004192
   Number of active neurons: 10
 >> iter 31000, loss: 0.003831
 >> iter 32000, loss: 0.003562
 >> iter 33000, loss: 0.003350
 >> iter 34000, loss: 0.003178
 >> iter 35000, loss: 0.003028
 >> iter 36000, loss: 0.002882
 >> iter 37000, loss: 0.002776
 >> iter 38000, loss: 0.002654
 >> iter 39000, loss: 0.002550
 >> iter 40000, loss: 0.002440
   Number of active neurons: 10
 >> iter 41000, loss: 0.002363
 >> iter 42000, loss: 0.002263
 >> iter 43000, loss: 0.002199
 >> iter 44000, loss: 0.002121
 >> iter 45000, loss: 0.002078
 >> iter 46000, loss: 0.001996
 >> iter 47000, loss: 0.001956
 >> iter 48000, loss: 0.001886
 >> iter 49000, loss: 0.001824
 >> iter 50000, loss: 0.001773
   Number of active neurons: 10
 >> iter 51000, loss: 0.001727
 >> iter 52000, loss: 0.001680
 >> iter 53000, loss: 0.001633
 >> iter 54000, loss: 0.001586
 >> iter 55000, loss: 0.001540
 >> iter 56000, loss: 0.001511
 >> iter 57000, loss: 0.001490
 >> iter 58000, loss: 0.001445
 >> iter 59000, loss: 0.001407
 >> iter 60000, loss: 0.004532
   Number of active neurons: 10
 >> iter 61000, loss: 0.002704
 >> iter 62000, loss: 0.001946
 >> iter 63000, loss: 0.001610
 >> iter 64000, loss: 0.001456
 >> iter 65000, loss: 0.001347
 >> iter 66000, loss: 0.001303
 >> iter 67000, loss: 0.001256
 >> iter 68000, loss: 0.001225
 >> iter 69000, loss: 0.001188
 >> iter 70000, loss: 0.001175
   Number of active neurons: 10
 >> iter 71000, loss: 0.001138
 >> iter 72000, loss: 0.001113
 >> iter 73000, loss: 0.001084
 >> iter 74000, loss: 0.001064
 >> iter 75000, loss: 0.001035
 >> iter 76000, loss: 0.001020
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.648589
 >> iter 2000, loss: 15.114984
 >> iter 3000, loss: 13.773683
 >> iter 4000, loss: 13.269075
 >> iter 5000, loss: 13.064825
 >> iter 6000, loss: 12.990130
 >> iter 7000, loss: 12.948228
 >> iter 8000, loss: 12.944040
 >> iter 9000, loss: 12.929138
 >> iter 10000, loss: 12.931423
   Number of active neurons: 5
 >> iter 11000, loss: 12.919454
 >> iter 12000, loss: 12.924794
 >> iter 13000, loss: 12.914378
 >> iter 14000, loss: 12.907961
 >> iter 15000, loss: 12.280369
 >> iter 16000, loss: 5.202584
 >> iter 17000, loss: 1.964977
 >> iter 18000, loss: 0.751644
 >> iter 19000, loss: 0.328166
 >> iter 20000, loss: 0.284594
   Number of active neurons: 10
 >> iter 21000, loss: 0.122287
 >> iter 22000, loss: 0.056955
 >> iter 23000, loss: 0.033915
 >> iter 24000, loss: 0.021052
 >> iter 25000, loss: 0.038085
 >> iter 26000, loss: 0.021410
 >> iter 27000, loss: 0.013982
 >> iter 28000, loss: 0.010527
 >> iter 29000, loss: 0.008667
 >> iter 30000, loss: 0.007588
   Number of active neurons: 10
 >> iter 31000, loss: 0.006801
 >> iter 32000, loss: 0.013802
 >> iter 33000, loss: 0.009297
 >> iter 34000, loss: 0.007133
 >> iter 35000, loss: 0.005974
 >> iter 36000, loss: 0.005334
 >> iter 37000, loss: 0.004873
 >> iter 38000, loss: 0.004540
 >> iter 39000, loss: 0.004248
 >> iter 40000, loss: 0.004009
   Number of active neurons: 10
 >> iter 41000, loss: 0.003793
 >> iter 42000, loss: 0.003609
 >> iter 43000, loss: 0.003447
 >> iter 44000, loss: 0.003307
 >> iter 45000, loss: 0.003166
 >> iter 46000, loss: 0.003033
 >> iter 47000, loss: 0.002917
 >> iter 48000, loss: 0.002823
 >> iter 49000, loss: 0.002717
 >> iter 50000, loss: 0.002633
   Number of active neurons: 10
 >> iter 51000, loss: 0.002533
 >> iter 52000, loss: 0.002450
 >> iter 53000, loss: 0.002376
 >> iter 54000, loss: 0.002304
 >> iter 55000, loss: 0.002239
 >> iter 56000, loss: 0.002184
 >> iter 57000, loss: 0.002483
 >> iter 58000, loss: 0.002356
 >> iter 59000, loss: 0.002209
 >> iter 60000, loss: 0.002099
   Number of active neurons: 10
 >> iter 61000, loss: 0.002024
 >> iter 62000, loss: 0.001949
 >> iter 63000, loss: 0.001900
 >> iter 64000, loss: 0.001843
 >> iter 65000, loss: 0.001785
 >> iter 66000, loss: 0.001741
 >> iter 67000, loss: 0.001698
 >> iter 68000, loss: 0.001656
 >> iter 69000, loss: 0.001609
 >> iter 70000, loss: 0.001575
   Number of active neurons: 10
 >> iter 71000, loss: 0.001549
 >> iter 72000, loss: 0.001513
 >> iter 73000, loss: 0.001482
 >> iter 74000, loss: 0.001448
 >> iter 75000, loss: 0.001424
 >> iter 76000, loss: 0.001391
 >> iter 77000, loss: 0.001367
 >> iter 78000, loss: 0.001342
 >> iter 79000, loss: 0.001322
 >> iter 80000, loss: 0.001299
   Number of active neurons: 10
 >> iter 81000, loss: 0.001273
 >> iter 82000, loss: 0.001251
 >> iter 83000, loss: 0.007103
 >> iter 84000, loss: 0.003509
 >> iter 85000, loss: 0.002131
 >> iter 86000, loss: 0.001599
 >> iter 87000, loss: 0.001395
 >> iter 88000, loss: 0.001280
 >> iter 89000, loss: 0.001227
 >> iter 90000, loss: 0.001194
   Number of active neurons: 10
 >> iter 91000, loss: 0.001161
 >> iter 92000, loss: 0.001133
 >> iter 93000, loss: 0.001113
 >> iter 94000, loss: 0.001089
 >> iter 95000, loss: 0.001075
 >> iter 96000, loss: 0.001237
 >> iter 97000, loss: 0.001175
 >> iter 98000, loss: 0.001101
 >> iter 99000, loss: 0.001065
 >> iter 100000, loss: 0.001032
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.609818
 >> iter 2000, loss: 15.090823
 >> iter 3000, loss: 13.750026
 >> iter 4000, loss: 13.260814
 >> iter 5000, loss: 13.064453
 >> iter 6000, loss: 12.997022
 >> iter 7000, loss: 12.962998
 >> iter 8000, loss: 12.959649
 >> iter 9000, loss: 12.947847
 >> iter 10000, loss: 12.951246
   Number of active neurons: 5
 >> iter 11000, loss: 12.942022
 >> iter 12000, loss: 12.944839
 >> iter 13000, loss: 12.829004
 >> iter 14000, loss: 9.111207
 >> iter 15000, loss: 3.453868
 >> iter 16000, loss: 1.308824
 >> iter 17000, loss: 0.503234
 >> iter 18000, loss: 0.351137
 >> iter 19000, loss: 0.201443
 >> iter 20000, loss: 0.087429
   Number of active neurons: 10
 >> iter 21000, loss: 0.042231
 >> iter 22000, loss: 0.023866
 >> iter 23000, loss: 0.015931
 >> iter 24000, loss: 0.012120
 >> iter 25000, loss: 0.010168
 >> iter 26000, loss: 0.008832
 >> iter 27000, loss: 0.007839
 >> iter 28000, loss: 0.007125
 >> iter 29000, loss: 0.006499
 >> iter 30000, loss: 0.018934
   Number of active neurons: 10
 >> iter 31000, loss: 0.010837
 >> iter 32000, loss: 0.007442
 >> iter 33000, loss: 0.005867
 >> iter 34000, loss: 0.005098
 >> iter 35000, loss: 0.004623
 >> iter 36000, loss: 0.004303
 >> iter 37000, loss: 0.004530
 >> iter 38000, loss: 0.004142
 >> iter 39000, loss: 0.003819
 >> iter 40000, loss: 0.003581
   Number of active neurons: 10
 >> iter 41000, loss: 0.003375
 >> iter 42000, loss: 0.003222
 >> iter 43000, loss: 0.003060
 >> iter 44000, loss: 0.002934
 >> iter 45000, loss: 0.002809
 >> iter 46000, loss: 0.002710
 >> iter 47000, loss: 0.002610
 >> iter 48000, loss: 0.002516
 >> iter 49000, loss: 0.002423
 >> iter 50000, loss: 0.002346
   Number of active neurons: 10
 >> iter 51000, loss: 0.002249
 >> iter 52000, loss: 0.002201
 >> iter 53000, loss: 0.002122
 >> iter 54000, loss: 0.002067
 >> iter 55000, loss: 0.001989
 >> iter 56000, loss: 0.001942
 >> iter 57000, loss: 0.001885
 >> iter 58000, loss: 0.001849
 >> iter 59000, loss: 0.001795
 >> iter 60000, loss: 0.001762
   Number of active neurons: 10
 >> iter 61000, loss: 0.001706
 >> iter 62000, loss: 0.001675
 >> iter 63000, loss: 0.001626
 >> iter 64000, loss: 0.001596
 >> iter 65000, loss: 0.001551
 >> iter 66000, loss: 0.001522
 >> iter 67000, loss: 0.001506
 >> iter 68000, loss: 0.001470
 >> iter 69000, loss: 0.001431
 >> iter 70000, loss: 0.001407
   Number of active neurons: 10
 >> iter 71000, loss: 0.001375
 >> iter 72000, loss: 0.001348
 >> iter 73000, loss: 0.001316
 >> iter 74000, loss: 0.001296
 >> iter 75000, loss: 0.001268
 >> iter 76000, loss: 0.001249
 >> iter 77000, loss: 0.001236
 >> iter 78000, loss: 0.001211
 >> iter 79000, loss: 0.001179
 >> iter 80000, loss: 0.001167
   Number of active neurons: 10
 >> iter 81000, loss: 0.168648
 >> iter 82000, loss: 0.063754
 >> iter 83000, loss: 0.024877
 >> iter 84000, loss: 0.010445
 >> iter 85000, loss: 0.005035
 >> iter 86000, loss: 0.002982
 >> iter 87000, loss: 0.002174
 >> iter 88000, loss: 0.001827
 >> iter 89000, loss: 0.001656
 >> iter 90000, loss: 0.001564
   Number of active neurons: 10
 >> iter 91000, loss: 0.001497
 >> iter 92000, loss: 0.001446
 >> iter 93000, loss: 0.001394
 >> iter 94000, loss: 0.001358
 >> iter 95000, loss: 0.001318
 >> iter 96000, loss: 0.001287
 >> iter 97000, loss: 0.001249
 >> iter 98000, loss: 0.001226
 >> iter 99000, loss: 0.001200
 >> iter 100000, loss: 0.001177
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.631463
 >> iter 2000, loss: 15.121577
 >> iter 3000, loss: 13.784218
 >> iter 4000, loss: 13.290297
 >> iter 5000, loss: 13.094659
 >> iter 6000, loss: 13.025213
 >> iter 7000, loss: 12.994483
 >> iter 8000, loss: 12.988718
 >> iter 9000, loss: 12.977389
 >> iter 10000, loss: 12.982919
   Number of active neurons: 7
 >> iter 11000, loss: 12.975038
 >> iter 12000, loss: 12.979484
 >> iter 13000, loss: 12.968427
 >> iter 14000, loss: 12.976760
 >> iter 15000, loss: 12.970878
 >> iter 16000, loss: 12.971304
 >> iter 17000, loss: 12.842358
 >> iter 18000, loss: 8.364143
 >> iter 19000, loss: 3.258877
 >> iter 20000, loss: 1.241842
   Number of active neurons: 10
 >> iter 21000, loss: 0.482867
 >> iter 22000, loss: 0.195748
 >> iter 23000, loss: 0.086054
 >> iter 24000, loss: 0.042999
 >> iter 25000, loss: 0.025366
 >> iter 26000, loss: 0.017468
 >> iter 27000, loss: 0.013608
 >> iter 28000, loss: 0.011366
 >> iter 29000, loss: 0.009911
 >> iter 30000, loss: 0.008884
   Number of active neurons: 10
 >> iter 31000, loss: 0.008080
 >> iter 32000, loss: 0.007371
 >> iter 33000, loss: 0.006854
 >> iter 34000, loss: 0.006333
 >> iter 35000, loss: 0.005934
 >> iter 36000, loss: 0.005548
 >> iter 37000, loss: 0.005248
 >> iter 38000, loss: 0.004956
 >> iter 39000, loss: 0.004730
 >> iter 40000, loss: 0.004501
   Number of active neurons: 10
 >> iter 41000, loss: 0.004286
 >> iter 42000, loss: 0.004067
 >> iter 43000, loss: 0.003902
 >> iter 44000, loss: 0.003708
 >> iter 45000, loss: 0.003554
 >> iter 46000, loss: 0.003406
 >> iter 47000, loss: 0.003310
 >> iter 48000, loss: 0.003208
 >> iter 49000, loss: 0.003115
 >> iter 50000, loss: 0.002981
   Number of active neurons: 10
 >> iter 51000, loss: 0.002883
 >> iter 52000, loss: 0.002804
 >> iter 53000, loss: 0.002705
 >> iter 54000, loss: 0.002624
 >> iter 55000, loss: 0.002548
 >> iter 56000, loss: 0.002483
 >> iter 57000, loss: 0.002425
 >> iter 58000, loss: 0.002346
 >> iter 59000, loss: 0.002285
 >> iter 60000, loss: 0.002217
   Number of active neurons: 10
 >> iter 61000, loss: 0.002175
 >> iter 62000, loss: 0.002121
 >> iter 63000, loss: 0.002073
 >> iter 64000, loss: 0.002026
 >> iter 65000, loss: 0.001990
 >> iter 66000, loss: 0.001946
 >> iter 67000, loss: 0.001919
 >> iter 68000, loss: 0.001860
 >> iter 69000, loss: 0.001821
 >> iter 70000, loss: 0.001778
   Number of active neurons: 10
 >> iter 71000, loss: 0.001749
 >> iter 72000, loss: 0.001709
 >> iter 73000, loss: 0.001681
 >> iter 74000, loss: 0.001657
 >> iter 75000, loss: 0.001671
 >> iter 76000, loss: 0.001607
 >> iter 77000, loss: 0.001572
 >> iter 78000, loss: 0.001534
 >> iter 79000, loss: 0.001509
 >> iter 80000, loss: 0.001482
   Number of active neurons: 10
 >> iter 81000, loss: 0.001480
 >> iter 82000, loss: 0.001445
 >> iter 83000, loss: 0.001413
 >> iter 84000, loss: 0.001389
 >> iter 85000, loss: 0.001362
 >> iter 86000, loss: 0.001338
 >> iter 87000, loss: 0.001319
 >> iter 88000, loss: 0.001299
 >> iter 89000, loss: 0.001285
 >> iter 90000, loss: 0.001268
   Number of active neurons: 10
 >> iter 91000, loss: 0.001253
 >> iter 92000, loss: 0.001228
 >> iter 93000, loss: 0.001216
 >> iter 94000, loss: 0.001197
 >> iter 95000, loss: 0.001177
 >> iter 96000, loss: 0.001159
 >> iter 97000, loss: 0.001151
 >> iter 98000, loss: 0.001135
 >> iter 99000, loss: 0.001118
 >> iter 100000, loss: 0.001106
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.650883
 >> iter 2000, loss: 15.108945
 >> iter 3000, loss: 13.770590
 >> iter 4000, loss: 13.271862
 >> iter 5000, loss: 13.072987
 >> iter 6000, loss: 13.006932
 >> iter 7000, loss: 12.971892
 >> iter 8000, loss: 12.967843
 >> iter 9000, loss: 12.954734
 >> iter 10000, loss: 12.961072
   Number of active neurons: 6
 >> iter 11000, loss: 12.946087
 >> iter 12000, loss: 12.948510
 >> iter 13000, loss: 12.942009
 >> iter 14000, loss: 12.946257
 >> iter 15000, loss: 12.940763
 >> iter 16000, loss: 12.903546
 >> iter 17000, loss: 12.282863
 >> iter 18000, loss: 5.647635
 >> iter 19000, loss: 2.190928
 >> iter 20000, loss: 0.841470
   Number of active neurons: 10
 >> iter 21000, loss: 0.332444
 >> iter 22000, loss: 0.141312
 >> iter 23000, loss: 0.064783
 >> iter 24000, loss: 0.033904
 >> iter 25000, loss: 0.020944
 >> iter 26000, loss: 0.014868
 >> iter 27000, loss: 0.011811
 >> iter 28000, loss: 0.009911
 >> iter 29000, loss: 0.008731
 >> iter 30000, loss: 0.007761
   Number of active neurons: 10
 >> iter 31000, loss: 0.007057
 >> iter 32000, loss: 0.006447
 >> iter 33000, loss: 0.005971
 >> iter 34000, loss: 0.005498
 >> iter 35000, loss: 0.005145
 >> iter 36000, loss: 0.004813
 >> iter 37000, loss: 0.004539
 >> iter 38000, loss: 0.004260
 >> iter 39000, loss: 0.004036
 >> iter 40000, loss: 0.003838
   Number of active neurons: 10
 >> iter 41000, loss: 0.003649
 >> iter 42000, loss: 0.003464
 >> iter 43000, loss: 0.003314
 >> iter 44000, loss: 0.003156
 >> iter 45000, loss: 0.003041
 >> iter 46000, loss: 0.002904
 >> iter 47000, loss: 0.002800
 >> iter 48000, loss: 0.002685
 >> iter 49000, loss: 0.002657
 >> iter 50000, loss: 0.002540
   Number of active neurons: 10
 >> iter 51000, loss: 0.002459
 >> iter 52000, loss: 0.002352
 >> iter 53000, loss: 0.002284
 >> iter 54000, loss: 0.002205
 >> iter 55000, loss: 0.002146
 >> iter 56000, loss: 0.002071
 >> iter 57000, loss: 0.002026
 >> iter 58000, loss: 0.001965
 >> iter 59000, loss: 0.001917
 >> iter 60000, loss: 0.001855
   Number of active neurons: 10
 >> iter 61000, loss: 0.001812
 >> iter 62000, loss: 0.001759
 >> iter 63000, loss: 0.001723
 >> iter 64000, loss: 0.001675
 >> iter 65000, loss: 0.001642
 >> iter 66000, loss: 0.001598
 >> iter 67000, loss: 0.001573
 >> iter 68000, loss: 0.001526
 >> iter 69000, loss: 0.001504
 >> iter 70000, loss: 0.001465
   Number of active neurons: 10
 >> iter 71000, loss: 0.001442
 >> iter 72000, loss: 0.001407
 >> iter 73000, loss: 0.001386
 >> iter 74000, loss: 0.001354
 >> iter 75000, loss: 0.001328
 >> iter 76000, loss: 0.001299
 >> iter 77000, loss: 0.001283
 >> iter 78000, loss: 0.001250
 >> iter 79000, loss: 0.001242
 >> iter 80000, loss: 0.001211
   Number of active neurons: 10
 >> iter 81000, loss: 0.001192
 >> iter 82000, loss: 0.001169
 >> iter 83000, loss: 0.049062
 >> iter 84000, loss: 0.019021
 >> iter 85000, loss: 0.007897
 >> iter 86000, loss: 0.003742
 >> iter 87000, loss: 0.002188
 >> iter 88000, loss: 0.001581
 >> iter 89000, loss: 0.001339
 >> iter 90000, loss: 0.001225
   Number of active neurons: 10
 >> iter 91000, loss: 0.001165
 >> iter 92000, loss: 0.001119
 >> iter 93000, loss: 0.001096
 >> iter 94000, loss: 0.001071
 >> iter 95000, loss: 0.001051
 >> iter 96000, loss: 0.001036
 >> iter 97000, loss: 0.001015
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.670724
 >> iter 2000, loss: 15.140308
 >> iter 3000, loss: 13.796627
 >> iter 4000, loss: 13.293184
 >> iter 5000, loss: 13.090577
 >> iter 6000, loss: 13.014202
 >> iter 7000, loss: 12.975639
 >> iter 8000, loss: 12.961583
 >> iter 9000, loss: 12.742463
 >> iter 10000, loss: 12.097140
   Number of active neurons: 10
 >> iter 11000, loss: 5.357138
 >> iter 12000, loss: 2.149409
 >> iter 13000, loss: 0.830329
 >> iter 14000, loss: 0.331440
 >> iter 15000, loss: 0.141130
 >> iter 16000, loss: 0.066303
 >> iter 17000, loss: 0.035826
 >> iter 18000, loss: 0.022580
 >> iter 19000, loss: 0.016252
 >> iter 20000, loss: 0.012709
   Number of active neurons: 10
 >> iter 21000, loss: 0.010728
 >> iter 22000, loss: 0.009168
 >> iter 23000, loss: 0.152300
 >> iter 24000, loss: 0.063751
 >> iter 25000, loss: 0.030204
 >> iter 26000, loss: 0.015566
 >> iter 27000, loss: 0.009838
 >> iter 28000, loss: 0.007240
 >> iter 29000, loss: 0.006081
 >> iter 30000, loss: 0.007481
   Number of active neurons: 10
 >> iter 31000, loss: 0.006144
 >> iter 32000, loss: 0.005122
 >> iter 33000, loss: 0.004569
 >> iter 34000, loss: 0.004105
 >> iter 35000, loss: 0.003842
 >> iter 36000, loss: 0.003572
 >> iter 37000, loss: 0.003418
 >> iter 38000, loss: 0.003226
 >> iter 39000, loss: 0.003144
 >> iter 40000, loss: 0.002974
   Number of active neurons: 10
 >> iter 41000, loss: 0.002936
 >> iter 42000, loss: 0.002761
 >> iter 43000, loss: 0.002680
 >> iter 44000, loss: 0.002543
 >> iter 45000, loss: 0.002488
 >> iter 46000, loss: 0.002392
 >> iter 47000, loss: 0.002356
 >> iter 48000, loss: 0.002259
 >> iter 49000, loss: 0.002207
 >> iter 50000, loss: 0.003680
   Number of active neurons: 10
 >> iter 51000, loss: 0.003457
 >> iter 52000, loss: 0.002797
 >> iter 53000, loss: 0.002440
 >> iter 54000, loss: 0.002192
 >> iter 55000, loss: 0.002074
 >> iter 56000, loss: 0.001928
 >> iter 57000, loss: 0.001863
 >> iter 58000, loss: 0.001814
 >> iter 59000, loss: 0.001767
 >> iter 60000, loss: 0.001702
   Number of active neurons: 10
 >> iter 61000, loss: 0.001667
 >> iter 62000, loss: 0.001605
 >> iter 63000, loss: 0.001588
 >> iter 64000, loss: 0.001546
 >> iter 65000, loss: 0.001514
 >> iter 66000, loss: 0.001470
 >> iter 67000, loss: 0.001483
 >> iter 68000, loss: 0.001431
 >> iter 69000, loss: 0.001423
 >> iter 70000, loss: 0.001370
   Number of active neurons: 10
 >> iter 71000, loss: 0.001345
 >> iter 72000, loss: 0.001341
 >> iter 73000, loss: 0.001331
 >> iter 74000, loss: 0.001287
 >> iter 75000, loss: 0.001257
 >> iter 76000, loss: 0.001224
 >> iter 77000, loss: 0.001216
 >> iter 78000, loss: 0.001186
 >> iter 79000, loss: 0.001190
 >> iter 80000, loss: 0.001155
   Number of active neurons: 10
 >> iter 81000, loss: 0.001138
 >> iter 82000, loss: 0.001113
 >> iter 83000, loss: 0.001109
 >> iter 84000, loss: 0.001091
 >> iter 85000, loss: 0.001067
 >> iter 86000, loss: 0.001049
 >> iter 87000, loss: 0.001054
 >> iter 88000, loss: 0.001025
 >> iter 89000, loss: 0.001021
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.623852
 >> iter 2000, loss: 15.091048
 >> iter 3000, loss: 13.750170
 >> iter 4000, loss: 13.261546
 >> iter 5000, loss: 13.060069
 >> iter 6000, loss: 12.991402
 >> iter 7000, loss: 12.951822
 >> iter 8000, loss: 12.948553
 >> iter 9000, loss: 12.934198
 >> iter 10000, loss: 12.939136
   Number of active neurons: 5
 >> iter 11000, loss: 12.923536
 >> iter 12000, loss: 12.379907
 >> iter 13000, loss: 6.057215
 >> iter 14000, loss: 2.286929
 >> iter 15000, loss: 0.862812
 >> iter 16000, loss: 0.331938
 >> iter 17000, loss: 0.132545
 >> iter 18000, loss: 0.057109
 >> iter 19000, loss: 0.029679
 >> iter 20000, loss: 0.017411
   Number of active neurons: 10
 >> iter 21000, loss: 0.011754
 >> iter 22000, loss: 0.009096
 >> iter 23000, loss: 0.007520
 >> iter 24000, loss: 0.006582
 >> iter 25000, loss: 0.005875
 >> iter 26000, loss: 0.005438
 >> iter 27000, loss: 0.004961
 >> iter 28000, loss: 0.004614
 >> iter 29000, loss: 0.004259
 >> iter 30000, loss: 0.004086
   Number of active neurons: 10
 >> iter 31000, loss: 0.003794
 >> iter 32000, loss: 0.003564
 >> iter 33000, loss: 0.003354
 >> iter 34000, loss: 0.003192
 >> iter 35000, loss: 0.003028
 >> iter 36000, loss: 0.002889
 >> iter 37000, loss: 0.002959
 >> iter 38000, loss: 0.002832
 >> iter 39000, loss: 0.091994
 >> iter 40000, loss: 0.036112
   Number of active neurons: 10
 >> iter 41000, loss: 0.015259
 >> iter 42000, loss: 0.007467
 >> iter 43000, loss: 0.004470
 >> iter 44000, loss: 0.003304
 >> iter 45000, loss: 0.002763
 >> iter 46000, loss: 0.002522
 >> iter 47000, loss: 0.002347
 >> iter 48000, loss: 0.002236
 >> iter 49000, loss: 0.002126
 >> iter 50000, loss: 0.002089
   Number of active neurons: 10
 >> iter 51000, loss: 0.001986
 >> iter 52000, loss: 0.001931
 >> iter 53000, loss: 0.001930
 >> iter 54000, loss: 0.002253
 >> iter 55000, loss: 0.002015
 >> iter 56000, loss: 0.001900
 >> iter 57000, loss: 0.001780
 >> iter 58000, loss: 0.001708
 >> iter 59000, loss: 0.001733
 >> iter 60000, loss: 0.001685
   Number of active neurons: 10
 >> iter 61000, loss: 0.001604
 >> iter 62000, loss: 0.001557
 >> iter 63000, loss: 0.001492
 >> iter 64000, loss: 0.001456
 >> iter 65000, loss: 0.001409
 >> iter 66000, loss: 0.001378
 >> iter 67000, loss: 0.001340
 >> iter 68000, loss: 0.001309
 >> iter 69000, loss: 0.001273
 >> iter 70000, loss: 0.001250
   Number of active neurons: 10
 >> iter 71000, loss: 0.001217
 >> iter 72000, loss: 0.001201
 >> iter 73000, loss: 0.001171
 >> iter 74000, loss: 0.001149
 >> iter 75000, loss: 0.001139
 >> iter 76000, loss: 0.001110
 >> iter 77000, loss: 0.001084
 >> iter 78000, loss: 0.001066
 >> iter 79000, loss: 0.001043
 >> iter 80000, loss: 0.001034
   Number of active neurons: 10
 >> iter 81000, loss: 0.001012
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.640917
 >> iter 2000, loss: 15.118106
 >> iter 3000, loss: 13.778508
 >> iter 4000, loss: 13.278614
 >> iter 5000, loss: 13.077315
 >> iter 6000, loss: 13.003523
 >> iter 7000, loss: 12.967876
 >> iter 8000, loss: 12.960163
 >> iter 9000, loss: 12.944963
 >> iter 10000, loss: 12.796616
   Number of active neurons: 8
 >> iter 11000, loss: 11.633475
 >> iter 12000, loss: 4.769118
 >> iter 13000, loss: 1.794292
 >> iter 14000, loss: 0.682177
 >> iter 15000, loss: 0.265724
 >> iter 16000, loss: 0.108934
 >> iter 17000, loss: 0.048872
 >> iter 18000, loss: 0.025197
 >> iter 19000, loss: 0.015485
 >> iter 20000, loss: 0.011046
   Number of active neurons: 10
 >> iter 21000, loss: 0.008770
 >> iter 22000, loss: 0.007400
 >> iter 23000, loss: 0.006485
 >> iter 24000, loss: 0.005828
 >> iter 25000, loss: 0.005290
 >> iter 26000, loss: 0.004912
 >> iter 27000, loss: 0.004503
 >> iter 28000, loss: 0.004191
 >> iter 29000, loss: 0.003930
 >> iter 30000, loss: 0.003682
   Number of active neurons: 10
 >> iter 31000, loss: 0.003459
 >> iter 32000, loss: 0.003266
 >> iter 33000, loss: 0.003081
 >> iter 34000, loss: 0.003074
 >> iter 35000, loss: 0.002871
 >> iter 36000, loss: 0.002717
 >> iter 37000, loss: 0.002555
 >> iter 38000, loss: 0.002455
 >> iter 39000, loss: 0.002328
 >> iter 40000, loss: 0.002244
   Number of active neurons: 10
 >> iter 41000, loss: 0.294130
 >> iter 42000, loss: 0.121286
 >> iter 43000, loss: 0.046986
 >> iter 44000, loss: 0.019334
 >> iter 45000, loss: 0.009185
 >> iter 46000, loss: 0.005083
 >> iter 47000, loss: 0.003406
 >> iter 48000, loss: 0.002706
 >> iter 49000, loss: 0.002344
 >> iter 50000, loss: 0.002174
   Number of active neurons: 10
 >> iter 51000, loss: 0.002019
 >> iter 52000, loss: 0.001936
 >> iter 53000, loss: 0.001835
 >> iter 54000, loss: 0.001776
 >> iter 55000, loss: 0.001697
 >> iter 56000, loss: 0.001647
 >> iter 57000, loss: 0.001575
 >> iter 58000, loss: 0.001547
 >> iter 59000, loss: 0.001475
 >> iter 60000, loss: 0.001441
   Number of active neurons: 10
 >> iter 61000, loss: 0.001395
 >> iter 62000, loss: 0.001366
 >> iter 63000, loss: 0.001315
 >> iter 64000, loss: 0.001292
 >> iter 65000, loss: 0.001249
 >> iter 66000, loss: 0.001232
 >> iter 67000, loss: 0.001188
 >> iter 68000, loss: 0.001172
 >> iter 69000, loss: 0.001134
 >> iter 70000, loss: 0.001119
   Number of active neurons: 10
 >> iter 71000, loss: 0.001087
 >> iter 72000, loss: 0.001076
 >> iter 73000, loss: 0.001045
 >> iter 74000, loss: 0.001034
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.621843
 >> iter 2000, loss: 15.120964
 >> iter 3000, loss: 13.798047
 >> iter 4000, loss: 13.303582
 >> iter 5000, loss: 13.098218
 >> iter 6000, loss: 13.020762
 >> iter 7000, loss: 12.980862
 >> iter 8000, loss: 12.972002
 >> iter 9000, loss: 12.956088
 >> iter 10000, loss: 12.962649
   Number of active neurons: 7
 >> iter 11000, loss: 12.948075
 >> iter 12000, loss: 12.946730
 >> iter 13000, loss: 12.935580
 >> iter 14000, loss: 12.685234
 >> iter 15000, loss: 9.189521
 >> iter 16000, loss: 3.452807
 >> iter 17000, loss: 1.300758
 >> iter 18000, loss: 0.497849
 >> iter 19000, loss: 0.197527
 >> iter 20000, loss: 0.083945
   Number of active neurons: 10
 >> iter 21000, loss: 0.040815
 >> iter 22000, loss: 0.023074
 >> iter 23000, loss: 0.015417
 >> iter 24000, loss: 0.011759
 >> iter 25000, loss: 0.009752
 >> iter 26000, loss: 0.008478
 >> iter 27000, loss: 0.007608
 >> iter 28000, loss: 0.006914
 >> iter 29000, loss: 0.006400
 >> iter 30000, loss: 0.005902
   Number of active neurons: 10
 >> iter 31000, loss: 0.005520
 >> iter 32000, loss: 0.005191
 >> iter 33000, loss: 0.005226
 >> iter 34000, loss: 0.004792
 >> iter 35000, loss: 0.004469
 >> iter 36000, loss: 0.004205
 >> iter 37000, loss: 0.003967
 >> iter 38000, loss: 0.003787
 >> iter 39000, loss: 0.003605
 >> iter 40000, loss: 0.003441
   Number of active neurons: 10
 >> iter 41000, loss: 0.003315
 >> iter 42000, loss: 0.172335
 >> iter 43000, loss: 0.066620
 >> iter 44000, loss: 0.027225
 >> iter 45000, loss: 0.012482
 >> iter 46000, loss: 0.006885
 >> iter 47000, loss: 0.004683
 >> iter 48000, loss: 0.003750
 >> iter 49000, loss: 0.003298
 >> iter 50000, loss: 0.003056
   Number of active neurons: 10
 >> iter 51000, loss: 0.002881
 >> iter 52000, loss: 0.002746
 >> iter 53000, loss: 0.002624
 >> iter 54000, loss: 0.002552
 >> iter 55000, loss: 0.002460
 >> iter 56000, loss: 0.002362
 >> iter 57000, loss: 0.002280
 >> iter 58000, loss: 0.002219
 >> iter 59000, loss: 0.002140
 >> iter 60000, loss: 0.002082
   Number of active neurons: 10
 >> iter 61000, loss: 0.002021
 >> iter 62000, loss: 0.001971
 >> iter 63000, loss: 0.001918
 >> iter 64000, loss: 0.001871
 >> iter 65000, loss: 0.001820
 >> iter 66000, loss: 0.001772
 >> iter 67000, loss: 0.001724
 >> iter 68000, loss: 0.001694
 >> iter 69000, loss: 0.001653
 >> iter 70000, loss: 0.001627
   Number of active neurons: 10
 >> iter 71000, loss: 0.001586
 >> iter 72000, loss: 0.001554
 >> iter 73000, loss: 0.001518
 >> iter 74000, loss: 0.001489
 >> iter 75000, loss: 0.001465
 >> iter 76000, loss: 0.001438
 >> iter 77000, loss: 0.001408
 >> iter 78000, loss: 0.001392
 >> iter 79000, loss: 0.001366
 >> iter 80000, loss: 0.001333
   Number of active neurons: 10
 >> iter 81000, loss: 0.001305
 >> iter 82000, loss: 0.001286
 >> iter 83000, loss: 0.001266
 >> iter 84000, loss: 0.001244
 >> iter 85000, loss: 0.001226
 >> iter 86000, loss: 0.001209
 >> iter 87000, loss: 0.001982
 >> iter 88000, loss: 0.001632
 >> iter 89000, loss: 0.001433
 >> iter 90000, loss: 0.001325
   Number of active neurons: 10
 >> iter 91000, loss: 0.001259
 >> iter 92000, loss: 0.001209
 >> iter 93000, loss: 0.001179
 >> iter 94000, loss: 0.001151
 >> iter 95000, loss: 0.001129
 >> iter 96000, loss: 0.001102
 >> iter 97000, loss: 0.001088
 >> iter 98000, loss: 0.001063
 >> iter 99000, loss: 0.001046
 >> iter 100000, loss: 0.001026
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.614844
 >> iter 2000, loss: 15.084085
 >> iter 3000, loss: 13.742982
 >> iter 4000, loss: 13.249968
 >> iter 5000, loss: 13.051710
 >> iter 6000, loss: 12.981129
 >> iter 7000, loss: 12.945561
 >> iter 8000, loss: 12.938011
 >> iter 9000, loss: 12.884789
 >> iter 10000, loss: 12.222659
   Number of active neurons: 9
 >> iter 11000, loss: 6.357834
 >> iter 12000, loss: 2.375439
 >> iter 13000, loss: 0.892716
 >> iter 14000, loss: 0.341097
 >> iter 15000, loss: 0.134893
 >> iter 16000, loss: 0.057188
 >> iter 17000, loss: 0.027379
 >> iter 18000, loss: 0.016495
 >> iter 19000, loss: 0.010793
 >> iter 20000, loss: 0.008052
   Number of active neurons: 10
 >> iter 21000, loss: 0.006573
 >> iter 22000, loss: 0.005699
 >> iter 23000, loss: 0.005094
 >> iter 24000, loss: 0.004688
 >> iter 25000, loss: 0.004286
 >> iter 26000, loss: 0.003949
 >> iter 27000, loss: 0.003720
 >> iter 28000, loss: 0.003463
 >> iter 29000, loss: 0.003246
 >> iter 30000, loss: 1.379342
   Number of active neurons: 10
 >> iter 31000, loss: 0.527385
 >> iter 32000, loss: 0.227640
 >> iter 33000, loss: 0.093145
 >> iter 34000, loss: 0.040660
 >> iter 35000, loss: 0.020179
 >> iter 36000, loss: 0.011925
 >> iter 37000, loss: 0.008294
 >> iter 38000, loss: 0.006575
 >> iter 39000, loss: 0.005598
 >> iter 40000, loss: 0.004948
   Number of active neurons: 10
 >> iter 41000, loss: 0.004462
 >> iter 42000, loss: 0.004078
 >> iter 43000, loss: 0.003831
 >> iter 44000, loss: 0.003543
 >> iter 45000, loss: 0.003290
 >> iter 46000, loss: 0.003117
 >> iter 47000, loss: 0.002924
 >> iter 48000, loss: 0.002753
 >> iter 49000, loss: 0.002597
 >> iter 50000, loss: 0.002479
   Number of active neurons: 10
 >> iter 51000, loss: 0.002362
 >> iter 52000, loss: 0.002252
 >> iter 53000, loss: 0.002146
 >> iter 54000, loss: 0.002071
 >> iter 55000, loss: 0.002011
 >> iter 56000, loss: 0.001927
 >> iter 57000, loss: 0.001838
 >> iter 58000, loss: 0.001781
 >> iter 59000, loss: 0.001841
 >> iter 60000, loss: 0.001721
   Number of active neurons: 10
 >> iter 61000, loss: 0.001653
 >> iter 62000, loss: 0.001577
 >> iter 63000, loss: 0.001513
 >> iter 64000, loss: 0.001464
 >> iter 65000, loss: 0.001425
 >> iter 66000, loss: 0.001394
 >> iter 67000, loss: 0.001347
 >> iter 68000, loss: 0.001314
 >> iter 69000, loss: 0.001270
 >> iter 70000, loss: 0.001241
   Number of active neurons: 10
 >> iter 71000, loss: 0.001209
 >> iter 72000, loss: 0.001194
 >> iter 73000, loss: 0.001155
 >> iter 74000, loss: 0.001131
 >> iter 75000, loss: 0.001107
 >> iter 76000, loss: 0.001091
 >> iter 77000, loss: 0.001062
 >> iter 78000, loss: 0.001037
 >> iter 79000, loss: 0.001015
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.624415
 >> iter 2000, loss: 15.116426
 >> iter 3000, loss: 13.786686
 >> iter 4000, loss: 13.284367
 >> iter 5000, loss: 13.081298
 >> iter 6000, loss: 13.008805
 >> iter 7000, loss: 12.969786
 >> iter 8000, loss: 12.871607
 >> iter 9000, loss: 12.374106
 >> iter 10000, loss: 7.579001
   Number of active neurons: 10
 >> iter 11000, loss: 2.874175
 >> iter 12000, loss: 1.097251
 >> iter 13000, loss: 0.424886
 >> iter 14000, loss: 0.172177
 >> iter 15000, loss: 0.074981
 >> iter 16000, loss: 0.037055
 >> iter 17000, loss: 0.164467
 >> iter 18000, loss: 0.069616
 >> iter 19000, loss: 0.032701
 >> iter 20000, loss: 0.018932
   Number of active neurons: 10
 >> iter 21000, loss: 0.012579
 >> iter 22000, loss: 0.009720
 >> iter 23000, loss: 0.008106
 >> iter 24000, loss: 0.007042
 >> iter 25000, loss: 0.007604
 >> iter 26000, loss: 0.006534
 >> iter 27000, loss: 0.005709
 >> iter 28000, loss: 0.005184
 >> iter 29000, loss: 0.004745
 >> iter 30000, loss: 0.004409
   Number of active neurons: 10
 >> iter 31000, loss: 0.004123
 >> iter 32000, loss: 0.003892
 >> iter 33000, loss: 0.003646
 >> iter 34000, loss: 0.003744
 >> iter 35000, loss: 0.003552
 >> iter 36000, loss: 0.003324
 >> iter 37000, loss: 0.003110
 >> iter 38000, loss: 0.002944
 >> iter 39000, loss: 0.002846
 >> iter 40000, loss: 0.002722
   Number of active neurons: 10
 >> iter 41000, loss: 0.002589
 >> iter 42000, loss: 0.002480
 >> iter 43000, loss: 0.055788
 >> iter 44000, loss: 0.022773
 >> iter 45000, loss: 0.010235
 >> iter 46000, loss: 0.006012
 >> iter 47000, loss: 0.003908
 >> iter 48000, loss: 0.002957
 >> iter 49000, loss: 0.002534
 >> iter 50000, loss: 0.002289
   Number of active neurons: 10
 >> iter 51000, loss: 0.002148
 >> iter 52000, loss: 0.002045
 >> iter 53000, loss: 0.001964
 >> iter 54000, loss: 0.001901
 >> iter 55000, loss: 0.001823
 >> iter 56000, loss: 0.007737
 >> iter 57000, loss: 0.004197
 >> iter 58000, loss: 0.002766
 >> iter 59000, loss: 0.002161
 >> iter 60000, loss: 0.001895
   Number of active neurons: 10
 >> iter 61000, loss: 0.001747
 >> iter 62000, loss: 0.001663
 >> iter 63000, loss: 0.001596
 >> iter 64000, loss: 0.001551
 >> iter 65000, loss: 0.001510
 >> iter 66000, loss: 0.001468
 >> iter 67000, loss: 0.001424
 >> iter 68000, loss: 0.001392
 >> iter 69000, loss: 0.003225
 >> iter 70000, loss: 0.002417
   Number of active neurons: 10
 >> iter 71000, loss: 0.001945
 >> iter 72000, loss: 0.001675
 >> iter 73000, loss: 0.001548
 >> iter 74000, loss: 0.001465
 >> iter 75000, loss: 0.001398
 >> iter 76000, loss: 0.001339
 >> iter 77000, loss: 0.001295
 >> iter 78000, loss: 0.001257
 >> iter 79000, loss: 0.001226
 >> iter 80000, loss: 0.001191
   Number of active neurons: 10
 >> iter 81000, loss: 0.001167
 >> iter 82000, loss: 0.001141
 >> iter 83000, loss: 0.001119
 >> iter 84000, loss: 0.001088
 >> iter 85000, loss: 0.001066
 >> iter 86000, loss: 0.001043
 >> iter 87000, loss: 0.001032
 >> iter 88000, loss: 0.001011
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.598834
 >> iter 2000, loss: 15.095499
 >> iter 3000, loss: 13.772341
 >> iter 4000, loss: 13.284892
 >> iter 5000, loss: 13.078384
 >> iter 6000, loss: 13.013097
 >> iter 7000, loss: 12.973728
 >> iter 8000, loss: 12.965384
 >> iter 9000, loss: 12.946843
 >> iter 10000, loss: 12.948800
   Number of active neurons: 5
 >> iter 11000, loss: 12.932113
 >> iter 12000, loss: 12.519347
 >> iter 13000, loss: 8.715259
 >> iter 14000, loss: 3.291540
 >> iter 15000, loss: 1.243322
 >> iter 16000, loss: 0.477545
 >> iter 17000, loss: 0.190126
 >> iter 18000, loss: 0.139207
 >> iter 19000, loss: 0.061801
 >> iter 20000, loss: 0.031491
   Number of active neurons: 10
 >> iter 21000, loss: 0.019009
 >> iter 22000, loss: 0.013486
 >> iter 23000, loss: 0.010645
 >> iter 24000, loss: 0.009052
 >> iter 25000, loss: 0.007951
 >> iter 26000, loss: 0.007181
 >> iter 27000, loss: 0.006630
 >> iter 28000, loss: 0.006263
 >> iter 29000, loss: 0.005677
 >> iter 30000, loss: 0.005244
   Number of active neurons: 10
 >> iter 31000, loss: 0.004901
 >> iter 32000, loss: 0.004593
 >> iter 33000, loss: 0.004531
 >> iter 34000, loss: 0.004244
 >> iter 35000, loss: 0.003950
 >> iter 36000, loss: 0.003728
 >> iter 37000, loss: 0.003558
 >> iter 38000, loss: 0.003410
 >> iter 39000, loss: 0.003248
 >> iter 40000, loss: 0.003104
   Number of active neurons: 10
 >> iter 41000, loss: 0.002988
 >> iter 42000, loss: 0.002871
 >> iter 43000, loss: 0.002771
 >> iter 44000, loss: 0.002675
 >> iter 45000, loss: 0.002564
 >> iter 46000, loss: 0.002484
 >> iter 47000, loss: 0.002412
 >> iter 48000, loss: 0.002329
 >> iter 49000, loss: 0.002260
 >> iter 50000, loss: 0.004612
   Number of active neurons: 10
 >> iter 51000, loss: 0.003158
 >> iter 52000, loss: 0.002509
 >> iter 53000, loss: 0.002207
 >> iter 54000, loss: 0.002067
 >> iter 55000, loss: 0.012070
 >> iter 56000, loss: 0.005871
 >> iter 57000, loss: 0.003441
 >> iter 58000, loss: 0.002512
 >> iter 59000, loss: 0.002102
 >> iter 60000, loss: 0.001928
   Number of active neurons: 10
 >> iter 61000, loss: 0.001839
 >> iter 62000, loss: 0.001769
 >> iter 63000, loss: 0.001695
 >> iter 64000, loss: 0.001650
 >> iter 65000, loss: 0.001603
 >> iter 66000, loss: 0.001582
 >> iter 67000, loss: 0.001529
 >> iter 68000, loss: 0.001502
 >> iter 69000, loss: 0.001459
 >> iter 70000, loss: 0.001439
   Number of active neurons: 10
 >> iter 71000, loss: 0.001398
 >> iter 72000, loss: 0.001374
 >> iter 73000, loss: 0.001339
 >> iter 74000, loss: 0.001322
 >> iter 75000, loss: 0.001288
 >> iter 76000, loss: 0.001273
 >> iter 77000, loss: 0.001251
 >> iter 78000, loss: 0.001227
 >> iter 79000, loss: 0.001238
 >> iter 80000, loss: 0.001203
   Number of active neurons: 10
 >> iter 81000, loss: 0.001168
 >> iter 82000, loss: 0.001154
 >> iter 83000, loss: 0.001127
 >> iter 84000, loss: 0.001120
 >> iter 85000, loss: 0.001089
 >> iter 86000, loss: 0.001077
 >> iter 87000, loss: 0.001059
 >> iter 88000, loss: 0.001045
 >> iter 89000, loss: 0.001020
 >> iter 90000, loss: 0.001017
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.634912
 >> iter 2000, loss: 15.136565
 >> iter 3000, loss: 13.791026
 >> iter 4000, loss: 13.288465
 >> iter 5000, loss: 13.081934
 >> iter 6000, loss: 13.006779
 >> iter 7000, loss: 12.960235
 >> iter 8000, loss: 12.951178
 >> iter 9000, loss: 12.937713
 >> iter 10000, loss: 12.942465
   Number of active neurons: 4
 >> iter 11000, loss: 12.927613
 >> iter 12000, loss: 12.924979
 >> iter 13000, loss: 12.602636
 >> iter 14000, loss: 5.612644
 >> iter 15000, loss: 2.097104
 >> iter 16000, loss: 0.790080
 >> iter 17000, loss: 0.303654
 >> iter 18000, loss: 0.121647
 >> iter 19000, loss: 0.052892
 >> iter 20000, loss: 0.118453
   Number of active neurons: 10
 >> iter 21000, loss: 0.051402
 >> iter 22000, loss: 0.025154
 >> iter 23000, loss: 0.014570
 >> iter 24000, loss: 0.010026
 >> iter 25000, loss: 0.007870
 >> iter 26000, loss: 0.006627
 >> iter 27000, loss: 0.006177
 >> iter 28000, loss: 0.005659
 >> iter 29000, loss: 0.005085
 >> iter 30000, loss: 0.004606
   Number of active neurons: 10
 >> iter 31000, loss: 0.004258
 >> iter 32000, loss: 0.003922
 >> iter 33000, loss: 0.003693
 >> iter 34000, loss: 0.003460
 >> iter 35000, loss: 0.003273
 >> iter 36000, loss: 0.003096
 >> iter 37000, loss: 0.002949
 >> iter 38000, loss: 0.002807
 >> iter 39000, loss: 0.002825
 >> iter 40000, loss: 0.002802
   Number of active neurons: 10
 >> iter 41000, loss: 0.002656
 >> iter 42000, loss: 0.002501
 >> iter 43000, loss: 0.002374
 >> iter 44000, loss: 0.002271
 >> iter 45000, loss: 0.002166
 >> iter 46000, loss: 0.002078
 >> iter 47000, loss: 0.002011
 >> iter 48000, loss: 0.001930
 >> iter 49000, loss: 0.001881
 >> iter 50000, loss: 0.001813
   Number of active neurons: 10
 >> iter 51000, loss: 0.001761
 >> iter 52000, loss: 0.001700
 >> iter 53000, loss: 0.001652
 >> iter 54000, loss: 0.001606
 >> iter 55000, loss: 0.001569
 >> iter 56000, loss: 0.001529
 >> iter 57000, loss: 0.001500
 >> iter 58000, loss: 0.001457
 >> iter 59000, loss: 0.001435
 >> iter 60000, loss: 0.001386
   Number of active neurons: 10
 >> iter 61000, loss: 0.001352
 >> iter 62000, loss: 0.001323
 >> iter 63000, loss: 0.001291
 >> iter 64000, loss: 0.001271
 >> iter 65000, loss: 0.001247
 >> iter 66000, loss: 0.001212
 >> iter 67000, loss: 0.001185
 >> iter 68000, loss: 0.001161
 >> iter 69000, loss: 0.001139
 >> iter 70000, loss: 0.001121
   Number of active neurons: 10
 >> iter 71000, loss: 0.002985
 >> iter 72000, loss: 0.001908
 >> iter 73000, loss: 0.001487
 >> iter 74000, loss: 0.001297
 >> iter 75000, loss: 0.001198
 >> iter 76000, loss: 0.001142
 >> iter 77000, loss: 0.001109
 >> iter 78000, loss: 0.001073
 >> iter 79000, loss: 0.001058
 >> iter 80000, loss: 0.001029
   Number of active neurons: 10
 >> iter 81000, loss: 0.001006
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.641123
 >> iter 2000, loss: 15.094975
 >> iter 3000, loss: 13.759834
 >> iter 4000, loss: 13.266290
 >> iter 5000, loss: 13.065447
 >> iter 6000, loss: 12.994055
 >> iter 7000, loss: 12.953347
 >> iter 8000, loss: 12.945136
 >> iter 9000, loss: 12.928725
 >> iter 10000, loss: 12.934243
   Number of active neurons: 5
 >> iter 11000, loss: 12.923127
 >> iter 12000, loss: 12.926077
 >> iter 13000, loss: 12.912688
 >> iter 14000, loss: 12.569592
 >> iter 15000, loss: 7.786165
 >> iter 16000, loss: 3.268889
 >> iter 17000, loss: 1.233733
 >> iter 18000, loss: 0.472066
 >> iter 19000, loss: 0.187617
 >> iter 20000, loss: 0.078917
   Number of active neurons: 10
 >> iter 21000, loss: 0.037076
 >> iter 22000, loss: 0.020561
 >> iter 23000, loss: 0.024539
 >> iter 24000, loss: 0.016247
 >> iter 25000, loss: 0.010977
 >> iter 26000, loss: 0.008411
 >> iter 27000, loss: 0.006935
 >> iter 28000, loss: 0.006088
 >> iter 29000, loss: 0.005425
 >> iter 30000, loss: 0.004979
   Number of active neurons: 10
 >> iter 31000, loss: 0.004619
 >> iter 32000, loss: 0.004303
 >> iter 33000, loss: 0.004010
 >> iter 34000, loss: 0.003789
 >> iter 35000, loss: 0.003552
 >> iter 36000, loss: 0.003365
 >> iter 37000, loss: 0.003206
 >> iter 38000, loss: 0.003064
 >> iter 39000, loss: 0.002914
 >> iter 40000, loss: 0.002797
   Number of active neurons: 10
 >> iter 41000, loss: 0.002673
 >> iter 42000, loss: 0.002581
 >> iter 43000, loss: 0.002499
 >> iter 44000, loss: 0.002419
 >> iter 45000, loss: 0.002320
 >> iter 46000, loss: 0.002231
 >> iter 47000, loss: 0.002141
 >> iter 48000, loss: 0.002083
 >> iter 49000, loss: 0.002011
 >> iter 50000, loss: 0.001950
   Number of active neurons: 10
 >> iter 51000, loss: 0.001894
 >> iter 52000, loss: 0.001842
 >> iter 53000, loss: 0.001790
 >> iter 54000, loss: 0.001748
 >> iter 55000, loss: 0.001697
 >> iter 56000, loss: 0.001658
 >> iter 57000, loss: 0.001605
 >> iter 58000, loss: 0.001571
 >> iter 59000, loss: 0.001528
 >> iter 60000, loss: 0.001507
   Number of active neurons: 10
 >> iter 61000, loss: 0.001472
 >> iter 62000, loss: 0.001455
 >> iter 63000, loss: 0.001416
 >> iter 64000, loss: 0.001384
 >> iter 65000, loss: 0.001354
 >> iter 66000, loss: 0.001328
 >> iter 67000, loss: 0.001300
 >> iter 68000, loss: 0.001275
 >> iter 69000, loss: 0.001256
 >> iter 70000, loss: 0.001226
   Number of active neurons: 10
 >> iter 71000, loss: 0.001202
 >> iter 72000, loss: 0.001181
 >> iter 73000, loss: 0.001170
 >> iter 74000, loss: 0.001143
 >> iter 75000, loss: 0.001114
 >> iter 76000, loss: 0.001101
 >> iter 77000, loss: 0.001078
 >> iter 78000, loss: 0.001065
 >> iter 79000, loss: 0.001043
 >> iter 80000, loss: 0.001030
   Number of active neurons: 10
 >> iter 81000, loss: 0.001015
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

