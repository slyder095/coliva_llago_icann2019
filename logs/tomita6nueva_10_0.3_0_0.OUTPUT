 > Problema: tomita6nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.3
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.677543
 >> iter 2000, loss: 15.125317
 >> iter 3000, loss: 13.771976
 >> iter 4000, loss: 13.280935
 >> iter 5000, loss: 13.086252
 >> iter 6000, loss: 13.005696
 >> iter 7000, loss: 12.968368
 >> iter 8000, loss: 12.958261
 >> iter 9000, loss: 12.951443
 >> iter 10000, loss: 12.957478
   Number of active neurons: 7
 >> iter 11000, loss: 12.951254
 >> iter 12000, loss: 12.957553
 >> iter 13000, loss: 12.942291
 >> iter 14000, loss: 12.955751
 >> iter 15000, loss: 12.942954
 >> iter 16000, loss: 12.942689
 >> iter 17000, loss: 12.294151
 >> iter 18000, loss: 10.462003
 >> iter 19000, loss: 5.088325
 >> iter 20000, loss: 1.928883
   Number of active neurons: 10
 >> iter 21000, loss: 0.741677
 >> iter 22000, loss: 0.453509
 >> iter 23000, loss: 0.183933
 >> iter 24000, loss: 0.078974
 >> iter 25000, loss: 0.038897
 >> iter 26000, loss: 0.026797
 >> iter 27000, loss: 0.016282
 >> iter 28000, loss: 0.248243
 >> iter 29000, loss: 0.103235
 >> iter 30000, loss: 0.086577
   Number of active neurons: 10
 >> iter 31000, loss: 0.038526
 >> iter 32000, loss: 0.019949
 >> iter 33000, loss: 0.011985
 >> iter 34000, loss: 0.008182
 >> iter 35000, loss: 0.006456
 >> iter 36000, loss: 0.011658
 >> iter 37000, loss: 0.007136
 >> iter 38000, loss: 0.005296
 >> iter 39000, loss: 0.004528
 >> iter 40000, loss: 0.004020
   Number of active neurons: 10
 >> iter 41000, loss: 0.003526
 >> iter 42000, loss: 0.003264
 >> iter 43000, loss: 0.003154
 >> iter 44000, loss: 0.155861
 >> iter 45000, loss: 0.061018
 >> iter 46000, loss: 0.025300
 >> iter 47000, loss: 0.011882
 >> iter 48000, loss: 0.006811
 >> iter 49000, loss: 0.004718
 >> iter 50000, loss: 0.003888
   Number of active neurons: 10
 >> iter 51000, loss: 0.003370
 >> iter 52000, loss: 0.002951
 >> iter 53000, loss: 0.003057
 >> iter 54000, loss: 0.002742
 >> iter 55000, loss: 0.002510
 >> iter 56000, loss: 0.002370
 >> iter 57000, loss: 0.002247
 >> iter 58000, loss: 0.002115
 >> iter 59000, loss: 0.002031
 >> iter 60000, loss: 0.001962
   Number of active neurons: 10
 >> iter 61000, loss: 0.048372
 >> iter 62000, loss: 0.019866
 >> iter 63000, loss: 0.008912
 >> iter 64000, loss: 0.004690
 >> iter 65000, loss: 0.003162
 >> iter 66000, loss: 0.002360
 >> iter 67000, loss: 0.004609
 >> iter 68000, loss: 0.003208
 >> iter 69000, loss: 0.002365
 >> iter 70000, loss: 0.001980
   Number of active neurons: 10
 >> iter 71000, loss: 0.001953
 >> iter 72000, loss: 0.001750
 >> iter 73000, loss: 0.001622
 >> iter 74000, loss: 0.001583
 >> iter 75000, loss: 0.001470
 >> iter 76000, loss: 0.001421
 >> iter 77000, loss: 0.001343
 >> iter 78000, loss: 0.001300
 >> iter 79000, loss: 0.001266
 >> iter 80000, loss: 0.001245
   Number of active neurons: 10
 >> iter 81000, loss: 0.001223
 >> iter 82000, loss: 0.001207
 >> iter 83000, loss: 0.001152
 >> iter 84000, loss: 0.001120
 >> iter 85000, loss: 0.001283
 >> iter 86000, loss: 0.001233
 >> iter 87000, loss: 0.012920
 >> iter 88000, loss: 0.005783
 >> iter 89000, loss: 0.003101
 >> iter 90000, loss: 0.001990
   Number of active neurons: 10
 >> iter 91000, loss: 0.003584
 >> iter 92000, loss: 0.002301
 >> iter 93000, loss: 0.001692
 >> iter 94000, loss: 0.001606
 >> iter 95000, loss: 0.009192
 >> iter 96000, loss: 0.004606
 >> iter 97000, loss: 0.002686
 >> iter 98000, loss: 0.001873
 >> iter 99000, loss: 0.001472
 >> iter 100000, loss: 0.001317
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.684093
 >> iter 2000, loss: 15.168626
 >> iter 3000, loss: 13.815717
 >> iter 4000, loss: 13.299290
 >> iter 5000, loss: 13.093336
 >> iter 6000, loss: 13.015117
 >> iter 7000, loss: 12.974311
 >> iter 8000, loss: 12.963438
 >> iter 9000, loss: 12.886238
 >> iter 10000, loss: 12.528758
   Number of active neurons: 9
 >> iter 11000, loss: 10.987010
 >> iter 12000, loss: 6.964562
 >> iter 13000, loss: 2.832990
 >> iter 14000, loss: 1.254088
 >> iter 15000, loss: 0.563717
 >> iter 16000, loss: 0.426021
 >> iter 17000, loss: 0.201543
 >> iter 18000, loss: 0.526962
 >> iter 19000, loss: 0.309195
 >> iter 20000, loss: 0.168785
   Number of active neurons: 10
 >> iter 21000, loss: 0.071525
 >> iter 22000, loss: 0.141046
 >> iter 23000, loss: 0.066230
 >> iter 24000, loss: 0.031048
 >> iter 25000, loss: 0.021245
 >> iter 26000, loss: 0.012942
 >> iter 27000, loss: 0.019976
 >> iter 28000, loss: 0.012593
 >> iter 29000, loss: 0.008113
 >> iter 30000, loss: 0.017068
   Number of active neurons: 10
 >> iter 31000, loss: 0.120039
 >> iter 32000, loss: 0.049101
 >> iter 33000, loss: 0.188050
 >> iter 34000, loss: 0.078698
 >> iter 35000, loss: 0.033605
 >> iter 36000, loss: 0.061752
 >> iter 37000, loss: 0.028713
 >> iter 38000, loss: 0.013748
 >> iter 39000, loss: 0.015922
 >> iter 40000, loss: 0.175521
   Number of active neurons: 10
 >> iter 41000, loss: 0.088261
 >> iter 42000, loss: 0.036253
 >> iter 43000, loss: 0.016390
 >> iter 44000, loss: 0.008809
 >> iter 45000, loss: 0.005724
 >> iter 46000, loss: 0.004359
 >> iter 47000, loss: 0.003675
 >> iter 48000, loss: 0.003293
 >> iter 49000, loss: 0.003088
 >> iter 50000, loss: 0.002969
   Number of active neurons: 10
 >> iter 51000, loss: 0.002711
 >> iter 52000, loss: 0.002533
 >> iter 53000, loss: 0.002372
 >> iter 54000, loss: 0.002442
 >> iter 55000, loss: 0.002582
 >> iter 56000, loss: 0.002619
 >> iter 57000, loss: 0.002227
 >> iter 58000, loss: 0.002015
 >> iter 59000, loss: 0.001906
 >> iter 60000, loss: 0.001800
   Number of active neurons: 10
 >> iter 61000, loss: 0.001804
 >> iter 62000, loss: 0.001692
 >> iter 63000, loss: 0.001967
 >> iter 64000, loss: 0.001773
 >> iter 65000, loss: 0.001711
 >> iter 66000, loss: 0.001589
 >> iter 67000, loss: 0.001920
 >> iter 68000, loss: 0.001933
 >> iter 69000, loss: 0.001771
 >> iter 70000, loss: 0.001600
   Number of active neurons: 10
 >> iter 71000, loss: 0.001487
 >> iter 72000, loss: 0.001404
 >> iter 73000, loss: 0.001377
 >> iter 74000, loss: 0.001322
 >> iter 75000, loss: 0.001253
 >> iter 76000, loss: 0.001235
 >> iter 77000, loss: 0.001228
 >> iter 78000, loss: 0.001164
 >> iter 79000, loss: 0.001136
 >> iter 80000, loss: 0.072291
   Number of active neurons: 10
 >> iter 81000, loss: 0.070856
 >> iter 82000, loss: 0.027178
 >> iter 83000, loss: 0.010977
 >> iter 84000, loss: 0.004946
 >> iter 85000, loss: 0.002712
 >> iter 86000, loss: 0.001848
 >> iter 87000, loss: 0.012777
 >> iter 88000, loss: 0.005715
 >> iter 89000, loss: 0.003010
 >> iter 90000, loss: 0.002223
   Number of active neurons: 10
 >> iter 91000, loss: 0.063958
 >> iter 92000, loss: 0.149595
 >> iter 93000, loss: 0.059124
 >> iter 94000, loss: 0.023133
 >> iter 95000, loss: 0.009786
 >> iter 96000, loss: 0.004800
 >> iter 97000, loss: 0.002825
 >> iter 98000, loss: 0.002965
 >> iter 99000, loss: 0.002159
 >> iter 100000, loss: 0.001768
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.661227
 >> iter 2000, loss: 15.104039
 >> iter 3000, loss: 13.766141
 >> iter 4000, loss: 13.261547
 >> iter 5000, loss: 13.057100
 >> iter 6000, loss: 12.991302
 >> iter 7000, loss: 12.954755
 >> iter 8000, loss: 12.951165
 >> iter 9000, loss: 12.938550
 >> iter 10000, loss: 12.942326
   Number of active neurons: 5
 >> iter 11000, loss: 12.924137
 >> iter 12000, loss: 12.696503
 >> iter 13000, loss: 11.930310
 >> iter 14000, loss: 10.079063
 >> iter 15000, loss: 5.437039
 >> iter 16000, loss: 2.092924
 >> iter 17000, loss: 0.934804
 >> iter 18000, loss: 0.365574
 >> iter 19000, loss: 0.150106
 >> iter 20000, loss: 0.190022
   Number of active neurons: 10
 >> iter 21000, loss: 0.154152
 >> iter 22000, loss: 0.069442
 >> iter 23000, loss: 0.034401
 >> iter 24000, loss: 0.020827
 >> iter 25000, loss: 0.015783
 >> iter 26000, loss: 0.011495
 >> iter 27000, loss: 0.009415
 >> iter 28000, loss: 0.008235
 >> iter 29000, loss: 0.006919
 >> iter 30000, loss: 0.006292
   Number of active neurons: 10
 >> iter 31000, loss: 0.005704
 >> iter 32000, loss: 0.005195
 >> iter 33000, loss: 0.004774
 >> iter 34000, loss: 0.004205
 >> iter 35000, loss: 0.003991
 >> iter 36000, loss: 0.003679
 >> iter 37000, loss: 0.003461
 >> iter 38000, loss: 0.003486
 >> iter 39000, loss: 0.003206
 >> iter 40000, loss: 0.014662
   Number of active neurons: 10
 >> iter 41000, loss: 0.008014
 >> iter 42000, loss: 0.004851
 >> iter 43000, loss: 0.003432
 >> iter 44000, loss: 0.002842
 >> iter 45000, loss: 0.002516
 >> iter 46000, loss: 0.002343
 >> iter 47000, loss: 0.002977
 >> iter 48000, loss: 0.005430
 >> iter 49000, loss: 0.004027
 >> iter 50000, loss: 0.002830
   Number of active neurons: 10
 >> iter 51000, loss: 0.002321
 >> iter 52000, loss: 0.002015
 >> iter 53000, loss: 0.004872
 >> iter 54000, loss: 0.002927
 >> iter 55000, loss: 0.002497
 >> iter 56000, loss: 0.001892
 >> iter 57000, loss: 0.001690
 >> iter 58000, loss: 0.001584
 >> iter 59000, loss: 0.001554
 >> iter 60000, loss: 0.028855
   Number of active neurons: 10
 >> iter 61000, loss: 0.011731
 >> iter 62000, loss: 0.005483
 >> iter 63000, loss: 0.002976
 >> iter 64000, loss: 0.002015
 >> iter 65000, loss: 0.001596
 >> iter 66000, loss: 0.001526
 >> iter 67000, loss: 0.001380
 >> iter 68000, loss: 0.001346
 >> iter 69000, loss: 0.001290
 >> iter 70000, loss: 0.001207
   Number of active neurons: 10
 >> iter 71000, loss: 0.001175
 >> iter 72000, loss: 0.085512
 >> iter 73000, loss: 0.051251
 >> iter 74000, loss: 0.020046
 >> iter 75000, loss: 0.064112
 >> iter 76000, loss: 0.024824
 >> iter 77000, loss: 0.010223
 >> iter 78000, loss: 0.004888
 >> iter 79000, loss: 0.002727
 >> iter 80000, loss: 0.001905
   Number of active neurons: 10
 >> iter 81000, loss: 0.001557
 >> iter 82000, loss: 0.001422
 >> iter 83000, loss: 0.001353
 >> iter 84000, loss: 0.001332
 >> iter 85000, loss: 0.001278
 >> iter 86000, loss: 0.001359
 >> iter 87000, loss: 0.001534
 >> iter 88000, loss: 0.001269
 >> iter 89000, loss: 0.001245
 >> iter 90000, loss: 0.001119
   Number of active neurons: 10
 >> iter 91000, loss: 0.001132
 >> iter 92000, loss: 0.001046
 >> iter 93000, loss: 0.001069
 >> iter 94000, loss: 0.001013
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.667277
 >> iter 2000, loss: 15.164173
 >> iter 3000, loss: 13.818317
 >> iter 4000, loss: 13.311929
 >> iter 5000, loss: 13.109985
 >> iter 6000, loss: 13.028291
 >> iter 7000, loss: 12.993772
 >> iter 8000, loss: 12.989889
 >> iter 9000, loss: 12.980906
 >> iter 10000, loss: 12.982292
   Number of active neurons: 8
 >> iter 11000, loss: 12.973838
 >> iter 12000, loss: 12.974911
 >> iter 13000, loss: 12.965710
 >> iter 14000, loss: 12.977453
 >> iter 15000, loss: 12.968111
 >> iter 16000, loss: 12.967093
 >> iter 17000, loss: 12.961340
 >> iter 18000, loss: 12.968134
 >> iter 19000, loss: 12.959784
 >> iter 20000, loss: 12.970983
   Number of active neurons: 7
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 7
 >> iter 21000, loss: 12.956685
 >> iter 22000, loss: 12.965159
 >> iter 23000, loss: 12.826898
 >> iter 24000, loss: 10.333191
 >> iter 25000, loss: 4.542010
 >> iter 26000, loss: 1.868314
 >> iter 27000, loss: 0.826219
 >> iter 28000, loss: 0.333621
 >> iter 29000, loss: 0.145625
 >> iter 30000, loss: 0.070495
   Number of active neurons: 10
 >> iter 31000, loss: 0.039691
 >> iter 32000, loss: 0.028691
 >> iter 33000, loss: 0.021312
 >> iter 34000, loss: 0.143389
 >> iter 35000, loss: 0.063462
 >> iter 36000, loss: 0.033746
 >> iter 37000, loss: 0.019853
 >> iter 38000, loss: 0.024631
 >> iter 39000, loss: 0.016657
 >> iter 40000, loss: 0.012157
   Number of active neurons: 10
 >> iter 41000, loss: 0.070954
 >> iter 42000, loss: 0.032889
 >> iter 43000, loss: 0.017198
 >> iter 44000, loss: 0.011176
 >> iter 45000, loss: 0.008458
 >> iter 46000, loss: 0.007199
 >> iter 47000, loss: 0.006511
 >> iter 48000, loss: 0.006053
 >> iter 49000, loss: 0.005628
 >> iter 50000, loss: 0.005383
   Number of active neurons: 10
 >> iter 51000, loss: 0.005107
 >> iter 52000, loss: 0.005338
 >> iter 53000, loss: 0.004974
 >> iter 54000, loss: 0.025495
 >> iter 55000, loss: 0.012279
 >> iter 56000, loss: 0.060998
 >> iter 57000, loss: 0.025247
 >> iter 58000, loss: 0.011990
 >> iter 59000, loss: 0.006941
 >> iter 60000, loss: 0.004958
   Number of active neurons: 10
 >> iter 61000, loss: 0.004110
 >> iter 62000, loss: 0.003771
 >> iter 63000, loss: 0.003527
 >> iter 64000, loss: 0.003397
 >> iter 65000, loss: 0.003877
 >> iter 66000, loss: 0.003726
 >> iter 67000, loss: 0.003381
 >> iter 68000, loss: 0.003172
 >> iter 69000, loss: 0.097605
 >> iter 70000, loss: 0.037996
   Number of active neurons: 10
 >> iter 71000, loss: 0.015969
 >> iter 72000, loss: 0.007761
 >> iter 73000, loss: 0.004677
 >> iter 74000, loss: 0.003770
 >> iter 75000, loss: 0.003268
 >> iter 76000, loss: 0.003110
 >> iter 77000, loss: 0.068886
 >> iter 78000, loss: 0.093607
 >> iter 79000, loss: 0.061760
 >> iter 80000, loss: 0.045611
   Number of active neurons: 10
 >> iter 81000, loss: 0.019992
 >> iter 82000, loss: 0.009474
 >> iter 83000, loss: 0.005366
 >> iter 84000, loss: 0.004000
 >> iter 85000, loss: 0.003189
 >> iter 86000, loss: 0.003003
 >> iter 87000, loss: 0.002915
 >> iter 88000, loss: 0.003159
 >> iter 89000, loss: 0.002695
 >> iter 90000, loss: 0.002454
   Number of active neurons: 10
 >> iter 91000, loss: 0.002309
 >> iter 92000, loss: 0.002245
 >> iter 93000, loss: 0.002180
 >> iter 94000, loss: 0.002146
 >> iter 95000, loss: 0.002088
 >> iter 96000, loss: 0.002025
 >> iter 97000, loss: 0.002004
 >> iter 98000, loss: 0.001968
 >> iter 99000, loss: 0.001905
 >> iter 100000, loss: 0.001898
   Number of active neurons: 10
 >> iter 101000, loss: 0.001831
 >> iter 102000, loss: 0.024030
 >> iter 103000, loss: 0.253952
 >> iter 104000, loss: 0.095770
 >> iter 105000, loss: 0.036923
 >> iter 106000, loss: 0.015181
 >> iter 107000, loss: 0.007075
 >> iter 108000, loss: 0.004040
 >> iter 109000, loss: 0.002839
 >> iter 110000, loss: 0.002362
   Number of active neurons: 10
 >> iter 111000, loss: 0.002679
 >> iter 112000, loss: 0.002384
 >> iter 113000, loss: 0.002110
 >> iter 114000, loss: 0.001975
 >> iter 115000, loss: 0.066638
 >> iter 116000, loss: 0.025882
 >> iter 117000, loss: 0.010784
 >> iter 118000, loss: 0.005186
 >> iter 119000, loss: 0.003066
 >> iter 120000, loss: 0.002266
   Number of active neurons: 10
 >> iter 121000, loss: 0.001924
 >> iter 122000, loss: 0.001789
 >> iter 123000, loss: 0.001728
 >> iter 124000, loss: 0.001697
 >> iter 125000, loss: 0.001632
 >> iter 126000, loss: 0.001610
 >> iter 127000, loss: 0.001579
 >> iter 128000, loss: 0.001574
 >> iter 129000, loss: 0.001519
 >> iter 130000, loss: 0.001493
   Number of active neurons: 10
 >> iter 131000, loss: 0.001489
 >> iter 132000, loss: 0.001461
 >> iter 133000, loss: 0.001427
 >> iter 134000, loss: 0.001417
 >> iter 135000, loss: 0.001387
 >> iter 136000, loss: 0.001358
 >> iter 137000, loss: 0.001335
 >> iter 138000, loss: 0.001341
 >> iter 139000, loss: 0.001308
 >> iter 140000, loss: 0.001297
   Number of active neurons: 10
 >> iter 141000, loss: 0.001278
 >> iter 142000, loss: 0.001258
 >> iter 143000, loss: 0.001234
 >> iter 144000, loss: 0.001254
 >> iter 145000, loss: 0.001221
 >> iter 146000, loss: 0.001200
 >> iter 147000, loss: 0.001184
 >> iter 148000, loss: 0.001171
 >> iter 149000, loss: 0.001155
 >> iter 150000, loss: 0.001140
   Number of active neurons: 10
 >> iter 151000, loss: 0.001129
 >> iter 152000, loss: 0.001130
 >> iter 153000, loss: 0.001101
 >> iter 154000, loss: 0.001090
 >> iter 155000, loss: 0.001077
 >> iter 156000, loss: 0.001069
 >> iter 157000, loss: 0.001056
 >> iter 158000, loss: 0.001048
 >> iter 159000, loss: 0.001034
 >> iter 160000, loss: 0.001025
   Number of active neurons: 10
 >> iter 161000, loss: 0.001008
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.665602
 >> iter 2000, loss: 15.181950
 >> iter 3000, loss: 13.830609
 >> iter 4000, loss: 13.318846
 >> iter 5000, loss: 13.106608
 >> iter 6000, loss: 13.031689
 >> iter 7000, loss: 13.003403
 >> iter 8000, loss: 12.999595
 >> iter 9000, loss: 12.971366
 >> iter 10000, loss: 12.970951
   Number of active neurons: 7
 >> iter 11000, loss: 12.967446
 >> iter 12000, loss: 12.962491
 >> iter 13000, loss: 12.946384
 >> iter 14000, loss: 12.909481
 >> iter 15000, loss: 12.591775
 >> iter 16000, loss: 11.502713
 >> iter 17000, loss: 9.050829
 >> iter 18000, loss: 3.472901
 >> iter 19000, loss: 1.310504
 >> iter 20000, loss: 0.502704
   Number of active neurons: 10
 >> iter 21000, loss: 0.200240
 >> iter 22000, loss: 0.085581
 >> iter 23000, loss: 0.041447
 >> iter 24000, loss: 0.024130
 >> iter 25000, loss: 0.016395
 >> iter 26000, loss: 0.012796
 >> iter 27000, loss: 0.010559
 >> iter 28000, loss: 0.009144
 >> iter 29000, loss: 0.008346
 >> iter 30000, loss: 0.007494
   Number of active neurons: 10
 >> iter 31000, loss: 0.017055
 >> iter 32000, loss: 0.010554
 >> iter 33000, loss: 0.007598
 >> iter 34000, loss: 0.006360
 >> iter 35000, loss: 0.005569
 >> iter 36000, loss: 0.005073
 >> iter 37000, loss: 0.004671
 >> iter 38000, loss: 0.004412
 >> iter 39000, loss: 0.004136
 >> iter 40000, loss: 0.004009
   Number of active neurons: 10
 >> iter 41000, loss: 0.003824
 >> iter 42000, loss: 0.003581
 >> iter 43000, loss: 0.003382
 >> iter 44000, loss: 0.332098
 >> iter 45000, loss: 0.126948
 >> iter 46000, loss: 0.049839
 >> iter 47000, loss: 0.021158
 >> iter 48000, loss: 0.010349
 >> iter 49000, loss: 0.006220
 >> iter 50000, loss: 0.004620
   Number of active neurons: 10
 >> iter 51000, loss: 0.013937
 >> iter 52000, loss: 0.011004
 >> iter 53000, loss: 0.006618
 >> iter 54000, loss: 0.004653
 >> iter 55000, loss: 0.003777
 >> iter 56000, loss: 0.003279
 >> iter 57000, loss: 0.003015
 >> iter 58000, loss: 0.002847
 >> iter 59000, loss: 0.002700
 >> iter 60000, loss: 0.002610
   Number of active neurons: 10
 >> iter 61000, loss: 0.002529
 >> iter 62000, loss: 0.002426
 >> iter 63000, loss: 0.002289
 >> iter 64000, loss: 0.002217
 >> iter 65000, loss: 0.002115
 >> iter 66000, loss: 0.002083
 >> iter 67000, loss: 0.002012
 >> iter 68000, loss: 0.001943
 >> iter 69000, loss: 0.001890
 >> iter 70000, loss: 0.001821
   Number of active neurons: 10
 >> iter 71000, loss: 0.001783
 >> iter 72000, loss: 0.001754
 >> iter 73000, loss: 0.001703
 >> iter 74000, loss: 0.002185
 >> iter 75000, loss: 0.001893
 >> iter 76000, loss: 0.001762
 >> iter 77000, loss: 0.001692
 >> iter 78000, loss: 0.001603
 >> iter 79000, loss: 0.001572
 >> iter 80000, loss: 0.001518
   Number of active neurons: 10
 >> iter 81000, loss: 0.001465
 >> iter 82000, loss: 0.001487
 >> iter 83000, loss: 0.001424
 >> iter 84000, loss: 0.001376
 >> iter 85000, loss: 0.001322
 >> iter 86000, loss: 0.001291
 >> iter 87000, loss: 0.001268
 >> iter 88000, loss: 0.001283
 >> iter 89000, loss: 0.001234
 >> iter 90000, loss: 0.001219
   Number of active neurons: 10
 >> iter 91000, loss: 0.001199
 >> iter 92000, loss: 0.001182
 >> iter 93000, loss: 0.001145
 >> iter 94000, loss: 0.001122
 >> iter 95000, loss: 0.001099
 >> iter 96000, loss: 0.001078
 >> iter 97000, loss: 0.001054
 >> iter 98000, loss: 0.001097
 >> iter 99000, loss: 0.001049
 >> iter 100000, loss: 0.001038
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.652764
 >> iter 2000, loss: 15.147014
 >> iter 3000, loss: 13.797691
 >> iter 4000, loss: 13.289907
 >> iter 5000, loss: 13.082508
 >> iter 6000, loss: 13.012244
 >> iter 7000, loss: 12.968167
 >> iter 8000, loss: 12.960231
 >> iter 9000, loss: 12.943688
 >> iter 10000, loss: 12.947546
   Number of active neurons: 7
 >> iter 11000, loss: 12.932967
 >> iter 12000, loss: 12.939674
 >> iter 13000, loss: 12.896572
 >> iter 14000, loss: 12.255644
 >> iter 15000, loss: 10.663188
 >> iter 16000, loss: 5.228495
 >> iter 17000, loss: 2.018725
 >> iter 18000, loss: 0.792387
 >> iter 19000, loss: 0.318427
 >> iter 20000, loss: 0.136333
   Number of active neurons: 10
 >> iter 21000, loss: 0.064343
 >> iter 22000, loss: 0.238736
 >> iter 23000, loss: 0.243756
 >> iter 24000, loss: 0.103088
 >> iter 25000, loss: 0.046952
 >> iter 26000, loss: 0.024422
 >> iter 27000, loss: 0.022615
 >> iter 28000, loss: 0.013840
 >> iter 29000, loss: 0.009644
 >> iter 30000, loss: 0.007776
   Number of active neurons: 10
 >> iter 31000, loss: 0.006428
 >> iter 32000, loss: 0.008310
 >> iter 33000, loss: 0.006176
 >> iter 34000, loss: 0.004979
 >> iter 35000, loss: 0.005099
 >> iter 36000, loss: 0.004326
 >> iter 37000, loss: 0.004005
 >> iter 38000, loss: 0.003660
 >> iter 39000, loss: 0.003267
 >> iter 40000, loss: 0.002962
   Number of active neurons: 10
 >> iter 41000, loss: 0.003224
 >> iter 42000, loss: 0.002909
 >> iter 43000, loss: 0.002756
 >> iter 44000, loss: 0.002542
 >> iter 45000, loss: 0.002357
 >> iter 46000, loss: 0.002178
 >> iter 47000, loss: 0.002062
 >> iter 48000, loss: 0.001990
 >> iter 49000, loss: 0.010170
 >> iter 50000, loss: 0.005130
   Number of active neurons: 10
 >> iter 51000, loss: 0.003242
 >> iter 52000, loss: 0.002348
 >> iter 53000, loss: 0.002008
 >> iter 54000, loss: 0.001775
 >> iter 55000, loss: 0.001980
 >> iter 56000, loss: 0.089753
 >> iter 57000, loss: 0.034497
 >> iter 58000, loss: 0.025052
 >> iter 59000, loss: 0.010862
 >> iter 60000, loss: 0.005289
   Number of active neurons: 10
 >> iter 61000, loss: 0.003066
 >> iter 62000, loss: 0.015856
 >> iter 63000, loss: 0.006921
 >> iter 64000, loss: 0.003508
 >> iter 65000, loss: 0.002223
 >> iter 66000, loss: 0.001678
 >> iter 67000, loss: 0.001566
 >> iter 68000, loss: 0.001340
 >> iter 69000, loss: 0.001283
 >> iter 70000, loss: 0.001163
   Number of active neurons: 10
 >> iter 71000, loss: 0.001172
 >> iter 72000, loss: 0.001119
 >> iter 73000, loss: 0.001139
 >> iter 74000, loss: 0.001136
 >> iter 75000, loss: 0.001071
 >> iter 76000, loss: 0.001026
 >> iter 77000, loss: 0.001031
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.702288
 >> iter 2000, loss: 15.168008
 >> iter 3000, loss: 13.807040
 >> iter 4000, loss: 13.302910
 >> iter 5000, loss: 13.107492
 >> iter 6000, loss: 13.044980
 >> iter 7000, loss: 13.005615
 >> iter 8000, loss: 12.998545
 >> iter 9000, loss: 12.990954
 >> iter 10000, loss: 13.000531
   Number of active neurons: 8
 >> iter 11000, loss: 12.986844
 >> iter 12000, loss: 12.997638
 >> iter 13000, loss: 12.988173
 >> iter 14000, loss: 12.997971
 >> iter 15000, loss: 12.992093
 >> iter 16000, loss: 13.000220
 >> iter 17000, loss: 12.992546
 >> iter 18000, loss: 12.994466
 >> iter 19000, loss: 12.987199
 >> iter 20000, loss: 12.999965
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 8
 >> iter 21000, loss: 12.986672
 >> iter 22000, loss: 12.996825
 >> iter 23000, loss: 12.978293
 >> iter 24000, loss: 12.707781
 >> iter 25000, loss: 10.690866
 >> iter 26000, loss: 4.840179
 >> iter 27000, loss: 1.937524
 >> iter 28000, loss: 0.841032
 >> iter 29000, loss: 0.336140
 >> iter 30000, loss: 0.142517
   Number of active neurons: 10
 >> iter 31000, loss: 0.067357
 >> iter 32000, loss: 0.042383
 >> iter 33000, loss: 0.027901
 >> iter 34000, loss: 0.027584
 >> iter 35000, loss: 0.018967
 >> iter 36000, loss: 0.014727
 >> iter 37000, loss: 0.089315
 >> iter 38000, loss: 0.040552
 >> iter 39000, loss: 0.022089
 >> iter 40000, loss: 0.014167
   Number of active neurons: 10
 >> iter 41000, loss: 0.010286
 >> iter 42000, loss: 0.010945
 >> iter 43000, loss: 0.008756
 >> iter 44000, loss: 0.007446
 >> iter 45000, loss: 0.006882
 >> iter 46000, loss: 0.006269
 >> iter 47000, loss: 0.019103
 >> iter 48000, loss: 0.010823
 >> iter 49000, loss: 0.007322
 >> iter 50000, loss: 0.005783
   Number of active neurons: 10
 >> iter 51000, loss: 0.005035
 >> iter 52000, loss: 0.006331
 >> iter 53000, loss: 0.005294
 >> iter 54000, loss: 0.005670
 >> iter 55000, loss: 0.004757
 >> iter 56000, loss: 0.004281
 >> iter 57000, loss: 0.005407
 >> iter 58000, loss: 0.031801
 >> iter 59000, loss: 0.014166
 >> iter 60000, loss: 0.007489
   Number of active neurons: 10
 >> iter 61000, loss: 0.005679
 >> iter 62000, loss: 0.004411
 >> iter 63000, loss: 0.003753
 >> iter 64000, loss: 0.003424
 >> iter 65000, loss: 0.003180
 >> iter 66000, loss: 0.003163
 >> iter 67000, loss: 0.002947
 >> iter 68000, loss: 0.002821
 >> iter 69000, loss: 0.002743
 >> iter 70000, loss: 0.002599
   Number of active neurons: 10
 >> iter 71000, loss: 0.002534
 >> iter 72000, loss: 0.002495
 >> iter 73000, loss: 0.002399
 >> iter 74000, loss: 0.002318
 >> iter 75000, loss: 0.002265
 >> iter 76000, loss: 0.002228
 >> iter 77000, loss: 0.002159
 >> iter 78000, loss: 0.002110
 >> iter 79000, loss: 0.002052
 >> iter 80000, loss: 0.002011
   Number of active neurons: 10
 >> iter 81000, loss: 0.001971
 >> iter 82000, loss: 0.001991
 >> iter 83000, loss: 0.001923
 >> iter 84000, loss: 0.001861
 >> iter 85000, loss: 0.001820
 >> iter 86000, loss: 0.001803
 >> iter 87000, loss: 0.001761
 >> iter 88000, loss: 0.001757
 >> iter 89000, loss: 0.001754
 >> iter 90000, loss: 0.001683
   Number of active neurons: 10
 >> iter 91000, loss: 0.001668
 >> iter 92000, loss: 0.001626
 >> iter 93000, loss: 0.001608
 >> iter 94000, loss: 0.001621
 >> iter 95000, loss: 0.001607
 >> iter 96000, loss: 0.001569
 >> iter 97000, loss: 0.001525
 >> iter 98000, loss: 0.001476
 >> iter 99000, loss: 0.001475
 >> iter 100000, loss: 0.001457
   Number of active neurons: 10
 >> iter 101000, loss: 0.001447
 >> iter 102000, loss: 0.001414
 >> iter 103000, loss: 0.001384
 >> iter 104000, loss: 0.001408
 >> iter 105000, loss: 0.001386
 >> iter 106000, loss: 0.001332
 >> iter 107000, loss: 0.001374
 >> iter 108000, loss: 0.001331
 >> iter 109000, loss: 0.001326
 >> iter 110000, loss: 0.001294
   Number of active neurons: 10
 >> iter 111000, loss: 0.001252
 >> iter 112000, loss: 0.001226
 >> iter 113000, loss: 0.001205
 >> iter 114000, loss: 0.001204
 >> iter 115000, loss: 0.001208
 >> iter 116000, loss: 0.001172
 >> iter 117000, loss: 0.001150
 >> iter 118000, loss: 0.001140
 >> iter 119000, loss: 0.001127
 >> iter 120000, loss: 0.001142
   Number of active neurons: 10
 >> iter 121000, loss: 0.001112
 >> iter 122000, loss: 0.001102
 >> iter 123000, loss: 0.001091
 >> iter 124000, loss: 0.001063
 >> iter 125000, loss: 0.001064
 >> iter 126000, loss: 0.001057
 >> iter 127000, loss: 0.001041
 >> iter 128000, loss: 0.001021
 >> iter 129000, loss: 0.001041
 >> iter 130000, loss: 0.001033
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.678575
 >> iter 2000, loss: 15.190011
 >> iter 3000, loss: 13.849324
 >> iter 4000, loss: 13.333626
 >> iter 5000, loss: 13.123018
 >> iter 6000, loss: 13.044463
 >> iter 7000, loss: 13.010467
 >> iter 8000, loss: 13.004350
 >> iter 9000, loss: 12.984723
 >> iter 10000, loss: 12.996627
   Number of active neurons: 9
 >> iter 11000, loss: 12.982393
 >> iter 12000, loss: 12.983861
 >> iter 13000, loss: 12.977325
 >> iter 14000, loss: 12.978623
 >> iter 15000, loss: 12.965121
 >> iter 16000, loss: 12.975168
 >> iter 17000, loss: 12.965028
 >> iter 18000, loss: 12.966962
 >> iter 19000, loss: 12.947141
 >> iter 20000, loss: 12.934398
   Number of active neurons: 10
 >> iter 21000, loss: 12.860715
 >> iter 22000, loss: 10.633687
 >> iter 23000, loss: 4.065611
 >> iter 24000, loss: 1.563135
 >> iter 25000, loss: 0.605118
 >> iter 26000, loss: 0.263801
 >> iter 27000, loss: 0.114164
 >> iter 28000, loss: 0.055501
 >> iter 29000, loss: 0.030012
 >> iter 30000, loss: 0.018749
   Number of active neurons: 10
 >> iter 31000, loss: 0.014019
 >> iter 32000, loss: 0.011422
 >> iter 33000, loss: 0.028977
 >> iter 34000, loss: 0.137357
 >> iter 35000, loss: 0.058256
 >> iter 36000, loss: 0.026349
 >> iter 37000, loss: 0.061250
 >> iter 38000, loss: 0.027154
 >> iter 39000, loss: 0.013846
 >> iter 40000, loss: 0.044346
   Number of active neurons: 10
 >> iter 41000, loss: 0.022383
 >> iter 42000, loss: 0.011847
 >> iter 43000, loss: 0.007460
 >> iter 44000, loss: 0.005998
 >> iter 45000, loss: 0.057930
 >> iter 46000, loss: 0.024116
 >> iter 47000, loss: 0.011293
 >> iter 48000, loss: 0.006277
 >> iter 49000, loss: 0.004337
 >> iter 50000, loss: 0.003591
   Number of active neurons: 10
 >> iter 51000, loss: 0.003068
 >> iter 52000, loss: 0.002850
 >> iter 53000, loss: 0.002669
 >> iter 54000, loss: 0.002563
 >> iter 55000, loss: 0.002429
 >> iter 56000, loss: 0.002318
 >> iter 57000, loss: 0.002158
 >> iter 58000, loss: 0.002170
 >> iter 59000, loss: 0.002081
 >> iter 60000, loss: 0.002107
   Number of active neurons: 10
 >> iter 61000, loss: 0.002020
 >> iter 62000, loss: 0.001939
 >> iter 63000, loss: 0.001875
 >> iter 64000, loss: 0.001772
 >> iter 65000, loss: 0.001746
 >> iter 66000, loss: 0.001680
 >> iter 67000, loss: 0.001659
 >> iter 68000, loss: 0.001588
 >> iter 69000, loss: 0.001515
 >> iter 70000, loss: 0.001488
   Number of active neurons: 10
 >> iter 71000, loss: 0.001524
 >> iter 72000, loss: 0.001436
 >> iter 73000, loss: 0.001422
 >> iter 74000, loss: 0.001356
 >> iter 75000, loss: 0.001330
 >> iter 76000, loss: 0.001298
 >> iter 77000, loss: 0.001264
 >> iter 78000, loss: 0.001234
 >> iter 79000, loss: 0.001355
 >> iter 80000, loss: 0.001314
   Number of active neurons: 10
 >> iter 81000, loss: 0.001195
 >> iter 82000, loss: 0.001174
 >> iter 83000, loss: 0.001137
 >> iter 84000, loss: 0.001085
 >> iter 85000, loss: 0.001077
 >> iter 86000, loss: 0.001213
 >> iter 87000, loss: 0.001093
 >> iter 88000, loss: 0.001060
 >> iter 89000, loss: 0.001020
 >> iter 90000, loss: 0.001055
   Number of active neurons: 10
 >> iter 91000, loss: 0.001007
 >> iter 92000, loss: 0.001104
 >> iter 93000, loss: 0.001026
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.702182
 >> iter 2000, loss: 15.179389
 >> iter 3000, loss: 13.807352
 >> iter 4000, loss: 13.299608
 >> iter 5000, loss: 13.093109
 >> iter 6000, loss: 13.019625
 >> iter 7000, loss: 12.974867
 >> iter 8000, loss: 12.963859
 >> iter 9000, loss: 12.955160
 >> iter 10000, loss: 12.963409
   Number of active neurons: 5
 >> iter 11000, loss: 12.955272
 >> iter 12000, loss: 12.956436
 >> iter 13000, loss: 12.947993
 >> iter 14000, loss: 12.959366
 >> iter 15000, loss: 12.951676
 >> iter 16000, loss: 12.956348
 >> iter 17000, loss: 12.949729
 >> iter 18000, loss: 12.952405
 >> iter 19000, loss: 12.943600
 >> iter 20000, loss: 12.959620
   Number of active neurons: 6
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 6
 >> iter 21000, loss: 12.947511
 >> iter 22000, loss: 12.951655
 >> iter 23000, loss: 12.715747
 >> iter 24000, loss: 11.059584
 >> iter 25000, loss: 4.391628
 >> iter 26000, loss: 1.672620
 >> iter 27000, loss: 0.646312
 >> iter 28000, loss: 0.273478
 >> iter 29000, loss: 0.117109
 >> iter 30000, loss: 0.056224
   Number of active neurons: 10
 >> iter 31000, loss: 0.031607
 >> iter 32000, loss: 0.020916
 >> iter 33000, loss: 0.015894
 >> iter 34000, loss: 0.013364
 >> iter 35000, loss: 0.011294
 >> iter 36000, loss: 0.009967
 >> iter 37000, loss: 0.053812
 >> iter 38000, loss: 0.025816
 >> iter 39000, loss: 0.014249
 >> iter 40000, loss: 0.011973
   Number of active neurons: 10
 >> iter 41000, loss: 0.009933
 >> iter 42000, loss: 0.007859
 >> iter 43000, loss: 0.007784
 >> iter 44000, loss: 0.006433
 >> iter 45000, loss: 0.005580
 >> iter 46000, loss: 0.005608
 >> iter 47000, loss: 0.005192
 >> iter 48000, loss: 0.004793
 >> iter 49000, loss: 0.004368
 >> iter 50000, loss: 0.004236
   Number of active neurons: 10
 >> iter 51000, loss: 0.004073
 >> iter 52000, loss: 0.003935
 >> iter 53000, loss: 0.004137
 >> iter 54000, loss: 0.003814
 >> iter 55000, loss: 0.003490
 >> iter 56000, loss: 0.003306
 >> iter 57000, loss: 0.003122
 >> iter 58000, loss: 0.003062
 >> iter 59000, loss: 0.002904
 >> iter 60000, loss: 0.003179
   Number of active neurons: 10
 >> iter 61000, loss: 0.002899
 >> iter 62000, loss: 0.002770
 >> iter 63000, loss: 0.006527
 >> iter 64000, loss: 0.004355
 >> iter 65000, loss: 0.003334
 >> iter 66000, loss: 0.005931
 >> iter 67000, loss: 0.005720
 >> iter 68000, loss: 0.004026
 >> iter 69000, loss: 0.003092
 >> iter 70000, loss: 0.002688
   Number of active neurons: 10
 >> iter 71000, loss: 0.002464
 >> iter 72000, loss: 0.002353
 >> iter 73000, loss: 0.002337
 >> iter 74000, loss: 0.002227
 >> iter 75000, loss: 0.002061
 >> iter 76000, loss: 0.001999
 >> iter 77000, loss: 0.001890
 >> iter 78000, loss: 0.001875
 >> iter 79000, loss: 0.001807
 >> iter 80000, loss: 0.001751
   Number of active neurons: 10
 >> iter 81000, loss: 0.001753
 >> iter 82000, loss: 0.001723
 >> iter 83000, loss: 0.001646
 >> iter 84000, loss: 0.001620
 >> iter 85000, loss: 0.001619
 >> iter 86000, loss: 0.001576
 >> iter 87000, loss: 0.001512
 >> iter 88000, loss: 0.001480
 >> iter 89000, loss: 0.001435
 >> iter 90000, loss: 0.001606
   Number of active neurons: 10
 >> iter 91000, loss: 0.001456
 >> iter 92000, loss: 0.001544
 >> iter 93000, loss: 0.001422
 >> iter 94000, loss: 0.001404
 >> iter 95000, loss: 0.001786
 >> iter 96000, loss: 0.001707
 >> iter 97000, loss: 0.001480
 >> iter 98000, loss: 0.001394
 >> iter 99000, loss: 0.001325
 >> iter 100000, loss: 0.001292
   Number of active neurons: 10
 >> iter 101000, loss: 0.001251
 >> iter 102000, loss: 0.001259
 >> iter 103000, loss: 0.001216
 >> iter 104000, loss: 0.001187
 >> iter 105000, loss: 0.001133
 >> iter 106000, loss: 0.001129
 >> iter 107000, loss: 0.001076
 >> iter 108000, loss: 0.001080
 >> iter 109000, loss: 0.001041
 >> iter 110000, loss: 0.001107
   Number of active neurons: 10
 >> iter 111000, loss: 0.001078
 >> iter 112000, loss: 0.001042
 >> iter 113000, loss: 0.001017
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.670930
 >> iter 2000, loss: 15.155177
 >> iter 3000, loss: 13.791022
 >> iter 4000, loss: 13.284565
 >> iter 5000, loss: 13.087397
 >> iter 6000, loss: 13.007065
 >> iter 7000, loss: 12.969266
 >> iter 8000, loss: 12.968722
 >> iter 9000, loss: 12.958615
 >> iter 10000, loss: 12.961522
   Number of active neurons: 7
 >> iter 11000, loss: 12.944459
 >> iter 12000, loss: 12.953904
 >> iter 13000, loss: 12.948827
 >> iter 14000, loss: 12.953075
 >> iter 15000, loss: 12.681837
 >> iter 16000, loss: 11.647525
 >> iter 17000, loss: 10.178500
 >> iter 18000, loss: 4.906186
 >> iter 19000, loss: 2.024583
 >> iter 20000, loss: 0.900375
   Number of active neurons: 10
 >> iter 21000, loss: 0.698185
 >> iter 22000, loss: 0.300835
 >> iter 23000, loss: 0.150647
 >> iter 24000, loss: 0.374601
 >> iter 25000, loss: 0.173782
 >> iter 26000, loss: 0.158426
 >> iter 27000, loss: 0.206615
 >> iter 28000, loss: 0.095764
 >> iter 29000, loss: 0.232210
 >> iter 30000, loss: 0.102349
   Number of active neurons: 10
 >> iter 31000, loss: 0.050943
 >> iter 32000, loss: 0.030182
 >> iter 33000, loss: 0.021909
 >> iter 34000, loss: 0.017548
 >> iter 35000, loss: 0.015565
 >> iter 36000, loss: 0.015102
 >> iter 37000, loss: 0.013132
 >> iter 38000, loss: 0.011854
 >> iter 39000, loss: 0.013944
 >> iter 40000, loss: 0.094906
   Number of active neurons: 10
 >> iter 41000, loss: 0.085686
 >> iter 42000, loss: 0.037847
 >> iter 43000, loss: 0.019815
 >> iter 44000, loss: 0.012762
 >> iter 45000, loss: 0.009971
 >> iter 46000, loss: 0.008698
 >> iter 47000, loss: 0.007981
 >> iter 48000, loss: 0.007502
 >> iter 49000, loss: 0.007207
 >> iter 50000, loss: 0.006942
   Number of active neurons: 10
 >> iter 51000, loss: 0.006682
 >> iter 52000, loss: 0.006436
 >> iter 53000, loss: 0.031110
 >> iter 54000, loss: 0.024769
 >> iter 55000, loss: 0.013158
 >> iter 56000, loss: 0.009119
 >> iter 57000, loss: 0.007168
 >> iter 58000, loss: 0.016892
 >> iter 59000, loss: 0.010243
 >> iter 60000, loss: 0.007194
   Number of active neurons: 10
 >> iter 61000, loss: 0.005924
 >> iter 62000, loss: 0.005375
 >> iter 63000, loss: 0.004969
 >> iter 64000, loss: 0.004757
 >> iter 65000, loss: 0.004595
 >> iter 66000, loss: 0.004620
 >> iter 67000, loss: 0.004439
 >> iter 68000, loss: 0.004213
 >> iter 69000, loss: 0.004054
 >> iter 70000, loss: 0.004026
   Number of active neurons: 10
 >> iter 71000, loss: 0.166543
 >> iter 72000, loss: 0.064028
 >> iter 73000, loss: 0.676873
 >> iter 74000, loss: 0.255591
 >> iter 75000, loss: 0.098713
 >> iter 76000, loss: 0.040322
 >> iter 77000, loss: 0.018581
 >> iter 78000, loss: 0.010432
 >> iter 79000, loss: 0.007221
 >> iter 80000, loss: 0.005806
   Number of active neurons: 10
 >> iter 81000, loss: 0.005276
 >> iter 82000, loss: 0.004875
 >> iter 83000, loss: 0.004646
 >> iter 84000, loss: 0.004445
 >> iter 85000, loss: 0.004332
 >> iter 86000, loss: 0.004214
 >> iter 87000, loss: 0.004107
 >> iter 88000, loss: 0.003928
 >> iter 89000, loss: 0.003815
 >> iter 90000, loss: 0.003740
   Number of active neurons: 10
 >> iter 91000, loss: 0.003661
 >> iter 92000, loss: 0.003557
 >> iter 93000, loss: 0.003580
 >> iter 94000, loss: 0.003444
 >> iter 95000, loss: 0.003347
 >> iter 96000, loss: 0.003249
 >> iter 97000, loss: 0.003183
 >> iter 98000, loss: 0.003089
 >> iter 99000, loss: 0.025375
 >> iter 100000, loss: 0.011741
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.690073
 >> iter 2000, loss: 15.164291
 >> iter 3000, loss: 13.802736
 >> iter 4000, loss: 13.297368
 >> iter 5000, loss: 13.083068
 >> iter 6000, loss: 13.012539
 >> iter 7000, loss: 12.968012
 >> iter 8000, loss: 12.962212
 >> iter 9000, loss: 12.949072
 >> iter 10000, loss: 12.958501
   Number of active neurons: 5
 >> iter 11000, loss: 12.950529
 >> iter 12000, loss: 12.955344
 >> iter 13000, loss: 12.945563
 >> iter 14000, loss: 12.952887
 >> iter 15000, loss: 12.943524
 >> iter 16000, loss: 12.928146
 >> iter 17000, loss: 12.510719
 >> iter 18000, loss: 11.031436
 >> iter 19000, loss: 9.656872
 >> iter 20000, loss: 3.786868
   Number of active neurons: 10
 >> iter 21000, loss: 1.473964
 >> iter 22000, loss: 0.737836
 >> iter 23000, loss: 0.320504
 >> iter 24000, loss: 0.132387
 >> iter 25000, loss: 0.090051
 >> iter 26000, loss: 0.044534
 >> iter 27000, loss: 0.029376
 >> iter 28000, loss: 0.017205
 >> iter 29000, loss: 0.011791
 >> iter 30000, loss: 0.009141
   Number of active neurons: 10
 >> iter 31000, loss: 0.007450
 >> iter 32000, loss: 0.027746
 >> iter 33000, loss: 0.013884
 >> iter 34000, loss: 0.008444
 >> iter 35000, loss: 0.006106
 >> iter 36000, loss: 0.005020
 >> iter 37000, loss: 0.004415
 >> iter 38000, loss: 0.003991
 >> iter 39000, loss: 0.005669
 >> iter 40000, loss: 0.004397
   Number of active neurons: 10
 >> iter 41000, loss: 0.003703
 >> iter 42000, loss: 0.003336
 >> iter 43000, loss: 0.003113
 >> iter 44000, loss: 0.002850
 >> iter 45000, loss: 0.002667
 >> iter 46000, loss: 0.003485
 >> iter 47000, loss: 0.003017
 >> iter 48000, loss: 0.008384
 >> iter 49000, loss: 0.004739
 >> iter 50000, loss: 0.003165
   Number of active neurons: 10
 >> iter 51000, loss: 0.003054
 >> iter 52000, loss: 0.002551
 >> iter 53000, loss: 0.002229
 >> iter 54000, loss: 0.002025
 >> iter 55000, loss: 0.001904
 >> iter 56000, loss: 0.001831
 >> iter 57000, loss: 0.001769
 >> iter 58000, loss: 0.001685
 >> iter 59000, loss: 0.001643
 >> iter 60000, loss: 0.001583
   Number of active neurons: 10
 >> iter 61000, loss: 0.001530
 >> iter 62000, loss: 0.001473
 >> iter 63000, loss: 0.001445
 >> iter 64000, loss: 0.001392
 >> iter 65000, loss: 0.001342
 >> iter 66000, loss: 0.001316
 >> iter 67000, loss: 0.001280
 >> iter 68000, loss: 0.001298
 >> iter 69000, loss: 0.001264
 >> iter 70000, loss: 0.001209
   Number of active neurons: 10
 >> iter 71000, loss: 0.001179
 >> iter 72000, loss: 0.001142
 >> iter 73000, loss: 0.001110
 >> iter 74000, loss: 0.001087
 >> iter 75000, loss: 0.001076
 >> iter 76000, loss: 0.001045
 >> iter 77000, loss: 0.001027
 >> iter 78000, loss: 0.001613
 >> iter 79000, loss: 0.001318
 >> iter 80000, loss: 0.118070
   Number of active neurons: 10
 >> iter 81000, loss: 0.197042
 >> iter 82000, loss: 0.074335
 >> iter 83000, loss: 0.028797
 >> iter 84000, loss: 0.011880
 >> iter 85000, loss: 0.005538
 >> iter 86000, loss: 0.003162
 >> iter 87000, loss: 0.002212
 >> iter 88000, loss: 0.001795
 >> iter 89000, loss: 0.001615
 >> iter 90000, loss: 0.001485
   Number of active neurons: 10
 >> iter 91000, loss: 0.001405
 >> iter 92000, loss: 0.001367
 >> iter 93000, loss: 0.002586
 >> iter 94000, loss: 0.001908
 >> iter 95000, loss: 0.001525
 >> iter 96000, loss: 0.001362
 >> iter 97000, loss: 0.001257
 >> iter 98000, loss: 0.001180
 >> iter 99000, loss: 0.001129
 >> iter 100000, loss: 0.001098
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.719757
 >> iter 2000, loss: 15.142629
 >> iter 3000, loss: 13.776128
 >> iter 4000, loss: 13.275018
 >> iter 5000, loss: 13.071994
 >> iter 6000, loss: 13.001462
 >> iter 7000, loss: 12.967620
 >> iter 8000, loss: 12.965887
 >> iter 9000, loss: 12.957404
 >> iter 10000, loss: 12.960600
   Number of active neurons: 7
 >> iter 11000, loss: 12.950344
 >> iter 12000, loss: 12.955246
 >> iter 13000, loss: 12.946452
 >> iter 14000, loss: 12.954534
 >> iter 15000, loss: 12.949099
 >> iter 16000, loss: 12.955989
 >> iter 17000, loss: 12.950559
 >> iter 18000, loss: 12.954753
 >> iter 19000, loss: 12.943381
 >> iter 20000, loss: 12.954497
   Number of active neurons: 7
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 7
 >> iter 21000, loss: 12.889922
 >> iter 22000, loss: 12.358874
 >> iter 23000, loss: 11.081021
 >> iter 24000, loss: 9.381176
 >> iter 25000, loss: 5.120768
 >> iter 26000, loss: 2.033568
 >> iter 27000, loss: 0.817826
 >> iter 28000, loss: 0.348156
 >> iter 29000, loss: 0.146168
 >> iter 30000, loss: 0.072125
   Number of active neurons: 10
 >> iter 31000, loss: 2.962821
 >> iter 32000, loss: 1.289520
 >> iter 33000, loss: 0.578148
 >> iter 34000, loss: 0.283494
 >> iter 35000, loss: 0.274948
 >> iter 36000, loss: 0.123234
 >> iter 37000, loss: 0.062450
 >> iter 38000, loss: 0.037456
 >> iter 39000, loss: 0.081778
 >> iter 40000, loss: 0.063320
   Number of active neurons: 10
 >> iter 41000, loss: 0.033342
 >> iter 42000, loss: 0.020751
 >> iter 43000, loss: 0.014533
 >> iter 44000, loss: 0.011569
 >> iter 45000, loss: 0.010097
 >> iter 46000, loss: 0.013375
 >> iter 47000, loss: 0.009598
 >> iter 48000, loss: 0.009056
 >> iter 49000, loss: 0.008272
 >> iter 50000, loss: 0.007379
   Number of active neurons: 10
 >> iter 51000, loss: 0.006441
 >> iter 52000, loss: 0.005797
 >> iter 53000, loss: 0.005251
 >> iter 54000, loss: 0.004910
 >> iter 55000, loss: 0.004777
 >> iter 56000, loss: 0.004458
 >> iter 57000, loss: 0.009266
 >> iter 58000, loss: 0.008667
 >> iter 59000, loss: 0.044120
 >> iter 60000, loss: 0.034990
   Number of active neurons: 10
 >> iter 61000, loss: 0.076667
 >> iter 62000, loss: 0.150795
 >> iter 63000, loss: 0.061530
 >> iter 64000, loss: 0.026184
 >> iter 65000, loss: 0.012790
 >> iter 66000, loss: 0.007506
 >> iter 67000, loss: 0.005370
 >> iter 68000, loss: 0.004381
 >> iter 69000, loss: 0.003998
 >> iter 70000, loss: 0.003679
   Number of active neurons: 10
 >> iter 71000, loss: 0.003713
 >> iter 72000, loss: 0.003502
 >> iter 73000, loss: 0.003344
 >> iter 74000, loss: 0.003188
 >> iter 75000, loss: 0.002969
 >> iter 76000, loss: 0.002891
 >> iter 77000, loss: 0.002725
 >> iter 78000, loss: 0.002601
 >> iter 79000, loss: 0.002674
 >> iter 80000, loss: 0.002542
   Number of active neurons: 10
 >> iter 81000, loss: 0.002496
 >> iter 82000, loss: 0.002326
 >> iter 83000, loss: 0.002306
 >> iter 84000, loss: 0.008374
 >> iter 85000, loss: 0.073853
 >> iter 86000, loss: 0.029329
 >> iter 87000, loss: 0.012527
 >> iter 88000, loss: 0.006226
 >> iter 89000, loss: 0.003946
 >> iter 90000, loss: 0.003061
   Number of active neurons: 10
 >> iter 91000, loss: 0.002736
 >> iter 92000, loss: 0.002411
 >> iter 93000, loss: 0.002254
 >> iter 94000, loss: 0.002298
 >> iter 95000, loss: 0.002236
 >> iter 96000, loss: 0.002114
 >> iter 97000, loss: 0.002008
 >> iter 98000, loss: 0.001896
 >> iter 99000, loss: 0.001876
 >> iter 100000, loss: 0.001952
   Number of active neurons: 10
 >> iter 101000, loss: 0.002266
 >> iter 102000, loss: 0.002051
 >> iter 103000, loss: 0.001877
 >> iter 104000, loss: 0.001767
 >> iter 105000, loss: 0.001885
 >> iter 106000, loss: 0.001664
 >> iter 107000, loss: 0.001594
 >> iter 108000, loss: 0.001600
 >> iter 109000, loss: 0.001646
 >> iter 110000, loss: 0.001529
   Number of active neurons: 10
 >> iter 111000, loss: 0.001516
 >> iter 112000, loss: 0.001475
 >> iter 113000, loss: 0.001541
 >> iter 114000, loss: 0.001482
 >> iter 115000, loss: 0.001684
 >> iter 116000, loss: 0.001428
 >> iter 117000, loss: 0.001652
 >> iter 118000, loss: 0.001417
 >> iter 119000, loss: 0.001573
 >> iter 120000, loss: 0.001395
   Number of active neurons: 10
 >> iter 121000, loss: 0.001471
 >> iter 122000, loss: 0.001345
 >> iter 123000, loss: 0.001257
 >> iter 124000, loss: 0.001213
 >> iter 125000, loss: 0.001173
 >> iter 126000, loss: 0.001138
 >> iter 127000, loss: 0.001143
 >> iter 128000, loss: 0.001114
 >> iter 129000, loss: 0.001297
 >> iter 130000, loss: 0.001150
   Number of active neurons: 10
 >> iter 131000, loss: 0.001266
 >> iter 132000, loss: 0.001302
 >> iter 133000, loss: 0.001660
 >> iter 134000, loss: 0.001277
 >> iter 135000, loss: 0.001123
 >> iter 136000, loss: 0.001057
 >> iter 137000, loss: 0.001136
 >> iter 138000, loss: 0.001101
 >> iter 139000, loss: 0.001020
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.683120
 >> iter 2000, loss: 15.167456
 >> iter 3000, loss: 13.816275
 >> iter 4000, loss: 13.317300
 >> iter 5000, loss: 13.115058
 >> iter 6000, loss: 13.043251
 >> iter 7000, loss: 13.007410
 >> iter 8000, loss: 13.000769
 >> iter 9000, loss: 12.993799
 >> iter 10000, loss: 13.007093
   Number of active neurons: 7
 >> iter 11000, loss: 12.991759
 >> iter 12000, loss: 12.995791
 >> iter 13000, loss: 12.984461
 >> iter 14000, loss: 12.986125
 >> iter 15000, loss: 12.981183
 >> iter 16000, loss: 12.988328
 >> iter 17000, loss: 12.944596
 >> iter 18000, loss: 12.249155
 >> iter 19000, loss: 6.277429
 >> iter 20000, loss: 2.555142
   Number of active neurons: 10
 >> iter 21000, loss: 1.062471
 >> iter 22000, loss: 0.497624
 >> iter 23000, loss: 0.223376
 >> iter 24000, loss: 0.124973
 >> iter 25000, loss: 0.060897
 >> iter 26000, loss: 0.031888
 >> iter 27000, loss: 0.019104
 >> iter 28000, loss: 0.030689
 >> iter 29000, loss: 0.049991
 >> iter 30000, loss: 0.024710
   Number of active neurons: 10
 >> iter 31000, loss: 0.013914
 >> iter 32000, loss: 0.009337
 >> iter 33000, loss: 0.007275
 >> iter 34000, loss: 0.007530
 >> iter 35000, loss: 0.006859
 >> iter 36000, loss: 0.069822
 >> iter 37000, loss: 0.030032
 >> iter 38000, loss: 0.014659
 >> iter 39000, loss: 0.008222
 >> iter 40000, loss: 0.006347
   Number of active neurons: 10
 >> iter 41000, loss: 0.004895
 >> iter 42000, loss: 0.005249
 >> iter 43000, loss: 0.004227
 >> iter 44000, loss: 0.003669
 >> iter 45000, loss: 0.003454
 >> iter 46000, loss: 0.003153
 >> iter 47000, loss: 0.002923
 >> iter 48000, loss: 0.003076
 >> iter 49000, loss: 0.002805
 >> iter 50000, loss: 0.002646
   Number of active neurons: 10
 >> iter 51000, loss: 0.002652
 >> iter 52000, loss: 0.002427
 >> iter 53000, loss: 0.002284
 >> iter 54000, loss: 0.002195
 >> iter 55000, loss: 0.055027
 >> iter 56000, loss: 0.022670
 >> iter 57000, loss: 0.010897
 >> iter 58000, loss: 0.005848
 >> iter 59000, loss: 0.003668
 >> iter 60000, loss: 0.002818
   Number of active neurons: 10
 >> iter 61000, loss: 0.002391
 >> iter 62000, loss: 0.002610
 >> iter 63000, loss: 0.036293
 >> iter 64000, loss: 0.015216
 >> iter 65000, loss: 0.007224
 >> iter 66000, loss: 0.004299
 >> iter 67000, loss: 0.003035
 >> iter 68000, loss: 0.002577
 >> iter 69000, loss: 0.002204
 >> iter 70000, loss: 0.002518
   Number of active neurons: 10
 >> iter 71000, loss: 0.002299
 >> iter 72000, loss: 0.002094
 >> iter 73000, loss: 0.001971
 >> iter 74000, loss: 0.001842
 >> iter 75000, loss: 0.001685
 >> iter 76000, loss: 0.001609
 >> iter 77000, loss: 0.001522
 >> iter 78000, loss: 0.001468
 >> iter 79000, loss: 0.001415
 >> iter 80000, loss: 0.001413
   Number of active neurons: 10
 >> iter 81000, loss: 0.001754
 >> iter 82000, loss: 0.001535
 >> iter 83000, loss: 0.001526
 >> iter 84000, loss: 0.001397
 >> iter 85000, loss: 0.001324
 >> iter 86000, loss: 0.001284
 >> iter 87000, loss: 0.001223
 >> iter 88000, loss: 0.001188
 >> iter 89000, loss: 0.003874
 >> iter 90000, loss: 0.002658
   Number of active neurons: 10
 >> iter 91000, loss: 0.002628
 >> iter 92000, loss: 0.002032
 >> iter 93000, loss: 0.001626
 >> iter 94000, loss: 0.001393
 >> iter 95000, loss: 0.001247
 >> iter 96000, loss: 0.001227
 >> iter 97000, loss: 0.001142
 >> iter 98000, loss: 0.001149
 >> iter 99000, loss: 0.001164
 >> iter 100000, loss: 0.001092
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.639359
 >> iter 2000, loss: 15.115603
 >> iter 3000, loss: 13.780111
 >> iter 4000, loss: 13.282151
 >> iter 5000, loss: 13.073556
 >> iter 6000, loss: 13.003280
 >> iter 7000, loss: 12.964774
 >> iter 8000, loss: 12.957890
 >> iter 9000, loss: 12.938026
 >> iter 10000, loss: 12.944279
   Number of active neurons: 7
 >> iter 11000, loss: 12.940279
 >> iter 12000, loss: 12.901351
 >> iter 13000, loss: 12.426787
 >> iter 14000, loss: 11.623152
 >> iter 15000, loss: 10.522341
 >> iter 16000, loss: 5.477991
 >> iter 17000, loss: 2.107319
 >> iter 18000, loss: 0.813281
 >> iter 19000, loss: 0.330340
 >> iter 20000, loss: 0.242491
   Number of active neurons: 10
 >> iter 21000, loss: 0.106052
 >> iter 22000, loss: 0.055281
 >> iter 23000, loss: 0.034356
 >> iter 24000, loss: 0.022436
 >> iter 25000, loss: 0.017282
 >> iter 26000, loss: 0.013892
 >> iter 27000, loss: 0.011544
 >> iter 28000, loss: 0.011974
 >> iter 29000, loss: 0.011074
 >> iter 30000, loss: 0.010440
   Number of active neurons: 10
 >> iter 31000, loss: 0.010377
 >> iter 32000, loss: 0.008368
 >> iter 33000, loss: 0.007609
 >> iter 34000, loss: 0.006791
 >> iter 35000, loss: 0.048079
 >> iter 36000, loss: 0.022206
 >> iter 37000, loss: 0.012103
 >> iter 38000, loss: 0.007755
 >> iter 39000, loss: 0.012742
 >> iter 40000, loss: 0.061513
   Number of active neurons: 10
 >> iter 41000, loss: 0.027557
 >> iter 42000, loss: 0.014451
 >> iter 43000, loss: 0.008750
 >> iter 44000, loss: 0.006202
 >> iter 45000, loss: 0.004969
 >> iter 46000, loss: 0.004328
 >> iter 47000, loss: 0.004269
 >> iter 48000, loss: 0.089557
 >> iter 49000, loss: 0.036061
 >> iter 50000, loss: 0.016263
   Number of active neurons: 10
 >> iter 51000, loss: 0.008639
 >> iter 52000, loss: 0.005897
 >> iter 53000, loss: 0.004575
 >> iter 54000, loss: 0.003880
 >> iter 55000, loss: 0.003655
 >> iter 56000, loss: 0.003609
 >> iter 57000, loss: 0.003297
 >> iter 58000, loss: 0.011188
 >> iter 59000, loss: 0.006744
 >> iter 60000, loss: 0.004515
   Number of active neurons: 10
 >> iter 61000, loss: 0.003560
 >> iter 62000, loss: 0.003546
 >> iter 63000, loss: 0.003273
 >> iter 64000, loss: 0.002930
 >> iter 65000, loss: 0.005080
 >> iter 66000, loss: 0.062460
 >> iter 67000, loss: 0.025607
 >> iter 68000, loss: 0.011444
 >> iter 69000, loss: 0.106248
 >> iter 70000, loss: 0.041791
   Number of active neurons: 10
 >> iter 71000, loss: 0.017962
 >> iter 72000, loss: 0.008753
 >> iter 73000, loss: 0.005185
 >> iter 74000, loss: 0.003688
 >> iter 75000, loss: 0.003141
 >> iter 76000, loss: 0.002802
 >> iter 77000, loss: 0.002743
 >> iter 78000, loss: 0.002576
 >> iter 79000, loss: 0.002491
 >> iter 80000, loss: 0.002448
   Number of active neurons: 10
 >> iter 81000, loss: 0.002399
 >> iter 82000, loss: 0.002221
 >> iter 83000, loss: 0.002200
 >> iter 84000, loss: 0.002146
 >> iter 85000, loss: 0.002134
 >> iter 86000, loss: 0.003150
 >> iter 87000, loss: 0.002698
 >> iter 88000, loss: 0.002290
 >> iter 89000, loss: 0.002162
 >> iter 90000, loss: 0.002028
   Number of active neurons: 10
 >> iter 91000, loss: 0.001921
 >> iter 92000, loss: 0.001896
 >> iter 93000, loss: 0.001849
 >> iter 94000, loss: 0.001800
 >> iter 95000, loss: 0.001772
 >> iter 96000, loss: 0.001693
 >> iter 97000, loss: 0.001684
 >> iter 98000, loss: 0.001621
 >> iter 99000, loss: 0.001653
 >> iter 100000, loss: 0.001607
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.663323
 >> iter 2000, loss: 15.147714
 >> iter 3000, loss: 13.792447
 >> iter 4000, loss: 13.281082
 >> iter 5000, loss: 13.075970
 >> iter 6000, loss: 13.002498
 >> iter 7000, loss: 12.967623
 >> iter 8000, loss: 12.959190
 >> iter 9000, loss: 12.944228
 >> iter 10000, loss: 12.949560
   Number of active neurons: 5
 >> iter 11000, loss: 12.934741
 >> iter 12000, loss: 12.938979
 >> iter 13000, loss: 12.933245
 >> iter 14000, loss: 12.939593
 >> iter 15000, loss: 12.929332
 >> iter 16000, loss: 12.850024
 >> iter 17000, loss: 11.905769
 >> iter 18000, loss: 6.552494
 >> iter 19000, loss: 2.507765
 >> iter 20000, loss: 1.099583
   Number of active neurons: 10
 >> iter 21000, loss: 0.473585
 >> iter 22000, loss: 0.192705
 >> iter 23000, loss: 0.084004
 >> iter 24000, loss: 0.040817
 >> iter 25000, loss: 0.023520
 >> iter 26000, loss: 0.016760
 >> iter 27000, loss: 0.012446
 >> iter 28000, loss: 0.010164
 >> iter 29000, loss: 0.008910
 >> iter 30000, loss: 0.046506
   Number of active neurons: 10
 >> iter 31000, loss: 0.022086
 >> iter 32000, loss: 0.012578
 >> iter 33000, loss: 0.008393
 >> iter 34000, loss: 0.037062
 >> iter 35000, loss: 0.017573
 >> iter 36000, loss: 0.010399
 >> iter 37000, loss: 0.007045
 >> iter 38000, loss: 0.020856
 >> iter 39000, loss: 0.058830
 >> iter 40000, loss: 0.025370
   Number of active neurons: 10
 >> iter 41000, loss: 0.014693
 >> iter 42000, loss: 0.008908
 >> iter 43000, loss: 0.007326
 >> iter 44000, loss: 0.007817
 >> iter 45000, loss: 0.019634
 >> iter 46000, loss: 0.010174
 >> iter 47000, loss: 0.006154
 >> iter 48000, loss: 0.004539
 >> iter 49000, loss: 0.003907
 >> iter 50000, loss: 0.003736
   Number of active neurons: 10
 >> iter 51000, loss: 0.003277
 >> iter 52000, loss: 0.002997
 >> iter 53000, loss: 0.002768
 >> iter 54000, loss: 0.002642
 >> iter 55000, loss: 0.002470
 >> iter 56000, loss: 0.002341
 >> iter 57000, loss: 0.002259
 >> iter 58000, loss: 0.002167
 >> iter 59000, loss: 0.002091
 >> iter 60000, loss: 0.002068
   Number of active neurons: 10
 >> iter 61000, loss: 0.001987
 >> iter 62000, loss: 0.001919
 >> iter 63000, loss: 0.001820
 >> iter 64000, loss: 0.001855
 >> iter 65000, loss: 0.001801
 >> iter 66000, loss: 0.001921
 >> iter 67000, loss: 0.001798
 >> iter 68000, loss: 0.001755
 >> iter 69000, loss: 0.106210
 >> iter 70000, loss: 0.041285
   Number of active neurons: 10
 >> iter 71000, loss: 0.016793
 >> iter 72000, loss: 0.037925
 >> iter 73000, loss: 0.015712
 >> iter 74000, loss: 0.007408
 >> iter 75000, loss: 0.004162
 >> iter 76000, loss: 0.002891
 >> iter 77000, loss: 0.002394
 >> iter 78000, loss: 0.002121
 >> iter 79000, loss: 0.001964
 >> iter 80000, loss: 0.001875
   Number of active neurons: 10
 >> iter 81000, loss: 0.001750
 >> iter 82000, loss: 0.001717
 >> iter 83000, loss: 0.001664
 >> iter 84000, loss: 0.001599
 >> iter 85000, loss: 0.001530
 >> iter 86000, loss: 0.001570
 >> iter 87000, loss: 0.001576
 >> iter 88000, loss: 0.001488
 >> iter 89000, loss: 0.001456
 >> iter 90000, loss: 0.001393
   Number of active neurons: 10
 >> iter 91000, loss: 0.001384
 >> iter 92000, loss: 0.001362
 >> iter 93000, loss: 0.001323
 >> iter 94000, loss: 0.001267
 >> iter 95000, loss: 0.001227
 >> iter 96000, loss: 0.001208
 >> iter 97000, loss: 0.001180
 >> iter 98000, loss: 0.001160
 >> iter 99000, loss: 0.001133
 >> iter 100000, loss: 0.001580
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.682032
 >> iter 2000, loss: 15.164545
 >> iter 3000, loss: 13.818007
 >> iter 4000, loss: 13.310004
 >> iter 5000, loss: 13.104425
 >> iter 6000, loss: 13.025725
 >> iter 7000, loss: 12.990904
 >> iter 8000, loss: 12.983524
 >> iter 9000, loss: 12.968134
 >> iter 10000, loss: 12.979918
   Number of active neurons: 6
 >> iter 11000, loss: 12.967661
 >> iter 12000, loss: 12.976744
 >> iter 13000, loss: 12.962552
 >> iter 14000, loss: 12.976047
 >> iter 15000, loss: 12.964302
 >> iter 16000, loss: 12.974895
 >> iter 17000, loss: 12.962272
 >> iter 18000, loss: 12.964691
 >> iter 19000, loss: 12.901982
 >> iter 20000, loss: 12.103532
   Number of active neurons: 10
 >> iter 21000, loss: 9.456948
 >> iter 22000, loss: 7.419566
 >> iter 23000, loss: 4.936965
 >> iter 24000, loss: 2.340890
 >> iter 25000, loss: 1.185316
 >> iter 26000, loss: 0.546486
 >> iter 27000, loss: 0.565505
 >> iter 28000, loss: 0.243015
 >> iter 29000, loss: 0.108522
 >> iter 30000, loss: 0.090343
   Number of active neurons: 10
 >> iter 31000, loss: 0.095304
 >> iter 32000, loss: 0.097707
 >> iter 33000, loss: 0.046399
 >> iter 34000, loss: 0.025845
 >> iter 35000, loss: 0.016977
 >> iter 36000, loss: 0.012798
 >> iter 37000, loss: 0.010756
 >> iter 38000, loss: 0.009682
 >> iter 39000, loss: 0.008514
 >> iter 40000, loss: 0.088140
   Number of active neurons: 10
 >> iter 41000, loss: 0.045897
 >> iter 42000, loss: 0.022294
 >> iter 43000, loss: 0.012391
 >> iter 44000, loss: 0.008935
 >> iter 45000, loss: 0.008115
 >> iter 46000, loss: 0.006792
 >> iter 47000, loss: 0.005861
 >> iter 48000, loss: 0.005242
 >> iter 49000, loss: 0.013261
 >> iter 50000, loss: 0.067549
   Number of active neurons: 10
 >> iter 51000, loss: 0.028366
 >> iter 52000, loss: 0.013469
 >> iter 53000, loss: 0.007774
 >> iter 54000, loss: 0.005445
 >> iter 55000, loss: 0.004317
 >> iter 56000, loss: 0.003825
 >> iter 57000, loss: 0.003492
 >> iter 58000, loss: 0.006571
 >> iter 59000, loss: 0.004656
 >> iter 60000, loss: 0.003871
   Number of active neurons: 10
 >> iter 61000, loss: 0.003247
 >> iter 62000, loss: 0.020302
 >> iter 63000, loss: 0.056619
 >> iter 64000, loss: 0.023692
 >> iter 65000, loss: 0.011237
 >> iter 66000, loss: 0.006371
 >> iter 67000, loss: 0.004556
 >> iter 68000, loss: 0.003823
 >> iter 69000, loss: 0.009743
 >> iter 70000, loss: 0.005375
   Number of active neurons: 10
 >> iter 71000, loss: 0.003562
 >> iter 72000, loss: 0.004466
 >> iter 73000, loss: 0.029846
 >> iter 74000, loss: 0.013620
 >> iter 75000, loss: 0.007012
 >> iter 76000, loss: 0.004161
 >> iter 77000, loss: 0.003209
 >> iter 78000, loss: 0.002676
 >> iter 79000, loss: 0.002386
 >> iter 80000, loss: 0.002255
   Number of active neurons: 10
 >> iter 81000, loss: 0.002106
 >> iter 82000, loss: 0.002044
 >> iter 83000, loss: 0.001934
 >> iter 84000, loss: 0.001897
 >> iter 85000, loss: 0.001793
 >> iter 86000, loss: 0.001739
 >> iter 87000, loss: 0.001721
 >> iter 88000, loss: 0.001681
 >> iter 89000, loss: 0.001597
 >> iter 90000, loss: 0.001623
   Number of active neurons: 10
 >> iter 91000, loss: 0.001536
 >> iter 92000, loss: 0.001570
 >> iter 93000, loss: 0.001469
 >> iter 94000, loss: 0.001483
 >> iter 95000, loss: 0.001428
 >> iter 96000, loss: 0.001440
 >> iter 97000, loss: 0.001369
 >> iter 98000, loss: 0.001352
 >> iter 99000, loss: 0.001326
 >> iter 100000, loss: 0.001311
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.667249
 >> iter 2000, loss: 15.153621
 >> iter 3000, loss: 13.799867
 >> iter 4000, loss: 13.303312
 >> iter 5000, loss: 13.095657
 >> iter 6000, loss: 13.021234
 >> iter 7000, loss: 12.985618
 >> iter 8000, loss: 12.972822
 >> iter 9000, loss: 12.960478
 >> iter 10000, loss: 12.957783
   Number of active neurons: 7
 >> iter 11000, loss: 12.942343
 >> iter 12000, loss: 12.899305
 >> iter 13000, loss: 12.171325
 >> iter 14000, loss: 10.457510
 >> iter 15000, loss: 6.819449
 >> iter 16000, loss: 2.721354
 >> iter 17000, loss: 1.039801
 >> iter 18000, loss: 0.402047
 >> iter 19000, loss: 0.162138
 >> iter 20000, loss: 0.070128
   Number of active neurons: 10
 >> iter 21000, loss: 0.034249
 >> iter 22000, loss: 0.019989
 >> iter 23000, loss: 0.013621
 >> iter 24000, loss: 0.010632
 >> iter 25000, loss: 0.008714
 >> iter 26000, loss: 0.007440
 >> iter 27000, loss: 0.006526
 >> iter 28000, loss: 0.006000
 >> iter 29000, loss: 0.005513
 >> iter 30000, loss: 0.005217
   Number of active neurons: 10
 >> iter 31000, loss: 0.004851
 >> iter 32000, loss: 0.004387
 >> iter 33000, loss: 0.004104
 >> iter 34000, loss: 0.003860
 >> iter 35000, loss: 0.003601
 >> iter 36000, loss: 0.003431
 >> iter 37000, loss: 0.003239
 >> iter 38000, loss: 0.003096
 >> iter 39000, loss: 0.002933
 >> iter 40000, loss: 0.002803
   Number of active neurons: 10
 >> iter 41000, loss: 0.002811
 >> iter 42000, loss: 0.002665
 >> iter 43000, loss: 0.002501
 >> iter 44000, loss: 0.002517
 >> iter 45000, loss: 0.002328
 >> iter 46000, loss: 0.002238
 >> iter 47000, loss: 0.002094
 >> iter 48000, loss: 0.002051
 >> iter 49000, loss: 0.002022
 >> iter 50000, loss: 0.002051
   Number of active neurons: 10
 >> iter 51000, loss: 0.001970
 >> iter 52000, loss: 0.001820
 >> iter 53000, loss: 0.001779
 >> iter 54000, loss: 0.001738
 >> iter 55000, loss: 0.001655
 >> iter 56000, loss: 0.001641
 >> iter 57000, loss: 0.001576
 >> iter 58000, loss: 0.002248
 >> iter 59000, loss: 0.001930
 >> iter 60000, loss: 0.001713
   Number of active neurons: 10
 >> iter 61000, loss: 0.001530
 >> iter 62000, loss: 0.001461
 >> iter 63000, loss: 0.001410
 >> iter 64000, loss: 0.001393
 >> iter 65000, loss: 0.001349
 >> iter 66000, loss: 0.001296
 >> iter 67000, loss: 0.001263
 >> iter 68000, loss: 0.001233
 >> iter 69000, loss: 0.001187
 >> iter 70000, loss: 0.001176
   Number of active neurons: 10
 >> iter 71000, loss: 0.001121
 >> iter 72000, loss: 0.001114
 >> iter 73000, loss: 0.001062
 >> iter 74000, loss: 0.001045
 >> iter 75000, loss: 0.001086
 >> iter 76000, loss: 0.001072
 >> iter 77000, loss: 0.001026
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.656712
 >> iter 2000, loss: 15.154315
 >> iter 3000, loss: 13.825243
 >> iter 4000, loss: 13.314378
 >> iter 5000, loss: 13.096149
 >> iter 6000, loss: 13.033460
 >> iter 7000, loss: 12.987398
 >> iter 8000, loss: 12.979278
 >> iter 9000, loss: 12.975631
 >> iter 10000, loss: 12.978036
   Number of active neurons: 7
 >> iter 11000, loss: 12.977591
 >> iter 12000, loss: 12.978629
 >> iter 13000, loss: 12.967026
 >> iter 14000, loss: 12.974720
 >> iter 15000, loss: 12.963739
 >> iter 16000, loss: 12.733770
 >> iter 17000, loss: 11.822136
 >> iter 18000, loss: 10.215184
 >> iter 19000, loss: 4.695754
 >> iter 20000, loss: 2.105076
   Number of active neurons: 10
 >> iter 21000, loss: 1.061884
 >> iter 22000, loss: 0.778213
 >> iter 23000, loss: 0.348878
 >> iter 24000, loss: 0.152831
 >> iter 25000, loss: 0.071880
 >> iter 26000, loss: 0.138115
 >> iter 27000, loss: 0.222767
 >> iter 28000, loss: 0.110004
 >> iter 29000, loss: 0.056707
 >> iter 30000, loss: 0.078223
   Number of active neurons: 10
 >> iter 31000, loss: 0.102167
 >> iter 32000, loss: 0.048699
 >> iter 33000, loss: 0.025878
 >> iter 34000, loss: 0.015812
 >> iter 35000, loss: 0.014717
 >> iter 36000, loss: 0.012785
 >> iter 37000, loss: 0.023059
 >> iter 38000, loss: 0.013139
 >> iter 39000, loss: 0.038769
 >> iter 40000, loss: 0.569585
   Number of active neurons: 10
 >> iter 41000, loss: 0.222060
 >> iter 42000, loss: 0.088482
 >> iter 43000, loss: 0.091797
 >> iter 44000, loss: 0.093685
 >> iter 45000, loss: 0.040718
 >> iter 46000, loss: 0.378514
 >> iter 47000, loss: 0.152939
 >> iter 48000, loss: 0.065387
 >> iter 49000, loss: 0.029496
 >> iter 50000, loss: 0.015289
   Number of active neurons: 10
 >> iter 51000, loss: 0.104314
 >> iter 52000, loss: 0.043720
 >> iter 53000, loss: 0.033774
 >> iter 54000, loss: 0.016708
 >> iter 55000, loss: 0.010214
 >> iter 56000, loss: 0.007333
 >> iter 57000, loss: 0.005881
 >> iter 58000, loss: 0.005433
 >> iter 59000, loss: 0.004733
 >> iter 60000, loss: 0.004322
   Number of active neurons: 10
 >> iter 61000, loss: 0.139740
 >> iter 62000, loss: 0.055702
 >> iter 63000, loss: 0.023628
 >> iter 64000, loss: 0.011289
 >> iter 65000, loss: 0.063680
 >> iter 66000, loss: 0.029807
 >> iter 67000, loss: 0.013560
 >> iter 68000, loss: 0.009069
 >> iter 69000, loss: 0.005714
 >> iter 70000, loss: 0.004359
   Number of active neurons: 10
 >> iter 71000, loss: 0.003596
 >> iter 72000, loss: 0.003387
 >> iter 73000, loss: 0.003193
 >> iter 74000, loss: 0.003058
 >> iter 75000, loss: 0.008210
 >> iter 76000, loss: 0.005611
 >> iter 77000, loss: 0.015724
 >> iter 78000, loss: 0.236661
 >> iter 79000, loss: 0.111742
 >> iter 80000, loss: 0.044681
   Number of active neurons: 10
 >> iter 81000, loss: 0.019517
 >> iter 82000, loss: 0.088639
 >> iter 83000, loss: 0.036181
 >> iter 84000, loss: 0.016301
 >> iter 85000, loss: 0.008549
 >> iter 86000, loss: 0.005469
 >> iter 87000, loss: 0.004303
 >> iter 88000, loss: 0.003702
 >> iter 89000, loss: 0.003408
 >> iter 90000, loss: 0.003565
   Number of active neurons: 10
 >> iter 91000, loss: 0.003077
 >> iter 92000, loss: 0.002887
 >> iter 93000, loss: 0.002693
 >> iter 94000, loss: 0.002980
 >> iter 95000, loss: 0.002627
 >> iter 96000, loss: 0.002994
 >> iter 97000, loss: 0.002701
 >> iter 98000, loss: 0.002500
 >> iter 99000, loss: 0.002369
 >> iter 100000, loss: 0.020051
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.672080
 >> iter 2000, loss: 15.201659
 >> iter 3000, loss: 13.837658
 >> iter 4000, loss: 13.309719
 >> iter 5000, loss: 13.099914
 >> iter 6000, loss: 13.027742
 >> iter 7000, loss: 12.979040
 >> iter 8000, loss: 12.971776
 >> iter 9000, loss: 12.956705
 >> iter 10000, loss: 12.961086
   Number of active neurons: 7
 >> iter 11000, loss: 12.950025
 >> iter 12000, loss: 12.957964
 >> iter 13000, loss: 12.945014
 >> iter 14000, loss: 12.953336
 >> iter 15000, loss: 12.944128
 >> iter 16000, loss: 12.948302
 >> iter 17000, loss: 12.856100
 >> iter 18000, loss: 12.356027
 >> iter 19000, loss: 8.967656
 >> iter 20000, loss: 3.591180
   Number of active neurons: 10
 >> iter 21000, loss: 1.590535
 >> iter 22000, loss: 0.774493
 >> iter 23000, loss: 0.330939
 >> iter 24000, loss: 0.148287
 >> iter 25000, loss: 0.096742
 >> iter 26000, loss: 0.048134
 >> iter 27000, loss: 0.042719
 >> iter 28000, loss: 0.023300
 >> iter 29000, loss: 0.044105
 >> iter 30000, loss: 0.022150
   Number of active neurons: 10
 >> iter 31000, loss: 0.013018
 >> iter 32000, loss: 0.009485
 >> iter 33000, loss: 0.007433
 >> iter 34000, loss: 0.006289
 >> iter 35000, loss: 0.005526
 >> iter 36000, loss: 0.006476
 >> iter 37000, loss: 0.005791
 >> iter 38000, loss: 0.005429
 >> iter 39000, loss: 0.004775
 >> iter 40000, loss: 0.004208
   Number of active neurons: 10
 >> iter 41000, loss: 0.003813
 >> iter 42000, loss: 0.003549
 >> iter 43000, loss: 0.003326
 >> iter 44000, loss: 0.003219
 >> iter 45000, loss: 0.003130
 >> iter 46000, loss: 0.002896
 >> iter 47000, loss: 0.002799
 >> iter 48000, loss: 0.002617
 >> iter 49000, loss: 0.002571
 >> iter 50000, loss: 0.002460
   Number of active neurons: 10
 >> iter 51000, loss: 0.002413
 >> iter 52000, loss: 0.004114
 >> iter 53000, loss: 0.003024
 >> iter 54000, loss: 0.002555
 >> iter 55000, loss: 0.002280
 >> iter 56000, loss: 0.003531
 >> iter 57000, loss: 0.139636
 >> iter 58000, loss: 0.053591
 >> iter 59000, loss: 0.021484
 >> iter 60000, loss: 0.009453
   Number of active neurons: 10
 >> iter 61000, loss: 0.078773
 >> iter 62000, loss: 0.031253
 >> iter 63000, loss: 0.013463
 >> iter 64000, loss: 0.006689
 >> iter 65000, loss: 0.004118
 >> iter 66000, loss: 0.003073
 >> iter 67000, loss: 0.003179
 >> iter 68000, loss: 0.002603
 >> iter 69000, loss: 0.002297
 >> iter 70000, loss: 0.002530
   Number of active neurons: 10
 >> iter 71000, loss: 0.002312
 >> iter 72000, loss: 0.002143
 >> iter 73000, loss: 0.001991
 >> iter 74000, loss: 0.001871
 >> iter 75000, loss: 0.001799
 >> iter 76000, loss: 0.001730
 >> iter 77000, loss: 0.001617
 >> iter 78000, loss: 0.001595
 >> iter 79000, loss: 0.001566
 >> iter 80000, loss: 0.002079
   Number of active neurons: 10
 >> iter 81000, loss: 0.001920
 >> iter 82000, loss: 0.001764
 >> iter 83000, loss: 0.001790
 >> iter 84000, loss: 0.001684
 >> iter 85000, loss: 0.001847
 >> iter 86000, loss: 0.001532
 >> iter 87000, loss: 0.001437
 >> iter 88000, loss: 0.002020
 >> iter 89000, loss: 0.001645
 >> iter 90000, loss: 0.001445
   Number of active neurons: 10
 >> iter 91000, loss: 0.001331
 >> iter 92000, loss: 0.001249
 >> iter 93000, loss: 0.001201
 >> iter 94000, loss: 0.001387
 >> iter 95000, loss: 0.001364
 >> iter 96000, loss: 0.001241
 >> iter 97000, loss: 0.001196
 >> iter 98000, loss: 0.001166
 >> iter 99000, loss: 0.001140
 >> iter 100000, loss: 0.001108
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.658806
 >> iter 2000, loss: 15.156043
 >> iter 3000, loss: 13.812825
 >> iter 4000, loss: 13.297199
 >> iter 5000, loss: 13.095719
 >> iter 6000, loss: 13.024804
 >> iter 7000, loss: 12.984945
 >> iter 8000, loss: 12.976443
 >> iter 9000, loss: 12.955848
 >> iter 10000, loss: 12.958015
   Number of active neurons: 6
 >> iter 11000, loss: 12.944451
 >> iter 12000, loss: 12.959759
 >> iter 13000, loss: 12.948081
 >> iter 14000, loss: 12.960598
 >> iter 15000, loss: 12.948256
 >> iter 16000, loss: 12.956093
 >> iter 17000, loss: 12.895493
 >> iter 18000, loss: 12.266471
 >> iter 19000, loss: 10.835974
 >> iter 20000, loss: 9.334353
   Number of active neurons: 10
 >> iter 21000, loss: 6.227155
 >> iter 22000, loss: 2.590649
 >> iter 23000, loss: 0.990896
 >> iter 24000, loss: 0.451743
 >> iter 25000, loss: 0.179756
 >> iter 26000, loss: 0.077940
 >> iter 27000, loss: 0.038162
 >> iter 28000, loss: 0.025654
 >> iter 29000, loss: 0.016146
 >> iter 30000, loss: 0.011216
   Number of active neurons: 10
 >> iter 31000, loss: 0.014275
 >> iter 32000, loss: 0.009560
 >> iter 33000, loss: 0.007512
 >> iter 34000, loss: 0.006492
 >> iter 35000, loss: 0.005722
 >> iter 36000, loss: 0.005250
 >> iter 37000, loss: 0.006469
 >> iter 38000, loss: 0.005383
 >> iter 39000, loss: 0.004521
 >> iter 40000, loss: 0.006890
   Number of active neurons: 10
 >> iter 41000, loss: 0.004943
 >> iter 42000, loss: 0.003925
 >> iter 43000, loss: 0.003597
 >> iter 44000, loss: 0.003261
 >> iter 45000, loss: 0.002975
 >> iter 46000, loss: 0.002863
 >> iter 47000, loss: 0.002688
 >> iter 48000, loss: 0.002608
 >> iter 49000, loss: 0.002458
 >> iter 50000, loss: 0.003066
   Number of active neurons: 10
 >> iter 51000, loss: 0.002796
 >> iter 52000, loss: 0.003555
 >> iter 53000, loss: 0.003065
 >> iter 54000, loss: 0.002634
 >> iter 55000, loss: 0.040580
 >> iter 56000, loss: 0.016793
 >> iter 57000, loss: 0.010762
 >> iter 58000, loss: 0.022962
 >> iter 59000, loss: 0.023853
 >> iter 60000, loss: 0.097305
   Number of active neurons: 10
 >> iter 61000, loss: 0.097025
 >> iter 62000, loss: 0.039190
 >> iter 63000, loss: 0.040187
 >> iter 64000, loss: 0.039873
 >> iter 65000, loss: 0.084785
 >> iter 66000, loss: 0.115150
 >> iter 67000, loss: 0.045137
 >> iter 68000, loss: 0.018895
 >> iter 69000, loss: 0.024672
 >> iter 70000, loss: 0.011333
   Number of active neurons: 10
 >> iter 71000, loss: 0.006069
 >> iter 72000, loss: 0.003915
 >> iter 73000, loss: 0.003180
 >> iter 74000, loss: 0.002822
 >> iter 75000, loss: 0.002443
 >> iter 76000, loss: 0.002251
 >> iter 77000, loss: 0.002148
 >> iter 78000, loss: 0.002007
 >> iter 79000, loss: 0.002009
 >> iter 80000, loss: 0.001914
   Number of active neurons: 10
 >> iter 81000, loss: 0.001825
 >> iter 82000, loss: 0.001740
 >> iter 83000, loss: 0.001681
 >> iter 84000, loss: 0.001678
 >> iter 85000, loss: 0.001552
 >> iter 86000, loss: 0.001501
 >> iter 87000, loss: 0.001449
 >> iter 88000, loss: 0.001404
 >> iter 89000, loss: 0.001346
 >> iter 90000, loss: 0.001322
   Number of active neurons: 10
 >> iter 91000, loss: 0.001275
 >> iter 92000, loss: 0.001245
 >> iter 93000, loss: 0.001231
 >> iter 94000, loss: 0.001245
 >> iter 95000, loss: 0.001193
 >> iter 96000, loss: 0.001171
 >> iter 97000, loss: 0.001144
 >> iter 98000, loss: 0.001111
 >> iter 99000, loss: 0.001086
 >> iter 100000, loss: 0.001062
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

