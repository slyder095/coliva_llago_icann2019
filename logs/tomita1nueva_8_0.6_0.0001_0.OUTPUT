 > Problema: tomita1nueva
 > Args:
   - Hidden size: 8
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.911760
 >> iter 2000, loss: 4.055918
 >> iter 3000, loss: 1.521626
 >> iter 4000, loss: 0.593212
 >> iter 5000, loss: 0.248041
 >> iter 6000, loss: 0.110528
 >> iter 7000, loss: 0.058840
 >> iter 8000, loss: 0.041045
 >> iter 9000, loss: 0.033004
 >> iter 10000, loss: 0.028453
   Number of active neurons: 4
 >> iter 11000, loss: 0.027078
 >> iter 12000, loss: 0.028861
 >> iter 13000, loss: 0.030330
 >> iter 14000, loss: 0.026851
 >> iter 15000, loss: 0.027884
 >> iter 16000, loss: 0.027157
 >> iter 17000, loss: 0.029638
 >> iter 18000, loss: 0.028362
 >> iter 19000, loss: 0.031970
 >> iter 20000, loss: 0.052533
   Number of active neurons: 4
 >> iter 21000, loss: 0.035281
 >> iter 22000, loss: 0.036116
 >> iter 23000, loss: 0.042912
 >> iter 24000, loss: 0.032496
 >> iter 25000, loss: 0.042580
 >> iter 26000, loss: 0.029671
 >> iter 27000, loss: 0.040689
 >> iter 28000, loss: 0.029500
 >> iter 29000, loss: 0.025944
 >> iter 30000, loss: 0.023192
   Number of active neurons: 3
 >> iter 31000, loss: 0.030659
 >> iter 32000, loss: 0.024849
 >> iter 33000, loss: 0.025172
 >> iter 34000, loss: 0.024018
 >> iter 35000, loss: 0.024290
 >> iter 36000, loss: 0.025429
 >> iter 37000, loss: 0.022148
 >> iter 38000, loss: 0.028786
 >> iter 39000, loss: 0.027458
 >> iter 40000, loss: 0.030284
   Number of active neurons: 2
 >> iter 41000, loss: 0.023244
 >> iter 42000, loss: 0.027385
 >> iter 43000, loss: 0.027558
 >> iter 44000, loss: 0.027563
 >> iter 45000, loss: 0.024237
 >> iter 46000, loss: 0.022319
 >> iter 47000, loss: 0.020837
 >> iter 48000, loss: 0.019242
 >> iter 49000, loss: 0.025441
 >> iter 50000, loss: 0.023528
   Number of active neurons: 2
 >> iter 51000, loss: 0.022116
 >> iter 52000, loss: 0.020619
 >> iter 53000, loss: 0.030987
 >> iter 54000, loss: 0.026122
 >> iter 55000, loss: 0.041882
 >> iter 56000, loss: 0.045971
 >> iter 57000, loss: 0.033359
 >> iter 58000, loss: 0.027916
 >> iter 59000, loss: 0.025010
 >> iter 60000, loss: 0.040551
   Number of active neurons: 2
 >> iter 61000, loss: 0.028340
 >> iter 62000, loss: 0.024666
 >> iter 63000, loss: 0.023644
 >> iter 64000, loss: 0.023580
 >> iter 65000, loss: 0.022934
 >> iter 66000, loss: 0.062050
 >> iter 67000, loss: 0.038241
 >> iter 68000, loss: 0.038238
 >> iter 69000, loss: 0.042756
 >> iter 70000, loss: 0.036517
   Number of active neurons: 1
 >> iter 71000, loss: 0.025730
 >> iter 72000, loss: 0.021375
 >> iter 73000, loss: 0.021260
 >> iter 74000, loss: 0.031454
 >> iter 75000, loss: 0.041021
 >> iter 76000, loss: 0.028267
 >> iter 77000, loss: 0.042445
 >> iter 78000, loss: 0.025745
 >> iter 79000, loss: 0.026123
 >> iter 80000, loss: 0.022012
   Number of active neurons: 1
 >> iter 81000, loss: 0.018872
 >> iter 82000, loss: 0.019967
 >> iter 83000, loss: 0.021877
 >> iter 84000, loss: 0.026420
 >> iter 85000, loss: 0.020611
 >> iter 86000, loss: 0.018374
 >> iter 87000, loss: 0.021606
 >> iter 88000, loss: 0.018589
 >> iter 89000, loss: 0.016564
 >> iter 90000, loss: 0.016479
   Number of active neurons: 1
 >> iter 91000, loss: 0.020170
 >> iter 92000, loss: 0.052209
 >> iter 93000, loss: 0.030699
 >> iter 94000, loss: 0.026218
 >> iter 95000, loss: 0.020458
 >> iter 96000, loss: 0.018860
 >> iter 97000, loss: 0.021940
 >> iter 98000, loss: 0.020218
 >> iter 99000, loss: 0.024466
 >> iter 100000, loss: 0.019359
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455162
   Number of active neurons: 0
 >> iter 1000, loss: 10.914332
 >> iter 2000, loss: 4.059104
 >> iter 3000, loss: 1.514882
 >> iter 4000, loss: 0.579891
 >> iter 5000, loss: 0.234894
 >> iter 6000, loss: 0.107989
 >> iter 7000, loss: 0.057754
 >> iter 8000, loss: 0.040202
 >> iter 9000, loss: 0.052985
 >> iter 10000, loss: 0.038839
   Number of active neurons: 4
 >> iter 11000, loss: 0.031737
 >> iter 12000, loss: 0.031379
 >> iter 13000, loss: 0.031949
 >> iter 14000, loss: 0.026965
 >> iter 15000, loss: 0.025415
 >> iter 16000, loss: 0.034954
 >> iter 17000, loss: 0.036002
 >> iter 18000, loss: 0.030697
 >> iter 19000, loss: 0.027904
 >> iter 20000, loss: 0.033189
   Number of active neurons: 3
 >> iter 21000, loss: 0.027398
 >> iter 22000, loss: 0.044697
 >> iter 23000, loss: 0.035550
 >> iter 24000, loss: 0.030806
 >> iter 25000, loss: 0.028312
 >> iter 26000, loss: 0.028486
 >> iter 27000, loss: 0.067802
 >> iter 28000, loss: 0.041754
 >> iter 29000, loss: 0.030085
 >> iter 30000, loss: 0.038866
   Number of active neurons: 3
 >> iter 31000, loss: 0.033182
 >> iter 32000, loss: 0.025306
 >> iter 33000, loss: 0.024450
 >> iter 34000, loss: 0.025473
 >> iter 35000, loss: 0.031175
 >> iter 36000, loss: 0.028580
 >> iter 37000, loss: 0.025061
 >> iter 38000, loss: 0.022302
 >> iter 39000, loss: 0.021953
 >> iter 40000, loss: 0.022795
   Number of active neurons: 2
 >> iter 41000, loss: 0.026905
 >> iter 42000, loss: 0.023196
 >> iter 43000, loss: 0.022826
 >> iter 44000, loss: 0.025466
 >> iter 45000, loss: 0.032102
 >> iter 46000, loss: 0.044145
 >> iter 47000, loss: 0.033530
 >> iter 48000, loss: 0.037244
 >> iter 49000, loss: 0.029867
 >> iter 50000, loss: 0.024703
   Number of active neurons: 1
 >> iter 51000, loss: 0.022571
 >> iter 52000, loss: 0.023109
 >> iter 53000, loss: 0.030214
 >> iter 54000, loss: 0.027546
 >> iter 55000, loss: 0.021794
 >> iter 56000, loss: 0.020330
 >> iter 57000, loss: 0.026000
 >> iter 58000, loss: 0.021717
 >> iter 59000, loss: 0.022460
 >> iter 60000, loss: 0.027516
   Number of active neurons: 1
 >> iter 61000, loss: 0.022733
 >> iter 62000, loss: 0.018621
 >> iter 63000, loss: 0.021356
 >> iter 64000, loss: 0.031372
 >> iter 65000, loss: 0.031939
 >> iter 66000, loss: 0.028021
 >> iter 67000, loss: 0.029363
 >> iter 68000, loss: 0.021689
 >> iter 69000, loss: 0.021954
 >> iter 70000, loss: 0.023220
   Number of active neurons: 1
 >> iter 71000, loss: 0.028000
 >> iter 72000, loss: 0.027603
 >> iter 73000, loss: 0.023753
 >> iter 74000, loss: 0.020367
 >> iter 75000, loss: 0.019554
 >> iter 76000, loss: 0.019863
 >> iter 77000, loss: 0.018444
 >> iter 78000, loss: 0.017528
 >> iter 79000, loss: 0.017352
 >> iter 80000, loss: 0.016774
   Number of active neurons: 1
 >> iter 81000, loss: 0.015692
 >> iter 82000, loss: 0.015886
 >> iter 83000, loss: 0.018713
 >> iter 84000, loss: 0.018819
 >> iter 85000, loss: 0.021510
 >> iter 86000, loss: 0.021432
 >> iter 87000, loss: 0.030199
 >> iter 88000, loss: 0.025087
 >> iter 89000, loss: 0.025380
 >> iter 90000, loss: 0.019794
   Number of active neurons: 1
 >> iter 91000, loss: 0.020670
 >> iter 92000, loss: 0.019159
 >> iter 93000, loss: 0.024060
 >> iter 94000, loss: 0.040762
 >> iter 95000, loss: 0.025021
 >> iter 96000, loss: 0.021306
 >> iter 97000, loss: 0.028225
 >> iter 98000, loss: 0.025874
 >> iter 99000, loss: 0.023490
 >> iter 100000, loss: 0.023967
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.979290
 >> iter 2000, loss: 4.072945
 >> iter 3000, loss: 1.518907
 >> iter 4000, loss: 0.577902
 >> iter 5000, loss: 0.235870
 >> iter 6000, loss: 0.106204
 >> iter 7000, loss: 0.059465
 >> iter 8000, loss: 0.038916
 >> iter 9000, loss: 0.034380
 >> iter 10000, loss: 0.035120
   Number of active neurons: 5
 >> iter 11000, loss: 0.030757
 >> iter 12000, loss: 0.032144
 >> iter 13000, loss: 0.031049
 >> iter 14000, loss: 0.029722
 >> iter 15000, loss: 0.031338
 >> iter 16000, loss: 0.028938
 >> iter 17000, loss: 0.032519
 >> iter 18000, loss: 0.033652
 >> iter 19000, loss: 0.051116
 >> iter 20000, loss: 0.047191
   Number of active neurons: 5
 >> iter 21000, loss: 0.034713
 >> iter 22000, loss: 0.029426
 >> iter 23000, loss: 0.032412
 >> iter 24000, loss: 0.034154
 >> iter 25000, loss: 0.031286
 >> iter 26000, loss: 0.030839
 >> iter 27000, loss: 0.026175
 >> iter 28000, loss: 0.027632
 >> iter 29000, loss: 0.026263
 >> iter 30000, loss: 0.028639
   Number of active neurons: 4
 >> iter 31000, loss: 0.026373
 >> iter 32000, loss: 0.025557
 >> iter 33000, loss: 0.025760
 >> iter 34000, loss: 0.023929
 >> iter 35000, loss: 0.040020
 >> iter 36000, loss: 0.030902
 >> iter 37000, loss: 0.027093
 >> iter 38000, loss: 0.025790
 >> iter 39000, loss: 0.023995
 >> iter 40000, loss: 0.022049
   Number of active neurons: 2
 >> iter 41000, loss: 0.021687
 >> iter 42000, loss: 0.023843
 >> iter 43000, loss: 0.023053
 >> iter 44000, loss: 0.039767
 >> iter 45000, loss: 0.032694
 >> iter 46000, loss: 0.027902
 >> iter 47000, loss: 0.024819
 >> iter 48000, loss: 0.032568
 >> iter 49000, loss: 0.027167
 >> iter 50000, loss: 0.022421
   Number of active neurons: 2
 >> iter 51000, loss: 0.023952
 >> iter 52000, loss: 0.023741
 >> iter 53000, loss: 0.023337
 >> iter 54000, loss: 0.027128
 >> iter 55000, loss: 0.028024
 >> iter 56000, loss: 0.027193
 >> iter 57000, loss: 0.026009
 >> iter 58000, loss: 0.029221
 >> iter 59000, loss: 0.024392
 >> iter 60000, loss: 0.020810
   Number of active neurons: 2
 >> iter 61000, loss: 0.020500
 >> iter 62000, loss: 0.023313
 >> iter 63000, loss: 0.020961
 >> iter 64000, loss: 0.028326
 >> iter 65000, loss: 0.026278
 >> iter 66000, loss: 0.048102
 >> iter 67000, loss: 0.033024
 >> iter 68000, loss: 0.024788
 >> iter 69000, loss: 0.029985
 >> iter 70000, loss: 0.022513
   Number of active neurons: 2
 >> iter 71000, loss: 0.020354
 >> iter 72000, loss: 0.024527
 >> iter 73000, loss: 0.021887
 >> iter 74000, loss: 0.021037
 >> iter 75000, loss: 0.020997
 >> iter 76000, loss: 0.020936
 >> iter 77000, loss: 0.021191
 >> iter 78000, loss: 0.025030
 >> iter 79000, loss: 0.024154
 >> iter 80000, loss: 0.023834
   Number of active neurons: 2
 >> iter 81000, loss: 0.022494
 >> iter 82000, loss: 0.024154
 >> iter 83000, loss: 0.026239
 >> iter 84000, loss: 0.024696
 >> iter 85000, loss: 0.025362
 >> iter 86000, loss: 0.021905
 >> iter 87000, loss: 0.034664
 >> iter 88000, loss: 0.028179
 >> iter 89000, loss: 0.022374
 >> iter 90000, loss: 0.021945
   Number of active neurons: 2
 >> iter 91000, loss: 0.025505
 >> iter 92000, loss: 0.061770
 >> iter 93000, loss: 0.036086
 >> iter 94000, loss: 0.026589
 >> iter 95000, loss: 0.026034
 >> iter 96000, loss: 0.022997
 >> iter 97000, loss: 0.035850
 >> iter 98000, loss: 0.027288
 >> iter 99000, loss: 0.044510
 >> iter 100000, loss: 0.048627
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.007014
 >> iter 2000, loss: 4.091246
 >> iter 3000, loss: 1.534747
 >> iter 4000, loss: 0.593783
 >> iter 5000, loss: 0.241463
 >> iter 6000, loss: 0.108921
 >> iter 7000, loss: 0.062148
 >> iter 8000, loss: 0.051157
 >> iter 9000, loss: 0.042276
 >> iter 10000, loss: 0.034148
   Number of active neurons: 5
 >> iter 11000, loss: 0.033072
 >> iter 12000, loss: 0.036135
 >> iter 13000, loss: 0.029359
 >> iter 14000, loss: 0.027897
 >> iter 15000, loss: 0.027788
 >> iter 16000, loss: 0.029794
 >> iter 17000, loss: 0.033920
 >> iter 18000, loss: 0.029823
 >> iter 19000, loss: 0.026760
 >> iter 20000, loss: 0.029004
   Number of active neurons: 4
 >> iter 21000, loss: 0.029004
 >> iter 22000, loss: 0.046040
 >> iter 23000, loss: 0.034083
 >> iter 24000, loss: 0.027768
 >> iter 25000, loss: 0.025761
 >> iter 26000, loss: 0.031170
 >> iter 27000, loss: 0.031772
 >> iter 28000, loss: 0.027017
 >> iter 29000, loss: 0.028215
 >> iter 30000, loss: 0.033343
   Number of active neurons: 2
 >> iter 31000, loss: 0.025852
 >> iter 32000, loss: 0.025111
 >> iter 33000, loss: 0.025126
 >> iter 34000, loss: 0.023635
 >> iter 35000, loss: 0.023448
 >> iter 36000, loss: 0.022071
 >> iter 37000, loss: 0.032985
 >> iter 38000, loss: 0.027280
 >> iter 39000, loss: 0.028490
 >> iter 40000, loss: 0.024175
   Number of active neurons: 2
 >> iter 41000, loss: 0.029965
 >> iter 42000, loss: 0.025170
 >> iter 43000, loss: 0.022184
 >> iter 44000, loss: 0.034954
 >> iter 45000, loss: 0.028943
 >> iter 46000, loss: 0.023725
 >> iter 47000, loss: 0.049251
 >> iter 48000, loss: 0.043967
 >> iter 49000, loss: 0.042828
 >> iter 50000, loss: 0.038911
   Number of active neurons: 2
 >> iter 51000, loss: 0.029836
 >> iter 52000, loss: 0.023539
 >> iter 53000, loss: 0.021689
 >> iter 54000, loss: 0.022696
 >> iter 55000, loss: 0.023636
 >> iter 56000, loss: 0.030852
 >> iter 57000, loss: 0.026134
 >> iter 58000, loss: 0.026130
 >> iter 59000, loss: 0.029422
 >> iter 60000, loss: 0.023204
   Number of active neurons: 2
 >> iter 61000, loss: 0.022733
 >> iter 62000, loss: 0.021866
 >> iter 63000, loss: 0.041487
 >> iter 64000, loss: 0.035531
 >> iter 65000, loss: 0.033208
 >> iter 66000, loss: 0.034338
 >> iter 67000, loss: 0.031229
 >> iter 68000, loss: 0.030396
 >> iter 69000, loss: 0.023421
 >> iter 70000, loss: 0.022901
   Number of active neurons: 2
 >> iter 71000, loss: 0.026339
 >> iter 72000, loss: 0.033555
 >> iter 73000, loss: 0.024201
 >> iter 74000, loss: 0.022759
 >> iter 75000, loss: 0.025190
 >> iter 76000, loss: 0.023451
 >> iter 77000, loss: 0.032909
 >> iter 78000, loss: 0.032029
 >> iter 79000, loss: 0.024292
 >> iter 80000, loss: 0.045763
   Number of active neurons: 1
 >> iter 81000, loss: 0.029667
 >> iter 82000, loss: 0.025517
 >> iter 83000, loss: 0.023760
 >> iter 84000, loss: 0.021016
 >> iter 85000, loss: 0.032683
 >> iter 86000, loss: 0.025722
 >> iter 87000, loss: 0.024090
 >> iter 88000, loss: 0.023708
 >> iter 89000, loss: 0.020398
 >> iter 90000, loss: 0.018120
   Number of active neurons: 1
 >> iter 91000, loss: 0.025737
 >> iter 92000, loss: 0.019570
 >> iter 93000, loss: 0.018928
 >> iter 94000, loss: 0.018151
 >> iter 95000, loss: 0.019905
 >> iter 96000, loss: 0.032573
 >> iter 97000, loss: 0.030568
 >> iter 98000, loss: 0.024867
 >> iter 99000, loss: 0.024847
 >> iter 100000, loss: 0.028945
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.907361
 >> iter 2000, loss: 4.055467
 >> iter 3000, loss: 1.522623
 >> iter 4000, loss: 0.584287
 >> iter 5000, loss: 0.232924
 >> iter 6000, loss: 0.104505
 >> iter 7000, loss: 0.055714
 >> iter 8000, loss: 0.050098
 >> iter 9000, loss: 0.036720
 >> iter 10000, loss: 0.032843
   Number of active neurons: 3
 >> iter 11000, loss: 0.029242
 >> iter 12000, loss: 0.026129
 >> iter 13000, loss: 0.031350
 >> iter 14000, loss: 0.027275
 >> iter 15000, loss: 0.023677
 >> iter 16000, loss: 0.026920
 >> iter 17000, loss: 0.027842
 >> iter 18000, loss: 0.025152
 >> iter 19000, loss: 0.033615
 >> iter 20000, loss: 0.030147
   Number of active neurons: 3
 >> iter 21000, loss: 0.026362
 >> iter 22000, loss: 0.024517
 >> iter 23000, loss: 0.026734
 >> iter 24000, loss: 0.026750
 >> iter 25000, loss: 0.024867
 >> iter 26000, loss: 0.037163
 >> iter 27000, loss: 0.031325
 >> iter 28000, loss: 0.025694
 >> iter 29000, loss: 0.024694
 >> iter 30000, loss: 0.022733
   Number of active neurons: 3
 >> iter 31000, loss: 0.034220
 >> iter 32000, loss: 0.026129
 >> iter 33000, loss: 0.024052
 >> iter 34000, loss: 0.026887
 >> iter 35000, loss: 0.025660
 >> iter 36000, loss: 0.027366
 >> iter 37000, loss: 0.025274
 >> iter 38000, loss: 0.024300
 >> iter 39000, loss: 0.026020
 >> iter 40000, loss: 0.026643
   Number of active neurons: 3
 >> iter 41000, loss: 0.024486
 >> iter 42000, loss: 0.025800
 >> iter 43000, loss: 0.028870
 >> iter 44000, loss: 0.025878
 >> iter 45000, loss: 0.024310
 >> iter 46000, loss: 0.045640
 >> iter 47000, loss: 0.034297
 >> iter 48000, loss: 0.028326
 >> iter 49000, loss: 0.028678
 >> iter 50000, loss: 0.030010
   Number of active neurons: 3
 >> iter 51000, loss: 0.024602
 >> iter 52000, loss: 0.036823
 >> iter 53000, loss: 0.040321
 >> iter 54000, loss: 0.029031
 >> iter 55000, loss: 0.023595
 >> iter 56000, loss: 0.025990
 >> iter 57000, loss: 0.029893
 >> iter 58000, loss: 0.025217
 >> iter 59000, loss: 0.077521
 >> iter 60000, loss: 0.052386
   Number of active neurons: 2
 >> iter 61000, loss: 0.043059
 >> iter 62000, loss: 0.029344
 >> iter 63000, loss: 0.038433
 >> iter 64000, loss: 0.028994
 >> iter 65000, loss: 0.046742
 >> iter 66000, loss: 0.031731
 >> iter 67000, loss: 0.028751
 >> iter 68000, loss: 0.034394
 >> iter 69000, loss: 0.025810
 >> iter 70000, loss: 0.023293
   Number of active neurons: 2
 >> iter 71000, loss: 0.025453
 >> iter 72000, loss: 0.025182
 >> iter 73000, loss: 0.028918
 >> iter 74000, loss: 0.021987
 >> iter 75000, loss: 0.028189
 >> iter 76000, loss: 0.022417
 >> iter 77000, loss: 0.025396
 >> iter 78000, loss: 0.023674
 >> iter 79000, loss: 0.024027
 >> iter 80000, loss: 0.021287
   Number of active neurons: 1
 >> iter 81000, loss: 0.027126
 >> iter 82000, loss: 0.021493
 >> iter 83000, loss: 0.033959
 >> iter 84000, loss: 0.037437
 >> iter 85000, loss: 0.027237
 >> iter 86000, loss: 0.021247
 >> iter 87000, loss: 0.017326
 >> iter 88000, loss: 0.018376
 >> iter 89000, loss: 0.026427
 >> iter 90000, loss: 0.021929
   Number of active neurons: 1
 >> iter 91000, loss: 0.031146
 >> iter 92000, loss: 0.021910
 >> iter 93000, loss: 0.020592
 >> iter 94000, loss: 0.022176
 >> iter 95000, loss: 0.031049
 >> iter 96000, loss: 0.025234
 >> iter 97000, loss: 0.019990
 >> iter 98000, loss: 0.019442
 >> iter 99000, loss: 0.017502
 >> iter 100000, loss: 0.016200
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.984481
 >> iter 2000, loss: 4.083614
 >> iter 3000, loss: 1.524403
 >> iter 4000, loss: 0.584520
 >> iter 5000, loss: 0.236553
 >> iter 6000, loss: 0.109306
 >> iter 7000, loss: 0.059414
 >> iter 8000, loss: 0.038317
 >> iter 9000, loss: 0.031121
 >> iter 10000, loss: 0.037117
   Number of active neurons: 4
 >> iter 11000, loss: 0.027896
 >> iter 12000, loss: 0.027335
 >> iter 13000, loss: 0.047214
 >> iter 14000, loss: 0.035920
 >> iter 15000, loss: 0.030358
 >> iter 16000, loss: 0.030525
 >> iter 17000, loss: 0.027128
 >> iter 18000, loss: 0.034185
 >> iter 19000, loss: 0.032150
 >> iter 20000, loss: 0.034761
   Number of active neurons: 4
 >> iter 21000, loss: 0.030868
 >> iter 22000, loss: 0.027056
 >> iter 23000, loss: 0.026255
 >> iter 24000, loss: 0.024910
 >> iter 25000, loss: 0.026779
 >> iter 26000, loss: 0.026866
 >> iter 27000, loss: 0.027154
 >> iter 28000, loss: 0.026729
 >> iter 29000, loss: 0.027766
 >> iter 30000, loss: 0.027655
   Number of active neurons: 4
 >> iter 31000, loss: 0.040063
 >> iter 32000, loss: 0.032755
 >> iter 33000, loss: 0.031453
 >> iter 34000, loss: 0.028782
 >> iter 35000, loss: 0.030575
 >> iter 36000, loss: 0.030692
 >> iter 37000, loss: 0.027503
 >> iter 38000, loss: 0.025271
 >> iter 39000, loss: 0.030694
 >> iter 40000, loss: 0.027491
   Number of active neurons: 3
 >> iter 41000, loss: 0.027929
 >> iter 42000, loss: 0.032013
 >> iter 43000, loss: 0.027756
 >> iter 44000, loss: 0.032364
 >> iter 45000, loss: 0.026253
 >> iter 46000, loss: 0.036410
 >> iter 47000, loss: 0.028095
 >> iter 48000, loss: 0.026318
 >> iter 49000, loss: 0.023087
 >> iter 50000, loss: 0.023097
   Number of active neurons: 1
 >> iter 51000, loss: 0.031147
 >> iter 52000, loss: 0.025134
 >> iter 53000, loss: 0.021475
 >> iter 54000, loss: 0.018308
 >> iter 55000, loss: 0.017925
 >> iter 56000, loss: 0.024982
 >> iter 57000, loss: 0.023041
 >> iter 58000, loss: 0.020324
 >> iter 59000, loss: 0.018193
 >> iter 60000, loss: 0.021105
   Number of active neurons: 1
 >> iter 61000, loss: 0.019526
 >> iter 62000, loss: 0.016465
 >> iter 63000, loss: 0.032847
 >> iter 64000, loss: 0.027063
 >> iter 65000, loss: 0.034425
 >> iter 66000, loss: 0.028359
 >> iter 67000, loss: 0.022179
 >> iter 68000, loss: 0.019745
 >> iter 69000, loss: 0.021216
 >> iter 70000, loss: 0.039007
   Number of active neurons: 1
 >> iter 71000, loss: 0.026176
 >> iter 72000, loss: 0.019773
 >> iter 73000, loss: 0.018174
 >> iter 74000, loss: 0.017434
 >> iter 75000, loss: 0.018427
 >> iter 76000, loss: 0.018205
 >> iter 77000, loss: 0.022267
 >> iter 78000, loss: 0.018754
 >> iter 79000, loss: 0.016762
 >> iter 80000, loss: 0.045222
   Number of active neurons: 1
 >> iter 81000, loss: 0.027915
 >> iter 82000, loss: 0.028206
 >> iter 83000, loss: 0.039132
 >> iter 84000, loss: 0.024867
 >> iter 85000, loss: 0.027448
 >> iter 86000, loss: 0.022075
 >> iter 87000, loss: 0.025429
 >> iter 88000, loss: 0.026381
 >> iter 89000, loss: 0.020475
 >> iter 90000, loss: 0.020124
   Number of active neurons: 1
 >> iter 91000, loss: 0.026899
 >> iter 92000, loss: 0.040580
 >> iter 93000, loss: 0.025849
 >> iter 94000, loss: 0.029481
 >> iter 95000, loss: 0.025205
 >> iter 96000, loss: 0.020399
 >> iter 97000, loss: 0.023722
 >> iter 98000, loss: 0.021331
 >> iter 99000, loss: 0.019736
 >> iter 100000, loss: 0.017931
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.019423
 >> iter 2000, loss: 4.096664
 >> iter 3000, loss: 1.530490
 >> iter 4000, loss: 0.589008
 >> iter 5000, loss: 0.278864
 >> iter 6000, loss: 0.128549
 >> iter 7000, loss: 0.065879
 >> iter 8000, loss: 0.053349
 >> iter 9000, loss: 0.038518
 >> iter 10000, loss: 0.030327
   Number of active neurons: 5
 >> iter 11000, loss: 0.031570
 >> iter 12000, loss: 0.035823
 >> iter 13000, loss: 0.034612
 >> iter 14000, loss: 0.041884
 >> iter 15000, loss: 0.031417
 >> iter 16000, loss: 0.032724
 >> iter 17000, loss: 0.031567
 >> iter 18000, loss: 0.029474
 >> iter 19000, loss: 0.031027
 >> iter 20000, loss: 0.027616
   Number of active neurons: 3
 >> iter 21000, loss: 0.030242
 >> iter 22000, loss: 0.027416
 >> iter 23000, loss: 0.025065
 >> iter 24000, loss: 0.026660
 >> iter 25000, loss: 0.026049
 >> iter 26000, loss: 0.042945
 >> iter 27000, loss: 0.035238
 >> iter 28000, loss: 0.025843
 >> iter 29000, loss: 0.026201
 >> iter 30000, loss: 0.027890
   Number of active neurons: 2
 >> iter 31000, loss: 0.024730
 >> iter 32000, loss: 0.023955
 >> iter 33000, loss: 0.023197
 >> iter 34000, loss: 0.026556
 >> iter 35000, loss: 0.026213
 >> iter 36000, loss: 0.022015
 >> iter 37000, loss: 0.024577
 >> iter 38000, loss: 0.023347
 >> iter 39000, loss: 0.021870
 >> iter 40000, loss: 0.028434
   Number of active neurons: 2
 >> iter 41000, loss: 0.023322
 >> iter 42000, loss: 0.020912
 >> iter 43000, loss: 0.023325
 >> iter 44000, loss: 0.022868
 >> iter 45000, loss: 0.021537
 >> iter 46000, loss: 0.025092
 >> iter 47000, loss: 0.021520
 >> iter 48000, loss: 0.020861
 >> iter 49000, loss: 0.024845
 >> iter 50000, loss: 0.021533
   Number of active neurons: 2
 >> iter 51000, loss: 0.021874
 >> iter 52000, loss: 0.023338
 >> iter 53000, loss: 0.021755
 >> iter 54000, loss: 0.021739
 >> iter 55000, loss: 0.021766
 >> iter 56000, loss: 0.025912
 >> iter 57000, loss: 0.022586
 >> iter 58000, loss: 0.064776
 >> iter 59000, loss: 0.037468
 >> iter 60000, loss: 0.027246
   Number of active neurons: 1
 >> iter 61000, loss: 0.023473
 >> iter 62000, loss: 0.020781
 >> iter 63000, loss: 0.023274
 >> iter 64000, loss: 0.019536
 >> iter 65000, loss: 0.018311
 >> iter 66000, loss: 0.019143
 >> iter 67000, loss: 0.018268
 >> iter 68000, loss: 0.017459
 >> iter 69000, loss: 0.047521
 >> iter 70000, loss: 0.034052
   Number of active neurons: 1
 >> iter 71000, loss: 0.022976
 >> iter 72000, loss: 0.023778
 >> iter 73000, loss: 0.018919
 >> iter 74000, loss: 0.023400
 >> iter 75000, loss: 0.077196
 >> iter 76000, loss: 0.040399
 >> iter 77000, loss: 0.030471
 >> iter 78000, loss: 0.027397
 >> iter 79000, loss: 0.023875
 >> iter 80000, loss: 0.019714
   Number of active neurons: 1
 >> iter 81000, loss: 0.016755
 >> iter 82000, loss: 0.020617
 >> iter 83000, loss: 0.022386
 >> iter 84000, loss: 0.019951
 >> iter 85000, loss: 0.017469
 >> iter 86000, loss: 0.020229
 >> iter 87000, loss: 0.020430
 >> iter 88000, loss: 0.020721
 >> iter 89000, loss: 0.025099
 >> iter 90000, loss: 0.018455
   Number of active neurons: 1
 >> iter 91000, loss: 0.027305
 >> iter 92000, loss: 0.037191
 >> iter 93000, loss: 0.026809
 >> iter 94000, loss: 0.020575
 >> iter 95000, loss: 0.026980
 >> iter 96000, loss: 0.032885
 >> iter 97000, loss: 0.030574
 >> iter 98000, loss: 0.023954
 >> iter 99000, loss: 0.020119
 >> iter 100000, loss: 0.022507
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.958264
 >> iter 2000, loss: 4.085581
 >> iter 3000, loss: 1.538450
 >> iter 4000, loss: 0.593509
 >> iter 5000, loss: 0.234658
 >> iter 6000, loss: 0.107821
 >> iter 7000, loss: 0.061308
 >> iter 8000, loss: 0.042993
 >> iter 9000, loss: 0.030371
 >> iter 10000, loss: 0.027139
   Number of active neurons: 3
 >> iter 11000, loss: 0.027170
 >> iter 12000, loss: 0.027101
 >> iter 13000, loss: 0.028478
 >> iter 14000, loss: 0.036493
 >> iter 15000, loss: 0.045800
 >> iter 16000, loss: 0.033720
 >> iter 17000, loss: 0.033563
 >> iter 18000, loss: 0.027656
 >> iter 19000, loss: 0.024585
 >> iter 20000, loss: 0.024373
   Number of active neurons: 3
 >> iter 21000, loss: 0.029111
 >> iter 22000, loss: 0.037886
 >> iter 23000, loss: 0.030504
 >> iter 24000, loss: 0.029447
 >> iter 25000, loss: 0.026815
 >> iter 26000, loss: 0.030876
 >> iter 27000, loss: 0.036627
 >> iter 28000, loss: 0.028975
 >> iter 29000, loss: 0.026163
 >> iter 30000, loss: 0.038037
   Number of active neurons: 3
 >> iter 31000, loss: 0.028727
 >> iter 32000, loss: 0.027702
 >> iter 33000, loss: 0.029470
 >> iter 34000, loss: 0.025477
 >> iter 35000, loss: 0.031819
 >> iter 36000, loss: 0.029043
 >> iter 37000, loss: 0.039545
 >> iter 38000, loss: 0.046735
 >> iter 39000, loss: 0.032553
 >> iter 40000, loss: 0.029757
   Number of active neurons: 3
 >> iter 41000, loss: 0.027537
 >> iter 42000, loss: 0.027918
 >> iter 43000, loss: 0.026983
 >> iter 44000, loss: 0.033152
 >> iter 45000, loss: 0.030399
 >> iter 46000, loss: 0.027272
 >> iter 47000, loss: 0.041898
 >> iter 48000, loss: 0.030432
 >> iter 49000, loss: 0.049051
 >> iter 50000, loss: 0.039325
   Number of active neurons: 2
 >> iter 51000, loss: 0.029486
 >> iter 52000, loss: 0.029593
 >> iter 53000, loss: 0.023876
 >> iter 54000, loss: 0.027299
 >> iter 55000, loss: 0.028534
 >> iter 56000, loss: 0.024018
 >> iter 57000, loss: 0.021961
 >> iter 58000, loss: 0.038710
 >> iter 59000, loss: 0.037467
 >> iter 60000, loss: 0.025014
   Number of active neurons: 1
 >> iter 61000, loss: 0.036259
 >> iter 62000, loss: 0.033072
 >> iter 63000, loss: 0.035850
 >> iter 64000, loss: 0.023681
 >> iter 65000, loss: 0.023943
 >> iter 66000, loss: 0.019848
 >> iter 67000, loss: 0.045042
 >> iter 68000, loss: 0.027224
 >> iter 69000, loss: 0.021207
 >> iter 70000, loss: 0.019879
   Number of active neurons: 1
 >> iter 71000, loss: 0.019836
 >> iter 72000, loss: 0.022293
 >> iter 73000, loss: 0.022155
 >> iter 74000, loss: 0.019027
 >> iter 75000, loss: 0.018801
 >> iter 76000, loss: 0.020096
 >> iter 77000, loss: 0.021930
 >> iter 78000, loss: 0.025577
 >> iter 79000, loss: 0.020900
 >> iter 80000, loss: 0.022077
   Number of active neurons: 1
 >> iter 81000, loss: 0.035869
 >> iter 82000, loss: 0.024412
 >> iter 83000, loss: 0.026500
 >> iter 84000, loss: 0.022931
 >> iter 85000, loss: 0.057092
 >> iter 86000, loss: 0.031504
 >> iter 87000, loss: 0.022864
 >> iter 88000, loss: 0.035508
 >> iter 89000, loss: 0.031874
 >> iter 90000, loss: 0.043481
   Number of active neurons: 1
 >> iter 91000, loss: 0.029599
 >> iter 92000, loss: 0.022887
 >> iter 93000, loss: 0.020598
 >> iter 94000, loss: 0.032232
 >> iter 95000, loss: 0.038011
 >> iter 96000, loss: 0.027866
 >> iter 97000, loss: 0.023300
 >> iter 98000, loss: 0.019579
 >> iter 99000, loss: 0.022005
 >> iter 100000, loss: 0.024619
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.963510
 >> iter 2000, loss: 4.076337
 >> iter 3000, loss: 1.527722
 >> iter 4000, loss: 0.586091
 >> iter 5000, loss: 0.233838
 >> iter 6000, loss: 0.102628
 >> iter 7000, loss: 0.057604
 >> iter 8000, loss: 0.038422
 >> iter 9000, loss: 0.029705
 >> iter 10000, loss: 0.032390
   Number of active neurons: 4
 >> iter 11000, loss: 0.029568
 >> iter 12000, loss: 0.028020
 >> iter 13000, loss: 0.034343
 >> iter 14000, loss: 0.031036
 >> iter 15000, loss: 0.028886
 >> iter 16000, loss: 0.029269
 >> iter 17000, loss: 0.031507
 >> iter 18000, loss: 0.028238
 >> iter 19000, loss: 0.027984
 >> iter 20000, loss: 0.029857
   Number of active neurons: 3
 >> iter 21000, loss: 0.025768
 >> iter 22000, loss: 0.022569
 >> iter 23000, loss: 0.026726
 >> iter 24000, loss: 0.029723
 >> iter 25000, loss: 0.026714
 >> iter 26000, loss: 0.023413
 >> iter 27000, loss: 0.024026
 >> iter 28000, loss: 0.023591
 >> iter 29000, loss: 0.023089
 >> iter 30000, loss: 0.021911
   Number of active neurons: 2
 >> iter 31000, loss: 0.020788
 >> iter 32000, loss: 0.026145
 >> iter 33000, loss: 0.023590
 >> iter 34000, loss: 0.020540
 >> iter 35000, loss: 0.021176
 >> iter 36000, loss: 0.020725
 >> iter 37000, loss: 0.022308
 >> iter 38000, loss: 0.022878
 >> iter 39000, loss: 0.037570
 >> iter 40000, loss: 0.046756
   Number of active neurons: 2
 >> iter 41000, loss: 0.032610
 >> iter 42000, loss: 0.036130
 >> iter 43000, loss: 0.038361
 >> iter 44000, loss: 0.027468
 >> iter 45000, loss: 0.024743
 >> iter 46000, loss: 0.021588
 >> iter 47000, loss: 0.029084
 >> iter 48000, loss: 0.026706
 >> iter 49000, loss: 0.052585
 >> iter 50000, loss: 0.031247
   Number of active neurons: 2
 >> iter 51000, loss: 0.025533
 >> iter 52000, loss: 0.035403
 >> iter 53000, loss: 0.032860
 >> iter 54000, loss: 0.024223
 >> iter 55000, loss: 0.032360
 >> iter 56000, loss: 0.026504
 >> iter 57000, loss: 0.038910
 >> iter 58000, loss: 0.030274
 >> iter 59000, loss: 0.026009
 >> iter 60000, loss: 0.022404
   Number of active neurons: 1
 >> iter 61000, loss: 0.022409
 >> iter 62000, loss: 0.018951
 >> iter 63000, loss: 0.029956
 >> iter 64000, loss: 0.026254
 >> iter 65000, loss: 0.021365
 >> iter 66000, loss: 0.022654
 >> iter 67000, loss: 0.021173
 >> iter 68000, loss: 0.017111
 >> iter 69000, loss: 0.025380
 >> iter 70000, loss: 0.019261
   Number of active neurons: 1
 >> iter 71000, loss: 0.019310
 >> iter 72000, loss: 0.020954
 >> iter 73000, loss: 0.022233
 >> iter 74000, loss: 0.019945
 >> iter 75000, loss: 0.033630
 >> iter 76000, loss: 0.021797
 >> iter 77000, loss: 0.021724
 >> iter 78000, loss: 0.021288
 >> iter 79000, loss: 0.018009
 >> iter 80000, loss: 0.018691
   Number of active neurons: 1
 >> iter 81000, loss: 0.023816
 >> iter 82000, loss: 0.018702
 >> iter 83000, loss: 0.019894
 >> iter 84000, loss: 0.016911
 >> iter 85000, loss: 0.018893
 >> iter 86000, loss: 0.020542
 >> iter 87000, loss: 0.018737
 >> iter 88000, loss: 0.020232
 >> iter 89000, loss: 0.025043
 >> iter 90000, loss: 0.024121
   Number of active neurons: 1
 >> iter 91000, loss: 0.034133
 >> iter 92000, loss: 0.023456
 >> iter 93000, loss: 0.037448
 >> iter 94000, loss: 0.030937
 >> iter 95000, loss: 0.029428
 >> iter 96000, loss: 0.020863
 >> iter 97000, loss: 0.024663
 >> iter 98000, loss: 0.020094
 >> iter 99000, loss: 0.018479
 >> iter 100000, loss: 0.017602
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.983351
 >> iter 2000, loss: 4.093326
 >> iter 3000, loss: 1.530927
 >> iter 4000, loss: 0.587270
 >> iter 5000, loss: 0.238481
 >> iter 6000, loss: 0.111323
 >> iter 7000, loss: 0.071875
 >> iter 8000, loss: 0.052043
 >> iter 9000, loss: 0.039952
 >> iter 10000, loss: 0.039885
   Number of active neurons: 5
 >> iter 11000, loss: 0.032609
 >> iter 12000, loss: 0.033233
 >> iter 13000, loss: 0.032146
 >> iter 14000, loss: 0.030479
 >> iter 15000, loss: 0.028213
 >> iter 16000, loss: 0.031033
 >> iter 17000, loss: 0.041337
 >> iter 18000, loss: 0.034075
 >> iter 19000, loss: 0.033128
 >> iter 20000, loss: 0.034221
   Number of active neurons: 5
 >> iter 21000, loss: 0.036062
 >> iter 22000, loss: 0.031019
 >> iter 23000, loss: 0.027202
 >> iter 24000, loss: 0.026800
 >> iter 25000, loss: 0.027169
 >> iter 26000, loss: 0.026739
 >> iter 27000, loss: 0.027314
 >> iter 28000, loss: 0.024166
 >> iter 29000, loss: 0.023646
 >> iter 30000, loss: 0.024275
   Number of active neurons: 3
 >> iter 31000, loss: 0.025659
 >> iter 32000, loss: 0.022806
 >> iter 33000, loss: 0.021733
 >> iter 34000, loss: 0.045454
 >> iter 35000, loss: 0.034277
 >> iter 36000, loss: 0.029607
 >> iter 37000, loss: 0.024532
 >> iter 38000, loss: 0.031024
 >> iter 39000, loss: 0.026192
 >> iter 40000, loss: 0.024998
   Number of active neurons: 2
 >> iter 41000, loss: 0.023756
 >> iter 42000, loss: 0.023625
 >> iter 43000, loss: 0.024147
 >> iter 44000, loss: 0.021412
 >> iter 45000, loss: 0.021395
 >> iter 46000, loss: 0.022686
 >> iter 47000, loss: 0.024855
 >> iter 48000, loss: 0.022143
 >> iter 49000, loss: 0.034730
 >> iter 50000, loss: 0.029976
   Number of active neurons: 2
 >> iter 51000, loss: 0.024004
 >> iter 52000, loss: 0.023842
 >> iter 53000, loss: 0.024183
 >> iter 54000, loss: 0.021365
 >> iter 55000, loss: 0.021563
 >> iter 56000, loss: 0.040519
 >> iter 57000, loss: 0.029031
 >> iter 58000, loss: 0.023655
 >> iter 59000, loss: 0.021633
 >> iter 60000, loss: 0.021034
   Number of active neurons: 2
 >> iter 61000, loss: 0.020959
 >> iter 62000, loss: 0.020984
 >> iter 63000, loss: 0.020668
 >> iter 64000, loss: 0.021500
 >> iter 65000, loss: 0.021925
 >> iter 66000, loss: 0.022428
 >> iter 67000, loss: 0.021817
 >> iter 68000, loss: 0.022050
 >> iter 69000, loss: 0.019651
 >> iter 70000, loss: 0.026220
   Number of active neurons: 2
 >> iter 71000, loss: 0.022820
 >> iter 72000, loss: 0.023240
 >> iter 73000, loss: 0.023433
 >> iter 74000, loss: 0.020596
 >> iter 75000, loss: 0.019511
 >> iter 76000, loss: 0.019517
 >> iter 77000, loss: 0.024943
 >> iter 78000, loss: 0.023282
 >> iter 79000, loss: 0.024212
 >> iter 80000, loss: 0.021167
   Number of active neurons: 2
 >> iter 81000, loss: 0.021980
 >> iter 82000, loss: 0.023023
 >> iter 83000, loss: 0.032251
 >> iter 84000, loss: 0.025479
 >> iter 85000, loss: 0.023015
 >> iter 86000, loss: 0.025039
 >> iter 87000, loss: 0.022182
 >> iter 88000, loss: 0.020972
 >> iter 89000, loss: 0.021766
 >> iter 90000, loss: 0.021279
   Number of active neurons: 2
 >> iter 91000, loss: 0.020290
 >> iter 92000, loss: 0.023001
 >> iter 93000, loss: 0.023103
 >> iter 94000, loss: 0.020999
 >> iter 95000, loss: 0.036526
 >> iter 96000, loss: 0.028962
 >> iter 97000, loss: 0.025759
 >> iter 98000, loss: 0.052494
 >> iter 99000, loss: 0.038297
 >> iter 100000, loss: 0.034343
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.947757
 >> iter 2000, loss: 4.070223
 >> iter 3000, loss: 1.519669
 >> iter 4000, loss: 0.577620
 >> iter 5000, loss: 0.236396
 >> iter 6000, loss: 0.106099
 >> iter 7000, loss: 0.056296
 >> iter 8000, loss: 0.037342
 >> iter 9000, loss: 0.033569
 >> iter 10000, loss: 0.037085
   Number of active neurons: 3
 >> iter 11000, loss: 0.030285
 >> iter 12000, loss: 0.026091
 >> iter 13000, loss: 0.029875
 >> iter 14000, loss: 0.033255
 >> iter 15000, loss: 0.030441
 >> iter 16000, loss: 0.027284
 >> iter 17000, loss: 0.025473
 >> iter 18000, loss: 0.023922
 >> iter 19000, loss: 0.023515
 >> iter 20000, loss: 0.037731
   Number of active neurons: 2
 >> iter 21000, loss: 0.032153
 >> iter 22000, loss: 0.027825
 >> iter 23000, loss: 0.027169
 >> iter 24000, loss: 0.022489
 >> iter 25000, loss: 0.023170
 >> iter 26000, loss: 0.025457
 >> iter 27000, loss: 0.022587
 >> iter 28000, loss: 0.023257
 >> iter 29000, loss: 0.023902
 >> iter 30000, loss: 0.022133
   Number of active neurons: 2
 >> iter 31000, loss: 0.031722
 >> iter 32000, loss: 0.023814
 >> iter 33000, loss: 0.024071
 >> iter 34000, loss: 0.021643
 >> iter 35000, loss: 0.020612
 >> iter 36000, loss: 0.021855
 >> iter 37000, loss: 0.023235
 >> iter 38000, loss: 0.025678
 >> iter 39000, loss: 0.022429
 >> iter 40000, loss: 0.022078
   Number of active neurons: 2
 >> iter 41000, loss: 0.022374
 >> iter 42000, loss: 0.021138
 >> iter 43000, loss: 0.038370
 >> iter 44000, loss: 0.027679
 >> iter 45000, loss: 0.027606
 >> iter 46000, loss: 0.024741
 >> iter 47000, loss: 0.026880
 >> iter 48000, loss: 0.028169
 >> iter 49000, loss: 0.028757
 >> iter 50000, loss: 0.027043
   Number of active neurons: 2
 >> iter 51000, loss: 0.025100
 >> iter 52000, loss: 0.021598
 >> iter 53000, loss: 0.021853
 >> iter 54000, loss: 0.021019
 >> iter 55000, loss: 0.024745
 >> iter 56000, loss: 0.023560
 >> iter 57000, loss: 0.032617
 >> iter 58000, loss: 0.025478
 >> iter 59000, loss: 0.021541
 >> iter 60000, loss: 0.021125
   Number of active neurons: 2
 >> iter 61000, loss: 0.023558
 >> iter 62000, loss: 0.020272
 >> iter 63000, loss: 0.028328
 >> iter 64000, loss: 0.022305
 >> iter 65000, loss: 0.027942
 >> iter 66000, loss: 0.047289
 >> iter 67000, loss: 0.034785
 >> iter 68000, loss: 0.026297
 >> iter 69000, loss: 0.024748
 >> iter 70000, loss: 0.025198
   Number of active neurons: 1
 >> iter 71000, loss: 0.023309
 >> iter 72000, loss: 0.019927
 >> iter 73000, loss: 0.023342
 >> iter 74000, loss: 0.021750
 >> iter 75000, loss: 0.049651
 >> iter 76000, loss: 0.035581
 >> iter 77000, loss: 0.026311
 >> iter 78000, loss: 0.022782
 >> iter 79000, loss: 0.023003
 >> iter 80000, loss: 0.018605
   Number of active neurons: 1
 >> iter 81000, loss: 0.016853
 >> iter 82000, loss: 0.020814
 >> iter 83000, loss: 0.017970
 >> iter 84000, loss: 0.019543
 >> iter 85000, loss: 0.048449
 >> iter 86000, loss: 0.036645
 >> iter 87000, loss: 0.025594
 >> iter 88000, loss: 0.028220
 >> iter 89000, loss: 0.021849
 >> iter 90000, loss: 0.021636
   Number of active neurons: 1
 >> iter 91000, loss: 0.017798
 >> iter 92000, loss: 0.030926
 >> iter 93000, loss: 0.022457
 >> iter 94000, loss: 0.020353
 >> iter 95000, loss: 0.039548
 >> iter 96000, loss: 0.043089
 >> iter 97000, loss: 0.030339
 >> iter 98000, loss: 0.024075
 >> iter 99000, loss: 0.045819
 >> iter 100000, loss: 0.057684
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.003729
 >> iter 2000, loss: 4.084567
 >> iter 3000, loss: 1.528614
 >> iter 4000, loss: 0.589656
 >> iter 5000, loss: 0.237215
 >> iter 6000, loss: 0.103423
 >> iter 7000, loss: 0.059275
 >> iter 8000, loss: 0.039192
 >> iter 9000, loss: 0.031675
 >> iter 10000, loss: 0.030219
   Number of active neurons: 3
 >> iter 11000, loss: 0.026061
 >> iter 12000, loss: 0.028252
 >> iter 13000, loss: 0.027724
 >> iter 14000, loss: 0.023350
 >> iter 15000, loss: 0.024879
 >> iter 16000, loss: 0.024658
 >> iter 17000, loss: 0.025116
 >> iter 18000, loss: 0.021745
 >> iter 19000, loss: 0.030743
 >> iter 20000, loss: 0.035983
   Number of active neurons: 2
 >> iter 21000, loss: 0.029168
 >> iter 22000, loss: 0.023499
 >> iter 23000, loss: 0.022233
 >> iter 24000, loss: 0.025251
 >> iter 25000, loss: 0.021554
 >> iter 26000, loss: 0.021285
 >> iter 27000, loss: 0.037815
 >> iter 28000, loss: 0.028757
 >> iter 29000, loss: 0.033447
 >> iter 30000, loss: 0.046612
   Number of active neurons: 2
 >> iter 31000, loss: 0.031312
 >> iter 32000, loss: 0.024702
 >> iter 33000, loss: 0.024230
 >> iter 34000, loss: 0.030236
 >> iter 35000, loss: 0.023483
 >> iter 36000, loss: 0.032682
 >> iter 37000, loss: 0.025302
 >> iter 38000, loss: 0.025782
 >> iter 39000, loss: 0.023462
 >> iter 40000, loss: 0.027467
   Number of active neurons: 2
 >> iter 41000, loss: 0.023027
 >> iter 42000, loss: 0.041701
 >> iter 43000, loss: 0.038313
 >> iter 44000, loss: 0.029595
 >> iter 45000, loss: 0.023104
 >> iter 46000, loss: 0.022686
 >> iter 47000, loss: 0.029096
 >> iter 48000, loss: 0.022667
 >> iter 49000, loss: 0.024554
 >> iter 50000, loss: 0.027077
   Number of active neurons: 2
 >> iter 51000, loss: 0.030491
 >> iter 52000, loss: 0.028774
 >> iter 53000, loss: 0.024889
 >> iter 54000, loss: 0.027150
 >> iter 55000, loss: 0.023684
 >> iter 56000, loss: 0.024941
 >> iter 57000, loss: 0.024373
 >> iter 58000, loss: 0.050921
 >> iter 59000, loss: 0.032963
 >> iter 60000, loss: 0.023940
   Number of active neurons: 1
 >> iter 61000, loss: 0.028016
 >> iter 62000, loss: 0.023179
 >> iter 63000, loss: 0.023383
 >> iter 64000, loss: 0.025127
 >> iter 65000, loss: 0.020593
 >> iter 66000, loss: 0.020281
 >> iter 67000, loss: 0.031003
 >> iter 68000, loss: 0.024642
 >> iter 69000, loss: 0.020997
 >> iter 70000, loss: 0.020531
   Number of active neurons: 1
 >> iter 71000, loss: 0.038312
 >> iter 72000, loss: 0.025121
 >> iter 73000, loss: 0.023125
 >> iter 74000, loss: 0.018958
 >> iter 75000, loss: 0.016635
 >> iter 76000, loss: 0.017566
 >> iter 77000, loss: 0.020904
 >> iter 78000, loss: 0.018620
 >> iter 79000, loss: 0.027127
 >> iter 80000, loss: 0.031984
   Number of active neurons: 1
 >> iter 81000, loss: 0.022273
 >> iter 82000, loss: 0.018655
 >> iter 83000, loss: 0.020347
 >> iter 84000, loss: 0.017969
 >> iter 85000, loss: 0.016741
 >> iter 86000, loss: 0.017747
 >> iter 87000, loss: 0.016394
 >> iter 88000, loss: 0.015733
 >> iter 89000, loss: 0.017936
 >> iter 90000, loss: 0.018083
   Number of active neurons: 1
 >> iter 91000, loss: 0.026283
 >> iter 92000, loss: 0.021356
 >> iter 93000, loss: 0.022619
 >> iter 94000, loss: 0.021167
 >> iter 95000, loss: 0.020901
 >> iter 96000, loss: 0.023486
 >> iter 97000, loss: 0.018865
 >> iter 98000, loss: 0.017611
 >> iter 99000, loss: 0.016067
 >> iter 100000, loss: 0.017286
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.927802
 >> iter 2000, loss: 4.066681
 >> iter 3000, loss: 1.524140
 >> iter 4000, loss: 0.623693
 >> iter 5000, loss: 0.251098
 >> iter 6000, loss: 0.115635
 >> iter 7000, loss: 0.067528
 >> iter 8000, loss: 0.046826
 >> iter 9000, loss: 0.046293
 >> iter 10000, loss: 0.038184
   Number of active neurons: 4
 >> iter 11000, loss: 0.037526
 >> iter 12000, loss: 0.033410
 >> iter 13000, loss: 0.035208
 >> iter 14000, loss: 0.030319
 >> iter 15000, loss: 0.029116
 >> iter 16000, loss: 0.028401
 >> iter 17000, loss: 0.030206
 >> iter 18000, loss: 0.030763
 >> iter 19000, loss: 0.034054
 >> iter 20000, loss: 0.028607
   Number of active neurons: 4
 >> iter 21000, loss: 0.029111
 >> iter 22000, loss: 0.028350
 >> iter 23000, loss: 0.031681
 >> iter 24000, loss: 0.026229
 >> iter 25000, loss: 0.027750
 >> iter 26000, loss: 0.025675
 >> iter 27000, loss: 0.034250
 >> iter 28000, loss: 0.027890
 >> iter 29000, loss: 0.025941
 >> iter 30000, loss: 0.032380
   Number of active neurons: 2
 >> iter 31000, loss: 0.027185
 >> iter 32000, loss: 0.046423
 >> iter 33000, loss: 0.044372
 >> iter 34000, loss: 0.030630
 >> iter 35000, loss: 0.025444
 >> iter 36000, loss: 0.021947
 >> iter 37000, loss: 0.020930
 >> iter 38000, loss: 0.020496
 >> iter 39000, loss: 0.027986
 >> iter 40000, loss: 0.022008
   Number of active neurons: 1
 >> iter 41000, loss: 0.022071
 >> iter 42000, loss: 0.018757
 >> iter 43000, loss: 0.028725
 >> iter 44000, loss: 0.034844
 >> iter 45000, loss: 0.024043
 >> iter 46000, loss: 0.024483
 >> iter 47000, loss: 0.020348
 >> iter 48000, loss: 0.021955
 >> iter 49000, loss: 0.022374
 >> iter 50000, loss: 0.033510
   Number of active neurons: 1
 >> iter 51000, loss: 0.023058
 >> iter 52000, loss: 0.018805
 >> iter 53000, loss: 0.016509
 >> iter 54000, loss: 0.017443
 >> iter 55000, loss: 0.018478
 >> iter 56000, loss: 0.017511
 >> iter 57000, loss: 0.023023
 >> iter 58000, loss: 0.019928
 >> iter 59000, loss: 0.026578
 >> iter 60000, loss: 0.019078
   Number of active neurons: 1
 >> iter 61000, loss: 0.017053
 >> iter 62000, loss: 0.031692
 >> iter 63000, loss: 0.032326
 >> iter 64000, loss: 0.027640
 >> iter 65000, loss: 0.020770
 >> iter 66000, loss: 0.019517
 >> iter 67000, loss: 0.026568
 >> iter 68000, loss: 0.021973
 >> iter 69000, loss: 0.030789
 >> iter 70000, loss: 0.030386
   Number of active neurons: 1
 >> iter 71000, loss: 0.021574
 >> iter 72000, loss: 0.018199
 >> iter 73000, loss: 0.019759
 >> iter 74000, loss: 0.029352
 >> iter 75000, loss: 0.026877
 >> iter 76000, loss: 0.049352
 >> iter 77000, loss: 0.028816
 >> iter 78000, loss: 0.020450
 >> iter 79000, loss: 0.022074
 >> iter 80000, loss: 0.029636
   Number of active neurons: 1
 >> iter 81000, loss: 0.041365
 >> iter 82000, loss: 0.032732
 >> iter 83000, loss: 0.031283
 >> iter 84000, loss: 0.022346
 >> iter 85000, loss: 0.021082
 >> iter 86000, loss: 0.020044
 >> iter 87000, loss: 0.020356
 >> iter 88000, loss: 0.017985
 >> iter 89000, loss: 0.016940
 >> iter 90000, loss: 0.016592
   Number of active neurons: 1
 >> iter 91000, loss: 0.018577
 >> iter 92000, loss: 0.018837
 >> iter 93000, loss: 0.018691
 >> iter 94000, loss: 0.017427
 >> iter 95000, loss: 0.018393
 >> iter 96000, loss: 0.022060
 >> iter 97000, loss: 0.018568
 >> iter 98000, loss: 0.019744
 >> iter 99000, loss: 0.018345
 >> iter 100000, loss: 0.017391
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 11.034992
 >> iter 2000, loss: 4.087308
 >> iter 3000, loss: 1.532594
 >> iter 4000, loss: 0.584809
 >> iter 5000, loss: 0.240574
 >> iter 6000, loss: 0.109111
 >> iter 7000, loss: 0.057315
 >> iter 8000, loss: 0.038040
 >> iter 9000, loss: 0.034228
 >> iter 10000, loss: 0.027885
   Number of active neurons: 4
 >> iter 11000, loss: 0.038109
 >> iter 12000, loss: 0.059096
 >> iter 13000, loss: 0.047853
 >> iter 14000, loss: 0.045640
 >> iter 15000, loss: 0.040598
 >> iter 16000, loss: 0.030618
 >> iter 17000, loss: 0.027390
 >> iter 18000, loss: 0.029196
 >> iter 19000, loss: 0.028255
 >> iter 20000, loss: 0.024235
   Number of active neurons: 3
 >> iter 21000, loss: 0.024469
 >> iter 22000, loss: 0.026181
 >> iter 23000, loss: 0.028602
 >> iter 24000, loss: 0.026129
 >> iter 25000, loss: 0.023915
 >> iter 26000, loss: 0.035621
 >> iter 27000, loss: 0.029140
 >> iter 28000, loss: 0.027780
 >> iter 29000, loss: 0.031242
 >> iter 30000, loss: 0.030889
   Number of active neurons: 3
 >> iter 31000, loss: 0.030448
 >> iter 32000, loss: 0.029422
 >> iter 33000, loss: 0.034006
 >> iter 34000, loss: 0.026983
 >> iter 35000, loss: 0.025061
 >> iter 36000, loss: 0.023173
 >> iter 37000, loss: 0.024104
 >> iter 38000, loss: 0.021723
 >> iter 39000, loss: 0.019749
 >> iter 40000, loss: 0.025655
   Number of active neurons: 1
 >> iter 41000, loss: 0.024809
 >> iter 42000, loss: 0.021521
 >> iter 43000, loss: 0.018671
 >> iter 44000, loss: 0.017490
 >> iter 45000, loss: 0.017742
 >> iter 46000, loss: 0.018162
 >> iter 47000, loss: 0.019254
 >> iter 48000, loss: 0.019571
 >> iter 49000, loss: 0.022629
 >> iter 50000, loss: 0.019832
   Number of active neurons: 1
 >> iter 51000, loss: 0.027455
 >> iter 52000, loss: 0.021124
 >> iter 53000, loss: 0.019330
 >> iter 54000, loss: 0.021395
 >> iter 55000, loss: 0.017611
 >> iter 56000, loss: 0.016696
 >> iter 57000, loss: 0.019446
 >> iter 58000, loss: 0.031788
 >> iter 59000, loss: 0.022891
 >> iter 60000, loss: 0.019725
   Number of active neurons: 1
 >> iter 61000, loss: 0.022165
 >> iter 62000, loss: 0.018508
 >> iter 63000, loss: 0.017630
 >> iter 64000, loss: 0.016448
 >> iter 65000, loss: 0.021780
 >> iter 66000, loss: 0.017541
 >> iter 67000, loss: 0.021733
 >> iter 68000, loss: 0.019135
 >> iter 69000, loss: 0.017783
 >> iter 70000, loss: 0.017391
   Number of active neurons: 1
 >> iter 71000, loss: 0.015951
 >> iter 72000, loss: 0.031535
 >> iter 73000, loss: 0.035379
 >> iter 74000, loss: 0.024237
 >> iter 75000, loss: 0.025081
 >> iter 76000, loss: 0.030234
 >> iter 77000, loss: 0.025086
 >> iter 78000, loss: 0.019612
 >> iter 79000, loss: 0.018832
 >> iter 80000, loss: 0.029624
   Number of active neurons: 1
 >> iter 81000, loss: 0.022304
 >> iter 82000, loss: 0.024116
 >> iter 83000, loss: 0.026185
 >> iter 84000, loss: 0.020909
 >> iter 85000, loss: 0.029104
 >> iter 86000, loss: 0.030310
 >> iter 87000, loss: 0.021732
 >> iter 88000, loss: 0.018028
 >> iter 89000, loss: 0.032854
 >> iter 90000, loss: 0.024706
   Number of active neurons: 1
 >> iter 91000, loss: 0.025619
 >> iter 92000, loss: 0.024498
 >> iter 93000, loss: 0.019690
 >> iter 94000, loss: 0.017914
 >> iter 95000, loss: 0.019200
 >> iter 96000, loss: 0.016519
 >> iter 97000, loss: 0.016148
 >> iter 98000, loss: 0.022778
 >> iter 99000, loss: 0.042136
 >> iter 100000, loss: 0.027140
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 10.979479
 >> iter 2000, loss: 4.081082
 >> iter 3000, loss: 1.522571
 >> iter 4000, loss: 0.614211
 >> iter 5000, loss: 0.247948
 >> iter 6000, loss: 0.119775
 >> iter 7000, loss: 0.061521
 >> iter 8000, loss: 0.044198
 >> iter 9000, loss: 0.032108
 >> iter 10000, loss: 0.031549
   Number of active neurons: 5
 >> iter 11000, loss: 0.033758
 >> iter 12000, loss: 0.036984
 >> iter 13000, loss: 0.029516
 >> iter 14000, loss: 0.055778
 >> iter 15000, loss: 0.050296
 >> iter 16000, loss: 0.036878
 >> iter 17000, loss: 0.030562
 >> iter 18000, loss: 0.031443
 >> iter 19000, loss: 0.044229
 >> iter 20000, loss: 0.044753
   Number of active neurons: 4
 >> iter 21000, loss: 0.034165
 >> iter 22000, loss: 0.027035
 >> iter 23000, loss: 0.025391
 >> iter 24000, loss: 0.041489
 >> iter 25000, loss: 0.035458
 >> iter 26000, loss: 0.027989
 >> iter 27000, loss: 0.029981
 >> iter 28000, loss: 0.030064
 >> iter 29000, loss: 0.030294
 >> iter 30000, loss: 0.026264
   Number of active neurons: 3
 >> iter 31000, loss: 0.025240
 >> iter 32000, loss: 0.028336
 >> iter 33000, loss: 0.029838
 >> iter 34000, loss: 0.025642
 >> iter 35000, loss: 0.025669
 >> iter 36000, loss: 0.051285
 >> iter 37000, loss: 0.034773
 >> iter 38000, loss: 0.028501
 >> iter 39000, loss: 0.025532
 >> iter 40000, loss: 0.024910
   Number of active neurons: 3
 >> iter 41000, loss: 0.026351
 >> iter 42000, loss: 0.023625
 >> iter 43000, loss: 0.022047
 >> iter 44000, loss: 0.021820
 >> iter 45000, loss: 0.025566
 >> iter 46000, loss: 0.023178
 >> iter 47000, loss: 0.022080
 >> iter 48000, loss: 0.022490
 >> iter 49000, loss: 0.021222
 >> iter 50000, loss: 0.032508
   Number of active neurons: 2
 >> iter 51000, loss: 0.028873
 >> iter 52000, loss: 0.024943
 >> iter 53000, loss: 0.022970
 >> iter 54000, loss: 0.020561
 >> iter 55000, loss: 0.023399
 >> iter 56000, loss: 0.024412
 >> iter 57000, loss: 0.021400
 >> iter 58000, loss: 0.021809
 >> iter 59000, loss: 0.023007
 >> iter 60000, loss: 0.028175
   Number of active neurons: 2
 >> iter 61000, loss: 0.023561
 >> iter 62000, loss: 0.032454
 >> iter 63000, loss: 0.028505
 >> iter 64000, loss: 0.024428
 >> iter 65000, loss: 0.037804
 >> iter 66000, loss: 0.028338
 >> iter 67000, loss: 0.029589
 >> iter 68000, loss: 0.042918
 >> iter 69000, loss: 0.033378
 >> iter 70000, loss: 0.025433
   Number of active neurons: 2
 >> iter 71000, loss: 0.048018
 >> iter 72000, loss: 0.034881
 >> iter 73000, loss: 0.025627
 >> iter 74000, loss: 0.027217
 >> iter 75000, loss: 0.024728
 >> iter 76000, loss: 0.021658
 >> iter 77000, loss: 0.021327
 >> iter 78000, loss: 0.021809
 >> iter 79000, loss: 0.023466
 >> iter 80000, loss: 0.022163
   Number of active neurons: 2
 >> iter 81000, loss: 0.026841
 >> iter 82000, loss: 0.030672
 >> iter 83000, loss: 0.028059
 >> iter 84000, loss: 0.025119
 >> iter 85000, loss: 0.025960
 >> iter 86000, loss: 0.040072
 >> iter 87000, loss: 0.029316
 >> iter 88000, loss: 0.022775
 >> iter 89000, loss: 0.028916
 >> iter 90000, loss: 0.037716
   Number of active neurons: 2
 >> iter 91000, loss: 0.041349
 >> iter 92000, loss: 0.030087
 >> iter 93000, loss: 0.024104
 >> iter 94000, loss: 0.032858
 >> iter 95000, loss: 0.032378
 >> iter 96000, loss: 0.045556
 >> iter 97000, loss: 0.029455
 >> iter 98000, loss: 0.025009
 >> iter 99000, loss: 0.023615
 >> iter 100000, loss: 0.023798
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.970437
 >> iter 2000, loss: 4.076594
 >> iter 3000, loss: 1.525341
 >> iter 4000, loss: 0.585923
 >> iter 5000, loss: 0.238216
 >> iter 6000, loss: 0.106486
 >> iter 7000, loss: 0.068639
 >> iter 8000, loss: 0.043941
 >> iter 9000, loss: 0.034505
 >> iter 10000, loss: 0.037316
   Number of active neurons: 4
 >> iter 11000, loss: 0.031993
 >> iter 12000, loss: 0.029649
 >> iter 13000, loss: 0.028556
 >> iter 14000, loss: 0.026013
 >> iter 15000, loss: 0.026172
 >> iter 16000, loss: 0.025495
 >> iter 17000, loss: 0.030762
 >> iter 18000, loss: 0.028527
 >> iter 19000, loss: 0.027469
 >> iter 20000, loss: 0.026817
   Number of active neurons: 4
 >> iter 21000, loss: 0.030009
 >> iter 22000, loss: 0.028189
 >> iter 23000, loss: 0.027604
 >> iter 24000, loss: 0.043145
 >> iter 25000, loss: 0.030846
 >> iter 26000, loss: 0.037760
 >> iter 27000, loss: 0.033458
 >> iter 28000, loss: 0.037341
 >> iter 29000, loss: 0.035934
 >> iter 30000, loss: 0.031678
   Number of active neurons: 4
 >> iter 31000, loss: 0.034789
 >> iter 32000, loss: 0.029581
 >> iter 33000, loss: 0.027412
 >> iter 34000, loss: 0.024704
 >> iter 35000, loss: 0.026135
 >> iter 36000, loss: 0.025589
 >> iter 37000, loss: 0.028805
 >> iter 38000, loss: 0.027138
 >> iter 39000, loss: 0.083329
 >> iter 40000, loss: 0.047487
   Number of active neurons: 2
 >> iter 41000, loss: 0.041903
 >> iter 42000, loss: 0.031377
 >> iter 43000, loss: 0.040363
 >> iter 44000, loss: 0.029820
 >> iter 45000, loss: 0.030238
 >> iter 46000, loss: 0.024985
 >> iter 47000, loss: 0.023199
 >> iter 48000, loss: 0.020752
 >> iter 49000, loss: 0.025886
 >> iter 50000, loss: 0.026403
   Number of active neurons: 2
 >> iter 51000, loss: 0.035567
 >> iter 52000, loss: 0.024789
 >> iter 53000, loss: 0.023393
 >> iter 54000, loss: 0.023562
 >> iter 55000, loss: 0.027384
 >> iter 56000, loss: 0.037585
 >> iter 57000, loss: 0.026039
 >> iter 58000, loss: 0.025149
 >> iter 59000, loss: 0.026880
 >> iter 60000, loss: 0.021402
   Number of active neurons: 1
 >> iter 61000, loss: 0.020279
 >> iter 62000, loss: 0.027014
 >> iter 63000, loss: 0.021964
 >> iter 64000, loss: 0.019798
 >> iter 65000, loss: 0.018862
 >> iter 66000, loss: 0.023197
 >> iter 67000, loss: 0.047501
 >> iter 68000, loss: 0.030748
 >> iter 69000, loss: 0.029750
 >> iter 70000, loss: 0.030372
   Number of active neurons: 1
 >> iter 71000, loss: 0.020762
 >> iter 72000, loss: 0.018137
 >> iter 73000, loss: 0.020358
 >> iter 74000, loss: 0.029473
 >> iter 75000, loss: 0.026335
 >> iter 76000, loss: 0.020785
 >> iter 77000, loss: 0.018319
 >> iter 78000, loss: 0.048492
 >> iter 79000, loss: 0.031144
 >> iter 80000, loss: 0.028976
   Number of active neurons: 1
 >> iter 81000, loss: 0.022913
 >> iter 82000, loss: 0.020149
 >> iter 83000, loss: 0.035563
 >> iter 84000, loss: 0.026666
 >> iter 85000, loss: 0.020243
 >> iter 86000, loss: 0.020652
 >> iter 87000, loss: 0.021401
 >> iter 88000, loss: 0.026278
 >> iter 89000, loss: 0.019764
 >> iter 90000, loss: 0.017203
   Number of active neurons: 1
 >> iter 91000, loss: 0.017254
 >> iter 92000, loss: 0.025301
 >> iter 93000, loss: 0.020169
 >> iter 94000, loss: 0.019568
 >> iter 95000, loss: 0.018712
 >> iter 96000, loss: 0.016858
 >> iter 97000, loss: 0.019839
 >> iter 98000, loss: 0.017604
 >> iter 99000, loss: 0.017896
 >> iter 100000, loss: 0.034146
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.931898
 >> iter 2000, loss: 4.064460
 >> iter 3000, loss: 1.524311
 >> iter 4000, loss: 0.580456
 >> iter 5000, loss: 0.237913
 >> iter 6000, loss: 0.105598
 >> iter 7000, loss: 0.053819
 >> iter 8000, loss: 0.037928
 >> iter 9000, loss: 0.028280
 >> iter 10000, loss: 0.027160
   Number of active neurons: 2
 >> iter 11000, loss: 0.022381
 >> iter 12000, loss: 0.026509
 >> iter 13000, loss: 0.027123
 >> iter 14000, loss: 0.036034
 >> iter 15000, loss: 0.025927
 >> iter 16000, loss: 0.023982
 >> iter 17000, loss: 0.032081
 >> iter 18000, loss: 0.025734
 >> iter 19000, loss: 0.025346
 >> iter 20000, loss: 0.024116
   Number of active neurons: 2
 >> iter 21000, loss: 0.028016
 >> iter 22000, loss: 0.023186
 >> iter 23000, loss: 0.020957
 >> iter 24000, loss: 0.019184
 >> iter 25000, loss: 0.022795
 >> iter 26000, loss: 0.022083
 >> iter 27000, loss: 0.022186
 >> iter 28000, loss: 0.028451
 >> iter 29000, loss: 0.023067
 >> iter 30000, loss: 0.025963
   Number of active neurons: 2
 >> iter 31000, loss: 0.029752
 >> iter 32000, loss: 0.024389
 >> iter 33000, loss: 0.022365
 >> iter 34000, loss: 0.020625
 >> iter 35000, loss: 0.023793
 >> iter 36000, loss: 0.041891
 >> iter 37000, loss: 0.043010
 >> iter 38000, loss: 0.031507
 >> iter 39000, loss: 0.025674
 >> iter 40000, loss: 0.021085
   Number of active neurons: 2
 >> iter 41000, loss: 0.020682
 >> iter 42000, loss: 0.022105
 >> iter 43000, loss: 0.021571
 >> iter 44000, loss: 0.021163
 >> iter 45000, loss: 0.021886
 >> iter 46000, loss: 0.022037
 >> iter 47000, loss: 0.021297
 >> iter 48000, loss: 0.021167
 >> iter 49000, loss: 0.021257
 >> iter 50000, loss: 0.019539
   Number of active neurons: 2
 >> iter 51000, loss: 0.022841
 >> iter 52000, loss: 0.025944
 >> iter 53000, loss: 0.025293
 >> iter 54000, loss: 0.031078
 >> iter 55000, loss: 0.025108
 >> iter 56000, loss: 0.021744
 >> iter 57000, loss: 0.021984
 >> iter 58000, loss: 0.030513
 >> iter 59000, loss: 0.024330
 >> iter 60000, loss: 0.023123
   Number of active neurons: 2
 >> iter 61000, loss: 0.032440
 >> iter 62000, loss: 0.039290
 >> iter 63000, loss: 0.034982
 >> iter 64000, loss: 0.028438
 >> iter 65000, loss: 0.032987
 >> iter 66000, loss: 0.026227
 >> iter 67000, loss: 0.022309
 >> iter 68000, loss: 0.022868
 >> iter 69000, loss: 0.032687
 >> iter 70000, loss: 0.031751
   Number of active neurons: 2
 >> iter 71000, loss: 0.029455
 >> iter 72000, loss: 0.029409
 >> iter 73000, loss: 0.026461
 >> iter 74000, loss: 0.024086
 >> iter 75000, loss: 0.034098
 >> iter 76000, loss: 0.028664
 >> iter 77000, loss: 0.022105
 >> iter 78000, loss: 0.035654
 >> iter 79000, loss: 0.026862
 >> iter 80000, loss: 0.022690
   Number of active neurons: 2
 >> iter 81000, loss: 0.022708
 >> iter 82000, loss: 0.025531
 >> iter 83000, loss: 0.026213
 >> iter 84000, loss: 0.022894
 >> iter 85000, loss: 0.032161
 >> iter 86000, loss: 0.027384
 >> iter 87000, loss: 0.026432
 >> iter 88000, loss: 0.021777
 >> iter 89000, loss: 0.025749
 >> iter 90000, loss: 0.023151
   Number of active neurons: 1
 >> iter 91000, loss: 0.024304
 >> iter 92000, loss: 0.023847
 >> iter 93000, loss: 0.027221
 >> iter 94000, loss: 0.022376
 >> iter 95000, loss: 0.022871
 >> iter 96000, loss: 0.019497
 >> iter 97000, loss: 0.030184
 >> iter 98000, loss: 0.021146
 >> iter 99000, loss: 0.018069
 >> iter 100000, loss: 0.018055
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.982424
 >> iter 2000, loss: 4.080560
 >> iter 3000, loss: 1.525877
 >> iter 4000, loss: 0.588691
 >> iter 5000, loss: 0.238874
 >> iter 6000, loss: 0.113415
 >> iter 7000, loss: 0.065978
 >> iter 8000, loss: 0.040787
 >> iter 9000, loss: 0.037040
 >> iter 10000, loss: 0.029692
   Number of active neurons: 4
 >> iter 11000, loss: 0.029523
 >> iter 12000, loss: 0.028576
 >> iter 13000, loss: 0.048360
 >> iter 14000, loss: 0.032758
 >> iter 15000, loss: 0.034528
 >> iter 16000, loss: 0.026431
 >> iter 17000, loss: 0.028130
 >> iter 18000, loss: 0.030709
 >> iter 19000, loss: 0.025456
 >> iter 20000, loss: 0.028412
   Number of active neurons: 3
 >> iter 21000, loss: 0.023838
 >> iter 22000, loss: 0.025694
 >> iter 23000, loss: 0.024231
 >> iter 24000, loss: 0.029532
 >> iter 25000, loss: 0.024148
 >> iter 26000, loss: 0.025785
 >> iter 27000, loss: 0.030580
 >> iter 28000, loss: 0.025083
 >> iter 29000, loss: 0.023964
 >> iter 30000, loss: 0.027147
   Number of active neurons: 3
 >> iter 31000, loss: 0.032119
 >> iter 32000, loss: 0.028150
 >> iter 33000, loss: 0.024063
 >> iter 34000, loss: 0.023397
 >> iter 35000, loss: 0.022316
 >> iter 36000, loss: 0.022366
 >> iter 37000, loss: 0.020817
 >> iter 38000, loss: 0.022787
 >> iter 39000, loss: 0.030126
 >> iter 40000, loss: 0.023208
   Number of active neurons: 2
 >> iter 41000, loss: 0.026634
 >> iter 42000, loss: 0.024297
 >> iter 43000, loss: 0.022543
 >> iter 44000, loss: 0.021473
 >> iter 45000, loss: 0.039039
 >> iter 46000, loss: 0.028136
 >> iter 47000, loss: 0.024993
 >> iter 48000, loss: 0.055215
 >> iter 49000, loss: 0.033343
 >> iter 50000, loss: 0.027885
   Number of active neurons: 2
 >> iter 51000, loss: 0.025516
 >> iter 52000, loss: 0.032352
 >> iter 53000, loss: 0.027960
 >> iter 54000, loss: 0.025447
 >> iter 55000, loss: 0.023061
 >> iter 56000, loss: 0.022644
 >> iter 57000, loss: 0.023072
 >> iter 58000, loss: 0.020985
 >> iter 59000, loss: 0.020353
 >> iter 60000, loss: 0.019516
   Number of active neurons: 2
 >> iter 61000, loss: 0.020183
 >> iter 62000, loss: 0.022234
 >> iter 63000, loss: 0.021356
 >> iter 64000, loss: 0.027460
 >> iter 65000, loss: 0.021587
 >> iter 66000, loss: 0.020664
 >> iter 67000, loss: 0.024551
 >> iter 68000, loss: 0.026876
 >> iter 69000, loss: 0.020677
 >> iter 70000, loss: 0.028644
   Number of active neurons: 2
 >> iter 71000, loss: 0.023454
 >> iter 72000, loss: 0.036609
 >> iter 73000, loss: 0.032002
 >> iter 74000, loss: 0.024277
 >> iter 75000, loss: 0.023313
 >> iter 76000, loss: 0.026408
 >> iter 77000, loss: 0.027012
 >> iter 78000, loss: 0.022300
 >> iter 79000, loss: 0.023319
 >> iter 80000, loss: 0.021029
   Number of active neurons: 2
 >> iter 81000, loss: 0.025786
 >> iter 82000, loss: 0.021375
 >> iter 83000, loss: 0.020565
 >> iter 84000, loss: 0.019481
 >> iter 85000, loss: 0.024206
 >> iter 86000, loss: 0.020940
 >> iter 87000, loss: 0.024451
 >> iter 88000, loss: 0.022160
 >> iter 89000, loss: 0.022370
 >> iter 90000, loss: 0.022233
   Number of active neurons: 2
 >> iter 91000, loss: 0.022982
 >> iter 92000, loss: 0.022200
 >> iter 93000, loss: 0.022178
 >> iter 94000, loss: 0.022229
 >> iter 95000, loss: 0.022434
 >> iter 96000, loss: 0.021555
 >> iter 97000, loss: 0.032384
 >> iter 98000, loss: 0.024183
 >> iter 99000, loss: 0.026349
 >> iter 100000, loss: 0.022326
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.996975
 >> iter 2000, loss: 4.087900
 >> iter 3000, loss: 1.530679
 >> iter 4000, loss: 0.589701
 >> iter 5000, loss: 0.248345
 >> iter 6000, loss: 0.107683
 >> iter 7000, loss: 0.056400
 >> iter 8000, loss: 0.036616
 >> iter 9000, loss: 0.052904
 >> iter 10000, loss: 0.048341
   Number of active neurons: 4
 >> iter 11000, loss: 0.039232
 >> iter 12000, loss: 0.032601
 >> iter 13000, loss: 0.029936
 >> iter 14000, loss: 0.029671
 >> iter 15000, loss: 0.028901
 >> iter 16000, loss: 0.028991
 >> iter 17000, loss: 0.035360
 >> iter 18000, loss: 0.027964
 >> iter 19000, loss: 0.043997
 >> iter 20000, loss: 0.033437
   Number of active neurons: 3
 >> iter 21000, loss: 0.030347
 >> iter 22000, loss: 0.032683
 >> iter 23000, loss: 0.028806
 >> iter 24000, loss: 0.026348
 >> iter 25000, loss: 0.023869
 >> iter 26000, loss: 0.027890
 >> iter 27000, loss: 0.024410
 >> iter 28000, loss: 0.023058
 >> iter 29000, loss: 0.023509
 >> iter 30000, loss: 0.025702
   Number of active neurons: 2
 >> iter 31000, loss: 0.025512
 >> iter 32000, loss: 0.022663
 >> iter 33000, loss: 0.022993
 >> iter 34000, loss: 0.022093
 >> iter 35000, loss: 0.022031
 >> iter 36000, loss: 0.021601
 >> iter 37000, loss: 0.035342
 >> iter 38000, loss: 0.027950
 >> iter 39000, loss: 0.023215
 >> iter 40000, loss: 0.021690
   Number of active neurons: 2
 >> iter 41000, loss: 0.024123
 >> iter 42000, loss: 0.020603
 >> iter 43000, loss: 0.022866
 >> iter 44000, loss: 0.024753
 >> iter 45000, loss: 0.022986
 >> iter 46000, loss: 0.020653
 >> iter 47000, loss: 0.023481
 >> iter 48000, loss: 0.023155
 >> iter 49000, loss: 0.021441
 >> iter 50000, loss: 0.022499
   Number of active neurons: 2
 >> iter 51000, loss: 0.022116
 >> iter 52000, loss: 0.022371
 >> iter 53000, loss: 0.021093
 >> iter 54000, loss: 0.020179
 >> iter 55000, loss: 0.019885
 >> iter 56000, loss: 0.021651
 >> iter 57000, loss: 0.021130
 >> iter 58000, loss: 0.036954
 >> iter 59000, loss: 0.038210
 >> iter 60000, loss: 0.035430
   Number of active neurons: 2
 >> iter 61000, loss: 0.030741
 >> iter 62000, loss: 0.025949
 >> iter 63000, loss: 0.024347
 >> iter 64000, loss: 0.023668
 >> iter 65000, loss: 0.021819
 >> iter 66000, loss: 0.033251
 >> iter 67000, loss: 0.028604
 >> iter 68000, loss: 0.024564
 >> iter 69000, loss: 0.024293
 >> iter 70000, loss: 0.021411
   Number of active neurons: 2
 >> iter 71000, loss: 0.024754
 >> iter 72000, loss: 0.023784
 >> iter 73000, loss: 0.035714
 >> iter 74000, loss: 0.030387
 >> iter 75000, loss: 0.026331
 >> iter 76000, loss: 0.022180
 >> iter 77000, loss: 0.025766
 >> iter 78000, loss: 0.029551
 >> iter 79000, loss: 0.022597
 >> iter 80000, loss: 0.022448
   Number of active neurons: 2
 >> iter 81000, loss: 0.030246
 >> iter 82000, loss: 0.023172
 >> iter 83000, loss: 0.022941
 >> iter 84000, loss: 0.027771
 >> iter 85000, loss: 0.025822
 >> iter 86000, loss: 0.024028
 >> iter 87000, loss: 0.035318
 >> iter 88000, loss: 0.031994
 >> iter 89000, loss: 0.024132
 >> iter 90000, loss: 0.025917
   Number of active neurons: 2
 >> iter 91000, loss: 0.022781
 >> iter 92000, loss: 0.024413
 >> iter 93000, loss: 0.025081
 >> iter 94000, loss: 0.020268
 >> iter 95000, loss: 0.018956
 >> iter 96000, loss: 0.020237
 >> iter 97000, loss: 0.018955
 >> iter 98000, loss: 0.022094
 >> iter 99000, loss: 0.019620
 >> iter 100000, loss: 0.020560
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.990477
 >> iter 2000, loss: 4.078369
 >> iter 3000, loss: 1.523417
 >> iter 4000, loss: 0.583605
 >> iter 5000, loss: 0.254131
 >> iter 6000, loss: 0.111794
 >> iter 7000, loss: 0.058156
 >> iter 8000, loss: 0.036588
 >> iter 9000, loss: 0.028533
 >> iter 10000, loss: 0.025130
   Number of active neurons: 3
 >> iter 11000, loss: 0.038546
 >> iter 12000, loss: 0.030635
 >> iter 13000, loss: 0.030332
 >> iter 14000, loss: 0.027744
 >> iter 15000, loss: 0.029074
 >> iter 16000, loss: 0.025480
 >> iter 17000, loss: 0.034867
 >> iter 18000, loss: 0.027226
 >> iter 19000, loss: 0.030411
 >> iter 20000, loss: 0.024462
   Number of active neurons: 3
 >> iter 21000, loss: 0.037115
 >> iter 22000, loss: 0.028524
 >> iter 23000, loss: 0.033704
 >> iter 24000, loss: 0.032753
 >> iter 25000, loss: 0.032148
 >> iter 26000, loss: 0.034825
 >> iter 27000, loss: 0.038340
 >> iter 28000, loss: 0.030575
 >> iter 29000, loss: 0.026648
 >> iter 30000, loss: 0.025214
   Number of active neurons: 2
 >> iter 31000, loss: 0.023012
 >> iter 32000, loss: 0.021677
 >> iter 33000, loss: 0.036799
 >> iter 34000, loss: 0.042151
 >> iter 35000, loss: 0.028925
 >> iter 36000, loss: 0.035509
 >> iter 37000, loss: 0.025919
 >> iter 38000, loss: 0.022840
 >> iter 39000, loss: 0.025149
 >> iter 40000, loss: 0.028010
   Number of active neurons: 2
 >> iter 41000, loss: 0.034735
 >> iter 42000, loss: 0.034435
 >> iter 43000, loss: 0.025169
 >> iter 44000, loss: 0.025384
 >> iter 45000, loss: 0.025011
 >> iter 46000, loss: 0.021389
 >> iter 47000, loss: 0.023957
 >> iter 48000, loss: 0.020376
 >> iter 49000, loss: 0.022590
 >> iter 50000, loss: 0.039827
   Number of active neurons: 1
 >> iter 51000, loss: 0.025427
 >> iter 52000, loss: 0.031200
 >> iter 53000, loss: 0.023867
 >> iter 54000, loss: 0.021208
 >> iter 55000, loss: 0.067900
 >> iter 56000, loss: 0.035785
 >> iter 57000, loss: 0.034532
 >> iter 58000, loss: 0.023033
 >> iter 59000, loss: 0.020438
 >> iter 60000, loss: 0.032987
   Number of active neurons: 1
 >> iter 61000, loss: 0.022408
 >> iter 62000, loss: 0.041281
 >> iter 63000, loss: 0.027174
 >> iter 64000, loss: 0.029256
 >> iter 65000, loss: 0.032401
 >> iter 66000, loss: 0.030200
 >> iter 67000, loss: 0.027923
 >> iter 68000, loss: 0.019820
 >> iter 69000, loss: 0.022382
 >> iter 70000, loss: 0.020501
   Number of active neurons: 1
 >> iter 71000, loss: 0.018245
 >> iter 72000, loss: 0.017974
 >> iter 73000, loss: 0.018232
 >> iter 74000, loss: 0.025945
 >> iter 75000, loss: 0.021436
 >> iter 76000, loss: 0.022733
 >> iter 77000, loss: 0.019864
 >> iter 78000, loss: 0.016975
 >> iter 79000, loss: 0.023009
 >> iter 80000, loss: 0.021107
   Number of active neurons: 1
 >> iter 81000, loss: 0.019686
 >> iter 82000, loss: 0.016836
 >> iter 83000, loss: 0.022771
 >> iter 84000, loss: 0.018330
 >> iter 85000, loss: 0.020632
 >> iter 86000, loss: 0.019315
 >> iter 87000, loss: 0.020078
 >> iter 88000, loss: 0.017864
 >> iter 89000, loss: 0.036588
 >> iter 90000, loss: 0.025244
   Number of active neurons: 1
 >> iter 91000, loss: 0.021450
 >> iter 92000, loss: 0.020426
 >> iter 93000, loss: 0.017618
 >> iter 94000, loss: 0.021053
 >> iter 95000, loss: 0.023132
 >> iter 96000, loss: 0.021244
 >> iter 97000, loss: 0.018454
 >> iter 98000, loss: 0.017523
 >> iter 99000, loss: 0.019867
 >> iter 100000, loss: 0.056200
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

