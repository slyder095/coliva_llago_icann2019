 > Problema: tomita3nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.884297
 >> iter 2000, loss: 16.910514
 >> iter 3000, loss: 15.777496
 >> iter 4000, loss: 15.190708
 >> iter 5000, loss: 14.999913
 >> iter 6000, loss: 14.656317
 >> iter 7000, loss: 14.755746
 >> iter 8000, loss: 14.909712
 >> iter 9000, loss: 14.762591
 >> iter 10000, loss: 14.219487
   Number of active neurons: 2
 >> iter 11000, loss: 14.136235
 >> iter 12000, loss: 14.065436
 >> iter 13000, loss: 14.216195
 >> iter 14000, loss: 13.618618
 >> iter 15000, loss: 14.096423
 >> iter 16000, loss: 13.404134
 >> iter 17000, loss: 13.845752
 >> iter 18000, loss: 13.488981
 >> iter 19000, loss: 13.698323
 >> iter 20000, loss: 13.358185
   Number of active neurons: 2
 >> iter 21000, loss: 12.874333
 >> iter 22000, loss: 12.349300
 >> iter 23000, loss: 12.145626
 >> iter 24000, loss: 11.841819
 >> iter 25000, loss: 11.871408
 >> iter 26000, loss: 11.814763
 >> iter 27000, loss: 11.893551
 >> iter 28000, loss: 11.821225
 >> iter 29000, loss: 12.017298
 >> iter 30000, loss: 11.710297
   Number of active neurons: 2
 >> iter 31000, loss: 11.997095
 >> iter 32000, loss: 11.850526
 >> iter 33000, loss: 11.950303
 >> iter 34000, loss: 11.813160
 >> iter 35000, loss: 12.022919
 >> iter 36000, loss: 11.893526
 >> iter 37000, loss: 11.938020
 >> iter 38000, loss: 11.824655
 >> iter 39000, loss: 11.873759
 >> iter 40000, loss: 11.755336
   Number of active neurons: 2
 >> iter 41000, loss: 11.887386
 >> iter 42000, loss: 11.931639
 >> iter 43000, loss: 12.012831
 >> iter 44000, loss: 11.931855
 >> iter 45000, loss: 12.052317
 >> iter 46000, loss: 11.782572
 >> iter 47000, loss: 11.931784
 >> iter 48000, loss: 11.859980
 >> iter 49000, loss: 11.963908
 >> iter 50000, loss: 11.798668
   Number of active neurons: 2
 >> iter 51000, loss: 11.864321
 >> iter 52000, loss: 12.078282
 >> iter 53000, loss: 12.019854
 >> iter 54000, loss: 12.221125
 >> iter 55000, loss: 12.182810
 >> iter 56000, loss: 12.029714
 >> iter 57000, loss: 11.919971
 >> iter 58000, loss: 12.113542
 >> iter 59000, loss: 12.087565
 >> iter 60000, loss: 12.069141
   Number of active neurons: 2
 >> iter 61000, loss: 12.002243
 >> iter 62000, loss: 12.005263
 >> iter 63000, loss: 12.139946
 >> iter 64000, loss: 11.778103
 >> iter 65000, loss: 12.195011
 >> iter 66000, loss: 11.861173
 >> iter 67000, loss: 11.896098
 >> iter 68000, loss: 11.689373
 >> iter 69000, loss: 11.898041
 >> iter 70000, loss: 11.682993
   Number of active neurons: 2
 >> iter 71000, loss: 11.742619
 >> iter 72000, loss: 11.756015
 >> iter 73000, loss: 12.226046
 >> iter 74000, loss: 12.111412
 >> iter 75000, loss: 13.925870
 >> iter 76000, loss: 16.301115
 >> iter 77000, loss: 17.017967
 >> iter 78000, loss: 17.173927
 >> iter 79000, loss: 16.334008
 >> iter 80000, loss: 15.557739
   Number of active neurons: 2
 >> iter 81000, loss: 14.789285
 >> iter 82000, loss: 12.985497
 >> iter 83000, loss: 12.356174
 >> iter 84000, loss: 11.940902
 >> iter 85000, loss: 12.141186
 >> iter 86000, loss: 11.913161
 >> iter 87000, loss: 11.836455
 >> iter 88000, loss: 11.929391
 >> iter 89000, loss: 12.315453
 >> iter 90000, loss: 12.332390
   Number of active neurons: 2
 >> iter 91000, loss: 11.997271
 >> iter 92000, loss: 11.686956
 >> iter 93000, loss: 12.034687
 >> iter 94000, loss: 11.767370
 >> iter 95000, loss: 12.004275
 >> iter 96000, loss: 11.727059
 >> iter 97000, loss: 12.049814
 >> iter 98000, loss: 11.826081
 >> iter 99000, loss: 12.030278
 >> iter 100000, loss: 11.719702
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 21.2075758485
   - Test - Long: 4.38478076096
   - Test - Big: 21.4587854121
   - Test - A: 65.9556029598
   - Test - B: 16.145590294
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.753685
 >> iter 2000, loss: 16.480850
 >> iter 3000, loss: 15.750573
 >> iter 4000, loss: 14.454599
 >> iter 5000, loss: 14.172581
 >> iter 6000, loss: 13.870692
 >> iter 7000, loss: 13.696730
 >> iter 8000, loss: 13.580429
 >> iter 9000, loss: 13.823461
 >> iter 10000, loss: 13.816966
   Number of active neurons: 2
 >> iter 11000, loss: 13.589464
 >> iter 12000, loss: 13.528512
 >> iter 13000, loss: 13.801969
 >> iter 14000, loss: 13.672949
 >> iter 15000, loss: 13.634857
 >> iter 16000, loss: 13.392765
 >> iter 17000, loss: 13.715674
 >> iter 18000, loss: 13.309497
 >> iter 19000, loss: 13.637906
 >> iter 20000, loss: 13.259539
   Number of active neurons: 2
 >> iter 21000, loss: 13.465044
 >> iter 22000, loss: 13.218145
 >> iter 23000, loss: 12.644654
 >> iter 24000, loss: 11.754539
 >> iter 25000, loss: 11.154443
 >> iter 26000, loss: 10.782842
 >> iter 27000, loss: 10.601152
 >> iter 28000, loss: 10.536578
 >> iter 29000, loss: 10.508852
 >> iter 30000, loss: 10.459688
   Number of active neurons: 2
 >> iter 31000, loss: 10.393699
 >> iter 32000, loss: 10.416579
 >> iter 33000, loss: 10.370382
 >> iter 34000, loss: 10.371983
 >> iter 35000, loss: 10.363946
 >> iter 36000, loss: 10.376441
 >> iter 37000, loss: 10.339994
 >> iter 38000, loss: 10.364766
 >> iter 39000, loss: 10.315850
 >> iter 40000, loss: 10.354740
   Number of active neurons: 2
 >> iter 41000, loss: 10.318677
 >> iter 42000, loss: 10.316726
 >> iter 43000, loss: 10.294947
 >> iter 44000, loss: 10.294992
 >> iter 45000, loss: 10.292423
 >> iter 46000, loss: 10.307270
 >> iter 47000, loss: 10.338318
 >> iter 48000, loss: 10.301613
 >> iter 49000, loss: 10.304679
 >> iter 50000, loss: 10.314369
   Number of active neurons: 2
 >> iter 51000, loss: 10.303259
 >> iter 52000, loss: 10.307663
 >> iter 53000, loss: 10.260825
 >> iter 54000, loss: 10.313592
 >> iter 55000, loss: 10.278964
 >> iter 56000, loss: 10.320214
 >> iter 57000, loss: 10.299033
 >> iter 58000, loss: 10.315694
 >> iter 59000, loss: 10.266406
 >> iter 60000, loss: 10.299005
   Number of active neurons: 2
 >> iter 61000, loss: 10.279047
 >> iter 62000, loss: 10.339935
 >> iter 63000, loss: 10.284960
 >> iter 64000, loss: 10.336969
 >> iter 65000, loss: 10.294116
 >> iter 66000, loss: 10.320832
 >> iter 67000, loss: 10.313080
 >> iter 68000, loss: 10.294216
 >> iter 69000, loss: 10.261665
 >> iter 70000, loss: 10.279802
   Number of active neurons: 2
 >> iter 71000, loss: 10.302509
 >> iter 72000, loss: 10.306961
 >> iter 73000, loss: 10.296841
 >> iter 74000, loss: 10.322723
 >> iter 75000, loss: 10.299670
 >> iter 76000, loss: 10.302612
 >> iter 77000, loss: 10.312405
 >> iter 78000, loss: 10.297875
 >> iter 79000, loss: 10.300102
 >> iter 80000, loss: 10.302966
   Number of active neurons: 2
 >> iter 81000, loss: 10.323505
 >> iter 82000, loss: 10.317692
 >> iter 83000, loss: 10.335232
 >> iter 84000, loss: 10.296487
 >> iter 85000, loss: 10.332870
 >> iter 86000, loss: 10.309532
 >> iter 87000, loss: 10.342863
 >> iter 88000, loss: 10.364919
 >> iter 89000, loss: 10.366222
 >> iter 90000, loss: 10.328471
   Number of active neurons: 2
 >> iter 91000, loss: 10.336187
 >> iter 92000, loss: 10.348501
 >> iter 93000, loss: 10.348641
 >> iter 94000, loss: 10.303218
 >> iter 95000, loss: 10.321087
 >> iter 96000, loss: 10.294434
 >> iter 97000, loss: 10.337034
 >> iter 98000, loss: 10.314011
 >> iter 99000, loss: 10.358399
 >> iter 100000, loss: 10.302263
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 17.8476430471
   - Test - Long: 3.68481575921
   - Test - Big: 18.0358196418
   - Test - A: 17.1988534098
   - Test - B: 15.6122925138
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.395396
 >> iter 2000, loss: 15.613008
 >> iter 3000, loss: 14.416805
 >> iter 4000, loss: 13.662515
 >> iter 5000, loss: 13.714225
 >> iter 6000, loss: 13.871674
 >> iter 7000, loss: 14.014852
 >> iter 8000, loss: 13.852839
 >> iter 9000, loss: 14.200645
 >> iter 10000, loss: 13.802396
   Number of active neurons: 2
 >> iter 11000, loss: 13.858141
 >> iter 12000, loss: 13.534526
 >> iter 13000, loss: 13.720435
 >> iter 14000, loss: 13.535586
 >> iter 15000, loss: 13.712034
 >> iter 16000, loss: 13.796718
 >> iter 17000, loss: 13.621678
 >> iter 18000, loss: 13.393347
 >> iter 19000, loss: 13.562064
 >> iter 20000, loss: 13.479418
   Number of active neurons: 2
 >> iter 21000, loss: 13.405162
 >> iter 22000, loss: 13.280359
 >> iter 23000, loss: 13.357410
 >> iter 24000, loss: 13.164612
 >> iter 25000, loss: 13.488570
 >> iter 26000, loss: 13.294223
 >> iter 27000, loss: 13.360600
 >> iter 28000, loss: 13.417194
 >> iter 29000, loss: 13.424171
 >> iter 30000, loss: 12.576330
   Number of active neurons: 2
 >> iter 31000, loss: 11.700832
 >> iter 32000, loss: 11.029577
 >> iter 33000, loss: 10.758670
 >> iter 34000, loss: 10.588303
 >> iter 35000, loss: 10.449427
 >> iter 36000, loss: 10.416805
 >> iter 37000, loss: 10.372320
 >> iter 38000, loss: 10.368773
 >> iter 39000, loss: 10.322148
 >> iter 40000, loss: 10.359862
   Number of active neurons: 2
 >> iter 41000, loss: 10.331931
 >> iter 42000, loss: 10.320731
 >> iter 43000, loss: 10.333928
 >> iter 44000, loss: 10.318731
 >> iter 45000, loss: 10.353097
 >> iter 46000, loss: 10.366788
 >> iter 47000, loss: 10.322732
 >> iter 48000, loss: 10.321154
 >> iter 49000, loss: 10.295103
 >> iter 50000, loss: 10.316633
   Number of active neurons: 2
 >> iter 51000, loss: 10.287039
 >> iter 52000, loss: 10.299991
 >> iter 53000, loss: 10.294286
 >> iter 54000, loss: 10.293400
 >> iter 55000, loss: 10.274004
 >> iter 56000, loss: 10.297960
 >> iter 57000, loss: 10.303759
 >> iter 58000, loss: 10.312667
 >> iter 59000, loss: 10.265853
 >> iter 60000, loss: 10.280511
   Number of active neurons: 2
 >> iter 61000, loss: 10.279224
 >> iter 62000, loss: 10.326216
 >> iter 63000, loss: 10.267755
 >> iter 64000, loss: 10.296570
 >> iter 65000, loss: 10.272092
 >> iter 66000, loss: 10.289833
 >> iter 67000, loss: 10.269072
 >> iter 68000, loss: 10.301533
 >> iter 69000, loss: 10.284772
 >> iter 70000, loss: 10.290716
   Number of active neurons: 2
 >> iter 71000, loss: 10.308390
 >> iter 72000, loss: 10.310847
 >> iter 73000, loss: 10.314073
 >> iter 74000, loss: 10.316607
 >> iter 75000, loss: 10.327377
 >> iter 76000, loss: 10.304818
 >> iter 77000, loss: 10.298149
 >> iter 78000, loss: 10.293460
 >> iter 79000, loss: 10.307247
 >> iter 80000, loss: 10.285222
   Number of active neurons: 2
 >> iter 81000, loss: 10.297505
 >> iter 82000, loss: 10.254103
 >> iter 83000, loss: 10.337293
 >> iter 84000, loss: 10.296138
 >> iter 85000, loss: 10.298993
 >> iter 86000, loss: 10.279115
 >> iter 87000, loss: 10.290532
 >> iter 88000, loss: 10.293717
 >> iter 89000, loss: 10.307079
 >> iter 90000, loss: 10.287623
   Number of active neurons: 2
 >> iter 91000, loss: 10.286567
 >> iter 92000, loss: 10.264815
 >> iter 93000, loss: 10.272947
 >> iter 94000, loss: 10.259553
 >> iter 95000, loss: 10.271794
 >> iter 96000, loss: 10.262103
 >> iter 97000, loss: 10.307597
 >> iter 98000, loss: 10.260947
 >> iter 99000, loss: 10.307637
 >> iter 100000, loss: 10.265254
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 17.8476430471
   - Test - Long: 3.68481575921
   - Test - Big: 18.0358196418
   - Test - A: 17.1988534098
   - Test - B: 15.6122925138
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.545109
 >> iter 2000, loss: 16.402560
 >> iter 3000, loss: 15.359282
 >> iter 4000, loss: 14.888078
 >> iter 5000, loss: 14.817482
 >> iter 6000, loss: 14.784985
 >> iter 7000, loss: 14.844540
 >> iter 8000, loss: 13.964188
 >> iter 9000, loss: 13.936478
 >> iter 10000, loss: 14.186583
   Number of active neurons: 2
 >> iter 11000, loss: 14.083184
 >> iter 12000, loss: 13.654899
 >> iter 13000, loss: 13.923419
 >> iter 14000, loss: 13.784426
 >> iter 15000, loss: 14.388051
 >> iter 16000, loss: 14.366585
 >> iter 17000, loss: 13.179003
 >> iter 18000, loss: 12.642976
 >> iter 19000, loss: 12.543738
 >> iter 20000, loss: 12.209117
   Number of active neurons: 2
 >> iter 21000, loss: 12.255929
 >> iter 22000, loss: 12.140503
 >> iter 23000, loss: 12.147538
 >> iter 24000, loss: 12.353585
 >> iter 25000, loss: 12.339869
 >> iter 26000, loss: 12.011140
 >> iter 27000, loss: 12.086351
 >> iter 28000, loss: 11.922637
 >> iter 29000, loss: 12.296600
 >> iter 30000, loss: 12.035886
   Number of active neurons: 2
 >> iter 31000, loss: 11.950600
 >> iter 32000, loss: 12.174412
 >> iter 33000, loss: 12.080876
 >> iter 34000, loss: 12.037517
 >> iter 35000, loss: 12.025327
 >> iter 36000, loss: 12.030793
 >> iter 37000, loss: 12.048654
 >> iter 38000, loss: 11.982558
 >> iter 39000, loss: 12.357066
 >> iter 40000, loss: 11.923638
   Number of active neurons: 2
 >> iter 41000, loss: 12.020063
 >> iter 42000, loss: 11.983882
 >> iter 43000, loss: 11.897803
 >> iter 44000, loss: 11.833451
 >> iter 45000, loss: 11.982726
 >> iter 46000, loss: 11.925707
 >> iter 47000, loss: 12.334924
 >> iter 48000, loss: 12.247199
 >> iter 49000, loss: 12.116024
 >> iter 50000, loss: 12.073825
   Number of active neurons: 2
 >> iter 51000, loss: 12.180720
 >> iter 52000, loss: 12.010337
 >> iter 53000, loss: 12.069375
 >> iter 54000, loss: 11.820036
 >> iter 55000, loss: 12.196891
 >> iter 56000, loss: 12.199424
 >> iter 57000, loss: 11.949294
 >> iter 58000, loss: 11.837141
 >> iter 59000, loss: 11.821704
 >> iter 60000, loss: 11.747194
   Number of active neurons: 2
 >> iter 61000, loss: 11.822434
 >> iter 62000, loss: 11.810592
 >> iter 63000, loss: 12.094783
 >> iter 64000, loss: 12.079543
 >> iter 65000, loss: 12.008088
 >> iter 66000, loss: 11.743200
 >> iter 67000, loss: 11.771329
 >> iter 68000, loss: 11.771606
 >> iter 69000, loss: 11.822087
 >> iter 70000, loss: 11.773963
   Number of active neurons: 2
 >> iter 71000, loss: 15.031986
 >> iter 72000, loss: 16.730117
 >> iter 73000, loss: 17.372292
 >> iter 74000, loss: 17.420093
 >> iter 75000, loss: 17.629780
 >> iter 76000, loss: 17.675581
 >> iter 77000, loss: 17.405419
 >> iter 78000, loss: 16.892785
 >> iter 79000, loss: 13.488350
 >> iter 80000, loss: 11.437481
   Number of active neurons: 2
 >> iter 81000, loss: 10.684362
 >> iter 82000, loss: 10.195492
 >> iter 83000, loss: 10.156602
 >> iter 84000, loss: 9.995302
 >> iter 85000, loss: 10.087739
 >> iter 86000, loss: 9.953942
 >> iter 87000, loss: 10.038928
 >> iter 88000, loss: 9.918497
 >> iter 89000, loss: 10.016733
 >> iter 90000, loss: 9.889907
   Number of active neurons: 2
 >> iter 91000, loss: 9.991743
 >> iter 92000, loss: 9.877609
 >> iter 93000, loss: 9.992401
 >> iter 94000, loss: 9.886016
 >> iter 95000, loss: 9.995666
 >> iter 96000, loss: 9.899501
 >> iter 97000, loss: 10.006416
 >> iter 98000, loss: 9.883414
 >> iter 99000, loss: 9.986773
 >> iter 100000, loss: 9.874209
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 17.7036459271
   - Test - Long: 3.65981700915
   - Test - Big: 17.8398216018
   - Test - A: 17.4321711886
   - Test - B: 16.1589227385
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.537938
 >> iter 2000, loss: 15.839493
 >> iter 3000, loss: 14.508034
 >> iter 4000, loss: 13.822923
 >> iter 5000, loss: 13.873884
 >> iter 6000, loss: 13.657102
 >> iter 7000, loss: 14.004446
 >> iter 8000, loss: 13.851968
 >> iter 9000, loss: 13.882829
 >> iter 10000, loss: 13.545629
   Number of active neurons: 2
 >> iter 11000, loss: 13.721847
 >> iter 12000, loss: 14.143181
 >> iter 13000, loss: 14.266312
 >> iter 14000, loss: 13.809443
 >> iter 15000, loss: 14.082417
 >> iter 16000, loss: 14.024830
 >> iter 17000, loss: 13.732510
 >> iter 18000, loss: 14.140417
 >> iter 19000, loss: 14.429047
 >> iter 20000, loss: 13.972961
   Number of active neurons: 2
 >> iter 21000, loss: 14.347769
 >> iter 22000, loss: 13.772522
 >> iter 23000, loss: 14.748741
 >> iter 24000, loss: 15.081805
 >> iter 25000, loss: 15.201437
 >> iter 26000, loss: 15.219566
 >> iter 27000, loss: 14.936576
 >> iter 28000, loss: 14.844649
 >> iter 29000, loss: 14.457368
 >> iter 30000, loss: 14.131458
   Number of active neurons: 2
 >> iter 31000, loss: 14.137254
 >> iter 32000, loss: 13.866727
 >> iter 33000, loss: 15.072002
 >> iter 34000, loss: 13.318121
 >> iter 35000, loss: 12.406381
 >> iter 36000, loss: 12.177597
 >> iter 37000, loss: 12.710523
 >> iter 38000, loss: 12.530897
 >> iter 39000, loss: 12.666016
 >> iter 40000, loss: 12.381664
   Number of active neurons: 2
 >> iter 41000, loss: 12.131559
 >> iter 42000, loss: 11.780751
 >> iter 43000, loss: 11.948445
 >> iter 44000, loss: 11.943593
 >> iter 45000, loss: 11.989435
 >> iter 46000, loss: 11.900533
 >> iter 47000, loss: 12.078585
 >> iter 48000, loss: 11.788021
 >> iter 49000, loss: 12.027539
 >> iter 50000, loss: 11.830603
   Number of active neurons: 2
 >> iter 51000, loss: 12.059467
 >> iter 52000, loss: 12.031963
 >> iter 53000, loss: 12.518830
 >> iter 54000, loss: 12.092439
 >> iter 55000, loss: 11.971857
 >> iter 56000, loss: 11.974200
 >> iter 57000, loss: 11.912694
 >> iter 58000, loss: 11.726058
 >> iter 59000, loss: 11.990550
 >> iter 60000, loss: 11.802007
   Number of active neurons: 2
 >> iter 61000, loss: 11.926158
 >> iter 62000, loss: 11.931726
 >> iter 63000, loss: 11.944487
 >> iter 64000, loss: 11.909197
 >> iter 65000, loss: 11.961362
 >> iter 66000, loss: 11.792810
 >> iter 67000, loss: 12.061700
 >> iter 68000, loss: 11.826628
 >> iter 69000, loss: 11.923676
 >> iter 70000, loss: 11.929365
   Number of active neurons: 2
 >> iter 71000, loss: 12.095124
 >> iter 72000, loss: 11.784586
 >> iter 73000, loss: 11.848737
 >> iter 74000, loss: 11.702680
 >> iter 75000, loss: 11.986610
 >> iter 76000, loss: 11.704141
 >> iter 77000, loss: 11.931311
 >> iter 78000, loss: 11.801514
 >> iter 79000, loss: 12.029775
 >> iter 80000, loss: 11.811376
   Number of active neurons: 2
 >> iter 81000, loss: 11.841953
 >> iter 82000, loss: 12.131028
 >> iter 83000, loss: 11.987185
 >> iter 84000, loss: 11.851296
 >> iter 85000, loss: 11.843417
 >> iter 86000, loss: 11.911451
 >> iter 87000, loss: 11.904578
 >> iter 88000, loss: 11.782676
 >> iter 89000, loss: 11.886934
 >> iter 90000, loss: 11.916629
   Number of active neurons: 2
 >> iter 91000, loss: 11.947089
 >> iter 92000, loss: 11.857956
 >> iter 93000, loss: 12.013853
 >> iter 94000, loss: 11.760399
 >> iter 95000, loss: 11.941088
 >> iter 96000, loss: 11.806663
 >> iter 97000, loss: 12.089646
 >> iter 98000, loss: 11.803805
 >> iter 99000, loss: 11.804858
 >> iter 100000, loss: 11.861564
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 21.7895642087
   - Test - Long: 4.48977551122
   - Test - Big: 22.0507794922
   - Test - A: 65.9822678488
   - Test - B: 16.1055929605
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.740125
 >> iter 2000, loss: 16.478994
 >> iter 3000, loss: 15.506766
 >> iter 4000, loss: 14.508629
 >> iter 5000, loss: 14.004916
 >> iter 6000, loss: 13.621502
 >> iter 7000, loss: 13.998567
 >> iter 8000, loss: 13.648384
 >> iter 9000, loss: 14.077174
 >> iter 10000, loss: 13.794310
   Number of active neurons: 2
 >> iter 11000, loss: 13.977139
 >> iter 12000, loss: 13.658314
 >> iter 13000, loss: 13.879766
 >> iter 14000, loss: 13.672333
 >> iter 15000, loss: 13.917444
 >> iter 16000, loss: 13.669514
 >> iter 17000, loss: 14.080491
 >> iter 18000, loss: 13.784636
 >> iter 19000, loss: 13.772226
 >> iter 20000, loss: 13.348424
   Number of active neurons: 2
 >> iter 21000, loss: 13.730775
 >> iter 22000, loss: 13.435841
 >> iter 23000, loss: 13.621360
 >> iter 24000, loss: 13.456110
 >> iter 25000, loss: 13.374451
 >> iter 26000, loss: 13.079083
 >> iter 27000, loss: 12.958135
 >> iter 28000, loss: 12.193370
 >> iter 29000, loss: 11.514443
 >> iter 30000, loss: 10.979789
   Number of active neurons: 2
 >> iter 31000, loss: 10.685427
 >> iter 32000, loss: 10.580766
 >> iter 33000, loss: 10.476131
 >> iter 34000, loss: 10.500392
 >> iter 35000, loss: 10.401564
 >> iter 36000, loss: 10.388296
 >> iter 37000, loss: 10.358807
 >> iter 38000, loss: 10.361901
 >> iter 39000, loss: 10.318441
 >> iter 40000, loss: 10.327401
   Number of active neurons: 2
 >> iter 41000, loss: 10.332766
 >> iter 42000, loss: 10.347086
 >> iter 43000, loss: 10.324885
 >> iter 44000, loss: 10.350637
 >> iter 45000, loss: 10.302721
 >> iter 46000, loss: 10.299358
 >> iter 47000, loss: 10.287804
 >> iter 48000, loss: 10.299022
 >> iter 49000, loss: 10.304307
 >> iter 50000, loss: 10.317721
   Number of active neurons: 2
 >> iter 51000, loss: 10.290834
 >> iter 52000, loss: 10.300456
 >> iter 53000, loss: 10.317943
 >> iter 54000, loss: 10.311009
 >> iter 55000, loss: 10.273658
 >> iter 56000, loss: 10.302634
 >> iter 57000, loss: 10.266733
 >> iter 58000, loss: 10.294459
 >> iter 59000, loss: 10.260962
 >> iter 60000, loss: 10.317091
   Number of active neurons: 2
 >> iter 61000, loss: 10.275729
 >> iter 62000, loss: 10.304721
 >> iter 63000, loss: 10.289231
 >> iter 64000, loss: 10.360393
 >> iter 65000, loss: 10.336666
 >> iter 66000, loss: 10.346740
 >> iter 67000, loss: 10.323776
 >> iter 68000, loss: 10.315197
 >> iter 69000, loss: 10.289517
 >> iter 70000, loss: 10.285337
   Number of active neurons: 2
 >> iter 71000, loss: 10.312882
 >> iter 72000, loss: 10.324700
 >> iter 73000, loss: 10.321940
 >> iter 74000, loss: 10.285553
 >> iter 75000, loss: 10.330755
 >> iter 76000, loss: 10.311990
 >> iter 77000, loss: 10.319000
 >> iter 78000, loss: 10.285594
 >> iter 79000, loss: 10.309858
 >> iter 80000, loss: 10.330861
   Number of active neurons: 2
 >> iter 81000, loss: 10.353082
 >> iter 82000, loss: 10.282260
 >> iter 83000, loss: 10.287653
 >> iter 84000, loss: 10.283333
 >> iter 85000, loss: 10.313924
 >> iter 86000, loss: 10.292219
 >> iter 87000, loss: 10.320707
 >> iter 88000, loss: 10.307030
 >> iter 89000, loss: 10.301175
 >> iter 90000, loss: 10.275641
   Number of active neurons: 2
 >> iter 91000, loss: 10.329048
 >> iter 92000, loss: 10.284476
 >> iter 93000, loss: 10.301687
 >> iter 94000, loss: 10.295272
 >> iter 95000, loss: 10.310983
 >> iter 96000, loss: 10.275145
 >> iter 97000, loss: 10.287713
 >> iter 98000, loss: 10.265643
 >> iter 99000, loss: 10.320805
 >> iter 100000, loss: 10.276511
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 17.8476430471
   - Test - Long: 3.68481575921
   - Test - Big: 18.0358196418
   - Test - A: 17.1988534098
   - Test - B: 15.6122925138
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.110510
 >> iter 2000, loss: 15.383192
 >> iter 3000, loss: 14.552482
 >> iter 4000, loss: 13.793789
 >> iter 5000, loss: 13.675813
 >> iter 6000, loss: 13.628342
 >> iter 7000, loss: 13.766548
 >> iter 8000, loss: 13.547575
 >> iter 9000, loss: 13.675038
 >> iter 10000, loss: 13.341088
   Number of active neurons: 2
 >> iter 11000, loss: 13.748784
 >> iter 12000, loss: 13.572074
 >> iter 13000, loss: 12.823704
 >> iter 14000, loss: 12.323663
 >> iter 15000, loss: 12.364891
 >> iter 16000, loss: 12.332270
 >> iter 17000, loss: 12.042303
 >> iter 18000, loss: 12.064428
 >> iter 19000, loss: 12.265482
 >> iter 20000, loss: 12.111262
   Number of active neurons: 2
 >> iter 21000, loss: 12.226168
 >> iter 22000, loss: 12.007738
 >> iter 23000, loss: 11.969421
 >> iter 24000, loss: 11.823981
 >> iter 25000, loss: 12.003563
 >> iter 26000, loss: 12.028382
 >> iter 27000, loss: 12.221803
 >> iter 28000, loss: 12.002504
 >> iter 29000, loss: 12.158660
 >> iter 30000, loss: 12.026388
   Number of active neurons: 2
 >> iter 31000, loss: 12.008216
 >> iter 32000, loss: 11.904102
 >> iter 33000, loss: 12.035740
 >> iter 34000, loss: 12.007356
 >> iter 35000, loss: 12.104972
 >> iter 36000, loss: 11.883092
 >> iter 37000, loss: 11.980412
 >> iter 38000, loss: 11.877119
 >> iter 39000, loss: 12.005828
 >> iter 40000, loss: 11.924875
   Number of active neurons: 2
 >> iter 41000, loss: 12.266113
 >> iter 42000, loss: 11.873753
 >> iter 43000, loss: 11.947562
 >> iter 44000, loss: 11.717948
 >> iter 45000, loss: 11.988266
 >> iter 46000, loss: 11.917083
 >> iter 47000, loss: 12.214209
 >> iter 48000, loss: 11.827191
 >> iter 49000, loss: 11.951822
 >> iter 50000, loss: 11.774506
   Number of active neurons: 2
 >> iter 51000, loss: 12.022977
 >> iter 52000, loss: 11.988198
 >> iter 53000, loss: 11.798910
 >> iter 54000, loss: 11.776047
 >> iter 55000, loss: 11.780073
 >> iter 56000, loss: 11.860343
 >> iter 57000, loss: 11.805275
 >> iter 58000, loss: 11.723909
 >> iter 59000, loss: 11.845179
 >> iter 60000, loss: 11.878655
   Number of active neurons: 2
 >> iter 61000, loss: 11.988145
 >> iter 62000, loss: 12.042043
 >> iter 63000, loss: 12.156638
 >> iter 64000, loss: 11.913853
 >> iter 65000, loss: 12.067439
 >> iter 66000, loss: 11.876565
 >> iter 67000, loss: 11.885323
 >> iter 68000, loss: 11.838894
 >> iter 69000, loss: 11.964271
 >> iter 70000, loss: 11.826229
   Number of active neurons: 2
 >> iter 71000, loss: 11.998965
 >> iter 72000, loss: 11.845633
 >> iter 73000, loss: 11.944363
 >> iter 74000, loss: 11.916247
 >> iter 75000, loss: 11.919211
 >> iter 76000, loss: 11.770289
 >> iter 77000, loss: 11.937447
 >> iter 78000, loss: 11.612167
 >> iter 79000, loss: 11.966424
 >> iter 80000, loss: 11.890227
   Number of active neurons: 2
 >> iter 81000, loss: 11.960475
 >> iter 82000, loss: 11.849377
 >> iter 83000, loss: 12.034322
 >> iter 84000, loss: 11.987358
 >> iter 85000, loss: 11.857063
 >> iter 86000, loss: 11.757742
 >> iter 87000, loss: 11.859445
 >> iter 88000, loss: 11.885521
 >> iter 89000, loss: 11.858227
 >> iter 90000, loss: 11.770907
   Number of active neurons: 2
 >> iter 91000, loss: 11.884961
 >> iter 92000, loss: 11.776534
 >> iter 93000, loss: 11.912190
 >> iter 94000, loss: 11.986271
 >> iter 95000, loss: 12.098842
 >> iter 96000, loss: 11.738425
 >> iter 97000, loss: 11.740190
 >> iter 98000, loss: 12.125571
 >> iter 99000, loss: 11.880178
 >> iter 100000, loss: 11.676252
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 22.2695546089
   - Test - Long: 4.799760012
   - Test - Big: 22.4977750222
   - Test - A: 63.9957336178
   - Test - B: 16.5722285181
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.753482
 >> iter 2000, loss: 16.014453
 >> iter 3000, loss: 14.674557
 >> iter 4000, loss: 13.821161
 >> iter 5000, loss: 13.716480
 >> iter 6000, loss: 13.689870
 >> iter 7000, loss: 13.974784
 >> iter 8000, loss: 13.831280
 >> iter 9000, loss: 14.283840
 >> iter 10000, loss: 14.327683
   Number of active neurons: 2
 >> iter 11000, loss: 13.946165
 >> iter 12000, loss: 13.509997
 >> iter 13000, loss: 14.044993
 >> iter 14000, loss: 14.046383
 >> iter 15000, loss: 14.116010
 >> iter 16000, loss: 13.588964
 >> iter 17000, loss: 13.898722
 >> iter 18000, loss: 13.485847
 >> iter 19000, loss: 13.076381
 >> iter 20000, loss: 12.502759
   Number of active neurons: 2
 >> iter 21000, loss: 11.790362
 >> iter 22000, loss: 11.260974
 >> iter 23000, loss: 10.908362
 >> iter 24000, loss: 10.745421
 >> iter 25000, loss: 10.602047
 >> iter 26000, loss: 10.546767
 >> iter 27000, loss: 10.490841
 >> iter 28000, loss: 10.433900
 >> iter 29000, loss: 10.394393
 >> iter 30000, loss: 10.387110
   Number of active neurons: 2
 >> iter 31000, loss: 10.361189
 >> iter 32000, loss: 10.383603
 >> iter 33000, loss: 10.351028
 >> iter 34000, loss: 10.385414
 >> iter 35000, loss: 10.340526
 >> iter 36000, loss: 10.373983
 >> iter 37000, loss: 10.349497
 >> iter 38000, loss: 10.345492
 >> iter 39000, loss: 10.320439
 >> iter 40000, loss: 10.326848
   Number of active neurons: 2
 >> iter 41000, loss: 10.286972
 >> iter 42000, loss: 10.299154
 >> iter 43000, loss: 10.280893
 >> iter 44000, loss: 10.303848
 >> iter 45000, loss: 10.319810
 >> iter 46000, loss: 10.331416
 >> iter 47000, loss: 10.326652
 >> iter 48000, loss: 10.328185
 >> iter 49000, loss: 10.321222
 >> iter 50000, loss: 10.358671
   Number of active neurons: 2
 >> iter 51000, loss: 10.318605
 >> iter 52000, loss: 10.338691
 >> iter 53000, loss: 10.306429
 >> iter 54000, loss: 10.316348
 >> iter 55000, loss: 10.286040
 >> iter 56000, loss: 10.331576
 >> iter 57000, loss: 10.294275
 >> iter 58000, loss: 10.335677
 >> iter 59000, loss: 10.277300
 >> iter 60000, loss: 10.326691
   Number of active neurons: 2
 >> iter 61000, loss: 10.277041
 >> iter 62000, loss: 10.318951
 >> iter 63000, loss: 10.271432
 >> iter 64000, loss: 10.306174
 >> iter 65000, loss: 10.301639
 >> iter 66000, loss: 10.349329
 >> iter 67000, loss: 10.313531
 >> iter 68000, loss: 10.329578
 >> iter 69000, loss: 10.289208
 >> iter 70000, loss: 10.330078
   Number of active neurons: 2
 >> iter 71000, loss: 10.348926
 >> iter 72000, loss: 10.319034
 >> iter 73000, loss: 10.333561
 >> iter 74000, loss: 10.328111
 >> iter 75000, loss: 10.326455
 >> iter 76000, loss: 10.291375
 >> iter 77000, loss: 10.352340
 >> iter 78000, loss: 10.319603
 >> iter 79000, loss: 10.326299
 >> iter 80000, loss: 10.298224
   Number of active neurons: 2
 >> iter 81000, loss: 10.317090
 >> iter 82000, loss: 10.321424
 >> iter 83000, loss: 10.350477
 >> iter 84000, loss: 10.359682
 >> iter 85000, loss: 10.340854
 >> iter 86000, loss: 10.315711
 >> iter 87000, loss: 10.349868
 >> iter 88000, loss: 10.353292
 >> iter 89000, loss: 10.337047
 >> iter 90000, loss: 10.306384
   Number of active neurons: 2
 >> iter 91000, loss: 10.342266
 >> iter 92000, loss: 10.353315
 >> iter 93000, loss: 10.357772
 >> iter 94000, loss: 10.321314
 >> iter 95000, loss: 10.333816
 >> iter 96000, loss: 10.325820
 >> iter 97000, loss: 10.341883
 >> iter 98000, loss: 10.328302
 >> iter 99000, loss: 10.346459
 >> iter 100000, loss: 10.361921
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 17.8476430471
   - Test - Long: 3.68481575921
   - Test - Big: 18.0358196418
   - Test - A: 17.1988534098
   - Test - B: 15.6122925138
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 21.128750
 >> iter 2000, loss: 18.814846
 >> iter 3000, loss: 17.949897
 >> iter 4000, loss: 17.646805
 >> iter 5000, loss: 17.518601
 >> iter 6000, loss: 17.489517
 >> iter 7000, loss: 17.461453
 >> iter 8000, loss: 17.468087
 >> iter 9000, loss: 17.452693
 >> iter 10000, loss: 17.464687
   Number of active neurons: 0
 >> iter 11000, loss: 17.448629
 >> iter 12000, loss: 17.463661
 >> iter 13000, loss: 17.450072
 >> iter 14000, loss: 17.463729
 >> iter 15000, loss: 17.448758
 >> iter 16000, loss: 17.465579
 >> iter 17000, loss: 17.449689
 >> iter 18000, loss: 17.465422
 >> iter 19000, loss: 17.453755
 >> iter 20000, loss: 17.465505
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 15.172956
 >> iter 22000, loss: 13.557602
 >> iter 23000, loss: 12.630096
 >> iter 24000, loss: 11.794956
 >> iter 25000, loss: 11.476876
 >> iter 26000, loss: 10.487136
 >> iter 27000, loss: 10.171696
 >> iter 28000, loss: 9.427978
 >> iter 29000, loss: 9.490369
 >> iter 30000, loss: 9.154890
   Number of active neurons: 2
 >> iter 31000, loss: 9.368304
 >> iter 32000, loss: 9.251188
 >> iter 33000, loss: 9.269648
 >> iter 34000, loss: 9.012654
 >> iter 35000, loss: 9.380708
 >> iter 36000, loss: 9.035132
 >> iter 37000, loss: 9.212521
 >> iter 38000, loss: 9.221087
 >> iter 39000, loss: 9.327728
 >> iter 40000, loss: 9.169438
   Number of active neurons: 2
 >> iter 41000, loss: 9.325875
 >> iter 42000, loss: 9.245938
 >> iter 43000, loss: 9.235554
 >> iter 44000, loss: 9.024925
 >> iter 45000, loss: 9.064384
 >> iter 46000, loss: 9.145098
 >> iter 47000, loss: 9.294606
 >> iter 48000, loss: 9.112163
 >> iter 49000, loss: 9.155763
 >> iter 50000, loss: 9.020688
   Number of active neurons: 2
 >> iter 51000, loss: 9.235605
 >> iter 52000, loss: 9.135993
 >> iter 53000, loss: 9.278142
 >> iter 54000, loss: 9.264968
 >> iter 55000, loss: 9.249665
 >> iter 56000, loss: 9.202267
 >> iter 57000, loss: 9.259852
 >> iter 58000, loss: 9.077865
 >> iter 59000, loss: 9.135794
 >> iter 60000, loss: 8.994340
   Number of active neurons: 2
 >> iter 61000, loss: 9.173624
 >> iter 62000, loss: 9.153307
 >> iter 63000, loss: 9.224923
 >> iter 64000, loss: 9.103855
 >> iter 65000, loss: 9.285866
 >> iter 66000, loss: 9.101556
 >> iter 67000, loss: 9.204460
 >> iter 68000, loss: 9.277273
 >> iter 69000, loss: 9.353247
 >> iter 70000, loss: 9.125635
   Number of active neurons: 2
 >> iter 71000, loss: 9.296553
 >> iter 72000, loss: 9.050260
 >> iter 73000, loss: 9.302878
 >> iter 74000, loss: 9.043800
 >> iter 75000, loss: 9.119033
 >> iter 76000, loss: 9.008893
 >> iter 77000, loss: 9.294559
 >> iter 78000, loss: 9.078986
 >> iter 79000, loss: 9.368847
 >> iter 80000, loss: 9.143982
   Number of active neurons: 2
 >> iter 81000, loss: 9.329292
 >> iter 82000, loss: 9.216540
 >> iter 83000, loss: 9.335801
 >> iter 84000, loss: 9.111708
 >> iter 85000, loss: 9.342884
 >> iter 86000, loss: 9.111654
 >> iter 87000, loss: 9.339693
 >> iter 88000, loss: 9.081030
 >> iter 89000, loss: 9.400969
 >> iter 90000, loss: 9.121452
   Number of active neurons: 2
 >> iter 91000, loss: 9.220661
 >> iter 92000, loss: 9.123121
 >> iter 93000, loss: 9.372879
 >> iter 94000, loss: 9.086512
 >> iter 95000, loss: 9.382760
 >> iter 96000, loss: 9.171660
 >> iter 97000, loss: 9.401259
 >> iter 98000, loss: 9.080179
 >> iter 99000, loss: 9.349209
 >> iter 100000, loss: 9.072564
   Number of active neurons: 2
 >> iter 101000, loss: 9.189753
 >> iter 102000, loss: 9.045460
 >> iter 103000, loss: 9.215767
 >> iter 104000, loss: 9.173743
 >> iter 105000, loss: 9.334665
 >> iter 106000, loss: 9.133488
 >> iter 107000, loss: 9.339602
 >> iter 108000, loss: 9.091229
 >> iter 109000, loss: 9.155408
 >> iter 110000, loss: 9.054581
   Number of active neurons: 2
 >> iter 111000, loss: 9.243035
 >> iter 112000, loss: 9.070223
 >> iter 113000, loss: 9.207166
 >> iter 114000, loss: 9.018105
 >> iter 115000, loss: 9.059660
 >> iter 116000, loss: 9.022331
 >> iter 117000, loss: 9.118578
 >> iter 118000, loss: 9.050595
 >> iter 119000, loss: 9.111568
 >> iter 120000, loss: 9.127897
   Number of active neurons: 2
 >> iter 121000, loss: 9.148012
 >> iter 122000, loss: 9.119839
 >> iter 123000, loss: 9.203055
 >> iter 124000, loss: 8.911524
 >> iter 125000, loss: 9.160092
 >> iter 126000, loss: 9.054760
 >> iter 127000, loss: 9.149279
 >> iter 128000, loss: 9.053183
 >> iter 129000, loss: 9.174115
 >> iter 130000, loss: 9.192549
   Number of active neurons: 2
 >> iter 131000, loss: 9.313329
 >> iter 132000, loss: 9.134604
 >> iter 133000, loss: 9.154734
 >> iter 134000, loss: 9.020307
 >> iter 135000, loss: 9.166742
 >> iter 136000, loss: 9.119865
 >> iter 137000, loss: 9.230366
 >> iter 138000, loss: 9.011864
 >> iter 139000, loss: 9.182162
 >> iter 140000, loss: 9.215950
   Number of active neurons: 2
 >> iter 141000, loss: 9.201122
 >> iter 142000, loss: 9.019513
 >> iter 143000, loss: 9.002010
 >> iter 144000, loss: 9.066860
 >> iter 145000, loss: 9.129174
 >> iter 146000, loss: 8.925412
 >> iter 147000, loss: 9.123358
 >> iter 148000, loss: 9.028450
 >> iter 149000, loss: 9.113395
 >> iter 150000, loss: 8.953776
   Number of active neurons: 2
 >> iter 151000, loss: 9.248628
 >> iter 152000, loss: 9.106966
 >> iter 153000, loss: 9.237794
 >> iter 154000, loss: 9.136721
 >> iter 155000, loss: 9.087859
 >> iter 156000, loss: 8.936753
 >> iter 157000, loss: 9.144834
 >> iter 158000, loss: 9.039091
 >> iter 159000, loss: 9.207826
 >> iter 160000, loss: 9.105080
   Number of active neurons: 2
 >> iter 161000, loss: 9.188359
 >> iter 162000, loss: 8.976244
 >> iter 163000, loss: 9.292777
 >> iter 164000, loss: 9.214023
 >> iter 165000, loss: 9.158243
 >> iter 166000, loss: 8.966040
 >> iter 167000, loss: 9.167151
 >> iter 168000, loss: 9.023597
 >> iter 169000, loss: 9.164388
 >> iter 170000, loss: 9.041708
   Number of active neurons: 2
 >> iter 171000, loss: 9.155547
 >> iter 172000, loss: 9.002029
 >> iter 173000, loss: 9.204489
 >> iter 174000, loss: 9.002390
 >> iter 175000, loss: 9.271832
 >> iter 176000, loss: 9.071186
 >> iter 177000, loss: 9.267445
 >> iter 178000, loss: 9.131239
 >> iter 179000, loss: 9.286710
 >> iter 180000, loss: 9.123164
   Number of active neurons: 2
 >> iter 181000, loss: 9.128672
 >> iter 182000, loss: 9.097751
 >> iter 183000, loss: 9.154793
 >> iter 184000, loss: 9.143426
 >> iter 185000, loss: 9.254547
 >> iter 186000, loss: 8.863167
 >> iter 187000, loss: 9.150737
 >> iter 188000, loss: 8.964483
 >> iter 189000, loss: 9.183243
 >> iter 190000, loss: 8.956525
   Number of active neurons: 2
 >> iter 191000, loss: 9.405525
 >> iter 192000, loss: 9.161532
 >> iter 193000, loss: 9.246591
 >> iter 194000, loss: 9.105019
 >> iter 195000, loss: 9.327670
 >> iter 196000, loss: 9.047205
 >> iter 197000, loss: 9.199893
 >> iter 198000, loss: 8.888495
 >> iter 199000, loss: 9.232275
 >> iter 200000, loss: 9.053035
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 12.6617467651
   - Test - Long: 2.81985900705
   - Test - Big: 12.2788772112
   - Test - A: 17.0521965202
   - Test - B: 26.5315645624
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 21.128755
 >> iter 2000, loss: 18.814848
 >> iter 3000, loss: 17.949898
 >> iter 4000, loss: 17.646805
 >> iter 5000, loss: 17.518601
 >> iter 6000, loss: 17.489517
 >> iter 7000, loss: 17.461453
 >> iter 8000, loss: 17.468087
 >> iter 9000, loss: 17.452693
 >> iter 10000, loss: 17.464687
   Number of active neurons: 0
 >> iter 11000, loss: 17.448629
 >> iter 12000, loss: 17.463661
 >> iter 13000, loss: 17.450072
 >> iter 14000, loss: 17.463729
 >> iter 15000, loss: 17.448758
 >> iter 16000, loss: 17.465579
 >> iter 17000, loss: 17.449689
 >> iter 18000, loss: 17.465421
 >> iter 19000, loss: 17.453755
 >> iter 20000, loss: 17.465505
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 15.212509
 >> iter 22000, loss: 12.176582
 >> iter 23000, loss: 10.935135
 >> iter 24000, loss: 9.990749
 >> iter 25000, loss: 9.869708
 >> iter 26000, loss: 9.583558
 >> iter 27000, loss: 9.556488
 >> iter 28000, loss: 9.266040
 >> iter 29000, loss: 9.297128
 >> iter 30000, loss: 9.035110
   Number of active neurons: 2
 >> iter 31000, loss: 9.330783
 >> iter 32000, loss: 9.034655
 >> iter 33000, loss: 9.323036
 >> iter 34000, loss: 9.092045
 >> iter 35000, loss: 9.303790
 >> iter 36000, loss: 9.113330
 >> iter 37000, loss: 9.335490
 >> iter 38000, loss: 9.009294
 >> iter 39000, loss: 9.295959
 >> iter 40000, loss: 9.003734
   Number of active neurons: 2
 >> iter 41000, loss: 9.132584
 >> iter 42000, loss: 8.970058
 >> iter 43000, loss: 9.336195
 >> iter 44000, loss: 9.171142
 >> iter 45000, loss: 9.309763
 >> iter 46000, loss: 9.009175
 >> iter 47000, loss: 9.225895
 >> iter 48000, loss: 9.057320
 >> iter 49000, loss: 9.201927
 >> iter 50000, loss: 9.138333
   Number of active neurons: 2
 >> iter 51000, loss: 9.216619
 >> iter 52000, loss: 9.033946
 >> iter 53000, loss: 9.161160
 >> iter 54000, loss: 9.019774
 >> iter 55000, loss: 9.181723
 >> iter 56000, loss: 9.112404
 >> iter 57000, loss: 9.365952
 >> iter 58000, loss: 9.283425
 >> iter 59000, loss: 9.274082
 >> iter 60000, loss: 9.086329
   Number of active neurons: 2
 >> iter 61000, loss: 9.046404
 >> iter 62000, loss: 9.137828
 >> iter 63000, loss: 9.339758
 >> iter 64000, loss: 9.065908
 >> iter 65000, loss: 9.276741
 >> iter 66000, loss: 9.026781
 >> iter 67000, loss: 9.199331
 >> iter 68000, loss: 9.059704
 >> iter 69000, loss: 9.213644
 >> iter 70000, loss: 8.957084
   Number of active neurons: 2
 >> iter 71000, loss: 9.219963
 >> iter 72000, loss: 9.023657
 >> iter 73000, loss: 9.227645
 >> iter 74000, loss: 9.001734
 >> iter 75000, loss: 9.263713
 >> iter 76000, loss: 9.031174
 >> iter 77000, loss: 9.245903
 >> iter 78000, loss: 9.021934
 >> iter 79000, loss: 9.206384
 >> iter 80000, loss: 9.122615
   Number of active neurons: 2
 >> iter 81000, loss: 9.244753
 >> iter 82000, loss: 9.115206
 >> iter 83000, loss: 9.306413
 >> iter 84000, loss: 9.074134
 >> iter 85000, loss: 9.166223
 >> iter 86000, loss: 9.266511
 >> iter 87000, loss: 9.413841
 >> iter 88000, loss: 9.258308
 >> iter 89000, loss: 9.362171
 >> iter 90000, loss: 9.121446
   Number of active neurons: 2
 >> iter 91000, loss: 9.262212
 >> iter 92000, loss: 9.004503
 >> iter 93000, loss: 9.229102
 >> iter 94000, loss: 9.060224
 >> iter 95000, loss: 9.198836
 >> iter 96000, loss: 9.077662
 >> iter 97000, loss: 9.353484
 >> iter 98000, loss: 9.065351
 >> iter 99000, loss: 9.298467
 >> iter 100000, loss: 9.073850
   Number of active neurons: 2
 >> iter 101000, loss: 9.269605
 >> iter 102000, loss: 9.073279
 >> iter 103000, loss: 9.094393
 >> iter 104000, loss: 9.016416
 >> iter 105000, loss: 9.176803
 >> iter 106000, loss: 9.098526
 >> iter 107000, loss: 9.124681
 >> iter 108000, loss: 8.982978
 >> iter 109000, loss: 9.218190
 >> iter 110000, loss: 9.047365
   Number of active neurons: 2
 >> iter 111000, loss: 9.159894
 >> iter 112000, loss: 9.135211
 >> iter 113000, loss: 9.282589
 >> iter 114000, loss: 9.116586
 >> iter 115000, loss: 9.212521
 >> iter 116000, loss: 8.978371
 >> iter 117000, loss: 9.179716
 >> iter 118000, loss: 9.013494
 >> iter 119000, loss: 9.158171
 >> iter 120000, loss: 9.035603
   Number of active neurons: 2
 >> iter 121000, loss: 9.197105
 >> iter 122000, loss: 9.055479
 >> iter 123000, loss: 9.206576
 >> iter 124000, loss: 9.003407
 >> iter 125000, loss: 9.089405
 >> iter 126000, loss: 9.202301
 >> iter 127000, loss: 9.240026
 >> iter 128000, loss: 9.096817
 >> iter 129000, loss: 9.093540
 >> iter 130000, loss: 9.149452
   Number of active neurons: 2
 >> iter 131000, loss: 9.211334
 >> iter 132000, loss: 9.084316
 >> iter 133000, loss: 9.167109
 >> iter 134000, loss: 9.074077
 >> iter 135000, loss: 9.217766
 >> iter 136000, loss: 9.085007
 >> iter 137000, loss: 9.155764
 >> iter 138000, loss: 9.136809
 >> iter 139000, loss: 9.160811
 >> iter 140000, loss: 9.039425
   Number of active neurons: 2
 >> iter 141000, loss: 9.175186
 >> iter 142000, loss: 9.130207
 >> iter 143000, loss: 9.215712
 >> iter 144000, loss: 9.099023
 >> iter 145000, loss: 9.135025
 >> iter 146000, loss: 9.186492
 >> iter 147000, loss: 9.214518
 >> iter 148000, loss: 9.115100
 >> iter 149000, loss: 9.201476
 >> iter 150000, loss: 9.095395
   Number of active neurons: 2
 >> iter 151000, loss: 9.156368
 >> iter 152000, loss: 9.128523
 >> iter 153000, loss: 9.120242
 >> iter 154000, loss: 9.228129
 >> iter 155000, loss: 9.265322
 >> iter 156000, loss: 9.049357
 >> iter 157000, loss: 9.253507
 >> iter 158000, loss: 9.089467
 >> iter 159000, loss: 9.204498
 >> iter 160000, loss: 9.056555
   Number of active neurons: 2
 >> iter 161000, loss: 9.132100
 >> iter 162000, loss: 9.097245
 >> iter 163000, loss: 9.117753
 >> iter 164000, loss: 9.079274
 >> iter 165000, loss: 9.148345
 >> iter 166000, loss: 9.020401
 >> iter 167000, loss: 9.110087
 >> iter 168000, loss: 8.894104
 >> iter 169000, loss: 9.071378
 >> iter 170000, loss: 8.985272
   Number of active neurons: 2
 >> iter 171000, loss: 9.271481
 >> iter 172000, loss: 9.074785
 >> iter 173000, loss: 9.243777
 >> iter 174000, loss: 9.054942
 >> iter 175000, loss: 9.158336
 >> iter 176000, loss: 8.984689
 >> iter 177000, loss: 9.220555
 >> iter 178000, loss: 8.994339
 >> iter 179000, loss: 9.119554
 >> iter 180000, loss: 9.005279
   Number of active neurons: 2
 >> iter 181000, loss: 9.303761
 >> iter 182000, loss: 9.157858
 >> iter 183000, loss: 9.312588
 >> iter 184000, loss: 9.059093
 >> iter 185000, loss: 9.142012
 >> iter 186000, loss: 8.926929
 >> iter 187000, loss: 9.085424
 >> iter 188000, loss: 9.022893
 >> iter 189000, loss: 9.238455
 >> iter 190000, loss: 9.106029
   Number of active neurons: 2
 >> iter 191000, loss: 9.110872
 >> iter 192000, loss: 9.152711
 >> iter 193000, loss: 9.333692
 >> iter 194000, loss: 9.029565
 >> iter 195000, loss: 9.386717
 >> iter 196000, loss: 8.980351
 >> iter 197000, loss: 9.182268
 >> iter 198000, loss: 9.047065
 >> iter 199000, loss: 9.258331
 >> iter 200000, loss: 9.022813
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 12.2577548449
   - Test - Long: 2.68986550672
   - Test - Big: 11.7568824312
   - Test - A: 17.0521965202
   - Test - B: 27.6781547897
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 21.128750
 >> iter 2000, loss: 18.814846
 >> iter 3000, loss: 17.949897
 >> iter 4000, loss: 17.646805
 >> iter 5000, loss: 17.518601
 >> iter 6000, loss: 17.489517
 >> iter 7000, loss: 17.461453
 >> iter 8000, loss: 17.468087
 >> iter 9000, loss: 17.452693
 >> iter 10000, loss: 17.464687
   Number of active neurons: 0
 >> iter 11000, loss: 17.448629
 >> iter 12000, loss: 17.463661
 >> iter 13000, loss: 17.450072
 >> iter 14000, loss: 17.463729
 >> iter 15000, loss: 17.448758
 >> iter 16000, loss: 17.465579
 >> iter 17000, loss: 17.449689
 >> iter 18000, loss: 17.465422
 >> iter 19000, loss: 17.453755
 >> iter 20000, loss: 17.465505
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 14.420204
 >> iter 22000, loss: 12.300528
 >> iter 23000, loss: 11.554358
 >> iter 24000, loss: 10.893395
 >> iter 25000, loss: 10.723673
 >> iter 26000, loss: 10.438743
 >> iter 27000, loss: 10.604672
 >> iter 28000, loss: 10.416031
 >> iter 29000, loss: 10.456610
 >> iter 30000, loss: 10.265133
   Number of active neurons: 2
 >> iter 31000, loss: 10.444927
 >> iter 32000, loss: 10.292560
 >> iter 33000, loss: 10.301955
 >> iter 34000, loss: 10.177939
 >> iter 35000, loss: 10.349640
 >> iter 36000, loss: 10.286777
 >> iter 37000, loss: 10.477627
 >> iter 38000, loss: 10.521479
 >> iter 39000, loss: 10.495019
 >> iter 40000, loss: 10.141224
   Number of active neurons: 2
 >> iter 41000, loss: 10.457623
 >> iter 42000, loss: 10.192495
 >> iter 43000, loss: 10.147806
 >> iter 44000, loss: 10.106379
 >> iter 45000, loss: 10.451788
 >> iter 46000, loss: 10.275033
 >> iter 47000, loss: 10.268579
 >> iter 48000, loss: 10.112125
 >> iter 49000, loss: 10.322193
 >> iter 50000, loss: 10.262246
   Number of active neurons: 2
 >> iter 51000, loss: 10.298592
 >> iter 52000, loss: 10.103254
 >> iter 53000, loss: 10.265521
 >> iter 54000, loss: 10.111718
 >> iter 55000, loss: 10.197522
 >> iter 56000, loss: 10.056898
 >> iter 57000, loss: 10.074381
 >> iter 58000, loss: 10.028116
 >> iter 59000, loss: 10.061742
 >> iter 60000, loss: 9.885311
   Number of active neurons: 2
 >> iter 61000, loss: 10.022213
 >> iter 62000, loss: 9.968106
 >> iter 63000, loss: 10.012249
 >> iter 64000, loss: 9.927891
 >> iter 65000, loss: 10.186667
 >> iter 66000, loss: 10.120128
 >> iter 67000, loss: 10.181161
 >> iter 68000, loss: 9.980592
 >> iter 69000, loss: 10.028742
 >> iter 70000, loss: 10.106689
   Number of active neurons: 2
 >> iter 71000, loss: 10.120293
 >> iter 72000, loss: 9.988682
 >> iter 73000, loss: 10.107127
 >> iter 74000, loss: 9.937630
 >> iter 75000, loss: 10.119942
 >> iter 76000, loss: 9.951164
 >> iter 77000, loss: 10.025875
 >> iter 78000, loss: 9.912627
 >> iter 79000, loss: 10.218378
 >> iter 80000, loss: 10.029116
   Number of active neurons: 2
 >> iter 81000, loss: 10.068240
 >> iter 82000, loss: 9.933519
 >> iter 83000, loss: 10.044519
 >> iter 84000, loss: 9.830893
 >> iter 85000, loss: 10.029826
 >> iter 86000, loss: 9.872645
 >> iter 87000, loss: 10.114976
 >> iter 88000, loss: 10.014222
 >> iter 89000, loss: 10.085715
 >> iter 90000, loss: 9.981373
   Number of active neurons: 2
 >> iter 91000, loss: 10.215684
 >> iter 92000, loss: 9.889318
 >> iter 93000, loss: 10.005277
 >> iter 94000, loss: 9.886528
 >> iter 95000, loss: 10.145633
 >> iter 96000, loss: 9.965842
 >> iter 97000, loss: 10.088231
 >> iter 98000, loss: 10.064419
 >> iter 99000, loss: 10.201621
 >> iter 100000, loss: 9.862027
   Number of active neurons: 2
 >> iter 101000, loss: 10.053676
 >> iter 102000, loss: 9.835788
 >> iter 103000, loss: 9.996996
 >> iter 104000, loss: 9.763597
 >> iter 105000, loss: 10.085050
 >> iter 106000, loss: 10.061731
 >> iter 107000, loss: 10.062559
 >> iter 108000, loss: 9.965147
 >> iter 109000, loss: 10.230536
 >> iter 110000, loss: 9.829172
   Number of active neurons: 2
 >> iter 111000, loss: 10.245996
 >> iter 112000, loss: 9.732188
 >> iter 113000, loss: 10.008078
 >> iter 114000, loss: 9.928577
 >> iter 115000, loss: 10.059814
 >> iter 116000, loss: 9.825045
 >> iter 117000, loss: 10.004484
 >> iter 118000, loss: 9.841024
 >> iter 119000, loss: 10.009276
 >> iter 120000, loss: 9.910587
   Number of active neurons: 2
 >> iter 121000, loss: 9.865150
 >> iter 122000, loss: 9.770230
 >> iter 123000, loss: 10.009390
 >> iter 124000, loss: 9.886621
 >> iter 125000, loss: 10.008786
 >> iter 126000, loss: 9.811429
 >> iter 127000, loss: 9.896269
 >> iter 128000, loss: 9.777180
 >> iter 129000, loss: 9.866075
 >> iter 130000, loss: 9.864204
   Number of active neurons: 2
 >> iter 131000, loss: 9.968649
 >> iter 132000, loss: 9.808008
 >> iter 133000, loss: 9.995196
 >> iter 134000, loss: 9.852297
 >> iter 135000, loss: 10.044175
 >> iter 136000, loss: 9.739285
 >> iter 137000, loss: 10.119759
 >> iter 138000, loss: 9.960097
 >> iter 139000, loss: 9.976087
 >> iter 140000, loss: 9.811626
   Number of active neurons: 2
 >> iter 141000, loss: 9.985340
 >> iter 142000, loss: 9.776409
 >> iter 143000, loss: 9.987317
 >> iter 144000, loss: 9.881854
 >> iter 145000, loss: 10.056625
 >> iter 146000, loss: 9.987703
 >> iter 147000, loss: 10.173200
 >> iter 148000, loss: 10.056984
 >> iter 149000, loss: 10.007815
 >> iter 150000, loss: 10.090212
   Number of active neurons: 2
 >> iter 151000, loss: 10.005839
 >> iter 152000, loss: 9.841799
 >> iter 153000, loss: 9.996464
 >> iter 154000, loss: 9.741326
 >> iter 155000, loss: 10.013703
 >> iter 156000, loss: 9.811941
 >> iter 157000, loss: 9.972281
 >> iter 158000, loss: 9.782480
 >> iter 159000, loss: 10.088281
 >> iter 160000, loss: 9.940681
   Number of active neurons: 2
 >> iter 161000, loss: 10.063209
 >> iter 162000, loss: 9.876309
 >> iter 163000, loss: 9.889509
 >> iter 164000, loss: 9.771223
 >> iter 165000, loss: 9.845077
 >> iter 166000, loss: 9.802038
 >> iter 167000, loss: 9.868966
 >> iter 168000, loss: 9.818037
 >> iter 169000, loss: 10.040026
 >> iter 170000, loss: 9.909115
   Number of active neurons: 2
 >> iter 171000, loss: 9.984199
 >> iter 172000, loss: 9.902237
 >> iter 173000, loss: 10.028776
 >> iter 174000, loss: 9.947584
 >> iter 175000, loss: 10.012497
 >> iter 176000, loss: 9.776738
 >> iter 177000, loss: 10.005094
 >> iter 178000, loss: 9.879382
 >> iter 179000, loss: 9.874487
 >> iter 180000, loss: 9.797884
   Number of active neurons: 2
 >> iter 181000, loss: 9.952671
 >> iter 182000, loss: 9.861842
 >> iter 183000, loss: 10.118387
 >> iter 184000, loss: 9.853486
 >> iter 185000, loss: 10.075977
 >> iter 186000, loss: 9.982360
 >> iter 187000, loss: 10.235385
 >> iter 188000, loss: 9.945689
 >> iter 189000, loss: 9.935025
 >> iter 190000, loss: 9.895015
   Number of active neurons: 2
 >> iter 191000, loss: 9.968767
 >> iter 192000, loss: 9.899991
 >> iter 193000, loss: 9.887690
 >> iter 194000, loss: 9.859644
 >> iter 195000, loss: 10.058175
 >> iter 196000, loss: 9.782876
 >> iter 197000, loss: 10.024059
 >> iter 198000, loss: 9.879317
 >> iter 199000, loss: 9.994023
 >> iter 200000, loss: 9.900226
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 17.595648087
   - Test - Long: 3.02984850757
   - Test - Big: 17.7488225118
   - Test - A: 17.0521965202
   - Test - B: 36.6042263849
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.878839
 >> iter 2000, loss: 16.516777
 >> iter 3000, loss: 15.405224
 >> iter 4000, loss: 14.766395
 >> iter 5000, loss: 14.516127
 >> iter 6000, loss: 14.653798
 >> iter 7000, loss: 14.798190
 >> iter 8000, loss: 14.609160
 >> iter 9000, loss: 14.649792
 >> iter 10000, loss: 14.648556
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 1
 >> iter 11000, loss: 12.285280
 >> iter 12000, loss: 8.761840
 >> iter 13000, loss: 7.533013
 >> iter 14000, loss: 6.866582
 >> iter 15000, loss: 6.744825
 >> iter 16000, loss: 6.494460
 >> iter 17000, loss: 6.620869
 >> iter 18000, loss: 6.366940
 >> iter 19000, loss: 6.529358
 >> iter 20000, loss: 6.331140
   Number of active neurons: 2
 >> iter 21000, loss: 6.489065
 >> iter 22000, loss: 6.400562
 >> iter 23000, loss: 6.618748
 >> iter 24000, loss: 6.399062
 >> iter 25000, loss: 6.552661
 >> iter 26000, loss: 6.280100
 >> iter 27000, loss: 6.549258
 >> iter 28000, loss: 6.328179
 >> iter 29000, loss: 6.471117
 >> iter 30000, loss: 6.261140
   Number of active neurons: 2
 >> iter 31000, loss: 6.462829
 >> iter 32000, loss: 6.268727
 >> iter 33000, loss: 6.505771
 >> iter 34000, loss: 6.315764
 >> iter 35000, loss: 6.442303
 >> iter 36000, loss: 6.395380
 >> iter 37000, loss: 6.596428
 >> iter 38000, loss: 6.313512
 >> iter 39000, loss: 6.454294
 >> iter 40000, loss: 6.252313
   Number of active neurons: 2
 >> iter 41000, loss: 6.446665
 >> iter 42000, loss: 6.274385
 >> iter 43000, loss: 6.469436
 >> iter 44000, loss: 6.350908
 >> iter 45000, loss: 6.487756
 >> iter 46000, loss: 6.314084
 >> iter 47000, loss: 6.463361
 >> iter 48000, loss: 6.252582
 >> iter 49000, loss: 6.497743
 >> iter 50000, loss: 6.313288
   Number of active neurons: 2
 >> iter 51000, loss: 6.429249
 >> iter 52000, loss: 6.295717
 >> iter 53000, loss: 6.500729
 >> iter 54000, loss: 6.335930
 >> iter 55000, loss: 6.456244
 >> iter 56000, loss: 6.308578
 >> iter 57000, loss: 6.518614
 >> iter 58000, loss: 6.343212
 >> iter 59000, loss: 6.489297
 >> iter 60000, loss: 6.346533
   Number of active neurons: 2
 >> iter 61000, loss: 6.419898
 >> iter 62000, loss: 6.287113
 >> iter 63000, loss: 6.465582
 >> iter 64000, loss: 6.290614
 >> iter 65000, loss: 6.557103
 >> iter 66000, loss: 6.375739
 >> iter 67000, loss: 6.492448
 >> iter 68000, loss: 6.329316
 >> iter 69000, loss: 6.436632
 >> iter 70000, loss: 6.390637
   Number of active neurons: 2
 >> iter 71000, loss: 6.520972
 >> iter 72000, loss: 6.384904
 >> iter 73000, loss: 6.501898
 >> iter 74000, loss: 6.349017
 >> iter 75000, loss: 6.475869
 >> iter 76000, loss: 6.383014
 >> iter 77000, loss: 6.440140
 >> iter 78000, loss: 6.374713
 >> iter 79000, loss: 6.507393
 >> iter 80000, loss: 6.336439
   Number of active neurons: 2
 >> iter 81000, loss: 6.542928
 >> iter 82000, loss: 6.407280
 >> iter 83000, loss: 6.524930
 >> iter 84000, loss: 6.356968
 >> iter 85000, loss: 6.558145
 >> iter 86000, loss: 6.389337
 >> iter 87000, loss: 6.560777
 >> iter 88000, loss: 6.343487
 >> iter 89000, loss: 6.537879
 >> iter 90000, loss: 6.359774
   Number of active neurons: 2
 >> iter 91000, loss: 6.510731
 >> iter 92000, loss: 6.341845
 >> iter 93000, loss: 6.462606
 >> iter 94000, loss: 6.311268
 >> iter 95000, loss: 6.477145
 >> iter 96000, loss: 6.321817
 >> iter 97000, loss: 6.460961
 >> iter 98000, loss: 6.315539
 >> iter 99000, loss: 6.481560
 >> iter 100000, loss: 6.279251
   Number of active neurons: 2
 >> iter 101000, loss: 6.553218
 >> iter 102000, loss: 6.318515
 >> iter 103000, loss: 6.505866
 >> iter 104000, loss: 6.388730
 >> iter 105000, loss: 6.522033
 >> iter 106000, loss: 6.399177
 >> iter 107000, loss: 6.500371
 >> iter 108000, loss: 6.308403
 >> iter 109000, loss: 6.480803
 >> iter 110000, loss: 6.373365
   Number of active neurons: 2
 >> iter 111000, loss: 6.521299
 >> iter 112000, loss: 6.386820
 >> iter 113000, loss: 6.476467
 >> iter 114000, loss: 6.350665
 >> iter 115000, loss: 6.518759
 >> iter 116000, loss: 6.331714
 >> iter 117000, loss: 6.461833
 >> iter 118000, loss: 6.330974
 >> iter 119000, loss: 6.494223
 >> iter 120000, loss: 6.305785
   Number of active neurons: 2
 >> iter 121000, loss: 6.475175
 >> iter 122000, loss: 6.337297
 >> iter 123000, loss: 6.468483
 >> iter 124000, loss: 6.350384
 >> iter 125000, loss: 6.441364
 >> iter 126000, loss: 6.312842
 >> iter 127000, loss: 6.489128
 >> iter 128000, loss: 6.321908
 >> iter 129000, loss: 6.413144
 >> iter 130000, loss: 6.366277
   Number of active neurons: 2
 >> iter 131000, loss: 6.492104
 >> iter 132000, loss: 6.351944
 >> iter 133000, loss: 6.439898
 >> iter 134000, loss: 6.311832
 >> iter 135000, loss: 6.527707
 >> iter 136000, loss: 6.346054
 >> iter 137000, loss: 6.533693
 >> iter 138000, loss: 6.359188
 >> iter 139000, loss: 6.552017
 >> iter 140000, loss: 6.358724
   Number of active neurons: 2
 >> iter 141000, loss: 6.442415
 >> iter 142000, loss: 6.311822
 >> iter 143000, loss: 6.548842
 >> iter 144000, loss: 6.335875
 >> iter 145000, loss: 6.512621
 >> iter 146000, loss: 6.361254
 >> iter 147000, loss: 6.450749
 >> iter 148000, loss: 6.308548
 >> iter 149000, loss: 6.407793
 >> iter 150000, loss: 6.312915
   Number of active neurons: 2
 >> iter 151000, loss: 6.439908
 >> iter 152000, loss: 6.426348
 >> iter 153000, loss: 6.499389
 >> iter 154000, loss: 6.384283
 >> iter 155000, loss: 6.484958
 >> iter 156000, loss: 6.322109
 >> iter 157000, loss: 6.543752
 >> iter 158000, loss: 6.360994
 >> iter 159000, loss: 6.491293
 >> iter 160000, loss: 6.339045
   Number of active neurons: 2
 >> iter 161000, loss: 6.468085
 >> iter 162000, loss: 6.283449
 >> iter 163000, loss: 6.463608
 >> iter 164000, loss: 6.370820
 >> iter 165000, loss: 6.518837
 >> iter 166000, loss: 6.343616
 >> iter 167000, loss: 6.496515
 >> iter 168000, loss: 6.396924
 >> iter 169000, loss: 6.488181
 >> iter 170000, loss: 6.339962
   Number of active neurons: 2
 >> iter 171000, loss: 6.451142
 >> iter 172000, loss: 6.324162
 >> iter 173000, loss: 6.478772
 >> iter 174000, loss: 6.327001
 >> iter 175000, loss: 6.498008
 >> iter 176000, loss: 6.384388
 >> iter 177000, loss: 6.560425
 >> iter 178000, loss: 6.382437
 >> iter 179000, loss: 6.551037
 >> iter 180000, loss: 6.351251
   Number of active neurons: 2
 >> iter 181000, loss: 6.527569
 >> iter 182000, loss: 6.345775
 >> iter 183000, loss: 6.487995
 >> iter 184000, loss: 6.390507
 >> iter 185000, loss: 6.519634
 >> iter 186000, loss: 6.374839
 >> iter 187000, loss: 6.530601
 >> iter 188000, loss: 6.348513
 >> iter 189000, loss: 6.503034
 >> iter 190000, loss: 6.350218
   Number of active neurons: 2
 >> iter 191000, loss: 6.499360
 >> iter 192000, loss: 6.357244
 >> iter 193000, loss: 6.545375
 >> iter 194000, loss: 6.404496
 >> iter 195000, loss: 6.577123
 >> iter 196000, loss: 6.353247
 >> iter 197000, loss: 6.614936
 >> iter 198000, loss: 6.355351
 >> iter 199000, loss: 6.574413
 >> iter 200000, loss: 6.396943
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 8.94182116358
   - Test - Long: 2.13489325534
   - Test - Big: 9.27090729093
   - Test - A: 0.819945336978
   - Test - B: 15.325644957
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.780761
 >> iter 2000, loss: 16.639336
 >> iter 3000, loss: 15.517132
 >> iter 4000, loss: 14.567583
 >> iter 5000, loss: 14.021064
 >> iter 6000, loss: 13.579408
 >> iter 7000, loss: 13.721635
 >> iter 8000, loss: 13.722274
 >> iter 9000, loss: 13.957384
 >> iter 10000, loss: 13.714983
   Number of active neurons: 2
 >> iter 11000, loss: 13.876356
 >> iter 12000, loss: 13.810734
 >> iter 13000, loss: 14.066762
 >> iter 14000, loss: 13.762248
 >> iter 15000, loss: 14.024941
 >> iter 16000, loss: 13.758068
 >> iter 17000, loss: 13.750851
 >> iter 18000, loss: 13.606791
 >> iter 19000, loss: 13.528168
 >> iter 20000, loss: 13.344453
   Number of active neurons: 2
 >> iter 21000, loss: 13.279191
 >> iter 22000, loss: 13.523433
 >> iter 23000, loss: 13.755999
 >> iter 24000, loss: 13.250249
 >> iter 25000, loss: 13.643489
 >> iter 26000, loss: 13.605939
 >> iter 27000, loss: 13.731094
 >> iter 28000, loss: 13.325585
 >> iter 29000, loss: 13.110433
 >> iter 30000, loss: 12.123013
   Number of active neurons: 2
 >> iter 31000, loss: 11.404996
 >> iter 32000, loss: 10.886641
 >> iter 33000, loss: 10.622664
 >> iter 34000, loss: 10.509364
 >> iter 35000, loss: 10.418364
 >> iter 36000, loss: 10.406230
 >> iter 37000, loss: 10.390258
 >> iter 38000, loss: 10.377271
 >> iter 39000, loss: 10.356200
 >> iter 40000, loss: 10.346384
   Number of active neurons: 2
 >> iter 41000, loss: 10.323227
 >> iter 42000, loss: 10.313884
 >> iter 43000, loss: 10.296639
 >> iter 44000, loss: 10.323478
 >> iter 45000, loss: 10.303390
 >> iter 46000, loss: 10.302196
 >> iter 47000, loss: 10.289748
 >> iter 48000, loss: 10.294454
 >> iter 49000, loss: 10.303406
 >> iter 50000, loss: 10.314806
   Number of active neurons: 2
 >> iter 51000, loss: 10.269645
 >> iter 52000, loss: 10.300466
 >> iter 53000, loss: 10.285376
 >> iter 54000, loss: 10.337215
 >> iter 55000, loss: 10.300906
 >> iter 56000, loss: 10.308726
 >> iter 57000, loss: 10.314751
 >> iter 58000, loss: 10.318931
 >> iter 59000, loss: 10.295881
 >> iter 60000, loss: 10.308778
   Number of active neurons: 2
 >> iter 61000, loss: 10.272935
 >> iter 62000, loss: 10.297668
 >> iter 63000, loss: 10.285391
 >> iter 64000, loss: 10.330600
 >> iter 65000, loss: 10.317746
 >> iter 66000, loss: 10.337042
 >> iter 67000, loss: 10.305514
 >> iter 68000, loss: 10.299165
 >> iter 69000, loss: 10.278446
 >> iter 70000, loss: 10.298256
   Number of active neurons: 2
 >> iter 71000, loss: 10.312697
 >> iter 72000, loss: 10.289466
 >> iter 73000, loss: 10.312842
 >> iter 74000, loss: 10.289375
 >> iter 75000, loss: 10.283867
 >> iter 76000, loss: 10.295697
 >> iter 77000, loss: 10.314043
 >> iter 78000, loss: 10.291959
 >> iter 79000, loss: 10.303647
 >> iter 80000, loss: 10.302808
   Number of active neurons: 2
 >> iter 81000, loss: 10.295771
 >> iter 82000, loss: 10.263164
 >> iter 83000, loss: 10.317317
 >> iter 84000, loss: 10.268123
 >> iter 85000, loss: 10.298990
 >> iter 86000, loss: 10.277013
 >> iter 87000, loss: 10.325693
 >> iter 88000, loss: 10.282092
 >> iter 89000, loss: 10.294702
 >> iter 90000, loss: 10.263266
   Number of active neurons: 2
 >> iter 91000, loss: 10.281160
 >> iter 92000, loss: 10.260511
 >> iter 93000, loss: 10.278459
 >> iter 94000, loss: 10.276020
 >> iter 95000, loss: 10.270864
 >> iter 96000, loss: 10.252894
 >> iter 97000, loss: 10.286602
 >> iter 98000, loss: 10.286512
 >> iter 99000, loss: 10.325057
 >> iter 100000, loss: 10.279589
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 17.8476430471
   - Test - Long: 3.68481575921
   - Test - Big: 18.0358196418
   - Test - A: 17.1988534098
   - Test - B: 15.6122925138
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.746513
 >> iter 2000, loss: 15.723881
 >> iter 3000, loss: 14.494299
 >> iter 4000, loss: 13.891087
 >> iter 5000, loss: 13.544733
 >> iter 6000, loss: 13.722845
 >> iter 7000, loss: 13.790925
 >> iter 8000, loss: 13.606159
 >> iter 9000, loss: 13.869772
 >> iter 10000, loss: 13.761139
   Number of active neurons: 2
 >> iter 11000, loss: 13.762302
 >> iter 12000, loss: 13.368495
 >> iter 13000, loss: 13.589675
 >> iter 14000, loss: 13.397287
 >> iter 15000, loss: 13.508553
 >> iter 16000, loss: 13.191632
 >> iter 17000, loss: 13.545353
 >> iter 18000, loss: 13.300666
 >> iter 19000, loss: 13.279757
 >> iter 20000, loss: 12.508738
   Number of active neurons: 2
 >> iter 21000, loss: 12.064553
 >> iter 22000, loss: 11.532949
 >> iter 23000, loss: 11.108907
 >> iter 24000, loss: 10.764578
 >> iter 25000, loss: 10.575632
 >> iter 26000, loss: 10.472403
 >> iter 27000, loss: 10.433902
 >> iter 28000, loss: 10.447800
 >> iter 29000, loss: 10.394125
 >> iter 30000, loss: 10.383324
   Number of active neurons: 2
 >> iter 31000, loss: 10.335691
 >> iter 32000, loss: 10.352542
 >> iter 33000, loss: 10.335501
 >> iter 34000, loss: 10.400261
 >> iter 35000, loss: 10.337889
 >> iter 36000, loss: 10.343511
 >> iter 37000, loss: 10.314185
 >> iter 38000, loss: 10.346048
 >> iter 39000, loss: 10.345645
 >> iter 40000, loss: 10.342423
   Number of active neurons: 2
 >> iter 41000, loss: 10.320706
 >> iter 42000, loss: 10.317631
 >> iter 43000, loss: 10.315918
 >> iter 44000, loss: 10.336483
 >> iter 45000, loss: 10.308809
 >> iter 46000, loss: 10.327999
 >> iter 47000, loss: 10.313397
 >> iter 48000, loss: 10.324244
 >> iter 49000, loss: 10.285292
 >> iter 50000, loss: 10.325006
   Number of active neurons: 2
 >> iter 51000, loss: 10.292759
 >> iter 52000, loss: 10.318681
 >> iter 53000, loss: 10.289374
 >> iter 54000, loss: 10.312875
 >> iter 55000, loss: 10.266680
 >> iter 56000, loss: 10.305120
 >> iter 57000, loss: 10.271920
 >> iter 58000, loss: 10.287226
 >> iter 59000, loss: 10.263410
 >> iter 60000, loss: 10.340193
   Number of active neurons: 2
 >> iter 61000, loss: 10.280997
 >> iter 62000, loss: 10.298429
 >> iter 63000, loss: 10.256860
 >> iter 64000, loss: 10.297002
 >> iter 65000, loss: 10.269538
 >> iter 66000, loss: 10.305884
 >> iter 67000, loss: 10.250233
 >> iter 68000, loss: 10.273319
 >> iter 69000, loss: 10.278708
 >> iter 70000, loss: 10.299995
   Number of active neurons: 2
 >> iter 71000, loss: 10.298866
 >> iter 72000, loss: 10.305399
 >> iter 73000, loss: 10.298513
 >> iter 74000, loss: 10.275395
 >> iter 75000, loss: 10.316835
 >> iter 76000, loss: 10.301900
 >> iter 77000, loss: 10.285851
 >> iter 78000, loss: 10.266401
 >> iter 79000, loss: 10.281975
 >> iter 80000, loss: 10.267029
   Number of active neurons: 2
 >> iter 81000, loss: 10.272090
 >> iter 82000, loss: 10.301966
 >> iter 83000, loss: 10.298773
 >> iter 84000, loss: 10.274726
 >> iter 85000, loss: 10.308824
 >> iter 86000, loss: 10.270132
 >> iter 87000, loss: 10.283143
 >> iter 88000, loss: 10.277464
 >> iter 89000, loss: 10.301364
 >> iter 90000, loss: 10.281756
   Number of active neurons: 2
 >> iter 91000, loss: 10.298109
 >> iter 92000, loss: 10.297604
 >> iter 93000, loss: 10.298719
 >> iter 94000, loss: 10.288638
 >> iter 95000, loss: 10.288973
 >> iter 96000, loss: 10.247535
 >> iter 97000, loss: 10.264637
 >> iter 98000, loss: 10.275836
 >> iter 99000, loss: 10.292624
 >> iter 100000, loss: 10.264472
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 17.8476430471
   - Test - Long: 3.68481575921
   - Test - Big: 18.0358196418
   - Test - A: 17.1988534098
   - Test - B: 15.6122925138
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.940634
 >> iter 2000, loss: 16.357916
 >> iter 3000, loss: 15.259876
 >> iter 4000, loss: 14.889979
 >> iter 5000, loss: 14.828076
 >> iter 6000, loss: 14.601215
 >> iter 7000, loss: 14.730579
 >> iter 8000, loss: 14.699653
 >> iter 9000, loss: 14.563926
 >> iter 10000, loss: 13.583660
   Number of active neurons: 2
 >> iter 11000, loss: 13.881557
 >> iter 12000, loss: 13.760243
 >> iter 13000, loss: 14.080157
 >> iter 14000, loss: 13.750911
 >> iter 15000, loss: 14.091182
 >> iter 16000, loss: 13.764260
 >> iter 17000, loss: 13.895792
 >> iter 18000, loss: 13.695647
 >> iter 19000, loss: 13.778185
 >> iter 20000, loss: 13.553022
   Number of active neurons: 2
 >> iter 21000, loss: 13.735861
 >> iter 22000, loss: 13.696551
 >> iter 23000, loss: 13.861632
 >> iter 24000, loss: 13.445207
 >> iter 25000, loss: 13.652813
 >> iter 26000, loss: 13.152556
 >> iter 27000, loss: 12.281491
 >> iter 28000, loss: 11.512502
 >> iter 29000, loss: 10.945580
 >> iter 30000, loss: 10.684250
   Number of active neurons: 2
 >> iter 31000, loss: 10.568538
 >> iter 32000, loss: 10.467851
 >> iter 33000, loss: 10.393743
 >> iter 34000, loss: 10.448123
 >> iter 35000, loss: 10.348399
 >> iter 36000, loss: 10.367769
 >> iter 37000, loss: 10.347502
 >> iter 38000, loss: 10.349292
 >> iter 39000, loss: 10.312331
 >> iter 40000, loss: 10.334524
   Number of active neurons: 2
 >> iter 41000, loss: 10.325577
 >> iter 42000, loss: 10.355615
 >> iter 43000, loss: 10.348856
 >> iter 44000, loss: 10.339538
 >> iter 45000, loss: 10.303953
 >> iter 46000, loss: 10.335709
 >> iter 47000, loss: 10.330101
 >> iter 48000, loss: 10.307177
 >> iter 49000, loss: 10.318136
 >> iter 50000, loss: 10.320340
   Number of active neurons: 2
 >> iter 51000, loss: 10.295522
 >> iter 52000, loss: 10.334092
 >> iter 53000, loss: 10.308127
 >> iter 54000, loss: 10.320227
 >> iter 55000, loss: 10.269527
 >> iter 56000, loss: 10.331405
 >> iter 57000, loss: 10.276144
 >> iter 58000, loss: 10.332089
 >> iter 59000, loss: 10.281840
 >> iter 60000, loss: 10.311333
   Number of active neurons: 2
 >> iter 61000, loss: 10.266405
 >> iter 62000, loss: 10.319992
 >> iter 63000, loss: 10.266722
 >> iter 64000, loss: 10.302061
 >> iter 65000, loss: 10.280596
 >> iter 66000, loss: 10.294223
 >> iter 67000, loss: 10.281554
 >> iter 68000, loss: 10.305274
 >> iter 69000, loss: 10.270794
 >> iter 70000, loss: 10.297101
   Number of active neurons: 2
 >> iter 71000, loss: 10.312008
 >> iter 72000, loss: 10.279084
 >> iter 73000, loss: 10.316443
 >> iter 74000, loss: 10.303049
 >> iter 75000, loss: 10.307474
 >> iter 76000, loss: 10.277961
 >> iter 77000, loss: 10.289564
 >> iter 78000, loss: 10.312344
 >> iter 79000, loss: 10.323992
 >> iter 80000, loss: 10.288173
   Number of active neurons: 2
 >> iter 81000, loss: 10.300627
 >> iter 82000, loss: 10.293644
 >> iter 83000, loss: 10.305587
 >> iter 84000, loss: 10.268983
 >> iter 85000, loss: 10.302735
 >> iter 86000, loss: 10.291369
 >> iter 87000, loss: 10.307499
 >> iter 88000, loss: 10.289477
 >> iter 89000, loss: 10.306436
 >> iter 90000, loss: 10.278309
   Number of active neurons: 2
 >> iter 91000, loss: 10.273876
 >> iter 92000, loss: 10.291094
 >> iter 93000, loss: 10.310441
 >> iter 94000, loss: 10.276656
 >> iter 95000, loss: 10.320853
 >> iter 96000, loss: 10.322806
 >> iter 97000, loss: 10.331759
 >> iter 98000, loss: 10.308714
 >> iter 99000, loss: 10.320702
 >> iter 100000, loss: 10.322947
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 17.8476430471
   - Test - Long: 3.68481575921
   - Test - Big: 18.0358196418
   - Test - A: 17.1988534098
   - Test - B: 15.6122925138
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 21.128752
 >> iter 2000, loss: 18.814847
 >> iter 3000, loss: 17.949898
 >> iter 4000, loss: 17.646805
 >> iter 5000, loss: 17.518601
 >> iter 6000, loss: 17.489517
 >> iter 7000, loss: 17.461453
 >> iter 8000, loss: 17.468087
 >> iter 9000, loss: 17.452693
 >> iter 10000, loss: 17.464687
   Number of active neurons: 0
 >> iter 11000, loss: 17.448629
 >> iter 12000, loss: 17.463661
 >> iter 13000, loss: 17.450072
 >> iter 14000, loss: 17.463729
 >> iter 15000, loss: 17.448758
 >> iter 16000, loss: 17.465579
 >> iter 17000, loss: 17.449689
 >> iter 18000, loss: 17.465421
 >> iter 19000, loss: 17.453755
 >> iter 20000, loss: 17.465505
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 15.438677
 >> iter 22000, loss: 12.986310
 >> iter 23000, loss: 11.791874
 >> iter 24000, loss: 11.140628
 >> iter 25000, loss: 11.041618
 >> iter 26000, loss: 10.689119
 >> iter 27000, loss: 10.555037
 >> iter 28000, loss: 10.477229
 >> iter 29000, loss: 10.661182
 >> iter 30000, loss: 10.387959
   Number of active neurons: 2
 >> iter 31000, loss: 10.576554
 >> iter 32000, loss: 10.366771
 >> iter 33000, loss: 10.377573
 >> iter 34000, loss: 10.290748
 >> iter 35000, loss: 10.488796
 >> iter 36000, loss: 10.283689
 >> iter 37000, loss: 10.287730
 >> iter 38000, loss: 10.062990
 >> iter 39000, loss: 10.239004
 >> iter 40000, loss: 10.091517
   Number of active neurons: 2
 >> iter 41000, loss: 10.334138
 >> iter 42000, loss: 10.311735
 >> iter 43000, loss: 10.322130
 >> iter 44000, loss: 10.357962
 >> iter 45000, loss: 10.248738
 >> iter 46000, loss: 9.978525
 >> iter 47000, loss: 10.205920
 >> iter 48000, loss: 10.103360
 >> iter 49000, loss: 10.152367
 >> iter 50000, loss: 10.090608
   Number of active neurons: 2
 >> iter 51000, loss: 10.272635
 >> iter 52000, loss: 10.119812
 >> iter 53000, loss: 10.356315
 >> iter 54000, loss: 10.066579
 >> iter 55000, loss: 10.156190
 >> iter 56000, loss: 10.105479
 >> iter 57000, loss: 10.117684
 >> iter 58000, loss: 9.922822
 >> iter 59000, loss: 10.073247
 >> iter 60000, loss: 10.007016
   Number of active neurons: 2
 >> iter 61000, loss: 10.168271
 >> iter 62000, loss: 10.094136
 >> iter 63000, loss: 10.336848
 >> iter 64000, loss: 10.031606
 >> iter 65000, loss: 10.106862
 >> iter 66000, loss: 10.034823
 >> iter 67000, loss: 10.035188
 >> iter 68000, loss: 9.892970
 >> iter 69000, loss: 9.946527
 >> iter 70000, loss: 9.920722
   Number of active neurons: 2
 >> iter 71000, loss: 10.242939
 >> iter 72000, loss: 9.958291
 >> iter 73000, loss: 10.100037
 >> iter 74000, loss: 9.945283
 >> iter 75000, loss: 10.084401
 >> iter 76000, loss: 9.967310
 >> iter 77000, loss: 10.145406
 >> iter 78000, loss: 9.824483
 >> iter 79000, loss: 10.204153
 >> iter 80000, loss: 10.031996
   Number of active neurons: 2
 >> iter 81000, loss: 10.270416
 >> iter 82000, loss: 10.144865
 >> iter 83000, loss: 10.286017
 >> iter 84000, loss: 10.084850
 >> iter 85000, loss: 10.146268
 >> iter 86000, loss: 10.109994
 >> iter 87000, loss: 10.284890
 >> iter 88000, loss: 9.891646
 >> iter 89000, loss: 10.078246
 >> iter 90000, loss: 10.020013
   Number of active neurons: 2
 >> iter 91000, loss: 10.227985
 >> iter 92000, loss: 10.040832
 >> iter 93000, loss: 10.160532
 >> iter 94000, loss: 9.984513
 >> iter 95000, loss: 10.147857
 >> iter 96000, loss: 9.955408
 >> iter 97000, loss: 10.002329
 >> iter 98000, loss: 9.806963
 >> iter 99000, loss: 10.033019
 >> iter 100000, loss: 9.884367
   Number of active neurons: 2
 >> iter 101000, loss: 10.050240
 >> iter 102000, loss: 9.951511
 >> iter 103000, loss: 10.111943
 >> iter 104000, loss: 9.883971
 >> iter 105000, loss: 10.012903
 >> iter 106000, loss: 10.179639
 >> iter 107000, loss: 10.165479
 >> iter 108000, loss: 9.824983
 >> iter 109000, loss: 9.996169
 >> iter 110000, loss: 9.866202
   Number of active neurons: 2
 >> iter 111000, loss: 10.039455
 >> iter 112000, loss: 9.884562
 >> iter 113000, loss: 10.081713
 >> iter 114000, loss: 9.794978
 >> iter 115000, loss: 10.068025
 >> iter 116000, loss: 9.979338
 >> iter 117000, loss: 10.149784
 >> iter 118000, loss: 9.959987
 >> iter 119000, loss: 10.063655
 >> iter 120000, loss: 9.900032
   Number of active neurons: 2
 >> iter 121000, loss: 9.997950
 >> iter 122000, loss: 9.872101
 >> iter 123000, loss: 9.976451
 >> iter 124000, loss: 9.808424
 >> iter 125000, loss: 10.057852
 >> iter 126000, loss: 9.876327
 >> iter 127000, loss: 10.112832
 >> iter 128000, loss: 9.822596
 >> iter 129000, loss: 10.114410
 >> iter 130000, loss: 9.889737
   Number of active neurons: 2
 >> iter 131000, loss: 10.089579
 >> iter 132000, loss: 9.833441
 >> iter 133000, loss: 9.931833
 >> iter 134000, loss: 9.742456
 >> iter 135000, loss: 9.992679
 >> iter 136000, loss: 9.992297
 >> iter 137000, loss: 9.980122
 >> iter 138000, loss: 9.889778
 >> iter 139000, loss: 9.969612
 >> iter 140000, loss: 9.885464
   Number of active neurons: 2
 >> iter 141000, loss: 9.911905
 >> iter 142000, loss: 9.889924
 >> iter 143000, loss: 9.928856
 >> iter 144000, loss: 9.834242
 >> iter 145000, loss: 10.192594
 >> iter 146000, loss: 9.968056
 >> iter 147000, loss: 9.978835
 >> iter 148000, loss: 9.880833
 >> iter 149000, loss: 10.014778
 >> iter 150000, loss: 9.989642
   Number of active neurons: 2
 >> iter 151000, loss: 10.015781
 >> iter 152000, loss: 10.037798
 >> iter 153000, loss: 9.973564
 >> iter 154000, loss: 9.889739
 >> iter 155000, loss: 9.995518
 >> iter 156000, loss: 9.825175
 >> iter 157000, loss: 9.942449
 >> iter 158000, loss: 9.758704
 >> iter 159000, loss: 9.966039
 >> iter 160000, loss: 10.054803
   Number of active neurons: 2
 >> iter 161000, loss: 10.219704
 >> iter 162000, loss: 10.054781
 >> iter 163000, loss: 10.118106
 >> iter 164000, loss: 9.857742
 >> iter 165000, loss: 10.065655
 >> iter 166000, loss: 9.930831
 >> iter 167000, loss: 9.958906
 >> iter 168000, loss: 9.796288
 >> iter 169000, loss: 9.959892
 >> iter 170000, loss: 9.827699
   Number of active neurons: 2
 >> iter 171000, loss: 9.940411
 >> iter 172000, loss: 9.890653
 >> iter 173000, loss: 10.000973
 >> iter 174000, loss: 9.796887
 >> iter 175000, loss: 10.062776
 >> iter 176000, loss: 9.866443
 >> iter 177000, loss: 10.002340
 >> iter 178000, loss: 9.703738
 >> iter 179000, loss: 9.974519
 >> iter 180000, loss: 9.803756
   Number of active neurons: 2
 >> iter 181000, loss: 9.968153
 >> iter 182000, loss: 9.750916
 >> iter 183000, loss: 9.968610
 >> iter 184000, loss: 9.732031
 >> iter 185000, loss: 10.021922
 >> iter 186000, loss: 9.794005
 >> iter 187000, loss: 10.104517
 >> iter 188000, loss: 9.899739
 >> iter 189000, loss: 9.899276
 >> iter 190000, loss: 9.870245
   Number of active neurons: 2
 >> iter 191000, loss: 10.149604
 >> iter 192000, loss: 10.100274
 >> iter 193000, loss: 10.007485
 >> iter 194000, loss: 9.710998
 >> iter 195000, loss: 10.122737
 >> iter 196000, loss: 10.131425
 >> iter 197000, loss: 10.178244
 >> iter 198000, loss: 10.032478
 >> iter 199000, loss: 10.118891
 >> iter 200000, loss: 9.923223
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 17.3436531269
   - Test - Long: 3.02984850757
   - Test - Big: 17.5498245018
   - Test - A: 17.0521965202
   - Test - B: 36.4975668289
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 21.128751
 >> iter 2000, loss: 18.814847
 >> iter 3000, loss: 17.949898
 >> iter 4000, loss: 17.646805
 >> iter 5000, loss: 17.518601
 >> iter 6000, loss: 17.489517
 >> iter 7000, loss: 17.461453
 >> iter 8000, loss: 17.468087
 >> iter 9000, loss: 17.452692
 >> iter 10000, loss: 17.464687
   Number of active neurons: 0
 >> iter 11000, loss: 17.448629
 >> iter 12000, loss: 17.463661
 >> iter 13000, loss: 17.450072
 >> iter 14000, loss: 17.463729
 >> iter 15000, loss: 17.448758
 >> iter 16000, loss: 17.465579
 >> iter 17000, loss: 17.449688
 >> iter 18000, loss: 17.465421
 >> iter 19000, loss: 17.453755
 >> iter 20000, loss: 17.465505
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 15.542460
 >> iter 22000, loss: 14.362145
 >> iter 23000, loss: 14.102198
 >> iter 24000, loss: 13.931726
 >> iter 25000, loss: 13.886825
 >> iter 26000, loss: 13.752440
 >> iter 27000, loss: 13.921349
 >> iter 28000, loss: 13.520877
 >> iter 29000, loss: 13.713572
 >> iter 30000, loss: 13.715020
   Number of active neurons: 2
 >> iter 31000, loss: 13.637175
 >> iter 32000, loss: 13.568359
 >> iter 33000, loss: 13.866261
 >> iter 34000, loss: 13.607647
 >> iter 35000, loss: 13.767507
 >> iter 36000, loss: 13.615661
 >> iter 37000, loss: 13.685746
 >> iter 38000, loss: 13.572449
 >> iter 39000, loss: 13.875307
 >> iter 40000, loss: 13.586082
   Number of active neurons: 2
 >> iter 41000, loss: 13.887813
 >> iter 42000, loss: 13.695129
 >> iter 43000, loss: 14.100912
 >> iter 44000, loss: 13.617604
 >> iter 45000, loss: 13.575351
 >> iter 46000, loss: 13.309262
 >> iter 47000, loss: 13.449408
 >> iter 48000, loss: 13.167964
 >> iter 49000, loss: 12.495106
 >> iter 50000, loss: 11.615523
   Number of active neurons: 2
 >> iter 51000, loss: 11.034147
 >> iter 52000, loss: 10.757915
 >> iter 53000, loss: 10.609218
 >> iter 54000, loss: 10.528394
 >> iter 55000, loss: 10.376979
 >> iter 56000, loss: 10.427679
 >> iter 57000, loss: 10.364193
 >> iter 58000, loss: 10.366699
 >> iter 59000, loss: 10.326664
 >> iter 60000, loss: 10.349792
   Number of active neurons: 2
 >> iter 61000, loss: 10.327018
 >> iter 62000, loss: 10.374810
 >> iter 63000, loss: 10.350802
 >> iter 64000, loss: 10.329196
 >> iter 65000, loss: 10.314653
 >> iter 66000, loss: 10.327504
 >> iter 67000, loss: 10.310936
 >> iter 68000, loss: 10.313232
 >> iter 69000, loss: 10.300273
 >> iter 70000, loss: 10.291723
   Number of active neurons: 2
 >> iter 71000, loss: 10.290156
 >> iter 72000, loss: 10.282484
 >> iter 73000, loss: 10.318429
 >> iter 74000, loss: 10.301449
 >> iter 75000, loss: 10.327401
 >> iter 76000, loss: 10.302204
 >> iter 77000, loss: 10.304010
 >> iter 78000, loss: 10.315246
 >> iter 79000, loss: 10.301346
 >> iter 80000, loss: 10.299251
   Number of active neurons: 2
 >> iter 81000, loss: 10.286469
 >> iter 82000, loss: 10.295310
 >> iter 83000, loss: 10.303380
 >> iter 84000, loss: 10.317965
 >> iter 85000, loss: 10.315254
 >> iter 86000, loss: 10.309818
 >> iter 87000, loss: 10.322622
 >> iter 88000, loss: 10.287039
 >> iter 89000, loss: 10.290260
 >> iter 90000, loss: 10.284091
   Number of active neurons: 2
 >> iter 91000, loss: 10.282921
 >> iter 92000, loss: 10.273875
 >> iter 93000, loss: 10.290057
 >> iter 94000, loss: 10.295117
 >> iter 95000, loss: 10.305978
 >> iter 96000, loss: 10.263881
 >> iter 97000, loss: 10.292674
 >> iter 98000, loss: 10.251310
 >> iter 99000, loss: 10.304286
 >> iter 100000, loss: 10.278735
   Number of active neurons: 2
 >> iter 101000, loss: 10.298772
 >> iter 102000, loss: 10.277789
 >> iter 103000, loss: 10.280402
 >> iter 104000, loss: 10.261538
 >> iter 105000, loss: 10.282749
 >> iter 106000, loss: 10.279111
 >> iter 107000, loss: 10.291739
 >> iter 108000, loss: 10.301349
 >> iter 109000, loss: 10.295015
 >> iter 110000, loss: 10.294744
   Number of active neurons: 2
 >> iter 111000, loss: 10.308569
 >> iter 112000, loss: 10.272280
 >> iter 113000, loss: 10.266019
 >> iter 114000, loss: 10.283731
 >> iter 115000, loss: 10.287383
 >> iter 116000, loss: 10.259255
 >> iter 117000, loss: 10.282177
 >> iter 118000, loss: 10.284658
 >> iter 119000, loss: 10.255416
 >> iter 120000, loss: 10.281365
   Number of active neurons: 2
 >> iter 121000, loss: 10.279767
 >> iter 122000, loss: 10.286606
 >> iter 123000, loss: 10.259019
 >> iter 124000, loss: 10.273922
 >> iter 125000, loss: 10.256697
 >> iter 126000, loss: 10.250210
 >> iter 127000, loss: 10.299087
 >> iter 128000, loss: 10.295419
 >> iter 129000, loss: 10.268895
 >> iter 130000, loss: 10.333097
   Number of active neurons: 2
 >> iter 131000, loss: 10.287543
 >> iter 132000, loss: 10.317153
 >> iter 133000, loss: 10.290562
 >> iter 134000, loss: 10.317460
 >> iter 135000, loss: 10.265328
 >> iter 136000, loss: 10.296982
 >> iter 137000, loss: 10.316589
 >> iter 138000, loss: 10.290737
 >> iter 139000, loss: 10.264696
 >> iter 140000, loss: 10.306298
   Number of active neurons: 2
 >> iter 141000, loss: 10.285216
 >> iter 142000, loss: 10.297696
 >> iter 143000, loss: 10.260507
 >> iter 144000, loss: 10.280371
 >> iter 145000, loss: 10.268288
 >> iter 146000, loss: 10.271347
 >> iter 147000, loss: 10.302290
 >> iter 148000, loss: 10.299534
 >> iter 149000, loss: 10.266025
 >> iter 150000, loss: 10.300883
   Number of active neurons: 2
 >> iter 151000, loss: 10.290914
 >> iter 152000, loss: 10.311443
 >> iter 153000, loss: 10.307653
 >> iter 154000, loss: 10.304848
 >> iter 155000, loss: 10.307013
 >> iter 156000, loss: 10.311785
 >> iter 157000, loss: 10.326963
 >> iter 158000, loss: 10.307883
 >> iter 159000, loss: 10.310312
 >> iter 160000, loss: 10.312250
   Number of active neurons: 2
 >> iter 161000, loss: 10.311119
 >> iter 162000, loss: 10.339370
 >> iter 163000, loss: 10.345122
 >> iter 164000, loss: 10.363914
 >> iter 165000, loss: 10.342082
 >> iter 166000, loss: 10.331673
 >> iter 167000, loss: 10.312997
 >> iter 168000, loss: 10.315067
 >> iter 169000, loss: 10.339084
 >> iter 170000, loss: 10.356297
   Number of active neurons: 2
 >> iter 171000, loss: 10.354715
 >> iter 172000, loss: 10.331961
 >> iter 173000, loss: 10.346442
 >> iter 174000, loss: 10.358306
 >> iter 175000, loss: 10.392961
 >> iter 176000, loss: 10.412906
 >> iter 177000, loss: 10.378069
 >> iter 178000, loss: 10.395818
 >> iter 179000, loss: 10.379338
 >> iter 180000, loss: 10.374309
   Number of active neurons: 2
 >> iter 181000, loss: 10.369496
 >> iter 182000, loss: 10.342620
 >> iter 183000, loss: 10.343001
 >> iter 184000, loss: 10.383394
 >> iter 185000, loss: 10.394718
 >> iter 186000, loss: 10.350453
 >> iter 187000, loss: 10.322715
 >> iter 188000, loss: 10.332872
 >> iter 189000, loss: 10.354246
 >> iter 190000, loss: 10.336563
   Number of active neurons: 2
 >> iter 191000, loss: 10.308466
 >> iter 192000, loss: 10.341222
 >> iter 193000, loss: 10.323916
 >> iter 194000, loss: 10.341811
 >> iter 195000, loss: 10.392601
 >> iter 196000, loss: 10.398638
 >> iter 197000, loss: 10.353139
 >> iter 198000, loss: 10.401686
 >> iter 199000, loss: 10.338871
 >> iter 200000, loss: 10.330761
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 17.8476430471
   - Test - Long: 3.68481575921
   - Test - Big: 18.0358196418
   - Test - A: 17.1988534098
   - Test - B: 15.6122925138
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.635761
 >> iter 2000, loss: 16.350142
 >> iter 3000, loss: 14.889548
 >> iter 4000, loss: 14.056640
 >> iter 5000, loss: 14.385610
 >> iter 6000, loss: 13.955497
 >> iter 7000, loss: 13.906627
 >> iter 8000, loss: 13.586187
 >> iter 9000, loss: 13.710557
 >> iter 10000, loss: 13.639522
   Number of active neurons: 2
 >> iter 11000, loss: 13.747381
 >> iter 12000, loss: 13.908346
 >> iter 13000, loss: 13.820333
 >> iter 14000, loss: 13.850691
 >> iter 15000, loss: 14.007890
 >> iter 16000, loss: 13.774293
 >> iter 17000, loss: 13.630436
 >> iter 18000, loss: 13.290127
 >> iter 19000, loss: 13.730188
 >> iter 20000, loss: 13.439601
   Number of active neurons: 2
 >> iter 21000, loss: 13.548350
 >> iter 22000, loss: 13.312344
 >> iter 23000, loss: 13.739868
 >> iter 24000, loss: 13.503918
 >> iter 25000, loss: 13.415830
 >> iter 26000, loss: 13.323037
 >> iter 27000, loss: 13.473928
 >> iter 28000, loss: 13.041532
 >> iter 29000, loss: 12.435860
 >> iter 30000, loss: 11.685006
   Number of active neurons: 2
 >> iter 31000, loss: 11.557215
 >> iter 32000, loss: 11.175782
 >> iter 33000, loss: 10.828416
 >> iter 34000, loss: 10.643505
 >> iter 35000, loss: 10.508562
 >> iter 36000, loss: 10.489264
 >> iter 37000, loss: 10.433872
 >> iter 38000, loss: 10.425032
 >> iter 39000, loss: 10.447125
 >> iter 40000, loss: 10.412293
   Number of active neurons: 2
 >> iter 41000, loss: 10.389254
 >> iter 42000, loss: 10.405621
 >> iter 43000, loss: 10.343710
 >> iter 44000, loss: 10.347455
 >> iter 45000, loss: 10.347464
 >> iter 46000, loss: 10.330571
 >> iter 47000, loss: 10.321727
 >> iter 48000, loss: 10.343272
 >> iter 49000, loss: 10.280644
 >> iter 50000, loss: 10.311455
   Number of active neurons: 2
 >> iter 51000, loss: 10.317021
 >> iter 52000, loss: 10.315809
 >> iter 53000, loss: 10.300411
 >> iter 54000, loss: 10.328736
 >> iter 55000, loss: 10.312228
 >> iter 56000, loss: 10.324692
 >> iter 57000, loss: 10.285057
 >> iter 58000, loss: 10.295870
 >> iter 59000, loss: 10.276255
 >> iter 60000, loss: 10.302300
   Number of active neurons: 2
 >> iter 61000, loss: 10.295971
 >> iter 62000, loss: 10.321766
 >> iter 63000, loss: 10.291680
 >> iter 64000, loss: 10.324757
 >> iter 65000, loss: 10.284211
 >> iter 66000, loss: 10.317945
 >> iter 67000, loss: 10.313554
 >> iter 68000, loss: 10.304386
 >> iter 69000, loss: 10.258231
 >> iter 70000, loss: 10.298605
   Number of active neurons: 2
 >> iter 71000, loss: 10.312585
 >> iter 72000, loss: 10.281047
 >> iter 73000, loss: 10.313474
 >> iter 74000, loss: 10.303106
 >> iter 75000, loss: 10.303855
 >> iter 76000, loss: 10.305942
 >> iter 77000, loss: 10.295396
 >> iter 78000, loss: 10.281799
 >> iter 79000, loss: 10.297827
 >> iter 80000, loss: 10.269007
   Number of active neurons: 2
 >> iter 81000, loss: 10.274819
 >> iter 82000, loss: 10.281353
 >> iter 83000, loss: 10.314478
 >> iter 84000, loss: 10.295189
 >> iter 85000, loss: 10.312353
 >> iter 86000, loss: 10.277860
 >> iter 87000, loss: 10.319197
 >> iter 88000, loss: 10.284381
 >> iter 89000, loss: 10.325903
 >> iter 90000, loss: 10.296286
   Number of active neurons: 2
 >> iter 91000, loss: 10.290251
 >> iter 92000, loss: 10.272865
 >> iter 93000, loss: 10.284186
 >> iter 94000, loss: 10.266008
 >> iter 95000, loss: 10.314868
 >> iter 96000, loss: 10.294022
 >> iter 97000, loss: 10.307313
 >> iter 98000, loss: 10.262074
 >> iter 99000, loss: 10.281918
 >> iter 100000, loss: 10.266338
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 17.8476430471
   - Test - Long: 3.68481575921
   - Test - Big: 18.0358196418
   - Test - A: 17.1988534098
   - Test - B: 15.6122925138
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.576278
 >> iter 2000, loss: 15.646048
 >> iter 3000, loss: 14.422472
 >> iter 4000, loss: 13.579828
 >> iter 5000, loss: 13.404672
 >> iter 6000, loss: 13.594622
 >> iter 7000, loss: 13.685933
 >> iter 8000, loss: 13.640158
 >> iter 9000, loss: 13.705731
 >> iter 10000, loss: 13.427083
   Number of active neurons: 2
 >> iter 11000, loss: 13.765779
 >> iter 12000, loss: 13.562651
 >> iter 13000, loss: 13.617778
 >> iter 14000, loss: 13.477996
 >> iter 15000, loss: 13.618935
 >> iter 16000, loss: 13.523908
 >> iter 17000, loss: 13.496278
 >> iter 18000, loss: 13.334222
 >> iter 19000, loss: 13.643593
 >> iter 20000, loss: 13.361472
   Number of active neurons: 2
 >> iter 21000, loss: 13.517234
 >> iter 22000, loss: 13.212328
 >> iter 23000, loss: 13.192040
 >> iter 24000, loss: 12.260590
 >> iter 25000, loss: 11.718462
 >> iter 26000, loss: 11.174355
 >> iter 27000, loss: 10.772412
 >> iter 28000, loss: 10.574759
 >> iter 29000, loss: 10.488834
 >> iter 30000, loss: 10.413719
   Number of active neurons: 2
 >> iter 31000, loss: 10.413482
 >> iter 32000, loss: 10.395677
 >> iter 33000, loss: 10.335695
 >> iter 34000, loss: 10.360454
 >> iter 35000, loss: 10.353158
 >> iter 36000, loss: 10.372952
 >> iter 37000, loss: 10.356673
 >> iter 38000, loss: 10.335672
 >> iter 39000, loss: 10.301276
 >> iter 40000, loss: 10.322521
   Number of active neurons: 2
 >> iter 41000, loss: 10.298141
 >> iter 42000, loss: 10.325744
 >> iter 43000, loss: 10.284184
 >> iter 44000, loss: 10.332854
 >> iter 45000, loss: 10.326831
 >> iter 46000, loss: 10.352153
 >> iter 47000, loss: 10.338567
 >> iter 48000, loss: 10.349357
 >> iter 49000, loss: 10.326409
 >> iter 50000, loss: 10.364835
   Number of active neurons: 2
 >> iter 51000, loss: 10.311661
 >> iter 52000, loss: 10.325666
 >> iter 53000, loss: 10.302813
 >> iter 54000, loss: 10.326205
 >> iter 55000, loss: 10.268538
 >> iter 56000, loss: 10.296966
 >> iter 57000, loss: 10.291868
 >> iter 58000, loss: 10.304878
 >> iter 59000, loss: 10.249380
 >> iter 60000, loss: 10.304262
   Number of active neurons: 2
 >> iter 61000, loss: 10.273700
 >> iter 62000, loss: 10.308130
 >> iter 63000, loss: 10.255014
 >> iter 64000, loss: 10.297949
 >> iter 65000, loss: 10.287844
 >> iter 66000, loss: 10.310160
 >> iter 67000, loss: 10.296025
 >> iter 68000, loss: 10.333789
 >> iter 69000, loss: 10.283228
 >> iter 70000, loss: 10.304266
   Number of active neurons: 2
 >> iter 71000, loss: 10.296762
 >> iter 72000, loss: 10.288498
 >> iter 73000, loss: 10.299151
 >> iter 74000, loss: 10.286569
 >> iter 75000, loss: 10.304921
 >> iter 76000, loss: 10.288742
 >> iter 77000, loss: 10.304355
 >> iter 78000, loss: 10.292281
 >> iter 79000, loss: 10.277783
 >> iter 80000, loss: 10.264235
   Number of active neurons: 2
 >> iter 81000, loss: 10.290232
 >> iter 82000, loss: 10.327079
 >> iter 83000, loss: 10.344243
 >> iter 84000, loss: 10.296488
 >> iter 85000, loss: 10.292181
 >> iter 86000, loss: 10.261692
 >> iter 87000, loss: 10.320737
 >> iter 88000, loss: 10.271974
 >> iter 89000, loss: 10.310190
 >> iter 90000, loss: 10.285482
   Number of active neurons: 2
 >> iter 91000, loss: 10.289262
 >> iter 92000, loss: 10.300740
 >> iter 93000, loss: 10.306097
 >> iter 94000, loss: 10.301279
 >> iter 95000, loss: 10.327237
 >> iter 96000, loss: 10.278588
 >> iter 97000, loss: 10.311623
 >> iter 98000, loss: 10.274225
 >> iter 99000, loss: 10.324010
 >> iter 100000, loss: 10.274775
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 17.8476430471
   - Test - Long: 3.68481575921
   - Test - Big: 18.0358196418
   - Test - A: 17.1988534098
   - Test - B: 15.6122925138
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.768809
 >> iter 2000, loss: 16.360957
 >> iter 3000, loss: 15.298087
 >> iter 4000, loss: 14.962201
 >> iter 5000, loss: 14.776795
 >> iter 6000, loss: 14.148672
 >> iter 7000, loss: 13.886011
 >> iter 8000, loss: 14.123882
 >> iter 9000, loss: 13.957288
 >> iter 10000, loss: 13.962427
   Number of active neurons: 2
 >> iter 11000, loss: 14.305276
 >> iter 12000, loss: 12.983541
 >> iter 13000, loss: 12.445836
 >> iter 14000, loss: 12.459199
 >> iter 15000, loss: 12.268456
 >> iter 16000, loss: 12.037931
 >> iter 17000, loss: 12.142124
 >> iter 18000, loss: 12.210379
 >> iter 19000, loss: 12.144165
 >> iter 20000, loss: 12.028417
   Number of active neurons: 2
 >> iter 21000, loss: 11.874328
 >> iter 22000, loss: 10.864521
 >> iter 23000, loss: 10.347118
 >> iter 24000, loss: 9.989519
 >> iter 25000, loss: 10.002491
 >> iter 26000, loss: 9.850071
 >> iter 27000, loss: 9.942170
 >> iter 28000, loss: 9.814559
 >> iter 29000, loss: 9.924122
 >> iter 30000, loss: 9.800420
   Number of active neurons: 2
 >> iter 31000, loss: 9.918744
 >> iter 32000, loss: 9.817271
 >> iter 33000, loss: 9.916789
 >> iter 34000, loss: 9.810567
 >> iter 35000, loss: 9.931783
 >> iter 36000, loss: 9.806882
 >> iter 37000, loss: 9.922026
 >> iter 38000, loss: 9.812880
 >> iter 39000, loss: 9.918090
 >> iter 40000, loss: 9.813849
   Number of active neurons: 2
 >> iter 41000, loss: 9.922198
 >> iter 42000, loss: 9.816807
 >> iter 43000, loss: 9.928170
 >> iter 44000, loss: 9.815482
 >> iter 45000, loss: 9.918703
 >> iter 46000, loss: 9.811063
 >> iter 47000, loss: 9.920939
 >> iter 48000, loss: 9.810160
 >> iter 49000, loss: 9.998693
 >> iter 50000, loss: 9.564642
   Number of active neurons: 2
 >> iter 51000, loss: 9.581384
 >> iter 52000, loss: 9.247437
 >> iter 53000, loss: 9.350690
 >> iter 54000, loss: 9.208637
 >> iter 55000, loss: 9.247771
 >> iter 56000, loss: 9.127415
 >> iter 57000, loss: 9.294663
 >> iter 58000, loss: 9.165075
 >> iter 59000, loss: 9.359372
 >> iter 60000, loss: 9.156672
   Number of active neurons: 2
 >> iter 61000, loss: 9.336931
 >> iter 62000, loss: 9.185612
 >> iter 63000, loss: 9.302525
 >> iter 64000, loss: 9.176778
 >> iter 65000, loss: 9.247398
 >> iter 66000, loss: 8.976296
 >> iter 67000, loss: 9.277546
 >> iter 68000, loss: 9.093471
 >> iter 69000, loss: 9.330814
 >> iter 70000, loss: 9.119274
   Number of active neurons: 2
 >> iter 71000, loss: 9.380561
 >> iter 72000, loss: 9.098990
 >> iter 73000, loss: 9.233762
 >> iter 74000, loss: 9.042721
 >> iter 75000, loss: 9.265367
 >> iter 76000, loss: 9.130276
 >> iter 77000, loss: 9.338155
 >> iter 78000, loss: 9.120842
 >> iter 79000, loss: 9.373095
 >> iter 80000, loss: 9.008102
   Number of active neurons: 2
 >> iter 81000, loss: 9.307894
 >> iter 82000, loss: 9.141963
 >> iter 83000, loss: 9.237096
 >> iter 84000, loss: 9.183358
 >> iter 85000, loss: 9.269435
 >> iter 86000, loss: 9.071187
 >> iter 87000, loss: 9.300386
 >> iter 88000, loss: 8.948390
 >> iter 89000, loss: 9.291434
 >> iter 90000, loss: 9.066360
   Number of active neurons: 2
 >> iter 91000, loss: 9.282466
 >> iter 92000, loss: 9.008602
 >> iter 93000, loss: 9.251692
 >> iter 94000, loss: 9.126098
 >> iter 95000, loss: 9.235574
 >> iter 96000, loss: 8.981496
 >> iter 97000, loss: 9.147514
 >> iter 98000, loss: 8.928426
 >> iter 99000, loss: 9.217882
 >> iter 100000, loss: 9.071110
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 12.6617467651
   - Test - Long: 2.81985900705
   - Test - Big: 12.2788772112
   - Test - A: 17.0521965202
   - Test - B: 26.5315645624

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

