 > Problema: tomita1nueva
 > Args:
   - Hidden size: 12
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.938763
 >> iter 2000, loss: 4.091507
 >> iter 3000, loss: 1.552677
 >> iter 4000, loss: 0.592997
 >> iter 5000, loss: 0.248608
 >> iter 6000, loss: 0.112388
 >> iter 7000, loss: 0.085799
 >> iter 8000, loss: 0.049951
 >> iter 9000, loss: 0.038775
 >> iter 10000, loss: 0.035943
   Number of active neurons: 4
 >> iter 11000, loss: 0.035134
 >> iter 12000, loss: 0.032311
 >> iter 13000, loss: 0.028781
 >> iter 14000, loss: 0.028961
 >> iter 15000, loss: 0.027628
 >> iter 16000, loss: 0.032663
 >> iter 17000, loss: 0.028522
 >> iter 18000, loss: 0.040539
 >> iter 19000, loss: 0.032523
 >> iter 20000, loss: 0.028967
   Number of active neurons: 2
 >> iter 21000, loss: 0.027658
 >> iter 22000, loss: 0.022844
 >> iter 23000, loss: 0.023937
 >> iter 24000, loss: 0.027996
 >> iter 25000, loss: 0.034183
 >> iter 26000, loss: 0.033184
 >> iter 27000, loss: 0.025168
 >> iter 28000, loss: 0.030713
 >> iter 29000, loss: 0.025348
 >> iter 30000, loss: 0.028128
   Number of active neurons: 2
 >> iter 31000, loss: 0.022713
 >> iter 32000, loss: 0.021397
 >> iter 33000, loss: 0.023414
 >> iter 34000, loss: 0.019984
 >> iter 35000, loss: 0.039984
 >> iter 36000, loss: 0.030526
 >> iter 37000, loss: 0.030414
 >> iter 38000, loss: 0.024621
 >> iter 39000, loss: 0.023341
 >> iter 40000, loss: 0.024681
   Number of active neurons: 2
 >> iter 41000, loss: 0.021354
 >> iter 42000, loss: 0.020661
 >> iter 43000, loss: 0.021126
 >> iter 44000, loss: 0.021883
 >> iter 45000, loss: 0.020478
 >> iter 46000, loss: 0.022428
 >> iter 47000, loss: 0.028048
 >> iter 48000, loss: 0.036621
 >> iter 49000, loss: 0.031299
 >> iter 50000, loss: 0.024041
   Number of active neurons: 2
 >> iter 51000, loss: 0.021144
 >> iter 52000, loss: 0.029292
 >> iter 53000, loss: 0.025621
 >> iter 54000, loss: 0.022187
 >> iter 55000, loss: 0.023211
 >> iter 56000, loss: 0.065870
 >> iter 57000, loss: 0.046110
 >> iter 58000, loss: 0.030652
 >> iter 59000, loss: 0.026466
 >> iter 60000, loss: 0.026611
   Number of active neurons: 1
 >> iter 61000, loss: 0.027093
 >> iter 62000, loss: 0.023737
 >> iter 63000, loss: 0.021403
 >> iter 64000, loss: 0.025747
 >> iter 65000, loss: 0.019490
 >> iter 66000, loss: 0.019639
 >> iter 67000, loss: 0.017626
 >> iter 68000, loss: 0.033435
 >> iter 69000, loss: 0.024361
 >> iter 70000, loss: 0.032625
   Number of active neurons: 1
 >> iter 71000, loss: 0.023972
 >> iter 72000, loss: 0.020319
 >> iter 73000, loss: 0.019576
 >> iter 74000, loss: 0.016645
 >> iter 75000, loss: 0.018771
 >> iter 76000, loss: 0.018211
 >> iter 77000, loss: 0.028993
 >> iter 78000, loss: 0.028572
 >> iter 79000, loss: 0.021217
 >> iter 80000, loss: 0.017942
   Number of active neurons: 1
 >> iter 81000, loss: 0.020078
 >> iter 82000, loss: 0.017817
 >> iter 83000, loss: 0.016546
 >> iter 84000, loss: 0.018519
 >> iter 85000, loss: 0.025778
 >> iter 86000, loss: 0.022184
 >> iter 87000, loss: 0.017719
 >> iter 88000, loss: 0.017472
 >> iter 89000, loss: 0.015920
 >> iter 90000, loss: 0.022797
   Number of active neurons: 1
 >> iter 91000, loss: 0.035957
 >> iter 92000, loss: 0.025100
 >> iter 93000, loss: 0.020932
 >> iter 94000, loss: 0.019129
 >> iter 95000, loss: 0.028262
 >> iter 96000, loss: 0.023279
 >> iter 97000, loss: 0.042951
 >> iter 98000, loss: 0.028011
 >> iter 99000, loss: 0.023501
 >> iter 100000, loss: 0.020525
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.876498
 >> iter 2000, loss: 4.036331
 >> iter 3000, loss: 1.510240
 >> iter 4000, loss: 0.594666
 >> iter 5000, loss: 0.243906
 >> iter 6000, loss: 0.108974
 >> iter 7000, loss: 0.059862
 >> iter 8000, loss: 0.038886
 >> iter 9000, loss: 0.032029
 >> iter 10000, loss: 0.029482
   Number of active neurons: 3
 >> iter 11000, loss: 0.029664
 >> iter 12000, loss: 0.025229
 >> iter 13000, loss: 0.026889
 >> iter 14000, loss: 0.026484
 >> iter 15000, loss: 0.033276
 >> iter 16000, loss: 0.027657
 >> iter 17000, loss: 0.040231
 >> iter 18000, loss: 0.036663
 >> iter 19000, loss: 0.033349
 >> iter 20000, loss: 0.028184
   Number of active neurons: 3
 >> iter 21000, loss: 0.027829
 >> iter 22000, loss: 0.030505
 >> iter 23000, loss: 0.039333
 >> iter 24000, loss: 0.035119
 >> iter 25000, loss: 0.032618
 >> iter 26000, loss: 0.032533
 >> iter 27000, loss: 0.029072
 >> iter 28000, loss: 0.032466
 >> iter 29000, loss: 0.034956
 >> iter 30000, loss: 0.027901
   Number of active neurons: 3
 >> iter 31000, loss: 0.032729
 >> iter 32000, loss: 0.027196
 >> iter 33000, loss: 0.038241
 >> iter 34000, loss: 0.029260
 >> iter 35000, loss: 0.026514
 >> iter 36000, loss: 0.023743
 >> iter 37000, loss: 0.030367
 >> iter 38000, loss: 0.026343
 >> iter 39000, loss: 0.024423
 >> iter 40000, loss: 0.053373
   Number of active neurons: 1
 >> iter 41000, loss: 0.033771
 >> iter 42000, loss: 0.026236
 >> iter 43000, loss: 0.022929
 >> iter 44000, loss: 0.020969
 >> iter 45000, loss: 0.018433
 >> iter 46000, loss: 0.022673
 >> iter 47000, loss: 0.024660
 >> iter 48000, loss: 0.020570
 >> iter 49000, loss: 0.025957
 >> iter 50000, loss: 0.022132
   Number of active neurons: 1
 >> iter 51000, loss: 0.020776
 >> iter 52000, loss: 0.018783
 >> iter 53000, loss: 0.021243
 >> iter 54000, loss: 0.027778
 >> iter 55000, loss: 0.024502
 >> iter 56000, loss: 0.022456
 >> iter 57000, loss: 0.024397
 >> iter 58000, loss: 0.020548
 >> iter 59000, loss: 0.022296
 >> iter 60000, loss: 0.027273
   Number of active neurons: 1
 >> iter 61000, loss: 0.021796
 >> iter 62000, loss: 0.021540
 >> iter 63000, loss: 0.020761
 >> iter 64000, loss: 0.017954
 >> iter 65000, loss: 0.021343
 >> iter 66000, loss: 0.028231
 >> iter 67000, loss: 0.021091
 >> iter 68000, loss: 0.017888
 >> iter 69000, loss: 0.021936
 >> iter 70000, loss: 0.017645
   Number of active neurons: 1
 >> iter 71000, loss: 0.020097
 >> iter 72000, loss: 0.019537
 >> iter 73000, loss: 0.023916
 >> iter 74000, loss: 0.030642
 >> iter 75000, loss: 0.029304
 >> iter 76000, loss: 0.024058
 >> iter 77000, loss: 0.021916
 >> iter 78000, loss: 0.019277
 >> iter 79000, loss: 0.017814
 >> iter 80000, loss: 0.025303
   Number of active neurons: 1
 >> iter 81000, loss: 0.019083
 >> iter 82000, loss: 0.023357
 >> iter 83000, loss: 0.032836
 >> iter 84000, loss: 0.026760
 >> iter 85000, loss: 0.025228
 >> iter 86000, loss: 0.019733
 >> iter 87000, loss: 0.018026
 >> iter 88000, loss: 0.015629
 >> iter 89000, loss: 0.021772
 >> iter 90000, loss: 0.017086
   Number of active neurons: 1
 >> iter 91000, loss: 0.017120
 >> iter 92000, loss: 0.018311
 >> iter 93000, loss: 0.017861
 >> iter 94000, loss: 0.017904
 >> iter 95000, loss: 0.019543
 >> iter 96000, loss: 0.017739
 >> iter 97000, loss: 0.019311
 >> iter 98000, loss: 0.031627
 >> iter 99000, loss: 0.023126
 >> iter 100000, loss: 0.023095
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.998244
 >> iter 2000, loss: 4.099050
 >> iter 3000, loss: 1.540192
 >> iter 4000, loss: 0.592288
 >> iter 5000, loss: 0.250691
 >> iter 6000, loss: 0.119194
 >> iter 7000, loss: 0.070650
 >> iter 8000, loss: 0.045170
 >> iter 9000, loss: 0.038089
 >> iter 10000, loss: 0.046346
   Number of active neurons: 5
 >> iter 11000, loss: 0.040402
 >> iter 12000, loss: 0.032087
 >> iter 13000, loss: 0.029402
 >> iter 14000, loss: 0.033486
 >> iter 15000, loss: 0.031967
 >> iter 16000, loss: 0.032700
 >> iter 17000, loss: 0.034971
 >> iter 18000, loss: 0.034277
 >> iter 19000, loss: 0.029637
 >> iter 20000, loss: 0.026354
   Number of active neurons: 4
 >> iter 21000, loss: 0.028339
 >> iter 22000, loss: 0.027180
 >> iter 23000, loss: 0.048672
 >> iter 24000, loss: 0.035310
 >> iter 25000, loss: 0.042808
 >> iter 26000, loss: 0.033716
 >> iter 27000, loss: 0.032166
 >> iter 28000, loss: 0.026318
 >> iter 29000, loss: 0.026253
 >> iter 30000, loss: 0.024592
   Number of active neurons: 3
 >> iter 31000, loss: 0.023075
 >> iter 32000, loss: 0.024456
 >> iter 33000, loss: 0.025668
 >> iter 34000, loss: 0.045151
 >> iter 35000, loss: 0.031792
 >> iter 36000, loss: 0.043156
 >> iter 37000, loss: 0.030868
 >> iter 38000, loss: 0.026193
 >> iter 39000, loss: 0.025237
 >> iter 40000, loss: 0.023819
   Number of active neurons: 3
 >> iter 41000, loss: 0.026049
 >> iter 42000, loss: 0.023714
 >> iter 43000, loss: 0.028185
 >> iter 44000, loss: 0.027863
 >> iter 45000, loss: 0.026191
 >> iter 46000, loss: 0.022691
 >> iter 47000, loss: 0.038853
 >> iter 48000, loss: 0.026665
 >> iter 49000, loss: 0.023971
 >> iter 50000, loss: 0.021751
   Number of active neurons: 2
 >> iter 51000, loss: 0.020375
 >> iter 52000, loss: 0.026985
 >> iter 53000, loss: 0.024670
 >> iter 54000, loss: 0.024906
 >> iter 55000, loss: 0.021397
 >> iter 56000, loss: 0.022587
 >> iter 57000, loss: 0.020632
 >> iter 58000, loss: 0.022009
 >> iter 59000, loss: 0.022300
 >> iter 60000, loss: 0.023852
   Number of active neurons: 2
 >> iter 61000, loss: 0.022638
 >> iter 62000, loss: 0.021073
 >> iter 63000, loss: 0.023186
 >> iter 64000, loss: 0.022158
 >> iter 65000, loss: 0.021747
 >> iter 66000, loss: 0.023373
 >> iter 67000, loss: 0.030393
 >> iter 68000, loss: 0.022929
 >> iter 69000, loss: 0.020677
 >> iter 70000, loss: 0.026361
   Number of active neurons: 2
 >> iter 71000, loss: 0.026200
 >> iter 72000, loss: 0.029060
 >> iter 73000, loss: 0.029615
 >> iter 74000, loss: 0.026428
 >> iter 75000, loss: 0.034297
 >> iter 76000, loss: 0.034558
 >> iter 77000, loss: 0.026987
 >> iter 78000, loss: 0.021131
 >> iter 79000, loss: 0.033084
 >> iter 80000, loss: 0.023255
   Number of active neurons: 1
 >> iter 81000, loss: 0.021892
 >> iter 82000, loss: 0.033957
 >> iter 83000, loss: 0.026518
 >> iter 84000, loss: 0.021322
 >> iter 85000, loss: 0.022674
 >> iter 86000, loss: 0.030726
 >> iter 87000, loss: 0.021240
 >> iter 88000, loss: 0.020079
 >> iter 89000, loss: 0.029286
 >> iter 90000, loss: 0.021978
   Number of active neurons: 1
 >> iter 91000, loss: 0.020966
 >> iter 92000, loss: 0.023018
 >> iter 93000, loss: 0.028256
 >> iter 94000, loss: 0.020015
 >> iter 95000, loss: 0.027272
 >> iter 96000, loss: 0.027068
 >> iter 97000, loss: 0.032682
 >> iter 98000, loss: 0.025058
 >> iter 99000, loss: 0.036438
 >> iter 100000, loss: 0.025464
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.869053
 >> iter 2000, loss: 4.043209
 >> iter 3000, loss: 1.513144
 >> iter 4000, loss: 0.577555
 >> iter 5000, loss: 0.233017
 >> iter 6000, loss: 0.104866
 >> iter 7000, loss: 0.071490
 >> iter 8000, loss: 0.042411
 >> iter 9000, loss: 0.034490
 >> iter 10000, loss: 0.028718
   Number of active neurons: 4
 >> iter 11000, loss: 0.027428
 >> iter 12000, loss: 0.030043
 >> iter 13000, loss: 0.031696
 >> iter 14000, loss: 0.032495
 >> iter 15000, loss: 0.027041
 >> iter 16000, loss: 0.025025
 >> iter 17000, loss: 0.027656
 >> iter 18000, loss: 0.038270
 >> iter 19000, loss: 0.031379
 >> iter 20000, loss: 0.029524
   Number of active neurons: 3
 >> iter 21000, loss: 0.029498
 >> iter 22000, loss: 0.031607
 >> iter 23000, loss: 0.033986
 >> iter 24000, loss: 0.027538
 >> iter 25000, loss: 0.025206
 >> iter 26000, loss: 0.025134
 >> iter 27000, loss: 0.022744
 >> iter 28000, loss: 0.021953
 >> iter 29000, loss: 0.027770
 >> iter 30000, loss: 0.026606
   Number of active neurons: 3
 >> iter 31000, loss: 0.024574
 >> iter 32000, loss: 0.025595
 >> iter 33000, loss: 0.038613
 >> iter 34000, loss: 0.034368
 >> iter 35000, loss: 0.033875
 >> iter 36000, loss: 0.035878
 >> iter 37000, loss: 0.034243
 >> iter 38000, loss: 0.026264
 >> iter 39000, loss: 0.023385
 >> iter 40000, loss: 0.034107
   Number of active neurons: 2
 >> iter 41000, loss: 0.033414
 >> iter 42000, loss: 0.033805
 >> iter 43000, loss: 0.025680
 >> iter 44000, loss: 0.025501
 >> iter 45000, loss: 0.036056
 >> iter 46000, loss: 0.033850
 >> iter 47000, loss: 0.027654
 >> iter 48000, loss: 0.022895
 >> iter 49000, loss: 0.024592
 >> iter 50000, loss: 0.024906
   Number of active neurons: 2
 >> iter 51000, loss: 0.021370
 >> iter 52000, loss: 0.020961
 >> iter 53000, loss: 0.044519
 >> iter 54000, loss: 0.031473
 >> iter 55000, loss: 0.028053
 >> iter 56000, loss: 0.026684
 >> iter 57000, loss: 0.031598
 >> iter 58000, loss: 0.055736
 >> iter 59000, loss: 0.032716
 >> iter 60000, loss: 0.023524
   Number of active neurons: 1
 >> iter 61000, loss: 0.020053
 >> iter 62000, loss: 0.025274
 >> iter 63000, loss: 0.023811
 >> iter 64000, loss: 0.021595
 >> iter 65000, loss: 0.033954
 >> iter 66000, loss: 0.022682
 >> iter 67000, loss: 0.019088
 >> iter 68000, loss: 0.017929
 >> iter 69000, loss: 0.025639
 >> iter 70000, loss: 0.021946
   Number of active neurons: 1
 >> iter 71000, loss: 0.023096
 >> iter 72000, loss: 0.020038
 >> iter 73000, loss: 0.020827
 >> iter 74000, loss: 0.018956
 >> iter 75000, loss: 0.022009
 >> iter 76000, loss: 0.020920
 >> iter 77000, loss: 0.022098
 >> iter 78000, loss: 0.021980
 >> iter 79000, loss: 0.018453
 >> iter 80000, loss: 0.025042
   Number of active neurons: 1
 >> iter 81000, loss: 0.019617
 >> iter 82000, loss: 0.023410
 >> iter 83000, loss: 0.024736
 >> iter 84000, loss: 0.018931
 >> iter 85000, loss: 0.027753
 >> iter 86000, loss: 0.021299
 >> iter 87000, loss: 0.019217
 >> iter 88000, loss: 0.018684
 >> iter 89000, loss: 0.021405
 >> iter 90000, loss: 0.021193
   Number of active neurons: 1
 >> iter 91000, loss: 0.017055
 >> iter 92000, loss: 0.018176
 >> iter 93000, loss: 0.018395
 >> iter 94000, loss: 0.018427
 >> iter 95000, loss: 0.023556
 >> iter 96000, loss: 0.017643
 >> iter 97000, loss: 0.022624
 >> iter 98000, loss: 0.021481
 >> iter 99000, loss: 0.038265
 >> iter 100000, loss: 0.024475
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.956080
 >> iter 2000, loss: 4.081373
 >> iter 3000, loss: 1.533026
 >> iter 4000, loss: 0.587284
 >> iter 5000, loss: 0.267126
 >> iter 6000, loss: 0.135408
 >> iter 7000, loss: 0.075347
 >> iter 8000, loss: 0.056705
 >> iter 9000, loss: 0.063592
 >> iter 10000, loss: 0.054122
   Number of active neurons: 4
 >> iter 11000, loss: 0.038765
 >> iter 12000, loss: 0.041205
 >> iter 13000, loss: 0.036850
 >> iter 14000, loss: 0.031800
 >> iter 15000, loss: 0.029263
 >> iter 16000, loss: 0.027218
 >> iter 17000, loss: 0.029090
 >> iter 18000, loss: 0.028145
 >> iter 19000, loss: 0.028671
 >> iter 20000, loss: 0.025277
   Number of active neurons: 2
 >> iter 21000, loss: 0.022715
 >> iter 22000, loss: 0.027000
 >> iter 23000, loss: 0.024413
 >> iter 24000, loss: 0.023237
 >> iter 25000, loss: 0.023630
 >> iter 26000, loss: 0.023033
 >> iter 27000, loss: 0.025453
 >> iter 28000, loss: 0.023330
 >> iter 29000, loss: 0.024412
 >> iter 30000, loss: 0.044234
   Number of active neurons: 1
 >> iter 31000, loss: 0.042672
 >> iter 32000, loss: 0.034362
 >> iter 33000, loss: 0.024401
 >> iter 34000, loss: 0.021591
 >> iter 35000, loss: 0.022136
 >> iter 36000, loss: 0.019614
 >> iter 37000, loss: 0.033290
 >> iter 38000, loss: 0.026111
 >> iter 39000, loss: 0.023193
 >> iter 40000, loss: 0.020321
   Number of active neurons: 1
 >> iter 41000, loss: 0.033874
 >> iter 42000, loss: 0.027996
 >> iter 43000, loss: 0.026021
 >> iter 44000, loss: 0.020199
 >> iter 45000, loss: 0.036066
 >> iter 46000, loss: 0.024552
 >> iter 47000, loss: 0.021085
 >> iter 48000, loss: 0.018774
 >> iter 49000, loss: 0.016614
 >> iter 50000, loss: 0.016607
   Number of active neurons: 1
 >> iter 51000, loss: 0.016941
 >> iter 52000, loss: 0.016718
 >> iter 53000, loss: 0.042086
 >> iter 54000, loss: 0.042475
 >> iter 55000, loss: 0.026435
 >> iter 56000, loss: 0.021234
 >> iter 57000, loss: 0.020909
 >> iter 58000, loss: 0.023029
 >> iter 59000, loss: 0.023358
 >> iter 60000, loss: 0.025366
   Number of active neurons: 1
 >> iter 61000, loss: 0.031640
 >> iter 62000, loss: 0.046118
 >> iter 63000, loss: 0.027550
 >> iter 64000, loss: 0.020885
 >> iter 65000, loss: 0.017646
 >> iter 66000, loss: 0.020464
 >> iter 67000, loss: 0.029280
 >> iter 68000, loss: 0.022140
 >> iter 69000, loss: 0.033005
 >> iter 70000, loss: 0.024691
   Number of active neurons: 1
 >> iter 71000, loss: 0.024565
 >> iter 72000, loss: 0.023551
 >> iter 73000, loss: 0.030275
 >> iter 74000, loss: 0.024340
 >> iter 75000, loss: 0.020418
 >> iter 76000, loss: 0.020021
 >> iter 77000, loss: 0.018848
 >> iter 78000, loss: 0.018169
 >> iter 79000, loss: 0.028349
 >> iter 80000, loss: 0.026224
   Number of active neurons: 1
 >> iter 81000, loss: 0.022732
 >> iter 82000, loss: 0.023850
 >> iter 83000, loss: 0.018514
 >> iter 84000, loss: 0.024220
 >> iter 85000, loss: 0.024767
 >> iter 86000, loss: 0.032824
 >> iter 87000, loss: 0.022234
 >> iter 88000, loss: 0.022024
 >> iter 89000, loss: 0.025542
 >> iter 90000, loss: 0.019005
   Number of active neurons: 1
 >> iter 91000, loss: 0.019460
 >> iter 92000, loss: 0.016110
 >> iter 93000, loss: 0.022064
 >> iter 94000, loss: 0.018609
 >> iter 95000, loss: 0.019137
 >> iter 96000, loss: 0.019120
 >> iter 97000, loss: 0.024239
 >> iter 98000, loss: 0.019945
 >> iter 99000, loss: 0.019208
 >> iter 100000, loss: 0.040808
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.934098
 >> iter 2000, loss: 4.051134
 >> iter 3000, loss: 1.519879
 >> iter 4000, loss: 0.585585
 >> iter 5000, loss: 0.234085
 >> iter 6000, loss: 0.116613
 >> iter 7000, loss: 0.060155
 >> iter 8000, loss: 0.044311
 >> iter 9000, loss: 0.032795
 >> iter 10000, loss: 0.029669
   Number of active neurons: 3
 >> iter 11000, loss: 0.028040
 >> iter 12000, loss: 0.025895
 >> iter 13000, loss: 0.023910
 >> iter 14000, loss: 0.024962
 >> iter 15000, loss: 0.028767
 >> iter 16000, loss: 0.023326
 >> iter 17000, loss: 0.023637
 >> iter 18000, loss: 0.024074
 >> iter 19000, loss: 0.027636
 >> iter 20000, loss: 0.025615
   Number of active neurons: 3
 >> iter 21000, loss: 0.025865
 >> iter 22000, loss: 0.026314
 >> iter 23000, loss: 0.026685
 >> iter 24000, loss: 0.036776
 >> iter 25000, loss: 0.031224
 >> iter 26000, loss: 0.024959
 >> iter 27000, loss: 0.024068
 >> iter 28000, loss: 0.023410
 >> iter 29000, loss: 0.025528
 >> iter 30000, loss: 0.024107
   Number of active neurons: 3
 >> iter 31000, loss: 0.023610
 >> iter 32000, loss: 0.028385
 >> iter 33000, loss: 0.030964
 >> iter 34000, loss: 0.034255
 >> iter 35000, loss: 0.030886
 >> iter 36000, loss: 0.025330
 >> iter 37000, loss: 0.023003
 >> iter 38000, loss: 0.034484
 >> iter 39000, loss: 0.028488
 >> iter 40000, loss: 0.028313
   Number of active neurons: 3
 >> iter 41000, loss: 0.026200
 >> iter 42000, loss: 0.025701
 >> iter 43000, loss: 0.023095
 >> iter 44000, loss: 0.023099
 >> iter 45000, loss: 0.025725
 >> iter 46000, loss: 0.023369
 >> iter 47000, loss: 0.023319
 >> iter 48000, loss: 0.025368
 >> iter 49000, loss: 0.036528
 >> iter 50000, loss: 0.028972
   Number of active neurons: 3
 >> iter 51000, loss: 0.027575
 >> iter 52000, loss: 0.022840
 >> iter 53000, loss: 0.025057
 >> iter 54000, loss: 0.028744
 >> iter 55000, loss: 0.025498
 >> iter 56000, loss: 0.027956
 >> iter 57000, loss: 0.027091
 >> iter 58000, loss: 0.025795
 >> iter 59000, loss: 0.024145
 >> iter 60000, loss: 0.031147
   Number of active neurons: 3
 >> iter 61000, loss: 0.024040
 >> iter 62000, loss: 0.031739
 >> iter 63000, loss: 0.027962
 >> iter 64000, loss: 0.023792
 >> iter 65000, loss: 0.024018
 >> iter 66000, loss: 0.023578
 >> iter 67000, loss: 0.023296
 >> iter 68000, loss: 0.023501
 >> iter 69000, loss: 0.034905
 >> iter 70000, loss: 0.027020
   Number of active neurons: 3
 >> iter 71000, loss: 0.030759
 >> iter 72000, loss: 0.027348
 >> iter 73000, loss: 0.027468
 >> iter 74000, loss: 0.023149
 >> iter 75000, loss: 0.026086
 >> iter 76000, loss: 0.023928
 >> iter 77000, loss: 0.028847
 >> iter 78000, loss: 0.026283
 >> iter 79000, loss: 0.047770
 >> iter 80000, loss: 0.033813
   Number of active neurons: 3
 >> iter 81000, loss: 0.029865
 >> iter 82000, loss: 0.024450
 >> iter 83000, loss: 0.023546
 >> iter 84000, loss: 0.031023
 >> iter 85000, loss: 0.026217
 >> iter 86000, loss: 0.023094
 >> iter 87000, loss: 0.023989
 >> iter 88000, loss: 0.020722
 >> iter 89000, loss: 0.020227
 >> iter 90000, loss: 0.032524
   Number of active neurons: 2
 >> iter 91000, loss: 0.030591
 >> iter 92000, loss: 0.023430
 >> iter 93000, loss: 0.023143
 >> iter 94000, loss: 0.022859
 >> iter 95000, loss: 0.020794
 >> iter 96000, loss: 0.021101
 >> iter 97000, loss: 0.030945
 >> iter 98000, loss: 0.025156
 >> iter 99000, loss: 0.022058
 >> iter 100000, loss: 0.022720
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.956051
 >> iter 2000, loss: 4.080260
 >> iter 3000, loss: 1.544167
 >> iter 4000, loss: 0.594611
 >> iter 5000, loss: 0.240870
 >> iter 6000, loss: 0.108400
 >> iter 7000, loss: 0.063247
 >> iter 8000, loss: 0.079545
 >> iter 9000, loss: 0.047908
 >> iter 10000, loss: 0.035449
   Number of active neurons: 4
 >> iter 11000, loss: 0.034622
 >> iter 12000, loss: 0.038731
 >> iter 13000, loss: 0.031253
 >> iter 14000, loss: 0.027536
 >> iter 15000, loss: 0.026814
 >> iter 16000, loss: 0.028535
 >> iter 17000, loss: 0.025997
 >> iter 18000, loss: 0.054091
 >> iter 19000, loss: 0.034948
 >> iter 20000, loss: 0.028671
   Number of active neurons: 3
 >> iter 21000, loss: 0.024891
 >> iter 22000, loss: 0.027659
 >> iter 23000, loss: 0.030177
 >> iter 24000, loss: 0.034240
 >> iter 25000, loss: 0.030646
 >> iter 26000, loss: 0.025483
 >> iter 27000, loss: 0.023394
 >> iter 28000, loss: 0.024518
 >> iter 29000, loss: 0.027870
 >> iter 30000, loss: 0.025442
   Number of active neurons: 3
 >> iter 31000, loss: 0.026068
 >> iter 32000, loss: 0.022243
 >> iter 33000, loss: 0.023308
 >> iter 34000, loss: 0.022205
 >> iter 35000, loss: 0.030681
 >> iter 36000, loss: 0.030444
 >> iter 37000, loss: 0.026355
 >> iter 38000, loss: 0.023587
 >> iter 39000, loss: 0.022546
 >> iter 40000, loss: 0.022291
   Number of active neurons: 2
 >> iter 41000, loss: 0.070915
 >> iter 42000, loss: 0.042212
 >> iter 43000, loss: 0.029177
 >> iter 44000, loss: 0.030844
 >> iter 45000, loss: 0.028401
 >> iter 46000, loss: 0.025871
 >> iter 47000, loss: 0.021991
 >> iter 48000, loss: 0.019932
 >> iter 49000, loss: 0.020005
 >> iter 50000, loss: 0.021120
   Number of active neurons: 2
 >> iter 51000, loss: 0.026508
 >> iter 52000, loss: 0.042120
 >> iter 53000, loss: 0.028769
 >> iter 54000, loss: 0.023155
 >> iter 55000, loss: 0.021065
 >> iter 56000, loss: 0.024609
 >> iter 57000, loss: 0.022266
 >> iter 58000, loss: 0.021225
 >> iter 59000, loss: 0.020754
 >> iter 60000, loss: 0.020155
   Number of active neurons: 2
 >> iter 61000, loss: 0.026707
 >> iter 62000, loss: 0.022852
 >> iter 63000, loss: 0.024318
 >> iter 64000, loss: 0.022776
 >> iter 65000, loss: 0.036478
 >> iter 66000, loss: 0.032798
 >> iter 67000, loss: 0.027011
 >> iter 68000, loss: 0.022140
 >> iter 69000, loss: 0.023374
 >> iter 70000, loss: 0.020438
   Number of active neurons: 2
 >> iter 71000, loss: 0.032989
 >> iter 72000, loss: 0.029825
 >> iter 73000, loss: 0.027043
 >> iter 74000, loss: 0.021755
 >> iter 75000, loss: 0.021512
 >> iter 76000, loss: 0.022297
 >> iter 77000, loss: 0.022607
 >> iter 78000, loss: 0.023807
 >> iter 79000, loss: 0.023077
 >> iter 80000, loss: 0.025879
   Number of active neurons: 2
 >> iter 81000, loss: 0.030311
 >> iter 82000, loss: 0.025135
 >> iter 83000, loss: 0.021763
 >> iter 84000, loss: 0.021152
 >> iter 85000, loss: 0.020230
 >> iter 86000, loss: 0.023805
 >> iter 87000, loss: 0.025395
 >> iter 88000, loss: 0.025458
 >> iter 89000, loss: 0.030716
 >> iter 90000, loss: 0.027129
   Number of active neurons: 1
 >> iter 91000, loss: 0.044828
 >> iter 92000, loss: 0.027130
 >> iter 93000, loss: 0.021802
 >> iter 94000, loss: 0.034346
 >> iter 95000, loss: 0.024107
 >> iter 96000, loss: 0.033034
 >> iter 97000, loss: 0.038878
 >> iter 98000, loss: 0.027024
 >> iter 99000, loss: 0.022948
 >> iter 100000, loss: 0.019384
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.937113
 >> iter 2000, loss: 4.059087
 >> iter 3000, loss: 1.524857
 >> iter 4000, loss: 0.587539
 >> iter 5000, loss: 0.236051
 >> iter 6000, loss: 0.109934
 >> iter 7000, loss: 0.059070
 >> iter 8000, loss: 0.044733
 >> iter 9000, loss: 0.036109
 >> iter 10000, loss: 0.028468
   Number of active neurons: 4
 >> iter 11000, loss: 0.028650
 >> iter 12000, loss: 0.026786
 >> iter 13000, loss: 0.028742
 >> iter 14000, loss: 0.030330
 >> iter 15000, loss: 0.033088
 >> iter 16000, loss: 0.028494
 >> iter 17000, loss: 0.027540
 >> iter 18000, loss: 0.033773
 >> iter 19000, loss: 0.029153
 >> iter 20000, loss: 0.027586
   Number of active neurons: 4
 >> iter 21000, loss: 0.030628
 >> iter 22000, loss: 0.027804
 >> iter 23000, loss: 0.025280
 >> iter 24000, loss: 0.027243
 >> iter 25000, loss: 0.030213
 >> iter 26000, loss: 0.031678
 >> iter 27000, loss: 0.028298
 >> iter 28000, loss: 0.025195
 >> iter 29000, loss: 0.026911
 >> iter 30000, loss: 0.026818
   Number of active neurons: 4
 >> iter 31000, loss: 0.025567
 >> iter 32000, loss: 0.024931
 >> iter 33000, loss: 0.033755
 >> iter 34000, loss: 0.030479
 >> iter 35000, loss: 0.027925
 >> iter 36000, loss: 0.028417
 >> iter 37000, loss: 0.027971
 >> iter 38000, loss: 0.024309
 >> iter 39000, loss: 0.024610
 >> iter 40000, loss: 0.027856
   Number of active neurons: 4
 >> iter 41000, loss: 0.056500
 >> iter 42000, loss: 0.044141
 >> iter 43000, loss: 0.038667
 >> iter 44000, loss: 0.031160
 >> iter 45000, loss: 0.037761
 >> iter 46000, loss: 0.028954
 >> iter 47000, loss: 0.033002
 >> iter 48000, loss: 0.032127
 >> iter 49000, loss: 0.028393
 >> iter 50000, loss: 0.026345
   Number of active neurons: 4
 >> iter 51000, loss: 0.026078
 >> iter 52000, loss: 0.032065
 >> iter 53000, loss: 0.026082
 >> iter 54000, loss: 0.027424
 >> iter 55000, loss: 0.029859
 >> iter 56000, loss: 0.027212
 >> iter 57000, loss: 0.034118
 >> iter 58000, loss: 0.031988
 >> iter 59000, loss: 0.029720
 >> iter 60000, loss: 0.024653
   Number of active neurons: 2
 >> iter 61000, loss: 0.024517
 >> iter 62000, loss: 0.023175
 >> iter 63000, loss: 0.028432
 >> iter 64000, loss: 0.025876
 >> iter 65000, loss: 0.032537
 >> iter 66000, loss: 0.023711
 >> iter 67000, loss: 0.029508
 >> iter 68000, loss: 0.028669
 >> iter 69000, loss: 0.028848
 >> iter 70000, loss: 0.023835
   Number of active neurons: 2
 >> iter 71000, loss: 0.023789
 >> iter 72000, loss: 0.020004
 >> iter 73000, loss: 0.041516
 >> iter 74000, loss: 0.029069
 >> iter 75000, loss: 0.028199
 >> iter 76000, loss: 0.027357
 >> iter 77000, loss: 0.030208
 >> iter 78000, loss: 0.025022
 >> iter 79000, loss: 0.023997
 >> iter 80000, loss: 0.032643
   Number of active neurons: 2
 >> iter 81000, loss: 0.039850
 >> iter 82000, loss: 0.053640
 >> iter 83000, loss: 0.042542
 >> iter 84000, loss: 0.033373
 >> iter 85000, loss: 0.026707
 >> iter 86000, loss: 0.024621
 >> iter 87000, loss: 0.022615
 >> iter 88000, loss: 0.024280
 >> iter 89000, loss: 0.024277
 >> iter 90000, loss: 0.029937
   Number of active neurons: 2
 >> iter 91000, loss: 0.023958
 >> iter 92000, loss: 0.024525
 >> iter 93000, loss: 0.051482
 >> iter 94000, loss: 0.042261
 >> iter 95000, loss: 0.028326
 >> iter 96000, loss: 0.025136
 >> iter 97000, loss: 0.032357
 >> iter 98000, loss: 0.025134
 >> iter 99000, loss: 0.027292
 >> iter 100000, loss: 0.028388
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.941172
 >> iter 2000, loss: 4.073491
 >> iter 3000, loss: 1.536114
 >> iter 4000, loss: 0.581842
 >> iter 5000, loss: 0.237350
 >> iter 6000, loss: 0.127040
 >> iter 7000, loss: 0.066069
 >> iter 8000, loss: 0.045452
 >> iter 9000, loss: 0.047065
 >> iter 10000, loss: 0.039258
   Number of active neurons: 5
 >> iter 11000, loss: 0.040116
 >> iter 12000, loss: 0.035559
 >> iter 13000, loss: 0.030130
 >> iter 14000, loss: 0.030122
 >> iter 15000, loss: 0.035426
 >> iter 16000, loss: 0.034610
 >> iter 17000, loss: 0.036706
 >> iter 18000, loss: 0.029833
 >> iter 19000, loss: 0.035964
 >> iter 20000, loss: 0.031791
   Number of active neurons: 5
 >> iter 21000, loss: 0.048931
 >> iter 22000, loss: 0.037302
 >> iter 23000, loss: 0.030113
 >> iter 24000, loss: 0.029564
 >> iter 25000, loss: 0.031960
 >> iter 26000, loss: 0.032080
 >> iter 27000, loss: 0.032748
 >> iter 28000, loss: 0.036225
 >> iter 29000, loss: 0.031654
 >> iter 30000, loss: 0.028215
   Number of active neurons: 4
 >> iter 31000, loss: 0.027380
 >> iter 32000, loss: 0.029270
 >> iter 33000, loss: 0.031606
 >> iter 34000, loss: 0.043516
 >> iter 35000, loss: 0.032626
 >> iter 36000, loss: 0.030867
 >> iter 37000, loss: 0.026517
 >> iter 38000, loss: 0.025735
 >> iter 39000, loss: 0.045718
 >> iter 40000, loss: 0.034958
   Number of active neurons: 4
 >> iter 41000, loss: 0.033013
 >> iter 42000, loss: 0.027035
 >> iter 43000, loss: 0.025735
 >> iter 44000, loss: 0.039878
 >> iter 45000, loss: 0.032170
 >> iter 46000, loss: 0.026137
 >> iter 47000, loss: 0.030914
 >> iter 48000, loss: 0.027115
 >> iter 49000, loss: 0.023322
 >> iter 50000, loss: 0.021769
   Number of active neurons: 2
 >> iter 51000, loss: 0.020418
 >> iter 52000, loss: 0.020975
 >> iter 53000, loss: 0.024779
 >> iter 54000, loss: 0.030207
 >> iter 55000, loss: 0.038628
 >> iter 56000, loss: 0.025955
 >> iter 57000, loss: 0.031981
 >> iter 58000, loss: 0.034793
 >> iter 59000, loss: 0.028047
 >> iter 60000, loss: 0.024153
   Number of active neurons: 1
 >> iter 61000, loss: 0.020464
 >> iter 62000, loss: 0.020542
 >> iter 63000, loss: 0.020362
 >> iter 64000, loss: 0.018060
 >> iter 65000, loss: 0.021728
 >> iter 66000, loss: 0.051837
 >> iter 67000, loss: 0.030512
 >> iter 68000, loss: 0.024568
 >> iter 69000, loss: 0.021665
 >> iter 70000, loss: 0.018736
   Number of active neurons: 1
 >> iter 71000, loss: 0.017690
 >> iter 72000, loss: 0.021360
 >> iter 73000, loss: 0.019995
 >> iter 74000, loss: 0.017314
 >> iter 75000, loss: 0.023356
 >> iter 76000, loss: 0.025333
 >> iter 77000, loss: 0.022328
 >> iter 78000, loss: 0.018743
 >> iter 79000, loss: 0.045317
 >> iter 80000, loss: 0.027561
   Number of active neurons: 1
 >> iter 81000, loss: 0.022261
 >> iter 82000, loss: 0.018266
 >> iter 83000, loss: 0.017099
 >> iter 84000, loss: 0.028279
 >> iter 85000, loss: 0.022028
 >> iter 86000, loss: 0.026551
 >> iter 87000, loss: 0.028586
 >> iter 88000, loss: 0.028801
 >> iter 89000, loss: 0.022470
 >> iter 90000, loss: 0.022230
   Number of active neurons: 1
 >> iter 91000, loss: 0.023696
 >> iter 92000, loss: 0.023302
 >> iter 93000, loss: 0.022901
 >> iter 94000, loss: 0.025136
 >> iter 95000, loss: 0.030081
 >> iter 96000, loss: 0.032738
 >> iter 97000, loss: 0.022584
 >> iter 98000, loss: 0.017902
 >> iter 99000, loss: 0.019605
 >> iter 100000, loss: 0.017373
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.971258
 >> iter 2000, loss: 4.088974
 >> iter 3000, loss: 1.532374
 >> iter 4000, loss: 0.584043
 >> iter 5000, loss: 0.244989
 >> iter 6000, loss: 0.114065
 >> iter 7000, loss: 0.067693
 >> iter 8000, loss: 0.041556
 >> iter 9000, loss: 0.033427
 >> iter 10000, loss: 0.049461
   Number of active neurons: 2
 >> iter 11000, loss: 0.035515
 >> iter 12000, loss: 0.038177
 >> iter 13000, loss: 0.043581
 >> iter 14000, loss: 0.030690
 >> iter 15000, loss: 0.034394
 >> iter 16000, loss: 0.029079
 >> iter 17000, loss: 0.025030
 >> iter 18000, loss: 0.023856
 >> iter 19000, loss: 0.022587
 >> iter 20000, loss: 0.021328
   Number of active neurons: 2
 >> iter 21000, loss: 0.020408
 >> iter 22000, loss: 0.020298
 >> iter 23000, loss: 0.022209
 >> iter 24000, loss: 0.025837
 >> iter 25000, loss: 0.037240
 >> iter 26000, loss: 0.037952
 >> iter 27000, loss: 0.048656
 >> iter 28000, loss: 0.035240
 >> iter 29000, loss: 0.036531
 >> iter 30000, loss: 0.027203
   Number of active neurons: 2
 >> iter 31000, loss: 0.025202
 >> iter 32000, loss: 0.022022
 >> iter 33000, loss: 0.021514
 >> iter 34000, loss: 0.021366
 >> iter 35000, loss: 0.021793
 >> iter 36000, loss: 0.046266
 >> iter 37000, loss: 0.030592
 >> iter 38000, loss: 0.024180
 >> iter 39000, loss: 0.023565
 >> iter 40000, loss: 0.022202
   Number of active neurons: 2
 >> iter 41000, loss: 0.025047
 >> iter 42000, loss: 0.023276
 >> iter 43000, loss: 0.025817
 >> iter 44000, loss: 0.027422
 >> iter 45000, loss: 0.030363
 >> iter 46000, loss: 0.025264
 >> iter 47000, loss: 0.027439
 >> iter 48000, loss: 0.022937
 >> iter 49000, loss: 0.020248
 >> iter 50000, loss: 0.027696
   Number of active neurons: 1
 >> iter 51000, loss: 0.024516
 >> iter 52000, loss: 0.021671
 >> iter 53000, loss: 0.017915
 >> iter 54000, loss: 0.016657
 >> iter 55000, loss: 0.022194
 >> iter 56000, loss: 0.024531
 >> iter 57000, loss: 0.021756
 >> iter 58000, loss: 0.029841
 >> iter 59000, loss: 0.026900
 >> iter 60000, loss: 0.025849
   Number of active neurons: 1
 >> iter 61000, loss: 0.028086
 >> iter 62000, loss: 0.022111
 >> iter 63000, loss: 0.025856
 >> iter 64000, loss: 0.021503
 >> iter 65000, loss: 0.021456
 >> iter 66000, loss: 0.019827
 >> iter 67000, loss: 0.019905
 >> iter 68000, loss: 0.024378
 >> iter 69000, loss: 0.029524
 >> iter 70000, loss: 0.022584
   Number of active neurons: 1
 >> iter 71000, loss: 0.022415
 >> iter 72000, loss: 0.017482
 >> iter 73000, loss: 0.022300
 >> iter 74000, loss: 0.021378
 >> iter 75000, loss: 0.019863
 >> iter 76000, loss: 0.017548
 >> iter 77000, loss: 0.027552
 >> iter 78000, loss: 0.026362
 >> iter 79000, loss: 0.022312
 >> iter 80000, loss: 0.019233
   Number of active neurons: 1
 >> iter 81000, loss: 0.025296
 >> iter 82000, loss: 0.018963
 >> iter 83000, loss: 0.019014
 >> iter 84000, loss: 0.019911
 >> iter 85000, loss: 0.021577
 >> iter 86000, loss: 0.017780
 >> iter 87000, loss: 0.017963
 >> iter 88000, loss: 0.015400
 >> iter 89000, loss: 0.029549
 >> iter 90000, loss: 0.021713
   Number of active neurons: 1
 >> iter 91000, loss: 0.021514
 >> iter 92000, loss: 0.027937
 >> iter 93000, loss: 0.024555
 >> iter 94000, loss: 0.019203
 >> iter 95000, loss: 0.018072
 >> iter 96000, loss: 0.016907
 >> iter 97000, loss: 0.018977
 >> iter 98000, loss: 0.017397
 >> iter 99000, loss: 0.019295
 >> iter 100000, loss: 0.016084
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.897916
 >> iter 2000, loss: 4.067670
 >> iter 3000, loss: 1.524763
 >> iter 4000, loss: 0.581339
 >> iter 5000, loss: 0.236243
 >> iter 6000, loss: 0.109331
 >> iter 7000, loss: 0.062603
 >> iter 8000, loss: 0.041272
 >> iter 9000, loss: 0.035753
 >> iter 10000, loss: 0.032259
   Number of active neurons: 2
 >> iter 11000, loss: 0.035513
 >> iter 12000, loss: 0.044764
 >> iter 13000, loss: 0.034522
 >> iter 14000, loss: 0.032670
 >> iter 15000, loss: 0.029119
 >> iter 16000, loss: 0.024050
 >> iter 17000, loss: 0.024279
 >> iter 18000, loss: 0.031648
 >> iter 19000, loss: 0.029672
 >> iter 20000, loss: 0.031856
   Number of active neurons: 2
 >> iter 21000, loss: 0.027023
 >> iter 22000, loss: 0.028945
 >> iter 23000, loss: 0.025143
 >> iter 24000, loss: 0.022952
 >> iter 25000, loss: 0.020330
 >> iter 26000, loss: 0.021163
 >> iter 27000, loss: 0.023779
 >> iter 28000, loss: 0.023108
 >> iter 29000, loss: 0.020928
 >> iter 30000, loss: 0.049643
   Number of active neurons: 1
 >> iter 31000, loss: 0.030612
 >> iter 32000, loss: 0.028423
 >> iter 33000, loss: 0.023246
 >> iter 34000, loss: 0.020053
 >> iter 35000, loss: 0.035773
 >> iter 36000, loss: 0.028080
 >> iter 37000, loss: 0.021650
 >> iter 38000, loss: 0.028014
 >> iter 39000, loss: 0.023855
 >> iter 40000, loss: 0.022679
   Number of active neurons: 1
 >> iter 41000, loss: 0.041855
 >> iter 42000, loss: 0.026354
 >> iter 43000, loss: 0.022942
 >> iter 44000, loss: 0.024601
 >> iter 45000, loss: 0.052143
 >> iter 46000, loss: 0.034753
 >> iter 47000, loss: 0.022991
 >> iter 48000, loss: 0.018435
 >> iter 49000, loss: 0.028827
 >> iter 50000, loss: 0.027678
   Number of active neurons: 1
 >> iter 51000, loss: 0.028783
 >> iter 52000, loss: 0.022683
 >> iter 53000, loss: 0.024245
 >> iter 54000, loss: 0.022319
 >> iter 55000, loss: 0.019309
 >> iter 56000, loss: 0.026706
 >> iter 57000, loss: 0.025728
 >> iter 58000, loss: 0.019083
 >> iter 59000, loss: 0.018779
 >> iter 60000, loss: 0.018531
   Number of active neurons: 1
 >> iter 61000, loss: 0.039803
 >> iter 62000, loss: 0.026116
 >> iter 63000, loss: 0.027836
 >> iter 64000, loss: 0.026674
 >> iter 65000, loss: 0.021426
 >> iter 66000, loss: 0.017813
 >> iter 67000, loss: 0.044593
 >> iter 68000, loss: 0.026551
 >> iter 69000, loss: 0.022475
 >> iter 70000, loss: 0.021221
   Number of active neurons: 1
 >> iter 71000, loss: 0.018278
 >> iter 72000, loss: 0.017507
 >> iter 73000, loss: 0.024737
 >> iter 74000, loss: 0.018898
 >> iter 75000, loss: 0.021569
 >> iter 76000, loss: 0.018033
 >> iter 77000, loss: 0.022307
 >> iter 78000, loss: 0.030156
 >> iter 79000, loss: 0.023793
 >> iter 80000, loss: 0.018110
   Number of active neurons: 1
 >> iter 81000, loss: 0.017068
 >> iter 82000, loss: 0.016820
 >> iter 83000, loss: 0.031673
 >> iter 84000, loss: 0.024420
 >> iter 85000, loss: 0.026040
 >> iter 86000, loss: 0.022335
 >> iter 87000, loss: 0.023979
 >> iter 88000, loss: 0.020739
 >> iter 89000, loss: 0.017971
 >> iter 90000, loss: 0.028301
   Number of active neurons: 1
 >> iter 91000, loss: 0.020908
 >> iter 92000, loss: 0.021406
 >> iter 93000, loss: 0.023237
 >> iter 94000, loss: 0.023696
 >> iter 95000, loss: 0.019416
 >> iter 96000, loss: 0.019056
 >> iter 97000, loss: 0.020982
 >> iter 98000, loss: 0.017958
 >> iter 99000, loss: 0.022454
 >> iter 100000, loss: 0.019649
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.907273
 >> iter 2000, loss: 4.062704
 >> iter 3000, loss: 1.525020
 >> iter 4000, loss: 0.586002
 >> iter 5000, loss: 0.240830
 >> iter 6000, loss: 0.112388
 >> iter 7000, loss: 0.072777
 >> iter 8000, loss: 0.055714
 >> iter 9000, loss: 0.046513
 >> iter 10000, loss: 0.038226
   Number of active neurons: 5
 >> iter 11000, loss: 0.034677
 >> iter 12000, loss: 0.029194
 >> iter 13000, loss: 0.028504
 >> iter 14000, loss: 0.027217
 >> iter 15000, loss: 0.028441
 >> iter 16000, loss: 0.027898
 >> iter 17000, loss: 0.031383
 >> iter 18000, loss: 0.031375
 >> iter 19000, loss: 0.027497
 >> iter 20000, loss: 0.029179
   Number of active neurons: 4
 >> iter 21000, loss: 0.031188
 >> iter 22000, loss: 0.031516
 >> iter 23000, loss: 0.027765
 >> iter 24000, loss: 0.024137
 >> iter 25000, loss: 0.026641
 >> iter 26000, loss: 0.024957
 >> iter 27000, loss: 0.024328
 >> iter 28000, loss: 0.022806
 >> iter 29000, loss: 0.023837
 >> iter 30000, loss: 0.031957
   Number of active neurons: 3
 >> iter 31000, loss: 0.027955
 >> iter 32000, loss: 0.027666
 >> iter 33000, loss: 0.024830
 >> iter 34000, loss: 0.032407
 >> iter 35000, loss: 0.031062
 >> iter 36000, loss: 0.027514
 >> iter 37000, loss: 0.031863
 >> iter 38000, loss: 0.035440
 >> iter 39000, loss: 0.026713
 >> iter 40000, loss: 0.024205
   Number of active neurons: 3
 >> iter 41000, loss: 0.025541
 >> iter 42000, loss: 0.023615
 >> iter 43000, loss: 0.024874
 >> iter 44000, loss: 0.029541
 >> iter 45000, loss: 0.034164
 >> iter 46000, loss: 0.026904
 >> iter 47000, loss: 0.024551
 >> iter 48000, loss: 0.022933
 >> iter 49000, loss: 0.022764
 >> iter 50000, loss: 0.037746
   Number of active neurons: 3
 >> iter 51000, loss: 0.038356
 >> iter 52000, loss: 0.028342
 >> iter 53000, loss: 0.025824
 >> iter 54000, loss: 0.026073
 >> iter 55000, loss: 0.022442
 >> iter 56000, loss: 0.035381
 >> iter 57000, loss: 0.033943
 >> iter 58000, loss: 0.027016
 >> iter 59000, loss: 0.023621
 >> iter 60000, loss: 0.031924
   Number of active neurons: 2
 >> iter 61000, loss: 0.029039
 >> iter 62000, loss: 0.023986
 >> iter 63000, loss: 0.026740
 >> iter 64000, loss: 0.028247
 >> iter 65000, loss: 0.031255
 >> iter 66000, loss: 0.026187
 >> iter 67000, loss: 0.022750
 >> iter 68000, loss: 0.033056
 >> iter 69000, loss: 0.030795
 >> iter 70000, loss: 0.030064
   Number of active neurons: 2
 >> iter 71000, loss: 0.037489
 >> iter 72000, loss: 0.026604
 >> iter 73000, loss: 0.022969
 >> iter 74000, loss: 0.022931
 >> iter 75000, loss: 0.021215
 >> iter 76000, loss: 0.024202
 >> iter 77000, loss: 0.044436
 >> iter 78000, loss: 0.030104
 >> iter 79000, loss: 0.025372
 >> iter 80000, loss: 0.021883
   Number of active neurons: 2
 >> iter 81000, loss: 0.022602
 >> iter 82000, loss: 0.019898
 >> iter 83000, loss: 0.020803
 >> iter 84000, loss: 0.022895
 >> iter 85000, loss: 0.022517
 >> iter 86000, loss: 0.021206
 >> iter 87000, loss: 0.020551
 >> iter 88000, loss: 0.026223
 >> iter 89000, loss: 0.020412
 >> iter 90000, loss: 0.018294
   Number of active neurons: 1
 >> iter 91000, loss: 0.019552
 >> iter 92000, loss: 0.025433
 >> iter 93000, loss: 0.020520
 >> iter 94000, loss: 0.018999
 >> iter 95000, loss: 0.017016
 >> iter 96000, loss: 0.019662
 >> iter 97000, loss: 0.023292
 >> iter 98000, loss: 0.020589
 >> iter 99000, loss: 0.022114
 >> iter 100000, loss: 0.020995
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.957136
 >> iter 2000, loss: 4.084682
 >> iter 3000, loss: 1.533331
 >> iter 4000, loss: 0.583299
 >> iter 5000, loss: 0.234598
 >> iter 6000, loss: 0.112111
 >> iter 7000, loss: 0.058071
 >> iter 8000, loss: 0.041708
 >> iter 9000, loss: 0.033887
 >> iter 10000, loss: 0.029666
   Number of active neurons: 4
 >> iter 11000, loss: 0.027542
 >> iter 12000, loss: 0.030950
 >> iter 13000, loss: 0.026813
 >> iter 14000, loss: 0.028815
 >> iter 15000, loss: 0.037253
 >> iter 16000, loss: 0.031549
 >> iter 17000, loss: 0.031064
 >> iter 18000, loss: 0.026803
 >> iter 19000, loss: 0.027376
 >> iter 20000, loss: 0.051821
   Number of active neurons: 4
 >> iter 21000, loss: 0.037637
 >> iter 22000, loss: 0.030357
 >> iter 23000, loss: 0.028703
 >> iter 24000, loss: 0.027279
 >> iter 25000, loss: 0.024699
 >> iter 26000, loss: 0.023240
 >> iter 27000, loss: 0.037231
 >> iter 28000, loss: 0.032550
 >> iter 29000, loss: 0.025952
 >> iter 30000, loss: 0.024418
   Number of active neurons: 3
 >> iter 31000, loss: 0.025320
 >> iter 32000, loss: 0.028562
 >> iter 33000, loss: 0.023875
 >> iter 34000, loss: 0.021860
 >> iter 35000, loss: 0.024259
 >> iter 36000, loss: 0.023653
 >> iter 37000, loss: 0.024911
 >> iter 38000, loss: 0.029567
 >> iter 39000, loss: 0.027058
 >> iter 40000, loss: 0.027314
   Number of active neurons: 3
 >> iter 41000, loss: 0.027677
 >> iter 42000, loss: 0.026757
 >> iter 43000, loss: 0.023385
 >> iter 44000, loss: 0.021840
 >> iter 45000, loss: 0.025465
 >> iter 46000, loss: 0.022150
 >> iter 47000, loss: 0.023265
 >> iter 48000, loss: 0.030542
 >> iter 49000, loss: 0.023337
 >> iter 50000, loss: 0.025248
   Number of active neurons: 2
 >> iter 51000, loss: 0.023730
 >> iter 52000, loss: 0.026050
 >> iter 53000, loss: 0.021837
 >> iter 54000, loss: 0.026573
 >> iter 55000, loss: 0.024785
 >> iter 56000, loss: 0.021907
 >> iter 57000, loss: 0.021971
 >> iter 58000, loss: 0.020420
 >> iter 59000, loss: 0.022337
 >> iter 60000, loss: 0.020996
   Number of active neurons: 2
 >> iter 61000, loss: 0.020127
 >> iter 62000, loss: 0.020826
 >> iter 63000, loss: 0.030871
 >> iter 64000, loss: 0.025092
 >> iter 65000, loss: 0.030302
 >> iter 66000, loss: 0.023177
 >> iter 67000, loss: 0.022281
 >> iter 68000, loss: 0.024964
 >> iter 69000, loss: 0.031374
 >> iter 70000, loss: 0.032434
   Number of active neurons: 2
 >> iter 71000, loss: 0.025355
 >> iter 72000, loss: 0.025264
 >> iter 73000, loss: 0.024451
 >> iter 74000, loss: 0.021386
 >> iter 75000, loss: 0.021886
 >> iter 76000, loss: 0.023086
 >> iter 77000, loss: 0.024177
 >> iter 78000, loss: 0.023945
 >> iter 79000, loss: 0.022053
 >> iter 80000, loss: 0.028445
   Number of active neurons: 2
 >> iter 81000, loss: 0.025903
 >> iter 82000, loss: 0.021432
 >> iter 83000, loss: 0.023234
 >> iter 84000, loss: 0.020393
 >> iter 85000, loss: 0.019465
 >> iter 86000, loss: 0.022507
 >> iter 87000, loss: 0.022482
 >> iter 88000, loss: 0.024260
 >> iter 89000, loss: 0.023094
 >> iter 90000, loss: 0.020838
   Number of active neurons: 2
 >> iter 91000, loss: 0.020667
 >> iter 92000, loss: 0.022010
 >> iter 93000, loss: 0.022229
 >> iter 94000, loss: 0.022234
 >> iter 95000, loss: 0.022258
 >> iter 96000, loss: 0.020543
 >> iter 97000, loss: 0.049146
 >> iter 98000, loss: 0.030933
 >> iter 99000, loss: 0.024546
 >> iter 100000, loss: 0.024545
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.902425
 >> iter 2000, loss: 4.066351
 >> iter 3000, loss: 1.526411
 >> iter 4000, loss: 0.581327
 >> iter 5000, loss: 0.244313
 >> iter 6000, loss: 0.106696
 >> iter 7000, loss: 0.055987
 >> iter 8000, loss: 0.038104
 >> iter 9000, loss: 0.030580
 >> iter 10000, loss: 0.032615
   Number of active neurons: 4
 >> iter 11000, loss: 0.038569
 >> iter 12000, loss: 0.033962
 >> iter 13000, loss: 0.035700
 >> iter 14000, loss: 0.027962
 >> iter 15000, loss: 0.029223
 >> iter 16000, loss: 0.027410
 >> iter 17000, loss: 0.025062
 >> iter 18000, loss: 0.040597
 >> iter 19000, loss: 0.047129
 >> iter 20000, loss: 0.037156
   Number of active neurons: 3
 >> iter 21000, loss: 0.034957
 >> iter 22000, loss: 0.041865
 >> iter 23000, loss: 0.031864
 >> iter 24000, loss: 0.026525
 >> iter 25000, loss: 0.024242
 >> iter 26000, loss: 0.023218
 >> iter 27000, loss: 0.025775
 >> iter 28000, loss: 0.034049
 >> iter 29000, loss: 0.028755
 >> iter 30000, loss: 0.025009
   Number of active neurons: 3
 >> iter 31000, loss: 0.024489
 >> iter 32000, loss: 0.025368
 >> iter 33000, loss: 0.025331
 >> iter 34000, loss: 0.024678
 >> iter 35000, loss: 0.025493
 >> iter 36000, loss: 0.023870
 >> iter 37000, loss: 0.039440
 >> iter 38000, loss: 0.028573
 >> iter 39000, loss: 0.027913
 >> iter 40000, loss: 0.035384
   Number of active neurons: 2
 >> iter 41000, loss: 0.029915
 >> iter 42000, loss: 0.026437
 >> iter 43000, loss: 0.029072
 >> iter 44000, loss: 0.023559
 >> iter 45000, loss: 0.021082
 >> iter 46000, loss: 0.023539
 >> iter 47000, loss: 0.021818
 >> iter 48000, loss: 0.025452
 >> iter 49000, loss: 0.021513
 >> iter 50000, loss: 0.023449
   Number of active neurons: 2
 >> iter 51000, loss: 0.027060
 >> iter 52000, loss: 0.024160
 >> iter 53000, loss: 0.022612
 >> iter 54000, loss: 0.021199
 >> iter 55000, loss: 0.021386
 >> iter 56000, loss: 0.020867
 >> iter 57000, loss: 0.022820
 >> iter 58000, loss: 0.027922
 >> iter 59000, loss: 0.026107
 >> iter 60000, loss: 0.028039
   Number of active neurons: 2
 >> iter 61000, loss: 0.023091
 >> iter 62000, loss: 0.024244
 >> iter 63000, loss: 0.030977
 >> iter 64000, loss: 0.024502
 >> iter 65000, loss: 0.022702
 >> iter 66000, loss: 0.023515
 >> iter 67000, loss: 0.021753
 >> iter 68000, loss: 0.026457
 >> iter 69000, loss: 0.033443
 >> iter 70000, loss: 0.024306
   Number of active neurons: 1
 >> iter 71000, loss: 0.025293
 >> iter 72000, loss: 0.020555
 >> iter 73000, loss: 0.019264
 >> iter 74000, loss: 0.032971
 >> iter 75000, loss: 0.030738
 >> iter 76000, loss: 0.024573
 >> iter 77000, loss: 0.022369
 >> iter 78000, loss: 0.022083
 >> iter 79000, loss: 0.019035
 >> iter 80000, loss: 0.018321
   Number of active neurons: 1
 >> iter 81000, loss: 0.017029
 >> iter 82000, loss: 0.022104
 >> iter 83000, loss: 0.026099
 >> iter 84000, loss: 0.022577
 >> iter 85000, loss: 0.020884
 >> iter 86000, loss: 0.022260
 >> iter 87000, loss: 0.023709
 >> iter 88000, loss: 0.021244
 >> iter 89000, loss: 0.019081
 >> iter 90000, loss: 0.019404
   Number of active neurons: 1
 >> iter 91000, loss: 0.020652
 >> iter 92000, loss: 0.038791
 >> iter 93000, loss: 0.033189
 >> iter 94000, loss: 0.022831
 >> iter 95000, loss: 0.032268
 >> iter 96000, loss: 0.022727
 >> iter 97000, loss: 0.027815
 >> iter 98000, loss: 0.023801
 >> iter 99000, loss: 0.022705
 >> iter 100000, loss: 0.028337
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.895850
 >> iter 2000, loss: 4.044364
 >> iter 3000, loss: 1.515371
 >> iter 4000, loss: 0.584826
 >> iter 5000, loss: 0.238609
 >> iter 6000, loss: 0.108446
 >> iter 7000, loss: 0.064258
 >> iter 8000, loss: 0.045500
 >> iter 9000, loss: 0.036782
 >> iter 10000, loss: 0.029550
   Number of active neurons: 4
 >> iter 11000, loss: 0.029436
 >> iter 12000, loss: 0.028431
 >> iter 13000, loss: 0.026892
 >> iter 14000, loss: 0.024789
 >> iter 15000, loss: 0.024304
 >> iter 16000, loss: 0.024923
 >> iter 17000, loss: 0.024472
 >> iter 18000, loss: 0.027718
 >> iter 19000, loss: 0.026323
 >> iter 20000, loss: 0.023005
   Number of active neurons: 2
 >> iter 21000, loss: 0.025335
 >> iter 22000, loss: 0.044105
 >> iter 23000, loss: 0.031181
 >> iter 24000, loss: 0.025201
 >> iter 25000, loss: 0.022294
 >> iter 26000, loss: 0.021091
 >> iter 27000, loss: 0.020626
 >> iter 28000, loss: 0.021317
 >> iter 29000, loss: 0.029483
 >> iter 30000, loss: 0.022972
   Number of active neurons: 2
 >> iter 31000, loss: 0.022783
 >> iter 32000, loss: 0.020652
 >> iter 33000, loss: 0.023031
 >> iter 34000, loss: 0.021933
 >> iter 35000, loss: 0.020928
 >> iter 36000, loss: 0.019059
 >> iter 37000, loss: 0.022326
 >> iter 38000, loss: 0.021545
 >> iter 39000, loss: 0.024595
 >> iter 40000, loss: 0.044065
   Number of active neurons: 2
 >> iter 41000, loss: 0.031298
 >> iter 42000, loss: 0.022910
 >> iter 43000, loss: 0.024603
 >> iter 44000, loss: 0.020683
 >> iter 45000, loss: 0.028757
 >> iter 46000, loss: 0.024356
 >> iter 47000, loss: 0.019838
 >> iter 48000, loss: 0.022905
 >> iter 49000, loss: 0.020587
 >> iter 50000, loss: 0.019131
   Number of active neurons: 2
 >> iter 51000, loss: 0.021546
 >> iter 52000, loss: 0.021264
 >> iter 53000, loss: 0.022011
 >> iter 54000, loss: 0.021748
 >> iter 55000, loss: 0.020512
 >> iter 56000, loss: 0.021720
 >> iter 57000, loss: 0.023245
 >> iter 58000, loss: 0.022376
 >> iter 59000, loss: 0.022558
 >> iter 60000, loss: 0.025144
   Number of active neurons: 2
 >> iter 61000, loss: 0.034514
 >> iter 62000, loss: 0.025872
 >> iter 63000, loss: 0.026182
 >> iter 64000, loss: 0.020064
 >> iter 65000, loss: 0.019612
 >> iter 66000, loss: 0.019120
 >> iter 67000, loss: 0.020554
 >> iter 68000, loss: 0.024187
 >> iter 69000, loss: 0.024484
 >> iter 70000, loss: 0.023587
   Number of active neurons: 2
 >> iter 71000, loss: 0.023345
 >> iter 72000, loss: 0.033104
 >> iter 73000, loss: 0.032079
 >> iter 74000, loss: 0.034320
 >> iter 75000, loss: 0.026880
 >> iter 76000, loss: 0.055482
 >> iter 77000, loss: 0.034106
 >> iter 78000, loss: 0.026744
 >> iter 79000, loss: 0.025599
 >> iter 80000, loss: 0.022165
   Number of active neurons: 2
 >> iter 81000, loss: 0.021277
 >> iter 82000, loss: 0.021639
 >> iter 83000, loss: 0.022070
 >> iter 84000, loss: 0.025974
 >> iter 85000, loss: 0.030797
 >> iter 86000, loss: 0.046402
 >> iter 87000, loss: 0.031337
 >> iter 88000, loss: 0.024980
 >> iter 89000, loss: 0.023870
 >> iter 90000, loss: 0.021186
   Number of active neurons: 2
 >> iter 91000, loss: 0.031165
 >> iter 92000, loss: 0.060898
 >> iter 93000, loss: 0.036652
 >> iter 94000, loss: 0.028616
 >> iter 95000, loss: 0.029671
 >> iter 96000, loss: 0.025681
 >> iter 97000, loss: 0.024028
 >> iter 98000, loss: 0.027810
 >> iter 99000, loss: 0.031563
 >> iter 100000, loss: 0.029862
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.970061
 >> iter 2000, loss: 4.072304
 >> iter 3000, loss: 1.520789
 >> iter 4000, loss: 0.582762
 >> iter 5000, loss: 0.232194
 >> iter 6000, loss: 0.103493
 >> iter 7000, loss: 0.058081
 >> iter 8000, loss: 0.039424
 >> iter 9000, loss: 0.032718
 >> iter 10000, loss: 0.033617
   Number of active neurons: 3
 >> iter 11000, loss: 0.030440
 >> iter 12000, loss: 0.030266
 >> iter 13000, loss: 0.025922
 >> iter 14000, loss: 0.023982
 >> iter 15000, loss: 0.023991
 >> iter 16000, loss: 0.024188
 >> iter 17000, loss: 0.036750
 >> iter 18000, loss: 0.034769
 >> iter 19000, loss: 0.052570
 >> iter 20000, loss: 0.041148
   Number of active neurons: 3
 >> iter 21000, loss: 0.046595
 >> iter 22000, loss: 0.034202
 >> iter 23000, loss: 0.030024
 >> iter 24000, loss: 0.038636
 >> iter 25000, loss: 0.031204
 >> iter 26000, loss: 0.030264
 >> iter 27000, loss: 0.047756
 >> iter 28000, loss: 0.032691
 >> iter 29000, loss: 0.038459
 >> iter 30000, loss: 0.028203
   Number of active neurons: 3
 >> iter 31000, loss: 0.025460
 >> iter 32000, loss: 0.026045
 >> iter 33000, loss: 0.023830
 >> iter 34000, loss: 0.025855
 >> iter 35000, loss: 0.024113
 >> iter 36000, loss: 0.029174
 >> iter 37000, loss: 0.032886
 >> iter 38000, loss: 0.024371
 >> iter 39000, loss: 0.023076
 >> iter 40000, loss: 0.020376
   Number of active neurons: 1
 >> iter 41000, loss: 0.018281
 >> iter 42000, loss: 0.019619
 >> iter 43000, loss: 0.019084
 >> iter 44000, loss: 0.025976
 >> iter 45000, loss: 0.022240
 >> iter 46000, loss: 0.020686
 >> iter 47000, loss: 0.024318
 >> iter 48000, loss: 0.032153
 >> iter 49000, loss: 0.028593
 >> iter 50000, loss: 0.037413
   Number of active neurons: 1
 >> iter 51000, loss: 0.026899
 >> iter 52000, loss: 0.022236
 >> iter 53000, loss: 0.022620
 >> iter 54000, loss: 0.018488
 >> iter 55000, loss: 0.022720
 >> iter 56000, loss: 0.018906
 >> iter 57000, loss: 0.023895
 >> iter 58000, loss: 0.020866
 >> iter 59000, loss: 0.018074
 >> iter 60000, loss: 0.017091
   Number of active neurons: 1
 >> iter 61000, loss: 0.018994
 >> iter 62000, loss: 0.017983
 >> iter 63000, loss: 0.026657
 >> iter 64000, loss: 0.023935
 >> iter 65000, loss: 0.022045
 >> iter 66000, loss: 0.018382
 >> iter 67000, loss: 0.036694
 >> iter 68000, loss: 0.036933
 >> iter 69000, loss: 0.037642
 >> iter 70000, loss: 0.025975
   Number of active neurons: 1
 >> iter 71000, loss: 0.020875
 >> iter 72000, loss: 0.022779
 >> iter 73000, loss: 0.024799
 >> iter 74000, loss: 0.033045
 >> iter 75000, loss: 0.024593
 >> iter 76000, loss: 0.019965
 >> iter 77000, loss: 0.018763
 >> iter 78000, loss: 0.017759
 >> iter 79000, loss: 0.019264
 >> iter 80000, loss: 0.018912
   Number of active neurons: 1
 >> iter 81000, loss: 0.016589
 >> iter 82000, loss: 0.021129
 >> iter 83000, loss: 0.019842
 >> iter 84000, loss: 0.019694
 >> iter 85000, loss: 0.037039
 >> iter 86000, loss: 0.028602
 >> iter 87000, loss: 0.025522
 >> iter 88000, loss: 0.023673
 >> iter 89000, loss: 0.019919
 >> iter 90000, loss: 0.019744
   Number of active neurons: 1
 >> iter 91000, loss: 0.017190
 >> iter 92000, loss: 0.025736
 >> iter 93000, loss: 0.021216
 >> iter 94000, loss: 0.018393
 >> iter 95000, loss: 0.016696
 >> iter 96000, loss: 0.022251
 >> iter 97000, loss: 0.021002
 >> iter 98000, loss: 0.029914
 >> iter 99000, loss: 0.035501
 >> iter 100000, loss: 0.028029
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.944782
 >> iter 2000, loss: 4.096208
 >> iter 3000, loss: 1.548208
 >> iter 4000, loss: 0.590999
 >> iter 5000, loss: 0.249292
 >> iter 6000, loss: 0.109001
 >> iter 7000, loss: 0.059616
 >> iter 8000, loss: 0.040801
 >> iter 9000, loss: 0.034749
 >> iter 10000, loss: 0.032789
   Number of active neurons: 3
 >> iter 11000, loss: 0.030029
 >> iter 12000, loss: 0.033177
 >> iter 13000, loss: 0.047076
 >> iter 14000, loss: 0.033207
 >> iter 15000, loss: 0.028480
 >> iter 16000, loss: 0.026714
 >> iter 17000, loss: 0.024898
 >> iter 18000, loss: 0.024496
 >> iter 19000, loss: 0.022084
 >> iter 20000, loss: 0.021599
   Number of active neurons: 2
 >> iter 21000, loss: 0.034166
 >> iter 22000, loss: 0.033526
 >> iter 23000, loss: 0.028545
 >> iter 24000, loss: 0.024137
 >> iter 25000, loss: 0.023566
 >> iter 26000, loss: 0.020619
 >> iter 27000, loss: 0.021005
 >> iter 28000, loss: 0.021417
 >> iter 29000, loss: 0.020937
 >> iter 30000, loss: 0.021978
   Number of active neurons: 2
 >> iter 31000, loss: 0.032136
 >> iter 32000, loss: 0.022801
 >> iter 33000, loss: 0.022578
 >> iter 34000, loss: 0.022289
 >> iter 35000, loss: 0.026412
 >> iter 36000, loss: 0.022896
 >> iter 37000, loss: 0.020832
 >> iter 38000, loss: 0.024369
 >> iter 39000, loss: 0.032092
 >> iter 40000, loss: 0.024753
   Number of active neurons: 2
 >> iter 41000, loss: 0.022154
 >> iter 42000, loss: 0.020911
 >> iter 43000, loss: 0.021752
 >> iter 44000, loss: 0.025054
 >> iter 45000, loss: 0.021680
 >> iter 46000, loss: 0.019517
 >> iter 47000, loss: 0.020075
 >> iter 48000, loss: 0.021373
 >> iter 49000, loss: 0.021697
 >> iter 50000, loss: 0.027647
   Number of active neurons: 2
 >> iter 51000, loss: 0.023644
 >> iter 52000, loss: 0.022719
 >> iter 53000, loss: 0.023003
 >> iter 54000, loss: 0.020539
 >> iter 55000, loss: 0.024396
 >> iter 56000, loss: 0.021168
 >> iter 57000, loss: 0.021247
 >> iter 58000, loss: 0.022382
 >> iter 59000, loss: 0.021154
 >> iter 60000, loss: 0.035065
   Number of active neurons: 2
 >> iter 61000, loss: 0.025164
 >> iter 62000, loss: 0.023735
 >> iter 63000, loss: 0.023773
 >> iter 64000, loss: 0.022084
 >> iter 65000, loss: 0.021074
 >> iter 66000, loss: 0.037357
 >> iter 67000, loss: 0.032094
 >> iter 68000, loss: 0.026320
 >> iter 69000, loss: 0.023656
 >> iter 70000, loss: 0.033424
   Number of active neurons: 2
 >> iter 71000, loss: 0.031118
 >> iter 72000, loss: 0.026589
 >> iter 73000, loss: 0.021899
 >> iter 74000, loss: 0.029633
 >> iter 75000, loss: 0.031139
 >> iter 76000, loss: 0.036880
 >> iter 77000, loss: 0.027614
 >> iter 78000, loss: 0.026602
 >> iter 79000, loss: 0.024486
 >> iter 80000, loss: 0.026861
   Number of active neurons: 2
 >> iter 81000, loss: 0.026794
 >> iter 82000, loss: 0.024861
 >> iter 83000, loss: 0.026356
 >> iter 84000, loss: 0.021283
 >> iter 85000, loss: 0.022784
 >> iter 86000, loss: 0.023663
 >> iter 87000, loss: 0.073297
 >> iter 88000, loss: 0.040190
 >> iter 89000, loss: 0.026715
 >> iter 90000, loss: 0.023139
   Number of active neurons: 1
 >> iter 91000, loss: 0.030183
 >> iter 92000, loss: 0.025342
 >> iter 93000, loss: 0.032834
 >> iter 94000, loss: 0.024645
 >> iter 95000, loss: 0.019420
 >> iter 96000, loss: 0.032395
 >> iter 97000, loss: 0.022894
 >> iter 98000, loss: 0.026581
 >> iter 99000, loss: 0.021929
 >> iter 100000, loss: 0.019303
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.892911
 >> iter 2000, loss: 4.056385
 >> iter 3000, loss: 1.527534
 >> iter 4000, loss: 0.580468
 >> iter 5000, loss: 0.238977
 >> iter 6000, loss: 0.114240
 >> iter 7000, loss: 0.065696
 >> iter 8000, loss: 0.051485
 >> iter 9000, loss: 0.039695
 >> iter 10000, loss: 0.032753
   Number of active neurons: 5
 >> iter 11000, loss: 0.029852
 >> iter 12000, loss: 0.039210
 >> iter 13000, loss: 0.031965
 >> iter 14000, loss: 0.027362
 >> iter 15000, loss: 0.046024
 >> iter 16000, loss: 0.032515
 >> iter 17000, loss: 0.027567
 >> iter 18000, loss: 0.026909
 >> iter 19000, loss: 0.032262
 >> iter 20000, loss: 0.031048
   Number of active neurons: 2
 >> iter 21000, loss: 0.025040
 >> iter 22000, loss: 0.021633
 >> iter 23000, loss: 0.031025
 >> iter 24000, loss: 0.025269
 >> iter 25000, loss: 0.021641
 >> iter 26000, loss: 0.022960
 >> iter 27000, loss: 0.031179
 >> iter 28000, loss: 0.030237
 >> iter 29000, loss: 0.027819
 >> iter 30000, loss: 0.022090
   Number of active neurons: 2
 >> iter 31000, loss: 0.024710
 >> iter 32000, loss: 0.022083
 >> iter 33000, loss: 0.021439
 >> iter 34000, loss: 0.032628
 >> iter 35000, loss: 0.025973
 >> iter 36000, loss: 0.029821
 >> iter 37000, loss: 0.022867
 >> iter 38000, loss: 0.026745
 >> iter 39000, loss: 0.027125
 >> iter 40000, loss: 0.022618
   Number of active neurons: 2
 >> iter 41000, loss: 0.038406
 >> iter 42000, loss: 0.047479
 >> iter 43000, loss: 0.030734
 >> iter 44000, loss: 0.022583
 >> iter 45000, loss: 0.028554
 >> iter 46000, loss: 0.037521
 >> iter 47000, loss: 0.030893
 >> iter 48000, loss: 0.023915
 >> iter 49000, loss: 0.048911
 >> iter 50000, loss: 0.033302
   Number of active neurons: 2
 >> iter 51000, loss: 0.029466
 >> iter 52000, loss: 0.034524
 >> iter 53000, loss: 0.031491
 >> iter 54000, loss: 0.024976
 >> iter 55000, loss: 0.032031
 >> iter 56000, loss: 0.026650
 >> iter 57000, loss: 0.022740
 >> iter 58000, loss: 0.021535
 >> iter 59000, loss: 0.023238
 >> iter 60000, loss: 0.024863
   Number of active neurons: 2
 >> iter 61000, loss: 0.023065
 >> iter 62000, loss: 0.024168
 >> iter 63000, loss: 0.023874
 >> iter 64000, loss: 0.021823
 >> iter 65000, loss: 0.036046
 >> iter 66000, loss: 0.027590
 >> iter 67000, loss: 0.030633
 >> iter 68000, loss: 0.030777
 >> iter 69000, loss: 0.023721
 >> iter 70000, loss: 0.022061
   Number of active neurons: 2
 >> iter 71000, loss: 0.021975
 >> iter 72000, loss: 0.022028
 >> iter 73000, loss: 0.021295
 >> iter 74000, loss: 0.020108
 >> iter 75000, loss: 0.021818
 >> iter 76000, loss: 0.020599
 >> iter 77000, loss: 0.022202
 >> iter 78000, loss: 0.026895
 >> iter 79000, loss: 0.023904
 >> iter 80000, loss: 0.021311
   Number of active neurons: 1
 >> iter 81000, loss: 0.020808
 >> iter 82000, loss: 0.024098
 >> iter 83000, loss: 0.022433
 >> iter 84000, loss: 0.025145
 >> iter 85000, loss: 0.039793
 >> iter 86000, loss: 0.025523
 >> iter 87000, loss: 0.020492
 >> iter 88000, loss: 0.025284
 >> iter 89000, loss: 0.032739
 >> iter 90000, loss: 0.025312
   Number of active neurons: 1
 >> iter 91000, loss: 0.022589
 >> iter 92000, loss: 0.018829
 >> iter 93000, loss: 0.025001
 >> iter 94000, loss: 0.031039
 >> iter 95000, loss: 0.035382
 >> iter 96000, loss: 0.048126
 >> iter 97000, loss: 0.027731
 >> iter 98000, loss: 0.035200
 >> iter 99000, loss: 0.032946
 >> iter 100000, loss: 0.022041
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.911641
 >> iter 2000, loss: 4.064015
 >> iter 3000, loss: 1.522749
 >> iter 4000, loss: 0.591072
 >> iter 5000, loss: 0.238703
 >> iter 6000, loss: 0.124191
 >> iter 7000, loss: 0.066977
 >> iter 8000, loss: 0.053794
 >> iter 9000, loss: 0.044521
 >> iter 10000, loss: 0.040052
   Number of active neurons: 4
 >> iter 11000, loss: 0.039055
 >> iter 12000, loss: 0.036256
 >> iter 13000, loss: 0.028813
 >> iter 14000, loss: 0.027632
 >> iter 15000, loss: 0.026844
 >> iter 16000, loss: 0.032221
 >> iter 17000, loss: 0.031744
 >> iter 18000, loss: 0.036281
 >> iter 19000, loss: 0.029954
 >> iter 20000, loss: 0.027158
   Number of active neurons: 3
 >> iter 21000, loss: 0.047622
 >> iter 22000, loss: 0.032509
 >> iter 23000, loss: 0.028212
 >> iter 24000, loss: 0.030305
 >> iter 25000, loss: 0.029429
 >> iter 26000, loss: 0.036862
 >> iter 27000, loss: 0.030763
 >> iter 28000, loss: 0.025361
 >> iter 29000, loss: 0.031198
 >> iter 30000, loss: 0.023824
   Number of active neurons: 2
 >> iter 31000, loss: 0.022798
 >> iter 32000, loss: 0.029756
 >> iter 33000, loss: 0.032174
 >> iter 34000, loss: 0.028213
 >> iter 35000, loss: 0.036449
 >> iter 36000, loss: 0.034947
 >> iter 37000, loss: 0.026167
 >> iter 38000, loss: 0.023251
 >> iter 39000, loss: 0.023144
 >> iter 40000, loss: 0.030691
   Number of active neurons: 2
 >> iter 41000, loss: 0.073721
 >> iter 42000, loss: 0.045522
 >> iter 43000, loss: 0.031978
 >> iter 44000, loss: 0.031009
 >> iter 45000, loss: 0.024893
 >> iter 46000, loss: 0.023330
 >> iter 47000, loss: 0.022564
 >> iter 48000, loss: 0.020190
 >> iter 49000, loss: 0.025705
 >> iter 50000, loss: 0.026143
   Number of active neurons: 1
 >> iter 51000, loss: 0.025911
 >> iter 52000, loss: 0.027778
 >> iter 53000, loss: 0.021815
 >> iter 54000, loss: 0.020810
 >> iter 55000, loss: 0.029742
 >> iter 56000, loss: 0.024676
 >> iter 57000, loss: 0.023291
 >> iter 58000, loss: 0.022462
 >> iter 59000, loss: 0.019610
 >> iter 60000, loss: 0.031351
   Number of active neurons: 1
 >> iter 61000, loss: 0.024197
 >> iter 62000, loss: 0.022289
 >> iter 63000, loss: 0.019501
 >> iter 64000, loss: 0.024177
 >> iter 65000, loss: 0.019160
 >> iter 66000, loss: 0.022282
 >> iter 67000, loss: 0.019979
 >> iter 68000, loss: 0.018100
 >> iter 69000, loss: 0.023852
 >> iter 70000, loss: 0.019227
   Number of active neurons: 1
 >> iter 71000, loss: 0.040318
 >> iter 72000, loss: 0.025690
 >> iter 73000, loss: 0.020435
 >> iter 74000, loss: 0.017774
 >> iter 75000, loss: 0.015816
 >> iter 76000, loss: 0.028048
 >> iter 77000, loss: 0.030991
 >> iter 78000, loss: 0.023354
 >> iter 79000, loss: 0.028313
 >> iter 80000, loss: 0.031968
   Number of active neurons: 1
 >> iter 81000, loss: 0.027215
 >> iter 82000, loss: 0.021984
 >> iter 83000, loss: 0.021174
 >> iter 84000, loss: 0.019891
 >> iter 85000, loss: 0.023083
 >> iter 86000, loss: 0.031209
 >> iter 87000, loss: 0.032044
 >> iter 88000, loss: 0.031716
 >> iter 89000, loss: 0.023789
 >> iter 90000, loss: 0.025628
   Number of active neurons: 1
 >> iter 91000, loss: 0.023104
 >> iter 92000, loss: 0.019417
 >> iter 93000, loss: 0.016651
 >> iter 94000, loss: 0.019704
 >> iter 95000, loss: 0.028350
 >> iter 96000, loss: 0.023480
 >> iter 97000, loss: 0.019101
 >> iter 98000, loss: 0.023486
 >> iter 99000, loss: 0.020555
 >> iter 100000, loss: 0.030076
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.941378
 >> iter 2000, loss: 4.069134
 >> iter 3000, loss: 1.532292
 >> iter 4000, loss: 0.595816
 >> iter 5000, loss: 0.240388
 >> iter 6000, loss: 0.107904
 >> iter 7000, loss: 0.062992
 >> iter 8000, loss: 0.047856
 >> iter 9000, loss: 0.036948
 >> iter 10000, loss: 0.029801
   Number of active neurons: 3
 >> iter 11000, loss: 0.026700
 >> iter 12000, loss: 0.027601
 >> iter 13000, loss: 0.027821
 >> iter 14000, loss: 0.033634
 >> iter 15000, loss: 0.052978
 >> iter 16000, loss: 0.032755
 >> iter 17000, loss: 0.028399
 >> iter 18000, loss: 0.024404
 >> iter 19000, loss: 0.023753
 >> iter 20000, loss: 0.022600
   Number of active neurons: 3
 >> iter 21000, loss: 0.028144
 >> iter 22000, loss: 0.025830
 >> iter 23000, loss: 0.026482
 >> iter 24000, loss: 0.030091
 >> iter 25000, loss: 0.024910
 >> iter 26000, loss: 0.024411
 >> iter 27000, loss: 0.023188
 >> iter 28000, loss: 0.024194
 >> iter 29000, loss: 0.022817
 >> iter 30000, loss: 0.026720
   Number of active neurons: 2
 >> iter 31000, loss: 0.028499
 >> iter 32000, loss: 0.030390
 >> iter 33000, loss: 0.024838
 >> iter 34000, loss: 0.027154
 >> iter 35000, loss: 0.024600
 >> iter 36000, loss: 0.028668
 >> iter 37000, loss: 0.023437
 >> iter 38000, loss: 0.022580
 >> iter 39000, loss: 0.034209
 >> iter 40000, loss: 0.027600
   Number of active neurons: 2
 >> iter 41000, loss: 0.028840
 >> iter 42000, loss: 0.027166
 >> iter 43000, loss: 0.022461
 >> iter 44000, loss: 0.022542
 >> iter 45000, loss: 0.020557
 >> iter 46000, loss: 0.020073
 >> iter 47000, loss: 0.028199
 >> iter 48000, loss: 0.026406
 >> iter 49000, loss: 0.022885
 >> iter 50000, loss: 0.021664
   Number of active neurons: 2
 >> iter 51000, loss: 0.022659
 >> iter 52000, loss: 0.020367
 >> iter 53000, loss: 0.021447
 >> iter 54000, loss: 0.022832
 >> iter 55000, loss: 0.021695
 >> iter 56000, loss: 0.023759
 >> iter 57000, loss: 0.022539
 >> iter 58000, loss: 0.037118
 >> iter 59000, loss: 0.025635
 >> iter 60000, loss: 0.022028
   Number of active neurons: 1
 >> iter 61000, loss: 0.022217
 >> iter 62000, loss: 0.020241
 >> iter 63000, loss: 0.018746
 >> iter 64000, loss: 0.020817
 >> iter 65000, loss: 0.021349
 >> iter 66000, loss: 0.018896
 >> iter 67000, loss: 0.017777
 >> iter 68000, loss: 0.022289
 >> iter 69000, loss: 0.023155
 >> iter 70000, loss: 0.019561
   Number of active neurons: 1
 >> iter 71000, loss: 0.022696
 >> iter 72000, loss: 0.034763
 >> iter 73000, loss: 0.027585
 >> iter 74000, loss: 0.020709
 >> iter 75000, loss: 0.020434
 >> iter 76000, loss: 0.018367
 >> iter 77000, loss: 0.020167
 >> iter 78000, loss: 0.032224
 >> iter 79000, loss: 0.036340
 >> iter 80000, loss: 0.026979
   Number of active neurons: 1
 >> iter 81000, loss: 0.035903
 >> iter 82000, loss: 0.027922
 >> iter 83000, loss: 0.024265
 >> iter 84000, loss: 0.020105
 >> iter 85000, loss: 0.023229
 >> iter 86000, loss: 0.049141
 >> iter 87000, loss: 0.034875
 >> iter 88000, loss: 0.022291
 >> iter 89000, loss: 0.024785
 >> iter 90000, loss: 0.020459
   Number of active neurons: 1
 >> iter 91000, loss: 0.024626
 >> iter 92000, loss: 0.029435
 >> iter 93000, loss: 0.021299
 >> iter 94000, loss: 0.017773
 >> iter 95000, loss: 0.018398
 >> iter 96000, loss: 0.018348
 >> iter 97000, loss: 0.017302
 >> iter 98000, loss: 0.019357
 >> iter 99000, loss: 0.025336
 >> iter 100000, loss: 0.020372
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

