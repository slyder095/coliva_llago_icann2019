 > Problema: tomita7nueva
 > Args:
   - Hidden size: 8
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.393753
 >> iter 2000, loss: 11.291692
 >> iter 3000, loss: 8.009717
 >> iter 4000, loss: 5.550385
 >> iter 5000, loss: 3.781624
 >> iter 6000, loss: 2.697183
 >> iter 7000, loss: 2.264057
 >> iter 8000, loss: 2.151287
 >> iter 9000, loss: 2.016500
 >> iter 10000, loss: 1.920721
   Number of active neurons: 6
 >> iter 11000, loss: 1.771756
 >> iter 12000, loss: 1.863457
 >> iter 13000, loss: 1.791099
 >> iter 14000, loss: 1.898239
 >> iter 15000, loss: 1.954336
   Number of active neurons: 7
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 2.126170
 >> iter 17000, loss: 1.905283
 >> iter 18000, loss: 1.803566
 >> iter 19000, loss: 1.733199
 >> iter 20000, loss: 1.736684
   Number of active neurons: 8
 >> iter 21000, loss: 1.801706
 >> iter 22000, loss: 1.798427
 >> iter 23000, loss: 1.730356
 >> iter 24000, loss: 1.747358
 >> iter 25000, loss: 1.506259
 >> iter 26000, loss: 1.329058
 >> iter 27000, loss: 1.156560
 >> iter 28000, loss: 1.074722
 >> iter 29000, loss: 0.905912
 >> iter 30000, loss: 0.902936
   Number of active neurons: 7
 >> iter 31000, loss: 0.874146
 >> iter 32000, loss: 0.818282
 >> iter 33000, loss: 0.752458
 >> iter 34000, loss: 0.792269
 >> iter 35000, loss: 0.772382
 >> iter 36000, loss: 0.670424
 >> iter 37000, loss: 0.654807
 >> iter 38000, loss: 0.676668
 >> iter 39000, loss: 0.708142
 >> iter 40000, loss: 0.547312
   Number of active neurons: 7
 >> iter 41000, loss: 0.607320
 >> iter 42000, loss: 0.682582
 >> iter 43000, loss: 0.742856
 >> iter 44000, loss: 0.720223
 >> iter 45000, loss: 0.534669
 >> iter 46000, loss: 0.473995
 >> iter 47000, loss: 0.496557
 >> iter 48000, loss: 0.462363
 >> iter 49000, loss: 0.477692
 >> iter 50000, loss: 0.483956
   Number of active neurons: 6
 >> iter 51000, loss: 0.483019
 >> iter 52000, loss: 0.418990
 >> iter 53000, loss: 0.643430
 >> iter 54000, loss: 0.580231
 >> iter 55000, loss: 0.516137
 >> iter 56000, loss: 0.411608
 >> iter 57000, loss: 0.442022
 >> iter 58000, loss: 0.368776
 >> iter 59000, loss: 0.439576
 >> iter 60000, loss: 0.421312
   Number of active neurons: 6
 >> iter 61000, loss: 0.428112
 >> iter 62000, loss: 0.412067
 >> iter 63000, loss: 0.362073
 >> iter 64000, loss: 0.476362
 >> iter 65000, loss: 0.455973
 >> iter 66000, loss: 0.422639
 >> iter 67000, loss: 0.447110
 >> iter 68000, loss: 0.564868
 >> iter 69000, loss: 0.364480
 >> iter 70000, loss: 0.458450
   Number of active neurons: 6
 >> iter 71000, loss: 0.486433
 >> iter 72000, loss: 0.368544
 >> iter 73000, loss: 0.373028
 >> iter 74000, loss: 0.452527
 >> iter 75000, loss: 0.587281
 >> iter 76000, loss: 0.570501
 >> iter 77000, loss: 0.584328
 >> iter 78000, loss: 0.591771
 >> iter 79000, loss: 0.485553
 >> iter 80000, loss: 0.513518
   Number of active neurons: 6
 >> iter 81000, loss: 0.394873
 >> iter 82000, loss: 0.335579
 >> iter 83000, loss: 0.407155
 >> iter 84000, loss: 0.455856
 >> iter 85000, loss: 0.551682
 >> iter 86000, loss: 0.484299
 >> iter 87000, loss: 0.383728
 >> iter 88000, loss: 0.338509
 >> iter 89000, loss: 0.261039
 >> iter 90000, loss: 0.288983
   Number of active neurons: 6
 >> iter 91000, loss: 0.285916
 >> iter 92000, loss: 0.400971
 >> iter 93000, loss: 0.417069
 >> iter 94000, loss: 0.510846
 >> iter 95000, loss: 0.370188
 >> iter 96000, loss: 0.352935
 >> iter 97000, loss: 0.378694
 >> iter 98000, loss: 0.452944
 >> iter 99000, loss: 0.307962
 >> iter 100000, loss: 0.381723
   Number of active neurons: 5
 >> iter 101000, loss: 0.303280
 >> iter 102000, loss: 0.249348
 >> iter 103000, loss: 0.347930
 >> iter 104000, loss: 0.234007
 >> iter 105000, loss: 0.289790
 >> iter 106000, loss: 0.324675
 >> iter 107000, loss: 0.397685
 >> iter 108000, loss: 0.268014
 >> iter 109000, loss: 0.260506
 >> iter 110000, loss: 0.278521
   Number of active neurons: 4
 >> iter 111000, loss: 0.332681
 >> iter 112000, loss: 0.230746
 >> iter 113000, loss: 0.220636
 >> iter 114000, loss: 0.281399
 >> iter 115000, loss: 0.308600
 >> iter 116000, loss: 0.228617
 >> iter 117000, loss: 0.178373
 >> iter 118000, loss: 0.232766
 >> iter 119000, loss: 0.249047
 >> iter 120000, loss: 0.217495
   Number of active neurons: 4
 >> iter 121000, loss: 0.293812
 >> iter 122000, loss: 0.351267
 >> iter 123000, loss: 0.343695
 >> iter 124000, loss: 0.339986
 >> iter 125000, loss: 0.367035
 >> iter 126000, loss: 0.304810
 >> iter 127000, loss: 0.363411
 >> iter 128000, loss: 0.330587
 >> iter 129000, loss: 0.231247
 >> iter 130000, loss: 0.307166
   Number of active neurons: 4
 >> iter 131000, loss: 0.307630
 >> iter 132000, loss: 0.309652
 >> iter 133000, loss: 0.267716
 >> iter 134000, loss: 0.327489
 >> iter 135000, loss: 0.343359
 >> iter 136000, loss: 0.326445
 >> iter 137000, loss: 0.377740
 >> iter 138000, loss: 0.292950
 >> iter 139000, loss: 0.278111
 >> iter 140000, loss: 0.361756
   Number of active neurons: 4
 >> iter 141000, loss: 0.309640
 >> iter 142000, loss: 0.251180
 >> iter 143000, loss: 0.261642
 >> iter 144000, loss: 0.196099
 >> iter 145000, loss: 0.323013
 >> iter 146000, loss: 0.435121
 >> iter 147000, loss: 0.312823
 >> iter 148000, loss: 0.323214
 >> iter 149000, loss: 0.408019
 >> iter 150000, loss: 0.345048
   Number of active neurons: 4
 >> iter 151000, loss: 0.380143
 >> iter 152000, loss: 0.332607
 >> iter 153000, loss: 0.261594
 >> iter 154000, loss: 0.318184
 >> iter 155000, loss: 0.269688
 >> iter 156000, loss: 0.276813
 >> iter 157000, loss: 0.289889
 >> iter 158000, loss: 0.365296
 >> iter 159000, loss: 0.380120
 >> iter 160000, loss: 0.279079
   Number of active neurons: 4
 >> iter 161000, loss: 0.355870
 >> iter 162000, loss: 0.416683
 >> iter 163000, loss: 0.384669
 >> iter 164000, loss: 0.346943
 >> iter 165000, loss: 0.248913
 >> iter 166000, loss: 0.295348
 >> iter 167000, loss: 0.290490
 >> iter 168000, loss: 0.275042
 >> iter 169000, loss: 0.325974
 >> iter 170000, loss: 0.271372
   Number of active neurons: 4
 >> iter 171000, loss: 0.278593
 >> iter 172000, loss: 0.443850
 >> iter 173000, loss: 0.391926
 >> iter 174000, loss: 0.337901
 >> iter 175000, loss: 0.352363
 >> iter 176000, loss: 0.323963
 >> iter 177000, loss: 0.312694
 >> iter 178000, loss: 0.277577
 >> iter 179000, loss: 0.269155
 >> iter 180000, loss: 0.228228
   Number of active neurons: 4
 >> iter 181000, loss: 0.198205
 >> iter 182000, loss: 0.365006
 >> iter 183000, loss: 0.253186
 >> iter 184000, loss: 0.208644
 >> iter 185000, loss: 0.263911
 >> iter 186000, loss: 0.323033
 >> iter 187000, loss: 0.253011
 >> iter 188000, loss: 0.224936
 >> iter 189000, loss: 0.204683
 >> iter 190000, loss: 0.216585
   Number of active neurons: 4
 >> iter 191000, loss: 0.229603
 >> iter 192000, loss: 0.192439
 >> iter 193000, loss: 0.310799
 >> iter 194000, loss: 0.221992
 >> iter 195000, loss: 0.294960
 >> iter 196000, loss: 0.315875
 >> iter 197000, loss: 0.394739
 >> iter 198000, loss: 0.376563
 >> iter 199000, loss: 0.367886
 >> iter 200000, loss: 0.346652
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.704919
 >> iter 2000, loss: 8.926553
 >> iter 3000, loss: 4.720898
 >> iter 4000, loss: 2.502467
 >> iter 5000, loss: 1.604013
 >> iter 6000, loss: 1.264173
 >> iter 7000, loss: 1.215139
 >> iter 8000, loss: 0.895027
 >> iter 9000, loss: 0.877492
 >> iter 10000, loss: 0.727594
   Number of active neurons: 6
 >> iter 11000, loss: 0.567476
 >> iter 12000, loss: 0.540056
 >> iter 13000, loss: 0.481546
 >> iter 14000, loss: 0.473958
 >> iter 15000, loss: 0.629634
 >> iter 16000, loss: 0.472704
 >> iter 17000, loss: 0.431612
 >> iter 18000, loss: 0.329460
 >> iter 19000, loss: 0.364054
 >> iter 20000, loss: 0.365311
   Number of active neurons: 6
 >> iter 21000, loss: 0.488352
 >> iter 22000, loss: 0.367645
 >> iter 23000, loss: 0.440888
 >> iter 24000, loss: 0.494115
 >> iter 25000, loss: 0.517612
 >> iter 26000, loss: 0.438065
 >> iter 27000, loss: 0.499832
 >> iter 28000, loss: 0.398791
 >> iter 29000, loss: 0.575491
 >> iter 30000, loss: 0.545247
   Number of active neurons: 6
 >> iter 31000, loss: 0.469163
 >> iter 32000, loss: 0.380744
 >> iter 33000, loss: 0.343545
 >> iter 34000, loss: 0.575972
 >> iter 35000, loss: 0.714338
 >> iter 36000, loss: 0.502811
 >> iter 37000, loss: 0.436181
 >> iter 38000, loss: 0.490415
 >> iter 39000, loss: 0.509358
 >> iter 40000, loss: 0.488589
   Number of active neurons: 6
 >> iter 41000, loss: 0.569918
 >> iter 42000, loss: 0.473788
 >> iter 43000, loss: 0.683439
 >> iter 44000, loss: 0.536562
 >> iter 45000, loss: 0.432780
 >> iter 46000, loss: 0.501875
 >> iter 47000, loss: 0.466535
 >> iter 48000, loss: 0.459500
 >> iter 49000, loss: 0.542208
 >> iter 50000, loss: 0.568277
   Number of active neurons: 6
 >> iter 51000, loss: 0.533095
 >> iter 52000, loss: 0.382540
 >> iter 53000, loss: 0.384106
 >> iter 54000, loss: 0.501310
 >> iter 55000, loss: 0.623104
 >> iter 56000, loss: 0.532600
 >> iter 57000, loss: 0.482164
 >> iter 58000, loss: 0.797675
 >> iter 59000, loss: 0.582667
 >> iter 60000, loss: 0.485432
   Number of active neurons: 6
 >> iter 61000, loss: 0.612112
 >> iter 62000, loss: 0.557595
 >> iter 63000, loss: 0.613612
 >> iter 64000, loss: 0.495644
 >> iter 65000, loss: 0.483533
 >> iter 66000, loss: 0.479991
 >> iter 67000, loss: 0.453390
 >> iter 68000, loss: 0.509687
 >> iter 69000, loss: 0.528880
 >> iter 70000, loss: 0.419315
   Number of active neurons: 6
 >> iter 71000, loss: 0.405416
 >> iter 72000, loss: 0.619623
 >> iter 73000, loss: 0.532335
 >> iter 74000, loss: 0.462748
 >> iter 75000, loss: 0.570833
 >> iter 76000, loss: 0.426657
 >> iter 77000, loss: 0.672725
 >> iter 78000, loss: 0.523095
 >> iter 79000, loss: 0.423242
 >> iter 80000, loss: 0.501621
   Number of active neurons: 6
 >> iter 81000, loss: 0.603772
 >> iter 82000, loss: 0.430670
 >> iter 83000, loss: 0.424330
 >> iter 84000, loss: 0.364416
 >> iter 85000, loss: 0.466029
 >> iter 86000, loss: 0.434688
 >> iter 87000, loss: 0.540664
 >> iter 88000, loss: 0.536386
 >> iter 89000, loss: 0.709681
 >> iter 90000, loss: 0.644425
   Number of active neurons: 6
 >> iter 91000, loss: 0.537066
 >> iter 92000, loss: 0.420388
 >> iter 93000, loss: 0.505173
 >> iter 94000, loss: 0.612521
 >> iter 95000, loss: 0.786005
 >> iter 96000, loss: 0.756010
 >> iter 97000, loss: 0.595247
 >> iter 98000, loss: 0.613509
 >> iter 99000, loss: 0.701710
 >> iter 100000, loss: 0.717448
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.120293
 >> iter 2000, loss: 10.615904
 >> iter 3000, loss: 7.743084
 >> iter 4000, loss: 5.284888
 >> iter 5000, loss: 3.208197
 >> iter 6000, loss: 2.076619
 >> iter 7000, loss: 1.501326
 >> iter 8000, loss: 1.147600
 >> iter 9000, loss: 0.993341
 >> iter 10000, loss: 0.858662
   Number of active neurons: 6
 >> iter 11000, loss: 0.758387
 >> iter 12000, loss: 0.597343
 >> iter 13000, loss: 0.569586
 >> iter 14000, loss: 0.695617
 >> iter 15000, loss: 0.637830
 >> iter 16000, loss: 0.402440
 >> iter 17000, loss: 0.570010
 >> iter 18000, loss: 0.577338
 >> iter 19000, loss: 0.540191
 >> iter 20000, loss: 0.499190
   Number of active neurons: 6
 >> iter 21000, loss: 0.451146
 >> iter 22000, loss: 0.469987
 >> iter 23000, loss: 0.405648
 >> iter 24000, loss: 0.352425
 >> iter 25000, loss: 0.437792
 >> iter 26000, loss: 0.447817
 >> iter 27000, loss: 0.371465
 >> iter 28000, loss: 0.422260
 >> iter 29000, loss: 0.329508
 >> iter 30000, loss: 0.489326
   Number of active neurons: 6
 >> iter 31000, loss: 0.427345
 >> iter 32000, loss: 0.476784
 >> iter 33000, loss: 0.446232
 >> iter 34000, loss: 0.500860
 >> iter 35000, loss: 0.558166
 >> iter 36000, loss: 0.518297
 >> iter 37000, loss: 0.529721
 >> iter 38000, loss: 0.578391
 >> iter 39000, loss: 0.453651
 >> iter 40000, loss: 0.459734
   Number of active neurons: 7
 >> iter 41000, loss: 0.414889
 >> iter 42000, loss: 0.474207
 >> iter 43000, loss: 0.555833
 >> iter 44000, loss: 0.426752
 >> iter 45000, loss: 0.371102
 >> iter 46000, loss: 0.425627
 >> iter 47000, loss: 0.538386
 >> iter 48000, loss: 0.474641
 >> iter 49000, loss: 0.498149
 >> iter 50000, loss: 0.390285
   Number of active neurons: 6
 >> iter 51000, loss: 0.553991
 >> iter 52000, loss: 0.447187
 >> iter 53000, loss: 0.488210
 >> iter 54000, loss: 0.485270
 >> iter 55000, loss: 0.452838
 >> iter 56000, loss: 0.478423
 >> iter 57000, loss: 0.496700
 >> iter 58000, loss: 0.420420
 >> iter 59000, loss: 0.502480
 >> iter 60000, loss: 0.491780
   Number of active neurons: 5
 >> iter 61000, loss: 0.342908
 >> iter 62000, loss: 0.314151
 >> iter 63000, loss: 0.337324
 >> iter 64000, loss: 0.379851
 >> iter 65000, loss: 0.455417
 >> iter 66000, loss: 0.392510
 >> iter 67000, loss: 0.484836
 >> iter 68000, loss: 0.412731
 >> iter 69000, loss: 0.444297
 >> iter 70000, loss: 0.407317
   Number of active neurons: 4
 >> iter 71000, loss: 0.480985
 >> iter 72000, loss: 0.548104
 >> iter 73000, loss: 0.337224
 >> iter 74000, loss: 0.372109
 >> iter 75000, loss: 0.459424
 >> iter 76000, loss: 0.527830
 >> iter 77000, loss: 0.411541
 >> iter 78000, loss: 0.561736
 >> iter 79000, loss: 0.486205
 >> iter 80000, loss: 0.379006
   Number of active neurons: 4
 >> iter 81000, loss: 0.492216
 >> iter 82000, loss: 0.512168
 >> iter 83000, loss: 0.527877
 >> iter 84000, loss: 0.425715
 >> iter 85000, loss: 0.394282
 >> iter 86000, loss: 0.399855
 >> iter 87000, loss: 0.536648
 >> iter 88000, loss: 0.534907
 >> iter 89000, loss: 0.492490
 >> iter 90000, loss: 0.348523
   Number of active neurons: 4
 >> iter 91000, loss: 0.396189
 >> iter 92000, loss: 0.299991
 >> iter 93000, loss: 0.273497
 >> iter 94000, loss: 0.385744
 >> iter 95000, loss: 0.475618
 >> iter 96000, loss: 0.480985
 >> iter 97000, loss: 0.438148
 >> iter 98000, loss: 0.394884
 >> iter 99000, loss: 0.420280
 >> iter 100000, loss: 0.369429
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 17.200818
 >> iter 2000, loss: 10.116665
 >> iter 3000, loss: 6.093719
 >> iter 4000, loss: 3.509072
 >> iter 5000, loss: 2.119811
 >> iter 6000, loss: 1.400043
 >> iter 7000, loss: 0.936111
 >> iter 8000, loss: 0.726045
 >> iter 9000, loss: 0.915941
 >> iter 10000, loss: 0.677607
   Number of active neurons: 6
 >> iter 11000, loss: 0.477679
 >> iter 12000, loss: 0.493885
 >> iter 13000, loss: 0.490302
 >> iter 14000, loss: 0.378064
 >> iter 15000, loss: 0.296479
 >> iter 16000, loss: 0.294603
 >> iter 17000, loss: 0.363081
 >> iter 18000, loss: 0.506459
 >> iter 19000, loss: 0.477716
 >> iter 20000, loss: 0.466100
   Number of active neurons: 6
 >> iter 21000, loss: 0.520684
 >> iter 22000, loss: 0.523176
 >> iter 23000, loss: 0.437906
 >> iter 24000, loss: 0.412473
 >> iter 25000, loss: 0.584226
 >> iter 26000, loss: 0.423953
 >> iter 27000, loss: 0.401265
 >> iter 28000, loss: 0.473899
 >> iter 29000, loss: 0.308038
 >> iter 30000, loss: 0.391693
   Number of active neurons: 5
 >> iter 31000, loss: 0.450244
 >> iter 32000, loss: 0.435536
 >> iter 33000, loss: 0.542792
 >> iter 34000, loss: 0.390523
 >> iter 35000, loss: 0.450985
 >> iter 36000, loss: 0.454667
 >> iter 37000, loss: 0.310524
 >> iter 38000, loss: 0.384815
 >> iter 39000, loss: 0.396975
 >> iter 40000, loss: 0.475379
   Number of active neurons: 5
 >> iter 41000, loss: 0.439834
 >> iter 42000, loss: 0.548830
 >> iter 43000, loss: 0.549372
 >> iter 44000, loss: 0.493954
 >> iter 45000, loss: 0.470217
 >> iter 46000, loss: 0.330651
 >> iter 47000, loss: 0.538733
 >> iter 48000, loss: 0.386493
 >> iter 49000, loss: 0.423118
 >> iter 50000, loss: 0.580853
   Number of active neurons: 5
 >> iter 51000, loss: 0.517359
 >> iter 52000, loss: 0.482331
 >> iter 53000, loss: 0.396762
 >> iter 54000, loss: 0.356969
 >> iter 55000, loss: 0.532044
 >> iter 56000, loss: 0.530197
 >> iter 57000, loss: 0.409218
 >> iter 58000, loss: 0.393542
 >> iter 59000, loss: 0.281511
 >> iter 60000, loss: 0.459643
   Number of active neurons: 5
 >> iter 61000, loss: 0.506319
 >> iter 62000, loss: 0.463135
 >> iter 63000, loss: 0.502230
 >> iter 64000, loss: 0.404754
 >> iter 65000, loss: 0.298396
 >> iter 66000, loss: 0.406838
 >> iter 67000, loss: 0.485526
 >> iter 68000, loss: 0.499703
 >> iter 69000, loss: 0.458257
 >> iter 70000, loss: 0.432267
   Number of active neurons: 5
 >> iter 71000, loss: 0.449653
 >> iter 72000, loss: 0.451605
 >> iter 73000, loss: 0.623329
 >> iter 74000, loss: 0.519374
 >> iter 75000, loss: 0.568142
 >> iter 76000, loss: 0.558111
 >> iter 77000, loss: 0.397249
 >> iter 78000, loss: 0.492031
 >> iter 79000, loss: 0.522691
 >> iter 80000, loss: 0.596596
   Number of active neurons: 5
 >> iter 81000, loss: 0.467574
 >> iter 82000, loss: 0.470668
 >> iter 83000, loss: 0.473568
 >> iter 84000, loss: 0.361668
 >> iter 85000, loss: 0.468518
 >> iter 86000, loss: 0.527615
 >> iter 87000, loss: 0.598398
 >> iter 88000, loss: 0.643389
 >> iter 89000, loss: 0.577455
 >> iter 90000, loss: 0.483818
   Number of active neurons: 5
 >> iter 91000, loss: 0.494118
 >> iter 92000, loss: 0.430394
 >> iter 93000, loss: 0.515858
 >> iter 94000, loss: 0.770233
 >> iter 95000, loss: 0.611951
 >> iter 96000, loss: 0.586340
 >> iter 97000, loss: 0.477488
 >> iter 98000, loss: 0.695631
 >> iter 99000, loss: 0.619769
 >> iter 100000, loss: 0.580566
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.285408
 >> iter 2000, loss: 10.131204
 >> iter 3000, loss: 5.502905
 >> iter 4000, loss: 2.990832
 >> iter 5000, loss: 1.772082
 >> iter 6000, loss: 1.327995
 >> iter 7000, loss: 1.000986
 >> iter 8000, loss: 0.815382
 >> iter 9000, loss: 0.946141
 >> iter 10000, loss: 0.706851
   Number of active neurons: 4
 >> iter 11000, loss: 0.785722
 >> iter 12000, loss: 0.664501
 >> iter 13000, loss: 0.609163
 >> iter 14000, loss: 0.564153
 >> iter 15000, loss: 0.572951
 >> iter 16000, loss: 0.735393
 >> iter 17000, loss: 0.818935
 >> iter 18000, loss: 0.807961
 >> iter 19000, loss: 0.698521
 >> iter 20000, loss: 0.614859
   Number of active neurons: 4
 >> iter 21000, loss: 0.578530
 >> iter 22000, loss: 0.426477
 >> iter 23000, loss: 0.435550
 >> iter 24000, loss: 0.459234
 >> iter 25000, loss: 0.485918
 >> iter 26000, loss: 0.538886
 >> iter 27000, loss: 0.729237
 >> iter 28000, loss: 0.730803
 >> iter 29000, loss: 0.499279
 >> iter 30000, loss: 0.523557
   Number of active neurons: 4
 >> iter 31000, loss: 0.660171
 >> iter 32000, loss: 0.657131
 >> iter 33000, loss: 0.845152
 >> iter 34000, loss: 0.982875
 >> iter 35000, loss: 0.728206
 >> iter 36000, loss: 0.649888
 >> iter 37000, loss: 0.551449
 >> iter 38000, loss: 0.719447
 >> iter 39000, loss: 0.563971
 >> iter 40000, loss: 0.471373
   Number of active neurons: 4
 >> iter 41000, loss: 0.471394
 >> iter 42000, loss: 0.478744
 >> iter 43000, loss: 0.449479
 >> iter 44000, loss: 0.435577
 >> iter 45000, loss: 0.522948
 >> iter 46000, loss: 0.602169
 >> iter 47000, loss: 0.601555
 >> iter 48000, loss: 0.506581
 >> iter 49000, loss: 0.484841
 >> iter 50000, loss: 0.395745
   Number of active neurons: 4
 >> iter 51000, loss: 0.546908
 >> iter 52000, loss: 0.508194
 >> iter 53000, loss: 0.500706
 >> iter 54000, loss: 0.440034
 >> iter 55000, loss: 0.359682
 >> iter 56000, loss: 0.390696
 >> iter 57000, loss: 0.569323
 >> iter 58000, loss: 0.465080
 >> iter 59000, loss: 0.520136
 >> iter 60000, loss: 0.491324
   Number of active neurons: 4
 >> iter 61000, loss: 0.628644
 >> iter 62000, loss: 0.653228
 >> iter 63000, loss: 0.507404
 >> iter 64000, loss: 0.463985
 >> iter 65000, loss: 0.440159
 >> iter 66000, loss: 0.505919
 >> iter 67000, loss: 0.588378
 >> iter 68000, loss: 0.462628
 >> iter 69000, loss: 0.499204
 >> iter 70000, loss: 0.431701
   Number of active neurons: 4
 >> iter 71000, loss: 0.459164
 >> iter 72000, loss: 0.355456
 >> iter 73000, loss: 0.573776
 >> iter 74000, loss: 0.468754
 >> iter 75000, loss: 0.512580
 >> iter 76000, loss: 0.639732
 >> iter 77000, loss: 0.603071
 >> iter 78000, loss: 0.587099
 >> iter 79000, loss: 0.578785
 >> iter 80000, loss: 0.553387
   Number of active neurons: 4
 >> iter 81000, loss: 0.665614
 >> iter 82000, loss: 0.530107
 >> iter 83000, loss: 0.475535
 >> iter 84000, loss: 0.546545
 >> iter 85000, loss: 0.559132
 >> iter 86000, loss: 0.651587
 >> iter 87000, loss: 0.502949
 >> iter 88000, loss: 0.452750
 >> iter 89000, loss: 0.426773
 >> iter 90000, loss: 0.416213
   Number of active neurons: 4
 >> iter 91000, loss: 0.375768
 >> iter 92000, loss: 0.405376
 >> iter 93000, loss: 0.461167
 >> iter 94000, loss: 0.376582
 >> iter 95000, loss: 0.569451
 >> iter 96000, loss: 0.546817
 >> iter 97000, loss: 0.413240
 >> iter 98000, loss: 0.447885
 >> iter 99000, loss: 0.489978
 >> iter 100000, loss: 0.402708
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.032650
 >> iter 2000, loss: 11.068580
 >> iter 3000, loss: 8.602704
 >> iter 4000, loss: 6.920067
 >> iter 5000, loss: 4.313213
 >> iter 6000, loss: 2.314638
 >> iter 7000, loss: 1.484299
 >> iter 8000, loss: 0.970710
 >> iter 9000, loss: 0.829603
 >> iter 10000, loss: 0.546019
   Number of active neurons: 5
 >> iter 11000, loss: 0.652910
 >> iter 12000, loss: 0.504122
 >> iter 13000, loss: 0.549943
 >> iter 14000, loss: 0.423226
 >> iter 15000, loss: 0.345220
 >> iter 16000, loss: 0.412505
 >> iter 17000, loss: 0.364506
 >> iter 18000, loss: 0.383324
 >> iter 19000, loss: 0.338553
 >> iter 20000, loss: 0.344279
   Number of active neurons: 6
 >> iter 21000, loss: 0.302407
 >> iter 22000, loss: 0.298184
 >> iter 23000, loss: 0.352811
 >> iter 24000, loss: 0.352390
 >> iter 25000, loss: 0.296366
 >> iter 26000, loss: 0.359361
 >> iter 27000, loss: 0.461422
 >> iter 28000, loss: 0.400227
 >> iter 29000, loss: 0.336581
 >> iter 30000, loss: 0.286225
   Number of active neurons: 5
 >> iter 31000, loss: 0.317000
 >> iter 32000, loss: 0.296447
 >> iter 33000, loss: 0.347188
 >> iter 34000, loss: 0.340500
 >> iter 35000, loss: 0.460344
 >> iter 36000, loss: 0.425119
 >> iter 37000, loss: 0.395340
 >> iter 38000, loss: 0.308513
 >> iter 39000, loss: 0.287587
 >> iter 40000, loss: 0.345280
   Number of active neurons: 5
 >> iter 41000, loss: 0.344889
 >> iter 42000, loss: 0.314233
 >> iter 43000, loss: 0.324552
 >> iter 44000, loss: 0.291393
 >> iter 45000, loss: 0.222071
 >> iter 46000, loss: 0.287305
 >> iter 47000, loss: 0.276384
 >> iter 48000, loss: 0.320050
 >> iter 49000, loss: 0.234490
 >> iter 50000, loss: 0.317132
   Number of active neurons: 5
 >> iter 51000, loss: 0.327682
 >> iter 52000, loss: 0.264340
 >> iter 53000, loss: 0.267178
 >> iter 54000, loss: 0.298695
 >> iter 55000, loss: 0.415256
 >> iter 56000, loss: 0.393236
 >> iter 57000, loss: 0.408106
 >> iter 58000, loss: 0.377083
 >> iter 59000, loss: 0.321946
 >> iter 60000, loss: 0.448542
   Number of active neurons: 5
 >> iter 61000, loss: 0.369622
 >> iter 62000, loss: 0.433495
 >> iter 63000, loss: 0.312850
 >> iter 64000, loss: 0.313211
 >> iter 65000, loss: 0.347249
 >> iter 66000, loss: 0.312634
 >> iter 67000, loss: 0.530919
 >> iter 68000, loss: 0.357003
 >> iter 69000, loss: 0.345268
 >> iter 70000, loss: 0.397207
   Number of active neurons: 5
 >> iter 71000, loss: 0.416942
 >> iter 72000, loss: 0.401923
 >> iter 73000, loss: 0.259871
 >> iter 74000, loss: 0.240397
 >> iter 75000, loss: 0.394292
 >> iter 76000, loss: 0.346454
 >> iter 77000, loss: 0.341951
 >> iter 78000, loss: 0.347177
 >> iter 79000, loss: 0.411811
 >> iter 80000, loss: 0.367962
   Number of active neurons: 5
 >> iter 81000, loss: 0.383532
 >> iter 82000, loss: 0.309814
 >> iter 83000, loss: 0.337902
 >> iter 84000, loss: 0.343228
 >> iter 85000, loss: 0.334434
 >> iter 86000, loss: 0.338591
 >> iter 87000, loss: 0.486407
 >> iter 88000, loss: 0.407586
 >> iter 89000, loss: 0.338017
 >> iter 90000, loss: 0.388635
   Number of active neurons: 5
 >> iter 91000, loss: 0.413609
 >> iter 92000, loss: 0.412318
 >> iter 93000, loss: 0.505389
 >> iter 94000, loss: 0.402506
 >> iter 95000, loss: 0.452259
 >> iter 96000, loss: 0.377346
 >> iter 97000, loss: 0.384486
 >> iter 98000, loss: 0.365791
 >> iter 99000, loss: 0.387488
 >> iter 100000, loss: 0.378456
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.192874
 >> iter 2000, loss: 10.030339
 >> iter 3000, loss: 5.997460
 >> iter 4000, loss: 3.099409
 >> iter 5000, loss: 1.670367
 >> iter 6000, loss: 1.109820
 >> iter 7000, loss: 0.769494
 >> iter 8000, loss: 0.697847
 >> iter 9000, loss: 0.462324
 >> iter 10000, loss: 0.444253
   Number of active neurons: 8
 >> iter 11000, loss: 0.321827
 >> iter 12000, loss: 0.293945
 >> iter 13000, loss: 0.289587
 >> iter 14000, loss: 0.252837
 >> iter 15000, loss: 0.351767
 >> iter 16000, loss: 0.336620
 >> iter 17000, loss: 0.239816
 >> iter 18000, loss: 0.304600
 >> iter 19000, loss: 0.322823
 >> iter 20000, loss: 0.276882
   Number of active neurons: 8
 >> iter 21000, loss: 0.248088
 >> iter 22000, loss: 0.416046
 >> iter 23000, loss: 0.364028
 >> iter 24000, loss: 0.384052
 >> iter 25000, loss: 0.281861
 >> iter 26000, loss: 0.302012
 >> iter 27000, loss: 0.370061
 >> iter 28000, loss: 0.492252
 >> iter 29000, loss: 0.445455
 >> iter 30000, loss: 0.364602
   Number of active neurons: 7
 >> iter 31000, loss: 0.354468
 >> iter 32000, loss: 0.355299
 >> iter 33000, loss: 0.437181
 >> iter 34000, loss: 0.322214
 >> iter 35000, loss: 0.363873
 >> iter 36000, loss: 0.275029
 >> iter 37000, loss: 0.404862
 >> iter 38000, loss: 0.364897
 >> iter 39000, loss: 0.503804
 >> iter 40000, loss: 0.399863
   Number of active neurons: 6
 >> iter 41000, loss: 0.372250
 >> iter 42000, loss: 0.451074
 >> iter 43000, loss: 0.362479
 >> iter 44000, loss: 0.411464
 >> iter 45000, loss: 0.306629
 >> iter 46000, loss: 0.329122
 >> iter 47000, loss: 0.304760
 >> iter 48000, loss: 0.434577
 >> iter 49000, loss: 0.344547
 >> iter 50000, loss: 0.314772
   Number of active neurons: 6
 >> iter 51000, loss: 0.312473
 >> iter 52000, loss: 0.414150
 >> iter 53000, loss: 0.385717
 >> iter 54000, loss: 0.471506
 >> iter 55000, loss: 0.401371
 >> iter 56000, loss: 0.325444
 >> iter 57000, loss: 0.360559
 >> iter 58000, loss: 0.419886
 >> iter 59000, loss: 0.458843
 >> iter 60000, loss: 0.426985
   Number of active neurons: 6
 >> iter 61000, loss: 0.421792
 >> iter 62000, loss: 0.499832
 >> iter 63000, loss: 0.430395
 >> iter 64000, loss: 0.294155
 >> iter 65000, loss: 0.368149
 >> iter 66000, loss: 0.315877
 >> iter 67000, loss: 0.344025
 >> iter 68000, loss: 0.412171
 >> iter 69000, loss: 0.335621
 >> iter 70000, loss: 0.309201
   Number of active neurons: 6
 >> iter 71000, loss: 0.309260
 >> iter 72000, loss: 0.274203
 >> iter 73000, loss: 0.310902
 >> iter 74000, loss: 0.393281
 >> iter 75000, loss: 0.425177
 >> iter 76000, loss: 0.295904
 >> iter 77000, loss: 0.436283
 >> iter 78000, loss: 0.357158
 >> iter 79000, loss: 0.388389
 >> iter 80000, loss: 0.292101
   Number of active neurons: 6
 >> iter 81000, loss: 0.289810
 >> iter 82000, loss: 0.246097
 >> iter 83000, loss: 0.337773
 >> iter 84000, loss: 0.447641
 >> iter 85000, loss: 0.372992
 >> iter 86000, loss: 0.352470
 >> iter 87000, loss: 0.266781
 >> iter 88000, loss: 0.386662
 >> iter 89000, loss: 0.373996
 >> iter 90000, loss: 0.283779
   Number of active neurons: 6
 >> iter 91000, loss: 0.358010
 >> iter 92000, loss: 0.410754
 >> iter 93000, loss: 0.349962
 >> iter 94000, loss: 0.321871
 >> iter 95000, loss: 0.274757
 >> iter 96000, loss: 0.256905
 >> iter 97000, loss: 0.307331
 >> iter 98000, loss: 0.263563
 >> iter 99000, loss: 0.249586
 >> iter 100000, loss: 0.320592
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.781114
 >> iter 2000, loss: 10.827553
 >> iter 3000, loss: 6.918766
 >> iter 4000, loss: 4.227786
 >> iter 5000, loss: 2.740183
 >> iter 6000, loss: 1.860578
 >> iter 7000, loss: 1.695012
 >> iter 8000, loss: 1.226168
 >> iter 9000, loss: 0.952602
 >> iter 10000, loss: 0.824978
   Number of active neurons: 6
 >> iter 11000, loss: 0.824103
 >> iter 12000, loss: 0.614412
 >> iter 13000, loss: 0.695127
 >> iter 14000, loss: 0.705238
 >> iter 15000, loss: 0.738905
 >> iter 16000, loss: 0.678773
 >> iter 17000, loss: 0.516979
 >> iter 18000, loss: 0.399289
 >> iter 19000, loss: 0.421624
 >> iter 20000, loss: 0.436672
   Number of active neurons: 6
 >> iter 21000, loss: 0.548814
 >> iter 22000, loss: 0.457899
 >> iter 23000, loss: 0.345999
 >> iter 24000, loss: 0.352126
 >> iter 25000, loss: 0.470916
 >> iter 26000, loss: 0.371433
 >> iter 27000, loss: 0.411353
 >> iter 28000, loss: 0.564863
 >> iter 29000, loss: 0.427533
 >> iter 30000, loss: 0.287668
   Number of active neurons: 5
 >> iter 31000, loss: 0.379339
 >> iter 32000, loss: 0.394174
 >> iter 33000, loss: 0.445477
 >> iter 34000, loss: 0.416528
 >> iter 35000, loss: 0.479555
 >> iter 36000, loss: 0.411344
 >> iter 37000, loss: 0.420811
 >> iter 38000, loss: 0.293806
 >> iter 39000, loss: 0.391758
 >> iter 40000, loss: 0.461486
   Number of active neurons: 5
 >> iter 41000, loss: 0.552705
 >> iter 42000, loss: 0.528575
 >> iter 43000, loss: 0.464372
 >> iter 44000, loss: 0.446190
 >> iter 45000, loss: 0.454762
 >> iter 46000, loss: 0.449900
 >> iter 47000, loss: 0.587065
 >> iter 48000, loss: 0.494806
 >> iter 49000, loss: 0.540444
 >> iter 50000, loss: 0.567442
   Number of active neurons: 5
 >> iter 51000, loss: 0.562988
 >> iter 52000, loss: 0.505882
 >> iter 53000, loss: 0.478283
 >> iter 54000, loss: 0.573311
 >> iter 55000, loss: 0.548815
 >> iter 56000, loss: 0.525118
 >> iter 57000, loss: 0.531498
 >> iter 58000, loss: 0.619256
 >> iter 59000, loss: 0.486802
 >> iter 60000, loss: 0.453201
   Number of active neurons: 5
 >> iter 61000, loss: 0.524909
 >> iter 62000, loss: 0.546739
 >> iter 63000, loss: 0.532931
 >> iter 64000, loss: 0.379984
 >> iter 65000, loss: 0.487693
 >> iter 66000, loss: 0.633728
 >> iter 67000, loss: 0.599869
 >> iter 68000, loss: 0.438612
 >> iter 69000, loss: 0.454140
 >> iter 70000, loss: 0.402276
   Number of active neurons: 5
 >> iter 71000, loss: 0.513609
 >> iter 72000, loss: 0.769443
 >> iter 73000, loss: 0.784929
 >> iter 74000, loss: 0.619007
 >> iter 75000, loss: 0.630337
 >> iter 76000, loss: 0.739456
 >> iter 77000, loss: 0.530638
 >> iter 78000, loss: 0.524674
 >> iter 79000, loss: 0.441826
 >> iter 80000, loss: 0.457710
   Number of active neurons: 5
 >> iter 81000, loss: 0.337103
 >> iter 82000, loss: 0.476966
 >> iter 83000, loss: 0.459920
 >> iter 84000, loss: 0.518917
 >> iter 85000, loss: 0.461868
 >> iter 86000, loss: 0.620308
 >> iter 87000, loss: 0.587963
 >> iter 88000, loss: 0.650028
 >> iter 89000, loss: 0.643612
 >> iter 90000, loss: 0.611801
   Number of active neurons: 5
 >> iter 91000, loss: 0.703855
 >> iter 92000, loss: 0.559560
 >> iter 93000, loss: 0.565925
 >> iter 94000, loss: 0.525108
 >> iter 95000, loss: 0.478024
 >> iter 96000, loss: 0.578584
 >> iter 97000, loss: 0.712294
 >> iter 98000, loss: 0.743900
 >> iter 99000, loss: 0.598230
 >> iter 100000, loss: 0.480777
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.491275
 >> iter 2000, loss: 10.048441
 >> iter 3000, loss: 5.396763
 >> iter 4000, loss: 2.896280
 >> iter 5000, loss: 1.411681
 >> iter 6000, loss: 0.961527
 >> iter 7000, loss: 0.763654
 >> iter 8000, loss: 0.658536
 >> iter 9000, loss: 0.570993
 >> iter 10000, loss: 0.606750
   Number of active neurons: 5
 >> iter 11000, loss: 0.520156
 >> iter 12000, loss: 0.412994
 >> iter 13000, loss: 0.363007
 >> iter 14000, loss: 0.384220
 >> iter 15000, loss: 0.436107
 >> iter 16000, loss: 0.440267
 >> iter 17000, loss: 0.421011
 >> iter 18000, loss: 0.556339
 >> iter 19000, loss: 0.666786
 >> iter 20000, loss: 0.483810
   Number of active neurons: 5
 >> iter 21000, loss: 0.610558
 >> iter 22000, loss: 0.427523
 >> iter 23000, loss: 0.425728
 >> iter 24000, loss: 0.486117
 >> iter 25000, loss: 0.428618
 >> iter 26000, loss: 0.354767
 >> iter 27000, loss: 0.393700
 >> iter 28000, loss: 0.438821
 >> iter 29000, loss: 0.508360
 >> iter 30000, loss: 0.348144
   Number of active neurons: 5
 >> iter 31000, loss: 0.357009
 >> iter 32000, loss: 0.477983
 >> iter 33000, loss: 0.425319
 >> iter 34000, loss: 0.348518
 >> iter 35000, loss: 0.464700
 >> iter 36000, loss: 0.494994
 >> iter 37000, loss: 0.448751
 >> iter 38000, loss: 0.544734
 >> iter 39000, loss: 0.512049
 >> iter 40000, loss: 0.431817
   Number of active neurons: 5
 >> iter 41000, loss: 0.419046
 >> iter 42000, loss: 0.681324
 >> iter 43000, loss: 0.757945
 >> iter 44000, loss: 0.778176
 >> iter 45000, loss: 0.651726
 >> iter 46000, loss: 0.556993
 >> iter 47000, loss: 0.482064
 >> iter 48000, loss: 0.513677
 >> iter 49000, loss: 0.488554
 >> iter 50000, loss: 0.465674
   Number of active neurons: 5
 >> iter 51000, loss: 0.395096
 >> iter 52000, loss: 0.600590
 >> iter 53000, loss: 0.410707
 >> iter 54000, loss: 0.404909
 >> iter 55000, loss: 0.423881
 >> iter 56000, loss: 0.464537
 >> iter 57000, loss: 0.394112
 >> iter 58000, loss: 0.423639
 >> iter 59000, loss: 0.369497
 >> iter 60000, loss: 0.461933
   Number of active neurons: 5
 >> iter 61000, loss: 0.393684
 >> iter 62000, loss: 0.411001
 >> iter 63000, loss: 0.551050
 >> iter 64000, loss: 0.409250
 >> iter 65000, loss: 0.421175
 >> iter 66000, loss: 0.401456
 >> iter 67000, loss: 0.497256
 >> iter 68000, loss: 0.564011
 >> iter 69000, loss: 0.528030
 >> iter 70000, loss: 0.697077
   Number of active neurons: 5
 >> iter 71000, loss: 0.547814
 >> iter 72000, loss: 0.408189
 >> iter 73000, loss: 0.510660
 >> iter 74000, loss: 0.558475
 >> iter 75000, loss: 0.421334
 >> iter 76000, loss: 0.498350
 >> iter 77000, loss: 0.443194
 >> iter 78000, loss: 0.468185
 >> iter 79000, loss: 0.559436
 >> iter 80000, loss: 0.601678
   Number of active neurons: 5
 >> iter 81000, loss: 0.563992
 >> iter 82000, loss: 0.427183
 >> iter 83000, loss: 0.485494
 >> iter 84000, loss: 0.420780
 >> iter 85000, loss: 0.359766
 >> iter 86000, loss: 0.333732
 >> iter 87000, loss: 0.399686
 >> iter 88000, loss: 0.442978
 >> iter 89000, loss: 0.403625
 >> iter 90000, loss: 0.404198
   Number of active neurons: 5
 >> iter 91000, loss: 0.392765
 >> iter 92000, loss: 0.687256
 >> iter 93000, loss: 0.472190
 >> iter 94000, loss: 0.482866
 >> iter 95000, loss: 0.568157
 >> iter 96000, loss: 0.510787
 >> iter 97000, loss: 0.428648
 >> iter 98000, loss: 0.375918
 >> iter 99000, loss: 0.364694
 >> iter 100000, loss: 0.301345
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.144519
 >> iter 2000, loss: 11.563406
 >> iter 3000, loss: 6.310336
 >> iter 4000, loss: 2.930255
 >> iter 5000, loss: 1.525508
 >> iter 6000, loss: 0.876411
 >> iter 7000, loss: 0.643601
 >> iter 8000, loss: 0.463134
 >> iter 9000, loss: 0.394578
 >> iter 10000, loss: 0.360821
   Number of active neurons: 6
 >> iter 11000, loss: 0.252639
 >> iter 12000, loss: 0.367710
 >> iter 13000, loss: 0.305266
 >> iter 14000, loss: 0.238050
 >> iter 15000, loss: 0.206632
 >> iter 16000, loss: 0.311396
 >> iter 17000, loss: 0.381574
 >> iter 18000, loss: 0.252355
 >> iter 19000, loss: 0.299235
 >> iter 20000, loss: 0.363474
   Number of active neurons: 6
 >> iter 21000, loss: 0.276086
 >> iter 22000, loss: 0.332387
 >> iter 23000, loss: 0.337586
 >> iter 24000, loss: 0.254324
 >> iter 25000, loss: 0.299859
 >> iter 26000, loss: 0.382487
 >> iter 27000, loss: 0.401153
 >> iter 28000, loss: 0.372058
 >> iter 29000, loss: 0.327028
 >> iter 30000, loss: 0.237678
   Number of active neurons: 5
 >> iter 31000, loss: 0.198715
 >> iter 32000, loss: 0.300514
 >> iter 33000, loss: 0.289857
 >> iter 34000, loss: 0.262034
 >> iter 35000, loss: 0.245447
 >> iter 36000, loss: 0.257407
 >> iter 37000, loss: 0.220109
 >> iter 38000, loss: 0.209456
 >> iter 39000, loss: 0.318778
 >> iter 40000, loss: 0.312946
   Number of active neurons: 5
 >> iter 41000, loss: 0.258766
 >> iter 42000, loss: 0.337576
 >> iter 43000, loss: 0.297501
 >> iter 44000, loss: 0.379485
 >> iter 45000, loss: 0.285275
 >> iter 46000, loss: 0.235849
 >> iter 47000, loss: 0.318636
 >> iter 48000, loss: 0.323818
 >> iter 49000, loss: 0.339026
 >> iter 50000, loss: 0.233430
   Number of active neurons: 5
 >> iter 51000, loss: 0.447819
 >> iter 52000, loss: 0.344850
 >> iter 53000, loss: 0.285930
 >> iter 54000, loss: 0.227271
 >> iter 55000, loss: 0.292129
 >> iter 56000, loss: 0.236694
 >> iter 57000, loss: 0.196920
 >> iter 58000, loss: 0.350810
 >> iter 59000, loss: 0.291078
 >> iter 60000, loss: 0.335904
   Number of active neurons: 5
 >> iter 61000, loss: 0.274203
 >> iter 62000, loss: 0.231882
 >> iter 63000, loss: 0.229030
 >> iter 64000, loss: 0.296715
 >> iter 65000, loss: 0.391900
 >> iter 66000, loss: 0.346274
 >> iter 67000, loss: 0.228873
 >> iter 68000, loss: 0.251205
 >> iter 69000, loss: 0.218855
 >> iter 70000, loss: 0.202481
   Number of active neurons: 5
 >> iter 71000, loss: 0.247098
 >> iter 72000, loss: 0.210646
 >> iter 73000, loss: 0.277461
 >> iter 74000, loss: 0.346751
 >> iter 75000, loss: 0.255346
 >> iter 76000, loss: 0.285620
 >> iter 77000, loss: 0.367995
 >> iter 78000, loss: 0.413091
 >> iter 79000, loss: 0.362787
 >> iter 80000, loss: 0.310373
   Number of active neurons: 5
 >> iter 81000, loss: 0.337892
 >> iter 82000, loss: 0.335582
 >> iter 83000, loss: 0.242776
 >> iter 84000, loss: 0.180991
 >> iter 85000, loss: 0.241704
 >> iter 86000, loss: 0.230896
 >> iter 87000, loss: 0.206711
 >> iter 88000, loss: 0.216151
 >> iter 89000, loss: 0.268143
 >> iter 90000, loss: 0.262365
   Number of active neurons: 5
 >> iter 91000, loss: 0.237364
 >> iter 92000, loss: 0.281753
 >> iter 93000, loss: 0.319651
 >> iter 94000, loss: 0.324379
 >> iter 95000, loss: 0.225781
 >> iter 96000, loss: 0.217081
 >> iter 97000, loss: 0.364296
 >> iter 98000, loss: 0.355130
 >> iter 99000, loss: 0.411899
 >> iter 100000, loss: 0.290776
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.915284
 >> iter 2000, loss: 9.670077
 >> iter 3000, loss: 5.424201
 >> iter 4000, loss: 2.719178
 >> iter 5000, loss: 1.570994
 >> iter 6000, loss: 1.046540
 >> iter 7000, loss: 0.665565
 >> iter 8000, loss: 0.555229
 >> iter 9000, loss: 0.412953
 >> iter 10000, loss: 0.347725
   Number of active neurons: 7
 >> iter 11000, loss: 0.293450
 >> iter 12000, loss: 0.354233
 >> iter 13000, loss: 0.316933
 >> iter 14000, loss: 0.404910
 >> iter 15000, loss: 0.358862
 >> iter 16000, loss: 0.206791
 >> iter 17000, loss: 0.283427
 >> iter 18000, loss: 0.361576
 >> iter 19000, loss: 0.341231
 >> iter 20000, loss: 0.278695
   Number of active neurons: 7
 >> iter 21000, loss: 0.236578
 >> iter 22000, loss: 0.372024
 >> iter 23000, loss: 0.363314
 >> iter 24000, loss: 0.381057
 >> iter 25000, loss: 0.387777
 >> iter 26000, loss: 0.385242
 >> iter 27000, loss: 0.414193
 >> iter 28000, loss: 0.432660
 >> iter 29000, loss: 0.439272
 >> iter 30000, loss: 0.507167
   Number of active neurons: 7
 >> iter 31000, loss: 0.344569
 >> iter 32000, loss: 0.294932
 >> iter 33000, loss: 0.287812
 >> iter 34000, loss: 0.271297
 >> iter 35000, loss: 0.303323
 >> iter 36000, loss: 0.338143
 >> iter 37000, loss: 0.300089
 >> iter 38000, loss: 0.308000
 >> iter 39000, loss: 0.367978
 >> iter 40000, loss: 0.248343
   Number of active neurons: 6
 >> iter 41000, loss: 0.423159
 >> iter 42000, loss: 0.411113
 >> iter 43000, loss: 0.393964
 >> iter 44000, loss: 0.406380
 >> iter 45000, loss: 0.355610
 >> iter 46000, loss: 0.322787
 >> iter 47000, loss: 0.278383
 >> iter 48000, loss: 0.409733
 >> iter 49000, loss: 0.317563
 >> iter 50000, loss: 0.288264
   Number of active neurons: 6
 >> iter 51000, loss: 0.331492
 >> iter 52000, loss: 0.376492
 >> iter 53000, loss: 0.342069
 >> iter 54000, loss: 0.325218
 >> iter 55000, loss: 0.210039
 >> iter 56000, loss: 0.217873
 >> iter 57000, loss: 0.356064
 >> iter 58000, loss: 0.225327
 >> iter 59000, loss: 0.286245
 >> iter 60000, loss: 0.280047
   Number of active neurons: 6
 >> iter 61000, loss: 0.272276
 >> iter 62000, loss: 0.456696
 >> iter 63000, loss: 0.313541
 >> iter 64000, loss: 0.253701
 >> iter 65000, loss: 0.262098
 >> iter 66000, loss: 0.319224
 >> iter 67000, loss: 0.382349
 >> iter 68000, loss: 0.328574
 >> iter 69000, loss: 0.388649
 >> iter 70000, loss: 0.318974
   Number of active neurons: 6
 >> iter 71000, loss: 0.397376
 >> iter 72000, loss: 0.270514
 >> iter 73000, loss: 0.249606
 >> iter 74000, loss: 0.297448
 >> iter 75000, loss: 0.255663
 >> iter 76000, loss: 0.293732
 >> iter 77000, loss: 0.254758
 >> iter 78000, loss: 0.269937
 >> iter 79000, loss: 0.234253
 >> iter 80000, loss: 0.272560
   Number of active neurons: 6
 >> iter 81000, loss: 0.285692
 >> iter 82000, loss: 0.266721
 >> iter 83000, loss: 0.331253
 >> iter 84000, loss: 0.335533
 >> iter 85000, loss: 0.278790
 >> iter 86000, loss: 0.214584
 >> iter 87000, loss: 0.385015
 >> iter 88000, loss: 0.271315
 >> iter 89000, loss: 0.385576
 >> iter 90000, loss: 0.269721
   Number of active neurons: 6
 >> iter 91000, loss: 0.275973
 >> iter 92000, loss: 0.289278
 >> iter 93000, loss: 0.264528
 >> iter 94000, loss: 0.310533
 >> iter 95000, loss: 0.419748
 >> iter 96000, loss: 0.285739
 >> iter 97000, loss: 0.298940
 >> iter 98000, loss: 0.250995
 >> iter 99000, loss: 0.364774
 >> iter 100000, loss: 0.306093
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.639234
 >> iter 2000, loss: 12.387698
 >> iter 3000, loss: 8.660262
 >> iter 4000, loss: 6.501594
 >> iter 5000, loss: 4.124232
 >> iter 6000, loss: 2.427293
 >> iter 7000, loss: 1.660872
 >> iter 8000, loss: 1.275068
 >> iter 9000, loss: 1.065651
 >> iter 10000, loss: 0.987107
   Number of active neurons: 8
 >> iter 11000, loss: 0.891561
 >> iter 12000, loss: 0.731562
 >> iter 13000, loss: 0.708763
 >> iter 14000, loss: 0.755402
 >> iter 15000, loss: 0.747696
 >> iter 16000, loss: 0.590082
 >> iter 17000, loss: 0.732728
 >> iter 18000, loss: 0.737354
 >> iter 19000, loss: 0.880194
 >> iter 20000, loss: 0.653459
   Number of active neurons: 7
 >> iter 21000, loss: 0.680800
 >> iter 22000, loss: 0.633358
 >> iter 23000, loss: 0.841085
 >> iter 24000, loss: 0.758319
 >> iter 25000, loss: 0.762632
 >> iter 26000, loss: 0.870024
 >> iter 27000, loss: 0.811001
 >> iter 28000, loss: 0.697648
 >> iter 29000, loss: 0.915960
 >> iter 30000, loss: 0.946681
   Number of active neurons: 6
 >> iter 31000, loss: 0.971441
 >> iter 32000, loss: 0.866432
 >> iter 33000, loss: 0.834003
 >> iter 34000, loss: 0.899319
 >> iter 35000, loss: 0.805138
 >> iter 36000, loss: 0.774355
 >> iter 37000, loss: 0.581341
 >> iter 38000, loss: 0.557914
 >> iter 39000, loss: 0.872383
 >> iter 40000, loss: 0.805709
   Number of active neurons: 6
 >> iter 41000, loss: 0.941536
 >> iter 42000, loss: 1.086235
 >> iter 43000, loss: 1.231634
 >> iter 44000, loss: 0.961036
 >> iter 45000, loss: 0.764283
 >> iter 46000, loss: 0.578287
 >> iter 47000, loss: 0.760869
 >> iter 48000, loss: 0.804818
 >> iter 49000, loss: 0.738774
 >> iter 50000, loss: 0.601855
   Number of active neurons: 5
 >> iter 51000, loss: 0.657683
 >> iter 52000, loss: 0.802261
 >> iter 53000, loss: 0.753574
 >> iter 54000, loss: 0.726732
 >> iter 55000, loss: 0.556878
 >> iter 56000, loss: 0.718485
 >> iter 57000, loss: 0.745043
 >> iter 58000, loss: 0.654813
 >> iter 59000, loss: 0.714110
 >> iter 60000, loss: 0.679380
   Number of active neurons: 5
 >> iter 61000, loss: 0.632649
 >> iter 62000, loss: 0.544281
 >> iter 63000, loss: 0.532601
 >> iter 64000, loss: 0.468578
 >> iter 65000, loss: 0.493831
 >> iter 66000, loss: 0.769730
 >> iter 67000, loss: 0.770459
 >> iter 68000, loss: 0.689716
 >> iter 69000, loss: 0.853190
 >> iter 70000, loss: 0.745018
   Number of active neurons: 5
 >> iter 71000, loss: 0.596293
 >> iter 72000, loss: 0.493534
 >> iter 73000, loss: 0.703181
 >> iter 74000, loss: 0.732962
 >> iter 75000, loss: 0.811665
 >> iter 76000, loss: 0.753899
 >> iter 77000, loss: 0.586791
 >> iter 78000, loss: 0.599673
 >> iter 79000, loss: 0.550265
 >> iter 80000, loss: 0.597554
   Number of active neurons: 5
 >> iter 81000, loss: 0.643356
 >> iter 82000, loss: 0.784125
 >> iter 83000, loss: 0.900038
 >> iter 84000, loss: 0.892874
 >> iter 85000, loss: 0.833383
 >> iter 86000, loss: 0.768500
 >> iter 87000, loss: 0.721860
 >> iter 88000, loss: 0.845638
 >> iter 89000, loss: 0.784698
 >> iter 90000, loss: 0.741252
   Number of active neurons: 5
 >> iter 91000, loss: 0.749612
 >> iter 92000, loss: 0.927275
 >> iter 93000, loss: 0.782866
 >> iter 94000, loss: 0.681170
 >> iter 95000, loss: 0.708874
 >> iter 96000, loss: 0.561894
 >> iter 97000, loss: 0.627408
 >> iter 98000, loss: 0.665531
 >> iter 99000, loss: 0.719329
 >> iter 100000, loss: 0.910119
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.277994440111
   - Test - Long: 0.029998500075
   - Test - Big: 0.259997400026
   - Test - A: 25.99160056
   - Test - B: 54.789680688
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.959491
 >> iter 2000, loss: 11.245425
 >> iter 3000, loss: 7.911442
 >> iter 4000, loss: 5.015174
 >> iter 5000, loss: 2.600412
 >> iter 6000, loss: 1.326201
 >> iter 7000, loss: 0.710096
 >> iter 8000, loss: 0.486187
 >> iter 9000, loss: 0.431726
 >> iter 10000, loss: 0.323121
   Number of active neurons: 7
 >> iter 11000, loss: 0.325434
 >> iter 12000, loss: 0.331316
 >> iter 13000, loss: 0.331783
 >> iter 14000, loss: 0.374113
 >> iter 15000, loss: 0.409181
 >> iter 16000, loss: 0.357807
 >> iter 17000, loss: 0.345421
 >> iter 18000, loss: 0.371979
 >> iter 19000, loss: 0.374095
 >> iter 20000, loss: 0.416284
   Number of active neurons: 5
 >> iter 21000, loss: 0.296018
 >> iter 22000, loss: 0.315634
 >> iter 23000, loss: 0.373736
 >> iter 24000, loss: 0.411449
 >> iter 25000, loss: 0.358625
 >> iter 26000, loss: 0.341364
 >> iter 27000, loss: 0.394052
 >> iter 28000, loss: 0.481519
 >> iter 29000, loss: 0.393369
 >> iter 30000, loss: 0.386465
   Number of active neurons: 5
 >> iter 31000, loss: 0.491359
 >> iter 32000, loss: 0.540851
 >> iter 33000, loss: 0.402788
 >> iter 34000, loss: 0.292539
 >> iter 35000, loss: 0.253862
 >> iter 36000, loss: 0.256306
 >> iter 37000, loss: 0.263106
 >> iter 38000, loss: 0.224709
 >> iter 39000, loss: 0.294000
 >> iter 40000, loss: 0.194110
   Number of active neurons: 5
 >> iter 41000, loss: 0.352444
 >> iter 42000, loss: 0.384942
 >> iter 43000, loss: 0.408220
 >> iter 44000, loss: 0.503475
 >> iter 45000, loss: 0.414484
 >> iter 46000, loss: 0.291550
 >> iter 47000, loss: 0.303415
 >> iter 48000, loss: 0.287455
 >> iter 49000, loss: 0.358555
 >> iter 50000, loss: 0.283620
   Number of active neurons: 5
 >> iter 51000, loss: 0.266940
 >> iter 52000, loss: 0.243519
 >> iter 53000, loss: 0.499174
 >> iter 54000, loss: 0.513810
 >> iter 55000, loss: 0.504232
 >> iter 56000, loss: 0.401717
 >> iter 57000, loss: 0.460620
 >> iter 58000, loss: 0.472330
 >> iter 59000, loss: 0.408787
 >> iter 60000, loss: 0.347318
   Number of active neurons: 5
 >> iter 61000, loss: 0.412358
 >> iter 62000, loss: 0.333909
 >> iter 63000, loss: 0.368963
 >> iter 64000, loss: 0.309774
 >> iter 65000, loss: 0.290647
 >> iter 66000, loss: 0.288305
 >> iter 67000, loss: 0.404285
 >> iter 68000, loss: 0.411399
 >> iter 69000, loss: 0.352788
 >> iter 70000, loss: 0.423315
   Number of active neurons: 4
 >> iter 71000, loss: 0.453607
 >> iter 72000, loss: 0.386223
 >> iter 73000, loss: 0.384522
 >> iter 74000, loss: 0.378605
 >> iter 75000, loss: 0.432333
 >> iter 76000, loss: 0.367225
 >> iter 77000, loss: 0.323467
 >> iter 78000, loss: 0.332726
 >> iter 79000, loss: 0.255907
 >> iter 80000, loss: 0.405429
   Number of active neurons: 4
 >> iter 81000, loss: 0.312376
 >> iter 82000, loss: 0.324265
 >> iter 83000, loss: 0.343135
 >> iter 84000, loss: 0.403010
 >> iter 85000, loss: 0.305533
 >> iter 86000, loss: 0.320005
 >> iter 87000, loss: 0.316173
 >> iter 88000, loss: 0.333027
 >> iter 89000, loss: 0.492251
 >> iter 90000, loss: 0.449463
   Number of active neurons: 4
 >> iter 91000, loss: 0.341687
 >> iter 92000, loss: 0.385698
 >> iter 93000, loss: 0.394760
 >> iter 94000, loss: 0.419464
 >> iter 95000, loss: 0.432263
 >> iter 96000, loss: 0.275964
 >> iter 97000, loss: 0.408769
 >> iter 98000, loss: 0.450786
 >> iter 99000, loss: 0.486640
 >> iter 100000, loss: 0.328191
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 16.643386
 >> iter 2000, loss: 9.251392
 >> iter 3000, loss: 4.442297
 >> iter 4000, loss: 2.098160
 >> iter 5000, loss: 1.055532
 >> iter 6000, loss: 0.624646
 >> iter 7000, loss: 0.448101
 >> iter 8000, loss: 0.281148
 >> iter 9000, loss: 0.298384
 >> iter 10000, loss: 0.258813
   Number of active neurons: 7
 >> iter 11000, loss: 0.301272
 >> iter 12000, loss: 0.212206
 >> iter 13000, loss: 0.278720
 >> iter 14000, loss: 0.275800
 >> iter 15000, loss: 0.249310
 >> iter 16000, loss: 0.232474
 >> iter 17000, loss: 0.267866
 >> iter 18000, loss: 0.258129
 >> iter 19000, loss: 0.210152
 >> iter 20000, loss: 0.345522
   Number of active neurons: 7
 >> iter 21000, loss: 0.322234
 >> iter 22000, loss: 0.304034
 >> iter 23000, loss: 0.270218
 >> iter 24000, loss: 0.229713
 >> iter 25000, loss: 0.260736
 >> iter 26000, loss: 0.374872
 >> iter 27000, loss: 0.327692
 >> iter 28000, loss: 0.237311
 >> iter 29000, loss: 0.243944
 >> iter 30000, loss: 0.193672
   Number of active neurons: 7
 >> iter 31000, loss: 0.303976
 >> iter 32000, loss: 0.218473
 >> iter 33000, loss: 0.218239
 >> iter 34000, loss: 0.179799
 >> iter 35000, loss: 0.200118
 >> iter 36000, loss: 0.256740
 >> iter 37000, loss: 0.250278
 >> iter 38000, loss: 0.288826
 >> iter 39000, loss: 0.284186
 >> iter 40000, loss: 0.268074
   Number of active neurons: 6
 >> iter 41000, loss: 0.187888
 >> iter 42000, loss: 0.311882
 >> iter 43000, loss: 0.216759
 >> iter 44000, loss: 0.205022
 >> iter 45000, loss: 0.230479
 >> iter 46000, loss: 0.262206
 >> iter 47000, loss: 0.198049
 >> iter 48000, loss: 0.217466
 >> iter 49000, loss: 0.219773
 >> iter 50000, loss: 0.228011
   Number of active neurons: 6
 >> iter 51000, loss: 0.206700
 >> iter 52000, loss: 0.289643
 >> iter 53000, loss: 0.211275
 >> iter 54000, loss: 0.207634
 >> iter 55000, loss: 0.189891
 >> iter 56000, loss: 0.206435
 >> iter 57000, loss: 0.209859
 >> iter 58000, loss: 0.184244
 >> iter 59000, loss: 0.273675
 >> iter 60000, loss: 0.162566
   Number of active neurons: 6
 >> iter 61000, loss: 0.276573
 >> iter 62000, loss: 0.238920
 >> iter 63000, loss: 0.268610
 >> iter 64000, loss: 0.280052
 >> iter 65000, loss: 0.261312
 >> iter 66000, loss: 0.254867
 >> iter 67000, loss: 0.249564
 >> iter 68000, loss: 0.227727
 >> iter 69000, loss: 0.214561
 >> iter 70000, loss: 0.187754
   Number of active neurons: 6
 >> iter 71000, loss: 0.236291
 >> iter 72000, loss: 0.348177
 >> iter 73000, loss: 0.295638
 >> iter 74000, loss: 0.365389
 >> iter 75000, loss: 0.259360
 >> iter 76000, loss: 0.239367
 >> iter 77000, loss: 0.231140
 >> iter 78000, loss: 0.179391
 >> iter 79000, loss: 0.243077
 >> iter 80000, loss: 0.208065
   Number of active neurons: 6
 >> iter 81000, loss: 0.207838
 >> iter 82000, loss: 0.294496
 >> iter 83000, loss: 0.185832
 >> iter 84000, loss: 0.137372
 >> iter 85000, loss: 0.298698
 >> iter 86000, loss: 0.196262
 >> iter 87000, loss: 0.230455
 >> iter 88000, loss: 0.241246
 >> iter 89000, loss: 0.246586
 >> iter 90000, loss: 0.337445
   Number of active neurons: 6
 >> iter 91000, loss: 0.339541
 >> iter 92000, loss: 0.335368
 >> iter 93000, loss: 0.319046
 >> iter 94000, loss: 0.240911
 >> iter 95000, loss: 0.279331
 >> iter 96000, loss: 0.371463
 >> iter 97000, loss: 0.301110
 >> iter 98000, loss: 0.327266
 >> iter 99000, loss: 0.287540
 >> iter 100000, loss: 0.316758
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.233873
 >> iter 2000, loss: 10.235993
 >> iter 3000, loss: 5.696790
 >> iter 4000, loss: 3.195775
 >> iter 5000, loss: 1.825948
 >> iter 6000, loss: 1.082419
 >> iter 7000, loss: 0.809518
 >> iter 8000, loss: 0.618135
 >> iter 9000, loss: 0.434135
 >> iter 10000, loss: 0.414118
   Number of active neurons: 5
 >> iter 11000, loss: 0.423726
 >> iter 12000, loss: 0.479890
 >> iter 13000, loss: 0.502383
 >> iter 14000, loss: 0.425546
 >> iter 15000, loss: 0.387635
 >> iter 16000, loss: 0.478606
 >> iter 17000, loss: 0.381417
 >> iter 18000, loss: 0.363112
 >> iter 19000, loss: 0.442949
 >> iter 20000, loss: 0.594020
   Number of active neurons: 5
 >> iter 21000, loss: 0.514402
 >> iter 22000, loss: 0.603080
 >> iter 23000, loss: 0.491812
 >> iter 24000, loss: 0.378750
 >> iter 25000, loss: 0.449666
 >> iter 26000, loss: 0.449920
 >> iter 27000, loss: 0.417216
 >> iter 28000, loss: 0.541517
 >> iter 29000, loss: 0.390294
 >> iter 30000, loss: 0.291442
   Number of active neurons: 5
 >> iter 31000, loss: 0.431512
 >> iter 32000, loss: 0.477240
 >> iter 33000, loss: 0.424883
 >> iter 34000, loss: 0.515163
 >> iter 35000, loss: 0.498428
 >> iter 36000, loss: 0.506055
 >> iter 37000, loss: 0.513655
 >> iter 38000, loss: 0.437878
 >> iter 39000, loss: 0.497610
 >> iter 40000, loss: 0.400018
   Number of active neurons: 4
 >> iter 41000, loss: 0.466610
 >> iter 42000, loss: 0.482500
 >> iter 43000, loss: 0.377374
 >> iter 44000, loss: 0.356905
 >> iter 45000, loss: 0.434929
 >> iter 46000, loss: 0.441978
 >> iter 47000, loss: 0.354021
 >> iter 48000, loss: 0.535900
 >> iter 49000, loss: 0.435775
 >> iter 50000, loss: 0.408230
   Number of active neurons: 4
 >> iter 51000, loss: 0.461240
 >> iter 52000, loss: 0.441057
 >> iter 53000, loss: 0.428150
 >> iter 54000, loss: 0.482276
 >> iter 55000, loss: 0.601715
 >> iter 56000, loss: 0.625029
 >> iter 57000, loss: 0.513265
 >> iter 58000, loss: 0.560219
 >> iter 59000, loss: 0.588257
 >> iter 60000, loss: 0.554405
   Number of active neurons: 4
 >> iter 61000, loss: 0.509762
 >> iter 62000, loss: 0.614232
 >> iter 63000, loss: 0.563480
 >> iter 64000, loss: 0.568576
 >> iter 65000, loss: 0.440941
 >> iter 66000, loss: 0.690794
 >> iter 67000, loss: 0.485883
 >> iter 68000, loss: 0.483971
 >> iter 69000, loss: 0.493627
 >> iter 70000, loss: 0.567522
   Number of active neurons: 4
 >> iter 71000, loss: 0.636405
 >> iter 72000, loss: 0.643360
 >> iter 73000, loss: 0.656154
 >> iter 74000, loss: 0.476494
 >> iter 75000, loss: 0.420372
 >> iter 76000, loss: 0.528140
 >> iter 77000, loss: 0.556986
 >> iter 78000, loss: 0.490008
 >> iter 79000, loss: 0.562433
 >> iter 80000, loss: 0.400843
   Number of active neurons: 4
 >> iter 81000, loss: 0.465649
 >> iter 82000, loss: 0.457508
 >> iter 83000, loss: 0.506854
 >> iter 84000, loss: 0.668655
 >> iter 85000, loss: 0.662666
 >> iter 86000, loss: 0.545017
 >> iter 87000, loss: 0.549291
 >> iter 88000, loss: 0.447648
 >> iter 89000, loss: 0.558751
 >> iter 90000, loss: 0.475907
   Number of active neurons: 4
 >> iter 91000, loss: 0.554339
 >> iter 92000, loss: 0.630001
 >> iter 93000, loss: 0.493105
 >> iter 94000, loss: 0.674562
 >> iter 95000, loss: 0.605137
 >> iter 96000, loss: 0.641736
 >> iter 97000, loss: 0.663911
 >> iter 98000, loss: 0.482392
 >> iter 99000, loss: 0.450215
 >> iter 100000, loss: 0.336008
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.119831
 >> iter 2000, loss: 12.034767
 >> iter 3000, loss: 8.203661
 >> iter 4000, loss: 5.414220
 >> iter 5000, loss: 3.144123
 >> iter 6000, loss: 1.757596
 >> iter 7000, loss: 1.230424
 >> iter 8000, loss: 1.045191
 >> iter 9000, loss: 0.787154
 >> iter 10000, loss: 0.696680
   Number of active neurons: 7
 >> iter 11000, loss: 0.725343
 >> iter 12000, loss: 0.539386
 >> iter 13000, loss: 0.557783
 >> iter 14000, loss: 0.446363
 >> iter 15000, loss: 0.440184
 >> iter 16000, loss: 0.580045
 >> iter 17000, loss: 0.563733
 >> iter 18000, loss: 0.554181
 >> iter 19000, loss: 0.548990
 >> iter 20000, loss: 0.540738
   Number of active neurons: 7
 >> iter 21000, loss: 0.518543
 >> iter 22000, loss: 0.465434
 >> iter 23000, loss: 0.486463
 >> iter 24000, loss: 0.615455
 >> iter 25000, loss: 0.573374
 >> iter 26000, loss: 0.492764
 >> iter 27000, loss: 0.517979
 >> iter 28000, loss: 0.346840
 >> iter 29000, loss: 0.442075
 >> iter 30000, loss: 0.392047
   Number of active neurons: 7
 >> iter 31000, loss: 0.331112
 >> iter 32000, loss: 0.402996
 >> iter 33000, loss: 0.436888
 >> iter 34000, loss: 0.490970
 >> iter 35000, loss: 0.470401
 >> iter 36000, loss: 0.406819
 >> iter 37000, loss: 0.393908
 >> iter 38000, loss: 0.316228
 >> iter 39000, loss: 0.342887
 >> iter 40000, loss: 0.378267
   Number of active neurons: 7
 >> iter 41000, loss: 0.457072
 >> iter 42000, loss: 0.484194
 >> iter 43000, loss: 0.530192
 >> iter 44000, loss: 0.501476
 >> iter 45000, loss: 0.342695
 >> iter 46000, loss: 0.455247
 >> iter 47000, loss: 0.544582
 >> iter 48000, loss: 0.433948
 >> iter 49000, loss: 0.469833
 >> iter 50000, loss: 0.391796
   Number of active neurons: 7
 >> iter 51000, loss: 0.438094
 >> iter 52000, loss: 0.400598
 >> iter 53000, loss: 0.289526
 >> iter 54000, loss: 0.373100
 >> iter 55000, loss: 0.365216
 >> iter 56000, loss: 0.330933
 >> iter 57000, loss: 0.519762
 >> iter 58000, loss: 0.566693
 >> iter 59000, loss: 0.446552
 >> iter 60000, loss: 0.439386
   Number of active neurons: 7
 >> iter 61000, loss: 0.368987
 >> iter 62000, loss: 0.263918
 >> iter 63000, loss: 0.404014
 >> iter 64000, loss: 0.340511
 >> iter 65000, loss: 0.391498
 >> iter 66000, loss: 0.358794
 >> iter 67000, loss: 0.454600
 >> iter 68000, loss: 0.384562
 >> iter 69000, loss: 0.480582
 >> iter 70000, loss: 0.385723
   Number of active neurons: 7
 >> iter 71000, loss: 0.408331
 >> iter 72000, loss: 0.390093
 >> iter 73000, loss: 0.387457
 >> iter 74000, loss: 0.317080
 >> iter 75000, loss: 0.214316
 >> iter 76000, loss: 0.314156
 >> iter 77000, loss: 0.451578
 >> iter 78000, loss: 0.462746
 >> iter 79000, loss: 0.392014
 >> iter 80000, loss: 0.400474
   Number of active neurons: 7
 >> iter 81000, loss: 0.266549
 >> iter 82000, loss: 0.317559
 >> iter 83000, loss: 0.427118
 >> iter 84000, loss: 0.443290
 >> iter 85000, loss: 0.457760
 >> iter 86000, loss: 0.456309
 >> iter 87000, loss: 0.405039
 >> iter 88000, loss: 0.350705
 >> iter 89000, loss: 0.316152
 >> iter 90000, loss: 0.410894
   Number of active neurons: 7
 >> iter 91000, loss: 0.316619
 >> iter 92000, loss: 0.291315
 >> iter 93000, loss: 0.302162
 >> iter 94000, loss: 0.309236
 >> iter 95000, loss: 0.241628
 >> iter 96000, loss: 0.207264
 >> iter 97000, loss: 0.244331
 >> iter 98000, loss: 0.223346
 >> iter 99000, loss: 0.240884
 >> iter 100000, loss: 0.204934
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.581225
 >> iter 2000, loss: 10.782150
 >> iter 3000, loss: 6.101392
 >> iter 4000, loss: 3.552272
 >> iter 5000, loss: 2.039705
 >> iter 6000, loss: 1.371788
 >> iter 7000, loss: 1.077822
 >> iter 8000, loss: 0.857956
 >> iter 9000, loss: 0.684561
 >> iter 10000, loss: 0.629003
   Number of active neurons: 5
 >> iter 11000, loss: 0.481089
 >> iter 12000, loss: 0.491007
 >> iter 13000, loss: 0.482094
 >> iter 14000, loss: 0.469157
 >> iter 15000, loss: 0.462947
 >> iter 16000, loss: 0.461006
 >> iter 17000, loss: 0.425046
 >> iter 18000, loss: 0.471928
 >> iter 19000, loss: 0.469377
 >> iter 20000, loss: 0.405528
   Number of active neurons: 4
 >> iter 21000, loss: 0.420951
 >> iter 22000, loss: 0.296504
 >> iter 23000, loss: 0.450088
 >> iter 24000, loss: 0.484710
 >> iter 25000, loss: 0.472715
 >> iter 26000, loss: 0.449593
 >> iter 27000, loss: 0.367437
 >> iter 28000, loss: 0.549824
 >> iter 29000, loss: 0.482773
 >> iter 30000, loss: 0.402586
   Number of active neurons: 4
 >> iter 31000, loss: 0.371940
 >> iter 32000, loss: 0.264814
 >> iter 33000, loss: 0.273508
 >> iter 34000, loss: 0.467714
 >> iter 35000, loss: 0.400795
 >> iter 36000, loss: 0.315662
 >> iter 37000, loss: 0.305976
 >> iter 38000, loss: 0.344702
 >> iter 39000, loss: 0.357043
 >> iter 40000, loss: 0.358964
   Number of active neurons: 4
 >> iter 41000, loss: 0.506662
 >> iter 42000, loss: 0.505934
 >> iter 43000, loss: 0.454554
 >> iter 44000, loss: 0.490005
 >> iter 45000, loss: 0.399059
 >> iter 46000, loss: 0.435247
 >> iter 47000, loss: 0.599987
 >> iter 48000, loss: 0.501365
 >> iter 49000, loss: 0.709033
 >> iter 50000, loss: 0.688301
   Number of active neurons: 4
 >> iter 51000, loss: 0.721620
 >> iter 52000, loss: 0.516530
 >> iter 53000, loss: 0.401893
 >> iter 54000, loss: 0.456306
 >> iter 55000, loss: 0.559096
 >> iter 56000, loss: 0.561129
 >> iter 57000, loss: 0.464954
 >> iter 58000, loss: 0.373755
 >> iter 59000, loss: 0.426708
 >> iter 60000, loss: 0.486115
   Number of active neurons: 4
 >> iter 61000, loss: 0.575892
 >> iter 62000, loss: 0.574194
 >> iter 63000, loss: 0.459599
 >> iter 64000, loss: 0.389904
 >> iter 65000, loss: 0.351012
 >> iter 66000, loss: 0.504309
 >> iter 67000, loss: 0.520916
 >> iter 68000, loss: 0.613462
 >> iter 69000, loss: 0.512780
 >> iter 70000, loss: 0.571477
   Number of active neurons: 4
 >> iter 71000, loss: 0.429638
 >> iter 72000, loss: 0.455419
 >> iter 73000, loss: 0.473751
 >> iter 74000, loss: 0.480390
 >> iter 75000, loss: 0.509521
 >> iter 76000, loss: 0.580425
 >> iter 77000, loss: 0.476393
 >> iter 78000, loss: 0.497445
 >> iter 79000, loss: 0.818548
 >> iter 80000, loss: 0.831935
   Number of active neurons: 4
 >> iter 81000, loss: 0.537114
 >> iter 82000, loss: 0.607668
 >> iter 83000, loss: 0.498340
 >> iter 84000, loss: 0.479401
 >> iter 85000, loss: 0.364711
 >> iter 86000, loss: 0.338145
 >> iter 87000, loss: 0.459489
 >> iter 88000, loss: 0.427644
 >> iter 89000, loss: 0.423387
 >> iter 90000, loss: 0.377566
   Number of active neurons: 4
 >> iter 91000, loss: 0.403197
 >> iter 92000, loss: 0.465065
 >> iter 93000, loss: 0.374669
 >> iter 94000, loss: 0.364009
 >> iter 95000, loss: 0.480793
 >> iter 96000, loss: 0.412046
 >> iter 97000, loss: 0.575851
 >> iter 98000, loss: 0.507614
 >> iter 99000, loss: 0.627285
 >> iter 100000, loss: 0.599712
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.334003
 >> iter 2000, loss: 11.239734
 >> iter 3000, loss: 6.807268
 >> iter 4000, loss: 3.097215
 >> iter 5000, loss: 1.463198
 >> iter 6000, loss: 0.884269
 >> iter 7000, loss: 0.661412
 >> iter 8000, loss: 0.470398
 >> iter 9000, loss: 0.396496
 >> iter 10000, loss: 0.392235
   Number of active neurons: 5
 >> iter 11000, loss: 0.411575
 >> iter 12000, loss: 0.399378
 >> iter 13000, loss: 0.403929
 >> iter 14000, loss: 0.289357
 >> iter 15000, loss: 0.248287
 >> iter 16000, loss: 0.283385
 >> iter 17000, loss: 0.331528
 >> iter 18000, loss: 0.273114
 >> iter 19000, loss: 0.442922
 >> iter 20000, loss: 0.366185
   Number of active neurons: 5
 >> iter 21000, loss: 0.298574
 >> iter 22000, loss: 0.317078
 >> iter 23000, loss: 0.298562
 >> iter 24000, loss: 0.273644
 >> iter 25000, loss: 0.439436
 >> iter 26000, loss: 0.476788
 >> iter 27000, loss: 0.453343
 >> iter 28000, loss: 0.413050
 >> iter 29000, loss: 0.358872
 >> iter 30000, loss: 0.278549
   Number of active neurons: 5
 >> iter 31000, loss: 0.287051
 >> iter 32000, loss: 0.282797
 >> iter 33000, loss: 0.353787
 >> iter 34000, loss: 0.348438
 >> iter 35000, loss: 0.324471
 >> iter 36000, loss: 0.406711
 >> iter 37000, loss: 0.375117
 >> iter 38000, loss: 0.340786
 >> iter 39000, loss: 0.353332
 >> iter 40000, loss: 0.273099
   Number of active neurons: 5
 >> iter 41000, loss: 0.310986
 >> iter 42000, loss: 0.303531
 >> iter 43000, loss: 0.287187
 >> iter 44000, loss: 0.234858
 >> iter 45000, loss: 0.322494
 >> iter 46000, loss: 0.319529
 >> iter 47000, loss: 0.335694
 >> iter 48000, loss: 0.353334
 >> iter 49000, loss: 0.459875
 >> iter 50000, loss: 0.401681
   Number of active neurons: 5
 >> iter 51000, loss: 0.390076
 >> iter 52000, loss: 0.379247
 >> iter 53000, loss: 0.325340
 >> iter 54000, loss: 0.437576
 >> iter 55000, loss: 0.428662
 >> iter 56000, loss: 0.462172
 >> iter 57000, loss: 0.307703
 >> iter 58000, loss: 0.334292
 >> iter 59000, loss: 0.317180
 >> iter 60000, loss: 0.342317
   Number of active neurons: 5
 >> iter 61000, loss: 0.294289
 >> iter 62000, loss: 0.347575
 >> iter 63000, loss: 0.223260
 >> iter 64000, loss: 0.371813
 >> iter 65000, loss: 0.324541
 >> iter 66000, loss: 0.309507
 >> iter 67000, loss: 0.342631
 >> iter 68000, loss: 0.414405
 >> iter 69000, loss: 0.400178
 >> iter 70000, loss: 0.311776
   Number of active neurons: 5
 >> iter 71000, loss: 0.281062
 >> iter 72000, loss: 0.323623
 >> iter 73000, loss: 0.355733
 >> iter 74000, loss: 0.248456
 >> iter 75000, loss: 0.412365
 >> iter 76000, loss: 0.341894
 >> iter 77000, loss: 0.238171
 >> iter 78000, loss: 0.372150
 >> iter 79000, loss: 0.316337
 >> iter 80000, loss: 0.293849
   Number of active neurons: 5
 >> iter 81000, loss: 0.277293
 >> iter 82000, loss: 0.385309
 >> iter 83000, loss: 0.347477
 >> iter 84000, loss: 0.421788
 >> iter 85000, loss: 0.356268
 >> iter 86000, loss: 0.358462
 >> iter 87000, loss: 0.332415
 >> iter 88000, loss: 0.371270
 >> iter 89000, loss: 0.309074
 >> iter 90000, loss: 0.296899
   Number of active neurons: 5
 >> iter 91000, loss: 0.425468
 >> iter 92000, loss: 0.400818
 >> iter 93000, loss: 0.254456
 >> iter 94000, loss: 0.310065
 >> iter 95000, loss: 0.192402
 >> iter 96000, loss: 0.257868
 >> iter 97000, loss: 0.440919
 >> iter 98000, loss: 0.435034
 >> iter 99000, loss: 0.323364
 >> iter 100000, loss: 0.329780
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.604599
 >> iter 2000, loss: 11.548537
 >> iter 3000, loss: 8.252934
 >> iter 4000, loss: 4.550368
 >> iter 5000, loss: 2.114874
 >> iter 6000, loss: 1.122815
 >> iter 7000, loss: 0.753516
 >> iter 8000, loss: 0.514106
 >> iter 9000, loss: 0.485188
 >> iter 10000, loss: 0.375141
   Number of active neurons: 4
 >> iter 11000, loss: 0.257797
 >> iter 12000, loss: 0.243917
 >> iter 13000, loss: 0.329278
 >> iter 14000, loss: 0.212747
 >> iter 15000, loss: 0.245536
 >> iter 16000, loss: 0.185275
 >> iter 17000, loss: 0.279769
 >> iter 18000, loss: 0.243501
 >> iter 19000, loss: 0.335247
 >> iter 20000, loss: 0.327042
   Number of active neurons: 4
 >> iter 21000, loss: 0.259119
 >> iter 22000, loss: 0.434952
 >> iter 23000, loss: 0.423898
 >> iter 24000, loss: 0.405944
 >> iter 25000, loss: 0.322643
 >> iter 26000, loss: 0.424335
 >> iter 27000, loss: 0.405485
 >> iter 28000, loss: 0.406178
 >> iter 29000, loss: 0.526951
 >> iter 30000, loss: 0.366390
   Number of active neurons: 4
 >> iter 31000, loss: 0.304731
 >> iter 32000, loss: 0.369256
 >> iter 33000, loss: 0.366131
 >> iter 34000, loss: 0.332870
 >> iter 35000, loss: 0.320285
 >> iter 36000, loss: 0.361898
 >> iter 37000, loss: 0.327753
 >> iter 38000, loss: 0.255738
 >> iter 39000, loss: 0.341428
 >> iter 40000, loss: 0.273004
   Number of active neurons: 4
 >> iter 41000, loss: 0.288898
 >> iter 42000, loss: 0.318652
 >> iter 43000, loss: 0.313357
 >> iter 44000, loss: 0.280388
 >> iter 45000, loss: 0.222106
 >> iter 46000, loss: 0.283399
 >> iter 47000, loss: 0.335259
 >> iter 48000, loss: 0.406980
 >> iter 49000, loss: 0.466510
 >> iter 50000, loss: 0.587498
   Number of active neurons: 4
 >> iter 51000, loss: 0.403384
 >> iter 52000, loss: 0.298907
 >> iter 53000, loss: 0.256780
 >> iter 54000, loss: 0.332357
 >> iter 55000, loss: 0.300053
 >> iter 56000, loss: 0.337394
 >> iter 57000, loss: 0.345160
 >> iter 58000, loss: 0.297500
 >> iter 59000, loss: 0.273256
 >> iter 60000, loss: 0.328475
   Number of active neurons: 4
 >> iter 61000, loss: 0.334614
 >> iter 62000, loss: 0.378439
 >> iter 63000, loss: 0.378043
 >> iter 64000, loss: 0.387850
 >> iter 65000, loss: 0.490302
 >> iter 66000, loss: 0.376923
 >> iter 67000, loss: 0.438352
 >> iter 68000, loss: 0.447491
 >> iter 69000, loss: 0.309197
 >> iter 70000, loss: 0.379535
   Number of active neurons: 4
 >> iter 71000, loss: 0.364545
 >> iter 72000, loss: 0.319634
 >> iter 73000, loss: 0.229824
 >> iter 74000, loss: 0.387836
 >> iter 75000, loss: 0.243095
 >> iter 76000, loss: 0.305889
 >> iter 77000, loss: 0.413262
 >> iter 78000, loss: 0.427608
 >> iter 79000, loss: 0.431785
 >> iter 80000, loss: 0.344075
   Number of active neurons: 4
 >> iter 81000, loss: 0.286189
 >> iter 82000, loss: 0.373110
 >> iter 83000, loss: 0.280206
 >> iter 84000, loss: 0.306758
 >> iter 85000, loss: 0.280730
 >> iter 86000, loss: 0.366092
 >> iter 87000, loss: 0.238332
 >> iter 88000, loss: 0.379196
 >> iter 89000, loss: 0.405722
 >> iter 90000, loss: 0.464763
   Number of active neurons: 4
 >> iter 91000, loss: 0.385781
 >> iter 92000, loss: 0.413195
 >> iter 93000, loss: 0.341787
 >> iter 94000, loss: 0.303326
 >> iter 95000, loss: 0.328054
 >> iter 96000, loss: 0.248668
 >> iter 97000, loss: 0.436968
 >> iter 98000, loss: 0.343560
 >> iter 99000, loss: 0.402184
 >> iter 100000, loss: 0.367134
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.534611
 >> iter 2000, loss: 11.608026
 >> iter 3000, loss: 8.218801
 >> iter 4000, loss: 4.736789
 >> iter 5000, loss: 2.357169
 >> iter 6000, loss: 1.216054
 >> iter 7000, loss: 0.739994
 >> iter 8000, loss: 0.540934
 >> iter 9000, loss: 0.426725
 >> iter 10000, loss: 0.363038
   Number of active neurons: 7
 >> iter 11000, loss: 0.348110
 >> iter 12000, loss: 0.313860
 >> iter 13000, loss: 0.359930
 >> iter 14000, loss: 0.277099
 >> iter 15000, loss: 0.366800
 >> iter 16000, loss: 0.260684
 >> iter 17000, loss: 0.270215
 >> iter 18000, loss: 0.244091
 >> iter 19000, loss: 0.221051
 >> iter 20000, loss: 0.295179
   Number of active neurons: 6
 >> iter 21000, loss: 0.298228
 >> iter 22000, loss: 0.301540
 >> iter 23000, loss: 0.281986
 >> iter 24000, loss: 0.252442
 >> iter 25000, loss: 0.191182
 >> iter 26000, loss: 0.287511
 >> iter 27000, loss: 0.223730
 >> iter 28000, loss: 0.260788
 >> iter 29000, loss: 0.301775
 >> iter 30000, loss: 0.332584
   Number of active neurons: 6
 >> iter 31000, loss: 0.276510
 >> iter 32000, loss: 0.245067
 >> iter 33000, loss: 0.264205
 >> iter 34000, loss: 0.225747
 >> iter 35000, loss: 0.261112
 >> iter 36000, loss: 0.259486
 >> iter 37000, loss: 0.306391
 >> iter 38000, loss: 0.297182
 >> iter 39000, loss: 0.297314
 >> iter 40000, loss: 0.278973
   Number of active neurons: 6
 >> iter 41000, loss: 0.219884
 >> iter 42000, loss: 0.220487
 >> iter 43000, loss: 0.300278
 >> iter 44000, loss: 0.299828
 >> iter 45000, loss: 0.259778
 >> iter 46000, loss: 0.296570
 >> iter 47000, loss: 0.239253
 >> iter 48000, loss: 0.204724
 >> iter 49000, loss: 0.209911
 >> iter 50000, loss: 0.245278
   Number of active neurons: 6
 >> iter 51000, loss: 0.381702
 >> iter 52000, loss: 0.262314
 >> iter 53000, loss: 0.190041
 >> iter 54000, loss: 0.224596
 >> iter 55000, loss: 0.161105
 >> iter 56000, loss: 0.257933
 >> iter 57000, loss: 0.360853
 >> iter 58000, loss: 0.264918
 >> iter 59000, loss: 0.311597
 >> iter 60000, loss: 0.273139
   Number of active neurons: 6
 >> iter 61000, loss: 0.270285
 >> iter 62000, loss: 0.274677
 >> iter 63000, loss: 0.223459
 >> iter 64000, loss: 0.186070
 >> iter 65000, loss: 0.171618
 >> iter 66000, loss: 0.179671
 >> iter 67000, loss: 0.245566
 >> iter 68000, loss: 0.236883
 >> iter 69000, loss: 0.227124
 >> iter 70000, loss: 0.239959
   Number of active neurons: 6
 >> iter 71000, loss: 0.225142
 >> iter 72000, loss: 0.286539
 >> iter 73000, loss: 0.298004
 >> iter 74000, loss: 0.224357
 >> iter 75000, loss: 0.178250
 >> iter 76000, loss: 0.158084
 >> iter 77000, loss: 0.273283
 >> iter 78000, loss: 0.244340
 >> iter 79000, loss: 0.166646
 >> iter 80000, loss: 0.184731
   Number of active neurons: 6
 >> iter 81000, loss: 0.124682
 >> iter 82000, loss: 0.110127
 >> iter 83000, loss: 0.219179
 >> iter 84000, loss: 0.213266
 >> iter 85000, loss: 0.220202
 >> iter 86000, loss: 0.185308
 >> iter 87000, loss: 0.317044
 >> iter 88000, loss: 0.245867
 >> iter 89000, loss: 0.238860
 >> iter 90000, loss: 0.183440
   Number of active neurons: 5
 >> iter 91000, loss: 0.323655
 >> iter 92000, loss: 0.214487
 >> iter 93000, loss: 0.160283
 >> iter 94000, loss: 0.199923
 >> iter 95000, loss: 0.225859
 >> iter 96000, loss: 0.347871
 >> iter 97000, loss: 0.282312
 >> iter 98000, loss: 0.212042
 >> iter 99000, loss: 0.261724
 >> iter 100000, loss: 0.279879
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

