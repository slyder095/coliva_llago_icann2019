 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.8
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.176148
 >> iter 2000, loss: 11.263020
 >> iter 3000, loss: 5.152805
 >> iter 4000, loss: 2.267628
 >> iter 5000, loss: 1.208842
 >> iter 6000, loss: 0.651174
 >> iter 7000, loss: 0.405040
 >> iter 8000, loss: 0.207282
 >> iter 9000, loss: 0.110881
 >> iter 10000, loss: 0.087056
   Number of active neurons: 10
 >> iter 11000, loss: 0.168652
 >> iter 12000, loss: 0.106864
 >> iter 13000, loss: 0.061011
 >> iter 14000, loss: 0.062329
 >> iter 15000, loss: 0.037217
 >> iter 16000, loss: 0.019791
 >> iter 17000, loss: 0.103717
 >> iter 18000, loss: 0.057968
 >> iter 19000, loss: 0.031381
 >> iter 20000, loss: 0.017171
   Number of active neurons: 10
 >> iter 21000, loss: 0.016378
 >> iter 22000, loss: 0.011232
 >> iter 23000, loss: 0.036137
 >> iter 24000, loss: 0.023473
 >> iter 25000, loss: 0.022147
 >> iter 26000, loss: 0.016353
 >> iter 27000, loss: 0.026611
 >> iter 28000, loss: 0.014230
 >> iter 29000, loss: 0.008807
 >> iter 30000, loss: 0.027718
   Number of active neurons: 10
 >> iter 31000, loss: 0.012796
 >> iter 32000, loss: 0.037183
 >> iter 33000, loss: 0.036236
 >> iter 34000, loss: 0.020488
 >> iter 35000, loss: 0.009843
 >> iter 36000, loss: 0.009078
 >> iter 37000, loss: 0.005338
 >> iter 38000, loss: 0.004491
 >> iter 39000, loss: 0.003412
 >> iter 40000, loss: 0.014620
   Number of active neurons: 10
 >> iter 41000, loss: 0.017730
 >> iter 42000, loss: 0.010140
 >> iter 43000, loss: 0.007065
 >> iter 44000, loss: 0.042835
 >> iter 45000, loss: 0.018435
 >> iter 46000, loss: 0.008955
 >> iter 47000, loss: 0.103811
 >> iter 48000, loss: 0.040886
 >> iter 49000, loss: 0.018727
 >> iter 50000, loss: 0.009862
   Number of active neurons: 10
 >> iter 51000, loss: 0.015404
 >> iter 52000, loss: 0.007532
 >> iter 53000, loss: 0.022652
 >> iter 54000, loss: 0.015086
 >> iter 55000, loss: 0.007812
 >> iter 56000, loss: 0.005166
 >> iter 57000, loss: 0.003598
 >> iter 58000, loss: 0.002660
 >> iter 59000, loss: 0.024786
 >> iter 60000, loss: 0.120285
   Number of active neurons: 10
 >> iter 61000, loss: 0.046854
 >> iter 62000, loss: 0.019103
 >> iter 63000, loss: 0.008909
 >> iter 64000, loss: 0.004933
 >> iter 65000, loss: 0.003597
 >> iter 66000, loss: 0.020378
 >> iter 67000, loss: 0.019683
 >> iter 68000, loss: 0.008792
 >> iter 69000, loss: 0.043608
 >> iter 70000, loss: 0.069706
   Number of active neurons: 10
 >> iter 71000, loss: 0.027815
 >> iter 72000, loss: 0.025789
 >> iter 73000, loss: 0.108211
 >> iter 74000, loss: 0.042504
 >> iter 75000, loss: 0.017214
 >> iter 76000, loss: 0.008036
 >> iter 77000, loss: 0.004286
 >> iter 78000, loss: 0.003605
 >> iter 79000, loss: 0.002727
 >> iter 80000, loss: 0.010135
   Number of active neurons: 10
 >> iter 81000, loss: 0.022363
 >> iter 82000, loss: 0.009907
 >> iter 83000, loss: 0.005178
 >> iter 84000, loss: 0.059263
 >> iter 85000, loss: 0.023610
 >> iter 86000, loss: 0.023015
 >> iter 87000, loss: 0.009808
 >> iter 88000, loss: 0.004954
 >> iter 89000, loss: 0.030190
 >> iter 90000, loss: 0.017725
   Number of active neurons: 10
 >> iter 91000, loss: 0.008184
 >> iter 92000, loss: 0.006984
 >> iter 93000, loss: 0.003704
 >> iter 94000, loss: 0.002248
 >> iter 95000, loss: 0.011125
 >> iter 96000, loss: 0.004990
 >> iter 97000, loss: 0.002705
 >> iter 98000, loss: 0.001855
 >> iter 99000, loss: 0.001594
 >> iter 100000, loss: 0.001983
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.951811
 >> iter 2000, loss: 11.009177
 >> iter 3000, loss: 5.076211
 >> iter 4000, loss: 2.364330
 >> iter 5000, loss: 1.291998
 >> iter 6000, loss: 0.729065
 >> iter 7000, loss: 0.407243
 >> iter 8000, loss: 0.406254
 >> iter 9000, loss: 0.216294
 >> iter 10000, loss: 0.095162
   Number of active neurons: 10
 >> iter 11000, loss: 0.065963
 >> iter 12000, loss: 0.068992
 >> iter 13000, loss: 0.121073
 >> iter 14000, loss: 0.105117
 >> iter 15000, loss: 0.094018
 >> iter 16000, loss: 0.069743
 >> iter 17000, loss: 0.032749
 >> iter 18000, loss: 0.085175
 >> iter 19000, loss: 0.054926
 >> iter 20000, loss: 0.073905
   Number of active neurons: 10
 >> iter 21000, loss: 0.136902
 >> iter 22000, loss: 0.191455
 >> iter 23000, loss: 0.081352
 >> iter 24000, loss: 0.098374
 >> iter 25000, loss: 0.135531
 >> iter 26000, loss: 0.098600
 >> iter 27000, loss: 0.163122
 >> iter 28000, loss: 0.080825
 >> iter 29000, loss: 0.118927
 >> iter 30000, loss: 0.075611
   Number of active neurons: 10
 >> iter 31000, loss: 0.033821
 >> iter 32000, loss: 0.068490
 >> iter 33000, loss: 0.035684
 >> iter 34000, loss: 0.017998
 >> iter 35000, loss: 0.010539
 >> iter 36000, loss: 0.060537
 >> iter 37000, loss: 0.027799
 >> iter 38000, loss: 0.024379
 >> iter 39000, loss: 0.016520
 >> iter 40000, loss: 0.023043
   Number of active neurons: 10
 >> iter 41000, loss: 0.012299
 >> iter 42000, loss: 0.007369
 >> iter 43000, loss: 0.025968
 >> iter 44000, loss: 0.012720
 >> iter 45000, loss: 0.031139
 >> iter 46000, loss: 0.014221
 >> iter 47000, loss: 0.008285
 >> iter 48000, loss: 0.005612
 >> iter 49000, loss: 0.006238
 >> iter 50000, loss: 0.013047
   Number of active neurons: 10
 >> iter 51000, loss: 0.012153
 >> iter 52000, loss: 0.006690
 >> iter 53000, loss: 0.008829
 >> iter 54000, loss: 0.004847
 >> iter 55000, loss: 0.003978
 >> iter 56000, loss: 0.038262
 >> iter 57000, loss: 0.029028
 >> iter 58000, loss: 0.012631
 >> iter 59000, loss: 0.007254
 >> iter 60000, loss: 0.004411
   Number of active neurons: 10
 >> iter 61000, loss: 0.003783
 >> iter 62000, loss: 0.019206
 >> iter 63000, loss: 0.010013
 >> iter 64000, loss: 0.006342
 >> iter 65000, loss: 0.003773
 >> iter 66000, loss: 0.002640
 >> iter 67000, loss: 0.003115
 >> iter 68000, loss: 0.002429
 >> iter 69000, loss: 0.002517
 >> iter 70000, loss: 0.002741
   Number of active neurons: 10
 >> iter 71000, loss: 0.002095
 >> iter 72000, loss: 0.009126
 >> iter 73000, loss: 0.005568
 >> iter 74000, loss: 0.033182
 >> iter 75000, loss: 0.052171
 >> iter 76000, loss: 0.021405
 >> iter 77000, loss: 0.010096
 >> iter 78000, loss: 0.005272
 >> iter 79000, loss: 0.009421
 >> iter 80000, loss: 0.005948
   Number of active neurons: 10
 >> iter 81000, loss: 0.011205
 >> iter 82000, loss: 0.005107
 >> iter 83000, loss: 0.002942
 >> iter 84000, loss: 0.002041
 >> iter 85000, loss: 0.074986
 >> iter 86000, loss: 0.028884
 >> iter 87000, loss: 0.013242
 >> iter 88000, loss: 0.022346
 >> iter 89000, loss: 0.009591
 >> iter 90000, loss: 0.004935
   Number of active neurons: 10
 >> iter 91000, loss: 0.002978
 >> iter 92000, loss: 0.002592
 >> iter 93000, loss: 0.002915
 >> iter 94000, loss: 0.002064
 >> iter 95000, loss: 0.025360
 >> iter 96000, loss: 0.010394
 >> iter 97000, loss: 0.004872
 >> iter 98000, loss: 0.201770
 >> iter 99000, loss: 0.076313
 >> iter 100000, loss: 0.032057
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.130929
 >> iter 2000, loss: 12.216665
 >> iter 3000, loss: 6.026170
 >> iter 4000, loss: 2.935569
 >> iter 5000, loss: 1.516779
 >> iter 6000, loss: 0.721700
 >> iter 7000, loss: 0.378754
 >> iter 8000, loss: 0.214456
 >> iter 9000, loss: 0.228243
 >> iter 10000, loss: 0.169145
   Number of active neurons: 10
 >> iter 11000, loss: 0.133306
 >> iter 12000, loss: 0.293062
 >> iter 13000, loss: 0.156665
 >> iter 14000, loss: 0.178369
 >> iter 15000, loss: 0.143665
 >> iter 16000, loss: 0.065369
 >> iter 17000, loss: 0.078810
 >> iter 18000, loss: 0.055766
 >> iter 19000, loss: 0.031306
 >> iter 20000, loss: 0.031389
   Number of active neurons: 10
 >> iter 21000, loss: 0.033924
 >> iter 22000, loss: 0.029312
 >> iter 23000, loss: 0.016839
 >> iter 24000, loss: 0.101433
 >> iter 25000, loss: 0.057013
 >> iter 26000, loss: 0.027647
 >> iter 27000, loss: 0.043186
 >> iter 28000, loss: 0.028905
 >> iter 29000, loss: 0.015590
 >> iter 30000, loss: 0.009539
   Number of active neurons: 10
 >> iter 31000, loss: 0.007448
 >> iter 32000, loss: 0.006621
 >> iter 33000, loss: 0.007853
 >> iter 34000, loss: 0.017504
 >> iter 35000, loss: 0.047873
 >> iter 36000, loss: 0.034477
 >> iter 37000, loss: 0.019573
 >> iter 38000, loss: 0.010499
 >> iter 39000, loss: 0.006918
 >> iter 40000, loss: 0.005782
   Number of active neurons: 10
 >> iter 41000, loss: 0.006639
 >> iter 42000, loss: 0.014529
 >> iter 43000, loss: 0.013373
 >> iter 44000, loss: 0.007440
 >> iter 45000, loss: 0.005275
 >> iter 46000, loss: 0.006568
 >> iter 47000, loss: 0.004660
 >> iter 48000, loss: 0.003805
 >> iter 49000, loss: 0.003923
 >> iter 50000, loss: 0.003398
   Number of active neurons: 10
 >> iter 51000, loss: 0.003073
 >> iter 52000, loss: 0.007939
 >> iter 53000, loss: 0.004488
 >> iter 54000, loss: 0.003601
 >> iter 55000, loss: 0.003668
 >> iter 56000, loss: 0.004282
 >> iter 57000, loss: 0.018676
 >> iter 58000, loss: 0.008851
 >> iter 59000, loss: 0.004702
 >> iter 60000, loss: 0.003232
   Number of active neurons: 10
 >> iter 61000, loss: 0.002747
 >> iter 62000, loss: 0.007521
 >> iter 63000, loss: 0.012114
 >> iter 64000, loss: 0.019985
 >> iter 65000, loss: 0.008827
 >> iter 66000, loss: 0.005035
 >> iter 67000, loss: 0.003711
 >> iter 68000, loss: 0.004923
 >> iter 69000, loss: 0.020022
 >> iter 70000, loss: 0.068964
   Number of active neurons: 10
 >> iter 71000, loss: 0.028500
 >> iter 72000, loss: 0.064540
 >> iter 73000, loss: 0.025692
 >> iter 74000, loss: 0.035243
 >> iter 75000, loss: 0.023764
 >> iter 76000, loss: 0.010673
 >> iter 77000, loss: 0.021219
 >> iter 78000, loss: 0.009928
 >> iter 79000, loss: 0.041445
 >> iter 80000, loss: 0.031819
   Number of active neurons: 10
 >> iter 81000, loss: 0.069585
 >> iter 82000, loss: 0.061198
 >> iter 83000, loss: 0.025378
 >> iter 84000, loss: 0.012901
 >> iter 85000, loss: 0.006591
 >> iter 86000, loss: 0.004249
 >> iter 87000, loss: 0.002986
 >> iter 88000, loss: 0.002706
 >> iter 89000, loss: 0.002453
 >> iter 90000, loss: 0.003062
   Number of active neurons: 10
 >> iter 91000, loss: 0.003077
 >> iter 92000, loss: 0.002673
 >> iter 93000, loss: 0.003998
 >> iter 94000, loss: 0.010331
 >> iter 95000, loss: 0.023619
 >> iter 96000, loss: 0.011333
 >> iter 97000, loss: 0.005496
 >> iter 98000, loss: 0.003276
 >> iter 99000, loss: 0.002481
 >> iter 100000, loss: 0.002271
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.984122
 >> iter 2000, loss: 11.652426
 >> iter 3000, loss: 6.114958
 >> iter 4000, loss: 3.283404
 >> iter 5000, loss: 1.649087
 >> iter 6000, loss: 0.943981
 >> iter 7000, loss: 0.570822
 >> iter 8000, loss: 0.508616
 >> iter 9000, loss: 0.300411
 >> iter 10000, loss: 0.229870
   Number of active neurons: 10
 >> iter 11000, loss: 0.124675
 >> iter 12000, loss: 0.128763
 >> iter 13000, loss: 0.143607
 >> iter 14000, loss: 0.141204
 >> iter 15000, loss: 0.103061
 >> iter 16000, loss: 0.065015
 >> iter 17000, loss: 0.034217
 >> iter 18000, loss: 0.045777
 >> iter 19000, loss: 0.214462
 >> iter 20000, loss: 0.138787
   Number of active neurons: 10
 >> iter 21000, loss: 0.068883
 >> iter 22000, loss: 0.072787
 >> iter 23000, loss: 0.038806
 >> iter 24000, loss: 0.093907
 >> iter 25000, loss: 0.099095
 >> iter 26000, loss: 0.082587
 >> iter 27000, loss: 0.070566
 >> iter 28000, loss: 0.148929
 >> iter 29000, loss: 0.110712
 >> iter 30000, loss: 0.050679
   Number of active neurons: 10
 >> iter 31000, loss: 0.028135
 >> iter 32000, loss: 0.017621
 >> iter 33000, loss: 0.010905
 >> iter 34000, loss: 0.008522
 >> iter 35000, loss: 0.009109
 >> iter 36000, loss: 0.052562
 >> iter 37000, loss: 0.066308
 >> iter 38000, loss: 0.085695
 >> iter 39000, loss: 0.047249
 >> iter 40000, loss: 0.023678
   Number of active neurons: 10
 >> iter 41000, loss: 0.015683
 >> iter 42000, loss: 0.010954
 >> iter 43000, loss: 0.006834
 >> iter 44000, loss: 0.005341
 >> iter 45000, loss: 0.072986
 >> iter 46000, loss: 0.045729
 >> iter 47000, loss: 0.054504
 >> iter 48000, loss: 0.093819
 >> iter 49000, loss: 0.055053
 >> iter 50000, loss: 0.033990
   Number of active neurons: 10
 >> iter 51000, loss: 0.016024
 >> iter 52000, loss: 0.009986
 >> iter 53000, loss: 0.044173
 >> iter 54000, loss: 0.098503
 >> iter 55000, loss: 0.080737
 >> iter 56000, loss: 0.043961
 >> iter 57000, loss: 0.024718
 >> iter 58000, loss: 0.026059
 >> iter 59000, loss: 0.017052
 >> iter 60000, loss: 0.010040
   Number of active neurons: 10
 >> iter 61000, loss: 0.040992
 >> iter 62000, loss: 0.018625
 >> iter 63000, loss: 0.008985
 >> iter 64000, loss: 0.007039
 >> iter 65000, loss: 0.037617
 >> iter 66000, loss: 0.064616
 >> iter 67000, loss: 0.028241
 >> iter 68000, loss: 0.042059
 >> iter 69000, loss: 0.021059
 >> iter 70000, loss: 0.068318
   Number of active neurons: 10
 >> iter 71000, loss: 0.051781
 >> iter 72000, loss: 0.039364
 >> iter 73000, loss: 0.017060
 >> iter 74000, loss: 0.023420
 >> iter 75000, loss: 0.024715
 >> iter 76000, loss: 0.011436
 >> iter 77000, loss: 0.010699
 >> iter 78000, loss: 0.006116
 >> iter 79000, loss: 0.004206
 >> iter 80000, loss: 0.002982
   Number of active neurons: 10
 >> iter 81000, loss: 0.011397
 >> iter 82000, loss: 0.007240
 >> iter 83000, loss: 0.006836
 >> iter 84000, loss: 0.009955
 >> iter 85000, loss: 0.040162
 >> iter 86000, loss: 0.021078
 >> iter 87000, loss: 0.019696
 >> iter 88000, loss: 0.039655
 >> iter 89000, loss: 0.021254
 >> iter 90000, loss: 0.009304
   Number of active neurons: 10
 >> iter 91000, loss: 0.005406
 >> iter 92000, loss: 0.018041
 >> iter 93000, loss: 0.008401
 >> iter 94000, loss: 0.004430
 >> iter 95000, loss: 0.004377
 >> iter 96000, loss: 0.003863
 >> iter 97000, loss: 0.003424
 >> iter 98000, loss: 0.013568
 >> iter 99000, loss: 0.082887
 >> iter 100000, loss: 0.053454
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.999887
 >> iter 2000, loss: 11.100283
 >> iter 3000, loss: 5.249076
 >> iter 4000, loss: 2.683414
 >> iter 5000, loss: 1.428826
 >> iter 6000, loss: 0.718039
 >> iter 7000, loss: 0.468584
 >> iter 8000, loss: 0.367140
 >> iter 9000, loss: 0.189826
 >> iter 10000, loss: 0.085458
   Number of active neurons: 10
 >> iter 11000, loss: 0.130679
 >> iter 12000, loss: 0.066318
 >> iter 13000, loss: 0.035951
 >> iter 14000, loss: 0.034435
 >> iter 15000, loss: 0.124048
 >> iter 16000, loss: 0.156179
 >> iter 17000, loss: 0.065428
 >> iter 18000, loss: 0.038403
 >> iter 19000, loss: 0.020756
 >> iter 20000, loss: 0.024313
   Number of active neurons: 10
 >> iter 21000, loss: 0.014373
 >> iter 22000, loss: 0.011032
 >> iter 23000, loss: 0.011193
 >> iter 24000, loss: 0.051425
 >> iter 25000, loss: 0.035616
 >> iter 26000, loss: 0.017172
 >> iter 27000, loss: 0.015793
 >> iter 28000, loss: 0.029624
 >> iter 29000, loss: 0.013400
 >> iter 30000, loss: 0.015136
   Number of active neurons: 10
 >> iter 31000, loss: 0.014035
 >> iter 32000, loss: 0.009055
 >> iter 33000, loss: 0.056869
 >> iter 34000, loss: 0.023549
 >> iter 35000, loss: 0.094753
 >> iter 36000, loss: 0.072301
 >> iter 37000, loss: 0.053370
 >> iter 38000, loss: 0.024133
 >> iter 39000, loss: 0.012120
 >> iter 40000, loss: 0.006689
   Number of active neurons: 10
 >> iter 41000, loss: 0.033649
 >> iter 42000, loss: 0.016919
 >> iter 43000, loss: 0.022927
 >> iter 44000, loss: 0.010465
 >> iter 45000, loss: 0.014136
 >> iter 46000, loss: 0.007122
 >> iter 47000, loss: 0.017249
 >> iter 48000, loss: 0.025927
 >> iter 49000, loss: 0.012030
 >> iter 50000, loss: 0.014087
   Number of active neurons: 10
 >> iter 51000, loss: 0.006751
 >> iter 52000, loss: 0.003803
 >> iter 53000, loss: 0.002770
 >> iter 54000, loss: 0.002412
 >> iter 55000, loss: 0.002171
 >> iter 56000, loss: 0.001912
 >> iter 57000, loss: 0.001766
 >> iter 58000, loss: 0.001731
 >> iter 59000, loss: 0.002805
 >> iter 60000, loss: 0.002215
   Number of active neurons: 10
 >> iter 61000, loss: 0.017211
 >> iter 62000, loss: 0.012548
 >> iter 63000, loss: 0.005687
 >> iter 64000, loss: 0.003219
 >> iter 65000, loss: 0.007707
 >> iter 66000, loss: 0.004157
 >> iter 67000, loss: 0.003834
 >> iter 68000, loss: 0.008085
 >> iter 69000, loss: 0.003989
 >> iter 70000, loss: 0.002459
   Number of active neurons: 10
 >> iter 71000, loss: 0.001753
 >> iter 72000, loss: 0.005066
 >> iter 73000, loss: 0.002921
 >> iter 74000, loss: 0.002090
 >> iter 75000, loss: 0.001549
 >> iter 76000, loss: 0.001260
 >> iter 77000, loss: 0.002884
 >> iter 78000, loss: 0.002025
 >> iter 79000, loss: 0.001469
 >> iter 80000, loss: 0.001202
   Number of active neurons: 10
 >> iter 81000, loss: 0.001163
 >> iter 82000, loss: 0.001368
 >> iter 83000, loss: 0.001367
 >> iter 84000, loss: 0.001223
 >> iter 85000, loss: 0.001214
 >> iter 86000, loss: 0.001671
 >> iter 87000, loss: 0.001389
 >> iter 88000, loss: 0.001579
 >> iter 89000, loss: 0.001204
 >> iter 90000, loss: 0.001486
   Number of active neurons: 10
 >> iter 91000, loss: 0.001053
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.033182
 >> iter 2000, loss: 11.214417
 >> iter 3000, loss: 5.164239
 >> iter 4000, loss: 2.200828
 >> iter 5000, loss: 0.977086
 >> iter 6000, loss: 0.524823
 >> iter 7000, loss: 0.293573
 >> iter 8000, loss: 0.171094
 >> iter 9000, loss: 0.213954
 >> iter 10000, loss: 0.097790
   Number of active neurons: 10
 >> iter 11000, loss: 0.065681
 >> iter 12000, loss: 0.080150
 >> iter 13000, loss: 0.042934
 >> iter 14000, loss: 0.022304
 >> iter 15000, loss: 0.055581
 >> iter 16000, loss: 0.056384
 >> iter 17000, loss: 0.196567
 >> iter 18000, loss: 0.143316
 >> iter 19000, loss: 0.136570
 >> iter 20000, loss: 0.063608
   Number of active neurons: 10
 >> iter 21000, loss: 0.034319
 >> iter 22000, loss: 0.030877
 >> iter 23000, loss: 0.121285
 >> iter 24000, loss: 0.061230
 >> iter 25000, loss: 0.102288
 >> iter 26000, loss: 0.047765
 >> iter 27000, loss: 0.022714
 >> iter 28000, loss: 0.013594
 >> iter 29000, loss: 0.011056
 >> iter 30000, loss: 0.009344
   Number of active neurons: 10
 >> iter 31000, loss: 0.020769
 >> iter 32000, loss: 0.236976
 >> iter 33000, loss: 0.092380
 >> iter 34000, loss: 0.040229
 >> iter 35000, loss: 0.023187
 >> iter 36000, loss: 0.048766
 >> iter 37000, loss: 0.021574
 >> iter 38000, loss: 0.047873
 >> iter 39000, loss: 0.021104
 >> iter 40000, loss: 0.010789
   Number of active neurons: 10
 >> iter 41000, loss: 0.006266
 >> iter 42000, loss: 0.018489
 >> iter 43000, loss: 0.012772
 >> iter 44000, loss: 0.084449
 >> iter 45000, loss: 0.130451
 >> iter 46000, loss: 0.070755
 >> iter 47000, loss: 0.028758
 >> iter 48000, loss: 0.047358
 >> iter 49000, loss: 0.024459
 >> iter 50000, loss: 0.011456
   Number of active neurons: 10
 >> iter 51000, loss: 0.013844
 >> iter 52000, loss: 0.056634
 >> iter 53000, loss: 0.023389
 >> iter 54000, loss: 0.010796
 >> iter 55000, loss: 0.006094
 >> iter 56000, loss: 0.004092
 >> iter 57000, loss: 0.003214
 >> iter 58000, loss: 0.004479
 >> iter 59000, loss: 0.093198
 >> iter 60000, loss: 0.039757
   Number of active neurons: 10
 >> iter 61000, loss: 0.016172
 >> iter 62000, loss: 0.007546
 >> iter 63000, loss: 0.019946
 >> iter 64000, loss: 0.009920
 >> iter 65000, loss: 0.004936
 >> iter 66000, loss: 0.003462
 >> iter 67000, loss: 0.002509
 >> iter 68000, loss: 0.002398
 >> iter 69000, loss: 0.001973
 >> iter 70000, loss: 0.001927
   Number of active neurons: 10
 >> iter 71000, loss: 0.010545
 >> iter 72000, loss: 0.004845
 >> iter 73000, loss: 0.002891
 >> iter 74000, loss: 0.018614
 >> iter 75000, loss: 0.008861
 >> iter 76000, loss: 0.014345
 >> iter 77000, loss: 0.007405
 >> iter 78000, loss: 0.003947
 >> iter 79000, loss: 0.002656
 >> iter 80000, loss: 0.002086
   Number of active neurons: 10
 >> iter 81000, loss: 0.003466
 >> iter 82000, loss: 0.003046
 >> iter 83000, loss: 0.002040
 >> iter 84000, loss: 0.001941
 >> iter 85000, loss: 0.014463
 >> iter 86000, loss: 0.028752
 >> iter 87000, loss: 0.047406
 >> iter 88000, loss: 0.019472
 >> iter 89000, loss: 0.012348
 >> iter 90000, loss: 0.080808
   Number of active neurons: 10
 >> iter 91000, loss: 0.040708
 >> iter 92000, loss: 0.016351
 >> iter 93000, loss: 0.007920
 >> iter 94000, loss: 0.004209
 >> iter 95000, loss: 0.002776
 >> iter 96000, loss: 0.002018
 >> iter 97000, loss: 0.001701
 >> iter 98000, loss: 0.002817
 >> iter 99000, loss: 0.101053
 >> iter 100000, loss: 0.038771
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.051661
 >> iter 2000, loss: 11.042338
 >> iter 3000, loss: 4.842339
 >> iter 4000, loss: 2.287443
 >> iter 5000, loss: 1.109241
 >> iter 6000, loss: 0.541605
 >> iter 7000, loss: 0.337454
 >> iter 8000, loss: 0.168507
 >> iter 9000, loss: 0.096794
 >> iter 10000, loss: 0.119331
   Number of active neurons: 10
 >> iter 11000, loss: 0.078160
 >> iter 12000, loss: 0.045395
 >> iter 13000, loss: 0.025784
 >> iter 14000, loss: 0.039689
 >> iter 15000, loss: 0.027683
 >> iter 16000, loss: 0.061520
 >> iter 17000, loss: 0.091104
 >> iter 18000, loss: 0.116800
 >> iter 19000, loss: 0.145439
 >> iter 20000, loss: 0.091496
   Number of active neurons: 10
 >> iter 21000, loss: 0.046940
 >> iter 22000, loss: 0.031826
 >> iter 23000, loss: 0.078901
 >> iter 24000, loss: 0.088646
 >> iter 25000, loss: 0.079795
 >> iter 26000, loss: 0.034428
 >> iter 27000, loss: 0.020704
 >> iter 28000, loss: 0.015541
 >> iter 29000, loss: 0.081717
 >> iter 30000, loss: 0.034549
   Number of active neurons: 10
 >> iter 31000, loss: 0.017246
 >> iter 32000, loss: 0.009992
 >> iter 33000, loss: 0.028865
 >> iter 34000, loss: 0.013786
 >> iter 35000, loss: 0.007867
 >> iter 36000, loss: 0.005478
 >> iter 37000, loss: 0.009403
 >> iter 38000, loss: 0.006805
 >> iter 39000, loss: 0.014944
 >> iter 40000, loss: 0.008214
   Number of active neurons: 10
 >> iter 41000, loss: 0.006595
 >> iter 42000, loss: 0.005070
 >> iter 43000, loss: 0.003441
 >> iter 44000, loss: 0.019013
 >> iter 45000, loss: 0.023636
 >> iter 46000, loss: 0.057270
 >> iter 47000, loss: 0.023497
 >> iter 48000, loss: 0.055417
 >> iter 49000, loss: 0.022690
 >> iter 50000, loss: 0.011459
   Number of active neurons: 10
 >> iter 51000, loss: 0.038082
 >> iter 52000, loss: 0.016786
 >> iter 53000, loss: 0.050696
 >> iter 54000, loss: 0.023686
 >> iter 55000, loss: 0.010603
 >> iter 56000, loss: 0.010530
 >> iter 57000, loss: 0.005912
 >> iter 58000, loss: 0.003615
 >> iter 59000, loss: 0.003125
 >> iter 60000, loss: 0.002407
   Number of active neurons: 10
 >> iter 61000, loss: 0.117433
 >> iter 62000, loss: 0.045652
 >> iter 63000, loss: 0.018919
 >> iter 64000, loss: 0.008605
 >> iter 65000, loss: 0.004786
 >> iter 66000, loss: 0.003055
 >> iter 67000, loss: 0.008224
 >> iter 68000, loss: 0.004331
 >> iter 69000, loss: 0.002741
 >> iter 70000, loss: 0.002044
   Number of active neurons: 10
 >> iter 71000, loss: 0.021962
 >> iter 72000, loss: 0.012647
 >> iter 73000, loss: 0.044171
 >> iter 74000, loss: 0.018142
 >> iter 75000, loss: 0.008271
 >> iter 76000, loss: 0.004351
 >> iter 77000, loss: 0.002864
 >> iter 78000, loss: 0.013927
 >> iter 79000, loss: 0.038550
 >> iter 80000, loss: 0.017364
   Number of active neurons: 10
 >> iter 81000, loss: 0.075294
 >> iter 82000, loss: 0.029800
 >> iter 83000, loss: 0.012427
 >> iter 84000, loss: 0.034576
 >> iter 85000, loss: 0.014376
 >> iter 86000, loss: 0.006953
 >> iter 87000, loss: 0.004085
 >> iter 88000, loss: 0.002642
 >> iter 89000, loss: 0.001949
 >> iter 90000, loss: 0.105289
   Number of active neurons: 10
 >> iter 91000, loss: 0.040981
 >> iter 92000, loss: 0.016262
 >> iter 93000, loss: 0.007071
 >> iter 94000, loss: 0.004123
 >> iter 95000, loss: 0.002598
 >> iter 96000, loss: 0.002151
 >> iter 97000, loss: 0.055162
 >> iter 98000, loss: 0.022016
 >> iter 99000, loss: 0.009244
 >> iter 100000, loss: 0.008217
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.122757
 >> iter 2000, loss: 12.296930
 >> iter 3000, loss: 5.743391
 >> iter 4000, loss: 2.510653
 >> iter 5000, loss: 1.247428
 >> iter 6000, loss: 0.693083
 >> iter 7000, loss: 0.383436
 >> iter 8000, loss: 0.193959
 >> iter 9000, loss: 0.119355
 >> iter 10000, loss: 0.178075
   Number of active neurons: 10
 >> iter 11000, loss: 0.287978
 >> iter 12000, loss: 0.176823
 >> iter 13000, loss: 0.114690
 >> iter 14000, loss: 0.128166
 >> iter 15000, loss: 0.060439
 >> iter 16000, loss: 0.056654
 >> iter 17000, loss: 0.046031
 >> iter 18000, loss: 0.101893
 >> iter 19000, loss: 0.097762
 >> iter 20000, loss: 0.044083
   Number of active neurons: 10
 >> iter 21000, loss: 0.022202
 >> iter 22000, loss: 0.035299
 >> iter 23000, loss: 0.026349
 >> iter 24000, loss: 0.014576
 >> iter 25000, loss: 0.009297
 >> iter 26000, loss: 0.007169
 >> iter 27000, loss: 0.037862
 >> iter 28000, loss: 0.059265
 >> iter 29000, loss: 0.028562
 >> iter 30000, loss: 0.016371
   Number of active neurons: 10
 >> iter 31000, loss: 0.111919
 >> iter 32000, loss: 0.094128
 >> iter 33000, loss: 0.114659
 >> iter 34000, loss: 0.048081
 >> iter 35000, loss: 0.021850
 >> iter 36000, loss: 0.071157
 >> iter 37000, loss: 0.029524
 >> iter 38000, loss: 0.013822
 >> iter 39000, loss: 0.008373
 >> iter 40000, loss: 0.005715
   Number of active neurons: 10
 >> iter 41000, loss: 0.052293
 >> iter 42000, loss: 0.039721
 >> iter 43000, loss: 0.094903
 >> iter 44000, loss: 0.107872
 >> iter 45000, loss: 0.156000
 >> iter 46000, loss: 0.066423
 >> iter 47000, loss: 0.028392
 >> iter 48000, loss: 0.014378
 >> iter 49000, loss: 0.008429
 >> iter 50000, loss: 0.005521
   Number of active neurons: 10
 >> iter 51000, loss: 0.004343
 >> iter 52000, loss: 0.003836
 >> iter 53000, loss: 0.055976
 >> iter 54000, loss: 0.022933
 >> iter 55000, loss: 0.023039
 >> iter 56000, loss: 0.010694
 >> iter 57000, loss: 0.005939
 >> iter 58000, loss: 0.051442
 >> iter 59000, loss: 0.022036
 >> iter 60000, loss: 0.010431
   Number of active neurons: 10
 >> iter 61000, loss: 0.005781
 >> iter 62000, loss: 0.003965
 >> iter 63000, loss: 0.007248
 >> iter 64000, loss: 0.004256
 >> iter 65000, loss: 0.003198
 >> iter 66000, loss: 0.002639
 >> iter 67000, loss: 0.005332
 >> iter 68000, loss: 0.106247
 >> iter 69000, loss: 0.049118
 >> iter 70000, loss: 0.020609
   Number of active neurons: 10
 >> iter 71000, loss: 0.017427
 >> iter 72000, loss: 0.008555
 >> iter 73000, loss: 0.004705
 >> iter 74000, loss: 0.003500
 >> iter 75000, loss: 0.040933
 >> iter 76000, loss: 0.016905
 >> iter 77000, loss: 0.012791
 >> iter 78000, loss: 0.006246
 >> iter 79000, loss: 0.003823
 >> iter 80000, loss: 0.003299
   Number of active neurons: 10
 >> iter 81000, loss: 0.002422
 >> iter 82000, loss: 0.002171
 >> iter 83000, loss: 0.002076
 >> iter 84000, loss: 0.002541
 >> iter 85000, loss: 0.037351
 >> iter 86000, loss: 0.061866
 >> iter 87000, loss: 0.030818
 >> iter 88000, loss: 0.013060
 >> iter 89000, loss: 0.006495
 >> iter 90000, loss: 0.003744
   Number of active neurons: 10
 >> iter 91000, loss: 0.029969
 >> iter 92000, loss: 0.012230
 >> iter 93000, loss: 0.005785
 >> iter 94000, loss: 0.003311
 >> iter 95000, loss: 0.002280
 >> iter 96000, loss: 0.008495
 >> iter 97000, loss: 0.030866
 >> iter 98000, loss: 0.037410
 >> iter 99000, loss: 0.015295
 >> iter 100000, loss: 0.007420
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.917472
 >> iter 2000, loss: 12.499107
 >> iter 3000, loss: 6.443102
 >> iter 4000, loss: 2.753246
 >> iter 5000, loss: 1.499244
 >> iter 6000, loss: 0.824793
 >> iter 7000, loss: 0.455808
 >> iter 8000, loss: 0.290470
 >> iter 9000, loss: 0.310318
 >> iter 10000, loss: 0.136991
   Number of active neurons: 10
 >> iter 11000, loss: 0.164813
 >> iter 12000, loss: 0.085736
 >> iter 13000, loss: 0.096365
 >> iter 14000, loss: 0.048493
 >> iter 15000, loss: 0.079567
 >> iter 16000, loss: 0.166632
 >> iter 17000, loss: 0.095313
 >> iter 18000, loss: 0.238429
 >> iter 19000, loss: 0.103126
 >> iter 20000, loss: 0.047462
   Number of active neurons: 10
 >> iter 21000, loss: 0.029848
 >> iter 22000, loss: 0.050066
 >> iter 23000, loss: 0.058010
 >> iter 24000, loss: 0.032551
 >> iter 25000, loss: 0.017540
 >> iter 26000, loss: 0.031173
 >> iter 27000, loss: 0.051519
 >> iter 28000, loss: 0.025574
 >> iter 29000, loss: 0.014880
 >> iter 30000, loss: 0.037602
   Number of active neurons: 10
 >> iter 31000, loss: 0.039661
 >> iter 32000, loss: 0.024637
 >> iter 33000, loss: 0.013608
 >> iter 34000, loss: 0.117090
 >> iter 35000, loss: 0.126629
 >> iter 36000, loss: 0.052215
 >> iter 37000, loss: 0.023858
 >> iter 38000, loss: 0.012774
 >> iter 39000, loss: 0.025102
 >> iter 40000, loss: 0.012996
   Number of active neurons: 10
 >> iter 41000, loss: 0.057650
 >> iter 42000, loss: 0.024834
 >> iter 43000, loss: 0.013374
 >> iter 44000, loss: 0.008580
 >> iter 45000, loss: 0.083079
 >> iter 46000, loss: 0.034423
 >> iter 47000, loss: 0.015517
 >> iter 48000, loss: 0.008768
 >> iter 49000, loss: 0.005975
 >> iter 50000, loss: 0.004366
   Number of active neurons: 10
 >> iter 51000, loss: 0.003927
 >> iter 52000, loss: 0.030380
 >> iter 53000, loss: 0.013716
 >> iter 54000, loss: 0.007181
 >> iter 55000, loss: 0.030033
 >> iter 56000, loss: 0.021443
 >> iter 57000, loss: 0.009983
 >> iter 58000, loss: 0.006058
 >> iter 59000, loss: 0.062103
 >> iter 60000, loss: 0.049804
   Number of active neurons: 10
 >> iter 61000, loss: 0.021312
 >> iter 62000, loss: 0.021886
 >> iter 63000, loss: 0.010206
 >> iter 64000, loss: 0.005417
 >> iter 65000, loss: 0.004571
 >> iter 66000, loss: 0.003529
 >> iter 67000, loss: 0.003057
 >> iter 68000, loss: 0.020063
 >> iter 69000, loss: 0.010646
 >> iter 70000, loss: 0.009776
   Number of active neurons: 10
 >> iter 71000, loss: 0.093104
 >> iter 72000, loss: 0.054324
 >> iter 73000, loss: 0.022449
 >> iter 74000, loss: 0.009959
 >> iter 75000, loss: 0.014693
 >> iter 76000, loss: 0.007655
 >> iter 77000, loss: 0.064931
 >> iter 78000, loss: 0.025944
 >> iter 79000, loss: 0.011434
 >> iter 80000, loss: 0.010452
   Number of active neurons: 10
 >> iter 81000, loss: 0.044996
 >> iter 82000, loss: 0.018838
 >> iter 83000, loss: 0.010412
 >> iter 84000, loss: 0.028076
 >> iter 85000, loss: 0.012288
 >> iter 86000, loss: 0.006265
 >> iter 87000, loss: 0.003968
 >> iter 88000, loss: 0.002875
 >> iter 89000, loss: 0.007925
 >> iter 90000, loss: 0.014663
   Number of active neurons: 10
 >> iter 91000, loss: 0.006826
 >> iter 92000, loss: 0.016418
 >> iter 93000, loss: 0.072304
 >> iter 94000, loss: 0.029455
 >> iter 95000, loss: 0.013659
 >> iter 96000, loss: 0.007226
 >> iter 97000, loss: 0.004496
 >> iter 98000, loss: 0.003022
 >> iter 99000, loss: 0.002445
 >> iter 100000, loss: 0.002356
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.256525
 >> iter 2000, loss: 13.589204
 >> iter 3000, loss: 7.219155
 >> iter 4000, loss: 3.666065
 >> iter 5000, loss: 1.889207
 >> iter 6000, loss: 1.256538
 >> iter 7000, loss: 0.870191
 >> iter 8000, loss: 0.542637
 >> iter 9000, loss: 0.475596
 >> iter 10000, loss: 0.244151
   Number of active neurons: 10
 >> iter 11000, loss: 0.350686
 >> iter 12000, loss: 0.212414
 >> iter 13000, loss: 0.164745
 >> iter 14000, loss: 0.229232
 >> iter 15000, loss: 0.181995
 >> iter 16000, loss: 0.095734
 >> iter 17000, loss: 0.143134
 >> iter 18000, loss: 0.090766
 >> iter 19000, loss: 0.187248
 >> iter 20000, loss: 0.130008
   Number of active neurons: 10
 >> iter 21000, loss: 0.063979
 >> iter 22000, loss: 0.172261
 >> iter 23000, loss: 0.116910
 >> iter 24000, loss: 0.054185
 >> iter 25000, loss: 0.076535
 >> iter 26000, loss: 0.108133
 >> iter 27000, loss: 0.225319
 >> iter 28000, loss: 0.155472
 >> iter 29000, loss: 0.127855
 >> iter 30000, loss: 0.061338
   Number of active neurons: 10
 >> iter 31000, loss: 0.141027
 >> iter 32000, loss: 0.181081
 >> iter 33000, loss: 0.121480
 >> iter 34000, loss: 0.131404
 >> iter 35000, loss: 0.084971
 >> iter 36000, loss: 0.105821
 >> iter 37000, loss: 0.045828
 >> iter 38000, loss: 0.076220
 >> iter 39000, loss: 0.060819
 >> iter 40000, loss: 0.142780
   Number of active neurons: 10
 >> iter 41000, loss: 0.105455
 >> iter 42000, loss: 0.048416
 >> iter 43000, loss: 0.036741
 >> iter 44000, loss: 0.098140
 >> iter 45000, loss: 0.053724
 >> iter 46000, loss: 0.026917
 >> iter 47000, loss: 0.025016
 >> iter 48000, loss: 0.016336
 >> iter 49000, loss: 0.055412
 >> iter 50000, loss: 0.029641
   Number of active neurons: 10
 >> iter 51000, loss: 0.023771
 >> iter 52000, loss: 0.018919
 >> iter 53000, loss: 0.014723
 >> iter 54000, loss: 0.018147
 >> iter 55000, loss: 0.139971
 >> iter 56000, loss: 0.068096
 >> iter 57000, loss: 0.050113
 >> iter 58000, loss: 0.025159
 >> iter 59000, loss: 0.012164
 >> iter 60000, loss: 0.007251
   Number of active neurons: 10
 >> iter 61000, loss: 0.054233
 >> iter 62000, loss: 0.028500
 >> iter 63000, loss: 0.068297
 >> iter 64000, loss: 0.030340
 >> iter 65000, loss: 0.045684
 >> iter 66000, loss: 0.115167
 >> iter 67000, loss: 0.046131
 >> iter 68000, loss: 0.054348
 >> iter 69000, loss: 0.023622
 >> iter 70000, loss: 0.011070
   Number of active neurons: 10
 >> iter 71000, loss: 0.027890
 >> iter 72000, loss: 0.014842
 >> iter 73000, loss: 0.059741
 >> iter 74000, loss: 0.025983
 >> iter 75000, loss: 0.065570
 >> iter 76000, loss: 0.038693
 >> iter 77000, loss: 0.023327
 >> iter 78000, loss: 0.011289
 >> iter 79000, loss: 0.008871
 >> iter 80000, loss: 0.017734
   Number of active neurons: 10
 >> iter 81000, loss: 0.030147
 >> iter 82000, loss: 0.013339
 >> iter 83000, loss: 0.009977
 >> iter 84000, loss: 0.006695
 >> iter 85000, loss: 0.004305
 >> iter 86000, loss: 0.006667
 >> iter 87000, loss: 0.081815
 >> iter 88000, loss: 0.054878
 >> iter 89000, loss: 0.056116
 >> iter 90000, loss: 0.023965
   Number of active neurons: 10
 >> iter 91000, loss: 0.023827
 >> iter 92000, loss: 0.012649
 >> iter 93000, loss: 0.006826
 >> iter 94000, loss: 0.050720
 >> iter 95000, loss: 0.042353
 >> iter 96000, loss: 0.027153
 >> iter 97000, loss: 0.025917
 >> iter 98000, loss: 0.011826
 >> iter 99000, loss: 0.007162
 >> iter 100000, loss: 0.004674
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.218384
 >> iter 2000, loss: 11.430014
 >> iter 3000, loss: 5.210872
 >> iter 4000, loss: 2.348205
 >> iter 5000, loss: 1.277497
 >> iter 6000, loss: 0.670756
 >> iter 7000, loss: 0.402421
 >> iter 8000, loss: 0.259880
 >> iter 9000, loss: 0.216274
 >> iter 10000, loss: 0.254161
   Number of active neurons: 10
 >> iter 11000, loss: 0.230433
 >> iter 12000, loss: 0.096373
 >> iter 13000, loss: 0.125006
 >> iter 14000, loss: 0.077841
 >> iter 15000, loss: 0.076410
 >> iter 16000, loss: 0.049849
 >> iter 17000, loss: 0.048899
 >> iter 18000, loss: 0.167610
 >> iter 19000, loss: 0.082561
 >> iter 20000, loss: 0.035348
   Number of active neurons: 10
 >> iter 21000, loss: 0.026397
 >> iter 22000, loss: 0.024989
 >> iter 23000, loss: 0.016533
 >> iter 24000, loss: 0.010254
 >> iter 25000, loss: 0.034405
 >> iter 26000, loss: 0.021747
 >> iter 27000, loss: 0.042141
 >> iter 28000, loss: 0.046564
 >> iter 29000, loss: 0.021613
 >> iter 30000, loss: 0.070705
   Number of active neurons: 10
 >> iter 31000, loss: 0.029039
 >> iter 32000, loss: 0.013085
 >> iter 33000, loss: 0.006806
 >> iter 34000, loss: 0.051142
 >> iter 35000, loss: 0.021469
 >> iter 36000, loss: 0.010644
 >> iter 37000, loss: 0.005836
 >> iter 38000, loss: 0.003876
 >> iter 39000, loss: 0.003143
 >> iter 40000, loss: 0.003027
   Number of active neurons: 10
 >> iter 41000, loss: 0.002859
 >> iter 42000, loss: 0.006298
 >> iter 43000, loss: 0.014566
 >> iter 44000, loss: 0.007358
 >> iter 45000, loss: 0.004215
 >> iter 46000, loss: 0.030506
 >> iter 47000, loss: 0.013038
 >> iter 48000, loss: 0.012849
 >> iter 49000, loss: 0.011507
 >> iter 50000, loss: 0.031400
   Number of active neurons: 10
 >> iter 51000, loss: 0.013273
 >> iter 52000, loss: 0.036568
 >> iter 53000, loss: 0.019733
 >> iter 54000, loss: 0.008691
 >> iter 55000, loss: 0.004649
 >> iter 56000, loss: 0.005707
 >> iter 57000, loss: 0.030515
 >> iter 58000, loss: 0.021205
 >> iter 59000, loss: 0.009465
 >> iter 60000, loss: 0.004716
   Number of active neurons: 10
 >> iter 61000, loss: 0.002808
 >> iter 62000, loss: 0.002199
 >> iter 63000, loss: 0.001844
 >> iter 64000, loss: 0.001627
 >> iter 65000, loss: 0.022899
 >> iter 66000, loss: 0.054251
 >> iter 67000, loss: 0.022538
 >> iter 68000, loss: 0.011360
 >> iter 69000, loss: 0.010595
 >> iter 70000, loss: 0.038791
   Number of active neurons: 10
 >> iter 71000, loss: 0.046831
 >> iter 72000, loss: 0.039072
 >> iter 73000, loss: 0.016167
 >> iter 74000, loss: 0.039975
 >> iter 75000, loss: 0.019191
 >> iter 76000, loss: 0.008582
 >> iter 77000, loss: 0.004393
 >> iter 78000, loss: 0.002695
 >> iter 79000, loss: 0.002055
 >> iter 80000, loss: 0.001771
   Number of active neurons: 10
 >> iter 81000, loss: 0.001637
 >> iter 82000, loss: 0.001661
 >> iter 83000, loss: 0.001585
 >> iter 84000, loss: 0.001415
 >> iter 85000, loss: 0.001361
 >> iter 86000, loss: 0.001440
 >> iter 87000, loss: 0.001298
 >> iter 88000, loss: 0.001682
 >> iter 89000, loss: 0.001345
 >> iter 90000, loss: 0.001257
   Number of active neurons: 10
 >> iter 91000, loss: 0.003913
 >> iter 92000, loss: 0.030047
 >> iter 93000, loss: 0.060458
 >> iter 94000, loss: 0.023433
 >> iter 95000, loss: 0.009805
 >> iter 96000, loss: 0.004661
 >> iter 97000, loss: 0.002586
 >> iter 98000, loss: 0.001744
 >> iter 99000, loss: 0.001651
 >> iter 100000, loss: 0.001527
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.337515
 >> iter 2000, loss: 14.202243
 >> iter 3000, loss: 8.478780
 >> iter 4000, loss: 4.075460
 >> iter 5000, loss: 1.896330
 >> iter 6000, loss: 1.252784
 >> iter 7000, loss: 0.672578
 >> iter 8000, loss: 0.462683
 >> iter 9000, loss: 0.472583
 >> iter 10000, loss: 0.299502
   Number of active neurons: 10
 >> iter 11000, loss: 0.186288
 >> iter 12000, loss: 0.339981
 >> iter 13000, loss: 0.175927
 >> iter 14000, loss: 0.207763
 >> iter 15000, loss: 0.281887
 >> iter 16000, loss: 0.152621
 >> iter 17000, loss: 0.158522
 >> iter 18000, loss: 0.117552
 >> iter 19000, loss: 0.115183
 >> iter 20000, loss: 0.090695
   Number of active neurons: 10
 >> iter 21000, loss: 0.214193
 >> iter 22000, loss: 0.167128
 >> iter 23000, loss: 0.072079
 >> iter 24000, loss: 0.086256
 >> iter 25000, loss: 0.115970
 >> iter 26000, loss: 0.099619
 >> iter 27000, loss: 0.043492
 >> iter 28000, loss: 0.050504
 >> iter 29000, loss: 0.059039
 >> iter 30000, loss: 0.072270
   Number of active neurons: 10
 >> iter 31000, loss: 0.034301
 >> iter 32000, loss: 0.036147
 >> iter 33000, loss: 0.022258
 >> iter 34000, loss: 0.037161
 >> iter 35000, loss: 0.069678
 >> iter 36000, loss: 0.041170
 >> iter 37000, loss: 0.024458
 >> iter 38000, loss: 0.028731
 >> iter 39000, loss: 0.024206
 >> iter 40000, loss: 0.039996
   Number of active neurons: 10
 >> iter 41000, loss: 0.022674
 >> iter 42000, loss: 0.015847
 >> iter 43000, loss: 0.017420
 >> iter 44000, loss: 0.021825
 >> iter 45000, loss: 0.065380
 >> iter 46000, loss: 0.077637
 >> iter 47000, loss: 0.068863
 >> iter 48000, loss: 0.062376
 >> iter 49000, loss: 0.026767
 >> iter 50000, loss: 0.012919
   Number of active neurons: 10
 >> iter 51000, loss: 0.009144
 >> iter 52000, loss: 0.005932
 >> iter 53000, loss: 0.009587
 >> iter 54000, loss: 0.005445
 >> iter 55000, loss: 0.011791
 >> iter 56000, loss: 0.040796
 >> iter 57000, loss: 0.021831
 >> iter 58000, loss: 0.088106
 >> iter 59000, loss: 0.047515
 >> iter 60000, loss: 0.068195
   Number of active neurons: 10
 >> iter 61000, loss: 0.027870
 >> iter 62000, loss: 0.012782
 >> iter 63000, loss: 0.006704
 >> iter 64000, loss: 0.007708
 >> iter 65000, loss: 0.004477
 >> iter 66000, loss: 0.003310
 >> iter 67000, loss: 0.019216
 >> iter 68000, loss: 0.010177
 >> iter 69000, loss: 0.009336
 >> iter 70000, loss: 0.036512
   Number of active neurons: 10
 >> iter 71000, loss: 0.014976
 >> iter 72000, loss: 0.007079
 >> iter 73000, loss: 0.004062
 >> iter 74000, loss: 0.008439
 >> iter 75000, loss: 0.004511
 >> iter 76000, loss: 0.054703
 >> iter 77000, loss: 0.022534
 >> iter 78000, loss: 0.036985
 >> iter 79000, loss: 0.015381
 >> iter 80000, loss: 0.007149
   Number of active neurons: 10
 >> iter 81000, loss: 0.063053
 >> iter 82000, loss: 0.028374
 >> iter 83000, loss: 0.011968
 >> iter 84000, loss: 0.020952
 >> iter 85000, loss: 0.010990
 >> iter 86000, loss: 0.062066
 >> iter 87000, loss: 0.029142
 >> iter 88000, loss: 0.012298
 >> iter 89000, loss: 0.005874
 >> iter 90000, loss: 0.003412
   Number of active neurons: 10
 >> iter 91000, loss: 0.002392
 >> iter 92000, loss: 0.002023
 >> iter 93000, loss: 0.001906
 >> iter 94000, loss: 0.064130
 >> iter 95000, loss: 0.032729
 >> iter 96000, loss: 0.017007
 >> iter 97000, loss: 0.009634
 >> iter 98000, loss: 0.004715
 >> iter 99000, loss: 0.002985
 >> iter 100000, loss: 0.061381
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.948171
 >> iter 2000, loss: 11.291937
 >> iter 3000, loss: 5.079449
 >> iter 4000, loss: 2.298929
 >> iter 5000, loss: 1.086131
 >> iter 6000, loss: 0.477805
 >> iter 7000, loss: 0.442535
 >> iter 8000, loss: 0.215139
 >> iter 9000, loss: 0.104635
 >> iter 10000, loss: 0.074600
   Number of active neurons: 10
 >> iter 11000, loss: 0.177907
 >> iter 12000, loss: 0.109177
 >> iter 13000, loss: 0.118945
 >> iter 14000, loss: 0.147818
 >> iter 15000, loss: 0.063772
 >> iter 16000, loss: 0.139573
 >> iter 17000, loss: 0.063995
 >> iter 18000, loss: 0.177493
 >> iter 19000, loss: 0.154723
 >> iter 20000, loss: 0.189526
   Number of active neurons: 10
 >> iter 21000, loss: 0.085594
 >> iter 22000, loss: 0.037554
 >> iter 23000, loss: 0.019185
 >> iter 24000, loss: 0.011652
 >> iter 25000, loss: 0.071412
 >> iter 26000, loss: 0.030942
 >> iter 27000, loss: 0.025895
 >> iter 28000, loss: 0.012925
 >> iter 29000, loss: 0.007906
 >> iter 30000, loss: 0.036318
   Number of active neurons: 10
 >> iter 31000, loss: 0.016777
 >> iter 32000, loss: 0.009089
 >> iter 33000, loss: 0.024176
 >> iter 34000, loss: 0.011754
 >> iter 35000, loss: 0.006688
 >> iter 36000, loss: 0.007303
 >> iter 37000, loss: 0.004814
 >> iter 38000, loss: 0.004208
 >> iter 39000, loss: 0.003477
 >> iter 40000, loss: 0.015620
   Number of active neurons: 10
 >> iter 41000, loss: 0.010049
 >> iter 42000, loss: 0.009202
 >> iter 43000, loss: 0.007207
 >> iter 44000, loss: 0.097751
 >> iter 45000, loss: 0.057661
 >> iter 46000, loss: 0.023512
 >> iter 47000, loss: 0.010305
 >> iter 48000, loss: 0.006736
 >> iter 49000, loss: 0.068038
 >> iter 50000, loss: 0.026910
   Number of active neurons: 10
 >> iter 51000, loss: 0.011748
 >> iter 52000, loss: 0.007681
 >> iter 53000, loss: 0.005541
 >> iter 54000, loss: 0.058649
 >> iter 55000, loss: 0.023416
 >> iter 56000, loss: 0.010234
 >> iter 57000, loss: 0.007100
 >> iter 58000, loss: 0.007983
 >> iter 59000, loss: 0.032060
 >> iter 60000, loss: 0.013433
   Number of active neurons: 10
 >> iter 61000, loss: 0.006806
 >> iter 62000, loss: 0.003671
 >> iter 63000, loss: 0.002881
 >> iter 64000, loss: 0.002430
 >> iter 65000, loss: 0.002505
 >> iter 66000, loss: 0.001975
 >> iter 67000, loss: 0.001679
 >> iter 68000, loss: 0.002299
 >> iter 69000, loss: 0.001787
 >> iter 70000, loss: 0.001528
   Number of active neurons: 10
 >> iter 71000, loss: 0.001426
 >> iter 72000, loss: 0.001344
 >> iter 73000, loss: 0.001382
 >> iter 74000, loss: 0.001321
 >> iter 75000, loss: 0.028180
 >> iter 76000, loss: 0.011782
 >> iter 77000, loss: 0.034191
 >> iter 78000, loss: 0.015612
 >> iter 79000, loss: 0.007047
 >> iter 80000, loss: 0.003612
   Number of active neurons: 10
 >> iter 81000, loss: 0.002384
 >> iter 82000, loss: 0.001939
 >> iter 83000, loss: 0.040306
 >> iter 84000, loss: 0.024863
 >> iter 85000, loss: 0.025975
 >> iter 86000, loss: 0.069954
 >> iter 87000, loss: 0.097824
 >> iter 88000, loss: 0.037433
 >> iter 89000, loss: 0.014991
 >> iter 90000, loss: 0.006684
   Number of active neurons: 10
 >> iter 91000, loss: 0.004264
 >> iter 92000, loss: 0.002859
 >> iter 93000, loss: 0.002467
 >> iter 94000, loss: 0.001946
 >> iter 95000, loss: 0.070267
 >> iter 96000, loss: 0.073133
 >> iter 97000, loss: 0.028334
 >> iter 98000, loss: 0.012138
 >> iter 99000, loss: 0.006281
 >> iter 100000, loss: 0.003501
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.104328
 >> iter 2000, loss: 12.797615
 >> iter 3000, loss: 5.886872
 >> iter 4000, loss: 2.555507
 >> iter 5000, loss: 1.229224
 >> iter 6000, loss: 0.568411
 >> iter 7000, loss: 0.344010
 >> iter 8000, loss: 0.294303
 >> iter 9000, loss: 0.206370
 >> iter 10000, loss: 0.133242
   Number of active neurons: 10
 >> iter 11000, loss: 0.063574
 >> iter 12000, loss: 0.070258
 >> iter 13000, loss: 0.109010
 >> iter 14000, loss: 0.059892
 >> iter 15000, loss: 0.117560
 >> iter 16000, loss: 0.115993
 >> iter 17000, loss: 0.243166
 >> iter 18000, loss: 0.098836
 >> iter 19000, loss: 0.090948
 >> iter 20000, loss: 0.069116
   Number of active neurons: 10
 >> iter 21000, loss: 0.032245
 >> iter 22000, loss: 0.016956
 >> iter 23000, loss: 0.024004
 >> iter 24000, loss: 0.072264
 >> iter 25000, loss: 0.058475
 >> iter 26000, loss: 0.027745
 >> iter 27000, loss: 0.017985
 >> iter 28000, loss: 0.010417
 >> iter 29000, loss: 0.012310
 >> iter 30000, loss: 0.013611
   Number of active neurons: 10
 >> iter 31000, loss: 0.009570
 >> iter 32000, loss: 0.006456
 >> iter 33000, loss: 0.026937
 >> iter 34000, loss: 0.044912
 >> iter 35000, loss: 0.024458
 >> iter 36000, loss: 0.126323
 >> iter 37000, loss: 0.050020
 >> iter 38000, loss: 0.022219
 >> iter 39000, loss: 0.011792
 >> iter 40000, loss: 0.006943
   Number of active neurons: 10
 >> iter 41000, loss: 0.056312
 >> iter 42000, loss: 0.023619
 >> iter 43000, loss: 0.011649
 >> iter 44000, loss: 0.006678
 >> iter 45000, loss: 0.004344
 >> iter 46000, loss: 0.003529
 >> iter 47000, loss: 0.006209
 >> iter 48000, loss: 0.004943
 >> iter 49000, loss: 0.006908
 >> iter 50000, loss: 0.046234
   Number of active neurons: 10
 >> iter 51000, loss: 0.021136
 >> iter 52000, loss: 0.009517
 >> iter 53000, loss: 0.005265
 >> iter 54000, loss: 0.003614
 >> iter 55000, loss: 0.002735
 >> iter 56000, loss: 0.002401
 >> iter 57000, loss: 0.002656
 >> iter 58000, loss: 0.002288
 >> iter 59000, loss: 0.002355
 >> iter 60000, loss: 0.031922
   Number of active neurons: 10
 >> iter 61000, loss: 0.013973
 >> iter 62000, loss: 0.006397
 >> iter 63000, loss: 0.005523
 >> iter 64000, loss: 0.003188
 >> iter 65000, loss: 0.002500
 >> iter 66000, loss: 0.002040
 >> iter 67000, loss: 0.002847
 >> iter 68000, loss: 0.002969
 >> iter 69000, loss: 0.002363
 >> iter 70000, loss: 0.001778
   Number of active neurons: 10
 >> iter 71000, loss: 0.005695
 >> iter 72000, loss: 0.003131
 >> iter 73000, loss: 0.002087
 >> iter 74000, loss: 0.001558
 >> iter 75000, loss: 0.001414
 >> iter 76000, loss: 0.001332
 >> iter 77000, loss: 0.001395
 >> iter 78000, loss: 0.001328
 >> iter 79000, loss: 0.001292
 >> iter 80000, loss: 0.063350
   Number of active neurons: 10
 >> iter 81000, loss: 0.024515
 >> iter 82000, loss: 0.009921
 >> iter 83000, loss: 0.007121
 >> iter 84000, loss: 0.005624
 >> iter 85000, loss: 0.002953
 >> iter 86000, loss: 0.001948
 >> iter 87000, loss: 0.007655
 >> iter 88000, loss: 0.003668
 >> iter 89000, loss: 0.002564
 >> iter 90000, loss: 0.002101
   Number of active neurons: 10
 >> iter 91000, loss: 0.071628
 >> iter 92000, loss: 0.027284
 >> iter 93000, loss: 0.011001
 >> iter 94000, loss: 0.004943
 >> iter 95000, loss: 0.002613
 >> iter 96000, loss: 0.001990
 >> iter 97000, loss: 0.001574
 >> iter 98000, loss: 0.001570
 >> iter 99000, loss: 0.001285
 >> iter 100000, loss: 0.001196
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.943042
 >> iter 2000, loss: 11.340127
 >> iter 3000, loss: 5.931332
 >> iter 4000, loss: 2.750758
 >> iter 5000, loss: 1.317173
 >> iter 6000, loss: 0.743281
 >> iter 7000, loss: 0.583659
 >> iter 8000, loss: 0.465744
 >> iter 9000, loss: 0.328362
 >> iter 10000, loss: 0.149047
   Number of active neurons: 10
 >> iter 11000, loss: 0.204142
 >> iter 12000, loss: 0.179478
 >> iter 13000, loss: 0.152210
 >> iter 14000, loss: 0.070687
 >> iter 15000, loss: 0.111843
 >> iter 16000, loss: 0.105847
 >> iter 17000, loss: 0.058294
 >> iter 18000, loss: 0.032191
 >> iter 19000, loss: 0.031357
 >> iter 20000, loss: 0.034856
   Number of active neurons: 10
 >> iter 21000, loss: 0.035190
 >> iter 22000, loss: 0.022211
 >> iter 23000, loss: 0.027497
 >> iter 24000, loss: 0.048125
 >> iter 25000, loss: 0.028385
 >> iter 26000, loss: 0.021075
 >> iter 27000, loss: 0.013297
 >> iter 28000, loss: 0.015428
 >> iter 29000, loss: 0.014806
 >> iter 30000, loss: 0.009512
   Number of active neurons: 10
 >> iter 31000, loss: 0.010929
 >> iter 32000, loss: 0.025981
 >> iter 33000, loss: 0.061771
 >> iter 34000, loss: 0.029320
 >> iter 35000, loss: 0.059625
 >> iter 36000, loss: 0.103949
 >> iter 37000, loss: 0.042737
 >> iter 38000, loss: 0.054486
 >> iter 39000, loss: 0.025314
 >> iter 40000, loss: 0.012879
   Number of active neurons: 10
 >> iter 41000, loss: 0.011907
 >> iter 42000, loss: 0.007522
 >> iter 43000, loss: 0.006333
 >> iter 44000, loss: 0.007901
 >> iter 45000, loss: 0.005736
 >> iter 46000, loss: 0.004522
 >> iter 47000, loss: 0.004077
 >> iter 48000, loss: 0.003770
 >> iter 49000, loss: 0.004782
 >> iter 50000, loss: 0.057621
   Number of active neurons: 10
 >> iter 51000, loss: 0.031781
 >> iter 52000, loss: 0.014672
 >> iter 53000, loss: 0.008033
 >> iter 54000, loss: 0.005567
 >> iter 55000, loss: 0.004477
 >> iter 56000, loss: 0.013740
 >> iter 57000, loss: 0.020173
 >> iter 58000, loss: 0.067797
 >> iter 59000, loss: 0.029101
 >> iter 60000, loss: 0.013802
   Number of active neurons: 10
 >> iter 61000, loss: 0.007400
 >> iter 62000, loss: 0.008930
 >> iter 63000, loss: 0.272651
 >> iter 64000, loss: 0.120447
 >> iter 65000, loss: 0.063973
 >> iter 66000, loss: 0.043165
 >> iter 67000, loss: 0.030063
 >> iter 68000, loss: 0.013724
 >> iter 69000, loss: 0.010850
 >> iter 70000, loss: 0.017579
   Number of active neurons: 10
 >> iter 71000, loss: 0.028837
 >> iter 72000, loss: 0.050434
 >> iter 73000, loss: 0.021432
 >> iter 74000, loss: 0.010369
 >> iter 75000, loss: 0.005877
 >> iter 76000, loss: 0.004408
 >> iter 77000, loss: 0.005980
 >> iter 78000, loss: 0.003983
 >> iter 79000, loss: 0.003215
 >> iter 80000, loss: 0.003018
   Number of active neurons: 10
 >> iter 81000, loss: 0.009084
 >> iter 82000, loss: 0.005018
 >> iter 83000, loss: 0.003299
 >> iter 84000, loss: 0.002614
 >> iter 85000, loss: 0.002965
 >> iter 86000, loss: 0.002815
 >> iter 87000, loss: 0.002288
 >> iter 88000, loss: 0.002356
 >> iter 89000, loss: 0.002819
 >> iter 90000, loss: 0.002157
   Number of active neurons: 10
 >> iter 91000, loss: 0.002310
 >> iter 92000, loss: 0.002288
 >> iter 93000, loss: 0.002222
 >> iter 94000, loss: 0.001934
 >> iter 95000, loss: 0.001862
 >> iter 96000, loss: 0.001666
 >> iter 97000, loss: 0.001716
 >> iter 98000, loss: 0.002809
 >> iter 99000, loss: 0.002122
 >> iter 100000, loss: 0.001962
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.966225
 >> iter 2000, loss: 11.545429
 >> iter 3000, loss: 5.593279
 >> iter 4000, loss: 2.735449
 >> iter 5000, loss: 1.515271
 >> iter 6000, loss: 0.792719
 >> iter 7000, loss: 0.401694
 >> iter 8000, loss: 0.287095
 >> iter 9000, loss: 0.259267
 >> iter 10000, loss: 0.436950
   Number of active neurons: 10
 >> iter 11000, loss: 0.300033
 >> iter 12000, loss: 0.198461
 >> iter 13000, loss: 0.177843
 >> iter 14000, loss: 0.180862
 >> iter 15000, loss: 0.146685
 >> iter 16000, loss: 0.173649
 >> iter 17000, loss: 0.115476
 >> iter 18000, loss: 0.062096
 >> iter 19000, loss: 0.080432
 >> iter 20000, loss: 0.045638
   Number of active neurons: 10
 >> iter 21000, loss: 0.140784
 >> iter 22000, loss: 0.108880
 >> iter 23000, loss: 0.152135
 >> iter 24000, loss: 0.115123
 >> iter 25000, loss: 0.062178
 >> iter 26000, loss: 0.224030
 >> iter 27000, loss: 0.108743
 >> iter 28000, loss: 0.117220
 >> iter 29000, loss: 0.195468
 >> iter 30000, loss: 0.099101
   Number of active neurons: 10
 >> iter 31000, loss: 0.055973
 >> iter 32000, loss: 0.028399
 >> iter 33000, loss: 0.244991
 >> iter 34000, loss: 0.204449
 >> iter 35000, loss: 0.104602
 >> iter 36000, loss: 0.104539
 >> iter 37000, loss: 0.045515
 >> iter 38000, loss: 0.035019
 >> iter 39000, loss: 0.018018
 >> iter 40000, loss: 0.082963
   Number of active neurons: 10
 >> iter 41000, loss: 0.037112
 >> iter 42000, loss: 0.019203
 >> iter 43000, loss: 0.011619
 >> iter 44000, loss: 0.008383
 >> iter 45000, loss: 0.007594
 >> iter 46000, loss: 0.009002
 >> iter 47000, loss: 0.006677
 >> iter 48000, loss: 0.012360
 >> iter 49000, loss: 0.009629
 >> iter 50000, loss: 0.006490
   Number of active neurons: 10
 >> iter 51000, loss: 0.005617
 >> iter 52000, loss: 0.019559
 >> iter 53000, loss: 0.010088
 >> iter 54000, loss: 0.015343
 >> iter 55000, loss: 0.007869
 >> iter 56000, loss: 0.005167
 >> iter 57000, loss: 0.003986
 >> iter 58000, loss: 0.003365
 >> iter 59000, loss: 0.003952
 >> iter 60000, loss: 0.003802
   Number of active neurons: 10
 >> iter 61000, loss: 0.022207
 >> iter 62000, loss: 0.011882
 >> iter 63000, loss: 0.006505
 >> iter 64000, loss: 0.028595
 >> iter 65000, loss: 0.014431
 >> iter 66000, loss: 0.030749
 >> iter 67000, loss: 0.013200
 >> iter 68000, loss: 0.008957
 >> iter 69000, loss: 0.004992
 >> iter 70000, loss: 0.023484
   Number of active neurons: 10
 >> iter 71000, loss: 0.010394
 >> iter 72000, loss: 0.005494
 >> iter 73000, loss: 0.113686
 >> iter 74000, loss: 0.107530
 >> iter 75000, loss: 0.041887
 >> iter 76000, loss: 0.017750
 >> iter 77000, loss: 0.030601
 >> iter 78000, loss: 0.020005
 >> iter 79000, loss: 0.033912
 >> iter 80000, loss: 0.016267
   Number of active neurons: 10
 >> iter 81000, loss: 0.007813
 >> iter 82000, loss: 0.005026
 >> iter 83000, loss: 0.061639
 >> iter 84000, loss: 0.032507
 >> iter 85000, loss: 0.031134
 >> iter 86000, loss: 0.013934
 >> iter 87000, loss: 0.008966
 >> iter 88000, loss: 0.005033
 >> iter 89000, loss: 0.115868
 >> iter 90000, loss: 0.099787
   Number of active neurons: 10
 >> iter 91000, loss: 0.039379
 >> iter 92000, loss: 0.016229
 >> iter 93000, loss: 0.008183
 >> iter 94000, loss: 0.050876
 >> iter 95000, loss: 0.020855
 >> iter 96000, loss: 0.048421
 >> iter 97000, loss: 0.019590
 >> iter 98000, loss: 0.021109
 >> iter 99000, loss: 0.016767
 >> iter 100000, loss: 0.008241
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.352980
 >> iter 2000, loss: 12.827372
 >> iter 3000, loss: 7.099412
 >> iter 4000, loss: 3.457996
 >> iter 5000, loss: 1.564769
 >> iter 6000, loss: 0.974515
 >> iter 7000, loss: 0.497447
 >> iter 8000, loss: 0.326142
 >> iter 9000, loss: 0.269251
 >> iter 10000, loss: 0.323760
   Number of active neurons: 10
 >> iter 11000, loss: 0.284383
 >> iter 12000, loss: 0.205318
 >> iter 13000, loss: 0.283397
 >> iter 14000, loss: 0.187628
 >> iter 15000, loss: 0.133599
 >> iter 16000, loss: 0.103121
 >> iter 17000, loss: 0.058982
 >> iter 18000, loss: 0.036621
 >> iter 19000, loss: 0.020768
 >> iter 20000, loss: 0.135470
   Number of active neurons: 10
 >> iter 21000, loss: 0.125679
 >> iter 22000, loss: 0.079457
 >> iter 23000, loss: 0.116277
 >> iter 24000, loss: 0.100017
 >> iter 25000, loss: 0.149859
 >> iter 26000, loss: 0.064170
 >> iter 27000, loss: 0.031620
 >> iter 28000, loss: 0.039119
 >> iter 29000, loss: 0.021176
 >> iter 30000, loss: 0.041577
   Number of active neurons: 10
 >> iter 31000, loss: 0.020409
 >> iter 32000, loss: 0.101679
 >> iter 33000, loss: 0.041185
 >> iter 34000, loss: 0.018689
 >> iter 35000, loss: 0.099510
 >> iter 36000, loss: 0.040605
 >> iter 37000, loss: 0.042525
 >> iter 38000, loss: 0.018640
 >> iter 39000, loss: 0.009955
 >> iter 40000, loss: 0.073621
   Number of active neurons: 10
 >> iter 41000, loss: 0.102188
 >> iter 42000, loss: 0.043297
 >> iter 43000, loss: 0.021265
 >> iter 44000, loss: 0.016867
 >> iter 45000, loss: 0.009806
 >> iter 46000, loss: 0.017624
 >> iter 47000, loss: 0.011977
 >> iter 48000, loss: 0.007700
 >> iter 49000, loss: 0.005105
 >> iter 50000, loss: 0.003464
   Number of active neurons: 10
 >> iter 51000, loss: 0.003121
 >> iter 52000, loss: 0.014555
 >> iter 53000, loss: 0.008227
 >> iter 54000, loss: 0.049963
 >> iter 55000, loss: 0.020723
 >> iter 56000, loss: 0.012100
 >> iter 57000, loss: 0.111721
 >> iter 58000, loss: 0.043883
 >> iter 59000, loss: 0.018196
 >> iter 60000, loss: 0.008373
   Number of active neurons: 10
 >> iter 61000, loss: 0.004853
 >> iter 62000, loss: 0.005062
 >> iter 63000, loss: 0.004459
 >> iter 64000, loss: 0.003163
 >> iter 65000, loss: 0.005140
 >> iter 66000, loss: 0.003226
 >> iter 67000, loss: 0.002585
 >> iter 68000, loss: 0.002281
 >> iter 69000, loss: 0.002423
 >> iter 70000, loss: 0.005966
   Number of active neurons: 10
 >> iter 71000, loss: 0.040373
 >> iter 72000, loss: 0.019736
 >> iter 73000, loss: 0.008682
 >> iter 74000, loss: 0.004372
 >> iter 75000, loss: 0.021713
 >> iter 76000, loss: 0.022693
 >> iter 77000, loss: 0.015909
 >> iter 78000, loss: 0.033470
 >> iter 79000, loss: 0.013709
 >> iter 80000, loss: 0.007076
   Number of active neurons: 10
 >> iter 81000, loss: 0.004825
 >> iter 82000, loss: 0.118761
 >> iter 83000, loss: 0.045320
 >> iter 84000, loss: 0.032638
 >> iter 85000, loss: 0.015074
 >> iter 86000, loss: 0.073825
 >> iter 87000, loss: 0.032739
 >> iter 88000, loss: 0.013958
 >> iter 89000, loss: 0.006664
 >> iter 90000, loss: 0.003890
   Number of active neurons: 10
 >> iter 91000, loss: 0.072313
 >> iter 92000, loss: 0.029412
 >> iter 93000, loss: 0.025760
 >> iter 94000, loss: 0.013515
 >> iter 95000, loss: 0.007493
 >> iter 96000, loss: 0.004580
 >> iter 97000, loss: 0.002716
 >> iter 98000, loss: 0.002735
 >> iter 99000, loss: 0.022608
 >> iter 100000, loss: 0.071658
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 19.145168
 >> iter 2000, loss: 12.073535
 >> iter 3000, loss: 5.480102
 >> iter 4000, loss: 2.337809
 >> iter 5000, loss: 1.053564
 >> iter 6000, loss: 0.616596
 >> iter 7000, loss: 0.497211
 >> iter 8000, loss: 0.307028
 >> iter 9000, loss: 0.186086
 >> iter 10000, loss: 0.171602
   Number of active neurons: 10
 >> iter 11000, loss: 0.267332
 >> iter 12000, loss: 0.164161
 >> iter 13000, loss: 0.161727
 >> iter 14000, loss: 0.116846
 >> iter 15000, loss: 0.085073
 >> iter 16000, loss: 0.092039
 >> iter 17000, loss: 0.047350
 >> iter 18000, loss: 0.024039
 >> iter 19000, loss: 0.050447
 >> iter 20000, loss: 0.058599
   Number of active neurons: 10
 >> iter 21000, loss: 0.112334
 >> iter 22000, loss: 0.076982
 >> iter 23000, loss: 0.038870
 >> iter 24000, loss: 0.031124
 >> iter 25000, loss: 0.039644
 >> iter 26000, loss: 0.033907
 >> iter 27000, loss: 0.060742
 >> iter 28000, loss: 0.089275
 >> iter 29000, loss: 0.037228
 >> iter 30000, loss: 0.051613
   Number of active neurons: 10
 >> iter 31000, loss: 0.024239
 >> iter 32000, loss: 0.027633
 >> iter 33000, loss: 0.013523
 >> iter 34000, loss: 0.008000
 >> iter 35000, loss: 0.042245
 >> iter 36000, loss: 0.018642
 >> iter 37000, loss: 0.030725
 >> iter 38000, loss: 0.016048
 >> iter 39000, loss: 0.008631
 >> iter 40000, loss: 0.007606
   Number of active neurons: 10
 >> iter 41000, loss: 0.023048
 >> iter 42000, loss: 0.010656
 >> iter 43000, loss: 0.011403
 >> iter 44000, loss: 0.006952
 >> iter 45000, loss: 0.004785
 >> iter 46000, loss: 0.034719
 >> iter 47000, loss: 0.070531
 >> iter 48000, loss: 0.030876
 >> iter 49000, loss: 0.013669
 >> iter 50000, loss: 0.089933
   Number of active neurons: 10
 >> iter 51000, loss: 0.036912
 >> iter 52000, loss: 0.021472
 >> iter 53000, loss: 0.024847
 >> iter 54000, loss: 0.011260
 >> iter 55000, loss: 0.006241
 >> iter 56000, loss: 0.007923
 >> iter 57000, loss: 0.009151
 >> iter 58000, loss: 0.005623
 >> iter 59000, loss: 0.086116
 >> iter 60000, loss: 0.093519
   Number of active neurons: 10
 >> iter 61000, loss: 0.043583
 >> iter 62000, loss: 0.017691
 >> iter 63000, loss: 0.008289
 >> iter 64000, loss: 0.009462
 >> iter 65000, loss: 0.029276
 >> iter 66000, loss: 0.025877
 >> iter 67000, loss: 0.030078
 >> iter 68000, loss: 0.013187
 >> iter 69000, loss: 0.078558
 >> iter 70000, loss: 0.030883
   Number of active neurons: 10
 >> iter 71000, loss: 0.013422
 >> iter 72000, loss: 0.016203
 >> iter 73000, loss: 0.008588
 >> iter 74000, loss: 0.005415
 >> iter 75000, loss: 0.003646
 >> iter 76000, loss: 0.002542
 >> iter 77000, loss: 0.002199
 >> iter 78000, loss: 0.041653
 >> iter 79000, loss: 0.017467
 >> iter 80000, loss: 0.007765
   Number of active neurons: 10
 >> iter 81000, loss: 0.004510
 >> iter 82000, loss: 0.002891
 >> iter 83000, loss: 0.016978
 >> iter 84000, loss: 0.007861
 >> iter 85000, loss: 0.025575
 >> iter 86000, loss: 0.014990
 >> iter 87000, loss: 0.006702
 >> iter 88000, loss: 0.029629
 >> iter 89000, loss: 0.012753
 >> iter 90000, loss: 0.006642
   Number of active neurons: 10
 >> iter 91000, loss: 0.003783
 >> iter 92000, loss: 0.007665
 >> iter 93000, loss: 0.004081
 >> iter 94000, loss: 0.077061
 >> iter 95000, loss: 0.031735
 >> iter 96000, loss: 0.031726
 >> iter 97000, loss: 0.067751
 >> iter 98000, loss: 0.026521
 >> iter 99000, loss: 0.021220
 >> iter 100000, loss: 0.009286
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.062041
 >> iter 2000, loss: 12.094968
 >> iter 3000, loss: 5.862007
 >> iter 4000, loss: 2.610847
 >> iter 5000, loss: 1.241152
 >> iter 6000, loss: 0.594701
 >> iter 7000, loss: 0.464550
 >> iter 8000, loss: 0.351150
 >> iter 9000, loss: 0.378760
 >> iter 10000, loss: 0.341590
   Number of active neurons: 10
 >> iter 11000, loss: 0.274173
 >> iter 12000, loss: 0.243055
 >> iter 13000, loss: 0.216599
 >> iter 14000, loss: 0.267431
 >> iter 15000, loss: 0.138918
 >> iter 16000, loss: 0.075978
 >> iter 17000, loss: 0.074915
 >> iter 18000, loss: 0.048176
 >> iter 19000, loss: 0.094991
 >> iter 20000, loss: 0.175852
   Number of active neurons: 10
 >> iter 21000, loss: 0.080531
 >> iter 22000, loss: 0.060330
 >> iter 23000, loss: 0.036289
 >> iter 24000, loss: 0.076791
 >> iter 25000, loss: 0.137002
 >> iter 26000, loss: 0.059931
 >> iter 27000, loss: 0.041040
 >> iter 28000, loss: 0.076716
 >> iter 29000, loss: 0.045751
 >> iter 30000, loss: 0.025063
   Number of active neurons: 10
 >> iter 31000, loss: 0.014132
 >> iter 32000, loss: 0.009138
 >> iter 33000, loss: 0.040799
 >> iter 34000, loss: 0.051729
 >> iter 35000, loss: 0.041600
 >> iter 36000, loss: 0.037003
 >> iter 37000, loss: 0.033718
 >> iter 38000, loss: 0.075433
 >> iter 39000, loss: 0.159579
 >> iter 40000, loss: 0.063493
   Number of active neurons: 10
 >> iter 41000, loss: 0.027103
 >> iter 42000, loss: 0.122767
 >> iter 43000, loss: 0.073762
 >> iter 44000, loss: 0.093478
 >> iter 45000, loss: 0.039908
 >> iter 46000, loss: 0.083183
 >> iter 47000, loss: 0.041155
 >> iter 48000, loss: 0.025548
 >> iter 49000, loss: 0.013827
 >> iter 50000, loss: 0.007769
   Number of active neurons: 10
 >> iter 51000, loss: 0.006617
 >> iter 52000, loss: 0.036648
 >> iter 53000, loss: 0.037877
 >> iter 54000, loss: 0.090118
 >> iter 55000, loss: 0.036401
 >> iter 56000, loss: 0.071814
 >> iter 57000, loss: 0.040710
 >> iter 58000, loss: 0.043722
 >> iter 59000, loss: 0.019012
 >> iter 60000, loss: 0.009264
   Number of active neurons: 10
 >> iter 61000, loss: 0.005675
 >> iter 62000, loss: 0.004114
 >> iter 63000, loss: 0.006859
 >> iter 64000, loss: 0.153796
 >> iter 65000, loss: 0.060432
 >> iter 66000, loss: 0.082702
 >> iter 67000, loss: 0.033848
 >> iter 68000, loss: 0.017516
 >> iter 69000, loss: 0.014087
 >> iter 70000, loss: 0.007669
   Number of active neurons: 10
 >> iter 71000, loss: 0.004704
 >> iter 72000, loss: 0.004189
 >> iter 73000, loss: 0.003398
 >> iter 74000, loss: 0.016541
 >> iter 75000, loss: 0.008146
 >> iter 76000, loss: 0.005880
 >> iter 77000, loss: 0.003956
 >> iter 78000, loss: 0.002806
 >> iter 79000, loss: 0.002557
 >> iter 80000, loss: 0.002102
   Number of active neurons: 10
 >> iter 81000, loss: 0.003599
 >> iter 82000, loss: 0.002500
 >> iter 83000, loss: 0.010875
 >> iter 84000, loss: 0.019100
 >> iter 85000, loss: 0.095193
 >> iter 86000, loss: 0.036840
 >> iter 87000, loss: 0.081111
 >> iter 88000, loss: 0.039622
 >> iter 89000, loss: 0.016331
 >> iter 90000, loss: 0.018359
   Number of active neurons: 10
 >> iter 91000, loss: 0.141150
 >> iter 92000, loss: 0.055461
 >> iter 93000, loss: 0.031656
 >> iter 94000, loss: 0.014111
 >> iter 95000, loss: 0.007826
 >> iter 96000, loss: 0.007050
 >> iter 97000, loss: 0.005226
 >> iter 98000, loss: 0.003430
 >> iter 99000, loss: 0.004185
 >> iter 100000, loss: 0.002969
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.193667
 >> iter 2000, loss: 11.977635
 >> iter 3000, loss: 5.510778
 >> iter 4000, loss: 2.417397
 >> iter 5000, loss: 1.140967
 >> iter 6000, loss: 0.539441
 >> iter 7000, loss: 0.228089
 >> iter 8000, loss: 0.234673
 >> iter 9000, loss: 0.132566
 >> iter 10000, loss: 0.197614
   Number of active neurons: 10
 >> iter 11000, loss: 0.104538
 >> iter 12000, loss: 0.080087
 >> iter 13000, loss: 0.080896
 >> iter 14000, loss: 0.038476
 >> iter 15000, loss: 0.020996
 >> iter 16000, loss: 0.059648
 >> iter 17000, loss: 0.031658
 >> iter 18000, loss: 0.022628
 >> iter 19000, loss: 0.031294
 >> iter 20000, loss: 0.026514
   Number of active neurons: 10
 >> iter 21000, loss: 0.019227
 >> iter 22000, loss: 0.068572
 >> iter 23000, loss: 0.037852
 >> iter 24000, loss: 0.032663
 >> iter 25000, loss: 0.018248
 >> iter 26000, loss: 0.086152
 >> iter 27000, loss: 0.073076
 >> iter 28000, loss: 0.035046
 >> iter 29000, loss: 0.066180
 >> iter 30000, loss: 0.153472
   Number of active neurons: 10
 >> iter 31000, loss: 0.125666
 >> iter 32000, loss: 0.061461
 >> iter 33000, loss: 0.139150
 >> iter 34000, loss: 0.066230
 >> iter 35000, loss: 0.030142
 >> iter 36000, loss: 0.015164
 >> iter 37000, loss: 0.009325
 >> iter 38000, loss: 0.006262
 >> iter 39000, loss: 0.014683
 >> iter 40000, loss: 0.008614
   Number of active neurons: 10
 >> iter 41000, loss: 0.006558
 >> iter 42000, loss: 0.004892
 >> iter 43000, loss: 0.004438
 >> iter 44000, loss: 0.003469
 >> iter 45000, loss: 0.023565
 >> iter 46000, loss: 0.016059
 >> iter 47000, loss: 0.009681
 >> iter 48000, loss: 0.005606
 >> iter 49000, loss: 0.004690
 >> iter 50000, loss: 0.003495
   Number of active neurons: 10
 >> iter 51000, loss: 0.002954
 >> iter 52000, loss: 0.002774
 >> iter 53000, loss: 0.062417
 >> iter 54000, loss: 0.028629
 >> iter 55000, loss: 0.072312
 >> iter 56000, loss: 0.098230
 >> iter 57000, loss: 0.052913
 >> iter 58000, loss: 0.022255
 >> iter 59000, loss: 0.011755
 >> iter 60000, loss: 0.043449
   Number of active neurons: 10
 >> iter 61000, loss: 0.018221
 >> iter 62000, loss: 0.008993
 >> iter 63000, loss: 0.031151
 >> iter 64000, loss: 0.022559
 >> iter 65000, loss: 0.012996
 >> iter 66000, loss: 0.039376
 >> iter 67000, loss: 0.016214
 >> iter 68000, loss: 0.106214
 >> iter 69000, loss: 0.042637
 >> iter 70000, loss: 0.062461
   Number of active neurons: 10
 >> iter 71000, loss: 0.025001
 >> iter 72000, loss: 0.014185
 >> iter 73000, loss: 0.116254
 >> iter 74000, loss: 0.047401
 >> iter 75000, loss: 0.019402
 >> iter 76000, loss: 0.009065
 >> iter 77000, loss: 0.005123
 >> iter 78000, loss: 0.004802
 >> iter 79000, loss: 0.003308
 >> iter 80000, loss: 0.002509
   Number of active neurons: 10
 >> iter 81000, loss: 0.002510
 >> iter 82000, loss: 0.002233
 >> iter 83000, loss: 0.001973
 >> iter 84000, loss: 0.002000
 >> iter 85000, loss: 0.034200
 >> iter 86000, loss: 0.022944
 >> iter 87000, loss: 0.010205
 >> iter 88000, loss: 0.010318
 >> iter 89000, loss: 0.005433
 >> iter 90000, loss: 0.007297
   Number of active neurons: 10
 >> iter 91000, loss: 0.015915
 >> iter 92000, loss: 0.013059
 >> iter 93000, loss: 0.006268
 >> iter 94000, loss: 0.003461
 >> iter 95000, loss: 0.002369
 >> iter 96000, loss: 0.007400
 >> iter 97000, loss: 0.004039
 >> iter 98000, loss: 0.002647
 >> iter 99000, loss: 0.001961
 >> iter 100000, loss: 0.002542
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

