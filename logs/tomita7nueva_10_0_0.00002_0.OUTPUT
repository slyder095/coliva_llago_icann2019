 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 2e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.242152
 >> iter 2000, loss: 7.987457
 >> iter 3000, loss: 3.169997
 >> iter 4000, loss: 1.259021
 >> iter 5000, loss: 0.484455
 >> iter 6000, loss: 0.197921
 >> iter 7000, loss: 0.080978
 >> iter 8000, loss: 0.036595
 >> iter 9000, loss: 0.020062
 >> iter 10000, loss: 0.013379
   Number of active neurons: 10
 >> iter 11000, loss: 0.011014
 >> iter 12000, loss: 0.009746
 >> iter 13000, loss: 0.009521
 >> iter 14000, loss: 0.009087
 >> iter 15000, loss: 0.053760
 >> iter 16000, loss: 0.026391
 >> iter 17000, loss: 0.016101
 >> iter 18000, loss: 0.011850
 >> iter 19000, loss: 0.010568
 >> iter 20000, loss: 0.187360
   Number of active neurons: 10
 >> iter 21000, loss: 0.078225
 >> iter 22000, loss: 0.036377
 >> iter 23000, loss: 0.021007
 >> iter 24000, loss: 0.014410
 >> iter 25000, loss: 0.071104
 >> iter 26000, loss: 0.130520
 >> iter 27000, loss: 0.056894
 >> iter 28000, loss: 0.028165
 >> iter 29000, loss: 0.077749
 >> iter 30000, loss: 0.197192
   Number of active neurons: 10
 >> iter 31000, loss: 0.081693
 >> iter 32000, loss: 0.036741
 >> iter 33000, loss: 0.019945
 >> iter 34000, loss: 0.013024
 >> iter 35000, loss: 0.010583
 >> iter 36000, loss: 0.009336
 >> iter 37000, loss: 0.009078
 >> iter 38000, loss: 0.008750
 >> iter 39000, loss: 0.008818
 >> iter 40000, loss: 0.008626
   Number of active neurons: 10
 >> iter 41000, loss: 0.008776
 >> iter 42000, loss: 0.008610
 >> iter 43000, loss: 0.008783
 >> iter 44000, loss: 0.008629
 >> iter 45000, loss: 0.008818
 >> iter 46000, loss: 0.008622
 >> iter 47000, loss: 0.008811
 >> iter 48000, loss: 0.008595
 >> iter 49000, loss: 0.008761
 >> iter 50000, loss: 0.008542
   Number of active neurons: 10
 >> iter 51000, loss: 0.008677
 >> iter 52000, loss: 0.008479
 >> iter 53000, loss: 0.104482
 >> iter 54000, loss: 0.068985
 >> iter 55000, loss: 0.031162
 >> iter 56000, loss: 0.016654
 >> iter 57000, loss: 0.011331
 >> iter 58000, loss: 0.009220
 >> iter 59000, loss: 0.008551
 >> iter 60000, loss: 0.008231
   Number of active neurons: 10
 >> iter 61000, loss: 0.008277
 >> iter 62000, loss: 0.008192
 >> iter 63000, loss: 0.008361
 >> iter 64000, loss: 0.008212
 >> iter 65000, loss: 0.008356
 >> iter 66000, loss: 0.008156
 >> iter 67000, loss: 0.008334
 >> iter 68000, loss: 0.008065
 >> iter 69000, loss: 0.008175
 >> iter 70000, loss: 0.007977
   Number of active neurons: 8
 >> iter 71000, loss: 0.008087
 >> iter 72000, loss: 0.007911
 >> iter 73000, loss: 0.008017
 >> iter 74000, loss: 0.007842
 >> iter 75000, loss: 0.138795
 >> iter 76000, loss: 0.058286
 >> iter 77000, loss: 0.027261
 >> iter 78000, loss: 0.015327
 >> iter 79000, loss: 0.010892
 >> iter 80000, loss: 0.009041
   Number of active neurons: 8
 >> iter 81000, loss: 0.008389
 >> iter 82000, loss: 0.007953
 >> iter 83000, loss: 0.007824
 >> iter 84000, loss: 0.007597
 >> iter 85000, loss: 0.007571
 >> iter 86000, loss: 0.007401
 >> iter 87000, loss: 0.007381
 >> iter 88000, loss: 0.007211
 >> iter 89000, loss: 0.007211
 >> iter 90000, loss: 0.007085
   Number of active neurons: 9
 >> iter 91000, loss: 0.007084
 >> iter 92000, loss: 0.006971
 >> iter 93000, loss: 0.028851
 >> iter 94000, loss: 0.015356
 >> iter 95000, loss: 0.009963
 >> iter 96000, loss: 0.007878
 >> iter 97000, loss: 0.007199
 >> iter 98000, loss: 0.006878
 >> iter 99000, loss: 0.292034
 >> iter 100000, loss: 0.199899
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.948495
 >> iter 2000, loss: 8.185169
 >> iter 3000, loss: 3.295746
 >> iter 4000, loss: 1.342393
 >> iter 5000, loss: 0.513980
 >> iter 6000, loss: 0.197549
 >> iter 7000, loss: 0.079823
 >> iter 8000, loss: 0.088217
 >> iter 9000, loss: 0.039659
 >> iter 10000, loss: 0.020717
   Number of active neurons: 10
 >> iter 11000, loss: 0.013594
 >> iter 12000, loss: 0.010587
 >> iter 13000, loss: 0.009507
 >> iter 14000, loss: 0.120544
 >> iter 15000, loss: 0.052562
 >> iter 16000, loss: 0.025941
 >> iter 17000, loss: 0.015705
 >> iter 18000, loss: 0.108974
 >> iter 19000, loss: 0.047114
 >> iter 20000, loss: 0.023362
   Number of active neurons: 10
 >> iter 21000, loss: 0.014502
 >> iter 22000, loss: 0.136861
 >> iter 23000, loss: 0.058300
 >> iter 24000, loss: 0.027924
 >> iter 25000, loss: 0.016380
 >> iter 26000, loss: 0.109527
 >> iter 27000, loss: 0.046964
 >> iter 28000, loss: 0.022941
 >> iter 29000, loss: 0.013950
 >> iter 30000, loss: 0.072330
   Number of active neurons: 10
 >> iter 31000, loss: 0.033256
 >> iter 32000, loss: 0.018082
 >> iter 33000, loss: 0.012409
 >> iter 34000, loss: 0.010167
 >> iter 35000, loss: 0.009283
 >> iter 36000, loss: 0.112909
 >> iter 37000, loss: 0.087230
 >> iter 38000, loss: 0.039160
 >> iter 39000, loss: 0.020600
 >> iter 40000, loss: 0.013533
   Number of active neurons: 10
 >> iter 41000, loss: 0.010495
 >> iter 42000, loss: 0.009795
 >> iter 43000, loss: 0.008838
 >> iter 44000, loss: 0.089406
 >> iter 45000, loss: 0.039031
 >> iter 46000, loss: 0.019853
 >> iter 47000, loss: 0.012703
 >> iter 48000, loss: 0.009949
 >> iter 49000, loss: 0.048235
 >> iter 50000, loss: 0.023109
   Number of active neurons: 10
 >> iter 51000, loss: 0.013782
 >> iter 52000, loss: 0.093921
 >> iter 53000, loss: 0.094311
 >> iter 54000, loss: 0.069826
 >> iter 55000, loss: 0.133555
 >> iter 56000, loss: 0.056965
 >> iter 57000, loss: 0.090465
 >> iter 58000, loss: 0.040542
 >> iter 59000, loss: 0.021007
 >> iter 60000, loss: 0.013366
   Number of active neurons: 10
 >> iter 61000, loss: 0.010444
 >> iter 62000, loss: 0.033063
 >> iter 63000, loss: 0.017722
 >> iter 64000, loss: 0.011706
 >> iter 65000, loss: 0.009410
 >> iter 66000, loss: 0.008491
 >> iter 67000, loss: 0.008088
 >> iter 68000, loss: 0.007995
 >> iter 69000, loss: 0.007830
 >> iter 70000, loss: 0.008002
   Number of active neurons: 10
 >> iter 71000, loss: 0.007789
 >> iter 72000, loss: 0.007866
 >> iter 73000, loss: 0.007740
 >> iter 74000, loss: 0.007933
 >> iter 75000, loss: 0.221225
 >> iter 76000, loss: 0.102603
 >> iter 77000, loss: 0.193165
 >> iter 78000, loss: 0.080114
 >> iter 79000, loss: 0.121609
 >> iter 80000, loss: 0.053060
   Number of active neurons: 10
 >> iter 81000, loss: 0.047898
 >> iter 82000, loss: 0.023541
 >> iter 83000, loss: 0.047659
 >> iter 84000, loss: 0.023379
 >> iter 85000, loss: 0.053589
 >> iter 86000, loss: 0.043053
 >> iter 87000, loss: 0.047636
 >> iter 88000, loss: 0.086040
 >> iter 89000, loss: 0.059903
 >> iter 90000, loss: 0.028262
   Number of active neurons: 10
 >> iter 91000, loss: 0.137572
 >> iter 92000, loss: 0.075571
 >> iter 93000, loss: 0.064365
 >> iter 94000, loss: 0.039217
 >> iter 95000, loss: 0.020143
 >> iter 96000, loss: 0.012580
 >> iter 97000, loss: 0.099116
 >> iter 98000, loss: 0.053100
 >> iter 99000, loss: 0.136165
 >> iter 100000, loss: 0.056999
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 19.3387107526
   - Test - B: 22.3718418772
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.266562
 >> iter 2000, loss: 7.188676
 >> iter 3000, loss: 2.828341
 >> iter 4000, loss: 1.059977
 >> iter 5000, loss: 0.420722
 >> iter 6000, loss: 0.258489
 >> iter 7000, loss: 0.105778
 >> iter 8000, loss: 0.047131
 >> iter 9000, loss: 0.026907
 >> iter 10000, loss: 0.056968
   Number of active neurons: 10
 >> iter 11000, loss: 0.030117
 >> iter 12000, loss: 0.056898
 >> iter 13000, loss: 0.068796
 >> iter 14000, loss: 0.096963
 >> iter 15000, loss: 0.046665
 >> iter 16000, loss: 0.022745
 >> iter 17000, loss: 0.046845
 >> iter 18000, loss: 0.023285
 >> iter 19000, loss: 0.157186
 >> iter 20000, loss: 0.134697
   Number of active neurons: 10
 >> iter 21000, loss: 0.090097
 >> iter 22000, loss: 0.040660
 >> iter 23000, loss: 0.070500
 >> iter 24000, loss: 0.032738
 >> iter 25000, loss: 0.041533
 >> iter 26000, loss: 0.021111
 >> iter 27000, loss: 0.154400
 >> iter 28000, loss: 0.081642
 >> iter 29000, loss: 0.077636
 >> iter 30000, loss: 0.035456
   Number of active neurons: 9
 >> iter 31000, loss: 0.034337
 >> iter 32000, loss: 0.018204
 >> iter 33000, loss: 0.053987
 >> iter 34000, loss: 0.025957
 >> iter 35000, loss: 0.015399
 >> iter 36000, loss: 0.010319
 >> iter 37000, loss: 0.057653
 >> iter 38000, loss: 0.026619
 >> iter 39000, loss: 0.151212
 >> iter 40000, loss: 0.061943
   Number of active neurons: 9
 >> iter 41000, loss: 0.089914
 >> iter 42000, loss: 0.038913
 >> iter 43000, loss: 0.114298
 >> iter 44000, loss: 0.048136
 >> iter 45000, loss: 0.281200
 >> iter 46000, loss: 0.113257
 >> iter 47000, loss: 0.142401
 >> iter 48000, loss: 0.059769
 >> iter 49000, loss: 0.172445
 >> iter 50000, loss: 0.071716
   Number of active neurons: 8
 >> iter 51000, loss: 0.032700
 >> iter 52000, loss: 0.017548
 >> iter 53000, loss: 0.143996
 >> iter 54000, loss: 0.059890
 >> iter 55000, loss: 0.124410
 >> iter 56000, loss: 0.052486
 >> iter 57000, loss: 0.163417
 >> iter 58000, loss: 0.068232
 >> iter 59000, loss: 0.143199
 >> iter 60000, loss: 0.060433
   Number of active neurons: 8
 >> iter 61000, loss: 0.113671
 >> iter 62000, loss: 0.048709
 >> iter 63000, loss: 0.349795
 >> iter 64000, loss: 0.142834
 >> iter 65000, loss: 0.060829
 >> iter 66000, loss: 0.028933
 >> iter 67000, loss: 0.112950
 >> iter 68000, loss: 0.057487
 >> iter 69000, loss: 0.103664
 >> iter 70000, loss: 0.044940
   Number of active neurons: 8
 >> iter 71000, loss: 0.022190
 >> iter 72000, loss: 0.013266
 >> iter 73000, loss: 0.065868
 >> iter 74000, loss: 0.029767
 >> iter 75000, loss: 0.112336
 >> iter 76000, loss: 0.047344
 >> iter 77000, loss: 0.233697
 >> iter 78000, loss: 0.095208
 >> iter 79000, loss: 0.041714
 >> iter 80000, loss: 0.021016
   Number of active neurons: 8
 >> iter 81000, loss: 0.174213
 >> iter 82000, loss: 0.072272
 >> iter 83000, loss: 0.032747
 >> iter 84000, loss: 0.017239
 >> iter 85000, loss: 0.013511
 >> iter 86000, loss: 0.009467
 >> iter 87000, loss: 0.242341
 >> iter 88000, loss: 0.098146
 >> iter 89000, loss: 0.042753
 >> iter 90000, loss: 0.021263
   Number of active neurons: 8
 >> iter 91000, loss: 0.166868
 >> iter 92000, loss: 0.069253
 >> iter 93000, loss: 0.088587
 >> iter 94000, loss: 0.039330
 >> iter 95000, loss: 0.084661
 >> iter 96000, loss: 0.037618
 >> iter 97000, loss: 0.019133
 >> iter 98000, loss: 0.011725
 >> iter 99000, loss: 0.353039
 >> iter 100000, loss: 0.142844
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 17.8321445237
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.264185
 >> iter 2000, loss: 7.822364
 >> iter 3000, loss: 2.928447
 >> iter 4000, loss: 1.261922
 >> iter 5000, loss: 0.481546
 >> iter 6000, loss: 0.188499
 >> iter 7000, loss: 0.133708
 >> iter 8000, loss: 0.089241
 >> iter 9000, loss: 0.041526
 >> iter 10000, loss: 0.022430
   Number of active neurons: 10
 >> iter 11000, loss: 0.015223
 >> iter 12000, loss: 0.011912
 >> iter 13000, loss: 0.010797
 >> iter 14000, loss: 0.009911
 >> iter 15000, loss: 0.009758
 >> iter 16000, loss: 0.009293
 >> iter 17000, loss: 0.009330
 >> iter 18000, loss: 0.009015
 >> iter 19000, loss: 0.009120
 >> iter 20000, loss: 0.378667
   Number of active neurons: 10
 >> iter 21000, loss: 0.154193
 >> iter 22000, loss: 0.068512
 >> iter 23000, loss: 0.032825
 >> iter 24000, loss: 0.108775
 >> iter 25000, loss: 0.049661
 >> iter 26000, loss: 0.083434
 >> iter 27000, loss: 0.208541
 >> iter 28000, loss: 0.087617
 >> iter 29000, loss: 0.098472
 >> iter 30000, loss: 0.044971
   Number of active neurons: 10
 >> iter 31000, loss: 0.023881
 >> iter 32000, loss: 0.015010
 >> iter 33000, loss: 0.011742
 >> iter 34000, loss: 0.070112
 >> iter 35000, loss: 0.351444
 >> iter 36000, loss: 0.141378
 >> iter 37000, loss: 0.061441
 >> iter 38000, loss: 0.038721
 >> iter 39000, loss: 0.021245
 >> iter 40000, loss: 0.127446
   Number of active neurons: 10
 >> iter 41000, loss: 0.056493
 >> iter 42000, loss: 0.029337
 >> iter 43000, loss: 0.070520
 >> iter 44000, loss: 0.033899
 >> iter 45000, loss: 0.020729
 >> iter 46000, loss: 0.013936
 >> iter 47000, loss: 0.032926
 >> iter 48000, loss: 0.018693
 >> iter 49000, loss: 0.012982
 >> iter 50000, loss: 0.224811
   Number of active neurons: 10
 >> iter 51000, loss: 0.215467
 >> iter 52000, loss: 0.219221
 >> iter 53000, loss: 0.093978
 >> iter 54000, loss: 0.043635
 >> iter 55000, loss: 0.032796
 >> iter 56000, loss: 0.019191
 >> iter 57000, loss: 0.205963
 >> iter 58000, loss: 0.085327
 >> iter 59000, loss: 0.235398
 >> iter 60000, loss: 0.203352
   Number of active neurons: 10
 >> iter 61000, loss: 0.236274
 >> iter 62000, loss: 0.182698
 >> iter 63000, loss: 0.081136
 >> iter 64000, loss: 0.099122
 >> iter 65000, loss: 0.354585
 >> iter 66000, loss: 0.148670
 >> iter 67000, loss: 0.065317
 >> iter 68000, loss: 0.031630
 >> iter 69000, loss: 0.018630
 >> iter 70000, loss: 0.102581
   Number of active neurons: 10
 >> iter 71000, loss: 0.045770
 >> iter 72000, loss: 0.023753
 >> iter 73000, loss: 0.015016
 >> iter 74000, loss: 0.182121
 >> iter 75000, loss: 0.136751
 >> iter 76000, loss: 0.084850
 >> iter 77000, loss: 0.130822
 >> iter 78000, loss: 0.069080
 >> iter 79000, loss: 0.044456
 >> iter 80000, loss: 0.023741
   Number of active neurons: 10
 >> iter 81000, loss: 0.070917
 >> iter 82000, loss: 0.034635
 >> iter 83000, loss: 0.018982
 >> iter 84000, loss: 0.012411
 >> iter 85000, loss: 0.011153
 >> iter 86000, loss: 0.009077
 >> iter 87000, loss: 0.008447
 >> iter 88000, loss: 0.007801
 >> iter 89000, loss: 0.007884
 >> iter 90000, loss: 0.007836
   Number of active neurons: 10
 >> iter 91000, loss: 0.007799
 >> iter 92000, loss: 0.011945
 >> iter 93000, loss: 0.168582
 >> iter 94000, loss: 0.090879
 >> iter 95000, loss: 0.063462
 >> iter 96000, loss: 0.275084
 >> iter 97000, loss: 0.181262
 >> iter 98000, loss: 0.077935
 >> iter 99000, loss: 0.036984
 >> iter 100000, loss: 0.020504
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0129998700013
   - Test - A: 14.3323778415
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.606242
 >> iter 2000, loss: 7.683701
 >> iter 3000, loss: 2.852286
 >> iter 4000, loss: 1.061538
 >> iter 5000, loss: 0.399938
 >> iter 6000, loss: 0.154891
 >> iter 7000, loss: 0.064199
 >> iter 8000, loss: 0.030120
 >> iter 9000, loss: 0.017614
 >> iter 10000, loss: 0.012396
   Number of active neurons: 10
 >> iter 11000, loss: 0.010542
 >> iter 12000, loss: 0.009550
 >> iter 13000, loss: 0.009327
 >> iter 14000, loss: 0.008953
 >> iter 15000, loss: 0.008985
 >> iter 16000, loss: 0.008747
 >> iter 17000, loss: 0.008847
 >> iter 18000, loss: 0.008630
 >> iter 19000, loss: 0.146679
 >> iter 20000, loss: 0.061035
   Number of active neurons: 9
 >> iter 21000, loss: 0.028283
 >> iter 22000, loss: 0.015843
 >> iter 23000, loss: 0.011315
 >> iter 24000, loss: 0.009499
 >> iter 25000, loss: 0.008967
 >> iter 26000, loss: 0.008568
 >> iter 27000, loss: 0.141422
 >> iter 28000, loss: 0.059052
 >> iter 29000, loss: 0.027633
 >> iter 30000, loss: 0.015653
   Number of active neurons: 9
 >> iter 31000, loss: 0.011267
 >> iter 32000, loss: 0.009494
 >> iter 33000, loss: 0.008937
 >> iter 34000, loss: 0.008574
 >> iter 35000, loss: 0.114133
 >> iter 36000, loss: 0.048344
 >> iter 37000, loss: 0.023248
 >> iter 38000, loss: 0.013726
 >> iter 39000, loss: 0.010261
 >> iter 40000, loss: 0.008897
   Number of active neurons: 9
 >> iter 41000, loss: 0.008453
 >> iter 42000, loss: 0.008185
 >> iter 43000, loss: 0.008117
 >> iter 44000, loss: 0.007992
 >> iter 45000, loss: 0.007955
 >> iter 46000, loss: 0.007847
 >> iter 47000, loss: 0.007815
 >> iter 48000, loss: 0.007733
 >> iter 49000, loss: 0.007711
 >> iter 50000, loss: 0.007643
   Number of active neurons: 9
 >> iter 51000, loss: 0.007623
 >> iter 52000, loss: 0.007566
 >> iter 53000, loss: 0.007544
 >> iter 54000, loss: 0.007472
 >> iter 55000, loss: 0.007459
 >> iter 56000, loss: 0.007357
 >> iter 57000, loss: 0.231555
 >> iter 58000, loss: 0.092560
 >> iter 59000, loss: 0.040288
 >> iter 60000, loss: 0.020420
   Number of active neurons: 9
 >> iter 61000, loss: 0.012900
 >> iter 62000, loss: 0.009874
 >> iter 63000, loss: 0.008716
 >> iter 64000, loss: 0.008117
 >> iter 65000, loss: 0.007918
 >> iter 66000, loss: 0.007699
 >> iter 67000, loss: 0.007666
 >> iter 68000, loss: 0.007517
 >> iter 69000, loss: 0.007528
 >> iter 70000, loss: 0.007388
   Number of active neurons: 9
 >> iter 71000, loss: 0.329942
 >> iter 72000, loss: 0.167993
 >> iter 73000, loss: 0.070689
 >> iter 74000, loss: 0.031773
 >> iter 75000, loss: 0.016900
 >> iter 76000, loss: 0.011053
 >> iter 77000, loss: 0.029277
 >> iter 78000, loss: 0.015769
 >> iter 79000, loss: 0.010523
 >> iter 80000, loss: 0.008408
   Number of active neurons: 8
 >> iter 81000, loss: 0.007653
 >> iter 82000, loss: 0.007244
 >> iter 83000, loss: 0.007150
 >> iter 84000, loss: 0.006988
 >> iter 85000, loss: 0.006991
 >> iter 86000, loss: 0.006875
 >> iter 87000, loss: 0.006861
 >> iter 88000, loss: 0.006759
 >> iter 89000, loss: 0.006743
 >> iter 90000, loss: 0.006648
   Number of active neurons: 8
 >> iter 91000, loss: 0.006618
 >> iter 92000, loss: 0.006532
 >> iter 93000, loss: 0.006523
 >> iter 94000, loss: 0.006452
 >> iter 95000, loss: 0.375620
 >> iter 96000, loss: 0.148434
 >> iter 97000, loss: 0.061759
 >> iter 98000, loss: 0.028342
 >> iter 99000, loss: 0.015420
 >> iter 100000, loss: 0.010286
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0049997500125
   - Test - Big: 0.0
   - Test - A: 18.7120858609
   - Test - B: 16.6922205186
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.258040
 >> iter 2000, loss: 7.300237
 >> iter 3000, loss: 2.750437
 >> iter 4000, loss: 1.022713
 >> iter 5000, loss: 0.384240
 >> iter 6000, loss: 0.148008
 >> iter 7000, loss: 0.249808
 >> iter 8000, loss: 0.102689
 >> iter 9000, loss: 0.045432
 >> iter 10000, loss: 0.096863
   Number of active neurons: 10
 >> iter 11000, loss: 0.043315
 >> iter 12000, loss: 0.022025
 >> iter 13000, loss: 0.091035
 >> iter 14000, loss: 0.041533
 >> iter 15000, loss: 0.021455
 >> iter 16000, loss: 0.013261
 >> iter 17000, loss: 0.081287
 >> iter 18000, loss: 0.038699
 >> iter 19000, loss: 0.299628
 >> iter 20000, loss: 0.119758
   Number of active neurons: 9
 >> iter 21000, loss: 0.057880
 >> iter 22000, loss: 0.066829
 >> iter 23000, loss: 0.031413
 >> iter 24000, loss: 0.017452
 >> iter 25000, loss: 0.258199
 >> iter 26000, loss: 0.116170
 >> iter 27000, loss: 0.050038
 >> iter 28000, loss: 0.024487
 >> iter 29000, loss: 0.094315
 >> iter 30000, loss: 0.041264
   Number of active neurons: 9
 >> iter 31000, loss: 0.053290
 >> iter 32000, loss: 0.025621
 >> iter 33000, loss: 0.014597
 >> iter 34000, loss: 0.116810
 >> iter 35000, loss: 0.055900
 >> iter 36000, loss: 0.026434
 >> iter 37000, loss: 0.014838
 >> iter 38000, loss: 0.010174
 >> iter 39000, loss: 0.384772
 >> iter 40000, loss: 0.154390
   Number of active neurons: 9
 >> iter 41000, loss: 0.154312
 >> iter 42000, loss: 0.065503
 >> iter 43000, loss: 0.030420
 >> iter 44000, loss: 0.018258
 >> iter 45000, loss: 0.011838
 >> iter 46000, loss: 0.008918
 >> iter 47000, loss: 0.156452
 >> iter 48000, loss: 0.146090
 >> iter 49000, loss: 0.061696
 >> iter 50000, loss: 0.028948
   Number of active neurons: 9
 >> iter 51000, loss: 0.028690
 >> iter 52000, loss: 0.015865
 >> iter 53000, loss: 0.251460
 >> iter 54000, loss: 0.102339
 >> iter 55000, loss: 0.065456
 >> iter 56000, loss: 0.030226
 >> iter 57000, loss: 0.016616
 >> iter 58000, loss: 0.011165
 >> iter 59000, loss: 0.031361
 >> iter 60000, loss: 0.016507
   Number of active neurons: 9
 >> iter 61000, loss: 0.034257
 >> iter 62000, loss: 0.017534
 >> iter 63000, loss: 0.154880
 >> iter 64000, loss: 0.063672
 >> iter 65000, loss: 0.029019
 >> iter 66000, loss: 0.015731
 >> iter 67000, loss: 0.010551
 >> iter 68000, loss: 0.017052
 >> iter 69000, loss: 0.177420
 >> iter 70000, loss: 0.072213
   Number of active neurons: 9
 >> iter 71000, loss: 0.032301
 >> iter 72000, loss: 0.016946
 >> iter 73000, loss: 0.011051
 >> iter 74000, loss: 0.008530
 >> iter 75000, loss: 0.221985
 >> iter 76000, loss: 0.112761
 >> iter 77000, loss: 0.047680
 >> iter 78000, loss: 0.022635
 >> iter 79000, loss: 0.052921
 >> iter 80000, loss: 0.024481
   Number of active neurons: 9
 >> iter 81000, loss: 0.013467
 >> iter 82000, loss: 0.009146
 >> iter 83000, loss: 0.251526
 >> iter 84000, loss: 0.100793
 >> iter 85000, loss: 0.043186
 >> iter 86000, loss: 0.021136
 >> iter 87000, loss: 0.137467
 >> iter 88000, loss: 0.057385
 >> iter 89000, loss: 0.100728
 >> iter 90000, loss: 0.043983
   Number of active neurons: 9
 >> iter 91000, loss: 0.021661
 >> iter 92000, loss: 0.012846
 >> iter 93000, loss: 0.254211
 >> iter 94000, loss: 0.103574
 >> iter 95000, loss: 0.044996
 >> iter 96000, loss: 0.022229
 >> iter 97000, loss: 0.097891
 >> iter 98000, loss: 0.042662
 >> iter 99000, loss: 0.021196
 >> iter 100000, loss: 0.012742
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0089999100009
   - Test - A: 0.0
   - Test - B: 18.5454303046
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.288512
 >> iter 2000, loss: 10.276803
 >> iter 3000, loss: 4.617602
 >> iter 4000, loss: 1.733178
 >> iter 5000, loss: 0.692846
 >> iter 6000, loss: 0.296662
 >> iter 7000, loss: 0.136741
 >> iter 8000, loss: 0.059208
 >> iter 9000, loss: 0.105478
 >> iter 10000, loss: 0.049526
   Number of active neurons: 10
 >> iter 11000, loss: 0.025681
 >> iter 12000, loss: 0.091255
 >> iter 13000, loss: 0.069031
 >> iter 14000, loss: 0.130317
 >> iter 15000, loss: 0.069495
 >> iter 16000, loss: 0.042954
 >> iter 17000, loss: 0.101764
 >> iter 18000, loss: 0.084553
 >> iter 19000, loss: 0.165786
 >> iter 20000, loss: 0.070741
   Number of active neurons: 9
 >> iter 21000, loss: 0.055448
 >> iter 22000, loss: 0.026841
 >> iter 23000, loss: 0.053183
 >> iter 24000, loss: 0.090402
 >> iter 25000, loss: 0.040547
 >> iter 26000, loss: 0.020619
 >> iter 27000, loss: 0.013953
 >> iter 28000, loss: 0.020695
 >> iter 29000, loss: 0.061782
 >> iter 30000, loss: 0.051797
   Number of active neurons: 8
 >> iter 31000, loss: 0.065358
 >> iter 32000, loss: 0.030560
 >> iter 33000, loss: 0.052135
 >> iter 34000, loss: 0.025454
 >> iter 35000, loss: 0.015210
 >> iter 36000, loss: 0.010549
 >> iter 37000, loss: 0.052185
 >> iter 38000, loss: 0.035673
 >> iter 39000, loss: 0.018605
 >> iter 40000, loss: 0.023666
   Number of active neurons: 8
 >> iter 41000, loss: 0.013720
 >> iter 42000, loss: 0.009752
 >> iter 43000, loss: 0.034967
 >> iter 44000, loss: 0.019143
 >> iter 45000, loss: 0.039194
 >> iter 46000, loss: 0.019928
 >> iter 47000, loss: 0.032806
 >> iter 48000, loss: 0.017126
 >> iter 49000, loss: 0.048992
 >> iter 50000, loss: 0.165835
   Number of active neurons: 8
 >> iter 51000, loss: 0.099134
 >> iter 52000, loss: 0.043588
 >> iter 53000, loss: 0.051390
 >> iter 54000, loss: 0.024613
 >> iter 55000, loss: 0.019545
 >> iter 56000, loss: 0.012383
 >> iter 57000, loss: 0.009378
 >> iter 58000, loss: 0.008005
 >> iter 59000, loss: 0.025074
 >> iter 60000, loss: 0.014227
   Number of active neurons: 8
 >> iter 61000, loss: 0.009790
 >> iter 62000, loss: 0.007939
 >> iter 63000, loss: 0.007670
 >> iter 64000, loss: 0.006991
 >> iter 65000, loss: 0.048457
 >> iter 66000, loss: 0.022454
 >> iter 67000, loss: 0.013459
 >> iter 68000, loss: 0.009187
 >> iter 69000, loss: 0.132466
 >> iter 70000, loss: 0.080689
   Number of active neurons: 8
 >> iter 71000, loss: 0.036331
 >> iter 72000, loss: 0.018517
 >> iter 73000, loss: 0.011697
 >> iter 74000, loss: 0.008666
 >> iter 75000, loss: 0.023597
 >> iter 76000, loss: 0.013158
 >> iter 77000, loss: 0.083309
 >> iter 78000, loss: 0.099363
 >> iter 79000, loss: 0.057880
 >> iter 80000, loss: 0.026807
   Number of active neurons: 8
 >> iter 81000, loss: 0.044801
 >> iter 82000, loss: 0.021802
 >> iter 83000, loss: 0.102414
 >> iter 84000, loss: 0.059893
 >> iter 85000, loss: 0.027745
 >> iter 86000, loss: 0.015203
 >> iter 87000, loss: 0.051410
 >> iter 88000, loss: 0.024086
 >> iter 89000, loss: 0.036752
 >> iter 90000, loss: 0.018425
   Number of active neurons: 8
 >> iter 91000, loss: 0.084531
 >> iter 92000, loss: 0.056172
 >> iter 93000, loss: 0.137092
 >> iter 94000, loss: 0.056668
 >> iter 95000, loss: 0.026626
 >> iter 96000, loss: 0.014532
 >> iter 97000, loss: 0.010579
 >> iter 98000, loss: 0.010510
 >> iter 99000, loss: 0.063069
 >> iter 100000, loss: 0.027778
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.029999400012
   - Test - Long: 0.0249987500625
   - Test - Big: 0.0339996600034
   - Test - A: 23.1784547697
   - Test - B: 19.3187120859
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.771615
 >> iter 2000, loss: 7.623786
 >> iter 3000, loss: 2.912739
 >> iter 4000, loss: 1.089293
 >> iter 5000, loss: 0.431807
 >> iter 6000, loss: 0.169014
 >> iter 7000, loss: 0.187282
 >> iter 8000, loss: 0.080384
 >> iter 9000, loss: 0.099375
 >> iter 10000, loss: 0.089666
   Number of active neurons: 10
 >> iter 11000, loss: 0.042839
 >> iter 12000, loss: 0.023697
 >> iter 13000, loss: 0.016226
 >> iter 14000, loss: 0.089988
 >> iter 15000, loss: 0.041617
 >> iter 16000, loss: 0.084146
 >> iter 17000, loss: 0.039262
 >> iter 18000, loss: 0.021525
 >> iter 19000, loss: 0.014824
 >> iter 20000, loss: 0.080996
   Number of active neurons: 10
 >> iter 21000, loss: 0.044429
 >> iter 22000, loss: 0.022638
 >> iter 23000, loss: 0.014437
 >> iter 24000, loss: 0.011251
 >> iter 25000, loss: 0.057634
 >> iter 26000, loss: 0.066762
 >> iter 27000, loss: 0.031699
 >> iter 28000, loss: 0.204318
 >> iter 29000, loss: 0.086860
 >> iter 30000, loss: 0.039822
   Number of active neurons: 10
 >> iter 31000, loss: 0.021562
 >> iter 32000, loss: 0.080354
 >> iter 33000, loss: 0.037296
 >> iter 34000, loss: 0.020022
 >> iter 35000, loss: 0.013461
 >> iter 36000, loss: 0.012511
 >> iter 37000, loss: 0.033188
 >> iter 38000, loss: 0.018037
 >> iter 39000, loss: 0.043817
 >> iter 40000, loss: 0.086407
   Number of active neurons: 10
 >> iter 41000, loss: 0.038892
 >> iter 42000, loss: 0.040089
 >> iter 43000, loss: 0.021553
 >> iter 44000, loss: 0.164565
 >> iter 45000, loss: 0.091012
 >> iter 46000, loss: 0.040077
 >> iter 47000, loss: 0.021249
 >> iter 48000, loss: 0.125583
 >> iter 49000, loss: 0.058595
 >> iter 50000, loss: 0.115919
   Number of active neurons: 10
 >> iter 51000, loss: 0.065721
 >> iter 52000, loss: 0.030838
 >> iter 53000, loss: 0.018136
 >> iter 54000, loss: 0.013337
 >> iter 55000, loss: 0.043856
 >> iter 56000, loss: 0.022457
 >> iter 57000, loss: 0.014385
 >> iter 58000, loss: 0.019249
 >> iter 59000, loss: 0.034389
 >> iter 60000, loss: 0.019081
   Number of active neurons: 10
 >> iter 61000, loss: 0.012747
 >> iter 62000, loss: 0.176373
 >> iter 63000, loss: 0.073443
 >> iter 64000, loss: 0.043337
 >> iter 65000, loss: 0.022603
 >> iter 66000, loss: 0.052676
 >> iter 67000, loss: 0.025570
 >> iter 68000, loss: 0.064612
 >> iter 69000, loss: 0.029851
 >> iter 70000, loss: 0.023845
   Number of active neurons: 10
 >> iter 71000, loss: 0.036315
 >> iter 72000, loss: 0.018784
 >> iter 73000, loss: 0.026425
 >> iter 74000, loss: 0.014815
 >> iter 75000, loss: 0.117526
 >> iter 76000, loss: 0.049948
 >> iter 77000, loss: 0.024276
 >> iter 78000, loss: 0.014648
 >> iter 79000, loss: 0.010899
 >> iter 80000, loss: 0.014988
   Number of active neurons: 10
 >> iter 81000, loss: 0.011140
 >> iter 82000, loss: 0.121778
 >> iter 83000, loss: 0.051826
 >> iter 84000, loss: 0.222199
 >> iter 85000, loss: 0.090779
 >> iter 86000, loss: 0.039924
 >> iter 87000, loss: 0.020611
 >> iter 88000, loss: 0.073251
 >> iter 89000, loss: 0.033663
 >> iter 90000, loss: 0.022222
   Number of active neurons: 10
 >> iter 91000, loss: 0.040374
 >> iter 92000, loss: 0.020891
 >> iter 93000, loss: 0.013240
 >> iter 94000, loss: 0.010446
 >> iter 95000, loss: 0.020230
 >> iter 96000, loss: 0.012176
 >> iter 97000, loss: 0.075855
 >> iter 98000, loss: 0.050259
 >> iter 99000, loss: 0.025104
 >> iter 100000, loss: 0.014565
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.049997500125
   - Test - Big: 0.0089999100009
   - Test - A: 15.1856542897
   - Test - B: 56.5228984734
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.592900
 >> iter 2000, loss: 7.084903
 >> iter 3000, loss: 2.842246
 >> iter 4000, loss: 1.065476
 >> iter 5000, loss: 0.457480
 >> iter 6000, loss: 0.177848
 >> iter 7000, loss: 0.271086
 >> iter 8000, loss: 0.112896
 >> iter 9000, loss: 0.051204
 >> iter 10000, loss: 0.025167
   Number of active neurons: 10
 >> iter 11000, loss: 0.115373
 >> iter 12000, loss: 0.050644
 >> iter 13000, loss: 0.072938
 >> iter 14000, loss: 0.033640
 >> iter 15000, loss: 0.035180
 >> iter 16000, loss: 0.018663
 >> iter 17000, loss: 0.078993
 >> iter 18000, loss: 0.189397
 >> iter 19000, loss: 0.160162
 >> iter 20000, loss: 0.066702
   Number of active neurons: 10
 >> iter 21000, loss: 0.150868
 >> iter 22000, loss: 0.064503
 >> iter 23000, loss: 0.316449
 >> iter 24000, loss: 0.143334
 >> iter 25000, loss: 0.203593
 >> iter 26000, loss: 0.093127
 >> iter 27000, loss: 0.057338
 >> iter 28000, loss: 0.027165
 >> iter 29000, loss: 0.087133
 >> iter 30000, loss: 0.095032
   Number of active neurons: 10
 >> iter 31000, loss: 0.060459
 >> iter 32000, loss: 0.035071
 >> iter 33000, loss: 0.076403
 >> iter 34000, loss: 0.034466
 >> iter 35000, loss: 0.065676
 >> iter 36000, loss: 0.034857
 >> iter 37000, loss: 0.059811
 >> iter 38000, loss: 0.140074
 >> iter 39000, loss: 0.222232
 >> iter 40000, loss: 0.092031
   Number of active neurons: 10
 >> iter 41000, loss: 0.221636
 >> iter 42000, loss: 0.092418
 >> iter 43000, loss: 0.040649
 >> iter 44000, loss: 0.020361
 >> iter 45000, loss: 0.014252
 >> iter 46000, loss: 0.053812
 >> iter 47000, loss: 0.046546
 >> iter 48000, loss: 0.034982
 >> iter 49000, loss: 0.037923
 >> iter 50000, loss: 0.019029
   Number of active neurons: 9
 >> iter 51000, loss: 0.082071
 >> iter 52000, loss: 0.043408
 >> iter 53000, loss: 0.034479
 >> iter 54000, loss: 0.033987
 >> iter 55000, loss: 0.035776
 >> iter 56000, loss: 0.056365
 >> iter 57000, loss: 0.026457
 >> iter 58000, loss: 0.014522
 >> iter 59000, loss: 0.033007
 >> iter 60000, loss: 0.016993
   Number of active neurons: 9
 >> iter 61000, loss: 0.010975
 >> iter 62000, loss: 0.008235
 >> iter 63000, loss: 0.007407
 >> iter 64000, loss: 0.035576
 >> iter 65000, loss: 0.017584
 >> iter 66000, loss: 0.010462
 >> iter 67000, loss: 0.201688
 >> iter 68000, loss: 0.081121
 >> iter 69000, loss: 0.071769
 >> iter 70000, loss: 0.187233
   Number of active neurons: 8
 >> iter 71000, loss: 0.101418
 >> iter 72000, loss: 0.043893
 >> iter 73000, loss: 0.027232
 >> iter 74000, loss: 0.015117
 >> iter 75000, loss: 0.161732
 >> iter 76000, loss: 0.104303
 >> iter 77000, loss: 0.048697
 >> iter 78000, loss: 0.085066
 >> iter 79000, loss: 0.168588
 >> iter 80000, loss: 0.081958
   Number of active neurons: 8
 >> iter 81000, loss: 0.071829
 >> iter 82000, loss: 0.032959
 >> iter 83000, loss: 0.206033
 >> iter 84000, loss: 0.101138
 >> iter 85000, loss: 0.045172
 >> iter 86000, loss: 0.027490
 >> iter 87000, loss: 0.015985
 >> iter 88000, loss: 0.010469
 >> iter 89000, loss: 0.039056
 >> iter 90000, loss: 0.128188
   Number of active neurons: 8
 >> iter 91000, loss: 0.072031
 >> iter 92000, loss: 0.032397
 >> iter 93000, loss: 0.038511
 >> iter 94000, loss: 0.019053
 >> iter 95000, loss: 0.087632
 >> iter 96000, loss: 0.038614
 >> iter 97000, loss: 0.019113
 >> iter 98000, loss: 0.011416
 >> iter 99000, loss: 0.033238
 >> iter 100000, loss: 0.016493
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.00599988000241
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 13.0591293914
   - Test - B: 15.9122725152
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.620012
 >> iter 2000, loss: 6.162252
 >> iter 3000, loss: 2.287576
 >> iter 4000, loss: 0.853722
 >> iter 5000, loss: 0.323674
 >> iter 6000, loss: 0.126982
 >> iter 7000, loss: 0.053953
 >> iter 8000, loss: 0.026361
 >> iter 9000, loss: 0.016015
 >> iter 10000, loss: 0.011743
   Number of active neurons: 10
 >> iter 11000, loss: 0.110075
 >> iter 12000, loss: 0.047230
 >> iter 13000, loss: 0.109747
 >> iter 14000, loss: 0.047340
 >> iter 15000, loss: 0.230596
 >> iter 16000, loss: 0.094720
 >> iter 17000, loss: 0.042695
 >> iter 18000, loss: 0.022499
 >> iter 19000, loss: 0.103207
 >> iter 20000, loss: 0.045355
   Number of active neurons: 10
 >> iter 21000, loss: 0.123754
 >> iter 22000, loss: 0.053304
 >> iter 23000, loss: 0.130329
 >> iter 24000, loss: 0.055584
 >> iter 25000, loss: 0.131674
 >> iter 26000, loss: 0.056047
 >> iter 27000, loss: 0.131569
 >> iter 28000, loss: 0.055962
 >> iter 29000, loss: 0.130563
 >> iter 30000, loss: 0.055584
   Number of active neurons: 10
 >> iter 31000, loss: 0.129686
 >> iter 32000, loss: 0.055281
 >> iter 33000, loss: 0.128036
 >> iter 34000, loss: 0.054727
 >> iter 35000, loss: 0.182157
 >> iter 36000, loss: 0.075544
 >> iter 37000, loss: 0.055617
 >> iter 38000, loss: 0.026649
 >> iter 39000, loss: 0.015594
 >> iter 40000, loss: 0.035895
   Number of active neurons: 10
 >> iter 41000, loss: 0.018838
 >> iter 42000, loss: 0.012402
 >> iter 43000, loss: 0.231148
 >> iter 44000, loss: 0.093454
 >> iter 45000, loss: 0.044507
 >> iter 46000, loss: 0.022021
 >> iter 47000, loss: 0.013412
 >> iter 48000, loss: 0.010044
 >> iter 49000, loss: 0.008634
 >> iter 50000, loss: 0.008165
   Number of active neurons: 10
 >> iter 51000, loss: 0.007661
 >> iter 52000, loss: 0.007734
 >> iter 53000, loss: 0.007245
 >> iter 54000, loss: 0.031302
 >> iter 55000, loss: 0.015964
 >> iter 56000, loss: 0.010077
 >> iter 57000, loss: 0.200406
 >> iter 58000, loss: 0.081763
 >> iter 59000, loss: 0.036406
 >> iter 60000, loss: 0.018900
   Number of active neurons: 10
 >> iter 61000, loss: 0.039160
 >> iter 62000, loss: 0.019769
 >> iter 63000, loss: 0.012296
 >> iter 64000, loss: 0.009228
 >> iter 65000, loss: 0.008148
 >> iter 66000, loss: 0.007469
 >> iter 67000, loss: 0.007137
 >> iter 68000, loss: 0.128523
 >> iter 69000, loss: 0.142666
 >> iter 70000, loss: 0.058692
   Number of active neurons: 10
 >> iter 71000, loss: 0.030435
 >> iter 72000, loss: 0.016132
 >> iter 73000, loss: 0.010755
 >> iter 74000, loss: 0.037011
 >> iter 75000, loss: 0.018293
 >> iter 76000, loss: 0.011137
 >> iter 77000, loss: 0.008517
 >> iter 78000, loss: 0.212164
 >> iter 79000, loss: 0.084045
 >> iter 80000, loss: 0.036285
   Number of active neurons: 8
 >> iter 81000, loss: 0.018086
 >> iter 82000, loss: 0.053458
 >> iter 83000, loss: 0.085323
 >> iter 84000, loss: 0.036798
 >> iter 85000, loss: 0.029097
 >> iter 86000, loss: 0.015401
 >> iter 87000, loss: 0.010470
 >> iter 88000, loss: 0.008249
 >> iter 89000, loss: 0.007498
 >> iter 90000, loss: 0.035977
   Number of active neurons: 7
 >> iter 91000, loss: 0.018156
 >> iter 92000, loss: 0.011290
 >> iter 93000, loss: 0.256400
 >> iter 94000, loss: 0.122456
 >> iter 95000, loss: 0.078385
 >> iter 96000, loss: 0.034306
 >> iter 97000, loss: 0.017637
 >> iter 98000, loss: 0.011167
 >> iter 99000, loss: 0.012898
 >> iter 100000, loss: 0.009077
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.506632891141
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.256530
 >> iter 2000, loss: 8.160074
 >> iter 3000, loss: 3.134266
 >> iter 4000, loss: 1.180693
 >> iter 5000, loss: 0.452999
 >> iter 6000, loss: 0.180222
 >> iter 7000, loss: 0.104425
 >> iter 8000, loss: 0.048920
 >> iter 9000, loss: 0.027821
 >> iter 10000, loss: 0.062177
   Number of active neurons: 10
 >> iter 11000, loss: 0.031936
 >> iter 12000, loss: 0.019737
 >> iter 13000, loss: 0.015153
 >> iter 14000, loss: 0.023437
 >> iter 15000, loss: 0.016238
 >> iter 16000, loss: 0.012933
 >> iter 17000, loss: 0.011811
 >> iter 18000, loss: 0.011038
 >> iter 19000, loss: 0.010859
 >> iter 20000, loss: 0.010501
   Number of active neurons: 10
 >> iter 21000, loss: 0.010517
 >> iter 22000, loss: 0.010212
 >> iter 23000, loss: 0.010288
 >> iter 24000, loss: 0.010015
 >> iter 25000, loss: 0.010112
 >> iter 26000, loss: 0.009844
 >> iter 27000, loss: 0.763493
 >> iter 28000, loss: 0.368467
 >> iter 29000, loss: 0.146432
 >> iter 30000, loss: 0.061258
   Number of active neurons: 10
 >> iter 31000, loss: 0.029766
 >> iter 32000, loss: 0.016817
 >> iter 33000, loss: 0.012087
 >> iter 34000, loss: 0.009687
 >> iter 35000, loss: 0.322347
 >> iter 36000, loss: 0.129868
 >> iter 37000, loss: 0.055577
 >> iter 38000, loss: 0.026641
 >> iter 39000, loss: 0.015591
 >> iter 40000, loss: 0.011121
   Number of active neurons: 10
 >> iter 41000, loss: 0.028978
 >> iter 42000, loss: 0.073537
 >> iter 43000, loss: 0.033116
 >> iter 44000, loss: 0.017605
 >> iter 45000, loss: 0.011729
 >> iter 46000, loss: 0.009412
 >> iter 47000, loss: 0.008613
 >> iter 48000, loss: 0.008144
 >> iter 49000, loss: 0.371701
 >> iter 50000, loss: 0.146177
   Number of active neurons: 10
 >> iter 51000, loss: 0.060170
 >> iter 52000, loss: 0.027703
 >> iter 53000, loss: 0.015528
 >> iter 54000, loss: 0.010947
 >> iter 55000, loss: 0.010567
 >> iter 56000, loss: 0.009055
 >> iter 57000, loss: 0.030762
 >> iter 58000, loss: 0.074447
 >> iter 59000, loss: 0.032946
 >> iter 60000, loss: 0.017085
   Number of active neurons: 9
 >> iter 61000, loss: 0.053360
 >> iter 62000, loss: 0.025009
 >> iter 63000, loss: 0.047754
 >> iter 64000, loss: 0.023041
 >> iter 65000, loss: 0.013729
 >> iter 66000, loss: 0.009916
 >> iter 67000, loss: 0.034379
 >> iter 68000, loss: 0.017530
 >> iter 69000, loss: 0.054365
 >> iter 70000, loss: 0.025321
   Number of active neurons: 9
 >> iter 71000, loss: 0.033947
 >> iter 72000, loss: 0.017558
 >> iter 73000, loss: 0.144900
 >> iter 74000, loss: 0.061057
 >> iter 75000, loss: 0.028411
 >> iter 76000, loss: 0.015786
 >> iter 77000, loss: 0.064802
 >> iter 78000, loss: 0.029213
 >> iter 79000, loss: 0.130066
 >> iter 80000, loss: 0.054509
   Number of active neurons: 9
 >> iter 81000, loss: 0.076860
 >> iter 82000, loss: 0.034730
 >> iter 83000, loss: 0.095135
 >> iter 84000, loss: 0.041001
 >> iter 85000, loss: 0.100112
 >> iter 86000, loss: 0.043349
 >> iter 87000, loss: 0.021564
 >> iter 88000, loss: 0.015804
 >> iter 89000, loss: 0.010847
 >> iter 90000, loss: 0.008851
   Number of active neurons: 9
 >> iter 91000, loss: 0.103708
 >> iter 92000, loss: 0.044230
 >> iter 93000, loss: 0.021793
 >> iter 94000, loss: 0.013166
 >> iter 95000, loss: 0.055657
 >> iter 96000, loss: 0.026146
 >> iter 97000, loss: 0.087976
 >> iter 98000, loss: 0.038851
 >> iter 99000, loss: 0.019714
 >> iter 100000, loss: 0.036048
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.276081
 >> iter 2000, loss: 7.634705
 >> iter 3000, loss: 2.898684
 >> iter 4000, loss: 1.081065
 >> iter 5000, loss: 0.616426
 >> iter 6000, loss: 0.241144
 >> iter 7000, loss: 0.135301
 >> iter 8000, loss: 0.057887
 >> iter 9000, loss: 0.048597
 >> iter 10000, loss: 0.024488
   Number of active neurons: 10
 >> iter 11000, loss: 0.029885
 >> iter 12000, loss: 0.016762
 >> iter 13000, loss: 0.076471
 >> iter 14000, loss: 0.034155
 >> iter 15000, loss: 0.048381
 >> iter 16000, loss: 0.048759
 >> iter 17000, loss: 0.371428
 >> iter 18000, loss: 0.149589
 >> iter 19000, loss: 0.063412
 >> iter 20000, loss: 0.030049
   Number of active neurons: 10
 >> iter 21000, loss: 0.017249
 >> iter 22000, loss: 0.012022
 >> iter 23000, loss: 0.036569
 >> iter 24000, loss: 0.019161
 >> iter 25000, loss: 0.046280
 >> iter 26000, loss: 0.022837
 >> iter 27000, loss: 0.079410
 >> iter 28000, loss: 0.077313
 >> iter 29000, loss: 0.090813
 >> iter 30000, loss: 0.039909
   Number of active neurons: 10
 >> iter 31000, loss: 0.049757
 >> iter 32000, loss: 0.023979
 >> iter 33000, loss: 0.014587
 >> iter 34000, loss: 0.010363
 >> iter 35000, loss: 0.008770
 >> iter 36000, loss: 0.008070
 >> iter 37000, loss: 0.093862
 >> iter 38000, loss: 0.039687
 >> iter 39000, loss: 0.091042
 >> iter 40000, loss: 0.039629
   Number of active neurons: 10
 >> iter 41000, loss: 0.098731
 >> iter 42000, loss: 0.042201
 >> iter 43000, loss: 0.292209
 >> iter 44000, loss: 0.117370
 >> iter 45000, loss: 0.050455
 >> iter 46000, loss: 0.024685
 >> iter 47000, loss: 0.014792
 >> iter 48000, loss: 0.010821
 >> iter 49000, loss: 0.084274
 >> iter 50000, loss: 0.037032
   Number of active neurons: 10
 >> iter 51000, loss: 0.019149
 >> iter 52000, loss: 0.012330
 >> iter 53000, loss: 0.107363
 >> iter 54000, loss: 0.045592
 >> iter 55000, loss: 0.114632
 >> iter 56000, loss: 0.048386
 >> iter 57000, loss: 0.116082
 >> iter 58000, loss: 0.049074
 >> iter 59000, loss: 0.108010
 >> iter 60000, loss: 0.046058
   Number of active neurons: 10
 >> iter 61000, loss: 0.110889
 >> iter 62000, loss: 0.046958
 >> iter 63000, loss: 0.106399
 >> iter 64000, loss: 0.045317
 >> iter 65000, loss: 0.103366
 >> iter 66000, loss: 0.043937
 >> iter 67000, loss: 0.021654
 >> iter 68000, loss: 0.013172
 >> iter 69000, loss: 0.102862
 >> iter 70000, loss: 0.043546
   Number of active neurons: 10
 >> iter 71000, loss: 0.502348
 >> iter 72000, loss: 0.303224
 >> iter 73000, loss: 0.121656
 >> iter 74000, loss: 0.052189
 >> iter 75000, loss: 0.025585
 >> iter 76000, loss: 0.015142
 >> iter 77000, loss: 0.011004
 >> iter 78000, loss: 0.009185
 >> iter 79000, loss: 0.008385
 >> iter 80000, loss: 0.007880
   Number of active neurons: 9
 >> iter 81000, loss: 0.076551
 >> iter 82000, loss: 0.033360
 >> iter 83000, loss: 0.065354
 >> iter 84000, loss: 0.029263
 >> iter 85000, loss: 0.015589
 >> iter 86000, loss: 0.010389
 >> iter 87000, loss: 0.493397
 >> iter 88000, loss: 0.202777
 >> iter 89000, loss: 0.083104
 >> iter 90000, loss: 0.037224
   Number of active neurons: 9
 >> iter 91000, loss: 0.101003
 >> iter 92000, loss: 0.044821
 >> iter 93000, loss: 0.044980
 >> iter 94000, loss: 0.022576
 >> iter 95000, loss: 0.013792
 >> iter 96000, loss: 0.072465
 >> iter 97000, loss: 0.081067
 >> iter 98000, loss: 0.036363
 >> iter 99000, loss: 0.019033
 >> iter 100000, loss: 0.012104
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 20.4319712019
   - Test - B: 17.1321911873
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.176106
 >> iter 2000, loss: 7.320369
 >> iter 3000, loss: 2.711135
 >> iter 4000, loss: 1.006047
 >> iter 5000, loss: 0.377237
 >> iter 6000, loss: 0.144896
 >> iter 7000, loss: 0.059306
 >> iter 8000, loss: 0.027299
 >> iter 9000, loss: 0.015510
 >> iter 10000, loss: 0.010871
   Number of active neurons: 10
 >> iter 11000, loss: 0.009291
 >> iter 12000, loss: 0.008423
 >> iter 13000, loss: 0.008308
 >> iter 14000, loss: 0.007940
 >> iter 15000, loss: 0.008080
 >> iter 16000, loss: 0.007746
 >> iter 17000, loss: 0.234117
 >> iter 18000, loss: 0.093605
 >> iter 19000, loss: 0.040522
 >> iter 20000, loss: 0.020379
   Number of active neurons: 10
 >> iter 21000, loss: 0.012959
 >> iter 22000, loss: 0.009894
 >> iter 23000, loss: 0.008884
 >> iter 24000, loss: 0.008238
 >> iter 25000, loss: 0.215831
 >> iter 26000, loss: 0.087246
 >> iter 27000, loss: 0.038559
 >> iter 28000, loss: 0.020007
 >> iter 29000, loss: 0.666051
 >> iter 30000, loss: 0.268052
   Number of active neurons: 10
 >> iter 31000, loss: 0.107721
 >> iter 32000, loss: 0.046594
 >> iter 33000, loss: 0.098355
 >> iter 34000, loss: 0.042982
 >> iter 35000, loss: 0.021550
 >> iter 36000, loss: 0.013183
 >> iter 37000, loss: 0.092886
 >> iter 38000, loss: 0.040282
 >> iter 39000, loss: 0.020408
 >> iter 40000, loss: 0.012763
   Number of active neurons: 10
 >> iter 41000, loss: 0.009900
 >> iter 42000, loss: 0.008650
 >> iter 43000, loss: 0.050998
 >> iter 44000, loss: 0.023873
 >> iter 45000, loss: 0.013824
 >> iter 46000, loss: 0.037241
 >> iter 47000, loss: 0.018713
 >> iter 48000, loss: 0.012098
 >> iter 49000, loss: 0.134470
 >> iter 50000, loss: 0.056220
   Number of active neurons: 10
 >> iter 51000, loss: 0.074439
 >> iter 52000, loss: 0.033950
 >> iter 53000, loss: 0.018751
 >> iter 54000, loss: 0.011928
 >> iter 55000, loss: 0.009231
 >> iter 56000, loss: 0.008928
 >> iter 57000, loss: 0.007943
 >> iter 58000, loss: 0.007595
 >> iter 59000, loss: 0.048683
 >> iter 60000, loss: 0.023131
   Number of active neurons: 10
 >> iter 61000, loss: 0.013729
 >> iter 62000, loss: 0.010001
 >> iter 63000, loss: 0.108420
 >> iter 64000, loss: 0.065762
 >> iter 65000, loss: 0.030606
 >> iter 66000, loss: 0.016573
 >> iter 67000, loss: 0.167172
 >> iter 68000, loss: 0.068448
 >> iter 69000, loss: 0.088140
 >> iter 70000, loss: 0.038283
   Number of active neurons: 10
 >> iter 71000, loss: 0.204934
 >> iter 72000, loss: 0.081761
 >> iter 73000, loss: 0.035323
 >> iter 74000, loss: 0.088651
 >> iter 75000, loss: 0.038528
 >> iter 76000, loss: 0.019312
 >> iter 77000, loss: 0.067672
 >> iter 78000, loss: 0.030199
 >> iter 79000, loss: 0.015964
 >> iter 80000, loss: 0.155662
   Number of active neurons: 10
 >> iter 81000, loss: 0.064225
 >> iter 82000, loss: 0.029067
 >> iter 83000, loss: 0.081508
 >> iter 84000, loss: 0.036436
 >> iter 85000, loss: 0.074424
 >> iter 86000, loss: 0.034056
 >> iter 87000, loss: 0.017740
 >> iter 88000, loss: 0.075931
 >> iter 89000, loss: 0.062655
 >> iter 90000, loss: 0.029077
   Number of active neurons: 10
 >> iter 91000, loss: 0.016085
 >> iter 92000, loss: 0.030281
 >> iter 93000, loss: 0.112773
 >> iter 94000, loss: 0.080271
 >> iter 95000, loss: 0.035886
 >> iter 96000, loss: 0.018717
 >> iter 97000, loss: 0.074303
 >> iter 98000, loss: 0.033746
 >> iter 99000, loss: 0.017712
 >> iter 100000, loss: 0.039475
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 14.319045397
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.164916
 >> iter 2000, loss: 8.800566
 >> iter 3000, loss: 3.450427
 >> iter 4000, loss: 1.281518
 >> iter 5000, loss: 0.576980
 >> iter 6000, loss: 0.220967
 >> iter 7000, loss: 0.153043
 >> iter 8000, loss: 0.064293
 >> iter 9000, loss: 0.102613
 >> iter 10000, loss: 0.045654
   Number of active neurons: 10
 >> iter 11000, loss: 0.091476
 >> iter 12000, loss: 0.041381
 >> iter 13000, loss: 0.021997
 >> iter 14000, loss: 0.013690
 >> iter 15000, loss: 0.083956
 >> iter 16000, loss: 0.068618
 >> iter 17000, loss: 0.045525
 >> iter 18000, loss: 0.022450
 >> iter 19000, loss: 0.093697
 >> iter 20000, loss: 0.041724
   Number of active neurons: 10
 >> iter 21000, loss: 0.093449
 >> iter 22000, loss: 0.041555
 >> iter 23000, loss: 0.051078
 >> iter 24000, loss: 0.024997
 >> iter 25000, loss: 0.028002
 >> iter 26000, loss: 0.041396
 >> iter 27000, loss: 0.021128
 >> iter 28000, loss: 0.012902
 >> iter 29000, loss: 0.035490
 >> iter 30000, loss: 0.018127
   Number of active neurons: 10
 >> iter 31000, loss: 0.102947
 >> iter 32000, loss: 0.043725
 >> iter 33000, loss: 0.049481
 >> iter 34000, loss: 0.023495
 >> iter 35000, loss: 0.013471
 >> iter 36000, loss: 0.009567
 >> iter 37000, loss: 0.095042
 >> iter 38000, loss: 0.041899
 >> iter 39000, loss: 0.022238
 >> iter 40000, loss: 0.012778
   Number of active neurons: 10
 >> iter 41000, loss: 0.009241
 >> iter 42000, loss: 0.007895
 >> iter 43000, loss: 0.028798
 >> iter 44000, loss: 0.015111
 >> iter 45000, loss: 0.009944
 >> iter 46000, loss: 0.008120
 >> iter 47000, loss: 0.031792
 >> iter 48000, loss: 0.016586
 >> iter 49000, loss: 0.260126
 >> iter 50000, loss: 0.105944
   Number of active neurons: 10
 >> iter 51000, loss: 0.046234
 >> iter 52000, loss: 0.022427
 >> iter 53000, loss: 0.013304
 >> iter 54000, loss: 0.009759
 >> iter 55000, loss: 0.012587
 >> iter 56000, loss: 0.009119
 >> iter 57000, loss: 0.083947
 >> iter 58000, loss: 0.036263
 >> iter 59000, loss: 0.022559
 >> iter 60000, loss: 0.012858
   Number of active neurons: 10
 >> iter 61000, loss: 0.009515
 >> iter 62000, loss: 0.007996
 >> iter 63000, loss: 0.145199
 >> iter 64000, loss: 0.088441
 >> iter 65000, loss: 0.043514
 >> iter 66000, loss: 0.021539
 >> iter 67000, loss: 0.013439
 >> iter 68000, loss: 0.009597
 >> iter 69000, loss: 0.063908
 >> iter 70000, loss: 0.057728
   Number of active neurons: 10
 >> iter 71000, loss: 0.132341
 >> iter 72000, loss: 0.057394
 >> iter 73000, loss: 0.027595
 >> iter 74000, loss: 0.015935
 >> iter 75000, loss: 0.086390
 >> iter 76000, loss: 0.037486
 >> iter 77000, loss: 0.019023
 >> iter 78000, loss: 0.012057
 >> iter 79000, loss: 0.088946
 >> iter 80000, loss: 0.038476
   Number of active neurons: 10
 >> iter 81000, loss: 0.019648
 >> iter 82000, loss: 0.012227
 >> iter 83000, loss: 0.177770
 >> iter 84000, loss: 0.095104
 >> iter 85000, loss: 0.043074
 >> iter 86000, loss: 0.021216
 >> iter 87000, loss: 0.013438
 >> iter 88000, loss: 0.009677
 >> iter 89000, loss: 0.008211
 >> iter 90000, loss: 0.007488
   Number of active neurons: 8
 >> iter 91000, loss: 0.241552
 >> iter 92000, loss: 0.097703
 >> iter 93000, loss: 0.042444
 >> iter 94000, loss: 0.021214
 >> iter 95000, loss: 0.013012
 >> iter 96000, loss: 0.009663
 >> iter 97000, loss: 0.008299
 >> iter 98000, loss: 0.007633
 >> iter 99000, loss: 0.007311
 >> iter 100000, loss: 0.007103
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 7.54616358909
   - Test - B: 12.4591693887
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.962848
 >> iter 2000, loss: 7.963336
 >> iter 3000, loss: 3.200613
 >> iter 4000, loss: 1.275004
 >> iter 5000, loss: 0.525912
 >> iter 6000, loss: 0.220988
 >> iter 7000, loss: 0.158707
 >> iter 8000, loss: 0.076107
 >> iter 9000, loss: 0.103248
 >> iter 10000, loss: 0.049734
   Number of active neurons: 10
 >> iter 11000, loss: 0.074026
 >> iter 12000, loss: 0.061606
 >> iter 13000, loss: 0.073392
 >> iter 14000, loss: 0.036093
 >> iter 15000, loss: 0.101127
 >> iter 16000, loss: 0.048121
 >> iter 17000, loss: 0.027204
 >> iter 18000, loss: 0.017892
 >> iter 19000, loss: 0.066120
 >> iter 20000, loss: 0.061602
   Number of active neurons: 10
 >> iter 21000, loss: 0.064884
 >> iter 22000, loss: 0.032243
 >> iter 23000, loss: 0.226185
 >> iter 24000, loss: 0.140182
 >> iter 25000, loss: 0.084744
 >> iter 26000, loss: 0.041289
 >> iter 27000, loss: 0.101351
 >> iter 28000, loss: 0.046780
 >> iter 29000, loss: 0.084799
 >> iter 30000, loss: 0.039610
   Number of active neurons: 10
 >> iter 31000, loss: 0.120534
 >> iter 32000, loss: 0.053560
 >> iter 33000, loss: 0.281310
 >> iter 34000, loss: 0.134446
 >> iter 35000, loss: 0.058996
 >> iter 36000, loss: 0.029196
 >> iter 37000, loss: 0.031709
 >> iter 38000, loss: 0.102558
 >> iter 39000, loss: 0.128365
 >> iter 40000, loss: 0.055973
   Number of active neurons: 10
 >> iter 41000, loss: 0.027316
 >> iter 42000, loss: 0.046675
 >> iter 43000, loss: 0.042676
 >> iter 44000, loss: 0.042689
 >> iter 45000, loss: 0.137537
 >> iter 46000, loss: 0.059991
 >> iter 47000, loss: 0.029609
 >> iter 48000, loss: 0.016865
 >> iter 49000, loss: 0.012483
 >> iter 50000, loss: 0.010211
   Number of active neurons: 10
 >> iter 51000, loss: 0.009490
 >> iter 52000, loss: 0.009064
 >> iter 53000, loss: 0.009372
 >> iter 54000, loss: 0.008997
 >> iter 55000, loss: 0.010289
 >> iter 56000, loss: 0.010317
 >> iter 57000, loss: 0.009560
 >> iter 58000, loss: 0.009096
 >> iter 59000, loss: 0.009873
 >> iter 60000, loss: 0.009227
   Number of active neurons: 10
 >> iter 61000, loss: 0.009476
 >> iter 62000, loss: 0.009113
 >> iter 63000, loss: 0.099428
 >> iter 64000, loss: 0.043911
 >> iter 65000, loss: 0.022430
 >> iter 66000, loss: 0.014109
 >> iter 67000, loss: 0.175265
 >> iter 68000, loss: 0.073922
 >> iter 69000, loss: 0.034061
 >> iter 70000, loss: 0.018693
   Number of active neurons: 10
 >> iter 71000, loss: 0.012973
 >> iter 72000, loss: 0.010500
 >> iter 73000, loss: 0.009947
 >> iter 74000, loss: 0.009254
 >> iter 75000, loss: 0.156677
 >> iter 76000, loss: 0.065198
 >> iter 77000, loss: 0.030955
 >> iter 78000, loss: 0.017173
 >> iter 79000, loss: 0.012471
 >> iter 80000, loss: 0.010083
   Number of active neurons: 10
 >> iter 81000, loss: 0.009698
 >> iter 82000, loss: 0.009060
 >> iter 83000, loss: 0.009311
 >> iter 84000, loss: 0.008985
 >> iter 85000, loss: 0.009164
 >> iter 86000, loss: 0.009139
 >> iter 87000, loss: 0.009278
 >> iter 88000, loss: 0.009235
 >> iter 89000, loss: 0.009444
 >> iter 90000, loss: 0.009292
   Number of active neurons: 10
 >> iter 91000, loss: 0.009699
 >> iter 92000, loss: 0.009327
 >> iter 93000, loss: 0.042927
 >> iter 94000, loss: 0.021734
 >> iter 95000, loss: 0.013799
 >> iter 96000, loss: 0.010821
 >> iter 97000, loss: 0.121772
 >> iter 98000, loss: 0.051811
 >> iter 99000, loss: 0.038689
 >> iter 100000, loss: 0.020029
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 13.1857876142
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.199625
 >> iter 2000, loss: 8.011850
 >> iter 3000, loss: 3.040128
 >> iter 4000, loss: 1.193457
 >> iter 5000, loss: 0.525315
 >> iter 6000, loss: 0.203268
 >> iter 7000, loss: 0.162558
 >> iter 8000, loss: 0.078617
 >> iter 9000, loss: 0.174243
 >> iter 10000, loss: 0.075295
   Number of active neurons: 10
 >> iter 11000, loss: 0.088012
 >> iter 12000, loss: 0.040307
 >> iter 13000, loss: 0.021252
 >> iter 14000, loss: 0.013680
 >> iter 15000, loss: 0.025974
 >> iter 16000, loss: 0.015094
 >> iter 17000, loss: 0.049775
 >> iter 18000, loss: 0.024756
 >> iter 19000, loss: 0.068958
 >> iter 20000, loss: 0.032686
   Number of active neurons: 10
 >> iter 21000, loss: 0.018604
 >> iter 22000, loss: 0.012737
 >> iter 23000, loss: 0.029533
 >> iter 24000, loss: 0.029477
 >> iter 25000, loss: 0.016841
 >> iter 26000, loss: 0.011589
 >> iter 27000, loss: 0.043430
 >> iter 28000, loss: 0.022957
 >> iter 29000, loss: 0.138493
 >> iter 30000, loss: 0.083468
   Number of active neurons: 10
 >> iter 31000, loss: 0.037161
 >> iter 32000, loss: 0.019530
 >> iter 33000, loss: 0.013047
 >> iter 34000, loss: 0.010543
 >> iter 35000, loss: 0.051823
 >> iter 36000, loss: 0.024662
 >> iter 37000, loss: 0.593547
 >> iter 38000, loss: 0.270093
 >> iter 39000, loss: 0.326639
 >> iter 40000, loss: 0.142869
   Number of active neurons: 10
 >> iter 41000, loss: 0.116567
 >> iter 42000, loss: 0.050852
 >> iter 43000, loss: 0.025052
 >> iter 44000, loss: 0.015648
 >> iter 45000, loss: 0.032639
 >> iter 46000, loss: 0.017424
 >> iter 47000, loss: 0.026047
 >> iter 48000, loss: 0.014412
 >> iter 49000, loss: 0.010019
 >> iter 50000, loss: 0.072818
   Number of active neurons: 10
 >> iter 51000, loss: 0.033000
 >> iter 52000, loss: 0.059882
 >> iter 53000, loss: 0.028217
 >> iter 54000, loss: 0.053225
 >> iter 55000, loss: 0.142717
 >> iter 56000, loss: 0.060941
 >> iter 57000, loss: 0.158893
 >> iter 58000, loss: 0.067263
 >> iter 59000, loss: 0.031777
 >> iter 60000, loss: 0.089197
   Number of active neurons: 10
 >> iter 61000, loss: 0.166094
 >> iter 62000, loss: 0.078116
 >> iter 63000, loss: 0.035941
 >> iter 64000, loss: 0.035013
 >> iter 65000, loss: 0.018873
 >> iter 66000, loss: 0.090836
 >> iter 67000, loss: 0.041536
 >> iter 68000, loss: 0.126242
 >> iter 69000, loss: 0.120147
 >> iter 70000, loss: 0.079891
   Number of active neurons: 10
 >> iter 71000, loss: 0.036995
 >> iter 72000, loss: 0.048550
 >> iter 73000, loss: 0.029373
 >> iter 74000, loss: 0.016335
 >> iter 75000, loss: 0.011320
 >> iter 76000, loss: 0.160258
 >> iter 77000, loss: 0.068666
 >> iter 78000, loss: 0.031173
 >> iter 79000, loss: 0.035419
 >> iter 80000, loss: 0.018696
   Number of active neurons: 10
 >> iter 81000, loss: 0.012016
 >> iter 82000, loss: 0.017301
 >> iter 83000, loss: 0.177050
 >> iter 84000, loss: 0.072692
 >> iter 85000, loss: 0.112508
 >> iter 86000, loss: 0.048490
 >> iter 87000, loss: 0.024628
 >> iter 88000, loss: 0.080229
 >> iter 89000, loss: 0.194472
 >> iter 90000, loss: 0.081770
   Number of active neurons: 10
 >> iter 91000, loss: 0.054046
 >> iter 92000, loss: 0.026207
 >> iter 93000, loss: 0.063166
 >> iter 94000, loss: 0.235458
 >> iter 95000, loss: 0.096933
 >> iter 96000, loss: 0.042694
 >> iter 97000, loss: 0.067536
 >> iter 98000, loss: 0.031509
 >> iter 99000, loss: 0.017258
 >> iter 100000, loss: 0.019690
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.00799984000319
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 24.8183454436
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.250836
 >> iter 2000, loss: 7.416120
 >> iter 3000, loss: 2.873070
 >> iter 4000, loss: 1.073404
 >> iter 5000, loss: 0.405699
 >> iter 6000, loss: 0.157636
 >> iter 7000, loss: 0.157659
 >> iter 8000, loss: 0.066437
 >> iter 9000, loss: 0.031218
 >> iter 10000, loss: 0.017504
   Number of active neurons: 9
 >> iter 11000, loss: 0.012260
 >> iter 12000, loss: 0.010025
 >> iter 13000, loss: 0.259511
 >> iter 14000, loss: 0.106175
 >> iter 15000, loss: 0.099794
 >> iter 16000, loss: 0.045372
 >> iter 17000, loss: 0.120994
 >> iter 18000, loss: 0.052455
 >> iter 19000, loss: 0.026144
 >> iter 20000, loss: 0.015778
   Number of active neurons: 9
 >> iter 21000, loss: 0.217974
 >> iter 22000, loss: 0.089422
 >> iter 23000, loss: 0.136444
 >> iter 24000, loss: 0.058637
 >> iter 25000, loss: 0.039565
 >> iter 26000, loss: 0.021199
 >> iter 27000, loss: 0.013842
 >> iter 28000, loss: 0.010660
 >> iter 29000, loss: 0.009473
 >> iter 30000, loss: 0.056619
   Number of active neurons: 9
 >> iter 31000, loss: 0.027076
 >> iter 32000, loss: 0.015589
 >> iter 33000, loss: 0.093380
 >> iter 34000, loss: 0.041836
 >> iter 35000, loss: 0.049465
 >> iter 36000, loss: 0.024397
 >> iter 37000, loss: 0.014597
 >> iter 38000, loss: 0.010549
 >> iter 39000, loss: 0.372593
 >> iter 40000, loss: 0.145578
   Number of active neurons: 9
 >> iter 41000, loss: 0.060350
 >> iter 42000, loss: 0.028210
 >> iter 43000, loss: 0.114214
 >> iter 44000, loss: 0.049244
 >> iter 45000, loss: 0.024193
 >> iter 46000, loss: 0.014374
 >> iter 47000, loss: 0.010616
 >> iter 48000, loss: 0.009047
 >> iter 49000, loss: 0.088493
 >> iter 50000, loss: 0.040307
   Number of active neurons: 9
 >> iter 51000, loss: 0.097263
 >> iter 52000, loss: 0.042096
 >> iter 53000, loss: 0.088188
 >> iter 54000, loss: 0.038995
 >> iter 55000, loss: 0.184021
 >> iter 56000, loss: 0.077420
 >> iter 57000, loss: 0.035198
 >> iter 58000, loss: 0.018792
 >> iter 59000, loss: 0.012370
 >> iter 60000, loss: 0.009752
   Number of active neurons: 9
 >> iter 61000, loss: 0.008633
 >> iter 62000, loss: 0.024565
 >> iter 63000, loss: 0.014219
 >> iter 64000, loss: 0.010176
 >> iter 65000, loss: 0.051480
 >> iter 66000, loss: 0.024223
 >> iter 67000, loss: 0.013964
 >> iter 68000, loss: 0.030024
 >> iter 69000, loss: 0.016228
 >> iter 70000, loss: 0.010974
   Number of active neurons: 9
 >> iter 71000, loss: 0.122268
 >> iter 72000, loss: 0.051540
 >> iter 73000, loss: 0.051896
 >> iter 74000, loss: 0.024551
 >> iter 75000, loss: 0.014127
 >> iter 76000, loss: 0.072876
 >> iter 77000, loss: 0.032859
 >> iter 78000, loss: 0.017257
 >> iter 79000, loss: 0.085693
 >> iter 80000, loss: 0.037104
   Number of active neurons: 9
 >> iter 81000, loss: 0.093141
 >> iter 82000, loss: 0.040160
 >> iter 83000, loss: 0.019913
 >> iter 84000, loss: 0.054532
 >> iter 85000, loss: 0.025838
 >> iter 86000, loss: 0.014715
 >> iter 87000, loss: 0.010479
 >> iter 88000, loss: 0.008612
 >> iter 89000, loss: 0.160452
 >> iter 90000, loss: 0.066011
   Number of active neurons: 9
 >> iter 91000, loss: 0.029555
 >> iter 92000, loss: 0.144128
 >> iter 93000, loss: 0.134186
 >> iter 94000, loss: 0.056176
 >> iter 95000, loss: 0.026385
 >> iter 96000, loss: 0.030854
 >> iter 97000, loss: 0.019801
 >> iter 98000, loss: 0.012170
 >> iter 99000, loss: 0.175948
 >> iter 100000, loss: 0.072584
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 16.7255516299
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 15.709554
 >> iter 2000, loss: 6.913209
 >> iter 3000, loss: 2.939542
 >> iter 4000, loss: 1.105676
 >> iter 5000, loss: 0.443535
 >> iter 6000, loss: 0.175849
 >> iter 7000, loss: 0.079156
 >> iter 8000, loss: 0.083653
 >> iter 9000, loss: 0.058076
 >> iter 10000, loss: 0.027634
   Number of active neurons: 10
 >> iter 11000, loss: 0.016804
 >> iter 12000, loss: 0.011347
 >> iter 13000, loss: 0.009488
 >> iter 14000, loss: 0.008531
 >> iter 15000, loss: 0.008587
 >> iter 16000, loss: 0.008100
 >> iter 17000, loss: 0.158480
 >> iter 18000, loss: 0.065719
 >> iter 19000, loss: 0.030078
 >> iter 20000, loss: 0.016232
   Number of active neurons: 10
 >> iter 21000, loss: 0.014593
 >> iter 22000, loss: 0.010276
 >> iter 23000, loss: 0.009025
 >> iter 24000, loss: 0.007874
 >> iter 25000, loss: 0.007454
 >> iter 26000, loss: 0.007193
 >> iter 27000, loss: 0.007325
 >> iter 28000, loss: 0.006965
 >> iter 29000, loss: 0.006889
 >> iter 30000, loss: 0.006804
   Number of active neurons: 10
 >> iter 31000, loss: 0.006841
 >> iter 32000, loss: 0.006808
 >> iter 33000, loss: 0.006855
 >> iter 34000, loss: 0.006855
 >> iter 35000, loss: 0.006905
 >> iter 36000, loss: 0.006908
 >> iter 37000, loss: 0.006966
 >> iter 38000, loss: 0.006981
 >> iter 39000, loss: 0.007026
 >> iter 40000, loss: 0.007038
   Number of active neurons: 10
 >> iter 41000, loss: 0.007087
 >> iter 42000, loss: 0.007105
 >> iter 43000, loss: 0.007156
 >> iter 44000, loss: 0.007178
 >> iter 45000, loss: 0.007213
 >> iter 46000, loss: 0.007231
 >> iter 47000, loss: 0.007267
 >> iter 48000, loss: 0.007286
 >> iter 49000, loss: 0.007321
 >> iter 50000, loss: 0.007332
   Number of active neurons: 10
 >> iter 51000, loss: 0.007358
 >> iter 52000, loss: 0.007360
 >> iter 53000, loss: 0.007382
 >> iter 54000, loss: 0.007382
 >> iter 55000, loss: 0.007406
 >> iter 56000, loss: 0.007408
 >> iter 57000, loss: 0.007427
 >> iter 58000, loss: 0.007425
 >> iter 59000, loss: 0.007434
 >> iter 60000, loss: 0.007414
   Number of active neurons: 10
 >> iter 61000, loss: 0.007431
 >> iter 62000, loss: 0.007396
 >> iter 63000, loss: 0.007406
 >> iter 64000, loss: 0.007353
 >> iter 65000, loss: 0.007364
 >> iter 66000, loss: 0.007298
 >> iter 67000, loss: 0.007297
 >> iter 68000, loss: 0.007233
 >> iter 69000, loss: 0.007228
 >> iter 70000, loss: 0.007182
   Number of active neurons: 9
 >> iter 71000, loss: 0.007156
 >> iter 72000, loss: 0.007182
 >> iter 73000, loss: 0.007092
 >> iter 74000, loss: 0.327469
 >> iter 75000, loss: 0.154590
 >> iter 76000, loss: 0.063570
 >> iter 77000, loss: 0.029260
 >> iter 78000, loss: 0.016104
 >> iter 79000, loss: 0.011044
 >> iter 80000, loss: 0.008943
   Number of active neurons: 9
 >> iter 81000, loss: 0.008112
 >> iter 82000, loss: 0.007653
 >> iter 83000, loss: 0.007467
 >> iter 84000, loss: 0.007259
 >> iter 85000, loss: 0.007172
 >> iter 86000, loss: 0.007054
 >> iter 87000, loss: 0.006956
 >> iter 88000, loss: 0.049358
 >> iter 89000, loss: 0.022874
 >> iter 90000, loss: 0.012868
   Number of active neurons: 9
 >> iter 91000, loss: 0.009107
 >> iter 92000, loss: 0.007674
 >> iter 93000, loss: 0.007157
 >> iter 94000, loss: 0.255120
 >> iter 95000, loss: 0.102112
 >> iter 96000, loss: 0.043429
 >> iter 97000, loss: 0.021180
 >> iter 98000, loss: 0.012529
 >> iter 99000, loss: 0.009174
 >> iter 100000, loss: 0.007786
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 17.4721685221
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.102335
 >> iter 2000, loss: 7.146586
 >> iter 3000, loss: 2.673935
 >> iter 4000, loss: 0.994859
 >> iter 5000, loss: 0.374254
 >> iter 6000, loss: 0.183979
 >> iter 7000, loss: 0.074488
 >> iter 8000, loss: 0.033145
 >> iter 9000, loss: 0.017711
 >> iter 10000, loss: 0.011671
   Number of active neurons: 10
 >> iter 11000, loss: 0.009351
 >> iter 12000, loss: 0.107866
 >> iter 13000, loss: 0.045901
 >> iter 14000, loss: 0.022368
 >> iter 15000, loss: 0.013484
 >> iter 16000, loss: 0.009924
 >> iter 17000, loss: 0.060324
 >> iter 18000, loss: 0.027773
 >> iter 19000, loss: 0.015473
 >> iter 20000, loss: 0.010618
   Number of active neurons: 9
 >> iter 21000, loss: 0.113021
 >> iter 22000, loss: 0.047429
 >> iter 23000, loss: 0.022730
 >> iter 24000, loss: 0.013262
 >> iter 25000, loss: 0.286936
 >> iter 26000, loss: 0.133137
 >> iter 27000, loss: 0.055799
 >> iter 28000, loss: 0.026185
 >> iter 29000, loss: 0.014964
 >> iter 30000, loss: 0.010428
   Number of active neurons: 9
 >> iter 31000, loss: 0.008719
 >> iter 32000, loss: 0.007815
 >> iter 33000, loss: 0.284590
 >> iter 34000, loss: 0.113367
 >> iter 35000, loss: 0.170778
 >> iter 36000, loss: 0.071614
 >> iter 37000, loss: 0.033128
 >> iter 38000, loss: 0.018024
 >> iter 39000, loss: 0.012002
 >> iter 40000, loss: 0.009373
   Number of active neurons: 9
 >> iter 41000, loss: 0.008218
 >> iter 42000, loss: 0.007571
 >> iter 43000, loss: 0.347789
 >> iter 44000, loss: 0.139903
 >> iter 45000, loss: 0.059086
 >> iter 46000, loss: 0.027886
 >> iter 47000, loss: 0.015803
 >> iter 48000, loss: 0.010884
 >> iter 49000, loss: 0.166658
 >> iter 50000, loss: 0.067736
   Number of active neurons: 9
 >> iter 51000, loss: 0.030541
 >> iter 52000, loss: 0.016351
 >> iter 53000, loss: 0.010887
 >> iter 54000, loss: 0.008626
 >> iter 55000, loss: 0.007613
 >> iter 56000, loss: 0.030840
 >> iter 57000, loss: 0.263731
 >> iter 58000, loss: 0.105389
 >> iter 59000, loss: 0.045127
 >> iter 60000, loss: 0.022053
   Number of active neurons: 9
 >> iter 61000, loss: 0.013200
 >> iter 62000, loss: 0.009599
 >> iter 63000, loss: 0.008118
 >> iter 64000, loss: 0.169658
 >> iter 65000, loss: 0.069604
 >> iter 66000, loss: 0.031424
 >> iter 67000, loss: 0.016815
 >> iter 68000, loss: 0.011035
 >> iter 69000, loss: 0.096784
 >> iter 70000, loss: 0.041073
   Number of active neurons: 8
 >> iter 71000, loss: 0.020059
 >> iter 72000, loss: 0.011956
 >> iter 73000, loss: 0.008837
 >> iter 74000, loss: 0.208888
 >> iter 75000, loss: 0.151575
 >> iter 76000, loss: 0.111820
 >> iter 77000, loss: 0.047518
 >> iter 78000, loss: 0.022893
 >> iter 79000, loss: 0.013390
 >> iter 80000, loss: 0.080712
   Number of active neurons: 8
 >> iter 81000, loss: 0.180567
 >> iter 82000, loss: 0.074710
 >> iter 83000, loss: 0.109480
 >> iter 84000, loss: 0.047275
 >> iter 85000, loss: 0.023185
 >> iter 86000, loss: 0.013567
 >> iter 87000, loss: 0.009757
 >> iter 88000, loss: 0.008058
 >> iter 89000, loss: 0.007329
 >> iter 90000, loss: 0.006916
   Number of active neurons: 8
 >> iter 91000, loss: 0.006649
 >> iter 92000, loss: 0.296856
 >> iter 93000, loss: 0.117937
 >> iter 94000, loss: 0.184952
 >> iter 95000, loss: 0.076965
 >> iter 96000, loss: 0.034720
 >> iter 97000, loss: 0.018257
 >> iter 98000, loss: 0.011545
 >> iter 99000, loss: 0.008757
 >> iter 100000, loss: 0.130080
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0039999200016
   - Test - Long: 0.0049997500125
   - Test - Big: 0.0159998400016
   - Test - A: 0.0
   - Test - B: 18.1921205253
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.737110
 >> iter 2000, loss: 6.191182
 >> iter 3000, loss: 2.405549
 >> iter 4000, loss: 0.900538
 >> iter 5000, loss: 0.374438
 >> iter 6000, loss: 0.198374
 >> iter 7000, loss: 0.097391
 >> iter 8000, loss: 0.043740
 >> iter 9000, loss: 0.035685
 >> iter 10000, loss: 0.019581
   Number of active neurons: 10
 >> iter 11000, loss: 0.164684
 >> iter 12000, loss: 0.071847
 >> iter 13000, loss: 0.086736
 >> iter 14000, loss: 0.039527
 >> iter 15000, loss: 0.039705
 >> iter 16000, loss: 0.020692
 >> iter 17000, loss: 0.193446
 >> iter 18000, loss: 0.081143
 >> iter 19000, loss: 0.050160
 >> iter 20000, loss: 0.024843
   Number of active neurons: 9
 >> iter 21000, loss: 0.258573
 >> iter 22000, loss: 0.105228
 >> iter 23000, loss: 0.092175
 >> iter 24000, loss: 0.041400
 >> iter 25000, loss: 0.069791
 >> iter 26000, loss: 0.037757
 >> iter 27000, loss: 0.051951
 >> iter 28000, loss: 0.025417
 >> iter 29000, loss: 0.104375
 >> iter 30000, loss: 0.058217
   Number of active neurons: 9
 >> iter 31000, loss: 0.027731
 >> iter 32000, loss: 0.015644
 >> iter 33000, loss: 0.174760
 >> iter 34000, loss: 0.071496
 >> iter 35000, loss: 0.048216
 >> iter 36000, loss: 0.023410
 >> iter 37000, loss: 0.014282
 >> iter 38000, loss: 0.010209
 >> iter 39000, loss: 0.008787
 >> iter 40000, loss: 0.007800
   Number of active neurons: 9
 >> iter 41000, loss: 0.007643
 >> iter 42000, loss: 0.007211
 >> iter 43000, loss: 0.118801
 >> iter 44000, loss: 0.049481
 >> iter 45000, loss: 0.023188
 >> iter 46000, loss: 0.015431
 >> iter 47000, loss: 0.060227
 >> iter 48000, loss: 0.027645
 >> iter 49000, loss: 0.091208
 >> iter 50000, loss: 0.039345
   Number of active neurons: 8
 >> iter 51000, loss: 0.065566
 >> iter 52000, loss: 0.030029
 >> iter 53000, loss: 0.092833
 >> iter 54000, loss: 0.040357
 >> iter 55000, loss: 0.020140
 >> iter 56000, loss: 0.054697
 >> iter 57000, loss: 0.025347
 >> iter 58000, loss: 0.014123
 >> iter 59000, loss: 0.049032
 >> iter 60000, loss: 0.023569
   Number of active neurons: 8
 >> iter 61000, loss: 0.015591
 >> iter 62000, loss: 0.010263
 >> iter 63000, loss: 0.008138
 >> iter 64000, loss: 0.007240
 >> iter 65000, loss: 0.053464
 >> iter 66000, loss: 0.027775
 >> iter 67000, loss: 0.014793
 >> iter 68000, loss: 0.009722
 >> iter 69000, loss: 0.030924
 >> iter 70000, loss: 0.016343
   Number of active neurons: 8
 >> iter 71000, loss: 0.010427
 >> iter 72000, loss: 0.044221
 >> iter 73000, loss: 0.044527
 >> iter 74000, loss: 0.020983
 >> iter 75000, loss: 0.066768
 >> iter 76000, loss: 0.029792
 >> iter 77000, loss: 0.073584
 >> iter 78000, loss: 0.032832
 >> iter 79000, loss: 0.198053
 >> iter 80000, loss: 0.103857
   Number of active neurons: 8
 >> iter 81000, loss: 0.043882
 >> iter 82000, loss: 0.020985
 >> iter 83000, loss: 0.056137
 >> iter 84000, loss: 0.026096
 >> iter 85000, loss: 0.014553
 >> iter 86000, loss: 0.226482
 >> iter 87000, loss: 0.092647
 >> iter 88000, loss: 0.039958
 >> iter 89000, loss: 0.065198
 >> iter 90000, loss: 0.029867
   Number of active neurons: 8
 >> iter 91000, loss: 0.055698
 >> iter 92000, loss: 0.026564
 >> iter 93000, loss: 0.042807
 >> iter 94000, loss: 0.021201
 >> iter 95000, loss: 0.055915
 >> iter 96000, loss: 0.026053
 >> iter 97000, loss: 0.063674
 >> iter 98000, loss: 0.028796
 >> iter 99000, loss: 0.015365
 >> iter 100000, loss: 0.010122
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0399980001
   - Test - Big: 0.00199998000021
   - Test - A: 21.3585760949
   - Test - B: 18.1521231918

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

