 > Problema: tomita1nueva
 > Args:
   - Hidden size: 20
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.996891
 >> iter 2000, loss: 4.114303
 >> iter 3000, loss: 1.553053
 >> iter 4000, loss: 0.599206
 >> iter 5000, loss: 0.242503
 >> iter 6000, loss: 0.112320
 >> iter 7000, loss: 0.066604
 >> iter 8000, loss: 0.048078
 >> iter 9000, loss: 0.038957
 >> iter 10000, loss: 0.034730
   Number of active neurons: 7
 >> iter 11000, loss: 0.034350
 >> iter 12000, loss: 0.032150
 >> iter 13000, loss: 0.034277
 >> iter 14000, loss: 0.035257
 >> iter 15000, loss: 0.030651
 >> iter 16000, loss: 0.029983
 >> iter 17000, loss: 0.033623
 >> iter 18000, loss: 0.029450
 >> iter 19000, loss: 0.029881
 >> iter 20000, loss: 0.031018
   Number of active neurons: 4
 >> iter 21000, loss: 0.038150
 >> iter 22000, loss: 0.030623
 >> iter 23000, loss: 0.027804
 >> iter 24000, loss: 0.027855
 >> iter 25000, loss: 0.026166
 >> iter 26000, loss: 0.025933
 >> iter 27000, loss: 0.028939
 >> iter 28000, loss: 0.037906
 >> iter 29000, loss: 0.032871
 >> iter 30000, loss: 0.028561
   Number of active neurons: 4
 >> iter 31000, loss: 0.025707
 >> iter 32000, loss: 0.023464
 >> iter 33000, loss: 0.027373
 >> iter 34000, loss: 0.034979
 >> iter 35000, loss: 0.027442
 >> iter 36000, loss: 0.024511
 >> iter 37000, loss: 0.024326
 >> iter 38000, loss: 0.026241
 >> iter 39000, loss: 0.025398
 >> iter 40000, loss: 0.028904
   Number of active neurons: 3
 >> iter 41000, loss: 0.027168
 >> iter 42000, loss: 0.026894
 >> iter 43000, loss: 0.024398
 >> iter 44000, loss: 0.022764
 >> iter 45000, loss: 0.023606
 >> iter 46000, loss: 0.023760
 >> iter 47000, loss: 0.032356
 >> iter 48000, loss: 0.036728
 >> iter 49000, loss: 0.036944
 >> iter 50000, loss: 0.029694
   Number of active neurons: 3
 >> iter 51000, loss: 0.024747
 >> iter 52000, loss: 0.027958
 >> iter 53000, loss: 0.031312
 >> iter 54000, loss: 0.026958
 >> iter 55000, loss: 0.025909
 >> iter 56000, loss: 0.024304
 >> iter 57000, loss: 0.022724
 >> iter 58000, loss: 0.023842
 >> iter 59000, loss: 0.024020
 >> iter 60000, loss: 0.030786
   Number of active neurons: 3
 >> iter 61000, loss: 0.028160
 >> iter 62000, loss: 0.035642
 >> iter 63000, loss: 0.027978
 >> iter 64000, loss: 0.026597
 >> iter 65000, loss: 0.031307
 >> iter 66000, loss: 0.024667
 >> iter 67000, loss: 0.025063
 >> iter 68000, loss: 0.021192
 >> iter 69000, loss: 0.024299
 >> iter 70000, loss: 0.021450
   Number of active neurons: 2
 >> iter 71000, loss: 0.022509
 >> iter 72000, loss: 0.023583
 >> iter 73000, loss: 0.026980
 >> iter 74000, loss: 0.031279
 >> iter 75000, loss: 0.025416
 >> iter 76000, loss: 0.023073
 >> iter 77000, loss: 0.032716
 >> iter 78000, loss: 0.029222
 >> iter 79000, loss: 0.030388
 >> iter 80000, loss: 0.023604
   Number of active neurons: 2
 >> iter 81000, loss: 0.022781
 >> iter 82000, loss: 0.032714
 >> iter 83000, loss: 0.053974
 >> iter 84000, loss: 0.037780
 >> iter 85000, loss: 0.030047
 >> iter 86000, loss: 0.035218
 >> iter 87000, loss: 0.037627
 >> iter 88000, loss: 0.036677
 >> iter 89000, loss: 0.028571
 >> iter 90000, loss: 0.025460
   Number of active neurons: 2
 >> iter 91000, loss: 0.021698
 >> iter 92000, loss: 0.022178
 >> iter 93000, loss: 0.052140
 >> iter 94000, loss: 0.036748
 >> iter 95000, loss: 0.039740
 >> iter 96000, loss: 0.028538
 >> iter 97000, loss: 0.025344
 >> iter 98000, loss: 0.036221
 >> iter 99000, loss: 0.030386
 >> iter 100000, loss: 0.024395
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.982232
 >> iter 2000, loss: 4.095937
 >> iter 3000, loss: 1.545689
 >> iter 4000, loss: 0.589886
 >> iter 5000, loss: 0.240584
 >> iter 6000, loss: 0.121817
 >> iter 7000, loss: 0.067361
 >> iter 8000, loss: 0.048384
 >> iter 9000, loss: 0.040144
 >> iter 10000, loss: 0.032179
   Number of active neurons: 5
 >> iter 11000, loss: 0.032135
 >> iter 12000, loss: 0.030439
 >> iter 13000, loss: 0.027422
 >> iter 14000, loss: 0.030330
 >> iter 15000, loss: 0.034417
 >> iter 16000, loss: 0.026945
 >> iter 17000, loss: 0.028816
 >> iter 18000, loss: 0.027285
 >> iter 19000, loss: 0.028490
 >> iter 20000, loss: 0.025712
   Number of active neurons: 3
 >> iter 21000, loss: 0.026471
 >> iter 22000, loss: 0.024657
 >> iter 23000, loss: 0.025576
 >> iter 24000, loss: 0.026141
 >> iter 25000, loss: 0.026580
 >> iter 26000, loss: 0.031889
 >> iter 27000, loss: 0.031503
 >> iter 28000, loss: 0.027155
 >> iter 29000, loss: 0.025042
 >> iter 30000, loss: 0.027039
   Number of active neurons: 3
 >> iter 31000, loss: 0.025165
 >> iter 32000, loss: 0.025470
 >> iter 33000, loss: 0.024305
 >> iter 34000, loss: 0.025071
 >> iter 35000, loss: 0.030444
 >> iter 36000, loss: 0.025500
 >> iter 37000, loss: 0.027816
 >> iter 38000, loss: 0.024265
 >> iter 39000, loss: 0.032653
 >> iter 40000, loss: 0.025554
   Number of active neurons: 3
 >> iter 41000, loss: 0.035167
 >> iter 42000, loss: 0.029174
 >> iter 43000, loss: 0.026577
 >> iter 44000, loss: 0.027320
 >> iter 45000, loss: 0.046631
 >> iter 46000, loss: 0.034663
 >> iter 47000, loss: 0.028168
 >> iter 48000, loss: 0.030995
 >> iter 49000, loss: 0.029540
 >> iter 50000, loss: 0.026551
   Number of active neurons: 3
 >> iter 51000, loss: 0.024108
 >> iter 52000, loss: 0.035524
 >> iter 53000, loss: 0.044145
 >> iter 54000, loss: 0.031075
 >> iter 55000, loss: 0.029768
 >> iter 56000, loss: 0.025529
 >> iter 57000, loss: 0.026421
 >> iter 58000, loss: 0.029126
 >> iter 59000, loss: 0.026658
 >> iter 60000, loss: 0.034215
   Number of active neurons: 2
 >> iter 61000, loss: 0.053188
 >> iter 62000, loss: 0.039389
 >> iter 63000, loss: 0.028670
 >> iter 64000, loss: 0.023361
 >> iter 65000, loss: 0.026154
 >> iter 66000, loss: 0.025691
 >> iter 67000, loss: 0.024378
 >> iter 68000, loss: 0.028812
 >> iter 69000, loss: 0.022794
 >> iter 70000, loss: 0.033846
   Number of active neurons: 1
 >> iter 71000, loss: 0.027454
 >> iter 72000, loss: 0.021919
 >> iter 73000, loss: 0.024493
 >> iter 74000, loss: 0.022654
 >> iter 75000, loss: 0.023078
 >> iter 76000, loss: 0.033810
 >> iter 77000, loss: 0.024451
 >> iter 78000, loss: 0.020502
 >> iter 79000, loss: 0.020095
 >> iter 80000, loss: 0.022188
   Number of active neurons: 1
 >> iter 81000, loss: 0.027172
 >> iter 82000, loss: 0.020028
 >> iter 83000, loss: 0.018623
 >> iter 84000, loss: 0.036622
 >> iter 85000, loss: 0.024210
 >> iter 86000, loss: 0.023519
 >> iter 87000, loss: 0.021401
 >> iter 88000, loss: 0.017558
 >> iter 89000, loss: 0.024278
 >> iter 90000, loss: 0.023688
   Number of active neurons: 1
 >> iter 91000, loss: 0.020944
 >> iter 92000, loss: 0.022924
 >> iter 93000, loss: 0.024462
 >> iter 94000, loss: 0.019769
 >> iter 95000, loss: 0.019740
 >> iter 96000, loss: 0.017606
 >> iter 97000, loss: 0.018451
 >> iter 98000, loss: 0.018276
 >> iter 99000, loss: 0.018556
 >> iter 100000, loss: 0.019986
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.917613
 >> iter 2000, loss: 4.058884
 >> iter 3000, loss: 1.525669
 >> iter 4000, loss: 0.589502
 >> iter 5000, loss: 0.261358
 >> iter 6000, loss: 0.118079
 >> iter 7000, loss: 0.064590
 >> iter 8000, loss: 0.042226
 >> iter 9000, loss: 0.038968
 >> iter 10000, loss: 0.032037
   Number of active neurons: 4
 >> iter 11000, loss: 0.031196
 >> iter 12000, loss: 0.039128
 >> iter 13000, loss: 0.033181
 >> iter 14000, loss: 0.028537
 >> iter 15000, loss: 0.027487
 >> iter 16000, loss: 0.025969
 >> iter 17000, loss: 0.031881
 >> iter 18000, loss: 0.027343
 >> iter 19000, loss: 0.025665
 >> iter 20000, loss: 0.025096
   Number of active neurons: 3
 >> iter 21000, loss: 0.024378
 >> iter 22000, loss: 0.024622
 >> iter 23000, loss: 0.023660
 >> iter 24000, loss: 0.037557
 >> iter 25000, loss: 0.027608
 >> iter 26000, loss: 0.027233
 >> iter 27000, loss: 0.027851
 >> iter 28000, loss: 0.024275
 >> iter 29000, loss: 0.034851
 >> iter 30000, loss: 0.028147
   Number of active neurons: 3
 >> iter 31000, loss: 0.031410
 >> iter 32000, loss: 0.033398
 >> iter 33000, loss: 0.031048
 >> iter 34000, loss: 0.025309
 >> iter 35000, loss: 0.027123
 >> iter 36000, loss: 0.023322
 >> iter 37000, loss: 0.031814
 >> iter 38000, loss: 0.025948
 >> iter 39000, loss: 0.028054
 >> iter 40000, loss: 0.025455
   Number of active neurons: 3
 >> iter 41000, loss: 0.040610
 >> iter 42000, loss: 0.032246
 >> iter 43000, loss: 0.029947
 >> iter 44000, loss: 0.026025
 >> iter 45000, loss: 0.039382
 >> iter 46000, loss: 0.031085
 >> iter 47000, loss: 0.025306
 >> iter 48000, loss: 0.025466
 >> iter 49000, loss: 0.034987
 >> iter 50000, loss: 0.027125
   Number of active neurons: 2
 >> iter 51000, loss: 0.021969
 >> iter 52000, loss: 0.020917
 >> iter 53000, loss: 0.025949
 >> iter 54000, loss: 0.032358
 >> iter 55000, loss: 0.025404
 >> iter 56000, loss: 0.022059
 >> iter 57000, loss: 0.019971
 >> iter 58000, loss: 0.021869
 >> iter 59000, loss: 0.025994
 >> iter 60000, loss: 0.022961
   Number of active neurons: 2
 >> iter 61000, loss: 0.024842
 >> iter 62000, loss: 0.022145
 >> iter 63000, loss: 0.022498
 >> iter 64000, loss: 0.019662
 >> iter 65000, loss: 0.021618
 >> iter 66000, loss: 0.035203
 >> iter 67000, loss: 0.027295
 >> iter 68000, loss: 0.021496
 >> iter 69000, loss: 0.020788
 >> iter 70000, loss: 0.022081
   Number of active neurons: 2
 >> iter 71000, loss: 0.022395
 >> iter 72000, loss: 0.023019
 >> iter 73000, loss: 0.029724
 >> iter 74000, loss: 0.022326
 >> iter 75000, loss: 0.023143
 >> iter 76000, loss: 0.024559
 >> iter 77000, loss: 0.027316
 >> iter 78000, loss: 0.023307
 >> iter 79000, loss: 0.021065
 >> iter 80000, loss: 0.020670
   Number of active neurons: 2
 >> iter 81000, loss: 0.026414
 >> iter 82000, loss: 0.026936
 >> iter 83000, loss: 0.025004
 >> iter 84000, loss: 0.022254
 >> iter 85000, loss: 0.035707
 >> iter 86000, loss: 0.027040
 >> iter 87000, loss: 0.026232
 >> iter 88000, loss: 0.024258
 >> iter 89000, loss: 0.021851
 >> iter 90000, loss: 0.022553
   Number of active neurons: 2
 >> iter 91000, loss: 0.021738
 >> iter 92000, loss: 0.038455
 >> iter 93000, loss: 0.027548
 >> iter 94000, loss: 0.024430
 >> iter 95000, loss: 0.024179
 >> iter 96000, loss: 0.021621
 >> iter 97000, loss: 0.024927
 >> iter 98000, loss: 0.021886
 >> iter 99000, loss: 0.023220
 >> iter 100000, loss: 0.026155
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.944594
 >> iter 2000, loss: 4.078446
 >> iter 3000, loss: 1.543508
 >> iter 4000, loss: 0.591401
 >> iter 5000, loss: 0.250771
 >> iter 6000, loss: 0.115971
 >> iter 7000, loss: 0.063637
 >> iter 8000, loss: 0.043563
 >> iter 9000, loss: 0.040283
 >> iter 10000, loss: 0.035095
   Number of active neurons: 6
 >> iter 11000, loss: 0.034744
 >> iter 12000, loss: 0.030590
 >> iter 13000, loss: 0.031335
 >> iter 14000, loss: 0.033070
 >> iter 15000, loss: 0.034531
 >> iter 16000, loss: 0.029490
 >> iter 17000, loss: 0.031934
 >> iter 18000, loss: 0.030050
 >> iter 19000, loss: 0.031874
 >> iter 20000, loss: 0.029484
   Number of active neurons: 4
 >> iter 21000, loss: 0.034390
 >> iter 22000, loss: 0.040945
 >> iter 23000, loss: 0.038315
 >> iter 24000, loss: 0.032532
 >> iter 25000, loss: 0.027169
 >> iter 26000, loss: 0.031022
 >> iter 27000, loss: 0.030188
 >> iter 28000, loss: 0.025999
 >> iter 29000, loss: 0.027346
 >> iter 30000, loss: 0.027217
   Number of active neurons: 3
 >> iter 31000, loss: 0.027312
 >> iter 32000, loss: 0.026376
 >> iter 33000, loss: 0.031668
 >> iter 34000, loss: 0.026199
 >> iter 35000, loss: 0.023270
 >> iter 36000, loss: 0.031436
 >> iter 37000, loss: 0.026735
 >> iter 38000, loss: 0.032879
 >> iter 39000, loss: 0.027298
 >> iter 40000, loss: 0.024653
   Number of active neurons: 2
 >> iter 41000, loss: 0.029231
 >> iter 42000, loss: 0.035545
 >> iter 43000, loss: 0.033445
 >> iter 44000, loss: 0.024915
 >> iter 45000, loss: 0.024263
 >> iter 46000, loss: 0.023114
 >> iter 47000, loss: 0.027667
 >> iter 48000, loss: 0.026580
 >> iter 49000, loss: 0.024481
 >> iter 50000, loss: 0.021977
   Number of active neurons: 2
 >> iter 51000, loss: 0.024817
 >> iter 52000, loss: 0.025921
 >> iter 53000, loss: 0.024531
 >> iter 54000, loss: 0.024484
 >> iter 55000, loss: 0.024474
 >> iter 56000, loss: 0.022180
 >> iter 57000, loss: 0.025096
 >> iter 58000, loss: 0.020936
 >> iter 59000, loss: 0.021104
 >> iter 60000, loss: 0.032367
   Number of active neurons: 1
 >> iter 61000, loss: 0.025877
 >> iter 62000, loss: 0.031782
 >> iter 63000, loss: 0.029375
 >> iter 64000, loss: 0.022766
 >> iter 65000, loss: 0.022228
 >> iter 66000, loss: 0.018179
 >> iter 67000, loss: 0.028780
 >> iter 68000, loss: 0.021292
 >> iter 69000, loss: 0.020765
 >> iter 70000, loss: 0.018095
   Number of active neurons: 1
 >> iter 71000, loss: 0.017544
 >> iter 72000, loss: 0.016291
 >> iter 73000, loss: 0.021847
 >> iter 74000, loss: 0.024434
 >> iter 75000, loss: 0.030937
 >> iter 76000, loss: 0.023823
 >> iter 77000, loss: 0.024208
 >> iter 78000, loss: 0.018119
 >> iter 79000, loss: 0.016923
 >> iter 80000, loss: 0.016776
   Number of active neurons: 1
 >> iter 81000, loss: 0.019133
 >> iter 82000, loss: 0.024276
 >> iter 83000, loss: 0.020344
 >> iter 84000, loss: 0.028364
 >> iter 85000, loss: 0.024855
 >> iter 86000, loss: 0.019951
 >> iter 87000, loss: 0.017041
 >> iter 88000, loss: 0.031353
 >> iter 89000, loss: 0.029688
 >> iter 90000, loss: 0.021769
   Number of active neurons: 1
 >> iter 91000, loss: 0.058579
 >> iter 92000, loss: 0.041435
 >> iter 93000, loss: 0.026020
 >> iter 94000, loss: 0.020674
 >> iter 95000, loss: 0.039547
 >> iter 96000, loss: 0.027191
 >> iter 97000, loss: 0.020981
 >> iter 98000, loss: 0.026931
 >> iter 99000, loss: 0.019761
 >> iter 100000, loss: 0.017478
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.947925
 >> iter 2000, loss: 4.071073
 >> iter 3000, loss: 1.533415
 >> iter 4000, loss: 0.584108
 >> iter 5000, loss: 0.240872
 >> iter 6000, loss: 0.107703
 >> iter 7000, loss: 0.061029
 >> iter 8000, loss: 0.042897
 >> iter 9000, loss: 0.034834
 >> iter 10000, loss: 0.031744
   Number of active neurons: 5
 >> iter 11000, loss: 0.036971
 >> iter 12000, loss: 0.034329
 >> iter 13000, loss: 0.029263
 >> iter 14000, loss: 0.029866
 >> iter 15000, loss: 0.031130
 >> iter 16000, loss: 0.029003
 >> iter 17000, loss: 0.036185
 >> iter 18000, loss: 0.030301
 >> iter 19000, loss: 0.028552
 >> iter 20000, loss: 0.037582
   Number of active neurons: 4
 >> iter 21000, loss: 0.028816
 >> iter 22000, loss: 0.029199
 >> iter 23000, loss: 0.025468
 >> iter 24000, loss: 0.029901
 >> iter 25000, loss: 0.025790
 >> iter 26000, loss: 0.026158
 >> iter 27000, loss: 0.027176
 >> iter 28000, loss: 0.026816
 >> iter 29000, loss: 0.031988
 >> iter 30000, loss: 0.024612
   Number of active neurons: 3
 >> iter 31000, loss: 0.038165
 >> iter 32000, loss: 0.029386
 >> iter 33000, loss: 0.056557
 >> iter 34000, loss: 0.038380
 >> iter 35000, loss: 0.031671
 >> iter 36000, loss: 0.034801
 >> iter 37000, loss: 0.027198
 >> iter 38000, loss: 0.029760
 >> iter 39000, loss: 0.023954
 >> iter 40000, loss: 0.023331
   Number of active neurons: 2
 >> iter 41000, loss: 0.048236
 >> iter 42000, loss: 0.030820
 >> iter 43000, loss: 0.030551
 >> iter 44000, loss: 0.024590
 >> iter 45000, loss: 0.021906
 >> iter 46000, loss: 0.022744
 >> iter 47000, loss: 0.023234
 >> iter 48000, loss: 0.035861
 >> iter 49000, loss: 0.025833
 >> iter 50000, loss: 0.022234
   Number of active neurons: 2
 >> iter 51000, loss: 0.019918
 >> iter 52000, loss: 0.021362
 >> iter 53000, loss: 0.020440
 >> iter 54000, loss: 0.035687
 >> iter 55000, loss: 0.030137
 >> iter 56000, loss: 0.038673
 >> iter 57000, loss: 0.029142
 >> iter 58000, loss: 0.024010
 >> iter 59000, loss: 0.024570
 >> iter 60000, loss: 0.022278
   Number of active neurons: 2
 >> iter 61000, loss: 0.030163
 >> iter 62000, loss: 0.028838
 >> iter 63000, loss: 0.024956
 >> iter 64000, loss: 0.024343
 >> iter 65000, loss: 0.022568
 >> iter 66000, loss: 0.025478
 >> iter 67000, loss: 0.027119
 >> iter 68000, loss: 0.023651
 >> iter 69000, loss: 0.032883
 >> iter 70000, loss: 0.028854
   Number of active neurons: 2
 >> iter 71000, loss: 0.026088
 >> iter 72000, loss: 0.027368
 >> iter 73000, loss: 0.037176
 >> iter 74000, loss: 0.028296
 >> iter 75000, loss: 0.024426
 >> iter 76000, loss: 0.024918
 >> iter 77000, loss: 0.021239
 >> iter 78000, loss: 0.021935
 >> iter 79000, loss: 0.021623
 >> iter 80000, loss: 0.023349
   Number of active neurons: 2
 >> iter 81000, loss: 0.022306
 >> iter 82000, loss: 0.019696
 >> iter 83000, loss: 0.024902
 >> iter 84000, loss: 0.037176
 >> iter 85000, loss: 0.029965
 >> iter 86000, loss: 0.028536
 >> iter 87000, loss: 0.031876
 >> iter 88000, loss: 0.024405
 >> iter 89000, loss: 0.022297
 >> iter 90000, loss: 0.050793
   Number of active neurons: 2
 >> iter 91000, loss: 0.035776
 >> iter 92000, loss: 0.026158
 >> iter 93000, loss: 0.024231
 >> iter 94000, loss: 0.022087
 >> iter 95000, loss: 0.028880
 >> iter 96000, loss: 0.030230
 >> iter 97000, loss: 0.026066
 >> iter 98000, loss: 0.028584
 >> iter 99000, loss: 0.036259
 >> iter 100000, loss: 0.027289
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.954705
 >> iter 2000, loss: 4.084026
 >> iter 3000, loss: 1.530887
 >> iter 4000, loss: 0.591076
 >> iter 5000, loss: 0.251044
 >> iter 6000, loss: 0.116092
 >> iter 7000, loss: 0.076489
 >> iter 8000, loss: 0.050010
 >> iter 9000, loss: 0.046620
 >> iter 10000, loss: 0.036387
   Number of active neurons: 5
 >> iter 11000, loss: 0.033765
 >> iter 12000, loss: 0.039854
 >> iter 13000, loss: 0.031119
 >> iter 14000, loss: 0.032536
 >> iter 15000, loss: 0.039131
 >> iter 16000, loss: 0.035027
 >> iter 17000, loss: 0.036822
 >> iter 18000, loss: 0.039793
 >> iter 19000, loss: 0.032754
 >> iter 20000, loss: 0.029034
   Number of active neurons: 3
 >> iter 21000, loss: 0.044090
 >> iter 22000, loss: 0.034044
 >> iter 23000, loss: 0.027512
 >> iter 24000, loss: 0.025203
 >> iter 25000, loss: 0.024831
 >> iter 26000, loss: 0.024948
 >> iter 27000, loss: 0.024788
 >> iter 28000, loss: 0.026050
 >> iter 29000, loss: 0.032051
 >> iter 30000, loss: 0.029591
   Number of active neurons: 3
 >> iter 31000, loss: 0.024412
 >> iter 32000, loss: 0.022611
 >> iter 33000, loss: 0.036769
 >> iter 34000, loss: 0.027958
 >> iter 35000, loss: 0.028292
 >> iter 36000, loss: 0.025937
 >> iter 37000, loss: 0.023952
 >> iter 38000, loss: 0.022069
 >> iter 39000, loss: 0.025117
 >> iter 40000, loss: 0.030973
   Number of active neurons: 2
 >> iter 41000, loss: 0.039195
 >> iter 42000, loss: 0.028260
 >> iter 43000, loss: 0.040007
 >> iter 44000, loss: 0.031117
 >> iter 45000, loss: 0.023707
 >> iter 46000, loss: 0.023393
 >> iter 47000, loss: 0.024868
 >> iter 48000, loss: 0.024295
 >> iter 49000, loss: 0.022234
 >> iter 50000, loss: 0.023224
   Number of active neurons: 2
 >> iter 51000, loss: 0.028040
 >> iter 52000, loss: 0.026727
 >> iter 53000, loss: 0.023577
 >> iter 54000, loss: 0.028715
 >> iter 55000, loss: 0.022979
 >> iter 56000, loss: 0.031276
 >> iter 57000, loss: 0.023346
 >> iter 58000, loss: 0.023398
 >> iter 59000, loss: 0.039773
 >> iter 60000, loss: 0.026522
   Number of active neurons: 2
 >> iter 61000, loss: 0.027511
 >> iter 62000, loss: 0.022692
 >> iter 63000, loss: 0.022459
 >> iter 64000, loss: 0.022012
 >> iter 65000, loss: 0.019558
 >> iter 66000, loss: 0.020152
 >> iter 67000, loss: 0.035555
 >> iter 68000, loss: 0.029264
 >> iter 69000, loss: 0.032669
 >> iter 70000, loss: 0.026252
   Number of active neurons: 1
 >> iter 71000, loss: 0.021143
 >> iter 72000, loss: 0.030955
 >> iter 73000, loss: 0.023850
 >> iter 74000, loss: 0.022546
 >> iter 75000, loss: 0.018545
 >> iter 76000, loss: 0.018783
 >> iter 77000, loss: 0.040268
 >> iter 78000, loss: 0.026007
 >> iter 79000, loss: 0.023566
 >> iter 80000, loss: 0.023188
   Number of active neurons: 1
 >> iter 81000, loss: 0.021406
 >> iter 82000, loss: 0.023616
 >> iter 83000, loss: 0.023232
 >> iter 84000, loss: 0.020418
 >> iter 85000, loss: 0.023186
 >> iter 86000, loss: 0.033164
 >> iter 87000, loss: 0.023039
 >> iter 88000, loss: 0.023379
 >> iter 89000, loss: 0.020128
 >> iter 90000, loss: 0.020887
   Number of active neurons: 1
 >> iter 91000, loss: 0.023057
 >> iter 92000, loss: 0.018749
 >> iter 93000, loss: 0.016617
 >> iter 94000, loss: 0.019314
 >> iter 95000, loss: 0.018448
 >> iter 96000, loss: 0.018119
 >> iter 97000, loss: 0.019549
 >> iter 98000, loss: 0.016838
 >> iter 99000, loss: 0.016817
 >> iter 100000, loss: 0.021258
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.947218
 >> iter 2000, loss: 4.116763
 >> iter 3000, loss: 1.553740
 >> iter 4000, loss: 0.603071
 >> iter 5000, loss: 0.244591
 >> iter 6000, loss: 0.112573
 >> iter 7000, loss: 0.063964
 >> iter 8000, loss: 0.053504
 >> iter 9000, loss: 0.044990
 >> iter 10000, loss: 0.036064
   Number of active neurons: 6
 >> iter 11000, loss: 0.035382
 >> iter 12000, loss: 0.030134
 >> iter 13000, loss: 0.028986
 >> iter 14000, loss: 0.030440
 >> iter 15000, loss: 0.033738
 >> iter 16000, loss: 0.039938
 >> iter 17000, loss: 0.034149
 >> iter 18000, loss: 0.030120
 >> iter 19000, loss: 0.030753
 >> iter 20000, loss: 0.037291
   Number of active neurons: 5
 >> iter 21000, loss: 0.031888
 >> iter 22000, loss: 0.029586
 >> iter 23000, loss: 0.033262
 >> iter 24000, loss: 0.035226
 >> iter 25000, loss: 0.031385
 >> iter 26000, loss: 0.033686
 >> iter 27000, loss: 0.033097
 >> iter 28000, loss: 0.032119
 >> iter 29000, loss: 0.036672
 >> iter 30000, loss: 0.032893
   Number of active neurons: 5
 >> iter 31000, loss: 0.029180
 >> iter 32000, loss: 0.045231
 >> iter 33000, loss: 0.033344
 >> iter 34000, loss: 0.029679
 >> iter 35000, loss: 0.032161
 >> iter 36000, loss: 0.033391
 >> iter 37000, loss: 0.027386
 >> iter 38000, loss: 0.024928
 >> iter 39000, loss: 0.026037
 >> iter 40000, loss: 0.024546
   Number of active neurons: 2
 >> iter 41000, loss: 0.026237
 >> iter 42000, loss: 0.023682
 >> iter 43000, loss: 0.025996
 >> iter 44000, loss: 0.022575
 >> iter 45000, loss: 0.020192
 >> iter 46000, loss: 0.027253
 >> iter 47000, loss: 0.025746
 >> iter 48000, loss: 0.027804
 >> iter 49000, loss: 0.024533
 >> iter 50000, loss: 0.021502
   Number of active neurons: 2
 >> iter 51000, loss: 0.022343
 >> iter 52000, loss: 0.030067
 >> iter 53000, loss: 0.025283
 >> iter 54000, loss: 0.024424
 >> iter 55000, loss: 0.026249
 >> iter 56000, loss: 0.023618
 >> iter 57000, loss: 0.024301
 >> iter 58000, loss: 0.027782
 >> iter 59000, loss: 0.030260
 >> iter 60000, loss: 0.029125
   Number of active neurons: 2
 >> iter 61000, loss: 0.024863
 >> iter 62000, loss: 0.022144
 >> iter 63000, loss: 0.020399
 >> iter 64000, loss: 0.027396
 >> iter 65000, loss: 0.024205
 >> iter 66000, loss: 0.026372
 >> iter 67000, loss: 0.023012
 >> iter 68000, loss: 0.021742
 >> iter 69000, loss: 0.019093
 >> iter 70000, loss: 0.020705
   Number of active neurons: 2
 >> iter 71000, loss: 0.021128
 >> iter 72000, loss: 0.024077
 >> iter 73000, loss: 0.030090
 >> iter 74000, loss: 0.023183
 >> iter 75000, loss: 0.021887
 >> iter 76000, loss: 0.026565
 >> iter 77000, loss: 0.029596
 >> iter 78000, loss: 0.029820
 >> iter 79000, loss: 0.024691
 >> iter 80000, loss: 0.035960
   Number of active neurons: 2
 >> iter 81000, loss: 0.032024
 >> iter 82000, loss: 0.027205
 >> iter 83000, loss: 0.031061
 >> iter 84000, loss: 0.024766
 >> iter 85000, loss: 0.025915
 >> iter 86000, loss: 0.023585
 >> iter 87000, loss: 0.026206
 >> iter 88000, loss: 0.022064
 >> iter 89000, loss: 0.023407
 >> iter 90000, loss: 0.026969
   Number of active neurons: 2
 >> iter 91000, loss: 0.043005
 >> iter 92000, loss: 0.029832
 >> iter 93000, loss: 0.034486
 >> iter 94000, loss: 0.028348
 >> iter 95000, loss: 0.022938
 >> iter 96000, loss: 0.021556
 >> iter 97000, loss: 0.038689
 >> iter 98000, loss: 0.027683
 >> iter 99000, loss: 0.022779
 >> iter 100000, loss: 0.023835
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.010511
 >> iter 2000, loss: 4.128507
 >> iter 3000, loss: 1.549632
 >> iter 4000, loss: 0.606736
 >> iter 5000, loss: 0.252651
 >> iter 6000, loss: 0.115020
 >> iter 7000, loss: 0.069082
 >> iter 8000, loss: 0.046763
 >> iter 9000, loss: 0.041851
 >> iter 10000, loss: 0.037281
   Number of active neurons: 6
 >> iter 11000, loss: 0.034398
 >> iter 12000, loss: 0.031636
 >> iter 13000, loss: 0.039695
 >> iter 14000, loss: 0.034108
 >> iter 15000, loss: 0.031813
 >> iter 16000, loss: 0.042994
 >> iter 17000, loss: 0.036317
 >> iter 18000, loss: 0.029899
 >> iter 19000, loss: 0.027641
 >> iter 20000, loss: 0.029982
   Number of active neurons: 2
 >> iter 21000, loss: 0.028338
 >> iter 22000, loss: 0.028282
 >> iter 23000, loss: 0.039100
 >> iter 24000, loss: 0.031332
 >> iter 25000, loss: 0.027639
 >> iter 26000, loss: 0.029096
 >> iter 27000, loss: 0.024210
 >> iter 28000, loss: 0.021290
 >> iter 29000, loss: 0.038029
 >> iter 30000, loss: 0.029905
   Number of active neurons: 2
 >> iter 31000, loss: 0.033253
 >> iter 32000, loss: 0.025297
 >> iter 33000, loss: 0.021553
 >> iter 34000, loss: 0.020535
 >> iter 35000, loss: 0.021026
 >> iter 36000, loss: 0.025356
 >> iter 37000, loss: 0.044027
 >> iter 38000, loss: 0.036236
 >> iter 39000, loss: 0.026960
 >> iter 40000, loss: 0.026177
   Number of active neurons: 2
 >> iter 41000, loss: 0.022332
 >> iter 42000, loss: 0.023134
 >> iter 43000, loss: 0.042824
 >> iter 44000, loss: 0.032527
 >> iter 45000, loss: 0.033891
 >> iter 46000, loss: 0.024366
 >> iter 47000, loss: 0.020834
 >> iter 48000, loss: 0.020333
 >> iter 49000, loss: 0.018617
 >> iter 50000, loss: 0.020016
   Number of active neurons: 1
 >> iter 51000, loss: 0.016857
 >> iter 52000, loss: 0.017510
 >> iter 53000, loss: 0.052063
 >> iter 54000, loss: 0.032463
 >> iter 55000, loss: 0.025748
 >> iter 56000, loss: 0.027976
 >> iter 57000, loss: 0.024953
 >> iter 58000, loss: 0.020263
 >> iter 59000, loss: 0.036652
 >> iter 60000, loss: 0.023579
   Number of active neurons: 1
 >> iter 61000, loss: 0.019198
 >> iter 62000, loss: 0.024228
 >> iter 63000, loss: 0.021177
 >> iter 64000, loss: 0.030599
 >> iter 65000, loss: 0.029165
 >> iter 66000, loss: 0.032459
 >> iter 67000, loss: 0.023740
 >> iter 68000, loss: 0.018451
 >> iter 69000, loss: 0.020462
 >> iter 70000, loss: 0.030637
   Number of active neurons: 1
 >> iter 71000, loss: 0.021728
 >> iter 72000, loss: 0.018482
 >> iter 73000, loss: 0.019412
 >> iter 74000, loss: 0.018188
 >> iter 75000, loss: 0.033609
 >> iter 76000, loss: 0.023746
 >> iter 77000, loss: 0.019029
 >> iter 78000, loss: 0.018175
 >> iter 79000, loss: 0.021146
 >> iter 80000, loss: 0.021293
   Number of active neurons: 1
 >> iter 81000, loss: 0.023520
 >> iter 82000, loss: 0.019908
 >> iter 83000, loss: 0.018145
 >> iter 84000, loss: 0.021879
 >> iter 85000, loss: 0.021923
 >> iter 86000, loss: 0.019971
 >> iter 87000, loss: 0.022840
 >> iter 88000, loss: 0.019800
 >> iter 89000, loss: 0.020257
 >> iter 90000, loss: 0.017833
   Number of active neurons: 1
 >> iter 91000, loss: 0.017824
 >> iter 92000, loss: 0.019137
 >> iter 93000, loss: 0.019098
 >> iter 94000, loss: 0.027591
 >> iter 95000, loss: 0.024238
 >> iter 96000, loss: 0.019515
 >> iter 97000, loss: 0.018575
 >> iter 98000, loss: 0.034023
 >> iter 99000, loss: 0.022968
 >> iter 100000, loss: 0.020989
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.959838
 >> iter 2000, loss: 4.075507
 >> iter 3000, loss: 1.532175
 >> iter 4000, loss: 0.590905
 >> iter 5000, loss: 0.240135
 >> iter 6000, loss: 0.116130
 >> iter 7000, loss: 0.064950
 >> iter 8000, loss: 0.045004
 >> iter 9000, loss: 0.048374
 >> iter 10000, loss: 0.036177
   Number of active neurons: 4
 >> iter 11000, loss: 0.034331
 >> iter 12000, loss: 0.028911
 >> iter 13000, loss: 0.054213
 >> iter 14000, loss: 0.037533
 >> iter 15000, loss: 0.029354
 >> iter 16000, loss: 0.026499
 >> iter 17000, loss: 0.025710
 >> iter 18000, loss: 0.027708
 >> iter 19000, loss: 0.030516
 >> iter 20000, loss: 0.034616
   Number of active neurons: 3
 >> iter 21000, loss: 0.030520
 >> iter 22000, loss: 0.029356
 >> iter 23000, loss: 0.024711
 >> iter 24000, loss: 0.022224
 >> iter 25000, loss: 0.025872
 >> iter 26000, loss: 0.025058
 >> iter 27000, loss: 0.022769
 >> iter 28000, loss: 0.034225
 >> iter 29000, loss: 0.028746
 >> iter 30000, loss: 0.024253
   Number of active neurons: 2
 >> iter 31000, loss: 0.021829
 >> iter 32000, loss: 0.024205
 >> iter 33000, loss: 0.026417
 >> iter 34000, loss: 0.022638
 >> iter 35000, loss: 0.028819
 >> iter 36000, loss: 0.024201
 >> iter 37000, loss: 0.023092
 >> iter 38000, loss: 0.022452
 >> iter 39000, loss: 0.021787
 >> iter 40000, loss: 0.020566
   Number of active neurons: 2
 >> iter 41000, loss: 0.021066
 >> iter 42000, loss: 0.020327
 >> iter 43000, loss: 0.028565
 >> iter 44000, loss: 0.023280
 >> iter 45000, loss: 0.032084
 >> iter 46000, loss: 0.023722
 >> iter 47000, loss: 0.068824
 >> iter 48000, loss: 0.040506
 >> iter 49000, loss: 0.029539
 >> iter 50000, loss: 0.024575
   Number of active neurons: 2
 >> iter 51000, loss: 0.022645
 >> iter 52000, loss: 0.022015
 >> iter 53000, loss: 0.021386
 >> iter 54000, loss: 0.020656
 >> iter 55000, loss: 0.021495
 >> iter 56000, loss: 0.020861
 >> iter 57000, loss: 0.021249
 >> iter 58000, loss: 0.020624
 >> iter 59000, loss: 0.022675
 >> iter 60000, loss: 0.020237
   Number of active neurons: 2
 >> iter 61000, loss: 0.027180
 >> iter 62000, loss: 0.023766
 >> iter 63000, loss: 0.021580
 >> iter 64000, loss: 0.020457
 >> iter 65000, loss: 0.022532
 >> iter 66000, loss: 0.024539
 >> iter 67000, loss: 0.028269
 >> iter 68000, loss: 0.023200
 >> iter 69000, loss: 0.022840
 >> iter 70000, loss: 0.037048
   Number of active neurons: 2
 >> iter 71000, loss: 0.028905
 >> iter 72000, loss: 0.028089
 >> iter 73000, loss: 0.022555
 >> iter 74000, loss: 0.019645
 >> iter 75000, loss: 0.024251
 >> iter 76000, loss: 0.031173
 >> iter 77000, loss: 0.025492
 >> iter 78000, loss: 0.026605
 >> iter 79000, loss: 0.023557
 >> iter 80000, loss: 0.020459
   Number of active neurons: 2
 >> iter 81000, loss: 0.022679
 >> iter 82000, loss: 0.020897
 >> iter 83000, loss: 0.020171
 >> iter 84000, loss: 0.021939
 >> iter 85000, loss: 0.026472
 >> iter 86000, loss: 0.023832
 >> iter 87000, loss: 0.027993
 >> iter 88000, loss: 0.023709
 >> iter 89000, loss: 0.028589
 >> iter 90000, loss: 0.023093
   Number of active neurons: 2
 >> iter 91000, loss: 0.023346
 >> iter 92000, loss: 0.021710
 >> iter 93000, loss: 0.026557
 >> iter 94000, loss: 0.024251
 >> iter 95000, loss: 0.028525
 >> iter 96000, loss: 0.026768
 >> iter 97000, loss: 0.042293
 >> iter 98000, loss: 0.030459
 >> iter 99000, loss: 0.044339
 >> iter 100000, loss: 0.031530
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.022796
 >> iter 2000, loss: 4.110425
 >> iter 3000, loss: 1.556463
 >> iter 4000, loss: 0.596431
 >> iter 5000, loss: 0.241326
 >> iter 6000, loss: 0.112161
 >> iter 7000, loss: 0.066329
 >> iter 8000, loss: 0.045129
 >> iter 9000, loss: 0.037359
 >> iter 10000, loss: 0.036388
   Number of active neurons: 5
 >> iter 11000, loss: 0.034526
 >> iter 12000, loss: 0.032074
 >> iter 13000, loss: 0.029467
 >> iter 14000, loss: 0.038856
 >> iter 15000, loss: 0.033839
 >> iter 16000, loss: 0.030753
 >> iter 17000, loss: 0.027970
 >> iter 18000, loss: 0.027551
 >> iter 19000, loss: 0.028160
 >> iter 20000, loss: 0.029019
   Number of active neurons: 4
 >> iter 21000, loss: 0.028034
 >> iter 22000, loss: 0.026999
 >> iter 23000, loss: 0.039182
 >> iter 24000, loss: 0.032255
 >> iter 25000, loss: 0.029222
 >> iter 26000, loss: 0.025607
 >> iter 27000, loss: 0.031038
 >> iter 28000, loss: 0.027973
 >> iter 29000, loss: 0.030019
 >> iter 30000, loss: 0.026376
   Number of active neurons: 3
 >> iter 31000, loss: 0.026666
 >> iter 32000, loss: 0.033378
 >> iter 33000, loss: 0.027274
 >> iter 34000, loss: 0.025579
 >> iter 35000, loss: 0.023225
 >> iter 36000, loss: 0.024530
 >> iter 37000, loss: 0.023787
 >> iter 38000, loss: 0.023291
 >> iter 39000, loss: 0.024019
 >> iter 40000, loss: 0.025934
   Number of active neurons: 3
 >> iter 41000, loss: 0.025077
 >> iter 42000, loss: 0.022508
 >> iter 43000, loss: 0.024927
 >> iter 44000, loss: 0.040749
 >> iter 45000, loss: 0.029519
 >> iter 46000, loss: 0.025983
 >> iter 47000, loss: 0.024544
 >> iter 48000, loss: 0.028617
 >> iter 49000, loss: 0.023822
 >> iter 50000, loss: 0.022800
   Number of active neurons: 2
 >> iter 51000, loss: 0.029848
 >> iter 52000, loss: 0.025978
 >> iter 53000, loss: 0.024587
 >> iter 54000, loss: 0.022472
 >> iter 55000, loss: 0.019929
 >> iter 56000, loss: 0.020856
 >> iter 57000, loss: 0.021256
 >> iter 58000, loss: 0.062720
 >> iter 59000, loss: 0.036623
 >> iter 60000, loss: 0.039129
   Number of active neurons: 2
 >> iter 61000, loss: 0.044749
 >> iter 62000, loss: 0.034161
 >> iter 63000, loss: 0.026931
 >> iter 64000, loss: 0.025998
 >> iter 65000, loss: 0.024662
 >> iter 66000, loss: 0.020834
 >> iter 67000, loss: 0.020625
 >> iter 68000, loss: 0.023040
 >> iter 69000, loss: 0.026823
 >> iter 70000, loss: 0.022626
   Number of active neurons: 2
 >> iter 71000, loss: 0.021615
 >> iter 72000, loss: 0.024433
 >> iter 73000, loss: 0.025484
 >> iter 74000, loss: 0.021672
 >> iter 75000, loss: 0.025525
 >> iter 76000, loss: 0.056380
 >> iter 77000, loss: 0.037626
 >> iter 78000, loss: 0.027201
 >> iter 79000, loss: 0.031755
 >> iter 80000, loss: 0.025730
   Number of active neurons: 2
 >> iter 81000, loss: 0.023879
 >> iter 82000, loss: 0.029863
 >> iter 83000, loss: 0.030846
 >> iter 84000, loss: 0.025466
 >> iter 85000, loss: 0.022996
 >> iter 86000, loss: 0.022713
 >> iter 87000, loss: 0.030446
 >> iter 88000, loss: 0.024705
 >> iter 89000, loss: 0.021385
 >> iter 90000, loss: 0.029294
   Number of active neurons: 2
 >> iter 91000, loss: 0.023762
 >> iter 92000, loss: 0.022188
 >> iter 93000, loss: 0.023278
 >> iter 94000, loss: 0.024931
 >> iter 95000, loss: 0.031609
 >> iter 96000, loss: 0.045085
 >> iter 97000, loss: 0.032910
 >> iter 98000, loss: 0.023201
 >> iter 99000, loss: 0.026070
 >> iter 100000, loss: 0.021175
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.997518
 >> iter 2000, loss: 4.093251
 >> iter 3000, loss: 1.563333
 >> iter 4000, loss: 0.603027
 >> iter 5000, loss: 0.248420
 >> iter 6000, loss: 0.114401
 >> iter 7000, loss: 0.069175
 >> iter 8000, loss: 0.046175
 >> iter 9000, loss: 0.038226
 >> iter 10000, loss: 0.034489
   Number of active neurons: 6
 >> iter 11000, loss: 0.046021
 >> iter 12000, loss: 0.036369
 >> iter 13000, loss: 0.030802
 >> iter 14000, loss: 0.030680
 >> iter 15000, loss: 0.029425
 >> iter 16000, loss: 0.034447
 >> iter 17000, loss: 0.035714
 >> iter 18000, loss: 0.028634
 >> iter 19000, loss: 0.026649
 >> iter 20000, loss: 0.026412
   Number of active neurons: 4
 >> iter 21000, loss: 0.027088
 >> iter 22000, loss: 0.039111
 >> iter 23000, loss: 0.035472
 >> iter 24000, loss: 0.030029
 >> iter 25000, loss: 0.028751
 >> iter 26000, loss: 0.026020
 >> iter 27000, loss: 0.023326
 >> iter 28000, loss: 0.027131
 >> iter 29000, loss: 0.029293
 >> iter 30000, loss: 0.029391
   Number of active neurons: 3
 >> iter 31000, loss: 0.025310
 >> iter 32000, loss: 0.024553
 >> iter 33000, loss: 0.027141
 >> iter 34000, loss: 0.028383
 >> iter 35000, loss: 0.026397
 >> iter 36000, loss: 0.025908
 >> iter 37000, loss: 0.025382
 >> iter 38000, loss: 0.025739
 >> iter 39000, loss: 0.024170
 >> iter 40000, loss: 0.025076
   Number of active neurons: 3
 >> iter 41000, loss: 0.024806
 >> iter 42000, loss: 0.023249
 >> iter 43000, loss: 0.023970
 >> iter 44000, loss: 0.027160
 >> iter 45000, loss: 0.027550
 >> iter 46000, loss: 0.028227
 >> iter 47000, loss: 0.023690
 >> iter 48000, loss: 0.024569
 >> iter 49000, loss: 0.022816
 >> iter 50000, loss: 0.022167
   Number of active neurons: 3
 >> iter 51000, loss: 0.022748
 >> iter 52000, loss: 0.027373
 >> iter 53000, loss: 0.037025
 >> iter 54000, loss: 0.026668
 >> iter 55000, loss: 0.023517
 >> iter 56000, loss: 0.026843
 >> iter 57000, loss: 0.027133
 >> iter 58000, loss: 0.023531
 >> iter 59000, loss: 0.024379
 >> iter 60000, loss: 0.034548
   Number of active neurons: 3
 >> iter 61000, loss: 0.030820
 >> iter 62000, loss: 0.024247
 >> iter 63000, loss: 0.024453
 >> iter 64000, loss: 0.026273
 >> iter 65000, loss: 0.024986
 >> iter 66000, loss: 0.025654
 >> iter 67000, loss: 0.027161
 >> iter 68000, loss: 0.025243
 >> iter 69000, loss: 0.024700
 >> iter 70000, loss: 0.024416
   Number of active neurons: 3
 >> iter 71000, loss: 0.030954
 >> iter 72000, loss: 0.032943
 >> iter 73000, loss: 0.028414
 >> iter 74000, loss: 0.025266
 >> iter 75000, loss: 0.038067
 >> iter 76000, loss: 0.035233
 >> iter 77000, loss: 0.027442
 >> iter 78000, loss: 0.023904
 >> iter 79000, loss: 0.022786
 >> iter 80000, loss: 0.021804
   Number of active neurons: 2
 >> iter 81000, loss: 0.023212
 >> iter 82000, loss: 0.023998
 >> iter 83000, loss: 0.025547
 >> iter 84000, loss: 0.023666
 >> iter 85000, loss: 0.021837
 >> iter 86000, loss: 0.028659
 >> iter 87000, loss: 0.025256
 >> iter 88000, loss: 0.025834
 >> iter 89000, loss: 0.022919
 >> iter 90000, loss: 0.020077
   Number of active neurons: 2
 >> iter 91000, loss: 0.022555
 >> iter 92000, loss: 0.026758
 >> iter 93000, loss: 0.029518
 >> iter 94000, loss: 0.025104
 >> iter 95000, loss: 0.022595
 >> iter 96000, loss: 0.021210
 >> iter 97000, loss: 0.025944
 >> iter 98000, loss: 0.024235
 >> iter 99000, loss: 0.021225
 >> iter 100000, loss: 0.021956
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.976276
 >> iter 2000, loss: 4.105089
 >> iter 3000, loss: 1.545164
 >> iter 4000, loss: 0.606288
 >> iter 5000, loss: 0.249028
 >> iter 6000, loss: 0.117376
 >> iter 7000, loss: 0.072910
 >> iter 8000, loss: 0.046763
 >> iter 9000, loss: 0.036115
 >> iter 10000, loss: 0.033455
   Number of active neurons: 4
 >> iter 11000, loss: 0.044258
 >> iter 12000, loss: 0.055187
 >> iter 13000, loss: 0.039135
 >> iter 14000, loss: 0.029705
 >> iter 15000, loss: 0.031490
 >> iter 16000, loss: 0.029564
 >> iter 17000, loss: 0.029133
 >> iter 18000, loss: 0.028704
 >> iter 19000, loss: 0.029645
 >> iter 20000, loss: 0.027103
   Number of active neurons: 4
 >> iter 21000, loss: 0.027870
 >> iter 22000, loss: 0.029477
 >> iter 23000, loss: 0.028319
 >> iter 24000, loss: 0.030725
 >> iter 25000, loss: 0.036979
 >> iter 26000, loss: 0.028580
 >> iter 27000, loss: 0.039671
 >> iter 28000, loss: 0.039507
 >> iter 29000, loss: 0.031249
 >> iter 30000, loss: 0.028214
   Number of active neurons: 4
 >> iter 31000, loss: 0.039318
 >> iter 32000, loss: 0.033256
 >> iter 33000, loss: 0.029161
 >> iter 34000, loss: 0.029564
 >> iter 35000, loss: 0.027676
 >> iter 36000, loss: 0.026394
 >> iter 37000, loss: 0.025075
 >> iter 38000, loss: 0.028457
 >> iter 39000, loss: 0.049441
 >> iter 40000, loss: 0.047070
   Number of active neurons: 3
 >> iter 41000, loss: 0.035666
 >> iter 42000, loss: 0.029235
 >> iter 43000, loss: 0.043179
 >> iter 44000, loss: 0.035338
 >> iter 45000, loss: 0.028929
 >> iter 46000, loss: 0.024335
 >> iter 47000, loss: 0.023639
 >> iter 48000, loss: 0.038294
 >> iter 49000, loss: 0.026609
 >> iter 50000, loss: 0.027505
   Number of active neurons: 2
 >> iter 51000, loss: 0.033275
 >> iter 52000, loss: 0.027981
 >> iter 53000, loss: 0.024920
 >> iter 54000, loss: 0.023741
 >> iter 55000, loss: 0.045871
 >> iter 56000, loss: 0.034138
 >> iter 57000, loss: 0.025850
 >> iter 58000, loss: 0.037806
 >> iter 59000, loss: 0.029095
 >> iter 60000, loss: 0.024809
   Number of active neurons: 2
 >> iter 61000, loss: 0.026308
 >> iter 62000, loss: 0.023883
 >> iter 63000, loss: 0.023209
 >> iter 64000, loss: 0.021186
 >> iter 65000, loss: 0.037424
 >> iter 66000, loss: 0.029612
 >> iter 67000, loss: 0.026554
 >> iter 68000, loss: 0.024936
 >> iter 69000, loss: 0.023157
 >> iter 70000, loss: 0.018502
   Number of active neurons: 1
 >> iter 71000, loss: 0.022328
 >> iter 72000, loss: 0.019691
 >> iter 73000, loss: 0.037403
 >> iter 74000, loss: 0.024884
 >> iter 75000, loss: 0.019704
 >> iter 76000, loss: 0.027655
 >> iter 77000, loss: 0.028670
 >> iter 78000, loss: 0.038760
 >> iter 79000, loss: 0.024555
 >> iter 80000, loss: 0.020156
   Number of active neurons: 1
 >> iter 81000, loss: 0.023187
 >> iter 82000, loss: 0.019563
 >> iter 83000, loss: 0.049848
 >> iter 84000, loss: 0.032258
 >> iter 85000, loss: 0.022658
 >> iter 86000, loss: 0.024757
 >> iter 87000, loss: 0.020015
 >> iter 88000, loss: 0.026288
 >> iter 89000, loss: 0.021388
 >> iter 90000, loss: 0.017962
   Number of active neurons: 1
 >> iter 91000, loss: 0.016380
 >> iter 92000, loss: 0.016594
 >> iter 93000, loss: 0.019372
 >> iter 94000, loss: 0.023143
 >> iter 95000, loss: 0.020173
 >> iter 96000, loss: 0.021765
 >> iter 97000, loss: 0.018039
 >> iter 98000, loss: 0.022658
 >> iter 99000, loss: 0.022132
 >> iter 100000, loss: 0.021793
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.928000
 >> iter 2000, loss: 4.065846
 >> iter 3000, loss: 1.526282
 >> iter 4000, loss: 0.589906
 >> iter 5000, loss: 0.240840
 >> iter 6000, loss: 0.105106
 >> iter 7000, loss: 0.059924
 >> iter 8000, loss: 0.045583
 >> iter 9000, loss: 0.033503
 >> iter 10000, loss: 0.034556
   Number of active neurons: 4
 >> iter 11000, loss: 0.054730
 >> iter 12000, loss: 0.039099
 >> iter 13000, loss: 0.032832
 >> iter 14000, loss: 0.030867
 >> iter 15000, loss: 0.045019
 >> iter 16000, loss: 0.033175
 >> iter 17000, loss: 0.036438
 >> iter 18000, loss: 0.030989
 >> iter 19000, loss: 0.029852
 >> iter 20000, loss: 0.027366
   Number of active neurons: 4
 >> iter 21000, loss: 0.028618
 >> iter 22000, loss: 0.027787
 >> iter 23000, loss: 0.050370
 >> iter 24000, loss: 0.044504
 >> iter 25000, loss: 0.058353
 >> iter 26000, loss: 0.052902
 >> iter 27000, loss: 0.038841
 >> iter 28000, loss: 0.036316
 >> iter 29000, loss: 0.029493
 >> iter 30000, loss: 0.028207
   Number of active neurons: 4
 >> iter 31000, loss: 0.026857
 >> iter 32000, loss: 0.026199
 >> iter 33000, loss: 0.028574
 >> iter 34000, loss: 0.029351
 >> iter 35000, loss: 0.028597
 >> iter 36000, loss: 0.031779
 >> iter 37000, loss: 0.042660
 >> iter 38000, loss: 0.032828
 >> iter 39000, loss: 0.029155
 >> iter 40000, loss: 0.027715
   Number of active neurons: 2
 >> iter 41000, loss: 0.024631
 >> iter 42000, loss: 0.032097
 >> iter 43000, loss: 0.027700
 >> iter 44000, loss: 0.024151
 >> iter 45000, loss: 0.023135
 >> iter 46000, loss: 0.029492
 >> iter 47000, loss: 0.041425
 >> iter 48000, loss: 0.029524
 >> iter 49000, loss: 0.023235
 >> iter 50000, loss: 0.032052
   Number of active neurons: 1
 >> iter 51000, loss: 0.035565
 >> iter 52000, loss: 0.025810
 >> iter 53000, loss: 0.022478
 >> iter 54000, loss: 0.019950
 >> iter 55000, loss: 0.024847
 >> iter 56000, loss: 0.045122
 >> iter 57000, loss: 0.029037
 >> iter 58000, loss: 0.044886
 >> iter 59000, loss: 0.033649
 >> iter 60000, loss: 0.023063
   Number of active neurons: 1
 >> iter 61000, loss: 0.019387
 >> iter 62000, loss: 0.017932
 >> iter 63000, loss: 0.018617
 >> iter 64000, loss: 0.018206
 >> iter 65000, loss: 0.019417
 >> iter 66000, loss: 0.017051
 >> iter 67000, loss: 0.018038
 >> iter 68000, loss: 0.032221
 >> iter 69000, loss: 0.028470
 >> iter 70000, loss: 0.033720
   Number of active neurons: 1
 >> iter 71000, loss: 0.023611
 >> iter 72000, loss: 0.020121
 >> iter 73000, loss: 0.017733
 >> iter 74000, loss: 0.025833
 >> iter 75000, loss: 0.019815
 >> iter 76000, loss: 0.024546
 >> iter 77000, loss: 0.021397
 >> iter 78000, loss: 0.017566
 >> iter 79000, loss: 0.018647
 >> iter 80000, loss: 0.019381
   Number of active neurons: 1
 >> iter 81000, loss: 0.034421
 >> iter 82000, loss: 0.027037
 >> iter 83000, loss: 0.025507
 >> iter 84000, loss: 0.021269
 >> iter 85000, loss: 0.031389
 >> iter 86000, loss: 0.026564
 >> iter 87000, loss: 0.019439
 >> iter 88000, loss: 0.029503
 >> iter 89000, loss: 0.024477
 >> iter 90000, loss: 0.025118
   Number of active neurons: 1
 >> iter 91000, loss: 0.020827
 >> iter 92000, loss: 0.029950
 >> iter 93000, loss: 0.023026
 >> iter 94000, loss: 0.019819
 >> iter 95000, loss: 0.021848
 >> iter 96000, loss: 0.019716
 >> iter 97000, loss: 0.029100
 >> iter 98000, loss: 0.023543
 >> iter 99000, loss: 0.034749
 >> iter 100000, loss: 0.023833
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.937697
 >> iter 2000, loss: 4.066325
 >> iter 3000, loss: 1.530993
 >> iter 4000, loss: 0.596675
 >> iter 5000, loss: 0.245518
 >> iter 6000, loss: 0.113157
 >> iter 7000, loss: 0.075991
 >> iter 8000, loss: 0.046289
 >> iter 9000, loss: 0.054680
 >> iter 10000, loss: 0.039614
   Number of active neurons: 5
 >> iter 11000, loss: 0.034546
 >> iter 12000, loss: 0.028004
 >> iter 13000, loss: 0.027763
 >> iter 14000, loss: 0.030046
 >> iter 15000, loss: 0.028065
 >> iter 16000, loss: 0.031242
 >> iter 17000, loss: 0.030413
 >> iter 18000, loss: 0.032693
 >> iter 19000, loss: 0.029965
 >> iter 20000, loss: 0.024856
   Number of active neurons: 3
 >> iter 21000, loss: 0.023643
 >> iter 22000, loss: 0.029205
 >> iter 23000, loss: 0.028144
 >> iter 24000, loss: 0.024733
 >> iter 25000, loss: 0.027916
 >> iter 26000, loss: 0.034801
 >> iter 27000, loss: 0.026646
 >> iter 28000, loss: 0.032508
 >> iter 29000, loss: 0.026764
 >> iter 30000, loss: 0.024036
   Number of active neurons: 3
 >> iter 31000, loss: 0.024343
 >> iter 32000, loss: 0.026540
 >> iter 33000, loss: 0.028906
 >> iter 34000, loss: 0.030143
 >> iter 35000, loss: 0.026623
 >> iter 36000, loss: 0.024326
 >> iter 37000, loss: 0.023908
 >> iter 38000, loss: 0.025111
 >> iter 39000, loss: 0.023150
 >> iter 40000, loss: 0.024531
   Number of active neurons: 3
 >> iter 41000, loss: 0.030706
 >> iter 42000, loss: 0.036672
 >> iter 43000, loss: 0.033942
 >> iter 44000, loss: 0.027984
 >> iter 45000, loss: 0.028351
 >> iter 46000, loss: 0.025116
 >> iter 47000, loss: 0.023603
 >> iter 48000, loss: 0.021337
 >> iter 49000, loss: 0.021015
 >> iter 50000, loss: 0.024584
   Number of active neurons: 2
 >> iter 51000, loss: 0.074667
 >> iter 52000, loss: 0.053514
 >> iter 53000, loss: 0.033983
 >> iter 54000, loss: 0.029299
 >> iter 55000, loss: 0.026316
 >> iter 56000, loss: 0.021158
 >> iter 57000, loss: 0.023399
 >> iter 58000, loss: 0.028850
 >> iter 59000, loss: 0.033181
 >> iter 60000, loss: 0.026465
   Number of active neurons: 2
 >> iter 61000, loss: 0.024334
 >> iter 62000, loss: 0.021750
 >> iter 63000, loss: 0.022118
 >> iter 64000, loss: 0.030868
 >> iter 65000, loss: 0.024767
 >> iter 66000, loss: 0.026367
 >> iter 67000, loss: 0.023960
 >> iter 68000, loss: 0.027047
 >> iter 69000, loss: 0.027226
 >> iter 70000, loss: 0.021179
   Number of active neurons: 1
 >> iter 71000, loss: 0.031743
 >> iter 72000, loss: 0.024506
 >> iter 73000, loss: 0.023025
 >> iter 74000, loss: 0.020891
 >> iter 75000, loss: 0.018159
 >> iter 76000, loss: 0.018517
 >> iter 77000, loss: 0.026585
 >> iter 78000, loss: 0.024465
 >> iter 79000, loss: 0.019468
 >> iter 80000, loss: 0.019341
   Number of active neurons: 1
 >> iter 81000, loss: 0.018262
 >> iter 82000, loss: 0.016167
 >> iter 83000, loss: 0.018604
 >> iter 84000, loss: 0.016412
 >> iter 85000, loss: 0.028167
 >> iter 86000, loss: 0.020135
 >> iter 87000, loss: 0.020049
 >> iter 88000, loss: 0.066034
 >> iter 89000, loss: 0.035753
 >> iter 90000, loss: 0.028847
   Number of active neurons: 1
 >> iter 91000, loss: 0.023951
 >> iter 92000, loss: 0.020233
 >> iter 93000, loss: 0.022068
 >> iter 94000, loss: 0.020312
 >> iter 95000, loss: 0.029181
 >> iter 96000, loss: 0.020853
 >> iter 97000, loss: 0.019912
 >> iter 98000, loss: 0.019933
 >> iter 99000, loss: 0.037597
 >> iter 100000, loss: 0.024229
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.047373
 >> iter 2000, loss: 4.114477
 >> iter 3000, loss: 1.547001
 >> iter 4000, loss: 0.604730
 >> iter 5000, loss: 0.253885
 >> iter 6000, loss: 0.118089
 >> iter 7000, loss: 0.070235
 >> iter 8000, loss: 0.051295
 >> iter 9000, loss: 0.038900
 >> iter 10000, loss: 0.040392
   Number of active neurons: 6
 >> iter 11000, loss: 0.044974
 >> iter 12000, loss: 0.038267
 >> iter 13000, loss: 0.031382
 >> iter 14000, loss: 0.031871
 >> iter 15000, loss: 0.032496
 >> iter 16000, loss: 0.030382
 >> iter 17000, loss: 0.028325
 >> iter 18000, loss: 0.031379
 >> iter 19000, loss: 0.031952
 >> iter 20000, loss: 0.027020
   Number of active neurons: 3
 >> iter 21000, loss: 0.032896
 >> iter 22000, loss: 0.035160
 >> iter 23000, loss: 0.029416
 >> iter 24000, loss: 0.029203
 >> iter 25000, loss: 0.045621
 >> iter 26000, loss: 0.035677
 >> iter 27000, loss: 0.028604
 >> iter 28000, loss: 0.029442
 >> iter 29000, loss: 0.031867
 >> iter 30000, loss: 0.028316
   Number of active neurons: 3
 >> iter 31000, loss: 0.032852
 >> iter 32000, loss: 0.028192
 >> iter 33000, loss: 0.026702
 >> iter 34000, loss: 0.025048
 >> iter 35000, loss: 0.024739
 >> iter 36000, loss: 0.026757
 >> iter 37000, loss: 0.038879
 >> iter 38000, loss: 0.034228
 >> iter 39000, loss: 0.038564
 >> iter 40000, loss: 0.027650
   Number of active neurons: 3
 >> iter 41000, loss: 0.030564
 >> iter 42000, loss: 0.026867
 >> iter 43000, loss: 0.023498
 >> iter 44000, loss: 0.023934
 >> iter 45000, loss: 0.029853
 >> iter 46000, loss: 0.026322
 >> iter 47000, loss: 0.030879
 >> iter 48000, loss: 0.025030
 >> iter 49000, loss: 0.023535
 >> iter 50000, loss: 0.026408
   Number of active neurons: 3
 >> iter 51000, loss: 0.024653
 >> iter 52000, loss: 0.023263
 >> iter 53000, loss: 0.026642
 >> iter 54000, loss: 0.024361
 >> iter 55000, loss: 0.027867
 >> iter 56000, loss: 0.024921
 >> iter 57000, loss: 0.030367
 >> iter 58000, loss: 0.027675
 >> iter 59000, loss: 0.027361
 >> iter 60000, loss: 0.043143
   Number of active neurons: 3
 >> iter 61000, loss: 0.040885
 >> iter 62000, loss: 0.030652
 >> iter 63000, loss: 0.040986
 >> iter 64000, loss: 0.035716
 >> iter 65000, loss: 0.036097
 >> iter 66000, loss: 0.030036
 >> iter 67000, loss: 0.024515
 >> iter 68000, loss: 0.033990
 >> iter 69000, loss: 0.025392
 >> iter 70000, loss: 0.024150
   Number of active neurons: 2
 >> iter 71000, loss: 0.024250
 >> iter 72000, loss: 0.023493
 >> iter 73000, loss: 0.022276
 >> iter 74000, loss: 0.022079
 >> iter 75000, loss: 0.019806
 >> iter 76000, loss: 0.035832
 >> iter 77000, loss: 0.025639
 >> iter 78000, loss: 0.021995
 >> iter 79000, loss: 0.020885
 >> iter 80000, loss: 0.029096
   Number of active neurons: 1
 >> iter 81000, loss: 0.025684
 >> iter 82000, loss: 0.020586
 >> iter 83000, loss: 0.026196
 >> iter 84000, loss: 0.024107
 >> iter 85000, loss: 0.027887
 >> iter 86000, loss: 0.021476
 >> iter 87000, loss: 0.022086
 >> iter 88000, loss: 0.020916
 >> iter 89000, loss: 0.024323
 >> iter 90000, loss: 0.019751
   Number of active neurons: 1
 >> iter 91000, loss: 0.019878
 >> iter 92000, loss: 0.036904
 >> iter 93000, loss: 0.024755
 >> iter 94000, loss: 0.021263
 >> iter 95000, loss: 0.023689
 >> iter 96000, loss: 0.029265
 >> iter 97000, loss: 0.021528
 >> iter 98000, loss: 0.027589
 >> iter 99000, loss: 0.025447
 >> iter 100000, loss: 0.019430
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.989099
 >> iter 2000, loss: 4.089036
 >> iter 3000, loss: 1.535247
 >> iter 4000, loss: 0.590940
 >> iter 5000, loss: 0.247029
 >> iter 6000, loss: 0.115001
 >> iter 7000, loss: 0.071951
 >> iter 8000, loss: 0.047077
 >> iter 9000, loss: 0.041412
 >> iter 10000, loss: 0.036571
   Number of active neurons: 5
 >> iter 11000, loss: 0.033110
 >> iter 12000, loss: 0.032166
 >> iter 13000, loss: 0.043878
 >> iter 14000, loss: 0.039054
 >> iter 15000, loss: 0.036986
 >> iter 16000, loss: 0.032998
 >> iter 17000, loss: 0.028867
 >> iter 18000, loss: 0.028350
 >> iter 19000, loss: 0.027983
 >> iter 20000, loss: 0.049729
   Number of active neurons: 5
 >> iter 21000, loss: 0.043174
 >> iter 22000, loss: 0.041028
 >> iter 23000, loss: 0.033337
 >> iter 24000, loss: 0.030735
 >> iter 25000, loss: 0.031079
 >> iter 26000, loss: 0.029303
 >> iter 27000, loss: 0.028309
 >> iter 28000, loss: 0.025872
 >> iter 29000, loss: 0.028661
 >> iter 30000, loss: 0.048586
   Number of active neurons: 2
 >> iter 31000, loss: 0.034251
 >> iter 32000, loss: 0.031370
 >> iter 33000, loss: 0.027512
 >> iter 34000, loss: 0.030049
 >> iter 35000, loss: 0.028862
 >> iter 36000, loss: 0.031890
 >> iter 37000, loss: 0.025782
 >> iter 38000, loss: 0.027975
 >> iter 39000, loss: 0.022785
 >> iter 40000, loss: 0.019820
   Number of active neurons: 1
 >> iter 41000, loss: 0.037470
 >> iter 42000, loss: 0.033385
 >> iter 43000, loss: 0.023534
 >> iter 44000, loss: 0.023384
 >> iter 45000, loss: 0.023768
 >> iter 46000, loss: 0.019357
 >> iter 47000, loss: 0.021709
 >> iter 48000, loss: 0.019336
 >> iter 49000, loss: 0.020976
 >> iter 50000, loss: 0.023870
   Number of active neurons: 1
 >> iter 51000, loss: 0.019607
 >> iter 52000, loss: 0.017035
 >> iter 53000, loss: 0.016895
 >> iter 54000, loss: 0.017250
 >> iter 55000, loss: 0.022118
 >> iter 56000, loss: 0.021508
 >> iter 57000, loss: 0.017676
 >> iter 58000, loss: 0.016164
 >> iter 59000, loss: 0.019114
 >> iter 60000, loss: 0.016651
   Number of active neurons: 1
 >> iter 61000, loss: 0.020372
 >> iter 62000, loss: 0.019834
 >> iter 63000, loss: 0.016801
 >> iter 64000, loss: 0.016941
 >> iter 65000, loss: 0.016082
 >> iter 66000, loss: 0.028173
 >> iter 67000, loss: 0.021558
 >> iter 68000, loss: 0.027193
 >> iter 69000, loss: 0.021098
 >> iter 70000, loss: 0.022669
   Number of active neurons: 1
 >> iter 71000, loss: 0.018512
 >> iter 72000, loss: 0.019306
 >> iter 73000, loss: 0.030661
 >> iter 74000, loss: 0.029077
 >> iter 75000, loss: 0.020197
 >> iter 76000, loss: 0.021719
 >> iter 77000, loss: 0.019676
 >> iter 78000, loss: 0.037863
 >> iter 79000, loss: 0.029506
 >> iter 80000, loss: 0.022371
   Number of active neurons: 1
 >> iter 81000, loss: 0.019032
 >> iter 82000, loss: 0.021569
 >> iter 83000, loss: 0.018649
 >> iter 84000, loss: 0.016349
 >> iter 85000, loss: 0.017784
 >> iter 86000, loss: 0.016366
 >> iter 87000, loss: 0.017924
 >> iter 88000, loss: 0.027878
 >> iter 89000, loss: 0.023458
 >> iter 90000, loss: 0.019040
   Number of active neurons: 1
 >> iter 91000, loss: 0.022868
 >> iter 92000, loss: 0.017749
 >> iter 93000, loss: 0.019060
 >> iter 94000, loss: 0.017621
 >> iter 95000, loss: 0.019209
 >> iter 96000, loss: 0.019466
 >> iter 97000, loss: 0.032349
 >> iter 98000, loss: 0.022804
 >> iter 99000, loss: 0.025036
 >> iter 100000, loss: 0.031380
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.003306
 >> iter 2000, loss: 4.116820
 >> iter 3000, loss: 1.550837
 >> iter 4000, loss: 0.596695
 >> iter 5000, loss: 0.247987
 >> iter 6000, loss: 0.113706
 >> iter 7000, loss: 0.068202
 >> iter 8000, loss: 0.047866
 >> iter 9000, loss: 0.045623
 >> iter 10000, loss: 0.043669
   Number of active neurons: 6
 >> iter 11000, loss: 0.036010
 >> iter 12000, loss: 0.030137
 >> iter 13000, loss: 0.032866
 >> iter 14000, loss: 0.052382
 >> iter 15000, loss: 0.041497
 >> iter 16000, loss: 0.033857
 >> iter 17000, loss: 0.036471
 >> iter 18000, loss: 0.029673
 >> iter 19000, loss: 0.029227
 >> iter 20000, loss: 0.029295
   Number of active neurons: 5
 >> iter 21000, loss: 0.035381
 >> iter 22000, loss: 0.030503
 >> iter 23000, loss: 0.035239
 >> iter 24000, loss: 0.034529
 >> iter 25000, loss: 0.052117
 >> iter 26000, loss: 0.042069
 >> iter 27000, loss: 0.037285
 >> iter 28000, loss: 0.029594
 >> iter 29000, loss: 0.028439
 >> iter 30000, loss: 0.026365
   Number of active neurons: 4
 >> iter 31000, loss: 0.026748
 >> iter 32000, loss: 0.035017
 >> iter 33000, loss: 0.028736
 >> iter 34000, loss: 0.025579
 >> iter 35000, loss: 0.028890
 >> iter 36000, loss: 0.027178
 >> iter 37000, loss: 0.040141
 >> iter 38000, loss: 0.038640
 >> iter 39000, loss: 0.030408
 >> iter 40000, loss: 0.035615
   Number of active neurons: 2
 >> iter 41000, loss: 0.029324
 >> iter 42000, loss: 0.033415
 >> iter 43000, loss: 0.026393
 >> iter 44000, loss: 0.034116
 >> iter 45000, loss: 0.025001
 >> iter 46000, loss: 0.022700
 >> iter 47000, loss: 0.020677
 >> iter 48000, loss: 0.021929
 >> iter 49000, loss: 0.023877
 >> iter 50000, loss: 0.021831
   Number of active neurons: 2
 >> iter 51000, loss: 0.024897
 >> iter 52000, loss: 0.030033
 >> iter 53000, loss: 0.023585
 >> iter 54000, loss: 0.024862
 >> iter 55000, loss: 0.025592
 >> iter 56000, loss: 0.026381
 >> iter 57000, loss: 0.021558
 >> iter 58000, loss: 0.030063
 >> iter 59000, loss: 0.025167
 >> iter 60000, loss: 0.022254
   Number of active neurons: 1
 >> iter 61000, loss: 0.022699
 >> iter 62000, loss: 0.047919
 >> iter 63000, loss: 0.029552
 >> iter 64000, loss: 0.048555
 >> iter 65000, loss: 0.028390
 >> iter 66000, loss: 0.022419
 >> iter 67000, loss: 0.020172
 >> iter 68000, loss: 0.021631
 >> iter 69000, loss: 0.018168
 >> iter 70000, loss: 0.031239
   Number of active neurons: 1
 >> iter 71000, loss: 0.023163
 >> iter 72000, loss: 0.020308
 >> iter 73000, loss: 0.017774
 >> iter 74000, loss: 0.030201
 >> iter 75000, loss: 0.024114
 >> iter 76000, loss: 0.037628
 >> iter 77000, loss: 0.025085
 >> iter 78000, loss: 0.020348
 >> iter 79000, loss: 0.019065
 >> iter 80000, loss: 0.018390
   Number of active neurons: 1
 >> iter 81000, loss: 0.018899
 >> iter 82000, loss: 0.017646
 >> iter 83000, loss: 0.016451
 >> iter 84000, loss: 0.015696
 >> iter 85000, loss: 0.016060
 >> iter 86000, loss: 0.018608
 >> iter 87000, loss: 0.017731
 >> iter 88000, loss: 0.034281
 >> iter 89000, loss: 0.029773
 >> iter 90000, loss: 0.021571
   Number of active neurons: 1
 >> iter 91000, loss: 0.019622
 >> iter 92000, loss: 0.021056
 >> iter 93000, loss: 0.022495
 >> iter 94000, loss: 0.043501
 >> iter 95000, loss: 0.030415
 >> iter 96000, loss: 0.028164
 >> iter 97000, loss: 0.021449
 >> iter 98000, loss: 0.023422
 >> iter 99000, loss: 0.026467
 >> iter 100000, loss: 0.021429
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.926116
 >> iter 2000, loss: 4.090796
 >> iter 3000, loss: 1.546444
 >> iter 4000, loss: 0.606615
 >> iter 5000, loss: 0.245766
 >> iter 6000, loss: 0.111338
 >> iter 7000, loss: 0.063244
 >> iter 8000, loss: 0.041743
 >> iter 9000, loss: 0.039192
 >> iter 10000, loss: 0.036706
   Number of active neurons: 4
 >> iter 11000, loss: 0.037673
 >> iter 12000, loss: 0.030521
 >> iter 13000, loss: 0.028890
 >> iter 14000, loss: 0.027350
 >> iter 15000, loss: 0.024886
 >> iter 16000, loss: 0.027631
 >> iter 17000, loss: 0.032593
 >> iter 18000, loss: 0.028349
 >> iter 19000, loss: 0.038676
 >> iter 20000, loss: 0.031955
   Number of active neurons: 3
 >> iter 21000, loss: 0.026597
 >> iter 22000, loss: 0.024495
 >> iter 23000, loss: 0.023681
 >> iter 24000, loss: 0.033558
 >> iter 25000, loss: 0.028756
 >> iter 26000, loss: 0.035263
 >> iter 27000, loss: 0.028955
 >> iter 28000, loss: 0.025052
 >> iter 29000, loss: 0.035564
 >> iter 30000, loss: 0.027900
   Number of active neurons: 3
 >> iter 31000, loss: 0.024856
 >> iter 32000, loss: 0.027930
 >> iter 33000, loss: 0.028079
 >> iter 34000, loss: 0.043165
 >> iter 35000, loss: 0.032486
 >> iter 36000, loss: 0.026921
 >> iter 37000, loss: 0.031403
 >> iter 38000, loss: 0.026696
 >> iter 39000, loss: 0.027375
 >> iter 40000, loss: 0.027014
   Number of active neurons: 3
 >> iter 41000, loss: 0.025871
 >> iter 42000, loss: 0.026088
 >> iter 43000, loss: 0.026895
 >> iter 44000, loss: 0.023438
 >> iter 45000, loss: 0.022673
 >> iter 46000, loss: 0.028747
 >> iter 47000, loss: 0.024922
 >> iter 48000, loss: 0.027222
 >> iter 49000, loss: 0.025482
 >> iter 50000, loss: 0.023089
   Number of active neurons: 3
 >> iter 51000, loss: 0.022631
 >> iter 52000, loss: 0.031898
 >> iter 53000, loss: 0.031613
 >> iter 54000, loss: 0.026407
 >> iter 55000, loss: 0.036778
 >> iter 56000, loss: 0.030444
 >> iter 57000, loss: 0.024105
 >> iter 58000, loss: 0.024107
 >> iter 59000, loss: 0.025017
 >> iter 60000, loss: 0.023799
   Number of active neurons: 3
 >> iter 61000, loss: 0.031204
 >> iter 62000, loss: 0.028047
 >> iter 63000, loss: 0.029115
 >> iter 64000, loss: 0.030367
 >> iter 65000, loss: 0.031132
 >> iter 66000, loss: 0.024982
 >> iter 67000, loss: 0.022635
 >> iter 68000, loss: 0.024637
 >> iter 69000, loss: 0.041227
 >> iter 70000, loss: 0.035050
   Number of active neurons: 3
 >> iter 71000, loss: 0.028701
 >> iter 72000, loss: 0.027529
 >> iter 73000, loss: 0.024939
 >> iter 74000, loss: 0.026573
 >> iter 75000, loss: 0.027186
 >> iter 76000, loss: 0.022801
 >> iter 77000, loss: 0.022816
 >> iter 78000, loss: 0.032323
 >> iter 79000, loss: 0.025651
 >> iter 80000, loss: 0.030672
   Number of active neurons: 3
 >> iter 81000, loss: 0.028442
 >> iter 82000, loss: 0.031042
 >> iter 83000, loss: 0.026607
 >> iter 84000, loss: 0.023329
 >> iter 85000, loss: 0.026156
 >> iter 86000, loss: 0.027767
 >> iter 87000, loss: 0.024001
 >> iter 88000, loss: 0.021929
 >> iter 89000, loss: 0.035489
 >> iter 90000, loss: 0.027710
   Number of active neurons: 2
 >> iter 91000, loss: 0.026659
 >> iter 92000, loss: 0.027281
 >> iter 93000, loss: 0.024667
 >> iter 94000, loss: 0.035644
 >> iter 95000, loss: 0.025086
 >> iter 96000, loss: 0.022292
 >> iter 97000, loss: 0.024778
 >> iter 98000, loss: 0.022185
 >> iter 99000, loss: 0.021476
 >> iter 100000, loss: 0.070555
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.930989
 >> iter 2000, loss: 4.070787
 >> iter 3000, loss: 1.562068
 >> iter 4000, loss: 0.607628
 >> iter 5000, loss: 0.255895
 >> iter 6000, loss: 0.120676
 >> iter 7000, loss: 0.074463
 >> iter 8000, loss: 0.050540
 >> iter 9000, loss: 0.040418
 >> iter 10000, loss: 0.036744
   Number of active neurons: 6
 >> iter 11000, loss: 0.040495
 >> iter 12000, loss: 0.034608
 >> iter 13000, loss: 0.033849
 >> iter 14000, loss: 0.031205
 >> iter 15000, loss: 0.035542
 >> iter 16000, loss: 0.029691
 >> iter 17000, loss: 0.029737
 >> iter 18000, loss: 0.027383
 >> iter 19000, loss: 0.024882
 >> iter 20000, loss: 0.042375
   Number of active neurons: 2
 >> iter 21000, loss: 0.034369
 >> iter 22000, loss: 0.029041
 >> iter 23000, loss: 0.031400
 >> iter 24000, loss: 0.027321
 >> iter 25000, loss: 0.024115
 >> iter 26000, loss: 0.022449
 >> iter 27000, loss: 0.023096
 >> iter 28000, loss: 0.028812
 >> iter 29000, loss: 0.024054
 >> iter 30000, loss: 0.023780
   Number of active neurons: 1
 >> iter 31000, loss: 0.034350
 >> iter 32000, loss: 0.024399
 >> iter 33000, loss: 0.021741
 >> iter 34000, loss: 0.025822
 >> iter 35000, loss: 0.022491
 >> iter 36000, loss: 0.049787
 >> iter 37000, loss: 0.028802
 >> iter 38000, loss: 0.021694
 >> iter 39000, loss: 0.021546
 >> iter 40000, loss: 0.023648
   Number of active neurons: 1
 >> iter 41000, loss: 0.020077
 >> iter 42000, loss: 0.020908
 >> iter 43000, loss: 0.022529
 >> iter 44000, loss: 0.017692
 >> iter 45000, loss: 0.017602
 >> iter 46000, loss: 0.017352
 >> iter 47000, loss: 0.019581
 >> iter 48000, loss: 0.019617
 >> iter 49000, loss: 0.018021
 >> iter 50000, loss: 0.018854
   Number of active neurons: 1
 >> iter 51000, loss: 0.019884
 >> iter 52000, loss: 0.026299
 >> iter 53000, loss: 0.033833
 >> iter 54000, loss: 0.042975
 >> iter 55000, loss: 0.025862
 >> iter 56000, loss: 0.021403
 >> iter 57000, loss: 0.025545
 >> iter 58000, loss: 0.022469
 >> iter 59000, loss: 0.035217
 >> iter 60000, loss: 0.026192
   Number of active neurons: 1
 >> iter 61000, loss: 0.020868
 >> iter 62000, loss: 0.024515
 >> iter 63000, loss: 0.032807
 >> iter 64000, loss: 0.022262
 >> iter 65000, loss: 0.021221
 >> iter 66000, loss: 0.025808
 >> iter 67000, loss: 0.022803
 >> iter 68000, loss: 0.027120
 >> iter 69000, loss: 0.029328
 >> iter 70000, loss: 0.021076
   Number of active neurons: 1
 >> iter 71000, loss: 0.020128
 >> iter 72000, loss: 0.019629
 >> iter 73000, loss: 0.017648
 >> iter 74000, loss: 0.028012
 >> iter 75000, loss: 0.021242
 >> iter 76000, loss: 0.023356
 >> iter 77000, loss: 0.018674
 >> iter 78000, loss: 0.034625
 >> iter 79000, loss: 0.024300
 >> iter 80000, loss: 0.019022
   Number of active neurons: 1
 >> iter 81000, loss: 0.019852
 >> iter 82000, loss: 0.022495
 >> iter 83000, loss: 0.020002
 >> iter 84000, loss: 0.025297
 >> iter 85000, loss: 0.020071
 >> iter 86000, loss: 0.017357
 >> iter 87000, loss: 0.023769
 >> iter 88000, loss: 0.021731
 >> iter 89000, loss: 0.021193
 >> iter 90000, loss: 0.020213
   Number of active neurons: 1
 >> iter 91000, loss: 0.017832
 >> iter 92000, loss: 0.020340
 >> iter 93000, loss: 0.039077
 >> iter 94000, loss: 0.025684
 >> iter 95000, loss: 0.034593
 >> iter 96000, loss: 0.024291
 >> iter 97000, loss: 0.022834
 >> iter 98000, loss: 0.021804
 >> iter 99000, loss: 0.038883
 >> iter 100000, loss: 0.026650
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 10.969499
 >> iter 2000, loss: 4.085211
 >> iter 3000, loss: 1.532307
 >> iter 4000, loss: 0.599672
 >> iter 5000, loss: 0.244697
 >> iter 6000, loss: 0.114093
 >> iter 7000, loss: 0.069547
 >> iter 8000, loss: 0.066829
 >> iter 9000, loss: 0.044214
 >> iter 10000, loss: 0.037859
   Number of active neurons: 4
 >> iter 11000, loss: 0.029659
 >> iter 12000, loss: 0.036919
 >> iter 13000, loss: 0.029692
 >> iter 14000, loss: 0.027895
 >> iter 15000, loss: 0.033500
 >> iter 16000, loss: 0.027268
 >> iter 17000, loss: 0.024372
 >> iter 18000, loss: 0.029140
 >> iter 19000, loss: 0.025119
 >> iter 20000, loss: 0.029237
   Number of active neurons: 3
 >> iter 21000, loss: 0.025793
 >> iter 22000, loss: 0.023607
 >> iter 23000, loss: 0.025086
 >> iter 24000, loss: 0.023652
 >> iter 25000, loss: 0.024351
 >> iter 26000, loss: 0.029115
 >> iter 27000, loss: 0.032775
 >> iter 28000, loss: 0.027896
 >> iter 29000, loss: 0.028527
 >> iter 30000, loss: 0.024475
   Number of active neurons: 3
 >> iter 31000, loss: 0.023229
 >> iter 32000, loss: 0.036924
 >> iter 33000, loss: 0.031694
 >> iter 34000, loss: 0.034708
 >> iter 35000, loss: 0.033141
 >> iter 36000, loss: 0.025948
 >> iter 37000, loss: 0.041507
 >> iter 38000, loss: 0.035701
 >> iter 39000, loss: 0.032816
 >> iter 40000, loss: 0.028118
   Number of active neurons: 3
 >> iter 41000, loss: 0.027102
 >> iter 42000, loss: 0.023485
 >> iter 43000, loss: 0.025343
 >> iter 44000, loss: 0.026913
 >> iter 45000, loss: 0.026219
 >> iter 46000, loss: 0.023309
 >> iter 47000, loss: 0.023910
 >> iter 48000, loss: 0.024062
 >> iter 49000, loss: 0.026804
 >> iter 50000, loss: 0.022629
   Number of active neurons: 2
 >> iter 51000, loss: 0.036669
 >> iter 52000, loss: 0.040746
 >> iter 53000, loss: 0.035244
 >> iter 54000, loss: 0.036964
 >> iter 55000, loss: 0.027721
 >> iter 56000, loss: 0.025515
 >> iter 57000, loss: 0.030418
 >> iter 58000, loss: 0.033098
 >> iter 59000, loss: 0.031303
 >> iter 60000, loss: 0.024864
   Number of active neurons: 2
 >> iter 61000, loss: 0.021978
 >> iter 62000, loss: 0.024054
 >> iter 63000, loss: 0.021068
 >> iter 64000, loss: 0.026499
 >> iter 65000, loss: 0.022213
 >> iter 66000, loss: 0.034627
 >> iter 67000, loss: 0.027456
 >> iter 68000, loss: 0.026477
 >> iter 69000, loss: 0.025224
 >> iter 70000, loss: 0.023148
   Number of active neurons: 2
 >> iter 71000, loss: 0.026107
 >> iter 72000, loss: 0.023018
 >> iter 73000, loss: 0.027535
 >> iter 74000, loss: 0.024444
 >> iter 75000, loss: 0.020726
 >> iter 76000, loss: 0.026435
 >> iter 77000, loss: 0.031801
 >> iter 78000, loss: 0.043908
 >> iter 79000, loss: 0.035898
 >> iter 80000, loss: 0.028176
   Number of active neurons: 2
 >> iter 81000, loss: 0.032373
 >> iter 82000, loss: 0.026306
 >> iter 83000, loss: 0.025864
 >> iter 84000, loss: 0.022390
 >> iter 85000, loss: 0.029159
 >> iter 86000, loss: 0.024415
 >> iter 87000, loss: 0.024297
 >> iter 88000, loss: 0.022122
 >> iter 89000, loss: 0.022124
 >> iter 90000, loss: 0.020340
   Number of active neurons: 2
 >> iter 91000, loss: 0.019644
 >> iter 92000, loss: 0.025671
 >> iter 93000, loss: 0.022693
 >> iter 94000, loss: 0.020656
 >> iter 95000, loss: 0.022627
 >> iter 96000, loss: 0.021702
 >> iter 97000, loss: 0.025734
 >> iter 98000, loss: 0.020496
 >> iter 99000, loss: 0.019288
 >> iter 100000, loss: 0.028705
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

