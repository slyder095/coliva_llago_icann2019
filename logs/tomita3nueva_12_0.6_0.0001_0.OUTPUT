 > Problema: tomita3nueva
 > Args:
   - Hidden size: 12
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.149586
 >> iter 2000, loss: 11.183118
 >> iter 3000, loss: 5.199932
 >> iter 4000, loss: 2.376644
 >> iter 5000, loss: 1.199485
 >> iter 6000, loss: 0.684250
 >> iter 7000, loss: 0.564623
 >> iter 8000, loss: 0.367711
 >> iter 9000, loss: 0.306644
 >> iter 10000, loss: 0.373637
   Number of active neurons: 8
 >> iter 11000, loss: 0.428065
 >> iter 12000, loss: 0.288399
 >> iter 13000, loss: 0.409867
 >> iter 14000, loss: 0.393455
 >> iter 15000, loss: 0.285696
 >> iter 16000, loss: 0.376825
 >> iter 17000, loss: 0.288524
 >> iter 18000, loss: 0.348365
 >> iter 19000, loss: 0.370301
 >> iter 20000, loss: 0.293045
   Number of active neurons: 8
 >> iter 21000, loss: 0.226458
 >> iter 22000, loss: 0.234612
 >> iter 23000, loss: 0.508863
 >> iter 24000, loss: 0.296212
 >> iter 25000, loss: 0.300266
 >> iter 26000, loss: 0.211755
 >> iter 27000, loss: 0.382797
 >> iter 28000, loss: 0.269115
 >> iter 29000, loss: 0.297371
 >> iter 30000, loss: 0.283672
   Number of active neurons: 8
 >> iter 31000, loss: 0.316538
 >> iter 32000, loss: 0.307405
 >> iter 33000, loss: 0.238921
 >> iter 34000, loss: 0.186520
 >> iter 35000, loss: 0.267793
 >> iter 36000, loss: 0.173566
 >> iter 37000, loss: 0.278833
 >> iter 38000, loss: 0.176040
 >> iter 39000, loss: 0.176011
 >> iter 40000, loss: 0.187920
   Number of active neurons: 7
 >> iter 41000, loss: 0.417060
 >> iter 42000, loss: 0.260411
 >> iter 43000, loss: 0.329908
 >> iter 44000, loss: 0.253895
 >> iter 45000, loss: 0.272278
 >> iter 46000, loss: 0.319869
 >> iter 47000, loss: 0.250887
 >> iter 48000, loss: 0.259767
 >> iter 49000, loss: 0.216872
 >> iter 50000, loss: 0.247297
   Number of active neurons: 6
 >> iter 51000, loss: 0.200210
 >> iter 52000, loss: 0.149234
 >> iter 53000, loss: 0.212780
 >> iter 54000, loss: 0.190648
 >> iter 55000, loss: 0.185954
 >> iter 56000, loss: 0.187120
 >> iter 57000, loss: 0.286345
 >> iter 58000, loss: 0.230207
 >> iter 59000, loss: 0.215166
 >> iter 60000, loss: 0.207746
   Number of active neurons: 6
 >> iter 61000, loss: 0.386573
 >> iter 62000, loss: 0.278408
 >> iter 63000, loss: 0.186802
 >> iter 64000, loss: 0.197638
 >> iter 65000, loss: 0.180518
 >> iter 66000, loss: 0.117526
 >> iter 67000, loss: 0.253379
 >> iter 68000, loss: 0.198268
 >> iter 69000, loss: 0.161982
 >> iter 70000, loss: 0.243067
   Number of active neurons: 5
 >> iter 71000, loss: 0.264947
 >> iter 72000, loss: 0.271529
 >> iter 73000, loss: 0.246258
 >> iter 74000, loss: 0.197126
 >> iter 75000, loss: 0.430587
 >> iter 76000, loss: 0.316049
 >> iter 77000, loss: 0.487663
 >> iter 78000, loss: 0.279590
 >> iter 79000, loss: 0.256495
 >> iter 80000, loss: 0.216013
   Number of active neurons: 4
 >> iter 81000, loss: 0.161365
 >> iter 82000, loss: 0.206661
 >> iter 83000, loss: 0.258929
 >> iter 84000, loss: 0.284133
 >> iter 85000, loss: 0.243851
 >> iter 86000, loss: 0.192120
 >> iter 87000, loss: 0.432062
 >> iter 88000, loss: 0.235033
 >> iter 89000, loss: 0.237205
 >> iter 90000, loss: 0.231640
   Number of active neurons: 4
 >> iter 91000, loss: 0.256585
 >> iter 92000, loss: 0.275781
 >> iter 93000, loss: 0.219709
 >> iter 94000, loss: 0.214615
 >> iter 95000, loss: 0.332708
 >> iter 96000, loss: 0.270827
 >> iter 97000, loss: 0.187126
 >> iter 98000, loss: 0.208329
 >> iter 99000, loss: 0.231269
 >> iter 100000, loss: 0.223777
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.984365
 >> iter 2000, loss: 10.349033
 >> iter 3000, loss: 4.702034
 >> iter 4000, loss: 2.297435
 >> iter 5000, loss: 1.178874
 >> iter 6000, loss: 0.853558
 >> iter 7000, loss: 0.619724
 >> iter 8000, loss: 0.579144
 >> iter 9000, loss: 0.608163
 >> iter 10000, loss: 0.387669
   Number of active neurons: 7
 >> iter 11000, loss: 0.298683
 >> iter 12000, loss: 0.267399
 >> iter 13000, loss: 0.433515
 >> iter 14000, loss: 0.400702
 >> iter 15000, loss: 0.304855
 >> iter 16000, loss: 0.265624
 >> iter 17000, loss: 0.324455
 >> iter 18000, loss: 0.315547
 >> iter 19000, loss: 0.255756
 >> iter 20000, loss: 0.313776
   Number of active neurons: 7
 >> iter 21000, loss: 0.354008
 >> iter 22000, loss: 0.504474
 >> iter 23000, loss: 0.403979
 >> iter 24000, loss: 0.405062
 >> iter 25000, loss: 0.351675
 >> iter 26000, loss: 0.276532
 >> iter 27000, loss: 0.377211
 >> iter 28000, loss: 0.323054
 >> iter 29000, loss: 0.437965
 >> iter 30000, loss: 0.345841
   Number of active neurons: 7
 >> iter 31000, loss: 0.358705
 >> iter 32000, loss: 0.288502
 >> iter 33000, loss: 0.259659
 >> iter 34000, loss: 0.299575
 >> iter 35000, loss: 0.439127
 >> iter 36000, loss: 0.364786
 >> iter 37000, loss: 0.557543
 >> iter 38000, loss: 0.349167
 >> iter 39000, loss: 0.316231
 >> iter 40000, loss: 0.386828
   Number of active neurons: 7
 >> iter 41000, loss: 0.399111
 >> iter 42000, loss: 0.312010
 >> iter 43000, loss: 0.333058
 >> iter 44000, loss: 0.418117
 >> iter 45000, loss: 0.453811
 >> iter 46000, loss: 0.343985
 >> iter 47000, loss: 0.316980
 >> iter 48000, loss: 0.382925
 >> iter 49000, loss: 0.418283
 >> iter 50000, loss: 0.344962
   Number of active neurons: 7
 >> iter 51000, loss: 0.402850
 >> iter 52000, loss: 0.341756
 >> iter 53000, loss: 0.370849
 >> iter 54000, loss: 0.277229
 >> iter 55000, loss: 0.366249
 >> iter 56000, loss: 0.498723
 >> iter 57000, loss: 0.422005
 >> iter 58000, loss: 0.262521
 >> iter 59000, loss: 0.414413
 >> iter 60000, loss: 0.264578
   Number of active neurons: 5
 >> iter 61000, loss: 0.362840
 >> iter 62000, loss: 0.403408
 >> iter 63000, loss: 0.382793
 >> iter 64000, loss: 0.437455
 >> iter 65000, loss: 0.409034
 >> iter 66000, loss: 0.290112
 >> iter 67000, loss: 0.575566
 >> iter 68000, loss: 0.374174
 >> iter 69000, loss: 0.360964
 >> iter 70000, loss: 0.320908
   Number of active neurons: 5
 >> iter 71000, loss: 0.279815
 >> iter 72000, loss: 0.318061
 >> iter 73000, loss: 0.270245
 >> iter 74000, loss: 0.239545
 >> iter 75000, loss: 0.293258
 >> iter 76000, loss: 0.277097
 >> iter 77000, loss: 0.286198
 >> iter 78000, loss: 0.469784
 >> iter 79000, loss: 0.390995
 >> iter 80000, loss: 0.320275
   Number of active neurons: 5
 >> iter 81000, loss: 0.312271
 >> iter 82000, loss: 0.452998
 >> iter 83000, loss: 0.300572
 >> iter 84000, loss: 0.268760
 >> iter 85000, loss: 0.429871
 >> iter 86000, loss: 0.254233
 >> iter 87000, loss: 0.284426
 >> iter 88000, loss: 0.284740
 >> iter 89000, loss: 0.211121
 >> iter 90000, loss: 0.299204
   Number of active neurons: 5
 >> iter 91000, loss: 0.380909
 >> iter 92000, loss: 0.350948
 >> iter 93000, loss: 0.369033
 >> iter 94000, loss: 0.268983
 >> iter 95000, loss: 0.403839
 >> iter 96000, loss: 0.308190
 >> iter 97000, loss: 0.210196
 >> iter 98000, loss: 0.235322
 >> iter 99000, loss: 0.500044
 >> iter 100000, loss: 0.313382
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.138468
 >> iter 2000, loss: 13.648698
 >> iter 3000, loss: 7.634914
 >> iter 4000, loss: 3.719248
 >> iter 5000, loss: 2.022859
 >> iter 6000, loss: 1.160737
 >> iter 7000, loss: 0.803780
 >> iter 8000, loss: 0.546699
 >> iter 9000, loss: 0.474154
 >> iter 10000, loss: 0.377461
   Number of active neurons: 5
 >> iter 11000, loss: 0.243978
 >> iter 12000, loss: 0.367000
 >> iter 13000, loss: 0.402590
 >> iter 14000, loss: 0.441328
 >> iter 15000, loss: 0.444315
 >> iter 16000, loss: 0.428340
 >> iter 17000, loss: 0.539725
 >> iter 18000, loss: 0.467320
 >> iter 19000, loss: 0.530700
 >> iter 20000, loss: 0.376525
   Number of active neurons: 5
 >> iter 21000, loss: 0.233083
 >> iter 22000, loss: 0.243478
 >> iter 23000, loss: 0.257284
 >> iter 24000, loss: 0.223225
 >> iter 25000, loss: 0.209990
 >> iter 26000, loss: 0.302538
 >> iter 27000, loss: 0.256986
 >> iter 28000, loss: 0.274159
 >> iter 29000, loss: 0.418410
 >> iter 30000, loss: 0.304392
   Number of active neurons: 5
 >> iter 31000, loss: 0.384811
 >> iter 32000, loss: 0.328750
 >> iter 33000, loss: 0.416672
 >> iter 34000, loss: 0.411436
 >> iter 35000, loss: 0.328770
 >> iter 36000, loss: 0.371654
 >> iter 37000, loss: 0.327652
 >> iter 38000, loss: 0.299381
 >> iter 39000, loss: 0.285882
 >> iter 40000, loss: 0.352152
   Number of active neurons: 4
 >> iter 41000, loss: 0.228317
 >> iter 42000, loss: 0.235497
 >> iter 43000, loss: 0.305069
 >> iter 44000, loss: 0.279510
 >> iter 45000, loss: 0.178454
 >> iter 46000, loss: 0.242747
 >> iter 47000, loss: 0.227756
 >> iter 48000, loss: 0.179246
 >> iter 49000, loss: 0.369089
 >> iter 50000, loss: 0.296989
   Number of active neurons: 4
 >> iter 51000, loss: 0.253859
 >> iter 52000, loss: 0.191185
 >> iter 53000, loss: 0.260079
 >> iter 54000, loss: 0.343711
 >> iter 55000, loss: 0.279805
 >> iter 56000, loss: 0.393386
 >> iter 57000, loss: 0.223473
 >> iter 58000, loss: 0.277936
 >> iter 59000, loss: 0.266763
 >> iter 60000, loss: 0.373428
   Number of active neurons: 4
 >> iter 61000, loss: 0.405856
 >> iter 62000, loss: 0.299792
 >> iter 63000, loss: 0.217193
 >> iter 64000, loss: 0.330444
 >> iter 65000, loss: 0.232039
 >> iter 66000, loss: 0.261522
 >> iter 67000, loss: 0.387567
 >> iter 68000, loss: 0.339483
 >> iter 69000, loss: 0.403550
 >> iter 70000, loss: 0.323739
   Number of active neurons: 4
 >> iter 71000, loss: 0.361339
 >> iter 72000, loss: 0.287624
 >> iter 73000, loss: 0.380980
 >> iter 74000, loss: 0.323454
 >> iter 75000, loss: 0.275991
 >> iter 76000, loss: 0.298691
 >> iter 77000, loss: 0.185515
 >> iter 78000, loss: 0.215486
 >> iter 79000, loss: 0.258912
 >> iter 80000, loss: 0.314856
   Number of active neurons: 4
 >> iter 81000, loss: 0.299118
 >> iter 82000, loss: 0.338371
 >> iter 83000, loss: 0.380968
 >> iter 84000, loss: 0.357115
 >> iter 85000, loss: 0.310815
 >> iter 86000, loss: 0.318006
 >> iter 87000, loss: 0.315663
 >> iter 88000, loss: 0.246579
 >> iter 89000, loss: 0.326163
 >> iter 90000, loss: 0.416546
   Number of active neurons: 4
 >> iter 91000, loss: 0.304798
 >> iter 92000, loss: 0.282370
 >> iter 93000, loss: 0.321553
 >> iter 94000, loss: 0.320970
 >> iter 95000, loss: 0.271927
 >> iter 96000, loss: 0.261791
 >> iter 97000, loss: 0.257542
 >> iter 98000, loss: 0.258486
 >> iter 99000, loss: 0.213668
 >> iter 100000, loss: 0.167795
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.112495
 >> iter 2000, loss: 10.743956
 >> iter 3000, loss: 5.314460
 >> iter 4000, loss: 2.466389
 >> iter 5000, loss: 1.177713
 >> iter 6000, loss: 1.024455
 >> iter 7000, loss: 0.725769
 >> iter 8000, loss: 0.442810
 >> iter 9000, loss: 0.559622
 >> iter 10000, loss: 0.431565
   Number of active neurons: 7
 >> iter 11000, loss: 0.389084
 >> iter 12000, loss: 0.349749
 >> iter 13000, loss: 0.377137
 >> iter 14000, loss: 0.308774
 >> iter 15000, loss: 0.374588
 >> iter 16000, loss: 0.291216
 >> iter 17000, loss: 0.475050
 >> iter 18000, loss: 0.261022
 >> iter 19000, loss: 0.441298
 >> iter 20000, loss: 0.381369
   Number of active neurons: 7
 >> iter 21000, loss: 0.326666
 >> iter 22000, loss: 0.516572
 >> iter 23000, loss: 0.703142
 >> iter 24000, loss: 0.512822
 >> iter 25000, loss: 0.675948
 >> iter 26000, loss: 0.543347
 >> iter 27000, loss: 0.411919
 >> iter 28000, loss: 0.302444
 >> iter 29000, loss: 0.400767
 >> iter 30000, loss: 0.331541
   Number of active neurons: 6
 >> iter 31000, loss: 0.399346
 >> iter 32000, loss: 0.359129
 >> iter 33000, loss: 0.542768
 >> iter 34000, loss: 0.549302
 >> iter 35000, loss: 0.388763
 >> iter 36000, loss: 0.479208
 >> iter 37000, loss: 0.388722
 >> iter 38000, loss: 0.365498
 >> iter 39000, loss: 0.372748
 >> iter 40000, loss: 0.291887
   Number of active neurons: 6
 >> iter 41000, loss: 0.279476
 >> iter 42000, loss: 0.440077
 >> iter 43000, loss: 0.467635
 >> iter 44000, loss: 0.299684
 >> iter 45000, loss: 0.345373
 >> iter 46000, loss: 0.402083
 >> iter 47000, loss: 0.352013
 >> iter 48000, loss: 0.322982
 >> iter 49000, loss: 0.303961
 >> iter 50000, loss: 0.367155
   Number of active neurons: 5
 >> iter 51000, loss: 0.274983
 >> iter 52000, loss: 0.355207
 >> iter 53000, loss: 0.318066
 >> iter 54000, loss: 0.369064
 >> iter 55000, loss: 0.305936
 >> iter 56000, loss: 0.387328
 >> iter 57000, loss: 0.381169
 >> iter 58000, loss: 0.315275
 >> iter 59000, loss: 0.285158
 >> iter 60000, loss: 0.437473
   Number of active neurons: 5
 >> iter 61000, loss: 0.290468
 >> iter 62000, loss: 0.313945
 >> iter 63000, loss: 0.264025
 >> iter 64000, loss: 0.282106
 >> iter 65000, loss: 0.295819
 >> iter 66000, loss: 0.332878
 >> iter 67000, loss: 0.336810
 >> iter 68000, loss: 0.359915
 >> iter 69000, loss: 0.304960
 >> iter 70000, loss: 0.387341
   Number of active neurons: 5
 >> iter 71000, loss: 0.445720
 >> iter 72000, loss: 0.299418
 >> iter 73000, loss: 0.325203
 >> iter 74000, loss: 0.316049
 >> iter 75000, loss: 0.204226
 >> iter 76000, loss: 0.167060
 >> iter 77000, loss: 0.248924
 >> iter 78000, loss: 0.283043
 >> iter 79000, loss: 0.342722
 >> iter 80000, loss: 0.320739
   Number of active neurons: 5
 >> iter 81000, loss: 0.331643
 >> iter 82000, loss: 0.415288
 >> iter 83000, loss: 0.353824
 >> iter 84000, loss: 0.302415
 >> iter 85000, loss: 0.195533
 >> iter 86000, loss: 0.220871
 >> iter 87000, loss: 0.228864
 >> iter 88000, loss: 0.142564
 >> iter 89000, loss: 0.170749
 >> iter 90000, loss: 0.329851
   Number of active neurons: 5
 >> iter 91000, loss: 0.442905
 >> iter 92000, loss: 0.357900
 >> iter 93000, loss: 0.382340
 >> iter 94000, loss: 0.409744
 >> iter 95000, loss: 0.319602
 >> iter 96000, loss: 0.351979
 >> iter 97000, loss: 0.234662
 >> iter 98000, loss: 0.294206
 >> iter 99000, loss: 0.328350
 >> iter 100000, loss: 0.288695
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.788365
 >> iter 2000, loss: 10.776281
 >> iter 3000, loss: 4.598279
 >> iter 4000, loss: 2.156280
 >> iter 5000, loss: 1.065580
 >> iter 6000, loss: 0.651435
 >> iter 7000, loss: 0.347502
 >> iter 8000, loss: 0.220056
 >> iter 9000, loss: 0.252181
 >> iter 10000, loss: 0.291172
   Number of active neurons: 7
 >> iter 11000, loss: 0.649572
 >> iter 12000, loss: 0.471144
 >> iter 13000, loss: 0.362652
 >> iter 14000, loss: 0.257006
 >> iter 15000, loss: 0.200282
 >> iter 16000, loss: 0.294435
 >> iter 17000, loss: 0.186679
 >> iter 18000, loss: 0.209094
 >> iter 19000, loss: 0.347031
 >> iter 20000, loss: 0.399925
   Number of active neurons: 7
 >> iter 21000, loss: 0.295013
 >> iter 22000, loss: 0.335421
 >> iter 23000, loss: 0.224729
 >> iter 24000, loss: 0.251534
 >> iter 25000, loss: 0.204464
 >> iter 26000, loss: 0.350156
 >> iter 27000, loss: 0.289231
 >> iter 28000, loss: 0.182295
 >> iter 29000, loss: 0.327813
 >> iter 30000, loss: 0.406673
   Number of active neurons: 7
 >> iter 31000, loss: 0.287930
 >> iter 32000, loss: 0.218926
 >> iter 33000, loss: 0.319203
 >> iter 34000, loss: 0.205327
 >> iter 35000, loss: 0.381143
 >> iter 36000, loss: 0.439118
 >> iter 37000, loss: 0.387186
 >> iter 38000, loss: 0.254350
 >> iter 39000, loss: 0.295614
 >> iter 40000, loss: 0.226487
   Number of active neurons: 7
 >> iter 41000, loss: 0.280712
 >> iter 42000, loss: 0.317730
 >> iter 43000, loss: 0.362089
 >> iter 44000, loss: 0.269432
 >> iter 45000, loss: 0.276584
 >> iter 46000, loss: 0.236523
 >> iter 47000, loss: 0.263140
 >> iter 48000, loss: 0.308200
 >> iter 49000, loss: 0.284669
 >> iter 50000, loss: 0.384853
   Number of active neurons: 7
 >> iter 51000, loss: 0.302416
 >> iter 52000, loss: 0.205787
 >> iter 53000, loss: 0.384444
 >> iter 54000, loss: 0.273788
 >> iter 55000, loss: 0.259552
 >> iter 56000, loss: 0.401037
 >> iter 57000, loss: 0.268373
 >> iter 58000, loss: 0.182769
 >> iter 59000, loss: 0.271976
 >> iter 60000, loss: 0.309894
   Number of active neurons: 7
 >> iter 61000, loss: 0.359974
 >> iter 62000, loss: 0.365309
 >> iter 63000, loss: 0.318856
 >> iter 64000, loss: 0.226644
 >> iter 65000, loss: 0.271078
 >> iter 66000, loss: 0.236281
 >> iter 67000, loss: 0.308764
 >> iter 68000, loss: 0.265640
 >> iter 69000, loss: 0.302768
 >> iter 70000, loss: 0.258645
   Number of active neurons: 7
 >> iter 71000, loss: 0.178478
 >> iter 72000, loss: 0.305961
 >> iter 73000, loss: 0.416107
 >> iter 74000, loss: 0.289046
 >> iter 75000, loss: 0.327914
 >> iter 76000, loss: 0.481380
 >> iter 77000, loss: 0.243640
 >> iter 78000, loss: 0.268110
 >> iter 79000, loss: 0.320324
 >> iter 80000, loss: 0.298140
   Number of active neurons: 7
 >> iter 81000, loss: 0.216959
 >> iter 82000, loss: 0.354301
 >> iter 83000, loss: 0.343423
 >> iter 84000, loss: 0.275894
 >> iter 85000, loss: 0.323963
 >> iter 86000, loss: 0.270677
 >> iter 87000, loss: 0.344017
 >> iter 88000, loss: 0.347806
 >> iter 89000, loss: 0.486504
 >> iter 90000, loss: 0.296599
   Number of active neurons: 7
 >> iter 91000, loss: 0.350085
 >> iter 92000, loss: 0.198914
 >> iter 93000, loss: 0.232045
 >> iter 94000, loss: 0.210209
 >> iter 95000, loss: 0.478178
 >> iter 96000, loss: 0.458808
 >> iter 97000, loss: 0.239474
 >> iter 98000, loss: 0.365442
 >> iter 99000, loss: 0.356373
 >> iter 100000, loss: 0.271796
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.152315
 >> iter 2000, loss: 11.504145
 >> iter 3000, loss: 5.582008
 >> iter 4000, loss: 2.408743
 >> iter 5000, loss: 1.251936
 >> iter 6000, loss: 0.858180
 >> iter 7000, loss: 0.500959
 >> iter 8000, loss: 0.585642
 >> iter 9000, loss: 0.515051
 >> iter 10000, loss: 0.407603
   Number of active neurons: 5
 >> iter 11000, loss: 0.427841
 >> iter 12000, loss: 0.343522
 >> iter 13000, loss: 0.424567
 >> iter 14000, loss: 0.272236
 >> iter 15000, loss: 0.307577
 >> iter 16000, loss: 0.271674
 >> iter 17000, loss: 0.223100
 >> iter 18000, loss: 0.231433
 >> iter 19000, loss: 0.246672
 >> iter 20000, loss: 0.322659
   Number of active neurons: 5
 >> iter 21000, loss: 0.240542
 >> iter 22000, loss: 0.356807
 >> iter 23000, loss: 0.505445
 >> iter 24000, loss: 0.312004
 >> iter 25000, loss: 0.298431
 >> iter 26000, loss: 0.258326
 >> iter 27000, loss: 0.258894
 >> iter 28000, loss: 0.206105
 >> iter 29000, loss: 0.302733
 >> iter 30000, loss: 0.325437
   Number of active neurons: 5
 >> iter 31000, loss: 0.462105
 >> iter 32000, loss: 0.261536
 >> iter 33000, loss: 0.165320
 >> iter 34000, loss: 0.183702
 >> iter 35000, loss: 0.311802
 >> iter 36000, loss: 0.156619
 >> iter 37000, loss: 0.169117
 >> iter 38000, loss: 0.139228
 >> iter 39000, loss: 0.200399
 >> iter 40000, loss: 0.177838
   Number of active neurons: 5
 >> iter 41000, loss: 0.240293
 >> iter 42000, loss: 0.255944
 >> iter 43000, loss: 0.201712
 >> iter 44000, loss: 0.212363
 >> iter 45000, loss: 0.279502
 >> iter 46000, loss: 0.282857
 >> iter 47000, loss: 0.246754
 >> iter 48000, loss: 0.311002
 >> iter 49000, loss: 0.227473
 >> iter 50000, loss: 0.257215
   Number of active neurons: 5
 >> iter 51000, loss: 0.239640
 >> iter 52000, loss: 0.274391
 >> iter 53000, loss: 0.206562
 >> iter 54000, loss: 0.218514
 >> iter 55000, loss: 0.161284
 >> iter 56000, loss: 0.254601
 >> iter 57000, loss: 0.434509
 >> iter 58000, loss: 0.273856
 >> iter 59000, loss: 0.193110
 >> iter 60000, loss: 0.118032
   Number of active neurons: 5
 >> iter 61000, loss: 0.190035
 >> iter 62000, loss: 0.253357
 >> iter 63000, loss: 0.227847
 >> iter 64000, loss: 0.282898
 >> iter 65000, loss: 0.205187
 >> iter 66000, loss: 0.136779
 >> iter 67000, loss: 0.272143
 >> iter 68000, loss: 0.186979
 >> iter 69000, loss: 0.214530
 >> iter 70000, loss: 0.207648
   Number of active neurons: 5
 >> iter 71000, loss: 0.211454
 >> iter 72000, loss: 0.268868
 >> iter 73000, loss: 0.180864
 >> iter 74000, loss: 0.205742
 >> iter 75000, loss: 0.140846
 >> iter 76000, loss: 0.252192
 >> iter 77000, loss: 0.236303
 >> iter 78000, loss: 0.293345
 >> iter 79000, loss: 0.418784
 >> iter 80000, loss: 0.248765
   Number of active neurons: 5
 >> iter 81000, loss: 0.244807
 >> iter 82000, loss: 0.181027
 >> iter 83000, loss: 0.213393
 >> iter 84000, loss: 0.190507
 >> iter 85000, loss: 0.225639
 >> iter 86000, loss: 0.244490
 >> iter 87000, loss: 0.352780
 >> iter 88000, loss: 0.277838
 >> iter 89000, loss: 0.223591
 >> iter 90000, loss: 0.297691
   Number of active neurons: 4
 >> iter 91000, loss: 0.246015
 >> iter 92000, loss: 0.202571
 >> iter 93000, loss: 0.202819
 >> iter 94000, loss: 0.282747
 >> iter 95000, loss: 0.228590
 >> iter 96000, loss: 0.198501
 >> iter 97000, loss: 0.176802
 >> iter 98000, loss: 0.192749
 >> iter 99000, loss: 0.253127
 >> iter 100000, loss: 0.286191
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.818688
 >> iter 2000, loss: 10.716018
 >> iter 3000, loss: 5.745769
 >> iter 4000, loss: 2.591060
 >> iter 5000, loss: 1.317396
 >> iter 6000, loss: 0.787993
 >> iter 7000, loss: 0.565542
 >> iter 8000, loss: 0.387612
 >> iter 9000, loss: 0.350353
 >> iter 10000, loss: 0.341141
   Number of active neurons: 8
 >> iter 11000, loss: 0.316538
 >> iter 12000, loss: 0.257672
 >> iter 13000, loss: 0.265271
 >> iter 14000, loss: 0.291984
 >> iter 15000, loss: 0.256531
 >> iter 16000, loss: 0.189089
 >> iter 17000, loss: 0.207888
 >> iter 18000, loss: 0.325409
 >> iter 19000, loss: 0.274611
 >> iter 20000, loss: 0.445719
   Number of active neurons: 8
 >> iter 21000, loss: 0.314749
 >> iter 22000, loss: 0.241038
 >> iter 23000, loss: 0.199949
 >> iter 24000, loss: 0.429561
 >> iter 25000, loss: 0.274758
 >> iter 26000, loss: 0.279696
 >> iter 27000, loss: 0.382877
 >> iter 28000, loss: 0.218823
 >> iter 29000, loss: 0.207018
 >> iter 30000, loss: 0.210938
   Number of active neurons: 7
 >> iter 31000, loss: 0.258971
 >> iter 32000, loss: 0.244720
 >> iter 33000, loss: 0.352896
 >> iter 34000, loss: 0.258239
 >> iter 35000, loss: 0.313962
 >> iter 36000, loss: 0.283783
 >> iter 37000, loss: 0.440080
 >> iter 38000, loss: 0.281279
 >> iter 39000, loss: 0.211023
 >> iter 40000, loss: 0.191048
   Number of active neurons: 6
 >> iter 41000, loss: 0.285922
 >> iter 42000, loss: 0.357946
 >> iter 43000, loss: 0.196215
 >> iter 44000, loss: 0.122852
 >> iter 45000, loss: 0.267906
 >> iter 46000, loss: 0.210931
 >> iter 47000, loss: 0.159714
 >> iter 48000, loss: 0.248685
 >> iter 49000, loss: 0.395297
 >> iter 50000, loss: 0.342108
   Number of active neurons: 5
 >> iter 51000, loss: 0.423982
 >> iter 52000, loss: 0.344957
 >> iter 53000, loss: 0.237208
 >> iter 54000, loss: 0.283768
 >> iter 55000, loss: 0.290191
 >> iter 56000, loss: 0.244802
 >> iter 57000, loss: 0.293010
 >> iter 58000, loss: 0.231005
 >> iter 59000, loss: 0.329437
 >> iter 60000, loss: 0.329931
   Number of active neurons: 5
 >> iter 61000, loss: 0.293847
 >> iter 62000, loss: 0.329859
 >> iter 63000, loss: 0.211554
 >> iter 64000, loss: 0.193236
 >> iter 65000, loss: 0.224712
 >> iter 66000, loss: 0.254296
 >> iter 67000, loss: 0.223348
 >> iter 68000, loss: 0.302134
 >> iter 69000, loss: 0.235741
 >> iter 70000, loss: 0.207106
   Number of active neurons: 5
 >> iter 71000, loss: 0.221722
 >> iter 72000, loss: 0.201614
 >> iter 73000, loss: 0.433652
 >> iter 74000, loss: 0.343160
 >> iter 75000, loss: 0.249753
 >> iter 76000, loss: 0.251587
 >> iter 77000, loss: 0.309430
 >> iter 78000, loss: 0.207262
 >> iter 79000, loss: 0.223085
 >> iter 80000, loss: 0.237118
   Number of active neurons: 5
 >> iter 81000, loss: 0.347635
 >> iter 82000, loss: 0.383834
 >> iter 83000, loss: 0.322823
 >> iter 84000, loss: 0.334662
 >> iter 85000, loss: 0.209490
 >> iter 86000, loss: 0.271828
 >> iter 87000, loss: 0.247369
 >> iter 88000, loss: 0.251008
 >> iter 89000, loss: 0.324261
 >> iter 90000, loss: 0.255199
   Number of active neurons: 5
 >> iter 91000, loss: 0.212974
 >> iter 92000, loss: 0.235951
 >> iter 93000, loss: 0.280371
 >> iter 94000, loss: 0.257671
 >> iter 95000, loss: 0.280968
 >> iter 96000, loss: 0.379922
 >> iter 97000, loss: 0.295499
 >> iter 98000, loss: 0.236619
 >> iter 99000, loss: 0.147301
 >> iter 100000, loss: 0.222610
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.050227
 >> iter 2000, loss: 10.418083
 >> iter 3000, loss: 4.597519
 >> iter 4000, loss: 2.031633
 >> iter 5000, loss: 0.924151
 >> iter 6000, loss: 0.525323
 >> iter 7000, loss: 0.318035
 >> iter 8000, loss: 0.339933
 >> iter 9000, loss: 0.325951
 >> iter 10000, loss: 0.211159
   Number of active neurons: 7
 >> iter 11000, loss: 0.272863
 >> iter 12000, loss: 0.242026
 >> iter 13000, loss: 0.209339
 >> iter 14000, loss: 0.144682
 >> iter 15000, loss: 0.266573
 >> iter 16000, loss: 0.403344
 >> iter 17000, loss: 0.253907
 >> iter 18000, loss: 0.512711
 >> iter 19000, loss: 0.532409
 >> iter 20000, loss: 0.316137
   Number of active neurons: 6
 >> iter 21000, loss: 0.452043
 >> iter 22000, loss: 0.329980
 >> iter 23000, loss: 0.269649
 >> iter 24000, loss: 0.227809
 >> iter 25000, loss: 0.367143
 >> iter 26000, loss: 0.349664
 >> iter 27000, loss: 0.336745
 >> iter 28000, loss: 0.192529
 >> iter 29000, loss: 0.257111
 >> iter 30000, loss: 0.274274
   Number of active neurons: 6
 >> iter 31000, loss: 0.236889
 >> iter 32000, loss: 0.135329
 >> iter 33000, loss: 0.325842
 >> iter 34000, loss: 0.218706
 >> iter 35000, loss: 0.294151
 >> iter 36000, loss: 0.300508
 >> iter 37000, loss: 0.422855
 >> iter 38000, loss: 0.287648
 >> iter 39000, loss: 0.219795
 >> iter 40000, loss: 0.313167
   Number of active neurons: 6
 >> iter 41000, loss: 0.291253
 >> iter 42000, loss: 0.208151
 >> iter 43000, loss: 0.214116
 >> iter 44000, loss: 0.238964
 >> iter 45000, loss: 0.253140
 >> iter 46000, loss: 0.259420
 >> iter 47000, loss: 0.162515
 >> iter 48000, loss: 0.233717
 >> iter 49000, loss: 0.208529
 >> iter 50000, loss: 0.208155
   Number of active neurons: 6
 >> iter 51000, loss: 0.195321
 >> iter 52000, loss: 0.194436
 >> iter 53000, loss: 0.170550
 >> iter 54000, loss: 0.233336
 >> iter 55000, loss: 0.225034
 >> iter 56000, loss: 0.191769
 >> iter 57000, loss: 0.166840
 >> iter 58000, loss: 0.128415
 >> iter 59000, loss: 0.262909
 >> iter 60000, loss: 0.163844
   Number of active neurons: 6
 >> iter 61000, loss: 0.171789
 >> iter 62000, loss: 0.206666
 >> iter 63000, loss: 0.317840
 >> iter 64000, loss: 0.305075
 >> iter 65000, loss: 0.248773
 >> iter 66000, loss: 0.285389
 >> iter 67000, loss: 0.213853
 >> iter 68000, loss: 0.216563
 >> iter 69000, loss: 0.189076
 >> iter 70000, loss: 0.123032
   Number of active neurons: 6
 >> iter 71000, loss: 0.201958
 >> iter 72000, loss: 0.152865
 >> iter 73000, loss: 0.208136
 >> iter 74000, loss: 0.173066
 >> iter 75000, loss: 0.286337
 >> iter 76000, loss: 0.226609
 >> iter 77000, loss: 0.171173
 >> iter 78000, loss: 0.165948
 >> iter 79000, loss: 0.098873
 >> iter 80000, loss: 0.111825
   Number of active neurons: 5
 >> iter 81000, loss: 0.168166
 >> iter 82000, loss: 0.187120
 >> iter 83000, loss: 0.173098
 >> iter 84000, loss: 0.430860
 >> iter 85000, loss: 0.258878
 >> iter 86000, loss: 0.182541
 >> iter 87000, loss: 0.165775
 >> iter 88000, loss: 0.118848
 >> iter 89000, loss: 0.227359
 >> iter 90000, loss: 0.156751
   Number of active neurons: 5
 >> iter 91000, loss: 0.146574
 >> iter 92000, loss: 0.231428
 >> iter 93000, loss: 0.297266
 >> iter 94000, loss: 0.216063
 >> iter 95000, loss: 0.202170
 >> iter 96000, loss: 0.214661
 >> iter 97000, loss: 0.225372
 >> iter 98000, loss: 0.127062
 >> iter 99000, loss: 0.191348
 >> iter 100000, loss: 0.167879
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.188971
 >> iter 2000, loss: 11.433427
 >> iter 3000, loss: 5.134779
 >> iter 4000, loss: 2.300424
 >> iter 5000, loss: 1.268552
 >> iter 6000, loss: 0.844623
 >> iter 7000, loss: 0.597434
 >> iter 8000, loss: 0.531602
 >> iter 9000, loss: 0.588497
 >> iter 10000, loss: 0.472613
   Number of active neurons: 8
 >> iter 11000, loss: 0.329153
 >> iter 12000, loss: 0.325369
 >> iter 13000, loss: 0.421629
 >> iter 14000, loss: 0.416991
 >> iter 15000, loss: 0.436768
 >> iter 16000, loss: 0.365052
 >> iter 17000, loss: 0.420784
 >> iter 18000, loss: 0.294436
 >> iter 19000, loss: 0.566264
 >> iter 20000, loss: 0.405069
   Number of active neurons: 8
 >> iter 21000, loss: 0.389877
 >> iter 22000, loss: 0.481138
 >> iter 23000, loss: 0.449829
 >> iter 24000, loss: 0.312196
 >> iter 25000, loss: 0.268111
 >> iter 26000, loss: 0.259981
 >> iter 27000, loss: 0.413387
 >> iter 28000, loss: 0.454044
 >> iter 29000, loss: 0.366885
 >> iter 30000, loss: 0.235556
   Number of active neurons: 8
 >> iter 31000, loss: 0.280121
 >> iter 32000, loss: 0.292815
 >> iter 33000, loss: 0.402833
 >> iter 34000, loss: 0.254825
 >> iter 35000, loss: 0.284317
 >> iter 36000, loss: 0.308151
 >> iter 37000, loss: 0.227227
 >> iter 38000, loss: 0.216851
 >> iter 39000, loss: 0.238293
 >> iter 40000, loss: 0.333242
   Number of active neurons: 8
 >> iter 41000, loss: 0.353816
 >> iter 42000, loss: 0.329114
 >> iter 43000, loss: 0.316409
 >> iter 44000, loss: 0.311590
 >> iter 45000, loss: 0.430522
 >> iter 46000, loss: 0.307582
 >> iter 47000, loss: 0.306030
 >> iter 48000, loss: 0.258901
 >> iter 49000, loss: 0.206976
 >> iter 50000, loss: 0.327465
   Number of active neurons: 7
 >> iter 51000, loss: 0.426583
 >> iter 52000, loss: 0.417440
 >> iter 53000, loss: 0.262109
 >> iter 54000, loss: 0.253198
 >> iter 55000, loss: 0.356063
 >> iter 56000, loss: 0.305177
 >> iter 57000, loss: 0.464862
 >> iter 58000, loss: 0.494165
 >> iter 59000, loss: 0.339023
 >> iter 60000, loss: 0.380285
   Number of active neurons: 6
 >> iter 61000, loss: 0.285798
 >> iter 62000, loss: 0.395964
 >> iter 63000, loss: 0.410901
 >> iter 64000, loss: 0.366495
 >> iter 65000, loss: 0.434701
 >> iter 66000, loss: 0.352370
 >> iter 67000, loss: 0.411290
 >> iter 68000, loss: 0.516195
 >> iter 69000, loss: 0.361022
 >> iter 70000, loss: 0.273322
   Number of active neurons: 6
 >> iter 71000, loss: 0.203354
 >> iter 72000, loss: 0.210693
 >> iter 73000, loss: 0.354089
 >> iter 74000, loss: 0.405024
 >> iter 75000, loss: 0.497056
 >> iter 76000, loss: 0.421999
 >> iter 77000, loss: 0.308329
 >> iter 78000, loss: 0.398421
 >> iter 79000, loss: 0.300231
 >> iter 80000, loss: 0.273763
   Number of active neurons: 6
 >> iter 81000, loss: 0.294914
 >> iter 82000, loss: 0.389656
 >> iter 83000, loss: 0.390051
 >> iter 84000, loss: 0.330580
 >> iter 85000, loss: 0.249212
 >> iter 86000, loss: 0.331053
 >> iter 87000, loss: 0.414520
 >> iter 88000, loss: 0.491749
 >> iter 89000, loss: 0.374905
 >> iter 90000, loss: 0.298934
   Number of active neurons: 6
 >> iter 91000, loss: 0.409266
 >> iter 92000, loss: 0.389656
 >> iter 93000, loss: 0.319612
 >> iter 94000, loss: 0.527895
 >> iter 95000, loss: 0.357632
 >> iter 96000, loss: 0.344234
 >> iter 97000, loss: 0.299374
 >> iter 98000, loss: 0.341587
 >> iter 99000, loss: 0.379851
 >> iter 100000, loss: 0.413975
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.286544
 >> iter 2000, loss: 14.182248
 >> iter 3000, loss: 8.347745
 >> iter 4000, loss: 4.276318
 >> iter 5000, loss: 2.129300
 >> iter 6000, loss: 1.392899
 >> iter 7000, loss: 0.834407
 >> iter 8000, loss: 0.575755
 >> iter 9000, loss: 0.458507
 >> iter 10000, loss: 0.539614
   Number of active neurons: 5
 >> iter 11000, loss: 0.501884
 >> iter 12000, loss: 0.442903
 >> iter 13000, loss: 0.411912
 >> iter 14000, loss: 0.242437
 >> iter 15000, loss: 0.407796
 >> iter 16000, loss: 0.319776
 >> iter 17000, loss: 0.483769
 >> iter 18000, loss: 0.431920
 >> iter 19000, loss: 0.381539
 >> iter 20000, loss: 0.468497
   Number of active neurons: 6
 >> iter 21000, loss: 0.398249
 >> iter 22000, loss: 0.506813
 >> iter 23000, loss: 0.371225
 >> iter 24000, loss: 0.358970
 >> iter 25000, loss: 0.545169
 >> iter 26000, loss: 0.385349
 >> iter 27000, loss: 0.312741
 >> iter 28000, loss: 0.418294
 >> iter 29000, loss: 0.410352
 >> iter 30000, loss: 0.231982
   Number of active neurons: 5
 >> iter 31000, loss: 0.320316
 >> iter 32000, loss: 0.240050
 >> iter 33000, loss: 0.214756
 >> iter 34000, loss: 0.210202
 >> iter 35000, loss: 0.317852
 >> iter 36000, loss: 0.265567
 >> iter 37000, loss: 0.246474
 >> iter 38000, loss: 0.329510
 >> iter 39000, loss: 0.387470
 >> iter 40000, loss: 0.348242
   Number of active neurons: 5
 >> iter 41000, loss: 0.414351
 >> iter 42000, loss: 0.291188
 >> iter 43000, loss: 0.373377
 >> iter 44000, loss: 0.287128
 >> iter 45000, loss: 0.407051
 >> iter 46000, loss: 0.422828
 >> iter 47000, loss: 0.297778
 >> iter 48000, loss: 0.389747
 >> iter 49000, loss: 0.468924
 >> iter 50000, loss: 0.308986
   Number of active neurons: 5
 >> iter 51000, loss: 0.231566
 >> iter 52000, loss: 0.337863
 >> iter 53000, loss: 0.410974
 >> iter 54000, loss: 0.371780
 >> iter 55000, loss: 0.341103
 >> iter 56000, loss: 0.301938
 >> iter 57000, loss: 0.229930
 >> iter 58000, loss: 0.129550
 >> iter 59000, loss: 0.237982
 >> iter 60000, loss: 0.329905
   Number of active neurons: 5
 >> iter 61000, loss: 0.216769
 >> iter 62000, loss: 0.261726
 >> iter 63000, loss: 0.252016
 >> iter 64000, loss: 0.348941
 >> iter 65000, loss: 0.327361
 >> iter 66000, loss: 0.254131
 >> iter 67000, loss: 0.246689
 >> iter 68000, loss: 0.177622
 >> iter 69000, loss: 0.309956
 >> iter 70000, loss: 0.254697
   Number of active neurons: 5
 >> iter 71000, loss: 0.245661
 >> iter 72000, loss: 0.291187
 >> iter 73000, loss: 0.208547
 >> iter 74000, loss: 0.298268
 >> iter 75000, loss: 0.202953
 >> iter 76000, loss: 0.139887
 >> iter 77000, loss: 0.201826
 >> iter 78000, loss: 0.193749
 >> iter 79000, loss: 0.324807
 >> iter 80000, loss: 0.184181
   Number of active neurons: 5
 >> iter 81000, loss: 0.128509
 >> iter 82000, loss: 0.146932
 >> iter 83000, loss: 0.350723
 >> iter 84000, loss: 0.313486
 >> iter 85000, loss: 0.199576
 >> iter 86000, loss: 0.171964
 >> iter 87000, loss: 0.250112
 >> iter 88000, loss: 0.199421
 >> iter 89000, loss: 0.231332
 >> iter 90000, loss: 0.169541
   Number of active neurons: 4
 >> iter 91000, loss: 0.219995
 >> iter 92000, loss: 0.145530
 >> iter 93000, loss: 0.209812
 >> iter 94000, loss: 0.173536
 >> iter 95000, loss: 0.202064
 >> iter 96000, loss: 0.237885
 >> iter 97000, loss: 0.289759
 >> iter 98000, loss: 0.145652
 >> iter 99000, loss: 0.310588
 >> iter 100000, loss: 0.235901
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.158996
 >> iter 2000, loss: 11.285075
 >> iter 3000, loss: 4.896380
 >> iter 4000, loss: 2.124858
 >> iter 5000, loss: 1.091008
 >> iter 6000, loss: 0.707477
 >> iter 7000, loss: 0.527307
 >> iter 8000, loss: 0.481034
 >> iter 9000, loss: 0.416198
 >> iter 10000, loss: 0.358595
   Number of active neurons: 7
 >> iter 11000, loss: 0.357905
 >> iter 12000, loss: 0.309756
 >> iter 13000, loss: 0.317338
 >> iter 14000, loss: 0.305787
 >> iter 15000, loss: 0.318675
 >> iter 16000, loss: 0.236376
 >> iter 17000, loss: 0.347699
 >> iter 18000, loss: 0.278039
 >> iter 19000, loss: 0.232022
 >> iter 20000, loss: 0.409418
   Number of active neurons: 7
 >> iter 21000, loss: 0.379395
 >> iter 22000, loss: 0.374527
 >> iter 23000, loss: 0.331813
 >> iter 24000, loss: 0.367005
 >> iter 25000, loss: 0.285644
 >> iter 26000, loss: 0.339699
 >> iter 27000, loss: 0.388640
 >> iter 28000, loss: 0.268867
 >> iter 29000, loss: 0.259064
 >> iter 30000, loss: 0.166754
   Number of active neurons: 7
 >> iter 31000, loss: 0.377867
 >> iter 32000, loss: 0.330007
 >> iter 33000, loss: 0.212399
 >> iter 34000, loss: 0.182626
 >> iter 35000, loss: 0.240226
 >> iter 36000, loss: 0.203823
 >> iter 37000, loss: 0.281436
 >> iter 38000, loss: 0.309347
 >> iter 39000, loss: 0.225431
 >> iter 40000, loss: 0.325224
   Number of active neurons: 7
 >> iter 41000, loss: 0.334741
 >> iter 42000, loss: 0.227112
 >> iter 43000, loss: 0.169135
 >> iter 44000, loss: 0.164845
 >> iter 45000, loss: 0.182450
 >> iter 46000, loss: 0.265181
 >> iter 47000, loss: 0.224789
 >> iter 48000, loss: 0.197533
 >> iter 49000, loss: 0.249404
 >> iter 50000, loss: 0.251712
   Number of active neurons: 7
 >> iter 51000, loss: 0.328772
 >> iter 52000, loss: 0.207518
 >> iter 53000, loss: 0.234780
 >> iter 54000, loss: 0.173390
 >> iter 55000, loss: 0.180810
 >> iter 56000, loss: 0.199880
 >> iter 57000, loss: 0.180204
 >> iter 58000, loss: 0.216704
 >> iter 59000, loss: 0.181492
 >> iter 60000, loss: 0.245780
   Number of active neurons: 6
 >> iter 61000, loss: 0.184180
 >> iter 62000, loss: 0.157330
 >> iter 63000, loss: 0.328230
 >> iter 64000, loss: 0.221302
 >> iter 65000, loss: 0.195227
 >> iter 66000, loss: 0.134727
 >> iter 67000, loss: 0.114780
 >> iter 68000, loss: 0.328466
 >> iter 69000, loss: 0.314294
 >> iter 70000, loss: 0.227321
   Number of active neurons: 6
 >> iter 71000, loss: 0.197832
 >> iter 72000, loss: 0.144114
 >> iter 73000, loss: 0.151060
 >> iter 74000, loss: 0.191474
 >> iter 75000, loss: 0.161454
 >> iter 76000, loss: 0.122276
 >> iter 77000, loss: 0.124511
 >> iter 78000, loss: 0.104299
 >> iter 79000, loss: 0.104150
 >> iter 80000, loss: 0.127269
   Number of active neurons: 5
 >> iter 81000, loss: 0.250991
 >> iter 82000, loss: 0.143051
 >> iter 83000, loss: 0.143941
 >> iter 84000, loss: 0.111330
 >> iter 85000, loss: 0.074198
 >> iter 86000, loss: 0.210477
 >> iter 87000, loss: 0.170867
 >> iter 88000, loss: 0.168247
 >> iter 89000, loss: 0.316228
 >> iter 90000, loss: 0.166316
   Number of active neurons: 5
 >> iter 91000, loss: 0.166053
 >> iter 92000, loss: 0.234853
 >> iter 93000, loss: 0.162398
 >> iter 94000, loss: 0.201933
 >> iter 95000, loss: 0.276629
 >> iter 96000, loss: 0.179661
 >> iter 97000, loss: 0.158481
 >> iter 98000, loss: 0.180330
 >> iter 99000, loss: 0.203512
 >> iter 100000, loss: 0.187296
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.110621
 >> iter 2000, loss: 13.328876
 >> iter 3000, loss: 9.978807
 >> iter 4000, loss: 6.449193
 >> iter 5000, loss: 4.443343
 >> iter 6000, loss: 2.614307
 >> iter 7000, loss: 1.605076
 >> iter 8000, loss: 1.243874
 >> iter 9000, loss: 1.198285
 >> iter 10000, loss: 1.208940
   Number of active neurons: 8
 >> iter 11000, loss: 1.017375
 >> iter 12000, loss: 0.876052
 >> iter 13000, loss: 0.922982
 >> iter 14000, loss: 1.242083
 >> iter 15000, loss: 0.884515
 >> iter 16000, loss: 0.891500
 >> iter 17000, loss: 0.531137
 >> iter 18000, loss: 0.554843
 >> iter 19000, loss: 0.530049
 >> iter 20000, loss: 0.812187
   Number of active neurons: 7
 >> iter 21000, loss: 0.773960
 >> iter 22000, loss: 0.681932
 >> iter 23000, loss: 0.721475
 >> iter 24000, loss: 0.646860
 >> iter 25000, loss: 0.988446
 >> iter 26000, loss: 0.901200
 >> iter 27000, loss: 0.780951
 >> iter 28000, loss: 0.514839
 >> iter 29000, loss: 0.758093
 >> iter 30000, loss: 0.768177
   Number of active neurons: 6
 >> iter 31000, loss: 0.683930
 >> iter 32000, loss: 1.130763
 >> iter 33000, loss: 0.899284
 >> iter 34000, loss: 0.827488
 >> iter 35000, loss: 0.601684
 >> iter 36000, loss: 0.710008
 >> iter 37000, loss: 0.515437
 >> iter 38000, loss: 0.498038
 >> iter 39000, loss: 0.717403
 >> iter 40000, loss: 0.913298
   Number of active neurons: 6
 >> iter 41000, loss: 0.542085
 >> iter 42000, loss: 0.618307
 >> iter 43000, loss: 0.563240
 >> iter 44000, loss: 0.539819
 >> iter 45000, loss: 0.517122
 >> iter 46000, loss: 0.591881
 >> iter 47000, loss: 0.609099
 >> iter 48000, loss: 0.939703
 >> iter 49000, loss: 1.015674
 >> iter 50000, loss: 0.810443
   Number of active neurons: 7
 >> iter 51000, loss: 0.741477
 >> iter 52000, loss: 0.527472
 >> iter 53000, loss: 0.361978
 >> iter 54000, loss: 0.479113
 >> iter 55000, loss: 0.450099
 >> iter 56000, loss: 0.659902
 >> iter 57000, loss: 0.785613
 >> iter 58000, loss: 0.615652
 >> iter 59000, loss: 0.890824
 >> iter 60000, loss: 0.703944
   Number of active neurons: 6
 >> iter 61000, loss: 1.013792
 >> iter 62000, loss: 0.608654
 >> iter 63000, loss: 0.783460
 >> iter 64000, loss: 0.569701
 >> iter 65000, loss: 0.690138
 >> iter 66000, loss: 0.604036
 >> iter 67000, loss: 0.783955
 >> iter 68000, loss: 0.870277
 >> iter 69000, loss: 0.836676
 >> iter 70000, loss: 0.687154
   Number of active neurons: 6
 >> iter 71000, loss: 0.665193
 >> iter 72000, loss: 0.822893
 >> iter 73000, loss: 0.751067
 >> iter 74000, loss: 0.679397
 >> iter 75000, loss: 0.667729
 >> iter 76000, loss: 0.597200
 >> iter 77000, loss: 0.600147
 >> iter 78000, loss: 0.524799
 >> iter 79000, loss: 0.735713
 >> iter 80000, loss: 0.751366
   Number of active neurons: 6
 >> iter 81000, loss: 0.678408
 >> iter 82000, loss: 0.686375
 >> iter 83000, loss: 0.770085
 >> iter 84000, loss: 0.654712
 >> iter 85000, loss: 0.631215
 >> iter 86000, loss: 0.466008
 >> iter 87000, loss: 0.576898
 >> iter 88000, loss: 0.508563
 >> iter 89000, loss: 0.580122
 >> iter 90000, loss: 0.555161
   Number of active neurons: 6
 >> iter 91000, loss: 0.656530
 >> iter 92000, loss: 0.710405
 >> iter 93000, loss: 0.723317
 >> iter 94000, loss: 0.662334
 >> iter 95000, loss: 0.655754
 >> iter 96000, loss: 0.588978
 >> iter 97000, loss: 0.557387
 >> iter 98000, loss: 0.529498
 >> iter 99000, loss: 0.667158
 >> iter 100000, loss: 0.480314
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 19.334191
 >> iter 2000, loss: 10.803394
 >> iter 3000, loss: 4.672038
 >> iter 4000, loss: 2.017049
 >> iter 5000, loss: 1.007726
 >> iter 6000, loss: 0.827005
 >> iter 7000, loss: 0.617723
 >> iter 8000, loss: 0.334661
 >> iter 9000, loss: 0.520082
 >> iter 10000, loss: 0.424903
   Number of active neurons: 8
 >> iter 11000, loss: 0.404865
 >> iter 12000, loss: 0.302758
 >> iter 13000, loss: 0.586882
 >> iter 14000, loss: 0.560850
 >> iter 15000, loss: 0.418353
 >> iter 16000, loss: 0.342965
 >> iter 17000, loss: 0.368592
 >> iter 18000, loss: 0.359832
 >> iter 19000, loss: 0.407461
 >> iter 20000, loss: 0.273398
   Number of active neurons: 8
 >> iter 21000, loss: 0.285804
 >> iter 22000, loss: 0.219210
 >> iter 23000, loss: 0.414795
 >> iter 24000, loss: 0.285823
 >> iter 25000, loss: 0.242641
 >> iter 26000, loss: 0.401894
 >> iter 27000, loss: 0.376278
 >> iter 28000, loss: 0.244835
 >> iter 29000, loss: 0.426657
 >> iter 30000, loss: 0.420691
   Number of active neurons: 8
 >> iter 31000, loss: 0.455066
 >> iter 32000, loss: 0.487134
 >> iter 33000, loss: 0.332442
 >> iter 34000, loss: 0.334989
 >> iter 35000, loss: 0.408100
 >> iter 36000, loss: 0.286492
 >> iter 37000, loss: 0.342459
 >> iter 38000, loss: 0.283612
 >> iter 39000, loss: 0.259545
 >> iter 40000, loss: 0.190146
   Number of active neurons: 8
 >> iter 41000, loss: 0.172030
 >> iter 42000, loss: 0.168574
 >> iter 43000, loss: 0.153818
 >> iter 44000, loss: 0.159619
 >> iter 45000, loss: 0.198056
 >> iter 46000, loss: 0.164771
 >> iter 47000, loss: 0.400292
 >> iter 48000, loss: 0.289140
 >> iter 49000, loss: 0.620844
 >> iter 50000, loss: 0.351696
   Number of active neurons: 8
 >> iter 51000, loss: 0.299389
 >> iter 52000, loss: 0.266117
 >> iter 53000, loss: 0.204378
 >> iter 54000, loss: 0.191113
 >> iter 55000, loss: 0.173244
 >> iter 56000, loss: 0.338471
 >> iter 57000, loss: 0.240191
 >> iter 58000, loss: 0.164600
 >> iter 59000, loss: 0.137196
 >> iter 60000, loss: 0.225764
   Number of active neurons: 8
 >> iter 61000, loss: 0.225166
 >> iter 62000, loss: 0.198217
 >> iter 63000, loss: 0.131019
 >> iter 64000, loss: 0.234466
 >> iter 65000, loss: 0.225952
 >> iter 66000, loss: 0.229480
 >> iter 67000, loss: 0.273890
 >> iter 68000, loss: 0.248177
 >> iter 69000, loss: 0.236240
 >> iter 70000, loss: 0.218189
   Number of active neurons: 8
 >> iter 71000, loss: 0.183604
 >> iter 72000, loss: 0.255842
 >> iter 73000, loss: 0.201016
 >> iter 74000, loss: 0.178563
 >> iter 75000, loss: 0.201716
 >> iter 76000, loss: 0.213566
 >> iter 77000, loss: 0.342755
 >> iter 78000, loss: 0.431427
 >> iter 79000, loss: 0.308977
 >> iter 80000, loss: 0.239472
   Number of active neurons: 8
 >> iter 81000, loss: 0.303748
 >> iter 82000, loss: 0.311535
 >> iter 83000, loss: 0.205197
 >> iter 84000, loss: 0.259769
 >> iter 85000, loss: 0.199104
 >> iter 86000, loss: 0.160567
 >> iter 87000, loss: 0.169888
 >> iter 88000, loss: 0.229756
 >> iter 89000, loss: 0.251585
 >> iter 90000, loss: 0.160981
   Number of active neurons: 8
 >> iter 91000, loss: 0.231085
 >> iter 92000, loss: 0.316726
 >> iter 93000, loss: 0.267137
 >> iter 94000, loss: 0.359333
 >> iter 95000, loss: 0.197357
 >> iter 96000, loss: 0.268975
 >> iter 97000, loss: 0.236847
 >> iter 98000, loss: 0.206636
 >> iter 99000, loss: 0.162317
 >> iter 100000, loss: 0.190942
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.071050
 >> iter 2000, loss: 11.077590
 >> iter 3000, loss: 5.022882
 >> iter 4000, loss: 2.363858
 >> iter 5000, loss: 1.212124
 >> iter 6000, loss: 0.759300
 >> iter 7000, loss: 0.774187
 >> iter 8000, loss: 0.658467
 >> iter 9000, loss: 0.614870
 >> iter 10000, loss: 0.402315
   Number of active neurons: 6
 >> iter 11000, loss: 0.346190
 >> iter 12000, loss: 0.312996
 >> iter 13000, loss: 0.348463
 >> iter 14000, loss: 0.346583
 >> iter 15000, loss: 0.239369
 >> iter 16000, loss: 0.315680
 >> iter 17000, loss: 0.330494
 >> iter 18000, loss: 0.231684
 >> iter 19000, loss: 0.340457
 >> iter 20000, loss: 0.409036
   Number of active neurons: 6
 >> iter 21000, loss: 0.218013
 >> iter 22000, loss: 0.376002
 >> iter 23000, loss: 0.269890
 >> iter 24000, loss: 0.331220
 >> iter 25000, loss: 0.244072
 >> iter 26000, loss: 0.295952
 >> iter 27000, loss: 0.217468
 >> iter 28000, loss: 0.182946
 >> iter 29000, loss: 0.281390
 >> iter 30000, loss: 0.240451
   Number of active neurons: 6
 >> iter 31000, loss: 0.266037
 >> iter 32000, loss: 0.304852
 >> iter 33000, loss: 0.228361
 >> iter 34000, loss: 0.311860
 >> iter 35000, loss: 0.227293
 >> iter 36000, loss: 0.212469
 >> iter 37000, loss: 0.177865
 >> iter 38000, loss: 0.221767
 >> iter 39000, loss: 0.350967
 >> iter 40000, loss: 0.410449
   Number of active neurons: 6
 >> iter 41000, loss: 0.323961
 >> iter 42000, loss: 0.305575
 >> iter 43000, loss: 0.221727
 >> iter 44000, loss: 0.368946
 >> iter 45000, loss: 0.326301
 >> iter 46000, loss: 0.401986
 >> iter 47000, loss: 0.400975
 >> iter 48000, loss: 0.477082
 >> iter 49000, loss: 0.552274
 >> iter 50000, loss: 0.354567
   Number of active neurons: 6
 >> iter 51000, loss: 0.230692
 >> iter 52000, loss: 0.560280
 >> iter 53000, loss: 0.347681
 >> iter 54000, loss: 0.277967
 >> iter 55000, loss: 0.275448
 >> iter 56000, loss: 0.263668
 >> iter 57000, loss: 0.322059
 >> iter 58000, loss: 0.432258
 >> iter 59000, loss: 0.415058
 >> iter 60000, loss: 0.398223
   Number of active neurons: 6
 >> iter 61000, loss: 0.407757
 >> iter 62000, loss: 0.392889
 >> iter 63000, loss: 0.337061
 >> iter 64000, loss: 0.305788
 >> iter 65000, loss: 0.280013
 >> iter 66000, loss: 0.267505
 >> iter 67000, loss: 0.310356
 >> iter 68000, loss: 0.348531
 >> iter 69000, loss: 0.363596
 >> iter 70000, loss: 0.307798
   Number of active neurons: 6
 >> iter 71000, loss: 0.376702
 >> iter 72000, loss: 0.255863
 >> iter 73000, loss: 0.350236
 >> iter 74000, loss: 0.226338
 >> iter 75000, loss: 0.283161
 >> iter 76000, loss: 0.285689
 >> iter 77000, loss: 0.362697
 >> iter 78000, loss: 0.366380
 >> iter 79000, loss: 0.378865
 >> iter 80000, loss: 0.368925
   Number of active neurons: 6
 >> iter 81000, loss: 0.225222
 >> iter 82000, loss: 0.403111
 >> iter 83000, loss: 0.535090
 >> iter 84000, loss: 0.423675
 >> iter 85000, loss: 0.262066
 >> iter 86000, loss: 0.341973
 >> iter 87000, loss: 0.362698
 >> iter 88000, loss: 0.313733
 >> iter 89000, loss: 0.253954
 >> iter 90000, loss: 0.267552
   Number of active neurons: 6
 >> iter 91000, loss: 0.268758
 >> iter 92000, loss: 0.247792
 >> iter 93000, loss: 0.232916
 >> iter 94000, loss: 0.311841
 >> iter 95000, loss: 0.247223
 >> iter 96000, loss: 0.184086
 >> iter 97000, loss: 0.285039
 >> iter 98000, loss: 0.307957
 >> iter 99000, loss: 0.422548
 >> iter 100000, loss: 0.234381
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.950903
 >> iter 2000, loss: 12.494281
 >> iter 3000, loss: 7.030254
 >> iter 4000, loss: 2.944498
 >> iter 5000, loss: 1.550439
 >> iter 6000, loss: 0.817628
 >> iter 7000, loss: 0.514552
 >> iter 8000, loss: 0.498215
 >> iter 9000, loss: 0.387763
 >> iter 10000, loss: 0.358548
   Number of active neurons: 5
 >> iter 11000, loss: 0.250220
 >> iter 12000, loss: 0.237208
 >> iter 13000, loss: 0.354805
 >> iter 14000, loss: 0.337911
 >> iter 15000, loss: 0.275693
 >> iter 16000, loss: 0.322841
 >> iter 17000, loss: 0.369015
 >> iter 18000, loss: 0.272239
 >> iter 19000, loss: 0.389269
 >> iter 20000, loss: 0.429805
   Number of active neurons: 5
 >> iter 21000, loss: 0.299581
 >> iter 22000, loss: 0.305252
 >> iter 23000, loss: 0.345833
 >> iter 24000, loss: 0.428403
 >> iter 25000, loss: 0.453241
 >> iter 26000, loss: 0.406796
 >> iter 27000, loss: 0.370419
 >> iter 28000, loss: 0.375916
 >> iter 29000, loss: 0.427340
 >> iter 30000, loss: 0.375381
   Number of active neurons: 5
 >> iter 31000, loss: 0.528277
 >> iter 32000, loss: 0.508233
 >> iter 33000, loss: 0.391997
 >> iter 34000, loss: 0.301899
 >> iter 35000, loss: 0.398477
 >> iter 36000, loss: 0.415604
 >> iter 37000, loss: 0.393925
 >> iter 38000, loss: 0.430561
 >> iter 39000, loss: 0.604253
 >> iter 40000, loss: 0.441200
   Number of active neurons: 5
 >> iter 41000, loss: 0.369753
 >> iter 42000, loss: 0.542302
 >> iter 43000, loss: 0.482089
 >> iter 44000, loss: 0.481675
 >> iter 45000, loss: 0.414061
 >> iter 46000, loss: 0.391137
 >> iter 47000, loss: 0.338639
 >> iter 48000, loss: 0.296908
 >> iter 49000, loss: 0.281618
 >> iter 50000, loss: 0.519537
   Number of active neurons: 5
 >> iter 51000, loss: 0.484399
 >> iter 52000, loss: 0.424729
 >> iter 53000, loss: 0.242176
 >> iter 54000, loss: 0.406914
 >> iter 55000, loss: 0.448612
 >> iter 56000, loss: 0.312781
 >> iter 57000, loss: 0.413779
 >> iter 58000, loss: 0.329236
 >> iter 59000, loss: 0.294463
 >> iter 60000, loss: 0.326878
   Number of active neurons: 5
 >> iter 61000, loss: 0.272163
 >> iter 62000, loss: 0.351715
 >> iter 63000, loss: 0.411854
 >> iter 64000, loss: 0.527651
 >> iter 65000, loss: 0.615354
 >> iter 66000, loss: 0.389647
 >> iter 67000, loss: 0.341076
 >> iter 68000, loss: 0.260114
 >> iter 69000, loss: 0.305050
 >> iter 70000, loss: 0.404089
   Number of active neurons: 5
 >> iter 71000, loss: 0.229733
 >> iter 72000, loss: 0.260269
 >> iter 73000, loss: 0.239472
 >> iter 74000, loss: 0.240777
 >> iter 75000, loss: 0.384960
 >> iter 76000, loss: 0.352439
 >> iter 77000, loss: 0.255865
 >> iter 78000, loss: 0.338997
 >> iter 79000, loss: 0.256903
 >> iter 80000, loss: 0.249214
   Number of active neurons: 5
 >> iter 81000, loss: 0.339466
 >> iter 82000, loss: 0.300698
 >> iter 83000, loss: 0.462327
 >> iter 84000, loss: 0.363895
 >> iter 85000, loss: 0.219749
 >> iter 86000, loss: 0.286122
 >> iter 87000, loss: 0.434081
 >> iter 88000, loss: 0.320330
 >> iter 89000, loss: 0.367533
 >> iter 90000, loss: 0.467137
   Number of active neurons: 5
 >> iter 91000, loss: 0.359849
 >> iter 92000, loss: 0.428769
 >> iter 93000, loss: 0.364214
 >> iter 94000, loss: 0.374235
 >> iter 95000, loss: 0.276972
 >> iter 96000, loss: 0.369984
 >> iter 97000, loss: 0.413371
 >> iter 98000, loss: 0.324034
 >> iter 99000, loss: 0.417637
 >> iter 100000, loss: 0.329420
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.019999600008
   - Test - Long: 0.0
   - Test - Big: 0.00599994000061
   - Test - A: 0.0
   - Test - B: 22.8184787681
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.924510
 >> iter 2000, loss: 11.732029
 >> iter 3000, loss: 6.415471
 >> iter 4000, loss: 3.102076
 >> iter 5000, loss: 1.455213
 >> iter 6000, loss: 0.725032
 >> iter 7000, loss: 0.411865
 >> iter 8000, loss: 0.365010
 >> iter 9000, loss: 0.326689
 >> iter 10000, loss: 0.203039
   Number of active neurons: 6
 >> iter 11000, loss: 0.187937
 >> iter 12000, loss: 0.305311
 >> iter 13000, loss: 0.322779
 >> iter 14000, loss: 0.296953
 >> iter 15000, loss: 0.293807
 >> iter 16000, loss: 0.258148
 >> iter 17000, loss: 0.278582
 >> iter 18000, loss: 0.296257
 >> iter 19000, loss: 0.314854
 >> iter 20000, loss: 0.393545
   Number of active neurons: 6
 >> iter 21000, loss: 0.281921
 >> iter 22000, loss: 0.178002
 >> iter 23000, loss: 0.274146
 >> iter 24000, loss: 0.214468
 >> iter 25000, loss: 0.216691
 >> iter 26000, loss: 0.303840
 >> iter 27000, loss: 0.194165
 >> iter 28000, loss: 0.300425
 >> iter 29000, loss: 0.273340
 >> iter 30000, loss: 0.226858
   Number of active neurons: 6
 >> iter 31000, loss: 0.150872
 >> iter 32000, loss: 0.181080
 >> iter 33000, loss: 0.182497
 >> iter 34000, loss: 0.235497
 >> iter 35000, loss: 0.236186
 >> iter 36000, loss: 0.374525
 >> iter 37000, loss: 0.365514
 >> iter 38000, loss: 0.401613
 >> iter 39000, loss: 0.230842
 >> iter 40000, loss: 0.209418
   Number of active neurons: 6
 >> iter 41000, loss: 0.173598
 >> iter 42000, loss: 0.177690
 >> iter 43000, loss: 0.162517
 >> iter 44000, loss: 0.213168
 >> iter 45000, loss: 0.232975
 >> iter 46000, loss: 0.165103
 >> iter 47000, loss: 0.276569
 >> iter 48000, loss: 0.233339
 >> iter 49000, loss: 0.228896
 >> iter 50000, loss: 0.256420
   Number of active neurons: 6
 >> iter 51000, loss: 0.334789
 >> iter 52000, loss: 0.492305
 >> iter 53000, loss: 0.296752
 >> iter 54000, loss: 0.306729
 >> iter 55000, loss: 0.242995
 >> iter 56000, loss: 0.256288
 >> iter 57000, loss: 0.191878
 >> iter 58000, loss: 0.141933
 >> iter 59000, loss: 0.280835
 >> iter 60000, loss: 0.273471
   Number of active neurons: 6
 >> iter 61000, loss: 0.299676
 >> iter 62000, loss: 0.285794
 >> iter 63000, loss: 0.347731
 >> iter 64000, loss: 0.312727
 >> iter 65000, loss: 0.229287
 >> iter 66000, loss: 0.185435
 >> iter 67000, loss: 0.262151
 >> iter 68000, loss: 0.229555
 >> iter 69000, loss: 0.166181
 >> iter 70000, loss: 0.198056
   Number of active neurons: 6
 >> iter 71000, loss: 0.147285
 >> iter 72000, loss: 0.169839
 >> iter 73000, loss: 0.171683
 >> iter 74000, loss: 0.227621
 >> iter 75000, loss: 0.296658
 >> iter 76000, loss: 0.173064
 >> iter 77000, loss: 0.345909
 >> iter 78000, loss: 0.286323
 >> iter 79000, loss: 0.276909
 >> iter 80000, loss: 0.286222
   Number of active neurons: 5
 >> iter 81000, loss: 0.241533
 >> iter 82000, loss: 0.146691
 >> iter 83000, loss: 0.162238
 >> iter 84000, loss: 0.194788
 >> iter 85000, loss: 0.181431
 >> iter 86000, loss: 0.180520
 >> iter 87000, loss: 0.304898
 >> iter 88000, loss: 0.260201
 >> iter 89000, loss: 0.210549
 >> iter 90000, loss: 0.297368
   Number of active neurons: 5
 >> iter 91000, loss: 0.351765
 >> iter 92000, loss: 0.313654
 >> iter 93000, loss: 0.362922
 >> iter 94000, loss: 0.320816
 >> iter 95000, loss: 0.281981
 >> iter 96000, loss: 0.345284
 >> iter 97000, loss: 0.323397
 >> iter 98000, loss: 0.212930
 >> iter 99000, loss: 0.415346
 >> iter 100000, loss: 0.435676
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.894972
 >> iter 2000, loss: 11.538737
 >> iter 3000, loss: 5.668198
 >> iter 4000, loss: 2.860121
 >> iter 5000, loss: 1.533352
 >> iter 6000, loss: 0.934054
 >> iter 7000, loss: 0.849666
 >> iter 8000, loss: 0.839734
 >> iter 9000, loss: 0.542921
 >> iter 10000, loss: 0.454332
   Number of active neurons: 10
 >> iter 11000, loss: 0.547958
 >> iter 12000, loss: 0.534324
 >> iter 13000, loss: 0.530980
 >> iter 14000, loss: 0.364317
 >> iter 15000, loss: 0.457389
 >> iter 16000, loss: 0.580965
 >> iter 17000, loss: 0.426596
 >> iter 18000, loss: 0.230106
 >> iter 19000, loss: 0.181993
 >> iter 20000, loss: 0.177017
   Number of active neurons: 9
 >> iter 21000, loss: 0.265038
 >> iter 22000, loss: 0.280284
 >> iter 23000, loss: 0.258874
 >> iter 24000, loss: 0.542310
 >> iter 25000, loss: 0.343631
 >> iter 26000, loss: 0.311387
 >> iter 27000, loss: 0.475181
 >> iter 28000, loss: 0.368609
 >> iter 29000, loss: 0.353660
 >> iter 30000, loss: 0.422358
   Number of active neurons: 9
 >> iter 31000, loss: 0.345364
 >> iter 32000, loss: 0.270440
 >> iter 33000, loss: 0.283837
 >> iter 34000, loss: 0.396554
 >> iter 35000, loss: 0.303321
 >> iter 36000, loss: 0.309036
 >> iter 37000, loss: 0.255246
 >> iter 38000, loss: 0.219864
 >> iter 39000, loss: 0.295345
 >> iter 40000, loss: 0.244445
   Number of active neurons: 8
 >> iter 41000, loss: 0.176756
 >> iter 42000, loss: 0.151459
 >> iter 43000, loss: 0.299698
 >> iter 44000, loss: 0.318162
 >> iter 45000, loss: 0.304717
 >> iter 46000, loss: 0.356815
 >> iter 47000, loss: 0.244258
 >> iter 48000, loss: 0.171124
 >> iter 49000, loss: 0.349019
 >> iter 50000, loss: 0.389559
   Number of active neurons: 8
 >> iter 51000, loss: 0.273680
 >> iter 52000, loss: 0.301778
 >> iter 53000, loss: 0.284466
 >> iter 54000, loss: 0.181934
 >> iter 55000, loss: 0.317581
 >> iter 56000, loss: 0.256033
 >> iter 57000, loss: 0.342787
 >> iter 58000, loss: 0.384753
 >> iter 59000, loss: 0.308407
 >> iter 60000, loss: 0.260401
   Number of active neurons: 8
 >> iter 61000, loss: 0.194603
 >> iter 62000, loss: 0.303901
 >> iter 63000, loss: 0.500386
 >> iter 64000, loss: 0.335788
 >> iter 65000, loss: 0.216502
 >> iter 66000, loss: 0.194079
 >> iter 67000, loss: 0.304779
 >> iter 68000, loss: 0.275948
 >> iter 69000, loss: 0.273825
 >> iter 70000, loss: 0.174055
   Number of active neurons: 7
 >> iter 71000, loss: 0.237851
 >> iter 72000, loss: 0.231249
 >> iter 73000, loss: 0.339754
 >> iter 74000, loss: 0.295165
 >> iter 75000, loss: 0.203705
 >> iter 76000, loss: 0.133696
 >> iter 77000, loss: 0.258438
 >> iter 78000, loss: 0.179034
 >> iter 79000, loss: 0.219329
 >> iter 80000, loss: 0.187669
   Number of active neurons: 7
 >> iter 81000, loss: 0.243164
 >> iter 82000, loss: 0.245187
 >> iter 83000, loss: 0.193388
 >> iter 84000, loss: 0.142180
 >> iter 85000, loss: 0.260857
 >> iter 86000, loss: 0.205216
 >> iter 87000, loss: 0.361543
 >> iter 88000, loss: 0.286310
 >> iter 89000, loss: 0.281823
 >> iter 90000, loss: 0.201208
   Number of active neurons: 7
 >> iter 91000, loss: 0.228827
 >> iter 92000, loss: 0.189269
 >> iter 93000, loss: 0.227612
 >> iter 94000, loss: 0.509418
 >> iter 95000, loss: 0.455709
 >> iter 96000, loss: 0.362851
 >> iter 97000, loss: 0.217684
 >> iter 98000, loss: 0.197353
 >> iter 99000, loss: 0.165329
 >> iter 100000, loss: 0.207173
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.165361
 >> iter 2000, loss: 12.687071
 >> iter 3000, loss: 6.200041
 >> iter 4000, loss: 2.811141
 >> iter 5000, loss: 1.346448
 >> iter 6000, loss: 0.682602
 >> iter 7000, loss: 0.513523
 >> iter 8000, loss: 0.440161
 >> iter 9000, loss: 0.423580
 >> iter 10000, loss: 0.412234
   Number of active neurons: 8
 >> iter 11000, loss: 0.394801
 >> iter 12000, loss: 0.468400
 >> iter 13000, loss: 0.391448
 >> iter 14000, loss: 0.336003
 >> iter 15000, loss: 0.493932
 >> iter 16000, loss: 0.391049
 >> iter 17000, loss: 0.334839
 >> iter 18000, loss: 0.339643
 >> iter 19000, loss: 0.413688
 >> iter 20000, loss: 0.354643
   Number of active neurons: 8
 >> iter 21000, loss: 0.434802
 >> iter 22000, loss: 0.370230
 >> iter 23000, loss: 0.296392
 >> iter 24000, loss: 0.298721
 >> iter 25000, loss: 0.288824
 >> iter 26000, loss: 0.380070
 >> iter 27000, loss: 0.335241
 >> iter 28000, loss: 0.241551
 >> iter 29000, loss: 0.312541
 >> iter 30000, loss: 0.315658
   Number of active neurons: 7
 >> iter 31000, loss: 0.301872
 >> iter 32000, loss: 0.309831
 >> iter 33000, loss: 0.207746
 >> iter 34000, loss: 0.200572
 >> iter 35000, loss: 0.260167
 >> iter 36000, loss: 0.231445
 >> iter 37000, loss: 0.264007
 >> iter 38000, loss: 0.313821
 >> iter 39000, loss: 0.406344
 >> iter 40000, loss: 0.300999
   Number of active neurons: 7
 >> iter 41000, loss: 0.389940
 >> iter 42000, loss: 0.250420
 >> iter 43000, loss: 0.381554
 >> iter 44000, loss: 0.258718
 >> iter 45000, loss: 0.465795
 >> iter 46000, loss: 0.373351
 >> iter 47000, loss: 0.351367
 >> iter 48000, loss: 0.360832
 >> iter 49000, loss: 0.321728
 >> iter 50000, loss: 0.304351
   Number of active neurons: 7
 >> iter 51000, loss: 0.229009
 >> iter 52000, loss: 0.348819
 >> iter 53000, loss: 0.298064
 >> iter 54000, loss: 0.277276
 >> iter 55000, loss: 0.319927
 >> iter 56000, loss: 0.306439
 >> iter 57000, loss: 0.196866
 >> iter 58000, loss: 0.374443
 >> iter 59000, loss: 0.292662
 >> iter 60000, loss: 0.239421
   Number of active neurons: 6
 >> iter 61000, loss: 0.258668
 >> iter 62000, loss: 0.261037
 >> iter 63000, loss: 0.289585
 >> iter 64000, loss: 0.194418
 >> iter 65000, loss: 0.222455
 >> iter 66000, loss: 0.278669
 >> iter 67000, loss: 0.241222
 >> iter 68000, loss: 0.294329
 >> iter 69000, loss: 0.340684
 >> iter 70000, loss: 0.362368
   Number of active neurons: 6
 >> iter 71000, loss: 0.299866
 >> iter 72000, loss: 0.197984
 >> iter 73000, loss: 0.186365
 >> iter 74000, loss: 0.407039
 >> iter 75000, loss: 0.303153
 >> iter 76000, loss: 0.514262
 >> iter 77000, loss: 0.336902
 >> iter 78000, loss: 0.254703
 >> iter 79000, loss: 0.246024
 >> iter 80000, loss: 0.427490
   Number of active neurons: 6
 >> iter 81000, loss: 0.278882
 >> iter 82000, loss: 0.199604
 >> iter 83000, loss: 0.192843
 >> iter 84000, loss: 0.317399
 >> iter 85000, loss: 0.359753
 >> iter 86000, loss: 0.300432
 >> iter 87000, loss: 0.359904
 >> iter 88000, loss: 0.460529
 >> iter 89000, loss: 0.291354
 >> iter 90000, loss: 0.378896
   Number of active neurons: 6
 >> iter 91000, loss: 0.269551
 >> iter 92000, loss: 0.278207
 >> iter 93000, loss: 0.307852
 >> iter 94000, loss: 0.243568
 >> iter 95000, loss: 0.269742
 >> iter 96000, loss: 0.365784
 >> iter 97000, loss: 0.323316
 >> iter 98000, loss: 0.392726
 >> iter 99000, loss: 0.299360
 >> iter 100000, loss: 0.246080
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.838346
 >> iter 2000, loss: 10.527220
 >> iter 3000, loss: 4.507016
 >> iter 4000, loss: 1.893909
 >> iter 5000, loss: 0.923412
 >> iter 6000, loss: 0.530404
 >> iter 7000, loss: 0.421450
 >> iter 8000, loss: 0.339522
 >> iter 9000, loss: 0.519582
 >> iter 10000, loss: 0.511565
   Number of active neurons: 6
 >> iter 11000, loss: 0.362933
 >> iter 12000, loss: 0.243067
 >> iter 13000, loss: 0.308045
 >> iter 14000, loss: 0.219535
 >> iter 15000, loss: 0.403586
 >> iter 16000, loss: 0.340739
 >> iter 17000, loss: 0.275714
 >> iter 18000, loss: 0.236649
 >> iter 19000, loss: 0.418714
 >> iter 20000, loss: 0.327754
   Number of active neurons: 6
 >> iter 21000, loss: 0.267813
 >> iter 22000, loss: 0.364503
 >> iter 23000, loss: 0.427168
 >> iter 24000, loss: 0.311617
 >> iter 25000, loss: 0.340884
 >> iter 26000, loss: 0.257735
 >> iter 27000, loss: 0.241064
 >> iter 28000, loss: 0.179391
 >> iter 29000, loss: 0.365654
 >> iter 30000, loss: 0.243192
   Number of active neurons: 6
 >> iter 31000, loss: 0.150833
 >> iter 32000, loss: 0.427931
 >> iter 33000, loss: 0.512903
 >> iter 34000, loss: 0.420876
 >> iter 35000, loss: 0.340013
 >> iter 36000, loss: 0.321019
 >> iter 37000, loss: 0.251218
 >> iter 38000, loss: 0.305936
 >> iter 39000, loss: 0.204958
 >> iter 40000, loss: 0.242165
   Number of active neurons: 6
 >> iter 41000, loss: 0.253502
 >> iter 42000, loss: 0.237971
 >> iter 43000, loss: 0.365193
 >> iter 44000, loss: 0.287515
 >> iter 45000, loss: 0.292459
 >> iter 46000, loss: 0.217847
 >> iter 47000, loss: 0.256950
 >> iter 48000, loss: 0.278640
 >> iter 49000, loss: 0.165478
 >> iter 50000, loss: 0.251689
   Number of active neurons: 6
 >> iter 51000, loss: 0.298509
 >> iter 52000, loss: 0.234664
 >> iter 53000, loss: 0.143978
 >> iter 54000, loss: 0.195468
 >> iter 55000, loss: 0.235033
 >> iter 56000, loss: 0.222428
 >> iter 57000, loss: 0.311287
 >> iter 58000, loss: 0.304106
 >> iter 59000, loss: 0.249629
 >> iter 60000, loss: 0.290227
   Number of active neurons: 5
 >> iter 61000, loss: 0.519057
 >> iter 62000, loss: 0.422804
 >> iter 63000, loss: 0.236393
 >> iter 64000, loss: 0.182825
 >> iter 65000, loss: 0.332884
 >> iter 66000, loss: 0.320362
 >> iter 67000, loss: 0.315882
 >> iter 68000, loss: 0.233081
 >> iter 69000, loss: 0.255447
 >> iter 70000, loss: 0.192388
   Number of active neurons: 5
 >> iter 71000, loss: 0.269565
 >> iter 72000, loss: 0.304813
 >> iter 73000, loss: 0.246930
 >> iter 74000, loss: 0.273940
 >> iter 75000, loss: 0.261271
 >> iter 76000, loss: 0.317461
 >> iter 77000, loss: 0.417752
 >> iter 78000, loss: 0.406606
 >> iter 79000, loss: 0.490017
 >> iter 80000, loss: 0.332735
   Number of active neurons: 5
 >> iter 81000, loss: 0.398223
 >> iter 82000, loss: 0.258342
 >> iter 83000, loss: 0.226297
 >> iter 84000, loss: 0.334697
 >> iter 85000, loss: 0.288013
 >> iter 86000, loss: 0.280655
 >> iter 87000, loss: 0.237805
 >> iter 88000, loss: 0.254268
 >> iter 89000, loss: 0.392211
 >> iter 90000, loss: 0.305456
   Number of active neurons: 5
 >> iter 91000, loss: 0.237315
 >> iter 92000, loss: 0.258401
 >> iter 93000, loss: 0.211640
 >> iter 94000, loss: 0.273817
 >> iter 95000, loss: 0.317083
 >> iter 96000, loss: 0.242579
 >> iter 97000, loss: 0.232764
 >> iter 98000, loss: 0.186462
 >> iter 99000, loss: 0.312449
 >> iter 100000, loss: 0.382550
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.795649
 >> iter 2000, loss: 9.462923
 >> iter 3000, loss: 3.882709
 >> iter 4000, loss: 1.759912
 >> iter 5000, loss: 0.858158
 >> iter 6000, loss: 0.507937
 >> iter 7000, loss: 0.532329
 >> iter 8000, loss: 0.339339
 >> iter 9000, loss: 0.203190
 >> iter 10000, loss: 0.220469
   Number of active neurons: 6
 >> iter 11000, loss: 0.428640
 >> iter 12000, loss: 0.288244
 >> iter 13000, loss: 0.297986
 >> iter 14000, loss: 0.266266
 >> iter 15000, loss: 0.294695
 >> iter 16000, loss: 0.204186
 >> iter 17000, loss: 0.228114
 >> iter 18000, loss: 0.208409
 >> iter 19000, loss: 0.178761
 >> iter 20000, loss: 0.269602
   Number of active neurons: 6
 >> iter 21000, loss: 0.228078
 >> iter 22000, loss: 0.344209
 >> iter 23000, loss: 0.327699
 >> iter 24000, loss: 0.237195
 >> iter 25000, loss: 0.199728
 >> iter 26000, loss: 0.179541
 >> iter 27000, loss: 0.212062
 >> iter 28000, loss: 0.226963
 >> iter 29000, loss: 0.217984
 >> iter 30000, loss: 0.346710
   Number of active neurons: 6
 >> iter 31000, loss: 0.275309
 >> iter 32000, loss: 0.186010
 >> iter 33000, loss: 0.230923
 >> iter 34000, loss: 0.164989
 >> iter 35000, loss: 0.262965
 >> iter 36000, loss: 0.237097
 >> iter 37000, loss: 0.269377
 >> iter 38000, loss: 0.234399
 >> iter 39000, loss: 0.200777
 >> iter 40000, loss: 0.327236
   Number of active neurons: 6
 >> iter 41000, loss: 0.345510
 >> iter 42000, loss: 0.347055
 >> iter 43000, loss: 0.312578
 >> iter 44000, loss: 0.266566
 >> iter 45000, loss: 0.298867
 >> iter 46000, loss: 0.207667
 >> iter 47000, loss: 0.147612
 >> iter 48000, loss: 0.240423
 >> iter 49000, loss: 0.256461
 >> iter 50000, loss: 0.208619
   Number of active neurons: 6
 >> iter 51000, loss: 0.171393
 >> iter 52000, loss: 0.155913
 >> iter 53000, loss: 0.233356
 >> iter 54000, loss: 0.183006
 >> iter 55000, loss: 0.169677
 >> iter 56000, loss: 0.185023
 >> iter 57000, loss: 0.178251
 >> iter 58000, loss: 0.223442
 >> iter 59000, loss: 0.282891
 >> iter 60000, loss: 0.202581
   Number of active neurons: 6
 >> iter 61000, loss: 0.250594
 >> iter 62000, loss: 0.148987
 >> iter 63000, loss: 0.148449
 >> iter 64000, loss: 0.146516
 >> iter 65000, loss: 0.107635
 >> iter 66000, loss: 0.260121
 >> iter 67000, loss: 0.167174
 >> iter 68000, loss: 0.167757
 >> iter 69000, loss: 0.213563
 >> iter 70000, loss: 0.188977
   Number of active neurons: 5
 >> iter 71000, loss: 0.322634
 >> iter 72000, loss: 0.199444
 >> iter 73000, loss: 0.299327
 >> iter 74000, loss: 0.181069
 >> iter 75000, loss: 0.190580
 >> iter 76000, loss: 0.180667
 >> iter 77000, loss: 0.228025
 >> iter 78000, loss: 0.241667
 >> iter 79000, loss: 0.356918
 >> iter 80000, loss: 0.353404
   Number of active neurons: 5
 >> iter 81000, loss: 0.180049
 >> iter 82000, loss: 0.133170
 >> iter 83000, loss: 0.310926
 >> iter 84000, loss: 0.310232
 >> iter 85000, loss: 0.250176
 >> iter 86000, loss: 0.154401
 >> iter 87000, loss: 0.262959
 >> iter 88000, loss: 0.274986
 >> iter 89000, loss: 0.365999
 >> iter 90000, loss: 0.276743
   Number of active neurons: 5
 >> iter 91000, loss: 0.210171
 >> iter 92000, loss: 0.195788
 >> iter 93000, loss: 0.172632
 >> iter 94000, loss: 0.143738
 >> iter 95000, loss: 0.160524
 >> iter 96000, loss: 0.195619
 >> iter 97000, loss: 0.147545
 >> iter 98000, loss: 0.193143
 >> iter 99000, loss: 0.235280
 >> iter 100000, loss: 0.188186
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

