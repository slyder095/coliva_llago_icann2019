 > Problema: tomita6nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.9
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.075610
 >> iter 2000, loss: 15.515431
 >> iter 3000, loss: 14.057835
 >> iter 4000, loss: 13.500912
 >> iter 5000, loss: 13.249133
 >> iter 6000, loss: 13.156369
 >> iter 7000, loss: 13.095200
 >> iter 8000, loss: 13.063024
 >> iter 9000, loss: 13.049004
 >> iter 10000, loss: 13.056167
   Number of active neurons: 10
 >> iter 11000, loss: 13.031842
 >> iter 12000, loss: 13.024895
 >> iter 13000, loss: 13.012898
 >> iter 14000, loss: 13.020243
 >> iter 15000, loss: 13.008684
 >> iter 16000, loss: 13.016793
 >> iter 17000, loss: 12.999587
 >> iter 18000, loss: 12.997846
 >> iter 19000, loss: 12.981953
 >> iter 20000, loss: 12.998305
   Number of active neurons: 10
 >> iter 21000, loss: 12.982783
 >> iter 22000, loss: 12.995762
 >> iter 23000, loss: 12.982838
 >> iter 24000, loss: 12.999795
 >> iter 25000, loss: 12.985223
 >> iter 26000, loss: 12.998907
 >> iter 27000, loss: 12.989329
 >> iter 28000, loss: 13.006477
 >> iter 29000, loss: 12.984988
 >> iter 30000, loss: 12.997375
   Number of active neurons: 10
 >> iter 31000, loss: 12.987847
 >> iter 32000, loss: 13.001596
 >> iter 33000, loss: 12.983812
 >> iter 34000, loss: 13.002428
 >> iter 35000, loss: 12.988032
 >> iter 36000, loss: 13.001588
 >> iter 37000, loss: 12.987898
 >> iter 38000, loss: 12.995510
 >> iter 39000, loss: 12.978586
 >> iter 40000, loss: 12.996523
   Number of active neurons: 10
 >> iter 41000, loss: 12.980627
 >> iter 42000, loss: 12.993674
 >> iter 43000, loss: 12.976301
 >> iter 44000, loss: 12.990473
 >> iter 45000, loss: 12.973331
 >> iter 46000, loss: 12.998633
 >> iter 47000, loss: 12.967660
 >> iter 48000, loss: 12.994058
 >> iter 49000, loss: 12.972655
 >> iter 50000, loss: 12.996339
   Number of active neurons: 10
 >> iter 51000, loss: 12.967917
 >> iter 52000, loss: 12.990546
 >> iter 53000, loss: 12.962343
 >> iter 54000, loss: 12.986341
 >> iter 55000, loss: 12.959033
 >> iter 56000, loss: 12.989183
 >> iter 57000, loss: 12.958914
 >> iter 58000, loss: 12.984863
 >> iter 59000, loss: 12.964135
 >> iter 60000, loss: 12.992054
   Number of active neurons: 10
 >> iter 61000, loss: 12.968630
 >> iter 62000, loss: 12.987503
 >> iter 63000, loss: 12.959689
 >> iter 64000, loss: 12.986691
 >> iter 65000, loss: 12.962840
 >> iter 66000, loss: 12.991957
 >> iter 67000, loss: 12.965102
 >> iter 68000, loss: 12.990762
 >> iter 69000, loss: 12.964767
 >> iter 70000, loss: 12.987977
   Number of active neurons: 10
 >> iter 71000, loss: 12.960854
 >> iter 72000, loss: 12.990156
 >> iter 73000, loss: 12.963301
 >> iter 74000, loss: 12.987146
 >> iter 75000, loss: 12.962489
 >> iter 76000, loss: 12.992440
 >> iter 77000, loss: 12.961117
 >> iter 78000, loss: 12.981484
 >> iter 79000, loss: 12.956271
 >> iter 80000, loss: 12.987260
   Number of active neurons: 10
 >> iter 81000, loss: 12.958228
 >> iter 82000, loss: 12.984510
 >> iter 83000, loss: 12.962431
 >> iter 84000, loss: 12.990392
 >> iter 85000, loss: 12.967226
 >> iter 86000, loss: 12.988307
 >> iter 87000, loss: 12.969616
 >> iter 88000, loss: 12.998531
 >> iter 89000, loss: 12.972909
 >> iter 90000, loss: 13.004627
   Number of active neurons: 10
 >> iter 91000, loss: 12.977303
 >> iter 92000, loss: 12.996624
 >> iter 93000, loss: 12.960280
 >> iter 94000, loss: 12.991907
 >> iter 95000, loss: 12.964343
 >> iter 96000, loss: 12.976870
 >> iter 97000, loss: 12.927593
 >> iter 98000, loss: 12.851715
 >> iter 99000, loss: 12.062848
 >> iter 100000, loss: 11.545184
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 22.8415431691
   - Test - Long: 32.1633918304
   - Test - Big: 23.0007699923
   - Test - A: 31.4512365842
   - Test - B: 32.5911605893
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.151127
 >> iter 2000, loss: 15.510908
 >> iter 3000, loss: 14.017113
 >> iter 4000, loss: 13.437952
 >> iter 5000, loss: 13.217304
 >> iter 6000, loss: 13.127516
 >> iter 7000, loss: 13.074804
 >> iter 8000, loss: 13.066436
 >> iter 9000, loss: 13.045225
 >> iter 10000, loss: 13.052055
   Number of active neurons: 10
 >> iter 11000, loss: 13.041114
 >> iter 12000, loss: 13.045862
 >> iter 13000, loss: 13.034800
 >> iter 14000, loss: 13.031228
 >> iter 15000, loss: 13.028063
 >> iter 16000, loss: 13.030127
 >> iter 17000, loss: 13.029633
 >> iter 18000, loss: 13.027462
 >> iter 19000, loss: 13.022368
 >> iter 20000, loss: 13.038620
   Number of active neurons: 10
 >> iter 21000, loss: 13.024876
 >> iter 22000, loss: 13.036559
 >> iter 23000, loss: 13.020138
 >> iter 24000, loss: 13.035802
 >> iter 25000, loss: 13.020019
 >> iter 26000, loss: 13.038525
 >> iter 27000, loss: 13.017072
 >> iter 28000, loss: 13.025545
 >> iter 29000, loss: 13.010932
 >> iter 30000, loss: 13.033491
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 8
 >> iter 31000, loss: 13.013198
 >> iter 32000, loss: 13.034313
 >> iter 33000, loss: 13.018029
 >> iter 34000, loss: 13.026316
 >> iter 35000, loss: 13.017729
 >> iter 36000, loss: 13.035361
 >> iter 37000, loss: 13.023542
 >> iter 38000, loss: 13.034042
 >> iter 39000, loss: 13.016995
 >> iter 40000, loss: 13.025773
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 9
 >> iter 41000, loss: 13.007594
 >> iter 42000, loss: 13.023293
 >> iter 43000, loss: 13.007325
 >> iter 44000, loss: 13.030138
 >> iter 45000, loss: 13.011378
 >> iter 46000, loss: 13.030960
 >> iter 47000, loss: 13.008216
 >> iter 48000, loss: 13.032854
 >> iter 49000, loss: 13.008340
 >> iter 50000, loss: 13.032240
   Number of active neurons: 9
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 9
 >> iter 51000, loss: 13.007317
 >> iter 52000, loss: 13.030728
 >> iter 53000, loss: 13.005036
 >> iter 54000, loss: 13.028736
 >> iter 55000, loss: 12.999526
 >> iter 56000, loss: 13.030563
 >> iter 57000, loss: 13.004126
 >> iter 58000, loss: 13.030010
 >> iter 59000, loss: 13.007464
 >> iter 60000, loss: 13.027297
   Number of active neurons: 9
   SHOCK
   Setting new limit to 287500.0 iters...
   Number of active neurons: 9
 >> iter 61000, loss: 13.003647
 >> iter 62000, loss: 13.031013
 >> iter 63000, loss: 13.006881
 >> iter 64000, loss: 13.031565
 >> iter 65000, loss: 13.006603
 >> iter 66000, loss: 13.031393
 >> iter 67000, loss: 13.006277
 >> iter 68000, loss: 13.024309
 >> iter 69000, loss: 13.002471
 >> iter 70000, loss: 13.009499
   Number of active neurons: 9
   SHOCK
   Setting new limit to 293750.0 iters...
   Number of active neurons: 9
 >> iter 71000, loss: 12.982542
 >> iter 72000, loss: 12.976708
 >> iter 73000, loss: 12.928294
 >> iter 74000, loss: 12.894820
 >> iter 75000, loss: 12.815740
 >> iter 76000, loss: 12.715052
 >> iter 77000, loss: 12.392339
 >> iter 78000, loss: 11.785931
 >> iter 79000, loss: 11.319118
 >> iter 80000, loss: 11.192156
   Number of active neurons: 10
 >> iter 81000, loss: 10.993409
 >> iter 82000, loss: 10.992484
 >> iter 83000, loss: 10.849586
 >> iter 84000, loss: 10.916905
 >> iter 85000, loss: 10.766322
 >> iter 86000, loss: 10.742493
 >> iter 87000, loss: 10.551508
 >> iter 88000, loss: 10.578817
 >> iter 89000, loss: 10.432665
 >> iter 90000, loss: 10.481832
   Number of active neurons: 10
 >> iter 91000, loss: 10.371474
 >> iter 92000, loss: 10.366550
 >> iter 93000, loss: 10.186787
 >> iter 94000, loss: 10.209106
 >> iter 95000, loss: 9.993175
 >> iter 96000, loss: 9.948263
 >> iter 97000, loss: 9.833744
 >> iter 98000, loss: 9.579845
 >> iter 99000, loss: 6.943427
 >> iter 100000, loss: 4.440551
   Number of active neurons: 10
 >> iter 101000, loss: 2.679833
 >> iter 102000, loss: 2.150043
 >> iter 103000, loss: 1.710342
 >> iter 104000, loss: 1.080687
 >> iter 105000, loss: 1.403503
 >> iter 106000, loss: 1.122290
 >> iter 107000, loss: 0.670706
 >> iter 108000, loss: 0.923594
 >> iter 109000, loss: 0.848568
 >> iter 110000, loss: 0.682505
   Number of active neurons: 10
 >> iter 111000, loss: 0.746093
 >> iter 112000, loss: 0.955821
 >> iter 113000, loss: 0.777490
 >> iter 114000, loss: 0.486938
 >> iter 115000, loss: 0.436818
 >> iter 116000, loss: 0.772808
 >> iter 117000, loss: 0.515754
 >> iter 118000, loss: 0.455609
 >> iter 119000, loss: 0.386360
 >> iter 120000, loss: 0.378875
   Number of active neurons: 10
 >> iter 121000, loss: 0.302289
 >> iter 122000, loss: 0.498655
 >> iter 123000, loss: 0.332688
 >> iter 124000, loss: 0.324524
 >> iter 125000, loss: 0.396868
 >> iter 126000, loss: 0.412002
 >> iter 127000, loss: 0.438426
 >> iter 128000, loss: 0.352245
 >> iter 129000, loss: 0.297628
 >> iter 130000, loss: 0.339334
   Number of active neurons: 10
 >> iter 131000, loss: 0.209215
 >> iter 132000, loss: 0.095233
 >> iter 133000, loss: 0.113636
 >> iter 134000, loss: 0.197448
 >> iter 135000, loss: 0.287275
 >> iter 136000, loss: 0.154184
 >> iter 137000, loss: 0.221810
 >> iter 138000, loss: 0.131039
 >> iter 139000, loss: 0.102774
 >> iter 140000, loss: 0.093691
   Number of active neurons: 10
 >> iter 141000, loss: 0.221135
 >> iter 142000, loss: 0.106187
 >> iter 143000, loss: 0.217146
 >> iter 144000, loss: 0.177272
 >> iter 145000, loss: 0.140774
 >> iter 146000, loss: 0.111074
 >> iter 147000, loss: 0.105537
 >> iter 148000, loss: 0.052814
 >> iter 149000, loss: 0.143029
 >> iter 150000, loss: 0.075139
   Number of active neurons: 10
 >> iter 151000, loss: 0.036721
 >> iter 152000, loss: 0.203044
 >> iter 153000, loss: 0.096708
 >> iter 154000, loss: 0.216983
 >> iter 155000, loss: 0.118459
 >> iter 156000, loss: 0.183602
 >> iter 157000, loss: 0.078263
 >> iter 158000, loss: 0.260326
 >> iter 159000, loss: 0.164803
 >> iter 160000, loss: 0.142656
   Number of active neurons: 10
 >> iter 161000, loss: 0.062415
 >> iter 162000, loss: 0.133358
 >> iter 163000, loss: 0.079323
 >> iter 164000, loss: 0.294700
 >> iter 165000, loss: 0.135810
 >> iter 166000, loss: 0.217458
 >> iter 167000, loss: 0.214392
 >> iter 168000, loss: 0.140475
 >> iter 169000, loss: 0.061469
 >> iter 170000, loss: 0.054014
   Number of active neurons: 10
 >> iter 171000, loss: 0.065146
 >> iter 172000, loss: 0.236697
 >> iter 173000, loss: 0.229296
 >> iter 174000, loss: 0.250219
 >> iter 175000, loss: 0.229489
 >> iter 176000, loss: 0.156516
 >> iter 177000, loss: 0.087862
 >> iter 178000, loss: 0.042014
 >> iter 179000, loss: 0.142622
 >> iter 180000, loss: 0.294979
   Number of active neurons: 10
 >> iter 181000, loss: 0.292636
 >> iter 182000, loss: 0.242834
 >> iter 183000, loss: 0.165016
 >> iter 184000, loss: 0.127400
 >> iter 185000, loss: 0.082844
 >> iter 186000, loss: 0.116229
 >> iter 187000, loss: 0.051243
 >> iter 188000, loss: 0.184861
 >> iter 189000, loss: 0.139742
 >> iter 190000, loss: 0.274384
   Number of active neurons: 10
 >> iter 191000, loss: 0.134989
 >> iter 192000, loss: 0.064207
 >> iter 193000, loss: 0.034386
 >> iter 194000, loss: 0.019347
 >> iter 195000, loss: 0.025335
 >> iter 196000, loss: 0.041742
 >> iter 197000, loss: 0.022418
 >> iter 198000, loss: 0.037005
 >> iter 199000, loss: 0.047262
 >> iter 200000, loss: 0.022614
   Number of active neurons: 10
 >> iter 201000, loss: 0.077476
 >> iter 202000, loss: 0.034686
 >> iter 203000, loss: 0.046954
 >> iter 204000, loss: 0.022145
 >> iter 205000, loss: 0.013125
 >> iter 206000, loss: 0.008942
 >> iter 207000, loss: 0.023510
 >> iter 208000, loss: 0.013427
 >> iter 209000, loss: 0.008931
 >> iter 210000, loss: 0.094358
   Number of active neurons: 10
 >> iter 211000, loss: 0.072299
 >> iter 212000, loss: 0.042955
 >> iter 213000, loss: 0.210565
 >> iter 214000, loss: 0.090087
 >> iter 215000, loss: 0.055317
 >> iter 216000, loss: 0.079115
 >> iter 217000, loss: 0.034327
 >> iter 218000, loss: 0.023452
 >> iter 219000, loss: 0.220072
 >> iter 220000, loss: 0.088032
   Number of active neurons: 10
 >> iter 221000, loss: 0.132166
 >> iter 222000, loss: 0.054734
 >> iter 223000, loss: 0.072797
 >> iter 224000, loss: 0.062139
 >> iter 225000, loss: 0.061921
 >> iter 226000, loss: 0.104532
 >> iter 227000, loss: 0.134660
 >> iter 228000, loss: 0.055632
 >> iter 229000, loss: 0.118883
 >> iter 230000, loss: 0.049599
   Number of active neurons: 10
 >> iter 231000, loss: 0.023633
 >> iter 232000, loss: 0.048482
 >> iter 233000, loss: 0.046090
 >> iter 234000, loss: 0.112292
 >> iter 235000, loss: 0.046683
 >> iter 236000, loss: 0.021846
 >> iter 237000, loss: 0.022302
 >> iter 238000, loss: 0.036300
 >> iter 239000, loss: 0.107158
 >> iter 240000, loss: 0.051516
   Number of active neurons: 10
 >> iter 241000, loss: 0.072250
 >> iter 242000, loss: 0.139995
 >> iter 243000, loss: 0.060899
 >> iter 244000, loss: 0.067252
 >> iter 245000, loss: 0.094761
 >> iter 246000, loss: 0.108181
 >> iter 247000, loss: 0.095817
 >> iter 248000, loss: 0.049144
 >> iter 249000, loss: 0.065315
 >> iter 250000, loss: 0.053679
   Number of active neurons: 10
 >> iter 251000, loss: 0.024661
 >> iter 252000, loss: 0.031402
 >> iter 253000, loss: 0.059911
 >> iter 254000, loss: 0.093387
 >> iter 255000, loss: 0.041628
 >> iter 256000, loss: 0.084166
 >> iter 257000, loss: 0.126623
 >> iter 258000, loss: 0.051214
 >> iter 259000, loss: 0.039249
 >> iter 260000, loss: 0.101729
   Number of active neurons: 10
 >> iter 261000, loss: 0.042182
 >> iter 262000, loss: 0.019702
 >> iter 263000, loss: 0.013741
 >> iter 264000, loss: 0.008502
 >> iter 265000, loss: 0.020929
 >> iter 266000, loss: 0.022984
 >> iter 267000, loss: 0.219748
 >> iter 268000, loss: 0.108015
 >> iter 269000, loss: 0.098431
 >> iter 270000, loss: 0.040644
   Number of active neurons: 10
 >> iter 271000, loss: 0.018644
 >> iter 272000, loss: 0.010374
 >> iter 273000, loss: 0.006921
 >> iter 274000, loss: 0.111120
 >> iter 275000, loss: 0.054401
 >> iter 276000, loss: 0.023648
 >> iter 277000, loss: 0.011792
 >> iter 278000, loss: 0.025410
 >> iter 279000, loss: 0.017604
 >> iter 280000, loss: 0.010636
   Number of active neurons: 10
 >> iter 281000, loss: 0.006688
 >> iter 282000, loss: 0.006470
 >> iter 283000, loss: 0.025375
 >> iter 284000, loss: 0.011931
 >> iter 285000, loss: 0.007061
 >> iter 286000, loss: 0.127342
 >> iter 287000, loss: 0.063038
 >> iter 288000, loss: 0.026497
 >> iter 289000, loss: 0.103202
 >> iter 290000, loss: 0.083368
   Number of active neurons: 10
 >> iter 291000, loss: 0.125379
 >> iter 292000, loss: 0.065817
 >> iter 293000, loss: 0.028101
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.123019
 >> iter 2000, loss: 15.569820
 >> iter 3000, loss: 14.110479
 >> iter 4000, loss: 13.520741
 >> iter 5000, loss: 13.275471
 >> iter 6000, loss: 13.178343
 >> iter 7000, loss: 13.123585
 >> iter 8000, loss: 13.103000
 >> iter 9000, loss: 13.082609
 >> iter 10000, loss: 13.073581
   Number of active neurons: 10
 >> iter 11000, loss: 13.060103
 >> iter 12000, loss: 13.071070
 >> iter 13000, loss: 13.048261
 >> iter 14000, loss: 13.053563
 >> iter 15000, loss: 13.040304
 >> iter 16000, loss: 13.046825
 >> iter 17000, loss: 13.030086
 >> iter 18000, loss: 13.038247
 >> iter 19000, loss: 13.028852
 >> iter 20000, loss: 13.045721
   Number of active neurons: 10
 >> iter 21000, loss: 13.031815
 >> iter 22000, loss: 13.033176
 >> iter 23000, loss: 13.021633
 >> iter 24000, loss: 13.032045
 >> iter 25000, loss: 13.026046
 >> iter 26000, loss: 13.043041
 >> iter 27000, loss: 13.027329
 >> iter 28000, loss: 13.034830
 >> iter 29000, loss: 13.012979
 >> iter 30000, loss: 13.030317
   Number of active neurons: 10
 >> iter 31000, loss: 13.017986
 >> iter 32000, loss: 13.030552
 >> iter 33000, loss: 13.020273
 >> iter 34000, loss: 13.035074
 >> iter 35000, loss: 13.018625
 >> iter 36000, loss: 13.026064
 >> iter 37000, loss: 13.017753
 >> iter 38000, loss: 13.021934
 >> iter 39000, loss: 13.009131
 >> iter 40000, loss: 13.033263
   Number of active neurons: 10
 >> iter 41000, loss: 13.012881
 >> iter 42000, loss: 13.030150
 >> iter 43000, loss: 13.006963
 >> iter 44000, loss: 13.027639
 >> iter 45000, loss: 13.005533
 >> iter 46000, loss: 13.025245
 >> iter 47000, loss: 13.012100
 >> iter 48000, loss: 13.037387
 >> iter 49000, loss: 13.012261
 >> iter 50000, loss: 13.042550
   Number of active neurons: 10
 >> iter 51000, loss: 13.010573
 >> iter 52000, loss: 13.031512
 >> iter 53000, loss: 13.008337
 >> iter 54000, loss: 13.029414
 >> iter 55000, loss: 13.000202
 >> iter 56000, loss: 13.024858
 >> iter 57000, loss: 13.001592
 >> iter 58000, loss: 13.001581
 >> iter 59000, loss: 12.964983
 >> iter 60000, loss: 12.939893
   Number of active neurons: 10
 >> iter 61000, loss: 12.875966
 >> iter 62000, loss: 12.791671
 >> iter 63000, loss: 12.700742
 >> iter 64000, loss: 12.466179
 >> iter 65000, loss: 11.893466
 >> iter 66000, loss: 11.550965
 >> iter 67000, loss: 11.259099
 >> iter 68000, loss: 11.189006
 >> iter 69000, loss: 11.007072
 >> iter 70000, loss: 10.969436
   Number of active neurons: 10
 >> iter 71000, loss: 10.690597
 >> iter 72000, loss: 10.603699
 >> iter 73000, loss: 10.355883
 >> iter 74000, loss: 10.264055
 >> iter 75000, loss: 9.988289
 >> iter 76000, loss: 9.953141
 >> iter 77000, loss: 9.808472
 >> iter 78000, loss: 9.765033
 >> iter 79000, loss: 9.538096
 >> iter 80000, loss: 9.566869
   Number of active neurons: 10
 >> iter 81000, loss: 9.356105
 >> iter 82000, loss: 9.363311
 >> iter 83000, loss: 9.187505
 >> iter 84000, loss: 9.213943
 >> iter 85000, loss: 9.093442
 >> iter 86000, loss: 9.151018
 >> iter 87000, loss: 9.056330
 >> iter 88000, loss: 9.114320
 >> iter 89000, loss: 8.988650
 >> iter 90000, loss: 9.116925
   Number of active neurons: 10
 >> iter 91000, loss: 8.996281
 >> iter 92000, loss: 9.066284
 >> iter 93000, loss: 8.918096
 >> iter 94000, loss: 8.955313
 >> iter 95000, loss: 8.888881
 >> iter 96000, loss: 8.920100
 >> iter 97000, loss: 8.796225
 >> iter 98000, loss: 8.893606
 >> iter 99000, loss: 8.727699
 >> iter 100000, loss: 8.808125
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 17.6596468071
   - Test - Long: 31.3934303285
   - Test - Big: 17.6778232218
   - Test - A: 30.3513099127
   - Test - B: 32.4911672555
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.072647
 >> iter 2000, loss: 15.521011
 >> iter 3000, loss: 14.047119
 >> iter 4000, loss: 13.479749
 >> iter 5000, loss: 13.238344
 >> iter 6000, loss: 13.156561
 >> iter 7000, loss: 13.085290
 >> iter 8000, loss: 13.066761
 >> iter 9000, loss: 13.051067
 >> iter 10000, loss: 13.042737
   Number of active neurons: 10
 >> iter 11000, loss: 13.022746
 >> iter 12000, loss: 13.025564
 >> iter 13000, loss: 13.012702
 >> iter 14000, loss: 13.027774
 >> iter 15000, loss: 13.009238
 >> iter 16000, loss: 13.022110
 >> iter 17000, loss: 13.008660
 >> iter 18000, loss: 13.013225
 >> iter 19000, loss: 12.999221
 >> iter 20000, loss: 13.012402
   Number of active neurons: 10
 >> iter 21000, loss: 12.992406
 >> iter 22000, loss: 13.011460
 >> iter 23000, loss: 13.002090
 >> iter 24000, loss: 13.012011
 >> iter 25000, loss: 12.999491
 >> iter 26000, loss: 13.005673
 >> iter 27000, loss: 12.983438
 >> iter 28000, loss: 13.000870
 >> iter 29000, loss: 12.984373
 >> iter 30000, loss: 12.995287
   Number of active neurons: 10
 >> iter 31000, loss: 12.980818
 >> iter 32000, loss: 12.996260
 >> iter 33000, loss: 12.975925
 >> iter 34000, loss: 12.992621
 >> iter 35000, loss: 12.975375
 >> iter 36000, loss: 12.975198
 >> iter 37000, loss: 12.944790
 >> iter 38000, loss: 12.636192
 >> iter 39000, loss: 11.863431
 >> iter 40000, loss: 11.397497
   Number of active neurons: 10
 >> iter 41000, loss: 11.050103
 >> iter 42000, loss: 10.935707
 >> iter 43000, loss: 10.732657
 >> iter 44000, loss: 10.684936
 >> iter 45000, loss: 10.390356
 >> iter 46000, loss: 10.310258
 >> iter 47000, loss: 10.108757
 >> iter 48000, loss: 10.040559
 >> iter 49000, loss: 9.779989
 >> iter 50000, loss: 9.617841
   Number of active neurons: 10
 >> iter 51000, loss: 9.352339
 >> iter 52000, loss: 9.347783
 >> iter 53000, loss: 9.215358
 >> iter 54000, loss: 9.224156
 >> iter 55000, loss: 9.107495
 >> iter 56000, loss: 9.187070
 >> iter 57000, loss: 9.129503
 >> iter 58000, loss: 9.091616
 >> iter 59000, loss: 8.972030
 >> iter 60000, loss: 8.982224
   Number of active neurons: 10
 >> iter 61000, loss: 8.837495
 >> iter 62000, loss: 8.897725
 >> iter 63000, loss: 8.778121
 >> iter 64000, loss: 8.827011
 >> iter 65000, loss: 8.752048
 >> iter 66000, loss: 8.855569
 >> iter 67000, loss: 8.739611
 >> iter 68000, loss: 8.835523
 >> iter 69000, loss: 8.694134
 >> iter 70000, loss: 8.747477
   Number of active neurons: 10
 >> iter 71000, loss: 8.684637
 >> iter 72000, loss: 8.728899
 >> iter 73000, loss: 8.629146
 >> iter 74000, loss: 8.705926
 >> iter 75000, loss: 8.603983
 >> iter 76000, loss: 8.700574
 >> iter 77000, loss: 8.606821
 >> iter 78000, loss: 8.686932
 >> iter 79000, loss: 8.611775
 >> iter 80000, loss: 8.669756
   Number of active neurons: 10
 >> iter 81000, loss: 8.591014
 >> iter 82000, loss: 8.693245
 >> iter 83000, loss: 8.587233
 >> iter 84000, loss: 8.678919
 >> iter 85000, loss: 8.693979
 >> iter 86000, loss: 8.738794
 >> iter 87000, loss: 8.650450
 >> iter 88000, loss: 8.762299
 >> iter 89000, loss: 8.720979
 >> iter 90000, loss: 9.064957
   Number of active neurons: 10
 >> iter 91000, loss: 8.985299
 >> iter 92000, loss: 9.206492
 >> iter 93000, loss: 8.997957
 >> iter 94000, loss: 9.303359
 >> iter 95000, loss: 8.895817
 >> iter 96000, loss: 8.828156
 >> iter 97000, loss: 8.668424
 >> iter 98000, loss: 8.578404
 >> iter 99000, loss: 8.452733
 >> iter 100000, loss: 8.413307
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 15.079698406
   - Test - Long: 30.8984550772
   - Test - Big: 15.0838491615
   - Test - A: 19.0987267515
   - Test - B: 31.577894807
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.999782
 >> iter 2000, loss: 15.477299
 >> iter 3000, loss: 13.996816
 >> iter 4000, loss: 13.429916
 >> iter 5000, loss: 13.206746
 >> iter 6000, loss: 13.109456
 >> iter 7000, loss: 13.057033
 >> iter 8000, loss: 13.048968
 >> iter 9000, loss: 13.013319
 >> iter 10000, loss: 13.003999
   Number of active neurons: 10
 >> iter 11000, loss: 13.004235
 >> iter 12000, loss: 13.011917
 >> iter 13000, loss: 13.002391
 >> iter 14000, loss: 13.006787
 >> iter 15000, loss: 12.992924
 >> iter 16000, loss: 12.997776
 >> iter 17000, loss: 12.994010
 >> iter 18000, loss: 13.004695
 >> iter 19000, loss: 12.989938
 >> iter 20000, loss: 12.998072
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 12.988332
 >> iter 22000, loss: 12.997624
 >> iter 23000, loss: 12.980253
 >> iter 24000, loss: 12.986493
 >> iter 25000, loss: 12.978659
 >> iter 26000, loss: 12.989175
 >> iter 27000, loss: 12.966561
 >> iter 28000, loss: 12.986328
 >> iter 29000, loss: 12.974654
 >> iter 30000, loss: 12.992159
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 12.972256
 >> iter 32000, loss: 12.985120
 >> iter 33000, loss: 12.972602
 >> iter 34000, loss: 12.973017
 >> iter 35000, loss: 12.961633
 >> iter 36000, loss: 12.972623
 >> iter 37000, loss: 12.900618
 >> iter 38000, loss: 12.362275
 >> iter 39000, loss: 11.713203
 >> iter 40000, loss: 11.369396
   Number of active neurons: 10
 >> iter 41000, loss: 11.051111
 >> iter 42000, loss: 10.959002
 >> iter 43000, loss: 10.788272
 >> iter 44000, loss: 10.769054
 >> iter 45000, loss: 10.636056
 >> iter 46000, loss: 10.611062
 >> iter 47000, loss: 10.439439
 >> iter 48000, loss: 10.319419
 >> iter 49000, loss: 10.114289
 >> iter 50000, loss: 10.005642
   Number of active neurons: 10
 >> iter 51000, loss: 9.795828
 >> iter 52000, loss: 9.787110
 >> iter 53000, loss: 9.512815
 >> iter 54000, loss: 9.507233
 >> iter 55000, loss: 9.269447
 >> iter 56000, loss: 9.412280
 >> iter 57000, loss: 9.217418
 >> iter 58000, loss: 9.258041
 >> iter 59000, loss: 8.913576
 >> iter 60000, loss: 8.797819
   Number of active neurons: 10
 >> iter 61000, loss: 8.052563
 >> iter 62000, loss: 7.871454
 >> iter 63000, loss: 7.329454
 >> iter 64000, loss: 7.190338
 >> iter 65000, loss: 6.759487
 >> iter 66000, loss: 6.843327
 >> iter 67000, loss: 6.589026
 >> iter 68000, loss: 6.663475
 >> iter 69000, loss: 6.521183
 >> iter 70000, loss: 6.359835
   Number of active neurons: 10
 >> iter 71000, loss: 6.252434
 >> iter 72000, loss: 6.647102
 >> iter 73000, loss: 6.386222
 >> iter 74000, loss: 6.552785
 >> iter 75000, loss: 6.431309
 >> iter 76000, loss: 6.482116
 >> iter 77000, loss: 6.445080
 >> iter 78000, loss: 6.227639
 >> iter 79000, loss: 5.870902
 >> iter 80000, loss: 5.896978
   Number of active neurons: 10
 >> iter 81000, loss: 6.025500
 >> iter 82000, loss: 6.362811
 >> iter 83000, loss: 6.098014
 >> iter 84000, loss: 6.464145
 >> iter 85000, loss: 6.203868
 >> iter 86000, loss: 6.217285
 >> iter 87000, loss: 6.175981
 >> iter 88000, loss: 6.528358
 >> iter 89000, loss: 6.319406
 >> iter 90000, loss: 6.469293
   Number of active neurons: 10
 >> iter 91000, loss: 6.317467
 >> iter 92000, loss: 6.454475
 >> iter 93000, loss: 6.663392
 >> iter 94000, loss: 7.458726
 >> iter 95000, loss: 6.514528
 >> iter 96000, loss: 5.968110
 >> iter 97000, loss: 5.101808
 >> iter 98000, loss: 4.676654
 >> iter 99000, loss: 4.478154
 >> iter 100000, loss: 4.420203
   Number of active neurons: 10
 >> iter 101000, loss: 3.925892
 >> iter 102000, loss: 4.501877
 >> iter 103000, loss: 3.582274
 >> iter 104000, loss: 3.701899
 >> iter 105000, loss: 3.952528
 >> iter 106000, loss: 3.820685
 >> iter 107000, loss: 3.159444
 >> iter 108000, loss: 2.632158
 >> iter 109000, loss: 2.166686
 >> iter 110000, loss: 1.856606
   Number of active neurons: 10
 >> iter 111000, loss: 1.802207
 >> iter 112000, loss: 1.823098
 >> iter 113000, loss: 1.650791
 >> iter 114000, loss: 1.674323
 >> iter 115000, loss: 1.639579
 >> iter 116000, loss: 1.455005
 >> iter 117000, loss: 1.289264
 >> iter 118000, loss: 1.119276
 >> iter 119000, loss: 1.924782
 >> iter 120000, loss: 1.283487
   Number of active neurons: 10
 >> iter 121000, loss: 1.021479
 >> iter 122000, loss: 0.822697
 >> iter 123000, loss: 0.876281
 >> iter 124000, loss: 1.134578
 >> iter 125000, loss: 0.852951
 >> iter 126000, loss: 0.919993
 >> iter 127000, loss: 0.916137
 >> iter 128000, loss: 0.785180
 >> iter 129000, loss: 0.948966
 >> iter 130000, loss: 0.888465
   Number of active neurons: 10
 >> iter 131000, loss: 0.714459
 >> iter 132000, loss: 0.804026
 >> iter 133000, loss: 0.624770
 >> iter 134000, loss: 0.560731
 >> iter 135000, loss: 0.836859
 >> iter 136000, loss: 0.712788
 >> iter 137000, loss: 0.550177
 >> iter 138000, loss: 0.524967
 >> iter 139000, loss: 0.474022
 >> iter 140000, loss: 0.453877
   Number of active neurons: 10
 >> iter 141000, loss: 0.390245
 >> iter 142000, loss: 0.531448
 >> iter 143000, loss: 0.450442
 >> iter 144000, loss: 0.493322
 >> iter 145000, loss: 0.259603
 >> iter 146000, loss: 0.351245
 >> iter 147000, loss: 0.383175
 >> iter 148000, loss: 0.527222
 >> iter 149000, loss: 0.436951
 >> iter 150000, loss: 0.363903
   Number of active neurons: 10
 >> iter 151000, loss: 0.407799
 >> iter 152000, loss: 0.558243
 >> iter 153000, loss: 0.446801
 >> iter 154000, loss: 0.356358
 >> iter 155000, loss: 0.181616
 >> iter 156000, loss: 0.256548
 >> iter 157000, loss: 0.216557
 >> iter 158000, loss: 0.330062
 >> iter 159000, loss: 0.914147
 >> iter 160000, loss: 0.591520
   Number of active neurons: 10
 >> iter 161000, loss: 0.397489
 >> iter 162000, loss: 0.392262
 >> iter 163000, loss: 0.254177
 >> iter 164000, loss: 0.348903
 >> iter 165000, loss: 0.243040
 >> iter 166000, loss: 0.138421
 >> iter 167000, loss: 0.324700
 >> iter 168000, loss: 0.424845
 >> iter 169000, loss: 0.291596
 >> iter 170000, loss: 0.355681
   Number of active neurons: 10
 >> iter 171000, loss: 0.315255
 >> iter 172000, loss: 0.260980
 >> iter 173000, loss: 0.123464
 >> iter 174000, loss: 0.359921
 >> iter 175000, loss: 0.281494
 >> iter 176000, loss: 0.245370
 >> iter 177000, loss: 0.360234
 >> iter 178000, loss: 0.489732
 >> iter 179000, loss: 0.421234
 >> iter 180000, loss: 0.866776
   Number of active neurons: 10
 >> iter 181000, loss: 0.432254
 >> iter 182000, loss: 0.437239
 >> iter 183000, loss: 0.377121
 >> iter 184000, loss: 1.088212
 >> iter 185000, loss: 0.635606
 >> iter 186000, loss: 0.750006
 >> iter 187000, loss: 0.543935
 >> iter 188000, loss: 0.382350
 >> iter 189000, loss: 0.455213
 >> iter 190000, loss: 0.295473
   Number of active neurons: 10
 >> iter 191000, loss: 0.255971
 >> iter 192000, loss: 0.326758
 >> iter 193000, loss: 0.210784
 >> iter 194000, loss: 0.266101
 >> iter 195000, loss: 0.245084
 >> iter 196000, loss: 0.168561
 >> iter 197000, loss: 0.146313
 >> iter 198000, loss: 0.087624
 >> iter 199000, loss: 0.323356
 >> iter 200000, loss: 0.346022
   Number of active neurons: 10
 >> iter 201000, loss: 0.419166
 >> iter 202000, loss: 0.391486
 >> iter 203000, loss: 0.366425
 >> iter 204000, loss: 0.270586
 >> iter 205000, loss: 0.325888
 >> iter 206000, loss: 0.144588
 >> iter 207000, loss: 0.277965
 >> iter 208000, loss: 0.299572
 >> iter 209000, loss: 0.346937
 >> iter 210000, loss: 0.241951
   Number of active neurons: 10
 >> iter 211000, loss: 0.383360
 >> iter 212000, loss: 0.229633
 >> iter 213000, loss: 0.249623
 >> iter 214000, loss: 0.388376
 >> iter 215000, loss: 0.377336
 >> iter 216000, loss: 0.611279
 >> iter 217000, loss: 0.374673
 >> iter 218000, loss: 0.656515
 >> iter 219000, loss: 0.431313
 >> iter 220000, loss: 0.354478
   Number of active neurons: 10
 >> iter 221000, loss: 0.260476
 >> iter 222000, loss: 0.193301
 >> iter 223000, loss: 0.372265
 >> iter 224000, loss: 0.228365
 >> iter 225000, loss: 0.315128
 >> iter 226000, loss: 0.369513
 >> iter 227000, loss: 0.285350
 >> iter 228000, loss: 0.325558
 >> iter 229000, loss: 0.168298
 >> iter 230000, loss: 0.357868
   Number of active neurons: 10
 >> iter 231000, loss: 0.208427
 >> iter 232000, loss: 0.278483
 >> iter 233000, loss: 0.297251
 >> iter 234000, loss: 0.210926
 >> iter 235000, loss: 0.106273
 >> iter 236000, loss: 0.110321
 >> iter 237000, loss: 0.206584
 >> iter 238000, loss: 0.263342
 >> iter 239000, loss: 0.247047
 >> iter 240000, loss: 0.141402
   Number of active neurons: 10
 >> iter 241000, loss: 0.204294
 >> iter 242000, loss: 0.194400
 >> iter 243000, loss: 0.128954
 >> iter 244000, loss: 0.343529
 >> iter 245000, loss: 0.206907
 >> iter 246000, loss: 0.241897
 >> iter 247000, loss: 0.181260
 >> iter 248000, loss: 0.193034
 >> iter 249000, loss: 0.207950
 >> iter 250000, loss: 0.166361
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0279994400112
   - Test - Long: 0.0
   - Test - Big: 0.10099899001
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 19.071343
 >> iter 2000, loss: 15.549996
 >> iter 3000, loss: 14.061861
 >> iter 4000, loss: 13.468725
 >> iter 5000, loss: 13.239358
 >> iter 6000, loss: 13.164781
 >> iter 7000, loss: 13.110080
 >> iter 8000, loss: 13.094164
 >> iter 9000, loss: 13.066660
 >> iter 10000, loss: 13.075867
   Number of active neurons: 10
 >> iter 11000, loss: 13.054065
 >> iter 12000, loss: 13.058688
 >> iter 13000, loss: 13.026850
 >> iter 14000, loss: 13.033928
 >> iter 15000, loss: 13.030011
 >> iter 16000, loss: 13.032688
 >> iter 17000, loss: 13.021805
 >> iter 18000, loss: 13.032795
 >> iter 19000, loss: 13.018920
 >> iter 20000, loss: 13.020937
   Number of active neurons: 10
 >> iter 21000, loss: 13.009360
 >> iter 22000, loss: 13.010937
 >> iter 23000, loss: 13.000477
 >> iter 24000, loss: 13.011483
 >> iter 25000, loss: 13.000234
 >> iter 26000, loss: 13.005670
 >> iter 27000, loss: 12.989303
 >> iter 28000, loss: 12.994595
 >> iter 29000, loss: 12.982131
 >> iter 30000, loss: 12.992164
   Number of active neurons: 10
 >> iter 31000, loss: 12.973677
 >> iter 32000, loss: 12.870459
 >> iter 33000, loss: 12.158684
 >> iter 34000, loss: 11.645767
 >> iter 35000, loss: 11.249029
 >> iter 36000, loss: 11.144232
 >> iter 37000, loss: 10.960425
 >> iter 38000, loss: 10.976384
 >> iter 39000, loss: 10.826418
 >> iter 40000, loss: 10.816386
   Number of active neurons: 10
 >> iter 41000, loss: 10.667112
 >> iter 42000, loss: 10.671813
 >> iter 43000, loss: 10.519495
 >> iter 44000, loss: 10.536529
 >> iter 45000, loss: 10.411648
 >> iter 46000, loss: 10.377985
 >> iter 47000, loss: 10.173139
 >> iter 48000, loss: 10.022808
 >> iter 49000, loss: 9.693582
 >> iter 50000, loss: 9.432709
   Number of active neurons: 10
 >> iter 51000, loss: 9.209195
 >> iter 52000, loss: 9.187501
 >> iter 53000, loss: 8.979201
 >> iter 54000, loss: 9.006591
 >> iter 55000, loss: 8.897706
 >> iter 56000, loss: 8.962007
 >> iter 57000, loss: 8.829723
 >> iter 58000, loss: 8.879531
 >> iter 59000, loss: 8.791385
 >> iter 60000, loss: 8.829017
   Number of active neurons: 10
 >> iter 61000, loss: 8.752124
 >> iter 62000, loss: 8.818338
 >> iter 63000, loss: 8.717273
 >> iter 64000, loss: 8.822522
 >> iter 65000, loss: 8.701946
 >> iter 66000, loss: 8.623024
 >> iter 67000, loss: 7.817575
 >> iter 68000, loss: 7.653314
 >> iter 69000, loss: 7.336460
 >> iter 70000, loss: 7.365223
   Number of active neurons: 10
 >> iter 71000, loss: 7.238931
 >> iter 72000, loss: 7.350268
 >> iter 73000, loss: 7.156373
 >> iter 74000, loss: 7.282256
 >> iter 75000, loss: 7.155968
 >> iter 76000, loss: 7.250904
 >> iter 77000, loss: 7.169259
 >> iter 78000, loss: 7.259851
 >> iter 79000, loss: 7.164085
 >> iter 80000, loss: 7.346234
   Number of active neurons: 10
 >> iter 81000, loss: 7.129987
 >> iter 82000, loss: 7.213888
 >> iter 83000, loss: 7.097749
 >> iter 84000, loss: 7.232670
 >> iter 85000, loss: 7.115934
 >> iter 86000, loss: 7.212444
 >> iter 87000, loss: 7.111828
 >> iter 88000, loss: 7.258672
 >> iter 89000, loss: 7.141825
 >> iter 90000, loss: 7.220327
   Number of active neurons: 10
 >> iter 91000, loss: 7.188700
 >> iter 92000, loss: 7.213637
 >> iter 93000, loss: 7.082807
 >> iter 94000, loss: 7.170541
 >> iter 95000, loss: 7.059264
 >> iter 96000, loss: 7.156714
 >> iter 97000, loss: 7.063882
 >> iter 98000, loss: 7.138937
 >> iter 99000, loss: 7.056164
 >> iter 100000, loss: 7.132013
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 13.8817223656
   - Test - Long: 30.4784760762
   - Test - Big: 13.9818601814
   - Test - A: 7.99946670222
   - Test - B: 31.6112259183
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.062426
 >> iter 2000, loss: 15.516565
 >> iter 3000, loss: 14.083054
 >> iter 4000, loss: 13.500567
 >> iter 5000, loss: 13.266831
 >> iter 6000, loss: 13.163349
 >> iter 7000, loss: 13.103171
 >> iter 8000, loss: 13.082954
 >> iter 9000, loss: 13.068262
 >> iter 10000, loss: 13.071765
   Number of active neurons: 10
 >> iter 11000, loss: 13.055437
 >> iter 12000, loss: 13.053343
 >> iter 13000, loss: 13.044584
 >> iter 14000, loss: 13.054989
 >> iter 15000, loss: 13.042477
 >> iter 16000, loss: 13.050633
 >> iter 17000, loss: 13.036115
 >> iter 18000, loss: 13.029527
 >> iter 19000, loss: 13.013152
 >> iter 20000, loss: 13.019069
   Number of active neurons: 10
 >> iter 21000, loss: 13.010942
 >> iter 22000, loss: 13.024480
 >> iter 23000, loss: 13.010411
 >> iter 24000, loss: 13.019753
 >> iter 25000, loss: 12.996309
 >> iter 26000, loss: 13.009379
 >> iter 27000, loss: 12.996131
 >> iter 28000, loss: 13.005362
 >> iter 29000, loss: 12.993955
 >> iter 30000, loss: 13.012205
   Number of active neurons: 10
 >> iter 31000, loss: 12.997282
 >> iter 32000, loss: 13.006145
 >> iter 33000, loss: 12.999372
 >> iter 34000, loss: 13.009137
 >> iter 35000, loss: 12.999870
 >> iter 36000, loss: 13.005546
 >> iter 37000, loss: 12.994608
 >> iter 38000, loss: 13.005849
 >> iter 39000, loss: 12.990929
 >> iter 40000, loss: 13.003363
   Number of active neurons: 10
 >> iter 41000, loss: 12.987733
 >> iter 42000, loss: 12.999649
 >> iter 43000, loss: 12.987382
 >> iter 44000, loss: 13.012654
 >> iter 45000, loss: 12.990929
 >> iter 46000, loss: 13.011573
 >> iter 47000, loss: 12.987735
 >> iter 48000, loss: 13.007159
 >> iter 49000, loss: 12.987594
 >> iter 50000, loss: 13.009163
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 8
 >> iter 51000, loss: 12.985493
 >> iter 52000, loss: 13.010037
 >> iter 53000, loss: 12.981988
 >> iter 54000, loss: 13.005896
 >> iter 55000, loss: 12.982554
 >> iter 56000, loss: 13.007569
 >> iter 57000, loss: 12.983153
 >> iter 58000, loss: 13.012187
 >> iter 59000, loss: 12.982843
 >> iter 60000, loss: 13.009609
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 9
 >> iter 61000, loss: 12.986332
 >> iter 62000, loss: 13.014644
 >> iter 63000, loss: 12.984993
 >> iter 64000, loss: 13.010365
 >> iter 65000, loss: 12.982109
 >> iter 66000, loss: 13.008893
 >> iter 67000, loss: 12.984641
 >> iter 68000, loss: 13.009802
 >> iter 69000, loss: 12.981428
 >> iter 70000, loss: 12.996519
   Number of active neurons: 9
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 9
 >> iter 71000, loss: 12.960480
 >> iter 72000, loss: 12.941230
 >> iter 73000, loss: 12.886657
 >> iter 74000, loss: 12.844978
 >> iter 75000, loss: 12.762356
 >> iter 76000, loss: 12.602050
 >> iter 77000, loss: 11.951548
 >> iter 78000, loss: 11.565907
 >> iter 79000, loss: 11.240054
 >> iter 80000, loss: 11.146704
   Number of active neurons: 10
 >> iter 81000, loss: 10.878236
 >> iter 82000, loss: 10.757514
 >> iter 83000, loss: 10.598319
 >> iter 84000, loss: 10.538743
 >> iter 85000, loss: 10.396720
 >> iter 86000, loss: 10.441543
 >> iter 87000, loss: 10.157986
 >> iter 88000, loss: 9.828379
 >> iter 89000, loss: 9.442320
 >> iter 90000, loss: 9.354027
   Number of active neurons: 10
 >> iter 91000, loss: 8.416537
 >> iter 92000, loss: 7.421515
 >> iter 93000, loss: 6.090550
 >> iter 94000, loss: 4.452322
 >> iter 95000, loss: 3.626843
 >> iter 96000, loss: 3.178805
 >> iter 97000, loss: 2.423318
 >> iter 98000, loss: 1.883920
 >> iter 99000, loss: 1.849010
 >> iter 100000, loss: 2.078063
   Number of active neurons: 10
 >> iter 101000, loss: 1.669950
 >> iter 102000, loss: 1.628284
 >> iter 103000, loss: 1.727219
 >> iter 104000, loss: 1.576358
 >> iter 105000, loss: 1.392109
 >> iter 106000, loss: 1.614258
 >> iter 107000, loss: 1.350494
 >> iter 108000, loss: 1.300500
 >> iter 109000, loss: 1.182069
 >> iter 110000, loss: 1.017402
   Number of active neurons: 10
 >> iter 111000, loss: 0.909465
 >> iter 112000, loss: 0.943373
 >> iter 113000, loss: 0.901964
 >> iter 114000, loss: 1.086042
 >> iter 115000, loss: 0.965614
 >> iter 116000, loss: 1.021614
 >> iter 117000, loss: 0.949575
 >> iter 118000, loss: 0.821252
 >> iter 119000, loss: 0.769362
 >> iter 120000, loss: 1.303843
   Number of active neurons: 10
 >> iter 121000, loss: 1.072317
 >> iter 122000, loss: 1.159264
 >> iter 123000, loss: 1.014452
 >> iter 124000, loss: 0.798983
 >> iter 125000, loss: 0.779040
 >> iter 126000, loss: 2.730311
 >> iter 127000, loss: 1.465189
 >> iter 128000, loss: 1.086706
 >> iter 129000, loss: 0.878735
 >> iter 130000, loss: 0.636914
   Number of active neurons: 10
 >> iter 131000, loss: 0.668810
 >> iter 132000, loss: 0.445071
 >> iter 133000, loss: 0.565587
 >> iter 134000, loss: 0.611611
 >> iter 135000, loss: 0.613403
 >> iter 136000, loss: 0.508337
 >> iter 137000, loss: 0.525755
 >> iter 138000, loss: 0.482500
 >> iter 139000, loss: 0.768907
 >> iter 140000, loss: 0.563212
   Number of active neurons: 10
 >> iter 141000, loss: 0.562623
 >> iter 142000, loss: 0.563283
 >> iter 143000, loss: 0.370556
 >> iter 144000, loss: 0.317857
 >> iter 145000, loss: 0.338068
 >> iter 146000, loss: 0.538532
 >> iter 147000, loss: 0.418795
 >> iter 148000, loss: 0.401696
 >> iter 149000, loss: 0.541343
 >> iter 150000, loss: 0.528404
   Number of active neurons: 10
 >> iter 151000, loss: 0.579583
 >> iter 152000, loss: 0.399203
 >> iter 153000, loss: 0.434872
 >> iter 154000, loss: 0.536145
 >> iter 155000, loss: 0.444553
 >> iter 156000, loss: 0.481628
 >> iter 157000, loss: 0.614948
 >> iter 158000, loss: 0.440741
 >> iter 159000, loss: 0.509639
 >> iter 160000, loss: 0.377462
   Number of active neurons: 10
 >> iter 161000, loss: 0.454343
 >> iter 162000, loss: 0.408123
 >> iter 163000, loss: 0.271292
 >> iter 164000, loss: 0.359897
 >> iter 165000, loss: 0.364784
 >> iter 166000, loss: 0.234561
 >> iter 167000, loss: 0.208739
 >> iter 168000, loss: 0.240279
 >> iter 169000, loss: 0.438186
 >> iter 170000, loss: 0.411632
   Number of active neurons: 10
 >> iter 171000, loss: 0.370099
 >> iter 172000, loss: 0.247986
 >> iter 173000, loss: 0.327743
 >> iter 174000, loss: 0.418493
 >> iter 175000, loss: 0.352170
 >> iter 176000, loss: 0.286625
 >> iter 177000, loss: 0.618282
 >> iter 178000, loss: 0.491618
 >> iter 179000, loss: 0.335982
 >> iter 180000, loss: 0.147492
   Number of active neurons: 10
 >> iter 181000, loss: 0.364635
 >> iter 182000, loss: 0.293578
 >> iter 183000, loss: 0.465702
 >> iter 184000, loss: 0.420291
 >> iter 185000, loss: 0.217897
 >> iter 186000, loss: 0.391691
 >> iter 187000, loss: 0.233259
 >> iter 188000, loss: 0.127632
 >> iter 189000, loss: 0.134114
 >> iter 190000, loss: 0.157445
   Number of active neurons: 10
 >> iter 191000, loss: 0.197097
 >> iter 192000, loss: 0.198066
 >> iter 193000, loss: 0.136771
 >> iter 194000, loss: 0.225996
 >> iter 195000, loss: 0.176119
 >> iter 196000, loss: 0.136380
 >> iter 197000, loss: 0.264686
 >> iter 198000, loss: 0.220917
 >> iter 199000, loss: 0.180463
 >> iter 200000, loss: 0.388490
   Number of active neurons: 10
 >> iter 201000, loss: 0.273110
 >> iter 202000, loss: 0.357761
 >> iter 203000, loss: 0.232981
 >> iter 204000, loss: 0.258238
 >> iter 205000, loss: 0.201744
 >> iter 206000, loss: 0.532427
 >> iter 207000, loss: 0.331978
 >> iter 208000, loss: 0.216791
 >> iter 209000, loss: 0.162584
 >> iter 210000, loss: 0.275098
   Number of active neurons: 10
 >> iter 211000, loss: 0.242791
 >> iter 212000, loss: 0.294846
 >> iter 213000, loss: 0.161092
 >> iter 214000, loss: 0.117822
 >> iter 215000, loss: 0.192121
 >> iter 216000, loss: 0.189919
 >> iter 217000, loss: 0.242797
 >> iter 218000, loss: 0.215947
 >> iter 219000, loss: 0.328692
 >> iter 220000, loss: 0.278251
   Number of active neurons: 10
 >> iter 221000, loss: 0.190748
 >> iter 222000, loss: 0.268761
 >> iter 223000, loss: 0.128324
 >> iter 224000, loss: 0.170692
 >> iter 225000, loss: 0.224432
 >> iter 226000, loss: 0.325441
 >> iter 227000, loss: 0.183842
 >> iter 228000, loss: 0.101754
 >> iter 229000, loss: 0.095050
 >> iter 230000, loss: 0.091629
   Number of active neurons: 10
 >> iter 231000, loss: 0.074017
 >> iter 232000, loss: 0.255317
 >> iter 233000, loss: 0.212703
 >> iter 234000, loss: 0.489413
 >> iter 235000, loss: 0.255249
 >> iter 236000, loss: 0.273781
 >> iter 237000, loss: 0.195015
 >> iter 238000, loss: 0.290103
 >> iter 239000, loss: 0.198547
 >> iter 240000, loss: 0.177594
   Number of active neurons: 10
 >> iter 241000, loss: 0.170346
 >> iter 242000, loss: 0.133011
 >> iter 243000, loss: 0.105754
 >> iter 244000, loss: 0.107170
 >> iter 245000, loss: 0.192757
 >> iter 246000, loss: 0.134797
 >> iter 247000, loss: 0.184649
 >> iter 248000, loss: 0.103457
 >> iter 249000, loss: 0.088485
 >> iter 250000, loss: 0.301192
   Number of active neurons: 10
 >> iter 251000, loss: 0.291436
 >> iter 252000, loss: 0.210852
 >> iter 253000, loss: 0.155057
 >> iter 254000, loss: 0.185200
 >> iter 255000, loss: 0.101980
 >> iter 256000, loss: 0.172893
 >> iter 257000, loss: 0.401142
 >> iter 258000, loss: 0.410745
 >> iter 259000, loss: 0.251929
 >> iter 260000, loss: 0.173657
   Number of active neurons: 10
 >> iter 261000, loss: 0.339887
 >> iter 262000, loss: 0.191629
 >> iter 263000, loss: 0.133128
 >> iter 264000, loss: 0.085607
 >> iter 265000, loss: 0.145112
 >> iter 266000, loss: 0.276828
 >> iter 267000, loss: 0.160235
 >> iter 268000, loss: 0.214909
 >> iter 269000, loss: 0.142685
 >> iter 270000, loss: 0.260039
   Number of active neurons: 10
 >> iter 271000, loss: 0.274085
 >> iter 272000, loss: 0.164902
 >> iter 273000, loss: 0.198307
 >> iter 274000, loss: 0.157112
 >> iter 275000, loss: 0.338844
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 19.096670
 >> iter 2000, loss: 15.536212
 >> iter 3000, loss: 14.070665
 >> iter 4000, loss: 13.481177
 >> iter 5000, loss: 13.240133
 >> iter 6000, loss: 13.145922
 >> iter 7000, loss: 13.094285
 >> iter 8000, loss: 13.079468
 >> iter 9000, loss: 13.050679
 >> iter 10000, loss: 13.041870
   Number of active neurons: 10
 >> iter 11000, loss: 13.028810
 >> iter 12000, loss: 13.031714
 >> iter 13000, loss: 13.012273
 >> iter 14000, loss: 13.017204
 >> iter 15000, loss: 13.006292
 >> iter 16000, loss: 13.018605
 >> iter 17000, loss: 13.004681
 >> iter 18000, loss: 13.012512
 >> iter 19000, loss: 12.998728
 >> iter 20000, loss: 13.008223
   Number of active neurons: 10
 >> iter 21000, loss: 12.984885
 >> iter 22000, loss: 13.003520
 >> iter 23000, loss: 12.986676
 >> iter 24000, loss: 13.005156
 >> iter 25000, loss: 12.987870
 >> iter 26000, loss: 12.996970
 >> iter 27000, loss: 12.982764
 >> iter 28000, loss: 13.000516
 >> iter 29000, loss: 12.982303
 >> iter 30000, loss: 12.991362
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 12.984149
 >> iter 32000, loss: 13.006484
 >> iter 33000, loss: 12.992776
 >> iter 34000, loss: 12.996834
 >> iter 35000, loss: 12.987436
 >> iter 36000, loss: 12.985928
 >> iter 37000, loss: 12.974141
 >> iter 38000, loss: 12.987380
 >> iter 39000, loss: 12.980556
 >> iter 40000, loss: 12.989459
   Number of active neurons: 10
 >> iter 41000, loss: 12.975687
 >> iter 42000, loss: 12.989842
 >> iter 43000, loss: 12.963351
 >> iter 44000, loss: 12.965318
 >> iter 45000, loss: 12.910783
 >> iter 46000, loss: 12.850277
 >> iter 47000, loss: 12.218493
 >> iter 48000, loss: 11.724005
 >> iter 49000, loss: 11.293851
 >> iter 50000, loss: 11.167211
   Number of active neurons: 10
 >> iter 51000, loss: 10.983160
 >> iter 52000, loss: 10.983055
 >> iter 53000, loss: 10.831016
 >> iter 54000, loss: 10.874971
 >> iter 55000, loss: 10.768765
 >> iter 56000, loss: 10.784778
 >> iter 57000, loss: 10.590291
 >> iter 58000, loss: 10.559248
 >> iter 59000, loss: 10.249776
 >> iter 60000, loss: 10.080695
   Number of active neurons: 10
 >> iter 61000, loss: 9.743856
 >> iter 62000, loss: 9.662723
 >> iter 63000, loss: 9.270524
 >> iter 64000, loss: 8.870814
 >> iter 65000, loss: 8.619471
 >> iter 66000, loss: 8.595589
 >> iter 67000, loss: 8.505847
 >> iter 68000, loss: 8.200703
 >> iter 69000, loss: 8.099236
 >> iter 70000, loss: 7.971259
   Number of active neurons: 10
 >> iter 71000, loss: 7.802748
 >> iter 72000, loss: 7.862796
 >> iter 73000, loss: 7.667653
 >> iter 74000, loss: 7.732619
 >> iter 75000, loss: 7.605716
 >> iter 76000, loss: 7.426520
 >> iter 77000, loss: 6.874616
 >> iter 78000, loss: 6.618317
 >> iter 79000, loss: 5.325368
 >> iter 80000, loss: 4.383561
   Number of active neurons: 10
 >> iter 81000, loss: 3.902347
 >> iter 82000, loss: 3.970899
 >> iter 83000, loss: 3.641597
 >> iter 84000, loss: 3.480442
 >> iter 85000, loss: 2.922567
 >> iter 86000, loss: 2.408881
 >> iter 87000, loss: 2.077574
 >> iter 88000, loss: 1.970813
 >> iter 89000, loss: 1.942713
 >> iter 90000, loss: 2.074766
   Number of active neurons: 10
 >> iter 91000, loss: 1.739803
 >> iter 92000, loss: 1.456637
 >> iter 93000, loss: 1.307593
 >> iter 94000, loss: 1.616153
 >> iter 95000, loss: 1.333040
 >> iter 96000, loss: 1.199047
 >> iter 97000, loss: 1.171612
 >> iter 98000, loss: 1.491520
 >> iter 99000, loss: 1.382831
 >> iter 100000, loss: 1.050853
   Number of active neurons: 10
 >> iter 101000, loss: 0.774840
 >> iter 102000, loss: 1.188026
 >> iter 103000, loss: 1.194245
 >> iter 104000, loss: 1.251975
 >> iter 105000, loss: 0.843862
 >> iter 106000, loss: 0.801143
 >> iter 107000, loss: 1.192790
 >> iter 108000, loss: 1.458742
 >> iter 109000, loss: 0.925279
 >> iter 110000, loss: 0.889998
   Number of active neurons: 10
 >> iter 111000, loss: 0.999867
 >> iter 112000, loss: 0.707291
 >> iter 113000, loss: 0.567520
 >> iter 114000, loss: 0.512997
 >> iter 115000, loss: 0.442367
 >> iter 116000, loss: 0.672305
 >> iter 117000, loss: 0.445144
 >> iter 118000, loss: 0.573306
 >> iter 119000, loss: 0.509899
 >> iter 120000, loss: 0.438852
   Number of active neurons: 10
 >> iter 121000, loss: 0.438814
 >> iter 122000, loss: 0.489012
 >> iter 123000, loss: 0.747455
 >> iter 124000, loss: 0.650145
 >> iter 125000, loss: 0.446720
 >> iter 126000, loss: 0.400159
 >> iter 127000, loss: 0.422755
 >> iter 128000, loss: 0.593554
 >> iter 129000, loss: 0.377457
 >> iter 130000, loss: 0.492740
   Number of active neurons: 10
 >> iter 131000, loss: 0.344751
 >> iter 132000, loss: 0.369835
 >> iter 133000, loss: 0.332294
 >> iter 134000, loss: 0.326535
 >> iter 135000, loss: 0.377959
 >> iter 136000, loss: 0.453388
 >> iter 137000, loss: 0.346589
 >> iter 138000, loss: 0.488986
 >> iter 139000, loss: 0.385883
 >> iter 140000, loss: 0.370301
   Number of active neurons: 10
 >> iter 141000, loss: 0.514236
 >> iter 142000, loss: 0.454967
 >> iter 143000, loss: 0.628496
 >> iter 144000, loss: 0.658115
 >> iter 145000, loss: 0.485833
 >> iter 146000, loss: 0.653543
 >> iter 147000, loss: 0.587954
 >> iter 148000, loss: 0.561924
 >> iter 149000, loss: 0.442399
 >> iter 150000, loss: 0.530732
   Number of active neurons: 10
 >> iter 151000, loss: 0.603797
 >> iter 152000, loss: 0.434632
 >> iter 153000, loss: 0.246106
 >> iter 154000, loss: 0.248999
 >> iter 155000, loss: 0.347988
 >> iter 156000, loss: 0.541844
 >> iter 157000, loss: 0.420022
 >> iter 158000, loss: 0.367474
 >> iter 159000, loss: 0.404139
 >> iter 160000, loss: 0.266405
   Number of active neurons: 10
 >> iter 161000, loss: 0.142883
 >> iter 162000, loss: 0.093978
 >> iter 163000, loss: 0.194206
 >> iter 164000, loss: 0.313653
 >> iter 165000, loss: 0.192440
 >> iter 166000, loss: 0.132444
 >> iter 167000, loss: 1.017097
 >> iter 168000, loss: 0.678212
 >> iter 169000, loss: 0.375800
 >> iter 170000, loss: 0.246727
   Number of active neurons: 10
 >> iter 171000, loss: 0.211537
 >> iter 172000, loss: 0.197548
 >> iter 173000, loss: 0.134784
 >> iter 174000, loss: 0.354386
 >> iter 175000, loss: 0.273326
 >> iter 176000, loss: 0.166883
 >> iter 177000, loss: 0.130786
 >> iter 178000, loss: 0.159370
 >> iter 179000, loss: 0.266077
 >> iter 180000, loss: 0.194833
   Number of active neurons: 10
 >> iter 181000, loss: 0.145374
 >> iter 182000, loss: 0.136382
 >> iter 183000, loss: 0.115909
 >> iter 184000, loss: 0.111244
 >> iter 185000, loss: 0.285003
 >> iter 186000, loss: 0.187952
 >> iter 187000, loss: 0.153809
 >> iter 188000, loss: 0.221836
 >> iter 189000, loss: 0.317809
 >> iter 190000, loss: 0.416647
   Number of active neurons: 10
 >> iter 191000, loss: 0.428440
 >> iter 192000, loss: 0.430561
 >> iter 193000, loss: 0.254498
 >> iter 194000, loss: 0.121292
 >> iter 195000, loss: 0.145072
 >> iter 196000, loss: 0.180604
 >> iter 197000, loss: 0.291302
 >> iter 198000, loss: 0.218076
 >> iter 199000, loss: 0.133621
 >> iter 200000, loss: 0.250723
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455162
   Number of active neurons: 0
 >> iter 1000, loss: 19.013083
 >> iter 2000, loss: 15.555050
 >> iter 3000, loss: 14.085399
 >> iter 4000, loss: 13.520115
 >> iter 5000, loss: 13.268106
 >> iter 6000, loss: 13.157793
 >> iter 7000, loss: 13.110757
 >> iter 8000, loss: 13.097482
 >> iter 9000, loss: 13.073537
 >> iter 10000, loss: 13.070210
   Number of active neurons: 10
 >> iter 11000, loss: 13.052977
 >> iter 12000, loss: 13.062792
 >> iter 13000, loss: 13.046146
 >> iter 14000, loss: 13.047064
 >> iter 15000, loss: 13.026065
 >> iter 16000, loss: 13.040926
 >> iter 17000, loss: 13.020002
 >> iter 18000, loss: 13.021896
 >> iter 19000, loss: 13.017214
 >> iter 20000, loss: 13.042311
   Number of active neurons: 10
 >> iter 21000, loss: 13.027208
 >> iter 22000, loss: 13.028046
 >> iter 23000, loss: 13.017699
 >> iter 24000, loss: 13.028472
 >> iter 25000, loss: 13.014403
 >> iter 26000, loss: 13.025136
 >> iter 27000, loss: 13.007039
 >> iter 28000, loss: 13.013831
 >> iter 29000, loss: 12.996401
 >> iter 30000, loss: 13.008544
   Number of active neurons: 10
 >> iter 31000, loss: 12.996331
 >> iter 32000, loss: 13.008533
 >> iter 33000, loss: 12.993273
 >> iter 34000, loss: 13.001173
 >> iter 35000, loss: 12.984301
 >> iter 36000, loss: 13.001629
 >> iter 37000, loss: 12.988445
 >> iter 38000, loss: 13.004732
 >> iter 39000, loss: 12.986156
 >> iter 40000, loss: 13.000320
   Number of active neurons: 10
 >> iter 41000, loss: 12.973041
 >> iter 42000, loss: 12.997400
 >> iter 43000, loss: 12.974471
 >> iter 44000, loss: 12.998580
 >> iter 45000, loss: 12.972935
 >> iter 46000, loss: 13.001327
 >> iter 47000, loss: 12.976012
 >> iter 48000, loss: 12.956121
 >> iter 49000, loss: 12.502604
 >> iter 50000, loss: 11.856526
   Number of active neurons: 10
 >> iter 51000, loss: 11.350315
 >> iter 52000, loss: 11.165285
 >> iter 53000, loss: 10.946308
 >> iter 54000, loss: 10.922377
 >> iter 55000, loss: 10.746397
 >> iter 56000, loss: 10.714650
 >> iter 57000, loss: 10.502027
 >> iter 58000, loss: 10.478029
 >> iter 59000, loss: 10.279691
 >> iter 60000, loss: 10.258147
   Number of active neurons: 10
 >> iter 61000, loss: 10.089551
 >> iter 62000, loss: 10.096440
 >> iter 63000, loss: 9.924931
 >> iter 64000, loss: 9.948550
 >> iter 65000, loss: 9.773978
 >> iter 66000, loss: 9.879546
 >> iter 67000, loss: 9.680162
 >> iter 68000, loss: 9.731454
 >> iter 69000, loss: 9.533745
 >> iter 70000, loss: 9.474010
   Number of active neurons: 10
 >> iter 71000, loss: 9.546493
 >> iter 72000, loss: 9.541693
 >> iter 73000, loss: 9.382790
 >> iter 74000, loss: 9.358797
 >> iter 75000, loss: 9.208177
 >> iter 76000, loss: 9.173706
 >> iter 77000, loss: 9.019120
 >> iter 78000, loss: 9.035886
 >> iter 79000, loss: 8.862844
 >> iter 80000, loss: 8.958795
   Number of active neurons: 10
 >> iter 81000, loss: 8.777598
 >> iter 82000, loss: 8.822194
 >> iter 83000, loss: 8.690334
 >> iter 84000, loss: 8.805067
 >> iter 85000, loss: 8.695686
 >> iter 86000, loss: 8.650321
 >> iter 87000, loss: 8.276165
 >> iter 88000, loss: 8.363138
 >> iter 89000, loss: 8.038016
 >> iter 90000, loss: 7.816984
   Number of active neurons: 10
 >> iter 91000, loss: 7.418979
 >> iter 92000, loss: 7.258313
 >> iter 93000, loss: 6.992747
 >> iter 94000, loss: 7.109150
 >> iter 95000, loss: 6.877986
 >> iter 96000, loss: 6.831949
 >> iter 97000, loss: 6.738582
 >> iter 98000, loss: 6.624390
 >> iter 99000, loss: 6.401298
 >> iter 100000, loss: 6.664254
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 11.2117757645
   - Test - Long: 29.7035148243
   - Test - Big: 11.2018879811
   - Test - A: 7.74615025665
   - Test - B: 31.5912272515
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.131403
 >> iter 2000, loss: 15.521412
 >> iter 3000, loss: 14.050119
 >> iter 4000, loss: 13.467129
 >> iter 5000, loss: 13.228427
 >> iter 6000, loss: 13.134905
 >> iter 7000, loss: 13.093384
 >> iter 8000, loss: 13.080618
 >> iter 9000, loss: 13.060351
 >> iter 10000, loss: 13.055742
   Number of active neurons: 10
 >> iter 11000, loss: 13.044234
 >> iter 12000, loss: 13.046048
 >> iter 13000, loss: 13.027244
 >> iter 14000, loss: 13.034844
 >> iter 15000, loss: 13.027844
 >> iter 16000, loss: 13.037364
 >> iter 17000, loss: 13.024208
 >> iter 18000, loss: 13.033206
 >> iter 19000, loss: 13.024458
 >> iter 20000, loss: 13.034253
   Number of active neurons: 10
 >> iter 21000, loss: 13.021235
 >> iter 22000, loss: 13.031188
 >> iter 23000, loss: 13.023466
 >> iter 24000, loss: 13.038490
 >> iter 25000, loss: 13.017050
 >> iter 26000, loss: 13.025962
 >> iter 27000, loss: 13.017674
 >> iter 28000, loss: 13.028142
 >> iter 29000, loss: 13.012601
 >> iter 30000, loss: 13.025654
   Number of active neurons: 10
 >> iter 31000, loss: 13.013802
 >> iter 32000, loss: 13.018327
 >> iter 33000, loss: 13.012582
 >> iter 34000, loss: 13.016928
 >> iter 35000, loss: 13.005798
 >> iter 36000, loss: 12.999351
 >> iter 37000, loss: 12.985889
 >> iter 38000, loss: 12.974269
 >> iter 39000, loss: 12.929849
 >> iter 40000, loss: 12.868604
   Number of active neurons: 10
 >> iter 41000, loss: 12.786410
 >> iter 42000, loss: 12.201301
 >> iter 43000, loss: 11.561820
 >> iter 44000, loss: 11.275977
 >> iter 45000, loss: 11.024464
 >> iter 46000, loss: 10.969390
 >> iter 47000, loss: 10.811012
 >> iter 48000, loss: 10.822643
 >> iter 49000, loss: 10.676722
 >> iter 50000, loss: 10.648422
   Number of active neurons: 10
 >> iter 51000, loss: 10.517546
 >> iter 52000, loss: 10.554081
 >> iter 53000, loss: 10.435891
 >> iter 54000, loss: 10.462012
 >> iter 55000, loss: 10.335384
 >> iter 56000, loss: 10.402203
 >> iter 57000, loss: 10.211119
 >> iter 58000, loss: 9.964905
 >> iter 59000, loss: 9.332647
 >> iter 60000, loss: 8.951166
   Number of active neurons: 10
 >> iter 61000, loss: 6.934058
 >> iter 62000, loss: 4.945734
 >> iter 63000, loss: 3.910692
 >> iter 64000, loss: 2.896817
 >> iter 65000, loss: 2.328129
 >> iter 66000, loss: 1.817553
 >> iter 67000, loss: 1.678139
 >> iter 68000, loss: 1.597583
 >> iter 69000, loss: 1.210815
 >> iter 70000, loss: 1.211441
   Number of active neurons: 10
 >> iter 71000, loss: 1.178338
 >> iter 72000, loss: 0.644958
 >> iter 73000, loss: 0.435394
 >> iter 74000, loss: 0.849214
 >> iter 75000, loss: 0.852226
 >> iter 76000, loss: 0.498997
 >> iter 77000, loss: 0.937517
 >> iter 78000, loss: 0.609337
 >> iter 79000, loss: 0.413768
 >> iter 80000, loss: 0.559320
   Number of active neurons: 10
 >> iter 81000, loss: 0.605924
 >> iter 82000, loss: 0.630081
 >> iter 83000, loss: 0.546317
 >> iter 84000, loss: 0.338050
 >> iter 85000, loss: 0.348697
 >> iter 86000, loss: 0.586197
 >> iter 87000, loss: 0.655062
 >> iter 88000, loss: 0.692175
 >> iter 89000, loss: 0.763310
 >> iter 90000, loss: 0.498611
   Number of active neurons: 10
 >> iter 91000, loss: 0.484829
 >> iter 92000, loss: 0.601002
 >> iter 93000, loss: 0.590187
 >> iter 94000, loss: 0.357493
 >> iter 95000, loss: 0.220487
 >> iter 96000, loss: 0.208435
 >> iter 97000, loss: 0.280218
 >> iter 98000, loss: 0.286652
 >> iter 99000, loss: 0.398944
 >> iter 100000, loss: 0.199804
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0479995200048
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.122471
 >> iter 2000, loss: 15.575594
 >> iter 3000, loss: 14.086121
 >> iter 4000, loss: 13.495825
 >> iter 5000, loss: 13.258813
 >> iter 6000, loss: 13.159376
 >> iter 7000, loss: 13.106122
 >> iter 8000, loss: 13.078957
 >> iter 9000, loss: 13.045892
 >> iter 10000, loss: 13.057273
   Number of active neurons: 10
 >> iter 11000, loss: 13.036050
 >> iter 12000, loss: 13.046611
 >> iter 13000, loss: 13.030878
 >> iter 14000, loss: 13.035100
 >> iter 15000, loss: 13.030944
 >> iter 16000, loss: 13.042579
 >> iter 17000, loss: 13.032454
 >> iter 18000, loss: 13.039110
 >> iter 19000, loss: 13.024114
 >> iter 20000, loss: 13.032868
   Number of active neurons: 10
 >> iter 21000, loss: 13.013946
 >> iter 22000, loss: 13.023321
 >> iter 23000, loss: 13.003578
 >> iter 24000, loss: 13.015491
 >> iter 25000, loss: 13.000674
 >> iter 26000, loss: 13.012990
 >> iter 27000, loss: 12.992683
 >> iter 28000, loss: 13.005544
 >> iter 29000, loss: 12.995962
 >> iter 30000, loss: 13.009587
   Number of active neurons: 10
 >> iter 31000, loss: 12.997787
 >> iter 32000, loss: 13.011459
 >> iter 33000, loss: 13.003705
 >> iter 34000, loss: 13.011914
 >> iter 35000, loss: 12.996128
 >> iter 36000, loss: 13.007835
 >> iter 37000, loss: 12.995812
 >> iter 38000, loss: 13.003397
 >> iter 39000, loss: 12.983255
 >> iter 40000, loss: 12.951587
   Number of active neurons: 10
 >> iter 41000, loss: 12.919489
 >> iter 42000, loss: 12.883875
 >> iter 43000, loss: 12.831162
 >> iter 44000, loss: 12.742536
 >> iter 45000, loss: 12.241292
 >> iter 46000, loss: 11.736739
 >> iter 47000, loss: 11.284148
 >> iter 48000, loss: 11.020390
 >> iter 49000, loss: 10.540781
 >> iter 50000, loss: 10.295776
   Number of active neurons: 10
 >> iter 51000, loss: 9.915682
 >> iter 52000, loss: 9.659502
 >> iter 53000, loss: 9.286706
 >> iter 54000, loss: 9.104121
 >> iter 55000, loss: 8.788028
 >> iter 56000, loss: 8.662065
 >> iter 57000, loss: 8.616679
 >> iter 58000, loss: 8.624888
 >> iter 59000, loss: 8.534669
 >> iter 60000, loss: 8.641672
   Number of active neurons: 10
 >> iter 61000, loss: 8.437989
 >> iter 62000, loss: 8.488493
 >> iter 63000, loss: 8.275866
 >> iter 64000, loss: 8.418693
 >> iter 65000, loss: 8.305826
 >> iter 66000, loss: 8.445790
 >> iter 67000, loss: 8.192924
 >> iter 68000, loss: 8.174591
 >> iter 69000, loss: 8.107104
 >> iter 70000, loss: 8.242497
   Number of active neurons: 10
 >> iter 71000, loss: 8.228702
 >> iter 72000, loss: 8.211663
 >> iter 73000, loss: 8.110123
 >> iter 74000, loss: 8.043627
 >> iter 75000, loss: 8.027451
 >> iter 76000, loss: 8.101872
 >> iter 77000, loss: 8.086658
 >> iter 78000, loss: 8.040844
 >> iter 79000, loss: 7.889639
 >> iter 80000, loss: 7.878906
   Number of active neurons: 10
 >> iter 81000, loss: 7.772923
 >> iter 82000, loss: 7.891727
 >> iter 83000, loss: 7.813009
 >> iter 84000, loss: 7.900732
 >> iter 85000, loss: 7.862375
 >> iter 86000, loss: 7.885358
 >> iter 87000, loss: 7.852550
 >> iter 88000, loss: 7.897729
 >> iter 89000, loss: 7.816816
 >> iter 90000, loss: 7.879931
   Number of active neurons: 10
 >> iter 91000, loss: 7.800683
 >> iter 92000, loss: 7.966558
 >> iter 93000, loss: 7.718480
 >> iter 94000, loss: 7.846903
 >> iter 95000, loss: 7.784978
 >> iter 96000, loss: 7.873975
 >> iter 97000, loss: 7.849150
 >> iter 98000, loss: 7.841646
 >> iter 99000, loss: 7.678475
 >> iter 100000, loss: 7.760526
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 15.067698646
   - Test - Long: 30.6784660767
   - Test - Big: 15.0298497015
   - Test - A: 8.62609159389
   - Test - B: 31.6245583628
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.041495
 >> iter 2000, loss: 15.528679
 >> iter 3000, loss: 14.067734
 >> iter 4000, loss: 13.487392
 >> iter 5000, loss: 13.233699
 >> iter 6000, loss: 13.142234
 >> iter 7000, loss: 13.089878
 >> iter 8000, loss: 13.069468
 >> iter 9000, loss: 13.054369
 >> iter 10000, loss: 13.042825
   Number of active neurons: 10
 >> iter 11000, loss: 13.028325
 >> iter 12000, loss: 13.025440
 >> iter 13000, loss: 13.019164
 >> iter 14000, loss: 13.026851
 >> iter 15000, loss: 13.015268
 >> iter 16000, loss: 13.020227
 >> iter 17000, loss: 13.004638
 >> iter 18000, loss: 13.007783
 >> iter 19000, loss: 12.992161
 >> iter 20000, loss: 13.005244
   Number of active neurons: 10
 >> iter 21000, loss: 12.993272
 >> iter 22000, loss: 13.006126
 >> iter 23000, loss: 12.993754
 >> iter 24000, loss: 12.987198
 >> iter 25000, loss: 12.982853
 >> iter 26000, loss: 12.994457
 >> iter 27000, loss: 12.979973
 >> iter 28000, loss: 12.982243
 >> iter 29000, loss: 12.971388
 >> iter 30000, loss: 12.987877
   Number of active neurons: 10
 >> iter 31000, loss: 12.971395
 >> iter 32000, loss: 12.988600
 >> iter 33000, loss: 12.977797
 >> iter 34000, loss: 12.984076
 >> iter 35000, loss: 12.976787
 >> iter 36000, loss: 12.975004
 >> iter 37000, loss: 12.966422
 >> iter 38000, loss: 12.973312
 >> iter 39000, loss: 12.944198
 >> iter 40000, loss: 12.749988
   Number of active neurons: 10
 >> iter 41000, loss: 12.033447
 >> iter 42000, loss: 11.523112
 >> iter 43000, loss: 11.147226
 >> iter 44000, loss: 11.024255
 >> iter 45000, loss: 10.795430
 >> iter 46000, loss: 10.624811
 >> iter 47000, loss: 10.366909
 >> iter 48000, loss: 10.308387
 >> iter 49000, loss: 10.122931
 >> iter 50000, loss: 10.051974
   Number of active neurons: 10
 >> iter 51000, loss: 9.835330
 >> iter 52000, loss: 9.746488
 >> iter 53000, loss: 9.520485
 >> iter 54000, loss: 9.443551
 >> iter 55000, loss: 9.149537
 >> iter 56000, loss: 9.206328
 >> iter 57000, loss: 8.947482
 >> iter 58000, loss: 8.985090
 >> iter 59000, loss: 8.828197
 >> iter 60000, loss: 9.200845
   Number of active neurons: 10
 >> iter 61000, loss: 8.902318
 >> iter 62000, loss: 8.989801
 >> iter 63000, loss: 8.911813
 >> iter 64000, loss: 9.104098
 >> iter 65000, loss: 8.832618
 >> iter 66000, loss: 8.964673
 >> iter 67000, loss: 8.848999
 >> iter 68000, loss: 8.884673
 >> iter 69000, loss: 8.490921
 >> iter 70000, loss: 8.398161
   Number of active neurons: 10
 >> iter 71000, loss: 8.103189
 >> iter 72000, loss: 8.093791
 >> iter 73000, loss: 7.803437
 >> iter 74000, loss: 7.635543
 >> iter 75000, loss: 7.303146
 >> iter 76000, loss: 7.318723
 >> iter 77000, loss: 7.162925
 >> iter 78000, loss: 7.175249
 >> iter 79000, loss: 6.915085
 >> iter 80000, loss: 7.182936
   Number of active neurons: 10
 >> iter 81000, loss: 7.187923
 >> iter 82000, loss: 7.349853
 >> iter 83000, loss: 7.230843
 >> iter 84000, loss: 7.161006
 >> iter 85000, loss: 6.896634
 >> iter 86000, loss: 6.925036
 >> iter 87000, loss: 6.847548
 >> iter 88000, loss: 6.880188
 >> iter 89000, loss: 6.680088
 >> iter 90000, loss: 6.810214
   Number of active neurons: 10
 >> iter 91000, loss: 6.526182
 >> iter 92000, loss: 6.742742
 >> iter 93000, loss: 6.715815
 >> iter 94000, loss: 7.040135
 >> iter 95000, loss: 6.671125
 >> iter 96000, loss: 6.714603
 >> iter 97000, loss: 6.493513
 >> iter 98000, loss: 6.535452
 >> iter 99000, loss: 6.305406
 >> iter 100000, loss: 6.340860
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 11.0517789644
   - Test - Long: 29.3685315734
   - Test - Big: 10.9118908811
   - Test - A: 8.3061129258
   - Test - B: 15.3989734018
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.059970
 >> iter 2000, loss: 15.474836
 >> iter 3000, loss: 14.008237
 >> iter 4000, loss: 13.438647
 >> iter 5000, loss: 13.193142
 >> iter 6000, loss: 13.118003
 >> iter 7000, loss: 13.075214
 >> iter 8000, loss: 13.061241
 >> iter 9000, loss: 13.046004
 >> iter 10000, loss: 13.036069
   Number of active neurons: 10
 >> iter 11000, loss: 13.023787
 >> iter 12000, loss: 13.040532
 >> iter 13000, loss: 13.027945
 >> iter 14000, loss: 13.041245
 >> iter 15000, loss: 13.029289
 >> iter 16000, loss: 13.031367
 >> iter 17000, loss: 13.025325
 >> iter 18000, loss: 13.028999
 >> iter 19000, loss: 13.017961
 >> iter 20000, loss: 13.038512
   Number of active neurons: 10
 >> iter 21000, loss: 13.017690
 >> iter 22000, loss: 13.041092
 >> iter 23000, loss: 13.022466
 >> iter 24000, loss: 13.032299
 >> iter 25000, loss: 13.016371
 >> iter 26000, loss: 13.022374
 >> iter 27000, loss: 13.006691
 >> iter 28000, loss: 13.024738
 >> iter 29000, loss: 13.019064
 >> iter 30000, loss: 13.028425
   Number of active neurons: 10
 >> iter 31000, loss: 13.008317
 >> iter 32000, loss: 13.033804
 >> iter 33000, loss: 13.016374
 >> iter 34000, loss: 13.026702
 >> iter 35000, loss: 13.013358
 >> iter 36000, loss: 13.022363
 >> iter 37000, loss: 13.008700
 >> iter 38000, loss: 13.014880
 >> iter 39000, loss: 13.007406
 >> iter 40000, loss: 13.025522
   Number of active neurons: 10
 >> iter 41000, loss: 13.012544
 >> iter 42000, loss: 13.030952
 >> iter 43000, loss: 13.005524
 >> iter 44000, loss: 13.015672
 >> iter 45000, loss: 12.999178
 >> iter 46000, loss: 13.019733
 >> iter 47000, loss: 13.002155
 >> iter 48000, loss: 13.027392
 >> iter 49000, loss: 13.009667
 >> iter 50000, loss: 13.026540
   Number of active neurons: 10
 >> iter 51000, loss: 13.006756
 >> iter 52000, loss: 13.014969
 >> iter 53000, loss: 12.976635
 >> iter 54000, loss: 12.977171
 >> iter 55000, loss: 12.891132
 >> iter 56000, loss: 12.731376
 >> iter 57000, loss: 12.541056
 >> iter 58000, loss: 12.290498
 >> iter 59000, loss: 11.849240
 >> iter 60000, loss: 11.569961
   Number of active neurons: 10
 >> iter 61000, loss: 11.335936
 >> iter 62000, loss: 11.186080
 >> iter 63000, loss: 10.963851
 >> iter 64000, loss: 10.882864
 >> iter 65000, loss: 10.707831
 >> iter 66000, loss: 10.751433
 >> iter 67000, loss: 10.628160
 >> iter 68000, loss: 10.649255
 >> iter 69000, loss: 10.514679
 >> iter 70000, loss: 10.602972
   Number of active neurons: 10
 >> iter 71000, loss: 10.453181
 >> iter 72000, loss: 10.484588
 >> iter 73000, loss: 10.364209
 >> iter 74000, loss: 10.439779
 >> iter 75000, loss: 10.253321
 >> iter 76000, loss: 10.206198
 >> iter 77000, loss: 9.961253
 >> iter 78000, loss: 9.942792
 >> iter 79000, loss: 9.775694
 >> iter 80000, loss: 9.810184
   Number of active neurons: 10
 >> iter 81000, loss: 9.648000
 >> iter 82000, loss: 9.742554
 >> iter 83000, loss: 9.622853
 >> iter 84000, loss: 9.622785
 >> iter 85000, loss: 9.558496
 >> iter 86000, loss: 9.553195
 >> iter 87000, loss: 9.445337
 >> iter 88000, loss: 9.507194
 >> iter 89000, loss: 9.424087
 >> iter 90000, loss: 9.458897
   Number of active neurons: 10
 >> iter 91000, loss: 9.309783
 >> iter 92000, loss: 9.435010
 >> iter 93000, loss: 9.287720
 >> iter 94000, loss: 9.312017
 >> iter 95000, loss: 9.227180
 >> iter 96000, loss: 9.278601
 >> iter 97000, loss: 9.206160
 >> iter 98000, loss: 9.316248
 >> iter 99000, loss: 9.180612
 >> iter 100000, loss: 9.267909
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 18.9236215276
   - Test - Long: 31.5734213289
   - Test - Big: 18.9008109919
   - Test - A: 30.3713085794
   - Test - B: 31.6445570295
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.101809
 >> iter 2000, loss: 15.555566
 >> iter 3000, loss: 14.091028
 >> iter 4000, loss: 13.532847
 >> iter 5000, loss: 13.274033
 >> iter 6000, loss: 13.179619
 >> iter 7000, loss: 13.120014
 >> iter 8000, loss: 13.097881
 >> iter 9000, loss: 13.073570
 >> iter 10000, loss: 13.081673
   Number of active neurons: 10
 >> iter 11000, loss: 13.057004
 >> iter 12000, loss: 13.058905
 >> iter 13000, loss: 13.036741
 >> iter 14000, loss: 13.044507
 >> iter 15000, loss: 13.037907
 >> iter 16000, loss: 13.052784
 >> iter 17000, loss: 13.032730
 >> iter 18000, loss: 13.037942
 >> iter 19000, loss: 13.027589
 >> iter 20000, loss: 13.039175
   Number of active neurons: 10
 >> iter 21000, loss: 13.018495
 >> iter 22000, loss: 13.031566
 >> iter 23000, loss: 13.005808
 >> iter 24000, loss: 13.023727
 >> iter 25000, loss: 13.002727
 >> iter 26000, loss: 13.018206
 >> iter 27000, loss: 12.998642
 >> iter 28000, loss: 13.009863
 >> iter 29000, loss: 12.996741
 >> iter 30000, loss: 13.011279
   Number of active neurons: 10
 >> iter 31000, loss: 12.996797
 >> iter 32000, loss: 13.006697
 >> iter 33000, loss: 12.996913
 >> iter 34000, loss: 13.014345
 >> iter 35000, loss: 13.000416
 >> iter 36000, loss: 13.009248
 >> iter 37000, loss: 12.991893
 >> iter 38000, loss: 13.012242
 >> iter 39000, loss: 12.993281
 >> iter 40000, loss: 13.001277
   Number of active neurons: 10
 >> iter 41000, loss: 12.987899
 >> iter 42000, loss: 12.984489
 >> iter 43000, loss: 12.965794
 >> iter 44000, loss: 12.953899
 >> iter 45000, loss: 12.904873
 >> iter 46000, loss: 12.861271
 >> iter 47000, loss: 12.811795
 >> iter 48000, loss: 12.724511
 >> iter 49000, loss: 12.638477
 >> iter 50000, loss: 12.516502
   Number of active neurons: 10
 >> iter 51000, loss: 12.418883
 >> iter 52000, loss: 12.372333
 >> iter 53000, loss: 12.291090
 >> iter 54000, loss: 12.200309
 >> iter 55000, loss: 12.108384
 >> iter 56000, loss: 12.081557
 >> iter 57000, loss: 12.032041
 >> iter 58000, loss: 11.973478
 >> iter 59000, loss: 11.940878
 >> iter 60000, loss: 11.917666
   Number of active neurons: 10
 >> iter 61000, loss: 11.855703
 >> iter 62000, loss: 11.778900
 >> iter 63000, loss: 11.435246
 >> iter 64000, loss: 11.267170
 >> iter 65000, loss: 11.058243
 >> iter 66000, loss: 10.984032
 >> iter 67000, loss: 10.688058
 >> iter 68000, loss: 10.709916
 >> iter 69000, loss: 10.556209
 >> iter 70000, loss: 10.557295
   Number of active neurons: 10
 >> iter 71000, loss: 10.357225
 >> iter 72000, loss: 10.352260
 >> iter 73000, loss: 10.231549
 >> iter 74000, loss: 10.235305
 >> iter 75000, loss: 10.138220
 >> iter 76000, loss: 10.215621
 >> iter 77000, loss: 10.148593
 >> iter 78000, loss: 10.127562
 >> iter 79000, loss: 10.063734
 >> iter 80000, loss: 10.084329
   Number of active neurons: 10
 >> iter 81000, loss: 10.002831
 >> iter 82000, loss: 9.985697
 >> iter 83000, loss: 9.902813
 >> iter 84000, loss: 10.001988
 >> iter 85000, loss: 9.868188
 >> iter 86000, loss: 9.890112
 >> iter 87000, loss: 9.839618
 >> iter 88000, loss: 9.873883
 >> iter 89000, loss: 9.815669
 >> iter 90000, loss: 9.846125
   Number of active neurons: 10
 >> iter 91000, loss: 9.695587
 >> iter 92000, loss: 9.759104
 >> iter 93000, loss: 9.509441
 >> iter 94000, loss: 9.706570
 >> iter 95000, loss: 9.337025
 >> iter 96000, loss: 9.246722
 >> iter 97000, loss: 8.885382
 >> iter 98000, loss: 8.670701
 >> iter 99000, loss: 8.451161
 >> iter 100000, loss: 8.452539
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 11.5957680846
   - Test - Long: 29.0335483226
   - Test - Big: 11.6668833312
   - Test - A: 30.464635691
   - Test - B: 8.54609692687
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.106535
 >> iter 2000, loss: 15.475858
 >> iter 3000, loss: 14.022769
 >> iter 4000, loss: 13.421153
 >> iter 5000, loss: 13.191140
 >> iter 6000, loss: 13.114763
 >> iter 7000, loss: 13.064984
 >> iter 8000, loss: 13.064100
 >> iter 9000, loss: 13.037336
 >> iter 10000, loss: 13.038406
   Number of active neurons: 10
 >> iter 11000, loss: 13.021664
 >> iter 12000, loss: 13.027300
 >> iter 13000, loss: 13.007709
 >> iter 14000, loss: 13.023285
 >> iter 15000, loss: 13.014725
 >> iter 16000, loss: 13.011088
 >> iter 17000, loss: 13.006067
 >> iter 18000, loss: 13.004970
 >> iter 19000, loss: 12.991984
 >> iter 20000, loss: 13.009972
   Number of active neurons: 8
 >> iter 21000, loss: 12.991528
 >> iter 22000, loss: 13.004612
 >> iter 23000, loss: 12.989112
 >> iter 24000, loss: 13.002714
 >> iter 25000, loss: 12.978484
 >> iter 26000, loss: 12.998267
 >> iter 27000, loss: 12.985213
 >> iter 28000, loss: 12.996380
 >> iter 29000, loss: 12.984470
 >> iter 30000, loss: 13.001802
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 12.988034
 >> iter 32000, loss: 13.000078
 >> iter 33000, loss: 12.991148
 >> iter 34000, loss: 12.998234
 >> iter 35000, loss: 12.984050
 >> iter 36000, loss: 12.998370
 >> iter 37000, loss: 12.983604
 >> iter 38000, loss: 12.991175
 >> iter 39000, loss: 12.982465
 >> iter 40000, loss: 12.995123
   Number of active neurons: 10
 >> iter 41000, loss: 12.960319
 >> iter 42000, loss: 12.895759
 >> iter 43000, loss: 12.676286
 >> iter 44000, loss: 12.066385
 >> iter 45000, loss: 11.526344
 >> iter 46000, loss: 11.333899
 >> iter 47000, loss: 11.105765
 >> iter 48000, loss: 11.101508
 >> iter 49000, loss: 10.985078
 >> iter 50000, loss: 10.992896
   Number of active neurons: 10
 >> iter 51000, loss: 10.786974
 >> iter 52000, loss: 10.710544
 >> iter 53000, loss: 10.479264
 >> iter 54000, loss: 10.432557
 >> iter 55000, loss: 10.221171
 >> iter 56000, loss: 10.253828
 >> iter 57000, loss: 10.077526
 >> iter 58000, loss: 10.125973
 >> iter 59000, loss: 9.986652
 >> iter 60000, loss: 10.050047
   Number of active neurons: 10
 >> iter 61000, loss: 9.895293
 >> iter 62000, loss: 9.882897
 >> iter 63000, loss: 9.696307
 >> iter 64000, loss: 9.615207
 >> iter 65000, loss: 9.366820
 >> iter 66000, loss: 9.361705
 >> iter 67000, loss: 9.246034
 >> iter 68000, loss: 9.315767
 >> iter 69000, loss: 9.125313
 >> iter 70000, loss: 9.185409
   Number of active neurons: 10
 >> iter 71000, loss: 9.038274
 >> iter 72000, loss: 9.126793
 >> iter 73000, loss: 8.989120
 >> iter 74000, loss: 9.000315
 >> iter 75000, loss: 8.864513
 >> iter 76000, loss: 8.911231
 >> iter 77000, loss: 8.723519
 >> iter 78000, loss: 8.795819
 >> iter 79000, loss: 8.625164
 >> iter 80000, loss: 8.721159
   Number of active neurons: 10
 >> iter 81000, loss: 8.633577
 >> iter 82000, loss: 8.610021
 >> iter 83000, loss: 8.338447
 >> iter 84000, loss: 8.419331
 >> iter 85000, loss: 8.299954
 >> iter 86000, loss: 8.425880
 >> iter 87000, loss: 8.268470
 >> iter 88000, loss: 8.158853
 >> iter 89000, loss: 7.945518
 >> iter 90000, loss: 7.960827
   Number of active neurons: 10
 >> iter 91000, loss: 7.870588
 >> iter 92000, loss: 7.893835
 >> iter 93000, loss: 7.567256
 >> iter 94000, loss: 7.918224
 >> iter 95000, loss: 7.610502
 >> iter 96000, loss: 7.432419
 >> iter 97000, loss: 7.044745
 >> iter 98000, loss: 7.208958
 >> iter 99000, loss: 7.073550
 >> iter 100000, loss: 7.081776
   Number of active neurons: 10
 >> iter 101000, loss: 6.995453
 >> iter 102000, loss: 6.995235
 >> iter 103000, loss: 6.861914
 >> iter 104000, loss: 6.968514
 >> iter 105000, loss: 6.930045
 >> iter 106000, loss: 7.023114
 >> iter 107000, loss: 6.962781
 >> iter 108000, loss: 7.146022
 >> iter 109000, loss: 6.797036
 >> iter 110000, loss: 6.835188
   Number of active neurons: 10
 >> iter 111000, loss: 6.731590
 >> iter 112000, loss: 6.756385
 >> iter 113000, loss: 6.655944
 >> iter 114000, loss: 6.871678
 >> iter 115000, loss: 6.655853
 >> iter 116000, loss: 6.657846
 >> iter 117000, loss: 6.554938
 >> iter 118000, loss: 6.725597
 >> iter 119000, loss: 6.546691
 >> iter 120000, loss: 6.939689
   Number of active neurons: 10
 >> iter 121000, loss: 6.261501
 >> iter 122000, loss: 5.652732
 >> iter 123000, loss: 5.051354
 >> iter 124000, loss: 5.112465
 >> iter 125000, loss: 4.419794
 >> iter 126000, loss: 4.942652
 >> iter 127000, loss: 4.313525
 >> iter 128000, loss: 4.183516
 >> iter 129000, loss: 3.848850
 >> iter 130000, loss: 3.734269
   Number of active neurons: 10
 >> iter 131000, loss: 3.966303
 >> iter 132000, loss: 3.083335
 >> iter 133000, loss: 2.147998
 >> iter 134000, loss: 1.712613
 >> iter 135000, loss: 1.869212
 >> iter 136000, loss: 2.043920
 >> iter 137000, loss: 1.710144
 >> iter 138000, loss: 1.439408
 >> iter 139000, loss: 1.065522
 >> iter 140000, loss: 1.390072
   Number of active neurons: 10
 >> iter 141000, loss: 0.853291
 >> iter 142000, loss: 0.782074
 >> iter 143000, loss: 0.661585
 >> iter 144000, loss: 0.603358
 >> iter 145000, loss: 0.702873
 >> iter 146000, loss: 0.857882
 >> iter 147000, loss: 0.589022
 >> iter 148000, loss: 0.924507
 >> iter 149000, loss: 1.272452
 >> iter 150000, loss: 0.924108
   Number of active neurons: 10
 >> iter 151000, loss: 0.742727
 >> iter 152000, loss: 0.837313
 >> iter 153000, loss: 0.686379
 >> iter 154000, loss: 0.997594
 >> iter 155000, loss: 0.603637
 >> iter 156000, loss: 0.844343
 >> iter 157000, loss: 0.648807
 >> iter 158000, loss: 1.010525
 >> iter 159000, loss: 0.853682
 >> iter 160000, loss: 0.562907
   Number of active neurons: 10
 >> iter 161000, loss: 0.482798
 >> iter 162000, loss: 0.835689
 >> iter 163000, loss: 0.882740
 >> iter 164000, loss: 0.580666
 >> iter 165000, loss: 0.509311
 >> iter 166000, loss: 0.602723
 >> iter 167000, loss: 0.549196
 >> iter 168000, loss: 0.493169
 >> iter 169000, loss: 0.404590
 >> iter 170000, loss: 0.437563
   Number of active neurons: 10
 >> iter 171000, loss: 0.467154
 >> iter 172000, loss: 0.426782
 >> iter 173000, loss: 0.456094
 >> iter 174000, loss: 0.318268
 >> iter 175000, loss: 0.758598
 >> iter 176000, loss: 0.596469
 >> iter 177000, loss: 0.330548
 >> iter 178000, loss: 0.234392
 >> iter 179000, loss: 0.183043
 >> iter 180000, loss: 0.396946
   Number of active neurons: 10
 >> iter 181000, loss: 0.255621
 >> iter 182000, loss: 0.485799
 >> iter 183000, loss: 0.413786
 >> iter 184000, loss: 0.315212
 >> iter 185000, loss: 0.382478
 >> iter 186000, loss: 0.402022
 >> iter 187000, loss: 0.412878
 >> iter 188000, loss: 0.343770
 >> iter 189000, loss: 0.347772
 >> iter 190000, loss: 0.244715
   Number of active neurons: 10
 >> iter 191000, loss: 0.188428
 >> iter 192000, loss: 0.210841
 >> iter 193000, loss: 0.196922
 >> iter 194000, loss: 0.486776
 >> iter 195000, loss: 0.555654
 >> iter 196000, loss: 0.718291
 >> iter 197000, loss: 0.536596
 >> iter 198000, loss: 0.727393
 >> iter 199000, loss: 0.437431
 >> iter 200000, loss: 0.525707
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0639987200256
   - Test - Long: 0.0
   - Test - Big: 0.0139998600014
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.062127
 >> iter 2000, loss: 15.533993
 >> iter 3000, loss: 14.051072
 >> iter 4000, loss: 13.479017
 >> iter 5000, loss: 13.230543
 >> iter 6000, loss: 13.132255
 >> iter 7000, loss: 13.082503
 >> iter 8000, loss: 13.061880
 >> iter 9000, loss: 13.037359
 >> iter 10000, loss: 13.038844
   Number of active neurons: 10
 >> iter 11000, loss: 13.014283
 >> iter 12000, loss: 13.024047
 >> iter 13000, loss: 13.004284
 >> iter 14000, loss: 13.017649
 >> iter 15000, loss: 13.009784
 >> iter 16000, loss: 13.021035
 >> iter 17000, loss: 13.007278
 >> iter 18000, loss: 13.013668
 >> iter 19000, loss: 13.002792
 >> iter 20000, loss: 13.017372
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 12.995550
 >> iter 22000, loss: 13.000022
 >> iter 23000, loss: 13.003034
 >> iter 24000, loss: 13.016320
 >> iter 25000, loss: 12.987099
 >> iter 26000, loss: 12.986119
 >> iter 27000, loss: 12.954068
 >> iter 28000, loss: 12.487051
 >> iter 29000, loss: 11.785924
 >> iter 30000, loss: 11.379859
   Number of active neurons: 10
 >> iter 31000, loss: 11.083896
 >> iter 32000, loss: 10.984330
 >> iter 33000, loss: 10.802022
 >> iter 34000, loss: 10.749259
 >> iter 35000, loss: 10.606957
 >> iter 36000, loss: 10.560383
 >> iter 37000, loss: 10.466861
 >> iter 38000, loss: 10.438451
 >> iter 39000, loss: 10.312158
 >> iter 40000, loss: 10.242282
   Number of active neurons: 10
 >> iter 41000, loss: 9.942850
 >> iter 42000, loss: 9.493901
 >> iter 43000, loss: 8.183405
 >> iter 44000, loss: 7.534855
 >> iter 45000, loss: 6.867377
 >> iter 46000, loss: 6.550785
 >> iter 47000, loss: 5.904511
 >> iter 48000, loss: 5.976853
 >> iter 49000, loss: 5.551854
 >> iter 50000, loss: 5.882689
   Number of active neurons: 10
 >> iter 51000, loss: 5.650834
 >> iter 52000, loss: 5.636954
 >> iter 53000, loss: 5.342926
 >> iter 54000, loss: 5.418064
 >> iter 55000, loss: 5.210676
 >> iter 56000, loss: 5.392518
 >> iter 57000, loss: 5.128657
 >> iter 58000, loss: 5.340224
 >> iter 59000, loss: 5.251854
 >> iter 60000, loss: 5.295340
   Number of active neurons: 10
 >> iter 61000, loss: 5.017843
 >> iter 62000, loss: 5.363721
 >> iter 63000, loss: 5.169878
 >> iter 64000, loss: 5.293789
 >> iter 65000, loss: 5.031766
 >> iter 66000, loss: 5.408670
 >> iter 67000, loss: 5.070038
 >> iter 68000, loss: 5.152203
 >> iter 69000, loss: 4.964170
 >> iter 70000, loss: 5.077006
   Number of active neurons: 10
 >> iter 71000, loss: 4.876404
 >> iter 72000, loss: 5.019999
 >> iter 73000, loss: 4.957909
 >> iter 74000, loss: 5.108415
 >> iter 75000, loss: 4.949550
 >> iter 76000, loss: 5.111227
 >> iter 77000, loss: 4.929320
 >> iter 78000, loss: 5.050996
 >> iter 79000, loss: 4.969251
 >> iter 80000, loss: 5.119209
   Number of active neurons: 10
 >> iter 81000, loss: 4.950906
 >> iter 82000, loss: 5.056000
 >> iter 83000, loss: 4.965434
 >> iter 84000, loss: 5.061354
 >> iter 85000, loss: 5.020481
 >> iter 86000, loss: 5.157255
 >> iter 87000, loss: 5.015154
 >> iter 88000, loss: 5.059840
 >> iter 89000, loss: 4.839378
 >> iter 90000, loss: 4.990411
   Number of active neurons: 10
 >> iter 91000, loss: 4.830586
 >> iter 92000, loss: 5.060287
 >> iter 93000, loss: 5.029646
 >> iter 94000, loss: 5.188356
 >> iter 95000, loss: 4.883495
 >> iter 96000, loss: 4.982489
 >> iter 97000, loss: 4.856620
 >> iter 98000, loss: 4.982629
 >> iter 99000, loss: 4.879034
 >> iter 100000, loss: 5.048497
   Number of active neurons: 10
 >> iter 101000, loss: 5.014218
 >> iter 102000, loss: 5.076840
 >> iter 103000, loss: 4.997997
 >> iter 104000, loss: 5.011742
 >> iter 105000, loss: 4.883675
 >> iter 106000, loss: 5.072032
 >> iter 107000, loss: 4.902408
 >> iter 108000, loss: 5.059157
 >> iter 109000, loss: 4.838877
 >> iter 110000, loss: 5.010254
   Number of active neurons: 10
 >> iter 111000, loss: 4.870140
 >> iter 112000, loss: 4.954054
 >> iter 113000, loss: 4.902084
 >> iter 114000, loss: 5.009125
 >> iter 115000, loss: 4.812547
 >> iter 116000, loss: 4.961613
 >> iter 117000, loss: 4.831130
 >> iter 118000, loss: 4.944029
 >> iter 119000, loss: 4.773651
 >> iter 120000, loss: 4.910486
   Number of active neurons: 10
 >> iter 121000, loss: 4.767400
 >> iter 122000, loss: 4.931205
 >> iter 123000, loss: 4.781180
 >> iter 124000, loss: 4.978749
 >> iter 125000, loss: 4.784192
 >> iter 126000, loss: 4.966215
 >> iter 127000, loss: 4.799303
 >> iter 128000, loss: 4.969317
 >> iter 129000, loss: 4.843596
 >> iter 130000, loss: 4.945121
   Number of active neurons: 10
 >> iter 131000, loss: 4.777759
 >> iter 132000, loss: 4.959503
 >> iter 133000, loss: 4.763462
 >> iter 134000, loss: 4.953072
 >> iter 135000, loss: 4.754391
 >> iter 136000, loss: 5.014193
 >> iter 137000, loss: 4.854625
 >> iter 138000, loss: 5.000985
 >> iter 139000, loss: 4.826302
 >> iter 140000, loss: 4.941945
   Number of active neurons: 10
 >> iter 141000, loss: 4.744224
 >> iter 142000, loss: 4.940785
 >> iter 143000, loss: 4.762712
 >> iter 144000, loss: 5.013039
 >> iter 145000, loss: 4.818637
 >> iter 146000, loss: 4.943617
 >> iter 147000, loss: 4.760670
 >> iter 148000, loss: 4.931577
 >> iter 149000, loss: 4.826748
 >> iter 150000, loss: 4.962869
   Number of active neurons: 10
 >> iter 151000, loss: 4.768351
 >> iter 152000, loss: 4.944815
 >> iter 153000, loss: 4.768180
 >> iter 154000, loss: 4.910240
 >> iter 155000, loss: 4.804258
 >> iter 156000, loss: 4.946117
 >> iter 157000, loss: 4.897057
 >> iter 158000, loss: 4.951652
 >> iter 159000, loss: 4.800015
 >> iter 160000, loss: 4.971752
   Number of active neurons: 10
 >> iter 161000, loss: 4.764348
 >> iter 162000, loss: 5.037288
 >> iter 163000, loss: 4.915225
 >> iter 164000, loss: 4.965110
 >> iter 165000, loss: 4.899685
 >> iter 166000, loss: 4.973109
 >> iter 167000, loss: 4.815424
 >> iter 168000, loss: 4.946976
 >> iter 169000, loss: 4.757057
 >> iter 170000, loss: 4.977871
   Number of active neurons: 10
 >> iter 171000, loss: 4.865531
 >> iter 172000, loss: 5.016639
 >> iter 173000, loss: 4.816681
 >> iter 174000, loss: 5.015735
 >> iter 175000, loss: 4.786165
 >> iter 176000, loss: 4.938924
 >> iter 177000, loss: 4.764371
 >> iter 178000, loss: 4.936181
 >> iter 179000, loss: 4.754175
 >> iter 180000, loss: 4.932668
   Number of active neurons: 10
 >> iter 181000, loss: 4.771421
 >> iter 182000, loss: 4.933911
 >> iter 183000, loss: 4.756268
 >> iter 184000, loss: 4.987741
 >> iter 185000, loss: 4.790136
 >> iter 186000, loss: 4.935741
 >> iter 187000, loss: 4.742559
 >> iter 188000, loss: 4.925309
 >> iter 189000, loss: 4.751873
 >> iter 190000, loss: 5.020143
   Number of active neurons: 10
 >> iter 191000, loss: 4.777456
 >> iter 192000, loss: 4.962258
 >> iter 193000, loss: 4.865156
 >> iter 194000, loss: 5.056016
 >> iter 195000, loss: 4.807481
 >> iter 196000, loss: 4.933145
 >> iter 197000, loss: 4.896617
 >> iter 198000, loss: 4.986087
 >> iter 199000, loss: 4.778343
 >> iter 200000, loss: 4.952883
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 9.51780964381
   - Test - Long: 28.1985900705
   - Test - Big: 9.44590554094
   - Test - A: 7.99946670222
   - Test - B: 8.54609692687
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.084093
 >> iter 2000, loss: 15.464143
 >> iter 3000, loss: 13.999952
 >> iter 4000, loss: 13.451135
 >> iter 5000, loss: 13.208499
 >> iter 6000, loss: 13.109742
 >> iter 7000, loss: 13.076811
 >> iter 8000, loss: 13.069567
 >> iter 9000, loss: 13.043904
 >> iter 10000, loss: 13.046466
   Number of active neurons: 10
 >> iter 11000, loss: 13.026567
 >> iter 12000, loss: 13.031735
 >> iter 13000, loss: 13.016107
 >> iter 14000, loss: 13.027601
 >> iter 15000, loss: 13.012912
 >> iter 16000, loss: 13.024039
 >> iter 17000, loss: 13.004274
 >> iter 18000, loss: 13.009451
 >> iter 19000, loss: 12.999036
 >> iter 20000, loss: 13.015011
   Number of active neurons: 10
 >> iter 21000, loss: 13.004726
 >> iter 22000, loss: 13.004548
 >> iter 23000, loss: 12.996079
 >> iter 24000, loss: 13.009242
 >> iter 25000, loss: 12.992581
 >> iter 26000, loss: 13.003431
 >> iter 27000, loss: 12.992026
 >> iter 28000, loss: 13.002697
 >> iter 29000, loss: 12.995984
 >> iter 30000, loss: 13.002115
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 12.982768
 >> iter 32000, loss: 12.986082
 >> iter 33000, loss: 12.949956
 >> iter 34000, loss: 12.901594
 >> iter 35000, loss: 12.603257
 >> iter 36000, loss: 12.018102
 >> iter 37000, loss: 11.543567
 >> iter 38000, loss: 11.293631
 >> iter 39000, loss: 11.055374
 >> iter 40000, loss: 10.950119
   Number of active neurons: 10
 >> iter 41000, loss: 10.790666
 >> iter 42000, loss: 10.773707
 >> iter 43000, loss: 10.640942
 >> iter 44000, loss: 10.658987
 >> iter 45000, loss: 10.602973
 >> iter 46000, loss: 10.640249
 >> iter 47000, loss: 10.550507
 >> iter 48000, loss: 10.537160
 >> iter 49000, loss: 10.482057
 >> iter 50000, loss: 10.465405
   Number of active neurons: 10
 >> iter 51000, loss: 10.384440
 >> iter 52000, loss: 10.410120
 >> iter 53000, loss: 10.288372
 >> iter 54000, loss: 10.284444
 >> iter 55000, loss: 10.166227
 >> iter 56000, loss: 10.226024
 >> iter 57000, loss: 10.069561
 >> iter 58000, loss: 10.183137
 >> iter 59000, loss: 10.065161
 >> iter 60000, loss: 10.096955
   Number of active neurons: 10
 >> iter 61000, loss: 9.965909
 >> iter 62000, loss: 9.978570
 >> iter 63000, loss: 9.806370
 >> iter 64000, loss: 9.826363
 >> iter 65000, loss: 9.719984
 >> iter 66000, loss: 9.729324
 >> iter 67000, loss: 9.617593
 >> iter 68000, loss: 9.600050
 >> iter 69000, loss: 9.534016
 >> iter 70000, loss: 9.564585
   Number of active neurons: 10
 >> iter 71000, loss: 9.474146
 >> iter 72000, loss: 9.608673
 >> iter 73000, loss: 9.472235
 >> iter 74000, loss: 9.504217
 >> iter 75000, loss: 9.384842
 >> iter 76000, loss: 9.415725
 >> iter 77000, loss: 9.192172
 >> iter 78000, loss: 9.267026
 >> iter 79000, loss: 9.140093
 >> iter 80000, loss: 9.292452
   Number of active neurons: 10
 >> iter 81000, loss: 9.148102
 >> iter 82000, loss: 9.239810
 >> iter 83000, loss: 9.067243
 >> iter 84000, loss: 9.137523
 >> iter 85000, loss: 8.939138
 >> iter 86000, loss: 9.112184
 >> iter 87000, loss: 9.021195
 >> iter 88000, loss: 9.148266
 >> iter 89000, loss: 8.997968
 >> iter 90000, loss: 9.040060
   Number of active neurons: 10
 >> iter 91000, loss: 8.808281
 >> iter 92000, loss: 8.899085
 >> iter 93000, loss: 8.727329
 >> iter 94000, loss: 8.803504
 >> iter 95000, loss: 8.534852
 >> iter 96000, loss: 8.542223
 >> iter 97000, loss: 8.466490
 >> iter 98000, loss: 8.476733
 >> iter 99000, loss: 8.319836
 >> iter 100000, loss: 8.375545
   Number of active neurons: 10
 >> iter 101000, loss: 8.267696
 >> iter 102000, loss: 8.347393
 >> iter 103000, loss: 8.083919
 >> iter 104000, loss: 8.152959
 >> iter 105000, loss: 8.272517
 >> iter 106000, loss: 8.348420
 >> iter 107000, loss: 8.057417
 >> iter 108000, loss: 8.068598
 >> iter 109000, loss: 7.965124
 >> iter 110000, loss: 8.186879
   Number of active neurons: 10
 >> iter 111000, loss: 8.061770
 >> iter 112000, loss: 7.983839
 >> iter 113000, loss: 7.816165
 >> iter 114000, loss: 7.899154
 >> iter 115000, loss: 7.744469
 >> iter 116000, loss: 7.796283
 >> iter 117000, loss: 7.421912
 >> iter 118000, loss: 7.403980
 >> iter 119000, loss: 7.457181
 >> iter 120000, loss: 7.414327
   Number of active neurons: 10
 >> iter 121000, loss: 7.278152
 >> iter 122000, loss: 7.331349
 >> iter 123000, loss: 7.252008
 >> iter 124000, loss: 7.373231
 >> iter 125000, loss: 7.420589
 >> iter 126000, loss: 7.450678
 >> iter 127000, loss: 7.435942
 >> iter 128000, loss: 7.845521
 >> iter 129000, loss: 7.671909
 >> iter 130000, loss: 7.716699
   Number of active neurons: 10
 >> iter 131000, loss: 7.472931
 >> iter 132000, loss: 7.580664
 >> iter 133000, loss: 7.480228
 >> iter 134000, loss: 7.618240
 >> iter 135000, loss: 7.463436
 >> iter 136000, loss: 7.413212
 >> iter 137000, loss: 7.438854
 >> iter 138000, loss: 7.297441
 >> iter 139000, loss: 7.290600
 >> iter 140000, loss: 7.233552
   Number of active neurons: 10
 >> iter 141000, loss: 7.397063
 >> iter 142000, loss: 7.412400
 >> iter 143000, loss: 7.282133
 >> iter 144000, loss: 7.186524
 >> iter 145000, loss: 6.909980
 >> iter 146000, loss: 7.191966
 >> iter 147000, loss: 7.160940
 >> iter 148000, loss: 7.280425
 >> iter 149000, loss: 7.075611
 >> iter 150000, loss: 7.353397
   Number of active neurons: 10
 >> iter 151000, loss: 7.277136
 >> iter 152000, loss: 7.350540
 >> iter 153000, loss: 7.323751
 >> iter 154000, loss: 7.313104
 >> iter 155000, loss: 7.212021
 >> iter 156000, loss: 7.169891
 >> iter 157000, loss: 7.068818
 >> iter 158000, loss: 7.628121
 >> iter 159000, loss: 7.350939
 >> iter 160000, loss: 7.239690
   Number of active neurons: 10
 >> iter 161000, loss: 7.130819
 >> iter 162000, loss: 7.148922
 >> iter 163000, loss: 7.117508
 >> iter 164000, loss: 7.489561
 >> iter 165000, loss: 7.146461
 >> iter 166000, loss: 7.018396
 >> iter 167000, loss: 7.156632
 >> iter 168000, loss: 7.266184
 >> iter 169000, loss: 7.228133
 >> iter 170000, loss: 7.081117
   Number of active neurons: 10
 >> iter 171000, loss: 7.093727
 >> iter 172000, loss: 7.177701
 >> iter 173000, loss: 6.913504
 >> iter 174000, loss: 6.919102
 >> iter 175000, loss: 6.866162
 >> iter 176000, loss: 6.910901
 >> iter 177000, loss: 6.840051
 >> iter 178000, loss: 6.906910
 >> iter 179000, loss: 6.922346
 >> iter 180000, loss: 6.883046
   Number of active neurons: 10
 >> iter 181000, loss: 6.873847
 >> iter 182000, loss: 6.971938
 >> iter 183000, loss: 6.865710
 >> iter 184000, loss: 6.997954
 >> iter 185000, loss: 6.755092
 >> iter 186000, loss: 6.924789
 >> iter 187000, loss: 6.981301
 >> iter 188000, loss: 7.049725
 >> iter 189000, loss: 7.043123
 >> iter 190000, loss: 6.966160
   Number of active neurons: 10
 >> iter 191000, loss: 6.810148
 >> iter 192000, loss: 6.928949
 >> iter 193000, loss: 6.692201
 >> iter 194000, loss: 6.813777
 >> iter 195000, loss: 6.824980
 >> iter 196000, loss: 6.726277
 >> iter 197000, loss: 6.704290
 >> iter 198000, loss: 6.821711
 >> iter 199000, loss: 6.697979
 >> iter 200000, loss: 6.865690
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 12.9257414852
   - Test - Long: 29.8485075746
   - Test - Big: 12.7978720213
   - Test - A: 31.3379108059
   - Test - B: 8.51276581561
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.088896
 >> iter 2000, loss: 15.518095
 >> iter 3000, loss: 14.038955
 >> iter 4000, loss: 13.463931
 >> iter 5000, loss: 13.218785
 >> iter 6000, loss: 13.106861
 >> iter 7000, loss: 13.052204
 >> iter 8000, loss: 13.037462
 >> iter 9000, loss: 13.018144
 >> iter 10000, loss: 13.026027
   Number of active neurons: 9
 >> iter 11000, loss: 13.015600
 >> iter 12000, loss: 13.013278
 >> iter 13000, loss: 13.001623
 >> iter 14000, loss: 13.018830
 >> iter 15000, loss: 13.006001
 >> iter 16000, loss: 13.014360
 >> iter 17000, loss: 13.001871
 >> iter 18000, loss: 13.003325
 >> iter 19000, loss: 12.995174
 >> iter 20000, loss: 13.010439
   Number of active neurons: 10
 >> iter 21000, loss: 12.998913
 >> iter 22000, loss: 13.004428
 >> iter 23000, loss: 12.992599
 >> iter 24000, loss: 12.996216
 >> iter 25000, loss: 12.986167
 >> iter 26000, loss: 13.003219
 >> iter 27000, loss: 12.989438
 >> iter 28000, loss: 12.996032
 >> iter 29000, loss: 12.985668
 >> iter 30000, loss: 12.995143
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 12.976203
 >> iter 32000, loss: 12.979540
 >> iter 33000, loss: 12.967362
 >> iter 34000, loss: 12.952977
 >> iter 35000, loss: 12.930633
 >> iter 36000, loss: 12.893084
 >> iter 37000, loss: 12.797231
 >> iter 38000, loss: 12.468651
 >> iter 39000, loss: 11.943809
 >> iter 40000, loss: 11.587922
   Number of active neurons: 10
 >> iter 41000, loss: 11.219346
 >> iter 42000, loss: 11.086996
 >> iter 43000, loss: 10.887478
 >> iter 44000, loss: 10.830306
 >> iter 45000, loss: 10.630908
 >> iter 46000, loss: 10.591501
 >> iter 47000, loss: 10.399266
 >> iter 48000, loss: 10.305792
 >> iter 49000, loss: 10.135045
 >> iter 50000, loss: 10.129994
   Number of active neurons: 10
 >> iter 51000, loss: 9.939351
 >> iter 52000, loss: 9.849428
 >> iter 53000, loss: 9.603766
 >> iter 54000, loss: 9.583609
 >> iter 55000, loss: 9.518405
 >> iter 56000, loss: 9.446787
 >> iter 57000, loss: 9.293916
 >> iter 58000, loss: 9.333339
 >> iter 59000, loss: 9.107661
 >> iter 60000, loss: 9.097025
   Number of active neurons: 10
 >> iter 61000, loss: 8.911496
 >> iter 62000, loss: 8.923423
 >> iter 63000, loss: 8.798905
 >> iter 64000, loss: 8.926701
 >> iter 65000, loss: 8.762195
 >> iter 66000, loss: 8.742016
 >> iter 67000, loss: 8.608540
 >> iter 68000, loss: 8.626219
 >> iter 69000, loss: 8.569273
 >> iter 70000, loss: 8.601244
   Number of active neurons: 10
 >> iter 71000, loss: 8.506189
 >> iter 72000, loss: 8.195473
 >> iter 73000, loss: 6.982281
 >> iter 74000, loss: 6.201954
 >> iter 75000, loss: 5.311930
 >> iter 76000, loss: 5.206908
 >> iter 77000, loss: 4.760660
 >> iter 78000, loss: 4.725031
 >> iter 79000, loss: 4.651120
 >> iter 80000, loss: 4.756087
   Number of active neurons: 10
 >> iter 81000, loss: 4.402470
 >> iter 82000, loss: 4.445347
 >> iter 83000, loss: 4.134618
 >> iter 84000, loss: 4.424643
 >> iter 85000, loss: 4.048107
 >> iter 86000, loss: 4.101901
 >> iter 87000, loss: 3.799877
 >> iter 88000, loss: 4.002479
 >> iter 89000, loss: 3.903804
 >> iter 90000, loss: 3.981550
   Number of active neurons: 10
 >> iter 91000, loss: 3.697661
 >> iter 92000, loss: 3.715950
 >> iter 93000, loss: 3.537159
 >> iter 94000, loss: 3.717072
 >> iter 95000, loss: 3.411044
 >> iter 96000, loss: 3.494665
 >> iter 97000, loss: 3.324471
 >> iter 98000, loss: 3.728720
 >> iter 99000, loss: 3.431301
 >> iter 100000, loss: 3.782842
   Number of active neurons: 10
 >> iter 101000, loss: 3.508886
 >> iter 102000, loss: 3.549316
 >> iter 103000, loss: 3.303452
 >> iter 104000, loss: 3.431313
 >> iter 105000, loss: 3.177726
 >> iter 106000, loss: 3.344334
 >> iter 107000, loss: 3.097047
 >> iter 108000, loss: 3.355241
 >> iter 109000, loss: 3.173517
 >> iter 110000, loss: 3.238725
   Number of active neurons: 10
 >> iter 111000, loss: 3.139221
 >> iter 112000, loss: 3.221428
 >> iter 113000, loss: 3.088585
 >> iter 114000, loss: 3.379789
 >> iter 115000, loss: 3.143796
 >> iter 116000, loss: 3.243399
 >> iter 117000, loss: 3.098627
 >> iter 118000, loss: 3.341243
 >> iter 119000, loss: 3.130425
 >> iter 120000, loss: 3.339848
   Number of active neurons: 10
 >> iter 121000, loss: 3.365026
 >> iter 122000, loss: 3.806524
 >> iter 123000, loss: 3.795496
 >> iter 124000, loss: 3.000211
 >> iter 125000, loss: 2.731568
 >> iter 126000, loss: 2.523047
 >> iter 127000, loss: 2.162254
 >> iter 128000, loss: 2.074617
 >> iter 129000, loss: 2.433469
 >> iter 130000, loss: 1.917074
   Number of active neurons: 10
 >> iter 131000, loss: 1.742438
 >> iter 132000, loss: 1.926880
 >> iter 133000, loss: 1.543330
 >> iter 134000, loss: 1.539589
 >> iter 135000, loss: 1.639243
 >> iter 136000, loss: 2.274409
 >> iter 137000, loss: 1.674825
 >> iter 138000, loss: 1.636628
 >> iter 139000, loss: 1.364743
 >> iter 140000, loss: 1.072529
   Number of active neurons: 10
 >> iter 141000, loss: 0.983258
 >> iter 142000, loss: 1.060573
 >> iter 143000, loss: 0.810562
 >> iter 144000, loss: 0.975908
 >> iter 145000, loss: 0.856565
 >> iter 146000, loss: 0.845069
 >> iter 147000, loss: 0.931956
 >> iter 148000, loss: 0.836988
 >> iter 149000, loss: 0.801164
 >> iter 150000, loss: 0.714651
   Number of active neurons: 10
 >> iter 151000, loss: 0.901445
 >> iter 152000, loss: 0.908667
 >> iter 153000, loss: 0.879327
 >> iter 154000, loss: 0.611662
 >> iter 155000, loss: 0.544861
 >> iter 156000, loss: 0.651060
 >> iter 157000, loss: 0.635190
 >> iter 158000, loss: 0.763911
 >> iter 159000, loss: 0.569340
 >> iter 160000, loss: 0.954100
   Number of active neurons: 10
 >> iter 161000, loss: 0.559110
 >> iter 162000, loss: 0.620651
 >> iter 163000, loss: 0.505730
 >> iter 164000, loss: 0.380022
 >> iter 165000, loss: 0.411863
 >> iter 166000, loss: 0.454795
 >> iter 167000, loss: 1.175063
 >> iter 168000, loss: 1.221332
 >> iter 169000, loss: 0.797405
 >> iter 170000, loss: 0.349351
   Number of active neurons: 10
 >> iter 171000, loss: 0.466348
 >> iter 172000, loss: 0.890084
 >> iter 173000, loss: 0.668466
 >> iter 174000, loss: 0.563250
 >> iter 175000, loss: 0.553506
 >> iter 176000, loss: 0.362176
 >> iter 177000, loss: 0.499431
 >> iter 178000, loss: 0.557248
 >> iter 179000, loss: 0.473859
 >> iter 180000, loss: 0.322926
   Number of active neurons: 10
 >> iter 181000, loss: 0.699324
 >> iter 182000, loss: 0.675885
 >> iter 183000, loss: 0.440245
 >> iter 184000, loss: 0.282099
 >> iter 185000, loss: 0.171389
 >> iter 186000, loss: 0.733802
 >> iter 187000, loss: 0.651640
 >> iter 188000, loss: 0.862871
 >> iter 189000, loss: 0.600712
 >> iter 190000, loss: 0.656899
   Number of active neurons: 10
 >> iter 191000, loss: 0.516653
 >> iter 192000, loss: 0.393687
 >> iter 193000, loss: 0.280438
 >> iter 194000, loss: 0.370493
 >> iter 195000, loss: 0.323087
 >> iter 196000, loss: 0.510539
 >> iter 197000, loss: 0.520479
 >> iter 198000, loss: 0.445471
 >> iter 199000, loss: 0.363543
 >> iter 200000, loss: 0.216637
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0269997300027
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.033447
 >> iter 2000, loss: 15.529500
 >> iter 3000, loss: 14.059826
 >> iter 4000, loss: 13.501529
 >> iter 5000, loss: 13.234856
 >> iter 6000, loss: 13.153514
 >> iter 7000, loss: 13.100951
 >> iter 8000, loss: 13.081361
 >> iter 9000, loss: 13.050304
 >> iter 10000, loss: 13.054209
   Number of active neurons: 10
 >> iter 11000, loss: 13.024018
 >> iter 12000, loss: 13.029185
 >> iter 13000, loss: 13.021092
 >> iter 14000, loss: 13.029323
 >> iter 15000, loss: 13.015054
 >> iter 16000, loss: 13.031130
 >> iter 17000, loss: 13.017602
 >> iter 18000, loss: 13.020165
 >> iter 19000, loss: 13.000116
 >> iter 20000, loss: 13.020866
   Number of active neurons: 10
 >> iter 21000, loss: 13.012361
 >> iter 22000, loss: 13.030149
 >> iter 23000, loss: 13.008906
 >> iter 24000, loss: 13.013235
 >> iter 25000, loss: 13.000378
 >> iter 26000, loss: 13.020528
 >> iter 27000, loss: 13.003112
 >> iter 28000, loss: 13.015188
 >> iter 29000, loss: 13.006280
 >> iter 30000, loss: 13.016782
   Number of active neurons: 10
 >> iter 31000, loss: 13.006276
 >> iter 32000, loss: 13.026725
 >> iter 33000, loss: 13.006259
 >> iter 34000, loss: 13.015620
 >> iter 35000, loss: 13.007120
 >> iter 36000, loss: 13.018041
 >> iter 37000, loss: 13.001741
 >> iter 38000, loss: 12.995938
 >> iter 39000, loss: 12.958452
 >> iter 40000, loss: 12.569280
   Number of active neurons: 10
 >> iter 41000, loss: 11.794684
 >> iter 42000, loss: 11.413628
 >> iter 43000, loss: 11.073667
 >> iter 44000, loss: 10.969016
 >> iter 45000, loss: 10.813469
 >> iter 46000, loss: 10.814353
 >> iter 47000, loss: 10.662358
 >> iter 48000, loss: 10.569100
 >> iter 49000, loss: 10.405887
 >> iter 50000, loss: 10.412470
   Number of active neurons: 10
 >> iter 51000, loss: 10.331410
 >> iter 52000, loss: 10.338965
 >> iter 53000, loss: 10.199749
 >> iter 54000, loss: 10.299393
 >> iter 55000, loss: 10.195086
 >> iter 56000, loss: 10.287079
 >> iter 57000, loss: 10.148920
 >> iter 58000, loss: 10.212137
 >> iter 59000, loss: 10.099404
 >> iter 60000, loss: 10.143433
   Number of active neurons: 10
 >> iter 61000, loss: 10.074934
 >> iter 62000, loss: 10.138485
 >> iter 63000, loss: 10.028978
 >> iter 64000, loss: 10.112884
 >> iter 65000, loss: 10.019593
 >> iter 66000, loss: 10.067556
 >> iter 67000, loss: 9.930865
 >> iter 68000, loss: 10.007202
 >> iter 69000, loss: 9.814460
 >> iter 70000, loss: 9.744854
   Number of active neurons: 10
 >> iter 71000, loss: 9.599768
 >> iter 72000, loss: 9.664297
 >> iter 73000, loss: 9.515851
 >> iter 74000, loss: 9.603755
 >> iter 75000, loss: 9.519323
 >> iter 76000, loss: 9.583080
 >> iter 77000, loss: 9.478433
 >> iter 78000, loss: 9.505561
 >> iter 79000, loss: 9.486383
 >> iter 80000, loss: 9.470071
   Number of active neurons: 10
 >> iter 81000, loss: 9.348477
 >> iter 82000, loss: 9.352573
 >> iter 83000, loss: 9.273019
 >> iter 84000, loss: 9.297052
 >> iter 85000, loss: 9.039233
 >> iter 86000, loss: 9.013711
 >> iter 87000, loss: 8.962206
 >> iter 88000, loss: 8.997636
 >> iter 89000, loss: 8.810656
 >> iter 90000, loss: 8.795419
   Number of active neurons: 10
 >> iter 91000, loss: 8.625802
 >> iter 92000, loss: 8.537726
 >> iter 93000, loss: 8.334498
 >> iter 94000, loss: 8.263303
 >> iter 95000, loss: 8.231270
 >> iter 96000, loss: 8.274031
 >> iter 97000, loss: 8.216260
 >> iter 98000, loss: 8.306047
 >> iter 99000, loss: 8.149566
 >> iter 100000, loss: 8.226320
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 15.5756884862
   - Test - Long: 30.8884555772
   - Test - Big: 15.6578434216
   - Test - A: 11.9058729418
   - Test - B: 31.5978934738
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.081224
 >> iter 2000, loss: 15.517181
 >> iter 3000, loss: 14.068896
 >> iter 4000, loss: 13.505936
 >> iter 5000, loss: 13.272805
 >> iter 6000, loss: 13.184244
 >> iter 7000, loss: 13.122660
 >> iter 8000, loss: 13.113293
 >> iter 9000, loss: 13.073872
 >> iter 10000, loss: 13.077562
   Number of active neurons: 10
 >> iter 11000, loss: 13.055557
 >> iter 12000, loss: 13.060468
 >> iter 13000, loss: 13.047209
 >> iter 14000, loss: 13.054606
 >> iter 15000, loss: 13.035429
 >> iter 16000, loss: 13.037577
 >> iter 17000, loss: 13.019480
 >> iter 18000, loss: 13.028005
 >> iter 19000, loss: 13.019238
 >> iter 20000, loss: 13.027666
   Number of active neurons: 10
 >> iter 21000, loss: 13.012594
 >> iter 22000, loss: 13.033246
 >> iter 23000, loss: 13.018897
 >> iter 24000, loss: 13.027983
 >> iter 25000, loss: 13.009570
 >> iter 26000, loss: 13.022719
 >> iter 27000, loss: 13.007934
 >> iter 28000, loss: 13.026392
 >> iter 29000, loss: 13.004565
 >> iter 30000, loss: 13.021955
   Number of active neurons: 10
 >> iter 31000, loss: 13.003119
 >> iter 32000, loss: 13.010997
 >> iter 33000, loss: 12.998360
 >> iter 34000, loss: 13.000840
 >> iter 35000, loss: 12.993426
 >> iter 36000, loss: 13.002184
 >> iter 37000, loss: 12.988123
 >> iter 38000, loss: 12.985394
 >> iter 39000, loss: 12.972407
 >> iter 40000, loss: 12.952621
   Number of active neurons: 10
 >> iter 41000, loss: 12.910011
 >> iter 42000, loss: 12.855694
 >> iter 43000, loss: 12.704378
 >> iter 44000, loss: 12.090411
 >> iter 45000, loss: 11.458036
 >> iter 46000, loss: 11.206424
 >> iter 47000, loss: 10.951152
 >> iter 48000, loss: 10.871805
 >> iter 49000, loss: 10.742083
 >> iter 50000, loss: 10.752279
   Number of active neurons: 10
 >> iter 51000, loss: 10.651164
 >> iter 52000, loss: 10.670003
 >> iter 53000, loss: 10.555026
 >> iter 54000, loss: 10.593379
 >> iter 55000, loss: 10.463942
 >> iter 56000, loss: 10.495312
 >> iter 57000, loss: 10.407989
 >> iter 58000, loss: 10.446293
 >> iter 59000, loss: 10.351007
 >> iter 60000, loss: 10.432097
   Number of active neurons: 10
 >> iter 61000, loss: 10.349247
 >> iter 62000, loss: 10.368552
 >> iter 63000, loss: 10.285165
 >> iter 64000, loss: 10.329121
 >> iter 65000, loss: 10.168388
 >> iter 66000, loss: 10.091418
 >> iter 67000, loss: 9.849368
 >> iter 68000, loss: 9.836141
 >> iter 69000, loss: 9.690406
 >> iter 70000, loss: 9.913165
   Number of active neurons: 10
 >> iter 71000, loss: 9.727199
 >> iter 72000, loss: 9.701386
 >> iter 73000, loss: 9.531977
 >> iter 74000, loss: 9.397693
 >> iter 75000, loss: 9.285704
 >> iter 76000, loss: 9.350603
 >> iter 77000, loss: 9.278987
 >> iter 78000, loss: 9.319957
 >> iter 79000, loss: 9.228710
 >> iter 80000, loss: 9.122266
   Number of active neurons: 10
 >> iter 81000, loss: 8.956190
 >> iter 82000, loss: 8.994810
 >> iter 83000, loss: 8.869967
 >> iter 84000, loss: 8.887831
 >> iter 85000, loss: 8.681643
 >> iter 86000, loss: 8.700669
 >> iter 87000, loss: 8.409279
 >> iter 88000, loss: 8.446081
 >> iter 89000, loss: 8.106706
 >> iter 90000, loss: 8.127505
   Number of active neurons: 10
 >> iter 91000, loss: 7.938232
 >> iter 92000, loss: 8.098040
 >> iter 93000, loss: 7.652630
 >> iter 94000, loss: 7.672042
 >> iter 95000, loss: 7.551033
 >> iter 96000, loss: 7.301451
 >> iter 97000, loss: 7.339125
 >> iter 98000, loss: 7.365786
 >> iter 99000, loss: 7.211074
 >> iter 100000, loss: 7.068714
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 12.0717585648
   - Test - Long: 29.9585020749
   - Test - Big: 12.2898771012
   - Test - A: 0.0
   - Test - B: 31.604559696

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

