 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 2e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 15.425148
 >> iter 2000, loss: 5.722320
 >> iter 3000, loss: 2.121901
 >> iter 4000, loss: 0.791952
 >> iter 5000, loss: 0.300682
 >> iter 6000, loss: 0.118472
 >> iter 7000, loss: 0.050840
 >> iter 8000, loss: 0.025189
 >> iter 9000, loss: 0.015458
 >> iter 10000, loss: 0.011434
   Number of active neurons: 7
 >> iter 11000, loss: 0.009773
 >> iter 12000, loss: 0.008913
 >> iter 13000, loss: 0.008434
 >> iter 14000, loss: 0.008308
 >> iter 15000, loss: 0.007841
 >> iter 16000, loss: 0.193806
 >> iter 17000, loss: 0.076987
 >> iter 18000, loss: 0.033391
 >> iter 19000, loss: 0.017204
 >> iter 20000, loss: 0.152511
   Number of active neurons: 6
 >> iter 21000, loss: 0.061030
 >> iter 22000, loss: 0.027162
 >> iter 23000, loss: 0.213753
 >> iter 24000, loss: 0.086426
 >> iter 25000, loss: 0.038380
 >> iter 26000, loss: 0.019975
 >> iter 27000, loss: 0.057263
 >> iter 28000, loss: 0.027110
 >> iter 29000, loss: 0.015267
 >> iter 30000, loss: 0.010530
   Number of active neurons: 6
 >> iter 31000, loss: 0.216907
 >> iter 32000, loss: 0.087988
 >> iter 33000, loss: 0.039297
 >> iter 34000, loss: 0.020545
 >> iter 35000, loss: 0.142007
 >> iter 36000, loss: 0.059418
 >> iter 37000, loss: 0.028169
 >> iter 38000, loss: 0.016005
 >> iter 39000, loss: 0.022347
 >> iter 40000, loss: 0.013231
   Number of active neurons: 5
 >> iter 41000, loss: 0.157835
 >> iter 42000, loss: 0.064996
 >> iter 43000, loss: 0.030015
 >> iter 44000, loss: 0.016524
 >> iter 45000, loss: 0.060592
 >> iter 46000, loss: 0.027735
 >> iter 47000, loss: 0.015198
 >> iter 48000, loss: 0.010238
 >> iter 49000, loss: 0.008196
 >> iter 50000, loss: 0.007234
   Number of active neurons: 5
 >> iter 51000, loss: 0.218677
 >> iter 52000, loss: 0.087350
 >> iter 53000, loss: 0.038080
 >> iter 54000, loss: 0.019355
 >> iter 55000, loss: 0.012126
 >> iter 56000, loss: 0.009158
 >> iter 57000, loss: 0.061777
 >> iter 58000, loss: 0.027683
 >> iter 59000, loss: 0.014862
 >> iter 60000, loss: 0.009908
   Number of active neurons: 5
 >> iter 61000, loss: 0.241305
 >> iter 62000, loss: 0.095900
 >> iter 63000, loss: 0.041373
 >> iter 64000, loss: 0.020657
 >> iter 65000, loss: 0.012673
 >> iter 66000, loss: 0.009403
 >> iter 67000, loss: 0.023955
 >> iter 68000, loss: 0.013325
 >> iter 69000, loss: 0.040636
 >> iter 70000, loss: 0.019726
   Number of active neurons: 4
 >> iter 71000, loss: 0.030172
 >> iter 72000, loss: 0.015506
 >> iter 73000, loss: 0.009889
 >> iter 74000, loss: 0.007755
 >> iter 75000, loss: 0.007363
 >> iter 76000, loss: 0.006348
 >> iter 77000, loss: 0.058634
 >> iter 78000, loss: 0.025912
 >> iter 79000, loss: 0.032337
 >> iter 80000, loss: 0.015911
   Number of active neurons: 4
 >> iter 81000, loss: 0.009760
 >> iter 82000, loss: 0.007419
 >> iter 83000, loss: 0.023826
 >> iter 84000, loss: 0.012581
 >> iter 85000, loss: 0.035207
 >> iter 86000, loss: 0.016970
 >> iter 87000, loss: 0.029206
 >> iter 88000, loss: 0.014826
 >> iter 89000, loss: 0.360553
 >> iter 90000, loss: 0.142637
   Number of active neurons: 4
 >> iter 91000, loss: 0.060017
 >> iter 92000, loss: 0.028360
 >> iter 93000, loss: 0.103982
 >> iter 94000, loss: 0.045077
 >> iter 95000, loss: 0.022515
 >> iter 96000, loss: 0.013587
 >> iter 97000, loss: 0.129681
 >> iter 98000, loss: 0.054362
 >> iter 99000, loss: 0.025838
 >> iter 100000, loss: 0.014730
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0179998200018
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.401109
 >> iter 2000, loss: 5.949531
 >> iter 3000, loss: 2.206819
 >> iter 4000, loss: 0.823116
 >> iter 5000, loss: 0.311872
 >> iter 6000, loss: 0.122397
 >> iter 7000, loss: 0.052062
 >> iter 8000, loss: 0.025546
 >> iter 9000, loss: 0.015531
 >> iter 10000, loss: 0.011444
   Number of active neurons: 4
 >> iter 11000, loss: 0.028437
 >> iter 12000, loss: 0.016124
 >> iter 13000, loss: 0.193110
 >> iter 14000, loss: 0.079068
 >> iter 15000, loss: 0.036031
 >> iter 16000, loss: 0.019405
 >> iter 17000, loss: 0.012939
 >> iter 18000, loss: 0.010073
 >> iter 19000, loss: 0.008860
 >> iter 20000, loss: 0.008108
   Number of active neurons: 4
 >> iter 21000, loss: 0.254216
 >> iter 22000, loss: 0.101382
 >> iter 23000, loss: 0.062151
 >> iter 24000, loss: 0.029150
 >> iter 25000, loss: 0.016384
 >> iter 26000, loss: 0.011315
 >> iter 27000, loss: 0.009213
 >> iter 28000, loss: 0.008140
 >> iter 29000, loss: 0.647132
 >> iter 30000, loss: 0.442957
   Number of active neurons: 4
 >> iter 31000, loss: 0.175143
 >> iter 32000, loss: 0.073080
 >> iter 33000, loss: 0.034044
 >> iter 34000, loss: 0.018716
 >> iter 35000, loss: 0.012552
 >> iter 36000, loss: 0.009832
 >> iter 37000, loss: 0.008561
 >> iter 38000, loss: 0.007825
 >> iter 39000, loss: 0.007386
 >> iter 40000, loss: 0.007061
   Number of active neurons: 3
 >> iter 41000, loss: 0.006812
 >> iter 42000, loss: 0.006673
 >> iter 43000, loss: 0.103408
 >> iter 44000, loss: 0.042120
 >> iter 45000, loss: 0.019515
 >> iter 46000, loss: 0.011118
 >> iter 47000, loss: 0.175407
 >> iter 48000, loss: 0.212887
 >> iter 49000, loss: 0.086560
 >> iter 50000, loss: 0.038460
   Number of active neurons: 3
 >> iter 51000, loss: 0.019959
 >> iter 52000, loss: 0.012559
 >> iter 53000, loss: 0.009511
 >> iter 54000, loss: 0.008103
 >> iter 55000, loss: 0.007421
 >> iter 56000, loss: 0.007015
 >> iter 57000, loss: 0.032647
 >> iter 58000, loss: 0.017064
 >> iter 59000, loss: 0.010451
 >> iter 60000, loss: 0.009371
   Number of active neurons: 3
 >> iter 61000, loss: 0.007372
 >> iter 62000, loss: 0.007619
 >> iter 63000, loss: 0.053367
 >> iter 64000, loss: 0.032805
 >> iter 65000, loss: 0.016269
 >> iter 66000, loss: 0.010028
 >> iter 67000, loss: 0.007646
 >> iter 68000, loss: 0.008105
 >> iter 69000, loss: 0.167843
 >> iter 70000, loss: 0.074183
   Number of active neurons: 3
 >> iter 71000, loss: 0.032094
 >> iter 72000, loss: 0.016327
 >> iter 73000, loss: 0.192438
 >> iter 74000, loss: 0.076802
 >> iter 75000, loss: 0.034390
 >> iter 76000, loss: 0.019141
 >> iter 77000, loss: 0.040490
 >> iter 78000, loss: 0.019959
 >> iter 79000, loss: 0.015008
 >> iter 80000, loss: 0.029658
   Number of active neurons: 3
 >> iter 81000, loss: 0.236786
 >> iter 82000, loss: 0.095308
 >> iter 83000, loss: 0.041955
 >> iter 84000, loss: 0.022572
 >> iter 85000, loss: 0.022016
 >> iter 86000, loss: 0.013053
 >> iter 87000, loss: 0.009473
 >> iter 88000, loss: 0.008047
 >> iter 89000, loss: 0.121711
 >> iter 90000, loss: 0.051182
   Number of active neurons: 3
 >> iter 91000, loss: 0.052301
 >> iter 92000, loss: 0.023692
 >> iter 93000, loss: 0.013000
 >> iter 94000, loss: 0.008865
 >> iter 95000, loss: 0.012051
 >> iter 96000, loss: 0.009395
 >> iter 97000, loss: 0.124411
 >> iter 98000, loss: 0.051253
 >> iter 99000, loss: 0.232960
 >> iter 100000, loss: 0.098442
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.00599988000241
   - Test - Long: 0.0
   - Test - Big: 0.0079999200008
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.110639
 >> iter 2000, loss: 6.110642
 >> iter 3000, loss: 2.262032
 >> iter 4000, loss: 0.841453
 >> iter 5000, loss: 0.317281
 >> iter 6000, loss: 0.123502
 >> iter 7000, loss: 0.074737
 >> iter 8000, loss: 0.033585
 >> iter 9000, loss: 0.018009
 >> iter 10000, loss: 0.011912
   Number of active neurons: 8
 >> iter 11000, loss: 0.092870
 >> iter 12000, loss: 0.040699
 >> iter 13000, loss: 0.020772
 >> iter 14000, loss: 0.012992
 >> iter 15000, loss: 0.110450
 >> iter 16000, loss: 0.047911
 >> iter 17000, loss: 0.047406
 >> iter 18000, loss: 0.023624
 >> iter 19000, loss: 0.187224
 >> iter 20000, loss: 0.077647
   Number of active neurons: 5
 >> iter 21000, loss: 0.052240
 >> iter 22000, loss: 0.025527
 >> iter 23000, loss: 0.418781
 >> iter 24000, loss: 0.166660
 >> iter 25000, loss: 0.069448
 >> iter 26000, loss: 0.032129
 >> iter 27000, loss: 0.017653
 >> iter 28000, loss: 0.011801
 >> iter 29000, loss: 0.009354
 >> iter 30000, loss: 0.008160
   Number of active neurons: 5
 >> iter 31000, loss: 0.034946
 >> iter 32000, loss: 0.017437
 >> iter 33000, loss: 0.156264
 >> iter 34000, loss: 0.064311
 >> iter 35000, loss: 0.029403
 >> iter 36000, loss: 0.015993
 >> iter 37000, loss: 0.041291
 >> iter 38000, loss: 0.020281
 >> iter 39000, loss: 0.012211
 >> iter 40000, loss: 0.008974
   Number of active neurons: 5
 >> iter 41000, loss: 0.032376
 >> iter 42000, loss: 0.107159
 >> iter 43000, loss: 0.210786
 >> iter 44000, loss: 0.085161
 >> iter 45000, loss: 0.037466
 >> iter 46000, loss: 0.019156
 >> iter 47000, loss: 0.012012
 >> iter 48000, loss: 0.009109
 >> iter 49000, loss: 0.363905
 >> iter 50000, loss: 0.145088
   Number of active neurons: 5
 >> iter 51000, loss: 0.060925
 >> iter 52000, loss: 0.137075
 >> iter 53000, loss: 0.057883
 >> iter 54000, loss: 0.028094
 >> iter 55000, loss: 0.015672
 >> iter 56000, loss: 0.207684
 >> iter 57000, loss: 0.085188
 >> iter 58000, loss: 0.038183
 >> iter 59000, loss: 0.019913
 >> iter 60000, loss: 0.012729
   Number of active neurons: 5
 >> iter 61000, loss: 0.132137
 >> iter 62000, loss: 0.055372
 >> iter 63000, loss: 0.025879
 >> iter 64000, loss: 0.075660
 >> iter 65000, loss: 0.033119
 >> iter 66000, loss: 0.020838
 >> iter 67000, loss: 0.012275
 >> iter 68000, loss: 0.010297
 >> iter 69000, loss: 0.007950
 >> iter 70000, loss: 0.008428
   Number of active neurons: 5
 >> iter 71000, loss: 0.255026
 >> iter 72000, loss: 0.101351
 >> iter 73000, loss: 0.043436
 >> iter 74000, loss: 0.021358
 >> iter 75000, loss: 0.012800
 >> iter 76000, loss: 0.009322
 >> iter 77000, loss: 0.007824
 >> iter 78000, loss: 0.011063
 >> iter 79000, loss: 0.008088
 >> iter 80000, loss: 0.008694
   Number of active neurons: 5
 >> iter 81000, loss: 0.043491
 >> iter 82000, loss: 0.022511
 >> iter 83000, loss: 0.012465
 >> iter 84000, loss: 0.080539
 >> iter 85000, loss: 0.034211
 >> iter 86000, loss: 0.016953
 >> iter 87000, loss: 0.010431
 >> iter 88000, loss: 0.009437
 >> iter 89000, loss: 0.038010
 >> iter 90000, loss: 0.156040
   Number of active neurons: 5
 >> iter 91000, loss: 0.063014
 >> iter 92000, loss: 0.028772
 >> iter 93000, loss: 0.015280
 >> iter 94000, loss: 0.010298
 >> iter 95000, loss: 0.008034
 >> iter 96000, loss: 0.008217
 >> iter 97000, loss: 0.028923
 >> iter 98000, loss: 0.095552
 >> iter 99000, loss: 0.125677
 >> iter 100000, loss: 0.051970
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.129876
 >> iter 2000, loss: 5.993227
 >> iter 3000, loss: 2.222133
 >> iter 4000, loss: 0.829201
 >> iter 5000, loss: 0.314651
 >> iter 6000, loss: 0.123918
 >> iter 7000, loss: 0.053067
 >> iter 8000, loss: 0.026285
 >> iter 9000, loss: 0.016119
 >> iter 10000, loss: 0.011957
   Number of active neurons: 7
 >> iter 11000, loss: 0.014499
 >> iter 12000, loss: 0.017412
 >> iter 13000, loss: 0.037340
 >> iter 14000, loss: 0.019221
 >> iter 15000, loss: 0.012430
 >> iter 16000, loss: 0.009688
 >> iter 17000, loss: 0.208445
 >> iter 18000, loss: 0.085255
 >> iter 19000, loss: 0.038516
 >> iter 20000, loss: 0.020512
   Number of active neurons: 7
 >> iter 21000, loss: 0.013500
 >> iter 22000, loss: 0.010530
 >> iter 23000, loss: 0.312569
 >> iter 24000, loss: 0.126083
 >> iter 25000, loss: 0.054791
 >> iter 26000, loss: 0.027187
 >> iter 27000, loss: 0.016318
 >> iter 28000, loss: 0.011724
 >> iter 29000, loss: 0.009738
 >> iter 30000, loss: 0.008642
   Number of active neurons: 4
 >> iter 31000, loss: 0.059094
 >> iter 32000, loss: 0.027086
 >> iter 33000, loss: 0.014986
 >> iter 34000, loss: 0.010251
 >> iter 35000, loss: 0.194218
 >> iter 36000, loss: 0.078642
 >> iter 37000, loss: 0.035246
 >> iter 38000, loss: 0.018628
 >> iter 39000, loss: 0.012151
 >> iter 40000, loss: 0.009405
   Number of active neurons: 4
 >> iter 41000, loss: 0.176585
 >> iter 42000, loss: 0.072191
 >> iter 43000, loss: 0.032925
 >> iter 44000, loss: 0.017876
 >> iter 45000, loss: 0.011947
 >> iter 46000, loss: 0.009416
 >> iter 47000, loss: 0.008240
 >> iter 48000, loss: 0.007593
 >> iter 49000, loss: 0.007181
 >> iter 50000, loss: 0.006939
   Number of active neurons: 4
 >> iter 51000, loss: 0.007162
 >> iter 52000, loss: 0.157178
 >> iter 53000, loss: 0.062614
 >> iter 54000, loss: 0.027595
 >> iter 55000, loss: 0.014507
 >> iter 56000, loss: 0.434401
 >> iter 57000, loss: 0.188573
 >> iter 58000, loss: 0.075972
 >> iter 59000, loss: 0.201357
 >> iter 60000, loss: 0.082226
   Number of active neurons: 4
 >> iter 61000, loss: 0.037044
 >> iter 62000, loss: 0.019637
 >> iter 63000, loss: 0.012692
 >> iter 64000, loss: 0.009770
 >> iter 65000, loss: 0.438720
 >> iter 66000, loss: 0.175101
 >> iter 67000, loss: 0.073522
 >> iter 68000, loss: 0.034386
 >> iter 69000, loss: 0.019060
 >> iter 70000, loss: 0.012745
   Number of active neurons: 4
 >> iter 71000, loss: 0.009988
 >> iter 72000, loss: 0.008569
 >> iter 73000, loss: 0.034194
 >> iter 74000, loss: 0.017356
 >> iter 75000, loss: 0.010886
 >> iter 76000, loss: 0.008307
 >> iter 77000, loss: 0.007196
 >> iter 78000, loss: 0.006679
 >> iter 79000, loss: 0.023774
 >> iter 80000, loss: 0.401482
   Number of active neurons: 4
 >> iter 81000, loss: 0.155179
 >> iter 82000, loss: 0.063174
 >> iter 83000, loss: 0.028511
 >> iter 84000, loss: 0.015339
 >> iter 85000, loss: 0.012112
 >> iter 86000, loss: 0.009058
 >> iter 87000, loss: 0.007556
 >> iter 88000, loss: 0.006788
 >> iter 89000, loss: 0.037284
 >> iter 90000, loss: 0.017973
   Number of active neurons: 4
 >> iter 91000, loss: 0.010660
 >> iter 92000, loss: 0.007965
 >> iter 93000, loss: 0.112004
 >> iter 94000, loss: 0.045807
 >> iter 95000, loss: 0.021085
 >> iter 96000, loss: 0.011797
 >> iter 97000, loss: 0.061894
 >> iter 98000, loss: 0.117550
 >> iter 99000, loss: 0.076618
 >> iter 100000, loss: 0.032915
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.083949
 >> iter 2000, loss: 5.621679
 >> iter 3000, loss: 2.083023
 >> iter 4000, loss: 0.776182
 >> iter 5000, loss: 0.293846
 >> iter 6000, loss: 0.115290
 >> iter 7000, loss: 0.159294
 >> iter 8000, loss: 0.066952
 >> iter 9000, loss: 0.031721
 >> iter 10000, loss: 0.017895
   Number of active neurons: 6
 >> iter 11000, loss: 0.012494
 >> iter 12000, loss: 0.010058
 >> iter 13000, loss: 0.009268
 >> iter 14000, loss: 0.008379
 >> iter 15000, loss: 0.008005
 >> iter 16000, loss: 0.008588
 >> iter 17000, loss: 0.068231
 >> iter 18000, loss: 0.030188
 >> iter 19000, loss: 0.112550
 >> iter 20000, loss: 0.052115
   Number of active neurons: 5
 >> iter 21000, loss: 0.024777
 >> iter 22000, loss: 0.015483
 >> iter 23000, loss: 0.045203
 >> iter 24000, loss: 0.021924
 >> iter 25000, loss: 0.012654
 >> iter 26000, loss: 0.010048
 >> iter 27000, loss: 0.041777
 >> iter 28000, loss: 0.021116
 >> iter 29000, loss: 0.012050
 >> iter 30000, loss: 0.008640
   Number of active neurons: 5
 >> iter 31000, loss: 0.102531
 >> iter 32000, loss: 0.044623
 >> iter 33000, loss: 0.021290
 >> iter 34000, loss: 0.012440
 >> iter 35000, loss: 0.009024
 >> iter 36000, loss: 0.009194
 >> iter 37000, loss: 0.007611
 >> iter 38000, loss: 0.007995
 >> iter 39000, loss: 0.006998
 >> iter 40000, loss: 0.007652
   Number of active neurons: 5
 >> iter 41000, loss: 0.007015
 >> iter 42000, loss: 0.007685
 >> iter 43000, loss: 0.006631
 >> iter 44000, loss: 0.007073
 >> iter 45000, loss: 0.006501
 >> iter 46000, loss: 0.007589
 >> iter 47000, loss: 0.042470
 >> iter 48000, loss: 0.021499
 >> iter 49000, loss: 0.032513
 >> iter 50000, loss: 0.016060
   Number of active neurons: 3
 >> iter 51000, loss: 0.009936
 >> iter 52000, loss: 0.007655
 >> iter 53000, loss: 0.030490
 >> iter 54000, loss: 0.186910
 >> iter 55000, loss: 0.297086
 >> iter 56000, loss: 0.116107
 >> iter 57000, loss: 0.048620
 >> iter 58000, loss: 0.023216
 >> iter 59000, loss: 0.013496
 >> iter 60000, loss: 0.009651
   Number of active neurons: 3
 >> iter 61000, loss: 0.040422
 >> iter 62000, loss: 0.019529
 >> iter 63000, loss: 0.021667
 >> iter 64000, loss: 0.012264
 >> iter 65000, loss: 0.046948
 >> iter 66000, loss: 0.021773
 >> iter 67000, loss: 0.039069
 >> iter 68000, loss: 0.018673
 >> iter 69000, loss: 0.027617
 >> iter 70000, loss: 0.014360
   Number of active neurons: 3
 >> iter 71000, loss: 0.027820
 >> iter 72000, loss: 0.014391
 >> iter 73000, loss: 0.225882
 >> iter 74000, loss: 0.090137
 >> iter 75000, loss: 0.039198
 >> iter 76000, loss: 0.019814
 >> iter 77000, loss: 0.012250
 >> iter 78000, loss: 0.009124
 >> iter 79000, loss: 0.021918
 >> iter 80000, loss: 0.012351
   Number of active neurons: 3
 >> iter 81000, loss: 0.046308
 >> iter 82000, loss: 0.021521
 >> iter 83000, loss: 0.012129
 >> iter 84000, loss: 0.008464
 >> iter 85000, loss: 0.023206
 >> iter 86000, loss: 0.012525
 >> iter 87000, loss: 0.092538
 >> iter 88000, loss: 0.039026
 >> iter 89000, loss: 0.018928
 >> iter 90000, loss: 0.011216
   Number of active neurons: 3
 >> iter 91000, loss: 0.038405
 >> iter 92000, loss: 0.018333
 >> iter 93000, loss: 0.010740
 >> iter 94000, loss: 0.007761
 >> iter 95000, loss: 0.036011
 >> iter 96000, loss: 0.017177
 >> iter 97000, loss: 0.016872
 >> iter 98000, loss: 0.009890
 >> iter 99000, loss: 0.012631
 >> iter 100000, loss: 0.008150
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0159998400016
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.142481
 >> iter 2000, loss: 5.762256
 >> iter 3000, loss: 2.137417
 >> iter 4000, loss: 0.797416
 >> iter 5000, loss: 0.302356
 >> iter 6000, loss: 0.118867
 >> iter 7000, loss: 0.051141
 >> iter 8000, loss: 0.025188
 >> iter 9000, loss: 0.015261
 >> iter 10000, loss: 0.011177
   Number of active neurons: 4
 >> iter 11000, loss: 0.047754
 >> iter 12000, loss: 0.023388
 >> iter 13000, loss: 0.098428
 >> iter 14000, loss: 0.042873
 >> iter 15000, loss: 0.021920
 >> iter 16000, loss: 0.013690
 >> iter 17000, loss: 0.020828
 >> iter 18000, loss: 0.012918
 >> iter 19000, loss: 0.009804
 >> iter 20000, loss: 0.008375
   Number of active neurons: 4
 >> iter 21000, loss: 0.007862
 >> iter 22000, loss: 0.007425
 >> iter 23000, loss: 0.007144
 >> iter 24000, loss: 0.006973
 >> iter 25000, loss: 0.203530
 >> iter 26000, loss: 0.085289
 >> iter 27000, loss: 0.036582
 >> iter 28000, loss: 0.018375
 >> iter 29000, loss: 0.442445
 >> iter 30000, loss: 0.302366
   Number of active neurons: 4
 >> iter 31000, loss: 0.125479
 >> iter 32000, loss: 0.054230
 >> iter 33000, loss: 0.026929
 >> iter 34000, loss: 0.016084
 >> iter 35000, loss: 0.011602
 >> iter 36000, loss: 0.009523
 >> iter 37000, loss: 0.008489
 >> iter 38000, loss: 0.007844
 >> iter 39000, loss: 0.007439
 >> iter 40000, loss: 0.007124
   Number of active neurons: 4
 >> iter 41000, loss: 0.006870
 >> iter 42000, loss: 0.007414
 >> iter 43000, loss: 0.006768
 >> iter 44000, loss: 0.007585
 >> iter 45000, loss: 0.006647
 >> iter 46000, loss: 0.007087
 >> iter 47000, loss: 0.006375
 >> iter 48000, loss: 0.007201
 >> iter 49000, loss: 0.006270
 >> iter 50000, loss: 0.006083
   Number of active neurons: 3
 >> iter 51000, loss: 0.035458
 >> iter 52000, loss: 0.017339
 >> iter 53000, loss: 0.010107
 >> iter 54000, loss: 0.008205
 >> iter 55000, loss: 0.034641
 >> iter 56000, loss: 0.016593
 >> iter 57000, loss: 0.009799
 >> iter 58000, loss: 0.008070
 >> iter 59000, loss: 0.044282
 >> iter 60000, loss: 0.020180
   Number of active neurons: 3
 >> iter 61000, loss: 0.243103
 >> iter 62000, loss: 0.096950
 >> iter 63000, loss: 0.600326
 >> iter 64000, loss: 0.265497
 >> iter 65000, loss: 0.107429
 >> iter 66000, loss: 0.047315
 >> iter 67000, loss: 0.024046
 >> iter 68000, loss: 0.014697
 >> iter 69000, loss: 0.010714
 >> iter 70000, loss: 0.008843
   Number of active neurons: 3
 >> iter 71000, loss: 0.007842
 >> iter 72000, loss: 0.007225
 >> iter 73000, loss: 0.006817
 >> iter 74000, loss: 0.006490
 >> iter 75000, loss: 0.011185
 >> iter 76000, loss: 0.007827
 >> iter 77000, loss: 0.006538
 >> iter 78000, loss: 0.005987
 >> iter 79000, loss: 0.009166
 >> iter 80000, loss: 0.006822
   Number of active neurons: 3
 >> iter 81000, loss: 0.009775
 >> iter 82000, loss: 0.006945
 >> iter 83000, loss: 0.018215
 >> iter 84000, loss: 0.056150
 >> iter 85000, loss: 0.024496
 >> iter 86000, loss: 0.012916
 >> iter 87000, loss: 0.008341
 >> iter 88000, loss: 0.006921
 >> iter 89000, loss: 0.010585
 >> iter 90000, loss: 0.007327
   Number of active neurons: 3
 >> iter 91000, loss: 0.006259
 >> iter 92000, loss: 0.005499
 >> iter 93000, loss: 0.005209
 >> iter 94000, loss: 0.005204
 >> iter 95000, loss: 0.009970
 >> iter 96000, loss: 0.006921
 >> iter 97000, loss: 0.057259
 >> iter 98000, loss: 0.024592
 >> iter 99000, loss: 0.012388
 >> iter 100000, loss: 0.074417
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.238532
 >> iter 2000, loss: 6.107171
 >> iter 3000, loss: 2.259724
 >> iter 4000, loss: 0.839989
 >> iter 5000, loss: 0.455134
 >> iter 6000, loss: 0.176557
 >> iter 7000, loss: 0.072145
 >> iter 8000, loss: 0.032685
 >> iter 9000, loss: 0.017705
 >> iter 10000, loss: 0.028729
   Number of active neurons: 7
 >> iter 11000, loss: 0.090403
 >> iter 12000, loss: 0.039029
 >> iter 13000, loss: 0.019634
 >> iter 14000, loss: 0.334955
 >> iter 15000, loss: 0.134253
 >> iter 16000, loss: 0.056845
 >> iter 17000, loss: 0.027078
 >> iter 18000, loss: 0.015363
 >> iter 19000, loss: 0.063724
 >> iter 20000, loss: 0.028911
   Number of active neurons: 7
 >> iter 21000, loss: 0.015640
 >> iter 22000, loss: 0.010486
 >> iter 23000, loss: 0.180576
 >> iter 24000, loss: 0.074481
 >> iter 25000, loss: 0.033731
 >> iter 26000, loss: 0.018018
 >> iter 27000, loss: 0.121306
 >> iter 28000, loss: 0.050439
 >> iter 29000, loss: 0.023788
 >> iter 30000, loss: 0.055179
   Number of active neurons: 7
 >> iter 31000, loss: 0.123420
 >> iter 32000, loss: 0.057125
 >> iter 33000, loss: 0.026653
 >> iter 34000, loss: 0.015934
 >> iter 35000, loss: 0.010570
 >> iter 36000, loss: 0.041511
 >> iter 37000, loss: 0.163712
 >> iter 38000, loss: 0.067590
 >> iter 39000, loss: 0.030985
 >> iter 40000, loss: 0.016823
   Number of active neurons: 7
 >> iter 41000, loss: 0.037438
 >> iter 42000, loss: 0.020047
 >> iter 43000, loss: 0.012094
 >> iter 44000, loss: 0.009815
 >> iter 45000, loss: 0.219013
 >> iter 46000, loss: 0.088529
 >> iter 47000, loss: 0.038950
 >> iter 48000, loss: 0.019946
 >> iter 49000, loss: 0.012325
 >> iter 50000, loss: 0.079880
   Number of active neurons: 7
 >> iter 51000, loss: 0.034253
 >> iter 52000, loss: 0.022931
 >> iter 53000, loss: 0.258254
 >> iter 54000, loss: 0.104406
 >> iter 55000, loss: 0.045426
 >> iter 56000, loss: 0.022598
 >> iter 57000, loss: 0.013596
 >> iter 58000, loss: 0.009844
 >> iter 59000, loss: 0.217047
 >> iter 60000, loss: 0.088316
   Number of active neurons: 7
 >> iter 61000, loss: 0.039013
 >> iter 62000, loss: 0.019920
 >> iter 63000, loss: 0.012515
 >> iter 64000, loss: 0.009279
 >> iter 65000, loss: 0.007701
 >> iter 66000, loss: 0.087220
 >> iter 67000, loss: 0.036731
 >> iter 68000, loss: 0.025287
 >> iter 69000, loss: 0.224925
 >> iter 70000, loss: 0.090893
   Number of active neurons: 7
 >> iter 71000, loss: 0.039879
 >> iter 72000, loss: 0.020276
 >> iter 73000, loss: 0.018141
 >> iter 74000, loss: 0.230011
 >> iter 75000, loss: 0.091941
 >> iter 76000, loss: 0.040178
 >> iter 77000, loss: 0.019852
 >> iter 78000, loss: 0.012119
 >> iter 79000, loss: 0.008869
 >> iter 80000, loss: 0.013857
   Number of active neurons: 6
 >> iter 81000, loss: 0.155437
 >> iter 82000, loss: 0.063891
 >> iter 83000, loss: 0.029187
 >> iter 84000, loss: 0.022679
 >> iter 85000, loss: 0.013280
 >> iter 86000, loss: 0.016089
 >> iter 87000, loss: 0.170746
 >> iter 88000, loss: 0.074232
 >> iter 89000, loss: 0.033231
 >> iter 90000, loss: 0.017512
   Number of active neurons: 6
 >> iter 91000, loss: 0.034800
 >> iter 92000, loss: 0.017586
 >> iter 93000, loss: 0.022410
 >> iter 94000, loss: 0.267866
 >> iter 95000, loss: 0.105395
 >> iter 96000, loss: 0.044252
 >> iter 97000, loss: 0.021129
 >> iter 98000, loss: 0.082535
 >> iter 99000, loss: 0.035139
 >> iter 100000, loss: 0.020658
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.041887
 >> iter 2000, loss: 5.562178
 >> iter 3000, loss: 2.064037
 >> iter 4000, loss: 0.767924
 >> iter 5000, loss: 0.350856
 >> iter 6000, loss: 0.136854
 >> iter 7000, loss: 0.107039
 >> iter 8000, loss: 0.046237
 >> iter 9000, loss: 0.023234
 >> iter 10000, loss: 0.014032
   Number of active neurons: 7
 >> iter 11000, loss: 0.010985
 >> iter 12000, loss: 0.009004
 >> iter 13000, loss: 0.008039
 >> iter 14000, loss: 0.221263
 >> iter 15000, loss: 0.088031
 >> iter 16000, loss: 0.037829
 >> iter 17000, loss: 0.018897
 >> iter 18000, loss: 0.011558
 >> iter 19000, loss: 0.008731
 >> iter 20000, loss: 0.007514
   Number of active neurons: 7
 >> iter 21000, loss: 0.212069
 >> iter 22000, loss: 0.086111
 >> iter 23000, loss: 0.038114
 >> iter 24000, loss: 0.019587
 >> iter 25000, loss: 0.012289
 >> iter 26000, loss: 0.009878
 >> iter 27000, loss: 0.023567
 >> iter 28000, loss: 0.012865
 >> iter 29000, loss: 0.008935
 >> iter 30000, loss: 0.007306
   Number of active neurons: 5
 >> iter 31000, loss: 0.044233
 >> iter 32000, loss: 0.103987
 >> iter 33000, loss: 0.043592
 >> iter 34000, loss: 0.021091
 >> iter 35000, loss: 0.012284
 >> iter 36000, loss: 0.077595
 >> iter 37000, loss: 0.041472
 >> iter 38000, loss: 0.020245
 >> iter 39000, loss: 0.012097
 >> iter 40000, loss: 0.091270
   Number of active neurons: 5
 >> iter 41000, loss: 0.092899
 >> iter 42000, loss: 0.040177
 >> iter 43000, loss: 0.028568
 >> iter 44000, loss: 0.015061
 >> iter 45000, loss: 0.009815
 >> iter 46000, loss: 0.007689
 >> iter 47000, loss: 0.082117
 >> iter 48000, loss: 0.035139
 >> iter 49000, loss: 0.017449
 >> iter 50000, loss: 0.010625
   Number of active neurons: 5
 >> iter 51000, loss: 0.041685
 >> iter 52000, loss: 0.019674
 >> iter 53000, loss: 0.011332
 >> iter 54000, loss: 0.008080
 >> iter 55000, loss: 0.020078
 >> iter 56000, loss: 0.011215
 >> iter 57000, loss: 0.037743
 >> iter 58000, loss: 0.017824
 >> iter 59000, loss: 0.011349
 >> iter 60000, loss: 0.039221
   Number of active neurons: 5
 >> iter 61000, loss: 0.018203
 >> iter 62000, loss: 0.010528
 >> iter 63000, loss: 0.025130
 >> iter 64000, loss: 0.013075
 >> iter 65000, loss: 0.042177
 >> iter 66000, loss: 0.019510
 >> iter 67000, loss: 0.259595
 >> iter 68000, loss: 0.104616
 >> iter 69000, loss: 0.045368
 >> iter 70000, loss: 0.022403
   Number of active neurons: 5
 >> iter 71000, loss: 0.013296
 >> iter 72000, loss: 0.009443
 >> iter 73000, loss: 0.085035
 >> iter 74000, loss: 0.037009
 >> iter 75000, loss: 0.119401
 >> iter 76000, loss: 0.050818
 >> iter 77000, loss: 0.149725
 >> iter 78000, loss: 0.063436
 >> iter 79000, loss: 0.029755
 >> iter 80000, loss: 0.016384
   Number of active neurons: 5
 >> iter 81000, loss: 0.010883
 >> iter 82000, loss: 0.008426
 >> iter 83000, loss: 0.223427
 >> iter 84000, loss: 0.091423
 >> iter 85000, loss: 0.040587
 >> iter 86000, loss: 0.020739
 >> iter 87000, loss: 0.012767
 >> iter 88000, loss: 0.009314
 >> iter 89000, loss: 0.143666
 >> iter 90000, loss: 0.059671
   Number of active neurons: 4
 >> iter 91000, loss: 0.027694
 >> iter 92000, loss: 0.015152
 >> iter 93000, loss: 0.042498
 >> iter 94000, loss: 0.020487
 >> iter 95000, loss: 0.011946
 >> iter 96000, loss: 0.008421
 >> iter 97000, loss: 0.201181
 >> iter 98000, loss: 0.082226
 >> iter 99000, loss: 0.036612
 >> iter 100000, loss: 0.018843
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.330590
 >> iter 2000, loss: 5.694973
 >> iter 3000, loss: 2.114815
 >> iter 4000, loss: 0.787963
 >> iter 5000, loss: 0.298948
 >> iter 6000, loss: 0.117130
 >> iter 7000, loss: 0.049710
 >> iter 8000, loss: 0.024375
 >> iter 9000, loss: 0.014900
 >> iter 10000, loss: 0.011071
   Number of active neurons: 9
 >> iter 11000, loss: 0.131727
 >> iter 12000, loss: 0.055416
 >> iter 13000, loss: 0.026711
 >> iter 14000, loss: 0.015662
 >> iter 15000, loss: 0.011408
 >> iter 16000, loss: 0.009541
 >> iter 17000, loss: 0.027495
 >> iter 18000, loss: 0.015113
 >> iter 19000, loss: 0.010478
 >> iter 20000, loss: 0.008561
   Number of active neurons: 6
 >> iter 21000, loss: 0.007854
 >> iter 22000, loss: 0.007398
 >> iter 23000, loss: 0.039833
 >> iter 24000, loss: 0.020498
 >> iter 25000, loss: 0.011973
 >> iter 26000, loss: 0.008755
 >> iter 27000, loss: 0.103355
 >> iter 28000, loss: 0.213648
 >> iter 29000, loss: 0.086205
 >> iter 30000, loss: 0.037994
   Number of active neurons: 5
 >> iter 31000, loss: 0.019616
 >> iter 32000, loss: 0.012383
 >> iter 33000, loss: 0.009443
 >> iter 34000, loss: 0.008084
 >> iter 35000, loss: 0.031231
 >> iter 36000, loss: 0.015910
 >> iter 37000, loss: 0.010143
 >> iter 38000, loss: 0.007956
 >> iter 39000, loss: 0.020999
 >> iter 40000, loss: 0.011675
   Number of active neurons: 4
 >> iter 41000, loss: 0.008181
 >> iter 42000, loss: 0.007772
 >> iter 43000, loss: 0.026297
 >> iter 44000, loss: 0.013619
 >> iter 45000, loss: 0.008792
 >> iter 46000, loss: 0.007027
 >> iter 47000, loss: 0.135461
 >> iter 48000, loss: 0.055955
 >> iter 49000, loss: 0.025155
 >> iter 50000, loss: 0.115978
   Number of active neurons: 4
 >> iter 51000, loss: 0.048494
 >> iter 52000, loss: 0.024181
 >> iter 53000, loss: 0.013771
 >> iter 54000, loss: 0.013039
 >> iter 55000, loss: 0.009138
 >> iter 56000, loss: 0.086563
 >> iter 57000, loss: 0.036537
 >> iter 58000, loss: 0.018872
 >> iter 59000, loss: 0.011104
 >> iter 60000, loss: 0.089587
   Number of active neurons: 4
 >> iter 61000, loss: 0.172789
 >> iter 62000, loss: 0.070266
 >> iter 63000, loss: 0.031436
 >> iter 64000, loss: 0.016729
 >> iter 65000, loss: 0.010884
 >> iter 66000, loss: 0.009121
 >> iter 67000, loss: 0.007588
 >> iter 68000, loss: 0.090102
 >> iter 69000, loss: 0.193247
 >> iter 70000, loss: 0.077228
   Number of active neurons: 4
 >> iter 71000, loss: 0.033777
 >> iter 72000, loss: 0.018041
 >> iter 73000, loss: 0.011213
 >> iter 74000, loss: 0.009438
 >> iter 75000, loss: 0.007612
 >> iter 76000, loss: 0.037377
 >> iter 77000, loss: 0.066010
 >> iter 78000, loss: 0.028701
 >> iter 79000, loss: 0.014757
 >> iter 80000, loss: 0.010704
   Number of active neurons: 4
 >> iter 81000, loss: 0.007801
 >> iter 82000, loss: 0.063458
 >> iter 83000, loss: 0.027336
 >> iter 84000, loss: 0.013854
 >> iter 85000, loss: 0.008803
 >> iter 86000, loss: 0.006891
 >> iter 87000, loss: 0.047835
 >> iter 88000, loss: 0.112314
 >> iter 89000, loss: 0.046083
 >> iter 90000, loss: 0.022652
   Number of active neurons: 4
 >> iter 91000, loss: 0.012542
 >> iter 92000, loss: 0.105931
 >> iter 93000, loss: 0.697827
 >> iter 94000, loss: 0.325242
 >> iter 95000, loss: 0.130342
 >> iter 96000, loss: 0.055933
 >> iter 97000, loss: 0.027257
 >> iter 98000, loss: 0.015856
 >> iter 99000, loss: 0.011156
 >> iter 100000, loss: 0.009179
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.551948
 >> iter 2000, loss: 5.823026
 >> iter 3000, loss: 2.160710
 >> iter 4000, loss: 0.807114
 >> iter 5000, loss: 0.306721
 >> iter 6000, loss: 0.121072
 >> iter 7000, loss: 0.051962
 >> iter 8000, loss: 0.025850
 >> iter 9000, loss: 0.015825
 >> iter 10000, loss: 0.011785
   Number of active neurons: 5
 >> iter 11000, loss: 0.032261
 >> iter 12000, loss: 0.017675
 >> iter 13000, loss: 0.039077
 >> iter 14000, loss: 0.019631
 >> iter 15000, loss: 0.012316
 >> iter 16000, loss: 0.009463
 >> iter 17000, loss: 0.027786
 >> iter 18000, loss: 0.015217
 >> iter 19000, loss: 0.037891
 >> iter 20000, loss: 0.018876
   Number of active neurons: 4
 >> iter 21000, loss: 0.034568
 >> iter 22000, loss: 0.017287
 >> iter 23000, loss: 0.010832
 >> iter 24000, loss: 0.008382
 >> iter 25000, loss: 0.032237
 >> iter 26000, loss: 0.016046
 >> iter 27000, loss: 0.010046
 >> iter 28000, loss: 0.007807
 >> iter 29000, loss: 0.101769
 >> iter 30000, loss: 0.042276
   Number of active neurons: 4
 >> iter 31000, loss: 0.223603
 >> iter 32000, loss: 0.089601
 >> iter 33000, loss: 0.039396
 >> iter 34000, loss: 0.020310
 >> iter 35000, loss: 0.014821
 >> iter 36000, loss: 0.010778
 >> iter 37000, loss: 0.057221
 >> iter 38000, loss: 0.026348
 >> iter 39000, loss: 0.071450
 >> iter 40000, loss: 0.031625
   Number of active neurons: 4
 >> iter 41000, loss: 0.016586
 >> iter 42000, loss: 0.010765
 >> iter 43000, loss: 0.089232
 >> iter 44000, loss: 0.038404
 >> iter 45000, loss: 0.211356
 >> iter 46000, loss: 0.085654
 >> iter 47000, loss: 0.038054
 >> iter 48000, loss: 0.019740
 >> iter 49000, loss: 0.052340
 >> iter 50000, loss: 0.024736
   Number of active neurons: 4
 >> iter 51000, loss: 0.022646
 >> iter 52000, loss: 0.013080
 >> iter 53000, loss: 0.055794
 >> iter 54000, loss: 0.025444
 >> iter 55000, loss: 0.013947
 >> iter 56000, loss: 0.009469
 >> iter 57000, loss: 0.095119
 >> iter 58000, loss: 0.040117
 >> iter 59000, loss: 0.019495
 >> iter 60000, loss: 0.011620
   Number of active neurons: 4
 >> iter 61000, loss: 0.081279
 >> iter 62000, loss: 0.035204
 >> iter 63000, loss: 0.017727
 >> iter 64000, loss: 0.010918
 >> iter 65000, loss: 0.163942
 >> iter 66000, loss: 0.066476
 >> iter 67000, loss: 0.029888
 >> iter 68000, loss: 0.015920
 >> iter 69000, loss: 0.011023
 >> iter 70000, loss: 0.008446
   Number of active neurons: 3
 >> iter 71000, loss: 0.070159
 >> iter 72000, loss: 0.030406
 >> iter 73000, loss: 0.015482
 >> iter 74000, loss: 0.009760
 >> iter 75000, loss: 0.038922
 >> iter 76000, loss: 0.018583
 >> iter 77000, loss: 0.071218
 >> iter 78000, loss: 0.030858
 >> iter 79000, loss: 0.053282
 >> iter 80000, loss: 0.024236
   Number of active neurons: 3
 >> iter 81000, loss: 0.049715
 >> iter 82000, loss: 0.022880
 >> iter 83000, loss: 0.012684
 >> iter 84000, loss: 0.008689
 >> iter 85000, loss: 0.046956
 >> iter 86000, loss: 0.021534
 >> iter 87000, loss: 0.011919
 >> iter 88000, loss: 0.008171
 >> iter 89000, loss: 0.015538
 >> iter 90000, loss: 0.009295
   Number of active neurons: 3
 >> iter 91000, loss: 0.021869
 >> iter 92000, loss: 0.011621
 >> iter 93000, loss: 0.073376
 >> iter 94000, loss: 0.031054
 >> iter 95000, loss: 0.015237
 >> iter 96000, loss: 0.009235
 >> iter 97000, loss: 0.133745
 >> iter 98000, loss: 0.054341
 >> iter 99000, loss: 0.184368
 >> iter 100000, loss: 0.074780
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.483390
 >> iter 2000, loss: 6.207645
 >> iter 3000, loss: 2.307802
 >> iter 4000, loss: 0.862243
 >> iter 5000, loss: 0.327745
 >> iter 6000, loss: 0.129263
 >> iter 7000, loss: 0.055482
 >> iter 8000, loss: 0.027512
 >> iter 9000, loss: 0.016914
 >> iter 10000, loss: 0.012503
   Number of active neurons: 7
 >> iter 11000, loss: 0.010739
 >> iter 12000, loss: 0.009724
 >> iter 13000, loss: 0.009295
 >> iter 14000, loss: 0.008851
 >> iter 15000, loss: 0.008666
 >> iter 16000, loss: 0.008325
 >> iter 17000, loss: 0.008287
 >> iter 18000, loss: 0.007979
 >> iter 19000, loss: 0.029410
 >> iter 20000, loss: 0.015440
   Number of active neurons: 6
 >> iter 21000, loss: 0.010362
 >> iter 22000, loss: 0.008308
 >> iter 23000, loss: 0.007589
 >> iter 24000, loss: 0.007227
 >> iter 25000, loss: 0.339690
 >> iter 26000, loss: 0.133742
 >> iter 27000, loss: 0.074129
 >> iter 28000, loss: 0.033680
 >> iter 29000, loss: 0.018160
 >> iter 30000, loss: 0.011943
   Number of active neurons: 5
 >> iter 31000, loss: 0.151926
 >> iter 32000, loss: 0.063039
 >> iter 33000, loss: 0.076181
 >> iter 34000, loss: 0.034205
 >> iter 35000, loss: 0.024850
 >> iter 36000, loss: 0.014338
 >> iter 37000, loss: 0.010091
 >> iter 38000, loss: 0.008227
 >> iter 39000, loss: 0.007450
 >> iter 40000, loss: 0.007013
   Number of active neurons: 5
 >> iter 41000, loss: 0.006957
 >> iter 42000, loss: 0.006708
 >> iter 43000, loss: 0.006596
 >> iter 44000, loss: 0.006451
 >> iter 45000, loss: 0.247995
 >> iter 46000, loss: 0.098345
 >> iter 47000, loss: 0.042092
 >> iter 48000, loss: 0.020810
 >> iter 49000, loss: 0.012693
 >> iter 50000, loss: 0.009457
   Number of active neurons: 5
 >> iter 51000, loss: 0.008182
 >> iter 52000, loss: 0.007498
 >> iter 53000, loss: 0.007133
 >> iter 54000, loss: 0.006875
 >> iter 55000, loss: 0.231260
 >> iter 56000, loss: 0.091398
 >> iter 57000, loss: 0.039050
 >> iter 58000, loss: 0.019359
 >> iter 59000, loss: 0.012789
 >> iter 60000, loss: 0.227397
   Number of active neurons: 5
 >> iter 61000, loss: 0.090630
 >> iter 62000, loss: 0.039277
 >> iter 63000, loss: 0.019765
 >> iter 64000, loss: 0.063210
 >> iter 65000, loss: 0.028780
 >> iter 66000, loss: 0.133634
 >> iter 67000, loss: 0.055274
 >> iter 68000, loss: 0.025578
 >> iter 69000, loss: 0.014317
 >> iter 70000, loss: 0.009868
   Number of active neurons: 5
 >> iter 71000, loss: 0.008081
 >> iter 72000, loss: 0.007298
 >> iter 73000, loss: 0.275764
 >> iter 74000, loss: 0.109840
 >> iter 75000, loss: 0.148644
 >> iter 76000, loss: 0.062309
 >> iter 77000, loss: 0.029349
 >> iter 78000, loss: 0.016530
 >> iter 79000, loss: 0.050881
 >> iter 80000, loss: 0.148952
   Number of active neurons: 5
 >> iter 81000, loss: 0.061293
 >> iter 82000, loss: 0.027916
 >> iter 83000, loss: 0.104719
 >> iter 84000, loss: 0.044356
 >> iter 85000, loss: 0.089670
 >> iter 86000, loss: 0.039135
 >> iter 87000, loss: 0.019960
 >> iter 88000, loss: 0.014237
 >> iter 89000, loss: 0.009971
 >> iter 90000, loss: 0.008266
   Number of active neurons: 4
 >> iter 91000, loss: 0.031485
 >> iter 92000, loss: 0.311664
 >> iter 93000, loss: 0.122821
 >> iter 94000, loss: 0.051976
 >> iter 95000, loss: 0.025209
 >> iter 96000, loss: 0.014777
 >> iter 97000, loss: 0.010591
 >> iter 98000, loss: 0.008754
 >> iter 99000, loss: 0.007898
 >> iter 100000, loss: 0.009168
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.240258
 >> iter 2000, loss: 5.810750
 >> iter 3000, loss: 2.157720
 >> iter 4000, loss: 0.806381
 >> iter 5000, loss: 0.309251
 >> iter 6000, loss: 0.122034
 >> iter 7000, loss: 0.052128
 >> iter 8000, loss: 0.025624
 >> iter 9000, loss: 0.015469
 >> iter 10000, loss: 0.011301
   Number of active neurons: 5
 >> iter 11000, loss: 0.011945
 >> iter 12000, loss: 0.009711
 >> iter 13000, loss: 0.008426
 >> iter 14000, loss: 0.007885
 >> iter 15000, loss: 0.007470
 >> iter 16000, loss: 0.007367
 >> iter 17000, loss: 0.007069
 >> iter 18000, loss: 0.013544
 >> iter 19000, loss: 0.009384
 >> iter 20000, loss: 0.013430
   Number of active neurons: 5
 >> iter 21000, loss: 0.008910
 >> iter 22000, loss: 0.007194
 >> iter 23000, loss: 0.006590
 >> iter 24000, loss: 0.006403
 >> iter 25000, loss: 0.006281
 >> iter 26000, loss: 0.152119
 >> iter 27000, loss: 0.061252
 >> iter 28000, loss: 0.027435
 >> iter 29000, loss: 0.014740
 >> iter 30000, loss: 0.010075
   Number of active neurons: 5
 >> iter 31000, loss: 0.011446
 >> iter 32000, loss: 0.039278
 >> iter 33000, loss: 0.020430
 >> iter 34000, loss: 0.085655
 >> iter 35000, loss: 0.035612
 >> iter 36000, loss: 0.017114
 >> iter 37000, loss: 0.010203
 >> iter 38000, loss: 0.007728
 >> iter 39000, loss: 0.006625
 >> iter 40000, loss: 0.006403
   Number of active neurons: 5
 >> iter 41000, loss: 0.006032
 >> iter 42000, loss: 0.006149
 >> iter 43000, loss: 0.005873
 >> iter 44000, loss: 0.054368
 >> iter 45000, loss: 0.023710
 >> iter 46000, loss: 0.012736
 >> iter 47000, loss: 0.008295
 >> iter 48000, loss: 0.161744
 >> iter 49000, loss: 0.064127
 >> iter 50000, loss: 0.105016
   Number of active neurons: 4
 >> iter 51000, loss: 0.042753
 >> iter 52000, loss: 0.019799
 >> iter 53000, loss: 0.011106
 >> iter 54000, loss: 0.007951
 >> iter 55000, loss: 0.043193
 >> iter 56000, loss: 0.027996
 >> iter 57000, loss: 0.013870
 >> iter 58000, loss: 0.008667
 >> iter 59000, loss: 0.006697
 >> iter 60000, loss: 0.006004
   Number of active neurons: 4
 >> iter 61000, loss: 0.022405
 >> iter 62000, loss: 0.224149
 >> iter 63000, loss: 0.086647
 >> iter 64000, loss: 0.035660
 >> iter 65000, loss: 0.016875
 >> iter 66000, loss: 0.009746
 >> iter 67000, loss: 0.007066
 >> iter 68000, loss: 0.006071
 >> iter 69000, loss: 0.037712
 >> iter 70000, loss: 0.018930
   Number of active neurons: 4
 >> iter 71000, loss: 0.010313
 >> iter 72000, loss: 0.007098
 >> iter 73000, loss: 0.039127
 >> iter 74000, loss: 0.018145
 >> iter 75000, loss: 0.009868
 >> iter 76000, loss: 0.006823
 >> iter 77000, loss: 0.008347
 >> iter 78000, loss: 0.006836
 >> iter 79000, loss: 0.005515
 >> iter 80000, loss: 0.005054
   Number of active neurons: 4
 >> iter 81000, loss: 0.026508
 >> iter 82000, loss: 0.313194
 >> iter 83000, loss: 0.119270
 >> iter 84000, loss: 0.047805
 >> iter 85000, loss: 0.090349
 >> iter 86000, loss: 0.037654
 >> iter 87000, loss: 0.018086
 >> iter 88000, loss: 0.010750
 >> iter 89000, loss: 0.008091
 >> iter 90000, loss: 0.006968
   Number of active neurons: 4
 >> iter 91000, loss: 0.065936
 >> iter 92000, loss: 0.062790
 >> iter 93000, loss: 0.027107
 >> iter 94000, loss: 0.013890
 >> iter 95000, loss: 0.027274
 >> iter 96000, loss: 0.013768
 >> iter 97000, loss: 0.008738
 >> iter 98000, loss: 0.006822
 >> iter 99000, loss: 0.088166
 >> iter 100000, loss: 0.248304
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.413078
 >> iter 2000, loss: 5.872515
 >> iter 3000, loss: 2.178135
 >> iter 4000, loss: 0.812754
 >> iter 5000, loss: 0.308204
 >> iter 6000, loss: 0.121134
 >> iter 7000, loss: 0.051609
 >> iter 8000, loss: 0.025388
 >> iter 9000, loss: 0.015401
 >> iter 10000, loss: 0.011482
   Number of active neurons: 6
 >> iter 11000, loss: 0.009677
 >> iter 12000, loss: 0.021157
 >> iter 13000, loss: 0.017843
 >> iter 14000, loss: 0.011451
 >> iter 15000, loss: 0.008936
 >> iter 16000, loss: 0.219537
 >> iter 17000, loss: 0.087670
 >> iter 18000, loss: 0.038344
 >> iter 19000, loss: 0.020607
 >> iter 20000, loss: 0.013970
   Number of active neurons: 5
 >> iter 21000, loss: 0.010131
 >> iter 22000, loss: 0.008518
 >> iter 23000, loss: 0.007733
 >> iter 24000, loss: 0.007410
 >> iter 25000, loss: 0.007039
 >> iter 26000, loss: 0.006973
 >> iter 27000, loss: 0.006610
 >> iter 28000, loss: 0.042633
 >> iter 29000, loss: 0.382341
 >> iter 30000, loss: 0.152086
   Number of active neurons: 4
 >> iter 31000, loss: 0.064438
 >> iter 32000, loss: 0.030702
 >> iter 33000, loss: 0.017459
 >> iter 34000, loss: 0.011982
 >> iter 35000, loss: 0.009581
 >> iter 36000, loss: 0.008366
 >> iter 37000, loss: 0.007703
 >> iter 38000, loss: 0.007273
 >> iter 39000, loss: 0.006953
 >> iter 40000, loss: 0.006759
   Number of active neurons: 4
 >> iter 41000, loss: 0.006503
 >> iter 42000, loss: 0.006411
 >> iter 43000, loss: 0.006174
 >> iter 44000, loss: 0.006145
 >> iter 45000, loss: 0.005908
 >> iter 46000, loss: 0.006193
 >> iter 47000, loss: 0.005814
 >> iter 48000, loss: 0.006299
 >> iter 49000, loss: 0.005778
 >> iter 50000, loss: 0.006978
   Number of active neurons: 4
 >> iter 51000, loss: 0.005954
 >> iter 52000, loss: 0.007350
 >> iter 53000, loss: 0.005903
 >> iter 54000, loss: 0.411177
 >> iter 55000, loss: 0.207747
 >> iter 56000, loss: 0.082464
 >> iter 57000, loss: 0.035849
 >> iter 58000, loss: 0.018278
 >> iter 59000, loss: 0.011523
 >> iter 60000, loss: 0.008829
   Number of active neurons: 4
 >> iter 61000, loss: 0.007577
 >> iter 62000, loss: 0.007388
 >> iter 63000, loss: 0.006722
 >> iter 64000, loss: 0.006437
 >> iter 65000, loss: 0.006157
 >> iter 66000, loss: 0.006912
 >> iter 67000, loss: 0.006181
 >> iter 68000, loss: 0.006828
 >> iter 69000, loss: 0.006041
 >> iter 70000, loss: 0.006942
   Number of active neurons: 4
 >> iter 71000, loss: 0.005966
 >> iter 72000, loss: 0.006894
 >> iter 73000, loss: 0.005844
 >> iter 74000, loss: 0.006825
 >> iter 75000, loss: 0.005743
 >> iter 76000, loss: 0.008151
 >> iter 77000, loss: 0.006132
 >> iter 78000, loss: 0.005888
 >> iter 79000, loss: 0.005165
 >> iter 80000, loss: 0.005910
   Number of active neurons: 4
 >> iter 81000, loss: 0.005189
 >> iter 82000, loss: 0.005774
 >> iter 83000, loss: 0.005146
 >> iter 84000, loss: 0.070971
 >> iter 85000, loss: 0.029314
 >> iter 86000, loss: 0.016163
 >> iter 87000, loss: 0.009019
 >> iter 88000, loss: 0.322187
 >> iter 89000, loss: 0.123327
 >> iter 90000, loss: 0.049806
   Number of active neurons: 4
 >> iter 91000, loss: 0.022556
 >> iter 92000, loss: 0.012400
 >> iter 93000, loss: 0.008496
 >> iter 94000, loss: 0.007034
 >> iter 95000, loss: 0.006288
 >> iter 96000, loss: 0.020678
 >> iter 97000, loss: 0.011258
 >> iter 98000, loss: 0.008900
 >> iter 99000, loss: 0.006708
 >> iter 100000, loss: 0.026430
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0579988400232
   - Test - Long: 0.144992750362
   - Test - Big: 0.0139998600014
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.726866
 >> iter 2000, loss: 6.275121
 >> iter 3000, loss: 2.328122
 >> iter 4000, loss: 0.865888
 >> iter 5000, loss: 0.325996
 >> iter 6000, loss: 0.126236
 >> iter 7000, loss: 0.052604
 >> iter 8000, loss: 0.024647
 >> iter 9000, loss: 0.014082
 >> iter 10000, loss: 0.009913
   Number of active neurons: 6
 >> iter 11000, loss: 0.117957
 >> iter 12000, loss: 0.049250
 >> iter 13000, loss: 0.038761
 >> iter 14000, loss: 0.019533
 >> iter 15000, loss: 0.319518
 >> iter 16000, loss: 0.128192
 >> iter 17000, loss: 0.054619
 >> iter 18000, loss: 0.026276
 >> iter 19000, loss: 0.015120
 >> iter 20000, loss: 0.011048
   Number of active neurons: 6
 >> iter 21000, loss: 0.042094
 >> iter 22000, loss: 0.020326
 >> iter 23000, loss: 0.025625
 >> iter 24000, loss: 0.013968
 >> iter 25000, loss: 0.028320
 >> iter 26000, loss: 0.014670
 >> iter 27000, loss: 0.009436
 >> iter 28000, loss: 0.104894
 >> iter 29000, loss: 0.043643
 >> iter 30000, loss: 0.021714
   Number of active neurons: 5
 >> iter 31000, loss: 0.041692
 >> iter 32000, loss: 0.019768
 >> iter 33000, loss: 0.011482
 >> iter 34000, loss: 0.345841
 >> iter 35000, loss: 0.135953
 >> iter 36000, loss: 0.056462
 >> iter 37000, loss: 0.026263
 >> iter 38000, loss: 0.014608
 >> iter 39000, loss: 0.112257
 >> iter 40000, loss: 0.047343
   Number of active neurons: 5
 >> iter 41000, loss: 0.022580
 >> iter 42000, loss: 0.013982
 >> iter 43000, loss: 0.025745
 >> iter 44000, loss: 0.013797
 >> iter 45000, loss: 0.056250
 >> iter 46000, loss: 0.025350
 >> iter 47000, loss: 0.015267
 >> iter 48000, loss: 0.011502
 >> iter 49000, loss: 0.115180
 >> iter 50000, loss: 0.047909
   Number of active neurons: 5
 >> iter 51000, loss: 0.073049
 >> iter 52000, loss: 0.088561
 >> iter 53000, loss: 0.038163
 >> iter 54000, loss: 0.153248
 >> iter 55000, loss: 0.062963
 >> iter 56000, loss: 0.028495
 >> iter 57000, loss: 0.015247
 >> iter 58000, loss: 0.103852
 >> iter 59000, loss: 0.046410
 >> iter 60000, loss: 0.201861
   Number of active neurons: 5
 >> iter 61000, loss: 0.081794
 >> iter 62000, loss: 0.035943
 >> iter 63000, loss: 0.018326
 >> iter 64000, loss: 0.093149
 >> iter 65000, loss: 0.039868
 >> iter 66000, loss: 0.020337
 >> iter 67000, loss: 0.011982
 >> iter 68000, loss: 0.273070
 >> iter 69000, loss: 0.109037
 >> iter 70000, loss: 0.046445
   Number of active neurons: 5
 >> iter 71000, loss: 0.022472
 >> iter 72000, loss: 0.013232
 >> iter 73000, loss: 0.045430
 >> iter 74000, loss: 0.022198
 >> iter 75000, loss: 0.012720
 >> iter 76000, loss: 0.010039
 >> iter 77000, loss: 0.064162
 >> iter 78000, loss: 0.122794
 >> iter 79000, loss: 0.051061
 >> iter 80000, loss: 0.023884
   Number of active neurons: 5
 >> iter 81000, loss: 0.199579
 >> iter 82000, loss: 0.079956
 >> iter 83000, loss: 0.034909
 >> iter 84000, loss: 0.029036
 >> iter 85000, loss: 0.015278
 >> iter 86000, loss: 0.024287
 >> iter 87000, loss: 0.013140
 >> iter 88000, loss: 0.009928
 >> iter 89000, loss: 0.015077
 >> iter 90000, loss: 0.021771
   Number of active neurons: 5
 >> iter 91000, loss: 0.012252
 >> iter 92000, loss: 0.008090
 >> iter 93000, loss: 0.040344
 >> iter 94000, loss: 0.088414
 >> iter 95000, loss: 0.052993
 >> iter 96000, loss: 0.046422
 >> iter 97000, loss: 0.024102
 >> iter 98000, loss: 0.066796
 >> iter 99000, loss: 0.029277
 >> iter 100000, loss: 0.014940
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.449204
 >> iter 2000, loss: 6.107901
 >> iter 3000, loss: 2.265967
 >> iter 4000, loss: 0.845539
 >> iter 5000, loss: 0.320584
 >> iter 6000, loss: 0.125957
 >> iter 7000, loss: 0.053608
 >> iter 8000, loss: 0.026377
 >> iter 9000, loss: 0.015896
 >> iter 10000, loss: 0.011798
   Number of active neurons: 4
 >> iter 11000, loss: 0.009855
 >> iter 12000, loss: 0.008963
 >> iter 13000, loss: 0.008372
 >> iter 14000, loss: 0.008035
 >> iter 15000, loss: 0.007698
 >> iter 16000, loss: 0.007491
 >> iter 17000, loss: 0.007248
 >> iter 18000, loss: 0.007132
 >> iter 19000, loss: 0.006908
 >> iter 20000, loss: 0.148136
   Number of active neurons: 4
 >> iter 21000, loss: 0.059341
 >> iter 22000, loss: 0.026583
 >> iter 23000, loss: 0.014169
 >> iter 24000, loss: 0.009690
 >> iter 25000, loss: 0.007692
 >> iter 26000, loss: 0.007051
 >> iter 27000, loss: 0.006555
 >> iter 28000, loss: 0.006475
 >> iter 29000, loss: 0.006209
 >> iter 30000, loss: 0.006206
   Number of active neurons: 4
 >> iter 31000, loss: 0.005985
 >> iter 32000, loss: 0.006035
 >> iter 33000, loss: 0.005828
 >> iter 34000, loss: 0.005916
 >> iter 35000, loss: 0.005689
 >> iter 36000, loss: 0.100609
 >> iter 37000, loss: 0.050764
 >> iter 38000, loss: 0.053681
 >> iter 39000, loss: 0.027761
 >> iter 40000, loss: 0.134838
   Number of active neurons: 4
 >> iter 41000, loss: 0.074769
 >> iter 42000, loss: 0.032349
 >> iter 43000, loss: 0.016351
 >> iter 44000, loss: 0.010359
 >> iter 45000, loss: 0.007924
 >> iter 46000, loss: 0.006996
 >> iter 47000, loss: 0.006480
 >> iter 48000, loss: 0.006302
 >> iter 49000, loss: 0.006254
 >> iter 50000, loss: 0.006085
   Number of active neurons: 3
 >> iter 51000, loss: 0.005757
 >> iter 52000, loss: 0.005687
 >> iter 53000, loss: 0.070705
 >> iter 54000, loss: 0.029757
 >> iter 55000, loss: 0.096533
 >> iter 56000, loss: 0.039806
 >> iter 57000, loss: 0.018713
 >> iter 58000, loss: 0.010765
 >> iter 59000, loss: 0.057303
 >> iter 60000, loss: 0.025264
   Number of active neurons: 4
 >> iter 61000, loss: 0.083692
 >> iter 62000, loss: 0.035496
 >> iter 63000, loss: 0.017386
 >> iter 64000, loss: 0.010506
 >> iter 65000, loss: 0.062385
 >> iter 66000, loss: 0.027387
 >> iter 67000, loss: 0.174897
 >> iter 68000, loss: 0.070516
 >> iter 69000, loss: 0.032849
 >> iter 70000, loss: 0.017164
   Number of active neurons: 4
 >> iter 71000, loss: 0.010952
 >> iter 72000, loss: 0.008366
 >> iter 73000, loss: 0.009906
 >> iter 74000, loss: 0.007811
 >> iter 75000, loss: 0.093560
 >> iter 76000, loss: 0.039244
 >> iter 77000, loss: 0.018884
 >> iter 78000, loss: 0.011130
 >> iter 79000, loss: 0.009024
 >> iter 80000, loss: 0.007378
   Number of active neurons: 3
 >> iter 81000, loss: 0.182006
 >> iter 82000, loss: 0.072915
 >> iter 83000, loss: 0.032191
 >> iter 84000, loss: 0.016687
 >> iter 85000, loss: 0.010635
 >> iter 86000, loss: 0.008162
 >> iter 87000, loss: 0.117187
 >> iter 88000, loss: 0.048420
 >> iter 89000, loss: 0.022637
 >> iter 90000, loss: 0.012795
   Number of active neurons: 3
 >> iter 91000, loss: 0.008946
 >> iter 92000, loss: 0.007315
 >> iter 93000, loss: 0.158684
 >> iter 94000, loss: 0.064009
 >> iter 95000, loss: 0.028500
 >> iter 96000, loss: 0.015057
 >> iter 97000, loss: 0.159901
 >> iter 98000, loss: 0.064965
 >> iter 99000, loss: 0.029196
 >> iter 100000, loss: 0.015565
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.919014
 >> iter 2000, loss: 7.179621
 >> iter 3000, loss: 2.673674
 >> iter 4000, loss: 0.993996
 >> iter 5000, loss: 0.393730
 >> iter 6000, loss: 0.152091
 >> iter 7000, loss: 0.088305
 >> iter 8000, loss: 0.038481
 >> iter 9000, loss: 0.090500
 >> iter 10000, loss: 0.039690
   Number of active neurons: 9
 >> iter 11000, loss: 0.020080
 >> iter 12000, loss: 0.012302
 >> iter 13000, loss: 0.025949
 >> iter 14000, loss: 0.014685
 >> iter 15000, loss: 0.028893
 >> iter 16000, loss: 0.015494
 >> iter 17000, loss: 0.010306
 >> iter 18000, loss: 0.008158
 >> iter 19000, loss: 0.088340
 >> iter 20000, loss: 0.038144
   Number of active neurons: 8
 >> iter 21000, loss: 0.256835
 >> iter 22000, loss: 0.103171
 >> iter 23000, loss: 0.044734
 >> iter 24000, loss: 0.022274
 >> iter 25000, loss: 0.031048
 >> iter 26000, loss: 0.016677
 >> iter 27000, loss: 0.105145
 >> iter 28000, loss: 0.045138
 >> iter 29000, loss: 0.022271
 >> iter 30000, loss: 0.013324
   Number of active neurons: 7
 >> iter 31000, loss: 0.012252
 >> iter 32000, loss: 0.008895
 >> iter 33000, loss: 0.052452
 >> iter 34000, loss: 0.024179
 >> iter 35000, loss: 0.013633
 >> iter 36000, loss: 0.011243
 >> iter 37000, loss: 0.052271
 >> iter 38000, loss: 0.024186
 >> iter 39000, loss: 0.069811
 >> iter 40000, loss: 0.031012
   Number of active neurons: 6
 >> iter 41000, loss: 0.019818
 >> iter 42000, loss: 0.011912
 >> iter 43000, loss: 0.008850
 >> iter 44000, loss: 0.010654
 >> iter 45000, loss: 0.059898
 >> iter 46000, loss: 0.029217
 >> iter 47000, loss: 0.074183
 >> iter 48000, loss: 0.032871
 >> iter 49000, loss: 0.029292
 >> iter 50000, loss: 0.015741
   Number of active neurons: 6
 >> iter 51000, loss: 0.010538
 >> iter 52000, loss: 0.008405
 >> iter 53000, loss: 0.038237
 >> iter 54000, loss: 0.019563
 >> iter 55000, loss: 0.011579
 >> iter 56000, loss: 0.012281
 >> iter 57000, loss: 0.008627
 >> iter 58000, loss: 0.007267
 >> iter 59000, loss: 0.089349
 >> iter 60000, loss: 0.037703
   Number of active neurons: 4
 >> iter 61000, loss: 0.163230
 >> iter 62000, loss: 0.065376
 >> iter 63000, loss: 0.028951
 >> iter 64000, loss: 0.054522
 >> iter 65000, loss: 0.024863
 >> iter 66000, loss: 0.015496
 >> iter 67000, loss: 0.065737
 >> iter 68000, loss: 0.028929
 >> iter 69000, loss: 0.015063
 >> iter 70000, loss: 0.009715
   Number of active neurons: 4
 >> iter 71000, loss: 0.027902
 >> iter 72000, loss: 0.014495
 >> iter 73000, loss: 0.116956
 >> iter 74000, loss: 0.046957
 >> iter 75000, loss: 0.021123
 >> iter 76000, loss: 0.011524
 >> iter 77000, loss: 0.008000
 >> iter 78000, loss: 0.006634
 >> iter 79000, loss: 0.072992
 >> iter 80000, loss: 0.030875
   Number of active neurons: 4
 >> iter 81000, loss: 0.015696
 >> iter 82000, loss: 0.011073
 >> iter 83000, loss: 0.007767
 >> iter 84000, loss: 0.007052
 >> iter 85000, loss: 0.006219
 >> iter 86000, loss: 0.007279
 >> iter 87000, loss: 0.057500
 >> iter 88000, loss: 0.025350
 >> iter 89000, loss: 0.013419
 >> iter 90000, loss: 0.009497
   Number of active neurons: 4
 >> iter 91000, loss: 0.007379
 >> iter 92000, loss: 0.014999
 >> iter 93000, loss: 0.012966
 >> iter 94000, loss: 0.009415
 >> iter 95000, loss: 0.010954
 >> iter 96000, loss: 0.007508
 >> iter 97000, loss: 0.006171
 >> iter 98000, loss: 0.013051
 >> iter 99000, loss: 0.008124
 >> iter 100000, loss: 0.007561
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0039999200016
   - Test - Long: 0.0
   - Test - Big: 0.0069999300007
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 15.140587
 >> iter 2000, loss: 5.610851
 >> iter 3000, loss: 2.079852
 >> iter 4000, loss: 0.775702
 >> iter 5000, loss: 0.294136
 >> iter 6000, loss: 0.115712
 >> iter 7000, loss: 0.049481
 >> iter 8000, loss: 0.024454
 >> iter 9000, loss: 0.014956
 >> iter 10000, loss: 0.011035
   Number of active neurons: 5
 >> iter 11000, loss: 0.009438
 >> iter 12000, loss: 0.008558
 >> iter 13000, loss: 0.008144
 >> iter 14000, loss: 0.007769
 >> iter 15000, loss: 0.007570
 >> iter 16000, loss: 0.007308
 >> iter 17000, loss: 0.007175
 >> iter 18000, loss: 0.006955
 >> iter 19000, loss: 0.025849
 >> iter 20000, loss: 0.013793
   Number of active neurons: 5
 >> iter 21000, loss: 0.009340
 >> iter 22000, loss: 0.007613
 >> iter 23000, loss: 0.032860
 >> iter 24000, loss: 0.016475
 >> iter 25000, loss: 0.010351
 >> iter 26000, loss: 0.007986
 >> iter 27000, loss: 0.130092
 >> iter 28000, loss: 0.053394
 >> iter 29000, loss: 0.024630
 >> iter 30000, loss: 0.013658
   Number of active neurons: 5
 >> iter 31000, loss: 0.086953
 >> iter 32000, loss: 0.036810
 >> iter 33000, loss: 0.018084
 >> iter 34000, loss: 0.010951
 >> iter 35000, loss: 0.008194
 >> iter 36000, loss: 0.007021
 >> iter 37000, loss: 0.355255
 >> iter 38000, loss: 0.141556
 >> iter 39000, loss: 0.059563
 >> iter 40000, loss: 0.028004
   Number of active neurons: 5
 >> iter 41000, loss: 0.181615
 >> iter 42000, loss: 0.073540
 >> iter 43000, loss: 0.032814
 >> iter 44000, loss: 0.017229
 >> iter 45000, loss: 0.011205
 >> iter 46000, loss: 0.008593
 >> iter 47000, loss: 0.106687
 >> iter 48000, loss: 0.044268
 >> iter 49000, loss: 0.020990
 >> iter 50000, loss: 0.105141
   Number of active neurons: 5
 >> iter 51000, loss: 0.043733
 >> iter 52000, loss: 0.115397
 >> iter 53000, loss: 0.047818
 >> iter 54000, loss: 0.022382
 >> iter 55000, loss: 0.174262
 >> iter 56000, loss: 0.069229
 >> iter 57000, loss: 0.030145
 >> iter 58000, loss: 0.015511
 >> iter 59000, loss: 0.172356
 >> iter 60000, loss: 0.068208
   Number of active neurons: 5
 >> iter 61000, loss: 0.029551
 >> iter 62000, loss: 0.015137
 >> iter 63000, loss: 0.009733
 >> iter 64000, loss: 0.007605
 >> iter 65000, loss: 0.099663
 >> iter 66000, loss: 0.041027
 >> iter 67000, loss: 0.019183
 >> iter 68000, loss: 0.107383
 >> iter 69000, loss: 0.044146
 >> iter 70000, loss: 0.020535
   Number of active neurons: 5
 >> iter 71000, loss: 0.421859
 >> iter 72000, loss: 0.163450
 >> iter 73000, loss: 0.066423
 >> iter 74000, loss: 0.029859
 >> iter 75000, loss: 0.015995
 >> iter 76000, loss: 0.010452
 >> iter 77000, loss: 0.017782
 >> iter 78000, loss: 0.010684
 >> iter 79000, loss: 0.008154
 >> iter 80000, loss: 0.006799
   Number of active neurons: 5
 >> iter 81000, loss: 0.012213
 >> iter 82000, loss: 0.008146
 >> iter 83000, loss: 0.152549
 >> iter 84000, loss: 0.060672
 >> iter 85000, loss: 0.026444
 >> iter 86000, loss: 0.112566
 >> iter 87000, loss: 0.046067
 >> iter 88000, loss: 0.124975
 >> iter 89000, loss: 0.051263
 >> iter 90000, loss: 0.114038
   Number of active neurons: 3
 >> iter 91000, loss: 0.047311
 >> iter 92000, loss: 0.022255
 >> iter 93000, loss: 0.012758
 >> iter 94000, loss: 0.011635
 >> iter 95000, loss: 0.008373
 >> iter 96000, loss: 0.071192
 >> iter 97000, loss: 0.030416
 >> iter 98000, loss: 0.015153
 >> iter 99000, loss: 0.158681
 >> iter 100000, loss: 0.063027
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.988234
 >> iter 2000, loss: 5.968362
 >> iter 3000, loss: 2.216922
 >> iter 4000, loss: 0.826591
 >> iter 5000, loss: 0.312964
 >> iter 6000, loss: 0.122595
 >> iter 7000, loss: 0.065288
 >> iter 8000, loss: 0.030421
 >> iter 9000, loss: 0.055572
 >> iter 10000, loss: 0.026506
   Number of active neurons: 7
 >> iter 11000, loss: 0.015349
 >> iter 12000, loss: 0.010815
 >> iter 13000, loss: 0.027214
 >> iter 14000, loss: 0.014824
 >> iter 15000, loss: 0.030549
 >> iter 16000, loss: 0.015955
 >> iter 17000, loss: 0.060773
 >> iter 18000, loss: 0.027430
 >> iter 19000, loss: 0.050224
 >> iter 20000, loss: 0.023519
   Number of active neurons: 5
 >> iter 21000, loss: 0.048881
 >> iter 22000, loss: 0.023113
 >> iter 23000, loss: 0.013319
 >> iter 24000, loss: 0.010296
 >> iter 25000, loss: 0.011151
 >> iter 26000, loss: 0.008604
 >> iter 27000, loss: 0.018659
 >> iter 28000, loss: 0.010843
 >> iter 29000, loss: 0.007903
 >> iter 30000, loss: 0.006677
   Number of active neurons: 5
 >> iter 31000, loss: 0.043143
 >> iter 32000, loss: 0.019952
 >> iter 33000, loss: 0.052235
 >> iter 34000, loss: 0.023443
 >> iter 35000, loss: 0.012749
 >> iter 36000, loss: 0.008661
 >> iter 37000, loss: 0.022825
 >> iter 38000, loss: 0.012260
 >> iter 39000, loss: 0.008326
 >> iter 40000, loss: 0.006796
   Number of active neurons: 5
 >> iter 41000, loss: 0.105656
 >> iter 42000, loss: 0.043526
 >> iter 43000, loss: 0.020475
 >> iter 44000, loss: 0.298463
 >> iter 45000, loss: 0.117488
 >> iter 46000, loss: 0.049677
 >> iter 47000, loss: 0.024014
 >> iter 48000, loss: 0.014917
 >> iter 49000, loss: 0.010318
 >> iter 50000, loss: 0.008469
   Number of active neurons: 5
 >> iter 51000, loss: 0.007495
 >> iter 52000, loss: 0.007720
 >> iter 53000, loss: 0.006869
 >> iter 54000, loss: 0.098118
 >> iter 55000, loss: 0.040733
 >> iter 56000, loss: 0.128296
 >> iter 57000, loss: 0.052605
 >> iter 58000, loss: 0.129464
 >> iter 59000, loss: 0.053361
 >> iter 60000, loss: 0.111646
   Number of active neurons: 5
 >> iter 61000, loss: 0.046885
 >> iter 62000, loss: 0.023146
 >> iter 63000, loss: 0.013161
 >> iter 64000, loss: 0.068985
 >> iter 65000, loss: 0.030037
 >> iter 66000, loss: 0.015356
 >> iter 67000, loss: 0.009753
 >> iter 68000, loss: 0.008825
 >> iter 69000, loss: 0.007058
 >> iter 70000, loss: 0.098504
   Number of active neurons: 5
 >> iter 71000, loss: 0.043807
 >> iter 72000, loss: 0.113797
 >> iter 73000, loss: 0.051668
 >> iter 74000, loss: 0.097410
 >> iter 75000, loss: 0.041488
 >> iter 76000, loss: 0.151518
 >> iter 77000, loss: 0.065902
 >> iter 78000, loss: 0.030015
 >> iter 79000, loss: 0.016156
 >> iter 80000, loss: 0.010587
   Number of active neurons: 5
 >> iter 81000, loss: 0.008247
 >> iter 82000, loss: 0.007141
 >> iter 83000, loss: 0.006560
 >> iter 84000, loss: 0.007287
 >> iter 85000, loss: 0.006313
 >> iter 86000, loss: 0.037812
 >> iter 87000, loss: 0.017678
 >> iter 88000, loss: 0.115947
 >> iter 89000, loss: 0.048575
 >> iter 90000, loss: 0.022312
   Number of active neurons: 5
 >> iter 91000, loss: 0.012426
 >> iter 92000, loss: 0.010365
 >> iter 93000, loss: 0.007651
 >> iter 94000, loss: 0.035403
 >> iter 95000, loss: 0.016797
 >> iter 96000, loss: 0.009815
 >> iter 97000, loss: 0.007195
 >> iter 98000, loss: 0.046112
 >> iter 99000, loss: 0.020684
 >> iter 100000, loss: 0.115595
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0219997800022
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.643103
 >> iter 2000, loss: 5.819752
 >> iter 3000, loss: 2.157396
 >> iter 4000, loss: 0.803753
 >> iter 5000, loss: 0.304054
 >> iter 6000, loss: 0.119053
 >> iter 7000, loss: 0.050452
 >> iter 8000, loss: 0.024637
 >> iter 9000, loss: 0.014894
 >> iter 10000, loss: 0.010946
   Number of active neurons: 6
 >> iter 11000, loss: 0.009385
 >> iter 12000, loss: 0.008533
 >> iter 13000, loss: 0.008139
 >> iter 14000, loss: 0.007775
 >> iter 15000, loss: 0.007575
 >> iter 16000, loss: 0.007280
 >> iter 17000, loss: 0.007126
 >> iter 18000, loss: 0.041384
 >> iter 19000, loss: 0.019579
 >> iter 20000, loss: 0.011415
   Number of active neurons: 4
 >> iter 21000, loss: 0.008377
 >> iter 22000, loss: 0.007391
 >> iter 23000, loss: 0.010153
 >> iter 24000, loss: 0.007678
 >> iter 25000, loss: 0.006717
 >> iter 26000, loss: 0.006523
 >> iter 27000, loss: 0.022202
 >> iter 28000, loss: 0.012068
 >> iter 29000, loss: 0.008724
 >> iter 30000, loss: 0.006877
   Number of active neurons: 4
 >> iter 31000, loss: 0.023337
 >> iter 32000, loss: 0.012367
 >> iter 33000, loss: 0.152410
 >> iter 34000, loss: 0.061561
 >> iter 35000, loss: 0.027660
 >> iter 36000, loss: 0.014902
 >> iter 37000, loss: 0.024945
 >> iter 38000, loss: 0.013605
 >> iter 39000, loss: 0.009274
 >> iter 40000, loss: 0.007574
   Number of active neurons: 4
 >> iter 41000, loss: 0.119656
 >> iter 42000, loss: 0.049725
 >> iter 43000, loss: 0.023333
 >> iter 44000, loss: 0.013357
 >> iter 45000, loss: 0.025767
 >> iter 46000, loss: 0.013993
 >> iter 47000, loss: 0.009393
 >> iter 48000, loss: 0.007600
 >> iter 49000, loss: 0.020621
 >> iter 50000, loss: 0.011633
   Number of active neurons: 4
 >> iter 51000, loss: 0.008150
 >> iter 52000, loss: 0.006845
 >> iter 53000, loss: 0.013607
 >> iter 54000, loss: 0.008727
 >> iter 55000, loss: 0.006773
 >> iter 56000, loss: 0.006030
 >> iter 57000, loss: 0.020687
 >> iter 58000, loss: 0.011162
 >> iter 59000, loss: 0.007575
 >> iter 60000, loss: 0.006276
   Number of active neurons: 4
 >> iter 61000, loss: 0.023322
 >> iter 62000, loss: 0.346827
 >> iter 63000, loss: 0.134495
 >> iter 64000, loss: 0.055314
 >> iter 65000, loss: 0.025594
 >> iter 66000, loss: 0.014246
 >> iter 67000, loss: 0.009785
 >> iter 68000, loss: 0.007941
 >> iter 69000, loss: 0.007096
 >> iter 70000, loss: 0.006673
   Number of active neurons: 4
 >> iter 71000, loss: 0.025723
 >> iter 72000, loss: 0.115196
 >> iter 73000, loss: 0.047359
 >> iter 74000, loss: 0.021852
 >> iter 75000, loss: 0.012213
 >> iter 76000, loss: 0.008474
 >> iter 77000, loss: 0.006984
 >> iter 78000, loss: 0.006323
 >> iter 79000, loss: 0.196237
 >> iter 80000, loss: 0.078357
   Number of active neurons: 4
 >> iter 81000, loss: 0.034239
 >> iter 82000, loss: 0.017556
 >> iter 83000, loss: 0.011088
 >> iter 84000, loss: 0.008459
 >> iter 85000, loss: 0.140913
 >> iter 86000, loss: 0.058504
 >> iter 87000, loss: 0.026919
 >> iter 88000, loss: 0.069478
 >> iter 89000, loss: 0.030759
 >> iter 90000, loss: 0.016114
   Number of active neurons: 4
 >> iter 91000, loss: 0.087861
 >> iter 92000, loss: 0.037113
 >> iter 93000, loss: 0.143034
 >> iter 94000, loss: 0.057887
 >> iter 95000, loss: 0.026121
 >> iter 96000, loss: 0.014090
 >> iter 97000, loss: 0.108375
 >> iter 98000, loss: 0.045065
 >> iter 99000, loss: 0.021284
 >> iter 100000, loss: 0.012220
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0159998400016
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.108306
 >> iter 2000, loss: 6.449083
 >> iter 3000, loss: 2.392950
 >> iter 4000, loss: 0.892139
 >> iter 5000, loss: 0.337155
 >> iter 6000, loss: 0.131515
 >> iter 7000, loss: 0.055004
 >> iter 8000, loss: 0.026244
 >> iter 9000, loss: 0.015276
 >> iter 10000, loss: 0.010931
   Number of active neurons: 5
 >> iter 11000, loss: 0.009105
 >> iter 12000, loss: 0.008303
 >> iter 13000, loss: 0.007711
 >> iter 14000, loss: 0.132465
 >> iter 15000, loss: 0.054378
 >> iter 16000, loss: 0.025110
 >> iter 17000, loss: 0.014073
 >> iter 18000, loss: 0.009738
 >> iter 19000, loss: 0.107984
 >> iter 20000, loss: 0.045652
   Number of active neurons: 4
 >> iter 21000, loss: 0.045457
 >> iter 22000, loss: 0.021559
 >> iter 23000, loss: 0.012653
 >> iter 24000, loss: 0.009335
 >> iter 25000, loss: 0.018605
 >> iter 26000, loss: 0.012553
 >> iter 27000, loss: 0.067389
 >> iter 28000, loss: 0.029969
 >> iter 29000, loss: 0.158414
 >> iter 30000, loss: 0.064451
   Number of active neurons: 4
 >> iter 31000, loss: 0.174053
 >> iter 32000, loss: 0.071524
 >> iter 33000, loss: 0.032698
 >> iter 34000, loss: 0.018616
 >> iter 35000, loss: 0.012098
 >> iter 36000, loss: 0.010809
 >> iter 37000, loss: 0.008584
 >> iter 38000, loss: 0.008355
 >> iter 39000, loss: 0.029163
 >> iter 40000, loss: 0.116935
   Number of active neurons: 4
 >> iter 41000, loss: 0.296692
 >> iter 42000, loss: 0.119699
 >> iter 43000, loss: 0.051780
 >> iter 44000, loss: 0.025412
 >> iter 45000, loss: 0.014883
 >> iter 46000, loss: 0.016424
 >> iter 47000, loss: 0.121872
 >> iter 48000, loss: 0.052093
 >> iter 49000, loss: 0.230007
 >> iter 50000, loss: 0.094851
   Number of active neurons: 4
 >> iter 51000, loss: 0.042489
 >> iter 52000, loss: 0.021903
 >> iter 53000, loss: 0.013521
 >> iter 54000, loss: 0.128782
 >> iter 55000, loss: 0.052667
 >> iter 56000, loss: 0.141650
 >> iter 57000, loss: 0.057305
 >> iter 58000, loss: 0.072050
 >> iter 59000, loss: 0.031816
 >> iter 60000, loss: 0.140389
   Number of active neurons: 4
 >> iter 61000, loss: 0.056250
 >> iter 62000, loss: 0.025574
 >> iter 63000, loss: 0.013463
 >> iter 64000, loss: 0.136608
 >> iter 65000, loss: 0.054478
 >> iter 66000, loss: 0.074255
 >> iter 67000, loss: 0.259614
 >> iter 68000, loss: 0.104864
 >> iter 69000, loss: 0.045264
 >> iter 70000, loss: 0.022677
   Number of active neurons: 4
 >> iter 71000, loss: 0.013472
 >> iter 72000, loss: 0.011120
 >> iter 73000, loss: 0.008427
 >> iter 74000, loss: 0.135012
 >> iter 75000, loss: 0.054098
 >> iter 76000, loss: 0.024317
 >> iter 77000, loss: 0.012921
 >> iter 78000, loss: 0.136008
 >> iter 79000, loss: 0.054183
 >> iter 80000, loss: 0.151477
   Number of active neurons: 4
 >> iter 81000, loss: 0.087390
 >> iter 82000, loss: 0.037965
 >> iter 83000, loss: 0.045673
 >> iter 84000, loss: 0.022679
 >> iter 85000, loss: 0.148272
 >> iter 86000, loss: 0.128503
 >> iter 87000, loss: 0.051870
 >> iter 88000, loss: 0.147967
 >> iter 89000, loss: 0.059039
 >> iter 90000, loss: 0.145885
   Number of active neurons: 4
 >> iter 91000, loss: 0.058185
 >> iter 92000, loss: 0.149361
 >> iter 93000, loss: 0.059703
 >> iter 94000, loss: 0.027623
 >> iter 95000, loss: 0.014101
 >> iter 96000, loss: 0.133865
 >> iter 97000, loss: 0.053488
 >> iter 98000, loss: 0.148504
 >> iter 99000, loss: 0.059246
 >> iter 100000, loss: 0.027131
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0049999500005
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

