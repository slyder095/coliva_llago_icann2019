 > Problema: tomita2nueva
 > Args:
   - Hidden size: 18
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.344131
 >> iter 2000, loss: 4.488106
 >> iter 3000, loss: 1.800528
 >> iter 4000, loss: 0.759064
 >> iter 5000, loss: 0.363267
 >> iter 6000, loss: 0.185871
 >> iter 7000, loss: 0.128025
 >> iter 8000, loss: 0.130876
 >> iter 9000, loss: 0.110339
 >> iter 10000, loss: 0.084244
   Number of active neurons: 10
 >> iter 11000, loss: 0.101508
 >> iter 12000, loss: 0.101554
 >> iter 13000, loss: 0.076475
 >> iter 14000, loss: 0.075369
 >> iter 15000, loss: 0.074457
 >> iter 16000, loss: 0.065122
 >> iter 17000, loss: 0.058383
 >> iter 18000, loss: 0.064712
 >> iter 19000, loss: 0.071118
 >> iter 20000, loss: 0.059080
   Number of active neurons: 7
 >> iter 21000, loss: 0.047833
 >> iter 22000, loss: 0.042676
 >> iter 23000, loss: 0.075931
 >> iter 24000, loss: 0.061214
 >> iter 25000, loss: 0.059041
 >> iter 26000, loss: 0.056148
 >> iter 27000, loss: 0.062189
 >> iter 28000, loss: 0.050963
 >> iter 29000, loss: 0.066035
 >> iter 30000, loss: 0.051395
   Number of active neurons: 4
 >> iter 31000, loss: 0.075024
 >> iter 32000, loss: 0.051207
 >> iter 33000, loss: 0.048091
 >> iter 34000, loss: 0.044248
 >> iter 35000, loss: 0.045461
 >> iter 36000, loss: 0.056290
 >> iter 37000, loss: 0.052268
 >> iter 38000, loss: 0.045185
 >> iter 39000, loss: 0.040421
 >> iter 40000, loss: 0.068312
   Number of active neurons: 4
 >> iter 41000, loss: 0.059034
 >> iter 42000, loss: 0.052971
 >> iter 43000, loss: 0.072173
 >> iter 44000, loss: 0.062596
 >> iter 45000, loss: 0.054809
 >> iter 46000, loss: 0.047007
 >> iter 47000, loss: 0.060610
 >> iter 48000, loss: 0.047382
 >> iter 49000, loss: 0.055700
 >> iter 50000, loss: 0.047047
   Number of active neurons: 4
 >> iter 51000, loss: 0.044100
 >> iter 52000, loss: 0.061678
 >> iter 53000, loss: 0.051256
 >> iter 54000, loss: 0.057886
 >> iter 55000, loss: 0.071682
 >> iter 56000, loss: 0.052358
 >> iter 57000, loss: 0.052493
 >> iter 58000, loss: 0.064813
 >> iter 59000, loss: 0.050136
 >> iter 60000, loss: 0.046342
   Number of active neurons: 4
 >> iter 61000, loss: 0.041116
 >> iter 62000, loss: 0.035069
 >> iter 63000, loss: 0.041505
 >> iter 64000, loss: 0.042976
 >> iter 65000, loss: 0.069409
 >> iter 66000, loss: 0.049609
 >> iter 67000, loss: 0.047490
 >> iter 68000, loss: 0.065276
 >> iter 69000, loss: 0.053049
 >> iter 70000, loss: 0.045894
   Number of active neurons: 4
 >> iter 71000, loss: 0.051977
 >> iter 72000, loss: 0.054291
 >> iter 73000, loss: 0.054167
 >> iter 74000, loss: 0.056362
 >> iter 75000, loss: 0.064133
 >> iter 76000, loss: 0.051662
 >> iter 77000, loss: 0.049615
 >> iter 78000, loss: 0.055564
 >> iter 79000, loss: 0.040885
 >> iter 80000, loss: 0.050342
   Number of active neurons: 3
 >> iter 81000, loss: 0.038965
 >> iter 82000, loss: 0.060106
 >> iter 83000, loss: 0.060828
 >> iter 84000, loss: 0.050370
 >> iter 85000, loss: 0.043839
 >> iter 86000, loss: 0.036381
 >> iter 87000, loss: 0.051588
 >> iter 88000, loss: 0.050656
 >> iter 89000, loss: 0.064656
 >> iter 90000, loss: 0.053231
   Number of active neurons: 3
 >> iter 91000, loss: 0.047894
 >> iter 92000, loss: 0.051288
 >> iter 93000, loss: 0.038900
 >> iter 94000, loss: 0.037845
 >> iter 95000, loss: 0.047945
 >> iter 96000, loss: 0.069519
 >> iter 97000, loss: 0.040497
 >> iter 98000, loss: 0.036352
 >> iter 99000, loss: 0.030833
 >> iter 100000, loss: 0.044482
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.332146
 >> iter 2000, loss: 4.469342
 >> iter 3000, loss: 1.812155
 >> iter 4000, loss: 0.815964
 >> iter 5000, loss: 0.388234
 >> iter 6000, loss: 0.219566
 >> iter 7000, loss: 0.146415
 >> iter 8000, loss: 0.139239
 >> iter 9000, loss: 0.118439
 >> iter 10000, loss: 0.090013
   Number of active neurons: 10
 >> iter 11000, loss: 0.097692
 >> iter 12000, loss: 0.087942
 >> iter 13000, loss: 0.072403
 >> iter 14000, loss: 0.078627
 >> iter 15000, loss: 0.077914
 >> iter 16000, loss: 0.074179
 >> iter 17000, loss: 0.066296
 >> iter 18000, loss: 0.050729
 >> iter 19000, loss: 0.071798
 >> iter 20000, loss: 0.063166
   Number of active neurons: 7
 >> iter 21000, loss: 0.058072
 >> iter 22000, loss: 0.057317
 >> iter 23000, loss: 0.056658
 >> iter 24000, loss: 0.055042
 >> iter 25000, loss: 0.055885
 >> iter 26000, loss: 0.046205
 >> iter 27000, loss: 0.046934
 >> iter 28000, loss: 0.045877
 >> iter 29000, loss: 0.045727
 >> iter 30000, loss: 0.033231
   Number of active neurons: 6
 >> iter 31000, loss: 0.052161
 >> iter 32000, loss: 0.050751
 >> iter 33000, loss: 0.054780
 >> iter 34000, loss: 0.041417
 >> iter 35000, loss: 0.062402
 >> iter 36000, loss: 0.043916
 >> iter 37000, loss: 0.070334
 >> iter 38000, loss: 0.079679
 >> iter 39000, loss: 0.068524
 >> iter 40000, loss: 0.048569
   Number of active neurons: 5
 >> iter 41000, loss: 0.047309
 >> iter 42000, loss: 0.040625
 >> iter 43000, loss: 0.040549
 >> iter 44000, loss: 0.036366
 >> iter 45000, loss: 0.051027
 >> iter 46000, loss: 0.054418
 >> iter 47000, loss: 0.039325
 >> iter 48000, loss: 0.048152
 >> iter 49000, loss: 0.034923
 >> iter 50000, loss: 0.051870
   Number of active neurons: 4
 >> iter 51000, loss: 0.051076
 >> iter 52000, loss: 0.073695
 >> iter 53000, loss: 0.055101
 >> iter 54000, loss: 0.041827
 >> iter 55000, loss: 0.048338
 >> iter 56000, loss: 0.036046
 >> iter 57000, loss: 0.038382
 >> iter 58000, loss: 0.045817
 >> iter 59000, loss: 0.049364
 >> iter 60000, loss: 0.052473
   Number of active neurons: 3
 >> iter 61000, loss: 0.041617
 >> iter 62000, loss: 0.036332
 >> iter 63000, loss: 0.040926
 >> iter 64000, loss: 0.046971
 >> iter 65000, loss: 0.065915
 >> iter 66000, loss: 0.062950
 >> iter 67000, loss: 0.046475
 >> iter 68000, loss: 0.046778
 >> iter 69000, loss: 0.037975
 >> iter 70000, loss: 0.038369
   Number of active neurons: 3
 >> iter 71000, loss: 0.045938
 >> iter 72000, loss: 0.048725
 >> iter 73000, loss: 0.047816
 >> iter 74000, loss: 0.045010
 >> iter 75000, loss: 0.042196
 >> iter 76000, loss: 0.048993
 >> iter 77000, loss: 0.053000
 >> iter 78000, loss: 0.046439
 >> iter 79000, loss: 0.051709
 >> iter 80000, loss: 0.055081
   Number of active neurons: 3
 >> iter 81000, loss: 0.049313
 >> iter 82000, loss: 0.050591
 >> iter 83000, loss: 0.047442
 >> iter 84000, loss: 0.059902
 >> iter 85000, loss: 0.042975
 >> iter 86000, loss: 0.050790
 >> iter 87000, loss: 0.041783
 >> iter 88000, loss: 0.045898
 >> iter 89000, loss: 0.051087
 >> iter 90000, loss: 0.037920
   Number of active neurons: 3
 >> iter 91000, loss: 0.039962
 >> iter 92000, loss: 0.030013
 >> iter 93000, loss: 0.032657
 >> iter 94000, loss: 0.051018
 >> iter 95000, loss: 0.038761
 >> iter 96000, loss: 0.043643
 >> iter 97000, loss: 0.061081
 >> iter 98000, loss: 0.046759
 >> iter 99000, loss: 0.047737
 >> iter 100000, loss: 0.041661
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.350737
 >> iter 2000, loss: 4.483287
 >> iter 3000, loss: 1.793819
 >> iter 4000, loss: 0.751892
 >> iter 5000, loss: 0.339746
 >> iter 6000, loss: 0.210462
 >> iter 7000, loss: 0.168703
 >> iter 8000, loss: 0.106121
 >> iter 9000, loss: 0.095183
 >> iter 10000, loss: 0.086221
   Number of active neurons: 8
 >> iter 11000, loss: 0.067866
 >> iter 12000, loss: 0.076428
 >> iter 13000, loss: 0.069005
 >> iter 14000, loss: 0.080398
 >> iter 15000, loss: 0.068708
 >> iter 16000, loss: 0.067815
 >> iter 17000, loss: 0.046968
 >> iter 18000, loss: 0.045868
 >> iter 19000, loss: 0.053832
 >> iter 20000, loss: 0.067339
   Number of active neurons: 6
 >> iter 21000, loss: 0.047427
 >> iter 22000, loss: 0.050104
 >> iter 23000, loss: 0.050338
 >> iter 24000, loss: 0.059855
 >> iter 25000, loss: 0.051492
 >> iter 26000, loss: 0.043266
 >> iter 27000, loss: 0.054071
 >> iter 28000, loss: 0.075824
 >> iter 29000, loss: 0.051313
 >> iter 30000, loss: 0.047411
   Number of active neurons: 5
 >> iter 31000, loss: 0.044627
 >> iter 32000, loss: 0.044948
 >> iter 33000, loss: 0.051588
 >> iter 34000, loss: 0.045967
 >> iter 35000, loss: 0.042120
 >> iter 36000, loss: 0.049139
 >> iter 37000, loss: 0.038091
 >> iter 38000, loss: 0.042558
 >> iter 39000, loss: 0.052129
 >> iter 40000, loss: 0.040430
   Number of active neurons: 4
 >> iter 41000, loss: 0.060452
 >> iter 42000, loss: 0.044384
 >> iter 43000, loss: 0.056407
 >> iter 44000, loss: 0.044906
 >> iter 45000, loss: 0.039722
 >> iter 46000, loss: 0.039564
 >> iter 47000, loss: 0.048443
 >> iter 48000, loss: 0.050234
 >> iter 49000, loss: 0.059098
 >> iter 50000, loss: 0.060698
   Number of active neurons: 4
 >> iter 51000, loss: 0.054024
 >> iter 52000, loss: 0.058090
 >> iter 53000, loss: 0.063350
 >> iter 54000, loss: 0.051910
 >> iter 55000, loss: 0.052157
 >> iter 56000, loss: 0.032910
 >> iter 57000, loss: 0.032349
 >> iter 58000, loss: 0.039972
 >> iter 59000, loss: 0.033909
 >> iter 60000, loss: 0.048731
   Number of active neurons: 4
 >> iter 61000, loss: 0.048490
 >> iter 62000, loss: 0.037652
 >> iter 63000, loss: 0.036684
 >> iter 64000, loss: 0.035471
 >> iter 65000, loss: 0.061769
 >> iter 66000, loss: 0.053536
 >> iter 67000, loss: 0.063385
 >> iter 68000, loss: 0.044400
 >> iter 69000, loss: 0.045864
 >> iter 70000, loss: 0.037738
   Number of active neurons: 4
 >> iter 71000, loss: 0.037989
 >> iter 72000, loss: 0.041904
 >> iter 73000, loss: 0.056230
 >> iter 74000, loss: 0.045773
 >> iter 75000, loss: 0.046261
 >> iter 76000, loss: 0.053515
 >> iter 77000, loss: 0.043555
 >> iter 78000, loss: 0.042244
 >> iter 79000, loss: 0.034721
 >> iter 80000, loss: 0.070912
   Number of active neurons: 3
 >> iter 81000, loss: 0.055994
 >> iter 82000, loss: 0.043474
 >> iter 83000, loss: 0.058791
 >> iter 84000, loss: 0.053894
 >> iter 85000, loss: 0.058295
 >> iter 86000, loss: 0.045471
 >> iter 87000, loss: 0.061736
 >> iter 88000, loss: 0.070399
 >> iter 89000, loss: 0.048615
 >> iter 90000, loss: 0.044410
   Number of active neurons: 3
 >> iter 91000, loss: 0.052551
 >> iter 92000, loss: 0.053395
 >> iter 93000, loss: 0.053892
 >> iter 94000, loss: 0.040184
 >> iter 95000, loss: 0.033096
 >> iter 96000, loss: 0.032550
 >> iter 97000, loss: 0.047224
 >> iter 98000, loss: 0.042990
 >> iter 99000, loss: 0.033795
 >> iter 100000, loss: 0.046565
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.278059
 >> iter 2000, loss: 4.433196
 >> iter 3000, loss: 1.791023
 >> iter 4000, loss: 0.752052
 >> iter 5000, loss: 0.377363
 >> iter 6000, loss: 0.184649
 >> iter 7000, loss: 0.119505
 >> iter 8000, loss: 0.125584
 >> iter 9000, loss: 0.112095
 >> iter 10000, loss: 0.073794
   Number of active neurons: 10
 >> iter 11000, loss: 0.094081
 >> iter 12000, loss: 0.076431
 >> iter 13000, loss: 0.077130
 >> iter 14000, loss: 0.075027
 >> iter 15000, loss: 0.085960
 >> iter 16000, loss: 0.063928
 >> iter 17000, loss: 0.054135
 >> iter 18000, loss: 0.049957
 >> iter 19000, loss: 0.053138
 >> iter 20000, loss: 0.056656
   Number of active neurons: 9
 >> iter 21000, loss: 0.067421
 >> iter 22000, loss: 0.053689
 >> iter 23000, loss: 0.076308
 >> iter 24000, loss: 0.080269
 >> iter 25000, loss: 0.066916
 >> iter 26000, loss: 0.071636
 >> iter 27000, loss: 0.067104
 >> iter 28000, loss: 0.075830
 >> iter 29000, loss: 0.063863
 >> iter 30000, loss: 0.052175
   Number of active neurons: 7
 >> iter 31000, loss: 0.066379
 >> iter 32000, loss: 0.062911
 >> iter 33000, loss: 0.058683
 >> iter 34000, loss: 0.060057
 >> iter 35000, loss: 0.060400
 >> iter 36000, loss: 0.047404
 >> iter 37000, loss: 0.057165
 >> iter 38000, loss: 0.061942
 >> iter 39000, loss: 0.045177
 >> iter 40000, loss: 0.046950
   Number of active neurons: 6
 >> iter 41000, loss: 0.046004
 >> iter 42000, loss: 0.060776
 >> iter 43000, loss: 0.064711
 >> iter 44000, loss: 0.046881
 >> iter 45000, loss: 0.047151
 >> iter 46000, loss: 0.068166
 >> iter 47000, loss: 0.054298
 >> iter 48000, loss: 0.050583
 >> iter 49000, loss: 0.050518
 >> iter 50000, loss: 0.060446
   Number of active neurons: 5
 >> iter 51000, loss: 0.059884
 >> iter 52000, loss: 0.054942
 >> iter 53000, loss: 0.059373
 >> iter 54000, loss: 0.047780
 >> iter 55000, loss: 0.045242
 >> iter 56000, loss: 0.048836
 >> iter 57000, loss: 0.052258
 >> iter 58000, loss: 0.042808
 >> iter 59000, loss: 0.056184
 >> iter 60000, loss: 0.046711
   Number of active neurons: 3
 >> iter 61000, loss: 0.042260
 >> iter 62000, loss: 0.047273
 >> iter 63000, loss: 0.041537
 >> iter 64000, loss: 0.038219
 >> iter 65000, loss: 0.047151
 >> iter 66000, loss: 0.078236
 >> iter 67000, loss: 0.050650
 >> iter 68000, loss: 0.042442
 >> iter 69000, loss: 0.039139
 >> iter 70000, loss: 0.054414
   Number of active neurons: 3
 >> iter 71000, loss: 0.052144
 >> iter 72000, loss: 0.043618
 >> iter 73000, loss: 0.039444
 >> iter 74000, loss: 0.040306
 >> iter 75000, loss: 0.055893
 >> iter 76000, loss: 0.052863
 >> iter 77000, loss: 0.049860
 >> iter 78000, loss: 0.058976
 >> iter 79000, loss: 0.052884
 >> iter 80000, loss: 0.044327
   Number of active neurons: 3
 >> iter 81000, loss: 0.044645
 >> iter 82000, loss: 0.037784
 >> iter 83000, loss: 0.048696
 >> iter 84000, loss: 0.050394
 >> iter 85000, loss: 0.050172
 >> iter 86000, loss: 0.049174
 >> iter 87000, loss: 0.067003
 >> iter 88000, loss: 0.058773
 >> iter 89000, loss: 0.043365
 >> iter 90000, loss: 0.030646
   Number of active neurons: 3
 >> iter 91000, loss: 0.037327
 >> iter 92000, loss: 0.064341
 >> iter 93000, loss: 0.062702
 >> iter 94000, loss: 0.053042
 >> iter 95000, loss: 0.045975
 >> iter 96000, loss: 0.037278
 >> iter 97000, loss: 0.049481
 >> iter 98000, loss: 0.054809
 >> iter 99000, loss: 0.063806
 >> iter 100000, loss: 0.050815
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 11.332999
 >> iter 2000, loss: 4.444741
 >> iter 3000, loss: 1.792093
 >> iter 4000, loss: 0.748437
 >> iter 5000, loss: 0.346013
 >> iter 6000, loss: 0.215902
 >> iter 7000, loss: 0.124067
 >> iter 8000, loss: 0.105109
 >> iter 9000, loss: 0.080232
 >> iter 10000, loss: 0.103935
   Number of active neurons: 10
 >> iter 11000, loss: 0.097710
 >> iter 12000, loss: 0.088979
 >> iter 13000, loss: 0.089685
 >> iter 14000, loss: 0.073572
 >> iter 15000, loss: 0.071239
 >> iter 16000, loss: 0.082435
 >> iter 17000, loss: 0.087440
 >> iter 18000, loss: 0.064456
 >> iter 19000, loss: 0.060008
 >> iter 20000, loss: 0.067932
   Number of active neurons: 7
 >> iter 21000, loss: 0.059452
 >> iter 22000, loss: 0.056205
 >> iter 23000, loss: 0.052553
 >> iter 24000, loss: 0.045364
 >> iter 25000, loss: 0.051777
 >> iter 26000, loss: 0.068394
 >> iter 27000, loss: 0.089108
 >> iter 28000, loss: 0.077631
 >> iter 29000, loss: 0.090998
 >> iter 30000, loss: 0.072799
   Number of active neurons: 6
 >> iter 31000, loss: 0.054530
 >> iter 32000, loss: 0.058712
 >> iter 33000, loss: 0.055512
 >> iter 34000, loss: 0.067385
 >> iter 35000, loss: 0.063624
 >> iter 36000, loss: 0.046896
 >> iter 37000, loss: 0.063441
 >> iter 38000, loss: 0.069115
 >> iter 39000, loss: 0.065212
 >> iter 40000, loss: 0.056215
   Number of active neurons: 5
 >> iter 41000, loss: 0.054026
 >> iter 42000, loss: 0.075270
 >> iter 43000, loss: 0.067670
 >> iter 44000, loss: 0.057873
 >> iter 45000, loss: 0.061032
 >> iter 46000, loss: 0.054294
 >> iter 47000, loss: 0.051780
 >> iter 48000, loss: 0.041840
 >> iter 49000, loss: 0.046346
 >> iter 50000, loss: 0.046014
   Number of active neurons: 5
 >> iter 51000, loss: 0.048981
 >> iter 52000, loss: 0.044147
 >> iter 53000, loss: 0.046753
 >> iter 54000, loss: 0.058101
 >> iter 55000, loss: 0.046184
 >> iter 56000, loss: 0.039255
 >> iter 57000, loss: 0.043373
 >> iter 58000, loss: 0.048314
 >> iter 59000, loss: 0.047328
 >> iter 60000, loss: 0.047538
   Number of active neurons: 4
 >> iter 61000, loss: 0.040292
 >> iter 62000, loss: 0.040651
 >> iter 63000, loss: 0.069196
 >> iter 64000, loss: 0.067860
 >> iter 65000, loss: 0.056580
 >> iter 66000, loss: 0.049745
 >> iter 67000, loss: 0.046907
 >> iter 68000, loss: 0.046355
 >> iter 69000, loss: 0.081393
 >> iter 70000, loss: 0.079174
   Number of active neurons: 4
 >> iter 71000, loss: 0.059858
 >> iter 72000, loss: 0.042242
 >> iter 73000, loss: 0.051672
 >> iter 74000, loss: 0.040861
 >> iter 75000, loss: 0.045873
 >> iter 76000, loss: 0.038843
 >> iter 77000, loss: 0.045048
 >> iter 78000, loss: 0.063908
 >> iter 79000, loss: 0.052517
 >> iter 80000, loss: 0.053707
   Number of active neurons: 4
 >> iter 81000, loss: 0.045994
 >> iter 82000, loss: 0.044374
 >> iter 83000, loss: 0.040165
 >> iter 84000, loss: 0.056709
 >> iter 85000, loss: 0.049984
 >> iter 86000, loss: 0.059818
 >> iter 87000, loss: 0.052182
 >> iter 88000, loss: 0.047555
 >> iter 89000, loss: 0.037983
 >> iter 90000, loss: 0.034877
   Number of active neurons: 4
 >> iter 91000, loss: 0.040484
 >> iter 92000, loss: 0.038140
 >> iter 93000, loss: 0.050473
 >> iter 94000, loss: 0.081273
 >> iter 95000, loss: 0.054620
 >> iter 96000, loss: 0.047571
 >> iter 97000, loss: 0.045748
 >> iter 98000, loss: 0.055789
 >> iter 99000, loss: 0.050024
 >> iter 100000, loss: 0.036933
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.390431
 >> iter 2000, loss: 4.477408
 >> iter 3000, loss: 1.771547
 >> iter 4000, loss: 0.728668
 >> iter 5000, loss: 0.350593
 >> iter 6000, loss: 0.177413
 >> iter 7000, loss: 0.116393
 >> iter 8000, loss: 0.096710
 >> iter 9000, loss: 0.097080
 >> iter 10000, loss: 0.074782
   Number of active neurons: 8
 >> iter 11000, loss: 0.077555
 >> iter 12000, loss: 0.075756
 >> iter 13000, loss: 0.069635
 >> iter 14000, loss: 0.089769
 >> iter 15000, loss: 0.070397
 >> iter 16000, loss: 0.076580
 >> iter 17000, loss: 0.066355
 >> iter 18000, loss: 0.061885
 >> iter 19000, loss: 0.072557
 >> iter 20000, loss: 0.073392
   Number of active neurons: 8
 >> iter 21000, loss: 0.064731
 >> iter 22000, loss: 0.062177
 >> iter 23000, loss: 0.064586
 >> iter 24000, loss: 0.043317
 >> iter 25000, loss: 0.055248
 >> iter 26000, loss: 0.053425
 >> iter 27000, loss: 0.075468
 >> iter 28000, loss: 0.063347
 >> iter 29000, loss: 0.056681
 >> iter 30000, loss: 0.046849
   Number of active neurons: 5
 >> iter 31000, loss: 0.072642
 >> iter 32000, loss: 0.053555
 >> iter 33000, loss: 0.058231
 >> iter 34000, loss: 0.046097
 >> iter 35000, loss: 0.063892
 >> iter 36000, loss: 0.051960
 >> iter 37000, loss: 0.053336
 >> iter 38000, loss: 0.047632
 >> iter 39000, loss: 0.045777
 >> iter 40000, loss: 0.043685
   Number of active neurons: 4
 >> iter 41000, loss: 0.052065
 >> iter 42000, loss: 0.039686
 >> iter 43000, loss: 0.037631
 >> iter 44000, loss: 0.046594
 >> iter 45000, loss: 0.079218
 >> iter 46000, loss: 0.050738
 >> iter 47000, loss: 0.047537
 >> iter 48000, loss: 0.050018
 >> iter 49000, loss: 0.049652
 >> iter 50000, loss: 0.055604
   Number of active neurons: 4
 >> iter 51000, loss: 0.040734
 >> iter 52000, loss: 0.052408
 >> iter 53000, loss: 0.038916
 >> iter 54000, loss: 0.046934
 >> iter 55000, loss: 0.045719
 >> iter 56000, loss: 0.037001
 >> iter 57000, loss: 0.040472
 >> iter 58000, loss: 0.044567
 >> iter 59000, loss: 0.048767
 >> iter 60000, loss: 0.053325
   Number of active neurons: 4
 >> iter 61000, loss: 0.043297
 >> iter 62000, loss: 0.038590
 >> iter 63000, loss: 0.041161
 >> iter 64000, loss: 0.045460
 >> iter 65000, loss: 0.037272
 >> iter 66000, loss: 0.039530
 >> iter 67000, loss: 0.051799
 >> iter 68000, loss: 0.049077
 >> iter 69000, loss: 0.071831
 >> iter 70000, loss: 0.063023
   Number of active neurons: 4
 >> iter 71000, loss: 0.057712
 >> iter 72000, loss: 0.048643
 >> iter 73000, loss: 0.065028
 >> iter 74000, loss: 0.052319
 >> iter 75000, loss: 0.048814
 >> iter 76000, loss: 0.058019
 >> iter 77000, loss: 0.058366
 >> iter 78000, loss: 0.047411
 >> iter 79000, loss: 0.046823
 >> iter 80000, loss: 0.041494
   Number of active neurons: 3
 >> iter 81000, loss: 0.038430
 >> iter 82000, loss: 0.042049
 >> iter 83000, loss: 0.042080
 >> iter 84000, loss: 0.033419
 >> iter 85000, loss: 0.043350
 >> iter 86000, loss: 0.053610
 >> iter 87000, loss: 0.041147
 >> iter 88000, loss: 0.043438
 >> iter 89000, loss: 0.062706
 >> iter 90000, loss: 0.053798
   Number of active neurons: 3
 >> iter 91000, loss: 0.050795
 >> iter 92000, loss: 0.060768
 >> iter 93000, loss: 0.049711
 >> iter 94000, loss: 0.051189
 >> iter 95000, loss: 0.047592
 >> iter 96000, loss: 0.043760
 >> iter 97000, loss: 0.047977
 >> iter 98000, loss: 0.046830
 >> iter 99000, loss: 0.051890
 >> iter 100000, loss: 0.059637
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.370279
 >> iter 2000, loss: 4.466232
 >> iter 3000, loss: 1.805608
 >> iter 4000, loss: 0.752655
 >> iter 5000, loss: 0.334032
 >> iter 6000, loss: 0.184108
 >> iter 7000, loss: 0.123117
 >> iter 8000, loss: 0.094665
 >> iter 9000, loss: 0.086127
 >> iter 10000, loss: 0.084882
   Number of active neurons: 8
 >> iter 11000, loss: 0.072115
 >> iter 12000, loss: 0.065393
 >> iter 13000, loss: 0.078699
 >> iter 14000, loss: 0.090871
 >> iter 15000, loss: 0.059843
 >> iter 16000, loss: 0.053652
 >> iter 17000, loss: 0.057959
 >> iter 18000, loss: 0.077438
 >> iter 19000, loss: 0.052282
 >> iter 20000, loss: 0.048583
   Number of active neurons: 6
 >> iter 21000, loss: 0.065758
 >> iter 22000, loss: 0.058710
 >> iter 23000, loss: 0.072539
 >> iter 24000, loss: 0.056499
 >> iter 25000, loss: 0.057198
 >> iter 26000, loss: 0.057782
 >> iter 27000, loss: 0.050007
 >> iter 28000, loss: 0.056665
 >> iter 29000, loss: 0.068097
 >> iter 30000, loss: 0.056818
   Number of active neurons: 5
 >> iter 31000, loss: 0.062713
 >> iter 32000, loss: 0.056217
 >> iter 33000, loss: 0.053380
 >> iter 34000, loss: 0.041021
 >> iter 35000, loss: 0.036644
 >> iter 36000, loss: 0.056132
 >> iter 37000, loss: 0.063329
 >> iter 38000, loss: 0.069204
 >> iter 39000, loss: 0.054287
 >> iter 40000, loss: 0.041860
   Number of active neurons: 5
 >> iter 41000, loss: 0.034538
 >> iter 42000, loss: 0.051952
 >> iter 43000, loss: 0.064392
 >> iter 44000, loss: 0.044511
 >> iter 45000, loss: 0.064980
 >> iter 46000, loss: 0.047921
 >> iter 47000, loss: 0.066517
 >> iter 48000, loss: 0.051294
 >> iter 49000, loss: 0.053361
 >> iter 50000, loss: 0.043345
   Number of active neurons: 4
 >> iter 51000, loss: 0.052878
 >> iter 52000, loss: 0.044096
 >> iter 53000, loss: 0.056988
 >> iter 54000, loss: 0.058280
 >> iter 55000, loss: 0.049541
 >> iter 56000, loss: 0.044409
 >> iter 57000, loss: 0.050322
 >> iter 58000, loss: 0.038813
 >> iter 59000, loss: 0.055169
 >> iter 60000, loss: 0.052470
   Number of active neurons: 3
 >> iter 61000, loss: 0.065404
 >> iter 62000, loss: 0.045332
 >> iter 63000, loss: 0.040561
 >> iter 64000, loss: 0.064528
 >> iter 65000, loss: 0.056960
 >> iter 66000, loss: 0.051943
 >> iter 67000, loss: 0.041564
 >> iter 68000, loss: 0.035374
 >> iter 69000, loss: 0.046897
 >> iter 70000, loss: 0.060008
   Number of active neurons: 3
 >> iter 71000, loss: 0.052657
 >> iter 72000, loss: 0.074563
 >> iter 73000, loss: 0.058989
 >> iter 74000, loss: 0.046428
 >> iter 75000, loss: 0.063783
 >> iter 76000, loss: 0.068513
 >> iter 77000, loss: 0.056595
 >> iter 78000, loss: 0.048647
 >> iter 79000, loss: 0.041928
 >> iter 80000, loss: 0.047936
   Number of active neurons: 3
 >> iter 81000, loss: 0.038592
 >> iter 82000, loss: 0.050056
 >> iter 83000, loss: 0.043671
 >> iter 84000, loss: 0.048511
 >> iter 85000, loss: 0.042197
 >> iter 86000, loss: 0.052111
 >> iter 87000, loss: 0.070861
 >> iter 88000, loss: 0.053458
 >> iter 89000, loss: 0.052342
 >> iter 90000, loss: 0.049979
   Number of active neurons: 3
 >> iter 91000, loss: 0.047255
 >> iter 92000, loss: 0.052987
 >> iter 93000, loss: 0.055203
 >> iter 94000, loss: 0.037655
 >> iter 95000, loss: 0.037428
 >> iter 96000, loss: 0.042503
 >> iter 97000, loss: 0.045513
 >> iter 98000, loss: 0.047361
 >> iter 99000, loss: 0.063713
 >> iter 100000, loss: 0.062067
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.260046
 >> iter 2000, loss: 4.420909
 >> iter 3000, loss: 1.767469
 >> iter 4000, loss: 0.760226
 >> iter 5000, loss: 0.340307
 >> iter 6000, loss: 0.200839
 >> iter 7000, loss: 0.129295
 >> iter 8000, loss: 0.089440
 >> iter 9000, loss: 0.087651
 >> iter 10000, loss: 0.088466
   Number of active neurons: 9
 >> iter 11000, loss: 0.083241
 >> iter 12000, loss: 0.077990
 >> iter 13000, loss: 0.079856
 >> iter 14000, loss: 0.068495
 >> iter 15000, loss: 0.065383
 >> iter 16000, loss: 0.055462
 >> iter 17000, loss: 0.068766
 >> iter 18000, loss: 0.055117
 >> iter 19000, loss: 0.068949
 >> iter 20000, loss: 0.091873
   Number of active neurons: 6
 >> iter 21000, loss: 0.068628
 >> iter 22000, loss: 0.050730
 >> iter 23000, loss: 0.048811
 >> iter 24000, loss: 0.052356
 >> iter 25000, loss: 0.066442
 >> iter 26000, loss: 0.068593
 >> iter 27000, loss: 0.051334
 >> iter 28000, loss: 0.043695
 >> iter 29000, loss: 0.050930
 >> iter 30000, loss: 0.041968
   Number of active neurons: 6
 >> iter 31000, loss: 0.043646
 >> iter 32000, loss: 0.048369
 >> iter 33000, loss: 0.064308
 >> iter 34000, loss: 0.061732
 >> iter 35000, loss: 0.052483
 >> iter 36000, loss: 0.043819
 >> iter 37000, loss: 0.045778
 >> iter 38000, loss: 0.034798
 >> iter 39000, loss: 0.047803
 >> iter 40000, loss: 0.033539
   Number of active neurons: 3
 >> iter 41000, loss: 0.034917
 >> iter 42000, loss: 0.043489
 >> iter 43000, loss: 0.047293
 >> iter 44000, loss: 0.068166
 >> iter 45000, loss: 0.052638
 >> iter 46000, loss: 0.044764
 >> iter 47000, loss: 0.036114
 >> iter 48000, loss: 0.031553
 >> iter 49000, loss: 0.047103
 >> iter 50000, loss: 0.033660
   Number of active neurons: 3
 >> iter 51000, loss: 0.044193
 >> iter 52000, loss: 0.053934
 >> iter 53000, loss: 0.055217
 >> iter 54000, loss: 0.038970
 >> iter 55000, loss: 0.037222
 >> iter 56000, loss: 0.041368
 >> iter 57000, loss: 0.059574
 >> iter 58000, loss: 0.058014
 >> iter 59000, loss: 0.040602
 >> iter 60000, loss: 0.058040
   Number of active neurons: 3
 >> iter 61000, loss: 0.045678
 >> iter 62000, loss: 0.043441
 >> iter 63000, loss: 0.047294
 >> iter 64000, loss: 0.051476
 >> iter 65000, loss: 0.062887
 >> iter 66000, loss: 0.044680
 >> iter 67000, loss: 0.052374
 >> iter 68000, loss: 0.049628
 >> iter 69000, loss: 0.046733
 >> iter 70000, loss: 0.031270
   Number of active neurons: 3
 >> iter 71000, loss: 0.038045
 >> iter 72000, loss: 0.056499
 >> iter 73000, loss: 0.042829
 >> iter 74000, loss: 0.043592
 >> iter 75000, loss: 0.040519
 >> iter 76000, loss: 0.037793
 >> iter 77000, loss: 0.051036
 >> iter 78000, loss: 0.043041
 >> iter 79000, loss: 0.036653
 >> iter 80000, loss: 0.039753
   Number of active neurons: 2
 >> iter 81000, loss: 0.052184
 >> iter 82000, loss: 0.063165
 >> iter 83000, loss: 0.062454
 >> iter 84000, loss: 0.052165
 >> iter 85000, loss: 0.036757
 >> iter 86000, loss: 0.057901
 >> iter 87000, loss: 0.058528
 >> iter 88000, loss: 0.046653
 >> iter 89000, loss: 0.041308
 >> iter 90000, loss: 0.055779
   Number of active neurons: 2
 >> iter 91000, loss: 0.072801
 >> iter 92000, loss: 0.055477
 >> iter 93000, loss: 0.041413
 >> iter 94000, loss: 0.031153
 >> iter 95000, loss: 0.052529
 >> iter 96000, loss: 0.041693
 >> iter 97000, loss: 0.037060
 >> iter 98000, loss: 0.038455
 >> iter 99000, loss: 0.042165
 >> iter 100000, loss: 0.040742
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.348837
 >> iter 2000, loss: 4.485441
 >> iter 3000, loss: 1.811527
 >> iter 4000, loss: 0.794263
 >> iter 5000, loss: 0.371714
 >> iter 6000, loss: 0.197035
 >> iter 7000, loss: 0.138957
 >> iter 8000, loss: 0.107238
 >> iter 9000, loss: 0.108524
 >> iter 10000, loss: 0.136417
   Number of active neurons: 7
 >> iter 11000, loss: 0.086672
 >> iter 12000, loss: 0.076849
 >> iter 13000, loss: 0.066323
 >> iter 14000, loss: 0.064180
 >> iter 15000, loss: 0.067365
 >> iter 16000, loss: 0.054054
 >> iter 17000, loss: 0.055978
 >> iter 18000, loss: 0.046725
 >> iter 19000, loss: 0.055960
 >> iter 20000, loss: 0.050610
   Number of active neurons: 7
 >> iter 21000, loss: 0.042275
 >> iter 22000, loss: 0.068652
 >> iter 23000, loss: 0.061027
 >> iter 24000, loss: 0.060085
 >> iter 25000, loss: 0.049774
 >> iter 26000, loss: 0.041142
 >> iter 27000, loss: 0.055889
 >> iter 28000, loss: 0.048127
 >> iter 29000, loss: 0.065818
 >> iter 30000, loss: 0.053841
   Number of active neurons: 4
 >> iter 31000, loss: 0.077389
 >> iter 32000, loss: 0.060401
 >> iter 33000, loss: 0.046498
 >> iter 34000, loss: 0.046249
 >> iter 35000, loss: 0.047352
 >> iter 36000, loss: 0.069404
 >> iter 37000, loss: 0.045612
 >> iter 38000, loss: 0.035812
 >> iter 39000, loss: 0.043452
 >> iter 40000, loss: 0.049045
   Number of active neurons: 3
 >> iter 41000, loss: 0.072182
 >> iter 42000, loss: 0.048089
 >> iter 43000, loss: 0.049544
 >> iter 44000, loss: 0.047175
 >> iter 45000, loss: 0.036678
 >> iter 46000, loss: 0.053082
 >> iter 47000, loss: 0.063584
 >> iter 48000, loss: 0.057662
 >> iter 49000, loss: 0.043387
 >> iter 50000, loss: 0.034602
   Number of active neurons: 3
 >> iter 51000, loss: 0.042979
 >> iter 52000, loss: 0.033863
 >> iter 53000, loss: 0.062216
 >> iter 54000, loss: 0.048130
 >> iter 55000, loss: 0.069109
 >> iter 56000, loss: 0.044824
 >> iter 57000, loss: 0.044575
 >> iter 58000, loss: 0.046639
 >> iter 59000, loss: 0.052517
 >> iter 60000, loss: 0.057811
   Number of active neurons: 3
 >> iter 61000, loss: 0.059896
 >> iter 62000, loss: 0.046370
 >> iter 63000, loss: 0.037616
 >> iter 64000, loss: 0.041588
 >> iter 65000, loss: 0.060942
 >> iter 66000, loss: 0.057542
 >> iter 67000, loss: 0.057397
 >> iter 68000, loss: 0.057572
 >> iter 69000, loss: 0.070047
 >> iter 70000, loss: 0.060459
   Number of active neurons: 3
 >> iter 71000, loss: 0.041251
 >> iter 72000, loss: 0.042251
 >> iter 73000, loss: 0.051360
 >> iter 74000, loss: 0.046284
 >> iter 75000, loss: 0.050799
 >> iter 76000, loss: 0.045653
 >> iter 77000, loss: 0.039911
 >> iter 78000, loss: 0.042611
 >> iter 79000, loss: 0.043522
 >> iter 80000, loss: 0.053156
   Number of active neurons: 3
 >> iter 81000, loss: 0.060577
 >> iter 82000, loss: 0.057544
 >> iter 83000, loss: 0.055962
 >> iter 84000, loss: 0.059711
 >> iter 85000, loss: 0.044120
 >> iter 86000, loss: 0.044708
 >> iter 87000, loss: 0.039511
 >> iter 88000, loss: 0.039765
 >> iter 89000, loss: 0.036538
 >> iter 90000, loss: 0.045437
   Number of active neurons: 3
 >> iter 91000, loss: 0.038394
 >> iter 92000, loss: 0.080578
 >> iter 93000, loss: 0.054460
 >> iter 94000, loss: 0.052773
 >> iter 95000, loss: 0.071836
 >> iter 96000, loss: 0.067766
 >> iter 97000, loss: 0.047082
 >> iter 98000, loss: 0.041295
 >> iter 99000, loss: 0.048100
 >> iter 100000, loss: 0.044358
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.341564
 >> iter 2000, loss: 4.482031
 >> iter 3000, loss: 1.784731
 >> iter 4000, loss: 0.734964
 >> iter 5000, loss: 0.342514
 >> iter 6000, loss: 0.196268
 >> iter 7000, loss: 0.137914
 >> iter 8000, loss: 0.117712
 >> iter 9000, loss: 0.111221
 >> iter 10000, loss: 0.098460
   Number of active neurons: 9
 >> iter 11000, loss: 0.081420
 >> iter 12000, loss: 0.065389
 >> iter 13000, loss: 0.078842
 >> iter 14000, loss: 0.065404
 >> iter 15000, loss: 0.064111
 >> iter 16000, loss: 0.073148
 >> iter 17000, loss: 0.080309
 >> iter 18000, loss: 0.068533
 >> iter 19000, loss: 0.071956
 >> iter 20000, loss: 0.087178
   Number of active neurons: 8
 >> iter 21000, loss: 0.080534
 >> iter 22000, loss: 0.072331
 >> iter 23000, loss: 0.059129
 >> iter 24000, loss: 0.092111
 >> iter 25000, loss: 0.076501
 >> iter 26000, loss: 0.064298
 >> iter 27000, loss: 0.049968
 >> iter 28000, loss: 0.048888
 >> iter 29000, loss: 0.054701
 >> iter 30000, loss: 0.058938
   Number of active neurons: 6
 >> iter 31000, loss: 0.059394
 >> iter 32000, loss: 0.067199
 >> iter 33000, loss: 0.057869
 >> iter 34000, loss: 0.043199
 >> iter 35000, loss: 0.043107
 >> iter 36000, loss: 0.065589
 >> iter 37000, loss: 0.061341
 >> iter 38000, loss: 0.054790
 >> iter 39000, loss: 0.046183
 >> iter 40000, loss: 0.047657
   Number of active neurons: 6
 >> iter 41000, loss: 0.046776
 >> iter 42000, loss: 0.042064
 >> iter 43000, loss: 0.050513
 >> iter 44000, loss: 0.048975
 >> iter 45000, loss: 0.055444
 >> iter 46000, loss: 0.044841
 >> iter 47000, loss: 0.052815
 >> iter 48000, loss: 0.039050
 >> iter 49000, loss: 0.042191
 >> iter 50000, loss: 0.038704
   Number of active neurons: 5
 >> iter 51000, loss: 0.053423
 >> iter 52000, loss: 0.040586
 >> iter 53000, loss: 0.055862
 >> iter 54000, loss: 0.044382
 >> iter 55000, loss: 0.040906
 >> iter 56000, loss: 0.058352
 >> iter 57000, loss: 0.065756
 >> iter 58000, loss: 0.063857
 >> iter 59000, loss: 0.092079
 >> iter 60000, loss: 0.070977
   Number of active neurons: 5
 >> iter 61000, loss: 0.058895
 >> iter 62000, loss: 0.051571
 >> iter 63000, loss: 0.056766
 >> iter 64000, loss: 0.045263
 >> iter 65000, loss: 0.061800
 >> iter 66000, loss: 0.048099
 >> iter 67000, loss: 0.040490
 >> iter 68000, loss: 0.047017
 >> iter 69000, loss: 0.046166
 >> iter 70000, loss: 0.043543
   Number of active neurons: 4
 >> iter 71000, loss: 0.048612
 >> iter 72000, loss: 0.043994
 >> iter 73000, loss: 0.045352
 >> iter 74000, loss: 0.057163
 >> iter 75000, loss: 0.055338
 >> iter 76000, loss: 0.056802
 >> iter 77000, loss: 0.053806
 >> iter 78000, loss: 0.068397
 >> iter 79000, loss: 0.044735
 >> iter 80000, loss: 0.045245
   Number of active neurons: 4
 >> iter 81000, loss: 0.061981
 >> iter 82000, loss: 0.054798
 >> iter 83000, loss: 0.044717
 >> iter 84000, loss: 0.040899
 >> iter 85000, loss: 0.034713
 >> iter 86000, loss: 0.056882
 >> iter 87000, loss: 0.067027
 >> iter 88000, loss: 0.046055
 >> iter 89000, loss: 0.046715
 >> iter 90000, loss: 0.063736
   Number of active neurons: 4
 >> iter 91000, loss: 0.051327
 >> iter 92000, loss: 0.054937
 >> iter 93000, loss: 0.057622
 >> iter 94000, loss: 0.038756
 >> iter 95000, loss: 0.035827
 >> iter 96000, loss: 0.038713
 >> iter 97000, loss: 0.046952
 >> iter 98000, loss: 0.064526
 >> iter 99000, loss: 0.047428
 >> iter 100000, loss: 0.047128
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.337980
 >> iter 2000, loss: 4.436282
 >> iter 3000, loss: 1.749789
 >> iter 4000, loss: 0.767392
 >> iter 5000, loss: 0.353303
 >> iter 6000, loss: 0.229072
 >> iter 7000, loss: 0.158067
 >> iter 8000, loss: 0.119958
 >> iter 9000, loss: 0.108049
 >> iter 10000, loss: 0.078731
   Number of active neurons: 9
 >> iter 11000, loss: 0.076238
 >> iter 12000, loss: 0.087209
 >> iter 13000, loss: 0.060277
 >> iter 14000, loss: 0.069618
 >> iter 15000, loss: 0.066786
 >> iter 16000, loss: 0.080311
 >> iter 17000, loss: 0.079646
 >> iter 18000, loss: 0.060872
 >> iter 19000, loss: 0.066232
 >> iter 20000, loss: 0.067469
   Number of active neurons: 8
 >> iter 21000, loss: 0.057281
 >> iter 22000, loss: 0.056898
 >> iter 23000, loss: 0.068106
 >> iter 24000, loss: 0.048680
 >> iter 25000, loss: 0.062737
 >> iter 26000, loss: 0.047398
 >> iter 27000, loss: 0.060315
 >> iter 28000, loss: 0.053151
 >> iter 29000, loss: 0.048658
 >> iter 30000, loss: 0.043212
   Number of active neurons: 6
 >> iter 31000, loss: 0.039021
 >> iter 32000, loss: 0.045448
 >> iter 33000, loss: 0.043641
 >> iter 34000, loss: 0.049909
 >> iter 35000, loss: 0.047440
 >> iter 36000, loss: 0.066260
 >> iter 37000, loss: 0.051298
 >> iter 38000, loss: 0.051777
 >> iter 39000, loss: 0.061164
 >> iter 40000, loss: 0.056733
   Number of active neurons: 4
 >> iter 41000, loss: 0.040433
 >> iter 42000, loss: 0.035206
 >> iter 43000, loss: 0.030003
 >> iter 44000, loss: 0.035956
 >> iter 45000, loss: 0.042300
 >> iter 46000, loss: 0.034973
 >> iter 47000, loss: 0.038324
 >> iter 48000, loss: 0.058306
 >> iter 49000, loss: 0.045545
 >> iter 50000, loss: 0.042017
   Number of active neurons: 4
 >> iter 51000, loss: 0.052370
 >> iter 52000, loss: 0.055102
 >> iter 53000, loss: 0.052762
 >> iter 54000, loss: 0.052148
 >> iter 55000, loss: 0.045984
 >> iter 56000, loss: 0.045458
 >> iter 57000, loss: 0.054786
 >> iter 58000, loss: 0.051480
 >> iter 59000, loss: 0.039779
 >> iter 60000, loss: 0.039052
   Number of active neurons: 4
 >> iter 61000, loss: 0.036790
 >> iter 62000, loss: 0.044613
 >> iter 63000, loss: 0.055592
 >> iter 64000, loss: 0.046240
 >> iter 65000, loss: 0.041031
 >> iter 66000, loss: 0.037734
 >> iter 67000, loss: 0.033514
 >> iter 68000, loss: 0.049494
 >> iter 69000, loss: 0.054123
 >> iter 70000, loss: 0.046428
   Number of active neurons: 4
 >> iter 71000, loss: 0.048198
 >> iter 72000, loss: 0.041626
 >> iter 73000, loss: 0.054908
 >> iter 74000, loss: 0.055441
 >> iter 75000, loss: 0.063693
 >> iter 76000, loss: 0.045612
 >> iter 77000, loss: 0.034449
 >> iter 78000, loss: 0.047426
 >> iter 79000, loss: 0.041153
 >> iter 80000, loss: 0.046612
   Number of active neurons: 4
 >> iter 81000, loss: 0.056274
 >> iter 82000, loss: 0.050021
 >> iter 83000, loss: 0.035990
 >> iter 84000, loss: 0.029016
 >> iter 85000, loss: 0.056389
 >> iter 86000, loss: 0.076200
 >> iter 87000, loss: 0.065144
 >> iter 88000, loss: 0.050177
 >> iter 89000, loss: 0.041146
 >> iter 90000, loss: 0.041424
   Number of active neurons: 3
 >> iter 91000, loss: 0.055408
 >> iter 92000, loss: 0.057647
 >> iter 93000, loss: 0.045847
 >> iter 94000, loss: 0.051066
 >> iter 95000, loss: 0.057422
 >> iter 96000, loss: 0.056720
 >> iter 97000, loss: 0.046000
 >> iter 98000, loss: 0.046822
 >> iter 99000, loss: 0.044845
 >> iter 100000, loss: 0.046120
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.286104
 >> iter 2000, loss: 4.423309
 >> iter 3000, loss: 1.754627
 >> iter 4000, loss: 0.723701
 >> iter 5000, loss: 0.354511
 >> iter 6000, loss: 0.192149
 >> iter 7000, loss: 0.113726
 >> iter 8000, loss: 0.080953
 >> iter 9000, loss: 0.081616
 >> iter 10000, loss: 0.070016
   Number of active neurons: 8
 >> iter 11000, loss: 0.082385
 >> iter 12000, loss: 0.074017
 >> iter 13000, loss: 0.060174
 >> iter 14000, loss: 0.056515
 >> iter 15000, loss: 0.061461
 >> iter 16000, loss: 0.057381
 >> iter 17000, loss: 0.053468
 >> iter 18000, loss: 0.064287
 >> iter 19000, loss: 0.046396
 >> iter 20000, loss: 0.056178
   Number of active neurons: 5
 >> iter 21000, loss: 0.043272
 >> iter 22000, loss: 0.041833
 >> iter 23000, loss: 0.051651
 >> iter 24000, loss: 0.087969
 >> iter 25000, loss: 0.064364
 >> iter 26000, loss: 0.059183
 >> iter 27000, loss: 0.053073
 >> iter 28000, loss: 0.054325
 >> iter 29000, loss: 0.058573
 >> iter 30000, loss: 0.053597
   Number of active neurons: 4
 >> iter 31000, loss: 0.044666
 >> iter 32000, loss: 0.051474
 >> iter 33000, loss: 0.048925
 >> iter 34000, loss: 0.036771
 >> iter 35000, loss: 0.046206
 >> iter 36000, loss: 0.052114
 >> iter 37000, loss: 0.058234
 >> iter 38000, loss: 0.062280
 >> iter 39000, loss: 0.044513
 >> iter 40000, loss: 0.039597
   Number of active neurons: 3
 >> iter 41000, loss: 0.037276
 >> iter 42000, loss: 0.045642
 >> iter 43000, loss: 0.062151
 >> iter 44000, loss: 0.062562
 >> iter 45000, loss: 0.047828
 >> iter 46000, loss: 0.045805
 >> iter 47000, loss: 0.049139
 >> iter 48000, loss: 0.072028
 >> iter 49000, loss: 0.051123
 >> iter 50000, loss: 0.057441
   Number of active neurons: 3
 >> iter 51000, loss: 0.065646
 >> iter 52000, loss: 0.042300
 >> iter 53000, loss: 0.050316
 >> iter 54000, loss: 0.044063
 >> iter 55000, loss: 0.047150
 >> iter 56000, loss: 0.055242
 >> iter 57000, loss: 0.045120
 >> iter 58000, loss: 0.060627
 >> iter 59000, loss: 0.046973
 >> iter 60000, loss: 0.043875
   Number of active neurons: 3
 >> iter 61000, loss: 0.049015
 >> iter 62000, loss: 0.048791
 >> iter 63000, loss: 0.061022
 >> iter 64000, loss: 0.059897
 >> iter 65000, loss: 0.043942
 >> iter 66000, loss: 0.036724
 >> iter 67000, loss: 0.045249
 >> iter 68000, loss: 0.034819
 >> iter 69000, loss: 0.052489
 >> iter 70000, loss: 0.047376
   Number of active neurons: 3
 >> iter 71000, loss: 0.049960
 >> iter 72000, loss: 0.041866
 >> iter 73000, loss: 0.056076
 >> iter 74000, loss: 0.053570
 >> iter 75000, loss: 0.055552
 >> iter 76000, loss: 0.062468
 >> iter 77000, loss: 0.039138
 >> iter 78000, loss: 0.038794
 >> iter 79000, loss: 0.043749
 >> iter 80000, loss: 0.040605
   Number of active neurons: 2
 >> iter 81000, loss: 0.042852
 >> iter 82000, loss: 0.070426
 >> iter 83000, loss: 0.067422
 >> iter 84000, loss: 0.053029
 >> iter 85000, loss: 0.036352
 >> iter 86000, loss: 0.035117
 >> iter 87000, loss: 0.040557
 >> iter 88000, loss: 0.045434
 >> iter 89000, loss: 0.069540
 >> iter 90000, loss: 0.046897
   Number of active neurons: 2
 >> iter 91000, loss: 0.041169
 >> iter 92000, loss: 0.041846
 >> iter 93000, loss: 0.038752
 >> iter 94000, loss: 0.073647
 >> iter 95000, loss: 0.055071
 >> iter 96000, loss: 0.064896
 >> iter 97000, loss: 0.042011
 >> iter 98000, loss: 0.032966
 >> iter 99000, loss: 0.065141
 >> iter 100000, loss: 0.049480
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.276544
 >> iter 2000, loss: 4.431434
 >> iter 3000, loss: 1.796432
 >> iter 4000, loss: 0.796902
 >> iter 5000, loss: 0.396537
 >> iter 6000, loss: 0.251321
 >> iter 7000, loss: 0.190974
 >> iter 8000, loss: 0.138767
 >> iter 9000, loss: 0.115486
 >> iter 10000, loss: 0.109529
   Number of active neurons: 10
 >> iter 11000, loss: 0.094621
 >> iter 12000, loss: 0.078334
 >> iter 13000, loss: 0.081619
 >> iter 14000, loss: 0.072929
 >> iter 15000, loss: 0.057324
 >> iter 16000, loss: 0.067765
 >> iter 17000, loss: 0.058964
 >> iter 18000, loss: 0.063908
 >> iter 19000, loss: 0.070741
 >> iter 20000, loss: 0.074441
   Number of active neurons: 8
 >> iter 21000, loss: 0.072237
 >> iter 22000, loss: 0.057894
 >> iter 23000, loss: 0.054649
 >> iter 24000, loss: 0.054435
 >> iter 25000, loss: 0.049699
 >> iter 26000, loss: 0.042844
 >> iter 27000, loss: 0.063282
 >> iter 28000, loss: 0.061556
 >> iter 29000, loss: 0.069882
 >> iter 30000, loss: 0.068415
   Number of active neurons: 6
 >> iter 31000, loss: 0.056766
 >> iter 32000, loss: 0.043033
 >> iter 33000, loss: 0.054343
 >> iter 34000, loss: 0.040967
 >> iter 35000, loss: 0.047073
 >> iter 36000, loss: 0.059756
 >> iter 37000, loss: 0.051941
 >> iter 38000, loss: 0.040324
 >> iter 39000, loss: 0.059111
 >> iter 40000, loss: 0.053975
   Number of active neurons: 5
 >> iter 41000, loss: 0.054392
 >> iter 42000, loss: 0.037892
 >> iter 43000, loss: 0.046046
 >> iter 44000, loss: 0.041229
 >> iter 45000, loss: 0.044340
 >> iter 46000, loss: 0.063894
 >> iter 47000, loss: 0.057177
 >> iter 48000, loss: 0.047307
 >> iter 49000, loss: 0.045240
 >> iter 50000, loss: 0.042991
   Number of active neurons: 4
 >> iter 51000, loss: 0.043907
 >> iter 52000, loss: 0.038954
 >> iter 53000, loss: 0.036944
 >> iter 54000, loss: 0.070275
 >> iter 55000, loss: 0.052424
 >> iter 56000, loss: 0.064759
 >> iter 57000, loss: 0.051193
 >> iter 58000, loss: 0.083603
 >> iter 59000, loss: 0.068330
 >> iter 60000, loss: 0.061085
   Number of active neurons: 3
 >> iter 61000, loss: 0.047622
 >> iter 62000, loss: 0.041758
 >> iter 63000, loss: 0.043343
 >> iter 64000, loss: 0.040747
 >> iter 65000, loss: 0.042778
 >> iter 66000, loss: 0.039172
 >> iter 67000, loss: 0.035636
 >> iter 68000, loss: 0.046271
 >> iter 69000, loss: 0.035239
 >> iter 70000, loss: 0.041583
   Number of active neurons: 3
 >> iter 71000, loss: 0.037048
 >> iter 72000, loss: 0.036449
 >> iter 73000, loss: 0.041644
 >> iter 74000, loss: 0.047135
 >> iter 75000, loss: 0.069908
 >> iter 76000, loss: 0.067527
 >> iter 77000, loss: 0.048691
 >> iter 78000, loss: 0.067644
 >> iter 79000, loss: 0.066175
 >> iter 80000, loss: 0.051422
   Number of active neurons: 3
 >> iter 81000, loss: 0.046768
 >> iter 82000, loss: 0.048200
 >> iter 83000, loss: 0.046058
 >> iter 84000, loss: 0.042338
 >> iter 85000, loss: 0.058782
 >> iter 86000, loss: 0.042600
 >> iter 87000, loss: 0.040256
 >> iter 88000, loss: 0.057709
 >> iter 89000, loss: 0.053831
 >> iter 90000, loss: 0.057956
   Number of active neurons: 2
 >> iter 91000, loss: 0.046095
 >> iter 92000, loss: 0.051731
 >> iter 93000, loss: 0.058969
 >> iter 94000, loss: 0.040736
 >> iter 95000, loss: 0.052119
 >> iter 96000, loss: 0.051437
 >> iter 97000, loss: 0.042134
 >> iter 98000, loss: 0.034038
 >> iter 99000, loss: 0.065870
 >> iter 100000, loss: 0.063173
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.290637
 >> iter 2000, loss: 4.377495
 >> iter 3000, loss: 1.711714
 >> iter 4000, loss: 0.711102
 >> iter 5000, loss: 0.345269
 >> iter 6000, loss: 0.202133
 >> iter 7000, loss: 0.120521
 >> iter 8000, loss: 0.093554
 >> iter 9000, loss: 0.077449
 >> iter 10000, loss: 0.063138
   Number of active neurons: 7
 >> iter 11000, loss: 0.076714
 >> iter 12000, loss: 0.070108
 >> iter 13000, loss: 0.076064
 >> iter 14000, loss: 0.084469
 >> iter 15000, loss: 0.066060
 >> iter 16000, loss: 0.089833
 >> iter 17000, loss: 0.077750
 >> iter 18000, loss: 0.069580
 >> iter 19000, loss: 0.051809
 >> iter 20000, loss: 0.046508
   Number of active neurons: 6
 >> iter 21000, loss: 0.053783
 >> iter 22000, loss: 0.062583
 >> iter 23000, loss: 0.048832
 >> iter 24000, loss: 0.055223
 >> iter 25000, loss: 0.051860
 >> iter 26000, loss: 0.055896
 >> iter 27000, loss: 0.056287
 >> iter 28000, loss: 0.056101
 >> iter 29000, loss: 0.068369
 >> iter 30000, loss: 0.067056
   Number of active neurons: 5
 >> iter 31000, loss: 0.049440
 >> iter 32000, loss: 0.061998
 >> iter 33000, loss: 0.071524
 >> iter 34000, loss: 0.056604
 >> iter 35000, loss: 0.051269
 >> iter 36000, loss: 0.051673
 >> iter 37000, loss: 0.059680
 >> iter 38000, loss: 0.079172
 >> iter 39000, loss: 0.049892
 >> iter 40000, loss: 0.050134
   Number of active neurons: 5
 >> iter 41000, loss: 0.059885
 >> iter 42000, loss: 0.053442
 >> iter 43000, loss: 0.059407
 >> iter 44000, loss: 0.048338
 >> iter 45000, loss: 0.057336
 >> iter 46000, loss: 0.063224
 >> iter 47000, loss: 0.066679
 >> iter 48000, loss: 0.070516
 >> iter 49000, loss: 0.068853
 >> iter 50000, loss: 0.059256
   Number of active neurons: 5
 >> iter 51000, loss: 0.053412
 >> iter 52000, loss: 0.036011
 >> iter 53000, loss: 0.038791
 >> iter 54000, loss: 0.040087
 >> iter 55000, loss: 0.037223
 >> iter 56000, loss: 0.042295
 >> iter 57000, loss: 0.046820
 >> iter 58000, loss: 0.050592
 >> iter 59000, loss: 0.039086
 >> iter 60000, loss: 0.037894
   Number of active neurons: 4
 >> iter 61000, loss: 0.057214
 >> iter 62000, loss: 0.058635
 >> iter 63000, loss: 0.054019
 >> iter 64000, loss: 0.071019
 >> iter 65000, loss: 0.050837
 >> iter 66000, loss: 0.037409
 >> iter 67000, loss: 0.037373
 >> iter 68000, loss: 0.036801
 >> iter 69000, loss: 0.037899
 >> iter 70000, loss: 0.037875
   Number of active neurons: 4
 >> iter 71000, loss: 0.061026
 >> iter 72000, loss: 0.049328
 >> iter 73000, loss: 0.050898
 >> iter 74000, loss: 0.056093
 >> iter 75000, loss: 0.042517
 >> iter 76000, loss: 0.043190
 >> iter 77000, loss: 0.033318
 >> iter 78000, loss: 0.067619
 >> iter 79000, loss: 0.052939
 >> iter 80000, loss: 0.039599
   Number of active neurons: 4
 >> iter 81000, loss: 0.035229
 >> iter 82000, loss: 0.054401
 >> iter 83000, loss: 0.055383
 >> iter 84000, loss: 0.059106
 >> iter 85000, loss: 0.043155
 >> iter 86000, loss: 0.040088
 >> iter 87000, loss: 0.050566
 >> iter 88000, loss: 0.047778
 >> iter 89000, loss: 0.064860
 >> iter 90000, loss: 0.065846
   Number of active neurons: 4
 >> iter 91000, loss: 0.046111
 >> iter 92000, loss: 0.048422
 >> iter 93000, loss: 0.047938
 >> iter 94000, loss: 0.036059
 >> iter 95000, loss: 0.039163
 >> iter 96000, loss: 0.027875
 >> iter 97000, loss: 0.033904
 >> iter 98000, loss: 0.043487
 >> iter 99000, loss: 0.034938
 >> iter 100000, loss: 0.042555
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.350396
 >> iter 2000, loss: 4.470220
 >> iter 3000, loss: 1.842068
 >> iter 4000, loss: 0.824310
 >> iter 5000, loss: 0.406369
 >> iter 6000, loss: 0.225497
 >> iter 7000, loss: 0.146291
 >> iter 8000, loss: 0.114570
 >> iter 9000, loss: 0.092896
 >> iter 10000, loss: 0.101860
   Number of active neurons: 10
 >> iter 11000, loss: 0.085605
 >> iter 12000, loss: 0.068938
 >> iter 13000, loss: 0.067327
 >> iter 14000, loss: 0.071708
 >> iter 15000, loss: 0.069739
 >> iter 16000, loss: 0.091957
 >> iter 17000, loss: 0.074326
 >> iter 18000, loss: 0.072700
 >> iter 19000, loss: 0.065426
 >> iter 20000, loss: 0.078406
   Number of active neurons: 7
 >> iter 21000, loss: 0.073217
 >> iter 22000, loss: 0.047233
 >> iter 23000, loss: 0.051062
 >> iter 24000, loss: 0.056753
 >> iter 25000, loss: 0.056468
 >> iter 26000, loss: 0.049803
 >> iter 27000, loss: 0.044477
 >> iter 28000, loss: 0.068424
 >> iter 29000, loss: 0.081219
 >> iter 30000, loss: 0.061924
   Number of active neurons: 7
 >> iter 31000, loss: 0.050051
 >> iter 32000, loss: 0.055930
 >> iter 33000, loss: 0.037932
 >> iter 34000, loss: 0.051370
 >> iter 35000, loss: 0.074565
 >> iter 36000, loss: 0.050586
 >> iter 37000, loss: 0.061170
 >> iter 38000, loss: 0.049153
 >> iter 39000, loss: 0.036177
 >> iter 40000, loss: 0.063279
   Number of active neurons: 6
 >> iter 41000, loss: 0.052881
 >> iter 42000, loss: 0.039704
 >> iter 43000, loss: 0.066210
 >> iter 44000, loss: 0.048421
 >> iter 45000, loss: 0.055305
 >> iter 46000, loss: 0.054650
 >> iter 47000, loss: 0.042698
 >> iter 48000, loss: 0.044337
 >> iter 49000, loss: 0.054188
 >> iter 50000, loss: 0.040871
   Number of active neurons: 4
 >> iter 51000, loss: 0.037773
 >> iter 52000, loss: 0.045106
 >> iter 53000, loss: 0.037816
 >> iter 54000, loss: 0.038050
 >> iter 55000, loss: 0.031251
 >> iter 56000, loss: 0.030322
 >> iter 57000, loss: 0.044828
 >> iter 58000, loss: 0.040823
 >> iter 59000, loss: 0.048276
 >> iter 60000, loss: 0.053491
   Number of active neurons: 4
 >> iter 61000, loss: 0.046006
 >> iter 62000, loss: 0.039762
 >> iter 63000, loss: 0.044288
 >> iter 64000, loss: 0.071525
 >> iter 65000, loss: 0.044744
 >> iter 66000, loss: 0.056529
 >> iter 67000, loss: 0.075113
 >> iter 68000, loss: 0.056839
 >> iter 69000, loss: 0.046417
 >> iter 70000, loss: 0.043959
   Number of active neurons: 3
 >> iter 71000, loss: 0.046884
 >> iter 72000, loss: 0.057136
 >> iter 73000, loss: 0.042679
 >> iter 74000, loss: 0.046061
 >> iter 75000, loss: 0.062744
 >> iter 76000, loss: 0.049207
 >> iter 77000, loss: 0.033634
 >> iter 78000, loss: 0.029289
 >> iter 79000, loss: 0.032563
 >> iter 80000, loss: 0.046309
   Number of active neurons: 2
 >> iter 81000, loss: 0.036725
 >> iter 82000, loss: 0.036004
 >> iter 83000, loss: 0.050795
 >> iter 84000, loss: 0.071802
 >> iter 85000, loss: 0.059235
 >> iter 86000, loss: 0.051850
 >> iter 87000, loss: 0.052945
 >> iter 88000, loss: 0.055635
 >> iter 89000, loss: 0.038754
 >> iter 90000, loss: 0.034743
   Number of active neurons: 2
 >> iter 91000, loss: 0.041288
 >> iter 92000, loss: 0.038339
 >> iter 93000, loss: 0.054870
 >> iter 94000, loss: 0.059501
 >> iter 95000, loss: 0.043070
 >> iter 96000, loss: 0.053700
 >> iter 97000, loss: 0.049536
 >> iter 98000, loss: 0.058415
 >> iter 99000, loss: 0.051951
 >> iter 100000, loss: 0.073525
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455161
   Number of active neurons: 0
 >> iter 1000, loss: 11.231130
 >> iter 2000, loss: 4.356058
 >> iter 3000, loss: 1.747246
 >> iter 4000, loss: 0.750598
 >> iter 5000, loss: 0.355224
 >> iter 6000, loss: 0.205058
 >> iter 7000, loss: 0.164638
 >> iter 8000, loss: 0.124857
 >> iter 9000, loss: 0.107077
 >> iter 10000, loss: 0.093618
   Number of active neurons: 11
 >> iter 11000, loss: 0.089970
 >> iter 12000, loss: 0.107242
 >> iter 13000, loss: 0.100195
 >> iter 14000, loss: 0.096029
 >> iter 15000, loss: 0.090606
 >> iter 16000, loss: 0.071100
 >> iter 17000, loss: 0.073684
 >> iter 18000, loss: 0.085783
 >> iter 19000, loss: 0.072664
 >> iter 20000, loss: 0.067936
   Number of active neurons: 7
 >> iter 21000, loss: 0.063554
 >> iter 22000, loss: 0.050496
 >> iter 23000, loss: 0.055695
 >> iter 24000, loss: 0.061823
 >> iter 25000, loss: 0.061633
 >> iter 26000, loss: 0.075448
 >> iter 27000, loss: 0.059344
 >> iter 28000, loss: 0.049733
 >> iter 29000, loss: 0.041881
 >> iter 30000, loss: 0.077538
   Number of active neurons: 6
 >> iter 31000, loss: 0.058630
 >> iter 32000, loss: 0.059742
 >> iter 33000, loss: 0.062718
 >> iter 34000, loss: 0.050575
 >> iter 35000, loss: 0.042978
 >> iter 36000, loss: 0.050476
 >> iter 37000, loss: 0.044535
 >> iter 38000, loss: 0.048144
 >> iter 39000, loss: 0.054146
 >> iter 40000, loss: 0.054944
   Number of active neurons: 4
 >> iter 41000, loss: 0.054118
 >> iter 42000, loss: 0.062245
 >> iter 43000, loss: 0.060444
 >> iter 44000, loss: 0.058182
 >> iter 45000, loss: 0.056107
 >> iter 46000, loss: 0.041360
 >> iter 47000, loss: 0.045784
 >> iter 48000, loss: 0.050830
 >> iter 49000, loss: 0.051251
 >> iter 50000, loss: 0.058286
   Number of active neurons: 4
 >> iter 51000, loss: 0.083675
 >> iter 52000, loss: 0.057594
 >> iter 53000, loss: 0.075452
 >> iter 54000, loss: 0.049010
 >> iter 55000, loss: 0.047210
 >> iter 56000, loss: 0.048158
 >> iter 57000, loss: 0.054443
 >> iter 58000, loss: 0.050832
 >> iter 59000, loss: 0.068745
 >> iter 60000, loss: 0.048503
   Number of active neurons: 4
 >> iter 61000, loss: 0.031914
 >> iter 62000, loss: 0.042744
 >> iter 63000, loss: 0.032002
 >> iter 64000, loss: 0.062636
 >> iter 65000, loss: 0.065871
 >> iter 66000, loss: 0.061404
 >> iter 67000, loss: 0.042825
 >> iter 68000, loss: 0.040431
 >> iter 69000, loss: 0.041823
 >> iter 70000, loss: 0.058995
   Number of active neurons: 4
 >> iter 71000, loss: 0.064177
 >> iter 72000, loss: 0.056932
 >> iter 73000, loss: 0.067599
 >> iter 74000, loss: 0.051818
 >> iter 75000, loss: 0.042199
 >> iter 76000, loss: 0.050191
 >> iter 77000, loss: 0.040158
 >> iter 78000, loss: 0.056281
 >> iter 79000, loss: 0.038326
 >> iter 80000, loss: 0.042465
   Number of active neurons: 4
 >> iter 81000, loss: 0.049903
 >> iter 82000, loss: 0.058624
 >> iter 83000, loss: 0.055456
 >> iter 84000, loss: 0.057702
 >> iter 85000, loss: 0.053194
 >> iter 86000, loss: 0.053163
 >> iter 87000, loss: 0.041990
 >> iter 88000, loss: 0.044602
 >> iter 89000, loss: 0.045928
 >> iter 90000, loss: 0.048090
   Number of active neurons: 4
 >> iter 91000, loss: 0.049325
 >> iter 92000, loss: 0.066720
 >> iter 93000, loss: 0.061617
 >> iter 94000, loss: 0.048175
 >> iter 95000, loss: 0.068398
 >> iter 96000, loss: 0.048651
 >> iter 97000, loss: 0.041167
 >> iter 98000, loss: 0.044972
 >> iter 99000, loss: 0.037873
 >> iter 100000, loss: 0.080208
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455180
   Number of active neurons: 0
 >> iter 1000, loss: 11.339739
 >> iter 2000, loss: 4.399976
 >> iter 3000, loss: 1.706747
 >> iter 4000, loss: 0.721231
 >> iter 5000, loss: 0.317724
 >> iter 6000, loss: 0.170051
 >> iter 7000, loss: 0.096052
 >> iter 8000, loss: 0.099336
 >> iter 9000, loss: 0.076587
 >> iter 10000, loss: 0.077316
   Number of active neurons: 7
 >> iter 11000, loss: 0.061935
 >> iter 12000, loss: 0.051276
 >> iter 13000, loss: 0.062452
 >> iter 14000, loss: 0.054629
 >> iter 15000, loss: 0.084288
 >> iter 16000, loss: 0.089711
 >> iter 17000, loss: 0.098557
 >> iter 18000, loss: 0.066201
 >> iter 19000, loss: 0.066774
 >> iter 20000, loss: 0.056841
   Number of active neurons: 7
 >> iter 21000, loss: 0.072457
 >> iter 22000, loss: 0.054720
 >> iter 23000, loss: 0.055697
 >> iter 24000, loss: 0.048057
 >> iter 25000, loss: 0.050067
 >> iter 26000, loss: 0.050263
 >> iter 27000, loss: 0.065675
 >> iter 28000, loss: 0.073079
 >> iter 29000, loss: 0.051458
 >> iter 30000, loss: 0.045402
   Number of active neurons: 6
 >> iter 31000, loss: 0.046696
 >> iter 32000, loss: 0.074809
 >> iter 33000, loss: 0.065573
 >> iter 34000, loss: 0.071903
 >> iter 35000, loss: 0.053584
 >> iter 36000, loss: 0.050552
 >> iter 37000, loss: 0.057052
 >> iter 38000, loss: 0.058865
 >> iter 39000, loss: 0.051574
 >> iter 40000, loss: 0.050744
   Number of active neurons: 6
 >> iter 41000, loss: 0.053943
 >> iter 42000, loss: 0.068635
 >> iter 43000, loss: 0.052328
 >> iter 44000, loss: 0.044126
 >> iter 45000, loss: 0.056000
 >> iter 46000, loss: 0.043640
 >> iter 47000, loss: 0.047034
 >> iter 48000, loss: 0.033417
 >> iter 49000, loss: 0.033608
 >> iter 50000, loss: 0.056967
   Number of active neurons: 4
 >> iter 51000, loss: 0.058400
 >> iter 52000, loss: 0.054930
 >> iter 53000, loss: 0.052854
 >> iter 54000, loss: 0.063217
 >> iter 55000, loss: 0.055105
 >> iter 56000, loss: 0.056926
 >> iter 57000, loss: 0.065498
 >> iter 58000, loss: 0.044934
 >> iter 59000, loss: 0.056443
 >> iter 60000, loss: 0.040220
   Number of active neurons: 3
 >> iter 61000, loss: 0.038902
 >> iter 62000, loss: 0.058222
 >> iter 63000, loss: 0.063250
 >> iter 64000, loss: 0.047372
 >> iter 65000, loss: 0.065121
 >> iter 66000, loss: 0.046758
 >> iter 67000, loss: 0.048912
 >> iter 68000, loss: 0.047886
 >> iter 69000, loss: 0.056620
 >> iter 70000, loss: 0.070639
   Number of active neurons: 3
 >> iter 71000, loss: 0.060135
 >> iter 72000, loss: 0.045590
 >> iter 73000, loss: 0.064662
 >> iter 74000, loss: 0.049317
 >> iter 75000, loss: 0.054601
 >> iter 76000, loss: 0.050972
 >> iter 77000, loss: 0.040401
 >> iter 78000, loss: 0.033733
 >> iter 79000, loss: 0.035876
 >> iter 80000, loss: 0.073760
   Number of active neurons: 2
 >> iter 81000, loss: 0.083859
 >> iter 82000, loss: 0.058032
 >> iter 83000, loss: 0.052446
 >> iter 84000, loss: 0.051302
 >> iter 85000, loss: 0.042605
 >> iter 86000, loss: 0.030698
 >> iter 87000, loss: 0.026258
 >> iter 88000, loss: 0.039532
 >> iter 89000, loss: 0.050047
 >> iter 90000, loss: 0.045959
   Number of active neurons: 2
 >> iter 91000, loss: 0.045993
 >> iter 92000, loss: 0.051205
 >> iter 93000, loss: 0.038942
 >> iter 94000, loss: 0.038674
 >> iter 95000, loss: 0.052040
 >> iter 96000, loss: 0.034585
 >> iter 97000, loss: 0.037847
 >> iter 98000, loss: 0.028292
 >> iter 99000, loss: 0.031562
 >> iter 100000, loss: 0.054528
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455160
   Number of active neurons: 0
 >> iter 1000, loss: 11.238537
 >> iter 2000, loss: 4.455622
 >> iter 3000, loss: 1.780497
 >> iter 4000, loss: 0.731957
 >> iter 5000, loss: 0.371914
 >> iter 6000, loss: 0.213014
 >> iter 7000, loss: 0.129250
 >> iter 8000, loss: 0.107419
 >> iter 9000, loss: 0.085684
 >> iter 10000, loss: 0.079937
   Number of active neurons: 9
 >> iter 11000, loss: 0.058882
 >> iter 12000, loss: 0.078974
 >> iter 13000, loss: 0.081362
 >> iter 14000, loss: 0.092141
 >> iter 15000, loss: 0.085640
 >> iter 16000, loss: 0.072289
 >> iter 17000, loss: 0.066516
 >> iter 18000, loss: 0.050262
 >> iter 19000, loss: 0.062310
 >> iter 20000, loss: 0.064002
   Number of active neurons: 7
 >> iter 21000, loss: 0.051774
 >> iter 22000, loss: 0.064388
 >> iter 23000, loss: 0.061413
 >> iter 24000, loss: 0.055567
 >> iter 25000, loss: 0.044264
 >> iter 26000, loss: 0.051692
 >> iter 27000, loss: 0.073973
 >> iter 28000, loss: 0.058877
 >> iter 29000, loss: 0.047981
 >> iter 30000, loss: 0.053292
   Number of active neurons: 5
 >> iter 31000, loss: 0.063566
 >> iter 32000, loss: 0.049724
 >> iter 33000, loss: 0.040833
 >> iter 34000, loss: 0.055019
 >> iter 35000, loss: 0.050265
 >> iter 36000, loss: 0.054632
 >> iter 37000, loss: 0.056696
 >> iter 38000, loss: 0.063691
 >> iter 39000, loss: 0.058919
 >> iter 40000, loss: 0.058842
   Number of active neurons: 5
 >> iter 41000, loss: 0.047297
 >> iter 42000, loss: 0.051108
 >> iter 43000, loss: 0.042317
 >> iter 44000, loss: 0.044233
 >> iter 45000, loss: 0.060023
 >> iter 46000, loss: 0.046675
 >> iter 47000, loss: 0.043852
 >> iter 48000, loss: 0.055944
 >> iter 49000, loss: 0.044740
 >> iter 50000, loss: 0.065285
   Number of active neurons: 5
 >> iter 51000, loss: 0.053492
 >> iter 52000, loss: 0.048516
 >> iter 53000, loss: 0.052548
 >> iter 54000, loss: 0.061760
 >> iter 55000, loss: 0.062794
 >> iter 56000, loss: 0.058126
 >> iter 57000, loss: 0.046509
 >> iter 58000, loss: 0.063562
 >> iter 59000, loss: 0.059349
 >> iter 60000, loss: 0.041817
   Number of active neurons: 4
 >> iter 61000, loss: 0.047724
 >> iter 62000, loss: 0.035804
 >> iter 63000, loss: 0.057223
 >> iter 64000, loss: 0.053068
 >> iter 65000, loss: 0.045321
 >> iter 66000, loss: 0.049089
 >> iter 67000, loss: 0.046798
 >> iter 68000, loss: 0.046856
 >> iter 69000, loss: 0.042604
 >> iter 70000, loss: 0.060234
   Number of active neurons: 4
 >> iter 71000, loss: 0.050468
 >> iter 72000, loss: 0.055547
 >> iter 73000, loss: 0.069140
 >> iter 74000, loss: 0.049376
 >> iter 75000, loss: 0.050247
 >> iter 76000, loss: 0.059866
 >> iter 77000, loss: 0.046151
 >> iter 78000, loss: 0.051205
 >> iter 79000, loss: 0.071719
 >> iter 80000, loss: 0.062976
   Number of active neurons: 3
 >> iter 81000, loss: 0.053987
 >> iter 82000, loss: 0.059830
 >> iter 83000, loss: 0.045444
 >> iter 84000, loss: 0.043316
 >> iter 85000, loss: 0.048719
 >> iter 86000, loss: 0.035239
 >> iter 87000, loss: 0.043982
 >> iter 88000, loss: 0.041681
 >> iter 89000, loss: 0.046178
 >> iter 90000, loss: 0.049504
   Number of active neurons: 3
 >> iter 91000, loss: 0.054925
 >> iter 92000, loss: 0.038644
 >> iter 93000, loss: 0.047165
 >> iter 94000, loss: 0.042713
 >> iter 95000, loss: 0.047756
 >> iter 96000, loss: 0.038787
 >> iter 97000, loss: 0.060518
 >> iter 98000, loss: 0.049096
 >> iter 99000, loss: 0.046280
 >> iter 100000, loss: 0.042365
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455163
   Number of active neurons: 0
 >> iter 1000, loss: 11.329708
 >> iter 2000, loss: 4.460614
 >> iter 3000, loss: 1.771263
 >> iter 4000, loss: 0.750331
 >> iter 5000, loss: 0.351732
 >> iter 6000, loss: 0.201628
 >> iter 7000, loss: 0.146879
 >> iter 8000, loss: 0.111636
 >> iter 9000, loss: 0.093664
 >> iter 10000, loss: 0.096062
   Number of active neurons: 10
 >> iter 11000, loss: 0.088456
 >> iter 12000, loss: 0.070940
 >> iter 13000, loss: 0.061260
 >> iter 14000, loss: 0.070073
 >> iter 15000, loss: 0.061151
 >> iter 16000, loss: 0.054934
 >> iter 17000, loss: 0.057118
 >> iter 18000, loss: 0.081195
 >> iter 19000, loss: 0.075609
 >> iter 20000, loss: 0.063049
   Number of active neurons: 7
 >> iter 21000, loss: 0.067582
 >> iter 22000, loss: 0.053628
 >> iter 23000, loss: 0.072955
 >> iter 24000, loss: 0.050710
 >> iter 25000, loss: 0.049518
 >> iter 26000, loss: 0.048723
 >> iter 27000, loss: 0.052739
 >> iter 28000, loss: 0.082084
 >> iter 29000, loss: 0.056589
 >> iter 30000, loss: 0.042201
   Number of active neurons: 5
 >> iter 31000, loss: 0.043760
 >> iter 32000, loss: 0.052246
 >> iter 33000, loss: 0.036435
 >> iter 34000, loss: 0.031616
 >> iter 35000, loss: 0.052031
 >> iter 36000, loss: 0.070242
 >> iter 37000, loss: 0.058336
 >> iter 38000, loss: 0.043526
 >> iter 39000, loss: 0.038735
 >> iter 40000, loss: 0.038312
   Number of active neurons: 4
 >> iter 41000, loss: 0.041613
 >> iter 42000, loss: 0.042878
 >> iter 43000, loss: 0.041412
 >> iter 44000, loss: 0.042704
 >> iter 45000, loss: 0.051196
 >> iter 46000, loss: 0.066844
 >> iter 47000, loss: 0.050567
 >> iter 48000, loss: 0.052774
 >> iter 49000, loss: 0.044223
 >> iter 50000, loss: 0.057167
   Number of active neurons: 3
 >> iter 51000, loss: 0.042565
 >> iter 52000, loss: 0.045452
 >> iter 53000, loss: 0.036840
 >> iter 54000, loss: 0.041048
 >> iter 55000, loss: 0.057771
 >> iter 56000, loss: 0.050408
 >> iter 57000, loss: 0.044381
 >> iter 58000, loss: 0.037371
 >> iter 59000, loss: 0.041028
 >> iter 60000, loss: 0.034793
   Number of active neurons: 3
 >> iter 61000, loss: 0.033274
 >> iter 62000, loss: 0.045108
 >> iter 63000, loss: 0.061364
 >> iter 64000, loss: 0.041781
 >> iter 65000, loss: 0.044742
 >> iter 66000, loss: 0.039581
 >> iter 67000, loss: 0.049250
 >> iter 68000, loss: 0.048724
 >> iter 69000, loss: 0.052726
 >> iter 70000, loss: 0.038007
   Number of active neurons: 3
 >> iter 71000, loss: 0.036958
 >> iter 72000, loss: 0.039413
 >> iter 73000, loss: 0.043643
 >> iter 74000, loss: 0.035896
 >> iter 75000, loss: 0.046044
 >> iter 76000, loss: 0.040021
 >> iter 77000, loss: 0.045204
 >> iter 78000, loss: 0.037046
 >> iter 79000, loss: 0.032940
 >> iter 80000, loss: 0.055063
   Number of active neurons: 3
 >> iter 81000, loss: 0.048131
 >> iter 82000, loss: 0.036828
 >> iter 83000, loss: 0.039133
 >> iter 84000, loss: 0.048086
 >> iter 85000, loss: 0.037902
 >> iter 86000, loss: 0.042756
 >> iter 87000, loss: 0.054882
 >> iter 88000, loss: 0.038366
 >> iter 89000, loss: 0.040908
 >> iter 90000, loss: 0.039834
   Number of active neurons: 3
 >> iter 91000, loss: 0.039006
 >> iter 92000, loss: 0.033468
 >> iter 93000, loss: 0.032951
 >> iter 94000, loss: 0.036491
 >> iter 95000, loss: 0.043343
 >> iter 96000, loss: 0.035457
 >> iter 97000, loss: 0.050257
 >> iter 98000, loss: 0.036733
 >> iter 99000, loss: 0.052671
 >> iter 100000, loss: 0.058134
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.241448
 >> iter 2000, loss: 4.420392
 >> iter 3000, loss: 1.743531
 >> iter 4000, loss: 0.734142
 >> iter 5000, loss: 0.336092
 >> iter 6000, loss: 0.192999
 >> iter 7000, loss: 0.126930
 >> iter 8000, loss: 0.127591
 >> iter 9000, loss: 0.087941
 >> iter 10000, loss: 0.075691
   Number of active neurons: 9
 >> iter 11000, loss: 0.114578
 >> iter 12000, loss: 0.083723
 >> iter 13000, loss: 0.071754
 >> iter 14000, loss: 0.067906
 >> iter 15000, loss: 0.063331
 >> iter 16000, loss: 0.090909
 >> iter 17000, loss: 0.087721
 >> iter 18000, loss: 0.062650
 >> iter 19000, loss: 0.053943
 >> iter 20000, loss: 0.047326
   Number of active neurons: 6
 >> iter 21000, loss: 0.049015
 >> iter 22000, loss: 0.052938
 >> iter 23000, loss: 0.069239
 >> iter 24000, loss: 0.054999
 >> iter 25000, loss: 0.059679
 >> iter 26000, loss: 0.046084
 >> iter 27000, loss: 0.047733
 >> iter 28000, loss: 0.042333
 >> iter 29000, loss: 0.077691
 >> iter 30000, loss: 0.060457
   Number of active neurons: 6
 >> iter 31000, loss: 0.064837
 >> iter 32000, loss: 0.045953
 >> iter 33000, loss: 0.077593
 >> iter 34000, loss: 0.073110
 >> iter 35000, loss: 0.061271
 >> iter 36000, loss: 0.065133
 >> iter 37000, loss: 0.065330
 >> iter 38000, loss: 0.042660
 >> iter 39000, loss: 0.050893
 >> iter 40000, loss: 0.044464
   Number of active neurons: 5
 >> iter 41000, loss: 0.050050
 >> iter 42000, loss: 0.042463
 >> iter 43000, loss: 0.057203
 >> iter 44000, loss: 0.071155
 >> iter 45000, loss: 0.053658
 >> iter 46000, loss: 0.046692
 >> iter 47000, loss: 0.047828
 >> iter 48000, loss: 0.043392
 >> iter 49000, loss: 0.059272
 >> iter 50000, loss: 0.064698
   Number of active neurons: 4
 >> iter 51000, loss: 0.052322
 >> iter 52000, loss: 0.055386
 >> iter 53000, loss: 0.040533
 >> iter 54000, loss: 0.045339
 >> iter 55000, loss: 0.048654
 >> iter 56000, loss: 0.059101
 >> iter 57000, loss: 0.053816
 >> iter 58000, loss: 0.058319
 >> iter 59000, loss: 0.079394
 >> iter 60000, loss: 0.063027
   Number of active neurons: 3
 >> iter 61000, loss: 0.041291
 >> iter 62000, loss: 0.034710
 >> iter 63000, loss: 0.037548
 >> iter 64000, loss: 0.047690
 >> iter 65000, loss: 0.050102
 >> iter 66000, loss: 0.043229
 >> iter 67000, loss: 0.062581
 >> iter 68000, loss: 0.053510
 >> iter 69000, loss: 0.051345
 >> iter 70000, loss: 0.047879
   Number of active neurons: 2
 >> iter 71000, loss: 0.053243
 >> iter 72000, loss: 0.053149
 >> iter 73000, loss: 0.070693
 >> iter 74000, loss: 0.048203
 >> iter 75000, loss: 0.046959
 >> iter 76000, loss: 0.046091
 >> iter 77000, loss: 0.054505
 >> iter 78000, loss: 0.050989
 >> iter 79000, loss: 0.067375
 >> iter 80000, loss: 0.073987
   Number of active neurons: 2
 >> iter 81000, loss: 0.045885
 >> iter 82000, loss: 0.039948
 >> iter 83000, loss: 0.047231
 >> iter 84000, loss: 0.040903
 >> iter 85000, loss: 0.037557
 >> iter 86000, loss: 0.040892
 >> iter 87000, loss: 0.044637
 >> iter 88000, loss: 0.037280
 >> iter 89000, loss: 0.076784
 >> iter 90000, loss: 0.060420
   Number of active neurons: 2
 >> iter 91000, loss: 0.051817
 >> iter 92000, loss: 0.054684
 >> iter 93000, loss: 0.046753
 >> iter 94000, loss: 0.052470
 >> iter 95000, loss: 0.051577
 >> iter 96000, loss: 0.034552
 >> iter 97000, loss: 0.039127
 >> iter 98000, loss: 0.039483
 >> iter 99000, loss: 0.039809
 >> iter 100000, loss: 0.054951
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

