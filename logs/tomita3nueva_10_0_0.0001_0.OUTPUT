 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.682986
 >> iter 2000, loss: 7.984810
 >> iter 3000, loss: 2.995066
 >> iter 4000, loss: 1.147268
 >> iter 5000, loss: 0.492688
 >> iter 6000, loss: 0.226224
 >> iter 7000, loss: 0.152347
 >> iter 8000, loss: 0.095915
 >> iter 9000, loss: 0.069462
 >> iter 10000, loss: 0.063277
   Number of active neurons: 8
 >> iter 11000, loss: 0.061895
 >> iter 12000, loss: 0.058912
 >> iter 13000, loss: 0.150458
 >> iter 14000, loss: 0.093167
 >> iter 15000, loss: 0.199485
 >> iter 16000, loss: 0.108451
 >> iter 17000, loss: 0.150031
 >> iter 18000, loss: 0.088965
 >> iter 19000, loss: 0.202297
 >> iter 20000, loss: 0.108308
   Number of active neurons: 7
 >> iter 21000, loss: 0.190743
 >> iter 22000, loss: 0.105291
 >> iter 23000, loss: 0.159570
 >> iter 24000, loss: 0.101175
 >> iter 25000, loss: 0.149890
 >> iter 26000, loss: 0.098935
 >> iter 27000, loss: 0.136882
 >> iter 28000, loss: 0.093634
 >> iter 29000, loss: 0.129136
 >> iter 30000, loss: 0.088311
   Number of active neurons: 7
 >> iter 31000, loss: 0.131504
 >> iter 32000, loss: 0.085485
 >> iter 33000, loss: 0.136004
 >> iter 34000, loss: 0.085289
 >> iter 35000, loss: 0.138895
 >> iter 36000, loss: 0.089216
 >> iter 37000, loss: 0.148726
 >> iter 38000, loss: 0.101191
 >> iter 39000, loss: 0.156199
 >> iter 40000, loss: 0.113714
   Number of active neurons: 6
 >> iter 41000, loss: 0.157484
 >> iter 42000, loss: 0.116161
 >> iter 43000, loss: 0.144078
 >> iter 44000, loss: 0.106368
 >> iter 45000, loss: 0.148306
 >> iter 46000, loss: 0.102116
 >> iter 47000, loss: 0.153839
 >> iter 48000, loss: 0.113563
 >> iter 49000, loss: 0.079963
 >> iter 50000, loss: 0.086452
   Number of active neurons: 6
 >> iter 51000, loss: 0.141505
 >> iter 52000, loss: 0.108615
 >> iter 53000, loss: 0.137462
 >> iter 54000, loss: 0.092784
 >> iter 55000, loss: 0.141807
 >> iter 56000, loss: 0.111880
 >> iter 57000, loss: 0.149944
 >> iter 58000, loss: 0.103902
 >> iter 59000, loss: 0.144126
 >> iter 60000, loss: 0.108258
   Number of active neurons: 6
 >> iter 61000, loss: 0.138420
 >> iter 62000, loss: 0.101205
 >> iter 63000, loss: 0.140380
 >> iter 64000, loss: 0.094917
 >> iter 65000, loss: 0.136488
 >> iter 66000, loss: 0.099480
 >> iter 67000, loss: 0.137295
 >> iter 68000, loss: 0.096837
 >> iter 69000, loss: 0.136211
 >> iter 70000, loss: 0.088885
   Number of active neurons: 6
 >> iter 71000, loss: 0.132810
 >> iter 72000, loss: 0.097517
 >> iter 73000, loss: 0.135827
 >> iter 74000, loss: 0.097350
 >> iter 75000, loss: 0.136290
 >> iter 76000, loss: 0.098300
 >> iter 77000, loss: 0.134869
 >> iter 78000, loss: 0.096906
 >> iter 79000, loss: 0.133651
 >> iter 80000, loss: 0.093566
   Number of active neurons: 6
 >> iter 81000, loss: 0.132456
 >> iter 82000, loss: 0.087376
 >> iter 83000, loss: 0.128728
 >> iter 84000, loss: 0.096351
 >> iter 85000, loss: 0.133445
 >> iter 86000, loss: 0.083540
 >> iter 87000, loss: 0.127532
 >> iter 88000, loss: 0.095219
 >> iter 89000, loss: 0.130536
 >> iter 90000, loss: 0.097185
   Number of active neurons: 6
 >> iter 91000, loss: 0.130828
 >> iter 92000, loss: 0.188572
 >> iter 93000, loss: 0.164341
 >> iter 94000, loss: 0.105911
 >> iter 95000, loss: 0.070482
 >> iter 96000, loss: 0.141944
 >> iter 97000, loss: 0.097329
 >> iter 98000, loss: 0.068228
 >> iter 99000, loss: 0.065832
 >> iter 100000, loss: 0.067874
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0239995200096
   - Test - Long: 0.0
   - Test - Big: 0.0039999600004
   - Test - A: 0.0
   - Test - B: 22.7984801013
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.837449
 >> iter 2000, loss: 8.648707
 >> iter 3000, loss: 3.478314
 >> iter 4000, loss: 1.380299
 >> iter 5000, loss: 0.695336
 >> iter 6000, loss: 0.325774
 >> iter 7000, loss: 0.275608
 >> iter 8000, loss: 0.181605
 >> iter 9000, loss: 0.308835
 >> iter 10000, loss: 0.174921
   Number of active neurons: 5
 >> iter 11000, loss: 0.178156
 >> iter 12000, loss: 0.126402
 >> iter 13000, loss: 0.102559
 >> iter 14000, loss: 0.074647
 >> iter 15000, loss: 0.242761
 >> iter 16000, loss: 0.130117
 >> iter 17000, loss: 0.271427
 >> iter 18000, loss: 0.140735
 >> iter 19000, loss: 0.249638
 >> iter 20000, loss: 0.134877
   Number of active neurons: 5
 >> iter 21000, loss: 0.227574
 >> iter 22000, loss: 0.150254
 >> iter 23000, loss: 0.577185
 >> iter 24000, loss: 0.376623
 >> iter 25000, loss: 0.342242
 >> iter 26000, loss: 0.192271
 >> iter 27000, loss: 0.195263
 >> iter 28000, loss: 0.105931
 >> iter 29000, loss: 0.104865
 >> iter 30000, loss: 0.083619
   Number of active neurons: 5
 >> iter 31000, loss: 0.206491
 >> iter 32000, loss: 0.123261
 >> iter 33000, loss: 0.287164
 >> iter 34000, loss: 0.144537
 >> iter 35000, loss: 0.125016
 >> iter 36000, loss: 0.136390
 >> iter 37000, loss: 0.227558
 >> iter 38000, loss: 0.147837
 >> iter 39000, loss: 0.136504
 >> iter 40000, loss: 0.107291
   Number of active neurons: 5
 >> iter 41000, loss: 0.151256
 >> iter 42000, loss: 0.109916
 >> iter 43000, loss: 0.085961
 >> iter 44000, loss: 0.158879
 >> iter 45000, loss: 0.195490
 >> iter 46000, loss: 0.186257
 >> iter 47000, loss: 0.260679
 >> iter 48000, loss: 0.160696
 >> iter 49000, loss: 0.264862
 >> iter 50000, loss: 0.153028
   Number of active neurons: 5
 >> iter 51000, loss: 0.135059
 >> iter 52000, loss: 0.150035
 >> iter 53000, loss: 0.132847
 >> iter 54000, loss: 0.079880
 >> iter 55000, loss: 0.224123
 >> iter 56000, loss: 0.126752
 >> iter 57000, loss: 0.097162
 >> iter 58000, loss: 0.154264
 >> iter 59000, loss: 0.094066
 >> iter 60000, loss: 0.070655
   Number of active neurons: 5
 >> iter 61000, loss: 0.301853
 >> iter 62000, loss: 0.181930
 >> iter 63000, loss: 0.293343
 >> iter 64000, loss: 0.189722
 >> iter 65000, loss: 0.172146
 >> iter 66000, loss: 0.179977
 >> iter 67000, loss: 0.161330
 >> iter 68000, loss: 0.275998
 >> iter 69000, loss: 0.267544
 >> iter 70000, loss: 0.133881
   Number of active neurons: 5
 >> iter 71000, loss: 0.115566
 >> iter 72000, loss: 0.116916
 >> iter 73000, loss: 0.174178
 >> iter 74000, loss: 0.132340
 >> iter 75000, loss: 0.105729
 >> iter 76000, loss: 0.083663
 >> iter 77000, loss: 0.180788
 >> iter 78000, loss: 0.100439
 >> iter 79000, loss: 0.153446
 >> iter 80000, loss: 0.169108
   Number of active neurons: 5
 >> iter 81000, loss: 0.186931
 >> iter 82000, loss: 0.118192
 >> iter 83000, loss: 0.210397
 >> iter 84000, loss: 0.110181
 >> iter 85000, loss: 0.152077
 >> iter 86000, loss: 0.149132
 >> iter 87000, loss: 0.130343
 >> iter 88000, loss: 0.107994
 >> iter 89000, loss: 0.234569
 >> iter 90000, loss: 0.116418
   Number of active neurons: 5
 >> iter 91000, loss: 0.286386
 >> iter 92000, loss: 0.166388
 >> iter 93000, loss: 0.264997
 >> iter 94000, loss: 0.230363
 >> iter 95000, loss: 0.111335
 >> iter 96000, loss: 0.118242
 >> iter 97000, loss: 0.187153
 >> iter 98000, loss: 0.099087
 >> iter 99000, loss: 0.147941
 >> iter 100000, loss: 0.162086
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.00599988000241
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 4.83301113259
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.096164
 >> iter 2000, loss: 8.732141
 >> iter 3000, loss: 3.441660
 >> iter 4000, loss: 1.375335
 >> iter 5000, loss: 0.628127
 >> iter 6000, loss: 0.286751
 >> iter 7000, loss: 0.234906
 >> iter 8000, loss: 0.137434
 >> iter 9000, loss: 0.265001
 >> iter 10000, loss: 0.139264
   Number of active neurons: 5
 >> iter 11000, loss: 0.198262
 >> iter 12000, loss: 0.260628
 >> iter 13000, loss: 0.289819
 >> iter 14000, loss: 0.164036
 >> iter 15000, loss: 0.277285
 >> iter 16000, loss: 0.159064
 >> iter 17000, loss: 0.245862
 >> iter 18000, loss: 0.162136
 >> iter 19000, loss: 0.301756
 >> iter 20000, loss: 0.152853
   Number of active neurons: 5
 >> iter 21000, loss: 0.420608
 >> iter 22000, loss: 0.207558
 >> iter 23000, loss: 0.261705
 >> iter 24000, loss: 0.144664
 >> iter 25000, loss: 0.084050
 >> iter 26000, loss: 0.065420
 >> iter 27000, loss: 0.174344
 >> iter 28000, loss: 0.150998
 >> iter 29000, loss: 0.246363
 >> iter 30000, loss: 0.129267
   Number of active neurons: 5
 >> iter 31000, loss: 0.242328
 >> iter 32000, loss: 0.129742
 >> iter 33000, loss: 0.275861
 >> iter 34000, loss: 0.154824
 >> iter 35000, loss: 0.387385
 >> iter 36000, loss: 0.348289
 >> iter 37000, loss: 0.251434
 >> iter 38000, loss: 0.178436
 >> iter 39000, loss: 0.224073
 >> iter 40000, loss: 0.186087
   Number of active neurons: 5
 >> iter 41000, loss: 0.179590
 >> iter 42000, loss: 0.107689
 >> iter 43000, loss: 0.152773
 >> iter 44000, loss: 0.151643
 >> iter 45000, loss: 0.368606
 >> iter 46000, loss: 0.209700
 >> iter 47000, loss: 0.335630
 >> iter 48000, loss: 0.214791
 >> iter 49000, loss: 0.190328
 >> iter 50000, loss: 0.169878
   Number of active neurons: 5
 >> iter 51000, loss: 0.164899
 >> iter 52000, loss: 0.125974
 >> iter 53000, loss: 0.453894
 >> iter 54000, loss: 0.544007
 >> iter 55000, loss: 0.262909
 >> iter 56000, loss: 0.131249
 >> iter 57000, loss: 0.272229
 >> iter 58000, loss: 0.136381
 >> iter 59000, loss: 0.212825
 >> iter 60000, loss: 0.110791
   Number of active neurons: 5
 >> iter 61000, loss: 0.290954
 >> iter 62000, loss: 0.150834
 >> iter 63000, loss: 0.235007
 >> iter 64000, loss: 0.118552
 >> iter 65000, loss: 0.293983
 >> iter 66000, loss: 0.170570
 >> iter 67000, loss: 0.301143
 >> iter 68000, loss: 0.148034
 >> iter 69000, loss: 0.225979
 >> iter 70000, loss: 0.164443
   Number of active neurons: 5
 >> iter 71000, loss: 0.292798
 >> iter 72000, loss: 0.164925
 >> iter 73000, loss: 0.352590
 >> iter 74000, loss: 0.187291
 >> iter 75000, loss: 0.312494
 >> iter 76000, loss: 0.172868
 >> iter 77000, loss: 0.519157
 >> iter 78000, loss: 0.255366
 >> iter 79000, loss: 0.219605
 >> iter 80000, loss: 0.131782
   Number of active neurons: 4
 >> iter 81000, loss: 0.105380
 >> iter 82000, loss: 0.114078
 >> iter 83000, loss: 0.253212
 >> iter 84000, loss: 0.151418
 >> iter 85000, loss: 0.284431
 >> iter 86000, loss: 0.165128
 >> iter 87000, loss: 0.222172
 >> iter 88000, loss: 0.134424
 >> iter 89000, loss: 0.292557
 >> iter 90000, loss: 0.135983
   Number of active neurons: 4
 >> iter 91000, loss: 0.234483
 >> iter 92000, loss: 0.149250
 >> iter 93000, loss: 0.361673
 >> iter 94000, loss: 0.186763
 >> iter 95000, loss: 0.345294
 >> iter 96000, loss: 0.182321
 >> iter 97000, loss: 0.312161
 >> iter 98000, loss: 0.146164
 >> iter 99000, loss: 0.157157
 >> iter 100000, loss: 0.106016
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.1599920004
   - Test - Big: 0.0039999600004
   - Test - A: 0.0
   - Test - B: 20.2386507566
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.041715
 >> iter 2000, loss: 8.648378
 >> iter 3000, loss: 3.247052
 >> iter 4000, loss: 1.245443
 >> iter 5000, loss: 0.496908
 >> iter 6000, loss: 0.233334
 >> iter 7000, loss: 0.226065
 >> iter 8000, loss: 0.152982
 >> iter 9000, loss: 0.258453
 >> iter 10000, loss: 0.152290
   Number of active neurons: 8
 >> iter 11000, loss: 0.149446
 >> iter 12000, loss: 0.101013
 >> iter 13000, loss: 0.144403
 >> iter 14000, loss: 0.097628
 >> iter 15000, loss: 0.170634
 >> iter 16000, loss: 0.107499
 >> iter 17000, loss: 0.177447
 >> iter 18000, loss: 0.115056
 >> iter 19000, loss: 0.173654
 >> iter 20000, loss: 0.106793
   Number of active neurons: 8
 >> iter 21000, loss: 0.135432
 >> iter 22000, loss: 0.089902
 >> iter 23000, loss: 0.125950
 >> iter 24000, loss: 0.092453
 >> iter 25000, loss: 0.161152
 >> iter 26000, loss: 0.103863
 >> iter 27000, loss: 0.071904
 >> iter 28000, loss: 0.067637
 >> iter 29000, loss: 0.057604
 >> iter 30000, loss: 0.054219
   Number of active neurons: 8
 >> iter 31000, loss: 0.053214
 >> iter 32000, loss: 0.052757
 >> iter 33000, loss: 0.052622
 >> iter 34000, loss: 0.052139
 >> iter 35000, loss: 0.051967
 >> iter 36000, loss: 0.051608
 >> iter 37000, loss: 0.051655
 >> iter 38000, loss: 0.051227
 >> iter 39000, loss: 0.050997
 >> iter 40000, loss: 0.050172
   Number of active neurons: 7
 >> iter 41000, loss: 0.049474
 >> iter 42000, loss: 0.048376
 >> iter 43000, loss: 0.047663
 >> iter 44000, loss: 0.046597
 >> iter 45000, loss: 0.045660
 >> iter 46000, loss: 0.044250
 >> iter 47000, loss: 0.043446
 >> iter 48000, loss: 0.042570
 >> iter 49000, loss: 0.041939
 >> iter 50000, loss: 0.041251
   Number of active neurons: 8
 >> iter 51000, loss: 0.040821
 >> iter 52000, loss: 0.040410
 >> iter 53000, loss: 0.039963
 >> iter 54000, loss: 0.039371
 >> iter 55000, loss: 0.038820
 >> iter 56000, loss: 0.038359
 >> iter 57000, loss: 0.037744
 >> iter 58000, loss: 0.054130
 >> iter 59000, loss: 0.041915
 >> iter 60000, loss: 0.064609
   Number of active neurons: 6
 >> iter 61000, loss: 0.045089
 >> iter 62000, loss: 0.038261
 >> iter 63000, loss: 0.035779
 >> iter 64000, loss: 0.034938
 >> iter 65000, loss: 0.034491
 >> iter 66000, loss: 0.034166
 >> iter 67000, loss: 0.033890
 >> iter 68000, loss: 0.033532
 >> iter 69000, loss: 0.033118
 >> iter 70000, loss: 0.048262
   Number of active neurons: 6
 >> iter 71000, loss: 0.037333
 >> iter 72000, loss: 0.048781
 >> iter 73000, loss: 0.037298
 >> iter 74000, loss: 0.033805
 >> iter 75000, loss: 0.032087
 >> iter 76000, loss: 0.031632
 >> iter 77000, loss: 0.031365
 >> iter 78000, loss: 0.031511
 >> iter 79000, loss: 0.031220
 >> iter 80000, loss: 0.031153
   Number of active neurons: 6
 >> iter 81000, loss: 0.031118
 >> iter 82000, loss: 0.031093
 >> iter 83000, loss: 0.031016
 >> iter 84000, loss: 0.030963
 >> iter 85000, loss: 0.030894
 >> iter 86000, loss: 0.030832
 >> iter 87000, loss: 0.030768
 >> iter 88000, loss: 0.030757
 >> iter 89000, loss: 0.030648
 >> iter 90000, loss: 0.030648
   Number of active neurons: 6
 >> iter 91000, loss: 0.030537
 >> iter 92000, loss: 0.030547
 >> iter 93000, loss: 0.030442
 >> iter 94000, loss: 0.030661
 >> iter 95000, loss: 0.030379
 >> iter 96000, loss: 0.030249
 >> iter 97000, loss: 0.030306
 >> iter 98000, loss: 0.030268
 >> iter 99000, loss: 0.030286
 >> iter 100000, loss: 0.030224
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0133324445037
   - Test - B: 18.4587694154
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.033471
 >> iter 2000, loss: 13.085270
 >> iter 3000, loss: 6.019042
 >> iter 4000, loss: 2.383237
 >> iter 5000, loss: 1.194378
 >> iter 6000, loss: 0.499747
 >> iter 7000, loss: 0.379348
 >> iter 8000, loss: 0.197572
 >> iter 9000, loss: 0.387436
 >> iter 10000, loss: 0.194898
   Number of active neurons: 5
 >> iter 11000, loss: 0.148312
 >> iter 12000, loss: 0.115022
 >> iter 13000, loss: 0.076862
 >> iter 14000, loss: 0.085988
 >> iter 15000, loss: 0.144134
 >> iter 16000, loss: 0.086714
 >> iter 17000, loss: 0.184321
 >> iter 18000, loss: 0.099668
 >> iter 19000, loss: 0.069679
 >> iter 20000, loss: 0.081012
   Number of active neurons: 5
 >> iter 21000, loss: 0.067310
 >> iter 22000, loss: 0.060376
 >> iter 23000, loss: 0.138551
 >> iter 24000, loss: 0.083879
 >> iter 25000, loss: 0.073405
 >> iter 26000, loss: 0.056638
 >> iter 27000, loss: 0.262197
 >> iter 28000, loss: 0.123340
 >> iter 29000, loss: 0.078384
 >> iter 30000, loss: 0.083844
   Number of active neurons: 5
 >> iter 31000, loss: 0.088735
 >> iter 32000, loss: 0.076259
 >> iter 33000, loss: 0.081581
 >> iter 34000, loss: 0.060812
 >> iter 35000, loss: 0.082990
 >> iter 36000, loss: 0.062586
 >> iter 37000, loss: 0.106591
 >> iter 38000, loss: 0.069980
 >> iter 39000, loss: 0.149331
 >> iter 40000, loss: 0.092713
   Number of active neurons: 5
 >> iter 41000, loss: 0.061527
 >> iter 42000, loss: 0.086691
 >> iter 43000, loss: 0.188336
 >> iter 44000, loss: 0.097516
 >> iter 45000, loss: 0.067402
 >> iter 46000, loss: 0.108702
 >> iter 47000, loss: 0.116521
 >> iter 48000, loss: 0.073023
 >> iter 49000, loss: 0.081428
 >> iter 50000, loss: 0.060510
   Number of active neurons: 5
 >> iter 51000, loss: 0.054097
 >> iter 52000, loss: 0.081547
 >> iter 53000, loss: 0.138548
 >> iter 54000, loss: 0.088164
 >> iter 55000, loss: 0.076314
 >> iter 56000, loss: 0.053575
 >> iter 57000, loss: 0.104045
 >> iter 58000, loss: 0.077152
 >> iter 59000, loss: 0.148415
 >> iter 60000, loss: 0.086784
   Number of active neurons: 5
 >> iter 61000, loss: 0.212861
 >> iter 62000, loss: 0.289552
 >> iter 63000, loss: 0.139856
 >> iter 64000, loss: 0.079297
 >> iter 65000, loss: 0.057944
 >> iter 66000, loss: 0.050748
 >> iter 67000, loss: 0.420059
 >> iter 68000, loss: 0.220907
 >> iter 69000, loss: 0.425804
 >> iter 70000, loss: 0.189393
   Number of active neurons: 5
 >> iter 71000, loss: 0.153626
 >> iter 72000, loss: 0.087188
 >> iter 73000, loss: 0.454315
 >> iter 74000, loss: 0.317413
 >> iter 75000, loss: 0.226101
 >> iter 76000, loss: 0.252904
 >> iter 77000, loss: 0.174281
 >> iter 78000, loss: 0.097883
 >> iter 79000, loss: 0.069085
 >> iter 80000, loss: 0.061524
   Number of active neurons: 5
 >> iter 81000, loss: 0.216099
 >> iter 82000, loss: 0.108200
 >> iter 83000, loss: 0.196931
 >> iter 84000, loss: 0.296097
 >> iter 85000, loss: 0.149888
 >> iter 86000, loss: 0.086591
 >> iter 87000, loss: 0.114864
 >> iter 88000, loss: 0.082407
 >> iter 89000, loss: 0.134797
 >> iter 90000, loss: 0.078732
   Number of active neurons: 5
 >> iter 91000, loss: 0.222396
 >> iter 92000, loss: 0.108714
 >> iter 93000, loss: 0.108747
 >> iter 94000, loss: 0.066923
 >> iter 95000, loss: 0.053587
 >> iter 96000, loss: 0.045023
 >> iter 97000, loss: 0.041211
 >> iter 98000, loss: 0.039063
 >> iter 99000, loss: 0.037961
 >> iter 100000, loss: 0.037064
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 18.4787680821
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.598464
 >> iter 2000, loss: 7.874289
 >> iter 3000, loss: 2.983578
 >> iter 4000, loss: 1.158382
 >> iter 5000, loss: 0.468139
 >> iter 6000, loss: 0.212841
 >> iter 7000, loss: 0.113666
 >> iter 8000, loss: 0.077475
 >> iter 9000, loss: 0.060728
 >> iter 10000, loss: 0.054882
   Number of active neurons: 4
 >> iter 11000, loss: 0.050919
 >> iter 12000, loss: 0.050193
 >> iter 13000, loss: 0.067538
 >> iter 14000, loss: 0.057153
 >> iter 15000, loss: 0.050280
 >> iter 16000, loss: 0.050830
 >> iter 17000, loss: 0.047176
 >> iter 18000, loss: 0.049614
 >> iter 19000, loss: 0.045682
 >> iter 20000, loss: 0.047757
   Number of active neurons: 4
 >> iter 21000, loss: 0.045101
 >> iter 22000, loss: 0.046958
 >> iter 23000, loss: 0.044540
 >> iter 24000, loss: 0.046194
 >> iter 25000, loss: 0.043942
 >> iter 26000, loss: 0.045175
 >> iter 27000, loss: 0.043302
 >> iter 28000, loss: 0.044165
 >> iter 29000, loss: 0.042679
 >> iter 30000, loss: 0.043509
   Number of active neurons: 4
 >> iter 31000, loss: 0.042207
 >> iter 32000, loss: 0.046463
 >> iter 33000, loss: 0.043537
 >> iter 34000, loss: 0.047677
 >> iter 35000, loss: 0.043985
 >> iter 36000, loss: 0.046529
 >> iter 37000, loss: 0.042709
 >> iter 38000, loss: 0.043307
 >> iter 39000, loss: 0.042138
 >> iter 40000, loss: 0.043452
   Number of active neurons: 4
 >> iter 41000, loss: 0.042242
 >> iter 42000, loss: 0.043394
 >> iter 43000, loss: 0.041623
 >> iter 44000, loss: 0.077317
 >> iter 45000, loss: 0.055023
 >> iter 46000, loss: 0.049550
 >> iter 47000, loss: 0.044464
 >> iter 48000, loss: 0.045366
 >> iter 49000, loss: 0.042008
 >> iter 50000, loss: 0.043522
   Number of active neurons: 4
 >> iter 51000, loss: 0.040990
 >> iter 52000, loss: 0.042364
 >> iter 53000, loss: 0.040263
 >> iter 54000, loss: 0.041298
 >> iter 55000, loss: 0.039512
 >> iter 56000, loss: 0.040700
 >> iter 57000, loss: 0.038757
 >> iter 58000, loss: 0.040074
 >> iter 59000, loss: 0.038298
 >> iter 60000, loss: 0.039778
   Number of active neurons: 4
 >> iter 61000, loss: 0.037808
 >> iter 62000, loss: 0.039452
 >> iter 63000, loss: 0.037605
 >> iter 64000, loss: 0.039535
 >> iter 65000, loss: 0.037430
 >> iter 66000, loss: 0.039983
 >> iter 67000, loss: 0.037299
 >> iter 68000, loss: 0.051060
 >> iter 69000, loss: 0.168071
 >> iter 70000, loss: 0.101382
   Number of active neurons: 4
 >> iter 71000, loss: 0.178600
 >> iter 72000, loss: 0.094688
 >> iter 73000, loss: 0.173619
 >> iter 74000, loss: 0.089054
 >> iter 75000, loss: 0.159383
 >> iter 76000, loss: 0.083953
 >> iter 77000, loss: 0.052540
 >> iter 78000, loss: 0.043961
 >> iter 79000, loss: 0.098006
 >> iter 80000, loss: 0.056304
   Number of active neurons: 4
 >> iter 81000, loss: 0.041939
 >> iter 82000, loss: 0.036084
 >> iter 83000, loss: 0.034328
 >> iter 84000, loss: 0.033384
 >> iter 85000, loss: 0.033329
 >> iter 86000, loss: 0.033103
 >> iter 87000, loss: 0.033196
 >> iter 88000, loss: 0.032997
 >> iter 89000, loss: 0.033176
 >> iter 90000, loss: 0.033054
   Number of active neurons: 4
 >> iter 91000, loss: 0.033249
 >> iter 92000, loss: 0.032980
 >> iter 93000, loss: 0.033006
 >> iter 94000, loss: 0.032677
 >> iter 95000, loss: 0.032702
 >> iter 96000, loss: 0.032303
 >> iter 97000, loss: 0.032348
 >> iter 98000, loss: 0.031983
 >> iter 99000, loss: 0.032082
 >> iter 100000, loss: 0.031745
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.916561
 >> iter 2000, loss: 9.394318
 >> iter 3000, loss: 3.653275
 >> iter 4000, loss: 1.416062
 >> iter 5000, loss: 0.624717
 >> iter 6000, loss: 0.279423
 >> iter 7000, loss: 0.227853
 >> iter 8000, loss: 0.128432
 >> iter 9000, loss: 0.168803
 >> iter 10000, loss: 0.103071
   Number of active neurons: 5
 >> iter 11000, loss: 0.130882
 >> iter 12000, loss: 0.087867
 >> iter 13000, loss: 0.127466
 >> iter 14000, loss: 0.109636
 >> iter 15000, loss: 0.117942
 >> iter 16000, loss: 0.083920
 >> iter 17000, loss: 0.256853
 >> iter 18000, loss: 0.133518
 >> iter 19000, loss: 0.286305
 >> iter 20000, loss: 0.148269
   Number of active neurons: 5
 >> iter 21000, loss: 0.194286
 >> iter 22000, loss: 0.133762
 >> iter 23000, loss: 0.156041
 >> iter 24000, loss: 0.110805
 >> iter 25000, loss: 0.137941
 >> iter 26000, loss: 0.092312
 >> iter 27000, loss: 0.163802
 >> iter 28000, loss: 0.119788
 >> iter 29000, loss: 0.117626
 >> iter 30000, loss: 0.080512
   Number of active neurons: 5
 >> iter 31000, loss: 0.162406
 >> iter 32000, loss: 0.095758
 >> iter 33000, loss: 0.122177
 >> iter 34000, loss: 0.103845
 >> iter 35000, loss: 0.165531
 >> iter 36000, loss: 0.091503
 >> iter 37000, loss: 0.387626
 >> iter 38000, loss: 0.176433
 >> iter 39000, loss: 0.171237
 >> iter 40000, loss: 0.093573
   Number of active neurons: 5
 >> iter 41000, loss: 0.065536
 >> iter 42000, loss: 0.054225
 >> iter 43000, loss: 0.371637
 >> iter 44000, loss: 0.166926
 >> iter 45000, loss: 0.094414
 >> iter 46000, loss: 0.068592
 >> iter 47000, loss: 0.054648
 >> iter 48000, loss: 0.049190
 >> iter 49000, loss: 0.052314
 >> iter 50000, loss: 0.044934
   Number of active neurons: 5
 >> iter 51000, loss: 0.106580
 >> iter 52000, loss: 0.064991
 >> iter 53000, loss: 0.126939
 >> iter 54000, loss: 0.133625
 >> iter 55000, loss: 0.142142
 >> iter 56000, loss: 0.147803
 >> iter 57000, loss: 0.083543
 >> iter 58000, loss: 0.072789
 >> iter 59000, loss: 0.056225
 >> iter 60000, loss: 0.066861
   Number of active neurons: 5
 >> iter 61000, loss: 0.126341
 >> iter 62000, loss: 0.087970
 >> iter 63000, loss: 0.055275
 >> iter 64000, loss: 0.053421
 >> iter 65000, loss: 0.048220
 >> iter 66000, loss: 0.054667
 >> iter 67000, loss: 0.041847
 >> iter 68000, loss: 0.062574
 >> iter 69000, loss: 0.049609
 >> iter 70000, loss: 0.064159
   Number of active neurons: 5
 >> iter 71000, loss: 0.048749
 >> iter 72000, loss: 0.041891
 >> iter 73000, loss: 0.042619
 >> iter 74000, loss: 0.062699
 >> iter 75000, loss: 0.176820
 >> iter 76000, loss: 0.087361
 >> iter 77000, loss: 0.052606
 >> iter 78000, loss: 0.054045
 >> iter 79000, loss: 0.040942
 >> iter 80000, loss: 0.062116
   Number of active neurons: 5
 >> iter 81000, loss: 0.044421
 >> iter 82000, loss: 0.079134
 >> iter 83000, loss: 0.058121
 >> iter 84000, loss: 0.043321
 >> iter 85000, loss: 0.239634
 >> iter 86000, loss: 0.147317
 >> iter 87000, loss: 0.078488
 >> iter 88000, loss: 0.053104
 >> iter 89000, loss: 0.041734
 >> iter 90000, loss: 0.079041
   Number of active neurons: 5
 >> iter 91000, loss: 0.051072
 >> iter 92000, loss: 0.062168
 >> iter 93000, loss: 0.163827
 >> iter 94000, loss: 0.110647
 >> iter 95000, loss: 0.186310
 >> iter 96000, loss: 0.119748
 >> iter 97000, loss: 0.169815
 >> iter 98000, loss: 0.128897
 >> iter 99000, loss: 0.074044
 >> iter 100000, loss: 0.076404
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.009999800004
   - Test - Long: 0.0
   - Test - Big: 0.0039999600004
   - Test - A: 0.0
   - Test - B: 17.5854943004
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.024582
 >> iter 2000, loss: 8.620223
 >> iter 3000, loss: 3.320856
 >> iter 4000, loss: 1.295322
 >> iter 5000, loss: 0.524391
 >> iter 6000, loss: 0.313837
 >> iter 7000, loss: 0.210597
 >> iter 8000, loss: 0.120708
 >> iter 9000, loss: 0.157711
 >> iter 10000, loss: 0.219340
   Number of active neurons: 4
 >> iter 11000, loss: 0.219146
 >> iter 12000, loss: 0.180209
 >> iter 13000, loss: 0.171121
 >> iter 14000, loss: 0.199826
 >> iter 15000, loss: 0.198640
 >> iter 16000, loss: 0.153194
 >> iter 17000, loss: 0.172699
 >> iter 18000, loss: 0.141577
 >> iter 19000, loss: 0.167691
 >> iter 20000, loss: 0.133249
   Number of active neurons: 4
 >> iter 21000, loss: 0.165526
 >> iter 22000, loss: 0.190112
 >> iter 23000, loss: 0.232681
 >> iter 24000, loss: 0.171311
 >> iter 25000, loss: 0.192410
 >> iter 26000, loss: 0.144259
 >> iter 27000, loss: 0.199368
 >> iter 28000, loss: 0.160899
 >> iter 29000, loss: 0.162971
 >> iter 30000, loss: 0.101923
   Number of active neurons: 4
 >> iter 31000, loss: 0.169706
 >> iter 32000, loss: 0.115038
 >> iter 33000, loss: 0.171568
 >> iter 34000, loss: 0.102654
 >> iter 35000, loss: 0.151685
 >> iter 36000, loss: 0.123521
 >> iter 37000, loss: 0.199349
 >> iter 38000, loss: 0.123083
 >> iter 39000, loss: 0.231368
 >> iter 40000, loss: 0.122944
   Number of active neurons: 4
 >> iter 41000, loss: 0.081276
 >> iter 42000, loss: 0.085313
 >> iter 43000, loss: 0.392111
 >> iter 44000, loss: 0.197525
 >> iter 45000, loss: 0.260451
 >> iter 46000, loss: 0.149579
 >> iter 47000, loss: 0.189607
 >> iter 48000, loss: 0.102813
 >> iter 49000, loss: 0.208722
 >> iter 50000, loss: 0.124012
   Number of active neurons: 4
 >> iter 51000, loss: 0.207583
 >> iter 52000, loss: 0.129757
 >> iter 53000, loss: 0.261370
 >> iter 54000, loss: 0.130784
 >> iter 55000, loss: 0.304396
 >> iter 56000, loss: 0.175920
 >> iter 57000, loss: 0.124319
 >> iter 58000, loss: 0.086662
 >> iter 59000, loss: 0.126989
 >> iter 60000, loss: 0.104644
   Number of active neurons: 4
 >> iter 61000, loss: 0.148360
 >> iter 62000, loss: 0.092591
 >> iter 63000, loss: 0.190270
 >> iter 64000, loss: 0.129045
 >> iter 65000, loss: 0.199229
 >> iter 66000, loss: 0.130776
 >> iter 67000, loss: 0.162736
 >> iter 68000, loss: 0.103470
 >> iter 69000, loss: 0.150086
 >> iter 70000, loss: 0.109888
   Number of active neurons: 4
 >> iter 71000, loss: 0.110188
 >> iter 72000, loss: 0.098480
 >> iter 73000, loss: 0.172290
 >> iter 74000, loss: 0.090493
 >> iter 75000, loss: 0.214904
 >> iter 76000, loss: 0.113604
 >> iter 77000, loss: 0.122266
 >> iter 78000, loss: 0.076916
 >> iter 79000, loss: 0.248720
 >> iter 80000, loss: 0.146872
   Number of active neurons: 4
 >> iter 81000, loss: 0.184152
 >> iter 82000, loss: 0.120417
 >> iter 83000, loss: 0.186054
 >> iter 84000, loss: 0.122571
 >> iter 85000, loss: 0.179705
 >> iter 86000, loss: 0.125639
 >> iter 87000, loss: 0.167426
 >> iter 88000, loss: 0.094806
 >> iter 89000, loss: 0.125028
 >> iter 90000, loss: 0.103219
   Number of active neurons: 4
 >> iter 91000, loss: 0.165553
 >> iter 92000, loss: 0.096099
 >> iter 93000, loss: 0.188753
 >> iter 94000, loss: 0.207127
 >> iter 95000, loss: 0.285716
 >> iter 96000, loss: 0.158506
 >> iter 97000, loss: 0.128063
 >> iter 98000, loss: 0.100884
 >> iter 99000, loss: 0.100260
 >> iter 100000, loss: 0.072247
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0179996400072
   - Test - Long: 0.0
   - Test - Big: 0.0129998700013
   - Test - A: 0.0
   - Test - B: 23.558429438
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.892186
 >> iter 2000, loss: 9.025147
 >> iter 3000, loss: 3.402009
 >> iter 4000, loss: 1.338663
 >> iter 5000, loss: 0.538414
 >> iter 6000, loss: 0.273273
 >> iter 7000, loss: 0.138911
 >> iter 8000, loss: 0.086481
 >> iter 9000, loss: 0.067109
 >> iter 10000, loss: 0.058222
   Number of active neurons: 5
 >> iter 11000, loss: 0.054206
 >> iter 12000, loss: 0.058100
 >> iter 13000, loss: 0.052065
 >> iter 14000, loss: 0.091369
 >> iter 15000, loss: 0.115197
 >> iter 16000, loss: 0.219029
 >> iter 17000, loss: 0.110273
 >> iter 18000, loss: 0.074277
 >> iter 19000, loss: 0.056144
 >> iter 20000, loss: 0.060811
   Number of active neurons: 5
 >> iter 21000, loss: 0.051279
 >> iter 22000, loss: 0.140764
 >> iter 23000, loss: 0.081105
 >> iter 24000, loss: 0.094073
 >> iter 25000, loss: 0.063593
 >> iter 26000, loss: 0.122048
 >> iter 27000, loss: 0.072966
 >> iter 28000, loss: 0.057894
 >> iter 29000, loss: 0.050316
 >> iter 30000, loss: 0.048112
   Number of active neurons: 5
 >> iter 31000, loss: 0.047636
 >> iter 32000, loss: 0.046955
 >> iter 33000, loss: 0.047581
 >> iter 34000, loss: 0.066621
 >> iter 35000, loss: 0.052094
 >> iter 36000, loss: 0.047940
 >> iter 37000, loss: 0.053685
 >> iter 38000, loss: 0.047831
 >> iter 39000, loss: 0.059047
 >> iter 40000, loss: 0.050136
   Number of active neurons: 5
 >> iter 41000, loss: 0.067481
 >> iter 42000, loss: 0.053087
 >> iter 43000, loss: 0.072339
 >> iter 44000, loss: 0.054866
 >> iter 45000, loss: 0.072460
 >> iter 46000, loss: 0.054844
 >> iter 47000, loss: 0.071634
 >> iter 48000, loss: 0.054471
 >> iter 49000, loss: 0.070109
 >> iter 50000, loss: 0.053650
   Number of active neurons: 5
 >> iter 51000, loss: 0.066302
 >> iter 52000, loss: 0.051776
 >> iter 53000, loss: 0.062721
 >> iter 54000, loss: 0.049923
 >> iter 55000, loss: 0.060975
 >> iter 56000, loss: 0.048879
 >> iter 57000, loss: 0.057824
 >> iter 58000, loss: 0.046935
 >> iter 59000, loss: 0.055884
 >> iter 60000, loss: 0.045802
   Number of active neurons: 5
 >> iter 61000, loss: 0.052900
 >> iter 62000, loss: 0.044270
 >> iter 63000, loss: 0.044235
 >> iter 64000, loss: 0.040760
 >> iter 65000, loss: 0.041912
 >> iter 66000, loss: 0.039893
 >> iter 67000, loss: 0.041616
 >> iter 68000, loss: 0.039750
 >> iter 69000, loss: 0.041666
 >> iter 70000, loss: 0.039459
   Number of active neurons: 4
 >> iter 71000, loss: 0.041983
 >> iter 72000, loss: 0.039055
 >> iter 73000, loss: 0.041473
 >> iter 74000, loss: 0.038648
 >> iter 75000, loss: 0.041162
 >> iter 76000, loss: 0.038470
 >> iter 77000, loss: 0.041411
 >> iter 78000, loss: 0.038479
 >> iter 79000, loss: 0.042669
 >> iter 80000, loss: 0.038324
   Number of active neurons: 4
 >> iter 81000, loss: 0.046274
 >> iter 82000, loss: 0.039101
 >> iter 83000, loss: 0.046585
 >> iter 84000, loss: 0.038979
 >> iter 85000, loss: 0.049196
 >> iter 86000, loss: 0.039846
 >> iter 87000, loss: 0.050686
 >> iter 88000, loss: 0.040322
 >> iter 89000, loss: 0.050657
 >> iter 90000, loss: 0.040228
   Number of active neurons: 4
 >> iter 91000, loss: 0.050285
 >> iter 92000, loss: 0.039884
 >> iter 93000, loss: 0.048251
 >> iter 94000, loss: 0.038896
 >> iter 95000, loss: 0.042249
 >> iter 96000, loss: 0.036921
 >> iter 97000, loss: 0.048492
 >> iter 98000, loss: 0.038723
 >> iter 99000, loss: 0.045431
 >> iter 100000, loss: 0.048947
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 12.4058396107
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.915482
 >> iter 2000, loss: 9.942756
 >> iter 3000, loss: 3.837265
 >> iter 4000, loss: 1.473533
 >> iter 5000, loss: 0.623564
 >> iter 6000, loss: 0.267566
 >> iter 7000, loss: 0.166560
 >> iter 8000, loss: 0.170273
 >> iter 9000, loss: 0.282246
 >> iter 10000, loss: 0.139998
   Number of active neurons: 5
 >> iter 11000, loss: 0.084782
 >> iter 12000, loss: 0.076928
 >> iter 13000, loss: 0.062440
 >> iter 14000, loss: 0.117540
 >> iter 15000, loss: 0.086376
 >> iter 16000, loss: 0.116004
 >> iter 17000, loss: 0.082060
 >> iter 18000, loss: 0.108261
 >> iter 19000, loss: 0.090456
 >> iter 20000, loss: 0.125358
   Number of active neurons: 4
 >> iter 21000, loss: 0.163624
 >> iter 22000, loss: 0.100564
 >> iter 23000, loss: 0.141322
 >> iter 24000, loss: 0.086090
 >> iter 25000, loss: 0.162986
 >> iter 26000, loss: 0.137332
 >> iter 27000, loss: 0.096435
 >> iter 28000, loss: 0.119561
 >> iter 29000, loss: 0.114630
 >> iter 30000, loss: 0.088179
   Number of active neurons: 4
 >> iter 31000, loss: 0.127877
 >> iter 32000, loss: 0.098082
 >> iter 33000, loss: 0.119489
 >> iter 34000, loss: 0.177654
 >> iter 35000, loss: 0.135607
 >> iter 36000, loss: 0.099436
 >> iter 37000, loss: 0.073220
 >> iter 38000, loss: 0.076692
 >> iter 39000, loss: 0.114295
 >> iter 40000, loss: 0.131523
   Number of active neurons: 4
 >> iter 41000, loss: 0.239846
 >> iter 42000, loss: 0.115609
 >> iter 43000, loss: 0.202414
 >> iter 44000, loss: 0.103102
 >> iter 45000, loss: 0.195433
 >> iter 46000, loss: 0.110875
 >> iter 47000, loss: 0.204585
 >> iter 48000, loss: 0.104712
 >> iter 49000, loss: 0.152959
 >> iter 50000, loss: 0.171749
   Number of active neurons: 4
 >> iter 51000, loss: 0.118176
 >> iter 52000, loss: 0.145681
 >> iter 53000, loss: 0.179490
 >> iter 54000, loss: 0.094199
 >> iter 55000, loss: 0.122782
 >> iter 56000, loss: 0.081576
 >> iter 57000, loss: 0.060449
 >> iter 58000, loss: 0.048734
 >> iter 59000, loss: 0.206562
 >> iter 60000, loss: 0.158297
   Number of active neurons: 4
 >> iter 61000, loss: 0.211621
 >> iter 62000, loss: 0.239032
 >> iter 63000, loss: 0.162072
 >> iter 64000, loss: 0.188984
 >> iter 65000, loss: 0.226143
 >> iter 66000, loss: 0.180900
 >> iter 67000, loss: 0.132591
 >> iter 68000, loss: 0.087009
 >> iter 69000, loss: 0.191508
 >> iter 70000, loss: 0.097953
   Number of active neurons: 4
 >> iter 71000, loss: 0.226531
 >> iter 72000, loss: 0.142818
 >> iter 73000, loss: 0.107384
 >> iter 74000, loss: 0.087451
 >> iter 75000, loss: 0.125856
 >> iter 76000, loss: 0.100759
 >> iter 77000, loss: 0.087473
 >> iter 78000, loss: 0.138423
 >> iter 79000, loss: 0.170630
 >> iter 80000, loss: 0.097853
   Number of active neurons: 4
 >> iter 81000, loss: 0.100785
 >> iter 82000, loss: 0.081617
 >> iter 83000, loss: 0.223127
 >> iter 84000, loss: 0.127441
 >> iter 85000, loss: 0.217803
 >> iter 86000, loss: 0.123028
 >> iter 87000, loss: 0.168628
 >> iter 88000, loss: 0.091600
 >> iter 89000, loss: 0.182871
 >> iter 90000, loss: 0.097589
   Number of active neurons: 4
 >> iter 91000, loss: 0.174447
 >> iter 92000, loss: 0.098769
 >> iter 93000, loss: 0.143565
 >> iter 94000, loss: 0.109916
 >> iter 95000, loss: 0.136904
 >> iter 96000, loss: 0.100129
 >> iter 97000, loss: 0.129547
 >> iter 98000, loss: 0.112008
 >> iter 99000, loss: 0.167383
 >> iter 100000, loss: 0.176482
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0239995200096
   - Test - Long: 0.0649967501625
   - Test - Big: 0.0209997900021
   - Test - A: 0.0
   - Test - B: 22.8851409906
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.130805
 >> iter 2000, loss: 15.365665
 >> iter 3000, loss: 14.302443
 >> iter 4000, loss: 12.557945
 >> iter 5000, loss: 10.193054
 >> iter 6000, loss: 8.548141
 >> iter 7000, loss: 8.104479
 >> iter 8000, loss: 6.452293
 >> iter 9000, loss: 3.437269
 >> iter 10000, loss: 1.407254
   Number of active neurons: 6
 >> iter 11000, loss: 0.583913
 >> iter 12000, loss: 0.312415
 >> iter 13000, loss: 0.164730
 >> iter 14000, loss: 0.120953
 >> iter 15000, loss: 0.108003
 >> iter 16000, loss: 0.127698
 >> iter 17000, loss: 0.088032
 >> iter 18000, loss: 0.110658
 >> iter 19000, loss: 0.082123
 >> iter 20000, loss: 0.119555
   Number of active neurons: 6
 >> iter 21000, loss: 0.079829
 >> iter 22000, loss: 0.131389
 >> iter 23000, loss: 0.335853
 >> iter 24000, loss: 0.249285
 >> iter 25000, loss: 0.134260
 >> iter 26000, loss: 0.110907
 >> iter 27000, loss: 0.214072
 >> iter 28000, loss: 0.274580
 >> iter 29000, loss: 0.138986
 >> iter 30000, loss: 0.113618
   Number of active neurons: 5
 >> iter 31000, loss: 0.135932
 >> iter 32000, loss: 0.086927
 >> iter 33000, loss: 0.062166
 >> iter 34000, loss: 0.068194
 >> iter 35000, loss: 0.074086
 >> iter 36000, loss: 0.089974
 >> iter 37000, loss: 0.077953
 >> iter 38000, loss: 0.091727
 >> iter 39000, loss: 0.077526
 >> iter 40000, loss: 0.088881
   Number of active neurons: 5
 >> iter 41000, loss: 0.076685
 >> iter 42000, loss: 0.149688
 >> iter 43000, loss: 0.089015
 >> iter 44000, loss: 0.106567
 >> iter 45000, loss: 0.177038
 >> iter 46000, loss: 0.248764
 >> iter 47000, loss: 0.137554
 >> iter 48000, loss: 0.089521
 >> iter 49000, loss: 0.234212
 >> iter 50000, loss: 0.126280
   Number of active neurons: 5
 >> iter 51000, loss: 0.355165
 >> iter 52000, loss: 0.223633
 >> iter 53000, loss: 0.172046
 >> iter 54000, loss: 0.213629
 >> iter 55000, loss: 0.200130
 >> iter 56000, loss: 0.153957
 >> iter 57000, loss: 0.153138
 >> iter 58000, loss: 0.099921
 >> iter 59000, loss: 0.155977
 >> iter 60000, loss: 0.223864
   Number of active neurons: 5
 >> iter 61000, loss: 0.301948
 >> iter 62000, loss: 0.149303
 >> iter 63000, loss: 0.398612
 >> iter 64000, loss: 0.187126
 >> iter 65000, loss: 0.327097
 >> iter 66000, loss: 0.162003
 >> iter 67000, loss: 0.116492
 >> iter 68000, loss: 0.081579
 >> iter 69000, loss: 0.144967
 >> iter 70000, loss: 0.125839
   Number of active neurons: 5
 >> iter 71000, loss: 0.095874
 >> iter 72000, loss: 0.071026
 >> iter 73000, loss: 0.082452
 >> iter 74000, loss: 0.301940
 >> iter 75000, loss: 0.144030
 >> iter 76000, loss: 0.143955
 >> iter 77000, loss: 0.086563
 >> iter 78000, loss: 0.276159
 >> iter 79000, loss: 0.132047
 >> iter 80000, loss: 0.241625
   Number of active neurons: 5
 >> iter 81000, loss: 0.268489
 >> iter 82000, loss: 0.134938
 >> iter 83000, loss: 0.203273
 >> iter 84000, loss: 0.355145
 >> iter 85000, loss: 0.166820
 >> iter 86000, loss: 0.195283
 >> iter 87000, loss: 0.260944
 >> iter 88000, loss: 0.211551
 >> iter 89000, loss: 0.140069
 >> iter 90000, loss: 0.277433
   Number of active neurons: 5
 >> iter 91000, loss: 0.133814
 >> iter 92000, loss: 0.080478
 >> iter 93000, loss: 0.093169
 >> iter 94000, loss: 0.153673
 >> iter 95000, loss: 0.164794
 >> iter 96000, loss: 0.121172
 >> iter 97000, loss: 0.134835
 >> iter 98000, loss: 0.115608
 >> iter 99000, loss: 0.145454
 >> iter 100000, loss: 0.128438
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0119997600048
   - Test - Long: 0.0
   - Test - Big: 0.00999990000101
   - Test - A: 0.0
   - Test - B: 22.8184787681
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.737111
 >> iter 2000, loss: 7.737895
 >> iter 3000, loss: 3.057594
 >> iter 4000, loss: 1.211771
 >> iter 5000, loss: 0.649647
 >> iter 6000, loss: 0.287807
 >> iter 7000, loss: 0.296836
 >> iter 8000, loss: 0.177427
 >> iter 9000, loss: 0.226826
 >> iter 10000, loss: 0.123686
   Number of active neurons: 7
 >> iter 11000, loss: 0.179063
 >> iter 12000, loss: 0.105838
 >> iter 13000, loss: 0.190908
 >> iter 14000, loss: 0.107618
 >> iter 15000, loss: 0.281377
 >> iter 16000, loss: 0.179102
 >> iter 17000, loss: 0.183627
 >> iter 18000, loss: 0.110087
 >> iter 19000, loss: 0.229601
 >> iter 20000, loss: 0.127736
   Number of active neurons: 7
 >> iter 21000, loss: 0.193012
 >> iter 22000, loss: 0.177095
 >> iter 23000, loss: 0.412167
 >> iter 24000, loss: 0.199819
 >> iter 25000, loss: 0.196040
 >> iter 26000, loss: 0.152983
 >> iter 27000, loss: 0.289166
 >> iter 28000, loss: 0.144326
 >> iter 29000, loss: 0.233606
 >> iter 30000, loss: 0.121767
   Number of active neurons: 7
 >> iter 31000, loss: 0.185828
 >> iter 32000, loss: 0.102331
 >> iter 33000, loss: 0.168867
 >> iter 34000, loss: 0.096175
 >> iter 35000, loss: 0.270585
 >> iter 36000, loss: 0.131838
 >> iter 37000, loss: 0.340005
 >> iter 38000, loss: 0.160078
 >> iter 39000, loss: 0.363413
 >> iter 40000, loss: 0.181598
   Number of active neurons: 6
 >> iter 41000, loss: 0.228413
 >> iter 42000, loss: 0.135621
 >> iter 43000, loss: 0.258059
 >> iter 44000, loss: 0.139672
 >> iter 45000, loss: 0.239046
 >> iter 46000, loss: 0.146809
 >> iter 47000, loss: 0.178955
 >> iter 48000, loss: 0.108896
 >> iter 49000, loss: 0.140360
 >> iter 50000, loss: 0.141320
   Number of active neurons: 6
 >> iter 51000, loss: 0.153696
 >> iter 52000, loss: 0.148486
 >> iter 53000, loss: 0.166810
 >> iter 54000, loss: 0.131847
 >> iter 55000, loss: 0.271720
 >> iter 56000, loss: 0.161397
 >> iter 57000, loss: 0.221441
 >> iter 58000, loss: 0.124189
 >> iter 59000, loss: 0.235093
 >> iter 60000, loss: 0.232621
   Number of active neurons: 6
 >> iter 61000, loss: 0.275229
 >> iter 62000, loss: 0.201470
 >> iter 63000, loss: 0.219942
 >> iter 64000, loss: 0.168841
 >> iter 65000, loss: 0.169869
 >> iter 66000, loss: 0.103947
 >> iter 67000, loss: 0.217237
 >> iter 68000, loss: 0.121870
 >> iter 69000, loss: 0.144491
 >> iter 70000, loss: 0.230310
   Number of active neurons: 6
 >> iter 71000, loss: 0.191262
 >> iter 72000, loss: 0.107174
 >> iter 73000, loss: 0.137781
 >> iter 74000, loss: 0.083130
 >> iter 75000, loss: 0.130722
 >> iter 76000, loss: 0.078898
 >> iter 77000, loss: 0.060523
 >> iter 78000, loss: 0.050800
 >> iter 79000, loss: 0.047639
 >> iter 80000, loss: 0.045340
   Number of active neurons: 6
 >> iter 81000, loss: 0.044867
 >> iter 82000, loss: 0.043621
 >> iter 83000, loss: 0.046511
 >> iter 84000, loss: 0.043203
 >> iter 85000, loss: 0.043005
 >> iter 86000, loss: 0.043050
 >> iter 87000, loss: 0.042857
 >> iter 88000, loss: 0.043458
 >> iter 89000, loss: 0.042798
 >> iter 90000, loss: 0.043347
   Number of active neurons: 6
 >> iter 91000, loss: 0.042586
 >> iter 92000, loss: 0.043113
 >> iter 93000, loss: 0.042368
 >> iter 94000, loss: 0.042846
 >> iter 95000, loss: 0.042044
 >> iter 96000, loss: 0.042467
 >> iter 97000, loss: 0.041618
 >> iter 98000, loss: 0.041940
 >> iter 99000, loss: 0.041203
 >> iter 100000, loss: 0.041610
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0029999700003
   - Test - A: 0.0
   - Test - B: 22.1985200987
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.105917
 >> iter 2000, loss: 8.577503
 >> iter 3000, loss: 3.219538
 >> iter 4000, loss: 1.228601
 >> iter 5000, loss: 0.485894
 >> iter 6000, loss: 0.208685
 >> iter 7000, loss: 0.107787
 >> iter 8000, loss: 0.068557
 >> iter 9000, loss: 0.058042
 >> iter 10000, loss: 0.051844
   Number of active neurons: 6
 >> iter 11000, loss: 0.054152
 >> iter 12000, loss: 0.058650
 >> iter 13000, loss: 0.057035
 >> iter 14000, loss: 0.062851
 >> iter 15000, loss: 0.058298
 >> iter 16000, loss: 0.052129
 >> iter 17000, loss: 0.053885
 >> iter 18000, loss: 0.047531
 >> iter 19000, loss: 0.050861
 >> iter 20000, loss: 0.045929
   Number of active neurons: 6
 >> iter 21000, loss: 0.050285
 >> iter 22000, loss: 0.046598
 >> iter 23000, loss: 0.052436
 >> iter 24000, loss: 0.046904
 >> iter 25000, loss: 0.063413
 >> iter 26000, loss: 0.050414
 >> iter 27000, loss: 0.119646
 >> iter 28000, loss: 0.070870
 >> iter 29000, loss: 0.264761
 >> iter 30000, loss: 0.126455
   Number of active neurons: 5
 >> iter 31000, loss: 0.094657
 >> iter 32000, loss: 0.062210
 >> iter 33000, loss: 0.072117
 >> iter 34000, loss: 0.054344
 >> iter 35000, loss: 0.271214
 >> iter 36000, loss: 0.128073
 >> iter 37000, loss: 0.286022
 >> iter 38000, loss: 0.136301
 >> iter 39000, loss: 0.342998
 >> iter 40000, loss: 0.156939
   Number of active neurons: 5
 >> iter 41000, loss: 0.088736
 >> iter 42000, loss: 0.059807
 >> iter 43000, loss: 0.253285
 >> iter 44000, loss: 0.123624
 >> iter 45000, loss: 0.081037
 >> iter 46000, loss: 0.057700
 >> iter 47000, loss: 0.069752
 >> iter 48000, loss: 0.051420
 >> iter 49000, loss: 0.293071
 >> iter 50000, loss: 0.136657
   Number of active neurons: 5
 >> iter 51000, loss: 0.084151
 >> iter 52000, loss: 0.058111
 >> iter 53000, loss: 0.175331
 >> iter 54000, loss: 0.166197
 >> iter 55000, loss: 0.100977
 >> iter 56000, loss: 0.071420
 >> iter 57000, loss: 0.348149
 >> iter 58000, loss: 0.209412
 >> iter 59000, loss: 0.106788
 >> iter 60000, loss: 0.068228
   Number of active neurons: 5
 >> iter 61000, loss: 0.056812
 >> iter 62000, loss: 0.049478
 >> iter 63000, loss: 0.053595
 >> iter 64000, loss: 0.046852
 >> iter 65000, loss: 0.235281
 >> iter 66000, loss: 0.117959
 >> iter 67000, loss: 0.285798
 >> iter 68000, loss: 0.136684
 >> iter 69000, loss: 0.221305
 >> iter 70000, loss: 0.111309
   Number of active neurons: 5
 >> iter 71000, loss: 0.244052
 >> iter 72000, loss: 0.120314
 >> iter 73000, loss: 0.081548
 >> iter 74000, loss: 0.058697
 >> iter 75000, loss: 0.056870
 >> iter 76000, loss: 0.127087
 >> iter 77000, loss: 0.211173
 >> iter 78000, loss: 0.111355
 >> iter 79000, loss: 0.206700
 >> iter 80000, loss: 0.108372
   Number of active neurons: 5
 >> iter 81000, loss: 0.070445
 >> iter 82000, loss: 0.056350
 >> iter 83000, loss: 0.054410
 >> iter 84000, loss: 0.048516
 >> iter 85000, loss: 0.050430
 >> iter 86000, loss: 0.112915
 >> iter 87000, loss: 0.212359
 >> iter 88000, loss: 0.143142
 >> iter 89000, loss: 0.179722
 >> iter 90000, loss: 0.098228
   Number of active neurons: 5
 >> iter 91000, loss: 0.228370
 >> iter 92000, loss: 0.118890
 >> iter 93000, loss: 0.111643
 >> iter 94000, loss: 0.073364
 >> iter 95000, loss: 0.056806
 >> iter 96000, loss: 0.054381
 >> iter 97000, loss: 0.113079
 >> iter 98000, loss: 0.075210
 >> iter 99000, loss: 0.190354
 >> iter 100000, loss: 0.103345
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0019999600008
   - Test - Long: 0.0549972501375
   - Test - Big: 0.0069999300007
   - Test - A: 0.0
   - Test - B: 22.2051863209
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.865752
 >> iter 2000, loss: 7.824637
 >> iter 3000, loss: 3.027265
 >> iter 4000, loss: 1.173775
 >> iter 5000, loss: 0.532073
 >> iter 6000, loss: 0.235987
 >> iter 7000, loss: 0.134241
 >> iter 8000, loss: 0.086482
 >> iter 9000, loss: 0.069520
 >> iter 10000, loss: 0.058530
   Number of active neurons: 7
 >> iter 11000, loss: 0.112562
 >> iter 12000, loss: 0.081455
 >> iter 13000, loss: 0.076978
 >> iter 14000, loss: 0.087601
 >> iter 15000, loss: 0.092557
 >> iter 16000, loss: 0.064048
 >> iter 17000, loss: 0.083713
 >> iter 18000, loss: 0.057870
 >> iter 19000, loss: 0.051346
 >> iter 20000, loss: 0.045333
   Number of active neurons: 5
 >> iter 21000, loss: 0.044307
 >> iter 22000, loss: 0.043087
 >> iter 23000, loss: 0.043502
 >> iter 24000, loss: 0.042453
 >> iter 25000, loss: 0.042715
 >> iter 26000, loss: 0.041708
 >> iter 27000, loss: 0.042015
 >> iter 28000, loss: 0.041224
 >> iter 29000, loss: 0.041609
 >> iter 30000, loss: 0.040877
   Number of active neurons: 5
 >> iter 31000, loss: 0.041269
 >> iter 32000, loss: 0.040500
 >> iter 33000, loss: 0.040832
 >> iter 34000, loss: 0.040167
 >> iter 35000, loss: 0.040468
 >> iter 36000, loss: 0.039858
 >> iter 37000, loss: 0.040179
 >> iter 38000, loss: 0.039567
 >> iter 39000, loss: 0.039911
 >> iter 40000, loss: 0.039332
   Number of active neurons: 5
 >> iter 41000, loss: 0.039669
 >> iter 42000, loss: 0.039113
 >> iter 43000, loss: 0.039458
 >> iter 44000, loss: 0.038924
 >> iter 45000, loss: 0.039262
 >> iter 46000, loss: 0.038680
 >> iter 47000, loss: 0.038919
 >> iter 48000, loss: 0.038402
 >> iter 49000, loss: 0.038666
 >> iter 50000, loss: 0.038233
   Number of active neurons: 5
 >> iter 51000, loss: 0.038498
 >> iter 52000, loss: 0.038146
 >> iter 53000, loss: 0.038369
 >> iter 54000, loss: 0.038040
 >> iter 55000, loss: 0.038280
 >> iter 56000, loss: 0.037973
 >> iter 57000, loss: 0.038223
 >> iter 58000, loss: 0.037906
 >> iter 59000, loss: 0.038147
 >> iter 60000, loss: 0.037872
   Number of active neurons: 5
 >> iter 61000, loss: 0.038147
 >> iter 62000, loss: 0.037859
 >> iter 63000, loss: 0.038165
 >> iter 64000, loss: 0.037898
 >> iter 65000, loss: 0.038158
 >> iter 66000, loss: 0.037925
 >> iter 67000, loss: 0.038193
 >> iter 68000, loss: 0.038017
 >> iter 69000, loss: 0.038244
 >> iter 70000, loss: 0.037993
   Number of active neurons: 5
 >> iter 71000, loss: 0.038183
 >> iter 72000, loss: 0.037974
 >> iter 73000, loss: 0.038244
 >> iter 74000, loss: 0.038073
 >> iter 75000, loss: 0.038369
 >> iter 76000, loss: 0.038235
 >> iter 77000, loss: 0.038375
 >> iter 78000, loss: 0.038174
 >> iter 79000, loss: 0.038327
 >> iter 80000, loss: 0.038161
   Number of active neurons: 5
 >> iter 81000, loss: 0.038321
 >> iter 82000, loss: 0.038207
 >> iter 83000, loss: 0.038359
 >> iter 84000, loss: 0.038212
 >> iter 85000, loss: 0.038286
 >> iter 86000, loss: 0.037918
 >> iter 87000, loss: 0.037751
 >> iter 88000, loss: 0.037296
 >> iter 89000, loss: 0.037217
 >> iter 90000, loss: 0.036810
   Number of active neurons: 5
 >> iter 91000, loss: 0.036591
 >> iter 92000, loss: 0.036085
 >> iter 93000, loss: 0.035904
 >> iter 94000, loss: 0.035438
 >> iter 95000, loss: 0.035353
 >> iter 96000, loss: 0.034897
 >> iter 97000, loss: 0.034869
 >> iter 98000, loss: 0.034446
 >> iter 99000, loss: 0.034468
 >> iter 100000, loss: 0.034082
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.750507
 >> iter 2000, loss: 8.034993
 >> iter 3000, loss: 3.030029
 >> iter 4000, loss: 1.162702
 >> iter 5000, loss: 0.467732
 >> iter 6000, loss: 0.207852
 >> iter 7000, loss: 0.110159
 >> iter 8000, loss: 0.072264
 >> iter 9000, loss: 0.057496
 >> iter 10000, loss: 0.050678
   Number of active neurons: 5
 >> iter 11000, loss: 0.047854
 >> iter 12000, loss: 0.045796
 >> iter 13000, loss: 0.045009
 >> iter 14000, loss: 0.043868
 >> iter 15000, loss: 0.043565
 >> iter 16000, loss: 0.042739
 >> iter 17000, loss: 0.042679
 >> iter 18000, loss: 0.042001
 >> iter 19000, loss: 0.042049
 >> iter 20000, loss: 0.041442
   Number of active neurons: 5
 >> iter 21000, loss: 0.041585
 >> iter 22000, loss: 0.041026
 >> iter 23000, loss: 0.041177
 >> iter 24000, loss: 0.040594
 >> iter 25000, loss: 0.040704
 >> iter 26000, loss: 0.040133
 >> iter 27000, loss: 0.040301
 >> iter 28000, loss: 0.039807
 >> iter 29000, loss: 0.040041
 >> iter 30000, loss: 0.039595
   Number of active neurons: 5
 >> iter 31000, loss: 0.039906
 >> iter 32000, loss: 0.039405
 >> iter 33000, loss: 0.039618
 >> iter 34000, loss: 0.039193
 >> iter 35000, loss: 0.039392
 >> iter 36000, loss: 0.039110
 >> iter 37000, loss: 0.039330
 >> iter 38000, loss: 0.039021
 >> iter 39000, loss: 0.039295
 >> iter 40000, loss: 0.039090
   Number of active neurons: 5
 >> iter 41000, loss: 0.039334
 >> iter 42000, loss: 0.039309
 >> iter 43000, loss: 0.039315
 >> iter 44000, loss: 0.040010
 >> iter 45000, loss: 0.039287
 >> iter 46000, loss: 0.040482
 >> iter 47000, loss: 0.039238
 >> iter 48000, loss: 0.040287
 >> iter 49000, loss: 0.039101
 >> iter 50000, loss: 0.039124
   Number of active neurons: 5
 >> iter 51000, loss: 0.038704
 >> iter 52000, loss: 0.038959
 >> iter 53000, loss: 0.040701
 >> iter 54000, loss: 0.039108
 >> iter 55000, loss: 0.039079
 >> iter 56000, loss: 0.039326
 >> iter 57000, loss: 0.039309
 >> iter 58000, loss: 0.039290
 >> iter 59000, loss: 0.045227
 >> iter 60000, loss: 0.042129
   Number of active neurons: 5
 >> iter 61000, loss: 0.046756
 >> iter 62000, loss: 0.041920
 >> iter 63000, loss: 0.072796
 >> iter 64000, loss: 0.049495
 >> iter 65000, loss: 0.052828
 >> iter 66000, loss: 0.042442
 >> iter 67000, loss: 0.078989
 >> iter 68000, loss: 0.051788
 >> iter 69000, loss: 0.078762
 >> iter 70000, loss: 0.051400
   Number of active neurons: 5
 >> iter 71000, loss: 0.061549
 >> iter 72000, loss: 0.044403
 >> iter 73000, loss: 0.038719
 >> iter 74000, loss: 0.036181
 >> iter 75000, loss: 0.073416
 >> iter 76000, loss: 0.048566
 >> iter 77000, loss: 0.067544
 >> iter 78000, loss: 0.046083
 >> iter 79000, loss: 0.038573
 >> iter 80000, loss: 0.035748
   Number of active neurons: 5
 >> iter 81000, loss: 0.071753
 >> iter 82000, loss: 0.047771
 >> iter 83000, loss: 0.063230
 >> iter 84000, loss: 0.044188
 >> iter 85000, loss: 0.037600
 >> iter 86000, loss: 0.034985
 >> iter 87000, loss: 0.066731
 >> iter 88000, loss: 0.045728
 >> iter 89000, loss: 0.054028
 >> iter 90000, loss: 0.040512
   Number of active neurons: 4
 >> iter 91000, loss: 0.035919
 >> iter 92000, loss: 0.034260
 >> iter 93000, loss: 0.070834
 >> iter 94000, loss: 0.046874
 >> iter 95000, loss: 0.059151
 >> iter 96000, loss: 0.041753
 >> iter 97000, loss: 0.036727
 >> iter 98000, loss: 0.034106
 >> iter 99000, loss: 0.071077
 >> iter 100000, loss: 0.046701
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.023101
 >> iter 2000, loss: 9.709868
 >> iter 3000, loss: 3.689441
 >> iter 4000, loss: 1.408091
 >> iter 5000, loss: 0.582382
 >> iter 6000, loss: 0.254769
 >> iter 7000, loss: 0.139864
 >> iter 8000, loss: 0.193846
 >> iter 9000, loss: 0.116264
 >> iter 10000, loss: 0.095633
   Number of active neurons: 6
 >> iter 11000, loss: 0.096651
 >> iter 12000, loss: 0.096819
 >> iter 13000, loss: 0.081388
 >> iter 14000, loss: 0.156784
 >> iter 15000, loss: 0.102186
 >> iter 16000, loss: 0.066584
 >> iter 17000, loss: 0.076563
 >> iter 18000, loss: 0.092060
 >> iter 19000, loss: 0.079290
 >> iter 20000, loss: 0.057374
   Number of active neurons: 6
 >> iter 21000, loss: 0.106656
 >> iter 22000, loss: 0.067092
 >> iter 23000, loss: 0.183008
 >> iter 24000, loss: 0.096859
 >> iter 25000, loss: 0.065157
 >> iter 26000, loss: 0.053429
 >> iter 27000, loss: 0.430172
 >> iter 28000, loss: 0.190790
 >> iter 29000, loss: 0.329374
 >> iter 30000, loss: 0.158692
   Number of active neurons: 6
 >> iter 31000, loss: 0.183269
 >> iter 32000, loss: 0.100506
 >> iter 33000, loss: 0.233424
 >> iter 34000, loss: 0.128083
 >> iter 35000, loss: 0.246884
 >> iter 36000, loss: 0.132950
 >> iter 37000, loss: 0.089652
 >> iter 38000, loss: 0.092661
 >> iter 39000, loss: 0.083059
 >> iter 40000, loss: 0.091264
   Number of active neurons: 5
 >> iter 41000, loss: 0.273612
 >> iter 42000, loss: 0.174273
 >> iter 43000, loss: 0.131788
 >> iter 44000, loss: 0.089645
 >> iter 45000, loss: 0.155903
 >> iter 46000, loss: 0.124796
 >> iter 47000, loss: 0.198349
 >> iter 48000, loss: 0.108380
 >> iter 49000, loss: 0.368622
 >> iter 50000, loss: 0.175119
   Number of active neurons: 5
 >> iter 51000, loss: 0.123347
 >> iter 52000, loss: 0.098493
 >> iter 53000, loss: 0.171282
 >> iter 54000, loss: 0.125659
 >> iter 55000, loss: 0.189584
 >> iter 56000, loss: 0.182494
 >> iter 57000, loss: 0.220570
 >> iter 58000, loss: 0.126722
 >> iter 59000, loss: 0.215668
 >> iter 60000, loss: 0.156533
   Number of active neurons: 4
 >> iter 61000, loss: 0.144252
 >> iter 62000, loss: 0.272739
 >> iter 63000, loss: 0.241929
 >> iter 64000, loss: 0.164134
 >> iter 65000, loss: 0.251882
 >> iter 66000, loss: 0.192792
 >> iter 67000, loss: 0.296920
 >> iter 68000, loss: 0.191060
 >> iter 69000, loss: 0.458225
 >> iter 70000, loss: 0.222585
   Number of active neurons: 4
 >> iter 71000, loss: 0.492551
 >> iter 72000, loss: 0.251645
 >> iter 73000, loss: 0.243896
 >> iter 74000, loss: 0.151482
 >> iter 75000, loss: 0.154915
 >> iter 76000, loss: 0.097549
 >> iter 77000, loss: 0.105329
 >> iter 78000, loss: 0.111172
 >> iter 79000, loss: 0.155063
 >> iter 80000, loss: 0.110010
   Number of active neurons: 4
 >> iter 81000, loss: 0.206602
 >> iter 82000, loss: 0.127974
 >> iter 83000, loss: 0.079292
 >> iter 84000, loss: 0.121082
 >> iter 85000, loss: 0.580117
 >> iter 86000, loss: 0.270234
 >> iter 87000, loss: 0.127040
 >> iter 88000, loss: 0.102591
 >> iter 89000, loss: 0.081709
 >> iter 90000, loss: 0.089575
   Number of active neurons: 4
 >> iter 91000, loss: 0.119553
 >> iter 92000, loss: 0.108019
 >> iter 93000, loss: 0.303169
 >> iter 94000, loss: 0.169644
 >> iter 95000, loss: 0.091528
 >> iter 96000, loss: 0.129569
 >> iter 97000, loss: 0.199014
 >> iter 98000, loss: 0.124258
 >> iter 99000, loss: 0.074645
 >> iter 100000, loss: 0.099385
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0839983200336
   - Test - Long: 0.394980250987
   - Test - Big: 0.0709992900071
   - Test - A: 6.69288714086
   - Test - B: 23.585094327
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.877437
 >> iter 2000, loss: 8.202181
 >> iter 3000, loss: 3.220492
 >> iter 4000, loss: 1.342339
 >> iter 5000, loss: 0.673845
 >> iter 6000, loss: 0.305377
 >> iter 7000, loss: 0.162319
 >> iter 8000, loss: 0.115589
 >> iter 9000, loss: 0.082037
 >> iter 10000, loss: 0.143396
   Number of active neurons: 5
 >> iter 11000, loss: 0.086522
 >> iter 12000, loss: 0.115520
 >> iter 13000, loss: 0.074640
 >> iter 14000, loss: 0.083244
 >> iter 15000, loss: 0.090152
 >> iter 16000, loss: 0.073153
 >> iter 17000, loss: 0.134871
 >> iter 18000, loss: 0.091904
 >> iter 19000, loss: 0.245410
 >> iter 20000, loss: 0.191493
   Number of active neurons: 5
 >> iter 21000, loss: 0.244138
 >> iter 22000, loss: 0.172839
 >> iter 23000, loss: 0.162307
 >> iter 24000, loss: 0.161883
 >> iter 25000, loss: 0.248416
 >> iter 26000, loss: 0.125629
 >> iter 27000, loss: 0.140277
 >> iter 28000, loss: 0.165143
 >> iter 29000, loss: 0.169624
 >> iter 30000, loss: 0.183442
   Number of active neurons: 5
 >> iter 31000, loss: 0.162159
 >> iter 32000, loss: 0.185485
 >> iter 33000, loss: 0.184942
 >> iter 34000, loss: 0.263472
 >> iter 35000, loss: 0.294513
 >> iter 36000, loss: 0.179960
 >> iter 37000, loss: 0.148468
 >> iter 38000, loss: 0.183755
 >> iter 39000, loss: 0.178761
 >> iter 40000, loss: 0.114643
   Number of active neurons: 5
 >> iter 41000, loss: 0.184916
 >> iter 42000, loss: 0.098652
 >> iter 43000, loss: 0.159837
 >> iter 44000, loss: 0.170286
 >> iter 45000, loss: 0.134975
 >> iter 46000, loss: 0.166283
 >> iter 47000, loss: 0.089692
 >> iter 48000, loss: 0.069626
 >> iter 49000, loss: 0.219668
 >> iter 50000, loss: 0.109845
   Number of active neurons: 5
 >> iter 51000, loss: 0.150936
 >> iter 52000, loss: 0.103318
 >> iter 53000, loss: 0.169987
 >> iter 54000, loss: 0.163078
 >> iter 55000, loss: 0.193854
 >> iter 56000, loss: 0.131336
 >> iter 57000, loss: 0.116385
 >> iter 58000, loss: 0.083551
 >> iter 59000, loss: 0.164536
 >> iter 60000, loss: 0.103472
   Number of active neurons: 5
 >> iter 61000, loss: 0.165078
 >> iter 62000, loss: 0.102866
 >> iter 63000, loss: 0.241894
 >> iter 64000, loss: 0.130549
 >> iter 65000, loss: 0.162930
 >> iter 66000, loss: 0.254214
 >> iter 67000, loss: 0.145714
 >> iter 68000, loss: 0.142010
 >> iter 69000, loss: 0.141577
 >> iter 70000, loss: 0.122952
   Number of active neurons: 5
 >> iter 71000, loss: 0.088917
 >> iter 72000, loss: 0.067030
 >> iter 73000, loss: 0.176600
 >> iter 74000, loss: 0.098594
 >> iter 75000, loss: 0.204514
 >> iter 76000, loss: 0.158690
 >> iter 77000, loss: 0.124790
 >> iter 78000, loss: 0.081517
 >> iter 79000, loss: 0.158393
 >> iter 80000, loss: 0.115306
   Number of active neurons: 5
 >> iter 81000, loss: 0.094740
 >> iter 82000, loss: 0.076834
 >> iter 83000, loss: 0.112967
 >> iter 84000, loss: 0.083412
 >> iter 85000, loss: 0.193788
 >> iter 86000, loss: 0.095179
 >> iter 87000, loss: 0.279703
 >> iter 88000, loss: 0.128869
 >> iter 89000, loss: 0.314814
 >> iter 90000, loss: 0.148543
   Number of active neurons: 5
 >> iter 91000, loss: 0.144372
 >> iter 92000, loss: 0.154502
 >> iter 93000, loss: 0.107663
 >> iter 94000, loss: 0.071604
 >> iter 95000, loss: 0.159018
 >> iter 96000, loss: 0.091166
 >> iter 97000, loss: 0.108743
 >> iter 98000, loss: 0.082109
 >> iter 99000, loss: 0.231799
 >> iter 100000, loss: 0.111859
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0379992400152
   - Test - Long: 0.0249987500625
   - Test - Big: 0.029999700003
   - Test - A: 0.0
   - Test - B: 4.79301379908
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.638852
 >> iter 2000, loss: 7.750311
 >> iter 3000, loss: 2.944066
 >> iter 4000, loss: 1.142155
 >> iter 5000, loss: 0.527895
 >> iter 6000, loss: 0.258480
 >> iter 7000, loss: 0.215621
 >> iter 8000, loss: 0.202876
 >> iter 9000, loss: 0.193630
 >> iter 10000, loss: 0.125616
   Number of active neurons: 7
 >> iter 11000, loss: 0.200294
 >> iter 12000, loss: 0.161721
 >> iter 13000, loss: 0.101615
 >> iter 14000, loss: 0.136329
 >> iter 15000, loss: 0.096099
 >> iter 16000, loss: 0.131131
 >> iter 17000, loss: 0.091076
 >> iter 18000, loss: 0.133888
 >> iter 19000, loss: 0.090657
 >> iter 20000, loss: 0.074576
   Number of active neurons: 6
 >> iter 21000, loss: 0.072206
 >> iter 22000, loss: 0.067744
 >> iter 23000, loss: 0.066133
 >> iter 24000, loss: 0.141921
 >> iter 25000, loss: 0.103595
 >> iter 26000, loss: 0.082052
 >> iter 27000, loss: 0.066792
 >> iter 28000, loss: 0.067833
 >> iter 29000, loss: 0.064562
 >> iter 30000, loss: 0.061658
   Number of active neurons: 5
 >> iter 31000, loss: 0.072050
 >> iter 32000, loss: 0.064754
 >> iter 33000, loss: 0.064907
 >> iter 34000, loss: 0.064597
 >> iter 35000, loss: 0.218555
 >> iter 36000, loss: 0.117705
 >> iter 37000, loss: 0.092058
 >> iter 38000, loss: 0.075865
 >> iter 39000, loss: 0.124731
 >> iter 40000, loss: 0.089454
   Number of active neurons: 5
 >> iter 41000, loss: 0.135027
 >> iter 42000, loss: 0.099108
 >> iter 43000, loss: 0.134845
 >> iter 44000, loss: 0.101184
 >> iter 45000, loss: 0.148996
 >> iter 46000, loss: 0.110812
 >> iter 47000, loss: 0.149693
 >> iter 48000, loss: 0.102649
 >> iter 49000, loss: 0.123475
 >> iter 50000, loss: 0.088260
   Number of active neurons: 5
 >> iter 51000, loss: 0.072081
 >> iter 52000, loss: 0.058952
 >> iter 53000, loss: 0.061189
 >> iter 54000, loss: 0.054094
 >> iter 55000, loss: 0.055925
 >> iter 56000, loss: 0.046945
 >> iter 57000, loss: 0.051539
 >> iter 58000, loss: 0.049981
 >> iter 59000, loss: 0.103439
 >> iter 60000, loss: 0.066021
   Number of active neurons: 5
 >> iter 61000, loss: 0.055220
 >> iter 62000, loss: 0.057192
 >> iter 63000, loss: 0.047394
 >> iter 64000, loss: 0.044802
 >> iter 65000, loss: 0.056765
 >> iter 66000, loss: 0.045515
 >> iter 67000, loss: 0.050689
 >> iter 68000, loss: 0.045234
 >> iter 69000, loss: 0.041695
 >> iter 70000, loss: 0.057803
   Number of active neurons: 5
 >> iter 71000, loss: 0.048269
 >> iter 72000, loss: 0.065276
 >> iter 73000, loss: 0.050384
 >> iter 74000, loss: 0.069649
 >> iter 75000, loss: 0.052239
 >> iter 76000, loss: 0.070696
 >> iter 77000, loss: 0.052311
 >> iter 78000, loss: 0.070315
 >> iter 79000, loss: 0.052252
 >> iter 80000, loss: 0.069872
   Number of active neurons: 5
 >> iter 81000, loss: 0.052540
 >> iter 82000, loss: 0.070082
 >> iter 83000, loss: 0.052339
 >> iter 84000, loss: 0.071024
 >> iter 85000, loss: 0.052657
 >> iter 86000, loss: 0.069292
 >> iter 87000, loss: 0.050824
 >> iter 88000, loss: 0.046604
 >> iter 89000, loss: 0.044072
 >> iter 90000, loss: 0.045674
   Number of active neurons: 5
 >> iter 91000, loss: 0.042577
 >> iter 92000, loss: 0.044221
 >> iter 93000, loss: 0.041901
 >> iter 94000, loss: 0.044343
 >> iter 95000, loss: 0.042322
 >> iter 96000, loss: 0.043892
 >> iter 97000, loss: 0.042150
 >> iter 98000, loss: 0.043429
 >> iter 99000, loss: 0.041883
 >> iter 100000, loss: 0.043113
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 21.0852609826
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.696426
 >> iter 2000, loss: 8.707525
 >> iter 3000, loss: 3.326723
 >> iter 4000, loss: 1.268505
 >> iter 5000, loss: 0.503673
 >> iter 6000, loss: 0.323101
 >> iter 7000, loss: 0.151911
 >> iter 8000, loss: 0.091774
 >> iter 9000, loss: 0.064526
 >> iter 10000, loss: 0.059119
   Number of active neurons: 7
 >> iter 11000, loss: 0.056940
 >> iter 12000, loss: 0.053360
 >> iter 13000, loss: 0.090265
 >> iter 14000, loss: 0.066278
 >> iter 15000, loss: 0.061117
 >> iter 16000, loss: 0.051788
 >> iter 17000, loss: 0.055189
 >> iter 18000, loss: 0.054727
 >> iter 19000, loss: 0.160534
 >> iter 20000, loss: 0.096339
   Number of active neurons: 6
 >> iter 21000, loss: 0.201220
 >> iter 22000, loss: 0.202766
 >> iter 23000, loss: 0.112333
 >> iter 24000, loss: 0.095332
 >> iter 25000, loss: 0.067491
 >> iter 26000, loss: 0.085256
 >> iter 27000, loss: 0.063415
 >> iter 28000, loss: 0.097454
 >> iter 29000, loss: 0.068517
 >> iter 30000, loss: 0.079136
   Number of active neurons: 5
 >> iter 31000, loss: 0.062168
 >> iter 32000, loss: 0.077645
 >> iter 33000, loss: 0.061861
 >> iter 34000, loss: 0.078923
 >> iter 35000, loss: 0.101932
 >> iter 36000, loss: 0.078494
 >> iter 37000, loss: 0.119795
 >> iter 38000, loss: 0.139649
 >> iter 39000, loss: 0.163367
 >> iter 40000, loss: 0.109105
   Number of active neurons: 5
 >> iter 41000, loss: 0.070718
 >> iter 42000, loss: 0.071491
 >> iter 43000, loss: 0.055961
 >> iter 44000, loss: 0.064771
 >> iter 45000, loss: 0.053424
 >> iter 46000, loss: 0.064756
 >> iter 47000, loss: 0.053360
 >> iter 48000, loss: 0.068252
 >> iter 49000, loss: 0.078191
 >> iter 50000, loss: 0.074006
   Number of active neurons: 5
 >> iter 51000, loss: 0.064393
 >> iter 52000, loss: 0.068415
 >> iter 53000, loss: 0.072132
 >> iter 54000, loss: 0.067571
 >> iter 55000, loss: 0.056203
 >> iter 56000, loss: 0.060137
 >> iter 57000, loss: 0.051201
 >> iter 58000, loss: 0.053577
 >> iter 59000, loss: 0.046867
 >> iter 60000, loss: 0.059041
   Number of active neurons: 5
 >> iter 61000, loss: 0.057766
 >> iter 62000, loss: 0.047352
 >> iter 63000, loss: 0.084985
 >> iter 64000, loss: 0.062080
 >> iter 65000, loss: 0.053986
 >> iter 66000, loss: 0.053616
 >> iter 67000, loss: 0.087651
 >> iter 68000, loss: 0.073403
 >> iter 69000, loss: 0.122116
 >> iter 70000, loss: 0.192543
   Number of active neurons: 5
 >> iter 71000, loss: 0.109297
 >> iter 72000, loss: 0.082554
 >> iter 73000, loss: 0.133333
 >> iter 74000, loss: 0.077463
 >> iter 75000, loss: 0.060734
 >> iter 76000, loss: 0.059614
 >> iter 77000, loss: 0.085227
 >> iter 78000, loss: 0.063192
 >> iter 79000, loss: 0.052909
 >> iter 80000, loss: 0.052718
   Number of active neurons: 5
 >> iter 81000, loss: 0.083703
 >> iter 82000, loss: 0.066541
 >> iter 83000, loss: 0.097976
 >> iter 84000, loss: 0.068494
 >> iter 85000, loss: 0.072865
 >> iter 86000, loss: 0.065859
 >> iter 87000, loss: 0.058064
 >> iter 88000, loss: 0.056116
 >> iter 89000, loss: 0.051427
 >> iter 90000, loss: 0.048660
   Number of active neurons: 5
 >> iter 91000, loss: 0.089076
 >> iter 92000, loss: 0.060779
 >> iter 93000, loss: 0.082819
 >> iter 94000, loss: 0.057943
 >> iter 95000, loss: 0.102242
 >> iter 96000, loss: 0.064721
 >> iter 97000, loss: 0.132635
 >> iter 98000, loss: 0.076511
 >> iter 99000, loss: 0.068360
 >> iter 100000, loss: 0.055552
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 17.1655222985
   - Test - B: 21.9718685421
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.748798
 >> iter 2000, loss: 10.301431
 >> iter 3000, loss: 4.594907
 >> iter 4000, loss: 2.133160
 >> iter 5000, loss: 0.901039
 >> iter 6000, loss: 0.384964
 >> iter 7000, loss: 0.237171
 >> iter 8000, loss: 0.132844
 >> iter 9000, loss: 0.148606
 >> iter 10000, loss: 0.094076
   Number of active neurons: 5
 >> iter 11000, loss: 0.088628
 >> iter 12000, loss: 0.075629
 >> iter 13000, loss: 0.122656
 >> iter 14000, loss: 0.079563
 >> iter 15000, loss: 0.072971
 >> iter 16000, loss: 0.060997
 >> iter 17000, loss: 0.088688
 >> iter 18000, loss: 0.068507
 >> iter 19000, loss: 0.107317
 >> iter 20000, loss: 0.071875
   Number of active neurons: 5
 >> iter 21000, loss: 0.117950
 >> iter 22000, loss: 0.078949
 >> iter 23000, loss: 0.101715
 >> iter 24000, loss: 0.074541
 >> iter 25000, loss: 0.119064
 >> iter 26000, loss: 0.078654
 >> iter 27000, loss: 0.119381
 >> iter 28000, loss: 0.075355
 >> iter 29000, loss: 0.115464
 >> iter 30000, loss: 0.073793
   Number of active neurons: 5
 >> iter 31000, loss: 0.114298
 >> iter 32000, loss: 0.074476
 >> iter 33000, loss: 0.114243
 >> iter 34000, loss: 0.076450
 >> iter 35000, loss: 0.117467
 >> iter 36000, loss: 0.111403
 >> iter 37000, loss: 0.129658
 >> iter 38000, loss: 0.084400
 >> iter 39000, loss: 0.143082
 >> iter 40000, loss: 0.129157
   Number of active neurons: 5
 >> iter 41000, loss: 0.198970
 >> iter 42000, loss: 0.146627
 >> iter 43000, loss: 0.147997
 >> iter 44000, loss: 0.134010
 >> iter 45000, loss: 0.139226
 >> iter 46000, loss: 0.092716
 >> iter 47000, loss: 0.200431
 >> iter 48000, loss: 0.130978
 >> iter 49000, loss: 0.131680
 >> iter 50000, loss: 0.101579
   Number of active neurons: 4
 >> iter 51000, loss: 0.120486
 >> iter 52000, loss: 0.078729
 >> iter 53000, loss: 0.111837
 >> iter 54000, loss: 0.074744
 >> iter 55000, loss: 0.109048
 >> iter 56000, loss: 0.075400
 >> iter 57000, loss: 0.109760
 >> iter 58000, loss: 0.075428
 >> iter 59000, loss: 0.109556
 >> iter 60000, loss: 0.076194
   Number of active neurons: 4
 >> iter 61000, loss: 0.108978
 >> iter 62000, loss: 0.076125
 >> iter 63000, loss: 0.108276
 >> iter 64000, loss: 0.075904
 >> iter 65000, loss: 0.107694
 >> iter 66000, loss: 0.074101
 >> iter 67000, loss: 0.106393
 >> iter 68000, loss: 0.073703
 >> iter 69000, loss: 0.130022
 >> iter 70000, loss: 0.082607
   Number of active neurons: 4
 >> iter 71000, loss: 0.263823
 >> iter 72000, loss: 0.132669
 >> iter 73000, loss: 0.258051
 >> iter 74000, loss: 0.130199
 >> iter 75000, loss: 0.140527
 >> iter 76000, loss: 0.087261
 >> iter 77000, loss: 0.269582
 >> iter 78000, loss: 0.134559
 >> iter 79000, loss: 0.138380
 >> iter 80000, loss: 0.083072
   Number of active neurons: 4
 >> iter 81000, loss: 0.111167
 >> iter 82000, loss: 0.087573
 >> iter 83000, loss: 0.117007
 >> iter 84000, loss: 0.087090
 >> iter 85000, loss: 0.242415
 >> iter 86000, loss: 0.122782
 >> iter 87000, loss: 0.132846
 >> iter 88000, loss: 0.084480
 >> iter 89000, loss: 0.212397
 >> iter 90000, loss: 0.127838
   Number of active neurons: 4
 >> iter 91000, loss: 0.128082
 >> iter 92000, loss: 0.080714
 >> iter 93000, loss: 0.112510
 >> iter 94000, loss: 0.073663
 >> iter 95000, loss: 0.110748
 >> iter 96000, loss: 0.097746
 >> iter 97000, loss: 0.116751
 >> iter 98000, loss: 0.075490
 >> iter 99000, loss: 0.111231
 >> iter 100000, loss: 0.091826
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0659986800264
   - Test - Long: 0.21998900055
   - Test - Big: 0.0719992800072
   - Test - A: 0.0
   - Test - B: 26.3849076728

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

