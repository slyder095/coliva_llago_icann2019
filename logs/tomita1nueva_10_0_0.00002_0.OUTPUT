 > Problema: tomita1nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 2e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.696133
 >> iter 2000, loss: 3.944325
 >> iter 3000, loss: 1.457749
 >> iter 4000, loss: 0.541750
 >> iter 5000, loss: 0.204386
 >> iter 6000, loss: 0.079780
 >> iter 7000, loss: 0.033841
 >> iter 8000, loss: 0.016636
 >> iter 9000, loss: 0.010303
 >> iter 10000, loss: 0.007705
   Number of active neurons: 4
 >> iter 11000, loss: 0.006729
 >> iter 12000, loss: 0.006109
 >> iter 13000, loss: 0.005880
 >> iter 14000, loss: 0.005573
 >> iter 15000, loss: 0.005481
 >> iter 16000, loss: 0.005266
 >> iter 17000, loss: 0.005235
 >> iter 18000, loss: 0.005069
 >> iter 19000, loss: 0.005066
 >> iter 20000, loss: 0.004927
   Number of active neurons: 4
 >> iter 21000, loss: 0.004939
 >> iter 22000, loss: 0.004812
 >> iter 23000, loss: 0.004837
 >> iter 24000, loss: 0.004717
 >> iter 25000, loss: 0.004750
 >> iter 26000, loss: 0.004637
 >> iter 27000, loss: 0.004670
 >> iter 28000, loss: 0.004563
 >> iter 29000, loss: 0.004597
 >> iter 30000, loss: 0.004496
   Number of active neurons: 4
 >> iter 31000, loss: 0.004535
 >> iter 32000, loss: 0.004438
 >> iter 33000, loss: 0.004479
 >> iter 34000, loss: 0.004385
 >> iter 35000, loss: 0.004429
 >> iter 36000, loss: 0.004334
 >> iter 37000, loss: 0.004380
 >> iter 38000, loss: 0.004288
 >> iter 39000, loss: 0.004339
 >> iter 40000, loss: 0.004250
   Number of active neurons: 4
 >> iter 41000, loss: 0.004305
 >> iter 42000, loss: 0.004227
 >> iter 43000, loss: 0.004279
 >> iter 44000, loss: 0.004208
 >> iter 45000, loss: 0.004266
 >> iter 46000, loss: 0.004194
 >> iter 47000, loss: 0.004252
 >> iter 48000, loss: 0.004186
 >> iter 49000, loss: 0.004246
 >> iter 50000, loss: 0.004178
   Number of active neurons: 4
 >> iter 51000, loss: 0.004239
 >> iter 52000, loss: 0.004174
 >> iter 53000, loss: 0.004231
 >> iter 54000, loss: 0.004178
 >> iter 55000, loss: 0.004225
 >> iter 56000, loss: 0.004177
 >> iter 57000, loss: 0.004226
 >> iter 58000, loss: 0.004172
 >> iter 59000, loss: 0.004223
 >> iter 60000, loss: 0.004172
   Number of active neurons: 4
 >> iter 61000, loss: 0.004220
 >> iter 62000, loss: 0.004173
 >> iter 63000, loss: 0.004219
 >> iter 64000, loss: 0.004168
 >> iter 65000, loss: 0.004214
 >> iter 66000, loss: 0.004165
 >> iter 67000, loss: 0.004210
 >> iter 68000, loss: 0.004169
 >> iter 69000, loss: 0.004210
 >> iter 70000, loss: 0.004170
   Number of active neurons: 4
 >> iter 71000, loss: 0.004215
 >> iter 72000, loss: 0.004178
 >> iter 73000, loss: 0.004221
 >> iter 74000, loss: 0.004182
 >> iter 75000, loss: 0.004227
 >> iter 76000, loss: 0.004191
 >> iter 77000, loss: 0.004235
 >> iter 78000, loss: 0.004197
 >> iter 79000, loss: 0.004247
 >> iter 80000, loss: 0.004202
   Number of active neurons: 4
 >> iter 81000, loss: 0.004258
 >> iter 82000, loss: 0.004207
 >> iter 83000, loss: 0.004266
 >> iter 84000, loss: 0.004207
 >> iter 85000, loss: 0.004266
 >> iter 86000, loss: 0.004211
 >> iter 87000, loss: 0.004274
 >> iter 88000, loss: 0.004220
 >> iter 89000, loss: 0.004282
 >> iter 90000, loss: 0.004232
   Number of active neurons: 4
 >> iter 91000, loss: 0.004290
 >> iter 92000, loss: 0.004243
 >> iter 93000, loss: 0.004301
 >> iter 94000, loss: 0.004250
 >> iter 95000, loss: 0.004315
 >> iter 96000, loss: 0.004256
 >> iter 97000, loss: 0.004322
 >> iter 98000, loss: 0.004262
 >> iter 99000, loss: 0.004328
 >> iter 100000, loss: 0.004273
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.718155
 >> iter 2000, loss: 3.952815
 >> iter 3000, loss: 1.461085
 >> iter 4000, loss: 0.543142
 >> iter 5000, loss: 0.204974
 >> iter 6000, loss: 0.080078
 >> iter 7000, loss: 0.033976
 >> iter 8000, loss: 0.016718
 >> iter 9000, loss: 0.010315
 >> iter 10000, loss: 0.007731
   Number of active neurons: 7
 >> iter 11000, loss: 0.006767
 >> iter 12000, loss: 0.006240
 >> iter 13000, loss: 0.006081
 >> iter 14000, loss: 0.005883
 >> iter 15000, loss: 0.005869
 >> iter 16000, loss: 0.005744
 >> iter 17000, loss: 0.005765
 >> iter 18000, loss: 0.005666
 >> iter 19000, loss: 0.005692
 >> iter 20000, loss: 0.005606
   Number of active neurons: 6
 >> iter 21000, loss: 0.005637
 >> iter 22000, loss: 0.005553
 >> iter 23000, loss: 0.005590
 >> iter 24000, loss: 0.005509
 >> iter 25000, loss: 0.005554
 >> iter 26000, loss: 0.005481
 >> iter 27000, loss: 0.005524
 >> iter 28000, loss: 0.005452
 >> iter 29000, loss: 0.005488
 >> iter 30000, loss: 0.005415
   Number of active neurons: 5
 >> iter 31000, loss: 0.005451
 >> iter 32000, loss: 0.005375
 >> iter 33000, loss: 0.005407
 >> iter 34000, loss: 0.005331
 >> iter 35000, loss: 0.005366
 >> iter 36000, loss: 0.005285
 >> iter 37000, loss: 0.005315
 >> iter 38000, loss: 0.005231
 >> iter 39000, loss: 0.005265
 >> iter 40000, loss: 0.005182
   Number of active neurons: 4
 >> iter 41000, loss: 0.005215
 >> iter 42000, loss: 0.005134
 >> iter 43000, loss: 0.005162
 >> iter 44000, loss: 0.005088
 >> iter 45000, loss: 0.005117
 >> iter 46000, loss: 0.005041
 >> iter 47000, loss: 0.005067
 >> iter 48000, loss: 0.004992
 >> iter 49000, loss: 0.005014
 >> iter 50000, loss: 0.004935
   Number of active neurons: 4
 >> iter 51000, loss: 0.004959
 >> iter 52000, loss: 0.004885
 >> iter 53000, loss: 0.004906
 >> iter 54000, loss: 0.004842
 >> iter 55000, loss: 0.004853
 >> iter 56000, loss: 0.004792
 >> iter 57000, loss: 0.004804
 >> iter 58000, loss: 0.004735
 >> iter 59000, loss: 0.004753
 >> iter 60000, loss: 0.004688
   Number of active neurons: 3
 >> iter 61000, loss: 0.004704
 >> iter 62000, loss: 0.004645
 >> iter 63000, loss: 0.004663
 >> iter 64000, loss: 0.004603
 >> iter 65000, loss: 0.004625
 >> iter 66000, loss: 0.004568
 >> iter 67000, loss: 0.004584
 >> iter 68000, loss: 0.004532
 >> iter 69000, loss: 0.004541
 >> iter 70000, loss: 0.004481
   Number of active neurons: 2
 >> iter 71000, loss: 0.004491
 >> iter 72000, loss: 0.004436
 >> iter 73000, loss: 0.004446
 >> iter 74000, loss: 0.004389
 >> iter 75000, loss: 0.004401
 >> iter 76000, loss: 0.004347
 >> iter 77000, loss: 0.004357
 >> iter 78000, loss: 0.004298
 >> iter 79000, loss: 0.004314
 >> iter 80000, loss: 0.004251
   Number of active neurons: 2
 >> iter 81000, loss: 0.004269
 >> iter 82000, loss: 0.004199
 >> iter 83000, loss: 0.004222
 >> iter 84000, loss: 0.004150
 >> iter 85000, loss: 0.004172
 >> iter 86000, loss: 0.004098
 >> iter 87000, loss: 0.004120
 >> iter 88000, loss: 0.004046
 >> iter 89000, loss: 0.004065
 >> iter 90000, loss: 0.003990
   Number of active neurons: 2
 >> iter 91000, loss: 0.004006
 >> iter 92000, loss: 0.003936
 >> iter 93000, loss: 0.003954
 >> iter 94000, loss: 0.003881
 >> iter 95000, loss: 0.003906
 >> iter 96000, loss: 0.003828
 >> iter 97000, loss: 0.003854
 >> iter 98000, loss: 0.003774
 >> iter 99000, loss: 0.003803
 >> iter 100000, loss: 0.003730
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.716517
 >> iter 2000, loss: 3.952525
 >> iter 3000, loss: 1.461147
 >> iter 4000, loss: 0.543266
 >> iter 5000, loss: 0.205068
 >> iter 6000, loss: 0.080109
 >> iter 7000, loss: 0.033932
 >> iter 8000, loss: 0.016623
 >> iter 9000, loss: 0.010167
 >> iter 10000, loss: 0.007564
   Number of active neurons: 5
 >> iter 11000, loss: 0.006584
 >> iter 12000, loss: 0.006047
 >> iter 13000, loss: 0.005859
 >> iter 14000, loss: 0.005641
 >> iter 15000, loss: 0.005597
 >> iter 16000, loss: 0.005456
 >> iter 17000, loss: 0.005446
 >> iter 18000, loss: 0.005331
 >> iter 19000, loss: 0.005331
 >> iter 20000, loss: 0.005229
   Number of active neurons: 5
 >> iter 21000, loss: 0.005228
 >> iter 22000, loss: 0.005128
 >> iter 23000, loss: 0.005140
 >> iter 24000, loss: 0.005053
 >> iter 25000, loss: 0.005075
 >> iter 26000, loss: 0.004994
 >> iter 27000, loss: 0.005012
 >> iter 28000, loss: 0.004934
 >> iter 29000, loss: 0.004954
 >> iter 30000, loss: 0.004882
   Number of active neurons: 5
 >> iter 31000, loss: 0.004908
 >> iter 32000, loss: 0.004842
 >> iter 33000, loss: 0.004871
 >> iter 34000, loss: 0.004809
 >> iter 35000, loss: 0.004848
 >> iter 36000, loss: 0.004789
 >> iter 37000, loss: 0.004833
 >> iter 38000, loss: 0.004775
 >> iter 39000, loss: 0.004821
 >> iter 40000, loss: 0.004764
   Number of active neurons: 5
 >> iter 41000, loss: 0.004814
 >> iter 42000, loss: 0.004762
 >> iter 43000, loss: 0.004810
 >> iter 44000, loss: 0.004764
 >> iter 45000, loss: 0.004813
 >> iter 46000, loss: 0.004765
 >> iter 47000, loss: 0.004814
 >> iter 48000, loss: 0.004769
 >> iter 49000, loss: 0.004818
 >> iter 50000, loss: 0.004772
   Number of active neurons: 5
 >> iter 51000, loss: 0.004822
 >> iter 52000, loss: 0.004778
 >> iter 53000, loss: 0.004823
 >> iter 54000, loss: 0.004788
 >> iter 55000, loss: 0.004824
 >> iter 56000, loss: 0.004789
 >> iter 57000, loss: 0.004827
 >> iter 58000, loss: 0.004784
 >> iter 59000, loss: 0.004828
 >> iter 60000, loss: 0.004788
   Number of active neurons: 5
 >> iter 61000, loss: 0.004828
 >> iter 62000, loss: 0.004791
 >> iter 63000, loss: 0.004831
 >> iter 64000, loss: 0.004789
 >> iter 65000, loss: 0.004832
 >> iter 66000, loss: 0.004791
 >> iter 67000, loss: 0.004829
 >> iter 68000, loss: 0.004794
 >> iter 69000, loss: 0.004827
 >> iter 70000, loss: 0.004789
   Number of active neurons: 4
 >> iter 71000, loss: 0.004824
 >> iter 72000, loss: 0.004788
 >> iter 73000, loss: 0.004820
 >> iter 74000, loss: 0.004781
 >> iter 75000, loss: 0.004814
 >> iter 76000, loss: 0.004774
 >> iter 77000, loss: 0.004805
 >> iter 78000, loss: 0.004763
 >> iter 79000, loss: 0.004801
 >> iter 80000, loss: 0.004754
   Number of active neurons: 3
 >> iter 81000, loss: 0.004795
 >> iter 82000, loss: 0.004742
 >> iter 83000, loss: 0.004785
 >> iter 84000, loss: 0.004727
 >> iter 85000, loss: 0.004767
 >> iter 86000, loss: 0.004708
 >> iter 87000, loss: 0.004748
 >> iter 88000, loss: 0.004685
 >> iter 89000, loss: 0.004717
 >> iter 90000, loss: 0.004655
   Number of active neurons: 3
 >> iter 91000, loss: 0.004684
 >> iter 92000, loss: 0.004624
 >> iter 93000, loss: 0.004653
 >> iter 94000, loss: 0.004588
 >> iter 95000, loss: 0.004619
 >> iter 96000, loss: 0.004547
 >> iter 97000, loss: 0.004579
 >> iter 98000, loss: 0.004506
 >> iter 99000, loss: 0.004539
 >> iter 100000, loss: 0.004467
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.732225
 >> iter 2000, loss: 3.958319
 >> iter 3000, loss: 1.463244
 >> iter 4000, loss: 0.544041
 >> iter 5000, loss: 0.205343
 >> iter 6000, loss: 0.080259
 >> iter 7000, loss: 0.034067
 >> iter 8000, loss: 0.016822
 >> iter 9000, loss: 0.010430
 >> iter 10000, loss: 0.007904
   Number of active neurons: 9
 >> iter 11000, loss: 0.006993
 >> iter 12000, loss: 0.006527
 >> iter 13000, loss: 0.006412
 >> iter 14000, loss: 0.006254
 >> iter 15000, loss: 0.006269
 >> iter 16000, loss: 0.006172
 >> iter 17000, loss: 0.006216
 >> iter 18000, loss: 0.006139
 >> iter 19000, loss: 0.006189
 >> iter 20000, loss: 0.006123
   Number of active neurons: 9
 >> iter 21000, loss: 0.006173
 >> iter 22000, loss: 0.006104
 >> iter 23000, loss: 0.006158
 >> iter 24000, loss: 0.006092
 >> iter 25000, loss: 0.006153
 >> iter 26000, loss: 0.006092
 >> iter 27000, loss: 0.006153
 >> iter 28000, loss: 0.006095
 >> iter 29000, loss: 0.006153
 >> iter 30000, loss: 0.006096
   Number of active neurons: 7
 >> iter 31000, loss: 0.006155
 >> iter 32000, loss: 0.006099
 >> iter 33000, loss: 0.006158
 >> iter 34000, loss: 0.006102
 >> iter 35000, loss: 0.006164
 >> iter 36000, loss: 0.006104
 >> iter 37000, loss: 0.006166
 >> iter 38000, loss: 0.006103
 >> iter 39000, loss: 0.006167
 >> iter 40000, loss: 0.006102
   Number of active neurons: 6
 >> iter 41000, loss: 0.006163
 >> iter 42000, loss: 0.006100
 >> iter 43000, loss: 0.006155
 >> iter 44000, loss: 0.006096
 >> iter 45000, loss: 0.006148
 >> iter 46000, loss: 0.006086
 >> iter 47000, loss: 0.006134
 >> iter 48000, loss: 0.006073
 >> iter 49000, loss: 0.006119
 >> iter 50000, loss: 0.006053
   Number of active neurons: 6
 >> iter 51000, loss: 0.006093
 >> iter 52000, loss: 0.006019
 >> iter 53000, loss: 0.006049
 >> iter 54000, loss: 0.005985
 >> iter 55000, loss: 0.006005
 >> iter 56000, loss: 0.005943
 >> iter 57000, loss: 0.005967
 >> iter 58000, loss: 0.005893
 >> iter 59000, loss: 0.005914
 >> iter 60000, loss: 0.005840
   Number of active neurons: 6
 >> iter 61000, loss: 0.005856
 >> iter 62000, loss: 0.005785
 >> iter 63000, loss: 0.005798
 >> iter 64000, loss: 0.005719
 >> iter 65000, loss: 0.005737
 >> iter 66000, loss: 0.005667
 >> iter 67000, loss: 0.005686
 >> iter 68000, loss: 0.005628
 >> iter 69000, loss: 0.005645
 >> iter 70000, loss: 0.005584
   Number of active neurons: 5
 >> iter 71000, loss: 0.005604
 >> iter 72000, loss: 0.005549
 >> iter 73000, loss: 0.005568
 >> iter 74000, loss: 0.005513
 >> iter 75000, loss: 0.005534
 >> iter 76000, loss: 0.005481
 >> iter 77000, loss: 0.005501
 >> iter 78000, loss: 0.005449
 >> iter 79000, loss: 0.005480
 >> iter 80000, loss: 0.005425
   Number of active neurons: 2
 >> iter 81000, loss: 0.005460
 >> iter 82000, loss: 0.005402
 >> iter 83000, loss: 0.005439
 >> iter 84000, loss: 0.005377
 >> iter 85000, loss: 0.005411
 >> iter 86000, loss: 0.005348
 >> iter 87000, loss: 0.005379
 >> iter 88000, loss: 0.005309
 >> iter 89000, loss: 0.005333
 >> iter 90000, loss: 0.005267
   Number of active neurons: 2
 >> iter 91000, loss: 0.005288
 >> iter 92000, loss: 0.005220
 >> iter 93000, loss: 0.005234
 >> iter 94000, loss: 0.005161
 >> iter 95000, loss: 0.005179
 >> iter 96000, loss: 0.005099
 >> iter 97000, loss: 0.005116
 >> iter 98000, loss: 0.005033
 >> iter 99000, loss: 0.005048
 >> iter 100000, loss: 0.004967
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.695519
 >> iter 2000, loss: 3.945289
 >> iter 3000, loss: 1.458695
 >> iter 4000, loss: 0.542466
 >> iter 5000, loss: 0.204794
 >> iter 6000, loss: 0.079963
 >> iter 7000, loss: 0.033787
 >> iter 8000, loss: 0.016452
 >> iter 9000, loss: 0.009970
 >> iter 10000, loss: 0.007347
   Number of active neurons: 6
 >> iter 11000, loss: 0.006349
 >> iter 12000, loss: 0.005810
 >> iter 13000, loss: 0.005628
 >> iter 14000, loss: 0.005424
 >> iter 15000, loss: 0.005391
 >> iter 16000, loss: 0.005267
 >> iter 17000, loss: 0.005275
 >> iter 18000, loss: 0.005181
 >> iter 19000, loss: 0.005204
 >> iter 20000, loss: 0.005130
   Number of active neurons: 5
 >> iter 21000, loss: 0.005160
 >> iter 22000, loss: 0.005091
 >> iter 23000, loss: 0.005130
 >> iter 24000, loss: 0.005064
 >> iter 25000, loss: 0.005109
 >> iter 26000, loss: 0.005049
 >> iter 27000, loss: 0.005091
 >> iter 28000, loss: 0.005034
 >> iter 29000, loss: 0.005073
 >> iter 30000, loss: 0.005009
   Number of active neurons: 5
 >> iter 31000, loss: 0.005042
 >> iter 32000, loss: 0.004978
 >> iter 33000, loss: 0.005014
 >> iter 34000, loss: 0.004953
 >> iter 35000, loss: 0.004994
 >> iter 36000, loss: 0.004932
 >> iter 37000, loss: 0.004973
 >> iter 38000, loss: 0.004910
 >> iter 39000, loss: 0.004953
 >> iter 40000, loss: 0.004888
   Number of active neurons: 4
 >> iter 41000, loss: 0.004930
 >> iter 42000, loss: 0.004867
 >> iter 43000, loss: 0.004903
 >> iter 44000, loss: 0.004843
 >> iter 45000, loss: 0.004876
 >> iter 46000, loss: 0.004812
 >> iter 47000, loss: 0.004841
 >> iter 48000, loss: 0.004779
 >> iter 49000, loss: 0.004808
 >> iter 50000, loss: 0.004740
   Number of active neurons: 3
 >> iter 51000, loss: 0.004763
 >> iter 52000, loss: 0.004697
 >> iter 53000, loss: 0.004713
 >> iter 54000, loss: 0.004649
 >> iter 55000, loss: 0.004654
 >> iter 56000, loss: 0.004594
 >> iter 57000, loss: 0.004603
 >> iter 58000, loss: 0.004534
 >> iter 59000, loss: 0.004548
 >> iter 60000, loss: 0.004484
   Number of active neurons: 3
 >> iter 61000, loss: 0.004497
 >> iter 62000, loss: 0.004437
 >> iter 63000, loss: 0.004451
 >> iter 64000, loss: 0.004387
 >> iter 65000, loss: 0.004402
 >> iter 66000, loss: 0.004337
 >> iter 67000, loss: 0.004347
 >> iter 68000, loss: 0.004288
 >> iter 69000, loss: 0.004292
 >> iter 70000, loss: 0.004229
   Number of active neurons: 2
 >> iter 71000, loss: 0.004236
 >> iter 72000, loss: 0.004177
 >> iter 73000, loss: 0.004182
 >> iter 74000, loss: 0.004123
 >> iter 75000, loss: 0.004132
 >> iter 76000, loss: 0.004076
 >> iter 77000, loss: 0.004085
 >> iter 78000, loss: 0.004030
 >> iter 79000, loss: 0.004046
 >> iter 80000, loss: 0.003986
   Number of active neurons: 2
 >> iter 81000, loss: 0.004005
 >> iter 82000, loss: 0.003937
 >> iter 83000, loss: 0.003959
 >> iter 84000, loss: 0.003890
 >> iter 85000, loss: 0.003914
 >> iter 86000, loss: 0.003848
 >> iter 87000, loss: 0.003875
 >> iter 88000, loss: 0.003810
 >> iter 89000, loss: 0.003839
 >> iter 90000, loss: 0.003778
   Number of active neurons: 2
 >> iter 91000, loss: 0.003806
 >> iter 92000, loss: 0.003747
 >> iter 93000, loss: 0.003772
 >> iter 94000, loss: 0.003708
 >> iter 95000, loss: 0.003740
 >> iter 96000, loss: 0.003671
 >> iter 97000, loss: 0.003706
 >> iter 98000, loss: 0.003637
 >> iter 99000, loss: 0.003675
 >> iter 100000, loss: 0.003611
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.678163
 >> iter 2000, loss: 3.939652
 >> iter 3000, loss: 1.457136
 >> iter 4000, loss: 0.542324
 >> iter 5000, loss: 0.205145
 >> iter 6000, loss: 0.080501
 >> iter 7000, loss: 0.034390
 >> iter 8000, loss: 0.017066
 >> iter 9000, loss: 0.010563
 >> iter 10000, loss: 0.007920
   Number of active neurons: 4
 >> iter 11000, loss: 0.006898
 >> iter 12000, loss: 0.006334
 >> iter 13000, loss: 0.006124
 >> iter 14000, loss: 0.005886
 >> iter 15000, loss: 0.005814
 >> iter 16000, loss: 0.005649
 >> iter 17000, loss: 0.005617
 >> iter 18000, loss: 0.005479
 >> iter 19000, loss: 0.005457
 >> iter 20000, loss: 0.005334
   Number of active neurons: 4
 >> iter 21000, loss: 0.005312
 >> iter 22000, loss: 0.005191
 >> iter 23000, loss: 0.005176
 >> iter 24000, loss: 0.005061
 >> iter 25000, loss: 0.005054
 >> iter 26000, loss: 0.004948
 >> iter 27000, loss: 0.004942
 >> iter 28000, loss: 0.004844
 >> iter 29000, loss: 0.004838
 >> iter 30000, loss: 0.004745
   Number of active neurons: 4
 >> iter 31000, loss: 0.004741
 >> iter 32000, loss: 0.004652
 >> iter 33000, loss: 0.004656
 >> iter 34000, loss: 0.004578
 >> iter 35000, loss: 0.004593
 >> iter 36000, loss: 0.004520
 >> iter 37000, loss: 0.004541
 >> iter 38000, loss: 0.004474
 >> iter 39000, loss: 0.004503
 >> iter 40000, loss: 0.004440
   Number of active neurons: 3
 >> iter 41000, loss: 0.004471
 >> iter 42000, loss: 0.004413
 >> iter 43000, loss: 0.004443
 >> iter 44000, loss: 0.004391
 >> iter 45000, loss: 0.004421
 >> iter 46000, loss: 0.004369
 >> iter 47000, loss: 0.004399
 >> iter 48000, loss: 0.004349
 >> iter 49000, loss: 0.004376
 >> iter 50000, loss: 0.004320
   Number of active neurons: 3
 >> iter 51000, loss: 0.004348
 >> iter 52000, loss: 0.004294
 >> iter 53000, loss: 0.004315
 >> iter 54000, loss: 0.004265
 >> iter 55000, loss: 0.004280
 >> iter 56000, loss: 0.004233
 >> iter 57000, loss: 0.004252
 >> iter 58000, loss: 0.004200
 >> iter 59000, loss: 0.004222
 >> iter 60000, loss: 0.004169
   Number of active neurons: 3
 >> iter 61000, loss: 0.004185
 >> iter 62000, loss: 0.004135
 >> iter 63000, loss: 0.004152
 >> iter 64000, loss: 0.004099
 >> iter 65000, loss: 0.004120
 >> iter 66000, loss: 0.004069
 >> iter 67000, loss: 0.004087
 >> iter 68000, loss: 0.004042
 >> iter 69000, loss: 0.004057
 >> iter 70000, loss: 0.004012
   Number of active neurons: 2
 >> iter 71000, loss: 0.004031
 >> iter 72000, loss: 0.003990
 >> iter 73000, loss: 0.004008
 >> iter 74000, loss: 0.003967
 >> iter 75000, loss: 0.003987
 >> iter 76000, loss: 0.003947
 >> iter 77000, loss: 0.003966
 >> iter 78000, loss: 0.003925
 >> iter 79000, loss: 0.003951
 >> iter 80000, loss: 0.003906
   Number of active neurons: 2
 >> iter 81000, loss: 0.003936
 >> iter 82000, loss: 0.003886
 >> iter 83000, loss: 0.003918
 >> iter 84000, loss: 0.003864
 >> iter 85000, loss: 0.003895
 >> iter 86000, loss: 0.003837
 >> iter 87000, loss: 0.003864
 >> iter 88000, loss: 0.003805
 >> iter 89000, loss: 0.003830
 >> iter 90000, loss: 0.003772
   Number of active neurons: 2
 >> iter 91000, loss: 0.003794
 >> iter 92000, loss: 0.003738
 >> iter 93000, loss: 0.003761
 >> iter 94000, loss: 0.003704
 >> iter 95000, loss: 0.003734
 >> iter 96000, loss: 0.003674
 >> iter 97000, loss: 0.003706
 >> iter 98000, loss: 0.003645
 >> iter 99000, loss: 0.003680
 >> iter 100000, loss: 0.003623
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.694113
 >> iter 2000, loss: 3.944712
 >> iter 3000, loss: 1.458514
 >> iter 4000, loss: 0.542468
 >> iter 5000, loss: 0.204891
 >> iter 6000, loss: 0.080125
 >> iter 7000, loss: 0.033993
 >> iter 8000, loss: 0.016702
 >> iter 9000, loss: 0.010256
 >> iter 10000, loss: 0.007676
   Number of active neurons: 6
 >> iter 11000, loss: 0.006716
 >> iter 12000, loss: 0.006200
 >> iter 13000, loss: 0.006034
 >> iter 14000, loss: 0.005841
 >> iter 15000, loss: 0.005819
 >> iter 16000, loss: 0.005701
 >> iter 17000, loss: 0.005715
 >> iter 18000, loss: 0.005619
 >> iter 19000, loss: 0.005638
 >> iter 20000, loss: 0.005555
   Number of active neurons: 6
 >> iter 21000, loss: 0.005579
 >> iter 22000, loss: 0.005501
 >> iter 23000, loss: 0.005533
 >> iter 24000, loss: 0.005458
 >> iter 25000, loss: 0.005495
 >> iter 26000, loss: 0.005424
 >> iter 27000, loss: 0.005456
 >> iter 28000, loss: 0.005382
 >> iter 29000, loss: 0.005408
 >> iter 30000, loss: 0.005332
   Number of active neurons: 5
 >> iter 31000, loss: 0.005357
 >> iter 32000, loss: 0.005281
 >> iter 33000, loss: 0.005308
 >> iter 34000, loss: 0.005237
 >> iter 35000, loss: 0.005271
 >> iter 36000, loss: 0.005199
 >> iter 37000, loss: 0.005234
 >> iter 38000, loss: 0.005160
 >> iter 39000, loss: 0.005196
 >> iter 40000, loss: 0.005122
   Number of active neurons: 4
 >> iter 41000, loss: 0.005157
 >> iter 42000, loss: 0.005087
 >> iter 43000, loss: 0.005119
 >> iter 44000, loss: 0.005055
 >> iter 45000, loss: 0.005087
 >> iter 46000, loss: 0.005023
 >> iter 47000, loss: 0.005054
 >> iter 48000, loss: 0.004990
 >> iter 49000, loss: 0.005015
 >> iter 50000, loss: 0.004945
   Number of active neurons: 4
 >> iter 51000, loss: 0.004972
 >> iter 52000, loss: 0.004908
 >> iter 53000, loss: 0.004931
 >> iter 54000, loss: 0.004874
 >> iter 55000, loss: 0.004886
 >> iter 56000, loss: 0.004827
 >> iter 57000, loss: 0.004838
 >> iter 58000, loss: 0.004770
 >> iter 59000, loss: 0.004786
 >> iter 60000, loss: 0.004722
   Number of active neurons: 3
 >> iter 61000, loss: 0.004733
 >> iter 62000, loss: 0.004670
 >> iter 63000, loss: 0.004682
 >> iter 64000, loss: 0.004619
 >> iter 65000, loss: 0.004637
 >> iter 66000, loss: 0.004579
 >> iter 67000, loss: 0.004595
 >> iter 68000, loss: 0.004546
 >> iter 69000, loss: 0.004559
 >> iter 70000, loss: 0.004507
   Number of active neurons: 3
 >> iter 71000, loss: 0.004522
 >> iter 72000, loss: 0.004475
 >> iter 73000, loss: 0.004493
 >> iter 74000, loss: 0.004448
 >> iter 75000, loss: 0.004468
 >> iter 76000, loss: 0.004425
 >> iter 77000, loss: 0.004445
 >> iter 78000, loss: 0.004400
 >> iter 79000, loss: 0.004427
 >> iter 80000, loss: 0.004377
   Number of active neurons: 3
 >> iter 81000, loss: 0.004404
 >> iter 82000, loss: 0.004346
 >> iter 83000, loss: 0.004375
 >> iter 84000, loss: 0.004315
 >> iter 85000, loss: 0.004342
 >> iter 86000, loss: 0.004281
 >> iter 87000, loss: 0.004308
 >> iter 88000, loss: 0.004246
 >> iter 89000, loss: 0.004273
 >> iter 90000, loss: 0.004218
   Number of active neurons: 3
 >> iter 91000, loss: 0.004244
 >> iter 92000, loss: 0.004191
 >> iter 93000, loss: 0.004217
 >> iter 94000, loss: 0.004162
 >> iter 95000, loss: 0.004193
 >> iter 96000, loss: 0.004134
 >> iter 97000, loss: 0.004169
 >> iter 98000, loss: 0.004111
 >> iter 99000, loss: 0.004150
 >> iter 100000, loss: 0.004097
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.697004
 >> iter 2000, loss: 3.946962
 >> iter 3000, loss: 1.459901
 >> iter 4000, loss: 0.543297
 >> iter 5000, loss: 0.205370
 >> iter 6000, loss: 0.080416
 >> iter 7000, loss: 0.034143
 >> iter 8000, loss: 0.016768
 >> iter 9000, loss: 0.010250
 >> iter 10000, loss: 0.007625
   Number of active neurons: 5
 >> iter 11000, loss: 0.006614
 >> iter 12000, loss: 0.006077
 >> iter 13000, loss: 0.005879
 >> iter 14000, loss: 0.005666
 >> iter 15000, loss: 0.005615
 >> iter 16000, loss: 0.005479
 >> iter 17000, loss: 0.005469
 >> iter 18000, loss: 0.005364
 >> iter 19000, loss: 0.005370
 >> iter 20000, loss: 0.005284
   Number of active neurons: 5
 >> iter 21000, loss: 0.005296
 >> iter 22000, loss: 0.005215
 >> iter 23000, loss: 0.005234
 >> iter 24000, loss: 0.005156
 >> iter 25000, loss: 0.005179
 >> iter 26000, loss: 0.005102
 >> iter 27000, loss: 0.005126
 >> iter 28000, loss: 0.005058
 >> iter 29000, loss: 0.005085
 >> iter 30000, loss: 0.005022
   Number of active neurons: 5
 >> iter 31000, loss: 0.005052
 >> iter 32000, loss: 0.004989
 >> iter 33000, loss: 0.005019
 >> iter 34000, loss: 0.004959
 >> iter 35000, loss: 0.004994
 >> iter 36000, loss: 0.004932
 >> iter 37000, loss: 0.004969
 >> iter 38000, loss: 0.004909
 >> iter 39000, loss: 0.004951
 >> iter 40000, loss: 0.004892
   Number of active neurons: 4
 >> iter 41000, loss: 0.004935
 >> iter 42000, loss: 0.004881
 >> iter 43000, loss: 0.004921
 >> iter 44000, loss: 0.004872
 >> iter 45000, loss: 0.004911
 >> iter 46000, loss: 0.004862
 >> iter 47000, loss: 0.004901
 >> iter 48000, loss: 0.004854
 >> iter 49000, loss: 0.004893
 >> iter 50000, loss: 0.004843
   Number of active neurons: 4
 >> iter 51000, loss: 0.004883
 >> iter 52000, loss: 0.004835
 >> iter 53000, loss: 0.004869
 >> iter 54000, loss: 0.004827
 >> iter 55000, loss: 0.004849
 >> iter 56000, loss: 0.004804
 >> iter 57000, loss: 0.004830
 >> iter 58000, loss: 0.004780
 >> iter 59000, loss: 0.004811
 >> iter 60000, loss: 0.004763
   Number of active neurons: 4
 >> iter 61000, loss: 0.004788
 >> iter 62000, loss: 0.004740
 >> iter 63000, loss: 0.004764
 >> iter 64000, loss: 0.004712
 >> iter 65000, loss: 0.004740
 >> iter 66000, loss: 0.004691
 >> iter 67000, loss: 0.004716
 >> iter 68000, loss: 0.004674
 >> iter 69000, loss: 0.004695
 >> iter 70000, loss: 0.004652
   Number of active neurons: 4
 >> iter 71000, loss: 0.004678
 >> iter 72000, loss: 0.004640
 >> iter 73000, loss: 0.004666
 >> iter 74000, loss: 0.004628
 >> iter 75000, loss: 0.004657
 >> iter 76000, loss: 0.004620
 >> iter 77000, loss: 0.004649
 >> iter 78000, loss: 0.004612
 >> iter 79000, loss: 0.004648
 >> iter 80000, loss: 0.004608
   Number of active neurons: 3
 >> iter 81000, loss: 0.004649
 >> iter 82000, loss: 0.004605
 >> iter 83000, loss: 0.004648
 >> iter 84000, loss: 0.004601
 >> iter 85000, loss: 0.004643
 >> iter 86000, loss: 0.004596
 >> iter 87000, loss: 0.004639
 >> iter 88000, loss: 0.004591
 >> iter 89000, loss: 0.004632
 >> iter 90000, loss: 0.004589
   Number of active neurons: 3
 >> iter 91000, loss: 0.004627
 >> iter 92000, loss: 0.004584
 >> iter 93000, loss: 0.004621
 >> iter 94000, loss: 0.004575
 >> iter 95000, loss: 0.004617
 >> iter 96000, loss: 0.004565
 >> iter 97000, loss: 0.004607
 >> iter 98000, loss: 0.004552
 >> iter 99000, loss: 0.004595
 >> iter 100000, loss: 0.004544
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.706758
 >> iter 2000, loss: 3.948488
 >> iter 3000, loss: 1.459540
 >> iter 4000, loss: 0.542667
 >> iter 5000, loss: 0.204948
 >> iter 6000, loss: 0.080207
 >> iter 7000, loss: 0.034179
 >> iter 8000, loss: 0.016915
 >> iter 9000, loss: 0.010512
 >> iter 10000, loss: 0.007882
   Number of active neurons: 6
 >> iter 11000, loss: 0.006883
 >> iter 12000, loss: 0.006284
 >> iter 13000, loss: 0.006071
 >> iter 14000, loss: 0.005815
 >> iter 15000, loss: 0.005760
 >> iter 16000, loss: 0.005586
 >> iter 17000, loss: 0.005575
 >> iter 18000, loss: 0.005437
 >> iter 19000, loss: 0.005441
 >> iter 20000, loss: 0.005326
   Number of active neurons: 5
 >> iter 21000, loss: 0.005341
 >> iter 22000, loss: 0.005234
 >> iter 23000, loss: 0.005259
 >> iter 24000, loss: 0.005158
 >> iter 25000, loss: 0.005186
 >> iter 26000, loss: 0.005086
 >> iter 27000, loss: 0.005104
 >> iter 28000, loss: 0.005006
 >> iter 29000, loss: 0.005023
 >> iter 30000, loss: 0.004928
   Number of active neurons: 4
 >> iter 31000, loss: 0.004948
 >> iter 32000, loss: 0.004857
 >> iter 33000, loss: 0.004881
 >> iter 34000, loss: 0.004797
 >> iter 35000, loss: 0.004826
 >> iter 36000, loss: 0.004737
 >> iter 37000, loss: 0.004765
 >> iter 38000, loss: 0.004678
 >> iter 39000, loss: 0.004709
 >> iter 40000, loss: 0.004619
   Number of active neurons: 4
 >> iter 41000, loss: 0.004650
 >> iter 42000, loss: 0.004566
 >> iter 43000, loss: 0.004593
 >> iter 44000, loss: 0.004516
 >> iter 45000, loss: 0.004548
 >> iter 46000, loss: 0.004469
 >> iter 47000, loss: 0.004501
 >> iter 48000, loss: 0.004428
 >> iter 49000, loss: 0.004462
 >> iter 50000, loss: 0.004388
   Number of active neurons: 3
 >> iter 51000, loss: 0.004422
 >> iter 52000, loss: 0.004348
 >> iter 53000, loss: 0.004374
 >> iter 54000, loss: 0.004307
 >> iter 55000, loss: 0.004325
 >> iter 56000, loss: 0.004262
 >> iter 57000, loss: 0.004281
 >> iter 58000, loss: 0.004211
 >> iter 59000, loss: 0.004235
 >> iter 60000, loss: 0.004170
   Number of active neurons: 3
 >> iter 61000, loss: 0.004193
 >> iter 62000, loss: 0.004133
 >> iter 63000, loss: 0.004159
 >> iter 64000, loss: 0.004098
 >> iter 65000, loss: 0.004129
 >> iter 66000, loss: 0.004071
 >> iter 67000, loss: 0.004099
 >> iter 68000, loss: 0.004048
 >> iter 69000, loss: 0.004069
 >> iter 70000, loss: 0.004012
   Number of active neurons: 3
 >> iter 71000, loss: 0.004035
 >> iter 72000, loss: 0.003983
 >> iter 73000, loss: 0.004007
 >> iter 74000, loss: 0.003955
 >> iter 75000, loss: 0.003983
 >> iter 76000, loss: 0.003930
 >> iter 77000, loss: 0.003956
 >> iter 78000, loss: 0.003905
 >> iter 79000, loss: 0.003940
 >> iter 80000, loss: 0.003887
   Number of active neurons: 3
 >> iter 81000, loss: 0.003932
 >> iter 82000, loss: 0.003877
 >> iter 83000, loss: 0.003929
 >> iter 84000, loss: 0.003870
 >> iter 85000, loss: 0.003922
 >> iter 86000, loss: 0.003864
 >> iter 87000, loss: 0.003918
 >> iter 88000, loss: 0.003859
 >> iter 89000, loss: 0.003912
 >> iter 90000, loss: 0.003857
   Number of active neurons: 3
 >> iter 91000, loss: 0.003909
 >> iter 92000, loss: 0.003856
 >> iter 93000, loss: 0.003908
 >> iter 94000, loss: 0.003852
 >> iter 95000, loss: 0.003912
 >> iter 96000, loss: 0.003849
 >> iter 97000, loss: 0.003911
 >> iter 98000, loss: 0.003846
 >> iter 99000, loss: 0.003910
 >> iter 100000, loss: 0.003849
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.708578
 >> iter 2000, loss: 3.949892
 >> iter 3000, loss: 1.460342
 >> iter 4000, loss: 0.543091
 >> iter 5000, loss: 0.205066
 >> iter 6000, loss: 0.080149
 >> iter 7000, loss: 0.033967
 >> iter 8000, loss: 0.016672
 >> iter 9000, loss: 0.010216
 >> iter 10000, loss: 0.007627
   Number of active neurons: 7
 >> iter 11000, loss: 0.006645
 >> iter 12000, loss: 0.006125
 >> iter 13000, loss: 0.005950
 >> iter 14000, loss: 0.005752
 >> iter 15000, loss: 0.005718
 >> iter 16000, loss: 0.005594
 >> iter 17000, loss: 0.005603
 >> iter 18000, loss: 0.005506
 >> iter 19000, loss: 0.005528
 >> iter 20000, loss: 0.005450
   Number of active neurons: 6
 >> iter 21000, loss: 0.005481
 >> iter 22000, loss: 0.005411
 >> iter 23000, loss: 0.005451
 >> iter 24000, loss: 0.005384
 >> iter 25000, loss: 0.005429
 >> iter 26000, loss: 0.005366
 >> iter 27000, loss: 0.005412
 >> iter 28000, loss: 0.005356
 >> iter 29000, loss: 0.005402
 >> iter 30000, loss: 0.005347
   Number of active neurons: 6
 >> iter 31000, loss: 0.005393
 >> iter 32000, loss: 0.005334
 >> iter 33000, loss: 0.005376
 >> iter 34000, loss: 0.005316
 >> iter 35000, loss: 0.005363
 >> iter 36000, loss: 0.005300
 >> iter 37000, loss: 0.005346
 >> iter 38000, loss: 0.005281
 >> iter 39000, loss: 0.005329
 >> iter 40000, loss: 0.005261
   Number of active neurons: 6
 >> iter 41000, loss: 0.005306
 >> iter 42000, loss: 0.005241
 >> iter 43000, loss: 0.005281
 >> iter 44000, loss: 0.005222
 >> iter 45000, loss: 0.005262
 >> iter 46000, loss: 0.005204
 >> iter 47000, loss: 0.005245
 >> iter 48000, loss: 0.005193
 >> iter 49000, loss: 0.005236
 >> iter 50000, loss: 0.005182
   Number of active neurons: 5
 >> iter 51000, loss: 0.005227
 >> iter 52000, loss: 0.005176
 >> iter 53000, loss: 0.005217
 >> iter 54000, loss: 0.005174
 >> iter 55000, loss: 0.005206
 >> iter 56000, loss: 0.005165
 >> iter 57000, loss: 0.005200
 >> iter 58000, loss: 0.005151
 >> iter 59000, loss: 0.005189
 >> iter 60000, loss: 0.005141
   Number of active neurons: 4
 >> iter 61000, loss: 0.005173
 >> iter 62000, loss: 0.005126
 >> iter 63000, loss: 0.005157
 >> iter 64000, loss: 0.005103
 >> iter 65000, loss: 0.005131
 >> iter 66000, loss: 0.005074
 >> iter 67000, loss: 0.005099
 >> iter 68000, loss: 0.005049
 >> iter 69000, loss: 0.005069
 >> iter 70000, loss: 0.005015
   Number of active neurons: 4
 >> iter 71000, loss: 0.005035
 >> iter 72000, loss: 0.004981
 >> iter 73000, loss: 0.004994
 >> iter 74000, loss: 0.004933
 >> iter 75000, loss: 0.004947
 >> iter 76000, loss: 0.004888
 >> iter 77000, loss: 0.004902
 >> iter 78000, loss: 0.004844
 >> iter 79000, loss: 0.004866
 >> iter 80000, loss: 0.004803
   Number of active neurons: 4
 >> iter 81000, loss: 0.004828
 >> iter 82000, loss: 0.004764
 >> iter 83000, loss: 0.004794
 >> iter 84000, loss: 0.004730
 >> iter 85000, loss: 0.004761
 >> iter 86000, loss: 0.004700
 >> iter 87000, loss: 0.004734
 >> iter 88000, loss: 0.004674
 >> iter 89000, loss: 0.004709
 >> iter 90000, loss: 0.004656
   Number of active neurons: 4
 >> iter 91000, loss: 0.004692
 >> iter 92000, loss: 0.004644
 >> iter 93000, loss: 0.004681
 >> iter 94000, loss: 0.004632
 >> iter 95000, loss: 0.004677
 >> iter 96000, loss: 0.004623
 >> iter 97000, loss: 0.004670
 >> iter 98000, loss: 0.004616
 >> iter 99000, loss: 0.004666
 >> iter 100000, loss: 0.004617
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.736234
 >> iter 2000, loss: 3.959119
 >> iter 3000, loss: 1.463213
 >> iter 4000, loss: 0.543797
 >> iter 5000, loss: 0.205127
 >> iter 6000, loss: 0.080033
 >> iter 7000, loss: 0.033873
 >> iter 8000, loss: 0.016586
 >> iter 9000, loss: 0.010190
 >> iter 10000, loss: 0.007614
   Number of active neurons: 6
 >> iter 11000, loss: 0.006670
 >> iter 12000, loss: 0.006127
 >> iter 13000, loss: 0.005952
 >> iter 14000, loss: 0.005712
 >> iter 15000, loss: 0.005660
 >> iter 16000, loss: 0.005494
 >> iter 17000, loss: 0.005485
 >> iter 18000, loss: 0.005358
 >> iter 19000, loss: 0.005374
 >> iter 20000, loss: 0.005276
   Number of active neurons: 5
 >> iter 21000, loss: 0.005300
 >> iter 22000, loss: 0.005202
 >> iter 23000, loss: 0.005232
 >> iter 24000, loss: 0.005141
 >> iter 25000, loss: 0.005177
 >> iter 26000, loss: 0.005091
 >> iter 27000, loss: 0.005124
 >> iter 28000, loss: 0.005041
 >> iter 29000, loss: 0.005069
 >> iter 30000, loss: 0.004984
   Number of active neurons: 5
 >> iter 31000, loss: 0.005012
 >> iter 32000, loss: 0.004930
 >> iter 33000, loss: 0.004960
 >> iter 34000, loss: 0.004882
 >> iter 35000, loss: 0.004919
 >> iter 36000, loss: 0.004841
 >> iter 37000, loss: 0.004880
 >> iter 38000, loss: 0.004801
 >> iter 39000, loss: 0.004842
 >> iter 40000, loss: 0.004767
   Number of active neurons: 5
 >> iter 41000, loss: 0.004813
 >> iter 42000, loss: 0.004746
 >> iter 43000, loss: 0.004788
 >> iter 44000, loss: 0.004726
 >> iter 45000, loss: 0.004769
 >> iter 46000, loss: 0.004705
 >> iter 47000, loss: 0.004748
 >> iter 48000, loss: 0.004691
 >> iter 49000, loss: 0.004736
 >> iter 50000, loss: 0.004674
   Number of active neurons: 4
 >> iter 51000, loss: 0.004718
 >> iter 52000, loss: 0.004660
 >> iter 53000, loss: 0.004702
 >> iter 54000, loss: 0.004655
 >> iter 55000, loss: 0.004689
 >> iter 56000, loss: 0.004646
 >> iter 57000, loss: 0.004684
 >> iter 58000, loss: 0.004635
 >> iter 59000, loss: 0.004676
 >> iter 60000, loss: 0.004628
   Number of active neurons: 4
 >> iter 61000, loss: 0.004665
 >> iter 62000, loss: 0.004619
 >> iter 63000, loss: 0.004654
 >> iter 64000, loss: 0.004601
 >> iter 65000, loss: 0.004636
 >> iter 66000, loss: 0.004583
 >> iter 67000, loss: 0.004615
 >> iter 68000, loss: 0.004569
 >> iter 69000, loss: 0.004597
 >> iter 70000, loss: 0.004545
   Number of active neurons: 3
 >> iter 71000, loss: 0.004571
 >> iter 72000, loss: 0.004520
 >> iter 73000, loss: 0.004544
 >> iter 74000, loss: 0.004492
 >> iter 75000, loss: 0.004518
 >> iter 76000, loss: 0.004466
 >> iter 77000, loss: 0.004490
 >> iter 78000, loss: 0.004434
 >> iter 79000, loss: 0.004463
 >> iter 80000, loss: 0.004402
   Number of active neurons: 3
 >> iter 81000, loss: 0.004436
 >> iter 82000, loss: 0.004370
 >> iter 83000, loss: 0.004408
 >> iter 84000, loss: 0.004338
 >> iter 85000, loss: 0.004375
 >> iter 86000, loss: 0.004306
 >> iter 87000, loss: 0.004343
 >> iter 88000, loss: 0.004273
 >> iter 89000, loss: 0.004311
 >> iter 90000, loss: 0.004245
   Number of active neurons: 3
 >> iter 91000, loss: 0.004277
 >> iter 92000, loss: 0.004213
 >> iter 93000, loss: 0.004248
 >> iter 94000, loss: 0.004182
 >> iter 95000, loss: 0.004225
 >> iter 96000, loss: 0.004154
 >> iter 97000, loss: 0.004196
 >> iter 98000, loss: 0.004122
 >> iter 99000, loss: 0.004167
 >> iter 100000, loss: 0.004098
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.710726
 >> iter 2000, loss: 3.949781
 >> iter 3000, loss: 1.459854
 >> iter 4000, loss: 0.542639
 >> iter 5000, loss: 0.204787
 >> iter 6000, loss: 0.079992
 >> iter 7000, loss: 0.033920
 >> iter 8000, loss: 0.016653
 >> iter 9000, loss: 0.010244
 >> iter 10000, loss: 0.007658
   Number of active neurons: 7
 >> iter 11000, loss: 0.006700
 >> iter 12000, loss: 0.006166
 >> iter 13000, loss: 0.006004
 >> iter 14000, loss: 0.005791
 >> iter 15000, loss: 0.005763
 >> iter 16000, loss: 0.005625
 >> iter 17000, loss: 0.005637
 >> iter 18000, loss: 0.005532
 >> iter 19000, loss: 0.005560
 >> iter 20000, loss: 0.005478
   Number of active neurons: 6
 >> iter 21000, loss: 0.005514
 >> iter 22000, loss: 0.005437
 >> iter 23000, loss: 0.005482
 >> iter 24000, loss: 0.005410
 >> iter 25000, loss: 0.005455
 >> iter 26000, loss: 0.005382
 >> iter 27000, loss: 0.005423
 >> iter 28000, loss: 0.005356
 >> iter 29000, loss: 0.005397
 >> iter 30000, loss: 0.005332
   Number of active neurons: 6
 >> iter 31000, loss: 0.005371
 >> iter 32000, loss: 0.005300
 >> iter 33000, loss: 0.005339
 >> iter 34000, loss: 0.005271
 >> iter 35000, loss: 0.005311
 >> iter 36000, loss: 0.005234
 >> iter 37000, loss: 0.005271
 >> iter 38000, loss: 0.005195
 >> iter 39000, loss: 0.005237
 >> iter 40000, loss: 0.005159
   Number of active neurons: 5
 >> iter 41000, loss: 0.005200
 >> iter 42000, loss: 0.005129
 >> iter 43000, loss: 0.005166
 >> iter 44000, loss: 0.005100
 >> iter 45000, loss: 0.005135
 >> iter 46000, loss: 0.005067
 >> iter 47000, loss: 0.005101
 >> iter 48000, loss: 0.005036
 >> iter 49000, loss: 0.005070
 >> iter 50000, loss: 0.005002
   Number of active neurons: 4
 >> iter 51000, loss: 0.005035
 >> iter 52000, loss: 0.004970
 >> iter 53000, loss: 0.004998
 >> iter 54000, loss: 0.004939
 >> iter 55000, loss: 0.004953
 >> iter 56000, loss: 0.004896
 >> iter 57000, loss: 0.004917
 >> iter 58000, loss: 0.004856
 >> iter 59000, loss: 0.004880
 >> iter 60000, loss: 0.004816
   Number of active neurons: 4
 >> iter 61000, loss: 0.004833
 >> iter 62000, loss: 0.004774
 >> iter 63000, loss: 0.004794
 >> iter 64000, loss: 0.004733
 >> iter 65000, loss: 0.004756
 >> iter 66000, loss: 0.004696
 >> iter 67000, loss: 0.004716
 >> iter 68000, loss: 0.004664
 >> iter 69000, loss: 0.004681
 >> iter 70000, loss: 0.004625
   Number of active neurons: 3
 >> iter 71000, loss: 0.004641
 >> iter 72000, loss: 0.004588
 >> iter 73000, loss: 0.004604
 >> iter 74000, loss: 0.004550
 >> iter 75000, loss: 0.004565
 >> iter 76000, loss: 0.004510
 >> iter 77000, loss: 0.004525
 >> iter 78000, loss: 0.004471
 >> iter 79000, loss: 0.004494
 >> iter 80000, loss: 0.004435
   Number of active neurons: 3
 >> iter 81000, loss: 0.004461
 >> iter 82000, loss: 0.004397
 >> iter 83000, loss: 0.004428
 >> iter 84000, loss: 0.004363
 >> iter 85000, loss: 0.004395
 >> iter 86000, loss: 0.004334
 >> iter 87000, loss: 0.004368
 >> iter 88000, loss: 0.004307
 >> iter 89000, loss: 0.004338
 >> iter 90000, loss: 0.004277
   Number of active neurons: 3
 >> iter 91000, loss: 0.004305
 >> iter 92000, loss: 0.004247
 >> iter 93000, loss: 0.004276
 >> iter 94000, loss: 0.004214
 >> iter 95000, loss: 0.004247
 >> iter 96000, loss: 0.004181
 >> iter 97000, loss: 0.004217
 >> iter 98000, loss: 0.004151
 >> iter 99000, loss: 0.004191
 >> iter 100000, loss: 0.004131
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.695882
 >> iter 2000, loss: 3.944362
 >> iter 3000, loss: 1.457906
 >> iter 4000, loss: 0.541979
 >> iter 5000, loss: 0.204618
 >> iter 6000, loss: 0.080000
 >> iter 7000, loss: 0.033976
 >> iter 8000, loss: 0.016712
 >> iter 9000, loss: 0.010296
 >> iter 10000, loss: 0.007698
   Number of active neurons: 5
 >> iter 11000, loss: 0.006727
 >> iter 12000, loss: 0.006170
 >> iter 13000, loss: 0.005973
 >> iter 14000, loss: 0.005739
 >> iter 15000, loss: 0.005684
 >> iter 16000, loss: 0.005528
 >> iter 17000, loss: 0.005522
 >> iter 18000, loss: 0.005404
 >> iter 19000, loss: 0.005419
 >> iter 20000, loss: 0.005324
   Number of active neurons: 5
 >> iter 21000, loss: 0.005348
 >> iter 22000, loss: 0.005251
 >> iter 23000, loss: 0.005273
 >> iter 24000, loss: 0.005174
 >> iter 25000, loss: 0.005200
 >> iter 26000, loss: 0.005105
 >> iter 27000, loss: 0.005125
 >> iter 28000, loss: 0.005031
 >> iter 29000, loss: 0.005047
 >> iter 30000, loss: 0.004952
   Number of active neurons: 4
 >> iter 31000, loss: 0.004967
 >> iter 32000, loss: 0.004874
 >> iter 33000, loss: 0.004889
 >> iter 34000, loss: 0.004795
 >> iter 35000, loss: 0.004811
 >> iter 36000, loss: 0.004717
 >> iter 37000, loss: 0.004740
 >> iter 38000, loss: 0.004652
 >> iter 39000, loss: 0.004683
 >> iter 40000, loss: 0.004601
   Number of active neurons: 4
 >> iter 41000, loss: 0.004636
 >> iter 42000, loss: 0.004563
 >> iter 43000, loss: 0.004598
 >> iter 44000, loss: 0.004532
 >> iter 45000, loss: 0.004571
 >> iter 46000, loss: 0.004504
 >> iter 47000, loss: 0.004543
 >> iter 48000, loss: 0.004482
 >> iter 49000, loss: 0.004522
 >> iter 50000, loss: 0.004457
   Number of active neurons: 4
 >> iter 51000, loss: 0.004496
 >> iter 52000, loss: 0.004434
 >> iter 53000, loss: 0.004470
 >> iter 54000, loss: 0.004418
 >> iter 55000, loss: 0.004447
 >> iter 56000, loss: 0.004399
 >> iter 57000, loss: 0.004432
 >> iter 58000, loss: 0.004379
 >> iter 59000, loss: 0.004418
 >> iter 60000, loss: 0.004369
   Number of active neurons: 4
 >> iter 61000, loss: 0.004406
 >> iter 62000, loss: 0.004362
 >> iter 63000, loss: 0.004400
 >> iter 64000, loss: 0.004353
 >> iter 65000, loss: 0.004396
 >> iter 66000, loss: 0.004351
 >> iter 67000, loss: 0.004390
 >> iter 68000, loss: 0.004353
 >> iter 69000, loss: 0.004388
 >> iter 70000, loss: 0.004348
   Number of active neurons: 4
 >> iter 71000, loss: 0.004387
 >> iter 72000, loss: 0.004349
 >> iter 73000, loss: 0.004386
 >> iter 74000, loss: 0.004347
 >> iter 75000, loss: 0.004386
 >> iter 76000, loss: 0.004346
 >> iter 77000, loss: 0.004384
 >> iter 78000, loss: 0.004343
 >> iter 79000, loss: 0.004389
 >> iter 80000, loss: 0.004344
   Number of active neurons: 4
 >> iter 81000, loss: 0.004395
 >> iter 82000, loss: 0.004344
 >> iter 83000, loss: 0.004399
 >> iter 84000, loss: 0.004343
 >> iter 85000, loss: 0.004397
 >> iter 86000, loss: 0.004341
 >> iter 87000, loss: 0.004396
 >> iter 88000, loss: 0.004340
 >> iter 89000, loss: 0.004394
 >> iter 90000, loss: 0.004342
   Number of active neurons: 4
 >> iter 91000, loss: 0.004393
 >> iter 92000, loss: 0.004343
 >> iter 93000, loss: 0.004394
 >> iter 94000, loss: 0.004340
 >> iter 95000, loss: 0.004398
 >> iter 96000, loss: 0.004338
 >> iter 97000, loss: 0.004398
 >> iter 98000, loss: 0.004335
 >> iter 99000, loss: 0.004397
 >> iter 100000, loss: 0.004338
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.748609
 >> iter 2000, loss: 3.964100
 >> iter 3000, loss: 1.465369
 >> iter 4000, loss: 0.544862
 >> iter 5000, loss: 0.205764
 >> iter 6000, loss: 0.080497
 >> iter 7000, loss: 0.034240
 >> iter 8000, loss: 0.016903
 >> iter 9000, loss: 0.010459
 >> iter 10000, loss: 0.007850
   Number of active neurons: 7
 >> iter 11000, loss: 0.006870
 >> iter 12000, loss: 0.006308
 >> iter 13000, loss: 0.006116
 >> iter 14000, loss: 0.005882
 >> iter 15000, loss: 0.005832
 >> iter 16000, loss: 0.005680
 >> iter 17000, loss: 0.005672
 >> iter 18000, loss: 0.005551
 >> iter 19000, loss: 0.005557
 >> iter 20000, loss: 0.005459
   Number of active neurons: 5
 >> iter 21000, loss: 0.005483
 >> iter 22000, loss: 0.005397
 >> iter 23000, loss: 0.005430
 >> iter 24000, loss: 0.005346
 >> iter 25000, loss: 0.005382
 >> iter 26000, loss: 0.005303
 >> iter 27000, loss: 0.005334
 >> iter 28000, loss: 0.005247
 >> iter 29000, loss: 0.005259
 >> iter 30000, loss: 0.005165
   Number of active neurons: 4
 >> iter 31000, loss: 0.005181
 >> iter 32000, loss: 0.005093
 >> iter 33000, loss: 0.005114
 >> iter 34000, loss: 0.005032
 >> iter 35000, loss: 0.005059
 >> iter 36000, loss: 0.004976
 >> iter 37000, loss: 0.005004
 >> iter 38000, loss: 0.004913
 >> iter 39000, loss: 0.004935
 >> iter 40000, loss: 0.004843
   Number of active neurons: 4
 >> iter 41000, loss: 0.004867
 >> iter 42000, loss: 0.004779
 >> iter 43000, loss: 0.004796
 >> iter 44000, loss: 0.004712
 >> iter 45000, loss: 0.004730
 >> iter 46000, loss: 0.004647
 >> iter 47000, loss: 0.004665
 >> iter 48000, loss: 0.004587
 >> iter 49000, loss: 0.004609
 >> iter 50000, loss: 0.004533
   Number of active neurons: 3
 >> iter 51000, loss: 0.004559
 >> iter 52000, loss: 0.004487
 >> iter 53000, loss: 0.004508
 >> iter 54000, loss: 0.004447
 >> iter 55000, loss: 0.004462
 >> iter 56000, loss: 0.004402
 >> iter 57000, loss: 0.004417
 >> iter 58000, loss: 0.004347
 >> iter 59000, loss: 0.004364
 >> iter 60000, loss: 0.004300
   Number of active neurons: 3
 >> iter 61000, loss: 0.004318
 >> iter 62000, loss: 0.004261
 >> iter 63000, loss: 0.004283
 >> iter 64000, loss: 0.004225
 >> iter 65000, loss: 0.004253
 >> iter 66000, loss: 0.004198
 >> iter 67000, loss: 0.004223
 >> iter 68000, loss: 0.004175
 >> iter 69000, loss: 0.004198
 >> iter 70000, loss: 0.004148
   Number of active neurons: 3
 >> iter 71000, loss: 0.004172
 >> iter 72000, loss: 0.004122
 >> iter 73000, loss: 0.004143
 >> iter 74000, loss: 0.004092
 >> iter 75000, loss: 0.004115
 >> iter 76000, loss: 0.004065
 >> iter 77000, loss: 0.004089
 >> iter 78000, loss: 0.004039
 >> iter 79000, loss: 0.004070
 >> iter 80000, loss: 0.004016
   Number of active neurons: 3
 >> iter 81000, loss: 0.004054
 >> iter 82000, loss: 0.003995
 >> iter 83000, loss: 0.004038
 >> iter 84000, loss: 0.003978
 >> iter 85000, loss: 0.004022
 >> iter 86000, loss: 0.003964
 >> iter 87000, loss: 0.004010
 >> iter 88000, loss: 0.003953
 >> iter 89000, loss: 0.003999
 >> iter 90000, loss: 0.003946
   Number of active neurons: 3
 >> iter 91000, loss: 0.003991
 >> iter 92000, loss: 0.003941
 >> iter 93000, loss: 0.003987
 >> iter 94000, loss: 0.003934
 >> iter 95000, loss: 0.003987
 >> iter 96000, loss: 0.003929
 >> iter 97000, loss: 0.003984
 >> iter 98000, loss: 0.003923
 >> iter 99000, loss: 0.003981
 >> iter 100000, loss: 0.003924
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.734150
 >> iter 2000, loss: 3.959064
 >> iter 3000, loss: 1.463515
 >> iter 4000, loss: 0.544064
 >> iter 5000, loss: 0.205269
 >> iter 6000, loss: 0.080084
 >> iter 7000, loss: 0.033817
 >> iter 8000, loss: 0.016472
 >> iter 9000, loss: 0.010005
 >> iter 10000, loss: 0.007409
   Number of active neurons: 5
 >> iter 11000, loss: 0.006434
 >> iter 12000, loss: 0.005904
 >> iter 13000, loss: 0.005726
 >> iter 14000, loss: 0.005521
 >> iter 15000, loss: 0.005490
 >> iter 16000, loss: 0.005360
 >> iter 17000, loss: 0.005365
 >> iter 18000, loss: 0.005262
 >> iter 19000, loss: 0.005279
 >> iter 20000, loss: 0.005194
   Number of active neurons: 5
 >> iter 21000, loss: 0.005214
 >> iter 22000, loss: 0.005131
 >> iter 23000, loss: 0.005157
 >> iter 24000, loss: 0.005075
 >> iter 25000, loss: 0.005108
 >> iter 26000, loss: 0.005034
 >> iter 27000, loss: 0.005066
 >> iter 28000, loss: 0.004995
 >> iter 29000, loss: 0.005024
 >> iter 30000, loss: 0.004953
   Number of active neurons: 5
 >> iter 31000, loss: 0.004981
 >> iter 32000, loss: 0.004906
 >> iter 33000, loss: 0.004931
 >> iter 34000, loss: 0.004858
 >> iter 35000, loss: 0.004890
 >> iter 36000, loss: 0.004820
 >> iter 37000, loss: 0.004856
 >> iter 38000, loss: 0.004789
 >> iter 39000, loss: 0.004832
 >> iter 40000, loss: 0.004769
   Number of active neurons: 5
 >> iter 41000, loss: 0.004815
 >> iter 42000, loss: 0.004758
 >> iter 43000, loss: 0.004801
 >> iter 44000, loss: 0.004750
 >> iter 45000, loss: 0.004795
 >> iter 46000, loss: 0.004741
 >> iter 47000, loss: 0.004782
 >> iter 48000, loss: 0.004732
 >> iter 49000, loss: 0.004776
 >> iter 50000, loss: 0.004725
   Number of active neurons: 4
 >> iter 51000, loss: 0.004770
 >> iter 52000, loss: 0.004721
 >> iter 53000, loss: 0.004760
 >> iter 54000, loss: 0.004717
 >> iter 55000, loss: 0.004748
 >> iter 56000, loss: 0.004708
 >> iter 57000, loss: 0.004743
 >> iter 58000, loss: 0.004697
 >> iter 59000, loss: 0.004735
 >> iter 60000, loss: 0.004690
   Number of active neurons: 4
 >> iter 61000, loss: 0.004724
 >> iter 62000, loss: 0.004680
 >> iter 63000, loss: 0.004713
 >> iter 64000, loss: 0.004665
 >> iter 65000, loss: 0.004700
 >> iter 66000, loss: 0.004652
 >> iter 67000, loss: 0.004680
 >> iter 68000, loss: 0.004634
 >> iter 69000, loss: 0.004656
 >> iter 70000, loss: 0.004608
   Number of active neurons: 4
 >> iter 71000, loss: 0.004633
 >> iter 72000, loss: 0.004587
 >> iter 73000, loss: 0.004609
 >> iter 74000, loss: 0.004558
 >> iter 75000, loss: 0.004580
 >> iter 76000, loss: 0.004530
 >> iter 77000, loss: 0.004551
 >> iter 78000, loss: 0.004501
 >> iter 79000, loss: 0.004530
 >> iter 80000, loss: 0.004477
   Number of active neurons: 3
 >> iter 81000, loss: 0.004510
 >> iter 82000, loss: 0.004453
 >> iter 83000, loss: 0.004491
 >> iter 84000, loss: 0.004432
 >> iter 85000, loss: 0.004470
 >> iter 86000, loss: 0.004414
 >> iter 87000, loss: 0.004453
 >> iter 88000, loss: 0.004395
 >> iter 89000, loss: 0.004432
 >> iter 90000, loss: 0.004378
   Number of active neurons: 3
 >> iter 91000, loss: 0.004414
 >> iter 92000, loss: 0.004363
 >> iter 93000, loss: 0.004398
 >> iter 94000, loss: 0.004345
 >> iter 95000, loss: 0.004386
 >> iter 96000, loss: 0.004327
 >> iter 97000, loss: 0.004368
 >> iter 98000, loss: 0.004306
 >> iter 99000, loss: 0.004347
 >> iter 100000, loss: 0.004283
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.727733
 >> iter 2000, loss: 3.957270
 >> iter 3000, loss: 1.463284
 >> iter 4000, loss: 0.544359
 >> iter 5000, loss: 0.205714
 >> iter 6000, loss: 0.080543
 >> iter 7000, loss: 0.034238
 >> iter 8000, loss: 0.016863
 >> iter 9000, loss: 0.010362
 >> iter 10000, loss: 0.007744
   Number of active neurons: 5
 >> iter 11000, loss: 0.006745
 >> iter 12000, loss: 0.006205
 >> iter 13000, loss: 0.006015
 >> iter 14000, loss: 0.005804
 >> iter 15000, loss: 0.005762
 >> iter 16000, loss: 0.005628
 >> iter 17000, loss: 0.005625
 >> iter 18000, loss: 0.005515
 >> iter 19000, loss: 0.005519
 >> iter 20000, loss: 0.005425
   Number of active neurons: 4
 >> iter 21000, loss: 0.005431
 >> iter 22000, loss: 0.005338
 >> iter 23000, loss: 0.005345
 >> iter 24000, loss: 0.005247
 >> iter 25000, loss: 0.005249
 >> iter 26000, loss: 0.005150
 >> iter 27000, loss: 0.005151
 >> iter 28000, loss: 0.005058
 >> iter 29000, loss: 0.005064
 >> iter 30000, loss: 0.004977
   Number of active neurons: 4
 >> iter 31000, loss: 0.004987
 >> iter 32000, loss: 0.004902
 >> iter 33000, loss: 0.004914
 >> iter 34000, loss: 0.004834
 >> iter 35000, loss: 0.004853
 >> iter 36000, loss: 0.004775
 >> iter 37000, loss: 0.004800
 >> iter 38000, loss: 0.004727
 >> iter 39000, loss: 0.004755
 >> iter 40000, loss: 0.004683
   Number of active neurons: 4
 >> iter 41000, loss: 0.004714
 >> iter 42000, loss: 0.004648
 >> iter 43000, loss: 0.004679
 >> iter 44000, loss: 0.004619
 >> iter 45000, loss: 0.004648
 >> iter 46000, loss: 0.004586
 >> iter 47000, loss: 0.004614
 >> iter 48000, loss: 0.004558
 >> iter 49000, loss: 0.004590
 >> iter 50000, loss: 0.004535
   Number of active neurons: 4
 >> iter 51000, loss: 0.004569
 >> iter 52000, loss: 0.004518
 >> iter 53000, loss: 0.004551
 >> iter 54000, loss: 0.004511
 >> iter 55000, loss: 0.004539
 >> iter 56000, loss: 0.004502
 >> iter 57000, loss: 0.004535
 >> iter 58000, loss: 0.004494
 >> iter 59000, loss: 0.004532
 >> iter 60000, loss: 0.004493
   Number of active neurons: 4
 >> iter 61000, loss: 0.004528
 >> iter 62000, loss: 0.004492
 >> iter 63000, loss: 0.004529
 >> iter 64000, loss: 0.004489
 >> iter 65000, loss: 0.004529
 >> iter 66000, loss: 0.004491
 >> iter 67000, loss: 0.004528
 >> iter 68000, loss: 0.004497
 >> iter 69000, loss: 0.004530
 >> iter 70000, loss: 0.004496
   Number of active neurons: 4
 >> iter 71000, loss: 0.004532
 >> iter 72000, loss: 0.004501
 >> iter 73000, loss: 0.004535
 >> iter 74000, loss: 0.004502
 >> iter 75000, loss: 0.004538
 >> iter 76000, loss: 0.004505
 >> iter 77000, loss: 0.004539
 >> iter 78000, loss: 0.004505
 >> iter 79000, loss: 0.004547
 >> iter 80000, loss: 0.004509
   Number of active neurons: 4
 >> iter 81000, loss: 0.004555
 >> iter 82000, loss: 0.004512
 >> iter 83000, loss: 0.004562
 >> iter 84000, loss: 0.004515
 >> iter 85000, loss: 0.004563
 >> iter 86000, loss: 0.004517
 >> iter 87000, loss: 0.004566
 >> iter 88000, loss: 0.004519
 >> iter 89000, loss: 0.004567
 >> iter 90000, loss: 0.004525
   Number of active neurons: 4
 >> iter 91000, loss: 0.004571
 >> iter 92000, loss: 0.004530
 >> iter 93000, loss: 0.004575
 >> iter 94000, loss: 0.004531
 >> iter 95000, loss: 0.004582
 >> iter 96000, loss: 0.004532
 >> iter 97000, loss: 0.004585
 >> iter 98000, loss: 0.004534
 >> iter 99000, loss: 0.004589
 >> iter 100000, loss: 0.004541
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.712334
 >> iter 2000, loss: 3.950285
 >> iter 3000, loss: 1.460036
 >> iter 4000, loss: 0.542707
 >> iter 5000, loss: 0.204808
 >> iter 6000, loss: 0.079965
 >> iter 7000, loss: 0.033866
 >> iter 8000, loss: 0.016577
 >> iter 9000, loss: 0.010164
 >> iter 10000, loss: 0.007556
   Number of active neurons: 7
 >> iter 11000, loss: 0.006573
 >> iter 12000, loss: 0.006012
 >> iter 13000, loss: 0.005828
 >> iter 14000, loss: 0.005604
 >> iter 15000, loss: 0.005570
 >> iter 16000, loss: 0.005424
 >> iter 17000, loss: 0.005428
 >> iter 18000, loss: 0.005314
 >> iter 19000, loss: 0.005338
 >> iter 20000, loss: 0.005252
   Number of active neurons: 6
 >> iter 21000, loss: 0.005288
 >> iter 22000, loss: 0.005212
 >> iter 23000, loss: 0.005259
 >> iter 24000, loss: 0.005186
 >> iter 25000, loss: 0.005236
 >> iter 26000, loss: 0.005168
 >> iter 27000, loss: 0.005214
 >> iter 28000, loss: 0.005148
 >> iter 29000, loss: 0.005197
 >> iter 30000, loss: 0.005138
   Number of active neurons: 6
 >> iter 31000, loss: 0.005190
 >> iter 32000, loss: 0.005131
 >> iter 33000, loss: 0.005183
 >> iter 34000, loss: 0.005123
 >> iter 35000, loss: 0.005176
 >> iter 36000, loss: 0.005112
 >> iter 37000, loss: 0.005163
 >> iter 38000, loss: 0.005095
 >> iter 39000, loss: 0.005148
 >> iter 40000, loss: 0.005077
   Number of active neurons: 5
 >> iter 41000, loss: 0.005126
 >> iter 42000, loss: 0.005058
 >> iter 43000, loss: 0.005099
 >> iter 44000, loss: 0.005033
 >> iter 45000, loss: 0.005071
 >> iter 46000, loss: 0.004999
 >> iter 47000, loss: 0.005034
 >> iter 48000, loss: 0.004967
 >> iter 49000, loss: 0.005005
 >> iter 50000, loss: 0.004939
   Number of active neurons: 4
 >> iter 51000, loss: 0.004978
 >> iter 52000, loss: 0.004914
 >> iter 53000, loss: 0.004945
 >> iter 54000, loss: 0.004887
 >> iter 55000, loss: 0.004908
 >> iter 56000, loss: 0.004850
 >> iter 57000, loss: 0.004872
 >> iter 58000, loss: 0.004807
 >> iter 59000, loss: 0.004832
 >> iter 60000, loss: 0.004765
   Number of active neurons: 3
 >> iter 61000, loss: 0.004783
 >> iter 62000, loss: 0.004715
 >> iter 63000, loss: 0.004729
 >> iter 64000, loss: 0.004657
 >> iter 65000, loss: 0.004676
 >> iter 66000, loss: 0.004604
 >> iter 67000, loss: 0.004617
 >> iter 68000, loss: 0.004552
 >> iter 69000, loss: 0.004560
 >> iter 70000, loss: 0.004492
   Number of active neurons: 3
 >> iter 71000, loss: 0.004499
 >> iter 72000, loss: 0.004428
 >> iter 73000, loss: 0.004432
 >> iter 74000, loss: 0.004361
 >> iter 75000, loss: 0.004370
 >> iter 76000, loss: 0.004303
 >> iter 77000, loss: 0.004314
 >> iter 78000, loss: 0.004249
 >> iter 79000, loss: 0.004268
 >> iter 80000, loss: 0.004198
   Number of active neurons: 3
 >> iter 81000, loss: 0.004223
 >> iter 82000, loss: 0.004151
 >> iter 83000, loss: 0.004182
 >> iter 84000, loss: 0.004110
 >> iter 85000, loss: 0.004144
 >> iter 86000, loss: 0.004075
 >> iter 87000, loss: 0.004111
 >> iter 88000, loss: 0.004044
 >> iter 89000, loss: 0.004081
 >> iter 90000, loss: 0.004020
   Number of active neurons: 3
 >> iter 91000, loss: 0.004058
 >> iter 92000, loss: 0.004002
 >> iter 93000, loss: 0.004043
 >> iter 94000, loss: 0.003986
 >> iter 95000, loss: 0.004035
 >> iter 96000, loss: 0.003974
 >> iter 97000, loss: 0.004026
 >> iter 98000, loss: 0.003964
 >> iter 99000, loss: 0.004019
 >> iter 100000, loss: 0.003961
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.688099
 >> iter 2000, loss: 3.942986
 >> iter 3000, loss: 1.458023
 >> iter 4000, loss: 0.542276
 >> iter 5000, loss: 0.204719
 >> iter 6000, loss: 0.079922
 >> iter 7000, loss: 0.033737
 >> iter 8000, loss: 0.016405
 >> iter 9000, loss: 0.009918
 >> iter 10000, loss: 0.007310
   Number of active neurons: 5
 >> iter 11000, loss: 0.006312
 >> iter 12000, loss: 0.005783
 >> iter 13000, loss: 0.005599
 >> iter 14000, loss: 0.005400
 >> iter 15000, loss: 0.005363
 >> iter 16000, loss: 0.005244
 >> iter 17000, loss: 0.005249
 >> iter 18000, loss: 0.005160
 >> iter 19000, loss: 0.005176
 >> iter 20000, loss: 0.005102
   Number of active neurons: 5
 >> iter 21000, loss: 0.005124
 >> iter 22000, loss: 0.005052
 >> iter 23000, loss: 0.005079
 >> iter 24000, loss: 0.005009
 >> iter 25000, loss: 0.005041
 >> iter 26000, loss: 0.004977
 >> iter 27000, loss: 0.005010
 >> iter 28000, loss: 0.004947
 >> iter 29000, loss: 0.004977
 >> iter 30000, loss: 0.004916
   Number of active neurons: 5
 >> iter 31000, loss: 0.004948
 >> iter 32000, loss: 0.004888
 >> iter 33000, loss: 0.004921
 >> iter 34000, loss: 0.004863
 >> iter 35000, loss: 0.004901
 >> iter 36000, loss: 0.004841
 >> iter 37000, loss: 0.004879
 >> iter 38000, loss: 0.004818
 >> iter 39000, loss: 0.004861
 >> iter 40000, loss: 0.004803
   Number of active neurons: 5
 >> iter 41000, loss: 0.004848
 >> iter 42000, loss: 0.004795
 >> iter 43000, loss: 0.004837
 >> iter 44000, loss: 0.004789
 >> iter 45000, loss: 0.004832
 >> iter 46000, loss: 0.004783
 >> iter 47000, loss: 0.004824
 >> iter 48000, loss: 0.004778
 >> iter 49000, loss: 0.004820
 >> iter 50000, loss: 0.004771
   Number of active neurons: 3
 >> iter 51000, loss: 0.004814
 >> iter 52000, loss: 0.004767
 >> iter 53000, loss: 0.004804
 >> iter 54000, loss: 0.004765
 >> iter 55000, loss: 0.004793
 >> iter 56000, loss: 0.004755
 >> iter 57000, loss: 0.004785
 >> iter 58000, loss: 0.004737
 >> iter 59000, loss: 0.004767
 >> iter 60000, loss: 0.004720
   Number of active neurons: 3
 >> iter 61000, loss: 0.004747
 >> iter 62000, loss: 0.004702
 >> iter 63000, loss: 0.004729
 >> iter 64000, loss: 0.004678
 >> iter 65000, loss: 0.004705
 >> iter 66000, loss: 0.004655
 >> iter 67000, loss: 0.004674
 >> iter 68000, loss: 0.004623
 >> iter 69000, loss: 0.004634
 >> iter 70000, loss: 0.004578
   Number of active neurons: 3
 >> iter 71000, loss: 0.004589
 >> iter 72000, loss: 0.004531
 >> iter 73000, loss: 0.004538
 >> iter 74000, loss: 0.004477
 >> iter 75000, loss: 0.004484
 >> iter 76000, loss: 0.004421
 >> iter 77000, loss: 0.004426
 >> iter 78000, loss: 0.004364
 >> iter 79000, loss: 0.004378
 >> iter 80000, loss: 0.004316
   Number of active neurons: 3
 >> iter 81000, loss: 0.004334
 >> iter 82000, loss: 0.004271
 >> iter 83000, loss: 0.004294
 >> iter 84000, loss: 0.004230
 >> iter 85000, loss: 0.004254
 >> iter 86000, loss: 0.004194
 >> iter 87000, loss: 0.004224
 >> iter 88000, loss: 0.004168
 >> iter 89000, loss: 0.004199
 >> iter 90000, loss: 0.004150
   Number of active neurons: 3
 >> iter 91000, loss: 0.004182
 >> iter 92000, loss: 0.004137
 >> iter 93000, loss: 0.004170
 >> iter 94000, loss: 0.004124
 >> iter 95000, loss: 0.004165
 >> iter 96000, loss: 0.004114
 >> iter 97000, loss: 0.004157
 >> iter 98000, loss: 0.004106
 >> iter 99000, loss: 0.004152
 >> iter 100000, loss: 0.004106
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.669713
 >> iter 2000, loss: 3.936965
 >> iter 3000, loss: 1.456323
 >> iter 4000, loss: 0.542083
 >> iter 5000, loss: 0.205028
 >> iter 6000, loss: 0.080391
 >> iter 7000, loss: 0.034245
 >> iter 8000, loss: 0.016908
 >> iter 9000, loss: 0.010400
 >> iter 10000, loss: 0.007774
   Number of active neurons: 4
 >> iter 11000, loss: 0.006764
 >> iter 12000, loss: 0.006222
 >> iter 13000, loss: 0.006026
 >> iter 14000, loss: 0.005813
 >> iter 15000, loss: 0.005760
 >> iter 16000, loss: 0.005620
 >> iter 17000, loss: 0.005601
 >> iter 18000, loss: 0.005483
 >> iter 19000, loss: 0.005474
 >> iter 20000, loss: 0.005375
   Number of active neurons: 4
 >> iter 21000, loss: 0.005371
 >> iter 22000, loss: 0.005276
 >> iter 23000, loss: 0.005282
 >> iter 24000, loss: 0.005194
 >> iter 25000, loss: 0.005207
 >> iter 26000, loss: 0.005125
 >> iter 27000, loss: 0.005139
 >> iter 28000, loss: 0.005062
 >> iter 29000, loss: 0.005075
 >> iter 30000, loss: 0.005000
   Number of active neurons: 4
 >> iter 31000, loss: 0.005007
 >> iter 32000, loss: 0.004926
 >> iter 33000, loss: 0.004937
 >> iter 34000, loss: 0.004862
 >> iter 35000, loss: 0.004881
 >> iter 36000, loss: 0.004804
 >> iter 37000, loss: 0.004823
 >> iter 38000, loss: 0.004745
 >> iter 39000, loss: 0.004765
 >> iter 40000, loss: 0.004687
   Number of active neurons: 4
 >> iter 41000, loss: 0.004708
 >> iter 42000, loss: 0.004636
 >> iter 43000, loss: 0.004655
 >> iter 44000, loss: 0.004592
 >> iter 45000, loss: 0.004615
 >> iter 46000, loss: 0.004554
 >> iter 47000, loss: 0.004578
 >> iter 48000, loss: 0.004524
 >> iter 49000, loss: 0.004554
 >> iter 50000, loss: 0.004502
   Number of active neurons: 3
 >> iter 51000, loss: 0.004535
 >> iter 52000, loss: 0.004487
 >> iter 53000, loss: 0.004517
 >> iter 54000, loss: 0.004478
 >> iter 55000, loss: 0.004501
 >> iter 56000, loss: 0.004464
 >> iter 57000, loss: 0.004490
 >> iter 58000, loss: 0.004447
 >> iter 59000, loss: 0.004476
 >> iter 60000, loss: 0.004434
   Number of active neurons: 3
 >> iter 61000, loss: 0.004459
 >> iter 62000, loss: 0.004418
 >> iter 63000, loss: 0.004442
 >> iter 64000, loss: 0.004395
 >> iter 65000, loss: 0.004417
 >> iter 66000, loss: 0.004367
 >> iter 67000, loss: 0.004387
 >> iter 68000, loss: 0.004344
 >> iter 69000, loss: 0.004361
 >> iter 70000, loss: 0.004314
   Number of active neurons: 3
 >> iter 71000, loss: 0.004331
 >> iter 72000, loss: 0.004286
 >> iter 73000, loss: 0.004301
 >> iter 74000, loss: 0.004256
 >> iter 75000, loss: 0.004274
 >> iter 76000, loss: 0.004230
 >> iter 77000, loss: 0.004247
 >> iter 78000, loss: 0.004202
 >> iter 79000, loss: 0.004226
 >> iter 80000, loss: 0.004180
   Number of active neurons: 3
 >> iter 81000, loss: 0.004210
 >> iter 82000, loss: 0.004162
 >> iter 83000, loss: 0.004196
 >> iter 84000, loss: 0.004147
 >> iter 85000, loss: 0.004181
 >> iter 86000, loss: 0.004134
 >> iter 87000, loss: 0.004171
 >> iter 88000, loss: 0.004124
 >> iter 89000, loss: 0.004160
 >> iter 90000, loss: 0.004118
   Number of active neurons: 3
 >> iter 91000, loss: 0.004153
 >> iter 92000, loss: 0.004112
 >> iter 93000, loss: 0.004147
 >> iter 94000, loss: 0.004104
 >> iter 95000, loss: 0.004145
 >> iter 96000, loss: 0.004097
 >> iter 97000, loss: 0.004139
 >> iter 98000, loss: 0.004089
 >> iter 99000, loss: 0.004133
 >> iter 100000, loss: 0.004088
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.749927
 >> iter 2000, loss: 3.964017
 >> iter 3000, loss: 1.464946
 >> iter 4000, loss: 0.544392
 >> iter 5000, loss: 0.205350
 >> iter 6000, loss: 0.080124
 >> iter 7000, loss: 0.033911
 >> iter 8000, loss: 0.016617
 >> iter 9000, loss: 0.010235
 >> iter 10000, loss: 0.007681
   Number of active neurons: 8
 >> iter 11000, loss: 0.006767
 >> iter 12000, loss: 0.006261
 >> iter 13000, loss: 0.006116
 >> iter 14000, loss: 0.005907
 >> iter 15000, loss: 0.005892
 >> iter 16000, loss: 0.005753
 >> iter 17000, loss: 0.005770
 >> iter 18000, loss: 0.005662
 >> iter 19000, loss: 0.005699
 >> iter 20000, loss: 0.005617
   Number of active neurons: 6
 >> iter 21000, loss: 0.005661
 >> iter 22000, loss: 0.005584
 >> iter 23000, loss: 0.005628
 >> iter 24000, loss: 0.005541
 >> iter 25000, loss: 0.005587
 >> iter 26000, loss: 0.005511
 >> iter 27000, loss: 0.005556
 >> iter 28000, loss: 0.005482
 >> iter 29000, loss: 0.005523
 >> iter 30000, loss: 0.005449
   Number of active neurons: 5
 >> iter 31000, loss: 0.005487
 >> iter 32000, loss: 0.005409
 >> iter 33000, loss: 0.005444
 >> iter 34000, loss: 0.005364
 >> iter 35000, loss: 0.005401
 >> iter 36000, loss: 0.005315
 >> iter 37000, loss: 0.005349
 >> iter 38000, loss: 0.005260
 >> iter 39000, loss: 0.005297
 >> iter 40000, loss: 0.005208
   Number of active neurons: 4
 >> iter 41000, loss: 0.005245
 >> iter 42000, loss: 0.005161
 >> iter 43000, loss: 0.005191
 >> iter 44000, loss: 0.005110
 >> iter 45000, loss: 0.005137
 >> iter 46000, loss: 0.005051
 >> iter 47000, loss: 0.005073
 >> iter 48000, loss: 0.004989
 >> iter 49000, loss: 0.005008
 >> iter 50000, loss: 0.004919
   Number of active neurons: 4
 >> iter 51000, loss: 0.004939
 >> iter 52000, loss: 0.004858
 >> iter 53000, loss: 0.004877
 >> iter 54000, loss: 0.004809
 >> iter 55000, loss: 0.004822
 >> iter 56000, loss: 0.004758
 >> iter 57000, loss: 0.004771
 >> iter 58000, loss: 0.004699
 >> iter 59000, loss: 0.004718
 >> iter 60000, loss: 0.004648
   Number of active neurons: 4
 >> iter 61000, loss: 0.004663
 >> iter 62000, loss: 0.004598
 >> iter 63000, loss: 0.004615
 >> iter 64000, loss: 0.004548
 >> iter 65000, loss: 0.004569
 >> iter 66000, loss: 0.004508
 >> iter 67000, loss: 0.004530
 >> iter 68000, loss: 0.004479
 >> iter 69000, loss: 0.004498
 >> iter 70000, loss: 0.004447
   Number of active neurons: 4
 >> iter 71000, loss: 0.004471
 >> iter 72000, loss: 0.004425
 >> iter 73000, loss: 0.004451
 >> iter 74000, loss: 0.004407
 >> iter 75000, loss: 0.004436
 >> iter 76000, loss: 0.004394
 >> iter 77000, loss: 0.004423
 >> iter 78000, loss: 0.004381
 >> iter 79000, loss: 0.004419
 >> iter 80000, loss: 0.004374
   Number of active neurons: 4
 >> iter 81000, loss: 0.004418
 >> iter 82000, loss: 0.004367
 >> iter 83000, loss: 0.004414
 >> iter 84000, loss: 0.004356
 >> iter 85000, loss: 0.004401
 >> iter 86000, loss: 0.004345
 >> iter 87000, loss: 0.004392
 >> iter 88000, loss: 0.004336
 >> iter 89000, loss: 0.004382
 >> iter 90000, loss: 0.004330
   Number of active neurons: 3
 >> iter 91000, loss: 0.004374
 >> iter 92000, loss: 0.004324
 >> iter 93000, loss: 0.004368
 >> iter 94000, loss: 0.004314
 >> iter 95000, loss: 0.004364
 >> iter 96000, loss: 0.004304
 >> iter 97000, loss: 0.004355
 >> iter 98000, loss: 0.004293
 >> iter 99000, loss: 0.004345
 >> iter 100000, loss: 0.004286
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

