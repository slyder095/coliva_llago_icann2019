 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.7
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.551005
 >> iter 2000, loss: 9.846470
 >> iter 3000, loss: 6.519322
 >> iter 4000, loss: 3.713219
 >> iter 5000, loss: 2.155355
 >> iter 6000, loss: 1.297410
 >> iter 7000, loss: 0.748316
 >> iter 8000, loss: 0.588123
 >> iter 9000, loss: 0.376638
 >> iter 10000, loss: 0.351069
   Number of active neurons: 10
 >> iter 11000, loss: 0.442296
 >> iter 12000, loss: 0.391634
 >> iter 13000, loss: 0.308581
 >> iter 14000, loss: 0.228750
 >> iter 15000, loss: 0.153436
 >> iter 16000, loss: 0.170383
 >> iter 17000, loss: 0.209879
 >> iter 18000, loss: 0.222695
 >> iter 19000, loss: 0.182781
 >> iter 20000, loss: 0.127735
   Number of active neurons: 10
 >> iter 21000, loss: 0.104974
 >> iter 22000, loss: 0.124174
 >> iter 23000, loss: 0.156729
 >> iter 24000, loss: 0.112012
 >> iter 25000, loss: 0.073453
 >> iter 26000, loss: 0.051590
 >> iter 27000, loss: 0.075100
 >> iter 28000, loss: 0.098289
 >> iter 29000, loss: 0.082749
 >> iter 30000, loss: 0.072702
   Number of active neurons: 10
 >> iter 31000, loss: 0.079459
 >> iter 32000, loss: 0.034349
 >> iter 33000, loss: 0.016862
 >> iter 34000, loss: 0.122004
 >> iter 35000, loss: 0.072031
 >> iter 36000, loss: 0.030887
 >> iter 37000, loss: 0.047264
 >> iter 38000, loss: 0.043182
 >> iter 39000, loss: 0.021424
 >> iter 40000, loss: 0.010922
   Number of active neurons: 10
 >> iter 41000, loss: 0.041930
 >> iter 42000, loss: 0.063228
 >> iter 43000, loss: 0.028853
 >> iter 44000, loss: 0.036043
 >> iter 45000, loss: 0.072468
 >> iter 46000, loss: 0.052684
 >> iter 47000, loss: 0.073316
 >> iter 48000, loss: 0.079453
 >> iter 49000, loss: 0.039234
 >> iter 50000, loss: 0.017848
   Number of active neurons: 10
 >> iter 51000, loss: 0.018248
 >> iter 52000, loss: 0.062162
 >> iter 53000, loss: 0.052959
 >> iter 54000, loss: 0.052423
 >> iter 55000, loss: 0.034100
 >> iter 56000, loss: 0.043217
 >> iter 57000, loss: 0.019683
 >> iter 58000, loss: 0.039399
 >> iter 59000, loss: 0.017709
 >> iter 60000, loss: 0.021031
   Number of active neurons: 10
 >> iter 61000, loss: 0.042710
 >> iter 62000, loss: 0.018721
 >> iter 63000, loss: 0.011740
 >> iter 64000, loss: 0.052089
 >> iter 65000, loss: 0.021333
 >> iter 66000, loss: 0.026336
 >> iter 67000, loss: 0.013384
 >> iter 68000, loss: 0.007362
 >> iter 69000, loss: 0.006861
 >> iter 70000, loss: 0.005451
   Number of active neurons: 10
 >> iter 71000, loss: 0.031741
 >> iter 72000, loss: 0.027257
 >> iter 73000, loss: 0.048729
 >> iter 74000, loss: 0.020969
 >> iter 75000, loss: 0.037953
 >> iter 76000, loss: 0.054379
 >> iter 77000, loss: 0.022714
 >> iter 78000, loss: 0.044647
 >> iter 79000, loss: 0.024184
 >> iter 80000, loss: 0.010720
   Number of active neurons: 10
 >> iter 81000, loss: 0.012788
 >> iter 82000, loss: 0.006669
 >> iter 83000, loss: 0.062596
 >> iter 84000, loss: 0.063993
 >> iter 85000, loss: 0.054452
 >> iter 86000, loss: 0.029640
 >> iter 87000, loss: 0.022745
 >> iter 88000, loss: 0.010441
 >> iter 89000, loss: 0.005674
 >> iter 90000, loss: 0.004025
   Number of active neurons: 10
 >> iter 91000, loss: 0.002861
 >> iter 92000, loss: 0.054519
 >> iter 93000, loss: 0.041524
 >> iter 94000, loss: 0.017236
 >> iter 95000, loss: 0.007997
 >> iter 96000, loss: 0.004314
 >> iter 97000, loss: 0.002967
 >> iter 98000, loss: 0.002312
 >> iter 99000, loss: 0.006659
 >> iter 100000, loss: 0.025770
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.842301
 >> iter 2000, loss: 10.132246
 >> iter 3000, loss: 7.356123
 >> iter 4000, loss: 5.579708
 >> iter 5000, loss: 2.920915
 >> iter 6000, loss: 1.249195
 >> iter 7000, loss: 0.554365
 >> iter 8000, loss: 0.286421
 >> iter 9000, loss: 0.162318
 >> iter 10000, loss: 0.142478
   Number of active neurons: 10
 >> iter 11000, loss: 0.108373
 >> iter 12000, loss: 0.138821
 >> iter 13000, loss: 0.083602
 >> iter 14000, loss: 0.086097
 >> iter 15000, loss: 0.159893
 >> iter 16000, loss: 0.066805
 >> iter 17000, loss: 0.049886
 >> iter 18000, loss: 0.028893
 >> iter 19000, loss: 0.040696
 >> iter 20000, loss: 0.022391
   Number of active neurons: 10
 >> iter 21000, loss: 0.014197
 >> iter 22000, loss: 0.075123
 >> iter 23000, loss: 0.031614
 >> iter 24000, loss: 0.055854
 >> iter 25000, loss: 0.033578
 >> iter 26000, loss: 0.015605
 >> iter 27000, loss: 0.066165
 >> iter 28000, loss: 0.031211
 >> iter 29000, loss: 0.014345
 >> iter 30000, loss: 0.034455
   Number of active neurons: 10
 >> iter 31000, loss: 0.023205
 >> iter 32000, loss: 0.010570
 >> iter 33000, loss: 0.014164
 >> iter 34000, loss: 0.015962
 >> iter 35000, loss: 0.008449
 >> iter 36000, loss: 0.004727
 >> iter 37000, loss: 0.010887
 >> iter 38000, loss: 0.005810
 >> iter 39000, loss: 0.003894
 >> iter 40000, loss: 0.002983
   Number of active neurons: 10
 >> iter 41000, loss: 0.002231
 >> iter 42000, loss: 0.001985
 >> iter 43000, loss: 0.001690
 >> iter 44000, loss: 0.012331
 >> iter 45000, loss: 0.005565
 >> iter 46000, loss: 0.023813
 >> iter 47000, loss: 0.042685
 >> iter 48000, loss: 0.038270
 >> iter 49000, loss: 0.015608
 >> iter 50000, loss: 0.008963
   Number of active neurons: 10
 >> iter 51000, loss: 0.026044
 >> iter 52000, loss: 0.012826
 >> iter 53000, loss: 0.006292
 >> iter 54000, loss: 0.010678
 >> iter 55000, loss: 0.005130
 >> iter 56000, loss: 0.026667
 >> iter 57000, loss: 0.031021
 >> iter 58000, loss: 0.036689
 >> iter 59000, loss: 0.034551
 >> iter 60000, loss: 0.014406
   Number of active neurons: 10
 >> iter 61000, loss: 0.007260
 >> iter 62000, loss: 0.007003
 >> iter 63000, loss: 0.022464
 >> iter 64000, loss: 0.009756
 >> iter 65000, loss: 0.023871
 >> iter 66000, loss: 0.022279
 >> iter 67000, loss: 0.018988
 >> iter 68000, loss: 0.008135
 >> iter 69000, loss: 0.005804
 >> iter 70000, loss: 0.018344
   Number of active neurons: 10
 >> iter 71000, loss: 0.007851
 >> iter 72000, loss: 0.003911
 >> iter 73000, loss: 0.002382
 >> iter 74000, loss: 0.001791
 >> iter 75000, loss: 0.001471
 >> iter 76000, loss: 0.001269
 >> iter 77000, loss: 0.005602
 >> iter 78000, loss: 0.027334
 >> iter 79000, loss: 0.011067
 >> iter 80000, loss: 0.006325
   Number of active neurons: 10
 >> iter 81000, loss: 0.006880
 >> iter 82000, loss: 0.003574
 >> iter 83000, loss: 0.002045
 >> iter 84000, loss: 0.004773
 >> iter 85000, loss: 0.002610
 >> iter 86000, loss: 0.001698
 >> iter 87000, loss: 0.001267
 >> iter 88000, loss: 0.001014
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.698900
 >> iter 2000, loss: 9.929972
 >> iter 3000, loss: 5.796149
 >> iter 4000, loss: 2.814835
 >> iter 5000, loss: 1.326091
 >> iter 6000, loss: 0.734321
 >> iter 7000, loss: 0.390775
 >> iter 8000, loss: 0.247342
 >> iter 9000, loss: 0.265757
 >> iter 10000, loss: 0.241509
   Number of active neurons: 10
 >> iter 11000, loss: 0.161223
 >> iter 12000, loss: 0.127663
 >> iter 13000, loss: 0.203111
 >> iter 14000, loss: 0.102657
 >> iter 15000, loss: 0.098321
 >> iter 16000, loss: 0.184189
 >> iter 17000, loss: 0.104301
 >> iter 18000, loss: 0.092441
 >> iter 19000, loss: 0.065436
 >> iter 20000, loss: 0.121438
   Number of active neurons: 10
 >> iter 21000, loss: 0.083459
 >> iter 22000, loss: 0.051818
 >> iter 23000, loss: 0.043795
 >> iter 24000, loss: 0.055745
 >> iter 25000, loss: 0.025470
 >> iter 26000, loss: 0.013237
 >> iter 27000, loss: 0.015128
 >> iter 28000, loss: 0.013172
 >> iter 29000, loss: 0.008031
 >> iter 30000, loss: 0.005449
   Number of active neurons: 10
 >> iter 31000, loss: 0.032841
 >> iter 32000, loss: 0.044245
 >> iter 33000, loss: 0.057580
 >> iter 34000, loss: 0.062371
 >> iter 35000, loss: 0.056719
 >> iter 36000, loss: 0.024226
 >> iter 37000, loss: 0.028188
 >> iter 38000, loss: 0.024707
 >> iter 39000, loss: 0.011649
 >> iter 40000, loss: 0.006207
   Number of active neurons: 10
 >> iter 41000, loss: 0.004190
 >> iter 42000, loss: 0.003271
 >> iter 43000, loss: 0.003865
 >> iter 44000, loss: 0.002997
 >> iter 45000, loss: 0.002599
 >> iter 46000, loss: 0.002218
 >> iter 47000, loss: 0.002027
 >> iter 48000, loss: 0.001924
 >> iter 49000, loss: 0.006689
 >> iter 50000, loss: 0.003464
   Number of active neurons: 10
 >> iter 51000, loss: 0.021677
 >> iter 52000, loss: 0.026892
 >> iter 53000, loss: 0.081399
 >> iter 54000, loss: 0.032981
 >> iter 55000, loss: 0.014348
 >> iter 56000, loss: 0.018232
 >> iter 57000, loss: 0.008481
 >> iter 58000, loss: 0.004742
 >> iter 59000, loss: 0.002942
 >> iter 60000, loss: 0.005198
   Number of active neurons: 10
 >> iter 61000, loss: 0.014604
 >> iter 62000, loss: 0.024782
 >> iter 63000, loss: 0.019813
 >> iter 64000, loss: 0.037874
 >> iter 65000, loss: 0.090608
 >> iter 66000, loss: 0.045751
 >> iter 67000, loss: 0.026798
 >> iter 68000, loss: 0.031844
 >> iter 69000, loss: 0.015516
 >> iter 70000, loss: 0.039511
   Number of active neurons: 10
 >> iter 71000, loss: 0.016233
 >> iter 72000, loss: 0.077348
 >> iter 73000, loss: 0.031016
 >> iter 74000, loss: 0.013254
 >> iter 75000, loss: 0.020314
 >> iter 76000, loss: 0.009126
 >> iter 77000, loss: 0.004751
 >> iter 78000, loss: 0.006650
 >> iter 79000, loss: 0.011502
 >> iter 80000, loss: 0.005623
   Number of active neurons: 10
 >> iter 81000, loss: 0.025897
 >> iter 82000, loss: 0.077407
 >> iter 83000, loss: 0.043026
 >> iter 84000, loss: 0.017732
 >> iter 85000, loss: 0.042800
 >> iter 86000, loss: 0.034328
 >> iter 87000, loss: 0.030347
 >> iter 88000, loss: 0.046924
 >> iter 89000, loss: 0.019752
 >> iter 90000, loss: 0.042126
   Number of active neurons: 10
 >> iter 91000, loss: 0.018166
 >> iter 92000, loss: 0.020600
 >> iter 93000, loss: 0.014093
 >> iter 94000, loss: 0.006972
 >> iter 95000, loss: 0.004215
 >> iter 96000, loss: 0.029770
 >> iter 97000, loss: 0.034014
 >> iter 98000, loss: 0.047537
 >> iter 99000, loss: 0.053286
 >> iter 100000, loss: 0.021947
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.496382
 >> iter 2000, loss: 9.871681
 >> iter 3000, loss: 5.992736
 >> iter 4000, loss: 3.077668
 >> iter 5000, loss: 1.632404
 >> iter 6000, loss: 0.750249
 >> iter 7000, loss: 0.400430
 >> iter 8000, loss: 0.278162
 >> iter 9000, loss: 0.268101
 >> iter 10000, loss: 0.353657
   Number of active neurons: 10
 >> iter 11000, loss: 0.281672
 >> iter 12000, loss: 0.160751
 >> iter 13000, loss: 0.178523
 >> iter 14000, loss: 0.131310
 >> iter 15000, loss: 0.107980
 >> iter 16000, loss: 0.067276
 >> iter 17000, loss: 0.149425
 >> iter 18000, loss: 0.085025
 >> iter 19000, loss: 0.130429
 >> iter 20000, loss: 0.062647
   Number of active neurons: 10
 >> iter 21000, loss: 0.029857
 >> iter 22000, loss: 0.040174
 >> iter 23000, loss: 0.029508
 >> iter 24000, loss: 0.152976
 >> iter 25000, loss: 0.078645
 >> iter 26000, loss: 0.056877
 >> iter 27000, loss: 0.032091
 >> iter 28000, loss: 0.021439
 >> iter 29000, loss: 0.107478
 >> iter 30000, loss: 0.070900
   Number of active neurons: 10
 >> iter 31000, loss: 0.100520
 >> iter 32000, loss: 0.065488
 >> iter 33000, loss: 0.028835
 >> iter 34000, loss: 0.031751
 >> iter 35000, loss: 0.015755
 >> iter 36000, loss: 0.018049
 >> iter 37000, loss: 0.010157
 >> iter 38000, loss: 0.006254
 >> iter 39000, loss: 0.020552
 >> iter 40000, loss: 0.009963
   Number of active neurons: 10
 >> iter 41000, loss: 0.035888
 >> iter 42000, loss: 0.030031
 >> iter 43000, loss: 0.026121
 >> iter 44000, loss: 0.045415
 >> iter 45000, loss: 0.022025
 >> iter 46000, loss: 0.010001
 >> iter 47000, loss: 0.021317
 >> iter 48000, loss: 0.009808
 >> iter 49000, loss: 0.022718
 >> iter 50000, loss: 0.022918
   Number of active neurons: 10
 >> iter 51000, loss: 0.028129
 >> iter 52000, loss: 0.045518
 >> iter 53000, loss: 0.108913
 >> iter 54000, loss: 0.061736
 >> iter 55000, loss: 0.040697
 >> iter 56000, loss: 0.017782
 >> iter 57000, loss: 0.017666
 >> iter 58000, loss: 0.025228
 >> iter 59000, loss: 0.051148
 >> iter 60000, loss: 0.021128
   Number of active neurons: 10
 >> iter 61000, loss: 0.016330
 >> iter 62000, loss: 0.040312
 >> iter 63000, loss: 0.075797
 >> iter 64000, loss: 0.037732
 >> iter 65000, loss: 0.016611
 >> iter 66000, loss: 0.008422
 >> iter 67000, loss: 0.004892
 >> iter 68000, loss: 0.021610
 >> iter 69000, loss: 0.009886
 >> iter 70000, loss: 0.015231
   Number of active neurons: 10
 >> iter 71000, loss: 0.006993
 >> iter 72000, loss: 0.016056
 >> iter 73000, loss: 0.013282
 >> iter 74000, loss: 0.006777
 >> iter 75000, loss: 0.003788
 >> iter 76000, loss: 0.013236
 >> iter 77000, loss: 0.116569
 >> iter 78000, loss: 0.095312
 >> iter 79000, loss: 0.083099
 >> iter 80000, loss: 0.036685
   Number of active neurons: 10
 >> iter 81000, loss: 0.015965
 >> iter 82000, loss: 0.007755
 >> iter 83000, loss: 0.007662
 >> iter 84000, loss: 0.024367
 >> iter 85000, loss: 0.011013
 >> iter 86000, loss: 0.005696
 >> iter 87000, loss: 0.003604
 >> iter 88000, loss: 0.002536
 >> iter 89000, loss: 0.002117
 >> iter 90000, loss: 0.001897
   Number of active neurons: 10
 >> iter 91000, loss: 0.001749
 >> iter 92000, loss: 0.022277
 >> iter 93000, loss: 0.010802
 >> iter 94000, loss: 0.006304
 >> iter 95000, loss: 0.003569
 >> iter 96000, loss: 0.020063
 >> iter 97000, loss: 0.008893
 >> iter 98000, loss: 0.004408
 >> iter 99000, loss: 0.002656
 >> iter 100000, loss: 0.003413
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.493276
 >> iter 2000, loss: 10.160714
 >> iter 3000, loss: 6.540571
 >> iter 4000, loss: 3.379595
 >> iter 5000, loss: 1.444497
 >> iter 6000, loss: 0.667209
 >> iter 7000, loss: 0.352959
 >> iter 8000, loss: 0.217712
 >> iter 9000, loss: 0.115401
 >> iter 10000, loss: 0.117956
   Number of active neurons: 10
 >> iter 11000, loss: 0.116954
 >> iter 12000, loss: 0.140004
 >> iter 13000, loss: 0.091385
 >> iter 14000, loss: 0.075544
 >> iter 15000, loss: 0.040671
 >> iter 16000, loss: 0.056656
 >> iter 17000, loss: 0.036892
 >> iter 18000, loss: 0.072723
 >> iter 19000, loss: 0.036194
 >> iter 20000, loss: 0.069410
   Number of active neurons: 10
 >> iter 21000, loss: 0.071675
 >> iter 22000, loss: 0.050828
 >> iter 23000, loss: 0.024963
 >> iter 24000, loss: 0.034449
 >> iter 25000, loss: 0.061198
 >> iter 26000, loss: 0.095058
 >> iter 27000, loss: 0.067657
 >> iter 28000, loss: 0.108058
 >> iter 29000, loss: 0.052476
 >> iter 30000, loss: 0.050642
   Number of active neurons: 10
 >> iter 31000, loss: 0.035503
 >> iter 32000, loss: 0.017732
 >> iter 33000, loss: 0.032992
 >> iter 34000, loss: 0.015966
 >> iter 35000, loss: 0.011026
 >> iter 36000, loss: 0.031616
 >> iter 37000, loss: 0.025998
 >> iter 38000, loss: 0.028490
 >> iter 39000, loss: 0.058580
 >> iter 40000, loss: 0.059389
   Number of active neurons: 10
 >> iter 41000, loss: 0.071186
 >> iter 42000, loss: 0.065558
 >> iter 43000, loss: 0.104019
 >> iter 44000, loss: 0.055469
 >> iter 45000, loss: 0.081191
 >> iter 46000, loss: 0.052154
 >> iter 47000, loss: 0.023612
 >> iter 48000, loss: 0.012677
 >> iter 49000, loss: 0.020937
 >> iter 50000, loss: 0.027657
   Number of active neurons: 10
 >> iter 51000, loss: 0.013450
 >> iter 52000, loss: 0.015356
 >> iter 53000, loss: 0.008352
 >> iter 54000, loss: 0.036587
 >> iter 55000, loss: 0.016472
 >> iter 56000, loss: 0.013853
 >> iter 57000, loss: 0.007679
 >> iter 58000, loss: 0.020032
 >> iter 59000, loss: 0.030877
 >> iter 60000, loss: 0.031239
   Number of active neurons: 10
 >> iter 61000, loss: 0.014202
 >> iter 62000, loss: 0.010031
 >> iter 63000, loss: 0.005813
 >> iter 64000, loss: 0.019310
 >> iter 65000, loss: 0.033479
 >> iter 66000, loss: 0.014347
 >> iter 67000, loss: 0.007562
 >> iter 68000, loss: 0.004689
 >> iter 69000, loss: 0.003646
 >> iter 70000, loss: 0.003090
   Number of active neurons: 10
 >> iter 71000, loss: 0.002765
 >> iter 72000, loss: 0.020038
 >> iter 73000, loss: 0.009470
 >> iter 74000, loss: 0.005086
 >> iter 75000, loss: 0.003461
 >> iter 76000, loss: 0.002706
 >> iter 77000, loss: 0.002525
 >> iter 78000, loss: 0.002298
 >> iter 79000, loss: 0.002271
 >> iter 80000, loss: 0.002124
   Number of active neurons: 10
 >> iter 81000, loss: 0.002079
 >> iter 82000, loss: 0.044716
 >> iter 83000, loss: 0.017997
 >> iter 84000, loss: 0.007910
 >> iter 85000, loss: 0.004317
 >> iter 86000, loss: 0.002866
 >> iter 87000, loss: 0.026517
 >> iter 88000, loss: 0.037102
 >> iter 89000, loss: 0.033420
 >> iter 90000, loss: 0.021246
   Number of active neurons: 10
 >> iter 91000, loss: 0.009100
 >> iter 92000, loss: 0.004864
 >> iter 93000, loss: 0.002992
 >> iter 94000, loss: 0.002497
 >> iter 95000, loss: 0.002128
 >> iter 96000, loss: 0.001848
 >> iter 97000, loss: 0.001798
 >> iter 98000, loss: 0.001698
 >> iter 99000, loss: 0.001665
 >> iter 100000, loss: 0.001572
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.353315
 >> iter 2000, loss: 9.792203
 >> iter 3000, loss: 6.258452
 >> iter 4000, loss: 3.574970
 >> iter 5000, loss: 2.386941
 >> iter 6000, loss: 1.669919
 >> iter 7000, loss: 1.312951
 >> iter 8000, loss: 0.898561
 >> iter 9000, loss: 0.722907
 >> iter 10000, loss: 0.674289
   Number of active neurons: 10
 >> iter 11000, loss: 0.609301
 >> iter 12000, loss: 0.503747
 >> iter 13000, loss: 0.366306
 >> iter 14000, loss: 0.317918
 >> iter 15000, loss: 0.230442
 >> iter 16000, loss: 0.246287
 >> iter 17000, loss: 0.244349
 >> iter 18000, loss: 0.547625
 >> iter 19000, loss: 0.386190
 >> iter 20000, loss: 0.235913
   Number of active neurons: 10
 >> iter 21000, loss: 0.220798
 >> iter 22000, loss: 0.259221
 >> iter 23000, loss: 0.196211
 >> iter 24000, loss: 0.108034
 >> iter 25000, loss: 0.159434
 >> iter 26000, loss: 0.140444
 >> iter 27000, loss: 0.124068
 >> iter 28000, loss: 0.072329
 >> iter 29000, loss: 0.068364
 >> iter 30000, loss: 0.055105
   Number of active neurons: 10
 >> iter 31000, loss: 0.140851
 >> iter 32000, loss: 0.076010
 >> iter 33000, loss: 0.053692
 >> iter 34000, loss: 0.137590
 >> iter 35000, loss: 0.098804
 >> iter 36000, loss: 0.084628
 >> iter 37000, loss: 0.135206
 >> iter 38000, loss: 0.094342
 >> iter 39000, loss: 0.066163
 >> iter 40000, loss: 0.032509
   Number of active neurons: 10
 >> iter 41000, loss: 0.054115
 >> iter 42000, loss: 0.103786
 >> iter 43000, loss: 0.072258
 >> iter 44000, loss: 0.110739
 >> iter 45000, loss: 0.095224
 >> iter 46000, loss: 0.124364
 >> iter 47000, loss: 0.061792
 >> iter 48000, loss: 0.027287
 >> iter 49000, loss: 0.071459
 >> iter 50000, loss: 0.062711
   Number of active neurons: 10
 >> iter 51000, loss: 0.057990
 >> iter 52000, loss: 0.027346
 >> iter 53000, loss: 0.013411
 >> iter 54000, loss: 0.019655
 >> iter 55000, loss: 0.062335
 >> iter 56000, loss: 0.074104
 >> iter 57000, loss: 0.040165
 >> iter 58000, loss: 0.097732
 >> iter 59000, loss: 0.069257
 >> iter 60000, loss: 0.059397
   Number of active neurons: 10
 >> iter 61000, loss: 0.067167
 >> iter 62000, loss: 0.028573
 >> iter 63000, loss: 0.033881
 >> iter 64000, loss: 0.015677
 >> iter 65000, loss: 0.056998
 >> iter 66000, loss: 0.031420
 >> iter 67000, loss: 0.043005
 >> iter 68000, loss: 0.018659
 >> iter 69000, loss: 0.009391
 >> iter 70000, loss: 0.006668
   Number of active neurons: 10
 >> iter 71000, loss: 0.012458
 >> iter 72000, loss: 0.006601
 >> iter 73000, loss: 0.005377
 >> iter 74000, loss: 0.003901
 >> iter 75000, loss: 0.003255
 >> iter 76000, loss: 0.015984
 >> iter 77000, loss: 0.009439
 >> iter 78000, loss: 0.032211
 >> iter 79000, loss: 0.013820
 >> iter 80000, loss: 0.032132
   Number of active neurons: 10
 >> iter 81000, loss: 0.020951
 >> iter 82000, loss: 0.010641
 >> iter 83000, loss: 0.005566
 >> iter 84000, loss: 0.003567
 >> iter 85000, loss: 0.002762
 >> iter 86000, loss: 0.026519
 >> iter 87000, loss: 0.040111
 >> iter 88000, loss: 0.016605
 >> iter 89000, loss: 0.021046
 >> iter 90000, loss: 0.009649
   Number of active neurons: 10
 >> iter 91000, loss: 0.029884
 >> iter 92000, loss: 0.030585
 >> iter 93000, loss: 0.017015
 >> iter 94000, loss: 0.187896
 >> iter 95000, loss: 0.071868
 >> iter 96000, loss: 0.029028
 >> iter 97000, loss: 0.013312
 >> iter 98000, loss: 0.006678
 >> iter 99000, loss: 0.004200
 >> iter 100000, loss: 0.044979
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 16.903465
 >> iter 2000, loss: 10.255219
 >> iter 3000, loss: 7.131913
 >> iter 4000, loss: 5.169161
 >> iter 5000, loss: 3.554754
 >> iter 6000, loss: 2.442230
 >> iter 7000, loss: 1.602800
 >> iter 8000, loss: 1.045635
 >> iter 9000, loss: 0.615417
 >> iter 10000, loss: 0.430145
   Number of active neurons: 10
 >> iter 11000, loss: 0.420397
 >> iter 12000, loss: 0.407140
 >> iter 13000, loss: 0.216328
 >> iter 14000, loss: 0.217454
 >> iter 15000, loss: 0.218845
 >> iter 16000, loss: 0.193841
 >> iter 17000, loss: 0.223673
 >> iter 18000, loss: 0.267774
 >> iter 19000, loss: 0.123984
 >> iter 20000, loss: 0.092840
   Number of active neurons: 10
 >> iter 21000, loss: 0.130685
 >> iter 22000, loss: 0.072050
 >> iter 23000, loss: 0.134580
 >> iter 24000, loss: 0.077602
 >> iter 25000, loss: 0.043686
 >> iter 26000, loss: 0.031532
 >> iter 27000, loss: 0.044842
 >> iter 28000, loss: 0.023265
 >> iter 29000, loss: 0.021216
 >> iter 30000, loss: 0.011736
   Number of active neurons: 10
 >> iter 31000, loss: 0.019559
 >> iter 32000, loss: 0.056149
 >> iter 33000, loss: 0.066483
 >> iter 34000, loss: 0.045812
 >> iter 35000, loss: 0.080481
 >> iter 36000, loss: 0.143671
 >> iter 37000, loss: 0.103731
 >> iter 38000, loss: 0.053939
 >> iter 39000, loss: 0.072067
 >> iter 40000, loss: 0.050090
   Number of active neurons: 10
 >> iter 41000, loss: 0.024812
 >> iter 42000, loss: 0.012311
 >> iter 43000, loss: 0.027920
 >> iter 44000, loss: 0.045401
 >> iter 45000, loss: 0.043973
 >> iter 46000, loss: 0.019075
 >> iter 47000, loss: 0.012756
 >> iter 48000, loss: 0.006862
 >> iter 49000, loss: 0.007754
 >> iter 50000, loss: 0.004537
   Number of active neurons: 10
 >> iter 51000, loss: 0.003365
 >> iter 52000, loss: 0.021723
 >> iter 53000, loss: 0.009825
 >> iter 54000, loss: 0.005279
 >> iter 55000, loss: 0.003379
 >> iter 56000, loss: 0.002547
 >> iter 57000, loss: 0.002335
 >> iter 58000, loss: 0.002031
 >> iter 59000, loss: 0.036951
 >> iter 60000, loss: 0.014889
   Number of active neurons: 10
 >> iter 61000, loss: 0.006736
 >> iter 62000, loss: 0.032800
 >> iter 63000, loss: 0.013391
 >> iter 64000, loss: 0.006320
 >> iter 65000, loss: 0.003558
 >> iter 66000, loss: 0.002476
 >> iter 67000, loss: 0.001898
 >> iter 68000, loss: 0.001659
 >> iter 69000, loss: 0.001555
 >> iter 70000, loss: 0.001481
   Number of active neurons: 10
 >> iter 71000, loss: 0.001403
 >> iter 72000, loss: 0.001424
 >> iter 73000, loss: 0.001322
 >> iter 74000, loss: 0.001710
 >> iter 75000, loss: 0.001434
 >> iter 76000, loss: 0.001270
 >> iter 77000, loss: 0.001216
 >> iter 78000, loss: 0.001117
 >> iter 79000, loss: 0.001796
 >> iter 80000, loss: 0.001395
   Number of active neurons: 10
 >> iter 81000, loss: 0.001188
 >> iter 82000, loss: 0.001238
 >> iter 83000, loss: 0.001093
 >> iter 84000, loss: 0.001024
 >> iter 85000, loss: 0.003667
 >> iter 86000, loss: 0.011123
 >> iter 87000, loss: 0.004843
 >> iter 88000, loss: 0.002456
 >> iter 89000, loss: 0.002072
 >> iter 90000, loss: 0.001818
   Number of active neurons: 10
 >> iter 91000, loss: 0.001293
 >> iter 92000, loss: 0.001050
 >> iter 93000, loss: 0.050592
 >> iter 94000, loss: 0.020449
 >> iter 95000, loss: 0.008341
 >> iter 96000, loss: 0.003705
 >> iter 97000, loss: 0.002818
 >> iter 98000, loss: 0.002045
 >> iter 99000, loss: 0.001346
 >> iter 100000, loss: 0.001071
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.467792
 >> iter 2000, loss: 9.726725
 >> iter 3000, loss: 6.697677
 >> iter 4000, loss: 4.508314
 >> iter 5000, loss: 2.924441
 >> iter 6000, loss: 2.226015
 >> iter 7000, loss: 1.565833
 >> iter 8000, loss: 0.990963
 >> iter 9000, loss: 0.909500
 >> iter 10000, loss: 0.577447
   Number of active neurons: 10
 >> iter 11000, loss: 0.468778
 >> iter 12000, loss: 0.303070
 >> iter 13000, loss: 0.355891
 >> iter 14000, loss: 0.237142
 >> iter 15000, loss: 0.234959
 >> iter 16000, loss: 0.271321
 >> iter 17000, loss: 0.361954
 >> iter 18000, loss: 0.406782
 >> iter 19000, loss: 0.253808
 >> iter 20000, loss: 0.193277
   Number of active neurons: 10
 >> iter 21000, loss: 0.113307
 >> iter 22000, loss: 0.089583
 >> iter 23000, loss: 0.128959
 >> iter 24000, loss: 0.168771
 >> iter 25000, loss: 0.185591
 >> iter 26000, loss: 0.122867
 >> iter 27000, loss: 0.143577
 >> iter 28000, loss: 0.110994
 >> iter 29000, loss: 0.078975
 >> iter 30000, loss: 0.068581
   Number of active neurons: 10
 >> iter 31000, loss: 0.069032
 >> iter 32000, loss: 0.086286
 >> iter 33000, loss: 0.059534
 >> iter 34000, loss: 0.031425
 >> iter 35000, loss: 0.131687
 >> iter 36000, loss: 0.055557
 >> iter 37000, loss: 0.047189
 >> iter 38000, loss: 0.030324
 >> iter 39000, loss: 0.015345
 >> iter 40000, loss: 0.016837
   Number of active neurons: 10
 >> iter 41000, loss: 0.014899
 >> iter 42000, loss: 0.072768
 >> iter 43000, loss: 0.044547
 >> iter 44000, loss: 0.033970
 >> iter 45000, loss: 0.015945
 >> iter 46000, loss: 0.071832
 >> iter 47000, loss: 0.051094
 >> iter 48000, loss: 0.092587
 >> iter 49000, loss: 0.050259
 >> iter 50000, loss: 0.093814
   Number of active neurons: 10
 >> iter 51000, loss: 0.044850
 >> iter 52000, loss: 0.048277
 >> iter 53000, loss: 0.055231
 >> iter 54000, loss: 0.053207
 >> iter 55000, loss: 0.045047
 >> iter 56000, loss: 0.046910
 >> iter 57000, loss: 0.102895
 >> iter 58000, loss: 0.056254
 >> iter 59000, loss: 0.043352
 >> iter 60000, loss: 0.085430
   Number of active neurons: 10
 >> iter 61000, loss: 0.038413
 >> iter 62000, loss: 0.026727
 >> iter 63000, loss: 0.025239
 >> iter 64000, loss: 0.078967
 >> iter 65000, loss: 0.032693
 >> iter 66000, loss: 0.032432
 >> iter 67000, loss: 0.015370
 >> iter 68000, loss: 0.008100
 >> iter 69000, loss: 0.027508
 >> iter 70000, loss: 0.013987
   Number of active neurons: 10
 >> iter 71000, loss: 0.126112
 >> iter 72000, loss: 0.109643
 >> iter 73000, loss: 0.078250
 >> iter 74000, loss: 0.093219
 >> iter 75000, loss: 0.038380
 >> iter 76000, loss: 0.024833
 >> iter 77000, loss: 0.011640
 >> iter 78000, loss: 0.006482
 >> iter 79000, loss: 0.013495
 >> iter 80000, loss: 0.007391
   Number of active neurons: 10
 >> iter 81000, loss: 0.005649
 >> iter 82000, loss: 0.047958
 >> iter 83000, loss: 0.020685
 >> iter 84000, loss: 0.009591
 >> iter 85000, loss: 0.005331
 >> iter 86000, loss: 0.003640
 >> iter 87000, loss: 0.021085
 >> iter 88000, loss: 0.009330
 >> iter 89000, loss: 0.029713
 >> iter 90000, loss: 0.024136
   Number of active neurons: 10
 >> iter 91000, loss: 0.010680
 >> iter 92000, loss: 0.005450
 >> iter 93000, loss: 0.012881
 >> iter 94000, loss: 0.006265
 >> iter 95000, loss: 0.003709
 >> iter 96000, loss: 0.024890
 >> iter 97000, loss: 0.010486
 >> iter 98000, loss: 0.005040
 >> iter 99000, loss: 0.006548
 >> iter 100000, loss: 0.030726
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.563349
 >> iter 2000, loss: 9.649072
 >> iter 3000, loss: 5.562620
 >> iter 4000, loss: 2.788640
 >> iter 5000, loss: 1.446502
 >> iter 6000, loss: 0.736690
 >> iter 7000, loss: 0.576947
 >> iter 8000, loss: 0.340057
 >> iter 9000, loss: 0.229286
 >> iter 10000, loss: 0.113844
   Number of active neurons: 10
 >> iter 11000, loss: 0.093664
 >> iter 12000, loss: 0.217086
 >> iter 13000, loss: 0.130352
 >> iter 14000, loss: 0.127623
 >> iter 15000, loss: 0.096592
 >> iter 16000, loss: 0.132621
 >> iter 17000, loss: 0.063001
 >> iter 18000, loss: 0.065690
 >> iter 19000, loss: 0.045204
 >> iter 20000, loss: 0.053430
   Number of active neurons: 10
 >> iter 21000, loss: 0.057422
 >> iter 22000, loss: 0.108017
 >> iter 23000, loss: 0.126337
 >> iter 24000, loss: 0.083343
 >> iter 25000, loss: 0.057485
 >> iter 26000, loss: 0.026880
 >> iter 27000, loss: 0.086584
 >> iter 28000, loss: 0.124687
 >> iter 29000, loss: 0.092598
 >> iter 30000, loss: 0.080141
   Number of active neurons: 10
 >> iter 31000, loss: 0.062588
 >> iter 32000, loss: 0.059880
 >> iter 33000, loss: 0.031583
 >> iter 34000, loss: 0.142723
 >> iter 35000, loss: 0.095455
 >> iter 36000, loss: 0.135991
 >> iter 37000, loss: 0.058646
 >> iter 38000, loss: 0.040849
 >> iter 39000, loss: 0.034240
 >> iter 40000, loss: 0.016374
   Number of active neurons: 10
 >> iter 41000, loss: 0.009701
 >> iter 42000, loss: 0.059656
 >> iter 43000, loss: 0.025779
 >> iter 44000, loss: 0.078557
 >> iter 45000, loss: 0.051874
 >> iter 46000, loss: 0.037250
 >> iter 47000, loss: 0.042382
 >> iter 48000, loss: 0.021060
 >> iter 49000, loss: 0.025000
 >> iter 50000, loss: 0.048190
   Number of active neurons: 10
 >> iter 51000, loss: 0.054218
 >> iter 52000, loss: 0.047740
 >> iter 53000, loss: 0.035041
 >> iter 54000, loss: 0.015101
 >> iter 55000, loss: 0.082117
 >> iter 56000, loss: 0.058160
 >> iter 57000, loss: 0.063359
 >> iter 58000, loss: 0.130351
 >> iter 59000, loss: 0.054270
 >> iter 60000, loss: 0.083814
   Number of active neurons: 10
 >> iter 61000, loss: 0.035681
 >> iter 62000, loss: 0.015876
 >> iter 63000, loss: 0.008020
 >> iter 64000, loss: 0.040118
 >> iter 65000, loss: 0.018200
 >> iter 66000, loss: 0.013757
 >> iter 67000, loss: 0.038233
 >> iter 68000, loss: 0.016335
 >> iter 69000, loss: 0.008005
 >> iter 70000, loss: 0.004771
   Number of active neurons: 10
 >> iter 71000, loss: 0.005280
 >> iter 72000, loss: 0.003911
 >> iter 73000, loss: 0.002745
 >> iter 74000, loss: 0.042336
 >> iter 75000, loss: 0.017341
 >> iter 76000, loss: 0.038861
 >> iter 77000, loss: 0.024750
 >> iter 78000, loss: 0.025239
 >> iter 79000, loss: 0.024362
 >> iter 80000, loss: 0.034721
   Number of active neurons: 10
 >> iter 81000, loss: 0.031207
 >> iter 82000, loss: 0.079344
 >> iter 83000, loss: 0.059785
 >> iter 84000, loss: 0.024744
 >> iter 85000, loss: 0.014356
 >> iter 86000, loss: 0.024397
 >> iter 87000, loss: 0.011124
 >> iter 88000, loss: 0.008767
 >> iter 89000, loss: 0.005210
 >> iter 90000, loss: 0.003273
   Number of active neurons: 10
 >> iter 91000, loss: 0.034701
 >> iter 92000, loss: 0.022638
 >> iter 93000, loss: 0.009781
 >> iter 94000, loss: 0.004929
 >> iter 95000, loss: 0.003139
 >> iter 96000, loss: 0.028162
 >> iter 97000, loss: 0.011657
 >> iter 98000, loss: 0.005676
 >> iter 99000, loss: 0.031182
 >> iter 100000, loss: 0.015993
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 16.667145
 >> iter 2000, loss: 9.963198
 >> iter 3000, loss: 6.507838
 >> iter 4000, loss: 3.146881
 >> iter 5000, loss: 1.602290
 >> iter 6000, loss: 0.794898
 >> iter 7000, loss: 0.468444
 >> iter 8000, loss: 0.301028
 >> iter 9000, loss: 0.174578
 >> iter 10000, loss: 0.133467
   Number of active neurons: 10
 >> iter 11000, loss: 0.244297
 >> iter 12000, loss: 0.168913
 >> iter 13000, loss: 0.172431
 >> iter 14000, loss: 0.099444
 >> iter 15000, loss: 0.070928
 >> iter 16000, loss: 0.104727
 >> iter 17000, loss: 0.046177
 >> iter 18000, loss: 0.054078
 >> iter 19000, loss: 0.064012
 >> iter 20000, loss: 0.042319
   Number of active neurons: 10
 >> iter 21000, loss: 0.039585
 >> iter 22000, loss: 0.025899
 >> iter 23000, loss: 0.014460
 >> iter 24000, loss: 0.070124
 >> iter 25000, loss: 0.043219
 >> iter 26000, loss: 0.041101
 >> iter 27000, loss: 0.029979
 >> iter 28000, loss: 0.077517
 >> iter 29000, loss: 0.033292
 >> iter 30000, loss: 0.015582
   Number of active neurons: 10
 >> iter 31000, loss: 0.019625
 >> iter 32000, loss: 0.011900
 >> iter 33000, loss: 0.018944
 >> iter 34000, loss: 0.022051
 >> iter 35000, loss: 0.017521
 >> iter 36000, loss: 0.032262
 >> iter 37000, loss: 0.022548
 >> iter 38000, loss: 0.020422
 >> iter 39000, loss: 0.011316
 >> iter 40000, loss: 0.054823
   Number of active neurons: 10
 >> iter 41000, loss: 0.023462
 >> iter 42000, loss: 0.012758
 >> iter 43000, loss: 0.006841
 >> iter 44000, loss: 0.026298
 >> iter 45000, loss: 0.018492
 >> iter 46000, loss: 0.026417
 >> iter 47000, loss: 0.011912
 >> iter 48000, loss: 0.006256
 >> iter 49000, loss: 0.004329
 >> iter 50000, loss: 0.003414
   Number of active neurons: 10
 >> iter 51000, loss: 0.003138
 >> iter 52000, loss: 0.003806
 >> iter 53000, loss: 0.058114
 >> iter 54000, loss: 0.042653
 >> iter 55000, loss: 0.018170
 >> iter 56000, loss: 0.031751
 >> iter 57000, loss: 0.035827
 >> iter 58000, loss: 0.015963
 >> iter 59000, loss: 0.008424
 >> iter 60000, loss: 0.004856
   Number of active neurons: 10
 >> iter 61000, loss: 0.003479
 >> iter 62000, loss: 0.039596
 >> iter 63000, loss: 0.016701
 >> iter 64000, loss: 0.064954
 >> iter 65000, loss: 0.025665
 >> iter 66000, loss: 0.011120
 >> iter 67000, loss: 0.005707
 >> iter 68000, loss: 0.003887
 >> iter 69000, loss: 0.003005
 >> iter 70000, loss: 0.002545
   Number of active neurons: 10
 >> iter 71000, loss: 0.002304
 >> iter 72000, loss: 0.002192
 >> iter 73000, loss: 0.024226
 >> iter 74000, loss: 0.010369
 >> iter 75000, loss: 0.005120
 >> iter 76000, loss: 0.003508
 >> iter 77000, loss: 0.037228
 >> iter 78000, loss: 0.014882
 >> iter 79000, loss: 0.006617
 >> iter 80000, loss: 0.003836
   Number of active neurons: 10
 >> iter 81000, loss: 0.002487
 >> iter 82000, loss: 0.001957
 >> iter 83000, loss: 0.023478
 >> iter 84000, loss: 0.010377
 >> iter 85000, loss: 0.005010
 >> iter 86000, loss: 0.020057
 >> iter 87000, loss: 0.027182
 >> iter 88000, loss: 0.011177
 >> iter 89000, loss: 0.005819
 >> iter 90000, loss: 0.004483
   Number of active neurons: 10
 >> iter 91000, loss: 0.002794
 >> iter 92000, loss: 0.016158
 >> iter 93000, loss: 0.006972
 >> iter 94000, loss: 0.003601
 >> iter 95000, loss: 0.002325
 >> iter 96000, loss: 0.012971
 >> iter 97000, loss: 0.005783
 >> iter 98000, loss: 0.016705
 >> iter 99000, loss: 0.007248
 >> iter 100000, loss: 0.004428
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.621664
 >> iter 2000, loss: 11.209815
 >> iter 3000, loss: 7.296445
 >> iter 4000, loss: 4.042819
 >> iter 5000, loss: 1.968427
 >> iter 6000, loss: 1.074519
 >> iter 7000, loss: 0.663290
 >> iter 8000, loss: 0.366463
 >> iter 9000, loss: 0.327555
 >> iter 10000, loss: 0.217084
   Number of active neurons: 10
 >> iter 11000, loss: 0.187967
 >> iter 12000, loss: 0.146997
 >> iter 13000, loss: 0.098220
 >> iter 14000, loss: 0.219628
 >> iter 15000, loss: 0.175125
 >> iter 16000, loss: 0.116232
 >> iter 17000, loss: 0.164324
 >> iter 18000, loss: 0.140297
 >> iter 19000, loss: 0.105854
 >> iter 20000, loss: 0.054272
   Number of active neurons: 10
 >> iter 21000, loss: 0.101963
 >> iter 22000, loss: 0.083139
 >> iter 23000, loss: 0.055132
 >> iter 24000, loss: 0.100780
 >> iter 25000, loss: 0.228265
 >> iter 26000, loss: 0.130601
 >> iter 27000, loss: 0.112971
 >> iter 28000, loss: 0.069772
 >> iter 29000, loss: 0.054583
 >> iter 30000, loss: 0.091703
   Number of active neurons: 10
 >> iter 31000, loss: 0.083338
 >> iter 32000, loss: 0.062774
 >> iter 33000, loss: 0.077622
 >> iter 34000, loss: 0.049582
 >> iter 35000, loss: 0.054294
 >> iter 36000, loss: 0.044826
 >> iter 37000, loss: 0.092429
 >> iter 38000, loss: 0.038682
 >> iter 39000, loss: 0.019491
 >> iter 40000, loss: 0.102372
   Number of active neurons: 10
 >> iter 41000, loss: 0.083213
 >> iter 42000, loss: 0.070447
 >> iter 43000, loss: 0.064125
 >> iter 44000, loss: 0.077447
 >> iter 45000, loss: 0.034755
 >> iter 46000, loss: 0.030158
 >> iter 47000, loss: 0.044021
 >> iter 48000, loss: 0.020053
 >> iter 49000, loss: 0.025175
 >> iter 50000, loss: 0.012207
   Number of active neurons: 10
 >> iter 51000, loss: 0.032086
 >> iter 52000, loss: 0.022803
 >> iter 53000, loss: 0.048951
 >> iter 54000, loss: 0.022641
 >> iter 55000, loss: 0.011549
 >> iter 56000, loss: 0.007600
 >> iter 57000, loss: 0.019831
 >> iter 58000, loss: 0.010064
 >> iter 59000, loss: 0.019971
 >> iter 60000, loss: 0.037205
   Number of active neurons: 10
 >> iter 61000, loss: 0.032303
 >> iter 62000, loss: 0.014291
 >> iter 63000, loss: 0.049674
 >> iter 64000, loss: 0.037104
 >> iter 65000, loss: 0.016525
 >> iter 66000, loss: 0.014372
 >> iter 67000, loss: 0.008102
 >> iter 68000, loss: 0.030011
 >> iter 69000, loss: 0.014199
 >> iter 70000, loss: 0.007064
   Number of active neurons: 10
 >> iter 71000, loss: 0.004273
 >> iter 72000, loss: 0.004851
 >> iter 73000, loss: 0.032310
 >> iter 74000, loss: 0.013356
 >> iter 75000, loss: 0.006377
 >> iter 76000, loss: 0.022720
 >> iter 77000, loss: 0.010343
 >> iter 78000, loss: 0.008831
 >> iter 79000, loss: 0.016812
 >> iter 80000, loss: 0.007634
   Number of active neurons: 10
 >> iter 81000, loss: 0.003957
 >> iter 82000, loss: 0.003744
 >> iter 83000, loss: 0.002820
 >> iter 84000, loss: 0.002203
 >> iter 85000, loss: 0.008643
 >> iter 86000, loss: 0.015641
 >> iter 87000, loss: 0.065209
 >> iter 88000, loss: 0.025576
 >> iter 89000, loss: 0.010799
 >> iter 90000, loss: 0.005227
   Number of active neurons: 10
 >> iter 91000, loss: 0.011186
 >> iter 92000, loss: 0.005316
 >> iter 93000, loss: 0.029514
 >> iter 94000, loss: 0.030187
 >> iter 95000, loss: 0.013177
 >> iter 96000, loss: 0.006690
 >> iter 97000, loss: 0.036230
 >> iter 98000, loss: 0.015179
 >> iter 99000, loss: 0.007338
 >> iter 100000, loss: 0.004135
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.404077
 >> iter 2000, loss: 9.568441
 >> iter 3000, loss: 5.260036
 >> iter 4000, loss: 2.387786
 >> iter 5000, loss: 1.077275
 >> iter 6000, loss: 0.618554
 >> iter 7000, loss: 0.320356
 >> iter 8000, loss: 0.304656
 >> iter 9000, loss: 0.183722
 >> iter 10000, loss: 0.103646
   Number of active neurons: 10
 >> iter 11000, loss: 0.110900
 >> iter 12000, loss: 0.127411
 >> iter 13000, loss: 0.110775
 >> iter 14000, loss: 0.144283
 >> iter 15000, loss: 0.105768
 >> iter 16000, loss: 0.067411
 >> iter 17000, loss: 0.083862
 >> iter 18000, loss: 0.047040
 >> iter 19000, loss: 0.101374
 >> iter 20000, loss: 0.059451
   Number of active neurons: 10
 >> iter 21000, loss: 0.171846
 >> iter 22000, loss: 0.142739
 >> iter 23000, loss: 0.148323
 >> iter 24000, loss: 0.086139
 >> iter 25000, loss: 0.067827
 >> iter 26000, loss: 0.061320
 >> iter 27000, loss: 0.047967
 >> iter 28000, loss: 0.041696
 >> iter 29000, loss: 0.082724
 >> iter 30000, loss: 0.035662
   Number of active neurons: 10
 >> iter 31000, loss: 0.017864
 >> iter 32000, loss: 0.047257
 >> iter 33000, loss: 0.035220
 >> iter 34000, loss: 0.020419
 >> iter 35000, loss: 0.011480
 >> iter 36000, loss: 0.035323
 >> iter 37000, loss: 0.024225
 >> iter 38000, loss: 0.030634
 >> iter 39000, loss: 0.048797
 >> iter 40000, loss: 0.021612
   Number of active neurons: 10
 >> iter 41000, loss: 0.019385
 >> iter 42000, loss: 0.033959
 >> iter 43000, loss: 0.016383
 >> iter 44000, loss: 0.008731
 >> iter 45000, loss: 0.006162
 >> iter 46000, loss: 0.013532
 >> iter 47000, loss: 0.059710
 >> iter 48000, loss: 0.032497
 >> iter 49000, loss: 0.045481
 >> iter 50000, loss: 0.032109
   Number of active neurons: 10
 >> iter 51000, loss: 0.014113
 >> iter 52000, loss: 0.007448
 >> iter 53000, loss: 0.004738
 >> iter 54000, loss: 0.004003
 >> iter 55000, loss: 0.003283
 >> iter 56000, loss: 0.030070
 >> iter 57000, loss: 0.034097
 >> iter 58000, loss: 0.036666
 >> iter 59000, loss: 0.015819
 >> iter 60000, loss: 0.061832
   Number of active neurons: 10
 >> iter 61000, loss: 0.039497
 >> iter 62000, loss: 0.016673
 >> iter 63000, loss: 0.033918
 >> iter 64000, loss: 0.028097
 >> iter 65000, loss: 0.012773
 >> iter 66000, loss: 0.006615
 >> iter 67000, loss: 0.101366
 >> iter 68000, loss: 0.114410
 >> iter 69000, loss: 0.077002
 >> iter 70000, loss: 0.031394
   Number of active neurons: 10
 >> iter 71000, loss: 0.018781
 >> iter 72000, loss: 0.020332
 >> iter 73000, loss: 0.076819
 >> iter 74000, loss: 0.031001
 >> iter 75000, loss: 0.013915
 >> iter 76000, loss: 0.007247
 >> iter 77000, loss: 0.004632
 >> iter 78000, loss: 0.003631
 >> iter 79000, loss: 0.028400
 >> iter 80000, loss: 0.075072
   Number of active neurons: 10
 >> iter 81000, loss: 0.030653
 >> iter 82000, loss: 0.055377
 >> iter 83000, loss: 0.044031
 >> iter 84000, loss: 0.048391
 >> iter 85000, loss: 0.040244
 >> iter 86000, loss: 0.028652
 >> iter 87000, loss: 0.037028
 >> iter 88000, loss: 0.016681
 >> iter 89000, loss: 0.013685
 >> iter 90000, loss: 0.007420
   Number of active neurons: 10
 >> iter 91000, loss: 0.005887
 >> iter 92000, loss: 0.004394
 >> iter 93000, loss: 0.019121
 >> iter 94000, loss: 0.040084
 >> iter 95000, loss: 0.017224
 >> iter 96000, loss: 0.008302
 >> iter 97000, loss: 0.029742
 >> iter 98000, loss: 0.013154
 >> iter 99000, loss: 0.019696
 >> iter 100000, loss: 0.032789
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.625005
 >> iter 2000, loss: 9.620151
 >> iter 3000, loss: 5.333577
 >> iter 4000, loss: 2.424175
 >> iter 5000, loss: 1.237414
 >> iter 6000, loss: 0.692273
 >> iter 7000, loss: 0.436970
 >> iter 8000, loss: 0.293595
 >> iter 9000, loss: 0.332107
 >> iter 10000, loss: 0.220588
   Number of active neurons: 10
 >> iter 11000, loss: 0.266639
 >> iter 12000, loss: 0.286410
 >> iter 13000, loss: 0.178353
 >> iter 14000, loss: 0.141888
 >> iter 15000, loss: 0.183373
 >> iter 16000, loss: 0.129980
 >> iter 17000, loss: 0.094573
 >> iter 18000, loss: 0.105815
 >> iter 19000, loss: 0.082652
 >> iter 20000, loss: 0.113251
   Number of active neurons: 10
 >> iter 21000, loss: 0.085872
 >> iter 22000, loss: 0.063200
 >> iter 23000, loss: 0.173007
 >> iter 24000, loss: 0.077071
 >> iter 25000, loss: 0.083025
 >> iter 26000, loss: 0.211486
 >> iter 27000, loss: 0.142589
 >> iter 28000, loss: 0.095771
 >> iter 29000, loss: 0.126192
 >> iter 30000, loss: 0.111461
   Number of active neurons: 10
 >> iter 31000, loss: 0.047096
 >> iter 32000, loss: 0.103113
 >> iter 33000, loss: 0.083211
 >> iter 34000, loss: 0.051396
 >> iter 35000, loss: 0.083917
 >> iter 36000, loss: 0.035954
 >> iter 37000, loss: 0.023896
 >> iter 38000, loss: 0.101970
 >> iter 39000, loss: 0.043088
 >> iter 40000, loss: 0.018861
   Number of active neurons: 10
 >> iter 41000, loss: 0.045126
 >> iter 42000, loss: 0.074083
 >> iter 43000, loss: 0.072705
 >> iter 44000, loss: 0.043636
 >> iter 45000, loss: 0.019594
 >> iter 46000, loss: 0.010500
 >> iter 47000, loss: 0.020676
 >> iter 48000, loss: 0.016974
 >> iter 49000, loss: 0.008056
 >> iter 50000, loss: 0.013030
   Number of active neurons: 10
 >> iter 51000, loss: 0.020399
 >> iter 52000, loss: 0.097424
 >> iter 53000, loss: 0.117758
 >> iter 54000, loss: 0.051253
 >> iter 55000, loss: 0.082242
 >> iter 56000, loss: 0.044225
 >> iter 57000, loss: 0.019386
 >> iter 58000, loss: 0.014354
 >> iter 59000, loss: 0.198690
 >> iter 60000, loss: 0.093890
   Number of active neurons: 10
 >> iter 61000, loss: 0.072234
 >> iter 62000, loss: 0.038937
 >> iter 63000, loss: 0.016903
 >> iter 64000, loss: 0.045321
 >> iter 65000, loss: 0.029528
 >> iter 66000, loss: 0.013475
 >> iter 67000, loss: 0.030724
 >> iter 68000, loss: 0.013560
 >> iter 69000, loss: 0.058726
 >> iter 70000, loss: 0.058024
   Number of active neurons: 10
 >> iter 71000, loss: 0.063706
 >> iter 72000, loss: 0.027173
 >> iter 73000, loss: 0.012168
 >> iter 74000, loss: 0.013073
 >> iter 75000, loss: 0.026531
 >> iter 76000, loss: 0.020555
 >> iter 77000, loss: 0.029460
 >> iter 78000, loss: 0.025333
 >> iter 79000, loss: 0.067516
 >> iter 80000, loss: 0.027811
   Number of active neurons: 10
 >> iter 81000, loss: 0.012967
 >> iter 82000, loss: 0.006387
 >> iter 83000, loss: 0.003743
 >> iter 84000, loss: 0.019690
 >> iter 85000, loss: 0.032107
 >> iter 86000, loss: 0.013230
 >> iter 87000, loss: 0.006086
 >> iter 88000, loss: 0.003313
 >> iter 89000, loss: 0.016864
 >> iter 90000, loss: 0.031661
   Number of active neurons: 10
 >> iter 91000, loss: 0.059460
 >> iter 92000, loss: 0.047266
 >> iter 93000, loss: 0.040599
 >> iter 94000, loss: 0.017186
 >> iter 95000, loss: 0.008051
 >> iter 96000, loss: 0.004433
 >> iter 97000, loss: 0.021078
 >> iter 98000, loss: 0.009676
 >> iter 99000, loss: 0.023318
 >> iter 100000, loss: 0.018386
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.301895
 >> iter 2000, loss: 9.733023
 >> iter 3000, loss: 6.778828
 >> iter 4000, loss: 3.810633
 >> iter 5000, loss: 1.936492
 >> iter 6000, loss: 0.904589
 >> iter 7000, loss: 0.500971
 >> iter 8000, loss: 0.409685
 >> iter 9000, loss: 0.359589
 >> iter 10000, loss: 0.225904
   Number of active neurons: 10
 >> iter 11000, loss: 0.095913
 >> iter 12000, loss: 0.104453
 >> iter 13000, loss: 0.102955
 >> iter 14000, loss: 0.095324
 >> iter 15000, loss: 0.123157
 >> iter 16000, loss: 0.120218
 >> iter 17000, loss: 0.089580
 >> iter 18000, loss: 0.062783
 >> iter 19000, loss: 0.047002
 >> iter 20000, loss: 0.046005
   Number of active neurons: 10
 >> iter 21000, loss: 0.022299
 >> iter 22000, loss: 0.015724
 >> iter 23000, loss: 0.009386
 >> iter 24000, loss: 0.044526
 >> iter 25000, loss: 0.051076
 >> iter 26000, loss: 0.084540
 >> iter 27000, loss: 0.046782
 >> iter 28000, loss: 0.091731
 >> iter 29000, loss: 0.072642
 >> iter 30000, loss: 0.031346
   Number of active neurons: 10
 >> iter 31000, loss: 0.030452
 >> iter 32000, loss: 0.044788
 >> iter 33000, loss: 0.054536
 >> iter 34000, loss: 0.045529
 >> iter 35000, loss: 0.050376
 >> iter 36000, loss: 0.022119
 >> iter 37000, loss: 0.061816
 >> iter 38000, loss: 0.033901
 >> iter 39000, loss: 0.015957
 >> iter 40000, loss: 0.008481
   Number of active neurons: 10
 >> iter 41000, loss: 0.005327
 >> iter 42000, loss: 0.004093
 >> iter 43000, loss: 0.075216
 >> iter 44000, loss: 0.040832
 >> iter 45000, loss: 0.018464
 >> iter 46000, loss: 0.024171
 >> iter 47000, loss: 0.020058
 >> iter 48000, loss: 0.009924
 >> iter 49000, loss: 0.022091
 >> iter 50000, loss: 0.032540
   Number of active neurons: 10
 >> iter 51000, loss: 0.016024
 >> iter 52000, loss: 0.017847
 >> iter 53000, loss: 0.008737
 >> iter 54000, loss: 0.134356
 >> iter 55000, loss: 0.130969
 >> iter 56000, loss: 0.089951
 >> iter 57000, loss: 0.043785
 >> iter 58000, loss: 0.035799
 >> iter 59000, loss: 0.016439
 >> iter 60000, loss: 0.040743
   Number of active neurons: 10
 >> iter 61000, loss: 0.018137
 >> iter 62000, loss: 0.009098
 >> iter 63000, loss: 0.015569
 >> iter 64000, loss: 0.015546
 >> iter 65000, loss: 0.007849
 >> iter 66000, loss: 0.037660
 >> iter 67000, loss: 0.015991
 >> iter 68000, loss: 0.007661
 >> iter 69000, loss: 0.004495
 >> iter 70000, loss: 0.003108
   Number of active neurons: 10
 >> iter 71000, loss: 0.033764
 >> iter 72000, loss: 0.014115
 >> iter 73000, loss: 0.079173
 >> iter 74000, loss: 0.060910
 >> iter 75000, loss: 0.046842
 >> iter 76000, loss: 0.020095
 >> iter 77000, loss: 0.009678
 >> iter 78000, loss: 0.005205
 >> iter 79000, loss: 0.003559
 >> iter 80000, loss: 0.083041
   Number of active neurons: 10
 >> iter 81000, loss: 0.078785
 >> iter 82000, loss: 0.046099
 >> iter 83000, loss: 0.019357
 >> iter 84000, loss: 0.097257
 >> iter 85000, loss: 0.039114
 >> iter 86000, loss: 0.018149
 >> iter 87000, loss: 0.035415
 >> iter 88000, loss: 0.034963
 >> iter 89000, loss: 0.057387
 >> iter 90000, loss: 0.023929
   Number of active neurons: 10
 >> iter 91000, loss: 0.028562
 >> iter 92000, loss: 0.035651
 >> iter 93000, loss: 0.053003
 >> iter 94000, loss: 0.022301
 >> iter 95000, loss: 0.031031
 >> iter 96000, loss: 0.015365
 >> iter 97000, loss: 0.009015
 >> iter 98000, loss: 0.005082
 >> iter 99000, loss: 0.003528
 >> iter 100000, loss: 0.002702
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.874593
 >> iter 2000, loss: 10.026556
 >> iter 3000, loss: 6.584404
 >> iter 4000, loss: 3.703869
 >> iter 5000, loss: 1.978327
 >> iter 6000, loss: 1.085651
 >> iter 7000, loss: 0.608878
 >> iter 8000, loss: 0.376801
 >> iter 9000, loss: 0.299151
 >> iter 10000, loss: 0.175566
   Number of active neurons: 10
 >> iter 11000, loss: 0.178035
 >> iter 12000, loss: 0.113964
 >> iter 13000, loss: 0.144986
 >> iter 14000, loss: 0.063599
 >> iter 15000, loss: 0.077287
 >> iter 16000, loss: 0.117175
 >> iter 17000, loss: 0.204758
 >> iter 18000, loss: 0.171540
 >> iter 19000, loss: 0.132182
 >> iter 20000, loss: 0.107468
   Number of active neurons: 10
 >> iter 21000, loss: 0.109918
 >> iter 22000, loss: 0.093001
 >> iter 23000, loss: 0.157913
 >> iter 24000, loss: 0.149838
 >> iter 25000, loss: 0.099620
 >> iter 26000, loss: 0.062247
 >> iter 27000, loss: 0.028874
 >> iter 28000, loss: 0.136674
 >> iter 29000, loss: 0.081338
 >> iter 30000, loss: 0.089315
   Number of active neurons: 10
 >> iter 31000, loss: 0.058902
 >> iter 32000, loss: 0.052171
 >> iter 33000, loss: 0.024826
 >> iter 34000, loss: 0.044519
 >> iter 35000, loss: 0.030548
 >> iter 36000, loss: 0.016478
 >> iter 37000, loss: 0.066158
 >> iter 38000, loss: 0.028009
 >> iter 39000, loss: 0.069186
 >> iter 40000, loss: 0.028648
   Number of active neurons: 10
 >> iter 41000, loss: 0.021855
 >> iter 42000, loss: 0.010892
 >> iter 43000, loss: 0.006777
 >> iter 44000, loss: 0.019562
 >> iter 45000, loss: 0.009867
 >> iter 46000, loss: 0.006133
 >> iter 47000, loss: 0.007108
 >> iter 48000, loss: 0.008966
 >> iter 49000, loss: 0.005303
 >> iter 50000, loss: 0.003744
   Number of active neurons: 10
 >> iter 51000, loss: 0.002957
 >> iter 52000, loss: 0.002720
 >> iter 53000, loss: 0.002406
 >> iter 54000, loss: 0.002186
 >> iter 55000, loss: 0.002127
 >> iter 56000, loss: 0.020182
 >> iter 57000, loss: 0.053517
 >> iter 58000, loss: 0.023848
 >> iter 59000, loss: 0.010341
 >> iter 60000, loss: 0.005606
   Number of active neurons: 10
 >> iter 61000, loss: 0.003685
 >> iter 62000, loss: 0.002918
 >> iter 63000, loss: 0.002407
 >> iter 64000, loss: 0.007609
 >> iter 65000, loss: 0.044406
 >> iter 66000, loss: 0.017807
 >> iter 67000, loss: 0.007869
 >> iter 68000, loss: 0.011385
 >> iter 69000, loss: 0.026487
 >> iter 70000, loss: 0.016050
   Number of active neurons: 10
 >> iter 71000, loss: 0.007399
 >> iter 72000, loss: 0.004333
 >> iter 73000, loss: 0.003031
 >> iter 74000, loss: 0.002337
 >> iter 75000, loss: 0.066976
 >> iter 76000, loss: 0.063441
 >> iter 77000, loss: 0.025363
 >> iter 78000, loss: 0.022445
 >> iter 79000, loss: 0.135228
 >> iter 80000, loss: 0.053930
   Number of active neurons: 10
 >> iter 81000, loss: 0.022109
 >> iter 82000, loss: 0.009858
 >> iter 83000, loss: 0.005668
 >> iter 84000, loss: 0.003613
 >> iter 85000, loss: 0.002796
 >> iter 86000, loss: 0.002290
 >> iter 87000, loss: 0.002102
 >> iter 88000, loss: 0.001973
 >> iter 89000, loss: 0.031563
 >> iter 90000, loss: 0.012953
   Number of active neurons: 10
 >> iter 91000, loss: 0.105926
 >> iter 92000, loss: 0.045404
 >> iter 93000, loss: 0.018466
 >> iter 94000, loss: 0.022272
 >> iter 95000, loss: 0.009754
 >> iter 96000, loss: 0.004931
 >> iter 97000, loss: 0.003265
 >> iter 98000, loss: 0.006643
 >> iter 99000, loss: 0.004899
 >> iter 100000, loss: 0.025527
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.483911
 >> iter 2000, loss: 9.752926
 >> iter 3000, loss: 7.064265
 >> iter 4000, loss: 4.914596
 >> iter 5000, loss: 3.270093
 >> iter 6000, loss: 2.205590
 >> iter 7000, loss: 1.663112
 >> iter 8000, loss: 1.061890
 >> iter 9000, loss: 0.778196
 >> iter 10000, loss: 0.512178
   Number of active neurons: 10
 >> iter 11000, loss: 0.332738
 >> iter 12000, loss: 0.352629
 >> iter 13000, loss: 0.361581
 >> iter 14000, loss: 0.212535
 >> iter 15000, loss: 0.184942
 >> iter 16000, loss: 0.165883
 >> iter 17000, loss: 0.176519
 >> iter 18000, loss: 0.124896
 >> iter 19000, loss: 0.133100
 >> iter 20000, loss: 0.062827
   Number of active neurons: 10
 >> iter 21000, loss: 0.040417
 >> iter 22000, loss: 0.061486
 >> iter 23000, loss: 0.033830
 >> iter 24000, loss: 0.069152
 >> iter 25000, loss: 0.035645
 >> iter 26000, loss: 0.016480
 >> iter 27000, loss: 0.029616
 >> iter 28000, loss: 0.020032
 >> iter 29000, loss: 0.010800
 >> iter 30000, loss: 0.006617
   Number of active neurons: 10
 >> iter 31000, loss: 0.008540
 >> iter 32000, loss: 0.128823
 >> iter 33000, loss: 0.068476
 >> iter 34000, loss: 0.027966
 >> iter 35000, loss: 0.065559
 >> iter 36000, loss: 0.062263
 >> iter 37000, loss: 0.053253
 >> iter 38000, loss: 0.039920
 >> iter 39000, loss: 0.044746
 >> iter 40000, loss: 0.055105
   Number of active neurons: 10
 >> iter 41000, loss: 0.084089
 >> iter 42000, loss: 0.057728
 >> iter 43000, loss: 0.052868
 >> iter 44000, loss: 0.044033
 >> iter 45000, loss: 0.018819
 >> iter 46000, loss: 0.104571
 >> iter 47000, loss: 0.047804
 >> iter 48000, loss: 0.058346
 >> iter 49000, loss: 0.044456
 >> iter 50000, loss: 0.019108
   Number of active neurons: 10
 >> iter 51000, loss: 0.014241
 >> iter 52000, loss: 0.009208
 >> iter 53000, loss: 0.005865
 >> iter 54000, loss: 0.058315
 >> iter 55000, loss: 0.060874
 >> iter 56000, loss: 0.025493
 >> iter 57000, loss: 0.027761
 >> iter 58000, loss: 0.031966
 >> iter 59000, loss: 0.044736
 >> iter 60000, loss: 0.018653
   Number of active neurons: 10
 >> iter 61000, loss: 0.008614
 >> iter 62000, loss: 0.005026
 >> iter 63000, loss: 0.029658
 >> iter 64000, loss: 0.016894
 >> iter 65000, loss: 0.018976
 >> iter 66000, loss: 0.023475
 >> iter 67000, loss: 0.011169
 >> iter 68000, loss: 0.008430
 >> iter 69000, loss: 0.020373
 >> iter 70000, loss: 0.009008
   Number of active neurons: 10
 >> iter 71000, loss: 0.004615
 >> iter 72000, loss: 0.002761
 >> iter 73000, loss: 0.001931
 >> iter 74000, loss: 0.002460
 >> iter 75000, loss: 0.002262
 >> iter 76000, loss: 0.014272
 >> iter 77000, loss: 0.032627
 >> iter 78000, loss: 0.013100
 >> iter 79000, loss: 0.005914
 >> iter 80000, loss: 0.010228
   Number of active neurons: 10
 >> iter 81000, loss: 0.008006
 >> iter 82000, loss: 0.003815
 >> iter 83000, loss: 0.003223
 >> iter 84000, loss: 0.001969
 >> iter 85000, loss: 0.001473
 >> iter 86000, loss: 0.001226
 >> iter 87000, loss: 0.001100
 >> iter 88000, loss: 0.001021
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.788701
 >> iter 2000, loss: 10.066460
 >> iter 3000, loss: 7.067521
 >> iter 4000, loss: 4.007779
 >> iter 5000, loss: 1.947876
 >> iter 6000, loss: 1.178993
 >> iter 7000, loss: 0.787736
 >> iter 8000, loss: 0.445479
 >> iter 9000, loss: 0.254519
 >> iter 10000, loss: 0.292416
   Number of active neurons: 10
 >> iter 11000, loss: 0.205063
 >> iter 12000, loss: 0.168998
 >> iter 13000, loss: 0.147892
 >> iter 14000, loss: 0.104687
 >> iter 15000, loss: 0.091578
 >> iter 16000, loss: 0.050020
 >> iter 17000, loss: 0.049135
 >> iter 18000, loss: 0.058050
 >> iter 19000, loss: 0.101980
 >> iter 20000, loss: 0.194152
   Number of active neurons: 10
 >> iter 21000, loss: 0.136460
 >> iter 22000, loss: 0.063620
 >> iter 23000, loss: 0.042652
 >> iter 24000, loss: 0.063218
 >> iter 25000, loss: 0.083197
 >> iter 26000, loss: 0.111011
 >> iter 27000, loss: 0.070882
 >> iter 28000, loss: 0.083744
 >> iter 29000, loss: 0.036424
 >> iter 30000, loss: 0.017218
   Number of active neurons: 10
 >> iter 31000, loss: 0.039999
 >> iter 32000, loss: 0.070757
 >> iter 33000, loss: 0.039990
 >> iter 34000, loss: 0.045052
 >> iter 35000, loss: 0.075068
 >> iter 36000, loss: 0.032592
 >> iter 37000, loss: 0.030315
 >> iter 38000, loss: 0.014903
 >> iter 39000, loss: 0.008062
 >> iter 40000, loss: 0.018477
   Number of active neurons: 10
 >> iter 41000, loss: 0.017811
 >> iter 42000, loss: 0.009521
 >> iter 43000, loss: 0.008878
 >> iter 44000, loss: 0.013238
 >> iter 45000, loss: 0.011189
 >> iter 46000, loss: 0.014395
 >> iter 47000, loss: 0.007235
 >> iter 48000, loss: 0.005434
 >> iter 49000, loss: 0.058005
 >> iter 50000, loss: 0.047291
   Number of active neurons: 10
 >> iter 51000, loss: 0.020698
 >> iter 52000, loss: 0.050874
 >> iter 53000, loss: 0.021055
 >> iter 54000, loss: 0.069197
 >> iter 55000, loss: 0.174764
 >> iter 56000, loss: 0.074980
 >> iter 57000, loss: 0.031067
 >> iter 58000, loss: 0.025910
 >> iter 59000, loss: 0.055252
 >> iter 60000, loss: 0.024111
   Number of active neurons: 10
 >> iter 61000, loss: 0.018030
 >> iter 62000, loss: 0.014212
 >> iter 63000, loss: 0.020909
 >> iter 64000, loss: 0.025035
 >> iter 65000, loss: 0.035239
 >> iter 66000, loss: 0.024066
 >> iter 67000, loss: 0.010857
 >> iter 68000, loss: 0.005683
 >> iter 69000, loss: 0.003537
 >> iter 70000, loss: 0.002738
   Number of active neurons: 10
 >> iter 71000, loss: 0.002215
 >> iter 72000, loss: 0.001943
 >> iter 73000, loss: 0.031440
 >> iter 74000, loss: 0.043781
 >> iter 75000, loss: 0.018964
 >> iter 76000, loss: 0.039801
 >> iter 77000, loss: 0.048517
 >> iter 78000, loss: 0.019776
 >> iter 79000, loss: 0.032381
 >> iter 80000, loss: 0.013216
   Number of active neurons: 10
 >> iter 81000, loss: 0.025015
 >> iter 82000, loss: 0.024678
 >> iter 83000, loss: 0.010784
 >> iter 84000, loss: 0.005396
 >> iter 85000, loss: 0.003160
 >> iter 86000, loss: 0.015514
 >> iter 87000, loss: 0.006858
 >> iter 88000, loss: 0.003597
 >> iter 89000, loss: 0.008989
 >> iter 90000, loss: 0.004371
   Number of active neurons: 10
 >> iter 91000, loss: 0.005494
 >> iter 92000, loss: 0.008700
 >> iter 93000, loss: 0.007005
 >> iter 94000, loss: 0.004075
 >> iter 95000, loss: 0.002522
 >> iter 96000, loss: 0.013075
 >> iter 97000, loss: 0.075961
 >> iter 98000, loss: 0.030152
 >> iter 99000, loss: 0.012413
 >> iter 100000, loss: 0.006133
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.578321
 >> iter 2000, loss: 9.658778
 >> iter 3000, loss: 6.324252
 >> iter 4000, loss: 3.613597
 >> iter 5000, loss: 1.706513
 >> iter 6000, loss: 0.791563
 >> iter 7000, loss: 0.483679
 >> iter 8000, loss: 0.304620
 >> iter 9000, loss: 0.261761
 >> iter 10000, loss: 0.202651
   Number of active neurons: 10
 >> iter 11000, loss: 0.229618
 >> iter 12000, loss: 0.125851
 >> iter 13000, loss: 0.058237
 >> iter 14000, loss: 0.148915
 >> iter 15000, loss: 0.203853
 >> iter 16000, loss: 0.120140
 >> iter 17000, loss: 0.054303
 >> iter 18000, loss: 0.036509
 >> iter 19000, loss: 0.041076
 >> iter 20000, loss: 0.021371
   Number of active neurons: 10
 >> iter 21000, loss: 0.013635
 >> iter 22000, loss: 0.080013
 >> iter 23000, loss: 0.035395
 >> iter 24000, loss: 0.185059
 >> iter 25000, loss: 0.093339
 >> iter 26000, loss: 0.125043
 >> iter 27000, loss: 0.054217
 >> iter 28000, loss: 0.040332
 >> iter 29000, loss: 0.053443
 >> iter 30000, loss: 0.025128
   Number of active neurons: 10
 >> iter 31000, loss: 0.034403
 >> iter 32000, loss: 0.047296
 >> iter 33000, loss: 0.023046
 >> iter 34000, loss: 0.026277
 >> iter 35000, loss: 0.055960
 >> iter 36000, loss: 0.054875
 >> iter 37000, loss: 0.097510
 >> iter 38000, loss: 0.074582
 >> iter 39000, loss: 0.075218
 >> iter 40000, loss: 0.059880
   Number of active neurons: 10
 >> iter 41000, loss: 0.111506
 >> iter 42000, loss: 0.057322
 >> iter 43000, loss: 0.035916
 >> iter 44000, loss: 0.020252
 >> iter 45000, loss: 0.028361
 >> iter 46000, loss: 0.077729
 >> iter 47000, loss: 0.034276
 >> iter 48000, loss: 0.045033
 >> iter 49000, loss: 0.026912
 >> iter 50000, loss: 0.012488
   Number of active neurons: 10
 >> iter 51000, loss: 0.049669
 >> iter 52000, loss: 0.058884
 >> iter 53000, loss: 0.024820
 >> iter 54000, loss: 0.011642
 >> iter 55000, loss: 0.022385
 >> iter 56000, loss: 0.010674
 >> iter 57000, loss: 0.028991
 >> iter 58000, loss: 0.024615
 >> iter 59000, loss: 0.011050
 >> iter 60000, loss: 0.021227
   Number of active neurons: 10
 >> iter 61000, loss: 0.023496
 >> iter 62000, loss: 0.015512
 >> iter 63000, loss: 0.007425
 >> iter 64000, loss: 0.006837
 >> iter 65000, loss: 0.043205
 >> iter 66000, loss: 0.021449
 >> iter 67000, loss: 0.009811
 >> iter 68000, loss: 0.047307
 >> iter 69000, loss: 0.020125
 >> iter 70000, loss: 0.031987
   Number of active neurons: 10
 >> iter 71000, loss: 0.061428
 >> iter 72000, loss: 0.032829
 >> iter 73000, loss: 0.093977
 >> iter 74000, loss: 0.051660
 >> iter 75000, loss: 0.021313
 >> iter 76000, loss: 0.010186
 >> iter 77000, loss: 0.005598
 >> iter 78000, loss: 0.003473
 >> iter 79000, loss: 0.021252
 >> iter 80000, loss: 0.026019
   Number of active neurons: 10
 >> iter 81000, loss: 0.011285
 >> iter 82000, loss: 0.005625
 >> iter 83000, loss: 0.019111
 >> iter 84000, loss: 0.008463
 >> iter 85000, loss: 0.004478
 >> iter 86000, loss: 0.002728
 >> iter 87000, loss: 0.002078
 >> iter 88000, loss: 0.001701
 >> iter 89000, loss: 0.001598
 >> iter 90000, loss: 0.001425
   Number of active neurons: 10
 >> iter 91000, loss: 0.002536
 >> iter 92000, loss: 0.001730
 >> iter 93000, loss: 0.001507
 >> iter 94000, loss: 0.018624
 >> iter 95000, loss: 0.007624
 >> iter 96000, loss: 0.003605
 >> iter 97000, loss: 0.002006
 >> iter 98000, loss: 0.001459
 >> iter 99000, loss: 0.001217
 >> iter 100000, loss: 0.001152
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.572541
 >> iter 2000, loss: 9.702154
 >> iter 3000, loss: 6.228132
 >> iter 4000, loss: 3.651171
 >> iter 5000, loss: 2.075611
 >> iter 6000, loss: 1.604457
 >> iter 7000, loss: 1.137393
 >> iter 8000, loss: 0.901115
 >> iter 9000, loss: 0.643687
 >> iter 10000, loss: 0.566812
   Number of active neurons: 10
 >> iter 11000, loss: 0.467147
 >> iter 12000, loss: 0.285595
 >> iter 13000, loss: 0.320968
 >> iter 14000, loss: 0.349001
 >> iter 15000, loss: 0.182954
 >> iter 16000, loss: 0.195888
 >> iter 17000, loss: 0.236677
 >> iter 18000, loss: 0.216956
 >> iter 19000, loss: 0.209962
 >> iter 20000, loss: 0.124848
   Number of active neurons: 10
 >> iter 21000, loss: 0.080598
 >> iter 22000, loss: 0.231738
 >> iter 23000, loss: 0.155443
 >> iter 24000, loss: 0.144490
 >> iter 25000, loss: 0.112705
 >> iter 26000, loss: 0.248349
 >> iter 27000, loss: 0.230626
 >> iter 28000, loss: 0.172260
 >> iter 29000, loss: 0.232746
 >> iter 30000, loss: 0.131051
   Number of active neurons: 10
 >> iter 31000, loss: 0.114034
 >> iter 32000, loss: 0.137754
 >> iter 33000, loss: 0.131175
 >> iter 34000, loss: 0.192001
 >> iter 35000, loss: 0.080115
 >> iter 36000, loss: 0.170816
 >> iter 37000, loss: 0.139498
 >> iter 38000, loss: 0.111117
 >> iter 39000, loss: 0.057665
 >> iter 40000, loss: 0.025494
   Number of active neurons: 10
 >> iter 41000, loss: 0.075128
 >> iter 42000, loss: 0.109675
 >> iter 43000, loss: 0.045579
 >> iter 44000, loss: 0.120850
 >> iter 45000, loss: 0.093813
 >> iter 46000, loss: 0.172785
 >> iter 47000, loss: 0.092169
 >> iter 48000, loss: 0.045432
 >> iter 49000, loss: 0.021107
 >> iter 50000, loss: 0.092211
   Number of active neurons: 10
 >> iter 51000, loss: 0.061908
 >> iter 52000, loss: 0.067970
 >> iter 53000, loss: 0.137559
 >> iter 54000, loss: 0.169562
 >> iter 55000, loss: 0.102723
 >> iter 56000, loss: 0.046287
 >> iter 57000, loss: 0.058441
 >> iter 58000, loss: 0.055353
 >> iter 59000, loss: 0.024051
 >> iter 60000, loss: 0.011521
   Number of active neurons: 10
 >> iter 61000, loss: 0.024425
 >> iter 62000, loss: 0.023018
 >> iter 63000, loss: 0.021035
 >> iter 64000, loss: 0.010865
 >> iter 65000, loss: 0.005667
 >> iter 66000, loss: 0.033461
 >> iter 67000, loss: 0.055113
 >> iter 68000, loss: 0.059377
 >> iter 69000, loss: 0.024344
 >> iter 70000, loss: 0.010968
   Number of active neurons: 10
 >> iter 71000, loss: 0.017148
 >> iter 72000, loss: 0.007891
 >> iter 73000, loss: 0.030402
 >> iter 74000, loss: 0.027489
 >> iter 75000, loss: 0.062692
 >> iter 76000, loss: 0.043529
 >> iter 77000, loss: 0.061234
 >> iter 78000, loss: 0.059082
 >> iter 79000, loss: 0.067621
 >> iter 80000, loss: 0.029209
   Number of active neurons: 10
 >> iter 81000, loss: 0.013043
 >> iter 82000, loss: 0.030650
 >> iter 83000, loss: 0.013389
 >> iter 84000, loss: 0.006807
 >> iter 85000, loss: 0.032967
 >> iter 86000, loss: 0.046598
 >> iter 87000, loss: 0.021483
 >> iter 88000, loss: 0.033643
 >> iter 89000, loss: 0.030168
 >> iter 90000, loss: 0.034259
   Number of active neurons: 10
 >> iter 91000, loss: 0.051146
 >> iter 92000, loss: 0.021709
 >> iter 93000, loss: 0.010512
 >> iter 94000, loss: 0.132709
 >> iter 95000, loss: 0.067544
 >> iter 96000, loss: 0.083374
 >> iter 97000, loss: 0.045240
 >> iter 98000, loss: 0.021229
 >> iter 99000, loss: 0.010176
 >> iter 100000, loss: 0.026593
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.521739
 >> iter 2000, loss: 9.440392
 >> iter 3000, loss: 5.203096
 >> iter 4000, loss: 2.597805
 >> iter 5000, loss: 1.257231
 >> iter 6000, loss: 0.598353
 >> iter 7000, loss: 0.482198
 >> iter 8000, loss: 0.271987
 >> iter 9000, loss: 0.254512
 >> iter 10000, loss: 0.127979
   Number of active neurons: 10
 >> iter 11000, loss: 0.192712
 >> iter 12000, loss: 0.094529
 >> iter 13000, loss: 0.051688
 >> iter 14000, loss: 0.078026
 >> iter 15000, loss: 0.048529
 >> iter 16000, loss: 0.213263
 >> iter 17000, loss: 0.148906
 >> iter 18000, loss: 0.145653
 >> iter 19000, loss: 0.099469
 >> iter 20000, loss: 0.074067
   Number of active neurons: 10
 >> iter 21000, loss: 0.082197
 >> iter 22000, loss: 0.045580
 >> iter 23000, loss: 0.095363
 >> iter 24000, loss: 0.048251
 >> iter 25000, loss: 0.035274
 >> iter 26000, loss: 0.068032
 >> iter 27000, loss: 0.032348
 >> iter 28000, loss: 0.055499
 >> iter 29000, loss: 0.071694
 >> iter 30000, loss: 0.052235
   Number of active neurons: 10
 >> iter 31000, loss: 0.061462
 >> iter 32000, loss: 0.058021
 >> iter 33000, loss: 0.035909
 >> iter 34000, loss: 0.031614
 >> iter 35000, loss: 0.027501
 >> iter 36000, loss: 0.014924
 >> iter 37000, loss: 0.011998
 >> iter 38000, loss: 0.013606
 >> iter 39000, loss: 0.028540
 >> iter 40000, loss: 0.021265
   Number of active neurons: 10
 >> iter 41000, loss: 0.075709
 >> iter 42000, loss: 0.097579
 >> iter 43000, loss: 0.066152
 >> iter 44000, loss: 0.085241
 >> iter 45000, loss: 0.036141
 >> iter 46000, loss: 0.017246
 >> iter 47000, loss: 0.024120
 >> iter 48000, loss: 0.012685
 >> iter 49000, loss: 0.010475
 >> iter 50000, loss: 0.016378
   Number of active neurons: 10
 >> iter 51000, loss: 0.047675
 >> iter 52000, loss: 0.021569
 >> iter 53000, loss: 0.062754
 >> iter 54000, loss: 0.036658
 >> iter 55000, loss: 0.019018
 >> iter 56000, loss: 0.009952
 >> iter 57000, loss: 0.013221
 >> iter 58000, loss: 0.008400
 >> iter 59000, loss: 0.005583
 >> iter 60000, loss: 0.004559
   Number of active neurons: 10
 >> iter 61000, loss: 0.004499
 >> iter 62000, loss: 0.004484
 >> iter 63000, loss: 0.012445
 >> iter 64000, loss: 0.016540
 >> iter 65000, loss: 0.008579
 >> iter 66000, loss: 0.036389
 >> iter 67000, loss: 0.021107
 >> iter 68000, loss: 0.023301
 >> iter 69000, loss: 0.012346
 >> iter 70000, loss: 0.028080
   Number of active neurons: 10
 >> iter 71000, loss: 0.012755
 >> iter 72000, loss: 0.007039
 >> iter 73000, loss: 0.004719
 >> iter 74000, loss: 0.003634
 >> iter 75000, loss: 0.044918
 >> iter 76000, loss: 0.031597
 >> iter 77000, loss: 0.019363
 >> iter 78000, loss: 0.022834
 >> iter 79000, loss: 0.018938
 >> iter 80000, loss: 0.009121
   Number of active neurons: 10
 >> iter 81000, loss: 0.041949
 >> iter 82000, loss: 0.038796
 >> iter 83000, loss: 0.076374
 >> iter 84000, loss: 0.050488
 >> iter 85000, loss: 0.048567
 >> iter 86000, loss: 0.025043
 >> iter 87000, loss: 0.022324
 >> iter 88000, loss: 0.012208
 >> iter 89000, loss: 0.032118
 >> iter 90000, loss: 0.016342
   Number of active neurons: 10
 >> iter 91000, loss: 0.008339
 >> iter 92000, loss: 0.015857
 >> iter 93000, loss: 0.009849
 >> iter 94000, loss: 0.008728
 >> iter 95000, loss: 0.006046
 >> iter 96000, loss: 0.004273
 >> iter 97000, loss: 0.003636
 >> iter 98000, loss: 0.003180
 >> iter 99000, loss: 0.003032
 >> iter 100000, loss: 0.002824
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

