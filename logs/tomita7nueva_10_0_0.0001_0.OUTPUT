 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.833040
 >> iter 2000, loss: 7.654663
 >> iter 3000, loss: 3.451585
 >> iter 4000, loss: 1.434064
 >> iter 5000, loss: 0.697520
 >> iter 6000, loss: 0.331162
 >> iter 7000, loss: 0.197939
 >> iter 8000, loss: 0.131890
 >> iter 9000, loss: 0.166899
 >> iter 10000, loss: 0.151912
   Number of active neurons: 5
 >> iter 11000, loss: 0.262829
 >> iter 12000, loss: 0.174476
 >> iter 13000, loss: 0.376475
 >> iter 14000, loss: 0.283919
 >> iter 15000, loss: 0.260154
 >> iter 16000, loss: 0.217798
 >> iter 17000, loss: 0.344798
 >> iter 18000, loss: 0.324992
 >> iter 19000, loss: 0.851820
 >> iter 20000, loss: 0.595407
   Number of active neurons: 5
 >> iter 21000, loss: 0.627082
 >> iter 22000, loss: 0.342285
 >> iter 23000, loss: 0.384595
 >> iter 24000, loss: 0.264715
 >> iter 25000, loss: 0.489978
 >> iter 26000, loss: 0.307308
 >> iter 27000, loss: 0.259724
 >> iter 28000, loss: 0.400847
 >> iter 29000, loss: 0.194164
 >> iter 30000, loss: 0.434750
   Number of active neurons: 5
 >> iter 31000, loss: 0.420472
 >> iter 32000, loss: 0.368506
 >> iter 33000, loss: 0.409941
 >> iter 34000, loss: 0.292730
 >> iter 35000, loss: 0.265778
 >> iter 36000, loss: 0.396545
 >> iter 37000, loss: 0.383960
 >> iter 38000, loss: 0.415774
 >> iter 39000, loss: 0.304374
 >> iter 40000, loss: 0.163323
   Number of active neurons: 5
 >> iter 41000, loss: 0.528725
 >> iter 42000, loss: 0.710277
 >> iter 43000, loss: 0.528035
 >> iter 44000, loss: 0.327955
 >> iter 45000, loss: 0.254382
 >> iter 46000, loss: 0.231953
 >> iter 47000, loss: 0.297069
 >> iter 48000, loss: 0.191341
 >> iter 49000, loss: 0.355552
 >> iter 50000, loss: 0.340642
   Number of active neurons: 4
 >> iter 51000, loss: 0.308662
 >> iter 52000, loss: 0.283847
 >> iter 53000, loss: 0.282983
 >> iter 54000, loss: 0.285170
 >> iter 55000, loss: 0.313800
 >> iter 56000, loss: 0.257944
 >> iter 57000, loss: 0.223592
 >> iter 58000, loss: 0.233319
 >> iter 59000, loss: 0.220070
 >> iter 60000, loss: 0.153410
   Number of active neurons: 4
 >> iter 61000, loss: 0.275572
 >> iter 62000, loss: 0.178655
 >> iter 63000, loss: 0.205663
 >> iter 64000, loss: 0.180411
 >> iter 65000, loss: 0.340923
 >> iter 66000, loss: 0.297065
 >> iter 67000, loss: 0.250646
 >> iter 68000, loss: 0.158140
 >> iter 69000, loss: 0.172315
 >> iter 70000, loss: 0.127830
   Number of active neurons: 4
 >> iter 71000, loss: 0.140652
 >> iter 72000, loss: 0.106893
 >> iter 73000, loss: 0.187985
 >> iter 74000, loss: 0.118283
 >> iter 75000, loss: 0.132971
 >> iter 76000, loss: 0.112492
 >> iter 77000, loss: 0.150970
 >> iter 78000, loss: 0.110182
 >> iter 79000, loss: 0.106014
 >> iter 80000, loss: 0.104230
   Number of active neurons: 4
 >> iter 81000, loss: 0.181598
 >> iter 82000, loss: 0.191522
 >> iter 83000, loss: 0.177002
 >> iter 84000, loss: 0.149975
 >> iter 85000, loss: 0.191229
 >> iter 86000, loss: 0.091754
 >> iter 87000, loss: 0.307732
 >> iter 88000, loss: 0.214435
 >> iter 89000, loss: 0.379247
 >> iter 90000, loss: 0.165520
   Number of active neurons: 4
 >> iter 91000, loss: 0.284150
 >> iter 92000, loss: 0.273428
 >> iter 93000, loss: 0.154121
 >> iter 94000, loss: 0.141005
 >> iter 95000, loss: 0.344090
 >> iter 96000, loss: 0.150179
 >> iter 97000, loss: 0.228564
 >> iter 98000, loss: 0.158020
 >> iter 99000, loss: 0.113618
 >> iter 100000, loss: 0.138759
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0359992800144
   - Test - Long: 0.0
   - Test - Big: 0.0409995900041
   - Test - A: 55.7229518032
   - Test - B: 19.4453703086
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.939609
 >> iter 2000, loss: 6.654242
 >> iter 3000, loss: 2.518864
 >> iter 4000, loss: 1.144441
 >> iter 5000, loss: 0.557211
 >> iter 6000, loss: 0.269780
 >> iter 7000, loss: 0.507045
 >> iter 8000, loss: 0.217986
 >> iter 9000, loss: 0.224076
 >> iter 10000, loss: 0.107765
   Number of active neurons: 8
 >> iter 11000, loss: 0.215809
 >> iter 12000, loss: 0.133264
 >> iter 13000, loss: 0.340417
 >> iter 14000, loss: 0.151197
 >> iter 15000, loss: 0.335847
 >> iter 16000, loss: 0.199842
 >> iter 17000, loss: 0.356670
 >> iter 18000, loss: 0.156452
 >> iter 19000, loss: 0.192500
 >> iter 20000, loss: 0.093110
   Number of active neurons: 6
 >> iter 21000, loss: 0.118463
 >> iter 22000, loss: 0.428569
 >> iter 23000, loss: 0.188224
 >> iter 24000, loss: 0.170945
 >> iter 25000, loss: 0.138445
 >> iter 26000, loss: 0.071984
 >> iter 27000, loss: 0.055982
 >> iter 28000, loss: 0.193467
 >> iter 29000, loss: 0.121476
 >> iter 30000, loss: 0.206896
   Number of active neurons: 5
 >> iter 31000, loss: 0.151354
 >> iter 32000, loss: 0.146986
 >> iter 33000, loss: 0.089782
 >> iter 34000, loss: 0.161326
 >> iter 35000, loss: 0.082938
 >> iter 36000, loss: 0.142681
 >> iter 37000, loss: 0.127118
 >> iter 38000, loss: 0.248458
 >> iter 39000, loss: 0.118987
 >> iter 40000, loss: 0.124912
   Number of active neurons: 5
 >> iter 41000, loss: 0.148335
 >> iter 42000, loss: 0.122489
 >> iter 43000, loss: 0.099652
 >> iter 44000, loss: 0.070968
 >> iter 45000, loss: 0.075956
 >> iter 46000, loss: 0.085235
 >> iter 47000, loss: 0.207481
 >> iter 48000, loss: 0.134777
 >> iter 49000, loss: 0.119362
 >> iter 50000, loss: 0.230230
   Number of active neurons: 5
 >> iter 51000, loss: 0.224297
 >> iter 52000, loss: 0.133596
 >> iter 53000, loss: 0.123736
 >> iter 54000, loss: 0.098923
 >> iter 55000, loss: 0.055390
 >> iter 56000, loss: 0.074544
 >> iter 57000, loss: 0.205097
 >> iter 58000, loss: 0.123184
 >> iter 59000, loss: 0.422129
 >> iter 60000, loss: 0.180345
   Number of active neurons: 5
 >> iter 61000, loss: 0.096796
 >> iter 62000, loss: 0.242334
 >> iter 63000, loss: 0.129646
 >> iter 64000, loss: 0.101406
 >> iter 65000, loss: 0.158824
 >> iter 66000, loss: 0.232763
 >> iter 67000, loss: 0.201539
 >> iter 68000, loss: 0.114740
 >> iter 69000, loss: 0.287371
 >> iter 70000, loss: 0.159375
   Number of active neurons: 5
 >> iter 71000, loss: 0.111518
 >> iter 72000, loss: 0.083024
 >> iter 73000, loss: 0.238615
 >> iter 74000, loss: 0.107617
 >> iter 75000, loss: 0.073409
 >> iter 76000, loss: 0.127113
 >> iter 77000, loss: 0.148256
 >> iter 78000, loss: 0.422949
 >> iter 79000, loss: 0.301009
 >> iter 80000, loss: 0.131586
   Number of active neurons: 5
 >> iter 81000, loss: 0.097396
 >> iter 82000, loss: 0.052681
 >> iter 83000, loss: 0.140400
 >> iter 84000, loss: 0.120269
 >> iter 85000, loss: 0.494968
 >> iter 86000, loss: 0.229827
 >> iter 87000, loss: 0.174134
 >> iter 88000, loss: 0.082704
 >> iter 89000, loss: 0.160739
 >> iter 90000, loss: 0.189959
   Number of active neurons: 5
 >> iter 91000, loss: 0.154945
 >> iter 92000, loss: 0.099621
 >> iter 93000, loss: 0.054408
 >> iter 94000, loss: 0.111513
 >> iter 95000, loss: 0.058060
 >> iter 96000, loss: 0.505363
 >> iter 97000, loss: 0.213589
 >> iter 98000, loss: 0.098508
 >> iter 99000, loss: 0.212259
 >> iter 100000, loss: 0.209453
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 21.9985334311
   - Test - B: 0.00666622225185
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.236866
 >> iter 2000, loss: 8.055032
 >> iter 3000, loss: 3.188844
 >> iter 4000, loss: 1.209924
 >> iter 5000, loss: 0.552385
 >> iter 6000, loss: 0.226237
 >> iter 7000, loss: 0.335709
 >> iter 8000, loss: 0.199398
 >> iter 9000, loss: 0.203994
 >> iter 10000, loss: 0.098189
   Number of active neurons: 7
 >> iter 11000, loss: 0.173917
 >> iter 12000, loss: 0.087884
 >> iter 13000, loss: 0.213034
 >> iter 14000, loss: 0.139401
 >> iter 15000, loss: 0.134618
 >> iter 16000, loss: 0.106870
 >> iter 17000, loss: 0.270713
 >> iter 18000, loss: 0.125674
 >> iter 19000, loss: 0.131877
 >> iter 20000, loss: 0.108372
   Number of active neurons: 6
 >> iter 21000, loss: 0.253092
 >> iter 22000, loss: 0.267397
 >> iter 23000, loss: 0.208935
 >> iter 24000, loss: 0.138513
 >> iter 25000, loss: 0.293597
 >> iter 26000, loss: 0.179690
 >> iter 27000, loss: 0.219203
 >> iter 28000, loss: 0.200237
 >> iter 29000, loss: 0.329296
 >> iter 30000, loss: 0.226257
   Number of active neurons: 6
 >> iter 31000, loss: 0.271318
 >> iter 32000, loss: 0.182640
 >> iter 33000, loss: 0.153901
 >> iter 34000, loss: 0.331415
 >> iter 35000, loss: 0.218140
 >> iter 36000, loss: 0.216910
 >> iter 37000, loss: 0.287884
 >> iter 38000, loss: 0.294349
 >> iter 39000, loss: 0.181399
 >> iter 40000, loss: 0.197163
   Number of active neurons: 6
 >> iter 41000, loss: 0.386468
 >> iter 42000, loss: 0.267523
 >> iter 43000, loss: 0.335766
 >> iter 44000, loss: 0.192736
 >> iter 45000, loss: 0.125259
 >> iter 46000, loss: 0.093858
 >> iter 47000, loss: 0.221896
 >> iter 48000, loss: 0.103119
 >> iter 49000, loss: 0.468468
 >> iter 50000, loss: 0.202135
   Number of active neurons: 6
 >> iter 51000, loss: 0.124188
 >> iter 52000, loss: 0.098490
 >> iter 53000, loss: 0.200141
 >> iter 54000, loss: 0.181365
 >> iter 55000, loss: 0.155892
 >> iter 56000, loss: 0.274545
 >> iter 57000, loss: 0.310093
 >> iter 58000, loss: 0.275554
 >> iter 59000, loss: 0.262693
 >> iter 60000, loss: 0.397400
   Number of active neurons: 5
 >> iter 61000, loss: 0.321552
 >> iter 62000, loss: 0.148444
 >> iter 63000, loss: 0.206825
 >> iter 64000, loss: 0.186339
 >> iter 65000, loss: 0.147636
 >> iter 66000, loss: 0.171634
 >> iter 67000, loss: 0.276900
 >> iter 68000, loss: 0.312777
 >> iter 69000, loss: 0.159941
 >> iter 70000, loss: 0.172513
   Number of active neurons: 5
 >> iter 71000, loss: 0.602784
 >> iter 72000, loss: 0.355034
 >> iter 73000, loss: 0.176639
 >> iter 74000, loss: 0.129163
 >> iter 75000, loss: 0.290797
 >> iter 76000, loss: 0.302361
 >> iter 77000, loss: 0.209126
 >> iter 78000, loss: 0.169299
 >> iter 79000, loss: 0.577041
 >> iter 80000, loss: 0.283935
   Number of active neurons: 5
 >> iter 81000, loss: 0.316365
 >> iter 82000, loss: 0.187916
 >> iter 83000, loss: 0.094393
 >> iter 84000, loss: 0.286839
 >> iter 85000, loss: 0.227588
 >> iter 86000, loss: 0.329662
 >> iter 87000, loss: 0.410310
 >> iter 88000, loss: 0.282005
 >> iter 89000, loss: 0.290173
 >> iter 90000, loss: 0.132039
   Number of active neurons: 5
 >> iter 91000, loss: 0.251265
 >> iter 92000, loss: 0.249028
 >> iter 93000, loss: 0.408663
 >> iter 94000, loss: 0.598927
 >> iter 95000, loss: 0.275517
 >> iter 96000, loss: 0.135694
 >> iter 97000, loss: 0.132837
 >> iter 98000, loss: 0.208179
 >> iter 99000, loss: 0.148440
 >> iter 100000, loss: 0.239935
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.539989200216
   - Test - Long: 1.23493825309
   - Test - Big: 0.691993080069
   - Test - A: 62.2358509433
   - Test - B: 28.8380774615
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.939293
 >> iter 2000, loss: 11.662120
 >> iter 3000, loss: 9.200571
 >> iter 4000, loss: 4.049989
 >> iter 5000, loss: 1.748475
 >> iter 6000, loss: 0.854874
 >> iter 7000, loss: 0.458601
 >> iter 8000, loss: 0.270167
 >> iter 9000, loss: 0.442108
 >> iter 10000, loss: 0.269485
   Number of active neurons: 4
 >> iter 11000, loss: 0.358687
 >> iter 12000, loss: 0.223830
 >> iter 13000, loss: 0.271402
 >> iter 14000, loss: 0.272535
 >> iter 15000, loss: 0.198255
 >> iter 16000, loss: 0.174413
 >> iter 17000, loss: 0.274528
 >> iter 18000, loss: 0.357255
 >> iter 19000, loss: 0.193337
 >> iter 20000, loss: 0.180217
   Number of active neurons: 4
 >> iter 21000, loss: 0.297346
 >> iter 22000, loss: 0.237600
 >> iter 23000, loss: 0.146302
 >> iter 24000, loss: 0.076726
 >> iter 25000, loss: 0.073878
 >> iter 26000, loss: 0.046130
 >> iter 27000, loss: 0.064532
 >> iter 28000, loss: 0.039323
 >> iter 29000, loss: 0.111577
 >> iter 30000, loss: 0.067750
   Number of active neurons: 4
 >> iter 31000, loss: 0.092968
 >> iter 32000, loss: 0.072466
 >> iter 33000, loss: 0.067717
 >> iter 34000, loss: 0.110034
 >> iter 35000, loss: 0.062287
 >> iter 36000, loss: 0.070070
 >> iter 37000, loss: 0.044272
 >> iter 38000, loss: 0.032640
 >> iter 39000, loss: 0.121653
 >> iter 40000, loss: 0.064642
   Number of active neurons: 4
 >> iter 41000, loss: 0.250353
 >> iter 42000, loss: 0.121992
 >> iter 43000, loss: 0.123868
 >> iter 44000, loss: 0.080359
 >> iter 45000, loss: 0.136064
 >> iter 46000, loss: 0.133756
 >> iter 47000, loss: 0.168520
 >> iter 48000, loss: 0.125672
 >> iter 49000, loss: 0.076332
 >> iter 50000, loss: 0.063850
   Number of active neurons: 4
 >> iter 51000, loss: 0.040238
 >> iter 52000, loss: 0.084597
 >> iter 53000, loss: 0.291413
 >> iter 54000, loss: 0.284575
 >> iter 55000, loss: 0.133871
 >> iter 56000, loss: 0.094443
 >> iter 57000, loss: 0.316237
 >> iter 58000, loss: 0.248883
 >> iter 59000, loss: 0.204303
 >> iter 60000, loss: 0.186080
   Number of active neurons: 4
 >> iter 61000, loss: 0.101622
 >> iter 62000, loss: 0.083729
 >> iter 63000, loss: 0.218646
 >> iter 64000, loss: 0.154613
 >> iter 65000, loss: 0.124320
 >> iter 66000, loss: 0.121288
 >> iter 67000, loss: 0.062852
 >> iter 68000, loss: 0.101898
 >> iter 69000, loss: 0.158656
 >> iter 70000, loss: 0.160460
   Number of active neurons: 4
 >> iter 71000, loss: 0.185297
 >> iter 72000, loss: 0.191794
 >> iter 73000, loss: 0.122114
 >> iter 74000, loss: 0.085984
 >> iter 75000, loss: 0.178466
 >> iter 76000, loss: 0.123924
 >> iter 77000, loss: 0.338775
 >> iter 78000, loss: 0.259417
 >> iter 79000, loss: 0.172186
 >> iter 80000, loss: 0.181218
   Number of active neurons: 4
 >> iter 81000, loss: 0.395107
 >> iter 82000, loss: 0.177622
 >> iter 83000, loss: 0.204040
 >> iter 84000, loss: 0.140616
 >> iter 85000, loss: 0.213719
 >> iter 86000, loss: 0.133946
 >> iter 87000, loss: 0.131030
 >> iter 88000, loss: 0.071223
 >> iter 89000, loss: 0.259437
 >> iter 90000, loss: 0.213610
   Number of active neurons: 4
 >> iter 91000, loss: 0.145261
 >> iter 92000, loss: 0.073946
 >> iter 93000, loss: 0.194691
 >> iter 94000, loss: 0.097524
 >> iter 95000, loss: 0.317619
 >> iter 96000, loss: 0.251245
 >> iter 97000, loss: 0.337900
 >> iter 98000, loss: 0.191775
 >> iter 99000, loss: 0.345597
 >> iter 100000, loss: 0.447356
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.00799984000319
   - Test - Long: 0.0549972501375
   - Test - Big: 0.0779992200078
   - Test - A: 8.74608359443
   - Test - B: 19.3787080861
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.910231
 >> iter 2000, loss: 8.058687
 >> iter 3000, loss: 3.169613
 >> iter 4000, loss: 1.209451
 >> iter 5000, loss: 0.566937
 >> iter 6000, loss: 0.248568
 >> iter 7000, loss: 0.157979
 >> iter 8000, loss: 0.088699
 >> iter 9000, loss: 0.104350
 >> iter 10000, loss: 0.058110
   Number of active neurons: 4
 >> iter 11000, loss: 0.093006
 >> iter 12000, loss: 0.075000
 >> iter 13000, loss: 0.146446
 >> iter 14000, loss: 0.077224
 >> iter 15000, loss: 0.108994
 >> iter 16000, loss: 0.118031
 >> iter 17000, loss: 0.244019
 >> iter 18000, loss: 0.111895
 >> iter 19000, loss: 0.198206
 >> iter 20000, loss: 0.095096
   Number of active neurons: 4
 >> iter 21000, loss: 0.144183
 >> iter 22000, loss: 0.099735
 >> iter 23000, loss: 0.225155
 >> iter 24000, loss: 0.105069
 >> iter 25000, loss: 0.137267
 >> iter 26000, loss: 0.207836
 >> iter 27000, loss: 0.159752
 >> iter 28000, loss: 0.275732
 >> iter 29000, loss: 0.266209
 >> iter 30000, loss: 0.173857
   Number of active neurons: 4
 >> iter 31000, loss: 0.189312
 >> iter 32000, loss: 0.164269
 >> iter 33000, loss: 0.238321
 >> iter 34000, loss: 0.113459
 >> iter 35000, loss: 0.212430
 >> iter 36000, loss: 0.115238
 >> iter 37000, loss: 0.107297
 >> iter 38000, loss: 0.090765
 >> iter 39000, loss: 0.068951
 >> iter 40000, loss: 0.108845
   Number of active neurons: 4
 >> iter 41000, loss: 0.431437
 >> iter 42000, loss: 0.184492
 >> iter 43000, loss: 0.142480
 >> iter 44000, loss: 0.075167
 >> iter 45000, loss: 0.483073
 >> iter 46000, loss: 0.240384
 >> iter 47000, loss: 0.303832
 >> iter 48000, loss: 0.199881
 >> iter 49000, loss: 0.367492
 >> iter 50000, loss: 0.224591
   Number of active neurons: 4
 >> iter 51000, loss: 0.116706
 >> iter 52000, loss: 0.085576
 >> iter 53000, loss: 0.119490
 >> iter 54000, loss: 0.103101
 >> iter 55000, loss: 0.096866
 >> iter 56000, loss: 0.073715
 >> iter 57000, loss: 0.054168
 >> iter 58000, loss: 0.123610
 >> iter 59000, loss: 0.060854
 >> iter 60000, loss: 0.203122
   Number of active neurons: 4
 >> iter 61000, loss: 0.189638
 >> iter 62000, loss: 0.134522
 >> iter 63000, loss: 0.077718
 >> iter 64000, loss: 0.080716
 >> iter 65000, loss: 0.133472
 >> iter 66000, loss: 0.161617
 >> iter 67000, loss: 0.079056
 >> iter 68000, loss: 0.089868
 >> iter 69000, loss: 0.136260
 >> iter 70000, loss: 0.101005
   Number of active neurons: 4
 >> iter 71000, loss: 0.058396
 >> iter 72000, loss: 0.220365
 >> iter 73000, loss: 0.158280
 >> iter 74000, loss: 0.093859
 >> iter 75000, loss: 0.155009
 >> iter 76000, loss: 0.102005
 >> iter 77000, loss: 0.075273
 >> iter 78000, loss: 0.367932
 >> iter 79000, loss: 0.203664
 >> iter 80000, loss: 0.092988
   Number of active neurons: 4
 >> iter 81000, loss: 0.121743
 >> iter 82000, loss: 0.085776
 >> iter 83000, loss: 0.126965
 >> iter 84000, loss: 0.062995
 >> iter 85000, loss: 0.190677
 >> iter 86000, loss: 0.170600
 >> iter 87000, loss: 0.257144
 >> iter 88000, loss: 0.113832
 >> iter 89000, loss: 0.161726
 >> iter 90000, loss: 0.091194
   Number of active neurons: 4
 >> iter 91000, loss: 0.142492
 >> iter 92000, loss: 0.072853
 >> iter 93000, loss: 0.236523
 >> iter 94000, loss: 0.133571
 >> iter 95000, loss: 0.125059
 >> iter 96000, loss: 0.197229
 >> iter 97000, loss: 0.092633
 >> iter 98000, loss: 0.107548
 >> iter 99000, loss: 0.094208
 >> iter 100000, loss: 0.056779
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0109998900011
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.672345
 >> iter 2000, loss: 10.749217
 >> iter 3000, loss: 6.374256
 >> iter 4000, loss: 2.691679
 >> iter 5000, loss: 1.259000
 >> iter 6000, loss: 0.802171
 >> iter 7000, loss: 0.495253
 >> iter 8000, loss: 0.617635
 >> iter 9000, loss: 0.685926
 >> iter 10000, loss: 0.436178
   Number of active neurons: 9
 >> iter 11000, loss: 0.455181
 >> iter 12000, loss: 0.469897
 >> iter 13000, loss: 0.366383
 >> iter 14000, loss: 0.348995
 >> iter 15000, loss: 0.407983
 >> iter 16000, loss: 0.180767
 >> iter 17000, loss: 0.895076
 >> iter 18000, loss: 0.424349
 >> iter 19000, loss: 0.468988
 >> iter 20000, loss: 0.417864
   Number of active neurons: 8
 >> iter 21000, loss: 0.309497
 >> iter 22000, loss: 0.190698
 >> iter 23000, loss: 0.306767
 >> iter 24000, loss: 0.168453
 >> iter 25000, loss: 0.396592
 >> iter 26000, loss: 0.253469
 >> iter 27000, loss: 1.063797
 >> iter 28000, loss: 0.543865
 >> iter 29000, loss: 0.550865
 >> iter 30000, loss: 0.234883
   Number of active neurons: 6
 >> iter 31000, loss: 0.328140
 >> iter 32000, loss: 0.331952
 >> iter 33000, loss: 0.401564
 >> iter 34000, loss: 0.206038
 >> iter 35000, loss: 0.322310
 >> iter 36000, loss: 0.221033
 >> iter 37000, loss: 0.289689
 >> iter 38000, loss: 0.508726
 >> iter 39000, loss: 0.287022
 >> iter 40000, loss: 0.292515
   Number of active neurons: 5
 >> iter 41000, loss: 0.189192
 >> iter 42000, loss: 0.350798
 >> iter 43000, loss: 0.453062
 >> iter 44000, loss: 0.231832
 >> iter 45000, loss: 0.301712
 >> iter 46000, loss: 0.161768
 >> iter 47000, loss: 0.517094
 >> iter 48000, loss: 0.221261
 >> iter 49000, loss: 0.289374
 >> iter 50000, loss: 0.129436
   Number of active neurons: 5
 >> iter 51000, loss: 0.249971
 >> iter 52000, loss: 0.344876
 >> iter 53000, loss: 0.243500
 >> iter 54000, loss: 0.321539
 >> iter 55000, loss: 0.472055
 >> iter 56000, loss: 0.202750
 >> iter 57000, loss: 0.497329
 >> iter 58000, loss: 0.325805
 >> iter 59000, loss: 0.252018
 >> iter 60000, loss: 0.115137
   Number of active neurons: 5
 >> iter 61000, loss: 0.468131
 >> iter 62000, loss: 0.383672
 >> iter 63000, loss: 0.206040
 >> iter 64000, loss: 0.096694
 >> iter 65000, loss: 0.279374
 >> iter 66000, loss: 0.211144
 >> iter 67000, loss: 0.360442
 >> iter 68000, loss: 0.158468
 >> iter 69000, loss: 0.361850
 >> iter 70000, loss: 0.158348
   Number of active neurons: 4
 >> iter 71000, loss: 0.686658
 >> iter 72000, loss: 0.288458
 >> iter 73000, loss: 0.501059
 >> iter 74000, loss: 0.215880
 >> iter 75000, loss: 0.218700
 >> iter 76000, loss: 0.100912
 >> iter 77000, loss: 0.464593
 >> iter 78000, loss: 0.197934
 >> iter 79000, loss: 0.596017
 >> iter 80000, loss: 0.315272
   Number of active neurons: 4
 >> iter 81000, loss: 0.176664
 >> iter 82000, loss: 0.084488
 >> iter 83000, loss: 0.524313
 >> iter 84000, loss: 0.359220
 >> iter 85000, loss: 0.334559
 >> iter 86000, loss: 0.147469
 >> iter 87000, loss: 0.164485
 >> iter 88000, loss: 0.079076
 >> iter 89000, loss: 0.296144
 >> iter 90000, loss: 0.131625
   Number of active neurons: 4
 >> iter 91000, loss: 0.496238
 >> iter 92000, loss: 0.212750
 >> iter 93000, loss: 0.584974
 >> iter 94000, loss: 0.249264
 >> iter 95000, loss: 0.255350
 >> iter 96000, loss: 0.130354
 >> iter 97000, loss: 0.384958
 >> iter 98000, loss: 0.378492
 >> iter 99000, loss: 0.535515
 >> iter 100000, loss: 0.233336
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 17.4788347444
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 17.337324
 >> iter 2000, loss: 10.168588
 >> iter 3000, loss: 4.630345
 >> iter 4000, loss: 2.373042
 >> iter 5000, loss: 1.667287
 >> iter 6000, loss: 1.237560
 >> iter 7000, loss: 0.963567
 >> iter 8000, loss: 1.336855
 >> iter 9000, loss: 0.938038
 >> iter 10000, loss: 1.327316
   Number of active neurons: 7
 >> iter 11000, loss: 0.966949
 >> iter 12000, loss: 0.815785
 >> iter 13000, loss: 0.634429
 >> iter 14000, loss: 0.477930
 >> iter 15000, loss: 0.552757
 >> iter 16000, loss: 0.396307
 >> iter 17000, loss: 0.571614
 >> iter 18000, loss: 0.401134
 >> iter 19000, loss: 0.435307
 >> iter 20000, loss: 0.261311
   Number of active neurons: 6
 >> iter 21000, loss: 0.268009
 >> iter 22000, loss: 0.129839
 >> iter 23000, loss: 0.136033
 >> iter 24000, loss: 0.187934
 >> iter 25000, loss: 0.198840
 >> iter 26000, loss: 0.389740
 >> iter 27000, loss: 0.262200
 >> iter 28000, loss: 0.218634
 >> iter 29000, loss: 0.140394
 >> iter 30000, loss: 0.225541
   Number of active neurons: 5
 >> iter 31000, loss: 0.133611
 >> iter 32000, loss: 0.261287
 >> iter 33000, loss: 0.314599
 >> iter 34000, loss: 0.200478
 >> iter 35000, loss: 0.150543
 >> iter 36000, loss: 0.392324
 >> iter 37000, loss: 0.673986
 >> iter 38000, loss: 0.596204
 >> iter 39000, loss: 0.417009
 >> iter 40000, loss: 0.285028
   Number of active neurons: 5
 >> iter 41000, loss: 0.284386
 >> iter 42000, loss: 0.165344
 >> iter 43000, loss: 0.423262
 >> iter 44000, loss: 0.389482
 >> iter 45000, loss: 0.259368
 >> iter 46000, loss: 0.244218
 >> iter 47000, loss: 0.389999
 >> iter 48000, loss: 0.303901
 >> iter 49000, loss: 0.356835
 >> iter 50000, loss: 0.540976
   Number of active neurons: 6
 >> iter 51000, loss: 0.539138
 >> iter 52000, loss: 0.362353
 >> iter 53000, loss: 0.204515
 >> iter 54000, loss: 0.143207
 >> iter 55000, loss: 0.328529
 >> iter 56000, loss: 0.720276
 >> iter 57000, loss: 0.541586
 >> iter 58000, loss: 0.254906
 >> iter 59000, loss: 0.213749
 >> iter 60000, loss: 0.176224
   Number of active neurons: 5
 >> iter 61000, loss: 0.351164
 >> iter 62000, loss: 0.256371
 >> iter 63000, loss: 0.273802
 >> iter 64000, loss: 0.533744
 >> iter 65000, loss: 0.354905
 >> iter 66000, loss: 0.313061
 >> iter 67000, loss: 0.192898
 >> iter 68000, loss: 0.359964
 >> iter 69000, loss: 0.442025
 >> iter 70000, loss: 0.238436
   Number of active neurons: 6
 >> iter 71000, loss: 0.382608
 >> iter 72000, loss: 0.484327
 >> iter 73000, loss: 0.387043
 >> iter 74000, loss: 0.321215
 >> iter 75000, loss: 0.180012
 >> iter 76000, loss: 0.540377
 >> iter 77000, loss: 0.880791
 >> iter 78000, loss: 0.972067
 >> iter 79000, loss: 0.579240
 >> iter 80000, loss: 0.268836
   Number of active neurons: 6
 >> iter 81000, loss: 0.650842
 >> iter 82000, loss: 0.330350
 >> iter 83000, loss: 0.261065
 >> iter 84000, loss: 0.218802
 >> iter 85000, loss: 0.520297
 >> iter 86000, loss: 0.312119
 >> iter 87000, loss: 0.192365
 >> iter 88000, loss: 0.246850
 >> iter 89000, loss: 0.269670
 >> iter 90000, loss: 0.194041
   Number of active neurons: 5
 >> iter 91000, loss: 0.437973
 >> iter 92000, loss: 0.189870
 >> iter 93000, loss: 0.275775
 >> iter 94000, loss: 0.304236
 >> iter 95000, loss: 0.553280
 >> iter 96000, loss: 0.422644
 >> iter 97000, loss: 0.630390
 >> iter 98000, loss: 0.332329
 >> iter 99000, loss: 0.269840
 >> iter 100000, loss: 0.245607
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0019999600008
   - Test - Long: 0.0049997500125
   - Test - Big: 0.000999990000096
   - Test - A: 20.6652889807
   - Test - B: 9.7193520432
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.531349
 >> iter 2000, loss: 7.950139
 >> iter 3000, loss: 3.250204
 >> iter 4000, loss: 1.317253
 >> iter 5000, loss: 0.661900
 >> iter 6000, loss: 0.286029
 >> iter 7000, loss: 0.242713
 >> iter 8000, loss: 0.167986
 >> iter 9000, loss: 0.253641
 >> iter 10000, loss: 0.126962
   Number of active neurons: 5
 >> iter 11000, loss: 0.130697
 >> iter 12000, loss: 0.120358
 >> iter 13000, loss: 0.143880
 >> iter 14000, loss: 0.102082
 >> iter 15000, loss: 0.183556
 >> iter 16000, loss: 0.155610
 >> iter 17000, loss: 0.259430
 >> iter 18000, loss: 0.137220
 >> iter 19000, loss: 0.145675
 >> iter 20000, loss: 0.147736
   Number of active neurons: 5
 >> iter 21000, loss: 0.203515
 >> iter 22000, loss: 0.144059
 >> iter 23000, loss: 0.195222
 >> iter 24000, loss: 0.241436
 >> iter 25000, loss: 0.222323
 >> iter 26000, loss: 0.153170
 >> iter 27000, loss: 0.269480
 >> iter 28000, loss: 0.351307
 >> iter 29000, loss: 0.280788
 >> iter 30000, loss: 0.320971
   Number of active neurons: 5
 >> iter 31000, loss: 0.200623
 >> iter 32000, loss: 0.222522
 >> iter 33000, loss: 0.251549
 >> iter 34000, loss: 0.171551
 >> iter 35000, loss: 0.211219
 >> iter 36000, loss: 0.275497
 >> iter 37000, loss: 0.269298
 >> iter 38000, loss: 0.196730
 >> iter 39000, loss: 0.346041
 >> iter 40000, loss: 0.364136
   Number of active neurons: 5
 >> iter 41000, loss: 0.300821
 >> iter 42000, loss: 0.138647
 >> iter 43000, loss: 0.446419
 >> iter 44000, loss: 0.412826
 >> iter 45000, loss: 0.289992
 >> iter 46000, loss: 0.233488
 >> iter 47000, loss: 0.326568
 >> iter 48000, loss: 0.171107
 >> iter 49000, loss: 0.315594
 >> iter 50000, loss: 0.189866
   Number of active neurons: 5
 >> iter 51000, loss: 0.596486
 >> iter 52000, loss: 0.310819
 >> iter 53000, loss: 0.196700
 >> iter 54000, loss: 0.379917
 >> iter 55000, loss: 0.241234
 >> iter 56000, loss: 0.277136
 >> iter 57000, loss: 0.238492
 >> iter 58000, loss: 0.232174
 >> iter 59000, loss: 0.466355
 >> iter 60000, loss: 0.242078
   Number of active neurons: 5
 >> iter 61000, loss: 0.486343
 >> iter 62000, loss: 0.209703
 >> iter 63000, loss: 0.702160
 >> iter 64000, loss: 0.519168
 >> iter 65000, loss: 0.545806
 >> iter 66000, loss: 0.247339
 >> iter 67000, loss: 0.513098
 >> iter 68000, loss: 0.369611
 >> iter 69000, loss: 0.272087
 >> iter 70000, loss: 0.276102
   Number of active neurons: 4
 >> iter 71000, loss: 0.359655
 >> iter 72000, loss: 0.242508
 >> iter 73000, loss: 0.454740
 >> iter 74000, loss: 0.768815
 >> iter 75000, loss: 0.375461
 >> iter 76000, loss: 0.162170
 >> iter 77000, loss: 0.334755
 >> iter 78000, loss: 0.225889
 >> iter 79000, loss: 0.269463
 >> iter 80000, loss: 0.123201
   Number of active neurons: 4
 >> iter 81000, loss: 0.529535
 >> iter 82000, loss: 0.288448
 >> iter 83000, loss: 0.404682
 >> iter 84000, loss: 0.205550
 >> iter 85000, loss: 0.238215
 >> iter 86000, loss: 0.158225
 >> iter 87000, loss: 0.360877
 >> iter 88000, loss: 0.171688
 >> iter 89000, loss: 0.296747
 >> iter 90000, loss: 0.348051
   Number of active neurons: 4
 >> iter 91000, loss: 0.284300
 >> iter 92000, loss: 0.134893
 >> iter 93000, loss: 0.458842
 >> iter 94000, loss: 0.226742
 >> iter 95000, loss: 0.299052
 >> iter 96000, loss: 0.224887
 >> iter 97000, loss: 0.189790
 >> iter 98000, loss: 0.089172
 >> iter 99000, loss: 0.140769
 >> iter 100000, loss: 0.098721
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0319993600128
   - Test - Long: 0.069996500175
   - Test - Big: 0.0679993200068
   - Test - A: 23.0184654356
   - Test - B: 20.8452769815
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.578082
 >> iter 2000, loss: 8.243960
 >> iter 3000, loss: 3.073121
 >> iter 4000, loss: 1.164701
 >> iter 5000, loss: 0.530175
 >> iter 6000, loss: 0.231367
 >> iter 7000, loss: 0.192790
 >> iter 8000, loss: 0.094089
 >> iter 9000, loss: 0.117353
 >> iter 10000, loss: 0.119026
   Number of active neurons: 7
 >> iter 11000, loss: 0.083967
 >> iter 12000, loss: 0.150716
 >> iter 13000, loss: 0.078415
 >> iter 14000, loss: 0.139234
 >> iter 15000, loss: 0.073525
 >> iter 16000, loss: 0.093537
 >> iter 17000, loss: 0.129290
 >> iter 18000, loss: 0.068556
 >> iter 19000, loss: 0.054435
 >> iter 20000, loss: 0.079861
   Number of active neurons: 6
 >> iter 21000, loss: 0.253858
 >> iter 22000, loss: 0.123945
 >> iter 23000, loss: 0.071608
 >> iter 24000, loss: 0.078944
 >> iter 25000, loss: 0.082070
 >> iter 26000, loss: 0.089330
 >> iter 27000, loss: 0.058414
 >> iter 28000, loss: 0.116757
 >> iter 29000, loss: 0.063549
 >> iter 30000, loss: 0.089397
   Number of active neurons: 6
 >> iter 31000, loss: 0.058914
 >> iter 32000, loss: 0.161685
 >> iter 33000, loss: 0.083886
 >> iter 34000, loss: 0.090512
 >> iter 35000, loss: 0.073191
 >> iter 36000, loss: 0.140388
 >> iter 37000, loss: 0.120221
 >> iter 38000, loss: 0.327629
 >> iter 39000, loss: 0.196462
 >> iter 40000, loss: 0.193728
   Number of active neurons: 5
 >> iter 41000, loss: 0.244497
 >> iter 42000, loss: 0.123207
 >> iter 43000, loss: 0.123233
 >> iter 44000, loss: 0.229116
 >> iter 45000, loss: 0.151502
 >> iter 46000, loss: 0.203956
 >> iter 47000, loss: 0.241509
 >> iter 48000, loss: 0.130489
 >> iter 49000, loss: 0.066746
 >> iter 50000, loss: 0.082540
   Number of active neurons: 5
 >> iter 51000, loss: 0.097843
 >> iter 52000, loss: 0.067013
 >> iter 53000, loss: 0.041410
 >> iter 54000, loss: 0.140324
 >> iter 55000, loss: 0.199123
 >> iter 56000, loss: 0.108313
 >> iter 57000, loss: 0.144511
 >> iter 58000, loss: 0.087222
 >> iter 59000, loss: 0.479776
 >> iter 60000, loss: 0.292986
   Number of active neurons: 4
 >> iter 61000, loss: 0.199715
 >> iter 62000, loss: 0.180169
 >> iter 63000, loss: 0.084828
 >> iter 64000, loss: 0.091524
 >> iter 65000, loss: 0.228342
 >> iter 66000, loss: 0.109409
 >> iter 67000, loss: 0.087050
 >> iter 68000, loss: 0.122702
 >> iter 69000, loss: 0.116103
 >> iter 70000, loss: 0.142773
   Number of active neurons: 4
 >> iter 71000, loss: 0.098007
 >> iter 72000, loss: 0.137258
 >> iter 73000, loss: 0.117502
 >> iter 74000, loss: 0.160623
 >> iter 75000, loss: 0.099168
 >> iter 76000, loss: 0.099302
 >> iter 77000, loss: 0.074243
 >> iter 78000, loss: 0.327629
 >> iter 79000, loss: 0.414947
 >> iter 80000, loss: 0.194221
   Number of active neurons: 4
 >> iter 81000, loss: 0.123278
 >> iter 82000, loss: 0.216423
 >> iter 83000, loss: 0.155884
 >> iter 84000, loss: 0.268309
 >> iter 85000, loss: 0.182128
 >> iter 86000, loss: 0.160891
 >> iter 87000, loss: 0.105054
 >> iter 88000, loss: 0.077908
 >> iter 89000, loss: 0.075151
 >> iter 90000, loss: 0.096281
   Number of active neurons: 4
 >> iter 91000, loss: 0.098501
 >> iter 92000, loss: 0.119471
 >> iter 93000, loss: 0.064056
 >> iter 94000, loss: 0.707318
 >> iter 95000, loss: 0.330384
 >> iter 96000, loss: 0.183795
 >> iter 97000, loss: 0.124163
 >> iter 98000, loss: 0.081727
 >> iter 99000, loss: 0.093827
 >> iter 100000, loss: 0.201558
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 20.8786080928
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.385136
 >> iter 2000, loss: 7.141589
 >> iter 3000, loss: 2.727051
 >> iter 4000, loss: 1.175927
 >> iter 5000, loss: 0.473077
 >> iter 6000, loss: 0.201293
 >> iter 7000, loss: 0.158201
 >> iter 8000, loss: 0.199925
 >> iter 9000, loss: 0.182671
 >> iter 10000, loss: 0.096340
   Number of active neurons: 6
 >> iter 11000, loss: 0.176598
 >> iter 12000, loss: 0.187046
 >> iter 13000, loss: 0.142114
 >> iter 14000, loss: 0.119339
 >> iter 15000, loss: 0.133726
 >> iter 16000, loss: 0.120327
 >> iter 17000, loss: 0.164033
 >> iter 18000, loss: 0.102401
 >> iter 19000, loss: 0.311540
 >> iter 20000, loss: 0.163527
   Number of active neurons: 6
 >> iter 21000, loss: 0.152184
 >> iter 22000, loss: 0.080088
 >> iter 23000, loss: 0.097672
 >> iter 24000, loss: 0.182851
 >> iter 25000, loss: 0.173785
 >> iter 26000, loss: 0.096024
 >> iter 27000, loss: 0.070509
 >> iter 28000, loss: 0.115662
 >> iter 29000, loss: 0.179756
 >> iter 30000, loss: 0.293205
   Number of active neurons: 6
 >> iter 31000, loss: 0.209538
 >> iter 32000, loss: 0.101643
 >> iter 33000, loss: 0.178911
 >> iter 34000, loss: 0.126283
 >> iter 35000, loss: 0.118907
 >> iter 36000, loss: 0.226570
 >> iter 37000, loss: 0.175476
 >> iter 38000, loss: 0.217649
 >> iter 39000, loss: 0.125328
 >> iter 40000, loss: 0.124300
   Number of active neurons: 6
 >> iter 41000, loss: 0.210504
 >> iter 42000, loss: 0.141252
 >> iter 43000, loss: 0.329213
 >> iter 44000, loss: 0.160417
 >> iter 45000, loss: 0.134632
 >> iter 46000, loss: 0.164589
 >> iter 47000, loss: 0.161756
 >> iter 48000, loss: 0.095773
 >> iter 49000, loss: 0.333973
 >> iter 50000, loss: 0.147707
   Number of active neurons: 5
 >> iter 51000, loss: 0.206917
 >> iter 52000, loss: 0.131222
 >> iter 53000, loss: 0.156612
 >> iter 54000, loss: 0.163437
 >> iter 55000, loss: 0.190023
 >> iter 56000, loss: 0.129143
 >> iter 57000, loss: 0.152255
 >> iter 58000, loss: 0.101313
 >> iter 59000, loss: 0.163685
 >> iter 60000, loss: 0.142274
   Number of active neurons: 5
 >> iter 61000, loss: 0.197193
 >> iter 62000, loss: 0.178785
 >> iter 63000, loss: 0.125711
 >> iter 64000, loss: 0.100393
 >> iter 65000, loss: 0.076282
 >> iter 66000, loss: 0.062785
 >> iter 67000, loss: 0.159300
 >> iter 68000, loss: 0.105781
 >> iter 69000, loss: 0.150313
 >> iter 70000, loss: 0.144368
   Number of active neurons: 4
 >> iter 71000, loss: 0.162354
 >> iter 72000, loss: 0.080461
 >> iter 73000, loss: 0.145832
 >> iter 74000, loss: 0.103490
 >> iter 75000, loss: 0.113117
 >> iter 76000, loss: 0.091813
 >> iter 77000, loss: 0.176325
 >> iter 78000, loss: 0.113336
 >> iter 79000, loss: 0.181622
 >> iter 80000, loss: 0.089491
   Number of active neurons: 4
 >> iter 81000, loss: 0.242965
 >> iter 82000, loss: 0.119377
 >> iter 83000, loss: 0.119072
 >> iter 84000, loss: 0.087556
 >> iter 85000, loss: 0.156781
 >> iter 86000, loss: 0.087275
 >> iter 87000, loss: 0.159806
 >> iter 88000, loss: 0.078046
 >> iter 89000, loss: 0.140716
 >> iter 90000, loss: 0.076334
   Number of active neurons: 4
 >> iter 91000, loss: 0.109442
 >> iter 92000, loss: 0.158836
 >> iter 93000, loss: 0.157774
 >> iter 94000, loss: 0.075364
 >> iter 95000, loss: 0.222537
 >> iter 96000, loss: 0.112106
 >> iter 97000, loss: 0.100663
 >> iter 98000, loss: 0.082116
 >> iter 99000, loss: 0.269060
 >> iter 100000, loss: 0.119376
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0219995600088
   - Test - Long: 0.0049997500125
   - Test - Big: 0.0329996700033
   - Test - A: 59.9360042664
   - Test - B: 17.4121725218
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.445176
 >> iter 2000, loss: 8.860470
 >> iter 3000, loss: 3.543002
 >> iter 4000, loss: 1.455327
 >> iter 5000, loss: 0.725948
 >> iter 6000, loss: 0.323785
 >> iter 7000, loss: 0.223176
 >> iter 8000, loss: 0.139070
 >> iter 9000, loss: 0.080229
 >> iter 10000, loss: 0.072037
   Number of active neurons: 4
 >> iter 11000, loss: 0.078296
 >> iter 12000, loss: 0.071169
 >> iter 13000, loss: 0.084043
 >> iter 14000, loss: 0.068369
 >> iter 15000, loss: 0.155359
 >> iter 16000, loss: 0.164968
 >> iter 17000, loss: 0.145585
 >> iter 18000, loss: 0.089554
 >> iter 19000, loss: 0.153882
 >> iter 20000, loss: 0.122754
   Number of active neurons: 4
 >> iter 21000, loss: 0.149830
 >> iter 22000, loss: 0.238559
 >> iter 23000, loss: 0.363054
 >> iter 24000, loss: 0.239823
 >> iter 25000, loss: 0.169235
 >> iter 26000, loss: 0.128499
 >> iter 27000, loss: 0.358054
 >> iter 28000, loss: 0.422234
 >> iter 29000, loss: 0.256283
 >> iter 30000, loss: 0.151648
   Number of active neurons: 4
 >> iter 31000, loss: 0.199074
 >> iter 32000, loss: 0.165842
 >> iter 33000, loss: 0.376285
 >> iter 34000, loss: 0.201544
 >> iter 35000, loss: 0.379786
 >> iter 36000, loss: 0.193766
 >> iter 37000, loss: 0.398967
 >> iter 38000, loss: 0.296436
 >> iter 39000, loss: 0.230166
 >> iter 40000, loss: 0.281314
   Number of active neurons: 4
 >> iter 41000, loss: 0.235479
 >> iter 42000, loss: 0.174285
 >> iter 43000, loss: 0.336266
 >> iter 44000, loss: 0.166206
 >> iter 45000, loss: 0.326344
 >> iter 46000, loss: 0.180233
 >> iter 47000, loss: 0.298540
 >> iter 48000, loss: 0.143219
 >> iter 49000, loss: 0.332699
 >> iter 50000, loss: 0.264983
   Number of active neurons: 4
 >> iter 51000, loss: 0.519931
 >> iter 52000, loss: 0.237907
 >> iter 53000, loss: 0.263170
 >> iter 54000, loss: 0.147779
 >> iter 55000, loss: 0.294483
 >> iter 56000, loss: 0.144936
 >> iter 57000, loss: 0.319661
 >> iter 58000, loss: 0.182187
 >> iter 59000, loss: 0.366575
 >> iter 60000, loss: 0.240533
   Number of active neurons: 4
 >> iter 61000, loss: 0.196898
 >> iter 62000, loss: 0.097487
 >> iter 63000, loss: 0.216292
 >> iter 64000, loss: 0.266722
 >> iter 65000, loss: 0.345028
 >> iter 66000, loss: 0.172383
 >> iter 67000, loss: 0.502497
 >> iter 68000, loss: 0.228475
 >> iter 69000, loss: 0.501243
 >> iter 70000, loss: 0.221331
   Number of active neurons: 5
 >> iter 71000, loss: 0.270401
 >> iter 72000, loss: 0.122358
 >> iter 73000, loss: 0.130455
 >> iter 74000, loss: 0.079808
 >> iter 75000, loss: 0.299784
 >> iter 76000, loss: 0.132453
 >> iter 77000, loss: 0.151259
 >> iter 78000, loss: 0.147496
 >> iter 79000, loss: 0.358634
 >> iter 80000, loss: 0.200413
   Number of active neurons: 5
 >> iter 81000, loss: 0.094062
 >> iter 82000, loss: 0.086294
 >> iter 83000, loss: 0.293792
 >> iter 84000, loss: 0.152746
 >> iter 85000, loss: 0.203294
 >> iter 86000, loss: 0.115658
 >> iter 87000, loss: 0.061759
 >> iter 88000, loss: 0.144329
 >> iter 89000, loss: 0.116883
 >> iter 90000, loss: 0.149545
   Number of active neurons: 5
 >> iter 91000, loss: 0.083398
 >> iter 92000, loss: 0.200844
 >> iter 93000, loss: 0.092885
 >> iter 94000, loss: 0.090311
 >> iter 95000, loss: 0.138153
 >> iter 96000, loss: 0.072091
 >> iter 97000, loss: 0.093142
 >> iter 98000, loss: 0.115881
 >> iter 99000, loss: 0.060417
 >> iter 100000, loss: 0.337410
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 1.07397852043
   - Test - Long: 0.41997900105
   - Test - Big: 1.19298807012
   - Test - A: 19.3853743084
   - Test - B: 7.57949470035
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.658066
 >> iter 2000, loss: 9.613228
 >> iter 3000, loss: 4.143717
 >> iter 4000, loss: 1.763513
 >> iter 5000, loss: 1.291684
 >> iter 6000, loss: 0.753542
 >> iter 7000, loss: 0.766767
 >> iter 8000, loss: 0.507709
 >> iter 9000, loss: 0.512483
 >> iter 10000, loss: 0.413746
   Number of active neurons: 6
 >> iter 11000, loss: 0.486832
 >> iter 12000, loss: 0.491651
 >> iter 13000, loss: 0.257880
 >> iter 14000, loss: 0.241102
 >> iter 15000, loss: 0.377125
 >> iter 16000, loss: 0.437718
 >> iter 17000, loss: 0.224635
 >> iter 18000, loss: 0.401578
 >> iter 19000, loss: 0.398920
 >> iter 20000, loss: 0.197489
   Number of active neurons: 6
 >> iter 21000, loss: 0.731805
 >> iter 22000, loss: 0.724653
 >> iter 23000, loss: 0.367615
 >> iter 24000, loss: 0.182220
 >> iter 25000, loss: 0.155290
 >> iter 26000, loss: 0.180150
 >> iter 27000, loss: 0.229914
 >> iter 28000, loss: 0.276446
 >> iter 29000, loss: 0.540601
 >> iter 30000, loss: 0.800641
   Number of active neurons: 6
 >> iter 31000, loss: 0.422691
 >> iter 32000, loss: 0.351157
 >> iter 33000, loss: 0.206769
 >> iter 34000, loss: 0.228878
 >> iter 35000, loss: 0.256902
 >> iter 36000, loss: 0.424378
 >> iter 37000, loss: 0.453185
 >> iter 38000, loss: 0.225283
 >> iter 39000, loss: 0.316590
 >> iter 40000, loss: 0.191992
   Number of active neurons: 6
 >> iter 41000, loss: 0.381735
 >> iter 42000, loss: 0.567849
 >> iter 43000, loss: 0.864381
 >> iter 44000, loss: 0.887889
 >> iter 45000, loss: 0.631083
 >> iter 46000, loss: 0.279109
 >> iter 47000, loss: 0.151924
 >> iter 48000, loss: 0.718768
 >> iter 49000, loss: 1.016044
 >> iter 50000, loss: 0.487604
   Number of active neurons: 10
 >> iter 51000, loss: 0.451810
 >> iter 52000, loss: 0.279369
 >> iter 53000, loss: 0.219920
 >> iter 54000, loss: 0.426000
 >> iter 55000, loss: 0.462847
 >> iter 56000, loss: 0.601460
 >> iter 57000, loss: 0.606818
 >> iter 58000, loss: 0.256115
 >> iter 59000, loss: 0.471248
 >> iter 60000, loss: 0.413173
   Number of active neurons: 5
 >> iter 61000, loss: 0.326065
 >> iter 62000, loss: 0.608126
 >> iter 63000, loss: 0.648544
 >> iter 64000, loss: 0.514338
 >> iter 65000, loss: 0.444008
 >> iter 66000, loss: 0.300436
 >> iter 67000, loss: 0.321665
 >> iter 68000, loss: 0.385323
 >> iter 69000, loss: 0.250754
 >> iter 70000, loss: 0.261415
   Number of active neurons: 4
 >> iter 71000, loss: 0.171037
 >> iter 72000, loss: 0.308380
 >> iter 73000, loss: 0.342829
 >> iter 74000, loss: 0.163212
 >> iter 75000, loss: 0.386454
 >> iter 76000, loss: 0.233760
 >> iter 77000, loss: 0.314863
 >> iter 78000, loss: 0.646728
 >> iter 79000, loss: 0.473832
 >> iter 80000, loss: 0.259686
   Number of active neurons: 4
 >> iter 81000, loss: 0.348470
 >> iter 82000, loss: 0.266362
 >> iter 83000, loss: 0.194131
 >> iter 84000, loss: 0.246758
 >> iter 85000, loss: 0.504742
 >> iter 86000, loss: 0.425283
 >> iter 87000, loss: 0.432822
 >> iter 88000, loss: 0.250580
 >> iter 89000, loss: 0.226908
 >> iter 90000, loss: 0.233148
   Number of active neurons: 4
 >> iter 91000, loss: 0.616601
 >> iter 92000, loss: 0.428030
 >> iter 93000, loss: 0.468005
 >> iter 94000, loss: 0.321889
 >> iter 95000, loss: 0.804410
 >> iter 96000, loss: 0.605298
 >> iter 97000, loss: 0.634881
 >> iter 98000, loss: 0.264219
 >> iter 99000, loss: 0.484495
 >> iter 100000, loss: 0.356352
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 14.8190120659
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.258821
 >> iter 2000, loss: 8.896558
 >> iter 3000, loss: 3.754728
 >> iter 4000, loss: 1.497057
 >> iter 5000, loss: 0.869441
 >> iter 6000, loss: 0.855729
 >> iter 7000, loss: 0.396360
 >> iter 8000, loss: 0.220291
 >> iter 9000, loss: 0.102274
 >> iter 10000, loss: 0.111754
   Number of active neurons: 5
 >> iter 11000, loss: 0.306960
 >> iter 12000, loss: 0.238124
 >> iter 13000, loss: 0.203934
 >> iter 14000, loss: 0.403095
 >> iter 15000, loss: 0.231466
 >> iter 16000, loss: 0.205606
 >> iter 17000, loss: 0.522831
 >> iter 18000, loss: 0.320953
 >> iter 19000, loss: 0.331103
 >> iter 20000, loss: 0.151946
   Number of active neurons: 4
 >> iter 21000, loss: 0.570697
 >> iter 22000, loss: 0.351519
 >> iter 23000, loss: 0.218679
 >> iter 24000, loss: 0.099993
 >> iter 25000, loss: 0.441347
 >> iter 26000, loss: 0.616108
 >> iter 27000, loss: 0.948552
 >> iter 28000, loss: 0.554555
 >> iter 29000, loss: 0.297065
 >> iter 30000, loss: 0.134277
   Number of active neurons: 4
 >> iter 31000, loss: 0.436554
 >> iter 32000, loss: 0.483446
 >> iter 33000, loss: 0.818061
 >> iter 34000, loss: 0.589680
 >> iter 35000, loss: 0.319905
 >> iter 36000, loss: 0.385769
 >> iter 37000, loss: 0.513828
 >> iter 38000, loss: 0.691696
 >> iter 39000, loss: 0.613653
 >> iter 40000, loss: 0.282295
   Number of active neurons: 6
 >> iter 41000, loss: 0.256496
 >> iter 42000, loss: 0.130786
 >> iter 43000, loss: 0.445520
 >> iter 44000, loss: 0.209221
 >> iter 45000, loss: 0.182739
 >> iter 46000, loss: 0.113669
 >> iter 47000, loss: 0.378173
 >> iter 48000, loss: 0.165807
 >> iter 49000, loss: 0.506811
 >> iter 50000, loss: 0.667177
   Number of active neurons: 6
 >> iter 51000, loss: 0.572707
 >> iter 52000, loss: 0.345630
 >> iter 53000, loss: 0.321328
 >> iter 54000, loss: 0.263924
 >> iter 55000, loss: 0.378862
 >> iter 56000, loss: 0.410035
 >> iter 57000, loss: 0.319267
 >> iter 58000, loss: 0.179258
 >> iter 59000, loss: 0.219166
 >> iter 60000, loss: 0.146444
   Number of active neurons: 4
 >> iter 61000, loss: 0.338236
 >> iter 62000, loss: 0.181995
 >> iter 63000, loss: 0.179041
 >> iter 64000, loss: 0.150314
 >> iter 65000, loss: 0.530548
 >> iter 66000, loss: 0.259143
 >> iter 67000, loss: 0.220008
 >> iter 68000, loss: 0.132525
 >> iter 69000, loss: 0.192369
 >> iter 70000, loss: 0.101905
   Number of active neurons: 4
 >> iter 71000, loss: 0.201767
 >> iter 72000, loss: 0.238130
 >> iter 73000, loss: 0.506511
 >> iter 74000, loss: 0.233977
 >> iter 75000, loss: 0.181125
 >> iter 76000, loss: 0.143624
 >> iter 77000, loss: 0.120450
 >> iter 78000, loss: 0.071019
 >> iter 79000, loss: 0.234760
 >> iter 80000, loss: 0.128724
   Number of active neurons: 4
 >> iter 81000, loss: 0.351384
 >> iter 82000, loss: 0.205473
 >> iter 83000, loss: 0.216437
 >> iter 84000, loss: 0.101697
 >> iter 85000, loss: 0.448927
 >> iter 86000, loss: 0.230119
 >> iter 87000, loss: 0.291679
 >> iter 88000, loss: 0.131351
 >> iter 89000, loss: 0.271402
 >> iter 90000, loss: 0.122804
   Number of active neurons: 4
 >> iter 91000, loss: 0.433170
 >> iter 92000, loss: 0.317202
 >> iter 93000, loss: 0.236958
 >> iter 94000, loss: 0.151645
 >> iter 95000, loss: 0.205131
 >> iter 96000, loss: 0.095489
 >> iter 97000, loss: 0.252576
 >> iter 98000, loss: 0.115255
 >> iter 99000, loss: 0.189608
 >> iter 100000, loss: 0.120846
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0159996800064
   - Test - Long: 0.0
   - Test - Big: 0.0039999600004
   - Test - A: 51.7965468969
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.560859
 >> iter 2000, loss: 7.913393
 >> iter 3000, loss: 3.660130
 >> iter 4000, loss: 1.562077
 >> iter 5000, loss: 0.765168
 >> iter 6000, loss: 0.379269
 >> iter 7000, loss: 0.493593
 >> iter 8000, loss: 0.374562
 >> iter 9000, loss: 0.439723
 >> iter 10000, loss: 0.382798
   Number of active neurons: 6
 >> iter 11000, loss: 0.320524
 >> iter 12000, loss: 0.507618
 >> iter 13000, loss: 0.408368
 >> iter 14000, loss: 0.294850
 >> iter 15000, loss: 0.399392
 >> iter 16000, loss: 0.369014
 >> iter 17000, loss: 0.635226
 >> iter 18000, loss: 0.375103
 >> iter 19000, loss: 0.333406
 >> iter 20000, loss: 0.287377
   Number of active neurons: 6
 >> iter 21000, loss: 0.188724
 >> iter 22000, loss: 0.219450
 >> iter 23000, loss: 0.700443
 >> iter 24000, loss: 0.761994
 >> iter 25000, loss: 0.435729
 >> iter 26000, loss: 0.243566
 >> iter 27000, loss: 0.224897
 >> iter 28000, loss: 0.125278
 >> iter 29000, loss: 0.146138
 >> iter 30000, loss: 0.078544
   Number of active neurons: 6
 >> iter 31000, loss: 0.338373
 >> iter 32000, loss: 0.195807
 >> iter 33000, loss: 0.360263
 >> iter 34000, loss: 0.343703
 >> iter 35000, loss: 0.344371
 >> iter 36000, loss: 0.193780
 >> iter 37000, loss: 0.161386
 >> iter 38000, loss: 0.344181
 >> iter 39000, loss: 0.621362
 >> iter 40000, loss: 0.512285
   Number of active neurons: 6
 >> iter 41000, loss: 0.431156
 >> iter 42000, loss: 0.304371
 >> iter 43000, loss: 0.256971
 >> iter 44000, loss: 0.161591
 >> iter 45000, loss: 0.353356
 >> iter 46000, loss: 0.218918
 >> iter 47000, loss: 0.293141
 >> iter 48000, loss: 0.294445
 >> iter 49000, loss: 0.159235
 >> iter 50000, loss: 0.235940
   Number of active neurons: 6
 >> iter 51000, loss: 0.360826
 >> iter 52000, loss: 0.182916
 >> iter 53000, loss: 0.343209
 >> iter 54000, loss: 0.660463
 >> iter 55000, loss: 0.316355
 >> iter 56000, loss: 0.236370
 >> iter 57000, loss: 0.787050
 >> iter 58000, loss: 0.559689
 >> iter 59000, loss: 0.574358
 >> iter 60000, loss: 0.436859
   Number of active neurons: 6
 >> iter 61000, loss: 0.212748
 >> iter 62000, loss: 0.326546
 >> iter 63000, loss: 0.354993
 >> iter 64000, loss: 0.178479
 >> iter 65000, loss: 0.319206
 >> iter 66000, loss: 0.704334
 >> iter 67000, loss: 0.465923
 >> iter 68000, loss: 0.567687
 >> iter 69000, loss: 0.799900
 >> iter 70000, loss: 0.754154
   Number of active neurons: 6
 >> iter 71000, loss: 0.619673
 >> iter 72000, loss: 0.308911
 >> iter 73000, loss: 0.232055
 >> iter 74000, loss: 0.235918
 >> iter 75000, loss: 0.113238
 >> iter 76000, loss: 0.258189
 >> iter 77000, loss: 0.226236
 >> iter 78000, loss: 0.280738
 >> iter 79000, loss: 0.319189
 >> iter 80000, loss: 0.480611
   Number of active neurons: 6
 >> iter 81000, loss: 0.500689
 >> iter 82000, loss: 0.309775
 >> iter 83000, loss: 0.181738
 >> iter 84000, loss: 0.525635
 >> iter 85000, loss: 0.333380
 >> iter 86000, loss: 0.149443
 >> iter 87000, loss: 0.549368
 >> iter 88000, loss: 0.547445
 >> iter 89000, loss: 0.725188
 >> iter 90000, loss: 0.499370
   Number of active neurons: 6
 >> iter 91000, loss: 0.848134
 >> iter 92000, loss: 0.438582
 >> iter 93000, loss: 0.333613
 >> iter 94000, loss: 0.319909
 >> iter 95000, loss: 0.421780
 >> iter 96000, loss: 0.495082
 >> iter 97000, loss: 0.476634
 >> iter 98000, loss: 0.207316
 >> iter 99000, loss: 0.209074
 >> iter 100000, loss: 0.142401
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0819983600328
   - Test - Long: 0.0
   - Test - Big: 0.09999900001
   - Test - A: 26.3649090061
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.003645
 >> iter 2000, loss: 8.703328
 >> iter 3000, loss: 3.538748
 >> iter 4000, loss: 1.574991
 >> iter 5000, loss: 0.758949
 >> iter 6000, loss: 0.413647
 >> iter 7000, loss: 0.220534
 >> iter 8000, loss: 0.136530
 >> iter 9000, loss: 0.203419
 >> iter 10000, loss: 0.309654
   Number of active neurons: 4
 >> iter 11000, loss: 0.264759
 >> iter 12000, loss: 0.306088
 >> iter 13000, loss: 0.210305
 >> iter 14000, loss: 0.142288
 >> iter 15000, loss: 0.313532
 >> iter 16000, loss: 0.480766
 >> iter 17000, loss: 0.278843
 >> iter 18000, loss: 0.293714
 >> iter 19000, loss: 0.348866
 >> iter 20000, loss: 0.358287
   Number of active neurons: 4
 >> iter 21000, loss: 0.192579
 >> iter 22000, loss: 0.328130
 >> iter 23000, loss: 0.485743
 >> iter 24000, loss: 0.350304
 >> iter 25000, loss: 0.276790
 >> iter 26000, loss: 0.319922
 >> iter 27000, loss: 0.204663
 >> iter 28000, loss: 0.210946
 >> iter 29000, loss: 0.341599
 >> iter 30000, loss: 0.215299
   Number of active neurons: 4
 >> iter 31000, loss: 0.259105
 >> iter 32000, loss: 0.258915
 >> iter 33000, loss: 0.424053
 >> iter 34000, loss: 0.601617
 >> iter 35000, loss: 0.329533
 >> iter 36000, loss: 0.211943
 >> iter 37000, loss: 0.262289
 >> iter 38000, loss: 0.339979
 >> iter 39000, loss: 0.391438
 >> iter 40000, loss: 0.256895
   Number of active neurons: 4
 >> iter 41000, loss: 0.212222
 >> iter 42000, loss: 0.297444
 >> iter 43000, loss: 0.278807
 >> iter 44000, loss: 0.329238
 >> iter 45000, loss: 0.427788
 >> iter 46000, loss: 0.303580
 >> iter 47000, loss: 0.305991
 >> iter 48000, loss: 0.218312
 >> iter 49000, loss: 0.215224
 >> iter 50000, loss: 0.116990
   Number of active neurons: 5
 >> iter 51000, loss: 0.162003
 >> iter 52000, loss: 0.170254
 >> iter 53000, loss: 0.269139
 >> iter 54000, loss: 0.120750
 >> iter 55000, loss: 0.300599
 >> iter 56000, loss: 0.147919
 >> iter 57000, loss: 0.196125
 >> iter 58000, loss: 0.132049
 >> iter 59000, loss: 0.166532
 >> iter 60000, loss: 0.102092
   Number of active neurons: 5
 >> iter 61000, loss: 0.120903
 >> iter 62000, loss: 0.122551
 >> iter 63000, loss: 0.158776
 >> iter 64000, loss: 0.136929
 >> iter 65000, loss: 0.172645
 >> iter 66000, loss: 0.130204
 >> iter 67000, loss: 0.135078
 >> iter 68000, loss: 0.148452
 >> iter 69000, loss: 0.186952
 >> iter 70000, loss: 0.133392
   Number of active neurons: 4
 >> iter 71000, loss: 0.399668
 >> iter 72000, loss: 0.199052
 >> iter 73000, loss: 0.188749
 >> iter 74000, loss: 0.203718
 >> iter 75000, loss: 0.436568
 >> iter 76000, loss: 0.225827
 >> iter 77000, loss: 0.196365
 >> iter 78000, loss: 0.312934
 >> iter 79000, loss: 0.238237
 >> iter 80000, loss: 0.128228
   Number of active neurons: 4
 >> iter 81000, loss: 0.360926
 >> iter 82000, loss: 0.225514
 >> iter 83000, loss: 0.219986
 >> iter 84000, loss: 0.123144
 >> iter 85000, loss: 0.234814
 >> iter 86000, loss: 0.259630
 >> iter 87000, loss: 0.247718
 >> iter 88000, loss: 0.199478
 >> iter 89000, loss: 0.314512
 >> iter 90000, loss: 0.187783
   Number of active neurons: 4
 >> iter 91000, loss: 0.188973
 >> iter 92000, loss: 0.159839
 >> iter 93000, loss: 0.145482
 >> iter 94000, loss: 0.124008
 >> iter 95000, loss: 0.165779
 >> iter 96000, loss: 0.253336
 >> iter 97000, loss: 0.195940
 >> iter 98000, loss: 0.109563
 >> iter 99000, loss: 0.155809
 >> iter 100000, loss: 0.209030
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 12.9391373908
   - Test - B: 7.3795080328
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 16.816950
 >> iter 2000, loss: 10.174473
 >> iter 3000, loss: 5.332681
 >> iter 4000, loss: 2.301607
 >> iter 5000, loss: 1.075852
 >> iter 6000, loss: 0.502465
 >> iter 7000, loss: 0.330540
 >> iter 8000, loss: 0.535799
 >> iter 9000, loss: 0.347206
 >> iter 10000, loss: 0.225299
   Number of active neurons: 8
 >> iter 11000, loss: 0.461742
 >> iter 12000, loss: 0.236338
 >> iter 13000, loss: 0.242119
 >> iter 14000, loss: 0.192087
 >> iter 15000, loss: 0.267734
 >> iter 16000, loss: 0.183686
 >> iter 17000, loss: 0.172151
 >> iter 18000, loss: 0.181130
 >> iter 19000, loss: 0.318663
 >> iter 20000, loss: 0.248156
   Number of active neurons: 5
 >> iter 21000, loss: 0.260722
 >> iter 22000, loss: 0.268941
 >> iter 23000, loss: 0.201838
 >> iter 24000, loss: 0.493905
 >> iter 25000, loss: 0.607315
 >> iter 26000, loss: 0.279667
 >> iter 27000, loss: 0.284546
 >> iter 28000, loss: 0.317333
 >> iter 29000, loss: 0.423537
 >> iter 30000, loss: 0.574408
   Number of active neurons: 5
 >> iter 31000, loss: 0.272243
 >> iter 32000, loss: 0.274393
 >> iter 33000, loss: 0.178969
 >> iter 34000, loss: 0.306659
 >> iter 35000, loss: 0.223960
 >> iter 36000, loss: 0.351317
 >> iter 37000, loss: 0.392607
 >> iter 38000, loss: 0.408652
 >> iter 39000, loss: 0.431038
 >> iter 40000, loss: 0.224601
   Number of active neurons: 4
 >> iter 41000, loss: 0.245323
 >> iter 42000, loss: 0.517259
 >> iter 43000, loss: 0.275313
 >> iter 44000, loss: 0.303304
 >> iter 45000, loss: 0.267375
 >> iter 46000, loss: 0.220556
 >> iter 47000, loss: 0.208269
 >> iter 48000, loss: 0.139091
 >> iter 49000, loss: 0.374363
 >> iter 50000, loss: 0.185162
   Number of active neurons: 4
 >> iter 51000, loss: 0.153170
 >> iter 52000, loss: 0.320919
 >> iter 53000, loss: 0.221584
 >> iter 54000, loss: 0.328012
 >> iter 55000, loss: 0.358509
 >> iter 56000, loss: 0.388809
 >> iter 57000, loss: 0.321232
 >> iter 58000, loss: 0.758085
 >> iter 59000, loss: 1.043954
 >> iter 60000, loss: 0.618842
   Number of active neurons: 6
 >> iter 61000, loss: 0.281880
 >> iter 62000, loss: 0.201412
 >> iter 63000, loss: 0.380399
 >> iter 64000, loss: 0.227401
 >> iter 65000, loss: 0.424897
 >> iter 66000, loss: 0.242327
 >> iter 67000, loss: 0.550793
 >> iter 68000, loss: 0.237606
 >> iter 69000, loss: 0.208636
 >> iter 70000, loss: 0.416865
   Number of active neurons: 4
 >> iter 71000, loss: 1.097615
 >> iter 72000, loss: 1.367991
 >> iter 73000, loss: 0.842040
 >> iter 74000, loss: 0.386682
 >> iter 75000, loss: 0.173313
 >> iter 76000, loss: 0.684059
 >> iter 77000, loss: 0.529538
 >> iter 78000, loss: 0.282773
 >> iter 79000, loss: 0.260160
 >> iter 80000, loss: 0.644149
   Number of active neurons: 4
 >> iter 81000, loss: 0.554401
 >> iter 82000, loss: 0.233202
 >> iter 83000, loss: 0.466256
 >> iter 84000, loss: 0.334592
 >> iter 85000, loss: 0.232268
 >> iter 86000, loss: 0.420953
 >> iter 87000, loss: 0.472447
 >> iter 88000, loss: 0.202137
 >> iter 89000, loss: 0.562733
 >> iter 90000, loss: 0.518785
   Number of active neurons: 4
 >> iter 91000, loss: 0.565883
 >> iter 92000, loss: 0.249530
 >> iter 93000, loss: 0.182751
 >> iter 94000, loss: 0.555512
 >> iter 95000, loss: 0.541593
 >> iter 96000, loss: 0.228337
 >> iter 97000, loss: 0.202606
 >> iter 98000, loss: 0.427942
 >> iter 99000, loss: 0.341119
 >> iter 100000, loss: 0.181394
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0019999600008
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 20.1853209786
   - Test - B: 19.5720285314
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.509885
 >> iter 2000, loss: 7.076729
 >> iter 3000, loss: 2.646520
 >> iter 4000, loss: 1.007803
 >> iter 5000, loss: 0.411146
 >> iter 6000, loss: 0.171863
 >> iter 7000, loss: 0.103610
 >> iter 8000, loss: 0.057334
 >> iter 9000, loss: 0.103695
 >> iter 10000, loss: 0.058202
   Number of active neurons: 5
 >> iter 11000, loss: 0.116309
 >> iter 12000, loss: 0.187095
 >> iter 13000, loss: 0.148923
 >> iter 14000, loss: 0.112350
 >> iter 15000, loss: 0.129622
 >> iter 16000, loss: 0.068635
 >> iter 17000, loss: 0.272414
 >> iter 18000, loss: 0.122947
 >> iter 19000, loss: 0.148387
 >> iter 20000, loss: 0.097697
   Number of active neurons: 4
 >> iter 21000, loss: 0.111743
 >> iter 22000, loss: 0.146890
 >> iter 23000, loss: 0.298474
 >> iter 24000, loss: 0.229110
 >> iter 25000, loss: 0.143480
 >> iter 26000, loss: 0.089722
 >> iter 27000, loss: 0.398603
 >> iter 28000, loss: 0.245852
 >> iter 29000, loss: 0.154679
 >> iter 30000, loss: 0.090059
   Number of active neurons: 4
 >> iter 31000, loss: 0.202774
 >> iter 32000, loss: 0.110334
 >> iter 33000, loss: 0.141522
 >> iter 34000, loss: 0.095191
 >> iter 35000, loss: 0.090240
 >> iter 36000, loss: 0.068957
 >> iter 37000, loss: 0.133679
 >> iter 38000, loss: 0.083438
 >> iter 39000, loss: 0.337112
 >> iter 40000, loss: 0.205977
   Number of active neurons: 4
 >> iter 41000, loss: 0.151814
 >> iter 42000, loss: 0.115723
 >> iter 43000, loss: 0.170738
 >> iter 44000, loss: 0.090181
 >> iter 45000, loss: 0.113111
 >> iter 46000, loss: 0.071412
 >> iter 47000, loss: 0.103590
 >> iter 48000, loss: 0.293497
 >> iter 49000, loss: 0.136305
 >> iter 50000, loss: 0.067432
   Number of active neurons: 4
 >> iter 51000, loss: 0.187139
 >> iter 52000, loss: 0.156379
 >> iter 53000, loss: 0.141727
 >> iter 54000, loss: 0.144464
 >> iter 55000, loss: 0.229051
 >> iter 56000, loss: 0.170776
 >> iter 57000, loss: 0.424043
 >> iter 58000, loss: 0.217600
 >> iter 59000, loss: 0.303400
 >> iter 60000, loss: 0.144851
   Number of active neurons: 4
 >> iter 61000, loss: 0.403273
 >> iter 62000, loss: 0.173416
 >> iter 63000, loss: 0.084083
 >> iter 64000, loss: 0.113782
 >> iter 65000, loss: 0.114817
 >> iter 66000, loss: 0.217521
 >> iter 67000, loss: 0.107082
 >> iter 68000, loss: 0.102214
 >> iter 69000, loss: 0.190227
 >> iter 70000, loss: 0.153494
   Number of active neurons: 4
 >> iter 71000, loss: 0.217277
 >> iter 72000, loss: 0.204001
 >> iter 73000, loss: 0.111326
 >> iter 74000, loss: 0.260381
 >> iter 75000, loss: 0.150847
 >> iter 76000, loss: 0.191784
 >> iter 77000, loss: 0.196355
 >> iter 78000, loss: 0.094073
 >> iter 79000, loss: 0.056532
 >> iter 80000, loss: 0.058994
   Number of active neurons: 4
 >> iter 81000, loss: 0.072707
 >> iter 82000, loss: 0.088150
 >> iter 83000, loss: 0.065077
 >> iter 84000, loss: 0.122902
 >> iter 85000, loss: 0.102115
 >> iter 86000, loss: 0.119721
 >> iter 87000, loss: 0.133411
 >> iter 88000, loss: 0.065633
 >> iter 89000, loss: 0.249565
 >> iter 90000, loss: 0.111324
   Number of active neurons: 4
 >> iter 91000, loss: 0.064109
 >> iter 92000, loss: 0.083946
 >> iter 93000, loss: 0.064908
 >> iter 94000, loss: 0.104479
 >> iter 95000, loss: 0.064666
 >> iter 96000, loss: 0.094733
 >> iter 97000, loss: 0.124328
 >> iter 98000, loss: 0.394690
 >> iter 99000, loss: 0.209741
 >> iter 100000, loss: 0.096641
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0049999500005
   - Test - A: 0.0
   - Test - B: 0.679954669689
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.945629
 >> iter 2000, loss: 6.545175
 >> iter 3000, loss: 2.507048
 >> iter 4000, loss: 1.089033
 >> iter 5000, loss: 0.581403
 >> iter 6000, loss: 0.434775
 >> iter 7000, loss: 0.323928
 >> iter 8000, loss: 0.258936
 >> iter 9000, loss: 0.326861
 >> iter 10000, loss: 0.245138
   Number of active neurons: 7
 >> iter 11000, loss: 0.146873
 >> iter 12000, loss: 0.106313
 >> iter 13000, loss: 0.075036
 >> iter 14000, loss: 0.055852
 >> iter 15000, loss: 0.415244
 >> iter 16000, loss: 0.204113
 >> iter 17000, loss: 0.156421
 >> iter 18000, loss: 0.129771
 >> iter 19000, loss: 0.184131
 >> iter 20000, loss: 0.154369
   Number of active neurons: 7
 >> iter 21000, loss: 0.201307
 >> iter 22000, loss: 0.107254
 >> iter 23000, loss: 0.468610
 >> iter 24000, loss: 0.400090
 >> iter 25000, loss: 0.207373
 >> iter 26000, loss: 0.169831
 >> iter 27000, loss: 0.685746
 >> iter 28000, loss: 0.403657
 >> iter 29000, loss: 0.197829
 >> iter 30000, loss: 0.296595
   Number of active neurons: 7
 >> iter 31000, loss: 0.153263
 >> iter 32000, loss: 0.255797
 >> iter 33000, loss: 0.314682
 >> iter 34000, loss: 0.191706
 >> iter 35000, loss: 0.163162
 >> iter 36000, loss: 0.205732
 >> iter 37000, loss: 0.203946
 >> iter 38000, loss: 0.647139
 >> iter 39000, loss: 0.346201
 >> iter 40000, loss: 0.494556
   Number of active neurons: 7
 >> iter 41000, loss: 0.243835
 >> iter 42000, loss: 0.180520
 >> iter 43000, loss: 0.150270
 >> iter 44000, loss: 0.398288
 >> iter 45000, loss: 0.193301
 >> iter 46000, loss: 0.305538
 >> iter 47000, loss: 0.143060
 >> iter 48000, loss: 0.118419
 >> iter 49000, loss: 0.160929
 >> iter 50000, loss: 0.164371
   Number of active neurons: 7
 >> iter 51000, loss: 0.365278
 >> iter 52000, loss: 0.240210
 >> iter 53000, loss: 0.202891
 >> iter 54000, loss: 0.234591
 >> iter 55000, loss: 0.232068
 >> iter 56000, loss: 0.143924
 >> iter 57000, loss: 0.226560
 >> iter 58000, loss: 0.162467
 >> iter 59000, loss: 0.208438
 >> iter 60000, loss: 0.121164
   Number of active neurons: 6
 >> iter 61000, loss: 0.287525
 >> iter 62000, loss: 0.235193
 >> iter 63000, loss: 0.254603
 >> iter 64000, loss: 0.326484
 >> iter 65000, loss: 0.146980
 >> iter 66000, loss: 0.161938
 >> iter 67000, loss: 0.297069
 >> iter 68000, loss: 0.170328
 >> iter 69000, loss: 0.138179
 >> iter 70000, loss: 0.229870
   Number of active neurons: 6
 >> iter 71000, loss: 0.128465
 >> iter 72000, loss: 0.281387
 >> iter 73000, loss: 0.269308
 >> iter 74000, loss: 0.151145
 >> iter 75000, loss: 0.608919
 >> iter 76000, loss: 0.347557
 >> iter 77000, loss: 0.207159
 >> iter 78000, loss: 0.185165
 >> iter 79000, loss: 0.160691
 >> iter 80000, loss: 0.153025
   Number of active neurons: 6
 >> iter 81000, loss: 0.307636
 >> iter 82000, loss: 0.135712
 >> iter 83000, loss: 0.172614
 >> iter 84000, loss: 0.188778
 >> iter 85000, loss: 0.088549
 >> iter 86000, loss: 0.101375
 >> iter 87000, loss: 0.057619
 >> iter 88000, loss: 0.057437
 >> iter 89000, loss: 0.130475
 >> iter 90000, loss: 0.179713
   Number of active neurons: 5
 >> iter 91000, loss: 0.146230
 >> iter 92000, loss: 0.256229
 >> iter 93000, loss: 0.572447
 >> iter 94000, loss: 0.250868
 >> iter 95000, loss: 0.113426
 >> iter 96000, loss: 0.117850
 >> iter 97000, loss: 0.065705
 >> iter 98000, loss: 0.202160
 >> iter 99000, loss: 0.231577
 >> iter 100000, loss: 0.156505
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0039999200016
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 54.2363842411
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.994624
 >> iter 2000, loss: 9.522599
 >> iter 3000, loss: 4.497639
 >> iter 4000, loss: 2.021746
 >> iter 5000, loss: 1.280204
 >> iter 6000, loss: 0.671260
 >> iter 7000, loss: 0.509652
 >> iter 8000, loss: 0.347725
 >> iter 9000, loss: 0.274510
 >> iter 10000, loss: 0.283454
   Number of active neurons: 6
 >> iter 11000, loss: 0.347630
 >> iter 12000, loss: 0.387315
 >> iter 13000, loss: 0.335779
 >> iter 14000, loss: 0.186345
 >> iter 15000, loss: 0.209562
 >> iter 16000, loss: 0.186859
 >> iter 17000, loss: 0.236099
 >> iter 18000, loss: 0.445098
 >> iter 19000, loss: 0.339579
 >> iter 20000, loss: 0.316080
   Number of active neurons: 6
 >> iter 21000, loss: 0.279468
 >> iter 22000, loss: 0.227052
 >> iter 23000, loss: 0.231581
 >> iter 24000, loss: 0.266946
 >> iter 25000, loss: 0.211508
 >> iter 26000, loss: 0.184189
 >> iter 27000, loss: 0.214434
 >> iter 28000, loss: 0.242221
 >> iter 29000, loss: 0.233363
 >> iter 30000, loss: 0.344679
   Number of active neurons: 5
 >> iter 31000, loss: 0.531796
 >> iter 32000, loss: 0.277738
 >> iter 33000, loss: 0.292256
 >> iter 34000, loss: 0.365281
 >> iter 35000, loss: 0.276289
 >> iter 36000, loss: 0.164531
 >> iter 37000, loss: 0.198720
 >> iter 38000, loss: 0.095633
 >> iter 39000, loss: 0.295365
 >> iter 40000, loss: 0.204410
   Number of active neurons: 5
 >> iter 41000, loss: 0.285982
 >> iter 42000, loss: 0.300786
 >> iter 43000, loss: 0.274018
 >> iter 44000, loss: 0.411360
 >> iter 45000, loss: 0.355533
 >> iter 46000, loss: 0.156061
 >> iter 47000, loss: 0.411627
 >> iter 48000, loss: 0.331595
 >> iter 49000, loss: 0.223708
 >> iter 50000, loss: 0.110669
   Number of active neurons: 4
 >> iter 51000, loss: 0.368150
 >> iter 52000, loss: 0.262088
 >> iter 53000, loss: 0.420862
 >> iter 54000, loss: 0.184825
 >> iter 55000, loss: 0.194124
 >> iter 56000, loss: 0.381206
 >> iter 57000, loss: 0.244728
 >> iter 58000, loss: 0.159949
 >> iter 59000, loss: 0.238335
 >> iter 60000, loss: 0.183397
   Number of active neurons: 4
 >> iter 61000, loss: 0.294104
 >> iter 62000, loss: 0.353802
 >> iter 63000, loss: 0.370593
 >> iter 64000, loss: 0.259688
 >> iter 65000, loss: 0.165996
 >> iter 66000, loss: 0.139122
 >> iter 67000, loss: 0.313278
 >> iter 68000, loss: 0.191002
 >> iter 69000, loss: 0.147109
 >> iter 70000, loss: 0.125328
   Number of active neurons: 4
 >> iter 71000, loss: 0.333640
 >> iter 72000, loss: 0.213809
 >> iter 73000, loss: 0.335225
 >> iter 74000, loss: 0.203281
 >> iter 75000, loss: 0.389212
 >> iter 76000, loss: 0.229314
 >> iter 77000, loss: 0.206655
 >> iter 78000, loss: 0.226605
 >> iter 79000, loss: 0.409892
 >> iter 80000, loss: 0.480932
   Number of active neurons: 4
 >> iter 81000, loss: 0.788449
 >> iter 82000, loss: 0.451185
 >> iter 83000, loss: 0.249894
 >> iter 84000, loss: 0.232366
 >> iter 85000, loss: 0.223477
 >> iter 86000, loss: 0.235671
 >> iter 87000, loss: 0.236671
 >> iter 88000, loss: 0.145184
 >> iter 89000, loss: 0.298730
 >> iter 90000, loss: 0.441698
   Number of active neurons: 4
 >> iter 91000, loss: 0.355084
 >> iter 92000, loss: 0.160445
 >> iter 93000, loss: 0.127674
 >> iter 94000, loss: 0.209667
 >> iter 95000, loss: 0.339027
 >> iter 96000, loss: 0.590457
 >> iter 97000, loss: 0.386104
 >> iter 98000, loss: 0.180385
 >> iter 99000, loss: 0.324086
 >> iter 100000, loss: 0.388632
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.00599988000241
   - Test - Long: 0.01999900005
   - Test - Big: 0.0049999500005
   - Test - A: 24.8183454436
   - Test - B: 18.2454503033
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 17.335962
 >> iter 2000, loss: 10.466804
 >> iter 3000, loss: 4.712253
 >> iter 4000, loss: 1.771062
 >> iter 5000, loss: 0.779117
 >> iter 6000, loss: 0.374775
 >> iter 7000, loss: 0.238578
 >> iter 8000, loss: 0.112973
 >> iter 9000, loss: 0.107871
 >> iter 10000, loss: 0.064110
   Number of active neurons: 8
 >> iter 11000, loss: 0.156482
 >> iter 12000, loss: 0.087596
 >> iter 13000, loss: 0.111083
 >> iter 14000, loss: 0.106406
 >> iter 15000, loss: 0.073070
 >> iter 16000, loss: 0.056390
 >> iter 17000, loss: 0.044739
 >> iter 18000, loss: 0.086177
 >> iter 19000, loss: 0.119074
 >> iter 20000, loss: 0.317228
   Number of active neurons: 7
 >> iter 21000, loss: 0.155054
 >> iter 22000, loss: 0.179442
 >> iter 23000, loss: 0.091359
 >> iter 24000, loss: 0.074192
 >> iter 25000, loss: 0.072845
 >> iter 26000, loss: 0.147270
 >> iter 27000, loss: 0.084477
 >> iter 28000, loss: 0.058850
 >> iter 29000, loss: 0.064163
 >> iter 30000, loss: 0.400528
   Number of active neurons: 6
 >> iter 31000, loss: 0.182999
 >> iter 32000, loss: 0.205361
 >> iter 33000, loss: 0.102342
 >> iter 34000, loss: 0.063877
 >> iter 35000, loss: 0.077059
 >> iter 36000, loss: 0.069219
 >> iter 37000, loss: 0.385509
 >> iter 38000, loss: 0.166814
 >> iter 39000, loss: 0.110645
 >> iter 40000, loss: 0.081859
   Number of active neurons: 6
 >> iter 41000, loss: 0.135399
 >> iter 42000, loss: 0.069609
 >> iter 43000, loss: 0.094873
 >> iter 44000, loss: 0.229020
 >> iter 45000, loss: 0.124508
 >> iter 46000, loss: 0.125057
 >> iter 47000, loss: 0.494355
 >> iter 48000, loss: 0.246936
 >> iter 49000, loss: 0.415181
 >> iter 50000, loss: 0.183266
   Number of active neurons: 6
 >> iter 51000, loss: 0.097948
 >> iter 52000, loss: 0.212215
 >> iter 53000, loss: 0.108250
 >> iter 54000, loss: 0.074995
 >> iter 55000, loss: 0.068047
 >> iter 56000, loss: 0.172581
 >> iter 57000, loss: 0.092105
 >> iter 58000, loss: 0.085079
 >> iter 59000, loss: 0.202851
 >> iter 60000, loss: 0.191085
   Number of active neurons: 6
 >> iter 61000, loss: 0.247333
 >> iter 62000, loss: 0.135140
 >> iter 63000, loss: 0.294215
 >> iter 64000, loss: 0.236530
 >> iter 65000, loss: 0.137293
 >> iter 66000, loss: 0.148492
 >> iter 67000, loss: 0.251022
 >> iter 68000, loss: 0.143422
 >> iter 69000, loss: 0.291400
 >> iter 70000, loss: 0.156974
   Number of active neurons: 6
 >> iter 71000, loss: 0.154307
 >> iter 72000, loss: 0.167032
 >> iter 73000, loss: 0.246773
 >> iter 74000, loss: 0.148688
 >> iter 75000, loss: 0.149116
 >> iter 76000, loss: 0.225703
 >> iter 77000, loss: 0.260776
 >> iter 78000, loss: 0.152062
 >> iter 79000, loss: 0.200120
 >> iter 80000, loss: 0.143115
   Number of active neurons: 6
 >> iter 81000, loss: 0.253999
 >> iter 82000, loss: 0.179916
 >> iter 83000, loss: 0.173619
 >> iter 84000, loss: 0.110667
 >> iter 85000, loss: 0.105513
 >> iter 86000, loss: 0.127728
 >> iter 87000, loss: 0.286613
 >> iter 88000, loss: 0.174600
 >> iter 89000, loss: 0.168969
 >> iter 90000, loss: 0.225729
   Number of active neurons: 5
 >> iter 91000, loss: 0.127029
 >> iter 92000, loss: 0.112568
 >> iter 93000, loss: 0.096849
 >> iter 94000, loss: 0.155270
 >> iter 95000, loss: 0.138349
 >> iter 96000, loss: 0.085877
 >> iter 97000, loss: 0.052056
 >> iter 98000, loss: 0.052603
 >> iter 99000, loss: 0.135775
 >> iter 100000, loss: 0.140200
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0019999600008
   - Test - Long: 0.0449977501125
   - Test - Big: 0.0129998700013
   - Test - A: 14.9390040664
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

