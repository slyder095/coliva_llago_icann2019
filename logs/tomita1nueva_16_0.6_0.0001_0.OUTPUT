 > Problema: tomita1nueva
 > Args:
   - Hidden size: 16
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.983484
 >> iter 2000, loss: 4.104055
 >> iter 3000, loss: 1.539746
 >> iter 4000, loss: 0.606665
 >> iter 5000, loss: 0.251438
 >> iter 6000, loss: 0.115151
 >> iter 7000, loss: 0.068493
 >> iter 8000, loss: 0.050005
 >> iter 9000, loss: 0.036973
 >> iter 10000, loss: 0.034173
   Number of active neurons: 7
 >> iter 11000, loss: 0.038394
 >> iter 12000, loss: 0.035842
 >> iter 13000, loss: 0.033787
 >> iter 14000, loss: 0.030451
 >> iter 15000, loss: 0.035204
 >> iter 16000, loss: 0.031638
 >> iter 17000, loss: 0.029460
 >> iter 18000, loss: 0.034171
 >> iter 19000, loss: 0.056227
 >> iter 20000, loss: 0.039986
   Number of active neurons: 4
 >> iter 21000, loss: 0.031421
 >> iter 22000, loss: 0.027151
 >> iter 23000, loss: 0.027254
 >> iter 24000, loss: 0.029419
 >> iter 25000, loss: 0.025968
 >> iter 26000, loss: 0.024938
 >> iter 27000, loss: 0.031995
 >> iter 28000, loss: 0.028685
 >> iter 29000, loss: 0.031524
 >> iter 30000, loss: 0.028402
   Number of active neurons: 2
 >> iter 31000, loss: 0.028187
 >> iter 32000, loss: 0.024321
 >> iter 33000, loss: 0.022563
 >> iter 34000, loss: 0.021501
 >> iter 35000, loss: 0.020935
 >> iter 36000, loss: 0.021986
 >> iter 37000, loss: 0.020810
 >> iter 38000, loss: 0.025999
 >> iter 39000, loss: 0.023505
 >> iter 40000, loss: 0.022275
   Number of active neurons: 2
 >> iter 41000, loss: 0.021701
 >> iter 42000, loss: 0.020791
 >> iter 43000, loss: 0.033352
 >> iter 44000, loss: 0.030213
 >> iter 45000, loss: 0.023874
 >> iter 46000, loss: 0.020991
 >> iter 47000, loss: 0.023804
 >> iter 48000, loss: 0.029836
 >> iter 49000, loss: 0.033998
 >> iter 50000, loss: 0.029013
   Number of active neurons: 2
 >> iter 51000, loss: 0.023202
 >> iter 52000, loss: 0.032505
 >> iter 53000, loss: 0.027431
 >> iter 54000, loss: 0.033704
 >> iter 55000, loss: 0.024890
 >> iter 56000, loss: 0.045319
 >> iter 57000, loss: 0.032688
 >> iter 58000, loss: 0.030469
 >> iter 59000, loss: 0.025386
 >> iter 60000, loss: 0.030932
   Number of active neurons: 2
 >> iter 61000, loss: 0.036201
 >> iter 62000, loss: 0.053223
 >> iter 63000, loss: 0.033230
 >> iter 64000, loss: 0.041572
 >> iter 65000, loss: 0.027769
 >> iter 66000, loss: 0.035703
 >> iter 67000, loss: 0.036147
 >> iter 68000, loss: 0.028388
 >> iter 69000, loss: 0.024361
 >> iter 70000, loss: 0.020472
   Number of active neurons: 1
 >> iter 71000, loss: 0.032865
 >> iter 72000, loss: 0.027358
 >> iter 73000, loss: 0.023790
 >> iter 74000, loss: 0.029598
 >> iter 75000, loss: 0.023878
 >> iter 76000, loss: 0.024451
 >> iter 77000, loss: 0.030101
 >> iter 78000, loss: 0.021841
 >> iter 79000, loss: 0.027167
 >> iter 80000, loss: 0.020937
   Number of active neurons: 1
 >> iter 81000, loss: 0.021234
 >> iter 82000, loss: 0.037444
 >> iter 83000, loss: 0.032863
 >> iter 84000, loss: 0.023105
 >> iter 85000, loss: 0.019441
 >> iter 86000, loss: 0.019515
 >> iter 87000, loss: 0.021067
 >> iter 88000, loss: 0.033965
 >> iter 89000, loss: 0.055410
 >> iter 90000, loss: 0.039570
   Number of active neurons: 1
 >> iter 91000, loss: 0.025721
 >> iter 92000, loss: 0.021926
 >> iter 93000, loss: 0.021417
 >> iter 94000, loss: 0.030803
 >> iter 95000, loss: 0.033079
 >> iter 96000, loss: 0.022507
 >> iter 97000, loss: 0.021023
 >> iter 98000, loss: 0.026422
 >> iter 99000, loss: 0.019917
 >> iter 100000, loss: 0.016771
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.978339
 >> iter 2000, loss: 4.084952
 >> iter 3000, loss: 1.540371
 >> iter 4000, loss: 0.594598
 >> iter 5000, loss: 0.247317
 >> iter 6000, loss: 0.116927
 >> iter 7000, loss: 0.061362
 >> iter 8000, loss: 0.044903
 >> iter 9000, loss: 0.047047
 >> iter 10000, loss: 0.044318
   Number of active neurons: 6
 >> iter 11000, loss: 0.040664
 >> iter 12000, loss: 0.032696
 >> iter 13000, loss: 0.043774
 >> iter 14000, loss: 0.036283
 >> iter 15000, loss: 0.031235
 >> iter 16000, loss: 0.036140
 >> iter 17000, loss: 0.032916
 >> iter 18000, loss: 0.032258
 >> iter 19000, loss: 0.031785
 >> iter 20000, loss: 0.030770
   Number of active neurons: 4
 >> iter 21000, loss: 0.034451
 >> iter 22000, loss: 0.028278
 >> iter 23000, loss: 0.031381
 >> iter 24000, loss: 0.025941
 >> iter 25000, loss: 0.026024
 >> iter 26000, loss: 0.024591
 >> iter 27000, loss: 0.037528
 >> iter 28000, loss: 0.032937
 >> iter 29000, loss: 0.031853
 >> iter 30000, loss: 0.029502
   Number of active neurons: 4
 >> iter 31000, loss: 0.032709
 >> iter 32000, loss: 0.038883
 >> iter 33000, loss: 0.031407
 >> iter 34000, loss: 0.033725
 >> iter 35000, loss: 0.027559
 >> iter 36000, loss: 0.035676
 >> iter 37000, loss: 0.034394
 >> iter 38000, loss: 0.029112
 >> iter 39000, loss: 0.028490
 >> iter 40000, loss: 0.024868
   Number of active neurons: 2
 >> iter 41000, loss: 0.023769
 >> iter 42000, loss: 0.027733
 >> iter 43000, loss: 0.024631
 >> iter 44000, loss: 0.021455
 >> iter 45000, loss: 0.021302
 >> iter 46000, loss: 0.029228
 >> iter 47000, loss: 0.025011
 >> iter 48000, loss: 0.022080
 >> iter 49000, loss: 0.022715
 >> iter 50000, loss: 0.024048
   Number of active neurons: 2
 >> iter 51000, loss: 0.025032
 >> iter 52000, loss: 0.021342
 >> iter 53000, loss: 0.020754
 >> iter 54000, loss: 0.020273
 >> iter 55000, loss: 0.023367
 >> iter 56000, loss: 0.022386
 >> iter 57000, loss: 0.026700
 >> iter 58000, loss: 0.032976
 >> iter 59000, loss: 0.025843
 >> iter 60000, loss: 0.031785
   Number of active neurons: 2
 >> iter 61000, loss: 0.023845
 >> iter 62000, loss: 0.021893
 >> iter 63000, loss: 0.022132
 >> iter 64000, loss: 0.023686
 >> iter 65000, loss: 0.022418
 >> iter 66000, loss: 0.022860
 >> iter 67000, loss: 0.031945
 >> iter 68000, loss: 0.025184
 >> iter 69000, loss: 0.022063
 >> iter 70000, loss: 0.024777
   Number of active neurons: 2
 >> iter 71000, loss: 0.023551
 >> iter 72000, loss: 0.031744
 >> iter 73000, loss: 0.029297
 >> iter 74000, loss: 0.027474
 >> iter 75000, loss: 0.023612
 >> iter 76000, loss: 0.020341
 >> iter 77000, loss: 0.024495
 >> iter 78000, loss: 0.021281
 >> iter 79000, loss: 0.021710
 >> iter 80000, loss: 0.020534
   Number of active neurons: 2
 >> iter 81000, loss: 0.031722
 >> iter 82000, loss: 0.027347
 >> iter 83000, loss: 0.035257
 >> iter 84000, loss: 0.027329
 >> iter 85000, loss: 0.031151
 >> iter 86000, loss: 0.025083
 >> iter 87000, loss: 0.028145
 >> iter 88000, loss: 0.024208
 >> iter 89000, loss: 0.021579
 >> iter 90000, loss: 0.029027
   Number of active neurons: 2
 >> iter 91000, loss: 0.026009
 >> iter 92000, loss: 0.024616
 >> iter 93000, loss: 0.029353
 >> iter 94000, loss: 0.050932
 >> iter 95000, loss: 0.036574
 >> iter 96000, loss: 0.027970
 >> iter 97000, loss: 0.026462
 >> iter 98000, loss: 0.035086
 >> iter 99000, loss: 0.026086
 >> iter 100000, loss: 0.026606
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.958785
 >> iter 2000, loss: 4.077318
 >> iter 3000, loss: 1.530319
 >> iter 4000, loss: 0.585597
 >> iter 5000, loss: 0.237943
 >> iter 6000, loss: 0.130747
 >> iter 7000, loss: 0.083933
 >> iter 8000, loss: 0.050515
 >> iter 9000, loss: 0.041696
 >> iter 10000, loss: 0.040493
   Number of active neurons: 6
 >> iter 11000, loss: 0.043669
 >> iter 12000, loss: 0.035064
 >> iter 13000, loss: 0.044788
 >> iter 14000, loss: 0.037022
 >> iter 15000, loss: 0.031078
 >> iter 16000, loss: 0.029034
 >> iter 17000, loss: 0.037632
 >> iter 18000, loss: 0.030722
 >> iter 19000, loss: 0.034294
 >> iter 20000, loss: 0.034539
   Number of active neurons: 3
 >> iter 21000, loss: 0.034880
 >> iter 22000, loss: 0.027142
 >> iter 23000, loss: 0.026265
 >> iter 24000, loss: 0.033777
 >> iter 25000, loss: 0.027627
 >> iter 26000, loss: 0.041365
 >> iter 27000, loss: 0.041711
 >> iter 28000, loss: 0.030349
 >> iter 29000, loss: 0.029499
 >> iter 30000, loss: 0.024397
   Number of active neurons: 3
 >> iter 31000, loss: 0.030396
 >> iter 32000, loss: 0.025849
 >> iter 33000, loss: 0.025483
 >> iter 34000, loss: 0.023570
 >> iter 35000, loss: 0.023439
 >> iter 36000, loss: 0.022739
 >> iter 37000, loss: 0.022190
 >> iter 38000, loss: 0.024593
 >> iter 39000, loss: 0.050076
 >> iter 40000, loss: 0.030474
   Number of active neurons: 2
 >> iter 41000, loss: 0.086566
 >> iter 42000, loss: 0.046442
 >> iter 43000, loss: 0.030757
 >> iter 44000, loss: 0.027275
 >> iter 45000, loss: 0.023840
 >> iter 46000, loss: 0.024090
 >> iter 47000, loss: 0.025514
 >> iter 48000, loss: 0.032464
 >> iter 49000, loss: 0.031568
 >> iter 50000, loss: 0.029209
   Number of active neurons: 2
 >> iter 51000, loss: 0.026368
 >> iter 52000, loss: 0.030228
 >> iter 53000, loss: 0.025905
 >> iter 54000, loss: 0.026748
 >> iter 55000, loss: 0.024074
 >> iter 56000, loss: 0.033344
 >> iter 57000, loss: 0.031686
 >> iter 58000, loss: 0.024840
 >> iter 59000, loss: 0.035218
 >> iter 60000, loss: 0.025103
   Number of active neurons: 2
 >> iter 61000, loss: 0.025604
 >> iter 62000, loss: 0.036866
 >> iter 63000, loss: 0.026543
 >> iter 64000, loss: 0.025302
 >> iter 65000, loss: 0.023069
 >> iter 66000, loss: 0.039604
 >> iter 67000, loss: 0.036595
 >> iter 68000, loss: 0.027019
 >> iter 69000, loss: 0.025291
 >> iter 70000, loss: 0.022677
   Number of active neurons: 2
 >> iter 71000, loss: 0.021869
 >> iter 72000, loss: 0.019597
 >> iter 73000, loss: 0.019434
 >> iter 74000, loss: 0.027097
 >> iter 75000, loss: 0.022766
 >> iter 76000, loss: 0.021126
 >> iter 77000, loss: 0.021570
 >> iter 78000, loss: 0.021153
 >> iter 79000, loss: 0.019624
 >> iter 80000, loss: 0.020345
   Number of active neurons: 1
 >> iter 81000, loss: 0.026191
 >> iter 82000, loss: 0.021172
 >> iter 83000, loss: 0.023345
 >> iter 84000, loss: 0.018766
 >> iter 85000, loss: 0.029657
 >> iter 86000, loss: 0.025001
 >> iter 87000, loss: 0.024196
 >> iter 88000, loss: 0.019981
 >> iter 89000, loss: 0.044023
 >> iter 90000, loss: 0.045404
   Number of active neurons: 1
 >> iter 91000, loss: 0.027448
 >> iter 92000, loss: 0.021884
 >> iter 93000, loss: 0.019765
 >> iter 94000, loss: 0.025209
 >> iter 95000, loss: 0.026255
 >> iter 96000, loss: 0.025282
 >> iter 97000, loss: 0.020323
 >> iter 98000, loss: 0.017955
 >> iter 99000, loss: 0.017222
 >> iter 100000, loss: 0.017656
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.015361
 >> iter 2000, loss: 4.089272
 >> iter 3000, loss: 1.548115
 >> iter 4000, loss: 0.593457
 >> iter 5000, loss: 0.244350
 >> iter 6000, loss: 0.111698
 >> iter 7000, loss: 0.061538
 >> iter 8000, loss: 0.043074
 >> iter 9000, loss: 0.037319
 >> iter 10000, loss: 0.033730
   Number of active neurons: 5
 >> iter 11000, loss: 0.030521
 >> iter 12000, loss: 0.031020
 >> iter 13000, loss: 0.040658
 >> iter 14000, loss: 0.032508
 >> iter 15000, loss: 0.035940
 >> iter 16000, loss: 0.030785
 >> iter 17000, loss: 0.030448
 >> iter 18000, loss: 0.025580
 >> iter 19000, loss: 0.026346
 >> iter 20000, loss: 0.024344
   Number of active neurons: 3
 >> iter 21000, loss: 0.027718
 >> iter 22000, loss: 0.025899
 >> iter 23000, loss: 0.029343
 >> iter 24000, loss: 0.060587
 >> iter 25000, loss: 0.038581
 >> iter 26000, loss: 0.035923
 >> iter 27000, loss: 0.029094
 >> iter 28000, loss: 0.030117
 >> iter 29000, loss: 0.028071
 >> iter 30000, loss: 0.032514
   Number of active neurons: 2
 >> iter 31000, loss: 0.025535
 >> iter 32000, loss: 0.023040
 >> iter 33000, loss: 0.021815
 >> iter 34000, loss: 0.027250
 >> iter 35000, loss: 0.023749
 >> iter 36000, loss: 0.036031
 >> iter 37000, loss: 0.032110
 >> iter 38000, loss: 0.024507
 >> iter 39000, loss: 0.023027
 >> iter 40000, loss: 0.020692
   Number of active neurons: 2
 >> iter 41000, loss: 0.020716
 >> iter 42000, loss: 0.021855
 >> iter 43000, loss: 0.026479
 >> iter 44000, loss: 0.024990
 >> iter 45000, loss: 0.024270
 >> iter 46000, loss: 0.025797
 >> iter 47000, loss: 0.023582
 >> iter 48000, loss: 0.024516
 >> iter 49000, loss: 0.023796
 >> iter 50000, loss: 0.025678
   Number of active neurons: 2
 >> iter 51000, loss: 0.024114
 >> iter 52000, loss: 0.021234
 >> iter 53000, loss: 0.021948
 >> iter 54000, loss: 0.026470
 >> iter 55000, loss: 0.024183
 >> iter 56000, loss: 0.027264
 >> iter 57000, loss: 0.026572
 >> iter 58000, loss: 0.023047
 >> iter 59000, loss: 0.022843
 >> iter 60000, loss: 0.027374
   Number of active neurons: 2
 >> iter 61000, loss: 0.026547
 >> iter 62000, loss: 0.023276
 >> iter 63000, loss: 0.038529
 >> iter 64000, loss: 0.030403
 >> iter 65000, loss: 0.024555
 >> iter 66000, loss: 0.023415
 >> iter 67000, loss: 0.036875
 >> iter 68000, loss: 0.030254
 >> iter 69000, loss: 0.040626
 >> iter 70000, loss: 0.027072
   Number of active neurons: 2
 >> iter 71000, loss: 0.024061
 >> iter 72000, loss: 0.023072
 >> iter 73000, loss: 0.021668
 >> iter 74000, loss: 0.047662
 >> iter 75000, loss: 0.031836
 >> iter 76000, loss: 0.025451
 >> iter 77000, loss: 0.034759
 >> iter 78000, loss: 0.027654
 >> iter 79000, loss: 0.024737
 >> iter 80000, loss: 0.022338
   Number of active neurons: 2
 >> iter 81000, loss: 0.023687
 >> iter 82000, loss: 0.026764
 >> iter 83000, loss: 0.025391
 >> iter 84000, loss: 0.029940
 >> iter 85000, loss: 0.027089
 >> iter 86000, loss: 0.030782
 >> iter 87000, loss: 0.045550
 >> iter 88000, loss: 0.032014
 >> iter 89000, loss: 0.026824
 >> iter 90000, loss: 0.020497
   Number of active neurons: 1
 >> iter 91000, loss: 0.023033
 >> iter 92000, loss: 0.023966
 >> iter 93000, loss: 0.023805
 >> iter 94000, loss: 0.024973
 >> iter 95000, loss: 0.021958
 >> iter 96000, loss: 0.021971
 >> iter 97000, loss: 0.021175
 >> iter 98000, loss: 0.017793
 >> iter 99000, loss: 0.020854
 >> iter 100000, loss: 0.018699
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 10.894067
 >> iter 2000, loss: 4.100720
 >> iter 3000, loss: 1.548032
 >> iter 4000, loss: 0.591235
 >> iter 5000, loss: 0.254829
 >> iter 6000, loss: 0.116310
 >> iter 7000, loss: 0.068739
 >> iter 8000, loss: 0.044945
 >> iter 9000, loss: 0.054491
 >> iter 10000, loss: 0.043571
   Number of active neurons: 5
 >> iter 11000, loss: 0.038623
 >> iter 12000, loss: 0.044180
 >> iter 13000, loss: 0.035326
 >> iter 14000, loss: 0.030601
 >> iter 15000, loss: 0.029998
 >> iter 16000, loss: 0.028024
 >> iter 17000, loss: 0.025770
 >> iter 18000, loss: 0.026170
 >> iter 19000, loss: 0.030464
 >> iter 20000, loss: 0.025769
   Number of active neurons: 3
 >> iter 21000, loss: 0.032109
 >> iter 22000, loss: 0.028493
 >> iter 23000, loss: 0.031477
 >> iter 24000, loss: 0.036393
 >> iter 25000, loss: 0.027368
 >> iter 26000, loss: 0.035237
 >> iter 27000, loss: 0.028008
 >> iter 28000, loss: 0.025728
 >> iter 29000, loss: 0.024635
 >> iter 30000, loss: 0.050114
   Number of active neurons: 2
 >> iter 31000, loss: 0.031880
 >> iter 32000, loss: 0.028475
 >> iter 33000, loss: 0.048317
 >> iter 34000, loss: 0.032347
 >> iter 35000, loss: 0.027490
 >> iter 36000, loss: 0.024999
 >> iter 37000, loss: 0.023567
 >> iter 38000, loss: 0.036692
 >> iter 39000, loss: 0.030670
 >> iter 40000, loss: 0.031575
   Number of active neurons: 1
 >> iter 41000, loss: 0.029303
 >> iter 42000, loss: 0.030162
 >> iter 43000, loss: 0.022792
 >> iter 44000, loss: 0.020491
 >> iter 45000, loss: 0.019749
 >> iter 46000, loss: 0.025752
 >> iter 47000, loss: 0.022153
 >> iter 48000, loss: 0.021271
 >> iter 49000, loss: 0.022374
 >> iter 50000, loss: 0.020622
   Number of active neurons: 1
 >> iter 51000, loss: 0.026670
 >> iter 52000, loss: 0.023293
 >> iter 53000, loss: 0.021050
 >> iter 54000, loss: 0.017618
 >> iter 55000, loss: 0.015605
 >> iter 56000, loss: 0.018411
 >> iter 57000, loss: 0.017631
 >> iter 58000, loss: 0.019913
 >> iter 59000, loss: 0.019189
 >> iter 60000, loss: 0.018098
   Number of active neurons: 1
 >> iter 61000, loss: 0.016505
 >> iter 62000, loss: 0.016744
 >> iter 63000, loss: 0.015702
 >> iter 64000, loss: 0.016016
 >> iter 65000, loss: 0.024264
 >> iter 66000, loss: 0.021822
 >> iter 67000, loss: 0.024176
 >> iter 68000, loss: 0.018389
 >> iter 69000, loss: 0.016016
 >> iter 70000, loss: 0.024592
   Number of active neurons: 1
 >> iter 71000, loss: 0.022660
 >> iter 72000, loss: 0.021958
 >> iter 73000, loss: 0.020220
 >> iter 74000, loss: 0.018674
 >> iter 75000, loss: 0.024033
 >> iter 76000, loss: 0.019573
 >> iter 77000, loss: 0.017190
 >> iter 78000, loss: 0.017505
 >> iter 79000, loss: 0.016278
 >> iter 80000, loss: 0.018518
   Number of active neurons: 1
 >> iter 81000, loss: 0.026308
 >> iter 82000, loss: 0.023502
 >> iter 83000, loss: 0.018817
 >> iter 84000, loss: 0.017270
 >> iter 85000, loss: 0.016572
 >> iter 86000, loss: 0.018829
 >> iter 87000, loss: 0.017859
 >> iter 88000, loss: 0.016793
 >> iter 89000, loss: 0.019880
 >> iter 90000, loss: 0.020087
   Number of active neurons: 1
 >> iter 91000, loss: 0.019078
 >> iter 92000, loss: 0.017543
 >> iter 93000, loss: 0.022210
 >> iter 94000, loss: 0.021499
 >> iter 95000, loss: 0.023313
 >> iter 96000, loss: 0.018951
 >> iter 97000, loss: 0.018399
 >> iter 98000, loss: 0.016242
 >> iter 99000, loss: 0.019125
 >> iter 100000, loss: 0.025019
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.973783
 >> iter 2000, loss: 4.122082
 >> iter 3000, loss: 1.573023
 >> iter 4000, loss: 0.615400
 >> iter 5000, loss: 0.250364
 >> iter 6000, loss: 0.113548
 >> iter 7000, loss: 0.067029
 >> iter 8000, loss: 0.043355
 >> iter 9000, loss: 0.035737
 >> iter 10000, loss: 0.033915
   Number of active neurons: 5
 >> iter 11000, loss: 0.032069
 >> iter 12000, loss: 0.035568
 >> iter 13000, loss: 0.030423
 >> iter 14000, loss: 0.036894
 >> iter 15000, loss: 0.034572
 >> iter 16000, loss: 0.031789
 >> iter 17000, loss: 0.031392
 >> iter 18000, loss: 0.027934
 >> iter 19000, loss: 0.034342
 >> iter 20000, loss: 0.029892
   Number of active neurons: 4
 >> iter 21000, loss: 0.046486
 >> iter 22000, loss: 0.033653
 >> iter 23000, loss: 0.026768
 >> iter 24000, loss: 0.032999
 >> iter 25000, loss: 0.032694
 >> iter 26000, loss: 0.034506
 >> iter 27000, loss: 0.029071
 >> iter 28000, loss: 0.026533
 >> iter 29000, loss: 0.025114
 >> iter 30000, loss: 0.024572
   Number of active neurons: 3
 >> iter 31000, loss: 0.025449
 >> iter 32000, loss: 0.029921
 >> iter 33000, loss: 0.025677
 >> iter 34000, loss: 0.024594
 >> iter 35000, loss: 0.031398
 >> iter 36000, loss: 0.030525
 >> iter 37000, loss: 0.028516
 >> iter 38000, loss: 0.026665
 >> iter 39000, loss: 0.026202
 >> iter 40000, loss: 0.025485
   Number of active neurons: 3
 >> iter 41000, loss: 0.036914
 >> iter 42000, loss: 0.030074
 >> iter 43000, loss: 0.028535
 >> iter 44000, loss: 0.026581
 >> iter 45000, loss: 0.025631
 >> iter 46000, loss: 0.027662
 >> iter 47000, loss: 0.029537
 >> iter 48000, loss: 0.024647
 >> iter 49000, loss: 0.026436
 >> iter 50000, loss: 0.024241
   Number of active neurons: 3
 >> iter 51000, loss: 0.022882
 >> iter 52000, loss: 0.025184
 >> iter 53000, loss: 0.027256
 >> iter 54000, loss: 0.027359
 >> iter 55000, loss: 0.025604
 >> iter 56000, loss: 0.029558
 >> iter 57000, loss: 0.026543
 >> iter 58000, loss: 0.023682
 >> iter 59000, loss: 0.030316
 >> iter 60000, loss: 0.024753
   Number of active neurons: 2
 >> iter 61000, loss: 0.023864
 >> iter 62000, loss: 0.024505
 >> iter 63000, loss: 0.027924
 >> iter 64000, loss: 0.051643
 >> iter 65000, loss: 0.051629
 >> iter 66000, loss: 0.036326
 >> iter 67000, loss: 0.026639
 >> iter 68000, loss: 0.024021
 >> iter 69000, loss: 0.033851
 >> iter 70000, loss: 0.029621
   Number of active neurons: 2
 >> iter 71000, loss: 0.025874
 >> iter 72000, loss: 0.027148
 >> iter 73000, loss: 0.021670
 >> iter 74000, loss: 0.019851
 >> iter 75000, loss: 0.022333
 >> iter 76000, loss: 0.025291
 >> iter 77000, loss: 0.040361
 >> iter 78000, loss: 0.032031
 >> iter 79000, loss: 0.027348
 >> iter 80000, loss: 0.024737
   Number of active neurons: 2
 >> iter 81000, loss: 0.023521
 >> iter 82000, loss: 0.020872
 >> iter 83000, loss: 0.021360
 >> iter 84000, loss: 0.022222
 >> iter 85000, loss: 0.021480
 >> iter 86000, loss: 0.020092
 >> iter 87000, loss: 0.019734
 >> iter 88000, loss: 0.020590
 >> iter 89000, loss: 0.026613
 >> iter 90000, loss: 0.021553
   Number of active neurons: 1
 >> iter 91000, loss: 0.020186
 >> iter 92000, loss: 0.018002
 >> iter 93000, loss: 0.018145
 >> iter 94000, loss: 0.017823
 >> iter 95000, loss: 0.023826
 >> iter 96000, loss: 0.053268
 >> iter 97000, loss: 0.041516
 >> iter 98000, loss: 0.026729
 >> iter 99000, loss: 0.024870
 >> iter 100000, loss: 0.021368
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.895930
 >> iter 2000, loss: 4.052863
 >> iter 3000, loss: 1.514189
 >> iter 4000, loss: 0.587053
 >> iter 5000, loss: 0.236525
 >> iter 6000, loss: 0.108748
 >> iter 7000, loss: 0.072395
 >> iter 8000, loss: 0.050384
 >> iter 9000, loss: 0.075963
 >> iter 10000, loss: 0.044906
   Number of active neurons: 4
 >> iter 11000, loss: 0.034733
 >> iter 12000, loss: 0.030232
 >> iter 13000, loss: 0.029485
 >> iter 14000, loss: 0.028466
 >> iter 15000, loss: 0.033391
 >> iter 16000, loss: 0.030932
 >> iter 17000, loss: 0.031020
 >> iter 18000, loss: 0.025153
 >> iter 19000, loss: 0.031057
 >> iter 20000, loss: 0.027083
   Number of active neurons: 3
 >> iter 21000, loss: 0.024589
 >> iter 22000, loss: 0.022705
 >> iter 23000, loss: 0.023915
 >> iter 24000, loss: 0.023628
 >> iter 25000, loss: 0.022359
 >> iter 26000, loss: 0.021745
 >> iter 27000, loss: 0.026372
 >> iter 28000, loss: 0.026765
 >> iter 29000, loss: 0.049764
 >> iter 30000, loss: 0.032747
   Number of active neurons: 2
 >> iter 31000, loss: 0.033064
 >> iter 32000, loss: 0.029070
 >> iter 33000, loss: 0.022940
 >> iter 34000, loss: 0.028448
 >> iter 35000, loss: 0.023172
 >> iter 36000, loss: 0.022619
 >> iter 37000, loss: 0.022413
 >> iter 38000, loss: 0.019985
 >> iter 39000, loss: 0.019856
 >> iter 40000, loss: 0.019010
   Number of active neurons: 2
 >> iter 41000, loss: 0.020838
 >> iter 42000, loss: 0.025236
 >> iter 43000, loss: 0.022664
 >> iter 44000, loss: 0.023090
 >> iter 45000, loss: 0.022823
 >> iter 46000, loss: 0.022546
 >> iter 47000, loss: 0.021561
 >> iter 48000, loss: 0.046451
 >> iter 49000, loss: 0.033608
 >> iter 50000, loss: 0.025733
   Number of active neurons: 2
 >> iter 51000, loss: 0.022692
 >> iter 52000, loss: 0.020490
 >> iter 53000, loss: 0.022629
 >> iter 54000, loss: 0.020017
 >> iter 55000, loss: 0.023541
 >> iter 56000, loss: 0.022879
 >> iter 57000, loss: 0.023311
 >> iter 58000, loss: 0.022574
 >> iter 59000, loss: 0.023744
 >> iter 60000, loss: 0.021437
   Number of active neurons: 2
 >> iter 61000, loss: 0.022816
 >> iter 62000, loss: 0.021680
 >> iter 63000, loss: 0.019430
 >> iter 64000, loss: 0.019677
 >> iter 65000, loss: 0.021660
 >> iter 66000, loss: 0.020758
 >> iter 67000, loss: 0.020325
 >> iter 68000, loss: 0.020433
 >> iter 69000, loss: 0.020972
 >> iter 70000, loss: 0.027731
   Number of active neurons: 2
 >> iter 71000, loss: 0.027548
 >> iter 72000, loss: 0.021882
 >> iter 73000, loss: 0.019934
 >> iter 74000, loss: 0.021206
 >> iter 75000, loss: 0.022536
 >> iter 76000, loss: 0.022039
 >> iter 77000, loss: 0.023968
 >> iter 78000, loss: 0.025437
 >> iter 79000, loss: 0.026553
 >> iter 80000, loss: 0.023103
   Number of active neurons: 2
 >> iter 81000, loss: 0.024512
 >> iter 82000, loss: 0.032926
 >> iter 83000, loss: 0.025383
 >> iter 84000, loss: 0.025787
 >> iter 85000, loss: 0.021948
 >> iter 86000, loss: 0.028131
 >> iter 87000, loss: 0.028967
 >> iter 88000, loss: 0.026134
 >> iter 89000, loss: 0.023143
 >> iter 90000, loss: 0.027348
   Number of active neurons: 2
 >> iter 91000, loss: 0.023388
 >> iter 92000, loss: 0.021806
 >> iter 93000, loss: 0.022415
 >> iter 94000, loss: 0.023276
 >> iter 95000, loss: 0.020003
 >> iter 96000, loss: 0.022471
 >> iter 97000, loss: 0.027624
 >> iter 98000, loss: 0.024254
 >> iter 99000, loss: 0.023006
 >> iter 100000, loss: 0.020066
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.923537
 >> iter 2000, loss: 4.061847
 >> iter 3000, loss: 1.532077
 >> iter 4000, loss: 0.606919
 >> iter 5000, loss: 0.244223
 >> iter 6000, loss: 0.123859
 >> iter 7000, loss: 0.063325
 >> iter 8000, loss: 0.042880
 >> iter 9000, loss: 0.069593
 >> iter 10000, loss: 0.051463
   Number of active neurons: 5
 >> iter 11000, loss: 0.037622
 >> iter 12000, loss: 0.031416
 >> iter 13000, loss: 0.028177
 >> iter 14000, loss: 0.034997
 >> iter 15000, loss: 0.030576
 >> iter 16000, loss: 0.027694
 >> iter 17000, loss: 0.026421
 >> iter 18000, loss: 0.027017
 >> iter 19000, loss: 0.027334
 >> iter 20000, loss: 0.024251
   Number of active neurons: 2
 >> iter 21000, loss: 0.024499
 >> iter 22000, loss: 0.024446
 >> iter 23000, loss: 0.028131
 >> iter 24000, loss: 0.024801
 >> iter 25000, loss: 0.023400
 >> iter 26000, loss: 0.022830
 >> iter 27000, loss: 0.021988
 >> iter 28000, loss: 0.025140
 >> iter 29000, loss: 0.032444
 >> iter 30000, loss: 0.025589
   Number of active neurons: 2
 >> iter 31000, loss: 0.025403
 >> iter 32000, loss: 0.023175
 >> iter 33000, loss: 0.023537
 >> iter 34000, loss: 0.020606
 >> iter 35000, loss: 0.021957
 >> iter 36000, loss: 0.024375
 >> iter 37000, loss: 0.021865
 >> iter 38000, loss: 0.027960
 >> iter 39000, loss: 0.025186
 >> iter 40000, loss: 0.023719
   Number of active neurons: 2
 >> iter 41000, loss: 0.022858
 >> iter 42000, loss: 0.028682
 >> iter 43000, loss: 0.022772
 >> iter 44000, loss: 0.021294
 >> iter 45000, loss: 0.020953
 >> iter 46000, loss: 0.022868
 >> iter 47000, loss: 0.021214
 >> iter 48000, loss: 0.020623
 >> iter 49000, loss: 0.024870
 >> iter 50000, loss: 0.020969
   Number of active neurons: 2
 >> iter 51000, loss: 0.019467
 >> iter 52000, loss: 0.020070
 >> iter 53000, loss: 0.023447
 >> iter 54000, loss: 0.021489
 >> iter 55000, loss: 0.022340
 >> iter 56000, loss: 0.020988
 >> iter 57000, loss: 0.022494
 >> iter 58000, loss: 0.022386
 >> iter 59000, loss: 0.022040
 >> iter 60000, loss: 0.020612
   Number of active neurons: 2
 >> iter 61000, loss: 0.027527
 >> iter 62000, loss: 0.038952
 >> iter 63000, loss: 0.031935
 >> iter 64000, loss: 0.024361
 >> iter 65000, loss: 0.021079
 >> iter 66000, loss: 0.028117
 >> iter 67000, loss: 0.034342
 >> iter 68000, loss: 0.028557
 >> iter 69000, loss: 0.028882
 >> iter 70000, loss: 0.022514
   Number of active neurons: 2
 >> iter 71000, loss: 0.024412
 >> iter 72000, loss: 0.020988
 >> iter 73000, loss: 0.024855
 >> iter 74000, loss: 0.022825
 >> iter 75000, loss: 0.020656
 >> iter 76000, loss: 0.025541
 >> iter 77000, loss: 0.023202
 >> iter 78000, loss: 0.020703
 >> iter 79000, loss: 0.021814
 >> iter 80000, loss: 0.030865
   Number of active neurons: 2
 >> iter 81000, loss: 0.025217
 >> iter 82000, loss: 0.021725
 >> iter 83000, loss: 0.025143
 >> iter 84000, loss: 0.022749
 >> iter 85000, loss: 0.021667
 >> iter 86000, loss: 0.020793
 >> iter 87000, loss: 0.022723
 >> iter 88000, loss: 0.022854
 >> iter 89000, loss: 0.024386
 >> iter 90000, loss: 0.024476
   Number of active neurons: 2
 >> iter 91000, loss: 0.022034
 >> iter 92000, loss: 0.023656
 >> iter 93000, loss: 0.021107
 >> iter 94000, loss: 0.020105
 >> iter 95000, loss: 0.023355
 >> iter 96000, loss: 0.021600
 >> iter 97000, loss: 0.023939
 >> iter 98000, loss: 0.022364
 >> iter 99000, loss: 0.020359
 >> iter 100000, loss: 0.027423
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.901844
 >> iter 2000, loss: 4.083334
 >> iter 3000, loss: 1.527395
 >> iter 4000, loss: 0.599135
 >> iter 5000, loss: 0.248451
 >> iter 6000, loss: 0.115559
 >> iter 7000, loss: 0.076205
 >> iter 8000, loss: 0.048146
 >> iter 9000, loss: 0.040337
 >> iter 10000, loss: 0.037522
   Number of active neurons: 3
 >> iter 11000, loss: 0.034278
 >> iter 12000, loss: 0.030450
 >> iter 13000, loss: 0.050017
 >> iter 14000, loss: 0.038843
 >> iter 15000, loss: 0.033436
 >> iter 16000, loss: 0.026978
 >> iter 17000, loss: 0.031427
 >> iter 18000, loss: 0.036246
 >> iter 19000, loss: 0.028935
 >> iter 20000, loss: 0.030806
   Number of active neurons: 3
 >> iter 21000, loss: 0.029579
 >> iter 22000, loss: 0.036688
 >> iter 23000, loss: 0.035582
 >> iter 24000, loss: 0.030475
 >> iter 25000, loss: 0.032049
 >> iter 26000, loss: 0.028324
 >> iter 27000, loss: 0.026314
 >> iter 28000, loss: 0.024542
 >> iter 29000, loss: 0.035080
 >> iter 30000, loss: 0.026784
   Number of active neurons: 3
 >> iter 31000, loss: 0.025820
 >> iter 32000, loss: 0.026016
 >> iter 33000, loss: 0.039255
 >> iter 34000, loss: 0.045744
 >> iter 35000, loss: 0.036783
 >> iter 36000, loss: 0.038720
 >> iter 37000, loss: 0.041374
 >> iter 38000, loss: 0.031147
 >> iter 39000, loss: 0.024549
 >> iter 40000, loss: 0.074420
   Number of active neurons: 1
 >> iter 41000, loss: 0.041304
 >> iter 42000, loss: 0.036596
 >> iter 43000, loss: 0.028594
 >> iter 44000, loss: 0.023355
 >> iter 45000, loss: 0.022999
 >> iter 46000, loss: 0.020683
 >> iter 47000, loss: 0.021925
 >> iter 48000, loss: 0.020752
 >> iter 49000, loss: 0.020370
 >> iter 50000, loss: 0.020807
   Number of active neurons: 1
 >> iter 51000, loss: 0.018573
 >> iter 52000, loss: 0.018892
 >> iter 53000, loss: 0.039344
 >> iter 54000, loss: 0.040623
 >> iter 55000, loss: 0.029575
 >> iter 56000, loss: 0.024291
 >> iter 57000, loss: 0.020225
 >> iter 58000, loss: 0.018488
 >> iter 59000, loss: 0.016655
 >> iter 60000, loss: 0.042895
   Number of active neurons: 1
 >> iter 61000, loss: 0.028055
 >> iter 62000, loss: 0.037085
 >> iter 63000, loss: 0.025598
 >> iter 64000, loss: 0.022671
 >> iter 65000, loss: 0.020915
 >> iter 66000, loss: 0.017797
 >> iter 67000, loss: 0.030971
 >> iter 68000, loss: 0.023712
 >> iter 69000, loss: 0.032983
 >> iter 70000, loss: 0.029064
   Number of active neurons: 1
 >> iter 71000, loss: 0.023492
 >> iter 72000, loss: 0.021202
 >> iter 73000, loss: 0.022380
 >> iter 74000, loss: 0.036255
 >> iter 75000, loss: 0.022734
 >> iter 76000, loss: 0.020242
 >> iter 77000, loss: 0.017912
 >> iter 78000, loss: 0.017800
 >> iter 79000, loss: 0.017205
 >> iter 80000, loss: 0.036090
   Number of active neurons: 1
 >> iter 81000, loss: 0.025219
 >> iter 82000, loss: 0.025843
 >> iter 83000, loss: 0.025044
 >> iter 84000, loss: 0.022404
 >> iter 85000, loss: 0.023802
 >> iter 86000, loss: 0.028491
 >> iter 87000, loss: 0.021212
 >> iter 88000, loss: 0.022778
 >> iter 89000, loss: 0.019669
 >> iter 90000, loss: 0.028818
   Number of active neurons: 1
 >> iter 91000, loss: 0.027218
 >> iter 92000, loss: 0.026710
 >> iter 93000, loss: 0.020793
 >> iter 94000, loss: 0.018132
 >> iter 95000, loss: 0.017887
 >> iter 96000, loss: 0.039117
 >> iter 97000, loss: 0.028933
 >> iter 98000, loss: 0.021534
 >> iter 99000, loss: 0.018639
 >> iter 100000, loss: 0.020263
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 10.975031
 >> iter 2000, loss: 4.088510
 >> iter 3000, loss: 1.563333
 >> iter 4000, loss: 0.609492
 >> iter 5000, loss: 0.245718
 >> iter 6000, loss: 0.114526
 >> iter 7000, loss: 0.068825
 >> iter 8000, loss: 0.048379
 >> iter 9000, loss: 0.042007
 >> iter 10000, loss: 0.034072
   Number of active neurons: 5
 >> iter 11000, loss: 0.032830
 >> iter 12000, loss: 0.047274
 >> iter 13000, loss: 0.036122
 >> iter 14000, loss: 0.032261
 >> iter 15000, loss: 0.033567
 >> iter 16000, loss: 0.029733
 >> iter 17000, loss: 0.033560
 >> iter 18000, loss: 0.034297
 >> iter 19000, loss: 0.029082
 >> iter 20000, loss: 0.028143
   Number of active neurons: 5
 >> iter 21000, loss: 0.029579
 >> iter 22000, loss: 0.035026
 >> iter 23000, loss: 0.039322
 >> iter 24000, loss: 0.032875
 >> iter 25000, loss: 0.067697
 >> iter 26000, loss: 0.043667
 >> iter 27000, loss: 0.036229
 >> iter 28000, loss: 0.031805
 >> iter 29000, loss: 0.027900
 >> iter 30000, loss: 0.033322
   Number of active neurons: 4
 >> iter 31000, loss: 0.031886
 >> iter 32000, loss: 0.026057
 >> iter 33000, loss: 0.051115
 >> iter 34000, loss: 0.032699
 >> iter 35000, loss: 0.030227
 >> iter 36000, loss: 0.029183
 >> iter 37000, loss: 0.025963
 >> iter 38000, loss: 0.022733
 >> iter 39000, loss: 0.022450
 >> iter 40000, loss: 0.050356
   Number of active neurons: 2
 >> iter 41000, loss: 0.036651
 >> iter 42000, loss: 0.026378
 >> iter 43000, loss: 0.040485
 >> iter 44000, loss: 0.030635
 >> iter 45000, loss: 0.024124
 >> iter 46000, loss: 0.021716
 >> iter 47000, loss: 0.022643
 >> iter 48000, loss: 0.022214
 >> iter 49000, loss: 0.023024
 >> iter 50000, loss: 0.041202
   Number of active neurons: 2
 >> iter 51000, loss: 0.029873
 >> iter 52000, loss: 0.036080
 >> iter 53000, loss: 0.030948
 >> iter 54000, loss: 0.029040
 >> iter 55000, loss: 0.025420
 >> iter 56000, loss: 0.037746
 >> iter 57000, loss: 0.036011
 >> iter 58000, loss: 0.026732
 >> iter 59000, loss: 0.022900
 >> iter 60000, loss: 0.025582
   Number of active neurons: 2
 >> iter 61000, loss: 0.026698
 >> iter 62000, loss: 0.021600
 >> iter 63000, loss: 0.020182
 >> iter 64000, loss: 0.041691
 >> iter 65000, loss: 0.032909
 >> iter 66000, loss: 0.028540
 >> iter 67000, loss: 0.025690
 >> iter 68000, loss: 0.024313
 >> iter 69000, loss: 0.043279
 >> iter 70000, loss: 0.029426
   Number of active neurons: 2
 >> iter 71000, loss: 0.038730
 >> iter 72000, loss: 0.032998
 >> iter 73000, loss: 0.026526
 >> iter 74000, loss: 0.022436
 >> iter 75000, loss: 0.028222
 >> iter 76000, loss: 0.024477
 >> iter 77000, loss: 0.025932
 >> iter 78000, loss: 0.022819
 >> iter 79000, loss: 0.020481
 >> iter 80000, loss: 0.020103
   Number of active neurons: 2
 >> iter 81000, loss: 0.030299
 >> iter 82000, loss: 0.027869
 >> iter 83000, loss: 0.024413
 >> iter 84000, loss: 0.021337
 >> iter 85000, loss: 0.024452
 >> iter 86000, loss: 0.024657
 >> iter 87000, loss: 0.028175
 >> iter 88000, loss: 0.023786
 >> iter 89000, loss: 0.030812
 >> iter 90000, loss: 0.033023
   Number of active neurons: 2
 >> iter 91000, loss: 0.026342
 >> iter 92000, loss: 0.030983
 >> iter 93000, loss: 0.034715
 >> iter 94000, loss: 0.026447
 >> iter 95000, loss: 0.030125
 >> iter 96000, loss: 0.044620
 >> iter 97000, loss: 0.028910
 >> iter 98000, loss: 0.024667
 >> iter 99000, loss: 0.022632
 >> iter 100000, loss: 0.021771
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.953133
 >> iter 2000, loss: 4.095095
 >> iter 3000, loss: 1.539383
 >> iter 4000, loss: 0.592520
 >> iter 5000, loss: 0.244848
 >> iter 6000, loss: 0.117743
 >> iter 7000, loss: 0.071787
 >> iter 8000, loss: 0.045745
 >> iter 9000, loss: 0.036411
 >> iter 10000, loss: 0.035430
   Number of active neurons: 3
 >> iter 11000, loss: 0.029552
 >> iter 12000, loss: 0.027368
 >> iter 13000, loss: 0.030069
 >> iter 14000, loss: 0.028896
 >> iter 15000, loss: 0.025627
 >> iter 16000, loss: 0.029650
 >> iter 17000, loss: 0.037531
 >> iter 18000, loss: 0.027211
 >> iter 19000, loss: 0.024459
 >> iter 20000, loss: 0.030848
   Number of active neurons: 3
 >> iter 21000, loss: 0.033659
 >> iter 22000, loss: 0.027572
 >> iter 23000, loss: 0.027867
 >> iter 24000, loss: 0.024539
 >> iter 25000, loss: 0.023775
 >> iter 26000, loss: 0.024508
 >> iter 27000, loss: 0.023666
 >> iter 28000, loss: 0.030509
 >> iter 29000, loss: 0.025741
 >> iter 30000, loss: 0.024587
   Number of active neurons: 3
 >> iter 31000, loss: 0.024432
 >> iter 32000, loss: 0.023390
 >> iter 33000, loss: 0.027759
 >> iter 34000, loss: 0.028868
 >> iter 35000, loss: 0.027324
 >> iter 36000, loss: 0.027210
 >> iter 37000, loss: 0.028023
 >> iter 38000, loss: 0.025347
 >> iter 39000, loss: 0.022706
 >> iter 40000, loss: 0.024065
   Number of active neurons: 3
 >> iter 41000, loss: 0.024331
 >> iter 42000, loss: 0.027516
 >> iter 43000, loss: 0.024181
 >> iter 44000, loss: 0.029563
 >> iter 45000, loss: 0.027067
 >> iter 46000, loss: 0.027380
 >> iter 47000, loss: 0.025312
 >> iter 48000, loss: 0.031940
 >> iter 49000, loss: 0.025784
 >> iter 50000, loss: 0.023886
   Number of active neurons: 3
 >> iter 51000, loss: 0.025312
 >> iter 52000, loss: 0.025651
 >> iter 53000, loss: 0.028468
 >> iter 54000, loss: 0.027779
 >> iter 55000, loss: 0.025675
 >> iter 56000, loss: 0.023565
 >> iter 57000, loss: 0.024613
 >> iter 58000, loss: 0.035740
 >> iter 59000, loss: 0.034490
 >> iter 60000, loss: 0.026556
   Number of active neurons: 2
 >> iter 61000, loss: 0.023437
 >> iter 62000, loss: 0.024211
 >> iter 63000, loss: 0.021064
 >> iter 64000, loss: 0.022061
 >> iter 65000, loss: 0.043952
 >> iter 66000, loss: 0.033518
 >> iter 67000, loss: 0.026125
 >> iter 68000, loss: 0.024932
 >> iter 69000, loss: 0.025316
 >> iter 70000, loss: 0.022350
   Number of active neurons: 2
 >> iter 71000, loss: 0.022760
 >> iter 72000, loss: 0.021804
 >> iter 73000, loss: 0.038833
 >> iter 74000, loss: 0.037900
 >> iter 75000, loss: 0.028656
 >> iter 76000, loss: 0.032526
 >> iter 77000, loss: 0.031014
 >> iter 78000, loss: 0.030065
 >> iter 79000, loss: 0.024933
 >> iter 80000, loss: 0.022115
   Number of active neurons: 2
 >> iter 81000, loss: 0.030167
 >> iter 82000, loss: 0.025677
 >> iter 83000, loss: 0.021759
 >> iter 84000, loss: 0.027555
 >> iter 85000, loss: 0.024566
 >> iter 86000, loss: 0.029858
 >> iter 87000, loss: 0.077297
 >> iter 88000, loss: 0.042740
 >> iter 89000, loss: 0.033277
 >> iter 90000, loss: 0.025435
   Number of active neurons: 2
 >> iter 91000, loss: 0.022145
 >> iter 92000, loss: 0.035067
 >> iter 93000, loss: 0.059085
 >> iter 94000, loss: 0.043014
 >> iter 95000, loss: 0.032566
 >> iter 96000, loss: 0.025261
 >> iter 97000, loss: 0.023552
 >> iter 98000, loss: 0.033673
 >> iter 99000, loss: 0.033901
 >> iter 100000, loss: 0.022873
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.908348
 >> iter 2000, loss: 4.052466
 >> iter 3000, loss: 1.532333
 >> iter 4000, loss: 0.585171
 >> iter 5000, loss: 0.237005
 >> iter 6000, loss: 0.109839
 >> iter 7000, loss: 0.066236
 >> iter 8000, loss: 0.043996
 >> iter 9000, loss: 0.036509
 >> iter 10000, loss: 0.031481
   Number of active neurons: 5
 >> iter 11000, loss: 0.035359
 >> iter 12000, loss: 0.037120
 >> iter 13000, loss: 0.032131
 >> iter 14000, loss: 0.028407
 >> iter 15000, loss: 0.030478
 >> iter 16000, loss: 0.040144
 >> iter 17000, loss: 0.038739
 >> iter 18000, loss: 0.030157
 >> iter 19000, loss: 0.027232
 >> iter 20000, loss: 0.038651
   Number of active neurons: 2
 >> iter 21000, loss: 0.039467
 >> iter 22000, loss: 0.032491
 >> iter 23000, loss: 0.029962
 >> iter 24000, loss: 0.024054
 >> iter 25000, loss: 0.021817
 >> iter 26000, loss: 0.023434
 >> iter 27000, loss: 0.026861
 >> iter 28000, loss: 0.025993
 >> iter 29000, loss: 0.024625
 >> iter 30000, loss: 0.028495
   Number of active neurons: 2
 >> iter 31000, loss: 0.037841
 >> iter 32000, loss: 0.027107
 >> iter 33000, loss: 0.023639
 >> iter 34000, loss: 0.021109
 >> iter 35000, loss: 0.033902
 >> iter 36000, loss: 0.029854
 >> iter 37000, loss: 0.050715
 >> iter 38000, loss: 0.034094
 >> iter 39000, loss: 0.025292
 >> iter 40000, loss: 0.019912
   Number of active neurons: 1
 >> iter 41000, loss: 0.020102
 >> iter 42000, loss: 0.020434
 >> iter 43000, loss: 0.017818
 >> iter 44000, loss: 0.017661
 >> iter 45000, loss: 0.021104
 >> iter 46000, loss: 0.017332
 >> iter 47000, loss: 0.026806
 >> iter 48000, loss: 0.020329
 >> iter 49000, loss: 0.020078
 >> iter 50000, loss: 0.018051
   Number of active neurons: 1
 >> iter 51000, loss: 0.019762
 >> iter 52000, loss: 0.040173
 >> iter 53000, loss: 0.027126
 >> iter 54000, loss: 0.022211
 >> iter 55000, loss: 0.023885
 >> iter 56000, loss: 0.027967
 >> iter 57000, loss: 0.029120
 >> iter 58000, loss: 0.043518
 >> iter 59000, loss: 0.048698
 >> iter 60000, loss: 0.028209
   Number of active neurons: 1
 >> iter 61000, loss: 0.021945
 >> iter 62000, loss: 0.017336
 >> iter 63000, loss: 0.018055
 >> iter 64000, loss: 0.018228
 >> iter 65000, loss: 0.032109
 >> iter 66000, loss: 0.022127
 >> iter 67000, loss: 0.019903
 >> iter 68000, loss: 0.018540
 >> iter 69000, loss: 0.020117
 >> iter 70000, loss: 0.016980
   Number of active neurons: 1
 >> iter 71000, loss: 0.018138
 >> iter 72000, loss: 0.023711
 >> iter 73000, loss: 0.024863
 >> iter 74000, loss: 0.034039
 >> iter 75000, loss: 0.024306
 >> iter 76000, loss: 0.022157
 >> iter 77000, loss: 0.021557
 >> iter 78000, loss: 0.023397
 >> iter 79000, loss: 0.031246
 >> iter 80000, loss: 0.022325
   Number of active neurons: 1
 >> iter 81000, loss: 0.020130
 >> iter 82000, loss: 0.027776
 >> iter 83000, loss: 0.027619
 >> iter 84000, loss: 0.022458
 >> iter 85000, loss: 0.019978
 >> iter 86000, loss: 0.016930
 >> iter 87000, loss: 0.018101
 >> iter 88000, loss: 0.018954
 >> iter 89000, loss: 0.019382
 >> iter 90000, loss: 0.023477
   Number of active neurons: 1
 >> iter 91000, loss: 0.021433
 >> iter 92000, loss: 0.018150
 >> iter 93000, loss: 0.017657
 >> iter 94000, loss: 0.028468
 >> iter 95000, loss: 0.028523
 >> iter 96000, loss: 0.021604
 >> iter 97000, loss: 0.027986
 >> iter 98000, loss: 0.023984
 >> iter 99000, loss: 0.020167
 >> iter 100000, loss: 0.019816
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.957043
 >> iter 2000, loss: 4.093503
 >> iter 3000, loss: 1.543425
 >> iter 4000, loss: 0.592526
 >> iter 5000, loss: 0.246858
 >> iter 6000, loss: 0.118027
 >> iter 7000, loss: 0.076857
 >> iter 8000, loss: 0.051791
 >> iter 9000, loss: 0.043522
 >> iter 10000, loss: 0.035181
   Number of active neurons: 6
 >> iter 11000, loss: 0.033842
 >> iter 12000, loss: 0.033310
 >> iter 13000, loss: 0.031033
 >> iter 14000, loss: 0.032215
 >> iter 15000, loss: 0.033521
 >> iter 16000, loss: 0.035425
 >> iter 17000, loss: 0.030679
 >> iter 18000, loss: 0.050347
 >> iter 19000, loss: 0.039942
 >> iter 20000, loss: 0.033966
   Number of active neurons: 5
 >> iter 21000, loss: 0.032327
 >> iter 22000, loss: 0.031768
 >> iter 23000, loss: 0.036794
 >> iter 24000, loss: 0.032751
 >> iter 25000, loss: 0.044284
 >> iter 26000, loss: 0.032427
 >> iter 27000, loss: 0.051915
 >> iter 28000, loss: 0.039603
 >> iter 29000, loss: 0.029618
 >> iter 30000, loss: 0.026684
   Number of active neurons: 2
 >> iter 31000, loss: 0.033327
 >> iter 32000, loss: 0.027707
 >> iter 33000, loss: 0.024737
 >> iter 34000, loss: 0.028451
 >> iter 35000, loss: 0.035210
 >> iter 36000, loss: 0.027907
 >> iter 37000, loss: 0.027909
 >> iter 38000, loss: 0.024561
 >> iter 39000, loss: 0.024637
 >> iter 40000, loss: 0.023285
   Number of active neurons: 2
 >> iter 41000, loss: 0.022309
 >> iter 42000, loss: 0.024115
 >> iter 43000, loss: 0.023930
 >> iter 44000, loss: 0.021689
 >> iter 45000, loss: 0.021156
 >> iter 46000, loss: 0.060596
 >> iter 47000, loss: 0.049250
 >> iter 48000, loss: 0.035979
 >> iter 49000, loss: 0.027263
 >> iter 50000, loss: 0.022009
   Number of active neurons: 2
 >> iter 51000, loss: 0.026443
 >> iter 52000, loss: 0.026490
 >> iter 53000, loss: 0.023050
 >> iter 54000, loss: 0.020914
 >> iter 55000, loss: 0.025435
 >> iter 56000, loss: 0.037623
 >> iter 57000, loss: 0.029561
 >> iter 58000, loss: 0.022281
 >> iter 59000, loss: 0.021332
 >> iter 60000, loss: 0.023686
   Number of active neurons: 1
 >> iter 61000, loss: 0.023824
 >> iter 62000, loss: 0.022226
 >> iter 63000, loss: 0.020198
 >> iter 64000, loss: 0.017868
 >> iter 65000, loss: 0.018724
 >> iter 66000, loss: 0.018270
 >> iter 67000, loss: 0.027297
 >> iter 68000, loss: 0.020680
 >> iter 69000, loss: 0.018425
 >> iter 70000, loss: 0.020416
   Number of active neurons: 1
 >> iter 71000, loss: 0.019183
 >> iter 72000, loss: 0.018640
 >> iter 73000, loss: 0.017194
 >> iter 74000, loss: 0.019585
 >> iter 75000, loss: 0.026621
 >> iter 76000, loss: 0.020000
 >> iter 77000, loss: 0.028413
 >> iter 78000, loss: 0.028143
 >> iter 79000, loss: 0.027810
 >> iter 80000, loss: 0.022761
   Number of active neurons: 1
 >> iter 81000, loss: 0.021819
 >> iter 82000, loss: 0.020127
 >> iter 83000, loss: 0.019502
 >> iter 84000, loss: 0.023492
 >> iter 85000, loss: 0.018452
 >> iter 86000, loss: 0.033623
 >> iter 87000, loss: 0.023225
 >> iter 88000, loss: 0.022580
 >> iter 89000, loss: 0.019109
 >> iter 90000, loss: 0.016605
   Number of active neurons: 1
 >> iter 91000, loss: 0.015470
 >> iter 92000, loss: 0.018151
 >> iter 93000, loss: 0.019596
 >> iter 94000, loss: 0.020393
 >> iter 95000, loss: 0.021664
 >> iter 96000, loss: 0.025327
 >> iter 97000, loss: 0.026342
 >> iter 98000, loss: 0.023617
 >> iter 99000, loss: 0.019653
 >> iter 100000, loss: 0.024780
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.922380
 >> iter 2000, loss: 4.070649
 >> iter 3000, loss: 1.525793
 >> iter 4000, loss: 0.590793
 >> iter 5000, loss: 0.247570
 >> iter 6000, loss: 0.115952
 >> iter 7000, loss: 0.071529
 >> iter 8000, loss: 0.048687
 >> iter 9000, loss: 0.040323
 >> iter 10000, loss: 0.049803
   Number of active neurons: 5
 >> iter 11000, loss: 0.041794
 >> iter 12000, loss: 0.035694
 >> iter 13000, loss: 0.033238
 >> iter 14000, loss: 0.029126
 >> iter 15000, loss: 0.029284
 >> iter 16000, loss: 0.029463
 >> iter 17000, loss: 0.030401
 >> iter 18000, loss: 0.032980
 >> iter 19000, loss: 0.027902
 >> iter 20000, loss: 0.028421
   Number of active neurons: 3
 >> iter 21000, loss: 0.025261
 >> iter 22000, loss: 0.027357
 >> iter 23000, loss: 0.024354
 >> iter 24000, loss: 0.024119
 >> iter 25000, loss: 0.026662
 >> iter 26000, loss: 0.022826
 >> iter 27000, loss: 0.025180
 >> iter 28000, loss: 0.024405
 >> iter 29000, loss: 0.030907
 >> iter 30000, loss: 0.027191
   Number of active neurons: 1
 >> iter 31000, loss: 0.034414
 >> iter 32000, loss: 0.024352
 >> iter 33000, loss: 0.022444
 >> iter 34000, loss: 0.022745
 >> iter 35000, loss: 0.019816
 >> iter 36000, loss: 0.018033
 >> iter 37000, loss: 0.021658
 >> iter 38000, loss: 0.019417
 >> iter 39000, loss: 0.021052
 >> iter 40000, loss: 0.017284
   Number of active neurons: 1
 >> iter 41000, loss: 0.019956
 >> iter 42000, loss: 0.020532
 >> iter 43000, loss: 0.029011
 >> iter 44000, loss: 0.020660
 >> iter 45000, loss: 0.024236
 >> iter 46000, loss: 0.027693
 >> iter 47000, loss: 0.021801
 >> iter 48000, loss: 0.018074
 >> iter 49000, loss: 0.024297
 >> iter 50000, loss: 0.019595
   Number of active neurons: 1
 >> iter 51000, loss: 0.020215
 >> iter 52000, loss: 0.028679
 >> iter 53000, loss: 0.025888
 >> iter 54000, loss: 0.020352
 >> iter 55000, loss: 0.017770
 >> iter 56000, loss: 0.019154
 >> iter 57000, loss: 0.021911
 >> iter 58000, loss: 0.018970
 >> iter 59000, loss: 0.018310
 >> iter 60000, loss: 0.028523
   Number of active neurons: 1
 >> iter 61000, loss: 0.024329
 >> iter 62000, loss: 0.021626
 >> iter 63000, loss: 0.018091
 >> iter 64000, loss: 0.038021
 >> iter 65000, loss: 0.027000
 >> iter 66000, loss: 0.021636
 >> iter 67000, loss: 0.017567
 >> iter 68000, loss: 0.016247
 >> iter 69000, loss: 0.016071
 >> iter 70000, loss: 0.017645
   Number of active neurons: 1
 >> iter 71000, loss: 0.021353
 >> iter 72000, loss: 0.029332
 >> iter 73000, loss: 0.023529
 >> iter 74000, loss: 0.024580
 >> iter 75000, loss: 0.027387
 >> iter 76000, loss: 0.024558
 >> iter 77000, loss: 0.020408
 >> iter 78000, loss: 0.023503
 >> iter 79000, loss: 0.029021
 >> iter 80000, loss: 0.023468
   Number of active neurons: 1
 >> iter 81000, loss: 0.019148
 >> iter 82000, loss: 0.020301
 >> iter 83000, loss: 0.016411
 >> iter 84000, loss: 0.016523
 >> iter 85000, loss: 0.030213
 >> iter 86000, loss: 0.021592
 >> iter 87000, loss: 0.019459
 >> iter 88000, loss: 0.020969
 >> iter 89000, loss: 0.018578
 >> iter 90000, loss: 0.022026
   Number of active neurons: 1
 >> iter 91000, loss: 0.017678
 >> iter 92000, loss: 0.027265
 >> iter 93000, loss: 0.022622
 >> iter 94000, loss: 0.019495
 >> iter 95000, loss: 0.018643
 >> iter 96000, loss: 0.019813
 >> iter 97000, loss: 0.023499
 >> iter 98000, loss: 0.018163
 >> iter 99000, loss: 0.018865
 >> iter 100000, loss: 0.030965
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.969267
 >> iter 2000, loss: 4.080561
 >> iter 3000, loss: 1.540409
 >> iter 4000, loss: 0.609105
 >> iter 5000, loss: 0.250363
 >> iter 6000, loss: 0.113313
 >> iter 7000, loss: 0.066480
 >> iter 8000, loss: 0.044916
 >> iter 9000, loss: 0.035321
 >> iter 10000, loss: 0.033064
   Number of active neurons: 5
 >> iter 11000, loss: 0.029635
 >> iter 12000, loss: 0.030421
 >> iter 13000, loss: 0.043483
 >> iter 14000, loss: 0.043751
 >> iter 15000, loss: 0.033743
 >> iter 16000, loss: 0.032772
 >> iter 17000, loss: 0.044634
 >> iter 18000, loss: 0.031708
 >> iter 19000, loss: 0.035760
 >> iter 20000, loss: 0.027076
   Number of active neurons: 3
 >> iter 21000, loss: 0.023680
 >> iter 22000, loss: 0.023284
 >> iter 23000, loss: 0.032595
 >> iter 24000, loss: 0.063736
 >> iter 25000, loss: 0.038708
 >> iter 26000, loss: 0.030752
 >> iter 27000, loss: 0.025236
 >> iter 28000, loss: 0.022566
 >> iter 29000, loss: 0.028841
 >> iter 30000, loss: 0.032068
   Number of active neurons: 2
 >> iter 31000, loss: 0.029746
 >> iter 32000, loss: 0.027444
 >> iter 33000, loss: 0.028760
 >> iter 34000, loss: 0.030293
 >> iter 35000, loss: 0.028530
 >> iter 36000, loss: 0.022659
 >> iter 37000, loss: 0.023422
 >> iter 38000, loss: 0.022159
 >> iter 39000, loss: 0.032979
 >> iter 40000, loss: 0.024944
   Number of active neurons: 2
 >> iter 41000, loss: 0.021664
 >> iter 42000, loss: 0.021583
 >> iter 43000, loss: 0.020771
 >> iter 44000, loss: 0.020777
 >> iter 45000, loss: 0.026023
 >> iter 46000, loss: 0.040764
 >> iter 47000, loss: 0.027699
 >> iter 48000, loss: 0.026532
 >> iter 49000, loss: 0.023061
 >> iter 50000, loss: 0.028993
   Number of active neurons: 2
 >> iter 51000, loss: 0.039235
 >> iter 52000, loss: 0.029618
 >> iter 53000, loss: 0.025112
 >> iter 54000, loss: 0.028464
 >> iter 55000, loss: 0.025270
 >> iter 56000, loss: 0.034847
 >> iter 57000, loss: 0.025780
 >> iter 58000, loss: 0.023051
 >> iter 59000, loss: 0.021573
 >> iter 60000, loss: 0.023076
   Number of active neurons: 1
 >> iter 61000, loss: 0.021909
 >> iter 62000, loss: 0.023643
 >> iter 63000, loss: 0.021018
 >> iter 64000, loss: 0.026461
 >> iter 65000, loss: 0.020941
 >> iter 66000, loss: 0.019611
 >> iter 67000, loss: 0.020453
 >> iter 68000, loss: 0.022151
 >> iter 69000, loss: 0.018960
 >> iter 70000, loss: 0.023461
   Number of active neurons: 1
 >> iter 71000, loss: 0.018958
 >> iter 72000, loss: 0.018646
 >> iter 73000, loss: 0.018120
 >> iter 74000, loss: 0.033986
 >> iter 75000, loss: 0.026434
 >> iter 76000, loss: 0.024936
 >> iter 77000, loss: 0.019066
 >> iter 78000, loss: 0.016069
 >> iter 79000, loss: 0.017279
 >> iter 80000, loss: 0.019773
   Number of active neurons: 1
 >> iter 81000, loss: 0.026678
 >> iter 82000, loss: 0.041652
 >> iter 83000, loss: 0.036691
 >> iter 84000, loss: 0.026577
 >> iter 85000, loss: 0.020181
 >> iter 86000, loss: 0.019537
 >> iter 87000, loss: 0.020220
 >> iter 88000, loss: 0.028928
 >> iter 89000, loss: 0.023058
 >> iter 90000, loss: 0.019516
   Number of active neurons: 1
 >> iter 91000, loss: 0.024826
 >> iter 92000, loss: 0.022151
 >> iter 93000, loss: 0.017550
 >> iter 94000, loss: 0.019164
 >> iter 95000, loss: 0.026730
 >> iter 96000, loss: 0.020771
 >> iter 97000, loss: 0.019683
 >> iter 98000, loss: 0.018121
 >> iter 99000, loss: 0.017242
 >> iter 100000, loss: 0.019870
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.968357
 >> iter 2000, loss: 4.095435
 >> iter 3000, loss: 1.543148
 >> iter 4000, loss: 0.595792
 >> iter 5000, loss: 0.239519
 >> iter 6000, loss: 0.107894
 >> iter 7000, loss: 0.070962
 >> iter 8000, loss: 0.043985
 >> iter 9000, loss: 0.034658
 >> iter 10000, loss: 0.031833
   Number of active neurons: 4
 >> iter 11000, loss: 0.028708
 >> iter 12000, loss: 0.029378
 >> iter 13000, loss: 0.026930
 >> iter 14000, loss: 0.026135
 >> iter 15000, loss: 0.027020
 >> iter 16000, loss: 0.026903
 >> iter 17000, loss: 0.032087
 >> iter 18000, loss: 0.030335
 >> iter 19000, loss: 0.027057
 >> iter 20000, loss: 0.024014
   Number of active neurons: 3
 >> iter 21000, loss: 0.028387
 >> iter 22000, loss: 0.024619
 >> iter 23000, loss: 0.023606
 >> iter 24000, loss: 0.024723
 >> iter 25000, loss: 0.029633
 >> iter 26000, loss: 0.034336
 >> iter 27000, loss: 0.029666
 >> iter 28000, loss: 0.026593
 >> iter 29000, loss: 0.024332
 >> iter 30000, loss: 0.029686
   Number of active neurons: 3
 >> iter 31000, loss: 0.046265
 >> iter 32000, loss: 0.032577
 >> iter 33000, loss: 0.028341
 >> iter 34000, loss: 0.023974
 >> iter 35000, loss: 0.024113
 >> iter 36000, loss: 0.024718
 >> iter 37000, loss: 0.025210
 >> iter 38000, loss: 0.028353
 >> iter 39000, loss: 0.027441
 >> iter 40000, loss: 0.025496
   Number of active neurons: 3
 >> iter 41000, loss: 0.027157
 >> iter 42000, loss: 0.024959
 >> iter 43000, loss: 0.024033
 >> iter 44000, loss: 0.028773
 >> iter 45000, loss: 0.023200
 >> iter 46000, loss: 0.026246
 >> iter 47000, loss: 0.030813
 >> iter 48000, loss: 0.026568
 >> iter 49000, loss: 0.025784
 >> iter 50000, loss: 0.026589
   Number of active neurons: 2
 >> iter 51000, loss: 0.023004
 >> iter 52000, loss: 0.028488
 >> iter 53000, loss: 0.023972
 >> iter 54000, loss: 0.022849
 >> iter 55000, loss: 0.021119
 >> iter 56000, loss: 0.020056
 >> iter 57000, loss: 0.021978
 >> iter 58000, loss: 0.021092
 >> iter 59000, loss: 0.026251
 >> iter 60000, loss: 0.024586
   Number of active neurons: 2
 >> iter 61000, loss: 0.022037
 >> iter 62000, loss: 0.021944
 >> iter 63000, loss: 0.029435
 >> iter 64000, loss: 0.023087
 >> iter 65000, loss: 0.024979
 >> iter 66000, loss: 0.029784
 >> iter 67000, loss: 0.030701
 >> iter 68000, loss: 0.037971
 >> iter 69000, loss: 0.037763
 >> iter 70000, loss: 0.036186
   Number of active neurons: 2
 >> iter 71000, loss: 0.027263
 >> iter 72000, loss: 0.024951
 >> iter 73000, loss: 0.025150
 >> iter 74000, loss: 0.030444
 >> iter 75000, loss: 0.026660
 >> iter 76000, loss: 0.021868
 >> iter 77000, loss: 0.030618
 >> iter 78000, loss: 0.023478
 >> iter 79000, loss: 0.022472
 >> iter 80000, loss: 0.027374
   Number of active neurons: 2
 >> iter 81000, loss: 0.027596
 >> iter 82000, loss: 0.024490
 >> iter 83000, loss: 0.021288
 >> iter 84000, loss: 0.020454
 >> iter 85000, loss: 0.021258
 >> iter 86000, loss: 0.020437
 >> iter 87000, loss: 0.021453
 >> iter 88000, loss: 0.019999
 >> iter 89000, loss: 0.021865
 >> iter 90000, loss: 0.021181
   Number of active neurons: 2
 >> iter 91000, loss: 0.024405
 >> iter 92000, loss: 0.025832
 >> iter 93000, loss: 0.022793
 >> iter 94000, loss: 0.022504
 >> iter 95000, loss: 0.020774
 >> iter 96000, loss: 0.036714
 >> iter 97000, loss: 0.029242
 >> iter 98000, loss: 0.046359
 >> iter 99000, loss: 0.035806
 >> iter 100000, loss: 0.027406
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.931280
 >> iter 2000, loss: 4.064256
 >> iter 3000, loss: 1.537083
 >> iter 4000, loss: 0.594474
 >> iter 5000, loss: 0.246087
 >> iter 6000, loss: 0.110550
 >> iter 7000, loss: 0.062057
 >> iter 8000, loss: 0.042861
 >> iter 9000, loss: 0.040471
 >> iter 10000, loss: 0.036405
   Number of active neurons: 5
 >> iter 11000, loss: 0.037296
 >> iter 12000, loss: 0.043460
 >> iter 13000, loss: 0.043293
 >> iter 14000, loss: 0.040928
 >> iter 15000, loss: 0.034824
 >> iter 16000, loss: 0.038376
 >> iter 17000, loss: 0.029783
 >> iter 18000, loss: 0.026277
 >> iter 19000, loss: 0.024675
 >> iter 20000, loss: 0.029515
   Number of active neurons: 3
 >> iter 21000, loss: 0.024694
 >> iter 22000, loss: 0.023309
 >> iter 23000, loss: 0.023212
 >> iter 24000, loss: 0.023077
 >> iter 25000, loss: 0.021951
 >> iter 26000, loss: 0.033540
 >> iter 27000, loss: 0.025747
 >> iter 28000, loss: 0.022438
 >> iter 29000, loss: 0.027322
 >> iter 30000, loss: 0.028893
   Number of active neurons: 2
 >> iter 31000, loss: 0.024096
 >> iter 32000, loss: 0.020769
 >> iter 33000, loss: 0.036031
 >> iter 34000, loss: 0.025279
 >> iter 35000, loss: 0.022422
 >> iter 36000, loss: 0.021975
 >> iter 37000, loss: 0.023297
 >> iter 38000, loss: 0.022672
 >> iter 39000, loss: 0.020678
 >> iter 40000, loss: 0.029088
   Number of active neurons: 2
 >> iter 41000, loss: 0.026326
 >> iter 42000, loss: 0.021975
 >> iter 43000, loss: 0.023447
 >> iter 44000, loss: 0.033420
 >> iter 45000, loss: 0.029620
 >> iter 46000, loss: 0.027113
 >> iter 47000, loss: 0.026642
 >> iter 48000, loss: 0.022521
 >> iter 49000, loss: 0.022479
 >> iter 50000, loss: 0.039482
   Number of active neurons: 2
 >> iter 51000, loss: 0.029721
 >> iter 52000, loss: 0.026717
 >> iter 53000, loss: 0.023385
 >> iter 54000, loss: 0.041395
 >> iter 55000, loss: 0.027582
 >> iter 56000, loss: 0.026498
 >> iter 57000, loss: 0.023637
 >> iter 58000, loss: 0.048659
 >> iter 59000, loss: 0.034209
 >> iter 60000, loss: 0.027968
   Number of active neurons: 2
 >> iter 61000, loss: 0.025649
 >> iter 62000, loss: 0.027963
 >> iter 63000, loss: 0.034847
 >> iter 64000, loss: 0.039130
 >> iter 65000, loss: 0.028540
 >> iter 66000, loss: 0.024530
 >> iter 67000, loss: 0.030940
 >> iter 68000, loss: 0.047631
 >> iter 69000, loss: 0.038293
 >> iter 70000, loss: 0.046321
   Number of active neurons: 2
 >> iter 71000, loss: 0.031234
 >> iter 72000, loss: 0.024794
 >> iter 73000, loss: 0.030028
 >> iter 74000, loss: 0.024548
 >> iter 75000, loss: 0.022916
 >> iter 76000, loss: 0.021436
 >> iter 77000, loss: 0.027718
 >> iter 78000, loss: 0.022825
 >> iter 79000, loss: 0.026605
 >> iter 80000, loss: 0.022535
   Number of active neurons: 2
 >> iter 81000, loss: 0.022384
 >> iter 82000, loss: 0.028102
 >> iter 83000, loss: 0.030573
 >> iter 84000, loss: 0.024710
 >> iter 85000, loss: 0.026415
 >> iter 86000, loss: 0.022682
 >> iter 87000, loss: 0.054095
 >> iter 88000, loss: 0.031722
 >> iter 89000, loss: 0.023346
 >> iter 90000, loss: 0.022453
   Number of active neurons: 1
 >> iter 91000, loss: 0.022761
 >> iter 92000, loss: 0.020764
 >> iter 93000, loss: 0.018721
 >> iter 94000, loss: 0.018159
 >> iter 95000, loss: 0.031520
 >> iter 96000, loss: 0.023552
 >> iter 97000, loss: 0.019554
 >> iter 98000, loss: 0.021489
 >> iter 99000, loss: 0.022241
 >> iter 100000, loss: 0.019403
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.963970
 >> iter 2000, loss: 4.089061
 >> iter 3000, loss: 1.556033
 >> iter 4000, loss: 0.594482
 >> iter 5000, loss: 0.240921
 >> iter 6000, loss: 0.105976
 >> iter 7000, loss: 0.060279
 >> iter 8000, loss: 0.042374
 >> iter 9000, loss: 0.049478
 >> iter 10000, loss: 0.037149
   Number of active neurons: 4
 >> iter 11000, loss: 0.031109
 >> iter 12000, loss: 0.027224
 >> iter 13000, loss: 0.026802
 >> iter 14000, loss: 0.032204
 >> iter 15000, loss: 0.029391
 >> iter 16000, loss: 0.026980
 >> iter 17000, loss: 0.024445
 >> iter 18000, loss: 0.023217
 >> iter 19000, loss: 0.025333
 >> iter 20000, loss: 0.034202
   Number of active neurons: 3
 >> iter 21000, loss: 0.028863
 >> iter 22000, loss: 0.026818
 >> iter 23000, loss: 0.027205
 >> iter 24000, loss: 0.024998
 >> iter 25000, loss: 0.026077
 >> iter 26000, loss: 0.022615
 >> iter 27000, loss: 0.024165
 >> iter 28000, loss: 0.022381
 >> iter 29000, loss: 0.022732
 >> iter 30000, loss: 0.024989
   Number of active neurons: 3
 >> iter 31000, loss: 0.025277
 >> iter 32000, loss: 0.035719
 >> iter 33000, loss: 0.034330
 >> iter 34000, loss: 0.027125
 >> iter 35000, loss: 0.028135
 >> iter 36000, loss: 0.023896
 >> iter 37000, loss: 0.024144
 >> iter 38000, loss: 0.028849
 >> iter 39000, loss: 0.029468
 >> iter 40000, loss: 0.025513
   Number of active neurons: 2
 >> iter 41000, loss: 0.025087
 >> iter 42000, loss: 0.025295
 >> iter 43000, loss: 0.023165
 >> iter 44000, loss: 0.020620
 >> iter 45000, loss: 0.026608
 >> iter 46000, loss: 0.025403
 >> iter 47000, loss: 0.040740
 >> iter 48000, loss: 0.034270
 >> iter 49000, loss: 0.038473
 >> iter 50000, loss: 0.025617
   Number of active neurons: 2
 >> iter 51000, loss: 0.025142
 >> iter 52000, loss: 0.023264
 >> iter 53000, loss: 0.022342
 >> iter 54000, loss: 0.037661
 >> iter 55000, loss: 0.026720
 >> iter 56000, loss: 0.024863
 >> iter 57000, loss: 0.022991
 >> iter 58000, loss: 0.021468
 >> iter 59000, loss: 0.022101
 >> iter 60000, loss: 0.049185
   Number of active neurons: 2
 >> iter 61000, loss: 0.031035
 >> iter 62000, loss: 0.026702
 >> iter 63000, loss: 0.037214
 >> iter 64000, loss: 0.028783
 >> iter 65000, loss: 0.023303
 >> iter 66000, loss: 0.021037
 >> iter 67000, loss: 0.049918
 >> iter 68000, loss: 0.031780
 >> iter 69000, loss: 0.047314
 >> iter 70000, loss: 0.040952
   Number of active neurons: 2
 >> iter 71000, loss: 0.046796
 >> iter 72000, loss: 0.034537
 >> iter 73000, loss: 0.028269
 >> iter 74000, loss: 0.031485
 >> iter 75000, loss: 0.025853
 >> iter 76000, loss: 0.034005
 >> iter 77000, loss: 0.025541
 >> iter 78000, loss: 0.029377
 >> iter 79000, loss: 0.033199
 >> iter 80000, loss: 0.052469
   Number of active neurons: 2
 >> iter 81000, loss: 0.033388
 >> iter 82000, loss: 0.024989
 >> iter 83000, loss: 0.044001
 >> iter 84000, loss: 0.028903
 >> iter 85000, loss: 0.023674
 >> iter 86000, loss: 0.022299
 >> iter 87000, loss: 0.021324
 >> iter 88000, loss: 0.019177
 >> iter 89000, loss: 0.022792
 >> iter 90000, loss: 0.019330
   Number of active neurons: 1
 >> iter 91000, loss: 0.026827
 >> iter 92000, loss: 0.022036
 >> iter 93000, loss: 0.019455
 >> iter 94000, loss: 0.017783
 >> iter 95000, loss: 0.017978
 >> iter 96000, loss: 0.021061
 >> iter 97000, loss: 0.029226
 >> iter 98000, loss: 0.021765
 >> iter 99000, loss: 0.019507
 >> iter 100000, loss: 0.017079
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.904208
 >> iter 2000, loss: 4.057339
 >> iter 3000, loss: 1.533765
 >> iter 4000, loss: 0.596383
 >> iter 5000, loss: 0.241601
 >> iter 6000, loss: 0.111723
 >> iter 7000, loss: 0.064185
 >> iter 8000, loss: 0.041101
 >> iter 9000, loss: 0.047082
 >> iter 10000, loss: 0.047698
   Number of active neurons: 5
 >> iter 11000, loss: 0.035836
 >> iter 12000, loss: 0.029764
 >> iter 13000, loss: 0.039212
 >> iter 14000, loss: 0.033981
 >> iter 15000, loss: 0.029030
 >> iter 16000, loss: 0.030104
 >> iter 17000, loss: 0.028436
 >> iter 18000, loss: 0.027914
 >> iter 19000, loss: 0.029597
 >> iter 20000, loss: 0.026625
   Number of active neurons: 3
 >> iter 21000, loss: 0.039366
 >> iter 22000, loss: 0.031304
 >> iter 23000, loss: 0.031480
 >> iter 24000, loss: 0.025812
 >> iter 25000, loss: 0.025983
 >> iter 26000, loss: 0.033520
 >> iter 27000, loss: 0.029262
 >> iter 28000, loss: 0.024145
 >> iter 29000, loss: 0.024597
 >> iter 30000, loss: 0.027695
   Number of active neurons: 3
 >> iter 31000, loss: 0.026518
 >> iter 32000, loss: 0.043147
 >> iter 33000, loss: 0.041040
 >> iter 34000, loss: 0.030121
 >> iter 35000, loss: 0.025280
 >> iter 36000, loss: 0.032287
 >> iter 37000, loss: 0.040681
 >> iter 38000, loss: 0.028935
 >> iter 39000, loss: 0.025361
 >> iter 40000, loss: 0.026841
   Number of active neurons: 2
 >> iter 41000, loss: 0.026229
 >> iter 42000, loss: 0.025986
 >> iter 43000, loss: 0.024834
 >> iter 44000, loss: 0.023361
 >> iter 45000, loss: 0.024372
 >> iter 46000, loss: 0.031479
 >> iter 47000, loss: 0.034674
 >> iter 48000, loss: 0.025397
 >> iter 49000, loss: 0.023780
 >> iter 50000, loss: 0.041392
   Number of active neurons: 1
 >> iter 51000, loss: 0.039371
 >> iter 52000, loss: 0.025647
 >> iter 53000, loss: 0.021103
 >> iter 54000, loss: 0.019057
 >> iter 55000, loss: 0.018123
 >> iter 56000, loss: 0.018226
 >> iter 57000, loss: 0.018959
 >> iter 58000, loss: 0.018360
 >> iter 59000, loss: 0.030658
 >> iter 60000, loss: 0.030822
   Number of active neurons: 1
 >> iter 61000, loss: 0.024051
 >> iter 62000, loss: 0.023057
 >> iter 63000, loss: 0.019143
 >> iter 64000, loss: 0.018916
 >> iter 65000, loss: 0.019703
 >> iter 66000, loss: 0.017086
 >> iter 67000, loss: 0.015697
 >> iter 68000, loss: 0.032736
 >> iter 69000, loss: 0.023757
 >> iter 70000, loss: 0.019609
   Number of active neurons: 1
 >> iter 71000, loss: 0.020226
 >> iter 72000, loss: 0.017075
 >> iter 73000, loss: 0.028909
 >> iter 74000, loss: 0.020583
 >> iter 75000, loss: 0.018552
 >> iter 76000, loss: 0.021917
 >> iter 77000, loss: 0.019702
 >> iter 78000, loss: 0.035982
 >> iter 79000, loss: 0.024247
 >> iter 80000, loss: 0.035742
   Number of active neurons: 1
 >> iter 81000, loss: 0.024343
 >> iter 82000, loss: 0.021131
 >> iter 83000, loss: 0.018124
 >> iter 84000, loss: 0.016068
 >> iter 85000, loss: 0.017272
 >> iter 86000, loss: 0.019634
 >> iter 87000, loss: 0.018217
 >> iter 88000, loss: 0.020556
 >> iter 89000, loss: 0.018070
 >> iter 90000, loss: 0.019690
   Number of active neurons: 1
 >> iter 91000, loss: 0.024288
 >> iter 92000, loss: 0.037089
 >> iter 93000, loss: 0.053083
 >> iter 94000, loss: 0.033507
 >> iter 95000, loss: 0.023616
 >> iter 96000, loss: 0.034983
 >> iter 97000, loss: 0.037137
 >> iter 98000, loss: 0.025622
 >> iter 99000, loss: 0.024945
 >> iter 100000, loss: 0.031509
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.948318
 >> iter 2000, loss: 4.104827
 >> iter 3000, loss: 1.535033
 >> iter 4000, loss: 0.585320
 >> iter 5000, loss: 0.243009
 >> iter 6000, loss: 0.110581
 >> iter 7000, loss: 0.066601
 >> iter 8000, loss: 0.044281
 >> iter 9000, loss: 0.036533
 >> iter 10000, loss: 0.033844
   Number of active neurons: 6
 >> iter 11000, loss: 0.030723
 >> iter 12000, loss: 0.039909
 >> iter 13000, loss: 0.044018
 >> iter 14000, loss: 0.046508
 >> iter 15000, loss: 0.032390
 >> iter 16000, loss: 0.028794
 >> iter 17000, loss: 0.029152
 >> iter 18000, loss: 0.028002
 >> iter 19000, loss: 0.037141
 >> iter 20000, loss: 0.030240
   Number of active neurons: 4
 >> iter 21000, loss: 0.028315
 >> iter 22000, loss: 0.028728
 >> iter 23000, loss: 0.030948
 >> iter 24000, loss: 0.034580
 >> iter 25000, loss: 0.028590
 >> iter 26000, loss: 0.026981
 >> iter 27000, loss: 0.028403
 >> iter 28000, loss: 0.028412
 >> iter 29000, loss: 0.025361
 >> iter 30000, loss: 0.026926
   Number of active neurons: 4
 >> iter 31000, loss: 0.027860
 >> iter 32000, loss: 0.027747
 >> iter 33000, loss: 0.037711
 >> iter 34000, loss: 0.036177
 >> iter 35000, loss: 0.029075
 >> iter 36000, loss: 0.027083
 >> iter 37000, loss: 0.034603
 >> iter 38000, loss: 0.031950
 >> iter 39000, loss: 0.028687
 >> iter 40000, loss: 0.049843
   Number of active neurons: 3
 >> iter 41000, loss: 0.038728
 >> iter 42000, loss: 0.029305
 >> iter 43000, loss: 0.024634
 >> iter 44000, loss: 0.029539
 >> iter 45000, loss: 0.024061
 >> iter 46000, loss: 0.035620
 >> iter 47000, loss: 0.026388
 >> iter 48000, loss: 0.028955
 >> iter 49000, loss: 0.023866
 >> iter 50000, loss: 0.025620
   Number of active neurons: 2
 >> iter 51000, loss: 0.023457
 >> iter 52000, loss: 0.026317
 >> iter 53000, loss: 0.029574
 >> iter 54000, loss: 0.025990
 >> iter 55000, loss: 0.021649
 >> iter 56000, loss: 0.023240
 >> iter 57000, loss: 0.044764
 >> iter 58000, loss: 0.030374
 >> iter 59000, loss: 0.024663
 >> iter 60000, loss: 0.021748
   Number of active neurons: 1
 >> iter 61000, loss: 0.029605
 >> iter 62000, loss: 0.029527
 >> iter 63000, loss: 0.029215
 >> iter 64000, loss: 0.024292
 >> iter 65000, loss: 0.022434
 >> iter 66000, loss: 0.019966
 >> iter 67000, loss: 0.018656
 >> iter 68000, loss: 0.017204
 >> iter 69000, loss: 0.018841
 >> iter 70000, loss: 0.017114
   Number of active neurons: 1
 >> iter 71000, loss: 0.018297
 >> iter 72000, loss: 0.016784
 >> iter 73000, loss: 0.016485
 >> iter 74000, loss: 0.018076
 >> iter 75000, loss: 0.016387
 >> iter 76000, loss: 0.028680
 >> iter 77000, loss: 0.025153
 >> iter 78000, loss: 0.021086
 >> iter 79000, loss: 0.022922
 >> iter 80000, loss: 0.023426
   Number of active neurons: 1
 >> iter 81000, loss: 0.031245
 >> iter 82000, loss: 0.022782
 >> iter 83000, loss: 0.020491
 >> iter 84000, loss: 0.019167
 >> iter 85000, loss: 0.020811
 >> iter 86000, loss: 0.023797
 >> iter 87000, loss: 0.035850
 >> iter 88000, loss: 0.029357
 >> iter 89000, loss: 0.020943
 >> iter 90000, loss: 0.024940
   Number of active neurons: 1
 >> iter 91000, loss: 0.019698
 >> iter 92000, loss: 0.019348
 >> iter 93000, loss: 0.017474
 >> iter 94000, loss: 0.016551
 >> iter 95000, loss: 0.030885
 >> iter 96000, loss: 0.021850
 >> iter 97000, loss: 0.021309
 >> iter 98000, loss: 0.021309
 >> iter 99000, loss: 0.020735
 >> iter 100000, loss: 0.021217
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

