 > Problema: tomita2nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 12.133782
 >> iter 2000, loss: 5.752931
 >> iter 3000, loss: 3.491864
 >> iter 4000, loss: 2.532195
 >> iter 5000, loss: 2.270773
 >> iter 6000, loss: 2.088919
 >> iter 7000, loss: 2.093036
 >> iter 8000, loss: 1.996794
 >> iter 9000, loss: 2.053334
 >> iter 10000, loss: 1.972217
   Number of active neurons: 2
 >> iter 11000, loss: 2.025328
 >> iter 12000, loss: 1.945495
 >> iter 13000, loss: 2.015168
 >> iter 14000, loss: 1.965487
 >> iter 15000, loss: 2.025419
 >> iter 16000, loss: 1.953265
 >> iter 17000, loss: 2.001304
 >> iter 18000, loss: 1.950556
 >> iter 19000, loss: 2.009190
 >> iter 20000, loss: 1.956481
   Number of active neurons: 2
 >> iter 21000, loss: 2.008557
 >> iter 22000, loss: 1.951820
 >> iter 23000, loss: 2.009315
 >> iter 24000, loss: 1.934302
 >> iter 25000, loss: 1.994529
 >> iter 26000, loss: 1.937462
 >> iter 27000, loss: 1.983247
 >> iter 28000, loss: 1.932375
 >> iter 29000, loss: 1.996743
 >> iter 30000, loss: 1.927441
   Number of active neurons: 2
 >> iter 31000, loss: 1.993125
 >> iter 32000, loss: 1.920153
 >> iter 33000, loss: 1.997942
 >> iter 34000, loss: 1.950008
 >> iter 35000, loss: 2.015310
 >> iter 36000, loss: 1.946404
 >> iter 37000, loss: 1.994959
 >> iter 38000, loss: 1.936494
 >> iter 39000, loss: 1.978542
 >> iter 40000, loss: 1.934625
   Number of active neurons: 2
 >> iter 41000, loss: 1.991939
 >> iter 42000, loss: 1.916865
 >> iter 43000, loss: 1.978491
 >> iter 44000, loss: 1.914851
 >> iter 45000, loss: 1.956988
 >> iter 46000, loss: 1.914605
 >> iter 47000, loss: 1.979711
 >> iter 48000, loss: 1.926739
 >> iter 49000, loss: 1.972241
 >> iter 50000, loss: 1.908539
   Number of active neurons: 2
 >> iter 51000, loss: 1.978213
 >> iter 52000, loss: 1.934638
 >> iter 53000, loss: 1.967459
 >> iter 54000, loss: 1.927176
 >> iter 55000, loss: 1.966368
 >> iter 56000, loss: 1.930872
 >> iter 57000, loss: 1.966680
 >> iter 58000, loss: 1.918891
 >> iter 59000, loss: 1.945408
 >> iter 60000, loss: 1.906468
   Number of active neurons: 2
 >> iter 61000, loss: 1.976240
 >> iter 62000, loss: 1.916305
 >> iter 63000, loss: 1.990201
 >> iter 64000, loss: 1.938137
 >> iter 65000, loss: 1.972365
 >> iter 66000, loss: 1.920845
 >> iter 67000, loss: 1.972249
 >> iter 68000, loss: 1.933113
 >> iter 69000, loss: 1.980343
 >> iter 70000, loss: 1.936061
   Number of active neurons: 2
 >> iter 71000, loss: 1.977300
 >> iter 72000, loss: 1.929286
 >> iter 73000, loss: 1.973121
 >> iter 74000, loss: 1.904882
 >> iter 75000, loss: 1.961583
 >> iter 76000, loss: 1.918812
 >> iter 77000, loss: 1.971177
 >> iter 78000, loss: 1.912954
 >> iter 79000, loss: 1.981806
 >> iter 80000, loss: 1.920576
   Number of active neurons: 2
 >> iter 81000, loss: 1.970606
 >> iter 82000, loss: 1.933149
 >> iter 83000, loss: 1.959858
 >> iter 84000, loss: 1.925397
 >> iter 85000, loss: 1.959462
 >> iter 86000, loss: 1.906420
 >> iter 87000, loss: 1.945065
 >> iter 88000, loss: 1.915709
 >> iter 89000, loss: 1.957455
 >> iter 90000, loss: 1.908789
   Number of active neurons: 2
 >> iter 91000, loss: 1.945497
 >> iter 92000, loss: 1.893957
 >> iter 93000, loss: 1.954726
 >> iter 94000, loss: 1.917406
 >> iter 95000, loss: 1.978712
 >> iter 96000, loss: 1.900261
 >> iter 97000, loss: 1.936809
 >> iter 98000, loss: 1.902528
 >> iter 99000, loss: 1.948128
 >> iter 100000, loss: 1.902059
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.807350
 >> iter 2000, loss: 4.504288
 >> iter 3000, loss: 1.728301
 >> iter 4000, loss: 0.680609
 >> iter 5000, loss: 0.303125
 >> iter 6000, loss: 0.133248
 >> iter 7000, loss: 0.081832
 >> iter 8000, loss: 0.065325
 >> iter 9000, loss: 0.049286
 >> iter 10000, loss: 0.037916
   Number of active neurons: 2
 >> iter 11000, loss: 0.050617
 >> iter 12000, loss: 0.045179
 >> iter 13000, loss: 0.044882
 >> iter 14000, loss: 0.055402
 >> iter 15000, loss: 0.042179
 >> iter 16000, loss: 0.044052
 >> iter 17000, loss: 0.046168
 >> iter 18000, loss: 0.030035
 >> iter 19000, loss: 0.058971
 >> iter 20000, loss: 0.048841
   Number of active neurons: 2
 >> iter 21000, loss: 0.067816
 >> iter 22000, loss: 0.050821
 >> iter 23000, loss: 0.047590
 >> iter 24000, loss: 0.042259
 >> iter 25000, loss: 0.082202
 >> iter 26000, loss: 0.061045
 >> iter 27000, loss: 0.046575
 >> iter 28000, loss: 0.057107
 >> iter 29000, loss: 0.038156
 >> iter 30000, loss: 0.053221
   Number of active neurons: 2
 >> iter 31000, loss: 0.064355
 >> iter 32000, loss: 0.059374
 >> iter 33000, loss: 0.042353
 >> iter 34000, loss: 0.050171
 >> iter 35000, loss: 0.061253
 >> iter 36000, loss: 0.042379
 >> iter 37000, loss: 0.039581
 >> iter 38000, loss: 0.038439
 >> iter 39000, loss: 0.049609
 >> iter 40000, loss: 0.054750
   Number of active neurons: 2
 >> iter 41000, loss: 0.062403
 >> iter 42000, loss: 0.049215
 >> iter 43000, loss: 0.050771
 >> iter 44000, loss: 0.035049
 >> iter 45000, loss: 0.051929
 >> iter 46000, loss: 0.048816
 >> iter 47000, loss: 0.066458
 >> iter 48000, loss: 0.070285
 >> iter 49000, loss: 0.043425
 >> iter 50000, loss: 0.032180
   Number of active neurons: 2
 >> iter 51000, loss: 0.036516
 >> iter 52000, loss: 0.035888
 >> iter 53000, loss: 0.033832
 >> iter 54000, loss: 0.029250
 >> iter 55000, loss: 0.040500
 >> iter 56000, loss: 0.046385
 >> iter 57000, loss: 0.044292
 >> iter 58000, loss: 0.042474
 >> iter 59000, loss: 0.029203
 >> iter 60000, loss: 0.044234
   Number of active neurons: 2
 >> iter 61000, loss: 0.034025
 >> iter 62000, loss: 0.043462
 >> iter 63000, loss: 0.043160
 >> iter 64000, loss: 0.035343
 >> iter 65000, loss: 0.035607
 >> iter 66000, loss: 0.040940
 >> iter 67000, loss: 0.050695
 >> iter 68000, loss: 0.034030
 >> iter 69000, loss: 0.036609
 >> iter 70000, loss: 0.047076
   Number of active neurons: 2
 >> iter 71000, loss: 0.052094
 >> iter 72000, loss: 0.048104
 >> iter 73000, loss: 0.046360
 >> iter 74000, loss: 0.039736
 >> iter 75000, loss: 0.035382
 >> iter 76000, loss: 0.032327
 >> iter 77000, loss: 0.048457
 >> iter 78000, loss: 0.047598
 >> iter 79000, loss: 0.039386
 >> iter 80000, loss: 0.047747
   Number of active neurons: 2
 >> iter 81000, loss: 0.061123
 >> iter 82000, loss: 0.050560
 >> iter 83000, loss: 0.046695
 >> iter 84000, loss: 0.033767
 >> iter 85000, loss: 0.044811
 >> iter 86000, loss: 0.039219
 >> iter 87000, loss: 0.038119
 >> iter 88000, loss: 0.037838
 >> iter 89000, loss: 0.048283
 >> iter 90000, loss: 0.044843
   Number of active neurons: 2
 >> iter 91000, loss: 0.058727
 >> iter 92000, loss: 0.048623
 >> iter 93000, loss: 0.049769
 >> iter 94000, loss: 0.037161
 >> iter 95000, loss: 0.044514
 >> iter 96000, loss: 0.039769
 >> iter 97000, loss: 0.063464
 >> iter 98000, loss: 0.062988
 >> iter 99000, loss: 0.040520
 >> iter 100000, loss: 0.043614
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.879763
 >> iter 2000, loss: 4.579716
 >> iter 3000, loss: 1.759486
 >> iter 4000, loss: 0.714260
 >> iter 5000, loss: 0.310340
 >> iter 6000, loss: 0.158852
 >> iter 7000, loss: 0.087302
 >> iter 8000, loss: 0.075169
 >> iter 9000, loss: 0.062777
 >> iter 10000, loss: 0.057682
   Number of active neurons: 2
 >> iter 11000, loss: 0.052982
 >> iter 12000, loss: 0.064286
 >> iter 13000, loss: 0.046853
 >> iter 14000, loss: 0.043172
 >> iter 15000, loss: 0.038358
 >> iter 16000, loss: 0.049028
 >> iter 17000, loss: 0.044854
 >> iter 18000, loss: 0.035672
 >> iter 19000, loss: 0.044055
 >> iter 20000, loss: 0.038184
   Number of active neurons: 2
 >> iter 21000, loss: 0.048918
 >> iter 22000, loss: 0.044543
 >> iter 23000, loss: 0.034010
 >> iter 24000, loss: 0.039224
 >> iter 25000, loss: 0.042216
 >> iter 26000, loss: 0.050821
 >> iter 27000, loss: 0.045035
 >> iter 28000, loss: 0.034168
 >> iter 29000, loss: 0.049901
 >> iter 30000, loss: 0.033626
   Number of active neurons: 2
 >> iter 31000, loss: 0.053796
 >> iter 32000, loss: 0.048711
 >> iter 33000, loss: 0.046691
 >> iter 34000, loss: 0.064706
 >> iter 35000, loss: 0.047371
 >> iter 36000, loss: 0.043769
 >> iter 37000, loss: 0.033284
 >> iter 38000, loss: 0.044349
 >> iter 39000, loss: 0.053073
 >> iter 40000, loss: 0.036167
   Number of active neurons: 2
 >> iter 41000, loss: 0.040674
 >> iter 42000, loss: 0.056747
 >> iter 43000, loss: 0.037974
 >> iter 44000, loss: 0.058521
 >> iter 45000, loss: 0.060188
 >> iter 46000, loss: 0.047664
 >> iter 47000, loss: 0.035531
 >> iter 48000, loss: 0.033771
 >> iter 49000, loss: 0.052275
 >> iter 50000, loss: 0.048973
   Number of active neurons: 2
 >> iter 51000, loss: 0.040129
 >> iter 52000, loss: 0.041549
 >> iter 53000, loss: 0.036360
 >> iter 54000, loss: 0.052222
 >> iter 55000, loss: 0.045903
 >> iter 56000, loss: 0.040889
 >> iter 57000, loss: 0.045998
 >> iter 58000, loss: 0.066105
 >> iter 59000, loss: 0.056678
 >> iter 60000, loss: 0.036258
   Number of active neurons: 2
 >> iter 61000, loss: 0.031147
 >> iter 62000, loss: 0.038867
 >> iter 63000, loss: 0.030529
 >> iter 64000, loss: 0.032104
 >> iter 65000, loss: 0.053812
 >> iter 66000, loss: 0.048814
 >> iter 67000, loss: 0.045075
 >> iter 68000, loss: 0.039038
 >> iter 69000, loss: 0.038044
 >> iter 70000, loss: 0.057859
   Number of active neurons: 2
 >> iter 71000, loss: 0.064826
 >> iter 72000, loss: 0.058813
 >> iter 73000, loss: 0.054429
 >> iter 74000, loss: 0.040879
 >> iter 75000, loss: 0.072539
 >> iter 76000, loss: 0.074543
 >> iter 77000, loss: 0.045552
 >> iter 78000, loss: 0.061203
 >> iter 79000, loss: 0.059171
 >> iter 80000, loss: 0.048496
   Number of active neurons: 2
 >> iter 81000, loss: 0.044118
 >> iter 82000, loss: 0.042586
 >> iter 83000, loss: 0.034471
 >> iter 84000, loss: 0.031489
 >> iter 85000, loss: 0.049939
 >> iter 86000, loss: 0.039748
 >> iter 87000, loss: 0.051420
 >> iter 88000, loss: 0.031804
 >> iter 89000, loss: 0.053172
 >> iter 90000, loss: 0.045496
   Number of active neurons: 2
 >> iter 91000, loss: 0.044129
 >> iter 92000, loss: 0.038032
 >> iter 93000, loss: 0.030837
 >> iter 94000, loss: 0.036266
 >> iter 95000, loss: 0.032261
 >> iter 96000, loss: 0.027901
 >> iter 97000, loss: 0.049481
 >> iter 98000, loss: 0.046663
 >> iter 99000, loss: 0.053609
 >> iter 100000, loss: 0.054498
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 11.946790
 >> iter 2000, loss: 5.690297
 >> iter 3000, loss: 3.450187
 >> iter 4000, loss: 2.530169
 >> iter 5000, loss: 2.254930
 >> iter 6000, loss: 2.065706
 >> iter 7000, loss: 2.077492
 >> iter 8000, loss: 2.000345
 >> iter 9000, loss: 2.035637
 >> iter 10000, loss: 1.985600
   Number of active neurons: 2
 >> iter 11000, loss: 2.031842
 >> iter 12000, loss: 1.959641
 >> iter 13000, loss: 2.029333
 >> iter 14000, loss: 1.955558
 >> iter 15000, loss: 2.022153
 >> iter 16000, loss: 1.949440
 >> iter 17000, loss: 2.018584
 >> iter 18000, loss: 1.941311
 >> iter 19000, loss: 2.021001
 >> iter 20000, loss: 1.949202
   Number of active neurons: 2
 >> iter 21000, loss: 2.002454
 >> iter 22000, loss: 1.936696
 >> iter 23000, loss: 2.000709
 >> iter 24000, loss: 1.943519
 >> iter 25000, loss: 2.001719
 >> iter 26000, loss: 1.941431
 >> iter 27000, loss: 1.993433
 >> iter 28000, loss: 1.924692
 >> iter 29000, loss: 1.989711
 >> iter 30000, loss: 1.936386
   Number of active neurons: 2
 >> iter 31000, loss: 1.993508
 >> iter 32000, loss: 1.923955
 >> iter 33000, loss: 1.966914
 >> iter 34000, loss: 1.923950
 >> iter 35000, loss: 1.982482
 >> iter 36000, loss: 1.923845
 >> iter 37000, loss: 1.983344
 >> iter 38000, loss: 1.921758
 >> iter 39000, loss: 1.973060
 >> iter 40000, loss: 1.924215
   Number of active neurons: 2
 >> iter 41000, loss: 1.995705
 >> iter 42000, loss: 1.938489
 >> iter 43000, loss: 1.995164
 >> iter 44000, loss: 1.950913
 >> iter 45000, loss: 1.994724
 >> iter 46000, loss: 1.923284
 >> iter 47000, loss: 1.986804
 >> iter 48000, loss: 1.926171
 >> iter 49000, loss: 1.971363
 >> iter 50000, loss: 1.930315
   Number of active neurons: 2
 >> iter 51000, loss: 1.974844
 >> iter 52000, loss: 1.930403
 >> iter 53000, loss: 1.975792
 >> iter 54000, loss: 1.933118
 >> iter 55000, loss: 1.984489
 >> iter 56000, loss: 1.938584
 >> iter 57000, loss: 1.965950
 >> iter 58000, loss: 1.915363
 >> iter 59000, loss: 1.977708
 >> iter 60000, loss: 1.935790
   Number of active neurons: 2
 >> iter 61000, loss: 1.993178
 >> iter 62000, loss: 1.937044
 >> iter 63000, loss: 1.976554
 >> iter 64000, loss: 1.921098
 >> iter 65000, loss: 1.987769
 >> iter 66000, loss: 1.938988
 >> iter 67000, loss: 1.964085
 >> iter 68000, loss: 1.939913
 >> iter 69000, loss: 1.964558
 >> iter 70000, loss: 1.912529
   Number of active neurons: 2
 >> iter 71000, loss: 1.954644
 >> iter 72000, loss: 1.937734
 >> iter 73000, loss: 1.960845
 >> iter 74000, loss: 1.926372
 >> iter 75000, loss: 1.964360
 >> iter 76000, loss: 1.924665
 >> iter 77000, loss: 1.961400
 >> iter 78000, loss: 1.915016
 >> iter 79000, loss: 1.966882
 >> iter 80000, loss: 1.940553
   Number of active neurons: 2
 >> iter 81000, loss: 1.974240
 >> iter 82000, loss: 1.922604
 >> iter 83000, loss: 1.978679
 >> iter 84000, loss: 1.933414
 >> iter 85000, loss: 1.954554
 >> iter 86000, loss: 1.920470
 >> iter 87000, loss: 1.956773
 >> iter 88000, loss: 1.911421
 >> iter 89000, loss: 1.956766
 >> iter 90000, loss: 1.900757
   Number of active neurons: 2
 >> iter 91000, loss: 1.941324
 >> iter 92000, loss: 1.918258
 >> iter 93000, loss: 1.953969
 >> iter 94000, loss: 1.918201
 >> iter 95000, loss: 1.944203
 >> iter 96000, loss: 1.906887
 >> iter 97000, loss: 1.945461
 >> iter 98000, loss: 1.903044
 >> iter 99000, loss: 1.935282
 >> iter 100000, loss: 1.902151
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.764899
 >> iter 2000, loss: 4.519002
 >> iter 3000, loss: 1.735942
 >> iter 4000, loss: 0.682264
 >> iter 5000, loss: 0.307627
 >> iter 6000, loss: 0.145936
 >> iter 7000, loss: 0.077032
 >> iter 8000, loss: 0.064722
 >> iter 9000, loss: 0.061548
 >> iter 10000, loss: 0.058213
   Number of active neurons: 2
 >> iter 11000, loss: 0.072859
 >> iter 12000, loss: 0.083687
 >> iter 13000, loss: 0.055543
 >> iter 14000, loss: 0.054786
 >> iter 15000, loss: 0.046396
 >> iter 16000, loss: 0.052171
 >> iter 17000, loss: 0.060915
 >> iter 18000, loss: 0.063621
 >> iter 19000, loss: 0.043450
 >> iter 20000, loss: 0.035984
   Number of active neurons: 2
 >> iter 21000, loss: 0.053450
 >> iter 22000, loss: 0.034590
 >> iter 23000, loss: 0.061881
 >> iter 24000, loss: 0.049535
 >> iter 25000, loss: 0.049875
 >> iter 26000, loss: 0.037912
 >> iter 27000, loss: 0.038497
 >> iter 28000, loss: 0.057245
 >> iter 29000, loss: 0.058028
 >> iter 30000, loss: 0.054415
   Number of active neurons: 2
 >> iter 31000, loss: 0.052785
 >> iter 32000, loss: 0.062926
 >> iter 33000, loss: 0.045226
 >> iter 34000, loss: 0.036371
 >> iter 35000, loss: 0.043696
 >> iter 36000, loss: 0.058318
 >> iter 37000, loss: 0.037887
 >> iter 38000, loss: 0.051104
 >> iter 39000, loss: 0.053983
 >> iter 40000, loss: 0.043166
   Number of active neurons: 2
 >> iter 41000, loss: 0.034270
 >> iter 42000, loss: 0.052621
 >> iter 43000, loss: 0.038871
 >> iter 44000, loss: 0.047884
 >> iter 45000, loss: 0.055162
 >> iter 46000, loss: 0.046915
 >> iter 47000, loss: 0.055358
 >> iter 48000, loss: 0.035684
 >> iter 49000, loss: 0.045186
 >> iter 50000, loss: 0.048866
   Number of active neurons: 2
 >> iter 51000, loss: 0.033574
 >> iter 52000, loss: 0.062691
 >> iter 53000, loss: 0.045238
 >> iter 54000, loss: 0.044942
 >> iter 55000, loss: 0.044129
 >> iter 56000, loss: 0.039215
 >> iter 57000, loss: 0.037899
 >> iter 58000, loss: 0.034450
 >> iter 59000, loss: 0.040738
 >> iter 60000, loss: 0.037519
   Number of active neurons: 2
 >> iter 61000, loss: 0.050077
 >> iter 62000, loss: 0.041798
 >> iter 63000, loss: 0.049558
 >> iter 64000, loss: 0.036726
 >> iter 65000, loss: 0.029550
 >> iter 66000, loss: 0.043525
 >> iter 67000, loss: 0.047316
 >> iter 68000, loss: 0.040602
 >> iter 69000, loss: 0.041243
 >> iter 70000, loss: 0.035219
   Number of active neurons: 2
 >> iter 71000, loss: 0.062200
 >> iter 72000, loss: 0.065464
 >> iter 73000, loss: 0.050236
 >> iter 74000, loss: 0.042446
 >> iter 75000, loss: 0.036961
 >> iter 76000, loss: 0.046825
 >> iter 77000, loss: 0.056278
 >> iter 78000, loss: 0.054630
 >> iter 79000, loss: 0.042894
 >> iter 80000, loss: 0.041732
   Number of active neurons: 2
 >> iter 81000, loss: 0.035681
 >> iter 82000, loss: 0.036186
 >> iter 83000, loss: 0.035990
 >> iter 84000, loss: 0.034448
 >> iter 85000, loss: 0.033562
 >> iter 86000, loss: 0.038498
 >> iter 87000, loss: 0.041189
 >> iter 88000, loss: 0.056552
 >> iter 89000, loss: 0.043180
 >> iter 90000, loss: 0.041752
   Number of active neurons: 2
 >> iter 91000, loss: 0.030155
 >> iter 92000, loss: 0.037577
 >> iter 93000, loss: 0.061669
 >> iter 94000, loss: 0.042961
 >> iter 95000, loss: 0.042215
 >> iter 96000, loss: 0.030769
 >> iter 97000, loss: 0.042653
 >> iter 98000, loss: 0.052700
 >> iter 99000, loss: 0.038192
 >> iter 100000, loss: 0.042491
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 12.614080
 >> iter 2000, loss: 6.442677
 >> iter 3000, loss: 4.338672
 >> iter 4000, loss: 3.387602
 >> iter 5000, loss: 3.197863
 >> iter 6000, loss: 2.964862
 >> iter 7000, loss: 3.052362
 >> iter 8000, loss: 2.899196
 >> iter 9000, loss: 3.027846
 >> iter 10000, loss: 2.898388
   Number of active neurons: 1
 >> iter 11000, loss: 3.017767
 >> iter 12000, loss: 2.894205
 >> iter 13000, loss: 3.023012
 >> iter 14000, loss: 2.905044
 >> iter 15000, loss: 3.030205
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 2.893914
 >> iter 17000, loss: 3.023162
 >> iter 18000, loss: 2.898016
 >> iter 19000, loss: 3.007566
 >> iter 20000, loss: 2.895622
   Number of active neurons: 1
 >> iter 21000, loss: 3.014607
 >> iter 22000, loss: 2.887079
 >> iter 23000, loss: 3.014213
 >> iter 24000, loss: 2.887196
 >> iter 25000, loss: 3.014469
   Number of active neurons: 1
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 26000, loss: 2.889815
 >> iter 27000, loss: 3.010165
 >> iter 28000, loss: 2.896431
 >> iter 29000, loss: 3.021980
 >> iter 30000, loss: 2.891975
   Number of active neurons: 1
 >> iter 31000, loss: 3.017808
 >> iter 32000, loss: 2.885464
 >> iter 33000, loss: 3.007317
 >> iter 34000, loss: 2.889877
 >> iter 35000, loss: 3.013056
   Number of active neurons: 1
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 36000, loss: 2.891201
 >> iter 37000, loss: 3.009994
 >> iter 38000, loss: 2.898395
 >> iter 39000, loss: 3.018433
 >> iter 40000, loss: 2.916503
   Number of active neurons: 1
 >> iter 41000, loss: 3.017672
 >> iter 42000, loss: 2.896097
 >> iter 43000, loss: 3.017594
 >> iter 44000, loss: 2.896593
 >> iter 45000, loss: 2.993515
   Number of active neurons: 1
   SHOCK
   Setting new limit to 287500.0 iters...
 >> iter 46000, loss: 2.907185
 >> iter 47000, loss: 3.015849
 >> iter 48000, loss: 2.899635
 >> iter 49000, loss: 3.016119
 >> iter 50000, loss: 2.905462
   Number of active neurons: 1
 >> iter 51000, loss: 3.010746
 >> iter 52000, loss: 2.913861
 >> iter 53000, loss: 3.024627
 >> iter 54000, loss: 2.922522
 >> iter 55000, loss: 3.022675
   Number of active neurons: 1
   SHOCK
   Setting new limit to 293750.0 iters...
 >> iter 56000, loss: 2.921556
 >> iter 57000, loss: 3.023569
 >> iter 58000, loss: 2.912480
 >> iter 59000, loss: 3.012854
 >> iter 60000, loss: 2.917160
   Number of active neurons: 1
 >> iter 61000, loss: 3.025094
 >> iter 62000, loss: 2.905780
 >> iter 63000, loss: 3.019106
 >> iter 64000, loss: 2.909973
 >> iter 65000, loss: 3.030058
   Number of active neurons: 1
   SHOCK
   Setting new limit to 296875.0 iters...
 >> iter 66000, loss: 2.917904
 >> iter 67000, loss: 3.007884
 >> iter 68000, loss: 2.919468
 >> iter 69000, loss: 3.019734
 >> iter 70000, loss: 2.926707
   Number of active neurons: 1
 >> iter 71000, loss: 3.021424
 >> iter 72000, loss: 2.923196
 >> iter 73000, loss: 3.020225
 >> iter 74000, loss: 2.925240
 >> iter 75000, loss: 3.013579
   Number of active neurons: 1
   SHOCK
   Setting new limit to 298437.5 iters...
 >> iter 76000, loss: 2.926682
 >> iter 77000, loss: 3.021557
 >> iter 78000, loss: 2.937475
 >> iter 79000, loss: 3.026623
 >> iter 80000, loss: 2.931611
   Number of active neurons: 1
 >> iter 81000, loss: 3.025809
 >> iter 82000, loss: 2.920136
 >> iter 83000, loss: 3.016824
 >> iter 84000, loss: 2.917193
 >> iter 85000, loss: 3.015328
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299218.75 iters...
 >> iter 86000, loss: 2.915477
 >> iter 87000, loss: 3.009749
 >> iter 88000, loss: 2.926879
 >> iter 89000, loss: 3.004889
 >> iter 90000, loss: 2.908520
   Number of active neurons: 1
 >> iter 91000, loss: 3.002638
 >> iter 92000, loss: 2.910740
 >> iter 93000, loss: 3.001515
 >> iter 94000, loss: 2.922626
 >> iter 95000, loss: 3.011065
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299609.375 iters...
 >> iter 96000, loss: 2.922285
 >> iter 97000, loss: 3.011744
 >> iter 98000, loss: 2.908107
 >> iter 99000, loss: 3.008762
 >> iter 100000, loss: 2.918747
   Number of active neurons: 1
 >> iter 101000, loss: 3.009727
 >> iter 102000, loss: 2.919506
 >> iter 103000, loss: 3.016111
 >> iter 104000, loss: 2.925351
 >> iter 105000, loss: 3.015072
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299804.6875 iters...
 >> iter 106000, loss: 2.914799
 >> iter 107000, loss: 3.002380
 >> iter 108000, loss: 2.914852
 >> iter 109000, loss: 2.999952
 >> iter 110000, loss: 2.912354
   Number of active neurons: 1
 >> iter 111000, loss: 3.014574
 >> iter 112000, loss: 2.919674
 >> iter 113000, loss: 3.008800
 >> iter 114000, loss: 2.903040
 >> iter 115000, loss: 3.004451
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299902.34375 iters...
 >> iter 116000, loss: 2.908090
 >> iter 117000, loss: 3.026210
 >> iter 118000, loss: 2.913693
 >> iter 119000, loss: 3.035867
 >> iter 120000, loss: 2.912192
   Number of active neurons: 1
 >> iter 121000, loss: 3.007417
 >> iter 122000, loss: 2.899457
 >> iter 123000, loss: 3.007180
 >> iter 124000, loss: 2.894943
 >> iter 125000, loss: 3.005367
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299951.171875 iters...
 >> iter 126000, loss: 2.900637
 >> iter 127000, loss: 3.001778
 >> iter 128000, loss: 2.892193
 >> iter 129000, loss: 3.001554
 >> iter 130000, loss: 2.899696
   Number of active neurons: 1
 >> iter 131000, loss: 3.005908
 >> iter 132000, loss: 2.901526
 >> iter 133000, loss: 3.004640
 >> iter 134000, loss: 2.901655
 >> iter 135000, loss: 2.999400
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299975.585938 iters...
 >> iter 136000, loss: 2.916908
 >> iter 137000, loss: 3.010609
 >> iter 138000, loss: 2.914235
 >> iter 139000, loss: 3.011163
 >> iter 140000, loss: 2.918129
   Number of active neurons: 1
 >> iter 141000, loss: 2.991103
 >> iter 142000, loss: 2.909245
 >> iter 143000, loss: 2.997920
 >> iter 144000, loss: 2.915646
 >> iter 145000, loss: 2.997098
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299987.792969 iters...
 >> iter 146000, loss: 2.911439
 >> iter 147000, loss: 3.012824
 >> iter 148000, loss: 2.905813
 >> iter 149000, loss: 3.011152
 >> iter 150000, loss: 2.914866
   Number of active neurons: 1
 >> iter 151000, loss: 3.031541
 >> iter 152000, loss: 2.915650
 >> iter 153000, loss: 3.016097
 >> iter 154000, loss: 2.906902
 >> iter 155000, loss: 3.035471
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299993.896484 iters...
 >> iter 156000, loss: 2.910022
 >> iter 157000, loss: 3.006948
 >> iter 158000, loss: 2.899948
 >> iter 159000, loss: 3.027810
 >> iter 160000, loss: 2.898128
   Number of active neurons: 1
 >> iter 161000, loss: 3.033203
 >> iter 162000, loss: 2.917378
 >> iter 163000, loss: 3.025037
 >> iter 164000, loss: 2.886845
 >> iter 165000, loss: 3.041909
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299996.948242 iters...
 >> iter 166000, loss: 2.908650
 >> iter 167000, loss: 3.042897
 >> iter 168000, loss: 2.910274
 >> iter 169000, loss: 3.043488
 >> iter 170000, loss: 2.916357
   Number of active neurons: 1
 >> iter 171000, loss: 3.044740
 >> iter 172000, loss: 2.913216
 >> iter 173000, loss: 3.027311
 >> iter 174000, loss: 2.909608
 >> iter 175000, loss: 3.024679
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299998.474121 iters...
 >> iter 176000, loss: 2.889720
 >> iter 177000, loss: 3.009482
 >> iter 178000, loss: 2.918929
 >> iter 179000, loss: 3.031842
 >> iter 180000, loss: 2.914186
   Number of active neurons: 1
 >> iter 181000, loss: 3.019656
 >> iter 182000, loss: 2.922412
 >> iter 183000, loss: 3.016940
 >> iter 184000, loss: 2.927446
 >> iter 185000, loss: 3.019031
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299999.237061 iters...
 >> iter 186000, loss: 2.932392
 >> iter 187000, loss: 3.012113
 >> iter 188000, loss: 2.921217
 >> iter 189000, loss: 3.007572
 >> iter 190000, loss: 2.917711
   Number of active neurons: 1
 >> iter 191000, loss: 3.023273
 >> iter 192000, loss: 2.931993
 >> iter 193000, loss: 3.043531
 >> iter 194000, loss: 2.940685
 >> iter 195000, loss: 3.026700
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299999.61853 iters...
 >> iter 196000, loss: 2.926815
 >> iter 197000, loss: 3.019084
 >> iter 198000, loss: 2.938664
 >> iter 199000, loss: 3.029077
 >> iter 200000, loss: 2.930496
   Number of active neurons: 1
 >> iter 201000, loss: 3.036198
 >> iter 202000, loss: 2.924312
 >> iter 203000, loss: 3.032879
 >> iter 204000, loss: 2.911019
 >> iter 205000, loss: 3.028273
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299999.809265 iters...
 >> iter 206000, loss: 2.930417
 >> iter 207000, loss: 3.023144
 >> iter 208000, loss: 2.921294
 >> iter 209000, loss: 3.039220
 >> iter 210000, loss: 2.931675
   Number of active neurons: 1
 >> iter 211000, loss: 3.037106
 >> iter 212000, loss: 2.928228
 >> iter 213000, loss: 3.040678
 >> iter 214000, loss: 2.931494
 >> iter 215000, loss: 3.036894
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299999.904633 iters...
 >> iter 216000, loss: 2.926916
 >> iter 217000, loss: 3.044793
 >> iter 218000, loss: 2.944378
 >> iter 219000, loss: 3.035056
 >> iter 220000, loss: 2.913410
   Number of active neurons: 1
 >> iter 221000, loss: 3.020231
 >> iter 222000, loss: 2.917022
 >> iter 223000, loss: 3.034404
 >> iter 224000, loss: 2.931687
 >> iter 225000, loss: 3.033369
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299999.952316 iters...
 >> iter 226000, loss: 2.905686
 >> iter 227000, loss: 3.036707
 >> iter 228000, loss: 2.910696
 >> iter 229000, loss: 3.035513
 >> iter 230000, loss: 2.920997
   Number of active neurons: 1
 >> iter 231000, loss: 3.025365
 >> iter 232000, loss: 2.911945
 >> iter 233000, loss: 3.002599
 >> iter 234000, loss: 2.894384
 >> iter 235000, loss: 3.015740
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299999.976158 iters...
 >> iter 236000, loss: 2.914434
 >> iter 237000, loss: 3.032964
 >> iter 238000, loss: 2.911540
 >> iter 239000, loss: 3.032048
 >> iter 240000, loss: 2.914266
   Number of active neurons: 1
 >> iter 241000, loss: 3.017963
 >> iter 242000, loss: 2.909240
 >> iter 243000, loss: 3.026695
 >> iter 244000, loss: 2.895793
 >> iter 245000, loss: 3.031512
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299999.988079 iters...
 >> iter 246000, loss: 2.899063
 >> iter 247000, loss: 3.036312
 >> iter 248000, loss: 2.909193
 >> iter 249000, loss: 3.026611
 >> iter 250000, loss: 2.900173
   Number of active neurons: 1
 >> iter 251000, loss: 3.013914
 >> iter 252000, loss: 2.904183
 >> iter 253000, loss: 3.019412
 >> iter 254000, loss: 2.904635
 >> iter 255000, loss: 3.028485
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299999.99404 iters...
 >> iter 256000, loss: 2.898891
 >> iter 257000, loss: 3.011255
 >> iter 258000, loss: 2.904890
 >> iter 259000, loss: 3.017203
 >> iter 260000, loss: 2.906763
   Number of active neurons: 1
 >> iter 261000, loss: 3.013071
 >> iter 262000, loss: 2.901436
 >> iter 263000, loss: 3.017935
 >> iter 264000, loss: 2.908589
 >> iter 265000, loss: 3.015141
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299999.99702 iters...
 >> iter 266000, loss: 2.901220
 >> iter 267000, loss: 3.009565
 >> iter 268000, loss: 2.895275
 >> iter 269000, loss: 3.018453
 >> iter 270000, loss: 2.908587
   Number of active neurons: 1
 >> iter 271000, loss: 3.015381
 >> iter 272000, loss: 2.909075
 >> iter 273000, loss: 3.024718
 >> iter 274000, loss: 2.912198
 >> iter 275000, loss: 3.023109
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299999.99851 iters...
 >> iter 276000, loss: 2.899883
 >> iter 277000, loss: 3.025799
 >> iter 278000, loss: 2.902052
 >> iter 279000, loss: 3.005004
 >> iter 280000, loss: 2.896547
   Number of active neurons: 1
 >> iter 281000, loss: 3.025349
 >> iter 282000, loss: 2.903556
 >> iter 283000, loss: 3.012901
 >> iter 284000, loss: 2.907092
 >> iter 285000, loss: 3.015419
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299999.999255 iters...
 >> iter 286000, loss: 2.913397
 >> iter 287000, loss: 3.027156
 >> iter 288000, loss: 2.909713
 >> iter 289000, loss: 3.039787
 >> iter 290000, loss: 2.898720
   Number of active neurons: 1
 >> iter 291000, loss: 3.026734
 >> iter 292000, loss: 2.915209
 >> iter 293000, loss: 3.033061
 >> iter 294000, loss: 2.901460
 >> iter 295000, loss: 3.058901
   Number of active neurons: 1
   SHOCK
   Setting new limit to 299999.999627 iters...
 >> iter 296000, loss: 2.915098
 >> iter 297000, loss: 3.054328
 >> iter 298000, loss: 2.913499
 >> iter 299000, loss: 3.042566
 >> iter 300000, loss: 2.896834
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.859298
 >> iter 2000, loss: 4.658489
 >> iter 3000, loss: 1.779515
 >> iter 4000, loss: 0.712400
 >> iter 5000, loss: 0.320878
 >> iter 6000, loss: 0.153741
 >> iter 7000, loss: 0.080828
 >> iter 8000, loss: 0.055592
 >> iter 9000, loss: 0.052610
 >> iter 10000, loss: 0.052886
   Number of active neurons: 2
 >> iter 11000, loss: 0.040282
 >> iter 12000, loss: 0.053847
 >> iter 13000, loss: 0.073252
 >> iter 14000, loss: 0.059151
 >> iter 15000, loss: 0.041298
 >> iter 16000, loss: 0.039455
 >> iter 17000, loss: 0.048960
 >> iter 18000, loss: 0.040121
 >> iter 19000, loss: 0.052894
 >> iter 20000, loss: 0.045231
   Number of active neurons: 2
 >> iter 21000, loss: 0.045610
 >> iter 22000, loss: 0.051950
 >> iter 23000, loss: 0.048331
 >> iter 24000, loss: 0.057810
 >> iter 25000, loss: 0.076507
 >> iter 26000, loss: 0.051517
 >> iter 27000, loss: 0.043316
 >> iter 28000, loss: 0.050806
 >> iter 29000, loss: 0.038802
 >> iter 30000, loss: 0.055366
   Number of active neurons: 2
 >> iter 31000, loss: 0.042565
 >> iter 32000, loss: 0.044964
 >> iter 33000, loss: 0.058411
 >> iter 34000, loss: 0.040557
 >> iter 35000, loss: 0.042683
 >> iter 36000, loss: 0.053470
 >> iter 37000, loss: 0.059810
 >> iter 38000, loss: 0.041944
 >> iter 39000, loss: 0.040896
 >> iter 40000, loss: 0.058578
   Number of active neurons: 2
 >> iter 41000, loss: 0.042288
 >> iter 42000, loss: 0.057389
 >> iter 43000, loss: 0.047299
 >> iter 44000, loss: 0.040134
 >> iter 45000, loss: 0.028118
 >> iter 46000, loss: 0.045471
 >> iter 47000, loss: 0.065461
 >> iter 48000, loss: 0.061565
 >> iter 49000, loss: 0.045180
 >> iter 50000, loss: 0.047033
   Number of active neurons: 2
 >> iter 51000, loss: 0.045397
 >> iter 52000, loss: 0.052195
 >> iter 53000, loss: 0.043059
 >> iter 54000, loss: 0.035831
 >> iter 55000, loss: 0.045959
 >> iter 56000, loss: 0.034594
 >> iter 57000, loss: 0.057012
 >> iter 58000, loss: 0.047007
 >> iter 59000, loss: 0.054358
 >> iter 60000, loss: 0.052869
   Number of active neurons: 2
 >> iter 61000, loss: 0.046696
 >> iter 62000, loss: 0.036835
 >> iter 63000, loss: 0.041224
 >> iter 64000, loss: 0.045702
 >> iter 65000, loss: 0.038787
 >> iter 66000, loss: 0.052826
 >> iter 67000, loss: 0.042538
 >> iter 68000, loss: 0.038636
 >> iter 69000, loss: 0.047390
 >> iter 70000, loss: 0.051821
   Number of active neurons: 2
 >> iter 71000, loss: 0.061298
 >> iter 72000, loss: 0.044537
 >> iter 73000, loss: 0.043304
 >> iter 74000, loss: 0.039033
 >> iter 75000, loss: 0.041823
 >> iter 76000, loss: 0.036403
 >> iter 77000, loss: 0.042963
 >> iter 78000, loss: 0.053311
 >> iter 79000, loss: 0.056214
 >> iter 80000, loss: 0.045849
   Number of active neurons: 2
 >> iter 81000, loss: 0.060706
 >> iter 82000, loss: 0.043348
 >> iter 83000, loss: 0.048054
 >> iter 84000, loss: 0.060398
 >> iter 85000, loss: 0.040671
 >> iter 86000, loss: 0.037100
 >> iter 87000, loss: 0.033593
 >> iter 88000, loss: 0.047184
 >> iter 89000, loss: 0.044196
 >> iter 90000, loss: 0.046312
   Number of active neurons: 2
 >> iter 91000, loss: 0.048664
 >> iter 92000, loss: 0.055215
 >> iter 93000, loss: 0.046638
 >> iter 94000, loss: 0.040692
 >> iter 95000, loss: 0.031747
 >> iter 96000, loss: 0.043034
 >> iter 97000, loss: 0.038858
 >> iter 98000, loss: 0.040651
 >> iter 99000, loss: 0.047008
 >> iter 100000, loss: 0.048581
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.945912
 >> iter 2000, loss: 5.677437
 >> iter 3000, loss: 3.437242
 >> iter 4000, loss: 2.526792
 >> iter 5000, loss: 2.268061
 >> iter 6000, loss: 2.068494
 >> iter 7000, loss: 2.084534
 >> iter 8000, loss: 1.985554
 >> iter 9000, loss: 2.046787
 >> iter 10000, loss: 1.986297
   Number of active neurons: 2
 >> iter 11000, loss: 2.040232
 >> iter 12000, loss: 1.976060
 >> iter 13000, loss: 2.026266
 >> iter 14000, loss: 1.956978
 >> iter 15000, loss: 2.013995
 >> iter 16000, loss: 1.962774
 >> iter 17000, loss: 2.022787
 >> iter 18000, loss: 1.960210
 >> iter 19000, loss: 2.018016
 >> iter 20000, loss: 1.938411
   Number of active neurons: 2
 >> iter 21000, loss: 1.992601
 >> iter 22000, loss: 1.948208
 >> iter 23000, loss: 2.004124
 >> iter 24000, loss: 1.940934
 >> iter 25000, loss: 1.984699
 >> iter 26000, loss: 1.930342
 >> iter 27000, loss: 1.998979
 >> iter 28000, loss: 1.939528
 >> iter 29000, loss: 2.005265
 >> iter 30000, loss: 1.933119
   Number of active neurons: 2
 >> iter 31000, loss: 2.009517
 >> iter 32000, loss: 1.944219
 >> iter 33000, loss: 2.000687
 >> iter 34000, loss: 1.936128
 >> iter 35000, loss: 1.995269
 >> iter 36000, loss: 1.933472
 >> iter 37000, loss: 1.990566
 >> iter 38000, loss: 1.927380
 >> iter 39000, loss: 1.976044
 >> iter 40000, loss: 1.925337
   Number of active neurons: 2
 >> iter 41000, loss: 1.960562
 >> iter 42000, loss: 1.924986
 >> iter 43000, loss: 1.987266
 >> iter 44000, loss: 1.930961
 >> iter 45000, loss: 1.972106
 >> iter 46000, loss: 1.919813
 >> iter 47000, loss: 1.970889
 >> iter 48000, loss: 1.919989
 >> iter 49000, loss: 1.980829
 >> iter 50000, loss: 1.913514
   Number of active neurons: 2
 >> iter 51000, loss: 1.959256
 >> iter 52000, loss: 1.924393
 >> iter 53000, loss: 1.961626
 >> iter 54000, loss: 1.910407
 >> iter 55000, loss: 1.965426
 >> iter 56000, loss: 1.922333
 >> iter 57000, loss: 1.962372
 >> iter 58000, loss: 1.923949
 >> iter 59000, loss: 1.963041
 >> iter 60000, loss: 1.921219
   Number of active neurons: 2
 >> iter 61000, loss: 1.988398
 >> iter 62000, loss: 1.922300
 >> iter 63000, loss: 1.969568
 >> iter 64000, loss: 1.914187
 >> iter 65000, loss: 1.963668
 >> iter 66000, loss: 1.917836
 >> iter 67000, loss: 1.973473
 >> iter 68000, loss: 1.938509
 >> iter 69000, loss: 1.986894
 >> iter 70000, loss: 1.942149
   Number of active neurons: 2
 >> iter 71000, loss: 1.975593
 >> iter 72000, loss: 1.940691
 >> iter 73000, loss: 1.980903
 >> iter 74000, loss: 1.934097
 >> iter 75000, loss: 1.977225
 >> iter 76000, loss: 1.931724
 >> iter 77000, loss: 1.987994
 >> iter 78000, loss: 1.914551
 >> iter 79000, loss: 1.947661
 >> iter 80000, loss: 1.918004
   Number of active neurons: 2
 >> iter 81000, loss: 1.951403
 >> iter 82000, loss: 1.914292
 >> iter 83000, loss: 1.980838
 >> iter 84000, loss: 1.922246
 >> iter 85000, loss: 1.949569
 >> iter 86000, loss: 1.902746
 >> iter 87000, loss: 1.956218
 >> iter 88000, loss: 1.921438
 >> iter 89000, loss: 1.963894
 >> iter 90000, loss: 1.929171
   Number of active neurons: 2
 >> iter 91000, loss: 1.965222
 >> iter 92000, loss: 1.901249
 >> iter 93000, loss: 1.946875
 >> iter 94000, loss: 1.900597
 >> iter 95000, loss: 1.949735
 >> iter 96000, loss: 1.904133
 >> iter 97000, loss: 1.951208
 >> iter 98000, loss: 1.917007
 >> iter 99000, loss: 1.961406
 >> iter 100000, loss: 1.906592
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 12.042973
 >> iter 2000, loss: 5.726059
 >> iter 3000, loss: 3.479541
 >> iter 4000, loss: 2.534357
 >> iter 5000, loss: 2.263548
 >> iter 6000, loss: 2.069187
 >> iter 7000, loss: 2.063607
 >> iter 8000, loss: 1.991428
 >> iter 9000, loss: 2.046204
 >> iter 10000, loss: 1.989048
   Number of active neurons: 2
 >> iter 11000, loss: 2.022228
 >> iter 12000, loss: 1.958080
 >> iter 13000, loss: 2.027072
 >> iter 14000, loss: 1.962585
 >> iter 15000, loss: 2.020414
 >> iter 16000, loss: 1.961986
 >> iter 17000, loss: 2.015597
 >> iter 18000, loss: 1.945477
 >> iter 19000, loss: 2.014945
 >> iter 20000, loss: 1.951741
   Number of active neurons: 2
 >> iter 21000, loss: 2.019987
 >> iter 22000, loss: 1.952440
 >> iter 23000, loss: 2.015932
 >> iter 24000, loss: 1.939619
 >> iter 25000, loss: 1.999249
 >> iter 26000, loss: 1.933223
 >> iter 27000, loss: 2.001495
 >> iter 28000, loss: 1.934012
 >> iter 29000, loss: 1.996269
 >> iter 30000, loss: 1.945539
   Number of active neurons: 2
 >> iter 31000, loss: 2.008719
 >> iter 32000, loss: 1.942379
 >> iter 33000, loss: 1.986682
 >> iter 34000, loss: 1.924982
 >> iter 35000, loss: 1.979430
 >> iter 36000, loss: 1.925234
 >> iter 37000, loss: 1.988308
 >> iter 38000, loss: 1.931204
 >> iter 39000, loss: 1.976747
 >> iter 40000, loss: 1.929641
   Number of active neurons: 2
 >> iter 41000, loss: 1.993317
 >> iter 42000, loss: 1.927668
 >> iter 43000, loss: 1.977911
 >> iter 44000, loss: 1.923331
 >> iter 45000, loss: 1.972671
 >> iter 46000, loss: 1.920240
 >> iter 47000, loss: 1.965589
 >> iter 48000, loss: 1.918379
 >> iter 49000, loss: 1.966473
 >> iter 50000, loss: 1.909032
   Number of active neurons: 2
 >> iter 51000, loss: 1.973279
 >> iter 52000, loss: 1.928557
 >> iter 53000, loss: 1.979374
 >> iter 54000, loss: 1.918652
 >> iter 55000, loss: 1.975473
 >> iter 56000, loss: 1.931319
 >> iter 57000, loss: 1.968828
 >> iter 58000, loss: 1.936636
 >> iter 59000, loss: 1.976140
 >> iter 60000, loss: 1.935541
   Number of active neurons: 2
 >> iter 61000, loss: 1.965844
 >> iter 62000, loss: 1.884399
 >> iter 63000, loss: 1.961638
 >> iter 64000, loss: 1.913081
 >> iter 65000, loss: 1.970049
 >> iter 66000, loss: 1.923911
 >> iter 67000, loss: 1.980874
 >> iter 68000, loss: 1.922707
 >> iter 69000, loss: 1.953999
 >> iter 70000, loss: 1.919522
   Number of active neurons: 2
 >> iter 71000, loss: 1.957777
 >> iter 72000, loss: 1.937910
 >> iter 73000, loss: 1.992540
 >> iter 74000, loss: 1.926059
 >> iter 75000, loss: 1.973972
 >> iter 76000, loss: 1.926640
 >> iter 77000, loss: 1.966182
 >> iter 78000, loss: 1.921372
 >> iter 79000, loss: 1.960154
 >> iter 80000, loss: 1.912070
   Number of active neurons: 2
 >> iter 81000, loss: 1.959864
 >> iter 82000, loss: 1.909225
 >> iter 83000, loss: 1.961869
 >> iter 84000, loss: 1.893311
 >> iter 85000, loss: 1.966988
 >> iter 86000, loss: 1.919940
 >> iter 87000, loss: 1.949739
 >> iter 88000, loss: 1.927791
 >> iter 89000, loss: 1.964716
 >> iter 90000, loss: 1.907387
   Number of active neurons: 2
 >> iter 91000, loss: 1.953788
 >> iter 92000, loss: 1.915023
 >> iter 93000, loss: 1.950426
 >> iter 94000, loss: 1.911549
 >> iter 95000, loss: 1.966803
 >> iter 96000, loss: 1.922032
 >> iter 97000, loss: 1.958570
 >> iter 98000, loss: 1.908706
 >> iter 99000, loss: 1.943349
 >> iter 100000, loss: 1.889445
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 12.013106
 >> iter 2000, loss: 5.711350
 >> iter 3000, loss: 3.456359
 >> iter 4000, loss: 2.535453
 >> iter 5000, loss: 2.265471
 >> iter 6000, loss: 2.077644
 >> iter 7000, loss: 2.096965
 >> iter 8000, loss: 1.999941
 >> iter 9000, loss: 2.041992
 >> iter 10000, loss: 1.963615
   Number of active neurons: 2
 >> iter 11000, loss: 2.027513
 >> iter 12000, loss: 1.959163
 >> iter 13000, loss: 2.034806
 >> iter 14000, loss: 1.977093
 >> iter 15000, loss: 2.010463
 >> iter 16000, loss: 1.956812
 >> iter 17000, loss: 2.019660
 >> iter 18000, loss: 1.939313
 >> iter 19000, loss: 2.020451
 >> iter 20000, loss: 1.945505
   Number of active neurons: 2
 >> iter 21000, loss: 2.009435
 >> iter 22000, loss: 1.951561
 >> iter 23000, loss: 1.994533
 >> iter 24000, loss: 1.937796
 >> iter 25000, loss: 1.984626
 >> iter 26000, loss: 1.921332
 >> iter 27000, loss: 1.985615
 >> iter 28000, loss: 1.937160
 >> iter 29000, loss: 1.990880
 >> iter 30000, loss: 1.929091
   Number of active neurons: 2
 >> iter 31000, loss: 2.002534
 >> iter 32000, loss: 1.939395
 >> iter 33000, loss: 1.992062
 >> iter 34000, loss: 1.935854
 >> iter 35000, loss: 1.994162
 >> iter 36000, loss: 1.929158
 >> iter 37000, loss: 1.986993
 >> iter 38000, loss: 1.927088
 >> iter 39000, loss: 1.991067
 >> iter 40000, loss: 1.920587
   Number of active neurons: 2
 >> iter 41000, loss: 1.985869
 >> iter 42000, loss: 1.941102
 >> iter 43000, loss: 1.986351
 >> iter 44000, loss: 1.937979
 >> iter 45000, loss: 1.988101
 >> iter 46000, loss: 1.919682
 >> iter 47000, loss: 1.987364
 >> iter 48000, loss: 1.918590
 >> iter 49000, loss: 1.991388
 >> iter 50000, loss: 1.933205
   Number of active neurons: 2
 >> iter 51000, loss: 1.978787
 >> iter 52000, loss: 1.913608
 >> iter 53000, loss: 1.967398
 >> iter 54000, loss: 1.927649
 >> iter 55000, loss: 1.964783
 >> iter 56000, loss: 1.925336
 >> iter 57000, loss: 1.984588
 >> iter 58000, loss: 1.917723
 >> iter 59000, loss: 1.961635
 >> iter 60000, loss: 1.916296
   Number of active neurons: 2
 >> iter 61000, loss: 1.967098
 >> iter 62000, loss: 1.913091
 >> iter 63000, loss: 1.970587
 >> iter 64000, loss: 1.919699
 >> iter 65000, loss: 1.982254
 >> iter 66000, loss: 1.922705
 >> iter 67000, loss: 1.959387
 >> iter 68000, loss: 1.921816
 >> iter 69000, loss: 1.961980
 >> iter 70000, loss: 1.916343
   Number of active neurons: 2
 >> iter 71000, loss: 1.973611
 >> iter 72000, loss: 1.911875
 >> iter 73000, loss: 1.977201
 >> iter 74000, loss: 1.927889
 >> iter 75000, loss: 1.945327
 >> iter 76000, loss: 1.910354
 >> iter 77000, loss: 1.964778
 >> iter 78000, loss: 1.928411
 >> iter 79000, loss: 1.969370
 >> iter 80000, loss: 1.924558
   Number of active neurons: 2
 >> iter 81000, loss: 1.985833
 >> iter 82000, loss: 1.920995
 >> iter 83000, loss: 1.969982
 >> iter 84000, loss: 1.932522
 >> iter 85000, loss: 1.972670
 >> iter 86000, loss: 1.916226
 >> iter 87000, loss: 1.954553
 >> iter 88000, loss: 1.921235
 >> iter 89000, loss: 1.967351
 >> iter 90000, loss: 1.912347
   Number of active neurons: 2
 >> iter 91000, loss: 1.963102
 >> iter 92000, loss: 1.934993
 >> iter 93000, loss: 1.966994
 >> iter 94000, loss: 1.922673
 >> iter 95000, loss: 1.957219
 >> iter 96000, loss: 1.915054
 >> iter 97000, loss: 1.966660
 >> iter 98000, loss: 1.918273
 >> iter 99000, loss: 1.954469
 >> iter 100000, loss: 1.908817
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.576106
 >> iter 2000, loss: 4.410682
 >> iter 3000, loss: 1.687255
 >> iter 4000, loss: 0.686773
 >> iter 5000, loss: 0.331321
 >> iter 6000, loss: 0.148220
 >> iter 7000, loss: 0.087743
 >> iter 8000, loss: 0.064362
 >> iter 9000, loss: 0.044397
 >> iter 10000, loss: 0.066642
   Number of active neurons: 2
 >> iter 11000, loss: 0.073150
 >> iter 12000, loss: 0.079762
 >> iter 13000, loss: 0.099680
 >> iter 14000, loss: 0.059415
 >> iter 15000, loss: 0.052504
 >> iter 16000, loss: 0.062747
 >> iter 17000, loss: 0.043490
 >> iter 18000, loss: 0.050871
 >> iter 19000, loss: 0.054134
 >> iter 20000, loss: 0.056224
   Number of active neurons: 2
 >> iter 21000, loss: 0.059565
 >> iter 22000, loss: 0.046398
 >> iter 23000, loss: 0.043619
 >> iter 24000, loss: 0.054153
 >> iter 25000, loss: 0.042297
 >> iter 26000, loss: 0.047335
 >> iter 27000, loss: 0.056525
 >> iter 28000, loss: 0.042109
 >> iter 29000, loss: 0.050401
 >> iter 30000, loss: 0.041307
   Number of active neurons: 2
 >> iter 31000, loss: 0.035251
 >> iter 32000, loss: 0.035894
 >> iter 33000, loss: 0.039150
 >> iter 34000, loss: 0.032940
 >> iter 35000, loss: 0.046306
 >> iter 36000, loss: 0.041670
 >> iter 37000, loss: 0.042061
 >> iter 38000, loss: 0.048336
 >> iter 39000, loss: 0.041081
 >> iter 40000, loss: 0.056159
   Number of active neurons: 2
 >> iter 41000, loss: 0.034961
 >> iter 42000, loss: 0.030733
 >> iter 43000, loss: 0.028359
 >> iter 44000, loss: 0.042576
 >> iter 45000, loss: 0.039969
 >> iter 46000, loss: 0.054937
 >> iter 47000, loss: 0.053874
 >> iter 48000, loss: 0.053556
 >> iter 49000, loss: 0.043813
 >> iter 50000, loss: 0.058035
   Number of active neurons: 2
 >> iter 51000, loss: 0.062641
 >> iter 52000, loss: 0.063607
 >> iter 53000, loss: 0.053117
 >> iter 54000, loss: 0.057466
 >> iter 55000, loss: 0.068453
 >> iter 56000, loss: 0.062701
 >> iter 57000, loss: 0.044718
 >> iter 58000, loss: 0.038571
 >> iter 59000, loss: 0.036127
 >> iter 60000, loss: 0.038887
   Number of active neurons: 2
 >> iter 61000, loss: 0.075116
 >> iter 62000, loss: 0.065334
 >> iter 63000, loss: 0.063043
 >> iter 64000, loss: 0.059641
 >> iter 65000, loss: 0.048297
 >> iter 66000, loss: 0.037044
 >> iter 67000, loss: 0.045705
 >> iter 68000, loss: 0.043280
 >> iter 69000, loss: 0.052351
 >> iter 70000, loss: 0.059090
   Number of active neurons: 2
 >> iter 71000, loss: 0.051974
 >> iter 72000, loss: 0.044718
 >> iter 73000, loss: 0.058006
 >> iter 74000, loss: 0.064402
 >> iter 75000, loss: 0.056290
 >> iter 76000, loss: 0.044771
 >> iter 77000, loss: 0.060997
 >> iter 78000, loss: 0.046841
 >> iter 79000, loss: 0.045492
 >> iter 80000, loss: 0.051021
   Number of active neurons: 2
 >> iter 81000, loss: 0.032856
 >> iter 82000, loss: 0.038353
 >> iter 83000, loss: 0.039332
 >> iter 84000, loss: 0.033588
 >> iter 85000, loss: 0.061373
 >> iter 86000, loss: 0.054649
 >> iter 87000, loss: 0.047512
 >> iter 88000, loss: 0.044981
 >> iter 89000, loss: 0.034481
 >> iter 90000, loss: 0.068568
   Number of active neurons: 2
 >> iter 91000, loss: 0.051275
 >> iter 92000, loss: 0.046282
 >> iter 93000, loss: 0.054559
 >> iter 94000, loss: 0.042280
 >> iter 95000, loss: 0.049264
 >> iter 96000, loss: 0.056578
 >> iter 97000, loss: 0.050952
 >> iter 98000, loss: 0.037515
 >> iter 99000, loss: 0.055970
 >> iter 100000, loss: 0.047898
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.698789
 >> iter 2000, loss: 4.478417
 >> iter 3000, loss: 1.734312
 >> iter 4000, loss: 0.685590
 >> iter 5000, loss: 0.301587
 >> iter 6000, loss: 0.149923
 >> iter 7000, loss: 0.086292
 >> iter 8000, loss: 0.078414
 >> iter 9000, loss: 0.072424
 >> iter 10000, loss: 0.049773
   Number of active neurons: 2
 >> iter 11000, loss: 0.053321
 >> iter 12000, loss: 0.036099
 >> iter 13000, loss: 0.040381
 >> iter 14000, loss: 0.047244
 >> iter 15000, loss: 0.038212
 >> iter 16000, loss: 0.037145
 >> iter 17000, loss: 0.050359
 >> iter 18000, loss: 0.042860
 >> iter 19000, loss: 0.041372
 >> iter 20000, loss: 0.056608
   Number of active neurons: 2
 >> iter 21000, loss: 0.055267
 >> iter 22000, loss: 0.068111
 >> iter 23000, loss: 0.070015
 >> iter 24000, loss: 0.042437
 >> iter 25000, loss: 0.040435
 >> iter 26000, loss: 0.036335
 >> iter 27000, loss: 0.049870
 >> iter 28000, loss: 0.056499
 >> iter 29000, loss: 0.057642
 >> iter 30000, loss: 0.052504
   Number of active neurons: 2
 >> iter 31000, loss: 0.046343
 >> iter 32000, loss: 0.049892
 >> iter 33000, loss: 0.060807
 >> iter 34000, loss: 0.050411
 >> iter 35000, loss: 0.037796
 >> iter 36000, loss: 0.044268
 >> iter 37000, loss: 0.057900
 >> iter 38000, loss: 0.063643
 >> iter 39000, loss: 0.073451
 >> iter 40000, loss: 0.051274
   Number of active neurons: 2
 >> iter 41000, loss: 0.062509
 >> iter 42000, loss: 0.049242
 >> iter 43000, loss: 0.060323
 >> iter 44000, loss: 0.052260
 >> iter 45000, loss: 0.057269
 >> iter 46000, loss: 0.059649
 >> iter 47000, loss: 0.042040
 >> iter 48000, loss: 0.053204
 >> iter 49000, loss: 0.075281
 >> iter 50000, loss: 0.049834
   Number of active neurons: 2
 >> iter 51000, loss: 0.038281
 >> iter 52000, loss: 0.034689
 >> iter 53000, loss: 0.028253
 >> iter 54000, loss: 0.043462
 >> iter 55000, loss: 0.040159
 >> iter 56000, loss: 0.049452
 >> iter 57000, loss: 0.039382
 >> iter 58000, loss: 0.036589
 >> iter 59000, loss: 0.038620
 >> iter 60000, loss: 0.030773
   Number of active neurons: 2
 >> iter 61000, loss: 0.034905
 >> iter 62000, loss: 0.058723
 >> iter 63000, loss: 0.036705
 >> iter 64000, loss: 0.039065
 >> iter 65000, loss: 0.040056
 >> iter 66000, loss: 0.058669
 >> iter 67000, loss: 0.060177
 >> iter 68000, loss: 0.065227
 >> iter 69000, loss: 0.064615
 >> iter 70000, loss: 0.048924
   Number of active neurons: 2
 >> iter 71000, loss: 0.045934
 >> iter 72000, loss: 0.040288
 >> iter 73000, loss: 0.034096
 >> iter 74000, loss: 0.055548
 >> iter 75000, loss: 0.041436
 >> iter 76000, loss: 0.039976
 >> iter 77000, loss: 0.038593
 >> iter 78000, loss: 0.054496
 >> iter 79000, loss: 0.033344
 >> iter 80000, loss: 0.056073
   Number of active neurons: 2
 >> iter 81000, loss: 0.068353
 >> iter 82000, loss: 0.045896
 >> iter 83000, loss: 0.051943
 >> iter 84000, loss: 0.055495
 >> iter 85000, loss: 0.058789
 >> iter 86000, loss: 0.039463
 >> iter 87000, loss: 0.037873
 >> iter 88000, loss: 0.039961
 >> iter 89000, loss: 0.041683
 >> iter 90000, loss: 0.037114
   Number of active neurons: 2
 >> iter 91000, loss: 0.037787
 >> iter 92000, loss: 0.043215
 >> iter 93000, loss: 0.077798
 >> iter 94000, loss: 0.065866
 >> iter 95000, loss: 0.057115
 >> iter 96000, loss: 0.051942
 >> iter 97000, loss: 0.038501
 >> iter 98000, loss: 0.054749
 >> iter 99000, loss: 0.035704
 >> iter 100000, loss: 0.028619
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 12.096040
 >> iter 2000, loss: 4.698213
 >> iter 3000, loss: 1.871476
 >> iter 4000, loss: 0.755357
 >> iter 5000, loss: 0.310884
 >> iter 6000, loss: 0.145841
 >> iter 7000, loss: 0.089131
 >> iter 8000, loss: 0.061928
 >> iter 9000, loss: 0.062596
 >> iter 10000, loss: 0.043367
   Number of active neurons: 2
 >> iter 11000, loss: 0.038843
 >> iter 12000, loss: 0.070873
 >> iter 13000, loss: 0.060793
 >> iter 14000, loss: 0.038634
 >> iter 15000, loss: 0.041997
 >> iter 16000, loss: 0.053105
 >> iter 17000, loss: 0.059630
 >> iter 18000, loss: 0.052178
 >> iter 19000, loss: 0.059792
 >> iter 20000, loss: 0.051101
   Number of active neurons: 2
 >> iter 21000, loss: 0.046930
 >> iter 22000, loss: 0.047356
 >> iter 23000, loss: 0.046016
 >> iter 24000, loss: 0.051988
 >> iter 25000, loss: 0.059103
 >> iter 26000, loss: 0.053202
 >> iter 27000, loss: 0.042366
 >> iter 28000, loss: 0.056602
 >> iter 29000, loss: 0.046037
 >> iter 30000, loss: 0.044650
   Number of active neurons: 2
 >> iter 31000, loss: 0.037416
 >> iter 32000, loss: 0.042216
 >> iter 33000, loss: 0.036245
 >> iter 34000, loss: 0.039945
 >> iter 35000, loss: 0.047407
 >> iter 36000, loss: 0.062023
 >> iter 37000, loss: 0.050512
 >> iter 38000, loss: 0.047588
 >> iter 39000, loss: 0.035972
 >> iter 40000, loss: 0.032849
   Number of active neurons: 2
 >> iter 41000, loss: 0.055471
 >> iter 42000, loss: 0.037238
 >> iter 43000, loss: 0.044164
 >> iter 44000, loss: 0.038586
 >> iter 45000, loss: 0.037493
 >> iter 46000, loss: 0.046726
 >> iter 47000, loss: 0.045546
 >> iter 48000, loss: 0.040509
 >> iter 49000, loss: 0.029677
 >> iter 50000, loss: 0.045482
   Number of active neurons: 2
 >> iter 51000, loss: 0.042734
 >> iter 52000, loss: 0.038402
 >> iter 53000, loss: 0.041889
 >> iter 54000, loss: 0.032967
 >> iter 55000, loss: 0.037007
 >> iter 56000, loss: 0.028051
 >> iter 57000, loss: 0.031944
 >> iter 58000, loss: 0.053509
 >> iter 59000, loss: 0.049384
 >> iter 60000, loss: 0.043127
   Number of active neurons: 2
 >> iter 61000, loss: 0.035869
 >> iter 62000, loss: 0.038133
 >> iter 63000, loss: 0.049526
 >> iter 64000, loss: 0.041786
 >> iter 65000, loss: 0.040086
 >> iter 66000, loss: 0.044717
 >> iter 67000, loss: 0.045930
 >> iter 68000, loss: 0.047344
 >> iter 69000, loss: 0.039931
 >> iter 70000, loss: 0.058688
   Number of active neurons: 2
 >> iter 71000, loss: 0.057583
 >> iter 72000, loss: 0.040370
 >> iter 73000, loss: 0.041963
 >> iter 74000, loss: 0.044942
 >> iter 75000, loss: 0.036133
 >> iter 76000, loss: 0.030455
 >> iter 77000, loss: 0.076177
 >> iter 78000, loss: 0.062953
 >> iter 79000, loss: 0.052297
 >> iter 80000, loss: 0.049340
   Number of active neurons: 2
 >> iter 81000, loss: 0.040606
 >> iter 82000, loss: 0.050434
 >> iter 83000, loss: 0.055022
 >> iter 84000, loss: 0.057506
 >> iter 85000, loss: 0.049798
 >> iter 86000, loss: 0.046119
 >> iter 87000, loss: 0.039004
 >> iter 88000, loss: 0.053816
 >> iter 89000, loss: 0.045056
 >> iter 90000, loss: 0.058380
   Number of active neurons: 2
 >> iter 91000, loss: 0.044550
 >> iter 92000, loss: 0.038109
 >> iter 93000, loss: 0.059555
 >> iter 94000, loss: 0.061679
 >> iter 95000, loss: 0.046006
 >> iter 96000, loss: 0.041535
 >> iter 97000, loss: 0.052230
 >> iter 98000, loss: 0.054800
 >> iter 99000, loss: 0.038792
 >> iter 100000, loss: 0.036921
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.694905
 >> iter 2000, loss: 4.446442
 >> iter 3000, loss: 1.730539
 >> iter 4000, loss: 0.684126
 >> iter 5000, loss: 0.311468
 >> iter 6000, loss: 0.150644
 >> iter 7000, loss: 0.084613
 >> iter 8000, loss: 0.060919
 >> iter 9000, loss: 0.051465
 >> iter 10000, loss: 0.053546
   Number of active neurons: 2
 >> iter 11000, loss: 0.046878
 >> iter 12000, loss: 0.052238
 >> iter 13000, loss: 0.052109
 >> iter 14000, loss: 0.042028
 >> iter 15000, loss: 0.041539
 >> iter 16000, loss: 0.037138
 >> iter 17000, loss: 0.038304
 >> iter 18000, loss: 0.043243
 >> iter 19000, loss: 0.043214
 >> iter 20000, loss: 0.052775
   Number of active neurons: 2
 >> iter 21000, loss: 0.050361
 >> iter 22000, loss: 0.048942
 >> iter 23000, loss: 0.055557
 >> iter 24000, loss: 0.053311
 >> iter 25000, loss: 0.046610
 >> iter 26000, loss: 0.046876
 >> iter 27000, loss: 0.056165
 >> iter 28000, loss: 0.045834
 >> iter 29000, loss: 0.029975
 >> iter 30000, loss: 0.044612
   Number of active neurons: 2
 >> iter 31000, loss: 0.033632
 >> iter 32000, loss: 0.038700
 >> iter 33000, loss: 0.048548
 >> iter 34000, loss: 0.059406
 >> iter 35000, loss: 0.049307
 >> iter 36000, loss: 0.045534
 >> iter 37000, loss: 0.044925
 >> iter 38000, loss: 0.051080
 >> iter 39000, loss: 0.042585
 >> iter 40000, loss: 0.038378
   Number of active neurons: 2
 >> iter 41000, loss: 0.065022
 >> iter 42000, loss: 0.052465
 >> iter 43000, loss: 0.047212
 >> iter 44000, loss: 0.047873
 >> iter 45000, loss: 0.039725
 >> iter 46000, loss: 0.050112
 >> iter 47000, loss: 0.054009
 >> iter 48000, loss: 0.043321
 >> iter 49000, loss: 0.056322
 >> iter 50000, loss: 0.051489
   Number of active neurons: 2
 >> iter 51000, loss: 0.040700
 >> iter 52000, loss: 0.045414
 >> iter 53000, loss: 0.072241
 >> iter 54000, loss: 0.068567
 >> iter 55000, loss: 0.054263
 >> iter 56000, loss: 0.048698
 >> iter 57000, loss: 0.031197
 >> iter 58000, loss: 0.039182
 >> iter 59000, loss: 0.049767
 >> iter 60000, loss: 0.045217
   Number of active neurons: 2
 >> iter 61000, loss: 0.050535
 >> iter 62000, loss: 0.038837
 >> iter 63000, loss: 0.055404
 >> iter 64000, loss: 0.048339
 >> iter 65000, loss: 0.048086
 >> iter 66000, loss: 0.059352
 >> iter 67000, loss: 0.047399
 >> iter 68000, loss: 0.034144
 >> iter 69000, loss: 0.036673
 >> iter 70000, loss: 0.047860
   Number of active neurons: 2
 >> iter 71000, loss: 0.056334
 >> iter 72000, loss: 0.060787
 >> iter 73000, loss: 0.041416
 >> iter 74000, loss: 0.061513
 >> iter 75000, loss: 0.051045
 >> iter 76000, loss: 0.033286
 >> iter 77000, loss: 0.026851
 >> iter 78000, loss: 0.034699
 >> iter 79000, loss: 0.037175
 >> iter 80000, loss: 0.059879
   Number of active neurons: 2
 >> iter 81000, loss: 0.041023
 >> iter 82000, loss: 0.030978
 >> iter 83000, loss: 0.052423
 >> iter 84000, loss: 0.050539
 >> iter 85000, loss: 0.050320
 >> iter 86000, loss: 0.038381
 >> iter 87000, loss: 0.045578
 >> iter 88000, loss: 0.054781
 >> iter 89000, loss: 0.059074
 >> iter 90000, loss: 0.037357
   Number of active neurons: 2
 >> iter 91000, loss: 0.046386
 >> iter 92000, loss: 0.049629
 >> iter 93000, loss: 0.045948
 >> iter 94000, loss: 0.032901
 >> iter 95000, loss: 0.036721
 >> iter 96000, loss: 0.054989
 >> iter 97000, loss: 0.037019
 >> iter 98000, loss: 0.038417
 >> iter 99000, loss: 0.039955
 >> iter 100000, loss: 0.047074
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 12.012507
 >> iter 2000, loss: 5.695104
 >> iter 3000, loss: 3.465260
 >> iter 4000, loss: 2.512787
 >> iter 5000, loss: 2.243677
 >> iter 6000, loss: 2.051489
 >> iter 7000, loss: 2.071156
 >> iter 8000, loss: 2.000003
 >> iter 9000, loss: 2.034255
 >> iter 10000, loss: 1.969682
   Number of active neurons: 2
 >> iter 11000, loss: 2.030747
 >> iter 12000, loss: 1.963929
 >> iter 13000, loss: 2.023996
 >> iter 14000, loss: 1.967157
 >> iter 15000, loss: 2.030189
 >> iter 16000, loss: 1.954162
 >> iter 17000, loss: 2.012773
 >> iter 18000, loss: 1.942168
 >> iter 19000, loss: 2.009938
 >> iter 20000, loss: 1.936830
   Number of active neurons: 2
 >> iter 21000, loss: 1.991687
 >> iter 22000, loss: 1.931878
 >> iter 23000, loss: 1.991167
 >> iter 24000, loss: 1.928820
 >> iter 25000, loss: 1.995688
 >> iter 26000, loss: 1.941918
 >> iter 27000, loss: 1.998598
 >> iter 28000, loss: 1.930112
 >> iter 29000, loss: 1.996495
 >> iter 30000, loss: 1.937561
   Number of active neurons: 2
 >> iter 31000, loss: 1.987199
 >> iter 32000, loss: 1.908051
 >> iter 33000, loss: 1.970311
 >> iter 34000, loss: 1.938530
 >> iter 35000, loss: 1.998551
 >> iter 36000, loss: 1.919747
 >> iter 37000, loss: 1.963031
 >> iter 38000, loss: 1.909619
 >> iter 39000, loss: 1.959512
 >> iter 40000, loss: 1.916854
   Number of active neurons: 2
 >> iter 41000, loss: 1.992382
 >> iter 42000, loss: 1.927201
 >> iter 43000, loss: 1.964011
 >> iter 44000, loss: 1.927081
 >> iter 45000, loss: 1.959388
 >> iter 46000, loss: 1.909009
 >> iter 47000, loss: 1.966939
 >> iter 48000, loss: 1.913316
 >> iter 49000, loss: 1.976208
 >> iter 50000, loss: 1.905765
   Number of active neurons: 2
 >> iter 51000, loss: 1.966878
 >> iter 52000, loss: 1.929763
 >> iter 53000, loss: 1.982217
 >> iter 54000, loss: 1.933449
 >> iter 55000, loss: 1.965258
 >> iter 56000, loss: 1.911018
 >> iter 57000, loss: 1.968593
 >> iter 58000, loss: 1.904842
 >> iter 59000, loss: 1.949367
 >> iter 60000, loss: 1.918634
   Number of active neurons: 2
 >> iter 61000, loss: 1.966867
 >> iter 62000, loss: 1.919318
 >> iter 63000, loss: 1.974453
 >> iter 64000, loss: 1.935977
 >> iter 65000, loss: 1.984068
 >> iter 66000, loss: 1.932608
 >> iter 67000, loss: 1.984650
 >> iter 68000, loss: 1.912395
 >> iter 69000, loss: 1.948815
 >> iter 70000, loss: 1.897156
   Number of active neurons: 2
 >> iter 71000, loss: 1.955070
 >> iter 72000, loss: 1.924619
 >> iter 73000, loss: 1.951969
 >> iter 74000, loss: 1.919111
 >> iter 75000, loss: 1.972218
 >> iter 76000, loss: 1.905973
 >> iter 77000, loss: 1.954341
 >> iter 78000, loss: 1.941084
 >> iter 79000, loss: 1.955753
 >> iter 80000, loss: 1.895017
   Number of active neurons: 2
 >> iter 81000, loss: 1.952617
 >> iter 82000, loss: 1.909251
 >> iter 83000, loss: 1.977540
 >> iter 84000, loss: 1.920239
 >> iter 85000, loss: 1.961348
 >> iter 86000, loss: 1.906929
 >> iter 87000, loss: 1.932123
 >> iter 88000, loss: 1.913269
 >> iter 89000, loss: 1.950661
 >> iter 90000, loss: 1.903596
   Number of active neurons: 2
 >> iter 91000, loss: 1.940807
 >> iter 92000, loss: 1.900915
 >> iter 93000, loss: 1.934488
 >> iter 94000, loss: 1.909775
 >> iter 95000, loss: 1.955625
 >> iter 96000, loss: 1.917147
 >> iter 97000, loss: 1.958527
 >> iter 98000, loss: 1.903026
 >> iter 99000, loss: 1.961876
 >> iter 100000, loss: 1.908080
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 12.081831
 >> iter 2000, loss: 5.724158
 >> iter 3000, loss: 3.469679
 >> iter 4000, loss: 2.531341
 >> iter 5000, loss: 2.266066
 >> iter 6000, loss: 2.078703
 >> iter 7000, loss: 2.084884
 >> iter 8000, loss: 1.997077
 >> iter 9000, loss: 2.021398
 >> iter 10000, loss: 1.950881
   Number of active neurons: 2
 >> iter 11000, loss: 2.022682
 >> iter 12000, loss: 1.956975
 >> iter 13000, loss: 2.033211
 >> iter 14000, loss: 1.967060
 >> iter 15000, loss: 2.025172
 >> iter 16000, loss: 1.935309
 >> iter 17000, loss: 2.012878
 >> iter 18000, loss: 1.948564
 >> iter 19000, loss: 2.006905
 >> iter 20000, loss: 1.932188
   Number of active neurons: 2
 >> iter 21000, loss: 1.990818
 >> iter 22000, loss: 1.935200
 >> iter 23000, loss: 2.010567
 >> iter 24000, loss: 1.952299
 >> iter 25000, loss: 2.011481
 >> iter 26000, loss: 1.940634
 >> iter 27000, loss: 2.006914
 >> iter 28000, loss: 1.935042
 >> iter 29000, loss: 1.989390
 >> iter 30000, loss: 1.923943
   Number of active neurons: 2
 >> iter 31000, loss: 2.010500
 >> iter 32000, loss: 1.932531
 >> iter 33000, loss: 1.994781
 >> iter 34000, loss: 1.936327
 >> iter 35000, loss: 1.979262
 >> iter 36000, loss: 1.928456
 >> iter 37000, loss: 1.974848
 >> iter 38000, loss: 1.929545
 >> iter 39000, loss: 1.980972
 >> iter 40000, loss: 1.922871
   Number of active neurons: 2
 >> iter 41000, loss: 1.988931
 >> iter 42000, loss: 1.909295
 >> iter 43000, loss: 1.965680
 >> iter 44000, loss: 1.935965
 >> iter 45000, loss: 1.981924
 >> iter 46000, loss: 1.906891
 >> iter 47000, loss: 1.973403
 >> iter 48000, loss: 1.918734
 >> iter 49000, loss: 1.966090
 >> iter 50000, loss: 1.928959
   Number of active neurons: 2
 >> iter 51000, loss: 1.993313
 >> iter 52000, loss: 1.925830
 >> iter 53000, loss: 1.985847
 >> iter 54000, loss: 1.939256
 >> iter 55000, loss: 1.992706
 >> iter 56000, loss: 1.940085
 >> iter 57000, loss: 1.974924
 >> iter 58000, loss: 1.936980
 >> iter 59000, loss: 1.968688
 >> iter 60000, loss: 1.916112
   Number of active neurons: 2
 >> iter 61000, loss: 1.971639
 >> iter 62000, loss: 1.918339
 >> iter 63000, loss: 1.980829
 >> iter 64000, loss: 1.928559
 >> iter 65000, loss: 1.970444
 >> iter 66000, loss: 1.948674
 >> iter 67000, loss: 1.975398
 >> iter 68000, loss: 1.925155
 >> iter 69000, loss: 1.967484
 >> iter 70000, loss: 1.935602
   Number of active neurons: 2
 >> iter 71000, loss: 1.950179
 >> iter 72000, loss: 1.937477
 >> iter 73000, loss: 1.979448
 >> iter 74000, loss: 1.934083
 >> iter 75000, loss: 1.968195
 >> iter 76000, loss: 1.920369
 >> iter 77000, loss: 1.964801
 >> iter 78000, loss: 1.934325
 >> iter 79000, loss: 1.963055
 >> iter 80000, loss: 1.925248
   Number of active neurons: 2
 >> iter 81000, loss: 1.952050
 >> iter 82000, loss: 1.905118
 >> iter 83000, loss: 1.956035
 >> iter 84000, loss: 1.925995
 >> iter 85000, loss: 1.955733
 >> iter 86000, loss: 1.920502
 >> iter 87000, loss: 1.966956
 >> iter 88000, loss: 1.928539
 >> iter 89000, loss: 1.959729
 >> iter 90000, loss: 1.911708
   Number of active neurons: 2
 >> iter 91000, loss: 1.940956
 >> iter 92000, loss: 1.905609
 >> iter 93000, loss: 1.948130
 >> iter 94000, loss: 1.911141
 >> iter 95000, loss: 1.978074
 >> iter 96000, loss: 1.921672
 >> iter 97000, loss: 1.944369
 >> iter 98000, loss: 1.892344
 >> iter 99000, loss: 1.944825
 >> iter 100000, loss: 1.890333
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 12.030791
 >> iter 2000, loss: 5.707745
 >> iter 3000, loss: 3.461562
 >> iter 4000, loss: 2.527536
 >> iter 5000, loss: 2.240192
 >> iter 6000, loss: 2.054158
 >> iter 7000, loss: 2.082282
 >> iter 8000, loss: 2.000275
 >> iter 9000, loss: 2.060709
 >> iter 10000, loss: 1.985112
   Number of active neurons: 2
 >> iter 11000, loss: 2.007830
 >> iter 12000, loss: 1.956494
 >> iter 13000, loss: 2.037246
 >> iter 14000, loss: 1.963883
 >> iter 15000, loss: 2.033166
 >> iter 16000, loss: 1.966399
 >> iter 17000, loss: 2.036217
 >> iter 18000, loss: 1.960573
 >> iter 19000, loss: 2.022800
 >> iter 20000, loss: 1.965473
   Number of active neurons: 2
 >> iter 21000, loss: 2.005053
 >> iter 22000, loss: 1.931588
 >> iter 23000, loss: 1.992951
 >> iter 24000, loss: 1.924434
 >> iter 25000, loss: 1.999382
 >> iter 26000, loss: 1.937026
 >> iter 27000, loss: 1.993662
 >> iter 28000, loss: 1.927803
 >> iter 29000, loss: 1.984265
 >> iter 30000, loss: 1.934597
   Number of active neurons: 2
 >> iter 31000, loss: 1.987462
 >> iter 32000, loss: 1.917928
 >> iter 33000, loss: 1.983067
 >> iter 34000, loss: 1.936356
 >> iter 35000, loss: 1.991563
 >> iter 36000, loss: 1.940546
 >> iter 37000, loss: 1.997257
 >> iter 38000, loss: 1.918272
 >> iter 39000, loss: 1.981399
 >> iter 40000, loss: 1.925593
   Number of active neurons: 2
 >> iter 41000, loss: 1.987165
 >> iter 42000, loss: 1.927892
 >> iter 43000, loss: 1.989225
 >> iter 44000, loss: 1.939526
 >> iter 45000, loss: 1.983680
 >> iter 46000, loss: 1.926845
 >> iter 47000, loss: 1.979266
 >> iter 48000, loss: 1.939354
 >> iter 49000, loss: 1.970305
 >> iter 50000, loss: 1.911076
   Number of active neurons: 2
 >> iter 51000, loss: 1.977052
 >> iter 52000, loss: 1.931757
 >> iter 53000, loss: 1.979692
 >> iter 54000, loss: 1.940417
 >> iter 55000, loss: 1.977762
 >> iter 56000, loss: 1.925199
 >> iter 57000, loss: 1.957076
 >> iter 58000, loss: 1.920547
 >> iter 59000, loss: 1.958300
 >> iter 60000, loss: 1.931982
   Number of active neurons: 2
 >> iter 61000, loss: 1.989792
 >> iter 62000, loss: 1.933390
 >> iter 63000, loss: 1.979975
 >> iter 64000, loss: 1.912355
 >> iter 65000, loss: 1.970206
 >> iter 66000, loss: 1.929855
 >> iter 67000, loss: 1.986126
 >> iter 68000, loss: 1.926661
 >> iter 69000, loss: 1.966510
 >> iter 70000, loss: 1.920730
   Number of active neurons: 2
 >> iter 71000, loss: 1.968035
 >> iter 72000, loss: 1.938205
 >> iter 73000, loss: 1.969920
 >> iter 74000, loss: 1.925459
 >> iter 75000, loss: 1.969270
 >> iter 76000, loss: 1.926674
 >> iter 77000, loss: 1.970625
 >> iter 78000, loss: 1.917811
 >> iter 79000, loss: 1.981620
 >> iter 80000, loss: 1.925461
   Number of active neurons: 2
 >> iter 81000, loss: 1.966836
 >> iter 82000, loss: 1.907808
 >> iter 83000, loss: 1.939002
 >> iter 84000, loss: 1.917854
 >> iter 85000, loss: 1.938584
 >> iter 86000, loss: 1.907672
 >> iter 87000, loss: 1.946227
 >> iter 88000, loss: 1.922248
 >> iter 89000, loss: 1.953628
 >> iter 90000, loss: 1.889606
   Number of active neurons: 2
 >> iter 91000, loss: 1.958298
 >> iter 92000, loss: 1.919182
 >> iter 93000, loss: 1.938396
 >> iter 94000, loss: 1.904593
 >> iter 95000, loss: 1.952071
 >> iter 96000, loss: 1.914599
 >> iter 97000, loss: 1.970755
 >> iter 98000, loss: 1.897936
 >> iter 99000, loss: 1.952399
 >> iter 100000, loss: 1.915500
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.602215
 >> iter 2000, loss: 4.443034
 >> iter 3000, loss: 1.691267
 >> iter 4000, loss: 0.679726
 >> iter 5000, loss: 0.289917
 >> iter 6000, loss: 0.142802
 >> iter 7000, loss: 0.107016
 >> iter 8000, loss: 0.069603
 >> iter 9000, loss: 0.058672
 >> iter 10000, loss: 0.050761
   Number of active neurons: 2
 >> iter 11000, loss: 0.037890
 >> iter 12000, loss: 0.038651
 >> iter 13000, loss: 0.036946
 >> iter 14000, loss: 0.040581
 >> iter 15000, loss: 0.036318
 >> iter 16000, loss: 0.054776
 >> iter 17000, loss: 0.048911
 >> iter 18000, loss: 0.052554
 >> iter 19000, loss: 0.060970
 >> iter 20000, loss: 0.043031
   Number of active neurons: 2
 >> iter 21000, loss: 0.042940
 >> iter 22000, loss: 0.033855
 >> iter 23000, loss: 0.029655
 >> iter 24000, loss: 0.043355
 >> iter 25000, loss: 0.038699
 >> iter 26000, loss: 0.081985
 >> iter 27000, loss: 0.056419
 >> iter 28000, loss: 0.057520
 >> iter 29000, loss: 0.054061
 >> iter 30000, loss: 0.044975
   Number of active neurons: 2
 >> iter 31000, loss: 0.038603
 >> iter 32000, loss: 0.032314
 >> iter 33000, loss: 0.031830
 >> iter 34000, loss: 0.042652
 >> iter 35000, loss: 0.054205
 >> iter 36000, loss: 0.046790
 >> iter 37000, loss: 0.039939
 >> iter 38000, loss: 0.035895
 >> iter 39000, loss: 0.027489
 >> iter 40000, loss: 0.045936
   Number of active neurons: 2
 >> iter 41000, loss: 0.036837
 >> iter 42000, loss: 0.037012
 >> iter 43000, loss: 0.060242
 >> iter 44000, loss: 0.049251
 >> iter 45000, loss: 0.051894
 >> iter 46000, loss: 0.049897
 >> iter 47000, loss: 0.075392
 >> iter 48000, loss: 0.046798
 >> iter 49000, loss: 0.042072
 >> iter 50000, loss: 0.042842
   Number of active neurons: 2
 >> iter 51000, loss: 0.036494
 >> iter 52000, loss: 0.035463
 >> iter 53000, loss: 0.038231
 >> iter 54000, loss: 0.038862
 >> iter 55000, loss: 0.041261
 >> iter 56000, loss: 0.044090
 >> iter 57000, loss: 0.048858
 >> iter 58000, loss: 0.048591
 >> iter 59000, loss: 0.038924
 >> iter 60000, loss: 0.035578
   Number of active neurons: 2
 >> iter 61000, loss: 0.056327
 >> iter 62000, loss: 0.044277
 >> iter 63000, loss: 0.059767
 >> iter 64000, loss: 0.058164
 >> iter 65000, loss: 0.043564
 >> iter 66000, loss: 0.034731
 >> iter 67000, loss: 0.043070
 >> iter 68000, loss: 0.039770
 >> iter 69000, loss: 0.036247
 >> iter 70000, loss: 0.034574
   Number of active neurons: 2
 >> iter 71000, loss: 0.055404
 >> iter 72000, loss: 0.045285
 >> iter 73000, loss: 0.036835
 >> iter 74000, loss: 0.034127
 >> iter 75000, loss: 0.034496
 >> iter 76000, loss: 0.042696
 >> iter 77000, loss: 0.069619
 >> iter 78000, loss: 0.045774
 >> iter 79000, loss: 0.038537
 >> iter 80000, loss: 0.056312
   Number of active neurons: 2
 >> iter 81000, loss: 0.052926
 >> iter 82000, loss: 0.052465
 >> iter 83000, loss: 0.062039
 >> iter 84000, loss: 0.057434
 >> iter 85000, loss: 0.038573
 >> iter 86000, loss: 0.029296
 >> iter 87000, loss: 0.037251
 >> iter 88000, loss: 0.041509
 >> iter 89000, loss: 0.035308
 >> iter 90000, loss: 0.036028
   Number of active neurons: 2
 >> iter 91000, loss: 0.041420
 >> iter 92000, loss: 0.029512
 >> iter 93000, loss: 0.027089
 >> iter 94000, loss: 0.053991
 >> iter 95000, loss: 0.048143
 >> iter 96000, loss: 0.048169
 >> iter 97000, loss: 0.051189
 >> iter 98000, loss: 0.033051
 >> iter 99000, loss: 0.038827
 >> iter 100000, loss: 0.034526
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 12.010723
 >> iter 2000, loss: 5.711886
 >> iter 3000, loss: 3.452345
 >> iter 4000, loss: 2.529968
 >> iter 5000, loss: 2.262904
 >> iter 6000, loss: 2.082955
 >> iter 7000, loss: 2.092754
 >> iter 8000, loss: 2.003826
 >> iter 9000, loss: 2.065925
 >> iter 10000, loss: 1.979083
   Number of active neurons: 2
 >> iter 11000, loss: 2.031905
 >> iter 12000, loss: 1.971216
 >> iter 13000, loss: 2.024283
 >> iter 14000, loss: 1.970820
 >> iter 15000, loss: 2.027818
 >> iter 16000, loss: 1.953291
 >> iter 17000, loss: 2.009858
 >> iter 18000, loss: 1.949451
 >> iter 19000, loss: 2.010595
 >> iter 20000, loss: 1.958971
   Number of active neurons: 2
 >> iter 21000, loss: 2.015797
 >> iter 22000, loss: 1.955852
 >> iter 23000, loss: 2.001058
 >> iter 24000, loss: 1.937148
 >> iter 25000, loss: 2.015681
 >> iter 26000, loss: 1.942222
 >> iter 27000, loss: 2.012876
 >> iter 28000, loss: 1.939134
 >> iter 29000, loss: 1.992512
 >> iter 30000, loss: 1.931674
   Number of active neurons: 2
 >> iter 31000, loss: 1.986920
 >> iter 32000, loss: 1.929732
 >> iter 33000, loss: 2.003368
 >> iter 34000, loss: 1.943261
 >> iter 35000, loss: 2.011633
 >> iter 36000, loss: 1.921991
 >> iter 37000, loss: 1.998616
 >> iter 38000, loss: 1.923793
 >> iter 39000, loss: 1.973020
 >> iter 40000, loss: 1.907843
   Number of active neurons: 2
 >> iter 41000, loss: 1.976113
 >> iter 42000, loss: 1.924162
 >> iter 43000, loss: 1.985152
 >> iter 44000, loss: 1.935202
 >> iter 45000, loss: 1.981533
 >> iter 46000, loss: 1.933588
 >> iter 47000, loss: 1.999908
 >> iter 48000, loss: 1.915464
 >> iter 49000, loss: 1.981865
 >> iter 50000, loss: 1.923424
   Number of active neurons: 2
 >> iter 51000, loss: 1.976637
 >> iter 52000, loss: 1.926632
 >> iter 53000, loss: 1.973572
 >> iter 54000, loss: 1.913686
 >> iter 55000, loss: 1.956764
 >> iter 56000, loss: 1.906451
 >> iter 57000, loss: 1.962213
 >> iter 58000, loss: 1.910190
 >> iter 59000, loss: 1.966515
 >> iter 60000, loss: 1.916962
   Number of active neurons: 2
 >> iter 61000, loss: 1.978385
 >> iter 62000, loss: 1.918966
 >> iter 63000, loss: 1.990929
 >> iter 64000, loss: 1.933395
 >> iter 65000, loss: 1.964340
 >> iter 66000, loss: 1.918674
 >> iter 67000, loss: 1.952383
 >> iter 68000, loss: 1.920232
 >> iter 69000, loss: 1.960023
 >> iter 70000, loss: 1.932937
   Number of active neurons: 2
 >> iter 71000, loss: 1.968257
 >> iter 72000, loss: 1.931610
 >> iter 73000, loss: 1.984973
 >> iter 74000, loss: 1.921237
 >> iter 75000, loss: 1.956506
 >> iter 76000, loss: 1.911708
 >> iter 77000, loss: 1.952826
 >> iter 78000, loss: 1.928585
 >> iter 79000, loss: 1.969704
 >> iter 80000, loss: 1.926955
   Number of active neurons: 2
 >> iter 81000, loss: 1.974558
 >> iter 82000, loss: 1.920926
 >> iter 83000, loss: 1.952829
 >> iter 84000, loss: 1.916356
 >> iter 85000, loss: 1.972365
 >> iter 86000, loss: 1.920058
 >> iter 87000, loss: 1.959734
 >> iter 88000, loss: 1.908585
 >> iter 89000, loss: 1.959278
 >> iter 90000, loss: 1.911951
   Number of active neurons: 2
 >> iter 91000, loss: 1.959868
 >> iter 92000, loss: 1.914483
 >> iter 93000, loss: 1.969502
 >> iter 94000, loss: 1.931361
 >> iter 95000, loss: 1.971788
 >> iter 96000, loss: 1.935994
 >> iter 97000, loss: 1.967627
 >> iter 98000, loss: 1.897586
 >> iter 99000, loss: 1.952565
 >> iter 100000, loss: 1.911009
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 2.69794604108
   - Test - Long: 0.304984750762
   - Test - Big: 2.50297497025
   - Test - A: 0.00666622225185
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.889979
 >> iter 2000, loss: 4.696383
 >> iter 3000, loss: 1.805533
 >> iter 4000, loss: 0.714004
 >> iter 5000, loss: 0.326804
 >> iter 6000, loss: 0.162081
 >> iter 7000, loss: 0.081148
 >> iter 8000, loss: 0.089418
 >> iter 9000, loss: 0.067006
 >> iter 10000, loss: 0.065140
   Number of active neurons: 2
 >> iter 11000, loss: 0.057868
 >> iter 12000, loss: 0.043525
 >> iter 13000, loss: 0.058579
 >> iter 14000, loss: 0.049289
 >> iter 15000, loss: 0.074661
 >> iter 16000, loss: 0.055669
 >> iter 17000, loss: 0.045200
 >> iter 18000, loss: 0.044193
 >> iter 19000, loss: 0.054405
 >> iter 20000, loss: 0.046032
   Number of active neurons: 2
 >> iter 21000, loss: 0.035656
 >> iter 22000, loss: 0.040044
 >> iter 23000, loss: 0.045498
 >> iter 24000, loss: 0.062693
 >> iter 25000, loss: 0.046005
 >> iter 26000, loss: 0.077277
 >> iter 27000, loss: 0.063452
 >> iter 28000, loss: 0.053176
 >> iter 29000, loss: 0.050301
 >> iter 30000, loss: 0.039948
   Number of active neurons: 2
 >> iter 31000, loss: 0.040370
 >> iter 32000, loss: 0.050326
 >> iter 33000, loss: 0.040200
 >> iter 34000, loss: 0.049410
 >> iter 35000, loss: 0.053753
 >> iter 36000, loss: 0.048392
 >> iter 37000, loss: 0.053310
 >> iter 38000, loss: 0.050374
 >> iter 39000, loss: 0.048384
 >> iter 40000, loss: 0.047316
   Number of active neurons: 2
 >> iter 41000, loss: 0.046358
 >> iter 42000, loss: 0.057445
 >> iter 43000, loss: 0.044926
 >> iter 44000, loss: 0.055496
 >> iter 45000, loss: 0.042925
 >> iter 46000, loss: 0.050144
 >> iter 47000, loss: 0.051400
 >> iter 48000, loss: 0.049613
 >> iter 49000, loss: 0.044118
 >> iter 50000, loss: 0.059844
   Number of active neurons: 2
 >> iter 51000, loss: 0.045118
 >> iter 52000, loss: 0.037955
 >> iter 53000, loss: 0.041523
 >> iter 54000, loss: 0.042823
 >> iter 55000, loss: 0.033897
 >> iter 56000, loss: 0.035573
 >> iter 57000, loss: 0.036219
 >> iter 58000, loss: 0.038059
 >> iter 59000, loss: 0.051482
 >> iter 60000, loss: 0.050785
   Number of active neurons: 2
 >> iter 61000, loss: 0.053064
 >> iter 62000, loss: 0.067216
 >> iter 63000, loss: 0.048113
 >> iter 64000, loss: 0.047880
 >> iter 65000, loss: 0.037639
 >> iter 66000, loss: 0.054833
 >> iter 67000, loss: 0.064872
 >> iter 68000, loss: 0.043051
 >> iter 69000, loss: 0.038841
 >> iter 70000, loss: 0.035635
   Number of active neurons: 2
 >> iter 71000, loss: 0.040213
 >> iter 72000, loss: 0.043120
 >> iter 73000, loss: 0.042959
 >> iter 74000, loss: 0.048124
 >> iter 75000, loss: 0.043231
 >> iter 76000, loss: 0.049442
 >> iter 77000, loss: 0.043644
 >> iter 78000, loss: 0.033542
 >> iter 79000, loss: 0.050944
 >> iter 80000, loss: 0.048758
   Number of active neurons: 2
 >> iter 81000, loss: 0.052952
 >> iter 82000, loss: 0.049767
 >> iter 83000, loss: 0.035039
 >> iter 84000, loss: 0.035788
 >> iter 85000, loss: 0.033752
 >> iter 86000, loss: 0.033351
 >> iter 87000, loss: 0.052616
 >> iter 88000, loss: 0.042128
 >> iter 89000, loss: 0.044486
 >> iter 90000, loss: 0.040893
   Number of active neurons: 2
 >> iter 91000, loss: 0.053091
 >> iter 92000, loss: 0.084613
 >> iter 93000, loss: 0.047444
 >> iter 94000, loss: 0.038322
 >> iter 95000, loss: 0.047735
 >> iter 96000, loss: 0.038292
 >> iter 97000, loss: 0.069504
 >> iter 98000, loss: 0.042191
 >> iter 99000, loss: 0.030631
 >> iter 100000, loss: 0.041805
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

