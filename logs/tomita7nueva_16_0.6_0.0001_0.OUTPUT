 > Problema: tomita7nueva
 > Args:
   - Hidden size: 16
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.985881
 >> iter 2000, loss: 11.307639
 >> iter 3000, loss: 7.626964
 >> iter 4000, loss: 3.558780
 >> iter 5000, loss: 1.588079
 >> iter 6000, loss: 0.873180
 >> iter 7000, loss: 0.550028
 >> iter 8000, loss: 0.388930
 >> iter 9000, loss: 0.422119
 >> iter 10000, loss: 0.310974
   Number of active neurons: 8
 >> iter 11000, loss: 0.287998
 >> iter 12000, loss: 0.270403
 >> iter 13000, loss: 0.304534
 >> iter 14000, loss: 0.286470
 >> iter 15000, loss: 0.430450
 >> iter 16000, loss: 0.325111
 >> iter 17000, loss: 0.211343
 >> iter 18000, loss: 0.280269
 >> iter 19000, loss: 0.325573
 >> iter 20000, loss: 0.256419
   Number of active neurons: 6
 >> iter 21000, loss: 0.188770
 >> iter 22000, loss: 0.272077
 >> iter 23000, loss: 0.346354
 >> iter 24000, loss: 0.305096
 >> iter 25000, loss: 0.423649
 >> iter 26000, loss: 0.291354
 >> iter 27000, loss: 0.243592
 >> iter 28000, loss: 0.234334
 >> iter 29000, loss: 0.236375
 >> iter 30000, loss: 0.210164
   Number of active neurons: 6
 >> iter 31000, loss: 0.191025
 >> iter 32000, loss: 0.150287
 >> iter 33000, loss: 0.214207
 >> iter 34000, loss: 0.267924
 >> iter 35000, loss: 0.211117
 >> iter 36000, loss: 0.209116
 >> iter 37000, loss: 0.270363
 >> iter 38000, loss: 0.280057
 >> iter 39000, loss: 0.300160
 >> iter 40000, loss: 0.186100
   Number of active neurons: 6
 >> iter 41000, loss: 0.264165
 >> iter 42000, loss: 0.298110
 >> iter 43000, loss: 0.268891
 >> iter 44000, loss: 0.232071
 >> iter 45000, loss: 0.169471
 >> iter 46000, loss: 0.155441
 >> iter 47000, loss: 0.164556
 >> iter 48000, loss: 0.229521
 >> iter 49000, loss: 0.218680
 >> iter 50000, loss: 0.178838
   Number of active neurons: 6
 >> iter 51000, loss: 0.234853
 >> iter 52000, loss: 0.335292
 >> iter 53000, loss: 0.280332
 >> iter 54000, loss: 0.384419
 >> iter 55000, loss: 0.410249
 >> iter 56000, loss: 0.340039
 >> iter 57000, loss: 0.266737
 >> iter 58000, loss: 0.227845
 >> iter 59000, loss: 0.231186
 >> iter 60000, loss: 0.190855
   Number of active neurons: 6
 >> iter 61000, loss: 0.205588
 >> iter 62000, loss: 0.207480
 >> iter 63000, loss: 0.202299
 >> iter 64000, loss: 0.175137
 >> iter 65000, loss: 0.206974
 >> iter 66000, loss: 0.128100
 >> iter 67000, loss: 0.242773
 >> iter 68000, loss: 0.254533
 >> iter 69000, loss: 0.314593
 >> iter 70000, loss: 0.360549
   Number of active neurons: 6
 >> iter 71000, loss: 0.322375
 >> iter 72000, loss: 0.317436
 >> iter 73000, loss: 0.241704
 >> iter 74000, loss: 0.210304
 >> iter 75000, loss: 0.234866
 >> iter 76000, loss: 0.161259
 >> iter 77000, loss: 0.296510
 >> iter 78000, loss: 0.345581
 >> iter 79000, loss: 0.320600
 >> iter 80000, loss: 0.220507
   Number of active neurons: 6
 >> iter 81000, loss: 0.181166
 >> iter 82000, loss: 0.175126
 >> iter 83000, loss: 0.172154
 >> iter 84000, loss: 0.250944
 >> iter 85000, loss: 0.189993
 >> iter 86000, loss: 0.183724
 >> iter 87000, loss: 0.222057
 >> iter 88000, loss: 0.274046
 >> iter 89000, loss: 0.234172
 >> iter 90000, loss: 0.243083
   Number of active neurons: 6
 >> iter 91000, loss: 0.168987
 >> iter 92000, loss: 0.193998
 >> iter 93000, loss: 0.192369
 >> iter 94000, loss: 0.240171
 >> iter 95000, loss: 0.236301
 >> iter 96000, loss: 0.189574
 >> iter 97000, loss: 0.156311
 >> iter 98000, loss: 0.177049
 >> iter 99000, loss: 0.156375
 >> iter 100000, loss: 0.170270
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.799043
 >> iter 2000, loss: 10.118150
 >> iter 3000, loss: 7.435464
 >> iter 4000, loss: 5.170415
 >> iter 5000, loss: 3.924876
 >> iter 6000, loss: 3.203706
 >> iter 7000, loss: 3.193399
 >> iter 8000, loss: 2.169406
 >> iter 9000, loss: 1.420198
 >> iter 10000, loss: 1.118117
   Number of active neurons: 10
 >> iter 11000, loss: 0.758627
 >> iter 12000, loss: 0.462828
 >> iter 13000, loss: 0.487838
 >> iter 14000, loss: 0.429158
 >> iter 15000, loss: 0.486977
 >> iter 16000, loss: 0.376610
 >> iter 17000, loss: 0.593934
 >> iter 18000, loss: 0.449300
 >> iter 19000, loss: 0.458797
 >> iter 20000, loss: 0.368175
   Number of active neurons: 9
 >> iter 21000, loss: 0.455156
 >> iter 22000, loss: 0.539681
 >> iter 23000, loss: 0.338560
 >> iter 24000, loss: 0.385200
 >> iter 25000, loss: 0.394970
 >> iter 26000, loss: 0.314620
 >> iter 27000, loss: 0.262637
 >> iter 28000, loss: 0.256282
 >> iter 29000, loss: 0.276969
 >> iter 30000, loss: 0.236009
   Number of active neurons: 9
 >> iter 31000, loss: 0.280737
 >> iter 32000, loss: 0.350206
 >> iter 33000, loss: 0.263065
 >> iter 34000, loss: 0.295818
 >> iter 35000, loss: 0.345681
 >> iter 36000, loss: 0.282421
 >> iter 37000, loss: 0.308005
 >> iter 38000, loss: 0.286714
 >> iter 39000, loss: 0.228737
 >> iter 40000, loss: 0.291141
   Number of active neurons: 8
 >> iter 41000, loss: 0.435900
 >> iter 42000, loss: 0.291088
 >> iter 43000, loss: 0.292253
 >> iter 44000, loss: 0.359719
 >> iter 45000, loss: 0.343586
 >> iter 46000, loss: 0.247385
 >> iter 47000, loss: 0.305493
 >> iter 48000, loss: 0.265150
 >> iter 49000, loss: 0.225174
 >> iter 50000, loss: 0.257373
   Number of active neurons: 8
 >> iter 51000, loss: 0.397621
 >> iter 52000, loss: 0.333143
 >> iter 53000, loss: 0.299287
 >> iter 54000, loss: 0.402828
 >> iter 55000, loss: 0.378786
 >> iter 56000, loss: 0.339517
 >> iter 57000, loss: 0.337053
 >> iter 58000, loss: 0.271444
 >> iter 59000, loss: 0.296462
 >> iter 60000, loss: 0.329461
   Number of active neurons: 7
 >> iter 61000, loss: 0.406926
 >> iter 62000, loss: 0.374435
 >> iter 63000, loss: 0.390632
 >> iter 64000, loss: 0.400734
 >> iter 65000, loss: 0.347769
 >> iter 66000, loss: 0.354915
 >> iter 67000, loss: 0.280526
 >> iter 68000, loss: 0.303542
 >> iter 69000, loss: 0.295075
 >> iter 70000, loss: 0.308604
   Number of active neurons: 7
 >> iter 71000, loss: 0.328760
 >> iter 72000, loss: 0.283801
 >> iter 73000, loss: 0.316133
 >> iter 74000, loss: 0.329249
 >> iter 75000, loss: 0.364894
 >> iter 76000, loss: 0.399577
 >> iter 77000, loss: 0.299390
 >> iter 78000, loss: 0.326908
 >> iter 79000, loss: 0.297614
 >> iter 80000, loss: 0.361058
   Number of active neurons: 7
 >> iter 81000, loss: 0.338524
 >> iter 82000, loss: 0.281745
 >> iter 83000, loss: 0.355513
 >> iter 84000, loss: 0.315465
 >> iter 85000, loss: 0.352283
 >> iter 86000, loss: 0.354515
 >> iter 87000, loss: 0.345505
 >> iter 88000, loss: 0.518349
 >> iter 89000, loss: 0.516217
 >> iter 90000, loss: 0.372687
   Number of active neurons: 7
 >> iter 91000, loss: 0.387630
 >> iter 92000, loss: 0.325439
 >> iter 93000, loss: 0.399783
 >> iter 94000, loss: 0.310639
 >> iter 95000, loss: 0.469902
 >> iter 96000, loss: 0.365924
 >> iter 97000, loss: 0.421563
 >> iter 98000, loss: 0.388915
 >> iter 99000, loss: 0.463628
 >> iter 100000, loss: 0.324818
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.339896
 >> iter 2000, loss: 9.790094
 >> iter 3000, loss: 5.165416
 >> iter 4000, loss: 2.925760
 >> iter 5000, loss: 1.842891
 >> iter 6000, loss: 1.225325
 >> iter 7000, loss: 0.897311
 >> iter 8000, loss: 0.952560
 >> iter 9000, loss: 0.950194
 >> iter 10000, loss: 0.850014
   Number of active neurons: 4
 >> iter 11000, loss: 0.691748
 >> iter 12000, loss: 0.658673
 >> iter 13000, loss: 0.722946
 >> iter 14000, loss: 0.576780
 >> iter 15000, loss: 0.546387
 >> iter 16000, loss: 0.465759
 >> iter 17000, loss: 0.401595
 >> iter 18000, loss: 0.351214
 >> iter 19000, loss: 0.402450
 >> iter 20000, loss: 0.346402
   Number of active neurons: 4
 >> iter 21000, loss: 0.352176
 >> iter 22000, loss: 0.524466
 >> iter 23000, loss: 0.502786
 >> iter 24000, loss: 0.516857
 >> iter 25000, loss: 0.442791
 >> iter 26000, loss: 0.316758
 >> iter 27000, loss: 0.338414
 >> iter 28000, loss: 0.363036
 >> iter 29000, loss: 0.309254
 >> iter 30000, loss: 0.363025
   Number of active neurons: 4
 >> iter 31000, loss: 0.265826
 >> iter 32000, loss: 0.482141
 >> iter 33000, loss: 0.377201
 >> iter 34000, loss: 0.268793
 >> iter 35000, loss: 0.346592
 >> iter 36000, loss: 0.490442
 >> iter 37000, loss: 0.483381
 >> iter 38000, loss: 0.493004
 >> iter 39000, loss: 0.421464
 >> iter 40000, loss: 0.520273
   Number of active neurons: 4
 >> iter 41000, loss: 0.468711
 >> iter 42000, loss: 0.333892
 >> iter 43000, loss: 0.462912
 >> iter 44000, loss: 0.643766
 >> iter 45000, loss: 0.696643
 >> iter 46000, loss: 0.563337
 >> iter 47000, loss: 0.568263
 >> iter 48000, loss: 0.513828
 >> iter 49000, loss: 0.458742
 >> iter 50000, loss: 0.591312
   Number of active neurons: 4
 >> iter 51000, loss: 0.571391
 >> iter 52000, loss: 0.552374
 >> iter 53000, loss: 0.583920
 >> iter 54000, loss: 0.606383
 >> iter 55000, loss: 0.550656
 >> iter 56000, loss: 0.505586
 >> iter 57000, loss: 0.445509
 >> iter 58000, loss: 0.373253
 >> iter 59000, loss: 0.356989
 >> iter 60000, loss: 0.514795
   Number of active neurons: 4
 >> iter 61000, loss: 0.440099
 >> iter 62000, loss: 0.409618
 >> iter 63000, loss: 0.465783
 >> iter 64000, loss: 0.558516
 >> iter 65000, loss: 0.446219
 >> iter 66000, loss: 0.461186
 >> iter 67000, loss: 0.442333
 >> iter 68000, loss: 0.517405
 >> iter 69000, loss: 0.487081
 >> iter 70000, loss: 0.599791
   Number of active neurons: 4
 >> iter 71000, loss: 0.496914
 >> iter 72000, loss: 0.528622
 >> iter 73000, loss: 0.431816
 >> iter 74000, loss: 0.414589
 >> iter 75000, loss: 0.385854
 >> iter 76000, loss: 0.358904
 >> iter 77000, loss: 0.468308
 >> iter 78000, loss: 0.456683
 >> iter 79000, loss: 0.613765
 >> iter 80000, loss: 0.667154
   Number of active neurons: 4
 >> iter 81000, loss: 0.627024
 >> iter 82000, loss: 0.601259
 >> iter 83000, loss: 0.520833
 >> iter 84000, loss: 0.512043
 >> iter 85000, loss: 0.587216
 >> iter 86000, loss: 0.500562
 >> iter 87000, loss: 0.564946
 >> iter 88000, loss: 0.558929
 >> iter 89000, loss: 0.477327
 >> iter 90000, loss: 0.541066
   Number of active neurons: 4
 >> iter 91000, loss: 0.478379
 >> iter 92000, loss: 0.490663
 >> iter 93000, loss: 0.496626
 >> iter 94000, loss: 0.510675
 >> iter 95000, loss: 0.606756
 >> iter 96000, loss: 0.582685
 >> iter 97000, loss: 0.494393
 >> iter 98000, loss: 0.715139
 >> iter 99000, loss: 0.585616
 >> iter 100000, loss: 0.431682
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.840055
 >> iter 2000, loss: 9.626322
 >> iter 3000, loss: 5.620062
 >> iter 4000, loss: 2.666190
 >> iter 5000, loss: 1.333306
 >> iter 6000, loss: 0.959649
 >> iter 7000, loss: 0.526495
 >> iter 8000, loss: 0.388976
 >> iter 9000, loss: 0.393873
 >> iter 10000, loss: 0.363178
   Number of active neurons: 10
 >> iter 11000, loss: 0.316601
 >> iter 12000, loss: 0.287994
 >> iter 13000, loss: 0.306797
 >> iter 14000, loss: 0.279597
 >> iter 15000, loss: 0.397990
 >> iter 16000, loss: 0.280995
 >> iter 17000, loss: 0.435654
 >> iter 18000, loss: 0.384289
 >> iter 19000, loss: 0.308671
 >> iter 20000, loss: 0.497024
   Number of active neurons: 10
 >> iter 21000, loss: 0.351187
 >> iter 22000, loss: 0.324218
 >> iter 23000, loss: 0.410601
 >> iter 24000, loss: 0.402886
 >> iter 25000, loss: 0.260707
 >> iter 26000, loss: 0.339589
 >> iter 27000, loss: 0.299602
 >> iter 28000, loss: 0.191419
 >> iter 29000, loss: 0.238710
 >> iter 30000, loss: 0.256492
   Number of active neurons: 9
 >> iter 31000, loss: 0.362065
 >> iter 32000, loss: 0.332787
 >> iter 33000, loss: 0.281426
 >> iter 34000, loss: 0.339634
 >> iter 35000, loss: 0.382645
 >> iter 36000, loss: 0.376981
 >> iter 37000, loss: 0.340738
 >> iter 38000, loss: 0.181215
 >> iter 39000, loss: 0.304334
 >> iter 40000, loss: 0.347329
   Number of active neurons: 8
 >> iter 41000, loss: 0.260548
 >> iter 42000, loss: 0.448348
 >> iter 43000, loss: 0.377333
 >> iter 44000, loss: 0.454265
 >> iter 45000, loss: 0.299632
 >> iter 46000, loss: 0.302033
 >> iter 47000, loss: 0.287318
 >> iter 48000, loss: 0.296735
 >> iter 49000, loss: 0.328389
 >> iter 50000, loss: 0.352573
   Number of active neurons: 8
 >> iter 51000, loss: 0.371886
 >> iter 52000, loss: 0.339368
 >> iter 53000, loss: 0.340770
 >> iter 54000, loss: 0.393396
 >> iter 55000, loss: 0.351737
 >> iter 56000, loss: 0.281192
 >> iter 57000, loss: 0.424360
 >> iter 58000, loss: 0.329765
 >> iter 59000, loss: 0.297941
 >> iter 60000, loss: 0.317862
   Number of active neurons: 8
 >> iter 61000, loss: 0.327101
 >> iter 62000, loss: 0.499111
 >> iter 63000, loss: 0.388913
 >> iter 64000, loss: 0.319993
 >> iter 65000, loss: 0.341918
 >> iter 66000, loss: 0.277096
 >> iter 67000, loss: 0.275498
 >> iter 68000, loss: 0.191188
 >> iter 69000, loss: 0.344733
 >> iter 70000, loss: 0.233451
   Number of active neurons: 8
 >> iter 71000, loss: 0.230764
 >> iter 72000, loss: 0.322407
 >> iter 73000, loss: 0.416314
 >> iter 74000, loss: 0.295735
 >> iter 75000, loss: 0.276632
 >> iter 76000, loss: 0.347116
 >> iter 77000, loss: 0.224350
 >> iter 78000, loss: 0.279506
 >> iter 79000, loss: 0.347355
 >> iter 80000, loss: 0.309381
   Number of active neurons: 8
 >> iter 81000, loss: 0.356908
 >> iter 82000, loss: 0.353160
 >> iter 83000, loss: 0.323263
 >> iter 84000, loss: 0.275114
 >> iter 85000, loss: 0.240287
 >> iter 86000, loss: 0.236919
 >> iter 87000, loss: 0.280335
 >> iter 88000, loss: 0.387617
 >> iter 89000, loss: 0.338513
 >> iter 90000, loss: 0.410791
   Number of active neurons: 7
 >> iter 91000, loss: 0.313651
 >> iter 92000, loss: 0.281500
 >> iter 93000, loss: 0.216924
 >> iter 94000, loss: 0.206045
 >> iter 95000, loss: 0.221951
 >> iter 96000, loss: 0.247444
 >> iter 97000, loss: 0.278796
 >> iter 98000, loss: 0.190171
 >> iter 99000, loss: 0.253534
 >> iter 100000, loss: 0.208132
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.392977
 >> iter 2000, loss: 10.214893
 >> iter 3000, loss: 4.977062
 >> iter 4000, loss: 2.387732
 >> iter 5000, loss: 1.329945
 >> iter 6000, loss: 0.776316
 >> iter 7000, loss: 0.712172
 >> iter 8000, loss: 0.496945
 >> iter 9000, loss: 0.450642
 >> iter 10000, loss: 0.488792
   Number of active neurons: 8
 >> iter 11000, loss: 0.520037
 >> iter 12000, loss: 0.421375
 >> iter 13000, loss: 0.420439
 >> iter 14000, loss: 0.367490
 >> iter 15000, loss: 0.402945
 >> iter 16000, loss: 0.400430
 >> iter 17000, loss: 0.310493
 >> iter 18000, loss: 0.385961
 >> iter 19000, loss: 0.499892
 >> iter 20000, loss: 0.362426
   Number of active neurons: 8
 >> iter 21000, loss: 0.449843
 >> iter 22000, loss: 0.375107
 >> iter 23000, loss: 0.397575
 >> iter 24000, loss: 0.452948
 >> iter 25000, loss: 0.541859
 >> iter 26000, loss: 0.383582
 >> iter 27000, loss: 0.382706
 >> iter 28000, loss: 0.326057
 >> iter 29000, loss: 0.367089
 >> iter 30000, loss: 0.331977
   Number of active neurons: 7
 >> iter 31000, loss: 0.390805
 >> iter 32000, loss: 0.372047
 >> iter 33000, loss: 0.327553
 >> iter 34000, loss: 0.436775
 >> iter 35000, loss: 0.417483
 >> iter 36000, loss: 0.309772
 >> iter 37000, loss: 0.376706
 >> iter 38000, loss: 0.440551
 >> iter 39000, loss: 0.432478
 >> iter 40000, loss: 0.346923
   Number of active neurons: 7
 >> iter 41000, loss: 0.327548
 >> iter 42000, loss: 0.345535
 >> iter 43000, loss: 0.403421
 >> iter 44000, loss: 0.422365
 >> iter 45000, loss: 0.294121
 >> iter 46000, loss: 0.309989
 >> iter 47000, loss: 0.304000
 >> iter 48000, loss: 0.255690
 >> iter 49000, loss: 0.199513
 >> iter 50000, loss: 0.299247
   Number of active neurons: 7
 >> iter 51000, loss: 0.295009
 >> iter 52000, loss: 0.299163
 >> iter 53000, loss: 0.329451
 >> iter 54000, loss: 0.339007
 >> iter 55000, loss: 0.238088
 >> iter 56000, loss: 0.412257
 >> iter 57000, loss: 0.305416
 >> iter 58000, loss: 0.332070
 >> iter 59000, loss: 0.448088
 >> iter 60000, loss: 0.272419
   Number of active neurons: 7
 >> iter 61000, loss: 0.329859
 >> iter 62000, loss: 0.293106
 >> iter 63000, loss: 0.380208
 >> iter 64000, loss: 0.323685
 >> iter 65000, loss: 0.307215
 >> iter 66000, loss: 0.374127
 >> iter 67000, loss: 0.280407
 >> iter 68000, loss: 0.288114
 >> iter 69000, loss: 0.336310
 >> iter 70000, loss: 0.333667
   Number of active neurons: 7
 >> iter 71000, loss: 0.305949
 >> iter 72000, loss: 0.343832
 >> iter 73000, loss: 0.366640
 >> iter 74000, loss: 0.340585
 >> iter 75000, loss: 0.407643
 >> iter 76000, loss: 0.377210
 >> iter 77000, loss: 0.289296
 >> iter 78000, loss: 0.357953
 >> iter 79000, loss: 0.406915
 >> iter 80000, loss: 0.413018
   Number of active neurons: 7
 >> iter 81000, loss: 0.482497
 >> iter 82000, loss: 0.412924
 >> iter 83000, loss: 0.331664
 >> iter 84000, loss: 0.335410
 >> iter 85000, loss: 0.252190
 >> iter 86000, loss: 0.360806
 >> iter 87000, loss: 0.482043
 >> iter 88000, loss: 0.513577
 >> iter 89000, loss: 0.418212
 >> iter 90000, loss: 0.390925
   Number of active neurons: 7
 >> iter 91000, loss: 0.385570
 >> iter 92000, loss: 0.358696
 >> iter 93000, loss: 0.390122
 >> iter 94000, loss: 0.346702
 >> iter 95000, loss: 0.385859
 >> iter 96000, loss: 0.320663
 >> iter 97000, loss: 0.339501
 >> iter 98000, loss: 0.364782
 >> iter 99000, loss: 0.348440
 >> iter 100000, loss: 0.361666
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.767608
 >> iter 2000, loss: 10.014234
 >> iter 3000, loss: 6.955866
 >> iter 4000, loss: 3.512509
 >> iter 5000, loss: 1.554287
 >> iter 6000, loss: 0.851384
 >> iter 7000, loss: 0.552870
 >> iter 8000, loss: 0.312622
 >> iter 9000, loss: 0.300995
 >> iter 10000, loss: 0.366690
   Number of active neurons: 11
 >> iter 11000, loss: 0.338787
 >> iter 12000, loss: 0.341840
 >> iter 13000, loss: 0.380082
 >> iter 14000, loss: 0.294961
 >> iter 15000, loss: 0.328598
 >> iter 16000, loss: 0.276716
 >> iter 17000, loss: 0.216481
 >> iter 18000, loss: 0.253779
 >> iter 19000, loss: 0.296748
 >> iter 20000, loss: 0.330645
   Number of active neurons: 10
 >> iter 21000, loss: 0.235134
 >> iter 22000, loss: 0.237704
 >> iter 23000, loss: 0.326510
 >> iter 24000, loss: 0.232822
 >> iter 25000, loss: 0.418685
 >> iter 26000, loss: 0.278412
 >> iter 27000, loss: 0.275387
 >> iter 28000, loss: 0.302551
 >> iter 29000, loss: 0.244912
 >> iter 30000, loss: 0.238193
   Number of active neurons: 10
 >> iter 31000, loss: 0.209549
 >> iter 32000, loss: 0.213866
 >> iter 33000, loss: 0.244596
 >> iter 34000, loss: 0.294598
 >> iter 35000, loss: 0.245790
 >> iter 36000, loss: 0.238353
 >> iter 37000, loss: 0.211228
 >> iter 38000, loss: 0.209375
 >> iter 39000, loss: 0.253178
 >> iter 40000, loss: 0.287183
   Number of active neurons: 10
 >> iter 41000, loss: 0.434649
 >> iter 42000, loss: 0.263127
 >> iter 43000, loss: 0.188689
 >> iter 44000, loss: 0.279386
 >> iter 45000, loss: 0.281430
 >> iter 46000, loss: 0.193233
 >> iter 47000, loss: 0.217035
 >> iter 48000, loss: 0.174430
 >> iter 49000, loss: 0.301289
 >> iter 50000, loss: 0.280433
   Number of active neurons: 10
 >> iter 51000, loss: 0.242109
 >> iter 52000, loss: 0.234041
 >> iter 53000, loss: 0.344507
 >> iter 54000, loss: 0.231313
 >> iter 55000, loss: 0.195760
 >> iter 56000, loss: 0.191742
 >> iter 57000, loss: 0.241499
 >> iter 58000, loss: 0.203980
 >> iter 59000, loss: 0.283410
 >> iter 60000, loss: 0.291569
   Number of active neurons: 10
 >> iter 61000, loss: 0.309940
 >> iter 62000, loss: 0.297678
 >> iter 63000, loss: 0.238789
 >> iter 64000, loss: 0.216024
 >> iter 65000, loss: 0.229778
 >> iter 66000, loss: 0.233098
 >> iter 67000, loss: 0.435287
 >> iter 68000, loss: 0.326053
 >> iter 69000, loss: 0.345816
 >> iter 70000, loss: 0.358341
   Number of active neurons: 10
 >> iter 71000, loss: 0.241011
 >> iter 72000, loss: 0.188700
 >> iter 73000, loss: 0.244645
 >> iter 74000, loss: 0.320740
 >> iter 75000, loss: 0.356537
 >> iter 76000, loss: 0.250044
 >> iter 77000, loss: 0.321597
 >> iter 78000, loss: 0.331348
 >> iter 79000, loss: 0.255539
 >> iter 80000, loss: 0.277057
   Number of active neurons: 9
 >> iter 81000, loss: 0.259938
 >> iter 82000, loss: 0.298312
 >> iter 83000, loss: 0.391849
 >> iter 84000, loss: 0.287105
 >> iter 85000, loss: 0.331441
 >> iter 86000, loss: 0.350167
 >> iter 87000, loss: 0.333753
 >> iter 88000, loss: 0.307399
 >> iter 89000, loss: 0.275993
 >> iter 90000, loss: 0.303092
   Number of active neurons: 9
 >> iter 91000, loss: 0.227665
 >> iter 92000, loss: 0.207183
 >> iter 93000, loss: 0.260263
 >> iter 94000, loss: 0.199831
 >> iter 95000, loss: 0.272620
 >> iter 96000, loss: 0.245337
 >> iter 97000, loss: 0.334431
 >> iter 98000, loss: 0.327806
 >> iter 99000, loss: 0.291543
 >> iter 100000, loss: 0.284727
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.655509
 >> iter 2000, loss: 9.739443
 >> iter 3000, loss: 6.245908
 >> iter 4000, loss: 2.922120
 >> iter 5000, loss: 1.428283
 >> iter 6000, loss: 0.830163
 >> iter 7000, loss: 0.622796
 >> iter 8000, loss: 0.387065
 >> iter 9000, loss: 0.561910
 >> iter 10000, loss: 0.453879
   Number of active neurons: 12
 >> iter 11000, loss: 0.520555
 >> iter 12000, loss: 0.398960
 >> iter 13000, loss: 0.399982
 >> iter 14000, loss: 0.522441
 >> iter 15000, loss: 0.475542
 >> iter 16000, loss: 0.399556
 >> iter 17000, loss: 0.444394
 >> iter 18000, loss: 0.368914
 >> iter 19000, loss: 0.303599
 >> iter 20000, loss: 0.335508
   Number of active neurons: 11
 >> iter 21000, loss: 0.322095
 >> iter 22000, loss: 0.350315
 >> iter 23000, loss: 0.376680
 >> iter 24000, loss: 0.478898
 >> iter 25000, loss: 0.316502
 >> iter 26000, loss: 0.422817
 >> iter 27000, loss: 0.302491
 >> iter 28000, loss: 0.391320
 >> iter 29000, loss: 0.295064
 >> iter 30000, loss: 0.485759
   Number of active neurons: 11
 >> iter 31000, loss: 0.416058
 >> iter 32000, loss: 0.414535
 >> iter 33000, loss: 0.499629
 >> iter 34000, loss: 0.472315
 >> iter 35000, loss: 0.553009
 >> iter 36000, loss: 0.500573
 >> iter 37000, loss: 0.400105
 >> iter 38000, loss: 0.352028
 >> iter 39000, loss: 0.410341
 >> iter 40000, loss: 0.401765
   Number of active neurons: 9
 >> iter 41000, loss: 0.405761
 >> iter 42000, loss: 0.392361
 >> iter 43000, loss: 0.393493
 >> iter 44000, loss: 0.375816
 >> iter 45000, loss: 0.357383
 >> iter 46000, loss: 0.390252
 >> iter 47000, loss: 0.327190
 >> iter 48000, loss: 0.329302
 >> iter 49000, loss: 0.321724
 >> iter 50000, loss: 0.340933
   Number of active neurons: 8
 >> iter 51000, loss: 0.399763
 >> iter 52000, loss: 0.300771
 >> iter 53000, loss: 0.405662
 >> iter 54000, loss: 0.314125
 >> iter 55000, loss: 0.298922
 >> iter 56000, loss: 0.308290
 >> iter 57000, loss: 0.388126
 >> iter 58000, loss: 0.310945
 >> iter 59000, loss: 0.318212
 >> iter 60000, loss: 0.477249
   Number of active neurons: 7
 >> iter 61000, loss: 0.334866
 >> iter 62000, loss: 0.298154
 >> iter 63000, loss: 0.337976
 >> iter 64000, loss: 0.247177
 >> iter 65000, loss: 0.316027
 >> iter 66000, loss: 0.289311
 >> iter 67000, loss: 0.354471
 >> iter 68000, loss: 0.254220
 >> iter 69000, loss: 0.215065
 >> iter 70000, loss: 0.271741
   Number of active neurons: 7
 >> iter 71000, loss: 0.271201
 >> iter 72000, loss: 0.347038
 >> iter 73000, loss: 0.233796
 >> iter 74000, loss: 0.279172
 >> iter 75000, loss: 0.242975
 >> iter 76000, loss: 0.259325
 >> iter 77000, loss: 0.256016
 >> iter 78000, loss: 0.243471
 >> iter 79000, loss: 0.295693
 >> iter 80000, loss: 0.330882
   Number of active neurons: 7
 >> iter 81000, loss: 0.265353
 >> iter 82000, loss: 0.336938
 >> iter 83000, loss: 0.361344
 >> iter 84000, loss: 0.274508
 >> iter 85000, loss: 0.248747
 >> iter 86000, loss: 0.300100
 >> iter 87000, loss: 0.261461
 >> iter 88000, loss: 0.305301
 >> iter 89000, loss: 0.260984
 >> iter 90000, loss: 0.253554
   Number of active neurons: 7
 >> iter 91000, loss: 0.253424
 >> iter 92000, loss: 0.265425
 >> iter 93000, loss: 0.365051
 >> iter 94000, loss: 0.257434
 >> iter 95000, loss: 0.266210
 >> iter 96000, loss: 0.225540
 >> iter 97000, loss: 0.251414
 >> iter 98000, loss: 0.273156
 >> iter 99000, loss: 0.262235
 >> iter 100000, loss: 0.274679
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.655289
 >> iter 2000, loss: 9.595137
 >> iter 3000, loss: 5.513286
 >> iter 4000, loss: 2.998004
 >> iter 5000, loss: 1.710332
 >> iter 6000, loss: 1.061560
 >> iter 7000, loss: 0.776132
 >> iter 8000, loss: 0.651373
 >> iter 9000, loss: 0.655755
 >> iter 10000, loss: 0.536917
   Number of active neurons: 7
 >> iter 11000, loss: 0.556565
 >> iter 12000, loss: 0.525660
 >> iter 13000, loss: 0.585638
 >> iter 14000, loss: 0.360262
 >> iter 15000, loss: 0.315207
 >> iter 16000, loss: 0.259238
 >> iter 17000, loss: 0.254702
 >> iter 18000, loss: 0.285828
 >> iter 19000, loss: 0.222545
 >> iter 20000, loss: 0.256705
   Number of active neurons: 7
 >> iter 21000, loss: 0.353764
 >> iter 22000, loss: 0.347429
 >> iter 23000, loss: 0.375657
 >> iter 24000, loss: 0.413321
 >> iter 25000, loss: 0.277870
 >> iter 26000, loss: 0.358333
 >> iter 27000, loss: 0.424122
 >> iter 28000, loss: 0.378574
 >> iter 29000, loss: 0.356569
 >> iter 30000, loss: 0.338945
   Number of active neurons: 7
 >> iter 31000, loss: 0.352588
 >> iter 32000, loss: 0.384052
 >> iter 33000, loss: 0.424854
 >> iter 34000, loss: 0.387277
 >> iter 35000, loss: 0.416674
 >> iter 36000, loss: 0.302787
 >> iter 37000, loss: 0.312797
 >> iter 38000, loss: 0.414139
 >> iter 39000, loss: 0.348935
 >> iter 40000, loss: 0.329701
   Number of active neurons: 7
 >> iter 41000, loss: 0.430696
 >> iter 42000, loss: 0.455204
 >> iter 43000, loss: 0.399553
 >> iter 44000, loss: 0.324972
 >> iter 45000, loss: 0.369684
 >> iter 46000, loss: 0.415009
 >> iter 47000, loss: 0.419086
 >> iter 48000, loss: 0.405115
 >> iter 49000, loss: 0.336926
 >> iter 50000, loss: 0.338234
   Number of active neurons: 7
 >> iter 51000, loss: 0.315694
 >> iter 52000, loss: 0.262448
 >> iter 53000, loss: 0.384251
 >> iter 54000, loss: 0.272435
 >> iter 55000, loss: 0.315129
 >> iter 56000, loss: 0.306249
 >> iter 57000, loss: 0.337654
 >> iter 58000, loss: 0.346153
 >> iter 59000, loss: 0.255792
 >> iter 60000, loss: 0.215798
   Number of active neurons: 7
 >> iter 61000, loss: 0.334509
 >> iter 62000, loss: 0.292734
 >> iter 63000, loss: 0.298713
 >> iter 64000, loss: 0.261704
 >> iter 65000, loss: 0.318686
 >> iter 66000, loss: 0.277317
 >> iter 67000, loss: 0.401956
 >> iter 68000, loss: 0.313659
 >> iter 69000, loss: 0.316709
 >> iter 70000, loss: 0.323914
   Number of active neurons: 6
 >> iter 71000, loss: 0.300853
 >> iter 72000, loss: 0.256978
 >> iter 73000, loss: 0.275886
 >> iter 74000, loss: 0.283344
 >> iter 75000, loss: 0.303310
 >> iter 76000, loss: 0.315691
 >> iter 77000, loss: 0.281606
 >> iter 78000, loss: 0.210536
 >> iter 79000, loss: 0.220416
 >> iter 80000, loss: 0.235603
   Number of active neurons: 7
 >> iter 81000, loss: 0.296392
 >> iter 82000, loss: 0.226374
 >> iter 83000, loss: 0.329859
 >> iter 84000, loss: 0.320005
 >> iter 85000, loss: 0.258466
 >> iter 86000, loss: 0.248895
 >> iter 87000, loss: 0.315869
 >> iter 88000, loss: 0.283804
 >> iter 89000, loss: 0.237745
 >> iter 90000, loss: 0.296311
   Number of active neurons: 6
 >> iter 91000, loss: 0.267177
 >> iter 92000, loss: 0.263545
 >> iter 93000, loss: 0.436271
 >> iter 94000, loss: 0.338805
 >> iter 95000, loss: 0.360879
 >> iter 96000, loss: 0.272311
 >> iter 97000, loss: 0.321319
 >> iter 98000, loss: 0.241658
 >> iter 99000, loss: 0.297096
 >> iter 100000, loss: 0.301558
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.479832
 >> iter 2000, loss: 10.651462
 >> iter 3000, loss: 6.519023
 >> iter 4000, loss: 2.980332
 >> iter 5000, loss: 1.397367
 >> iter 6000, loss: 0.862850
 >> iter 7000, loss: 0.554331
 >> iter 8000, loss: 0.388303
 >> iter 9000, loss: 0.272629
 >> iter 10000, loss: 0.234221
   Number of active neurons: 8
 >> iter 11000, loss: 0.281540
 >> iter 12000, loss: 0.237499
 >> iter 13000, loss: 0.364797
 >> iter 14000, loss: 0.231930
 >> iter 15000, loss: 0.187710
 >> iter 16000, loss: 0.184124
 >> iter 17000, loss: 0.308697
 >> iter 18000, loss: 0.261482
 >> iter 19000, loss: 0.213548
 >> iter 20000, loss: 0.221045
   Number of active neurons: 8
 >> iter 21000, loss: 0.164817
 >> iter 22000, loss: 0.120810
 >> iter 23000, loss: 0.175849
 >> iter 24000, loss: 0.170887
 >> iter 25000, loss: 0.294401
 >> iter 26000, loss: 0.211506
 >> iter 27000, loss: 0.241098
 >> iter 28000, loss: 0.160568
 >> iter 29000, loss: 0.243266
 >> iter 30000, loss: 0.285980
   Number of active neurons: 7
 >> iter 31000, loss: 0.286291
 >> iter 32000, loss: 0.250931
 >> iter 33000, loss: 0.276385
 >> iter 34000, loss: 0.345690
 >> iter 35000, loss: 0.235984
 >> iter 36000, loss: 0.161515
 >> iter 37000, loss: 0.258762
 >> iter 38000, loss: 0.229665
 >> iter 39000, loss: 0.266813
 >> iter 40000, loss: 0.207289
   Number of active neurons: 7
 >> iter 41000, loss: 0.199158
 >> iter 42000, loss: 0.302964
 >> iter 43000, loss: 0.261125
 >> iter 44000, loss: 0.216350
 >> iter 45000, loss: 0.226561
 >> iter 46000, loss: 0.241969
 >> iter 47000, loss: 0.250575
 >> iter 48000, loss: 0.184904
 >> iter 49000, loss: 0.282170
 >> iter 50000, loss: 0.212912
   Number of active neurons: 7
 >> iter 51000, loss: 0.324681
 >> iter 52000, loss: 0.283779
 >> iter 53000, loss: 0.301050
 >> iter 54000, loss: 0.299757
 >> iter 55000, loss: 0.273048
 >> iter 56000, loss: 0.265210
 >> iter 57000, loss: 0.242363
 >> iter 58000, loss: 0.255961
 >> iter 59000, loss: 0.245287
 >> iter 60000, loss: 0.254043
   Number of active neurons: 7
 >> iter 61000, loss: 0.293253
 >> iter 62000, loss: 0.210671
 >> iter 63000, loss: 0.264285
 >> iter 64000, loss: 0.324073
 >> iter 65000, loss: 0.306651
 >> iter 66000, loss: 0.329708
 >> iter 67000, loss: 0.353784
 >> iter 68000, loss: 0.278483
 >> iter 69000, loss: 0.253103
 >> iter 70000, loss: 0.452814
   Number of active neurons: 7
 >> iter 71000, loss: 0.362818
 >> iter 72000, loss: 0.334539
 >> iter 73000, loss: 0.315433
 >> iter 74000, loss: 0.287061
 >> iter 75000, loss: 0.264955
 >> iter 76000, loss: 0.274619
 >> iter 77000, loss: 0.283892
 >> iter 78000, loss: 0.257359
 >> iter 79000, loss: 0.319705
 >> iter 80000, loss: 0.299206
   Number of active neurons: 7
 >> iter 81000, loss: 0.237634
 >> iter 82000, loss: 0.306705
 >> iter 83000, loss: 0.270167
 >> iter 84000, loss: 0.197831
 >> iter 85000, loss: 0.232871
 >> iter 86000, loss: 0.264237
 >> iter 87000, loss: 0.332936
 >> iter 88000, loss: 0.359291
 >> iter 89000, loss: 0.347207
 >> iter 90000, loss: 0.394158
   Number of active neurons: 7
 >> iter 91000, loss: 0.328344
 >> iter 92000, loss: 0.276453
 >> iter 93000, loss: 0.340868
 >> iter 94000, loss: 0.410800
 >> iter 95000, loss: 0.256914
 >> iter 96000, loss: 0.279780
 >> iter 97000, loss: 0.349673
 >> iter 98000, loss: 0.302819
 >> iter 99000, loss: 0.333151
 >> iter 100000, loss: 0.300972
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.434559
 >> iter 2000, loss: 9.820823
 >> iter 3000, loss: 5.861342
 >> iter 4000, loss: 2.809521
 >> iter 5000, loss: 1.369478
 >> iter 6000, loss: 0.839576
 >> iter 7000, loss: 0.569931
 >> iter 8000, loss: 0.427619
 >> iter 9000, loss: 0.356167
 >> iter 10000, loss: 0.368435
   Number of active neurons: 9
 >> iter 11000, loss: 0.432431
 >> iter 12000, loss: 0.355526
 >> iter 13000, loss: 0.395631
 >> iter 14000, loss: 0.358357
 >> iter 15000, loss: 0.412887
 >> iter 16000, loss: 0.417454
 >> iter 17000, loss: 0.360368
 >> iter 18000, loss: 0.417477
 >> iter 19000, loss: 0.435801
 >> iter 20000, loss: 0.482265
   Number of active neurons: 9
 >> iter 21000, loss: 0.368012
 >> iter 22000, loss: 0.287814
 >> iter 23000, loss: 0.232849
 >> iter 24000, loss: 0.216056
 >> iter 25000, loss: 0.283654
 >> iter 26000, loss: 0.207199
 >> iter 27000, loss: 0.179057
 >> iter 28000, loss: 0.230723
 >> iter 29000, loss: 0.177272
 >> iter 30000, loss: 0.191401
   Number of active neurons: 9
 >> iter 31000, loss: 0.253824
 >> iter 32000, loss: 0.205037
 >> iter 33000, loss: 0.301400
 >> iter 34000, loss: 0.205529
 >> iter 35000, loss: 0.161476
 >> iter 36000, loss: 0.232525
 >> iter 37000, loss: 0.210690
 >> iter 38000, loss: 0.225671
 >> iter 39000, loss: 0.170213
 >> iter 40000, loss: 0.248399
   Number of active neurons: 9
 >> iter 41000, loss: 0.247521
 >> iter 42000, loss: 0.230127
 >> iter 43000, loss: 0.164888
 >> iter 44000, loss: 0.175890
 >> iter 45000, loss: 0.238703
 >> iter 46000, loss: 0.228814
 >> iter 47000, loss: 0.238564
 >> iter 48000, loss: 0.225810
 >> iter 49000, loss: 0.303030
 >> iter 50000, loss: 0.298432
   Number of active neurons: 9
 >> iter 51000, loss: 0.380503
 >> iter 52000, loss: 0.197176
 >> iter 53000, loss: 0.195700
 >> iter 54000, loss: 0.252371
 >> iter 55000, loss: 0.277887
 >> iter 56000, loss: 0.207136
 >> iter 57000, loss: 0.308591
 >> iter 58000, loss: 0.298424
 >> iter 59000, loss: 0.398974
 >> iter 60000, loss: 0.295716
   Number of active neurons: 9
 >> iter 61000, loss: 0.290256
 >> iter 62000, loss: 0.312814
 >> iter 63000, loss: 0.293059
 >> iter 64000, loss: 0.364057
 >> iter 65000, loss: 0.367687
 >> iter 66000, loss: 0.318029
 >> iter 67000, loss: 0.285802
 >> iter 68000, loss: 0.307519
 >> iter 69000, loss: 0.243986
 >> iter 70000, loss: 0.244004
   Number of active neurons: 8
 >> iter 71000, loss: 0.321948
 >> iter 72000, loss: 0.310290
 >> iter 73000, loss: 0.299007
 >> iter 74000, loss: 0.199725
 >> iter 75000, loss: 0.232953
 >> iter 76000, loss: 0.308459
 >> iter 77000, loss: 0.308137
 >> iter 78000, loss: 0.294880
 >> iter 79000, loss: 0.248646
 >> iter 80000, loss: 0.267384
   Number of active neurons: 8
 >> iter 81000, loss: 0.400140
 >> iter 82000, loss: 0.300519
 >> iter 83000, loss: 0.355162
 >> iter 84000, loss: 0.464476
 >> iter 85000, loss: 0.308648
 >> iter 86000, loss: 0.272928
 >> iter 87000, loss: 0.243812
 >> iter 88000, loss: 0.299490
 >> iter 89000, loss: 0.313042
 >> iter 90000, loss: 0.278584
   Number of active neurons: 8
 >> iter 91000, loss: 0.228984
 >> iter 92000, loss: 0.217615
 >> iter 93000, loss: 0.261843
 >> iter 94000, loss: 0.357672
 >> iter 95000, loss: 0.312560
 >> iter 96000, loss: 0.234787
 >> iter 97000, loss: 0.184636
 >> iter 98000, loss: 0.287723
 >> iter 99000, loss: 0.343301
 >> iter 100000, loss: 0.272169
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.060503
 >> iter 2000, loss: 10.514975
 >> iter 3000, loss: 5.853676
 >> iter 4000, loss: 2.568205
 >> iter 5000, loss: 1.188444
 >> iter 6000, loss: 0.683648
 >> iter 7000, loss: 0.383364
 >> iter 8000, loss: 0.310851
 >> iter 9000, loss: 0.267341
 >> iter 10000, loss: 0.326373
   Number of active neurons: 11
 >> iter 11000, loss: 0.262065
 >> iter 12000, loss: 0.245488
 >> iter 13000, loss: 0.247381
 >> iter 14000, loss: 0.284053
 >> iter 15000, loss: 0.328170
 >> iter 16000, loss: 0.283010
 >> iter 17000, loss: 0.310650
 >> iter 18000, loss: 0.318408
 >> iter 19000, loss: 0.239802
 >> iter 20000, loss: 0.210215
   Number of active neurons: 9
 >> iter 21000, loss: 0.206823
 >> iter 22000, loss: 0.289652
 >> iter 23000, loss: 0.399267
 >> iter 24000, loss: 0.267415
 >> iter 25000, loss: 0.190258
 >> iter 26000, loss: 0.164233
 >> iter 27000, loss: 0.162122
 >> iter 28000, loss: 0.285938
 >> iter 29000, loss: 0.290138
 >> iter 30000, loss: 0.253657
   Number of active neurons: 8
 >> iter 31000, loss: 0.262469
 >> iter 32000, loss: 0.187880
 >> iter 33000, loss: 0.220098
 >> iter 34000, loss: 0.185571
 >> iter 35000, loss: 0.174031
 >> iter 36000, loss: 0.219698
 >> iter 37000, loss: 0.277174
 >> iter 38000, loss: 0.334735
 >> iter 39000, loss: 0.357774
 >> iter 40000, loss: 0.364213
   Number of active neurons: 8
 >> iter 41000, loss: 0.287449
 >> iter 42000, loss: 0.289282
 >> iter 43000, loss: 0.327533
 >> iter 44000, loss: 0.258542
 >> iter 45000, loss: 0.306705
 >> iter 46000, loss: 0.315443
 >> iter 47000, loss: 0.297975
 >> iter 48000, loss: 0.302718
 >> iter 49000, loss: 0.467086
 >> iter 50000, loss: 0.350950
   Number of active neurons: 7
 >> iter 51000, loss: 0.407036
 >> iter 52000, loss: 0.425519
 >> iter 53000, loss: 0.335216
 >> iter 54000, loss: 0.335037
 >> iter 55000, loss: 0.287613
 >> iter 56000, loss: 0.186576
 >> iter 57000, loss: 0.374243
 >> iter 58000, loss: 0.351110
 >> iter 59000, loss: 0.269157
 >> iter 60000, loss: 0.235749
   Number of active neurons: 7
 >> iter 61000, loss: 0.339186
 >> iter 62000, loss: 0.353126
 >> iter 63000, loss: 0.405839
 >> iter 64000, loss: 0.264640
 >> iter 65000, loss: 0.346500
 >> iter 66000, loss: 0.359847
 >> iter 67000, loss: 0.264686
 >> iter 68000, loss: 0.229120
 >> iter 69000, loss: 0.278031
 >> iter 70000, loss: 0.221118
   Number of active neurons: 7
 >> iter 71000, loss: 0.276088
 >> iter 72000, loss: 0.193302
 >> iter 73000, loss: 0.232988
 >> iter 74000, loss: 0.386077
 >> iter 75000, loss: 0.431529
 >> iter 76000, loss: 0.354246
 >> iter 77000, loss: 0.386540
 >> iter 78000, loss: 0.344896
 >> iter 79000, loss: 0.237664
 >> iter 80000, loss: 0.279996
   Number of active neurons: 7
 >> iter 81000, loss: 0.378345
 >> iter 82000, loss: 0.468633
 >> iter 83000, loss: 0.279263
 >> iter 84000, loss: 0.316741
 >> iter 85000, loss: 0.274764
 >> iter 86000, loss: 0.220599
 >> iter 87000, loss: 0.457761
 >> iter 88000, loss: 0.323244
 >> iter 89000, loss: 0.295235
 >> iter 90000, loss: 0.218504
   Number of active neurons: 6
 >> iter 91000, loss: 0.401744
 >> iter 92000, loss: 0.261313
 >> iter 93000, loss: 0.274683
 >> iter 94000, loss: 0.213706
 >> iter 95000, loss: 0.268143
 >> iter 96000, loss: 0.300190
 >> iter 97000, loss: 0.359857
 >> iter 98000, loss: 0.298189
 >> iter 99000, loss: 0.212633
 >> iter 100000, loss: 0.272358
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.332164
 >> iter 2000, loss: 10.366375
 >> iter 3000, loss: 5.785491
 >> iter 4000, loss: 3.021240
 >> iter 5000, loss: 1.906245
 >> iter 6000, loss: 1.233060
 >> iter 7000, loss: 0.789839
 >> iter 8000, loss: 0.643721
 >> iter 9000, loss: 0.591972
 >> iter 10000, loss: 0.590756
   Number of active neurons: 6
 >> iter 11000, loss: 0.626408
 >> iter 12000, loss: 0.423892
 >> iter 13000, loss: 0.516811
 >> iter 14000, loss: 0.432162
 >> iter 15000, loss: 0.644488
 >> iter 16000, loss: 0.515178
 >> iter 17000, loss: 0.355930
 >> iter 18000, loss: 0.398445
 >> iter 19000, loss: 0.546506
 >> iter 20000, loss: 0.472295
   Number of active neurons: 6
 >> iter 21000, loss: 0.481608
 >> iter 22000, loss: 0.405259
 >> iter 23000, loss: 0.377327
 >> iter 24000, loss: 0.352837
 >> iter 25000, loss: 0.526562
 >> iter 26000, loss: 0.474821
 >> iter 27000, loss: 0.461337
 >> iter 28000, loss: 0.467359
 >> iter 29000, loss: 0.475503
 >> iter 30000, loss: 0.458940
   Number of active neurons: 6
 >> iter 31000, loss: 0.411482
 >> iter 32000, loss: 0.432455
 >> iter 33000, loss: 0.385417
 >> iter 34000, loss: 0.372269
 >> iter 35000, loss: 0.402784
 >> iter 36000, loss: 0.368761
 >> iter 37000, loss: 0.497682
 >> iter 38000, loss: 0.563397
 >> iter 39000, loss: 0.659228
 >> iter 40000, loss: 0.547512
   Number of active neurons: 5
 >> iter 41000, loss: 0.462251
 >> iter 42000, loss: 0.374228
 >> iter 43000, loss: 0.376760
 >> iter 44000, loss: 0.400201
 >> iter 45000, loss: 0.407077
 >> iter 46000, loss: 0.333587
 >> iter 47000, loss: 0.462958
 >> iter 48000, loss: 0.350754
 >> iter 49000, loss: 0.533231
 >> iter 50000, loss: 0.424686
   Number of active neurons: 5
 >> iter 51000, loss: 0.491200
 >> iter 52000, loss: 0.423219
 >> iter 53000, loss: 0.435110
 >> iter 54000, loss: 0.572328
 >> iter 55000, loss: 0.455403
 >> iter 56000, loss: 0.417497
 >> iter 57000, loss: 0.445801
 >> iter 58000, loss: 0.432084
 >> iter 59000, loss: 0.534414
 >> iter 60000, loss: 0.372417
   Number of active neurons: 5
 >> iter 61000, loss: 0.385096
 >> iter 62000, loss: 0.388810
 >> iter 63000, loss: 0.433748
 >> iter 64000, loss: 0.481622
 >> iter 65000, loss: 0.411432
 >> iter 66000, loss: 0.485517
 >> iter 67000, loss: 0.654426
 >> iter 68000, loss: 0.637833
 >> iter 69000, loss: 0.516028
 >> iter 70000, loss: 0.460290
   Number of active neurons: 4
 >> iter 71000, loss: 0.540751
 >> iter 72000, loss: 0.511641
 >> iter 73000, loss: 0.554150
 >> iter 74000, loss: 0.515100
 >> iter 75000, loss: 0.615533
 >> iter 76000, loss: 0.521679
 >> iter 77000, loss: 0.489723
 >> iter 78000, loss: 0.517739
 >> iter 79000, loss: 0.532781
 >> iter 80000, loss: 0.368528
   Number of active neurons: 5
 >> iter 81000, loss: 0.447011
 >> iter 82000, loss: 0.474665
 >> iter 83000, loss: 0.462333
 >> iter 84000, loss: 0.420771
 >> iter 85000, loss: 0.489259
 >> iter 86000, loss: 0.517079
 >> iter 87000, loss: 0.447559
 >> iter 88000, loss: 0.635188
 >> iter 89000, loss: 0.419330
 >> iter 90000, loss: 0.546125
   Number of active neurons: 4
 >> iter 91000, loss: 0.522063
 >> iter 92000, loss: 0.393648
 >> iter 93000, loss: 0.483925
 >> iter 94000, loss: 0.358916
 >> iter 95000, loss: 0.364847
 >> iter 96000, loss: 0.488000
 >> iter 97000, loss: 0.394690
 >> iter 98000, loss: 0.549584
 >> iter 99000, loss: 0.475337
 >> iter 100000, loss: 0.518199
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.039238
 >> iter 2000, loss: 9.846806
 >> iter 3000, loss: 5.349176
 >> iter 4000, loss: 2.809160
 >> iter 5000, loss: 1.624828
 >> iter 6000, loss: 1.068067
 >> iter 7000, loss: 0.803759
 >> iter 8000, loss: 0.799943
 >> iter 9000, loss: 0.679939
 >> iter 10000, loss: 0.659982
   Number of active neurons: 5
 >> iter 11000, loss: 0.645065
 >> iter 12000, loss: 0.645561
 >> iter 13000, loss: 0.777145
 >> iter 14000, loss: 0.866416
 >> iter 15000, loss: 0.708810
 >> iter 16000, loss: 0.559683
 >> iter 17000, loss: 0.712290
 >> iter 18000, loss: 0.543911
 >> iter 19000, loss: 0.662205
 >> iter 20000, loss: 0.569901
   Number of active neurons: 5
 >> iter 21000, loss: 0.555713
 >> iter 22000, loss: 0.404201
 >> iter 23000, loss: 0.590145
 >> iter 24000, loss: 0.531522
 >> iter 25000, loss: 0.455015
 >> iter 26000, loss: 0.560438
 >> iter 27000, loss: 0.782300
 >> iter 28000, loss: 0.662371
 >> iter 29000, loss: 0.490645
 >> iter 30000, loss: 0.417905
   Number of active neurons: 5
 >> iter 31000, loss: 0.605244
 >> iter 32000, loss: 0.582171
 >> iter 33000, loss: 0.562267
 >> iter 34000, loss: 0.509972
 >> iter 35000, loss: 0.323523
 >> iter 36000, loss: 0.420082
 >> iter 37000, loss: 0.441485
 >> iter 38000, loss: 0.494921
 >> iter 39000, loss: 0.566027
 >> iter 40000, loss: 0.477404
   Number of active neurons: 5
 >> iter 41000, loss: 0.531025
 >> iter 42000, loss: 0.416104
 >> iter 43000, loss: 0.525064
 >> iter 44000, loss: 0.527322
 >> iter 45000, loss: 0.478134
 >> iter 46000, loss: 0.389709
 >> iter 47000, loss: 0.334925
 >> iter 48000, loss: 0.434739
 >> iter 49000, loss: 0.575836
 >> iter 50000, loss: 0.506240
   Number of active neurons: 5
 >> iter 51000, loss: 0.683342
 >> iter 52000, loss: 0.440632
 >> iter 53000, loss: 0.456954
 >> iter 54000, loss: 0.444455
 >> iter 55000, loss: 0.476642
 >> iter 56000, loss: 0.459619
 >> iter 57000, loss: 0.383525
 >> iter 58000, loss: 0.408221
 >> iter 59000, loss: 0.717066
 >> iter 60000, loss: 0.544646
   Number of active neurons: 5
 >> iter 61000, loss: 0.522703
 >> iter 62000, loss: 0.451942
 >> iter 63000, loss: 0.340898
 >> iter 64000, loss: 0.389082
 >> iter 65000, loss: 0.471047
 >> iter 66000, loss: 0.575766
 >> iter 67000, loss: 0.473811
 >> iter 68000, loss: 0.341147
 >> iter 69000, loss: 0.373258
 >> iter 70000, loss: 0.478088
   Number of active neurons: 5
 >> iter 71000, loss: 0.385259
 >> iter 72000, loss: 0.472344
 >> iter 73000, loss: 0.506059
 >> iter 74000, loss: 0.438101
 >> iter 75000, loss: 0.532127
 >> iter 76000, loss: 0.442060
 >> iter 77000, loss: 0.617394
 >> iter 78000, loss: 0.536310
 >> iter 79000, loss: 0.415916
 >> iter 80000, loss: 0.453132
   Number of active neurons: 5
 >> iter 81000, loss: 0.701649
 >> iter 82000, loss: 0.493588
 >> iter 83000, loss: 0.405362
 >> iter 84000, loss: 0.414635
 >> iter 85000, loss: 0.382970
 >> iter 86000, loss: 0.471221
 >> iter 87000, loss: 0.441087
 >> iter 88000, loss: 0.438757
 >> iter 89000, loss: 0.398689
 >> iter 90000, loss: 0.358061
   Number of active neurons: 5
 >> iter 91000, loss: 0.326601
 >> iter 92000, loss: 0.370758
 >> iter 93000, loss: 0.338537
 >> iter 94000, loss: 0.414843
 >> iter 95000, loss: 0.427190
 >> iter 96000, loss: 0.377796
 >> iter 97000, loss: 0.475380
 >> iter 98000, loss: 0.568110
 >> iter 99000, loss: 0.477891
 >> iter 100000, loss: 0.477199
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 16.543991
 >> iter 2000, loss: 9.365097
 >> iter 3000, loss: 5.030749
 >> iter 4000, loss: 2.669097
 >> iter 5000, loss: 1.661389
 >> iter 6000, loss: 1.129787
 >> iter 7000, loss: 0.728073
 >> iter 8000, loss: 0.600138
 >> iter 9000, loss: 0.694024
 >> iter 10000, loss: 0.509843
   Number of active neurons: 8
 >> iter 11000, loss: 0.547246
 >> iter 12000, loss: 0.505341
 >> iter 13000, loss: 0.409838
 >> iter 14000, loss: 0.449260
 >> iter 15000, loss: 0.347062
 >> iter 16000, loss: 0.272354
 >> iter 17000, loss: 0.379826
 >> iter 18000, loss: 0.328639
 >> iter 19000, loss: 0.348726
 >> iter 20000, loss: 0.378360
   Number of active neurons: 8
 >> iter 21000, loss: 0.320918
 >> iter 22000, loss: 0.329328
 >> iter 23000, loss: 0.321296
 >> iter 24000, loss: 0.360678
 >> iter 25000, loss: 0.410636
 >> iter 26000, loss: 0.372588
 >> iter 27000, loss: 0.298770
 >> iter 28000, loss: 0.270875
 >> iter 29000, loss: 0.368634
 >> iter 30000, loss: 0.333205
   Number of active neurons: 8
 >> iter 31000, loss: 0.249741
 >> iter 32000, loss: 0.285092
 >> iter 33000, loss: 0.312322
 >> iter 34000, loss: 0.308328
 >> iter 35000, loss: 0.294154
 >> iter 36000, loss: 0.324450
 >> iter 37000, loss: 0.367450
 >> iter 38000, loss: 0.303348
 >> iter 39000, loss: 0.333191
 >> iter 40000, loss: 0.538228
   Number of active neurons: 8
 >> iter 41000, loss: 0.456876
 >> iter 42000, loss: 0.331517
 >> iter 43000, loss: 0.391968
 >> iter 44000, loss: 0.313881
 >> iter 45000, loss: 0.264298
 >> iter 46000, loss: 0.296589
 >> iter 47000, loss: 0.276183
 >> iter 48000, loss: 0.251406
 >> iter 49000, loss: 0.326421
 >> iter 50000, loss: 0.384051
   Number of active neurons: 8
 >> iter 51000, loss: 0.345852
 >> iter 52000, loss: 0.335240
 >> iter 53000, loss: 0.256413
 >> iter 54000, loss: 0.244912
 >> iter 55000, loss: 0.267843
 >> iter 56000, loss: 0.354996
 >> iter 57000, loss: 0.327026
 >> iter 58000, loss: 0.274216
 >> iter 59000, loss: 0.273266
 >> iter 60000, loss: 0.275578
   Number of active neurons: 7
 >> iter 61000, loss: 0.355036
 >> iter 62000, loss: 0.305893
 >> iter 63000, loss: 0.247824
 >> iter 64000, loss: 0.359644
 >> iter 65000, loss: 0.331831
 >> iter 66000, loss: 0.374637
 >> iter 67000, loss: 0.417281
 >> iter 68000, loss: 0.265112
 >> iter 69000, loss: 0.217234
 >> iter 70000, loss: 0.239953
   Number of active neurons: 7
 >> iter 71000, loss: 0.245430
 >> iter 72000, loss: 0.295142
 >> iter 73000, loss: 0.350392
 >> iter 74000, loss: 0.305159
 >> iter 75000, loss: 0.285149
 >> iter 76000, loss: 0.296316
 >> iter 77000, loss: 0.264123
 >> iter 78000, loss: 0.279047
 >> iter 79000, loss: 0.246225
 >> iter 80000, loss: 0.181174
   Number of active neurons: 7
 >> iter 81000, loss: 0.234885
 >> iter 82000, loss: 0.226318
 >> iter 83000, loss: 0.357792
 >> iter 84000, loss: 0.312485
 >> iter 85000, loss: 0.266344
 >> iter 86000, loss: 0.361835
 >> iter 87000, loss: 0.282940
 >> iter 88000, loss: 0.228379
 >> iter 89000, loss: 0.191727
 >> iter 90000, loss: 0.205503
   Number of active neurons: 7
 >> iter 91000, loss: 0.279256
 >> iter 92000, loss: 0.340801
 >> iter 93000, loss: 0.411592
 >> iter 94000, loss: 0.375291
 >> iter 95000, loss: 0.248446
 >> iter 96000, loss: 0.280027
 >> iter 97000, loss: 0.264222
 >> iter 98000, loss: 0.207625
 >> iter 99000, loss: 0.227036
 >> iter 100000, loss: 0.221763
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.243385
 >> iter 2000, loss: 9.155811
 >> iter 3000, loss: 4.356407
 >> iter 4000, loss: 1.942382
 >> iter 5000, loss: 0.939297
 >> iter 6000, loss: 0.631528
 >> iter 7000, loss: 0.379159
 >> iter 8000, loss: 0.297509
 >> iter 9000, loss: 0.396137
 >> iter 10000, loss: 0.256901
   Number of active neurons: 10
 >> iter 11000, loss: 0.344104
 >> iter 12000, loss: 0.326050
 >> iter 13000, loss: 0.322571
 >> iter 14000, loss: 0.331667
 >> iter 15000, loss: 0.287936
 >> iter 16000, loss: 0.363047
 >> iter 17000, loss: 0.233625
 >> iter 18000, loss: 0.346126
 >> iter 19000, loss: 0.318042
 >> iter 20000, loss: 0.372968
   Number of active neurons: 10
 >> iter 21000, loss: 0.325902
 >> iter 22000, loss: 0.398576
 >> iter 23000, loss: 0.299437
 >> iter 24000, loss: 0.282098
 >> iter 25000, loss: 0.273369
 >> iter 26000, loss: 0.257821
 >> iter 27000, loss: 0.458741
 >> iter 28000, loss: 0.443220
 >> iter 29000, loss: 0.326195
 >> iter 30000, loss: 0.327236
   Number of active neurons: 10
 >> iter 31000, loss: 0.368133
 >> iter 32000, loss: 0.356961
 >> iter 33000, loss: 0.327345
 >> iter 34000, loss: 0.288321
 >> iter 35000, loss: 0.216852
 >> iter 36000, loss: 0.267849
 >> iter 37000, loss: 0.289917
 >> iter 38000, loss: 0.427686
 >> iter 39000, loss: 0.320715
 >> iter 40000, loss: 0.267557
   Number of active neurons: 10
 >> iter 41000, loss: 0.334006
 >> iter 42000, loss: 0.312579
 >> iter 43000, loss: 0.313952
 >> iter 44000, loss: 0.269584
 >> iter 45000, loss: 0.276905
 >> iter 46000, loss: 0.284620
 >> iter 47000, loss: 0.278550
 >> iter 48000, loss: 0.236775
 >> iter 49000, loss: 0.258669
 >> iter 50000, loss: 0.426782
   Number of active neurons: 9
 >> iter 51000, loss: 0.374502
 >> iter 52000, loss: 0.340520
 >> iter 53000, loss: 0.382216
 >> iter 54000, loss: 0.324551
 >> iter 55000, loss: 0.317436
 >> iter 56000, loss: 0.268426
 >> iter 57000, loss: 0.418246
 >> iter 58000, loss: 0.388647
 >> iter 59000, loss: 0.409246
 >> iter 60000, loss: 0.297650
   Number of active neurons: 9
 >> iter 61000, loss: 0.375345
 >> iter 62000, loss: 0.393371
 >> iter 63000, loss: 0.362362
 >> iter 64000, loss: 0.279136
 >> iter 65000, loss: 0.367010
 >> iter 66000, loss: 0.268452
 >> iter 67000, loss: 0.182162
 >> iter 68000, loss: 0.208444
 >> iter 69000, loss: 0.287779
 >> iter 70000, loss: 0.260359
   Number of active neurons: 9
 >> iter 71000, loss: 0.333807
 >> iter 72000, loss: 0.317432
 >> iter 73000, loss: 0.288440
 >> iter 74000, loss: 0.355404
 >> iter 75000, loss: 0.363650
 >> iter 76000, loss: 0.282793
 >> iter 77000, loss: 0.276770
 >> iter 78000, loss: 0.222267
 >> iter 79000, loss: 0.319922
 >> iter 80000, loss: 0.264894
   Number of active neurons: 9
 >> iter 81000, loss: 0.224140
 >> iter 82000, loss: 0.240736
 >> iter 83000, loss: 0.368277
 >> iter 84000, loss: 0.266242
 >> iter 85000, loss: 0.310603
 >> iter 86000, loss: 0.234521
 >> iter 87000, loss: 0.286645
 >> iter 88000, loss: 0.295274
 >> iter 89000, loss: 0.278604
 >> iter 90000, loss: 0.250939
   Number of active neurons: 9
 >> iter 91000, loss: 0.253669
 >> iter 92000, loss: 0.227896
 >> iter 93000, loss: 0.395567
 >> iter 94000, loss: 0.353494
 >> iter 95000, loss: 0.456972
 >> iter 96000, loss: 0.377871
 >> iter 97000, loss: 0.331896
 >> iter 98000, loss: 0.328819
 >> iter 99000, loss: 0.358459
 >> iter 100000, loss: 0.385604
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.699791
 >> iter 2000, loss: 9.663433
 >> iter 3000, loss: 5.246706
 >> iter 4000, loss: 3.560432
 >> iter 5000, loss: 2.314338
 >> iter 6000, loss: 1.769475
 >> iter 7000, loss: 1.367063
 >> iter 8000, loss: 1.265767
 >> iter 9000, loss: 1.146856
 >> iter 10000, loss: 0.852761
   Number of active neurons: 6
 >> iter 11000, loss: 0.775596
 >> iter 12000, loss: 0.579208
 >> iter 13000, loss: 0.550493
 >> iter 14000, loss: 0.490630
 >> iter 15000, loss: 0.447627
 >> iter 16000, loss: 0.349390
 >> iter 17000, loss: 0.339792
 >> iter 18000, loss: 0.370876
 >> iter 19000, loss: 0.335117
 >> iter 20000, loss: 0.358817
   Number of active neurons: 6
 >> iter 21000, loss: 0.353548
 >> iter 22000, loss: 0.471027
 >> iter 23000, loss: 0.498964
 >> iter 24000, loss: 0.437597
 >> iter 25000, loss: 0.360360
 >> iter 26000, loss: 0.383428
 >> iter 27000, loss: 0.412858
 >> iter 28000, loss: 0.457983
 >> iter 29000, loss: 0.390528
 >> iter 30000, loss: 0.432227
   Number of active neurons: 6
 >> iter 31000, loss: 0.460705
 >> iter 32000, loss: 0.367843
 >> iter 33000, loss: 0.356016
 >> iter 34000, loss: 0.428792
 >> iter 35000, loss: 0.416973
 >> iter 36000, loss: 0.374214
 >> iter 37000, loss: 0.322730
 >> iter 38000, loss: 0.394774
 >> iter 39000, loss: 0.405269
 >> iter 40000, loss: 0.340009
   Number of active neurons: 6
 >> iter 41000, loss: 0.333837
 >> iter 42000, loss: 0.273970
 >> iter 43000, loss: 0.406265
 >> iter 44000, loss: 0.383587
 >> iter 45000, loss: 0.372368
 >> iter 46000, loss: 0.407470
 >> iter 47000, loss: 0.386823
 >> iter 48000, loss: 0.487204
 >> iter 49000, loss: 0.368976
 >> iter 50000, loss: 0.367269
   Number of active neurons: 6
 >> iter 51000, loss: 0.448147
 >> iter 52000, loss: 0.454410
 >> iter 53000, loss: 0.339973
 >> iter 54000, loss: 0.408651
 >> iter 55000, loss: 0.277756
 >> iter 56000, loss: 0.245844
 >> iter 57000, loss: 0.225531
 >> iter 58000, loss: 0.213582
 >> iter 59000, loss: 0.277790
 >> iter 60000, loss: 0.220670
   Number of active neurons: 5
 >> iter 61000, loss: 0.257071
 >> iter 62000, loss: 0.292035
 >> iter 63000, loss: 0.370686
 >> iter 64000, loss: 0.266764
 >> iter 65000, loss: 0.267716
 >> iter 66000, loss: 0.353025
 >> iter 67000, loss: 0.344071
 >> iter 68000, loss: 0.308031
 >> iter 69000, loss: 0.308727
 >> iter 70000, loss: 0.343320
   Number of active neurons: 5
 >> iter 71000, loss: 0.344407
 >> iter 72000, loss: 0.273874
 >> iter 73000, loss: 0.359890
 >> iter 74000, loss: 0.340734
 >> iter 75000, loss: 0.243721
 >> iter 76000, loss: 0.263244
 >> iter 77000, loss: 0.222493
 >> iter 78000, loss: 0.294700
 >> iter 79000, loss: 0.262472
 >> iter 80000, loss: 0.272604
   Number of active neurons: 5
 >> iter 81000, loss: 0.222957
 >> iter 82000, loss: 0.257433
 >> iter 83000, loss: 0.280944
 >> iter 84000, loss: 0.249591
 >> iter 85000, loss: 0.259201
 >> iter 86000, loss: 0.330337
 >> iter 87000, loss: 0.284880
 >> iter 88000, loss: 0.242715
 >> iter 89000, loss: 0.258617
 >> iter 90000, loss: 0.195924
   Number of active neurons: 4
 >> iter 91000, loss: 0.245668
 >> iter 92000, loss: 0.279590
 >> iter 93000, loss: 0.271254
 >> iter 94000, loss: 0.300085
 >> iter 95000, loss: 0.312368
 >> iter 96000, loss: 0.308485
 >> iter 97000, loss: 0.292626
 >> iter 98000, loss: 0.342081
 >> iter 99000, loss: 0.291365
 >> iter 100000, loss: 0.223778
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.416379
 >> iter 2000, loss: 10.875866
 >> iter 3000, loss: 7.618865
 >> iter 4000, loss: 5.058722
 >> iter 5000, loss: 3.095744
 >> iter 6000, loss: 1.758751
 >> iter 7000, loss: 1.124208
 >> iter 8000, loss: 0.592257
 >> iter 9000, loss: 0.587905
 >> iter 10000, loss: 0.618744
   Number of active neurons: 14
 >> iter 11000, loss: 0.515453
 >> iter 12000, loss: 0.529833
 >> iter 13000, loss: 0.644558
 >> iter 14000, loss: 0.732638
 >> iter 15000, loss: 0.481092
 >> iter 16000, loss: 0.600091
 >> iter 17000, loss: 0.550449
 >> iter 18000, loss: 0.519488
 >> iter 19000, loss: 0.497665
 >> iter 20000, loss: 0.477428
   Number of active neurons: 12
 >> iter 21000, loss: 0.423292
 >> iter 22000, loss: 0.478435
 >> iter 23000, loss: 0.344545
 >> iter 24000, loss: 0.365565
 >> iter 25000, loss: 0.341180
 >> iter 26000, loss: 0.516540
 >> iter 27000, loss: 0.379388
 >> iter 28000, loss: 0.330634
 >> iter 29000, loss: 0.230657
 >> iter 30000, loss: 0.272005
   Number of active neurons: 10
 >> iter 31000, loss: 0.283201
 >> iter 32000, loss: 0.311826
 >> iter 33000, loss: 0.382057
 >> iter 34000, loss: 0.345822
 >> iter 35000, loss: 0.229993
 >> iter 36000, loss: 0.390381
 >> iter 37000, loss: 0.407009
 >> iter 38000, loss: 0.421523
 >> iter 39000, loss: 0.386636
 >> iter 40000, loss: 0.306100
   Number of active neurons: 8
 >> iter 41000, loss: 0.368608
 >> iter 42000, loss: 0.493557
 >> iter 43000, loss: 0.446755
 >> iter 44000, loss: 0.360510
 >> iter 45000, loss: 0.368280
 >> iter 46000, loss: 0.232383
 >> iter 47000, loss: 0.314129
 >> iter 48000, loss: 0.299613
 >> iter 49000, loss: 0.280964
 >> iter 50000, loss: 0.234538
   Number of active neurons: 7
 >> iter 51000, loss: 0.329681
 >> iter 52000, loss: 0.378855
 >> iter 53000, loss: 0.304135
 >> iter 54000, loss: 0.383815
 >> iter 55000, loss: 0.256372
 >> iter 56000, loss: 0.301359
 >> iter 57000, loss: 0.217600
 >> iter 58000, loss: 0.260166
 >> iter 59000, loss: 0.229890
 >> iter 60000, loss: 0.315644
   Number of active neurons: 6
 >> iter 61000, loss: 0.296983
 >> iter 62000, loss: 0.354167
 >> iter 63000, loss: 0.301862
 >> iter 64000, loss: 0.249369
 >> iter 65000, loss: 0.314899
 >> iter 66000, loss: 0.405856
 >> iter 67000, loss: 0.367891
 >> iter 68000, loss: 0.350514
 >> iter 69000, loss: 0.391852
 >> iter 70000, loss: 0.245069
   Number of active neurons: 5
 >> iter 71000, loss: 0.384272
 >> iter 72000, loss: 0.332280
 >> iter 73000, loss: 0.305008
 >> iter 74000, loss: 0.287771
 >> iter 75000, loss: 0.323559
 >> iter 76000, loss: 0.320604
 >> iter 77000, loss: 0.297352
 >> iter 78000, loss: 0.271362
 >> iter 79000, loss: 0.284998
 >> iter 80000, loss: 0.337844
   Number of active neurons: 5
 >> iter 81000, loss: 0.283422
 >> iter 82000, loss: 0.278807
 >> iter 83000, loss: 0.271563
 >> iter 84000, loss: 0.234851
 >> iter 85000, loss: 0.231838
 >> iter 86000, loss: 0.313075
 >> iter 87000, loss: 0.276408
 >> iter 88000, loss: 0.352077
 >> iter 89000, loss: 0.350979
 >> iter 90000, loss: 0.338433
   Number of active neurons: 5
 >> iter 91000, loss: 0.375244
 >> iter 92000, loss: 0.254168
 >> iter 93000, loss: 0.286643
 >> iter 94000, loss: 0.272602
 >> iter 95000, loss: 0.246180
 >> iter 96000, loss: 0.209082
 >> iter 97000, loss: 0.249909
 >> iter 98000, loss: 0.302459
 >> iter 99000, loss: 0.248419
 >> iter 100000, loss: 0.255985
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.989527
 >> iter 2000, loss: 10.003196
 >> iter 3000, loss: 5.099369
 >> iter 4000, loss: 2.338577
 >> iter 5000, loss: 1.050773
 >> iter 6000, loss: 0.638514
 >> iter 7000, loss: 0.506626
 >> iter 8000, loss: 0.344932
 >> iter 9000, loss: 0.421211
 >> iter 10000, loss: 0.400217
   Number of active neurons: 9
 >> iter 11000, loss: 0.402874
 >> iter 12000, loss: 0.309683
 >> iter 13000, loss: 0.344713
 >> iter 14000, loss: 0.260474
 >> iter 15000, loss: 0.270363
 >> iter 16000, loss: 0.307104
 >> iter 17000, loss: 0.309466
 >> iter 18000, loss: 0.250045
 >> iter 19000, loss: 0.351448
 >> iter 20000, loss: 0.413730
   Number of active neurons: 9
 >> iter 21000, loss: 0.286606
 >> iter 22000, loss: 0.324815
 >> iter 23000, loss: 0.274032
 >> iter 24000, loss: 0.247414
 >> iter 25000, loss: 0.314062
 >> iter 26000, loss: 0.221218
 >> iter 27000, loss: 0.429819
 >> iter 28000, loss: 0.369110
 >> iter 29000, loss: 0.485926
 >> iter 30000, loss: 0.338461
   Number of active neurons: 9
 >> iter 31000, loss: 0.291553
 >> iter 32000, loss: 0.340789
 >> iter 33000, loss: 0.420889
 >> iter 34000, loss: 0.468724
 >> iter 35000, loss: 0.314186
 >> iter 36000, loss: 0.257198
 >> iter 37000, loss: 0.366030
 >> iter 38000, loss: 0.280247
 >> iter 39000, loss: 0.295626
 >> iter 40000, loss: 0.344180
   Number of active neurons: 8
 >> iter 41000, loss: 0.413843
 >> iter 42000, loss: 0.294038
 >> iter 43000, loss: 0.362866
 >> iter 44000, loss: 0.280469
 >> iter 45000, loss: 0.415001
 >> iter 46000, loss: 0.375273
 >> iter 47000, loss: 0.280412
 >> iter 48000, loss: 0.269803
 >> iter 49000, loss: 0.276832
 >> iter 50000, loss: 0.290631
   Number of active neurons: 8
 >> iter 51000, loss: 0.243015
 >> iter 52000, loss: 0.224457
 >> iter 53000, loss: 0.272902
 >> iter 54000, loss: 0.227046
 >> iter 55000, loss: 0.267507
 >> iter 56000, loss: 0.225635
 >> iter 57000, loss: 0.286473
 >> iter 58000, loss: 0.308564
 >> iter 59000, loss: 0.288796
 >> iter 60000, loss: 0.278970
   Number of active neurons: 8
 >> iter 61000, loss: 0.205742
 >> iter 62000, loss: 0.281824
 >> iter 63000, loss: 0.234266
 >> iter 64000, loss: 0.210472
 >> iter 65000, loss: 0.295234
 >> iter 66000, loss: 0.284930
 >> iter 67000, loss: 0.239123
 >> iter 68000, loss: 0.198284
 >> iter 69000, loss: 0.205625
 >> iter 70000, loss: 0.279147
   Number of active neurons: 8
 >> iter 71000, loss: 0.297814
 >> iter 72000, loss: 0.311972
 >> iter 73000, loss: 0.366738
 >> iter 74000, loss: 0.270679
 >> iter 75000, loss: 0.219505
 >> iter 76000, loss: 0.353231
 >> iter 77000, loss: 0.329474
 >> iter 78000, loss: 0.207568
 >> iter 79000, loss: 0.228615
 >> iter 80000, loss: 0.277018
   Number of active neurons: 8
 >> iter 81000, loss: 0.258940
 >> iter 82000, loss: 0.202228
 >> iter 83000, loss: 0.220249
 >> iter 84000, loss: 0.186578
 >> iter 85000, loss: 0.234116
 >> iter 86000, loss: 0.193144
 >> iter 87000, loss: 0.238355
 >> iter 88000, loss: 0.228032
 >> iter 89000, loss: 0.233003
 >> iter 90000, loss: 0.189764
   Number of active neurons: 7
 >> iter 91000, loss: 0.252762
 >> iter 92000, loss: 0.292162
 >> iter 93000, loss: 0.255862
 >> iter 94000, loss: 0.189421
 >> iter 95000, loss: 0.230786
 >> iter 96000, loss: 0.207236
 >> iter 97000, loss: 0.305766
 >> iter 98000, loss: 0.303079
 >> iter 99000, loss: 0.311927
 >> iter 100000, loss: 0.245546
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.249750
 >> iter 2000, loss: 10.373971
 >> iter 3000, loss: 7.456753
 >> iter 4000, loss: 4.805652
 >> iter 5000, loss: 3.089476
 >> iter 6000, loss: 1.873650
 >> iter 7000, loss: 1.266218
 >> iter 8000, loss: 0.860969
 >> iter 9000, loss: 0.914013
 >> iter 10000, loss: 0.697640
   Number of active neurons: 10
 >> iter 11000, loss: 0.587435
 >> iter 12000, loss: 0.504544
 >> iter 13000, loss: 0.578285
 >> iter 14000, loss: 0.651006
 >> iter 15000, loss: 0.465768
 >> iter 16000, loss: 0.548489
 >> iter 17000, loss: 0.413785
 >> iter 18000, loss: 0.553332
 >> iter 19000, loss: 0.638021
 >> iter 20000, loss: 0.496153
   Number of active neurons: 8
 >> iter 21000, loss: 0.731831
 >> iter 22000, loss: 0.659770
 >> iter 23000, loss: 0.880087
 >> iter 24000, loss: 0.749218
 >> iter 25000, loss: 0.702393
 >> iter 26000, loss: 0.585319
 >> iter 27000, loss: 0.501778
 >> iter 28000, loss: 0.775944
 >> iter 29000, loss: 0.794942
 >> iter 30000, loss: 0.627163
   Number of active neurons: 6
 >> iter 31000, loss: 0.735903
 >> iter 32000, loss: 0.621271
 >> iter 33000, loss: 0.653729
 >> iter 34000, loss: 0.658461
 >> iter 35000, loss: 0.576320
 >> iter 36000, loss: 0.654469
 >> iter 37000, loss: 0.649493
 >> iter 38000, loss: 0.618942
 >> iter 39000, loss: 0.492323
 >> iter 40000, loss: 0.551524
   Number of active neurons: 6
 >> iter 41000, loss: 0.519622
 >> iter 42000, loss: 0.649165
 >> iter 43000, loss: 0.568920
 >> iter 44000, loss: 0.537134
 >> iter 45000, loss: 0.446202
 >> iter 46000, loss: 0.750906
 >> iter 47000, loss: 0.600308
 >> iter 48000, loss: 0.609719
 >> iter 49000, loss: 0.521410
 >> iter 50000, loss: 0.439637
   Number of active neurons: 6
 >> iter 51000, loss: 0.709736
 >> iter 52000, loss: 0.574541
 >> iter 53000, loss: 0.422825
 >> iter 54000, loss: 0.410486
 >> iter 55000, loss: 0.432866
 >> iter 56000, loss: 0.429911
 >> iter 57000, loss: 0.583380
 >> iter 58000, loss: 0.423530
 >> iter 59000, loss: 0.373960
 >> iter 60000, loss: 0.445014
   Number of active neurons: 6
 >> iter 61000, loss: 0.446371
 >> iter 62000, loss: 0.488040
 >> iter 63000, loss: 0.654184
 >> iter 64000, loss: 0.486194
 >> iter 65000, loss: 0.488419
 >> iter 66000, loss: 0.592347
 >> iter 67000, loss: 0.487066
 >> iter 68000, loss: 0.673539
 >> iter 69000, loss: 0.584089
 >> iter 70000, loss: 0.431244
   Number of active neurons: 6
 >> iter 71000, loss: 0.464476
 >> iter 72000, loss: 0.433293
 >> iter 73000, loss: 0.466279
 >> iter 74000, loss: 0.627061
 >> iter 75000, loss: 0.527897
 >> iter 76000, loss: 0.491086
 >> iter 77000, loss: 0.624098
 >> iter 78000, loss: 0.449401
 >> iter 79000, loss: 0.416836
 >> iter 80000, loss: 0.437282
   Number of active neurons: 6
 >> iter 81000, loss: 0.578332
 >> iter 82000, loss: 0.445199
 >> iter 83000, loss: 0.544158
 >> iter 84000, loss: 0.514560
 >> iter 85000, loss: 0.548173
 >> iter 86000, loss: 0.480691
 >> iter 87000, loss: 0.718103
 >> iter 88000, loss: 0.578427
 >> iter 89000, loss: 0.451096
 >> iter 90000, loss: 0.581229
   Number of active neurons: 6
 >> iter 91000, loss: 0.573955
 >> iter 92000, loss: 0.514381
 >> iter 93000, loss: 0.631324
 >> iter 94000, loss: 0.635995
 >> iter 95000, loss: 0.674625
 >> iter 96000, loss: 0.669721
 >> iter 97000, loss: 0.780267
 >> iter 98000, loss: 0.529737
 >> iter 99000, loss: 0.504243
 >> iter 100000, loss: 0.624547
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.094584
 >> iter 2000, loss: 10.285628
 >> iter 3000, loss: 5.219819
 >> iter 4000, loss: 2.468968
 >> iter 5000, loss: 1.359281
 >> iter 6000, loss: 0.839399
 >> iter 7000, loss: 0.488918
 >> iter 8000, loss: 0.380423
 >> iter 9000, loss: 0.458100
 >> iter 10000, loss: 0.292757
   Number of active neurons: 7
 >> iter 11000, loss: 0.438695
 >> iter 12000, loss: 0.337519
 >> iter 13000, loss: 0.251483
 >> iter 14000, loss: 0.224079
 >> iter 15000, loss: 0.434150
 >> iter 16000, loss: 0.342136
 >> iter 17000, loss: 0.298431
 >> iter 18000, loss: 0.279464
 >> iter 19000, loss: 0.303622
 >> iter 20000, loss: 0.204624
   Number of active neurons: 6
 >> iter 21000, loss: 0.244491
 >> iter 22000, loss: 0.309164
 >> iter 23000, loss: 0.217873
 >> iter 24000, loss: 0.231079
 >> iter 25000, loss: 0.155127
 >> iter 26000, loss: 0.292860
 >> iter 27000, loss: 0.352472
 >> iter 28000, loss: 0.294692
 >> iter 29000, loss: 0.296260
 >> iter 30000, loss: 0.270306
   Number of active neurons: 6
 >> iter 31000, loss: 0.246114
 >> iter 32000, loss: 0.223148
 >> iter 33000, loss: 0.348500
 >> iter 34000, loss: 0.267976
 >> iter 35000, loss: 0.227989
 >> iter 36000, loss: 0.258846
 >> iter 37000, loss: 0.311768
 >> iter 38000, loss: 0.315949
 >> iter 39000, loss: 0.366075
 >> iter 40000, loss: 0.356539
   Number of active neurons: 6
 >> iter 41000, loss: 0.247914
 >> iter 42000, loss: 0.394276
 >> iter 43000, loss: 0.288940
 >> iter 44000, loss: 0.253506
 >> iter 45000, loss: 0.293101
 >> iter 46000, loss: 0.305405
 >> iter 47000, loss: 0.259714
 >> iter 48000, loss: 0.214774
 >> iter 49000, loss: 0.274905
 >> iter 50000, loss: 0.279704
   Number of active neurons: 6
 >> iter 51000, loss: 0.317123
 >> iter 52000, loss: 0.336678
 >> iter 53000, loss: 0.277066
 >> iter 54000, loss: 0.347582
 >> iter 55000, loss: 0.251907
 >> iter 56000, loss: 0.262627
 >> iter 57000, loss: 0.211732
 >> iter 58000, loss: 0.299267
 >> iter 59000, loss: 0.464188
 >> iter 60000, loss: 0.291133
   Number of active neurons: 6
 >> iter 61000, loss: 0.349682
 >> iter 62000, loss: 0.298322
 >> iter 63000, loss: 0.223925
 >> iter 64000, loss: 0.323911
 >> iter 65000, loss: 0.260371
 >> iter 66000, loss: 0.162321
 >> iter 67000, loss: 0.270838
 >> iter 68000, loss: 0.258474
 >> iter 69000, loss: 0.380770
 >> iter 70000, loss: 0.293055
   Number of active neurons: 6
 >> iter 71000, loss: 0.257402
 >> iter 72000, loss: 0.346485
 >> iter 73000, loss: 0.329364
 >> iter 74000, loss: 0.265111
 >> iter 75000, loss: 0.239476
 >> iter 76000, loss: 0.301219
 >> iter 77000, loss: 0.328696
 >> iter 78000, loss: 0.368578
 >> iter 79000, loss: 0.382529
 >> iter 80000, loss: 0.408335
   Number of active neurons: 6
 >> iter 81000, loss: 0.387782
 >> iter 82000, loss: 0.250214
 >> iter 83000, loss: 0.339091
 >> iter 84000, loss: 0.318239
 >> iter 85000, loss: 0.328633
 >> iter 86000, loss: 0.233616
 >> iter 87000, loss: 0.230443
 >> iter 88000, loss: 0.212696
 >> iter 89000, loss: 0.185406
 >> iter 90000, loss: 0.175343
   Number of active neurons: 6
 >> iter 91000, loss: 0.164352
 >> iter 92000, loss: 0.193625
 >> iter 93000, loss: 0.240968
 >> iter 94000, loss: 0.348162
 >> iter 95000, loss: 0.332136
 >> iter 96000, loss: 0.327980
 >> iter 97000, loss: 0.295859
 >> iter 98000, loss: 0.216497
 >> iter 99000, loss: 0.325653
 >> iter 100000, loss: 0.312152
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

