 > Problema: tomita1nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.877384
 >> iter 2000, loss: 4.058565
 >> iter 3000, loss: 1.519426
 >> iter 4000, loss: 0.601782
 >> iter 5000, loss: 0.245148
 >> iter 6000, loss: 0.117306
 >> iter 7000, loss: 0.060027
 >> iter 8000, loss: 0.043565
 >> iter 9000, loss: 0.035160
 >> iter 10000, loss: 0.030877
   Number of active neurons: 4
 >> iter 11000, loss: 0.028291
 >> iter 12000, loss: 0.029532
 >> iter 13000, loss: 0.026608
 >> iter 14000, loss: 0.026007
 >> iter 15000, loss: 0.025625
 >> iter 16000, loss: 0.034183
 >> iter 17000, loss: 0.044378
 >> iter 18000, loss: 0.033611
 >> iter 19000, loss: 0.029830
 >> iter 20000, loss: 0.025515
   Number of active neurons: 3
 >> iter 21000, loss: 0.027270
 >> iter 22000, loss: 0.024462
 >> iter 23000, loss: 0.024708
 >> iter 24000, loss: 0.024667
 >> iter 25000, loss: 0.026750
 >> iter 26000, loss: 0.027732
 >> iter 27000, loss: 0.039698
 >> iter 28000, loss: 0.029569
 >> iter 29000, loss: 0.061448
 >> iter 30000, loss: 0.038595
   Number of active neurons: 3
 >> iter 31000, loss: 0.029938
 >> iter 32000, loss: 0.029535
 >> iter 33000, loss: 0.033031
 >> iter 34000, loss: 0.026779
 >> iter 35000, loss: 0.026988
 >> iter 36000, loss: 0.023709
 >> iter 37000, loss: 0.022103
 >> iter 38000, loss: 0.027018
 >> iter 39000, loss: 0.026970
 >> iter 40000, loss: 0.028376
   Number of active neurons: 3
 >> iter 41000, loss: 0.032526
 >> iter 42000, loss: 0.025731
 >> iter 43000, loss: 0.035827
 >> iter 44000, loss: 0.029375
 >> iter 45000, loss: 0.024100
 >> iter 46000, loss: 0.042026
 >> iter 47000, loss: 0.029049
 >> iter 48000, loss: 0.026231
 >> iter 49000, loss: 0.023860
 >> iter 50000, loss: 0.029925
   Number of active neurons: 2
 >> iter 51000, loss: 0.024831
 >> iter 52000, loss: 0.022106
 >> iter 53000, loss: 0.022848
 >> iter 54000, loss: 0.037759
 >> iter 55000, loss: 0.027749
 >> iter 56000, loss: 0.024332
 >> iter 57000, loss: 0.022709
 >> iter 58000, loss: 0.022261
 >> iter 59000, loss: 0.023632
 >> iter 60000, loss: 0.023287
   Number of active neurons: 2
 >> iter 61000, loss: 0.021802
 >> iter 62000, loss: 0.020885
 >> iter 63000, loss: 0.019730
 >> iter 64000, loss: 0.019821
 >> iter 65000, loss: 0.032633
 >> iter 66000, loss: 0.030374
 >> iter 67000, loss: 0.025513
 >> iter 68000, loss: 0.022175
 >> iter 69000, loss: 0.027161
 >> iter 70000, loss: 0.032347
   Number of active neurons: 2
 >> iter 71000, loss: 0.026944
 >> iter 72000, loss: 0.026132
 >> iter 73000, loss: 0.024780
 >> iter 74000, loss: 0.021351
 >> iter 75000, loss: 0.023409
 >> iter 76000, loss: 0.020716
 >> iter 77000, loss: 0.021107
 >> iter 78000, loss: 0.019881
 >> iter 79000, loss: 0.020912
 >> iter 80000, loss: 0.029730
   Number of active neurons: 2
 >> iter 81000, loss: 0.024642
 >> iter 82000, loss: 0.021426
 >> iter 83000, loss: 0.022901
 >> iter 84000, loss: 0.021374
 >> iter 85000, loss: 0.027647
 >> iter 86000, loss: 0.023957
 >> iter 87000, loss: 0.023256
 >> iter 88000, loss: 0.025507
 >> iter 89000, loss: 0.024153
 >> iter 90000, loss: 0.021789
   Number of active neurons: 2
 >> iter 91000, loss: 0.026305
 >> iter 92000, loss: 0.027127
 >> iter 93000, loss: 0.026941
 >> iter 94000, loss: 0.024294
 >> iter 95000, loss: 0.022920
 >> iter 96000, loss: 0.048759
 >> iter 97000, loss: 0.042422
 >> iter 98000, loss: 0.030739
 >> iter 99000, loss: 0.030037
 >> iter 100000, loss: 0.024333
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.959160
 >> iter 2000, loss: 4.067261
 >> iter 3000, loss: 1.520005
 >> iter 4000, loss: 0.581703
 >> iter 5000, loss: 0.229727
 >> iter 6000, loss: 0.101868
 >> iter 7000, loss: 0.052632
 >> iter 8000, loss: 0.040622
 >> iter 9000, loss: 0.039673
 >> iter 10000, loss: 0.033140
   Number of active neurons: 3
 >> iter 11000, loss: 0.031939
 >> iter 12000, loss: 0.029392
 >> iter 13000, loss: 0.026371
 >> iter 14000, loss: 0.024373
 >> iter 15000, loss: 0.026457
 >> iter 16000, loss: 0.025356
 >> iter 17000, loss: 0.027998
 >> iter 18000, loss: 0.025456
 >> iter 19000, loss: 0.026854
 >> iter 20000, loss: 0.026841
   Number of active neurons: 3
 >> iter 21000, loss: 0.023088
 >> iter 22000, loss: 0.027901
 >> iter 23000, loss: 0.027367
 >> iter 24000, loss: 0.023869
 >> iter 25000, loss: 0.022485
 >> iter 26000, loss: 0.027549
 >> iter 27000, loss: 0.029119
 >> iter 28000, loss: 0.025123
 >> iter 29000, loss: 0.023573
 >> iter 30000, loss: 0.026563
   Number of active neurons: 3
 >> iter 31000, loss: 0.023185
 >> iter 32000, loss: 0.035492
 >> iter 33000, loss: 0.031744
 >> iter 34000, loss: 0.026595
 >> iter 35000, loss: 0.025879
 >> iter 36000, loss: 0.022282
 >> iter 37000, loss: 0.021981
 >> iter 38000, loss: 0.023095
 >> iter 39000, loss: 0.027352
 >> iter 40000, loss: 0.024238
   Number of active neurons: 2
 >> iter 41000, loss: 0.024464
 >> iter 42000, loss: 0.030222
 >> iter 43000, loss: 0.024260
 >> iter 44000, loss: 0.025203
 >> iter 45000, loss: 0.024520
 >> iter 46000, loss: 0.025506
 >> iter 47000, loss: 0.023544
 >> iter 48000, loss: 0.032650
 >> iter 49000, loss: 0.035792
 >> iter 50000, loss: 0.026498
   Number of active neurons: 2
 >> iter 51000, loss: 0.022937
 >> iter 52000, loss: 0.021551
 >> iter 53000, loss: 0.019894
 >> iter 54000, loss: 0.024115
 >> iter 55000, loss: 0.021934
 >> iter 56000, loss: 0.021656
 >> iter 57000, loss: 0.021789
 >> iter 58000, loss: 0.021737
 >> iter 59000, loss: 0.024901
 >> iter 60000, loss: 0.021093
   Number of active neurons: 2
 >> iter 61000, loss: 0.034945
 >> iter 62000, loss: 0.038775
 >> iter 63000, loss: 0.037732
 >> iter 64000, loss: 0.035283
 >> iter 65000, loss: 0.027453
 >> iter 66000, loss: 0.023246
 >> iter 67000, loss: 0.024637
 >> iter 68000, loss: 0.023856
 >> iter 69000, loss: 0.022582
 >> iter 70000, loss: 0.019881
   Number of active neurons: 2
 >> iter 71000, loss: 0.028798
 >> iter 72000, loss: 0.027533
 >> iter 73000, loss: 0.022873
 >> iter 74000, loss: 0.055390
 >> iter 75000, loss: 0.058757
 >> iter 76000, loss: 0.037228
 >> iter 77000, loss: 0.030329
 >> iter 78000, loss: 0.024000
 >> iter 79000, loss: 0.023931
 >> iter 80000, loss: 0.020998
   Number of active neurons: 2
 >> iter 81000, loss: 0.022144
 >> iter 82000, loss: 0.059689
 >> iter 83000, loss: 0.044056
 >> iter 84000, loss: 0.035355
 >> iter 85000, loss: 0.030337
 >> iter 86000, loss: 0.023573
 >> iter 87000, loss: 0.025643
 >> iter 88000, loss: 0.025580
 >> iter 89000, loss: 0.023856
 >> iter 90000, loss: 0.022831
   Number of active neurons: 2
 >> iter 91000, loss: 0.022859
 >> iter 92000, loss: 0.023998
 >> iter 93000, loss: 0.033804
 >> iter 94000, loss: 0.029107
 >> iter 95000, loss: 0.024936
 >> iter 96000, loss: 0.022651
 >> iter 97000, loss: 0.021728
 >> iter 98000, loss: 0.028559
 >> iter 99000, loss: 0.031301
 >> iter 100000, loss: 0.027186
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.939536
 >> iter 2000, loss: 4.059433
 >> iter 3000, loss: 1.519315
 >> iter 4000, loss: 0.577837
 >> iter 5000, loss: 0.234852
 >> iter 6000, loss: 0.104987
 >> iter 7000, loss: 0.056094
 >> iter 8000, loss: 0.036898
 >> iter 9000, loss: 0.031726
 >> iter 10000, loss: 0.033161
   Number of active neurons: 3
 >> iter 11000, loss: 0.029103
 >> iter 12000, loss: 0.031165
 >> iter 13000, loss: 0.031045
 >> iter 14000, loss: 0.033278
 >> iter 15000, loss: 0.033619
 >> iter 16000, loss: 0.029043
 >> iter 17000, loss: 0.030001
 >> iter 18000, loss: 0.033244
 >> iter 19000, loss: 0.029446
 >> iter 20000, loss: 0.029288
   Number of active neurons: 3
 >> iter 21000, loss: 0.026947
 >> iter 22000, loss: 0.031095
 >> iter 23000, loss: 0.026455
 >> iter 24000, loss: 0.025503
 >> iter 25000, loss: 0.037057
 >> iter 26000, loss: 0.028308
 >> iter 27000, loss: 0.026551
 >> iter 28000, loss: 0.024076
 >> iter 29000, loss: 0.023318
 >> iter 30000, loss: 0.022648
   Number of active neurons: 2
 >> iter 31000, loss: 0.023668
 >> iter 32000, loss: 0.024822
 >> iter 33000, loss: 0.024321
 >> iter 34000, loss: 0.021753
 >> iter 35000, loss: 0.039900
 >> iter 36000, loss: 0.027652
 >> iter 37000, loss: 0.031711
 >> iter 38000, loss: 0.026282
 >> iter 39000, loss: 0.021192
 >> iter 40000, loss: 0.025096
   Number of active neurons: 2
 >> iter 41000, loss: 0.023993
 >> iter 42000, loss: 0.022476
 >> iter 43000, loss: 0.024236
 >> iter 44000, loss: 0.021115
 >> iter 45000, loss: 0.022189
 >> iter 46000, loss: 0.021580
 >> iter 47000, loss: 0.021899
 >> iter 48000, loss: 0.028496
 >> iter 49000, loss: 0.028323
 >> iter 50000, loss: 0.024866
   Number of active neurons: 2
 >> iter 51000, loss: 0.023767
 >> iter 52000, loss: 0.020522
 >> iter 53000, loss: 0.023974
 >> iter 54000, loss: 0.024856
 >> iter 55000, loss: 0.023105
 >> iter 56000, loss: 0.020521
 >> iter 57000, loss: 0.020255
 >> iter 58000, loss: 0.019303
 >> iter 59000, loss: 0.021696
 >> iter 60000, loss: 0.039352
   Number of active neurons: 2
 >> iter 61000, loss: 0.028120
 >> iter 62000, loss: 0.025686
 >> iter 63000, loss: 0.022520
 >> iter 64000, loss: 0.020768
 >> iter 65000, loss: 0.026261
 >> iter 66000, loss: 0.059972
 >> iter 67000, loss: 0.036645
 >> iter 68000, loss: 0.028733
 >> iter 69000, loss: 0.025607
 >> iter 70000, loss: 0.031291
   Number of active neurons: 2
 >> iter 71000, loss: 0.024059
 >> iter 72000, loss: 0.021549
 >> iter 73000, loss: 0.022083
 >> iter 74000, loss: 0.030267
 >> iter 75000, loss: 0.024509
 >> iter 76000, loss: 0.021062
 >> iter 77000, loss: 0.021912
 >> iter 78000, loss: 0.021078
 >> iter 79000, loss: 0.030112
 >> iter 80000, loss: 0.031447
   Number of active neurons: 2
 >> iter 81000, loss: 0.025371
 >> iter 82000, loss: 0.021987
 >> iter 83000, loss: 0.024984
 >> iter 84000, loss: 0.021934
 >> iter 85000, loss: 0.023527
 >> iter 86000, loss: 0.022738
 >> iter 87000, loss: 0.026862
 >> iter 88000, loss: 0.023618
 >> iter 89000, loss: 0.039196
 >> iter 90000, loss: 0.032441
   Number of active neurons: 2
 >> iter 91000, loss: 0.027352
 >> iter 92000, loss: 0.032615
 >> iter 93000, loss: 0.023704
 >> iter 94000, loss: 0.029076
 >> iter 95000, loss: 0.026069
 >> iter 96000, loss: 0.022239
 >> iter 97000, loss: 0.029878
 >> iter 98000, loss: 0.023133
 >> iter 99000, loss: 0.024747
 >> iter 100000, loss: 0.022699
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.012158
 >> iter 2000, loss: 4.099165
 >> iter 3000, loss: 1.539003
 >> iter 4000, loss: 0.588129
 >> iter 5000, loss: 0.241572
 >> iter 6000, loss: 0.109893
 >> iter 7000, loss: 0.065531
 >> iter 8000, loss: 0.047654
 >> iter 9000, loss: 0.035400
 >> iter 10000, loss: 0.035375
   Number of active neurons: 6
 >> iter 11000, loss: 0.035787
 >> iter 12000, loss: 0.044854
 >> iter 13000, loss: 0.036443
 >> iter 14000, loss: 0.039871
 >> iter 15000, loss: 0.033412
 >> iter 16000, loss: 0.037761
 >> iter 17000, loss: 0.032051
 >> iter 18000, loss: 0.033704
 >> iter 19000, loss: 0.030258
 >> iter 20000, loss: 0.029999
   Number of active neurons: 5
 >> iter 21000, loss: 0.029497
 >> iter 22000, loss: 0.032297
 >> iter 23000, loss: 0.036458
 >> iter 24000, loss: 0.032460
 >> iter 25000, loss: 0.034474
 >> iter 26000, loss: 0.030341
 >> iter 27000, loss: 0.027254
 >> iter 28000, loss: 0.029335
 >> iter 29000, loss: 0.040655
 >> iter 30000, loss: 0.031973
   Number of active neurons: 4
 >> iter 31000, loss: 0.027915
 >> iter 32000, loss: 0.027477
 >> iter 33000, loss: 0.029529
 >> iter 34000, loss: 0.027118
 >> iter 35000, loss: 0.025048
 >> iter 36000, loss: 0.033211
 >> iter 37000, loss: 0.028949
 >> iter 38000, loss: 0.032249
 >> iter 39000, loss: 0.034151
 >> iter 40000, loss: 0.030524
   Number of active neurons: 3
 >> iter 41000, loss: 0.027219
 >> iter 42000, loss: 0.025079
 >> iter 43000, loss: 0.025436
 >> iter 44000, loss: 0.025774
 >> iter 45000, loss: 0.032527
 >> iter 46000, loss: 0.037466
 >> iter 47000, loss: 0.028337
 >> iter 48000, loss: 0.024758
 >> iter 49000, loss: 0.022020
 >> iter 50000, loss: 0.027679
   Number of active neurons: 2
 >> iter 51000, loss: 0.027271
 >> iter 52000, loss: 0.026860
 >> iter 53000, loss: 0.023612
 >> iter 54000, loss: 0.022987
 >> iter 55000, loss: 0.021369
 >> iter 56000, loss: 0.020910
 >> iter 57000, loss: 0.022666
 >> iter 58000, loss: 0.023256
 >> iter 59000, loss: 0.025415
 >> iter 60000, loss: 0.027016
   Number of active neurons: 2
 >> iter 61000, loss: 0.022726
 >> iter 62000, loss: 0.020592
 >> iter 63000, loss: 0.022289
 >> iter 64000, loss: 0.024247
 >> iter 65000, loss: 0.026280
 >> iter 66000, loss: 0.022862
 >> iter 67000, loss: 0.026123
 >> iter 68000, loss: 0.024142
 >> iter 69000, loss: 0.034195
 >> iter 70000, loss: 0.028108
   Number of active neurons: 2
 >> iter 71000, loss: 0.025610
 >> iter 72000, loss: 0.022973
 >> iter 73000, loss: 0.024899
 >> iter 74000, loss: 0.024532
 >> iter 75000, loss: 0.023788
 >> iter 76000, loss: 0.021909
 >> iter 77000, loss: 0.025949
 >> iter 78000, loss: 0.024034
 >> iter 79000, loss: 0.035294
 >> iter 80000, loss: 0.032802
   Number of active neurons: 2
 >> iter 81000, loss: 0.031801
 >> iter 82000, loss: 0.024439
 >> iter 83000, loss: 0.029410
 >> iter 84000, loss: 0.024814
 >> iter 85000, loss: 0.020607
 >> iter 86000, loss: 0.019785
 >> iter 87000, loss: 0.024203
 >> iter 88000, loss: 0.021834
 >> iter 89000, loss: 0.019641
 >> iter 90000, loss: 0.021356
   Number of active neurons: 1
 >> iter 91000, loss: 0.021329
 >> iter 92000, loss: 0.018726
 >> iter 93000, loss: 0.024859
 >> iter 94000, loss: 0.026326
 >> iter 95000, loss: 0.036731
 >> iter 96000, loss: 0.026623
 >> iter 97000, loss: 0.021827
 >> iter 98000, loss: 0.020166
 >> iter 99000, loss: 0.017099
 >> iter 100000, loss: 0.018823
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.913037
 >> iter 2000, loss: 4.054722
 >> iter 3000, loss: 1.516097
 >> iter 4000, loss: 0.581574
 >> iter 5000, loss: 0.244397
 >> iter 6000, loss: 0.110973
 >> iter 7000, loss: 0.057678
 >> iter 8000, loss: 0.056865
 >> iter 9000, loss: 0.037677
 >> iter 10000, loss: 0.032216
   Number of active neurons: 3
 >> iter 11000, loss: 0.027542
 >> iter 12000, loss: 0.026320
 >> iter 13000, loss: 0.025311
 >> iter 14000, loss: 0.023912
 >> iter 15000, loss: 0.024403
 >> iter 16000, loss: 0.026658
 >> iter 17000, loss: 0.038816
 >> iter 18000, loss: 0.027104
 >> iter 19000, loss: 0.025377
 >> iter 20000, loss: 0.024951
   Number of active neurons: 2
 >> iter 21000, loss: 0.023882
 >> iter 22000, loss: 0.025351
 >> iter 23000, loss: 0.032655
 >> iter 24000, loss: 0.026505
 >> iter 25000, loss: 0.022865
 >> iter 26000, loss: 0.021490
 >> iter 27000, loss: 0.028944
 >> iter 28000, loss: 0.025621
 >> iter 29000, loss: 0.025524
 >> iter 30000, loss: 0.022240
   Number of active neurons: 2
 >> iter 31000, loss: 0.020936
 >> iter 32000, loss: 0.022281
 >> iter 33000, loss: 0.034545
 >> iter 34000, loss: 0.025060
 >> iter 35000, loss: 0.022022
 >> iter 36000, loss: 0.021050
 >> iter 37000, loss: 0.025037
 >> iter 38000, loss: 0.026721
 >> iter 39000, loss: 0.021969
 >> iter 40000, loss: 0.024764
   Number of active neurons: 2
 >> iter 41000, loss: 0.024551
 >> iter 42000, loss: 0.034519
 >> iter 43000, loss: 0.027127
 >> iter 44000, loss: 0.025228
 >> iter 45000, loss: 0.026247
 >> iter 46000, loss: 0.038898
 >> iter 47000, loss: 0.032533
 >> iter 48000, loss: 0.025746
 >> iter 49000, loss: 0.022375
 >> iter 50000, loss: 0.022217
   Number of active neurons: 2
 >> iter 51000, loss: 0.022664
 >> iter 52000, loss: 0.032123
 >> iter 53000, loss: 0.025157
 >> iter 54000, loss: 0.039422
 >> iter 55000, loss: 0.027404
 >> iter 56000, loss: 0.023860
 >> iter 57000, loss: 0.022631
 >> iter 58000, loss: 0.024682
 >> iter 59000, loss: 0.028397
 >> iter 60000, loss: 0.024862
   Number of active neurons: 1
 >> iter 61000, loss: 0.023421
 >> iter 62000, loss: 0.021469
 >> iter 63000, loss: 0.023205
 >> iter 64000, loss: 0.020254
 >> iter 65000, loss: 0.020344
 >> iter 66000, loss: 0.020509
 >> iter 67000, loss: 0.017984
 >> iter 68000, loss: 0.020103
 >> iter 69000, loss: 0.051301
 >> iter 70000, loss: 0.029949
   Number of active neurons: 1
 >> iter 71000, loss: 0.035923
 >> iter 72000, loss: 0.024800
 >> iter 73000, loss: 0.021200
 >> iter 74000, loss: 0.023583
 >> iter 75000, loss: 0.018421
 >> iter 76000, loss: 0.018303
 >> iter 77000, loss: 0.022351
 >> iter 78000, loss: 0.027962
 >> iter 79000, loss: 0.037601
 >> iter 80000, loss: 0.024250
   Number of active neurons: 1
 >> iter 81000, loss: 0.028869
 >> iter 82000, loss: 0.028187
 >> iter 83000, loss: 0.023979
 >> iter 84000, loss: 0.018695
 >> iter 85000, loss: 0.016431
 >> iter 86000, loss: 0.019000
 >> iter 87000, loss: 0.017847
 >> iter 88000, loss: 0.016689
 >> iter 89000, loss: 0.016212
 >> iter 90000, loss: 0.020868
   Number of active neurons: 1
 >> iter 91000, loss: 0.031018
 >> iter 92000, loss: 0.041217
 >> iter 93000, loss: 0.028115
 >> iter 94000, loss: 0.024082
 >> iter 95000, loss: 0.020681
 >> iter 96000, loss: 0.020623
 >> iter 97000, loss: 0.022884
 >> iter 98000, loss: 0.022889
 >> iter 99000, loss: 0.019461
 >> iter 100000, loss: 0.018458
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.949092
 >> iter 2000, loss: 4.072143
 >> iter 3000, loss: 1.537156
 >> iter 4000, loss: 0.590980
 >> iter 5000, loss: 0.247197
 >> iter 6000, loss: 0.109530
 >> iter 7000, loss: 0.065964
 >> iter 8000, loss: 0.046839
 >> iter 9000, loss: 0.038721
 >> iter 10000, loss: 0.035984
   Number of active neurons: 4
 >> iter 11000, loss: 0.040272
 >> iter 12000, loss: 0.035110
 >> iter 13000, loss: 0.030601
 >> iter 14000, loss: 0.034213
 >> iter 15000, loss: 0.034118
 >> iter 16000, loss: 0.027673
 >> iter 17000, loss: 0.026649
 >> iter 18000, loss: 0.033100
 >> iter 19000, loss: 0.034835
 >> iter 20000, loss: 0.035495
   Number of active neurons: 3
 >> iter 21000, loss: 0.042947
 >> iter 22000, loss: 0.030474
 >> iter 23000, loss: 0.050961
 >> iter 24000, loss: 0.033123
 >> iter 25000, loss: 0.029546
 >> iter 26000, loss: 0.024887
 >> iter 27000, loss: 0.024242
 >> iter 28000, loss: 0.026311
 >> iter 29000, loss: 0.023872
 >> iter 30000, loss: 0.034434
   Number of active neurons: 2
 >> iter 31000, loss: 0.030298
 >> iter 32000, loss: 0.031152
 >> iter 33000, loss: 0.025237
 >> iter 34000, loss: 0.046156
 >> iter 35000, loss: 0.032458
 >> iter 36000, loss: 0.024866
 >> iter 37000, loss: 0.027708
 >> iter 38000, loss: 0.033198
 >> iter 39000, loss: 0.024721
 >> iter 40000, loss: 0.020872
   Number of active neurons: 1
 >> iter 41000, loss: 0.019253
 >> iter 42000, loss: 0.034893
 >> iter 43000, loss: 0.024046
 >> iter 44000, loss: 0.019347
 >> iter 45000, loss: 0.017687
 >> iter 46000, loss: 0.020692
 >> iter 47000, loss: 0.020783
 >> iter 48000, loss: 0.018431
 >> iter 49000, loss: 0.021626
 >> iter 50000, loss: 0.017522
   Number of active neurons: 1
 >> iter 51000, loss: 0.017572
 >> iter 52000, loss: 0.016240
 >> iter 53000, loss: 0.016163
 >> iter 54000, loss: 0.018221
 >> iter 55000, loss: 0.018364
 >> iter 56000, loss: 0.026826
 >> iter 57000, loss: 0.021122
 >> iter 58000, loss: 0.019507
 >> iter 59000, loss: 0.018072
 >> iter 60000, loss: 0.016411
   Number of active neurons: 1
 >> iter 61000, loss: 0.017980
 >> iter 62000, loss: 0.022496
 >> iter 63000, loss: 0.020809
 >> iter 64000, loss: 0.021799
 >> iter 65000, loss: 0.048502
 >> iter 66000, loss: 0.029549
 >> iter 67000, loss: 0.023171
 >> iter 68000, loss: 0.035968
 >> iter 69000, loss: 0.026311
 >> iter 70000, loss: 0.029762
   Number of active neurons: 1
 >> iter 71000, loss: 0.021008
 >> iter 72000, loss: 0.018989
 >> iter 73000, loss: 0.016864
 >> iter 74000, loss: 0.018210
 >> iter 75000, loss: 0.016807
 >> iter 76000, loss: 0.035213
 >> iter 77000, loss: 0.024726
 >> iter 78000, loss: 0.029281
 >> iter 79000, loss: 0.022305
 >> iter 80000, loss: 0.019267
   Number of active neurons: 1
 >> iter 81000, loss: 0.024064
 >> iter 82000, loss: 0.020192
 >> iter 83000, loss: 0.018747
 >> iter 84000, loss: 0.017060
 >> iter 85000, loss: 0.026878
 >> iter 86000, loss: 0.020314
 >> iter 87000, loss: 0.020798
 >> iter 88000, loss: 0.021651
 >> iter 89000, loss: 0.018222
 >> iter 90000, loss: 0.016297
   Number of active neurons: 1
 >> iter 91000, loss: 0.017376
 >> iter 92000, loss: 0.018897
 >> iter 93000, loss: 0.019844
 >> iter 94000, loss: 0.027629
 >> iter 95000, loss: 0.020126
 >> iter 96000, loss: 0.019213
 >> iter 97000, loss: 0.018252
 >> iter 98000, loss: 0.017538
 >> iter 99000, loss: 0.018247
 >> iter 100000, loss: 0.020714
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.913090
 >> iter 2000, loss: 4.054586
 >> iter 3000, loss: 1.526340
 >> iter 4000, loss: 0.582643
 >> iter 5000, loss: 0.244950
 >> iter 6000, loss: 0.107370
 >> iter 7000, loss: 0.057162
 >> iter 8000, loss: 0.044329
 >> iter 9000, loss: 0.038338
 >> iter 10000, loss: 0.036782
   Number of active neurons: 5
 >> iter 11000, loss: 0.033072
 >> iter 12000, loss: 0.028581
 >> iter 13000, loss: 0.029301
 >> iter 14000, loss: 0.028316
 >> iter 15000, loss: 0.043228
 >> iter 16000, loss: 0.032562
 >> iter 17000, loss: 0.030651
 >> iter 18000, loss: 0.028654
 >> iter 19000, loss: 0.026952
 >> iter 20000, loss: 0.026148
   Number of active neurons: 4
 >> iter 21000, loss: 0.025447
 >> iter 22000, loss: 0.028525
 >> iter 23000, loss: 0.030618
 >> iter 24000, loss: 0.028044
 >> iter 25000, loss: 0.026678
 >> iter 26000, loss: 0.026566
 >> iter 27000, loss: 0.026552
 >> iter 28000, loss: 0.024330
 >> iter 29000, loss: 0.027027
 >> iter 30000, loss: 0.027236
   Number of active neurons: 3
 >> iter 31000, loss: 0.035778
 >> iter 32000, loss: 0.027079
 >> iter 33000, loss: 0.025168
 >> iter 34000, loss: 0.023381
 >> iter 35000, loss: 0.024400
 >> iter 36000, loss: 0.029376
 >> iter 37000, loss: 0.024537
 >> iter 38000, loss: 0.036354
 >> iter 39000, loss: 0.029988
 >> iter 40000, loss: 0.034849
   Number of active neurons: 2
 >> iter 41000, loss: 0.026876
 >> iter 42000, loss: 0.031299
 >> iter 43000, loss: 0.023481
 >> iter 44000, loss: 0.019753
 >> iter 45000, loss: 0.024337
 >> iter 46000, loss: 0.032862
 >> iter 47000, loss: 0.025722
 >> iter 48000, loss: 0.021598
 >> iter 49000, loss: 0.021401
 >> iter 50000, loss: 0.021406
   Number of active neurons: 2
 >> iter 51000, loss: 0.023678
 >> iter 52000, loss: 0.023802
 >> iter 53000, loss: 0.024833
 >> iter 54000, loss: 0.021527
 >> iter 55000, loss: 0.021940
 >> iter 56000, loss: 0.030120
 >> iter 57000, loss: 0.034113
 >> iter 58000, loss: 0.024935
 >> iter 59000, loss: 0.022974
 >> iter 60000, loss: 0.022376
   Number of active neurons: 2
 >> iter 61000, loss: 0.021675
 >> iter 62000, loss: 0.020007
 >> iter 63000, loss: 0.023820
 >> iter 64000, loss: 0.020544
 >> iter 65000, loss: 0.031945
 >> iter 66000, loss: 0.024947
 >> iter 67000, loss: 0.022871
 >> iter 68000, loss: 0.024314
 >> iter 69000, loss: 0.023840
 >> iter 70000, loss: 0.021784
   Number of active neurons: 2
 >> iter 71000, loss: 0.024662
 >> iter 72000, loss: 0.020930
 >> iter 73000, loss: 0.023521
 >> iter 74000, loss: 0.022329
 >> iter 75000, loss: 0.022758
 >> iter 76000, loss: 0.027264
 >> iter 77000, loss: 0.021295
 >> iter 78000, loss: 0.021940
 >> iter 79000, loss: 0.020684
 >> iter 80000, loss: 0.021242
   Number of active neurons: 2
 >> iter 81000, loss: 0.028632
 >> iter 82000, loss: 0.023275
 >> iter 83000, loss: 0.021167
 >> iter 84000, loss: 0.019782
 >> iter 85000, loss: 0.023228
 >> iter 86000, loss: 0.020995
 >> iter 87000, loss: 0.021173
 >> iter 88000, loss: 0.020633
 >> iter 89000, loss: 0.023065
 >> iter 90000, loss: 0.021879
   Number of active neurons: 2
 >> iter 91000, loss: 0.022366
 >> iter 92000, loss: 0.020610
 >> iter 93000, loss: 0.030524
 >> iter 94000, loss: 0.024157
 >> iter 95000, loss: 0.046426
 >> iter 96000, loss: 0.028830
 >> iter 97000, loss: 0.025307
 >> iter 98000, loss: 0.033329
 >> iter 99000, loss: 0.034177
 >> iter 100000, loss: 0.027481
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.915358
 >> iter 2000, loss: 4.047306
 >> iter 3000, loss: 1.517082
 >> iter 4000, loss: 0.583919
 >> iter 5000, loss: 0.235417
 >> iter 6000, loss: 0.107097
 >> iter 7000, loss: 0.064698
 >> iter 8000, loss: 0.040537
 >> iter 9000, loss: 0.032701
 >> iter 10000, loss: 0.029085
   Number of active neurons: 3
 >> iter 11000, loss: 0.040761
 >> iter 12000, loss: 0.030884
 >> iter 13000, loss: 0.028200
 >> iter 14000, loss: 0.028779
 >> iter 15000, loss: 0.026673
 >> iter 16000, loss: 0.023311
 >> iter 17000, loss: 0.026590
 >> iter 18000, loss: 0.024220
 >> iter 19000, loss: 0.027468
 >> iter 20000, loss: 0.026211
   Number of active neurons: 3
 >> iter 21000, loss: 0.025849
 >> iter 22000, loss: 0.024065
 >> iter 23000, loss: 0.027402
 >> iter 24000, loss: 0.025718
 >> iter 25000, loss: 0.028157
 >> iter 26000, loss: 0.027787
 >> iter 27000, loss: 0.032134
 >> iter 28000, loss: 0.031463
 >> iter 29000, loss: 0.034635
 >> iter 30000, loss: 0.028400
   Number of active neurons: 3
 >> iter 31000, loss: 0.026856
 >> iter 32000, loss: 0.023552
 >> iter 33000, loss: 0.024566
 >> iter 34000, loss: 0.023875
 >> iter 35000, loss: 0.030137
 >> iter 36000, loss: 0.033194
 >> iter 37000, loss: 0.028104
 >> iter 38000, loss: 0.023809
 >> iter 39000, loss: 0.029518
 >> iter 40000, loss: 0.027005
   Number of active neurons: 3
 >> iter 41000, loss: 0.024199
 >> iter 42000, loss: 0.023700
 >> iter 43000, loss: 0.023807
 >> iter 44000, loss: 0.026338
 >> iter 45000, loss: 0.036615
 >> iter 46000, loss: 0.036224
 >> iter 47000, loss: 0.028550
 >> iter 48000, loss: 0.026458
 >> iter 49000, loss: 0.026903
 >> iter 50000, loss: 0.022876
   Number of active neurons: 3
 >> iter 51000, loss: 0.029620
 >> iter 52000, loss: 0.028368
 >> iter 53000, loss: 0.034001
 >> iter 54000, loss: 0.030380
 >> iter 55000, loss: 0.026678
 >> iter 56000, loss: 0.034729
 >> iter 57000, loss: 0.034281
 >> iter 58000, loss: 0.026638
 >> iter 59000, loss: 0.024074
 >> iter 60000, loss: 0.021404
   Number of active neurons: 2
 >> iter 61000, loss: 0.027071
 >> iter 62000, loss: 0.021787
 >> iter 63000, loss: 0.020596
 >> iter 64000, loss: 0.023804
 >> iter 65000, loss: 0.022306
 >> iter 66000, loss: 0.023811
 >> iter 67000, loss: 0.027447
 >> iter 68000, loss: 0.022113
 >> iter 69000, loss: 0.023168
 >> iter 70000, loss: 0.021001
   Number of active neurons: 2
 >> iter 71000, loss: 0.022641
 >> iter 72000, loss: 0.022779
 >> iter 73000, loss: 0.022715
 >> iter 74000, loss: 0.025221
 >> iter 75000, loss: 0.021222
 >> iter 76000, loss: 0.034418
 >> iter 77000, loss: 0.051245
 >> iter 78000, loss: 0.032433
 >> iter 79000, loss: 0.037618
 >> iter 80000, loss: 0.038231
   Number of active neurons: 2
 >> iter 81000, loss: 0.034051
 >> iter 82000, loss: 0.028829
 >> iter 83000, loss: 0.038045
 >> iter 84000, loss: 0.030063
 >> iter 85000, loss: 0.024172
 >> iter 86000, loss: 0.025487
 >> iter 87000, loss: 0.025139
 >> iter 88000, loss: 0.020454
 >> iter 89000, loss: 0.020997
 >> iter 90000, loss: 0.027398
   Number of active neurons: 2
 >> iter 91000, loss: 0.022569
 >> iter 92000, loss: 0.020738
 >> iter 93000, loss: 0.019576
 >> iter 94000, loss: 0.021161
 >> iter 95000, loss: 0.020088
 >> iter 96000, loss: 0.020238
 >> iter 97000, loss: 0.028527
 >> iter 98000, loss: 0.025471
 >> iter 99000, loss: 0.026483
 >> iter 100000, loss: 0.024658
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.973374
 >> iter 2000, loss: 4.082315
 >> iter 3000, loss: 1.526273
 >> iter 4000, loss: 0.580906
 >> iter 5000, loss: 0.247513
 >> iter 6000, loss: 0.114913
 >> iter 7000, loss: 0.068538
 >> iter 8000, loss: 0.044534
 >> iter 9000, loss: 0.035726
 >> iter 10000, loss: 0.031266
   Number of active neurons: 4
 >> iter 11000, loss: 0.031260
 >> iter 12000, loss: 0.033126
 >> iter 13000, loss: 0.032463
 >> iter 14000, loss: 0.031004
 >> iter 15000, loss: 0.036287
 >> iter 16000, loss: 0.033979
 >> iter 17000, loss: 0.027984
 >> iter 18000, loss: 0.026607
 >> iter 19000, loss: 0.030147
 >> iter 20000, loss: 0.028543
   Number of active neurons: 4
 >> iter 21000, loss: 0.028444
 >> iter 22000, loss: 0.027334
 >> iter 23000, loss: 0.026934
 >> iter 24000, loss: 0.024217
 >> iter 25000, loss: 0.027355
 >> iter 26000, loss: 0.025618
 >> iter 27000, loss: 0.027661
 >> iter 28000, loss: 0.027637
 >> iter 29000, loss: 0.025949
 >> iter 30000, loss: 0.030485
   Number of active neurons: 3
 >> iter 31000, loss: 0.026285
 >> iter 32000, loss: 0.026059
 >> iter 33000, loss: 0.027153
 >> iter 34000, loss: 0.025951
 >> iter 35000, loss: 0.026873
 >> iter 36000, loss: 0.031500
 >> iter 37000, loss: 0.044949
 >> iter 38000, loss: 0.048868
 >> iter 39000, loss: 0.043562
 >> iter 40000, loss: 0.036231
   Number of active neurons: 3
 >> iter 41000, loss: 0.034046
 >> iter 42000, loss: 0.042106
 >> iter 43000, loss: 0.031913
 >> iter 44000, loss: 0.029517
 >> iter 45000, loss: 0.026386
 >> iter 46000, loss: 0.024403
 >> iter 47000, loss: 0.022702
 >> iter 48000, loss: 0.020872
 >> iter 49000, loss: 0.027266
 >> iter 50000, loss: 0.036009
   Number of active neurons: 1
 >> iter 51000, loss: 0.031305
 >> iter 52000, loss: 0.033297
 >> iter 53000, loss: 0.032278
 >> iter 54000, loss: 0.024086
 >> iter 55000, loss: 0.024042
 >> iter 56000, loss: 0.020784
 >> iter 57000, loss: 0.028611
 >> iter 58000, loss: 0.030444
 >> iter 59000, loss: 0.024351
 >> iter 60000, loss: 0.021328
   Number of active neurons: 1
 >> iter 61000, loss: 0.017493
 >> iter 62000, loss: 0.017217
 >> iter 63000, loss: 0.018391
 >> iter 64000, loss: 0.019580
 >> iter 65000, loss: 0.017912
 >> iter 66000, loss: 0.018045
 >> iter 67000, loss: 0.038953
 >> iter 68000, loss: 0.027490
 >> iter 69000, loss: 0.024381
 >> iter 70000, loss: 0.018698
   Number of active neurons: 1
 >> iter 71000, loss: 0.021977
 >> iter 72000, loss: 0.018642
 >> iter 73000, loss: 0.035294
 >> iter 74000, loss: 0.031503
 >> iter 75000, loss: 0.021507
 >> iter 76000, loss: 0.020151
 >> iter 77000, loss: 0.017692
 >> iter 78000, loss: 0.028068
 >> iter 79000, loss: 0.025254
 >> iter 80000, loss: 0.018793
   Number of active neurons: 1
 >> iter 81000, loss: 0.017467
 >> iter 82000, loss: 0.020122
 >> iter 83000, loss: 0.018868
 >> iter 84000, loss: 0.021291
 >> iter 85000, loss: 0.019367
 >> iter 86000, loss: 0.025533
 >> iter 87000, loss: 0.024958
 >> iter 88000, loss: 0.020473
 >> iter 89000, loss: 0.025219
 >> iter 90000, loss: 0.018686
   Number of active neurons: 1
 >> iter 91000, loss: 0.024126
 >> iter 92000, loss: 0.021105
 >> iter 93000, loss: 0.018183
 >> iter 94000, loss: 0.034686
 >> iter 95000, loss: 0.026531
 >> iter 96000, loss: 0.025121
 >> iter 97000, loss: 0.037903
 >> iter 98000, loss: 0.037381
 >> iter 99000, loss: 0.025181
 >> iter 100000, loss: 0.022948
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.946638
 >> iter 2000, loss: 4.078905
 >> iter 3000, loss: 1.538439
 >> iter 4000, loss: 0.587590
 >> iter 5000, loss: 0.240651
 >> iter 6000, loss: 0.126370
 >> iter 7000, loss: 0.066829
 >> iter 8000, loss: 0.046465
 >> iter 9000, loss: 0.036781
 >> iter 10000, loss: 0.030455
   Number of active neurons: 4
 >> iter 11000, loss: 0.029308
 >> iter 12000, loss: 0.035253
 >> iter 13000, loss: 0.035119
 >> iter 14000, loss: 0.029414
 >> iter 15000, loss: 0.044584
 >> iter 16000, loss: 0.036688
 >> iter 17000, loss: 0.030465
 >> iter 18000, loss: 0.028587
 >> iter 19000, loss: 0.030216
 >> iter 20000, loss: 0.029647
   Number of active neurons: 4
 >> iter 21000, loss: 0.033867
 >> iter 22000, loss: 0.027951
 >> iter 23000, loss: 0.027170
 >> iter 24000, loss: 0.029505
 >> iter 25000, loss: 0.038907
 >> iter 26000, loss: 0.036386
 >> iter 27000, loss: 0.030962
 >> iter 28000, loss: 0.029734
 >> iter 29000, loss: 0.033553
 >> iter 30000, loss: 0.027375
   Number of active neurons: 3
 >> iter 31000, loss: 0.028009
 >> iter 32000, loss: 0.038182
 >> iter 33000, loss: 0.037390
 >> iter 34000, loss: 0.026958
 >> iter 35000, loss: 0.024462
 >> iter 36000, loss: 0.027935
 >> iter 37000, loss: 0.031122
 >> iter 38000, loss: 0.034740
 >> iter 39000, loss: 0.036324
 >> iter 40000, loss: 0.026833
   Number of active neurons: 2
 >> iter 41000, loss: 0.023208
 >> iter 42000, loss: 0.027102
 >> iter 43000, loss: 0.034092
 >> iter 44000, loss: 0.032637
 >> iter 45000, loss: 0.024614
 >> iter 46000, loss: 0.021600
 >> iter 47000, loss: 0.019477
 >> iter 48000, loss: 0.029800
 >> iter 49000, loss: 0.021837
 >> iter 50000, loss: 0.021543
   Number of active neurons: 1
 >> iter 51000, loss: 0.018312
 >> iter 52000, loss: 0.017639
 >> iter 53000, loss: 0.025273
 >> iter 54000, loss: 0.020948
 >> iter 55000, loss: 0.024836
 >> iter 56000, loss: 0.021489
 >> iter 57000, loss: 0.033235
 >> iter 58000, loss: 0.022496
 >> iter 59000, loss: 0.023731
 >> iter 60000, loss: 0.027200
   Number of active neurons: 1
 >> iter 61000, loss: 0.057089
 >> iter 62000, loss: 0.036319
 >> iter 63000, loss: 0.025106
 >> iter 64000, loss: 0.019682
 >> iter 65000, loss: 0.018707
 >> iter 66000, loss: 0.020033
 >> iter 67000, loss: 0.021969
 >> iter 68000, loss: 0.020096
 >> iter 69000, loss: 0.023884
 >> iter 70000, loss: 0.018287
   Number of active neurons: 1
 >> iter 71000, loss: 0.024265
 >> iter 72000, loss: 0.019698
 >> iter 73000, loss: 0.017971
 >> iter 74000, loss: 0.017925
 >> iter 75000, loss: 0.017730
 >> iter 76000, loss: 0.016085
 >> iter 77000, loss: 0.017862
 >> iter 78000, loss: 0.020222
 >> iter 79000, loss: 0.019368
 >> iter 80000, loss: 0.059753
   Number of active neurons: 1
 >> iter 81000, loss: 0.033038
 >> iter 82000, loss: 0.037265
 >> iter 83000, loss: 0.026059
 >> iter 84000, loss: 0.029336
 >> iter 85000, loss: 0.025272
 >> iter 86000, loss: 0.022142
 >> iter 87000, loss: 0.035469
 >> iter 88000, loss: 0.024373
 >> iter 89000, loss: 0.020671
 >> iter 90000, loss: 0.026689
   Number of active neurons: 1
 >> iter 91000, loss: 0.021064
 >> iter 92000, loss: 0.022246
 >> iter 93000, loss: 0.018324
 >> iter 94000, loss: 0.016878
 >> iter 95000, loss: 0.021116
 >> iter 96000, loss: 0.022048
 >> iter 97000, loss: 0.019765
 >> iter 98000, loss: 0.016355
 >> iter 99000, loss: 0.024809
 >> iter 100000, loss: 0.035425
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.932901
 >> iter 2000, loss: 4.059005
 >> iter 3000, loss: 1.525805
 >> iter 4000, loss: 0.583139
 >> iter 5000, loss: 0.233503
 >> iter 6000, loss: 0.107589
 >> iter 7000, loss: 0.063041
 >> iter 8000, loss: 0.039845
 >> iter 9000, loss: 0.030846
 >> iter 10000, loss: 0.028102
   Number of active neurons: 3
 >> iter 11000, loss: 0.032277
 >> iter 12000, loss: 0.028182
 >> iter 13000, loss: 0.038522
 >> iter 14000, loss: 0.029089
 >> iter 15000, loss: 0.053654
 >> iter 16000, loss: 0.033573
 >> iter 17000, loss: 0.028914
 >> iter 18000, loss: 0.023194
 >> iter 19000, loss: 0.023704
 >> iter 20000, loss: 0.021600
   Number of active neurons: 2
 >> iter 21000, loss: 0.024222
 >> iter 22000, loss: 0.034097
 >> iter 23000, loss: 0.026470
 >> iter 24000, loss: 0.023278
 >> iter 25000, loss: 0.026018
 >> iter 26000, loss: 0.024307
 >> iter 27000, loss: 0.035980
 >> iter 28000, loss: 0.039190
 >> iter 29000, loss: 0.028697
 >> iter 30000, loss: 0.028399
   Number of active neurons: 2
 >> iter 31000, loss: 0.022739
 >> iter 32000, loss: 0.021612
 >> iter 33000, loss: 0.032777
 >> iter 34000, loss: 0.034698
 >> iter 35000, loss: 0.027135
 >> iter 36000, loss: 0.027023
 >> iter 37000, loss: 0.022611
 >> iter 38000, loss: 0.021288
 >> iter 39000, loss: 0.020309
 >> iter 40000, loss: 0.024900
   Number of active neurons: 2
 >> iter 41000, loss: 0.022210
 >> iter 42000, loss: 0.022003
 >> iter 43000, loss: 0.021288
 >> iter 44000, loss: 0.023099
 >> iter 45000, loss: 0.023111
 >> iter 46000, loss: 0.022478
 >> iter 47000, loss: 0.025634
 >> iter 48000, loss: 0.022699
 >> iter 49000, loss: 0.039493
 >> iter 50000, loss: 0.040576
   Number of active neurons: 2
 >> iter 51000, loss: 0.029096
 >> iter 52000, loss: 0.032643
 >> iter 53000, loss: 0.024921
 >> iter 54000, loss: 0.022875
 >> iter 55000, loss: 0.023649
 >> iter 56000, loss: 0.027240
 >> iter 57000, loss: 0.024451
 >> iter 58000, loss: 0.024227
 >> iter 59000, loss: 0.031881
 >> iter 60000, loss: 0.041767
   Number of active neurons: 2
 >> iter 61000, loss: 0.029736
 >> iter 62000, loss: 0.024506
 >> iter 63000, loss: 0.022939
 >> iter 64000, loss: 0.021905
 >> iter 65000, loss: 0.022613
 >> iter 66000, loss: 0.023051
 >> iter 67000, loss: 0.019970
 >> iter 68000, loss: 0.023606
 >> iter 69000, loss: 0.021963
 >> iter 70000, loss: 0.022246
   Number of active neurons: 1
 >> iter 71000, loss: 0.018939
 >> iter 72000, loss: 0.021055
 >> iter 73000, loss: 0.030208
 >> iter 74000, loss: 0.027301
 >> iter 75000, loss: 0.021907
 >> iter 76000, loss: 0.031584
 >> iter 77000, loss: 0.023815
 >> iter 78000, loss: 0.018385
 >> iter 79000, loss: 0.016835
 >> iter 80000, loss: 0.019820
   Number of active neurons: 1
 >> iter 81000, loss: 0.017528
 >> iter 82000, loss: 0.018343
 >> iter 83000, loss: 0.017497
 >> iter 84000, loss: 0.017560
 >> iter 85000, loss: 0.017342
 >> iter 86000, loss: 0.019262
 >> iter 87000, loss: 0.017139
 >> iter 88000, loss: 0.022410
 >> iter 89000, loss: 0.018788
 >> iter 90000, loss: 0.025326
   Number of active neurons: 1
 >> iter 91000, loss: 0.019107
 >> iter 92000, loss: 0.018602
 >> iter 93000, loss: 0.016676
 >> iter 94000, loss: 0.017077
 >> iter 95000, loss: 0.018980
 >> iter 96000, loss: 0.035954
 >> iter 97000, loss: 0.025101
 >> iter 98000, loss: 0.030726
 >> iter 99000, loss: 0.039673
 >> iter 100000, loss: 0.026961
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.937918
 >> iter 2000, loss: 4.087770
 >> iter 3000, loss: 1.543541
 >> iter 4000, loss: 0.590872
 >> iter 5000, loss: 0.237773
 >> iter 6000, loss: 0.107004
 >> iter 7000, loss: 0.064183
 >> iter 8000, loss: 0.040355
 >> iter 9000, loss: 0.030230
 >> iter 10000, loss: 0.026787
   Number of active neurons: 3
 >> iter 11000, loss: 0.025933
 >> iter 12000, loss: 0.034520
 >> iter 13000, loss: 0.027885
 >> iter 14000, loss: 0.028107
 >> iter 15000, loss: 0.028198
 >> iter 16000, loss: 0.025741
 >> iter 17000, loss: 0.025735
 >> iter 18000, loss: 0.028162
 >> iter 19000, loss: 0.026316
 >> iter 20000, loss: 0.024002
   Number of active neurons: 3
 >> iter 21000, loss: 0.029254
 >> iter 22000, loss: 0.024750
 >> iter 23000, loss: 0.030247
 >> iter 24000, loss: 0.026451
 >> iter 25000, loss: 0.027033
 >> iter 26000, loss: 0.025934
 >> iter 27000, loss: 0.032937
 >> iter 28000, loss: 0.030250
 >> iter 29000, loss: 0.030706
 >> iter 30000, loss: 0.037914
   Number of active neurons: 3
 >> iter 31000, loss: 0.030927
 >> iter 32000, loss: 0.026784
 >> iter 33000, loss: 0.027924
 >> iter 34000, loss: 0.025719
 >> iter 35000, loss: 0.026169
 >> iter 36000, loss: 0.053480
 >> iter 37000, loss: 0.035550
 >> iter 38000, loss: 0.041349
 >> iter 39000, loss: 0.035550
 >> iter 40000, loss: 0.030860
   Number of active neurons: 3
 >> iter 41000, loss: 0.027822
 >> iter 42000, loss: 0.024402
 >> iter 43000, loss: 0.062724
 >> iter 44000, loss: 0.043424
 >> iter 45000, loss: 0.034926
 >> iter 46000, loss: 0.027311
 >> iter 47000, loss: 0.027968
 >> iter 48000, loss: 0.025789
 >> iter 49000, loss: 0.025387
 >> iter 50000, loss: 0.023570
   Number of active neurons: 2
 >> iter 51000, loss: 0.028664
 >> iter 52000, loss: 0.028515
 >> iter 53000, loss: 0.025173
 >> iter 54000, loss: 0.023670
 >> iter 55000, loss: 0.025182
 >> iter 56000, loss: 0.021332
 >> iter 57000, loss: 0.022708
 >> iter 58000, loss: 0.036598
 >> iter 59000, loss: 0.028878
 >> iter 60000, loss: 0.022754
   Number of active neurons: 2
 >> iter 61000, loss: 0.020859
 >> iter 62000, loss: 0.023022
 >> iter 63000, loss: 0.025384
 >> iter 64000, loss: 0.037767
 >> iter 65000, loss: 0.029817
 >> iter 66000, loss: 0.023938
 >> iter 67000, loss: 0.023555
 >> iter 68000, loss: 0.019720
 >> iter 69000, loss: 0.022441
 >> iter 70000, loss: 0.020026
   Number of active neurons: 1
 >> iter 71000, loss: 0.019069
 >> iter 72000, loss: 0.048516
 >> iter 73000, loss: 0.046517
 >> iter 74000, loss: 0.028077
 >> iter 75000, loss: 0.022950
 >> iter 76000, loss: 0.019107
 >> iter 77000, loss: 0.018719
 >> iter 78000, loss: 0.019775
 >> iter 79000, loss: 0.017884
 >> iter 80000, loss: 0.023565
   Number of active neurons: 1
 >> iter 81000, loss: 0.022667
 >> iter 82000, loss: 0.021018
 >> iter 83000, loss: 0.018238
 >> iter 84000, loss: 0.017192
 >> iter 85000, loss: 0.017150
 >> iter 86000, loss: 0.016483
 >> iter 87000, loss: 0.055220
 >> iter 88000, loss: 0.036246
 >> iter 89000, loss: 0.029388
 >> iter 90000, loss: 0.025467
   Number of active neurons: 1
 >> iter 91000, loss: 0.026699
 >> iter 92000, loss: 0.023150
 >> iter 93000, loss: 0.019457
 >> iter 94000, loss: 0.020992
 >> iter 95000, loss: 0.019690
 >> iter 96000, loss: 0.021455
 >> iter 97000, loss: 0.019988
 >> iter 98000, loss: 0.017273
 >> iter 99000, loss: 0.016966
 >> iter 100000, loss: 0.016299
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.919107
 >> iter 2000, loss: 4.094707
 >> iter 3000, loss: 1.534249
 >> iter 4000, loss: 0.589265
 >> iter 5000, loss: 0.240148
 >> iter 6000, loss: 0.112771
 >> iter 7000, loss: 0.059937
 >> iter 8000, loss: 0.039068
 >> iter 9000, loss: 0.040552
 >> iter 10000, loss: 0.033719
   Number of active neurons: 4
 >> iter 11000, loss: 0.034329
 >> iter 12000, loss: 0.031078
 >> iter 13000, loss: 0.028073
 >> iter 14000, loss: 0.024585
 >> iter 15000, loss: 0.025391
 >> iter 16000, loss: 0.026920
 >> iter 17000, loss: 0.032293
 >> iter 18000, loss: 0.030091
 >> iter 19000, loss: 0.038727
 >> iter 20000, loss: 0.030738
   Number of active neurons: 2
 >> iter 21000, loss: 0.027970
 >> iter 22000, loss: 0.023081
 >> iter 23000, loss: 0.026691
 >> iter 24000, loss: 0.024385
 >> iter 25000, loss: 0.030610
 >> iter 26000, loss: 0.024232
 >> iter 27000, loss: 0.023977
 >> iter 28000, loss: 0.024200
 >> iter 29000, loss: 0.028571
 >> iter 30000, loss: 0.032673
   Number of active neurons: 2
 >> iter 31000, loss: 0.026853
 >> iter 32000, loss: 0.021866
 >> iter 33000, loss: 0.023552
 >> iter 34000, loss: 0.026234
 >> iter 35000, loss: 0.023829
 >> iter 36000, loss: 0.023094
 >> iter 37000, loss: 0.036260
 >> iter 38000, loss: 0.029772
 >> iter 39000, loss: 0.027373
 >> iter 40000, loss: 0.022830
   Number of active neurons: 2
 >> iter 41000, loss: 0.024132
 >> iter 42000, loss: 0.022695
 >> iter 43000, loss: 0.030466
 >> iter 44000, loss: 0.037325
 >> iter 45000, loss: 0.031959
 >> iter 46000, loss: 0.033200
 >> iter 47000, loss: 0.029969
 >> iter 48000, loss: 0.025766
 >> iter 49000, loss: 0.041322
 >> iter 50000, loss: 0.028307
   Number of active neurons: 1
 >> iter 51000, loss: 0.021094
 >> iter 52000, loss: 0.020541
 >> iter 53000, loss: 0.020176
 >> iter 54000, loss: 0.027684
 >> iter 55000, loss: 0.021449
 >> iter 56000, loss: 0.018054
 >> iter 57000, loss: 0.016492
 >> iter 58000, loss: 0.018459
 >> iter 59000, loss: 0.017764
 >> iter 60000, loss: 0.025580
   Number of active neurons: 1
 >> iter 61000, loss: 0.021378
 >> iter 62000, loss: 0.028493
 >> iter 63000, loss: 0.020549
 >> iter 64000, loss: 0.046045
 >> iter 65000, loss: 0.031932
 >> iter 66000, loss: 0.021879
 >> iter 67000, loss: 0.018886
 >> iter 68000, loss: 0.018912
 >> iter 69000, loss: 0.020324
 >> iter 70000, loss: 0.017808
   Number of active neurons: 1
 >> iter 71000, loss: 0.022593
 >> iter 72000, loss: 0.023522
 >> iter 73000, loss: 0.020739
 >> iter 74000, loss: 0.017590
 >> iter 75000, loss: 0.018646
 >> iter 76000, loss: 0.018888
 >> iter 77000, loss: 0.036051
 >> iter 78000, loss: 0.025971
 >> iter 79000, loss: 0.021068
 >> iter 80000, loss: 0.022355
   Number of active neurons: 1
 >> iter 81000, loss: 0.019683
 >> iter 82000, loss: 0.017191
 >> iter 83000, loss: 0.015744
 >> iter 84000, loss: 0.017443
 >> iter 85000, loss: 0.016915
 >> iter 86000, loss: 0.019476
 >> iter 87000, loss: 0.020842
 >> iter 88000, loss: 0.018507
 >> iter 89000, loss: 0.029398
 >> iter 90000, loss: 0.044108
   Number of active neurons: 1
 >> iter 91000, loss: 0.031027
 >> iter 92000, loss: 0.022365
 >> iter 93000, loss: 0.019813
 >> iter 94000, loss: 0.020655
 >> iter 95000, loss: 0.018789
 >> iter 96000, loss: 0.016454
 >> iter 97000, loss: 0.016816
 >> iter 98000, loss: 0.023852
 >> iter 99000, loss: 0.028212
 >> iter 100000, loss: 0.021494
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.962125
 >> iter 2000, loss: 4.088559
 >> iter 3000, loss: 1.542844
 >> iter 4000, loss: 0.605847
 >> iter 5000, loss: 0.250767
 >> iter 6000, loss: 0.111551
 >> iter 7000, loss: 0.061064
 >> iter 8000, loss: 0.057739
 >> iter 9000, loss: 0.046388
 >> iter 10000, loss: 0.042794
   Number of active neurons: 4
 >> iter 11000, loss: 0.036522
 >> iter 12000, loss: 0.034894
 >> iter 13000, loss: 0.034281
 >> iter 14000, loss: 0.032570
 >> iter 15000, loss: 0.028981
 >> iter 16000, loss: 0.025986
 >> iter 17000, loss: 0.026424
 >> iter 18000, loss: 0.026175
 >> iter 19000, loss: 0.026479
 >> iter 20000, loss: 0.029604
   Number of active neurons: 3
 >> iter 21000, loss: 0.025351
 >> iter 22000, loss: 0.028432
 >> iter 23000, loss: 0.026284
 >> iter 24000, loss: 0.023653
 >> iter 25000, loss: 0.024557
 >> iter 26000, loss: 0.023496
 >> iter 27000, loss: 0.023446
 >> iter 28000, loss: 0.026800
 >> iter 29000, loss: 0.026218
 >> iter 30000, loss: 0.025013
   Number of active neurons: 3
 >> iter 31000, loss: 0.024739
 >> iter 32000, loss: 0.023976
 >> iter 33000, loss: 0.032854
 >> iter 34000, loss: 0.026087
 >> iter 35000, loss: 0.028728
 >> iter 36000, loss: 0.026963
 >> iter 37000, loss: 0.027787
 >> iter 38000, loss: 0.024452
 >> iter 39000, loss: 0.023903
 >> iter 40000, loss: 0.022122
   Number of active neurons: 3
 >> iter 41000, loss: 0.026693
 >> iter 42000, loss: 0.024960
 >> iter 43000, loss: 0.029961
 >> iter 44000, loss: 0.026089
 >> iter 45000, loss: 0.031117
 >> iter 46000, loss: 0.028010
 >> iter 47000, loss: 0.025818
 >> iter 48000, loss: 0.030100
 >> iter 49000, loss: 0.029333
 >> iter 50000, loss: 0.028230
   Number of active neurons: 3
 >> iter 51000, loss: 0.029284
 >> iter 52000, loss: 0.025814
 >> iter 53000, loss: 0.028649
 >> iter 54000, loss: 0.027599
 >> iter 55000, loss: 0.027349
 >> iter 56000, loss: 0.026064
 >> iter 57000, loss: 0.024647
 >> iter 58000, loss: 0.023619
 >> iter 59000, loss: 0.026045
 >> iter 60000, loss: 0.024794
   Number of active neurons: 3
 >> iter 61000, loss: 0.022989
 >> iter 62000, loss: 0.028163
 >> iter 63000, loss: 0.025686
 >> iter 64000, loss: 0.025236
 >> iter 65000, loss: 0.027347
 >> iter 66000, loss: 0.029263
 >> iter 67000, loss: 0.023229
 >> iter 68000, loss: 0.024079
 >> iter 69000, loss: 0.023751
 >> iter 70000, loss: 0.023645
   Number of active neurons: 3
 >> iter 71000, loss: 0.026625
 >> iter 72000, loss: 0.044402
 >> iter 73000, loss: 0.031961
 >> iter 74000, loss: 0.026898
 >> iter 75000, loss: 0.028767
 >> iter 76000, loss: 0.027153
 >> iter 77000, loss: 0.028830
 >> iter 78000, loss: 0.028862
 >> iter 79000, loss: 0.025730
 >> iter 80000, loss: 0.023746
   Number of active neurons: 2
 >> iter 81000, loss: 0.024969
 >> iter 82000, loss: 0.023470
 >> iter 83000, loss: 0.021730
 >> iter 84000, loss: 0.021485
 >> iter 85000, loss: 0.020511
 >> iter 86000, loss: 0.023406
 >> iter 87000, loss: 0.023536
 >> iter 88000, loss: 0.042648
 >> iter 89000, loss: 0.028952
 >> iter 90000, loss: 0.024767
   Number of active neurons: 2
 >> iter 91000, loss: 0.022587
 >> iter 92000, loss: 0.022140
 >> iter 93000, loss: 0.023222
 >> iter 94000, loss: 0.020521
 >> iter 95000, loss: 0.021806
 >> iter 96000, loss: 0.025944
 >> iter 97000, loss: 0.027581
 >> iter 98000, loss: 0.024822
 >> iter 99000, loss: 0.026583
 >> iter 100000, loss: 0.022147
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.901656
 >> iter 2000, loss: 4.087997
 >> iter 3000, loss: 1.531760
 >> iter 4000, loss: 0.604418
 >> iter 5000, loss: 0.265537
 >> iter 6000, loss: 0.119780
 >> iter 7000, loss: 0.062072
 >> iter 8000, loss: 0.038588
 >> iter 9000, loss: 0.029384
 >> iter 10000, loss: 0.027672
   Number of active neurons: 3
 >> iter 11000, loss: 0.044511
 >> iter 12000, loss: 0.038492
 >> iter 13000, loss: 0.029521
 >> iter 14000, loss: 0.028560
 >> iter 15000, loss: 0.025451
 >> iter 16000, loss: 0.025172
 >> iter 17000, loss: 0.024095
 >> iter 18000, loss: 0.027466
 >> iter 19000, loss: 0.028786
 >> iter 20000, loss: 0.026772
   Number of active neurons: 3
 >> iter 21000, loss: 0.030177
 >> iter 22000, loss: 0.031468
 >> iter 23000, loss: 0.025747
 >> iter 24000, loss: 0.029791
 >> iter 25000, loss: 0.032753
 >> iter 26000, loss: 0.028126
 >> iter 27000, loss: 0.027116
 >> iter 28000, loss: 0.067390
 >> iter 29000, loss: 0.041369
 >> iter 30000, loss: 0.034010
   Number of active neurons: 3
 >> iter 31000, loss: 0.052525
 >> iter 32000, loss: 0.034032
 >> iter 33000, loss: 0.030246
 >> iter 34000, loss: 0.025118
 >> iter 35000, loss: 0.030299
 >> iter 36000, loss: 0.025674
 >> iter 37000, loss: 0.030016
 >> iter 38000, loss: 0.040335
 >> iter 39000, loss: 0.030807
 >> iter 40000, loss: 0.023582
   Number of active neurons: 2
 >> iter 41000, loss: 0.026359
 >> iter 42000, loss: 0.022144
 >> iter 43000, loss: 0.027512
 >> iter 44000, loss: 0.022895
 >> iter 45000, loss: 0.026405
 >> iter 46000, loss: 0.027654
 >> iter 47000, loss: 0.023665
 >> iter 48000, loss: 0.025503
 >> iter 49000, loss: 0.028288
 >> iter 50000, loss: 0.024620
   Number of active neurons: 2
 >> iter 51000, loss: 0.028468
 >> iter 52000, loss: 0.024027
 >> iter 53000, loss: 0.020638
 >> iter 54000, loss: 0.024619
 >> iter 55000, loss: 0.022270
 >> iter 56000, loss: 0.020181
 >> iter 57000, loss: 0.018844
 >> iter 58000, loss: 0.021096
 >> iter 59000, loss: 0.022090
 >> iter 60000, loss: 0.026128
   Number of active neurons: 1
 >> iter 61000, loss: 0.026058
 >> iter 62000, loss: 0.019810
 >> iter 63000, loss: 0.019798
 >> iter 64000, loss: 0.018078
 >> iter 65000, loss: 0.019642
 >> iter 66000, loss: 0.022136
 >> iter 67000, loss: 0.018889
 >> iter 68000, loss: 0.019467
 >> iter 69000, loss: 0.018942
 >> iter 70000, loss: 0.024134
   Number of active neurons: 1
 >> iter 71000, loss: 0.033989
 >> iter 72000, loss: 0.023718
 >> iter 73000, loss: 0.019227
 >> iter 74000, loss: 0.019545
 >> iter 75000, loss: 0.030133
 >> iter 76000, loss: 0.021342
 >> iter 77000, loss: 0.020516
 >> iter 78000, loss: 0.018538
 >> iter 79000, loss: 0.018745
 >> iter 80000, loss: 0.024151
   Number of active neurons: 1
 >> iter 81000, loss: 0.020668
 >> iter 82000, loss: 0.017107
 >> iter 83000, loss: 0.019346
 >> iter 84000, loss: 0.017527
 >> iter 85000, loss: 0.029383
 >> iter 86000, loss: 0.020314
 >> iter 87000, loss: 0.019469
 >> iter 88000, loss: 0.020000
 >> iter 89000, loss: 0.017525
 >> iter 90000, loss: 0.031536
   Number of active neurons: 1
 >> iter 91000, loss: 0.022189
 >> iter 92000, loss: 0.018598
 >> iter 93000, loss: 0.018776
 >> iter 94000, loss: 0.017451
 >> iter 95000, loss: 0.019670
 >> iter 96000, loss: 0.031600
 >> iter 97000, loss: 0.026209
 >> iter 98000, loss: 0.039988
 >> iter 99000, loss: 0.024530
 >> iter 100000, loss: 0.026166
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.989832
 >> iter 2000, loss: 4.099749
 >> iter 3000, loss: 1.541083
 >> iter 4000, loss: 0.586075
 >> iter 5000, loss: 0.235535
 >> iter 6000, loss: 0.113164
 >> iter 7000, loss: 0.069843
 >> iter 8000, loss: 0.043253
 >> iter 9000, loss: 0.045897
 >> iter 10000, loss: 0.035664
   Number of active neurons: 4
 >> iter 11000, loss: 0.034047
 >> iter 12000, loss: 0.043467
 >> iter 13000, loss: 0.035593
 >> iter 14000, loss: 0.033656
 >> iter 15000, loss: 0.029475
 >> iter 16000, loss: 0.026892
 >> iter 17000, loss: 0.026727
 >> iter 18000, loss: 0.023969
 >> iter 19000, loss: 0.026046
 >> iter 20000, loss: 0.025184
   Number of active neurons: 3
 >> iter 21000, loss: 0.026110
 >> iter 22000, loss: 0.023548
 >> iter 23000, loss: 0.027286
 >> iter 24000, loss: 0.023684
 >> iter 25000, loss: 0.021907
 >> iter 26000, loss: 0.023555
 >> iter 27000, loss: 0.027118
 >> iter 28000, loss: 0.024458
 >> iter 29000, loss: 0.026043
 >> iter 30000, loss: 0.027579
   Number of active neurons: 2
 >> iter 31000, loss: 0.034348
 >> iter 32000, loss: 0.036441
 >> iter 33000, loss: 0.028784
 >> iter 34000, loss: 0.043647
 >> iter 35000, loss: 0.042131
 >> iter 36000, loss: 0.028398
 >> iter 37000, loss: 0.026787
 >> iter 38000, loss: 0.023286
 >> iter 39000, loss: 0.021464
 >> iter 40000, loss: 0.029928
   Number of active neurons: 2
 >> iter 41000, loss: 0.025773
 >> iter 42000, loss: 0.027930
 >> iter 43000, loss: 0.027196
 >> iter 44000, loss: 0.022743
 >> iter 45000, loss: 0.020233
 >> iter 46000, loss: 0.025702
 >> iter 47000, loss: 0.026967
 >> iter 48000, loss: 0.023393
 >> iter 49000, loss: 0.021747
 >> iter 50000, loss: 0.020006
   Number of active neurons: 1
 >> iter 51000, loss: 0.021547
 >> iter 52000, loss: 0.028171
 >> iter 53000, loss: 0.021585
 >> iter 54000, loss: 0.022143
 >> iter 55000, loss: 0.020178
 >> iter 56000, loss: 0.021598
 >> iter 57000, loss: 0.023318
 >> iter 58000, loss: 0.022884
 >> iter 59000, loss: 0.021598
 >> iter 60000, loss: 0.021160
   Number of active neurons: 1
 >> iter 61000, loss: 0.017755
 >> iter 62000, loss: 0.017576
 >> iter 63000, loss: 0.016200
 >> iter 64000, loss: 0.022230
 >> iter 65000, loss: 0.029416
 >> iter 66000, loss: 0.033534
 >> iter 67000, loss: 0.035845
 >> iter 68000, loss: 0.024320
 >> iter 69000, loss: 0.052530
 >> iter 70000, loss: 0.045182
   Number of active neurons: 1
 >> iter 71000, loss: 0.029897
 >> iter 72000, loss: 0.023902
 >> iter 73000, loss: 0.019071
 >> iter 74000, loss: 0.016751
 >> iter 75000, loss: 0.016724
 >> iter 76000, loss: 0.017801
 >> iter 77000, loss: 0.029980
 >> iter 78000, loss: 0.022498
 >> iter 79000, loss: 0.019519
 >> iter 80000, loss: 0.021032
   Number of active neurons: 1
 >> iter 81000, loss: 0.024153
 >> iter 82000, loss: 0.022027
 >> iter 83000, loss: 0.018147
 >> iter 84000, loss: 0.018567
 >> iter 85000, loss: 0.023012
 >> iter 86000, loss: 0.020252
 >> iter 87000, loss: 0.021320
 >> iter 88000, loss: 0.027038
 >> iter 89000, loss: 0.023217
 >> iter 90000, loss: 0.020487
   Number of active neurons: 1
 >> iter 91000, loss: 0.017533
 >> iter 92000, loss: 0.015318
 >> iter 93000, loss: 0.019225
 >> iter 94000, loss: 0.016268
 >> iter 95000, loss: 0.030476
 >> iter 96000, loss: 0.023356
 >> iter 97000, loss: 0.018976
 >> iter 98000, loss: 0.020554
 >> iter 99000, loss: 0.024895
 >> iter 100000, loss: 0.022836
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.921702
 >> iter 2000, loss: 4.072535
 >> iter 3000, loss: 1.520315
 >> iter 4000, loss: 0.577909
 >> iter 5000, loss: 0.229841
 >> iter 6000, loss: 0.103792
 >> iter 7000, loss: 0.063719
 >> iter 8000, loss: 0.039239
 >> iter 9000, loss: 0.035547
 >> iter 10000, loss: 0.040356
   Number of active neurons: 4
 >> iter 11000, loss: 0.035935
 >> iter 12000, loss: 0.033622
 >> iter 13000, loss: 0.032248
 >> iter 14000, loss: 0.027556
 >> iter 15000, loss: 0.030418
 >> iter 16000, loss: 0.026478
 >> iter 17000, loss: 0.034647
 >> iter 18000, loss: 0.027659
 >> iter 19000, loss: 0.024535
 >> iter 20000, loss: 0.024937
   Number of active neurons: 4
 >> iter 21000, loss: 0.025976
 >> iter 22000, loss: 0.027774
 >> iter 23000, loss: 0.030107
 >> iter 24000, loss: 0.023868
 >> iter 25000, loss: 0.023254
 >> iter 26000, loss: 0.027696
 >> iter 27000, loss: 0.024126
 >> iter 28000, loss: 0.022720
 >> iter 29000, loss: 0.025209
 >> iter 30000, loss: 0.025411
   Number of active neurons: 3
 >> iter 31000, loss: 0.024019
 >> iter 32000, loss: 0.026632
 >> iter 33000, loss: 0.024084
 >> iter 34000, loss: 0.023227
 >> iter 35000, loss: 0.027627
 >> iter 36000, loss: 0.028133
 >> iter 37000, loss: 0.031575
 >> iter 38000, loss: 0.032035
 >> iter 39000, loss: 0.036094
 >> iter 40000, loss: 0.026261
   Number of active neurons: 3
 >> iter 41000, loss: 0.025915
 >> iter 42000, loss: 0.025785
 >> iter 43000, loss: 0.024440
 >> iter 44000, loss: 0.026006
 >> iter 45000, loss: 0.036888
 >> iter 46000, loss: 0.029236
 >> iter 47000, loss: 0.034468
 >> iter 48000, loss: 0.027865
 >> iter 49000, loss: 0.036644
 >> iter 50000, loss: 0.031958
   Number of active neurons: 3
 >> iter 51000, loss: 0.025638
 >> iter 52000, loss: 0.037793
 >> iter 53000, loss: 0.029035
 >> iter 54000, loss: 0.026319
 >> iter 55000, loss: 0.024992
 >> iter 56000, loss: 0.052811
 >> iter 57000, loss: 0.041213
 >> iter 58000, loss: 0.033897
 >> iter 59000, loss: 0.030987
 >> iter 60000, loss: 0.030527
   Number of active neurons: 3
 >> iter 61000, loss: 0.028131
 >> iter 62000, loss: 0.032949
 >> iter 63000, loss: 0.034254
 >> iter 64000, loss: 0.028887
 >> iter 65000, loss: 0.025161
 >> iter 66000, loss: 0.023030
 >> iter 67000, loss: 0.028247
 >> iter 68000, loss: 0.023442
 >> iter 69000, loss: 0.043739
 >> iter 70000, loss: 0.029098
   Number of active neurons: 2
 >> iter 71000, loss: 0.026796
 >> iter 72000, loss: 0.030861
 >> iter 73000, loss: 0.045912
 >> iter 74000, loss: 0.030072
 >> iter 75000, loss: 0.023826
 >> iter 76000, loss: 0.033733
 >> iter 77000, loss: 0.033691
 >> iter 78000, loss: 0.024736
 >> iter 79000, loss: 0.025812
 >> iter 80000, loss: 0.022190
   Number of active neurons: 2
 >> iter 81000, loss: 0.022021
 >> iter 82000, loss: 0.021245
 >> iter 83000, loss: 0.025366
 >> iter 84000, loss: 0.025885
 >> iter 85000, loss: 0.027720
 >> iter 86000, loss: 0.034579
 >> iter 87000, loss: 0.027747
 >> iter 88000, loss: 0.022503
 >> iter 89000, loss: 0.023942
 >> iter 90000, loss: 0.026237
   Number of active neurons: 1
 >> iter 91000, loss: 0.020947
 >> iter 92000, loss: 0.022815
 >> iter 93000, loss: 0.022298
 >> iter 94000, loss: 0.025757
 >> iter 95000, loss: 0.020441
 >> iter 96000, loss: 0.033845
 >> iter 97000, loss: 0.027743
 >> iter 98000, loss: 0.020820
 >> iter 99000, loss: 0.020615
 >> iter 100000, loss: 0.020765
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.931346
 >> iter 2000, loss: 4.062984
 >> iter 3000, loss: 1.542581
 >> iter 4000, loss: 0.594489
 >> iter 5000, loss: 0.248399
 >> iter 6000, loss: 0.115295
 >> iter 7000, loss: 0.062941
 >> iter 8000, loss: 0.046356
 >> iter 9000, loss: 0.036562
 >> iter 10000, loss: 0.034628
   Number of active neurons: 5
 >> iter 11000, loss: 0.029898
 >> iter 12000, loss: 0.029343
 >> iter 13000, loss: 0.028637
 >> iter 14000, loss: 0.031507
 >> iter 15000, loss: 0.028552
 >> iter 16000, loss: 0.026227
 >> iter 17000, loss: 0.029799
 >> iter 18000, loss: 0.032340
 >> iter 19000, loss: 0.028890
 >> iter 20000, loss: 0.025198
   Number of active neurons: 3
 >> iter 21000, loss: 0.035140
 >> iter 22000, loss: 0.030844
 >> iter 23000, loss: 0.029663
 >> iter 24000, loss: 0.033857
 >> iter 25000, loss: 0.030918
 >> iter 26000, loss: 0.029706
 >> iter 27000, loss: 0.026399
 >> iter 28000, loss: 0.029193
 >> iter 29000, loss: 0.025405
 >> iter 30000, loss: 0.023217
   Number of active neurons: 3
 >> iter 31000, loss: 0.034324
 >> iter 32000, loss: 0.028417
 >> iter 33000, loss: 0.030834
 >> iter 34000, loss: 0.026055
 >> iter 35000, loss: 0.025194
 >> iter 36000, loss: 0.025278
 >> iter 37000, loss: 0.024291
 >> iter 38000, loss: 0.026301
 >> iter 39000, loss: 0.065778
 >> iter 40000, loss: 0.042012
   Number of active neurons: 3
 >> iter 41000, loss: 0.041436
 >> iter 42000, loss: 0.042234
 >> iter 43000, loss: 0.033577
 >> iter 44000, loss: 0.027602
 >> iter 45000, loss: 0.040382
 >> iter 46000, loss: 0.036320
 >> iter 47000, loss: 0.031318
 >> iter 48000, loss: 0.025549
 >> iter 49000, loss: 0.028555
 >> iter 50000, loss: 0.032692
   Number of active neurons: 3
 >> iter 51000, loss: 0.027327
 >> iter 52000, loss: 0.031938
 >> iter 53000, loss: 0.032891
 >> iter 54000, loss: 0.026071
 >> iter 55000, loss: 0.023614
 >> iter 56000, loss: 0.033909
 >> iter 57000, loss: 0.024688
 >> iter 58000, loss: 0.027466
 >> iter 59000, loss: 0.024480
 >> iter 60000, loss: 0.020739
   Number of active neurons: 1
 >> iter 61000, loss: 0.018958
 >> iter 62000, loss: 0.022610
 >> iter 63000, loss: 0.019831
 >> iter 64000, loss: 0.023267
 >> iter 65000, loss: 0.020726
 >> iter 66000, loss: 0.018147
 >> iter 67000, loss: 0.017345
 >> iter 68000, loss: 0.030196
 >> iter 69000, loss: 0.020859
 >> iter 70000, loss: 0.026913
   Number of active neurons: 1
 >> iter 71000, loss: 0.026607
 >> iter 72000, loss: 0.023355
 >> iter 73000, loss: 0.022219
 >> iter 74000, loss: 0.032225
 >> iter 75000, loss: 0.021997
 >> iter 76000, loss: 0.035377
 >> iter 77000, loss: 0.035111
 >> iter 78000, loss: 0.023809
 >> iter 79000, loss: 0.025965
 >> iter 80000, loss: 0.022596
   Number of active neurons: 1
 >> iter 81000, loss: 0.019233
 >> iter 82000, loss: 0.021614
 >> iter 83000, loss: 0.024827
 >> iter 84000, loss: 0.021819
 >> iter 85000, loss: 0.019746
 >> iter 86000, loss: 0.025374
 >> iter 87000, loss: 0.020203
 >> iter 88000, loss: 0.019782
 >> iter 89000, loss: 0.018898
 >> iter 90000, loss: 0.025959
   Number of active neurons: 1
 >> iter 91000, loss: 0.020108
 >> iter 92000, loss: 0.018647
 >> iter 93000, loss: 0.025875
 >> iter 94000, loss: 0.019844
 >> iter 95000, loss: 0.021451
 >> iter 96000, loss: 0.018195
 >> iter 97000, loss: 0.018350
 >> iter 98000, loss: 0.029737
 >> iter 99000, loss: 0.020316
 >> iter 100000, loss: 0.017551
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.915644
 >> iter 2000, loss: 4.057076
 >> iter 3000, loss: 1.546323
 >> iter 4000, loss: 0.597449
 >> iter 5000, loss: 0.238697
 >> iter 6000, loss: 0.106894
 >> iter 7000, loss: 0.057996
 >> iter 8000, loss: 0.042334
 >> iter 9000, loss: 0.036222
 >> iter 10000, loss: 0.042327
   Number of active neurons: 4
 >> iter 11000, loss: 0.041123
 >> iter 12000, loss: 0.031572
 >> iter 13000, loss: 0.029367
 >> iter 14000, loss: 0.027179
 >> iter 15000, loss: 0.032199
 >> iter 16000, loss: 0.032944
 >> iter 17000, loss: 0.029441
 >> iter 18000, loss: 0.026745
 >> iter 19000, loss: 0.024239
 >> iter 20000, loss: 0.025064
   Number of active neurons: 3
 >> iter 21000, loss: 0.023601
 >> iter 22000, loss: 0.030708
 >> iter 23000, loss: 0.033693
 >> iter 24000, loss: 0.031101
 >> iter 25000, loss: 0.030805
 >> iter 26000, loss: 0.026616
 >> iter 27000, loss: 0.029642
 >> iter 28000, loss: 0.027271
 >> iter 29000, loss: 0.027129
 >> iter 30000, loss: 0.025364
   Number of active neurons: 2
 >> iter 31000, loss: 0.023290
 >> iter 32000, loss: 0.022774
 >> iter 33000, loss: 0.055908
 >> iter 34000, loss: 0.040028
 >> iter 35000, loss: 0.032972
 >> iter 36000, loss: 0.025667
 >> iter 37000, loss: 0.022107
 >> iter 38000, loss: 0.024042
 >> iter 39000, loss: 0.025919
 >> iter 40000, loss: 0.023188
   Number of active neurons: 2
 >> iter 41000, loss: 0.028440
 >> iter 42000, loss: 0.023451
 >> iter 43000, loss: 0.025532
 >> iter 44000, loss: 0.023273
 >> iter 45000, loss: 0.021333
 >> iter 46000, loss: 0.023658
 >> iter 47000, loss: 0.028939
 >> iter 48000, loss: 0.027194
 >> iter 49000, loss: 0.024906
 >> iter 50000, loss: 0.021644
   Number of active neurons: 2
 >> iter 51000, loss: 0.024775
 >> iter 52000, loss: 0.039176
 >> iter 53000, loss: 0.028197
 >> iter 54000, loss: 0.023777
 >> iter 55000, loss: 0.022134
 >> iter 56000, loss: 0.025445
 >> iter 57000, loss: 0.030221
 >> iter 58000, loss: 0.039188
 >> iter 59000, loss: 0.030337
 >> iter 60000, loss: 0.031293
   Number of active neurons: 2
 >> iter 61000, loss: 0.024935
 >> iter 62000, loss: 0.032776
 >> iter 63000, loss: 0.036118
 >> iter 64000, loss: 0.026297
 >> iter 65000, loss: 0.025089
 >> iter 66000, loss: 0.022221
 >> iter 67000, loss: 0.022451
 >> iter 68000, loss: 0.020848
 >> iter 69000, loss: 0.023877
 >> iter 70000, loss: 0.020437
   Number of active neurons: 1
 >> iter 71000, loss: 0.022264
 >> iter 72000, loss: 0.020821
 >> iter 73000, loss: 0.018474
 >> iter 74000, loss: 0.020369
 >> iter 75000, loss: 0.020634
 >> iter 76000, loss: 0.017312
 >> iter 77000, loss: 0.018178
 >> iter 78000, loss: 0.018621
 >> iter 79000, loss: 0.026606
 >> iter 80000, loss: 0.020157
   Number of active neurons: 1
 >> iter 81000, loss: 0.019763
 >> iter 82000, loss: 0.027823
 >> iter 83000, loss: 0.021241
 >> iter 84000, loss: 0.021351
 >> iter 85000, loss: 0.018710
 >> iter 86000, loss: 0.025458
 >> iter 87000, loss: 0.023341
 >> iter 88000, loss: 0.021502
 >> iter 89000, loss: 0.045580
 >> iter 90000, loss: 0.037851
   Number of active neurons: 1
 >> iter 91000, loss: 0.031438
 >> iter 92000, loss: 0.024546
 >> iter 93000, loss: 0.020584
 >> iter 94000, loss: 0.016922
 >> iter 95000, loss: 0.017620
 >> iter 96000, loss: 0.017743
 >> iter 97000, loss: 0.019043
 >> iter 98000, loss: 0.017506
 >> iter 99000, loss: 0.017868
 >> iter 100000, loss: 0.019016
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.886130
 >> iter 2000, loss: 4.050810
 >> iter 3000, loss: 1.515205
 >> iter 4000, loss: 0.589727
 >> iter 5000, loss: 0.237417
 >> iter 6000, loss: 0.104859
 >> iter 7000, loss: 0.053064
 >> iter 8000, loss: 0.034668
 >> iter 9000, loss: 0.027189
 >> iter 10000, loss: 0.030320
   Number of active neurons: 3
 >> iter 11000, loss: 0.027530
 >> iter 12000, loss: 0.028043
 >> iter 13000, loss: 0.030082
 >> iter 14000, loss: 0.024114
 >> iter 15000, loss: 0.037857
 >> iter 16000, loss: 0.027550
 >> iter 17000, loss: 0.052906
 >> iter 18000, loss: 0.034669
 >> iter 19000, loss: 0.028806
 >> iter 20000, loss: 0.025062
   Number of active neurons: 3
 >> iter 21000, loss: 0.025527
 >> iter 22000, loss: 0.027677
 >> iter 23000, loss: 0.023640
 >> iter 24000, loss: 0.022865
 >> iter 25000, loss: 0.026185
 >> iter 26000, loss: 0.032286
 >> iter 27000, loss: 0.029086
 >> iter 28000, loss: 0.028278
 >> iter 29000, loss: 0.026655
 >> iter 30000, loss: 0.024121
   Number of active neurons: 3
 >> iter 31000, loss: 0.025113
 >> iter 32000, loss: 0.025809
 >> iter 33000, loss: 0.025730
 >> iter 34000, loss: 0.026572
 >> iter 35000, loss: 0.024464
 >> iter 36000, loss: 0.022577
 >> iter 37000, loss: 0.022554
 >> iter 38000, loss: 0.041955
 >> iter 39000, loss: 0.029911
 >> iter 40000, loss: 0.034157
   Number of active neurons: 3
 >> iter 41000, loss: 0.030003
 >> iter 42000, loss: 0.028105
 >> iter 43000, loss: 0.027289
 >> iter 44000, loss: 0.026454
 >> iter 45000, loss: 0.024345
 >> iter 46000, loss: 0.023167
 >> iter 47000, loss: 0.028217
 >> iter 48000, loss: 0.026871
 >> iter 49000, loss: 0.022922
 >> iter 50000, loss: 0.022546
   Number of active neurons: 3
 >> iter 51000, loss: 0.028307
 >> iter 52000, loss: 0.030663
 >> iter 53000, loss: 0.024277
 >> iter 54000, loss: 0.023166
 >> iter 55000, loss: 0.040667
 >> iter 56000, loss: 0.029119
 >> iter 57000, loss: 0.027451
 >> iter 58000, loss: 0.025704
 >> iter 59000, loss: 0.024903
 >> iter 60000, loss: 0.022908
   Number of active neurons: 2
 >> iter 61000, loss: 0.021559
 >> iter 62000, loss: 0.023337
 >> iter 63000, loss: 0.024946
 >> iter 64000, loss: 0.038877
 >> iter 65000, loss: 0.028887
 >> iter 66000, loss: 0.027598
 >> iter 67000, loss: 0.034227
 >> iter 68000, loss: 0.024600
 >> iter 69000, loss: 0.021680
 >> iter 70000, loss: 0.023243
   Number of active neurons: 2
 >> iter 71000, loss: 0.022034
 >> iter 72000, loss: 0.025380
 >> iter 73000, loss: 0.033204
 >> iter 74000, loss: 0.026580
 >> iter 75000, loss: 0.026539
 >> iter 76000, loss: 0.035962
 >> iter 77000, loss: 0.026588
 >> iter 78000, loss: 0.023153
 >> iter 79000, loss: 0.025076
 >> iter 80000, loss: 0.029236
   Number of active neurons: 2
 >> iter 81000, loss: 0.024550
 >> iter 82000, loss: 0.022903
 >> iter 83000, loss: 0.026429
 >> iter 84000, loss: 0.022687
 >> iter 85000, loss: 0.026104
 >> iter 86000, loss: 0.026004
 >> iter 87000, loss: 0.027563
 >> iter 88000, loss: 0.024203
 >> iter 89000, loss: 0.026111
 >> iter 90000, loss: 0.024668
   Number of active neurons: 2
 >> iter 91000, loss: 0.026836
 >> iter 92000, loss: 0.022243
 >> iter 93000, loss: 0.021124
 >> iter 94000, loss: 0.022410
 >> iter 95000, loss: 0.023593
 >> iter 96000, loss: 0.021584
 >> iter 97000, loss: 0.022099
 >> iter 98000, loss: 0.019786
 >> iter 99000, loss: 0.023744
 >> iter 100000, loss: 0.031596
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

