 > Problema: tomita6nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.2
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.654900
 >> iter 2000, loss: 15.127550
 >> iter 3000, loss: 13.781545
 >> iter 4000, loss: 13.276729
 >> iter 5000, loss: 13.064269
 >> iter 6000, loss: 12.992026
 >> iter 7000, loss: 12.954283
 >> iter 8000, loss: 12.949407
 >> iter 9000, loss: 12.937717
 >> iter 10000, loss: 12.944453
   Number of active neurons: 5
 >> iter 11000, loss: 12.929547
 >> iter 12000, loss: 12.743820
 >> iter 13000, loss: 11.668966
 >> iter 14000, loss: 5.776131
 >> iter 15000, loss: 2.221260
 >> iter 16000, loss: 0.879850
 >> iter 17000, loss: 0.340446
 >> iter 18000, loss: 0.136333
 >> iter 19000, loss: 0.059236
 >> iter 20000, loss: 0.028944
   Number of active neurons: 10
 >> iter 21000, loss: 0.437824
 >> iter 22000, loss: 0.172654
 >> iter 23000, loss: 0.072207
 >> iter 24000, loss: 0.032882
 >> iter 25000, loss: 0.017328
 >> iter 26000, loss: 0.010950
 >> iter 27000, loss: 0.008877
 >> iter 28000, loss: 0.007611
 >> iter 29000, loss: 0.006300
 >> iter 30000, loss: 0.005443
   Number of active neurons: 10
 >> iter 31000, loss: 0.004849
 >> iter 32000, loss: 0.004422
 >> iter 33000, loss: 0.004130
 >> iter 34000, loss: 0.003883
 >> iter 35000, loss: 0.047070
 >> iter 36000, loss: 0.020186
 >> iter 37000, loss: 0.056168
 >> iter 38000, loss: 0.023652
 >> iter 39000, loss: 0.011151
 >> iter 40000, loss: 0.006322
   Number of active neurons: 10
 >> iter 41000, loss: 0.004456
 >> iter 42000, loss: 0.003588
 >> iter 43000, loss: 0.003183
 >> iter 44000, loss: 0.002937
 >> iter 45000, loss: 0.002844
 >> iter 46000, loss: 0.002679
 >> iter 47000, loss: 0.002592
 >> iter 48000, loss: 0.002462
 >> iter 49000, loss: 0.002852
 >> iter 50000, loss: 0.002607
   Number of active neurons: 10
 >> iter 51000, loss: 0.002509
 >> iter 52000, loss: 0.003501
 >> iter 53000, loss: 0.003105
 >> iter 54000, loss: 0.002559
 >> iter 55000, loss: 0.002308
 >> iter 56000, loss: 0.002047
 >> iter 57000, loss: 0.001904
 >> iter 58000, loss: 0.001816
 >> iter 59000, loss: 0.001790
 >> iter 60000, loss: 0.041742
   Number of active neurons: 10
 >> iter 61000, loss: 0.017445
 >> iter 62000, loss: 0.007798
 >> iter 63000, loss: 0.004138
 >> iter 64000, loss: 0.002658
 >> iter 65000, loss: 0.002042
 >> iter 66000, loss: 0.007394
 >> iter 67000, loss: 0.004178
 >> iter 68000, loss: 0.002802
 >> iter 69000, loss: 0.002179
 >> iter 70000, loss: 0.001867
   Number of active neurons: 10
 >> iter 71000, loss: 0.001701
 >> iter 72000, loss: 0.001583
 >> iter 73000, loss: 0.001509
 >> iter 74000, loss: 0.001441
 >> iter 75000, loss: 0.001364
 >> iter 76000, loss: 0.001314
 >> iter 77000, loss: 0.001292
 >> iter 78000, loss: 0.001249
 >> iter 79000, loss: 0.001195
 >> iter 80000, loss: 0.001163
   Number of active neurons: 10
 >> iter 81000, loss: 0.001133
 >> iter 82000, loss: 0.001116
 >> iter 83000, loss: 0.001124
 >> iter 84000, loss: 0.001071
 >> iter 85000, loss: 0.001042
 >> iter 86000, loss: 0.001018
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.654951
 >> iter 2000, loss: 15.108653
 >> iter 3000, loss: 13.758459
 >> iter 4000, loss: 13.261244
 >> iter 5000, loss: 13.070291
 >> iter 6000, loss: 12.994443
 >> iter 7000, loss: 12.961940
 >> iter 8000, loss: 12.956142
 >> iter 9000, loss: 12.949203
 >> iter 10000, loss: 12.948935
   Number of active neurons: 6
 >> iter 11000, loss: 12.939613
 >> iter 12000, loss: 12.909141
 >> iter 13000, loss: 12.313382
 >> iter 14000, loss: 9.712580
 >> iter 15000, loss: 3.888448
 >> iter 16000, loss: 1.598826
 >> iter 17000, loss: 0.617183
 >> iter 18000, loss: 0.246232
 >> iter 19000, loss: 0.157172
 >> iter 20000, loss: 0.163604
   Number of active neurons: 10
 >> iter 21000, loss: 0.072293
 >> iter 22000, loss: 0.036362
 >> iter 23000, loss: 0.022270
 >> iter 24000, loss: 0.015411
 >> iter 25000, loss: 0.011973
 >> iter 26000, loss: 0.010047
 >> iter 27000, loss: 0.008722
 >> iter 28000, loss: 0.007825
 >> iter 29000, loss: 0.007142
 >> iter 30000, loss: 0.006518
   Number of active neurons: 10
 >> iter 31000, loss: 0.008525
 >> iter 32000, loss: 0.007097
 >> iter 33000, loss: 0.006050
 >> iter 34000, loss: 0.005483
 >> iter 35000, loss: 0.004978
 >> iter 36000, loss: 0.004645
 >> iter 37000, loss: 0.004289
 >> iter 38000, loss: 0.004071
 >> iter 39000, loss: 0.003856
 >> iter 40000, loss: 0.003689
   Number of active neurons: 10
 >> iter 41000, loss: 0.003538
 >> iter 42000, loss: 0.003369
 >> iter 43000, loss: 0.003248
 >> iter 44000, loss: 0.003119
 >> iter 45000, loss: 0.002964
 >> iter 46000, loss: 0.002912
 >> iter 47000, loss: 0.004458
 >> iter 48000, loss: 0.081267
 >> iter 49000, loss: 0.032179
 >> iter 50000, loss: 0.013930
   Number of active neurons: 10
 >> iter 51000, loss: 0.007074
 >> iter 52000, loss: 0.004422
 >> iter 53000, loss: 0.003341
 >> iter 54000, loss: 0.002890
 >> iter 55000, loss: 0.002646
 >> iter 56000, loss: 0.002508
 >> iter 57000, loss: 0.002371
 >> iter 58000, loss: 0.002276
 >> iter 59000, loss: 0.002220
 >> iter 60000, loss: 0.002146
   Number of active neurons: 10
 >> iter 61000, loss: 0.002130
 >> iter 62000, loss: 0.002054
 >> iter 63000, loss: 0.001952
 >> iter 64000, loss: 0.001897
 >> iter 65000, loss: 0.001856
 >> iter 66000, loss: 0.001815
 >> iter 67000, loss: 0.001775
 >> iter 68000, loss: 0.001736
 >> iter 69000, loss: 0.001680
 >> iter 70000, loss: 0.001655
   Number of active neurons: 10
 >> iter 71000, loss: 0.001652
 >> iter 72000, loss: 0.001576
 >> iter 73000, loss: 0.001535
 >> iter 74000, loss: 0.001510
 >> iter 75000, loss: 0.001486
 >> iter 76000, loss: 0.001447
 >> iter 77000, loss: 0.001416
 >> iter 78000, loss: 0.001407
 >> iter 79000, loss: 0.001372
 >> iter 80000, loss: 0.001349
   Number of active neurons: 10
 >> iter 81000, loss: 0.001316
 >> iter 82000, loss: 0.001286
 >> iter 83000, loss: 0.001266
 >> iter 84000, loss: 0.001254
 >> iter 85000, loss: 0.001236
 >> iter 86000, loss: 0.001212
 >> iter 87000, loss: 0.001578
 >> iter 88000, loss: 0.001406
 >> iter 89000, loss: 0.001298
 >> iter 90000, loss: 0.001236
   Number of active neurons: 10
 >> iter 91000, loss: 0.001201
 >> iter 92000, loss: 0.001172
 >> iter 93000, loss: 0.001146
 >> iter 94000, loss: 0.001126
 >> iter 95000, loss: 0.001110
 >> iter 96000, loss: 0.001086
 >> iter 97000, loss: 0.001060
 >> iter 98000, loss: 0.001053
 >> iter 99000, loss: 0.001040
 >> iter 100000, loss: 0.001018
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.651702
 >> iter 2000, loss: 15.130393
 >> iter 3000, loss: 13.783267
 >> iter 4000, loss: 13.285255
 >> iter 5000, loss: 13.079348
 >> iter 6000, loss: 13.009750
 >> iter 7000, loss: 12.969492
 >> iter 8000, loss: 12.963131
 >> iter 9000, loss: 12.951309
 >> iter 10000, loss: 12.960422
   Number of active neurons: 5
 >> iter 11000, loss: 12.947047
 >> iter 12000, loss: 12.954852
 >> iter 13000, loss: 12.940308
 >> iter 14000, loss: 12.794028
 >> iter 15000, loss: 9.628911
 >> iter 16000, loss: 3.865885
 >> iter 17000, loss: 1.509961
 >> iter 18000, loss: 0.747807
 >> iter 19000, loss: 0.303484
 >> iter 20000, loss: 0.131727
   Number of active neurons: 10
 >> iter 21000, loss: 0.064659
 >> iter 22000, loss: 0.036841
 >> iter 23000, loss: 0.024369
 >> iter 24000, loss: 0.092103
 >> iter 25000, loss: 0.044454
 >> iter 26000, loss: 0.025915
 >> iter 27000, loss: 0.017742
 >> iter 28000, loss: 0.013650
 >> iter 29000, loss: 0.011371
 >> iter 30000, loss: 0.010126
   Number of active neurons: 10
 >> iter 31000, loss: 0.009948
 >> iter 32000, loss: 0.009438
 >> iter 33000, loss: 0.008259
 >> iter 34000, loss: 0.009497
 >> iter 35000, loss: 0.016441
 >> iter 36000, loss: 0.120696
 >> iter 37000, loss: 0.052137
 >> iter 38000, loss: 0.024783
 >> iter 39000, loss: 0.013758
 >> iter 40000, loss: 0.009380
   Number of active neurons: 10
 >> iter 41000, loss: 0.007224
 >> iter 42000, loss: 0.065100
 >> iter 43000, loss: 0.028242
 >> iter 44000, loss: 0.014241
 >> iter 45000, loss: 0.008694
 >> iter 46000, loss: 0.007046
 >> iter 47000, loss: 0.005647
 >> iter 48000, loss: 0.004953
 >> iter 49000, loss: 0.004507
 >> iter 50000, loss: 0.004285
   Number of active neurons: 10
 >> iter 51000, loss: 0.003989
 >> iter 52000, loss: 0.003844
 >> iter 53000, loss: 0.003667
 >> iter 54000, loss: 0.003534
 >> iter 55000, loss: 0.003365
 >> iter 56000, loss: 0.003308
 >> iter 57000, loss: 0.003143
 >> iter 58000, loss: 0.003047
 >> iter 59000, loss: 0.062867
 >> iter 60000, loss: 0.043094
   Number of active neurons: 10
 >> iter 61000, loss: 0.018312
 >> iter 62000, loss: 0.013724
 >> iter 63000, loss: 0.007293
 >> iter 64000, loss: 0.005075
 >> iter 65000, loss: 0.003811
 >> iter 66000, loss: 0.003235
 >> iter 67000, loss: 0.002931
 >> iter 68000, loss: 0.002754
 >> iter 69000, loss: 0.002623
 >> iter 70000, loss: 0.002569
   Number of active neurons: 10
 >> iter 71000, loss: 0.002461
 >> iter 72000, loss: 0.002381
 >> iter 73000, loss: 0.002322
 >> iter 74000, loss: 0.002271
 >> iter 75000, loss: 0.002224
 >> iter 76000, loss: 0.002178
 >> iter 77000, loss: 0.002115
 >> iter 78000, loss: 0.002075
 >> iter 79000, loss: 0.002010
 >> iter 80000, loss: 0.001995
   Number of active neurons: 10
 >> iter 81000, loss: 0.001922
 >> iter 82000, loss: 0.001892
 >> iter 83000, loss: 0.001874
 >> iter 84000, loss: 0.001834
 >> iter 85000, loss: 0.001778
 >> iter 86000, loss: 0.001789
 >> iter 87000, loss: 0.002685
 >> iter 88000, loss: 0.002232
 >> iter 89000, loss: 0.002386
 >> iter 90000, loss: 0.002092
   Number of active neurons: 10
 >> iter 91000, loss: 0.031630
 >> iter 92000, loss: 0.142639
 >> iter 93000, loss: 0.054106
 >> iter 94000, loss: 0.021363
 >> iter 95000, loss: 0.009302
 >> iter 96000, loss: 0.004781
 >> iter 97000, loss: 0.003066
 >> iter 98000, loss: 0.002443
 >> iter 99000, loss: 0.002112
 >> iter 100000, loss: 0.001949
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.644998
 >> iter 2000, loss: 15.130751
 >> iter 3000, loss: 13.781859
 >> iter 4000, loss: 13.280326
 >> iter 5000, loss: 13.081767
 >> iter 6000, loss: 13.011833
 >> iter 7000, loss: 12.980867
 >> iter 8000, loss: 12.978627
 >> iter 9000, loss: 12.963613
 >> iter 10000, loss: 12.971361
   Number of active neurons: 6
 >> iter 11000, loss: 12.964636
 >> iter 12000, loss: 12.973413
 >> iter 13000, loss: 12.956187
 >> iter 14000, loss: 12.960468
 >> iter 15000, loss: 12.722478
 >> iter 16000, loss: 11.399523
 >> iter 17000, loss: 4.509117
 >> iter 18000, loss: 1.733332
 >> iter 19000, loss: 0.667311
 >> iter 20000, loss: 0.264183
   Number of active neurons: 10
 >> iter 21000, loss: 0.110991
 >> iter 22000, loss: 0.052105
 >> iter 23000, loss: 0.104519
 >> iter 24000, loss: 0.048904
 >> iter 25000, loss: 0.026395
 >> iter 26000, loss: 0.017763
 >> iter 27000, loss: 0.013059
 >> iter 28000, loss: 0.010639
 >> iter 29000, loss: 0.496378
 >> iter 30000, loss: 0.194786
   Number of active neurons: 10
 >> iter 31000, loss: 0.150293
 >> iter 32000, loss: 0.065546
 >> iter 33000, loss: 0.031446
 >> iter 34000, loss: 0.017865
 >> iter 35000, loss: 0.012071
 >> iter 36000, loss: 0.009370
 >> iter 37000, loss: 0.007896
 >> iter 38000, loss: 0.007122
 >> iter 39000, loss: 0.006422
 >> iter 40000, loss: 0.005937
   Number of active neurons: 10
 >> iter 41000, loss: 0.005474
 >> iter 42000, loss: 0.005139
 >> iter 43000, loss: 0.004832
 >> iter 44000, loss: 0.004578
 >> iter 45000, loss: 0.004319
 >> iter 46000, loss: 0.004127
 >> iter 47000, loss: 0.003912
 >> iter 48000, loss: 0.003752
 >> iter 49000, loss: 0.003553
 >> iter 50000, loss: 0.003427
   Number of active neurons: 10
 >> iter 51000, loss: 0.003322
 >> iter 52000, loss: 0.003233
 >> iter 53000, loss: 0.003510
 >> iter 54000, loss: 0.003237
 >> iter 55000, loss: 0.003057
 >> iter 56000, loss: 0.003480
 >> iter 57000, loss: 0.003195
 >> iter 58000, loss: 0.002971
 >> iter 59000, loss: 0.002846
 >> iter 60000, loss: 0.002705
   Number of active neurons: 10
 >> iter 61000, loss: 0.002547
 >> iter 62000, loss: 0.002455
 >> iter 63000, loss: 0.002353
 >> iter 64000, loss: 0.002287
 >> iter 65000, loss: 0.002198
 >> iter 66000, loss: 0.002133
 >> iter 67000, loss: 0.002065
 >> iter 68000, loss: 0.002022
 >> iter 69000, loss: 0.001961
 >> iter 70000, loss: 0.001908
   Number of active neurons: 10
 >> iter 71000, loss: 0.001865
 >> iter 72000, loss: 0.001900
 >> iter 73000, loss: 0.001818
 >> iter 74000, loss: 0.001770
 >> iter 75000, loss: 0.001712
 >> iter 76000, loss: 0.001688
 >> iter 77000, loss: 0.001649
 >> iter 78000, loss: 0.001609
 >> iter 79000, loss: 0.001582
 >> iter 80000, loss: 0.001548
   Number of active neurons: 10
 >> iter 81000, loss: 0.001507
 >> iter 82000, loss: 0.001481
 >> iter 83000, loss: 0.001462
 >> iter 84000, loss: 0.001427
 >> iter 85000, loss: 0.001413
 >> iter 86000, loss: 0.001381
 >> iter 87000, loss: 0.001360
 >> iter 88000, loss: 0.001344
 >> iter 89000, loss: 0.001333
 >> iter 90000, loss: 0.001317
   Number of active neurons: 10
 >> iter 91000, loss: 0.001271
 >> iter 92000, loss: 0.001253
 >> iter 93000, loss: 0.001233
 >> iter 94000, loss: 0.001237
 >> iter 95000, loss: 0.001205
 >> iter 96000, loss: 0.001191
 >> iter 97000, loss: 0.001167
 >> iter 98000, loss: 0.001152
 >> iter 99000, loss: 0.001125
 >> iter 100000, loss: 0.001116
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.669228
 >> iter 2000, loss: 15.109823
 >> iter 3000, loss: 13.768059
 >> iter 4000, loss: 13.269617
 >> iter 5000, loss: 13.063657
 >> iter 6000, loss: 12.994027
 >> iter 7000, loss: 12.951785
 >> iter 8000, loss: 12.950439
 >> iter 9000, loss: 12.938739
 >> iter 10000, loss: 12.942079
   Number of active neurons: 6
 >> iter 11000, loss: 12.931820
 >> iter 12000, loss: 12.939555
 >> iter 13000, loss: 12.923760
 >> iter 14000, loss: 12.921806
 >> iter 15000, loss: 12.452119
 >> iter 16000, loss: 11.385936
 >> iter 17000, loss: 5.760123
 >> iter 18000, loss: 2.169961
 >> iter 19000, loss: 0.825561
 >> iter 20000, loss: 0.348708
   Number of active neurons: 10
 >> iter 21000, loss: 0.148024
 >> iter 22000, loss: 0.065290
 >> iter 23000, loss: 0.032644
 >> iter 24000, loss: 0.019582
 >> iter 25000, loss: 0.013569
 >> iter 26000, loss: 0.010589
 >> iter 27000, loss: 0.008888
 >> iter 28000, loss: 0.007768
 >> iter 29000, loss: 0.007085
 >> iter 30000, loss: 0.006411
   Number of active neurons: 10
 >> iter 31000, loss: 0.005784
 >> iter 32000, loss: 0.005381
 >> iter 33000, loss: 0.004976
 >> iter 34000, loss: 0.004654
 >> iter 35000, loss: 0.004345
 >> iter 36000, loss: 0.004102
 >> iter 37000, loss: 0.003834
 >> iter 38000, loss: 0.004241
 >> iter 39000, loss: 0.003739
 >> iter 40000, loss: 0.003500
   Number of active neurons: 10
 >> iter 41000, loss: 0.061783
 >> iter 42000, loss: 0.029940
 >> iter 43000, loss: 0.013464
 >> iter 44000, loss: 0.007560
 >> iter 45000, loss: 0.004854
 >> iter 46000, loss: 0.003695
 >> iter 47000, loss: 0.003165
 >> iter 48000, loss: 0.002867
 >> iter 49000, loss: 0.002660
 >> iter 50000, loss: 0.002528
   Number of active neurons: 10
 >> iter 51000, loss: 0.002433
 >> iter 52000, loss: 0.002335
 >> iter 53000, loss: 0.002244
 >> iter 54000, loss: 0.002152
 >> iter 55000, loss: 0.002069
 >> iter 56000, loss: 0.002024
 >> iter 57000, loss: 0.001930
 >> iter 58000, loss: 0.001891
 >> iter 59000, loss: 0.001810
 >> iter 60000, loss: 0.001757
   Number of active neurons: 10
 >> iter 61000, loss: 0.001725
 >> iter 62000, loss: 0.001664
 >> iter 63000, loss: 0.001606
 >> iter 64000, loss: 0.001577
 >> iter 65000, loss: 0.002493
 >> iter 66000, loss: 0.002006
 >> iter 67000, loss: 0.001724
 >> iter 68000, loss: 0.001599
 >> iter 69000, loss: 0.001497
 >> iter 70000, loss: 0.001437
   Number of active neurons: 10
 >> iter 71000, loss: 0.001384
 >> iter 72000, loss: 0.001345
 >> iter 73000, loss: 0.001301
 >> iter 74000, loss: 0.001654
 >> iter 75000, loss: 0.001440
 >> iter 76000, loss: 0.001312
 >> iter 77000, loss: 0.001215
 >> iter 78000, loss: 0.001188
 >> iter 79000, loss: 0.001135
 >> iter 80000, loss: 0.001107
   Number of active neurons: 10
 >> iter 81000, loss: 0.001084
 >> iter 82000, loss: 0.001066
 >> iter 83000, loss: 0.001034
 >> iter 84000, loss: 0.001014
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.643894
 >> iter 2000, loss: 15.145560
 >> iter 3000, loss: 13.791007
 >> iter 4000, loss: 13.285191
 >> iter 5000, loss: 13.079129
 >> iter 6000, loss: 13.011153
 >> iter 7000, loss: 12.972363
 >> iter 8000, loss: 12.968366
 >> iter 9000, loss: 12.952248
 >> iter 10000, loss: 12.956484
   Number of active neurons: 6
 >> iter 11000, loss: 12.939256
 >> iter 12000, loss: 12.927077
 >> iter 13000, loss: 12.555098
 >> iter 14000, loss: 6.947616
 >> iter 15000, loss: 2.643763
 >> iter 16000, loss: 1.035148
 >> iter 17000, loss: 0.742892
 >> iter 18000, loss: 0.306511
 >> iter 19000, loss: 0.167461
 >> iter 20000, loss: 0.077981
   Number of active neurons: 10
 >> iter 21000, loss: 0.042653
 >> iter 22000, loss: 0.026893
 >> iter 23000, loss: 0.019215
 >> iter 24000, loss: 0.015359
 >> iter 25000, loss: 0.012791
 >> iter 26000, loss: 0.011344
 >> iter 27000, loss: 0.010110
 >> iter 28000, loss: 0.009234
 >> iter 29000, loss: 0.008523
 >> iter 30000, loss: 0.019416
   Number of active neurons: 10
 >> iter 31000, loss: 0.012232
 >> iter 32000, loss: 0.009885
 >> iter 33000, loss: 0.007898
 >> iter 34000, loss: 0.006865
 >> iter 35000, loss: 0.133604
 >> iter 36000, loss: 0.054336
 >> iter 37000, loss: 0.023989
 >> iter 38000, loss: 0.012509
 >> iter 39000, loss: 0.008044
 >> iter 40000, loss: 0.006205
   Number of active neurons: 10
 >> iter 41000, loss: 0.005296
 >> iter 42000, loss: 0.004896
 >> iter 43000, loss: 0.004555
 >> iter 44000, loss: 0.004324
 >> iter 45000, loss: 0.004104
 >> iter 46000, loss: 0.003958
 >> iter 47000, loss: 0.003755
 >> iter 48000, loss: 0.003694
 >> iter 49000, loss: 0.003515
 >> iter 50000, loss: 0.003397
   Number of active neurons: 10
 >> iter 51000, loss: 0.003261
 >> iter 52000, loss: 0.003305
 >> iter 53000, loss: 0.003144
 >> iter 54000, loss: 0.003030
 >> iter 55000, loss: 0.002905
 >> iter 56000, loss: 0.002873
 >> iter 57000, loss: 0.002750
 >> iter 58000, loss: 0.002711
 >> iter 59000, loss: 0.002598
 >> iter 60000, loss: 0.002537
   Number of active neurons: 10
 >> iter 61000, loss: 0.002447
 >> iter 62000, loss: 0.002497
 >> iter 63000, loss: 0.002383
 >> iter 64000, loss: 0.002305
 >> iter 65000, loss: 0.002231
 >> iter 66000, loss: 0.002194
 >> iter 67000, loss: 0.002161
 >> iter 68000, loss: 0.002147
 >> iter 69000, loss: 0.002062
 >> iter 70000, loss: 0.002021
   Number of active neurons: 10
 >> iter 71000, loss: 0.001970
 >> iter 72000, loss: 0.001948
 >> iter 73000, loss: 0.001887
 >> iter 74000, loss: 0.001884
 >> iter 75000, loss: 0.001834
 >> iter 76000, loss: 0.001806
 >> iter 77000, loss: 0.001748
 >> iter 78000, loss: 0.001744
 >> iter 79000, loss: 0.001725
 >> iter 80000, loss: 0.001683
   Number of active neurons: 10
 >> iter 81000, loss: 0.001653
 >> iter 82000, loss: 0.001638
 >> iter 83000, loss: 0.001599
 >> iter 84000, loss: 0.001574
 >> iter 85000, loss: 0.001540
 >> iter 86000, loss: 0.001536
 >> iter 87000, loss: 0.001496
 >> iter 88000, loss: 0.001490
 >> iter 89000, loss: 0.001455
 >> iter 90000, loss: 0.001437
   Number of active neurons: 10
 >> iter 91000, loss: 0.087952
 >> iter 92000, loss: 0.033784
 >> iter 93000, loss: 0.013639
 >> iter 94000, loss: 0.006197
 >> iter 95000, loss: 0.003394
 >> iter 96000, loss: 0.002337
 >> iter 97000, loss: 0.001949
 >> iter 98000, loss: 0.001748
 >> iter 99000, loss: 0.001641
 >> iter 100000, loss: 0.001583
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.624685
 >> iter 2000, loss: 15.099511
 >> iter 3000, loss: 13.759587
 >> iter 4000, loss: 13.257715
 >> iter 5000, loss: 13.060407
 >> iter 6000, loss: 12.994095
 >> iter 7000, loss: 12.949739
 >> iter 8000, loss: 12.949395
 >> iter 9000, loss: 12.930238
 >> iter 10000, loss: 12.936981
   Number of active neurons: 5
 >> iter 11000, loss: 12.931526
 >> iter 12000, loss: 12.938093
 >> iter 13000, loss: 12.927445
 >> iter 14000, loss: 12.839231
 >> iter 15000, loss: 12.055163
 >> iter 16000, loss: 10.611178
 >> iter 17000, loss: 9.142937
 >> iter 18000, loss: 5.041199
 >> iter 19000, loss: 2.158737
 >> iter 20000, loss: 0.861632
   Number of active neurons: 10
 >> iter 21000, loss: 0.478543
 >> iter 22000, loss: 0.200187
 >> iter 23000, loss: 0.089654
 >> iter 24000, loss: 0.046725
 >> iter 25000, loss: 0.027765
 >> iter 26000, loss: 0.019316
 >> iter 27000, loss: 0.014957
 >> iter 28000, loss: 0.012484
 >> iter 29000, loss: 0.010995
 >> iter 30000, loss: 0.009797
   Number of active neurons: 10
 >> iter 31000, loss: 0.008771
 >> iter 32000, loss: 0.008161
 >> iter 33000, loss: 0.007512
 >> iter 34000, loss: 0.007017
 >> iter 35000, loss: 0.008638
 >> iter 36000, loss: 0.008148
 >> iter 37000, loss: 0.006893
 >> iter 38000, loss: 0.006982
 >> iter 39000, loss: 0.007075
 >> iter 40000, loss: 0.005967
   Number of active neurons: 10
 >> iter 41000, loss: 0.009659
 >> iter 42000, loss: 0.007117
 >> iter 43000, loss: 0.005617
 >> iter 44000, loss: 0.004740
 >> iter 45000, loss: 0.004408
 >> iter 46000, loss: 0.004176
 >> iter 47000, loss: 0.003857
 >> iter 48000, loss: 0.005420
 >> iter 49000, loss: 0.085005
 >> iter 50000, loss: 0.140648
   Number of active neurons: 10
 >> iter 51000, loss: 0.055925
 >> iter 52000, loss: 0.023489
 >> iter 53000, loss: 0.011082
 >> iter 54000, loss: 0.006351
 >> iter 55000, loss: 0.004451
 >> iter 56000, loss: 0.003792
 >> iter 57000, loss: 0.003353
 >> iter 58000, loss: 0.003111
 >> iter 59000, loss: 0.002953
 >> iter 60000, loss: 0.003012
   Number of active neurons: 10
 >> iter 61000, loss: 0.002861
 >> iter 62000, loss: 0.002732
 >> iter 63000, loss: 0.002617
 >> iter 64000, loss: 0.002539
 >> iter 65000, loss: 0.028455
 >> iter 66000, loss: 0.013316
 >> iter 67000, loss: 0.015102
 >> iter 68000, loss: 0.007450
 >> iter 69000, loss: 0.004500
 >> iter 70000, loss: 0.007207
   Number of active neurons: 10
 >> iter 71000, loss: 0.004354
 >> iter 72000, loss: 0.003200
 >> iter 73000, loss: 0.002944
 >> iter 74000, loss: 0.002717
 >> iter 75000, loss: 0.002439
 >> iter 76000, loss: 0.002287
 >> iter 77000, loss: 0.064359
 >> iter 78000, loss: 0.026134
 >> iter 79000, loss: 0.011147
 >> iter 80000, loss: 0.005554
   Number of active neurons: 10
 >> iter 81000, loss: 0.003445
 >> iter 82000, loss: 0.003288
 >> iter 83000, loss: 0.002709
 >> iter 84000, loss: 0.002362
 >> iter 85000, loss: 0.002200
 >> iter 86000, loss: 0.002056
 >> iter 87000, loss: 0.001975
 >> iter 88000, loss: 0.001905
 >> iter 89000, loss: 0.001852
 >> iter 90000, loss: 0.001817
   Number of active neurons: 10
 >> iter 91000, loss: 0.001764
 >> iter 92000, loss: 0.001712
 >> iter 93000, loss: 0.001683
 >> iter 94000, loss: 0.001642
 >> iter 95000, loss: 0.001627
 >> iter 96000, loss: 0.001589
 >> iter 97000, loss: 0.001543
 >> iter 98000, loss: 0.001512
 >> iter 99000, loss: 0.001491
 >> iter 100000, loss: 0.001466
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.662622
 >> iter 2000, loss: 15.142378
 >> iter 3000, loss: 13.797497
 >> iter 4000, loss: 13.290994
 >> iter 5000, loss: 13.096527
 >> iter 6000, loss: 13.026876
 >> iter 7000, loss: 12.991462
 >> iter 8000, loss: 12.994800
 >> iter 9000, loss: 12.981433
 >> iter 10000, loss: 12.992220
   Number of active neurons: 7
 >> iter 11000, loss: 12.977858
 >> iter 12000, loss: 12.978265
 >> iter 13000, loss: 12.917232
 >> iter 14000, loss: 12.278341
 >> iter 15000, loss: 7.252564
 >> iter 16000, loss: 2.750205
 >> iter 17000, loss: 1.042255
 >> iter 18000, loss: 0.404068
 >> iter 19000, loss: 0.163339
 >> iter 20000, loss: 0.073626
   Number of active neurons: 10
 >> iter 21000, loss: 0.036807
 >> iter 22000, loss: 0.021556
 >> iter 23000, loss: 0.014916
 >> iter 24000, loss: 0.039954
 >> iter 25000, loss: 0.060088
 >> iter 26000, loss: 0.028099
 >> iter 27000, loss: 0.015585
 >> iter 28000, loss: 0.010413
 >> iter 29000, loss: 0.008008
 >> iter 30000, loss: 0.006831
   Number of active neurons: 10
 >> iter 31000, loss: 0.006074
 >> iter 32000, loss: 0.005535
 >> iter 33000, loss: 0.005121
 >> iter 34000, loss: 0.004824
 >> iter 35000, loss: 0.004493
 >> iter 36000, loss: 0.004241
 >> iter 37000, loss: 0.004029
 >> iter 38000, loss: 0.003827
 >> iter 39000, loss: 0.003684
 >> iter 40000, loss: 0.003516
   Number of active neurons: 10
 >> iter 41000, loss: 0.003583
 >> iter 42000, loss: 0.003314
 >> iter 43000, loss: 0.003123
 >> iter 44000, loss: 0.002994
 >> iter 45000, loss: 0.002874
 >> iter 46000, loss: 0.002767
 >> iter 47000, loss: 0.002683
 >> iter 48000, loss: 0.002772
 >> iter 49000, loss: 0.003722
 >> iter 50000, loss: 0.002961
   Number of active neurons: 10
 >> iter 51000, loss: 0.002603
 >> iter 52000, loss: 0.002367
 >> iter 53000, loss: 0.002241
 >> iter 54000, loss: 0.002178
 >> iter 55000, loss: 0.002123
 >> iter 56000, loss: 0.002005
 >> iter 57000, loss: 0.001963
 >> iter 58000, loss: 0.001907
 >> iter 59000, loss: 0.001858
 >> iter 60000, loss: 0.001821
   Number of active neurons: 10
 >> iter 61000, loss: 0.001774
 >> iter 62000, loss: 0.001722
 >> iter 63000, loss: 0.001677
 >> iter 64000, loss: 0.001646
 >> iter 65000, loss: 0.001602
 >> iter 66000, loss: 0.001569
 >> iter 67000, loss: 0.001549
 >> iter 68000, loss: 0.001502
 >> iter 69000, loss: 0.056946
 >> iter 70000, loss: 0.022208
   Number of active neurons: 10
 >> iter 71000, loss: 0.009302
 >> iter 72000, loss: 0.004489
 >> iter 73000, loss: 0.002662
 >> iter 74000, loss: 0.001952
 >> iter 75000, loss: 0.001688
 >> iter 76000, loss: 0.001546
 >> iter 77000, loss: 0.001492
 >> iter 78000, loss: 0.001434
 >> iter 79000, loss: 0.001382
 >> iter 80000, loss: 0.001353
   Number of active neurons: 10
 >> iter 81000, loss: 0.001326
 >> iter 82000, loss: 0.001307
 >> iter 83000, loss: 0.001272
 >> iter 84000, loss: 0.001241
 >> iter 85000, loss: 0.001250
 >> iter 86000, loss: 0.001205
 >> iter 87000, loss: 0.001184
 >> iter 88000, loss: 0.001162
 >> iter 89000, loss: 0.001143
 >> iter 90000, loss: 0.001129
   Number of active neurons: 10
 >> iter 91000, loss: 0.001122
 >> iter 92000, loss: 0.001105
 >> iter 93000, loss: 0.001078
 >> iter 94000, loss: 0.001069
 >> iter 95000, loss: 0.001048
 >> iter 96000, loss: 0.001032
 >> iter 97000, loss: 0.001019
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.631650
 >> iter 2000, loss: 15.096698
 >> iter 3000, loss: 13.747045
 >> iter 4000, loss: 13.255006
 >> iter 5000, loss: 13.051243
 >> iter 6000, loss: 12.988323
 >> iter 7000, loss: 12.950575
 >> iter 8000, loss: 12.944388
 >> iter 9000, loss: 12.933757
 >> iter 10000, loss: 12.942696
   Number of active neurons: 4
 >> iter 11000, loss: 12.930989
 >> iter 12000, loss: 12.936591
 >> iter 13000, loss: 12.919422
 >> iter 14000, loss: 12.591056
 >> iter 15000, loss: 8.055942
 >> iter 16000, loss: 3.046463
 >> iter 17000, loss: 1.146856
 >> iter 18000, loss: 0.437585
 >> iter 19000, loss: 0.172058
 >> iter 20000, loss: 0.072016
   Number of active neurons: 10
 >> iter 21000, loss: 0.033576
 >> iter 22000, loss: 0.018256
 >> iter 23000, loss: 0.011778
 >> iter 24000, loss: 0.009353
 >> iter 25000, loss: 0.007315
 >> iter 26000, loss: 0.006167
 >> iter 27000, loss: 0.005475
 >> iter 28000, loss: 0.005326
 >> iter 29000, loss: 0.004691
 >> iter 30000, loss: 0.004212
   Number of active neurons: 10
 >> iter 31000, loss: 0.003798
 >> iter 32000, loss: 0.003533
 >> iter 33000, loss: 0.003285
 >> iter 34000, loss: 0.003106
 >> iter 35000, loss: 0.002904
 >> iter 36000, loss: 0.002774
 >> iter 37000, loss: 0.003023
 >> iter 38000, loss: 0.002721
 >> iter 39000, loss: 0.002528
 >> iter 40000, loss: 0.002332
   Number of active neurons: 10
 >> iter 41000, loss: 0.002166
 >> iter 42000, loss: 0.002051
 >> iter 43000, loss: 0.001974
 >> iter 44000, loss: 0.001900
 >> iter 45000, loss: 0.001799
 >> iter 46000, loss: 0.001747
 >> iter 47000, loss: 0.001692
 >> iter 48000, loss: 0.001632
 >> iter 49000, loss: 0.001611
 >> iter 50000, loss: 0.001530
   Number of active neurons: 10
 >> iter 51000, loss: 0.001492
 >> iter 52000, loss: 0.001444
 >> iter 53000, loss: 0.001441
 >> iter 54000, loss: 0.001372
 >> iter 55000, loss: 0.001330
 >> iter 56000, loss: 0.001311
 >> iter 57000, loss: 0.001271
 >> iter 58000, loss: 0.001224
 >> iter 59000, loss: 0.001176
 >> iter 60000, loss: 0.001262
   Number of active neurons: 10
 >> iter 61000, loss: 0.001170
 >> iter 62000, loss: 0.001121
 >> iter 63000, loss: 0.001123
 >> iter 64000, loss: 0.001103
 >> iter 65000, loss: 0.001053
 >> iter 66000, loss: 0.001026
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.643733
 >> iter 2000, loss: 15.153202
 >> iter 3000, loss: 13.805963
 >> iter 4000, loss: 13.311077
 >> iter 5000, loss: 13.105498
 >> iter 6000, loss: 13.035869
 >> iter 7000, loss: 13.002784
 >> iter 8000, loss: 12.997377
 >> iter 9000, loss: 12.987397
 >> iter 10000, loss: 12.994579
   Number of active neurons: 8
 >> iter 11000, loss: 12.983816
 >> iter 12000, loss: 12.990113
 >> iter 13000, loss: 12.979441
 >> iter 14000, loss: 12.991927
 >> iter 15000, loss: 12.980976
 >> iter 16000, loss: 12.983743
 >> iter 17000, loss: 12.979960
 >> iter 18000, loss: 12.927359
 >> iter 19000, loss: 12.490126
 >> iter 20000, loss: 9.757028
   Number of active neurons: 10
 >> iter 21000, loss: 3.734063
 >> iter 22000, loss: 1.449403
 >> iter 23000, loss: 0.567471
 >> iter 24000, loss: 0.236282
 >> iter 25000, loss: 0.106735
 >> iter 26000, loss: 0.056009
 >> iter 27000, loss: 0.034535
 >> iter 28000, loss: 0.026507
 >> iter 29000, loss: 0.021028
 >> iter 30000, loss: 0.017882
   Number of active neurons: 10
 >> iter 31000, loss: 0.015510
 >> iter 32000, loss: 0.013967
 >> iter 33000, loss: 0.012718
 >> iter 34000, loss: 0.011817
 >> iter 35000, loss: 0.010837
 >> iter 36000, loss: 0.010177
 >> iter 37000, loss: 0.009468
 >> iter 38000, loss: 0.008905
 >> iter 39000, loss: 0.008368
 >> iter 40000, loss: 0.007946
   Number of active neurons: 10
 >> iter 41000, loss: 0.008501
 >> iter 42000, loss: 0.007816
 >> iter 43000, loss: 0.007243
 >> iter 44000, loss: 0.006820
 >> iter 45000, loss: 0.006344
 >> iter 46000, loss: 0.006086
 >> iter 47000, loss: 0.005848
 >> iter 48000, loss: 0.005630
 >> iter 49000, loss: 0.005500
 >> iter 50000, loss: 0.005294
   Number of active neurons: 10
 >> iter 51000, loss: 0.005021
 >> iter 52000, loss: 0.004925
 >> iter 53000, loss: 0.004703
 >> iter 54000, loss: 0.004567
 >> iter 55000, loss: 0.004368
 >> iter 56000, loss: 0.004232
 >> iter 57000, loss: 0.004067
 >> iter 58000, loss: 0.004004
 >> iter 59000, loss: 0.003874
 >> iter 60000, loss: 0.003751
   Number of active neurons: 10
 >> iter 61000, loss: 0.003621
 >> iter 62000, loss: 0.003547
 >> iter 63000, loss: 0.003443
 >> iter 64000, loss: 0.003369
 >> iter 65000, loss: 0.003268
 >> iter 66000, loss: 0.003233
 >> iter 67000, loss: 0.003115
 >> iter 68000, loss: 0.003062
 >> iter 69000, loss: 0.002961
 >> iter 70000, loss: 0.002877
   Number of active neurons: 10
 >> iter 71000, loss: 0.002805
 >> iter 72000, loss: 0.003482
 >> iter 73000, loss: 0.003076
 >> iter 74000, loss: 0.002876
 >> iter 75000, loss: 0.002730
 >> iter 76000, loss: 0.002641
 >> iter 77000, loss: 0.002545
 >> iter 78000, loss: 0.002514
 >> iter 79000, loss: 0.002407
 >> iter 80000, loss: 0.002336
   Number of active neurons: 10
 >> iter 81000, loss: 0.002274
 >> iter 82000, loss: 0.002227
 >> iter 83000, loss: 0.002159
 >> iter 84000, loss: 0.002161
 >> iter 85000, loss: 0.002101
 >> iter 86000, loss: 0.002050
 >> iter 87000, loss: 0.001996
 >> iter 88000, loss: 0.001964
 >> iter 89000, loss: 0.001910
 >> iter 90000, loss: 0.001879
   Number of active neurons: 10
 >> iter 91000, loss: 0.001843
 >> iter 92000, loss: 0.001816
 >> iter 93000, loss: 0.001764
 >> iter 94000, loss: 0.134585
 >> iter 95000, loss: 0.097261
 >> iter 96000, loss: 0.037492
 >> iter 97000, loss: 0.015384
 >> iter 98000, loss: 0.007144
 >> iter 99000, loss: 0.004052
 >> iter 100000, loss: 0.002864
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.613314
 >> iter 2000, loss: 15.127384
 >> iter 3000, loss: 13.783955
 >> iter 4000, loss: 13.297654
 >> iter 5000, loss: 13.089485
 >> iter 6000, loss: 13.013982
 >> iter 7000, loss: 12.973806
 >> iter 8000, loss: 12.962307
 >> iter 9000, loss: 12.948015
 >> iter 10000, loss: 12.952824
   Number of active neurons: 6
 >> iter 11000, loss: 12.937348
 >> iter 12000, loss: 12.942644
 >> iter 13000, loss: 12.930639
 >> iter 14000, loss: 12.912886
 >> iter 15000, loss: 12.315776
 >> iter 16000, loss: 10.272499
 >> iter 17000, loss: 4.162711
 >> iter 18000, loss: 1.621542
 >> iter 19000, loss: 0.617390
 >> iter 20000, loss: 0.241652
   Number of active neurons: 10
 >> iter 21000, loss: 0.100279
 >> iter 22000, loss: 0.148159
 >> iter 23000, loss: 0.065400
 >> iter 24000, loss: 0.032322
 >> iter 25000, loss: 0.018326
 >> iter 26000, loss: 0.012342
 >> iter 27000, loss: 0.009620
 >> iter 28000, loss: 0.007913
 >> iter 29000, loss: 0.049186
 >> iter 30000, loss: 0.022896
   Number of active neurons: 10
 >> iter 31000, loss: 0.053302
 >> iter 32000, loss: 0.024289
 >> iter 33000, loss: 0.012923
 >> iter 34000, loss: 0.008209
 >> iter 35000, loss: 0.006224
 >> iter 36000, loss: 0.005094
 >> iter 37000, loss: 0.004514
 >> iter 38000, loss: 0.004235
 >> iter 39000, loss: 0.003878
 >> iter 40000, loss: 0.003594
   Number of active neurons: 10
 >> iter 41000, loss: 0.003443
 >> iter 42000, loss: 0.003282
 >> iter 43000, loss: 0.003127
 >> iter 44000, loss: 0.025926
 >> iter 45000, loss: 0.012180
 >> iter 46000, loss: 0.011053
 >> iter 47000, loss: 0.011319
 >> iter 48000, loss: 0.006405
 >> iter 49000, loss: 0.004268
 >> iter 50000, loss: 0.003373
   Number of active neurons: 10
 >> iter 51000, loss: 0.003016
 >> iter 52000, loss: 0.002797
 >> iter 53000, loss: 0.002515
 >> iter 54000, loss: 0.002332
 >> iter 55000, loss: 0.002237
 >> iter 56000, loss: 0.002142
 >> iter 57000, loss: 0.002363
 >> iter 58000, loss: 0.002180
 >> iter 59000, loss: 0.002113
 >> iter 60000, loss: 0.003930
   Number of active neurons: 10
 >> iter 61000, loss: 0.002875
 >> iter 62000, loss: 0.002320
 >> iter 63000, loss: 0.002012
 >> iter 64000, loss: 0.001851
 >> iter 65000, loss: 0.001726
 >> iter 66000, loss: 0.001644
 >> iter 67000, loss: 0.001598
 >> iter 68000, loss: 0.001626
 >> iter 69000, loss: 0.001563
 >> iter 70000, loss: 0.001489
   Number of active neurons: 10
 >> iter 71000, loss: 0.002727
 >> iter 72000, loss: 0.001924
 >> iter 73000, loss: 0.001617
 >> iter 74000, loss: 0.001461
 >> iter 75000, loss: 0.008177
 >> iter 76000, loss: 0.003951
 >> iter 77000, loss: 0.002334
 >> iter 78000, loss: 0.001705
 >> iter 79000, loss: 0.001485
 >> iter 80000, loss: 0.001317
   Number of active neurons: 10
 >> iter 81000, loss: 0.001250
 >> iter 82000, loss: 0.001225
 >> iter 83000, loss: 0.001180
 >> iter 84000, loss: 0.023806
 >> iter 85000, loss: 0.012344
 >> iter 86000, loss: 0.005555
 >> iter 87000, loss: 0.002969
 >> iter 88000, loss: 0.006454
 >> iter 89000, loss: 0.003334
 >> iter 90000, loss: 0.002125
   Number of active neurons: 10
 >> iter 91000, loss: 0.002245
 >> iter 92000, loss: 0.001631
 >> iter 93000, loss: 0.001385
 >> iter 94000, loss: 0.001248
 >> iter 95000, loss: 0.001195
 >> iter 96000, loss: 0.001131
 >> iter 97000, loss: 0.001126
 >> iter 98000, loss: 0.001279
 >> iter 99000, loss: 0.001153
 >> iter 100000, loss: 0.001061
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.631936
 >> iter 2000, loss: 15.141844
 >> iter 3000, loss: 13.791517
 >> iter 4000, loss: 13.290927
 >> iter 5000, loss: 13.092698
 >> iter 6000, loss: 13.015270
 >> iter 7000, loss: 12.980872
 >> iter 8000, loss: 12.974226
 >> iter 9000, loss: 12.959333
 >> iter 10000, loss: 12.955487
   Number of active neurons: 6
 >> iter 11000, loss: 12.933380
 >> iter 12000, loss: 12.848753
 >> iter 13000, loss: 11.981587
 >> iter 14000, loss: 7.585067
 >> iter 15000, loss: 2.890116
 >> iter 16000, loss: 1.089637
 >> iter 17000, loss: 0.418398
 >> iter 18000, loss: 0.165759
 >> iter 19000, loss: 0.070342
 >> iter 20000, loss: 0.033500
   Number of active neurons: 10
 >> iter 21000, loss: 0.019401
 >> iter 22000, loss: 0.013019
 >> iter 23000, loss: 0.018848
 >> iter 24000, loss: 0.012387
 >> iter 25000, loss: 0.009117
 >> iter 26000, loss: 0.007853
 >> iter 27000, loss: 0.006495
 >> iter 28000, loss: 0.005613
 >> iter 29000, loss: 0.004929
 >> iter 30000, loss: 0.004505
   Number of active neurons: 10
 >> iter 31000, loss: 0.004559
 >> iter 32000, loss: 0.045576
 >> iter 33000, loss: 0.022824
 >> iter 34000, loss: 0.011293
 >> iter 35000, loss: 0.006701
 >> iter 36000, loss: 0.004648
 >> iter 37000, loss: 0.003741
 >> iter 38000, loss: 0.003289
 >> iter 39000, loss: 0.002990
 >> iter 40000, loss: 0.002824
   Number of active neurons: 10
 >> iter 41000, loss: 0.002692
 >> iter 42000, loss: 0.002574
 >> iter 43000, loss: 0.002437
 >> iter 44000, loss: 0.002329
 >> iter 45000, loss: 0.002322
 >> iter 46000, loss: 0.002193
 >> iter 47000, loss: 0.002100
 >> iter 48000, loss: 0.002011
 >> iter 49000, loss: 0.001977
 >> iter 50000, loss: 0.001877
   Number of active neurons: 10
 >> iter 51000, loss: 0.001856
 >> iter 52000, loss: 0.001803
 >> iter 53000, loss: 0.001840
 >> iter 54000, loss: 0.001735
 >> iter 55000, loss: 0.001639
 >> iter 56000, loss: 0.001586
 >> iter 57000, loss: 0.001566
 >> iter 58000, loss: 0.001517
 >> iter 59000, loss: 0.001497
 >> iter 60000, loss: 0.001452
   Number of active neurons: 10
 >> iter 61000, loss: 0.001390
 >> iter 62000, loss: 0.001367
 >> iter 63000, loss: 0.001336
 >> iter 64000, loss: 0.001320
 >> iter 65000, loss: 0.001283
 >> iter 66000, loss: 0.001283
 >> iter 67000, loss: 0.001241
 >> iter 68000, loss: 0.001217
 >> iter 69000, loss: 0.001190
 >> iter 70000, loss: 0.001151
   Number of active neurons: 10
 >> iter 71000, loss: 0.001121
 >> iter 72000, loss: 0.001118
 >> iter 73000, loss: 0.001098
 >> iter 74000, loss: 0.001064
 >> iter 75000, loss: 0.001063
 >> iter 76000, loss: 0.001050
 >> iter 77000, loss: 0.001015
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.657725
 >> iter 2000, loss: 15.148537
 >> iter 3000, loss: 13.785159
 >> iter 4000, loss: 13.289045
 >> iter 5000, loss: 13.094805
 >> iter 6000, loss: 13.016860
 >> iter 7000, loss: 12.980204
 >> iter 8000, loss: 12.971224
 >> iter 9000, loss: 12.960552
 >> iter 10000, loss: 12.957883
   Number of active neurons: 7
 >> iter 11000, loss: 12.778295
 >> iter 12000, loss: 12.159990
 >> iter 13000, loss: 10.693561
 >> iter 14000, loss: 5.291238
 >> iter 15000, loss: 2.040929
 >> iter 16000, loss: 0.793356
 >> iter 17000, loss: 0.473424
 >> iter 18000, loss: 0.206390
 >> iter 19000, loss: 0.090256
 >> iter 20000, loss: 0.326118
   Number of active neurons: 10
 >> iter 21000, loss: 0.189478
 >> iter 22000, loss: 0.082948
 >> iter 23000, loss: 0.043146
 >> iter 24000, loss: 0.024784
 >> iter 25000, loss: 0.016540
 >> iter 26000, loss: 0.012527
 >> iter 27000, loss: 0.010241
 >> iter 28000, loss: 0.087813
 >> iter 29000, loss: 0.076635
 >> iter 30000, loss: 0.052066
   Number of active neurons: 10
 >> iter 31000, loss: 0.028129
 >> iter 32000, loss: 0.016913
 >> iter 33000, loss: 0.013476
 >> iter 34000, loss: 0.009290
 >> iter 35000, loss: 0.007172
 >> iter 36000, loss: 0.005953
 >> iter 37000, loss: 0.005293
 >> iter 38000, loss: 0.005384
 >> iter 39000, loss: 0.005211
 >> iter 40000, loss: 0.004813
   Number of active neurons: 10
 >> iter 41000, loss: 0.007089
 >> iter 42000, loss: 0.005552
 >> iter 43000, loss: 0.029460
 >> iter 44000, loss: 0.013939
 >> iter 45000, loss: 0.007695
 >> iter 46000, loss: 0.005066
 >> iter 47000, loss: 0.003946
 >> iter 48000, loss: 0.003461
 >> iter 49000, loss: 0.003128
 >> iter 50000, loss: 0.002963
   Number of active neurons: 10
 >> iter 51000, loss: 0.002850
 >> iter 52000, loss: 0.002679
 >> iter 53000, loss: 0.002606
 >> iter 54000, loss: 0.002506
 >> iter 55000, loss: 0.002392
 >> iter 56000, loss: 0.002516
 >> iter 57000, loss: 0.003583
 >> iter 58000, loss: 0.002910
 >> iter 59000, loss: 0.002681
 >> iter 60000, loss: 0.002371
   Number of active neurons: 10
 >> iter 61000, loss: 0.002170
 >> iter 62000, loss: 0.002305
 >> iter 63000, loss: 0.002232
 >> iter 64000, loss: 0.002114
 >> iter 65000, loss: 0.002001
 >> iter 66000, loss: 0.001918
 >> iter 67000, loss: 0.001826
 >> iter 68000, loss: 0.001776
 >> iter 69000, loss: 0.001722
 >> iter 70000, loss: 0.001877
   Number of active neurons: 10
 >> iter 71000, loss: 0.085438
 >> iter 72000, loss: 0.047406
 >> iter 73000, loss: 0.137890
 >> iter 74000, loss: 0.052960
 >> iter 75000, loss: 0.022187
 >> iter 76000, loss: 0.010103
 >> iter 77000, loss: 0.005411
 >> iter 78000, loss: 0.003534
 >> iter 79000, loss: 0.002797
 >> iter 80000, loss: 0.053996
   Number of active neurons: 10
 >> iter 81000, loss: 0.021507
 >> iter 82000, loss: 0.009375
 >> iter 83000, loss: 0.004804
 >> iter 84000, loss: 0.003036
 >> iter 85000, loss: 0.002332
 >> iter 86000, loss: 0.006949
 >> iter 87000, loss: 0.003981
 >> iter 88000, loss: 0.002767
 >> iter 89000, loss: 0.002224
 >> iter 90000, loss: 0.028369
   Number of active neurons: 10
 >> iter 91000, loss: 0.011943
 >> iter 92000, loss: 0.005964
 >> iter 93000, loss: 0.034327
 >> iter 94000, loss: 0.021958
 >> iter 95000, loss: 0.009411
 >> iter 96000, loss: 0.004685
 >> iter 97000, loss: 0.002858
 >> iter 98000, loss: 0.002125
 >> iter 99000, loss: 0.001801
 >> iter 100000, loss: 0.002977
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.647118
 >> iter 2000, loss: 15.133612
 >> iter 3000, loss: 13.788410
 >> iter 4000, loss: 13.278061
 >> iter 5000, loss: 13.066665
 >> iter 6000, loss: 12.984773
 >> iter 7000, loss: 12.949776
 >> iter 8000, loss: 12.941961
 >> iter 9000, loss: 12.926985
 >> iter 10000, loss: 12.930063
   Number of active neurons: 5
 >> iter 11000, loss: 12.914759
 >> iter 12000, loss: 12.663001
 >> iter 13000, loss: 11.318766
 >> iter 14000, loss: 8.434374
 >> iter 15000, loss: 3.457264
 >> iter 16000, loss: 1.344214
 >> iter 17000, loss: 0.515081
 >> iter 18000, loss: 0.593597
 >> iter 19000, loss: 0.237214
 >> iter 20000, loss: 0.099559
   Number of active neurons: 10
 >> iter 21000, loss: 0.046095
 >> iter 22000, loss: 0.026397
 >> iter 23000, loss: 0.195597
 >> iter 24000, loss: 0.208909
 >> iter 25000, loss: 0.085856
 >> iter 26000, loss: 0.038107
 >> iter 27000, loss: 0.019392
 >> iter 28000, loss: 0.013722
 >> iter 29000, loss: 0.010130
 >> iter 30000, loss: 0.007773
   Number of active neurons: 10
 >> iter 31000, loss: 0.006396
 >> iter 32000, loss: 0.005527
 >> iter 33000, loss: 0.004947
 >> iter 34000, loss: 0.004530
 >> iter 35000, loss: 0.005483
 >> iter 36000, loss: 0.004655
 >> iter 37000, loss: 0.004052
 >> iter 38000, loss: 0.003718
 >> iter 39000, loss: 0.003432
 >> iter 40000, loss: 0.003203
   Number of active neurons: 10
 >> iter 41000, loss: 0.333456
 >> iter 42000, loss: 0.175418
 >> iter 43000, loss: 0.068754
 >> iter 44000, loss: 0.070272
 >> iter 45000, loss: 0.029761
 >> iter 46000, loss: 0.014054
 >> iter 47000, loss: 0.007918
 >> iter 48000, loss: 0.006010
 >> iter 49000, loss: 0.007025
 >> iter 50000, loss: 0.005949
   Number of active neurons: 10
 >> iter 51000, loss: 0.057333
 >> iter 52000, loss: 0.023354
 >> iter 53000, loss: 0.010752
 >> iter 54000, loss: 0.005870
 >> iter 55000, loss: 0.003854
 >> iter 56000, loss: 0.003043
 >> iter 57000, loss: 0.002596
 >> iter 58000, loss: 0.002390
 >> iter 59000, loss: 0.002213
 >> iter 60000, loss: 0.002088
   Number of active neurons: 10
 >> iter 61000, loss: 0.002025
 >> iter 62000, loss: 0.001918
 >> iter 63000, loss: 0.001819
 >> iter 64000, loss: 0.001757
 >> iter 65000, loss: 0.001683
 >> iter 66000, loss: 0.001663
 >> iter 67000, loss: 0.001590
 >> iter 68000, loss: 0.001528
 >> iter 69000, loss: 0.001482
 >> iter 70000, loss: 0.001439
   Number of active neurons: 10
 >> iter 71000, loss: 0.001390
 >> iter 72000, loss: 0.001368
 >> iter 73000, loss: 0.001317
 >> iter 74000, loss: 0.001287
 >> iter 75000, loss: 0.001249
 >> iter 76000, loss: 0.001227
 >> iter 77000, loss: 0.001183
 >> iter 78000, loss: 0.001165
 >> iter 79000, loss: 0.001134
 >> iter 80000, loss: 0.001136
   Number of active neurons: 10
 >> iter 81000, loss: 0.001103
 >> iter 82000, loss: 0.001084
 >> iter 83000, loss: 0.001170
 >> iter 84000, loss: 0.002123
 >> iter 85000, loss: 0.001679
 >> iter 86000, loss: 0.001404
 >> iter 87000, loss: 0.001245
 >> iter 88000, loss: 0.001169
 >> iter 89000, loss: 0.001108
 >> iter 90000, loss: 0.001222
   Number of active neurons: 10
 >> iter 91000, loss: 0.001080
 >> iter 92000, loss: 0.001018
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.659141
 >> iter 2000, loss: 15.127021
 >> iter 3000, loss: 13.783895
 >> iter 4000, loss: 13.279995
 >> iter 5000, loss: 13.079420
 >> iter 6000, loss: 13.008236
 >> iter 7000, loss: 12.980411
 >> iter 8000, loss: 12.979375
 >> iter 9000, loss: 12.961418
 >> iter 10000, loss: 12.968963
   Number of active neurons: 6
 >> iter 11000, loss: 12.941417
 >> iter 12000, loss: 12.492090
 >> iter 13000, loss: 10.037940
 >> iter 14000, loss: 3.875804
 >> iter 15000, loss: 1.486978
 >> iter 16000, loss: 0.618967
 >> iter 17000, loss: 0.248162
 >> iter 18000, loss: 0.106514
 >> iter 19000, loss: 0.248401
 >> iter 20000, loss: 0.104668
   Number of active neurons: 10
 >> iter 21000, loss: 0.048999
 >> iter 22000, loss: 0.027056
 >> iter 23000, loss: 0.017635
 >> iter 24000, loss: 0.013268
 >> iter 25000, loss: 0.010949
 >> iter 26000, loss: 0.009526
 >> iter 27000, loss: 0.008522
 >> iter 28000, loss: 0.007831
 >> iter 29000, loss: 0.007124
 >> iter 30000, loss: 0.006635
   Number of active neurons: 10
 >> iter 31000, loss: 0.006153
 >> iter 32000, loss: 0.005728
 >> iter 33000, loss: 0.005359
 >> iter 34000, loss: 0.005023
 >> iter 35000, loss: 0.044254
 >> iter 36000, loss: 0.019885
 >> iter 37000, loss: 0.010415
 >> iter 38000, loss: 0.006704
 >> iter 39000, loss: 0.005164
 >> iter 40000, loss: 0.004386
   Number of active neurons: 10
 >> iter 41000, loss: 0.003948
 >> iter 42000, loss: 0.003690
 >> iter 43000, loss: 0.003465
 >> iter 44000, loss: 0.003298
 >> iter 45000, loss: 0.003209
 >> iter 46000, loss: 0.003050
 >> iter 47000, loss: 0.002956
 >> iter 48000, loss: 0.002832
 >> iter 49000, loss: 0.002749
 >> iter 50000, loss: 0.002704
   Number of active neurons: 10
 >> iter 51000, loss: 0.002562
 >> iter 52000, loss: 0.002488
 >> iter 53000, loss: 0.002430
 >> iter 54000, loss: 0.002377
 >> iter 55000, loss: 0.002292
 >> iter 56000, loss: 0.002344
 >> iter 57000, loss: 0.002201
 >> iter 58000, loss: 0.002766
 >> iter 59000, loss: 0.002344
 >> iter 60000, loss: 0.002131
   Number of active neurons: 10
 >> iter 61000, loss: 0.002052
 >> iter 62000, loss: 0.001986
 >> iter 63000, loss: 0.001924
 >> iter 64000, loss: 0.001866
 >> iter 65000, loss: 0.001818
 >> iter 66000, loss: 0.001765
 >> iter 67000, loss: 0.001722
 >> iter 68000, loss: 0.001701
 >> iter 69000, loss: 0.001643
 >> iter 70000, loss: 0.001850
   Number of active neurons: 10
 >> iter 71000, loss: 0.001701
 >> iter 72000, loss: 0.001595
 >> iter 73000, loss: 0.001582
 >> iter 74000, loss: 0.001522
 >> iter 75000, loss: 0.001475
 >> iter 76000, loss: 0.001476
 >> iter 77000, loss: 0.002355
 >> iter 78000, loss: 0.001949
 >> iter 79000, loss: 0.189394
 >> iter 80000, loss: 0.071611
   Number of active neurons: 10
 >> iter 81000, loss: 0.027794
 >> iter 82000, loss: 0.011555
 >> iter 83000, loss: 0.005482
 >> iter 84000, loss: 0.003195
 >> iter 85000, loss: 0.002365
 >> iter 86000, loss: 0.001956
 >> iter 87000, loss: 0.001771
 >> iter 88000, loss: 0.001701
 >> iter 89000, loss: 0.001620
 >> iter 90000, loss: 0.001563
   Number of active neurons: 10
 >> iter 91000, loss: 0.001518
 >> iter 92000, loss: 0.001590
 >> iter 93000, loss: 0.001467
 >> iter 94000, loss: 0.001426
 >> iter 95000, loss: 0.001376
 >> iter 96000, loss: 0.001336
 >> iter 97000, loss: 0.001339
 >> iter 98000, loss: 0.001296
 >> iter 99000, loss: 0.001284
 >> iter 100000, loss: 0.001243
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.657994
 >> iter 2000, loss: 15.115952
 >> iter 3000, loss: 13.778963
 >> iter 4000, loss: 13.280024
 >> iter 5000, loss: 13.081998
 >> iter 6000, loss: 13.012892
 >> iter 7000, loss: 12.971143
 >> iter 8000, loss: 12.968034
 >> iter 9000, loss: 12.954591
 >> iter 10000, loss: 12.952866
   Number of active neurons: 6
 >> iter 11000, loss: 12.743938
 >> iter 12000, loss: 11.757694
 >> iter 13000, loss: 5.440051
 >> iter 14000, loss: 2.141200
 >> iter 15000, loss: 1.209919
 >> iter 16000, loss: 0.480987
 >> iter 17000, loss: 0.228021
 >> iter 18000, loss: 0.101674
 >> iter 19000, loss: 0.071449
 >> iter 20000, loss: 0.052690
   Number of active neurons: 10
 >> iter 21000, loss: 0.029526
 >> iter 22000, loss: 0.066049
 >> iter 23000, loss: 0.032962
 >> iter 24000, loss: 0.019435
 >> iter 25000, loss: 0.013238
 >> iter 26000, loss: 0.010395
 >> iter 27000, loss: 0.008829
 >> iter 28000, loss: 0.007983
 >> iter 29000, loss: 0.007154
 >> iter 30000, loss: 0.006791
   Number of active neurons: 10
 >> iter 31000, loss: 0.006194
 >> iter 32000, loss: 0.005764
 >> iter 33000, loss: 0.005441
 >> iter 34000, loss: 0.005081
 >> iter 35000, loss: 0.004783
 >> iter 36000, loss: 0.004569
 >> iter 37000, loss: 0.004289
 >> iter 38000, loss: 0.004110
 >> iter 39000, loss: 0.003965
 >> iter 40000, loss: 0.003751
   Number of active neurons: 10
 >> iter 41000, loss: 0.003593
 >> iter 42000, loss: 0.003498
 >> iter 43000, loss: 0.003329
 >> iter 44000, loss: 0.003229
 >> iter 45000, loss: 0.003122
 >> iter 46000, loss: 0.003021
 >> iter 47000, loss: 0.002896
 >> iter 48000, loss: 0.002832
 >> iter 49000, loss: 0.003060
 >> iter 50000, loss: 0.002891
   Number of active neurons: 10
 >> iter 51000, loss: 0.002795
 >> iter 52000, loss: 0.002605
 >> iter 53000, loss: 0.002618
 >> iter 54000, loss: 0.002482
 >> iter 55000, loss: 0.002389
 >> iter 56000, loss: 0.002298
 >> iter 57000, loss: 0.002217
 >> iter 58000, loss: 0.002160
 >> iter 59000, loss: 0.002102
 >> iter 60000, loss: 0.002070
   Number of active neurons: 10
 >> iter 61000, loss: 0.002028
 >> iter 62000, loss: 0.001971
 >> iter 63000, loss: 0.001914
 >> iter 64000, loss: 0.001872
 >> iter 65000, loss: 0.001827
 >> iter 66000, loss: 0.001795
 >> iter 67000, loss: 0.001760
 >> iter 68000, loss: 0.001762
 >> iter 69000, loss: 0.001797
 >> iter 70000, loss: 0.001705
   Number of active neurons: 10
 >> iter 71000, loss: 0.001633
 >> iter 72000, loss: 0.001625
 >> iter 73000, loss: 0.001559
 >> iter 74000, loss: 0.001542
 >> iter 75000, loss: 0.001498
 >> iter 76000, loss: 0.001490
 >> iter 77000, loss: 0.001454
 >> iter 78000, loss: 0.001451
 >> iter 79000, loss: 0.001418
 >> iter 80000, loss: 0.001397
   Number of active neurons: 10
 >> iter 81000, loss: 0.001354
 >> iter 82000, loss: 0.001344
 >> iter 83000, loss: 0.001322
 >> iter 84000, loss: 0.001302
 >> iter 85000, loss: 0.001291
 >> iter 86000, loss: 0.001260
 >> iter 87000, loss: 0.001240
 >> iter 88000, loss: 0.001241
 >> iter 89000, loss: 0.001202
 >> iter 90000, loss: 0.001190
   Number of active neurons: 10
 >> iter 91000, loss: 0.001168
 >> iter 92000, loss: 0.001149
 >> iter 93000, loss: 0.001148
 >> iter 94000, loss: 0.001142
 >> iter 95000, loss: 0.001117
 >> iter 96000, loss: 0.001107
 >> iter 97000, loss: 0.001083
 >> iter 98000, loss: 0.001078
 >> iter 99000, loss: 0.001053
 >> iter 100000, loss: 0.001039
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.646827
 >> iter 2000, loss: 15.143452
 >> iter 3000, loss: 13.797632
 >> iter 4000, loss: 13.293302
 >> iter 5000, loss: 13.078294
 >> iter 6000, loss: 13.003248
 >> iter 7000, loss: 12.965694
 >> iter 8000, loss: 12.952469
 >> iter 9000, loss: 12.924715
 >> iter 10000, loss: 12.471952
   Number of active neurons: 9
 >> iter 11000, loss: 10.506525
 >> iter 12000, loss: 4.005608
 >> iter 13000, loss: 1.500308
 >> iter 14000, loss: 0.567260
 >> iter 15000, loss: 0.219708
 >> iter 16000, loss: 0.193671
 >> iter 17000, loss: 0.083207
 >> iter 18000, loss: 0.038718
 >> iter 19000, loss: 0.019866
 >> iter 20000, loss: 0.011973
   Number of active neurons: 10
 >> iter 21000, loss: 0.008426
 >> iter 22000, loss: 0.006769
 >> iter 23000, loss: 0.008422
 >> iter 24000, loss: 0.006324
 >> iter 25000, loss: 0.005300
 >> iter 26000, loss: 0.004461
 >> iter 27000, loss: 0.004054
 >> iter 28000, loss: 0.003627
 >> iter 29000, loss: 0.003334
 >> iter 30000, loss: 0.003246
   Number of active neurons: 10
 >> iter 31000, loss: 0.003022
 >> iter 32000, loss: 0.002787
 >> iter 33000, loss: 0.002669
 >> iter 34000, loss: 0.003833
 >> iter 35000, loss: 0.003088
 >> iter 36000, loss: 0.002585
 >> iter 37000, loss: 0.002361
 >> iter 38000, loss: 0.002142
 >> iter 39000, loss: 0.002021
 >> iter 40000, loss: 0.001904
   Number of active neurons: 10
 >> iter 41000, loss: 0.001847
 >> iter 42000, loss: 0.001759
 >> iter 43000, loss: 0.001707
 >> iter 44000, loss: 0.001632
 >> iter 45000, loss: 0.001574
 >> iter 46000, loss: 0.001524
 >> iter 47000, loss: 0.001484
 >> iter 48000, loss: 0.001476
 >> iter 49000, loss: 0.001472
 >> iter 50000, loss: 0.001380
   Number of active neurons: 10
 >> iter 51000, loss: 0.001338
 >> iter 52000, loss: 0.001281
 >> iter 53000, loss: 0.001274
 >> iter 54000, loss: 0.001224
 >> iter 55000, loss: 0.001218
 >> iter 56000, loss: 0.001167
 >> iter 57000, loss: 0.001133
 >> iter 58000, loss: 0.001133
 >> iter 59000, loss: 0.001121
 >> iter 60000, loss: 0.001078
   Number of active neurons: 10
 >> iter 61000, loss: 0.001046
 >> iter 62000, loss: 0.001016
 >> iter 63000, loss: 0.001010
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.655831
 >> iter 2000, loss: 15.135397
 >> iter 3000, loss: 13.783096
 >> iter 4000, loss: 13.276646
 >> iter 5000, loss: 13.071042
 >> iter 6000, loss: 12.998171
 >> iter 7000, loss: 12.956344
 >> iter 8000, loss: 12.949221
 >> iter 9000, loss: 12.936695
 >> iter 10000, loss: 12.943696
   Number of active neurons: 4
 >> iter 11000, loss: 12.930881
 >> iter 12000, loss: 12.928432
 >> iter 13000, loss: 12.818854
 >> iter 14000, loss: 11.030490
 >> iter 15000, loss: 4.363215
 >> iter 16000, loss: 1.798076
 >> iter 17000, loss: 0.690535
 >> iter 18000, loss: 0.272256
 >> iter 19000, loss: 0.116876
 >> iter 20000, loss: 0.054659
   Number of active neurons: 10
 >> iter 21000, loss: 0.029351
 >> iter 22000, loss: 0.019926
 >> iter 23000, loss: 0.014142
 >> iter 24000, loss: 0.011351
 >> iter 25000, loss: 0.009693
 >> iter 26000, loss: 0.008373
 >> iter 27000, loss: 0.007448
 >> iter 28000, loss: 0.006881
 >> iter 29000, loss: 0.069039
 >> iter 30000, loss: 0.030044
   Number of active neurons: 10
 >> iter 31000, loss: 0.016163
 >> iter 32000, loss: 0.010001
 >> iter 33000, loss: 0.007208
 >> iter 34000, loss: 0.005868
 >> iter 35000, loss: 0.005221
 >> iter 36000, loss: 0.004802
 >> iter 37000, loss: 0.004394
 >> iter 38000, loss: 0.007507
 >> iter 39000, loss: 0.005688
 >> iter 40000, loss: 0.004758
   Number of active neurons: 10
 >> iter 41000, loss: 0.004207
 >> iter 42000, loss: 0.003782
 >> iter 43000, loss: 0.015916
 >> iter 44000, loss: 0.008407
 >> iter 45000, loss: 0.005321
 >> iter 46000, loss: 0.004098
 >> iter 47000, loss: 0.003438
 >> iter 48000, loss: 0.003077
 >> iter 49000, loss: 0.002921
 >> iter 50000, loss: 0.002731
   Number of active neurons: 10
 >> iter 51000, loss: 0.002579
 >> iter 52000, loss: 0.002517
 >> iter 53000, loss: 0.002625
 >> iter 54000, loss: 0.002792
 >> iter 55000, loss: 0.012910
 >> iter 56000, loss: 0.006466
 >> iter 57000, loss: 0.004028
 >> iter 58000, loss: 0.002981
 >> iter 59000, loss: 0.002542
 >> iter 60000, loss: 0.002323
   Number of active neurons: 10
 >> iter 61000, loss: 0.002187
 >> iter 62000, loss: 0.002124
 >> iter 63000, loss: 0.002015
 >> iter 64000, loss: 0.001938
 >> iter 65000, loss: 0.001863
 >> iter 66000, loss: 0.001835
 >> iter 67000, loss: 0.001767
 >> iter 68000, loss: 0.001701
 >> iter 69000, loss: 0.001652
 >> iter 70000, loss: 0.001625
   Number of active neurons: 10
 >> iter 71000, loss: 0.001572
 >> iter 72000, loss: 0.001543
 >> iter 73000, loss: 0.001498
 >> iter 74000, loss: 0.001474
 >> iter 75000, loss: 0.001489
 >> iter 76000, loss: 0.001497
 >> iter 77000, loss: 0.001440
 >> iter 78000, loss: 0.001440
 >> iter 79000, loss: 0.001372
 >> iter 80000, loss: 0.001343
   Number of active neurons: 10
 >> iter 81000, loss: 0.001310
 >> iter 82000, loss: 0.001277
 >> iter 83000, loss: 0.001255
 >> iter 84000, loss: 0.001232
 >> iter 85000, loss: 0.001217
 >> iter 86000, loss: 0.001185
 >> iter 87000, loss: 0.001163
 >> iter 88000, loss: 0.001141
 >> iter 89000, loss: 0.001122
 >> iter 90000, loss: 0.001102
   Number of active neurons: 10
 >> iter 91000, loss: 0.001087
 >> iter 92000, loss: 0.001093
 >> iter 93000, loss: 0.001098
 >> iter 94000, loss: 0.001072
 >> iter 95000, loss: 0.001032
 >> iter 96000, loss: 0.001042
 >> iter 97000, loss: 0.001014
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.649119
 >> iter 2000, loss: 15.126806
 >> iter 3000, loss: 13.794435
 >> iter 4000, loss: 13.291031
 >> iter 5000, loss: 13.070561
 >> iter 6000, loss: 12.993705
 >> iter 7000, loss: 12.959728
 >> iter 8000, loss: 12.952921
 >> iter 9000, loss: 12.936645
 >> iter 10000, loss: 12.941917
   Number of active neurons: 5
 >> iter 11000, loss: 12.927979
 >> iter 12000, loss: 12.935312
 >> iter 13000, loss: 12.922907
 >> iter 14000, loss: 12.933391
 >> iter 15000, loss: 12.927257
 >> iter 16000, loss: 12.934885
 >> iter 17000, loss: 12.868517
 >> iter 18000, loss: 11.969444
 >> iter 19000, loss: 10.338179
 >> iter 20000, loss: 8.779494
   Number of active neurons: 10
 >> iter 21000, loss: 7.221247
 >> iter 22000, loss: 5.987259
 >> iter 23000, loss: 4.874911
 >> iter 24000, loss: 3.096136
 >> iter 25000, loss: 1.537909
 >> iter 26000, loss: 0.632540
 >> iter 27000, loss: 0.480188
 >> iter 28000, loss: 0.253839
 >> iter 29000, loss: 0.120573
 >> iter 30000, loss: 0.069592
   Number of active neurons: 10
 >> iter 31000, loss: 0.039513
 >> iter 32000, loss: 0.026864
 >> iter 33000, loss: 0.020201
 >> iter 34000, loss: 0.016765
 >> iter 35000, loss: 0.014149
 >> iter 36000, loss: 0.122617
 >> iter 37000, loss: 0.085660
 >> iter 38000, loss: 0.039462
 >> iter 39000, loss: 0.021359
 >> iter 40000, loss: 0.109129
   Number of active neurons: 10
 >> iter 41000, loss: 0.047818
 >> iter 42000, loss: 0.049873
 >> iter 43000, loss: 0.025202
 >> iter 44000, loss: 0.015268
 >> iter 45000, loss: 0.197627
 >> iter 46000, loss: 0.080019
 >> iter 47000, loss: 0.035645
 >> iter 48000, loss: 0.198443
 >> iter 49000, loss: 0.081336
 >> iter 50000, loss: 0.035962
   Number of active neurons: 10
 >> iter 51000, loss: 0.018403
 >> iter 52000, loss: 0.011518
 >> iter 53000, loss: 0.019153
 >> iter 54000, loss: 0.011817
 >> iter 55000, loss: 0.008500
 >> iter 56000, loss: 0.007078
 >> iter 57000, loss: 0.006161
 >> iter 58000, loss: 0.005673
 >> iter 59000, loss: 0.005190
 >> iter 60000, loss: 0.004993
   Number of active neurons: 10
 >> iter 61000, loss: 0.106499
 >> iter 62000, loss: 0.802093
 >> iter 63000, loss: 0.316242
 >> iter 64000, loss: 0.124273
 >> iter 65000, loss: 0.054214
 >> iter 66000, loss: 0.025692
 >> iter 67000, loss: 0.014403
 >> iter 68000, loss: 0.010077
 >> iter 69000, loss: 0.007811
 >> iter 70000, loss: 0.006887
   Number of active neurons: 10
 >> iter 71000, loss: 0.102488
 >> iter 72000, loss: 0.042857
 >> iter 73000, loss: 0.020021
 >> iter 74000, loss: 0.011355
 >> iter 75000, loss: 0.049748
 >> iter 76000, loss: 0.025756
 >> iter 77000, loss: 0.013355
 >> iter 78000, loss: 0.008379
 >> iter 79000, loss: 0.006133
 >> iter 80000, loss: 0.005324
   Number of active neurons: 10
 >> iter 81000, loss: 0.004711
 >> iter 82000, loss: 0.004383
 >> iter 83000, loss: 0.004513
 >> iter 84000, loss: 0.004172
 >> iter 85000, loss: 0.003860
 >> iter 86000, loss: 0.003691
 >> iter 87000, loss: 0.003462
 >> iter 88000, loss: 0.003360
 >> iter 89000, loss: 0.003172
 >> iter 90000, loss: 0.003093
   Number of active neurons: 10
 >> iter 91000, loss: 0.002915
 >> iter 92000, loss: 0.018360
 >> iter 93000, loss: 0.008995
 >> iter 94000, loss: 0.005343
 >> iter 95000, loss: 0.004175
 >> iter 96000, loss: 0.003388
 >> iter 97000, loss: 0.002950
 >> iter 98000, loss: 0.002752
 >> iter 99000, loss: 0.002990
 >> iter 100000, loss: 0.002814
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.658299
 >> iter 2000, loss: 15.161088
 >> iter 3000, loss: 13.813797
 >> iter 4000, loss: 13.302951
 >> iter 5000, loss: 13.096816
 >> iter 6000, loss: 13.024036
 >> iter 7000, loss: 12.988308
 >> iter 8000, loss: 12.977818
 >> iter 9000, loss: 12.970136
 >> iter 10000, loss: 12.971299
   Number of active neurons: 7
 >> iter 11000, loss: 12.957422
 >> iter 12000, loss: 12.963448
 >> iter 13000, loss: 12.951931
 >> iter 14000, loss: 12.870293
 >> iter 15000, loss: 9.387360
 >> iter 16000, loss: 3.562683
 >> iter 17000, loss: 1.353776
 >> iter 18000, loss: 0.554885
 >> iter 19000, loss: 0.224573
 >> iter 20000, loss: 0.098156
   Number of active neurons: 10
 >> iter 21000, loss: 0.048778
 >> iter 22000, loss: 0.028564
 >> iter 23000, loss: 0.019697
 >> iter 24000, loss: 0.015337
 >> iter 25000, loss: 0.205315
 >> iter 26000, loss: 0.117481
 >> iter 27000, loss: 0.051452
 >> iter 28000, loss: 0.057134
 >> iter 29000, loss: 0.028357
 >> iter 30000, loss: 0.016563
   Number of active neurons: 10
 >> iter 31000, loss: 0.011497
 >> iter 32000, loss: 0.009203
 >> iter 33000, loss: 0.007908
 >> iter 34000, loss: 0.007138
 >> iter 35000, loss: 0.006501
 >> iter 36000, loss: 0.006076
 >> iter 37000, loss: 0.005676
 >> iter 38000, loss: 0.005348
 >> iter 39000, loss: 0.005036
 >> iter 40000, loss: 0.004797
   Number of active neurons: 10
 >> iter 41000, loss: 0.004543
 >> iter 42000, loss: 0.004415
 >> iter 43000, loss: 0.004189
 >> iter 44000, loss: 0.004016
 >> iter 45000, loss: 0.003831
 >> iter 46000, loss: 0.003725
 >> iter 47000, loss: 0.003539
 >> iter 48000, loss: 0.003426
 >> iter 49000, loss: 0.003303
 >> iter 50000, loss: 0.003210
   Number of active neurons: 10
 >> iter 51000, loss: 0.003109
 >> iter 52000, loss: 0.003029
 >> iter 53000, loss: 0.002917
 >> iter 54000, loss: 0.002842
 >> iter 55000, loss: 0.002748
 >> iter 56000, loss: 0.002678
 >> iter 57000, loss: 0.002597
 >> iter 58000, loss: 0.002541
 >> iter 59000, loss: 0.002460
 >> iter 60000, loss: 0.002425
   Number of active neurons: 10
 >> iter 61000, loss: 0.002339
 >> iter 62000, loss: 0.002305
 >> iter 63000, loss: 0.002243
 >> iter 64000, loss: 0.002207
 >> iter 65000, loss: 0.002149
 >> iter 66000, loss: 0.002100
 >> iter 67000, loss: 0.002052
 >> iter 68000, loss: 0.002019
 >> iter 69000, loss: 0.001964
 >> iter 70000, loss: 0.001931
   Number of active neurons: 10
 >> iter 71000, loss: 0.001894
 >> iter 72000, loss: 0.001860
 >> iter 73000, loss: 0.001818
 >> iter 74000, loss: 0.001801
 >> iter 75000, loss: 0.001758
 >> iter 76000, loss: 0.001726
 >> iter 77000, loss: 0.001686
 >> iter 78000, loss: 0.001675
 >> iter 79000, loss: 0.001638
 >> iter 80000, loss: 0.001611
   Number of active neurons: 10
 >> iter 81000, loss: 0.001579
 >> iter 82000, loss: 0.001563
 >> iter 83000, loss: 0.001534
 >> iter 84000, loss: 0.001512
 >> iter 85000, loss: 0.001480
 >> iter 86000, loss: 0.001466
 >> iter 87000, loss: 0.001440
 >> iter 88000, loss: 0.001427
 >> iter 89000, loss: 0.001400
 >> iter 90000, loss: 0.001380
   Number of active neurons: 10
 >> iter 91000, loss: 0.001360
 >> iter 92000, loss: 0.001339
 >> iter 93000, loss: 0.001322
 >> iter 94000, loss: 0.001317
 >> iter 95000, loss: 0.001338
 >> iter 96000, loss: 0.001295
 >> iter 97000, loss: 0.001266
 >> iter 98000, loss: 0.001246
 >> iter 99000, loss: 0.001224
 >> iter 100000, loss: 0.001211
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

