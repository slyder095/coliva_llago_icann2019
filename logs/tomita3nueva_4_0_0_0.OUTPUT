 > Problema: tomita3nueva
 > Args:
   - Hidden size: 4
   - Noise level: 0.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.683568
 >> iter 2000, loss: 8.130814
 >> iter 3000, loss: 3.070491
 >> iter 4000, loss: 1.170545
 >> iter 5000, loss: 0.458817
 >> iter 6000, loss: 0.189889
 >> iter 7000, loss: 0.086957
 >> iter 8000, loss: 0.046112
 >> iter 9000, loss: 0.029174
 >> iter 10000, loss: 0.021299
   Number of active neurons: 4
 >> iter 11000, loss: 0.017298
 >> iter 12000, loss: 0.014792
 >> iter 13000, loss: 0.013153
 >> iter 14000, loss: 0.011843
 >> iter 15000, loss: 0.010856
 >> iter 16000, loss: 0.009977
 >> iter 17000, loss: 0.009284
 >> iter 18000, loss: 0.008636
 >> iter 19000, loss: 0.008113
 >> iter 20000, loss: 0.007612
   Number of active neurons: 4
 >> iter 21000, loss: 0.007208
 >> iter 22000, loss: 0.006808
 >> iter 23000, loss: 0.006483
 >> iter 24000, loss: 0.006153
 >> iter 25000, loss: 0.005886
 >> iter 26000, loss: 0.005612
 >> iter 27000, loss: 0.005388
 >> iter 28000, loss: 0.005156
 >> iter 29000, loss: 0.004967
 >> iter 30000, loss: 0.004770
   Number of active neurons: 4
 >> iter 31000, loss: 0.004610
 >> iter 32000, loss: 0.004436
 >> iter 33000, loss: 0.004297
 >> iter 34000, loss: 0.004148
 >> iter 35000, loss: 0.004024
 >> iter 36000, loss: 0.003895
 >> iter 37000, loss: 0.003785
 >> iter 38000, loss: 0.003669
 >> iter 39000, loss: 0.003572
 >> iter 40000, loss: 0.003468
   Number of active neurons: 4
 >> iter 41000, loss: 0.003381
 >> iter 42000, loss: 0.003288
 >> iter 43000, loss: 0.003209
 >> iter 44000, loss: 0.003126
 >> iter 45000, loss: 0.003055
 >> iter 46000, loss: 0.002978
 >> iter 47000, loss: 0.002912
 >> iter 48000, loss: 0.002845
 >> iter 49000, loss: 0.002782
 >> iter 50000, loss: 0.002721
   Number of active neurons: 4
 >> iter 51000, loss: 0.002663
 >> iter 52000, loss: 0.002610
 >> iter 53000, loss: 0.002555
 >> iter 54000, loss: 0.002506
 >> iter 55000, loss: 0.002454
 >> iter 56000, loss: 0.002409
 >> iter 57000, loss: 0.002362
 >> iter 58000, loss: 0.002320
 >> iter 59000, loss: 0.002275
 >> iter 60000, loss: 0.002238
   Number of active neurons: 4
 >> iter 61000, loss: 0.002195
 >> iter 62000, loss: 0.002160
 >> iter 63000, loss: 0.002121
 >> iter 64000, loss: 0.002089
 >> iter 65000, loss: 0.002052
 >> iter 66000, loss: 0.002022
 >> iter 67000, loss: 0.001988
 >> iter 68000, loss: 0.001959
 >> iter 69000, loss: 0.001925
 >> iter 70000, loss: 0.001900
   Number of active neurons: 4
 >> iter 71000, loss: 0.001868
 >> iter 72000, loss: 0.001844
 >> iter 73000, loss: 0.001814
 >> iter 74000, loss: 0.001791
 >> iter 75000, loss: 0.001764
 >> iter 76000, loss: 0.001743
 >> iter 77000, loss: 0.001714
 >> iter 78000, loss: 0.001695
 >> iter 79000, loss: 0.001669
 >> iter 80000, loss: 0.001651
   Number of active neurons: 4
 >> iter 81000, loss: 0.001625
 >> iter 82000, loss: 0.001609
 >> iter 83000, loss: 0.001584
 >> iter 84000, loss: 0.001568
 >> iter 85000, loss: 0.001545
 >> iter 86000, loss: 0.001530
 >> iter 87000, loss: 0.001507
 >> iter 88000, loss: 0.001494
 >> iter 89000, loss: 0.001471
 >> iter 90000, loss: 0.001460
   Number of active neurons: 4
 >> iter 91000, loss: 0.001437
 >> iter 92000, loss: 0.001426
 >> iter 93000, loss: 0.001405
 >> iter 94000, loss: 0.001394
 >> iter 95000, loss: 0.001375
 >> iter 96000, loss: 0.001363
 >> iter 97000, loss: 0.001345
 >> iter 98000, loss: 0.001334
 >> iter 99000, loss: 0.001317
 >> iter 100000, loss: 0.001305
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 11.2059196054
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.050179
 >> iter 2000, loss: 12.652792
 >> iter 3000, loss: 8.176543
 >> iter 4000, loss: 3.694440
 >> iter 5000, loss: 1.759223
 >> iter 6000, loss: 0.858777
 >> iter 7000, loss: 0.453790
 >> iter 8000, loss: 0.373575
 >> iter 9000, loss: 0.281446
 >> iter 10000, loss: 0.199264
   Number of active neurons: 4
 >> iter 11000, loss: 0.190895
 >> iter 12000, loss: 0.279539
 >> iter 13000, loss: 0.784452
 >> iter 14000, loss: 0.725686
 >> iter 15000, loss: 0.682829
 >> iter 16000, loss: 0.390015
 >> iter 17000, loss: 0.285854
 >> iter 18000, loss: 0.458628
 >> iter 19000, loss: 0.281449
 >> iter 20000, loss: 0.131936
   Number of active neurons: 4
 >> iter 21000, loss: 0.065297
 >> iter 22000, loss: 0.039359
 >> iter 23000, loss: 0.026484
 >> iter 24000, loss: 0.021659
 >> iter 25000, loss: 0.017434
 >> iter 26000, loss: 0.015163
 >> iter 27000, loss: 0.013409
 >> iter 28000, loss: 0.012161
 >> iter 29000, loss: 0.011177
 >> iter 30000, loss: 0.010311
   Number of active neurons: 4
 >> iter 31000, loss: 0.009676
 >> iter 32000, loss: 0.009040
 >> iter 33000, loss: 0.008567
 >> iter 34000, loss: 0.008077
 >> iter 35000, loss: 0.007699
 >> iter 36000, loss: 0.007386
 >> iter 37000, loss: 0.007022
 >> iter 38000, loss: 0.006864
 >> iter 39000, loss: 0.006489
 >> iter 40000, loss: 0.006153
   Number of active neurons: 4
 >> iter 41000, loss: 0.005911
 >> iter 42000, loss: 0.005678
 >> iter 43000, loss: 0.005481
 >> iter 44000, loss: 0.005279
 >> iter 45000, loss: 0.005114
 >> iter 46000, loss: 0.004935
 >> iter 47000, loss: 0.004792
 >> iter 48000, loss: 0.004636
 >> iter 49000, loss: 0.004511
 >> iter 50000, loss: 0.004369
   Number of active neurons: 4
 >> iter 51000, loss: 0.004262
 >> iter 52000, loss: 0.004138
 >> iter 53000, loss: 0.004038
 >> iter 54000, loss: 0.003927
 >> iter 55000, loss: 0.003837
 >> iter 56000, loss: 0.003737
 >> iter 57000, loss: 0.003660
 >> iter 58000, loss: 0.003565
 >> iter 59000, loss: 0.003495
 >> iter 60000, loss: 0.003410
   Number of active neurons: 4
 >> iter 61000, loss: 0.003347
 >> iter 62000, loss: 0.003266
 >> iter 63000, loss: 0.003212
 >> iter 64000, loss: 0.003138
 >> iter 65000, loss: 0.003088
 >> iter 66000, loss: 0.003019
 >> iter 67000, loss: 0.002973
 >> iter 68000, loss: 0.002910
 >> iter 69000, loss: 0.002864
 >> iter 70000, loss: 0.002807
   Number of active neurons: 4
 >> iter 71000, loss: 0.002766
 >> iter 72000, loss: 0.002711
 >> iter 73000, loss: 0.002674
 >> iter 74000, loss: 0.002621
 >> iter 75000, loss: 0.002588
 >> iter 76000, loss: 0.002539
 >> iter 77000, loss: 0.002505
 >> iter 78000, loss: 0.002459
 >> iter 79000, loss: 0.002428
 >> iter 80000, loss: 0.002384
   Number of active neurons: 4
 >> iter 81000, loss: 0.002355
 >> iter 82000, loss: 0.002315
 >> iter 83000, loss: 0.002288
 >> iter 84000, loss: 0.002249
 >> iter 85000, loss: 0.002225
 >> iter 86000, loss: 0.002188
 >> iter 87000, loss: 0.002165
 >> iter 88000, loss: 0.002131
 >> iter 89000, loss: 0.002107
 >> iter 90000, loss: 0.002076
   Number of active neurons: 4
 >> iter 91000, loss: 0.002052
 >> iter 92000, loss: 0.002023
 >> iter 93000, loss: 0.002000
 >> iter 94000, loss: 0.001972
 >> iter 95000, loss: 0.001955
 >> iter 96000, loss: 0.001924
 >> iter 97000, loss: 0.001908
 >> iter 98000, loss: 0.001879
 >> iter 99000, loss: 0.001864
 >> iter 100000, loss: 0.001835
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 12.9724685021
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.799559
 >> iter 2000, loss: 8.868097
 >> iter 3000, loss: 3.358887
 >> iter 4000, loss: 1.294826
 >> iter 5000, loss: 0.500353
 >> iter 6000, loss: 0.203996
 >> iter 7000, loss: 0.089312
 >> iter 8000, loss: 0.046805
 >> iter 9000, loss: 0.027352
 >> iter 10000, loss: 0.021121
   Number of active neurons: 4
 >> iter 11000, loss: 0.015620
 >> iter 12000, loss: 0.015957
 >> iter 13000, loss: 0.012341
 >> iter 14000, loss: 0.011696
 >> iter 15000, loss: 0.009591
 >> iter 16000, loss: 0.009859
 >> iter 17000, loss: 0.008173
 >> iter 18000, loss: 0.008816
 >> iter 19000, loss: 0.007234
 >> iter 20000, loss: 0.007911
   Number of active neurons: 4
 >> iter 21000, loss: 0.006463
 >> iter 22000, loss: 0.006867
 >> iter 23000, loss: 0.005729
 >> iter 24000, loss: 0.005882
 >> iter 25000, loss: 0.005094
 >> iter 26000, loss: 0.005147
 >> iter 27000, loss: 0.004572
 >> iter 28000, loss: 0.004492
 >> iter 29000, loss: 0.004099
 >> iter 30000, loss: 0.003883
   Number of active neurons: 4
 >> iter 31000, loss: 0.003683
 >> iter 32000, loss: 0.003543
 >> iter 33000, loss: 0.003381
 >> iter 34000, loss: 0.003276
 >> iter 35000, loss: 0.003134
 >> iter 36000, loss: 0.003044
 >> iter 37000, loss: 0.002930
 >> iter 38000, loss: 0.002862
 >> iter 39000, loss: 0.002766
 >> iter 40000, loss: 0.002709
   Number of active neurons: 4
 >> iter 41000, loss: 0.002611
 >> iter 42000, loss: 0.002547
 >> iter 43000, loss: 0.002465
 >> iter 44000, loss: 0.002414
 >> iter 45000, loss: 0.002343
 >> iter 46000, loss: 0.002294
 >> iter 47000, loss: 0.002230
 >> iter 48000, loss: 0.002190
 >> iter 49000, loss: 0.002130
 >> iter 50000, loss: 0.002093
   Number of active neurons: 4
 >> iter 51000, loss: 0.002037
 >> iter 52000, loss: 0.002007
 >> iter 53000, loss: 0.001953
 >> iter 54000, loss: 0.001926
 >> iter 55000, loss: 0.001876
 >> iter 56000, loss: 0.001852
 >> iter 57000, loss: 0.001805
 >> iter 58000, loss: 0.001783
 >> iter 59000, loss: 0.001739
 >> iter 60000, loss: 0.001721
   Number of active neurons: 4
 >> iter 61000, loss: 0.001679
 >> iter 62000, loss: 0.001661
 >> iter 63000, loss: 0.001623
 >> iter 64000, loss: 0.001608
 >> iter 65000, loss: 0.001572
 >> iter 66000, loss: 0.001557
 >> iter 67000, loss: 0.001522
 >> iter 68000, loss: 0.001510
 >> iter 69000, loss: 0.001475
 >> iter 70000, loss: 0.001464
   Number of active neurons: 4
 >> iter 71000, loss: 0.001432
 >> iter 72000, loss: 0.001422
 >> iter 73000, loss: 0.001392
 >> iter 74000, loss: 0.001382
 >> iter 75000, loss: 0.001353
 >> iter 76000, loss: 0.001346
 >> iter 77000, loss: 0.001317
 >> iter 78000, loss: 0.001310
 >> iter 79000, loss: 0.001282
 >> iter 80000, loss: 0.001275
   Number of active neurons: 4
 >> iter 81000, loss: 0.001249
 >> iter 82000, loss: 0.001243
 >> iter 83000, loss: 0.001217
 >> iter 84000, loss: 0.001212
 >> iter 85000, loss: 0.001188
 >> iter 86000, loss: 0.001183
 >> iter 87000, loss: 0.001159
 >> iter 88000, loss: 0.001156
 >> iter 89000, loss: 0.001132
 >> iter 90000, loss: 0.001130
   Number of active neurons: 4
 >> iter 91000, loss: 0.001105
 >> iter 92000, loss: 0.001104
 >> iter 93000, loss: 0.001080
 >> iter 94000, loss: 0.001079
 >> iter 95000, loss: 0.001058
 >> iter 96000, loss: 0.001056
 >> iter 97000, loss: 0.001036
 >> iter 98000, loss: 0.001033
 >> iter 99000, loss: 0.001014
 >> iter 100000, loss: 0.001012
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 16.965535631
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.004037
 >> iter 2000, loss: 8.925147
 >> iter 3000, loss: 3.391344
 >> iter 4000, loss: 1.298573
 >> iter 5000, loss: 0.511080
 >> iter 6000, loss: 0.212658
 >> iter 7000, loss: 0.098421
 >> iter 8000, loss: 0.052632
 >> iter 9000, loss: 0.033800
 >> iter 10000, loss: 0.024731
   Number of active neurons: 4
 >> iter 11000, loss: 0.020259
 >> iter 12000, loss: 0.017279
 >> iter 13000, loss: 0.015431
 >> iter 14000, loss: 0.013860
 >> iter 15000, loss: 0.012757
 >> iter 16000, loss: 0.011696
 >> iter 17000, loss: 0.010926
 >> iter 18000, loss: 0.010141
 >> iter 19000, loss: 0.009560
 >> iter 20000, loss: 0.008952
   Number of active neurons: 4
 >> iter 21000, loss: 0.008508
 >> iter 22000, loss: 0.008021
 >> iter 23000, loss: 0.007663
 >> iter 24000, loss: 0.007262
 >> iter 25000, loss: 0.006967
 >> iter 26000, loss: 0.006633
 >> iter 27000, loss: 0.006383
 >> iter 28000, loss: 0.006102
 >> iter 29000, loss: 0.005891
 >> iter 30000, loss: 0.005654
   Number of active neurons: 4
 >> iter 31000, loss: 0.005474
 >> iter 32000, loss: 0.005263
 >> iter 33000, loss: 0.005107
 >> iter 34000, loss: 0.004926
 >> iter 35000, loss: 0.004787
 >> iter 36000, loss: 0.004630
 >> iter 37000, loss: 0.004507
 >> iter 38000, loss: 0.004365
 >> iter 39000, loss: 0.004257
 >> iter 40000, loss: 0.004129
   Number of active neurons: 4
 >> iter 41000, loss: 0.004031
 >> iter 42000, loss: 0.003916
 >> iter 43000, loss: 0.003828
 >> iter 44000, loss: 0.003726
 >> iter 45000, loss: 0.003650
 >> iter 46000, loss: 0.003551
 >> iter 47000, loss: 0.003481
 >> iter 48000, loss: 0.003397
 >> iter 49000, loss: 0.003327
 >> iter 50000, loss: 0.003250
   Number of active neurons: 4
 >> iter 51000, loss: 0.003187
 >> iter 52000, loss: 0.003118
 >> iter 53000, loss: 0.003060
 >> iter 54000, loss: 0.002995
 >> iter 55000, loss: 0.002940
 >> iter 56000, loss: 0.002881
 >> iter 57000, loss: 0.002834
 >> iter 58000, loss: 0.002776
 >> iter 59000, loss: 0.002730
 >> iter 60000, loss: 0.002679
   Number of active neurons: 4
 >> iter 61000, loss: 0.002636
 >> iter 62000, loss: 0.002586
 >> iter 63000, loss: 0.002548
 >> iter 64000, loss: 0.002503
 >> iter 65000, loss: 0.002467
 >> iter 66000, loss: 0.002424
 >> iter 67000, loss: 0.002391
 >> iter 68000, loss: 0.002350
 >> iter 69000, loss: 0.002316
 >> iter 70000, loss: 0.002280
   Number of active neurons: 4
 >> iter 71000, loss: 0.002247
 >> iter 72000, loss: 0.002213
 >> iter 73000, loss: 0.002183
 >> iter 74000, loss: 0.002150
 >> iter 75000, loss: 0.002122
 >> iter 76000, loss: 0.002093
 >> iter 77000, loss: 0.002063
 >> iter 78000, loss: 0.002037
 >> iter 79000, loss: 0.002008
 >> iter 80000, loss: 0.001983
   Number of active neurons: 4
 >> iter 81000, loss: 0.001955
 >> iter 82000, loss: 0.001933
 >> iter 83000, loss: 0.001906
 >> iter 84000, loss: 0.001884
 >> iter 85000, loss: 0.001860
 >> iter 86000, loss: 0.001839
 >> iter 87000, loss: 0.001814
 >> iter 88000, loss: 0.001797
 >> iter 89000, loss: 0.001771
 >> iter 90000, loss: 0.001756
   Number of active neurons: 4
 >> iter 91000, loss: 0.001729
 >> iter 92000, loss: 0.001715
 >> iter 93000, loss: 0.001690
 >> iter 94000, loss: 0.001676
 >> iter 95000, loss: 0.001655
 >> iter 96000, loss: 0.001639
 >> iter 97000, loss: 0.001619
 >> iter 98000, loss: 0.001604
 >> iter 99000, loss: 0.001587
 >> iter 100000, loss: 0.001569
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.963494
 >> iter 2000, loss: 9.628937
 >> iter 3000, loss: 3.712266
 >> iter 4000, loss: 1.409503
 >> iter 5000, loss: 0.545305
 >> iter 6000, loss: 0.221677
 >> iter 7000, loss: 0.096763
 >> iter 8000, loss: 0.114567
 >> iter 9000, loss: 0.053868
 >> iter 10000, loss: 0.029708
   Number of active neurons: 4
 >> iter 11000, loss: 0.019665
 >> iter 12000, loss: 0.014951
 >> iter 13000, loss: 0.012518
 >> iter 14000, loss: 0.010946
 >> iter 15000, loss: 0.009890
 >> iter 16000, loss: 0.009014
 >> iter 17000, loss: 0.008348
 >> iter 18000, loss: 0.007736
 >> iter 19000, loss: 0.007247
 >> iter 20000, loss: 0.006785
   Number of active neurons: 4
 >> iter 21000, loss: 0.006411
 >> iter 22000, loss: 0.006052
 >> iter 23000, loss: 0.005746
 >> iter 24000, loss: 0.005456
 >> iter 25000, loss: 0.005204
 >> iter 26000, loss: 0.004964
 >> iter 27000, loss: 0.004752
 >> iter 28000, loss: 0.004553
 >> iter 29000, loss: 0.004373
 >> iter 30000, loss: 0.004205
   Number of active neurons: 4
 >> iter 31000, loss: 0.004053
 >> iter 32000, loss: 0.003905
 >> iter 33000, loss: 0.003772
 >> iter 34000, loss: 0.003647
 >> iter 35000, loss: 0.003528
 >> iter 36000, loss: 0.003420
 >> iter 37000, loss: 0.003315
 >> iter 38000, loss: 0.003217
 >> iter 39000, loss: 0.003125
 >> iter 40000, loss: 0.003039
   Number of active neurons: 4
 >> iter 41000, loss: 0.002954
 >> iter 42000, loss: 0.002878
 >> iter 43000, loss: 0.002801
 >> iter 44000, loss: 0.002734
 >> iter 45000, loss: 0.002667
 >> iter 46000, loss: 0.002602
 >> iter 47000, loss: 0.002539
 >> iter 48000, loss: 0.002485
 >> iter 49000, loss: 0.002424
 >> iter 50000, loss: 0.002374
   Number of active neurons: 4
 >> iter 51000, loss: 0.002319
 >> iter 52000, loss: 0.002276
 >> iter 53000, loss: 0.002222
 >> iter 54000, loss: 0.002183
 >> iter 55000, loss: 0.002133
 >> iter 56000, loss: 0.002098
 >> iter 57000, loss: 0.002052
 >> iter 58000, loss: 0.002019
 >> iter 59000, loss: 0.001975
 >> iter 60000, loss: 0.001946
   Number of active neurons: 4
 >> iter 61000, loss: 0.001905
 >> iter 62000, loss: 0.001876
 >> iter 63000, loss: 0.001840
 >> iter 64000, loss: 0.001814
 >> iter 65000, loss: 0.001780
 >> iter 66000, loss: 0.001756
 >> iter 67000, loss: 0.001724
 >> iter 68000, loss: 0.001701
 >> iter 69000, loss: 0.001668
 >> iter 70000, loss: 0.001649
   Number of active neurons: 4
 >> iter 71000, loss: 0.001618
 >> iter 72000, loss: 0.001599
 >> iter 73000, loss: 0.001571
 >> iter 74000, loss: 0.001552
 >> iter 75000, loss: 0.001526
 >> iter 76000, loss: 0.001510
 >> iter 77000, loss: 0.001483
 >> iter 78000, loss: 0.001468
 >> iter 79000, loss: 0.001443
 >> iter 80000, loss: 0.001428
   Number of active neurons: 4
 >> iter 81000, loss: 0.001404
 >> iter 82000, loss: 0.001391
 >> iter 83000, loss: 0.001367
 >> iter 84000, loss: 0.001355
 >> iter 85000, loss: 0.001334
 >> iter 86000, loss: 0.001322
 >> iter 87000, loss: 0.001300
 >> iter 88000, loss: 0.001291
 >> iter 89000, loss: 0.001268
 >> iter 90000, loss: 0.001261
   Number of active neurons: 4
 >> iter 91000, loss: 0.001238
 >> iter 92000, loss: 0.001232
 >> iter 93000, loss: 0.001209
 >> iter 94000, loss: 0.001203
 >> iter 95000, loss: 0.001184
 >> iter 96000, loss: 0.001176
 >> iter 97000, loss: 0.001158
 >> iter 98000, loss: 0.001150
 >> iter 99000, loss: 0.001134
 >> iter 100000, loss: 0.001125
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.920566
 >> iter 2000, loss: 9.113945
 >> iter 3000, loss: 3.496461
 >> iter 4000, loss: 1.325133
 >> iter 5000, loss: 0.575867
 >> iter 6000, loss: 0.231125
 >> iter 7000, loss: 0.109545
 >> iter 8000, loss: 0.052838
 >> iter 9000, loss: 0.035868
 >> iter 10000, loss: 0.022376
   Number of active neurons: 4
 >> iter 11000, loss: 0.061701
 >> iter 12000, loss: 0.030745
 >> iter 13000, loss: 0.024607
 >> iter 14000, loss: 0.015577
 >> iter 15000, loss: 0.012276
 >> iter 16000, loss: 0.009852
 >> iter 17000, loss: 0.008574
 >> iter 18000, loss: 0.007668
 >> iter 19000, loss: 0.007155
 >> iter 20000, loss: 0.006580
   Number of active neurons: 4
 >> iter 21000, loss: 0.006249
 >> iter 22000, loss: 0.005823
 >> iter 23000, loss: 0.005577
 >> iter 24000, loss: 0.005234
 >> iter 25000, loss: 0.005033
 >> iter 26000, loss: 0.004750
 >> iter 27000, loss: 0.004577
 >> iter 28000, loss: 0.004345
 >> iter 29000, loss: 0.004190
 >> iter 30000, loss: 0.004002
   Number of active neurons: 4
 >> iter 31000, loss: 0.003869
 >> iter 32000, loss: 0.003712
 >> iter 33000, loss: 0.003630
 >> iter 34000, loss: 0.003475
 >> iter 35000, loss: 0.003384
 >> iter 36000, loss: 0.003262
 >> iter 37000, loss: 0.003174
 >> iter 38000, loss: 0.003057
 >> iter 39000, loss: 0.003014
 >> iter 40000, loss: 0.002945
   Number of active neurons: 4
 >> iter 41000, loss: 0.002856
 >> iter 42000, loss: 0.002753
 >> iter 43000, loss: 0.002681
 >> iter 44000, loss: 0.002601
 >> iter 45000, loss: 0.002548
 >> iter 46000, loss: 0.002474
 >> iter 47000, loss: 0.002435
 >> iter 48000, loss: 0.002370
 >> iter 49000, loss: 0.002326
 >> iter 50000, loss: 0.002264
   Number of active neurons: 4
 >> iter 51000, loss: 0.002243
 >> iter 52000, loss: 0.002241
 >> iter 53000, loss: 0.019539
 >> iter 54000, loss: 0.008654
 >> iter 55000, loss: 0.004697
 >> iter 56000, loss: 0.003085
 >> iter 57000, loss: 0.002434
 >> iter 58000, loss: 0.002161
 >> iter 59000, loss: 0.002029
 >> iter 60000, loss: 0.001958
   Number of active neurons: 4
 >> iter 61000, loss: 0.001902
 >> iter 62000, loss: 0.001861
 >> iter 63000, loss: 0.001823
 >> iter 64000, loss: 0.001789
 >> iter 65000, loss: 0.001756
 >> iter 66000, loss: 0.001725
 >> iter 67000, loss: 0.001695
 >> iter 68000, loss: 0.001667
 >> iter 69000, loss: 0.001637
 >> iter 70000, loss: 0.001613
   Number of active neurons: 4
 >> iter 71000, loss: 0.001586
 >> iter 72000, loss: 0.001561
 >> iter 73000, loss: 0.001537
 >> iter 74000, loss: 0.001514
 >> iter 75000, loss: 0.001492
 >> iter 76000, loss: 0.001472
 >> iter 77000, loss: 0.001449
 >> iter 78000, loss: 0.001430
 >> iter 79000, loss: 0.001408
 >> iter 80000, loss: 0.001390
   Number of active neurons: 4
 >> iter 81000, loss: 0.001370
 >> iter 82000, loss: 0.001353
 >> iter 83000, loss: 0.001335
 >> iter 84000, loss: 0.001317
 >> iter 85000, loss: 0.001303
 >> iter 86000, loss: 0.001285
 >> iter 87000, loss: 0.001271
 >> iter 88000, loss: 0.001255
 >> iter 89000, loss: 0.001240
 >> iter 90000, loss: 0.001227
   Number of active neurons: 4
 >> iter 91000, loss: 0.001211
 >> iter 92000, loss: 0.001199
 >> iter 93000, loss: 0.001183
 >> iter 94000, loss: 0.001171
 >> iter 95000, loss: 0.001158
 >> iter 96000, loss: 0.001145
 >> iter 97000, loss: 0.001133
 >> iter 98000, loss: 0.001120
 >> iter 99000, loss: 0.001110
 >> iter 100000, loss: 0.001096
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 4.57302846477
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.482153
 >> iter 2000, loss: 7.700504
 >> iter 3000, loss: 2.887073
 >> iter 4000, loss: 1.097318
 >> iter 5000, loss: 0.424898
 >> iter 6000, loss: 0.178278
 >> iter 7000, loss: 0.078950
 >> iter 8000, loss: 0.046667
 >> iter 9000, loss: 0.026964
 >> iter 10000, loss: 0.024519
   Number of active neurons: 4
 >> iter 11000, loss: 0.016791
 >> iter 12000, loss: 0.015159
 >> iter 13000, loss: 0.012011
 >> iter 14000, loss: 0.013456
 >> iter 15000, loss: 0.010450
 >> iter 16000, loss: 0.009167
 >> iter 17000, loss: 0.008052
 >> iter 18000, loss: 0.008775
 >> iter 19000, loss: 0.007551
 >> iter 20000, loss: 0.012658
   Number of active neurons: 4
 >> iter 21000, loss: 0.008537
 >> iter 22000, loss: 0.012463
 >> iter 23000, loss: 0.008157
 >> iter 24000, loss: 0.009752
 >> iter 25000, loss: 0.006819
 >> iter 26000, loss: 0.008589
 >> iter 27000, loss: 0.006153
 >> iter 28000, loss: 0.008871
 >> iter 29000, loss: 0.006092
 >> iter 30000, loss: 0.008460
   Number of active neurons: 4
 >> iter 31000, loss: 0.005801
 >> iter 32000, loss: 0.006669
 >> iter 33000, loss: 0.004935
 >> iter 34000, loss: 0.007335
 >> iter 35000, loss: 0.005068
 >> iter 36000, loss: 0.004095
 >> iter 37000, loss: 0.003592
 >> iter 38000, loss: 0.003341
 >> iter 39000, loss: 0.003146
 >> iter 40000, loss: 0.003011
   Number of active neurons: 4
 >> iter 41000, loss: 0.002880
 >> iter 42000, loss: 0.002784
 >> iter 43000, loss: 0.002682
 >> iter 44000, loss: 0.002604
 >> iter 45000, loss: 0.002522
 >> iter 46000, loss: 0.002452
 >> iter 47000, loss: 0.002380
 >> iter 48000, loss: 0.002323
 >> iter 49000, loss: 0.002258
 >> iter 50000, loss: 0.002206
   Number of active neurons: 4
 >> iter 51000, loss: 0.002149
 >> iter 52000, loss: 0.002106
 >> iter 53000, loss: 0.002052
 >> iter 54000, loss: 0.002014
 >> iter 55000, loss: 0.001965
 >> iter 56000, loss: 0.001930
 >> iter 57000, loss: 0.001887
 >> iter 58000, loss: 0.001854
 >> iter 59000, loss: 0.001814
 >> iter 60000, loss: 0.001786
   Number of active neurons: 4
 >> iter 61000, loss: 0.001748
 >> iter 62000, loss: 0.001722
 >> iter 63000, loss: 0.001688
 >> iter 64000, loss: 0.001665
 >> iter 65000, loss: 0.001633
 >> iter 66000, loss: 0.001611
 >> iter 67000, loss: 0.001580
 >> iter 68000, loss: 0.001560
 >> iter 69000, loss: 0.001530
 >> iter 70000, loss: 0.001513
   Number of active neurons: 4
 >> iter 71000, loss: 0.001485
 >> iter 72000, loss: 0.001467
 >> iter 73000, loss: 0.001443
 >> iter 74000, loss: 0.001425
 >> iter 75000, loss: 0.001402
 >> iter 76000, loss: 0.001387
 >> iter 77000, loss: 0.001362
 >> iter 78000, loss: 0.001349
 >> iter 79000, loss: 0.001326
 >> iter 80000, loss: 0.001313
   Number of active neurons: 4
 >> iter 81000, loss: 0.001292
 >> iter 82000, loss: 0.001280
 >> iter 83000, loss: 0.001259
 >> iter 84000, loss: 0.001247
 >> iter 85000, loss: 0.001229
 >> iter 86000, loss: 0.001217
 >> iter 87000, loss: 0.001199
 >> iter 88000, loss: 0.001189
 >> iter 89000, loss: 0.001170
 >> iter 90000, loss: 0.001162
   Number of active neurons: 4
 >> iter 91000, loss: 0.001143
 >> iter 92000, loss: 0.001135
 >> iter 93000, loss: 0.001117
 >> iter 94000, loss: 0.001109
 >> iter 95000, loss: 0.001094
 >> iter 96000, loss: 0.001085
 >> iter 97000, loss: 0.001071
 >> iter 98000, loss: 0.001062
 >> iter 99000, loss: 0.001049
 >> iter 100000, loss: 0.001039
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 17.6654889674
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.115916
 >> iter 2000, loss: 9.316357
 >> iter 3000, loss: 3.627331
 >> iter 4000, loss: 1.376588
 >> iter 5000, loss: 0.591507
 >> iter 6000, loss: 0.238768
 >> iter 7000, loss: 0.104339
 >> iter 8000, loss: 0.051837
 >> iter 9000, loss: 0.068430
 >> iter 10000, loss: 0.036025
   Number of active neurons: 4
 >> iter 11000, loss: 0.022545
 >> iter 12000, loss: 0.016423
 >> iter 13000, loss: 0.013411
 >> iter 14000, loss: 0.011577
 >> iter 15000, loss: 0.010403
 >> iter 16000, loss: 0.009460
 >> iter 17000, loss: 0.043238
 >> iter 18000, loss: 0.021229
 >> iter 19000, loss: 0.012734
 >> iter 20000, loss: 0.009227
   Number of active neurons: 4
 >> iter 21000, loss: 0.007704
 >> iter 22000, loss: 0.006872
 >> iter 23000, loss: 0.006379
 >> iter 24000, loss: 0.005987
 >> iter 25000, loss: 0.005689
 >> iter 26000, loss: 0.005408
 >> iter 27000, loss: 0.005176
 >> iter 28000, loss: 0.004948
 >> iter 29000, loss: 0.004758
 >> iter 30000, loss: 0.004566
   Number of active neurons: 4
 >> iter 31000, loss: 0.004407
 >> iter 32000, loss: 0.004238
 >> iter 33000, loss: 0.004102
 >> iter 34000, loss: 0.003960
 >> iter 35000, loss: 0.003837
 >> iter 36000, loss: 0.003712
 >> iter 37000, loss: 0.003604
 >> iter 38000, loss: 0.003492
 >> iter 39000, loss: 0.003398
 >> iter 40000, loss: 0.003300
   Number of active neurons: 4
 >> iter 41000, loss: 0.003215
 >> iter 42000, loss: 0.003128
 >> iter 43000, loss: 0.003050
 >> iter 44000, loss: 0.002973
 >> iter 45000, loss: 0.002904
 >> iter 46000, loss: 0.002830
 >> iter 47000, loss: 0.002767
 >> iter 48000, loss: 0.002702
 >> iter 49000, loss: 0.002646
 >> iter 50000, loss: 0.002587
   Number of active neurons: 4
 >> iter 51000, loss: 0.002531
 >> iter 52000, loss: 0.002479
 >> iter 53000, loss: 0.002426
 >> iter 54000, loss: 0.002378
 >> iter 55000, loss: 0.002330
 >> iter 56000, loss: 0.002287
 >> iter 57000, loss: 0.002244
 >> iter 58000, loss: 0.002203
 >> iter 59000, loss: 0.002161
 >> iter 60000, loss: 0.002124
   Number of active neurons: 4
 >> iter 61000, loss: 0.002086
 >> iter 62000, loss: 0.002049
 >> iter 63000, loss: 0.002016
 >> iter 64000, loss: 0.001983
 >> iter 65000, loss: 0.001952
 >> iter 66000, loss: 0.001920
 >> iter 67000, loss: 0.001891
 >> iter 68000, loss: 0.001861
 >> iter 69000, loss: 0.001831
 >> iter 70000, loss: 0.001804
   Number of active neurons: 4
 >> iter 71000, loss: 0.001777
 >> iter 72000, loss: 0.001751
 >> iter 73000, loss: 0.001727
 >> iter 74000, loss: 0.001700
 >> iter 75000, loss: 0.001679
 >> iter 76000, loss: 0.001655
 >> iter 77000, loss: 0.001632
 >> iter 78000, loss: 0.001609
 >> iter 79000, loss: 0.001589
 >> iter 80000, loss: 0.001566
   Number of active neurons: 4
 >> iter 81000, loss: 0.001547
 >> iter 82000, loss: 0.001527
 >> iter 83000, loss: 0.001508
 >> iter 84000, loss: 0.001488
 >> iter 85000, loss: 0.001471
 >> iter 86000, loss: 0.001453
 >> iter 87000, loss: 0.001435
 >> iter 88000, loss: 0.001420
 >> iter 89000, loss: 0.001401
 >> iter 90000, loss: 0.001388
   Number of active neurons: 4
 >> iter 91000, loss: 0.001368
 >> iter 92000, loss: 0.001355
 >> iter 93000, loss: 0.001338
 >> iter 94000, loss: 0.001325
 >> iter 95000, loss: 0.001310
 >> iter 96000, loss: 0.001296
 >> iter 97000, loss: 0.001281
 >> iter 98000, loss: 0.001267
 >> iter 99000, loss: 0.001256
 >> iter 100000, loss: 0.001241
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.499966668889
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.019100
 >> iter 2000, loss: 11.541070
 >> iter 3000, loss: 4.487400
 >> iter 4000, loss: 1.714797
 >> iter 5000, loss: 0.668347
 >> iter 6000, loss: 0.271261
 >> iter 7000, loss: 0.119476
 >> iter 8000, loss: 0.059254
 >> iter 9000, loss: 0.034723
 >> iter 10000, loss: 0.023361
   Number of active neurons: 4
 >> iter 11000, loss: 0.017893
 >> iter 12000, loss: 0.014460
 >> iter 13000, loss: 0.012448
 >> iter 14000, loss: 0.010813
 >> iter 15000, loss: 0.009768
 >> iter 16000, loss: 0.008784
 >> iter 17000, loss: 0.008142
 >> iter 18000, loss: 0.007474
 >> iter 19000, loss: 0.007035
 >> iter 20000, loss: 0.006544
   Number of active neurons: 4
 >> iter 21000, loss: 0.006228
 >> iter 22000, loss: 0.005847
 >> iter 23000, loss: 0.005603
 >> iter 24000, loss: 0.005294
 >> iter 25000, loss: 0.005101
 >> iter 26000, loss: 0.004843
 >> iter 27000, loss: 0.004686
 >> iter 28000, loss: 0.004466
 >> iter 29000, loss: 0.004337
 >> iter 30000, loss: 0.004147
   Number of active neurons: 4
 >> iter 31000, loss: 0.004041
 >> iter 32000, loss: 0.003871
 >> iter 33000, loss: 0.003782
 >> iter 34000, loss: 0.003632
 >> iter 35000, loss: 0.003554
 >> iter 36000, loss: 0.003423
 >> iter 37000, loss: 0.003354
 >> iter 38000, loss: 0.003234
 >> iter 39000, loss: 0.003176
 >> iter 40000, loss: 0.003069
   Number of active neurons: 4
 >> iter 41000, loss: 0.003015
 >> iter 42000, loss: 0.002918
 >> iter 43000, loss: 0.002870
 >> iter 44000, loss: 0.002781
 >> iter 45000, loss: 0.002740
 >> iter 46000, loss: 0.002656
 >> iter 47000, loss: 0.002619
 >> iter 48000, loss: 0.002542
 >> iter 49000, loss: 0.002509
 >> iter 50000, loss: 0.002437
   Number of active neurons: 4
 >> iter 51000, loss: 0.002407
 >> iter 52000, loss: 0.002343
 >> iter 53000, loss: 0.002314
 >> iter 54000, loss: 0.002253
 >> iter 55000, loss: 0.002227
 >> iter 56000, loss: 0.002171
 >> iter 57000, loss: 0.002148
 >> iter 58000, loss: 0.002094
 >> iter 59000, loss: 0.002073
 >> iter 60000, loss: 0.002023
   Number of active neurons: 4
 >> iter 61000, loss: 0.002003
 >> iter 62000, loss: 0.001955
 >> iter 63000, loss: 0.001938
 >> iter 64000, loss: 0.001893
 >> iter 65000, loss: 0.001879
 >> iter 66000, loss: 0.001836
 >> iter 67000, loss: 0.001822
 >> iter 68000, loss: 0.001781
 >> iter 69000, loss: 0.001767
 >> iter 70000, loss: 0.001729
   Number of active neurons: 4
 >> iter 71000, loss: 0.001716
 >> iter 72000, loss: 0.001679
 >> iter 73000, loss: 0.001669
 >> iter 74000, loss: 0.001633
 >> iter 75000, loss: 0.001624
 >> iter 76000, loss: 0.001591
 >> iter 77000, loss: 0.001580
 >> iter 78000, loss: 0.001550
 >> iter 79000, loss: 0.001539
 >> iter 80000, loss: 0.001510
   Number of active neurons: 4
 >> iter 81000, loss: 0.001500
 >> iter 82000, loss: 0.001472
 >> iter 83000, loss: 0.001463
 >> iter 84000, loss: 0.001436
 >> iter 85000, loss: 0.001429
 >> iter 86000, loss: 0.001404
 >> iter 87000, loss: 0.001395
 >> iter 88000, loss: 0.001372
 >> iter 89000, loss: 0.001362
 >> iter 90000, loss: 0.001342
   Number of active neurons: 4
 >> iter 91000, loss: 0.001332
 >> iter 92000, loss: 0.001311
 >> iter 93000, loss: 0.001303
 >> iter 94000, loss: 0.001282
 >> iter 95000, loss: 0.001276
 >> iter 96000, loss: 0.001255
 >> iter 97000, loss: 0.001249
 >> iter 98000, loss: 0.001228
 >> iter 99000, loss: 0.001225
 >> iter 100000, loss: 0.001203
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.669737
 >> iter 2000, loss: 10.507914
 >> iter 3000, loss: 4.084299
 >> iter 4000, loss: 1.603730
 >> iter 5000, loss: 0.627541
 >> iter 6000, loss: 0.259605
 >> iter 7000, loss: 0.115564
 >> iter 8000, loss: 0.061306
 >> iter 9000, loss: 0.035928
 >> iter 10000, loss: 0.028243
   Number of active neurons: 4
 >> iter 11000, loss: 0.024365
 >> iter 12000, loss: 0.019605
 >> iter 13000, loss: 0.019189
 >> iter 14000, loss: 0.014784
 >> iter 15000, loss: 0.012897
 >> iter 16000, loss: 0.012154
 >> iter 17000, loss: 0.010741
 >> iter 18000, loss: 0.009369
 >> iter 19000, loss: 0.008701
 >> iter 20000, loss: 0.007918
   Number of active neurons: 4
 >> iter 21000, loss: 0.007482
 >> iter 22000, loss: 0.008272
 >> iter 23000, loss: 0.007422
 >> iter 24000, loss: 0.139523
 >> iter 25000, loss: 0.056748
 >> iter 26000, loss: 0.025423
 >> iter 27000, loss: 0.013582
 >> iter 28000, loss: 0.008912
 >> iter 29000, loss: 0.007015
 >> iter 30000, loss: 0.006086
   Number of active neurons: 4
 >> iter 31000, loss: 0.005621
 >> iter 32000, loss: 0.005258
 >> iter 33000, loss: 0.005032
 >> iter 34000, loss: 0.004790
 >> iter 35000, loss: 0.004634
 >> iter 36000, loss: 0.004432
 >> iter 37000, loss: 0.004368
 >> iter 38000, loss: 0.004157
 >> iter 39000, loss: 0.004073
 >> iter 40000, loss: 0.003890
   Number of active neurons: 4
 >> iter 41000, loss: 0.060370
 >> iter 42000, loss: 0.024823
 >> iter 43000, loss: 0.012059
 >> iter 44000, loss: 0.006885
 >> iter 45000, loss: 0.004949
 >> iter 46000, loss: 0.004084
 >> iter 47000, loss: 0.003732
 >> iter 48000, loss: 0.003493
 >> iter 49000, loss: 0.003376
 >> iter 50000, loss: 0.003242
   Number of active neurons: 4
 >> iter 51000, loss: 0.003167
 >> iter 52000, loss: 0.003063
 >> iter 53000, loss: 0.003001
 >> iter 54000, loss: 0.002908
 >> iter 55000, loss: 0.002853
 >> iter 56000, loss: 0.002771
 >> iter 57000, loss: 0.002725
 >> iter 58000, loss: 0.002648
 >> iter 59000, loss: 0.002607
 >> iter 60000, loss: 0.002537
   Number of active neurons: 4
 >> iter 61000, loss: 0.002501
 >> iter 62000, loss: 0.002433
 >> iter 63000, loss: 0.002401
 >> iter 64000, loss: 0.002339
 >> iter 65000, loss: 0.002326
 >> iter 66000, loss: 0.002261
 >> iter 67000, loss: 0.002279
 >> iter 68000, loss: 0.002198
 >> iter 69000, loss: 0.002196
 >> iter 70000, loss: 0.002124
   Number of active neurons: 4
 >> iter 71000, loss: 0.002188
 >> iter 72000, loss: 0.002090
 >> iter 73000, loss: 0.002038
 >> iter 74000, loss: 0.001983
 >> iter 75000, loss: 0.002030
 >> iter 76000, loss: 0.001947
 >> iter 77000, loss: 0.001927
 >> iter 78000, loss: 0.001873
 >> iter 79000, loss: 0.001962
 >> iter 80000, loss: 0.001868
   Number of active neurons: 4
 >> iter 81000, loss: 0.001811
 >> iter 82000, loss: 0.001765
 >> iter 83000, loss: 0.001797
 >> iter 84000, loss: 0.001733
 >> iter 85000, loss: 0.001750
 >> iter 86000, loss: 0.001690
 >> iter 87000, loss: 0.002297
 >> iter 88000, loss: 0.001972
 >> iter 89000, loss: 0.005227
 >> iter 90000, loss: 0.002984
   Number of active neurons: 4
 >> iter 91000, loss: 0.002123
 >> iter 92000, loss: 0.001795
 >> iter 93000, loss: 0.001643
 >> iter 94000, loss: 0.001580
 >> iter 95000, loss: 0.001532
 >> iter 96000, loss: 0.001505
 >> iter 97000, loss: 0.001475
 >> iter 98000, loss: 0.001456
 >> iter 99000, loss: 0.001432
 >> iter 100000, loss: 0.001413
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 11.0925938271
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.566366
 >> iter 2000, loss: 7.799217
 >> iter 3000, loss: 2.926150
 >> iter 4000, loss: 1.119221
 >> iter 5000, loss: 0.434033
 >> iter 6000, loss: 0.178654
 >> iter 7000, loss: 0.079567
 >> iter 8000, loss: 0.043468
 >> iter 9000, loss: 0.026139
 >> iter 10000, loss: 0.021540
   Number of active neurons: 4
 >> iter 11000, loss: 0.015975
 >> iter 12000, loss: 0.016640
 >> iter 13000, loss: 0.012836
 >> iter 14000, loss: 0.014875
 >> iter 15000, loss: 0.011254
 >> iter 16000, loss: 0.013868
 >> iter 17000, loss: 0.010201
 >> iter 18000, loss: 0.013212
 >> iter 19000, loss: 0.009434
 >> iter 20000, loss: 0.012950
   Number of active neurons: 4
 >> iter 21000, loss: 0.008932
 >> iter 22000, loss: 0.012582
 >> iter 23000, loss: 0.008458
 >> iter 24000, loss: 0.012034
 >> iter 25000, loss: 0.007974
 >> iter 26000, loss: 0.010582
 >> iter 27000, loss: 0.007195
 >> iter 28000, loss: 0.006019
 >> iter 29000, loss: 0.005137
 >> iter 30000, loss: 0.004747
   Number of active neurons: 4
 >> iter 31000, loss: 0.004389
 >> iter 32000, loss: 0.004153
 >> iter 33000, loss: 0.003929
 >> iter 34000, loss: 0.006993
 >> iter 35000, loss: 0.021717
 >> iter 36000, loss: 0.010333
 >> iter 37000, loss: 0.005971
 >> iter 38000, loss: 0.004289
 >> iter 39000, loss: 0.003561
 >> iter 40000, loss: 0.003241
   Number of active neurons: 4
 >> iter 41000, loss: 0.003035
 >> iter 42000, loss: 0.002918
 >> iter 43000, loss: 0.002800
 >> iter 44000, loss: 0.002722
 >> iter 45000, loss: 0.002628
 >> iter 46000, loss: 0.002562
 >> iter 47000, loss: 0.002478
 >> iter 48000, loss: 0.002424
 >> iter 49000, loss: 0.002346
 >> iter 50000, loss: 0.002299
   Number of active neurons: 4
 >> iter 51000, loss: 0.002228
 >> iter 52000, loss: 0.002189
 >> iter 53000, loss: 0.002122
 >> iter 54000, loss: 0.002087
 >> iter 55000, loss: 0.002026
 >> iter 56000, loss: 0.001994
 >> iter 57000, loss: 0.001939
 >> iter 58000, loss: 0.001910
 >> iter 59000, loss: 0.001859
 >> iter 60000, loss: 0.001834
   Number of active neurons: 4
 >> iter 61000, loss: 0.001786
 >> iter 62000, loss: 0.001763
 >> iter 63000, loss: 0.001719
 >> iter 64000, loss: 0.001700
 >> iter 65000, loss: 0.001659
 >> iter 66000, loss: 0.001641
 >> iter 67000, loss: 0.001602
 >> iter 68000, loss: 0.001586
 >> iter 69000, loss: 0.001547
 >> iter 70000, loss: 0.001534
   Number of active neurons: 4
 >> iter 71000, loss: 0.001498
 >> iter 72000, loss: 0.001485
 >> iter 73000, loss: 0.001453
 >> iter 74000, loss: 0.001440
 >> iter 75000, loss: 0.001409
 >> iter 76000, loss: 0.001399
 >> iter 77000, loss: 0.001367
 >> iter 78000, loss: 0.001358
 >> iter 79000, loss: 0.001329
 >> iter 80000, loss: 0.001320
   Number of active neurons: 4
 >> iter 81000, loss: 0.001292
 >> iter 82000, loss: 0.001284
 >> iter 83000, loss: 0.001258
 >> iter 84000, loss: 0.001250
 >> iter 85000, loss: 0.001226
 >> iter 86000, loss: 0.001219
 >> iter 87000, loss: 0.001194
 >> iter 88000, loss: 0.001189
 >> iter 89000, loss: 0.001165
 >> iter 90000, loss: 0.001160
   Number of active neurons: 4
 >> iter 91000, loss: 0.001136
 >> iter 92000, loss: 0.001133
 >> iter 93000, loss: 0.001109
 >> iter 94000, loss: 0.001106
 >> iter 95000, loss: 0.001085
 >> iter 96000, loss: 0.001080
 >> iter 97000, loss: 0.001061
 >> iter 98000, loss: 0.001056
 >> iter 99000, loss: 0.001039
 >> iter 100000, loss: 0.001033
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 18.3854409706
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.847731
 >> iter 2000, loss: 9.098678
 >> iter 3000, loss: 3.515012
 >> iter 4000, loss: 1.344950
 >> iter 5000, loss: 0.529668
 >> iter 6000, loss: 0.220271
 >> iter 7000, loss: 0.101835
 >> iter 8000, loss: 0.054292
 >> iter 9000, loss: 0.034754
 >> iter 10000, loss: 0.025337
   Number of active neurons: 4
 >> iter 11000, loss: 0.020759
 >> iter 12000, loss: 0.017640
 >> iter 13000, loss: 0.015808
 >> iter 14000, loss: 0.014129
 >> iter 15000, loss: 0.013051
 >> iter 16000, loss: 0.011903
 >> iter 17000, loss: 0.011161
 >> iter 18000, loss: 0.010304
 >> iter 19000, loss: 0.009752
 >> iter 20000, loss: 0.009083
   Number of active neurons: 4
 >> iter 21000, loss: 0.008667
 >> iter 22000, loss: 0.008123
 >> iter 23000, loss: 0.007795
 >> iter 24000, loss: 0.007343
 >> iter 25000, loss: 0.007079
 >> iter 26000, loss: 0.006697
 >> iter 27000, loss: 0.006480
 >> iter 28000, loss: 0.006156
 >> iter 29000, loss: 0.005975
 >> iter 30000, loss: 0.005697
   Number of active neurons: 4
 >> iter 31000, loss: 0.005546
 >> iter 32000, loss: 0.005301
 >> iter 33000, loss: 0.005173
 >> iter 34000, loss: 0.004964
 >> iter 35000, loss: 0.004846
 >> iter 36000, loss: 0.004668
 >> iter 37000, loss: 0.004561
 >> iter 38000, loss: 0.004398
 >> iter 39000, loss: 0.004306
 >> iter 40000, loss: 0.004160
   Number of active neurons: 4
 >> iter 41000, loss: 0.004076
 >> iter 42000, loss: 0.003944
 >> iter 43000, loss: 0.003870
 >> iter 44000, loss: 0.003752
 >> iter 45000, loss: 0.003685
 >> iter 46000, loss: 0.003575
 >> iter 47000, loss: 0.003513
 >> iter 48000, loss: 0.003418
 >> iter 49000, loss: 0.003357
 >> iter 50000, loss: 0.003270
   Number of active neurons: 4
 >> iter 51000, loss: 0.003214
 >> iter 52000, loss: 0.003138
 >> iter 53000, loss: 0.003083
 >> iter 54000, loss: 0.003013
 >> iter 55000, loss: 0.002963
 >> iter 56000, loss: 0.002897
 >> iter 57000, loss: 0.002852
 >> iter 58000, loss: 0.002790
 >> iter 59000, loss: 0.002748
 >> iter 60000, loss: 0.002693
   Number of active neurons: 4
 >> iter 61000, loss: 0.002652
 >> iter 62000, loss: 0.002600
 >> iter 63000, loss: 0.002562
 >> iter 64000, loss: 0.002516
 >> iter 65000, loss: 0.002481
 >> iter 66000, loss: 0.002436
 >> iter 67000, loss: 0.002403
 >> iter 68000, loss: 0.002361
 >> iter 69000, loss: 0.002328
 >> iter 70000, loss: 0.002289
   Number of active neurons: 4
 >> iter 71000, loss: 0.002259
 >> iter 72000, loss: 0.002222
 >> iter 73000, loss: 0.002195
 >> iter 74000, loss: 0.002160
 >> iter 75000, loss: 0.002134
 >> iter 76000, loss: 0.002102
 >> iter 77000, loss: 0.002074
 >> iter 78000, loss: 0.002045
 >> iter 79000, loss: 0.002019
 >> iter 80000, loss: 0.001991
   Number of active neurons: 4
 >> iter 81000, loss: 0.001966
 >> iter 82000, loss: 0.001941
 >> iter 83000, loss: 0.001917
 >> iter 84000, loss: 0.001891
 >> iter 85000, loss: 0.001871
 >> iter 86000, loss: 0.001848
 >> iter 87000, loss: 0.001825
 >> iter 88000, loss: 0.001804
 >> iter 89000, loss: 0.001782
 >> iter 90000, loss: 0.001763
   Number of active neurons: 4
 >> iter 91000, loss: 0.001741
 >> iter 92000, loss: 0.001723
 >> iter 93000, loss: 0.001701
 >> iter 94000, loss: 0.001683
 >> iter 95000, loss: 0.001665
 >> iter 96000, loss: 0.001646
 >> iter 97000, loss: 0.001629
 >> iter 98000, loss: 0.001611
 >> iter 99000, loss: 0.001595
 >> iter 100000, loss: 0.001577
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.006961
 >> iter 2000, loss: 9.031713
 >> iter 3000, loss: 3.529346
 >> iter 4000, loss: 1.360808
 >> iter 5000, loss: 0.528104
 >> iter 6000, loss: 0.211666
 >> iter 7000, loss: 0.092513
 >> iter 8000, loss: 0.045761
 >> iter 9000, loss: 0.026575
 >> iter 10000, loss: 0.018150
   Number of active neurons: 4
 >> iter 11000, loss: 0.015007
 >> iter 12000, loss: 0.012458
 >> iter 13000, loss: 0.010728
 >> iter 14000, loss: 0.009489
 >> iter 15000, loss: 0.008623
 >> iter 16000, loss: 0.007895
 >> iter 17000, loss: 0.007327
 >> iter 18000, loss: 0.006809
 >> iter 19000, loss: 0.006394
 >> iter 20000, loss: 0.006003
   Number of active neurons: 4
 >> iter 21000, loss: 0.005679
 >> iter 22000, loss: 0.005370
 >> iter 23000, loss: 0.005110
 >> iter 24000, loss: 0.004864
 >> iter 25000, loss: 0.004643
 >> iter 26000, loss: 0.004436
 >> iter 27000, loss: 0.004255
 >> iter 28000, loss: 0.004081
 >> iter 29000, loss: 0.003926
 >> iter 30000, loss: 0.003778
   Number of active neurons: 4
 >> iter 31000, loss: 0.003648
 >> iter 32000, loss: 0.003517
 >> iter 33000, loss: 0.003403
 >> iter 34000, loss: 0.003292
 >> iter 35000, loss: 0.003191
 >> iter 36000, loss: 0.003094
 >> iter 37000, loss: 0.003004
 >> iter 38000, loss: 0.002916
 >> iter 39000, loss: 0.002837
 >> iter 40000, loss: 0.002761
   Number of active neurons: 4
 >> iter 41000, loss: 0.002688
 >> iter 42000, loss: 0.002619
 >> iter 43000, loss: 0.002553
 >> iter 44000, loss: 0.002493
 >> iter 45000, loss: 0.002434
 >> iter 46000, loss: 0.002376
 >> iter 47000, loss: 0.002323
 >> iter 48000, loss: 0.002272
 >> iter 49000, loss: 0.002221
 >> iter 50000, loss: 0.002174
   Number of active neurons: 4
 >> iter 51000, loss: 0.002128
 >> iter 52000, loss: 0.002087
 >> iter 53000, loss: 0.002043
 >> iter 54000, loss: 0.002005
 >> iter 55000, loss: 0.001963
 >> iter 56000, loss: 0.001929
 >> iter 57000, loss: 0.001892
 >> iter 58000, loss: 0.001859
 >> iter 59000, loss: 0.001823
 >> iter 60000, loss: 0.001794
   Number of active neurons: 4
 >> iter 61000, loss: 0.001761
 >> iter 62000, loss: 0.001732
 >> iter 63000, loss: 0.001703
 >> iter 64000, loss: 0.001676
 >> iter 65000, loss: 0.001649
 >> iter 66000, loss: 0.001624
 >> iter 67000, loss: 0.001598
 >> iter 68000, loss: 0.001575
 >> iter 69000, loss: 0.001548
 >> iter 70000, loss: 0.001528
   Number of active neurons: 4
 >> iter 71000, loss: 0.001504
 >> iter 72000, loss: 0.001483
 >> iter 73000, loss: 0.001461
 >> iter 74000, loss: 0.001441
 >> iter 75000, loss: 0.001421
 >> iter 76000, loss: 0.001403
 >> iter 77000, loss: 0.001383
 >> iter 78000, loss: 0.001365
 >> iter 79000, loss: 0.001347
 >> iter 80000, loss: 0.001329
   Number of active neurons: 4
 >> iter 81000, loss: 0.001311
 >> iter 82000, loss: 0.001296
 >> iter 83000, loss: 0.001278
 >> iter 84000, loss: 0.001263
 >> iter 85000, loss: 0.001248
 >> iter 86000, loss: 0.001234
 >> iter 87000, loss: 0.001218
 >> iter 88000, loss: 0.001206
 >> iter 89000, loss: 0.001189
 >> iter 90000, loss: 0.001179
   Number of active neurons: 4
 >> iter 91000, loss: 0.001161
 >> iter 92000, loss: 0.001152
 >> iter 93000, loss: 0.001135
 >> iter 94000, loss: 0.001126
 >> iter 95000, loss: 0.001112
 >> iter 96000, loss: 0.001102
 >> iter 97000, loss: 0.001088
 >> iter 98000, loss: 0.001078
 >> iter 99000, loss: 0.001067
 >> iter 100000, loss: 0.001056
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.899847
 >> iter 2000, loss: 7.285592
 >> iter 3000, loss: 2.884891
 >> iter 4000, loss: 1.119380
 >> iter 5000, loss: 0.515148
 >> iter 6000, loss: 0.209961
 >> iter 7000, loss: 0.173673
 >> iter 8000, loss: 0.078193
 >> iter 9000, loss: 0.116649
 >> iter 10000, loss: 0.054228
   Number of active neurons: 4
 >> iter 11000, loss: 0.113117
 >> iter 12000, loss: 0.051103
 >> iter 13000, loss: 0.103366
 >> iter 14000, loss: 0.046119
 >> iter 15000, loss: 0.024292
 >> iter 16000, loss: 0.015395
 >> iter 17000, loss: 0.011698
 >> iter 18000, loss: 0.009776
 >> iter 19000, loss: 0.008777
 >> iter 20000, loss: 0.007994
   Number of active neurons: 4
 >> iter 21000, loss: 0.007499
 >> iter 22000, loss: 0.006989
 >> iter 23000, loss: 0.006640
 >> iter 24000, loss: 0.006243
 >> iter 25000, loss: 0.005973
 >> iter 26000, loss: 0.005649
 >> iter 27000, loss: 0.005429
 >> iter 28000, loss: 0.005160
 >> iter 29000, loss: 0.004978
 >> iter 30000, loss: 0.004752
   Number of active neurons: 4
 >> iter 31000, loss: 0.004599
 >> iter 32000, loss: 0.004408
 >> iter 33000, loss: 0.004276
 >> iter 34000, loss: 0.004110
 >> iter 35000, loss: 0.003996
 >> iter 36000, loss: 0.003849
 >> iter 37000, loss: 0.003750
 >> iter 38000, loss: 0.003619
 >> iter 39000, loss: 0.003533
 >> iter 40000, loss: 0.003418
   Number of active neurons: 4
 >> iter 41000, loss: 0.003338
 >> iter 42000, loss: 0.003238
 >> iter 43000, loss: 0.003163
 >> iter 44000, loss: 0.003075
 >> iter 45000, loss: 0.003008
 >> iter 46000, loss: 0.002926
 >> iter 47000, loss: 0.002863
 >> iter 48000, loss: 0.002792
 >> iter 49000, loss: 0.002733
 >> iter 50000, loss: 0.002668
   Number of active neurons: 4
 >> iter 51000, loss: 0.002614
 >> iter 52000, loss: 0.002558
 >> iter 53000, loss: 0.002505
 >> iter 54000, loss: 0.002454
 >> iter 55000, loss: 0.002404
 >> iter 56000, loss: 0.002358
 >> iter 57000, loss: 0.002313
 >> iter 58000, loss: 0.002269
 >> iter 59000, loss: 0.002226
 >> iter 60000, loss: 0.002189
   Number of active neurons: 4
 >> iter 61000, loss: 0.002147
 >> iter 62000, loss: 0.002115
 >> iter 63000, loss: 0.002076
 >> iter 64000, loss: 0.002045
 >> iter 65000, loss: 0.002009
 >> iter 66000, loss: 0.001980
 >> iter 67000, loss: 0.001944
 >> iter 68000, loss: 0.001921
 >> iter 69000, loss: 0.001883
 >> iter 70000, loss: 0.001862
   Number of active neurons: 4
 >> iter 71000, loss: 0.001828
 >> iter 72000, loss: 0.001807
 >> iter 73000, loss: 0.001776
 >> iter 74000, loss: 0.001756
 >> iter 75000, loss: 0.001726
 >> iter 76000, loss: 0.001708
 >> iter 77000, loss: 0.001677
 >> iter 78000, loss: 0.001662
 >> iter 79000, loss: 0.001632
 >> iter 80000, loss: 0.001618
   Number of active neurons: 4
 >> iter 81000, loss: 0.001589
 >> iter 82000, loss: 0.001577
 >> iter 83000, loss: 0.001550
 >> iter 84000, loss: 0.001536
 >> iter 85000, loss: 0.001513
 >> iter 86000, loss: 0.001499
 >> iter 87000, loss: 0.001475
 >> iter 88000, loss: 0.001464
 >> iter 89000, loss: 0.001440
 >> iter 90000, loss: 0.001430
   Number of active neurons: 4
 >> iter 91000, loss: 0.001406
 >> iter 92000, loss: 0.001398
 >> iter 93000, loss: 0.001374
 >> iter 94000, loss: 0.001365
 >> iter 95000, loss: 0.001344
 >> iter 96000, loss: 0.001335
 >> iter 97000, loss: 0.001315
 >> iter 98000, loss: 0.001307
 >> iter 99000, loss: 0.001287
 >> iter 100000, loss: 0.001279
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0039999600004
   - Test - A: 0.0999933337777
   - Test - B: 10.959269382
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.797249
 >> iter 2000, loss: 10.750935
 >> iter 3000, loss: 4.458708
 >> iter 4000, loss: 1.780751
 >> iter 5000, loss: 0.719807
 >> iter 6000, loss: 0.306316
 >> iter 7000, loss: 0.144606
 >> iter 8000, loss: 0.079070
 >> iter 9000, loss: 0.051887
 >> iter 10000, loss: 0.038354
   Number of active neurons: 4
 >> iter 11000, loss: 0.031598
 >> iter 12000, loss: 0.029503
 >> iter 13000, loss: 0.023507
 >> iter 14000, loss: 0.022030
 >> iter 15000, loss: 0.028656
 >> iter 16000, loss: 0.019977
 >> iter 17000, loss: 0.015988
 >> iter 18000, loss: 0.015558
 >> iter 19000, loss: 0.013088
 >> iter 20000, loss: 0.014468
   Number of active neurons: 4
 >> iter 21000, loss: 0.011910
 >> iter 22000, loss: 0.013934
 >> iter 23000, loss: 0.011580
 >> iter 24000, loss: 0.012866
 >> iter 25000, loss: 0.010835
 >> iter 26000, loss: 0.013003
 >> iter 27000, loss: 0.011690
 >> iter 28000, loss: 0.012185
 >> iter 29000, loss: 0.010085
 >> iter 30000, loss: 0.008698
   Number of active neurons: 4
 >> iter 31000, loss: 0.007392
 >> iter 32000, loss: 0.010108
 >> iter 33000, loss: 0.007868
 >> iter 34000, loss: 0.009875
 >> iter 35000, loss: 0.007776
 >> iter 36000, loss: 0.010499
 >> iter 37000, loss: 0.010924
 >> iter 38000, loss: 0.011636
 >> iter 39000, loss: 0.008778
 >> iter 40000, loss: 0.006835
   Number of active neurons: 4
 >> iter 41000, loss: 0.006293
 >> iter 42000, loss: 0.005181
 >> iter 43000, loss: 0.005117
 >> iter 44000, loss: 0.008000
 >> iter 45000, loss: 0.005591
 >> iter 46000, loss: 0.008079
 >> iter 47000, loss: 0.005526
 >> iter 48000, loss: 0.008447
 >> iter 49000, loss: 0.006245
 >> iter 50000, loss: 0.008363
   Number of active neurons: 4
 >> iter 51000, loss: 0.005325
 >> iter 52000, loss: 0.008259
 >> iter 53000, loss: 0.005248
 >> iter 54000, loss: 0.008938
 >> iter 55000, loss: 0.005614
 >> iter 56000, loss: 0.009516
 >> iter 57000, loss: 0.062496
 >> iter 58000, loss: 0.025705
 >> iter 59000, loss: 0.013826
 >> iter 60000, loss: 0.012163
   Number of active neurons: 4
 >> iter 61000, loss: 0.010065
 >> iter 62000, loss: 0.006981
 >> iter 63000, loss: 0.005827
 >> iter 64000, loss: 0.011034
 >> iter 65000, loss: 0.007459
 >> iter 66000, loss: 0.011019
 >> iter 67000, loss: 0.007288
 >> iter 68000, loss: 0.010065
 >> iter 69000, loss: 0.007223
 >> iter 70000, loss: 0.007860
   Number of active neurons: 4
 >> iter 71000, loss: 0.005747
 >> iter 72000, loss: 0.004096
 >> iter 73000, loss: 0.006137
 >> iter 74000, loss: 0.004054
 >> iter 75000, loss: 0.004042
 >> iter 76000, loss: 0.003329
 >> iter 77000, loss: 0.003573
 >> iter 78000, loss: 0.003080
 >> iter 79000, loss: 0.003153
 >> iter 80000, loss: 0.002782
   Number of active neurons: 4
 >> iter 81000, loss: 0.002476
 >> iter 82000, loss: 0.004652
 >> iter 83000, loss: 0.003155
 >> iter 84000, loss: 0.002450
 >> iter 85000, loss: 0.002329
 >> iter 86000, loss: 0.002071
 >> iter 87000, loss: 0.001951
 >> iter 88000, loss: 0.002790
 >> iter 89000, loss: 0.002992
 >> iter 90000, loss: 0.002583
   Number of active neurons: 4
 >> iter 91000, loss: 0.002128
 >> iter 92000, loss: 0.001878
 >> iter 93000, loss: 0.001773
 >> iter 94000, loss: 0.001694
 >> iter 95000, loss: 0.001680
 >> iter 96000, loss: 0.001609
 >> iter 97000, loss: 0.001738
 >> iter 98000, loss: 0.001686
 >> iter 99000, loss: 0.001712
 >> iter 100000, loss: 0.001612
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.00799984000319
   - Test - Long: 0.0
   - Test - Big: 0.0039999600004
   - Test - A: 0.0
   - Test - B: 12.625824945
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.695046
 >> iter 2000, loss: 8.579672
 >> iter 3000, loss: 3.475157
 >> iter 4000, loss: 1.339601
 >> iter 5000, loss: 0.530419
 >> iter 6000, loss: 0.219882
 >> iter 7000, loss: 0.101054
 >> iter 8000, loss: 0.053061
 >> iter 9000, loss: 0.033031
 >> iter 10000, loss: 0.023677
   Number of active neurons: 4
 >> iter 11000, loss: 0.019002
 >> iter 12000, loss: 0.016080
 >> iter 13000, loss: 0.014214
 >> iter 14000, loss: 0.012727
 >> iter 15000, loss: 0.011628
 >> iter 16000, loss: 0.010646
 >> iter 17000, loss: 0.009890
 >> iter 18000, loss: 0.009173
 >> iter 19000, loss: 0.008609
 >> iter 20000, loss: 0.008057
   Number of active neurons: 4
 >> iter 21000, loss: 0.007630
 >> iter 22000, loss: 0.007185
 >> iter 23000, loss: 0.006848
 >> iter 24000, loss: 0.006481
 >> iter 25000, loss: 0.006206
 >> iter 26000, loss: 0.005899
 >> iter 27000, loss: 0.005670
 >> iter 28000, loss: 0.005413
 >> iter 29000, loss: 0.005219
 >> iter 30000, loss: 0.005002
   Number of active neurons: 4
 >> iter 31000, loss: 0.004839
 >> iter 32000, loss: 0.004648
 >> iter 33000, loss: 0.004508
 >> iter 34000, loss: 0.004344
 >> iter 35000, loss: 0.004219
 >> iter 36000, loss: 0.004077
 >> iter 37000, loss: 0.003966
 >> iter 38000, loss: 0.003839
 >> iter 39000, loss: 0.003742
 >> iter 40000, loss: 0.003627
   Number of active neurons: 4
 >> iter 41000, loss: 0.003540
 >> iter 42000, loss: 0.003437
 >> iter 43000, loss: 0.003358
 >> iter 44000, loss: 0.003267
 >> iter 45000, loss: 0.003197
 >> iter 46000, loss: 0.003110
 >> iter 47000, loss: 0.003045
 >> iter 48000, loss: 0.002971
 >> iter 49000, loss: 0.002908
 >> iter 50000, loss: 0.002841
   Number of active neurons: 4
 >> iter 51000, loss: 0.002783
 >> iter 52000, loss: 0.002725
 >> iter 53000, loss: 0.002670
 >> iter 54000, loss: 0.002616
 >> iter 55000, loss: 0.002564
 >> iter 56000, loss: 0.002514
 >> iter 57000, loss: 0.002467
 >> iter 58000, loss: 0.002420
 >> iter 59000, loss: 0.002375
 >> iter 60000, loss: 0.002335
   Number of active neurons: 4
 >> iter 61000, loss: 0.002292
 >> iter 62000, loss: 0.002254
 >> iter 63000, loss: 0.002214
 >> iter 64000, loss: 0.002180
 >> iter 65000, loss: 0.002143
 >> iter 66000, loss: 0.002109
 >> iter 67000, loss: 0.002074
 >> iter 68000, loss: 0.002043
 >> iter 69000, loss: 0.002009
 >> iter 70000, loss: 0.001981
   Number of active neurons: 4
 >> iter 71000, loss: 0.001950
 >> iter 72000, loss: 0.001923
 >> iter 73000, loss: 0.001894
 >> iter 74000, loss: 0.001868
 >> iter 75000, loss: 0.001840
 >> iter 76000, loss: 0.001818
 >> iter 77000, loss: 0.001788
 >> iter 78000, loss: 0.001768
 >> iter 79000, loss: 0.001741
 >> iter 80000, loss: 0.001721
   Number of active neurons: 4
 >> iter 81000, loss: 0.001695
 >> iter 82000, loss: 0.001677
 >> iter 83000, loss: 0.001653
 >> iter 84000, loss: 0.001634
 >> iter 85000, loss: 0.001612
 >> iter 86000, loss: 0.001595
 >> iter 87000, loss: 0.001573
 >> iter 88000, loss: 0.001557
 >> iter 89000, loss: 0.001535
 >> iter 90000, loss: 0.001521
   Number of active neurons: 4
 >> iter 91000, loss: 0.001499
 >> iter 92000, loss: 0.001486
 >> iter 93000, loss: 0.001465
 >> iter 94000, loss: 0.001452
 >> iter 95000, loss: 0.001433
 >> iter 96000, loss: 0.001420
 >> iter 97000, loss: 0.001402
 >> iter 98000, loss: 0.001389
 >> iter 99000, loss: 0.001372
 >> iter 100000, loss: 0.001360
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0229997700023
   - Test - A: 0.0
   - Test - B: 7.14619025398
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.726990
 >> iter 2000, loss: 8.876700
 >> iter 3000, loss: 3.546953
 >> iter 4000, loss: 1.400842
 >> iter 5000, loss: 0.557400
 >> iter 6000, loss: 0.235550
 >> iter 7000, loss: 0.109952
 >> iter 8000, loss: 0.059363
 >> iter 9000, loss: 0.037853
 >> iter 10000, loss: 0.027642
   Number of active neurons: 4
 >> iter 11000, loss: 0.022306
 >> iter 12000, loss: 0.018947
 >> iter 13000, loss: 0.016716
 >> iter 14000, loss: 0.014962
 >> iter 15000, loss: 0.013625
 >> iter 16000, loss: 0.012464
 >> iter 17000, loss: 0.011536
 >> iter 18000, loss: 0.010691
 >> iter 19000, loss: 0.009998
 >> iter 20000, loss: 0.009352
   Number of active neurons: 4
 >> iter 21000, loss: 0.008824
 >> iter 22000, loss: 0.008307
 >> iter 23000, loss: 0.007887
 >> iter 24000, loss: 0.007465
 >> iter 25000, loss: 0.007121
 >> iter 26000, loss: 0.006772
 >> iter 27000, loss: 0.006482
 >> iter 28000, loss: 0.006191
 >> iter 29000, loss: 0.005946
 >> iter 30000, loss: 0.005702
   Number of active neurons: 4
 >> iter 31000, loss: 0.005495
 >> iter 32000, loss: 0.005284
 >> iter 33000, loss: 0.005103
 >> iter 34000, loss: 0.004922
 >> iter 35000, loss: 0.004763
 >> iter 36000, loss: 0.004607
 >> iter 37000, loss: 0.004469
 >> iter 38000, loss: 0.004327
 >> iter 39000, loss: 0.004205
 >> iter 40000, loss: 0.004080
   Number of active neurons: 4
 >> iter 41000, loss: 0.003969
 >> iter 42000, loss: 0.003859
 >> iter 43000, loss: 0.003757
 >> iter 44000, loss: 0.003660
 >> iter 45000, loss: 0.003569
 >> iter 46000, loss: 0.003478
 >> iter 47000, loss: 0.003394
 >> iter 48000, loss: 0.003317
 >> iter 49000, loss: 0.003236
 >> iter 50000, loss: 0.003166
   Number of active neurons: 4
 >> iter 51000, loss: 0.003092
 >> iter 52000, loss: 0.003032
 >> iter 53000, loss: 0.002961
 >> iter 54000, loss: 0.002906
 >> iter 55000, loss: 0.002839
 >> iter 56000, loss: 0.002789
 >> iter 57000, loss: 0.002728
 >> iter 58000, loss: 0.002681
 >> iter 59000, loss: 0.002624
 >> iter 60000, loss: 0.002584
   Number of active neurons: 4
 >> iter 61000, loss: 0.002528
 >> iter 62000, loss: 0.002490
 >> iter 63000, loss: 0.002441
 >> iter 64000, loss: 0.002406
 >> iter 65000, loss: 0.002360
 >> iter 66000, loss: 0.002326
 >> iter 67000, loss: 0.002282
 >> iter 68000, loss: 0.002252
 >> iter 69000, loss: 0.002208
 >> iter 70000, loss: 0.002182
   Number of active neurons: 4
 >> iter 71000, loss: 0.002141
 >> iter 72000, loss: 0.002115
 >> iter 73000, loss: 0.002077
 >> iter 74000, loss: 0.002053
 >> iter 75000, loss: 0.002017
 >> iter 76000, loss: 0.001995
 >> iter 77000, loss: 0.001958
 >> iter 78000, loss: 0.001939
 >> iter 79000, loss: 0.001905
 >> iter 80000, loss: 0.001885
   Number of active neurons: 4
 >> iter 81000, loss: 0.001853
 >> iter 82000, loss: 0.001836
 >> iter 83000, loss: 0.001805
 >> iter 84000, loss: 0.001787
 >> iter 85000, loss: 0.001759
 >> iter 86000, loss: 0.001743
 >> iter 87000, loss: 0.001715
 >> iter 88000, loss: 0.001701
 >> iter 89000, loss: 0.001672
 >> iter 90000, loss: 0.001661
   Number of active neurons: 4
 >> iter 91000, loss: 0.001632
 >> iter 92000, loss: 0.001621
 >> iter 93000, loss: 0.001594
 >> iter 94000, loss: 0.001583
 >> iter 95000, loss: 0.001558
 >> iter 96000, loss: 0.001546
 >> iter 97000, loss: 0.001523
 >> iter 98000, loss: 0.001512
 >> iter 99000, loss: 0.001491
 >> iter 100000, loss: 0.001479
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 16.8988734084
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.958478
 >> iter 2000, loss: 8.085499
 >> iter 3000, loss: 3.102216
 >> iter 4000, loss: 1.178243
 >> iter 5000, loss: 0.458342
 >> iter 6000, loss: 0.192470
 >> iter 7000, loss: 0.085947
 >> iter 8000, loss: 0.049897
 >> iter 9000, loss: 0.033558
 >> iter 10000, loss: 0.021863
   Number of active neurons: 4
 >> iter 11000, loss: 0.016600
 >> iter 12000, loss: 0.013637
 >> iter 13000, loss: 0.016608
 >> iter 14000, loss: 0.012434
 >> iter 15000, loss: 0.010483
 >> iter 16000, loss: 0.009221
 >> iter 17000, loss: 0.008489
 >> iter 18000, loss: 0.007811
 >> iter 19000, loss: 0.007358
 >> iter 20000, loss: 0.006871
   Number of active neurons: 4
 >> iter 21000, loss: 0.022166
 >> iter 22000, loss: 0.012124
 >> iter 23000, loss: 0.008210
 >> iter 24000, loss: 0.006550
 >> iter 25000, loss: 0.005809
 >> iter 26000, loss: 0.005354
 >> iter 27000, loss: 0.005065
 >> iter 28000, loss: 0.004812
 >> iter 29000, loss: 0.004639
 >> iter 30000, loss: 0.004441
   Number of active neurons: 4
 >> iter 31000, loss: 0.004285
 >> iter 32000, loss: 0.004113
 >> iter 33000, loss: 0.003992
 >> iter 34000, loss: 0.003848
 >> iter 35000, loss: 0.003733
 >> iter 36000, loss: 0.003606
 >> iter 37000, loss: 0.003505
 >> iter 38000, loss: 0.003399
 >> iter 39000, loss: 0.003312
 >> iter 40000, loss: 0.003210
   Number of active neurons: 4
 >> iter 41000, loss: 0.003132
 >> iter 42000, loss: 0.003157
 >> iter 43000, loss: 0.003060
 >> iter 44000, loss: 0.002951
 >> iter 45000, loss: 0.002870
 >> iter 46000, loss: 0.002800
 >> iter 47000, loss: 0.002730
 >> iter 48000, loss: 0.002653
 >> iter 49000, loss: 0.002598
 >> iter 50000, loss: 0.002534
   Number of active neurons: 4
 >> iter 51000, loss: 0.002485
 >> iter 52000, loss: 0.002428
 >> iter 53000, loss: 0.002382
 >> iter 54000, loss: 0.002331
 >> iter 55000, loss: 0.002289
 >> iter 56000, loss: 0.002241
 >> iter 57000, loss: 0.002203
 >> iter 58000, loss: 0.002159
 >> iter 59000, loss: 0.002123
 >> iter 60000, loss: 0.002081
   Number of active neurons: 4
 >> iter 61000, loss: 0.002049
 >> iter 62000, loss: 0.002009
 >> iter 63000, loss: 0.001982
 >> iter 64000, loss: 0.001943
 >> iter 65000, loss: 0.001918
 >> iter 66000, loss: 0.001883
 >> iter 67000, loss: 0.001859
 >> iter 68000, loss: 0.001825
 >> iter 69000, loss: 0.001801
 >> iter 70000, loss: 0.001770
   Number of active neurons: 4
 >> iter 71000, loss: 0.001749
 >> iter 72000, loss: 0.001718
 >> iter 73000, loss: 0.001700
 >> iter 74000, loss: 0.001668
 >> iter 75000, loss: 0.001652
 >> iter 76000, loss: 0.001625
 >> iter 77000, loss: 0.001608
 >> iter 78000, loss: 0.001580
 >> iter 79000, loss: 0.001565
 >> iter 80000, loss: 0.001537
   Number of active neurons: 4
 >> iter 81000, loss: 0.001524
 >> iter 82000, loss: 0.001499
 >> iter 83000, loss: 0.001485
 >> iter 84000, loss: 0.001461
 >> iter 85000, loss: 0.001450
 >> iter 86000, loss: 0.001428
 >> iter 87000, loss: 0.001415
 >> iter 88000, loss: 0.001395
 >> iter 89000, loss: 0.001381
 >> iter 90000, loss: 0.001364
   Number of active neurons: 4
 >> iter 91000, loss: 0.001348
 >> iter 92000, loss: 0.001332
 >> iter 93000, loss: 0.001318
 >> iter 94000, loss: 0.001302
 >> iter 95000, loss: 0.001292
 >> iter 96000, loss: 0.001273
 >> iter 97000, loss: 0.001263
 >> iter 98000, loss: 0.001246
 >> iter 99000, loss: 0.001239
 >> iter 100000, loss: 0.001219
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.995691
 >> iter 2000, loss: 9.646266
 >> iter 3000, loss: 3.788865
 >> iter 4000, loss: 1.449509
 >> iter 5000, loss: 0.607002
 >> iter 6000, loss: 0.248402
 >> iter 7000, loss: 0.111686
 >> iter 8000, loss: 0.056788
 >> iter 9000, loss: 0.034599
 >> iter 10000, loss: 0.024245
   Number of active neurons: 4
 >> iter 11000, loss: 0.019274
 >> iter 12000, loss: 0.016229
 >> iter 13000, loss: 0.014370
 >> iter 14000, loss: 0.012864
 >> iter 15000, loss: 0.011794
 >> iter 16000, loss: 0.010804
 >> iter 17000, loss: 0.010071
 >> iter 18000, loss: 0.009345
 >> iter 19000, loss: 0.008800
 >> iter 20000, loss: 0.008237
   Number of active neurons: 4
 >> iter 21000, loss: 0.007823
 >> iter 22000, loss: 0.007367
 >> iter 23000, loss: 0.007041
 >> iter 24000, loss: 0.006663
 >> iter 25000, loss: 0.006397
 >> iter 26000, loss: 0.006080
 >> iter 27000, loss: 0.005857
 >> iter 28000, loss: 0.005591
 >> iter 29000, loss: 0.005402
 >> iter 30000, loss: 0.005176
   Number of active neurons: 4
 >> iter 31000, loss: 0.005016
 >> iter 32000, loss: 0.004819
 >> iter 33000, loss: 0.004680
 >> iter 34000, loss: 0.004511
 >> iter 35000, loss: 0.004386
 >> iter 36000, loss: 0.004238
 >> iter 37000, loss: 0.004129
 >> iter 38000, loss: 0.003996
 >> iter 39000, loss: 0.003900
 >> iter 40000, loss: 0.003780
   Number of active neurons: 4
 >> iter 41000, loss: 0.003693
 >> iter 42000, loss: 0.003586
 >> iter 43000, loss: 0.003507
 >> iter 44000, loss: 0.003412
 >> iter 45000, loss: 0.003340
 >> iter 46000, loss: 0.003252
 >> iter 47000, loss: 0.003185
 >> iter 48000, loss: 0.003109
 >> iter 49000, loss: 0.003044
 >> iter 50000, loss: 0.002975
   Number of active neurons: 4
 >> iter 51000, loss: 0.002915
 >> iter 52000, loss: 0.002855
 >> iter 53000, loss: 0.002797
 >> iter 54000, loss: 0.002742
 >> iter 55000, loss: 0.002688
 >> iter 56000, loss: 0.002637
 >> iter 57000, loss: 0.002588
 >> iter 58000, loss: 0.002541
 >> iter 59000, loss: 0.002494
 >> iter 60000, loss: 0.002453
   Number of active neurons: 4
 >> iter 61000, loss: 0.002407
 >> iter 62000, loss: 0.002369
 >> iter 63000, loss: 0.002327
 >> iter 64000, loss: 0.002293
 >> iter 65000, loss: 0.002253
 >> iter 66000, loss: 0.002220
 >> iter 67000, loss: 0.002183
 >> iter 68000, loss: 0.002152
 >> iter 69000, loss: 0.002115
 >> iter 70000, loss: 0.002088
   Number of active neurons: 4
 >> iter 71000, loss: 0.002053
 >> iter 72000, loss: 0.002027
 >> iter 73000, loss: 0.001995
 >> iter 74000, loss: 0.001970
 >> iter 75000, loss: 0.001939
 >> iter 76000, loss: 0.001917
 >> iter 77000, loss: 0.001885
 >> iter 78000, loss: 0.001866
 >> iter 79000, loss: 0.001835
 >> iter 80000, loss: 0.001817
   Number of active neurons: 4
 >> iter 81000, loss: 0.001788
 >> iter 82000, loss: 0.001771
 >> iter 83000, loss: 0.001744
 >> iter 84000, loss: 0.001726
 >> iter 85000, loss: 0.001702
 >> iter 86000, loss: 0.001685
 >> iter 87000, loss: 0.001660
 >> iter 88000, loss: 0.001646
 >> iter 89000, loss: 0.001621
 >> iter 90000, loss: 0.001609
   Number of active neurons: 4
 >> iter 91000, loss: 0.001584
 >> iter 92000, loss: 0.001572
 >> iter 93000, loss: 0.001548
 >> iter 94000, loss: 0.001537
 >> iter 95000, loss: 0.001515
 >> iter 96000, loss: 0.001503
 >> iter 97000, loss: 0.001482
 >> iter 98000, loss: 0.001471
 >> iter 99000, loss: 0.001452
 >> iter 100000, loss: 0.001440
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 17.8988067462
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.835965
 >> iter 2000, loss: 9.720024
 >> iter 3000, loss: 3.915876
 >> iter 4000, loss: 1.508646
 >> iter 5000, loss: 0.817355
 >> iter 6000, loss: 0.332569
 >> iter 7000, loss: 0.350666
 >> iter 8000, loss: 0.150348
 >> iter 9000, loss: 0.258566
 >> iter 10000, loss: 0.111177
   Number of active neurons: 4
 >> iter 11000, loss: 0.252132
 >> iter 12000, loss: 0.109527
 >> iter 13000, loss: 0.148304
 >> iter 14000, loss: 0.066512
 >> iter 15000, loss: 0.226048
 >> iter 16000, loss: 0.096612
 >> iter 17000, loss: 0.045498
 >> iter 18000, loss: 0.025305
 >> iter 19000, loss: 0.198379
 >> iter 20000, loss: 0.082031
   Number of active neurons: 4
 >> iter 21000, loss: 0.122718
 >> iter 22000, loss: 0.054322
 >> iter 23000, loss: 0.027370
 >> iter 24000, loss: 0.016708
 >> iter 25000, loss: 0.012228
 >> iter 26000, loss: 0.010072
 >> iter 27000, loss: 0.008895
 >> iter 28000, loss: 0.008099
 >> iter 29000, loss: 0.276012
 >> iter 30000, loss: 0.214824
   Number of active neurons: 4
 >> iter 31000, loss: 0.089779
 >> iter 32000, loss: 0.038228
 >> iter 33000, loss: 0.050614
 >> iter 34000, loss: 0.023457
 >> iter 35000, loss: 0.013012
 >> iter 36000, loss: 0.008857
 >> iter 37000, loss: 0.007108
 >> iter 38000, loss: 0.006254
 >> iter 39000, loss: 0.005782
 >> iter 40000, loss: 0.005447
   Number of active neurons: 4
 >> iter 41000, loss: 0.005195
 >> iter 42000, loss: 0.004973
 >> iter 43000, loss: 0.004783
 >> iter 44000, loss: 0.004609
 >> iter 45000, loss: 0.004453
 >> iter 46000, loss: 0.004300
 >> iter 47000, loss: 0.004164
 >> iter 48000, loss: 0.004038
 >> iter 49000, loss: 0.003914
 >> iter 50000, loss: 0.003805
   Number of active neurons: 4
 >> iter 51000, loss: 0.003693
 >> iter 52000, loss: 0.003601
 >> iter 53000, loss: 0.003498
 >> iter 54000, loss: 0.003416
 >> iter 55000, loss: 0.003323
 >> iter 56000, loss: 0.003252
 >> iter 57000, loss: 0.003168
 >> iter 58000, loss: 0.003103
 >> iter 59000, loss: 0.003025
 >> iter 60000, loss: 0.002968
   Number of active neurons: 4
 >> iter 61000, loss: 0.002896
 >> iter 62000, loss: 0.002843
 >> iter 63000, loss: 0.002778
 >> iter 64000, loss: 0.002733
 >> iter 65000, loss: 0.002672
 >> iter 66000, loss: 0.002629
 >> iter 67000, loss: 0.002573
 >> iter 68000, loss: 0.002534
 >> iter 69000, loss: 0.002479
 >> iter 70000, loss: 0.002445
   Number of active neurons: 4
 >> iter 71000, loss: 0.002393
 >> iter 72000, loss: 0.002361
 >> iter 73000, loss: 0.002313
 >> iter 74000, loss: 0.002284
 >> iter 75000, loss: 0.002239
 >> iter 76000, loss: 0.002213
 >> iter 77000, loss: 0.002168
 >> iter 78000, loss: 0.002145
 >> iter 79000, loss: 0.002102
 >> iter 80000, loss: 0.002080
   Number of active neurons: 4
 >> iter 81000, loss: 0.002040
 >> iter 82000, loss: 0.002021
 >> iter 83000, loss: 0.001982
 >> iter 84000, loss: 0.001963
 >> iter 85000, loss: 0.001928
 >> iter 86000, loss: 0.001911
 >> iter 87000, loss: 0.001875
 >> iter 88000, loss: 0.001862
 >> iter 89000, loss: 0.001825
 >> iter 90000, loss: 0.001815
   Number of active neurons: 4
 >> iter 91000, loss: 0.001778
 >> iter 92000, loss: 0.001769
 >> iter 93000, loss: 0.001734
 >> iter 94000, loss: 0.001724
 >> iter 95000, loss: 0.001693
 >> iter 96000, loss: 0.001682
 >> iter 97000, loss: 0.001653
 >> iter 98000, loss: 0.001643
 >> iter 99000, loss: 0.001616
 >> iter 100000, loss: 0.001605
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

