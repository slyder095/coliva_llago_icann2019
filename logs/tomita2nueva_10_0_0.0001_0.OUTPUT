 > Problema: tomita2nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.821715
 >> iter 2000, loss: 4.008923
 >> iter 3000, loss: 1.495634
 >> iter 4000, loss: 0.568277
 >> iter 5000, loss: 0.226882
 >> iter 6000, loss: 0.100318
 >> iter 7000, loss: 0.054006
 >> iter 8000, loss: 0.036148
 >> iter 9000, loss: 0.029890
 >> iter 10000, loss: 0.027037
   Number of active neurons: 3
 >> iter 11000, loss: 0.026242
 >> iter 12000, loss: 0.025243
 >> iter 13000, loss: 0.025083
 >> iter 14000, loss: 0.024317
 >> iter 15000, loss: 0.024138
 >> iter 16000, loss: 0.023271
 >> iter 17000, loss: 0.023140
 >> iter 18000, loss: 0.022439
 >> iter 19000, loss: 0.022433
 >> iter 20000, loss: 0.021800
   Number of active neurons: 3
 >> iter 21000, loss: 0.021812
 >> iter 22000, loss: 0.021249
 >> iter 23000, loss: 0.021298
 >> iter 24000, loss: 0.020825
 >> iter 25000, loss: 0.020978
 >> iter 26000, loss: 0.020587
 >> iter 27000, loss: 0.020796
 >> iter 28000, loss: 0.020436
 >> iter 29000, loss: 0.020559
 >> iter 30000, loss: 0.020092
   Number of active neurons: 2
 >> iter 31000, loss: 0.020169
 >> iter 32000, loss: 0.019738
 >> iter 33000, loss: 0.019812
 >> iter 34000, loss: 0.019332
 >> iter 35000, loss: 0.019245
 >> iter 36000, loss: 0.018744
 >> iter 37000, loss: 0.018647
 >> iter 38000, loss: 0.018140
 >> iter 39000, loss: 0.017964
 >> iter 40000, loss: 0.017469
   Number of active neurons: 2
 >> iter 41000, loss: 0.017337
 >> iter 42000, loss: 0.016953
 >> iter 43000, loss: 0.016927
 >> iter 44000, loss: 0.016646
 >> iter 45000, loss: 0.016671
 >> iter 46000, loss: 0.016429
 >> iter 47000, loss: 0.016493
 >> iter 48000, loss: 0.016274
 >> iter 49000, loss: 0.016365
 >> iter 50000, loss: 0.016155
   Number of active neurons: 2
 >> iter 51000, loss: 0.016253
 >> iter 52000, loss: 0.016073
 >> iter 53000, loss: 0.016157
 >> iter 54000, loss: 0.016006
 >> iter 55000, loss: 0.016088
 >> iter 56000, loss: 0.015942
 >> iter 57000, loss: 0.016021
 >> iter 58000, loss: 0.015886
 >> iter 59000, loss: 0.015968
 >> iter 60000, loss: 0.015839
   Number of active neurons: 2
 >> iter 61000, loss: 0.015940
 >> iter 62000, loss: 0.015797
 >> iter 63000, loss: 0.015890
 >> iter 64000, loss: 0.015765
 >> iter 65000, loss: 0.015851
 >> iter 66000, loss: 0.015736
 >> iter 67000, loss: 0.015820
 >> iter 68000, loss: 0.015718
 >> iter 69000, loss: 0.015784
 >> iter 70000, loss: 0.015692
   Number of active neurons: 2
 >> iter 71000, loss: 0.015753
 >> iter 72000, loss: 0.015665
 >> iter 73000, loss: 0.015745
 >> iter 74000, loss: 0.015652
 >> iter 75000, loss: 0.015724
 >> iter 76000, loss: 0.015638
 >> iter 77000, loss: 0.015705
 >> iter 78000, loss: 0.015619
 >> iter 79000, loss: 0.015689
 >> iter 80000, loss: 0.015598
   Number of active neurons: 2
 >> iter 81000, loss: 0.015675
 >> iter 82000, loss: 0.015584
 >> iter 83000, loss: 0.015662
 >> iter 84000, loss: 0.015579
 >> iter 85000, loss: 0.015644
 >> iter 86000, loss: 0.015566
 >> iter 87000, loss: 0.015629
 >> iter 88000, loss: 0.015570
 >> iter 89000, loss: 0.015624
 >> iter 90000, loss: 0.015560
   Number of active neurons: 2
 >> iter 91000, loss: 0.015609
 >> iter 92000, loss: 0.015559
 >> iter 93000, loss: 0.015609
 >> iter 94000, loss: 0.015553
 >> iter 95000, loss: 0.015610
 >> iter 96000, loss: 0.015549
 >> iter 97000, loss: 0.015606
 >> iter 98000, loss: 0.015542
 >> iter 99000, loss: 0.015602
 >> iter 100000, loss: 0.015545
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.945731
 >> iter 2000, loss: 4.054164
 >> iter 3000, loss: 1.512054
 >> iter 4000, loss: 0.574555
 >> iter 5000, loss: 0.229349
 >> iter 6000, loss: 0.101305
 >> iter 7000, loss: 0.054342
 >> iter 8000, loss: 0.036237
 >> iter 9000, loss: 0.029828
 >> iter 10000, loss: 0.026820
   Number of active neurons: 5
 >> iter 11000, loss: 0.026071
 >> iter 12000, loss: 0.025295
 >> iter 13000, loss: 0.025374
 >> iter 14000, loss: 0.024881
 >> iter 15000, loss: 0.025132
 >> iter 16000, loss: 0.024406
 >> iter 17000, loss: 0.024522
 >> iter 18000, loss: 0.023869
 >> iter 19000, loss: 0.024059
 >> iter 20000, loss: 0.023463
   Number of active neurons: 5
 >> iter 21000, loss: 0.023622
 >> iter 22000, loss: 0.023097
 >> iter 23000, loss: 0.023362
 >> iter 24000, loss: 0.022944
 >> iter 25000, loss: 0.023181
 >> iter 26000, loss: 0.022726
 >> iter 27000, loss: 0.022996
 >> iter 28000, loss: 0.022626
 >> iter 29000, loss: 0.022938
 >> iter 30000, loss: 0.022625
   Number of active neurons: 5
 >> iter 31000, loss: 0.022943
 >> iter 32000, loss: 0.022635
 >> iter 33000, loss: 0.022937
 >> iter 34000, loss: 0.022655
 >> iter 35000, loss: 0.022907
 >> iter 36000, loss: 0.022621
 >> iter 37000, loss: 0.022808
 >> iter 38000, loss: 0.022384
 >> iter 39000, loss: 0.022418
 >> iter 40000, loss: 0.022004
   Number of active neurons: 4
 >> iter 41000, loss: 0.021942
 >> iter 42000, loss: 0.021497
 >> iter 43000, loss: 0.021466
 >> iter 44000, loss: 0.021063
 >> iter 45000, loss: 0.020995
 >> iter 46000, loss: 0.020589
 >> iter 47000, loss: 0.020616
 >> iter 48000, loss: 0.020322
 >> iter 49000, loss: 0.020457
 >> iter 50000, loss: 0.020217
   Number of active neurons: 4
 >> iter 51000, loss: 0.020389
 >> iter 52000, loss: 0.020201
 >> iter 53000, loss: 0.020361
 >> iter 54000, loss: 0.020207
 >> iter 55000, loss: 0.020358
 >> iter 56000, loss: 0.020198
 >> iter 57000, loss: 0.020321
 >> iter 58000, loss: 0.020045
 >> iter 59000, loss: 0.020022
 >> iter 60000, loss: 0.019731
   Number of active neurons: 3
 >> iter 61000, loss: 0.019740
 >> iter 62000, loss: 0.019437
 >> iter 63000, loss: 0.019352
 >> iter 64000, loss: 0.018970
 >> iter 65000, loss: 0.018831
 >> iter 66000, loss: 0.018449
 >> iter 67000, loss: 0.018257
 >> iter 68000, loss: 0.017820
 >> iter 69000, loss: 0.017570
 >> iter 70000, loss: 0.017208
   Number of active neurons: 3
 >> iter 71000, loss: 0.017061
 >> iter 72000, loss: 0.016806
 >> iter 73000, loss: 0.016756
 >> iter 74000, loss: 0.016555
 >> iter 75000, loss: 0.016540
 >> iter 76000, loss: 0.016377
 >> iter 77000, loss: 0.016383
 >> iter 78000, loss: 0.016238
 >> iter 79000, loss: 0.016260
 >> iter 80000, loss: 0.016122
   Number of active neurons: 3
 >> iter 81000, loss: 0.016161
 >> iter 82000, loss: 0.016031
 >> iter 83000, loss: 0.016077
 >> iter 84000, loss: 0.015961
 >> iter 85000, loss: 0.016000
 >> iter 86000, loss: 0.015894
 >> iter 87000, loss: 0.015935
 >> iter 88000, loss: 0.015851
 >> iter 89000, loss: 0.015887
 >> iter 90000, loss: 0.015802
   Number of active neurons: 3
 >> iter 91000, loss: 0.015836
 >> iter 92000, loss: 0.015768
 >> iter 93000, loss: 0.015805
 >> iter 94000, loss: 0.015733
 >> iter 95000, loss: 0.015779
 >> iter 96000, loss: 0.015705
 >> iter 97000, loss: 0.015753
 >> iter 98000, loss: 0.015677
 >> iter 99000, loss: 0.015729
 >> iter 100000, loss: 0.015662
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 10.903686
 >> iter 2000, loss: 4.038989
 >> iter 3000, loss: 1.506712
 >> iter 4000, loss: 0.572851
 >> iter 5000, loss: 0.228991
 >> iter 6000, loss: 0.101383
 >> iter 7000, loss: 0.054399
 >> iter 8000, loss: 0.036140
 >> iter 9000, loss: 0.029419
 >> iter 10000, loss: 0.026090
   Number of active neurons: 3
 >> iter 11000, loss: 0.024991
 >> iter 12000, loss: 0.023952
 >> iter 13000, loss: 0.023833
 >> iter 14000, loss: 0.023130
 >> iter 15000, loss: 0.023076
 >> iter 16000, loss: 0.022399
 >> iter 17000, loss: 0.022434
 >> iter 18000, loss: 0.021835
 >> iter 19000, loss: 0.021876
 >> iter 20000, loss: 0.021303
   Number of active neurons: 3
 >> iter 21000, loss: 0.021410
 >> iter 22000, loss: 0.020933
 >> iter 23000, loss: 0.021047
 >> iter 24000, loss: 0.020613
 >> iter 25000, loss: 0.020801
 >> iter 26000, loss: 0.020435
 >> iter 27000, loss: 0.020672
 >> iter 28000, loss: 0.020337
 >> iter 29000, loss: 0.020586
 >> iter 30000, loss: 0.020250
   Number of active neurons: 2
 >> iter 31000, loss: 0.020360
 >> iter 32000, loss: 0.019917
 >> iter 33000, loss: 0.020013
 >> iter 34000, loss: 0.019610
 >> iter 35000, loss: 0.019649
 >> iter 36000, loss: 0.019184
 >> iter 37000, loss: 0.019117
 >> iter 38000, loss: 0.018644
 >> iter 39000, loss: 0.018548
 >> iter 40000, loss: 0.018081
   Number of active neurons: 2
 >> iter 41000, loss: 0.017891
 >> iter 42000, loss: 0.017399
 >> iter 43000, loss: 0.017281
 >> iter 44000, loss: 0.016923
 >> iter 45000, loss: 0.016894
 >> iter 46000, loss: 0.016610
 >> iter 47000, loss: 0.016644
 >> iter 48000, loss: 0.016402
 >> iter 49000, loss: 0.016477
 >> iter 50000, loss: 0.016252
   Number of active neurons: 2
 >> iter 51000, loss: 0.016340
 >> iter 52000, loss: 0.016149
 >> iter 53000, loss: 0.016227
 >> iter 54000, loss: 0.016069
 >> iter 55000, loss: 0.016146
 >> iter 56000, loss: 0.015994
 >> iter 57000, loss: 0.016069
 >> iter 58000, loss: 0.015931
 >> iter 59000, loss: 0.016010
 >> iter 60000, loss: 0.015877
   Number of active neurons: 2
 >> iter 61000, loss: 0.015975
 >> iter 62000, loss: 0.015829
 >> iter 63000, loss: 0.015920
 >> iter 64000, loss: 0.015792
 >> iter 65000, loss: 0.015876
 >> iter 66000, loss: 0.015759
 >> iter 67000, loss: 0.015841
 >> iter 68000, loss: 0.015738
 >> iter 69000, loss: 0.015803
 >> iter 70000, loss: 0.015709
   Number of active neurons: 2
 >> iter 71000, loss: 0.015769
 >> iter 72000, loss: 0.015680
 >> iter 73000, loss: 0.015758
 >> iter 74000, loss: 0.015665
 >> iter 75000, loss: 0.015736
 >> iter 76000, loss: 0.015649
 >> iter 77000, loss: 0.015716
 >> iter 78000, loss: 0.015628
 >> iter 79000, loss: 0.015698
 >> iter 80000, loss: 0.015606
   Number of active neurons: 2
 >> iter 81000, loss: 0.015683
 >> iter 82000, loss: 0.015591
 >> iter 83000, loss: 0.015669
 >> iter 84000, loss: 0.015585
 >> iter 85000, loss: 0.015650
 >> iter 86000, loss: 0.015571
 >> iter 87000, loss: 0.015634
 >> iter 88000, loss: 0.015574
 >> iter 89000, loss: 0.015628
 >> iter 90000, loss: 0.015564
   Number of active neurons: 2
 >> iter 91000, loss: 0.015613
 >> iter 92000, loss: 0.015563
 >> iter 93000, loss: 0.015613
 >> iter 94000, loss: 0.015556
 >> iter 95000, loss: 0.015613
 >> iter 96000, loss: 0.015552
 >> iter 97000, loss: 0.015608
 >> iter 98000, loss: 0.015544
 >> iter 99000, loss: 0.015603
 >> iter 100000, loss: 0.015547
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.924709
 >> iter 2000, loss: 4.049410
 >> iter 3000, loss: 1.512163
 >> iter 4000, loss: 0.575189
 >> iter 5000, loss: 0.229661
 >> iter 6000, loss: 0.100961
 >> iter 7000, loss: 0.053645
 >> iter 8000, loss: 0.035301
 >> iter 9000, loss: 0.028719
 >> iter 10000, loss: 0.025637
   Number of active neurons: 4
 >> iter 11000, loss: 0.024687
 >> iter 12000, loss: 0.023646
 >> iter 13000, loss: 0.023378
 >> iter 14000, loss: 0.022495
 >> iter 15000, loss: 0.022352
 >> iter 16000, loss: 0.021570
 >> iter 17000, loss: 0.021579
 >> iter 18000, loss: 0.020891
 >> iter 19000, loss: 0.020928
 >> iter 20000, loss: 0.020330
   Number of active neurons: 4
 >> iter 21000, loss: 0.020476
 >> iter 22000, loss: 0.020009
 >> iter 23000, loss: 0.020224
 >> iter 24000, loss: 0.019757
 >> iter 25000, loss: 0.019905
 >> iter 26000, loss: 0.019511
 >> iter 27000, loss: 0.019716
 >> iter 28000, loss: 0.019384
 >> iter 29000, loss: 0.019619
 >> iter 30000, loss: 0.019340
   Number of active neurons: 4
 >> iter 31000, loss: 0.019588
 >> iter 32000, loss: 0.019326
 >> iter 33000, loss: 0.019559
 >> iter 34000, loss: 0.019309
 >> iter 35000, loss: 0.019531
 >> iter 36000, loss: 0.019317
 >> iter 37000, loss: 0.019547
 >> iter 38000, loss: 0.019346
 >> iter 39000, loss: 0.019552
 >> iter 40000, loss: 0.019369
   Number of active neurons: 4
 >> iter 41000, loss: 0.019532
 >> iter 42000, loss: 0.019350
 >> iter 43000, loss: 0.019530
 >> iter 44000, loss: 0.019382
 >> iter 45000, loss: 0.019558
 >> iter 46000, loss: 0.019403
 >> iter 47000, loss: 0.019592
 >> iter 48000, loss: 0.019435
 >> iter 49000, loss: 0.019636
 >> iter 50000, loss: 0.019471
   Number of active neurons: 4
 >> iter 51000, loss: 0.019669
 >> iter 52000, loss: 0.019530
 >> iter 53000, loss: 0.019701
 >> iter 54000, loss: 0.019591
 >> iter 55000, loss: 0.019756
 >> iter 56000, loss: 0.019642
 >> iter 57000, loss: 0.019799
 >> iter 58000, loss: 0.019695
 >> iter 59000, loss: 0.019854
 >> iter 60000, loss: 0.019754
   Number of active neurons: 4
 >> iter 61000, loss: 0.019935
 >> iter 62000, loss: 0.019809
 >> iter 63000, loss: 0.019979
 >> iter 64000, loss: 0.019871
 >> iter 65000, loss: 0.020029
 >> iter 66000, loss: 0.019927
 >> iter 67000, loss: 0.020080
 >> iter 68000, loss: 0.019986
 >> iter 69000, loss: 0.020111
 >> iter 70000, loss: 0.020018
   Number of active neurons: 4
 >> iter 71000, loss: 0.020126
 >> iter 72000, loss: 0.019967
 >> iter 73000, loss: 0.019948
 >> iter 74000, loss: 0.019694
 >> iter 75000, loss: 0.019672
 >> iter 76000, loss: 0.019451
 >> iter 77000, loss: 0.019411
 >> iter 78000, loss: 0.019097
 >> iter 79000, loss: 0.018950
 >> iter 80000, loss: 0.018612
   Number of active neurons: 3
 >> iter 81000, loss: 0.018447
 >> iter 82000, loss: 0.018068
 >> iter 83000, loss: 0.017824
 >> iter 84000, loss: 0.017417
 >> iter 85000, loss: 0.017214
 >> iter 86000, loss: 0.016922
 >> iter 87000, loss: 0.016818
 >> iter 88000, loss: 0.016623
 >> iter 89000, loss: 0.016569
 >> iter 90000, loss: 0.016413
   Number of active neurons: 3
 >> iter 91000, loss: 0.016387
 >> iter 92000, loss: 0.016269
 >> iter 93000, loss: 0.016263
 >> iter 94000, loss: 0.016153
 >> iter 95000, loss: 0.016165
 >> iter 96000, loss: 0.016059
 >> iter 97000, loss: 0.016080
 >> iter 98000, loss: 0.015978
 >> iter 99000, loss: 0.016008
 >> iter 100000, loss: 0.015920
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 10.913675
 >> iter 2000, loss: 4.045165
 >> iter 3000, loss: 1.510403
 >> iter 4000, loss: 0.575440
 >> iter 5000, loss: 0.231231
 >> iter 6000, loss: 0.103322
 >> iter 7000, loss: 0.056146
 >> iter 8000, loss: 0.037795
 >> iter 9000, loss: 0.031154
 >> iter 10000, loss: 0.027969
   Number of active neurons: 4
 >> iter 11000, loss: 0.027023
 >> iter 12000, loss: 0.026048
 >> iter 13000, loss: 0.025996
 >> iter 14000, loss: 0.025300
 >> iter 15000, loss: 0.025205
 >> iter 16000, loss: 0.024258
 >> iter 17000, loss: 0.024047
 >> iter 18000, loss: 0.023161
 >> iter 19000, loss: 0.022986
 >> iter 20000, loss: 0.022159
   Number of active neurons: 4
 >> iter 21000, loss: 0.022013
 >> iter 22000, loss: 0.021317
 >> iter 23000, loss: 0.021327
 >> iter 24000, loss: 0.020754
 >> iter 25000, loss: 0.020851
 >> iter 26000, loss: 0.020414
 >> iter 27000, loss: 0.020614
 >> iter 28000, loss: 0.020251
 >> iter 29000, loss: 0.020496
 >> iter 30000, loss: 0.020191
   Number of active neurons: 4
 >> iter 31000, loss: 0.020456
 >> iter 32000, loss: 0.020168
 >> iter 33000, loss: 0.020435
 >> iter 34000, loss: 0.020183
 >> iter 35000, loss: 0.020427
 >> iter 36000, loss: 0.020172
 >> iter 37000, loss: 0.020378
 >> iter 38000, loss: 0.020120
 >> iter 39000, loss: 0.020309
 >> iter 40000, loss: 0.019992
   Number of active neurons: 3
 >> iter 41000, loss: 0.020014
 >> iter 42000, loss: 0.019670
 >> iter 43000, loss: 0.019715
 >> iter 44000, loss: 0.019412
 >> iter 45000, loss: 0.019398
 >> iter 46000, loss: 0.018986
 >> iter 47000, loss: 0.018902
 >> iter 48000, loss: 0.018478
 >> iter 49000, loss: 0.018363
 >> iter 50000, loss: 0.017873
   Number of active neurons: 3
 >> iter 51000, loss: 0.017687
 >> iter 52000, loss: 0.017249
 >> iter 53000, loss: 0.017142
 >> iter 54000, loss: 0.016835
 >> iter 55000, loss: 0.016805
 >> iter 56000, loss: 0.016566
 >> iter 57000, loss: 0.016576
 >> iter 58000, loss: 0.016380
 >> iter 59000, loss: 0.016416
 >> iter 60000, loss: 0.016244
   Number of active neurons: 3
 >> iter 61000, loss: 0.016312
 >> iter 62000, loss: 0.016135
 >> iter 63000, loss: 0.016202
 >> iter 64000, loss: 0.016051
 >> iter 65000, loss: 0.016116
 >> iter 66000, loss: 0.015979
 >> iter 67000, loss: 0.016046
 >> iter 68000, loss: 0.015925
 >> iter 69000, loss: 0.015978
 >> iter 70000, loss: 0.015870
   Number of active neurons: 3
 >> iter 71000, loss: 0.015919
 >> iter 72000, loss: 0.015818
 >> iter 73000, loss: 0.015887
 >> iter 74000, loss: 0.015783
 >> iter 75000, loss: 0.015846
 >> iter 76000, loss: 0.015751
 >> iter 77000, loss: 0.015811
 >> iter 78000, loss: 0.015716
 >> iter 79000, loss: 0.015780
 >> iter 80000, loss: 0.015681
   Number of active neurons: 3
 >> iter 81000, loss: 0.015754
 >> iter 82000, loss: 0.015657
 >> iter 83000, loss: 0.015730
 >> iter 84000, loss: 0.015641
 >> iter 85000, loss: 0.015702
 >> iter 86000, loss: 0.015620
 >> iter 87000, loss: 0.015680
 >> iter 88000, loss: 0.015617
 >> iter 89000, loss: 0.015668
 >> iter 90000, loss: 0.015601
   Number of active neurons: 3
 >> iter 91000, loss: 0.015648
 >> iter 92000, loss: 0.015595
 >> iter 93000, loss: 0.015643
 >> iter 94000, loss: 0.015584
 >> iter 95000, loss: 0.015639
 >> iter 96000, loss: 0.015575
 >> iter 97000, loss: 0.015631
 >> iter 98000, loss: 0.015565
 >> iter 99000, loss: 0.015624
 >> iter 100000, loss: 0.015565
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.000693
 >> iter 2000, loss: 4.074962
 >> iter 3000, loss: 1.519935
 >> iter 4000, loss: 0.578039
 >> iter 5000, loss: 0.231602
 >> iter 6000, loss: 0.103360
 >> iter 7000, loss: 0.056517
 >> iter 8000, loss: 0.038491
 >> iter 9000, loss: 0.032122
 >> iter 10000, loss: 0.029048
   Number of active neurons: 4
 >> iter 11000, loss: 0.028216
 >> iter 12000, loss: 0.027253
 >> iter 13000, loss: 0.027105
 >> iter 14000, loss: 0.026257
 >> iter 15000, loss: 0.026216
 >> iter 16000, loss: 0.025267
 >> iter 17000, loss: 0.025019
 >> iter 18000, loss: 0.023868
 >> iter 19000, loss: 0.023577
 >> iter 20000, loss: 0.022598
   Number of active neurons: 3
 >> iter 21000, loss: 0.022405
 >> iter 22000, loss: 0.021502
 >> iter 23000, loss: 0.021366
 >> iter 24000, loss: 0.020594
 >> iter 25000, loss: 0.020617
 >> iter 26000, loss: 0.019979
 >> iter 27000, loss: 0.020044
 >> iter 28000, loss: 0.019564
 >> iter 29000, loss: 0.019717
 >> iter 30000, loss: 0.019351
   Number of active neurons: 3
 >> iter 31000, loss: 0.019541
 >> iter 32000, loss: 0.019222
 >> iter 33000, loss: 0.019425
 >> iter 34000, loss: 0.019161
 >> iter 35000, loss: 0.019343
 >> iter 36000, loss: 0.019106
 >> iter 37000, loss: 0.019288
 >> iter 38000, loss: 0.019070
 >> iter 39000, loss: 0.019237
 >> iter 40000, loss: 0.019066
   Number of active neurons: 3
 >> iter 41000, loss: 0.019202
 >> iter 42000, loss: 0.019015
 >> iter 43000, loss: 0.019134
 >> iter 44000, loss: 0.018972
 >> iter 45000, loss: 0.019089
 >> iter 46000, loss: 0.018933
 >> iter 47000, loss: 0.019067
 >> iter 48000, loss: 0.018918
 >> iter 49000, loss: 0.019061
 >> iter 50000, loss: 0.018907
   Number of active neurons: 3
 >> iter 51000, loss: 0.019045
 >> iter 52000, loss: 0.018917
 >> iter 53000, loss: 0.019027
 >> iter 54000, loss: 0.018928
 >> iter 55000, loss: 0.019033
 >> iter 56000, loss: 0.018925
 >> iter 57000, loss: 0.019022
 >> iter 58000, loss: 0.018922
 >> iter 59000, loss: 0.019018
 >> iter 60000, loss: 0.018921
   Number of active neurons: 3
 >> iter 61000, loss: 0.019038
 >> iter 62000, loss: 0.018916
 >> iter 63000, loss: 0.019020
 >> iter 64000, loss: 0.018916
 >> iter 65000, loss: 0.019009
 >> iter 66000, loss: 0.018916
 >> iter 67000, loss: 0.019002
 >> iter 68000, loss: 0.018924
 >> iter 69000, loss: 0.018987
 >> iter 70000, loss: 0.018919
   Number of active neurons: 3
 >> iter 71000, loss: 0.018972
 >> iter 72000, loss: 0.018909
 >> iter 73000, loss: 0.018983
 >> iter 74000, loss: 0.018910
 >> iter 75000, loss: 0.018975
 >> iter 76000, loss: 0.018910
 >> iter 77000, loss: 0.018970
 >> iter 78000, loss: 0.018902
 >> iter 79000, loss: 0.018966
 >> iter 80000, loss: 0.018888
   Number of active neurons: 3
 >> iter 81000, loss: 0.018959
 >> iter 82000, loss: 0.018884
 >> iter 83000, loss: 0.018960
 >> iter 84000, loss: 0.018886
 >> iter 85000, loss: 0.018947
 >> iter 86000, loss: 0.018879
 >> iter 87000, loss: 0.018937
 >> iter 88000, loss: 0.018899
 >> iter 89000, loss: 0.018937
 >> iter 90000, loss: 0.018894
   Number of active neurons: 3
 >> iter 91000, loss: 0.018926
 >> iter 92000, loss: 0.018900
 >> iter 93000, loss: 0.018939
 >> iter 94000, loss: 0.018897
 >> iter 95000, loss: 0.018943
 >> iter 96000, loss: 0.018898
 >> iter 97000, loss: 0.018942
 >> iter 98000, loss: 0.018893
 >> iter 99000, loss: 0.018945
 >> iter 100000, loss: 0.018904
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 10.977916
 >> iter 2000, loss: 4.066415
 >> iter 3000, loss: 1.516149
 >> iter 4000, loss: 0.576217
 >> iter 5000, loss: 0.230499
 >> iter 6000, loss: 0.102628
 >> iter 7000, loss: 0.055735
 >> iter 8000, loss: 0.037614
 >> iter 9000, loss: 0.030943
 >> iter 10000, loss: 0.027610
   Number of active neurons: 5
 >> iter 11000, loss: 0.026553
 >> iter 12000, loss: 0.025638
 >> iter 13000, loss: 0.025636
 >> iter 14000, loss: 0.025176
 >> iter 15000, loss: 0.025634
 >> iter 16000, loss: 0.025041
 >> iter 17000, loss: 0.025570
 >> iter 18000, loss: 0.025014
 >> iter 19000, loss: 0.025546
 >> iter 20000, loss: 0.025007
   Number of active neurons: 5
 >> iter 21000, loss: 0.025494
 >> iter 22000, loss: 0.024974
 >> iter 23000, loss: 0.025436
 >> iter 24000, loss: 0.024923
 >> iter 25000, loss: 0.025368
 >> iter 26000, loss: 0.024854
 >> iter 27000, loss: 0.025281
 >> iter 28000, loss: 0.024753
 >> iter 29000, loss: 0.025089
 >> iter 30000, loss: 0.024513
   Number of active neurons: 4
 >> iter 31000, loss: 0.024663
 >> iter 32000, loss: 0.024039
 >> iter 33000, loss: 0.024063
 >> iter 34000, loss: 0.023522
 >> iter 35000, loss: 0.023552
 >> iter 36000, loss: 0.023090
 >> iter 37000, loss: 0.023102
 >> iter 38000, loss: 0.022655
 >> iter 39000, loss: 0.022704
 >> iter 40000, loss: 0.022427
   Number of active neurons: 4
 >> iter 41000, loss: 0.022526
 >> iter 42000, loss: 0.022305
 >> iter 43000, loss: 0.022441
 >> iter 44000, loss: 0.022243
 >> iter 45000, loss: 0.022348
 >> iter 46000, loss: 0.022144
 >> iter 47000, loss: 0.022279
 >> iter 48000, loss: 0.022087
 >> iter 49000, loss: 0.022235
 >> iter 50000, loss: 0.022026
   Number of active neurons: 4
 >> iter 51000, loss: 0.022153
 >> iter 52000, loss: 0.021950
 >> iter 53000, loss: 0.022007
 >> iter 54000, loss: 0.021700
 >> iter 55000, loss: 0.021612
 >> iter 56000, loss: 0.021252
 >> iter 57000, loss: 0.021120
 >> iter 58000, loss: 0.020785
 >> iter 59000, loss: 0.020677
 >> iter 60000, loss: 0.020345
   Number of active neurons: 3
 >> iter 61000, loss: 0.020220
 >> iter 62000, loss: 0.019860
 >> iter 63000, loss: 0.019802
 >> iter 64000, loss: 0.019579
 >> iter 65000, loss: 0.019605
 >> iter 66000, loss: 0.019457
 >> iter 67000, loss: 0.019524
 >> iter 68000, loss: 0.019413
 >> iter 69000, loss: 0.019457
 >> iter 70000, loss: 0.019362
   Number of active neurons: 3
 >> iter 71000, loss: 0.019434
 >> iter 72000, loss: 0.019360
 >> iter 73000, loss: 0.019463
 >> iter 74000, loss: 0.019376
 >> iter 75000, loss: 0.019467
 >> iter 76000, loss: 0.019388
 >> iter 77000, loss: 0.019474
 >> iter 78000, loss: 0.019391
 >> iter 79000, loss: 0.019482
 >> iter 80000, loss: 0.019393
   Number of active neurons: 3
 >> iter 81000, loss: 0.019493
 >> iter 82000, loss: 0.019408
 >> iter 83000, loss: 0.019513
 >> iter 84000, loss: 0.019434
 >> iter 85000, loss: 0.019526
 >> iter 86000, loss: 0.019454
 >> iter 87000, loss: 0.019548
 >> iter 88000, loss: 0.019503
 >> iter 89000, loss: 0.019586
 >> iter 90000, loss: 0.019535
   Number of active neurons: 3
 >> iter 91000, loss: 0.019614
 >> iter 92000, loss: 0.019583
 >> iter 93000, loss: 0.019667
 >> iter 94000, loss: 0.019627
 >> iter 95000, loss: 0.019723
 >> iter 96000, loss: 0.019676
 >> iter 97000, loss: 0.019775
 >> iter 98000, loss: 0.019724
 >> iter 99000, loss: 0.019830
 >> iter 100000, loss: 0.019789
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.871204
 >> iter 2000, loss: 4.027540
 >> iter 3000, loss: 1.502534
 >> iter 4000, loss: 0.570778
 >> iter 5000, loss: 0.227416
 >> iter 6000, loss: 0.099785
 >> iter 7000, loss: 0.052682
 >> iter 8000, loss: 0.034507
 >> iter 9000, loss: 0.028001
 >> iter 10000, loss: 0.025025
   Number of active neurons: 4
 >> iter 11000, loss: 0.024262
 >> iter 12000, loss: 0.023492
 >> iter 13000, loss: 0.023531
 >> iter 14000, loss: 0.022969
 >> iter 15000, loss: 0.022994
 >> iter 16000, loss: 0.022318
 >> iter 17000, loss: 0.022354
 >> iter 18000, loss: 0.021761
 >> iter 19000, loss: 0.021827
 >> iter 20000, loss: 0.021242
   Number of active neurons: 4
 >> iter 21000, loss: 0.021319
 >> iter 22000, loss: 0.020805
 >> iter 23000, loss: 0.020899
 >> iter 24000, loss: 0.020460
 >> iter 25000, loss: 0.020647
 >> iter 26000, loss: 0.020286
 >> iter 27000, loss: 0.020531
 >> iter 28000, loss: 0.020210
 >> iter 29000, loss: 0.020477
 >> iter 30000, loss: 0.020194
   Number of active neurons: 4
 >> iter 31000, loss: 0.020469
 >> iter 32000, loss: 0.020191
 >> iter 33000, loss: 0.020458
 >> iter 34000, loss: 0.020201
 >> iter 35000, loss: 0.020412
 >> iter 36000, loss: 0.020066
 >> iter 37000, loss: 0.020114
 >> iter 38000, loss: 0.019721
 >> iter 39000, loss: 0.019773
 >> iter 40000, loss: 0.019450
   Number of active neurons: 3
 >> iter 41000, loss: 0.019455
 >> iter 42000, loss: 0.019035
 >> iter 43000, loss: 0.018954
 >> iter 44000, loss: 0.018544
 >> iter 45000, loss: 0.018420
 >> iter 46000, loss: 0.017953
 >> iter 47000, loss: 0.017760
 >> iter 48000, loss: 0.017299
 >> iter 49000, loss: 0.017206
 >> iter 50000, loss: 0.016849
   Number of active neurons: 3
 >> iter 51000, loss: 0.016842
 >> iter 52000, loss: 0.016576
 >> iter 53000, loss: 0.016599
 >> iter 54000, loss: 0.016395
 >> iter 55000, loss: 0.016438
 >> iter 56000, loss: 0.016256
 >> iter 57000, loss: 0.016307
 >> iter 58000, loss: 0.016146
 >> iter 59000, loss: 0.016207
 >> iter 60000, loss: 0.016057
   Number of active neurons: 3
 >> iter 61000, loss: 0.016141
 >> iter 62000, loss: 0.015981
 >> iter 63000, loss: 0.016061
 >> iter 64000, loss: 0.015922
 >> iter 65000, loss: 0.015997
 >> iter 66000, loss: 0.015870
 >> iter 67000, loss: 0.015945
 >> iter 68000, loss: 0.015833
 >> iter 69000, loss: 0.015891
 >> iter 70000, loss: 0.015790
   Number of active neurons: 3
 >> iter 71000, loss: 0.015845
 >> iter 72000, loss: 0.015750
 >> iter 73000, loss: 0.015824
 >> iter 74000, loss: 0.015725
 >> iter 75000, loss: 0.015792
 >> iter 76000, loss: 0.015700
 >> iter 77000, loss: 0.015764
 >> iter 78000, loss: 0.015673
 >> iter 79000, loss: 0.015740
 >> iter 80000, loss: 0.015644
   Number of active neurons: 3
 >> iter 81000, loss: 0.015719
 >> iter 82000, loss: 0.015624
 >> iter 83000, loss: 0.015700
 >> iter 84000, loss: 0.015614
 >> iter 85000, loss: 0.015677
 >> iter 86000, loss: 0.015596
 >> iter 87000, loss: 0.015658
 >> iter 88000, loss: 0.015596
 >> iter 89000, loss: 0.015648
 >> iter 90000, loss: 0.015582
   Number of active neurons: 3
 >> iter 91000, loss: 0.015631
 >> iter 92000, loss: 0.015579
 >> iter 93000, loss: 0.015628
 >> iter 94000, loss: 0.015570
 >> iter 95000, loss: 0.015626
 >> iter 96000, loss: 0.015564
 >> iter 97000, loss: 0.015620
 >> iter 98000, loss: 0.015554
 >> iter 99000, loss: 0.015614
 >> iter 100000, loss: 0.015556
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.958012
 >> iter 2000, loss: 4.065062
 >> iter 3000, loss: 1.519085
 >> iter 4000, loss: 0.579139
 >> iter 5000, loss: 0.232441
 >> iter 6000, loss: 0.102981
 >> iter 7000, loss: 0.054943
 >> iter 8000, loss: 0.035972
 >> iter 9000, loss: 0.029050
 >> iter 10000, loss: 0.025702
   Number of active neurons: 5
 >> iter 11000, loss: 0.024683
 >> iter 12000, loss: 0.023672
 >> iter 13000, loss: 0.023504
 >> iter 14000, loss: 0.022831
 >> iter 15000, loss: 0.022888
 >> iter 16000, loss: 0.022149
 >> iter 17000, loss: 0.022186
 >> iter 18000, loss: 0.021493
 >> iter 19000, loss: 0.021589
 >> iter 20000, loss: 0.020957
   Number of active neurons: 5
 >> iter 21000, loss: 0.021037
 >> iter 22000, loss: 0.020384
 >> iter 23000, loss: 0.020487
 >> iter 24000, loss: 0.019943
 >> iter 25000, loss: 0.020052
 >> iter 26000, loss: 0.019556
 >> iter 27000, loss: 0.019710
 >> iter 28000, loss: 0.019314
 >> iter 29000, loss: 0.019513
 >> iter 30000, loss: 0.019192
   Number of active neurons: 5
 >> iter 31000, loss: 0.019408
 >> iter 32000, loss: 0.019117
 >> iter 33000, loss: 0.019335
 >> iter 34000, loss: 0.019090
 >> iter 35000, loss: 0.019282
 >> iter 36000, loss: 0.019059
 >> iter 37000, loss: 0.019247
 >> iter 38000, loss: 0.019039
 >> iter 39000, loss: 0.019211
 >> iter 40000, loss: 0.019048
   Number of active neurons: 5
 >> iter 41000, loss: 0.019183
 >> iter 42000, loss: 0.018995
 >> iter 43000, loss: 0.019119
 >> iter 44000, loss: 0.018964
 >> iter 45000, loss: 0.019087
 >> iter 46000, loss: 0.018936
 >> iter 47000, loss: 0.019074
 >> iter 48000, loss: 0.018930
 >> iter 49000, loss: 0.019077
 >> iter 50000, loss: 0.018927
   Number of active neurons: 5
 >> iter 51000, loss: 0.019069
 >> iter 52000, loss: 0.018946
 >> iter 53000, loss: 0.019060
 >> iter 54000, loss: 0.018964
 >> iter 55000, loss: 0.019074
 >> iter 56000, loss: 0.018971
 >> iter 57000, loss: 0.019072
 >> iter 58000, loss: 0.018979
 >> iter 59000, loss: 0.019080
 >> iter 60000, loss: 0.018990
   Number of active neurons: 5
 >> iter 61000, loss: 0.019113
 >> iter 62000, loss: 0.018999
 >> iter 63000, loss: 0.019111
 >> iter 64000, loss: 0.019015
 >> iter 65000, loss: 0.019118
 >> iter 66000, loss: 0.019032
 >> iter 67000, loss: 0.019132
 >> iter 68000, loss: 0.019062
 >> iter 69000, loss: 0.019139
 >> iter 70000, loss: 0.019079
   Number of active neurons: 5
 >> iter 71000, loss: 0.019151
 >> iter 72000, loss: 0.019096
 >> iter 73000, loss: 0.019196
 >> iter 74000, loss: 0.019110
 >> iter 75000, loss: 0.019195
 >> iter 76000, loss: 0.019131
 >> iter 77000, loss: 0.019229
 >> iter 78000, loss: 0.019164
 >> iter 79000, loss: 0.019263
 >> iter 80000, loss: 0.019186
   Number of active neurons: 5
 >> iter 81000, loss: 0.019288
 >> iter 82000, loss: 0.019209
 >> iter 83000, loss: 0.019314
 >> iter 84000, loss: 0.019238
 >> iter 85000, loss: 0.019327
 >> iter 86000, loss: 0.019257
 >> iter 87000, loss: 0.019345
 >> iter 88000, loss: 0.019301
 >> iter 89000, loss: 0.019377
 >> iter 90000, loss: 0.019326
   Number of active neurons: 5
 >> iter 91000, loss: 0.019397
 >> iter 92000, loss: 0.019365
 >> iter 93000, loss: 0.019440
 >> iter 94000, loss: 0.019399
 >> iter 95000, loss: 0.019485
 >> iter 96000, loss: 0.019437
 >> iter 97000, loss: 0.019525
 >> iter 98000, loss: 0.019474
 >> iter 99000, loss: 0.019570
 >> iter 100000, loss: 0.019529
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.919758
 >> iter 2000, loss: 4.043919
 >> iter 3000, loss: 1.508309
 >> iter 4000, loss: 0.573541
 >> iter 5000, loss: 0.229679
 >> iter 6000, loss: 0.102272
 >> iter 7000, loss: 0.055548
 >> iter 8000, loss: 0.037538
 >> iter 9000, loss: 0.031171
 >> iter 10000, loss: 0.028170
   Number of active neurons: 5
 >> iter 11000, loss: 0.027352
 >> iter 12000, loss: 0.026432
 >> iter 13000, loss: 0.026436
 >> iter 14000, loss: 0.025905
 >> iter 15000, loss: 0.026172
 >> iter 16000, loss: 0.025690
 >> iter 17000, loss: 0.026012
 >> iter 18000, loss: 0.025528
 >> iter 19000, loss: 0.025722
 >> iter 20000, loss: 0.025113
   Number of active neurons: 4
 >> iter 21000, loss: 0.025206
 >> iter 22000, loss: 0.024605
 >> iter 23000, loss: 0.024710
 >> iter 24000, loss: 0.024030
 >> iter 25000, loss: 0.023987
 >> iter 26000, loss: 0.023251
 >> iter 27000, loss: 0.023228
 >> iter 28000, loss: 0.022605
 >> iter 29000, loss: 0.022603
 >> iter 30000, loss: 0.022030
   Number of active neurons: 3
 >> iter 31000, loss: 0.022058
 >> iter 32000, loss: 0.021495
 >> iter 33000, loss: 0.021486
 >> iter 34000, loss: 0.020993
 >> iter 35000, loss: 0.021030
 >> iter 36000, loss: 0.020624
 >> iter 37000, loss: 0.020730
 >> iter 38000, loss: 0.020330
 >> iter 39000, loss: 0.020319
 >> iter 40000, loss: 0.019927
   Number of active neurons: 2
 >> iter 41000, loss: 0.019920
 >> iter 42000, loss: 0.019553
 >> iter 43000, loss: 0.019493
 >> iter 44000, loss: 0.019057
 >> iter 45000, loss: 0.018939
 >> iter 46000, loss: 0.018489
 >> iter 47000, loss: 0.018330
 >> iter 48000, loss: 0.017815
 >> iter 49000, loss: 0.017641
 >> iter 50000, loss: 0.017200
   Number of active neurons: 2
 >> iter 51000, loss: 0.017132
 >> iter 52000, loss: 0.016815
 >> iter 53000, loss: 0.016803
 >> iter 54000, loss: 0.016569
 >> iter 55000, loss: 0.016592
 >> iter 56000, loss: 0.016391
 >> iter 57000, loss: 0.016429
 >> iter 58000, loss: 0.016256
 >> iter 59000, loss: 0.016308
 >> iter 60000, loss: 0.016149
   Number of active neurons: 2
 >> iter 61000, loss: 0.016227
 >> iter 62000, loss: 0.016059
 >> iter 63000, loss: 0.016133
 >> iter 64000, loss: 0.015988
 >> iter 65000, loss: 0.016058
 >> iter 66000, loss: 0.015926
 >> iter 67000, loss: 0.015997
 >> iter 68000, loss: 0.015881
 >> iter 69000, loss: 0.015936
 >> iter 70000, loss: 0.015832
   Number of active neurons: 2
 >> iter 71000, loss: 0.015883
 >> iter 72000, loss: 0.015786
 >> iter 73000, loss: 0.015857
 >> iter 74000, loss: 0.015755
 >> iter 75000, loss: 0.015820
 >> iter 76000, loss: 0.015727
 >> iter 77000, loss: 0.015788
 >> iter 78000, loss: 0.015696
 >> iter 79000, loss: 0.015761
 >> iter 80000, loss: 0.015664
   Number of active neurons: 2
 >> iter 81000, loss: 0.015737
 >> iter 82000, loss: 0.015642
 >> iter 83000, loss: 0.015716
 >> iter 84000, loss: 0.015629
 >> iter 85000, loss: 0.015690
 >> iter 86000, loss: 0.015609
 >> iter 87000, loss: 0.015669
 >> iter 88000, loss: 0.015607
 >> iter 89000, loss: 0.015658
 >> iter 90000, loss: 0.015592
   Number of active neurons: 2
 >> iter 91000, loss: 0.015639
 >> iter 92000, loss: 0.015587
 >> iter 93000, loss: 0.015636
 >> iter 94000, loss: 0.015578
 >> iter 95000, loss: 0.015633
 >> iter 96000, loss: 0.015570
 >> iter 97000, loss: 0.015625
 >> iter 98000, loss: 0.015560
 >> iter 99000, loss: 0.015619
 >> iter 100000, loss: 0.015561
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 10.913010
 >> iter 2000, loss: 4.041165
 >> iter 3000, loss: 1.507717
 >> iter 4000, loss: 0.573489
 >> iter 5000, loss: 0.229283
 >> iter 6000, loss: 0.101232
 >> iter 7000, loss: 0.054149
 >> iter 8000, loss: 0.035839
 >> iter 9000, loss: 0.029020
 >> iter 10000, loss: 0.025587
   Number of active neurons: 5
 >> iter 11000, loss: 0.024412
 >> iter 12000, loss: 0.023378
 >> iter 13000, loss: 0.023319
 >> iter 14000, loss: 0.022866
 >> iter 15000, loss: 0.023210
 >> iter 16000, loss: 0.022771
 >> iter 17000, loss: 0.023152
 >> iter 18000, loss: 0.022741
 >> iter 19000, loss: 0.023129
 >> iter 20000, loss: 0.022742
   Number of active neurons: 5
 >> iter 21000, loss: 0.023107
 >> iter 22000, loss: 0.022732
 >> iter 23000, loss: 0.023092
 >> iter 24000, loss: 0.022708
 >> iter 25000, loss: 0.022956
 >> iter 26000, loss: 0.022539
 >> iter 27000, loss: 0.022798
 >> iter 28000, loss: 0.022423
 >> iter 29000, loss: 0.022669
 >> iter 30000, loss: 0.022299
   Number of active neurons: 4
 >> iter 31000, loss: 0.022518
 >> iter 32000, loss: 0.022031
 >> iter 33000, loss: 0.022120
 >> iter 34000, loss: 0.021665
 >> iter 35000, loss: 0.021680
 >> iter 36000, loss: 0.021219
 >> iter 37000, loss: 0.021240
 >> iter 38000, loss: 0.020779
 >> iter 39000, loss: 0.020713
 >> iter 40000, loss: 0.020272
   Number of active neurons: 4
 >> iter 41000, loss: 0.020258
 >> iter 42000, loss: 0.019944
 >> iter 43000, loss: 0.020046
 >> iter 44000, loss: 0.019834
 >> iter 45000, loss: 0.019978
 >> iter 46000, loss: 0.019788
 >> iter 47000, loss: 0.019964
 >> iter 48000, loss: 0.019784
 >> iter 49000, loss: 0.019984
 >> iter 50000, loss: 0.019800
   Number of active neurons: 4
 >> iter 51000, loss: 0.019999
 >> iter 52000, loss: 0.019846
 >> iter 53000, loss: 0.020021
 >> iter 54000, loss: 0.019897
 >> iter 55000, loss: 0.020066
 >> iter 56000, loss: 0.019941
 >> iter 57000, loss: 0.020100
 >> iter 58000, loss: 0.019983
 >> iter 59000, loss: 0.020142
 >> iter 60000, loss: 0.020025
   Number of active neurons: 4
 >> iter 61000, loss: 0.020202
 >> iter 62000, loss: 0.020052
 >> iter 63000, loss: 0.020210
 >> iter 64000, loss: 0.020062
 >> iter 65000, loss: 0.020090
 >> iter 66000, loss: 0.019806
 >> iter 67000, loss: 0.019794
 >> iter 68000, loss: 0.019548
 >> iter 69000, loss: 0.019520
 >> iter 70000, loss: 0.019239
   Number of active neurons: 3
 >> iter 71000, loss: 0.019090
 >> iter 72000, loss: 0.018756
 >> iter 73000, loss: 0.018603
 >> iter 74000, loss: 0.018236
 >> iter 75000, loss: 0.018007
 >> iter 76000, loss: 0.017584
 >> iter 77000, loss: 0.017360
 >> iter 78000, loss: 0.017037
 >> iter 79000, loss: 0.016924
 >> iter 80000, loss: 0.016684
   Number of active neurons: 3
 >> iter 81000, loss: 0.016646
 >> iter 82000, loss: 0.016456
 >> iter 83000, loss: 0.016455
 >> iter 84000, loss: 0.016299
 >> iter 85000, loss: 0.016306
 >> iter 86000, loss: 0.016172
 >> iter 87000, loss: 0.016190
 >> iter 88000, loss: 0.016084
 >> iter 89000, loss: 0.016102
 >> iter 90000, loss: 0.015999
   Number of active neurons: 3
 >> iter 91000, loss: 0.016018
 >> iter 92000, loss: 0.015936
 >> iter 93000, loss: 0.015961
 >> iter 94000, loss: 0.015877
 >> iter 95000, loss: 0.015913
 >> iter 96000, loss: 0.015828
 >> iter 97000, loss: 0.015867
 >> iter 98000, loss: 0.015782
 >> iter 99000, loss: 0.015827
 >> iter 100000, loss: 0.015753
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 11.116005
 >> iter 2000, loss: 4.130715
 >> iter 3000, loss: 1.545080
 >> iter 4000, loss: 0.590981
 >> iter 5000, loss: 0.238888
 >> iter 6000, loss: 0.108662
 >> iter 7000, loss: 0.060536
 >> iter 8000, loss: 0.042009
 >> iter 9000, loss: 0.035234
 >> iter 10000, loss: 0.032021
   Number of active neurons: 7
 >> iter 11000, loss: 0.031028
 >> iter 12000, loss: 0.029895
 >> iter 13000, loss: 0.029708
 >> iter 14000, loss: 0.028943
 >> iter 15000, loss: 0.029024
 >> iter 16000, loss: 0.027975
 >> iter 17000, loss: 0.027908
 >> iter 18000, loss: 0.026899
 >> iter 19000, loss: 0.026928
 >> iter 20000, loss: 0.026043
   Number of active neurons: 6
 >> iter 21000, loss: 0.026170
 >> iter 22000, loss: 0.025498
 >> iter 23000, loss: 0.025808
 >> iter 24000, loss: 0.025285
 >> iter 25000, loss: 0.025678
 >> iter 26000, loss: 0.025197
 >> iter 27000, loss: 0.025615
 >> iter 28000, loss: 0.025132
 >> iter 29000, loss: 0.025413
 >> iter 30000, loss: 0.024934
   Number of active neurons: 5
 >> iter 31000, loss: 0.025178
 >> iter 32000, loss: 0.024736
 >> iter 33000, loss: 0.024952
 >> iter 34000, loss: 0.024526
 >> iter 35000, loss: 0.024551
 >> iter 36000, loss: 0.024010
 >> iter 37000, loss: 0.023942
 >> iter 38000, loss: 0.023379
 >> iter 39000, loss: 0.023205
 >> iter 40000, loss: 0.022550
   Number of active neurons: 4
 >> iter 41000, loss: 0.022193
 >> iter 42000, loss: 0.021496
 >> iter 43000, loss: 0.021255
 >> iter 44000, loss: 0.020750
 >> iter 45000, loss: 0.020587
 >> iter 46000, loss: 0.020128
 >> iter 47000, loss: 0.020071
 >> iter 48000, loss: 0.019753
 >> iter 49000, loss: 0.019815
 >> iter 50000, loss: 0.019555
   Number of active neurons: 4
 >> iter 51000, loss: 0.019688
 >> iter 52000, loss: 0.019511
 >> iter 53000, loss: 0.019643
 >> iter 54000, loss: 0.019506
 >> iter 55000, loss: 0.019636
 >> iter 56000, loss: 0.019501
 >> iter 57000, loss: 0.019622
 >> iter 58000, loss: 0.019500
 >> iter 59000, loss: 0.019624
 >> iter 60000, loss: 0.019508
   Number of active neurons: 4
 >> iter 61000, loss: 0.019656
 >> iter 62000, loss: 0.019517
 >> iter 63000, loss: 0.019657
 >> iter 64000, loss: 0.019540
 >> iter 65000, loss: 0.019670
 >> iter 66000, loss: 0.019566
 >> iter 67000, loss: 0.019695
 >> iter 68000, loss: 0.019608
 >> iter 69000, loss: 0.019715
 >> iter 70000, loss: 0.019639
   Number of active neurons: 4
 >> iter 71000, loss: 0.019741
 >> iter 72000, loss: 0.019673
 >> iter 73000, loss: 0.019803
 >> iter 74000, loss: 0.019722
 >> iter 75000, loss: 0.019845
 >> iter 76000, loss: 0.019774
 >> iter 77000, loss: 0.019894
 >> iter 78000, loss: 0.019819
 >> iter 79000, loss: 0.019943
 >> iter 80000, loss: 0.019860
   Number of active neurons: 4
 >> iter 81000, loss: 0.019993
 >> iter 82000, loss: 0.019909
 >> iter 83000, loss: 0.020042
 >> iter 84000, loss: 0.019960
 >> iter 85000, loss: 0.020075
 >> iter 86000, loss: 0.019991
 >> iter 87000, loss: 0.020097
 >> iter 88000, loss: 0.020016
 >> iter 89000, loss: 0.019995
 >> iter 90000, loss: 0.019762
   Number of active neurons: 3
 >> iter 91000, loss: 0.019702
 >> iter 92000, loss: 0.019510
 >> iter 93000, loss: 0.019457
 >> iter 94000, loss: 0.019221
 >> iter 95000, loss: 0.019063
 >> iter 96000, loss: 0.018754
 >> iter 97000, loss: 0.018575
 >> iter 98000, loss: 0.018239
 >> iter 99000, loss: 0.018000
 >> iter 100000, loss: 0.017604
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.873741
 >> iter 2000, loss: 4.026852
 >> iter 3000, loss: 1.501891
 >> iter 4000, loss: 0.570919
 >> iter 5000, loss: 0.228447
 >> iter 6000, loss: 0.101448
 >> iter 7000, loss: 0.054835
 >> iter 8000, loss: 0.036879
 >> iter 9000, loss: 0.030467
 >> iter 10000, loss: 0.027447
   Number of active neurons: 5
 >> iter 11000, loss: 0.026678
 >> iter 12000, loss: 0.025882
 >> iter 13000, loss: 0.026001
 >> iter 14000, loss: 0.025539
 >> iter 15000, loss: 0.025822
 >> iter 16000, loss: 0.025264
 >> iter 17000, loss: 0.025395
 >> iter 18000, loss: 0.024729
 >> iter 19000, loss: 0.024857
 >> iter 20000, loss: 0.024276
   Number of active neurons: 4
 >> iter 21000, loss: 0.024392
 >> iter 22000, loss: 0.023803
 >> iter 23000, loss: 0.023957
 >> iter 24000, loss: 0.023414
 >> iter 25000, loss: 0.023522
 >> iter 26000, loss: 0.022903
 >> iter 27000, loss: 0.022956
 >> iter 28000, loss: 0.022394
 >> iter 29000, loss: 0.022431
 >> iter 30000, loss: 0.021883
   Number of active neurons: 3
 >> iter 31000, loss: 0.021931
 >> iter 32000, loss: 0.021395
 >> iter 33000, loss: 0.021401
 >> iter 34000, loss: 0.020913
 >> iter 35000, loss: 0.020976
 >> iter 36000, loss: 0.020581
 >> iter 37000, loss: 0.020698
 >> iter 38000, loss: 0.020385
 >> iter 39000, loss: 0.020540
 >> iter 40000, loss: 0.020299
   Number of active neurons: 2
 >> iter 41000, loss: 0.020380
 >> iter 42000, loss: 0.020002
 >> iter 43000, loss: 0.020010
 >> iter 44000, loss: 0.019677
 >> iter 45000, loss: 0.019685
 >> iter 46000, loss: 0.019303
 >> iter 47000, loss: 0.019211
 >> iter 48000, loss: 0.018775
 >> iter 49000, loss: 0.018671
 >> iter 50000, loss: 0.018199
   Number of active neurons: 2
 >> iter 51000, loss: 0.018015
 >> iter 52000, loss: 0.017529
 >> iter 53000, loss: 0.017372
 >> iter 54000, loss: 0.017022
 >> iter 55000, loss: 0.016961
 >> iter 56000, loss: 0.016696
 >> iter 57000, loss: 0.016687
 >> iter 58000, loss: 0.016477
 >> iter 59000, loss: 0.016502
 >> iter 60000, loss: 0.016321
   Number of active neurons: 2
 >> iter 61000, loss: 0.016381
 >> iter 62000, loss: 0.016198
 >> iter 63000, loss: 0.016260
 >> iter 64000, loss: 0.016103
 >> iter 65000, loss: 0.016164
 >> iter 66000, loss: 0.016023
 >> iter 67000, loss: 0.016087
 >> iter 68000, loss: 0.015963
 >> iter 69000, loss: 0.016012
 >> iter 70000, loss: 0.015902
   Number of active neurons: 2
 >> iter 71000, loss: 0.015948
 >> iter 72000, loss: 0.015845
 >> iter 73000, loss: 0.015913
 >> iter 74000, loss: 0.015807
 >> iter 75000, loss: 0.015868
 >> iter 76000, loss: 0.015771
 >> iter 77000, loss: 0.015830
 >> iter 78000, loss: 0.015734
 >> iter 79000, loss: 0.015797
 >> iter 80000, loss: 0.015697
   Number of active neurons: 2
 >> iter 81000, loss: 0.015767
 >> iter 82000, loss: 0.015670
 >> iter 83000, loss: 0.015742
 >> iter 84000, loss: 0.015653
 >> iter 85000, loss: 0.015713
 >> iter 86000, loss: 0.015630
 >> iter 87000, loss: 0.015689
 >> iter 88000, loss: 0.015625
 >> iter 89000, loss: 0.015675
 >> iter 90000, loss: 0.015608
   Number of active neurons: 2
 >> iter 91000, loss: 0.015654
 >> iter 92000, loss: 0.015601
 >> iter 93000, loss: 0.015649
 >> iter 94000, loss: 0.015589
 >> iter 95000, loss: 0.015644
 >> iter 96000, loss: 0.015581
 >> iter 97000, loss: 0.015635
 >> iter 98000, loss: 0.015569
 >> iter 99000, loss: 0.015628
 >> iter 100000, loss: 0.015569
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455179
   Number of active neurons: 0
 >> iter 1000, loss: 10.862852
 >> iter 2000, loss: 4.025002
 >> iter 3000, loss: 1.501507
 >> iter 4000, loss: 0.569800
 >> iter 5000, loss: 0.225853
 >> iter 6000, loss: 0.097586
 >> iter 7000, loss: 0.049919
 >> iter 8000, loss: 0.031388
 >> iter 9000, loss: 0.024630
 >> iter 10000, loss: 0.021673
   Number of active neurons: 5
 >> iter 11000, loss: 0.020929
 >> iter 12000, loss: 0.020269
 >> iter 13000, loss: 0.020378
 >> iter 14000, loss: 0.020015
 >> iter 15000, loss: 0.020298
 >> iter 16000, loss: 0.019886
 >> iter 17000, loss: 0.020179
 >> iter 18000, loss: 0.019784
 >> iter 19000, loss: 0.020088
 >> iter 20000, loss: 0.019716
   Number of active neurons: 5
 >> iter 21000, loss: 0.020010
 >> iter 22000, loss: 0.019653
 >> iter 23000, loss: 0.019900
 >> iter 24000, loss: 0.019494
 >> iter 25000, loss: 0.019685
 >> iter 26000, loss: 0.019339
 >> iter 27000, loss: 0.019571
 >> iter 28000, loss: 0.019271
 >> iter 29000, loss: 0.019523
 >> iter 30000, loss: 0.019265
   Number of active neurons: 5
 >> iter 31000, loss: 0.019525
 >> iter 32000, loss: 0.019250
 >> iter 33000, loss: 0.019494
 >> iter 34000, loss: 0.019265
 >> iter 35000, loss: 0.019499
 >> iter 36000, loss: 0.019294
 >> iter 37000, loss: 0.019527
 >> iter 38000, loss: 0.019331
 >> iter 39000, loss: 0.019538
 >> iter 40000, loss: 0.019358
   Number of active neurons: 5
 >> iter 41000, loss: 0.019520
 >> iter 42000, loss: 0.019340
 >> iter 43000, loss: 0.019520
 >> iter 44000, loss: 0.019373
 >> iter 45000, loss: 0.019550
 >> iter 46000, loss: 0.019397
 >> iter 47000, loss: 0.019587
 >> iter 48000, loss: 0.019432
 >> iter 49000, loss: 0.019634
 >> iter 50000, loss: 0.019470
   Number of active neurons: 5
 >> iter 51000, loss: 0.019669
 >> iter 52000, loss: 0.019532
 >> iter 53000, loss: 0.019705
 >> iter 54000, loss: 0.019595
 >> iter 55000, loss: 0.019761
 >> iter 56000, loss: 0.019649
 >> iter 57000, loss: 0.019806
 >> iter 58000, loss: 0.019703
 >> iter 59000, loss: 0.019863
 >> iter 60000, loss: 0.019764
   Number of active neurons: 5
 >> iter 61000, loss: 0.019946
 >> iter 62000, loss: 0.019819
 >> iter 63000, loss: 0.019990
 >> iter 64000, loss: 0.019881
 >> iter 65000, loss: 0.020040
 >> iter 66000, loss: 0.019937
 >> iter 67000, loss: 0.020090
 >> iter 68000, loss: 0.019994
 >> iter 69000, loss: 0.020118
 >> iter 70000, loss: 0.020022
   Number of active neurons: 5
 >> iter 71000, loss: 0.020115
 >> iter 72000, loss: 0.019893
 >> iter 73000, loss: 0.019867
 >> iter 74000, loss: 0.019622
 >> iter 75000, loss: 0.019604
 >> iter 76000, loss: 0.019382
 >> iter 77000, loss: 0.019298
 >> iter 78000, loss: 0.018968
 >> iter 79000, loss: 0.018818
 >> iter 80000, loss: 0.018475
   Number of active neurons: 4
 >> iter 81000, loss: 0.018294
 >> iter 82000, loss: 0.017894
 >> iter 83000, loss: 0.017640
 >> iter 84000, loss: 0.017260
 >> iter 85000, loss: 0.017089
 >> iter 86000, loss: 0.016823
 >> iter 87000, loss: 0.016739
 >> iter 88000, loss: 0.016558
 >> iter 89000, loss: 0.016516
 >> iter 90000, loss: 0.016368
   Number of active neurons: 4
 >> iter 91000, loss: 0.016348
 >> iter 92000, loss: 0.016234
 >> iter 93000, loss: 0.016232
 >> iter 94000, loss: 0.016125
 >> iter 95000, loss: 0.016140
 >> iter 96000, loss: 0.016037
 >> iter 97000, loss: 0.016059
 >> iter 98000, loss: 0.015959
 >> iter 99000, loss: 0.015991
 >> iter 100000, loss: 0.015904
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.824173
 >> iter 2000, loss: 4.007780
 >> iter 3000, loss: 1.493655
 >> iter 4000, loss: 0.565888
 >> iter 5000, loss: 0.224257
 >> iter 6000, loss: 0.097583
 >> iter 7000, loss: 0.051021
 >> iter 8000, loss: 0.033282
 >> iter 9000, loss: 0.027072
 >> iter 10000, loss: 0.024315
   Number of active neurons: 3
 >> iter 11000, loss: 0.023624
 >> iter 12000, loss: 0.022889
 >> iter 13000, loss: 0.022912
 >> iter 14000, loss: 0.022393
 >> iter 15000, loss: 0.022453
 >> iter 16000, loss: 0.021720
 >> iter 17000, loss: 0.021762
 >> iter 18000, loss: 0.021111
 >> iter 19000, loss: 0.021190
 >> iter 20000, loss: 0.020547
   Number of active neurons: 3
 >> iter 21000, loss: 0.020620
 >> iter 22000, loss: 0.020075
 >> iter 23000, loss: 0.020258
 >> iter 24000, loss: 0.019756
 >> iter 25000, loss: 0.019878
 >> iter 26000, loss: 0.019459
 >> iter 27000, loss: 0.019644
 >> iter 28000, loss: 0.019298
 >> iter 29000, loss: 0.019514
 >> iter 30000, loss: 0.019227
   Number of active neurons: 3
 >> iter 31000, loss: 0.019454
 >> iter 32000, loss: 0.019187
 >> iter 33000, loss: 0.019416
 >> iter 34000, loss: 0.019189
 >> iter 35000, loss: 0.019395
 >> iter 36000, loss: 0.019187
 >> iter 37000, loss: 0.019393
 >> iter 38000, loss: 0.019191
 >> iter 39000, loss: 0.019362
 >> iter 40000, loss: 0.019181
   Number of active neurons: 3
 >> iter 41000, loss: 0.019326
 >> iter 42000, loss: 0.019150
 >> iter 43000, loss: 0.019302
 >> iter 44000, loss: 0.019159
 >> iter 45000, loss: 0.019334
 >> iter 46000, loss: 0.019193
 >> iter 47000, loss: 0.019377
 >> iter 48000, loss: 0.019228
 >> iter 49000, loss: 0.019419
 >> iter 50000, loss: 0.019257
   Number of active neurons: 3
 >> iter 51000, loss: 0.019441
 >> iter 52000, loss: 0.019303
 >> iter 53000, loss: 0.019458
 >> iter 54000, loss: 0.019348
 >> iter 55000, loss: 0.019495
 >> iter 56000, loss: 0.019382
 >> iter 57000, loss: 0.019520
 >> iter 58000, loss: 0.019416
 >> iter 59000, loss: 0.019556
 >> iter 60000, loss: 0.019457
   Number of active neurons: 3
 >> iter 61000, loss: 0.019619
 >> iter 62000, loss: 0.019495
 >> iter 63000, loss: 0.019648
 >> iter 64000, loss: 0.019544
 >> iter 65000, loss: 0.019686
 >> iter 66000, loss: 0.019594
 >> iter 67000, loss: 0.019734
 >> iter 68000, loss: 0.019655
 >> iter 69000, loss: 0.019775
 >> iter 70000, loss: 0.019706
   Number of active neurons: 3
 >> iter 71000, loss: 0.019819
 >> iter 72000, loss: 0.019755
 >> iter 73000, loss: 0.019894
 >> iter 74000, loss: 0.019817
 >> iter 75000, loss: 0.019948
 >> iter 76000, loss: 0.019878
 >> iter 77000, loss: 0.020003
 >> iter 78000, loss: 0.019925
 >> iter 79000, loss: 0.020051
 >> iter 80000, loss: 0.019961
   Number of active neurons: 3
 >> iter 81000, loss: 0.020090
 >> iter 82000, loss: 0.019991
 >> iter 83000, loss: 0.020109
 >> iter 84000, loss: 0.019916
 >> iter 85000, loss: 0.019869
 >> iter 86000, loss: 0.019633
 >> iter 87000, loss: 0.019598
 >> iter 88000, loss: 0.019401
 >> iter 89000, loss: 0.019327
 >> iter 90000, loss: 0.019025
   Number of active neurons: 2
 >> iter 91000, loss: 0.018852
 >> iter 92000, loss: 0.018555
 >> iter 93000, loss: 0.018351
 >> iter 94000, loss: 0.018000
 >> iter 95000, loss: 0.017725
 >> iter 96000, loss: 0.017349
 >> iter 97000, loss: 0.017150
 >> iter 98000, loss: 0.016881
 >> iter 99000, loss: 0.016782
 >> iter 100000, loss: 0.016595
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.806177
 >> iter 2000, loss: 4.003336
 >> iter 3000, loss: 1.493102
 >> iter 4000, loss: 0.566869
 >> iter 5000, loss: 0.225336
 >> iter 6000, loss: 0.098258
 >> iter 7000, loss: 0.051204
 >> iter 8000, loss: 0.032999
 >> iter 9000, loss: 0.026431
 >> iter 10000, loss: 0.023332
   Number of active neurons: 4
 >> iter 11000, loss: 0.022270
 >> iter 12000, loss: 0.021171
 >> iter 13000, loss: 0.021017
 >> iter 14000, loss: 0.020478
 >> iter 15000, loss: 0.020672
 >> iter 16000, loss: 0.020257
 >> iter 17000, loss: 0.020522
 >> iter 18000, loss: 0.020162
 >> iter 19000, loss: 0.020462
 >> iter 20000, loss: 0.020135
   Number of active neurons: 4
 >> iter 21000, loss: 0.020432
 >> iter 22000, loss: 0.020085
 >> iter 23000, loss: 0.020291
 >> iter 24000, loss: 0.019925
 >> iter 25000, loss: 0.020160
 >> iter 26000, loss: 0.019837
 >> iter 27000, loss: 0.020108
 >> iter 28000, loss: 0.019812
 >> iter 29000, loss: 0.020097
 >> iter 30000, loss: 0.019835
   Number of active neurons: 4
 >> iter 31000, loss: 0.020124
 >> iter 32000, loss: 0.019868
 >> iter 33000, loss: 0.020153
 >> iter 34000, loss: 0.019926
 >> iter 35000, loss: 0.020186
 >> iter 36000, loss: 0.019968
 >> iter 37000, loss: 0.020201
 >> iter 38000, loss: 0.019966
 >> iter 39000, loss: 0.020181
 >> iter 40000, loss: 0.019996
   Number of active neurons: 4
 >> iter 41000, loss: 0.020191
 >> iter 42000, loss: 0.019999
 >> iter 43000, loss: 0.020194
 >> iter 44000, loss: 0.019922
 >> iter 45000, loss: 0.019953
 >> iter 46000, loss: 0.019632
 >> iter 47000, loss: 0.019683
 >> iter 48000, loss: 0.019377
 >> iter 49000, loss: 0.019399
 >> iter 50000, loss: 0.018984
   Number of active neurons: 3
 >> iter 51000, loss: 0.018912
 >> iter 52000, loss: 0.018510
 >> iter 53000, loss: 0.018379
 >> iter 54000, loss: 0.017948
 >> iter 55000, loss: 0.017731
 >> iter 56000, loss: 0.017305
 >> iter 57000, loss: 0.017168
 >> iter 58000, loss: 0.016860
 >> iter 59000, loss: 0.016814
 >> iter 60000, loss: 0.016579
   Number of active neurons: 3
 >> iter 61000, loss: 0.016600
 >> iter 62000, loss: 0.016387
 >> iter 63000, loss: 0.016425
 >> iter 64000, loss: 0.016250
 >> iter 65000, loss: 0.016296
 >> iter 66000, loss: 0.016142
 >> iter 67000, loss: 0.016195
 >> iter 68000, loss: 0.016062
 >> iter 69000, loss: 0.016103
 >> iter 70000, loss: 0.015985
   Number of active neurons: 3
 >> iter 71000, loss: 0.016025
 >> iter 72000, loss: 0.015916
 >> iter 73000, loss: 0.015978
 >> iter 74000, loss: 0.015866
 >> iter 75000, loss: 0.015923
 >> iter 76000, loss: 0.015822
 >> iter 77000, loss: 0.015877
 >> iter 78000, loss: 0.015777
 >> iter 79000, loss: 0.015837
 >> iter 80000, loss: 0.015734
   Number of active neurons: 3
 >> iter 81000, loss: 0.015802
 >> iter 82000, loss: 0.015701
 >> iter 83000, loss: 0.015772
 >> iter 84000, loss: 0.015680
 >> iter 85000, loss: 0.015739
 >> iter 86000, loss: 0.015653
 >> iter 87000, loss: 0.015711
 >> iter 88000, loss: 0.015645
 >> iter 89000, loss: 0.015695
 >> iter 90000, loss: 0.015625
   Number of active neurons: 3
 >> iter 91000, loss: 0.015670
 >> iter 92000, loss: 0.015616
 >> iter 93000, loss: 0.015663
 >> iter 94000, loss: 0.015602
 >> iter 95000, loss: 0.015656
 >> iter 96000, loss: 0.015592
 >> iter 97000, loss: 0.015646
 >> iter 98000, loss: 0.015579
 >> iter 99000, loss: 0.015637
 >> iter 100000, loss: 0.015577
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.854354
 >> iter 2000, loss: 4.020898
 >> iter 3000, loss: 1.500685
 >> iter 4000, loss: 0.571309
 >> iter 5000, loss: 0.229250
 >> iter 6000, loss: 0.102377
 >> iter 7000, loss: 0.055740
 >> iter 8000, loss: 0.037621
 >> iter 9000, loss: 0.030982
 >> iter 10000, loss: 0.027718
   Number of active neurons: 4
 >> iter 11000, loss: 0.026695
 >> iter 12000, loss: 0.025722
 >> iter 13000, loss: 0.025682
 >> iter 14000, loss: 0.025121
 >> iter 15000, loss: 0.025267
 >> iter 16000, loss: 0.024555
 >> iter 17000, loss: 0.024629
 >> iter 18000, loss: 0.023991
 >> iter 19000, loss: 0.024149
 >> iter 20000, loss: 0.023573
   Number of active neurons: 4
 >> iter 21000, loss: 0.023760
 >> iter 22000, loss: 0.023301
 >> iter 23000, loss: 0.023601
 >> iter 24000, loss: 0.023223
 >> iter 25000, loss: 0.023509
 >> iter 26000, loss: 0.023091
 >> iter 27000, loss: 0.023385
 >> iter 28000, loss: 0.023023
 >> iter 29000, loss: 0.023351
 >> iter 30000, loss: 0.023048
   Number of active neurons: 4
 >> iter 31000, loss: 0.023390
 >> iter 32000, loss: 0.023098
 >> iter 33000, loss: 0.023435
 >> iter 34000, loss: 0.023177
 >> iter 35000, loss: 0.023481
 >> iter 36000, loss: 0.023234
 >> iter 37000, loss: 0.023523
 >> iter 38000, loss: 0.023246
 >> iter 39000, loss: 0.023429
 >> iter 40000, loss: 0.023035
   Number of active neurons: 2
 >> iter 41000, loss: 0.023066
 >> iter 42000, loss: 0.022662
 >> iter 43000, loss: 0.022569
 >> iter 44000, loss: 0.021969
 >> iter 45000, loss: 0.021735
 >> iter 46000, loss: 0.021121
 >> iter 47000, loss: 0.020777
 >> iter 48000, loss: 0.020021
 >> iter 49000, loss: 0.019657
 >> iter 50000, loss: 0.018983
   Number of active neurons: 2
 >> iter 51000, loss: 0.018657
 >> iter 52000, loss: 0.018056
 >> iter 53000, loss: 0.017815
 >> iter 54000, loss: 0.017399
 >> iter 55000, loss: 0.017289
 >> iter 56000, loss: 0.016986
 >> iter 57000, loss: 0.016948
 >> iter 58000, loss: 0.016712
 >> iter 59000, loss: 0.016718
 >> iter 60000, loss: 0.016518
   Number of active neurons: 2
 >> iter 61000, loss: 0.016562
 >> iter 62000, loss: 0.016365
 >> iter 63000, loss: 0.016415
 >> iter 64000, loss: 0.016246
 >> iter 65000, loss: 0.016297
 >> iter 66000, loss: 0.016146
 >> iter 67000, loss: 0.016201
 >> iter 68000, loss: 0.016068
 >> iter 69000, loss: 0.016110
 >> iter 70000, loss: 0.015992
   Number of active neurons: 2
 >> iter 71000, loss: 0.016032
 >> iter 72000, loss: 0.015923
 >> iter 73000, loss: 0.015984
 >> iter 74000, loss: 0.015873
 >> iter 75000, loss: 0.015930
 >> iter 76000, loss: 0.015828
 >> iter 77000, loss: 0.015882
 >> iter 78000, loss: 0.015782
 >> iter 79000, loss: 0.015842
 >> iter 80000, loss: 0.015738
   Number of active neurons: 2
 >> iter 81000, loss: 0.015806
 >> iter 82000, loss: 0.015706
 >> iter 83000, loss: 0.015775
 >> iter 84000, loss: 0.015684
 >> iter 85000, loss: 0.015742
 >> iter 86000, loss: 0.015657
 >> iter 87000, loss: 0.015714
 >> iter 88000, loss: 0.015648
 >> iter 89000, loss: 0.015697
 >> iter 90000, loss: 0.015628
   Number of active neurons: 2
 >> iter 91000, loss: 0.015673
 >> iter 92000, loss: 0.015618
 >> iter 93000, loss: 0.015665
 >> iter 94000, loss: 0.015604
 >> iter 95000, loss: 0.015658
 >> iter 96000, loss: 0.015593
 >> iter 97000, loss: 0.015648
 >> iter 98000, loss: 0.015580
 >> iter 99000, loss: 0.015638
 >> iter 100000, loss: 0.015579
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.867503
 >> iter 2000, loss: 4.025913
 >> iter 3000, loss: 1.502728
 >> iter 4000, loss: 0.572148
 >> iter 5000, loss: 0.229439
 >> iter 6000, loss: 0.101911
 >> iter 7000, loss: 0.054893
 >> iter 8000, loss: 0.036414
 >> iter 9000, loss: 0.029432
 >> iter 10000, loss: 0.025911
   Number of active neurons: 5
 >> iter 11000, loss: 0.024764
 >> iter 12000, loss: 0.023777
 >> iter 13000, loss: 0.023820
 >> iter 14000, loss: 0.023398
 >> iter 15000, loss: 0.023748
 >> iter 16000, loss: 0.023393
 >> iter 17000, loss: 0.023779
 >> iter 18000, loss: 0.023442
 >> iter 19000, loss: 0.023835
 >> iter 20000, loss: 0.023515
   Number of active neurons: 5
 >> iter 21000, loss: 0.023888
 >> iter 22000, loss: 0.023564
 >> iter 23000, loss: 0.023919
 >> iter 24000, loss: 0.023519
 >> iter 25000, loss: 0.023797
 >> iter 26000, loss: 0.023419
 >> iter 27000, loss: 0.023724
 >> iter 28000, loss: 0.023357
 >> iter 29000, loss: 0.023615
 >> iter 30000, loss: 0.023131
   Number of active neurons: 3
 >> iter 31000, loss: 0.023200
 >> iter 32000, loss: 0.022577
 >> iter 33000, loss: 0.022505
 >> iter 34000, loss: 0.021826
 >> iter 35000, loss: 0.021576
 >> iter 36000, loss: 0.020779
 >> iter 37000, loss: 0.020387
 >> iter 38000, loss: 0.019560
 >> iter 39000, loss: 0.019145
 >> iter 40000, loss: 0.018423
   Number of active neurons: 3
 >> iter 41000, loss: 0.018111
 >> iter 42000, loss: 0.017583
 >> iter 43000, loss: 0.017456
 >> iter 44000, loss: 0.017092
 >> iter 45000, loss: 0.017062
 >> iter 46000, loss: 0.016770
 >> iter 47000, loss: 0.016800
 >> iter 48000, loss: 0.016549
 >> iter 49000, loss: 0.016617
 >> iter 50000, loss: 0.016382
   Number of active neurons: 3
 >> iter 51000, loss: 0.016464
 >> iter 52000, loss: 0.016264
 >> iter 53000, loss: 0.016336
 >> iter 54000, loss: 0.016169
 >> iter 55000, loss: 0.016241
 >> iter 56000, loss: 0.016081
 >> iter 57000, loss: 0.016151
 >> iter 58000, loss: 0.016005
 >> iter 59000, loss: 0.016080
 >> iter 60000, loss: 0.015941
   Number of active neurons: 3
 >> iter 61000, loss: 0.016036
 >> iter 62000, loss: 0.015884
 >> iter 63000, loss: 0.015972
 >> iter 64000, loss: 0.015839
 >> iter 65000, loss: 0.015921
 >> iter 66000, loss: 0.015800
 >> iter 67000, loss: 0.015880
 >> iter 68000, loss: 0.015773
 >> iter 69000, loss: 0.015836
 >> iter 70000, loss: 0.015739
   Number of active neurons: 3
 >> iter 71000, loss: 0.015798
 >> iter 72000, loss: 0.015706
 >> iter 73000, loss: 0.015784
 >> iter 74000, loss: 0.015687
 >> iter 75000, loss: 0.015758
 >> iter 76000, loss: 0.015668
 >> iter 77000, loss: 0.015735
 >> iter 78000, loss: 0.015645
 >> iter 79000, loss: 0.015715
 >> iter 80000, loss: 0.015621
   Number of active neurons: 3
 >> iter 81000, loss: 0.015697
 >> iter 82000, loss: 0.015604
 >> iter 83000, loss: 0.015681
 >> iter 84000, loss: 0.015596
 >> iter 85000, loss: 0.015661
 >> iter 86000, loss: 0.015581
 >> iter 87000, loss: 0.015644
 >> iter 88000, loss: 0.015582
 >> iter 89000, loss: 0.015637
 >> iter 90000, loss: 0.015571
   Number of active neurons: 3
 >> iter 91000, loss: 0.015620
 >> iter 92000, loss: 0.015569
 >> iter 93000, loss: 0.015619
 >> iter 94000, loss: 0.015561
 >> iter 95000, loss: 0.015619
 >> iter 96000, loss: 0.015556
 >> iter 97000, loss: 0.015613
 >> iter 98000, loss: 0.015548
 >> iter 99000, loss: 0.015609
 >> iter 100000, loss: 0.015550
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.863081
 >> iter 2000, loss: 4.024122
 >> iter 3000, loss: 1.501971
 >> iter 4000, loss: 0.571789
 >> iter 5000, loss: 0.229404
 >> iter 6000, loss: 0.102348
 >> iter 7000, loss: 0.055582
 >> iter 8000, loss: 0.037455
 >> iter 9000, loss: 0.030998
 >> iter 10000, loss: 0.027966
   Number of active neurons: 5
 >> iter 11000, loss: 0.027138
 >> iter 12000, loss: 0.026242
 >> iter 13000, loss: 0.026310
 >> iter 14000, loss: 0.025848
 >> iter 15000, loss: 0.026189
 >> iter 16000, loss: 0.025745
 >> iter 17000, loss: 0.026117
 >> iter 18000, loss: 0.025705
 >> iter 19000, loss: 0.026071
 >> iter 20000, loss: 0.025648
   Number of active neurons: 3
 >> iter 21000, loss: 0.025925
 >> iter 22000, loss: 0.025335
 >> iter 23000, loss: 0.025412
 >> iter 24000, loss: 0.024620
 >> iter 25000, loss: 0.024405
 >> iter 26000, loss: 0.023513
 >> iter 27000, loss: 0.023280
 >> iter 28000, loss: 0.022426
 >> iter 29000, loss: 0.022223
 >> iter 30000, loss: 0.021491
   Number of active neurons: 3
 >> iter 31000, loss: 0.021425
 >> iter 32000, loss: 0.020899
 >> iter 33000, loss: 0.021002
 >> iter 34000, loss: 0.020635
 >> iter 35000, loss: 0.020779
 >> iter 36000, loss: 0.020445
 >> iter 37000, loss: 0.020606
 >> iter 38000, loss: 0.020322
 >> iter 39000, loss: 0.020496
 >> iter 40000, loss: 0.020264
   Number of active neurons: 2
 >> iter 41000, loss: 0.020316
 >> iter 42000, loss: 0.019940
 >> iter 43000, loss: 0.019954
 >> iter 44000, loss: 0.019626
 >> iter 45000, loss: 0.019633
 >> iter 46000, loss: 0.019228
 >> iter 47000, loss: 0.019133
 >> iter 48000, loss: 0.018698
 >> iter 49000, loss: 0.018588
 >> iter 50000, loss: 0.018107
   Number of active neurons: 2
 >> iter 51000, loss: 0.017914
 >> iter 52000, loss: 0.017441
 >> iter 53000, loss: 0.017301
 >> iter 54000, loss: 0.016966
 >> iter 55000, loss: 0.016915
 >> iter 56000, loss: 0.016659
 >> iter 57000, loss: 0.016657
 >> iter 58000, loss: 0.016452
 >> iter 59000, loss: 0.016480
 >> iter 60000, loss: 0.016302
   Number of active neurons: 2
 >> iter 61000, loss: 0.016363
 >> iter 62000, loss: 0.016182
 >> iter 63000, loss: 0.016246
 >> iter 64000, loss: 0.016091
 >> iter 65000, loss: 0.016153
 >> iter 66000, loss: 0.016013
 >> iter 67000, loss: 0.016077
 >> iter 68000, loss: 0.015954
 >> iter 69000, loss: 0.016004
 >> iter 70000, loss: 0.015894
   Number of active neurons: 2
 >> iter 71000, loss: 0.015941
 >> iter 72000, loss: 0.015839
 >> iter 73000, loss: 0.015906
 >> iter 74000, loss: 0.015801
 >> iter 75000, loss: 0.015863
 >> iter 76000, loss: 0.015766
 >> iter 77000, loss: 0.015825
 >> iter 78000, loss: 0.015729
 >> iter 79000, loss: 0.015793
 >> iter 80000, loss: 0.015693
   Number of active neurons: 2
 >> iter 81000, loss: 0.015764
 >> iter 82000, loss: 0.015667
 >> iter 83000, loss: 0.015739
 >> iter 84000, loss: 0.015650
 >> iter 85000, loss: 0.015710
 >> iter 86000, loss: 0.015628
 >> iter 87000, loss: 0.015687
 >> iter 88000, loss: 0.015623
 >> iter 89000, loss: 0.015674
 >> iter 90000, loss: 0.015606
   Number of active neurons: 2
 >> iter 91000, loss: 0.015653
 >> iter 92000, loss: 0.015599
 >> iter 93000, loss: 0.015647
 >> iter 94000, loss: 0.015588
 >> iter 95000, loss: 0.015643
 >> iter 96000, loss: 0.015579
 >> iter 97000, loss: 0.015635
 >> iter 98000, loss: 0.015568
 >> iter 99000, loss: 0.015627
 >> iter 100000, loss: 0.015568
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.803251
 >> iter 2000, loss: 4.001159
 >> iter 3000, loss: 1.492675
 >> iter 4000, loss: 0.567332
 >> iter 5000, loss: 0.226234
 >> iter 6000, loss: 0.099521
 >> iter 7000, loss: 0.053044
 >> iter 8000, loss: 0.035384
 >> iter 9000, loss: 0.029095
 >> iter 10000, loss: 0.026184
   Number of active neurons: 5
 >> iter 11000, loss: 0.025428
 >> iter 12000, loss: 0.024548
 >> iter 13000, loss: 0.024527
 >> iter 14000, loss: 0.023954
 >> iter 15000, loss: 0.024179
 >> iter 16000, loss: 0.023577
 >> iter 17000, loss: 0.023747
 >> iter 18000, loss: 0.023148
 >> iter 19000, loss: 0.023381
 >> iter 20000, loss: 0.022927
   Number of active neurons: 5
 >> iter 21000, loss: 0.023243
 >> iter 22000, loss: 0.022884
 >> iter 23000, loss: 0.023256
 >> iter 24000, loss: 0.022903
 >> iter 25000, loss: 0.023179
 >> iter 26000, loss: 0.022786
 >> iter 27000, loss: 0.023068
 >> iter 28000, loss: 0.022693
 >> iter 29000, loss: 0.022968
 >> iter 30000, loss: 0.022601
   Number of active neurons: 4
 >> iter 31000, loss: 0.022742
 >> iter 32000, loss: 0.022249
 >> iter 33000, loss: 0.022357
 >> iter 34000, loss: 0.021872
 >> iter 35000, loss: 0.021897
 >> iter 36000, loss: 0.021440
 >> iter 37000, loss: 0.021449
 >> iter 38000, loss: 0.020940
 >> iter 39000, loss: 0.020882
 >> iter 40000, loss: 0.020493
   Number of active neurons: 4
 >> iter 41000, loss: 0.020542
 >> iter 42000, loss: 0.020262
 >> iter 43000, loss: 0.020402
 >> iter 44000, loss: 0.020199
 >> iter 45000, loss: 0.020365
 >> iter 46000, loss: 0.020171
 >> iter 47000, loss: 0.020358
 >> iter 48000, loss: 0.020163
 >> iter 49000, loss: 0.020362
 >> iter 50000, loss: 0.020148
   Number of active neurons: 3
 >> iter 51000, loss: 0.020294
 >> iter 52000, loss: 0.019963
 >> iter 53000, loss: 0.019963
 >> iter 54000, loss: 0.019667
 >> iter 55000, loss: 0.019670
 >> iter 56000, loss: 0.019362
 >> iter 57000, loss: 0.019251
 >> iter 58000, loss: 0.018870
 >> iter 59000, loss: 0.018735
 >> iter 60000, loss: 0.018340
   Number of active neurons: 3
 >> iter 61000, loss: 0.018160
 >> iter 62000, loss: 0.017681
 >> iter 63000, loss: 0.017483
 >> iter 64000, loss: 0.017114
 >> iter 65000, loss: 0.017017
 >> iter 66000, loss: 0.016751
 >> iter 67000, loss: 0.016722
 >> iter 68000, loss: 0.016522
 >> iter 69000, loss: 0.016513
 >> iter 70000, loss: 0.016351
   Number of active neurons: 3
 >> iter 71000, loss: 0.016358
 >> iter 72000, loss: 0.016217
 >> iter 73000, loss: 0.016254
 >> iter 74000, loss: 0.016119
 >> iter 75000, loss: 0.016157
 >> iter 76000, loss: 0.016036
 >> iter 77000, loss: 0.016076
 >> iter 78000, loss: 0.015959
 >> iter 79000, loss: 0.016007
 >> iter 80000, loss: 0.015889
   Number of active neurons: 3
 >> iter 81000, loss: 0.015948
 >> iter 82000, loss: 0.015835
 >> iter 83000, loss: 0.015897
 >> iter 84000, loss: 0.015794
 >> iter 85000, loss: 0.015846
 >> iter 86000, loss: 0.015752
 >> iter 87000, loss: 0.015804
 >> iter 88000, loss: 0.015730
 >> iter 89000, loss: 0.015774
 >> iter 90000, loss: 0.015698
   Number of active neurons: 3
 >> iter 91000, loss: 0.015739
 >> iter 92000, loss: 0.015678
 >> iter 93000, loss: 0.015722
 >> iter 94000, loss: 0.015656
 >> iter 95000, loss: 0.015708
 >> iter 96000, loss: 0.015638
 >> iter 97000, loss: 0.015691
 >> iter 98000, loss: 0.015619
 >> iter 99000, loss: 0.015676
 >> iter 100000, loss: 0.015613
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

