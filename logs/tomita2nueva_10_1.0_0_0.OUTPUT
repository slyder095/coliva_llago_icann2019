 > Problema: tomita2nueva
 > Args:
   - Hidden size: 10
   - Noise level: 1.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.702031
 >> iter 2000, loss: 4.934974
 >> iter 3000, loss: 2.120826
 >> iter 4000, loss: 0.952635
 >> iter 5000, loss: 0.502100
 >> iter 6000, loss: 0.295202
 >> iter 7000, loss: 0.183715
 >> iter 8000, loss: 0.117726
 >> iter 9000, loss: 0.107461
 >> iter 10000, loss: 0.076539
   Number of active neurons: 10
 >> iter 11000, loss: 0.089297
 >> iter 12000, loss: 0.060322
 >> iter 13000, loss: 0.053546
 >> iter 14000, loss: 0.050967
 >> iter 15000, loss: 0.039576
 >> iter 16000, loss: 0.036933
 >> iter 17000, loss: 0.019905
 >> iter 18000, loss: 0.018059
 >> iter 19000, loss: 0.031242
 >> iter 20000, loss: 0.022237
   Number of active neurons: 10
 >> iter 21000, loss: 0.038859
 >> iter 22000, loss: 0.018373
 >> iter 23000, loss: 0.012196
 >> iter 24000, loss: 0.013597
 >> iter 25000, loss: 0.010450
 >> iter 26000, loss: 0.013643
 >> iter 27000, loss: 0.031143
 >> iter 28000, loss: 0.015698
 >> iter 29000, loss: 0.014276
 >> iter 30000, loss: 0.017410
   Number of active neurons: 10
 >> iter 31000, loss: 0.009348
 >> iter 32000, loss: 0.036101
 >> iter 33000, loss: 0.018471
 >> iter 34000, loss: 0.028097
 >> iter 35000, loss: 0.015452
 >> iter 36000, loss: 0.008225
 >> iter 37000, loss: 0.018661
 >> iter 38000, loss: 0.008811
 >> iter 39000, loss: 0.005574
 >> iter 40000, loss: 0.003750
   Number of active neurons: 10
 >> iter 41000, loss: 0.006295
 >> iter 42000, loss: 0.004053
 >> iter 43000, loss: 0.003668
 >> iter 44000, loss: 0.019567
 >> iter 45000, loss: 0.015599
 >> iter 46000, loss: 0.016204
 >> iter 47000, loss: 0.008324
 >> iter 48000, loss: 0.004389
 >> iter 49000, loss: 0.032432
 >> iter 50000, loss: 0.013561
   Number of active neurons: 10
 >> iter 51000, loss: 0.019361
 >> iter 52000, loss: 0.016302
 >> iter 53000, loss: 0.017110
 >> iter 54000, loss: 0.008538
 >> iter 55000, loss: 0.017271
 >> iter 56000, loss: 0.010584
 >> iter 57000, loss: 0.004931
 >> iter 58000, loss: 0.003375
 >> iter 59000, loss: 0.005496
 >> iter 60000, loss: 0.003320
   Number of active neurons: 10
 >> iter 61000, loss: 0.002484
 >> iter 62000, loss: 0.002947
 >> iter 63000, loss: 0.002183
 >> iter 64000, loss: 0.002913
 >> iter 65000, loss: 0.001977
 >> iter 66000, loss: 0.018855
 >> iter 67000, loss: 0.007941
 >> iter 68000, loss: 0.005148
 >> iter 69000, loss: 0.005280
 >> iter 70000, loss: 0.002703
   Number of active neurons: 10
 >> iter 71000, loss: 0.002555
 >> iter 72000, loss: 0.009086
 >> iter 73000, loss: 0.006087
 >> iter 74000, loss: 0.003068
 >> iter 75000, loss: 0.001923
 >> iter 76000, loss: 0.001443
 >> iter 77000, loss: 0.008124
 >> iter 78000, loss: 0.003614
 >> iter 79000, loss: 0.001982
 >> iter 80000, loss: 0.001276
   Number of active neurons: 10
 >> iter 81000, loss: 0.001272
 >> iter 82000, loss: 0.012868
 >> iter 83000, loss: 0.005450
 >> iter 84000, loss: 0.002596
 >> iter 85000, loss: 0.001452
 >> iter 86000, loss: 0.001104
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.753228
 >> iter 2000, loss: 4.921394
 >> iter 3000, loss: 2.108747
 >> iter 4000, loss: 0.902329
 >> iter 5000, loss: 0.456996
 >> iter 6000, loss: 0.257517
 >> iter 7000, loss: 0.184385
 >> iter 8000, loss: 0.111615
 >> iter 9000, loss: 0.091325
 >> iter 10000, loss: 0.063584
   Number of active neurons: 10
 >> iter 11000, loss: 0.051387
 >> iter 12000, loss: 0.050186
 >> iter 13000, loss: 0.048143
 >> iter 14000, loss: 0.039730
 >> iter 15000, loss: 0.035861
 >> iter 16000, loss: 0.019975
 >> iter 17000, loss: 0.020940
 >> iter 18000, loss: 0.024121
 >> iter 19000, loss: 0.022874
 >> iter 20000, loss: 0.014914
   Number of active neurons: 10
 >> iter 21000, loss: 0.010513
 >> iter 22000, loss: 0.020593
 >> iter 23000, loss: 0.014189
 >> iter 24000, loss: 0.016055
 >> iter 25000, loss: 0.008199
 >> iter 26000, loss: 0.008652
 >> iter 27000, loss: 0.005140
 >> iter 28000, loss: 0.032900
 >> iter 29000, loss: 0.016078
 >> iter 30000, loss: 0.010666
   Number of active neurons: 10
 >> iter 31000, loss: 0.011425
 >> iter 32000, loss: 0.019271
 >> iter 33000, loss: 0.028539
 >> iter 34000, loss: 0.012348
 >> iter 35000, loss: 0.013059
 >> iter 36000, loss: 0.013941
 >> iter 37000, loss: 0.008918
 >> iter 38000, loss: 0.012051
 >> iter 39000, loss: 0.009806
 >> iter 40000, loss: 0.020097
   Number of active neurons: 10
 >> iter 41000, loss: 0.019777
 >> iter 42000, loss: 0.008582
 >> iter 43000, loss: 0.004212
 >> iter 44000, loss: 0.003284
 >> iter 45000, loss: 0.003068
 >> iter 46000, loss: 0.002148
 >> iter 47000, loss: 0.001910
 >> iter 48000, loss: 0.003639
 >> iter 49000, loss: 0.007010
 >> iter 50000, loss: 0.003922
   Number of active neurons: 10
 >> iter 51000, loss: 0.002612
 >> iter 52000, loss: 0.002732
 >> iter 53000, loss: 0.003333
 >> iter 54000, loss: 0.002625
 >> iter 55000, loss: 0.001600
 >> iter 56000, loss: 0.001669
 >> iter 57000, loss: 0.002566
 >> iter 58000, loss: 0.001704
 >> iter 59000, loss: 0.001379
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 11.756248
 >> iter 2000, loss: 4.908309
 >> iter 3000, loss: 2.136348
 >> iter 4000, loss: 0.944528
 >> iter 5000, loss: 0.504376
 >> iter 6000, loss: 0.253903
 >> iter 7000, loss: 0.164711
 >> iter 8000, loss: 0.108677
 >> iter 9000, loss: 0.074117
 >> iter 10000, loss: 0.053233
   Number of active neurons: 10
 >> iter 11000, loss: 0.054733
 >> iter 12000, loss: 0.038228
 >> iter 13000, loss: 0.050365
 >> iter 14000, loss: 0.026845
 >> iter 15000, loss: 0.048475
 >> iter 16000, loss: 0.039018
 >> iter 17000, loss: 0.031428
 >> iter 18000, loss: 0.019957
 >> iter 19000, loss: 0.019144
 >> iter 20000, loss: 0.021788
   Number of active neurons: 10
 >> iter 21000, loss: 0.028046
 >> iter 22000, loss: 0.019165
 >> iter 23000, loss: 0.023472
 >> iter 24000, loss: 0.014087
 >> iter 25000, loss: 0.014245
 >> iter 26000, loss: 0.008648
 >> iter 27000, loss: 0.007193
 >> iter 28000, loss: 0.004811
 >> iter 29000, loss: 0.003970
 >> iter 30000, loss: 0.012874
   Number of active neurons: 10
 >> iter 31000, loss: 0.016274
 >> iter 32000, loss: 0.008430
 >> iter 33000, loss: 0.011188
 >> iter 34000, loss: 0.006153
 >> iter 35000, loss: 0.004065
 >> iter 36000, loss: 0.003056
 >> iter 37000, loss: 0.007869
 >> iter 38000, loss: 0.009186
 >> iter 39000, loss: 0.015160
 >> iter 40000, loss: 0.008356
   Number of active neurons: 10
 >> iter 41000, loss: 0.004575
 >> iter 42000, loss: 0.005676
 >> iter 43000, loss: 0.016536
 >> iter 44000, loss: 0.015792
 >> iter 45000, loss: 0.007020
 >> iter 46000, loss: 0.003617
 >> iter 47000, loss: 0.002362
 >> iter 48000, loss: 0.001867
 >> iter 49000, loss: 0.029472
 >> iter 50000, loss: 0.014643
   Number of active neurons: 10
 >> iter 51000, loss: 0.010854
 >> iter 52000, loss: 0.005098
 >> iter 53000, loss: 0.004417
 >> iter 54000, loss: 0.011970
 >> iter 55000, loss: 0.005978
 >> iter 56000, loss: 0.007301
 >> iter 57000, loss: 0.004397
 >> iter 58000, loss: 0.002608
 >> iter 59000, loss: 0.001705
 >> iter 60000, loss: 0.005861
   Number of active neurons: 10
 >> iter 61000, loss: 0.013962
 >> iter 62000, loss: 0.006464
 >> iter 63000, loss: 0.003600
 >> iter 64000, loss: 0.002216
 >> iter 65000, loss: 0.006546
 >> iter 66000, loss: 0.002876
 >> iter 67000, loss: 0.003004
 >> iter 68000, loss: 0.006595
 >> iter 69000, loss: 0.006051
 >> iter 70000, loss: 0.002954
   Number of active neurons: 10
 >> iter 71000, loss: 0.001836
 >> iter 72000, loss: 0.002752
 >> iter 73000, loss: 0.001535
 >> iter 74000, loss: 0.001407
 >> iter 75000, loss: 0.001442
 >> iter 76000, loss: 0.001101
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.738896
 >> iter 2000, loss: 4.867890
 >> iter 3000, loss: 2.062368
 >> iter 4000, loss: 0.921466
 >> iter 5000, loss: 0.416773
 >> iter 6000, loss: 0.240882
 >> iter 7000, loss: 0.167034
 >> iter 8000, loss: 0.152575
 >> iter 9000, loss: 0.106230
 >> iter 10000, loss: 0.073106
   Number of active neurons: 10
 >> iter 11000, loss: 0.087955
 >> iter 12000, loss: 0.055550
 >> iter 13000, loss: 0.043963
 >> iter 14000, loss: 0.022173
 >> iter 15000, loss: 0.028539
 >> iter 16000, loss: 0.032446
 >> iter 17000, loss: 0.043824
 >> iter 18000, loss: 0.032182
 >> iter 19000, loss: 0.018684
 >> iter 20000, loss: 0.020883
   Number of active neurons: 10
 >> iter 21000, loss: 0.017172
 >> iter 22000, loss: 0.027430
 >> iter 23000, loss: 0.038732
 >> iter 24000, loss: 0.021581
 >> iter 25000, loss: 0.025398
 >> iter 26000, loss: 0.018557
 >> iter 27000, loss: 0.011646
 >> iter 28000, loss: 0.007928
 >> iter 29000, loss: 0.024415
 >> iter 30000, loss: 0.020885
   Number of active neurons: 10
 >> iter 31000, loss: 0.013256
 >> iter 32000, loss: 0.012466
 >> iter 33000, loss: 0.007109
 >> iter 34000, loss: 0.008007
 >> iter 35000, loss: 0.005153
 >> iter 36000, loss: 0.023221
 >> iter 37000, loss: 0.024380
 >> iter 38000, loss: 0.016429
 >> iter 39000, loss: 0.011872
 >> iter 40000, loss: 0.012249
   Number of active neurons: 10
 >> iter 41000, loss: 0.008265
 >> iter 42000, loss: 0.026752
 >> iter 43000, loss: 0.013150
 >> iter 44000, loss: 0.023734
 >> iter 45000, loss: 0.022719
 >> iter 46000, loss: 0.009597
 >> iter 47000, loss: 0.008165
 >> iter 48000, loss: 0.005668
 >> iter 49000, loss: 0.003788
 >> iter 50000, loss: 0.003370
   Number of active neurons: 10
 >> iter 51000, loss: 0.002794
 >> iter 52000, loss: 0.009564
 >> iter 53000, loss: 0.007980
 >> iter 54000, loss: 0.003824
 >> iter 55000, loss: 0.002229
 >> iter 56000, loss: 0.002410
 >> iter 57000, loss: 0.011610
 >> iter 58000, loss: 0.005505
 >> iter 59000, loss: 0.002713
 >> iter 60000, loss: 0.001459
   Number of active neurons: 10
 >> iter 61000, loss: 0.001745
 >> iter 62000, loss: 0.005296
 >> iter 63000, loss: 0.006836
 >> iter 64000, loss: 0.003850
 >> iter 65000, loss: 0.001953
 >> iter 66000, loss: 0.001165
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.728237
 >> iter 2000, loss: 4.879605
 >> iter 3000, loss: 2.121987
 >> iter 4000, loss: 0.960734
 >> iter 5000, loss: 0.470831
 >> iter 6000, loss: 0.219043
 >> iter 7000, loss: 0.182234
 >> iter 8000, loss: 0.098844
 >> iter 9000, loss: 0.070791
 >> iter 10000, loss: 0.060089
   Number of active neurons: 10
 >> iter 11000, loss: 0.037917
 >> iter 12000, loss: 0.034576
 >> iter 13000, loss: 0.029890
 >> iter 14000, loss: 0.034958
 >> iter 15000, loss: 0.020288
 >> iter 16000, loss: 0.035178
 >> iter 17000, loss: 0.031651
 >> iter 18000, loss: 0.036362
 >> iter 19000, loss: 0.038824
 >> iter 20000, loss: 0.029042
   Number of active neurons: 10
 >> iter 21000, loss: 0.017005
 >> iter 22000, loss: 0.015379
 >> iter 23000, loss: 0.021615
 >> iter 24000, loss: 0.048432
 >> iter 25000, loss: 0.022522
 >> iter 26000, loss: 0.013314
 >> iter 27000, loss: 0.018273
 >> iter 28000, loss: 0.010297
 >> iter 29000, loss: 0.009234
 >> iter 30000, loss: 0.006775
   Number of active neurons: 10
 >> iter 31000, loss: 0.004388
 >> iter 32000, loss: 0.017231
 >> iter 33000, loss: 0.010069
 >> iter 34000, loss: 0.011659
 >> iter 35000, loss: 0.008206
 >> iter 36000, loss: 0.008496
 >> iter 37000, loss: 0.018501
 >> iter 38000, loss: 0.012786
 >> iter 39000, loss: 0.024179
 >> iter 40000, loss: 0.010766
   Number of active neurons: 10
 >> iter 41000, loss: 0.008890
 >> iter 42000, loss: 0.004929
 >> iter 43000, loss: 0.002813
 >> iter 44000, loss: 0.006390
 >> iter 45000, loss: 0.012090
 >> iter 46000, loss: 0.022975
 >> iter 47000, loss: 0.021763
 >> iter 48000, loss: 0.024453
 >> iter 49000, loss: 0.010756
 >> iter 50000, loss: 0.020599
   Number of active neurons: 10
 >> iter 51000, loss: 0.022568
 >> iter 52000, loss: 0.018053
 >> iter 53000, loss: 0.008308
 >> iter 54000, loss: 0.012276
 >> iter 55000, loss: 0.008023
 >> iter 56000, loss: 0.013362
 >> iter 57000, loss: 0.006058
 >> iter 58000, loss: 0.004797
 >> iter 59000, loss: 0.003449
 >> iter 60000, loss: 0.002445
   Number of active neurons: 10
 >> iter 61000, loss: 0.007358
 >> iter 62000, loss: 0.003940
 >> iter 63000, loss: 0.002776
 >> iter 64000, loss: 0.001704
 >> iter 65000, loss: 0.001820
 >> iter 66000, loss: 0.001612
 >> iter 67000, loss: 0.001241
 >> iter 68000, loss: 0.001861
 >> iter 69000, loss: 0.002290
 >> iter 70000, loss: 0.003613
   Number of active neurons: 10
 >> iter 71000, loss: 0.002737
 >> iter 72000, loss: 0.003742
 >> iter 73000, loss: 0.002276
 >> iter 74000, loss: 0.001626
 >> iter 75000, loss: 0.001632
 >> iter 76000, loss: 0.001639
 >> iter 77000, loss: 0.001055
 >> iter 78000, loss: 0.002302
 >> iter 79000, loss: 0.010019
 >> iter 80000, loss: 0.004833
   Number of active neurons: 10
 >> iter 81000, loss: 0.006818
 >> iter 82000, loss: 0.012231
 >> iter 83000, loss: 0.005612
 >> iter 84000, loss: 0.002840
 >> iter 85000, loss: 0.002227
 >> iter 86000, loss: 0.003351
 >> iter 87000, loss: 0.017845
 >> iter 88000, loss: 0.008393
 >> iter 89000, loss: 0.003916
 >> iter 90000, loss: 0.002115
   Number of active neurons: 10
 >> iter 91000, loss: 0.001879
 >> iter 92000, loss: 0.013027
 >> iter 93000, loss: 0.005622
 >> iter 94000, loss: 0.002601
 >> iter 95000, loss: 0.002631
 >> iter 96000, loss: 0.006091
 >> iter 97000, loss: 0.002597
 >> iter 98000, loss: 0.001336
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.697825
 >> iter 2000, loss: 4.843202
 >> iter 3000, loss: 2.102421
 >> iter 4000, loss: 0.927548
 >> iter 5000, loss: 0.485256
 >> iter 6000, loss: 0.289306
 >> iter 7000, loss: 0.175218
 >> iter 8000, loss: 0.126284
 >> iter 9000, loss: 0.104846
 >> iter 10000, loss: 0.106263
   Number of active neurons: 10
 >> iter 11000, loss: 0.056446
 >> iter 12000, loss: 0.063854
 >> iter 13000, loss: 0.053292
 >> iter 14000, loss: 0.060822
 >> iter 15000, loss: 0.038504
 >> iter 16000, loss: 0.045012
 >> iter 17000, loss: 0.024738
 >> iter 18000, loss: 0.022412
 >> iter 19000, loss: 0.023402
 >> iter 20000, loss: 0.038102
   Number of active neurons: 10
 >> iter 21000, loss: 0.036542
 >> iter 22000, loss: 0.020905
 >> iter 23000, loss: 0.014511
 >> iter 24000, loss: 0.025145
 >> iter 25000, loss: 0.019691
 >> iter 26000, loss: 0.030612
 >> iter 27000, loss: 0.022952
 >> iter 28000, loss: 0.011211
 >> iter 29000, loss: 0.012020
 >> iter 30000, loss: 0.019246
   Number of active neurons: 10
 >> iter 31000, loss: 0.009040
 >> iter 32000, loss: 0.005684
 >> iter 33000, loss: 0.007308
 >> iter 34000, loss: 0.007565
 >> iter 35000, loss: 0.013197
 >> iter 36000, loss: 0.007327
 >> iter 37000, loss: 0.008976
 >> iter 38000, loss: 0.004636
 >> iter 39000, loss: 0.004001
 >> iter 40000, loss: 0.003363
   Number of active neurons: 10
 >> iter 41000, loss: 0.005386
 >> iter 42000, loss: 0.017518
 >> iter 43000, loss: 0.013983
 >> iter 44000, loss: 0.006528
 >> iter 45000, loss: 0.004246
 >> iter 46000, loss: 0.002741
 >> iter 47000, loss: 0.007587
 >> iter 48000, loss: 0.005537
 >> iter 49000, loss: 0.012376
 >> iter 50000, loss: 0.040681
   Number of active neurons: 10
 >> iter 51000, loss: 0.016399
 >> iter 52000, loss: 0.019607
 >> iter 53000, loss: 0.018357
 >> iter 54000, loss: 0.007893
 >> iter 55000, loss: 0.006452
 >> iter 56000, loss: 0.008123
 >> iter 57000, loss: 0.005270
 >> iter 58000, loss: 0.006464
 >> iter 59000, loss: 0.004751
 >> iter 60000, loss: 0.004822
   Number of active neurons: 10
 >> iter 61000, loss: 0.002872
 >> iter 62000, loss: 0.006009
 >> iter 63000, loss: 0.005125
 >> iter 64000, loss: 0.003833
 >> iter 65000, loss: 0.002012
 >> iter 66000, loss: 0.001500
 >> iter 67000, loss: 0.001440
 >> iter 68000, loss: 0.002918
 >> iter 69000, loss: 0.006107
 >> iter 70000, loss: 0.004090
   Number of active neurons: 10
 >> iter 71000, loss: 0.001983
 >> iter 72000, loss: 0.001044
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.703373
 >> iter 2000, loss: 4.810518
 >> iter 3000, loss: 2.029989
 >> iter 4000, loss: 0.875112
 >> iter 5000, loss: 0.429208
 >> iter 6000, loss: 0.222190
 >> iter 7000, loss: 0.126802
 >> iter 8000, loss: 0.094413
 >> iter 9000, loss: 0.061870
 >> iter 10000, loss: 0.087792
   Number of active neurons: 10
 >> iter 11000, loss: 0.064423
 >> iter 12000, loss: 0.038181
 >> iter 13000, loss: 0.029339
 >> iter 14000, loss: 0.039531
 >> iter 15000, loss: 0.045911
 >> iter 16000, loss: 0.051482
 >> iter 17000, loss: 0.028289
 >> iter 18000, loss: 0.027828
 >> iter 19000, loss: 0.019037
 >> iter 20000, loss: 0.010698
   Number of active neurons: 10
 >> iter 21000, loss: 0.007541
 >> iter 22000, loss: 0.007689
 >> iter 23000, loss: 0.005289
 >> iter 24000, loss: 0.008371
 >> iter 25000, loss: 0.012574
 >> iter 26000, loss: 0.026657
 >> iter 27000, loss: 0.015908
 >> iter 28000, loss: 0.009599
 >> iter 29000, loss: 0.019138
 >> iter 30000, loss: 0.011726
   Number of active neurons: 10
 >> iter 31000, loss: 0.007942
 >> iter 32000, loss: 0.008892
 >> iter 33000, loss: 0.005622
 >> iter 34000, loss: 0.010285
 >> iter 35000, loss: 0.005985
 >> iter 36000, loss: 0.003515
 >> iter 37000, loss: 0.007532
 >> iter 38000, loss: 0.018501
 >> iter 39000, loss: 0.010161
 >> iter 40000, loss: 0.006318
   Number of active neurons: 10
 >> iter 41000, loss: 0.004078
 >> iter 42000, loss: 0.003351
 >> iter 43000, loss: 0.002044
 >> iter 44000, loss: 0.003458
 >> iter 45000, loss: 0.010989
 >> iter 46000, loss: 0.021030
 >> iter 47000, loss: 0.011506
 >> iter 48000, loss: 0.012161
 >> iter 49000, loss: 0.005409
 >> iter 50000, loss: 0.004415
   Number of active neurons: 10
 >> iter 51000, loss: 0.002756
 >> iter 52000, loss: 0.001810
 >> iter 53000, loss: 0.007235
 >> iter 54000, loss: 0.003873
 >> iter 55000, loss: 0.002111
 >> iter 56000, loss: 0.001709
 >> iter 57000, loss: 0.001469
 >> iter 58000, loss: 0.005685
 >> iter 59000, loss: 0.003332
 >> iter 60000, loss: 0.001663
   Number of active neurons: 10
 >> iter 61000, loss: 0.001275
 >> iter 62000, loss: 0.001521
 >> iter 63000, loss: 0.002530
 >> iter 64000, loss: 0.005534
 >> iter 65000, loss: 0.002546
 >> iter 66000, loss: 0.001775
 >> iter 67000, loss: 0.001089
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.733681
 >> iter 2000, loss: 4.846227
 >> iter 3000, loss: 2.095757
 >> iter 4000, loss: 0.943244
 >> iter 5000, loss: 0.502983
 >> iter 6000, loss: 0.282190
 >> iter 7000, loss: 0.153433
 >> iter 8000, loss: 0.117694
 >> iter 9000, loss: 0.075111
 >> iter 10000, loss: 0.059559
   Number of active neurons: 10
 >> iter 11000, loss: 0.054211
 >> iter 12000, loss: 0.033356
 >> iter 13000, loss: 0.042537
 >> iter 14000, loss: 0.031665
 >> iter 15000, loss: 0.018175
 >> iter 16000, loss: 0.029374
 >> iter 17000, loss: 0.022594
 >> iter 18000, loss: 0.030737
 >> iter 19000, loss: 0.020544
 >> iter 20000, loss: 0.031163
   Number of active neurons: 10
 >> iter 21000, loss: 0.017014
 >> iter 22000, loss: 0.010469
 >> iter 23000, loss: 0.009500
 >> iter 24000, loss: 0.011520
 >> iter 25000, loss: 0.010557
 >> iter 26000, loss: 0.015478
 >> iter 27000, loss: 0.013150
 >> iter 28000, loss: 0.009227
 >> iter 29000, loss: 0.008581
 >> iter 30000, loss: 0.005337
   Number of active neurons: 10
 >> iter 31000, loss: 0.054260
 >> iter 32000, loss: 0.021684
 >> iter 33000, loss: 0.011886
 >> iter 34000, loss: 0.010206
 >> iter 35000, loss: 0.006042
 >> iter 36000, loss: 0.005200
 >> iter 37000, loss: 0.015098
 >> iter 38000, loss: 0.012924
 >> iter 39000, loss: 0.009139
 >> iter 40000, loss: 0.015353
   Number of active neurons: 10
 >> iter 41000, loss: 0.022928
 >> iter 42000, loss: 0.015591
 >> iter 43000, loss: 0.020039
 >> iter 44000, loss: 0.009116
 >> iter 45000, loss: 0.017442
 >> iter 46000, loss: 0.021684
 >> iter 47000, loss: 0.016924
 >> iter 48000, loss: 0.015539
 >> iter 49000, loss: 0.012846
 >> iter 50000, loss: 0.006499
   Number of active neurons: 10
 >> iter 51000, loss: 0.005106
 >> iter 52000, loss: 0.002783
 >> iter 53000, loss: 0.002336
 >> iter 54000, loss: 0.011360
 >> iter 55000, loss: 0.009343
 >> iter 56000, loss: 0.004923
 >> iter 57000, loss: 0.003804
 >> iter 58000, loss: 0.002009
 >> iter 59000, loss: 0.001409
 >> iter 60000, loss: 0.001308
   Number of active neurons: 10
 >> iter 61000, loss: 0.003352
 >> iter 62000, loss: 0.005789
 >> iter 63000, loss: 0.002959
 >> iter 64000, loss: 0.003651
 >> iter 65000, loss: 0.002170
 >> iter 66000, loss: 0.010553
 >> iter 67000, loss: 0.005441
 >> iter 68000, loss: 0.003231
 >> iter 69000, loss: 0.006585
 >> iter 70000, loss: 0.003061
   Number of active neurons: 10
 >> iter 71000, loss: 0.002057
 >> iter 72000, loss: 0.001328
 >> iter 73000, loss: 0.001005
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 11.706933
 >> iter 2000, loss: 4.849080
 >> iter 3000, loss: 2.069600
 >> iter 4000, loss: 0.983803
 >> iter 5000, loss: 0.462284
 >> iter 6000, loss: 0.246331
 >> iter 7000, loss: 0.133547
 >> iter 8000, loss: 0.100741
 >> iter 9000, loss: 0.088494
 >> iter 10000, loss: 0.067879
   Number of active neurons: 10
 >> iter 11000, loss: 0.056655
 >> iter 12000, loss: 0.057697
 >> iter 13000, loss: 0.042117
 >> iter 14000, loss: 0.046546
 >> iter 15000, loss: 0.034676
 >> iter 16000, loss: 0.027860
 >> iter 17000, loss: 0.019600
 >> iter 18000, loss: 0.011732
 >> iter 19000, loss: 0.012561
 >> iter 20000, loss: 0.018573
   Number of active neurons: 10
 >> iter 21000, loss: 0.021008
 >> iter 22000, loss: 0.021769
 >> iter 23000, loss: 0.025717
 >> iter 24000, loss: 0.022100
 >> iter 25000, loss: 0.015143
 >> iter 26000, loss: 0.011784
 >> iter 27000, loss: 0.006110
 >> iter 28000, loss: 0.007649
 >> iter 29000, loss: 0.006412
 >> iter 30000, loss: 0.016681
   Number of active neurons: 10
 >> iter 31000, loss: 0.007998
 >> iter 32000, loss: 0.007454
 >> iter 33000, loss: 0.004615
 >> iter 34000, loss: 0.009280
 >> iter 35000, loss: 0.008713
 >> iter 36000, loss: 0.016028
 >> iter 37000, loss: 0.007216
 >> iter 38000, loss: 0.016120
 >> iter 39000, loss: 0.007387
 >> iter 40000, loss: 0.005234
   Number of active neurons: 10
 >> iter 41000, loss: 0.004408
 >> iter 42000, loss: 0.003734
 >> iter 43000, loss: 0.002472
 >> iter 44000, loss: 0.001807
 >> iter 45000, loss: 0.002347
 >> iter 46000, loss: 0.002102
 >> iter 47000, loss: 0.001814
 >> iter 48000, loss: 0.003808
 >> iter 49000, loss: 0.002393
 >> iter 50000, loss: 0.001498
   Number of active neurons: 10
 >> iter 51000, loss: 0.001313
 >> iter 52000, loss: 0.007160
 >> iter 53000, loss: 0.007247
 >> iter 54000, loss: 0.013652
 >> iter 55000, loss: 0.008958
 >> iter 56000, loss: 0.012200
 >> iter 57000, loss: 0.005247
 >> iter 58000, loss: 0.003335
 >> iter 59000, loss: 0.002198
 >> iter 60000, loss: 0.001381
   Number of active neurons: 10
 >> iter 61000, loss: 0.001345
 >> iter 62000, loss: 0.002187
 >> iter 63000, loss: 0.001492
 >> iter 64000, loss: 0.005106
 >> iter 65000, loss: 0.003990
 >> iter 66000, loss: 0.002673
 >> iter 67000, loss: 0.002426
 >> iter 68000, loss: 0.001563
 >> iter 69000, loss: 0.013282
 >> iter 70000, loss: 0.007108
   Number of active neurons: 10
 >> iter 71000, loss: 0.003332
 >> iter 72000, loss: 0.001959
 >> iter 73000, loss: 0.001309
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.716266
 >> iter 2000, loss: 4.886097
 >> iter 3000, loss: 2.088983
 >> iter 4000, loss: 0.941959
 >> iter 5000, loss: 0.482225
 >> iter 6000, loss: 0.240817
 >> iter 7000, loss: 0.154086
 >> iter 8000, loss: 0.128221
 >> iter 9000, loss: 0.090362
 >> iter 10000, loss: 0.102625
   Number of active neurons: 10
 >> iter 11000, loss: 0.057205
 >> iter 12000, loss: 0.070776
 >> iter 13000, loss: 0.045663
 >> iter 14000, loss: 0.039267
 >> iter 15000, loss: 0.028918
 >> iter 16000, loss: 0.041277
 >> iter 17000, loss: 0.021061
 >> iter 18000, loss: 0.015224
 >> iter 19000, loss: 0.018641
 >> iter 20000, loss: 0.015764
   Number of active neurons: 10
 >> iter 21000, loss: 0.008944
 >> iter 22000, loss: 0.014014
 >> iter 23000, loss: 0.011697
 >> iter 24000, loss: 0.027548
 >> iter 25000, loss: 0.030501
 >> iter 26000, loss: 0.022232
 >> iter 27000, loss: 0.023802
 >> iter 28000, loss: 0.013850
 >> iter 29000, loss: 0.008062
 >> iter 30000, loss: 0.019582
   Number of active neurons: 10
 >> iter 31000, loss: 0.009631
 >> iter 32000, loss: 0.048445
 >> iter 33000, loss: 0.030877
 >> iter 34000, loss: 0.013143
 >> iter 35000, loss: 0.005984
 >> iter 36000, loss: 0.008097
 >> iter 37000, loss: 0.009504
 >> iter 38000, loss: 0.005337
 >> iter 39000, loss: 0.003226
 >> iter 40000, loss: 0.005351
   Number of active neurons: 10
 >> iter 41000, loss: 0.007880
 >> iter 42000, loss: 0.004211
 >> iter 43000, loss: 0.002475
 >> iter 44000, loss: 0.015069
 >> iter 45000, loss: 0.031394
 >> iter 46000, loss: 0.016213
 >> iter 47000, loss: 0.026075
 >> iter 48000, loss: 0.012300
 >> iter 49000, loss: 0.011182
 >> iter 50000, loss: 0.013343
   Number of active neurons: 10
 >> iter 51000, loss: 0.006692
 >> iter 52000, loss: 0.014950
 >> iter 53000, loss: 0.006417
 >> iter 54000, loss: 0.003309
 >> iter 55000, loss: 0.012394
 >> iter 56000, loss: 0.023962
 >> iter 57000, loss: 0.014039
 >> iter 58000, loss: 0.007325
 >> iter 59000, loss: 0.004134
 >> iter 60000, loss: 0.002632
   Number of active neurons: 10
 >> iter 61000, loss: 0.001829
 >> iter 62000, loss: 0.001258
 >> iter 63000, loss: 0.001058
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.683956
 >> iter 2000, loss: 4.836489
 >> iter 3000, loss: 2.049598
 >> iter 4000, loss: 0.915355
 >> iter 5000, loss: 0.470182
 >> iter 6000, loss: 0.229954
 >> iter 7000, loss: 0.142545
 >> iter 8000, loss: 0.098939
 >> iter 9000, loss: 0.065918
 >> iter 10000, loss: 0.053509
   Number of active neurons: 10
 >> iter 11000, loss: 0.048931
 >> iter 12000, loss: 0.047582
 >> iter 13000, loss: 0.035643
 >> iter 14000, loss: 0.057182
 >> iter 15000, loss: 0.038377
 >> iter 16000, loss: 0.040760
 >> iter 17000, loss: 0.032700
 >> iter 18000, loss: 0.027800
 >> iter 19000, loss: 0.027242
 >> iter 20000, loss: 0.025918
   Number of active neurons: 10
 >> iter 21000, loss: 0.012583
 >> iter 22000, loss: 0.008122
 >> iter 23000, loss: 0.010313
 >> iter 24000, loss: 0.029031
 >> iter 25000, loss: 0.046792
 >> iter 26000, loss: 0.034273
 >> iter 27000, loss: 0.030000
 >> iter 28000, loss: 0.023920
 >> iter 29000, loss: 0.028312
 >> iter 30000, loss: 0.017908
   Number of active neurons: 10
 >> iter 31000, loss: 0.013330
 >> iter 32000, loss: 0.018646
 >> iter 33000, loss: 0.009433
 >> iter 34000, loss: 0.005219
 >> iter 35000, loss: 0.013683
 >> iter 36000, loss: 0.006930
 >> iter 37000, loss: 0.005369
 >> iter 38000, loss: 0.008826
 >> iter 39000, loss: 0.004811
 >> iter 40000, loss: 0.005884
   Number of active neurons: 10
 >> iter 41000, loss: 0.003249
 >> iter 42000, loss: 0.003622
 >> iter 43000, loss: 0.005423
 >> iter 44000, loss: 0.003174
 >> iter 45000, loss: 0.022641
 >> iter 46000, loss: 0.013653
 >> iter 47000, loss: 0.006312
 >> iter 48000, loss: 0.003314
 >> iter 49000, loss: 0.002251
 >> iter 50000, loss: 0.001587
   Number of active neurons: 10
 >> iter 51000, loss: 0.016579
 >> iter 52000, loss: 0.007348
 >> iter 53000, loss: 0.008304
 >> iter 54000, loss: 0.006454
 >> iter 55000, loss: 0.003876
 >> iter 56000, loss: 0.011108
 >> iter 57000, loss: 0.005010
 >> iter 58000, loss: 0.012034
 >> iter 59000, loss: 0.007100
 >> iter 60000, loss: 0.004526
   Number of active neurons: 10
 >> iter 61000, loss: 0.012278
 >> iter 62000, loss: 0.006663
 >> iter 63000, loss: 0.003340
 >> iter 64000, loss: 0.003902
 >> iter 65000, loss: 0.005328
 >> iter 66000, loss: 0.002982
 >> iter 67000, loss: 0.001729
 >> iter 68000, loss: 0.001350
 >> iter 69000, loss: 0.009374
 >> iter 70000, loss: 0.005696
   Number of active neurons: 10
 >> iter 71000, loss: 0.003074
 >> iter 72000, loss: 0.001684
 >> iter 73000, loss: 0.010413
 >> iter 74000, loss: 0.005277
 >> iter 75000, loss: 0.002551
 >> iter 76000, loss: 0.002254
 >> iter 77000, loss: 0.001316
 >> iter 78000, loss: 0.001203
 >> iter 79000, loss: 0.001187
 >> iter 80000, loss: 0.001315
   Number of active neurons: 10
 >> iter 81000, loss: 0.001236
 >> iter 82000, loss: 0.023930
 >> iter 83000, loss: 0.010642
 >> iter 84000, loss: 0.004634
 >> iter 85000, loss: 0.002259
 >> iter 86000, loss: 0.001287
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.699531
 >> iter 2000, loss: 4.861618
 >> iter 3000, loss: 2.098283
 >> iter 4000, loss: 0.902685
 >> iter 5000, loss: 0.462197
 >> iter 6000, loss: 0.212952
 >> iter 7000, loss: 0.135480
 >> iter 8000, loss: 0.092570
 >> iter 9000, loss: 0.064585
 >> iter 10000, loss: 0.059927
   Number of active neurons: 10
 >> iter 11000, loss: 0.036334
 >> iter 12000, loss: 0.038459
 >> iter 13000, loss: 0.043843
 >> iter 14000, loss: 0.033239
 >> iter 15000, loss: 0.031055
 >> iter 16000, loss: 0.018515
 >> iter 17000, loss: 0.019875
 >> iter 18000, loss: 0.012654
 >> iter 19000, loss: 0.027835
 >> iter 20000, loss: 0.018325
   Number of active neurons: 10
 >> iter 21000, loss: 0.018543
 >> iter 22000, loss: 0.014431
 >> iter 23000, loss: 0.012645
 >> iter 24000, loss: 0.015948
 >> iter 25000, loss: 0.017439
 >> iter 26000, loss: 0.016129
 >> iter 27000, loss: 0.021318
 >> iter 28000, loss: 0.009991
 >> iter 29000, loss: 0.007995
 >> iter 30000, loss: 0.004779
   Number of active neurons: 10
 >> iter 31000, loss: 0.003109
 >> iter 32000, loss: 0.004918
 >> iter 33000, loss: 0.007018
 >> iter 34000, loss: 0.007086
 >> iter 35000, loss: 0.005111
 >> iter 36000, loss: 0.009146
 >> iter 37000, loss: 0.004517
 >> iter 38000, loss: 0.002456
 >> iter 39000, loss: 0.002868
 >> iter 40000, loss: 0.004402
   Number of active neurons: 10
 >> iter 41000, loss: 0.002923
 >> iter 42000, loss: 0.002050
 >> iter 43000, loss: 0.014885
 >> iter 44000, loss: 0.008839
 >> iter 45000, loss: 0.004388
 >> iter 46000, loss: 0.019091
 >> iter 47000, loss: 0.016967
 >> iter 48000, loss: 0.009050
 >> iter 49000, loss: 0.024948
 >> iter 50000, loss: 0.010119
   Number of active neurons: 10
 >> iter 51000, loss: 0.007995
 >> iter 52000, loss: 0.005548
 >> iter 53000, loss: 0.002704
 >> iter 54000, loss: 0.001574
 >> iter 55000, loss: 0.002455
 >> iter 56000, loss: 0.006466
 >> iter 57000, loss: 0.012159
 >> iter 58000, loss: 0.006129
 >> iter 59000, loss: 0.003558
 >> iter 60000, loss: 0.001838
   Number of active neurons: 10
 >> iter 61000, loss: 0.001450
 >> iter 62000, loss: 0.001510
 >> iter 63000, loss: 0.001553
 >> iter 64000, loss: 0.001122
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455182
   Number of active neurons: 0
 >> iter 1000, loss: 11.749716
 >> iter 2000, loss: 4.959043
 >> iter 3000, loss: 2.088798
 >> iter 4000, loss: 0.905754
 >> iter 5000, loss: 0.420757
 >> iter 6000, loss: 0.254719
 >> iter 7000, loss: 0.156947
 >> iter 8000, loss: 0.113642
 >> iter 9000, loss: 0.062931
 >> iter 10000, loss: 0.042806
   Number of active neurons: 10
 >> iter 11000, loss: 0.025923
 >> iter 12000, loss: 0.039969
 >> iter 13000, loss: 0.026396
 >> iter 14000, loss: 0.037675
 >> iter 15000, loss: 0.028729
 >> iter 16000, loss: 0.031216
 >> iter 17000, loss: 0.029128
 >> iter 18000, loss: 0.020323
 >> iter 19000, loss: 0.029052
 >> iter 20000, loss: 0.023464
   Number of active neurons: 10
 >> iter 21000, loss: 0.021920
 >> iter 22000, loss: 0.025160
 >> iter 23000, loss: 0.011974
 >> iter 24000, loss: 0.005814
 >> iter 25000, loss: 0.005229
 >> iter 26000, loss: 0.003763
 >> iter 27000, loss: 0.017961
 >> iter 28000, loss: 0.033028
 >> iter 29000, loss: 0.034424
 >> iter 30000, loss: 0.022461
   Number of active neurons: 10
 >> iter 31000, loss: 0.011906
 >> iter 32000, loss: 0.006526
 >> iter 33000, loss: 0.006968
 >> iter 34000, loss: 0.003951
 >> iter 35000, loss: 0.003747
 >> iter 36000, loss: 0.013811
 >> iter 37000, loss: 0.007203
 >> iter 38000, loss: 0.008176
 >> iter 39000, loss: 0.004336
 >> iter 40000, loss: 0.002836
   Number of active neurons: 10
 >> iter 41000, loss: 0.003922
 >> iter 42000, loss: 0.002287
 >> iter 43000, loss: 0.005016
 >> iter 44000, loss: 0.009199
 >> iter 45000, loss: 0.005063
 >> iter 46000, loss: 0.002863
 >> iter 47000, loss: 0.007977
 >> iter 48000, loss: 0.003837
 >> iter 49000, loss: 0.002080
 >> iter 50000, loss: 0.001403
   Number of active neurons: 10
 >> iter 51000, loss: 0.001142
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.730837
 >> iter 2000, loss: 4.789948
 >> iter 3000, loss: 2.073792
 >> iter 4000, loss: 0.909526
 >> iter 5000, loss: 0.462959
 >> iter 6000, loss: 0.240018
 >> iter 7000, loss: 0.125476
 >> iter 8000, loss: 0.110734
 >> iter 9000, loss: 0.073171
 >> iter 10000, loss: 0.060960
   Number of active neurons: 10
 >> iter 11000, loss: 0.054760
 >> iter 12000, loss: 0.042581
 >> iter 13000, loss: 0.069038
 >> iter 14000, loss: 0.056468
 >> iter 15000, loss: 0.027534
 >> iter 16000, loss: 0.024410
 >> iter 17000, loss: 0.022993
 >> iter 18000, loss: 0.021095
 >> iter 19000, loss: 0.012171
 >> iter 20000, loss: 0.017440
   Number of active neurons: 10
 >> iter 21000, loss: 0.012047
 >> iter 22000, loss: 0.009614
 >> iter 23000, loss: 0.007006
 >> iter 24000, loss: 0.019231
 >> iter 25000, loss: 0.013176
 >> iter 26000, loss: 0.012476
 >> iter 27000, loss: 0.009434
 >> iter 28000, loss: 0.008150
 >> iter 29000, loss: 0.008218
 >> iter 30000, loss: 0.007071
   Number of active neurons: 10
 >> iter 31000, loss: 0.010857
 >> iter 32000, loss: 0.008005
 >> iter 33000, loss: 0.013308
 >> iter 34000, loss: 0.012327
 >> iter 35000, loss: 0.006713
 >> iter 36000, loss: 0.011670
 >> iter 37000, loss: 0.006569
 >> iter 38000, loss: 0.009186
 >> iter 39000, loss: 0.017158
 >> iter 40000, loss: 0.007920
   Number of active neurons: 10
 >> iter 41000, loss: 0.005395
 >> iter 42000, loss: 0.011245
 >> iter 43000, loss: 0.006073
 >> iter 44000, loss: 0.008863
 >> iter 45000, loss: 0.007766
 >> iter 46000, loss: 0.011617
 >> iter 47000, loss: 0.005341
 >> iter 48000, loss: 0.010815
 >> iter 49000, loss: 0.005651
 >> iter 50000, loss: 0.003462
   Number of active neurons: 10
 >> iter 51000, loss: 0.002368
 >> iter 52000, loss: 0.003411
 >> iter 53000, loss: 0.002455
 >> iter 54000, loss: 0.015807
 >> iter 55000, loss: 0.018368
 >> iter 56000, loss: 0.008743
 >> iter 57000, loss: 0.005797
 >> iter 58000, loss: 0.003569
 >> iter 59000, loss: 0.002858
 >> iter 60000, loss: 0.003239
   Number of active neurons: 10
 >> iter 61000, loss: 0.002471
 >> iter 62000, loss: 0.001805
 >> iter 63000, loss: 0.004986
 >> iter 64000, loss: 0.002964
 >> iter 65000, loss: 0.003529
 >> iter 66000, loss: 0.002728
 >> iter 67000, loss: 0.002037
 >> iter 68000, loss: 0.004488
 >> iter 69000, loss: 0.003179
 >> iter 70000, loss: 0.002544
   Number of active neurons: 10
 >> iter 71000, loss: 0.025859
 >> iter 72000, loss: 0.015683
 >> iter 73000, loss: 0.006737
 >> iter 74000, loss: 0.005032
 >> iter 75000, loss: 0.013825
 >> iter 76000, loss: 0.014902
 >> iter 77000, loss: 0.008160
 >> iter 78000, loss: 0.017259
 >> iter 79000, loss: 0.007577
 >> iter 80000, loss: 0.011797
   Number of active neurons: 10
 >> iter 81000, loss: 0.005529
 >> iter 82000, loss: 0.002562
 >> iter 83000, loss: 0.002752
 >> iter 84000, loss: 0.019527
 >> iter 85000, loss: 0.007905
 >> iter 86000, loss: 0.003945
 >> iter 87000, loss: 0.001957
 >> iter 88000, loss: 0.002394
 >> iter 89000, loss: 0.001566
 >> iter 90000, loss: 0.002229
   Number of active neurons: 10
 >> iter 91000, loss: 0.002846
 >> iter 92000, loss: 0.001587
 >> iter 93000, loss: 0.001156
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.748914
 >> iter 2000, loss: 4.838693
 >> iter 3000, loss: 2.044229
 >> iter 4000, loss: 0.900716
 >> iter 5000, loss: 0.441214
 >> iter 6000, loss: 0.248841
 >> iter 7000, loss: 0.135283
 >> iter 8000, loss: 0.120947
 >> iter 9000, loss: 0.068086
 >> iter 10000, loss: 0.057509
   Number of active neurons: 10
 >> iter 11000, loss: 0.044121
 >> iter 12000, loss: 0.032245
 >> iter 13000, loss: 0.039063
 >> iter 14000, loss: 0.034191
 >> iter 15000, loss: 0.034633
 >> iter 16000, loss: 0.022953
 >> iter 17000, loss: 0.018723
 >> iter 18000, loss: 0.012344
 >> iter 19000, loss: 0.009452
 >> iter 20000, loss: 0.011082
   Number of active neurons: 10
 >> iter 21000, loss: 0.022089
 >> iter 22000, loss: 0.037027
 >> iter 23000, loss: 0.025166
 >> iter 24000, loss: 0.012399
 >> iter 25000, loss: 0.010550
 >> iter 26000, loss: 0.020655
 >> iter 27000, loss: 0.014332
 >> iter 28000, loss: 0.012585
 >> iter 29000, loss: 0.015595
 >> iter 30000, loss: 0.014769
   Number of active neurons: 10
 >> iter 31000, loss: 0.009032
 >> iter 32000, loss: 0.009871
 >> iter 33000, loss: 0.011390
 >> iter 34000, loss: 0.009776
 >> iter 35000, loss: 0.006274
 >> iter 36000, loss: 0.003734
 >> iter 37000, loss: 0.009316
 >> iter 38000, loss: 0.006875
 >> iter 39000, loss: 0.011394
 >> iter 40000, loss: 0.013063
   Number of active neurons: 10
 >> iter 41000, loss: 0.021891
 >> iter 42000, loss: 0.021967
 >> iter 43000, loss: 0.014747
 >> iter 44000, loss: 0.007848
 >> iter 45000, loss: 0.004347
 >> iter 46000, loss: 0.003733
 >> iter 47000, loss: 0.002904
 >> iter 48000, loss: 0.002157
 >> iter 49000, loss: 0.001947
 >> iter 50000, loss: 0.001599
   Number of active neurons: 10
 >> iter 51000, loss: 0.002906
 >> iter 52000, loss: 0.002639
 >> iter 53000, loss: 0.002664
 >> iter 54000, loss: 0.006342
 >> iter 55000, loss: 0.003225
 >> iter 56000, loss: 0.004282
 >> iter 57000, loss: 0.004002
 >> iter 58000, loss: 0.002154
 >> iter 59000, loss: 0.013814
 >> iter 60000, loss: 0.005981
   Number of active neurons: 10
 >> iter 61000, loss: 0.004054
 >> iter 62000, loss: 0.006696
 >> iter 63000, loss: 0.008758
 >> iter 64000, loss: 0.003734
 >> iter 65000, loss: 0.002397
 >> iter 66000, loss: 0.001719
 >> iter 67000, loss: 0.001598
 >> iter 68000, loss: 0.002491
 >> iter 69000, loss: 0.001553
 >> iter 70000, loss: 0.001333
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.819947
 >> iter 2000, loss: 5.043513
 >> iter 3000, loss: 2.195321
 >> iter 4000, loss: 0.989598
 >> iter 5000, loss: 0.503519
 >> iter 6000, loss: 0.250066
 >> iter 7000, loss: 0.198964
 >> iter 8000, loss: 0.118108
 >> iter 9000, loss: 0.088801
 >> iter 10000, loss: 0.079359
   Number of active neurons: 10
 >> iter 11000, loss: 0.060270
 >> iter 12000, loss: 0.036924
 >> iter 13000, loss: 0.037629
 >> iter 14000, loss: 0.041517
 >> iter 15000, loss: 0.041783
 >> iter 16000, loss: 0.045669
 >> iter 17000, loss: 0.035985
 >> iter 18000, loss: 0.019737
 >> iter 19000, loss: 0.012479
 >> iter 20000, loss: 0.032821
   Number of active neurons: 10
 >> iter 21000, loss: 0.047754
 >> iter 22000, loss: 0.026748
 >> iter 23000, loss: 0.013913
 >> iter 24000, loss: 0.012012
 >> iter 25000, loss: 0.013378
 >> iter 26000, loss: 0.010206
 >> iter 27000, loss: 0.042249
 >> iter 28000, loss: 0.017957
 >> iter 29000, loss: 0.020306
 >> iter 30000, loss: 0.019670
   Number of active neurons: 10
 >> iter 31000, loss: 0.013137
 >> iter 32000, loss: 0.011268
 >> iter 33000, loss: 0.006539
 >> iter 34000, loss: 0.006903
 >> iter 35000, loss: 0.005124
 >> iter 36000, loss: 0.008033
 >> iter 37000, loss: 0.006348
 >> iter 38000, loss: 0.004529
 >> iter 39000, loss: 0.005332
 >> iter 40000, loss: 0.007261
   Number of active neurons: 10
 >> iter 41000, loss: 0.004798
 >> iter 42000, loss: 0.012578
 >> iter 43000, loss: 0.006958
 >> iter 44000, loss: 0.003355
 >> iter 45000, loss: 0.005166
 >> iter 46000, loss: 0.004529
 >> iter 47000, loss: 0.002445
 >> iter 48000, loss: 0.013731
 >> iter 49000, loss: 0.007356
 >> iter 50000, loss: 0.004341
   Number of active neurons: 10
 >> iter 51000, loss: 0.002515
 >> iter 52000, loss: 0.005589
 >> iter 53000, loss: 0.044714
 >> iter 54000, loss: 0.018661
 >> iter 55000, loss: 0.015510
 >> iter 56000, loss: 0.006471
 >> iter 57000, loss: 0.003073
 >> iter 58000, loss: 0.001617
 >> iter 59000, loss: 0.001845
 >> iter 60000, loss: 0.001252
   Number of active neurons: 10
 >> iter 61000, loss: 0.001708
 >> iter 62000, loss: 0.001250
 >> iter 63000, loss: 0.005109
 >> iter 64000, loss: 0.003741
 >> iter 65000, loss: 0.017176
 >> iter 66000, loss: 0.007029
 >> iter 67000, loss: 0.003778
 >> iter 68000, loss: 0.003255
 >> iter 69000, loss: 0.001874
 >> iter 70000, loss: 0.006691
   Number of active neurons: 10
 >> iter 71000, loss: 0.003408
 >> iter 72000, loss: 0.018830
 >> iter 73000, loss: 0.012842
 >> iter 74000, loss: 0.006417
 >> iter 75000, loss: 0.023618
 >> iter 76000, loss: 0.018183
 >> iter 77000, loss: 0.012076
 >> iter 78000, loss: 0.005010
 >> iter 79000, loss: 0.008845
 >> iter 80000, loss: 0.012491
   Number of active neurons: 10
 >> iter 81000, loss: 0.011744
 >> iter 82000, loss: 0.005977
 >> iter 83000, loss: 0.002967
 >> iter 84000, loss: 0.001726
 >> iter 85000, loss: 0.001542
 >> iter 86000, loss: 0.001065
 >> iter 87000, loss: 0.001252
 >> iter 88000, loss: 0.004586
 >> iter 89000, loss: 0.022921
 >> iter 90000, loss: 0.009238
   Number of active neurons: 10
 >> iter 91000, loss: 0.004114
 >> iter 92000, loss: 0.002198
 >> iter 93000, loss: 0.001340
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455183
   Number of active neurons: 0
 >> iter 1000, loss: 11.745360
 >> iter 2000, loss: 4.845790
 >> iter 3000, loss: 2.084097
 >> iter 4000, loss: 0.977213
 >> iter 5000, loss: 0.468206
 >> iter 6000, loss: 0.231417
 >> iter 7000, loss: 0.149885
 >> iter 8000, loss: 0.099475
 >> iter 9000, loss: 0.079709
 >> iter 10000, loss: 0.070264
   Number of active neurons: 10
 >> iter 11000, loss: 0.057489
 >> iter 12000, loss: 0.060456
 >> iter 13000, loss: 0.055593
 >> iter 14000, loss: 0.028446
 >> iter 15000, loss: 0.035937
 >> iter 16000, loss: 0.035085
 >> iter 17000, loss: 0.034312
 >> iter 18000, loss: 0.032757
 >> iter 19000, loss: 0.036125
 >> iter 20000, loss: 0.042116
   Number of active neurons: 10
 >> iter 21000, loss: 0.037573
 >> iter 22000, loss: 0.019637
 >> iter 23000, loss: 0.023889
 >> iter 24000, loss: 0.022429
 >> iter 25000, loss: 0.017816
 >> iter 26000, loss: 0.024279
 >> iter 27000, loss: 0.012936
 >> iter 28000, loss: 0.017364
 >> iter 29000, loss: 0.010224
 >> iter 30000, loss: 0.005986
   Number of active neurons: 10
 >> iter 31000, loss: 0.026200
 >> iter 32000, loss: 0.013004
 >> iter 33000, loss: 0.023723
 >> iter 34000, loss: 0.021313
 >> iter 35000, loss: 0.016523
 >> iter 36000, loss: 0.009024
 >> iter 37000, loss: 0.005257
 >> iter 38000, loss: 0.008053
 >> iter 39000, loss: 0.004650
 >> iter 40000, loss: 0.003008
   Number of active neurons: 10
 >> iter 41000, loss: 0.028269
 >> iter 42000, loss: 0.017455
 >> iter 43000, loss: 0.007527
 >> iter 44000, loss: 0.003590
 >> iter 45000, loss: 0.002814
 >> iter 46000, loss: 0.002014
 >> iter 47000, loss: 0.001489
 >> iter 48000, loss: 0.005857
 >> iter 49000, loss: 0.003129
 >> iter 50000, loss: 0.009750
   Number of active neurons: 10
 >> iter 51000, loss: 0.005538
 >> iter 52000, loss: 0.005161
 >> iter 53000, loss: 0.005960
 >> iter 54000, loss: 0.015090
 >> iter 55000, loss: 0.007853
 >> iter 56000, loss: 0.016087
 >> iter 57000, loss: 0.007489
 >> iter 58000, loss: 0.004808
 >> iter 59000, loss: 0.004484
 >> iter 60000, loss: 0.002078
   Number of active neurons: 10
 >> iter 61000, loss: 0.001200
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455162
   Number of active neurons: 0
 >> iter 1000, loss: 11.764642
 >> iter 2000, loss: 4.902906
 >> iter 3000, loss: 2.095573
 >> iter 4000, loss: 0.921020
 >> iter 5000, loss: 0.425968
 >> iter 6000, loss: 0.212388
 >> iter 7000, loss: 0.166000
 >> iter 8000, loss: 0.106941
 >> iter 9000, loss: 0.068578
 >> iter 10000, loss: 0.050136
   Number of active neurons: 10
 >> iter 11000, loss: 0.040146
 >> iter 12000, loss: 0.050962
 >> iter 13000, loss: 0.039333
 >> iter 14000, loss: 0.034413
 >> iter 15000, loss: 0.027101
 >> iter 16000, loss: 0.013157
 >> iter 17000, loss: 0.015292
 >> iter 18000, loss: 0.037916
 >> iter 19000, loss: 0.043768
 >> iter 20000, loss: 0.020030
   Number of active neurons: 10
 >> iter 21000, loss: 0.015883
 >> iter 22000, loss: 0.014256
 >> iter 23000, loss: 0.018800
 >> iter 24000, loss: 0.008873
 >> iter 25000, loss: 0.006933
 >> iter 26000, loss: 0.013650
 >> iter 27000, loss: 0.007060
 >> iter 28000, loss: 0.004840
 >> iter 29000, loss: 0.004952
 >> iter 30000, loss: 0.014475
   Number of active neurons: 10
 >> iter 31000, loss: 0.007716
 >> iter 32000, loss: 0.004433
 >> iter 33000, loss: 0.002619
 >> iter 34000, loss: 0.012815
 >> iter 35000, loss: 0.006887
 >> iter 36000, loss: 0.004581
 >> iter 37000, loss: 0.003012
 >> iter 38000, loss: 0.014345
 >> iter 39000, loss: 0.006046
 >> iter 40000, loss: 0.003238
   Number of active neurons: 10
 >> iter 41000, loss: 0.002809
 >> iter 42000, loss: 0.006732
 >> iter 43000, loss: 0.005274
 >> iter 44000, loss: 0.003269
 >> iter 45000, loss: 0.003625
 >> iter 46000, loss: 0.003628
 >> iter 47000, loss: 0.002140
 >> iter 48000, loss: 0.003514
 >> iter 49000, loss: 0.005999
 >> iter 50000, loss: 0.003228
   Number of active neurons: 10
 >> iter 51000, loss: 0.002088
 >> iter 52000, loss: 0.001479
 >> iter 53000, loss: 0.004426
 >> iter 54000, loss: 0.004382
 >> iter 55000, loss: 0.003111
 >> iter 56000, loss: 0.001777
 >> iter 57000, loss: 0.001377
 >> iter 58000, loss: 0.002565
 >> iter 59000, loss: 0.001505
 >> iter 60000, loss: 0.001733
   Number of active neurons: 10
 >> iter 61000, loss: 0.001377
 >> iter 62000, loss: 0.001658
 >> iter 63000, loss: 0.003750
 >> iter 64000, loss: 0.002003
 >> iter 65000, loss: 0.001227
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.684232
 >> iter 2000, loss: 4.848511
 >> iter 3000, loss: 1.992727
 >> iter 4000, loss: 0.906380
 >> iter 5000, loss: 0.409145
 >> iter 6000, loss: 0.220618
 >> iter 7000, loss: 0.137051
 >> iter 8000, loss: 0.101160
 >> iter 9000, loss: 0.069247
 >> iter 10000, loss: 0.042755
   Number of active neurons: 10
 >> iter 11000, loss: 0.048132
 >> iter 12000, loss: 0.078001
 >> iter 13000, loss: 0.102520
 >> iter 14000, loss: 0.086300
 >> iter 15000, loss: 0.058532
 >> iter 16000, loss: 0.045452
 >> iter 17000, loss: 0.038106
 >> iter 18000, loss: 0.028544
 >> iter 19000, loss: 0.015547
 >> iter 20000, loss: 0.013169
   Number of active neurons: 10
 >> iter 21000, loss: 0.032819
 >> iter 22000, loss: 0.021533
 >> iter 23000, loss: 0.018625
 >> iter 24000, loss: 0.018167
 >> iter 25000, loss: 0.010242
 >> iter 26000, loss: 0.010010
 >> iter 27000, loss: 0.006157
 >> iter 28000, loss: 0.004310
 >> iter 29000, loss: 0.008239
 >> iter 30000, loss: 0.010651
   Number of active neurons: 10
 >> iter 31000, loss: 0.009905
 >> iter 32000, loss: 0.005455
 >> iter 33000, loss: 0.005580
 >> iter 34000, loss: 0.003792
 >> iter 35000, loss: 0.008741
 >> iter 36000, loss: 0.005476
 >> iter 37000, loss: 0.013635
 >> iter 38000, loss: 0.006418
 >> iter 39000, loss: 0.005634
 >> iter 40000, loss: 0.004456
   Number of active neurons: 10
 >> iter 41000, loss: 0.009376
 >> iter 42000, loss: 0.010125
 >> iter 43000, loss: 0.004533
 >> iter 44000, loss: 0.003628
 >> iter 45000, loss: 0.009668
 >> iter 46000, loss: 0.013461
 >> iter 47000, loss: 0.007656
 >> iter 48000, loss: 0.003946
 >> iter 49000, loss: 0.004696
 >> iter 50000, loss: 0.003032
   Number of active neurons: 10
 >> iter 51000, loss: 0.030985
 >> iter 52000, loss: 0.012677
 >> iter 53000, loss: 0.010246
 >> iter 54000, loss: 0.004546
 >> iter 55000, loss: 0.003023
 >> iter 56000, loss: 0.002549
 >> iter 57000, loss: 0.001764
 >> iter 58000, loss: 0.001732
 >> iter 59000, loss: 0.016926
 >> iter 60000, loss: 0.014973
   Number of active neurons: 10
 >> iter 61000, loss: 0.007641
 >> iter 62000, loss: 0.015715
 >> iter 63000, loss: 0.008374
 >> iter 64000, loss: 0.007685
 >> iter 65000, loss: 0.003447
 >> iter 66000, loss: 0.002727
 >> iter 67000, loss: 0.001852
 >> iter 68000, loss: 0.001216
 >> iter 69000, loss: 0.002082
 >> iter 70000, loss: 0.002057
   Number of active neurons: 10
 >> iter 71000, loss: 0.001996
 >> iter 72000, loss: 0.002932
 >> iter 73000, loss: 0.008536
 >> iter 74000, loss: 0.004455
 >> iter 75000, loss: 0.013471
 >> iter 76000, loss: 0.010180
 >> iter 77000, loss: 0.013758
 >> iter 78000, loss: 0.006244
 >> iter 79000, loss: 0.027089
 >> iter 80000, loss: 0.014013
   Number of active neurons: 10
 >> iter 81000, loss: 0.010793
 >> iter 82000, loss: 0.005930
 >> iter 83000, loss: 0.003014
 >> iter 84000, loss: 0.001734
 >> iter 85000, loss: 0.001125
 >> iter 86000, loss: 0.001128
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455181
   Number of active neurons: 0
 >> iter 1000, loss: 11.692826
 >> iter 2000, loss: 4.827854
 >> iter 3000, loss: 2.084665
 >> iter 4000, loss: 0.906313
 >> iter 5000, loss: 0.432941
 >> iter 6000, loss: 0.207182
 >> iter 7000, loss: 0.120702
 >> iter 8000, loss: 0.075780
 >> iter 9000, loss: 0.054240
 >> iter 10000, loss: 0.044244
   Number of active neurons: 10
 >> iter 11000, loss: 0.041578
 >> iter 12000, loss: 0.029219
 >> iter 13000, loss: 0.025515
 >> iter 14000, loss: 0.015288
 >> iter 15000, loss: 0.015044
 >> iter 16000, loss: 0.016316
 >> iter 17000, loss: 0.018970
 >> iter 18000, loss: 0.018274
 >> iter 19000, loss: 0.015155
 >> iter 20000, loss: 0.042963
   Number of active neurons: 10
 >> iter 21000, loss: 0.025241
 >> iter 22000, loss: 0.012208
 >> iter 23000, loss: 0.006870
 >> iter 24000, loss: 0.009040
 >> iter 25000, loss: 0.006231
 >> iter 26000, loss: 0.015861
 >> iter 27000, loss: 0.015209
 >> iter 28000, loss: 0.022009
 >> iter 29000, loss: 0.026690
 >> iter 30000, loss: 0.015457
   Number of active neurons: 10
 >> iter 31000, loss: 0.010143
 >> iter 32000, loss: 0.006899
 >> iter 33000, loss: 0.004316
 >> iter 34000, loss: 0.004325
 >> iter 35000, loss: 0.003646
 >> iter 36000, loss: 0.002936
 >> iter 37000, loss: 0.007724
 >> iter 38000, loss: 0.010022
 >> iter 39000, loss: 0.005899
 >> iter 40000, loss: 0.003345
   Number of active neurons: 10
 >> iter 41000, loss: 0.005489
 >> iter 42000, loss: 0.003993
 >> iter 43000, loss: 0.002465
 >> iter 44000, loss: 0.001529
 >> iter 45000, loss: 0.001718
 >> iter 46000, loss: 0.001476
 >> iter 47000, loss: 0.001778
 >> iter 48000, loss: 0.004178
 >> iter 49000, loss: 0.003488
 >> iter 50000, loss: 0.003635
   Number of active neurons: 10
 >> iter 51000, loss: 0.006810
 >> iter 52000, loss: 0.013211
 >> iter 53000, loss: 0.005648
 >> iter 54000, loss: 0.003233
 >> iter 55000, loss: 0.009156
 >> iter 56000, loss: 0.004369
 >> iter 57000, loss: 0.002513
 >> iter 58000, loss: 0.008125
 >> iter 59000, loss: 0.035981
 >> iter 60000, loss: 0.014760
   Number of active neurons: 10
 >> iter 61000, loss: 0.015090
 >> iter 62000, loss: 0.008497
 >> iter 63000, loss: 0.012742
 >> iter 64000, loss: 0.005700
 >> iter 65000, loss: 0.003025
 >> iter 66000, loss: 0.001741
 >> iter 67000, loss: 0.002184
 >> iter 68000, loss: 0.001576
 >> iter 69000, loss: 0.013998
 >> iter 70000, loss: 0.006035
   Number of active neurons: 10
 >> iter 71000, loss: 0.002883
 >> iter 72000, loss: 0.002444
 >> iter 73000, loss: 0.001939
 >> iter 74000, loss: 0.010998
 >> iter 75000, loss: 0.004611
 >> iter 76000, loss: 0.002200
 >> iter 77000, loss: 0.002391
 >> iter 78000, loss: 0.002504
 >> iter 79000, loss: 0.004156
 >> iter 80000, loss: 0.001984
   Number of active neurons: 10
 >> iter 81000, loss: 0.001112
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

