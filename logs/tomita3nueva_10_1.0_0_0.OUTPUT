 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 1.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.332419
 >> iter 2000, loss: 13.631597
 >> iter 3000, loss: 8.100295
 >> iter 4000, loss: 3.814980
 >> iter 5000, loss: 2.198061
 >> iter 6000, loss: 1.189658
 >> iter 7000, loss: 0.573325
 >> iter 8000, loss: 0.489010
 >> iter 9000, loss: 0.314392
 >> iter 10000, loss: 0.370287
   Number of active neurons: 10
 >> iter 11000, loss: 0.316529
 >> iter 12000, loss: 0.185311
 >> iter 13000, loss: 0.112911
 >> iter 14000, loss: 0.054363
 >> iter 15000, loss: 0.068009
 >> iter 16000, loss: 0.038579
 >> iter 17000, loss: 0.028875
 >> iter 18000, loss: 0.073274
 >> iter 19000, loss: 0.082468
 >> iter 20000, loss: 0.071338
   Number of active neurons: 10
 >> iter 21000, loss: 0.045782
 >> iter 22000, loss: 0.023776
 >> iter 23000, loss: 0.241706
 >> iter 24000, loss: 0.125615
 >> iter 25000, loss: 0.144571
 >> iter 26000, loss: 0.115259
 >> iter 27000, loss: 0.087963
 >> iter 28000, loss: 0.073357
 >> iter 29000, loss: 0.031912
 >> iter 30000, loss: 0.017511
   Number of active neurons: 10
 >> iter 31000, loss: 0.198735
 >> iter 32000, loss: 0.148006
 >> iter 33000, loss: 0.241873
 >> iter 34000, loss: 0.118844
 >> iter 35000, loss: 0.050947
 >> iter 36000, loss: 0.029981
 >> iter 37000, loss: 0.062420
 >> iter 38000, loss: 0.051455
 >> iter 39000, loss: 0.304637
 >> iter 40000, loss: 0.198147
   Number of active neurons: 10
 >> iter 41000, loss: 0.093229
 >> iter 42000, loss: 0.052230
 >> iter 43000, loss: 0.024788
 >> iter 44000, loss: 0.017241
 >> iter 45000, loss: 0.010207
 >> iter 46000, loss: 0.007281
 >> iter 47000, loss: 0.010559
 >> iter 48000, loss: 0.007993
 >> iter 49000, loss: 0.035146
 >> iter 50000, loss: 0.041662
   Number of active neurons: 10
 >> iter 51000, loss: 0.081052
 >> iter 52000, loss: 0.036312
 >> iter 53000, loss: 0.051565
 >> iter 54000, loss: 0.028842
 >> iter 55000, loss: 0.023072
 >> iter 56000, loss: 0.026660
 >> iter 57000, loss: 0.038060
 >> iter 58000, loss: 0.019423
 >> iter 59000, loss: 0.071838
 >> iter 60000, loss: 0.030819
   Number of active neurons: 10
 >> iter 61000, loss: 0.014861
 >> iter 62000, loss: 0.014871
 >> iter 63000, loss: 0.018734
 >> iter 64000, loss: 0.009501
 >> iter 65000, loss: 0.016649
 >> iter 66000, loss: 0.033508
 >> iter 67000, loss: 0.037972
 >> iter 68000, loss: 0.016332
 >> iter 69000, loss: 0.018238
 >> iter 70000, loss: 0.008786
   Number of active neurons: 10
 >> iter 71000, loss: 0.019041
 >> iter 72000, loss: 0.049607
 >> iter 73000, loss: 0.021848
 >> iter 74000, loss: 0.010463
 >> iter 75000, loss: 0.005971
 >> iter 76000, loss: 0.005959
 >> iter 77000, loss: 0.004568
 >> iter 78000, loss: 0.005506
 >> iter 79000, loss: 0.019663
 >> iter 80000, loss: 0.025210
   Number of active neurons: 10
 >> iter 81000, loss: 0.015061
 >> iter 82000, loss: 0.007786
 >> iter 83000, loss: 0.006006
 >> iter 84000, loss: 0.021077
 >> iter 85000, loss: 0.009804
 >> iter 86000, loss: 0.013845
 >> iter 87000, loss: 0.006551
 >> iter 88000, loss: 0.030875
 >> iter 89000, loss: 0.012780
 >> iter 90000, loss: 0.006041
   Number of active neurons: 10
 >> iter 91000, loss: 0.017149
 >> iter 92000, loss: 0.042411
 >> iter 93000, loss: 0.017090
 >> iter 94000, loss: 0.008300
 >> iter 95000, loss: 0.009487
 >> iter 96000, loss: 0.004960
 >> iter 97000, loss: 0.068899
 >> iter 98000, loss: 0.029424
 >> iter 99000, loss: 0.018290
 >> iter 100000, loss: 0.008387
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.329622
 >> iter 2000, loss: 14.201708
 >> iter 3000, loss: 8.200853
 >> iter 4000, loss: 4.134949
 >> iter 5000, loss: 2.000638
 >> iter 6000, loss: 1.028561
 >> iter 7000, loss: 0.642121
 >> iter 8000, loss: 0.313771
 >> iter 9000, loss: 0.384820
 >> iter 10000, loss: 0.406857
   Number of active neurons: 10
 >> iter 11000, loss: 0.516135
 >> iter 12000, loss: 0.349104
 >> iter 13000, loss: 0.255186
 >> iter 14000, loss: 0.404383
 >> iter 15000, loss: 0.306789
 >> iter 16000, loss: 0.141836
 >> iter 17000, loss: 0.150619
 >> iter 18000, loss: 0.075731
 >> iter 19000, loss: 0.146121
 >> iter 20000, loss: 0.159464
   Number of active neurons: 10
 >> iter 21000, loss: 0.128776
 >> iter 22000, loss: 0.061134
 >> iter 23000, loss: 0.065149
 >> iter 24000, loss: 0.060426
 >> iter 25000, loss: 0.030095
 >> iter 26000, loss: 0.033772
 >> iter 27000, loss: 0.018837
 >> iter 28000, loss: 0.013716
 >> iter 29000, loss: 0.035424
 >> iter 30000, loss: 0.065121
   Number of active neurons: 10
 >> iter 31000, loss: 0.053648
 >> iter 32000, loss: 0.104322
 >> iter 33000, loss: 0.202188
 >> iter 34000, loss: 0.100435
 >> iter 35000, loss: 0.044215
 >> iter 36000, loss: 0.025573
 >> iter 37000, loss: 0.088071
 >> iter 38000, loss: 0.038360
 >> iter 39000, loss: 0.093916
 >> iter 40000, loss: 0.039849
   Number of active neurons: 10
 >> iter 41000, loss: 0.162200
 >> iter 42000, loss: 0.142969
 >> iter 43000, loss: 0.069209
 >> iter 44000, loss: 0.064532
 >> iter 45000, loss: 0.034194
 >> iter 46000, loss: 0.151709
 >> iter 47000, loss: 0.062293
 >> iter 48000, loss: 0.072394
 >> iter 49000, loss: 0.172193
 >> iter 50000, loss: 0.096601
   Number of active neurons: 10
 >> iter 51000, loss: 0.044699
 >> iter 52000, loss: 0.027305
 >> iter 53000, loss: 0.015290
 >> iter 54000, loss: 0.011640
 >> iter 55000, loss: 0.023723
 >> iter 56000, loss: 0.013822
 >> iter 57000, loss: 0.009839
 >> iter 58000, loss: 0.013118
 >> iter 59000, loss: 0.116748
 >> iter 60000, loss: 0.046989
   Number of active neurons: 10
 >> iter 61000, loss: 0.021572
 >> iter 62000, loss: 0.029604
 >> iter 63000, loss: 0.014615
 >> iter 64000, loss: 0.115119
 >> iter 65000, loss: 0.068277
 >> iter 66000, loss: 0.030899
 >> iter 67000, loss: 0.016050
 >> iter 68000, loss: 0.009569
 >> iter 69000, loss: 0.085249
 >> iter 70000, loss: 0.034473
   Number of active neurons: 10
 >> iter 71000, loss: 0.015576
 >> iter 72000, loss: 0.033094
 >> iter 73000, loss: 0.027045
 >> iter 74000, loss: 0.019240
 >> iter 75000, loss: 0.009990
 >> iter 76000, loss: 0.050528
 >> iter 77000, loss: 0.022818
 >> iter 78000, loss: 0.116677
 >> iter 79000, loss: 0.046928
 >> iter 80000, loss: 0.039888
   Number of active neurons: 10
 >> iter 81000, loss: 0.017667
 >> iter 82000, loss: 0.035470
 >> iter 83000, loss: 0.018436
 >> iter 84000, loss: 0.009754
 >> iter 85000, loss: 0.029430
 >> iter 86000, loss: 0.013223
 >> iter 87000, loss: 0.021540
 >> iter 88000, loss: 0.011025
 >> iter 89000, loss: 0.006076
 >> iter 90000, loss: 0.004159
   Number of active neurons: 10
 >> iter 91000, loss: 0.003422
 >> iter 92000, loss: 0.003279
 >> iter 93000, loss: 0.002955
 >> iter 94000, loss: 0.033547
 >> iter 95000, loss: 0.014643
 >> iter 96000, loss: 0.008382
 >> iter 97000, loss: 0.020523
 >> iter 98000, loss: 0.023080
 >> iter 99000, loss: 0.011203
 >> iter 100000, loss: 0.026315
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.156236
 >> iter 2000, loss: 12.952586
 >> iter 3000, loss: 7.058157
 >> iter 4000, loss: 3.301970
 >> iter 5000, loss: 1.808199
 >> iter 6000, loss: 0.863055
 >> iter 7000, loss: 0.601744
 >> iter 8000, loss: 0.396420
 >> iter 9000, loss: 0.319969
 >> iter 10000, loss: 0.244255
   Number of active neurons: 10
 >> iter 11000, loss: 0.337051
 >> iter 12000, loss: 0.257954
 >> iter 13000, loss: 0.144580
 >> iter 14000, loss: 0.195239
 >> iter 15000, loss: 0.171348
 >> iter 16000, loss: 0.244394
 >> iter 17000, loss: 0.225390
 >> iter 18000, loss: 0.096377
 >> iter 19000, loss: 0.141820
 >> iter 20000, loss: 0.127661
   Number of active neurons: 10
 >> iter 21000, loss: 0.212043
 >> iter 22000, loss: 0.108763
 >> iter 23000, loss: 0.116955
 >> iter 24000, loss: 0.120948
 >> iter 25000, loss: 0.158795
 >> iter 26000, loss: 0.133636
 >> iter 27000, loss: 0.075432
 >> iter 28000, loss: 0.087996
 >> iter 29000, loss: 0.044837
 >> iter 30000, loss: 0.117660
   Number of active neurons: 10
 >> iter 31000, loss: 0.054944
 >> iter 32000, loss: 0.054009
 >> iter 33000, loss: 0.024812
 >> iter 34000, loss: 0.018512
 >> iter 35000, loss: 0.010370
 >> iter 36000, loss: 0.025583
 >> iter 37000, loss: 0.013322
 >> iter 38000, loss: 0.009201
 >> iter 39000, loss: 0.008181
 >> iter 40000, loss: 0.034574
   Number of active neurons: 10
 >> iter 41000, loss: 0.016400
 >> iter 42000, loss: 0.026615
 >> iter 43000, loss: 0.022526
 >> iter 44000, loss: 0.025951
 >> iter 45000, loss: 0.288896
 >> iter 46000, loss: 0.137949
 >> iter 47000, loss: 0.184110
 >> iter 48000, loss: 0.130173
 >> iter 49000, loss: 0.055110
 >> iter 50000, loss: 0.028566
   Number of active neurons: 10
 >> iter 51000, loss: 0.013694
 >> iter 52000, loss: 0.009113
 >> iter 53000, loss: 0.007059
 >> iter 54000, loss: 0.005423
 >> iter 55000, loss: 0.024825
 >> iter 56000, loss: 0.014852
 >> iter 57000, loss: 0.007735
 >> iter 58000, loss: 0.053020
 >> iter 59000, loss: 0.024334
 >> iter 60000, loss: 0.022014
   Number of active neurons: 10
 >> iter 61000, loss: 0.088505
 >> iter 62000, loss: 0.035237
 >> iter 63000, loss: 0.015606
 >> iter 64000, loss: 0.008586
 >> iter 65000, loss: 0.004878
 >> iter 66000, loss: 0.003546
 >> iter 67000, loss: 0.004061
 >> iter 68000, loss: 0.008627
 >> iter 69000, loss: 0.004851
 >> iter 70000, loss: 0.006995
   Number of active neurons: 10
 >> iter 71000, loss: 0.028764
 >> iter 72000, loss: 0.045100
 >> iter 73000, loss: 0.090117
 >> iter 74000, loss: 0.036309
 >> iter 75000, loss: 0.015507
 >> iter 76000, loss: 0.085020
 >> iter 77000, loss: 0.034545
 >> iter 78000, loss: 0.015378
 >> iter 79000, loss: 0.007565
 >> iter 80000, loss: 0.004939
   Number of active neurons: 10
 >> iter 81000, loss: 0.070010
 >> iter 82000, loss: 0.028264
 >> iter 83000, loss: 0.012628
 >> iter 84000, loss: 0.006487
 >> iter 85000, loss: 0.013881
 >> iter 86000, loss: 0.021967
 >> iter 87000, loss: 0.010531
 >> iter 88000, loss: 0.051107
 >> iter 89000, loss: 0.021060
 >> iter 90000, loss: 0.009419
   Number of active neurons: 10
 >> iter 91000, loss: 0.007187
 >> iter 92000, loss: 0.005059
 >> iter 93000, loss: 0.032314
 >> iter 94000, loss: 0.023526
 >> iter 95000, loss: 0.011083
 >> iter 96000, loss: 0.006254
 >> iter 97000, loss: 0.003644
 >> iter 98000, loss: 0.002609
 >> iter 99000, loss: 0.002319
 >> iter 100000, loss: 0.002153
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 19.315239
 >> iter 2000, loss: 13.327578
 >> iter 3000, loss: 7.408196
 >> iter 4000, loss: 3.745954
 >> iter 5000, loss: 1.756518
 >> iter 6000, loss: 1.063678
 >> iter 7000, loss: 0.764496
 >> iter 8000, loss: 0.634287
 >> iter 9000, loss: 0.446055
 >> iter 10000, loss: 0.227912
   Number of active neurons: 10
 >> iter 11000, loss: 0.140560
 >> iter 12000, loss: 0.103902
 >> iter 13000, loss: 0.275593
 >> iter 14000, loss: 0.135950
 >> iter 15000, loss: 0.093801
 >> iter 16000, loss: 0.379058
 >> iter 17000, loss: 0.296245
 >> iter 18000, loss: 0.187839
 >> iter 19000, loss: 0.081230
 >> iter 20000, loss: 0.074261
   Number of active neurons: 10
 >> iter 21000, loss: 0.086276
 >> iter 22000, loss: 0.081050
 >> iter 23000, loss: 0.105366
 >> iter 24000, loss: 0.072532
 >> iter 25000, loss: 0.091623
 >> iter 26000, loss: 0.093583
 >> iter 27000, loss: 0.213468
 >> iter 28000, loss: 0.167625
 >> iter 29000, loss: 0.127514
 >> iter 30000, loss: 0.093199
   Number of active neurons: 10
 >> iter 31000, loss: 0.108661
 >> iter 32000, loss: 0.129338
 >> iter 33000, loss: 0.057538
 >> iter 34000, loss: 0.031356
 >> iter 35000, loss: 0.018978
 >> iter 36000, loss: 0.029810
 >> iter 37000, loss: 0.087051
 >> iter 38000, loss: 0.058716
 >> iter 39000, loss: 0.026700
 >> iter 40000, loss: 0.048694
   Number of active neurons: 10
 >> iter 41000, loss: 0.024316
 >> iter 42000, loss: 0.142000
 >> iter 43000, loss: 0.112218
 >> iter 44000, loss: 0.135154
 >> iter 45000, loss: 0.056044
 >> iter 46000, loss: 0.061006
 >> iter 47000, loss: 0.033557
 >> iter 48000, loss: 0.016166
 >> iter 49000, loss: 0.008532
 >> iter 50000, loss: 0.007563
   Number of active neurons: 10
 >> iter 51000, loss: 0.005478
 >> iter 52000, loss: 0.004801
 >> iter 53000, loss: 0.019350
 >> iter 54000, loss: 0.021586
 >> iter 55000, loss: 0.011475
 >> iter 56000, loss: 0.005979
 >> iter 57000, loss: 0.004503
 >> iter 58000, loss: 0.158243
 >> iter 59000, loss: 0.060953
 >> iter 60000, loss: 0.024693
   Number of active neurons: 10
 >> iter 61000, loss: 0.011089
 >> iter 62000, loss: 0.007146
 >> iter 63000, loss: 0.004495
 >> iter 64000, loss: 0.094800
 >> iter 65000, loss: 0.039979
 >> iter 66000, loss: 0.016490
 >> iter 67000, loss: 0.033679
 >> iter 68000, loss: 0.017597
 >> iter 69000, loss: 0.008593
 >> iter 70000, loss: 0.010306
   Number of active neurons: 10
 >> iter 71000, loss: 0.105812
 >> iter 72000, loss: 0.041329
 >> iter 73000, loss: 0.020565
 >> iter 74000, loss: 0.029130
 >> iter 75000, loss: 0.077106
 >> iter 76000, loss: 0.030918
 >> iter 77000, loss: 0.028730
 >> iter 78000, loss: 0.026112
 >> iter 79000, loss: 0.012848
 >> iter 80000, loss: 0.012201
   Number of active neurons: 10
 >> iter 81000, loss: 0.069347
 >> iter 82000, loss: 0.028368
 >> iter 83000, loss: 0.032179
 >> iter 84000, loss: 0.013971
 >> iter 85000, loss: 0.008160
 >> iter 86000, loss: 0.008328
 >> iter 87000, loss: 0.004668
 >> iter 88000, loss: 0.030237
 >> iter 89000, loss: 0.013617
 >> iter 90000, loss: 0.006515
   Number of active neurons: 10
 >> iter 91000, loss: 0.054651
 >> iter 92000, loss: 0.022178
 >> iter 93000, loss: 0.028196
 >> iter 94000, loss: 0.012530
 >> iter 95000, loss: 0.005900
 >> iter 96000, loss: 0.003854
 >> iter 97000, loss: 0.003108
 >> iter 98000, loss: 0.002268
 >> iter 99000, loss: 0.001864
 >> iter 100000, loss: 0.001709
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.282872
 >> iter 2000, loss: 13.673046
 >> iter 3000, loss: 8.312231
 >> iter 4000, loss: 4.320437
 >> iter 5000, loss: 2.132646
 >> iter 6000, loss: 1.496997
 >> iter 7000, loss: 0.973170
 >> iter 8000, loss: 0.626769
 >> iter 9000, loss: 0.393426
 >> iter 10000, loss: 0.344955
   Number of active neurons: 10
 >> iter 11000, loss: 0.177304
 >> iter 12000, loss: 0.286761
 >> iter 13000, loss: 0.146286
 >> iter 14000, loss: 0.146233
 >> iter 15000, loss: 0.351310
 >> iter 16000, loss: 0.191064
 >> iter 17000, loss: 0.144295
 >> iter 18000, loss: 0.227108
 >> iter 19000, loss: 0.213669
 >> iter 20000, loss: 0.132218
   Number of active neurons: 10
 >> iter 21000, loss: 0.080637
 >> iter 22000, loss: 0.080769
 >> iter 23000, loss: 0.092353
 >> iter 24000, loss: 0.096139
 >> iter 25000, loss: 0.064747
 >> iter 26000, loss: 0.075975
 >> iter 27000, loss: 0.058816
 >> iter 28000, loss: 0.132430
 >> iter 29000, loss: 0.090652
 >> iter 30000, loss: 0.040982
   Number of active neurons: 10
 >> iter 31000, loss: 0.021587
 >> iter 32000, loss: 0.022539
 >> iter 33000, loss: 0.084730
 >> iter 34000, loss: 0.117040
 >> iter 35000, loss: 0.119792
 >> iter 36000, loss: 0.052501
 >> iter 37000, loss: 0.027872
 >> iter 38000, loss: 0.014847
 >> iter 39000, loss: 0.060710
 >> iter 40000, loss: 0.028530
   Number of active neurons: 10
 >> iter 41000, loss: 0.057235
 >> iter 42000, loss: 0.087068
 >> iter 43000, loss: 0.055744
 >> iter 44000, loss: 0.029511
 >> iter 45000, loss: 0.016802
 >> iter 46000, loss: 0.094827
 >> iter 47000, loss: 0.039784
 >> iter 48000, loss: 0.134174
 >> iter 49000, loss: 0.092692
 >> iter 50000, loss: 0.143042
   Number of active neurons: 10
 >> iter 51000, loss: 0.086200
 >> iter 52000, loss: 0.074495
 >> iter 53000, loss: 0.053460
 >> iter 54000, loss: 0.127329
 >> iter 55000, loss: 0.078816
 >> iter 56000, loss: 0.051479
 >> iter 57000, loss: 0.052659
 >> iter 58000, loss: 0.024686
 >> iter 59000, loss: 0.033220
 >> iter 60000, loss: 0.045483
   Number of active neurons: 10
 >> iter 61000, loss: 0.177158
 >> iter 62000, loss: 0.109792
 >> iter 63000, loss: 0.097361
 >> iter 64000, loss: 0.041416
 >> iter 65000, loss: 0.019951
 >> iter 66000, loss: 0.079478
 >> iter 67000, loss: 0.038072
 >> iter 68000, loss: 0.017796
 >> iter 69000, loss: 0.009854
 >> iter 70000, loss: 0.006429
   Number of active neurons: 10
 >> iter 71000, loss: 0.029266
 >> iter 72000, loss: 0.032427
 >> iter 73000, loss: 0.016042
 >> iter 74000, loss: 0.032188
 >> iter 75000, loss: 0.016296
 >> iter 76000, loss: 0.008579
 >> iter 77000, loss: 0.005399
 >> iter 78000, loss: 0.005608
 >> iter 79000, loss: 0.004031
 >> iter 80000, loss: 0.005921
   Number of active neurons: 10
 >> iter 81000, loss: 0.006049
 >> iter 82000, loss: 0.030337
 >> iter 83000, loss: 0.028742
 >> iter 84000, loss: 0.029575
 >> iter 85000, loss: 0.013129
 >> iter 86000, loss: 0.008715
 >> iter 87000, loss: 0.005231
 >> iter 88000, loss: 0.008610
 >> iter 89000, loss: 0.008955
 >> iter 90000, loss: 0.006051
   Number of active neurons: 10
 >> iter 91000, loss: 0.010454
 >> iter 92000, loss: 0.065400
 >> iter 93000, loss: 0.027196
 >> iter 94000, loss: 0.082530
 >> iter 95000, loss: 0.078060
 >> iter 96000, loss: 0.106621
 >> iter 97000, loss: 0.061932
 >> iter 98000, loss: 0.026569
 >> iter 99000, loss: 0.014576
 >> iter 100000, loss: 0.030033
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.310389
 >> iter 2000, loss: 14.723420
 >> iter 3000, loss: 10.111955
 >> iter 4000, loss: 5.586804
 >> iter 5000, loss: 3.533135
 >> iter 6000, loss: 2.276415
 >> iter 7000, loss: 1.301262
 >> iter 8000, loss: 0.778529
 >> iter 9000, loss: 0.551664
 >> iter 10000, loss: 0.583726
   Number of active neurons: 10
 >> iter 11000, loss: 0.496880
 >> iter 12000, loss: 0.310170
 >> iter 13000, loss: 0.306132
 >> iter 14000, loss: 0.156932
 >> iter 15000, loss: 0.359167
 >> iter 16000, loss: 0.298591
 >> iter 17000, loss: 0.411602
 >> iter 18000, loss: 0.205354
 >> iter 19000, loss: 0.348233
 >> iter 20000, loss: 0.223439
   Number of active neurons: 10
 >> iter 21000, loss: 0.107927
 >> iter 22000, loss: 0.228106
 >> iter 23000, loss: 0.147101
 >> iter 24000, loss: 0.103568
 >> iter 25000, loss: 0.083947
 >> iter 26000, loss: 0.188309
 >> iter 27000, loss: 0.140269
 >> iter 28000, loss: 0.107128
 >> iter 29000, loss: 0.195993
 >> iter 30000, loss: 0.085009
   Number of active neurons: 10
 >> iter 31000, loss: 0.283539
 >> iter 32000, loss: 0.179321
 >> iter 33000, loss: 0.172973
 >> iter 34000, loss: 0.090209
 >> iter 35000, loss: 0.091053
 >> iter 36000, loss: 0.046110
 >> iter 37000, loss: 0.024762
 >> iter 38000, loss: 0.019665
 >> iter 39000, loss: 0.021858
 >> iter 40000, loss: 0.013809
   Number of active neurons: 10
 >> iter 41000, loss: 0.054292
 >> iter 42000, loss: 0.048024
 >> iter 43000, loss: 0.049897
 >> iter 44000, loss: 0.027378
 >> iter 45000, loss: 0.018085
 >> iter 46000, loss: 0.021679
 >> iter 47000, loss: 0.014622
 >> iter 48000, loss: 0.021415
 >> iter 49000, loss: 0.060712
 >> iter 50000, loss: 0.083204
   Number of active neurons: 10
 >> iter 51000, loss: 0.083654
 >> iter 52000, loss: 0.050674
 >> iter 53000, loss: 0.022371
 >> iter 54000, loss: 0.029141
 >> iter 55000, loss: 0.015036
 >> iter 56000, loss: 0.026117
 >> iter 57000, loss: 0.022241
 >> iter 58000, loss: 0.011601
 >> iter 59000, loss: 0.010992
 >> iter 60000, loss: 0.020504
   Number of active neurons: 10
 >> iter 61000, loss: 0.043068
 >> iter 62000, loss: 0.018903
 >> iter 63000, loss: 0.023674
 >> iter 64000, loss: 0.011353
 >> iter 65000, loss: 0.013522
 >> iter 66000, loss: 0.021429
 >> iter 67000, loss: 0.009873
 >> iter 68000, loss: 0.020180
 >> iter 69000, loss: 0.010078
 >> iter 70000, loss: 0.036874
   Number of active neurons: 10
 >> iter 71000, loss: 0.019452
 >> iter 72000, loss: 0.010814
 >> iter 73000, loss: 0.025631
 >> iter 74000, loss: 0.012817
 >> iter 75000, loss: 0.006482
 >> iter 76000, loss: 0.004234
 >> iter 77000, loss: 0.013590
 >> iter 78000, loss: 0.006714
 >> iter 79000, loss: 0.004707
 >> iter 80000, loss: 0.017630
   Number of active neurons: 10
 >> iter 81000, loss: 0.008173
 >> iter 82000, loss: 0.004588
 >> iter 83000, loss: 0.003030
 >> iter 84000, loss: 0.032467
 >> iter 85000, loss: 0.075518
 >> iter 86000, loss: 0.029982
 >> iter 87000, loss: 0.017040
 >> iter 88000, loss: 0.008403
 >> iter 89000, loss: 0.004422
 >> iter 90000, loss: 0.046276
   Number of active neurons: 10
 >> iter 91000, loss: 0.018441
 >> iter 92000, loss: 0.075989
 >> iter 93000, loss: 0.030941
 >> iter 94000, loss: 0.013442
 >> iter 95000, loss: 0.006745
 >> iter 96000, loss: 0.071554
 >> iter 97000, loss: 0.030207
 >> iter 98000, loss: 0.012481
 >> iter 99000, loss: 0.006251
 >> iter 100000, loss: 0.003843
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.318423
 >> iter 2000, loss: 14.015730
 >> iter 3000, loss: 9.143839
 >> iter 4000, loss: 4.888953
 >> iter 5000, loss: 2.988285
 >> iter 6000, loss: 1.533679
 >> iter 7000, loss: 0.901488
 >> iter 8000, loss: 0.670652
 >> iter 9000, loss: 0.583407
 >> iter 10000, loss: 0.492834
   Number of active neurons: 10
 >> iter 11000, loss: 0.483949
 >> iter 12000, loss: 0.351664
 >> iter 13000, loss: 0.203173
 >> iter 14000, loss: 0.254883
 >> iter 15000, loss: 0.259943
 >> iter 16000, loss: 0.281161
 >> iter 17000, loss: 0.326309
 >> iter 18000, loss: 0.181665
 >> iter 19000, loss: 0.177367
 >> iter 20000, loss: 0.181747
   Number of active neurons: 10
 >> iter 21000, loss: 0.116831
 >> iter 22000, loss: 0.191099
 >> iter 23000, loss: 0.128393
 >> iter 24000, loss: 0.099080
 >> iter 25000, loss: 0.068181
 >> iter 26000, loss: 0.036068
 >> iter 27000, loss: 0.047827
 >> iter 28000, loss: 0.074786
 >> iter 29000, loss: 0.036035
 >> iter 30000, loss: 0.048408
   Number of active neurons: 10
 >> iter 31000, loss: 0.104975
 >> iter 32000, loss: 0.068991
 >> iter 33000, loss: 0.094138
 >> iter 34000, loss: 0.041939
 >> iter 35000, loss: 0.021558
 >> iter 36000, loss: 0.016869
 >> iter 37000, loss: 0.011082
 >> iter 38000, loss: 0.068202
 >> iter 39000, loss: 0.201713
 >> iter 40000, loss: 0.121946
   Number of active neurons: 10
 >> iter 41000, loss: 0.056281
 >> iter 42000, loss: 0.074792
 >> iter 43000, loss: 0.054163
 >> iter 44000, loss: 0.025340
 >> iter 45000, loss: 0.013384
 >> iter 46000, loss: 0.040031
 >> iter 47000, loss: 0.020216
 >> iter 48000, loss: 0.011754
 >> iter 49000, loss: 0.015975
 >> iter 50000, loss: 0.028231
   Number of active neurons: 10
 >> iter 51000, loss: 0.026000
 >> iter 52000, loss: 0.050339
 >> iter 53000, loss: 0.021578
 >> iter 54000, loss: 0.020605
 >> iter 55000, loss: 0.016150
 >> iter 56000, loss: 0.022346
 >> iter 57000, loss: 0.057226
 >> iter 58000, loss: 0.037021
 >> iter 59000, loss: 0.017721
 >> iter 60000, loss: 0.008913
   Number of active neurons: 10
 >> iter 61000, loss: 0.007801
 >> iter 62000, loss: 0.048642
 >> iter 63000, loss: 0.021009
 >> iter 64000, loss: 0.012533
 >> iter 65000, loss: 0.021156
 >> iter 66000, loss: 0.010570
 >> iter 67000, loss: 0.006670
 >> iter 68000, loss: 0.064586
 >> iter 69000, loss: 0.027030
 >> iter 70000, loss: 0.012833
   Number of active neurons: 10
 >> iter 71000, loss: 0.020921
 >> iter 72000, loss: 0.080202
 >> iter 73000, loss: 0.033219
 >> iter 74000, loss: 0.015613
 >> iter 75000, loss: 0.010298
 >> iter 76000, loss: 0.093248
 >> iter 77000, loss: 0.040042
 >> iter 78000, loss: 0.109684
 >> iter 79000, loss: 0.043257
 >> iter 80000, loss: 0.036210
   Number of active neurons: 10
 >> iter 81000, loss: 0.025146
 >> iter 82000, loss: 0.011432
 >> iter 83000, loss: 0.006574
 >> iter 84000, loss: 0.005027
 >> iter 85000, loss: 0.101632
 >> iter 86000, loss: 0.039493
 >> iter 87000, loss: 0.029101
 >> iter 88000, loss: 0.013505
 >> iter 89000, loss: 0.007098
 >> iter 90000, loss: 0.004160
   Number of active neurons: 10
 >> iter 91000, loss: 0.003001
 >> iter 92000, loss: 0.004858
 >> iter 93000, loss: 0.003194
 >> iter 94000, loss: 0.002616
 >> iter 95000, loss: 0.002430
 >> iter 96000, loss: 0.002062
 >> iter 97000, loss: 0.004255
 >> iter 98000, loss: 0.002863
 >> iter 99000, loss: 0.044975
 >> iter 100000, loss: 0.034928
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.247831
 >> iter 2000, loss: 13.209046
 >> iter 3000, loss: 7.575339
 >> iter 4000, loss: 4.720106
 >> iter 5000, loss: 3.024399
 >> iter 6000, loss: 1.931148
 >> iter 7000, loss: 1.403596
 >> iter 8000, loss: 0.997380
 >> iter 9000, loss: 1.000159
 >> iter 10000, loss: 0.717311
   Number of active neurons: 10
 >> iter 11000, loss: 0.763730
 >> iter 12000, loss: 0.568216
 >> iter 13000, loss: 0.500906
 >> iter 14000, loss: 0.446917
 >> iter 15000, loss: 0.418943
 >> iter 16000, loss: 0.325509
 >> iter 17000, loss: 0.255655
 >> iter 18000, loss: 0.169075
 >> iter 19000, loss: 0.165468
 >> iter 20000, loss: 0.101037
   Number of active neurons: 10
 >> iter 21000, loss: 0.417560
 >> iter 22000, loss: 0.264234
 >> iter 23000, loss: 0.250853
 >> iter 24000, loss: 0.270246
 >> iter 25000, loss: 0.309422
 >> iter 26000, loss: 0.166833
 >> iter 27000, loss: 0.215372
 >> iter 28000, loss: 0.244590
 >> iter 29000, loss: 0.208463
 >> iter 30000, loss: 0.153067
   Number of active neurons: 10
 >> iter 31000, loss: 0.141717
 >> iter 32000, loss: 0.212023
 >> iter 33000, loss: 0.166754
 >> iter 34000, loss: 0.162246
 >> iter 35000, loss: 0.211685
 >> iter 36000, loss: 0.088083
 >> iter 37000, loss: 0.075918
 >> iter 38000, loss: 0.039238
 >> iter 39000, loss: 0.020327
 >> iter 40000, loss: 0.029166
   Number of active neurons: 10
 >> iter 41000, loss: 0.051894
 >> iter 42000, loss: 0.036671
 >> iter 43000, loss: 0.074527
 >> iter 44000, loss: 0.051298
 >> iter 45000, loss: 0.101003
 >> iter 46000, loss: 0.045739
 >> iter 47000, loss: 0.029980
 >> iter 48000, loss: 0.014749
 >> iter 49000, loss: 0.020932
 >> iter 50000, loss: 0.013048
   Number of active neurons: 10
 >> iter 51000, loss: 0.009254
 >> iter 52000, loss: 0.035415
 >> iter 53000, loss: 0.017527
 >> iter 54000, loss: 0.010833
 >> iter 55000, loss: 0.015556
 >> iter 56000, loss: 0.021781
 >> iter 57000, loss: 0.014216
 >> iter 58000, loss: 0.041449
 >> iter 59000, loss: 0.076510
 >> iter 60000, loss: 0.093297
   Number of active neurons: 10
 >> iter 61000, loss: 0.137889
 >> iter 62000, loss: 0.096743
 >> iter 63000, loss: 0.075322
 >> iter 64000, loss: 0.031874
 >> iter 65000, loss: 0.015360
 >> iter 66000, loss: 0.059381
 >> iter 67000, loss: 0.065368
 >> iter 68000, loss: 0.029843
 >> iter 69000, loss: 0.019442
 >> iter 70000, loss: 0.010462
   Number of active neurons: 10
 >> iter 71000, loss: 0.022586
 >> iter 72000, loss: 0.014578
 >> iter 73000, loss: 0.052122
 >> iter 74000, loss: 0.050603
 >> iter 75000, loss: 0.023142
 >> iter 76000, loss: 0.012068
 >> iter 77000, loss: 0.008041
 >> iter 78000, loss: 0.005057
 >> iter 79000, loss: 0.003623
 >> iter 80000, loss: 0.005106
   Number of active neurons: 10
 >> iter 81000, loss: 0.003515
 >> iter 82000, loss: 0.004007
 >> iter 83000, loss: 0.002821
 >> iter 84000, loss: 0.019858
 >> iter 85000, loss: 0.074920
 >> iter 86000, loss: 0.030971
 >> iter 87000, loss: 0.014304
 >> iter 88000, loss: 0.006551
 >> iter 89000, loss: 0.026225
 >> iter 90000, loss: 0.014265
   Number of active neurons: 10
 >> iter 91000, loss: 0.007908
 >> iter 92000, loss: 0.049852
 >> iter 93000, loss: 0.023145
 >> iter 94000, loss: 0.035057
 >> iter 95000, loss: 0.028804
 >> iter 96000, loss: 0.012437
 >> iter 97000, loss: 0.112688
 >> iter 98000, loss: 0.052941
 >> iter 99000, loss: 0.102739
 >> iter 100000, loss: 0.047524
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.262752
 >> iter 2000, loss: 12.763617
 >> iter 3000, loss: 6.856945
 >> iter 4000, loss: 3.980672
 >> iter 5000, loss: 2.229649
 >> iter 6000, loss: 1.355617
 >> iter 7000, loss: 0.815171
 >> iter 8000, loss: 0.632216
 >> iter 9000, loss: 0.598113
 >> iter 10000, loss: 0.349741
   Number of active neurons: 10
 >> iter 11000, loss: 0.306451
 >> iter 12000, loss: 0.218672
 >> iter 13000, loss: 0.146278
 >> iter 14000, loss: 0.263114
 >> iter 15000, loss: 0.172843
 >> iter 16000, loss: 0.253657
 >> iter 17000, loss: 0.202406
 >> iter 18000, loss: 0.204764
 >> iter 19000, loss: 0.138710
 >> iter 20000, loss: 0.079267
   Number of active neurons: 10
 >> iter 21000, loss: 0.040359
 >> iter 22000, loss: 0.048545
 >> iter 23000, loss: 0.046243
 >> iter 24000, loss: 0.025943
 >> iter 25000, loss: 0.092740
 >> iter 26000, loss: 0.069750
 >> iter 27000, loss: 0.141255
 >> iter 28000, loss: 0.086629
 >> iter 29000, loss: 0.142012
 >> iter 30000, loss: 0.083511
   Number of active neurons: 10
 >> iter 31000, loss: 0.055607
 >> iter 32000, loss: 0.197100
 >> iter 33000, loss: 0.108790
 >> iter 34000, loss: 0.055589
 >> iter 35000, loss: 0.145832
 >> iter 36000, loss: 0.069036
 >> iter 37000, loss: 0.044988
 >> iter 38000, loss: 0.022992
 >> iter 39000, loss: 0.012614
 >> iter 40000, loss: 0.107000
   Number of active neurons: 10
 >> iter 41000, loss: 0.090308
 >> iter 42000, loss: 0.039595
 >> iter 43000, loss: 0.036005
 >> iter 44000, loss: 0.064276
 >> iter 45000, loss: 0.028123
 >> iter 46000, loss: 0.019148
 >> iter 47000, loss: 0.132547
 >> iter 48000, loss: 0.057915
 >> iter 49000, loss: 0.025157
 >> iter 50000, loss: 0.012166
   Number of active neurons: 10
 >> iter 51000, loss: 0.007520
 >> iter 52000, loss: 0.010279
 >> iter 53000, loss: 0.015709
 >> iter 54000, loss: 0.058081
 >> iter 55000, loss: 0.046189
 >> iter 56000, loss: 0.025112
 >> iter 57000, loss: 0.022773
 >> iter 58000, loss: 0.024935
 >> iter 59000, loss: 0.017413
 >> iter 60000, loss: 0.012864
   Number of active neurons: 10
 >> iter 61000, loss: 0.007033
 >> iter 62000, loss: 0.056426
 >> iter 63000, loss: 0.030175
 >> iter 64000, loss: 0.031348
 >> iter 65000, loss: 0.093319
 >> iter 66000, loss: 0.047928
 >> iter 67000, loss: 0.021029
 >> iter 68000, loss: 0.015489
 >> iter 69000, loss: 0.008777
 >> iter 70000, loss: 0.040303
   Number of active neurons: 10
 >> iter 71000, loss: 0.068074
 >> iter 72000, loss: 0.093591
 >> iter 73000, loss: 0.273238
 >> iter 74000, loss: 0.126062
 >> iter 75000, loss: 0.069060
 >> iter 76000, loss: 0.051152
 >> iter 77000, loss: 0.023068
 >> iter 78000, loss: 0.153788
 >> iter 79000, loss: 0.066061
 >> iter 80000, loss: 0.062253
   Number of active neurons: 10
 >> iter 81000, loss: 0.044820
 >> iter 82000, loss: 0.071999
 >> iter 83000, loss: 0.039533
 >> iter 84000, loss: 0.021106
 >> iter 85000, loss: 0.028718
 >> iter 86000, loss: 0.067100
 >> iter 87000, loss: 0.105457
 >> iter 88000, loss: 0.044237
 >> iter 89000, loss: 0.047818
 >> iter 90000, loss: 0.029466
   Number of active neurons: 10
 >> iter 91000, loss: 0.015106
 >> iter 92000, loss: 0.039512
 >> iter 93000, loss: 0.020113
 >> iter 94000, loss: 0.010912
 >> iter 95000, loss: 0.006979
 >> iter 96000, loss: 0.005049
 >> iter 97000, loss: 0.004366
 >> iter 98000, loss: 0.006809
 >> iter 99000, loss: 0.006009
 >> iter 100000, loss: 0.020285
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.192409
 >> iter 2000, loss: 13.310524
 >> iter 3000, loss: 8.020969
 >> iter 4000, loss: 3.731524
 >> iter 5000, loss: 1.878985
 >> iter 6000, loss: 0.994424
 >> iter 7000, loss: 0.545124
 >> iter 8000, loss: 0.342544
 >> iter 9000, loss: 0.331062
 >> iter 10000, loss: 0.270100
   Number of active neurons: 10
 >> iter 11000, loss: 0.291022
 >> iter 12000, loss: 0.248561
 >> iter 13000, loss: 0.115221
 >> iter 14000, loss: 0.117795
 >> iter 15000, loss: 0.101856
 >> iter 16000, loss: 0.084665
 >> iter 17000, loss: 0.051899
 >> iter 18000, loss: 0.259747
 >> iter 19000, loss: 0.280969
 >> iter 20000, loss: 0.141579
   Number of active neurons: 10
 >> iter 21000, loss: 0.126872
 >> iter 22000, loss: 0.075806
 >> iter 23000, loss: 0.094730
 >> iter 24000, loss: 0.098400
 >> iter 25000, loss: 0.058028
 >> iter 26000, loss: 0.048075
 >> iter 27000, loss: 0.030858
 >> iter 28000, loss: 0.017172
 >> iter 29000, loss: 0.033985
 >> iter 30000, loss: 0.065585
   Number of active neurons: 10
 >> iter 31000, loss: 0.069441
 >> iter 32000, loss: 0.044613
 >> iter 33000, loss: 0.167870
 >> iter 34000, loss: 0.068272
 >> iter 35000, loss: 0.029397
 >> iter 36000, loss: 0.016948
 >> iter 37000, loss: 0.035105
 >> iter 38000, loss: 0.031691
 >> iter 39000, loss: 0.027546
 >> iter 40000, loss: 0.019911
   Number of active neurons: 10
 >> iter 41000, loss: 0.020175
 >> iter 42000, loss: 0.032701
 >> iter 43000, loss: 0.015565
 >> iter 44000, loss: 0.052995
 >> iter 45000, loss: 0.027168
 >> iter 46000, loss: 0.061300
 >> iter 47000, loss: 0.027715
 >> iter 48000, loss: 0.023324
 >> iter 49000, loss: 0.087875
 >> iter 50000, loss: 0.039948
   Number of active neurons: 10
 >> iter 51000, loss: 0.018474
 >> iter 52000, loss: 0.089741
 >> iter 53000, loss: 0.036632
 >> iter 54000, loss: 0.060489
 >> iter 55000, loss: 0.025534
 >> iter 56000, loss: 0.022295
 >> iter 57000, loss: 0.018131
 >> iter 58000, loss: 0.009770
 >> iter 59000, loss: 0.009164
 >> iter 60000, loss: 0.098093
   Number of active neurons: 10
 >> iter 61000, loss: 0.039237
 >> iter 62000, loss: 0.018499
 >> iter 63000, loss: 0.009429
 >> iter 64000, loss: 0.005925
 >> iter 65000, loss: 0.090884
 >> iter 66000, loss: 0.062615
 >> iter 67000, loss: 0.026735
 >> iter 68000, loss: 0.012388
 >> iter 69000, loss: 0.006909
 >> iter 70000, loss: 0.005869
   Number of active neurons: 10
 >> iter 71000, loss: 0.010610
 >> iter 72000, loss: 0.065308
 >> iter 73000, loss: 0.031200
 >> iter 74000, loss: 0.017116
 >> iter 75000, loss: 0.029612
 >> iter 76000, loss: 0.050840
 >> iter 77000, loss: 0.020935
 >> iter 78000, loss: 0.023186
 >> iter 79000, loss: 0.057025
 >> iter 80000, loss: 0.032474
   Number of active neurons: 10
 >> iter 81000, loss: 0.016462
 >> iter 82000, loss: 0.008631
 >> iter 83000, loss: 0.012277
 >> iter 84000, loss: 0.012968
 >> iter 85000, loss: 0.015358
 >> iter 86000, loss: 0.140192
 >> iter 87000, loss: 0.054474
 >> iter 88000, loss: 0.023858
 >> iter 89000, loss: 0.012688
 >> iter 90000, loss: 0.006820
   Number of active neurons: 10
 >> iter 91000, loss: 0.011132
 >> iter 92000, loss: 0.061119
 >> iter 93000, loss: 0.024603
 >> iter 94000, loss: 0.021454
 >> iter 95000, loss: 0.009672
 >> iter 96000, loss: 0.041027
 >> iter 97000, loss: 0.037091
 >> iter 98000, loss: 0.019666
 >> iter 99000, loss: 0.017442
 >> iter 100000, loss: 0.008222
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.198927
 >> iter 2000, loss: 13.138596
 >> iter 3000, loss: 7.198953
 >> iter 4000, loss: 3.842852
 >> iter 5000, loss: 1.964786
 >> iter 6000, loss: 0.962864
 >> iter 7000, loss: 0.833980
 >> iter 8000, loss: 0.516157
 >> iter 9000, loss: 0.398640
 >> iter 10000, loss: 0.271100
   Number of active neurons: 10
 >> iter 11000, loss: 0.403490
 >> iter 12000, loss: 0.267259
 >> iter 13000, loss: 0.261351
 >> iter 14000, loss: 0.142659
 >> iter 15000, loss: 0.154204
 >> iter 16000, loss: 0.100835
 >> iter 17000, loss: 0.128674
 >> iter 18000, loss: 0.075531
 >> iter 19000, loss: 0.108061
 >> iter 20000, loss: 0.062787
   Number of active neurons: 10
 >> iter 21000, loss: 0.053425
 >> iter 22000, loss: 0.073815
 >> iter 23000, loss: 0.089516
 >> iter 24000, loss: 0.099987
 >> iter 25000, loss: 0.045856
 >> iter 26000, loss: 0.029367
 >> iter 27000, loss: 0.042259
 >> iter 28000, loss: 0.072941
 >> iter 29000, loss: 0.159033
 >> iter 30000, loss: 0.117338
   Number of active neurons: 10
 >> iter 31000, loss: 0.088776
 >> iter 32000, loss: 0.058092
 >> iter 33000, loss: 0.042947
 >> iter 34000, loss: 0.168465
 >> iter 35000, loss: 0.178839
 >> iter 36000, loss: 0.086790
 >> iter 37000, loss: 0.042514
 >> iter 38000, loss: 0.046802
 >> iter 39000, loss: 0.128295
 >> iter 40000, loss: 0.057809
   Number of active neurons: 10
 >> iter 41000, loss: 0.026621
 >> iter 42000, loss: 0.035308
 >> iter 43000, loss: 0.028485
 >> iter 44000, loss: 0.027200
 >> iter 45000, loss: 0.038752
 >> iter 46000, loss: 0.018574
 >> iter 47000, loss: 0.053232
 >> iter 48000, loss: 0.032634
 >> iter 49000, loss: 0.016195
 >> iter 50000, loss: 0.035819
   Number of active neurons: 10
 >> iter 51000, loss: 0.052466
 >> iter 52000, loss: 0.024633
 >> iter 53000, loss: 0.032815
 >> iter 54000, loss: 0.057745
 >> iter 55000, loss: 0.036126
 >> iter 56000, loss: 0.017143
 >> iter 57000, loss: 0.032969
 >> iter 58000, loss: 0.023603
 >> iter 59000, loss: 0.016515
 >> iter 60000, loss: 0.009150
   Number of active neurons: 10
 >> iter 61000, loss: 0.006220
 >> iter 62000, loss: 0.005216
 >> iter 63000, loss: 0.065120
 >> iter 64000, loss: 0.028378
 >> iter 65000, loss: 0.073481
 >> iter 66000, loss: 0.052596
 >> iter 67000, loss: 0.026208
 >> iter 68000, loss: 0.108106
 >> iter 69000, loss: 0.042849
 >> iter 70000, loss: 0.024470
   Number of active neurons: 10
 >> iter 71000, loss: 0.019692
 >> iter 72000, loss: 0.009834
 >> iter 73000, loss: 0.006018
 >> iter 74000, loss: 0.039627
 >> iter 75000, loss: 0.103083
 >> iter 76000, loss: 0.073748
 >> iter 77000, loss: 0.030417
 >> iter 78000, loss: 0.013672
 >> iter 79000, loss: 0.008532
 >> iter 80000, loss: 0.033079
   Number of active neurons: 10
 >> iter 81000, loss: 0.015556
 >> iter 82000, loss: 0.059450
 >> iter 83000, loss: 0.025034
 >> iter 84000, loss: 0.012380
 >> iter 85000, loss: 0.057058
 >> iter 86000, loss: 0.024021
 >> iter 87000, loss: 0.011801
 >> iter 88000, loss: 0.007751
 >> iter 89000, loss: 0.005256
 >> iter 90000, loss: 0.103324
   Number of active neurons: 10
 >> iter 91000, loss: 0.054861
 >> iter 92000, loss: 0.022444
 >> iter 93000, loss: 0.023774
 >> iter 94000, loss: 0.064676
 >> iter 95000, loss: 0.026439
 >> iter 96000, loss: 0.020868
 >> iter 97000, loss: 0.064922
 >> iter 98000, loss: 0.026738
 >> iter 99000, loss: 0.014297
 >> iter 100000, loss: 0.007281
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.392743
 >> iter 2000, loss: 12.909788
 >> iter 3000, loss: 7.882185
 >> iter 4000, loss: 4.587787
 >> iter 5000, loss: 2.491282
 >> iter 6000, loss: 1.409151
 >> iter 7000, loss: 1.070744
 >> iter 8000, loss: 0.596628
 >> iter 9000, loss: 0.637457
 >> iter 10000, loss: 0.428300
   Number of active neurons: 10
 >> iter 11000, loss: 0.225470
 >> iter 12000, loss: 0.135243
 >> iter 13000, loss: 0.120882
 >> iter 14000, loss: 0.174380
 >> iter 15000, loss: 0.232200
 >> iter 16000, loss: 0.127977
 >> iter 17000, loss: 0.186994
 >> iter 18000, loss: 0.302914
 >> iter 19000, loss: 0.147300
 >> iter 20000, loss: 0.215318
   Number of active neurons: 10
 >> iter 21000, loss: 0.344733
 >> iter 22000, loss: 0.202466
 >> iter 23000, loss: 0.139040
 >> iter 24000, loss: 0.152465
 >> iter 25000, loss: 0.082893
 >> iter 26000, loss: 0.071714
 >> iter 27000, loss: 0.049276
 >> iter 28000, loss: 0.126500
 >> iter 29000, loss: 0.054477
 >> iter 30000, loss: 0.125425
   Number of active neurons: 10
 >> iter 31000, loss: 0.080553
 >> iter 32000, loss: 0.099153
 >> iter 33000, loss: 0.095458
 >> iter 34000, loss: 0.211805
 >> iter 35000, loss: 0.172608
 >> iter 36000, loss: 0.096837
 >> iter 37000, loss: 0.201860
 >> iter 38000, loss: 0.114345
 >> iter 39000, loss: 0.073007
 >> iter 40000, loss: 0.036971
   Number of active neurons: 10
 >> iter 41000, loss: 0.043310
 >> iter 42000, loss: 0.100434
 >> iter 43000, loss: 0.053135
 >> iter 44000, loss: 0.023716
 >> iter 45000, loss: 0.087547
 >> iter 46000, loss: 0.040920
 >> iter 47000, loss: 0.028653
 >> iter 48000, loss: 0.014945
 >> iter 49000, loss: 0.047398
 >> iter 50000, loss: 0.022986
   Number of active neurons: 10
 >> iter 51000, loss: 0.159150
 >> iter 52000, loss: 0.086899
 >> iter 53000, loss: 0.036337
 >> iter 54000, loss: 0.017528
 >> iter 55000, loss: 0.010804
 >> iter 56000, loss: 0.102430
 >> iter 57000, loss: 0.147939
 >> iter 58000, loss: 0.144461
 >> iter 59000, loss: 0.067168
 >> iter 60000, loss: 0.082537
   Number of active neurons: 10
 >> iter 61000, loss: 0.077984
 >> iter 62000, loss: 0.036790
 >> iter 63000, loss: 0.123203
 >> iter 64000, loss: 0.062566
 >> iter 65000, loss: 0.050748
 >> iter 66000, loss: 0.022076
 >> iter 67000, loss: 0.013259
 >> iter 68000, loss: 0.009367
 >> iter 69000, loss: 0.007416
 >> iter 70000, loss: 0.005360
   Number of active neurons: 10
 >> iter 71000, loss: 0.042582
 >> iter 72000, loss: 0.018395
 >> iter 73000, loss: 0.077159
 >> iter 74000, loss: 0.033945
 >> iter 75000, loss: 0.015041
 >> iter 76000, loss: 0.012281
 >> iter 77000, loss: 0.013898
 >> iter 78000, loss: 0.018896
 >> iter 79000, loss: 0.034971
 >> iter 80000, loss: 0.092825
   Number of active neurons: 10
 >> iter 81000, loss: 0.058325
 >> iter 82000, loss: 0.025966
 >> iter 83000, loss: 0.011863
 >> iter 84000, loss: 0.020463
 >> iter 85000, loss: 0.037128
 >> iter 86000, loss: 0.015655
 >> iter 87000, loss: 0.022257
 >> iter 88000, loss: 0.013558
 >> iter 89000, loss: 0.013987
 >> iter 90000, loss: 0.050775
   Number of active neurons: 10
 >> iter 91000, loss: 0.022203
 >> iter 92000, loss: 0.019747
 >> iter 93000, loss: 0.054456
 >> iter 94000, loss: 0.022684
 >> iter 95000, loss: 0.048234
 >> iter 96000, loss: 0.020049
 >> iter 97000, loss: 0.011257
 >> iter 98000, loss: 0.025484
 >> iter 99000, loss: 0.012103
 >> iter 100000, loss: 0.006304
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.241071
 >> iter 2000, loss: 13.787623
 >> iter 3000, loss: 8.148854
 >> iter 4000, loss: 4.014794
 >> iter 5000, loss: 2.055138
 >> iter 6000, loss: 1.083624
 >> iter 7000, loss: 0.767507
 >> iter 8000, loss: 0.380554
 >> iter 9000, loss: 0.276273
 >> iter 10000, loss: 0.376139
   Number of active neurons: 10
 >> iter 11000, loss: 0.380825
 >> iter 12000, loss: 0.204108
 >> iter 13000, loss: 0.244196
 >> iter 14000, loss: 0.194072
 >> iter 15000, loss: 0.170336
 >> iter 16000, loss: 0.234531
 >> iter 17000, loss: 0.214483
 >> iter 18000, loss: 0.124697
 >> iter 19000, loss: 0.130081
 >> iter 20000, loss: 0.088151
   Number of active neurons: 10
 >> iter 21000, loss: 0.214507
 >> iter 22000, loss: 0.168888
 >> iter 23000, loss: 0.070895
 >> iter 24000, loss: 0.041004
 >> iter 25000, loss: 0.183444
 >> iter 26000, loss: 0.228628
 >> iter 27000, loss: 0.144390
 >> iter 28000, loss: 0.069745
 >> iter 29000, loss: 0.037886
 >> iter 30000, loss: 0.020892
   Number of active neurons: 10
 >> iter 31000, loss: 0.014426
 >> iter 32000, loss: 0.026071
 >> iter 33000, loss: 0.054974
 >> iter 34000, loss: 0.025437
 >> iter 35000, loss: 0.029317
 >> iter 36000, loss: 0.063493
 >> iter 37000, loss: 0.045673
 >> iter 38000, loss: 0.020475
 >> iter 39000, loss: 0.128732
 >> iter 40000, loss: 0.087040
   Number of active neurons: 10
 >> iter 41000, loss: 0.131506
 >> iter 42000, loss: 0.080978
 >> iter 43000, loss: 0.042372
 >> iter 44000, loss: 0.034588
 >> iter 45000, loss: 0.047859
 >> iter 46000, loss: 0.025480
 >> iter 47000, loss: 0.014097
 >> iter 48000, loss: 0.008216
 >> iter 49000, loss: 0.007851
 >> iter 50000, loss: 0.005477
   Number of active neurons: 10
 >> iter 51000, loss: 0.004378
 >> iter 52000, loss: 0.009168
 >> iter 53000, loss: 0.006096
 >> iter 54000, loss: 0.009467
 >> iter 55000, loss: 0.005849
 >> iter 56000, loss: 0.005096
 >> iter 57000, loss: 0.011644
 >> iter 58000, loss: 0.069682
 >> iter 59000, loss: 0.030280
 >> iter 60000, loss: 0.015986
   Number of active neurons: 10
 >> iter 61000, loss: 0.063914
 >> iter 62000, loss: 0.025651
 >> iter 63000, loss: 0.016227
 >> iter 64000, loss: 0.027251
 >> iter 65000, loss: 0.011899
 >> iter 66000, loss: 0.021792
 >> iter 67000, loss: 0.009713
 >> iter 68000, loss: 0.008829
 >> iter 69000, loss: 0.005698
 >> iter 70000, loss: 0.015174
   Number of active neurons: 10
 >> iter 71000, loss: 0.039642
 >> iter 72000, loss: 0.018441
 >> iter 73000, loss: 0.008613
 >> iter 74000, loss: 0.004668
 >> iter 75000, loss: 0.003770
 >> iter 76000, loss: 0.007291
 >> iter 77000, loss: 0.020683
 >> iter 78000, loss: 0.019745
 >> iter 79000, loss: 0.008789
 >> iter 80000, loss: 0.004724
   Number of active neurons: 10
 >> iter 81000, loss: 0.004361
 >> iter 82000, loss: 0.012374
 >> iter 83000, loss: 0.010498
 >> iter 84000, loss: 0.016862
 >> iter 85000, loss: 0.028679
 >> iter 86000, loss: 0.011959
 >> iter 87000, loss: 0.034016
 >> iter 88000, loss: 0.021165
 >> iter 89000, loss: 0.075155
 >> iter 90000, loss: 0.029519
   Number of active neurons: 10
 >> iter 91000, loss: 0.071234
 >> iter 92000, loss: 0.028949
 >> iter 93000, loss: 0.012175
 >> iter 94000, loss: 0.005878
 >> iter 95000, loss: 0.011321
 >> iter 96000, loss: 0.005685
 >> iter 97000, loss: 0.003604
 >> iter 98000, loss: 0.039921
 >> iter 99000, loss: 0.044625
 >> iter 100000, loss: 0.069221
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.326959
 >> iter 2000, loss: 13.708862
 >> iter 3000, loss: 8.309527
 >> iter 4000, loss: 3.922569
 >> iter 5000, loss: 2.038177
 >> iter 6000, loss: 1.107690
 >> iter 7000, loss: 0.818167
 >> iter 8000, loss: 0.438613
 >> iter 9000, loss: 0.315600
 >> iter 10000, loss: 0.321274
   Number of active neurons: 10
 >> iter 11000, loss: 0.252602
 >> iter 12000, loss: 0.232361
 >> iter 13000, loss: 0.220549
 >> iter 14000, loss: 0.294284
 >> iter 15000, loss: 0.415731
 >> iter 16000, loss: 0.260631
 >> iter 17000, loss: 0.173527
 >> iter 18000, loss: 0.189679
 >> iter 19000, loss: 0.130004
 >> iter 20000, loss: 0.068559
   Number of active neurons: 10
 >> iter 21000, loss: 0.073142
 >> iter 22000, loss: 0.039293
 >> iter 23000, loss: 0.132258
 >> iter 24000, loss: 0.064909
 >> iter 25000, loss: 0.036665
 >> iter 26000, loss: 0.216364
 >> iter 27000, loss: 0.161351
 >> iter 28000, loss: 0.156869
 >> iter 29000, loss: 0.121648
 >> iter 30000, loss: 0.068780
   Number of active neurons: 10
 >> iter 31000, loss: 0.127492
 >> iter 32000, loss: 0.065246
 >> iter 33000, loss: 0.050888
 >> iter 34000, loss: 0.121217
 >> iter 35000, loss: 0.107772
 >> iter 36000, loss: 0.086270
 >> iter 37000, loss: 0.041467
 >> iter 38000, loss: 0.035120
 >> iter 39000, loss: 0.116722
 >> iter 40000, loss: 0.098868
   Number of active neurons: 10
 >> iter 41000, loss: 0.061394
 >> iter 42000, loss: 0.029285
 >> iter 43000, loss: 0.040355
 >> iter 44000, loss: 0.021905
 >> iter 45000, loss: 0.016619
 >> iter 46000, loss: 0.013599
 >> iter 47000, loss: 0.073560
 >> iter 48000, loss: 0.051090
 >> iter 49000, loss: 0.044618
 >> iter 50000, loss: 0.022593
   Number of active neurons: 10
 >> iter 51000, loss: 0.013023
 >> iter 52000, loss: 0.014649
 >> iter 53000, loss: 0.012163
 >> iter 54000, loss: 0.021901
 >> iter 55000, loss: 0.017554
 >> iter 56000, loss: 0.045319
 >> iter 57000, loss: 0.028054
 >> iter 58000, loss: 0.014285
 >> iter 59000, loss: 0.077745
 >> iter 60000, loss: 0.045958
   Number of active neurons: 10
 >> iter 61000, loss: 0.022196
 >> iter 62000, loss: 0.012143
 >> iter 63000, loss: 0.011582
 >> iter 64000, loss: 0.007477
 >> iter 65000, loss: 0.006112
 >> iter 66000, loss: 0.010572
 >> iter 67000, loss: 0.006770
 >> iter 68000, loss: 0.007691
 >> iter 69000, loss: 0.062147
 >> iter 70000, loss: 0.025788
   Number of active neurons: 10
 >> iter 71000, loss: 0.012435
 >> iter 72000, loss: 0.016904
 >> iter 73000, loss: 0.071711
 >> iter 74000, loss: 0.160575
 >> iter 75000, loss: 0.128942
 >> iter 76000, loss: 0.052914
 >> iter 77000, loss: 0.038990
 >> iter 78000, loss: 0.018703
 >> iter 79000, loss: 0.029097
 >> iter 80000, loss: 0.028494
   Number of active neurons: 10
 >> iter 81000, loss: 0.013414
 >> iter 82000, loss: 0.151042
 >> iter 83000, loss: 0.060779
 >> iter 84000, loss: 0.110222
 >> iter 85000, loss: 0.044514
 >> iter 86000, loss: 0.019616
 >> iter 87000, loss: 0.015539
 >> iter 88000, loss: 0.025255
 >> iter 89000, loss: 0.028003
 >> iter 90000, loss: 0.017831
   Number of active neurons: 10
 >> iter 91000, loss: 0.009695
 >> iter 92000, loss: 0.006372
 >> iter 93000, loss: 0.005461
 >> iter 94000, loss: 0.004439
 >> iter 95000, loss: 0.110816
 >> iter 96000, loss: 0.044005
 >> iter 97000, loss: 0.025243
 >> iter 98000, loss: 0.014432
 >> iter 99000, loss: 0.007788
 >> iter 100000, loss: 0.005085
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 19.220326
 >> iter 2000, loss: 13.805509
 >> iter 3000, loss: 8.398846
 >> iter 4000, loss: 4.586114
 >> iter 5000, loss: 2.451669
 >> iter 6000, loss: 1.142758
 >> iter 7000, loss: 0.679932
 >> iter 8000, loss: 0.521279
 >> iter 9000, loss: 0.333358
 >> iter 10000, loss: 0.316546
   Number of active neurons: 10
 >> iter 11000, loss: 0.210321
 >> iter 12000, loss: 0.119670
 >> iter 13000, loss: 0.077546
 >> iter 14000, loss: 0.199151
 >> iter 15000, loss: 0.170105
 >> iter 16000, loss: 0.207381
 >> iter 17000, loss: 0.098583
 >> iter 18000, loss: 0.169318
 >> iter 19000, loss: 0.120889
 >> iter 20000, loss: 0.056609
   Number of active neurons: 10
 >> iter 21000, loss: 0.035770
 >> iter 22000, loss: 0.065266
 >> iter 23000, loss: 0.035503
 >> iter 24000, loss: 0.063322
 >> iter 25000, loss: 0.087212
 >> iter 26000, loss: 0.096576
 >> iter 27000, loss: 0.092220
 >> iter 28000, loss: 0.052940
 >> iter 29000, loss: 0.046314
 >> iter 30000, loss: 0.053923
   Number of active neurons: 10
 >> iter 31000, loss: 0.080453
 >> iter 32000, loss: 0.201764
 >> iter 33000, loss: 0.086834
 >> iter 34000, loss: 0.039556
 >> iter 35000, loss: 0.023973
 >> iter 36000, loss: 0.024127
 >> iter 37000, loss: 0.015845
 >> iter 38000, loss: 0.026863
 >> iter 39000, loss: 0.014726
 >> iter 40000, loss: 0.054953
   Number of active neurons: 10
 >> iter 41000, loss: 0.026324
 >> iter 42000, loss: 0.014052
 >> iter 43000, loss: 0.032054
 >> iter 44000, loss: 0.032539
 >> iter 45000, loss: 0.033340
 >> iter 46000, loss: 0.101531
 >> iter 47000, loss: 0.043299
 >> iter 48000, loss: 0.083350
 >> iter 49000, loss: 0.035244
 >> iter 50000, loss: 0.015767
   Number of active neurons: 10
 >> iter 51000, loss: 0.009008
 >> iter 52000, loss: 0.058812
 >> iter 53000, loss: 0.027388
 >> iter 54000, loss: 0.114770
 >> iter 55000, loss: 0.048116
 >> iter 56000, loss: 0.042762
 >> iter 57000, loss: 0.033552
 >> iter 58000, loss: 0.032829
 >> iter 59000, loss: 0.046693
 >> iter 60000, loss: 0.043576
   Number of active neurons: 10
 >> iter 61000, loss: 0.111839
 >> iter 62000, loss: 0.045669
 >> iter 63000, loss: 0.020460
 >> iter 64000, loss: 0.009700
 >> iter 65000, loss: 0.256919
 >> iter 66000, loss: 0.146114
 >> iter 67000, loss: 0.075762
 >> iter 68000, loss: 0.057280
 >> iter 69000, loss: 0.030156
 >> iter 70000, loss: 0.014896
   Number of active neurons: 10
 >> iter 71000, loss: 0.007759
 >> iter 72000, loss: 0.027012
 >> iter 73000, loss: 0.014497
 >> iter 74000, loss: 0.009410
 >> iter 75000, loss: 0.005788
 >> iter 76000, loss: 0.004104
 >> iter 77000, loss: 0.017708
 >> iter 78000, loss: 0.028422
 >> iter 79000, loss: 0.012626
 >> iter 80000, loss: 0.006578
   Number of active neurons: 10
 >> iter 81000, loss: 0.024208
 >> iter 82000, loss: 0.010944
 >> iter 83000, loss: 0.007027
 >> iter 84000, loss: 0.004247
 >> iter 85000, loss: 0.003770
 >> iter 86000, loss: 0.003472
 >> iter 87000, loss: 0.002653
 >> iter 88000, loss: 0.002330
 >> iter 89000, loss: 0.032448
 >> iter 90000, loss: 0.013414
   Number of active neurons: 10
 >> iter 91000, loss: 0.007372
 >> iter 92000, loss: 0.005995
 >> iter 93000, loss: 0.003784
 >> iter 94000, loss: 0.003044
 >> iter 95000, loss: 0.002379
 >> iter 96000, loss: 0.002036
 >> iter 97000, loss: 0.001936
 >> iter 98000, loss: 0.001972
 >> iter 99000, loss: 0.001742
 >> iter 100000, loss: 0.007162
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.371625
 >> iter 2000, loss: 13.713089
 >> iter 3000, loss: 7.457047
 >> iter 4000, loss: 3.590392
 >> iter 5000, loss: 1.765140
 >> iter 6000, loss: 1.047224
 >> iter 7000, loss: 0.481975
 >> iter 8000, loss: 0.316091
 >> iter 9000, loss: 0.212096
 >> iter 10000, loss: 0.132928
   Number of active neurons: 10
 >> iter 11000, loss: 0.126994
 >> iter 12000, loss: 0.135909
 >> iter 13000, loss: 0.185287
 >> iter 14000, loss: 0.201185
 >> iter 15000, loss: 0.138578
 >> iter 16000, loss: 0.088871
 >> iter 17000, loss: 0.108750
 >> iter 18000, loss: 0.134831
 >> iter 19000, loss: 0.135957
 >> iter 20000, loss: 0.108833
   Number of active neurons: 10
 >> iter 21000, loss: 0.057247
 >> iter 22000, loss: 0.083389
 >> iter 23000, loss: 0.044311
 >> iter 24000, loss: 0.024730
 >> iter 25000, loss: 0.038396
 >> iter 26000, loss: 0.024192
 >> iter 27000, loss: 0.016914
 >> iter 28000, loss: 0.063739
 >> iter 29000, loss: 0.039455
 >> iter 30000, loss: 0.085522
   Number of active neurons: 10
 >> iter 31000, loss: 0.155354
 >> iter 32000, loss: 0.183571
 >> iter 33000, loss: 0.170992
 >> iter 34000, loss: 0.071609
 >> iter 35000, loss: 0.043653
 >> iter 36000, loss: 0.024001
 >> iter 37000, loss: 0.013002
 >> iter 38000, loss: 0.011191
 >> iter 39000, loss: 0.008341
 >> iter 40000, loss: 0.009487
   Number of active neurons: 10
 >> iter 41000, loss: 0.042154
 >> iter 42000, loss: 0.065985
 >> iter 43000, loss: 0.029994
 >> iter 44000, loss: 0.014145
 >> iter 45000, loss: 0.030196
 >> iter 46000, loss: 0.193542
 >> iter 47000, loss: 0.166946
 >> iter 48000, loss: 0.068188
 >> iter 49000, loss: 0.068214
 >> iter 50000, loss: 0.071232
   Number of active neurons: 10
 >> iter 51000, loss: 0.031267
 >> iter 52000, loss: 0.014540
 >> iter 53000, loss: 0.008733
 >> iter 54000, loss: 0.006912
 >> iter 55000, loss: 0.005675
 >> iter 56000, loss: 0.005287
 >> iter 57000, loss: 0.111645
 >> iter 58000, loss: 0.044600
 >> iter 59000, loss: 0.019758
 >> iter 60000, loss: 0.010077
   Number of active neurons: 10
 >> iter 61000, loss: 0.007020
 >> iter 62000, loss: 0.005023
 >> iter 63000, loss: 0.004139
 >> iter 64000, loss: 0.003305
 >> iter 65000, loss: 0.005020
 >> iter 66000, loss: 0.155329
 >> iter 67000, loss: 0.060872
 >> iter 68000, loss: 0.050515
 >> iter 69000, loss: 0.021096
 >> iter 70000, loss: 0.010997
   Number of active neurons: 10
 >> iter 71000, loss: 0.005822
 >> iter 72000, loss: 0.003714
 >> iter 73000, loss: 0.003369
 >> iter 74000, loss: 0.003123
 >> iter 75000, loss: 0.015040
 >> iter 76000, loss: 0.007412
 >> iter 77000, loss: 0.027430
 >> iter 78000, loss: 0.012092
 >> iter 79000, loss: 0.006191
 >> iter 80000, loss: 0.004075
   Number of active neurons: 10
 >> iter 81000, loss: 0.002884
 >> iter 82000, loss: 0.007203
 >> iter 83000, loss: 0.201153
 >> iter 84000, loss: 0.162794
 >> iter 85000, loss: 0.062640
 >> iter 86000, loss: 0.026017
 >> iter 87000, loss: 0.011434
 >> iter 88000, loss: 0.015142
 >> iter 89000, loss: 0.007560
 >> iter 90000, loss: 0.005198
   Number of active neurons: 10
 >> iter 91000, loss: 0.105700
 >> iter 92000, loss: 0.061620
 >> iter 93000, loss: 0.025554
 >> iter 94000, loss: 0.011622
 >> iter 95000, loss: 0.006468
 >> iter 96000, loss: 0.004872
 >> iter 97000, loss: 0.006210
 >> iter 98000, loss: 0.003804
 >> iter 99000, loss: 0.019990
 >> iter 100000, loss: 0.033797
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 19.257072
 >> iter 2000, loss: 13.775119
 >> iter 3000, loss: 8.831873
 >> iter 4000, loss: 4.447409
 >> iter 5000, loss: 2.360296
 >> iter 6000, loss: 1.341959
 >> iter 7000, loss: 0.794143
 >> iter 8000, loss: 0.421550
 >> iter 9000, loss: 0.396595
 >> iter 10000, loss: 0.408343
   Number of active neurons: 10
 >> iter 11000, loss: 0.257182
 >> iter 12000, loss: 0.252448
 >> iter 13000, loss: 0.269523
 >> iter 14000, loss: 0.278404
 >> iter 15000, loss: 0.143808
 >> iter 16000, loss: 0.088319
 >> iter 17000, loss: 0.050902
 >> iter 18000, loss: 0.078750
 >> iter 19000, loss: 0.297563
 >> iter 20000, loss: 0.219852
   Number of active neurons: 10
 >> iter 21000, loss: 0.154754
 >> iter 22000, loss: 0.120394
 >> iter 23000, loss: 0.200458
 >> iter 24000, loss: 0.155193
 >> iter 25000, loss: 0.073605
 >> iter 26000, loss: 0.080852
 >> iter 27000, loss: 0.045350
 >> iter 28000, loss: 0.023986
 >> iter 29000, loss: 0.072514
 >> iter 30000, loss: 0.035194
   Number of active neurons: 10
 >> iter 31000, loss: 0.191224
 >> iter 32000, loss: 0.081200
 >> iter 33000, loss: 0.108086
 >> iter 34000, loss: 0.191556
 >> iter 35000, loss: 0.116345
 >> iter 36000, loss: 0.068080
 >> iter 37000, loss: 0.031147
 >> iter 38000, loss: 0.069910
 >> iter 39000, loss: 0.031776
 >> iter 40000, loss: 0.017907
   Number of active neurons: 10
 >> iter 41000, loss: 0.031717
 >> iter 42000, loss: 0.018443
 >> iter 43000, loss: 0.010074
 >> iter 44000, loss: 0.111179
 >> iter 45000, loss: 0.050956
 >> iter 46000, loss: 0.030769
 >> iter 47000, loss: 0.014798
 >> iter 48000, loss: 0.008114
 >> iter 49000, loss: 0.010975
 >> iter 50000, loss: 0.006384
   Number of active neurons: 10
 >> iter 51000, loss: 0.004983
 >> iter 52000, loss: 0.004704
 >> iter 53000, loss: 0.102143
 >> iter 54000, loss: 0.041141
 >> iter 55000, loss: 0.019979
 >> iter 56000, loss: 0.041859
 >> iter 57000, loss: 0.041698
 >> iter 58000, loss: 0.018543
 >> iter 59000, loss: 0.031198
 >> iter 60000, loss: 0.016405
   Number of active neurons: 10
 >> iter 61000, loss: 0.008047
 >> iter 62000, loss: 0.032485
 >> iter 63000, loss: 0.021824
 >> iter 64000, loss: 0.010202
 >> iter 65000, loss: 0.005972
 >> iter 66000, loss: 0.014583
 >> iter 67000, loss: 0.007509
 >> iter 68000, loss: 0.004581
 >> iter 69000, loss: 0.007225
 >> iter 70000, loss: 0.015336
   Number of active neurons: 10
 >> iter 71000, loss: 0.008150
 >> iter 72000, loss: 0.007869
 >> iter 73000, loss: 0.005584
 >> iter 74000, loss: 0.003369
 >> iter 75000, loss: 0.002349
 >> iter 76000, loss: 0.007246
 >> iter 77000, loss: 0.003671
 >> iter 78000, loss: 0.002306
 >> iter 79000, loss: 0.050182
 >> iter 80000, loss: 0.118035
   Number of active neurons: 10
 >> iter 81000, loss: 0.045848
 >> iter 82000, loss: 0.024247
 >> iter 83000, loss: 0.010341
 >> iter 84000, loss: 0.006177
 >> iter 85000, loss: 0.091155
 >> iter 86000, loss: 0.035046
 >> iter 87000, loss: 0.014919
 >> iter 88000, loss: 0.008871
 >> iter 89000, loss: 0.004840
 >> iter 90000, loss: 0.004874
   Number of active neurons: 10
 >> iter 91000, loss: 0.004523
 >> iter 92000, loss: 0.002921
 >> iter 93000, loss: 0.008453
 >> iter 94000, loss: 0.004595
 >> iter 95000, loss: 0.010262
 >> iter 96000, loss: 0.007709
 >> iter 97000, loss: 0.003917
 >> iter 98000, loss: 0.002613
 >> iter 99000, loss: 0.003185
 >> iter 100000, loss: 0.012188
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.243298
 >> iter 2000, loss: 13.108791
 >> iter 3000, loss: 7.391034
 >> iter 4000, loss: 3.540191
 >> iter 5000, loss: 1.901237
 >> iter 6000, loss: 1.202240
 >> iter 7000, loss: 0.699530
 >> iter 8000, loss: 0.467773
 >> iter 9000, loss: 0.313218
 >> iter 10000, loss: 0.257193
   Number of active neurons: 10
 >> iter 11000, loss: 0.136687
 >> iter 12000, loss: 0.107893
 >> iter 13000, loss: 0.231169
 >> iter 14000, loss: 0.341243
 >> iter 15000, loss: 0.266105
 >> iter 16000, loss: 0.120384
 >> iter 17000, loss: 0.134874
 >> iter 18000, loss: 0.259912
 >> iter 19000, loss: 0.133002
 >> iter 20000, loss: 0.096969
   Number of active neurons: 10
 >> iter 21000, loss: 0.079785
 >> iter 22000, loss: 0.167030
 >> iter 23000, loss: 0.080524
 >> iter 24000, loss: 0.097696
 >> iter 25000, loss: 0.062897
 >> iter 26000, loss: 0.162095
 >> iter 27000, loss: 0.098860
 >> iter 28000, loss: 0.083777
 >> iter 29000, loss: 0.100916
 >> iter 30000, loss: 0.086994
   Number of active neurons: 10
 >> iter 31000, loss: 0.050949
 >> iter 32000, loss: 0.041097
 >> iter 33000, loss: 0.031509
 >> iter 34000, loss: 0.018911
 >> iter 35000, loss: 0.056520
 >> iter 36000, loss: 0.083309
 >> iter 37000, loss: 0.044856
 >> iter 38000, loss: 0.022461
 >> iter 39000, loss: 0.058791
 >> iter 40000, loss: 0.077978
   Number of active neurons: 10
 >> iter 41000, loss: 0.042889
 >> iter 42000, loss: 0.090242
 >> iter 43000, loss: 0.037315
 >> iter 44000, loss: 0.017497
 >> iter 45000, loss: 0.048881
 >> iter 46000, loss: 0.024652
 >> iter 47000, loss: 0.052396
 >> iter 48000, loss: 0.024078
 >> iter 49000, loss: 0.061887
 >> iter 50000, loss: 0.065442
   Number of active neurons: 10
 >> iter 51000, loss: 0.027496
 >> iter 52000, loss: 0.028738
 >> iter 53000, loss: 0.074485
 >> iter 54000, loss: 0.032755
 >> iter 55000, loss: 0.014907
 >> iter 56000, loss: 0.009038
 >> iter 57000, loss: 0.009932
 >> iter 58000, loss: 0.016083
 >> iter 59000, loss: 0.007972
 >> iter 60000, loss: 0.008427
   Number of active neurons: 10
 >> iter 61000, loss: 0.140280
 >> iter 62000, loss: 0.110632
 >> iter 63000, loss: 0.044162
 >> iter 64000, loss: 0.019426
 >> iter 65000, loss: 0.009464
 >> iter 66000, loss: 0.132558
 >> iter 67000, loss: 0.096645
 >> iter 68000, loss: 0.063209
 >> iter 69000, loss: 0.053686
 >> iter 70000, loss: 0.022840
   Number of active neurons: 10
 >> iter 71000, loss: 0.010682
 >> iter 72000, loss: 0.006552
 >> iter 73000, loss: 0.008121
 >> iter 74000, loss: 0.016992
 >> iter 75000, loss: 0.008845
 >> iter 76000, loss: 0.005034
 >> iter 77000, loss: 0.035776
 >> iter 78000, loss: 0.035729
 >> iter 79000, loss: 0.063036
 >> iter 80000, loss: 0.025499
   Number of active neurons: 10
 >> iter 81000, loss: 0.011882
 >> iter 82000, loss: 0.006417
 >> iter 83000, loss: 0.011768
 >> iter 84000, loss: 0.005806
 >> iter 85000, loss: 0.006734
 >> iter 86000, loss: 0.004039
 >> iter 87000, loss: 0.002771
 >> iter 88000, loss: 0.002134
 >> iter 89000, loss: 0.002159
 >> iter 90000, loss: 0.001983
   Number of active neurons: 10
 >> iter 91000, loss: 0.001779
 >> iter 92000, loss: 0.073735
 >> iter 93000, loss: 0.028598
 >> iter 94000, loss: 0.013121
 >> iter 95000, loss: 0.007409
 >> iter 96000, loss: 0.004059
 >> iter 97000, loss: 0.004494
 >> iter 98000, loss: 0.003343
 >> iter 99000, loss: 0.003116
 >> iter 100000, loss: 0.120180
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.322250
 >> iter 2000, loss: 13.613207
 >> iter 3000, loss: 8.274064
 >> iter 4000, loss: 4.917424
 >> iter 5000, loss: 2.843905
 >> iter 6000, loss: 2.081943
 >> iter 7000, loss: 1.095047
 >> iter 8000, loss: 0.575987
 >> iter 9000, loss: 0.486564
 >> iter 10000, loss: 0.444832
   Number of active neurons: 10
 >> iter 11000, loss: 0.424617
 >> iter 12000, loss: 0.477874
 >> iter 13000, loss: 0.364423
 >> iter 14000, loss: 0.262686
 >> iter 15000, loss: 0.244660
 >> iter 16000, loss: 0.374762
 >> iter 17000, loss: 0.258440
 >> iter 18000, loss: 0.177952
 >> iter 19000, loss: 0.146692
 >> iter 20000, loss: 0.184620
   Number of active neurons: 10
 >> iter 21000, loss: 0.119481
 >> iter 22000, loss: 0.118266
 >> iter 23000, loss: 0.102272
 >> iter 24000, loss: 0.182172
 >> iter 25000, loss: 0.083404
 >> iter 26000, loss: 0.094167
 >> iter 27000, loss: 0.203565
 >> iter 28000, loss: 0.090649
 >> iter 29000, loss: 0.236561
 >> iter 30000, loss: 0.165869
   Number of active neurons: 10
 >> iter 31000, loss: 0.163812
 >> iter 32000, loss: 0.134192
 >> iter 33000, loss: 0.061090
 >> iter 34000, loss: 0.168334
 >> iter 35000, loss: 0.160414
 >> iter 36000, loss: 0.280040
 >> iter 37000, loss: 0.172429
 >> iter 38000, loss: 0.136920
 >> iter 39000, loss: 0.073325
 >> iter 40000, loss: 0.119076
   Number of active neurons: 10
 >> iter 41000, loss: 0.066076
 >> iter 42000, loss: 0.034416
 >> iter 43000, loss: 0.019204
 >> iter 44000, loss: 0.015913
 >> iter 45000, loss: 0.025681
 >> iter 46000, loss: 0.115968
 >> iter 47000, loss: 0.092641
 >> iter 48000, loss: 0.103747
 >> iter 49000, loss: 0.052788
 >> iter 50000, loss: 0.023882
   Number of active neurons: 10
 >> iter 51000, loss: 0.013395
 >> iter 52000, loss: 0.125809
 >> iter 53000, loss: 0.058707
 >> iter 54000, loss: 0.026052
 >> iter 55000, loss: 0.019203
 >> iter 56000, loss: 0.165138
 >> iter 57000, loss: 0.080359
 >> iter 58000, loss: 0.051168
 >> iter 59000, loss: 0.069068
 >> iter 60000, loss: 0.070472
   Number of active neurons: 10
 >> iter 61000, loss: 0.034929
 >> iter 62000, loss: 0.044612
 >> iter 63000, loss: 0.045354
 >> iter 64000, loss: 0.035866
 >> iter 65000, loss: 0.076205
 >> iter 66000, loss: 0.032403
 >> iter 67000, loss: 0.015720
 >> iter 68000, loss: 0.062421
 >> iter 69000, loss: 0.118780
 >> iter 70000, loss: 0.095426
   Number of active neurons: 10
 >> iter 71000, loss: 0.044297
 >> iter 72000, loss: 0.028694
 >> iter 73000, loss: 0.022653
 >> iter 74000, loss: 0.026703
 >> iter 75000, loss: 0.074094
 >> iter 76000, loss: 0.059927
 >> iter 77000, loss: 0.025585
 >> iter 78000, loss: 0.013270
 >> iter 79000, loss: 0.017928
 >> iter 80000, loss: 0.043550
   Number of active neurons: 10
 >> iter 81000, loss: 0.019987
 >> iter 82000, loss: 0.009796
 >> iter 83000, loss: 0.015471
 >> iter 84000, loss: 0.012970
 >> iter 85000, loss: 0.006763
 >> iter 86000, loss: 0.004265
 >> iter 87000, loss: 0.003169
 >> iter 88000, loss: 0.002694
 >> iter 89000, loss: 0.002918
 >> iter 90000, loss: 0.038292
   Number of active neurons: 10
 >> iter 91000, loss: 0.043816
 >> iter 92000, loss: 0.017528
 >> iter 93000, loss: 0.129323
 >> iter 94000, loss: 0.056182
 >> iter 95000, loss: 0.049877
 >> iter 96000, loss: 0.020103
 >> iter 97000, loss: 0.009131
 >> iter 98000, loss: 0.052360
 >> iter 99000, loss: 0.037068
 >> iter 100000, loss: 0.016921
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.273334
 >> iter 2000, loss: 14.131593
 >> iter 3000, loss: 7.892995
 >> iter 4000, loss: 3.911720
 >> iter 5000, loss: 1.822482
 >> iter 6000, loss: 0.988630
 >> iter 7000, loss: 0.599943
 >> iter 8000, loss: 0.511367
 >> iter 9000, loss: 0.473443
 >> iter 10000, loss: 0.270810
   Number of active neurons: 10
 >> iter 11000, loss: 0.253044
 >> iter 12000, loss: 0.153572
 >> iter 13000, loss: 0.129677
 >> iter 14000, loss: 0.096140
 >> iter 15000, loss: 0.073740
 >> iter 16000, loss: 0.073098
 >> iter 17000, loss: 0.210249
 >> iter 18000, loss: 0.237292
 >> iter 19000, loss: 0.147953
 >> iter 20000, loss: 0.135945
   Number of active neurons: 10
 >> iter 21000, loss: 0.074616
 >> iter 22000, loss: 0.115771
 >> iter 23000, loss: 0.147566
 >> iter 24000, loss: 0.182830
 >> iter 25000, loss: 0.168788
 >> iter 26000, loss: 0.134308
 >> iter 27000, loss: 0.111051
 >> iter 28000, loss: 0.062300
 >> iter 29000, loss: 0.191395
 >> iter 30000, loss: 0.134578
   Number of active neurons: 10
 >> iter 31000, loss: 0.116404
 >> iter 32000, loss: 0.060058
 >> iter 33000, loss: 0.092296
 >> iter 34000, loss: 0.060953
 >> iter 35000, loss: 0.059318
 >> iter 36000, loss: 0.035240
 >> iter 37000, loss: 0.024039
 >> iter 38000, loss: 0.017194
 >> iter 39000, loss: 0.106870
 >> iter 40000, loss: 0.098932
   Number of active neurons: 10
 >> iter 41000, loss: 0.069905
 >> iter 42000, loss: 0.042663
 >> iter 43000, loss: 0.022061
 >> iter 44000, loss: 0.083049
 >> iter 45000, loss: 0.060611
 >> iter 46000, loss: 0.058856
 >> iter 47000, loss: 0.045204
 >> iter 48000, loss: 0.022119
 >> iter 49000, loss: 0.196911
 >> iter 50000, loss: 0.077902
   Number of active neurons: 10
 >> iter 51000, loss: 0.032632
 >> iter 52000, loss: 0.019813
 >> iter 53000, loss: 0.046549
 >> iter 54000, loss: 0.057046
 >> iter 55000, loss: 0.123094
 >> iter 56000, loss: 0.051859
 >> iter 57000, loss: 0.022313
 >> iter 58000, loss: 0.012096
 >> iter 59000, loss: 0.007308
 >> iter 60000, loss: 0.035231
   Number of active neurons: 10
 >> iter 61000, loss: 0.016142
 >> iter 62000, loss: 0.045120
 >> iter 63000, loss: 0.024520
 >> iter 64000, loss: 0.031372
 >> iter 65000, loss: 0.021813
 >> iter 66000, loss: 0.055815
 >> iter 67000, loss: 0.085894
 >> iter 68000, loss: 0.079930
 >> iter 69000, loss: 0.040767
 >> iter 70000, loss: 0.038580
   Number of active neurons: 10
 >> iter 71000, loss: 0.094984
 >> iter 72000, loss: 0.048634
 >> iter 73000, loss: 0.026619
 >> iter 74000, loss: 0.018619
 >> iter 75000, loss: 0.010192
 >> iter 76000, loss: 0.079237
 >> iter 77000, loss: 0.039905
 >> iter 78000, loss: 0.041320
 >> iter 79000, loss: 0.018083
 >> iter 80000, loss: 0.009378
   Number of active neurons: 10
 >> iter 81000, loss: 0.010171
 >> iter 82000, loss: 0.005632
 >> iter 83000, loss: 0.020582
 >> iter 84000, loss: 0.010308
 >> iter 85000, loss: 0.015377
 >> iter 86000, loss: 0.058998
 >> iter 87000, loss: 0.023610
 >> iter 88000, loss: 0.010601
 >> iter 89000, loss: 0.006900
 >> iter 90000, loss: 0.004064
   Number of active neurons: 10
 >> iter 91000, loss: 0.028205
 >> iter 92000, loss: 0.021471
 >> iter 93000, loss: 0.009677
 >> iter 94000, loss: 0.005690
 >> iter 95000, loss: 0.007195
 >> iter 96000, loss: 0.014927
 >> iter 97000, loss: 0.035244
 >> iter 98000, loss: 0.084698
 >> iter 99000, loss: 0.036379
 >> iter 100000, loss: 0.036495
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

