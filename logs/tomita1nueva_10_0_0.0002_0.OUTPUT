 > Problema: tomita1nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 0.0002
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.824189
 >> iter 2000, loss: 4.017877
 >> iter 3000, loss: 1.508852
 >> iter 4000, loss: 0.583751
 >> iter 5000, loss: 0.242759
 >> iter 6000, loss: 0.115334
 >> iter 7000, loss: 0.067543
 >> iter 8000, loss: 0.047923
 >> iter 9000, loss: 0.039614
 >> iter 10000, loss: 0.035184
   Number of active neurons: 1
 >> iter 11000, loss: 0.033398
 >> iter 12000, loss: 0.031942
 >> iter 13000, loss: 0.031575
 >> iter 14000, loss: 0.030776
 >> iter 15000, loss: 0.030760
 >> iter 16000, loss: 0.030161
 >> iter 17000, loss: 0.030261
 >> iter 18000, loss: 0.029755
 >> iter 19000, loss: 0.029901
 >> iter 20000, loss: 0.029470
   Number of active neurons: 1
 >> iter 21000, loss: 0.029647
 >> iter 22000, loss: 0.029237
 >> iter 23000, loss: 0.029456
 >> iter 24000, loss: 0.029059
 >> iter 25000, loss: 0.029315
 >> iter 26000, loss: 0.028950
 >> iter 27000, loss: 0.029210
 >> iter 28000, loss: 0.028864
 >> iter 29000, loss: 0.029120
 >> iter 30000, loss: 0.028783
   Number of active neurons: 1
 >> iter 31000, loss: 0.029055
 >> iter 32000, loss: 0.028723
 >> iter 33000, loss: 0.029001
 >> iter 34000, loss: 0.028680
 >> iter 35000, loss: 0.028983
 >> iter 36000, loss: 0.028646
 >> iter 37000, loss: 0.028954
 >> iter 38000, loss: 0.028614
 >> iter 39000, loss: 0.028940
 >> iter 40000, loss: 0.028594
   Number of active neurons: 1
 >> iter 41000, loss: 0.028918
 >> iter 42000, loss: 0.028589
 >> iter 43000, loss: 0.028894
 >> iter 44000, loss: 0.028587
 >> iter 45000, loss: 0.028892
 >> iter 46000, loss: 0.028578
 >> iter 47000, loss: 0.028880
 >> iter 48000, loss: 0.028583
 >> iter 49000, loss: 0.028889
 >> iter 50000, loss: 0.028575
   Number of active neurons: 1
 >> iter 51000, loss: 0.028887
 >> iter 52000, loss: 0.028588
 >> iter 53000, loss: 0.028878
 >> iter 54000, loss: 0.028622
 >> iter 55000, loss: 0.028868
 >> iter 56000, loss: 0.028623
 >> iter 57000, loss: 0.028889
 >> iter 58000, loss: 0.028608
 >> iter 59000, loss: 0.028894
 >> iter 60000, loss: 0.028619
   Number of active neurons: 1
 >> iter 61000, loss: 0.028884
 >> iter 62000, loss: 0.028622
 >> iter 63000, loss: 0.028891
 >> iter 64000, loss: 0.028604
 >> iter 65000, loss: 0.028890
 >> iter 66000, loss: 0.028610
 >> iter 67000, loss: 0.028878
 >> iter 68000, loss: 0.028633
 >> iter 69000, loss: 0.028880
 >> iter 70000, loss: 0.028616
   Number of active neurons: 1
 >> iter 71000, loss: 0.028879
 >> iter 72000, loss: 0.028630
 >> iter 73000, loss: 0.028881
 >> iter 74000, loss: 0.028621
 >> iter 75000, loss: 0.028882
 >> iter 76000, loss: 0.028620
 >> iter 77000, loss: 0.028873
 >> iter 78000, loss: 0.028603
 >> iter 79000, loss: 0.028903
 >> iter 80000, loss: 0.028608
   Number of active neurons: 1
 >> iter 81000, loss: 0.028935
 >> iter 82000, loss: 0.028611
 >> iter 83000, loss: 0.028955
 >> iter 84000, loss: 0.028607
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028599
 >> iter 87000, loss: 0.028947
 >> iter 88000, loss: 0.028595
 >> iter 89000, loss: 0.028937
 >> iter 90000, loss: 0.028608
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028606
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.775552
 >> iter 2000, loss: 3.997778
 >> iter 3000, loss: 1.502892
 >> iter 4000, loss: 0.583084
 >> iter 5000, loss: 0.244759
 >> iter 6000, loss: 0.119349
 >> iter 7000, loss: 0.074058
 >> iter 8000, loss: 0.056911
 >> iter 9000, loss: 0.051568
 >> iter 10000, loss: 0.049033
   Number of active neurons: 4
 >> iter 11000, loss: 0.048936
 >> iter 12000, loss: 0.048163
 >> iter 13000, loss: 0.048476
 >> iter 14000, loss: 0.047218
 >> iter 15000, loss: 0.046259
 >> iter 16000, loss: 0.043866
 >> iter 17000, loss: 0.042306
 >> iter 18000, loss: 0.040367
 >> iter 19000, loss: 0.039844
 >> iter 20000, loss: 0.038931
   Number of active neurons: 1
 >> iter 21000, loss: 0.038853
 >> iter 22000, loss: 0.037924
 >> iter 23000, loss: 0.036949
 >> iter 24000, loss: 0.034850
 >> iter 25000, loss: 0.033604
 >> iter 26000, loss: 0.032159
 >> iter 27000, loss: 0.031705
 >> iter 28000, loss: 0.030864
 >> iter 29000, loss: 0.030771
 >> iter 30000, loss: 0.030165
   Number of active neurons: 1
 >> iter 31000, loss: 0.030229
 >> iter 32000, loss: 0.029722
 >> iter 33000, loss: 0.029858
 >> iter 34000, loss: 0.029414
 >> iter 35000, loss: 0.029614
 >> iter 36000, loss: 0.029186
 >> iter 37000, loss: 0.029420
 >> iter 38000, loss: 0.029012
 >> iter 39000, loss: 0.029284
 >> iter 40000, loss: 0.028889
   Number of active neurons: 1
 >> iter 41000, loss: 0.029172
 >> iter 42000, loss: 0.028806
 >> iter 43000, loss: 0.029082
 >> iter 44000, loss: 0.028748
 >> iter 45000, loss: 0.029030
 >> iter 46000, loss: 0.028697
 >> iter 47000, loss: 0.028983
 >> iter 48000, loss: 0.028670
 >> iter 49000, loss: 0.028965
 >> iter 50000, loss: 0.028640
   Number of active neurons: 1
 >> iter 51000, loss: 0.028943
 >> iter 52000, loss: 0.028636
 >> iter 53000, loss: 0.028920
 >> iter 54000, loss: 0.028658
 >> iter 55000, loss: 0.028899
 >> iter 56000, loss: 0.028650
 >> iter 57000, loss: 0.028912
 >> iter 58000, loss: 0.028627
 >> iter 59000, loss: 0.028911
 >> iter 60000, loss: 0.028633
   Number of active neurons: 1
 >> iter 61000, loss: 0.028897
 >> iter 62000, loss: 0.028633
 >> iter 63000, loss: 0.028900
 >> iter 64000, loss: 0.028612
 >> iter 65000, loss: 0.028897
 >> iter 66000, loss: 0.028616
 >> iter 67000, loss: 0.028883
 >> iter 68000, loss: 0.028638
 >> iter 69000, loss: 0.028884
 >> iter 70000, loss: 0.028619
   Number of active neurons: 1
 >> iter 71000, loss: 0.028882
 >> iter 72000, loss: 0.028632
 >> iter 73000, loss: 0.028883
 >> iter 74000, loss: 0.028623
 >> iter 75000, loss: 0.028883
 >> iter 76000, loss: 0.028622
 >> iter 77000, loss: 0.028875
 >> iter 78000, loss: 0.028604
 >> iter 79000, loss: 0.028904
 >> iter 80000, loss: 0.028609
   Number of active neurons: 1
 >> iter 81000, loss: 0.028935
 >> iter 82000, loss: 0.028612
 >> iter 83000, loss: 0.028956
 >> iter 84000, loss: 0.028608
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028599
 >> iter 87000, loss: 0.028948
 >> iter 88000, loss: 0.028596
 >> iter 89000, loss: 0.028937
 >> iter 90000, loss: 0.028608
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028606
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.784877
 >> iter 2000, loss: 4.004265
 >> iter 3000, loss: 1.504187
 >> iter 4000, loss: 0.581965
 >> iter 5000, loss: 0.241407
 >> iter 6000, loss: 0.114019
 >> iter 7000, loss: 0.065809
 >> iter 8000, loss: 0.046028
 >> iter 9000, loss: 0.038108
 >> iter 10000, loss: 0.034183
   Number of active neurons: 1
 >> iter 11000, loss: 0.032748
 >> iter 12000, loss: 0.031512
 >> iter 13000, loss: 0.031274
 >> iter 14000, loss: 0.030551
 >> iter 15000, loss: 0.030582
 >> iter 16000, loss: 0.030016
 >> iter 17000, loss: 0.030140
 >> iter 18000, loss: 0.029652
 >> iter 19000, loss: 0.029812
 >> iter 20000, loss: 0.029394
   Number of active neurons: 1
 >> iter 21000, loss: 0.029581
 >> iter 22000, loss: 0.029181
 >> iter 23000, loss: 0.029407
 >> iter 24000, loss: 0.029018
 >> iter 25000, loss: 0.029280
 >> iter 26000, loss: 0.028919
 >> iter 27000, loss: 0.029183
 >> iter 28000, loss: 0.028841
 >> iter 29000, loss: 0.029100
 >> iter 30000, loss: 0.028766
   Number of active neurons: 1
 >> iter 31000, loss: 0.029040
 >> iter 32000, loss: 0.028710
 >> iter 33000, loss: 0.028990
 >> iter 34000, loss: 0.028671
 >> iter 35000, loss: 0.028975
 >> iter 36000, loss: 0.028639
 >> iter 37000, loss: 0.028948
 >> iter 38000, loss: 0.028609
 >> iter 39000, loss: 0.028935
 >> iter 40000, loss: 0.028590
   Number of active neurons: 1
 >> iter 41000, loss: 0.028915
 >> iter 42000, loss: 0.028586
 >> iter 43000, loss: 0.028892
 >> iter 44000, loss: 0.028585
 >> iter 45000, loss: 0.028890
 >> iter 46000, loss: 0.028576
 >> iter 47000, loss: 0.028879
 >> iter 48000, loss: 0.028582
 >> iter 49000, loss: 0.028888
 >> iter 50000, loss: 0.028575
   Number of active neurons: 1
 >> iter 51000, loss: 0.028887
 >> iter 52000, loss: 0.028587
 >> iter 53000, loss: 0.028877
 >> iter 54000, loss: 0.028622
 >> iter 55000, loss: 0.028868
 >> iter 56000, loss: 0.028623
 >> iter 57000, loss: 0.028889
 >> iter 58000, loss: 0.028608
 >> iter 59000, loss: 0.028894
 >> iter 60000, loss: 0.028619
   Number of active neurons: 1
 >> iter 61000, loss: 0.028884
 >> iter 62000, loss: 0.028622
 >> iter 63000, loss: 0.028891
 >> iter 64000, loss: 0.028604
 >> iter 65000, loss: 0.028890
 >> iter 66000, loss: 0.028610
 >> iter 67000, loss: 0.028878
 >> iter 68000, loss: 0.028633
 >> iter 69000, loss: 0.028880
 >> iter 70000, loss: 0.028616
   Number of active neurons: 1
 >> iter 71000, loss: 0.028879
 >> iter 72000, loss: 0.028630
 >> iter 73000, loss: 0.028881
 >> iter 74000, loss: 0.028621
 >> iter 75000, loss: 0.028882
 >> iter 76000, loss: 0.028620
 >> iter 77000, loss: 0.028873
 >> iter 78000, loss: 0.028603
 >> iter 79000, loss: 0.028903
 >> iter 80000, loss: 0.028608
   Number of active neurons: 1
 >> iter 81000, loss: 0.028935
 >> iter 82000, loss: 0.028611
 >> iter 83000, loss: 0.028955
 >> iter 84000, loss: 0.028607
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028599
 >> iter 87000, loss: 0.028947
 >> iter 88000, loss: 0.028595
 >> iter 89000, loss: 0.028937
 >> iter 90000, loss: 0.028608
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028606
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.813983
 >> iter 2000, loss: 4.012440
 >> iter 3000, loss: 1.507917
 >> iter 4000, loss: 0.584371
 >> iter 5000, loss: 0.243829
 >> iter 6000, loss: 0.117030
 >> iter 7000, loss: 0.070397
 >> iter 8000, loss: 0.051902
 >> iter 9000, loss: 0.044572
 >> iter 10000, loss: 0.040655
   Number of active neurons: 2
 >> iter 11000, loss: 0.039490
 >> iter 12000, loss: 0.038403
 >> iter 13000, loss: 0.038550
 >> iter 14000, loss: 0.038012
 >> iter 15000, loss: 0.038400
 >> iter 16000, loss: 0.037961
 >> iter 17000, loss: 0.038303
 >> iter 18000, loss: 0.037743
 >> iter 19000, loss: 0.037625
 >> iter 20000, loss: 0.035974
   Number of active neurons: 1
 >> iter 21000, loss: 0.034646
 >> iter 22000, loss: 0.032869
 >> iter 23000, loss: 0.032154
 >> iter 24000, loss: 0.031130
 >> iter 25000, loss: 0.030970
 >> iter 26000, loss: 0.030305
 >> iter 27000, loss: 0.030346
 >> iter 28000, loss: 0.029822
 >> iter 29000, loss: 0.029939
 >> iter 30000, loss: 0.029481
   Number of active neurons: 1
 >> iter 31000, loss: 0.029655
 >> iter 32000, loss: 0.029236
 >> iter 33000, loss: 0.029443
 >> iter 34000, loss: 0.029059
 >> iter 35000, loss: 0.029309
 >> iter 36000, loss: 0.028925
 >> iter 37000, loss: 0.029195
 >> iter 38000, loss: 0.028820
 >> iter 39000, loss: 0.029118
 >> iter 40000, loss: 0.028747
   Number of active neurons: 1
 >> iter 41000, loss: 0.029049
 >> iter 42000, loss: 0.028701
 >> iter 43000, loss: 0.028991
 >> iter 44000, loss: 0.028671
 >> iter 45000, loss: 0.028964
 >> iter 46000, loss: 0.028639
 >> iter 47000, loss: 0.028934
 >> iter 48000, loss: 0.028628
 >> iter 49000, loss: 0.028928
 >> iter 50000, loss: 0.028609
   Number of active neurons: 1
 >> iter 51000, loss: 0.028916
 >> iter 52000, loss: 0.028613
 >> iter 53000, loss: 0.028900
 >> iter 54000, loss: 0.028641
 >> iter 55000, loss: 0.028884
 >> iter 56000, loss: 0.028637
 >> iter 57000, loss: 0.028901
 >> iter 58000, loss: 0.028618
 >> iter 59000, loss: 0.028903
 >> iter 60000, loss: 0.028627
   Number of active neurons: 1
 >> iter 61000, loss: 0.028891
 >> iter 62000, loss: 0.028628
 >> iter 63000, loss: 0.028896
 >> iter 64000, loss: 0.028609
 >> iter 65000, loss: 0.028894
 >> iter 66000, loss: 0.028613
 >> iter 67000, loss: 0.028881
 >> iter 68000, loss: 0.028636
 >> iter 69000, loss: 0.028882
 >> iter 70000, loss: 0.028618
   Number of active neurons: 1
 >> iter 71000, loss: 0.028880
 >> iter 72000, loss: 0.028631
 >> iter 73000, loss: 0.028882
 >> iter 74000, loss: 0.028622
 >> iter 75000, loss: 0.028882
 >> iter 76000, loss: 0.028621
 >> iter 77000, loss: 0.028874
 >> iter 78000, loss: 0.028603
 >> iter 79000, loss: 0.028903
 >> iter 80000, loss: 0.028609
   Number of active neurons: 1
 >> iter 81000, loss: 0.028935
 >> iter 82000, loss: 0.028611
 >> iter 83000, loss: 0.028956
 >> iter 84000, loss: 0.028608
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028599
 >> iter 87000, loss: 0.028948
 >> iter 88000, loss: 0.028596
 >> iter 89000, loss: 0.028937
 >> iter 90000, loss: 0.028607
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028605
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.831376
 >> iter 2000, loss: 4.017667
 >> iter 3000, loss: 1.508047
 >> iter 4000, loss: 0.582242
 >> iter 5000, loss: 0.241495
 >> iter 6000, loss: 0.115159
 >> iter 7000, loss: 0.069221
 >> iter 8000, loss: 0.051423
 >> iter 9000, loss: 0.045191
 >> iter 10000, loss: 0.041654
   Number of active neurons: 2
 >> iter 11000, loss: 0.040098
 >> iter 12000, loss: 0.037985
 >> iter 13000, loss: 0.037439
 >> iter 14000, loss: 0.036350
 >> iter 15000, loss: 0.036558
 >> iter 16000, loss: 0.035943
 >> iter 17000, loss: 0.036353
 >> iter 18000, loss: 0.035847
 >> iter 19000, loss: 0.036314
 >> iter 20000, loss: 0.035919
   Number of active neurons: 2
 >> iter 21000, loss: 0.036415
 >> iter 22000, loss: 0.036071
 >> iter 23000, loss: 0.036579
 >> iter 24000, loss: 0.036214
 >> iter 25000, loss: 0.036738
 >> iter 26000, loss: 0.036400
 >> iter 27000, loss: 0.036915
 >> iter 28000, loss: 0.036603
 >> iter 29000, loss: 0.037109
 >> iter 30000, loss: 0.036818
   Number of active neurons: 2
 >> iter 31000, loss: 0.037343
 >> iter 32000, loss: 0.037064
 >> iter 33000, loss: 0.037585
 >> iter 34000, loss: 0.037311
 >> iter 35000, loss: 0.037814
 >> iter 36000, loss: 0.037452
 >> iter 37000, loss: 0.037790
 >> iter 38000, loss: 0.037131
 >> iter 39000, loss: 0.036488
 >> iter 40000, loss: 0.034592
   Number of active neurons: 1
 >> iter 41000, loss: 0.033411
 >> iter 42000, loss: 0.031956
 >> iter 43000, loss: 0.031506
 >> iter 44000, loss: 0.030675
 >> iter 45000, loss: 0.030607
 >> iter 46000, loss: 0.030011
 >> iter 47000, loss: 0.030093
 >> iter 48000, loss: 0.029614
 >> iter 49000, loss: 0.029772
 >> iter 50000, loss: 0.029329
   Number of active neurons: 1
 >> iter 51000, loss: 0.029535
 >> iter 52000, loss: 0.029143
 >> iter 53000, loss: 0.029356
 >> iter 54000, loss: 0.029031
 >> iter 55000, loss: 0.029220
 >> iter 56000, loss: 0.028925
 >> iter 57000, loss: 0.029149
 >> iter 58000, loss: 0.028830
 >> iter 59000, loss: 0.029086
 >> iter 60000, loss: 0.028784
   Number of active neurons: 1
 >> iter 61000, loss: 0.029026
 >> iter 62000, loss: 0.028744
 >> iter 63000, loss: 0.028996
 >> iter 64000, loss: 0.028694
 >> iter 65000, loss: 0.028968
 >> iter 66000, loss: 0.028677
 >> iter 67000, loss: 0.028936
 >> iter 68000, loss: 0.028683
 >> iter 69000, loss: 0.028923
 >> iter 70000, loss: 0.028652
   Number of active neurons: 1
 >> iter 71000, loss: 0.028910
 >> iter 72000, loss: 0.028657
 >> iter 73000, loss: 0.028904
 >> iter 74000, loss: 0.028641
 >> iter 75000, loss: 0.028899
 >> iter 76000, loss: 0.028635
 >> iter 77000, loss: 0.028886
 >> iter 78000, loss: 0.028614
 >> iter 79000, loss: 0.028913
 >> iter 80000, loss: 0.028616
   Number of active neurons: 1
 >> iter 81000, loss: 0.028942
 >> iter 82000, loss: 0.028617
 >> iter 83000, loss: 0.028961
 >> iter 84000, loss: 0.028612
 >> iter 85000, loss: 0.028951
 >> iter 86000, loss: 0.028602
 >> iter 87000, loss: 0.028950
 >> iter 88000, loss: 0.028598
 >> iter 89000, loss: 0.028939
 >> iter 90000, loss: 0.028609
   Number of active neurons: 1
 >> iter 91000, loss: 0.028938
 >> iter 92000, loss: 0.028618
 >> iter 93000, loss: 0.028947
 >> iter 94000, loss: 0.028606
 >> iter 95000, loss: 0.028977
 >> iter 96000, loss: 0.028599
 >> iter 97000, loss: 0.028982
 >> iter 98000, loss: 0.028591
 >> iter 99000, loss: 0.028988
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 10.735987
 >> iter 2000, loss: 3.983487
 >> iter 3000, loss: 1.497386
 >> iter 4000, loss: 0.581003
 >> iter 5000, loss: 0.243924
 >> iter 6000, loss: 0.118639
 >> iter 7000, loss: 0.072500
 >> iter 8000, loss: 0.053989
 >> iter 9000, loss: 0.047428
 >> iter 10000, loss: 0.044265
   Number of active neurons: 3
 >> iter 11000, loss: 0.043811
 >> iter 12000, loss: 0.042990
 >> iter 13000, loss: 0.043344
 >> iter 14000, loss: 0.042639
 >> iter 15000, loss: 0.042690
 >> iter 16000, loss: 0.041097
 >> iter 17000, loss: 0.040272
 >> iter 18000, loss: 0.038921
 >> iter 19000, loss: 0.038824
 >> iter 20000, loss: 0.038202
   Number of active neurons: 2
 >> iter 21000, loss: 0.038480
 >> iter 22000, loss: 0.038031
 >> iter 23000, loss: 0.038347
 >> iter 24000, loss: 0.037796
 >> iter 25000, loss: 0.037788
 >> iter 26000, loss: 0.036250
 >> iter 27000, loss: 0.034957
 >> iter 28000, loss: 0.033108
 >> iter 29000, loss: 0.032305
 >> iter 30000, loss: 0.031245
   Number of active neurons: 1
 >> iter 31000, loss: 0.031031
 >> iter 32000, loss: 0.030344
 >> iter 33000, loss: 0.030361
 >> iter 34000, loss: 0.029830
 >> iter 35000, loss: 0.029964
 >> iter 36000, loss: 0.029483
 >> iter 37000, loss: 0.029674
 >> iter 38000, loss: 0.029229
 >> iter 39000, loss: 0.029470
 >> iter 40000, loss: 0.029048
   Number of active neurons: 1
 >> iter 41000, loss: 0.029309
 >> iter 42000, loss: 0.028923
 >> iter 43000, loss: 0.029183
 >> iter 44000, loss: 0.028834
 >> iter 45000, loss: 0.029105
 >> iter 46000, loss: 0.028760
 >> iter 47000, loss: 0.029038
 >> iter 48000, loss: 0.028717
 >> iter 49000, loss: 0.029005
 >> iter 50000, loss: 0.028675
   Number of active neurons: 1
 >> iter 51000, loss: 0.028973
 >> iter 52000, loss: 0.028662
 >> iter 53000, loss: 0.028942
 >> iter 54000, loss: 0.028677
 >> iter 55000, loss: 0.028915
 >> iter 56000, loss: 0.028664
 >> iter 57000, loss: 0.028924
 >> iter 58000, loss: 0.028638
 >> iter 59000, loss: 0.028920
 >> iter 60000, loss: 0.028641
   Number of active neurons: 1
 >> iter 61000, loss: 0.028903
 >> iter 62000, loss: 0.028638
 >> iter 63000, loss: 0.028905
 >> iter 64000, loss: 0.028617
 >> iter 65000, loss: 0.028901
 >> iter 66000, loss: 0.028619
 >> iter 67000, loss: 0.028886
 >> iter 68000, loss: 0.028640
 >> iter 69000, loss: 0.028886
 >> iter 70000, loss: 0.028621
   Number of active neurons: 1
 >> iter 71000, loss: 0.028883
 >> iter 72000, loss: 0.028634
 >> iter 73000, loss: 0.028884
 >> iter 74000, loss: 0.028624
 >> iter 75000, loss: 0.028884
 >> iter 76000, loss: 0.028622
 >> iter 77000, loss: 0.028875
 >> iter 78000, loss: 0.028605
 >> iter 79000, loss: 0.028904
 >> iter 80000, loss: 0.028609
   Number of active neurons: 1
 >> iter 81000, loss: 0.028936
 >> iter 82000, loss: 0.028612
 >> iter 83000, loss: 0.028956
 >> iter 84000, loss: 0.028608
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028600
 >> iter 87000, loss: 0.028948
 >> iter 88000, loss: 0.028596
 >> iter 89000, loss: 0.028938
 >> iter 90000, loss: 0.028608
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028606
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.748417
 >> iter 2000, loss: 3.986560
 >> iter 3000, loss: 1.496638
 >> iter 4000, loss: 0.578210
 >> iter 5000, loss: 0.240086
 >> iter 6000, loss: 0.114858
 >> iter 7000, loss: 0.069361
 >> iter 8000, loss: 0.052110
 >> iter 9000, loss: 0.046488
 >> iter 10000, loss: 0.043911
   Number of active neurons: 3
 >> iter 11000, loss: 0.043697
 >> iter 12000, loss: 0.042988
 >> iter 13000, loss: 0.043386
 >> iter 14000, loss: 0.042693
 >> iter 15000, loss: 0.042636
 >> iter 16000, loss: 0.040979
 >> iter 17000, loss: 0.040197
 >> iter 18000, loss: 0.038959
 >> iter 19000, loss: 0.038920
 >> iter 20000, loss: 0.038322
   Number of active neurons: 2
 >> iter 21000, loss: 0.038557
 >> iter 22000, loss: 0.038025
 >> iter 23000, loss: 0.038111
 >> iter 24000, loss: 0.036971
 >> iter 25000, loss: 0.035797
 >> iter 26000, loss: 0.033803
 >> iter 27000, loss: 0.032811
 >> iter 28000, loss: 0.031599
 >> iter 29000, loss: 0.031279
 >> iter 30000, loss: 0.030535
   Number of active neurons: 1
 >> iter 31000, loss: 0.030514
 >> iter 32000, loss: 0.029949
 >> iter 33000, loss: 0.030046
 >> iter 34000, loss: 0.029571
 >> iter 35000, loss: 0.029747
 >> iter 36000, loss: 0.029299
 >> iter 37000, loss: 0.029517
 >> iter 38000, loss: 0.029095
 >> iter 39000, loss: 0.029355
 >> iter 40000, loss: 0.028949
   Number of active neurons: 1
 >> iter 41000, loss: 0.029224
 >> iter 42000, loss: 0.028851
 >> iter 43000, loss: 0.029120
 >> iter 44000, loss: 0.028781
 >> iter 45000, loss: 0.029058
 >> iter 46000, loss: 0.028721
 >> iter 47000, loss: 0.029004
 >> iter 48000, loss: 0.028688
 >> iter 49000, loss: 0.028980
 >> iter 50000, loss: 0.028653
   Number of active neurons: 1
 >> iter 51000, loss: 0.028955
 >> iter 52000, loss: 0.028646
 >> iter 53000, loss: 0.028928
 >> iter 54000, loss: 0.028665
 >> iter 55000, loss: 0.028905
 >> iter 56000, loss: 0.028655
 >> iter 57000, loss: 0.028917
 >> iter 58000, loss: 0.028631
 >> iter 59000, loss: 0.028914
 >> iter 60000, loss: 0.028636
   Number of active neurons: 1
 >> iter 61000, loss: 0.028899
 >> iter 62000, loss: 0.028635
 >> iter 63000, loss: 0.028902
 >> iter 64000, loss: 0.028614
 >> iter 65000, loss: 0.028899
 >> iter 66000, loss: 0.028618
 >> iter 67000, loss: 0.028884
 >> iter 68000, loss: 0.028639
 >> iter 69000, loss: 0.028885
 >> iter 70000, loss: 0.028620
   Number of active neurons: 1
 >> iter 71000, loss: 0.028882
 >> iter 72000, loss: 0.028633
 >> iter 73000, loss: 0.028883
 >> iter 74000, loss: 0.028623
 >> iter 75000, loss: 0.028883
 >> iter 76000, loss: 0.028622
 >> iter 77000, loss: 0.028875
 >> iter 78000, loss: 0.028604
 >> iter 79000, loss: 0.028904
 >> iter 80000, loss: 0.028609
   Number of active neurons: 1
 >> iter 81000, loss: 0.028936
 >> iter 82000, loss: 0.028612
 >> iter 83000, loss: 0.028956
 >> iter 84000, loss: 0.028608
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028599
 >> iter 87000, loss: 0.028948
 >> iter 88000, loss: 0.028596
 >> iter 89000, loss: 0.028938
 >> iter 90000, loss: 0.028608
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028606
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.794830
 >> iter 2000, loss: 4.003103
 >> iter 3000, loss: 1.501345
 >> iter 4000, loss: 0.579650
 >> iter 5000, loss: 0.240851
 >> iter 6000, loss: 0.115361
 >> iter 7000, loss: 0.068816
 >> iter 8000, loss: 0.050209
 >> iter 9000, loss: 0.043342
 >> iter 10000, loss: 0.040090
   Number of active neurons: 2
 >> iter 11000, loss: 0.039335
 >> iter 12000, loss: 0.038475
 >> iter 13000, loss: 0.038667
 >> iter 14000, loss: 0.038090
 >> iter 15000, loss: 0.038225
 >> iter 16000, loss: 0.037233
 >> iter 17000, loss: 0.036136
 >> iter 18000, loss: 0.034113
 >> iter 19000, loss: 0.033029
 >> iter 20000, loss: 0.031759
   Number of active neurons: 1
 >> iter 21000, loss: 0.031395
 >> iter 22000, loss: 0.030622
 >> iter 23000, loss: 0.030591
 >> iter 24000, loss: 0.030005
 >> iter 25000, loss: 0.030117
 >> iter 26000, loss: 0.029631
 >> iter 27000, loss: 0.029794
 >> iter 28000, loss: 0.029363
 >> iter 29000, loss: 0.029549
 >> iter 30000, loss: 0.029150
   Number of active neurons: 1
 >> iter 31000, loss: 0.029371
 >> iter 32000, loss: 0.028993
 >> iter 33000, loss: 0.029234
 >> iter 34000, loss: 0.028880
 >> iter 35000, loss: 0.029155
 >> iter 36000, loss: 0.028794
 >> iter 37000, loss: 0.029082
 >> iter 38000, loss: 0.028723
 >> iter 39000, loss: 0.029034
 >> iter 40000, loss: 0.028675
   Number of active neurons: 1
 >> iter 41000, loss: 0.028988
 >> iter 42000, loss: 0.028648
 >> iter 43000, loss: 0.028946
 >> iter 44000, loss: 0.028631
 >> iter 45000, loss: 0.028930
 >> iter 46000, loss: 0.028611
 >> iter 47000, loss: 0.028909
 >> iter 48000, loss: 0.028607
 >> iter 49000, loss: 0.028910
 >> iter 50000, loss: 0.028593
   Number of active neurons: 1
 >> iter 51000, loss: 0.028903
 >> iter 52000, loss: 0.028601
 >> iter 53000, loss: 0.028889
 >> iter 54000, loss: 0.028632
 >> iter 55000, loss: 0.028876
 >> iter 56000, loss: 0.028631
 >> iter 57000, loss: 0.028895
 >> iter 58000, loss: 0.028613
 >> iter 59000, loss: 0.028899
 >> iter 60000, loss: 0.028623
   Number of active neurons: 1
 >> iter 61000, loss: 0.028888
 >> iter 62000, loss: 0.028625
 >> iter 63000, loss: 0.028893
 >> iter 64000, loss: 0.028607
 >> iter 65000, loss: 0.028892
 >> iter 66000, loss: 0.028612
 >> iter 67000, loss: 0.028880
 >> iter 68000, loss: 0.028635
 >> iter 69000, loss: 0.028881
 >> iter 70000, loss: 0.028617
   Number of active neurons: 1
 >> iter 71000, loss: 0.028880
 >> iter 72000, loss: 0.028631
 >> iter 73000, loss: 0.028881
 >> iter 74000, loss: 0.028621
 >> iter 75000, loss: 0.028882
 >> iter 76000, loss: 0.028621
 >> iter 77000, loss: 0.028874
 >> iter 78000, loss: 0.028603
 >> iter 79000, loss: 0.028903
 >> iter 80000, loss: 0.028608
   Number of active neurons: 1
 >> iter 81000, loss: 0.028935
 >> iter 82000, loss: 0.028611
 >> iter 83000, loss: 0.028956
 >> iter 84000, loss: 0.028608
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028599
 >> iter 87000, loss: 0.028947
 >> iter 88000, loss: 0.028596
 >> iter 89000, loss: 0.028937
 >> iter 90000, loss: 0.028607
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028605
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.795538
 >> iter 2000, loss: 4.005876
 >> iter 3000, loss: 1.502435
 >> iter 4000, loss: 0.578200
 >> iter 5000, loss: 0.237648
 >> iter 6000, loss: 0.111570
 >> iter 7000, loss: 0.065520
 >> iter 8000, loss: 0.048047
 >> iter 9000, loss: 0.042097
 >> iter 10000, loss: 0.039392
   Number of active neurons: 2
 >> iter 11000, loss: 0.038921
 >> iter 12000, loss: 0.038206
 >> iter 13000, loss: 0.038461
 >> iter 14000, loss: 0.037901
 >> iter 15000, loss: 0.037988
 >> iter 16000, loss: 0.036731
 >> iter 17000, loss: 0.035524
 >> iter 18000, loss: 0.033559
 >> iter 19000, loss: 0.032628
 >> iter 20000, loss: 0.031481
   Number of active neurons: 1
 >> iter 21000, loss: 0.031198
 >> iter 22000, loss: 0.030475
 >> iter 23000, loss: 0.030477
 >> iter 24000, loss: 0.029912
 >> iter 25000, loss: 0.030040
 >> iter 26000, loss: 0.029566
 >> iter 27000, loss: 0.029739
 >> iter 28000, loss: 0.029315
 >> iter 29000, loss: 0.029508
 >> iter 30000, loss: 0.029115
   Number of active neurons: 1
 >> iter 31000, loss: 0.029341
 >> iter 32000, loss: 0.028968
 >> iter 33000, loss: 0.029212
 >> iter 34000, loss: 0.028861
 >> iter 35000, loss: 0.029138
 >> iter 36000, loss: 0.028780
 >> iter 37000, loss: 0.029069
 >> iter 38000, loss: 0.028712
 >> iter 39000, loss: 0.029025
 >> iter 40000, loss: 0.028667
   Number of active neurons: 1
 >> iter 41000, loss: 0.028981
 >> iter 42000, loss: 0.028643
 >> iter 43000, loss: 0.028941
 >> iter 44000, loss: 0.028627
 >> iter 45000, loss: 0.028926
 >> iter 46000, loss: 0.028607
 >> iter 47000, loss: 0.028906
 >> iter 48000, loss: 0.028605
 >> iter 49000, loss: 0.028908
 >> iter 50000, loss: 0.028591
   Number of active neurons: 1
 >> iter 51000, loss: 0.028901
 >> iter 52000, loss: 0.028600
 >> iter 53000, loss: 0.028888
 >> iter 54000, loss: 0.028631
 >> iter 55000, loss: 0.028876
 >> iter 56000, loss: 0.028630
 >> iter 57000, loss: 0.028895
 >> iter 58000, loss: 0.028613
 >> iter 59000, loss: 0.028898
 >> iter 60000, loss: 0.028623
   Number of active neurons: 1
 >> iter 61000, loss: 0.028887
 >> iter 62000, loss: 0.028625
 >> iter 63000, loss: 0.028893
 >> iter 64000, loss: 0.028606
 >> iter 65000, loss: 0.028892
 >> iter 66000, loss: 0.028612
 >> iter 67000, loss: 0.028880
 >> iter 68000, loss: 0.028635
 >> iter 69000, loss: 0.028881
 >> iter 70000, loss: 0.028617
   Number of active neurons: 1
 >> iter 71000, loss: 0.028880
 >> iter 72000, loss: 0.028631
 >> iter 73000, loss: 0.028881
 >> iter 74000, loss: 0.028621
 >> iter 75000, loss: 0.028882
 >> iter 76000, loss: 0.028621
 >> iter 77000, loss: 0.028874
 >> iter 78000, loss: 0.028603
 >> iter 79000, loss: 0.028903
 >> iter 80000, loss: 0.028609
   Number of active neurons: 1
 >> iter 81000, loss: 0.028935
 >> iter 82000, loss: 0.028611
 >> iter 83000, loss: 0.028956
 >> iter 84000, loss: 0.028608
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028599
 >> iter 87000, loss: 0.028948
 >> iter 88000, loss: 0.028596
 >> iter 89000, loss: 0.028937
 >> iter 90000, loss: 0.028607
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028605
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.746547
 >> iter 2000, loss: 3.985140
 >> iter 3000, loss: 1.494890
 >> iter 4000, loss: 0.577070
 >> iter 5000, loss: 0.239604
 >> iter 6000, loss: 0.114734
 >> iter 7000, loss: 0.069387
 >> iter 8000, loss: 0.052185
 >> iter 9000, loss: 0.046536
 >> iter 10000, loss: 0.043884
   Number of active neurons: 3
 >> iter 11000, loss: 0.043484
 >> iter 12000, loss: 0.042479
 >> iter 13000, loss: 0.042134
 >> iter 14000, loss: 0.040365
 >> iter 15000, loss: 0.039628
 >> iter 16000, loss: 0.038471
 >> iter 17000, loss: 0.038541
 >> iter 18000, loss: 0.037969
 >> iter 19000, loss: 0.038315
 >> iter 20000, loss: 0.037928
   Number of active neurons: 2
 >> iter 21000, loss: 0.038285
 >> iter 22000, loss: 0.037832
 >> iter 23000, loss: 0.037989
 >> iter 24000, loss: 0.036971
 >> iter 25000, loss: 0.035874
 >> iter 26000, loss: 0.033899
 >> iter 27000, loss: 0.032874
 >> iter 28000, loss: 0.031633
 >> iter 29000, loss: 0.031295
 >> iter 30000, loss: 0.030540
   Number of active neurons: 1
 >> iter 31000, loss: 0.030514
 >> iter 32000, loss: 0.029947
 >> iter 33000, loss: 0.030042
 >> iter 34000, loss: 0.029567
 >> iter 35000, loss: 0.029743
 >> iter 36000, loss: 0.029296
 >> iter 37000, loss: 0.029514
 >> iter 38000, loss: 0.029093
 >> iter 39000, loss: 0.029353
 >> iter 40000, loss: 0.028947
   Number of active neurons: 1
 >> iter 41000, loss: 0.029222
 >> iter 42000, loss: 0.028849
 >> iter 43000, loss: 0.029119
 >> iter 44000, loss: 0.028780
 >> iter 45000, loss: 0.029058
 >> iter 46000, loss: 0.028720
 >> iter 47000, loss: 0.029003
 >> iter 48000, loss: 0.028688
 >> iter 49000, loss: 0.028979
 >> iter 50000, loss: 0.028653
   Number of active neurons: 1
 >> iter 51000, loss: 0.028954
 >> iter 52000, loss: 0.028646
 >> iter 53000, loss: 0.028928
 >> iter 54000, loss: 0.028665
 >> iter 55000, loss: 0.028905
 >> iter 56000, loss: 0.028655
 >> iter 57000, loss: 0.028917
 >> iter 58000, loss: 0.028631
 >> iter 59000, loss: 0.028914
 >> iter 60000, loss: 0.028636
   Number of active neurons: 1
 >> iter 61000, loss: 0.028899
 >> iter 62000, loss: 0.028635
 >> iter 63000, loss: 0.028902
 >> iter 64000, loss: 0.028614
 >> iter 65000, loss: 0.028898
 >> iter 66000, loss: 0.028617
 >> iter 67000, loss: 0.028884
 >> iter 68000, loss: 0.028639
 >> iter 69000, loss: 0.028885
 >> iter 70000, loss: 0.028620
   Number of active neurons: 1
 >> iter 71000, loss: 0.028882
 >> iter 72000, loss: 0.028633
 >> iter 73000, loss: 0.028883
 >> iter 74000, loss: 0.028623
 >> iter 75000, loss: 0.028884
 >> iter 76000, loss: 0.028622
 >> iter 77000, loss: 0.028875
 >> iter 78000, loss: 0.028604
 >> iter 79000, loss: 0.028904
 >> iter 80000, loss: 0.028609
   Number of active neurons: 1
 >> iter 81000, loss: 0.028936
 >> iter 82000, loss: 0.028612
 >> iter 83000, loss: 0.028956
 >> iter 84000, loss: 0.028608
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028600
 >> iter 87000, loss: 0.028948
 >> iter 88000, loss: 0.028596
 >> iter 89000, loss: 0.028938
 >> iter 90000, loss: 0.028608
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028606
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.746465
 >> iter 2000, loss: 3.987266
 >> iter 3000, loss: 1.498476
 >> iter 4000, loss: 0.580309
 >> iter 5000, loss: 0.241783
 >> iter 6000, loss: 0.115587
 >> iter 7000, loss: 0.069511
 >> iter 8000, loss: 0.051691
 >> iter 9000, loss: 0.045764
 >> iter 10000, loss: 0.042695
   Number of active neurons: 2
 >> iter 11000, loss: 0.041962
 >> iter 12000, loss: 0.040126
 >> iter 13000, loss: 0.039279
 >> iter 14000, loss: 0.037375
 >> iter 15000, loss: 0.036975
 >> iter 16000, loss: 0.035863
 >> iter 17000, loss: 0.036064
 >> iter 18000, loss: 0.035309
 >> iter 19000, loss: 0.035688
 >> iter 20000, loss: 0.035068
   Number of active neurons: 2
 >> iter 21000, loss: 0.035498
 >> iter 22000, loss: 0.034900
 >> iter 23000, loss: 0.035382
 >> iter 24000, loss: 0.034798
 >> iter 25000, loss: 0.035322
 >> iter 26000, loss: 0.034780
 >> iter 27000, loss: 0.035297
 >> iter 28000, loss: 0.034785
 >> iter 29000, loss: 0.035294
 >> iter 30000, loss: 0.034809
   Number of active neurons: 2
 >> iter 31000, loss: 0.035337
 >> iter 32000, loss: 0.034886
 >> iter 33000, loss: 0.035430
 >> iter 34000, loss: 0.035034
 >> iter 35000, loss: 0.035626
 >> iter 36000, loss: 0.035256
 >> iter 37000, loss: 0.035780
 >> iter 38000, loss: 0.035400
 >> iter 39000, loss: 0.035954
 >> iter 40000, loss: 0.035592
   Number of active neurons: 2
 >> iter 41000, loss: 0.036171
 >> iter 42000, loss: 0.035817
 >> iter 43000, loss: 0.036340
 >> iter 44000, loss: 0.036005
 >> iter 45000, loss: 0.036521
 >> iter 46000, loss: 0.036184
 >> iter 47000, loss: 0.036701
 >> iter 48000, loss: 0.036403
 >> iter 49000, loss: 0.036935
 >> iter 50000, loss: 0.036636
   Number of active neurons: 2
 >> iter 51000, loss: 0.037186
 >> iter 52000, loss: 0.036926
 >> iter 53000, loss: 0.037445
 >> iter 54000, loss: 0.037248
 >> iter 55000, loss: 0.037683
 >> iter 56000, loss: 0.037463
 >> iter 57000, loss: 0.037818
 >> iter 58000, loss: 0.037382
 >> iter 59000, loss: 0.037293
 >> iter 60000, loss: 0.035729
   Number of active neurons: 1
 >> iter 61000, loss: 0.034436
 >> iter 62000, loss: 0.032749
 >> iter 63000, loss: 0.032022
 >> iter 64000, loss: 0.031054
 >> iter 65000, loss: 0.030871
 >> iter 66000, loss: 0.030246
 >> iter 67000, loss: 0.030253
 >> iter 68000, loss: 0.029799
 >> iter 69000, loss: 0.029874
 >> iter 70000, loss: 0.029465
   Number of active neurons: 1
 >> iter 71000, loss: 0.029607
 >> iter 72000, loss: 0.029254
 >> iter 73000, loss: 0.029417
 >> iter 74000, loss: 0.029080
 >> iter 75000, loss: 0.029277
 >> iter 76000, loss: 0.028959
 >> iter 77000, loss: 0.029165
 >> iter 78000, loss: 0.028853
 >> iter 79000, loss: 0.029118
 >> iter 80000, loss: 0.028793
   Number of active neurons: 1
 >> iter 81000, loss: 0.029094
 >> iter 82000, loss: 0.028748
 >> iter 83000, loss: 0.029073
 >> iter 84000, loss: 0.028708
 >> iter 85000, loss: 0.029034
 >> iter 86000, loss: 0.028674
 >> iter 87000, loss: 0.029012
 >> iter 88000, loss: 0.028651
 >> iter 89000, loss: 0.028985
 >> iter 90000, loss: 0.028649
   Number of active neurons: 1
 >> iter 91000, loss: 0.028972
 >> iter 92000, loss: 0.028646
 >> iter 93000, loss: 0.028972
 >> iter 94000, loss: 0.028628
 >> iter 95000, loss: 0.028995
 >> iter 96000, loss: 0.028615
 >> iter 97000, loss: 0.028996
 >> iter 98000, loss: 0.028602
 >> iter 99000, loss: 0.028998
 >> iter 100000, loss: 0.028630
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.791258
 >> iter 2000, loss: 4.001621
 >> iter 3000, loss: 1.500834
 >> iter 4000, loss: 0.578686
 >> iter 5000, loss: 0.239622
 >> iter 6000, loss: 0.114158
 >> iter 7000, loss: 0.068815
 >> iter 8000, loss: 0.051557
 >> iter 9000, loss: 0.045964
 >> iter 10000, loss: 0.043359
   Number of active neurons: 3
 >> iter 11000, loss: 0.043220
 >> iter 12000, loss: 0.042609
 >> iter 13000, loss: 0.043176
 >> iter 14000, loss: 0.042718
 >> iter 15000, loss: 0.043250
 >> iter 16000, loss: 0.042644
 >> iter 17000, loss: 0.042715
 >> iter 18000, loss: 0.041142
 >> iter 19000, loss: 0.040320
 >> iter 20000, loss: 0.039048
   Number of active neurons: 2
 >> iter 21000, loss: 0.038950
 >> iter 22000, loss: 0.038310
 >> iter 23000, loss: 0.038560
 >> iter 24000, loss: 0.038025
 >> iter 25000, loss: 0.038173
 >> iter 26000, loss: 0.037221
 >> iter 27000, loss: 0.036128
 >> iter 28000, loss: 0.034127
 >> iter 29000, loss: 0.033027
 >> iter 30000, loss: 0.031739
   Number of active neurons: 1
 >> iter 31000, loss: 0.031378
 >> iter 32000, loss: 0.030600
 >> iter 33000, loss: 0.030559
 >> iter 34000, loss: 0.029988
 >> iter 35000, loss: 0.030095
 >> iter 36000, loss: 0.029593
 >> iter 37000, loss: 0.029767
 >> iter 38000, loss: 0.029309
 >> iter 39000, loss: 0.029538
 >> iter 40000, loss: 0.029106
   Number of active neurons: 1
 >> iter 41000, loss: 0.029359
 >> iter 42000, loss: 0.028966
 >> iter 43000, loss: 0.029219
 >> iter 44000, loss: 0.028866
 >> iter 45000, loss: 0.029132
 >> iter 46000, loss: 0.028784
 >> iter 47000, loss: 0.029058
 >> iter 48000, loss: 0.028735
 >> iter 49000, loss: 0.029020
 >> iter 50000, loss: 0.028688
   Number of active neurons: 1
 >> iter 51000, loss: 0.028984
 >> iter 52000, loss: 0.028671
 >> iter 53000, loss: 0.028950
 >> iter 54000, loss: 0.028684
 >> iter 55000, loss: 0.028921
 >> iter 56000, loss: 0.028669
 >> iter 57000, loss: 0.028929
 >> iter 58000, loss: 0.028641
 >> iter 59000, loss: 0.028923
 >> iter 60000, loss: 0.028644
   Number of active neurons: 1
 >> iter 61000, loss: 0.028906
 >> iter 62000, loss: 0.028641
 >> iter 63000, loss: 0.028907
 >> iter 64000, loss: 0.028618
 >> iter 65000, loss: 0.028902
 >> iter 66000, loss: 0.028621
 >> iter 67000, loss: 0.028887
 >> iter 68000, loss: 0.028641
 >> iter 69000, loss: 0.028887
 >> iter 70000, loss: 0.028622
   Number of active neurons: 1
 >> iter 71000, loss: 0.028884
 >> iter 72000, loss: 0.028634
 >> iter 73000, loss: 0.028884
 >> iter 74000, loss: 0.028624
 >> iter 75000, loss: 0.028884
 >> iter 76000, loss: 0.028623
 >> iter 77000, loss: 0.028875
 >> iter 78000, loss: 0.028605
 >> iter 79000, loss: 0.028904
 >> iter 80000, loss: 0.028610
   Number of active neurons: 1
 >> iter 81000, loss: 0.028936
 >> iter 82000, loss: 0.028612
 >> iter 83000, loss: 0.028956
 >> iter 84000, loss: 0.028608
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028599
 >> iter 87000, loss: 0.028948
 >> iter 88000, loss: 0.028596
 >> iter 89000, loss: 0.028938
 >> iter 90000, loss: 0.028608
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028617
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028605
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.837279
 >> iter 2000, loss: 4.022031
 >> iter 3000, loss: 1.513690
 >> iter 4000, loss: 0.589525
 >> iter 5000, loss: 0.249547
 >> iter 6000, loss: 0.123074
 >> iter 7000, loss: 0.076786
 >> iter 8000, loss: 0.058834
 >> iter 9000, loss: 0.052044
 >> iter 10000, loss: 0.047089
   Number of active neurons: 2
 >> iter 11000, loss: 0.043992
 >> iter 12000, loss: 0.041280
 >> iter 13000, loss: 0.040243
 >> iter 14000, loss: 0.038728
 >> iter 15000, loss: 0.037458
 >> iter 16000, loss: 0.035157
 >> iter 17000, loss: 0.033835
 >> iter 18000, loss: 0.032341
 >> iter 19000, loss: 0.031860
 >> iter 20000, loss: 0.031015
   Number of active neurons: 1
 >> iter 21000, loss: 0.030911
 >> iter 22000, loss: 0.030291
 >> iter 23000, loss: 0.030351
 >> iter 24000, loss: 0.029821
 >> iter 25000, loss: 0.029970
 >> iter 26000, loss: 0.029510
 >> iter 27000, loss: 0.029694
 >> iter 28000, loss: 0.029278
 >> iter 29000, loss: 0.029477
 >> iter 30000, loss: 0.029089
   Number of active neurons: 1
 >> iter 31000, loss: 0.029319
 >> iter 32000, loss: 0.028949
 >> iter 33000, loss: 0.029196
 >> iter 34000, loss: 0.028847
 >> iter 35000, loss: 0.029127
 >> iter 36000, loss: 0.028769
 >> iter 37000, loss: 0.029061
 >> iter 38000, loss: 0.028705
 >> iter 39000, loss: 0.029019
 >> iter 40000, loss: 0.028662
   Number of active neurons: 1
 >> iter 41000, loss: 0.028976
 >> iter 42000, loss: 0.028639
 >> iter 43000, loss: 0.028938
 >> iter 44000, loss: 0.028624
 >> iter 45000, loss: 0.028924
 >> iter 46000, loss: 0.028605
 >> iter 47000, loss: 0.028904
 >> iter 48000, loss: 0.028603
 >> iter 49000, loss: 0.028906
 >> iter 50000, loss: 0.028590
   Number of active neurons: 1
 >> iter 51000, loss: 0.028900
 >> iter 52000, loss: 0.028599
 >> iter 53000, loss: 0.028888
 >> iter 54000, loss: 0.028630
 >> iter 55000, loss: 0.028875
 >> iter 56000, loss: 0.028629
 >> iter 57000, loss: 0.028894
 >> iter 58000, loss: 0.028612
 >> iter 59000, loss: 0.028898
 >> iter 60000, loss: 0.028622
   Number of active neurons: 1
 >> iter 61000, loss: 0.028887
 >> iter 62000, loss: 0.028625
 >> iter 63000, loss: 0.028893
 >> iter 64000, loss: 0.028606
 >> iter 65000, loss: 0.028892
 >> iter 66000, loss: 0.028612
 >> iter 67000, loss: 0.028879
 >> iter 68000, loss: 0.028635
 >> iter 69000, loss: 0.028881
 >> iter 70000, loss: 0.028617
   Number of active neurons: 1
 >> iter 71000, loss: 0.028880
 >> iter 72000, loss: 0.028630
 >> iter 73000, loss: 0.028881
 >> iter 74000, loss: 0.028621
 >> iter 75000, loss: 0.028882
 >> iter 76000, loss: 0.028621
 >> iter 77000, loss: 0.028874
 >> iter 78000, loss: 0.028603
 >> iter 79000, loss: 0.028903
 >> iter 80000, loss: 0.028608
   Number of active neurons: 1
 >> iter 81000, loss: 0.028935
 >> iter 82000, loss: 0.028611
 >> iter 83000, loss: 0.028956
 >> iter 84000, loss: 0.028608
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028599
 >> iter 87000, loss: 0.028948
 >> iter 88000, loss: 0.028596
 >> iter 89000, loss: 0.028937
 >> iter 90000, loss: 0.028607
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028605
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.797793
 >> iter 2000, loss: 4.006660
 >> iter 3000, loss: 1.508292
 >> iter 4000, loss: 0.588652
 >> iter 5000, loss: 0.250895
 >> iter 6000, loss: 0.125459
 >> iter 7000, loss: 0.079758
 >> iter 8000, loss: 0.061856
 >> iter 9000, loss: 0.054775
 >> iter 10000, loss: 0.049151
   Number of active neurons: 2
 >> iter 11000, loss: 0.045420
 >> iter 12000, loss: 0.042012
 >> iter 13000, loss: 0.040684
 >> iter 14000, loss: 0.039336
 >> iter 15000, loss: 0.039288
 >> iter 16000, loss: 0.038603
 >> iter 17000, loss: 0.038771
 >> iter 18000, loss: 0.038055
 >> iter 19000, loss: 0.037651
 >> iter 20000, loss: 0.035766
   Number of active neurons: 1
 >> iter 21000, loss: 0.034367
 >> iter 22000, loss: 0.032682
 >> iter 23000, loss: 0.032051
 >> iter 24000, loss: 0.031081
 >> iter 25000, loss: 0.030952
 >> iter 26000, loss: 0.030302
 >> iter 27000, loss: 0.030351
 >> iter 28000, loss: 0.029830
 >> iter 29000, loss: 0.029947
 >> iter 30000, loss: 0.029490
   Number of active neurons: 1
 >> iter 31000, loss: 0.029663
 >> iter 32000, loss: 0.029243
 >> iter 33000, loss: 0.029449
 >> iter 34000, loss: 0.029064
 >> iter 35000, loss: 0.029314
 >> iter 36000, loss: 0.028929
 >> iter 37000, loss: 0.029199
 >> iter 38000, loss: 0.028823
 >> iter 39000, loss: 0.029121
 >> iter 40000, loss: 0.028749
   Number of active neurons: 1
 >> iter 41000, loss: 0.029052
 >> iter 42000, loss: 0.028703
 >> iter 43000, loss: 0.028993
 >> iter 44000, loss: 0.028672
 >> iter 45000, loss: 0.028965
 >> iter 46000, loss: 0.028641
 >> iter 47000, loss: 0.028935
 >> iter 48000, loss: 0.028629
 >> iter 49000, loss: 0.028929
 >> iter 50000, loss: 0.028609
   Number of active neurons: 1
 >> iter 51000, loss: 0.028917
 >> iter 52000, loss: 0.028614
 >> iter 53000, loss: 0.028900
 >> iter 54000, loss: 0.028641
 >> iter 55000, loss: 0.028884
 >> iter 56000, loss: 0.028637
 >> iter 57000, loss: 0.028901
 >> iter 58000, loss: 0.028618
 >> iter 59000, loss: 0.028903
 >> iter 60000, loss: 0.028627
   Number of active neurons: 1
 >> iter 61000, loss: 0.028891
 >> iter 62000, loss: 0.028628
 >> iter 63000, loss: 0.028896
 >> iter 64000, loss: 0.028609
 >> iter 65000, loss: 0.028894
 >> iter 66000, loss: 0.028613
 >> iter 67000, loss: 0.028881
 >> iter 68000, loss: 0.028636
 >> iter 69000, loss: 0.028882
 >> iter 70000, loss: 0.028618
   Number of active neurons: 1
 >> iter 71000, loss: 0.028880
 >> iter 72000, loss: 0.028631
 >> iter 73000, loss: 0.028882
 >> iter 74000, loss: 0.028622
 >> iter 75000, loss: 0.028882
 >> iter 76000, loss: 0.028621
 >> iter 77000, loss: 0.028874
 >> iter 78000, loss: 0.028603
 >> iter 79000, loss: 0.028903
 >> iter 80000, loss: 0.028609
   Number of active neurons: 1
 >> iter 81000, loss: 0.028935
 >> iter 82000, loss: 0.028611
 >> iter 83000, loss: 0.028956
 >> iter 84000, loss: 0.028608
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028599
 >> iter 87000, loss: 0.028948
 >> iter 88000, loss: 0.028596
 >> iter 89000, loss: 0.028937
 >> iter 90000, loss: 0.028607
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028605
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.796190
 >> iter 2000, loss: 4.003108
 >> iter 3000, loss: 1.500425
 >> iter 4000, loss: 0.577659
 >> iter 5000, loss: 0.237639
 >> iter 6000, loss: 0.110999
 >> iter 7000, loss: 0.064474
 >> iter 8000, loss: 0.046559
 >> iter 9000, loss: 0.040456
 >> iter 10000, loss: 0.037568
   Number of active neurons: 2
 >> iter 11000, loss: 0.037075
 >> iter 12000, loss: 0.036243
 >> iter 13000, loss: 0.036586
 >> iter 14000, loss: 0.036096
 >> iter 15000, loss: 0.036613
 >> iter 16000, loss: 0.036246
 >> iter 17000, loss: 0.036771
 >> iter 18000, loss: 0.036420
 >> iter 19000, loss: 0.036926
 >> iter 20000, loss: 0.036624
   Number of active neurons: 2
 >> iter 21000, loss: 0.037127
 >> iter 22000, loss: 0.036824
 >> iter 23000, loss: 0.037355
 >> iter 24000, loss: 0.037054
 >> iter 25000, loss: 0.037605
 >> iter 26000, loss: 0.037324
 >> iter 27000, loss: 0.037828
 >> iter 28000, loss: 0.037511
 >> iter 29000, loss: 0.037866
 >> iter 30000, loss: 0.037342
   Number of active neurons: 1
 >> iter 31000, loss: 0.037062
 >> iter 32000, loss: 0.035314
 >> iter 33000, loss: 0.034035
 >> iter 34000, loss: 0.032414
 >> iter 35000, loss: 0.031829
 >> iter 36000, loss: 0.030885
 >> iter 37000, loss: 0.030775
 >> iter 38000, loss: 0.030122
 >> iter 39000, loss: 0.030212
 >> iter 40000, loss: 0.029672
   Number of active neurons: 1
 >> iter 41000, loss: 0.029840
 >> iter 42000, loss: 0.029375
 >> iter 43000, loss: 0.029570
 >> iter 44000, loss: 0.029165
 >> iter 45000, loss: 0.029389
 >> iter 46000, loss: 0.029004
 >> iter 47000, loss: 0.029247
 >> iter 48000, loss: 0.028897
 >> iter 49000, loss: 0.029159
 >> iter 50000, loss: 0.028807
   Number of active neurons: 1
 >> iter 51000, loss: 0.029087
 >> iter 52000, loss: 0.028759
 >> iter 53000, loss: 0.029025
 >> iter 54000, loss: 0.028749
 >> iter 55000, loss: 0.028977
 >> iter 56000, loss: 0.028717
 >> iter 57000, loss: 0.028970
 >> iter 58000, loss: 0.028677
 >> iter 59000, loss: 0.028954
 >> iter 60000, loss: 0.028670
   Number of active neurons: 1
 >> iter 61000, loss: 0.028928
 >> iter 62000, loss: 0.028660
 >> iter 63000, loss: 0.028924
 >> iter 64000, loss: 0.028632
 >> iter 65000, loss: 0.028914
 >> iter 66000, loss: 0.028631
 >> iter 67000, loss: 0.028896
 >> iter 68000, loss: 0.028649
 >> iter 69000, loss: 0.028894
 >> iter 70000, loss: 0.028627
   Number of active neurons: 1
 >> iter 71000, loss: 0.028889
 >> iter 72000, loss: 0.028638
 >> iter 73000, loss: 0.028888
 >> iter 74000, loss: 0.028627
 >> iter 75000, loss: 0.028887
 >> iter 76000, loss: 0.028625
 >> iter 77000, loss: 0.028877
 >> iter 78000, loss: 0.028606
 >> iter 79000, loss: 0.028906
 >> iter 80000, loss: 0.028611
   Number of active neurons: 1
 >> iter 81000, loss: 0.028937
 >> iter 82000, loss: 0.028613
 >> iter 83000, loss: 0.028957
 >> iter 84000, loss: 0.028609
 >> iter 85000, loss: 0.028948
 >> iter 86000, loss: 0.028600
 >> iter 87000, loss: 0.028948
 >> iter 88000, loss: 0.028596
 >> iter 89000, loss: 0.028938
 >> iter 90000, loss: 0.028608
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028617
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028606
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028599
 >> iter 97000, loss: 0.028982
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.749454
 >> iter 2000, loss: 3.986273
 >> iter 3000, loss: 1.494700
 >> iter 4000, loss: 0.575793
 >> iter 5000, loss: 0.237139
 >> iter 6000, loss: 0.110868
 >> iter 7000, loss: 0.064342
 >> iter 8000, loss: 0.046261
 >> iter 9000, loss: 0.040082
 >> iter 10000, loss: 0.036990
   Number of active neurons: 2
 >> iter 11000, loss: 0.036441
 >> iter 12000, loss: 0.035438
 >> iter 13000, loss: 0.035739
 >> iter 14000, loss: 0.035042
 >> iter 15000, loss: 0.035498
 >> iter 16000, loss: 0.034889
 >> iter 17000, loss: 0.035384
 >> iter 18000, loss: 0.034821
 >> iter 19000, loss: 0.035328
 >> iter 20000, loss: 0.034825
   Number of active neurons: 2
 >> iter 21000, loss: 0.035331
 >> iter 22000, loss: 0.034834
 >> iter 23000, loss: 0.035372
 >> iter 24000, loss: 0.034897
 >> iter 25000, loss: 0.035469
 >> iter 26000, loss: 0.035062
 >> iter 27000, loss: 0.035632
 >> iter 28000, loss: 0.035293
 >> iter 29000, loss: 0.035784
 >> iter 30000, loss: 0.035431
   Number of active neurons: 2
 >> iter 31000, loss: 0.035943
 >> iter 32000, loss: 0.035618
 >> iter 33000, loss: 0.036156
 >> iter 34000, loss: 0.035833
 >> iter 35000, loss: 0.036370
 >> iter 36000, loss: 0.036009
 >> iter 37000, loss: 0.036540
 >> iter 38000, loss: 0.036176
 >> iter 39000, loss: 0.036733
 >> iter 40000, loss: 0.036376
   Number of active neurons: 2
 >> iter 41000, loss: 0.036939
 >> iter 42000, loss: 0.036621
 >> iter 43000, loss: 0.037168
 >> iter 44000, loss: 0.036898
 >> iter 45000, loss: 0.037441
 >> iter 46000, loss: 0.037169
 >> iter 47000, loss: 0.037681
 >> iter 48000, loss: 0.037400
 >> iter 49000, loss: 0.037810
 >> iter 50000, loss: 0.037345
   Number of active neurons: 1
 >> iter 51000, loss: 0.037317
 >> iter 52000, loss: 0.035764
 >> iter 53000, loss: 0.034502
 >> iter 54000, loss: 0.032806
 >> iter 55000, loss: 0.032034
 >> iter 56000, loss: 0.031098
 >> iter 57000, loss: 0.030886
 >> iter 58000, loss: 0.030256
 >> iter 59000, loss: 0.030279
 >> iter 60000, loss: 0.029792
   Number of active neurons: 1
 >> iter 61000, loss: 0.029885
 >> iter 62000, loss: 0.029476
 >> iter 63000, loss: 0.029624
 >> iter 64000, loss: 0.029232
 >> iter 65000, loss: 0.029430
 >> iter 66000, loss: 0.029072
 >> iter 67000, loss: 0.029276
 >> iter 68000, loss: 0.028975
 >> iter 69000, loss: 0.029174
 >> iter 70000, loss: 0.028868
   Number of active neurons: 1
 >> iter 71000, loss: 0.029096
 >> iter 72000, loss: 0.028816
 >> iter 73000, loss: 0.029041
 >> iter 74000, loss: 0.028758
 >> iter 75000, loss: 0.029000
 >> iter 76000, loss: 0.028722
 >> iter 77000, loss: 0.028961
 >> iter 78000, loss: 0.028678
 >> iter 79000, loss: 0.028968
 >> iter 80000, loss: 0.028664
   Number of active neurons: 1
 >> iter 81000, loss: 0.028983
 >> iter 82000, loss: 0.028652
 >> iter 83000, loss: 0.028991
 >> iter 84000, loss: 0.028638
 >> iter 85000, loss: 0.028973
 >> iter 86000, loss: 0.028622
 >> iter 87000, loss: 0.028967
 >> iter 88000, loss: 0.028612
 >> iter 89000, loss: 0.028952
 >> iter 90000, loss: 0.028620
   Number of active neurons: 1
 >> iter 91000, loss: 0.028947
 >> iter 92000, loss: 0.028625
 >> iter 93000, loss: 0.028953
 >> iter 94000, loss: 0.028612
 >> iter 95000, loss: 0.028981
 >> iter 96000, loss: 0.028603
 >> iter 97000, loss: 0.028986
 >> iter 98000, loss: 0.028594
 >> iter 99000, loss: 0.028990
 >> iter 100000, loss: 0.028624
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.829506
 >> iter 2000, loss: 4.016210
 >> iter 3000, loss: 1.506433
 >> iter 4000, loss: 0.582012
 >> iter 5000, loss: 0.242440
 >> iter 6000, loss: 0.117062
 >> iter 7000, loss: 0.071540
 >> iter 8000, loss: 0.054276
 >> iter 9000, loss: 0.048369
 >> iter 10000, loss: 0.045290
   Number of active neurons: 1
 >> iter 11000, loss: 0.043479
 >> iter 12000, loss: 0.039876
 >> iter 13000, loss: 0.037034
 >> iter 14000, loss: 0.034375
 >> iter 15000, loss: 0.033211
 >> iter 16000, loss: 0.031917
 >> iter 17000, loss: 0.031599
 >> iter 18000, loss: 0.030821
 >> iter 19000, loss: 0.030781
 >> iter 20000, loss: 0.030210
   Number of active neurons: 1
 >> iter 21000, loss: 0.030278
 >> iter 22000, loss: 0.029776
 >> iter 23000, loss: 0.029920
 >> iter 24000, loss: 0.029457
 >> iter 25000, loss: 0.029658
 >> iter 26000, loss: 0.029244
 >> iter 27000, loss: 0.029463
 >> iter 28000, loss: 0.029081
 >> iter 29000, loss: 0.029307
 >> iter 30000, loss: 0.028943
   Number of active neurons: 1
 >> iter 31000, loss: 0.029193
 >> iter 32000, loss: 0.028841
 >> iter 33000, loss: 0.029103
 >> iter 34000, loss: 0.028768
 >> iter 35000, loss: 0.029058
 >> iter 36000, loss: 0.028711
 >> iter 37000, loss: 0.029010
 >> iter 38000, loss: 0.028662
 >> iter 39000, loss: 0.028981
 >> iter 40000, loss: 0.028630
   Number of active neurons: 1
 >> iter 41000, loss: 0.028949
 >> iter 42000, loss: 0.028615
 >> iter 43000, loss: 0.028917
 >> iter 44000, loss: 0.028607
 >> iter 45000, loss: 0.028908
 >> iter 46000, loss: 0.028592
 >> iter 47000, loss: 0.028893
 >> iter 48000, loss: 0.028593
 >> iter 49000, loss: 0.028898
 >> iter 50000, loss: 0.028583
   Number of active neurons: 1
 >> iter 51000, loss: 0.028894
 >> iter 52000, loss: 0.028594
 >> iter 53000, loss: 0.028883
 >> iter 54000, loss: 0.028626
 >> iter 55000, loss: 0.028872
 >> iter 56000, loss: 0.028627
 >> iter 57000, loss: 0.028892
 >> iter 58000, loss: 0.028610
 >> iter 59000, loss: 0.028896
 >> iter 60000, loss: 0.028621
   Number of active neurons: 1
 >> iter 61000, loss: 0.028886
 >> iter 62000, loss: 0.028623
 >> iter 63000, loss: 0.028892
 >> iter 64000, loss: 0.028605
 >> iter 65000, loss: 0.028891
 >> iter 66000, loss: 0.028611
 >> iter 67000, loss: 0.028879
 >> iter 68000, loss: 0.028634
 >> iter 69000, loss: 0.028881
 >> iter 70000, loss: 0.028617
   Number of active neurons: 1
 >> iter 71000, loss: 0.028879
 >> iter 72000, loss: 0.028630
 >> iter 73000, loss: 0.028881
 >> iter 74000, loss: 0.028621
 >> iter 75000, loss: 0.028882
 >> iter 76000, loss: 0.028620
 >> iter 77000, loss: 0.028873
 >> iter 78000, loss: 0.028603
 >> iter 79000, loss: 0.028903
 >> iter 80000, loss: 0.028608
   Number of active neurons: 1
 >> iter 81000, loss: 0.028935
 >> iter 82000, loss: 0.028611
 >> iter 83000, loss: 0.028956
 >> iter 84000, loss: 0.028607
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028599
 >> iter 87000, loss: 0.028947
 >> iter 88000, loss: 0.028595
 >> iter 89000, loss: 0.028937
 >> iter 90000, loss: 0.028608
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028606
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.757440
 >> iter 2000, loss: 3.992124
 >> iter 3000, loss: 1.499872
 >> iter 4000, loss: 0.580872
 >> iter 5000, loss: 0.241130
 >> iter 6000, loss: 0.114057
 >> iter 7000, loss: 0.067133
 >> iter 8000, loss: 0.049140
 >> iter 9000, loss: 0.042879
 >> iter 10000, loss: 0.039982
   Number of active neurons: 2
 >> iter 11000, loss: 0.039291
 >> iter 12000, loss: 0.038299
 >> iter 13000, loss: 0.037908
 >> iter 14000, loss: 0.035997
 >> iter 15000, loss: 0.034607
 >> iter 16000, loss: 0.032830
 >> iter 17000, loss: 0.032161
 >> iter 18000, loss: 0.031161
 >> iter 19000, loss: 0.030994
 >> iter 20000, loss: 0.030352
   Number of active neurons: 1
 >> iter 21000, loss: 0.030378
 >> iter 22000, loss: 0.029852
 >> iter 23000, loss: 0.029980
 >> iter 24000, loss: 0.029506
 >> iter 25000, loss: 0.029699
 >> iter 26000, loss: 0.029278
 >> iter 27000, loss: 0.029493
 >> iter 28000, loss: 0.029106
 >> iter 29000, loss: 0.029328
 >> iter 30000, loss: 0.028962
   Number of active neurons: 1
 >> iter 31000, loss: 0.029209
 >> iter 32000, loss: 0.028854
 >> iter 33000, loss: 0.029114
 >> iter 34000, loss: 0.028778
 >> iter 35000, loss: 0.029067
 >> iter 36000, loss: 0.028718
 >> iter 37000, loss: 0.029016
 >> iter 38000, loss: 0.028667
 >> iter 39000, loss: 0.028986
 >> iter 40000, loss: 0.028634
   Number of active neurons: 1
 >> iter 41000, loss: 0.028952
 >> iter 42000, loss: 0.028618
 >> iter 43000, loss: 0.028919
 >> iter 44000, loss: 0.028609
 >> iter 45000, loss: 0.028910
 >> iter 46000, loss: 0.028594
 >> iter 47000, loss: 0.028894
 >> iter 48000, loss: 0.028595
 >> iter 49000, loss: 0.028899
 >> iter 50000, loss: 0.028584
   Number of active neurons: 1
 >> iter 51000, loss: 0.028895
 >> iter 52000, loss: 0.028595
 >> iter 53000, loss: 0.028884
 >> iter 54000, loss: 0.028627
 >> iter 55000, loss: 0.028872
 >> iter 56000, loss: 0.028627
 >> iter 57000, loss: 0.028892
 >> iter 58000, loss: 0.028610
 >> iter 59000, loss: 0.028896
 >> iter 60000, loss: 0.028621
   Number of active neurons: 1
 >> iter 61000, loss: 0.028886
 >> iter 62000, loss: 0.028624
 >> iter 63000, loss: 0.028892
 >> iter 64000, loss: 0.028605
 >> iter 65000, loss: 0.028891
 >> iter 66000, loss: 0.028611
 >> iter 67000, loss: 0.028879
 >> iter 68000, loss: 0.028634
 >> iter 69000, loss: 0.028881
 >> iter 70000, loss: 0.028617
   Number of active neurons: 1
 >> iter 71000, loss: 0.028879
 >> iter 72000, loss: 0.028630
 >> iter 73000, loss: 0.028881
 >> iter 74000, loss: 0.028621
 >> iter 75000, loss: 0.028882
 >> iter 76000, loss: 0.028620
 >> iter 77000, loss: 0.028873
 >> iter 78000, loss: 0.028603
 >> iter 79000, loss: 0.028903
 >> iter 80000, loss: 0.028608
   Number of active neurons: 1
 >> iter 81000, loss: 0.028935
 >> iter 82000, loss: 0.028611
 >> iter 83000, loss: 0.028956
 >> iter 84000, loss: 0.028607
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028599
 >> iter 87000, loss: 0.028947
 >> iter 88000, loss: 0.028595
 >> iter 89000, loss: 0.028937
 >> iter 90000, loss: 0.028608
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028606
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.785669
 >> iter 2000, loss: 4.006788
 >> iter 3000, loss: 1.511730
 >> iter 4000, loss: 0.591548
 >> iter 5000, loss: 0.252268
 >> iter 6000, loss: 0.125395
 >> iter 7000, loss: 0.076844
 >> iter 8000, loss: 0.056320
 >> iter 9000, loss: 0.046981
 >> iter 10000, loss: 0.040691
   Number of active neurons: 1
 >> iter 11000, loss: 0.037101
 >> iter 12000, loss: 0.034354
 >> iter 13000, loss: 0.033212
 >> iter 14000, loss: 0.031952
 >> iter 15000, loss: 0.031665
 >> iter 16000, loss: 0.030889
 >> iter 17000, loss: 0.030872
 >> iter 18000, loss: 0.030274
 >> iter 19000, loss: 0.030347
 >> iter 20000, loss: 0.029855
   Number of active neurons: 1
 >> iter 21000, loss: 0.029980
 >> iter 22000, loss: 0.029523
 >> iter 23000, loss: 0.029704
 >> iter 24000, loss: 0.029272
 >> iter 25000, loss: 0.029499
 >> iter 26000, loss: 0.029108
 >> iter 27000, loss: 0.029346
 >> iter 28000, loss: 0.028981
 >> iter 29000, loss: 0.029221
 >> iter 30000, loss: 0.028869
   Number of active neurons: 1
 >> iter 31000, loss: 0.029129
 >> iter 32000, loss: 0.028787
 >> iter 33000, loss: 0.029056
 >> iter 34000, loss: 0.028728
 >> iter 35000, loss: 0.029023
 >> iter 36000, loss: 0.028681
 >> iter 37000, loss: 0.028985
 >> iter 38000, loss: 0.028640
 >> iter 39000, loss: 0.028962
 >> iter 40000, loss: 0.028613
   Number of active neurons: 1
 >> iter 41000, loss: 0.028935
 >> iter 42000, loss: 0.028603
 >> iter 43000, loss: 0.028907
 >> iter 44000, loss: 0.028598
 >> iter 45000, loss: 0.028901
 >> iter 46000, loss: 0.028586
 >> iter 47000, loss: 0.028887
 >> iter 48000, loss: 0.028589
 >> iter 49000, loss: 0.028894
 >> iter 50000, loss: 0.028579
   Number of active neurons: 1
 >> iter 51000, loss: 0.028891
 >> iter 52000, loss: 0.028591
 >> iter 53000, loss: 0.028881
 >> iter 54000, loss: 0.028624
 >> iter 55000, loss: 0.028870
 >> iter 56000, loss: 0.028625
 >> iter 57000, loss: 0.028891
 >> iter 58000, loss: 0.028609
 >> iter 59000, loss: 0.028895
 >> iter 60000, loss: 0.028620
   Number of active neurons: 1
 >> iter 61000, loss: 0.028885
 >> iter 62000, loss: 0.028623
 >> iter 63000, loss: 0.028892
 >> iter 64000, loss: 0.028605
 >> iter 65000, loss: 0.028891
 >> iter 66000, loss: 0.028611
 >> iter 67000, loss: 0.028879
 >> iter 68000, loss: 0.028634
 >> iter 69000, loss: 0.028881
 >> iter 70000, loss: 0.028616
   Number of active neurons: 1
 >> iter 71000, loss: 0.028879
 >> iter 72000, loss: 0.028630
 >> iter 73000, loss: 0.028881
 >> iter 74000, loss: 0.028621
 >> iter 75000, loss: 0.028882
 >> iter 76000, loss: 0.028620
 >> iter 77000, loss: 0.028873
 >> iter 78000, loss: 0.028603
 >> iter 79000, loss: 0.028903
 >> iter 80000, loss: 0.028608
   Number of active neurons: 1
 >> iter 81000, loss: 0.028935
 >> iter 82000, loss: 0.028611
 >> iter 83000, loss: 0.028956
 >> iter 84000, loss: 0.028607
 >> iter 85000, loss: 0.028947
 >> iter 86000, loss: 0.028599
 >> iter 87000, loss: 0.028948
 >> iter 88000, loss: 0.028595
 >> iter 89000, loss: 0.028937
 >> iter 90000, loss: 0.028608
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028606
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028590
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.723406
 >> iter 2000, loss: 3.978703
 >> iter 3000, loss: 1.495810
 >> iter 4000, loss: 0.580561
 >> iter 5000, loss: 0.243111
 >> iter 6000, loss: 0.116673
 >> iter 7000, loss: 0.069268
 >> iter 8000, loss: 0.049854
 >> iter 9000, loss: 0.042448
 >> iter 10000, loss: 0.038764
   Number of active neurons: 2
 >> iter 11000, loss: 0.037833
 >> iter 12000, loss: 0.036768
 >> iter 13000, loss: 0.036963
 >> iter 14000, loss: 0.036390
 >> iter 15000, loss: 0.036845
 >> iter 16000, loss: 0.036428
 >> iter 17000, loss: 0.036918
 >> iter 18000, loss: 0.036540
 >> iter 19000, loss: 0.037026
 >> iter 20000, loss: 0.036706
   Number of active neurons: 2
 >> iter 21000, loss: 0.037198
 >> iter 22000, loss: 0.036884
 >> iter 23000, loss: 0.037408
 >> iter 24000, loss: 0.037099
 >> iter 25000, loss: 0.037645
 >> iter 26000, loss: 0.037358
 >> iter 27000, loss: 0.037856
 >> iter 28000, loss: 0.037533
 >> iter 29000, loss: 0.037878
 >> iter 30000, loss: 0.037338
   Number of active neurons: 1
 >> iter 31000, loss: 0.037002
 >> iter 32000, loss: 0.035229
 >> iter 33000, loss: 0.033949
 >> iter 34000, loss: 0.032354
 >> iter 35000, loss: 0.031789
 >> iter 36000, loss: 0.030858
 >> iter 37000, loss: 0.030756
 >> iter 38000, loss: 0.030108
 >> iter 39000, loss: 0.030201
 >> iter 40000, loss: 0.029663
   Number of active neurons: 1
 >> iter 41000, loss: 0.029832
 >> iter 42000, loss: 0.029369
 >> iter 43000, loss: 0.029565
 >> iter 44000, loss: 0.029161
 >> iter 45000, loss: 0.029385
 >> iter 46000, loss: 0.029001
 >> iter 47000, loss: 0.029244
 >> iter 48000, loss: 0.028894
 >> iter 49000, loss: 0.029157
 >> iter 50000, loss: 0.028805
   Number of active neurons: 1
 >> iter 51000, loss: 0.029086
 >> iter 52000, loss: 0.028758
 >> iter 53000, loss: 0.029025
 >> iter 54000, loss: 0.028748
 >> iter 55000, loss: 0.028976
 >> iter 56000, loss: 0.028716
 >> iter 57000, loss: 0.028969
 >> iter 58000, loss: 0.028676
 >> iter 59000, loss: 0.028953
 >> iter 60000, loss: 0.028670
   Number of active neurons: 1
 >> iter 61000, loss: 0.028928
 >> iter 62000, loss: 0.028660
 >> iter 63000, loss: 0.028924
 >> iter 64000, loss: 0.028632
 >> iter 65000, loss: 0.028915
 >> iter 66000, loss: 0.028631
 >> iter 67000, loss: 0.028896
 >> iter 68000, loss: 0.028649
 >> iter 69000, loss: 0.028894
 >> iter 70000, loss: 0.028628
   Number of active neurons: 1
 >> iter 71000, loss: 0.028889
 >> iter 72000, loss: 0.028638
 >> iter 73000, loss: 0.028888
 >> iter 74000, loss: 0.028627
 >> iter 75000, loss: 0.028887
 >> iter 76000, loss: 0.028625
 >> iter 77000, loss: 0.028877
 >> iter 78000, loss: 0.028607
 >> iter 79000, loss: 0.028906
 >> iter 80000, loss: 0.028611
   Number of active neurons: 1
 >> iter 81000, loss: 0.028937
 >> iter 82000, loss: 0.028613
 >> iter 83000, loss: 0.028957
 >> iter 84000, loss: 0.028609
 >> iter 85000, loss: 0.028948
 >> iter 86000, loss: 0.028600
 >> iter 87000, loss: 0.028948
 >> iter 88000, loss: 0.028596
 >> iter 89000, loss: 0.028938
 >> iter 90000, loss: 0.028608
   Number of active neurons: 1
 >> iter 91000, loss: 0.028937
 >> iter 92000, loss: 0.028616
 >> iter 93000, loss: 0.028946
 >> iter 94000, loss: 0.028606
 >> iter 95000, loss: 0.028976
 >> iter 96000, loss: 0.028598
 >> iter 97000, loss: 0.028981
 >> iter 98000, loss: 0.028591
 >> iter 99000, loss: 0.028987
 >> iter 100000, loss: 0.028621
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

