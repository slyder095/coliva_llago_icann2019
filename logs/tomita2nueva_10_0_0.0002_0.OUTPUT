 > Problema: tomita2nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 0.0002
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.841370
 >> iter 2000, loss: 4.025645
 >> iter 3000, loss: 1.513727
 >> iter 4000, loss: 0.586959
 >> iter 5000, loss: 0.245905
 >> iter 6000, loss: 0.118852
 >> iter 7000, loss: 0.071917
 >> iter 8000, loss: 0.053140
 >> iter 9000, loss: 0.046368
 >> iter 10000, loss: 0.043022
   Number of active neurons: 3
 >> iter 11000, loss: 0.042274
 >> iter 12000, loss: 0.041118
 >> iter 13000, loss: 0.041089
 >> iter 14000, loss: 0.040413
 >> iter 15000, loss: 0.040777
 >> iter 16000, loss: 0.040291
 >> iter 17000, loss: 0.040788
 >> iter 18000, loss: 0.040378
 >> iter 19000, loss: 0.040902
 >> iter 20000, loss: 0.040444
   Number of active neurons: 3
 >> iter 21000, loss: 0.040891
 >> iter 22000, loss: 0.040482
 >> iter 23000, loss: 0.040995
 >> iter 24000, loss: 0.040619
 >> iter 25000, loss: 0.041172
 >> iter 26000, loss: 0.040772
 >> iter 27000, loss: 0.041332
 >> iter 28000, loss: 0.040871
 >> iter 29000, loss: 0.041122
 >> iter 30000, loss: 0.040175
   Number of active neurons: 2
 >> iter 31000, loss: 0.040131
 >> iter 32000, loss: 0.038898
 >> iter 33000, loss: 0.038389
 >> iter 34000, loss: 0.036848
 >> iter 35000, loss: 0.035964
 >> iter 36000, loss: 0.034663
 >> iter 37000, loss: 0.034350
 >> iter 38000, loss: 0.033553
 >> iter 39000, loss: 0.033542
 >> iter 40000, loss: 0.033015
   Number of active neurons: 2
 >> iter 41000, loss: 0.033097
 >> iter 42000, loss: 0.032645
 >> iter 43000, loss: 0.032799
 >> iter 44000, loss: 0.032429
 >> iter 45000, loss: 0.032604
 >> iter 46000, loss: 0.032250
 >> iter 47000, loss: 0.032460
 >> iter 48000, loss: 0.032124
 >> iter 49000, loss: 0.032364
 >> iter 50000, loss: 0.032028
   Number of active neurons: 2
 >> iter 51000, loss: 0.032273
 >> iter 52000, loss: 0.031985
 >> iter 53000, loss: 0.032196
 >> iter 54000, loss: 0.031957
 >> iter 55000, loss: 0.032163
 >> iter 56000, loss: 0.031927
 >> iter 57000, loss: 0.032120
 >> iter 58000, loss: 0.031903
 >> iter 59000, loss: 0.032097
 >> iter 60000, loss: 0.031887
   Number of active neurons: 2
 >> iter 61000, loss: 0.032118
 >> iter 62000, loss: 0.031870
 >> iter 63000, loss: 0.032082
 >> iter 64000, loss: 0.031866
 >> iter 65000, loss: 0.032061
 >> iter 66000, loss: 0.031861
 >> iter 67000, loss: 0.032051
 >> iter 68000, loss: 0.031873
 >> iter 69000, loss: 0.032025
 >> iter 70000, loss: 0.031863
   Number of active neurons: 2
 >> iter 71000, loss: 0.032002
 >> iter 72000, loss: 0.031846
 >> iter 73000, loss: 0.032019
 >> iter 74000, loss: 0.031854
 >> iter 75000, loss: 0.032010
 >> iter 76000, loss: 0.031854
 >> iter 77000, loss: 0.032000
 >> iter 78000, loss: 0.031842
 >> iter 79000, loss: 0.031992
 >> iter 80000, loss: 0.031822
   Number of active neurons: 2
 >> iter 81000, loss: 0.031983
 >> iter 82000, loss: 0.031815
 >> iter 83000, loss: 0.031976
 >> iter 84000, loss: 0.031822
 >> iter 85000, loss: 0.031954
 >> iter 86000, loss: 0.031811
 >> iter 87000, loss: 0.031939
 >> iter 88000, loss: 0.031831
 >> iter 89000, loss: 0.031941
 >> iter 90000, loss: 0.031822
   Number of active neurons: 2
 >> iter 91000, loss: 0.031922
 >> iter 92000, loss: 0.031832
 >> iter 93000, loss: 0.031931
 >> iter 94000, loss: 0.031828
 >> iter 95000, loss: 0.031942
 >> iter 96000, loss: 0.031829
 >> iter 97000, loss: 0.031940
 >> iter 98000, loss: 0.031820
 >> iter 99000, loss: 0.031937
 >> iter 100000, loss: 0.031836
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.898172
 >> iter 2000, loss: 4.054370
 >> iter 3000, loss: 1.530795
 >> iter 4000, loss: 0.599046
 >> iter 5000, loss: 0.254468
 >> iter 6000, loss: 0.124258
 >> iter 7000, loss: 0.075242
 >> iter 8000, loss: 0.055540
 >> iter 9000, loss: 0.048103
 >> iter 10000, loss: 0.043971
   Number of active neurons: 2
 >> iter 11000, loss: 0.042082
 >> iter 12000, loss: 0.039739
 >> iter 13000, loss: 0.038446
 >> iter 14000, loss: 0.036430
 >> iter 15000, loss: 0.035692
 >> iter 16000, loss: 0.034409
 >> iter 17000, loss: 0.034203
 >> iter 18000, loss: 0.033339
 >> iter 19000, loss: 0.033450
 >> iter 20000, loss: 0.032833
   Number of active neurons: 2
 >> iter 21000, loss: 0.033056
 >> iter 22000, loss: 0.032536
 >> iter 23000, loss: 0.032817
 >> iter 24000, loss: 0.032333
 >> iter 25000, loss: 0.032654
 >> iter 26000, loss: 0.032179
 >> iter 27000, loss: 0.032530
 >> iter 28000, loss: 0.032064
 >> iter 29000, loss: 0.032424
 >> iter 30000, loss: 0.031992
   Number of active neurons: 2
 >> iter 31000, loss: 0.032352
 >> iter 32000, loss: 0.031929
 >> iter 33000, loss: 0.032287
 >> iter 34000, loss: 0.031904
 >> iter 35000, loss: 0.032230
 >> iter 36000, loss: 0.031869
 >> iter 37000, loss: 0.032192
 >> iter 38000, loss: 0.031845
 >> iter 39000, loss: 0.032147
 >> iter 40000, loss: 0.031862
   Number of active neurons: 2
 >> iter 41000, loss: 0.032120
 >> iter 42000, loss: 0.031822
 >> iter 43000, loss: 0.032092
 >> iter 44000, loss: 0.031829
 >> iter 45000, loss: 0.032084
 >> iter 46000, loss: 0.031809
 >> iter 47000, loss: 0.032076
 >> iter 48000, loss: 0.031797
 >> iter 49000, loss: 0.032079
 >> iter 50000, loss: 0.031786
   Number of active neurons: 2
 >> iter 51000, loss: 0.032060
 >> iter 52000, loss: 0.031804
 >> iter 53000, loss: 0.032037
 >> iter 54000, loss: 0.031821
 >> iter 55000, loss: 0.032043
 >> iter 56000, loss: 0.031823
 >> iter 57000, loss: 0.032028
 >> iter 58000, loss: 0.031825
 >> iter 59000, loss: 0.032027
 >> iter 60000, loss: 0.031827
   Number of active neurons: 2
 >> iter 61000, loss: 0.032065
 >> iter 62000, loss: 0.031825
 >> iter 63000, loss: 0.032042
 >> iter 64000, loss: 0.031832
 >> iter 65000, loss: 0.032032
 >> iter 66000, loss: 0.031836
 >> iter 67000, loss: 0.032026
 >> iter 68000, loss: 0.031853
 >> iter 69000, loss: 0.032006
 >> iter 70000, loss: 0.031847
   Number of active neurons: 2
 >> iter 71000, loss: 0.031987
 >> iter 72000, loss: 0.031835
 >> iter 73000, loss: 0.032009
 >> iter 74000, loss: 0.031844
 >> iter 75000, loss: 0.032001
 >> iter 76000, loss: 0.031848
 >> iter 77000, loss: 0.031994
 >> iter 78000, loss: 0.031837
 >> iter 79000, loss: 0.031986
 >> iter 80000, loss: 0.031818
   Number of active neurons: 2
 >> iter 81000, loss: 0.031980
 >> iter 82000, loss: 0.031811
 >> iter 83000, loss: 0.031972
 >> iter 84000, loss: 0.031819
 >> iter 85000, loss: 0.031951
 >> iter 86000, loss: 0.031809
 >> iter 87000, loss: 0.031937
 >> iter 88000, loss: 0.031831
 >> iter 89000, loss: 0.031941
 >> iter 90000, loss: 0.031823
   Number of active neurons: 2
 >> iter 91000, loss: 0.031921
 >> iter 92000, loss: 0.031832
 >> iter 93000, loss: 0.031931
 >> iter 94000, loss: 0.031828
 >> iter 95000, loss: 0.031940
 >> iter 96000, loss: 0.031827
 >> iter 97000, loss: 0.031939
 >> iter 98000, loss: 0.031820
 >> iter 99000, loss: 0.031937
 >> iter 100000, loss: 0.031836
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.907890
 >> iter 2000, loss: 4.052520
 >> iter 3000, loss: 1.523086
 >> iter 4000, loss: 0.589100
 >> iter 5000, loss: 0.245460
 >> iter 6000, loss: 0.117407
 >> iter 7000, loss: 0.070255
 >> iter 8000, loss: 0.051873
 >> iter 9000, loss: 0.045555
 >> iter 10000, loss: 0.042491
   Number of active neurons: 4
 >> iter 11000, loss: 0.041913
 >> iter 12000, loss: 0.040891
 >> iter 13000, loss: 0.040858
 >> iter 14000, loss: 0.040227
 >> iter 15000, loss: 0.040581
 >> iter 16000, loss: 0.040043
 >> iter 17000, loss: 0.040489
 >> iter 18000, loss: 0.040075
 >> iter 19000, loss: 0.040600
 >> iter 20000, loss: 0.040173
   Number of active neurons: 4
 >> iter 21000, loss: 0.040606
 >> iter 22000, loss: 0.040189
 >> iter 23000, loss: 0.040675
 >> iter 24000, loss: 0.040297
 >> iter 25000, loss: 0.040836
 >> iter 26000, loss: 0.040451
 >> iter 27000, loss: 0.041023
 >> iter 28000, loss: 0.040623
 >> iter 29000, loss: 0.041198
 >> iter 30000, loss: 0.040805
   Number of active neurons: 4
 >> iter 31000, loss: 0.041346
 >> iter 32000, loss: 0.040713
 >> iter 33000, loss: 0.040721
 >> iter 34000, loss: 0.039806
 >> iter 35000, loss: 0.039493
 >> iter 36000, loss: 0.038211
 >> iter 37000, loss: 0.037491
 >> iter 38000, loss: 0.035873
 >> iter 39000, loss: 0.035170
 >> iter 40000, loss: 0.034170
   Number of active neurons: 3
 >> iter 41000, loss: 0.033953
 >> iter 42000, loss: 0.033303
 >> iter 43000, loss: 0.033325
 >> iter 44000, loss: 0.032861
 >> iter 45000, loss: 0.032963
 >> iter 46000, loss: 0.032552
 >> iter 47000, loss: 0.032717
 >> iter 48000, loss: 0.032342
 >> iter 49000, loss: 0.032551
 >> iter 50000, loss: 0.032189
   Number of active neurons: 3
 >> iter 51000, loss: 0.032411
 >> iter 52000, loss: 0.032103
 >> iter 53000, loss: 0.032300
 >> iter 54000, loss: 0.032046
 >> iter 55000, loss: 0.032237
 >> iter 56000, loss: 0.031991
 >> iter 57000, loss: 0.032174
 >> iter 58000, loss: 0.031952
 >> iter 59000, loss: 0.032140
 >> iter 60000, loss: 0.031923
   Number of active neurons: 3
 >> iter 61000, loss: 0.032149
 >> iter 62000, loss: 0.031898
 >> iter 63000, loss: 0.032106
 >> iter 64000, loss: 0.031887
 >> iter 65000, loss: 0.032081
 >> iter 66000, loss: 0.031878
 >> iter 67000, loss: 0.032065
 >> iter 68000, loss: 0.031887
 >> iter 69000, loss: 0.032036
 >> iter 70000, loss: 0.031873
   Number of active neurons: 3
 >> iter 71000, loss: 0.032009
 >> iter 72000, loss: 0.031855
 >> iter 73000, loss: 0.032026
 >> iter 74000, loss: 0.031859
 >> iter 75000, loss: 0.032014
 >> iter 76000, loss: 0.031859
 >> iter 77000, loss: 0.032003
 >> iter 78000, loss: 0.031846
 >> iter 79000, loss: 0.031994
 >> iter 80000, loss: 0.031824
   Number of active neurons: 2
 >> iter 81000, loss: 0.031986
 >> iter 82000, loss: 0.031818
 >> iter 83000, loss: 0.031977
 >> iter 84000, loss: 0.031824
 >> iter 85000, loss: 0.031955
 >> iter 86000, loss: 0.031812
 >> iter 87000, loss: 0.031940
 >> iter 88000, loss: 0.031832
 >> iter 89000, loss: 0.031943
 >> iter 90000, loss: 0.031824
   Number of active neurons: 2
 >> iter 91000, loss: 0.031922
 >> iter 92000, loss: 0.031832
 >> iter 93000, loss: 0.031933
 >> iter 94000, loss: 0.031830
 >> iter 95000, loss: 0.031943
 >> iter 96000, loss: 0.031829
 >> iter 97000, loss: 0.031941
 >> iter 98000, loss: 0.031820
 >> iter 99000, loss: 0.031937
 >> iter 100000, loss: 0.031836
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.856616
 >> iter 2000, loss: 4.036127
 >> iter 3000, loss: 1.520709
 >> iter 4000, loss: 0.592036
 >> iter 5000, loss: 0.249813
 >> iter 6000, loss: 0.122501
 >> iter 7000, loss: 0.076450
 >> iter 8000, loss: 0.058805
 >> iter 9000, loss: 0.053006
 >> iter 10000, loss: 0.049707
   Number of active neurons: 4
 >> iter 11000, loss: 0.048561
 >> iter 12000, loss: 0.046464
 >> iter 13000, loss: 0.045227
 >> iter 14000, loss: 0.042870
 >> iter 15000, loss: 0.041724
 >> iter 16000, loss: 0.039692
 >> iter 17000, loss: 0.038523
 >> iter 18000, loss: 0.036460
 >> iter 19000, loss: 0.035660
 >> iter 20000, loss: 0.034420
   Number of active neurons: 3
 >> iter 21000, loss: 0.034247
 >> iter 22000, loss: 0.033457
 >> iter 23000, loss: 0.033559
 >> iter 24000, loss: 0.032939
 >> iter 25000, loss: 0.033158
 >> iter 26000, loss: 0.032601
 >> iter 27000, loss: 0.032889
 >> iter 28000, loss: 0.032367
 >> iter 29000, loss: 0.032684
 >> iter 30000, loss: 0.032213
   Number of active neurons: 3
 >> iter 31000, loss: 0.032542
 >> iter 32000, loss: 0.032091
 >> iter 33000, loss: 0.032428
 >> iter 34000, loss: 0.032024
 >> iter 35000, loss: 0.032335
 >> iter 36000, loss: 0.031959
 >> iter 37000, loss: 0.032272
 >> iter 38000, loss: 0.031914
 >> iter 39000, loss: 0.032204
 >> iter 40000, loss: 0.031912
   Number of active neurons: 3
 >> iter 41000, loss: 0.032164
 >> iter 42000, loss: 0.031862
 >> iter 43000, loss: 0.032125
 >> iter 44000, loss: 0.031858
 >> iter 45000, loss: 0.032110
 >> iter 46000, loss: 0.031831
 >> iter 47000, loss: 0.032095
 >> iter 48000, loss: 0.031816
 >> iter 49000, loss: 0.032096
 >> iter 50000, loss: 0.031801
   Number of active neurons: 3
 >> iter 51000, loss: 0.032072
 >> iter 52000, loss: 0.031813
 >> iter 53000, loss: 0.032047
 >> iter 54000, loss: 0.031830
 >> iter 55000, loss: 0.032050
 >> iter 56000, loss: 0.031830
 >> iter 57000, loss: 0.032034
 >> iter 58000, loss: 0.031830
 >> iter 59000, loss: 0.032032
 >> iter 60000, loss: 0.031831
   Number of active neurons: 3
 >> iter 61000, loss: 0.032067
 >> iter 62000, loss: 0.031829
 >> iter 63000, loss: 0.032045
 >> iter 64000, loss: 0.031835
 >> iter 65000, loss: 0.032033
 >> iter 66000, loss: 0.031839
 >> iter 67000, loss: 0.032029
 >> iter 68000, loss: 0.031855
 >> iter 69000, loss: 0.032008
 >> iter 70000, loss: 0.031850
   Number of active neurons: 3
 >> iter 71000, loss: 0.031990
 >> iter 72000, loss: 0.031838
 >> iter 73000, loss: 0.032011
 >> iter 74000, loss: 0.031846
 >> iter 75000, loss: 0.032002
 >> iter 76000, loss: 0.031848
 >> iter 77000, loss: 0.031995
 >> iter 78000, loss: 0.031839
 >> iter 79000, loss: 0.031988
 >> iter 80000, loss: 0.031819
   Number of active neurons: 3
 >> iter 81000, loss: 0.031980
 >> iter 82000, loss: 0.031813
 >> iter 83000, loss: 0.031972
 >> iter 84000, loss: 0.031820
 >> iter 85000, loss: 0.031953
 >> iter 86000, loss: 0.031811
 >> iter 87000, loss: 0.031938
 >> iter 88000, loss: 0.031831
 >> iter 89000, loss: 0.031940
 >> iter 90000, loss: 0.031822
   Number of active neurons: 3
 >> iter 91000, loss: 0.031921
 >> iter 92000, loss: 0.031832
 >> iter 93000, loss: 0.031933
 >> iter 94000, loss: 0.031829
 >> iter 95000, loss: 0.031942
 >> iter 96000, loss: 0.031829
 >> iter 97000, loss: 0.031940
 >> iter 98000, loss: 0.031820
 >> iter 99000, loss: 0.031939
 >> iter 100000, loss: 0.031836
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.023419
 >> iter 2000, loss: 4.096886
 >> iter 3000, loss: 1.544355
 >> iter 4000, loss: 0.603966
 >> iter 5000, loss: 0.258042
 >> iter 6000, loss: 0.128798
 >> iter 7000, loss: 0.080930
 >> iter 8000, loss: 0.061413
 >> iter 9000, loss: 0.054103
 >> iter 10000, loss: 0.049666
   Number of active neurons: 3
 >> iter 11000, loss: 0.047657
 >> iter 12000, loss: 0.045394
 >> iter 13000, loss: 0.044567
 >> iter 14000, loss: 0.042604
 >> iter 15000, loss: 0.041970
 >> iter 16000, loss: 0.040692
 >> iter 17000, loss: 0.040756
 >> iter 18000, loss: 0.040024
 >> iter 19000, loss: 0.040341
 >> iter 20000, loss: 0.039810
   Number of active neurons: 3
 >> iter 21000, loss: 0.040148
 >> iter 22000, loss: 0.039612
 >> iter 23000, loss: 0.039933
 >> iter 24000, loss: 0.039487
 >> iter 25000, loss: 0.039904
 >> iter 26000, loss: 0.039499
 >> iter 27000, loss: 0.039972
 >> iter 28000, loss: 0.039532
 >> iter 29000, loss: 0.040057
 >> iter 30000, loss: 0.039709
   Number of active neurons: 3
 >> iter 31000, loss: 0.040230
 >> iter 32000, loss: 0.039851
 >> iter 33000, loss: 0.040351
 >> iter 34000, loss: 0.040017
 >> iter 35000, loss: 0.040473
 >> iter 36000, loss: 0.040167
 >> iter 37000, loss: 0.040633
 >> iter 38000, loss: 0.040344
 >> iter 39000, loss: 0.040793
 >> iter 40000, loss: 0.040582
   Number of active neurons: 3
 >> iter 41000, loss: 0.040986
 >> iter 42000, loss: 0.040746
 >> iter 43000, loss: 0.041159
 >> iter 44000, loss: 0.040918
 >> iter 45000, loss: 0.041194
 >> iter 46000, loss: 0.040428
 >> iter 47000, loss: 0.040278
 >> iter 48000, loss: 0.039323
 >> iter 49000, loss: 0.038791
 >> iter 50000, loss: 0.037444
   Number of active neurons: 2
 >> iter 51000, loss: 0.036486
 >> iter 52000, loss: 0.035115
 >> iter 53000, loss: 0.034574
 >> iter 54000, loss: 0.033809
 >> iter 55000, loss: 0.033658
 >> iter 56000, loss: 0.033153
 >> iter 57000, loss: 0.033151
 >> iter 58000, loss: 0.032771
 >> iter 59000, loss: 0.032838
 >> iter 60000, loss: 0.032516
   Number of active neurons: 2
 >> iter 61000, loss: 0.032659
 >> iter 62000, loss: 0.032332
 >> iter 63000, loss: 0.032482
 >> iter 64000, loss: 0.032209
 >> iter 65000, loss: 0.032360
 >> iter 66000, loss: 0.032116
 >> iter 67000, loss: 0.032272
 >> iter 68000, loss: 0.032063
 >> iter 69000, loss: 0.032190
 >> iter 70000, loss: 0.032006
   Number of active neurons: 2
 >> iter 71000, loss: 0.032127
 >> iter 72000, loss: 0.031954
 >> iter 73000, loss: 0.032114
 >> iter 74000, loss: 0.031935
 >> iter 75000, loss: 0.032081
 >> iter 76000, loss: 0.031915
 >> iter 77000, loss: 0.032053
 >> iter 78000, loss: 0.031889
 >> iter 79000, loss: 0.032034
 >> iter 80000, loss: 0.031859
   Number of active neurons: 2
 >> iter 81000, loss: 0.032016
 >> iter 82000, loss: 0.031842
 >> iter 83000, loss: 0.032000
 >> iter 84000, loss: 0.031843
 >> iter 85000, loss: 0.031972
 >> iter 86000, loss: 0.031827
 >> iter 87000, loss: 0.031954
 >> iter 88000, loss: 0.031844
 >> iter 89000, loss: 0.031953
 >> iter 90000, loss: 0.031833
   Number of active neurons: 2
 >> iter 91000, loss: 0.031931
 >> iter 92000, loss: 0.031839
 >> iter 93000, loss: 0.031939
 >> iter 94000, loss: 0.031835
 >> iter 95000, loss: 0.031947
 >> iter 96000, loss: 0.031832
 >> iter 97000, loss: 0.031943
 >> iter 98000, loss: 0.031823
 >> iter 99000, loss: 0.031940
 >> iter 100000, loss: 0.031838
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.995568
 >> iter 2000, loss: 4.088252
 >> iter 3000, loss: 1.542064
 >> iter 4000, loss: 0.604157
 >> iter 5000, loss: 0.259580
 >> iter 6000, loss: 0.131764
 >> iter 7000, loss: 0.084985
 >> iter 8000, loss: 0.066180
 >> iter 9000, loss: 0.059329
 >> iter 10000, loss: 0.055228
   Number of active neurons: 3
 >> iter 11000, loss: 0.053412
 >> iter 12000, loss: 0.050666
 >> iter 13000, loss: 0.048819
 >> iter 14000, loss: 0.046025
 >> iter 15000, loss: 0.044825
 >> iter 16000, loss: 0.043114
 >> iter 17000, loss: 0.042458
 >> iter 18000, loss: 0.040903
 >> iter 19000, loss: 0.040163
 >> iter 20000, loss: 0.038445
   Number of active neurons: 2
 >> iter 21000, loss: 0.037463
 >> iter 22000, loss: 0.035727
 >> iter 23000, loss: 0.035153
 >> iter 24000, loss: 0.034080
 >> iter 25000, loss: 0.034025
 >> iter 26000, loss: 0.033272
 >> iter 27000, loss: 0.033432
 >> iter 28000, loss: 0.032810
 >> iter 29000, loss: 0.033060
 >> iter 30000, loss: 0.032526
   Number of active neurons: 2
 >> iter 31000, loss: 0.032812
 >> iter 32000, loss: 0.032318
 >> iter 33000, loss: 0.032624
 >> iter 34000, loss: 0.032190
 >> iter 35000, loss: 0.032479
 >> iter 36000, loss: 0.032080
 >> iter 37000, loss: 0.032378
 >> iter 38000, loss: 0.032002
 >> iter 39000, loss: 0.032285
 >> iter 40000, loss: 0.031977
   Number of active neurons: 2
 >> iter 41000, loss: 0.032224
 >> iter 42000, loss: 0.031911
 >> iter 43000, loss: 0.032169
 >> iter 44000, loss: 0.031895
 >> iter 45000, loss: 0.032142
 >> iter 46000, loss: 0.031858
 >> iter 47000, loss: 0.032120
 >> iter 48000, loss: 0.031836
 >> iter 49000, loss: 0.032113
 >> iter 50000, loss: 0.031815
   Number of active neurons: 2
 >> iter 51000, loss: 0.032086
 >> iter 52000, loss: 0.031825
 >> iter 53000, loss: 0.032057
 >> iter 54000, loss: 0.031839
 >> iter 55000, loss: 0.032058
 >> iter 56000, loss: 0.031836
 >> iter 57000, loss: 0.032041
 >> iter 58000, loss: 0.031835
 >> iter 59000, loss: 0.032037
 >> iter 60000, loss: 0.031834
   Number of active neurons: 2
 >> iter 61000, loss: 0.032071
 >> iter 62000, loss: 0.031831
 >> iter 63000, loss: 0.032047
 >> iter 64000, loss: 0.031836
 >> iter 65000, loss: 0.032035
 >> iter 66000, loss: 0.031839
 >> iter 67000, loss: 0.032030
 >> iter 68000, loss: 0.031855
 >> iter 69000, loss: 0.032009
 >> iter 70000, loss: 0.031850
   Number of active neurons: 2
 >> iter 71000, loss: 0.031989
 >> iter 72000, loss: 0.031837
 >> iter 73000, loss: 0.032011
 >> iter 74000, loss: 0.031845
 >> iter 75000, loss: 0.032002
 >> iter 76000, loss: 0.031849
 >> iter 77000, loss: 0.031994
 >> iter 78000, loss: 0.031837
 >> iter 79000, loss: 0.031987
 >> iter 80000, loss: 0.031818
   Number of active neurons: 2
 >> iter 81000, loss: 0.031980
 >> iter 82000, loss: 0.031812
 >> iter 83000, loss: 0.031972
 >> iter 84000, loss: 0.031819
 >> iter 85000, loss: 0.031952
 >> iter 86000, loss: 0.031810
 >> iter 87000, loss: 0.031937
 >> iter 88000, loss: 0.031830
 >> iter 89000, loss: 0.031939
 >> iter 90000, loss: 0.031821
   Number of active neurons: 2
 >> iter 91000, loss: 0.031921
 >> iter 92000, loss: 0.031831
 >> iter 93000, loss: 0.031931
 >> iter 94000, loss: 0.031829
 >> iter 95000, loss: 0.031942
 >> iter 96000, loss: 0.031828
 >> iter 97000, loss: 0.031939
 >> iter 98000, loss: 0.031819
 >> iter 99000, loss: 0.031937
 >> iter 100000, loss: 0.031834
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.834634
 >> iter 2000, loss: 4.027145
 >> iter 3000, loss: 1.514576
 >> iter 4000, loss: 0.586464
 >> iter 5000, loss: 0.243571
 >> iter 6000, loss: 0.115379
 >> iter 7000, loss: 0.067544
 >> iter 8000, loss: 0.048224
 >> iter 9000, loss: 0.040969
 >> iter 10000, loss: 0.037135
   Number of active neurons: 2
 >> iter 11000, loss: 0.035725
 >> iter 12000, loss: 0.034328
 >> iter 13000, loss: 0.034097
 >> iter 14000, loss: 0.033304
 >> iter 15000, loss: 0.033433
 >> iter 16000, loss: 0.032791
 >> iter 17000, loss: 0.033002
 >> iter 18000, loss: 0.032428
 >> iter 19000, loss: 0.032723
 >> iter 20000, loss: 0.032248
   Number of active neurons: 2
 >> iter 21000, loss: 0.032567
 >> iter 22000, loss: 0.032130
 >> iter 23000, loss: 0.032471
 >> iter 24000, loss: 0.032042
 >> iter 25000, loss: 0.032402
 >> iter 26000, loss: 0.031966
 >> iter 27000, loss: 0.032343
 >> iter 28000, loss: 0.031905
 >> iter 29000, loss: 0.032286
 >> iter 30000, loss: 0.031874
   Number of active neurons: 2
 >> iter 31000, loss: 0.032250
 >> iter 32000, loss: 0.031841
 >> iter 33000, loss: 0.032211
 >> iter 34000, loss: 0.031838
 >> iter 35000, loss: 0.032172
 >> iter 36000, loss: 0.031818
 >> iter 37000, loss: 0.032149
 >> iter 38000, loss: 0.031807
 >> iter 39000, loss: 0.032112
 >> iter 40000, loss: 0.031831
   Number of active neurons: 2
 >> iter 41000, loss: 0.032094
 >> iter 42000, loss: 0.031800
 >> iter 43000, loss: 0.032071
 >> iter 44000, loss: 0.031812
 >> iter 45000, loss: 0.032068
 >> iter 46000, loss: 0.031794
 >> iter 47000, loss: 0.032065
 >> iter 48000, loss: 0.031787
 >> iter 49000, loss: 0.032069
 >> iter 50000, loss: 0.031777
   Number of active neurons: 2
 >> iter 51000, loss: 0.032054
 >> iter 52000, loss: 0.031797
 >> iter 53000, loss: 0.032032
 >> iter 54000, loss: 0.031816
 >> iter 55000, loss: 0.032037
 >> iter 56000, loss: 0.031819
 >> iter 57000, loss: 0.032025
 >> iter 58000, loss: 0.031822
 >> iter 59000, loss: 0.032025
 >> iter 60000, loss: 0.031824
   Number of active neurons: 2
 >> iter 61000, loss: 0.032062
 >> iter 62000, loss: 0.031824
 >> iter 63000, loss: 0.032040
 >> iter 64000, loss: 0.031830
 >> iter 65000, loss: 0.032029
 >> iter 66000, loss: 0.031835
 >> iter 67000, loss: 0.032026
 >> iter 68000, loss: 0.031851
 >> iter 69000, loss: 0.032005
 >> iter 70000, loss: 0.031846
   Number of active neurons: 2
 >> iter 71000, loss: 0.031986
 >> iter 72000, loss: 0.031834
 >> iter 73000, loss: 0.032009
 >> iter 74000, loss: 0.031844
 >> iter 75000, loss: 0.032001
 >> iter 76000, loss: 0.031847
 >> iter 77000, loss: 0.031993
 >> iter 78000, loss: 0.031836
 >> iter 79000, loss: 0.031986
 >> iter 80000, loss: 0.031818
   Number of active neurons: 2
 >> iter 81000, loss: 0.031979
 >> iter 82000, loss: 0.031811
 >> iter 83000, loss: 0.031972
 >> iter 84000, loss: 0.031820
 >> iter 85000, loss: 0.031952
 >> iter 86000, loss: 0.031809
 >> iter 87000, loss: 0.031937
 >> iter 88000, loss: 0.031830
 >> iter 89000, loss: 0.031940
 >> iter 90000, loss: 0.031822
   Number of active neurons: 2
 >> iter 91000, loss: 0.031921
 >> iter 92000, loss: 0.031831
 >> iter 93000, loss: 0.031931
 >> iter 94000, loss: 0.031828
 >> iter 95000, loss: 0.031941
 >> iter 96000, loss: 0.031828
 >> iter 97000, loss: 0.031939
 >> iter 98000, loss: 0.031819
 >> iter 99000, loss: 0.031937
 >> iter 100000, loss: 0.031836
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.912798
 >> iter 2000, loss: 4.056072
 >> iter 3000, loss: 1.528074
 >> iter 4000, loss: 0.595766
 >> iter 5000, loss: 0.252615
 >> iter 6000, loss: 0.124573
 >> iter 7000, loss: 0.077080
 >> iter 8000, loss: 0.057393
 >> iter 9000, loss: 0.049722
 >> iter 10000, loss: 0.045488
   Number of active neurons: 4
 >> iter 11000, loss: 0.044081
 >> iter 12000, loss: 0.042493
 >> iter 13000, loss: 0.042300
 >> iter 14000, loss: 0.041484
 >> iter 15000, loss: 0.041807
 >> iter 16000, loss: 0.041235
 >> iter 17000, loss: 0.041715
 >> iter 18000, loss: 0.041233
 >> iter 19000, loss: 0.041695
 >> iter 20000, loss: 0.041146
   Number of active neurons: 3
 >> iter 21000, loss: 0.041420
 >> iter 22000, loss: 0.040440
 >> iter 23000, loss: 0.040360
 >> iter 24000, loss: 0.039189
 >> iter 25000, loss: 0.038704
 >> iter 26000, loss: 0.037156
 >> iter 27000, loss: 0.036301
 >> iter 28000, loss: 0.034842
 >> iter 29000, loss: 0.034531
 >> iter 30000, loss: 0.033630
   Number of active neurons: 3
 >> iter 31000, loss: 0.033678
 >> iter 32000, loss: 0.033012
 >> iter 33000, loss: 0.033198
 >> iter 34000, loss: 0.032669
 >> iter 35000, loss: 0.032882
 >> iter 36000, loss: 0.032423
 >> iter 37000, loss: 0.032669
 >> iter 38000, loss: 0.032252
 >> iter 39000, loss: 0.032497
 >> iter 40000, loss: 0.032160
   Number of active neurons: 3
 >> iter 41000, loss: 0.032379
 >> iter 42000, loss: 0.032045
 >> iter 43000, loss: 0.032284
 >> iter 44000, loss: 0.031995
 >> iter 45000, loss: 0.032230
 >> iter 46000, loss: 0.031934
 >> iter 47000, loss: 0.032185
 >> iter 48000, loss: 0.031894
 >> iter 49000, loss: 0.032163
 >> iter 50000, loss: 0.031859
   Number of active neurons: 3
 >> iter 51000, loss: 0.032125
 >> iter 52000, loss: 0.031860
 >> iter 53000, loss: 0.032086
 >> iter 54000, loss: 0.031865
 >> iter 55000, loss: 0.032079
 >> iter 56000, loss: 0.031856
 >> iter 57000, loss: 0.032059
 >> iter 58000, loss: 0.031851
 >> iter 59000, loss: 0.032050
 >> iter 60000, loss: 0.031848
   Number of active neurons: 3
 >> iter 61000, loss: 0.032083
 >> iter 62000, loss: 0.031842
 >> iter 63000, loss: 0.032055
 >> iter 64000, loss: 0.031845
 >> iter 65000, loss: 0.032042
 >> iter 66000, loss: 0.031848
 >> iter 67000, loss: 0.032037
 >> iter 68000, loss: 0.031861
 >> iter 69000, loss: 0.032013
 >> iter 70000, loss: 0.031855
   Number of active neurons: 3
 >> iter 71000, loss: 0.031995
 >> iter 72000, loss: 0.031843
 >> iter 73000, loss: 0.032014
 >> iter 74000, loss: 0.031849
 >> iter 75000, loss: 0.032005
 >> iter 76000, loss: 0.031853
 >> iter 77000, loss: 0.031997
 >> iter 78000, loss: 0.031840
 >> iter 79000, loss: 0.031989
 >> iter 80000, loss: 0.031821
   Number of active neurons: 3
 >> iter 81000, loss: 0.031983
 >> iter 82000, loss: 0.031816
 >> iter 83000, loss: 0.031973
 >> iter 84000, loss: 0.031822
 >> iter 85000, loss: 0.031955
 >> iter 86000, loss: 0.031811
 >> iter 87000, loss: 0.031938
 >> iter 88000, loss: 0.031832
 >> iter 89000, loss: 0.031943
 >> iter 90000, loss: 0.031824
   Number of active neurons: 3
 >> iter 91000, loss: 0.031923
 >> iter 92000, loss: 0.031831
 >> iter 93000, loss: 0.031934
 >> iter 94000, loss: 0.031830
 >> iter 95000, loss: 0.031943
 >> iter 96000, loss: 0.031830
 >> iter 97000, loss: 0.031941
 >> iter 98000, loss: 0.031821
 >> iter 99000, loss: 0.031939
 >> iter 100000, loss: 0.031836
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.037128
 >> iter 2000, loss: 4.100860
 >> iter 3000, loss: 1.543756
 >> iter 4000, loss: 0.601235
 >> iter 5000, loss: 0.254252
 >> iter 6000, loss: 0.124973
 >> iter 7000, loss: 0.077243
 >> iter 8000, loss: 0.058475
 >> iter 9000, loss: 0.051939
 >> iter 10000, loss: 0.048850
   Number of active neurons: 5
 >> iter 11000, loss: 0.048242
 >> iter 12000, loss: 0.047403
 >> iter 13000, loss: 0.047663
 >> iter 14000, loss: 0.047115
 >> iter 15000, loss: 0.047607
 >> iter 16000, loss: 0.046598
 >> iter 17000, loss: 0.046884
 >> iter 18000, loss: 0.046291
 >> iter 19000, loss: 0.046801
 >> iter 20000, loss: 0.046397
   Number of active neurons: 5
 >> iter 21000, loss: 0.046883
 >> iter 22000, loss: 0.046497
 >> iter 23000, loss: 0.046888
 >> iter 24000, loss: 0.046392
 >> iter 25000, loss: 0.046918
 >> iter 26000, loss: 0.046452
 >> iter 27000, loss: 0.046950
 >> iter 28000, loss: 0.046275
 >> iter 29000, loss: 0.046231
 >> iter 30000, loss: 0.045018
   Number of active neurons: 3
 >> iter 31000, loss: 0.044656
 >> iter 32000, loss: 0.043240
 >> iter 33000, loss: 0.042809
 >> iter 34000, loss: 0.041835
 >> iter 35000, loss: 0.041968
 >> iter 36000, loss: 0.041421
 >> iter 37000, loss: 0.041758
 >> iter 38000, loss: 0.041189
 >> iter 39000, loss: 0.041046
 >> iter 40000, loss: 0.040138
   Number of active neurons: 2
 >> iter 41000, loss: 0.039655
 >> iter 42000, loss: 0.038354
 >> iter 43000, loss: 0.037500
 >> iter 44000, loss: 0.035930
 >> iter 45000, loss: 0.035182
 >> iter 46000, loss: 0.034190
 >> iter 47000, loss: 0.033978
 >> iter 48000, loss: 0.033343
 >> iter 49000, loss: 0.033374
 >> iter 50000, loss: 0.032870
   Number of active neurons: 2
 >> iter 51000, loss: 0.032986
 >> iter 52000, loss: 0.032588
 >> iter 53000, loss: 0.032714
 >> iter 54000, loss: 0.032398
 >> iter 55000, loss: 0.032541
 >> iter 56000, loss: 0.032249
 >> iter 57000, loss: 0.032399
 >> iter 58000, loss: 0.032141
 >> iter 59000, loss: 0.032303
 >> iter 60000, loss: 0.032064
   Number of active neurons: 2
 >> iter 61000, loss: 0.032272
 >> iter 62000, loss: 0.032004
 >> iter 63000, loss: 0.032198
 >> iter 64000, loss: 0.031966
 >> iter 65000, loss: 0.032150
 >> iter 66000, loss: 0.031938
 >> iter 67000, loss: 0.032117
 >> iter 68000, loss: 0.031930
 >> iter 69000, loss: 0.032074
 >> iter 70000, loss: 0.031906
   Number of active neurons: 2
 >> iter 71000, loss: 0.032039
 >> iter 72000, loss: 0.031880
 >> iter 73000, loss: 0.032049
 >> iter 74000, loss: 0.031879
 >> iter 75000, loss: 0.032032
 >> iter 76000, loss: 0.031873
 >> iter 77000, loss: 0.032018
 >> iter 78000, loss: 0.031859
 >> iter 79000, loss: 0.032005
 >> iter 80000, loss: 0.031833
   Number of active neurons: 2
 >> iter 81000, loss: 0.031993
 >> iter 82000, loss: 0.031823
 >> iter 83000, loss: 0.031983
 >> iter 84000, loss: 0.031829
 >> iter 85000, loss: 0.031960
 >> iter 86000, loss: 0.031816
 >> iter 87000, loss: 0.031945
 >> iter 88000, loss: 0.031836
 >> iter 89000, loss: 0.031945
 >> iter 90000, loss: 0.031826
   Number of active neurons: 2
 >> iter 91000, loss: 0.031925
 >> iter 92000, loss: 0.031835
 >> iter 93000, loss: 0.031935
 >> iter 94000, loss: 0.031831
 >> iter 95000, loss: 0.031944
 >> iter 96000, loss: 0.031830
 >> iter 97000, loss: 0.031939
 >> iter 98000, loss: 0.031821
 >> iter 99000, loss: 0.031939
 >> iter 100000, loss: 0.031837
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.869513
 >> iter 2000, loss: 4.039757
 >> iter 3000, loss: 1.520791
 >> iter 4000, loss: 0.589594
 >> iter 5000, loss: 0.245776
 >> iter 6000, loss: 0.117305
 >> iter 7000, loss: 0.070155
 >> iter 8000, loss: 0.051851
 >> iter 9000, loss: 0.045566
 >> iter 10000, loss: 0.042515
   Number of active neurons: 3
 >> iter 11000, loss: 0.041934
 >> iter 12000, loss: 0.040910
 >> iter 13000, loss: 0.040871
 >> iter 14000, loss: 0.040243
 >> iter 15000, loss: 0.040596
 >> iter 16000, loss: 0.040059
 >> iter 17000, loss: 0.040505
 >> iter 18000, loss: 0.040092
 >> iter 19000, loss: 0.040618
 >> iter 20000, loss: 0.040189
   Number of active neurons: 3
 >> iter 21000, loss: 0.040622
 >> iter 22000, loss: 0.040208
 >> iter 23000, loss: 0.040696
 >> iter 24000, loss: 0.040319
 >> iter 25000, loss: 0.040859
 >> iter 26000, loss: 0.040474
 >> iter 27000, loss: 0.041047
 >> iter 28000, loss: 0.040646
 >> iter 29000, loss: 0.041219
 >> iter 30000, loss: 0.040821
   Number of active neurons: 3
 >> iter 31000, loss: 0.041355
 >> iter 32000, loss: 0.040628
 >> iter 33000, loss: 0.040618
 >> iter 34000, loss: 0.039695
 >> iter 35000, loss: 0.039314
 >> iter 36000, loss: 0.038007
 >> iter 37000, loss: 0.037224
 >> iter 38000, loss: 0.035633
 >> iter 39000, loss: 0.034998
 >> iter 40000, loss: 0.034053
   Number of active neurons: 2
 >> iter 41000, loss: 0.033869
 >> iter 42000, loss: 0.033244
 >> iter 43000, loss: 0.033279
 >> iter 44000, loss: 0.032823
 >> iter 45000, loss: 0.032931
 >> iter 46000, loss: 0.032528
 >> iter 47000, loss: 0.032696
 >> iter 48000, loss: 0.032325
 >> iter 49000, loss: 0.032538
 >> iter 50000, loss: 0.032176
   Number of active neurons: 2
 >> iter 51000, loss: 0.032399
 >> iter 52000, loss: 0.032093
 >> iter 53000, loss: 0.032291
 >> iter 54000, loss: 0.032037
 >> iter 55000, loss: 0.032232
 >> iter 56000, loss: 0.031986
 >> iter 57000, loss: 0.032171
 >> iter 58000, loss: 0.031947
 >> iter 59000, loss: 0.032137
 >> iter 60000, loss: 0.031920
   Number of active neurons: 2
 >> iter 61000, loss: 0.032147
 >> iter 62000, loss: 0.031896
 >> iter 63000, loss: 0.032105
 >> iter 64000, loss: 0.031886
 >> iter 65000, loss: 0.032079
 >> iter 66000, loss: 0.031876
 >> iter 67000, loss: 0.032063
 >> iter 68000, loss: 0.031884
 >> iter 69000, loss: 0.032035
 >> iter 70000, loss: 0.031872
   Number of active neurons: 2
 >> iter 71000, loss: 0.032009
 >> iter 72000, loss: 0.031853
 >> iter 73000, loss: 0.032026
 >> iter 74000, loss: 0.031859
 >> iter 75000, loss: 0.032013
 >> iter 76000, loss: 0.031859
 >> iter 77000, loss: 0.032003
 >> iter 78000, loss: 0.031845
 >> iter 79000, loss: 0.031994
 >> iter 80000, loss: 0.031824
   Number of active neurons: 2
 >> iter 81000, loss: 0.031985
 >> iter 82000, loss: 0.031817
 >> iter 83000, loss: 0.031977
 >> iter 84000, loss: 0.031823
 >> iter 85000, loss: 0.031956
 >> iter 86000, loss: 0.031813
 >> iter 87000, loss: 0.031940
 >> iter 88000, loss: 0.031832
 >> iter 89000, loss: 0.031942
 >> iter 90000, loss: 0.031824
   Number of active neurons: 2
 >> iter 91000, loss: 0.031922
 >> iter 92000, loss: 0.031832
 >> iter 93000, loss: 0.031933
 >> iter 94000, loss: 0.031830
 >> iter 95000, loss: 0.031943
 >> iter 96000, loss: 0.031829
 >> iter 97000, loss: 0.031940
 >> iter 98000, loss: 0.031821
 >> iter 99000, loss: 0.031938
 >> iter 100000, loss: 0.031835
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.888870
 >> iter 2000, loss: 4.044878
 >> iter 3000, loss: 1.520690
 >> iter 4000, loss: 0.590423
 >> iter 5000, loss: 0.248952
 >> iter 6000, loss: 0.122384
 >> iter 7000, loss: 0.076338
 >> iter 8000, loss: 0.058630
 >> iter 9000, loss: 0.052858
 >> iter 10000, loss: 0.049976
   Number of active neurons: 3
 >> iter 11000, loss: 0.049448
 >> iter 12000, loss: 0.047781
 >> iter 13000, loss: 0.047191
 >> iter 14000, loss: 0.045522
 >> iter 15000, loss: 0.044485
 >> iter 16000, loss: 0.042346
 >> iter 17000, loss: 0.041325
 >> iter 18000, loss: 0.039314
 >> iter 19000, loss: 0.038252
 >> iter 20000, loss: 0.036323
   Number of active neurons: 2
 >> iter 21000, loss: 0.035567
 >> iter 22000, loss: 0.034371
 >> iter 23000, loss: 0.034220
 >> iter 24000, loss: 0.033435
 >> iter 25000, loss: 0.033553
 >> iter 26000, loss: 0.032916
 >> iter 27000, loss: 0.033149
 >> iter 28000, loss: 0.032582
 >> iter 29000, loss: 0.032866
 >> iter 30000, loss: 0.032365
   Number of active neurons: 2
 >> iter 31000, loss: 0.032676
 >> iter 32000, loss: 0.032203
 >> iter 33000, loss: 0.032524
 >> iter 34000, loss: 0.032104
 >> iter 35000, loss: 0.032404
 >> iter 36000, loss: 0.032017
 >> iter 37000, loss: 0.032322
 >> iter 38000, loss: 0.031955
 >> iter 39000, loss: 0.032244
 >> iter 40000, loss: 0.031943
   Number of active neurons: 2
 >> iter 41000, loss: 0.032192
 >> iter 42000, loss: 0.031883
 >> iter 43000, loss: 0.032145
 >> iter 44000, loss: 0.031874
 >> iter 45000, loss: 0.032125
 >> iter 46000, loss: 0.031845
 >> iter 47000, loss: 0.032106
 >> iter 48000, loss: 0.031824
 >> iter 49000, loss: 0.032102
 >> iter 50000, loss: 0.031805
   Number of active neurons: 2
 >> iter 51000, loss: 0.032079
 >> iter 52000, loss: 0.031819
 >> iter 53000, loss: 0.032050
 >> iter 54000, loss: 0.031832
 >> iter 55000, loss: 0.032053
 >> iter 56000, loss: 0.031832
 >> iter 57000, loss: 0.032037
 >> iter 58000, loss: 0.031831
 >> iter 59000, loss: 0.032034
 >> iter 60000, loss: 0.031832
   Number of active neurons: 2
 >> iter 61000, loss: 0.032070
 >> iter 62000, loss: 0.031829
 >> iter 63000, loss: 0.032045
 >> iter 64000, loss: 0.031835
 >> iter 65000, loss: 0.032034
 >> iter 66000, loss: 0.031837
 >> iter 67000, loss: 0.032029
 >> iter 68000, loss: 0.031854
 >> iter 69000, loss: 0.032009
 >> iter 70000, loss: 0.031849
   Number of active neurons: 2
 >> iter 71000, loss: 0.031989
 >> iter 72000, loss: 0.031836
 >> iter 73000, loss: 0.032010
 >> iter 74000, loss: 0.031844
 >> iter 75000, loss: 0.032002
 >> iter 76000, loss: 0.031848
 >> iter 77000, loss: 0.031994
 >> iter 78000, loss: 0.031837
 >> iter 79000, loss: 0.031988
 >> iter 80000, loss: 0.031819
   Number of active neurons: 2
 >> iter 81000, loss: 0.031980
 >> iter 82000, loss: 0.031812
 >> iter 83000, loss: 0.031973
 >> iter 84000, loss: 0.031819
 >> iter 85000, loss: 0.031951
 >> iter 86000, loss: 0.031808
 >> iter 87000, loss: 0.031937
 >> iter 88000, loss: 0.031830
 >> iter 89000, loss: 0.031940
 >> iter 90000, loss: 0.031822
   Number of active neurons: 2
 >> iter 91000, loss: 0.031922
 >> iter 92000, loss: 0.031832
 >> iter 93000, loss: 0.031931
 >> iter 94000, loss: 0.031828
 >> iter 95000, loss: 0.031941
 >> iter 96000, loss: 0.031827
 >> iter 97000, loss: 0.031939
 >> iter 98000, loss: 0.031819
 >> iter 99000, loss: 0.031937
 >> iter 100000, loss: 0.031836
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.915612
 >> iter 2000, loss: 4.057376
 >> iter 3000, loss: 1.526604
 >> iter 4000, loss: 0.591637
 >> iter 5000, loss: 0.247358
 >> iter 6000, loss: 0.119352
 >> iter 7000, loss: 0.072716
 >> iter 8000, loss: 0.054221
 >> iter 9000, loss: 0.047567
 >> iter 10000, loss: 0.043967
   Number of active neurons: 4
 >> iter 11000, loss: 0.043032
 >> iter 12000, loss: 0.041952
 >> iter 13000, loss: 0.042193
 >> iter 14000, loss: 0.041412
 >> iter 15000, loss: 0.041274
 >> iter 16000, loss: 0.040087
 >> iter 17000, loss: 0.039521
 >> iter 18000, loss: 0.037896
 >> iter 19000, loss: 0.036976
 >> iter 20000, loss: 0.035355
   Number of active neurons: 3
 >> iter 21000, loss: 0.034870
 >> iter 22000, loss: 0.033880
 >> iter 23000, loss: 0.033850
 >> iter 24000, loss: 0.033153
 >> iter 25000, loss: 0.033325
 >> iter 26000, loss: 0.032734
 >> iter 27000, loss: 0.032995
 >> iter 28000, loss: 0.032455
 >> iter 29000, loss: 0.032756
 >> iter 30000, loss: 0.032274
   Number of active neurons: 3
 >> iter 31000, loss: 0.032596
 >> iter 32000, loss: 0.032137
 >> iter 33000, loss: 0.032466
 >> iter 34000, loss: 0.032057
 >> iter 35000, loss: 0.032361
 >> iter 36000, loss: 0.031984
 >> iter 37000, loss: 0.032291
 >> iter 38000, loss: 0.031931
 >> iter 39000, loss: 0.032221
 >> iter 40000, loss: 0.031926
   Number of active neurons: 3
 >> iter 41000, loss: 0.032178
 >> iter 42000, loss: 0.031872
 >> iter 43000, loss: 0.032135
 >> iter 44000, loss: 0.031866
 >> iter 45000, loss: 0.032116
 >> iter 46000, loss: 0.031837
 >> iter 47000, loss: 0.032101
 >> iter 48000, loss: 0.031821
 >> iter 49000, loss: 0.032099
 >> iter 50000, loss: 0.031804
   Number of active neurons: 3
 >> iter 51000, loss: 0.032076
 >> iter 52000, loss: 0.031817
 >> iter 53000, loss: 0.032050
 >> iter 54000, loss: 0.031833
 >> iter 55000, loss: 0.032051
 >> iter 56000, loss: 0.031832
 >> iter 57000, loss: 0.032036
 >> iter 58000, loss: 0.031833
 >> iter 59000, loss: 0.032033
 >> iter 60000, loss: 0.031832
   Number of active neurons: 3
 >> iter 61000, loss: 0.032071
 >> iter 62000, loss: 0.031831
 >> iter 63000, loss: 0.032046
 >> iter 64000, loss: 0.031837
 >> iter 65000, loss: 0.032035
 >> iter 66000, loss: 0.031840
 >> iter 67000, loss: 0.032030
 >> iter 68000, loss: 0.031856
 >> iter 69000, loss: 0.032010
 >> iter 70000, loss: 0.031852
   Number of active neurons: 3
 >> iter 71000, loss: 0.031991
 >> iter 72000, loss: 0.031838
 >> iter 73000, loss: 0.032012
 >> iter 74000, loss: 0.031846
 >> iter 75000, loss: 0.032003
 >> iter 76000, loss: 0.031849
 >> iter 77000, loss: 0.031997
 >> iter 78000, loss: 0.031840
 >> iter 79000, loss: 0.031989
 >> iter 80000, loss: 0.031821
   Number of active neurons: 3
 >> iter 81000, loss: 0.031981
 >> iter 82000, loss: 0.031812
 >> iter 83000, loss: 0.031974
 >> iter 84000, loss: 0.031821
 >> iter 85000, loss: 0.031953
 >> iter 86000, loss: 0.031810
 >> iter 87000, loss: 0.031938
 >> iter 88000, loss: 0.031832
 >> iter 89000, loss: 0.031941
 >> iter 90000, loss: 0.031822
   Number of active neurons: 3
 >> iter 91000, loss: 0.031923
 >> iter 92000, loss: 0.031832
 >> iter 93000, loss: 0.031932
 >> iter 94000, loss: 0.031829
 >> iter 95000, loss: 0.031943
 >> iter 96000, loss: 0.031829
 >> iter 97000, loss: 0.031940
 >> iter 98000, loss: 0.031820
 >> iter 99000, loss: 0.031939
 >> iter 100000, loss: 0.031837
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.851203
 >> iter 2000, loss: 4.041418
 >> iter 3000, loss: 1.525110
 >> iter 4000, loss: 0.593858
 >> iter 5000, loss: 0.249230
 >> iter 6000, loss: 0.119497
 >> iter 7000, loss: 0.070752
 >> iter 8000, loss: 0.050445
 >> iter 9000, loss: 0.042170
 >> iter 10000, loss: 0.037574
   Number of active neurons: 4
 >> iter 11000, loss: 0.035758
 >> iter 12000, loss: 0.034237
 >> iter 13000, loss: 0.034030
 >> iter 14000, loss: 0.033304
 >> iter 15000, loss: 0.033498
 >> iter 16000, loss: 0.032900
 >> iter 17000, loss: 0.033139
 >> iter 18000, loss: 0.032543
 >> iter 19000, loss: 0.032822
 >> iter 20000, loss: 0.032324
   Number of active neurons: 4
 >> iter 21000, loss: 0.032632
 >> iter 22000, loss: 0.032184
 >> iter 23000, loss: 0.032519
 >> iter 24000, loss: 0.032085
 >> iter 25000, loss: 0.032442
 >> iter 26000, loss: 0.032002
 >> iter 27000, loss: 0.032375
 >> iter 28000, loss: 0.031936
 >> iter 29000, loss: 0.032313
 >> iter 30000, loss: 0.031900
   Number of active neurons: 4
 >> iter 31000, loss: 0.032272
 >> iter 32000, loss: 0.031862
 >> iter 33000, loss: 0.032227
 >> iter 34000, loss: 0.031856
 >> iter 35000, loss: 0.032187
 >> iter 36000, loss: 0.031833
 >> iter 37000, loss: 0.032160
 >> iter 38000, loss: 0.031819
 >> iter 39000, loss: 0.032123
 >> iter 40000, loss: 0.031843
   Number of active neurons: 4
 >> iter 41000, loss: 0.032102
 >> iter 42000, loss: 0.031808
 >> iter 43000, loss: 0.032078
 >> iter 44000, loss: 0.031818
 >> iter 45000, loss: 0.032075
 >> iter 46000, loss: 0.031801
 >> iter 47000, loss: 0.032069
 >> iter 48000, loss: 0.031793
 >> iter 49000, loss: 0.032074
 >> iter 50000, loss: 0.031783
   Number of active neurons: 4
 >> iter 51000, loss: 0.032056
 >> iter 52000, loss: 0.031802
 >> iter 53000, loss: 0.032035
 >> iter 54000, loss: 0.031820
 >> iter 55000, loss: 0.032041
 >> iter 56000, loss: 0.031824
 >> iter 57000, loss: 0.032027
 >> iter 58000, loss: 0.031826
 >> iter 59000, loss: 0.032027
 >> iter 60000, loss: 0.031828
   Number of active neurons: 4
 >> iter 61000, loss: 0.032065
 >> iter 62000, loss: 0.031828
 >> iter 63000, loss: 0.032042
 >> iter 64000, loss: 0.031833
 >> iter 65000, loss: 0.032031
 >> iter 66000, loss: 0.031838
 >> iter 67000, loss: 0.032029
 >> iter 68000, loss: 0.031855
 >> iter 69000, loss: 0.032007
 >> iter 70000, loss: 0.031849
   Number of active neurons: 4
 >> iter 71000, loss: 0.031989
 >> iter 72000, loss: 0.031837
 >> iter 73000, loss: 0.032011
 >> iter 74000, loss: 0.031848
 >> iter 75000, loss: 0.032002
 >> iter 76000, loss: 0.031849
 >> iter 77000, loss: 0.031994
 >> iter 78000, loss: 0.031839
 >> iter 79000, loss: 0.031988
 >> iter 80000, loss: 0.031819
   Number of active neurons: 4
 >> iter 81000, loss: 0.031980
 >> iter 82000, loss: 0.031813
 >> iter 83000, loss: 0.031974
 >> iter 84000, loss: 0.031821
 >> iter 85000, loss: 0.031953
 >> iter 86000, loss: 0.031810
 >> iter 87000, loss: 0.031938
 >> iter 88000, loss: 0.031832
 >> iter 89000, loss: 0.031942
 >> iter 90000, loss: 0.031823
   Number of active neurons: 4
 >> iter 91000, loss: 0.031922
 >> iter 92000, loss: 0.031833
 >> iter 93000, loss: 0.031932
 >> iter 94000, loss: 0.031829
 >> iter 95000, loss: 0.031941
 >> iter 96000, loss: 0.031829
 >> iter 97000, loss: 0.031940
 >> iter 98000, loss: 0.031821
 >> iter 99000, loss: 0.031938
 >> iter 100000, loss: 0.031836
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.945486
 >> iter 2000, loss: 4.065578
 >> iter 3000, loss: 1.527889
 >> iter 4000, loss: 0.591229
 >> iter 5000, loss: 0.246167
 >> iter 6000, loss: 0.118034
 >> iter 7000, loss: 0.071321
 >> iter 8000, loss: 0.053026
 >> iter 9000, loss: 0.046074
 >> iter 10000, loss: 0.041919
   Number of active neurons: 2
 >> iter 11000, loss: 0.039857
 >> iter 12000, loss: 0.037407
 >> iter 13000, loss: 0.036287
 >> iter 14000, loss: 0.034845
 >> iter 15000, loss: 0.034564
 >> iter 16000, loss: 0.033616
 >> iter 17000, loss: 0.033624
 >> iter 18000, loss: 0.032913
 >> iter 19000, loss: 0.033117
 >> iter 20000, loss: 0.032570
   Number of active neurons: 2
 >> iter 21000, loss: 0.032839
 >> iter 22000, loss: 0.032358
 >> iter 23000, loss: 0.032664
 >> iter 24000, loss: 0.032206
 >> iter 25000, loss: 0.032544
 >> iter 26000, loss: 0.032086
 >> iter 27000, loss: 0.032446
 >> iter 28000, loss: 0.031994
 >> iter 29000, loss: 0.032363
 >> iter 30000, loss: 0.031940
   Number of active neurons: 2
 >> iter 31000, loss: 0.032308
 >> iter 32000, loss: 0.031890
 >> iter 33000, loss: 0.032253
 >> iter 34000, loss: 0.031875
 >> iter 35000, loss: 0.032205
 >> iter 36000, loss: 0.031846
 >> iter 37000, loss: 0.032174
 >> iter 38000, loss: 0.031828
 >> iter 39000, loss: 0.032133
 >> iter 40000, loss: 0.031848
   Number of active neurons: 2
 >> iter 41000, loss: 0.032109
 >> iter 42000, loss: 0.031811
 >> iter 43000, loss: 0.032081
 >> iter 44000, loss: 0.031821
 >> iter 45000, loss: 0.032077
 >> iter 46000, loss: 0.031802
 >> iter 47000, loss: 0.032071
 >> iter 48000, loss: 0.031792
 >> iter 49000, loss: 0.032075
 >> iter 50000, loss: 0.031782
   Number of active neurons: 2
 >> iter 51000, loss: 0.032058
 >> iter 52000, loss: 0.031800
 >> iter 53000, loss: 0.032034
 >> iter 54000, loss: 0.031818
 >> iter 55000, loss: 0.032040
 >> iter 56000, loss: 0.031821
 >> iter 57000, loss: 0.032026
 >> iter 58000, loss: 0.031823
 >> iter 59000, loss: 0.032026
 >> iter 60000, loss: 0.031825
   Number of active neurons: 2
 >> iter 61000, loss: 0.032064
 >> iter 62000, loss: 0.031824
 >> iter 63000, loss: 0.032041
 >> iter 64000, loss: 0.031831
 >> iter 65000, loss: 0.032030
 >> iter 66000, loss: 0.031836
 >> iter 67000, loss: 0.032027
 >> iter 68000, loss: 0.031852
 >> iter 69000, loss: 0.032005
 >> iter 70000, loss: 0.031847
   Number of active neurons: 2
 >> iter 71000, loss: 0.031987
 >> iter 72000, loss: 0.031834
 >> iter 73000, loss: 0.032008
 >> iter 74000, loss: 0.031844
 >> iter 75000, loss: 0.032001
 >> iter 76000, loss: 0.031847
 >> iter 77000, loss: 0.031993
 >> iter 78000, loss: 0.031836
 >> iter 79000, loss: 0.031986
 >> iter 80000, loss: 0.031817
   Number of active neurons: 2
 >> iter 81000, loss: 0.031979
 >> iter 82000, loss: 0.031811
 >> iter 83000, loss: 0.031972
 >> iter 84000, loss: 0.031819
 >> iter 85000, loss: 0.031951
 >> iter 86000, loss: 0.031809
 >> iter 87000, loss: 0.031937
 >> iter 88000, loss: 0.031830
 >> iter 89000, loss: 0.031940
 >> iter 90000, loss: 0.031822
   Number of active neurons: 2
 >> iter 91000, loss: 0.031921
 >> iter 92000, loss: 0.031831
 >> iter 93000, loss: 0.031931
 >> iter 94000, loss: 0.031828
 >> iter 95000, loss: 0.031941
 >> iter 96000, loss: 0.031827
 >> iter 97000, loss: 0.031939
 >> iter 98000, loss: 0.031819
 >> iter 99000, loss: 0.031936
 >> iter 100000, loss: 0.031835
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 10.895499
 >> iter 2000, loss: 4.050652
 >> iter 3000, loss: 1.523866
 >> iter 4000, loss: 0.589823
 >> iter 5000, loss: 0.245027
 >> iter 6000, loss: 0.116252
 >> iter 7000, loss: 0.068882
 >> iter 8000, loss: 0.049884
 >> iter 9000, loss: 0.042404
 >> iter 10000, loss: 0.038058
   Number of active neurons: 2
 >> iter 11000, loss: 0.036334
 >> iter 12000, loss: 0.034730
 >> iter 13000, loss: 0.034395
 >> iter 14000, loss: 0.033524
 >> iter 15000, loss: 0.033613
 >> iter 16000, loss: 0.032927
 >> iter 17000, loss: 0.033115
 >> iter 18000, loss: 0.032523
 >> iter 19000, loss: 0.032806
 >> iter 20000, loss: 0.032319
   Number of active neurons: 2
 >> iter 21000, loss: 0.032631
 >> iter 22000, loss: 0.032185
 >> iter 23000, loss: 0.032517
 >> iter 24000, loss: 0.032082
 >> iter 25000, loss: 0.032438
 >> iter 26000, loss: 0.031998
 >> iter 27000, loss: 0.032370
 >> iter 28000, loss: 0.031928
 >> iter 29000, loss: 0.032306
 >> iter 30000, loss: 0.031892
   Number of active neurons: 2
 >> iter 31000, loss: 0.032267
 >> iter 32000, loss: 0.031854
 >> iter 33000, loss: 0.032222
 >> iter 34000, loss: 0.031847
 >> iter 35000, loss: 0.032181
 >> iter 36000, loss: 0.031826
 >> iter 37000, loss: 0.032155
 >> iter 38000, loss: 0.031813
 >> iter 39000, loss: 0.032118
 >> iter 40000, loss: 0.031836
   Number of active neurons: 2
 >> iter 41000, loss: 0.032098
 >> iter 42000, loss: 0.031802
 >> iter 43000, loss: 0.032075
 >> iter 44000, loss: 0.031814
 >> iter 45000, loss: 0.032071
 >> iter 46000, loss: 0.031797
 >> iter 47000, loss: 0.032066
 >> iter 48000, loss: 0.031789
 >> iter 49000, loss: 0.032071
 >> iter 50000, loss: 0.031779
   Number of active neurons: 2
 >> iter 51000, loss: 0.032055
 >> iter 52000, loss: 0.031799
 >> iter 53000, loss: 0.032033
 >> iter 54000, loss: 0.031817
 >> iter 55000, loss: 0.032038
 >> iter 56000, loss: 0.031820
 >> iter 57000, loss: 0.032025
 >> iter 58000, loss: 0.031822
 >> iter 59000, loss: 0.032025
 >> iter 60000, loss: 0.031825
   Number of active neurons: 2
 >> iter 61000, loss: 0.032063
 >> iter 62000, loss: 0.031824
 >> iter 63000, loss: 0.032040
 >> iter 64000, loss: 0.031830
 >> iter 65000, loss: 0.032030
 >> iter 66000, loss: 0.031835
 >> iter 67000, loss: 0.032026
 >> iter 68000, loss: 0.031852
 >> iter 69000, loss: 0.032005
 >> iter 70000, loss: 0.031846
   Number of active neurons: 2
 >> iter 71000, loss: 0.031986
 >> iter 72000, loss: 0.031834
 >> iter 73000, loss: 0.032008
 >> iter 74000, loss: 0.031844
 >> iter 75000, loss: 0.032001
 >> iter 76000, loss: 0.031847
 >> iter 77000, loss: 0.031993
 >> iter 78000, loss: 0.031837
 >> iter 79000, loss: 0.031986
 >> iter 80000, loss: 0.031817
   Number of active neurons: 2
 >> iter 81000, loss: 0.031978
 >> iter 82000, loss: 0.031810
 >> iter 83000, loss: 0.031972
 >> iter 84000, loss: 0.031819
 >> iter 85000, loss: 0.031952
 >> iter 86000, loss: 0.031809
 >> iter 87000, loss: 0.031937
 >> iter 88000, loss: 0.031830
 >> iter 89000, loss: 0.031940
 >> iter 90000, loss: 0.031821
   Number of active neurons: 2
 >> iter 91000, loss: 0.031920
 >> iter 92000, loss: 0.031831
 >> iter 93000, loss: 0.031931
 >> iter 94000, loss: 0.031829
 >> iter 95000, loss: 0.031941
 >> iter 96000, loss: 0.031827
 >> iter 97000, loss: 0.031939
 >> iter 98000, loss: 0.031819
 >> iter 99000, loss: 0.031936
 >> iter 100000, loss: 0.031835
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.015126
 >> iter 2000, loss: 4.095110
 >> iter 3000, loss: 1.540099
 >> iter 4000, loss: 0.597571
 >> iter 5000, loss: 0.251533
 >> iter 6000, loss: 0.123618
 >> iter 7000, loss: 0.077136
 >> iter 8000, loss: 0.059011
 >> iter 9000, loss: 0.053076
 >> iter 10000, loss: 0.050156
   Number of active neurons: 3
 >> iter 11000, loss: 0.049839
 >> iter 12000, loss: 0.048741
 >> iter 13000, loss: 0.048397
 >> iter 14000, loss: 0.046729
 >> iter 15000, loss: 0.045687
 >> iter 16000, loss: 0.043380
 >> iter 17000, loss: 0.041726
 >> iter 18000, loss: 0.039135
 >> iter 19000, loss: 0.037613
 >> iter 20000, loss: 0.035715
   Number of active neurons: 2
 >> iter 21000, loss: 0.035126
 >> iter 22000, loss: 0.034068
 >> iter 23000, loss: 0.034014
 >> iter 24000, loss: 0.033286
 >> iter 25000, loss: 0.033443
 >> iter 26000, loss: 0.032832
 >> iter 27000, loss: 0.033084
 >> iter 28000, loss: 0.032528
 >> iter 29000, loss: 0.032824
 >> iter 30000, loss: 0.032328
   Number of active neurons: 2
 >> iter 31000, loss: 0.032643
 >> iter 32000, loss: 0.032175
 >> iter 33000, loss: 0.032501
 >> iter 34000, loss: 0.032087
 >> iter 35000, loss: 0.032389
 >> iter 36000, loss: 0.032004
 >> iter 37000, loss: 0.032311
 >> iter 38000, loss: 0.031946
 >> iter 39000, loss: 0.032235
 >> iter 40000, loss: 0.031937
   Number of active neurons: 2
 >> iter 41000, loss: 0.032187
 >> iter 42000, loss: 0.031879
 >> iter 43000, loss: 0.032141
 >> iter 44000, loss: 0.031872
 >> iter 45000, loss: 0.032123
 >> iter 46000, loss: 0.031840
 >> iter 47000, loss: 0.032105
 >> iter 48000, loss: 0.031823
 >> iter 49000, loss: 0.032100
 >> iter 50000, loss: 0.031804
   Number of active neurons: 2
 >> iter 51000, loss: 0.032077
 >> iter 52000, loss: 0.031817
 >> iter 53000, loss: 0.032051
 >> iter 54000, loss: 0.031832
 >> iter 55000, loss: 0.032052
 >> iter 56000, loss: 0.031832
 >> iter 57000, loss: 0.032035
 >> iter 58000, loss: 0.031831
 >> iter 59000, loss: 0.032034
 >> iter 60000, loss: 0.031831
   Number of active neurons: 2
 >> iter 61000, loss: 0.032069
 >> iter 62000, loss: 0.031829
 >> iter 63000, loss: 0.032045
 >> iter 64000, loss: 0.031835
 >> iter 65000, loss: 0.032033
 >> iter 66000, loss: 0.031838
 >> iter 67000, loss: 0.032029
 >> iter 68000, loss: 0.031854
 >> iter 69000, loss: 0.032008
 >> iter 70000, loss: 0.031849
   Number of active neurons: 2
 >> iter 71000, loss: 0.031989
 >> iter 72000, loss: 0.031836
 >> iter 73000, loss: 0.032010
 >> iter 74000, loss: 0.031844
 >> iter 75000, loss: 0.032002
 >> iter 76000, loss: 0.031847
 >> iter 77000, loss: 0.031994
 >> iter 78000, loss: 0.031836
 >> iter 79000, loss: 0.031987
 >> iter 80000, loss: 0.031818
   Number of active neurons: 2
 >> iter 81000, loss: 0.031979
 >> iter 82000, loss: 0.031811
 >> iter 83000, loss: 0.031973
 >> iter 84000, loss: 0.031820
 >> iter 85000, loss: 0.031952
 >> iter 86000, loss: 0.031809
 >> iter 87000, loss: 0.031938
 >> iter 88000, loss: 0.031830
 >> iter 89000, loss: 0.031939
 >> iter 90000, loss: 0.031821
   Number of active neurons: 2
 >> iter 91000, loss: 0.031922
 >> iter 92000, loss: 0.031831
 >> iter 93000, loss: 0.031932
 >> iter 94000, loss: 0.031829
 >> iter 95000, loss: 0.031942
 >> iter 96000, loss: 0.031827
 >> iter 97000, loss: 0.031939
 >> iter 98000, loss: 0.031819
 >> iter 99000, loss: 0.031937
 >> iter 100000, loss: 0.031835
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.960868
 >> iter 2000, loss: 4.075832
 >> iter 3000, loss: 1.532666
 >> iter 4000, loss: 0.594137
 >> iter 5000, loss: 0.249224
 >> iter 6000, loss: 0.121074
 >> iter 7000, loss: 0.073782
 >> iter 8000, loss: 0.055082
 >> iter 9000, loss: 0.048507
 >> iter 10000, loss: 0.045090
   Number of active neurons: 4
 >> iter 11000, loss: 0.043861
 >> iter 12000, loss: 0.042346
 >> iter 13000, loss: 0.042063
 >> iter 14000, loss: 0.040900
 >> iter 15000, loss: 0.041126
 >> iter 16000, loss: 0.040544
 >> iter 17000, loss: 0.041049
 >> iter 18000, loss: 0.040621
 >> iter 19000, loss: 0.041166
 >> iter 20000, loss: 0.040725
   Number of active neurons: 4
 >> iter 21000, loss: 0.041177
 >> iter 22000, loss: 0.040740
 >> iter 23000, loss: 0.041249
 >> iter 24000, loss: 0.040840
 >> iter 25000, loss: 0.041367
 >> iter 26000, loss: 0.040737
 >> iter 27000, loss: 0.040770
 >> iter 28000, loss: 0.039800
 >> iter 29000, loss: 0.039580
 >> iter 30000, loss: 0.038244
   Number of active neurons: 3
 >> iter 31000, loss: 0.037603
 >> iter 32000, loss: 0.035915
 >> iter 33000, loss: 0.035269
 >> iter 34000, loss: 0.034166
 >> iter 35000, loss: 0.034014
 >> iter 36000, loss: 0.033305
 >> iter 37000, loss: 0.033381
 >> iter 38000, loss: 0.032838
 >> iter 39000, loss: 0.032990
 >> iter 40000, loss: 0.032576
   Number of active neurons: 3
 >> iter 41000, loss: 0.032733
 >> iter 42000, loss: 0.032345
 >> iter 43000, loss: 0.032543
 >> iter 44000, loss: 0.032215
 >> iter 45000, loss: 0.032421
 >> iter 46000, loss: 0.032096
 >> iter 47000, loss: 0.032325
 >> iter 48000, loss: 0.032013
 >> iter 49000, loss: 0.032267
 >> iter 50000, loss: 0.031947
   Number of active neurons: 3
 >> iter 51000, loss: 0.032203
 >> iter 52000, loss: 0.031928
 >> iter 53000, loss: 0.032145
 >> iter 54000, loss: 0.031915
 >> iter 55000, loss: 0.032125
 >> iter 56000, loss: 0.031896
 >> iter 57000, loss: 0.032092
 >> iter 58000, loss: 0.031881
 >> iter 59000, loss: 0.032076
 >> iter 60000, loss: 0.031870
   Number of active neurons: 3
 >> iter 61000, loss: 0.032102
 >> iter 62000, loss: 0.031859
 >> iter 63000, loss: 0.032072
 >> iter 64000, loss: 0.031860
 >> iter 65000, loss: 0.032054
 >> iter 66000, loss: 0.031857
 >> iter 67000, loss: 0.032046
 >> iter 68000, loss: 0.031870
 >> iter 69000, loss: 0.032022
 >> iter 70000, loss: 0.031862
   Number of active neurons: 3
 >> iter 71000, loss: 0.032000
 >> iter 72000, loss: 0.031847
 >> iter 73000, loss: 0.032020
 >> iter 74000, loss: 0.031854
 >> iter 75000, loss: 0.032010
 >> iter 76000, loss: 0.031854
 >> iter 77000, loss: 0.032001
 >> iter 78000, loss: 0.031843
 >> iter 79000, loss: 0.031992
 >> iter 80000, loss: 0.031823
   Number of active neurons: 3
 >> iter 81000, loss: 0.031985
 >> iter 82000, loss: 0.031817
 >> iter 83000, loss: 0.031977
 >> iter 84000, loss: 0.031823
 >> iter 85000, loss: 0.031957
 >> iter 86000, loss: 0.031812
 >> iter 87000, loss: 0.031940
 >> iter 88000, loss: 0.031833
 >> iter 89000, loss: 0.031943
 >> iter 90000, loss: 0.031825
   Number of active neurons: 3
 >> iter 91000, loss: 0.031925
 >> iter 92000, loss: 0.031833
 >> iter 93000, loss: 0.031934
 >> iter 94000, loss: 0.031831
 >> iter 95000, loss: 0.031944
 >> iter 96000, loss: 0.031829
 >> iter 97000, loss: 0.031941
 >> iter 98000, loss: 0.031820
 >> iter 99000, loss: 0.031939
 >> iter 100000, loss: 0.031837
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.846175
 >> iter 2000, loss: 4.029301
 >> iter 3000, loss: 1.514032
 >> iter 4000, loss: 0.585399
 >> iter 5000, loss: 0.243477
 >> iter 6000, loss: 0.116519
 >> iter 7000, loss: 0.070279
 >> iter 8000, loss: 0.052513
 >> iter 9000, loss: 0.046565
 >> iter 10000, loss: 0.043704
   Number of active neurons: 3
 >> iter 11000, loss: 0.043155
 >> iter 12000, loss: 0.042096
 >> iter 13000, loss: 0.042260
 >> iter 14000, loss: 0.041604
 >> iter 15000, loss: 0.041770
 >> iter 16000, loss: 0.040684
 >> iter 17000, loss: 0.040519
 >> iter 18000, loss: 0.039088
 >> iter 19000, loss: 0.038451
 >> iter 20000, loss: 0.036764
   Number of active neurons: 2
 >> iter 21000, loss: 0.035908
 >> iter 22000, loss: 0.034584
 >> iter 23000, loss: 0.034333
 >> iter 24000, loss: 0.033495
 >> iter 25000, loss: 0.033579
 >> iter 26000, loss: 0.032929
 >> iter 27000, loss: 0.033152
 >> iter 28000, loss: 0.032582
 >> iter 29000, loss: 0.032864
 >> iter 30000, loss: 0.032362
   Number of active neurons: 2
 >> iter 31000, loss: 0.032670
 >> iter 32000, loss: 0.032198
 >> iter 33000, loss: 0.032520
 >> iter 34000, loss: 0.032101
 >> iter 35000, loss: 0.032401
 >> iter 36000, loss: 0.032014
 >> iter 37000, loss: 0.032320
 >> iter 38000, loss: 0.031953
 >> iter 39000, loss: 0.032240
 >> iter 40000, loss: 0.031941
   Number of active neurons: 2
 >> iter 41000, loss: 0.032189
 >> iter 42000, loss: 0.031882
 >> iter 43000, loss: 0.032145
 >> iter 44000, loss: 0.031873
 >> iter 45000, loss: 0.032124
 >> iter 46000, loss: 0.031843
 >> iter 47000, loss: 0.032107
 >> iter 48000, loss: 0.031823
 >> iter 49000, loss: 0.032102
 >> iter 50000, loss: 0.031806
   Number of active neurons: 2
 >> iter 51000, loss: 0.032078
 >> iter 52000, loss: 0.031818
 >> iter 53000, loss: 0.032050
 >> iter 54000, loss: 0.031831
 >> iter 55000, loss: 0.032054
 >> iter 56000, loss: 0.031832
 >> iter 57000, loss: 0.032037
 >> iter 58000, loss: 0.031831
 >> iter 59000, loss: 0.032033
 >> iter 60000, loss: 0.031832
   Number of active neurons: 2
 >> iter 61000, loss: 0.032068
 >> iter 62000, loss: 0.031829
 >> iter 63000, loss: 0.032045
 >> iter 64000, loss: 0.031835
 >> iter 65000, loss: 0.032033
 >> iter 66000, loss: 0.031838
 >> iter 67000, loss: 0.032029
 >> iter 68000, loss: 0.031854
 >> iter 69000, loss: 0.032008
 >> iter 70000, loss: 0.031849
   Number of active neurons: 2
 >> iter 71000, loss: 0.031988
 >> iter 72000, loss: 0.031836
 >> iter 73000, loss: 0.032010
 >> iter 74000, loss: 0.031844
 >> iter 75000, loss: 0.032001
 >> iter 76000, loss: 0.031846
 >> iter 77000, loss: 0.031994
 >> iter 78000, loss: 0.031837
 >> iter 79000, loss: 0.031988
 >> iter 80000, loss: 0.031818
   Number of active neurons: 2
 >> iter 81000, loss: 0.031980
 >> iter 82000, loss: 0.031811
 >> iter 83000, loss: 0.031972
 >> iter 84000, loss: 0.031819
 >> iter 85000, loss: 0.031951
 >> iter 86000, loss: 0.031809
 >> iter 87000, loss: 0.031936
 >> iter 88000, loss: 0.031831
 >> iter 89000, loss: 0.031940
 >> iter 90000, loss: 0.031822
   Number of active neurons: 2
 >> iter 91000, loss: 0.031921
 >> iter 92000, loss: 0.031831
 >> iter 93000, loss: 0.031931
 >> iter 94000, loss: 0.031828
 >> iter 95000, loss: 0.031941
 >> iter 96000, loss: 0.031827
 >> iter 97000, loss: 0.031939
 >> iter 98000, loss: 0.031819
 >> iter 99000, loss: 0.031937
 >> iter 100000, loss: 0.031835
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.976510
 >> iter 2000, loss: 4.082207
 >> iter 3000, loss: 1.540505
 >> iter 4000, loss: 0.603037
 >> iter 5000, loss: 0.257905
 >> iter 6000, loss: 0.128326
 >> iter 7000, loss: 0.079329
 >> iter 8000, loss: 0.059392
 >> iter 9000, loss: 0.052218
 >> iter 10000, loss: 0.048487
   Number of active neurons: 4
 >> iter 11000, loss: 0.047118
 >> iter 12000, loss: 0.045238
 >> iter 13000, loss: 0.044486
 >> iter 14000, loss: 0.042659
 >> iter 15000, loss: 0.042013
 >> iter 16000, loss: 0.040705
 >> iter 17000, loss: 0.040744
 >> iter 18000, loss: 0.039982
 >> iter 19000, loss: 0.040294
 >> iter 20000, loss: 0.039722
   Number of active neurons: 4
 >> iter 21000, loss: 0.040056
 >> iter 22000, loss: 0.039489
 >> iter 23000, loss: 0.039808
 >> iter 24000, loss: 0.039304
 >> iter 25000, loss: 0.039700
 >> iter 26000, loss: 0.039225
 >> iter 27000, loss: 0.039652
 >> iter 28000, loss: 0.039181
 >> iter 29000, loss: 0.039612
 >> iter 30000, loss: 0.039176
   Number of active neurons: 4
 >> iter 31000, loss: 0.039596
 >> iter 32000, loss: 0.039158
 >> iter 33000, loss: 0.039573
 >> iter 34000, loss: 0.039185
 >> iter 35000, loss: 0.039539
 >> iter 36000, loss: 0.039178
 >> iter 37000, loss: 0.039527
 >> iter 38000, loss: 0.039174
 >> iter 39000, loss: 0.039492
 >> iter 40000, loss: 0.039225
   Number of active neurons: 4
 >> iter 41000, loss: 0.039477
 >> iter 42000, loss: 0.039193
 >> iter 43000, loss: 0.039453
 >> iter 44000, loss: 0.039218
 >> iter 45000, loss: 0.039469
 >> iter 46000, loss: 0.039204
 >> iter 47000, loss: 0.039467
 >> iter 48000, loss: 0.039206
 >> iter 49000, loss: 0.039479
 >> iter 50000, loss: 0.039202
   Number of active neurons: 4
 >> iter 51000, loss: 0.039462
 >> iter 52000, loss: 0.039232
 >> iter 53000, loss: 0.039438
 >> iter 54000, loss: 0.039265
 >> iter 55000, loss: 0.039463
 >> iter 56000, loss: 0.039277
 >> iter 57000, loss: 0.039455
 >> iter 58000, loss: 0.039292
 >> iter 59000, loss: 0.039466
 >> iter 60000, loss: 0.039310
   Number of active neurons: 4
 >> iter 61000, loss: 0.039535
 >> iter 62000, loss: 0.039327
 >> iter 63000, loss: 0.039526
 >> iter 64000, loss: 0.039362
 >> iter 65000, loss: 0.039538
 >> iter 66000, loss: 0.039407
 >> iter 67000, loss: 0.039573
 >> iter 68000, loss: 0.039483
 >> iter 69000, loss: 0.039611
 >> iter 70000, loss: 0.039552
   Number of active neurons: 4
 >> iter 71000, loss: 0.039678
 >> iter 72000, loss: 0.039609
 >> iter 73000, loss: 0.039798
 >> iter 74000, loss: 0.039746
 >> iter 75000, loss: 0.039954
 >> iter 76000, loss: 0.039900
 >> iter 77000, loss: 0.040080
 >> iter 78000, loss: 0.040008
 >> iter 79000, loss: 0.040200
 >> iter 80000, loss: 0.040116
   Number of active neurons: 4
 >> iter 81000, loss: 0.040335
 >> iter 82000, loss: 0.040260
 >> iter 83000, loss: 0.040498
 >> iter 84000, loss: 0.040440
 >> iter 85000, loss: 0.040663
 >> iter 86000, loss: 0.040619
 >> iter 87000, loss: 0.040850
 >> iter 88000, loss: 0.040843
 >> iter 89000, loss: 0.041050
 >> iter 90000, loss: 0.040982
   Number of active neurons: 4
 >> iter 91000, loss: 0.041074
 >> iter 92000, loss: 0.040538
 >> iter 93000, loss: 0.040182
 >> iter 94000, loss: 0.039451
 >> iter 95000, loss: 0.038719
 >> iter 96000, loss: 0.037583
 >> iter 97000, loss: 0.036451
 >> iter 98000, loss: 0.035207
 >> iter 99000, loss: 0.034524
 >> iter 100000, loss: 0.033865
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.154101
 >> iter 2000, loss: 4.152264
 >> iter 3000, loss: 1.568447
 >> iter 4000, loss: 0.616041
 >> iter 5000, loss: 0.265008
 >> iter 6000, loss: 0.133346
 >> iter 7000, loss: 0.083807
 >> iter 8000, loss: 0.063328
 >> iter 9000, loss: 0.055366
 >> iter 10000, loss: 0.051128
   Number of active neurons: 3
 >> iter 11000, loss: 0.049978
 >> iter 12000, loss: 0.048188
 >> iter 13000, loss: 0.047513
 >> iter 14000, loss: 0.045679
 >> iter 15000, loss: 0.044947
 >> iter 16000, loss: 0.043318
 >> iter 17000, loss: 0.042969
 >> iter 18000, loss: 0.041511
 >> iter 19000, loss: 0.041099
 >> iter 20000, loss: 0.039617
   Number of active neurons: 2
 >> iter 21000, loss: 0.038913
 >> iter 22000, loss: 0.037214
 >> iter 23000, loss: 0.036291
 >> iter 24000, loss: 0.034855
 >> iter 25000, loss: 0.034554
 >> iter 26000, loss: 0.033642
 >> iter 27000, loss: 0.033706
 >> iter 28000, loss: 0.033021
 >> iter 29000, loss: 0.033229
 >> iter 30000, loss: 0.032664
   Number of active neurons: 2
 >> iter 31000, loss: 0.032929
 >> iter 32000, loss: 0.032414
 >> iter 33000, loss: 0.032707
 >> iter 34000, loss: 0.032260
 >> iter 35000, loss: 0.032538
 >> iter 36000, loss: 0.032130
 >> iter 37000, loss: 0.032421
 >> iter 38000, loss: 0.032041
 >> iter 39000, loss: 0.032317
 >> iter 40000, loss: 0.032006
   Number of active neurons: 2
 >> iter 41000, loss: 0.032247
 >> iter 42000, loss: 0.031931
 >> iter 43000, loss: 0.032187
 >> iter 44000, loss: 0.031910
 >> iter 45000, loss: 0.032158
 >> iter 46000, loss: 0.031871
 >> iter 47000, loss: 0.032130
 >> iter 48000, loss: 0.031845
 >> iter 49000, loss: 0.032121
 >> iter 50000, loss: 0.031822
   Number of active neurons: 2
 >> iter 51000, loss: 0.032093
 >> iter 52000, loss: 0.031832
 >> iter 53000, loss: 0.032061
 >> iter 54000, loss: 0.031841
 >> iter 55000, loss: 0.032062
 >> iter 56000, loss: 0.031841
 >> iter 57000, loss: 0.032042
 >> iter 58000, loss: 0.031837
 >> iter 59000, loss: 0.032038
 >> iter 60000, loss: 0.031835
   Number of active neurons: 2
 >> iter 61000, loss: 0.032073
 >> iter 62000, loss: 0.031833
 >> iter 63000, loss: 0.032048
 >> iter 64000, loss: 0.031838
 >> iter 65000, loss: 0.032037
 >> iter 66000, loss: 0.031841
 >> iter 67000, loss: 0.032032
 >> iter 68000, loss: 0.031856
 >> iter 69000, loss: 0.032009
 >> iter 70000, loss: 0.031851
   Number of active neurons: 2
 >> iter 71000, loss: 0.031990
 >> iter 72000, loss: 0.031837
 >> iter 73000, loss: 0.032011
 >> iter 74000, loss: 0.031846
 >> iter 75000, loss: 0.032003
 >> iter 76000, loss: 0.031848
 >> iter 77000, loss: 0.031994
 >> iter 78000, loss: 0.031837
 >> iter 79000, loss: 0.031988
 >> iter 80000, loss: 0.031818
   Number of active neurons: 2
 >> iter 81000, loss: 0.031980
 >> iter 82000, loss: 0.031813
 >> iter 83000, loss: 0.031973
 >> iter 84000, loss: 0.031820
 >> iter 85000, loss: 0.031952
 >> iter 86000, loss: 0.031809
 >> iter 87000, loss: 0.031938
 >> iter 88000, loss: 0.031830
 >> iter 89000, loss: 0.031940
 >> iter 90000, loss: 0.031822
   Number of active neurons: 2
 >> iter 91000, loss: 0.031921
 >> iter 92000, loss: 0.031832
 >> iter 93000, loss: 0.031932
 >> iter 94000, loss: 0.031828
 >> iter 95000, loss: 0.031941
 >> iter 96000, loss: 0.031827
 >> iter 97000, loss: 0.031940
 >> iter 98000, loss: 0.031819
 >> iter 99000, loss: 0.031936
 >> iter 100000, loss: 0.031836
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

