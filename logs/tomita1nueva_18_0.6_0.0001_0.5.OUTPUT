 > Problema: tomita1nueva
 > Args:
   - Hidden size: 18
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.911204
 >> iter 2000, loss: 4.057828
 >> iter 3000, loss: 1.526588
 >> iter 4000, loss: 0.589933
 >> iter 5000, loss: 0.239820
 >> iter 6000, loss: 0.147394
 >> iter 7000, loss: 0.077782
 >> iter 8000, loss: 0.048960
 >> iter 9000, loss: 0.046021
 >> iter 10000, loss: 0.039959
   Number of active neurons: 5
 >> iter 11000, loss: 0.035593
 >> iter 12000, loss: 0.049210
 >> iter 13000, loss: 0.044912
 >> iter 14000, loss: 0.040911
 >> iter 15000, loss: 0.033052
 >> iter 16000, loss: 0.028370
 >> iter 17000, loss: 0.028361
 >> iter 18000, loss: 0.031978
 >> iter 19000, loss: 0.027759
 >> iter 20000, loss: 0.024244
   Number of active neurons: 2
 >> iter 21000, loss: 0.028297
 >> iter 22000, loss: 0.040244
 >> iter 23000, loss: 0.033677
 >> iter 24000, loss: 0.029281
 >> iter 25000, loss: 0.026108
 >> iter 26000, loss: 0.021382
 >> iter 27000, loss: 0.035124
 >> iter 28000, loss: 0.031033
 >> iter 29000, loss: 0.035897
 >> iter 30000, loss: 0.027795
   Number of active neurons: 2
 >> iter 31000, loss: 0.023743
 >> iter 32000, loss: 0.020983
 >> iter 33000, loss: 0.028933
 >> iter 34000, loss: 0.030088
 >> iter 35000, loss: 0.028113
 >> iter 36000, loss: 0.023539
 >> iter 37000, loss: 0.026822
 >> iter 38000, loss: 0.023048
 >> iter 39000, loss: 0.021123
 >> iter 40000, loss: 0.022363
   Number of active neurons: 2
 >> iter 41000, loss: 0.026511
 >> iter 42000, loss: 0.030049
 >> iter 43000, loss: 0.026416
 >> iter 44000, loss: 0.026236
 >> iter 45000, loss: 0.026098
 >> iter 46000, loss: 0.025065
 >> iter 47000, loss: 0.036238
 >> iter 48000, loss: 0.031439
 >> iter 49000, loss: 0.023615
 >> iter 50000, loss: 0.029073
   Number of active neurons: 2
 >> iter 51000, loss: 0.025976
 >> iter 52000, loss: 0.023754
 >> iter 53000, loss: 0.033902
 >> iter 54000, loss: 0.027265
 >> iter 55000, loss: 0.028297
 >> iter 56000, loss: 0.027362
 >> iter 57000, loss: 0.027761
 >> iter 58000, loss: 0.024668
 >> iter 59000, loss: 0.021848
 >> iter 60000, loss: 0.031991
   Number of active neurons: 2
 >> iter 61000, loss: 0.024408
 >> iter 62000, loss: 0.023490
 >> iter 63000, loss: 0.046153
 >> iter 64000, loss: 0.031013
 >> iter 65000, loss: 0.024700
 >> iter 66000, loss: 0.022835
 >> iter 67000, loss: 0.022734
 >> iter 68000, loss: 0.031342
 >> iter 69000, loss: 0.025241
 >> iter 70000, loss: 0.023068
   Number of active neurons: 2
 >> iter 71000, loss: 0.021829
 >> iter 72000, loss: 0.020671
 >> iter 73000, loss: 0.022601
 >> iter 74000, loss: 0.025728
 >> iter 75000, loss: 0.023554
 >> iter 76000, loss: 0.023959
 >> iter 77000, loss: 0.021758
 >> iter 78000, loss: 0.022437
 >> iter 79000, loss: 0.030294
 >> iter 80000, loss: 0.024663
   Number of active neurons: 1
 >> iter 81000, loss: 0.021198
 >> iter 82000, loss: 0.018488
 >> iter 83000, loss: 0.019051
 >> iter 84000, loss: 0.020545
 >> iter 85000, loss: 0.020895
 >> iter 86000, loss: 0.019775
 >> iter 87000, loss: 0.019534
 >> iter 88000, loss: 0.016626
 >> iter 89000, loss: 0.018354
 >> iter 90000, loss: 0.019630
   Number of active neurons: 1
 >> iter 91000, loss: 0.027984
 >> iter 92000, loss: 0.023178
 >> iter 93000, loss: 0.024730
 >> iter 94000, loss: 0.026258
 >> iter 95000, loss: 0.042070
 >> iter 96000, loss: 0.030023
 >> iter 97000, loss: 0.026732
 >> iter 98000, loss: 0.020897
 >> iter 99000, loss: 0.032141
 >> iter 100000, loss: 0.025535
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 10.942994
 >> iter 2000, loss: 4.077368
 >> iter 3000, loss: 1.548405
 >> iter 4000, loss: 0.601885
 >> iter 5000, loss: 0.253950
 >> iter 6000, loss: 0.114274
 >> iter 7000, loss: 0.064637
 >> iter 8000, loss: 0.042034
 >> iter 9000, loss: 0.034973
 >> iter 10000, loss: 0.033411
   Number of active neurons: 3
 >> iter 11000, loss: 0.034136
 >> iter 12000, loss: 0.030708
 >> iter 13000, loss: 0.029017
 >> iter 14000, loss: 0.028150
 >> iter 15000, loss: 0.032426
 >> iter 16000, loss: 0.027080
 >> iter 17000, loss: 0.029632
 >> iter 18000, loss: 0.029210
 >> iter 19000, loss: 0.026969
 >> iter 20000, loss: 0.025316
   Number of active neurons: 2
 >> iter 21000, loss: 0.024338
 >> iter 22000, loss: 0.026527
 >> iter 23000, loss: 0.030276
 >> iter 24000, loss: 0.024051
 >> iter 25000, loss: 0.022325
 >> iter 26000, loss: 0.021992
 >> iter 27000, loss: 0.026419
 >> iter 28000, loss: 0.023985
 >> iter 29000, loss: 0.026575
 >> iter 30000, loss: 0.023919
   Number of active neurons: 2
 >> iter 31000, loss: 0.040055
 >> iter 32000, loss: 0.029904
 >> iter 33000, loss: 0.025514
 >> iter 34000, loss: 0.023969
 >> iter 35000, loss: 0.024770
 >> iter 36000, loss: 0.026043
 >> iter 37000, loss: 0.032319
 >> iter 38000, loss: 0.024742
 >> iter 39000, loss: 0.030868
 >> iter 40000, loss: 0.030045
   Number of active neurons: 2
 >> iter 41000, loss: 0.023916
 >> iter 42000, loss: 0.032405
 >> iter 43000, loss: 0.037550
 >> iter 44000, loss: 0.025794
 >> iter 45000, loss: 0.024324
 >> iter 46000, loss: 0.021516
 >> iter 47000, loss: 0.025866
 >> iter 48000, loss: 0.032128
 >> iter 49000, loss: 0.026791
 >> iter 50000, loss: 0.028032
   Number of active neurons: 2
 >> iter 51000, loss: 0.024112
 >> iter 52000, loss: 0.026975
 >> iter 53000, loss: 0.022906
 >> iter 54000, loss: 0.021866
 >> iter 55000, loss: 0.029845
 >> iter 56000, loss: 0.023212
 >> iter 57000, loss: 0.038377
 >> iter 58000, loss: 0.028099
 >> iter 59000, loss: 0.034033
 >> iter 60000, loss: 0.024869
   Number of active neurons: 2
 >> iter 61000, loss: 0.028147
 >> iter 62000, loss: 0.024149
 >> iter 63000, loss: 0.024110
 >> iter 64000, loss: 0.020292
 >> iter 65000, loss: 0.022470
 >> iter 66000, loss: 0.029694
 >> iter 67000, loss: 0.025950
 >> iter 68000, loss: 0.021687
 >> iter 69000, loss: 0.022187
 >> iter 70000, loss: 0.025251
   Number of active neurons: 1
 >> iter 71000, loss: 0.021403
 >> iter 72000, loss: 0.020010
 >> iter 73000, loss: 0.018179
 >> iter 74000, loss: 0.019783
 >> iter 75000, loss: 0.018314
 >> iter 76000, loss: 0.020166
 >> iter 77000, loss: 0.017602
 >> iter 78000, loss: 0.021826
 >> iter 79000, loss: 0.026680
 >> iter 80000, loss: 0.024345
   Number of active neurons: 1
 >> iter 81000, loss: 0.023265
 >> iter 82000, loss: 0.020792
 >> iter 83000, loss: 0.024891
 >> iter 84000, loss: 0.026614
 >> iter 85000, loss: 0.019430
 >> iter 86000, loss: 0.021959
 >> iter 87000, loss: 0.048399
 >> iter 88000, loss: 0.030225
 >> iter 89000, loss: 0.021157
 >> iter 90000, loss: 0.018666
   Number of active neurons: 1
 >> iter 91000, loss: 0.021270
 >> iter 92000, loss: 0.022217
 >> iter 93000, loss: 0.019345
 >> iter 94000, loss: 0.063398
 >> iter 95000, loss: 0.033671
 >> iter 96000, loss: 0.025263
 >> iter 97000, loss: 0.024884
 >> iter 98000, loss: 0.019254
 >> iter 99000, loss: 0.019855
 >> iter 100000, loss: 0.018611
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.931708
 >> iter 2000, loss: 4.064559
 >> iter 3000, loss: 1.525892
 >> iter 4000, loss: 0.598175
 >> iter 5000, loss: 0.254638
 >> iter 6000, loss: 0.113208
 >> iter 7000, loss: 0.072745
 >> iter 8000, loss: 0.044943
 >> iter 9000, loss: 0.049847
 >> iter 10000, loss: 0.035911
   Number of active neurons: 3
 >> iter 11000, loss: 0.030896
 >> iter 12000, loss: 0.029375
 >> iter 13000, loss: 0.028225
 >> iter 14000, loss: 0.049622
 >> iter 15000, loss: 0.036995
 >> iter 16000, loss: 0.030909
 >> iter 17000, loss: 0.027835
 >> iter 18000, loss: 0.025697
 >> iter 19000, loss: 0.027424
 >> iter 20000, loss: 0.023889
   Number of active neurons: 3
 >> iter 21000, loss: 0.026715
 >> iter 22000, loss: 0.023799
 >> iter 23000, loss: 0.027034
 >> iter 24000, loss: 0.024082
 >> iter 25000, loss: 0.023727
 >> iter 26000, loss: 0.031682
 >> iter 27000, loss: 0.024616
 >> iter 28000, loss: 0.026383
 >> iter 29000, loss: 0.025645
 >> iter 30000, loss: 0.021909
   Number of active neurons: 2
 >> iter 31000, loss: 0.030274
 >> iter 32000, loss: 0.025232
 >> iter 33000, loss: 0.023150
 >> iter 34000, loss: 0.025444
 >> iter 35000, loss: 0.021003
 >> iter 36000, loss: 0.022452
 >> iter 37000, loss: 0.024583
 >> iter 38000, loss: 0.028964
 >> iter 39000, loss: 0.035415
 >> iter 40000, loss: 0.038917
   Number of active neurons: 2
 >> iter 41000, loss: 0.039011
 >> iter 42000, loss: 0.028135
 >> iter 43000, loss: 0.022728
 >> iter 44000, loss: 0.020900
 >> iter 45000, loss: 0.025478
 >> iter 46000, loss: 0.021620
 >> iter 47000, loss: 0.029087
 >> iter 48000, loss: 0.039139
 >> iter 49000, loss: 0.026908
 >> iter 50000, loss: 0.026667
   Number of active neurons: 1
 >> iter 51000, loss: 0.027086
 >> iter 52000, loss: 0.028283
 >> iter 53000, loss: 0.026189
 >> iter 54000, loss: 0.029797
 >> iter 55000, loss: 0.026979
 >> iter 56000, loss: 0.030984
 >> iter 57000, loss: 0.029141
 >> iter 58000, loss: 0.023008
 >> iter 59000, loss: 0.027303
 >> iter 60000, loss: 0.035651
   Number of active neurons: 1
 >> iter 61000, loss: 0.024648
 >> iter 62000, loss: 0.030794
 >> iter 63000, loss: 0.021514
 >> iter 64000, loss: 0.017952
 >> iter 65000, loss: 0.025215
 >> iter 66000, loss: 0.020090
 >> iter 67000, loss: 0.017134
 >> iter 68000, loss: 0.019284
 >> iter 69000, loss: 0.019191
 >> iter 70000, loss: 0.017815
   Number of active neurons: 1
 >> iter 71000, loss: 0.022863
 >> iter 72000, loss: 0.029940
 >> iter 73000, loss: 0.028005
 >> iter 74000, loss: 0.022255
 >> iter 75000, loss: 0.023620
 >> iter 76000, loss: 0.019625
 >> iter 77000, loss: 0.018641
 >> iter 78000, loss: 0.017377
 >> iter 79000, loss: 0.017010
 >> iter 80000, loss: 0.020340
   Number of active neurons: 1
 >> iter 81000, loss: 0.017556
 >> iter 82000, loss: 0.024044
 >> iter 83000, loss: 0.023822
 >> iter 84000, loss: 0.020309
 >> iter 85000, loss: 0.018021
 >> iter 86000, loss: 0.021697
 >> iter 87000, loss: 0.021735
 >> iter 88000, loss: 0.019484
 >> iter 89000, loss: 0.018438
 >> iter 90000, loss: 0.030461
   Number of active neurons: 1
 >> iter 91000, loss: 0.022621
 >> iter 92000, loss: 0.019634
 >> iter 93000, loss: 0.020401
 >> iter 94000, loss: 0.017480
 >> iter 95000, loss: 0.070500
 >> iter 96000, loss: 0.038795
 >> iter 97000, loss: 0.025732
 >> iter 98000, loss: 0.019678
 >> iter 99000, loss: 0.019469
 >> iter 100000, loss: 0.017781
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.895740
 >> iter 2000, loss: 4.069714
 >> iter 3000, loss: 1.543667
 >> iter 4000, loss: 0.606393
 >> iter 5000, loss: 0.252143
 >> iter 6000, loss: 0.115705
 >> iter 7000, loss: 0.061422
 >> iter 8000, loss: 0.046731
 >> iter 9000, loss: 0.048661
 >> iter 10000, loss: 0.053651
   Number of active neurons: 4
 >> iter 11000, loss: 0.036853
 >> iter 12000, loss: 0.032629
 >> iter 13000, loss: 0.033335
 >> iter 14000, loss: 0.028342
 >> iter 15000, loss: 0.036104
 >> iter 16000, loss: 0.028724
 >> iter 17000, loss: 0.034017
 >> iter 18000, loss: 0.028240
 >> iter 19000, loss: 0.028300
 >> iter 20000, loss: 0.031070
   Number of active neurons: 3
 >> iter 21000, loss: 0.031070
 >> iter 22000, loss: 0.034052
 >> iter 23000, loss: 0.028034
 >> iter 24000, loss: 0.025189
 >> iter 25000, loss: 0.067520
 >> iter 26000, loss: 0.044529
 >> iter 27000, loss: 0.032351
 >> iter 28000, loss: 0.027128
 >> iter 29000, loss: 0.024275
 >> iter 30000, loss: 0.025962
   Number of active neurons: 3
 >> iter 31000, loss: 0.024867
 >> iter 32000, loss: 0.030891
 >> iter 33000, loss: 0.034473
 >> iter 34000, loss: 0.027409
 >> iter 35000, loss: 0.036560
 >> iter 36000, loss: 0.028625
 >> iter 37000, loss: 0.025305
 >> iter 38000, loss: 0.020854
 >> iter 39000, loss: 0.020264
 >> iter 40000, loss: 0.037444
   Number of active neurons: 1
 >> iter 41000, loss: 0.026747
 >> iter 42000, loss: 0.021438
 >> iter 43000, loss: 0.038486
 >> iter 44000, loss: 0.024007
 >> iter 45000, loss: 0.041913
 >> iter 46000, loss: 0.025627
 >> iter 47000, loss: 0.020716
 >> iter 48000, loss: 0.018884
 >> iter 49000, loss: 0.019564
 >> iter 50000, loss: 0.019793
   Number of active neurons: 1
 >> iter 51000, loss: 0.019797
 >> iter 52000, loss: 0.021116
 >> iter 53000, loss: 0.018290
 >> iter 54000, loss: 0.021928
 >> iter 55000, loss: 0.031285
 >> iter 56000, loss: 0.024646
 >> iter 57000, loss: 0.024745
 >> iter 58000, loss: 0.040341
 >> iter 59000, loss: 0.024682
 >> iter 60000, loss: 0.019280
   Number of active neurons: 1
 >> iter 61000, loss: 0.039491
 >> iter 62000, loss: 0.029300
 >> iter 63000, loss: 0.026163
 >> iter 64000, loss: 0.020838
 >> iter 65000, loss: 0.021849
 >> iter 66000, loss: 0.037198
 >> iter 67000, loss: 0.028513
 >> iter 68000, loss: 0.023980
 >> iter 69000, loss: 0.019177
 >> iter 70000, loss: 0.019581
   Number of active neurons: 1
 >> iter 71000, loss: 0.021980
 >> iter 72000, loss: 0.027818
 >> iter 73000, loss: 0.037732
 >> iter 74000, loss: 0.027786
 >> iter 75000, loss: 0.022582
 >> iter 76000, loss: 0.031142
 >> iter 77000, loss: 0.024110
 >> iter 78000, loss: 0.020362
 >> iter 79000, loss: 0.022360
 >> iter 80000, loss: 0.018915
   Number of active neurons: 1
 >> iter 81000, loss: 0.020257
 >> iter 82000, loss: 0.018988
 >> iter 83000, loss: 0.016814
 >> iter 84000, loss: 0.017615
 >> iter 85000, loss: 0.017861
 >> iter 86000, loss: 0.030929
 >> iter 87000, loss: 0.023350
 >> iter 88000, loss: 0.028699
 >> iter 89000, loss: 0.019937
 >> iter 90000, loss: 0.019396
   Number of active neurons: 1
 >> iter 91000, loss: 0.017390
 >> iter 92000, loss: 0.022551
 >> iter 93000, loss: 0.042142
 >> iter 94000, loss: 0.025393
 >> iter 95000, loss: 0.022998
 >> iter 96000, loss: 0.022955
 >> iter 97000, loss: 0.027282
 >> iter 98000, loss: 0.024345
 >> iter 99000, loss: 0.021232
 >> iter 100000, loss: 0.018299
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.868626
 >> iter 2000, loss: 4.047187
 >> iter 3000, loss: 1.514657
 >> iter 4000, loss: 0.588023
 >> iter 5000, loss: 0.245310
 >> iter 6000, loss: 0.117857
 >> iter 7000, loss: 0.066236
 >> iter 8000, loss: 0.044511
 >> iter 9000, loss: 0.044109
 >> iter 10000, loss: 0.035262
   Number of active neurons: 4
 >> iter 11000, loss: 0.028234
 >> iter 12000, loss: 0.029027
 >> iter 13000, loss: 0.027835
 >> iter 14000, loss: 0.029210
 >> iter 15000, loss: 0.027978
 >> iter 16000, loss: 0.023705
 >> iter 17000, loss: 0.029683
 >> iter 18000, loss: 0.029243
 >> iter 19000, loss: 0.026662
 >> iter 20000, loss: 0.023778
   Number of active neurons: 2
 >> iter 21000, loss: 0.027895
 >> iter 22000, loss: 0.023674
 >> iter 23000, loss: 0.024176
 >> iter 24000, loss: 0.023766
 >> iter 25000, loss: 0.024246
 >> iter 26000, loss: 0.027347
 >> iter 27000, loss: 0.024836
 >> iter 28000, loss: 0.021414
 >> iter 29000, loss: 0.024189
 >> iter 30000, loss: 0.022434
   Number of active neurons: 2
 >> iter 31000, loss: 0.024194
 >> iter 32000, loss: 0.021236
 >> iter 33000, loss: 0.021433
 >> iter 34000, loss: 0.023533
 >> iter 35000, loss: 0.026910
 >> iter 36000, loss: 0.032784
 >> iter 37000, loss: 0.032106
 >> iter 38000, loss: 0.030541
 >> iter 39000, loss: 0.030092
 >> iter 40000, loss: 0.027137
   Number of active neurons: 2
 >> iter 41000, loss: 0.025189
 >> iter 42000, loss: 0.023232
 >> iter 43000, loss: 0.025602
 >> iter 44000, loss: 0.053154
 >> iter 45000, loss: 0.034797
 >> iter 46000, loss: 0.025540
 >> iter 47000, loss: 0.024432
 >> iter 48000, loss: 0.047240
 >> iter 49000, loss: 0.034503
 >> iter 50000, loss: 0.025000
   Number of active neurons: 2
 >> iter 51000, loss: 0.022456
 >> iter 52000, loss: 0.024778
 >> iter 53000, loss: 0.022955
 >> iter 54000, loss: 0.025463
 >> iter 55000, loss: 0.028415
 >> iter 56000, loss: 0.023000
 >> iter 57000, loss: 0.045421
 >> iter 58000, loss: 0.035401
 >> iter 59000, loss: 0.032362
 >> iter 60000, loss: 0.025595
   Number of active neurons: 2
 >> iter 61000, loss: 0.050209
 >> iter 62000, loss: 0.032775
 >> iter 63000, loss: 0.025707
 >> iter 64000, loss: 0.023479
 >> iter 65000, loss: 0.022972
 >> iter 66000, loss: 0.022578
 >> iter 67000, loss: 0.027767
 >> iter 68000, loss: 0.023235
 >> iter 69000, loss: 0.025504
 >> iter 70000, loss: 0.022089
   Number of active neurons: 2
 >> iter 71000, loss: 0.020637
 >> iter 72000, loss: 0.029065
 >> iter 73000, loss: 0.022083
 >> iter 74000, loss: 0.024403
 >> iter 75000, loss: 0.025290
 >> iter 76000, loss: 0.035779
 >> iter 77000, loss: 0.025650
 >> iter 78000, loss: 0.025003
 >> iter 79000, loss: 0.021690
 >> iter 80000, loss: 0.021904
   Number of active neurons: 1
 >> iter 81000, loss: 0.019086
 >> iter 82000, loss: 0.024727
 >> iter 83000, loss: 0.022157
 >> iter 84000, loss: 0.019473
 >> iter 85000, loss: 0.018287
 >> iter 86000, loss: 0.019189
 >> iter 87000, loss: 0.025845
 >> iter 88000, loss: 0.027263
 >> iter 89000, loss: 0.022631
 >> iter 90000, loss: 0.024692
   Number of active neurons: 1
 >> iter 91000, loss: 0.021320
 >> iter 92000, loss: 0.018972
 >> iter 93000, loss: 0.018520
 >> iter 94000, loss: 0.027235
 >> iter 95000, loss: 0.022004
 >> iter 96000, loss: 0.018840
 >> iter 97000, loss: 0.023727
 >> iter 98000, loss: 0.018376
 >> iter 99000, loss: 0.017943
 >> iter 100000, loss: 0.023003
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.951315
 >> iter 2000, loss: 4.071867
 >> iter 3000, loss: 1.542445
 >> iter 4000, loss: 0.593881
 >> iter 5000, loss: 0.242347
 >> iter 6000, loss: 0.112198
 >> iter 7000, loss: 0.069602
 >> iter 8000, loss: 0.057686
 >> iter 9000, loss: 0.040552
 >> iter 10000, loss: 0.032066
   Number of active neurons: 5
 >> iter 11000, loss: 0.031731
 >> iter 12000, loss: 0.030556
 >> iter 13000, loss: 0.029867
 >> iter 14000, loss: 0.030109
 >> iter 15000, loss: 0.028647
 >> iter 16000, loss: 0.040684
 >> iter 17000, loss: 0.053561
 >> iter 18000, loss: 0.040831
 >> iter 19000, loss: 0.031060
 >> iter 20000, loss: 0.027207
   Number of active neurons: 4
 >> iter 21000, loss: 0.030690
 >> iter 22000, loss: 0.032304
 >> iter 23000, loss: 0.027788
 >> iter 24000, loss: 0.027586
 >> iter 25000, loss: 0.026739
 >> iter 26000, loss: 0.027660
 >> iter 27000, loss: 0.026005
 >> iter 28000, loss: 0.026000
 >> iter 29000, loss: 0.026777
 >> iter 30000, loss: 0.024617
   Number of active neurons: 3
 >> iter 31000, loss: 0.023795
 >> iter 32000, loss: 0.026883
 >> iter 33000, loss: 0.026740
 >> iter 34000, loss: 0.028567
 >> iter 35000, loss: 0.027526
 >> iter 36000, loss: 0.029109
 >> iter 37000, loss: 0.047207
 >> iter 38000, loss: 0.036184
 >> iter 39000, loss: 0.026261
 >> iter 40000, loss: 0.032411
   Number of active neurons: 2
 >> iter 41000, loss: 0.030387
 >> iter 42000, loss: 0.031879
 >> iter 43000, loss: 0.026304
 >> iter 44000, loss: 0.023932
 >> iter 45000, loss: 0.069430
 >> iter 46000, loss: 0.040122
 >> iter 47000, loss: 0.032734
 >> iter 48000, loss: 0.023999
 >> iter 49000, loss: 0.023774
 >> iter 50000, loss: 0.033179
   Number of active neurons: 2
 >> iter 51000, loss: 0.025987
 >> iter 52000, loss: 0.023721
 >> iter 53000, loss: 0.024552
 >> iter 54000, loss: 0.020860
 >> iter 55000, loss: 0.023394
 >> iter 56000, loss: 0.027969
 >> iter 57000, loss: 0.023080
 >> iter 58000, loss: 0.022534
 >> iter 59000, loss: 0.024499
 >> iter 60000, loss: 0.022038
   Number of active neurons: 2
 >> iter 61000, loss: 0.054904
 >> iter 62000, loss: 0.042607
 >> iter 63000, loss: 0.049341
 >> iter 64000, loss: 0.036512
 >> iter 65000, loss: 0.058604
 >> iter 66000, loss: 0.034925
 >> iter 67000, loss: 0.026802
 >> iter 68000, loss: 0.026329
 >> iter 69000, loss: 0.022387
 >> iter 70000, loss: 0.026275
   Number of active neurons: 2
 >> iter 71000, loss: 0.021997
 >> iter 72000, loss: 0.023994
 >> iter 73000, loss: 0.024082
 >> iter 74000, loss: 0.021987
 >> iter 75000, loss: 0.021461
 >> iter 76000, loss: 0.030140
 >> iter 77000, loss: 0.034731
 >> iter 78000, loss: 0.026528
 >> iter 79000, loss: 0.025560
 >> iter 80000, loss: 0.024010
   Number of active neurons: 2
 >> iter 81000, loss: 0.025572
 >> iter 82000, loss: 0.021379
 >> iter 83000, loss: 0.022043
 >> iter 84000, loss: 0.044794
 >> iter 85000, loss: 0.050618
 >> iter 86000, loss: 0.033089
 >> iter 87000, loss: 0.040589
 >> iter 88000, loss: 0.032464
 >> iter 89000, loss: 0.023669
 >> iter 90000, loss: 0.021924
   Number of active neurons: 1
 >> iter 91000, loss: 0.021725
 >> iter 92000, loss: 0.020697
 >> iter 93000, loss: 0.018679
 >> iter 94000, loss: 0.019638
 >> iter 95000, loss: 0.051078
 >> iter 96000, loss: 0.030017
 >> iter 97000, loss: 0.021070
 >> iter 98000, loss: 0.024850
 >> iter 99000, loss: 0.022300
 >> iter 100000, loss: 0.020756
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.973754
 >> iter 2000, loss: 4.093142
 >> iter 3000, loss: 1.541262
 >> iter 4000, loss: 0.588963
 >> iter 5000, loss: 0.243762
 >> iter 6000, loss: 0.110078
 >> iter 7000, loss: 0.062897
 >> iter 8000, loss: 0.045067
 >> iter 9000, loss: 0.035930
 >> iter 10000, loss: 0.031351
   Number of active neurons: 6
 >> iter 11000, loss: 0.042699
 >> iter 12000, loss: 0.033049
 >> iter 13000, loss: 0.033821
 >> iter 14000, loss: 0.031468
 >> iter 15000, loss: 0.030805
 >> iter 16000, loss: 0.030027
 >> iter 17000, loss: 0.035348
 >> iter 18000, loss: 0.032663
 >> iter 19000, loss: 0.033288
 >> iter 20000, loss: 0.029587
   Number of active neurons: 5
 >> iter 21000, loss: 0.028069
 >> iter 22000, loss: 0.028872
 >> iter 23000, loss: 0.030567
 >> iter 24000, loss: 0.028359
 >> iter 25000, loss: 0.027916
 >> iter 26000, loss: 0.030054
 >> iter 27000, loss: 0.025561
 >> iter 28000, loss: 0.025418
 >> iter 29000, loss: 0.029587
 >> iter 30000, loss: 0.028118
   Number of active neurons: 4
 >> iter 31000, loss: 0.026821
 >> iter 32000, loss: 0.028482
 >> iter 33000, loss: 0.026837
 >> iter 34000, loss: 0.025168
 >> iter 35000, loss: 0.027598
 >> iter 36000, loss: 0.044669
 >> iter 37000, loss: 0.044410
 >> iter 38000, loss: 0.035186
 >> iter 39000, loss: 0.037589
 >> iter 40000, loss: 0.033539
   Number of active neurons: 3
 >> iter 41000, loss: 0.027980
 >> iter 42000, loss: 0.034520
 >> iter 43000, loss: 0.027548
 >> iter 44000, loss: 0.024764
 >> iter 45000, loss: 0.028819
 >> iter 46000, loss: 0.024393
 >> iter 47000, loss: 0.023827
 >> iter 48000, loss: 0.027007
 >> iter 49000, loss: 0.024430
 >> iter 50000, loss: 0.031352
   Number of active neurons: 2
 >> iter 51000, loss: 0.032251
 >> iter 52000, loss: 0.031199
 >> iter 53000, loss: 0.025840
 >> iter 54000, loss: 0.021756
 >> iter 55000, loss: 0.022858
 >> iter 56000, loss: 0.022955
 >> iter 57000, loss: 0.021342
 >> iter 58000, loss: 0.022406
 >> iter 59000, loss: 0.020060
 >> iter 60000, loss: 0.023490
   Number of active neurons: 2
 >> iter 61000, loss: 0.025744
 >> iter 62000, loss: 0.022992
 >> iter 63000, loss: 0.033954
 >> iter 64000, loss: 0.025646
 >> iter 65000, loss: 0.024512
 >> iter 66000, loss: 0.030079
 >> iter 67000, loss: 0.022518
 >> iter 68000, loss: 0.019990
 >> iter 69000, loss: 0.017935
 >> iter 70000, loss: 0.031680
   Number of active neurons: 1
 >> iter 71000, loss: 0.027332
 >> iter 72000, loss: 0.022422
 >> iter 73000, loss: 0.023233
 >> iter 74000, loss: 0.019822
 >> iter 75000, loss: 0.023798
 >> iter 76000, loss: 0.021581
 >> iter 77000, loss: 0.019445
 >> iter 78000, loss: 0.016877
 >> iter 79000, loss: 0.016869
 >> iter 80000, loss: 0.017902
   Number of active neurons: 1
 >> iter 81000, loss: 0.019167
 >> iter 82000, loss: 0.016118
 >> iter 83000, loss: 0.015075
 >> iter 84000, loss: 0.016515
 >> iter 85000, loss: 0.032771
 >> iter 86000, loss: 0.027099
 >> iter 87000, loss: 0.020821
 >> iter 88000, loss: 0.020243
 >> iter 89000, loss: 0.022901
 >> iter 90000, loss: 0.018078
   Number of active neurons: 1
 >> iter 91000, loss: 0.019436
 >> iter 92000, loss: 0.017607
 >> iter 93000, loss: 0.024874
 >> iter 94000, loss: 0.021342
 >> iter 95000, loss: 0.028148
 >> iter 96000, loss: 0.022690
 >> iter 97000, loss: 0.018036
 >> iter 98000, loss: 0.018577
 >> iter 99000, loss: 0.017492
 >> iter 100000, loss: 0.029597
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.020707
 >> iter 2000, loss: 4.113588
 >> iter 3000, loss: 1.542184
 >> iter 4000, loss: 0.594165
 >> iter 5000, loss: 0.244046
 >> iter 6000, loss: 0.121000
 >> iter 7000, loss: 0.063952
 >> iter 8000, loss: 0.045545
 >> iter 9000, loss: 0.037585
 >> iter 10000, loss: 0.032437
   Number of active neurons: 7
 >> iter 11000, loss: 0.036546
 >> iter 12000, loss: 0.039946
 >> iter 13000, loss: 0.048035
 >> iter 14000, loss: 0.037322
 >> iter 15000, loss: 0.030759
 >> iter 16000, loss: 0.026950
 >> iter 17000, loss: 0.029708
 >> iter 18000, loss: 0.027399
 >> iter 19000, loss: 0.029705
 >> iter 20000, loss: 0.025853
   Number of active neurons: 3
 >> iter 21000, loss: 0.024982
 >> iter 22000, loss: 0.024579
 >> iter 23000, loss: 0.024294
 >> iter 24000, loss: 0.023860
 >> iter 25000, loss: 0.023741
 >> iter 26000, loss: 0.022847
 >> iter 27000, loss: 0.023105
 >> iter 28000, loss: 0.033711
 >> iter 29000, loss: 0.029070
 >> iter 30000, loss: 0.029148
   Number of active neurons: 3
 >> iter 31000, loss: 0.029430
 >> iter 32000, loss: 0.023781
 >> iter 33000, loss: 0.024831
 >> iter 34000, loss: 0.023841
 >> iter 35000, loss: 0.025604
 >> iter 36000, loss: 0.025575
 >> iter 37000, loss: 0.025103
 >> iter 38000, loss: 0.028748
 >> iter 39000, loss: 0.027463
 >> iter 40000, loss: 0.033653
   Number of active neurons: 2
 >> iter 41000, loss: 0.025932
 >> iter 42000, loss: 0.023844
 >> iter 43000, loss: 0.028968
 >> iter 44000, loss: 0.031164
 >> iter 45000, loss: 0.026577
 >> iter 46000, loss: 0.024529
 >> iter 47000, loss: 0.021895
 >> iter 48000, loss: 0.024599
 >> iter 49000, loss: 0.021931
 >> iter 50000, loss: 0.024407
   Number of active neurons: 2
 >> iter 51000, loss: 0.022760
 >> iter 52000, loss: 0.033495
 >> iter 53000, loss: 0.031992
 >> iter 54000, loss: 0.025896
 >> iter 55000, loss: 0.022478
 >> iter 56000, loss: 0.020316
 >> iter 57000, loss: 0.026556
 >> iter 58000, loss: 0.028391
 >> iter 59000, loss: 0.025316
 >> iter 60000, loss: 0.034757
   Number of active neurons: 2
 >> iter 61000, loss: 0.029159
 >> iter 62000, loss: 0.041383
 >> iter 63000, loss: 0.027760
 >> iter 64000, loss: 0.021882
 >> iter 65000, loss: 0.022391
 >> iter 66000, loss: 0.021361
 >> iter 67000, loss: 0.041254
 >> iter 68000, loss: 0.033490
 >> iter 69000, loss: 0.027359
 >> iter 70000, loss: 0.034464
   Number of active neurons: 2
 >> iter 71000, loss: 0.025816
 >> iter 72000, loss: 0.027015
 >> iter 73000, loss: 0.036311
 >> iter 74000, loss: 0.031465
 >> iter 75000, loss: 0.024738
 >> iter 76000, loss: 0.021675
 >> iter 77000, loss: 0.034686
 >> iter 78000, loss: 0.026498
 >> iter 79000, loss: 0.026729
 >> iter 80000, loss: 0.023056
   Number of active neurons: 2
 >> iter 81000, loss: 0.022096
 >> iter 82000, loss: 0.030412
 >> iter 83000, loss: 0.025331
 >> iter 84000, loss: 0.035231
 >> iter 85000, loss: 0.027527
 >> iter 86000, loss: 0.028347
 >> iter 87000, loss: 0.023241
 >> iter 88000, loss: 0.021065
 >> iter 89000, loss: 0.022269
 >> iter 90000, loss: 0.026460
   Number of active neurons: 2
 >> iter 91000, loss: 0.022052
 >> iter 92000, loss: 0.030744
 >> iter 93000, loss: 0.031756
 >> iter 94000, loss: 0.031990
 >> iter 95000, loss: 0.026084
 >> iter 96000, loss: 0.039640
 >> iter 97000, loss: 0.034842
 >> iter 98000, loss: 0.030862
 >> iter 99000, loss: 0.023492
 >> iter 100000, loss: 0.020909
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.922407
 >> iter 2000, loss: 4.063427
 >> iter 3000, loss: 1.522510
 >> iter 4000, loss: 0.584652
 >> iter 5000, loss: 0.238478
 >> iter 6000, loss: 0.112001
 >> iter 7000, loss: 0.069396
 >> iter 8000, loss: 0.047299
 >> iter 9000, loss: 0.043089
 >> iter 10000, loss: 0.032710
   Number of active neurons: 4
 >> iter 11000, loss: 0.036043
 >> iter 12000, loss: 0.033955
 >> iter 13000, loss: 0.035336
 >> iter 14000, loss: 0.038423
 >> iter 15000, loss: 0.033062
 >> iter 16000, loss: 0.027734
 >> iter 17000, loss: 0.030512
 >> iter 18000, loss: 0.031407
 >> iter 19000, loss: 0.026247
 >> iter 20000, loss: 0.033587
   Number of active neurons: 3
 >> iter 21000, loss: 0.027665
 >> iter 22000, loss: 0.036162
 >> iter 23000, loss: 0.030491
 >> iter 24000, loss: 0.025840
 >> iter 25000, loss: 0.023577
 >> iter 26000, loss: 0.025438
 >> iter 27000, loss: 0.023368
 >> iter 28000, loss: 0.021902
 >> iter 29000, loss: 0.027108
 >> iter 30000, loss: 0.023467
   Number of active neurons: 2
 >> iter 31000, loss: 0.022516
 >> iter 32000, loss: 0.025231
 >> iter 33000, loss: 0.022260
 >> iter 34000, loss: 0.023272
 >> iter 35000, loss: 0.020122
 >> iter 36000, loss: 0.023450
 >> iter 37000, loss: 0.048501
 >> iter 38000, loss: 0.040026
 >> iter 39000, loss: 0.029914
 >> iter 40000, loss: 0.030160
   Number of active neurons: 2
 >> iter 41000, loss: 0.026073
 >> iter 42000, loss: 0.022127
 >> iter 43000, loss: 0.021246
 >> iter 44000, loss: 0.019745
 >> iter 45000, loss: 0.018953
 >> iter 46000, loss: 0.021822
 >> iter 47000, loss: 0.040737
 >> iter 48000, loss: 0.027884
 >> iter 49000, loss: 0.025212
 >> iter 50000, loss: 0.023448
   Number of active neurons: 2
 >> iter 51000, loss: 0.019609
 >> iter 52000, loss: 0.021357
 >> iter 53000, loss: 0.020375
 >> iter 54000, loss: 0.019657
 >> iter 55000, loss: 0.029602
 >> iter 56000, loss: 0.031838
 >> iter 57000, loss: 0.024279
 >> iter 58000, loss: 0.024117
 >> iter 59000, loss: 0.023877
 >> iter 60000, loss: 0.021816
   Number of active neurons: 1
 >> iter 61000, loss: 0.018831
 >> iter 62000, loss: 0.018261
 >> iter 63000, loss: 0.017351
 >> iter 64000, loss: 0.022147
 >> iter 65000, loss: 0.033346
 >> iter 66000, loss: 0.023135
 >> iter 67000, loss: 0.020163
 >> iter 68000, loss: 0.018697
 >> iter 69000, loss: 0.020378
 >> iter 70000, loss: 0.018165
   Number of active neurons: 1
 >> iter 71000, loss: 0.019878
 >> iter 72000, loss: 0.018978
 >> iter 73000, loss: 0.021306
 >> iter 74000, loss: 0.017774
 >> iter 75000, loss: 0.017382
 >> iter 76000, loss: 0.027197
 >> iter 77000, loss: 0.021774
 >> iter 78000, loss: 0.018553
 >> iter 79000, loss: 0.019487
 >> iter 80000, loss: 0.022964
   Number of active neurons: 1
 >> iter 81000, loss: 0.019759
 >> iter 82000, loss: 0.027904
 >> iter 83000, loss: 0.032599
 >> iter 84000, loss: 0.020955
 >> iter 85000, loss: 0.018860
 >> iter 86000, loss: 0.018228
 >> iter 87000, loss: 0.018439
 >> iter 88000, loss: 0.016329
 >> iter 89000, loss: 0.016436
 >> iter 90000, loss: 0.018607
   Number of active neurons: 1
 >> iter 91000, loss: 0.019143
 >> iter 92000, loss: 0.017277
 >> iter 93000, loss: 0.019794
 >> iter 94000, loss: 0.028689
 >> iter 95000, loss: 0.021605
 >> iter 96000, loss: 0.025057
 >> iter 97000, loss: 0.021065
 >> iter 98000, loss: 0.033151
 >> iter 99000, loss: 0.025137
 >> iter 100000, loss: 0.018590
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.953497
 >> iter 2000, loss: 4.069427
 >> iter 3000, loss: 1.527262
 >> iter 4000, loss: 0.586615
 >> iter 5000, loss: 0.237266
 >> iter 6000, loss: 0.108807
 >> iter 7000, loss: 0.067561
 >> iter 8000, loss: 0.051519
 >> iter 9000, loss: 0.037032
 >> iter 10000, loss: 0.039631
   Number of active neurons: 5
 >> iter 11000, loss: 0.036924
 >> iter 12000, loss: 0.030898
 >> iter 13000, loss: 0.028452
 >> iter 14000, loss: 0.029654
 >> iter 15000, loss: 0.029425
 >> iter 16000, loss: 0.031015
 >> iter 17000, loss: 0.029807
 >> iter 18000, loss: 0.029039
 >> iter 19000, loss: 0.030048
 >> iter 20000, loss: 0.032846
   Number of active neurons: 4
 >> iter 21000, loss: 0.029666
 >> iter 22000, loss: 0.033086
 >> iter 23000, loss: 0.029848
 >> iter 24000, loss: 0.025572
 >> iter 25000, loss: 0.028848
 >> iter 26000, loss: 0.028015
 >> iter 27000, loss: 0.043920
 >> iter 28000, loss: 0.056401
 >> iter 29000, loss: 0.043409
 >> iter 30000, loss: 0.035453
   Number of active neurons: 3
 >> iter 31000, loss: 0.027555
 >> iter 32000, loss: 0.029029
 >> iter 33000, loss: 0.026174
 >> iter 34000, loss: 0.024636
 >> iter 35000, loss: 0.023842
 >> iter 36000, loss: 0.024239
 >> iter 37000, loss: 0.027107
 >> iter 38000, loss: 0.023989
 >> iter 39000, loss: 0.023858
 >> iter 40000, loss: 0.027016
   Number of active neurons: 3
 >> iter 41000, loss: 0.028797
 >> iter 42000, loss: 0.024481
 >> iter 43000, loss: 0.023823
 >> iter 44000, loss: 0.025842
 >> iter 45000, loss: 0.027304
 >> iter 46000, loss: 0.042772
 >> iter 47000, loss: 0.037032
 >> iter 48000, loss: 0.028991
 >> iter 49000, loss: 0.025032
 >> iter 50000, loss: 0.023082
   Number of active neurons: 2
 >> iter 51000, loss: 0.023535
 >> iter 52000, loss: 0.026284
 >> iter 53000, loss: 0.022021
 >> iter 54000, loss: 0.020487
 >> iter 55000, loss: 0.022545
 >> iter 56000, loss: 0.027673
 >> iter 57000, loss: 0.023734
 >> iter 58000, loss: 0.022172
 >> iter 59000, loss: 0.030774
 >> iter 60000, loss: 0.022686
   Number of active neurons: 1
 >> iter 61000, loss: 0.027092
 >> iter 62000, loss: 0.022018
 >> iter 63000, loss: 0.019434
 >> iter 64000, loss: 0.017714
 >> iter 65000, loss: 0.019209
 >> iter 66000, loss: 0.017858
 >> iter 67000, loss: 0.017454
 >> iter 68000, loss: 0.019250
 >> iter 69000, loss: 0.018823
 >> iter 70000, loss: 0.034535
   Number of active neurons: 1
 >> iter 71000, loss: 0.022879
 >> iter 72000, loss: 0.033256
 >> iter 73000, loss: 0.021639
 >> iter 74000, loss: 0.052819
 >> iter 75000, loss: 0.034235
 >> iter 76000, loss: 0.025268
 >> iter 77000, loss: 0.018857
 >> iter 78000, loss: 0.018019
 >> iter 79000, loss: 0.018490
 >> iter 80000, loss: 0.020541
   Number of active neurons: 1
 >> iter 81000, loss: 0.017197
 >> iter 82000, loss: 0.020120
 >> iter 83000, loss: 0.018935
 >> iter 84000, loss: 0.022459
 >> iter 85000, loss: 0.018570
 >> iter 86000, loss: 0.026239
 >> iter 87000, loss: 0.025047
 >> iter 88000, loss: 0.025787
 >> iter 89000, loss: 0.019855
 >> iter 90000, loss: 0.025742
   Number of active neurons: 1
 >> iter 91000, loss: 0.020728
 >> iter 92000, loss: 0.019518
 >> iter 93000, loss: 0.019537
 >> iter 94000, loss: 0.017456
 >> iter 95000, loss: 0.022213
 >> iter 96000, loss: 0.023117
 >> iter 97000, loss: 0.020277
 >> iter 98000, loss: 0.017849
 >> iter 99000, loss: 0.020228
 >> iter 100000, loss: 0.017969
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.054991
 >> iter 2000, loss: 4.135969
 >> iter 3000, loss: 1.553482
 >> iter 4000, loss: 0.600772
 >> iter 5000, loss: 0.256807
 >> iter 6000, loss: 0.118529
 >> iter 7000, loss: 0.072445
 >> iter 8000, loss: 0.046183
 >> iter 9000, loss: 0.043804
 >> iter 10000, loss: 0.038369
   Number of active neurons: 6
 >> iter 11000, loss: 0.034551
 >> iter 12000, loss: 0.031474
 >> iter 13000, loss: 0.031936
 >> iter 14000, loss: 0.039777
 >> iter 15000, loss: 0.034644
 >> iter 16000, loss: 0.029292
 >> iter 17000, loss: 0.034251
 >> iter 18000, loss: 0.030554
 >> iter 19000, loss: 0.033959
 >> iter 20000, loss: 0.028600
   Number of active neurons: 5
 >> iter 21000, loss: 0.030528
 >> iter 22000, loss: 0.038132
 >> iter 23000, loss: 0.032114
 >> iter 24000, loss: 0.028158
 >> iter 25000, loss: 0.028048
 >> iter 26000, loss: 0.030601
 >> iter 27000, loss: 0.027170
 >> iter 28000, loss: 0.024968
 >> iter 29000, loss: 0.030862
 >> iter 30000, loss: 0.027356
   Number of active neurons: 4
 >> iter 31000, loss: 0.026134
 >> iter 32000, loss: 0.029778
 >> iter 33000, loss: 0.030288
 >> iter 34000, loss: 0.025927
 >> iter 35000, loss: 0.025568
 >> iter 36000, loss: 0.028887
 >> iter 37000, loss: 0.033383
 >> iter 38000, loss: 0.027328
 >> iter 39000, loss: 0.028599
 >> iter 40000, loss: 0.030349
   Number of active neurons: 3
 >> iter 41000, loss: 0.028858
 >> iter 42000, loss: 0.024749
 >> iter 43000, loss: 0.024508
 >> iter 44000, loss: 0.026794
 >> iter 45000, loss: 0.023670
 >> iter 46000, loss: 0.026632
 >> iter 47000, loss: 0.024568
 >> iter 48000, loss: 0.027717
 >> iter 49000, loss: 0.024334
 >> iter 50000, loss: 0.021463
   Number of active neurons: 2
 >> iter 51000, loss: 0.020671
 >> iter 52000, loss: 0.022824
 >> iter 53000, loss: 0.022671
 >> iter 54000, loss: 0.021230
 >> iter 55000, loss: 0.021999
 >> iter 56000, loss: 0.024148
 >> iter 57000, loss: 0.020634
 >> iter 58000, loss: 0.030696
 >> iter 59000, loss: 0.029601
 >> iter 60000, loss: 0.028920
   Number of active neurons: 2
 >> iter 61000, loss: 0.023496
 >> iter 62000, loss: 0.023768
 >> iter 63000, loss: 0.024128
 >> iter 64000, loss: 0.027195
 >> iter 65000, loss: 0.026534
 >> iter 66000, loss: 0.022376
 >> iter 67000, loss: 0.020478
 >> iter 68000, loss: 0.021105
 >> iter 69000, loss: 0.020496
 >> iter 70000, loss: 0.023568
   Number of active neurons: 2
 >> iter 71000, loss: 0.021222
 >> iter 72000, loss: 0.024984
 >> iter 73000, loss: 0.023218
 >> iter 74000, loss: 0.024158
 >> iter 75000, loss: 0.021548
 >> iter 76000, loss: 0.026367
 >> iter 77000, loss: 0.021948
 >> iter 78000, loss: 0.020635
 >> iter 79000, loss: 0.025909
 >> iter 80000, loss: 0.026900
   Number of active neurons: 2
 >> iter 81000, loss: 0.022267
 >> iter 82000, loss: 0.025749
 >> iter 83000, loss: 0.023530
 >> iter 84000, loss: 0.020666
 >> iter 85000, loss: 0.021244
 >> iter 86000, loss: 0.034232
 >> iter 87000, loss: 0.041654
 >> iter 88000, loss: 0.047065
 >> iter 89000, loss: 0.031410
 >> iter 90000, loss: 0.025897
   Number of active neurons: 2
 >> iter 91000, loss: 0.021880
 >> iter 92000, loss: 0.027691
 >> iter 93000, loss: 0.023851
 >> iter 94000, loss: 0.022709
 >> iter 95000, loss: 0.042105
 >> iter 96000, loss: 0.029564
 >> iter 97000, loss: 0.031200
 >> iter 98000, loss: 0.025572
 >> iter 99000, loss: 0.023791
 >> iter 100000, loss: 0.020385
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.020660
 >> iter 2000, loss: 4.104378
 >> iter 3000, loss: 1.551391
 >> iter 4000, loss: 0.593083
 >> iter 5000, loss: 0.254774
 >> iter 6000, loss: 0.111545
 >> iter 7000, loss: 0.062798
 >> iter 8000, loss: 0.045478
 >> iter 9000, loss: 0.043482
 >> iter 10000, loss: 0.037465
   Number of active neurons: 5
 >> iter 11000, loss: 0.040804
 >> iter 12000, loss: 0.041406
 >> iter 13000, loss: 0.036193
 >> iter 14000, loss: 0.031403
 >> iter 15000, loss: 0.029838
 >> iter 16000, loss: 0.032742
 >> iter 17000, loss: 0.028282
 >> iter 18000, loss: 0.028543
 >> iter 19000, loss: 0.030832
 >> iter 20000, loss: 0.031286
   Number of active neurons: 4
 >> iter 21000, loss: 0.033916
 >> iter 22000, loss: 0.029118
 >> iter 23000, loss: 0.025875
 >> iter 24000, loss: 0.027660
 >> iter 25000, loss: 0.024979
 >> iter 26000, loss: 0.026718
 >> iter 27000, loss: 0.027976
 >> iter 28000, loss: 0.024280
 >> iter 29000, loss: 0.028868
 >> iter 30000, loss: 0.024686
   Number of active neurons: 3
 >> iter 31000, loss: 0.023176
 >> iter 32000, loss: 0.023747
 >> iter 33000, loss: 0.031602
 >> iter 34000, loss: 0.035671
 >> iter 35000, loss: 0.029978
 >> iter 36000, loss: 0.028477
 >> iter 37000, loss: 0.025628
 >> iter 38000, loss: 0.024361
 >> iter 39000, loss: 0.032059
 >> iter 40000, loss: 0.024829
   Number of active neurons: 3
 >> iter 41000, loss: 0.024001
 >> iter 42000, loss: 0.024825
 >> iter 43000, loss: 0.023129
 >> iter 44000, loss: 0.031712
 >> iter 45000, loss: 0.025546
 >> iter 46000, loss: 0.028146
 >> iter 47000, loss: 0.024097
 >> iter 48000, loss: 0.027203
 >> iter 49000, loss: 0.022930
 >> iter 50000, loss: 0.021783
   Number of active neurons: 2
 >> iter 51000, loss: 0.030441
 >> iter 52000, loss: 0.029819
 >> iter 53000, loss: 0.049263
 >> iter 54000, loss: 0.032926
 >> iter 55000, loss: 0.052183
 >> iter 56000, loss: 0.034419
 >> iter 57000, loss: 0.025709
 >> iter 58000, loss: 0.023366
 >> iter 59000, loss: 0.039721
 >> iter 60000, loss: 0.028793
   Number of active neurons: 2
 >> iter 61000, loss: 0.032061
 >> iter 62000, loss: 0.029337
 >> iter 63000, loss: 0.024060
 >> iter 64000, loss: 0.022066
 >> iter 65000, loss: 0.026849
 >> iter 66000, loss: 0.023313
 >> iter 67000, loss: 0.021937
 >> iter 68000, loss: 0.022222
 >> iter 69000, loss: 0.027800
 >> iter 70000, loss: 0.034814
   Number of active neurons: 2
 >> iter 71000, loss: 0.025165
 >> iter 72000, loss: 0.023193
 >> iter 73000, loss: 0.020153
 >> iter 74000, loss: 0.019653
 >> iter 75000, loss: 0.023163
 >> iter 76000, loss: 0.019253
 >> iter 77000, loss: 0.023340
 >> iter 78000, loss: 0.019307
 >> iter 79000, loss: 0.028633
 >> iter 80000, loss: 0.031324
   Number of active neurons: 1
 >> iter 81000, loss: 0.030006
 >> iter 82000, loss: 0.022308
 >> iter 83000, loss: 0.021493
 >> iter 84000, loss: 0.023833
 >> iter 85000, loss: 0.023097
 >> iter 86000, loss: 0.018428
 >> iter 87000, loss: 0.020605
 >> iter 88000, loss: 0.018676
 >> iter 89000, loss: 0.018284
 >> iter 90000, loss: 0.020802
   Number of active neurons: 1
 >> iter 91000, loss: 0.017915
 >> iter 92000, loss: 0.023477
 >> iter 93000, loss: 0.022051
 >> iter 94000, loss: 0.018028
 >> iter 95000, loss: 0.018994
 >> iter 96000, loss: 0.023443
 >> iter 97000, loss: 0.020307
 >> iter 98000, loss: 0.020009
 >> iter 99000, loss: 0.029662
 >> iter 100000, loss: 0.026547
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 10.974799
 >> iter 2000, loss: 4.088991
 >> iter 3000, loss: 1.536204
 >> iter 4000, loss: 0.592165
 >> iter 5000, loss: 0.251906
 >> iter 6000, loss: 0.111833
 >> iter 7000, loss: 0.064906
 >> iter 8000, loss: 0.062438
 >> iter 9000, loss: 0.041128
 >> iter 10000, loss: 0.040228
   Number of active neurons: 5
 >> iter 11000, loss: 0.038135
 >> iter 12000, loss: 0.032155
 >> iter 13000, loss: 0.033676
 >> iter 14000, loss: 0.033962
 >> iter 15000, loss: 0.037666
 >> iter 16000, loss: 0.033501
 >> iter 17000, loss: 0.029960
 >> iter 18000, loss: 0.026453
 >> iter 19000, loss: 0.025238
 >> iter 20000, loss: 0.025160
   Number of active neurons: 3
 >> iter 21000, loss: 0.031569
 >> iter 22000, loss: 0.027577
 >> iter 23000, loss: 0.026006
 >> iter 24000, loss: 0.023973
 >> iter 25000, loss: 0.021301
 >> iter 26000, loss: 0.036666
 >> iter 27000, loss: 0.026266
 >> iter 28000, loss: 0.024180
 >> iter 29000, loss: 0.031625
 >> iter 30000, loss: 0.024272
   Number of active neurons: 2
 >> iter 31000, loss: 0.024532
 >> iter 32000, loss: 0.022784
 >> iter 33000, loss: 0.021278
 >> iter 34000, loss: 0.021151
 >> iter 35000, loss: 0.020936
 >> iter 36000, loss: 0.033617
 >> iter 37000, loss: 0.025188
 >> iter 38000, loss: 0.021107
 >> iter 39000, loss: 0.035743
 >> iter 40000, loss: 0.028819
   Number of active neurons: 2
 >> iter 41000, loss: 0.026798
 >> iter 42000, loss: 0.036929
 >> iter 43000, loss: 0.028577
 >> iter 44000, loss: 0.030398
 >> iter 45000, loss: 0.025125
 >> iter 46000, loss: 0.035116
 >> iter 47000, loss: 0.027796
 >> iter 48000, loss: 0.027917
 >> iter 49000, loss: 0.025302
 >> iter 50000, loss: 0.037973
   Number of active neurons: 2
 >> iter 51000, loss: 0.025698
 >> iter 52000, loss: 0.023030
 >> iter 53000, loss: 0.029356
 >> iter 54000, loss: 0.024959
 >> iter 55000, loss: 0.023432
 >> iter 56000, loss: 0.022631
 >> iter 57000, loss: 0.022246
 >> iter 58000, loss: 0.028466
 >> iter 59000, loss: 0.027383
 >> iter 60000, loss: 0.026064
   Number of active neurons: 2
 >> iter 61000, loss: 0.023379
 >> iter 62000, loss: 0.034405
 >> iter 63000, loss: 0.033231
 >> iter 64000, loss: 0.025428
 >> iter 65000, loss: 0.031554
 >> iter 66000, loss: 0.030064
 >> iter 67000, loss: 0.024845
 >> iter 68000, loss: 0.021147
 >> iter 69000, loss: 0.028498
 >> iter 70000, loss: 0.029619
   Number of active neurons: 1
 >> iter 71000, loss: 0.023479
 >> iter 72000, loss: 0.024376
 >> iter 73000, loss: 0.018974
 >> iter 74000, loss: 0.056068
 >> iter 75000, loss: 0.033195
 >> iter 76000, loss: 0.024871
 >> iter 77000, loss: 0.051891
 >> iter 78000, loss: 0.038472
 >> iter 79000, loss: 0.025602
 >> iter 80000, loss: 0.050370
   Number of active neurons: 1
 >> iter 81000, loss: 0.033185
 >> iter 82000, loss: 0.023484
 >> iter 83000, loss: 0.019525
 >> iter 84000, loss: 0.017163
 >> iter 85000, loss: 0.017281
 >> iter 86000, loss: 0.031271
 >> iter 87000, loss: 0.022921
 >> iter 88000, loss: 0.024538
 >> iter 89000, loss: 0.019218
 >> iter 90000, loss: 0.019574
   Number of active neurons: 1
 >> iter 91000, loss: 0.018982
 >> iter 92000, loss: 0.017661
 >> iter 93000, loss: 0.038689
 >> iter 94000, loss: 0.030210
 >> iter 95000, loss: 0.027514
 >> iter 96000, loss: 0.028064
 >> iter 97000, loss: 0.029918
 >> iter 98000, loss: 0.022705
 >> iter 99000, loss: 0.021434
 >> iter 100000, loss: 0.022949
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 10.962084
 >> iter 2000, loss: 4.108812
 >> iter 3000, loss: 1.547963
 >> iter 4000, loss: 0.591071
 >> iter 5000, loss: 0.241734
 >> iter 6000, loss: 0.111061
 >> iter 7000, loss: 0.064354
 >> iter 8000, loss: 0.045373
 >> iter 9000, loss: 0.037755
 >> iter 10000, loss: 0.033929
   Number of active neurons: 5
 >> iter 11000, loss: 0.032191
 >> iter 12000, loss: 0.028001
 >> iter 13000, loss: 0.027912
 >> iter 14000, loss: 0.026265
 >> iter 15000, loss: 0.026909
 >> iter 16000, loss: 0.026918
 >> iter 17000, loss: 0.027006
 >> iter 18000, loss: 0.027304
 >> iter 19000, loss: 0.024170
 >> iter 20000, loss: 0.026232
   Number of active neurons: 3
 >> iter 21000, loss: 0.032210
 >> iter 22000, loss: 0.027569
 >> iter 23000, loss: 0.026163
 >> iter 24000, loss: 0.024568
 >> iter 25000, loss: 0.032777
 >> iter 26000, loss: 0.026624
 >> iter 27000, loss: 0.023390
 >> iter 28000, loss: 0.029646
 >> iter 29000, loss: 0.025243
 >> iter 30000, loss: 0.027986
   Number of active neurons: 3
 >> iter 31000, loss: 0.025010
 >> iter 32000, loss: 0.022892
 >> iter 33000, loss: 0.023125
 >> iter 34000, loss: 0.024082
 >> iter 35000, loss: 0.021254
 >> iter 36000, loss: 0.023624
 >> iter 37000, loss: 0.020350
 >> iter 38000, loss: 0.021405
 >> iter 39000, loss: 0.022011
 >> iter 40000, loss: 0.026042
   Number of active neurons: 2
 >> iter 41000, loss: 0.023640
 >> iter 42000, loss: 0.023997
 >> iter 43000, loss: 0.022289
 >> iter 44000, loss: 0.024853
 >> iter 45000, loss: 0.022769
 >> iter 46000, loss: 0.021810
 >> iter 47000, loss: 0.022070
 >> iter 48000, loss: 0.023190
 >> iter 49000, loss: 0.024375
 >> iter 50000, loss: 0.021106
   Number of active neurons: 2
 >> iter 51000, loss: 0.022586
 >> iter 52000, loss: 0.024608
 >> iter 53000, loss: 0.023834
 >> iter 54000, loss: 0.022079
 >> iter 55000, loss: 0.021825
 >> iter 56000, loss: 0.020637
 >> iter 57000, loss: 0.020632
 >> iter 58000, loss: 0.020846
 >> iter 59000, loss: 0.030577
 >> iter 60000, loss: 0.024431
   Number of active neurons: 2
 >> iter 61000, loss: 0.021774
 >> iter 62000, loss: 0.020068
 >> iter 63000, loss: 0.020242
 >> iter 64000, loss: 0.023509
 >> iter 65000, loss: 0.022714
 >> iter 66000, loss: 0.024971
 >> iter 67000, loss: 0.021730
 >> iter 68000, loss: 0.038020
 >> iter 69000, loss: 0.029832
 >> iter 70000, loss: 0.026412
   Number of active neurons: 2
 >> iter 71000, loss: 0.026438
 >> iter 72000, loss: 0.024358
 >> iter 73000, loss: 0.030365
 >> iter 74000, loss: 0.022762
 >> iter 75000, loss: 0.022243
 >> iter 76000, loss: 0.019899
 >> iter 77000, loss: 0.019758
 >> iter 78000, loss: 0.023657
 >> iter 79000, loss: 0.025264
 >> iter 80000, loss: 0.027430
   Number of active neurons: 2
 >> iter 81000, loss: 0.023764
 >> iter 82000, loss: 0.027009
 >> iter 83000, loss: 0.023745
 >> iter 84000, loss: 0.021176
 >> iter 85000, loss: 0.026783
 >> iter 86000, loss: 0.029242
 >> iter 87000, loss: 0.028989
 >> iter 88000, loss: 0.024797
 >> iter 89000, loss: 0.048993
 >> iter 90000, loss: 0.031442
   Number of active neurons: 2
 >> iter 91000, loss: 0.027275
 >> iter 92000, loss: 0.026634
 >> iter 93000, loss: 0.022046
 >> iter 94000, loss: 0.021146
 >> iter 95000, loss: 0.022165
 >> iter 96000, loss: 0.021536
 >> iter 97000, loss: 0.022108
 >> iter 98000, loss: 0.022228
 >> iter 99000, loss: 0.027193
 >> iter 100000, loss: 0.027024
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.945480
 >> iter 2000, loss: 4.077485
 >> iter 3000, loss: 1.541716
 >> iter 4000, loss: 0.593078
 >> iter 5000, loss: 0.242180
 >> iter 6000, loss: 0.113994
 >> iter 7000, loss: 0.073215
 >> iter 8000, loss: 0.048042
 >> iter 9000, loss: 0.048839
 >> iter 10000, loss: 0.044461
   Number of active neurons: 4
 >> iter 11000, loss: 0.048169
 >> iter 12000, loss: 0.035364
 >> iter 13000, loss: 0.028639
 >> iter 14000, loss: 0.027942
 >> iter 15000, loss: 0.027293
 >> iter 16000, loss: 0.029304
 >> iter 17000, loss: 0.026854
 >> iter 18000, loss: 0.030508
 >> iter 19000, loss: 0.027058
 >> iter 20000, loss: 0.025253
   Number of active neurons: 4
 >> iter 21000, loss: 0.037688
 >> iter 22000, loss: 0.041749
 >> iter 23000, loss: 0.031972
 >> iter 24000, loss: 0.039199
 >> iter 25000, loss: 0.032895
 >> iter 26000, loss: 0.029962
 >> iter 27000, loss: 0.026759
 >> iter 28000, loss: 0.027151
 >> iter 29000, loss: 0.025347
 >> iter 30000, loss: 0.025856
   Number of active neurons: 3
 >> iter 31000, loss: 0.030012
 >> iter 32000, loss: 0.024894
 >> iter 33000, loss: 0.030362
 >> iter 34000, loss: 0.035395
 >> iter 35000, loss: 0.052752
 >> iter 36000, loss: 0.041725
 >> iter 37000, loss: 0.029523
 >> iter 38000, loss: 0.040001
 >> iter 39000, loss: 0.034992
 >> iter 40000, loss: 0.034463
   Number of active neurons: 2
 >> iter 41000, loss: 0.028638
 >> iter 42000, loss: 0.024934
 >> iter 43000, loss: 0.024037
 >> iter 44000, loss: 0.023112
 >> iter 45000, loss: 0.020918
 >> iter 46000, loss: 0.023075
 >> iter 47000, loss: 0.032990
 >> iter 48000, loss: 0.027199
 >> iter 49000, loss: 0.023982
 >> iter 50000, loss: 0.021869
   Number of active neurons: 2
 >> iter 51000, loss: 0.026979
 >> iter 52000, loss: 0.023192
 >> iter 53000, loss: 0.020306
 >> iter 54000, loss: 0.025742
 >> iter 55000, loss: 0.029526
 >> iter 56000, loss: 0.023749
 >> iter 57000, loss: 0.025636
 >> iter 58000, loss: 0.022144
 >> iter 59000, loss: 0.027471
 >> iter 60000, loss: 0.028302
   Number of active neurons: 2
 >> iter 61000, loss: 0.026154
 >> iter 62000, loss: 0.024718
 >> iter 63000, loss: 0.025057
 >> iter 64000, loss: 0.021319
 >> iter 65000, loss: 0.021074
 >> iter 66000, loss: 0.020071
 >> iter 67000, loss: 0.026705
 >> iter 68000, loss: 0.025502
 >> iter 69000, loss: 0.026149
 >> iter 70000, loss: 0.034383
   Number of active neurons: 2
 >> iter 71000, loss: 0.025992
 >> iter 72000, loss: 0.028019
 >> iter 73000, loss: 0.023591
 >> iter 74000, loss: 0.021346
 >> iter 75000, loss: 0.026144
 >> iter 76000, loss: 0.022753
 >> iter 77000, loss: 0.024058
 >> iter 78000, loss: 0.027401
 >> iter 79000, loss: 0.054359
 >> iter 80000, loss: 0.051089
   Number of active neurons: 2
 >> iter 81000, loss: 0.031787
 >> iter 82000, loss: 0.036774
 >> iter 83000, loss: 0.025870
 >> iter 84000, loss: 0.022761
 >> iter 85000, loss: 0.020595
 >> iter 86000, loss: 0.019447
 >> iter 87000, loss: 0.023858
 >> iter 88000, loss: 0.021782
 >> iter 89000, loss: 0.022678
 >> iter 90000, loss: 0.019866
   Number of active neurons: 1
 >> iter 91000, loss: 0.018980
 >> iter 92000, loss: 0.028947
 >> iter 93000, loss: 0.022406
 >> iter 94000, loss: 0.019244
 >> iter 95000, loss: 0.022242
 >> iter 96000, loss: 0.020452
 >> iter 97000, loss: 0.027141
 >> iter 98000, loss: 0.023751
 >> iter 99000, loss: 0.018424
 >> iter 100000, loss: 0.020936
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.939296
 >> iter 2000, loss: 4.079805
 >> iter 3000, loss: 1.580576
 >> iter 4000, loss: 0.604592
 >> iter 5000, loss: 0.246053
 >> iter 6000, loss: 0.112900
 >> iter 7000, loss: 0.069919
 >> iter 8000, loss: 0.045930
 >> iter 9000, loss: 0.036585
 >> iter 10000, loss: 0.038495
   Number of active neurons: 4
 >> iter 11000, loss: 0.033068
 >> iter 12000, loss: 0.028540
 >> iter 13000, loss: 0.027778
 >> iter 14000, loss: 0.027444
 >> iter 15000, loss: 0.028595
 >> iter 16000, loss: 0.027992
 >> iter 17000, loss: 0.027222
 >> iter 18000, loss: 0.031425
 >> iter 19000, loss: 0.026638
 >> iter 20000, loss: 0.025751
   Number of active neurons: 3
 >> iter 21000, loss: 0.025033
 >> iter 22000, loss: 0.023624
 >> iter 23000, loss: 0.039771
 >> iter 24000, loss: 0.028224
 >> iter 25000, loss: 0.026388
 >> iter 26000, loss: 0.037226
 >> iter 27000, loss: 0.035331
 >> iter 28000, loss: 0.029292
 >> iter 29000, loss: 0.023010
 >> iter 30000, loss: 0.042155
   Number of active neurons: 2
 >> iter 31000, loss: 0.031584
 >> iter 32000, loss: 0.023977
 >> iter 33000, loss: 0.023009
 >> iter 34000, loss: 0.028950
 >> iter 35000, loss: 0.028164
 >> iter 36000, loss: 0.034242
 >> iter 37000, loss: 0.026426
 >> iter 38000, loss: 0.027105
 >> iter 39000, loss: 0.040686
 >> iter 40000, loss: 0.033827
   Number of active neurons: 2
 >> iter 41000, loss: 0.032974
 >> iter 42000, loss: 0.027062
 >> iter 43000, loss: 0.056209
 >> iter 44000, loss: 0.038086
 >> iter 45000, loss: 0.035595
 >> iter 46000, loss: 0.031914
 >> iter 47000, loss: 0.032164
 >> iter 48000, loss: 0.029134
 >> iter 49000, loss: 0.024480
 >> iter 50000, loss: 0.021592
   Number of active neurons: 2
 >> iter 51000, loss: 0.021124
 >> iter 52000, loss: 0.020705
 >> iter 53000, loss: 0.030384
 >> iter 54000, loss: 0.040634
 >> iter 55000, loss: 0.035331
 >> iter 56000, loss: 0.026542
 >> iter 57000, loss: 0.036346
 >> iter 58000, loss: 0.027046
 >> iter 59000, loss: 0.025250
 >> iter 60000, loss: 0.022072
   Number of active neurons: 1
 >> iter 61000, loss: 0.023850
 >> iter 62000, loss: 0.020350
 >> iter 63000, loss: 0.048940
 >> iter 64000, loss: 0.033929
 >> iter 65000, loss: 0.038615
 >> iter 66000, loss: 0.033107
 >> iter 67000, loss: 0.048243
 >> iter 68000, loss: 0.028808
 >> iter 69000, loss: 0.025494
 >> iter 70000, loss: 0.023692
   Number of active neurons: 1
 >> iter 71000, loss: 0.021481
 >> iter 72000, loss: 0.018889
 >> iter 73000, loss: 0.016580
 >> iter 74000, loss: 0.018482
 >> iter 75000, loss: 0.022596
 >> iter 76000, loss: 0.040967
 >> iter 77000, loss: 0.028411
 >> iter 78000, loss: 0.021180
 >> iter 79000, loss: 0.017804
 >> iter 80000, loss: 0.017487
   Number of active neurons: 1
 >> iter 81000, loss: 0.016243
 >> iter 82000, loss: 0.033395
 >> iter 83000, loss: 0.023741
 >> iter 84000, loss: 0.019278
 >> iter 85000, loss: 0.020831
 >> iter 86000, loss: 0.016889
 >> iter 87000, loss: 0.017849
 >> iter 88000, loss: 0.016887
 >> iter 89000, loss: 0.018964
 >> iter 90000, loss: 0.019931
   Number of active neurons: 1
 >> iter 91000, loss: 0.019442
 >> iter 92000, loss: 0.017639
 >> iter 93000, loss: 0.017480
 >> iter 94000, loss: 0.021787
 >> iter 95000, loss: 0.047286
 >> iter 96000, loss: 0.031857
 >> iter 97000, loss: 0.027542
 >> iter 98000, loss: 0.020765
 >> iter 99000, loss: 0.020431
 >> iter 100000, loss: 0.016523
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 10.905074
 >> iter 2000, loss: 4.051658
 >> iter 3000, loss: 1.530491
 >> iter 4000, loss: 0.584664
 >> iter 5000, loss: 0.243004
 >> iter 6000, loss: 0.109517
 >> iter 7000, loss: 0.066380
 >> iter 8000, loss: 0.057817
 >> iter 9000, loss: 0.040744
 >> iter 10000, loss: 0.034997
   Number of active neurons: 3
 >> iter 11000, loss: 0.027950
 >> iter 12000, loss: 0.026597
 >> iter 13000, loss: 0.024524
 >> iter 14000, loss: 0.023495
 >> iter 15000, loss: 0.024552
 >> iter 16000, loss: 0.026255
 >> iter 17000, loss: 0.026186
 >> iter 18000, loss: 0.021732
 >> iter 19000, loss: 0.024006
 >> iter 20000, loss: 0.022988
   Number of active neurons: 2
 >> iter 21000, loss: 0.021694
 >> iter 22000, loss: 0.027113
 >> iter 23000, loss: 0.022179
 >> iter 24000, loss: 0.022561
 >> iter 25000, loss: 0.027424
 >> iter 26000, loss: 0.024407
 >> iter 27000, loss: 0.020934
 >> iter 28000, loss: 0.019218
 >> iter 29000, loss: 0.020968
 >> iter 30000, loss: 0.020220
   Number of active neurons: 2
 >> iter 31000, loss: 0.025450
 >> iter 32000, loss: 0.022781
 >> iter 33000, loss: 0.020568
 >> iter 34000, loss: 0.029569
 >> iter 35000, loss: 0.024460
 >> iter 36000, loss: 0.026020
 >> iter 37000, loss: 0.025303
 >> iter 38000, loss: 0.024045
 >> iter 39000, loss: 0.026765
 >> iter 40000, loss: 0.022414
   Number of active neurons: 2
 >> iter 41000, loss: 0.021022
 >> iter 42000, loss: 0.025654
 >> iter 43000, loss: 0.023557
 >> iter 44000, loss: 0.021497
 >> iter 45000, loss: 0.022101
 >> iter 46000, loss: 0.022509
 >> iter 47000, loss: 0.020697
 >> iter 48000, loss: 0.023256
 >> iter 49000, loss: 0.025036
 >> iter 50000, loss: 0.020426
   Number of active neurons: 2
 >> iter 51000, loss: 0.022178
 >> iter 52000, loss: 0.020592
 >> iter 53000, loss: 0.022019
 >> iter 54000, loss: 0.023467
 >> iter 55000, loss: 0.032023
 >> iter 56000, loss: 0.026404
 >> iter 57000, loss: 0.023083
 >> iter 58000, loss: 0.026459
 >> iter 59000, loss: 0.028027
 >> iter 60000, loss: 0.022678
   Number of active neurons: 2
 >> iter 61000, loss: 0.025637
 >> iter 62000, loss: 0.024078
 >> iter 63000, loss: 0.022306
 >> iter 64000, loss: 0.020603
 >> iter 65000, loss: 0.027655
 >> iter 66000, loss: 0.023403
 >> iter 67000, loss: 0.024335
 >> iter 68000, loss: 0.024106
 >> iter 69000, loss: 0.032067
 >> iter 70000, loss: 0.026687
   Number of active neurons: 2
 >> iter 71000, loss: 0.024439
 >> iter 72000, loss: 0.023493
 >> iter 73000, loss: 0.021085
 >> iter 74000, loss: 0.021871
 >> iter 75000, loss: 0.039709
 >> iter 76000, loss: 0.032867
 >> iter 77000, loss: 0.024209
 >> iter 78000, loss: 0.024745
 >> iter 79000, loss: 0.022832
 >> iter 80000, loss: 0.021381
   Number of active neurons: 2
 >> iter 81000, loss: 0.021099
 >> iter 82000, loss: 0.019745
 >> iter 83000, loss: 0.021384
 >> iter 84000, loss: 0.035638
 >> iter 85000, loss: 0.026159
 >> iter 86000, loss: 0.030582
 >> iter 87000, loss: 0.025209
 >> iter 88000, loss: 0.040812
 >> iter 89000, loss: 0.028186
 >> iter 90000, loss: 0.022286
   Number of active neurons: 2
 >> iter 91000, loss: 0.022000
 >> iter 92000, loss: 0.020744
 >> iter 93000, loss: 0.032248
 >> iter 94000, loss: 0.024201
 >> iter 95000, loss: 0.023547
 >> iter 96000, loss: 0.020996
 >> iter 97000, loss: 0.020843
 >> iter 98000, loss: 0.024362
 >> iter 99000, loss: 0.021759
 >> iter 100000, loss: 0.020546
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.896772
 >> iter 2000, loss: 4.050744
 >> iter 3000, loss: 1.558567
 >> iter 4000, loss: 0.600817
 >> iter 5000, loss: 0.241867
 >> iter 6000, loss: 0.120458
 >> iter 7000, loss: 0.071133
 >> iter 8000, loss: 0.045746
 >> iter 9000, loss: 0.044267
 >> iter 10000, loss: 0.040516
   Number of active neurons: 5
 >> iter 11000, loss: 0.036848
 >> iter 12000, loss: 0.036889
 >> iter 13000, loss: 0.030750
 >> iter 14000, loss: 0.028448
 >> iter 15000, loss: 0.040794
 >> iter 16000, loss: 0.030133
 >> iter 17000, loss: 0.029286
 >> iter 18000, loss: 0.026677
 >> iter 19000, loss: 0.025758
 >> iter 20000, loss: 0.053839
   Number of active neurons: 3
 >> iter 21000, loss: 0.038441
 >> iter 22000, loss: 0.034239
 >> iter 23000, loss: 0.033170
 >> iter 24000, loss: 0.029482
 >> iter 25000, loss: 0.040572
 >> iter 26000, loss: 0.029783
 >> iter 27000, loss: 0.029794
 >> iter 28000, loss: 0.031118
 >> iter 29000, loss: 0.035767
 >> iter 30000, loss: 0.040085
   Number of active neurons: 3
 >> iter 31000, loss: 0.037496
 >> iter 32000, loss: 0.032210
 >> iter 33000, loss: 0.029480
 >> iter 34000, loss: 0.032239
 >> iter 35000, loss: 0.026876
 >> iter 36000, loss: 0.040490
 >> iter 37000, loss: 0.029566
 >> iter 38000, loss: 0.025044
 >> iter 39000, loss: 0.027148
 >> iter 40000, loss: 0.033642
   Number of active neurons: 2
 >> iter 41000, loss: 0.027986
 >> iter 42000, loss: 0.022870
 >> iter 43000, loss: 0.021077
 >> iter 44000, loss: 0.021547
 >> iter 45000, loss: 0.026937
 >> iter 46000, loss: 0.028212
 >> iter 47000, loss: 0.022362
 >> iter 48000, loss: 0.022480
 >> iter 49000, loss: 0.036475
 >> iter 50000, loss: 0.024260
   Number of active neurons: 1
 >> iter 51000, loss: 0.025640
 >> iter 52000, loss: 0.027703
 >> iter 53000, loss: 0.042225
 >> iter 54000, loss: 0.027151
 >> iter 55000, loss: 0.019999
 >> iter 56000, loss: 0.035656
 >> iter 57000, loss: 0.032421
 >> iter 58000, loss: 0.023180
 >> iter 59000, loss: 0.019695
 >> iter 60000, loss: 0.020080
   Number of active neurons: 1
 >> iter 61000, loss: 0.035046
 >> iter 62000, loss: 0.023017
 >> iter 63000, loss: 0.033078
 >> iter 64000, loss: 0.024313
 >> iter 65000, loss: 0.019408
 >> iter 66000, loss: 0.018035
 >> iter 67000, loss: 0.018302
 >> iter 68000, loss: 0.017591
 >> iter 69000, loss: 0.039373
 >> iter 70000, loss: 0.029820
   Number of active neurons: 1
 >> iter 71000, loss: 0.023029
 >> iter 72000, loss: 0.023361
 >> iter 73000, loss: 0.022623
 >> iter 74000, loss: 0.018909
 >> iter 75000, loss: 0.019742
 >> iter 76000, loss: 0.017919
 >> iter 77000, loss: 0.016743
 >> iter 78000, loss: 0.018595
 >> iter 79000, loss: 0.017257
 >> iter 80000, loss: 0.018018
   Number of active neurons: 1
 >> iter 81000, loss: 0.025790
 >> iter 82000, loss: 0.021772
 >> iter 83000, loss: 0.017689
 >> iter 84000, loss: 0.019926
 >> iter 85000, loss: 0.023548
 >> iter 86000, loss: 0.019905
 >> iter 87000, loss: 0.018257
 >> iter 88000, loss: 0.021002
 >> iter 89000, loss: 0.028962
 >> iter 90000, loss: 0.023150
   Number of active neurons: 1
 >> iter 91000, loss: 0.021125
 >> iter 92000, loss: 0.021632
 >> iter 93000, loss: 0.032797
 >> iter 94000, loss: 0.029302
 >> iter 95000, loss: 0.021734
 >> iter 96000, loss: 0.017698
 >> iter 97000, loss: 0.019384
 >> iter 98000, loss: 0.017800
 >> iter 99000, loss: 0.016635
 >> iter 100000, loss: 0.019165
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455163
   Number of active neurons: 0
 >> iter 1000, loss: 10.969828
 >> iter 2000, loss: 4.085672
 >> iter 3000, loss: 1.536067
 >> iter 4000, loss: 0.592217
 >> iter 5000, loss: 0.279539
 >> iter 6000, loss: 0.128754
 >> iter 7000, loss: 0.067763
 >> iter 8000, loss: 0.051698
 >> iter 9000, loss: 0.054164
 >> iter 10000, loss: 0.039090
   Number of active neurons: 5
 >> iter 11000, loss: 0.033196
 >> iter 12000, loss: 0.031803
 >> iter 13000, loss: 0.028227
 >> iter 14000, loss: 0.035004
 >> iter 15000, loss: 0.030632
 >> iter 16000, loss: 0.025877
 >> iter 17000, loss: 0.024592
 >> iter 18000, loss: 0.025729
 >> iter 19000, loss: 0.026346
 >> iter 20000, loss: 0.023596
   Number of active neurons: 3
 >> iter 21000, loss: 0.040273
 >> iter 22000, loss: 0.036012
 >> iter 23000, loss: 0.028309
 >> iter 24000, loss: 0.028509
 >> iter 25000, loss: 0.034660
 >> iter 26000, loss: 0.027547
 >> iter 27000, loss: 0.024507
 >> iter 28000, loss: 0.026093
 >> iter 29000, loss: 0.024138
 >> iter 30000, loss: 0.023232
   Number of active neurons: 3
 >> iter 31000, loss: 0.028005
 >> iter 32000, loss: 0.025167
 >> iter 33000, loss: 0.046183
 >> iter 34000, loss: 0.031228
 >> iter 35000, loss: 0.032791
 >> iter 36000, loss: 0.028216
 >> iter 37000, loss: 0.026912
 >> iter 38000, loss: 0.023592
 >> iter 39000, loss: 0.033027
 >> iter 40000, loss: 0.029840
   Number of active neurons: 3
 >> iter 41000, loss: 0.025859
 >> iter 42000, loss: 0.036679
 >> iter 43000, loss: 0.035621
 >> iter 44000, loss: 0.047688
 >> iter 45000, loss: 0.034890
 >> iter 46000, loss: 0.027513
 >> iter 47000, loss: 0.026259
 >> iter 48000, loss: 0.025052
 >> iter 49000, loss: 0.038021
 >> iter 50000, loss: 0.030730
   Number of active neurons: 3
 >> iter 51000, loss: 0.029055
 >> iter 52000, loss: 0.028506
 >> iter 53000, loss: 0.025734
 >> iter 54000, loss: 0.025405
 >> iter 55000, loss: 0.023070
 >> iter 56000, loss: 0.026219
 >> iter 57000, loss: 0.023627
 >> iter 58000, loss: 0.035986
 >> iter 59000, loss: 0.029420
 >> iter 60000, loss: 0.024874
   Number of active neurons: 2
 >> iter 61000, loss: 0.024254
 >> iter 62000, loss: 0.024169
 >> iter 63000, loss: 0.025381
 >> iter 64000, loss: 0.021531
 >> iter 65000, loss: 0.024742
 >> iter 66000, loss: 0.050151
 >> iter 67000, loss: 0.033096
 >> iter 68000, loss: 0.028576
 >> iter 69000, loss: 0.030688
 >> iter 70000, loss: 0.028973
   Number of active neurons: 1
 >> iter 71000, loss: 0.023172
 >> iter 72000, loss: 0.018678
 >> iter 73000, loss: 0.019096
 >> iter 74000, loss: 0.026904
 >> iter 75000, loss: 0.020823
 >> iter 76000, loss: 0.019539
 >> iter 77000, loss: 0.018884
 >> iter 78000, loss: 0.018924
 >> iter 79000, loss: 0.021090
 >> iter 80000, loss: 0.020192
   Number of active neurons: 1
 >> iter 81000, loss: 0.024590
 >> iter 82000, loss: 0.023314
 >> iter 83000, loss: 0.018228
 >> iter 84000, loss: 0.021959
 >> iter 85000, loss: 0.019480
 >> iter 86000, loss: 0.020677
 >> iter 87000, loss: 0.017846
 >> iter 88000, loss: 0.023684
 >> iter 89000, loss: 0.027705
 >> iter 90000, loss: 0.023809
   Number of active neurons: 1
 >> iter 91000, loss: 0.018721
 >> iter 92000, loss: 0.019638
 >> iter 93000, loss: 0.019152
 >> iter 94000, loss: 0.018949
 >> iter 95000, loss: 0.019525
 >> iter 96000, loss: 0.030368
 >> iter 97000, loss: 0.022806
 >> iter 98000, loss: 0.030514
 >> iter 99000, loss: 0.025399
 >> iter 100000, loss: 0.021698
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.932533
 >> iter 2000, loss: 4.077623
 >> iter 3000, loss: 1.545326
 >> iter 4000, loss: 0.595784
 >> iter 5000, loss: 0.242576
 >> iter 6000, loss: 0.111034
 >> iter 7000, loss: 0.064868
 >> iter 8000, loss: 0.044943
 >> iter 9000, loss: 0.034396
 >> iter 10000, loss: 0.029891
   Number of active neurons: 5
 >> iter 11000, loss: 0.037462
 >> iter 12000, loss: 0.030047
 >> iter 13000, loss: 0.027850
 >> iter 14000, loss: 0.029227
 >> iter 15000, loss: 0.032408
 >> iter 16000, loss: 0.026920
 >> iter 17000, loss: 0.026120
 >> iter 18000, loss: 0.025810
 >> iter 19000, loss: 0.026115
 >> iter 20000, loss: 0.027381
   Number of active neurons: 3
 >> iter 21000, loss: 0.034472
 >> iter 22000, loss: 0.044820
 >> iter 23000, loss: 0.031562
 >> iter 24000, loss: 0.029917
 >> iter 25000, loss: 0.026777
 >> iter 26000, loss: 0.028250
 >> iter 27000, loss: 0.031901
 >> iter 28000, loss: 0.041498
 >> iter 29000, loss: 0.030174
 >> iter 30000, loss: 0.027834
   Number of active neurons: 2
 >> iter 31000, loss: 0.022667
 >> iter 32000, loss: 0.022414
 >> iter 33000, loss: 0.032132
 >> iter 34000, loss: 0.025934
 >> iter 35000, loss: 0.022674
 >> iter 36000, loss: 0.021450
 >> iter 37000, loss: 0.024237
 >> iter 38000, loss: 0.032408
 >> iter 39000, loss: 0.026008
 >> iter 40000, loss: 0.021618
   Number of active neurons: 2
 >> iter 41000, loss: 0.022388
 >> iter 42000, loss: 0.022180
 >> iter 43000, loss: 0.021039
 >> iter 44000, loss: 0.032342
 >> iter 45000, loss: 0.064242
 >> iter 46000, loss: 0.039389
 >> iter 47000, loss: 0.031629
 >> iter 48000, loss: 0.026558
 >> iter 49000, loss: 0.028892
 >> iter 50000, loss: 0.028933
   Number of active neurons: 2
 >> iter 51000, loss: 0.025335
 >> iter 52000, loss: 0.022411
 >> iter 53000, loss: 0.025018
 >> iter 54000, loss: 0.052686
 >> iter 55000, loss: 0.033654
 >> iter 56000, loss: 0.029183
 >> iter 57000, loss: 0.024264
 >> iter 58000, loss: 0.034886
 >> iter 59000, loss: 0.031515
 >> iter 60000, loss: 0.025340
   Number of active neurons: 2
 >> iter 61000, loss: 0.022407
 >> iter 62000, loss: 0.029699
 >> iter 63000, loss: 0.026132
 >> iter 64000, loss: 0.045493
 >> iter 65000, loss: 0.036646
 >> iter 66000, loss: 0.026708
 >> iter 67000, loss: 0.023609
 >> iter 68000, loss: 0.020219
 >> iter 69000, loss: 0.028182
 >> iter 70000, loss: 0.023234
   Number of active neurons: 2
 >> iter 71000, loss: 0.020846
 >> iter 72000, loss: 0.021245
 >> iter 73000, loss: 0.023145
 >> iter 74000, loss: 0.022847
 >> iter 75000, loss: 0.020919
 >> iter 76000, loss: 0.022827
 >> iter 77000, loss: 0.020578
 >> iter 78000, loss: 0.029182
 >> iter 79000, loss: 0.021572
 >> iter 80000, loss: 0.028691
   Number of active neurons: 1
 >> iter 81000, loss: 0.025247
 >> iter 82000, loss: 0.036349
 >> iter 83000, loss: 0.025873
 >> iter 84000, loss: 0.019158
 >> iter 85000, loss: 0.026927
 >> iter 86000, loss: 0.023219
 >> iter 87000, loss: 0.028400
 >> iter 88000, loss: 0.020270
 >> iter 89000, loss: 0.020177
 >> iter 90000, loss: 0.019955
   Number of active neurons: 1
 >> iter 91000, loss: 0.023367
 >> iter 92000, loss: 0.020714
 >> iter 93000, loss: 0.024357
 >> iter 94000, loss: 0.019041
 >> iter 95000, loss: 0.048312
 >> iter 96000, loss: 0.028143
 >> iter 97000, loss: 0.032037
 >> iter 98000, loss: 0.021811
 >> iter 99000, loss: 0.022770
 >> iter 100000, loss: 0.018154
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

