 > Problema: tomita2nueva
 > Args:
   - Hidden size: 8
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.504771
 >> iter 2000, loss: 4.496415
 >> iter 3000, loss: 1.787908
 >> iter 4000, loss: 0.712885
 >> iter 5000, loss: 0.309024
 >> iter 6000, loss: 0.153883
 >> iter 7000, loss: 0.111231
 >> iter 8000, loss: 0.078900
 >> iter 9000, loss: 0.054904
 >> iter 10000, loss: 0.076025
   Number of active neurons: 5
 >> iter 11000, loss: 0.069211
 >> iter 12000, loss: 0.059916
 >> iter 13000, loss: 0.060380
 >> iter 14000, loss: 0.056383
 >> iter 15000, loss: 0.061080
 >> iter 16000, loss: 0.056547
 >> iter 17000, loss: 0.050032
 >> iter 18000, loss: 0.059535
 >> iter 19000, loss: 0.067198
 >> iter 20000, loss: 0.069700
   Number of active neurons: 5
 >> iter 21000, loss: 0.070869
 >> iter 22000, loss: 0.054823
 >> iter 23000, loss: 0.054009
 >> iter 24000, loss: 0.050453
 >> iter 25000, loss: 0.060834
 >> iter 26000, loss: 0.045840
 >> iter 27000, loss: 0.044600
 >> iter 28000, loss: 0.035449
 >> iter 29000, loss: 0.057517
 >> iter 30000, loss: 0.047705
   Number of active neurons: 4
 >> iter 31000, loss: 0.094197
 >> iter 32000, loss: 0.056466
 >> iter 33000, loss: 0.047184
 >> iter 34000, loss: 0.040744
 >> iter 35000, loss: 0.058123
 >> iter 36000, loss: 0.060310
 >> iter 37000, loss: 0.052924
 >> iter 38000, loss: 0.037568
 >> iter 39000, loss: 0.047005
 >> iter 40000, loss: 0.053542
   Number of active neurons: 4
 >> iter 41000, loss: 0.042553
 >> iter 42000, loss: 0.035510
 >> iter 43000, loss: 0.057436
 >> iter 44000, loss: 0.054763
 >> iter 45000, loss: 0.049271
 >> iter 46000, loss: 0.043864
 >> iter 47000, loss: 0.062393
 >> iter 48000, loss: 0.067165
 >> iter 49000, loss: 0.044906
 >> iter 50000, loss: 0.038751
   Number of active neurons: 4
 >> iter 51000, loss: 0.039780
 >> iter 52000, loss: 0.044402
 >> iter 53000, loss: 0.049223
 >> iter 54000, loss: 0.061557
 >> iter 55000, loss: 0.057168
 >> iter 56000, loss: 0.048382
 >> iter 57000, loss: 0.055667
 >> iter 58000, loss: 0.063816
 >> iter 59000, loss: 0.053965
 >> iter 60000, loss: 0.040353
   Number of active neurons: 3
 >> iter 61000, loss: 0.051014
 >> iter 62000, loss: 0.046960
 >> iter 63000, loss: 0.044334
 >> iter 64000, loss: 0.043359
 >> iter 65000, loss: 0.039002
 >> iter 66000, loss: 0.035738
 >> iter 67000, loss: 0.047713
 >> iter 68000, loss: 0.050593
 >> iter 69000, loss: 0.049545
 >> iter 70000, loss: 0.045574
   Number of active neurons: 3
 >> iter 71000, loss: 0.038138
 >> iter 72000, loss: 0.051294
 >> iter 73000, loss: 0.042083
 >> iter 74000, loss: 0.048238
 >> iter 75000, loss: 0.041936
 >> iter 76000, loss: 0.049179
 >> iter 77000, loss: 0.052079
 >> iter 78000, loss: 0.064392
 >> iter 79000, loss: 0.055045
 >> iter 80000, loss: 0.042213
   Number of active neurons: 3
 >> iter 81000, loss: 0.042354
 >> iter 82000, loss: 0.054328
 >> iter 83000, loss: 0.039922
 >> iter 84000, loss: 0.045591
 >> iter 85000, loss: 0.055322
 >> iter 86000, loss: 0.061465
 >> iter 87000, loss: 0.055389
 >> iter 88000, loss: 0.063247
 >> iter 89000, loss: 0.043891
 >> iter 90000, loss: 0.038325
   Number of active neurons: 2
 >> iter 91000, loss: 0.035490
 >> iter 92000, loss: 0.033364
 >> iter 93000, loss: 0.039943
 >> iter 94000, loss: 0.046488
 >> iter 95000, loss: 0.038535
 >> iter 96000, loss: 0.029795
 >> iter 97000, loss: 0.042696
 >> iter 98000, loss: 0.057086
 >> iter 99000, loss: 0.056096
 >> iter 100000, loss: 0.057119
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.455586
 >> iter 2000, loss: 4.468282
 >> iter 3000, loss: 1.745269
 >> iter 4000, loss: 0.714023
 >> iter 5000, loss: 0.329674
 >> iter 6000, loss: 0.172097
 >> iter 7000, loss: 0.116228
 >> iter 8000, loss: 0.075355
 >> iter 9000, loss: 0.067866
 >> iter 10000, loss: 0.089394
   Number of active neurons: 6
 >> iter 11000, loss: 0.062916
 >> iter 12000, loss: 0.081707
 >> iter 13000, loss: 0.058872
 >> iter 14000, loss: 0.063858
 >> iter 15000, loss: 0.048227
 >> iter 16000, loss: 0.067061
 >> iter 17000, loss: 0.065123
 >> iter 18000, loss: 0.061545
 >> iter 19000, loss: 0.048633
 >> iter 20000, loss: 0.060246
   Number of active neurons: 6
 >> iter 21000, loss: 0.063955
 >> iter 22000, loss: 0.047963
 >> iter 23000, loss: 0.040011
 >> iter 24000, loss: 0.042001
 >> iter 25000, loss: 0.044483
 >> iter 26000, loss: 0.058515
 >> iter 27000, loss: 0.062072
 >> iter 28000, loss: 0.038850
 >> iter 29000, loss: 0.040371
 >> iter 30000, loss: 0.039336
   Number of active neurons: 5
 >> iter 31000, loss: 0.053979
 >> iter 32000, loss: 0.061121
 >> iter 33000, loss: 0.051587
 >> iter 34000, loss: 0.046649
 >> iter 35000, loss: 0.062376
 >> iter 36000, loss: 0.053572
 >> iter 37000, loss: 0.075436
 >> iter 38000, loss: 0.072759
 >> iter 39000, loss: 0.067224
 >> iter 40000, loss: 0.051061
   Number of active neurons: 5
 >> iter 41000, loss: 0.045381
 >> iter 42000, loss: 0.039947
 >> iter 43000, loss: 0.052843
 >> iter 44000, loss: 0.044815
 >> iter 45000, loss: 0.068552
 >> iter 46000, loss: 0.070298
 >> iter 47000, loss: 0.056185
 >> iter 48000, loss: 0.046027
 >> iter 49000, loss: 0.063588
 >> iter 50000, loss: 0.070842
   Number of active neurons: 4
 >> iter 51000, loss: 0.053307
 >> iter 52000, loss: 0.048128
 >> iter 53000, loss: 0.059576
 >> iter 54000, loss: 0.042736
 >> iter 55000, loss: 0.046653
 >> iter 56000, loss: 0.059303
 >> iter 57000, loss: 0.063488
 >> iter 58000, loss: 0.047161
 >> iter 59000, loss: 0.047225
 >> iter 60000, loss: 0.049814
   Number of active neurons: 3
 >> iter 61000, loss: 0.055834
 >> iter 62000, loss: 0.042817
 >> iter 63000, loss: 0.055417
 >> iter 64000, loss: 0.040928
 >> iter 65000, loss: 0.038358
 >> iter 66000, loss: 0.038810
 >> iter 67000, loss: 0.058359
 >> iter 68000, loss: 0.055211
 >> iter 69000, loss: 0.043758
 >> iter 70000, loss: 0.046723
   Number of active neurons: 3
 >> iter 71000, loss: 0.049450
 >> iter 72000, loss: 0.039799
 >> iter 73000, loss: 0.066625
 >> iter 74000, loss: 0.066592
 >> iter 75000, loss: 0.043696
 >> iter 76000, loss: 0.055428
 >> iter 77000, loss: 0.051792
 >> iter 78000, loss: 0.038205
 >> iter 79000, loss: 0.060881
 >> iter 80000, loss: 0.038759
   Number of active neurons: 3
 >> iter 81000, loss: 0.051275
 >> iter 82000, loss: 0.059021
 >> iter 83000, loss: 0.080585
 >> iter 84000, loss: 0.053744
 >> iter 85000, loss: 0.063571
 >> iter 86000, loss: 0.054270
 >> iter 87000, loss: 0.044326
 >> iter 88000, loss: 0.063015
 >> iter 89000, loss: 0.045804
 >> iter 90000, loss: 0.047921
   Number of active neurons: 3
 >> iter 91000, loss: 0.043346
 >> iter 92000, loss: 0.050491
 >> iter 93000, loss: 0.050232
 >> iter 94000, loss: 0.039147
 >> iter 95000, loss: 0.043464
 >> iter 96000, loss: 0.052056
 >> iter 97000, loss: 0.043984
 >> iter 98000, loss: 0.047060
 >> iter 99000, loss: 0.034530
 >> iter 100000, loss: 0.043340
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.350595
 >> iter 2000, loss: 4.370130
 >> iter 3000, loss: 1.717577
 >> iter 4000, loss: 0.702824
 >> iter 5000, loss: 0.315433
 >> iter 6000, loss: 0.186671
 >> iter 7000, loss: 0.121333
 >> iter 8000, loss: 0.084270
 >> iter 9000, loss: 0.083549
 >> iter 10000, loss: 0.087721
   Number of active neurons: 6
 >> iter 11000, loss: 0.055992
 >> iter 12000, loss: 0.056912
 >> iter 13000, loss: 0.063283
 >> iter 14000, loss: 0.054355
 >> iter 15000, loss: 0.061027
 >> iter 16000, loss: 0.072722
 >> iter 17000, loss: 0.068241
 >> iter 18000, loss: 0.059322
 >> iter 19000, loss: 0.069647
 >> iter 20000, loss: 0.051309
   Number of active neurons: 6
 >> iter 21000, loss: 0.045171
 >> iter 22000, loss: 0.045187
 >> iter 23000, loss: 0.052059
 >> iter 24000, loss: 0.045278
 >> iter 25000, loss: 0.047092
 >> iter 26000, loss: 0.046756
 >> iter 27000, loss: 0.047864
 >> iter 28000, loss: 0.056872
 >> iter 29000, loss: 0.060530
 >> iter 30000, loss: 0.060840
   Number of active neurons: 5
 >> iter 31000, loss: 0.056229
 >> iter 32000, loss: 0.051120
 >> iter 33000, loss: 0.050803
 >> iter 34000, loss: 0.042952
 >> iter 35000, loss: 0.042975
 >> iter 36000, loss: 0.073687
 >> iter 37000, loss: 0.053133
 >> iter 38000, loss: 0.060188
 >> iter 39000, loss: 0.079367
 >> iter 40000, loss: 0.058310
   Number of active neurons: 5
 >> iter 41000, loss: 0.054756
 >> iter 42000, loss: 0.049109
 >> iter 43000, loss: 0.065630
 >> iter 44000, loss: 0.047541
 >> iter 45000, loss: 0.057371
 >> iter 46000, loss: 0.047755
 >> iter 47000, loss: 0.040326
 >> iter 48000, loss: 0.042701
 >> iter 49000, loss: 0.039069
 >> iter 50000, loss: 0.035579
   Number of active neurons: 4
 >> iter 51000, loss: 0.043750
 >> iter 52000, loss: 0.064858
 >> iter 53000, loss: 0.078051
 >> iter 54000, loss: 0.074314
 >> iter 55000, loss: 0.054100
 >> iter 56000, loss: 0.061924
 >> iter 57000, loss: 0.057102
 >> iter 58000, loss: 0.067484
 >> iter 59000, loss: 0.041622
 >> iter 60000, loss: 0.038747
   Number of active neurons: 4
 >> iter 61000, loss: 0.038411
 >> iter 62000, loss: 0.056654
 >> iter 63000, loss: 0.045328
 >> iter 64000, loss: 0.052536
 >> iter 65000, loss: 0.049982
 >> iter 66000, loss: 0.044720
 >> iter 67000, loss: 0.054367
 >> iter 68000, loss: 0.052518
 >> iter 69000, loss: 0.067410
 >> iter 70000, loss: 0.057353
   Number of active neurons: 4
 >> iter 71000, loss: 0.056870
 >> iter 72000, loss: 0.045120
 >> iter 73000, loss: 0.045117
 >> iter 74000, loss: 0.049477
 >> iter 75000, loss: 0.051323
 >> iter 76000, loss: 0.040429
 >> iter 77000, loss: 0.037295
 >> iter 78000, loss: 0.036023
 >> iter 79000, loss: 0.081090
 >> iter 80000, loss: 0.059546
   Number of active neurons: 4
 >> iter 81000, loss: 0.060215
 >> iter 82000, loss: 0.053097
 >> iter 83000, loss: 0.050323
 >> iter 84000, loss: 0.058536
 >> iter 85000, loss: 0.055503
 >> iter 86000, loss: 0.062607
 >> iter 87000, loss: 0.050372
 >> iter 88000, loss: 0.041789
 >> iter 89000, loss: 0.053764
 >> iter 90000, loss: 0.049535
   Number of active neurons: 4
 >> iter 91000, loss: 0.039569
 >> iter 92000, loss: 0.058495
 >> iter 93000, loss: 0.047023
 >> iter 94000, loss: 0.059230
 >> iter 95000, loss: 0.045182
 >> iter 96000, loss: 0.052437
 >> iter 97000, loss: 0.049520
 >> iter 98000, loss: 0.049055
 >> iter 99000, loss: 0.034797
 >> iter 100000, loss: 0.057332
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.330682
 >> iter 2000, loss: 4.434080
 >> iter 3000, loss: 1.761952
 >> iter 4000, loss: 0.739894
 >> iter 5000, loss: 0.368350
 >> iter 6000, loss: 0.201831
 >> iter 7000, loss: 0.114019
 >> iter 8000, loss: 0.108848
 >> iter 9000, loss: 0.089247
 >> iter 10000, loss: 0.065642
   Number of active neurons: 8
 >> iter 11000, loss: 0.098804
 >> iter 12000, loss: 0.086869
 >> iter 13000, loss: 0.067476
 >> iter 14000, loss: 0.070592
 >> iter 15000, loss: 0.055653
 >> iter 16000, loss: 0.068081
 >> iter 17000, loss: 0.065394
 >> iter 18000, loss: 0.052000
 >> iter 19000, loss: 0.075853
 >> iter 20000, loss: 0.060163
   Number of active neurons: 8
 >> iter 21000, loss: 0.075093
 >> iter 22000, loss: 0.051236
 >> iter 23000, loss: 0.056885
 >> iter 24000, loss: 0.067818
 >> iter 25000, loss: 0.059490
 >> iter 26000, loss: 0.052699
 >> iter 27000, loss: 0.067353
 >> iter 28000, loss: 0.047209
 >> iter 29000, loss: 0.046732
 >> iter 30000, loss: 0.077600
   Number of active neurons: 7
 >> iter 31000, loss: 0.064237
 >> iter 32000, loss: 0.048509
 >> iter 33000, loss: 0.045136
 >> iter 34000, loss: 0.044872
 >> iter 35000, loss: 0.058204
 >> iter 36000, loss: 0.058790
 >> iter 37000, loss: 0.041850
 >> iter 38000, loss: 0.034859
 >> iter 39000, loss: 0.053392
 >> iter 40000, loss: 0.053924
   Number of active neurons: 6
 >> iter 41000, loss: 0.060252
 >> iter 42000, loss: 0.047954
 >> iter 43000, loss: 0.060342
 >> iter 44000, loss: 0.053253
 >> iter 45000, loss: 0.046291
 >> iter 46000, loss: 0.067851
 >> iter 47000, loss: 0.042013
 >> iter 48000, loss: 0.049744
 >> iter 49000, loss: 0.075668
 >> iter 50000, loss: 0.056247
   Number of active neurons: 5
 >> iter 51000, loss: 0.051852
 >> iter 52000, loss: 0.055585
 >> iter 53000, loss: 0.053633
 >> iter 54000, loss: 0.064758
 >> iter 55000, loss: 0.062553
 >> iter 56000, loss: 0.060319
 >> iter 57000, loss: 0.041250
 >> iter 58000, loss: 0.046884
 >> iter 59000, loss: 0.034509
 >> iter 60000, loss: 0.033454
   Number of active neurons: 5
 >> iter 61000, loss: 0.035335
 >> iter 62000, loss: 0.036056
 >> iter 63000, loss: 0.041769
 >> iter 64000, loss: 0.050137
 >> iter 65000, loss: 0.047307
 >> iter 66000, loss: 0.069778
 >> iter 67000, loss: 0.054885
 >> iter 68000, loss: 0.046034
 >> iter 69000, loss: 0.038956
 >> iter 70000, loss: 0.046999
   Number of active neurons: 4
 >> iter 71000, loss: 0.041239
 >> iter 72000, loss: 0.044899
 >> iter 73000, loss: 0.044457
 >> iter 74000, loss: 0.055881
 >> iter 75000, loss: 0.039611
 >> iter 76000, loss: 0.040079
 >> iter 77000, loss: 0.045515
 >> iter 78000, loss: 0.038150
 >> iter 79000, loss: 0.037678
 >> iter 80000, loss: 0.050290
   Number of active neurons: 4
 >> iter 81000, loss: 0.049291
 >> iter 82000, loss: 0.055729
 >> iter 83000, loss: 0.051322
 >> iter 84000, loss: 0.048991
 >> iter 85000, loss: 0.049601
 >> iter 86000, loss: 0.036268
 >> iter 87000, loss: 0.068651
 >> iter 88000, loss: 0.041345
 >> iter 89000, loss: 0.050522
 >> iter 90000, loss: 0.044086
   Number of active neurons: 3
 >> iter 91000, loss: 0.053471
 >> iter 92000, loss: 0.050581
 >> iter 93000, loss: 0.040720
 >> iter 94000, loss: 0.046071
 >> iter 95000, loss: 0.035490
 >> iter 96000, loss: 0.040018
 >> iter 97000, loss: 0.072416
 >> iter 98000, loss: 0.057446
 >> iter 99000, loss: 0.047454
 >> iter 100000, loss: 0.051927
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.409762
 >> iter 2000, loss: 4.394254
 >> iter 3000, loss: 1.746301
 >> iter 4000, loss: 0.704372
 >> iter 5000, loss: 0.354178
 >> iter 6000, loss: 0.188049
 >> iter 7000, loss: 0.121289
 >> iter 8000, loss: 0.092816
 >> iter 9000, loss: 0.065958
 >> iter 10000, loss: 0.063957
   Number of active neurons: 7
 >> iter 11000, loss: 0.064040
 >> iter 12000, loss: 0.047531
 >> iter 13000, loss: 0.052975
 >> iter 14000, loss: 0.041321
 >> iter 15000, loss: 0.062568
 >> iter 16000, loss: 0.070581
 >> iter 17000, loss: 0.080120
 >> iter 18000, loss: 0.050164
 >> iter 19000, loss: 0.057466
 >> iter 20000, loss: 0.057124
   Number of active neurons: 6
 >> iter 21000, loss: 0.052704
 >> iter 22000, loss: 0.061225
 >> iter 23000, loss: 0.058906
 >> iter 24000, loss: 0.056570
 >> iter 25000, loss: 0.057383
 >> iter 26000, loss: 0.051951
 >> iter 27000, loss: 0.050400
 >> iter 28000, loss: 0.049468
 >> iter 29000, loss: 0.047283
 >> iter 30000, loss: 0.061187
   Number of active neurons: 5
 >> iter 31000, loss: 0.064393
 >> iter 32000, loss: 0.045011
 >> iter 33000, loss: 0.034285
 >> iter 34000, loss: 0.050263
 >> iter 35000, loss: 0.058761
 >> iter 36000, loss: 0.080861
 >> iter 37000, loss: 0.051480
 >> iter 38000, loss: 0.038718
 >> iter 39000, loss: 0.033639
 >> iter 40000, loss: 0.042671
   Number of active neurons: 4
 >> iter 41000, loss: 0.053602
 >> iter 42000, loss: 0.071051
 >> iter 43000, loss: 0.067358
 >> iter 44000, loss: 0.051338
 >> iter 45000, loss: 0.041944
 >> iter 46000, loss: 0.069591
 >> iter 47000, loss: 0.075778
 >> iter 48000, loss: 0.061113
 >> iter 49000, loss: 0.044656
 >> iter 50000, loss: 0.041237
   Number of active neurons: 4
 >> iter 51000, loss: 0.053977
 >> iter 52000, loss: 0.048611
 >> iter 53000, loss: 0.048373
 >> iter 54000, loss: 0.067790
 >> iter 55000, loss: 0.045611
 >> iter 56000, loss: 0.050191
 >> iter 57000, loss: 0.065448
 >> iter 58000, loss: 0.044268
 >> iter 59000, loss: 0.054299
 >> iter 60000, loss: 0.061128
   Number of active neurons: 4
 >> iter 61000, loss: 0.044927
 >> iter 62000, loss: 0.040976
 >> iter 63000, loss: 0.047259
 >> iter 64000, loss: 0.037795
 >> iter 65000, loss: 0.035529
 >> iter 66000, loss: 0.032764
 >> iter 67000, loss: 0.068973
 >> iter 68000, loss: 0.057754
 >> iter 69000, loss: 0.060021
 >> iter 70000, loss: 0.069556
   Number of active neurons: 4
 >> iter 71000, loss: 0.059900
 >> iter 72000, loss: 0.055846
 >> iter 73000, loss: 0.058275
 >> iter 74000, loss: 0.044944
 >> iter 75000, loss: 0.058910
 >> iter 76000, loss: 0.042718
 >> iter 77000, loss: 0.048299
 >> iter 78000, loss: 0.046257
 >> iter 79000, loss: 0.039390
 >> iter 80000, loss: 0.043627
   Number of active neurons: 4
 >> iter 81000, loss: 0.042628
 >> iter 82000, loss: 0.040474
 >> iter 83000, loss: 0.044020
 >> iter 84000, loss: 0.044177
 >> iter 85000, loss: 0.044392
 >> iter 86000, loss: 0.035737
 >> iter 87000, loss: 0.044282
 >> iter 88000, loss: 0.051215
 >> iter 89000, loss: 0.043561
 >> iter 90000, loss: 0.049649
   Number of active neurons: 4
 >> iter 91000, loss: 0.046467
 >> iter 92000, loss: 0.047911
 >> iter 93000, loss: 0.038028
 >> iter 94000, loss: 0.034431
 >> iter 95000, loss: 0.042764
 >> iter 96000, loss: 0.036932
 >> iter 97000, loss: 0.040424
 >> iter 98000, loss: 0.041702
 >> iter 99000, loss: 0.038139
 >> iter 100000, loss: 0.057864
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 11.428014
 >> iter 2000, loss: 4.496182
 >> iter 3000, loss: 1.780024
 >> iter 4000, loss: 0.709840
 >> iter 5000, loss: 0.318882
 >> iter 6000, loss: 0.170774
 >> iter 7000, loss: 0.112516
 >> iter 8000, loss: 0.081943
 >> iter 9000, loss: 0.060253
 >> iter 10000, loss: 0.051691
   Number of active neurons: 7
 >> iter 11000, loss: 0.069059
 >> iter 12000, loss: 0.073289
 >> iter 13000, loss: 0.050453
 >> iter 14000, loss: 0.053515
 >> iter 15000, loss: 0.061359
 >> iter 16000, loss: 0.045956
 >> iter 17000, loss: 0.046911
 >> iter 18000, loss: 0.068931
 >> iter 19000, loss: 0.050252
 >> iter 20000, loss: 0.056313
   Number of active neurons: 5
 >> iter 21000, loss: 0.061496
 >> iter 22000, loss: 0.041744
 >> iter 23000, loss: 0.049755
 >> iter 24000, loss: 0.043129
 >> iter 25000, loss: 0.045145
 >> iter 26000, loss: 0.050554
 >> iter 27000, loss: 0.059055
 >> iter 28000, loss: 0.053518
 >> iter 29000, loss: 0.040244
 >> iter 30000, loss: 0.060687
   Number of active neurons: 5
 >> iter 31000, loss: 0.067322
 >> iter 32000, loss: 0.050892
 >> iter 33000, loss: 0.070892
 >> iter 34000, loss: 0.058670
 >> iter 35000, loss: 0.081360
 >> iter 36000, loss: 0.052436
 >> iter 37000, loss: 0.066750
 >> iter 38000, loss: 0.047925
 >> iter 39000, loss: 0.043875
 >> iter 40000, loss: 0.042283
   Number of active neurons: 4
 >> iter 41000, loss: 0.075193
 >> iter 42000, loss: 0.058058
 >> iter 43000, loss: 0.066746
 >> iter 44000, loss: 0.062675
 >> iter 45000, loss: 0.052887
 >> iter 46000, loss: 0.051516
 >> iter 47000, loss: 0.055025
 >> iter 48000, loss: 0.049615
 >> iter 49000, loss: 0.042076
 >> iter 50000, loss: 0.049055
   Number of active neurons: 4
 >> iter 51000, loss: 0.042104
 >> iter 52000, loss: 0.037455
 >> iter 53000, loss: 0.052377
 >> iter 54000, loss: 0.061403
 >> iter 55000, loss: 0.058303
 >> iter 56000, loss: 0.055344
 >> iter 57000, loss: 0.042086
 >> iter 58000, loss: 0.032030
 >> iter 59000, loss: 0.034458
 >> iter 60000, loss: 0.060349
   Number of active neurons: 4
 >> iter 61000, loss: 0.050700
 >> iter 62000, loss: 0.048367
 >> iter 63000, loss: 0.046753
 >> iter 64000, loss: 0.048835
 >> iter 65000, loss: 0.062913
 >> iter 66000, loss: 0.043672
 >> iter 67000, loss: 0.055147
 >> iter 68000, loss: 0.043290
 >> iter 69000, loss: 0.061674
 >> iter 70000, loss: 0.053142
   Number of active neurons: 3
 >> iter 71000, loss: 0.072847
 >> iter 72000, loss: 0.062013
 >> iter 73000, loss: 0.057116
 >> iter 74000, loss: 0.050665
 >> iter 75000, loss: 0.037194
 >> iter 76000, loss: 0.043561
 >> iter 77000, loss: 0.040752
 >> iter 78000, loss: 0.036247
 >> iter 79000, loss: 0.053554
 >> iter 80000, loss: 0.048003
   Number of active neurons: 2
 >> iter 81000, loss: 0.041452
 >> iter 82000, loss: 0.045813
 >> iter 83000, loss: 0.040408
 >> iter 84000, loss: 0.045895
 >> iter 85000, loss: 0.054243
 >> iter 86000, loss: 0.051880
 >> iter 87000, loss: 0.044756
 >> iter 88000, loss: 0.085429
 >> iter 89000, loss: 0.063402
 >> iter 90000, loss: 0.049918
   Number of active neurons: 2
 >> iter 91000, loss: 0.061490
 >> iter 92000, loss: 0.055212
 >> iter 93000, loss: 0.057441
 >> iter 94000, loss: 0.049336
 >> iter 95000, loss: 0.064155
 >> iter 96000, loss: 0.044098
 >> iter 97000, loss: 0.069090
 >> iter 98000, loss: 0.057305
 >> iter 99000, loss: 0.049172
 >> iter 100000, loss: 0.031387
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.491465
 >> iter 2000, loss: 4.515949
 >> iter 3000, loss: 1.789686
 >> iter 4000, loss: 0.754889
 >> iter 5000, loss: 0.321332
 >> iter 6000, loss: 0.171763
 >> iter 7000, loss: 0.133919
 >> iter 8000, loss: 0.098820
 >> iter 9000, loss: 0.089677
 >> iter 10000, loss: 0.065078
   Number of active neurons: 5
 >> iter 11000, loss: 0.067149
 >> iter 12000, loss: 0.062249
 >> iter 13000, loss: 0.074081
 >> iter 14000, loss: 0.078488
 >> iter 15000, loss: 0.064147
 >> iter 16000, loss: 0.040934
 >> iter 17000, loss: 0.053582
 >> iter 18000, loss: 0.044507
 >> iter 19000, loss: 0.071597
 >> iter 20000, loss: 0.065431
   Number of active neurons: 5
 >> iter 21000, loss: 0.080209
 >> iter 22000, loss: 0.056382
 >> iter 23000, loss: 0.068235
 >> iter 24000, loss: 0.072005
 >> iter 25000, loss: 0.063008
 >> iter 26000, loss: 0.047901
 >> iter 27000, loss: 0.045893
 >> iter 28000, loss: 0.052624
 >> iter 29000, loss: 0.041978
 >> iter 30000, loss: 0.047547
   Number of active neurons: 5
 >> iter 31000, loss: 0.034610
 >> iter 32000, loss: 0.042378
 >> iter 33000, loss: 0.044357
 >> iter 34000, loss: 0.050057
 >> iter 35000, loss: 0.053926
 >> iter 36000, loss: 0.052572
 >> iter 37000, loss: 0.062981
 >> iter 38000, loss: 0.048960
 >> iter 39000, loss: 0.067212
 >> iter 40000, loss: 0.049054
   Number of active neurons: 5
 >> iter 41000, loss: 0.043692
 >> iter 42000, loss: 0.045120
 >> iter 43000, loss: 0.064126
 >> iter 44000, loss: 0.048993
 >> iter 45000, loss: 0.039759
 >> iter 46000, loss: 0.044556
 >> iter 47000, loss: 0.046759
 >> iter 48000, loss: 0.057784
 >> iter 49000, loss: 0.045614
 >> iter 50000, loss: 0.036285
   Number of active neurons: 4
 >> iter 51000, loss: 0.044122
 >> iter 52000, loss: 0.068111
 >> iter 53000, loss: 0.064635
 >> iter 54000, loss: 0.079924
 >> iter 55000, loss: 0.056691
 >> iter 56000, loss: 0.059160
 >> iter 57000, loss: 0.041229
 >> iter 58000, loss: 0.038149
 >> iter 59000, loss: 0.037229
 >> iter 60000, loss: 0.055809
   Number of active neurons: 4
 >> iter 61000, loss: 0.051164
 >> iter 62000, loss: 0.056767
 >> iter 63000, loss: 0.049417
 >> iter 64000, loss: 0.066237
 >> iter 65000, loss: 0.082354
 >> iter 66000, loss: 0.057576
 >> iter 67000, loss: 0.036873
 >> iter 68000, loss: 0.054470
 >> iter 69000, loss: 0.048141
 >> iter 70000, loss: 0.043680
   Number of active neurons: 4
 >> iter 71000, loss: 0.046398
 >> iter 72000, loss: 0.034898
 >> iter 73000, loss: 0.040449
 >> iter 74000, loss: 0.050642
 >> iter 75000, loss: 0.060123
 >> iter 76000, loss: 0.063126
 >> iter 77000, loss: 0.039310
 >> iter 78000, loss: 0.035808
 >> iter 79000, loss: 0.039312
 >> iter 80000, loss: 0.039563
   Number of active neurons: 3
 >> iter 81000, loss: 0.043513
 >> iter 82000, loss: 0.050473
 >> iter 83000, loss: 0.040627
 >> iter 84000, loss: 0.044184
 >> iter 85000, loss: 0.080785
 >> iter 86000, loss: 0.063107
 >> iter 87000, loss: 0.054096
 >> iter 88000, loss: 0.058328
 >> iter 89000, loss: 0.037799
 >> iter 90000, loss: 0.054280
   Number of active neurons: 3
 >> iter 91000, loss: 0.056573
 >> iter 92000, loss: 0.056121
 >> iter 93000, loss: 0.047605
 >> iter 94000, loss: 0.042624
 >> iter 95000, loss: 0.062116
 >> iter 96000, loss: 0.047054
 >> iter 97000, loss: 0.039637
 >> iter 98000, loss: 0.029204
 >> iter 99000, loss: 0.051711
 >> iter 100000, loss: 0.039707
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.409041
 >> iter 2000, loss: 4.434356
 >> iter 3000, loss: 1.738619
 >> iter 4000, loss: 0.723986
 >> iter 5000, loss: 0.328807
 >> iter 6000, loss: 0.148656
 >> iter 7000, loss: 0.111714
 >> iter 8000, loss: 0.107085
 >> iter 9000, loss: 0.086233
 >> iter 10000, loss: 0.083302
   Number of active neurons: 5
 >> iter 11000, loss: 0.063588
 >> iter 12000, loss: 0.046372
 >> iter 13000, loss: 0.042878
 >> iter 14000, loss: 0.049089
 >> iter 15000, loss: 0.046253
 >> iter 16000, loss: 0.057215
 >> iter 17000, loss: 0.057415
 >> iter 18000, loss: 0.050047
 >> iter 19000, loss: 0.045775
 >> iter 20000, loss: 0.062718
   Number of active neurons: 5
 >> iter 21000, loss: 0.064932
 >> iter 22000, loss: 0.043222
 >> iter 23000, loss: 0.043982
 >> iter 24000, loss: 0.051780
 >> iter 25000, loss: 0.062956
 >> iter 26000, loss: 0.047353
 >> iter 27000, loss: 0.044757
 >> iter 28000, loss: 0.061904
 >> iter 29000, loss: 0.065157
 >> iter 30000, loss: 0.059231
   Number of active neurons: 4
 >> iter 31000, loss: 0.058202
 >> iter 32000, loss: 0.053788
 >> iter 33000, loss: 0.055594
 >> iter 34000, loss: 0.043298
 >> iter 35000, loss: 0.040524
 >> iter 36000, loss: 0.065444
 >> iter 37000, loss: 0.047161
 >> iter 38000, loss: 0.043568
 >> iter 39000, loss: 0.053285
 >> iter 40000, loss: 0.059608
   Number of active neurons: 4
 >> iter 41000, loss: 0.055633
 >> iter 42000, loss: 0.050337
 >> iter 43000, loss: 0.054557
 >> iter 44000, loss: 0.035672
 >> iter 45000, loss: 0.038010
 >> iter 46000, loss: 0.033231
 >> iter 47000, loss: 0.033804
 >> iter 48000, loss: 0.041019
 >> iter 49000, loss: 0.048612
 >> iter 50000, loss: 0.039691
   Number of active neurons: 4
 >> iter 51000, loss: 0.057202
 >> iter 52000, loss: 0.041624
 >> iter 53000, loss: 0.040693
 >> iter 54000, loss: 0.061886
 >> iter 55000, loss: 0.062702
 >> iter 56000, loss: 0.051910
 >> iter 57000, loss: 0.052226
 >> iter 58000, loss: 0.052435
 >> iter 59000, loss: 0.049906
 >> iter 60000, loss: 0.048383
   Number of active neurons: 4
 >> iter 61000, loss: 0.050633
 >> iter 62000, loss: 0.052206
 >> iter 63000, loss: 0.063139
 >> iter 64000, loss: 0.053572
 >> iter 65000, loss: 0.049305
 >> iter 66000, loss: 0.054499
 >> iter 67000, loss: 0.050165
 >> iter 68000, loss: 0.067208
 >> iter 69000, loss: 0.056206
 >> iter 70000, loss: 0.052606
   Number of active neurons: 4
 >> iter 71000, loss: 0.060997
 >> iter 72000, loss: 0.058378
 >> iter 73000, loss: 0.068416
 >> iter 74000, loss: 0.056694
 >> iter 75000, loss: 0.052115
 >> iter 76000, loss: 0.044262
 >> iter 77000, loss: 0.051977
 >> iter 78000, loss: 0.049335
 >> iter 79000, loss: 0.042860
 >> iter 80000, loss: 0.035015
   Number of active neurons: 4
 >> iter 81000, loss: 0.042535
 >> iter 82000, loss: 0.035656
 >> iter 83000, loss: 0.038172
 >> iter 84000, loss: 0.041123
 >> iter 85000, loss: 0.048025
 >> iter 86000, loss: 0.062862
 >> iter 87000, loss: 0.055914
 >> iter 88000, loss: 0.051297
 >> iter 89000, loss: 0.054555
 >> iter 90000, loss: 0.055905
   Number of active neurons: 4
 >> iter 91000, loss: 0.042291
 >> iter 92000, loss: 0.035139
 >> iter 93000, loss: 0.031385
 >> iter 94000, loss: 0.042572
 >> iter 95000, loss: 0.047192
 >> iter 96000, loss: 0.041672
 >> iter 97000, loss: 0.050445
 >> iter 98000, loss: 0.059138
 >> iter 99000, loss: 0.045869
 >> iter 100000, loss: 0.055024
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 11.218660
 >> iter 2000, loss: 4.295089
 >> iter 3000, loss: 1.675044
 >> iter 4000, loss: 0.690830
 >> iter 5000, loss: 0.305944
 >> iter 6000, loss: 0.152448
 >> iter 7000, loss: 0.088986
 >> iter 8000, loss: 0.077586
 >> iter 9000, loss: 0.071105
 >> iter 10000, loss: 0.063417
   Number of active neurons: 6
 >> iter 11000, loss: 0.049895
 >> iter 12000, loss: 0.042066
 >> iter 13000, loss: 0.051044
 >> iter 14000, loss: 0.048151
 >> iter 15000, loss: 0.063548
 >> iter 16000, loss: 0.070726
 >> iter 17000, loss: 0.061111
 >> iter 18000, loss: 0.054092
 >> iter 19000, loss: 0.048753
 >> iter 20000, loss: 0.048107
   Number of active neurons: 6
 >> iter 21000, loss: 0.062788
 >> iter 22000, loss: 0.054904
 >> iter 23000, loss: 0.048252
 >> iter 24000, loss: 0.058339
 >> iter 25000, loss: 0.053352
 >> iter 26000, loss: 0.049663
 >> iter 27000, loss: 0.047946
 >> iter 28000, loss: 0.045403
 >> iter 29000, loss: 0.047866
 >> iter 30000, loss: 0.058308
   Number of active neurons: 6
 >> iter 31000, loss: 0.078668
 >> iter 32000, loss: 0.061003
 >> iter 33000, loss: 0.051248
 >> iter 34000, loss: 0.057813
 >> iter 35000, loss: 0.056635
 >> iter 36000, loss: 0.067495
 >> iter 37000, loss: 0.049570
 >> iter 38000, loss: 0.058715
 >> iter 39000, loss: 0.080233
 >> iter 40000, loss: 0.049242
   Number of active neurons: 4
 >> iter 41000, loss: 0.056994
 >> iter 42000, loss: 0.054466
 >> iter 43000, loss: 0.048355
 >> iter 44000, loss: 0.050905
 >> iter 45000, loss: 0.063089
 >> iter 46000, loss: 0.049940
 >> iter 47000, loss: 0.054659
 >> iter 48000, loss: 0.045512
 >> iter 49000, loss: 0.040042
 >> iter 50000, loss: 0.035878
   Number of active neurons: 3
 >> iter 51000, loss: 0.033158
 >> iter 52000, loss: 0.028192
 >> iter 53000, loss: 0.048920
 >> iter 54000, loss: 0.050529
 >> iter 55000, loss: 0.046181
 >> iter 56000, loss: 0.048181
 >> iter 57000, loss: 0.062559
 >> iter 58000, loss: 0.046316
 >> iter 59000, loss: 0.040020
 >> iter 60000, loss: 0.047875
   Number of active neurons: 3
 >> iter 61000, loss: 0.049596
 >> iter 62000, loss: 0.054245
 >> iter 63000, loss: 0.048760
 >> iter 64000, loss: 0.050474
 >> iter 65000, loss: 0.042893
 >> iter 66000, loss: 0.044895
 >> iter 67000, loss: 0.050479
 >> iter 68000, loss: 0.048286
 >> iter 69000, loss: 0.047921
 >> iter 70000, loss: 0.048604
   Number of active neurons: 3
 >> iter 71000, loss: 0.063803
 >> iter 72000, loss: 0.057635
 >> iter 73000, loss: 0.063885
 >> iter 74000, loss: 0.069111
 >> iter 75000, loss: 0.054549
 >> iter 76000, loss: 0.054495
 >> iter 77000, loss: 0.054002
 >> iter 78000, loss: 0.047601
 >> iter 79000, loss: 0.041078
 >> iter 80000, loss: 0.048663
   Number of active neurons: 3
 >> iter 81000, loss: 0.040826
 >> iter 82000, loss: 0.054606
 >> iter 83000, loss: 0.058092
 >> iter 84000, loss: 0.058913
 >> iter 85000, loss: 0.040281
 >> iter 86000, loss: 0.050156
 >> iter 87000, loss: 0.068021
 >> iter 88000, loss: 0.063711
 >> iter 89000, loss: 0.051334
 >> iter 90000, loss: 0.069103
   Number of active neurons: 3
 >> iter 91000, loss: 0.054294
 >> iter 92000, loss: 0.065407
 >> iter 93000, loss: 0.039847
 >> iter 94000, loss: 0.043557
 >> iter 95000, loss: 0.047429
 >> iter 96000, loss: 0.040957
 >> iter 97000, loss: 0.033290
 >> iter 98000, loss: 0.032886
 >> iter 99000, loss: 0.038912
 >> iter 100000, loss: 0.057159
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.418052
 >> iter 2000, loss: 4.474871
 >> iter 3000, loss: 1.754291
 >> iter 4000, loss: 0.744422
 >> iter 5000, loss: 0.335660
 >> iter 6000, loss: 0.180763
 >> iter 7000, loss: 0.124178
 >> iter 8000, loss: 0.092234
 >> iter 9000, loss: 0.085509
 >> iter 10000, loss: 0.077208
   Number of active neurons: 7
 >> iter 11000, loss: 0.084453
 >> iter 12000, loss: 0.075510
 >> iter 13000, loss: 0.086646
 >> iter 14000, loss: 0.078119
 >> iter 15000, loss: 0.068897
 >> iter 16000, loss: 0.068586
 >> iter 17000, loss: 0.065915
 >> iter 18000, loss: 0.066003
 >> iter 19000, loss: 0.051721
 >> iter 20000, loss: 0.056991
   Number of active neurons: 7
 >> iter 21000, loss: 0.063698
 >> iter 22000, loss: 0.050908
 >> iter 23000, loss: 0.053651
 >> iter 24000, loss: 0.044185
 >> iter 25000, loss: 0.063566
 >> iter 26000, loss: 0.047213
 >> iter 27000, loss: 0.058291
 >> iter 28000, loss: 0.058158
 >> iter 29000, loss: 0.048194
 >> iter 30000, loss: 0.048142
   Number of active neurons: 5
 >> iter 31000, loss: 0.052671
 >> iter 32000, loss: 0.066053
 >> iter 33000, loss: 0.064629
 >> iter 34000, loss: 0.042853
 >> iter 35000, loss: 0.055101
 >> iter 36000, loss: 0.042070
 >> iter 37000, loss: 0.052374
 >> iter 38000, loss: 0.063670
 >> iter 39000, loss: 0.047391
 >> iter 40000, loss: 0.055436
   Number of active neurons: 5
 >> iter 41000, loss: 0.053995
 >> iter 42000, loss: 0.049729
 >> iter 43000, loss: 0.059291
 >> iter 44000, loss: 0.040428
 >> iter 45000, loss: 0.044043
 >> iter 46000, loss: 0.037305
 >> iter 47000, loss: 0.036388
 >> iter 48000, loss: 0.032461
 >> iter 49000, loss: 0.055752
 >> iter 50000, loss: 0.042170
   Number of active neurons: 4
 >> iter 51000, loss: 0.031726
 >> iter 52000, loss: 0.036449
 >> iter 53000, loss: 0.042754
 >> iter 54000, loss: 0.044283
 >> iter 55000, loss: 0.037494
 >> iter 56000, loss: 0.065436
 >> iter 57000, loss: 0.060271
 >> iter 58000, loss: 0.062949
 >> iter 59000, loss: 0.048603
 >> iter 60000, loss: 0.044394
   Number of active neurons: 4
 >> iter 61000, loss: 0.038977
 >> iter 62000, loss: 0.047361
 >> iter 63000, loss: 0.056016
 >> iter 64000, loss: 0.042028
 >> iter 65000, loss: 0.034700
 >> iter 66000, loss: 0.043647
 >> iter 67000, loss: 0.060635
 >> iter 68000, loss: 0.044953
 >> iter 69000, loss: 0.048722
 >> iter 70000, loss: 0.059725
   Number of active neurons: 4
 >> iter 71000, loss: 0.059436
 >> iter 72000, loss: 0.048634
 >> iter 73000, loss: 0.061739
 >> iter 74000, loss: 0.061917
 >> iter 75000, loss: 0.045025
 >> iter 76000, loss: 0.034966
 >> iter 77000, loss: 0.044636
 >> iter 78000, loss: 0.049323
 >> iter 79000, loss: 0.036301
 >> iter 80000, loss: 0.044780
   Number of active neurons: 3
 >> iter 81000, loss: 0.053866
 >> iter 82000, loss: 0.067681
 >> iter 83000, loss: 0.068735
 >> iter 84000, loss: 0.046220
 >> iter 85000, loss: 0.036258
 >> iter 86000, loss: 0.037513
 >> iter 87000, loss: 0.058666
 >> iter 88000, loss: 0.052961
 >> iter 89000, loss: 0.075464
 >> iter 90000, loss: 0.067805
   Number of active neurons: 3
 >> iter 91000, loss: 0.060159
 >> iter 92000, loss: 0.057628
 >> iter 93000, loss: 0.048026
 >> iter 94000, loss: 0.032551
 >> iter 95000, loss: 0.061249
 >> iter 96000, loss: 0.053980
 >> iter 97000, loss: 0.063390
 >> iter 98000, loss: 0.051748
 >> iter 99000, loss: 0.039168
 >> iter 100000, loss: 0.039896
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.430100
 >> iter 2000, loss: 4.414592
 >> iter 3000, loss: 1.725924
 >> iter 4000, loss: 0.700374
 >> iter 5000, loss: 0.307359
 >> iter 6000, loss: 0.158329
 >> iter 7000, loss: 0.107002
 >> iter 8000, loss: 0.086660
 >> iter 9000, loss: 0.128568
 >> iter 10000, loss: 0.093816
   Number of active neurons: 5
 >> iter 11000, loss: 0.065085
 >> iter 12000, loss: 0.047862
 >> iter 13000, loss: 0.054988
 >> iter 14000, loss: 0.058825
 >> iter 15000, loss: 0.064474
 >> iter 16000, loss: 0.052784
 >> iter 17000, loss: 0.065358
 >> iter 18000, loss: 0.053749
 >> iter 19000, loss: 0.046418
 >> iter 20000, loss: 0.077315
   Number of active neurons: 5
 >> iter 21000, loss: 0.048007
 >> iter 22000, loss: 0.047912
 >> iter 23000, loss: 0.070604
 >> iter 24000, loss: 0.051057
 >> iter 25000, loss: 0.067970
 >> iter 26000, loss: 0.045865
 >> iter 27000, loss: 0.062224
 >> iter 28000, loss: 0.052715
 >> iter 29000, loss: 0.045517
 >> iter 30000, loss: 0.041357
   Number of active neurons: 5
 >> iter 31000, loss: 0.063699
 >> iter 32000, loss: 0.052149
 >> iter 33000, loss: 0.055749
 >> iter 34000, loss: 0.044396
 >> iter 35000, loss: 0.038188
 >> iter 36000, loss: 0.036009
 >> iter 37000, loss: 0.038948
 >> iter 38000, loss: 0.041640
 >> iter 39000, loss: 0.039512
 >> iter 40000, loss: 0.047116
   Number of active neurons: 4
 >> iter 41000, loss: 0.050348
 >> iter 42000, loss: 0.080589
 >> iter 43000, loss: 0.054446
 >> iter 44000, loss: 0.043857
 >> iter 45000, loss: 0.058722
 >> iter 46000, loss: 0.045005
 >> iter 47000, loss: 0.038283
 >> iter 48000, loss: 0.037558
 >> iter 49000, loss: 0.038327
 >> iter 50000, loss: 0.042664
   Number of active neurons: 4
 >> iter 51000, loss: 0.045121
 >> iter 52000, loss: 0.051063
 >> iter 53000, loss: 0.043502
 >> iter 54000, loss: 0.057819
 >> iter 55000, loss: 0.057046
 >> iter 56000, loss: 0.055480
 >> iter 57000, loss: 0.045227
 >> iter 58000, loss: 0.047433
 >> iter 59000, loss: 0.057679
 >> iter 60000, loss: 0.047239
   Number of active neurons: 4
 >> iter 61000, loss: 0.056510
 >> iter 62000, loss: 0.045037
 >> iter 63000, loss: 0.051761
 >> iter 64000, loss: 0.058517
 >> iter 65000, loss: 0.042595
 >> iter 66000, loss: 0.033465
 >> iter 67000, loss: 0.032972
 >> iter 68000, loss: 0.049684
 >> iter 69000, loss: 0.050005
 >> iter 70000, loss: 0.036567
   Number of active neurons: 4
 >> iter 71000, loss: 0.034243
 >> iter 72000, loss: 0.031982
 >> iter 73000, loss: 0.038872
 >> iter 74000, loss: 0.043232
 >> iter 75000, loss: 0.060427
 >> iter 76000, loss: 0.056814
 >> iter 77000, loss: 0.045341
 >> iter 78000, loss: 0.039238
 >> iter 79000, loss: 0.064768
 >> iter 80000, loss: 0.058427
   Number of active neurons: 4
 >> iter 81000, loss: 0.059629
 >> iter 82000, loss: 0.046800
 >> iter 83000, loss: 0.042008
 >> iter 84000, loss: 0.050676
 >> iter 85000, loss: 0.046391
 >> iter 86000, loss: 0.048680
 >> iter 87000, loss: 0.049566
 >> iter 88000, loss: 0.053900
 >> iter 89000, loss: 0.048304
 >> iter 90000, loss: 0.076215
   Number of active neurons: 4
 >> iter 91000, loss: 0.067900
 >> iter 92000, loss: 0.044421
 >> iter 93000, loss: 0.045859
 >> iter 94000, loss: 0.049002
 >> iter 95000, loss: 0.042117
 >> iter 96000, loss: 0.042046
 >> iter 97000, loss: 0.047702
 >> iter 98000, loss: 0.036359
 >> iter 99000, loss: 0.040735
 >> iter 100000, loss: 0.059084
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.280887
 >> iter 2000, loss: 4.331425
 >> iter 3000, loss: 1.666489
 >> iter 4000, loss: 0.678314
 >> iter 5000, loss: 0.293056
 >> iter 6000, loss: 0.141787
 >> iter 7000, loss: 0.114950
 >> iter 8000, loss: 0.100447
 >> iter 9000, loss: 0.077117
 >> iter 10000, loss: 0.076991
   Number of active neurons: 6
 >> iter 11000, loss: 0.072823
 >> iter 12000, loss: 0.076237
 >> iter 13000, loss: 0.069937
 >> iter 14000, loss: 0.049041
 >> iter 15000, loss: 0.059808
 >> iter 16000, loss: 0.054170
 >> iter 17000, loss: 0.087308
 >> iter 18000, loss: 0.059668
 >> iter 19000, loss: 0.058946
 >> iter 20000, loss: 0.050331
   Number of active neurons: 6
 >> iter 21000, loss: 0.045267
 >> iter 22000, loss: 0.048676
 >> iter 23000, loss: 0.051516
 >> iter 24000, loss: 0.044491
 >> iter 25000, loss: 0.038984
 >> iter 26000, loss: 0.048238
 >> iter 27000, loss: 0.071055
 >> iter 28000, loss: 0.063378
 >> iter 29000, loss: 0.062383
 >> iter 30000, loss: 0.053273
   Number of active neurons: 6
 >> iter 31000, loss: 0.076347
 >> iter 32000, loss: 0.058318
 >> iter 33000, loss: 0.051354
 >> iter 34000, loss: 0.056598
 >> iter 35000, loss: 0.072492
 >> iter 36000, loss: 0.057206
 >> iter 37000, loss: 0.057152
 >> iter 38000, loss: 0.039309
 >> iter 39000, loss: 0.041303
 >> iter 40000, loss: 0.043636
   Number of active neurons: 6
 >> iter 41000, loss: 0.055960
 >> iter 42000, loss: 0.041297
 >> iter 43000, loss: 0.083482
 >> iter 44000, loss: 0.070679
 >> iter 45000, loss: 0.054436
 >> iter 46000, loss: 0.048999
 >> iter 47000, loss: 0.054157
 >> iter 48000, loss: 0.066341
 >> iter 49000, loss: 0.048422
 >> iter 50000, loss: 0.057542
   Number of active neurons: 5
 >> iter 51000, loss: 0.043850
 >> iter 52000, loss: 0.064940
 >> iter 53000, loss: 0.075661
 >> iter 54000, loss: 0.055636
 >> iter 55000, loss: 0.079243
 >> iter 56000, loss: 0.058961
 >> iter 57000, loss: 0.066574
 >> iter 58000, loss: 0.051893
 >> iter 59000, loss: 0.044172
 >> iter 60000, loss: 0.048130
   Number of active neurons: 4
 >> iter 61000, loss: 0.041142
 >> iter 62000, loss: 0.043058
 >> iter 63000, loss: 0.047288
 >> iter 64000, loss: 0.064475
 >> iter 65000, loss: 0.055786
 >> iter 66000, loss: 0.049600
 >> iter 67000, loss: 0.046951
 >> iter 68000, loss: 0.062918
 >> iter 69000, loss: 0.068752
 >> iter 70000, loss: 0.049142
   Number of active neurons: 3
 >> iter 71000, loss: 0.034555
 >> iter 72000, loss: 0.035397
 >> iter 73000, loss: 0.050672
 >> iter 74000, loss: 0.045222
 >> iter 75000, loss: 0.058510
 >> iter 76000, loss: 0.040359
 >> iter 77000, loss: 0.060883
 >> iter 78000, loss: 0.062375
 >> iter 79000, loss: 0.054280
 >> iter 80000, loss: 0.046568
   Number of active neurons: 3
 >> iter 81000, loss: 0.046485
 >> iter 82000, loss: 0.054310
 >> iter 83000, loss: 0.050839
 >> iter 84000, loss: 0.056484
 >> iter 85000, loss: 0.056590
 >> iter 86000, loss: 0.049790
 >> iter 87000, loss: 0.042175
 >> iter 88000, loss: 0.048922
 >> iter 89000, loss: 0.045615
 >> iter 90000, loss: 0.049927
   Number of active neurons: 3
 >> iter 91000, loss: 0.041795
 >> iter 92000, loss: 0.056975
 >> iter 93000, loss: 0.040297
 >> iter 94000, loss: 0.045374
 >> iter 95000, loss: 0.041533
 >> iter 96000, loss: 0.035873
 >> iter 97000, loss: 0.039203
 >> iter 98000, loss: 0.036062
 >> iter 99000, loss: 0.040957
 >> iter 100000, loss: 0.042661
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 11.286637
 >> iter 2000, loss: 4.321082
 >> iter 3000, loss: 1.704784
 >> iter 4000, loss: 0.686373
 >> iter 5000, loss: 0.309870
 >> iter 6000, loss: 0.148953
 >> iter 7000, loss: 0.094580
 >> iter 8000, loss: 0.080674
 >> iter 9000, loss: 0.088082
 >> iter 10000, loss: 0.071699
   Number of active neurons: 6
 >> iter 11000, loss: 0.082169
 >> iter 12000, loss: 0.069331
 >> iter 13000, loss: 0.059254
 >> iter 14000, loss: 0.045362
 >> iter 15000, loss: 0.063633
 >> iter 16000, loss: 0.060327
 >> iter 17000, loss: 0.064425
 >> iter 18000, loss: 0.072273
 >> iter 19000, loss: 0.078444
 >> iter 20000, loss: 0.069242
   Number of active neurons: 6
 >> iter 21000, loss: 0.062117
 >> iter 22000, loss: 0.048448
 >> iter 23000, loss: 0.047889
 >> iter 24000, loss: 0.049882
 >> iter 25000, loss: 0.057083
 >> iter 26000, loss: 0.053821
 >> iter 27000, loss: 0.055624
 >> iter 28000, loss: 0.069369
 >> iter 29000, loss: 0.044948
 >> iter 30000, loss: 0.039432
   Number of active neurons: 5
 >> iter 31000, loss: 0.057674
 >> iter 32000, loss: 0.044991
 >> iter 33000, loss: 0.042701
 >> iter 34000, loss: 0.046957
 >> iter 35000, loss: 0.058562
 >> iter 36000, loss: 0.068902
 >> iter 37000, loss: 0.057300
 >> iter 38000, loss: 0.073884
 >> iter 39000, loss: 0.055905
 >> iter 40000, loss: 0.057922
   Number of active neurons: 5
 >> iter 41000, loss: 0.040111
 >> iter 42000, loss: 0.047062
 >> iter 43000, loss: 0.058750
 >> iter 44000, loss: 0.041508
 >> iter 45000, loss: 0.049479
 >> iter 46000, loss: 0.048689
 >> iter 47000, loss: 0.046883
 >> iter 48000, loss: 0.040723
 >> iter 49000, loss: 0.038638
 >> iter 50000, loss: 0.032805
   Number of active neurons: 5
 >> iter 51000, loss: 0.044389
 >> iter 52000, loss: 0.071004
 >> iter 53000, loss: 0.054778
 >> iter 54000, loss: 0.045704
 >> iter 55000, loss: 0.073952
 >> iter 56000, loss: 0.062215
 >> iter 57000, loss: 0.052163
 >> iter 58000, loss: 0.047947
 >> iter 59000, loss: 0.073686
 >> iter 60000, loss: 0.059214
   Number of active neurons: 4
 >> iter 61000, loss: 0.076247
 >> iter 62000, loss: 0.061720
 >> iter 63000, loss: 0.045771
 >> iter 64000, loss: 0.055974
 >> iter 65000, loss: 0.041565
 >> iter 66000, loss: 0.045330
 >> iter 67000, loss: 0.045230
 >> iter 68000, loss: 0.046041
 >> iter 69000, loss: 0.058590
 >> iter 70000, loss: 0.047446
   Number of active neurons: 3
 >> iter 71000, loss: 0.078996
 >> iter 72000, loss: 0.057716
 >> iter 73000, loss: 0.051249
 >> iter 74000, loss: 0.046202
 >> iter 75000, loss: 0.044311
 >> iter 76000, loss: 0.071218
 >> iter 77000, loss: 0.061526
 >> iter 78000, loss: 0.084760
 >> iter 79000, loss: 0.059361
 >> iter 80000, loss: 0.044888
   Number of active neurons: 3
 >> iter 81000, loss: 0.045793
 >> iter 82000, loss: 0.046109
 >> iter 83000, loss: 0.058021
 >> iter 84000, loss: 0.044405
 >> iter 85000, loss: 0.046115
 >> iter 86000, loss: 0.053155
 >> iter 87000, loss: 0.057912
 >> iter 88000, loss: 0.049307
 >> iter 89000, loss: 0.043088
 >> iter 90000, loss: 0.033046
   Number of active neurons: 2
 >> iter 91000, loss: 0.061195
 >> iter 92000, loss: 0.072506
 >> iter 93000, loss: 0.060306
 >> iter 94000, loss: 0.040727
 >> iter 95000, loss: 0.052474
 >> iter 96000, loss: 0.043336
 >> iter 97000, loss: 0.039294
 >> iter 98000, loss: 0.047821
 >> iter 99000, loss: 0.048585
 >> iter 100000, loss: 0.035549
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.520221
 >> iter 2000, loss: 4.576976
 >> iter 3000, loss: 1.827288
 >> iter 4000, loss: 0.770982
 >> iter 5000, loss: 0.376123
 >> iter 6000, loss: 0.194700
 >> iter 7000, loss: 0.157977
 >> iter 8000, loss: 0.110394
 >> iter 9000, loss: 0.079775
 >> iter 10000, loss: 0.072599
   Number of active neurons: 6
 >> iter 11000, loss: 0.068942
 >> iter 12000, loss: 0.053990
 >> iter 13000, loss: 0.061092
 >> iter 14000, loss: 0.065477
 >> iter 15000, loss: 0.053610
 >> iter 16000, loss: 0.050292
 >> iter 17000, loss: 0.061487
 >> iter 18000, loss: 0.051806
 >> iter 19000, loss: 0.051660
 >> iter 20000, loss: 0.050489
   Number of active neurons: 6
 >> iter 21000, loss: 0.048123
 >> iter 22000, loss: 0.054686
 >> iter 23000, loss: 0.043820
 >> iter 24000, loss: 0.053637
 >> iter 25000, loss: 0.069860
 >> iter 26000, loss: 0.051472
 >> iter 27000, loss: 0.053933
 >> iter 28000, loss: 0.056316
 >> iter 29000, loss: 0.083955
 >> iter 30000, loss: 0.061803
   Number of active neurons: 5
 >> iter 31000, loss: 0.048684
 >> iter 32000, loss: 0.047353
 >> iter 33000, loss: 0.045876
 >> iter 34000, loss: 0.050850
 >> iter 35000, loss: 0.052754
 >> iter 36000, loss: 0.063257
 >> iter 37000, loss: 0.068942
 >> iter 38000, loss: 0.044814
 >> iter 39000, loss: 0.061785
 >> iter 40000, loss: 0.049423
   Number of active neurons: 5
 >> iter 41000, loss: 0.056494
 >> iter 42000, loss: 0.057579
 >> iter 43000, loss: 0.056634
 >> iter 44000, loss: 0.043886
 >> iter 45000, loss: 0.051222
 >> iter 46000, loss: 0.050863
 >> iter 47000, loss: 0.045681
 >> iter 48000, loss: 0.048432
 >> iter 49000, loss: 0.048176
 >> iter 50000, loss: 0.041947
   Number of active neurons: 5
 >> iter 51000, loss: 0.041141
 >> iter 52000, loss: 0.036914
 >> iter 53000, loss: 0.042206
 >> iter 54000, loss: 0.053175
 >> iter 55000, loss: 0.043388
 >> iter 56000, loss: 0.034912
 >> iter 57000, loss: 0.051138
 >> iter 58000, loss: 0.049760
 >> iter 59000, loss: 0.043564
 >> iter 60000, loss: 0.048157
   Number of active neurons: 4
 >> iter 61000, loss: 0.050485
 >> iter 62000, loss: 0.041967
 >> iter 63000, loss: 0.045389
 >> iter 64000, loss: 0.041521
 >> iter 65000, loss: 0.046387
 >> iter 66000, loss: 0.038362
 >> iter 67000, loss: 0.044679
 >> iter 68000, loss: 0.040362
 >> iter 69000, loss: 0.030917
 >> iter 70000, loss: 0.042366
   Number of active neurons: 4
 >> iter 71000, loss: 0.049641
 >> iter 72000, loss: 0.047038
 >> iter 73000, loss: 0.047580
 >> iter 74000, loss: 0.053618
 >> iter 75000, loss: 0.053529
 >> iter 76000, loss: 0.036753
 >> iter 77000, loss: 0.032448
 >> iter 78000, loss: 0.036547
 >> iter 79000, loss: 0.031453
 >> iter 80000, loss: 0.041220
   Number of active neurons: 3
 >> iter 81000, loss: 0.054136
 >> iter 82000, loss: 0.042290
 >> iter 83000, loss: 0.048600
 >> iter 84000, loss: 0.040239
 >> iter 85000, loss: 0.046827
 >> iter 86000, loss: 0.041899
 >> iter 87000, loss: 0.033848
 >> iter 88000, loss: 0.035956
 >> iter 89000, loss: 0.053551
 >> iter 90000, loss: 0.040179
   Number of active neurons: 3
 >> iter 91000, loss: 0.041246
 >> iter 92000, loss: 0.041827
 >> iter 93000, loss: 0.039872
 >> iter 94000, loss: 0.030126
 >> iter 95000, loss: 0.035225
 >> iter 96000, loss: 0.046120
 >> iter 97000, loss: 0.044543
 >> iter 98000, loss: 0.059055
 >> iter 99000, loss: 0.057399
 >> iter 100000, loss: 0.039553
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.446391
 >> iter 2000, loss: 4.441098
 >> iter 3000, loss: 1.723989
 >> iter 4000, loss: 0.714812
 >> iter 5000, loss: 0.323413
 >> iter 6000, loss: 0.164364
 >> iter 7000, loss: 0.098552
 >> iter 8000, loss: 0.073025
 >> iter 9000, loss: 0.062200
 >> iter 10000, loss: 0.057096
   Number of active neurons: 5
 >> iter 11000, loss: 0.047934
 >> iter 12000, loss: 0.062163
 >> iter 13000, loss: 0.071242
 >> iter 14000, loss: 0.064557
 >> iter 15000, loss: 0.059071
 >> iter 16000, loss: 0.051303
 >> iter 17000, loss: 0.054533
 >> iter 18000, loss: 0.050664
 >> iter 19000, loss: 0.043551
 >> iter 20000, loss: 0.055263
   Number of active neurons: 5
 >> iter 21000, loss: 0.060519
 >> iter 22000, loss: 0.062809
 >> iter 23000, loss: 0.052595
 >> iter 24000, loss: 0.051325
 >> iter 25000, loss: 0.054211
 >> iter 26000, loss: 0.051096
 >> iter 27000, loss: 0.043376
 >> iter 28000, loss: 0.040906
 >> iter 29000, loss: 0.081859
 >> iter 30000, loss: 0.071799
   Number of active neurons: 3
 >> iter 31000, loss: 0.058418
 >> iter 32000, loss: 0.045947
 >> iter 33000, loss: 0.049467
 >> iter 34000, loss: 0.046189
 >> iter 35000, loss: 0.076791
 >> iter 36000, loss: 0.051362
 >> iter 37000, loss: 0.050930
 >> iter 38000, loss: 0.042381
 >> iter 39000, loss: 0.035878
 >> iter 40000, loss: 0.052147
   Number of active neurons: 3
 >> iter 41000, loss: 0.037291
 >> iter 42000, loss: 0.032502
 >> iter 43000, loss: 0.037011
 >> iter 44000, loss: 0.029013
 >> iter 45000, loss: 0.046473
 >> iter 46000, loss: 0.049152
 >> iter 47000, loss: 0.046886
 >> iter 48000, loss: 0.044771
 >> iter 49000, loss: 0.054681
 >> iter 50000, loss: 0.046452
   Number of active neurons: 3
 >> iter 51000, loss: 0.051582
 >> iter 52000, loss: 0.050934
 >> iter 53000, loss: 0.041304
 >> iter 54000, loss: 0.037568
 >> iter 55000, loss: 0.042670
 >> iter 56000, loss: 0.046578
 >> iter 57000, loss: 0.059207
 >> iter 58000, loss: 0.048835
 >> iter 59000, loss: 0.042748
 >> iter 60000, loss: 0.049392
   Number of active neurons: 2
 >> iter 61000, loss: 0.037121
 >> iter 62000, loss: 0.033498
 >> iter 63000, loss: 0.040640
 >> iter 64000, loss: 0.032472
 >> iter 65000, loss: 0.048881
 >> iter 66000, loss: 0.060936
 >> iter 67000, loss: 0.050680
 >> iter 68000, loss: 0.038701
 >> iter 69000, loss: 0.059955
 >> iter 70000, loss: 0.040843
   Number of active neurons: 2
 >> iter 71000, loss: 0.043373
 >> iter 72000, loss: 0.047152
 >> iter 73000, loss: 0.052400
 >> iter 74000, loss: 0.040759
 >> iter 75000, loss: 0.049409
 >> iter 76000, loss: 0.051152
 >> iter 77000, loss: 0.060105
 >> iter 78000, loss: 0.071152
 >> iter 79000, loss: 0.043606
 >> iter 80000, loss: 0.053523
   Number of active neurons: 2
 >> iter 81000, loss: 0.043573
 >> iter 82000, loss: 0.051444
 >> iter 83000, loss: 0.049641
 >> iter 84000, loss: 0.044415
 >> iter 85000, loss: 0.039821
 >> iter 86000, loss: 0.055306
 >> iter 87000, loss: 0.047168
 >> iter 88000, loss: 0.056763
 >> iter 89000, loss: 0.036834
 >> iter 90000, loss: 0.066136
   Number of active neurons: 2
 >> iter 91000, loss: 0.065137
 >> iter 92000, loss: 0.052766
 >> iter 93000, loss: 0.038752
 >> iter 94000, loss: 0.040063
 >> iter 95000, loss: 0.042413
 >> iter 96000, loss: 0.050907
 >> iter 97000, loss: 0.045425
 >> iter 98000, loss: 0.052296
 >> iter 99000, loss: 0.051960
 >> iter 100000, loss: 0.057899
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.386696
 >> iter 2000, loss: 4.376743
 >> iter 3000, loss: 1.732548
 >> iter 4000, loss: 0.717128
 >> iter 5000, loss: 0.312488
 >> iter 6000, loss: 0.174256
 >> iter 7000, loss: 0.109548
 >> iter 8000, loss: 0.073674
 >> iter 9000, loss: 0.072962
 >> iter 10000, loss: 0.057891
   Number of active neurons: 5
 >> iter 11000, loss: 0.061704
 >> iter 12000, loss: 0.059189
 >> iter 13000, loss: 0.076817
 >> iter 14000, loss: 0.090895
 >> iter 15000, loss: 0.067245
 >> iter 16000, loss: 0.048189
 >> iter 17000, loss: 0.053198
 >> iter 18000, loss: 0.048297
 >> iter 19000, loss: 0.061005
 >> iter 20000, loss: 0.061302
   Number of active neurons: 5
 >> iter 21000, loss: 0.062984
 >> iter 22000, loss: 0.062175
 >> iter 23000, loss: 0.069867
 >> iter 24000, loss: 0.060829
 >> iter 25000, loss: 0.053285
 >> iter 26000, loss: 0.051576
 >> iter 27000, loss: 0.040016
 >> iter 28000, loss: 0.052489
 >> iter 29000, loss: 0.044672
 >> iter 30000, loss: 0.044014
   Number of active neurons: 5
 >> iter 31000, loss: 0.065700
 >> iter 32000, loss: 0.055431
 >> iter 33000, loss: 0.077361
 >> iter 34000, loss: 0.052105
 >> iter 35000, loss: 0.061283
 >> iter 36000, loss: 0.056673
 >> iter 37000, loss: 0.053630
 >> iter 38000, loss: 0.044513
 >> iter 39000, loss: 0.038788
 >> iter 40000, loss: 0.040128
   Number of active neurons: 4
 >> iter 41000, loss: 0.058868
 >> iter 42000, loss: 0.052654
 >> iter 43000, loss: 0.058837
 >> iter 44000, loss: 0.055165
 >> iter 45000, loss: 0.050447
 >> iter 46000, loss: 0.048916
 >> iter 47000, loss: 0.045239
 >> iter 48000, loss: 0.057885
 >> iter 49000, loss: 0.054017
 >> iter 50000, loss: 0.050789
   Number of active neurons: 4
 >> iter 51000, loss: 0.061518
 >> iter 52000, loss: 0.061704
 >> iter 53000, loss: 0.057660
 >> iter 54000, loss: 0.042853
 >> iter 55000, loss: 0.043243
 >> iter 56000, loss: 0.043033
 >> iter 57000, loss: 0.048092
 >> iter 58000, loss: 0.064225
 >> iter 59000, loss: 0.050641
 >> iter 60000, loss: 0.063958
   Number of active neurons: 2
 >> iter 61000, loss: 0.049486
 >> iter 62000, loss: 0.047564
 >> iter 63000, loss: 0.059478
 >> iter 64000, loss: 0.056339
 >> iter 65000, loss: 0.045905
 >> iter 66000, loss: 0.035789
 >> iter 67000, loss: 0.038526
 >> iter 68000, loss: 0.032726
 >> iter 69000, loss: 0.040726
 >> iter 70000, loss: 0.046577
   Number of active neurons: 2
 >> iter 71000, loss: 0.050574
 >> iter 72000, loss: 0.036082
 >> iter 73000, loss: 0.034471
 >> iter 74000, loss: 0.028361
 >> iter 75000, loss: 0.062407
 >> iter 76000, loss: 0.043109
 >> iter 77000, loss: 0.033489
 >> iter 78000, loss: 0.039467
 >> iter 79000, loss: 0.067024
 >> iter 80000, loss: 0.056372
   Number of active neurons: 2
 >> iter 81000, loss: 0.051248
 >> iter 82000, loss: 0.043790
 >> iter 83000, loss: 0.040655
 >> iter 84000, loss: 0.048767
 >> iter 85000, loss: 0.046342
 >> iter 86000, loss: 0.057005
 >> iter 87000, loss: 0.064645
 >> iter 88000, loss: 0.046336
 >> iter 89000, loss: 0.034526
 >> iter 90000, loss: 0.037619
   Number of active neurons: 2
 >> iter 91000, loss: 0.044160
 >> iter 92000, loss: 0.049549
 >> iter 93000, loss: 0.040799
 >> iter 94000, loss: 0.046141
 >> iter 95000, loss: 0.045278
 >> iter 96000, loss: 0.041196
 >> iter 97000, loss: 0.037995
 >> iter 98000, loss: 0.037264
 >> iter 99000, loss: 0.060763
 >> iter 100000, loss: 0.039659
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.387320
 >> iter 2000, loss: 4.452879
 >> iter 3000, loss: 1.737657
 >> iter 4000, loss: 0.724800
 >> iter 5000, loss: 0.334854
 >> iter 6000, loss: 0.176722
 >> iter 7000, loss: 0.113070
 >> iter 8000, loss: 0.079535
 >> iter 9000, loss: 0.065247
 >> iter 10000, loss: 0.054402
   Number of active neurons: 6
 >> iter 11000, loss: 0.065655
 >> iter 12000, loss: 0.053826
 >> iter 13000, loss: 0.042810
 >> iter 14000, loss: 0.048962
 >> iter 15000, loss: 0.075838
 >> iter 16000, loss: 0.064709
 >> iter 17000, loss: 0.045903
 >> iter 18000, loss: 0.037652
 >> iter 19000, loss: 0.075704
 >> iter 20000, loss: 0.073924
   Number of active neurons: 4
 >> iter 21000, loss: 0.049558
 >> iter 22000, loss: 0.055625
 >> iter 23000, loss: 0.045038
 >> iter 24000, loss: 0.036173
 >> iter 25000, loss: 0.049632
 >> iter 26000, loss: 0.052678
 >> iter 27000, loss: 0.055437
 >> iter 28000, loss: 0.044532
 >> iter 29000, loss: 0.043454
 >> iter 30000, loss: 0.043070
   Number of active neurons: 4
 >> iter 31000, loss: 0.046239
 >> iter 32000, loss: 0.053927
 >> iter 33000, loss: 0.056638
 >> iter 34000, loss: 0.047463
 >> iter 35000, loss: 0.038127
 >> iter 36000, loss: 0.042703
 >> iter 37000, loss: 0.046160
 >> iter 38000, loss: 0.046821
 >> iter 39000, loss: 0.042069
 >> iter 40000, loss: 0.045436
   Number of active neurons: 4
 >> iter 41000, loss: 0.042481
 >> iter 42000, loss: 0.053713
 >> iter 43000, loss: 0.054402
 >> iter 44000, loss: 0.047046
 >> iter 45000, loss: 0.062777
 >> iter 46000, loss: 0.043692
 >> iter 47000, loss: 0.044789
 >> iter 48000, loss: 0.041394
 >> iter 49000, loss: 0.039190
 >> iter 50000, loss: 0.053291
   Number of active neurons: 3
 >> iter 51000, loss: 0.044608
 >> iter 52000, loss: 0.046297
 >> iter 53000, loss: 0.058641
 >> iter 54000, loss: 0.046799
 >> iter 55000, loss: 0.055092
 >> iter 56000, loss: 0.045934
 >> iter 57000, loss: 0.043872
 >> iter 58000, loss: 0.053406
 >> iter 59000, loss: 0.052246
 >> iter 60000, loss: 0.047535
   Number of active neurons: 3
 >> iter 61000, loss: 0.068007
 >> iter 62000, loss: 0.065023
 >> iter 63000, loss: 0.044364
 >> iter 64000, loss: 0.047053
 >> iter 65000, loss: 0.052872
 >> iter 66000, loss: 0.050711
 >> iter 67000, loss: 0.043826
 >> iter 68000, loss: 0.041041
 >> iter 69000, loss: 0.034902
 >> iter 70000, loss: 0.043076
   Number of active neurons: 3
 >> iter 71000, loss: 0.056554
 >> iter 72000, loss: 0.056292
 >> iter 73000, loss: 0.048336
 >> iter 74000, loss: 0.047889
 >> iter 75000, loss: 0.062213
 >> iter 76000, loss: 0.068984
 >> iter 77000, loss: 0.049790
 >> iter 78000, loss: 0.041912
 >> iter 79000, loss: 0.042644
 >> iter 80000, loss: 0.042713
   Number of active neurons: 3
 >> iter 81000, loss: 0.048052
 >> iter 82000, loss: 0.036734
 >> iter 83000, loss: 0.044400
 >> iter 84000, loss: 0.046635
 >> iter 85000, loss: 0.044159
 >> iter 86000, loss: 0.049487
 >> iter 87000, loss: 0.046719
 >> iter 88000, loss: 0.048754
 >> iter 89000, loss: 0.056046
 >> iter 90000, loss: 0.039629
   Number of active neurons: 3
 >> iter 91000, loss: 0.049191
 >> iter 92000, loss: 0.057095
 >> iter 93000, loss: 0.037209
 >> iter 94000, loss: 0.052105
 >> iter 95000, loss: 0.048976
 >> iter 96000, loss: 0.059292
 >> iter 97000, loss: 0.042062
 >> iter 98000, loss: 0.052361
 >> iter 99000, loss: 0.042387
 >> iter 100000, loss: 0.061494
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.364503
 >> iter 2000, loss: 4.418234
 >> iter 3000, loss: 1.727417
 >> iter 4000, loss: 0.689995
 >> iter 5000, loss: 0.315651
 >> iter 6000, loss: 0.146529
 >> iter 7000, loss: 0.112687
 >> iter 8000, loss: 0.098486
 >> iter 9000, loss: 0.079650
 >> iter 10000, loss: 0.071307
   Number of active neurons: 6
 >> iter 11000, loss: 0.094413
 >> iter 12000, loss: 0.062952
 >> iter 13000, loss: 0.073479
 >> iter 14000, loss: 0.057016
 >> iter 15000, loss: 0.069584
 >> iter 16000, loss: 0.058440
 >> iter 17000, loss: 0.043750
 >> iter 18000, loss: 0.050236
 >> iter 19000, loss: 0.084221
 >> iter 20000, loss: 0.067102
   Number of active neurons: 6
 >> iter 21000, loss: 0.063697
 >> iter 22000, loss: 0.059698
 >> iter 23000, loss: 0.055549
 >> iter 24000, loss: 0.056199
 >> iter 25000, loss: 0.049394
 >> iter 26000, loss: 0.049619
 >> iter 27000, loss: 0.075324
 >> iter 28000, loss: 0.071350
 >> iter 29000, loss: 0.064035
 >> iter 30000, loss: 0.055042
   Number of active neurons: 6
 >> iter 31000, loss: 0.049774
 >> iter 32000, loss: 0.052208
 >> iter 33000, loss: 0.050437
 >> iter 34000, loss: 0.049568
 >> iter 35000, loss: 0.042220
 >> iter 36000, loss: 0.046409
 >> iter 37000, loss: 0.051464
 >> iter 38000, loss: 0.044278
 >> iter 39000, loss: 0.061057
 >> iter 40000, loss: 0.079244
   Number of active neurons: 6
 >> iter 41000, loss: 0.057453
 >> iter 42000, loss: 0.063118
 >> iter 43000, loss: 0.059557
 >> iter 44000, loss: 0.049631
 >> iter 45000, loss: 0.052031
 >> iter 46000, loss: 0.073251
 >> iter 47000, loss: 0.077852
 >> iter 48000, loss: 0.052289
 >> iter 49000, loss: 0.063163
 >> iter 50000, loss: 0.055590
   Number of active neurons: 6
 >> iter 51000, loss: 0.061600
 >> iter 52000, loss: 0.061325
 >> iter 53000, loss: 0.045806
 >> iter 54000, loss: 0.048248
 >> iter 55000, loss: 0.047787
 >> iter 56000, loss: 0.052491
 >> iter 57000, loss: 0.045240
 >> iter 58000, loss: 0.048810
 >> iter 59000, loss: 0.053031
 >> iter 60000, loss: 0.050314
   Number of active neurons: 5
 >> iter 61000, loss: 0.060907
 >> iter 62000, loss: 0.051038
 >> iter 63000, loss: 0.058346
 >> iter 64000, loss: 0.053398
 >> iter 65000, loss: 0.051290
 >> iter 66000, loss: 0.038913
 >> iter 67000, loss: 0.034123
 >> iter 68000, loss: 0.044382
 >> iter 69000, loss: 0.053202
 >> iter 70000, loss: 0.046955
   Number of active neurons: 4
 >> iter 71000, loss: 0.054753
 >> iter 72000, loss: 0.050212
 >> iter 73000, loss: 0.059739
 >> iter 74000, loss: 0.052429
 >> iter 75000, loss: 0.055555
 >> iter 76000, loss: 0.054880
 >> iter 77000, loss: 0.078840
 >> iter 78000, loss: 0.052883
 >> iter 79000, loss: 0.070403
 >> iter 80000, loss: 0.064523
   Number of active neurons: 4
 >> iter 81000, loss: 0.041153
 >> iter 82000, loss: 0.033126
 >> iter 83000, loss: 0.038125
 >> iter 84000, loss: 0.034657
 >> iter 85000, loss: 0.052719
 >> iter 86000, loss: 0.037736
 >> iter 87000, loss: 0.044417
 >> iter 88000, loss: 0.034443
 >> iter 89000, loss: 0.048508
 >> iter 90000, loss: 0.038155
   Number of active neurons: 3
 >> iter 91000, loss: 0.039010
 >> iter 92000, loss: 0.054235
 >> iter 93000, loss: 0.061760
 >> iter 94000, loss: 0.050129
 >> iter 95000, loss: 0.051877
 >> iter 96000, loss: 0.047995
 >> iter 97000, loss: 0.041629
 >> iter 98000, loss: 0.062467
 >> iter 99000, loss: 0.061287
 >> iter 100000, loss: 0.053999
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 11.345502
 >> iter 2000, loss: 4.392303
 >> iter 3000, loss: 1.747941
 >> iter 4000, loss: 0.706929
 >> iter 5000, loss: 0.315492
 >> iter 6000, loss: 0.166253
 >> iter 7000, loss: 0.100952
 >> iter 8000, loss: 0.091765
 >> iter 9000, loss: 0.074964
 >> iter 10000, loss: 0.068607
   Number of active neurons: 7
 >> iter 11000, loss: 0.073585
 >> iter 12000, loss: 0.084543
 >> iter 13000, loss: 0.062320
 >> iter 14000, loss: 0.053056
 >> iter 15000, loss: 0.049627
 >> iter 16000, loss: 0.064120
 >> iter 17000, loss: 0.085672
 >> iter 18000, loss: 0.053791
 >> iter 19000, loss: 0.050264
 >> iter 20000, loss: 0.061608
   Number of active neurons: 6
 >> iter 21000, loss: 0.052421
 >> iter 22000, loss: 0.060273
 >> iter 23000, loss: 0.054862
 >> iter 24000, loss: 0.061568
 >> iter 25000, loss: 0.058617
 >> iter 26000, loss: 0.044110
 >> iter 27000, loss: 0.040858
 >> iter 28000, loss: 0.044515
 >> iter 29000, loss: 0.062144
 >> iter 30000, loss: 0.055218
   Number of active neurons: 4
 >> iter 31000, loss: 0.046923
 >> iter 32000, loss: 0.055448
 >> iter 33000, loss: 0.047558
 >> iter 34000, loss: 0.043436
 >> iter 35000, loss: 0.068356
 >> iter 36000, loss: 0.045720
 >> iter 37000, loss: 0.053724
 >> iter 38000, loss: 0.055306
 >> iter 39000, loss: 0.046033
 >> iter 40000, loss: 0.048189
   Number of active neurons: 4
 >> iter 41000, loss: 0.047640
 >> iter 42000, loss: 0.035182
 >> iter 43000, loss: 0.032547
 >> iter 44000, loss: 0.041214
 >> iter 45000, loss: 0.036900
 >> iter 46000, loss: 0.041478
 >> iter 47000, loss: 0.072527
 >> iter 48000, loss: 0.046722
 >> iter 49000, loss: 0.045161
 >> iter 50000, loss: 0.045965
   Number of active neurons: 4
 >> iter 51000, loss: 0.045715
 >> iter 52000, loss: 0.050917
 >> iter 53000, loss: 0.040170
 >> iter 54000, loss: 0.052215
 >> iter 55000, loss: 0.062186
 >> iter 56000, loss: 0.049247
 >> iter 57000, loss: 0.054161
 >> iter 58000, loss: 0.048400
 >> iter 59000, loss: 0.059336
 >> iter 60000, loss: 0.045086
   Number of active neurons: 4
 >> iter 61000, loss: 0.041503
 >> iter 62000, loss: 0.046226
 >> iter 63000, loss: 0.044096
 >> iter 64000, loss: 0.040918
 >> iter 65000, loss: 0.051923
 >> iter 66000, loss: 0.075352
 >> iter 67000, loss: 0.054108
 >> iter 68000, loss: 0.053197
 >> iter 69000, loss: 0.057306
 >> iter 70000, loss: 0.051918
   Number of active neurons: 4
 >> iter 71000, loss: 0.059477
 >> iter 72000, loss: 0.038813
 >> iter 73000, loss: 0.047045
 >> iter 74000, loss: 0.039598
 >> iter 75000, loss: 0.044013
 >> iter 76000, loss: 0.045827
 >> iter 77000, loss: 0.045668
 >> iter 78000, loss: 0.043987
 >> iter 79000, loss: 0.054895
 >> iter 80000, loss: 0.036516
   Number of active neurons: 4
 >> iter 81000, loss: 0.048123
 >> iter 82000, loss: 0.040302
 >> iter 83000, loss: 0.051120
 >> iter 84000, loss: 0.038704
 >> iter 85000, loss: 0.041003
 >> iter 86000, loss: 0.048625
 >> iter 87000, loss: 0.043607
 >> iter 88000, loss: 0.033054
 >> iter 89000, loss: 0.057401
 >> iter 90000, loss: 0.044554
   Number of active neurons: 4
 >> iter 91000, loss: 0.051053
 >> iter 92000, loss: 0.047032
 >> iter 93000, loss: 0.044977
 >> iter 94000, loss: 0.055842
 >> iter 95000, loss: 0.043477
 >> iter 96000, loss: 0.037453
 >> iter 97000, loss: 0.031101
 >> iter 98000, loss: 0.049550
 >> iter 99000, loss: 0.044298
 >> iter 100000, loss: 0.039467
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.399023
 >> iter 2000, loss: 4.434067
 >> iter 3000, loss: 1.715524
 >> iter 4000, loss: 0.687734
 >> iter 5000, loss: 0.309428
 >> iter 6000, loss: 0.164022
 >> iter 7000, loss: 0.116229
 >> iter 8000, loss: 0.079209
 >> iter 9000, loss: 0.066235
 >> iter 10000, loss: 0.054528
   Number of active neurons: 6
 >> iter 11000, loss: 0.065323
 >> iter 12000, loss: 0.063316
 >> iter 13000, loss: 0.067295
 >> iter 14000, loss: 0.076798
 >> iter 15000, loss: 0.053020
 >> iter 16000, loss: 0.052573
 >> iter 17000, loss: 0.054895
 >> iter 18000, loss: 0.043620
 >> iter 19000, loss: 0.061236
 >> iter 20000, loss: 0.046432
   Number of active neurons: 5
 >> iter 21000, loss: 0.061967
 >> iter 22000, loss: 0.063638
 >> iter 23000, loss: 0.043219
 >> iter 24000, loss: 0.064246
 >> iter 25000, loss: 0.066001
 >> iter 26000, loss: 0.068337
 >> iter 27000, loss: 0.050281
 >> iter 28000, loss: 0.034853
 >> iter 29000, loss: 0.054164
 >> iter 30000, loss: 0.048402
   Number of active neurons: 4
 >> iter 31000, loss: 0.046954
 >> iter 32000, loss: 0.046434
 >> iter 33000, loss: 0.037708
 >> iter 34000, loss: 0.037032
 >> iter 35000, loss: 0.059795
 >> iter 36000, loss: 0.051295
 >> iter 37000, loss: 0.050212
 >> iter 38000, loss: 0.058242
 >> iter 39000, loss: 0.042372
 >> iter 40000, loss: 0.041270
   Number of active neurons: 4
 >> iter 41000, loss: 0.033901
 >> iter 42000, loss: 0.033907
 >> iter 43000, loss: 0.051381
 >> iter 44000, loss: 0.038595
 >> iter 45000, loss: 0.045295
 >> iter 46000, loss: 0.083194
 >> iter 47000, loss: 0.056924
 >> iter 48000, loss: 0.056058
 >> iter 49000, loss: 0.055699
 >> iter 50000, loss: 0.044044
   Number of active neurons: 4
 >> iter 51000, loss: 0.045615
 >> iter 52000, loss: 0.035290
 >> iter 53000, loss: 0.052843
 >> iter 54000, loss: 0.050887
 >> iter 55000, loss: 0.040317
 >> iter 56000, loss: 0.045605
 >> iter 57000, loss: 0.047612
 >> iter 58000, loss: 0.050026
 >> iter 59000, loss: 0.063344
 >> iter 60000, loss: 0.042693
   Number of active neurons: 4
 >> iter 61000, loss: 0.053590
 >> iter 62000, loss: 0.051047
 >> iter 63000, loss: 0.046209
 >> iter 64000, loss: 0.040211
 >> iter 65000, loss: 0.067400
 >> iter 66000, loss: 0.062339
 >> iter 67000, loss: 0.057369
 >> iter 68000, loss: 0.062144
 >> iter 69000, loss: 0.055625
 >> iter 70000, loss: 0.052011
   Number of active neurons: 4
 >> iter 71000, loss: 0.046287
 >> iter 72000, loss: 0.043671
 >> iter 73000, loss: 0.064057
 >> iter 74000, loss: 0.060454
 >> iter 75000, loss: 0.051486
 >> iter 76000, loss: 0.048369
 >> iter 77000, loss: 0.042015
 >> iter 78000, loss: 0.048449
 >> iter 79000, loss: 0.057410
 >> iter 80000, loss: 0.042928
   Number of active neurons: 4
 >> iter 81000, loss: 0.043706
 >> iter 82000, loss: 0.068084
 >> iter 83000, loss: 0.064944
 >> iter 84000, loss: 0.068794
 >> iter 85000, loss: 0.057599
 >> iter 86000, loss: 0.062278
 >> iter 87000, loss: 0.044409
 >> iter 88000, loss: 0.059072
 >> iter 89000, loss: 0.043794
 >> iter 90000, loss: 0.032487
   Number of active neurons: 3
 >> iter 91000, loss: 0.036049
 >> iter 92000, loss: 0.036728
 >> iter 93000, loss: 0.045911
 >> iter 94000, loss: 0.050248
 >> iter 95000, loss: 0.048823
 >> iter 96000, loss: 0.040164
 >> iter 97000, loss: 0.036430
 >> iter 98000, loss: 0.050792
 >> iter 99000, loss: 0.044738
 >> iter 100000, loss: 0.039879
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

