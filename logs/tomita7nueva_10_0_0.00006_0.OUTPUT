 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 6e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 16.187131
 >> iter 2000, loss: 7.484224
 >> iter 3000, loss: 2.982418
 >> iter 4000, loss: 1.169460
 >> iter 5000, loss: 0.495359
 >> iter 6000, loss: 0.215230
 >> iter 7000, loss: 0.200005
 >> iter 8000, loss: 0.116184
 >> iter 9000, loss: 0.107352
 >> iter 10000, loss: 0.097974
   Number of active neurons: 9
 >> iter 11000, loss: 0.504178
 >> iter 12000, loss: 0.245198
 >> iter 13000, loss: 0.201957
 >> iter 14000, loss: 0.098002
 >> iter 15000, loss: 0.132378
 >> iter 16000, loss: 0.069755
 >> iter 17000, loss: 0.084089
 >> iter 18000, loss: 0.056019
 >> iter 19000, loss: 0.139507
 >> iter 20000, loss: 0.133770
   Number of active neurons: 9
 >> iter 21000, loss: 0.113422
 >> iter 22000, loss: 0.067401
 >> iter 23000, loss: 0.185451
 >> iter 24000, loss: 0.155013
 >> iter 25000, loss: 0.157401
 >> iter 26000, loss: 0.088441
 >> iter 27000, loss: 0.126651
 >> iter 28000, loss: 0.065957
 >> iter 29000, loss: 0.152919
 >> iter 30000, loss: 0.101473
   Number of active neurons: 9
 >> iter 31000, loss: 0.108498
 >> iter 32000, loss: 0.113933
 >> iter 33000, loss: 0.200247
 >> iter 34000, loss: 0.094970
 >> iter 35000, loss: 0.093384
 >> iter 36000, loss: 0.058032
 >> iter 37000, loss: 0.257257
 >> iter 38000, loss: 0.125879
 >> iter 39000, loss: 0.091567
 >> iter 40000, loss: 0.058457
   Number of active neurons: 9
 >> iter 41000, loss: 0.083109
 >> iter 42000, loss: 0.092656
 >> iter 43000, loss: 0.104817
 >> iter 44000, loss: 0.057743
 >> iter 45000, loss: 0.281294
 >> iter 46000, loss: 0.225052
 >> iter 47000, loss: 0.128098
 >> iter 48000, loss: 0.114092
 >> iter 49000, loss: 0.112159
 >> iter 50000, loss: 0.119871
   Number of active neurons: 8
 >> iter 51000, loss: 0.084412
 >> iter 52000, loss: 0.134586
 >> iter 53000, loss: 0.117275
 >> iter 54000, loss: 0.179517
 >> iter 55000, loss: 0.178684
 >> iter 56000, loss: 0.083091
 >> iter 57000, loss: 0.070358
 >> iter 58000, loss: 0.040133
 >> iter 59000, loss: 0.045573
 >> iter 60000, loss: 0.029948
   Number of active neurons: 7
 >> iter 61000, loss: 0.117858
 >> iter 62000, loss: 0.055785
 >> iter 63000, loss: 0.120289
 >> iter 64000, loss: 0.056815
 >> iter 65000, loss: 0.170491
 >> iter 66000, loss: 0.085072
 >> iter 67000, loss: 0.110164
 >> iter 68000, loss: 0.053327
 >> iter 69000, loss: 0.104161
 >> iter 70000, loss: 0.050853
   Number of active neurons: 7
 >> iter 71000, loss: 0.135881
 >> iter 72000, loss: 0.063722
 >> iter 73000, loss: 0.134325
 >> iter 74000, loss: 0.063234
 >> iter 75000, loss: 0.111388
 >> iter 76000, loss: 0.053933
 >> iter 77000, loss: 0.044032
 >> iter 78000, loss: 0.028661
 >> iter 79000, loss: 0.073146
 >> iter 80000, loss: 0.038266
   Number of active neurons: 7
 >> iter 81000, loss: 0.026614
 >> iter 82000, loss: 0.022077
 >> iter 83000, loss: 0.025381
 >> iter 84000, loss: 0.146300
 >> iter 85000, loss: 0.069635
 >> iter 86000, loss: 0.038685
 >> iter 87000, loss: 0.041141
 >> iter 88000, loss: 0.028660
 >> iter 89000, loss: 0.044979
 >> iter 90000, loss: 0.094436
   Number of active neurons: 6
 >> iter 91000, loss: 0.049487
 >> iter 92000, loss: 0.048219
 >> iter 93000, loss: 0.072201
 >> iter 94000, loss: 0.037937
 >> iter 95000, loss: 0.075862
 >> iter 96000, loss: 0.040107
 >> iter 97000, loss: 0.055060
 >> iter 98000, loss: 0.032498
 >> iter 99000, loss: 0.081481
 >> iter 100000, loss: 0.042466
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.009999800004
   - Test - Long: 0.0249987500625
   - Test - Big: 0.0209997900021
   - Test - A: 25.0449970002
   - Test - B: 15.7322845144
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 15.880968
 >> iter 2000, loss: 6.764745
 >> iter 3000, loss: 2.539171
 >> iter 4000, loss: 0.954234
 >> iter 5000, loss: 0.369078
 >> iter 6000, loss: 0.198008
 >> iter 7000, loss: 0.091476
 >> iter 8000, loss: 0.049463
 >> iter 9000, loss: 0.048963
 >> iter 10000, loss: 0.184946
   Number of active neurons: 10
 >> iter 11000, loss: 0.122571
 >> iter 12000, loss: 0.082496
 >> iter 13000, loss: 0.064338
 >> iter 14000, loss: 0.040284
 >> iter 15000, loss: 0.399973
 >> iter 16000, loss: 0.180640
 >> iter 17000, loss: 0.314574
 >> iter 18000, loss: 0.159372
 >> iter 19000, loss: 0.097421
 >> iter 20000, loss: 0.125200
   Number of active neurons: 9
 >> iter 21000, loss: 0.144948
 >> iter 22000, loss: 0.183639
 >> iter 23000, loss: 0.118912
 >> iter 24000, loss: 0.059146
 >> iter 25000, loss: 0.114766
 >> iter 26000, loss: 0.056831
 >> iter 27000, loss: 0.115856
 >> iter 28000, loss: 0.056985
 >> iter 29000, loss: 0.211072
 >> iter 30000, loss: 0.151887
   Number of active neurons: 8
 >> iter 31000, loss: 0.104486
 >> iter 32000, loss: 0.053065
 >> iter 33000, loss: 0.081386
 >> iter 34000, loss: 0.191325
 >> iter 35000, loss: 0.149624
 >> iter 36000, loss: 0.113665
 >> iter 37000, loss: 0.064725
 >> iter 38000, loss: 0.047178
 >> iter 39000, loss: 0.110570
 >> iter 40000, loss: 0.053136
   Number of active neurons: 6
 >> iter 41000, loss: 0.113844
 >> iter 42000, loss: 0.054213
 >> iter 43000, loss: 0.117410
 >> iter 44000, loss: 0.059703
 >> iter 45000, loss: 0.084154
 >> iter 46000, loss: 0.042495
 >> iter 47000, loss: 0.216740
 >> iter 48000, loss: 0.093654
 >> iter 49000, loss: 0.142537
 >> iter 50000, loss: 0.065529
   Number of active neurons: 6
 >> iter 51000, loss: 0.055397
 >> iter 52000, loss: 0.076653
 >> iter 53000, loss: 0.085296
 >> iter 54000, loss: 0.042211
 >> iter 55000, loss: 0.064255
 >> iter 56000, loss: 0.034106
 >> iter 57000, loss: 0.118476
 >> iter 58000, loss: 0.053926
 >> iter 59000, loss: 0.046337
 >> iter 60000, loss: 0.026622
   Number of active neurons: 6
 >> iter 61000, loss: 0.049621
 >> iter 62000, loss: 0.027847
 >> iter 63000, loss: 0.033335
 >> iter 64000, loss: 0.021485
 >> iter 65000, loss: 0.062756
 >> iter 66000, loss: 0.032348
 >> iter 67000, loss: 0.132479
 >> iter 68000, loss: 0.058814
 >> iter 69000, loss: 0.175137
 >> iter 70000, loss: 0.076020
   Number of active neurons: 5
 >> iter 71000, loss: 0.123519
 >> iter 72000, loss: 0.056055
 >> iter 73000, loss: 0.048950
 >> iter 74000, loss: 0.027634
 >> iter 75000, loss: 0.112154
 >> iter 76000, loss: 0.132664
 >> iter 77000, loss: 0.130247
 >> iter 78000, loss: 0.057747
 >> iter 79000, loss: 0.068246
 >> iter 80000, loss: 0.035027
   Number of active neurons: 5
 >> iter 81000, loss: 0.192984
 >> iter 82000, loss: 0.081969
 >> iter 83000, loss: 0.040836
 >> iter 84000, loss: 0.072985
 >> iter 85000, loss: 0.192852
 >> iter 86000, loss: 0.081970
 >> iter 87000, loss: 0.133397
 >> iter 88000, loss: 0.060146
 >> iter 89000, loss: 0.077964
 >> iter 90000, loss: 0.142009
   Number of active neurons: 5
 >> iter 91000, loss: 0.069419
 >> iter 92000, loss: 0.036375
 >> iter 93000, loss: 0.061495
 >> iter 94000, loss: 0.033093
 >> iter 95000, loss: 0.288584
 >> iter 96000, loss: 0.119760
 >> iter 97000, loss: 0.136644
 >> iter 98000, loss: 0.062441
 >> iter 99000, loss: 0.136590
 >> iter 100000, loss: 0.061406
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.00799984000319
   - Test - Long: 0.0
   - Test - Big: 0.0029999700003
   - Test - A: 56.9428704753
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.125490
 >> iter 2000, loss: 7.774775
 >> iter 3000, loss: 3.025254
 >> iter 4000, loss: 1.169782
 >> iter 5000, loss: 0.447384
 >> iter 6000, loss: 0.197837
 >> iter 7000, loss: 0.355553
 >> iter 8000, loss: 0.154603
 >> iter 9000, loss: 0.082772
 >> iter 10000, loss: 0.167081
   Number of active neurons: 8
 >> iter 11000, loss: 0.078015
 >> iter 12000, loss: 0.218690
 >> iter 13000, loss: 0.097702
 >> iter 14000, loss: 0.050053
 >> iter 15000, loss: 0.057462
 >> iter 16000, loss: 0.033963
 >> iter 17000, loss: 0.053212
 >> iter 18000, loss: 0.271321
 >> iter 19000, loss: 0.196403
 >> iter 20000, loss: 0.088542
   Number of active neurons: 8
 >> iter 21000, loss: 0.213942
 >> iter 22000, loss: 0.095399
 >> iter 23000, loss: 0.111143
 >> iter 24000, loss: 0.055269
 >> iter 25000, loss: 0.047956
 >> iter 26000, loss: 0.345933
 >> iter 27000, loss: 0.149222
 >> iter 28000, loss: 0.073292
 >> iter 29000, loss: 0.266029
 >> iter 30000, loss: 0.115849
   Number of active neurons: 8
 >> iter 31000, loss: 0.056636
 >> iter 32000, loss: 0.107934
 >> iter 33000, loss: 0.151283
 >> iter 34000, loss: 0.069837
 >> iter 35000, loss: 0.214406
 >> iter 36000, loss: 0.124561
 >> iter 37000, loss: 0.059639
 >> iter 38000, loss: 0.034415
 >> iter 39000, loss: 0.024810
 >> iter 40000, loss: 0.230650
   Number of active neurons: 8
 >> iter 41000, loss: 0.181881
 >> iter 42000, loss: 0.080824
 >> iter 43000, loss: 0.067489
 >> iter 44000, loss: 0.126622
 >> iter 45000, loss: 0.059932
 >> iter 46000, loss: 0.034290
 >> iter 47000, loss: 0.041203
 >> iter 48000, loss: 0.119313
 >> iter 49000, loss: 0.056732
 >> iter 50000, loss: 0.032900
   Number of active neurons: 7
 >> iter 51000, loss: 0.094736
 >> iter 52000, loss: 0.047008
 >> iter 53000, loss: 0.118102
 >> iter 54000, loss: 0.056821
 >> iter 55000, loss: 0.124348
 >> iter 56000, loss: 0.058721
 >> iter 57000, loss: 0.254653
 >> iter 58000, loss: 0.109691
 >> iter 59000, loss: 0.053544
 >> iter 60000, loss: 0.033969
   Number of active neurons: 6
 >> iter 61000, loss: 0.024305
 >> iter 62000, loss: 0.054976
 >> iter 63000, loss: 0.179306
 >> iter 64000, loss: 0.079923
 >> iter 65000, loss: 0.174469
 >> iter 66000, loss: 0.078124
 >> iter 67000, loss: 0.085557
 >> iter 68000, loss: 0.043621
 >> iter 69000, loss: 0.040236
 >> iter 70000, loss: 0.086553
   Number of active neurons: 6
 >> iter 71000, loss: 0.071185
 >> iter 72000, loss: 0.037909
 >> iter 73000, loss: 0.120195
 >> iter 74000, loss: 0.057228
 >> iter 75000, loss: 0.194662
 >> iter 76000, loss: 0.207082
 >> iter 77000, loss: 0.140196
 >> iter 78000, loss: 0.065533
 >> iter 79000, loss: 0.083765
 >> iter 80000, loss: 0.043394
   Number of active neurons: 6
 >> iter 81000, loss: 0.235361
 >> iter 82000, loss: 0.144473
 >> iter 83000, loss: 0.115411
 >> iter 84000, loss: 0.059704
 >> iter 85000, loss: 0.138599
 >> iter 86000, loss: 0.064774
 >> iter 87000, loss: 0.061818
 >> iter 88000, loss: 0.050470
 >> iter 89000, loss: 0.032808
 >> iter 90000, loss: 0.064030
   Number of active neurons: 5
 >> iter 91000, loss: 0.077677
 >> iter 92000, loss: 0.051211
 >> iter 93000, loss: 0.147615
 >> iter 94000, loss: 0.066244
 >> iter 95000, loss: 0.082925
 >> iter 96000, loss: 0.064511
 >> iter 97000, loss: 0.045478
 >> iter 98000, loss: 0.088203
 >> iter 99000, loss: 0.072961
 >> iter 100000, loss: 0.037121
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.009999500025
   - Test - Big: 0.0
   - Test - A: 22.4318378775
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.230358
 >> iter 2000, loss: 7.889773
 >> iter 3000, loss: 2.992852
 >> iter 4000, loss: 1.155759
 >> iter 5000, loss: 0.515095
 >> iter 6000, loss: 0.274018
 >> iter 7000, loss: 0.176296
 >> iter 8000, loss: 0.211996
 >> iter 9000, loss: 0.180066
 >> iter 10000, loss: 0.105061
   Number of active neurons: 7
 >> iter 11000, loss: 0.120748
 >> iter 12000, loss: 0.095677
 >> iter 13000, loss: 0.136602
 >> iter 14000, loss: 0.067076
 >> iter 15000, loss: 0.086661
 >> iter 16000, loss: 0.236947
 >> iter 17000, loss: 0.110875
 >> iter 18000, loss: 0.112126
 >> iter 19000, loss: 0.069423
 >> iter 20000, loss: 0.041551
   Number of active neurons: 7
 >> iter 21000, loss: 0.034211
 >> iter 22000, loss: 0.026704
 >> iter 23000, loss: 0.086938
 >> iter 24000, loss: 0.246991
 >> iter 25000, loss: 0.118825
 >> iter 26000, loss: 0.149457
 >> iter 27000, loss: 0.174876
 >> iter 28000, loss: 0.088441
 >> iter 29000, loss: 0.209747
 >> iter 30000, loss: 0.126549
   Number of active neurons: 7
 >> iter 31000, loss: 0.192766
 >> iter 32000, loss: 0.119308
 >> iter 33000, loss: 0.102987
 >> iter 34000, loss: 0.100652
 >> iter 35000, loss: 0.141973
 >> iter 36000, loss: 0.098236
 >> iter 37000, loss: 0.215374
 >> iter 38000, loss: 0.097870
 >> iter 39000, loss: 0.113603
 >> iter 40000, loss: 0.105080
   Number of active neurons: 7
 >> iter 41000, loss: 0.077090
 >> iter 42000, loss: 0.142638
 >> iter 43000, loss: 0.156944
 >> iter 44000, loss: 0.317796
 >> iter 45000, loss: 0.154922
 >> iter 46000, loss: 0.154540
 >> iter 47000, loss: 0.074246
 >> iter 48000, loss: 0.069780
 >> iter 49000, loss: 0.050242
 >> iter 50000, loss: 0.079626
   Number of active neurons: 7
 >> iter 51000, loss: 0.151606
 >> iter 52000, loss: 0.070586
 >> iter 53000, loss: 0.130034
 >> iter 54000, loss: 0.106594
 >> iter 55000, loss: 0.197027
 >> iter 56000, loss: 0.089071
 >> iter 57000, loss: 0.133197
 >> iter 58000, loss: 0.105880
 >> iter 59000, loss: 0.103536
 >> iter 60000, loss: 0.275147
   Number of active neurons: 7
 >> iter 61000, loss: 0.226832
 >> iter 62000, loss: 0.100149
 >> iter 63000, loss: 0.135310
 >> iter 64000, loss: 0.065484
 >> iter 65000, loss: 0.071355
 >> iter 66000, loss: 0.168538
 >> iter 67000, loss: 0.145960
 >> iter 68000, loss: 0.068701
 >> iter 69000, loss: 0.152154
 >> iter 70000, loss: 0.072027
   Number of active neurons: 6
 >> iter 71000, loss: 0.111084
 >> iter 72000, loss: 0.145067
 >> iter 73000, loss: 0.176415
 >> iter 74000, loss: 0.143656
 >> iter 75000, loss: 0.123924
 >> iter 76000, loss: 0.063314
 >> iter 77000, loss: 0.132874
 >> iter 78000, loss: 0.076513
 >> iter 79000, loss: 0.118079
 >> iter 80000, loss: 0.056804
   Number of active neurons: 6
 >> iter 81000, loss: 0.127346
 >> iter 82000, loss: 0.066187
 >> iter 83000, loss: 0.067506
 >> iter 84000, loss: 0.038605
 >> iter 85000, loss: 0.134540
 >> iter 86000, loss: 0.062545
 >> iter 87000, loss: 0.212691
 >> iter 88000, loss: 0.093541
 >> iter 89000, loss: 0.138956
 >> iter 90000, loss: 0.064769
   Number of active neurons: 6
 >> iter 91000, loss: 0.139358
 >> iter 92000, loss: 0.064543
 >> iter 93000, loss: 0.084607
 >> iter 94000, loss: 0.042906
 >> iter 95000, loss: 0.080234
 >> iter 96000, loss: 0.041541
 >> iter 97000, loss: 0.324263
 >> iter 98000, loss: 0.136368
 >> iter 99000, loss: 0.066430
 >> iter 100000, loss: 0.036763
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.00599988000241
   - Test - Long: 0.009999500025
   - Test - Big: 0.000999990000096
   - Test - A: 55.8896073595
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.023792
 >> iter 2000, loss: 8.823970
 >> iter 3000, loss: 4.028629
 >> iter 4000, loss: 1.714119
 >> iter 5000, loss: 0.721452
 >> iter 6000, loss: 0.282136
 >> iter 7000, loss: 0.192315
 >> iter 8000, loss: 0.115737
 >> iter 9000, loss: 0.114267
 >> iter 10000, loss: 0.060433
   Number of active neurons: 6
 >> iter 11000, loss: 0.358075
 >> iter 12000, loss: 0.174820
 >> iter 13000, loss: 0.135878
 >> iter 14000, loss: 0.072846
 >> iter 15000, loss: 0.083755
 >> iter 16000, loss: 0.093662
 >> iter 17000, loss: 0.094597
 >> iter 18000, loss: 0.126109
 >> iter 19000, loss: 0.168798
 >> iter 20000, loss: 0.262489
   Number of active neurons: 6
 >> iter 21000, loss: 0.188455
 >> iter 22000, loss: 0.113191
 >> iter 23000, loss: 0.089753
 >> iter 24000, loss: 0.053783
 >> iter 25000, loss: 0.076003
 >> iter 26000, loss: 0.141196
 >> iter 27000, loss: 0.215854
 >> iter 28000, loss: 0.165502
 >> iter 29000, loss: 0.227036
 >> iter 30000, loss: 0.173187
   Number of active neurons: 6
 >> iter 31000, loss: 0.371799
 >> iter 32000, loss: 0.186040
 >> iter 33000, loss: 0.276771
 >> iter 34000, loss: 0.129311
 >> iter 35000, loss: 0.198751
 >> iter 36000, loss: 0.218980
 >> iter 37000, loss: 0.254105
 >> iter 38000, loss: 0.248596
 >> iter 39000, loss: 0.175573
 >> iter 40000, loss: 0.079723
   Number of active neurons: 6
 >> iter 41000, loss: 0.282032
 >> iter 42000, loss: 0.151968
 >> iter 43000, loss: 0.070218
 >> iter 44000, loss: 0.037592
 >> iter 45000, loss: 0.143317
 >> iter 46000, loss: 0.152690
 >> iter 47000, loss: 0.419291
 >> iter 48000, loss: 0.178878
 >> iter 49000, loss: 0.169108
 >> iter 50000, loss: 0.085578
   Number of active neurons: 4
 >> iter 51000, loss: 0.259556
 >> iter 52000, loss: 0.127344
 >> iter 53000, loss: 0.095935
 >> iter 54000, loss: 0.098553
 >> iter 55000, loss: 0.562149
 >> iter 56000, loss: 0.416359
 >> iter 57000, loss: 0.194068
 >> iter 58000, loss: 0.106200
 >> iter 59000, loss: 0.217286
 >> iter 60000, loss: 0.105072
   Number of active neurons: 4
 >> iter 61000, loss: 0.157988
 >> iter 62000, loss: 0.072166
 >> iter 63000, loss: 0.188937
 >> iter 64000, loss: 0.099691
 >> iter 65000, loss: 0.309387
 >> iter 66000, loss: 0.167828
 >> iter 67000, loss: 0.186780
 >> iter 68000, loss: 0.307043
 >> iter 69000, loss: 0.211348
 >> iter 70000, loss: 0.092934
   Number of active neurons: 4
 >> iter 71000, loss: 0.240828
 >> iter 72000, loss: 0.129268
 >> iter 73000, loss: 0.226713
 >> iter 74000, loss: 0.111349
 >> iter 75000, loss: 0.134373
 >> iter 76000, loss: 0.122273
 >> iter 77000, loss: 0.231049
 >> iter 78000, loss: 0.128684
 >> iter 79000, loss: 0.466855
 >> iter 80000, loss: 0.194146
   Number of active neurons: 4
 >> iter 81000, loss: 0.254598
 >> iter 82000, loss: 0.110583
 >> iter 83000, loss: 0.120987
 >> iter 84000, loss: 0.133368
 >> iter 85000, loss: 0.197459
 >> iter 86000, loss: 0.172653
 >> iter 87000, loss: 0.279293
 >> iter 88000, loss: 0.134478
 >> iter 89000, loss: 0.140500
 >> iter 90000, loss: 0.109500
   Number of active neurons: 4
 >> iter 91000, loss: 0.163088
 >> iter 92000, loss: 0.126263
 >> iter 93000, loss: 0.188581
 >> iter 94000, loss: 0.120567
 >> iter 95000, loss: 0.257850
 >> iter 96000, loss: 0.198798
 >> iter 97000, loss: 0.180916
 >> iter 98000, loss: 0.185166
 >> iter 99000, loss: 0.263990
 >> iter 100000, loss: 0.126579
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0219995600088
   - Test - Long: 0.0049997500125
   - Test - Big: 0.0079999200008
   - Test - A: 25.99160056
   - Test - B: 14.8856742884
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 15.977452
 >> iter 2000, loss: 7.316737
 >> iter 3000, loss: 2.840499
 >> iter 4000, loss: 1.125397
 >> iter 5000, loss: 0.434492
 >> iter 6000, loss: 0.215049
 >> iter 7000, loss: 0.188858
 >> iter 8000, loss: 0.156237
 >> iter 9000, loss: 0.075959
 >> iter 10000, loss: 0.043472
   Number of active neurons: 7
 >> iter 11000, loss: 0.206751
 >> iter 12000, loss: 0.144984
 >> iter 13000, loss: 0.145680
 >> iter 14000, loss: 0.069886
 >> iter 15000, loss: 0.071764
 >> iter 16000, loss: 0.041051
 >> iter 17000, loss: 0.108318
 >> iter 18000, loss: 0.365276
 >> iter 19000, loss: 0.157237
 >> iter 20000, loss: 0.073955
   Number of active neurons: 7
 >> iter 21000, loss: 0.137726
 >> iter 22000, loss: 0.196730
 >> iter 23000, loss: 0.089486
 >> iter 24000, loss: 0.193558
 >> iter 25000, loss: 0.268867
 >> iter 26000, loss: 0.161201
 >> iter 27000, loss: 0.234474
 >> iter 28000, loss: 0.193715
 >> iter 29000, loss: 0.088637
 >> iter 30000, loss: 0.093641
   Number of active neurons: 6
 >> iter 31000, loss: 0.371771
 >> iter 32000, loss: 0.156714
 >> iter 33000, loss: 0.382588
 >> iter 34000, loss: 0.163333
 >> iter 35000, loss: 0.361224
 >> iter 36000, loss: 0.155479
 >> iter 37000, loss: 0.286050
 >> iter 38000, loss: 0.127001
 >> iter 39000, loss: 0.207513
 >> iter 40000, loss: 0.135830
   Number of active neurons: 6
 >> iter 41000, loss: 0.250033
 >> iter 42000, loss: 0.110898
 >> iter 43000, loss: 0.132625
 >> iter 44000, loss: 0.129269
 >> iter 45000, loss: 0.086213
 >> iter 46000, loss: 0.147670
 >> iter 47000, loss: 0.437701
 >> iter 48000, loss: 0.188079
 >> iter 49000, loss: 0.215832
 >> iter 50000, loss: 0.111518
   Number of active neurons: 6
 >> iter 51000, loss: 0.088325
 >> iter 52000, loss: 0.046753
 >> iter 53000, loss: 0.358735
 >> iter 54000, loss: 0.178956
 >> iter 55000, loss: 0.081881
 >> iter 56000, loss: 0.043758
 >> iter 57000, loss: 0.147317
 >> iter 58000, loss: 0.163893
 >> iter 59000, loss: 0.310563
 >> iter 60000, loss: 0.132375
   Number of active neurons: 6
 >> iter 61000, loss: 0.144366
 >> iter 62000, loss: 0.142595
 >> iter 63000, loss: 0.078514
 >> iter 64000, loss: 0.041249
 >> iter 65000, loss: 0.105280
 >> iter 66000, loss: 0.051686
 >> iter 67000, loss: 0.566486
 >> iter 68000, loss: 0.230943
 >> iter 69000, loss: 0.225419
 >> iter 70000, loss: 0.102120
   Number of active neurons: 6
 >> iter 71000, loss: 0.085186
 >> iter 72000, loss: 0.044550
 >> iter 73000, loss: 0.130087
 >> iter 74000, loss: 0.061679
 >> iter 75000, loss: 0.195177
 >> iter 76000, loss: 0.086443
 >> iter 77000, loss: 0.136761
 >> iter 78000, loss: 0.063252
 >> iter 79000, loss: 0.187270
 >> iter 80000, loss: 0.083051
   Number of active neurons: 6
 >> iter 81000, loss: 0.101425
 >> iter 82000, loss: 0.049805
 >> iter 83000, loss: 0.269321
 >> iter 84000, loss: 0.116443
 >> iter 85000, loss: 0.101173
 >> iter 86000, loss: 0.066862
 >> iter 87000, loss: 0.218785
 >> iter 88000, loss: 0.094453
 >> iter 89000, loss: 0.131211
 >> iter 90000, loss: 0.061544
   Number of active neurons: 6
 >> iter 91000, loss: 0.067772
 >> iter 92000, loss: 0.036965
 >> iter 93000, loss: 0.079523
 >> iter 94000, loss: 0.389149
 >> iter 95000, loss: 0.328352
 >> iter 96000, loss: 0.138023
 >> iter 97000, loss: 0.103858
 >> iter 98000, loss: 0.090879
 >> iter 99000, loss: 0.232660
 >> iter 100000, loss: 0.101291
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0049997500125
   - Test - Big: 0.0
   - Test - A: 21.625224985
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.167263
 >> iter 2000, loss: 10.784601
 >> iter 3000, loss: 4.262503
 >> iter 4000, loss: 1.589650
 >> iter 5000, loss: 0.631118
 >> iter 6000, loss: 0.245785
 >> iter 7000, loss: 0.748035
 >> iter 8000, loss: 0.301427
 >> iter 9000, loss: 0.146165
 >> iter 10000, loss: 0.067227
   Number of active neurons: 6
 >> iter 11000, loss: 0.084961
 >> iter 12000, loss: 0.043212
 >> iter 13000, loss: 0.078198
 >> iter 14000, loss: 0.041131
 >> iter 15000, loss: 0.066863
 >> iter 16000, loss: 0.142425
 >> iter 17000, loss: 0.065194
 >> iter 18000, loss: 0.065643
 >> iter 19000, loss: 0.091380
 >> iter 20000, loss: 0.046068
   Number of active neurons: 5
 >> iter 21000, loss: 0.102291
 >> iter 22000, loss: 0.049268
 >> iter 23000, loss: 0.137239
 >> iter 24000, loss: 0.062238
 >> iter 25000, loss: 0.153312
 >> iter 26000, loss: 0.069045
 >> iter 27000, loss: 0.080299
 >> iter 28000, loss: 0.180357
 >> iter 29000, loss: 0.192229
 >> iter 30000, loss: 0.086424
   Number of active neurons: 5
 >> iter 31000, loss: 0.142626
 >> iter 32000, loss: 0.067563
 >> iter 33000, loss: 0.083348
 >> iter 34000, loss: 0.060114
 >> iter 35000, loss: 0.072352
 >> iter 36000, loss: 0.105977
 >> iter 37000, loss: 0.249420
 >> iter 38000, loss: 0.125624
 >> iter 39000, loss: 0.181152
 >> iter 40000, loss: 0.081320
   Number of active neurons: 5
 >> iter 41000, loss: 0.334943
 >> iter 42000, loss: 0.143884
 >> iter 43000, loss: 0.144538
 >> iter 44000, loss: 0.104308
 >> iter 45000, loss: 0.147568
 >> iter 46000, loss: 0.098514
 >> iter 47000, loss: 0.175542
 >> iter 48000, loss: 0.080140
 >> iter 49000, loss: 0.138636
 >> iter 50000, loss: 0.067586
   Number of active neurons: 5
 >> iter 51000, loss: 0.138946
 >> iter 52000, loss: 0.064572
 >> iter 53000, loss: 0.092682
 >> iter 54000, loss: 0.046650
 >> iter 55000, loss: 0.337086
 >> iter 56000, loss: 0.244054
 >> iter 57000, loss: 0.210730
 >> iter 58000, loss: 0.093525
 >> iter 59000, loss: 0.154868
 >> iter 60000, loss: 0.075235
   Number of active neurons: 5
 >> iter 61000, loss: 0.171573
 >> iter 62000, loss: 0.077414
 >> iter 63000, loss: 0.165550
 >> iter 64000, loss: 0.342061
 >> iter 65000, loss: 0.205226
 >> iter 66000, loss: 0.091947
 >> iter 67000, loss: 0.120596
 >> iter 68000, loss: 0.105160
 >> iter 69000, loss: 0.103623
 >> iter 70000, loss: 0.091334
   Number of active neurons: 5
 >> iter 71000, loss: 0.145326
 >> iter 72000, loss: 0.098654
 >> iter 73000, loss: 0.127289
 >> iter 74000, loss: 0.107944
 >> iter 75000, loss: 0.172749
 >> iter 76000, loss: 0.078465
 >> iter 77000, loss: 0.251564
 >> iter 78000, loss: 0.133766
 >> iter 79000, loss: 0.125188
 >> iter 80000, loss: 0.058521
   Number of active neurons: 5
 >> iter 81000, loss: 0.142199
 >> iter 82000, loss: 0.102716
 >> iter 83000, loss: 0.348439
 >> iter 84000, loss: 0.149191
 >> iter 85000, loss: 0.216202
 >> iter 86000, loss: 0.156251
 >> iter 87000, loss: 0.138186
 >> iter 88000, loss: 0.091134
 >> iter 89000, loss: 0.117287
 >> iter 90000, loss: 0.063496
   Number of active neurons: 5
 >> iter 91000, loss: 0.134123
 >> iter 92000, loss: 0.086124
 >> iter 93000, loss: 0.158870
 >> iter 94000, loss: 0.072797
 >> iter 95000, loss: 0.191366
 >> iter 96000, loss: 0.085688
 >> iter 97000, loss: 0.118607
 >> iter 98000, loss: 0.056605
 >> iter 99000, loss: 0.105545
 >> iter 100000, loss: 0.051333
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0159996800064
   - Test - Long: 0.0
   - Test - Big: 0.0169998300017
   - Test - A: 26.5782281181
   - Test - B: 18.1987867476
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.268817
 >> iter 2000, loss: 8.705254
 >> iter 3000, loss: 4.030235
 >> iter 4000, loss: 1.515111
 >> iter 5000, loss: 0.628989
 >> iter 6000, loss: 0.251343
 >> iter 7000, loss: 0.247490
 >> iter 8000, loss: 0.108754
 >> iter 9000, loss: 0.076386
 >> iter 10000, loss: 0.054164
   Number of active neurons: 8
 >> iter 11000, loss: 0.095161
 >> iter 12000, loss: 0.059042
 >> iter 13000, loss: 0.122633
 >> iter 14000, loss: 0.064593
 >> iter 15000, loss: 0.087811
 >> iter 16000, loss: 0.052458
 >> iter 17000, loss: 0.110928
 >> iter 18000, loss: 0.088490
 >> iter 19000, loss: 0.092684
 >> iter 20000, loss: 0.049428
   Number of active neurons: 8
 >> iter 21000, loss: 0.100343
 >> iter 22000, loss: 0.056837
 >> iter 23000, loss: 0.039823
 >> iter 24000, loss: 0.071606
 >> iter 25000, loss: 0.209131
 >> iter 26000, loss: 0.114088
 >> iter 27000, loss: 0.076762
 >> iter 28000, loss: 0.045647
 >> iter 29000, loss: 0.033852
 >> iter 30000, loss: 0.066446
   Number of active neurons: 8
 >> iter 31000, loss: 0.084084
 >> iter 32000, loss: 0.080625
 >> iter 33000, loss: 0.094144
 >> iter 34000, loss: 0.077082
 >> iter 35000, loss: 0.092277
 >> iter 36000, loss: 0.063884
 >> iter 37000, loss: 0.075185
 >> iter 38000, loss: 0.071780
 >> iter 39000, loss: 0.044097
 >> iter 40000, loss: 0.063385
   Number of active neurons: 7
 >> iter 41000, loss: 0.064414
 >> iter 42000, loss: 0.074777
 >> iter 43000, loss: 0.055994
 >> iter 44000, loss: 0.068533
 >> iter 45000, loss: 0.088485
 >> iter 46000, loss: 0.075969
 >> iter 47000, loss: 0.067713
 >> iter 48000, loss: 0.062282
 >> iter 49000, loss: 0.063843
 >> iter 50000, loss: 0.091598
   Number of active neurons: 7
 >> iter 51000, loss: 0.074155
 >> iter 52000, loss: 0.051689
 >> iter 53000, loss: 0.032480
 >> iter 54000, loss: 0.055782
 >> iter 55000, loss: 0.073526
 >> iter 56000, loss: 0.062625
 >> iter 57000, loss: 0.042608
 >> iter 58000, loss: 0.044490
 >> iter 59000, loss: 0.068693
 >> iter 60000, loss: 0.062412
   Number of active neurons: 7
 >> iter 61000, loss: 0.142455
 >> iter 62000, loss: 0.065909
 >> iter 63000, loss: 0.171781
 >> iter 64000, loss: 0.093809
 >> iter 65000, loss: 0.056823
 >> iter 66000, loss: 0.119492
 >> iter 67000, loss: 0.148854
 >> iter 68000, loss: 0.170298
 >> iter 69000, loss: 0.136803
 >> iter 70000, loss: 0.081376
   Number of active neurons: 7
 >> iter 71000, loss: 0.044140
 >> iter 72000, loss: 0.055478
 >> iter 73000, loss: 0.124648
 >> iter 74000, loss: 0.078074
 >> iter 75000, loss: 0.072721
 >> iter 76000, loss: 0.103438
 >> iter 77000, loss: 0.072312
 >> iter 78000, loss: 0.138819
 >> iter 79000, loss: 0.067852
 >> iter 80000, loss: 0.055487
   Number of active neurons: 6
 >> iter 81000, loss: 0.037053
 >> iter 82000, loss: 0.105965
 >> iter 83000, loss: 0.056444
 >> iter 84000, loss: 0.111828
 >> iter 85000, loss: 0.096458
 >> iter 86000, loss: 0.080320
 >> iter 87000, loss: 0.064487
 >> iter 88000, loss: 0.049882
 >> iter 89000, loss: 0.083218
 >> iter 90000, loss: 0.073877
   Number of active neurons: 5
 >> iter 91000, loss: 0.062519
 >> iter 92000, loss: 0.041635
 >> iter 93000, loss: 0.059817
 >> iter 94000, loss: 0.057983
 >> iter 95000, loss: 0.046846
 >> iter 96000, loss: 0.047560
 >> iter 97000, loss: 0.079593
 >> iter 98000, loss: 0.054746
 >> iter 99000, loss: 0.047216
 >> iter 100000, loss: 0.180564
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 16.396390
 >> iter 2000, loss: 7.616487
 >> iter 3000, loss: 2.972307
 >> iter 4000, loss: 1.286918
 >> iter 5000, loss: 0.560871
 >> iter 6000, loss: 0.223746
 >> iter 7000, loss: 0.173221
 >> iter 8000, loss: 0.078988
 >> iter 9000, loss: 0.231218
 >> iter 10000, loss: 0.103462
   Number of active neurons: 9
 >> iter 11000, loss: 0.083199
 >> iter 12000, loss: 0.109011
 >> iter 13000, loss: 0.064003
 >> iter 14000, loss: 0.128521
 >> iter 15000, loss: 0.192956
 >> iter 16000, loss: 0.086245
 >> iter 17000, loss: 0.113521
 >> iter 18000, loss: 0.054250
 >> iter 19000, loss: 0.175718
 >> iter 20000, loss: 0.078947
   Number of active neurons: 6
 >> iter 21000, loss: 0.088610
 >> iter 22000, loss: 0.045018
 >> iter 23000, loss: 0.135783
 >> iter 24000, loss: 0.064066
 >> iter 25000, loss: 0.060990
 >> iter 26000, loss: 0.106142
 >> iter 27000, loss: 0.121797
 >> iter 28000, loss: 0.058478
 >> iter 29000, loss: 0.218855
 >> iter 30000, loss: 0.096200
   Number of active neurons: 6
 >> iter 31000, loss: 0.096828
 >> iter 32000, loss: 0.049309
 >> iter 33000, loss: 0.132528
 >> iter 34000, loss: 0.062359
 >> iter 35000, loss: 0.177093
 >> iter 36000, loss: 0.079798
 >> iter 37000, loss: 0.198983
 >> iter 38000, loss: 0.088561
 >> iter 39000, loss: 0.163321
 >> iter 40000, loss: 0.074596
   Number of active neurons: 6
 >> iter 41000, loss: 0.074708
 >> iter 42000, loss: 0.040403
 >> iter 43000, loss: 0.067408
 >> iter 44000, loss: 0.037099
 >> iter 45000, loss: 0.121145
 >> iter 46000, loss: 0.058721
 >> iter 47000, loss: 0.146901
 >> iter 48000, loss: 0.067073
 >> iter 49000, loss: 0.078211
 >> iter 50000, loss: 0.042686
   Number of active neurons: 6
 >> iter 51000, loss: 0.106527
 >> iter 52000, loss: 0.051984
 >> iter 53000, loss: 0.576750
 >> iter 54000, loss: 0.238786
 >> iter 55000, loss: 0.111645
 >> iter 56000, loss: 0.054779
 >> iter 57000, loss: 0.294657
 >> iter 58000, loss: 0.126245
 >> iter 59000, loss: 0.115339
 >> iter 60000, loss: 0.068912
   Number of active neurons: 6
 >> iter 61000, loss: 0.187740
 >> iter 62000, loss: 0.083002
 >> iter 63000, loss: 0.184781
 >> iter 64000, loss: 0.130634
 >> iter 65000, loss: 0.063441
 >> iter 66000, loss: 0.036115
 >> iter 67000, loss: 0.031564
 >> iter 68000, loss: 0.055936
 >> iter 69000, loss: 0.154370
 >> iter 70000, loss: 0.069357
   Number of active neurons: 6
 >> iter 71000, loss: 0.037615
 >> iter 72000, loss: 0.107533
 >> iter 73000, loss: 0.104936
 >> iter 74000, loss: 0.343498
 >> iter 75000, loss: 0.143833
 >> iter 76000, loss: 0.066274
 >> iter 77000, loss: 0.036809
 >> iter 78000, loss: 0.110316
 >> iter 79000, loss: 0.053371
 >> iter 80000, loss: 0.032511
   Number of active neurons: 6
 >> iter 81000, loss: 0.341141
 >> iter 82000, loss: 0.168755
 >> iter 83000, loss: 0.079607
 >> iter 84000, loss: 0.041235
 >> iter 85000, loss: 0.026570
 >> iter 86000, loss: 0.251081
 >> iter 87000, loss: 0.108026
 >> iter 88000, loss: 0.074355
 >> iter 89000, loss: 0.038899
 >> iter 90000, loss: 0.104577
   Number of active neurons: 6
 >> iter 91000, loss: 0.055799
 >> iter 92000, loss: 0.191778
 >> iter 93000, loss: 0.103493
 >> iter 94000, loss: 0.049490
 >> iter 95000, loss: 0.029143
 >> iter 96000, loss: 0.058644
 >> iter 97000, loss: 0.032172
 >> iter 98000, loss: 0.321198
 >> iter 99000, loss: 0.149534
 >> iter 100000, loss: 0.068885
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.00599988000241
   - Test - Long: 0.0349982500875
   - Test - Big: 0.0029999700003
   - Test - A: 36.5775614959
   - Test - B: 12.4058396107
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.212518
 >> iter 2000, loss: 7.223336
 >> iter 3000, loss: 2.722790
 >> iter 4000, loss: 1.030714
 >> iter 5000, loss: 0.424542
 >> iter 6000, loss: 0.183023
 >> iter 7000, loss: 0.130671
 >> iter 8000, loss: 0.162806
 >> iter 9000, loss: 0.086655
 >> iter 10000, loss: 0.085607
   Number of active neurons: 7
 >> iter 11000, loss: 0.076147
 >> iter 12000, loss: 0.069120
 >> iter 13000, loss: 0.122924
 >> iter 14000, loss: 0.062074
 >> iter 15000, loss: 0.062105
 >> iter 16000, loss: 0.167120
 >> iter 17000, loss: 0.138888
 >> iter 18000, loss: 0.172048
 >> iter 19000, loss: 0.197057
 >> iter 20000, loss: 0.089294
   Number of active neurons: 7
 >> iter 21000, loss: 0.082292
 >> iter 22000, loss: 0.093104
 >> iter 23000, loss: 0.133815
 >> iter 24000, loss: 0.063534
 >> iter 25000, loss: 0.142792
 >> iter 26000, loss: 0.067672
 >> iter 27000, loss: 0.181470
 >> iter 28000, loss: 0.117799
 >> iter 29000, loss: 0.077324
 >> iter 30000, loss: 0.040652
   Number of active neurons: 7
 >> iter 31000, loss: 0.154481
 >> iter 32000, loss: 0.160625
 >> iter 33000, loss: 0.252970
 >> iter 34000, loss: 0.177430
 >> iter 35000, loss: 0.104276
 >> iter 36000, loss: 0.172596
 >> iter 37000, loss: 0.227660
 >> iter 38000, loss: 0.102288
 >> iter 39000, loss: 0.101300
 >> iter 40000, loss: 0.054139
   Number of active neurons: 6
 >> iter 41000, loss: 0.328954
 >> iter 42000, loss: 0.162067
 >> iter 43000, loss: 0.176788
 >> iter 44000, loss: 0.254328
 >> iter 45000, loss: 0.198190
 >> iter 46000, loss: 0.152159
 >> iter 47000, loss: 0.102520
 >> iter 48000, loss: 0.102905
 >> iter 49000, loss: 0.086597
 >> iter 50000, loss: 0.044740
   Number of active neurons: 6
 >> iter 51000, loss: 0.104091
 >> iter 52000, loss: 0.103526
 >> iter 53000, loss: 0.246905
 >> iter 54000, loss: 0.106428
 >> iter 55000, loss: 0.308086
 >> iter 56000, loss: 0.131339
 >> iter 57000, loss: 0.175213
 >> iter 58000, loss: 0.080295
 >> iter 59000, loss: 0.140346
 >> iter 60000, loss: 0.065274
   Number of active neurons: 6
 >> iter 61000, loss: 0.184926
 >> iter 62000, loss: 0.082859
 >> iter 63000, loss: 0.203458
 >> iter 64000, loss: 0.089963
 >> iter 65000, loss: 0.138438
 >> iter 66000, loss: 0.065059
 >> iter 67000, loss: 0.306737
 >> iter 68000, loss: 0.129785
 >> iter 69000, loss: 0.092423
 >> iter 70000, loss: 0.048447
   Number of active neurons: 6
 >> iter 71000, loss: 0.101352
 >> iter 72000, loss: 0.050027
 >> iter 73000, loss: 0.226056
 >> iter 74000, loss: 0.098768
 >> iter 75000, loss: 0.183285
 >> iter 76000, loss: 0.081479
 >> iter 77000, loss: 0.247789
 >> iter 78000, loss: 0.106819
 >> iter 79000, loss: 0.123279
 >> iter 80000, loss: 0.058601
   Number of active neurons: 5
 >> iter 81000, loss: 0.135339
 >> iter 82000, loss: 0.062236
 >> iter 83000, loss: 0.213118
 >> iter 84000, loss: 0.158120
 >> iter 85000, loss: 0.095952
 >> iter 86000, loss: 0.047228
 >> iter 87000, loss: 0.092373
 >> iter 88000, loss: 0.045460
 >> iter 89000, loss: 0.134827
 >> iter 90000, loss: 0.060895
   Number of active neurons: 5
 >> iter 91000, loss: 0.093171
 >> iter 92000, loss: 0.045220
 >> iter 93000, loss: 0.178606
 >> iter 94000, loss: 0.077708
 >> iter 95000, loss: 0.140229
 >> iter 96000, loss: 0.063651
 >> iter 97000, loss: 0.218215
 >> iter 98000, loss: 0.137633
 >> iter 99000, loss: 0.061501
 >> iter 100000, loss: 0.032683
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0139997200056
   - Test - Long: 0.009999500025
   - Test - Big: 0.0079999200008
   - Test - A: 59.1827211519
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 15.983964
 >> iter 2000, loss: 7.166004
 >> iter 3000, loss: 2.777683
 >> iter 4000, loss: 1.108550
 >> iter 5000, loss: 0.585617
 >> iter 6000, loss: 0.237924
 >> iter 7000, loss: 0.141614
 >> iter 8000, loss: 0.105408
 >> iter 9000, loss: 0.148746
 >> iter 10000, loss: 0.102377
   Number of active neurons: 8
 >> iter 11000, loss: 0.416151
 >> iter 12000, loss: 0.192818
 >> iter 13000, loss: 0.140878
 >> iter 14000, loss: 0.068440
 >> iter 15000, loss: 0.246699
 >> iter 16000, loss: 0.111806
 >> iter 17000, loss: 0.112876
 >> iter 18000, loss: 0.136703
 >> iter 19000, loss: 0.119771
 >> iter 20000, loss: 0.060421
   Number of active neurons: 8
 >> iter 21000, loss: 0.108686
 >> iter 22000, loss: 0.079493
 >> iter 23000, loss: 0.181430
 >> iter 24000, loss: 0.082831
 >> iter 25000, loss: 0.117121
 >> iter 26000, loss: 0.077589
 >> iter 27000, loss: 0.117046
 >> iter 28000, loss: 0.086768
 >> iter 29000, loss: 0.154129
 >> iter 30000, loss: 0.091530
   Number of active neurons: 8
 >> iter 31000, loss: 0.113952
 >> iter 32000, loss: 0.056767
 >> iter 33000, loss: 0.193652
 >> iter 34000, loss: 0.093415
 >> iter 35000, loss: 0.159323
 >> iter 36000, loss: 0.075926
 >> iter 37000, loss: 0.180097
 >> iter 38000, loss: 0.086265
 >> iter 39000, loss: 0.087726
 >> iter 40000, loss: 0.091938
   Number of active neurons: 7
 >> iter 41000, loss: 0.188200
 >> iter 42000, loss: 0.094744
 >> iter 43000, loss: 0.153959
 >> iter 44000, loss: 0.079918
 >> iter 45000, loss: 0.150792
 >> iter 46000, loss: 0.095639
 >> iter 47000, loss: 0.168798
 >> iter 48000, loss: 0.126013
 >> iter 49000, loss: 0.141292
 >> iter 50000, loss: 0.086272
   Number of active neurons: 7
 >> iter 51000, loss: 0.154136
 >> iter 52000, loss: 0.094934
 >> iter 53000, loss: 0.203146
 >> iter 54000, loss: 0.101484
 >> iter 55000, loss: 0.153266
 >> iter 56000, loss: 0.165502
 >> iter 57000, loss: 0.137892
 >> iter 58000, loss: 0.189277
 >> iter 59000, loss: 0.125453
 >> iter 60000, loss: 0.069455
   Number of active neurons: 7
 >> iter 61000, loss: 0.151571
 >> iter 62000, loss: 0.180682
 >> iter 63000, loss: 0.185772
 >> iter 64000, loss: 0.090927
 >> iter 65000, loss: 0.097247
 >> iter 66000, loss: 0.091235
 >> iter 67000, loss: 0.244715
 >> iter 68000, loss: 0.127456
 >> iter 69000, loss: 0.109557
 >> iter 70000, loss: 0.117131
   Number of active neurons: 7
 >> iter 71000, loss: 0.115863
 >> iter 72000, loss: 0.134676
 >> iter 73000, loss: 0.186879
 >> iter 74000, loss: 0.179613
 >> iter 75000, loss: 0.165047
 >> iter 76000, loss: 0.111740
 >> iter 77000, loss: 0.188275
 >> iter 78000, loss: 0.120085
 >> iter 79000, loss: 0.138256
 >> iter 80000, loss: 0.087004
   Number of active neurons: 6
 >> iter 81000, loss: 0.187579
 >> iter 82000, loss: 0.139340
 >> iter 83000, loss: 0.081263
 >> iter 84000, loss: 0.054878
 >> iter 85000, loss: 0.089306
 >> iter 86000, loss: 0.069488
 >> iter 87000, loss: 0.175586
 >> iter 88000, loss: 0.140438
 >> iter 89000, loss: 0.084540
 >> iter 90000, loss: 0.045634
   Number of active neurons: 6
 >> iter 91000, loss: 0.305766
 >> iter 92000, loss: 0.130548
 >> iter 93000, loss: 0.146773
 >> iter 94000, loss: 0.120288
 >> iter 95000, loss: 0.146208
 >> iter 96000, loss: 0.157134
 >> iter 97000, loss: 0.143378
 >> iter 98000, loss: 0.103823
 >> iter 99000, loss: 0.182098
 >> iter 100000, loss: 0.104822
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.00599988000241
   - Test - Long: 0.0
   - Test - Big: 0.0109998900011
   - Test - A: 24.3917072195
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.890068
 >> iter 2000, loss: 6.508380
 >> iter 3000, loss: 2.517940
 >> iter 4000, loss: 0.988810
 >> iter 5000, loss: 0.502156
 >> iter 6000, loss: 0.288187
 >> iter 7000, loss: 0.172041
 >> iter 8000, loss: 0.183620
 >> iter 9000, loss: 0.123583
 >> iter 10000, loss: 0.127163
   Number of active neurons: 8
 >> iter 11000, loss: 0.161094
 >> iter 12000, loss: 0.131645
 >> iter 13000, loss: 0.171821
 >> iter 14000, loss: 0.129220
 >> iter 15000, loss: 0.119562
 >> iter 16000, loss: 0.203296
 >> iter 17000, loss: 0.231557
 >> iter 18000, loss: 0.155214
 >> iter 19000, loss: 0.170703
 >> iter 20000, loss: 0.135876
   Number of active neurons: 7
 >> iter 21000, loss: 0.167072
 >> iter 22000, loss: 0.149914
 >> iter 23000, loss: 0.186428
 >> iter 24000, loss: 0.083496
 >> iter 25000, loss: 0.050807
 >> iter 26000, loss: 0.188138
 >> iter 27000, loss: 0.123904
 >> iter 28000, loss: 0.059703
 >> iter 29000, loss: 0.051840
 >> iter 30000, loss: 0.072594
   Number of active neurons: 6
 >> iter 31000, loss: 0.054336
 >> iter 32000, loss: 0.055131
 >> iter 33000, loss: 0.058464
 >> iter 34000, loss: 0.101315
 >> iter 35000, loss: 0.339820
 >> iter 36000, loss: 0.142176
 >> iter 37000, loss: 0.093598
 >> iter 38000, loss: 0.159395
 >> iter 39000, loss: 0.204534
 >> iter 40000, loss: 0.090453
   Number of active neurons: 6
 >> iter 41000, loss: 0.174307
 >> iter 42000, loss: 0.109922
 >> iter 43000, loss: 0.159442
 >> iter 44000, loss: 0.112843
 >> iter 45000, loss: 0.134972
 >> iter 46000, loss: 0.096950
 >> iter 47000, loss: 0.087452
 >> iter 48000, loss: 0.109655
 >> iter 49000, loss: 0.132383
 >> iter 50000, loss: 0.346152
   Number of active neurons: 6
 >> iter 51000, loss: 0.221218
 >> iter 52000, loss: 0.130938
 >> iter 53000, loss: 0.142847
 >> iter 54000, loss: 0.096361
 >> iter 55000, loss: 0.112459
 >> iter 56000, loss: 0.054441
 >> iter 57000, loss: 0.161453
 >> iter 58000, loss: 0.072844
 >> iter 59000, loss: 0.323050
 >> iter 60000, loss: 0.179077
   Number of active neurons: 6
 >> iter 61000, loss: 0.147727
 >> iter 62000, loss: 0.068631
 >> iter 63000, loss: 0.330263
 >> iter 64000, loss: 0.172661
 >> iter 65000, loss: 0.178329
 >> iter 66000, loss: 0.144792
 >> iter 67000, loss: 0.137695
 >> iter 68000, loss: 0.071987
 >> iter 69000, loss: 0.109795
 >> iter 70000, loss: 0.053382
   Number of active neurons: 6
 >> iter 71000, loss: 0.068099
 >> iter 72000, loss: 0.054837
 >> iter 73000, loss: 0.104682
 >> iter 74000, loss: 0.049486
 >> iter 75000, loss: 0.141801
 >> iter 76000, loss: 0.063961
 >> iter 77000, loss: 0.088037
 >> iter 78000, loss: 0.043883
 >> iter 79000, loss: 0.198823
 >> iter 80000, loss: 0.086397
   Number of active neurons: 6
 >> iter 81000, loss: 0.079586
 >> iter 82000, loss: 0.041466
 >> iter 83000, loss: 0.154355
 >> iter 84000, loss: 0.083691
 >> iter 85000, loss: 0.341142
 >> iter 86000, loss: 0.139193
 >> iter 87000, loss: 0.063337
 >> iter 88000, loss: 0.045285
 >> iter 89000, loss: 0.067077
 >> iter 90000, loss: 0.035994
   Number of active neurons: 6
 >> iter 91000, loss: 0.207412
 >> iter 92000, loss: 0.090046
 >> iter 93000, loss: 0.259600
 >> iter 94000, loss: 0.116217
 >> iter 95000, loss: 0.184393
 >> iter 96000, loss: 0.081584
 >> iter 97000, loss: 0.044156
 >> iter 98000, loss: 0.042921
 >> iter 99000, loss: 0.042989
 >> iter 100000, loss: 0.096468
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 19.0653956403
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.270538
 >> iter 2000, loss: 7.625615
 >> iter 3000, loss: 2.922373
 >> iter 4000, loss: 1.201210
 >> iter 5000, loss: 0.493004
 >> iter 6000, loss: 0.199169
 >> iter 7000, loss: 0.099640
 >> iter 8000, loss: 0.082048
 >> iter 9000, loss: 0.181643
 >> iter 10000, loss: 0.084455
   Number of active neurons: 7
 >> iter 11000, loss: 0.066333
 >> iter 12000, loss: 0.038679
 >> iter 13000, loss: 0.087370
 >> iter 14000, loss: 0.046571
 >> iter 15000, loss: 0.068561
 >> iter 16000, loss: 0.039224
 >> iter 17000, loss: 0.197198
 >> iter 18000, loss: 0.089190
 >> iter 19000, loss: 0.098943
 >> iter 20000, loss: 0.050850
   Number of active neurons: 6
 >> iter 21000, loss: 0.088712
 >> iter 22000, loss: 0.046968
 >> iter 23000, loss: 0.101653
 >> iter 24000, loss: 0.051126
 >> iter 25000, loss: 0.141166
 >> iter 26000, loss: 0.065988
 >> iter 27000, loss: 0.222111
 >> iter 28000, loss: 0.099307
 >> iter 29000, loss: 0.050801
 >> iter 30000, loss: 0.083493
   Number of active neurons: 5
 >> iter 31000, loss: 0.044573
 >> iter 32000, loss: 0.086695
 >> iter 33000, loss: 0.044914
 >> iter 34000, loss: 0.029232
 >> iter 35000, loss: 0.022180
 >> iter 36000, loss: 0.036325
 >> iter 37000, loss: 0.024506
 >> iter 38000, loss: 0.209888
 >> iter 39000, loss: 0.123485
 >> iter 40000, loss: 0.102637
   Number of active neurons: 5
 >> iter 41000, loss: 0.055784
 >> iter 42000, loss: 0.032832
 >> iter 43000, loss: 0.078750
 >> iter 44000, loss: 0.044891
 >> iter 45000, loss: 0.026666
 >> iter 46000, loss: 0.041294
 >> iter 47000, loss: 0.025267
 >> iter 48000, loss: 0.046070
 >> iter 49000, loss: 0.026664
 >> iter 50000, loss: 0.102410
   Number of active neurons: 5
 >> iter 51000, loss: 0.047400
 >> iter 52000, loss: 0.151808
 >> iter 53000, loss: 0.126191
 >> iter 54000, loss: 0.075365
 >> iter 55000, loss: 0.201234
 >> iter 56000, loss: 0.086638
 >> iter 57000, loss: 0.166102
 >> iter 58000, loss: 0.079858
 >> iter 59000, loss: 0.189572
 >> iter 60000, loss: 0.109282
   Number of active neurons: 5
 >> iter 61000, loss: 0.052404
 >> iter 62000, loss: 0.030203
 >> iter 63000, loss: 0.022993
 >> iter 64000, loss: 0.239071
 >> iter 65000, loss: 0.100360
 >> iter 66000, loss: 0.097664
 >> iter 67000, loss: 0.047238
 >> iter 68000, loss: 0.098473
 >> iter 69000, loss: 0.068989
 >> iter 70000, loss: 0.094441
   Number of active neurons: 5
 >> iter 71000, loss: 0.046155
 >> iter 72000, loss: 0.171670
 >> iter 73000, loss: 0.087761
 >> iter 74000, loss: 0.042951
 >> iter 75000, loss: 0.026081
 >> iter 76000, loss: 0.387066
 >> iter 77000, loss: 0.377840
 >> iter 78000, loss: 0.171380
 >> iter 79000, loss: 0.117631
 >> iter 80000, loss: 0.055976
   Number of active neurons: 5
 >> iter 81000, loss: 0.042160
 >> iter 82000, loss: 0.026319
 >> iter 83000, loss: 0.020086
 >> iter 84000, loss: 0.073656
 >> iter 85000, loss: 0.037173
 >> iter 86000, loss: 0.418063
 >> iter 87000, loss: 0.246041
 >> iter 88000, loss: 0.104993
 >> iter 89000, loss: 0.051617
 >> iter 90000, loss: 0.029813
   Number of active neurons: 5
 >> iter 91000, loss: 0.023363
 >> iter 92000, loss: 0.113215
 >> iter 93000, loss: 0.052045
 >> iter 94000, loss: 0.033000
 >> iter 95000, loss: 0.022211
 >> iter 96000, loss: 0.157808
 >> iter 97000, loss: 0.126845
 >> iter 98000, loss: 0.074852
 >> iter 99000, loss: 0.038403
 >> iter 100000, loss: 0.096359
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0039999200016
   - Test - Long: 0.009999500025
   - Test - Big: 0.0
   - Test - A: 54.7096860209
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.088016
 >> iter 2000, loss: 7.299219
 >> iter 3000, loss: 2.806532
 >> iter 4000, loss: 1.054746
 >> iter 5000, loss: 0.432482
 >> iter 6000, loss: 0.176056
 >> iter 7000, loss: 0.121175
 >> iter 8000, loss: 0.058784
 >> iter 9000, loss: 0.100392
 >> iter 10000, loss: 0.051795
   Number of active neurons: 9
 >> iter 11000, loss: 0.050475
 >> iter 12000, loss: 0.032097
 >> iter 13000, loss: 0.136704
 >> iter 14000, loss: 0.064716
 >> iter 15000, loss: 0.088963
 >> iter 16000, loss: 0.047498
 >> iter 17000, loss: 0.126974
 >> iter 18000, loss: 0.061854
 >> iter 19000, loss: 0.078844
 >> iter 20000, loss: 0.043702
   Number of active neurons: 9
 >> iter 21000, loss: 0.035451
 >> iter 22000, loss: 0.038909
 >> iter 23000, loss: 0.116092
 >> iter 24000, loss: 0.057142
 >> iter 25000, loss: 0.136654
 >> iter 26000, loss: 0.065412
 >> iter 27000, loss: 0.102402
 >> iter 28000, loss: 0.051441
 >> iter 29000, loss: 0.034337
 >> iter 30000, loss: 0.025297
   Number of active neurons: 7
 >> iter 31000, loss: 0.047097
 >> iter 32000, loss: 0.029655
 >> iter 33000, loss: 0.120595
 >> iter 34000, loss: 0.057178
 >> iter 35000, loss: 0.055342
 >> iter 36000, loss: 0.032810
 >> iter 37000, loss: 0.024542
 >> iter 38000, loss: 0.125113
 >> iter 39000, loss: 0.057720
 >> iter 40000, loss: 0.033346
   Number of active neurons: 7
 >> iter 41000, loss: 0.024032
 >> iter 42000, loss: 0.157729
 >> iter 43000, loss: 0.071281
 >> iter 44000, loss: 0.123939
 >> iter 45000, loss: 0.086798
 >> iter 46000, loss: 0.104777
 >> iter 47000, loss: 0.063776
 >> iter 48000, loss: 0.135817
 >> iter 49000, loss: 0.084162
 >> iter 50000, loss: 0.119370
   Number of active neurons: 7
 >> iter 51000, loss: 0.055245
 >> iter 52000, loss: 0.189089
 >> iter 53000, loss: 0.128150
 >> iter 54000, loss: 0.083108
 >> iter 55000, loss: 0.102817
 >> iter 56000, loss: 0.100101
 >> iter 57000, loss: 0.053394
 >> iter 58000, loss: 0.072162
 >> iter 59000, loss: 0.039471
 >> iter 60000, loss: 0.038456
   Number of active neurons: 7
 >> iter 61000, loss: 0.034034
 >> iter 62000, loss: 0.089508
 >> iter 63000, loss: 0.079851
 >> iter 64000, loss: 0.090668
 >> iter 65000, loss: 0.046098
 >> iter 66000, loss: 0.059979
 >> iter 67000, loss: 0.074168
 >> iter 68000, loss: 0.038808
 >> iter 69000, loss: 0.025137
 >> iter 70000, loss: 0.079191
   Number of active neurons: 6
 >> iter 71000, loss: 0.062987
 >> iter 72000, loss: 0.234599
 >> iter 73000, loss: 0.265097
 >> iter 74000, loss: 0.111805
 >> iter 75000, loss: 0.053817
 >> iter 76000, loss: 0.035987
 >> iter 77000, loss: 0.160039
 >> iter 78000, loss: 0.148539
 >> iter 79000, loss: 0.094322
 >> iter 80000, loss: 0.056445
   Number of active neurons: 6
 >> iter 81000, loss: 0.070120
 >> iter 82000, loss: 0.067295
 >> iter 83000, loss: 0.038111
 >> iter 84000, loss: 0.043221
 >> iter 85000, loss: 0.025918
 >> iter 86000, loss: 0.073662
 >> iter 87000, loss: 0.039636
 >> iter 88000, loss: 0.064943
 >> iter 89000, loss: 0.034382
 >> iter 90000, loss: 0.134622
   Number of active neurons: 5
 >> iter 91000, loss: 0.067728
 >> iter 92000, loss: 0.402350
 >> iter 93000, loss: 0.379176
 >> iter 94000, loss: 0.158579
 >> iter 95000, loss: 0.120555
 >> iter 96000, loss: 0.056897
 >> iter 97000, loss: 0.035992
 >> iter 98000, loss: 0.023693
 >> iter 99000, loss: 0.102485
 >> iter 100000, loss: 0.156464
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0049997500125
   - Test - Big: 0.0
   - Test - A: 20.4786347577
   - Test - B: 0.226651556563
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 16.816052
 >> iter 2000, loss: 8.366370
 >> iter 3000, loss: 3.289655
 >> iter 4000, loss: 1.242646
 >> iter 5000, loss: 0.478178
 >> iter 6000, loss: 0.191394
 >> iter 7000, loss: 0.172748
 >> iter 8000, loss: 0.079810
 >> iter 9000, loss: 0.125593
 >> iter 10000, loss: 0.139889
   Number of active neurons: 8
 >> iter 11000, loss: 0.103142
 >> iter 12000, loss: 0.071567
 >> iter 13000, loss: 0.118438
 >> iter 14000, loss: 0.112644
 >> iter 15000, loss: 0.137883
 >> iter 16000, loss: 0.116354
 >> iter 17000, loss: 0.129890
 >> iter 18000, loss: 0.233944
 >> iter 19000, loss: 0.184664
 >> iter 20000, loss: 0.085770
   Number of active neurons: 7
 >> iter 21000, loss: 0.124884
 >> iter 22000, loss: 0.079510
 >> iter 23000, loss: 0.107211
 >> iter 24000, loss: 0.255832
 >> iter 25000, loss: 0.311601
 >> iter 26000, loss: 0.135296
 >> iter 27000, loss: 0.421050
 >> iter 28000, loss: 0.180255
 >> iter 29000, loss: 0.083609
 >> iter 30000, loss: 0.245135
   Number of active neurons: 7
 >> iter 31000, loss: 0.208936
 >> iter 32000, loss: 0.094282
 >> iter 33000, loss: 0.073658
 >> iter 34000, loss: 0.040912
 >> iter 35000, loss: 0.101952
 >> iter 36000, loss: 0.084655
 >> iter 37000, loss: 0.077359
 >> iter 38000, loss: 0.083250
 >> iter 39000, loss: 0.074704
 >> iter 40000, loss: 0.078263
   Number of active neurons: 6
 >> iter 41000, loss: 0.067781
 >> iter 42000, loss: 0.069639
 >> iter 43000, loss: 0.081929
 >> iter 44000, loss: 0.196664
 >> iter 45000, loss: 0.108774
 >> iter 46000, loss: 0.052196
 >> iter 47000, loss: 0.201268
 >> iter 48000, loss: 0.087826
 >> iter 49000, loss: 0.082145
 >> iter 50000, loss: 0.042182
   Number of active neurons: 5
 >> iter 51000, loss: 0.073614
 >> iter 52000, loss: 0.054751
 >> iter 53000, loss: 0.297039
 >> iter 54000, loss: 0.124383
 >> iter 55000, loss: 0.097931
 >> iter 56000, loss: 0.048051
 >> iter 57000, loss: 0.098158
 >> iter 58000, loss: 0.060218
 >> iter 59000, loss: 0.102165
 >> iter 60000, loss: 0.139305
   Number of active neurons: 5
 >> iter 61000, loss: 0.090312
 >> iter 62000, loss: 0.045362
 >> iter 63000, loss: 0.047057
 >> iter 64000, loss: 0.057066
 >> iter 65000, loss: 0.090524
 >> iter 66000, loss: 0.072153
 >> iter 67000, loss: 0.131292
 >> iter 68000, loss: 0.069797
 >> iter 69000, loss: 0.079775
 >> iter 70000, loss: 0.072774
   Number of active neurons: 5
 >> iter 71000, loss: 0.170361
 >> iter 72000, loss: 0.076499
 >> iter 73000, loss: 0.038922
 >> iter 74000, loss: 0.040142
 >> iter 75000, loss: 0.032481
 >> iter 76000, loss: 0.041485
 >> iter 77000, loss: 0.100681
 >> iter 78000, loss: 0.122766
 >> iter 79000, loss: 0.067671
 >> iter 80000, loss: 0.059928
   Number of active neurons: 5
 >> iter 81000, loss: 0.042170
 >> iter 82000, loss: 0.151333
 >> iter 83000, loss: 0.067069
 >> iter 84000, loss: 0.036164
 >> iter 85000, loss: 0.343543
 >> iter 86000, loss: 0.180476
 >> iter 87000, loss: 0.156923
 >> iter 88000, loss: 0.093624
 >> iter 89000, loss: 0.049564
 >> iter 90000, loss: 0.028382
   Number of active neurons: 5
 >> iter 91000, loss: 0.174228
 >> iter 92000, loss: 0.076857
 >> iter 93000, loss: 0.136377
 >> iter 94000, loss: 0.080625
 >> iter 95000, loss: 0.040099
 >> iter 96000, loss: 0.108947
 >> iter 97000, loss: 0.102431
 >> iter 98000, loss: 0.048542
 >> iter 99000, loss: 0.028304
 >> iter 100000, loss: 0.197113
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.00599988000241
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 54.4097060196
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.377672
 >> iter 2000, loss: 7.625373
 >> iter 3000, loss: 3.048575
 >> iter 4000, loss: 1.186204
 >> iter 5000, loss: 0.771465
 >> iter 6000, loss: 0.332317
 >> iter 7000, loss: 0.166728
 >> iter 8000, loss: 0.141594
 >> iter 9000, loss: 0.073351
 >> iter 10000, loss: 0.045570
   Number of active neurons: 9
 >> iter 11000, loss: 0.138561
 >> iter 12000, loss: 0.071199
 >> iter 13000, loss: 0.046463
 >> iter 14000, loss: 0.066631
 >> iter 15000, loss: 0.044253
 >> iter 16000, loss: 0.511204
 >> iter 17000, loss: 0.452429
 >> iter 18000, loss: 0.190875
 >> iter 19000, loss: 0.243995
 >> iter 20000, loss: 0.130840
   Number of active neurons: 8
 >> iter 21000, loss: 0.070023
 >> iter 22000, loss: 0.045071
 >> iter 23000, loss: 0.035859
 >> iter 24000, loss: 0.098985
 >> iter 25000, loss: 0.054564
 >> iter 26000, loss: 0.194687
 >> iter 27000, loss: 0.135662
 >> iter 28000, loss: 0.366875
 >> iter 29000, loss: 0.219388
 >> iter 30000, loss: 0.134190
   Number of active neurons: 8
 >> iter 31000, loss: 0.085073
 >> iter 32000, loss: 0.090013
 >> iter 33000, loss: 0.146154
 >> iter 34000, loss: 0.075786
 >> iter 35000, loss: 0.262336
 >> iter 36000, loss: 0.117964
 >> iter 37000, loss: 0.273635
 >> iter 38000, loss: 0.123832
 >> iter 39000, loss: 0.061574
 >> iter 40000, loss: 0.082148
   Number of active neurons: 8
 >> iter 41000, loss: 0.074159
 >> iter 42000, loss: 0.092034
 >> iter 43000, loss: 0.083242
 >> iter 44000, loss: 0.044397
 >> iter 45000, loss: 0.237017
 >> iter 46000, loss: 0.104099
 >> iter 47000, loss: 0.098721
 >> iter 48000, loss: 0.052101
 >> iter 49000, loss: 0.097820
 >> iter 50000, loss: 0.139453
   Number of active neurons: 8
 >> iter 51000, loss: 0.105342
 >> iter 52000, loss: 0.052643
 >> iter 53000, loss: 0.099307
 >> iter 54000, loss: 0.139293
 >> iter 55000, loss: 0.076511
 >> iter 56000, loss: 0.202948
 >> iter 57000, loss: 0.090521
 >> iter 58000, loss: 0.150334
 >> iter 59000, loss: 0.156964
 >> iter 60000, loss: 0.161383
   Number of active neurons: 7
 >> iter 61000, loss: 0.305192
 >> iter 62000, loss: 0.171361
 >> iter 63000, loss: 0.111834
 >> iter 64000, loss: 0.087451
 >> iter 65000, loss: 0.104143
 >> iter 66000, loss: 0.187441
 >> iter 67000, loss: 0.133698
 >> iter 68000, loss: 0.117889
 >> iter 69000, loss: 0.300510
 >> iter 70000, loss: 0.128421
   Number of active neurons: 7
 >> iter 71000, loss: 0.089152
 >> iter 72000, loss: 0.047495
 >> iter 73000, loss: 0.050432
 >> iter 74000, loss: 0.031219
 >> iter 75000, loss: 0.096452
 >> iter 76000, loss: 0.132797
 >> iter 77000, loss: 0.092823
 >> iter 78000, loss: 0.046686
 >> iter 79000, loss: 0.097614
 >> iter 80000, loss: 0.048517
   Number of active neurons: 6
 >> iter 81000, loss: 0.066856
 >> iter 82000, loss: 0.090122
 >> iter 83000, loss: 0.114416
 >> iter 84000, loss: 0.072459
 >> iter 85000, loss: 0.084872
 >> iter 86000, loss: 0.134386
 >> iter 87000, loss: 0.239377
 >> iter 88000, loss: 0.152633
 >> iter 89000, loss: 0.100598
 >> iter 90000, loss: 0.073909
   Number of active neurons: 6
 >> iter 91000, loss: 0.040560
 >> iter 92000, loss: 0.209283
 >> iter 93000, loss: 0.143794
 >> iter 94000, loss: 0.067033
 >> iter 95000, loss: 0.097980
 >> iter 96000, loss: 0.047742
 >> iter 97000, loss: 0.202019
 >> iter 98000, loss: 0.091911
 >> iter 99000, loss: 0.093154
 >> iter 100000, loss: 0.070704
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 19.9253383108
   - Test - B: 17.5054996334
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.119299
 >> iter 2000, loss: 7.383829
 >> iter 3000, loss: 2.767646
 >> iter 4000, loss: 1.047414
 >> iter 5000, loss: 0.550972
 >> iter 6000, loss: 0.226068
 >> iter 7000, loss: 0.143131
 >> iter 8000, loss: 0.071712
 >> iter 9000, loss: 0.261566
 >> iter 10000, loss: 0.234431
   Number of active neurons: 8
 >> iter 11000, loss: 0.254273
 >> iter 12000, loss: 0.113717
 >> iter 13000, loss: 0.072045
 >> iter 14000, loss: 0.043188
 >> iter 15000, loss: 0.085094
 >> iter 16000, loss: 0.064017
 >> iter 17000, loss: 0.039728
 >> iter 18000, loss: 0.030460
 >> iter 19000, loss: 0.027780
 >> iter 20000, loss: 0.026066
   Number of active neurons: 8
 >> iter 21000, loss: 0.026376
 >> iter 22000, loss: 0.164461
 >> iter 23000, loss: 0.079955
 >> iter 24000, loss: 0.158911
 >> iter 25000, loss: 0.078413
 >> iter 26000, loss: 0.104739
 >> iter 27000, loss: 0.056804
 >> iter 28000, loss: 0.145106
 >> iter 29000, loss: 0.075611
 >> iter 30000, loss: 0.048397
   Number of active neurons: 6
 >> iter 31000, loss: 0.061087
 >> iter 32000, loss: 0.038766
 >> iter 33000, loss: 0.030785
 >> iter 34000, loss: 0.027648
 >> iter 35000, loss: 0.248082
 >> iter 36000, loss: 0.140145
 >> iter 37000, loss: 0.068945
 >> iter 38000, loss: 0.041997
 >> iter 39000, loss: 0.031892
 >> iter 40000, loss: 0.098359
   Number of active neurons: 6
 >> iter 41000, loss: 0.274706
 >> iter 42000, loss: 0.122234
 >> iter 43000, loss: 0.062166
 >> iter 44000, loss: 0.039193
 >> iter 45000, loss: 0.262832
 >> iter 46000, loss: 0.117633
 >> iter 47000, loss: 0.060507
 >> iter 48000, loss: 0.038799
 >> iter 49000, loss: 0.030724
 >> iter 50000, loss: 0.027826
   Number of active neurons: 6
 >> iter 51000, loss: 0.078146
 >> iter 52000, loss: 0.046496
 >> iter 53000, loss: 0.034130
 >> iter 54000, loss: 0.375320
 >> iter 55000, loss: 0.181668
 >> iter 56000, loss: 0.083647
 >> iter 57000, loss: 0.047191
 >> iter 58000, loss: 0.033820
 >> iter 59000, loss: 0.028889
 >> iter 60000, loss: 0.027151
   Number of active neurons: 6
 >> iter 61000, loss: 0.026475
 >> iter 62000, loss: 0.157040
 >> iter 63000, loss: 0.303787
 >> iter 64000, loss: 0.131584
 >> iter 65000, loss: 0.066669
 >> iter 66000, loss: 0.095291
 >> iter 67000, loss: 0.051884
 >> iter 68000, loss: 0.035531
 >> iter 69000, loss: 0.029401
 >> iter 70000, loss: 0.026870
   Number of active neurons: 5
 >> iter 71000, loss: 0.025738
 >> iter 72000, loss: 0.134886
 >> iter 73000, loss: 0.066861
 >> iter 74000, loss: 0.042595
 >> iter 75000, loss: 0.031183
 >> iter 76000, loss: 0.284604
 >> iter 77000, loss: 0.123596
 >> iter 78000, loss: 0.061838
 >> iter 79000, loss: 0.038740
 >> iter 80000, loss: 0.030060
   Number of active neurons: 5
 >> iter 81000, loss: 0.026623
 >> iter 82000, loss: 0.025373
 >> iter 83000, loss: 0.024655
 >> iter 84000, loss: 0.024558
 >> iter 85000, loss: 0.024159
 >> iter 86000, loss: 0.289544
 >> iter 87000, loss: 0.126477
 >> iter 88000, loss: 0.064167
 >> iter 89000, loss: 0.040605
 >> iter 90000, loss: 0.031303
   Number of active neurons: 5
 >> iter 91000, loss: 0.027554
 >> iter 92000, loss: 0.092678
 >> iter 93000, loss: 0.050522
 >> iter 94000, loss: 0.034899
 >> iter 95000, loss: 0.028325
 >> iter 96000, loss: 0.198846
 >> iter 97000, loss: 0.091930
 >> iter 98000, loss: 0.051085
 >> iter 99000, loss: 0.035383
 >> iter 100000, loss: 0.208990
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 19.2253849743
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.128846
 >> iter 2000, loss: 7.322259
 >> iter 3000, loss: 2.721812
 >> iter 4000, loss: 1.018599
 >> iter 5000, loss: 0.459271
 >> iter 6000, loss: 0.185771
 >> iter 7000, loss: 0.145027
 >> iter 8000, loss: 0.067883
 >> iter 9000, loss: 0.044841
 >> iter 10000, loss: 0.063226
   Number of active neurons: 8
 >> iter 11000, loss: 0.095605
 >> iter 12000, loss: 0.049365
 >> iter 13000, loss: 0.093626
 >> iter 14000, loss: 0.049029
 >> iter 15000, loss: 0.114777
 >> iter 16000, loss: 0.057269
 >> iter 17000, loss: 0.119151
 >> iter 18000, loss: 0.068076
 >> iter 19000, loss: 0.098800
 >> iter 20000, loss: 0.051341
   Number of active neurons: 8
 >> iter 21000, loss: 0.054076
 >> iter 22000, loss: 0.033756
 >> iter 23000, loss: 0.075323
 >> iter 24000, loss: 0.041500
 >> iter 25000, loss: 0.040900
 >> iter 26000, loss: 0.063321
 >> iter 27000, loss: 0.108050
 >> iter 28000, loss: 0.054039
 >> iter 29000, loss: 0.055084
 >> iter 30000, loss: 0.032896
   Number of active neurons: 8
 >> iter 31000, loss: 0.166317
 >> iter 32000, loss: 0.076706
 >> iter 33000, loss: 0.077037
 >> iter 34000, loss: 0.046581
 >> iter 35000, loss: 0.046495
 >> iter 36000, loss: 0.029902
 >> iter 37000, loss: 0.114204
 >> iter 38000, loss: 0.097931
 >> iter 39000, loss: 0.089906
 >> iter 40000, loss: 0.046937
   Number of active neurons: 7
 >> iter 41000, loss: 0.069449
 >> iter 42000, loss: 0.038900
 >> iter 43000, loss: 0.095060
 >> iter 44000, loss: 0.053746
 >> iter 45000, loss: 0.120199
 >> iter 46000, loss: 0.056939
 >> iter 47000, loss: 0.105834
 >> iter 48000, loss: 0.101623
 >> iter 49000, loss: 0.242999
 >> iter 50000, loss: 0.137869
   Number of active neurons: 6
 >> iter 51000, loss: 0.078571
 >> iter 52000, loss: 0.063299
 >> iter 53000, loss: 0.138333
 >> iter 54000, loss: 0.063586
 >> iter 55000, loss: 0.047638
 >> iter 56000, loss: 0.103402
 >> iter 57000, loss: 0.234729
 >> iter 58000, loss: 0.125388
 >> iter 59000, loss: 0.135621
 >> iter 60000, loss: 0.062042
   Number of active neurons: 5
 >> iter 61000, loss: 0.106639
 >> iter 62000, loss: 0.063640
 >> iter 63000, loss: 0.035108
 >> iter 64000, loss: 0.074677
 >> iter 65000, loss: 0.108981
 >> iter 66000, loss: 0.051804
 >> iter 67000, loss: 0.173197
 >> iter 68000, loss: 0.076642
 >> iter 69000, loss: 0.167590
 >> iter 70000, loss: 0.073804
   Number of active neurons: 6
 >> iter 71000, loss: 0.052519
 >> iter 72000, loss: 0.066897
 >> iter 73000, loss: 0.035714
 >> iter 74000, loss: 0.042704
 >> iter 75000, loss: 0.030190
 >> iter 76000, loss: 0.020991
 >> iter 77000, loss: 0.233605
 >> iter 78000, loss: 0.098984
 >> iter 79000, loss: 0.122759
 >> iter 80000, loss: 0.056437
   Number of active neurons: 6
 >> iter 81000, loss: 0.236970
 >> iter 82000, loss: 0.101507
 >> iter 83000, loss: 0.140701
 >> iter 84000, loss: 0.064323
 >> iter 85000, loss: 0.207814
 >> iter 86000, loss: 0.089965
 >> iter 87000, loss: 0.071931
 >> iter 88000, loss: 0.038263
 >> iter 89000, loss: 0.358493
 >> iter 90000, loss: 0.148002
   Number of active neurons: 6
 >> iter 91000, loss: 0.067453
 >> iter 92000, loss: 0.036637
 >> iter 93000, loss: 0.082638
 >> iter 94000, loss: 0.064893
 >> iter 95000, loss: 0.078087
 >> iter 96000, loss: 0.039792
 >> iter 97000, loss: 0.116259
 >> iter 98000, loss: 0.054235
 >> iter 99000, loss: 0.042914
 >> iter 100000, loss: 0.199070
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.00599988000241
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 51.0099326712
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.288165
 >> iter 2000, loss: 7.304937
 >> iter 3000, loss: 2.852406
 >> iter 4000, loss: 1.103455
 >> iter 5000, loss: 0.537130
 >> iter 6000, loss: 0.235253
 >> iter 7000, loss: 0.137654
 >> iter 8000, loss: 0.065218
 >> iter 9000, loss: 0.134673
 >> iter 10000, loss: 0.066289
   Number of active neurons: 8
 >> iter 11000, loss: 0.055741
 >> iter 12000, loss: 0.034200
 >> iter 13000, loss: 0.111038
 >> iter 14000, loss: 0.055257
 >> iter 15000, loss: 0.066095
 >> iter 16000, loss: 0.037199
 >> iter 17000, loss: 0.143105
 >> iter 18000, loss: 0.067316
 >> iter 19000, loss: 0.132401
 >> iter 20000, loss: 0.062620
   Number of active neurons: 7
 >> iter 21000, loss: 0.039984
 >> iter 22000, loss: 0.026186
 >> iter 23000, loss: 0.042150
 >> iter 24000, loss: 0.026863
 >> iter 25000, loss: 0.029586
 >> iter 26000, loss: 0.022635
 >> iter 27000, loss: 0.254684
 >> iter 28000, loss: 0.108038
 >> iter 29000, loss: 0.052326
 >> iter 30000, loss: 0.112783
   Number of active neurons: 6
 >> iter 31000, loss: 0.121495
 >> iter 32000, loss: 0.056973
 >> iter 33000, loss: 0.435434
 >> iter 34000, loss: 0.186018
 >> iter 35000, loss: 0.084161
 >> iter 36000, loss: 0.055888
 >> iter 37000, loss: 0.033264
 >> iter 38000, loss: 0.039974
 >> iter 39000, loss: 0.070441
 >> iter 40000, loss: 0.044466
   Number of active neurons: 6
 >> iter 41000, loss: 0.240373
 >> iter 42000, loss: 0.103159
 >> iter 43000, loss: 0.055041
 >> iter 44000, loss: 0.033124
 >> iter 45000, loss: 0.024160
 >> iter 46000, loss: 0.020494
 >> iter 47000, loss: 0.126535
 >> iter 48000, loss: 0.060730
 >> iter 49000, loss: 0.033734
 >> iter 50000, loss: 0.399727
   Number of active neurons: 5
 >> iter 51000, loss: 0.242527
 >> iter 52000, loss: 0.109171
 >> iter 53000, loss: 0.056030
 >> iter 54000, loss: 0.033417
 >> iter 55000, loss: 0.099481
 >> iter 56000, loss: 0.082572
 >> iter 57000, loss: 0.178322
 >> iter 58000, loss: 0.080577
 >> iter 59000, loss: 0.042801
 >> iter 60000, loss: 0.143524
   Number of active neurons: 6
 >> iter 61000, loss: 0.173692
 >> iter 62000, loss: 0.104264
 >> iter 63000, loss: 0.120255
 >> iter 64000, loss: 0.072445
 >> iter 65000, loss: 0.043203
 >> iter 66000, loss: 0.053677
 >> iter 67000, loss: 0.043262
 >> iter 68000, loss: 0.142362
 >> iter 69000, loss: 0.144626
 >> iter 70000, loss: 0.065081
   Number of active neurons: 5
 >> iter 71000, loss: 0.034685
 >> iter 72000, loss: 0.103557
 >> iter 73000, loss: 0.049645
 >> iter 74000, loss: 0.111517
 >> iter 75000, loss: 0.284512
 >> iter 76000, loss: 0.178122
 >> iter 77000, loss: 0.107008
 >> iter 78000, loss: 0.051154
 >> iter 79000, loss: 0.054111
 >> iter 80000, loss: 0.107392
   Number of active neurons: 5
 >> iter 81000, loss: 0.050596
 >> iter 82000, loss: 0.061836
 >> iter 83000, loss: 0.040797
 >> iter 84000, loss: 0.058068
 >> iter 85000, loss: 0.034891
 >> iter 86000, loss: 0.022476
 >> iter 87000, loss: 0.018065
 >> iter 88000, loss: 0.066409
 >> iter 89000, loss: 0.034159
 >> iter 90000, loss: 0.022691
   Number of active neurons: 5
 >> iter 91000, loss: 0.102664
 >> iter 92000, loss: 0.202983
 >> iter 93000, loss: 0.086861
 >> iter 94000, loss: 0.103948
 >> iter 95000, loss: 0.048978
 >> iter 96000, loss: 0.041691
 >> iter 97000, loss: 0.036484
 >> iter 98000, loss: 0.040825
 >> iter 99000, loss: 0.024376
 >> iter 100000, loss: 0.157911
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 19.085394307
   - Test - B: 15.6056262916
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.121612
 >> iter 2000, loss: 7.888706
 >> iter 3000, loss: 3.550492
 >> iter 4000, loss: 1.405320
 >> iter 5000, loss: 0.611102
 >> iter 6000, loss: 0.243237
 >> iter 7000, loss: 0.167745
 >> iter 8000, loss: 0.136627
 >> iter 9000, loss: 0.158626
 >> iter 10000, loss: 0.300785
   Number of active neurons: 7
 >> iter 11000, loss: 0.146125
 >> iter 12000, loss: 0.068866
 >> iter 13000, loss: 0.121610
 >> iter 14000, loss: 0.148577
 >> iter 15000, loss: 0.146219
 >> iter 16000, loss: 0.117845
 >> iter 17000, loss: 0.174621
 >> iter 18000, loss: 0.091507
 >> iter 19000, loss: 0.115914
 >> iter 20000, loss: 0.237754
   Number of active neurons: 7
 >> iter 21000, loss: 0.139923
 >> iter 22000, loss: 0.084212
 >> iter 23000, loss: 0.094244
 >> iter 24000, loss: 0.121366
 >> iter 25000, loss: 0.087101
 >> iter 26000, loss: 0.226627
 >> iter 27000, loss: 0.176148
 >> iter 28000, loss: 0.218682
 >> iter 29000, loss: 0.191907
 >> iter 30000, loss: 0.209533
   Number of active neurons: 6
 >> iter 31000, loss: 0.145452
 >> iter 32000, loss: 0.212741
 >> iter 33000, loss: 0.162606
 >> iter 34000, loss: 0.116215
 >> iter 35000, loss: 0.110498
 >> iter 36000, loss: 0.086827
 >> iter 37000, loss: 0.250134
 >> iter 38000, loss: 0.126925
 >> iter 39000, loss: 0.109472
 >> iter 40000, loss: 0.093894
   Number of active neurons: 5
 >> iter 41000, loss: 0.112633
 >> iter 42000, loss: 0.155699
 >> iter 43000, loss: 0.096214
 >> iter 44000, loss: 0.328367
 >> iter 45000, loss: 0.254027
 >> iter 46000, loss: 0.230151
 >> iter 47000, loss: 0.198339
 >> iter 48000, loss: 0.281063
 >> iter 49000, loss: 0.140448
 >> iter 50000, loss: 0.068493
   Number of active neurons: 5
 >> iter 51000, loss: 0.049632
 >> iter 52000, loss: 0.120388
 >> iter 53000, loss: 0.219463
 >> iter 54000, loss: 0.159785
 >> iter 55000, loss: 0.175836
 >> iter 56000, loss: 0.146647
 >> iter 57000, loss: 0.234084
 >> iter 58000, loss: 0.146994
 >> iter 59000, loss: 0.125215
 >> iter 60000, loss: 0.099937
   Number of active neurons: 5
 >> iter 61000, loss: 0.214040
 >> iter 62000, loss: 0.239834
 >> iter 63000, loss: 0.183046
 >> iter 64000, loss: 0.261114
 >> iter 65000, loss: 0.330097
 >> iter 66000, loss: 0.217161
 >> iter 67000, loss: 0.424728
 >> iter 68000, loss: 0.308767
 >> iter 69000, loss: 0.174906
 >> iter 70000, loss: 0.156222
   Number of active neurons: 5
 >> iter 71000, loss: 0.128101
 >> iter 72000, loss: 0.207619
 >> iter 73000, loss: 0.237226
 >> iter 74000, loss: 0.237079
 >> iter 75000, loss: 0.563309
 >> iter 76000, loss: 0.240206
 >> iter 77000, loss: 0.199267
 >> iter 78000, loss: 0.166329
 >> iter 79000, loss: 0.113605
 >> iter 80000, loss: 0.177206
   Number of active neurons: 5
 >> iter 81000, loss: 0.243508
 >> iter 82000, loss: 0.135327
 >> iter 83000, loss: 0.347458
 >> iter 84000, loss: 0.420177
 >> iter 85000, loss: 0.289527
 >> iter 86000, loss: 0.235158
 >> iter 87000, loss: 0.265152
 >> iter 88000, loss: 0.218630
 >> iter 89000, loss: 0.191384
 >> iter 90000, loss: 0.498561
   Number of active neurons: 5
 >> iter 91000, loss: 0.427669
 >> iter 92000, loss: 0.263446
 >> iter 93000, loss: 0.169668
 >> iter 94000, loss: 0.077896
 >> iter 95000, loss: 0.186401
 >> iter 96000, loss: 0.098670
 >> iter 97000, loss: 0.410313
 >> iter 98000, loss: 0.311224
 >> iter 99000, loss: 0.390370
 >> iter 100000, loss: 0.172434
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0759984800304
   - Test - Long: 0.0249987500625
   - Test - Big: 0.0719992800072
   - Test - A: 25.99160056
   - Test - B: 20.1986534231

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

