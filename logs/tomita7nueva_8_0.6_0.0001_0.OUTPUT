 > Problema: tomita7nueva
 > Args:
   - Hidden size: 8
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.123150
 >> iter 2000, loss: 10.058682
 >> iter 3000, loss: 5.250839
 >> iter 4000, loss: 2.688254
 >> iter 5000, loss: 1.393194
 >> iter 6000, loss: 0.768167
 >> iter 7000, loss: 0.719016
 >> iter 8000, loss: 0.559605
 >> iter 9000, loss: 0.431008
 >> iter 10000, loss: 0.346215
   Number of active neurons: 6
 >> iter 11000, loss: 0.344567
 >> iter 12000, loss: 0.322206
 >> iter 13000, loss: 0.402947
 >> iter 14000, loss: 0.284433
 >> iter 15000, loss: 0.335807
 >> iter 16000, loss: 0.385158
 >> iter 17000, loss: 0.462932
 >> iter 18000, loss: 0.397028
 >> iter 19000, loss: 0.383786
 >> iter 20000, loss: 0.391410
   Number of active neurons: 6
 >> iter 21000, loss: 0.373091
 >> iter 22000, loss: 0.409512
 >> iter 23000, loss: 0.304033
 >> iter 24000, loss: 0.324313
 >> iter 25000, loss: 0.286712
 >> iter 26000, loss: 0.318816
 >> iter 27000, loss: 0.325903
 >> iter 28000, loss: 0.263307
 >> iter 29000, loss: 0.263316
 >> iter 30000, loss: 0.361837
   Number of active neurons: 6
 >> iter 31000, loss: 0.244794
 >> iter 32000, loss: 0.286980
 >> iter 33000, loss: 0.331025
 >> iter 34000, loss: 0.247813
 >> iter 35000, loss: 0.322889
 >> iter 36000, loss: 0.363427
 >> iter 37000, loss: 0.337641
 >> iter 38000, loss: 0.366107
 >> iter 39000, loss: 0.366475
 >> iter 40000, loss: 0.327684
   Number of active neurons: 6
 >> iter 41000, loss: 0.305608
 >> iter 42000, loss: 0.311994
 >> iter 43000, loss: 0.254393
 >> iter 44000, loss: 0.257926
 >> iter 45000, loss: 0.319016
 >> iter 46000, loss: 0.271198
 >> iter 47000, loss: 0.336689
 >> iter 48000, loss: 0.253333
 >> iter 49000, loss: 0.305856
 >> iter 50000, loss: 0.274651
   Number of active neurons: 6
 >> iter 51000, loss: 0.323644
 >> iter 52000, loss: 0.422152
 >> iter 53000, loss: 0.299339
 >> iter 54000, loss: 0.248298
 >> iter 55000, loss: 0.225949
 >> iter 56000, loss: 0.255154
 >> iter 57000, loss: 0.245686
 >> iter 58000, loss: 0.256832
 >> iter 59000, loss: 0.301296
 >> iter 60000, loss: 0.376513
   Number of active neurons: 6
 >> iter 61000, loss: 0.369866
 >> iter 62000, loss: 0.296040
 >> iter 63000, loss: 0.332933
 >> iter 64000, loss: 0.366329
 >> iter 65000, loss: 0.341930
 >> iter 66000, loss: 0.261827
 >> iter 67000, loss: 0.250794
 >> iter 68000, loss: 0.303700
 >> iter 69000, loss: 0.241857
 >> iter 70000, loss: 0.322056
   Number of active neurons: 6
 >> iter 71000, loss: 0.255957
 >> iter 72000, loss: 0.268532
 >> iter 73000, loss: 0.264659
 >> iter 74000, loss: 0.334603
 >> iter 75000, loss: 0.303422
 >> iter 76000, loss: 0.288101
 >> iter 77000, loss: 0.311144
 >> iter 78000, loss: 0.352693
 >> iter 79000, loss: 0.275965
 >> iter 80000, loss: 0.253686
   Number of active neurons: 6
 >> iter 81000, loss: 0.247248
 >> iter 82000, loss: 0.244984
 >> iter 83000, loss: 0.456566
 >> iter 84000, loss: 0.450439
 >> iter 85000, loss: 0.300155
 >> iter 86000, loss: 0.227335
 >> iter 87000, loss: 0.254729
 >> iter 88000, loss: 0.288832
 >> iter 89000, loss: 0.457232
 >> iter 90000, loss: 0.332830
   Number of active neurons: 6
 >> iter 91000, loss: 0.336419
 >> iter 92000, loss: 0.225925
 >> iter 93000, loss: 0.286862
 >> iter 94000, loss: 0.306601
 >> iter 95000, loss: 0.297340
 >> iter 96000, loss: 0.230723
 >> iter 97000, loss: 0.323102
 >> iter 98000, loss: 0.357917
 >> iter 99000, loss: 0.277258
 >> iter 100000, loss: 0.235715
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 17.343247
 >> iter 2000, loss: 10.355563
 >> iter 3000, loss: 9.931000
 >> iter 4000, loss: 7.295913
 >> iter 5000, loss: 5.605165
 >> iter 6000, loss: 3.596919
 >> iter 7000, loss: 2.184553
 >> iter 8000, loss: 1.380600
 >> iter 9000, loss: 0.962777
 >> iter 10000, loss: 0.783429
   Number of active neurons: 8
 >> iter 11000, loss: 0.746891
 >> iter 12000, loss: 0.497558
 >> iter 13000, loss: 0.442191
 >> iter 14000, loss: 0.378925
 >> iter 15000, loss: 0.368173
 >> iter 16000, loss: 0.318271
 >> iter 17000, loss: 0.270535
 >> iter 18000, loss: 0.329258
 >> iter 19000, loss: 0.277144
 >> iter 20000, loss: 0.224543
   Number of active neurons: 8
 >> iter 21000, loss: 0.296147
 >> iter 22000, loss: 0.360748
 >> iter 23000, loss: 0.357856
 >> iter 24000, loss: 0.258249
 >> iter 25000, loss: 0.201469
 >> iter 26000, loss: 0.260332
 >> iter 27000, loss: 0.265398
 >> iter 28000, loss: 0.223768
 >> iter 29000, loss: 0.225101
 >> iter 30000, loss: 0.361329
   Number of active neurons: 7
 >> iter 31000, loss: 0.360518
 >> iter 32000, loss: 0.298504
 >> iter 33000, loss: 0.228526
 >> iter 34000, loss: 0.167898
 >> iter 35000, loss: 0.194512
 >> iter 36000, loss: 0.254758
 >> iter 37000, loss: 0.248458
 >> iter 38000, loss: 0.308038
 >> iter 39000, loss: 0.329670
 >> iter 40000, loss: 0.291113
   Number of active neurons: 6
 >> iter 41000, loss: 0.240674
 >> iter 42000, loss: 0.284010
 >> iter 43000, loss: 0.277995
 >> iter 44000, loss: 0.282429
 >> iter 45000, loss: 0.247184
 >> iter 46000, loss: 0.235744
 >> iter 47000, loss: 0.278512
 >> iter 48000, loss: 0.471350
 >> iter 49000, loss: 0.335839
 >> iter 50000, loss: 0.393531
   Number of active neurons: 6
 >> iter 51000, loss: 0.243666
 >> iter 52000, loss: 0.179639
 >> iter 53000, loss: 0.232689
 >> iter 54000, loss: 0.263358
 >> iter 55000, loss: 0.304729
 >> iter 56000, loss: 0.289789
 >> iter 57000, loss: 0.328356
 >> iter 58000, loss: 0.431737
 >> iter 59000, loss: 0.342719
 >> iter 60000, loss: 0.316374
   Number of active neurons: 5
 >> iter 61000, loss: 0.331033
 >> iter 62000, loss: 0.325507
 >> iter 63000, loss: 0.295299
 >> iter 64000, loss: 0.228529
 >> iter 65000, loss: 0.397783
 >> iter 66000, loss: 0.361370
 >> iter 67000, loss: 0.289835
 >> iter 68000, loss: 0.361440
 >> iter 69000, loss: 0.314849
 >> iter 70000, loss: 0.342023
   Number of active neurons: 4
 >> iter 71000, loss: 0.412113
 >> iter 72000, loss: 0.385553
 >> iter 73000, loss: 0.257635
 >> iter 74000, loss: 0.274457
 >> iter 75000, loss: 0.332560
 >> iter 76000, loss: 0.276994
 >> iter 77000, loss: 0.275171
 >> iter 78000, loss: 0.313109
 >> iter 79000, loss: 0.432435
 >> iter 80000, loss: 0.390098
   Number of active neurons: 4
 >> iter 81000, loss: 0.314452
 >> iter 82000, loss: 0.402638
 >> iter 83000, loss: 0.299522
 >> iter 84000, loss: 0.308234
 >> iter 85000, loss: 0.401121
 >> iter 86000, loss: 0.446988
 >> iter 87000, loss: 0.334333
 >> iter 88000, loss: 0.329783
 >> iter 89000, loss: 0.286940
 >> iter 90000, loss: 0.279155
   Number of active neurons: 4
 >> iter 91000, loss: 0.248669
 >> iter 92000, loss: 0.323797
 >> iter 93000, loss: 0.307200
 >> iter 94000, loss: 0.283285
 >> iter 95000, loss: 0.274665
 >> iter 96000, loss: 0.256592
 >> iter 97000, loss: 0.361715
 >> iter 98000, loss: 0.388771
 >> iter 99000, loss: 0.335370
 >> iter 100000, loss: 0.270371
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.557427
 >> iter 2000, loss: 9.640869
 >> iter 3000, loss: 4.687633
 >> iter 4000, loss: 2.240008
 >> iter 5000, loss: 1.157682
 >> iter 6000, loss: 0.715172
 >> iter 7000, loss: 0.541214
 >> iter 8000, loss: 0.532940
 >> iter 9000, loss: 0.446775
 >> iter 10000, loss: 0.355625
   Number of active neurons: 7
 >> iter 11000, loss: 0.385015
 >> iter 12000, loss: 0.287824
 >> iter 13000, loss: 0.343944
 >> iter 14000, loss: 0.295201
 >> iter 15000, loss: 0.251133
 >> iter 16000, loss: 0.450448
 >> iter 17000, loss: 0.413727
 >> iter 18000, loss: 0.392047
 >> iter 19000, loss: 0.369934
 >> iter 20000, loss: 0.355868
   Number of active neurons: 6
 >> iter 21000, loss: 0.274278
 >> iter 22000, loss: 0.227656
 >> iter 23000, loss: 0.271543
 >> iter 24000, loss: 0.266797
 >> iter 25000, loss: 0.281948
 >> iter 26000, loss: 0.248171
 >> iter 27000, loss: 0.314639
 >> iter 28000, loss: 0.308294
 >> iter 29000, loss: 0.448124
 >> iter 30000, loss: 0.317023
   Number of active neurons: 5
 >> iter 31000, loss: 0.251586
 >> iter 32000, loss: 0.279121
 >> iter 33000, loss: 0.295719
 >> iter 34000, loss: 0.307350
 >> iter 35000, loss: 0.311520
 >> iter 36000, loss: 0.404611
 >> iter 37000, loss: 0.378677
 >> iter 38000, loss: 0.369610
 >> iter 39000, loss: 0.286988
 >> iter 40000, loss: 0.351504
   Number of active neurons: 5
 >> iter 41000, loss: 0.243722
 >> iter 42000, loss: 0.267883
 >> iter 43000, loss: 0.339309
 >> iter 44000, loss: 0.321211
 >> iter 45000, loss: 0.279663
 >> iter 46000, loss: 0.255436
 >> iter 47000, loss: 0.312249
 >> iter 48000, loss: 0.264168
 >> iter 49000, loss: 0.222910
 >> iter 50000, loss: 0.251512
   Number of active neurons: 5
 >> iter 51000, loss: 0.279103
 >> iter 52000, loss: 0.246811
 >> iter 53000, loss: 0.244886
 >> iter 54000, loss: 0.216348
 >> iter 55000, loss: 0.247244
 >> iter 56000, loss: 0.247377
 >> iter 57000, loss: 0.377738
 >> iter 58000, loss: 0.345724
 >> iter 59000, loss: 0.330890
 >> iter 60000, loss: 0.366229
   Number of active neurons: 5
 >> iter 61000, loss: 0.249949
 >> iter 62000, loss: 0.204652
 >> iter 63000, loss: 0.248106
 >> iter 64000, loss: 0.262521
 >> iter 65000, loss: 0.216962
 >> iter 66000, loss: 0.346675
 >> iter 67000, loss: 0.331721
 >> iter 68000, loss: 0.282433
 >> iter 69000, loss: 0.340440
 >> iter 70000, loss: 0.256276
   Number of active neurons: 5
 >> iter 71000, loss: 0.315188
 >> iter 72000, loss: 0.300074
 >> iter 73000, loss: 0.235336
 >> iter 74000, loss: 0.204698
 >> iter 75000, loss: 0.289683
 >> iter 76000, loss: 0.249457
 >> iter 77000, loss: 0.243555
 >> iter 78000, loss: 0.236678
 >> iter 79000, loss: 0.333003
 >> iter 80000, loss: 0.247896
   Number of active neurons: 4
 >> iter 81000, loss: 0.323852
 >> iter 82000, loss: 0.295167
 >> iter 83000, loss: 0.286420
 >> iter 84000, loss: 0.182402
 >> iter 85000, loss: 0.202377
 >> iter 86000, loss: 0.181040
 >> iter 87000, loss: 0.262366
 >> iter 88000, loss: 0.304204
 >> iter 89000, loss: 0.235027
 >> iter 90000, loss: 0.309030
   Number of active neurons: 4
 >> iter 91000, loss: 0.207275
 >> iter 92000, loss: 0.364923
 >> iter 93000, loss: 0.313957
 >> iter 94000, loss: 0.288794
 >> iter 95000, loss: 0.286464
 >> iter 96000, loss: 0.308004
 >> iter 97000, loss: 0.269900
 >> iter 98000, loss: 0.307103
 >> iter 99000, loss: 0.232197
 >> iter 100000, loss: 0.220715
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.528826
 >> iter 2000, loss: 13.012889
 >> iter 3000, loss: 9.630392
 >> iter 4000, loss: 7.346052
 >> iter 5000, loss: 4.051844
 >> iter 6000, loss: 1.838432
 >> iter 7000, loss: 1.095626
 >> iter 8000, loss: 0.644911
 >> iter 9000, loss: 0.397998
 >> iter 10000, loss: 0.315918
   Number of active neurons: 7
 >> iter 11000, loss: 0.395425
 >> iter 12000, loss: 0.419172
 >> iter 13000, loss: 0.385580
 >> iter 14000, loss: 0.254426
 >> iter 15000, loss: 0.298737
 >> iter 16000, loss: 0.242788
 >> iter 17000, loss: 0.248840
 >> iter 18000, loss: 0.301994
 >> iter 19000, loss: 0.293446
 >> iter 20000, loss: 0.263855
   Number of active neurons: 7
 >> iter 21000, loss: 0.190140
 >> iter 22000, loss: 0.276249
 >> iter 23000, loss: 0.314236
 >> iter 24000, loss: 0.329391
 >> iter 25000, loss: 0.319415
 >> iter 26000, loss: 0.414524
 >> iter 27000, loss: 0.489638
 >> iter 28000, loss: 0.442949
 >> iter 29000, loss: 0.320695
 >> iter 30000, loss: 0.336636
   Number of active neurons: 7
 >> iter 31000, loss: 0.250883
 >> iter 32000, loss: 0.254909
 >> iter 33000, loss: 0.314102
 >> iter 34000, loss: 0.281548
 >> iter 35000, loss: 0.271886
 >> iter 36000, loss: 0.224053
 >> iter 37000, loss: 0.303223
 >> iter 38000, loss: 0.214739
 >> iter 39000, loss: 0.174324
 >> iter 40000, loss: 0.217480
   Number of active neurons: 7
 >> iter 41000, loss: 0.386661
 >> iter 42000, loss: 0.373127
 >> iter 43000, loss: 0.295324
 >> iter 44000, loss: 0.250346
 >> iter 45000, loss: 0.244390
 >> iter 46000, loss: 0.251531
 >> iter 47000, loss: 0.158618
 >> iter 48000, loss: 0.205468
 >> iter 49000, loss: 0.191532
 >> iter 50000, loss: 0.217331
   Number of active neurons: 7
 >> iter 51000, loss: 0.302100
 >> iter 52000, loss: 0.287346
 >> iter 53000, loss: 0.259808
 >> iter 54000, loss: 0.235256
 >> iter 55000, loss: 0.211576
 >> iter 56000, loss: 0.251732
 >> iter 57000, loss: 0.246770
 >> iter 58000, loss: 0.186870
 >> iter 59000, loss: 0.161557
 >> iter 60000, loss: 0.250571
   Number of active neurons: 7
 >> iter 61000, loss: 0.269667
 >> iter 62000, loss: 0.389535
 >> iter 63000, loss: 0.400696
 >> iter 64000, loss: 0.295234
 >> iter 65000, loss: 0.257584
 >> iter 66000, loss: 0.251566
 >> iter 67000, loss: 0.255829
 >> iter 68000, loss: 0.373806
 >> iter 69000, loss: 0.282052
 >> iter 70000, loss: 0.278355
   Number of active neurons: 7
 >> iter 71000, loss: 0.272006
 >> iter 72000, loss: 0.277729
 >> iter 73000, loss: 0.210644
 >> iter 74000, loss: 0.239936
 >> iter 75000, loss: 0.243603
 >> iter 76000, loss: 0.255872
 >> iter 77000, loss: 0.238192
 >> iter 78000, loss: 0.181823
 >> iter 79000, loss: 0.255709
 >> iter 80000, loss: 0.397956
   Number of active neurons: 7
 >> iter 81000, loss: 0.314034
 >> iter 82000, loss: 0.243456
 >> iter 83000, loss: 0.232310
 >> iter 84000, loss: 0.214317
 >> iter 85000, loss: 0.170360
 >> iter 86000, loss: 0.204350
 >> iter 87000, loss: 0.169833
 >> iter 88000, loss: 0.213384
 >> iter 89000, loss: 0.318384
 >> iter 90000, loss: 0.341093
   Number of active neurons: 7
 >> iter 91000, loss: 0.349354
 >> iter 92000, loss: 0.344183
 >> iter 93000, loss: 0.254428
 >> iter 94000, loss: 0.237625
 >> iter 95000, loss: 0.200214
 >> iter 96000, loss: 0.209489
 >> iter 97000, loss: 0.213107
 >> iter 98000, loss: 0.220840
 >> iter 99000, loss: 0.252356
 >> iter 100000, loss: 0.268748
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.025707
 >> iter 2000, loss: 9.982416
 >> iter 3000, loss: 6.362115
 >> iter 4000, loss: 3.710200
 >> iter 5000, loss: 2.327644
 >> iter 6000, loss: 1.750549
 >> iter 7000, loss: 1.109494
 >> iter 8000, loss: 0.877121
 >> iter 9000, loss: 0.894586
 >> iter 10000, loss: 0.736620
   Number of active neurons: 6
 >> iter 11000, loss: 0.822490
 >> iter 12000, loss: 0.795001
 >> iter 13000, loss: 0.779713
 >> iter 14000, loss: 0.677114
 >> iter 15000, loss: 0.552165
 >> iter 16000, loss: 0.585954
 >> iter 17000, loss: 0.577800
 >> iter 18000, loss: 0.519997
 >> iter 19000, loss: 0.467744
 >> iter 20000, loss: 0.493086
   Number of active neurons: 6
 >> iter 21000, loss: 0.621102
 >> iter 22000, loss: 0.559362
 >> iter 23000, loss: 0.574644
 >> iter 24000, loss: 0.627346
 >> iter 25000, loss: 0.499957
 >> iter 26000, loss: 0.560110
 >> iter 27000, loss: 0.586604
 >> iter 28000, loss: 0.415757
 >> iter 29000, loss: 0.514148
 >> iter 30000, loss: 0.616443
   Number of active neurons: 6
 >> iter 31000, loss: 0.598480
 >> iter 32000, loss: 0.466987
 >> iter 33000, loss: 0.467246
 >> iter 34000, loss: 0.480952
 >> iter 35000, loss: 0.491660
 >> iter 36000, loss: 0.447841
 >> iter 37000, loss: 0.517216
 >> iter 38000, loss: 0.403322
 >> iter 39000, loss: 0.398703
 >> iter 40000, loss: 0.410743
   Number of active neurons: 6
 >> iter 41000, loss: 0.505351
 >> iter 42000, loss: 0.398823
 >> iter 43000, loss: 0.500201
 >> iter 44000, loss: 0.499664
 >> iter 45000, loss: 0.518296
 >> iter 46000, loss: 0.533628
 >> iter 47000, loss: 0.591410
 >> iter 48000, loss: 0.528033
 >> iter 49000, loss: 0.553282
 >> iter 50000, loss: 0.549891
   Number of active neurons: 5
 >> iter 51000, loss: 0.673591
 >> iter 52000, loss: 0.606269
 >> iter 53000, loss: 0.511812
 >> iter 54000, loss: 0.442000
 >> iter 55000, loss: 0.416148
 >> iter 56000, loss: 0.479255
 >> iter 57000, loss: 0.443064
 >> iter 58000, loss: 0.421960
 >> iter 59000, loss: 0.524183
 >> iter 60000, loss: 0.507094
   Number of active neurons: 5
 >> iter 61000, loss: 0.376875
 >> iter 62000, loss: 0.523370
 >> iter 63000, loss: 0.546203
 >> iter 64000, loss: 0.702301
 >> iter 65000, loss: 0.615730
 >> iter 66000, loss: 0.651332
 >> iter 67000, loss: 0.551270
 >> iter 68000, loss: 0.723215
 >> iter 69000, loss: 0.624570
 >> iter 70000, loss: 0.496984
   Number of active neurons: 5
 >> iter 71000, loss: 0.355090
 >> iter 72000, loss: 0.542752
 >> iter 73000, loss: 0.486256
 >> iter 74000, loss: 0.413060
 >> iter 75000, loss: 0.519764
 >> iter 76000, loss: 0.533209
 >> iter 77000, loss: 0.545915
 >> iter 78000, loss: 0.439230
 >> iter 79000, loss: 0.471182
 >> iter 80000, loss: 0.419781
   Number of active neurons: 5
 >> iter 81000, loss: 0.494033
 >> iter 82000, loss: 0.543865
 >> iter 83000, loss: 0.508534
 >> iter 84000, loss: 0.500466
 >> iter 85000, loss: 0.463153
 >> iter 86000, loss: 0.491890
 >> iter 87000, loss: 0.513814
 >> iter 88000, loss: 0.417015
 >> iter 89000, loss: 0.401761
 >> iter 90000, loss: 0.547383
   Number of active neurons: 5
 >> iter 91000, loss: 0.555669
 >> iter 92000, loss: 0.541626
 >> iter 93000, loss: 0.659104
 >> iter 94000, loss: 0.528111
 >> iter 95000, loss: 0.636369
 >> iter 96000, loss: 0.374271
 >> iter 97000, loss: 0.516265
 >> iter 98000, loss: 0.531394
 >> iter 99000, loss: 0.481795
 >> iter 100000, loss: 0.560665
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0019999600008
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 7.56616225585
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.335092
 >> iter 2000, loss: 11.838508
 >> iter 3000, loss: 7.447697
 >> iter 4000, loss: 4.167677
 >> iter 5000, loss: 2.926675
 >> iter 6000, loss: 1.746436
 >> iter 7000, loss: 1.342581
 >> iter 8000, loss: 0.910812
 >> iter 9000, loss: 0.843796
 >> iter 10000, loss: 0.785141
   Number of active neurons: 7
 >> iter 11000, loss: 0.612497
 >> iter 12000, loss: 0.610084
 >> iter 13000, loss: 0.698093
 >> iter 14000, loss: 0.481636
 >> iter 15000, loss: 0.643930
 >> iter 16000, loss: 0.670488
 >> iter 17000, loss: 1.008697
 >> iter 18000, loss: 0.658142
 >> iter 19000, loss: 0.589578
 >> iter 20000, loss: 0.560920
   Number of active neurons: 6
 >> iter 21000, loss: 0.473094
 >> iter 22000, loss: 0.381032
 >> iter 23000, loss: 0.290120
 >> iter 24000, loss: 0.360315
 >> iter 25000, loss: 0.301879
 >> iter 26000, loss: 0.327013
 >> iter 27000, loss: 0.474197
 >> iter 28000, loss: 0.415507
 >> iter 29000, loss: 0.430382
 >> iter 30000, loss: 0.489520
   Number of active neurons: 5
 >> iter 31000, loss: 0.520529
 >> iter 32000, loss: 0.406939
 >> iter 33000, loss: 0.461507
 >> iter 34000, loss: 0.407904
 >> iter 35000, loss: 0.496740
 >> iter 36000, loss: 0.405141
 >> iter 37000, loss: 0.280792
 >> iter 38000, loss: 0.292835
 >> iter 39000, loss: 0.326867
 >> iter 40000, loss: 0.383216
   Number of active neurons: 5
 >> iter 41000, loss: 0.376008
 >> iter 42000, loss: 0.385673
 >> iter 43000, loss: 0.426279
 >> iter 44000, loss: 0.330767
 >> iter 45000, loss: 0.383812
 >> iter 46000, loss: 0.450423
 >> iter 47000, loss: 0.359822
 >> iter 48000, loss: 0.335622
 >> iter 49000, loss: 0.431790
 >> iter 50000, loss: 0.408759
   Number of active neurons: 5
 >> iter 51000, loss: 0.436524
 >> iter 52000, loss: 0.406331
 >> iter 53000, loss: 0.406252
 >> iter 54000, loss: 0.425387
 >> iter 55000, loss: 0.401499
 >> iter 56000, loss: 0.420154
 >> iter 57000, loss: 0.409154
 >> iter 58000, loss: 0.280392
 >> iter 59000, loss: 0.356091
 >> iter 60000, loss: 0.313057
   Number of active neurons: 5
 >> iter 61000, loss: 0.340551
 >> iter 62000, loss: 0.429164
 >> iter 63000, loss: 0.478156
 >> iter 64000, loss: 0.504615
 >> iter 65000, loss: 0.425080
 >> iter 66000, loss: 0.426547
 >> iter 67000, loss: 0.357970
 >> iter 68000, loss: 0.417524
 >> iter 69000, loss: 0.475733
 >> iter 70000, loss: 0.508244
   Number of active neurons: 5
 >> iter 71000, loss: 0.449135
 >> iter 72000, loss: 0.454985
 >> iter 73000, loss: 0.506499
 >> iter 74000, loss: 0.439292
 >> iter 75000, loss: 0.486964
 >> iter 76000, loss: 0.492956
 >> iter 77000, loss: 0.393082
 >> iter 78000, loss: 0.445746
 >> iter 79000, loss: 0.343183
 >> iter 80000, loss: 0.380467
   Number of active neurons: 5
 >> iter 81000, loss: 0.429477
 >> iter 82000, loss: 0.277218
 >> iter 83000, loss: 0.306818
 >> iter 84000, loss: 0.363017
 >> iter 85000, loss: 0.364325
 >> iter 86000, loss: 0.339112
 >> iter 87000, loss: 0.433267
 >> iter 88000, loss: 0.422527
 >> iter 89000, loss: 0.443804
 >> iter 90000, loss: 0.393527
   Number of active neurons: 5
 >> iter 91000, loss: 0.313093
 >> iter 92000, loss: 0.552764
 >> iter 93000, loss: 0.475219
 >> iter 94000, loss: 0.379367
 >> iter 95000, loss: 0.483011
 >> iter 96000, loss: 0.351532
 >> iter 97000, loss: 0.387791
 >> iter 98000, loss: 0.499737
 >> iter 99000, loss: 0.443914
 >> iter 100000, loss: 0.364697
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.281565
 >> iter 2000, loss: 11.587784
 >> iter 3000, loss: 8.133324
 >> iter 4000, loss: 5.084113
 >> iter 5000, loss: 3.229736
 >> iter 6000, loss: 1.920160
 >> iter 7000, loss: 1.147963
 >> iter 8000, loss: 1.014611
 >> iter 9000, loss: 1.000370
 >> iter 10000, loss: 0.927244
   Number of active neurons: 7
 >> iter 11000, loss: 0.801966
 >> iter 12000, loss: 0.606805
 >> iter 13000, loss: 0.610198
 >> iter 14000, loss: 0.923071
 >> iter 15000, loss: 0.789866
 >> iter 16000, loss: 0.596589
 >> iter 17000, loss: 0.677198
 >> iter 18000, loss: 0.606208
 >> iter 19000, loss: 0.719896
 >> iter 20000, loss: 0.726329
   Number of active neurons: 6
 >> iter 21000, loss: 0.608241
 >> iter 22000, loss: 0.776591
 >> iter 23000, loss: 0.553611
 >> iter 24000, loss: 0.547264
 >> iter 25000, loss: 0.494910
 >> iter 26000, loss: 0.541292
 >> iter 27000, loss: 0.439057
 >> iter 28000, loss: 0.508657
 >> iter 29000, loss: 0.554641
 >> iter 30000, loss: 0.561638
   Number of active neurons: 6
 >> iter 31000, loss: 0.330252
 >> iter 32000, loss: 0.251928
 >> iter 33000, loss: 0.272876
 >> iter 34000, loss: 0.377529
 >> iter 35000, loss: 0.464419
 >> iter 36000, loss: 0.494260
 >> iter 37000, loss: 0.397168
 >> iter 38000, loss: 0.545842
 >> iter 39000, loss: 0.558439
 >> iter 40000, loss: 0.561992
   Number of active neurons: 6
 >> iter 41000, loss: 0.555393
 >> iter 42000, loss: 0.763294
 >> iter 43000, loss: 0.747898
 >> iter 44000, loss: 0.601412
 >> iter 45000, loss: 0.484621
 >> iter 46000, loss: 0.491071
 >> iter 47000, loss: 0.502048
 >> iter 48000, loss: 0.643763
 >> iter 49000, loss: 0.596820
 >> iter 50000, loss: 0.442391
   Number of active neurons: 6
 >> iter 51000, loss: 0.528780
 >> iter 52000, loss: 0.449831
 >> iter 53000, loss: 0.545755
 >> iter 54000, loss: 0.507289
 >> iter 55000, loss: 0.601316
 >> iter 56000, loss: 0.586300
 >> iter 57000, loss: 0.526837
 >> iter 58000, loss: 0.519985
 >> iter 59000, loss: 0.628746
 >> iter 60000, loss: 0.635684
   Number of active neurons: 8
 >> iter 61000, loss: 0.431536
 >> iter 62000, loss: 0.614098
 >> iter 63000, loss: 0.440681
 >> iter 64000, loss: 0.529829
 >> iter 65000, loss: 0.595050
 >> iter 66000, loss: 0.548894
 >> iter 67000, loss: 0.520421
 >> iter 68000, loss: 0.418048
 >> iter 69000, loss: 0.414223
 >> iter 70000, loss: 0.457898
   Number of active neurons: 6
 >> iter 71000, loss: 0.573437
 >> iter 72000, loss: 0.744261
 >> iter 73000, loss: 0.516724
 >> iter 74000, loss: 0.586069
 >> iter 75000, loss: 0.566905
 >> iter 76000, loss: 0.513799
 >> iter 77000, loss: 0.517563
 >> iter 78000, loss: 0.484083
 >> iter 79000, loss: 0.603856
 >> iter 80000, loss: 0.601072
   Number of active neurons: 6
 >> iter 81000, loss: 0.766855
 >> iter 82000, loss: 0.503204
 >> iter 83000, loss: 0.548021
 >> iter 84000, loss: 0.495958
 >> iter 85000, loss: 0.612890
 >> iter 86000, loss: 0.518449
 >> iter 87000, loss: 0.555758
 >> iter 88000, loss: 0.562584
 >> iter 89000, loss: 0.416482
 >> iter 90000, loss: 0.499651
   Number of active neurons: 6
 >> iter 91000, loss: 0.536348
 >> iter 92000, loss: 0.539838
 >> iter 93000, loss: 0.458112
 >> iter 94000, loss: 0.440292
 >> iter 95000, loss: 0.390251
 >> iter 96000, loss: 0.299625
 >> iter 97000, loss: 0.375930
 >> iter 98000, loss: 0.337536
 >> iter 99000, loss: 0.434276
 >> iter 100000, loss: 0.457289
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 10.6859542697
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 17.773441
 >> iter 2000, loss: 11.972251
 >> iter 3000, loss: 8.149217
 >> iter 4000, loss: 4.985391
 >> iter 5000, loss: 2.901913
 >> iter 6000, loss: 1.769312
 >> iter 7000, loss: 1.492239
 >> iter 8000, loss: 1.076093
 >> iter 9000, loss: 1.174771
 >> iter 10000, loss: 0.836284
   Number of active neurons: 7
 >> iter 11000, loss: 0.783045
 >> iter 12000, loss: 0.710388
 >> iter 13000, loss: 0.847249
 >> iter 14000, loss: 0.726914
 >> iter 15000, loss: 0.624555
 >> iter 16000, loss: 0.830258
 >> iter 17000, loss: 0.835712
 >> iter 18000, loss: 0.877924
 >> iter 19000, loss: 0.808422
 >> iter 20000, loss: 0.708359
   Number of active neurons: 7
 >> iter 21000, loss: 0.852672
 >> iter 22000, loss: 0.701638
 >> iter 23000, loss: 0.981762
 >> iter 24000, loss: 0.870952
 >> iter 25000, loss: 0.729070
 >> iter 26000, loss: 0.714758
 >> iter 27000, loss: 0.592626
 >> iter 28000, loss: 0.726520
 >> iter 29000, loss: 0.842455
 >> iter 30000, loss: 0.753648
   Number of active neurons: 6
 >> iter 31000, loss: 1.035541
 >> iter 32000, loss: 0.777166
 >> iter 33000, loss: 0.907299
 >> iter 34000, loss: 0.662162
 >> iter 35000, loss: 0.918318
 >> iter 36000, loss: 0.890260
 >> iter 37000, loss: 0.745943
 >> iter 38000, loss: 0.787500
 >> iter 39000, loss: 0.606914
 >> iter 40000, loss: 0.865161
   Number of active neurons: 6
 >> iter 41000, loss: 1.081038
 >> iter 42000, loss: 0.727096
 >> iter 43000, loss: 0.758783
 >> iter 44000, loss: 0.749982
 >> iter 45000, loss: 0.656185
 >> iter 46000, loss: 0.716604
 >> iter 47000, loss: 0.939145
 >> iter 48000, loss: 0.692879
 >> iter 49000, loss: 0.785958
 >> iter 50000, loss: 0.817365
   Number of active neurons: 6
 >> iter 51000, loss: 0.762791
 >> iter 52000, loss: 0.812461
 >> iter 53000, loss: 0.819870
 >> iter 54000, loss: 0.823761
 >> iter 55000, loss: 0.855597
 >> iter 56000, loss: 0.759452
 >> iter 57000, loss: 0.895228
 >> iter 58000, loss: 0.921323
 >> iter 59000, loss: 0.956074
 >> iter 60000, loss: 0.777317
   Number of active neurons: 6
 >> iter 61000, loss: 0.701550
 >> iter 62000, loss: 0.749081
 >> iter 63000, loss: 0.766452
 >> iter 64000, loss: 0.708860
 >> iter 65000, loss: 0.741204
 >> iter 66000, loss: 0.786677
 >> iter 67000, loss: 0.840798
 >> iter 68000, loss: 0.831666
 >> iter 69000, loss: 0.785723
 >> iter 70000, loss: 0.703018
   Number of active neurons: 6
 >> iter 71000, loss: 0.675752
 >> iter 72000, loss: 0.615273
 >> iter 73000, loss: 0.698347
 >> iter 74000, loss: 0.686971
 >> iter 75000, loss: 0.761645
 >> iter 76000, loss: 0.673697
 >> iter 77000, loss: 0.952838
 >> iter 78000, loss: 0.838425
 >> iter 79000, loss: 0.821010
 >> iter 80000, loss: 0.672967
   Number of active neurons: 5
 >> iter 81000, loss: 0.663260
 >> iter 82000, loss: 0.664099
 >> iter 83000, loss: 0.740636
 >> iter 84000, loss: 0.757018
 >> iter 85000, loss: 0.742932
 >> iter 86000, loss: 0.633781
 >> iter 87000, loss: 0.723298
 >> iter 88000, loss: 0.719784
 >> iter 89000, loss: 0.734356
 >> iter 90000, loss: 0.733378
   Number of active neurons: 5
 >> iter 91000, loss: 0.822462
 >> iter 92000, loss: 0.819073
 >> iter 93000, loss: 0.757696
 >> iter 94000, loss: 0.671103
 >> iter 95000, loss: 0.596092
 >> iter 96000, loss: 0.466781
 >> iter 97000, loss: 0.701212
 >> iter 98000, loss: 0.710438
 >> iter 99000, loss: 0.751990
 >> iter 100000, loss: 0.704817
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.00599988000241
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 24.4117058863
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.537460
 >> iter 2000, loss: 9.626140
 >> iter 3000, loss: 5.621853
 >> iter 4000, loss: 3.176608
 >> iter 5000, loss: 2.298363
 >> iter 6000, loss: 1.357748
 >> iter 7000, loss: 1.081924
 >> iter 8000, loss: 0.939689
 >> iter 9000, loss: 0.737096
 >> iter 10000, loss: 0.843098
   Number of active neurons: 6
 >> iter 11000, loss: 0.690163
 >> iter 12000, loss: 0.639318
 >> iter 13000, loss: 0.639480
 >> iter 14000, loss: 0.560658
 >> iter 15000, loss: 0.708203
 >> iter 16000, loss: 0.529952
 >> iter 17000, loss: 0.411609
 >> iter 18000, loss: 0.835091
 >> iter 19000, loss: 0.707722
 >> iter 20000, loss: 0.492364
   Number of active neurons: 6
 >> iter 21000, loss: 0.711769
 >> iter 22000, loss: 0.677098
 >> iter 23000, loss: 0.673926
 >> iter 24000, loss: 0.807960
 >> iter 25000, loss: 0.739042
 >> iter 26000, loss: 0.599344
 >> iter 27000, loss: 0.605930
 >> iter 28000, loss: 0.544589
 >> iter 29000, loss: 0.715865
 >> iter 30000, loss: 0.636896
   Number of active neurons: 6
 >> iter 31000, loss: 0.507438
 >> iter 32000, loss: 0.596918
 >> iter 33000, loss: 0.765476
 >> iter 34000, loss: 0.785995
 >> iter 35000, loss: 0.641155
 >> iter 36000, loss: 0.561486
 >> iter 37000, loss: 0.422318
 >> iter 38000, loss: 0.432908
 >> iter 39000, loss: 0.429000
 >> iter 40000, loss: 0.501930
   Number of active neurons: 6
 >> iter 41000, loss: 0.517511
 >> iter 42000, loss: 0.714735
 >> iter 43000, loss: 0.776679
 >> iter 44000, loss: 0.704711
 >> iter 45000, loss: 0.594356
 >> iter 46000, loss: 0.482289
 >> iter 47000, loss: 0.400498
 >> iter 48000, loss: 0.386256
 >> iter 49000, loss: 0.483082
 >> iter 50000, loss: 0.430864
   Number of active neurons: 6
 >> iter 51000, loss: 0.493815
 >> iter 52000, loss: 0.452789
 >> iter 53000, loss: 0.586894
 >> iter 54000, loss: 0.694215
 >> iter 55000, loss: 0.581536
 >> iter 56000, loss: 0.610563
 >> iter 57000, loss: 0.788726
 >> iter 58000, loss: 0.657197
 >> iter 59000, loss: 0.500446
 >> iter 60000, loss: 0.532507
   Number of active neurons: 6
 >> iter 61000, loss: 0.622058
 >> iter 62000, loss: 0.501629
 >> iter 63000, loss: 0.527283
 >> iter 64000, loss: 0.571299
 >> iter 65000, loss: 0.489069
 >> iter 66000, loss: 0.582684
 >> iter 67000, loss: 0.584487
 >> iter 68000, loss: 0.548672
 >> iter 69000, loss: 0.534329
 >> iter 70000, loss: 0.692356
   Number of active neurons: 6
 >> iter 71000, loss: 0.683200
 >> iter 72000, loss: 0.680180
 >> iter 73000, loss: 0.747037
 >> iter 74000, loss: 0.614746
 >> iter 75000, loss: 0.587018
 >> iter 76000, loss: 0.499129
 >> iter 77000, loss: 0.528685
 >> iter 78000, loss: 0.476530
 >> iter 79000, loss: 0.473462
 >> iter 80000, loss: 0.702663
   Number of active neurons: 4
 >> iter 81000, loss: 0.608284
 >> iter 82000, loss: 0.633296
 >> iter 83000, loss: 0.630474
 >> iter 84000, loss: 0.625677
 >> iter 85000, loss: 0.777437
 >> iter 86000, loss: 0.791589
 >> iter 87000, loss: 0.689845
 >> iter 88000, loss: 0.564090
 >> iter 89000, loss: 0.394311
 >> iter 90000, loss: 0.495198
   Number of active neurons: 4
 >> iter 91000, loss: 0.388022
 >> iter 92000, loss: 0.457471
 >> iter 93000, loss: 0.604858
 >> iter 94000, loss: 0.608746
 >> iter 95000, loss: 0.505795
 >> iter 96000, loss: 0.583623
 >> iter 97000, loss: 0.637148
 >> iter 98000, loss: 0.582564
 >> iter 99000, loss: 0.607205
 >> iter 100000, loss: 0.725319
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.619779
 >> iter 2000, loss: 11.259671
 >> iter 3000, loss: 7.484978
 >> iter 4000, loss: 3.796247
 >> iter 5000, loss: 1.864347
 >> iter 6000, loss: 1.086208
 >> iter 7000, loss: 0.751719
 >> iter 8000, loss: 0.468814
 >> iter 9000, loss: 0.359443
 >> iter 10000, loss: 0.333679
   Number of active neurons: 5
 >> iter 11000, loss: 0.407065
 >> iter 12000, loss: 0.261248
 >> iter 13000, loss: 0.307583
 >> iter 14000, loss: 0.414416
 >> iter 15000, loss: 0.376395
 >> iter 16000, loss: 0.402712
 >> iter 17000, loss: 0.376035
 >> iter 18000, loss: 0.395822
 >> iter 19000, loss: 0.331776
 >> iter 20000, loss: 0.418878
   Number of active neurons: 5
 >> iter 21000, loss: 0.378489
 >> iter 22000, loss: 0.308015
 >> iter 23000, loss: 0.331129
 >> iter 24000, loss: 0.343601
 >> iter 25000, loss: 0.405280
 >> iter 26000, loss: 0.414548
 >> iter 27000, loss: 0.499334
 >> iter 28000, loss: 0.456511
 >> iter 29000, loss: 0.390765
 >> iter 30000, loss: 0.439034
   Number of active neurons: 5
 >> iter 31000, loss: 0.375624
 >> iter 32000, loss: 0.380282
 >> iter 33000, loss: 0.416539
 >> iter 34000, loss: 0.348799
 >> iter 35000, loss: 0.450790
 >> iter 36000, loss: 0.364969
 >> iter 37000, loss: 0.329255
 >> iter 38000, loss: 0.297325
 >> iter 39000, loss: 0.372306
 >> iter 40000, loss: 0.327534
   Number of active neurons: 5
 >> iter 41000, loss: 0.264661
 >> iter 42000, loss: 0.360907
 >> iter 43000, loss: 0.351503
 >> iter 44000, loss: 0.539258
 >> iter 45000, loss: 0.512637
 >> iter 46000, loss: 0.466868
 >> iter 47000, loss: 0.402781
 >> iter 48000, loss: 0.328957
 >> iter 49000, loss: 0.386689
 >> iter 50000, loss: 0.356273
   Number of active neurons: 4
 >> iter 51000, loss: 0.290662
 >> iter 52000, loss: 0.271797
 >> iter 53000, loss: 0.278055
 >> iter 54000, loss: 0.265245
 >> iter 55000, loss: 0.237849
 >> iter 56000, loss: 0.376404
 >> iter 57000, loss: 0.357665
 >> iter 58000, loss: 0.328360
 >> iter 59000, loss: 0.499364
 >> iter 60000, loss: 0.429210
   Number of active neurons: 4
 >> iter 61000, loss: 0.379603
 >> iter 62000, loss: 0.463644
 >> iter 63000, loss: 0.376339
 >> iter 64000, loss: 0.297527
 >> iter 65000, loss: 0.345369
 >> iter 66000, loss: 0.299137
 >> iter 67000, loss: 0.324968
 >> iter 68000, loss: 0.438111
 >> iter 69000, loss: 0.386913
 >> iter 70000, loss: 0.407118
   Number of active neurons: 4
 >> iter 71000, loss: 0.437878
 >> iter 72000, loss: 0.505904
 >> iter 73000, loss: 0.502601
 >> iter 74000, loss: 0.358615
 >> iter 75000, loss: 0.392113
 >> iter 76000, loss: 0.359727
 >> iter 77000, loss: 0.304419
 >> iter 78000, loss: 0.288327
 >> iter 79000, loss: 0.332769
 >> iter 80000, loss: 0.321286
   Number of active neurons: 4
 >> iter 81000, loss: 0.393214
 >> iter 82000, loss: 0.359140
 >> iter 83000, loss: 0.478531
 >> iter 84000, loss: 0.447770
 >> iter 85000, loss: 0.529126
 >> iter 86000, loss: 0.423147
 >> iter 87000, loss: 0.506380
 >> iter 88000, loss: 0.462012
 >> iter 89000, loss: 0.455297
 >> iter 90000, loss: 0.552685
   Number of active neurons: 4
 >> iter 91000, loss: 0.553970
 >> iter 92000, loss: 0.421664
 >> iter 93000, loss: 0.467952
 >> iter 94000, loss: 0.374994
 >> iter 95000, loss: 0.352220
 >> iter 96000, loss: 0.397664
 >> iter 97000, loss: 0.470772
 >> iter 98000, loss: 0.457215
 >> iter 99000, loss: 0.476333
 >> iter 100000, loss: 0.316448
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.302920
 >> iter 2000, loss: 11.125172
 >> iter 3000, loss: 6.819006
 >> iter 4000, loss: 3.690317
 >> iter 5000, loss: 2.019478
 >> iter 6000, loss: 1.409198
 >> iter 7000, loss: 1.190802
 >> iter 8000, loss: 1.045783
 >> iter 9000, loss: 0.840951
 >> iter 10000, loss: 0.595014
   Number of active neurons: 6
 >> iter 11000, loss: 0.644058
 >> iter 12000, loss: 0.570348
 >> iter 13000, loss: 0.587405
 >> iter 14000, loss: 0.490233
 >> iter 15000, loss: 0.612926
 >> iter 16000, loss: 0.512800
 >> iter 17000, loss: 0.425553
 >> iter 18000, loss: 0.496706
 >> iter 19000, loss: 0.587437
 >> iter 20000, loss: 0.581830
   Number of active neurons: 5
 >> iter 21000, loss: 0.672886
 >> iter 22000, loss: 0.599387
 >> iter 23000, loss: 0.619454
 >> iter 24000, loss: 0.442706
 >> iter 25000, loss: 0.500693
 >> iter 26000, loss: 0.781135
 >> iter 27000, loss: 0.600241
 >> iter 28000, loss: 0.573864
 >> iter 29000, loss: 0.546371
 >> iter 30000, loss: 0.585371
   Number of active neurons: 5
 >> iter 31000, loss: 0.588128
 >> iter 32000, loss: 0.423805
 >> iter 33000, loss: 0.509673
 >> iter 34000, loss: 0.569921
 >> iter 35000, loss: 0.633680
 >> iter 36000, loss: 0.601686
 >> iter 37000, loss: 0.622258
 >> iter 38000, loss: 0.471551
 >> iter 39000, loss: 0.524644
 >> iter 40000, loss: 0.487082
   Number of active neurons: 5
 >> iter 41000, loss: 0.542458
 >> iter 42000, loss: 0.629573
 >> iter 43000, loss: 0.628497
 >> iter 44000, loss: 0.588627
 >> iter 45000, loss: 0.551324
 >> iter 46000, loss: 0.457766
 >> iter 47000, loss: 0.537547
 >> iter 48000, loss: 0.486447
 >> iter 49000, loss: 0.547679
 >> iter 50000, loss: 0.585801
   Number of active neurons: 5
 >> iter 51000, loss: 0.556027
 >> iter 52000, loss: 0.499959
 >> iter 53000, loss: 0.476676
 >> iter 54000, loss: 0.481294
 >> iter 55000, loss: 0.499947
 >> iter 56000, loss: 0.547540
 >> iter 57000, loss: 0.482959
 >> iter 58000, loss: 0.510010
 >> iter 59000, loss: 0.666495
 >> iter 60000, loss: 0.518332
   Number of active neurons: 4
 >> iter 61000, loss: 0.688525
 >> iter 62000, loss: 0.581298
 >> iter 63000, loss: 0.713872
 >> iter 64000, loss: 0.670169
 >> iter 65000, loss: 0.485384
 >> iter 66000, loss: 0.501409
 >> iter 67000, loss: 0.629390
 >> iter 68000, loss: 0.498957
 >> iter 69000, loss: 0.560464
 >> iter 70000, loss: 0.472081
   Number of active neurons: 4
 >> iter 71000, loss: 0.512578
 >> iter 72000, loss: 0.640895
 >> iter 73000, loss: 0.745912
 >> iter 74000, loss: 0.803829
 >> iter 75000, loss: 0.678756
 >> iter 76000, loss: 0.622873
 >> iter 77000, loss: 0.616220
 >> iter 78000, loss: 0.609714
 >> iter 79000, loss: 0.693812
 >> iter 80000, loss: 0.630770
   Number of active neurons: 4
 >> iter 81000, loss: 0.602013
 >> iter 82000, loss: 0.540669
 >> iter 83000, loss: 0.472170
 >> iter 84000, loss: 0.548831
 >> iter 85000, loss: 0.605018
 >> iter 86000, loss: 0.484189
 >> iter 87000, loss: 0.476649
 >> iter 88000, loss: 0.520685
 >> iter 89000, loss: 0.552845
 >> iter 90000, loss: 0.542877
   Number of active neurons: 4
 >> iter 91000, loss: 0.656588
 >> iter 92000, loss: 0.697641
 >> iter 93000, loss: 0.523619
 >> iter 94000, loss: 0.524103
 >> iter 95000, loss: 0.646805
 >> iter 96000, loss: 0.571070
 >> iter 97000, loss: 0.567652
 >> iter 98000, loss: 0.471694
 >> iter 99000, loss: 0.475696
 >> iter 100000, loss: 0.721681
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.610777
 >> iter 2000, loss: 11.406989
 >> iter 3000, loss: 7.742583
 >> iter 4000, loss: 4.624654
 >> iter 5000, loss: 3.469652
 >> iter 6000, loss: 2.773214
 >> iter 7000, loss: 2.422735
 >> iter 8000, loss: 2.001501
 >> iter 9000, loss: 2.242462
 >> iter 10000, loss: 1.816794
   Number of active neurons: 7
 >> iter 11000, loss: 1.386723
 >> iter 12000, loss: 1.163167
 >> iter 13000, loss: 1.171969
 >> iter 14000, loss: 1.477061
 >> iter 15000, loss: 1.664313
 >> iter 16000, loss: 1.348911
 >> iter 17000, loss: 1.099013
 >> iter 18000, loss: 0.865955
 >> iter 19000, loss: 0.562701
 >> iter 20000, loss: 0.402778
   Number of active neurons: 7
 >> iter 21000, loss: 0.323723
 >> iter 22000, loss: 0.241587
 >> iter 23000, loss: 0.174587
 >> iter 24000, loss: 0.146423
 >> iter 25000, loss: 0.199266
 >> iter 26000, loss: 0.181926
 >> iter 27000, loss: 0.231576
 >> iter 28000, loss: 0.175879
 >> iter 29000, loss: 0.205057
 >> iter 30000, loss: 0.232791
   Number of active neurons: 6
 >> iter 31000, loss: 0.271138
 >> iter 32000, loss: 0.256326
 >> iter 33000, loss: 0.186971
 >> iter 34000, loss: 0.244563
 >> iter 35000, loss: 0.207519
 >> iter 36000, loss: 0.249938
 >> iter 37000, loss: 0.287287
 >> iter 38000, loss: 0.286109
 >> iter 39000, loss: 0.266426
 >> iter 40000, loss: 0.314272
   Number of active neurons: 5
 >> iter 41000, loss: 0.320989
 >> iter 42000, loss: 0.273109
 >> iter 43000, loss: 0.311472
 >> iter 44000, loss: 0.384834
 >> iter 45000, loss: 0.244839
 >> iter 46000, loss: 0.313631
 >> iter 47000, loss: 0.304851
 >> iter 48000, loss: 0.337987
 >> iter 49000, loss: 0.292057
 >> iter 50000, loss: 0.368388
   Number of active neurons: 4
 >> iter 51000, loss: 0.292217
 >> iter 52000, loss: 0.299959
 >> iter 53000, loss: 0.332403
 >> iter 54000, loss: 0.290845
 >> iter 55000, loss: 0.247230
 >> iter 56000, loss: 0.282178
 >> iter 57000, loss: 0.215099
 >> iter 58000, loss: 0.311529
 >> iter 59000, loss: 0.222401
 >> iter 60000, loss: 0.247745
   Number of active neurons: 4
 >> iter 61000, loss: 0.268141
 >> iter 62000, loss: 0.174668
 >> iter 63000, loss: 0.278691
 >> iter 64000, loss: 0.271244
 >> iter 65000, loss: 0.220402
 >> iter 66000, loss: 0.240183
 >> iter 67000, loss: 0.320237
 >> iter 68000, loss: 0.331973
 >> iter 69000, loss: 0.283938
 >> iter 70000, loss: 0.326600
   Number of active neurons: 4
 >> iter 71000, loss: 0.279700
 >> iter 72000, loss: 0.239351
 >> iter 73000, loss: 0.311069
 >> iter 74000, loss: 0.318306
 >> iter 75000, loss: 0.282543
 >> iter 76000, loss: 0.304065
 >> iter 77000, loss: 0.267331
 >> iter 78000, loss: 0.261044
 >> iter 79000, loss: 0.241684
 >> iter 80000, loss: 0.213005
   Number of active neurons: 4
 >> iter 81000, loss: 0.203223
 >> iter 82000, loss: 0.198037
 >> iter 83000, loss: 0.239070
 >> iter 84000, loss: 0.219004
 >> iter 85000, loss: 0.278790
 >> iter 86000, loss: 0.336117
 >> iter 87000, loss: 0.326192
 >> iter 88000, loss: 0.305058
 >> iter 89000, loss: 0.267993
 >> iter 90000, loss: 0.283542
   Number of active neurons: 4
 >> iter 91000, loss: 0.273971
 >> iter 92000, loss: 0.245406
 >> iter 93000, loss: 0.292693
 >> iter 94000, loss: 0.249487
 >> iter 95000, loss: 0.310978
 >> iter 96000, loss: 0.218769
 >> iter 97000, loss: 0.314998
 >> iter 98000, loss: 0.266064
 >> iter 99000, loss: 0.293569
 >> iter 100000, loss: 0.268208
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.254122
 >> iter 2000, loss: 12.974973
 >> iter 3000, loss: 9.024950
 >> iter 4000, loss: 5.421002
 >> iter 5000, loss: 2.663474
 >> iter 6000, loss: 1.414193
 >> iter 7000, loss: 0.729033
 >> iter 8000, loss: 0.356019
 >> iter 9000, loss: 0.329376
 >> iter 10000, loss: 0.296238
   Number of active neurons: 6
 >> iter 11000, loss: 0.245775
 >> iter 12000, loss: 0.198581
 >> iter 13000, loss: 0.194073
 >> iter 14000, loss: 0.285754
 >> iter 15000, loss: 0.306089
 >> iter 16000, loss: 0.159781
 >> iter 17000, loss: 0.184634
 >> iter 18000, loss: 0.240829
 >> iter 19000, loss: 0.280181
 >> iter 20000, loss: 0.218868
   Number of active neurons: 5
 >> iter 21000, loss: 0.216406
 >> iter 22000, loss: 0.206863
 >> iter 23000, loss: 0.325510
 >> iter 24000, loss: 0.310329
 >> iter 25000, loss: 0.316157
 >> iter 26000, loss: 0.301887
 >> iter 27000, loss: 0.382755
 >> iter 28000, loss: 0.437319
 >> iter 29000, loss: 0.422698
 >> iter 30000, loss: 0.313294
   Number of active neurons: 6
 >> iter 31000, loss: 0.219053
 >> iter 32000, loss: 0.339043
 >> iter 33000, loss: 0.284405
 >> iter 34000, loss: 0.279833
 >> iter 35000, loss: 0.374828
 >> iter 36000, loss: 0.279551
 >> iter 37000, loss: 0.295242
 >> iter 38000, loss: 0.242881
 >> iter 39000, loss: 0.275068
 >> iter 40000, loss: 0.210056
   Number of active neurons: 5
 >> iter 41000, loss: 0.376390
 >> iter 42000, loss: 0.293547
 >> iter 43000, loss: 0.315540
 >> iter 44000, loss: 0.320924
 >> iter 45000, loss: 0.258962
 >> iter 46000, loss: 0.398616
 >> iter 47000, loss: 0.356047
 >> iter 48000, loss: 0.409399
 >> iter 49000, loss: 0.378100
 >> iter 50000, loss: 0.299614
   Number of active neurons: 4
 >> iter 51000, loss: 0.306007
 >> iter 52000, loss: 0.269708
 >> iter 53000, loss: 0.371812
 >> iter 54000, loss: 0.396700
 >> iter 55000, loss: 0.395320
 >> iter 56000, loss: 0.382092
 >> iter 57000, loss: 0.438901
 >> iter 58000, loss: 0.386296
 >> iter 59000, loss: 0.475994
 >> iter 60000, loss: 0.334958
   Number of active neurons: 4
 >> iter 61000, loss: 0.298308
 >> iter 62000, loss: 0.376224
 >> iter 63000, loss: 0.368592
 >> iter 64000, loss: 0.339212
 >> iter 65000, loss: 0.303430
 >> iter 66000, loss: 0.376099
 >> iter 67000, loss: 0.374371
 >> iter 68000, loss: 0.307746
 >> iter 69000, loss: 0.294209
 >> iter 70000, loss: 0.301648
   Number of active neurons: 4
 >> iter 71000, loss: 0.335082
 >> iter 72000, loss: 0.388463
 >> iter 73000, loss: 0.415276
 >> iter 74000, loss: 0.450762
 >> iter 75000, loss: 0.429312
 >> iter 76000, loss: 0.378625
 >> iter 77000, loss: 0.337332
 >> iter 78000, loss: 0.395945
 >> iter 79000, loss: 0.338532
 >> iter 80000, loss: 0.292329
   Number of active neurons: 4
 >> iter 81000, loss: 0.212544
 >> iter 82000, loss: 0.348633
 >> iter 83000, loss: 0.256318
 >> iter 84000, loss: 0.236064
 >> iter 85000, loss: 0.291721
 >> iter 86000, loss: 0.359459
 >> iter 87000, loss: 0.342313
 >> iter 88000, loss: 0.410496
 >> iter 89000, loss: 0.423855
 >> iter 90000, loss: 0.325540
   Number of active neurons: 4
 >> iter 91000, loss: 0.392283
 >> iter 92000, loss: 0.368756
 >> iter 93000, loss: 0.380992
 >> iter 94000, loss: 0.274627
 >> iter 95000, loss: 0.390002
 >> iter 96000, loss: 0.363144
 >> iter 97000, loss: 0.235504
 >> iter 98000, loss: 0.245898
 >> iter 99000, loss: 0.368963
 >> iter 100000, loss: 0.350058
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.800021
 >> iter 2000, loss: 9.543186
 >> iter 3000, loss: 5.743616
 >> iter 4000, loss: 3.266448
 >> iter 5000, loss: 2.055973
 >> iter 6000, loss: 1.344336
 >> iter 7000, loss: 1.021029
 >> iter 8000, loss: 0.704019
 >> iter 9000, loss: 0.723888
 >> iter 10000, loss: 0.563774
   Number of active neurons: 6
 >> iter 11000, loss: 0.580214
 >> iter 12000, loss: 0.529157
 >> iter 13000, loss: 0.494926
 >> iter 14000, loss: 0.355951
 >> iter 15000, loss: 0.490261
 >> iter 16000, loss: 0.500745
 >> iter 17000, loss: 0.589423
 >> iter 18000, loss: 0.566405
 >> iter 19000, loss: 0.492147
 >> iter 20000, loss: 0.532938
   Number of active neurons: 6
 >> iter 21000, loss: 0.443478
 >> iter 22000, loss: 0.347661
 >> iter 23000, loss: 0.357244
 >> iter 24000, loss: 0.530276
 >> iter 25000, loss: 0.484556
 >> iter 26000, loss: 0.427861
 >> iter 27000, loss: 0.408923
 >> iter 28000, loss: 0.307108
 >> iter 29000, loss: 0.337670
 >> iter 30000, loss: 0.391529
   Number of active neurons: 6
 >> iter 31000, loss: 0.446871
 >> iter 32000, loss: 0.462239
 >> iter 33000, loss: 0.525822
 >> iter 34000, loss: 0.436698
 >> iter 35000, loss: 0.380685
 >> iter 36000, loss: 0.354500
 >> iter 37000, loss: 0.445546
 >> iter 38000, loss: 0.457102
 >> iter 39000, loss: 0.377273
 >> iter 40000, loss: 0.539076
   Number of active neurons: 6
 >> iter 41000, loss: 0.421562
 >> iter 42000, loss: 0.363645
 >> iter 43000, loss: 0.486345
 >> iter 44000, loss: 0.499759
 >> iter 45000, loss: 0.378265
 >> iter 46000, loss: 0.455785
 >> iter 47000, loss: 0.442982
 >> iter 48000, loss: 0.393369
 >> iter 49000, loss: 0.404913
 >> iter 50000, loss: 0.397737
   Number of active neurons: 5
 >> iter 51000, loss: 0.579322
 >> iter 52000, loss: 0.562824
 >> iter 53000, loss: 0.367304
 >> iter 54000, loss: 0.483722
 >> iter 55000, loss: 0.329270
 >> iter 56000, loss: 0.263467
 >> iter 57000, loss: 0.287537
 >> iter 58000, loss: 0.351185
 >> iter 59000, loss: 0.424147
 >> iter 60000, loss: 0.331699
   Number of active neurons: 5
 >> iter 61000, loss: 0.409931
 >> iter 62000, loss: 0.387238
 >> iter 63000, loss: 0.396480
 >> iter 64000, loss: 0.321833
 >> iter 65000, loss: 0.307858
 >> iter 66000, loss: 0.292419
 >> iter 67000, loss: 0.315506
 >> iter 68000, loss: 0.403103
 >> iter 69000, loss: 0.376300
 >> iter 70000, loss: 0.346952
   Number of active neurons: 5
 >> iter 71000, loss: 0.473468
 >> iter 72000, loss: 0.364861
 >> iter 73000, loss: 0.328166
 >> iter 74000, loss: 0.296380
 >> iter 75000, loss: 0.208181
 >> iter 76000, loss: 0.283309
 >> iter 77000, loss: 0.286503
 >> iter 78000, loss: 0.301757
 >> iter 79000, loss: 0.429502
 >> iter 80000, loss: 0.385422
   Number of active neurons: 5
 >> iter 81000, loss: 0.407528
 >> iter 82000, loss: 0.259316
 >> iter 83000, loss: 0.333015
 >> iter 84000, loss: 0.532543
 >> iter 85000, loss: 0.473796
 >> iter 86000, loss: 0.391723
 >> iter 87000, loss: 0.350308
 >> iter 88000, loss: 0.272741
 >> iter 89000, loss: 0.340073
 >> iter 90000, loss: 0.342610
   Number of active neurons: 5
 >> iter 91000, loss: 0.329874
 >> iter 92000, loss: 0.352450
 >> iter 93000, loss: 0.545213
 >> iter 94000, loss: 0.513485
 >> iter 95000, loss: 0.461713
 >> iter 96000, loss: 0.476277
 >> iter 97000, loss: 0.391828
 >> iter 98000, loss: 0.390137
 >> iter 99000, loss: 0.537421
 >> iter 100000, loss: 0.321772
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.078635
 >> iter 2000, loss: 9.868892
 >> iter 3000, loss: 5.371091
 >> iter 4000, loss: 2.879516
 >> iter 5000, loss: 1.649880
 >> iter 6000, loss: 0.939453
 >> iter 7000, loss: 0.676873
 >> iter 8000, loss: 0.578119
 >> iter 9000, loss: 0.421971
 >> iter 10000, loss: 0.442563
   Number of active neurons: 5
 >> iter 11000, loss: 0.373728
 >> iter 12000, loss: 0.485767
 >> iter 13000, loss: 0.417139
 >> iter 14000, loss: 0.394874
 >> iter 15000, loss: 0.414250
 >> iter 16000, loss: 0.384602
 >> iter 17000, loss: 0.381304
 >> iter 18000, loss: 0.415729
 >> iter 19000, loss: 0.496042
 >> iter 20000, loss: 0.434208
   Number of active neurons: 5
 >> iter 21000, loss: 0.493274
 >> iter 22000, loss: 0.480229
 >> iter 23000, loss: 0.449975
 >> iter 24000, loss: 0.492400
 >> iter 25000, loss: 0.385192
 >> iter 26000, loss: 0.422828
 >> iter 27000, loss: 0.371780
 >> iter 28000, loss: 0.495010
 >> iter 29000, loss: 0.436396
 >> iter 30000, loss: 0.505529
   Number of active neurons: 5
 >> iter 31000, loss: 0.463511
 >> iter 32000, loss: 0.521498
 >> iter 33000, loss: 0.486776
 >> iter 34000, loss: 0.351702
 >> iter 35000, loss: 0.525260
 >> iter 36000, loss: 0.459568
 >> iter 37000, loss: 0.521701
 >> iter 38000, loss: 0.318398
 >> iter 39000, loss: 0.271373
 >> iter 40000, loss: 0.319601
   Number of active neurons: 5
 >> iter 41000, loss: 0.440669
 >> iter 42000, loss: 0.382225
 >> iter 43000, loss: 0.385084
 >> iter 44000, loss: 0.364772
 >> iter 45000, loss: 0.291960
 >> iter 46000, loss: 0.536150
 >> iter 47000, loss: 0.513366
 >> iter 48000, loss: 0.411174
 >> iter 49000, loss: 0.428216
 >> iter 50000, loss: 0.246991
   Number of active neurons: 5
 >> iter 51000, loss: 0.285457
 >> iter 52000, loss: 0.292354
 >> iter 53000, loss: 0.357056
 >> iter 54000, loss: 0.351915
 >> iter 55000, loss: 0.390802
 >> iter 56000, loss: 0.401945
 >> iter 57000, loss: 0.393097
 >> iter 58000, loss: 0.416482
 >> iter 59000, loss: 0.347064
 >> iter 60000, loss: 0.463110
   Number of active neurons: 5
 >> iter 61000, loss: 0.376701
 >> iter 62000, loss: 0.392690
 >> iter 63000, loss: 0.301629
 >> iter 64000, loss: 0.380171
 >> iter 65000, loss: 0.331672
 >> iter 66000, loss: 0.360791
 >> iter 67000, loss: 0.558809
 >> iter 68000, loss: 0.478277
 >> iter 69000, loss: 0.342759
 >> iter 70000, loss: 0.284770
   Number of active neurons: 5
 >> iter 71000, loss: 0.391676
 >> iter 72000, loss: 0.509446
 >> iter 73000, loss: 0.317569
 >> iter 74000, loss: 0.290518
 >> iter 75000, loss: 0.322839
 >> iter 76000, loss: 0.264578
 >> iter 77000, loss: 0.264788
 >> iter 78000, loss: 0.299674
 >> iter 79000, loss: 0.329558
 >> iter 80000, loss: 0.360220
   Number of active neurons: 5
 >> iter 81000, loss: 0.314662
 >> iter 82000, loss: 0.322305
 >> iter 83000, loss: 0.378883
 >> iter 84000, loss: 0.348958
 >> iter 85000, loss: 0.421706
 >> iter 86000, loss: 0.365559
 >> iter 87000, loss: 0.310964
 >> iter 88000, loss: 0.258018
 >> iter 89000, loss: 0.520192
 >> iter 90000, loss: 0.421443
   Number of active neurons: 5
 >> iter 91000, loss: 0.413634
 >> iter 92000, loss: 0.316538
 >> iter 93000, loss: 0.336178
 >> iter 94000, loss: 0.293016
 >> iter 95000, loss: 0.361342
 >> iter 96000, loss: 0.301988
 >> iter 97000, loss: 0.334399
 >> iter 98000, loss: 0.298910
 >> iter 99000, loss: 0.239918
 >> iter 100000, loss: 0.308235
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.885077
 >> iter 2000, loss: 10.324124
 >> iter 3000, loss: 6.630344
 >> iter 4000, loss: 3.795778
 >> iter 5000, loss: 2.274919
 >> iter 6000, loss: 1.449998
 >> iter 7000, loss: 0.886103
 >> iter 8000, loss: 0.726357
 >> iter 9000, loss: 0.634198
 >> iter 10000, loss: 0.417141
   Number of active neurons: 6
 >> iter 11000, loss: 0.291870
 >> iter 12000, loss: 0.369635
 >> iter 13000, loss: 0.435395
 >> iter 14000, loss: 0.432380
 >> iter 15000, loss: 0.296258
 >> iter 16000, loss: 0.287454
 >> iter 17000, loss: 0.356863
 >> iter 18000, loss: 0.348627
 >> iter 19000, loss: 0.390236
 >> iter 20000, loss: 0.409100
   Number of active neurons: 6
 >> iter 21000, loss: 0.445025
 >> iter 22000, loss: 0.630844
 >> iter 23000, loss: 0.492436
 >> iter 24000, loss: 0.390043
 >> iter 25000, loss: 0.397130
 >> iter 26000, loss: 0.364102
 >> iter 27000, loss: 0.490002
 >> iter 28000, loss: 0.487630
 >> iter 29000, loss: 0.467511
 >> iter 30000, loss: 0.261072
   Number of active neurons: 6
 >> iter 31000, loss: 0.308198
 >> iter 32000, loss: 0.464232
 >> iter 33000, loss: 0.364631
 >> iter 34000, loss: 0.321030
 >> iter 35000, loss: 0.417635
 >> iter 36000, loss: 0.398802
 >> iter 37000, loss: 0.514395
 >> iter 38000, loss: 0.422284
 >> iter 39000, loss: 0.403812
 >> iter 40000, loss: 0.392309
   Number of active neurons: 6
 >> iter 41000, loss: 0.401807
 >> iter 42000, loss: 0.373781
 >> iter 43000, loss: 0.526144
 >> iter 44000, loss: 0.384018
 >> iter 45000, loss: 0.544081
 >> iter 46000, loss: 0.598424
 >> iter 47000, loss: 0.556925
 >> iter 48000, loss: 0.434653
 >> iter 49000, loss: 0.579563
 >> iter 50000, loss: 0.445558
   Number of active neurons: 6
 >> iter 51000, loss: 0.403666
 >> iter 52000, loss: 0.571657
 >> iter 53000, loss: 0.536507
 >> iter 54000, loss: 0.454909
 >> iter 55000, loss: 0.500641
 >> iter 56000, loss: 0.473443
 >> iter 57000, loss: 0.459396
 >> iter 58000, loss: 0.374830
 >> iter 59000, loss: 0.448362
 >> iter 60000, loss: 0.426978
   Number of active neurons: 6
 >> iter 61000, loss: 0.382201
 >> iter 62000, loss: 0.326365
 >> iter 63000, loss: 0.451388
 >> iter 64000, loss: 0.502139
 >> iter 65000, loss: 0.379646
 >> iter 66000, loss: 0.533006
 >> iter 67000, loss: 0.480881
 >> iter 68000, loss: 0.415006
 >> iter 69000, loss: 0.357437
 >> iter 70000, loss: 0.357425
   Number of active neurons: 6
 >> iter 71000, loss: 0.520060
 >> iter 72000, loss: 0.495333
 >> iter 73000, loss: 0.613562
 >> iter 74000, loss: 0.428108
 >> iter 75000, loss: 0.449080
 >> iter 76000, loss: 0.641989
 >> iter 77000, loss: 0.618490
 >> iter 78000, loss: 0.498196
 >> iter 79000, loss: 0.609719
 >> iter 80000, loss: 0.519459
   Number of active neurons: 6
 >> iter 81000, loss: 0.433495
 >> iter 82000, loss: 0.414522
 >> iter 83000, loss: 0.539714
 >> iter 84000, loss: 0.465607
 >> iter 85000, loss: 0.419582
 >> iter 86000, loss: 0.573782
 >> iter 87000, loss: 0.547300
 >> iter 88000, loss: 0.558239
 >> iter 89000, loss: 0.408873
 >> iter 90000, loss: 0.696683
   Number of active neurons: 6
 >> iter 91000, loss: 0.516192
 >> iter 92000, loss: 0.383294
 >> iter 93000, loss: 0.410304
 >> iter 94000, loss: 0.381172
 >> iter 95000, loss: 0.452867
 >> iter 96000, loss: 0.407888
 >> iter 97000, loss: 0.393457
 >> iter 98000, loss: 0.555898
 >> iter 99000, loss: 0.527625
 >> iter 100000, loss: 0.708279
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 17.574440
 >> iter 2000, loss: 10.657211
 >> iter 3000, loss: 6.366423
 >> iter 4000, loss: 3.653315
 >> iter 5000, loss: 2.316655
 >> iter 6000, loss: 1.505325
 >> iter 7000, loss: 1.243034
 >> iter 8000, loss: 1.108005
 >> iter 9000, loss: 0.894273
 >> iter 10000, loss: 0.833926
   Number of active neurons: 8
 >> iter 11000, loss: 0.883230
 >> iter 12000, loss: 0.743924
 >> iter 13000, loss: 0.970313
 >> iter 14000, loss: 0.736726
 >> iter 15000, loss: 1.002670
 >> iter 16000, loss: 0.835691
 >> iter 17000, loss: 0.806038
 >> iter 18000, loss: 0.848698
 >> iter 19000, loss: 0.859425
 >> iter 20000, loss: 0.710991
   Number of active neurons: 8
 >> iter 21000, loss: 0.756719
 >> iter 22000, loss: 0.697107
 >> iter 23000, loss: 0.705112
 >> iter 24000, loss: 0.687734
 >> iter 25000, loss: 0.632217
 >> iter 26000, loss: 0.715249
 >> iter 27000, loss: 0.648823
 >> iter 28000, loss: 0.532211
 >> iter 29000, loss: 0.560849
 >> iter 30000, loss: 0.756200
   Number of active neurons: 8
 >> iter 31000, loss: 0.648042
 >> iter 32000, loss: 0.621909
 >> iter 33000, loss: 0.769664
 >> iter 34000, loss: 0.694364
 >> iter 35000, loss: 0.995652
 >> iter 36000, loss: 0.925902
 >> iter 37000, loss: 0.980977
 >> iter 38000, loss: 0.951791
 >> iter 39000, loss: 0.829850
 >> iter 40000, loss: 0.807674
   Number of active neurons: 7
 >> iter 41000, loss: 0.774883
 >> iter 42000, loss: 0.775172
 >> iter 43000, loss: 0.793675
 >> iter 44000, loss: 0.770705
 >> iter 45000, loss: 0.783370
 >> iter 46000, loss: 0.680773
 >> iter 47000, loss: 0.667024
 >> iter 48000, loss: 0.751651
 >> iter 49000, loss: 0.760507
 >> iter 50000, loss: 0.724401
   Number of active neurons: 6
 >> iter 51000, loss: 0.908183
 >> iter 52000, loss: 0.702908
 >> iter 53000, loss: 0.851609
 >> iter 54000, loss: 0.853003
 >> iter 55000, loss: 0.749889
 >> iter 56000, loss: 0.794714
 >> iter 57000, loss: 0.898137
 >> iter 58000, loss: 0.760795
 >> iter 59000, loss: 0.761159
 >> iter 60000, loss: 0.629824
   Number of active neurons: 5
 >> iter 61000, loss: 0.696763
 >> iter 62000, loss: 0.601454
 >> iter 63000, loss: 0.882069
 >> iter 64000, loss: 0.986546
 >> iter 65000, loss: 0.698074
 >> iter 66000, loss: 0.685591
 >> iter 67000, loss: 0.797425
 >> iter 68000, loss: 0.719985
 >> iter 69000, loss: 0.771807
 >> iter 70000, loss: 0.644401
   Number of active neurons: 5
 >> iter 71000, loss: 0.789667
 >> iter 72000, loss: 0.755225
 >> iter 73000, loss: 0.881902
 >> iter 74000, loss: 0.812327
 >> iter 75000, loss: 1.057714
   Number of active neurons: 5
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 76000, loss: 0.923061
 >> iter 77000, loss: 0.920436
 >> iter 78000, loss: 0.823096
 >> iter 79000, loss: 0.954350
 >> iter 80000, loss: 0.661515
   Number of active neurons: 5
 >> iter 81000, loss: 0.583691
 >> iter 82000, loss: 0.530842
 >> iter 83000, loss: 1.131735
 >> iter 84000, loss: 0.904642
 >> iter 85000, loss: 0.847236
 >> iter 86000, loss: 1.228701
 >> iter 87000, loss: 1.240973
 >> iter 88000, loss: 0.981744
 >> iter 89000, loss: 0.802800
 >> iter 90000, loss: 0.732143
   Number of active neurons: 5
 >> iter 91000, loss: 0.970702
 >> iter 92000, loss: 0.868997
 >> iter 93000, loss: 0.927945
 >> iter 94000, loss: 0.954122
 >> iter 95000, loss: 1.233620
   Number of active neurons: 5
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 96000, loss: 0.929723
 >> iter 97000, loss: 0.938039
 >> iter 98000, loss: 0.970247
 >> iter 99000, loss: 0.744857
 >> iter 100000, loss: 0.706627
   Number of active neurons: 5
 >> iter 101000, loss: 0.616165
 >> iter 102000, loss: 0.817780
 >> iter 103000, loss: 0.840283
 >> iter 104000, loss: 0.710796
 >> iter 105000, loss: 1.330332
   Number of active neurons: 7
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 106000, loss: 1.001190
 >> iter 107000, loss: 1.298281
 >> iter 108000, loss: 1.222888
 >> iter 109000, loss: 1.018880
 >> iter 110000, loss: 0.875466
   Number of active neurons: 7
 >> iter 111000, loss: 0.994472
 >> iter 112000, loss: 0.722930
 >> iter 113000, loss: 0.660007
 >> iter 114000, loss: 0.790770
 >> iter 115000, loss: 0.892834
 >> iter 116000, loss: 0.767795
 >> iter 117000, loss: 0.762317
 >> iter 118000, loss: 0.829168
 >> iter 119000, loss: 0.766989
 >> iter 120000, loss: 0.888143
   Number of active neurons: 5
 >> iter 121000, loss: 0.897688
 >> iter 122000, loss: 0.655688
 >> iter 123000, loss: 0.724906
 >> iter 124000, loss: 0.857034
 >> iter 125000, loss: 0.855944
 >> iter 126000, loss: 0.721238
 >> iter 127000, loss: 0.748259
 >> iter 128000, loss: 1.025206
 >> iter 129000, loss: 1.019652
 >> iter 130000, loss: 0.885428
   Number of active neurons: 5
 >> iter 131000, loss: 0.774364
 >> iter 132000, loss: 0.635620
 >> iter 133000, loss: 0.691645
 >> iter 134000, loss: 0.821440
 >> iter 135000, loss: 0.783320
 >> iter 136000, loss: 0.657973
 >> iter 137000, loss: 0.709651
 >> iter 138000, loss: 0.601484
 >> iter 139000, loss: 0.681505
 >> iter 140000, loss: 0.803665
   Number of active neurons: 4
 >> iter 141000, loss: 0.799307
 >> iter 142000, loss: 0.737029
 >> iter 143000, loss: 0.733214
 >> iter 144000, loss: 0.851437
 >> iter 145000, loss: 0.781036
 >> iter 146000, loss: 0.847498
 >> iter 147000, loss: 0.633145
 >> iter 148000, loss: 0.659039
 >> iter 149000, loss: 0.660195
 >> iter 150000, loss: 0.797106
   Number of active neurons: 4
 >> iter 151000, loss: 0.741765
 >> iter 152000, loss: 0.719751
 >> iter 153000, loss: 0.698971
 >> iter 154000, loss: 0.839443
 >> iter 155000, loss: 0.867307
 >> iter 156000, loss: 0.787431
 >> iter 157000, loss: 0.770359
 >> iter 158000, loss: 0.702069
 >> iter 159000, loss: 0.785397
 >> iter 160000, loss: 0.810987
   Number of active neurons: 4
 >> iter 161000, loss: 0.830800
 >> iter 162000, loss: 0.956930
 >> iter 163000, loss: 0.804575
 >> iter 164000, loss: 0.708648
 >> iter 165000, loss: 0.620471
 >> iter 166000, loss: 0.745543
 >> iter 167000, loss: 0.754000
 >> iter 168000, loss: 0.682668
 >> iter 169000, loss: 0.609843
 >> iter 170000, loss: 0.648026
   Number of active neurons: 4
 >> iter 171000, loss: 0.748366
 >> iter 172000, loss: 0.664360
 >> iter 173000, loss: 0.915478
 >> iter 174000, loss: 0.849528
 >> iter 175000, loss: 0.709003
 >> iter 176000, loss: 0.783820
 >> iter 177000, loss: 0.620396
 >> iter 178000, loss: 0.810081
 >> iter 179000, loss: 0.758589
 >> iter 180000, loss: 0.862576
   Number of active neurons: 4
 >> iter 181000, loss: 0.819596
 >> iter 182000, loss: 0.934282
 >> iter 183000, loss: 0.929726
 >> iter 184000, loss: 0.979842
 >> iter 185000, loss: 0.863912
 >> iter 186000, loss: 0.940303
 >> iter 187000, loss: 0.800397
 >> iter 188000, loss: 0.972300
 >> iter 189000, loss: 0.889780
 >> iter 190000, loss: 0.730179
   Number of active neurons: 4
 >> iter 191000, loss: 0.783520
 >> iter 192000, loss: 0.607168
 >> iter 193000, loss: 0.711330
 >> iter 194000, loss: 0.628581
 >> iter 195000, loss: 0.630780
 >> iter 196000, loss: 0.710424
 >> iter 197000, loss: 0.743855
 >> iter 198000, loss: 0.757877
 >> iter 199000, loss: 0.755548
 >> iter 200000, loss: 0.722176
   Number of active neurons: 4
 >> iter 201000, loss: 0.719927
 >> iter 202000, loss: 0.736822
 >> iter 203000, loss: 0.708632
 >> iter 204000, loss: 0.698687
 >> iter 205000, loss: 0.808647
 >> iter 206000, loss: 0.659735
 >> iter 207000, loss: 0.609566
 >> iter 208000, loss: 0.731161
 >> iter 209000, loss: 0.775085
 >> iter 210000, loss: 0.952644
   Number of active neurons: 5
 >> iter 211000, loss: 0.832017
 >> iter 212000, loss: 0.867291
 >> iter 213000, loss: 0.830465
 >> iter 214000, loss: 0.771861
 >> iter 215000, loss: 0.757501
 >> iter 216000, loss: 0.755932
 >> iter 217000, loss: 0.772269
 >> iter 218000, loss: 0.779238
 >> iter 219000, loss: 0.749028
 >> iter 220000, loss: 0.699174
   Number of active neurons: 4
 >> iter 221000, loss: 0.740093
 >> iter 222000, loss: 0.669497
 >> iter 223000, loss: 0.673963
 >> iter 224000, loss: 0.895429
 >> iter 225000, loss: 0.973121
 >> iter 226000, loss: 0.889541
 >> iter 227000, loss: 0.725678
 >> iter 228000, loss: 0.725398
 >> iter 229000, loss: 0.686376
 >> iter 230000, loss: 0.650049
   Number of active neurons: 4
 >> iter 231000, loss: 0.915442
 >> iter 232000, loss: 0.852830
 >> iter 233000, loss: 0.811459
 >> iter 234000, loss: 0.686654
 >> iter 235000, loss: 0.745365
 >> iter 236000, loss: 0.839990
 >> iter 237000, loss: 0.749288
 >> iter 238000, loss: 0.671064
 >> iter 239000, loss: 0.833757
 >> iter 240000, loss: 0.720361
   Number of active neurons: 4
 >> iter 241000, loss: 0.895832
 >> iter 242000, loss: 0.668377
 >> iter 243000, loss: 0.716744
 >> iter 244000, loss: 0.811349
 >> iter 245000, loss: 0.765661
 >> iter 246000, loss: 0.800153
 >> iter 247000, loss: 0.905662
 >> iter 248000, loss: 0.964140
 >> iter 249000, loss: 0.754397
 >> iter 250000, loss: 0.881834
   Number of active neurons: 4
 >> iter 251000, loss: 0.808064
 >> iter 252000, loss: 0.767922
 >> iter 253000, loss: 0.722965
 >> iter 254000, loss: 0.687674
 >> iter 255000, loss: 0.841491
 >> iter 256000, loss: 0.728110
 >> iter 257000, loss: 0.745137
 >> iter 258000, loss: 0.733736
 >> iter 259000, loss: 0.714722
 >> iter 260000, loss: 0.742298
   Number of active neurons: 4
 >> iter 261000, loss: 0.781433
 >> iter 262000, loss: 0.695393
 >> iter 263000, loss: 0.745743
 >> iter 264000, loss: 0.864840
 >> iter 265000, loss: 0.847694
 >> iter 266000, loss: 0.913197
 >> iter 267000, loss: 1.077573
 >> iter 268000, loss: 0.916644
 >> iter 269000, loss: 1.132598
 >> iter 270000, loss: 0.886731
   Number of active neurons: 4
 >> iter 271000, loss: 0.835036
 >> iter 272000, loss: 0.698876
 >> iter 273000, loss: 0.876324
 >> iter 274000, loss: 0.879851
 >> iter 275000, loss: 0.805089
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.804709
 >> iter 2000, loss: 9.943290
 >> iter 3000, loss: 6.349901
 >> iter 4000, loss: 3.903719
 >> iter 5000, loss: 2.448560
 >> iter 6000, loss: 1.522781
 >> iter 7000, loss: 1.097537
 >> iter 8000, loss: 0.982774
 >> iter 9000, loss: 0.717744
 >> iter 10000, loss: 0.779933
   Number of active neurons: 5
 >> iter 11000, loss: 0.642094
 >> iter 12000, loss: 0.660620
 >> iter 13000, loss: 0.642887
 >> iter 14000, loss: 0.577943
 >> iter 15000, loss: 0.497143
 >> iter 16000, loss: 0.498828
 >> iter 17000, loss: 0.593158
 >> iter 18000, loss: 0.781401
 >> iter 19000, loss: 0.522184
 >> iter 20000, loss: 0.543044
   Number of active neurons: 5
 >> iter 21000, loss: 0.542847
 >> iter 22000, loss: 0.614922
 >> iter 23000, loss: 0.551622
 >> iter 24000, loss: 0.451023
 >> iter 25000, loss: 0.557718
 >> iter 26000, loss: 0.480955
 >> iter 27000, loss: 0.406594
 >> iter 28000, loss: 0.489005
 >> iter 29000, loss: 0.443797
 >> iter 30000, loss: 0.664234
   Number of active neurons: 4
 >> iter 31000, loss: 0.504183
 >> iter 32000, loss: 0.486263
 >> iter 33000, loss: 0.774278
 >> iter 34000, loss: 0.537367
 >> iter 35000, loss: 0.454013
 >> iter 36000, loss: 0.485939
 >> iter 37000, loss: 0.554827
 >> iter 38000, loss: 0.531303
 >> iter 39000, loss: 0.325399
 >> iter 40000, loss: 0.380985
   Number of active neurons: 4
 >> iter 41000, loss: 0.399558
 >> iter 42000, loss: 0.464750
 >> iter 43000, loss: 0.457453
 >> iter 44000, loss: 0.461412
 >> iter 45000, loss: 0.467961
 >> iter 46000, loss: 0.378136
 >> iter 47000, loss: 0.390107
 >> iter 48000, loss: 0.488326
 >> iter 49000, loss: 0.579031
 >> iter 50000, loss: 0.537866
   Number of active neurons: 4
 >> iter 51000, loss: 0.424988
 >> iter 52000, loss: 0.316721
 >> iter 53000, loss: 0.349631
 >> iter 54000, loss: 0.443527
 >> iter 55000, loss: 0.422031
 >> iter 56000, loss: 0.409900
 >> iter 57000, loss: 0.413336
 >> iter 58000, loss: 0.402039
 >> iter 59000, loss: 0.518904
 >> iter 60000, loss: 0.409213
   Number of active neurons: 4
 >> iter 61000, loss: 0.429919
 >> iter 62000, loss: 0.460710
 >> iter 63000, loss: 0.521069
 >> iter 64000, loss: 0.383908
 >> iter 65000, loss: 0.402401
 >> iter 66000, loss: 0.452413
 >> iter 67000, loss: 0.444441
 >> iter 68000, loss: 0.541150
 >> iter 69000, loss: 0.553808
 >> iter 70000, loss: 0.619535
   Number of active neurons: 4
 >> iter 71000, loss: 0.635139
 >> iter 72000, loss: 0.482544
 >> iter 73000, loss: 0.479879
 >> iter 74000, loss: 0.490012
 >> iter 75000, loss: 0.357509
 >> iter 76000, loss: 0.413281
 >> iter 77000, loss: 0.304896
 >> iter 78000, loss: 0.409678
 >> iter 79000, loss: 0.452262
 >> iter 80000, loss: 0.566678
   Number of active neurons: 4
 >> iter 81000, loss: 0.434623
 >> iter 82000, loss: 0.500238
 >> iter 83000, loss: 0.442591
 >> iter 84000, loss: 0.317409
 >> iter 85000, loss: 0.283123
 >> iter 86000, loss: 0.450194
 >> iter 87000, loss: 0.369418
 >> iter 88000, loss: 0.493560
 >> iter 89000, loss: 0.577436
 >> iter 90000, loss: 0.570787
   Number of active neurons: 4
 >> iter 91000, loss: 0.500751
 >> iter 92000, loss: 0.546291
 >> iter 93000, loss: 0.584810
 >> iter 94000, loss: 0.632518
 >> iter 95000, loss: 0.516137
 >> iter 96000, loss: 0.477619
 >> iter 97000, loss: 0.541783
 >> iter 98000, loss: 0.526602
 >> iter 99000, loss: 0.429934
 >> iter 100000, loss: 0.457658
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.191924
 >> iter 2000, loss: 11.752101
 >> iter 3000, loss: 8.469436
 >> iter 4000, loss: 5.505639
 >> iter 5000, loss: 3.229803
 >> iter 6000, loss: 1.895555
 >> iter 7000, loss: 1.231199
 >> iter 8000, loss: 0.929315
 >> iter 9000, loss: 0.700391
 >> iter 10000, loss: 0.563578
   Number of active neurons: 6
 >> iter 11000, loss: 0.597543
 >> iter 12000, loss: 0.441979
 >> iter 13000, loss: 0.580723
 >> iter 14000, loss: 0.722514
 >> iter 15000, loss: 0.663223
 >> iter 16000, loss: 0.730310
 >> iter 17000, loss: 0.724133
 >> iter 18000, loss: 0.624447
 >> iter 19000, loss: 0.754846
 >> iter 20000, loss: 0.693648
   Number of active neurons: 6
 >> iter 21000, loss: 0.631469
 >> iter 22000, loss: 0.698366
 >> iter 23000, loss: 0.541788
 >> iter 24000, loss: 0.632382
 >> iter 25000, loss: 0.560599
 >> iter 26000, loss: 0.676345
 >> iter 27000, loss: 0.527818
 >> iter 28000, loss: 0.671403
 >> iter 29000, loss: 0.518068
 >> iter 30000, loss: 0.599196
   Number of active neurons: 6
 >> iter 31000, loss: 0.598653
 >> iter 32000, loss: 0.624028
 >> iter 33000, loss: 0.496905
 >> iter 34000, loss: 0.485385
 >> iter 35000, loss: 0.546362
 >> iter 36000, loss: 0.521005
 >> iter 37000, loss: 0.516340
 >> iter 38000, loss: 0.584119
 >> iter 39000, loss: 0.532734
 >> iter 40000, loss: 0.466998
   Number of active neurons: 6
 >> iter 41000, loss: 0.561706
 >> iter 42000, loss: 0.539645
 >> iter 43000, loss: 0.504709
 >> iter 44000, loss: 0.441189
 >> iter 45000, loss: 0.599897
 >> iter 46000, loss: 0.694171
 >> iter 47000, loss: 0.525933
 >> iter 48000, loss: 0.369584
 >> iter 49000, loss: 0.437411
 >> iter 50000, loss: 0.319248
   Number of active neurons: 6
 >> iter 51000, loss: 0.487605
 >> iter 52000, loss: 0.555306
 >> iter 53000, loss: 0.488297
 >> iter 54000, loss: 0.536274
 >> iter 55000, loss: 0.447747
 >> iter 56000, loss: 0.499359
 >> iter 57000, loss: 0.353602
 >> iter 58000, loss: 0.402871
 >> iter 59000, loss: 0.501141
 >> iter 60000, loss: 0.464762
   Number of active neurons: 5
 >> iter 61000, loss: 0.487265
 >> iter 62000, loss: 0.408600
 >> iter 63000, loss: 0.479790
 >> iter 64000, loss: 0.486494
 >> iter 65000, loss: 0.544792
 >> iter 66000, loss: 0.537272
 >> iter 67000, loss: 0.459504
 >> iter 68000, loss: 0.500883
 >> iter 69000, loss: 0.459073
 >> iter 70000, loss: 0.539899
   Number of active neurons: 5
 >> iter 71000, loss: 0.553509
 >> iter 72000, loss: 0.413316
 >> iter 73000, loss: 0.485813
 >> iter 74000, loss: 0.313885
 >> iter 75000, loss: 0.301430
 >> iter 76000, loss: 0.366547
 >> iter 77000, loss: 0.442335
 >> iter 78000, loss: 0.450932
 >> iter 79000, loss: 0.480525
 >> iter 80000, loss: 0.360542
   Number of active neurons: 5
 >> iter 81000, loss: 0.378472
 >> iter 82000, loss: 0.332589
 >> iter 83000, loss: 0.460896
 >> iter 84000, loss: 0.331571
 >> iter 85000, loss: 0.334829
 >> iter 86000, loss: 0.414669
 >> iter 87000, loss: 0.534193
 >> iter 88000, loss: 0.475556
 >> iter 89000, loss: 0.476736
 >> iter 90000, loss: 0.431255
   Number of active neurons: 5
 >> iter 91000, loss: 0.355315
 >> iter 92000, loss: 0.352412
 >> iter 93000, loss: 0.417221
 >> iter 94000, loss: 0.366439
 >> iter 95000, loss: 0.554564
 >> iter 96000, loss: 0.517187
 >> iter 97000, loss: 0.458537
 >> iter 98000, loss: 0.406502
 >> iter 99000, loss: 0.416381
 >> iter 100000, loss: 0.342145
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.581199
 >> iter 2000, loss: 11.903154
 >> iter 3000, loss: 8.657375
 >> iter 4000, loss: 4.528323
 >> iter 5000, loss: 2.342408
 >> iter 6000, loss: 1.375313
 >> iter 7000, loss: 0.947321
 >> iter 8000, loss: 0.749724
 >> iter 9000, loss: 0.588043
 >> iter 10000, loss: 0.564291
   Number of active neurons: 4
 >> iter 11000, loss: 0.516554
 >> iter 12000, loss: 0.486146
 >> iter 13000, loss: 0.424269
 >> iter 14000, loss: 0.468510
 >> iter 15000, loss: 0.443839
 >> iter 16000, loss: 0.465924
 >> iter 17000, loss: 0.490533
 >> iter 18000, loss: 0.500640
 >> iter 19000, loss: 0.331733
 >> iter 20000, loss: 0.450075
   Number of active neurons: 4
 >> iter 21000, loss: 0.483221
 >> iter 22000, loss: 0.375195
 >> iter 23000, loss: 0.333466
 >> iter 24000, loss: 0.356755
 >> iter 25000, loss: 0.368166
 >> iter 26000, loss: 0.363520
 >> iter 27000, loss: 0.326561
 >> iter 28000, loss: 0.344329
 >> iter 29000, loss: 0.405123
 >> iter 30000, loss: 0.395335
   Number of active neurons: 4
 >> iter 31000, loss: 0.277567
 >> iter 32000, loss: 0.356284
 >> iter 33000, loss: 0.319612
 >> iter 34000, loss: 0.410875
 >> iter 35000, loss: 0.335858
 >> iter 36000, loss: 0.300740
 >> iter 37000, loss: 0.445369
 >> iter 38000, loss: 0.509523
 >> iter 39000, loss: 0.395126
 >> iter 40000, loss: 0.498370
   Number of active neurons: 4
 >> iter 41000, loss: 0.483511
 >> iter 42000, loss: 0.620850
 >> iter 43000, loss: 0.449146
 >> iter 44000, loss: 0.341665
 >> iter 45000, loss: 0.387412
 >> iter 46000, loss: 0.354502
 >> iter 47000, loss: 0.430340
 >> iter 48000, loss: 0.414529
 >> iter 49000, loss: 0.334389
 >> iter 50000, loss: 0.270195
   Number of active neurons: 4
 >> iter 51000, loss: 0.353827
 >> iter 52000, loss: 0.319581
 >> iter 53000, loss: 0.442450
 >> iter 54000, loss: 0.548133
 >> iter 55000, loss: 0.551239
 >> iter 56000, loss: 0.424766
 >> iter 57000, loss: 0.443481
 >> iter 58000, loss: 0.435435
 >> iter 59000, loss: 0.365310
 >> iter 60000, loss: 0.342001
   Number of active neurons: 4
 >> iter 61000, loss: 0.448431
 >> iter 62000, loss: 0.462345
 >> iter 63000, loss: 0.500462
 >> iter 64000, loss: 0.500829
 >> iter 65000, loss: 0.358647
 >> iter 66000, loss: 0.292830
 >> iter 67000, loss: 0.363121
 >> iter 68000, loss: 0.437990
 >> iter 69000, loss: 0.457909
 >> iter 70000, loss: 0.531539
   Number of active neurons: 4
 >> iter 71000, loss: 0.492194
 >> iter 72000, loss: 0.401740
 >> iter 73000, loss: 0.562085
 >> iter 74000, loss: 0.460671
 >> iter 75000, loss: 0.626534
 >> iter 76000, loss: 0.512772
 >> iter 77000, loss: 0.373858
 >> iter 78000, loss: 0.350789
 >> iter 79000, loss: 0.512462
 >> iter 80000, loss: 0.594135
   Number of active neurons: 4
 >> iter 81000, loss: 0.522158
 >> iter 82000, loss: 0.617738
 >> iter 83000, loss: 0.555759
 >> iter 84000, loss: 0.542618
 >> iter 85000, loss: 0.520799
 >> iter 86000, loss: 0.523989
 >> iter 87000, loss: 0.574944
 >> iter 88000, loss: 0.507578
 >> iter 89000, loss: 0.455742
 >> iter 90000, loss: 0.499508
   Number of active neurons: 4
 >> iter 91000, loss: 0.389091
 >> iter 92000, loss: 0.377682
 >> iter 93000, loss: 0.501842
 >> iter 94000, loss: 0.547897
 >> iter 95000, loss: 0.513578
 >> iter 96000, loss: 0.359146
 >> iter 97000, loss: 0.365352
 >> iter 98000, loss: 0.375459
 >> iter 99000, loss: 0.518741
 >> iter 100000, loss: 0.374737
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

