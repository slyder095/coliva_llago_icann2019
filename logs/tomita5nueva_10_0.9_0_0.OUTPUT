 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.9
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.265124
 >> iter 2000, loss: 10.933291
 >> iter 3000, loss: 9.040897
 >> iter 4000, loss: 8.166194
 >> iter 5000, loss: 7.882788
 >> iter 6000, loss: 7.712290
 >> iter 7000, loss: 7.668133
 >> iter 8000, loss: 7.628988
 >> iter 9000, loss: 7.615592
 >> iter 10000, loss: 7.627145
   Number of active neurons: 10
 >> iter 11000, loss: 7.608312
 >> iter 12000, loss: 7.589890
 >> iter 13000, loss: 7.615699
 >> iter 14000, loss: 7.614950
 >> iter 15000, loss: 7.597929
 >> iter 16000, loss: 7.583502
 >> iter 17000, loss: 7.624422
 >> iter 18000, loss: 7.588166
 >> iter 19000, loss: 7.586074
 >> iter 20000, loss: 7.570960
   Number of active neurons: 10
 >> iter 21000, loss: 7.575097
 >> iter 22000, loss: 7.627507
 >> iter 23000, loss: 7.589101
 >> iter 24000, loss: 7.562857
 >> iter 25000, loss: 7.594547
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 7.585459
 >> iter 27000, loss: 7.572328
 >> iter 28000, loss: 7.554648
 >> iter 29000, loss: 7.568421
 >> iter 30000, loss: 7.565478
   Number of active neurons: 10
 >> iter 31000, loss: 7.561332
 >> iter 32000, loss: 7.552259
 >> iter 33000, loss: 7.556562
 >> iter 34000, loss: 7.540066
 >> iter 35000, loss: 7.593553
 >> iter 36000, loss: 7.560292
 >> iter 37000, loss: 7.521679
 >> iter 38000, loss: 7.441812
 >> iter 39000, loss: 7.284277
 >> iter 40000, loss: 7.082982
   Number of active neurons: 10
 >> iter 41000, loss: 6.910777
 >> iter 42000, loss: 6.713137
 >> iter 43000, loss: 6.532548
 >> iter 44000, loss: 6.388366
 >> iter 45000, loss: 6.336956
 >> iter 46000, loss: 6.266103
 >> iter 47000, loss: 6.264571
 >> iter 48000, loss: 6.222839
 >> iter 49000, loss: 6.237557
 >> iter 50000, loss: 6.210981
   Number of active neurons: 10
 >> iter 51000, loss: 6.234397
 >> iter 52000, loss: 6.283021
 >> iter 53000, loss: 6.222358
 >> iter 54000, loss: 6.165047
 >> iter 55000, loss: 6.159889
 >> iter 56000, loss: 6.082315
 >> iter 57000, loss: 6.090551
 >> iter 58000, loss: 6.068055
 >> iter 59000, loss: 5.937409
 >> iter 60000, loss: 5.804725
   Number of active neurons: 10
 >> iter 61000, loss: 5.729065
 >> iter 62000, loss: 5.567832
 >> iter 63000, loss: 5.528646
 >> iter 64000, loss: 5.424557
 >> iter 65000, loss: 5.287606
 >> iter 66000, loss: 5.108552
 >> iter 67000, loss: 3.817799
 >> iter 68000, loss: 1.950629
 >> iter 69000, loss: 1.123098
 >> iter 70000, loss: 0.766697
   Number of active neurons: 10
 >> iter 71000, loss: 0.488258
 >> iter 72000, loss: 0.422411
 >> iter 73000, loss: 0.412037
 >> iter 74000, loss: 0.340643
 >> iter 75000, loss: 0.236499
 >> iter 76000, loss: 0.201460
 >> iter 77000, loss: 0.202150
 >> iter 78000, loss: 0.172851
 >> iter 79000, loss: 0.349205
 >> iter 80000, loss: 0.241729
   Number of active neurons: 10
 >> iter 81000, loss: 0.244825
 >> iter 82000, loss: 0.199372
 >> iter 83000, loss: 0.260787
 >> iter 84000, loss: 0.137807
 >> iter 85000, loss: 0.104479
 >> iter 86000, loss: 0.183014
 >> iter 87000, loss: 0.085037
 >> iter 88000, loss: 0.123032
 >> iter 89000, loss: 0.073653
 >> iter 90000, loss: 0.065514
   Number of active neurons: 10
 >> iter 91000, loss: 0.057576
 >> iter 92000, loss: 0.047400
 >> iter 93000, loss: 0.063126
 >> iter 94000, loss: 0.114114
 >> iter 95000, loss: 0.074687
 >> iter 96000, loss: 0.043918
 >> iter 97000, loss: 0.054098
 >> iter 98000, loss: 0.059531
 >> iter 99000, loss: 0.069566
 >> iter 100000, loss: 0.253981
   Number of active neurons: 10
 >> iter 101000, loss: 0.355818
 >> iter 102000, loss: 0.171300
 >> iter 103000, loss: 0.077412
 >> iter 104000, loss: 0.104689
 >> iter 105000, loss: 0.050812
 >> iter 106000, loss: 0.029011
 >> iter 107000, loss: 0.020157
 >> iter 108000, loss: 0.016213
 >> iter 109000, loss: 0.032311
 >> iter 110000, loss: 0.031739
   Number of active neurons: 10
 >> iter 111000, loss: 0.121623
 >> iter 112000, loss: 0.114838
 >> iter 113000, loss: 0.166249
 >> iter 114000, loss: 0.085026
 >> iter 115000, loss: 0.088315
 >> iter 116000, loss: 0.046892
 >> iter 117000, loss: 0.025043
 >> iter 118000, loss: 0.031330
 >> iter 119000, loss: 0.038604
 >> iter 120000, loss: 0.110712
   Number of active neurons: 10
 >> iter 121000, loss: 0.048290
 >> iter 122000, loss: 0.024754
 >> iter 123000, loss: 0.072758
 >> iter 124000, loss: 0.105420
 >> iter 125000, loss: 0.046645
 >> iter 126000, loss: 0.039211
 >> iter 127000, loss: 0.087074
 >> iter 128000, loss: 0.119147
 >> iter 129000, loss: 0.051105
 >> iter 130000, loss: 0.025549
   Number of active neurons: 10
 >> iter 131000, loss: 0.141946
 >> iter 132000, loss: 0.059671
 >> iter 133000, loss: 0.028241
 >> iter 134000, loss: 0.022194
 >> iter 135000, loss: 0.015046
 >> iter 136000, loss: 0.012790
 >> iter 137000, loss: 0.072411
 >> iter 138000, loss: 0.032894
 >> iter 139000, loss: 0.073728
 >> iter 140000, loss: 0.032404
   Number of active neurons: 10
 >> iter 141000, loss: 0.048228
 >> iter 142000, loss: 0.022788
 >> iter 143000, loss: 0.024132
 >> iter 144000, loss: 0.035421
 >> iter 145000, loss: 0.017862
 >> iter 146000, loss: 0.011113
 >> iter 147000, loss: 0.024441
 >> iter 148000, loss: 0.013433
 >> iter 149000, loss: 0.014991
 >> iter 150000, loss: 0.045023
   Number of active neurons: 10
 >> iter 151000, loss: 0.025633
 >> iter 152000, loss: 0.024112
 >> iter 153000, loss: 0.038720
 >> iter 154000, loss: 0.020635
 >> iter 155000, loss: 0.012136
 >> iter 156000, loss: 0.040446
 >> iter 157000, loss: 0.019000
 >> iter 158000, loss: 0.042912
 >> iter 159000, loss: 0.019877
 >> iter 160000, loss: 0.022958
   Number of active neurons: 10
 >> iter 161000, loss: 0.029869
 >> iter 162000, loss: 0.041458
 >> iter 163000, loss: 0.019187
 >> iter 164000, loss: 0.010649
 >> iter 165000, loss: 0.007387
 >> iter 166000, loss: 0.006266
 >> iter 167000, loss: 0.005924
 >> iter 168000, loss: 0.005436
 >> iter 169000, loss: 0.035178
 >> iter 170000, loss: 0.016532
   Number of active neurons: 10
 >> iter 171000, loss: 0.009953
 >> iter 172000, loss: 0.016624
 >> iter 173000, loss: 0.009036
 >> iter 174000, loss: 0.012826
 >> iter 175000, loss: 0.007550
 >> iter 176000, loss: 0.005638
 >> iter 177000, loss: 0.004821
 >> iter 178000, loss: 0.004592
 >> iter 179000, loss: 0.026468
 >> iter 180000, loss: 0.020040
   Number of active neurons: 10
 >> iter 181000, loss: 0.010064
 >> iter 182000, loss: 0.006309
 >> iter 183000, loss: 0.004852
 >> iter 184000, loss: 0.004434
 >> iter 185000, loss: 0.008586
 >> iter 186000, loss: 0.005829
 >> iter 187000, loss: 0.004701
 >> iter 188000, loss: 0.005513
 >> iter 189000, loss: 0.004340
 >> iter 190000, loss: 0.017892
   Number of active neurons: 10
 >> iter 191000, loss: 0.009425
 >> iter 192000, loss: 0.005769
 >> iter 193000, loss: 0.006972
 >> iter 194000, loss: 0.004827
 >> iter 195000, loss: 0.003926
 >> iter 196000, loss: 0.004287
 >> iter 197000, loss: 0.003734
 >> iter 198000, loss: 0.003487
 >> iter 199000, loss: 0.010276
 >> iter 200000, loss: 0.006160
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.247642
 >> iter 2000, loss: 10.899383
 >> iter 3000, loss: 8.862342
 >> iter 4000, loss: 8.077103
 >> iter 5000, loss: 7.830282
 >> iter 6000, loss: 7.688680
 >> iter 7000, loss: 7.639389
 >> iter 8000, loss: 7.605915
 >> iter 9000, loss: 7.612682
 >> iter 10000, loss: 7.607190
   Number of active neurons: 10
 >> iter 11000, loss: 7.602513
 >> iter 12000, loss: 7.581074
 >> iter 13000, loss: 7.602308
 >> iter 14000, loss: 7.582081
 >> iter 15000, loss: 7.606302
 >> iter 16000, loss: 7.561815
 >> iter 17000, loss: 7.442415
 >> iter 18000, loss: 7.233055
 >> iter 19000, loss: 7.095968
 >> iter 20000, loss: 6.951018
   Number of active neurons: 10
 >> iter 21000, loss: 6.868440
 >> iter 22000, loss: 6.760547
 >> iter 23000, loss: 6.747424
 >> iter 24000, loss: 6.795738
 >> iter 25000, loss: 6.716796
 >> iter 26000, loss: 6.675536
 >> iter 27000, loss: 6.655501
 >> iter 28000, loss: 6.651413
 >> iter 29000, loss: 6.652382
 >> iter 30000, loss: 6.646792
   Number of active neurons: 10
 >> iter 31000, loss: 6.666608
 >> iter 32000, loss: 6.652158
 >> iter 33000, loss: 6.531266
 >> iter 34000, loss: 6.340592
 >> iter 35000, loss: 6.112772
 >> iter 36000, loss: 5.928106
 >> iter 37000, loss: 5.799803
 >> iter 38000, loss: 5.703813
 >> iter 39000, loss: 5.727326
 >> iter 40000, loss: 5.615279
   Number of active neurons: 10
 >> iter 41000, loss: 5.602783
 >> iter 42000, loss: 5.583684
 >> iter 43000, loss: 5.515474
 >> iter 44000, loss: 5.506458
 >> iter 45000, loss: 5.485598
 >> iter 46000, loss: 5.472247
 >> iter 47000, loss: 5.448744
 >> iter 48000, loss: 5.435683
 >> iter 49000, loss: 5.434403
 >> iter 50000, loss: 5.440049
   Number of active neurons: 10
 >> iter 51000, loss: 5.462136
 >> iter 52000, loss: 5.437868
 >> iter 53000, loss: 5.452511
 >> iter 54000, loss: 5.353180
 >> iter 55000, loss: 5.306755
 >> iter 56000, loss: 4.949754
 >> iter 57000, loss: 4.762395
 >> iter 58000, loss: 4.641208
 >> iter 59000, loss: 4.559115
 >> iter 60000, loss: 4.261146
   Number of active neurons: 10
 >> iter 61000, loss: 4.138800
 >> iter 62000, loss: 4.107565
 >> iter 63000, loss: 4.065713
 >> iter 64000, loss: 4.016854
 >> iter 65000, loss: 3.938728
 >> iter 66000, loss: 3.743236
 >> iter 67000, loss: 3.865287
 >> iter 68000, loss: 3.724365
 >> iter 69000, loss: 3.852429
 >> iter 70000, loss: 3.797238
   Number of active neurons: 10
 >> iter 71000, loss: 3.960133
 >> iter 72000, loss: 3.754168
 >> iter 73000, loss: 3.816833
 >> iter 74000, loss: 3.750750
 >> iter 75000, loss: 3.830822
 >> iter 76000, loss: 3.742252
 >> iter 77000, loss: 3.818993
 >> iter 78000, loss: 3.575239
 >> iter 79000, loss: 3.472671
 >> iter 80000, loss: 3.593992
   Number of active neurons: 10
 >> iter 81000, loss: 3.219491
 >> iter 82000, loss: 3.178244
 >> iter 83000, loss: 2.920815
 >> iter 84000, loss: 2.182955
 >> iter 85000, loss: 1.596476
 >> iter 86000, loss: 1.383072
 >> iter 87000, loss: 0.858358
 >> iter 88000, loss: 0.611194
 >> iter 89000, loss: 0.582468
 >> iter 90000, loss: 0.586259
   Number of active neurons: 10
 >> iter 91000, loss: 0.383617
 >> iter 92000, loss: 0.355076
 >> iter 93000, loss: 0.212579
 >> iter 94000, loss: 0.342190
 >> iter 95000, loss: 0.261716
 >> iter 96000, loss: 0.484203
 >> iter 97000, loss: 0.237388
 >> iter 98000, loss: 0.332675
 >> iter 99000, loss: 0.236973
 >> iter 100000, loss: 0.154881
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.471067
 >> iter 2000, loss: 11.102321
 >> iter 3000, loss: 8.929184
 >> iter 4000, loss: 8.117605
 >> iter 5000, loss: 7.767404
 >> iter 6000, loss: 7.644866
 >> iter 7000, loss: 7.609889
 >> iter 8000, loss: 7.564120
 >> iter 9000, loss: 7.559507
 >> iter 10000, loss: 7.539161
   Number of active neurons: 10
 >> iter 11000, loss: 7.545964
 >> iter 12000, loss: 7.534970
 >> iter 13000, loss: 7.566882
 >> iter 14000, loss: 7.538327
 >> iter 15000, loss: 7.542062
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 7.529825
 >> iter 17000, loss: 7.541747
 >> iter 18000, loss: 7.552176
 >> iter 19000, loss: 7.543062
 >> iter 20000, loss: 7.531572
   Number of active neurons: 10
 >> iter 21000, loss: 7.536518
 >> iter 22000, loss: 7.538156
 >> iter 23000, loss: 7.539558
 >> iter 24000, loss: 7.524686
 >> iter 25000, loss: 7.534002
 >> iter 26000, loss: 7.536710
 >> iter 27000, loss: 7.537740
 >> iter 28000, loss: 7.532078
 >> iter 29000, loss: 7.534808
 >> iter 30000, loss: 7.527816
   Number of active neurons: 10
 >> iter 31000, loss: 7.532017
 >> iter 32000, loss: 7.530401
 >> iter 33000, loss: 7.537879
 >> iter 34000, loss: 7.521078
 >> iter 35000, loss: 7.534427
 >> iter 36000, loss: 7.525565
 >> iter 37000, loss: 7.534979
 >> iter 38000, loss: 7.520520
 >> iter 39000, loss: 7.532514
 >> iter 40000, loss: 7.525290
   Number of active neurons: 10
 >> iter 41000, loss: 7.536298
 >> iter 42000, loss: 7.523086
 >> iter 43000, loss: 7.535573
 >> iter 44000, loss: 7.524151
 >> iter 45000, loss: 7.535748
 >> iter 46000, loss: 7.522229
 >> iter 47000, loss: 7.531986
 >> iter 48000, loss: 7.518003
 >> iter 49000, loss: 7.590577
 >> iter 50000, loss: 7.539297
   Number of active neurons: 10
 >> iter 51000, loss: 7.540499
 >> iter 52000, loss: 7.521016
 >> iter 53000, loss: 7.533045
 >> iter 54000, loss: 7.513401
 >> iter 55000, loss: 7.531945
 >> iter 56000, loss: 7.519755
 >> iter 57000, loss: 7.533960
 >> iter 58000, loss: 7.517537
 >> iter 59000, loss: 7.530437
 >> iter 60000, loss: 7.520870
   Number of active neurons: 10
 >> iter 61000, loss: 7.529449
 >> iter 62000, loss: 7.653134
 >> iter 63000, loss: 7.606276
 >> iter 64000, loss: 7.445085
 >> iter 65000, loss: 7.289456
 >> iter 66000, loss: 7.096647
 >> iter 67000, loss: 6.998905
 >> iter 68000, loss: 6.945157
 >> iter 69000, loss: 6.894821
 >> iter 70000, loss: 6.837024
   Number of active neurons: 10
 >> iter 71000, loss: 6.797270
 >> iter 72000, loss: 6.674685
 >> iter 73000, loss: 6.527898
 >> iter 74000, loss: 6.454381
 >> iter 75000, loss: 6.243121
 >> iter 76000, loss: 6.049145
 >> iter 77000, loss: 5.944724
 >> iter 78000, loss: 5.863218
 >> iter 79000, loss: 5.849608
 >> iter 80000, loss: 5.793754
   Number of active neurons: 10
 >> iter 81000, loss: 5.573865
 >> iter 82000, loss: 5.324839
 >> iter 83000, loss: 4.609313
 >> iter 84000, loss: 2.847795
 >> iter 85000, loss: 1.293731
 >> iter 86000, loss: 0.566746
 >> iter 87000, loss: 0.354935
 >> iter 88000, loss: 0.175864
 >> iter 89000, loss: 0.097625
 >> iter 90000, loss: 0.216285
   Number of active neurons: 10
 >> iter 91000, loss: 0.112331
 >> iter 92000, loss: 0.107403
 >> iter 93000, loss: 0.072498
 >> iter 94000, loss: 0.135384
 >> iter 95000, loss: 0.247147
 >> iter 96000, loss: 0.224894
 >> iter 97000, loss: 0.185628
 >> iter 98000, loss: 0.088183
 >> iter 99000, loss: 0.067229
 >> iter 100000, loss: 0.111460
   Number of active neurons: 10
 >> iter 101000, loss: 0.163447
 >> iter 102000, loss: 0.142643
 >> iter 103000, loss: 0.185917
 >> iter 104000, loss: 0.111127
 >> iter 105000, loss: 0.099782
 >> iter 106000, loss: 0.068346
 >> iter 107000, loss: 0.099474
 >> iter 108000, loss: 0.047328
 >> iter 109000, loss: 0.027362
 >> iter 110000, loss: 0.019182
   Number of active neurons: 10
 >> iter 111000, loss: 0.017127
 >> iter 112000, loss: 0.110614
 >> iter 113000, loss: 0.047392
 >> iter 114000, loss: 0.064462
 >> iter 115000, loss: 0.031324
 >> iter 116000, loss: 0.064280
 >> iter 117000, loss: 0.136956
 >> iter 118000, loss: 0.088841
 >> iter 119000, loss: 0.039348
 >> iter 120000, loss: 0.020390
   Number of active neurons: 10
 >> iter 121000, loss: 0.015601
 >> iter 122000, loss: 0.011248
 >> iter 123000, loss: 0.009047
 >> iter 124000, loss: 0.011167
 >> iter 125000, loss: 0.057070
 >> iter 126000, loss: 0.027061
 >> iter 127000, loss: 0.114200
 >> iter 128000, loss: 0.046893
 >> iter 129000, loss: 0.063841
 >> iter 130000, loss: 0.036601
   Number of active neurons: 10
 >> iter 131000, loss: 0.039304
 >> iter 132000, loss: 0.018713
 >> iter 133000, loss: 0.010542
 >> iter 134000, loss: 0.008052
 >> iter 135000, loss: 0.006198
 >> iter 136000, loss: 0.005426
 >> iter 137000, loss: 0.037214
 >> iter 138000, loss: 0.113379
 >> iter 139000, loss: 0.309713
 >> iter 140000, loss: 0.118031
   Number of active neurons: 10
 >> iter 141000, loss: 0.046949
 >> iter 142000, loss: 0.020961
 >> iter 143000, loss: 0.011529
 >> iter 144000, loss: 0.007723
 >> iter 145000, loss: 0.005884
 >> iter 146000, loss: 0.005072
 >> iter 147000, loss: 0.004766
 >> iter 148000, loss: 0.004424
 >> iter 149000, loss: 0.004178
 >> iter 150000, loss: 0.004249
   Number of active neurons: 10
 >> iter 151000, loss: 0.004140
 >> iter 152000, loss: 0.004321
 >> iter 153000, loss: 0.003844
 >> iter 154000, loss: 0.003724
 >> iter 155000, loss: 0.003520
 >> iter 156000, loss: 0.003242
 >> iter 157000, loss: 0.003182
 >> iter 158000, loss: 0.027004
 >> iter 159000, loss: 0.012180
 >> iter 160000, loss: 0.032927
   Number of active neurons: 10
 >> iter 161000, loss: 0.014878
 >> iter 162000, loss: 0.007442
 >> iter 163000, loss: 0.004611
 >> iter 164000, loss: 0.004166
 >> iter 165000, loss: 0.003241
 >> iter 166000, loss: 0.007717
 >> iter 167000, loss: 0.004497
 >> iter 168000, loss: 0.003329
 >> iter 169000, loss: 0.003248
 >> iter 170000, loss: 0.002823
   Number of active neurons: 10
 >> iter 171000, loss: 0.002621
 >> iter 172000, loss: 0.004123
 >> iter 173000, loss: 0.003451
 >> iter 174000, loss: 0.003703
 >> iter 175000, loss: 0.002753
 >> iter 176000, loss: 0.002419
 >> iter 177000, loss: 0.010929
 >> iter 178000, loss: 0.005524
 >> iter 179000, loss: 0.003312
 >> iter 180000, loss: 0.002530
   Number of active neurons: 10
 >> iter 181000, loss: 0.002229
 >> iter 182000, loss: 0.002172
 >> iter 183000, loss: 0.002037
 >> iter 184000, loss: 0.001997
 >> iter 185000, loss: 0.007529
 >> iter 186000, loss: 0.004153
 >> iter 187000, loss: 0.002767
 >> iter 188000, loss: 0.002190
 >> iter 189000, loss: 0.001934
 >> iter 190000, loss: 0.002445
   Number of active neurons: 10
 >> iter 191000, loss: 0.002611
 >> iter 192000, loss: 0.002124
 >> iter 193000, loss: 0.001848
 >> iter 194000, loss: 0.001754
 >> iter 195000, loss: 0.001751
 >> iter 196000, loss: 0.121978
 >> iter 197000, loss: 0.046143
 >> iter 198000, loss: 0.018366
 >> iter 199000, loss: 0.007878
 >> iter 200000, loss: 0.003983
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.326276
 >> iter 2000, loss: 10.975743
 >> iter 3000, loss: 8.895018
 >> iter 4000, loss: 8.082120
 >> iter 5000, loss: 7.777693
 >> iter 6000, loss: 7.652171
 >> iter 7000, loss: 7.612168
 >> iter 8000, loss: 7.589294
 >> iter 9000, loss: 7.584557
 >> iter 10000, loss: 7.595400
   Number of active neurons: 10
 >> iter 11000, loss: 7.584630
 >> iter 12000, loss: 7.567703
 >> iter 13000, loss: 7.574190
 >> iter 14000, loss: 7.564719
 >> iter 15000, loss: 7.569208
 >> iter 16000, loss: 7.564727
 >> iter 17000, loss: 7.573582
 >> iter 18000, loss: 7.558035
 >> iter 19000, loss: 7.564023
 >> iter 20000, loss: 7.556476
   Number of active neurons: 10
 >> iter 21000, loss: 7.565318
 >> iter 22000, loss: 7.558574
 >> iter 23000, loss: 7.565305
 >> iter 24000, loss: 7.560253
 >> iter 25000, loss: 7.568682
 >> iter 26000, loss: 7.556992
 >> iter 27000, loss: 7.564865
 >> iter 28000, loss: 7.559870
 >> iter 29000, loss: 7.577340
 >> iter 30000, loss: 7.563275
   Number of active neurons: 10
 >> iter 31000, loss: 7.565557
 >> iter 32000, loss: 7.582602
 >> iter 33000, loss: 7.573382
 >> iter 34000, loss: 7.561168
 >> iter 35000, loss: 7.569072
 >> iter 36000, loss: 7.561041
 >> iter 37000, loss: 7.563761
 >> iter 38000, loss: 7.553932
 >> iter 39000, loss: 7.563494
 >> iter 40000, loss: 7.557440
   Number of active neurons: 10
 >> iter 41000, loss: 7.561880
 >> iter 42000, loss: 7.549668
 >> iter 43000, loss: 7.555532
 >> iter 44000, loss: 7.540995
 >> iter 45000, loss: 7.589649
 >> iter 46000, loss: 7.626825
 >> iter 47000, loss: 7.596233
 >> iter 48000, loss: 7.406683
 >> iter 49000, loss: 7.224385
 >> iter 50000, loss: 7.006370
   Number of active neurons: 10
 >> iter 51000, loss: 6.847014
 >> iter 52000, loss: 6.823861
 >> iter 53000, loss: 6.713850
 >> iter 54000, loss: 6.541637
 >> iter 55000, loss: 6.418859
 >> iter 56000, loss: 6.336776
 >> iter 57000, loss: 6.288336
 >> iter 58000, loss: 6.219718
 >> iter 59000, loss: 6.194080
 >> iter 60000, loss: 6.107813
   Number of active neurons: 10
 >> iter 61000, loss: 6.044340
 >> iter 62000, loss: 5.917167
 >> iter 63000, loss: 5.749953
 >> iter 64000, loss: 5.631482
 >> iter 65000, loss: 5.537919
 >> iter 66000, loss: 5.268229
 >> iter 67000, loss: 3.684864
 >> iter 68000, loss: 2.751079
 >> iter 69000, loss: 1.853569
 >> iter 70000, loss: 1.232507
   Number of active neurons: 10
 >> iter 71000, loss: 1.120951
 >> iter 72000, loss: 0.867462
 >> iter 73000, loss: 0.922897
 >> iter 74000, loss: 0.646855
 >> iter 75000, loss: 0.553390
 >> iter 76000, loss: 0.511704
 >> iter 77000, loss: 0.596720
 >> iter 78000, loss: 0.602384
 >> iter 79000, loss: 0.543722
 >> iter 80000, loss: 0.481993
   Number of active neurons: 10
 >> iter 81000, loss: 0.500780
 >> iter 82000, loss: 0.387634
 >> iter 83000, loss: 0.408596
 >> iter 84000, loss: 0.330922
 >> iter 85000, loss: 0.322321
 >> iter 86000, loss: 0.235305
 >> iter 87000, loss: 0.243440
 >> iter 88000, loss: 0.171768
 >> iter 89000, loss: 0.286002
 >> iter 90000, loss: 0.368836
   Number of active neurons: 10
 >> iter 91000, loss: 0.309271
 >> iter 92000, loss: 0.408886
 >> iter 93000, loss: 0.282139
 >> iter 94000, loss: 0.282030
 >> iter 95000, loss: 0.241507
 >> iter 96000, loss: 0.208666
 >> iter 97000, loss: 0.318661
 >> iter 98000, loss: 0.283014
 >> iter 99000, loss: 0.235149
 >> iter 100000, loss: 0.274210
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.738007
 >> iter 2000, loss: 11.067022
 >> iter 3000, loss: 8.905642
 >> iter 4000, loss: 8.066317
 >> iter 5000, loss: 7.750070
 >> iter 6000, loss: 7.612696
 >> iter 7000, loss: 7.569413
 >> iter 8000, loss: 7.544550
 >> iter 9000, loss: 7.551654
 >> iter 10000, loss: 7.575926
   Number of active neurons: 10
 >> iter 11000, loss: 7.552742
 >> iter 12000, loss: 7.526622
 >> iter 13000, loss: 7.528883
 >> iter 14000, loss: 7.514013
 >> iter 15000, loss: 7.518311
 >> iter 16000, loss: 7.508923
 >> iter 17000, loss: 7.512566
 >> iter 18000, loss: 7.508619
 >> iter 19000, loss: 7.516754
 >> iter 20000, loss: 7.511357
   Number of active neurons: 9
 >> iter 21000, loss: 7.519340
 >> iter 22000, loss: 7.505892
 >> iter 23000, loss: 7.533269
 >> iter 24000, loss: 7.515163
 >> iter 25000, loss: 7.519481
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 7.507761
 >> iter 27000, loss: 7.517567
 >> iter 28000, loss: 7.526436
 >> iter 29000, loss: 7.526752
 >> iter 30000, loss: 7.511332
   Number of active neurons: 9
 >> iter 31000, loss: 7.521096
 >> iter 32000, loss: 7.513166
 >> iter 33000, loss: 7.518992
 >> iter 34000, loss: 7.511880
 >> iter 35000, loss: 7.520121
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 36000, loss: 7.528362
 >> iter 37000, loss: 7.527281
 >> iter 38000, loss: 7.508947
 >> iter 39000, loss: 7.516414
 >> iter 40000, loss: 7.507368
   Number of active neurons: 9
 >> iter 41000, loss: 7.516452
 >> iter 42000, loss: 7.502608
 >> iter 43000, loss: 7.516782
 >> iter 44000, loss: 7.500348
 >> iter 45000, loss: 7.574895
 >> iter 46000, loss: 7.525568
 >> iter 47000, loss: 7.528713
 >> iter 48000, loss: 7.505260
 >> iter 49000, loss: 7.519747
 >> iter 50000, loss: 7.500248
   Number of active neurons: 9
 >> iter 51000, loss: 7.514605
 >> iter 52000, loss: 7.494833
 >> iter 53000, loss: 7.515614
 >> iter 54000, loss: 7.498995
 >> iter 55000, loss: 7.513175
   Number of active neurons: 8
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 56000, loss: 7.502025
 >> iter 57000, loss: 7.515544
 >> iter 58000, loss: 7.502159
 >> iter 59000, loss: 7.516170
 >> iter 60000, loss: 7.504109
   Number of active neurons: 8
 >> iter 61000, loss: 7.515427
 >> iter 62000, loss: 7.496072
 >> iter 63000, loss: 7.512097
 >> iter 64000, loss: 7.502953
 >> iter 65000, loss: 7.512997
   Number of active neurons: 8
   SHOCK
   Setting new limit to 287500.0 iters...
 >> iter 66000, loss: 7.499655
 >> iter 67000, loss: 7.512350
 >> iter 68000, loss: 7.498545
 >> iter 69000, loss: 7.510899
 >> iter 70000, loss: 7.499597
   Number of active neurons: 8
 >> iter 71000, loss: 7.516282
 >> iter 72000, loss: 7.504425
 >> iter 73000, loss: 7.511944
 >> iter 74000, loss: 7.502643
 >> iter 75000, loss: 7.514529
   Number of active neurons: 8
   SHOCK
   Setting new limit to 293750.0 iters...
 >> iter 76000, loss: 7.499704
 >> iter 77000, loss: 7.513661
 >> iter 78000, loss: 7.504025
 >> iter 79000, loss: 7.511401
 >> iter 80000, loss: 7.504883
   Number of active neurons: 8
 >> iter 81000, loss: 7.514662
 >> iter 82000, loss: 7.503559
 >> iter 83000, loss: 7.511687
 >> iter 84000, loss: 7.504306
 >> iter 85000, loss: 7.512622
   Number of active neurons: 9
   SHOCK
   Setting new limit to 296875.0 iters...
 >> iter 86000, loss: 7.506858
 >> iter 87000, loss: 7.511692
 >> iter 88000, loss: 7.530578
 >> iter 89000, loss: 7.519535
 >> iter 90000, loss: 7.508764
   Number of active neurons: 9
 >> iter 91000, loss: 7.511077
 >> iter 92000, loss: 7.508595
 >> iter 93000, loss: 7.511455
 >> iter 94000, loss: 7.508208
 >> iter 95000, loss: 7.505268
 >> iter 96000, loss: 7.505791
 >> iter 97000, loss: 7.508924
 >> iter 98000, loss: 7.508737
 >> iter 99000, loss: 7.509530
 >> iter 100000, loss: 7.507529
   Number of active neurons: 8
   SHOCK
   Setting new limit to 298437.5 iters...
   Number of active neurons: 8
 >> iter 101000, loss: 7.507842
 >> iter 102000, loss: 7.508488
 >> iter 103000, loss: 7.511433
 >> iter 104000, loss: 7.512209
 >> iter 105000, loss: 7.509981
   Number of active neurons: 8
   SHOCK
   Setting new limit to 299218.75 iters...
 >> iter 106000, loss: 7.510214
 >> iter 107000, loss: 7.512936
 >> iter 108000, loss: 7.506517
 >> iter 109000, loss: 7.508666
 >> iter 110000, loss: 7.503922
   Number of active neurons: 8
 >> iter 111000, loss: 7.506690
 >> iter 112000, loss: 7.502246
 >> iter 113000, loss: 7.506558
 >> iter 114000, loss: 7.502406
 >> iter 115000, loss: 7.511512
   Number of active neurons: 9
   SHOCK
   Setting new limit to 299609.375 iters...
 >> iter 116000, loss: 7.510377
 >> iter 117000, loss: 7.512602
 >> iter 118000, loss: 7.508205
 >> iter 119000, loss: 7.511915
 >> iter 120000, loss: 7.506378
   Number of active neurons: 9
 >> iter 121000, loss: 7.511544
 >> iter 122000, loss: 7.510003
 >> iter 123000, loss: 7.518993
 >> iter 124000, loss: 7.508325
 >> iter 125000, loss: 7.513161
   Number of active neurons: 8
   SHOCK
   Setting new limit to 299804.6875 iters...
 >> iter 126000, loss: 7.510749
 >> iter 127000, loss: 7.506444
 >> iter 128000, loss: 7.557774
 >> iter 129000, loss: 7.530959
 >> iter 130000, loss: 7.596169
   Number of active neurons: 9
   SHOCK
   Setting new limit to 299902.34375 iters...
   Number of active neurons: 9
 >> iter 131000, loss: 7.547738
 >> iter 132000, loss: 7.541009
 >> iter 133000, loss: 7.544511
 >> iter 134000, loss: 7.551477
 >> iter 135000, loss: 7.524911
 >> iter 136000, loss: 7.513633
 >> iter 137000, loss: 7.519475
 >> iter 138000, loss: 7.470522
 >> iter 139000, loss: 7.357549
 >> iter 140000, loss: 7.158417
   Number of active neurons: 10
 >> iter 141000, loss: 6.922619
 >> iter 142000, loss: 6.777768
 >> iter 143000, loss: 6.435100
 >> iter 144000, loss: 6.155505
 >> iter 145000, loss: 6.021467
 >> iter 146000, loss: 5.910082
 >> iter 147000, loss: 5.922095
 >> iter 148000, loss: 5.853630
 >> iter 149000, loss: 5.715559
 >> iter 150000, loss: 5.646575
   Number of active neurons: 10
 >> iter 151000, loss: 5.593646
 >> iter 152000, loss: 5.546528
 >> iter 153000, loss: 5.470085
 >> iter 154000, loss: 5.373722
 >> iter 155000, loss: 5.258768
 >> iter 156000, loss: 5.288060
 >> iter 157000, loss: 5.202538
 >> iter 158000, loss: 5.174237
 >> iter 159000, loss: 5.175021
 >> iter 160000, loss: 5.172823
   Number of active neurons: 10
 >> iter 161000, loss: 5.173204
 >> iter 162000, loss: 5.116752
 >> iter 163000, loss: 5.084146
 >> iter 164000, loss: 5.045842
 >> iter 165000, loss: 5.044797
 >> iter 166000, loss: 5.030996
 >> iter 167000, loss: 4.977063
 >> iter 168000, loss: 4.988347
 >> iter 169000, loss: 4.937654
 >> iter 170000, loss: 4.955962
   Number of active neurons: 10
 >> iter 171000, loss: 4.783928
 >> iter 172000, loss: 4.788006
 >> iter 173000, loss: 4.662009
 >> iter 174000, loss: 4.682467
 >> iter 175000, loss: 4.702093
 >> iter 176000, loss: 4.701080
 >> iter 177000, loss: 4.601467
 >> iter 178000, loss: 4.590880
 >> iter 179000, loss: 4.573115
 >> iter 180000, loss: 4.637002
   Number of active neurons: 10
 >> iter 181000, loss: 4.558966
 >> iter 182000, loss: 4.565259
 >> iter 183000, loss: 4.543216
 >> iter 184000, loss: 4.570477
 >> iter 185000, loss: 4.513303
 >> iter 186000, loss: 4.551652
 >> iter 187000, loss: 4.454917
 >> iter 188000, loss: 4.237756
 >> iter 189000, loss: 4.006761
 >> iter 190000, loss: 3.942810
   Number of active neurons: 10
 >> iter 191000, loss: 3.776855
 >> iter 192000, loss: 3.773781
 >> iter 193000, loss: 3.667278
 >> iter 194000, loss: 3.004461
 >> iter 195000, loss: 2.631740
 >> iter 196000, loss: 1.561761
 >> iter 197000, loss: 1.428080
 >> iter 198000, loss: 1.237224
 >> iter 199000, loss: 1.347950
 >> iter 200000, loss: 1.181841
   Number of active neurons: 10
 >> iter 201000, loss: 1.290031
 >> iter 202000, loss: 1.021347
 >> iter 203000, loss: 1.006086
 >> iter 204000, loss: 0.962348
 >> iter 205000, loss: 0.849373
 >> iter 206000, loss: 0.807933
 >> iter 207000, loss: 0.682376
 >> iter 208000, loss: 0.681131
 >> iter 209000, loss: 0.817045
 >> iter 210000, loss: 0.577309
   Number of active neurons: 10
 >> iter 211000, loss: 0.519587
 >> iter 212000, loss: 0.656973
 >> iter 213000, loss: 0.591711
 >> iter 214000, loss: 0.567566
 >> iter 215000, loss: 0.558647
 >> iter 216000, loss: 0.411858
 >> iter 217000, loss: 0.319215
 >> iter 218000, loss: 0.547780
 >> iter 219000, loss: 0.585073
 >> iter 220000, loss: 0.472691
   Number of active neurons: 10
 >> iter 221000, loss: 0.346903
 >> iter 222000, loss: 0.526482
 >> iter 223000, loss: 0.537061
 >> iter 224000, loss: 0.410642
 >> iter 225000, loss: 0.538155
 >> iter 226000, loss: 0.609251
 >> iter 227000, loss: 0.462514
 >> iter 228000, loss: 0.610806
 >> iter 229000, loss: 0.618159
 >> iter 230000, loss: 0.491701
   Number of active neurons: 10
 >> iter 231000, loss: 0.378295
 >> iter 232000, loss: 0.466879
 >> iter 233000, loss: 0.476506
 >> iter 234000, loss: 0.333272
 >> iter 235000, loss: 0.553047
 >> iter 236000, loss: 0.447566
 >> iter 237000, loss: 0.493312
 >> iter 238000, loss: 0.483429
 >> iter 239000, loss: 0.469732
 >> iter 240000, loss: 0.571926
   Number of active neurons: 10
 >> iter 241000, loss: 0.584598
 >> iter 242000, loss: 0.409843
 >> iter 243000, loss: 0.644794
 >> iter 244000, loss: 0.522634
 >> iter 245000, loss: 0.450668
 >> iter 246000, loss: 0.359954
 >> iter 247000, loss: 0.462165
 >> iter 248000, loss: 0.378683
 >> iter 249000, loss: 0.379203
 >> iter 250000, loss: 0.429168
   Number of active neurons: 10
 >> iter 251000, loss: 0.280603
 >> iter 252000, loss: 0.173906
 >> iter 253000, loss: 0.201222
 >> iter 254000, loss: 0.260378
 >> iter 255000, loss: 0.235268
 >> iter 256000, loss: 0.243730
 >> iter 257000, loss: 0.263328
 >> iter 258000, loss: 0.234805
 >> iter 259000, loss: 0.280119
 >> iter 260000, loss: 0.561492
   Number of active neurons: 10
 >> iter 261000, loss: 0.391387
 >> iter 262000, loss: 0.359236
 >> iter 263000, loss: 0.259024
 >> iter 264000, loss: 0.301708
 >> iter 265000, loss: 0.197656
 >> iter 266000, loss: 0.271781
 >> iter 267000, loss: 0.348170
 >> iter 268000, loss: 0.207153
 >> iter 269000, loss: 0.413484
 >> iter 270000, loss: 0.417287
   Number of active neurons: 10
 >> iter 271000, loss: 0.327323
 >> iter 272000, loss: 0.209015
 >> iter 273000, loss: 0.183889
 >> iter 274000, loss: 0.191565
 >> iter 275000, loss: 0.114212
 >> iter 276000, loss: 0.303441
 >> iter 277000, loss: 0.239342
 >> iter 278000, loss: 0.165232
 >> iter 279000, loss: 0.114859
 >> iter 280000, loss: 0.129136
   Number of active neurons: 10
 >> iter 281000, loss: 0.178564
 >> iter 282000, loss: 0.140350
 >> iter 283000, loss: 0.146147
 >> iter 284000, loss: 0.123838
 >> iter 285000, loss: 0.121345
 >> iter 286000, loss: 0.179903
 >> iter 287000, loss: 0.092917
 >> iter 288000, loss: 0.049892
 >> iter 289000, loss: 0.066621
 >> iter 290000, loss: 0.033361
   Number of active neurons: 10
 >> iter 291000, loss: 0.045246
 >> iter 292000, loss: 0.067508
 >> iter 293000, loss: 0.086718
 >> iter 294000, loss: 0.084593
 >> iter 295000, loss: 0.075871
 >> iter 296000, loss: 0.035143
 >> iter 297000, loss: 0.109046
 >> iter 298000, loss: 0.096604
 >> iter 299000, loss: 0.094158
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.210122
 >> iter 2000, loss: 10.934403
 >> iter 3000, loss: 8.913671
 >> iter 4000, loss: 8.164015
 >> iter 5000, loss: 7.812907
 >> iter 6000, loss: 7.660874
 >> iter 7000, loss: 7.608624
 >> iter 8000, loss: 7.580288
 >> iter 9000, loss: 7.623263
 >> iter 10000, loss: 7.574615
   Number of active neurons: 10
 >> iter 11000, loss: 7.579950
 >> iter 12000, loss: 7.578528
 >> iter 13000, loss: 7.571838
 >> iter 14000, loss: 7.556887
 >> iter 15000, loss: 7.558718
 >> iter 16000, loss: 7.555318
 >> iter 17000, loss: 7.564540
 >> iter 18000, loss: 7.632615
 >> iter 19000, loss: 7.580965
 >> iter 20000, loss: 7.552403
   Number of active neurons: 10
 >> iter 21000, loss: 7.558951
 >> iter 22000, loss: 7.548838
 >> iter 23000, loss: 7.553085
 >> iter 24000, loss: 7.540170
 >> iter 25000, loss: 7.548745
 >> iter 26000, loss: 7.541435
 >> iter 27000, loss: 7.548731
 >> iter 28000, loss: 7.557683
 >> iter 29000, loss: 7.559755
 >> iter 30000, loss: 7.548833
   Number of active neurons: 10
 >> iter 31000, loss: 7.557147
 >> iter 32000, loss: 7.545870
 >> iter 33000, loss: 7.554141
 >> iter 34000, loss: 7.548594
 >> iter 35000, loss: 7.551437
 >> iter 36000, loss: 7.546379
 >> iter 37000, loss: 7.554597
 >> iter 38000, loss: 7.540694
 >> iter 39000, loss: 7.553233
 >> iter 40000, loss: 7.541242
   Number of active neurons: 10
 >> iter 41000, loss: 7.550416
 >> iter 42000, loss: 7.542462
 >> iter 43000, loss: 7.549385
 >> iter 44000, loss: 7.539495
 >> iter 45000, loss: 7.554127
 >> iter 46000, loss: 7.540652
 >> iter 47000, loss: 7.684096
 >> iter 48000, loss: 7.579537
 >> iter 49000, loss: 7.568020
 >> iter 50000, loss: 7.630520
   Number of active neurons: 10
 >> iter 51000, loss: 7.709736
 >> iter 52000, loss: 7.533910
 >> iter 53000, loss: 7.487812
 >> iter 54000, loss: 7.333175
 >> iter 55000, loss: 7.164163
 >> iter 56000, loss: 7.036547
 >> iter 57000, loss: 6.884269
 >> iter 58000, loss: 6.810501
 >> iter 59000, loss: 6.736447
 >> iter 60000, loss: 6.569059
   Number of active neurons: 10
 >> iter 61000, loss: 6.324122
 >> iter 62000, loss: 6.152819
 >> iter 63000, loss: 6.051108
 >> iter 64000, loss: 5.922758
 >> iter 65000, loss: 5.777237
 >> iter 66000, loss: 5.616934
 >> iter 67000, loss: 5.502864
 >> iter 68000, loss: 5.499844
 >> iter 69000, loss: 5.440066
 >> iter 70000, loss: 5.422711
   Number of active neurons: 10
 >> iter 71000, loss: 5.337966
 >> iter 72000, loss: 5.221797
 >> iter 73000, loss: 5.170962
 >> iter 74000, loss: 5.093297
 >> iter 75000, loss: 5.051679
 >> iter 76000, loss: 5.006692
 >> iter 77000, loss: 4.969329
 >> iter 78000, loss: 4.947857
 >> iter 79000, loss: 4.959773
 >> iter 80000, loss: 4.935457
   Number of active neurons: 10
 >> iter 81000, loss: 5.087540
 >> iter 82000, loss: 4.969198
 >> iter 83000, loss: 4.935191
 >> iter 84000, loss: 4.911343
 >> iter 85000, loss: 4.819751
 >> iter 86000, loss: 4.676603
 >> iter 87000, loss: 4.696450
 >> iter 88000, loss: 4.613717
 >> iter 89000, loss: 4.601726
 >> iter 90000, loss: 4.532091
   Number of active neurons: 10
 >> iter 91000, loss: 4.498673
 >> iter 92000, loss: 4.589284
 >> iter 93000, loss: 4.523540
 >> iter 94000, loss: 4.499365
 >> iter 95000, loss: 4.483293
 >> iter 96000, loss: 4.494741
 >> iter 97000, loss: 4.553193
 >> iter 98000, loss: 4.523267
 >> iter 99000, loss: 4.487098
 >> iter 100000, loss: 4.497922
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 12.549749005
   - Test - Long: 23.2888355582
   - Test - Big: 12.2408775912
   - Test - A: 16.2722485168
   - Test - B: 3.2531164589
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.399699
 >> iter 2000, loss: 11.024226
 >> iter 3000, loss: 9.073787
 >> iter 4000, loss: 8.156998
 >> iter 5000, loss: 7.819513
 >> iter 6000, loss: 7.673498
 >> iter 7000, loss: 7.603898
 >> iter 8000, loss: 7.568671
 >> iter 9000, loss: 7.563062
 >> iter 10000, loss: 7.550249
   Number of active neurons: 10
 >> iter 11000, loss: 7.565555
 >> iter 12000, loss: 7.554705
 >> iter 13000, loss: 7.557539
 >> iter 14000, loss: 7.557812
 >> iter 15000, loss: 7.556151
 >> iter 16000, loss: 7.537632
 >> iter 17000, loss: 7.545833
 >> iter 18000, loss: 7.527478
 >> iter 19000, loss: 7.559440
 >> iter 20000, loss: 7.536297
   Number of active neurons: 10
 >> iter 21000, loss: 7.536335
 >> iter 22000, loss: 7.526785
 >> iter 23000, loss: 7.531610
 >> iter 24000, loss: 7.573169
 >> iter 25000, loss: 7.551428
 >> iter 26000, loss: 7.529167
 >> iter 27000, loss: 7.534619
 >> iter 28000, loss: 7.527290
 >> iter 29000, loss: 7.533090
 >> iter 30000, loss: 7.523624
   Number of active neurons: 10
 >> iter 31000, loss: 7.554473
 >> iter 32000, loss: 7.534691
 >> iter 33000, loss: 7.536711
 >> iter 34000, loss: 7.525914
 >> iter 35000, loss: 7.525843
 >> iter 36000, loss: 7.586298
 >> iter 37000, loss: 7.567415
 >> iter 38000, loss: 7.593791
 >> iter 39000, loss: 7.501037
 >> iter 40000, loss: 7.400554
   Number of active neurons: 10
 >> iter 41000, loss: 7.412348
 >> iter 42000, loss: 7.139825
 >> iter 43000, loss: 6.964245
 >> iter 44000, loss: 6.820450
 >> iter 45000, loss: 6.678029
 >> iter 46000, loss: 6.477892
 >> iter 47000, loss: 6.411425
 >> iter 48000, loss: 6.464388
 >> iter 49000, loss: 6.338341
 >> iter 50000, loss: 6.274529
   Number of active neurons: 10
 >> iter 51000, loss: 6.236183
 >> iter 52000, loss: 6.184155
 >> iter 53000, loss: 6.155669
 >> iter 54000, loss: 6.103889
 >> iter 55000, loss: 6.116502
 >> iter 56000, loss: 6.059059
 >> iter 57000, loss: 6.093716
 >> iter 58000, loss: 6.138098
 >> iter 59000, loss: 6.087470
 >> iter 60000, loss: 6.074552
   Number of active neurons: 10
 >> iter 61000, loss: 6.000827
 >> iter 62000, loss: 5.993988
 >> iter 63000, loss: 5.994586
 >> iter 64000, loss: 6.049347
 >> iter 65000, loss: 5.995093
 >> iter 66000, loss: 5.908457
 >> iter 67000, loss: 5.803584
 >> iter 68000, loss: 5.877503
 >> iter 69000, loss: 5.678128
 >> iter 70000, loss: 5.485246
   Number of active neurons: 10
 >> iter 71000, loss: 5.463246
 >> iter 72000, loss: 4.983073
 >> iter 73000, loss: 4.766608
 >> iter 74000, loss: 4.511970
 >> iter 75000, loss: 4.427818
 >> iter 76000, loss: 4.542247
 >> iter 77000, loss: 3.853479
 >> iter 78000, loss: 3.358754
 >> iter 79000, loss: 2.481881
 >> iter 80000, loss: 2.384320
   Number of active neurons: 10
 >> iter 81000, loss: 2.079436
 >> iter 82000, loss: 1.905543
 >> iter 83000, loss: 2.021441
 >> iter 84000, loss: 1.802882
 >> iter 85000, loss: 1.407875
 >> iter 86000, loss: 1.536209
 >> iter 87000, loss: 1.532403
 >> iter 88000, loss: 1.491662
 >> iter 89000, loss: 1.488171
 >> iter 90000, loss: 1.566778
   Number of active neurons: 10
 >> iter 91000, loss: 1.362974
 >> iter 92000, loss: 1.394421
 >> iter 93000, loss: 1.301375
 >> iter 94000, loss: 1.326012
 >> iter 95000, loss: 1.329633
 >> iter 96000, loss: 1.381354
 >> iter 97000, loss: 1.373139
 >> iter 98000, loss: 1.285275
 >> iter 99000, loss: 1.249453
 >> iter 100000, loss: 1.317890
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 1.72796544069
   - Test - Long: 3.73481325934
   - Test - Big: 1.89598104019
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.175670
 >> iter 2000, loss: 10.973339
 >> iter 3000, loss: 8.957042
 >> iter 4000, loss: 8.128788
 >> iter 5000, loss: 7.936801
 >> iter 6000, loss: 7.698384
 >> iter 7000, loss: 7.617567
 >> iter 8000, loss: 7.598142
 >> iter 9000, loss: 7.574078
 >> iter 10000, loss: 7.557317
   Number of active neurons: 8
 >> iter 11000, loss: 7.558292
 >> iter 12000, loss: 7.543609
 >> iter 13000, loss: 7.549595
 >> iter 14000, loss: 7.536646
 >> iter 15000, loss: 7.546329
 >> iter 16000, loss: 7.538413
 >> iter 17000, loss: 7.549556
 >> iter 18000, loss: 7.537770
 >> iter 19000, loss: 7.546480
 >> iter 20000, loss: 7.536528
   Number of active neurons: 8
 >> iter 21000, loss: 7.544726
 >> iter 22000, loss: 7.533377
 >> iter 23000, loss: 7.600277
 >> iter 24000, loss: 7.555263
 >> iter 25000, loss: 7.555981
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 7.541702
 >> iter 27000, loss: 7.547195
 >> iter 28000, loss: 7.531936
 >> iter 29000, loss: 7.571341
 >> iter 30000, loss: 7.531742
   Number of active neurons: 10
 >> iter 31000, loss: 7.463163
 >> iter 32000, loss: 7.358753
 >> iter 33000, loss: 7.194712
 >> iter 34000, loss: 7.021521
 >> iter 35000, loss: 6.893441
 >> iter 36000, loss: 6.808069
 >> iter 37000, loss: 6.665307
 >> iter 38000, loss: 6.508089
 >> iter 39000, loss: 6.372818
 >> iter 40000, loss: 6.232281
   Number of active neurons: 10
 >> iter 41000, loss: 6.174340
 >> iter 42000, loss: 6.031137
 >> iter 43000, loss: 5.980913
 >> iter 44000, loss: 5.860392
 >> iter 45000, loss: 5.659954
 >> iter 46000, loss: 3.887329
 >> iter 47000, loss: 1.908587
 >> iter 48000, loss: 1.225833
 >> iter 49000, loss: 0.789464
 >> iter 50000, loss: 0.757529
   Number of active neurons: 10
 >> iter 51000, loss: 0.423252
 >> iter 52000, loss: 0.293290
 >> iter 53000, loss: 0.184499
 >> iter 54000, loss: 0.232252
 >> iter 55000, loss: 0.186789
 >> iter 56000, loss: 0.244030
 >> iter 57000, loss: 0.369490
 >> iter 58000, loss: 0.208165
 >> iter 59000, loss: 0.095602
 >> iter 60000, loss: 0.054845
   Number of active neurons: 10
 >> iter 61000, loss: 0.103795
 >> iter 62000, loss: 0.159138
 >> iter 63000, loss: 0.189449
 >> iter 64000, loss: 0.112408
 >> iter 65000, loss: 0.190061
 >> iter 66000, loss: 0.137939
 >> iter 67000, loss: 0.063411
 >> iter 68000, loss: 0.034267
 >> iter 69000, loss: 0.021897
 >> iter 70000, loss: 0.140793
   Number of active neurons: 10
 >> iter 71000, loss: 0.161811
 >> iter 72000, loss: 0.147995
 >> iter 73000, loss: 0.067856
 >> iter 74000, loss: 0.210149
 >> iter 75000, loss: 0.123049
 >> iter 76000, loss: 0.116293
 >> iter 77000, loss: 0.122634
 >> iter 78000, loss: 0.127994
 >> iter 79000, loss: 0.072980
 >> iter 80000, loss: 0.121500
   Number of active neurons: 10
 >> iter 81000, loss: 0.058306
 >> iter 82000, loss: 0.140614
 >> iter 83000, loss: 0.136418
 >> iter 84000, loss: 0.061431
 >> iter 85000, loss: 0.061333
 >> iter 86000, loss: 0.031172
 >> iter 87000, loss: 0.076739
 >> iter 88000, loss: 0.036487
 >> iter 89000, loss: 0.022914
 >> iter 90000, loss: 0.031596
   Number of active neurons: 10
 >> iter 91000, loss: 0.017229
 >> iter 92000, loss: 0.011914
 >> iter 93000, loss: 0.018526
 >> iter 94000, loss: 0.012128
 >> iter 95000, loss: 0.009054
 >> iter 96000, loss: 0.007803
 >> iter 97000, loss: 0.007648
 >> iter 98000, loss: 0.008042
 >> iter 99000, loss: 0.016171
 >> iter 100000, loss: 0.009830
   Number of active neurons: 10
 >> iter 101000, loss: 0.007351
 >> iter 102000, loss: 0.024587
 >> iter 103000, loss: 0.012573
 >> iter 104000, loss: 0.016258
 >> iter 105000, loss: 0.009365
 >> iter 106000, loss: 0.007134
 >> iter 107000, loss: 0.011521
 >> iter 108000, loss: 0.034837
 >> iter 109000, loss: 0.015991
 >> iter 110000, loss: 0.009387
   Number of active neurons: 10
 >> iter 111000, loss: 0.031590
 >> iter 112000, loss: 0.015313
 >> iter 113000, loss: 0.009287
 >> iter 114000, loss: 0.009320
 >> iter 115000, loss: 0.037984
 >> iter 116000, loss: 0.019942
 >> iter 117000, loss: 0.071437
 >> iter 118000, loss: 0.029923
 >> iter 119000, loss: 0.013922
 >> iter 120000, loss: 0.024911
   Number of active neurons: 10
 >> iter 121000, loss: 0.017722
 >> iter 122000, loss: 0.009204
 >> iter 123000, loss: 0.005863
 >> iter 124000, loss: 0.004577
 >> iter 125000, loss: 0.004386
 >> iter 126000, loss: 0.004536
 >> iter 127000, loss: 0.054416
 >> iter 128000, loss: 0.022575
 >> iter 129000, loss: 0.085049
 >> iter 130000, loss: 0.034722
   Number of active neurons: 10
 >> iter 131000, loss: 0.113628
 >> iter 132000, loss: 0.045149
 >> iter 133000, loss: 0.019747
 >> iter 134000, loss: 0.009852
 >> iter 135000, loss: 0.006233
 >> iter 136000, loss: 0.005172
 >> iter 137000, loss: 0.004371
 >> iter 138000, loss: 0.003898
 >> iter 139000, loss: 0.006684
 >> iter 140000, loss: 0.004651
   Number of active neurons: 10
 >> iter 141000, loss: 0.003783
 >> iter 142000, loss: 0.003475
 >> iter 143000, loss: 0.004102
 >> iter 144000, loss: 0.003452
 >> iter 145000, loss: 0.020262
 >> iter 146000, loss: 0.009330
 >> iter 147000, loss: 0.005381
 >> iter 148000, loss: 0.003815
 >> iter 149000, loss: 0.003170
 >> iter 150000, loss: 0.002936
   Number of active neurons: 10
 >> iter 151000, loss: 0.007027
 >> iter 152000, loss: 0.063265
 >> iter 153000, loss: 0.025228
 >> iter 154000, loss: 0.011190
 >> iter 155000, loss: 0.005811
 >> iter 156000, loss: 0.003958
 >> iter 157000, loss: 0.003105
 >> iter 158000, loss: 0.002843
 >> iter 159000, loss: 0.002733
 >> iter 160000, loss: 0.002942
   Number of active neurons: 10
 >> iter 161000, loss: 0.007637
 >> iter 162000, loss: 0.004689
 >> iter 163000, loss: 0.003357
 >> iter 164000, loss: 0.005881
 >> iter 165000, loss: 0.039906
 >> iter 166000, loss: 0.025617
 >> iter 167000, loss: 0.010992
 >> iter 168000, loss: 0.006075
 >> iter 169000, loss: 0.004051
 >> iter 170000, loss: 0.002967
   Number of active neurons: 10
 >> iter 171000, loss: 0.040507
 >> iter 172000, loss: 0.016869
 >> iter 173000, loss: 0.007678
 >> iter 174000, loss: 0.004377
 >> iter 175000, loss: 0.003152
 >> iter 176000, loss: 0.002623
 >> iter 177000, loss: 0.003122
 >> iter 178000, loss: 0.002493
 >> iter 179000, loss: 0.023329
 >> iter 180000, loss: 0.010163
   Number of active neurons: 10
 >> iter 181000, loss: 0.006798
 >> iter 182000, loss: 0.007554
 >> iter 183000, loss: 0.086110
 >> iter 184000, loss: 0.113421
 >> iter 185000, loss: 0.043336
 >> iter 186000, loss: 0.022150
 >> iter 187000, loss: 0.028684
 >> iter 188000, loss: 0.012208
 >> iter 189000, loss: 0.006032
 >> iter 190000, loss: 0.003671
   Number of active neurons: 10
 >> iter 191000, loss: 0.008609
 >> iter 192000, loss: 0.004558
 >> iter 193000, loss: 0.003184
 >> iter 194000, loss: 0.002821
 >> iter 195000, loss: 0.002473
 >> iter 196000, loss: 0.004359
 >> iter 197000, loss: 0.003213
 >> iter 198000, loss: 0.002735
 >> iter 199000, loss: 0.015878
 >> iter 200000, loss: 0.096426
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.355019
 >> iter 2000, loss: 11.018924
 >> iter 3000, loss: 8.949362
 >> iter 4000, loss: 8.105476
 >> iter 5000, loss: 7.796206
 >> iter 6000, loss: 7.661648
 >> iter 7000, loss: 7.632175
 >> iter 8000, loss: 7.591600
 >> iter 9000, loss: 7.593068
 >> iter 10000, loss: 7.579686
   Number of active neurons: 10
 >> iter 11000, loss: 7.593496
 >> iter 12000, loss: 7.609271
 >> iter 13000, loss: 7.583853
 >> iter 14000, loss: 7.571656
 >> iter 15000, loss: 7.570929
 >> iter 16000, loss: 7.553003
 >> iter 17000, loss: 7.557205
 >> iter 18000, loss: 7.561976
 >> iter 19000, loss: 7.561819
 >> iter 20000, loss: 7.547036
   Number of active neurons: 10
 >> iter 21000, loss: 7.554304
 >> iter 22000, loss: 7.549548
 >> iter 23000, loss: 7.555142
 >> iter 24000, loss: 7.546733
 >> iter 25000, loss: 7.550302
 >> iter 26000, loss: 7.540658
 >> iter 27000, loss: 7.545576
 >> iter 28000, loss: 7.541081
 >> iter 29000, loss: 7.549794
 >> iter 30000, loss: 7.544032
   Number of active neurons: 10
 >> iter 31000, loss: 7.542629
 >> iter 32000, loss: 7.550498
 >> iter 33000, loss: 7.557189
 >> iter 34000, loss: 7.545532
 >> iter 35000, loss: 7.548664
 >> iter 36000, loss: 7.538066
 >> iter 37000, loss: 7.548047
 >> iter 38000, loss: 7.541795
 >> iter 39000, loss: 7.551947
 >> iter 40000, loss: 7.542516
   Number of active neurons: 10
 >> iter 41000, loss: 7.551004
 >> iter 42000, loss: 7.540422
 >> iter 43000, loss: 7.549962
 >> iter 44000, loss: 7.537859
 >> iter 45000, loss: 7.548300
 >> iter 46000, loss: 7.538728
 >> iter 47000, loss: 7.561571
 >> iter 48000, loss: 7.575274
 >> iter 49000, loss: 7.556641
 >> iter 50000, loss: 7.538741
   Number of active neurons: 10
 >> iter 51000, loss: 7.552782
 >> iter 52000, loss: 7.533918
 >> iter 53000, loss: 7.547731
 >> iter 54000, loss: 7.534448
 >> iter 55000, loss: 7.545035
 >> iter 56000, loss: 7.535549
 >> iter 57000, loss: 7.546128
 >> iter 58000, loss: 7.535030
 >> iter 59000, loss: 7.547541
 >> iter 60000, loss: 7.538811
   Number of active neurons: 10
 >> iter 61000, loss: 7.546653
 >> iter 62000, loss: 7.534815
 >> iter 63000, loss: 7.554884
 >> iter 64000, loss: 7.542661
 >> iter 65000, loss: 7.545534
 >> iter 66000, loss: 7.536868
 >> iter 67000, loss: 7.548727
 >> iter 68000, loss: 7.537550
 >> iter 69000, loss: 7.545076
 >> iter 70000, loss: 7.563537
   Number of active neurons: 10
 >> iter 71000, loss: 7.556330
 >> iter 72000, loss: 7.540191
 >> iter 73000, loss: 7.544003
 >> iter 74000, loss: 7.538016
 >> iter 75000, loss: 7.546972
 >> iter 76000, loss: 7.537073
 >> iter 77000, loss: 7.547699
 >> iter 78000, loss: 7.535626
 >> iter 79000, loss: 7.544258
 >> iter 80000, loss: 7.536927
   Number of active neurons: 10
 >> iter 81000, loss: 7.540740
 >> iter 82000, loss: 7.538999
 >> iter 83000, loss: 7.544472
 >> iter 84000, loss: 7.539268
 >> iter 85000, loss: 7.544169
 >> iter 86000, loss: 7.535966
 >> iter 87000, loss: 7.542718
 >> iter 88000, loss: 7.536877
 >> iter 89000, loss: 7.538714
 >> iter 90000, loss: 7.537903
   Number of active neurons: 9
 >> iter 91000, loss: 7.542356
 >> iter 92000, loss: 7.542946
 >> iter 93000, loss: 7.557259
 >> iter 94000, loss: 7.547581
 >> iter 95000, loss: 7.540283
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 96000, loss: 7.540767
 >> iter 97000, loss: 7.538141
 >> iter 98000, loss: 7.540880
 >> iter 99000, loss: 7.540053
 >> iter 100000, loss: 7.540639
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 9
 >> iter 101000, loss: 7.519392
 >> iter 102000, loss: 7.503268
 >> iter 103000, loss: 7.430840
 >> iter 104000, loss: 7.324543
 >> iter 105000, loss: 7.153706
 >> iter 106000, loss: 7.027867
 >> iter 107000, loss: 6.915262
 >> iter 108000, loss: 6.723987
 >> iter 109000, loss: 6.510545
 >> iter 110000, loss: 6.382089
   Number of active neurons: 10
 >> iter 111000, loss: 6.332311
 >> iter 112000, loss: 6.273220
 >> iter 113000, loss: 6.248172
 >> iter 114000, loss: 6.197097
 >> iter 115000, loss: 6.115532
 >> iter 116000, loss: 6.044260
 >> iter 117000, loss: 5.984497
 >> iter 118000, loss: 5.726326
 >> iter 119000, loss: 5.426097
 >> iter 120000, loss: 4.072566
   Number of active neurons: 10
 >> iter 121000, loss: 1.900820
 >> iter 122000, loss: 1.099079
 >> iter 123000, loss: 0.717471
 >> iter 124000, loss: 0.723278
 >> iter 125000, loss: 0.336966
 >> iter 126000, loss: 0.157067
 >> iter 127000, loss: 0.238631
 >> iter 128000, loss: 0.270640
 >> iter 129000, loss: 0.218095
 >> iter 130000, loss: 0.167959
   Number of active neurons: 10
 >> iter 131000, loss: 0.079226
 >> iter 132000, loss: 0.239134
 >> iter 133000, loss: 0.123867
 >> iter 134000, loss: 0.057875
 >> iter 135000, loss: 0.046615
 >> iter 136000, loss: 0.025522
 >> iter 137000, loss: 0.058926
 >> iter 138000, loss: 0.042798
 >> iter 139000, loss: 0.078780
 >> iter 140000, loss: 0.036943
   Number of active neurons: 10
 >> iter 141000, loss: 0.033000
 >> iter 142000, loss: 0.109192
 >> iter 143000, loss: 0.046580
 >> iter 144000, loss: 0.023387
 >> iter 145000, loss: 0.014270
 >> iter 146000, loss: 0.010042
 >> iter 147000, loss: 0.009599
 >> iter 148000, loss: 0.007550
 >> iter 149000, loss: 0.006456
 >> iter 150000, loss: 0.048542
   Number of active neurons: 10
 >> iter 151000, loss: 0.022105
 >> iter 152000, loss: 0.058024
 >> iter 153000, loss: 0.129476
 >> iter 154000, loss: 0.063235
 >> iter 155000, loss: 0.028202
 >> iter 156000, loss: 0.088214
 >> iter 157000, loss: 0.037381
 >> iter 158000, loss: 0.017221
 >> iter 159000, loss: 0.009962
 >> iter 160000, loss: 0.006742
   Number of active neurons: 10
 >> iter 161000, loss: 0.244889
 >> iter 162000, loss: 0.094360
 >> iter 163000, loss: 0.038462
 >> iter 164000, loss: 0.062281
 >> iter 165000, loss: 0.061811
 >> iter 166000, loss: 0.025929
 >> iter 167000, loss: 0.013497
 >> iter 168000, loss: 0.020112
 >> iter 169000, loss: 0.010363
 >> iter 170000, loss: 0.006671
   Number of active neurons: 10
 >> iter 171000, loss: 0.106282
 >> iter 172000, loss: 0.096922
 >> iter 173000, loss: 0.039236
 >> iter 174000, loss: 0.017486
 >> iter 175000, loss: 0.009452
 >> iter 176000, loss: 0.006561
 >> iter 177000, loss: 0.004983
 >> iter 178000, loss: 0.004287
 >> iter 179000, loss: 0.003816
 >> iter 180000, loss: 0.003482
   Number of active neurons: 10
 >> iter 181000, loss: 0.003546
 >> iter 182000, loss: 0.003327
 >> iter 183000, loss: 0.052423
 >> iter 184000, loss: 0.021619
 >> iter 185000, loss: 0.010025
 >> iter 186000, loss: 0.005851
 >> iter 187000, loss: 0.026025
 >> iter 188000, loss: 0.042142
 >> iter 189000, loss: 0.018875
 >> iter 190000, loss: 0.009089
   Number of active neurons: 10
 >> iter 191000, loss: 0.005442
 >> iter 192000, loss: 0.003926
 >> iter 193000, loss: 0.003518
 >> iter 194000, loss: 0.004053
 >> iter 195000, loss: 0.018160
 >> iter 196000, loss: 0.008410
 >> iter 197000, loss: 0.030227
 >> iter 198000, loss: 0.032488
 >> iter 199000, loss: 0.013669
 >> iter 200000, loss: 0.026577
   Number of active neurons: 10
 >> iter 201000, loss: 0.011411
 >> iter 202000, loss: 0.005791
 >> iter 203000, loss: 0.003819
 >> iter 204000, loss: 0.032063
 >> iter 205000, loss: 0.013535
 >> iter 206000, loss: 0.006522
 >> iter 207000, loss: 0.003898
 >> iter 208000, loss: 0.003068
 >> iter 209000, loss: 0.002735
 >> iter 210000, loss: 0.002334
   Number of active neurons: 10
 >> iter 211000, loss: 0.005850
 >> iter 212000, loss: 0.003699
 >> iter 213000, loss: 0.002672
 >> iter 214000, loss: 0.058332
 >> iter 215000, loss: 0.116495
 >> iter 216000, loss: 0.044651
 >> iter 217000, loss: 0.087705
 >> iter 218000, loss: 0.034193
 >> iter 219000, loss: 0.014401
 >> iter 220000, loss: 0.006823
   Number of active neurons: 10
 >> iter 221000, loss: 0.007044
 >> iter 222000, loss: 0.005187
 >> iter 223000, loss: 0.003421
 >> iter 224000, loss: 0.002959
 >> iter 225000, loss: 0.002458
 >> iter 226000, loss: 0.002400
 >> iter 227000, loss: 0.002152
 >> iter 228000, loss: 0.001996
 >> iter 229000, loss: 0.001908
 >> iter 230000, loss: 0.001865
   Number of active neurons: 10
 >> iter 231000, loss: 0.001823
 >> iter 232000, loss: 0.001775
 >> iter 233000, loss: 0.001682
 >> iter 234000, loss: 0.001682
 >> iter 235000, loss: 0.001638
 >> iter 236000, loss: 0.001606
 >> iter 237000, loss: 0.030835
 >> iter 238000, loss: 0.012460
 >> iter 239000, loss: 0.023453
 >> iter 240000, loss: 0.009854
   Number of active neurons: 10
 >> iter 241000, loss: 0.005116
 >> iter 242000, loss: 0.003484
 >> iter 243000, loss: 0.002312
 >> iter 244000, loss: 0.001798
 >> iter 245000, loss: 0.051540
 >> iter 246000, loss: 0.037933
 >> iter 247000, loss: 0.015439
 >> iter 248000, loss: 0.007341
 >> iter 249000, loss: 0.003912
 >> iter 250000, loss: 0.002555
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.343882
 >> iter 2000, loss: 11.043758
 >> iter 3000, loss: 8.956520
 >> iter 4000, loss: 8.126999
 >> iter 5000, loss: 7.782025
 >> iter 6000, loss: 7.646628
 >> iter 7000, loss: 7.627632
 >> iter 8000, loss: 7.574245
 >> iter 9000, loss: 7.623881
 >> iter 10000, loss: 7.575262
   Number of active neurons: 10
 >> iter 11000, loss: 7.572127
 >> iter 12000, loss: 7.555000
 >> iter 13000, loss: 7.559359
 >> iter 14000, loss: 7.548456
 >> iter 15000, loss: 7.555932
 >> iter 16000, loss: 7.542402
 >> iter 17000, loss: 7.556087
 >> iter 18000, loss: 7.548529
 >> iter 19000, loss: 7.556767
 >> iter 20000, loss: 7.545499
   Number of active neurons: 10
 >> iter 21000, loss: 7.552082
 >> iter 22000, loss: 7.544603
 >> iter 23000, loss: 7.550611
 >> iter 24000, loss: 7.540940
 >> iter 25000, loss: 7.550102
 >> iter 26000, loss: 7.543310
 >> iter 27000, loss: 7.548165
 >> iter 28000, loss: 7.544064
 >> iter 29000, loss: 7.550779
 >> iter 30000, loss: 7.544885
   Number of active neurons: 10
 >> iter 31000, loss: 7.548050
 >> iter 32000, loss: 7.545186
 >> iter 33000, loss: 7.552497
 >> iter 34000, loss: 7.544287
 >> iter 35000, loss: 7.554773
 >> iter 36000, loss: 7.546095
 >> iter 37000, loss: 7.553796
 >> iter 38000, loss: 7.550341
 >> iter 39000, loss: 7.549266
 >> iter 40000, loss: 7.538898
   Number of active neurons: 10
 >> iter 41000, loss: 7.548911
 >> iter 42000, loss: 7.539626
 >> iter 43000, loss: 7.547352
 >> iter 44000, loss: 7.534934
 >> iter 45000, loss: 7.547242
 >> iter 46000, loss: 7.534845
 >> iter 47000, loss: 7.545935
 >> iter 48000, loss: 7.533834
 >> iter 49000, loss: 7.543189
 >> iter 50000, loss: 7.557139
   Number of active neurons: 10
 >> iter 51000, loss: 7.544970
 >> iter 52000, loss: 7.492179
 >> iter 53000, loss: 7.470451
 >> iter 54000, loss: 7.394363
 >> iter 55000, loss: 7.349471
 >> iter 56000, loss: 7.189709
 >> iter 57000, loss: 7.089684
 >> iter 58000, loss: 6.963942
 >> iter 59000, loss: 6.869766
 >> iter 60000, loss: 6.617430
   Number of active neurons: 10
 >> iter 61000, loss: 6.455249
 >> iter 62000, loss: 6.310478
 >> iter 63000, loss: 6.285592
 >> iter 64000, loss: 6.251916
 >> iter 65000, loss: 6.154535
 >> iter 66000, loss: 6.035920
 >> iter 67000, loss: 5.958892
 >> iter 68000, loss: 5.883806
 >> iter 69000, loss: 5.832145
 >> iter 70000, loss: 5.748798
   Number of active neurons: 10
 >> iter 71000, loss: 5.645410
 >> iter 72000, loss: 5.529761
 >> iter 73000, loss: 5.482802
 >> iter 74000, loss: 5.317187
 >> iter 75000, loss: 5.390158
 >> iter 76000, loss: 5.305188
 >> iter 77000, loss: 5.204647
 >> iter 78000, loss: 5.140460
 >> iter 79000, loss: 4.859249
 >> iter 80000, loss: 4.825205
   Number of active neurons: 10
 >> iter 81000, loss: 4.725751
 >> iter 82000, loss: 4.497797
 >> iter 83000, loss: 4.679971
 >> iter 84000, loss: 4.555699
 >> iter 85000, loss: 3.940226
 >> iter 86000, loss: 3.209610
 >> iter 87000, loss: 2.516688
 >> iter 88000, loss: 2.323761
 >> iter 89000, loss: 2.151787
 >> iter 90000, loss: 1.850251
   Number of active neurons: 10
 >> iter 91000, loss: 1.311325
 >> iter 92000, loss: 1.378208
 >> iter 93000, loss: 1.193529
 >> iter 94000, loss: 1.037610
 >> iter 95000, loss: 0.948464
 >> iter 96000, loss: 0.912667
 >> iter 97000, loss: 1.065603
 >> iter 98000, loss: 1.106162
 >> iter 99000, loss: 0.910446
 >> iter 100000, loss: 0.687505
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.353327
 >> iter 2000, loss: 10.940925
 >> iter 3000, loss: 8.920184
 >> iter 4000, loss: 8.121568
 >> iter 5000, loss: 7.805873
 >> iter 6000, loss: 7.699766
 >> iter 7000, loss: 7.647328
 >> iter 8000, loss: 7.633999
 >> iter 9000, loss: 7.619000
 >> iter 10000, loss: 7.608531
   Number of active neurons: 10
 >> iter 11000, loss: 7.606500
 >> iter 12000, loss: 7.600788
 >> iter 13000, loss: 7.604168
 >> iter 14000, loss: 7.596729
 >> iter 15000, loss: 7.601137
 >> iter 16000, loss: 7.594092
 >> iter 17000, loss: 7.602612
 >> iter 18000, loss: 7.601305
 >> iter 19000, loss: 7.597696
 >> iter 20000, loss: 7.586522
   Number of active neurons: 10
 >> iter 21000, loss: 7.593549
 >> iter 22000, loss: 7.597730
 >> iter 23000, loss: 7.589782
 >> iter 24000, loss: 7.603687
 >> iter 25000, loss: 7.584947
 >> iter 26000, loss: 7.570281
 >> iter 27000, loss: 7.533714
 >> iter 28000, loss: 7.433784
 >> iter 29000, loss: 7.314422
 >> iter 30000, loss: 7.154875
   Number of active neurons: 10
 >> iter 31000, loss: 7.048844
 >> iter 32000, loss: 6.943132
 >> iter 33000, loss: 6.820800
 >> iter 34000, loss: 6.717939
 >> iter 35000, loss: 6.687451
 >> iter 36000, loss: 6.578187
 >> iter 37000, loss: 6.443429
 >> iter 38000, loss: 6.224485
 >> iter 39000, loss: 6.057036
 >> iter 40000, loss: 5.931601
   Number of active neurons: 10
 >> iter 41000, loss: 5.929509
 >> iter 42000, loss: 5.802202
 >> iter 43000, loss: 5.551288
 >> iter 44000, loss: 5.426345
 >> iter 45000, loss: 5.295995
 >> iter 46000, loss: 5.211345
 >> iter 47000, loss: 5.110201
 >> iter 48000, loss: 5.093834
 >> iter 49000, loss: 5.006753
 >> iter 50000, loss: 4.679211
   Number of active neurons: 10
 >> iter 51000, loss: 4.247032
 >> iter 52000, loss: 3.886598
 >> iter 53000, loss: 3.740997
 >> iter 54000, loss: 3.650105
 >> iter 55000, loss: 3.434849
 >> iter 56000, loss: 3.196698
 >> iter 57000, loss: 2.312234
 >> iter 58000, loss: 1.253280
 >> iter 59000, loss: 0.632592
 >> iter 60000, loss: 0.406710
   Number of active neurons: 10
 >> iter 61000, loss: 0.334899
 >> iter 62000, loss: 0.231830
 >> iter 63000, loss: 0.214947
 >> iter 64000, loss: 0.191337
 >> iter 65000, loss: 0.111999
 >> iter 66000, loss: 0.086179
 >> iter 67000, loss: 0.065398
 >> iter 68000, loss: 0.077705
 >> iter 69000, loss: 0.082128
 >> iter 70000, loss: 0.174515
   Number of active neurons: 10
 >> iter 71000, loss: 0.084284
 >> iter 72000, loss: 0.110258
 >> iter 73000, loss: 0.077930
 >> iter 74000, loss: 0.082408
 >> iter 75000, loss: 0.196328
 >> iter 76000, loss: 0.119879
 >> iter 77000, loss: 0.134981
 >> iter 78000, loss: 0.063717
 >> iter 79000, loss: 0.034074
 >> iter 80000, loss: 0.046283
   Number of active neurons: 10
 >> iter 81000, loss: 0.035311
 >> iter 82000, loss: 0.064868
 >> iter 83000, loss: 0.038908
 >> iter 84000, loss: 0.068433
 >> iter 85000, loss: 0.105411
 >> iter 86000, loss: 0.060746
 >> iter 87000, loss: 0.204951
 >> iter 88000, loss: 0.154227
 >> iter 89000, loss: 0.080623
 >> iter 90000, loss: 0.104759
   Number of active neurons: 10
 >> iter 91000, loss: 0.080228
 >> iter 92000, loss: 0.049359
 >> iter 93000, loss: 0.055451
 >> iter 94000, loss: 0.044253
 >> iter 95000, loss: 0.024347
 >> iter 96000, loss: 0.035642
 >> iter 97000, loss: 0.032960
 >> iter 98000, loss: 0.019140
 >> iter 99000, loss: 0.134703
 >> iter 100000, loss: 0.091396
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.357256
 >> iter 2000, loss: 10.916412
 >> iter 3000, loss: 8.869647
 >> iter 4000, loss: 8.058451
 >> iter 5000, loss: 7.769041
 >> iter 6000, loss: 7.646517
 >> iter 7000, loss: 7.631152
 >> iter 8000, loss: 7.575317
 >> iter 9000, loss: 7.568000
 >> iter 10000, loss: 7.555184
   Number of active neurons: 8
 >> iter 11000, loss: 7.558265
 >> iter 12000, loss: 7.570113
 >> iter 13000, loss: 7.563207
 >> iter 14000, loss: 7.548496
 >> iter 15000, loss: 7.553278
 >> iter 16000, loss: 7.556527
 >> iter 17000, loss: 7.551805
 >> iter 18000, loss: 7.543662
 >> iter 19000, loss: 7.552752
 >> iter 20000, loss: 7.568685
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 7.559876
 >> iter 22000, loss: 7.535668
 >> iter 23000, loss: 7.545320
 >> iter 24000, loss: 7.537582
 >> iter 25000, loss: 7.588499
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 26000, loss: 7.552315
 >> iter 27000, loss: 7.549124
 >> iter 28000, loss: 7.542564
 >> iter 29000, loss: 7.552189
 >> iter 30000, loss: 7.541251
   Number of active neurons: 9
 >> iter 31000, loss: 7.546663
 >> iter 32000, loss: 7.540440
 >> iter 33000, loss: 7.546670
 >> iter 34000, loss: 7.538298
 >> iter 35000, loss: 7.550423
   Number of active neurons: 9
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 36000, loss: 7.540648
 >> iter 37000, loss: 7.546897
 >> iter 38000, loss: 7.533526
 >> iter 39000, loss: 7.547152
 >> iter 40000, loss: 7.537715
   Number of active neurons: 9
 >> iter 41000, loss: 7.548538
 >> iter 42000, loss: 7.536319
 >> iter 43000, loss: 7.543043
 >> iter 44000, loss: 7.539894
 >> iter 45000, loss: 7.546867
   Number of active neurons: 9
   SHOCK
   Setting new limit to 287500.0 iters...
 >> iter 46000, loss: 7.531585
 >> iter 47000, loss: 7.537027
 >> iter 48000, loss: 7.556357
 >> iter 49000, loss: 7.546001
 >> iter 50000, loss: 7.525023
   Number of active neurons: 9
 >> iter 51000, loss: 7.535351
 >> iter 52000, loss: 7.520391
 >> iter 53000, loss: 7.532811
 >> iter 54000, loss: 7.525525
 >> iter 55000, loss: 7.533830
   Number of active neurons: 9
   SHOCK
   Setting new limit to 293750.0 iters...
 >> iter 56000, loss: 7.520044
 >> iter 57000, loss: 7.533989
 >> iter 58000, loss: 7.518238
 >> iter 59000, loss: 7.530657
 >> iter 60000, loss: 7.515102
   Number of active neurons: 9
 >> iter 61000, loss: 7.523922
 >> iter 62000, loss: 7.514442
 >> iter 63000, loss: 7.529258
 >> iter 64000, loss: 7.518171
 >> iter 65000, loss: 7.532732
   Number of active neurons: 9
   SHOCK
   Setting new limit to 296875.0 iters...
 >> iter 66000, loss: 7.520976
 >> iter 67000, loss: 7.530562
 >> iter 68000, loss: 7.518275
 >> iter 69000, loss: 7.529396
 >> iter 70000, loss: 7.520131
   Number of active neurons: 9
 >> iter 71000, loss: 7.529312
 >> iter 72000, loss: 7.520409
 >> iter 73000, loss: 7.534909
 >> iter 74000, loss: 7.517020
 >> iter 75000, loss: 7.529146
   Number of active neurons: 9
   SHOCK
   Setting new limit to 298437.5 iters...
 >> iter 76000, loss: 7.534302
 >> iter 77000, loss: 7.536872
 >> iter 78000, loss: 7.564923
 >> iter 79000, loss: 7.513113
 >> iter 80000, loss: 7.416249
   Number of active neurons: 10
 >> iter 81000, loss: 7.247123
 >> iter 82000, loss: 7.077108
 >> iter 83000, loss: 6.909423
 >> iter 84000, loss: 6.676240
 >> iter 85000, loss: 6.541835
 >> iter 86000, loss: 6.355742
 >> iter 87000, loss: 6.264351
 >> iter 88000, loss: 6.187928
 >> iter 89000, loss: 6.134548
 >> iter 90000, loss: 6.010712
   Number of active neurons: 10
 >> iter 91000, loss: 5.873781
 >> iter 92000, loss: 5.698170
 >> iter 93000, loss: 5.384187
 >> iter 94000, loss: 4.394193
 >> iter 95000, loss: 2.239827
 >> iter 96000, loss: 1.175380
 >> iter 97000, loss: 0.694337
 >> iter 98000, loss: 0.461068
 >> iter 99000, loss: 0.388608
 >> iter 100000, loss: 0.435974
   Number of active neurons: 10
 >> iter 101000, loss: 0.431423
 >> iter 102000, loss: 0.431861
 >> iter 103000, loss: 0.283925
 >> iter 104000, loss: 0.351771
 >> iter 105000, loss: 0.267378
 >> iter 106000, loss: 0.156199
 >> iter 107000, loss: 0.181556
 >> iter 108000, loss: 0.150616
 >> iter 109000, loss: 0.521746
 >> iter 110000, loss: 0.403076
   Number of active neurons: 10
 >> iter 111000, loss: 0.277439
 >> iter 112000, loss: 0.217527
 >> iter 113000, loss: 0.177548
 >> iter 114000, loss: 0.090785
 >> iter 115000, loss: 0.062387
 >> iter 116000, loss: 0.101147
 >> iter 117000, loss: 0.242710
 >> iter 118000, loss: 0.123964
 >> iter 119000, loss: 0.087926
 >> iter 120000, loss: 0.127238
   Number of active neurons: 10
 >> iter 121000, loss: 0.058861
 >> iter 122000, loss: 0.134083
 >> iter 123000, loss: 0.064294
 >> iter 124000, loss: 0.177915
 >> iter 125000, loss: 0.321849
 >> iter 126000, loss: 0.132579
 >> iter 127000, loss: 0.102957
 >> iter 128000, loss: 0.131131
 >> iter 129000, loss: 0.073838
 >> iter 130000, loss: 0.110785
   Number of active neurons: 10
 >> iter 131000, loss: 0.068403
 >> iter 132000, loss: 0.059149
 >> iter 133000, loss: 0.036580
 >> iter 134000, loss: 0.076392
 >> iter 135000, loss: 0.107382
 >> iter 136000, loss: 0.110343
 >> iter 137000, loss: 0.048335
 >> iter 138000, loss: 0.108956
 >> iter 139000, loss: 0.123291
 >> iter 140000, loss: 0.234835
   Number of active neurons: 10
 >> iter 141000, loss: 0.107345
 >> iter 142000, loss: 0.100233
 >> iter 143000, loss: 0.061105
 >> iter 144000, loss: 0.029987
 >> iter 145000, loss: 0.055701
 >> iter 146000, loss: 0.070847
 >> iter 147000, loss: 0.032833
 >> iter 148000, loss: 0.018197
 >> iter 149000, loss: 0.012578
 >> iter 150000, loss: 0.012043
   Number of active neurons: 10
 >> iter 151000, loss: 0.036560
 >> iter 152000, loss: 0.081410
 >> iter 153000, loss: 0.067447
 >> iter 154000, loss: 0.047250
 >> iter 155000, loss: 0.059857
 >> iter 156000, loss: 0.027949
 >> iter 157000, loss: 0.023579
 >> iter 158000, loss: 0.087974
 >> iter 159000, loss: 0.037374
 >> iter 160000, loss: 0.057269
   Number of active neurons: 10
 >> iter 161000, loss: 0.104976
 >> iter 162000, loss: 0.043609
 >> iter 163000, loss: 0.020256
 >> iter 164000, loss: 0.080242
 >> iter 165000, loss: 0.148102
 >> iter 166000, loss: 0.059827
 >> iter 167000, loss: 0.073196
 >> iter 168000, loss: 0.116697
 >> iter 169000, loss: 0.091846
 >> iter 170000, loss: 0.038721
   Number of active neurons: 10
 >> iter 171000, loss: 0.029674
 >> iter 172000, loss: 0.070632
 >> iter 173000, loss: 0.039597
 >> iter 174000, loss: 0.019027
 >> iter 175000, loss: 0.011095
 >> iter 176000, loss: 0.021122
 >> iter 177000, loss: 0.011697
 >> iter 178000, loss: 0.008078
 >> iter 179000, loss: 0.006386
 >> iter 180000, loss: 0.005500
   Number of active neurons: 10
 >> iter 181000, loss: 0.014409
 >> iter 182000, loss: 0.036944
 >> iter 183000, loss: 0.016978
 >> iter 184000, loss: 0.030480
 >> iter 185000, loss: 0.014402
 >> iter 186000, loss: 0.007894
 >> iter 187000, loss: 0.009725
 >> iter 188000, loss: 0.055277
 >> iter 189000, loss: 0.027024
 >> iter 190000, loss: 0.025800
   Number of active neurons: 10
 >> iter 191000, loss: 0.024076
 >> iter 192000, loss: 0.042826
 >> iter 193000, loss: 0.140525
 >> iter 194000, loss: 0.072966
 >> iter 195000, loss: 0.064723
 >> iter 196000, loss: 0.027762
 >> iter 197000, loss: 0.013471
 >> iter 198000, loss: 0.008104
 >> iter 199000, loss: 0.098530
 >> iter 200000, loss: 0.120016
   Number of active neurons: 10
 >> iter 201000, loss: 0.048283
 >> iter 202000, loss: 0.021721
 >> iter 203000, loss: 0.106955
 >> iter 204000, loss: 0.087658
 >> iter 205000, loss: 0.057099
 >> iter 206000, loss: 0.028285
 >> iter 207000, loss: 0.014477
 >> iter 208000, loss: 0.009545
 >> iter 209000, loss: 0.006610
 >> iter 210000, loss: 0.005416
   Number of active neurons: 10
 >> iter 211000, loss: 0.004794
 >> iter 212000, loss: 0.004646
 >> iter 213000, loss: 0.004211
 >> iter 214000, loss: 0.004157
 >> iter 215000, loss: 0.005884
 >> iter 216000, loss: 0.007988
 >> iter 217000, loss: 0.005447
 >> iter 218000, loss: 0.133055
 >> iter 219000, loss: 0.241623
 >> iter 220000, loss: 0.093972
   Number of active neurons: 10
 >> iter 221000, loss: 0.040998
 >> iter 222000, loss: 0.018121
 >> iter 223000, loss: 0.009163
 >> iter 224000, loss: 0.005938
 >> iter 225000, loss: 0.004312
 >> iter 226000, loss: 0.003758
 >> iter 227000, loss: 0.005228
 >> iter 228000, loss: 0.003916
 >> iter 229000, loss: 0.033034
 >> iter 230000, loss: 0.029796
   Number of active neurons: 10
 >> iter 231000, loss: 0.145831
 >> iter 232000, loss: 0.056282
 >> iter 233000, loss: 0.034334
 >> iter 234000, loss: 0.063975
 >> iter 235000, loss: 0.036233
 >> iter 236000, loss: 0.016444
 >> iter 237000, loss: 0.009553
 >> iter 238000, loss: 0.049543
 >> iter 239000, loss: 0.020580
 >> iter 240000, loss: 0.020215
   Number of active neurons: 10
 >> iter 241000, loss: 0.010170
 >> iter 242000, loss: 0.005899
 >> iter 243000, loss: 0.004271
 >> iter 244000, loss: 0.003459
 >> iter 245000, loss: 0.003097
 >> iter 246000, loss: 0.002876
 >> iter 247000, loss: 0.002799
 >> iter 248000, loss: 0.010375
 >> iter 249000, loss: 0.009248
 >> iter 250000, loss: 0.005107
   Number of active neurons: 10
 >> iter 251000, loss: 0.003508
 >> iter 252000, loss: 0.003218
 >> iter 253000, loss: 0.002729
 >> iter 254000, loss: 0.002652
 >> iter 255000, loss: 0.002459
 >> iter 256000, loss: 0.002389
 >> iter 257000, loss: 0.002290
 >> iter 258000, loss: 0.002272
 >> iter 259000, loss: 0.002671
 >> iter 260000, loss: 0.002300
   Number of active neurons: 10
 >> iter 261000, loss: 0.112041
 >> iter 262000, loss: 0.047299
 >> iter 263000, loss: 0.019445
 >> iter 264000, loss: 0.008778
 >> iter 265000, loss: 0.005357
 >> iter 266000, loss: 0.030765
 >> iter 267000, loss: 0.014601
 >> iter 268000, loss: 0.007087
 >> iter 269000, loss: 0.004378
 >> iter 270000, loss: 0.064084
   Number of active neurons: 10
 >> iter 271000, loss: 0.039371
 >> iter 272000, loss: 0.016013
 >> iter 273000, loss: 0.007321
 >> iter 274000, loss: 0.004339
 >> iter 275000, loss: 0.002976
 >> iter 276000, loss: 0.002559
 >> iter 277000, loss: 0.021093
 >> iter 278000, loss: 0.009223
 >> iter 279000, loss: 0.004819
 >> iter 280000, loss: 0.003140
   Number of active neurons: 10
 >> iter 281000, loss: 0.002476
 >> iter 282000, loss: 0.008874
 >> iter 283000, loss: 0.004652
 >> iter 284000, loss: 0.002983
 >> iter 285000, loss: 0.015712
 >> iter 286000, loss: 0.006992
 >> iter 287000, loss: 0.003982
 >> iter 288000, loss: 0.003112
 >> iter 289000, loss: 0.002300
 >> iter 290000, loss: 0.001953
   Number of active neurons: 10
 >> iter 291000, loss: 0.002781
 >> iter 292000, loss: 0.003300
 >> iter 293000, loss: 0.002366
 >> iter 294000, loss: 0.002159
 >> iter 295000, loss: 0.001928
 >> iter 296000, loss: 0.001778
 >> iter 297000, loss: 0.001624
 >> iter 298000, loss: 0.001577
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.369588
 >> iter 2000, loss: 10.971160
 >> iter 3000, loss: 8.935531
 >> iter 4000, loss: 8.112450
 >> iter 5000, loss: 7.803980
 >> iter 6000, loss: 7.676651
 >> iter 7000, loss: 7.621220
 >> iter 8000, loss: 7.598281
 >> iter 9000, loss: 7.594480
 >> iter 10000, loss: 7.596032
   Number of active neurons: 10
 >> iter 11000, loss: 7.594034
 >> iter 12000, loss: 7.564458
 >> iter 13000, loss: 7.563588
 >> iter 14000, loss: 7.550162
 >> iter 15000, loss: 7.573393
 >> iter 16000, loss: 7.556454
 >> iter 17000, loss: 7.556501
 >> iter 18000, loss: 7.546551
 >> iter 19000, loss: 7.557668
 >> iter 20000, loss: 7.567500
   Number of active neurons: 10
 >> iter 21000, loss: 7.563978
 >> iter 22000, loss: 7.559605
 >> iter 23000, loss: 7.558118
 >> iter 24000, loss: 7.546224
 >> iter 25000, loss: 7.552130
 >> iter 26000, loss: 7.540247
 >> iter 27000, loss: 7.551558
 >> iter 28000, loss: 7.577844
 >> iter 29000, loss: 7.563548
 >> iter 30000, loss: 7.594380
   Number of active neurons: 10
 >> iter 31000, loss: 7.571503
 >> iter 32000, loss: 7.554703
 >> iter 33000, loss: 7.554482
 >> iter 34000, loss: 7.547275
 >> iter 35000, loss: 7.551692
 >> iter 36000, loss: 7.556844
 >> iter 37000, loss: 7.558440
 >> iter 38000, loss: 7.542576
 >> iter 39000, loss: 7.554896
 >> iter 40000, loss: 7.545766
   Number of active neurons: 10
 >> iter 41000, loss: 7.552154
 >> iter 42000, loss: 7.539875
 >> iter 43000, loss: 7.549754
 >> iter 44000, loss: 7.552111
 >> iter 45000, loss: 7.556115
 >> iter 46000, loss: 7.549875
 >> iter 47000, loss: 7.568675
 >> iter 48000, loss: 7.483086
 >> iter 49000, loss: 7.453893
 >> iter 50000, loss: 7.338450
   Number of active neurons: 10
 >> iter 51000, loss: 7.248125
 >> iter 52000, loss: 7.126033
 >> iter 53000, loss: 7.031047
 >> iter 54000, loss: 6.950725
 >> iter 55000, loss: 6.893427
 >> iter 56000, loss: 6.793246
 >> iter 57000, loss: 6.655679
 >> iter 58000, loss: 6.518851
 >> iter 59000, loss: 6.447255
 >> iter 60000, loss: 6.350365
   Number of active neurons: 10
 >> iter 61000, loss: 6.318163
 >> iter 62000, loss: 6.277536
 >> iter 63000, loss: 6.266806
 >> iter 64000, loss: 6.280052
 >> iter 65000, loss: 6.271745
 >> iter 66000, loss: 6.239530
 >> iter 67000, loss: 6.235521
 >> iter 68000, loss: 6.190126
 >> iter 69000, loss: 6.198358
 >> iter 70000, loss: 6.167832
   Number of active neurons: 10
 >> iter 71000, loss: 6.173480
 >> iter 72000, loss: 6.177807
 >> iter 73000, loss: 6.168859
 >> iter 74000, loss: 6.121737
 >> iter 75000, loss: 6.112059
 >> iter 76000, loss: 6.089367
 >> iter 77000, loss: 6.061881
 >> iter 78000, loss: 6.029563
 >> iter 79000, loss: 6.005347
 >> iter 80000, loss: 6.040373
   Number of active neurons: 10
 >> iter 81000, loss: 6.009195
 >> iter 82000, loss: 5.989099
 >> iter 83000, loss: 5.966137
 >> iter 84000, loss: 5.981912
 >> iter 85000, loss: 5.939180
 >> iter 86000, loss: 5.941364
 >> iter 87000, loss: 5.855831
 >> iter 88000, loss: 5.749587
 >> iter 89000, loss: 5.657595
 >> iter 90000, loss: 5.594746
   Number of active neurons: 10
 >> iter 91000, loss: 5.474374
 >> iter 92000, loss: 5.382503
 >> iter 93000, loss: 5.400958
 >> iter 94000, loss: 5.242540
 >> iter 95000, loss: 4.851624
 >> iter 96000, loss: 4.405569
 >> iter 97000, loss: 2.783116
 >> iter 98000, loss: 1.617409
 >> iter 99000, loss: 0.850414
 >> iter 100000, loss: 0.438264
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.517515
 >> iter 2000, loss: 11.089452
 >> iter 3000, loss: 8.950580
 >> iter 4000, loss: 8.134209
 >> iter 5000, loss: 7.818994
 >> iter 6000, loss: 7.665226
 >> iter 7000, loss: 7.612144
 >> iter 8000, loss: 7.584311
 >> iter 9000, loss: 7.580120
 >> iter 10000, loss: 7.577270
   Number of active neurons: 9
 >> iter 11000, loss: 7.573235
 >> iter 12000, loss: 7.560416
 >> iter 13000, loss: 7.566294
 >> iter 14000, loss: 7.558099
 >> iter 15000, loss: 7.566374
 >> iter 16000, loss: 7.561742
 >> iter 17000, loss: 7.563774
 >> iter 18000, loss: 7.576791
 >> iter 19000, loss: 7.570425
 >> iter 20000, loss: 7.592964
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 7.572714
 >> iter 22000, loss: 7.557348
 >> iter 23000, loss: 7.642950
 >> iter 24000, loss: 7.582206
 >> iter 25000, loss: 7.564384
 >> iter 26000, loss: 7.546684
 >> iter 27000, loss: 7.552664
 >> iter 28000, loss: 7.541215
 >> iter 29000, loss: 7.549070
 >> iter 30000, loss: 7.553161
   Number of active neurons: 9
 >> iter 31000, loss: 7.558222
 >> iter 32000, loss: 7.547030
 >> iter 33000, loss: 7.553119
 >> iter 34000, loss: 7.543922
 >> iter 35000, loss: 7.552135
 >> iter 36000, loss: 7.562049
 >> iter 37000, loss: 7.555360
 >> iter 38000, loss: 7.539268
 >> iter 39000, loss: 7.547759
 >> iter 40000, loss: 7.536447
   Number of active neurons: 9
 >> iter 41000, loss: 7.544549
 >> iter 42000, loss: 7.532670
 >> iter 43000, loss: 7.544819
 >> iter 44000, loss: 7.530079
 >> iter 45000, loss: 7.543810
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 46000, loss: 7.531160
 >> iter 47000, loss: 7.547943
 >> iter 48000, loss: 7.534180
 >> iter 49000, loss: 7.549618
 >> iter 50000, loss: 7.534836
   Number of active neurons: 9
 >> iter 51000, loss: 7.547768
 >> iter 52000, loss: 7.562461
 >> iter 53000, loss: 7.557624
 >> iter 54000, loss: 7.536782
 >> iter 55000, loss: 7.546117
   Number of active neurons: 9
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 56000, loss: 7.529259
 >> iter 57000, loss: 7.543410
 >> iter 58000, loss: 7.530261
 >> iter 59000, loss: 7.544447
 >> iter 60000, loss: 7.528632
   Number of active neurons: 9
 >> iter 61000, loss: 7.541937
 >> iter 62000, loss: 7.525769
 >> iter 63000, loss: 7.523586
 >> iter 64000, loss: 7.436048
 >> iter 65000, loss: 7.319517
 >> iter 66000, loss: 7.224045
 >> iter 67000, loss: 7.069363
 >> iter 68000, loss: 6.971704
 >> iter 69000, loss: 6.943815
 >> iter 70000, loss: 6.865063
   Number of active neurons: 10
 >> iter 71000, loss: 6.720483
 >> iter 72000, loss: 6.519488
 >> iter 73000, loss: 6.351806
 >> iter 74000, loss: 6.222857
 >> iter 75000, loss: 6.170096
 >> iter 76000, loss: 6.088095
 >> iter 77000, loss: 6.023548
 >> iter 78000, loss: 5.902660
 >> iter 79000, loss: 5.528287
 >> iter 80000, loss: 4.645078
   Number of active neurons: 10
 >> iter 81000, loss: 3.036886
 >> iter 82000, loss: 1.557057
 >> iter 83000, loss: 0.800235
 >> iter 84000, loss: 0.486157
 >> iter 85000, loss: 0.251155
 >> iter 86000, loss: 0.222514
 >> iter 87000, loss: 0.133410
 >> iter 88000, loss: 0.189952
 >> iter 89000, loss: 0.105459
 >> iter 90000, loss: 0.053599
   Number of active neurons: 10
 >> iter 91000, loss: 0.053680
 >> iter 92000, loss: 0.056173
 >> iter 93000, loss: 0.091307
 >> iter 94000, loss: 0.097984
 >> iter 95000, loss: 0.044126
 >> iter 96000, loss: 0.026062
 >> iter 97000, loss: 0.024170
 >> iter 98000, loss: 0.021979
 >> iter 99000, loss: 0.016136
 >> iter 100000, loss: 0.054175
   Number of active neurons: 10
 >> iter 101000, loss: 0.063404
 >> iter 102000, loss: 0.028294
 >> iter 103000, loss: 0.016240
 >> iter 104000, loss: 0.040549
 >> iter 105000, loss: 0.020951
 >> iter 106000, loss: 0.028741
 >> iter 107000, loss: 0.013914
 >> iter 108000, loss: 0.010920
 >> iter 109000, loss: 0.028770
 >> iter 110000, loss: 0.026044
   Number of active neurons: 10
 >> iter 111000, loss: 0.032264
 >> iter 112000, loss: 0.020265
 >> iter 113000, loss: 0.070660
 >> iter 114000, loss: 0.031649
 >> iter 115000, loss: 0.037056
 >> iter 116000, loss: 0.017300
 >> iter 117000, loss: 0.009039
 >> iter 118000, loss: 0.006814
 >> iter 119000, loss: 0.004807
 >> iter 120000, loss: 0.005122
   Number of active neurons: 10
 >> iter 121000, loss: 0.004077
 >> iter 122000, loss: 0.003814
 >> iter 123000, loss: 0.015871
 >> iter 124000, loss: 0.225781
 >> iter 125000, loss: 0.087984
 >> iter 126000, loss: 0.035073
 >> iter 127000, loss: 0.015141
 >> iter 128000, loss: 0.007904
 >> iter 129000, loss: 0.012845
 >> iter 130000, loss: 0.078629
   Number of active neurons: 10
 >> iter 131000, loss: 0.031889
 >> iter 132000, loss: 0.014104
 >> iter 133000, loss: 0.009199
 >> iter 134000, loss: 0.006198
 >> iter 135000, loss: 0.004158
 >> iter 136000, loss: 0.003373
 >> iter 137000, loss: 0.008688
 >> iter 138000, loss: 0.004923
 >> iter 139000, loss: 0.005459
 >> iter 140000, loss: 0.007751
   Number of active neurons: 10
 >> iter 141000, loss: 0.004784
 >> iter 142000, loss: 0.003324
 >> iter 143000, loss: 0.002975
 >> iter 144000, loss: 0.002520
 >> iter 145000, loss: 0.002611
 >> iter 146000, loss: 0.002289
 >> iter 147000, loss: 0.002271
 >> iter 148000, loss: 0.002351
 >> iter 149000, loss: 0.002268
 >> iter 150000, loss: 0.002160
   Number of active neurons: 10
 >> iter 151000, loss: 0.001981
 >> iter 152000, loss: 0.001857
 >> iter 153000, loss: 0.001814
 >> iter 154000, loss: 0.001749
 >> iter 155000, loss: 0.004109
 >> iter 156000, loss: 0.058800
 >> iter 157000, loss: 0.049084
 >> iter 158000, loss: 0.019276
 >> iter 159000, loss: 0.008226
 >> iter 160000, loss: 0.004195
   Number of active neurons: 10
 >> iter 161000, loss: 0.002771
 >> iter 162000, loss: 0.009070
 >> iter 163000, loss: 0.004383
 >> iter 164000, loss: 0.002669
 >> iter 165000, loss: 0.002015
 >> iter 166000, loss: 0.001746
 >> iter 167000, loss: 0.002208
 >> iter 168000, loss: 0.001825
 >> iter 169000, loss: 0.001683
 >> iter 170000, loss: 0.001557
   Number of active neurons: 10
 >> iter 171000, loss: 0.004039
 >> iter 172000, loss: 0.002429
 >> iter 173000, loss: 0.001803
 >> iter 174000, loss: 0.001731
 >> iter 175000, loss: 0.011825
 >> iter 176000, loss: 0.005315
 >> iter 177000, loss: 0.087604
 >> iter 178000, loss: 0.033343
 >> iter 179000, loss: 0.013554
 >> iter 180000, loss: 0.006018
   Number of active neurons: 10
 >> iter 181000, loss: 0.003170
 >> iter 182000, loss: 0.002129
 >> iter 183000, loss: 0.026990
 >> iter 184000, loss: 0.012468
 >> iter 185000, loss: 0.005721
 >> iter 186000, loss: 0.003092
 >> iter 187000, loss: 0.002597
 >> iter 188000, loss: 0.001857
 >> iter 189000, loss: 0.001655
 >> iter 190000, loss: 0.001495
   Number of active neurons: 10
 >> iter 191000, loss: 0.001556
 >> iter 192000, loss: 0.001398
 >> iter 193000, loss: 0.001327
 >> iter 194000, loss: 0.001351
 >> iter 195000, loss: 0.002546
 >> iter 196000, loss: 0.006758
 >> iter 197000, loss: 0.003259
 >> iter 198000, loss: 0.002108
 >> iter 199000, loss: 0.001530
 >> iter 200000, loss: 0.001337
   Number of active neurons: 10
 >> iter 201000, loss: 0.001439
 >> iter 202000, loss: 0.015159
 >> iter 203000, loss: 0.006303
 >> iter 204000, loss: 0.004475
 >> iter 205000, loss: 0.002437
 >> iter 206000, loss: 0.001645
 >> iter 207000, loss: 0.001312
 >> iter 208000, loss: 0.001192
 >> iter 209000, loss: 0.001098
 >> iter 210000, loss: 0.001116
   Number of active neurons: 10
 >> iter 211000, loss: 0.001077
 >> iter 212000, loss: 0.001039
 >> iter 213000, loss: 0.001099
 >> iter 214000, loss: 0.001193
 >> iter 215000, loss: 0.001054
 >> iter 216000, loss: 0.001001
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.266002
 >> iter 2000, loss: 10.953585
 >> iter 3000, loss: 8.921689
 >> iter 4000, loss: 8.114615
 >> iter 5000, loss: 7.825909
 >> iter 6000, loss: 7.683267
 >> iter 7000, loss: 7.620526
 >> iter 8000, loss: 7.588347
 >> iter 9000, loss: 7.580487
 >> iter 10000, loss: 7.565981
   Number of active neurons: 10
 >> iter 11000, loss: 7.571115
 >> iter 12000, loss: 7.571168
 >> iter 13000, loss: 7.569791
 >> iter 14000, loss: 7.560255
 >> iter 15000, loss: 7.577945
 >> iter 16000, loss: 7.581160
 >> iter 17000, loss: 7.589731
 >> iter 18000, loss: 7.564682
 >> iter 19000, loss: 7.568391
 >> iter 20000, loss: 7.578072
   Number of active neurons: 10
 >> iter 21000, loss: 7.585746
 >> iter 22000, loss: 7.557938
 >> iter 23000, loss: 7.557921
 >> iter 24000, loss: 7.554374
 >> iter 25000, loss: 7.559212
 >> iter 26000, loss: 7.543166
 >> iter 27000, loss: 7.550636
 >> iter 28000, loss: 7.560193
 >> iter 29000, loss: 7.556962
 >> iter 30000, loss: 7.540463
   Number of active neurons: 10
 >> iter 31000, loss: 7.593232
 >> iter 32000, loss: 7.561276
 >> iter 33000, loss: 7.558405
 >> iter 34000, loss: 7.545912
 >> iter 35000, loss: 7.549855
 >> iter 36000, loss: 7.543615
 >> iter 37000, loss: 7.605828
 >> iter 38000, loss: 7.560700
 >> iter 39000, loss: 7.558428
 >> iter 40000, loss: 7.541225
   Number of active neurons: 10
 >> iter 41000, loss: 7.550865
 >> iter 42000, loss: 7.537602
 >> iter 43000, loss: 7.545361
 >> iter 44000, loss: 7.537546
 >> iter 45000, loss: 7.547689
 >> iter 46000, loss: 7.538106
 >> iter 47000, loss: 7.549678
 >> iter 48000, loss: 7.535204
 >> iter 49000, loss: 7.573983
 >> iter 50000, loss: 7.549121
   Number of active neurons: 10
 >> iter 51000, loss: 7.560448
 >> iter 52000, loss: 7.538797
 >> iter 53000, loss: 7.546931
 >> iter 54000, loss: 7.529346
 >> iter 55000, loss: 7.558995
 >> iter 56000, loss: 7.546534
 >> iter 57000, loss: 7.562621
 >> iter 58000, loss: 7.508029
 >> iter 59000, loss: 7.471202
 >> iter 60000, loss: 7.417369
   Number of active neurons: 10
 >> iter 61000, loss: 7.354410
 >> iter 62000, loss: 7.224605
 >> iter 63000, loss: 7.102675
 >> iter 64000, loss: 7.006701
 >> iter 65000, loss: 6.944455
 >> iter 66000, loss: 6.893065
 >> iter 67000, loss: 6.851116
 >> iter 68000, loss: 6.810383
 >> iter 69000, loss: 6.714075
 >> iter 70000, loss: 6.524054
   Number of active neurons: 10
 >> iter 71000, loss: 6.272124
 >> iter 72000, loss: 5.969931
 >> iter 73000, loss: 5.724041
 >> iter 74000, loss: 5.520388
 >> iter 75000, loss: 5.290516
 >> iter 76000, loss: 5.188836
 >> iter 77000, loss: 5.194329
 >> iter 78000, loss: 5.096525
 >> iter 79000, loss: 5.041039
 >> iter 80000, loss: 5.028798
   Number of active neurons: 10
 >> iter 81000, loss: 4.995702
 >> iter 82000, loss: 4.953046
 >> iter 83000, loss: 4.917807
 >> iter 84000, loss: 4.931524
 >> iter 85000, loss: 4.952312
 >> iter 86000, loss: 4.944401
 >> iter 87000, loss: 4.917632
 >> iter 88000, loss: 4.933623
 >> iter 89000, loss: 5.075959
 >> iter 90000, loss: 4.969978
   Number of active neurons: 10
 >> iter 91000, loss: 4.870235
 >> iter 92000, loss: 4.897422
 >> iter 93000, loss: 4.867529
 >> iter 94000, loss: 4.864170
 >> iter 95000, loss: 4.859256
 >> iter 96000, loss: 4.843301
 >> iter 97000, loss: 4.829510
 >> iter 98000, loss: 4.877539
 >> iter 99000, loss: 4.836429
 >> iter 100000, loss: 4.852126
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 13.5337293254
   - Test - Long: 23.5138243088
   - Test - Big: 13.2418675813
   - Test - A: 15.6389574028
   - Test - B: 15.3589760683
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.298589
 >> iter 2000, loss: 11.010233
 >> iter 3000, loss: 8.926320
 >> iter 4000, loss: 8.126010
 >> iter 5000, loss: 7.815024
 >> iter 6000, loss: 7.708101
 >> iter 7000, loss: 7.664297
 >> iter 8000, loss: 7.608676
 >> iter 9000, loss: 7.596063
 >> iter 10000, loss: 7.564890
   Number of active neurons: 10
 >> iter 11000, loss: 7.564348
 >> iter 12000, loss: 7.546886
 >> iter 13000, loss: 7.578800
 >> iter 14000, loss: 7.550138
 >> iter 15000, loss: 7.560835
 >> iter 16000, loss: 7.595303
 >> iter 17000, loss: 7.568636
 >> iter 18000, loss: 7.541778
 >> iter 19000, loss: 7.492982
 >> iter 20000, loss: 7.413629
   Number of active neurons: 10
 >> iter 21000, loss: 7.266519
 >> iter 22000, loss: 7.077891
 >> iter 23000, loss: 6.968278
 >> iter 24000, loss: 6.812151
 >> iter 25000, loss: 6.720372
 >> iter 26000, loss: 6.438073
 >> iter 27000, loss: 6.054162
 >> iter 28000, loss: 5.826074
 >> iter 29000, loss: 5.663738
 >> iter 30000, loss: 5.550103
   Number of active neurons: 10
 >> iter 31000, loss: 5.489906
 >> iter 32000, loss: 5.374570
 >> iter 33000, loss: 5.282117
 >> iter 34000, loss: 5.186345
 >> iter 35000, loss: 5.189426
 >> iter 36000, loss: 4.911493
 >> iter 37000, loss: 4.800639
 >> iter 38000, loss: 4.655069
 >> iter 39000, loss: 4.669669
 >> iter 40000, loss: 4.566758
   Number of active neurons: 10
 >> iter 41000, loss: 4.609581
 >> iter 42000, loss: 4.535892
 >> iter 43000, loss: 4.549240
 >> iter 44000, loss: 4.528634
 >> iter 45000, loss: 4.529398
 >> iter 46000, loss: 4.426312
 >> iter 47000, loss: 3.481811
 >> iter 48000, loss: 1.807789
 >> iter 49000, loss: 0.984351
 >> iter 50000, loss: 0.707202
   Number of active neurons: 10
 >> iter 51000, loss: 0.386247
 >> iter 52000, loss: 0.366303
 >> iter 53000, loss: 0.303173
 >> iter 54000, loss: 0.254858
 >> iter 55000, loss: 0.233820
 >> iter 56000, loss: 0.194050
 >> iter 57000, loss: 0.225020
 >> iter 58000, loss: 0.279731
 >> iter 59000, loss: 0.423369
 >> iter 60000, loss: 0.238172
   Number of active neurons: 10
 >> iter 61000, loss: 0.208629
 >> iter 62000, loss: 0.167086
 >> iter 63000, loss: 0.156965
 >> iter 64000, loss: 0.074586
 >> iter 65000, loss: 0.050952
 >> iter 66000, loss: 0.174863
 >> iter 67000, loss: 0.121784
 >> iter 68000, loss: 0.096974
 >> iter 69000, loss: 0.082545
 >> iter 70000, loss: 0.150161
   Number of active neurons: 10
 >> iter 71000, loss: 0.212132
 >> iter 72000, loss: 0.122217
 >> iter 73000, loss: 0.091247
 >> iter 74000, loss: 0.075588
 >> iter 75000, loss: 0.122616
 >> iter 76000, loss: 0.085398
 >> iter 77000, loss: 0.042439
 >> iter 78000, loss: 0.038045
 >> iter 79000, loss: 0.021718
 >> iter 80000, loss: 0.046787
   Number of active neurons: 10
 >> iter 81000, loss: 0.025468
 >> iter 82000, loss: 0.033230
 >> iter 83000, loss: 0.018976
 >> iter 84000, loss: 0.013835
 >> iter 85000, loss: 0.160692
 >> iter 86000, loss: 0.135867
 >> iter 87000, loss: 0.108108
 >> iter 88000, loss: 0.082163
 >> iter 89000, loss: 0.110037
 >> iter 90000, loss: 0.059137
   Number of active neurons: 10
 >> iter 91000, loss: 0.061812
 >> iter 92000, loss: 0.047261
 >> iter 93000, loss: 0.044101
 >> iter 94000, loss: 0.121308
 >> iter 95000, loss: 0.117797
 >> iter 96000, loss: 0.199044
 >> iter 97000, loss: 0.098076
 >> iter 98000, loss: 0.080934
 >> iter 99000, loss: 0.185654
 >> iter 100000, loss: 0.078056
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.361647
 >> iter 2000, loss: 11.086243
 >> iter 3000, loss: 8.940314
 >> iter 4000, loss: 8.117863
 >> iter 5000, loss: 7.801125
 >> iter 6000, loss: 7.689783
 >> iter 7000, loss: 7.632596
 >> iter 8000, loss: 7.619193
 >> iter 9000, loss: 7.596652
 >> iter 10000, loss: 7.611419
   Number of active neurons: 10
 >> iter 11000, loss: 7.591712
 >> iter 12000, loss: 7.643024
 >> iter 13000, loss: 7.601233
 >> iter 14000, loss: 7.596579
 >> iter 15000, loss: 7.584174
 >> iter 16000, loss: 7.558736
 >> iter 17000, loss: 7.594127
 >> iter 18000, loss: 7.563857
 >> iter 19000, loss: 7.563249
 >> iter 20000, loss: 7.554837
   Number of active neurons: 9
 >> iter 21000, loss: 7.567754
 >> iter 22000, loss: 7.563311
 >> iter 23000, loss: 7.565557
 >> iter 24000, loss: 7.557710
 >> iter 25000, loss: 7.562128
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 7.564977
 >> iter 27000, loss: 7.607918
 >> iter 28000, loss: 7.570354
 >> iter 29000, loss: 7.565237
 >> iter 30000, loss: 7.578271
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 7.476644
 >> iter 32000, loss: 7.226574
 >> iter 33000, loss: 7.044667
 >> iter 34000, loss: 6.941274
 >> iter 35000, loss: 6.839130
 >> iter 36000, loss: 6.761612
 >> iter 37000, loss: 6.709529
 >> iter 38000, loss: 6.694047
 >> iter 39000, loss: 6.704555
 >> iter 40000, loss: 6.643044
   Number of active neurons: 10
 >> iter 41000, loss: 6.549095
 >> iter 42000, loss: 6.286495
 >> iter 43000, loss: 5.997370
 >> iter 44000, loss: 5.719431
 >> iter 45000, loss: 5.215228
 >> iter 46000, loss: 3.262549
 >> iter 47000, loss: 1.570499
 >> iter 48000, loss: 0.967992
 >> iter 49000, loss: 0.549657
 >> iter 50000, loss: 0.239924
   Number of active neurons: 10
 >> iter 51000, loss: 0.309368
 >> iter 52000, loss: 0.215693
 >> iter 53000, loss: 0.276074
 >> iter 54000, loss: 0.258802
 >> iter 55000, loss: 0.202945
 >> iter 56000, loss: 0.140601
 >> iter 57000, loss: 0.147955
 >> iter 58000, loss: 0.130838
 >> iter 59000, loss: 0.209499
 >> iter 60000, loss: 0.154879
   Number of active neurons: 10
 >> iter 61000, loss: 0.167916
 >> iter 62000, loss: 0.129888
 >> iter 63000, loss: 0.067732
 >> iter 64000, loss: 0.036855
 >> iter 65000, loss: 0.021882
 >> iter 66000, loss: 0.033704
 >> iter 67000, loss: 0.069514
 >> iter 68000, loss: 0.033609
 >> iter 69000, loss: 0.019631
 >> iter 70000, loss: 0.012329
   Number of active neurons: 10
 >> iter 71000, loss: 0.010889
 >> iter 72000, loss: 0.020210
 >> iter 73000, loss: 0.023966
 >> iter 74000, loss: 0.021191
 >> iter 75000, loss: 0.012200
 >> iter 76000, loss: 0.010709
 >> iter 77000, loss: 0.008348
 >> iter 78000, loss: 0.030766
 >> iter 79000, loss: 0.068231
 >> iter 80000, loss: 0.028436
   Number of active neurons: 10
 >> iter 81000, loss: 0.040346
 >> iter 82000, loss: 0.047041
 >> iter 83000, loss: 0.047560
 >> iter 84000, loss: 0.062557
 >> iter 85000, loss: 0.026654
 >> iter 86000, loss: 0.013175
 >> iter 87000, loss: 0.009840
 >> iter 88000, loss: 0.006564
 >> iter 89000, loss: 0.005291
 >> iter 90000, loss: 0.004822
   Number of active neurons: 10
 >> iter 91000, loss: 0.004418
 >> iter 92000, loss: 0.004693
 >> iter 93000, loss: 0.004019
 >> iter 94000, loss: 0.010761
 >> iter 95000, loss: 0.019379
 >> iter 96000, loss: 0.009334
 >> iter 97000, loss: 0.057742
 >> iter 98000, loss: 0.023917
 >> iter 99000, loss: 0.024344
 >> iter 100000, loss: 0.017701
   Number of active neurons: 10
 >> iter 101000, loss: 0.009300
 >> iter 102000, loss: 0.005855
 >> iter 103000, loss: 0.004883
 >> iter 104000, loss: 0.003267
 >> iter 105000, loss: 0.032130
 >> iter 106000, loss: 0.048305
 >> iter 107000, loss: 0.019423
 >> iter 108000, loss: 0.012607
 >> iter 109000, loss: 0.009767
 >> iter 110000, loss: 0.007084
   Number of active neurons: 10
 >> iter 111000, loss: 0.006169
 >> iter 112000, loss: 0.171787
 >> iter 113000, loss: 0.067356
 >> iter 114000, loss: 0.027104
 >> iter 115000, loss: 0.020862
 >> iter 116000, loss: 0.009382
 >> iter 117000, loss: 0.005050
 >> iter 118000, loss: 0.048588
 >> iter 119000, loss: 0.040574
 >> iter 120000, loss: 0.017469
   Number of active neurons: 10
 >> iter 121000, loss: 0.023443
 >> iter 122000, loss: 0.010588
 >> iter 123000, loss: 0.005926
 >> iter 124000, loss: 0.003475
 >> iter 125000, loss: 0.002541
 >> iter 126000, loss: 0.002603
 >> iter 127000, loss: 0.003155
 >> iter 128000, loss: 0.002390
 >> iter 129000, loss: 0.003416
 >> iter 130000, loss: 0.034292
   Number of active neurons: 10
 >> iter 131000, loss: 0.013772
 >> iter 132000, loss: 0.031541
 >> iter 133000, loss: 0.013153
 >> iter 134000, loss: 0.006531
 >> iter 135000, loss: 0.018813
 >> iter 136000, loss: 0.011373
 >> iter 137000, loss: 0.005999
 >> iter 138000, loss: 0.003300
 >> iter 139000, loss: 0.195622
 >> iter 140000, loss: 0.078493
   Number of active neurons: 10
 >> iter 141000, loss: 0.089469
 >> iter 142000, loss: 0.064276
 >> iter 143000, loss: 0.028138
 >> iter 144000, loss: 0.011842
 >> iter 145000, loss: 0.006367
 >> iter 146000, loss: 0.003470
 >> iter 147000, loss: 0.002486
 >> iter 148000, loss: 0.002157
 >> iter 149000, loss: 0.002424
 >> iter 150000, loss: 0.030236
   Number of active neurons: 10
 >> iter 151000, loss: 0.012358
 >> iter 152000, loss: 0.086975
 >> iter 153000, loss: 0.033495
 >> iter 154000, loss: 0.020025
 >> iter 155000, loss: 0.133692
 >> iter 156000, loss: 0.051142
 >> iter 157000, loss: 0.020608
 >> iter 158000, loss: 0.009202
 >> iter 159000, loss: 0.005004
 >> iter 160000, loss: 0.003433
   Number of active neurons: 10
 >> iter 161000, loss: 0.002751
 >> iter 162000, loss: 0.002371
 >> iter 163000, loss: 0.002246
 >> iter 164000, loss: 0.002209
 >> iter 165000, loss: 0.001987
 >> iter 166000, loss: 0.001915
 >> iter 167000, loss: 0.001883
 >> iter 168000, loss: 0.001893
 >> iter 169000, loss: 0.001852
 >> iter 170000, loss: 0.002109
   Number of active neurons: 10
 >> iter 171000, loss: 0.001778
 >> iter 172000, loss: 0.003453
 >> iter 173000, loss: 0.002457
 >> iter 174000, loss: 0.002048
 >> iter 175000, loss: 0.001845
 >> iter 176000, loss: 0.001775
 >> iter 177000, loss: 0.017345
 >> iter 178000, loss: 0.007334
 >> iter 179000, loss: 0.003770
 >> iter 180000, loss: 0.002304
   Number of active neurons: 10
 >> iter 181000, loss: 0.001683
 >> iter 182000, loss: 0.043753
 >> iter 183000, loss: 0.017199
 >> iter 184000, loss: 0.007283
 >> iter 185000, loss: 0.004633
 >> iter 186000, loss: 0.002750
 >> iter 187000, loss: 0.001853
 >> iter 188000, loss: 0.001491
 >> iter 189000, loss: 0.001392
 >> iter 190000, loss: 0.001826
   Number of active neurons: 10
 >> iter 191000, loss: 0.001481
 >> iter 192000, loss: 0.001274
 >> iter 193000, loss: 0.001208
 >> iter 194000, loss: 0.001303
 >> iter 195000, loss: 0.001213
 >> iter 196000, loss: 0.001195
 >> iter 197000, loss: 0.001638
 >> iter 198000, loss: 0.001283
 >> iter 199000, loss: 0.001141
 >> iter 200000, loss: 0.001159
   Number of active neurons: 10
 >> iter 201000, loss: 0.001223
 >> iter 202000, loss: 0.001109
 >> iter 203000, loss: 0.001068
 >> iter 204000, loss: 0.001202
 >> iter 205000, loss: 0.039176
 >> iter 206000, loss: 0.015088
 >> iter 207000, loss: 0.011129
 >> iter 208000, loss: 0.051384
 >> iter 209000, loss: 0.019572
 >> iter 210000, loss: 0.007865
   Number of active neurons: 10
 >> iter 211000, loss: 0.003544
 >> iter 212000, loss: 0.002073
 >> iter 213000, loss: 0.001407
 >> iter 214000, loss: 0.001142
 >> iter 215000, loss: 0.001025
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.344504
 >> iter 2000, loss: 10.964271
 >> iter 3000, loss: 8.851419
 >> iter 4000, loss: 8.050366
 >> iter 5000, loss: 7.777591
 >> iter 6000, loss: 7.681288
 >> iter 7000, loss: 7.622167
 >> iter 8000, loss: 7.572086
 >> iter 9000, loss: 7.561120
 >> iter 10000, loss: 7.549930
   Number of active neurons: 10
 >> iter 11000, loss: 7.573395
 >> iter 12000, loss: 7.556241
 >> iter 13000, loss: 7.555831
 >> iter 14000, loss: 7.556209
 >> iter 15000, loss: 7.554988
 >> iter 16000, loss: 7.545576
 >> iter 17000, loss: 7.549930
 >> iter 18000, loss: 7.537847
 >> iter 19000, loss: 7.547708
 >> iter 20000, loss: 7.550203
   Number of active neurons: 9
 >> iter 21000, loss: 7.550508
 >> iter 22000, loss: 7.538270
 >> iter 23000, loss: 7.542054
 >> iter 24000, loss: 7.534725
 >> iter 25000, loss: 7.545593
 >> iter 26000, loss: 7.537637
 >> iter 27000, loss: 7.547475
 >> iter 28000, loss: 7.540920
 >> iter 29000, loss: 7.547506
 >> iter 30000, loss: 7.540566
   Number of active neurons: 10
 >> iter 31000, loss: 7.562681
 >> iter 32000, loss: 7.542726
 >> iter 33000, loss: 7.553319
 >> iter 34000, loss: 7.535374
 >> iter 35000, loss: 7.533787
 >> iter 36000, loss: 7.551097
 >> iter 37000, loss: 7.515638
 >> iter 38000, loss: 7.490836
 >> iter 39000, loss: 7.217477
 >> iter 40000, loss: 6.971744
   Number of active neurons: 10
 >> iter 41000, loss: 6.730621
 >> iter 42000, loss: 6.364716
 >> iter 43000, loss: 6.145524
 >> iter 44000, loss: 5.890264
 >> iter 45000, loss: 5.709606
 >> iter 46000, loss: 5.581837
 >> iter 47000, loss: 5.521384
 >> iter 48000, loss: 5.483827
 >> iter 49000, loss: 5.422298
 >> iter 50000, loss: 5.347103
   Number of active neurons: 10
 >> iter 51000, loss: 5.278572
 >> iter 52000, loss: 5.259154
 >> iter 53000, loss: 5.225334
 >> iter 54000, loss: 5.213849
 >> iter 55000, loss: 5.155471
 >> iter 56000, loss: 5.111094
 >> iter 57000, loss: 5.076642
 >> iter 58000, loss: 5.082619
 >> iter 59000, loss: 4.930887
 >> iter 60000, loss: 4.837979
   Number of active neurons: 10
 >> iter 61000, loss: 4.868789
 >> iter 62000, loss: 4.704045
 >> iter 63000, loss: 4.595848
 >> iter 64000, loss: 4.473437
 >> iter 65000, loss: 4.494006
 >> iter 66000, loss: 4.420253
 >> iter 67000, loss: 4.310831
 >> iter 68000, loss: 4.294955
 >> iter 69000, loss: 4.268719
 >> iter 70000, loss: 4.231175
   Number of active neurons: 10
 >> iter 71000, loss: 4.182919
 >> iter 72000, loss: 4.224584
 >> iter 73000, loss: 4.148350
 >> iter 74000, loss: 4.142506
 >> iter 75000, loss: 4.148789
 >> iter 76000, loss: 4.092912
 >> iter 77000, loss: 4.039790
 >> iter 78000, loss: 4.066938
 >> iter 79000, loss: 4.057004
 >> iter 80000, loss: 4.066410
   Number of active neurons: 10
 >> iter 81000, loss: 4.044789
 >> iter 82000, loss: 4.022017
 >> iter 83000, loss: 3.994987
 >> iter 84000, loss: 3.991247
 >> iter 85000, loss: 3.967407
 >> iter 86000, loss: 4.015856
 >> iter 87000, loss: 3.992538
 >> iter 88000, loss: 3.969168
 >> iter 89000, loss: 3.930272
 >> iter 90000, loss: 3.965363
   Number of active neurons: 10
 >> iter 91000, loss: 3.948922
 >> iter 92000, loss: 4.047632
 >> iter 93000, loss: 3.961570
 >> iter 94000, loss: 3.931030
 >> iter 95000, loss: 3.920158
 >> iter 96000, loss: 3.933190
 >> iter 97000, loss: 3.947951
 >> iter 98000, loss: 3.942863
 >> iter 99000, loss: 3.942898
 >> iter 100000, loss: 3.983983
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 9.2558148837
   - Test - Long: 22.2938853057
   - Test - Big: 9.0159098409
   - Test - A: 15.3056462902
   - Test - B: 0.579961335911
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.329763
 >> iter 2000, loss: 11.109943
 >> iter 3000, loss: 9.007016
 >> iter 4000, loss: 8.135672
 >> iter 5000, loss: 7.822387
 >> iter 6000, loss: 7.722162
 >> iter 7000, loss: 7.649636
 >> iter 8000, loss: 7.602550
 >> iter 9000, loss: 7.597166
 >> iter 10000, loss: 7.597458
   Number of active neurons: 9
 >> iter 11000, loss: 7.599889
 >> iter 12000, loss: 7.583412
 >> iter 13000, loss: 7.587735
 >> iter 14000, loss: 7.574206
 >> iter 15000, loss: 7.584343
 >> iter 16000, loss: 7.575760
 >> iter 17000, loss: 7.581256
 >> iter 18000, loss: 7.585699
 >> iter 19000, loss: 7.585974
 >> iter 20000, loss: 7.568647
   Number of active neurons: 9
 >> iter 21000, loss: 7.580885
 >> iter 22000, loss: 7.567429
 >> iter 23000, loss: 7.534236
 >> iter 24000, loss: 7.422393
 >> iter 25000, loss: 7.157905
 >> iter 26000, loss: 6.935379
 >> iter 27000, loss: 6.778285
 >> iter 28000, loss: 6.623860
 >> iter 29000, loss: 6.423456
 >> iter 30000, loss: 6.281344
   Number of active neurons: 10
 >> iter 31000, loss: 6.170918
 >> iter 32000, loss: 6.141396
 >> iter 33000, loss: 6.076532
 >> iter 34000, loss: 5.901293
 >> iter 35000, loss: 5.548514
 >> iter 36000, loss: 5.293078
 >> iter 37000, loss: 5.147012
 >> iter 38000, loss: 5.066255
 >> iter 39000, loss: 5.021161
 >> iter 40000, loss: 4.975372
   Number of active neurons: 10
 >> iter 41000, loss: 4.963959
 >> iter 42000, loss: 4.887794
 >> iter 43000, loss: 4.807037
 >> iter 44000, loss: 4.760832
 >> iter 45000, loss: 4.664286
 >> iter 46000, loss: 4.558512
 >> iter 47000, loss: 4.642746
 >> iter 48000, loss: 4.547929
 >> iter 49000, loss: 4.642598
 >> iter 50000, loss: 4.545831
   Number of active neurons: 10
 >> iter 51000, loss: 4.542221
 >> iter 52000, loss: 4.491823
 >> iter 53000, loss: 4.511794
 >> iter 54000, loss: 4.471291
 >> iter 55000, loss: 4.535402
 >> iter 56000, loss: 4.473362
 >> iter 57000, loss: 4.535590
 >> iter 58000, loss: 4.527948
 >> iter 59000, loss: 4.523739
 >> iter 60000, loss: 4.466199
   Number of active neurons: 10
 >> iter 61000, loss: 4.482020
 >> iter 62000, loss: 4.476887
 >> iter 63000, loss: 4.460942
 >> iter 64000, loss: 4.364235
 >> iter 65000, loss: 4.307237
 >> iter 66000, loss: 4.156506
 >> iter 67000, loss: 4.212257
 >> iter 68000, loss: 3.842522
 >> iter 69000, loss: 3.905276
 >> iter 70000, loss: 3.727551
   Number of active neurons: 10
 >> iter 71000, loss: 3.696545
 >> iter 72000, loss: 3.643664
 >> iter 73000, loss: 3.684896
 >> iter 74000, loss: 3.654215
 >> iter 75000, loss: 3.562677
 >> iter 76000, loss: 3.547921
 >> iter 77000, loss: 3.646284
 >> iter 78000, loss: 3.504411
 >> iter 79000, loss: 3.543651
 >> iter 80000, loss: 3.411683
   Number of active neurons: 10
 >> iter 81000, loss: 3.452069
 >> iter 82000, loss: 3.395292
 >> iter 83000, loss: 3.419411
 >> iter 84000, loss: 3.372982
 >> iter 85000, loss: 3.358118
 >> iter 86000, loss: 3.248441
 >> iter 87000, loss: 3.255645
 >> iter 88000, loss: 3.131022
 >> iter 89000, loss: 3.170921
 >> iter 90000, loss: 3.569111
   Number of active neurons: 10
 >> iter 91000, loss: 3.762780
 >> iter 92000, loss: 3.501969
 >> iter 93000, loss: 3.227846
 >> iter 94000, loss: 3.206294
 >> iter 95000, loss: 3.156292
 >> iter 96000, loss: 3.225616
 >> iter 97000, loss: 3.026678
 >> iter 98000, loss: 2.828550
 >> iter 99000, loss: 2.722566
 >> iter 100000, loss: 2.698409
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 1.93196136077
   - Test - Long: 15.4442277886
   - Test - Big: 1.77698223018
   - Test - A: 2.699820012
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.399241
 >> iter 2000, loss: 10.957209
 >> iter 3000, loss: 8.900810
 >> iter 4000, loss: 8.119545
 >> iter 5000, loss: 7.799136
 >> iter 6000, loss: 7.653951
 >> iter 7000, loss: 7.617449
 >> iter 8000, loss: 7.588008
 >> iter 9000, loss: 7.585858
 >> iter 10000, loss: 7.599271
   Number of active neurons: 10
 >> iter 11000, loss: 7.585640
 >> iter 12000, loss: 7.568976
 >> iter 13000, loss: 7.576724
 >> iter 14000, loss: 7.564172
 >> iter 15000, loss: 7.568686
 >> iter 16000, loss: 7.562237
 >> iter 17000, loss: 7.568082
 >> iter 18000, loss: 7.594728
 >> iter 19000, loss: 7.576081
 >> iter 20000, loss: 7.590838
   Number of active neurons: 10
 >> iter 21000, loss: 7.579464
 >> iter 22000, loss: 7.560404
 >> iter 23000, loss: 7.580072
 >> iter 24000, loss: 7.565754
 >> iter 25000, loss: 7.571451
 >> iter 26000, loss: 7.580354
 >> iter 27000, loss: 7.575713
 >> iter 28000, loss: 7.566526
 >> iter 29000, loss: 7.570358
 >> iter 30000, loss: 7.562883
   Number of active neurons: 10
 >> iter 31000, loss: 7.571338
 >> iter 32000, loss: 7.565867
 >> iter 33000, loss: 7.571880
 >> iter 34000, loss: 7.565369
 >> iter 35000, loss: 7.570321
 >> iter 36000, loss: 7.575544
 >> iter 37000, loss: 7.572770
 >> iter 38000, loss: 7.561635
 >> iter 39000, loss: 7.568246
 >> iter 40000, loss: 7.557734
   Number of active neurons: 10
 >> iter 41000, loss: 7.568712
 >> iter 42000, loss: 7.559263
 >> iter 43000, loss: 7.567570
 >> iter 44000, loss: 7.556165
 >> iter 45000, loss: 7.565141
 >> iter 46000, loss: 7.557043
 >> iter 47000, loss: 7.569176
 >> iter 48000, loss: 7.551390
 >> iter 49000, loss: 7.562426
 >> iter 50000, loss: 7.552466
   Number of active neurons: 10
 >> iter 51000, loss: 7.564662
 >> iter 52000, loss: 7.548728
 >> iter 53000, loss: 7.561504
 >> iter 54000, loss: 7.557301
 >> iter 55000, loss: 7.562464
 >> iter 56000, loss: 7.554064
 >> iter 57000, loss: 7.560564
 >> iter 58000, loss: 7.567674
 >> iter 59000, loss: 7.568333
 >> iter 60000, loss: 7.556354
   Number of active neurons: 10
 >> iter 61000, loss: 7.574354
 >> iter 62000, loss: 7.555282
 >> iter 63000, loss: 7.563307
 >> iter 64000, loss: 7.552661
 >> iter 65000, loss: 7.560911
 >> iter 66000, loss: 7.552901
 >> iter 67000, loss: 7.562977
 >> iter 68000, loss: 7.552078
 >> iter 69000, loss: 7.562578
 >> iter 70000, loss: 7.552995
   Number of active neurons: 10
 >> iter 71000, loss: 7.563342
 >> iter 72000, loss: 7.558846
 >> iter 73000, loss: 7.566543
 >> iter 74000, loss: 7.553259
 >> iter 75000, loss: 7.560507
 >> iter 76000, loss: 7.554941
 >> iter 77000, loss: 7.559466
 >> iter 78000, loss: 7.553140
 >> iter 79000, loss: 7.558356
 >> iter 80000, loss: 7.555702
   Number of active neurons: 10
 >> iter 81000, loss: 7.561612
 >> iter 82000, loss: 7.554783
 >> iter 83000, loss: 7.561038
 >> iter 84000, loss: 7.554986
 >> iter 85000, loss: 7.559247
 >> iter 86000, loss: 7.556247
 >> iter 87000, loss: 7.557521
 >> iter 88000, loss: 7.556735
 >> iter 89000, loss: 7.559451
 >> iter 90000, loss: 7.557823
   Number of active neurons: 10
 >> iter 91000, loss: 7.557946
 >> iter 92000, loss: 7.557695
 >> iter 93000, loss: 7.552632
 >> iter 94000, loss: 7.556117
 >> iter 95000, loss: 7.553245
 >> iter 96000, loss: 7.558567
 >> iter 97000, loss: 7.556780
 >> iter 98000, loss: 7.556543
 >> iter 99000, loss: 7.555015
 >> iter 100000, loss: 7.559127
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 20.6855862883
   - Test - Long: 24.5087745613
   - Test - Big: 20.6557934421
   - Test - A: 32.9178054796
   - Test - B: 32.4711685888

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

