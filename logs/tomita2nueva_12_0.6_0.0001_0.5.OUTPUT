 > Problema: tomita2nueva
 > Args:
   - Hidden size: 12
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.331625
 >> iter 2000, loss: 4.414195
 >> iter 3000, loss: 1.728078
 >> iter 4000, loss: 0.716700
 >> iter 5000, loss: 0.315703
 >> iter 6000, loss: 0.171042
 >> iter 7000, loss: 0.109270
 >> iter 8000, loss: 0.090452
 >> iter 9000, loss: 0.082809
 >> iter 10000, loss: 0.072039
   Number of active neurons: 9
 >> iter 11000, loss: 0.065051
 >> iter 12000, loss: 0.064405
 >> iter 13000, loss: 0.054611
 >> iter 14000, loss: 0.086160
 >> iter 15000, loss: 0.069623
 >> iter 16000, loss: 0.060418
 >> iter 17000, loss: 0.071169
 >> iter 18000, loss: 0.054326
 >> iter 19000, loss: 0.064271
 >> iter 20000, loss: 0.061680
   Number of active neurons: 5
 >> iter 21000, loss: 0.052399
 >> iter 22000, loss: 0.056763
 >> iter 23000, loss: 0.054255
 >> iter 24000, loss: 0.039412
 >> iter 25000, loss: 0.046617
 >> iter 26000, loss: 0.055416
 >> iter 27000, loss: 0.047637
 >> iter 28000, loss: 0.058786
 >> iter 29000, loss: 0.054488
 >> iter 30000, loss: 0.054897
   Number of active neurons: 5
 >> iter 31000, loss: 0.061087
 >> iter 32000, loss: 0.057461
 >> iter 33000, loss: 0.067420
 >> iter 34000, loss: 0.061693
 >> iter 35000, loss: 0.078494
 >> iter 36000, loss: 0.057795
 >> iter 37000, loss: 0.047290
 >> iter 38000, loss: 0.049494
 >> iter 39000, loss: 0.055926
 >> iter 40000, loss: 0.046631
   Number of active neurons: 3
 >> iter 41000, loss: 0.045665
 >> iter 42000, loss: 0.064517
 >> iter 43000, loss: 0.060013
 >> iter 44000, loss: 0.052096
 >> iter 45000, loss: 0.046912
 >> iter 46000, loss: 0.036503
 >> iter 47000, loss: 0.057471
 >> iter 48000, loss: 0.050895
 >> iter 49000, loss: 0.079230
 >> iter 50000, loss: 0.068396
   Number of active neurons: 3
 >> iter 51000, loss: 0.045027
 >> iter 52000, loss: 0.038984
 >> iter 53000, loss: 0.038789
 >> iter 54000, loss: 0.041077
 >> iter 55000, loss: 0.041391
 >> iter 56000, loss: 0.033760
 >> iter 57000, loss: 0.037370
 >> iter 58000, loss: 0.043880
 >> iter 59000, loss: 0.048500
 >> iter 60000, loss: 0.041918
   Number of active neurons: 3
 >> iter 61000, loss: 0.040185
 >> iter 62000, loss: 0.033327
 >> iter 63000, loss: 0.035969
 >> iter 64000, loss: 0.038218
 >> iter 65000, loss: 0.056461
 >> iter 66000, loss: 0.039253
 >> iter 67000, loss: 0.055134
 >> iter 68000, loss: 0.043366
 >> iter 69000, loss: 0.045172
 >> iter 70000, loss: 0.048870
   Number of active neurons: 3
 >> iter 71000, loss: 0.063016
 >> iter 72000, loss: 0.067260
 >> iter 73000, loss: 0.046454
 >> iter 74000, loss: 0.038405
 >> iter 75000, loss: 0.062130
 >> iter 76000, loss: 0.051071
 >> iter 77000, loss: 0.043208
 >> iter 78000, loss: 0.045532
 >> iter 79000, loss: 0.066877
 >> iter 80000, loss: 0.058325
   Number of active neurons: 3
 >> iter 81000, loss: 0.043606
 >> iter 82000, loss: 0.054361
 >> iter 83000, loss: 0.046136
 >> iter 84000, loss: 0.047543
 >> iter 85000, loss: 0.060946
 >> iter 86000, loss: 0.050909
 >> iter 87000, loss: 0.046729
 >> iter 88000, loss: 0.042483
 >> iter 89000, loss: 0.056340
 >> iter 90000, loss: 0.052047
   Number of active neurons: 3
 >> iter 91000, loss: 0.044315
 >> iter 92000, loss: 0.040037
 >> iter 93000, loss: 0.040919
 >> iter 94000, loss: 0.040052
 >> iter 95000, loss: 0.036618
 >> iter 96000, loss: 0.042939
 >> iter 97000, loss: 0.040874
 >> iter 98000, loss: 0.054817
 >> iter 99000, loss: 0.056544
 >> iter 100000, loss: 0.052159
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.377442
 >> iter 2000, loss: 4.456469
 >> iter 3000, loss: 1.750963
 >> iter 4000, loss: 0.702744
 >> iter 5000, loss: 0.328248
 >> iter 6000, loss: 0.179971
 >> iter 7000, loss: 0.113806
 >> iter 8000, loss: 0.086505
 >> iter 9000, loss: 0.089721
 >> iter 10000, loss: 0.077809
   Number of active neurons: 8
 >> iter 11000, loss: 0.069754
 >> iter 12000, loss: 0.068078
 >> iter 13000, loss: 0.087967
 >> iter 14000, loss: 0.096495
 >> iter 15000, loss: 0.068836
 >> iter 16000, loss: 0.062043
 >> iter 17000, loss: 0.053084
 >> iter 18000, loss: 0.077231
 >> iter 19000, loss: 0.058431
 >> iter 20000, loss: 0.053517
   Number of active neurons: 7
 >> iter 21000, loss: 0.064708
 >> iter 22000, loss: 0.071994
 >> iter 23000, loss: 0.100456
 >> iter 24000, loss: 0.064551
 >> iter 25000, loss: 0.081067
 >> iter 26000, loss: 0.055855
 >> iter 27000, loss: 0.060919
 >> iter 28000, loss: 0.056851
 >> iter 29000, loss: 0.059010
 >> iter 30000, loss: 0.055335
   Number of active neurons: 5
 >> iter 31000, loss: 0.050947
 >> iter 32000, loss: 0.070090
 >> iter 33000, loss: 0.059666
 >> iter 34000, loss: 0.052606
 >> iter 35000, loss: 0.055900
 >> iter 36000, loss: 0.075494
 >> iter 37000, loss: 0.065468
 >> iter 38000, loss: 0.050834
 >> iter 39000, loss: 0.047182
 >> iter 40000, loss: 0.042700
   Number of active neurons: 5
 >> iter 41000, loss: 0.047342
 >> iter 42000, loss: 0.039063
 >> iter 43000, loss: 0.060970
 >> iter 44000, loss: 0.063653
 >> iter 45000, loss: 0.057763
 >> iter 46000, loss: 0.056058
 >> iter 47000, loss: 0.054255
 >> iter 48000, loss: 0.036024
 >> iter 49000, loss: 0.063672
 >> iter 50000, loss: 0.082338
   Number of active neurons: 5
 >> iter 51000, loss: 0.075265
 >> iter 52000, loss: 0.063591
 >> iter 53000, loss: 0.046627
 >> iter 54000, loss: 0.055530
 >> iter 55000, loss: 0.043620
 >> iter 56000, loss: 0.047549
 >> iter 57000, loss: 0.048106
 >> iter 58000, loss: 0.057291
 >> iter 59000, loss: 0.057928
 >> iter 60000, loss: 0.052030
   Number of active neurons: 5
 >> iter 61000, loss: 0.070266
 >> iter 62000, loss: 0.049258
 >> iter 63000, loss: 0.045002
 >> iter 64000, loss: 0.040756
 >> iter 65000, loss: 0.042674
 >> iter 66000, loss: 0.054494
 >> iter 67000, loss: 0.047134
 >> iter 68000, loss: 0.044674
 >> iter 69000, loss: 0.062918
 >> iter 70000, loss: 0.056379
   Number of active neurons: 5
 >> iter 71000, loss: 0.060814
 >> iter 72000, loss: 0.041920
 >> iter 73000, loss: 0.046925
 >> iter 74000, loss: 0.042295
 >> iter 75000, loss: 0.052856
 >> iter 76000, loss: 0.046600
 >> iter 77000, loss: 0.059374
 >> iter 78000, loss: 0.052452
 >> iter 79000, loss: 0.046630
 >> iter 80000, loss: 0.043526
   Number of active neurons: 4
 >> iter 81000, loss: 0.056314
 >> iter 82000, loss: 0.042112
 >> iter 83000, loss: 0.040908
 >> iter 84000, loss: 0.046257
 >> iter 85000, loss: 0.038698
 >> iter 86000, loss: 0.053396
 >> iter 87000, loss: 0.054102
 >> iter 88000, loss: 0.045544
 >> iter 89000, loss: 0.049735
 >> iter 90000, loss: 0.037396
   Number of active neurons: 4
 >> iter 91000, loss: 0.040849
 >> iter 92000, loss: 0.042562
 >> iter 93000, loss: 0.040447
 >> iter 94000, loss: 0.038767
 >> iter 95000, loss: 0.046487
 >> iter 96000, loss: 0.042409
 >> iter 97000, loss: 0.036291
 >> iter 98000, loss: 0.065888
 >> iter 99000, loss: 0.046466
 >> iter 100000, loss: 0.042663
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.322694
 >> iter 2000, loss: 4.416213
 >> iter 3000, loss: 1.748446
 >> iter 4000, loss: 0.739628
 >> iter 5000, loss: 0.346935
 >> iter 6000, loss: 0.165002
 >> iter 7000, loss: 0.133834
 >> iter 8000, loss: 0.101837
 >> iter 9000, loss: 0.079407
 >> iter 10000, loss: 0.096684
   Number of active neurons: 9
 >> iter 11000, loss: 0.084979
 >> iter 12000, loss: 0.074335
 >> iter 13000, loss: 0.077437
 >> iter 14000, loss: 0.052639
 >> iter 15000, loss: 0.084099
 >> iter 16000, loss: 0.084363
 >> iter 17000, loss: 0.100427
 >> iter 18000, loss: 0.077991
 >> iter 19000, loss: 0.064164
 >> iter 20000, loss: 0.063063
   Number of active neurons: 6
 >> iter 21000, loss: 0.061929
 >> iter 22000, loss: 0.058950
 >> iter 23000, loss: 0.054801
 >> iter 24000, loss: 0.051509
 >> iter 25000, loss: 0.050908
 >> iter 26000, loss: 0.047684
 >> iter 27000, loss: 0.054615
 >> iter 28000, loss: 0.044571
 >> iter 29000, loss: 0.048525
 >> iter 30000, loss: 0.046671
   Number of active neurons: 6
 >> iter 31000, loss: 0.070476
 >> iter 32000, loss: 0.051174
 >> iter 33000, loss: 0.063252
 >> iter 34000, loss: 0.047860
 >> iter 35000, loss: 0.035372
 >> iter 36000, loss: 0.045893
 >> iter 37000, loss: 0.045313
 >> iter 38000, loss: 0.042949
 >> iter 39000, loss: 0.058769
 >> iter 40000, loss: 0.052337
   Number of active neurons: 5
 >> iter 41000, loss: 0.061635
 >> iter 42000, loss: 0.065295
 >> iter 43000, loss: 0.058031
 >> iter 44000, loss: 0.054493
 >> iter 45000, loss: 0.061362
 >> iter 46000, loss: 0.060630
 >> iter 47000, loss: 0.048777
 >> iter 48000, loss: 0.051225
 >> iter 49000, loss: 0.058269
 >> iter 50000, loss: 0.048060
   Number of active neurons: 5
 >> iter 51000, loss: 0.039008
 >> iter 52000, loss: 0.043763
 >> iter 53000, loss: 0.054866
 >> iter 54000, loss: 0.058586
 >> iter 55000, loss: 0.064045
 >> iter 56000, loss: 0.056561
 >> iter 57000, loss: 0.043615
 >> iter 58000, loss: 0.044290
 >> iter 59000, loss: 0.054649
 >> iter 60000, loss: 0.052726
   Number of active neurons: 4
 >> iter 61000, loss: 0.039036
 >> iter 62000, loss: 0.053329
 >> iter 63000, loss: 0.062310
 >> iter 64000, loss: 0.044936
 >> iter 65000, loss: 0.050903
 >> iter 66000, loss: 0.048534
 >> iter 67000, loss: 0.045841
 >> iter 68000, loss: 0.038577
 >> iter 69000, loss: 0.038350
 >> iter 70000, loss: 0.044170
   Number of active neurons: 4
 >> iter 71000, loss: 0.074022
 >> iter 72000, loss: 0.050741
 >> iter 73000, loss: 0.052755
 >> iter 74000, loss: 0.042788
 >> iter 75000, loss: 0.057094
 >> iter 76000, loss: 0.043940
 >> iter 77000, loss: 0.050292
 >> iter 78000, loss: 0.050685
 >> iter 79000, loss: 0.044938
 >> iter 80000, loss: 0.036504
   Number of active neurons: 3
 >> iter 81000, loss: 0.046585
 >> iter 82000, loss: 0.041652
 >> iter 83000, loss: 0.047844
 >> iter 84000, loss: 0.054541
 >> iter 85000, loss: 0.056510
 >> iter 86000, loss: 0.044662
 >> iter 87000, loss: 0.042193
 >> iter 88000, loss: 0.039319
 >> iter 89000, loss: 0.037459
 >> iter 90000, loss: 0.040950
   Number of active neurons: 3
 >> iter 91000, loss: 0.049997
 >> iter 92000, loss: 0.034919
 >> iter 93000, loss: 0.055465
 >> iter 94000, loss: 0.041952
 >> iter 95000, loss: 0.046947
 >> iter 96000, loss: 0.036083
 >> iter 97000, loss: 0.038696
 >> iter 98000, loss: 0.050966
 >> iter 99000, loss: 0.060250
 >> iter 100000, loss: 0.045962
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.289092
 >> iter 2000, loss: 4.351797
 >> iter 3000, loss: 1.714045
 >> iter 4000, loss: 0.718949
 >> iter 5000, loss: 0.347045
 >> iter 6000, loss: 0.176762
 >> iter 7000, loss: 0.126101
 >> iter 8000, loss: 0.083652
 >> iter 9000, loss: 0.069683
 >> iter 10000, loss: 0.073373
   Number of active neurons: 8
 >> iter 11000, loss: 0.062589
 >> iter 12000, loss: 0.056059
 >> iter 13000, loss: 0.053290
 >> iter 14000, loss: 0.078072
 >> iter 15000, loss: 0.085019
 >> iter 16000, loss: 0.073582
 >> iter 17000, loss: 0.071206
 >> iter 18000, loss: 0.061829
 >> iter 19000, loss: 0.062698
 >> iter 20000, loss: 0.049981
   Number of active neurons: 8
 >> iter 21000, loss: 0.053229
 >> iter 22000, loss: 0.054804
 >> iter 23000, loss: 0.059942
 >> iter 24000, loss: 0.055548
 >> iter 25000, loss: 0.047555
 >> iter 26000, loss: 0.037621
 >> iter 27000, loss: 0.058214
 >> iter 28000, loss: 0.041467
 >> iter 29000, loss: 0.049513
 >> iter 30000, loss: 0.058774
   Number of active neurons: 6
 >> iter 31000, loss: 0.090266
 >> iter 32000, loss: 0.087971
 >> iter 33000, loss: 0.067285
 >> iter 34000, loss: 0.069821
 >> iter 35000, loss: 0.085594
 >> iter 36000, loss: 0.060163
 >> iter 37000, loss: 0.054588
 >> iter 38000, loss: 0.047807
 >> iter 39000, loss: 0.044573
 >> iter 40000, loss: 0.051641
   Number of active neurons: 6
 >> iter 41000, loss: 0.055368
 >> iter 42000, loss: 0.067856
 >> iter 43000, loss: 0.065960
 >> iter 44000, loss: 0.075923
 >> iter 45000, loss: 0.051898
 >> iter 46000, loss: 0.051289
 >> iter 47000, loss: 0.083468
 >> iter 48000, loss: 0.059824
 >> iter 49000, loss: 0.075789
 >> iter 50000, loss: 0.067464
   Number of active neurons: 4
 >> iter 51000, loss: 0.056557
 >> iter 52000, loss: 0.056431
 >> iter 53000, loss: 0.053014
 >> iter 54000, loss: 0.049961
 >> iter 55000, loss: 0.041420
 >> iter 56000, loss: 0.049149
 >> iter 57000, loss: 0.044101
 >> iter 58000, loss: 0.053728
 >> iter 59000, loss: 0.051714
 >> iter 60000, loss: 0.044871
   Number of active neurons: 4
 >> iter 61000, loss: 0.062356
 >> iter 62000, loss: 0.054061
 >> iter 63000, loss: 0.048077
 >> iter 64000, loss: 0.052517
 >> iter 65000, loss: 0.058648
 >> iter 66000, loss: 0.039617
 >> iter 67000, loss: 0.046962
 >> iter 68000, loss: 0.059175
 >> iter 69000, loss: 0.072161
 >> iter 70000, loss: 0.046027
   Number of active neurons: 3
 >> iter 71000, loss: 0.046880
 >> iter 72000, loss: 0.053930
 >> iter 73000, loss: 0.052244
 >> iter 74000, loss: 0.069512
 >> iter 75000, loss: 0.072759
 >> iter 76000, loss: 0.047450
 >> iter 77000, loss: 0.050071
 >> iter 78000, loss: 0.047007
 >> iter 79000, loss: 0.040706
 >> iter 80000, loss: 0.039461
   Number of active neurons: 2
 >> iter 81000, loss: 0.067097
 >> iter 82000, loss: 0.040779
 >> iter 83000, loss: 0.041139
 >> iter 84000, loss: 0.047729
 >> iter 85000, loss: 0.054073
 >> iter 86000, loss: 0.037787
 >> iter 87000, loss: 0.069863
 >> iter 88000, loss: 0.044668
 >> iter 89000, loss: 0.052460
 >> iter 90000, loss: 0.064201
   Number of active neurons: 2
 >> iter 91000, loss: 0.053971
 >> iter 92000, loss: 0.040570
 >> iter 93000, loss: 0.046479
 >> iter 94000, loss: 0.042660
 >> iter 95000, loss: 0.055073
 >> iter 96000, loss: 0.058692
 >> iter 97000, loss: 0.045924
 >> iter 98000, loss: 0.031762
 >> iter 99000, loss: 0.029374
 >> iter 100000, loss: 0.057075
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.340571
 >> iter 2000, loss: 4.432586
 >> iter 3000, loss: 1.746453
 >> iter 4000, loss: 0.753229
 >> iter 5000, loss: 0.379786
 >> iter 6000, loss: 0.212246
 >> iter 7000, loss: 0.140695
 >> iter 8000, loss: 0.106632
 >> iter 9000, loss: 0.091211
 >> iter 10000, loss: 0.107025
   Number of active neurons: 9
 >> iter 11000, loss: 0.085706
 >> iter 12000, loss: 0.075322
 >> iter 13000, loss: 0.074312
 >> iter 14000, loss: 0.073424
 >> iter 15000, loss: 0.055409
 >> iter 16000, loss: 0.063324
 >> iter 17000, loss: 0.063905
 >> iter 18000, loss: 0.075907
 >> iter 19000, loss: 0.067384
 >> iter 20000, loss: 0.058172
   Number of active neurons: 7
 >> iter 21000, loss: 0.061564
 >> iter 22000, loss: 0.063845
 >> iter 23000, loss: 0.046780
 >> iter 24000, loss: 0.048059
 >> iter 25000, loss: 0.061312
 >> iter 26000, loss: 0.054494
 >> iter 27000, loss: 0.052373
 >> iter 28000, loss: 0.050599
 >> iter 29000, loss: 0.043456
 >> iter 30000, loss: 0.061524
   Number of active neurons: 6
 >> iter 31000, loss: 0.055934
 >> iter 32000, loss: 0.047136
 >> iter 33000, loss: 0.038918
 >> iter 34000, loss: 0.044892
 >> iter 35000, loss: 0.072171
 >> iter 36000, loss: 0.063662
 >> iter 37000, loss: 0.056578
 >> iter 38000, loss: 0.047633
 >> iter 39000, loss: 0.051271
 >> iter 40000, loss: 0.078893
   Number of active neurons: 5
 >> iter 41000, loss: 0.053378
 >> iter 42000, loss: 0.056153
 >> iter 43000, loss: 0.069251
 >> iter 44000, loss: 0.052402
 >> iter 45000, loss: 0.048798
 >> iter 46000, loss: 0.062162
 >> iter 47000, loss: 0.057516
 >> iter 48000, loss: 0.047620
 >> iter 49000, loss: 0.045688
 >> iter 50000, loss: 0.041187
   Number of active neurons: 5
 >> iter 51000, loss: 0.046880
 >> iter 52000, loss: 0.058121
 >> iter 53000, loss: 0.050308
 >> iter 54000, loss: 0.058759
 >> iter 55000, loss: 0.063529
 >> iter 56000, loss: 0.070488
 >> iter 57000, loss: 0.049412
 >> iter 58000, loss: 0.045582
 >> iter 59000, loss: 0.037728
 >> iter 60000, loss: 0.051096
   Number of active neurons: 5
 >> iter 61000, loss: 0.051350
 >> iter 62000, loss: 0.043177
 >> iter 63000, loss: 0.043085
 >> iter 64000, loss: 0.083458
 >> iter 65000, loss: 0.063496
 >> iter 66000, loss: 0.052435
 >> iter 67000, loss: 0.058013
 >> iter 68000, loss: 0.049142
 >> iter 69000, loss: 0.060624
 >> iter 70000, loss: 0.049838
   Number of active neurons: 5
 >> iter 71000, loss: 0.047486
 >> iter 72000, loss: 0.049712
 >> iter 73000, loss: 0.049837
 >> iter 74000, loss: 0.056502
 >> iter 75000, loss: 0.051209
 >> iter 76000, loss: 0.068135
 >> iter 77000, loss: 0.065990
 >> iter 78000, loss: 0.070480
 >> iter 79000, loss: 0.071328
 >> iter 80000, loss: 0.059275
   Number of active neurons: 5
 >> iter 81000, loss: 0.079869
 >> iter 82000, loss: 0.053753
 >> iter 83000, loss: 0.042554
 >> iter 84000, loss: 0.053681
 >> iter 85000, loss: 0.061634
 >> iter 86000, loss: 0.049125
 >> iter 87000, loss: 0.043824
 >> iter 88000, loss: 0.038316
 >> iter 89000, loss: 0.049718
 >> iter 90000, loss: 0.054116
   Number of active neurons: 4
 >> iter 91000, loss: 0.037671
 >> iter 92000, loss: 0.049180
 >> iter 93000, loss: 0.045784
 >> iter 94000, loss: 0.049372
 >> iter 95000, loss: 0.045333
 >> iter 96000, loss: 0.038230
 >> iter 97000, loss: 0.085473
 >> iter 98000, loss: 0.061119
 >> iter 99000, loss: 0.062105
 >> iter 100000, loss: 0.052847
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.325376
 >> iter 2000, loss: 4.395197
 >> iter 3000, loss: 1.725854
 >> iter 4000, loss: 0.715361
 >> iter 5000, loss: 0.347288
 >> iter 6000, loss: 0.179704
 >> iter 7000, loss: 0.145746
 >> iter 8000, loss: 0.117430
 >> iter 9000, loss: 0.089976
 >> iter 10000, loss: 0.082251
   Number of active neurons: 8
 >> iter 11000, loss: 0.075488
 >> iter 12000, loss: 0.056767
 >> iter 13000, loss: 0.060342
 >> iter 14000, loss: 0.074952
 >> iter 15000, loss: 0.073007
 >> iter 16000, loss: 0.052344
 >> iter 17000, loss: 0.087073
 >> iter 18000, loss: 0.086673
 >> iter 19000, loss: 0.060851
 >> iter 20000, loss: 0.073025
   Number of active neurons: 8
 >> iter 21000, loss: 0.070063
 >> iter 22000, loss: 0.056669
 >> iter 23000, loss: 0.071261
 >> iter 24000, loss: 0.060953
 >> iter 25000, loss: 0.058472
 >> iter 26000, loss: 0.048406
 >> iter 27000, loss: 0.050495
 >> iter 28000, loss: 0.082126
 >> iter 29000, loss: 0.056970
 >> iter 30000, loss: 0.074374
   Number of active neurons: 7
 >> iter 31000, loss: 0.049198
 >> iter 32000, loss: 0.079362
 >> iter 33000, loss: 0.082607
 >> iter 34000, loss: 0.066869
 >> iter 35000, loss: 0.064722
 >> iter 36000, loss: 0.082754
 >> iter 37000, loss: 0.060542
 >> iter 38000, loss: 0.051937
 >> iter 39000, loss: 0.062867
 >> iter 40000, loss: 0.057954
   Number of active neurons: 4
 >> iter 41000, loss: 0.057324
 >> iter 42000, loss: 0.040943
 >> iter 43000, loss: 0.054804
 >> iter 44000, loss: 0.067274
 >> iter 45000, loss: 0.059999
 >> iter 46000, loss: 0.044664
 >> iter 47000, loss: 0.043765
 >> iter 48000, loss: 0.035699
 >> iter 49000, loss: 0.060716
 >> iter 50000, loss: 0.060214
   Number of active neurons: 4
 >> iter 51000, loss: 0.056921
 >> iter 52000, loss: 0.035971
 >> iter 53000, loss: 0.042427
 >> iter 54000, loss: 0.035843
 >> iter 55000, loss: 0.039439
 >> iter 56000, loss: 0.033470
 >> iter 57000, loss: 0.058873
 >> iter 58000, loss: 0.052209
 >> iter 59000, loss: 0.043224
 >> iter 60000, loss: 0.038538
   Number of active neurons: 4
 >> iter 61000, loss: 0.042077
 >> iter 62000, loss: 0.038601
 >> iter 63000, loss: 0.038674
 >> iter 64000, loss: 0.046979
 >> iter 65000, loss: 0.044867
 >> iter 66000, loss: 0.033981
 >> iter 67000, loss: 0.040661
 >> iter 68000, loss: 0.035774
 >> iter 69000, loss: 0.044490
 >> iter 70000, loss: 0.036176
   Number of active neurons: 4
 >> iter 71000, loss: 0.042603
 >> iter 72000, loss: 0.068458
 >> iter 73000, loss: 0.053626
 >> iter 74000, loss: 0.042675
 >> iter 75000, loss: 0.038016
 >> iter 76000, loss: 0.044088
 >> iter 77000, loss: 0.068111
 >> iter 78000, loss: 0.053230
 >> iter 79000, loss: 0.072115
 >> iter 80000, loss: 0.051584
   Number of active neurons: 4
 >> iter 81000, loss: 0.040504
 >> iter 82000, loss: 0.044852
 >> iter 83000, loss: 0.052402
 >> iter 84000, loss: 0.055530
 >> iter 85000, loss: 0.038976
 >> iter 86000, loss: 0.042909
 >> iter 87000, loss: 0.038558
 >> iter 88000, loss: 0.048439
 >> iter 89000, loss: 0.050787
 >> iter 90000, loss: 0.041750
   Number of active neurons: 3
 >> iter 91000, loss: 0.055978
 >> iter 92000, loss: 0.048666
 >> iter 93000, loss: 0.039280
 >> iter 94000, loss: 0.044834
 >> iter 95000, loss: 0.056085
 >> iter 96000, loss: 0.056573
 >> iter 97000, loss: 0.044650
 >> iter 98000, loss: 0.062445
 >> iter 99000, loss: 0.043342
 >> iter 100000, loss: 0.052626
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 11.331806
 >> iter 2000, loss: 4.403144
 >> iter 3000, loss: 1.720658
 >> iter 4000, loss: 0.698456
 >> iter 5000, loss: 0.331358
 >> iter 6000, loss: 0.165871
 >> iter 7000, loss: 0.140066
 >> iter 8000, loss: 0.085878
 >> iter 9000, loss: 0.072513
 >> iter 10000, loss: 0.073767
   Number of active neurons: 8
 >> iter 11000, loss: 0.064264
 >> iter 12000, loss: 0.054360
 >> iter 13000, loss: 0.070273
 >> iter 14000, loss: 0.060927
 >> iter 15000, loss: 0.050382
 >> iter 16000, loss: 0.084376
 >> iter 17000, loss: 0.063333
 >> iter 18000, loss: 0.051618
 >> iter 19000, loss: 0.075831
 >> iter 20000, loss: 0.066804
   Number of active neurons: 6
 >> iter 21000, loss: 0.057657
 >> iter 22000, loss: 0.050956
 >> iter 23000, loss: 0.044381
 >> iter 24000, loss: 0.040527
 >> iter 25000, loss: 0.056472
 >> iter 26000, loss: 0.055112
 >> iter 27000, loss: 0.064035
 >> iter 28000, loss: 0.051068
 >> iter 29000, loss: 0.060693
 >> iter 30000, loss: 0.076949
   Number of active neurons: 5
 >> iter 31000, loss: 0.060936
 >> iter 32000, loss: 0.047904
 >> iter 33000, loss: 0.059188
 >> iter 34000, loss: 0.060721
 >> iter 35000, loss: 0.051473
 >> iter 36000, loss: 0.049407
 >> iter 37000, loss: 0.044547
 >> iter 38000, loss: 0.054324
 >> iter 39000, loss: 0.046875
 >> iter 40000, loss: 0.050820
   Number of active neurons: 5
 >> iter 41000, loss: 0.044176
 >> iter 42000, loss: 0.061990
 >> iter 43000, loss: 0.048456
 >> iter 44000, loss: 0.051518
 >> iter 45000, loss: 0.041892
 >> iter 46000, loss: 0.072759
 >> iter 47000, loss: 0.058129
 >> iter 48000, loss: 0.044143
 >> iter 49000, loss: 0.048256
 >> iter 50000, loss: 0.086560
   Number of active neurons: 5
 >> iter 51000, loss: 0.056936
 >> iter 52000, loss: 0.046504
 >> iter 53000, loss: 0.072161
 >> iter 54000, loss: 0.051357
 >> iter 55000, loss: 0.046920
 >> iter 56000, loss: 0.043381
 >> iter 57000, loss: 0.038672
 >> iter 58000, loss: 0.031934
 >> iter 59000, loss: 0.048774
 >> iter 60000, loss: 0.046494
   Number of active neurons: 4
 >> iter 61000, loss: 0.049595
 >> iter 62000, loss: 0.040439
 >> iter 63000, loss: 0.046699
 >> iter 64000, loss: 0.044728
 >> iter 65000, loss: 0.043248
 >> iter 66000, loss: 0.038355
 >> iter 67000, loss: 0.032110
 >> iter 68000, loss: 0.039489
 >> iter 69000, loss: 0.042137
 >> iter 70000, loss: 0.048329
   Number of active neurons: 4
 >> iter 71000, loss: 0.044136
 >> iter 72000, loss: 0.042445
 >> iter 73000, loss: 0.043240
 >> iter 74000, loss: 0.062849
 >> iter 75000, loss: 0.072794
 >> iter 76000, loss: 0.047437
 >> iter 77000, loss: 0.041788
 >> iter 78000, loss: 0.036415
 >> iter 79000, loss: 0.032824
 >> iter 80000, loss: 0.034768
   Number of active neurons: 4
 >> iter 81000, loss: 0.040427
 >> iter 82000, loss: 0.063274
 >> iter 83000, loss: 0.056864
 >> iter 84000, loss: 0.048730
 >> iter 85000, loss: 0.050400
 >> iter 86000, loss: 0.057857
 >> iter 87000, loss: 0.042472
 >> iter 88000, loss: 0.039823
 >> iter 89000, loss: 0.049911
 >> iter 90000, loss: 0.047780
   Number of active neurons: 4
 >> iter 91000, loss: 0.064557
 >> iter 92000, loss: 0.041491
 >> iter 93000, loss: 0.048184
 >> iter 94000, loss: 0.051427
 >> iter 95000, loss: 0.041953
 >> iter 96000, loss: 0.043255
 >> iter 97000, loss: 0.053216
 >> iter 98000, loss: 0.038601
 >> iter 99000, loss: 0.040528
 >> iter 100000, loss: 0.040807
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.428367
 >> iter 2000, loss: 4.445128
 >> iter 3000, loss: 1.764812
 >> iter 4000, loss: 0.750504
 >> iter 5000, loss: 0.355564
 >> iter 6000, loss: 0.177673
 >> iter 7000, loss: 0.135759
 >> iter 8000, loss: 0.102187
 >> iter 9000, loss: 0.087750
 >> iter 10000, loss: 0.066679
   Number of active neurons: 9
 >> iter 11000, loss: 0.062650
 >> iter 12000, loss: 0.071543
 >> iter 13000, loss: 0.077930
 >> iter 14000, loss: 0.079970
 >> iter 15000, loss: 0.068378
 >> iter 16000, loss: 0.064921
 >> iter 17000, loss: 0.080839
 >> iter 18000, loss: 0.062493
 >> iter 19000, loss: 0.054275
 >> iter 20000, loss: 0.057825
   Number of active neurons: 7
 >> iter 21000, loss: 0.059262
 >> iter 22000, loss: 0.054098
 >> iter 23000, loss: 0.058855
 >> iter 24000, loss: 0.043203
 >> iter 25000, loss: 0.059089
 >> iter 26000, loss: 0.059688
 >> iter 27000, loss: 0.053933
 >> iter 28000, loss: 0.045656
 >> iter 29000, loss: 0.048570
 >> iter 30000, loss: 0.049620
   Number of active neurons: 5
 >> iter 31000, loss: 0.045194
 >> iter 32000, loss: 0.045431
 >> iter 33000, loss: 0.053271
 >> iter 34000, loss: 0.047245
 >> iter 35000, loss: 0.057931
 >> iter 36000, loss: 0.041800
 >> iter 37000, loss: 0.046288
 >> iter 38000, loss: 0.047199
 >> iter 39000, loss: 0.043124
 >> iter 40000, loss: 0.043734
   Number of active neurons: 4
 >> iter 41000, loss: 0.037250
 >> iter 42000, loss: 0.039332
 >> iter 43000, loss: 0.042788
 >> iter 44000, loss: 0.062557
 >> iter 45000, loss: 0.056045
 >> iter 46000, loss: 0.047084
 >> iter 47000, loss: 0.054377
 >> iter 48000, loss: 0.054433
 >> iter 49000, loss: 0.047950
 >> iter 50000, loss: 0.036532
   Number of active neurons: 4
 >> iter 51000, loss: 0.039564
 >> iter 52000, loss: 0.049392
 >> iter 53000, loss: 0.049114
 >> iter 54000, loss: 0.047557
 >> iter 55000, loss: 0.051560
 >> iter 56000, loss: 0.058547
 >> iter 57000, loss: 0.044486
 >> iter 58000, loss: 0.046554
 >> iter 59000, loss: 0.057694
 >> iter 60000, loss: 0.066980
   Number of active neurons: 3
 >> iter 61000, loss: 0.068975
 >> iter 62000, loss: 0.071891
 >> iter 63000, loss: 0.049867
 >> iter 64000, loss: 0.036468
 >> iter 65000, loss: 0.036776
 >> iter 66000, loss: 0.031481
 >> iter 67000, loss: 0.038723
 >> iter 68000, loss: 0.061210
 >> iter 69000, loss: 0.048915
 >> iter 70000, loss: 0.041299
   Number of active neurons: 3
 >> iter 71000, loss: 0.051721
 >> iter 72000, loss: 0.039765
 >> iter 73000, loss: 0.032137
 >> iter 74000, loss: 0.051246
 >> iter 75000, loss: 0.079893
 >> iter 76000, loss: 0.051181
 >> iter 77000, loss: 0.041000
 >> iter 78000, loss: 0.067549
 >> iter 79000, loss: 0.059649
 >> iter 80000, loss: 0.050111
   Number of active neurons: 3
 >> iter 81000, loss: 0.038199
 >> iter 82000, loss: 0.040576
 >> iter 83000, loss: 0.046431
 >> iter 84000, loss: 0.038746
 >> iter 85000, loss: 0.046003
 >> iter 86000, loss: 0.050748
 >> iter 87000, loss: 0.045257
 >> iter 88000, loss: 0.040695
 >> iter 89000, loss: 0.038915
 >> iter 90000, loss: 0.056362
   Number of active neurons: 3
 >> iter 91000, loss: 0.055281
 >> iter 92000, loss: 0.045507
 >> iter 93000, loss: 0.062455
 >> iter 94000, loss: 0.043280
 >> iter 95000, loss: 0.035376
 >> iter 96000, loss: 0.037526
 >> iter 97000, loss: 0.047768
 >> iter 98000, loss: 0.058551
 >> iter 99000, loss: 0.062668
 >> iter 100000, loss: 0.042170
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.323720
 >> iter 2000, loss: 4.437000
 >> iter 3000, loss: 1.783943
 >> iter 4000, loss: 0.729323
 >> iter 5000, loss: 0.367058
 >> iter 6000, loss: 0.192254
 >> iter 7000, loss: 0.134487
 >> iter 8000, loss: 0.109296
 >> iter 9000, loss: 0.098480
 >> iter 10000, loss: 0.098108
   Number of active neurons: 9
 >> iter 11000, loss: 0.088434
 >> iter 12000, loss: 0.074599
 >> iter 13000, loss: 0.072097
 >> iter 14000, loss: 0.062567
 >> iter 15000, loss: 0.076124
 >> iter 16000, loss: 0.076527
 >> iter 17000, loss: 0.075921
 >> iter 18000, loss: 0.068315
 >> iter 19000, loss: 0.055922
 >> iter 20000, loss: 0.053995
   Number of active neurons: 7
 >> iter 21000, loss: 0.054172
 >> iter 22000, loss: 0.047419
 >> iter 23000, loss: 0.050323
 >> iter 24000, loss: 0.044002
 >> iter 25000, loss: 0.054225
 >> iter 26000, loss: 0.040054
 >> iter 27000, loss: 0.056856
 >> iter 28000, loss: 0.046334
 >> iter 29000, loss: 0.069423
 >> iter 30000, loss: 0.050876
   Number of active neurons: 6
 >> iter 31000, loss: 0.044260
 >> iter 32000, loss: 0.040293
 >> iter 33000, loss: 0.064519
 >> iter 34000, loss: 0.044569
 >> iter 35000, loss: 0.038348
 >> iter 36000, loss: 0.058910
 >> iter 37000, loss: 0.043707
 >> iter 38000, loss: 0.060892
 >> iter 39000, loss: 0.064909
 >> iter 40000, loss: 0.048036
   Number of active neurons: 6
 >> iter 41000, loss: 0.039533
 >> iter 42000, loss: 0.061367
 >> iter 43000, loss: 0.059504
 >> iter 44000, loss: 0.055539
 >> iter 45000, loss: 0.044853
 >> iter 46000, loss: 0.041471
 >> iter 47000, loss: 0.039616
 >> iter 48000, loss: 0.056133
 >> iter 49000, loss: 0.058510
 >> iter 50000, loss: 0.063051
   Number of active neurons: 4
 >> iter 51000, loss: 0.046812
 >> iter 52000, loss: 0.052180
 >> iter 53000, loss: 0.063181
 >> iter 54000, loss: 0.047497
 >> iter 55000, loss: 0.062156
 >> iter 56000, loss: 0.050018
 >> iter 57000, loss: 0.053227
 >> iter 58000, loss: 0.044205
 >> iter 59000, loss: 0.037863
 >> iter 60000, loss: 0.046754
   Number of active neurons: 3
 >> iter 61000, loss: 0.048784
 >> iter 62000, loss: 0.041820
 >> iter 63000, loss: 0.043637
 >> iter 64000, loss: 0.050228
 >> iter 65000, loss: 0.051310
 >> iter 66000, loss: 0.042911
 >> iter 67000, loss: 0.040767
 >> iter 68000, loss: 0.043517
 >> iter 69000, loss: 0.039479
 >> iter 70000, loss: 0.033578
   Number of active neurons: 3
 >> iter 71000, loss: 0.030255
 >> iter 72000, loss: 0.038649
 >> iter 73000, loss: 0.043368
 >> iter 74000, loss: 0.039602
 >> iter 75000, loss: 0.048153
 >> iter 76000, loss: 0.045207
 >> iter 77000, loss: 0.064873
 >> iter 78000, loss: 0.047211
 >> iter 79000, loss: 0.037342
 >> iter 80000, loss: 0.036813
   Number of active neurons: 2
 >> iter 81000, loss: 0.040075
 >> iter 82000, loss: 0.050207
 >> iter 83000, loss: 0.040375
 >> iter 84000, loss: 0.040301
 >> iter 85000, loss: 0.055577
 >> iter 86000, loss: 0.046087
 >> iter 87000, loss: 0.044134
 >> iter 88000, loss: 0.049636
 >> iter 89000, loss: 0.043470
 >> iter 90000, loss: 0.039937
   Number of active neurons: 2
 >> iter 91000, loss: 0.056474
 >> iter 92000, loss: 0.048552
 >> iter 93000, loss: 0.061012
 >> iter 94000, loss: 0.049633
 >> iter 95000, loss: 0.044732
 >> iter 96000, loss: 0.037144
 >> iter 97000, loss: 0.041890
 >> iter 98000, loss: 0.050586
 >> iter 99000, loss: 0.039165
 >> iter 100000, loss: 0.038253
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455180
   Number of active neurons: 0
 >> iter 1000, loss: 11.364981
 >> iter 2000, loss: 4.429242
 >> iter 3000, loss: 1.744339
 >> iter 4000, loss: 0.730999
 >> iter 5000, loss: 0.329611
 >> iter 6000, loss: 0.188859
 >> iter 7000, loss: 0.136972
 >> iter 8000, loss: 0.083849
 >> iter 9000, loss: 0.079324
 >> iter 10000, loss: 0.073906
   Number of active neurons: 6
 >> iter 11000, loss: 0.070520
 >> iter 12000, loss: 0.077992
 >> iter 13000, loss: 0.067614
 >> iter 14000, loss: 0.049339
 >> iter 15000, loss: 0.051866
 >> iter 16000, loss: 0.043753
 >> iter 17000, loss: 0.043180
 >> iter 18000, loss: 0.061437
 >> iter 19000, loss: 0.044821
 >> iter 20000, loss: 0.040512
   Number of active neurons: 6
 >> iter 21000, loss: 0.053010
 >> iter 22000, loss: 0.041149
 >> iter 23000, loss: 0.053902
 >> iter 24000, loss: 0.052794
 >> iter 25000, loss: 0.052053
 >> iter 26000, loss: 0.045079
 >> iter 27000, loss: 0.078108
 >> iter 28000, loss: 0.056900
 >> iter 29000, loss: 0.059156
 >> iter 30000, loss: 0.054772
   Number of active neurons: 6
 >> iter 31000, loss: 0.052830
 >> iter 32000, loss: 0.069719
 >> iter 33000, loss: 0.064496
 >> iter 34000, loss: 0.077788
 >> iter 35000, loss: 0.050780
 >> iter 36000, loss: 0.051646
 >> iter 37000, loss: 0.043955
 >> iter 38000, loss: 0.047540
 >> iter 39000, loss: 0.041607
 >> iter 40000, loss: 0.055230
   Number of active neurons: 4
 >> iter 41000, loss: 0.048307
 >> iter 42000, loss: 0.050285
 >> iter 43000, loss: 0.044978
 >> iter 44000, loss: 0.039495
 >> iter 45000, loss: 0.040722
 >> iter 46000, loss: 0.041913
 >> iter 47000, loss: 0.039846
 >> iter 48000, loss: 0.038272
 >> iter 49000, loss: 0.044580
 >> iter 50000, loss: 0.061898
   Number of active neurons: 4
 >> iter 51000, loss: 0.057833
 >> iter 52000, loss: 0.051073
 >> iter 53000, loss: 0.066440
 >> iter 54000, loss: 0.048422
 >> iter 55000, loss: 0.045188
 >> iter 56000, loss: 0.047605
 >> iter 57000, loss: 0.044736
 >> iter 58000, loss: 0.051238
 >> iter 59000, loss: 0.039557
 >> iter 60000, loss: 0.037540
   Number of active neurons: 4
 >> iter 61000, loss: 0.049659
 >> iter 62000, loss: 0.057071
 >> iter 63000, loss: 0.051686
 >> iter 64000, loss: 0.052023
 >> iter 65000, loss: 0.043362
 >> iter 66000, loss: 0.051399
 >> iter 67000, loss: 0.068067
 >> iter 68000, loss: 0.067656
 >> iter 69000, loss: 0.064605
 >> iter 70000, loss: 0.077927
   Number of active neurons: 3
 >> iter 71000, loss: 0.053586
 >> iter 72000, loss: 0.049001
 >> iter 73000, loss: 0.051378
 >> iter 74000, loss: 0.036426
 >> iter 75000, loss: 0.036748
 >> iter 76000, loss: 0.041550
 >> iter 77000, loss: 0.045925
 >> iter 78000, loss: 0.038098
 >> iter 79000, loss: 0.058242
 >> iter 80000, loss: 0.054187
   Number of active neurons: 3
 >> iter 81000, loss: 0.050892
 >> iter 82000, loss: 0.054690
 >> iter 83000, loss: 0.044374
 >> iter 84000, loss: 0.044085
 >> iter 85000, loss: 0.048433
 >> iter 86000, loss: 0.045506
 >> iter 87000, loss: 0.046412
 >> iter 88000, loss: 0.041868
 >> iter 89000, loss: 0.078959
 >> iter 90000, loss: 0.058396
   Number of active neurons: 3
 >> iter 91000, loss: 0.061320
 >> iter 92000, loss: 0.057758
 >> iter 93000, loss: 0.042564
 >> iter 94000, loss: 0.039475
 >> iter 95000, loss: 0.042644
 >> iter 96000, loss: 0.040440
 >> iter 97000, loss: 0.048466
 >> iter 98000, loss: 0.041916
 >> iter 99000, loss: 0.047027
 >> iter 100000, loss: 0.054116
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 11.359645
 >> iter 2000, loss: 4.474864
 >> iter 3000, loss: 1.755639
 >> iter 4000, loss: 0.748921
 >> iter 5000, loss: 0.363485
 >> iter 6000, loss: 0.230979
 >> iter 7000, loss: 0.147992
 >> iter 8000, loss: 0.098917
 >> iter 9000, loss: 0.078274
 >> iter 10000, loss: 0.076717
   Number of active neurons: 9
 >> iter 11000, loss: 0.072332
 >> iter 12000, loss: 0.071331
 >> iter 13000, loss: 0.073213
 >> iter 14000, loss: 0.064148
 >> iter 15000, loss: 0.045580
 >> iter 16000, loss: 0.063109
 >> iter 17000, loss: 0.080414
 >> iter 18000, loss: 0.068749
 >> iter 19000, loss: 0.089583
 >> iter 20000, loss: 0.062914
   Number of active neurons: 7
 >> iter 21000, loss: 0.059675
 >> iter 22000, loss: 0.053357
 >> iter 23000, loss: 0.050986
 >> iter 24000, loss: 0.064309
 >> iter 25000, loss: 0.059373
 >> iter 26000, loss: 0.054231
 >> iter 27000, loss: 0.045693
 >> iter 28000, loss: 0.056990
 >> iter 29000, loss: 0.047046
 >> iter 30000, loss: 0.044055
   Number of active neurons: 5
 >> iter 31000, loss: 0.054761
 >> iter 32000, loss: 0.043657
 >> iter 33000, loss: 0.053105
 >> iter 34000, loss: 0.048122
 >> iter 35000, loss: 0.045151
 >> iter 36000, loss: 0.059664
 >> iter 37000, loss: 0.055338
 >> iter 38000, loss: 0.067795
 >> iter 39000, loss: 0.059799
 >> iter 40000, loss: 0.055347
   Number of active neurons: 5
 >> iter 41000, loss: 0.058913
 >> iter 42000, loss: 0.050753
 >> iter 43000, loss: 0.056121
 >> iter 44000, loss: 0.050539
 >> iter 45000, loss: 0.055819
 >> iter 46000, loss: 0.040363
 >> iter 47000, loss: 0.050108
 >> iter 48000, loss: 0.040440
 >> iter 49000, loss: 0.037501
 >> iter 50000, loss: 0.040748
   Number of active neurons: 4
 >> iter 51000, loss: 0.057756
 >> iter 52000, loss: 0.045378
 >> iter 53000, loss: 0.044957
 >> iter 54000, loss: 0.070662
 >> iter 55000, loss: 0.055213
 >> iter 56000, loss: 0.038324
 >> iter 57000, loss: 0.041815
 >> iter 58000, loss: 0.044236
 >> iter 59000, loss: 0.034136
 >> iter 60000, loss: 0.032677
   Number of active neurons: 2
 >> iter 61000, loss: 0.041120
 >> iter 62000, loss: 0.044542
 >> iter 63000, loss: 0.052570
 >> iter 64000, loss: 0.046915
 >> iter 65000, loss: 0.044339
 >> iter 66000, loss: 0.051107
 >> iter 67000, loss: 0.075978
 >> iter 68000, loss: 0.047559
 >> iter 69000, loss: 0.033251
 >> iter 70000, loss: 0.026434
   Number of active neurons: 2
 >> iter 71000, loss: 0.023739
 >> iter 72000, loss: 0.059975
 >> iter 73000, loss: 0.075962
 >> iter 74000, loss: 0.064368
 >> iter 75000, loss: 0.051847
 >> iter 76000, loss: 0.038888
 >> iter 77000, loss: 0.038625
 >> iter 78000, loss: 0.053637
 >> iter 79000, loss: 0.063090
 >> iter 80000, loss: 0.053671
   Number of active neurons: 2
 >> iter 81000, loss: 0.044158
 >> iter 82000, loss: 0.030148
 >> iter 83000, loss: 0.029395
 >> iter 84000, loss: 0.022924
 >> iter 85000, loss: 0.041735
 >> iter 86000, loss: 0.053346
 >> iter 87000, loss: 0.046321
 >> iter 88000, loss: 0.050719
 >> iter 89000, loss: 0.034513
 >> iter 90000, loss: 0.051037
   Number of active neurons: 2
 >> iter 91000, loss: 0.040027
 >> iter 92000, loss: 0.037941
 >> iter 93000, loss: 0.043759
 >> iter 94000, loss: 0.054365
 >> iter 95000, loss: 0.049093
 >> iter 96000, loss: 0.050729
 >> iter 97000, loss: 0.038596
 >> iter 98000, loss: 0.041655
 >> iter 99000, loss: 0.038384
 >> iter 100000, loss: 0.044573
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.340383
 >> iter 2000, loss: 4.421797
 >> iter 3000, loss: 1.749911
 >> iter 4000, loss: 0.734887
 >> iter 5000, loss: 0.363760
 >> iter 6000, loss: 0.200920
 >> iter 7000, loss: 0.123684
 >> iter 8000, loss: 0.114047
 >> iter 9000, loss: 0.110946
 >> iter 10000, loss: 0.087186
   Number of active neurons: 9
 >> iter 11000, loss: 0.086439
 >> iter 12000, loss: 0.062098
 >> iter 13000, loss: 0.070794
 >> iter 14000, loss: 0.079266
 >> iter 15000, loss: 0.089602
 >> iter 16000, loss: 0.072223
 >> iter 17000, loss: 0.072750
 >> iter 18000, loss: 0.084941
 >> iter 19000, loss: 0.059334
 >> iter 20000, loss: 0.050642
   Number of active neurons: 7
 >> iter 21000, loss: 0.059029
 >> iter 22000, loss: 0.060727
 >> iter 23000, loss: 0.073205
 >> iter 24000, loss: 0.062718
 >> iter 25000, loss: 0.049540
 >> iter 26000, loss: 0.039903
 >> iter 27000, loss: 0.055777
 >> iter 28000, loss: 0.059265
 >> iter 29000, loss: 0.052823
 >> iter 30000, loss: 0.046430
   Number of active neurons: 6
 >> iter 31000, loss: 0.071604
 >> iter 32000, loss: 0.062316
 >> iter 33000, loss: 0.046990
 >> iter 34000, loss: 0.060598
 >> iter 35000, loss: 0.045885
 >> iter 36000, loss: 0.052979
 >> iter 37000, loss: 0.067929
 >> iter 38000, loss: 0.056728
 >> iter 39000, loss: 0.080614
 >> iter 40000, loss: 0.051901
   Number of active neurons: 5
 >> iter 41000, loss: 0.043029
 >> iter 42000, loss: 0.053150
 >> iter 43000, loss: 0.037547
 >> iter 44000, loss: 0.045063
 >> iter 45000, loss: 0.035401
 >> iter 46000, loss: 0.033387
 >> iter 47000, loss: 0.047385
 >> iter 48000, loss: 0.043034
 >> iter 49000, loss: 0.042975
 >> iter 50000, loss: 0.034662
   Number of active neurons: 5
 >> iter 51000, loss: 0.054950
 >> iter 52000, loss: 0.047029
 >> iter 53000, loss: 0.036588
 >> iter 54000, loss: 0.035201
 >> iter 55000, loss: 0.035925
 >> iter 56000, loss: 0.047732
 >> iter 57000, loss: 0.042796
 >> iter 58000, loss: 0.043230
 >> iter 59000, loss: 0.063852
 >> iter 60000, loss: 0.041826
   Number of active neurons: 5
 >> iter 61000, loss: 0.046206
 >> iter 62000, loss: 0.051608
 >> iter 63000, loss: 0.051687
 >> iter 64000, loss: 0.040592
 >> iter 65000, loss: 0.039655
 >> iter 66000, loss: 0.037980
 >> iter 67000, loss: 0.034440
 >> iter 68000, loss: 0.039378
 >> iter 69000, loss: 0.031952
 >> iter 70000, loss: 0.054389
   Number of active neurons: 3
 >> iter 71000, loss: 0.046092
 >> iter 72000, loss: 0.041480
 >> iter 73000, loss: 0.051382
 >> iter 74000, loss: 0.059228
 >> iter 75000, loss: 0.056074
 >> iter 76000, loss: 0.049534
 >> iter 77000, loss: 0.041744
 >> iter 78000, loss: 0.031808
 >> iter 79000, loss: 0.059101
 >> iter 80000, loss: 0.057368
   Number of active neurons: 3
 >> iter 81000, loss: 0.038562
 >> iter 82000, loss: 0.042531
 >> iter 83000, loss: 0.050438
 >> iter 84000, loss: 0.043778
 >> iter 85000, loss: 0.057791
 >> iter 86000, loss: 0.059034
 >> iter 87000, loss: 0.052153
 >> iter 88000, loss: 0.044990
 >> iter 89000, loss: 0.049032
 >> iter 90000, loss: 0.034393
   Number of active neurons: 3
 >> iter 91000, loss: 0.051474
 >> iter 92000, loss: 0.048848
 >> iter 93000, loss: 0.040587
 >> iter 94000, loss: 0.040285
 >> iter 95000, loss: 0.055479
 >> iter 96000, loss: 0.053715
 >> iter 97000, loss: 0.042848
 >> iter 98000, loss: 0.043305
 >> iter 99000, loss: 0.048656
 >> iter 100000, loss: 0.055222
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.380993
 >> iter 2000, loss: 4.445917
 >> iter 3000, loss: 1.754528
 >> iter 4000, loss: 0.717652
 >> iter 5000, loss: 0.334234
 >> iter 6000, loss: 0.168548
 >> iter 7000, loss: 0.091818
 >> iter 8000, loss: 0.081922
 >> iter 9000, loss: 0.080006
 >> iter 10000, loss: 0.068488
   Number of active neurons: 7
 >> iter 11000, loss: 0.077908
 >> iter 12000, loss: 0.061157
 >> iter 13000, loss: 0.065446
 >> iter 14000, loss: 0.055222
 >> iter 15000, loss: 0.069643
 >> iter 16000, loss: 0.074298
 >> iter 17000, loss: 0.080239
 >> iter 18000, loss: 0.057604
 >> iter 19000, loss: 0.054366
 >> iter 20000, loss: 0.070209
   Number of active neurons: 6
 >> iter 21000, loss: 0.060336
 >> iter 22000, loss: 0.048624
 >> iter 23000, loss: 0.050984
 >> iter 24000, loss: 0.054761
 >> iter 25000, loss: 0.053898
 >> iter 26000, loss: 0.046616
 >> iter 27000, loss: 0.048168
 >> iter 28000, loss: 0.050598
 >> iter 29000, loss: 0.051369
 >> iter 30000, loss: 0.050887
   Number of active neurons: 5
 >> iter 31000, loss: 0.064605
 >> iter 32000, loss: 0.066553
 >> iter 33000, loss: 0.051430
 >> iter 34000, loss: 0.051959
 >> iter 35000, loss: 0.038971
 >> iter 36000, loss: 0.033916
 >> iter 37000, loss: 0.041258
 >> iter 38000, loss: 0.075771
 >> iter 39000, loss: 0.051789
 >> iter 40000, loss: 0.054303
   Number of active neurons: 4
 >> iter 41000, loss: 0.045317
 >> iter 42000, loss: 0.046588
 >> iter 43000, loss: 0.043914
 >> iter 44000, loss: 0.037032
 >> iter 45000, loss: 0.057717
 >> iter 46000, loss: 0.051428
 >> iter 47000, loss: 0.055233
 >> iter 48000, loss: 0.050377
 >> iter 49000, loss: 0.053111
 >> iter 50000, loss: 0.071040
   Number of active neurons: 4
 >> iter 51000, loss: 0.084057
 >> iter 52000, loss: 0.068691
 >> iter 53000, loss: 0.074236
 >> iter 54000, loss: 0.047223
 >> iter 55000, loss: 0.054665
 >> iter 56000, loss: 0.041219
 >> iter 57000, loss: 0.038759
 >> iter 58000, loss: 0.043071
 >> iter 59000, loss: 0.050543
 >> iter 60000, loss: 0.057029
   Number of active neurons: 4
 >> iter 61000, loss: 0.053210
 >> iter 62000, loss: 0.069412
 >> iter 63000, loss: 0.058568
 >> iter 64000, loss: 0.052538
 >> iter 65000, loss: 0.044849
 >> iter 66000, loss: 0.042610
 >> iter 67000, loss: 0.079591
 >> iter 68000, loss: 0.073414
 >> iter 69000, loss: 0.056619
 >> iter 70000, loss: 0.046988
   Number of active neurons: 4
 >> iter 71000, loss: 0.057831
 >> iter 72000, loss: 0.056330
 >> iter 73000, loss: 0.069379
 >> iter 74000, loss: 0.043921
 >> iter 75000, loss: 0.046767
 >> iter 76000, loss: 0.046145
 >> iter 77000, loss: 0.053326
 >> iter 78000, loss: 0.072260
 >> iter 79000, loss: 0.088255
 >> iter 80000, loss: 0.056341
   Number of active neurons: 3
 >> iter 81000, loss: 0.054249
 >> iter 82000, loss: 0.045338
 >> iter 83000, loss: 0.046098
 >> iter 84000, loss: 0.063162
 >> iter 85000, loss: 0.050106
 >> iter 86000, loss: 0.065882
 >> iter 87000, loss: 0.053562
 >> iter 88000, loss: 0.044311
 >> iter 89000, loss: 0.047930
 >> iter 90000, loss: 0.050539
   Number of active neurons: 3
 >> iter 91000, loss: 0.039926
 >> iter 92000, loss: 0.049478
 >> iter 93000, loss: 0.048147
 >> iter 94000, loss: 0.040633
 >> iter 95000, loss: 0.066405
 >> iter 96000, loss: 0.047945
 >> iter 97000, loss: 0.059427
 >> iter 98000, loss: 0.040210
 >> iter 99000, loss: 0.038022
 >> iter 100000, loss: 0.034070
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.308378
 >> iter 2000, loss: 4.344740
 >> iter 3000, loss: 1.690543
 >> iter 4000, loss: 0.693777
 >> iter 5000, loss: 0.322076
 >> iter 6000, loss: 0.171123
 >> iter 7000, loss: 0.089804
 >> iter 8000, loss: 0.058294
 >> iter 9000, loss: 0.073626
 >> iter 10000, loss: 0.074720
   Number of active neurons: 5
 >> iter 11000, loss: 0.068182
 >> iter 12000, loss: 0.059762
 >> iter 13000, loss: 0.058120
 >> iter 14000, loss: 0.059018
 >> iter 15000, loss: 0.060296
 >> iter 16000, loss: 0.043932
 >> iter 17000, loss: 0.058926
 >> iter 18000, loss: 0.047720
 >> iter 19000, loss: 0.068047
 >> iter 20000, loss: 0.057411
   Number of active neurons: 5
 >> iter 21000, loss: 0.050151
 >> iter 22000, loss: 0.050597
 >> iter 23000, loss: 0.043068
 >> iter 24000, loss: 0.056847
 >> iter 25000, loss: 0.068951
 >> iter 26000, loss: 0.064453
 >> iter 27000, loss: 0.057775
 >> iter 28000, loss: 0.056382
 >> iter 29000, loss: 0.058328
 >> iter 30000, loss: 0.048027
   Number of active neurons: 3
 >> iter 31000, loss: 0.039679
 >> iter 32000, loss: 0.029681
 >> iter 33000, loss: 0.062850
 >> iter 34000, loss: 0.043557
 >> iter 35000, loss: 0.052761
 >> iter 36000, loss: 0.040705
 >> iter 37000, loss: 0.035056
 >> iter 38000, loss: 0.042868
 >> iter 39000, loss: 0.036935
 >> iter 40000, loss: 0.063337
   Number of active neurons: 3
 >> iter 41000, loss: 0.054307
 >> iter 42000, loss: 0.039231
 >> iter 43000, loss: 0.036462
 >> iter 44000, loss: 0.038911
 >> iter 45000, loss: 0.050695
 >> iter 46000, loss: 0.074629
 >> iter 47000, loss: 0.053988
 >> iter 48000, loss: 0.059182
 >> iter 49000, loss: 0.054107
 >> iter 50000, loss: 0.039003
   Number of active neurons: 3
 >> iter 51000, loss: 0.040058
 >> iter 52000, loss: 0.038061
 >> iter 53000, loss: 0.037983
 >> iter 54000, loss: 0.058800
 >> iter 55000, loss: 0.066698
 >> iter 56000, loss: 0.068396
 >> iter 57000, loss: 0.046125
 >> iter 58000, loss: 0.049034
 >> iter 59000, loss: 0.043121
 >> iter 60000, loss: 0.042518
   Number of active neurons: 3
 >> iter 61000, loss: 0.037306
 >> iter 62000, loss: 0.055053
 >> iter 63000, loss: 0.049986
 >> iter 64000, loss: 0.060284
 >> iter 65000, loss: 0.046525
 >> iter 66000, loss: 0.036735
 >> iter 67000, loss: 0.052501
 >> iter 68000, loss: 0.044926
 >> iter 69000, loss: 0.049926
 >> iter 70000, loss: 0.050608
   Number of active neurons: 3
 >> iter 71000, loss: 0.040574
 >> iter 72000, loss: 0.048223
 >> iter 73000, loss: 0.039384
 >> iter 74000, loss: 0.060652
 >> iter 75000, loss: 0.038604
 >> iter 76000, loss: 0.070683
 >> iter 77000, loss: 0.062095
 >> iter 78000, loss: 0.066152
 >> iter 79000, loss: 0.056931
 >> iter 80000, loss: 0.043721
   Number of active neurons: 3
 >> iter 81000, loss: 0.034229
 >> iter 82000, loss: 0.046630
 >> iter 83000, loss: 0.056935
 >> iter 84000, loss: 0.041716
 >> iter 85000, loss: 0.041560
 >> iter 86000, loss: 0.051346
 >> iter 87000, loss: 0.056735
 >> iter 88000, loss: 0.039017
 >> iter 89000, loss: 0.053533
 >> iter 90000, loss: 0.049840
   Number of active neurons: 3
 >> iter 91000, loss: 0.050963
 >> iter 92000, loss: 0.037613
 >> iter 93000, loss: 0.031101
 >> iter 94000, loss: 0.043353
 >> iter 95000, loss: 0.050438
 >> iter 96000, loss: 0.049285
 >> iter 97000, loss: 0.055252
 >> iter 98000, loss: 0.041846
 >> iter 99000, loss: 0.035733
 >> iter 100000, loss: 0.032686
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.342647
 >> iter 2000, loss: 4.446602
 >> iter 3000, loss: 1.751458
 >> iter 4000, loss: 0.714435
 >> iter 5000, loss: 0.326888
 >> iter 6000, loss: 0.169188
 >> iter 7000, loss: 0.116870
 >> iter 8000, loss: 0.083778
 >> iter 9000, loss: 0.105853
 >> iter 10000, loss: 0.074419
   Number of active neurons: 6
 >> iter 11000, loss: 0.063836
 >> iter 12000, loss: 0.046638
 >> iter 13000, loss: 0.061839
 >> iter 14000, loss: 0.047455
 >> iter 15000, loss: 0.054370
 >> iter 16000, loss: 0.056816
 >> iter 17000, loss: 0.080764
 >> iter 18000, loss: 0.082416
 >> iter 19000, loss: 0.061116
 >> iter 20000, loss: 0.061855
   Number of active neurons: 6
 >> iter 21000, loss: 0.114058
 >> iter 22000, loss: 0.080395
 >> iter 23000, loss: 0.065547
 >> iter 24000, loss: 0.057851
 >> iter 25000, loss: 0.056301
 >> iter 26000, loss: 0.065669
 >> iter 27000, loss: 0.047950
 >> iter 28000, loss: 0.045723
 >> iter 29000, loss: 0.038100
 >> iter 30000, loss: 0.054266
   Number of active neurons: 6
 >> iter 31000, loss: 0.056159
 >> iter 32000, loss: 0.048389
 >> iter 33000, loss: 0.056410
 >> iter 34000, loss: 0.053495
 >> iter 35000, loss: 0.050633
 >> iter 36000, loss: 0.051557
 >> iter 37000, loss: 0.060035
 >> iter 38000, loss: 0.050543
 >> iter 39000, loss: 0.045342
 >> iter 40000, loss: 0.051837
   Number of active neurons: 5
 >> iter 41000, loss: 0.059773
 >> iter 42000, loss: 0.049004
 >> iter 43000, loss: 0.041922
 >> iter 44000, loss: 0.043349
 >> iter 45000, loss: 0.051660
 >> iter 46000, loss: 0.068072
 >> iter 47000, loss: 0.047282
 >> iter 48000, loss: 0.049142
 >> iter 49000, loss: 0.052364
 >> iter 50000, loss: 0.055961
   Number of active neurons: 5
 >> iter 51000, loss: 0.063266
 >> iter 52000, loss: 0.046557
 >> iter 53000, loss: 0.036789
 >> iter 54000, loss: 0.063331
 >> iter 55000, loss: 0.077526
 >> iter 56000, loss: 0.066833
 >> iter 57000, loss: 0.070537
 >> iter 58000, loss: 0.055916
 >> iter 59000, loss: 0.056168
 >> iter 60000, loss: 0.057216
   Number of active neurons: 3
 >> iter 61000, loss: 0.053934
 >> iter 62000, loss: 0.042882
 >> iter 63000, loss: 0.048282
 >> iter 64000, loss: 0.041862
 >> iter 65000, loss: 0.064903
 >> iter 66000, loss: 0.055037
 >> iter 67000, loss: 0.038646
 >> iter 68000, loss: 0.041227
 >> iter 69000, loss: 0.045476
 >> iter 70000, loss: 0.039995
   Number of active neurons: 3
 >> iter 71000, loss: 0.065807
 >> iter 72000, loss: 0.056918
 >> iter 73000, loss: 0.073928
 >> iter 74000, loss: 0.047473
 >> iter 75000, loss: 0.048108
 >> iter 76000, loss: 0.038434
 >> iter 77000, loss: 0.067092
 >> iter 78000, loss: 0.054236
 >> iter 79000, loss: 0.044456
 >> iter 80000, loss: 0.034554
   Number of active neurons: 2
 >> iter 81000, loss: 0.051408
 >> iter 82000, loss: 0.038053
 >> iter 83000, loss: 0.045245
 >> iter 84000, loss: 0.055333
 >> iter 85000, loss: 0.036694
 >> iter 86000, loss: 0.037317
 >> iter 87000, loss: 0.044601
 >> iter 88000, loss: 0.058401
 >> iter 89000, loss: 0.044864
 >> iter 90000, loss: 0.030630
   Number of active neurons: 2
 >> iter 91000, loss: 0.035136
 >> iter 92000, loss: 0.033683
 >> iter 93000, loss: 0.038816
 >> iter 94000, loss: 0.037758
 >> iter 95000, loss: 0.050289
 >> iter 96000, loss: 0.054706
 >> iter 97000, loss: 0.038209
 >> iter 98000, loss: 0.040591
 >> iter 99000, loss: 0.049910
 >> iter 100000, loss: 0.045810
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.335809
 >> iter 2000, loss: 4.424585
 >> iter 3000, loss: 1.746114
 >> iter 4000, loss: 0.730781
 >> iter 5000, loss: 0.342446
 >> iter 6000, loss: 0.179543
 >> iter 7000, loss: 0.111518
 >> iter 8000, loss: 0.114409
 >> iter 9000, loss: 0.085203
 >> iter 10000, loss: 0.074554
   Number of active neurons: 8
 >> iter 11000, loss: 0.078846
 >> iter 12000, loss: 0.070786
 >> iter 13000, loss: 0.064545
 >> iter 14000, loss: 0.062095
 >> iter 15000, loss: 0.075551
 >> iter 16000, loss: 0.067346
 >> iter 17000, loss: 0.050325
 >> iter 18000, loss: 0.047865
 >> iter 19000, loss: 0.049865
 >> iter 20000, loss: 0.055179
   Number of active neurons: 6
 >> iter 21000, loss: 0.051283
 >> iter 22000, loss: 0.046414
 >> iter 23000, loss: 0.050635
 >> iter 24000, loss: 0.044750
 >> iter 25000, loss: 0.055959
 >> iter 26000, loss: 0.054281
 >> iter 27000, loss: 0.045411
 >> iter 28000, loss: 0.041446
 >> iter 29000, loss: 0.045356
 >> iter 30000, loss: 0.049606
   Number of active neurons: 6
 >> iter 31000, loss: 0.054231
 >> iter 32000, loss: 0.047405
 >> iter 33000, loss: 0.057516
 >> iter 34000, loss: 0.055167
 >> iter 35000, loss: 0.040217
 >> iter 36000, loss: 0.047411
 >> iter 37000, loss: 0.039623
 >> iter 38000, loss: 0.041469
 >> iter 39000, loss: 0.048170
 >> iter 40000, loss: 0.039750
   Number of active neurons: 4
 >> iter 41000, loss: 0.054318
 >> iter 42000, loss: 0.050921
 >> iter 43000, loss: 0.035362
 >> iter 44000, loss: 0.046299
 >> iter 45000, loss: 0.057664
 >> iter 46000, loss: 0.054923
 >> iter 47000, loss: 0.058806
 >> iter 48000, loss: 0.052332
 >> iter 49000, loss: 0.039011
 >> iter 50000, loss: 0.036122
   Number of active neurons: 3
 >> iter 51000, loss: 0.046067
 >> iter 52000, loss: 0.047094
 >> iter 53000, loss: 0.044070
 >> iter 54000, loss: 0.041232
 >> iter 55000, loss: 0.044194
 >> iter 56000, loss: 0.041029
 >> iter 57000, loss: 0.036075
 >> iter 58000, loss: 0.036196
 >> iter 59000, loss: 0.055512
 >> iter 60000, loss: 0.039112
   Number of active neurons: 3
 >> iter 61000, loss: 0.053233
 >> iter 62000, loss: 0.056070
 >> iter 63000, loss: 0.042723
 >> iter 64000, loss: 0.043067
 >> iter 65000, loss: 0.043911
 >> iter 66000, loss: 0.049410
 >> iter 67000, loss: 0.036699
 >> iter 68000, loss: 0.041669
 >> iter 69000, loss: 0.041528
 >> iter 70000, loss: 0.038742
   Number of active neurons: 3
 >> iter 71000, loss: 0.036246
 >> iter 72000, loss: 0.038256
 >> iter 73000, loss: 0.039786
 >> iter 74000, loss: 0.038045
 >> iter 75000, loss: 0.037598
 >> iter 76000, loss: 0.046360
 >> iter 77000, loss: 0.056263
 >> iter 78000, loss: 0.044093
 >> iter 79000, loss: 0.033892
 >> iter 80000, loss: 0.053836
   Number of active neurons: 3
 >> iter 81000, loss: 0.050231
 >> iter 82000, loss: 0.052069
 >> iter 83000, loss: 0.044730
 >> iter 84000, loss: 0.041181
 >> iter 85000, loss: 0.039358
 >> iter 86000, loss: 0.042614
 >> iter 87000, loss: 0.049234
 >> iter 88000, loss: 0.040734
 >> iter 89000, loss: 0.041357
 >> iter 90000, loss: 0.045792
   Number of active neurons: 3
 >> iter 91000, loss: 0.045135
 >> iter 92000, loss: 0.043001
 >> iter 93000, loss: 0.045616
 >> iter 94000, loss: 0.059972
 >> iter 95000, loss: 0.043576
 >> iter 96000, loss: 0.037368
 >> iter 97000, loss: 0.036478
 >> iter 98000, loss: 0.033511
 >> iter 99000, loss: 0.046477
 >> iter 100000, loss: 0.049871
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455183
   Number of active neurons: 0
 >> iter 1000, loss: 11.431732
 >> iter 2000, loss: 4.485809
 >> iter 3000, loss: 1.779311
 >> iter 4000, loss: 0.725665
 >> iter 5000, loss: 0.322816
 >> iter 6000, loss: 0.176708
 >> iter 7000, loss: 0.133816
 >> iter 8000, loss: 0.108470
 >> iter 9000, loss: 0.095533
 >> iter 10000, loss: 0.079419
   Number of active neurons: 8
 >> iter 11000, loss: 0.058078
 >> iter 12000, loss: 0.060584
 >> iter 13000, loss: 0.067381
 >> iter 14000, loss: 0.065995
 >> iter 15000, loss: 0.061647
 >> iter 16000, loss: 0.054588
 >> iter 17000, loss: 0.059092
 >> iter 18000, loss: 0.069958
 >> iter 19000, loss: 0.070181
 >> iter 20000, loss: 0.060150
   Number of active neurons: 5
 >> iter 21000, loss: 0.059782
 >> iter 22000, loss: 0.048914
 >> iter 23000, loss: 0.050931
 >> iter 24000, loss: 0.041417
 >> iter 25000, loss: 0.068607
 >> iter 26000, loss: 0.057031
 >> iter 27000, loss: 0.054311
 >> iter 28000, loss: 0.057063
 >> iter 29000, loss: 0.049869
 >> iter 30000, loss: 0.047206
   Number of active neurons: 5
 >> iter 31000, loss: 0.049011
 >> iter 32000, loss: 0.057764
 >> iter 33000, loss: 0.049615
 >> iter 34000, loss: 0.047385
 >> iter 35000, loss: 0.059590
 >> iter 36000, loss: 0.045435
 >> iter 37000, loss: 0.054336
 >> iter 38000, loss: 0.044458
 >> iter 39000, loss: 0.052241
 >> iter 40000, loss: 0.045617
   Number of active neurons: 4
 >> iter 41000, loss: 0.052823
 >> iter 42000, loss: 0.048271
 >> iter 43000, loss: 0.048256
 >> iter 44000, loss: 0.038187
 >> iter 45000, loss: 0.060128
 >> iter 46000, loss: 0.047576
 >> iter 47000, loss: 0.051407
 >> iter 48000, loss: 0.050522
 >> iter 49000, loss: 0.056389
 >> iter 50000, loss: 0.087793
   Number of active neurons: 2
 >> iter 51000, loss: 0.067080
 >> iter 52000, loss: 0.054901
 >> iter 53000, loss: 0.058517
 >> iter 54000, loss: 0.045519
 >> iter 55000, loss: 0.042264
 >> iter 56000, loss: 0.047977
 >> iter 57000, loss: 0.056782
 >> iter 58000, loss: 0.045006
 >> iter 59000, loss: 0.038689
 >> iter 60000, loss: 0.062578
   Number of active neurons: 2
 >> iter 61000, loss: 0.052504
 >> iter 62000, loss: 0.045795
 >> iter 63000, loss: 0.043046
 >> iter 64000, loss: 0.041966
 >> iter 65000, loss: 0.045303
 >> iter 66000, loss: 0.051733
 >> iter 67000, loss: 0.038032
 >> iter 68000, loss: 0.039212
 >> iter 69000, loss: 0.039788
 >> iter 70000, loss: 0.032966
   Number of active neurons: 2
 >> iter 71000, loss: 0.031286
 >> iter 72000, loss: 0.050732
 >> iter 73000, loss: 0.043152
 >> iter 74000, loss: 0.052991
 >> iter 75000, loss: 0.054191
 >> iter 76000, loss: 0.040106
 >> iter 77000, loss: 0.038432
 >> iter 78000, loss: 0.069385
 >> iter 79000, loss: 0.070330
 >> iter 80000, loss: 0.062585
   Number of active neurons: 2
 >> iter 81000, loss: 0.056698
 >> iter 82000, loss: 0.041961
 >> iter 83000, loss: 0.038167
 >> iter 84000, loss: 0.032020
 >> iter 85000, loss: 0.034465
 >> iter 86000, loss: 0.038721
 >> iter 87000, loss: 0.053271
 >> iter 88000, loss: 0.054710
 >> iter 89000, loss: 0.039696
 >> iter 90000, loss: 0.038131
   Number of active neurons: 2
 >> iter 91000, loss: 0.048073
 >> iter 92000, loss: 0.054162
 >> iter 93000, loss: 0.033474
 >> iter 94000, loss: 0.063682
 >> iter 95000, loss: 0.051110
 >> iter 96000, loss: 0.041402
 >> iter 97000, loss: 0.036678
 >> iter 98000, loss: 0.063369
 >> iter 99000, loss: 0.044754
 >> iter 100000, loss: 0.043379
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455179
   Number of active neurons: 0
 >> iter 1000, loss: 11.443048
 >> iter 2000, loss: 4.511360
 >> iter 3000, loss: 1.816065
 >> iter 4000, loss: 0.760973
 >> iter 5000, loss: 0.358258
 >> iter 6000, loss: 0.204108
 >> iter 7000, loss: 0.135843
 >> iter 8000, loss: 0.099772
 >> iter 9000, loss: 0.106287
 >> iter 10000, loss: 0.081172
   Number of active neurons: 8
 >> iter 11000, loss: 0.079121
 >> iter 12000, loss: 0.108819
 >> iter 13000, loss: 0.103401
 >> iter 14000, loss: 0.084544
 >> iter 15000, loss: 0.079107
 >> iter 16000, loss: 0.068296
 >> iter 17000, loss: 0.053800
 >> iter 18000, loss: 0.058655
 >> iter 19000, loss: 0.070866
 >> iter 20000, loss: 0.071940
   Number of active neurons: 8
 >> iter 21000, loss: 0.064551
 >> iter 22000, loss: 0.054405
 >> iter 23000, loss: 0.054970
 >> iter 24000, loss: 0.054752
 >> iter 25000, loss: 0.048990
 >> iter 26000, loss: 0.053264
 >> iter 27000, loss: 0.050906
 >> iter 28000, loss: 0.041465
 >> iter 29000, loss: 0.053455
 >> iter 30000, loss: 0.042045
   Number of active neurons: 5
 >> iter 31000, loss: 0.039677
 >> iter 32000, loss: 0.039417
 >> iter 33000, loss: 0.057561
 >> iter 34000, loss: 0.049118
 >> iter 35000, loss: 0.051545
 >> iter 36000, loss: 0.063675
 >> iter 37000, loss: 0.067189
 >> iter 38000, loss: 0.075948
 >> iter 39000, loss: 0.065106
 >> iter 40000, loss: 0.059079
   Number of active neurons: 4
 >> iter 41000, loss: 0.045027
 >> iter 42000, loss: 0.066869
 >> iter 43000, loss: 0.046175
 >> iter 44000, loss: 0.059011
 >> iter 45000, loss: 0.056195
 >> iter 46000, loss: 0.045733
 >> iter 47000, loss: 0.044398
 >> iter 48000, loss: 0.042768
 >> iter 49000, loss: 0.040679
 >> iter 50000, loss: 0.041242
   Number of active neurons: 4
 >> iter 51000, loss: 0.037929
 >> iter 52000, loss: 0.044924
 >> iter 53000, loss: 0.039322
 >> iter 54000, loss: 0.052170
 >> iter 55000, loss: 0.060765
 >> iter 56000, loss: 0.051159
 >> iter 57000, loss: 0.060257
 >> iter 58000, loss: 0.054034
 >> iter 59000, loss: 0.043619
 >> iter 60000, loss: 0.034775
   Number of active neurons: 3
 >> iter 61000, loss: 0.062655
 >> iter 62000, loss: 0.053682
 >> iter 63000, loss: 0.042514
 >> iter 64000, loss: 0.059355
 >> iter 65000, loss: 0.051029
 >> iter 66000, loss: 0.045485
 >> iter 67000, loss: 0.036787
 >> iter 68000, loss: 0.037318
 >> iter 69000, loss: 0.038029
 >> iter 70000, loss: 0.044643
   Number of active neurons: 2
 >> iter 71000, loss: 0.040302
 >> iter 72000, loss: 0.041600
 >> iter 73000, loss: 0.054065
 >> iter 74000, loss: 0.040725
 >> iter 75000, loss: 0.037664
 >> iter 76000, loss: 0.027519
 >> iter 77000, loss: 0.044110
 >> iter 78000, loss: 0.039435
 >> iter 79000, loss: 0.034760
 >> iter 80000, loss: 0.061064
   Number of active neurons: 2
 >> iter 81000, loss: 0.048527
 >> iter 82000, loss: 0.052000
 >> iter 83000, loss: 0.037345
 >> iter 84000, loss: 0.041696
 >> iter 85000, loss: 0.051101
 >> iter 86000, loss: 0.071758
 >> iter 87000, loss: 0.045242
 >> iter 88000, loss: 0.041942
 >> iter 89000, loss: 0.035154
 >> iter 90000, loss: 0.029415
   Number of active neurons: 2
 >> iter 91000, loss: 0.027279
 >> iter 92000, loss: 0.042904
 >> iter 93000, loss: 0.044186
 >> iter 94000, loss: 0.037448
 >> iter 95000, loss: 0.026315
 >> iter 96000, loss: 0.037272
 >> iter 97000, loss: 0.032261
 >> iter 98000, loss: 0.036996
 >> iter 99000, loss: 0.024194
 >> iter 100000, loss: 0.041535
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.395085
 >> iter 2000, loss: 4.515685
 >> iter 3000, loss: 1.807005
 >> iter 4000, loss: 0.740672
 >> iter 5000, loss: 0.370162
 >> iter 6000, loss: 0.193033
 >> iter 7000, loss: 0.139569
 >> iter 8000, loss: 0.083902
 >> iter 9000, loss: 0.089536
 >> iter 10000, loss: 0.068895
   Number of active neurons: 8
 >> iter 11000, loss: 0.076147
 >> iter 12000, loss: 0.084334
 >> iter 13000, loss: 0.077059
 >> iter 14000, loss: 0.064944
 >> iter 15000, loss: 0.058306
 >> iter 16000, loss: 0.080073
 >> iter 17000, loss: 0.082012
 >> iter 18000, loss: 0.087118
 >> iter 19000, loss: 0.063884
 >> iter 20000, loss: 0.049504
   Number of active neurons: 6
 >> iter 21000, loss: 0.066958
 >> iter 22000, loss: 0.055987
 >> iter 23000, loss: 0.053023
 >> iter 24000, loss: 0.048908
 >> iter 25000, loss: 0.051548
 >> iter 26000, loss: 0.061076
 >> iter 27000, loss: 0.090258
 >> iter 28000, loss: 0.074629
 >> iter 29000, loss: 0.057640
 >> iter 30000, loss: 0.054148
   Number of active neurons: 6
 >> iter 31000, loss: 0.073598
 >> iter 32000, loss: 0.056675
 >> iter 33000, loss: 0.056049
 >> iter 34000, loss: 0.046824
 >> iter 35000, loss: 0.040771
 >> iter 36000, loss: 0.041833
 >> iter 37000, loss: 0.042124
 >> iter 38000, loss: 0.061332
 >> iter 39000, loss: 0.042492
 >> iter 40000, loss: 0.042307
   Number of active neurons: 5
 >> iter 41000, loss: 0.057388
 >> iter 42000, loss: 0.045373
 >> iter 43000, loss: 0.051478
 >> iter 44000, loss: 0.046849
 >> iter 45000, loss: 0.053862
 >> iter 46000, loss: 0.060317
 >> iter 47000, loss: 0.069711
 >> iter 48000, loss: 0.058164
 >> iter 49000, loss: 0.050187
 >> iter 50000, loss: 0.052325
   Number of active neurons: 3
 >> iter 51000, loss: 0.052590
 >> iter 52000, loss: 0.071270
 >> iter 53000, loss: 0.044613
 >> iter 54000, loss: 0.051771
 >> iter 55000, loss: 0.053297
 >> iter 56000, loss: 0.051047
 >> iter 57000, loss: 0.039501
 >> iter 58000, loss: 0.041712
 >> iter 59000, loss: 0.039309
 >> iter 60000, loss: 0.033563
   Number of active neurons: 3
 >> iter 61000, loss: 0.035387
 >> iter 62000, loss: 0.029341
 >> iter 63000, loss: 0.049438
 >> iter 64000, loss: 0.063459
 >> iter 65000, loss: 0.068403
 >> iter 66000, loss: 0.044948
 >> iter 67000, loss: 0.039527
 >> iter 68000, loss: 0.032649
 >> iter 69000, loss: 0.036539
 >> iter 70000, loss: 0.046497
   Number of active neurons: 3
 >> iter 71000, loss: 0.047699
 >> iter 72000, loss: 0.055706
 >> iter 73000, loss: 0.050363
 >> iter 74000, loss: 0.042648
 >> iter 75000, loss: 0.047038
 >> iter 76000, loss: 0.035191
 >> iter 77000, loss: 0.037027
 >> iter 78000, loss: 0.054470
 >> iter 79000, loss: 0.051999
 >> iter 80000, loss: 0.044368
   Number of active neurons: 3
 >> iter 81000, loss: 0.057511
 >> iter 82000, loss: 0.060621
 >> iter 83000, loss: 0.040502
 >> iter 84000, loss: 0.049295
 >> iter 85000, loss: 0.046233
 >> iter 86000, loss: 0.042997
 >> iter 87000, loss: 0.037473
 >> iter 88000, loss: 0.040244
 >> iter 89000, loss: 0.050143
 >> iter 90000, loss: 0.048345
   Number of active neurons: 3
 >> iter 91000, loss: 0.051106
 >> iter 92000, loss: 0.047196
 >> iter 93000, loss: 0.045332
 >> iter 94000, loss: 0.056712
 >> iter 95000, loss: 0.042237
 >> iter 96000, loss: 0.040939
 >> iter 97000, loss: 0.068717
 >> iter 98000, loss: 0.070997
 >> iter 99000, loss: 0.049547
 >> iter 100000, loss: 0.038703
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.431856
 >> iter 2000, loss: 4.488937
 >> iter 3000, loss: 1.749307
 >> iter 4000, loss: 0.728137
 >> iter 5000, loss: 0.336363
 >> iter 6000, loss: 0.184943
 >> iter 7000, loss: 0.125925
 >> iter 8000, loss: 0.096515
 >> iter 9000, loss: 0.090849
 >> iter 10000, loss: 0.095919
   Number of active neurons: 8
 >> iter 11000, loss: 0.086242
 >> iter 12000, loss: 0.067805
 >> iter 13000, loss: 0.081479
 >> iter 14000, loss: 0.084204
 >> iter 15000, loss: 0.073111
 >> iter 16000, loss: 0.062616
 >> iter 17000, loss: 0.054743
 >> iter 18000, loss: 0.067560
 >> iter 19000, loss: 0.064270
 >> iter 20000, loss: 0.058186
   Number of active neurons: 7
 >> iter 21000, loss: 0.057369
 >> iter 22000, loss: 0.055697
 >> iter 23000, loss: 0.053571
 >> iter 24000, loss: 0.072430
 >> iter 25000, loss: 0.064032
 >> iter 26000, loss: 0.073140
 >> iter 27000, loss: 0.064615
 >> iter 28000, loss: 0.045320
 >> iter 29000, loss: 0.051101
 >> iter 30000, loss: 0.068534
   Number of active neurons: 6
 >> iter 31000, loss: 0.076691
 >> iter 32000, loss: 0.065327
 >> iter 33000, loss: 0.060521
 >> iter 34000, loss: 0.040574
 >> iter 35000, loss: 0.045183
 >> iter 36000, loss: 0.047352
 >> iter 37000, loss: 0.054288
 >> iter 38000, loss: 0.061079
 >> iter 39000, loss: 0.062138
 >> iter 40000, loss: 0.044494
   Number of active neurons: 4
 >> iter 41000, loss: 0.039023
 >> iter 42000, loss: 0.047176
 >> iter 43000, loss: 0.048912
 >> iter 44000, loss: 0.048842
 >> iter 45000, loss: 0.047041
 >> iter 46000, loss: 0.037558
 >> iter 47000, loss: 0.054939
 >> iter 48000, loss: 0.041756
 >> iter 49000, loss: 0.035022
 >> iter 50000, loss: 0.039650
   Number of active neurons: 4
 >> iter 51000, loss: 0.044250
 >> iter 52000, loss: 0.044078
 >> iter 53000, loss: 0.043882
 >> iter 54000, loss: 0.062576
 >> iter 55000, loss: 0.050058
 >> iter 56000, loss: 0.051084
 >> iter 57000, loss: 0.056593
 >> iter 58000, loss: 0.045800
 >> iter 59000, loss: 0.066852
 >> iter 60000, loss: 0.055171
   Number of active neurons: 4
 >> iter 61000, loss: 0.051598
 >> iter 62000, loss: 0.046535
 >> iter 63000, loss: 0.040669
 >> iter 64000, loss: 0.036523
 >> iter 65000, loss: 0.031062
 >> iter 66000, loss: 0.037054
 >> iter 67000, loss: 0.052380
 >> iter 68000, loss: 0.040384
 >> iter 69000, loss: 0.043290
 >> iter 70000, loss: 0.039748
   Number of active neurons: 4
 >> iter 71000, loss: 0.037832
 >> iter 72000, loss: 0.044161
 >> iter 73000, loss: 0.059791
 >> iter 74000, loss: 0.090794
 >> iter 75000, loss: 0.070008
 >> iter 76000, loss: 0.066939
 >> iter 77000, loss: 0.056850
 >> iter 78000, loss: 0.053694
 >> iter 79000, loss: 0.040778
 >> iter 80000, loss: 0.046125
   Number of active neurons: 4
 >> iter 81000, loss: 0.057872
 >> iter 82000, loss: 0.052783
 >> iter 83000, loss: 0.037461
 >> iter 84000, loss: 0.050681
 >> iter 85000, loss: 0.039236
 >> iter 86000, loss: 0.059213
 >> iter 87000, loss: 0.042720
 >> iter 88000, loss: 0.040777
 >> iter 89000, loss: 0.044493
 >> iter 90000, loss: 0.037986
   Number of active neurons: 4
 >> iter 91000, loss: 0.041555
 >> iter 92000, loss: 0.031401
 >> iter 93000, loss: 0.059571
 >> iter 94000, loss: 0.058995
 >> iter 95000, loss: 0.052523
 >> iter 96000, loss: 0.058585
 >> iter 97000, loss: 0.064198
 >> iter 98000, loss: 0.057226
 >> iter 99000, loss: 0.056250
 >> iter 100000, loss: 0.043701
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

