 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.972645
 >> iter 2000, loss: 10.729508
 >> iter 3000, loss: 8.721375
 >> iter 4000, loss: 7.960090
 >> iter 5000, loss: 7.672935
 >> iter 6000, loss: 7.554327
 >> iter 7000, loss: 7.520413
 >> iter 8000, loss: 7.499821
 >> iter 9000, loss: 7.501406
 >> iter 10000, loss: 7.484212
   Number of active neurons: 5
 >> iter 11000, loss: 7.535454
 >> iter 12000, loss: 7.494415
 >> iter 13000, loss: 7.495851
 >> iter 14000, loss: 7.479437
 >> iter 15000, loss: 7.486577
   Number of active neurons: 5
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 7.472832
 >> iter 17000, loss: 7.488380
 >> iter 18000, loss: 7.474324
 >> iter 19000, loss: 7.485530
 >> iter 20000, loss: 7.477207
   Number of active neurons: 5
 >> iter 21000, loss: 7.489268
 >> iter 22000, loss: 7.477306
 >> iter 23000, loss: 7.484706
 >> iter 24000, loss: 7.474918
 >> iter 25000, loss: 7.487269
   Number of active neurons: 5
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 26000, loss: 7.479482
 >> iter 27000, loss: 7.486741
 >> iter 28000, loss: 7.478662
 >> iter 29000, loss: 7.485869
 >> iter 30000, loss: 7.476807
   Number of active neurons: 5
 >> iter 31000, loss: 7.484169
 >> iter 32000, loss: 7.466416
 >> iter 33000, loss: 7.459167
 >> iter 34000, loss: 7.477273
 >> iter 35000, loss: 7.416687
 >> iter 36000, loss: 7.329820
 >> iter 37000, loss: 7.248296
 >> iter 38000, loss: 7.154308
 >> iter 39000, loss: 7.065568
 >> iter 40000, loss: 6.932993
   Number of active neurons: 10
 >> iter 41000, loss: 6.725760
 >> iter 42000, loss: 6.522027
 >> iter 43000, loss: 6.377676
 >> iter 44000, loss: 6.284383
 >> iter 45000, loss: 6.215935
 >> iter 46000, loss: 6.153062
 >> iter 47000, loss: 6.101625
 >> iter 48000, loss: 5.951570
 >> iter 49000, loss: 5.724742
 >> iter 50000, loss: 5.489572
   Number of active neurons: 10
 >> iter 51000, loss: 5.320774
 >> iter 52000, loss: 5.228647
 >> iter 53000, loss: 5.132577
 >> iter 54000, loss: 5.015414
 >> iter 55000, loss: 4.943513
 >> iter 56000, loss: 4.896133
 >> iter 57000, loss: 4.386638
 >> iter 58000, loss: 3.401721
 >> iter 59000, loss: 2.795319
 >> iter 60000, loss: 2.192361
   Number of active neurons: 10
 >> iter 61000, loss: 1.817167
 >> iter 62000, loss: 1.729429
 >> iter 63000, loss: 1.678702
 >> iter 64000, loss: 1.390897
 >> iter 65000, loss: 1.511188
 >> iter 66000, loss: 1.401454
 >> iter 67000, loss: 1.006731
 >> iter 68000, loss: 1.054744
 >> iter 69000, loss: 1.185054
 >> iter 70000, loss: 1.099566
   Number of active neurons: 10
 >> iter 71000, loss: 1.094976
 >> iter 72000, loss: 1.226385
 >> iter 73000, loss: 0.993337
 >> iter 74000, loss: 0.777537
 >> iter 75000, loss: 0.912394
 >> iter 76000, loss: 0.671979
 >> iter 77000, loss: 0.609860
 >> iter 78000, loss: 0.641386
 >> iter 79000, loss: 0.680658
 >> iter 80000, loss: 0.603550
   Number of active neurons: 10
 >> iter 81000, loss: 0.442268
 >> iter 82000, loss: 0.542086
 >> iter 83000, loss: 0.474236
 >> iter 84000, loss: 0.750095
 >> iter 85000, loss: 0.538281
 >> iter 86000, loss: 0.514475
 >> iter 87000, loss: 0.451036
 >> iter 88000, loss: 0.381794
 >> iter 89000, loss: 0.242132
 >> iter 90000, loss: 0.247857
   Number of active neurons: 10
 >> iter 91000, loss: 0.192368
 >> iter 92000, loss: 0.222351
 >> iter 93000, loss: 0.137077
 >> iter 94000, loss: 0.504512
 >> iter 95000, loss: 0.498416
 >> iter 96000, loss: 0.397548
 >> iter 97000, loss: 0.520148
 >> iter 98000, loss: 0.480231
 >> iter 99000, loss: 0.368293
 >> iter 100000, loss: 0.440545
   Number of active neurons: 10
 >> iter 101000, loss: 0.374826
 >> iter 102000, loss: 0.545747
 >> iter 103000, loss: 0.521242
 >> iter 104000, loss: 0.582052
 >> iter 105000, loss: 0.546018
 >> iter 106000, loss: 0.388249
 >> iter 107000, loss: 0.350239
 >> iter 108000, loss: 0.301640
 >> iter 109000, loss: 0.371218
 >> iter 110000, loss: 0.353774
   Number of active neurons: 10
 >> iter 111000, loss: 0.330203
 >> iter 112000, loss: 0.357248
 >> iter 113000, loss: 0.188137
 >> iter 114000, loss: 0.198409
 >> iter 115000, loss: 0.172749
 >> iter 116000, loss: 0.158605
 >> iter 117000, loss: 0.353735
 >> iter 118000, loss: 0.299357
 >> iter 119000, loss: 0.211591
 >> iter 120000, loss: 0.243044
   Number of active neurons: 10
 >> iter 121000, loss: 0.266256
 >> iter 122000, loss: 0.171254
 >> iter 123000, loss: 0.315087
 >> iter 124000, loss: 0.235916
 >> iter 125000, loss: 0.285709
 >> iter 126000, loss: 0.219837
 >> iter 127000, loss: 0.148567
 >> iter 128000, loss: 0.234621
 >> iter 129000, loss: 0.164711
 >> iter 130000, loss: 0.550834
   Number of active neurons: 10
 >> iter 131000, loss: 0.497272
 >> iter 132000, loss: 0.342771
 >> iter 133000, loss: 0.257942
 >> iter 134000, loss: 0.292912
 >> iter 135000, loss: 0.211852
 >> iter 136000, loss: 0.191957
 >> iter 137000, loss: 0.247554
 >> iter 138000, loss: 0.129801
 >> iter 139000, loss: 0.190240
 >> iter 140000, loss: 0.113177
   Number of active neurons: 10
 >> iter 141000, loss: 0.420497
 >> iter 142000, loss: 0.334876
 >> iter 143000, loss: 0.291137
 >> iter 144000, loss: 0.257094
 >> iter 145000, loss: 0.188690
 >> iter 146000, loss: 0.141153
 >> iter 147000, loss: 0.163519
 >> iter 148000, loss: 0.305623
 >> iter 149000, loss: 0.183022
 >> iter 150000, loss: 0.253321
   Number of active neurons: 10
 >> iter 151000, loss: 0.423720
 >> iter 152000, loss: 0.420940
 >> iter 153000, loss: 0.743587
 >> iter 154000, loss: 0.443100
 >> iter 155000, loss: 0.355115
 >> iter 156000, loss: 0.204127
 >> iter 157000, loss: 0.227386
 >> iter 158000, loss: 0.154919
 >> iter 159000, loss: 0.163490
 >> iter 160000, loss: 0.165951
   Number of active neurons: 10
 >> iter 161000, loss: 0.193608
 >> iter 162000, loss: 0.155021
 >> iter 163000, loss: 0.088076
 >> iter 164000, loss: 0.122020
 >> iter 165000, loss: 0.119366
 >> iter 166000, loss: 0.251221
 >> iter 167000, loss: 0.187482
 >> iter 168000, loss: 0.102009
 >> iter 169000, loss: 0.098827
 >> iter 170000, loss: 0.179438
   Number of active neurons: 10
 >> iter 171000, loss: 0.108583
 >> iter 172000, loss: 0.056991
 >> iter 173000, loss: 0.050462
 >> iter 174000, loss: 0.050301
 >> iter 175000, loss: 0.247063
 >> iter 176000, loss: 0.138027
 >> iter 177000, loss: 0.083075
 >> iter 178000, loss: 0.173803
 >> iter 179000, loss: 0.120144
 >> iter 180000, loss: 0.100714
   Number of active neurons: 10
 >> iter 181000, loss: 0.113976
 >> iter 182000, loss: 0.179499
 >> iter 183000, loss: 0.160134
 >> iter 184000, loss: 0.074142
 >> iter 185000, loss: 0.218110
 >> iter 186000, loss: 0.163516
 >> iter 187000, loss: 0.242489
 >> iter 188000, loss: 0.190116
 >> iter 189000, loss: 0.124910
 >> iter 190000, loss: 0.088671
   Number of active neurons: 10
 >> iter 191000, loss: 0.132737
 >> iter 192000, loss: 0.176311
 >> iter 193000, loss: 0.086972
 >> iter 194000, loss: 0.126107
 >> iter 195000, loss: 0.059566
 >> iter 196000, loss: 0.060151
 >> iter 197000, loss: 0.135374
 >> iter 198000, loss: 0.233502
 >> iter 199000, loss: 0.189070
 >> iter 200000, loss: 0.083463
   Number of active neurons: 10
 >> iter 201000, loss: 0.064736
 >> iter 202000, loss: 0.035566
 >> iter 203000, loss: 0.119523
 >> iter 204000, loss: 0.263380
 >> iter 205000, loss: 0.344920
 >> iter 206000, loss: 0.243934
 >> iter 207000, loss: 0.193553
 >> iter 208000, loss: 0.137973
 >> iter 209000, loss: 0.129091
 >> iter 210000, loss: 0.098537
   Number of active neurons: 10
 >> iter 211000, loss: 0.140447
 >> iter 212000, loss: 0.091922
 >> iter 213000, loss: 0.061010
 >> iter 214000, loss: 0.130786
 >> iter 215000, loss: 0.076549
 >> iter 216000, loss: 0.039909
 >> iter 217000, loss: 0.025862
 >> iter 218000, loss: 0.020211
 >> iter 219000, loss: 0.055185
 >> iter 220000, loss: 0.228500
   Number of active neurons: 10
 >> iter 221000, loss: 0.181074
 >> iter 222000, loss: 0.112561
 >> iter 223000, loss: 0.053269
 >> iter 224000, loss: 0.039530
 >> iter 225000, loss: 0.102835
 >> iter 226000, loss: 0.053537
 >> iter 227000, loss: 0.029815
 >> iter 228000, loss: 0.033712
 >> iter 229000, loss: 0.081256
 >> iter 230000, loss: 0.086151
   Number of active neurons: 10
 >> iter 231000, loss: 0.041257
 >> iter 232000, loss: 0.039541
 >> iter 233000, loss: 0.172554
 >> iter 234000, loss: 0.185156
 >> iter 235000, loss: 0.084722
 >> iter 236000, loss: 0.393582
 >> iter 237000, loss: 0.240131
 >> iter 238000, loss: 0.117130
 >> iter 239000, loss: 0.063850
 >> iter 240000, loss: 0.034106
   Number of active neurons: 10
 >> iter 241000, loss: 0.085965
 >> iter 242000, loss: 0.052075
 >> iter 243000, loss: 0.048466
 >> iter 244000, loss: 0.058302
 >> iter 245000, loss: 0.065184
 >> iter 246000, loss: 0.075464
 >> iter 247000, loss: 0.098657
 >> iter 248000, loss: 0.076887
 >> iter 249000, loss: 0.040853
 >> iter 250000, loss: 0.031132
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.976008
 >> iter 2000, loss: 10.814712
 >> iter 3000, loss: 8.807963
 >> iter 4000, loss: 8.077573
 >> iter 5000, loss: 7.787138
 >> iter 6000, loss: 7.738064
 >> iter 7000, loss: 7.647518
 >> iter 8000, loss: 7.597167
 >> iter 9000, loss: 7.597099
 >> iter 10000, loss: 7.581571
   Number of active neurons: 9
 >> iter 11000, loss: 7.584493
 >> iter 12000, loss: 7.575307
 >> iter 13000, loss: 7.580107
 >> iter 14000, loss: 7.568294
 >> iter 15000, loss: 7.574617
 >> iter 16000, loss: 7.536533
 >> iter 17000, loss: 7.337279
 >> iter 18000, loss: 7.030787
 >> iter 19000, loss: 6.783162
 >> iter 20000, loss: 6.166064
   Number of active neurons: 10
 >> iter 21000, loss: 3.212368
 >> iter 22000, loss: 1.289664
 >> iter 23000, loss: 0.644486
 >> iter 24000, loss: 0.265451
 >> iter 25000, loss: 0.161972
 >> iter 26000, loss: 0.108793
 >> iter 27000, loss: 0.049698
 >> iter 28000, loss: 0.050284
 >> iter 29000, loss: 0.027536
 >> iter 30000, loss: 0.016622
   Number of active neurons: 10
 >> iter 31000, loss: 0.067961
 >> iter 32000, loss: 0.031504
 >> iter 33000, loss: 0.016838
 >> iter 34000, loss: 0.010849
 >> iter 35000, loss: 0.067400
 >> iter 36000, loss: 0.054529
 >> iter 37000, loss: 0.024080
 >> iter 38000, loss: 0.012525
 >> iter 39000, loss: 0.007767
 >> iter 40000, loss: 0.005879
   Number of active neurons: 10
 >> iter 41000, loss: 0.120469
 >> iter 42000, loss: 0.049690
 >> iter 43000, loss: 0.034862
 >> iter 44000, loss: 0.016196
 >> iter 45000, loss: 0.009028
 >> iter 46000, loss: 0.006157
 >> iter 47000, loss: 0.004629
 >> iter 48000, loss: 0.003974
 >> iter 49000, loss: 0.006219
 >> iter 50000, loss: 0.004606
   Number of active neurons: 10
 >> iter 51000, loss: 0.003879
 >> iter 52000, loss: 0.005314
 >> iter 53000, loss: 0.058209
 >> iter 54000, loss: 0.024449
 >> iter 55000, loss: 0.010813
 >> iter 56000, loss: 0.005727
 >> iter 57000, loss: 0.003727
 >> iter 58000, loss: 0.002921
 >> iter 59000, loss: 0.004546
 >> iter 60000, loss: 0.006320
   Number of active neurons: 10
 >> iter 61000, loss: 0.070801
 >> iter 62000, loss: 0.027836
 >> iter 63000, loss: 0.011797
 >> iter 64000, loss: 0.006523
 >> iter 65000, loss: 0.004023
 >> iter 66000, loss: 0.002993
 >> iter 67000, loss: 0.002613
 >> iter 68000, loss: 0.002211
 >> iter 69000, loss: 0.075022
 >> iter 70000, loss: 0.035450
   Number of active neurons: 10
 >> iter 71000, loss: 0.014641
 >> iter 72000, loss: 0.008627
 >> iter 73000, loss: 0.006737
 >> iter 74000, loss: 0.003972
 >> iter 75000, loss: 0.003002
 >> iter 76000, loss: 0.002322
 >> iter 77000, loss: 0.001939
 >> iter 78000, loss: 0.001809
 >> iter 79000, loss: 0.001682
 >> iter 80000, loss: 0.001718
   Number of active neurons: 10
 >> iter 81000, loss: 0.001607
 >> iter 82000, loss: 0.001548
 >> iter 83000, loss: 0.001625
 >> iter 84000, loss: 0.001598
 >> iter 85000, loss: 0.001437
 >> iter 86000, loss: 0.001379
 >> iter 87000, loss: 0.001375
 >> iter 88000, loss: 0.001481
 >> iter 89000, loss: 0.001317
 >> iter 90000, loss: 0.001262
   Number of active neurons: 10
 >> iter 91000, loss: 0.001231
 >> iter 92000, loss: 0.001170
 >> iter 93000, loss: 0.001121
 >> iter 94000, loss: 0.001334
 >> iter 95000, loss: 0.001234
 >> iter 96000, loss: 0.001236
 >> iter 97000, loss: 0.001225
 >> iter 98000, loss: 0.001083
 >> iter 99000, loss: 0.001055
 >> iter 100000, loss: 0.001256
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.769489
 >> iter 2000, loss: 10.637955
 >> iter 3000, loss: 8.728132
 >> iter 4000, loss: 8.025453
 >> iter 5000, loss: 7.764496
 >> iter 6000, loss: 7.664795
 >> iter 7000, loss: 7.615427
 >> iter 8000, loss: 7.587840
 >> iter 9000, loss: 7.583680
 >> iter 10000, loss: 7.544636
   Number of active neurons: 10
 >> iter 11000, loss: 7.344673
 >> iter 12000, loss: 6.977120
 >> iter 13000, loss: 6.645372
 >> iter 14000, loss: 6.370206
 >> iter 15000, loss: 6.176582
 >> iter 16000, loss: 6.011307
 >> iter 17000, loss: 5.753975
 >> iter 18000, loss: 5.553405
 >> iter 19000, loss: 5.457617
 >> iter 20000, loss: 5.415628
   Number of active neurons: 10
 >> iter 21000, loss: 4.124799
 >> iter 22000, loss: 2.022575
 >> iter 23000, loss: 0.955775
 >> iter 24000, loss: 0.387731
 >> iter 25000, loss: 0.224228
 >> iter 26000, loss: 0.105054
 >> iter 27000, loss: 0.052605
 >> iter 28000, loss: 0.073577
 >> iter 29000, loss: 0.097141
 >> iter 30000, loss: 0.093985
   Number of active neurons: 10
 >> iter 31000, loss: 0.066972
 >> iter 32000, loss: 0.044186
 >> iter 33000, loss: 0.058854
 >> iter 34000, loss: 0.056063
 >> iter 35000, loss: 0.046484
 >> iter 36000, loss: 0.045577
 >> iter 37000, loss: 0.026173
 >> iter 38000, loss: 0.037358
 >> iter 39000, loss: 0.020010
 >> iter 40000, loss: 0.011990
   Number of active neurons: 10
 >> iter 41000, loss: 0.044711
 >> iter 42000, loss: 0.104755
 >> iter 43000, loss: 0.043300
 >> iter 44000, loss: 0.033421
 >> iter 45000, loss: 0.016470
 >> iter 46000, loss: 0.009794
 >> iter 47000, loss: 0.008019
 >> iter 48000, loss: 0.006096
 >> iter 49000, loss: 0.005486
 >> iter 50000, loss: 0.005287
   Number of active neurons: 10
 >> iter 51000, loss: 0.004629
 >> iter 52000, loss: 0.004821
 >> iter 53000, loss: 0.004191
 >> iter 54000, loss: 0.003960
 >> iter 55000, loss: 0.003729
 >> iter 56000, loss: 0.003479
 >> iter 57000, loss: 0.003350
 >> iter 58000, loss: 0.003245
 >> iter 59000, loss: 0.003062
 >> iter 60000, loss: 0.004078
   Number of active neurons: 10
 >> iter 61000, loss: 0.036649
 >> iter 62000, loss: 0.015682
 >> iter 63000, loss: 0.007895
 >> iter 64000, loss: 0.017493
 >> iter 65000, loss: 0.009890
 >> iter 66000, loss: 0.032029
 >> iter 67000, loss: 0.014663
 >> iter 68000, loss: 0.007444
 >> iter 69000, loss: 0.004481
 >> iter 70000, loss: 0.056442
   Number of active neurons: 10
 >> iter 71000, loss: 0.023040
 >> iter 72000, loss: 0.010389
 >> iter 73000, loss: 0.006219
 >> iter 74000, loss: 0.009610
 >> iter 75000, loss: 0.005350
 >> iter 76000, loss: 0.003868
 >> iter 77000, loss: 0.003146
 >> iter 78000, loss: 0.002927
 >> iter 79000, loss: 0.002680
 >> iter 80000, loss: 0.002536
   Number of active neurons: 10
 >> iter 81000, loss: 0.004919
 >> iter 82000, loss: 0.003624
 >> iter 83000, loss: 0.017160
 >> iter 84000, loss: 0.007646
 >> iter 85000, loss: 0.004215
 >> iter 86000, loss: 0.002733
 >> iter 87000, loss: 0.002353
 >> iter 88000, loss: 0.002022
 >> iter 89000, loss: 0.034375
 >> iter 90000, loss: 0.014188
   Number of active neurons: 10
 >> iter 91000, loss: 0.006888
 >> iter 92000, loss: 0.003873
 >> iter 93000, loss: 0.002630
 >> iter 94000, loss: 0.002125
 >> iter 95000, loss: 0.001906
 >> iter 96000, loss: 0.001694
 >> iter 97000, loss: 0.001626
 >> iter 98000, loss: 0.001670
 >> iter 99000, loss: 0.001588
 >> iter 100000, loss: 0.001922
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.783712
 >> iter 2000, loss: 10.659968
 >> iter 3000, loss: 8.722553
 >> iter 4000, loss: 7.988797
 >> iter 5000, loss: 7.716362
 >> iter 6000, loss: 7.565134
 >> iter 7000, loss: 7.185696
 >> iter 8000, loss: 6.908028
 >> iter 9000, loss: 6.536922
 >> iter 10000, loss: 6.023738
   Number of active neurons: 10
 >> iter 11000, loss: 5.918621
 >> iter 12000, loss: 5.440225
 >> iter 13000, loss: 2.521478
 >> iter 14000, loss: 1.229660
 >> iter 15000, loss: 0.537648
 >> iter 16000, loss: 0.306778
 >> iter 17000, loss: 0.175660
 >> iter 18000, loss: 0.144073
 >> iter 19000, loss: 0.097086
 >> iter 20000, loss: 0.048575
   Number of active neurons: 10
 >> iter 21000, loss: 0.122003
 >> iter 22000, loss: 0.245833
 >> iter 23000, loss: 0.118075
 >> iter 24000, loss: 0.059436
 >> iter 25000, loss: 0.044948
 >> iter 26000, loss: 0.024549
 >> iter 27000, loss: 0.061265
 >> iter 28000, loss: 0.035769
 >> iter 29000, loss: 0.019481
 >> iter 30000, loss: 0.012713
   Number of active neurons: 10
 >> iter 31000, loss: 0.009854
 >> iter 32000, loss: 0.008226
 >> iter 33000, loss: 0.046695
 >> iter 34000, loss: 0.024487
 >> iter 35000, loss: 0.084370
 >> iter 36000, loss: 0.049796
 >> iter 37000, loss: 0.051486
 >> iter 38000, loss: 0.028750
 >> iter 39000, loss: 0.015024
 >> iter 40000, loss: 0.035136
   Number of active neurons: 10
 >> iter 41000, loss: 0.016970
 >> iter 42000, loss: 0.010048
 >> iter 43000, loss: 0.017501
 >> iter 44000, loss: 0.076099
 >> iter 45000, loss: 0.064314
 >> iter 46000, loss: 0.028112
 >> iter 47000, loss: 0.112177
 >> iter 48000, loss: 0.063236
 >> iter 49000, loss: 0.027369
 >> iter 50000, loss: 0.019899
   Number of active neurons: 10
 >> iter 51000, loss: 0.078456
 >> iter 52000, loss: 0.033150
 >> iter 53000, loss: 0.016008
 >> iter 54000, loss: 0.009133
 >> iter 55000, loss: 0.007813
 >> iter 56000, loss: 0.067207
 >> iter 57000, loss: 0.028152
 >> iter 58000, loss: 0.013681
 >> iter 59000, loss: 0.008160
 >> iter 60000, loss: 0.005728
   Number of active neurons: 10
 >> iter 61000, loss: 0.004487
 >> iter 62000, loss: 0.003986
 >> iter 63000, loss: 0.003953
 >> iter 64000, loss: 0.003573
 >> iter 65000, loss: 0.003254
 >> iter 66000, loss: 0.003075
 >> iter 67000, loss: 0.003707
 >> iter 68000, loss: 0.003362
 >> iter 69000, loss: 0.002953
 >> iter 70000, loss: 0.002804
   Number of active neurons: 10
 >> iter 71000, loss: 0.002684
 >> iter 72000, loss: 0.002955
 >> iter 73000, loss: 0.002840
 >> iter 74000, loss: 0.002925
 >> iter 75000, loss: 0.002756
 >> iter 76000, loss: 0.081414
 >> iter 77000, loss: 0.032836
 >> iter 78000, loss: 0.014787
 >> iter 79000, loss: 0.007223
 >> iter 80000, loss: 0.004343
   Number of active neurons: 10
 >> iter 81000, loss: 0.003290
 >> iter 82000, loss: 0.002951
 >> iter 83000, loss: 0.002800
 >> iter 84000, loss: 0.002534
 >> iter 85000, loss: 0.002357
 >> iter 86000, loss: 0.002354
 >> iter 87000, loss: 0.002151
 >> iter 88000, loss: 0.002095
 >> iter 89000, loss: 0.002141
 >> iter 90000, loss: 0.002026
   Number of active neurons: 10
 >> iter 91000, loss: 0.082236
 >> iter 92000, loss: 0.032080
 >> iter 93000, loss: 0.013437
 >> iter 94000, loss: 0.006531
 >> iter 95000, loss: 0.003841
 >> iter 96000, loss: 0.002763
 >> iter 97000, loss: 0.002382
 >> iter 98000, loss: 0.002252
 >> iter 99000, loss: 0.002094
 >> iter 100000, loss: 0.002059
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.854739
 >> iter 2000, loss: 10.750895
 >> iter 3000, loss: 8.778709
 >> iter 4000, loss: 8.024479
 >> iter 5000, loss: 7.746756
 >> iter 6000, loss: 7.669898
 >> iter 7000, loss: 7.609860
 >> iter 8000, loss: 7.571874
 >> iter 9000, loss: 7.563863
 >> iter 10000, loss: 7.550753
   Number of active neurons: 8
 >> iter 11000, loss: 7.560204
 >> iter 12000, loss: 7.548299
 >> iter 13000, loss: 7.560363
 >> iter 14000, loss: 7.551815
 >> iter 15000, loss: 7.556139
 >> iter 16000, loss: 7.546809
 >> iter 17000, loss: 7.554798
 >> iter 18000, loss: 7.466803
 >> iter 19000, loss: 7.307365
 >> iter 20000, loss: 6.979395
   Number of active neurons: 10
 >> iter 21000, loss: 6.794359
 >> iter 22000, loss: 6.469052
 >> iter 23000, loss: 6.077480
 >> iter 24000, loss: 5.543774
 >> iter 25000, loss: 4.153504
 >> iter 26000, loss: 1.719759
 >> iter 27000, loss: 0.765998
 >> iter 28000, loss: 0.427291
 >> iter 29000, loss: 0.253698
 >> iter 30000, loss: 0.177261
   Number of active neurons: 10
 >> iter 31000, loss: 0.096027
 >> iter 32000, loss: 0.073431
 >> iter 33000, loss: 0.037304
 >> iter 34000, loss: 0.039261
 >> iter 35000, loss: 0.021902
 >> iter 36000, loss: 0.016412
 >> iter 37000, loss: 0.138367
 >> iter 38000, loss: 0.058697
 >> iter 39000, loss: 0.027517
 >> iter 40000, loss: 0.015134
   Number of active neurons: 10
 >> iter 41000, loss: 0.012322
 >> iter 42000, loss: 0.013513
 >> iter 43000, loss: 0.062719
 >> iter 44000, loss: 0.027066
 >> iter 45000, loss: 0.014414
 >> iter 46000, loss: 0.008847
 >> iter 47000, loss: 0.037941
 >> iter 48000, loss: 0.017464
 >> iter 49000, loss: 0.221125
 >> iter 50000, loss: 0.090812
   Number of active neurons: 10
 >> iter 51000, loss: 0.037395
 >> iter 52000, loss: 0.017130
 >> iter 53000, loss: 0.009395
 >> iter 54000, loss: 0.006682
 >> iter 55000, loss: 0.005936
 >> iter 56000, loss: 0.074470
 >> iter 57000, loss: 0.030540
 >> iter 58000, loss: 0.064488
 >> iter 59000, loss: 0.032913
 >> iter 60000, loss: 0.015218
   Number of active neurons: 10
 >> iter 61000, loss: 0.017521
 >> iter 62000, loss: 0.008989
 >> iter 63000, loss: 0.005648
 >> iter 64000, loss: 0.004304
 >> iter 65000, loss: 0.003636
 >> iter 66000, loss: 0.003532
 >> iter 67000, loss: 0.003448
 >> iter 68000, loss: 0.003165
 >> iter 69000, loss: 0.002801
 >> iter 70000, loss: 0.002661
   Number of active neurons: 10
 >> iter 71000, loss: 0.002843
 >> iter 72000, loss: 0.002525
 >> iter 73000, loss: 0.002351
 >> iter 74000, loss: 0.002545
 >> iter 75000, loss: 0.002371
 >> iter 76000, loss: 0.002248
 >> iter 77000, loss: 0.002126
 >> iter 78000, loss: 0.002108
 >> iter 79000, loss: 0.007429
 >> iter 80000, loss: 0.040998
   Number of active neurons: 10
 >> iter 81000, loss: 0.016497
 >> iter 82000, loss: 0.007461
 >> iter 83000, loss: 0.004289
 >> iter 84000, loss: 0.002893
 >> iter 85000, loss: 0.002261
 >> iter 86000, loss: 0.059434
 >> iter 87000, loss: 0.024102
 >> iter 88000, loss: 0.018250
 >> iter 89000, loss: 0.110209
 >> iter 90000, loss: 0.042250
   Number of active neurons: 10
 >> iter 91000, loss: 0.021067
 >> iter 92000, loss: 0.009802
 >> iter 93000, loss: 0.005269
 >> iter 94000, loss: 0.003348
 >> iter 95000, loss: 0.002701
 >> iter 96000, loss: 0.002161
 >> iter 97000, loss: 0.002007
 >> iter 98000, loss: 0.001900
 >> iter 99000, loss: 0.001922
 >> iter 100000, loss: 0.001761
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455180
   Number of active neurons: 0
 >> iter 1000, loss: 15.946275
 >> iter 2000, loss: 10.695609
 >> iter 3000, loss: 8.727015
 >> iter 4000, loss: 7.976323
 >> iter 5000, loss: 7.708622
 >> iter 6000, loss: 7.599762
 >> iter 7000, loss: 7.565121
 >> iter 8000, loss: 7.558120
 >> iter 9000, loss: 7.545993
 >> iter 10000, loss: 7.527999
   Number of active neurons: 7
 >> iter 11000, loss: 7.532980
 >> iter 12000, loss: 7.516302
 >> iter 13000, loss: 7.520134
 >> iter 14000, loss: 7.468393
 >> iter 15000, loss: 7.298633
 >> iter 16000, loss: 6.937820
 >> iter 17000, loss: 6.386766
 >> iter 18000, loss: 5.898676
 >> iter 19000, loss: 5.567296
 >> iter 20000, loss: 5.066288
   Number of active neurons: 10
 >> iter 21000, loss: 4.840852
 >> iter 22000, loss: 4.611785
 >> iter 23000, loss: 2.673250
 >> iter 24000, loss: 1.132688
 >> iter 25000, loss: 0.500241
 >> iter 26000, loss: 0.349481
 >> iter 27000, loss: 0.185904
 >> iter 28000, loss: 0.183457
 >> iter 29000, loss: 0.198216
 >> iter 30000, loss: 0.175353
   Number of active neurons: 10
 >> iter 31000, loss: 0.093425
 >> iter 32000, loss: 0.081011
 >> iter 33000, loss: 0.093140
 >> iter 34000, loss: 0.046893
 >> iter 35000, loss: 0.043185
 >> iter 36000, loss: 0.146665
 >> iter 37000, loss: 0.075325
 >> iter 38000, loss: 0.036207
 >> iter 39000, loss: 0.021100
 >> iter 40000, loss: 0.020800
   Number of active neurons: 10
 >> iter 41000, loss: 0.086430
 >> iter 42000, loss: 0.040303
 >> iter 43000, loss: 0.065267
 >> iter 44000, loss: 0.036745
 >> iter 45000, loss: 0.033399
 >> iter 46000, loss: 0.071791
 >> iter 47000, loss: 0.032956
 >> iter 48000, loss: 0.175126
 >> iter 49000, loss: 0.071061
 >> iter 50000, loss: 0.032129
   Number of active neurons: 10
 >> iter 51000, loss: 0.017209
 >> iter 52000, loss: 0.017627
 >> iter 53000, loss: 0.011488
 >> iter 54000, loss: 0.071985
 >> iter 55000, loss: 0.031507
 >> iter 56000, loss: 0.016147
 >> iter 57000, loss: 0.010453
 >> iter 58000, loss: 0.010314
 >> iter 59000, loss: 0.008182
 >> iter 60000, loss: 0.006790
   Number of active neurons: 10
 >> iter 61000, loss: 0.008963
 >> iter 62000, loss: 0.006925
 >> iter 63000, loss: 0.019825
 >> iter 64000, loss: 0.010450
 >> iter 65000, loss: 0.007046
 >> iter 66000, loss: 0.005861
 >> iter 67000, loss: 0.005201
 >> iter 68000, loss: 0.010704
 >> iter 69000, loss: 0.006550
 >> iter 70000, loss: 0.004911
   Number of active neurons: 10
 >> iter 71000, loss: 0.004832
 >> iter 72000, loss: 0.004144
 >> iter 73000, loss: 0.211605
 >> iter 74000, loss: 0.137708
 >> iter 75000, loss: 0.058449
 >> iter 76000, loss: 0.057753
 >> iter 77000, loss: 0.024523
 >> iter 78000, loss: 0.012093
 >> iter 79000, loss: 0.007349
 >> iter 80000, loss: 0.005476
   Number of active neurons: 10
 >> iter 81000, loss: 0.004802
 >> iter 82000, loss: 0.004332
 >> iter 83000, loss: 0.030043
 >> iter 84000, loss: 0.013645
 >> iter 85000, loss: 0.054165
 >> iter 86000, loss: 0.022826
 >> iter 87000, loss: 0.011033
 >> iter 88000, loss: 0.007155
 >> iter 89000, loss: 0.031350
 >> iter 90000, loss: 0.014087
   Number of active neurons: 10
 >> iter 91000, loss: 0.008304
 >> iter 92000, loss: 0.008982
 >> iter 93000, loss: 0.005639
 >> iter 94000, loss: 0.004236
 >> iter 95000, loss: 0.003798
 >> iter 96000, loss: 0.003457
 >> iter 97000, loss: 0.004863
 >> iter 98000, loss: 0.003727
 >> iter 99000, loss: 0.003296
 >> iter 100000, loss: 0.003081
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.038309
 >> iter 2000, loss: 10.797574
 >> iter 3000, loss: 8.788031
 >> iter 4000, loss: 8.032209
 >> iter 5000, loss: 7.750725
 >> iter 6000, loss: 7.632696
 >> iter 7000, loss: 7.650637
 >> iter 8000, loss: 7.593207
 >> iter 9000, loss: 7.582250
 >> iter 10000, loss: 7.579829
   Number of active neurons: 10
 >> iter 11000, loss: 7.568773
 >> iter 12000, loss: 7.558253
 >> iter 13000, loss: 7.563019
 >> iter 14000, loss: 7.545549
 >> iter 15000, loss: 7.555211
 >> iter 16000, loss: 7.639433
 >> iter 17000, loss: 7.476810
 >> iter 18000, loss: 7.162776
 >> iter 19000, loss: 6.949736
 >> iter 20000, loss: 6.795544
   Number of active neurons: 10
 >> iter 21000, loss: 6.717067
 >> iter 22000, loss: 6.415107
 >> iter 23000, loss: 6.175306
 >> iter 24000, loss: 5.987463
 >> iter 25000, loss: 5.644004
 >> iter 26000, loss: 5.175905
 >> iter 27000, loss: 3.184261
 >> iter 28000, loss: 1.496316
 >> iter 29000, loss: 0.735905
 >> iter 30000, loss: 0.387043
   Number of active neurons: 10
 >> iter 31000, loss: 0.250072
 >> iter 32000, loss: 0.204638
 >> iter 33000, loss: 0.135549
 >> iter 34000, loss: 0.114048
 >> iter 35000, loss: 0.127950
 >> iter 36000, loss: 0.066556
 >> iter 37000, loss: 0.045445
 >> iter 38000, loss: 0.057269
 >> iter 39000, loss: 0.191524
 >> iter 40000, loss: 0.163265
   Number of active neurons: 10
 >> iter 41000, loss: 0.078202
 >> iter 42000, loss: 0.043444
 >> iter 43000, loss: 0.043201
 >> iter 44000, loss: 0.046706
 >> iter 45000, loss: 0.088784
 >> iter 46000, loss: 0.044977
 >> iter 47000, loss: 0.030672
 >> iter 48000, loss: 0.032450
 >> iter 49000, loss: 0.019433
 >> iter 50000, loss: 0.015058
   Number of active neurons: 10
 >> iter 51000, loss: 0.040351
 >> iter 52000, loss: 0.021512
 >> iter 53000, loss: 0.019103
 >> iter 54000, loss: 0.053554
 >> iter 55000, loss: 0.063049
 >> iter 56000, loss: 0.046987
 >> iter 57000, loss: 0.047111
 >> iter 58000, loss: 0.061482
 >> iter 59000, loss: 0.029734
 >> iter 60000, loss: 0.024169
   Number of active neurons: 10
 >> iter 61000, loss: 0.018885
 >> iter 62000, loss: 0.012687
 >> iter 63000, loss: 0.089745
 >> iter 64000, loss: 0.042911
 >> iter 65000, loss: 0.020632
 >> iter 66000, loss: 0.055151
 >> iter 67000, loss: 0.052291
 >> iter 68000, loss: 0.025097
 >> iter 69000, loss: 0.014867
 >> iter 70000, loss: 0.009689
   Number of active neurons: 10
 >> iter 71000, loss: 0.008793
 >> iter 72000, loss: 0.091140
 >> iter 73000, loss: 0.038850
 >> iter 74000, loss: 0.020011
 >> iter 75000, loss: 0.014259
 >> iter 76000, loss: 0.013024
 >> iter 77000, loss: 0.008600
 >> iter 78000, loss: 0.010175
 >> iter 79000, loss: 0.111792
 >> iter 80000, loss: 0.045900
   Number of active neurons: 10
 >> iter 81000, loss: 0.021639
 >> iter 82000, loss: 0.012005
 >> iter 83000, loss: 0.019074
 >> iter 84000, loss: 0.012969
 >> iter 85000, loss: 0.088701
 >> iter 86000, loss: 0.040093
 >> iter 87000, loss: 0.037156
 >> iter 88000, loss: 0.035398
 >> iter 89000, loss: 0.017309
 >> iter 90000, loss: 0.080755
   Number of active neurons: 10
 >> iter 91000, loss: 0.033431
 >> iter 92000, loss: 0.030555
 >> iter 93000, loss: 0.036549
 >> iter 94000, loss: 0.016816
 >> iter 95000, loss: 0.009233
 >> iter 96000, loss: 0.006281
 >> iter 97000, loss: 0.005281
 >> iter 98000, loss: 0.004793
 >> iter 99000, loss: 0.018687
 >> iter 100000, loss: 0.009408
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.778861
 >> iter 2000, loss: 10.673833
 >> iter 3000, loss: 8.739276
 >> iter 4000, loss: 8.037764
 >> iter 5000, loss: 7.761010
 >> iter 6000, loss: 7.701953
 >> iter 7000, loss: 7.633504
 >> iter 8000, loss: 7.596691
 >> iter 9000, loss: 7.595103
 >> iter 10000, loss: 7.579033
   Number of active neurons: 10
 >> iter 11000, loss: 7.582156
 >> iter 12000, loss: 7.575453
 >> iter 13000, loss: 7.579824
 >> iter 14000, loss: 7.572997
 >> iter 15000, loss: 7.582626
 >> iter 16000, loss: 7.573808
 >> iter 17000, loss: 7.576269
 >> iter 18000, loss: 7.559271
 >> iter 19000, loss: 7.553251
 >> iter 20000, loss: 7.284678
   Number of active neurons: 10
 >> iter 21000, loss: 7.060536
 >> iter 22000, loss: 6.745148
 >> iter 23000, loss: 6.451725
 >> iter 24000, loss: 6.137812
 >> iter 25000, loss: 5.968350
 >> iter 26000, loss: 5.750085
 >> iter 27000, loss: 5.218571
 >> iter 28000, loss: 4.465475
 >> iter 29000, loss: 2.867376
 >> iter 30000, loss: 1.248298
   Number of active neurons: 10
 >> iter 31000, loss: 0.501855
 >> iter 32000, loss: 0.270407
 >> iter 33000, loss: 0.176767
 >> iter 34000, loss: 0.081643
 >> iter 35000, loss: 0.062438
 >> iter 36000, loss: 0.054777
 >> iter 37000, loss: 0.031898
 >> iter 38000, loss: 0.018309
 >> iter 39000, loss: 0.012532
 >> iter 40000, loss: 0.010406
   Number of active neurons: 10
 >> iter 41000, loss: 0.012589
 >> iter 42000, loss: 0.009473
 >> iter 43000, loss: 0.009378
 >> iter 44000, loss: 0.019194
 >> iter 45000, loss: 0.010570
 >> iter 46000, loss: 0.010004
 >> iter 47000, loss: 0.007613
 >> iter 48000, loss: 0.005923
 >> iter 49000, loss: 0.004996
 >> iter 50000, loss: 0.008119
   Number of active neurons: 10
 >> iter 51000, loss: 0.007059
 >> iter 52000, loss: 0.005311
 >> iter 53000, loss: 0.004799
 >> iter 54000, loss: 0.003938
 >> iter 55000, loss: 0.003785
 >> iter 56000, loss: 0.003420
 >> iter 57000, loss: 0.003331
 >> iter 58000, loss: 0.003338
 >> iter 59000, loss: 0.003081
 >> iter 60000, loss: 0.005725
   Number of active neurons: 10
 >> iter 61000, loss: 0.003847
 >> iter 62000, loss: 0.003045
 >> iter 63000, loss: 0.003052
 >> iter 64000, loss: 0.026603
 >> iter 65000, loss: 0.011622
 >> iter 66000, loss: 0.006651
 >> iter 67000, loss: 0.080264
 >> iter 68000, loss: 0.031504
 >> iter 69000, loss: 0.014861
 >> iter 70000, loss: 0.043150
   Number of active neurons: 10
 >> iter 71000, loss: 0.017435
 >> iter 72000, loss: 0.007816
 >> iter 73000, loss: 0.004356
 >> iter 74000, loss: 0.004010
 >> iter 75000, loss: 0.002842
 >> iter 76000, loss: 0.004322
 >> iter 77000, loss: 0.002848
 >> iter 78000, loss: 0.002485
 >> iter 79000, loss: 0.017702
 >> iter 80000, loss: 0.008121
   Number of active neurons: 10
 >> iter 81000, loss: 0.004123
 >> iter 82000, loss: 0.003083
 >> iter 83000, loss: 0.002211
 >> iter 84000, loss: 0.001890
 >> iter 85000, loss: 0.001718
 >> iter 86000, loss: 0.001656
 >> iter 87000, loss: 0.001646
 >> iter 88000, loss: 0.001588
 >> iter 89000, loss: 0.001457
 >> iter 90000, loss: 0.001426
   Number of active neurons: 10
 >> iter 91000, loss: 0.001430
 >> iter 92000, loss: 0.001389
 >> iter 93000, loss: 0.001317
 >> iter 94000, loss: 0.001282
 >> iter 95000, loss: 0.001275
 >> iter 96000, loss: 0.001242
 >> iter 97000, loss: 0.001283
 >> iter 98000, loss: 0.001184
 >> iter 99000, loss: 0.001151
 >> iter 100000, loss: 0.001211
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.870220
 >> iter 2000, loss: 10.654277
 >> iter 3000, loss: 8.723382
 >> iter 4000, loss: 8.001525
 >> iter 5000, loss: 7.766065
 >> iter 6000, loss: 7.669129
 >> iter 7000, loss: 7.607621
 >> iter 8000, loss: 7.573260
 >> iter 9000, loss: 7.561634
 >> iter 10000, loss: 7.566449
   Number of active neurons: 8
 >> iter 11000, loss: 7.546268
 >> iter 12000, loss: 7.469643
 >> iter 13000, loss: 7.115399
 >> iter 14000, loss: 6.545994
 >> iter 15000, loss: 5.933795
 >> iter 16000, loss: 5.644081
 >> iter 17000, loss: 5.476940
 >> iter 18000, loss: 5.270555
 >> iter 19000, loss: 5.118862
 >> iter 20000, loss: 4.918835
   Number of active neurons: 10
 >> iter 21000, loss: 2.395152
 >> iter 22000, loss: 1.097859
 >> iter 23000, loss: 0.712662
 >> iter 24000, loss: 0.478191
 >> iter 25000, loss: 0.236496
 >> iter 26000, loss: 0.197521
 >> iter 27000, loss: 0.189439
 >> iter 28000, loss: 0.108631
 >> iter 29000, loss: 0.170718
 >> iter 30000, loss: 0.222485
   Number of active neurons: 10
 >> iter 31000, loss: 0.144727
 >> iter 32000, loss: 0.157002
 >> iter 33000, loss: 0.140082
 >> iter 34000, loss: 0.079927
 >> iter 35000, loss: 0.046933
 >> iter 36000, loss: 0.031406
 >> iter 37000, loss: 0.037670
 >> iter 38000, loss: 0.073157
 >> iter 39000, loss: 0.037994
 >> iter 40000, loss: 0.022159
   Number of active neurons: 10
 >> iter 41000, loss: 0.106940
 >> iter 42000, loss: 0.060320
 >> iter 43000, loss: 0.060245
 >> iter 44000, loss: 0.088790
 >> iter 45000, loss: 0.081002
 >> iter 46000, loss: 0.064617
 >> iter 47000, loss: 0.037173
 >> iter 48000, loss: 0.020638
 >> iter 49000, loss: 0.026693
 >> iter 50000, loss: 0.045178
   Number of active neurons: 10
 >> iter 51000, loss: 0.053053
 >> iter 52000, loss: 0.070433
 >> iter 53000, loss: 0.077134
 >> iter 54000, loss: 0.046996
 >> iter 55000, loss: 0.023102
 >> iter 56000, loss: 0.078369
 >> iter 57000, loss: 0.034541
 >> iter 58000, loss: 0.064143
 >> iter 59000, loss: 0.049683
 >> iter 60000, loss: 0.081923
   Number of active neurons: 10
 >> iter 61000, loss: 0.036500
 >> iter 62000, loss: 0.018711
 >> iter 63000, loss: 0.016866
 >> iter 64000, loss: 0.031848
 >> iter 65000, loss: 0.016235
 >> iter 66000, loss: 0.028745
 >> iter 67000, loss: 0.014665
 >> iter 68000, loss: 0.028834
 >> iter 69000, loss: 0.068763
 >> iter 70000, loss: 0.030004
   Number of active neurons: 10
 >> iter 71000, loss: 0.015659
 >> iter 72000, loss: 0.009482
 >> iter 73000, loss: 0.048764
 >> iter 74000, loss: 0.086255
 >> iter 75000, loss: 0.035766
 >> iter 76000, loss: 0.017315
 >> iter 77000, loss: 0.058359
 >> iter 78000, loss: 0.072382
 >> iter 79000, loss: 0.030462
 >> iter 80000, loss: 0.014850
   Number of active neurons: 10
 >> iter 81000, loss: 0.054572
 >> iter 82000, loss: 0.023515
 >> iter 83000, loss: 0.011973
 >> iter 84000, loss: 0.049548
 >> iter 85000, loss: 0.051196
 >> iter 86000, loss: 0.022438
 >> iter 87000, loss: 0.033625
 >> iter 88000, loss: 0.052572
 >> iter 89000, loss: 0.065483
 >> iter 90000, loss: 0.038970
   Number of active neurons: 10
 >> iter 91000, loss: 0.046040
 >> iter 92000, loss: 0.104498
 >> iter 93000, loss: 0.042477
 >> iter 94000, loss: 0.023133
 >> iter 95000, loss: 0.012865
 >> iter 96000, loss: 0.008247
 >> iter 97000, loss: 0.006181
 >> iter 98000, loss: 0.005317
 >> iter 99000, loss: 0.004925
 >> iter 100000, loss: 0.004662
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.799649
 >> iter 2000, loss: 10.653050
 >> iter 3000, loss: 8.717877
 >> iter 4000, loss: 7.976573
 >> iter 5000, loss: 7.720530
 >> iter 6000, loss: 7.604404
 >> iter 7000, loss: 7.583502
 >> iter 8000, loss: 7.545774
 >> iter 9000, loss: 7.551209
 >> iter 10000, loss: 7.535413
   Number of active neurons: 8
 >> iter 11000, loss: 7.545863
 >> iter 12000, loss: 7.464592
 >> iter 13000, loss: 7.229221
 >> iter 14000, loss: 6.825612
 >> iter 15000, loss: 6.410779
 >> iter 16000, loss: 6.108876
 >> iter 17000, loss: 5.982161
 >> iter 18000, loss: 5.826658
 >> iter 19000, loss: 5.557486
 >> iter 20000, loss: 4.753786
   Number of active neurons: 10
 >> iter 21000, loss: 4.327323
 >> iter 22000, loss: 3.971667
 >> iter 23000, loss: 3.924761
 >> iter 24000, loss: 3.714873
 >> iter 25000, loss: 3.728550
 >> iter 26000, loss: 3.672993
 >> iter 27000, loss: 3.675076
 >> iter 28000, loss: 3.608905
 >> iter 29000, loss: 3.777285
 >> iter 30000, loss: 2.334094
   Number of active neurons: 10
 >> iter 31000, loss: 1.136468
 >> iter 32000, loss: 0.776061
 >> iter 33000, loss: 0.450554
 >> iter 34000, loss: 0.303305
 >> iter 35000, loss: 0.317148
 >> iter 36000, loss: 0.249975
 >> iter 37000, loss: 0.301893
 >> iter 38000, loss: 0.234299
 >> iter 39000, loss: 0.163318
 >> iter 40000, loss: 0.167464
   Number of active neurons: 10
 >> iter 41000, loss: 0.214851
 >> iter 42000, loss: 0.118510
 >> iter 43000, loss: 0.083424
 >> iter 44000, loss: 0.050572
 >> iter 45000, loss: 0.115286
 >> iter 46000, loss: 0.293119
 >> iter 47000, loss: 0.141993
 >> iter 48000, loss: 0.069239
 >> iter 49000, loss: 0.037986
 >> iter 50000, loss: 0.073288
   Number of active neurons: 10
 >> iter 51000, loss: 0.038357
 >> iter 52000, loss: 0.111947
 >> iter 53000, loss: 0.052512
 >> iter 54000, loss: 0.054275
 >> iter 55000, loss: 0.060434
 >> iter 56000, loss: 0.080686
 >> iter 57000, loss: 0.038996
 >> iter 58000, loss: 0.158185
 >> iter 59000, loss: 0.190269
 >> iter 60000, loss: 0.098831
   Number of active neurons: 10
 >> iter 61000, loss: 0.044916
 >> iter 62000, loss: 0.099298
 >> iter 63000, loss: 0.079484
 >> iter 64000, loss: 0.036454
 >> iter 65000, loss: 0.037444
 >> iter 66000, loss: 0.110668
 >> iter 67000, loss: 0.060130
 >> iter 68000, loss: 0.029902
 >> iter 69000, loss: 0.022895
 >> iter 70000, loss: 0.071637
   Number of active neurons: 10
 >> iter 71000, loss: 0.220652
 >> iter 72000, loss: 0.117332
 >> iter 73000, loss: 0.050185
 >> iter 74000, loss: 0.025691
 >> iter 75000, loss: 0.015763
 >> iter 76000, loss: 0.010915
 >> iter 77000, loss: 0.009074
 >> iter 78000, loss: 0.007856
 >> iter 79000, loss: 0.007619
 >> iter 80000, loss: 0.129662
   Number of active neurons: 10
 >> iter 81000, loss: 0.085296
 >> iter 82000, loss: 0.064327
 >> iter 83000, loss: 0.035654
 >> iter 84000, loss: 0.020447
 >> iter 85000, loss: 0.013081
 >> iter 86000, loss: 0.009101
 >> iter 87000, loss: 0.079479
 >> iter 88000, loss: 0.034169
 >> iter 89000, loss: 0.016918
 >> iter 90000, loss: 0.009769
   Number of active neurons: 10
 >> iter 91000, loss: 0.007594
 >> iter 92000, loss: 0.041884
 >> iter 93000, loss: 0.019226
 >> iter 94000, loss: 0.010918
 >> iter 95000, loss: 0.028137
 >> iter 96000, loss: 0.049703
 >> iter 97000, loss: 0.021859
 >> iter 98000, loss: 0.011068
 >> iter 99000, loss: 0.007570
 >> iter 100000, loss: 0.006158
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.891307
 >> iter 2000, loss: 10.697089
 >> iter 3000, loss: 8.773320
 >> iter 4000, loss: 8.069728
 >> iter 5000, loss: 7.765076
 >> iter 6000, loss: 7.634627
 >> iter 7000, loss: 7.593405
 >> iter 8000, loss: 7.570061
 >> iter 9000, loss: 7.566331
 >> iter 10000, loss: 7.551594
   Number of active neurons: 8
 >> iter 11000, loss: 7.565355
 >> iter 12000, loss: 7.541168
 >> iter 13000, loss: 7.552506
 >> iter 14000, loss: 7.546046
 >> iter 15000, loss: 7.545691
 >> iter 16000, loss: 7.528977
 >> iter 17000, loss: 7.539853
 >> iter 18000, loss: 7.566090
 >> iter 19000, loss: 7.594565
 >> iter 20000, loss: 7.380499
   Number of active neurons: 10
 >> iter 21000, loss: 7.016238
 >> iter 22000, loss: 6.659531
 >> iter 23000, loss: 6.310367
 >> iter 24000, loss: 5.729826
 >> iter 25000, loss: 2.396204
 >> iter 26000, loss: 0.931629
 >> iter 27000, loss: 0.423274
 >> iter 28000, loss: 0.173375
 >> iter 29000, loss: 0.078015
 >> iter 30000, loss: 0.219557
   Number of active neurons: 10
 >> iter 31000, loss: 0.099385
 >> iter 32000, loss: 0.140182
 >> iter 33000, loss: 0.062221
 >> iter 34000, loss: 0.031954
 >> iter 35000, loss: 0.019115
 >> iter 36000, loss: 0.015309
 >> iter 37000, loss: 0.045913
 >> iter 38000, loss: 0.023776
 >> iter 39000, loss: 0.028595
 >> iter 40000, loss: 0.040611
   Number of active neurons: 10
 >> iter 41000, loss: 0.019716
 >> iter 42000, loss: 0.044949
 >> iter 43000, loss: 0.021637
 >> iter 44000, loss: 0.052975
 >> iter 45000, loss: 0.023637
 >> iter 46000, loss: 0.053153
 >> iter 47000, loss: 0.034379
 >> iter 48000, loss: 0.020105
 >> iter 49000, loss: 0.011238
 >> iter 50000, loss: 0.007069
   Number of active neurons: 10
 >> iter 51000, loss: 0.005378
 >> iter 52000, loss: 0.005780
 >> iter 53000, loss: 0.004846
 >> iter 54000, loss: 0.004628
 >> iter 55000, loss: 0.003998
 >> iter 56000, loss: 0.003587
 >> iter 57000, loss: 0.004295
 >> iter 58000, loss: 0.027674
 >> iter 59000, loss: 0.012593
 >> iter 60000, loss: 0.007074
   Number of active neurons: 10
 >> iter 61000, loss: 0.004745
 >> iter 62000, loss: 0.003549
 >> iter 63000, loss: 0.017423
 >> iter 64000, loss: 0.030063
 >> iter 65000, loss: 0.098899
 >> iter 66000, loss: 0.038650
 >> iter 67000, loss: 0.017200
 >> iter 68000, loss: 0.009574
 >> iter 69000, loss: 0.005860
 >> iter 70000, loss: 0.013080
   Number of active neurons: 10
 >> iter 71000, loss: 0.006762
 >> iter 72000, loss: 0.004248
 >> iter 73000, loss: 0.003323
 >> iter 74000, loss: 0.002852
 >> iter 75000, loss: 0.002588
 >> iter 76000, loss: 0.002470
 >> iter 77000, loss: 0.002358
 >> iter 78000, loss: 0.002259
 >> iter 79000, loss: 0.048231
 >> iter 80000, loss: 0.019407
   Number of active neurons: 10
 >> iter 81000, loss: 0.008742
 >> iter 82000, loss: 0.004661
 >> iter 83000, loss: 0.003090
 >> iter 84000, loss: 0.002483
 >> iter 85000, loss: 0.002193
 >> iter 86000, loss: 0.002063
 >> iter 87000, loss: 0.002011
 >> iter 88000, loss: 0.001974
 >> iter 89000, loss: 0.001899
 >> iter 90000, loss: 0.001818
   Number of active neurons: 10
 >> iter 91000, loss: 0.001789
 >> iter 92000, loss: 0.001767
 >> iter 93000, loss: 0.001707
 >> iter 94000, loss: 0.001648
 >> iter 95000, loss: 0.001623
 >> iter 96000, loss: 0.001573
 >> iter 97000, loss: 0.001532
 >> iter 98000, loss: 0.001485
 >> iter 99000, loss: 0.001479
 >> iter 100000, loss: 0.001449
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 15.779536
 >> iter 2000, loss: 10.693195
 >> iter 3000, loss: 8.751907
 >> iter 4000, loss: 8.067233
 >> iter 5000, loss: 7.784762
 >> iter 6000, loss: 7.686269
 >> iter 7000, loss: 7.541793
 >> iter 8000, loss: 7.124476
 >> iter 9000, loss: 6.746036
 >> iter 10000, loss: 6.215267
   Number of active neurons: 10
 >> iter 11000, loss: 5.778556
 >> iter 12000, loss: 5.469030
 >> iter 13000, loss: 4.242901
 >> iter 14000, loss: 1.947621
 >> iter 15000, loss: 0.775134
 >> iter 16000, loss: 0.535129
 >> iter 17000, loss: 0.246129
 >> iter 18000, loss: 0.172720
 >> iter 19000, loss: 0.128320
 >> iter 20000, loss: 0.097175
   Number of active neurons: 10
 >> iter 21000, loss: 0.092372
 >> iter 22000, loss: 0.054892
 >> iter 23000, loss: 0.069245
 >> iter 24000, loss: 0.101414
 >> iter 25000, loss: 0.056267
 >> iter 26000, loss: 0.029665
 >> iter 27000, loss: 0.020208
 >> iter 28000, loss: 0.096197
 >> iter 29000, loss: 0.043338
 >> iter 30000, loss: 0.022448
   Number of active neurons: 10
 >> iter 31000, loss: 0.034460
 >> iter 32000, loss: 0.021185
 >> iter 33000, loss: 0.067356
 >> iter 34000, loss: 0.033133
 >> iter 35000, loss: 0.031939
 >> iter 36000, loss: 0.018194
 >> iter 37000, loss: 0.155577
 >> iter 38000, loss: 0.180753
 >> iter 39000, loss: 0.073653
 >> iter 40000, loss: 0.032758
   Number of active neurons: 10
 >> iter 41000, loss: 0.035944
 >> iter 42000, loss: 0.077367
 >> iter 43000, loss: 0.033939
 >> iter 44000, loss: 0.016859
 >> iter 45000, loss: 0.010355
 >> iter 46000, loss: 0.008542
 >> iter 47000, loss: 0.006875
 >> iter 48000, loss: 0.007832
 >> iter 49000, loss: 0.006170
 >> iter 50000, loss: 0.005411
   Number of active neurons: 10
 >> iter 51000, loss: 0.004873
 >> iter 52000, loss: 0.004613
 >> iter 53000, loss: 0.004383
 >> iter 54000, loss: 0.004257
 >> iter 55000, loss: 0.031970
 >> iter 56000, loss: 0.014480
 >> iter 57000, loss: 0.067952
 >> iter 58000, loss: 0.028232
 >> iter 59000, loss: 0.012849
 >> iter 60000, loss: 0.020019
   Number of active neurons: 10
 >> iter 61000, loss: 0.010357
 >> iter 62000, loss: 0.006611
 >> iter 63000, loss: 0.006289
 >> iter 64000, loss: 0.004769
 >> iter 65000, loss: 0.003887
 >> iter 66000, loss: 0.003673
 >> iter 67000, loss: 0.003444
 >> iter 68000, loss: 0.055886
 >> iter 69000, loss: 0.023173
 >> iter 70000, loss: 0.073497
   Number of active neurons: 10
 >> iter 71000, loss: 0.029242
 >> iter 72000, loss: 0.013141
 >> iter 73000, loss: 0.006796
 >> iter 74000, loss: 0.004482
 >> iter 75000, loss: 0.003387
 >> iter 76000, loss: 0.056523
 >> iter 77000, loss: 0.023331
 >> iter 78000, loss: 0.010599
 >> iter 79000, loss: 0.005929
 >> iter 80000, loss: 0.004179
   Number of active neurons: 10
 >> iter 81000, loss: 0.003352
 >> iter 82000, loss: 0.003014
 >> iter 83000, loss: 0.002903
 >> iter 84000, loss: 0.002703
 >> iter 85000, loss: 0.004354
 >> iter 86000, loss: 0.003375
 >> iter 87000, loss: 0.002974
 >> iter 88000, loss: 0.003173
 >> iter 89000, loss: 0.048571
 >> iter 90000, loss: 0.095219
   Number of active neurons: 10
 >> iter 91000, loss: 0.050110
 >> iter 92000, loss: 0.020722
 >> iter 93000, loss: 0.009581
 >> iter 94000, loss: 0.005403
 >> iter 95000, loss: 0.003816
 >> iter 96000, loss: 0.003242
 >> iter 97000, loss: 0.003604
 >> iter 98000, loss: 0.003417
 >> iter 99000, loss: 0.002924
 >> iter 100000, loss: 0.012744
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.766501
 >> iter 2000, loss: 10.655292
 >> iter 3000, loss: 8.751870
 >> iter 4000, loss: 7.994772
 >> iter 5000, loss: 7.713703
 >> iter 6000, loss: 7.605751
 >> iter 7000, loss: 7.571412
 >> iter 8000, loss: 7.546401
 >> iter 9000, loss: 7.552009
 >> iter 10000, loss: 7.533920
   Number of active neurons: 9
 >> iter 11000, loss: 7.548418
 >> iter 12000, loss: 7.507343
 >> iter 13000, loss: 7.354812
 >> iter 14000, loss: 7.089455
 >> iter 15000, loss: 6.852899
 >> iter 16000, loss: 6.525385
 >> iter 17000, loss: 6.246776
 >> iter 18000, loss: 5.912952
 >> iter 19000, loss: 5.154363
 >> iter 20000, loss: 2.349630
   Number of active neurons: 10
 >> iter 21000, loss: 1.038152
 >> iter 22000, loss: 0.527573
 >> iter 23000, loss: 0.426192
 >> iter 24000, loss: 0.206779
 >> iter 25000, loss: 0.104901
 >> iter 26000, loss: 0.130069
 >> iter 27000, loss: 0.079352
 >> iter 28000, loss: 0.092264
 >> iter 29000, loss: 0.060832
 >> iter 30000, loss: 0.032898
   Number of active neurons: 10
 >> iter 31000, loss: 0.074200
 >> iter 32000, loss: 0.098481
 >> iter 33000, loss: 0.045224
 >> iter 34000, loss: 0.023181
 >> iter 35000, loss: 0.015323
 >> iter 36000, loss: 0.011431
 >> iter 37000, loss: 0.009234
 >> iter 38000, loss: 0.042151
 >> iter 39000, loss: 0.021917
 >> iter 40000, loss: 0.060006
   Number of active neurons: 10
 >> iter 41000, loss: 0.035724
 >> iter 42000, loss: 0.018146
 >> iter 43000, loss: 0.010571
 >> iter 44000, loss: 0.007590
 >> iter 45000, loss: 0.006196
 >> iter 46000, loss: 0.005545
 >> iter 47000, loss: 0.005572
 >> iter 48000, loss: 0.004945
 >> iter 49000, loss: 0.004515
 >> iter 50000, loss: 0.004336
   Number of active neurons: 10
 >> iter 51000, loss: 0.003964
 >> iter 52000, loss: 0.014568
 >> iter 53000, loss: 0.007535
 >> iter 54000, loss: 0.005277
 >> iter 55000, loss: 0.004187
 >> iter 56000, loss: 0.021696
 >> iter 57000, loss: 0.148341
 >> iter 58000, loss: 0.059278
 >> iter 59000, loss: 0.027015
 >> iter 60000, loss: 0.012480
   Number of active neurons: 10
 >> iter 61000, loss: 0.006725
 >> iter 62000, loss: 0.004620
 >> iter 63000, loss: 0.003657
 >> iter 64000, loss: 0.004009
 >> iter 65000, loss: 0.078176
 >> iter 66000, loss: 0.031952
 >> iter 67000, loss: 0.014834
 >> iter 68000, loss: 0.008155
 >> iter 69000, loss: 0.005738
 >> iter 70000, loss: 0.003852
   Number of active neurons: 10
 >> iter 71000, loss: 0.003090
 >> iter 72000, loss: 0.002913
 >> iter 73000, loss: 0.002607
 >> iter 74000, loss: 0.002523
 >> iter 75000, loss: 0.002414
 >> iter 76000, loss: 0.002617
 >> iter 77000, loss: 0.002384
 >> iter 78000, loss: 0.002277
 >> iter 79000, loss: 0.002161
 >> iter 80000, loss: 0.002029
   Number of active neurons: 10
 >> iter 81000, loss: 0.001933
 >> iter 82000, loss: 0.001875
 >> iter 83000, loss: 0.002829
 >> iter 84000, loss: 0.002309
 >> iter 85000, loss: 0.002060
 >> iter 86000, loss: 0.001882
 >> iter 87000, loss: 0.002214
 >> iter 88000, loss: 0.001912
 >> iter 89000, loss: 0.001878
 >> iter 90000, loss: 0.002090
   Number of active neurons: 10
 >> iter 91000, loss: 0.001885
 >> iter 92000, loss: 0.001666
 >> iter 93000, loss: 0.001690
 >> iter 94000, loss: 0.001629
 >> iter 95000, loss: 0.060577
 >> iter 96000, loss: 0.027421
 >> iter 97000, loss: 0.011337
 >> iter 98000, loss: 0.005235
 >> iter 99000, loss: 0.002900
 >> iter 100000, loss: 0.002010
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.925839
 >> iter 2000, loss: 10.707541
 >> iter 3000, loss: 8.769129
 >> iter 4000, loss: 8.044803
 >> iter 5000, loss: 7.776134
 >> iter 6000, loss: 7.644948
 >> iter 7000, loss: 7.577767
 >> iter 8000, loss: 7.329923
 >> iter 9000, loss: 6.987296
 >> iter 10000, loss: 6.350401
   Number of active neurons: 10
 >> iter 11000, loss: 5.864071
 >> iter 12000, loss: 5.588990
 >> iter 13000, loss: 5.491839
 >> iter 14000, loss: 5.356799
 >> iter 15000, loss: 5.152547
 >> iter 16000, loss: 4.944099
 >> iter 17000, loss: 4.816468
 >> iter 18000, loss: 3.731953
 >> iter 19000, loss: 1.892249
 >> iter 20000, loss: 1.210929
   Number of active neurons: 10
 >> iter 21000, loss: 1.131021
 >> iter 22000, loss: 0.674806
 >> iter 23000, loss: 0.438464
 >> iter 24000, loss: 0.455420
 >> iter 25000, loss: 0.388800
 >> iter 26000, loss: 0.268649
 >> iter 27000, loss: 0.159626
 >> iter 28000, loss: 0.311822
 >> iter 29000, loss: 0.372327
 >> iter 30000, loss: 0.252049
   Number of active neurons: 10
 >> iter 31000, loss: 0.170282
 >> iter 32000, loss: 0.202986
 >> iter 33000, loss: 0.155539
 >> iter 34000, loss: 0.267399
 >> iter 35000, loss: 0.122302
 >> iter 36000, loss: 0.084543
 >> iter 37000, loss: 0.110428
 >> iter 38000, loss: 0.064338
 >> iter 39000, loss: 0.146332
 >> iter 40000, loss: 0.103816
   Number of active neurons: 10
 >> iter 41000, loss: 0.049959
 >> iter 42000, loss: 0.126835
 >> iter 43000, loss: 0.137780
 >> iter 44000, loss: 0.076325
 >> iter 45000, loss: 0.063053
 >> iter 46000, loss: 0.099330
 >> iter 47000, loss: 0.119630
 >> iter 48000, loss: 0.054906
 >> iter 49000, loss: 0.069785
 >> iter 50000, loss: 0.037779
   Number of active neurons: 10
 >> iter 51000, loss: 0.199141
 >> iter 52000, loss: 0.140242
 >> iter 53000, loss: 0.081404
 >> iter 54000, loss: 0.056516
 >> iter 55000, loss: 0.028983
 >> iter 56000, loss: 0.098716
 >> iter 57000, loss: 0.046260
 >> iter 58000, loss: 0.023847
 >> iter 59000, loss: 0.084115
 >> iter 60000, loss: 0.084098
   Number of active neurons: 10
 >> iter 61000, loss: 0.051190
 >> iter 62000, loss: 0.024593
 >> iter 63000, loss: 0.094731
 >> iter 64000, loss: 0.072116
 >> iter 65000, loss: 0.032488
 >> iter 66000, loss: 0.076288
 >> iter 67000, loss: 0.034433
 >> iter 68000, loss: 0.020781
 >> iter 69000, loss: 0.013986
 >> iter 70000, loss: 0.010215
   Number of active neurons: 10
 >> iter 71000, loss: 0.008681
 >> iter 72000, loss: 0.026823
 >> iter 73000, loss: 0.132301
 >> iter 74000, loss: 0.055907
 >> iter 75000, loss: 0.036486
 >> iter 76000, loss: 0.029183
 >> iter 77000, loss: 0.065063
 >> iter 78000, loss: 0.048129
 >> iter 79000, loss: 0.026859
 >> iter 80000, loss: 0.053981
   Number of active neurons: 10
 >> iter 81000, loss: 0.120318
 >> iter 82000, loss: 0.051673
 >> iter 83000, loss: 0.062680
 >> iter 84000, loss: 0.045531
 >> iter 85000, loss: 0.024525
 >> iter 86000, loss: 0.014861
 >> iter 87000, loss: 0.050162
 >> iter 88000, loss: 0.194881
 >> iter 89000, loss: 0.077924
 >> iter 90000, loss: 0.103192
   Number of active neurons: 10
 >> iter 91000, loss: 0.152920
 >> iter 92000, loss: 0.077946
 >> iter 93000, loss: 0.135050
 >> iter 94000, loss: 0.097907
 >> iter 95000, loss: 0.169652
 >> iter 96000, loss: 0.074462
 >> iter 97000, loss: 0.034590
 >> iter 98000, loss: 0.033368
 >> iter 99000, loss: 0.017126
 >> iter 100000, loss: 0.010951
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.709743
 >> iter 2000, loss: 10.598117
 >> iter 3000, loss: 8.687776
 >> iter 4000, loss: 7.956934
 >> iter 5000, loss: 7.691253
 >> iter 6000, loss: 7.586587
 >> iter 7000, loss: 7.553662
 >> iter 8000, loss: 7.526680
 >> iter 9000, loss: 7.529185
 >> iter 10000, loss: 7.521280
   Number of active neurons: 8
 >> iter 11000, loss: 7.529441
 >> iter 12000, loss: 7.517653
 >> iter 13000, loss: 7.525450
 >> iter 14000, loss: 7.512864
 >> iter 15000, loss: 7.519593
 >> iter 16000, loss: 7.506411
 >> iter 17000, loss: 7.525801
 >> iter 18000, loss: 7.511225
 >> iter 19000, loss: 7.520157
 >> iter 20000, loss: 7.527152
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 21000, loss: 7.527110
 >> iter 22000, loss: 7.507703
 >> iter 23000, loss: 7.516138
 >> iter 24000, loss: 7.505051
 >> iter 25000, loss: 7.572782
   Number of active neurons: 7
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 26000, loss: 7.521468
 >> iter 27000, loss: 7.200830
 >> iter 28000, loss: 6.885953
 >> iter 29000, loss: 6.719024
 >> iter 30000, loss: 6.445951
   Number of active neurons: 10
 >> iter 31000, loss: 6.037245
 >> iter 32000, loss: 5.739545
 >> iter 33000, loss: 5.589664
 >> iter 34000, loss: 5.490638
 >> iter 35000, loss: 5.452149
 >> iter 36000, loss: 5.421766
 >> iter 37000, loss: 5.398318
 >> iter 38000, loss: 5.313977
 >> iter 39000, loss: 5.072518
 >> iter 40000, loss: 4.857083
   Number of active neurons: 10
 >> iter 41000, loss: 4.977600
 >> iter 42000, loss: 3.019009
 >> iter 43000, loss: 1.269929
 >> iter 44000, loss: 0.591384
 >> iter 45000, loss: 0.268676
 >> iter 46000, loss: 0.146780
 >> iter 47000, loss: 0.086179
 >> iter 48000, loss: 0.107027
 >> iter 49000, loss: 0.183034
 >> iter 50000, loss: 0.077229
   Number of active neurons: 10
 >> iter 51000, loss: 0.256095
 >> iter 52000, loss: 0.177836
 >> iter 53000, loss: 0.076011
 >> iter 54000, loss: 0.052253
 >> iter 55000, loss: 0.052698
 >> iter 56000, loss: 0.059946
 >> iter 57000, loss: 0.088900
 >> iter 58000, loss: 0.043533
 >> iter 59000, loss: 0.036231
 >> iter 60000, loss: 0.020013
   Number of active neurons: 10
 >> iter 61000, loss: 0.049351
 >> iter 62000, loss: 0.066065
 >> iter 63000, loss: 0.079195
 >> iter 64000, loss: 0.047698
 >> iter 65000, loss: 0.036090
 >> iter 66000, loss: 0.024780
 >> iter 67000, loss: 0.013036
 >> iter 68000, loss: 0.051803
 >> iter 69000, loss: 0.119469
 >> iter 70000, loss: 0.049469
   Number of active neurons: 10
 >> iter 71000, loss: 0.022427
 >> iter 72000, loss: 0.023225
 >> iter 73000, loss: 0.027512
 >> iter 74000, loss: 0.013503
 >> iter 75000, loss: 0.012176
 >> iter 76000, loss: 0.065997
 >> iter 77000, loss: 0.027941
 >> iter 78000, loss: 0.013232
 >> iter 79000, loss: 0.008384
 >> iter 80000, loss: 0.172921
   Number of active neurons: 10
 >> iter 81000, loss: 0.067360
 >> iter 82000, loss: 0.027695
 >> iter 83000, loss: 0.012709
 >> iter 84000, loss: 0.007082
 >> iter 85000, loss: 0.005103
 >> iter 86000, loss: 0.004098
 >> iter 87000, loss: 0.003552
 >> iter 88000, loss: 0.037481
 >> iter 89000, loss: 0.015981
 >> iter 90000, loss: 0.019550
   Number of active neurons: 10
 >> iter 91000, loss: 0.009473
 >> iter 92000, loss: 0.209038
 >> iter 93000, loss: 0.080603
 >> iter 94000, loss: 0.032313
 >> iter 95000, loss: 0.014670
 >> iter 96000, loss: 0.007829
 >> iter 97000, loss: 0.005300
 >> iter 98000, loss: 0.003962
 >> iter 99000, loss: 0.003418
 >> iter 100000, loss: 0.003101
   Number of active neurons: 10
 >> iter 101000, loss: 0.002886
 >> iter 102000, loss: 0.003034
 >> iter 103000, loss: 0.003006
 >> iter 104000, loss: 0.041530
 >> iter 105000, loss: 0.017248
 >> iter 106000, loss: 0.023790
 >> iter 107000, loss: 0.010626
 >> iter 108000, loss: 0.232238
 >> iter 109000, loss: 0.159014
 >> iter 110000, loss: 0.062105
   Number of active neurons: 10
 >> iter 111000, loss: 0.062651
 >> iter 112000, loss: 0.026056
 >> iter 113000, loss: 0.012495
 >> iter 114000, loss: 0.007035
 >> iter 115000, loss: 0.004961
 >> iter 116000, loss: 0.004427
 >> iter 117000, loss: 0.036488
 >> iter 118000, loss: 0.032947
 >> iter 119000, loss: 0.014500
 >> iter 120000, loss: 0.007398
   Number of active neurons: 10
 >> iter 121000, loss: 0.005440
 >> iter 122000, loss: 0.003951
 >> iter 123000, loss: 0.024849
 >> iter 124000, loss: 0.011599
 >> iter 125000, loss: 0.025162
 >> iter 126000, loss: 0.011776
 >> iter 127000, loss: 0.006488
 >> iter 128000, loss: 0.004187
 >> iter 129000, loss: 0.003459
 >> iter 130000, loss: 0.003693
   Number of active neurons: 10
 >> iter 131000, loss: 0.002956
 >> iter 132000, loss: 0.002618
 >> iter 133000, loss: 0.002435
 >> iter 134000, loss: 0.002426
 >> iter 135000, loss: 0.002294
 >> iter 136000, loss: 0.002155
 >> iter 137000, loss: 0.002041
 >> iter 138000, loss: 0.002232
 >> iter 139000, loss: 0.002068
 >> iter 140000, loss: 0.001961
   Number of active neurons: 10
 >> iter 141000, loss: 0.001823
 >> iter 142000, loss: 0.001923
 >> iter 143000, loss: 0.001803
 >> iter 144000, loss: 0.001726
 >> iter 145000, loss: 0.001784
 >> iter 146000, loss: 0.001671
 >> iter 147000, loss: 0.001676
 >> iter 148000, loss: 0.002000
 >> iter 149000, loss: 0.143659
 >> iter 150000, loss: 0.067973
   Number of active neurons: 10
 >> iter 151000, loss: 0.026633
 >> iter 152000, loss: 0.011107
 >> iter 153000, loss: 0.007080
 >> iter 154000, loss: 0.003812
 >> iter 155000, loss: 0.003387
 >> iter 156000, loss: 0.019350
 >> iter 157000, loss: 0.008269
 >> iter 158000, loss: 0.008329
 >> iter 159000, loss: 0.004195
 >> iter 160000, loss: 0.002628
   Number of active neurons: 10
 >> iter 161000, loss: 0.001959
 >> iter 162000, loss: 0.002563
 >> iter 163000, loss: 0.001974
 >> iter 164000, loss: 0.001951
 >> iter 165000, loss: 0.001639
 >> iter 166000, loss: 0.001726
 >> iter 167000, loss: 0.001540
 >> iter 168000, loss: 0.001484
 >> iter 169000, loss: 0.001480
 >> iter 170000, loss: 0.001380
   Number of active neurons: 10
 >> iter 171000, loss: 0.001754
 >> iter 172000, loss: 0.001432
 >> iter 173000, loss: 0.001317
 >> iter 174000, loss: 0.001266
 >> iter 175000, loss: 0.001224
 >> iter 176000, loss: 0.001194
 >> iter 177000, loss: 0.001156
 >> iter 178000, loss: 0.007170
 >> iter 179000, loss: 0.015171
 >> iter 180000, loss: 0.024103
   Number of active neurons: 10
 >> iter 181000, loss: 0.009663
 >> iter 182000, loss: 0.004386
 >> iter 183000, loss: 0.023216
 >> iter 184000, loss: 0.009414
 >> iter 185000, loss: 0.006889
 >> iter 186000, loss: 0.003496
 >> iter 187000, loss: 0.132296
 >> iter 188000, loss: 0.049768
 >> iter 189000, loss: 0.019496
 >> iter 190000, loss: 0.008645
   Number of active neurons: 10
 >> iter 191000, loss: 0.010561
 >> iter 192000, loss: 0.004839
 >> iter 193000, loss: 0.041274
 >> iter 194000, loss: 0.016468
 >> iter 195000, loss: 0.007219
 >> iter 196000, loss: 0.003741
 >> iter 197000, loss: 0.009696
 >> iter 198000, loss: 0.004413
 >> iter 199000, loss: 0.002445
 >> iter 200000, loss: 0.002010
   Number of active neurons: 10
 >> iter 201000, loss: 0.001586
 >> iter 202000, loss: 0.001417
 >> iter 203000, loss: 0.001264
 >> iter 204000, loss: 0.001207
 >> iter 205000, loss: 0.001603
 >> iter 206000, loss: 0.001328
 >> iter 207000, loss: 0.001269
 >> iter 208000, loss: 0.001160
 >> iter 209000, loss: 0.031231
 >> iter 210000, loss: 0.012838
   Number of active neurons: 10
 >> iter 211000, loss: 0.005658
 >> iter 212000, loss: 0.003216
 >> iter 213000, loss: 0.001948
 >> iter 214000, loss: 0.009801
 >> iter 215000, loss: 0.004600
 >> iter 216000, loss: 0.002417
 >> iter 217000, loss: 0.001586
 >> iter 218000, loss: 0.001642
 >> iter 219000, loss: 0.001392
 >> iter 220000, loss: 0.001687
   Number of active neurons: 10
 >> iter 221000, loss: 0.003037
 >> iter 222000, loss: 0.002657
 >> iter 223000, loss: 0.001633
 >> iter 224000, loss: 0.067774
 >> iter 225000, loss: 0.025827
 >> iter 226000, loss: 0.010308
 >> iter 227000, loss: 0.004524
 >> iter 228000, loss: 0.002544
 >> iter 229000, loss: 0.001719
 >> iter 230000, loss: 0.001323
   Number of active neurons: 10
 >> iter 231000, loss: 0.001167
 >> iter 232000, loss: 0.001063
 >> iter 233000, loss: 0.001020
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.834140
 >> iter 2000, loss: 10.651931
 >> iter 3000, loss: 8.732267
 >> iter 4000, loss: 8.000761
 >> iter 5000, loss: 7.762638
 >> iter 6000, loss: 7.648593
 >> iter 7000, loss: 7.614252
 >> iter 8000, loss: 7.587761
 >> iter 9000, loss: 7.579646
 >> iter 10000, loss: 7.564309
   Number of active neurons: 9
 >> iter 11000, loss: 7.572085
 >> iter 12000, loss: 7.552760
 >> iter 13000, loss: 7.620641
 >> iter 14000, loss: 7.574925
 >> iter 15000, loss: 7.506093
 >> iter 16000, loss: 7.079567
 >> iter 17000, loss: 6.646919
 >> iter 18000, loss: 6.192516
 >> iter 19000, loss: 5.833575
 >> iter 20000, loss: 5.546106
   Number of active neurons: 10
 >> iter 21000, loss: 5.444646
 >> iter 22000, loss: 5.018255
 >> iter 23000, loss: 2.265854
 >> iter 24000, loss: 1.059942
 >> iter 25000, loss: 0.486287
 >> iter 26000, loss: 0.250480
 >> iter 27000, loss: 0.110592
 >> iter 28000, loss: 0.053484
 >> iter 29000, loss: 0.054066
 >> iter 30000, loss: 0.057675
   Number of active neurons: 10
 >> iter 31000, loss: 0.051946
 >> iter 32000, loss: 0.041016
 >> iter 33000, loss: 0.056453
 >> iter 34000, loss: 0.071603
 >> iter 35000, loss: 0.094484
 >> iter 36000, loss: 0.041766
 >> iter 37000, loss: 0.022575
 >> iter 38000, loss: 0.013798
 >> iter 39000, loss: 0.009204
 >> iter 40000, loss: 0.006840
   Number of active neurons: 10
 >> iter 41000, loss: 0.006033
 >> iter 42000, loss: 0.040218
 >> iter 43000, loss: 0.018483
 >> iter 44000, loss: 0.009770
 >> iter 45000, loss: 0.006550
 >> iter 46000, loss: 0.004824
 >> iter 47000, loss: 0.004161
 >> iter 48000, loss: 0.003824
 >> iter 49000, loss: 0.003743
 >> iter 50000, loss: 0.003623
   Number of active neurons: 10
 >> iter 51000, loss: 0.015005
 >> iter 52000, loss: 0.033577
 >> iter 53000, loss: 0.014574
 >> iter 54000, loss: 0.007574
 >> iter 55000, loss: 0.013278
 >> iter 56000, loss: 0.022866
 >> iter 57000, loss: 0.032935
 >> iter 58000, loss: 0.014062
 >> iter 59000, loss: 0.007052
 >> iter 60000, loss: 0.004297
   Number of active neurons: 10
 >> iter 61000, loss: 0.061308
 >> iter 62000, loss: 0.024883
 >> iter 63000, loss: 0.010882
 >> iter 64000, loss: 0.005650
 >> iter 65000, loss: 0.003652
 >> iter 66000, loss: 0.002785
 >> iter 67000, loss: 0.002582
 >> iter 68000, loss: 0.015278
 >> iter 69000, loss: 0.008043
 >> iter 70000, loss: 0.004692
   Number of active neurons: 10
 >> iter 71000, loss: 0.003141
 >> iter 72000, loss: 0.002446
 >> iter 73000, loss: 0.002172
 >> iter 74000, loss: 0.001970
 >> iter 75000, loss: 0.002051
 >> iter 76000, loss: 0.001935
 >> iter 77000, loss: 0.001786
 >> iter 78000, loss: 0.001675
 >> iter 79000, loss: 0.001628
 >> iter 80000, loss: 0.001621
   Number of active neurons: 10
 >> iter 81000, loss: 0.001640
 >> iter 82000, loss: 0.001544
 >> iter 83000, loss: 0.001533
 >> iter 84000, loss: 0.002176
 >> iter 85000, loss: 0.028537
 >> iter 86000, loss: 0.011530
 >> iter 87000, loss: 0.005218
 >> iter 88000, loss: 0.002859
 >> iter 89000, loss: 0.001943
 >> iter 90000, loss: 0.001677
   Number of active neurons: 10
 >> iter 91000, loss: 0.001467
 >> iter 92000, loss: 0.001342
 >> iter 93000, loss: 0.001534
 >> iter 94000, loss: 0.001322
 >> iter 95000, loss: 0.049045
 >> iter 96000, loss: 0.019231
 >> iter 97000, loss: 0.007937
 >> iter 98000, loss: 0.003719
 >> iter 99000, loss: 0.002189
 >> iter 100000, loss: 0.002040
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.809885
 >> iter 2000, loss: 10.752406
 >> iter 3000, loss: 8.792365
 >> iter 4000, loss: 8.040861
 >> iter 5000, loss: 7.797523
 >> iter 6000, loss: 7.659194
 >> iter 7000, loss: 7.476002
 >> iter 8000, loss: 7.284636
 >> iter 9000, loss: 6.996237
 >> iter 10000, loss: 6.830463
   Number of active neurons: 10
 >> iter 11000, loss: 6.742327
 >> iter 12000, loss: 6.713134
 >> iter 13000, loss: 6.664696
 >> iter 14000, loss: 6.579302
 >> iter 15000, loss: 6.354072
 >> iter 16000, loss: 5.896815
 >> iter 17000, loss: 5.074238
 >> iter 18000, loss: 2.209124
 >> iter 19000, loss: 0.885495
 >> iter 20000, loss: 0.418532
   Number of active neurons: 10
 >> iter 21000, loss: 0.314274
 >> iter 22000, loss: 0.153772
 >> iter 23000, loss: 0.177525
 >> iter 24000, loss: 0.208842
 >> iter 25000, loss: 0.114766
 >> iter 26000, loss: 0.077465
 >> iter 27000, loss: 0.039570
 >> iter 28000, loss: 0.028835
 >> iter 29000, loss: 0.037188
 >> iter 30000, loss: 0.074319
   Number of active neurons: 10
 >> iter 31000, loss: 0.035228
 >> iter 32000, loss: 0.021442
 >> iter 33000, loss: 0.014446
 >> iter 34000, loss: 0.011265
 >> iter 35000, loss: 0.013565
 >> iter 36000, loss: 0.010657
 >> iter 37000, loss: 0.018388
 >> iter 38000, loss: 0.023457
 >> iter 39000, loss: 0.022569
 >> iter 40000, loss: 0.048369
   Number of active neurons: 10
 >> iter 41000, loss: 0.022349
 >> iter 42000, loss: 0.012188
 >> iter 43000, loss: 0.034376
 >> iter 44000, loss: 0.015984
 >> iter 45000, loss: 0.009077
 >> iter 46000, loss: 0.050934
 >> iter 47000, loss: 0.021999
 >> iter 48000, loss: 0.011632
 >> iter 49000, loss: 0.079969
 >> iter 50000, loss: 0.035220
   Number of active neurons: 10
 >> iter 51000, loss: 0.016182
 >> iter 52000, loss: 0.008392
 >> iter 53000, loss: 0.019904
 >> iter 54000, loss: 0.026582
 >> iter 55000, loss: 0.023196
 >> iter 56000, loss: 0.021364
 >> iter 57000, loss: 0.010974
 >> iter 58000, loss: 0.134718
 >> iter 59000, loss: 0.052940
 >> iter 60000, loss: 0.022154
   Number of active neurons: 10
 >> iter 61000, loss: 0.010457
 >> iter 62000, loss: 0.006121
 >> iter 63000, loss: 0.004942
 >> iter 64000, loss: 0.003768
 >> iter 65000, loss: 0.004099
 >> iter 66000, loss: 0.003532
 >> iter 67000, loss: 0.003108
 >> iter 68000, loss: 0.003038
 >> iter 69000, loss: 0.002683
 >> iter 70000, loss: 0.002577
   Number of active neurons: 10
 >> iter 71000, loss: 0.005105
 >> iter 72000, loss: 0.003458
 >> iter 73000, loss: 0.002713
 >> iter 74000, loss: 0.002835
 >> iter 75000, loss: 0.003016
 >> iter 76000, loss: 0.002517
 >> iter 77000, loss: 0.002264
 >> iter 78000, loss: 0.002206
 >> iter 79000, loss: 0.001993
 >> iter 80000, loss: 0.001853
   Number of active neurons: 10
 >> iter 81000, loss: 0.002029
 >> iter 82000, loss: 0.001939
 >> iter 83000, loss: 0.001759
 >> iter 84000, loss: 0.001732
 >> iter 85000, loss: 0.053449
 >> iter 86000, loss: 0.021063
 >> iter 87000, loss: 0.009114
 >> iter 88000, loss: 0.004958
 >> iter 89000, loss: 0.003043
 >> iter 90000, loss: 0.002279
   Number of active neurons: 10
 >> iter 91000, loss: 0.001878
 >> iter 92000, loss: 0.001703
 >> iter 93000, loss: 0.001637
 >> iter 94000, loss: 0.001610
 >> iter 95000, loss: 0.001554
 >> iter 96000, loss: 0.001592
 >> iter 97000, loss: 0.001478
 >> iter 98000, loss: 0.001433
 >> iter 99000, loss: 0.001350
 >> iter 100000, loss: 0.001553
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.842626
 >> iter 2000, loss: 10.696342
 >> iter 3000, loss: 8.764931
 >> iter 4000, loss: 8.082418
 >> iter 5000, loss: 7.835168
 >> iter 6000, loss: 7.673933
 >> iter 7000, loss: 7.484771
 >> iter 8000, loss: 7.192464
 >> iter 9000, loss: 6.822879
 >> iter 10000, loss: 6.371963
   Number of active neurons: 10
 >> iter 11000, loss: 5.944392
 >> iter 12000, loss: 5.532697
 >> iter 13000, loss: 3.580145
 >> iter 14000, loss: 1.421052
 >> iter 15000, loss: 0.632943
 >> iter 16000, loss: 0.286534
 >> iter 17000, loss: 0.121307
 >> iter 18000, loss: 0.163517
 >> iter 19000, loss: 0.073522
 >> iter 20000, loss: 0.103932
   Number of active neurons: 10
 >> iter 21000, loss: 0.070137
 >> iter 22000, loss: 0.033321
 >> iter 23000, loss: 0.030586
 >> iter 24000, loss: 0.020031
 >> iter 25000, loss: 0.014547
 >> iter 26000, loss: 0.009783
 >> iter 27000, loss: 0.007947
 >> iter 28000, loss: 0.077751
 >> iter 29000, loss: 0.032631
 >> iter 30000, loss: 0.017689
   Number of active neurons: 10
 >> iter 31000, loss: 0.044171
 >> iter 32000, loss: 0.019982
 >> iter 33000, loss: 0.010320
 >> iter 34000, loss: 0.006650
 >> iter 35000, loss: 0.005084
 >> iter 36000, loss: 0.004345
 >> iter 37000, loss: 0.003806
 >> iter 38000, loss: 0.003420
 >> iter 39000, loss: 0.003307
 >> iter 40000, loss: 0.062762
   Number of active neurons: 10
 >> iter 41000, loss: 0.160972
 >> iter 42000, loss: 0.062320
 >> iter 43000, loss: 0.025390
 >> iter 44000, loss: 0.011574
 >> iter 45000, loss: 0.006325
 >> iter 46000, loss: 0.004808
 >> iter 47000, loss: 0.003652
 >> iter 48000, loss: 0.003423
 >> iter 49000, loss: 0.002962
 >> iter 50000, loss: 0.002696
   Number of active neurons: 10
 >> iter 51000, loss: 0.002490
 >> iter 52000, loss: 0.002522
 >> iter 53000, loss: 0.002307
 >> iter 54000, loss: 0.002525
 >> iter 55000, loss: 0.078913
 >> iter 56000, loss: 0.030728
 >> iter 57000, loss: 0.089618
 >> iter 58000, loss: 0.036057
 >> iter 59000, loss: 0.015161
 >> iter 60000, loss: 0.021602
   Number of active neurons: 10
 >> iter 61000, loss: 0.009807
 >> iter 62000, loss: 0.005316
 >> iter 63000, loss: 0.003520
 >> iter 64000, loss: 0.024429
 >> iter 65000, loss: 0.010624
 >> iter 66000, loss: 0.012514
 >> iter 67000, loss: 0.006195
 >> iter 68000, loss: 0.003780
 >> iter 69000, loss: 0.004446
 >> iter 70000, loss: 0.002997
   Number of active neurons: 10
 >> iter 71000, loss: 0.002392
 >> iter 72000, loss: 0.002057
 >> iter 73000, loss: 0.001931
 >> iter 74000, loss: 0.001824
 >> iter 75000, loss: 0.002134
 >> iter 76000, loss: 0.001836
 >> iter 77000, loss: 0.001802
 >> iter 78000, loss: 0.001709
 >> iter 79000, loss: 0.001623
 >> iter 80000, loss: 0.001613
   Number of active neurons: 10
 >> iter 81000, loss: 0.001931
 >> iter 82000, loss: 0.002082
 >> iter 83000, loss: 0.001925
 >> iter 84000, loss: 0.001615
 >> iter 85000, loss: 0.001480
 >> iter 86000, loss: 0.001365
 >> iter 87000, loss: 0.001395
 >> iter 88000, loss: 0.001452
 >> iter 89000, loss: 0.001388
 >> iter 90000, loss: 0.001363
   Number of active neurons: 10
 >> iter 91000, loss: 0.001259
 >> iter 92000, loss: 0.001213
 >> iter 93000, loss: 0.001169
 >> iter 94000, loss: 0.001125
 >> iter 95000, loss: 0.001320
 >> iter 96000, loss: 0.001170
 >> iter 97000, loss: 0.001079
 >> iter 98000, loss: 0.001065
 >> iter 99000, loss: 0.001047
 >> iter 100000, loss: 0.001032
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.887412
 >> iter 2000, loss: 10.680926
 >> iter 3000, loss: 8.763710
 >> iter 4000, loss: 8.010252
 >> iter 5000, loss: 7.739673
 >> iter 6000, loss: 7.628916
 >> iter 7000, loss: 7.588402
 >> iter 8000, loss: 7.622850
 >> iter 9000, loss: 7.590150
 >> iter 10000, loss: 7.561901
   Number of active neurons: 10
 >> iter 11000, loss: 7.552253
 >> iter 12000, loss: 7.355085
 >> iter 13000, loss: 7.048921
 >> iter 14000, loss: 6.577487
 >> iter 15000, loss: 6.042222
 >> iter 16000, loss: 5.562183
 >> iter 17000, loss: 5.129496
 >> iter 18000, loss: 2.594251
 >> iter 19000, loss: 1.080943
 >> iter 20000, loss: 0.425619
   Number of active neurons: 10
 >> iter 21000, loss: 0.179770
 >> iter 22000, loss: 0.202602
 >> iter 23000, loss: 0.162295
 >> iter 24000, loss: 0.100816
 >> iter 25000, loss: 0.055473
 >> iter 26000, loss: 0.037291
 >> iter 27000, loss: 0.021693
 >> iter 28000, loss: 0.015189
 >> iter 29000, loss: 0.011899
 >> iter 30000, loss: 0.028918
   Number of active neurons: 10
 >> iter 31000, loss: 0.020252
 >> iter 32000, loss: 0.012962
 >> iter 33000, loss: 0.009041
 >> iter 34000, loss: 0.044403
 >> iter 35000, loss: 0.020766
 >> iter 36000, loss: 0.011939
 >> iter 37000, loss: 0.008013
 >> iter 38000, loss: 0.007033
 >> iter 39000, loss: 0.008339
 >> iter 40000, loss: 0.151090
   Number of active neurons: 10
 >> iter 41000, loss: 0.059739
 >> iter 42000, loss: 0.025643
 >> iter 43000, loss: 0.012556
 >> iter 44000, loss: 0.034120
 >> iter 45000, loss: 0.015987
 >> iter 46000, loss: 0.008896
 >> iter 47000, loss: 0.006142
 >> iter 48000, loss: 0.005181
 >> iter 49000, loss: 0.038737
 >> iter 50000, loss: 0.017215
   Number of active neurons: 10
 >> iter 51000, loss: 0.008823
 >> iter 52000, loss: 0.006757
 >> iter 53000, loss: 0.022123
 >> iter 54000, loss: 0.012661
 >> iter 55000, loss: 0.012740
 >> iter 56000, loss: 0.007171
 >> iter 57000, loss: 0.013039
 >> iter 58000, loss: 0.050004
 >> iter 59000, loss: 0.020931
 >> iter 60000, loss: 0.009951
   Number of active neurons: 10
 >> iter 61000, loss: 0.009787
 >> iter 62000, loss: 0.005553
 >> iter 63000, loss: 0.027286
 >> iter 64000, loss: 0.011932
 >> iter 65000, loss: 0.006126
 >> iter 66000, loss: 0.003968
 >> iter 67000, loss: 0.003241
 >> iter 68000, loss: 0.002751
 >> iter 69000, loss: 0.036878
 >> iter 70000, loss: 0.039708
   Number of active neurons: 10
 >> iter 71000, loss: 0.016278
 >> iter 72000, loss: 0.008524
 >> iter 73000, loss: 0.004616
 >> iter 74000, loss: 0.003257
 >> iter 75000, loss: 0.004098
 >> iter 76000, loss: 0.005704
 >> iter 77000, loss: 0.004053
 >> iter 78000, loss: 0.004243
 >> iter 79000, loss: 0.002935
 >> iter 80000, loss: 0.002542
   Number of active neurons: 10
 >> iter 81000, loss: 0.002317
 >> iter 82000, loss: 0.002144
 >> iter 83000, loss: 0.002074
 >> iter 84000, loss: 0.001949
 >> iter 85000, loss: 0.001868
 >> iter 86000, loss: 0.001868
 >> iter 87000, loss: 0.001766
 >> iter 88000, loss: 0.001826
 >> iter 89000, loss: 0.002098
 >> iter 90000, loss: 0.002112
   Number of active neurons: 10
 >> iter 91000, loss: 0.001804
 >> iter 92000, loss: 0.001774
 >> iter 93000, loss: 0.001674
 >> iter 94000, loss: 0.001569
 >> iter 95000, loss: 0.001592
 >> iter 96000, loss: 0.001576
 >> iter 97000, loss: 0.001507
 >> iter 98000, loss: 0.001501
 >> iter 99000, loss: 0.001550
 >> iter 100000, loss: 0.001458
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.808635
 >> iter 2000, loss: 10.666588
 >> iter 3000, loss: 8.766050
 >> iter 4000, loss: 8.019607
 >> iter 5000, loss: 7.750798
 >> iter 6000, loss: 7.663266
 >> iter 7000, loss: 7.623383
 >> iter 8000, loss: 7.584226
 >> iter 9000, loss: 7.474979
 >> iter 10000, loss: 7.289102
   Number of active neurons: 10
 >> iter 11000, loss: 6.845123
 >> iter 12000, loss: 6.387494
 >> iter 13000, loss: 6.077538
 >> iter 14000, loss: 5.817113
 >> iter 15000, loss: 5.587066
 >> iter 16000, loss: 5.261382
 >> iter 17000, loss: 4.378469
 >> iter 18000, loss: 3.395922
 >> iter 19000, loss: 2.962209
 >> iter 20000, loss: 1.362744
   Number of active neurons: 10
 >> iter 21000, loss: 0.568283
 >> iter 22000, loss: 0.290851
 >> iter 23000, loss: 0.230337
 >> iter 24000, loss: 0.131505
 >> iter 25000, loss: 0.064543
 >> iter 26000, loss: 0.038821
 >> iter 27000, loss: 0.024679
 >> iter 28000, loss: 0.017675
 >> iter 29000, loss: 0.058995
 >> iter 30000, loss: 0.044521
   Number of active neurons: 10
 >> iter 31000, loss: 0.022827
 >> iter 32000, loss: 0.014344
 >> iter 33000, loss: 0.045109
 >> iter 34000, loss: 0.069835
 >> iter 35000, loss: 0.036483
 >> iter 36000, loss: 0.019190
 >> iter 37000, loss: 0.012136
 >> iter 38000, loss: 0.009239
 >> iter 39000, loss: 0.057212
 >> iter 40000, loss: 0.036889
   Number of active neurons: 10
 >> iter 41000, loss: 0.017659
 >> iter 42000, loss: 0.011584
 >> iter 43000, loss: 0.009252
 >> iter 44000, loss: 0.006750
 >> iter 45000, loss: 0.005739
 >> iter 46000, loss: 0.005071
 >> iter 47000, loss: 0.004793
 >> iter 48000, loss: 0.004504
 >> iter 49000, loss: 0.005309
 >> iter 50000, loss: 0.004552
   Number of active neurons: 10
 >> iter 51000, loss: 0.004151
 >> iter 52000, loss: 0.003896
 >> iter 53000, loss: 0.003672
 >> iter 54000, loss: 0.003573
 >> iter 55000, loss: 0.003762
 >> iter 56000, loss: 0.003525
 >> iter 57000, loss: 0.003273
 >> iter 58000, loss: 0.003118
 >> iter 59000, loss: 0.002963
 >> iter 60000, loss: 0.056928
   Number of active neurons: 10
 >> iter 61000, loss: 0.042906
 >> iter 62000, loss: 0.106387
 >> iter 63000, loss: 0.068290
 >> iter 64000, loss: 0.027727
 >> iter 65000, loss: 0.012788
 >> iter 66000, loss: 0.006964
 >> iter 67000, loss: 0.004768
 >> iter 68000, loss: 0.003837
 >> iter 69000, loss: 0.003359
 >> iter 70000, loss: 0.003389
   Number of active neurons: 10
 >> iter 71000, loss: 0.003082
 >> iter 72000, loss: 0.002934
 >> iter 73000, loss: 0.040665
 >> iter 74000, loss: 0.016800
 >> iter 75000, loss: 0.007940
 >> iter 76000, loss: 0.004617
 >> iter 77000, loss: 0.003355
 >> iter 78000, loss: 0.003249
 >> iter 79000, loss: 0.002715
 >> iter 80000, loss: 0.002830
   Number of active neurons: 10
 >> iter 81000, loss: 0.002586
 >> iter 82000, loss: 0.002370
 >> iter 83000, loss: 0.002245
 >> iter 84000, loss: 0.002201
 >> iter 85000, loss: 0.002146
 >> iter 86000, loss: 0.002069
 >> iter 87000, loss: 0.002023
 >> iter 88000, loss: 0.083904
 >> iter 89000, loss: 0.032400
 >> iter 90000, loss: 0.013368
   Number of active neurons: 10
 >> iter 91000, loss: 0.006319
 >> iter 92000, loss: 0.003864
 >> iter 93000, loss: 0.029952
 >> iter 94000, loss: 0.012334
 >> iter 95000, loss: 0.005838
 >> iter 96000, loss: 0.003391
 >> iter 97000, loss: 0.002475
 >> iter 98000, loss: 0.002095
 >> iter 99000, loss: 0.001948
 >> iter 100000, loss: 0.001866
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

