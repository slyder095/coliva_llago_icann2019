 > Problema: tomita2nueva
 > Args:
   - Hidden size: 6
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.559598
 >> iter 2000, loss: 4.422112
 >> iter 3000, loss: 1.689544
 >> iter 4000, loss: 0.709039
 >> iter 5000, loss: 0.311856
 >> iter 6000, loss: 0.165226
 >> iter 7000, loss: 0.102700
 >> iter 8000, loss: 0.069977
 >> iter 9000, loss: 0.064257
 >> iter 10000, loss: 0.055932
   Number of active neurons: 4
 >> iter 11000, loss: 0.045495
 >> iter 12000, loss: 0.071602
 >> iter 13000, loss: 0.054864
 >> iter 14000, loss: 0.051326
 >> iter 15000, loss: 0.063960
 >> iter 16000, loss: 0.047801
 >> iter 17000, loss: 0.089854
 >> iter 18000, loss: 0.051815
 >> iter 19000, loss: 0.058965
 >> iter 20000, loss: 0.046507
   Number of active neurons: 4
 >> iter 21000, loss: 0.061216
 >> iter 22000, loss: 0.062505
 >> iter 23000, loss: 0.053160
 >> iter 24000, loss: 0.039517
 >> iter 25000, loss: 0.040160
 >> iter 26000, loss: 0.040704
 >> iter 27000, loss: 0.038893
 >> iter 28000, loss: 0.054262
 >> iter 29000, loss: 0.056429
 >> iter 30000, loss: 0.049395
   Number of active neurons: 3
 >> iter 31000, loss: 0.038656
 >> iter 32000, loss: 0.046629
 >> iter 33000, loss: 0.046018
 >> iter 34000, loss: 0.049984
 >> iter 35000, loss: 0.036084
 >> iter 36000, loss: 0.043518
 >> iter 37000, loss: 0.061275
 >> iter 38000, loss: 0.057859
 >> iter 39000, loss: 0.037819
 >> iter 40000, loss: 0.043010
   Number of active neurons: 2
 >> iter 41000, loss: 0.049893
 >> iter 42000, loss: 0.053861
 >> iter 43000, loss: 0.051397
 >> iter 44000, loss: 0.046839
 >> iter 45000, loss: 0.040357
 >> iter 46000, loss: 0.040929
 >> iter 47000, loss: 0.031074
 >> iter 48000, loss: 0.038912
 >> iter 49000, loss: 0.038073
 >> iter 50000, loss: 0.042730
   Number of active neurons: 2
 >> iter 51000, loss: 0.039278
 >> iter 52000, loss: 0.049189
 >> iter 53000, loss: 0.046100
 >> iter 54000, loss: 0.031971
 >> iter 55000, loss: 0.029752
 >> iter 56000, loss: 0.032141
 >> iter 57000, loss: 0.031201
 >> iter 58000, loss: 0.044855
 >> iter 59000, loss: 0.041246
 >> iter 60000, loss: 0.039033
   Number of active neurons: 2
 >> iter 61000, loss: 0.046272
 >> iter 62000, loss: 0.039482
 >> iter 63000, loss: 0.051077
 >> iter 64000, loss: 0.045832
 >> iter 65000, loss: 0.046988
 >> iter 66000, loss: 0.061523
 >> iter 67000, loss: 0.059221
 >> iter 68000, loss: 0.047145
 >> iter 69000, loss: 0.037008
 >> iter 70000, loss: 0.030358
   Number of active neurons: 2
 >> iter 71000, loss: 0.049388
 >> iter 72000, loss: 0.038009
 >> iter 73000, loss: 0.057315
 >> iter 74000, loss: 0.052641
 >> iter 75000, loss: 0.052967
 >> iter 76000, loss: 0.046278
 >> iter 77000, loss: 0.042756
 >> iter 78000, loss: 0.037662
 >> iter 79000, loss: 0.041968
 >> iter 80000, loss: 0.044193
   Number of active neurons: 2
 >> iter 81000, loss: 0.059875
 >> iter 82000, loss: 0.069824
 >> iter 83000, loss: 0.040629
 >> iter 84000, loss: 0.042212
 >> iter 85000, loss: 0.035598
 >> iter 86000, loss: 0.047394
 >> iter 87000, loss: 0.050735
 >> iter 88000, loss: 0.043143
 >> iter 89000, loss: 0.045639
 >> iter 90000, loss: 0.037994
   Number of active neurons: 2
 >> iter 91000, loss: 0.048362
 >> iter 92000, loss: 0.038773
 >> iter 93000, loss: 0.041285
 >> iter 94000, loss: 0.055937
 >> iter 95000, loss: 0.055700
 >> iter 96000, loss: 0.035398
 >> iter 97000, loss: 0.040471
 >> iter 98000, loss: 0.030176
 >> iter 99000, loss: 0.039150
 >> iter 100000, loss: 0.039725
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 11.346369
 >> iter 2000, loss: 4.378645
 >> iter 3000, loss: 1.693324
 >> iter 4000, loss: 0.705136
 >> iter 5000, loss: 0.313048
 >> iter 6000, loss: 0.166633
 >> iter 7000, loss: 0.094907
 >> iter 8000, loss: 0.081131
 >> iter 9000, loss: 0.064527
 >> iter 10000, loss: 0.080817
   Number of active neurons: 5
 >> iter 11000, loss: 0.078307
 >> iter 12000, loss: 0.065322
 >> iter 13000, loss: 0.066802
 >> iter 14000, loss: 0.053972
 >> iter 15000, loss: 0.042468
 >> iter 16000, loss: 0.032261
 >> iter 17000, loss: 0.057059
 >> iter 18000, loss: 0.062008
 >> iter 19000, loss: 0.077084
 >> iter 20000, loss: 0.068970
   Number of active neurons: 5
 >> iter 21000, loss: 0.069352
 >> iter 22000, loss: 0.056288
 >> iter 23000, loss: 0.068881
 >> iter 24000, loss: 0.054855
 >> iter 25000, loss: 0.068638
 >> iter 26000, loss: 0.067631
 >> iter 27000, loss: 0.057865
 >> iter 28000, loss: 0.056679
 >> iter 29000, loss: 0.059493
 >> iter 30000, loss: 0.050096
   Number of active neurons: 5
 >> iter 31000, loss: 0.076399
 >> iter 32000, loss: 0.064751
 >> iter 33000, loss: 0.072849
 >> iter 34000, loss: 0.050767
 >> iter 35000, loss: 0.045668
 >> iter 36000, loss: 0.043440
 >> iter 37000, loss: 0.036131
 >> iter 38000, loss: 0.045055
 >> iter 39000, loss: 0.056393
 >> iter 40000, loss: 0.054219
   Number of active neurons: 5
 >> iter 41000, loss: 0.050940
 >> iter 42000, loss: 0.065907
 >> iter 43000, loss: 0.052991
 >> iter 44000, loss: 0.042017
 >> iter 45000, loss: 0.064434
 >> iter 46000, loss: 0.043983
 >> iter 47000, loss: 0.040707
 >> iter 48000, loss: 0.046391
 >> iter 49000, loss: 0.035169
 >> iter 50000, loss: 0.042851
   Number of active neurons: 5
 >> iter 51000, loss: 0.061168
 >> iter 52000, loss: 0.058441
 >> iter 53000, loss: 0.055933
 >> iter 54000, loss: 0.040092
 >> iter 55000, loss: 0.049983
 >> iter 56000, loss: 0.052170
 >> iter 57000, loss: 0.048889
 >> iter 58000, loss: 0.059357
 >> iter 59000, loss: 0.039329
 >> iter 60000, loss: 0.043152
   Number of active neurons: 4
 >> iter 61000, loss: 0.036385
 >> iter 62000, loss: 0.056291
 >> iter 63000, loss: 0.043322
 >> iter 64000, loss: 0.048839
 >> iter 65000, loss: 0.037372
 >> iter 66000, loss: 0.040011
 >> iter 67000, loss: 0.048323
 >> iter 68000, loss: 0.042496
 >> iter 69000, loss: 0.064723
 >> iter 70000, loss: 0.049142
   Number of active neurons: 3
 >> iter 71000, loss: 0.054047
 >> iter 72000, loss: 0.046702
 >> iter 73000, loss: 0.046434
 >> iter 74000, loss: 0.046600
 >> iter 75000, loss: 0.057690
 >> iter 76000, loss: 0.040241
 >> iter 77000, loss: 0.046809
 >> iter 78000, loss: 0.041425
 >> iter 79000, loss: 0.034886
 >> iter 80000, loss: 0.059162
   Number of active neurons: 2
 >> iter 81000, loss: 0.054228
 >> iter 82000, loss: 0.053435
 >> iter 83000, loss: 0.054907
 >> iter 84000, loss: 0.071691
 >> iter 85000, loss: 0.051658
 >> iter 86000, loss: 0.054690
 >> iter 87000, loss: 0.042937
 >> iter 88000, loss: 0.049333
 >> iter 89000, loss: 0.034831
 >> iter 90000, loss: 0.038736
   Number of active neurons: 2
 >> iter 91000, loss: 0.031933
 >> iter 92000, loss: 0.048362
 >> iter 93000, loss: 0.039048
 >> iter 94000, loss: 0.050201
 >> iter 95000, loss: 0.046951
 >> iter 96000, loss: 0.029883
 >> iter 97000, loss: 0.035096
 >> iter 98000, loss: 0.032718
 >> iter 99000, loss: 0.046700
 >> iter 100000, loss: 0.042054
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.478900
 >> iter 2000, loss: 4.449738
 >> iter 3000, loss: 1.726877
 >> iter 4000, loss: 0.706206
 >> iter 5000, loss: 0.314481
 >> iter 6000, loss: 0.149237
 >> iter 7000, loss: 0.095323
 >> iter 8000, loss: 0.072927
 >> iter 9000, loss: 0.087970
 >> iter 10000, loss: 0.065838
   Number of active neurons: 4
 >> iter 11000, loss: 0.050064
 >> iter 12000, loss: 0.060251
 >> iter 13000, loss: 0.062531
 >> iter 14000, loss: 0.062255
 >> iter 15000, loss: 0.056247
 >> iter 16000, loss: 0.053199
 >> iter 17000, loss: 0.046125
 >> iter 18000, loss: 0.040101
 >> iter 19000, loss: 0.045673
 >> iter 20000, loss: 0.057606
   Number of active neurons: 4
 >> iter 21000, loss: 0.047695
 >> iter 22000, loss: 0.053669
 >> iter 23000, loss: 0.046152
 >> iter 24000, loss: 0.063251
 >> iter 25000, loss: 0.058921
 >> iter 26000, loss: 0.047186
 >> iter 27000, loss: 0.044941
 >> iter 28000, loss: 0.058466
 >> iter 29000, loss: 0.053037
 >> iter 30000, loss: 0.049954
   Number of active neurons: 4
 >> iter 31000, loss: 0.047217
 >> iter 32000, loss: 0.051377
 >> iter 33000, loss: 0.053319
 >> iter 34000, loss: 0.044019
 >> iter 35000, loss: 0.033622
 >> iter 36000, loss: 0.052189
 >> iter 37000, loss: 0.044779
 >> iter 38000, loss: 0.044252
 >> iter 39000, loss: 0.058188
 >> iter 40000, loss: 0.058614
   Number of active neurons: 4
 >> iter 41000, loss: 0.049772
 >> iter 42000, loss: 0.038748
 >> iter 43000, loss: 0.044112
 >> iter 44000, loss: 0.041251
 >> iter 45000, loss: 0.038614
 >> iter 46000, loss: 0.040966
 >> iter 47000, loss: 0.059851
 >> iter 48000, loss: 0.067509
 >> iter 49000, loss: 0.048454
 >> iter 50000, loss: 0.040055
   Number of active neurons: 4
 >> iter 51000, loss: 0.052388
 >> iter 52000, loss: 0.042553
 >> iter 53000, loss: 0.046025
 >> iter 54000, loss: 0.042726
 >> iter 55000, loss: 0.041332
 >> iter 56000, loss: 0.046904
 >> iter 57000, loss: 0.062516
 >> iter 58000, loss: 0.067360
 >> iter 59000, loss: 0.044043
 >> iter 60000, loss: 0.045013
   Number of active neurons: 4
 >> iter 61000, loss: 0.041583
 >> iter 62000, loss: 0.041509
 >> iter 63000, loss: 0.041137
 >> iter 64000, loss: 0.046798
 >> iter 65000, loss: 0.048924
 >> iter 66000, loss: 0.042568
 >> iter 67000, loss: 0.050342
 >> iter 68000, loss: 0.041936
 >> iter 69000, loss: 0.034921
 >> iter 70000, loss: 0.031831
   Number of active neurons: 4
 >> iter 71000, loss: 0.058986
 >> iter 72000, loss: 0.051561
 >> iter 73000, loss: 0.046346
 >> iter 74000, loss: 0.070333
 >> iter 75000, loss: 0.057277
 >> iter 76000, loss: 0.054459
 >> iter 77000, loss: 0.047053
 >> iter 78000, loss: 0.046172
 >> iter 79000, loss: 0.036202
 >> iter 80000, loss: 0.038294
   Number of active neurons: 4
 >> iter 81000, loss: 0.036994
 >> iter 82000, loss: 0.040854
 >> iter 83000, loss: 0.040699
 >> iter 84000, loss: 0.038943
 >> iter 85000, loss: 0.035252
 >> iter 86000, loss: 0.039890
 >> iter 87000, loss: 0.029249
 >> iter 88000, loss: 0.027698
 >> iter 89000, loss: 0.028266
 >> iter 90000, loss: 0.029553
   Number of active neurons: 3
 >> iter 91000, loss: 0.031561
 >> iter 92000, loss: 0.026374
 >> iter 93000, loss: 0.036716
 >> iter 94000, loss: 0.046287
 >> iter 95000, loss: 0.031379
 >> iter 96000, loss: 0.034066
 >> iter 97000, loss: 0.037571
 >> iter 98000, loss: 0.055074
 >> iter 99000, loss: 0.055311
 >> iter 100000, loss: 0.041224
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.657405
 >> iter 2000, loss: 4.457128
 >> iter 3000, loss: 1.711017
 >> iter 4000, loss: 0.673135
 >> iter 5000, loss: 0.298231
 >> iter 6000, loss: 0.141818
 >> iter 7000, loss: 0.102071
 >> iter 8000, loss: 0.084004
 >> iter 9000, loss: 0.056839
 >> iter 10000, loss: 0.058487
   Number of active neurons: 3
 >> iter 11000, loss: 0.088418
 >> iter 12000, loss: 0.071496
 >> iter 13000, loss: 0.060181
 >> iter 14000, loss: 0.046856
 >> iter 15000, loss: 0.067772
 >> iter 16000, loss: 0.052568
 >> iter 17000, loss: 0.047682
 >> iter 18000, loss: 0.044735
 >> iter 19000, loss: 0.043512
 >> iter 20000, loss: 0.054688
   Number of active neurons: 3
 >> iter 21000, loss: 0.066872
 >> iter 22000, loss: 0.055472
 >> iter 23000, loss: 0.044442
 >> iter 24000, loss: 0.059861
 >> iter 25000, loss: 0.058811
 >> iter 26000, loss: 0.049508
 >> iter 27000, loss: 0.041765
 >> iter 28000, loss: 0.033078
 >> iter 29000, loss: 0.076728
 >> iter 30000, loss: 0.057166
   Number of active neurons: 3
 >> iter 31000, loss: 0.043027
 >> iter 32000, loss: 0.077039
 >> iter 33000, loss: 0.061614
 >> iter 34000, loss: 0.055026
 >> iter 35000, loss: 0.040472
 >> iter 36000, loss: 0.041304
 >> iter 37000, loss: 0.061586
 >> iter 38000, loss: 0.056177
 >> iter 39000, loss: 0.046956
 >> iter 40000, loss: 0.048848
   Number of active neurons: 3
 >> iter 41000, loss: 0.048174
 >> iter 42000, loss: 0.050599
 >> iter 43000, loss: 0.052859
 >> iter 44000, loss: 0.052316
 >> iter 45000, loss: 0.054375
 >> iter 46000, loss: 0.046349
 >> iter 47000, loss: 0.056453
 >> iter 48000, loss: 0.073980
 >> iter 49000, loss: 0.059506
 >> iter 50000, loss: 0.059799
   Number of active neurons: 2
 >> iter 51000, loss: 0.060762
 >> iter 52000, loss: 0.053434
 >> iter 53000, loss: 0.035973
 >> iter 54000, loss: 0.042313
 >> iter 55000, loss: 0.041243
 >> iter 56000, loss: 0.067486
 >> iter 57000, loss: 0.061513
 >> iter 58000, loss: 0.048809
 >> iter 59000, loss: 0.051886
 >> iter 60000, loss: 0.052511
   Number of active neurons: 2
 >> iter 61000, loss: 0.041589
 >> iter 62000, loss: 0.057145
 >> iter 63000, loss: 0.051102
 >> iter 64000, loss: 0.033920
 >> iter 65000, loss: 0.051816
 >> iter 66000, loss: 0.048290
 >> iter 67000, loss: 0.044553
 >> iter 68000, loss: 0.036765
 >> iter 69000, loss: 0.048480
 >> iter 70000, loss: 0.049490
   Number of active neurons: 2
 >> iter 71000, loss: 0.054893
 >> iter 72000, loss: 0.047881
 >> iter 73000, loss: 0.061668
 >> iter 74000, loss: 0.058094
 >> iter 75000, loss: 0.047460
 >> iter 76000, loss: 0.043520
 >> iter 77000, loss: 0.030077
 >> iter 78000, loss: 0.035261
 >> iter 79000, loss: 0.031356
 >> iter 80000, loss: 0.036635
   Number of active neurons: 2
 >> iter 81000, loss: 0.028969
 >> iter 82000, loss: 0.031774
 >> iter 83000, loss: 0.043162
 >> iter 84000, loss: 0.053444
 >> iter 85000, loss: 0.038895
 >> iter 86000, loss: 0.041473
 >> iter 87000, loss: 0.038168
 >> iter 88000, loss: 0.047813
 >> iter 89000, loss: 0.036148
 >> iter 90000, loss: 0.036592
   Number of active neurons: 2
 >> iter 91000, loss: 0.043120
 >> iter 92000, loss: 0.045840
 >> iter 93000, loss: 0.031369
 >> iter 94000, loss: 0.031473
 >> iter 95000, loss: 0.052219
 >> iter 96000, loss: 0.048526
 >> iter 97000, loss: 0.047398
 >> iter 98000, loss: 0.040599
 >> iter 99000, loss: 0.036526
 >> iter 100000, loss: 0.036410
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.461017
 >> iter 2000, loss: 4.474930
 >> iter 3000, loss: 1.715628
 >> iter 4000, loss: 0.678963
 >> iter 5000, loss: 0.304743
 >> iter 6000, loss: 0.142062
 >> iter 7000, loss: 0.111426
 >> iter 8000, loss: 0.085933
 >> iter 9000, loss: 0.056457
 >> iter 10000, loss: 0.054514
   Number of active neurons: 4
 >> iter 11000, loss: 0.050853
 >> iter 12000, loss: 0.058819
 >> iter 13000, loss: 0.073042
 >> iter 14000, loss: 0.072444
 >> iter 15000, loss: 0.058359
 >> iter 16000, loss: 0.046095
 >> iter 17000, loss: 0.038583
 >> iter 18000, loss: 0.047557
 >> iter 19000, loss: 0.044110
 >> iter 20000, loss: 0.060537
   Number of active neurons: 3
 >> iter 21000, loss: 0.045168
 >> iter 22000, loss: 0.061642
 >> iter 23000, loss: 0.045623
 >> iter 24000, loss: 0.059451
 >> iter 25000, loss: 0.052253
 >> iter 26000, loss: 0.057426
 >> iter 27000, loss: 0.039248
 >> iter 28000, loss: 0.044766
 >> iter 29000, loss: 0.038485
 >> iter 30000, loss: 0.035814
   Number of active neurons: 3
 >> iter 31000, loss: 0.047003
 >> iter 32000, loss: 0.047476
 >> iter 33000, loss: 0.066335
 >> iter 34000, loss: 0.064049
 >> iter 35000, loss: 0.042746
 >> iter 36000, loss: 0.034790
 >> iter 37000, loss: 0.039652
 >> iter 38000, loss: 0.047425
 >> iter 39000, loss: 0.046708
 >> iter 40000, loss: 0.038975
   Number of active neurons: 3
 >> iter 41000, loss: 0.038490
 >> iter 42000, loss: 0.034597
 >> iter 43000, loss: 0.054888
 >> iter 44000, loss: 0.040769
 >> iter 45000, loss: 0.044794
 >> iter 46000, loss: 0.042821
 >> iter 47000, loss: 0.038290
 >> iter 48000, loss: 0.049781
 >> iter 49000, loss: 0.056886
 >> iter 50000, loss: 0.059135
   Number of active neurons: 3
 >> iter 51000, loss: 0.053028
 >> iter 52000, loss: 0.051772
 >> iter 53000, loss: 0.051266
 >> iter 54000, loss: 0.037960
 >> iter 55000, loss: 0.042787
 >> iter 56000, loss: 0.053997
 >> iter 57000, loss: 0.085604
 >> iter 58000, loss: 0.061342
 >> iter 59000, loss: 0.049309
 >> iter 60000, loss: 0.048701
   Number of active neurons: 3
 >> iter 61000, loss: 0.061877
 >> iter 62000, loss: 0.056920
 >> iter 63000, loss: 0.043028
 >> iter 64000, loss: 0.053728
 >> iter 65000, loss: 0.054961
 >> iter 66000, loss: 0.047729
 >> iter 67000, loss: 0.042094
 >> iter 68000, loss: 0.049504
 >> iter 69000, loss: 0.052981
 >> iter 70000, loss: 0.049701
   Number of active neurons: 3
 >> iter 71000, loss: 0.055918
 >> iter 72000, loss: 0.037379
 >> iter 73000, loss: 0.035078
 >> iter 74000, loss: 0.048657
 >> iter 75000, loss: 0.045369
 >> iter 76000, loss: 0.041648
 >> iter 77000, loss: 0.041992
 >> iter 78000, loss: 0.040952
 >> iter 79000, loss: 0.043963
 >> iter 80000, loss: 0.044916
   Number of active neurons: 3
 >> iter 81000, loss: 0.047660
 >> iter 82000, loss: 0.039866
 >> iter 83000, loss: 0.054457
 >> iter 84000, loss: 0.063564
 >> iter 85000, loss: 0.047930
 >> iter 86000, loss: 0.050494
 >> iter 87000, loss: 0.047587
 >> iter 88000, loss: 0.048909
 >> iter 89000, loss: 0.064325
 >> iter 90000, loss: 0.049375
   Number of active neurons: 2
 >> iter 91000, loss: 0.049775
 >> iter 92000, loss: 0.035966
 >> iter 93000, loss: 0.051777
 >> iter 94000, loss: 0.052144
 >> iter 95000, loss: 0.053012
 >> iter 96000, loss: 0.055710
 >> iter 97000, loss: 0.043778
 >> iter 98000, loss: 0.040405
 >> iter 99000, loss: 0.045699
 >> iter 100000, loss: 0.036171
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.333214
 >> iter 2000, loss: 4.378688
 >> iter 3000, loss: 1.667881
 >> iter 4000, loss: 0.660425
 >> iter 5000, loss: 0.301149
 >> iter 6000, loss: 0.180785
 >> iter 7000, loss: 0.111895
 >> iter 8000, loss: 0.071894
 >> iter 9000, loss: 0.054944
 >> iter 10000, loss: 0.049618
   Number of active neurons: 4
 >> iter 11000, loss: 0.054008
 >> iter 12000, loss: 0.055628
 >> iter 13000, loss: 0.048188
 >> iter 14000, loss: 0.046138
 >> iter 15000, loss: 0.101063
 >> iter 16000, loss: 0.066296
 >> iter 17000, loss: 0.053022
 >> iter 18000, loss: 0.055030
 >> iter 19000, loss: 0.046109
 >> iter 20000, loss: 0.051908
   Number of active neurons: 4
 >> iter 21000, loss: 0.054252
 >> iter 22000, loss: 0.066382
 >> iter 23000, loss: 0.045102
 >> iter 24000, loss: 0.050070
 >> iter 25000, loss: 0.047749
 >> iter 26000, loss: 0.056625
 >> iter 27000, loss: 0.064147
 >> iter 28000, loss: 0.051468
 >> iter 29000, loss: 0.051250
 >> iter 30000, loss: 0.047553
   Number of active neurons: 4
 >> iter 31000, loss: 0.043132
 >> iter 32000, loss: 0.052105
 >> iter 33000, loss: 0.050334
 >> iter 34000, loss: 0.046082
 >> iter 35000, loss: 0.050683
 >> iter 36000, loss: 0.042791
 >> iter 37000, loss: 0.043230
 >> iter 38000, loss: 0.041103
 >> iter 39000, loss: 0.046048
 >> iter 40000, loss: 0.056228
   Number of active neurons: 4
 >> iter 41000, loss: 0.053814
 >> iter 42000, loss: 0.053062
 >> iter 43000, loss: 0.056011
 >> iter 44000, loss: 0.052523
 >> iter 45000, loss: 0.050742
 >> iter 46000, loss: 0.056927
 >> iter 47000, loss: 0.054322
 >> iter 48000, loss: 0.048014
 >> iter 49000, loss: 0.042732
 >> iter 50000, loss: 0.050572
   Number of active neurons: 4
 >> iter 51000, loss: 0.055722
 >> iter 52000, loss: 0.044074
 >> iter 53000, loss: 0.065413
 >> iter 54000, loss: 0.051172
 >> iter 55000, loss: 0.061579
 >> iter 56000, loss: 0.052299
 >> iter 57000, loss: 0.048817
 >> iter 58000, loss: 0.065179
 >> iter 59000, loss: 0.057100
 >> iter 60000, loss: 0.042623
   Number of active neurons: 3
 >> iter 61000, loss: 0.043791
 >> iter 62000, loss: 0.032277
 >> iter 63000, loss: 0.071419
 >> iter 64000, loss: 0.061214
 >> iter 65000, loss: 0.044882
 >> iter 66000, loss: 0.043103
 >> iter 67000, loss: 0.056220
 >> iter 68000, loss: 0.064083
 >> iter 69000, loss: 0.055851
 >> iter 70000, loss: 0.066385
   Number of active neurons: 3
 >> iter 71000, loss: 0.039896
 >> iter 72000, loss: 0.036931
 >> iter 73000, loss: 0.052291
 >> iter 74000, loss: 0.041339
 >> iter 75000, loss: 0.056889
 >> iter 76000, loss: 0.058892
 >> iter 77000, loss: 0.045257
 >> iter 78000, loss: 0.043466
 >> iter 79000, loss: 0.051579
 >> iter 80000, loss: 0.051751
   Number of active neurons: 3
 >> iter 81000, loss: 0.044437
 >> iter 82000, loss: 0.051786
 >> iter 83000, loss: 0.044069
 >> iter 84000, loss: 0.052211
 >> iter 85000, loss: 0.052710
 >> iter 86000, loss: 0.039299
 >> iter 87000, loss: 0.043766
 >> iter 88000, loss: 0.037099
 >> iter 89000, loss: 0.049776
 >> iter 90000, loss: 0.049048
   Number of active neurons: 3
 >> iter 91000, loss: 0.042870
 >> iter 92000, loss: 0.034588
 >> iter 93000, loss: 0.036944
 >> iter 94000, loss: 0.041827
 >> iter 95000, loss: 0.044087
 >> iter 96000, loss: 0.057699
 >> iter 97000, loss: 0.037800
 >> iter 98000, loss: 0.062592
 >> iter 99000, loss: 0.060779
 >> iter 100000, loss: 0.069024
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455162
   Number of active neurons: 0
 >> iter 1000, loss: 11.249036
 >> iter 2000, loss: 4.358561
 >> iter 3000, loss: 1.682709
 >> iter 4000, loss: 0.652373
 >> iter 5000, loss: 0.291350
 >> iter 6000, loss: 0.158679
 >> iter 7000, loss: 0.082944
 >> iter 8000, loss: 0.053810
 >> iter 9000, loss: 0.046659
 >> iter 10000, loss: 0.042543
   Number of active neurons: 4
 >> iter 11000, loss: 0.036618
 >> iter 12000, loss: 0.042142
 >> iter 13000, loss: 0.041223
 >> iter 14000, loss: 0.047137
 >> iter 15000, loss: 0.050177
 >> iter 16000, loss: 0.045900
 >> iter 17000, loss: 0.040127
 >> iter 18000, loss: 0.037017
 >> iter 19000, loss: 0.050439
 >> iter 20000, loss: 0.050839
   Number of active neurons: 4
 >> iter 21000, loss: 0.080838
 >> iter 22000, loss: 0.060527
 >> iter 23000, loss: 0.061765
 >> iter 24000, loss: 0.069493
 >> iter 25000, loss: 0.048759
 >> iter 26000, loss: 0.044143
 >> iter 27000, loss: 0.047650
 >> iter 28000, loss: 0.050728
 >> iter 29000, loss: 0.066648
 >> iter 30000, loss: 0.047751
   Number of active neurons: 4
 >> iter 31000, loss: 0.058214
 >> iter 32000, loss: 0.058239
 >> iter 33000, loss: 0.051829
 >> iter 34000, loss: 0.039243
 >> iter 35000, loss: 0.050147
 >> iter 36000, loss: 0.065132
 >> iter 37000, loss: 0.052912
 >> iter 38000, loss: 0.048892
 >> iter 39000, loss: 0.058014
 >> iter 40000, loss: 0.057834
   Number of active neurons: 3
 >> iter 41000, loss: 0.045425
 >> iter 42000, loss: 0.046696
 >> iter 43000, loss: 0.061072
 >> iter 44000, loss: 0.054393
 >> iter 45000, loss: 0.065624
 >> iter 46000, loss: 0.049140
 >> iter 47000, loss: 0.051542
 >> iter 48000, loss: 0.039498
 >> iter 49000, loss: 0.035504
 >> iter 50000, loss: 0.035175
   Number of active neurons: 3
 >> iter 51000, loss: 0.033255
 >> iter 52000, loss: 0.040318
 >> iter 53000, loss: 0.042279
 >> iter 54000, loss: 0.050555
 >> iter 55000, loss: 0.033421
 >> iter 56000, loss: 0.042599
 >> iter 57000, loss: 0.043550
 >> iter 58000, loss: 0.044277
 >> iter 59000, loss: 0.046854
 >> iter 60000, loss: 0.036217
   Number of active neurons: 3
 >> iter 61000, loss: 0.041221
 >> iter 62000, loss: 0.055535
 >> iter 63000, loss: 0.049369
 >> iter 64000, loss: 0.046177
 >> iter 65000, loss: 0.043355
 >> iter 66000, loss: 0.050353
 >> iter 67000, loss: 0.039879
 >> iter 68000, loss: 0.036717
 >> iter 69000, loss: 0.044962
 >> iter 70000, loss: 0.056385
   Number of active neurons: 3
 >> iter 71000, loss: 0.065940
 >> iter 72000, loss: 0.053969
 >> iter 73000, loss: 0.053164
 >> iter 74000, loss: 0.052958
 >> iter 75000, loss: 0.049826
 >> iter 76000, loss: 0.041583
 >> iter 77000, loss: 0.041252
 >> iter 78000, loss: 0.051604
 >> iter 79000, loss: 0.050095
 >> iter 80000, loss: 0.053606
   Number of active neurons: 3
 >> iter 81000, loss: 0.036544
 >> iter 82000, loss: 0.031953
 >> iter 83000, loss: 0.055427
 >> iter 84000, loss: 0.053980
 >> iter 85000, loss: 0.044018
 >> iter 86000, loss: 0.039618
 >> iter 87000, loss: 0.043119
 >> iter 88000, loss: 0.037137
 >> iter 89000, loss: 0.039616
 >> iter 90000, loss: 0.031403
   Number of active neurons: 3
 >> iter 91000, loss: 0.046239
 >> iter 92000, loss: 0.040939
 >> iter 93000, loss: 0.034466
 >> iter 94000, loss: 0.045626
 >> iter 95000, loss: 0.046041
 >> iter 96000, loss: 0.034382
 >> iter 97000, loss: 0.046019
 >> iter 98000, loss: 0.044211
 >> iter 99000, loss: 0.050844
 >> iter 100000, loss: 0.067038
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.355905
 >> iter 2000, loss: 4.381123
 >> iter 3000, loss: 1.697844
 >> iter 4000, loss: 0.682412
 >> iter 5000, loss: 0.289652
 >> iter 6000, loss: 0.144863
 >> iter 7000, loss: 0.114425
 >> iter 8000, loss: 0.081475
 >> iter 9000, loss: 0.074477
 >> iter 10000, loss: 0.077433
   Number of active neurons: 6
 >> iter 11000, loss: 0.069533
 >> iter 12000, loss: 0.065441
 >> iter 13000, loss: 0.046778
 >> iter 14000, loss: 0.046445
 >> iter 15000, loss: 0.050600
 >> iter 16000, loss: 0.070748
 >> iter 17000, loss: 0.072317
 >> iter 18000, loss: 0.074654
 >> iter 19000, loss: 0.069180
 >> iter 20000, loss: 0.056842
   Number of active neurons: 6
 >> iter 21000, loss: 0.047934
 >> iter 22000, loss: 0.068287
 >> iter 23000, loss: 0.061522
 >> iter 24000, loss: 0.060282
 >> iter 25000, loss: 0.053528
 >> iter 26000, loss: 0.058893
 >> iter 27000, loss: 0.067370
 >> iter 28000, loss: 0.049497
 >> iter 29000, loss: 0.049675
 >> iter 30000, loss: 0.037791
   Number of active neurons: 5
 >> iter 31000, loss: 0.048464
 >> iter 32000, loss: 0.052434
 >> iter 33000, loss: 0.048836
 >> iter 34000, loss: 0.057089
 >> iter 35000, loss: 0.050184
 >> iter 36000, loss: 0.059434
 >> iter 37000, loss: 0.064948
 >> iter 38000, loss: 0.071253
 >> iter 39000, loss: 0.095263
 >> iter 40000, loss: 0.066327
   Number of active neurons: 5
 >> iter 41000, loss: 0.055042
 >> iter 42000, loss: 0.066985
 >> iter 43000, loss: 0.063363
 >> iter 44000, loss: 0.046967
 >> iter 45000, loss: 0.057191
 >> iter 46000, loss: 0.038590
 >> iter 47000, loss: 0.062403
 >> iter 48000, loss: 0.043783
 >> iter 49000, loss: 0.057443
 >> iter 50000, loss: 0.047305
   Number of active neurons: 4
 >> iter 51000, loss: 0.041640
 >> iter 52000, loss: 0.071904
 >> iter 53000, loss: 0.049012
 >> iter 54000, loss: 0.037081
 >> iter 55000, loss: 0.035987
 >> iter 56000, loss: 0.060959
 >> iter 57000, loss: 0.055641
 >> iter 58000, loss: 0.042724
 >> iter 59000, loss: 0.062091
 >> iter 60000, loss: 0.043904
   Number of active neurons: 4
 >> iter 61000, loss: 0.073687
 >> iter 62000, loss: 0.056978
 >> iter 63000, loss: 0.057630
 >> iter 64000, loss: 0.045984
 >> iter 65000, loss: 0.048626
 >> iter 66000, loss: 0.054688
 >> iter 67000, loss: 0.040513
 >> iter 68000, loss: 0.051162
 >> iter 69000, loss: 0.040248
 >> iter 70000, loss: 0.035298
   Number of active neurons: 4
 >> iter 71000, loss: 0.039050
 >> iter 72000, loss: 0.062744
 >> iter 73000, loss: 0.049149
 >> iter 74000, loss: 0.038823
 >> iter 75000, loss: 0.039421
 >> iter 76000, loss: 0.045993
 >> iter 77000, loss: 0.039075
 >> iter 78000, loss: 0.043064
 >> iter 79000, loss: 0.091542
 >> iter 80000, loss: 0.060386
   Number of active neurons: 3
 >> iter 81000, loss: 0.071013
 >> iter 82000, loss: 0.067039
 >> iter 83000, loss: 0.056305
 >> iter 84000, loss: 0.038188
 >> iter 85000, loss: 0.040533
 >> iter 86000, loss: 0.036592
 >> iter 87000, loss: 0.069203
 >> iter 88000, loss: 0.046763
 >> iter 89000, loss: 0.064192
 >> iter 90000, loss: 0.046730
   Number of active neurons: 3
 >> iter 91000, loss: 0.038434
 >> iter 92000, loss: 0.035747
 >> iter 93000, loss: 0.041013
 >> iter 94000, loss: 0.059234
 >> iter 95000, loss: 0.045602
 >> iter 96000, loss: 0.036355
 >> iter 97000, loss: 0.054650
 >> iter 98000, loss: 0.049370
 >> iter 99000, loss: 0.043600
 >> iter 100000, loss: 0.032286
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.404763
 >> iter 2000, loss: 4.409806
 >> iter 3000, loss: 1.710439
 >> iter 4000, loss: 0.688561
 >> iter 5000, loss: 0.311900
 >> iter 6000, loss: 0.152437
 >> iter 7000, loss: 0.115248
 >> iter 8000, loss: 0.080352
 >> iter 9000, loss: 0.059342
 >> iter 10000, loss: 0.061892
   Number of active neurons: 4
 >> iter 11000, loss: 0.058634
 >> iter 12000, loss: 0.046213
 >> iter 13000, loss: 0.059677
 >> iter 14000, loss: 0.059777
 >> iter 15000, loss: 0.072762
 >> iter 16000, loss: 0.056070
 >> iter 17000, loss: 0.045800
 >> iter 18000, loss: 0.070517
 >> iter 19000, loss: 0.047078
 >> iter 20000, loss: 0.048565
   Number of active neurons: 4
 >> iter 21000, loss: 0.060233
 >> iter 22000, loss: 0.061722
 >> iter 23000, loss: 0.045608
 >> iter 24000, loss: 0.040461
 >> iter 25000, loss: 0.054426
 >> iter 26000, loss: 0.046895
 >> iter 27000, loss: 0.049244
 >> iter 28000, loss: 0.042863
 >> iter 29000, loss: 0.059922
 >> iter 30000, loss: 0.040124
   Number of active neurons: 4
 >> iter 31000, loss: 0.051982
 >> iter 32000, loss: 0.061284
 >> iter 33000, loss: 0.046584
 >> iter 34000, loss: 0.050906
 >> iter 35000, loss: 0.040547
 >> iter 36000, loss: 0.043803
 >> iter 37000, loss: 0.047508
 >> iter 38000, loss: 0.052036
 >> iter 39000, loss: 0.057803
 >> iter 40000, loss: 0.050298
   Number of active neurons: 3
 >> iter 41000, loss: 0.054254
 >> iter 42000, loss: 0.073452
 >> iter 43000, loss: 0.046995
 >> iter 44000, loss: 0.051059
 >> iter 45000, loss: 0.060560
 >> iter 46000, loss: 0.041629
 >> iter 47000, loss: 0.049809
 >> iter 48000, loss: 0.043952
 >> iter 49000, loss: 0.076034
 >> iter 50000, loss: 0.059032
   Number of active neurons: 3
 >> iter 51000, loss: 0.056409
 >> iter 52000, loss: 0.040775
 >> iter 53000, loss: 0.048681
 >> iter 54000, loss: 0.049529
 >> iter 55000, loss: 0.040673
 >> iter 56000, loss: 0.035947
 >> iter 57000, loss: 0.039882
 >> iter 58000, loss: 0.038941
 >> iter 59000, loss: 0.051406
 >> iter 60000, loss: 0.042141
   Number of active neurons: 3
 >> iter 61000, loss: 0.043757
 >> iter 62000, loss: 0.038320
 >> iter 63000, loss: 0.054430
 >> iter 64000, loss: 0.059789
 >> iter 65000, loss: 0.049889
 >> iter 66000, loss: 0.050395
 >> iter 67000, loss: 0.069710
 >> iter 68000, loss: 0.063159
 >> iter 69000, loss: 0.046678
 >> iter 70000, loss: 0.037371
   Number of active neurons: 3
 >> iter 71000, loss: 0.057645
 >> iter 72000, loss: 0.049163
 >> iter 73000, loss: 0.046903
 >> iter 74000, loss: 0.040722
 >> iter 75000, loss: 0.054674
 >> iter 76000, loss: 0.079178
 >> iter 77000, loss: 0.060771
 >> iter 78000, loss: 0.057548
 >> iter 79000, loss: 0.044635
 >> iter 80000, loss: 0.042050
   Number of active neurons: 3
 >> iter 81000, loss: 0.042629
 >> iter 82000, loss: 0.044861
 >> iter 83000, loss: 0.048910
 >> iter 84000, loss: 0.055293
 >> iter 85000, loss: 0.064478
 >> iter 86000, loss: 0.055662
 >> iter 87000, loss: 0.039828
 >> iter 88000, loss: 0.032579
 >> iter 89000, loss: 0.037732
 >> iter 90000, loss: 0.045813
   Number of active neurons: 3
 >> iter 91000, loss: 0.051706
 >> iter 92000, loss: 0.049066
 >> iter 93000, loss: 0.054329
 >> iter 94000, loss: 0.044778
 >> iter 95000, loss: 0.035144
 >> iter 96000, loss: 0.030059
 >> iter 97000, loss: 0.033768
 >> iter 98000, loss: 0.048821
 >> iter 99000, loss: 0.043761
 >> iter 100000, loss: 0.061753
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.354571
 >> iter 2000, loss: 4.407896
 >> iter 3000, loss: 1.703256
 >> iter 4000, loss: 0.689331
 >> iter 5000, loss: 0.330050
 >> iter 6000, loss: 0.178246
 >> iter 7000, loss: 0.113697
 >> iter 8000, loss: 0.074925
 >> iter 9000, loss: 0.065725
 >> iter 10000, loss: 0.059188
   Number of active neurons: 6
 >> iter 11000, loss: 0.069940
 >> iter 12000, loss: 0.084154
 >> iter 13000, loss: 0.068629
 >> iter 14000, loss: 0.076580
 >> iter 15000, loss: 0.072977
 >> iter 16000, loss: 0.058071
 >> iter 17000, loss: 0.063332
 >> iter 18000, loss: 0.049408
 >> iter 19000, loss: 0.079609
 >> iter 20000, loss: 0.062031
   Number of active neurons: 6
 >> iter 21000, loss: 0.042599
 >> iter 22000, loss: 0.040881
 >> iter 23000, loss: 0.048756
 >> iter 24000, loss: 0.060813
 >> iter 25000, loss: 0.082953
 >> iter 26000, loss: 0.067145
 >> iter 27000, loss: 0.067831
 >> iter 28000, loss: 0.053646
 >> iter 29000, loss: 0.079919
 >> iter 30000, loss: 0.061569
   Number of active neurons: 6
 >> iter 31000, loss: 0.082528
 >> iter 32000, loss: 0.068362
 >> iter 33000, loss: 0.052495
 >> iter 34000, loss: 0.045026
 >> iter 35000, loss: 0.037848
 >> iter 36000, loss: 0.050509
 >> iter 37000, loss: 0.053635
 >> iter 38000, loss: 0.051860
 >> iter 39000, loss: 0.051854
 >> iter 40000, loss: 0.038836
   Number of active neurons: 6
 >> iter 41000, loss: 0.047342
 >> iter 42000, loss: 0.051742
 >> iter 43000, loss: 0.046291
 >> iter 44000, loss: 0.049559
 >> iter 45000, loss: 0.051143
 >> iter 46000, loss: 0.059084
 >> iter 47000, loss: 0.048753
 >> iter 48000, loss: 0.040401
 >> iter 49000, loss: 0.042914
 >> iter 50000, loss: 0.044249
   Number of active neurons: 4
 >> iter 51000, loss: 0.040591
 >> iter 52000, loss: 0.036911
 >> iter 53000, loss: 0.050132
 >> iter 54000, loss: 0.052982
 >> iter 55000, loss: 0.037247
 >> iter 56000, loss: 0.029511
 >> iter 57000, loss: 0.051446
 >> iter 58000, loss: 0.039544
 >> iter 59000, loss: 0.050728
 >> iter 60000, loss: 0.048002
   Number of active neurons: 4
 >> iter 61000, loss: 0.059225
 >> iter 62000, loss: 0.063042
 >> iter 63000, loss: 0.054293
 >> iter 64000, loss: 0.052035
 >> iter 65000, loss: 0.049803
 >> iter 66000, loss: 0.035287
 >> iter 67000, loss: 0.044614
 >> iter 68000, loss: 0.038229
 >> iter 69000, loss: 0.046162
 >> iter 70000, loss: 0.062415
   Number of active neurons: 4
 >> iter 71000, loss: 0.046618
 >> iter 72000, loss: 0.068048
 >> iter 73000, loss: 0.055555
 >> iter 74000, loss: 0.078182
 >> iter 75000, loss: 0.060987
 >> iter 76000, loss: 0.043256
 >> iter 77000, loss: 0.041410
 >> iter 78000, loss: 0.060192
 >> iter 79000, loss: 0.046910
 >> iter 80000, loss: 0.056001
   Number of active neurons: 4
 >> iter 81000, loss: 0.058659
 >> iter 82000, loss: 0.048687
 >> iter 83000, loss: 0.042089
 >> iter 84000, loss: 0.061928
 >> iter 85000, loss: 0.051116
 >> iter 86000, loss: 0.054168
 >> iter 87000, loss: 0.061712
 >> iter 88000, loss: 0.059768
 >> iter 89000, loss: 0.068118
 >> iter 90000, loss: 0.044340
   Number of active neurons: 4
 >> iter 91000, loss: 0.045420
 >> iter 92000, loss: 0.050063
 >> iter 93000, loss: 0.042737
 >> iter 94000, loss: 0.042363
 >> iter 95000, loss: 0.059277
 >> iter 96000, loss: 0.065732
 >> iter 97000, loss: 0.072706
 >> iter 98000, loss: 0.056925
 >> iter 99000, loss: 0.053488
 >> iter 100000, loss: 0.067608
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 11.290312
 >> iter 2000, loss: 4.377091
 >> iter 3000, loss: 1.727901
 >> iter 4000, loss: 0.707651
 >> iter 5000, loss: 0.307380
 >> iter 6000, loss: 0.145047
 >> iter 7000, loss: 0.130213
 >> iter 8000, loss: 0.095135
 >> iter 9000, loss: 0.081084
 >> iter 10000, loss: 0.067665
   Number of active neurons: 6
 >> iter 11000, loss: 0.088062
 >> iter 12000, loss: 0.076628
 >> iter 13000, loss: 0.076226
 >> iter 14000, loss: 0.069904
 >> iter 15000, loss: 0.063795
 >> iter 16000, loss: 0.058768
 >> iter 17000, loss: 0.044588
 >> iter 18000, loss: 0.054988
 >> iter 19000, loss: 0.085584
 >> iter 20000, loss: 0.064282
   Number of active neurons: 6
 >> iter 21000, loss: 0.062955
 >> iter 22000, loss: 0.070934
 >> iter 23000, loss: 0.057985
 >> iter 24000, loss: 0.042907
 >> iter 25000, loss: 0.051356
 >> iter 26000, loss: 0.038485
 >> iter 27000, loss: 0.047029
 >> iter 28000, loss: 0.053367
 >> iter 29000, loss: 0.063911
 >> iter 30000, loss: 0.056080
   Number of active neurons: 6
 >> iter 31000, loss: 0.060693
 >> iter 32000, loss: 0.065561
 >> iter 33000, loss: 0.064863
 >> iter 34000, loss: 0.052926
 >> iter 35000, loss: 0.064268
 >> iter 36000, loss: 0.050829
 >> iter 37000, loss: 0.054802
 >> iter 38000, loss: 0.041270
 >> iter 39000, loss: 0.062409
 >> iter 40000, loss: 0.063455
   Number of active neurons: 3
 >> iter 41000, loss: 0.054006
 >> iter 42000, loss: 0.051291
 >> iter 43000, loss: 0.047555
 >> iter 44000, loss: 0.049019
 >> iter 45000, loss: 0.053626
 >> iter 46000, loss: 0.042516
 >> iter 47000, loss: 0.046434
 >> iter 48000, loss: 0.036532
 >> iter 49000, loss: 0.058333
 >> iter 50000, loss: 0.055767
   Number of active neurons: 3
 >> iter 51000, loss: 0.058401
 >> iter 52000, loss: 0.048929
 >> iter 53000, loss: 0.047012
 >> iter 54000, loss: 0.034343
 >> iter 55000, loss: 0.040075
 >> iter 56000, loss: 0.051642
 >> iter 57000, loss: 0.054304
 >> iter 58000, loss: 0.036085
 >> iter 59000, loss: 0.040261
 >> iter 60000, loss: 0.054389
   Number of active neurons: 3
 >> iter 61000, loss: 0.043781
 >> iter 62000, loss: 0.038005
 >> iter 63000, loss: 0.048278
 >> iter 64000, loss: 0.037329
 >> iter 65000, loss: 0.054534
 >> iter 66000, loss: 0.050269
 >> iter 67000, loss: 0.060056
 >> iter 68000, loss: 0.048011
 >> iter 69000, loss: 0.090135
 >> iter 70000, loss: 0.070435
   Number of active neurons: 3
 >> iter 71000, loss: 0.072695
 >> iter 72000, loss: 0.057830
 >> iter 73000, loss: 0.054014
 >> iter 74000, loss: 0.034163
 >> iter 75000, loss: 0.033570
 >> iter 76000, loss: 0.048228
 >> iter 77000, loss: 0.045815
 >> iter 78000, loss: 0.038947
 >> iter 79000, loss: 0.041139
 >> iter 80000, loss: 0.045116
   Number of active neurons: 2
 >> iter 81000, loss: 0.045807
 >> iter 82000, loss: 0.051578
 >> iter 83000, loss: 0.070983
 >> iter 84000, loss: 0.051095
 >> iter 85000, loss: 0.065431
 >> iter 86000, loss: 0.062273
 >> iter 87000, loss: 0.064194
 >> iter 88000, loss: 0.058991
 >> iter 89000, loss: 0.041252
 >> iter 90000, loss: 0.038681
   Number of active neurons: 2
 >> iter 91000, loss: 0.029148
 >> iter 92000, loss: 0.038275
 >> iter 93000, loss: 0.065842
 >> iter 94000, loss: 0.056166
 >> iter 95000, loss: 0.057509
 >> iter 96000, loss: 0.046191
 >> iter 97000, loss: 0.054474
 >> iter 98000, loss: 0.042844
 >> iter 99000, loss: 0.056936
 >> iter 100000, loss: 0.047459
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.404842
 >> iter 2000, loss: 4.420515
 >> iter 3000, loss: 1.712912
 >> iter 4000, loss: 0.709407
 >> iter 5000, loss: 0.301450
 >> iter 6000, loss: 0.147287
 >> iter 7000, loss: 0.100587
 >> iter 8000, loss: 0.087636
 >> iter 9000, loss: 0.073579
 >> iter 10000, loss: 0.064816
   Number of active neurons: 5
 >> iter 11000, loss: 0.059069
 >> iter 12000, loss: 0.064838
 >> iter 13000, loss: 0.058209
 >> iter 14000, loss: 0.049976
 >> iter 15000, loss: 0.059785
 >> iter 16000, loss: 0.053669
 >> iter 17000, loss: 0.087113
 >> iter 18000, loss: 0.059940
 >> iter 19000, loss: 0.067526
 >> iter 20000, loss: 0.077741
   Number of active neurons: 5
 >> iter 21000, loss: 0.051557
 >> iter 22000, loss: 0.058617
 >> iter 23000, loss: 0.090535
 >> iter 24000, loss: 0.057505
 >> iter 25000, loss: 0.059050
 >> iter 26000, loss: 0.056517
 >> iter 27000, loss: 0.063837
 >> iter 28000, loss: 0.060028
 >> iter 29000, loss: 0.054383
 >> iter 30000, loss: 0.056154
   Number of active neurons: 5
 >> iter 31000, loss: 0.052481
 >> iter 32000, loss: 0.038250
 >> iter 33000, loss: 0.052068
 >> iter 34000, loss: 0.057861
 >> iter 35000, loss: 0.050347
 >> iter 36000, loss: 0.045132
 >> iter 37000, loss: 0.061006
 >> iter 38000, loss: 0.055637
 >> iter 39000, loss: 0.043674
 >> iter 40000, loss: 0.037607
   Number of active neurons: 4
 >> iter 41000, loss: 0.043376
 >> iter 42000, loss: 0.040328
 >> iter 43000, loss: 0.051054
 >> iter 44000, loss: 0.046301
 >> iter 45000, loss: 0.044831
 >> iter 46000, loss: 0.062583
 >> iter 47000, loss: 0.055607
 >> iter 48000, loss: 0.050943
 >> iter 49000, loss: 0.055977
 >> iter 50000, loss: 0.045318
   Number of active neurons: 4
 >> iter 51000, loss: 0.038658
 >> iter 52000, loss: 0.052610
 >> iter 53000, loss: 0.056169
 >> iter 54000, loss: 0.044728
 >> iter 55000, loss: 0.057569
 >> iter 56000, loss: 0.058787
 >> iter 57000, loss: 0.062807
 >> iter 58000, loss: 0.050787
 >> iter 59000, loss: 0.051826
 >> iter 60000, loss: 0.043726
   Number of active neurons: 4
 >> iter 61000, loss: 0.050764
 >> iter 62000, loss: 0.051320
 >> iter 63000, loss: 0.040696
 >> iter 64000, loss: 0.038937
 >> iter 65000, loss: 0.052558
 >> iter 66000, loss: 0.045133
 >> iter 67000, loss: 0.065743
 >> iter 68000, loss: 0.061490
 >> iter 69000, loss: 0.073233
 >> iter 70000, loss: 0.082072
   Number of active neurons: 4
 >> iter 71000, loss: 0.066827
 >> iter 72000, loss: 0.055024
 >> iter 73000, loss: 0.038766
 >> iter 74000, loss: 0.049162
 >> iter 75000, loss: 0.045410
 >> iter 76000, loss: 0.048884
 >> iter 77000, loss: 0.068774
 >> iter 78000, loss: 0.066508
 >> iter 79000, loss: 0.059018
 >> iter 80000, loss: 0.074826
   Number of active neurons: 4
 >> iter 81000, loss: 0.043915
 >> iter 82000, loss: 0.045333
 >> iter 83000, loss: 0.057890
 >> iter 84000, loss: 0.057637
 >> iter 85000, loss: 0.057448
 >> iter 86000, loss: 0.054889
 >> iter 87000, loss: 0.039995
 >> iter 88000, loss: 0.042772
 >> iter 89000, loss: 0.031166
 >> iter 90000, loss: 0.036397
   Number of active neurons: 4
 >> iter 91000, loss: 0.049909
 >> iter 92000, loss: 0.042157
 >> iter 93000, loss: 0.045122
 >> iter 94000, loss: 0.051208
 >> iter 95000, loss: 0.069293
 >> iter 96000, loss: 0.061154
 >> iter 97000, loss: 0.051478
 >> iter 98000, loss: 0.053489
 >> iter 99000, loss: 0.045594
 >> iter 100000, loss: 0.050428
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.334239
 >> iter 2000, loss: 4.360319
 >> iter 3000, loss: 1.672153
 >> iter 4000, loss: 0.662253
 >> iter 5000, loss: 0.280944
 >> iter 6000, loss: 0.153840
 >> iter 7000, loss: 0.092056
 >> iter 8000, loss: 0.079658
 >> iter 9000, loss: 0.072873
 >> iter 10000, loss: 0.047766
   Number of active neurons: 5
 >> iter 11000, loss: 0.054344
 >> iter 12000, loss: 0.055584
 >> iter 13000, loss: 0.052307
 >> iter 14000, loss: 0.042352
 >> iter 15000, loss: 0.079581
 >> iter 16000, loss: 0.092015
 >> iter 17000, loss: 0.095402
 >> iter 18000, loss: 0.058134
 >> iter 19000, loss: 0.062967
 >> iter 20000, loss: 0.046022
   Number of active neurons: 5
 >> iter 21000, loss: 0.056712
 >> iter 22000, loss: 0.052495
 >> iter 23000, loss: 0.077088
 >> iter 24000, loss: 0.063186
 >> iter 25000, loss: 0.051361
 >> iter 26000, loss: 0.045782
 >> iter 27000, loss: 0.046594
 >> iter 28000, loss: 0.073247
 >> iter 29000, loss: 0.061986
 >> iter 30000, loss: 0.058508
   Number of active neurons: 5
 >> iter 31000, loss: 0.045120
 >> iter 32000, loss: 0.053864
 >> iter 33000, loss: 0.062086
 >> iter 34000, loss: 0.046678
 >> iter 35000, loss: 0.040696
 >> iter 36000, loss: 0.047924
 >> iter 37000, loss: 0.050285
 >> iter 38000, loss: 0.057690
 >> iter 39000, loss: 0.050626
 >> iter 40000, loss: 0.050743
   Number of active neurons: 4
 >> iter 41000, loss: 0.070777
 >> iter 42000, loss: 0.043749
 >> iter 43000, loss: 0.073490
 >> iter 44000, loss: 0.048463
 >> iter 45000, loss: 0.055698
 >> iter 46000, loss: 0.052014
 >> iter 47000, loss: 0.052918
 >> iter 48000, loss: 0.041474
 >> iter 49000, loss: 0.060612
 >> iter 50000, loss: 0.045487
   Number of active neurons: 4
 >> iter 51000, loss: 0.068548
 >> iter 52000, loss: 0.046007
 >> iter 53000, loss: 0.046600
 >> iter 54000, loss: 0.041058
 >> iter 55000, loss: 0.047416
 >> iter 56000, loss: 0.040303
 >> iter 57000, loss: 0.034544
 >> iter 58000, loss: 0.044944
 >> iter 59000, loss: 0.053863
 >> iter 60000, loss: 0.047411
   Number of active neurons: 4
 >> iter 61000, loss: 0.036322
 >> iter 62000, loss: 0.041414
 >> iter 63000, loss: 0.049819
 >> iter 64000, loss: 0.052802
 >> iter 65000, loss: 0.050827
 >> iter 66000, loss: 0.040319
 >> iter 67000, loss: 0.053985
 >> iter 68000, loss: 0.059726
 >> iter 69000, loss: 0.043909
 >> iter 70000, loss: 0.059792
   Number of active neurons: 3
 >> iter 71000, loss: 0.056907
 >> iter 72000, loss: 0.049536
 >> iter 73000, loss: 0.051206
 >> iter 74000, loss: 0.041934
 >> iter 75000, loss: 0.060998
 >> iter 76000, loss: 0.057668
 >> iter 77000, loss: 0.055485
 >> iter 78000, loss: 0.042673
 >> iter 79000, loss: 0.056799
 >> iter 80000, loss: 0.049796
   Number of active neurons: 3
 >> iter 81000, loss: 0.070138
 >> iter 82000, loss: 0.057271
 >> iter 83000, loss: 0.048510
 >> iter 84000, loss: 0.046020
 >> iter 85000, loss: 0.042385
 >> iter 86000, loss: 0.047900
 >> iter 87000, loss: 0.049393
 >> iter 88000, loss: 0.053671
 >> iter 89000, loss: 0.046272
 >> iter 90000, loss: 0.058866
   Number of active neurons: 3
 >> iter 91000, loss: 0.050066
 >> iter 92000, loss: 0.039506
 >> iter 93000, loss: 0.035051
 >> iter 94000, loss: 0.035097
 >> iter 95000, loss: 0.043543
 >> iter 96000, loss: 0.050269
 >> iter 97000, loss: 0.039104
 >> iter 98000, loss: 0.043552
 >> iter 99000, loss: 0.050574
 >> iter 100000, loss: 0.053482
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.656454
 >> iter 2000, loss: 4.584832
 >> iter 3000, loss: 1.761720
 >> iter 4000, loss: 0.730419
 >> iter 5000, loss: 0.311978
 >> iter 6000, loss: 0.163962
 >> iter 7000, loss: 0.098638
 >> iter 8000, loss: 0.060276
 >> iter 9000, loss: 0.044472
 >> iter 10000, loss: 0.035958
   Number of active neurons: 4
 >> iter 11000, loss: 0.051684
 >> iter 12000, loss: 0.060961
 >> iter 13000, loss: 0.054356
 >> iter 14000, loss: 0.050925
 >> iter 15000, loss: 0.039991
 >> iter 16000, loss: 0.049862
 >> iter 17000, loss: 0.047347
 >> iter 18000, loss: 0.050595
 >> iter 19000, loss: 0.046533
 >> iter 20000, loss: 0.037245
   Number of active neurons: 4
 >> iter 21000, loss: 0.052948
 >> iter 22000, loss: 0.046902
 >> iter 23000, loss: 0.085233
 >> iter 24000, loss: 0.067338
 >> iter 25000, loss: 0.049158
 >> iter 26000, loss: 0.054395
 >> iter 27000, loss: 0.040930
 >> iter 28000, loss: 0.040156
 >> iter 29000, loss: 0.048645
 >> iter 30000, loss: 0.062565
   Number of active neurons: 4
 >> iter 31000, loss: 0.050829
 >> iter 32000, loss: 0.051511
 >> iter 33000, loss: 0.059976
 >> iter 34000, loss: 0.051746
 >> iter 35000, loss: 0.065163
 >> iter 36000, loss: 0.061153
 >> iter 37000, loss: 0.046226
 >> iter 38000, loss: 0.038921
 >> iter 39000, loss: 0.040587
 >> iter 40000, loss: 0.068887
   Number of active neurons: 3
 >> iter 41000, loss: 0.055536
 >> iter 42000, loss: 0.049285
 >> iter 43000, loss: 0.049344
 >> iter 44000, loss: 0.050605
 >> iter 45000, loss: 0.064215
 >> iter 46000, loss: 0.045590
 >> iter 47000, loss: 0.051477
 >> iter 48000, loss: 0.035442
 >> iter 49000, loss: 0.053861
 >> iter 50000, loss: 0.049657
   Number of active neurons: 3
 >> iter 51000, loss: 0.037886
 >> iter 52000, loss: 0.050058
 >> iter 53000, loss: 0.057735
 >> iter 54000, loss: 0.046182
 >> iter 55000, loss: 0.056177
 >> iter 56000, loss: 0.037895
 >> iter 57000, loss: 0.043523
 >> iter 58000, loss: 0.044008
 >> iter 59000, loss: 0.035951
 >> iter 60000, loss: 0.042669
   Number of active neurons: 3
 >> iter 61000, loss: 0.058038
 >> iter 62000, loss: 0.050139
 >> iter 63000, loss: 0.049926
 >> iter 64000, loss: 0.042749
 >> iter 65000, loss: 0.036688
 >> iter 66000, loss: 0.048171
 >> iter 67000, loss: 0.049537
 >> iter 68000, loss: 0.041163
 >> iter 69000, loss: 0.038943
 >> iter 70000, loss: 0.032889
   Number of active neurons: 2
 >> iter 71000, loss: 0.052410
 >> iter 72000, loss: 0.043120
 >> iter 73000, loss: 0.061765
 >> iter 74000, loss: 0.054629
 >> iter 75000, loss: 0.045065
 >> iter 76000, loss: 0.049488
 >> iter 77000, loss: 0.044212
 >> iter 78000, loss: 0.038146
 >> iter 79000, loss: 0.031138
 >> iter 80000, loss: 0.055413
   Number of active neurons: 2
 >> iter 81000, loss: 0.055471
 >> iter 82000, loss: 0.032535
 >> iter 83000, loss: 0.052864
 >> iter 84000, loss: 0.039416
 >> iter 85000, loss: 0.042454
 >> iter 86000, loss: 0.055334
 >> iter 87000, loss: 0.043320
 >> iter 88000, loss: 0.039023
 >> iter 89000, loss: 0.053436
 >> iter 90000, loss: 0.044584
   Number of active neurons: 2
 >> iter 91000, loss: 0.032866
 >> iter 92000, loss: 0.040893
 >> iter 93000, loss: 0.040762
 >> iter 94000, loss: 0.044328
 >> iter 95000, loss: 0.041120
 >> iter 96000, loss: 0.044790
 >> iter 97000, loss: 0.051454
 >> iter 98000, loss: 0.037372
 >> iter 99000, loss: 0.038090
 >> iter 100000, loss: 0.035361
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.420848
 >> iter 2000, loss: 4.442019
 >> iter 3000, loss: 1.735376
 >> iter 4000, loss: 0.680293
 >> iter 5000, loss: 0.338461
 >> iter 6000, loss: 0.157409
 >> iter 7000, loss: 0.096495
 >> iter 8000, loss: 0.081251
 >> iter 9000, loss: 0.074942
 >> iter 10000, loss: 0.060877
   Number of active neurons: 5
 >> iter 11000, loss: 0.056084
 >> iter 12000, loss: 0.060015
 >> iter 13000, loss: 0.057833
 >> iter 14000, loss: 0.051897
 >> iter 15000, loss: 0.071291
 >> iter 16000, loss: 0.065483
 >> iter 17000, loss: 0.057823
 >> iter 18000, loss: 0.044788
 >> iter 19000, loss: 0.049332
 >> iter 20000, loss: 0.061678
   Number of active neurons: 4
 >> iter 21000, loss: 0.069565
 >> iter 22000, loss: 0.054450
 >> iter 23000, loss: 0.051598
 >> iter 24000, loss: 0.066227
 >> iter 25000, loss: 0.058364
 >> iter 26000, loss: 0.052591
 >> iter 27000, loss: 0.054423
 >> iter 28000, loss: 0.045873
 >> iter 29000, loss: 0.048852
 >> iter 30000, loss: 0.050183
   Number of active neurons: 4
 >> iter 31000, loss: 0.049512
 >> iter 32000, loss: 0.041416
 >> iter 33000, loss: 0.073091
 >> iter 34000, loss: 0.059153
 >> iter 35000, loss: 0.043783
 >> iter 36000, loss: 0.052289
 >> iter 37000, loss: 0.069314
 >> iter 38000, loss: 0.064700
 >> iter 39000, loss: 0.046275
 >> iter 40000, loss: 0.052074
   Number of active neurons: 3
 >> iter 41000, loss: 0.039494
 >> iter 42000, loss: 0.041595
 >> iter 43000, loss: 0.057584
 >> iter 44000, loss: 0.039555
 >> iter 45000, loss: 0.034641
 >> iter 46000, loss: 0.052109
 >> iter 47000, loss: 0.045772
 >> iter 48000, loss: 0.059514
 >> iter 49000, loss: 0.049939
 >> iter 50000, loss: 0.053443
   Number of active neurons: 3
 >> iter 51000, loss: 0.060739
 >> iter 52000, loss: 0.058119
 >> iter 53000, loss: 0.054117
 >> iter 54000, loss: 0.053033
 >> iter 55000, loss: 0.053192
 >> iter 56000, loss: 0.048560
 >> iter 57000, loss: 0.048139
 >> iter 58000, loss: 0.042439
 >> iter 59000, loss: 0.044853
 >> iter 60000, loss: 0.048321
   Number of active neurons: 3
 >> iter 61000, loss: 0.047042
 >> iter 62000, loss: 0.042437
 >> iter 63000, loss: 0.050897
 >> iter 64000, loss: 0.046723
 >> iter 65000, loss: 0.050899
 >> iter 66000, loss: 0.041886
 >> iter 67000, loss: 0.048605
 >> iter 68000, loss: 0.046205
 >> iter 69000, loss: 0.043061
 >> iter 70000, loss: 0.047062
   Number of active neurons: 2
 >> iter 71000, loss: 0.058774
 >> iter 72000, loss: 0.038940
 >> iter 73000, loss: 0.059093
 >> iter 74000, loss: 0.056543
 >> iter 75000, loss: 0.044190
 >> iter 76000, loss: 0.045212
 >> iter 77000, loss: 0.037147
 >> iter 78000, loss: 0.047562
 >> iter 79000, loss: 0.061996
 >> iter 80000, loss: 0.041545
   Number of active neurons: 2
 >> iter 81000, loss: 0.047607
 >> iter 82000, loss: 0.036655
 >> iter 83000, loss: 0.041307
 >> iter 84000, loss: 0.031399
 >> iter 85000, loss: 0.052263
 >> iter 86000, loss: 0.042728
 >> iter 87000, loss: 0.055088
 >> iter 88000, loss: 0.046677
 >> iter 89000, loss: 0.058118
 >> iter 90000, loss: 0.048717
   Number of active neurons: 2
 >> iter 91000, loss: 0.052443
 >> iter 92000, loss: 0.035491
 >> iter 93000, loss: 0.048298
 >> iter 94000, loss: 0.035222
 >> iter 95000, loss: 0.027116
 >> iter 96000, loss: 0.051916
 >> iter 97000, loss: 0.076011
 >> iter 98000, loss: 0.055250
 >> iter 99000, loss: 0.040554
 >> iter 100000, loss: 0.053013
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.413890
 >> iter 2000, loss: 4.382176
 >> iter 3000, loss: 1.699623
 >> iter 4000, loss: 0.683918
 >> iter 5000, loss: 0.286477
 >> iter 6000, loss: 0.154541
 >> iter 7000, loss: 0.095877
 >> iter 8000, loss: 0.061992
 >> iter 9000, loss: 0.068360
 >> iter 10000, loss: 0.060331
   Number of active neurons: 5
 >> iter 11000, loss: 0.045877
 >> iter 12000, loss: 0.052423
 >> iter 13000, loss: 0.050477
 >> iter 14000, loss: 0.046140
 >> iter 15000, loss: 0.061904
 >> iter 16000, loss: 0.058169
 >> iter 17000, loss: 0.058739
 >> iter 18000, loss: 0.061410
 >> iter 19000, loss: 0.048490
 >> iter 20000, loss: 0.046837
   Number of active neurons: 5
 >> iter 21000, loss: 0.049028
 >> iter 22000, loss: 0.052667
 >> iter 23000, loss: 0.071201
 >> iter 24000, loss: 0.052669
 >> iter 25000, loss: 0.040092
 >> iter 26000, loss: 0.057874
 >> iter 27000, loss: 0.054333
 >> iter 28000, loss: 0.047424
 >> iter 29000, loss: 0.059600
 >> iter 30000, loss: 0.075586
   Number of active neurons: 5
 >> iter 31000, loss: 0.055144
 >> iter 32000, loss: 0.057326
 >> iter 33000, loss: 0.042425
 >> iter 34000, loss: 0.050362
 >> iter 35000, loss: 0.060176
 >> iter 36000, loss: 0.066224
 >> iter 37000, loss: 0.051037
 >> iter 38000, loss: 0.050670
 >> iter 39000, loss: 0.067839
 >> iter 40000, loss: 0.050227
   Number of active neurons: 5
 >> iter 41000, loss: 0.042413
 >> iter 42000, loss: 0.059548
 >> iter 43000, loss: 0.056817
 >> iter 44000, loss: 0.054844
 >> iter 45000, loss: 0.043363
 >> iter 46000, loss: 0.049689
 >> iter 47000, loss: 0.042107
 >> iter 48000, loss: 0.056086
 >> iter 49000, loss: 0.049645
 >> iter 50000, loss: 0.046486
   Number of active neurons: 4
 >> iter 51000, loss: 0.043311
 >> iter 52000, loss: 0.052586
 >> iter 53000, loss: 0.051764
 >> iter 54000, loss: 0.051099
 >> iter 55000, loss: 0.055054
 >> iter 56000, loss: 0.052501
 >> iter 57000, loss: 0.042596
 >> iter 58000, loss: 0.052121
 >> iter 59000, loss: 0.077874
 >> iter 60000, loss: 0.053372
   Number of active neurons: 4
 >> iter 61000, loss: 0.072366
 >> iter 62000, loss: 0.043115
 >> iter 63000, loss: 0.046355
 >> iter 64000, loss: 0.076164
 >> iter 65000, loss: 0.063641
 >> iter 66000, loss: 0.050659
 >> iter 67000, loss: 0.047991
 >> iter 68000, loss: 0.038089
 >> iter 69000, loss: 0.035489
 >> iter 70000, loss: 0.056502
   Number of active neurons: 3
 >> iter 71000, loss: 0.059756
 >> iter 72000, loss: 0.047105
 >> iter 73000, loss: 0.050478
 >> iter 74000, loss: 0.041723
 >> iter 75000, loss: 0.046299
 >> iter 76000, loss: 0.055251
 >> iter 77000, loss: 0.044419
 >> iter 78000, loss: 0.060047
 >> iter 79000, loss: 0.055599
 >> iter 80000, loss: 0.036854
   Number of active neurons: 3
 >> iter 81000, loss: 0.051446
 >> iter 82000, loss: 0.070763
 >> iter 83000, loss: 0.070313
 >> iter 84000, loss: 0.059518
 >> iter 85000, loss: 0.038140
 >> iter 86000, loss: 0.030903
 >> iter 87000, loss: 0.045513
 >> iter 88000, loss: 0.039220
 >> iter 89000, loss: 0.039879
 >> iter 90000, loss: 0.032949
   Number of active neurons: 3
 >> iter 91000, loss: 0.052704
 >> iter 92000, loss: 0.051743
 >> iter 93000, loss: 0.047988
 >> iter 94000, loss: 0.069961
 >> iter 95000, loss: 0.062533
 >> iter 96000, loss: 0.042015
 >> iter 97000, loss: 0.034545
 >> iter 98000, loss: 0.046641
 >> iter 99000, loss: 0.047435
 >> iter 100000, loss: 0.049472
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.413957
 >> iter 2000, loss: 4.426326
 >> iter 3000, loss: 1.722383
 >> iter 4000, loss: 0.700019
 >> iter 5000, loss: 0.304155
 >> iter 6000, loss: 0.151401
 >> iter 7000, loss: 0.113263
 >> iter 8000, loss: 0.089180
 >> iter 9000, loss: 0.080753
 >> iter 10000, loss: 0.071961
   Number of active neurons: 5
 >> iter 11000, loss: 0.056663
 >> iter 12000, loss: 0.068681
 >> iter 13000, loss: 0.058369
 >> iter 14000, loss: 0.043305
 >> iter 15000, loss: 0.064182
 >> iter 16000, loss: 0.049063
 >> iter 17000, loss: 0.074394
 >> iter 18000, loss: 0.064732
 >> iter 19000, loss: 0.065863
 >> iter 20000, loss: 0.052138
   Number of active neurons: 5
 >> iter 21000, loss: 0.056241
 >> iter 22000, loss: 0.041847
 >> iter 23000, loss: 0.058625
 >> iter 24000, loss: 0.063846
 >> iter 25000, loss: 0.054120
 >> iter 26000, loss: 0.067715
 >> iter 27000, loss: 0.046458
 >> iter 28000, loss: 0.047988
 >> iter 29000, loss: 0.063464
 >> iter 30000, loss: 0.067073
   Number of active neurons: 5
 >> iter 31000, loss: 0.046450
 >> iter 32000, loss: 0.048071
 >> iter 33000, loss: 0.072042
 >> iter 34000, loss: 0.052053
 >> iter 35000, loss: 0.055527
 >> iter 36000, loss: 0.064281
 >> iter 37000, loss: 0.051554
 >> iter 38000, loss: 0.049806
 >> iter 39000, loss: 0.067533
 >> iter 40000, loss: 0.042326
   Number of active neurons: 4
 >> iter 41000, loss: 0.045153
 >> iter 42000, loss: 0.052751
 >> iter 43000, loss: 0.050409
 >> iter 44000, loss: 0.055039
 >> iter 45000, loss: 0.069353
 >> iter 46000, loss: 0.070383
 >> iter 47000, loss: 0.051581
 >> iter 48000, loss: 0.052233
 >> iter 49000, loss: 0.058598
 >> iter 50000, loss: 0.056844
   Number of active neurons: 4
 >> iter 51000, loss: 0.056637
 >> iter 52000, loss: 0.039930
 >> iter 53000, loss: 0.045484
 >> iter 54000, loss: 0.043652
 >> iter 55000, loss: 0.034905
 >> iter 56000, loss: 0.064169
 >> iter 57000, loss: 0.070867
 >> iter 58000, loss: 0.050723
 >> iter 59000, loss: 0.071679
 >> iter 60000, loss: 0.069959
   Number of active neurons: 4
 >> iter 61000, loss: 0.054028
 >> iter 62000, loss: 0.042033
 >> iter 63000, loss: 0.043984
 >> iter 64000, loss: 0.051121
 >> iter 65000, loss: 0.045020
 >> iter 66000, loss: 0.034013
 >> iter 67000, loss: 0.042692
 >> iter 68000, loss: 0.042289
 >> iter 69000, loss: 0.069900
 >> iter 70000, loss: 0.072576
   Number of active neurons: 4
 >> iter 71000, loss: 0.057535
 >> iter 72000, loss: 0.047487
 >> iter 73000, loss: 0.052956
 >> iter 74000, loss: 0.063325
 >> iter 75000, loss: 0.058499
 >> iter 76000, loss: 0.049585
 >> iter 77000, loss: 0.040170
 >> iter 78000, loss: 0.051969
 >> iter 79000, loss: 0.053592
 >> iter 80000, loss: 0.061301
   Number of active neurons: 3
 >> iter 81000, loss: 0.066031
 >> iter 82000, loss: 0.050845
 >> iter 83000, loss: 0.051183
 >> iter 84000, loss: 0.048424
 >> iter 85000, loss: 0.035280
 >> iter 86000, loss: 0.033978
 >> iter 87000, loss: 0.035089
 >> iter 88000, loss: 0.030194
 >> iter 89000, loss: 0.037277
 >> iter 90000, loss: 0.032475
   Number of active neurons: 3
 >> iter 91000, loss: 0.041913
 >> iter 92000, loss: 0.047698
 >> iter 93000, loss: 0.078176
 >> iter 94000, loss: 0.065966
 >> iter 95000, loss: 0.052296
 >> iter 96000, loss: 0.040153
 >> iter 97000, loss: 0.061667
 >> iter 98000, loss: 0.053259
 >> iter 99000, loss: 0.059142
 >> iter 100000, loss: 0.059745
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.383914
 >> iter 2000, loss: 4.361549
 >> iter 3000, loss: 1.676950
 >> iter 4000, loss: 0.703435
 >> iter 5000, loss: 0.312909
 >> iter 6000, loss: 0.153461
 >> iter 7000, loss: 0.095190
 >> iter 8000, loss: 0.063130
 >> iter 9000, loss: 0.063924
 >> iter 10000, loss: 0.069300
   Number of active neurons: 5
 >> iter 11000, loss: 0.060190
 >> iter 12000, loss: 0.054725
 >> iter 13000, loss: 0.053341
 >> iter 14000, loss: 0.050973
 >> iter 15000, loss: 0.101445
 >> iter 16000, loss: 0.097398
 >> iter 17000, loss: 0.087125
 >> iter 18000, loss: 0.073932
 >> iter 19000, loss: 0.059050
 >> iter 20000, loss: 0.063175
   Number of active neurons: 4
 >> iter 21000, loss: 0.050949
 >> iter 22000, loss: 0.054563
 >> iter 23000, loss: 0.058668
 >> iter 24000, loss: 0.050937
 >> iter 25000, loss: 0.079122
 >> iter 26000, loss: 0.044467
 >> iter 27000, loss: 0.035258
 >> iter 28000, loss: 0.033569
 >> iter 29000, loss: 0.039435
 >> iter 30000, loss: 0.053201
   Number of active neurons: 4
 >> iter 31000, loss: 0.048710
 >> iter 32000, loss: 0.056320
 >> iter 33000, loss: 0.049872
 >> iter 34000, loss: 0.052221
 >> iter 35000, loss: 0.055338
 >> iter 36000, loss: 0.065600
 >> iter 37000, loss: 0.047650
 >> iter 38000, loss: 0.040234
 >> iter 39000, loss: 0.040645
 >> iter 40000, loss: 0.044496
   Number of active neurons: 4
 >> iter 41000, loss: 0.046072
 >> iter 42000, loss: 0.050861
 >> iter 43000, loss: 0.039068
 >> iter 44000, loss: 0.046892
 >> iter 45000, loss: 0.035065
 >> iter 46000, loss: 0.046318
 >> iter 47000, loss: 0.046401
 >> iter 48000, loss: 0.036594
 >> iter 49000, loss: 0.043263
 >> iter 50000, loss: 0.047155
   Number of active neurons: 4
 >> iter 51000, loss: 0.057323
 >> iter 52000, loss: 0.047344
 >> iter 53000, loss: 0.051258
 >> iter 54000, loss: 0.057913
 >> iter 55000, loss: 0.046349
 >> iter 56000, loss: 0.052184
 >> iter 57000, loss: 0.039032
 >> iter 58000, loss: 0.028681
 >> iter 59000, loss: 0.083894
 >> iter 60000, loss: 0.071314
   Number of active neurons: 4
 >> iter 61000, loss: 0.066690
 >> iter 62000, loss: 0.050392
 >> iter 63000, loss: 0.055147
 >> iter 64000, loss: 0.053959
 >> iter 65000, loss: 0.050176
 >> iter 66000, loss: 0.052344
 >> iter 67000, loss: 0.042520
 >> iter 68000, loss: 0.048843
 >> iter 69000, loss: 0.035116
 >> iter 70000, loss: 0.043087
   Number of active neurons: 4
 >> iter 71000, loss: 0.037684
 >> iter 72000, loss: 0.038602
 >> iter 73000, loss: 0.052089
 >> iter 74000, loss: 0.051241
 >> iter 75000, loss: 0.053059
 >> iter 76000, loss: 0.056592
 >> iter 77000, loss: 0.067753
 >> iter 78000, loss: 0.062488
 >> iter 79000, loss: 0.060677
 >> iter 80000, loss: 0.049487
   Number of active neurons: 4
 >> iter 81000, loss: 0.052263
 >> iter 82000, loss: 0.047721
 >> iter 83000, loss: 0.064323
 >> iter 84000, loss: 0.051961
 >> iter 85000, loss: 0.042099
 >> iter 86000, loss: 0.054985
 >> iter 87000, loss: 0.038107
 >> iter 88000, loss: 0.060136
 >> iter 89000, loss: 0.039360
 >> iter 90000, loss: 0.043562
   Number of active neurons: 3
 >> iter 91000, loss: 0.033941
 >> iter 92000, loss: 0.032834
 >> iter 93000, loss: 0.036434
 >> iter 94000, loss: 0.042835
 >> iter 95000, loss: 0.041612
 >> iter 96000, loss: 0.039714
 >> iter 97000, loss: 0.048476
 >> iter 98000, loss: 0.063998
 >> iter 99000, loss: 0.056908
 >> iter 100000, loss: 0.050248
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.378465
 >> iter 2000, loss: 4.338858
 >> iter 3000, loss: 1.686288
 >> iter 4000, loss: 0.678394
 >> iter 5000, loss: 0.317593
 >> iter 6000, loss: 0.187403
 >> iter 7000, loss: 0.120775
 >> iter 8000, loss: 0.086296
 >> iter 9000, loss: 0.065760
 >> iter 10000, loss: 0.051181
   Number of active neurons: 5
 >> iter 11000, loss: 0.079409
 >> iter 12000, loss: 0.065391
 >> iter 13000, loss: 0.053170
 >> iter 14000, loss: 0.043348
 >> iter 15000, loss: 0.036850
 >> iter 16000, loss: 0.057786
 >> iter 17000, loss: 0.059275
 >> iter 18000, loss: 0.049060
 >> iter 19000, loss: 0.047606
 >> iter 20000, loss: 0.059850
   Number of active neurons: 5
 >> iter 21000, loss: 0.065352
 >> iter 22000, loss: 0.052588
 >> iter 23000, loss: 0.052949
 >> iter 24000, loss: 0.043816
 >> iter 25000, loss: 0.053523
 >> iter 26000, loss: 0.047057
 >> iter 27000, loss: 0.043567
 >> iter 28000, loss: 0.051807
 >> iter 29000, loss: 0.043790
 >> iter 30000, loss: 0.062176
   Number of active neurons: 5
 >> iter 31000, loss: 0.059371
 >> iter 32000, loss: 0.074576
 >> iter 33000, loss: 0.060891
 >> iter 34000, loss: 0.061231
 >> iter 35000, loss: 0.045872
 >> iter 36000, loss: 0.068580
 >> iter 37000, loss: 0.054489
 >> iter 38000, loss: 0.051339
 >> iter 39000, loss: 0.045467
 >> iter 40000, loss: 0.042571
   Number of active neurons: 5
 >> iter 41000, loss: 0.038500
 >> iter 42000, loss: 0.050008
 >> iter 43000, loss: 0.034498
 >> iter 44000, loss: 0.039939
 >> iter 45000, loss: 0.056587
 >> iter 46000, loss: 0.053272
 >> iter 47000, loss: 0.049163
 >> iter 48000, loss: 0.044105
 >> iter 49000, loss: 0.043045
 >> iter 50000, loss: 0.044067
   Number of active neurons: 4
 >> iter 51000, loss: 0.038007
 >> iter 52000, loss: 0.036956
 >> iter 53000, loss: 0.038154
 >> iter 54000, loss: 0.041372
 >> iter 55000, loss: 0.064839
 >> iter 56000, loss: 0.061914
 >> iter 57000, loss: 0.043671
 >> iter 58000, loss: 0.052051
 >> iter 59000, loss: 0.043709
 >> iter 60000, loss: 0.053193
   Number of active neurons: 4
 >> iter 61000, loss: 0.038659
 >> iter 62000, loss: 0.030028
 >> iter 63000, loss: 0.056214
 >> iter 64000, loss: 0.061178
 >> iter 65000, loss: 0.048723
 >> iter 66000, loss: 0.041577
 >> iter 67000, loss: 0.048217
 >> iter 68000, loss: 0.043395
 >> iter 69000, loss: 0.046586
 >> iter 70000, loss: 0.038710
   Number of active neurons: 3
 >> iter 71000, loss: 0.040369
 >> iter 72000, loss: 0.041360
 >> iter 73000, loss: 0.061935
 >> iter 74000, loss: 0.052633
 >> iter 75000, loss: 0.044885
 >> iter 76000, loss: 0.035322
 >> iter 77000, loss: 0.057444
 >> iter 78000, loss: 0.050661
 >> iter 79000, loss: 0.041985
 >> iter 80000, loss: 0.053391
   Number of active neurons: 3
 >> iter 81000, loss: 0.073629
 >> iter 82000, loss: 0.058162
 >> iter 83000, loss: 0.047330
 >> iter 84000, loss: 0.043404
 >> iter 85000, loss: 0.045773
 >> iter 86000, loss: 0.035806
 >> iter 87000, loss: 0.035712
 >> iter 88000, loss: 0.040242
 >> iter 89000, loss: 0.064556
 >> iter 90000, loss: 0.044161
   Number of active neurons: 3
 >> iter 91000, loss: 0.052934
 >> iter 92000, loss: 0.041176
 >> iter 93000, loss: 0.058991
 >> iter 94000, loss: 0.054647
 >> iter 95000, loss: 0.064069
 >> iter 96000, loss: 0.055005
 >> iter 97000, loss: 0.056323
 >> iter 98000, loss: 0.038048
 >> iter 99000, loss: 0.052435
 >> iter 100000, loss: 0.041150
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.317363
 >> iter 2000, loss: 4.330901
 >> iter 3000, loss: 1.655603
 >> iter 4000, loss: 0.666231
 >> iter 5000, loss: 0.313905
 >> iter 6000, loss: 0.175550
 >> iter 7000, loss: 0.110172
 >> iter 8000, loss: 0.089493
 >> iter 9000, loss: 0.056620
 >> iter 10000, loss: 0.052147
   Number of active neurons: 4
 >> iter 11000, loss: 0.060961
 >> iter 12000, loss: 0.043466
 >> iter 13000, loss: 0.037886
 >> iter 14000, loss: 0.044774
 >> iter 15000, loss: 0.041605
 >> iter 16000, loss: 0.052371
 >> iter 17000, loss: 0.045585
 >> iter 18000, loss: 0.037093
 >> iter 19000, loss: 0.048384
 >> iter 20000, loss: 0.041077
   Number of active neurons: 4
 >> iter 21000, loss: 0.076735
 >> iter 22000, loss: 0.059967
 >> iter 23000, loss: 0.073452
 >> iter 24000, loss: 0.047849
 >> iter 25000, loss: 0.066399
 >> iter 26000, loss: 0.064147
 >> iter 27000, loss: 0.063290
 >> iter 28000, loss: 0.053246
 >> iter 29000, loss: 0.050743
 >> iter 30000, loss: 0.064832
   Number of active neurons: 4
 >> iter 31000, loss: 0.058693
 >> iter 32000, loss: 0.064693
 >> iter 33000, loss: 0.084799
 >> iter 34000, loss: 0.081622
 >> iter 35000, loss: 0.064402
 >> iter 36000, loss: 0.039309
 >> iter 37000, loss: 0.043878
 >> iter 38000, loss: 0.053408
 >> iter 39000, loss: 0.059892
 >> iter 40000, loss: 0.054658
   Number of active neurons: 4
 >> iter 41000, loss: 0.041162
 >> iter 42000, loss: 0.060723
 >> iter 43000, loss: 0.052743
 >> iter 44000, loss: 0.037223
 >> iter 45000, loss: 0.039915
 >> iter 46000, loss: 0.055029
 >> iter 47000, loss: 0.055557
 >> iter 48000, loss: 0.059953
 >> iter 49000, loss: 0.046545
 >> iter 50000, loss: 0.047967
   Number of active neurons: 3
 >> iter 51000, loss: 0.038170
 >> iter 52000, loss: 0.031055
 >> iter 53000, loss: 0.030350
 >> iter 54000, loss: 0.035274
 >> iter 55000, loss: 0.041256
 >> iter 56000, loss: 0.044599
 >> iter 57000, loss: 0.040794
 >> iter 58000, loss: 0.049472
 >> iter 59000, loss: 0.046633
 >> iter 60000, loss: 0.045841
   Number of active neurons: 3
 >> iter 61000, loss: 0.077977
 >> iter 62000, loss: 0.055886
 >> iter 63000, loss: 0.040852
 >> iter 64000, loss: 0.059157
 >> iter 65000, loss: 0.058564
 >> iter 66000, loss: 0.056574
 >> iter 67000, loss: 0.061061
 >> iter 68000, loss: 0.045808
 >> iter 69000, loss: 0.043327
 >> iter 70000, loss: 0.043247
   Number of active neurons: 3
 >> iter 71000, loss: 0.036437
 >> iter 72000, loss: 0.046997
 >> iter 73000, loss: 0.054119
 >> iter 74000, loss: 0.040605
 >> iter 75000, loss: 0.048027
 >> iter 76000, loss: 0.055667
 >> iter 77000, loss: 0.056554
 >> iter 78000, loss: 0.041522
 >> iter 79000, loss: 0.068083
 >> iter 80000, loss: 0.047135
   Number of active neurons: 3
 >> iter 81000, loss: 0.044524
 >> iter 82000, loss: 0.041110
 >> iter 83000, loss: 0.061520
 >> iter 84000, loss: 0.039871
 >> iter 85000, loss: 0.060553
 >> iter 86000, loss: 0.059314
 >> iter 87000, loss: 0.040127
 >> iter 88000, loss: 0.037547
 >> iter 89000, loss: 0.067572
 >> iter 90000, loss: 0.051331
   Number of active neurons: 3
 >> iter 91000, loss: 0.046331
 >> iter 92000, loss: 0.045452
 >> iter 93000, loss: 0.043353
 >> iter 94000, loss: 0.064975
 >> iter 95000, loss: 0.040642
 >> iter 96000, loss: 0.054959
 >> iter 97000, loss: 0.048713
 >> iter 98000, loss: 0.035117
 >> iter 99000, loss: 0.050584
 >> iter 100000, loss: 0.054617
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

