 > Problema: tomita4nueva
 > Args:
   - Hidden size: 14
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.386755
 >> iter 2000, loss: 8.704355
 >> iter 3000, loss: 4.050090
 >> iter 4000, loss: 1.908538
 >> iter 5000, loss: 1.096391
 >> iter 6000, loss: 0.576212
 >> iter 7000, loss: 0.387650
 >> iter 8000, loss: 0.290433
 >> iter 9000, loss: 0.471773
 >> iter 10000, loss: 0.310383
   Number of active neurons: 5
 >> iter 11000, loss: 0.531195
 >> iter 12000, loss: 0.285778
 >> iter 13000, loss: 0.204011
 >> iter 14000, loss: 0.228073
 >> iter 15000, loss: 0.494544
 >> iter 16000, loss: 0.362912
 >> iter 17000, loss: 0.321591
 >> iter 18000, loss: 0.249544
 >> iter 19000, loss: 0.120670
 >> iter 20000, loss: 0.309100
   Number of active neurons: 3
 >> iter 21000, loss: 0.207548
 >> iter 22000, loss: 0.177391
 >> iter 23000, loss: 0.381894
 >> iter 24000, loss: 0.314074
 >> iter 25000, loss: 0.253147
 >> iter 26000, loss: 0.439453
 >> iter 27000, loss: 0.247901
 >> iter 28000, loss: 0.191478
 >> iter 29000, loss: 0.255919
 >> iter 30000, loss: 0.168319
   Number of active neurons: 3
 >> iter 31000, loss: 0.111935
 >> iter 32000, loss: 0.117933
 >> iter 33000, loss: 0.169076
 >> iter 34000, loss: 0.322034
 >> iter 35000, loss: 0.365690
 >> iter 36000, loss: 0.300769
 >> iter 37000, loss: 0.225254
 >> iter 38000, loss: 0.285632
 >> iter 39000, loss: 0.207053
 >> iter 40000, loss: 0.208199
   Number of active neurons: 3
 >> iter 41000, loss: 0.185582
 >> iter 42000, loss: 0.155686
 >> iter 43000, loss: 0.231158
 >> iter 44000, loss: 0.413016
 >> iter 45000, loss: 0.231474
 >> iter 46000, loss: 0.181881
 >> iter 47000, loss: 0.149939
 >> iter 48000, loss: 0.145313
 >> iter 49000, loss: 0.289947
 >> iter 50000, loss: 0.334282
   Number of active neurons: 3
 >> iter 51000, loss: 0.321372
 >> iter 52000, loss: 0.257776
 >> iter 53000, loss: 0.143912
 >> iter 54000, loss: 0.205798
 >> iter 55000, loss: 0.266677
 >> iter 56000, loss: 0.310568
 >> iter 57000, loss: 0.293762
 >> iter 58000, loss: 0.149702
 >> iter 59000, loss: 0.422179
 >> iter 60000, loss: 0.237781
   Number of active neurons: 3
 >> iter 61000, loss: 0.325791
 >> iter 62000, loss: 0.291946
 >> iter 63000, loss: 0.299814
 >> iter 64000, loss: 0.242225
 >> iter 65000, loss: 0.172615
 >> iter 66000, loss: 0.176953
 >> iter 67000, loss: 0.228474
 >> iter 68000, loss: 0.188857
 >> iter 69000, loss: 0.195912
 >> iter 70000, loss: 0.152810
   Number of active neurons: 3
 >> iter 71000, loss: 0.087895
 >> iter 72000, loss: 0.066560
 >> iter 73000, loss: 0.119733
 >> iter 74000, loss: 0.155983
 >> iter 75000, loss: 0.222166
 >> iter 76000, loss: 0.302627
 >> iter 77000, loss: 0.219255
 >> iter 78000, loss: 0.182533
 >> iter 79000, loss: 0.294532
 >> iter 80000, loss: 0.267236
   Number of active neurons: 3
 >> iter 81000, loss: 0.174776
 >> iter 82000, loss: 0.304405
 >> iter 83000, loss: 0.251290
 >> iter 84000, loss: 0.273466
 >> iter 85000, loss: 0.160268
 >> iter 86000, loss: 0.221838
 >> iter 87000, loss: 0.147398
 >> iter 88000, loss: 0.207843
 >> iter 89000, loss: 0.203232
 >> iter 90000, loss: 0.135253
   Number of active neurons: 3
 >> iter 91000, loss: 0.231965
 >> iter 92000, loss: 0.166956
 >> iter 93000, loss: 0.094862
 >> iter 94000, loss: 0.226178
 >> iter 95000, loss: 0.266262
 >> iter 96000, loss: 0.349151
 >> iter 97000, loss: 0.229108
 >> iter 98000, loss: 0.268932
 >> iter 99000, loss: 0.189321
 >> iter 100000, loss: 0.176583
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.378338
 >> iter 2000, loss: 8.566775
 >> iter 3000, loss: 3.898585
 >> iter 4000, loss: 1.896527
 >> iter 5000, loss: 1.192148
 >> iter 6000, loss: 0.735955
 >> iter 7000, loss: 0.468307
 >> iter 8000, loss: 0.500489
 >> iter 9000, loss: 0.651711
 >> iter 10000, loss: 0.553368
   Number of active neurons: 6
 >> iter 11000, loss: 0.491749
 >> iter 12000, loss: 0.480371
 >> iter 13000, loss: 0.421056
 >> iter 14000, loss: 0.535557
 >> iter 15000, loss: 0.323726
 >> iter 16000, loss: 0.581109
 >> iter 17000, loss: 0.430300
 >> iter 18000, loss: 0.646658
 >> iter 19000, loss: 0.449671
 >> iter 20000, loss: 0.463934
   Number of active neurons: 6
 >> iter 21000, loss: 0.394914
 >> iter 22000, loss: 0.568197
 >> iter 23000, loss: 0.617023
 >> iter 24000, loss: 0.376851
 >> iter 25000, loss: 0.357813
 >> iter 26000, loss: 0.305912
 >> iter 27000, loss: 0.397426
 >> iter 28000, loss: 0.438227
 >> iter 29000, loss: 0.408505
 >> iter 30000, loss: 0.485218
   Number of active neurons: 5
 >> iter 31000, loss: 0.418501
 >> iter 32000, loss: 0.391326
 >> iter 33000, loss: 0.238955
 >> iter 34000, loss: 0.279249
 >> iter 35000, loss: 0.328997
 >> iter 36000, loss: 0.220062
 >> iter 37000, loss: 0.167304
 >> iter 38000, loss: 0.241994
 >> iter 39000, loss: 0.395233
 >> iter 40000, loss: 0.498573
   Number of active neurons: 5
 >> iter 41000, loss: 0.614934
 >> iter 42000, loss: 0.361208
 >> iter 43000, loss: 0.552481
 >> iter 44000, loss: 0.491031
 >> iter 45000, loss: 0.387131
 >> iter 46000, loss: 0.266413
 >> iter 47000, loss: 0.541244
 >> iter 48000, loss: 0.335544
 >> iter 49000, loss: 0.464099
 >> iter 50000, loss: 0.295391
   Number of active neurons: 5
 >> iter 51000, loss: 0.246502
 >> iter 52000, loss: 0.368890
 >> iter 53000, loss: 0.415893
 >> iter 54000, loss: 0.425257
 >> iter 55000, loss: 0.484649
 >> iter 56000, loss: 0.334169
 >> iter 57000, loss: 0.497213
 >> iter 58000, loss: 0.400241
 >> iter 59000, loss: 0.320336
 >> iter 60000, loss: 0.606235
   Number of active neurons: 5
 >> iter 61000, loss: 0.677902
 >> iter 62000, loss: 0.427417
 >> iter 63000, loss: 0.515103
 >> iter 64000, loss: 0.336348
 >> iter 65000, loss: 0.437213
 >> iter 66000, loss: 0.316819
 >> iter 67000, loss: 0.195553
 >> iter 68000, loss: 0.230447
 >> iter 69000, loss: 0.185154
 >> iter 70000, loss: 0.355843
   Number of active neurons: 5
 >> iter 71000, loss: 0.324611
 >> iter 72000, loss: 0.344578
 >> iter 73000, loss: 0.249062
 >> iter 74000, loss: 0.430637
 >> iter 75000, loss: 0.350979
 >> iter 76000, loss: 0.249876
 >> iter 77000, loss: 0.250098
 >> iter 78000, loss: 0.289178
 >> iter 79000, loss: 0.180019
 >> iter 80000, loss: 0.190410
   Number of active neurons: 5
 >> iter 81000, loss: 0.299047
 >> iter 82000, loss: 0.288721
 >> iter 83000, loss: 0.429679
 >> iter 84000, loss: 0.271092
 >> iter 85000, loss: 0.323899
 >> iter 86000, loss: 0.376571
 >> iter 87000, loss: 0.324921
 >> iter 88000, loss: 0.317313
 >> iter 89000, loss: 0.219112
 >> iter 90000, loss: 0.200136
   Number of active neurons: 4
 >> iter 91000, loss: 0.257242
 >> iter 92000, loss: 0.385544
 >> iter 93000, loss: 0.360926
 >> iter 94000, loss: 0.282855
 >> iter 95000, loss: 0.377042
 >> iter 96000, loss: 0.257496
 >> iter 97000, loss: 0.209976
 >> iter 98000, loss: 0.177958
 >> iter 99000, loss: 0.161573
 >> iter 100000, loss: 0.362827
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.422698
 >> iter 2000, loss: 11.760993
 >> iter 3000, loss: 6.576846
 >> iter 4000, loss: 3.692623
 >> iter 5000, loss: 2.187861
 >> iter 6000, loss: 1.173980
 >> iter 7000, loss: 0.694080
 >> iter 8000, loss: 0.734966
 >> iter 9000, loss: 0.489180
 >> iter 10000, loss: 0.465810
   Number of active neurons: 9
 >> iter 11000, loss: 0.649096
 >> iter 12000, loss: 0.701408
 >> iter 13000, loss: 0.705175
 >> iter 14000, loss: 0.665198
 >> iter 15000, loss: 0.537575
 >> iter 16000, loss: 0.486258
 >> iter 17000, loss: 0.621738
 >> iter 18000, loss: 0.540637
 >> iter 19000, loss: 0.531838
 >> iter 20000, loss: 0.642247
   Number of active neurons: 9
 >> iter 21000, loss: 0.720267
 >> iter 22000, loss: 0.539659
 >> iter 23000, loss: 0.565732
 >> iter 24000, loss: 0.700537
 >> iter 25000, loss: 0.685647
 >> iter 26000, loss: 0.572561
 >> iter 27000, loss: 0.614016
 >> iter 28000, loss: 0.677703
 >> iter 29000, loss: 0.448914
 >> iter 30000, loss: 0.523879
   Number of active neurons: 6
 >> iter 31000, loss: 0.568398
 >> iter 32000, loss: 0.484531
 >> iter 33000, loss: 0.676812
 >> iter 34000, loss: 0.642101
 >> iter 35000, loss: 0.438922
 >> iter 36000, loss: 0.447526
 >> iter 37000, loss: 0.410255
 >> iter 38000, loss: 0.478395
 >> iter 39000, loss: 0.419841
 >> iter 40000, loss: 0.333193
   Number of active neurons: 6
 >> iter 41000, loss: 0.244104
 >> iter 42000, loss: 0.395856
 >> iter 43000, loss: 0.490025
 >> iter 44000, loss: 0.591130
 >> iter 45000, loss: 0.406842
 >> iter 46000, loss: 0.358549
 >> iter 47000, loss: 0.334207
 >> iter 48000, loss: 0.459843
 >> iter 49000, loss: 0.393793
 >> iter 50000, loss: 0.293860
   Number of active neurons: 6
 >> iter 51000, loss: 0.252666
 >> iter 52000, loss: 0.413229
 >> iter 53000, loss: 0.281012
 >> iter 54000, loss: 0.242527
 >> iter 55000, loss: 0.245187
 >> iter 56000, loss: 0.323512
 >> iter 57000, loss: 0.266162
 >> iter 58000, loss: 0.449933
 >> iter 59000, loss: 0.586794
 >> iter 60000, loss: 0.342656
   Number of active neurons: 5
 >> iter 61000, loss: 0.433804
 >> iter 62000, loss: 0.275194
 >> iter 63000, loss: 0.234402
 >> iter 64000, loss: 0.301779
 >> iter 65000, loss: 0.476108
 >> iter 66000, loss: 0.361033
 >> iter 67000, loss: 0.314990
 >> iter 68000, loss: 0.275178
 >> iter 69000, loss: 0.286104
 >> iter 70000, loss: 0.362241
   Number of active neurons: 5
 >> iter 71000, loss: 0.288611
 >> iter 72000, loss: 0.324596
 >> iter 73000, loss: 0.261473
 >> iter 74000, loss: 0.311773
 >> iter 75000, loss: 0.269317
 >> iter 76000, loss: 0.370750
 >> iter 77000, loss: 0.327859
 >> iter 78000, loss: 0.343004
 >> iter 79000, loss: 0.304849
 >> iter 80000, loss: 0.380770
   Number of active neurons: 5
 >> iter 81000, loss: 0.293527
 >> iter 82000, loss: 0.342731
 >> iter 83000, loss: 0.313443
 >> iter 84000, loss: 0.373673
 >> iter 85000, loss: 0.338189
 >> iter 86000, loss: 0.424891
 >> iter 87000, loss: 0.290552
 >> iter 88000, loss: 0.379919
 >> iter 89000, loss: 0.242632
 >> iter 90000, loss: 0.301098
   Number of active neurons: 5
 >> iter 91000, loss: 0.298107
 >> iter 92000, loss: 0.289075
 >> iter 93000, loss: 0.301103
 >> iter 94000, loss: 0.291833
 >> iter 95000, loss: 0.241722
 >> iter 96000, loss: 0.278448
 >> iter 97000, loss: 0.274045
 >> iter 98000, loss: 0.187964
 >> iter 99000, loss: 0.204833
 >> iter 100000, loss: 0.319917
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.576354
 >> iter 2000, loss: 8.677362
 >> iter 3000, loss: 4.016292
 >> iter 4000, loss: 2.241605
 >> iter 5000, loss: 1.165369
 >> iter 6000, loss: 0.559376
 >> iter 7000, loss: 0.402329
 >> iter 8000, loss: 0.300653
 >> iter 9000, loss: 0.381183
 >> iter 10000, loss: 0.387006
   Number of active neurons: 4
 >> iter 11000, loss: 0.239547
 >> iter 12000, loss: 0.338086
 >> iter 13000, loss: 0.251656
 >> iter 14000, loss: 0.340862
 >> iter 15000, loss: 0.495973
 >> iter 16000, loss: 0.329697
 >> iter 17000, loss: 0.277183
 >> iter 18000, loss: 0.225107
 >> iter 19000, loss: 0.168766
 >> iter 20000, loss: 0.214345
   Number of active neurons: 3
 >> iter 21000, loss: 0.347928
 >> iter 22000, loss: 0.368694
 >> iter 23000, loss: 0.232107
 >> iter 24000, loss: 0.175038
 >> iter 25000, loss: 0.159126
 >> iter 26000, loss: 0.378206
 >> iter 27000, loss: 0.248912
 >> iter 28000, loss: 0.268674
 >> iter 29000, loss: 0.153496
 >> iter 30000, loss: 0.209919
   Number of active neurons: 3
 >> iter 31000, loss: 0.242830
 >> iter 32000, loss: 0.256961
 >> iter 33000, loss: 0.341657
 >> iter 34000, loss: 0.229262
 >> iter 35000, loss: 0.186494
 >> iter 36000, loss: 0.191820
 >> iter 37000, loss: 0.245410
 >> iter 38000, loss: 0.286099
 >> iter 39000, loss: 0.312693
 >> iter 40000, loss: 0.328334
   Number of active neurons: 3
 >> iter 41000, loss: 0.262378
 >> iter 42000, loss: 0.319037
 >> iter 43000, loss: 0.409301
 >> iter 44000, loss: 0.346651
 >> iter 45000, loss: 0.316683
 >> iter 46000, loss: 0.288568
 >> iter 47000, loss: 0.493206
 >> iter 48000, loss: 0.539499
 >> iter 49000, loss: 0.297576
 >> iter 50000, loss: 0.169961
   Number of active neurons: 3
 >> iter 51000, loss: 0.163462
 >> iter 52000, loss: 0.186834
 >> iter 53000, loss: 0.281660
 >> iter 54000, loss: 0.408837
 >> iter 55000, loss: 0.360029
 >> iter 56000, loss: 0.216431
 >> iter 57000, loss: 0.258753
 >> iter 58000, loss: 0.327736
 >> iter 59000, loss: 0.260033
 >> iter 60000, loss: 0.523704
   Number of active neurons: 3
 >> iter 61000, loss: 0.387014
 >> iter 62000, loss: 0.190849
 >> iter 63000, loss: 0.268408
 >> iter 64000, loss: 0.317195
 >> iter 65000, loss: 0.378413
 >> iter 66000, loss: 0.244990
 >> iter 67000, loss: 0.271050
 >> iter 68000, loss: 0.135765
 >> iter 69000, loss: 0.230565
 >> iter 70000, loss: 0.217252
   Number of active neurons: 3
 >> iter 71000, loss: 0.254165
 >> iter 72000, loss: 0.243586
 >> iter 73000, loss: 0.261686
 >> iter 74000, loss: 0.296965
 >> iter 75000, loss: 0.145907
 >> iter 76000, loss: 0.221705
 >> iter 77000, loss: 0.234005
 >> iter 78000, loss: 0.242924
 >> iter 79000, loss: 0.359186
 >> iter 80000, loss: 0.248470
   Number of active neurons: 3
 >> iter 81000, loss: 0.182713
 >> iter 82000, loss: 0.290541
 >> iter 83000, loss: 0.313935
 >> iter 84000, loss: 0.191780
 >> iter 85000, loss: 0.284328
 >> iter 86000, loss: 0.293850
 >> iter 87000, loss: 0.264181
 >> iter 88000, loss: 0.231691
 >> iter 89000, loss: 0.193985
 >> iter 90000, loss: 0.248409
   Number of active neurons: 3
 >> iter 91000, loss: 0.202967
 >> iter 92000, loss: 0.283618
 >> iter 93000, loss: 0.136914
 >> iter 94000, loss: 0.160018
 >> iter 95000, loss: 0.400285
 >> iter 96000, loss: 0.337867
 >> iter 97000, loss: 0.361916
 >> iter 98000, loss: 0.317140
 >> iter 99000, loss: 0.211758
 >> iter 100000, loss: 0.219300
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.956569
 >> iter 2000, loss: 8.804440
 >> iter 3000, loss: 4.849923
 >> iter 4000, loss: 2.172934
 >> iter 5000, loss: 1.046413
 >> iter 6000, loss: 0.659750
 >> iter 7000, loss: 0.677562
 >> iter 8000, loss: 0.506463
 >> iter 9000, loss: 0.483291
 >> iter 10000, loss: 0.439897
   Number of active neurons: 5
 >> iter 11000, loss: 0.384396
 >> iter 12000, loss: 0.237472
 >> iter 13000, loss: 0.373775
 >> iter 14000, loss: 0.282798
 >> iter 15000, loss: 0.267565
 >> iter 16000, loss: 0.718100
 >> iter 17000, loss: 0.606010
 >> iter 18000, loss: 0.576020
 >> iter 19000, loss: 0.434113
 >> iter 20000, loss: 0.407959
   Number of active neurons: 5
 >> iter 21000, loss: 0.520965
 >> iter 22000, loss: 0.260235
 >> iter 23000, loss: 0.301170
 >> iter 24000, loss: 0.287453
 >> iter 25000, loss: 0.296505
 >> iter 26000, loss: 0.295933
 >> iter 27000, loss: 0.249070
 >> iter 28000, loss: 0.334389
 >> iter 29000, loss: 0.313075
 >> iter 30000, loss: 0.449295
   Number of active neurons: 4
 >> iter 31000, loss: 0.480883
 >> iter 32000, loss: 0.473146
 >> iter 33000, loss: 0.336607
 >> iter 34000, loss: 0.619854
 >> iter 35000, loss: 0.628219
 >> iter 36000, loss: 0.567199
 >> iter 37000, loss: 0.468804
 >> iter 38000, loss: 0.260551
 >> iter 39000, loss: 0.375651
 >> iter 40000, loss: 0.641401
   Number of active neurons: 4
 >> iter 41000, loss: 0.482833
 >> iter 42000, loss: 0.699378
 >> iter 43000, loss: 0.619596
 >> iter 44000, loss: 0.364609
 >> iter 45000, loss: 0.698772
 >> iter 46000, loss: 0.495607
 >> iter 47000, loss: 0.346207
 >> iter 48000, loss: 0.412867
 >> iter 49000, loss: 0.264771
 >> iter 50000, loss: 0.415461
   Number of active neurons: 4
 >> iter 51000, loss: 0.289635
 >> iter 52000, loss: 0.374370
 >> iter 53000, loss: 0.412495
 >> iter 54000, loss: 0.405070
 >> iter 55000, loss: 0.417747
 >> iter 56000, loss: 0.328808
 >> iter 57000, loss: 0.486700
 >> iter 58000, loss: 0.568894
 >> iter 59000, loss: 0.499299
 >> iter 60000, loss: 0.265098
   Number of active neurons: 4
 >> iter 61000, loss: 0.387465
 >> iter 62000, loss: 0.441892
 >> iter 63000, loss: 0.361601
 >> iter 64000, loss: 0.274297
 >> iter 65000, loss: 0.216007
 >> iter 66000, loss: 0.270652
 >> iter 67000, loss: 0.240404
 >> iter 68000, loss: 0.733168
 >> iter 69000, loss: 0.431216
 >> iter 70000, loss: 0.444680
   Number of active neurons: 4
 >> iter 71000, loss: 0.265514
 >> iter 72000, loss: 0.249436
 >> iter 73000, loss: 0.326332
 >> iter 74000, loss: 0.568862
 >> iter 75000, loss: 0.471239
 >> iter 76000, loss: 0.495359
 >> iter 77000, loss: 0.536866
 >> iter 78000, loss: 0.360527
 >> iter 79000, loss: 0.299630
 >> iter 80000, loss: 0.449035
   Number of active neurons: 4
 >> iter 81000, loss: 0.313237
 >> iter 82000, loss: 0.328358
 >> iter 83000, loss: 0.191588
 >> iter 84000, loss: 0.530875
 >> iter 85000, loss: 0.381462
 >> iter 86000, loss: 0.429404
 >> iter 87000, loss: 0.378870
 >> iter 88000, loss: 0.269170
 >> iter 89000, loss: 0.549506
 >> iter 90000, loss: 0.548548
   Number of active neurons: 4
 >> iter 91000, loss: 0.318736
 >> iter 92000, loss: 0.575554
 >> iter 93000, loss: 0.555771
 >> iter 94000, loss: 0.331487
 >> iter 95000, loss: 0.356813
 >> iter 96000, loss: 0.190004
 >> iter 97000, loss: 0.279118
 >> iter 98000, loss: 0.129884
 >> iter 99000, loss: 0.281240
 >> iter 100000, loss: 0.270193
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.445141
 >> iter 2000, loss: 8.478068
 >> iter 3000, loss: 3.911595
 >> iter 4000, loss: 1.824313
 >> iter 5000, loss: 0.989907
 >> iter 6000, loss: 0.679969
 >> iter 7000, loss: 0.463118
 >> iter 8000, loss: 0.340102
 >> iter 9000, loss: 0.354212
 >> iter 10000, loss: 0.450347
   Number of active neurons: 5
 >> iter 11000, loss: 0.439622
 >> iter 12000, loss: 0.529610
 >> iter 13000, loss: 0.383380
 >> iter 14000, loss: 0.492745
 >> iter 15000, loss: 0.492792
 >> iter 16000, loss: 0.354248
 >> iter 17000, loss: 0.334858
 >> iter 18000, loss: 0.445671
 >> iter 19000, loss: 0.295896
 >> iter 20000, loss: 0.310742
   Number of active neurons: 5
 >> iter 21000, loss: 0.459736
 >> iter 22000, loss: 0.294620
 >> iter 23000, loss: 0.360517
 >> iter 24000, loss: 0.336349
 >> iter 25000, loss: 0.237515
 >> iter 26000, loss: 0.265107
 >> iter 27000, loss: 0.340170
 >> iter 28000, loss: 0.280952
 >> iter 29000, loss: 0.215172
 >> iter 30000, loss: 0.439254
   Number of active neurons: 5
 >> iter 31000, loss: 0.287205
 >> iter 32000, loss: 0.270643
 >> iter 33000, loss: 0.369603
 >> iter 34000, loss: 0.265512
 >> iter 35000, loss: 0.280141
 >> iter 36000, loss: 0.403763
 >> iter 37000, loss: 0.202921
 >> iter 38000, loss: 0.460609
 >> iter 39000, loss: 0.252138
 >> iter 40000, loss: 0.338261
   Number of active neurons: 5
 >> iter 41000, loss: 0.219182
 >> iter 42000, loss: 0.163849
 >> iter 43000, loss: 0.163935
 >> iter 44000, loss: 0.199752
 >> iter 45000, loss: 0.272910
 >> iter 46000, loss: 0.131446
 >> iter 47000, loss: 0.193259
 >> iter 48000, loss: 0.305416
 >> iter 49000, loss: 0.302747
 >> iter 50000, loss: 0.249115
   Number of active neurons: 5
 >> iter 51000, loss: 0.195485
 >> iter 52000, loss: 0.280255
 >> iter 53000, loss: 0.299793
 >> iter 54000, loss: 0.281826
 >> iter 55000, loss: 0.561174
 >> iter 56000, loss: 0.350943
 >> iter 57000, loss: 0.247974
 >> iter 58000, loss: 0.258735
 >> iter 59000, loss: 0.242036
 >> iter 60000, loss: 0.390399
   Number of active neurons: 4
 >> iter 61000, loss: 0.330963
 >> iter 62000, loss: 0.308054
 >> iter 63000, loss: 0.381317
 >> iter 64000, loss: 0.254949
 >> iter 65000, loss: 0.417138
 >> iter 66000, loss: 0.271010
 >> iter 67000, loss: 0.192487
 >> iter 68000, loss: 0.115186
 >> iter 69000, loss: 0.188315
 >> iter 70000, loss: 0.184841
   Number of active neurons: 4
 >> iter 71000, loss: 0.131746
 >> iter 72000, loss: 0.368458
 >> iter 73000, loss: 0.210598
 >> iter 74000, loss: 0.299064
 >> iter 75000, loss: 0.204103
 >> iter 76000, loss: 0.175338
 >> iter 77000, loss: 0.284269
 >> iter 78000, loss: 0.410575
 >> iter 79000, loss: 0.339701
 >> iter 80000, loss: 0.285121
   Number of active neurons: 4
 >> iter 81000, loss: 0.160585
 >> iter 82000, loss: 0.349555
 >> iter 83000, loss: 0.215176
 >> iter 84000, loss: 0.274289
 >> iter 85000, loss: 0.217938
 >> iter 86000, loss: 0.294602
 >> iter 87000, loss: 0.224168
 >> iter 88000, loss: 0.284951
 >> iter 89000, loss: 0.335943
 >> iter 90000, loss: 0.214834
   Number of active neurons: 4
 >> iter 91000, loss: 0.135624
 >> iter 92000, loss: 0.162553
 >> iter 93000, loss: 0.275987
 >> iter 94000, loss: 0.267407
 >> iter 95000, loss: 0.223044
 >> iter 96000, loss: 0.112029
 >> iter 97000, loss: 0.106333
 >> iter 98000, loss: 0.132980
 >> iter 99000, loss: 0.222581
 >> iter 100000, loss: 0.152804
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.778480
 >> iter 2000, loss: 8.836117
 >> iter 3000, loss: 3.692016
 >> iter 4000, loss: 1.758304
 >> iter 5000, loss: 0.843704
 >> iter 6000, loss: 0.726207
 >> iter 7000, loss: 0.349456
 >> iter 8000, loss: 0.592660
 >> iter 9000, loss: 0.407044
 >> iter 10000, loss: 0.420245
   Number of active neurons: 6
 >> iter 11000, loss: 0.527351
 >> iter 12000, loss: 0.434752
 >> iter 13000, loss: 0.361345
 >> iter 14000, loss: 0.266525
 >> iter 15000, loss: 0.377735
 >> iter 16000, loss: 0.281731
 >> iter 17000, loss: 0.395713
 >> iter 18000, loss: 0.307237
 >> iter 19000, loss: 0.346348
 >> iter 20000, loss: 0.393018
   Number of active neurons: 5
 >> iter 21000, loss: 0.288733
 >> iter 22000, loss: 0.300677
 >> iter 23000, loss: 0.555480
 >> iter 24000, loss: 0.348764
 >> iter 25000, loss: 0.220033
 >> iter 26000, loss: 0.319886
 >> iter 27000, loss: 0.200693
 >> iter 28000, loss: 0.192199
 >> iter 29000, loss: 0.454474
 >> iter 30000, loss: 0.297213
   Number of active neurons: 4
 >> iter 31000, loss: 0.337800
 >> iter 32000, loss: 0.203589
 >> iter 33000, loss: 0.415925
 >> iter 34000, loss: 0.276785
 >> iter 35000, loss: 0.264043
 >> iter 36000, loss: 0.252750
 >> iter 37000, loss: 0.260159
 >> iter 38000, loss: 0.234512
 >> iter 39000, loss: 0.182608
 >> iter 40000, loss: 0.140167
   Number of active neurons: 3
 >> iter 41000, loss: 0.197936
 >> iter 42000, loss: 0.328821
 >> iter 43000, loss: 0.278169
 >> iter 44000, loss: 0.230367
 >> iter 45000, loss: 0.170367
 >> iter 46000, loss: 0.254223
 >> iter 47000, loss: 0.226600
 >> iter 48000, loss: 0.196559
 >> iter 49000, loss: 0.155104
 >> iter 50000, loss: 0.245230
   Number of active neurons: 3
 >> iter 51000, loss: 0.228420
 >> iter 52000, loss: 0.323008
 >> iter 53000, loss: 0.321113
 >> iter 54000, loss: 0.357108
 >> iter 55000, loss: 0.223178
 >> iter 56000, loss: 0.220672
 >> iter 57000, loss: 0.276357
 >> iter 58000, loss: 0.303474
 >> iter 59000, loss: 0.182813
 >> iter 60000, loss: 0.161917
   Number of active neurons: 3
 >> iter 61000, loss: 0.205031
 >> iter 62000, loss: 0.281602
 >> iter 63000, loss: 0.224526
 >> iter 64000, loss: 0.366458
 >> iter 65000, loss: 0.240673
 >> iter 66000, loss: 0.176509
 >> iter 67000, loss: 0.209098
 >> iter 68000, loss: 0.234840
 >> iter 69000, loss: 0.180143
 >> iter 70000, loss: 0.372164
   Number of active neurons: 3
 >> iter 71000, loss: 0.258161
 >> iter 72000, loss: 0.334208
 >> iter 73000, loss: 0.184774
 >> iter 74000, loss: 0.338329
 >> iter 75000, loss: 0.234630
 >> iter 76000, loss: 0.448173
 >> iter 77000, loss: 0.261999
 >> iter 78000, loss: 0.190065
 >> iter 79000, loss: 0.203108
 >> iter 80000, loss: 0.252169
   Number of active neurons: 3
 >> iter 81000, loss: 0.260069
 >> iter 82000, loss: 0.284165
 >> iter 83000, loss: 0.336422
 >> iter 84000, loss: 0.304453
 >> iter 85000, loss: 0.171801
 >> iter 86000, loss: 0.134038
 >> iter 87000, loss: 0.168095
 >> iter 88000, loss: 0.138018
 >> iter 89000, loss: 0.159119
 >> iter 90000, loss: 0.256053
   Number of active neurons: 3
 >> iter 91000, loss: 0.320439
 >> iter 92000, loss: 0.267205
 >> iter 93000, loss: 0.216514
 >> iter 94000, loss: 0.255426
 >> iter 95000, loss: 0.299273
 >> iter 96000, loss: 0.301527
 >> iter 97000, loss: 0.261025
 >> iter 98000, loss: 0.389917
 >> iter 99000, loss: 0.292367
 >> iter 100000, loss: 0.321637
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.226198
 >> iter 2000, loss: 8.384715
 >> iter 3000, loss: 3.963405
 >> iter 4000, loss: 1.800630
 >> iter 5000, loss: 0.873945
 >> iter 6000, loss: 0.544574
 >> iter 7000, loss: 0.533208
 >> iter 8000, loss: 0.457317
 >> iter 9000, loss: 0.426407
 >> iter 10000, loss: 0.326241
   Number of active neurons: 5
 >> iter 11000, loss: 0.215966
 >> iter 12000, loss: 0.205744
 >> iter 13000, loss: 0.324240
 >> iter 14000, loss: 0.237560
 >> iter 15000, loss: 0.281019
 >> iter 16000, loss: 0.410061
 >> iter 17000, loss: 0.433140
 >> iter 18000, loss: 0.415746
 >> iter 19000, loss: 0.539677
 >> iter 20000, loss: 0.368645
   Number of active neurons: 4
 >> iter 21000, loss: 0.197446
 >> iter 22000, loss: 0.180692
 >> iter 23000, loss: 0.420160
 >> iter 24000, loss: 0.508939
 >> iter 25000, loss: 0.288334
 >> iter 26000, loss: 0.243404
 >> iter 27000, loss: 0.326632
 >> iter 28000, loss: 0.280367
 >> iter 29000, loss: 0.473020
 >> iter 30000, loss: 0.370508
   Number of active neurons: 4
 >> iter 31000, loss: 0.348303
 >> iter 32000, loss: 0.269407
 >> iter 33000, loss: 0.292107
 >> iter 34000, loss: 0.313352
 >> iter 35000, loss: 0.411129
 >> iter 36000, loss: 0.431452
 >> iter 37000, loss: 0.264810
 >> iter 38000, loss: 0.254606
 >> iter 39000, loss: 0.396633
 >> iter 40000, loss: 0.328590
   Number of active neurons: 4
 >> iter 41000, loss: 0.273145
 >> iter 42000, loss: 0.320467
 >> iter 43000, loss: 0.284991
 >> iter 44000, loss: 0.398870
 >> iter 45000, loss: 0.474543
 >> iter 46000, loss: 0.344062
 >> iter 47000, loss: 0.299941
 >> iter 48000, loss: 0.273276
 >> iter 49000, loss: 0.179870
 >> iter 50000, loss: 0.278590
   Number of active neurons: 4
 >> iter 51000, loss: 0.326279
 >> iter 52000, loss: 0.208229
 >> iter 53000, loss: 0.364121
 >> iter 54000, loss: 0.325154
 >> iter 55000, loss: 0.419267
 >> iter 56000, loss: 0.345659
 >> iter 57000, loss: 0.349496
 >> iter 58000, loss: 0.728623
 >> iter 59000, loss: 0.510856
 >> iter 60000, loss: 0.432860
   Number of active neurons: 4
 >> iter 61000, loss: 0.277327
 >> iter 62000, loss: 0.436119
 >> iter 63000, loss: 0.403930
 >> iter 64000, loss: 0.408967
 >> iter 65000, loss: 0.251982
 >> iter 66000, loss: 0.250518
 >> iter 67000, loss: 0.265453
 >> iter 68000, loss: 0.192489
 >> iter 69000, loss: 0.318464
 >> iter 70000, loss: 0.294476
   Number of active neurons: 4
 >> iter 71000, loss: 0.225248
 >> iter 72000, loss: 0.284155
 >> iter 73000, loss: 0.381253
 >> iter 74000, loss: 0.270250
 >> iter 75000, loss: 0.381356
 >> iter 76000, loss: 0.289814
 >> iter 77000, loss: 0.285637
 >> iter 78000, loss: 0.234376
 >> iter 79000, loss: 0.267006
 >> iter 80000, loss: 0.227591
   Number of active neurons: 4
 >> iter 81000, loss: 0.219763
 >> iter 82000, loss: 0.155081
 >> iter 83000, loss: 0.385959
 >> iter 84000, loss: 0.222467
 >> iter 85000, loss: 0.324171
 >> iter 86000, loss: 0.277244
 >> iter 87000, loss: 0.272802
 >> iter 88000, loss: 0.232520
 >> iter 89000, loss: 0.182139
 >> iter 90000, loss: 0.152516
   Number of active neurons: 3
 >> iter 91000, loss: 0.212183
 >> iter 92000, loss: 0.232280
 >> iter 93000, loss: 0.148761
 >> iter 94000, loss: 0.109869
 >> iter 95000, loss: 0.180336
 >> iter 96000, loss: 0.279694
 >> iter 97000, loss: 0.248598
 >> iter 98000, loss: 0.264306
 >> iter 99000, loss: 0.337534
 >> iter 100000, loss: 0.294875
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.245421
 >> iter 2000, loss: 8.225573
 >> iter 3000, loss: 3.832923
 >> iter 4000, loss: 2.111325
 >> iter 5000, loss: 1.070925
 >> iter 6000, loss: 0.567654
 >> iter 7000, loss: 0.511089
 >> iter 8000, loss: 0.459891
 >> iter 9000, loss: 0.520785
 >> iter 10000, loss: 0.583248
   Number of active neurons: 5
 >> iter 11000, loss: 0.405830
 >> iter 12000, loss: 0.267957
 >> iter 13000, loss: 0.391277
 >> iter 14000, loss: 0.404944
 >> iter 15000, loss: 0.624396
 >> iter 16000, loss: 0.330902
 >> iter 17000, loss: 0.217403
 >> iter 18000, loss: 0.410547
 >> iter 19000, loss: 0.326773
 >> iter 20000, loss: 0.338810
   Number of active neurons: 5
 >> iter 21000, loss: 0.278911
 >> iter 22000, loss: 0.244643
 >> iter 23000, loss: 0.387961
 >> iter 24000, loss: 0.286111
 >> iter 25000, loss: 0.172071
 >> iter 26000, loss: 0.324717
 >> iter 27000, loss: 0.388280
 >> iter 28000, loss: 0.434716
 >> iter 29000, loss: 0.347820
 >> iter 30000, loss: 0.202131
   Number of active neurons: 5
 >> iter 31000, loss: 0.243288
 >> iter 32000, loss: 0.436087
 >> iter 33000, loss: 0.622183
 >> iter 34000, loss: 0.383952
 >> iter 35000, loss: 0.222631
 >> iter 36000, loss: 0.287991
 >> iter 37000, loss: 0.294369
 >> iter 38000, loss: 0.453248
 >> iter 39000, loss: 0.374474
 >> iter 40000, loss: 0.281348
   Number of active neurons: 5
 >> iter 41000, loss: 0.247652
 >> iter 42000, loss: 0.213162
 >> iter 43000, loss: 0.405094
 >> iter 44000, loss: 0.312826
 >> iter 45000, loss: 0.247551
 >> iter 46000, loss: 0.187010
 >> iter 47000, loss: 0.216672
 >> iter 48000, loss: 0.172912
 >> iter 49000, loss: 0.145997
 >> iter 50000, loss: 0.286875
   Number of active neurons: 4
 >> iter 51000, loss: 0.325935
 >> iter 52000, loss: 0.338574
 >> iter 53000, loss: 0.282161
 >> iter 54000, loss: 0.265461
 >> iter 55000, loss: 0.170055
 >> iter 56000, loss: 0.297686
 >> iter 57000, loss: 0.233266
 >> iter 58000, loss: 0.352364
 >> iter 59000, loss: 0.247185
 >> iter 60000, loss: 0.380768
   Number of active neurons: 3
 >> iter 61000, loss: 0.349876
 >> iter 62000, loss: 0.355654
 >> iter 63000, loss: 0.254617
 >> iter 64000, loss: 0.296242
 >> iter 65000, loss: 0.218329
 >> iter 66000, loss: 0.217199
 >> iter 67000, loss: 0.301587
 >> iter 68000, loss: 0.357372
 >> iter 69000, loss: 0.317408
 >> iter 70000, loss: 0.214106
   Number of active neurons: 3
 >> iter 71000, loss: 0.326697
 >> iter 72000, loss: 0.288300
 >> iter 73000, loss: 0.272857
 >> iter 74000, loss: 0.304565
 >> iter 75000, loss: 0.268778
 >> iter 76000, loss: 0.487955
 >> iter 77000, loss: 0.295585
 >> iter 78000, loss: 0.260236
 >> iter 79000, loss: 0.284863
 >> iter 80000, loss: 0.389222
   Number of active neurons: 3
 >> iter 81000, loss: 0.293884
 >> iter 82000, loss: 0.240804
 >> iter 83000, loss: 0.276810
 >> iter 84000, loss: 0.191604
 >> iter 85000, loss: 0.278409
 >> iter 86000, loss: 0.236162
 >> iter 87000, loss: 0.277205
 >> iter 88000, loss: 0.283675
 >> iter 89000, loss: 0.192300
 >> iter 90000, loss: 0.308095
   Number of active neurons: 3
 >> iter 91000, loss: 0.271230
 >> iter 92000, loss: 0.164092
 >> iter 93000, loss: 0.228656
 >> iter 94000, loss: 0.326158
 >> iter 95000, loss: 0.209978
 >> iter 96000, loss: 0.192568
 >> iter 97000, loss: 0.227867
 >> iter 98000, loss: 0.194461
 >> iter 99000, loss: 0.163399
 >> iter 100000, loss: 0.146963
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.666960
 >> iter 2000, loss: 8.638956
 >> iter 3000, loss: 3.843096
 >> iter 4000, loss: 1.657299
 >> iter 5000, loss: 0.975942
 >> iter 6000, loss: 0.606779
 >> iter 7000, loss: 0.647902
 >> iter 8000, loss: 0.346090
 >> iter 9000, loss: 0.504345
 >> iter 10000, loss: 0.441017
   Number of active neurons: 4
 >> iter 11000, loss: 0.390206
 >> iter 12000, loss: 0.316642
 >> iter 13000, loss: 0.299775
 >> iter 14000, loss: 0.229622
 >> iter 15000, loss: 0.322706
 >> iter 16000, loss: 0.224084
 >> iter 17000, loss: 0.296440
 >> iter 18000, loss: 0.285077
 >> iter 19000, loss: 0.456608
 >> iter 20000, loss: 0.364828
   Number of active neurons: 4
 >> iter 21000, loss: 0.446887
 >> iter 22000, loss: 0.316011
 >> iter 23000, loss: 0.298919
 >> iter 24000, loss: 0.316959
 >> iter 25000, loss: 0.327428
 >> iter 26000, loss: 0.189691
 >> iter 27000, loss: 0.246544
 >> iter 28000, loss: 0.273891
 >> iter 29000, loss: 0.244678
 >> iter 30000, loss: 0.176656
   Number of active neurons: 4
 >> iter 31000, loss: 0.254331
 >> iter 32000, loss: 0.311686
 >> iter 33000, loss: 0.171382
 >> iter 34000, loss: 0.318263
 >> iter 35000, loss: 0.419335
 >> iter 36000, loss: 0.366180
 >> iter 37000, loss: 0.356230
 >> iter 38000, loss: 0.352138
 >> iter 39000, loss: 0.263735
 >> iter 40000, loss: 0.159684
   Number of active neurons: 3
 >> iter 41000, loss: 0.304421
 >> iter 42000, loss: 0.267344
 >> iter 43000, loss: 0.303279
 >> iter 44000, loss: 0.317913
 >> iter 45000, loss: 0.281876
 >> iter 46000, loss: 0.301341
 >> iter 47000, loss: 0.400192
 >> iter 48000, loss: 0.486096
 >> iter 49000, loss: 0.259652
 >> iter 50000, loss: 0.223441
   Number of active neurons: 3
 >> iter 51000, loss: 0.248667
 >> iter 52000, loss: 0.354619
 >> iter 53000, loss: 0.226763
 >> iter 54000, loss: 0.437850
 >> iter 55000, loss: 0.356536
 >> iter 56000, loss: 0.377225
 >> iter 57000, loss: 0.381383
 >> iter 58000, loss: 0.474335
 >> iter 59000, loss: 0.207077
 >> iter 60000, loss: 0.324845
   Number of active neurons: 3
 >> iter 61000, loss: 0.438219
 >> iter 62000, loss: 0.386309
 >> iter 63000, loss: 0.319200
 >> iter 64000, loss: 0.152076
 >> iter 65000, loss: 0.245005
 >> iter 66000, loss: 0.379060
 >> iter 67000, loss: 0.195041
 >> iter 68000, loss: 0.101000
 >> iter 69000, loss: 0.133131
 >> iter 70000, loss: 0.153258
   Number of active neurons: 3
 >> iter 71000, loss: 0.163697
 >> iter 72000, loss: 0.261943
 >> iter 73000, loss: 0.272495
 >> iter 74000, loss: 0.276132
 >> iter 75000, loss: 0.270493
 >> iter 76000, loss: 0.182130
 >> iter 77000, loss: 0.105690
 >> iter 78000, loss: 0.070253
 >> iter 79000, loss: 0.160191
 >> iter 80000, loss: 0.192544
   Number of active neurons: 3
 >> iter 81000, loss: 0.240382
 >> iter 82000, loss: 0.264081
 >> iter 83000, loss: 0.249066
 >> iter 84000, loss: 0.256859
 >> iter 85000, loss: 0.238554
 >> iter 86000, loss: 0.407189
 >> iter 87000, loss: 0.360693
 >> iter 88000, loss: 0.332393
 >> iter 89000, loss: 0.226261
 >> iter 90000, loss: 0.290385
   Number of active neurons: 3
 >> iter 91000, loss: 0.247583
 >> iter 92000, loss: 0.247717
 >> iter 93000, loss: 0.235230
 >> iter 94000, loss: 0.260219
 >> iter 95000, loss: 0.318907
 >> iter 96000, loss: 0.228786
 >> iter 97000, loss: 0.187413
 >> iter 98000, loss: 0.322900
 >> iter 99000, loss: 0.347603
 >> iter 100000, loss: 0.187475
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.649845
 >> iter 2000, loss: 9.376114
 >> iter 3000, loss: 4.817569
 >> iter 4000, loss: 2.402169
 >> iter 5000, loss: 1.163993
 >> iter 6000, loss: 0.811208
 >> iter 7000, loss: 0.671720
 >> iter 8000, loss: 0.517794
 >> iter 9000, loss: 0.470821
 >> iter 10000, loss: 0.579558
   Number of active neurons: 7
 >> iter 11000, loss: 0.599317
 >> iter 12000, loss: 0.448549
 >> iter 13000, loss: 0.260268
 >> iter 14000, loss: 0.328967
 >> iter 15000, loss: 0.419961
 >> iter 16000, loss: 0.394173
 >> iter 17000, loss: 0.479184
 >> iter 18000, loss: 0.425587
 >> iter 19000, loss: 0.423515
 >> iter 20000, loss: 0.385177
   Number of active neurons: 7
 >> iter 21000, loss: 0.433973
 >> iter 22000, loss: 0.332395
 >> iter 23000, loss: 0.449000
 >> iter 24000, loss: 0.430334
 >> iter 25000, loss: 0.392720
 >> iter 26000, loss: 0.285923
 >> iter 27000, loss: 0.704434
 >> iter 28000, loss: 0.654635
 >> iter 29000, loss: 0.380939
 >> iter 30000, loss: 0.305331
   Number of active neurons: 7
 >> iter 31000, loss: 0.345391
 >> iter 32000, loss: 0.249820
 >> iter 33000, loss: 0.697305
 >> iter 34000, loss: 0.537411
 >> iter 35000, loss: 0.361051
 >> iter 36000, loss: 0.332842
 >> iter 37000, loss: 0.292983
 >> iter 38000, loss: 0.446718
 >> iter 39000, loss: 0.313899
 >> iter 40000, loss: 0.397306
   Number of active neurons: 7
 >> iter 41000, loss: 0.384268
 >> iter 42000, loss: 0.391879
 >> iter 43000, loss: 0.292117
 >> iter 44000, loss: 0.233091
 >> iter 45000, loss: 0.395381
 >> iter 46000, loss: 0.483544
 >> iter 47000, loss: 0.217708
 >> iter 48000, loss: 0.258450
 >> iter 49000, loss: 0.360619
 >> iter 50000, loss: 0.238020
   Number of active neurons: 7
 >> iter 51000, loss: 0.194162
 >> iter 52000, loss: 0.521248
 >> iter 53000, loss: 0.367313
 >> iter 54000, loss: 0.415421
 >> iter 55000, loss: 0.474666
 >> iter 56000, loss: 0.536511
 >> iter 57000, loss: 0.347342
 >> iter 58000, loss: 0.210076
 >> iter 59000, loss: 0.254012
 >> iter 60000, loss: 0.385724
   Number of active neurons: 5
 >> iter 61000, loss: 0.431066
 >> iter 62000, loss: 0.291698
 >> iter 63000, loss: 0.146121
 >> iter 64000, loss: 0.121119
 >> iter 65000, loss: 0.198973
 >> iter 66000, loss: 0.307553
 >> iter 67000, loss: 0.309318
 >> iter 68000, loss: 0.363279
 >> iter 69000, loss: 0.626375
 >> iter 70000, loss: 0.393335
   Number of active neurons: 5
 >> iter 71000, loss: 0.302519
 >> iter 72000, loss: 0.501156
 >> iter 73000, loss: 0.344384
 >> iter 74000, loss: 0.198317
 >> iter 75000, loss: 0.243606
 >> iter 76000, loss: 0.422414
 >> iter 77000, loss: 0.450852
 >> iter 78000, loss: 0.389941
 >> iter 79000, loss: 0.435305
 >> iter 80000, loss: 0.479327
   Number of active neurons: 5
 >> iter 81000, loss: 0.393337
 >> iter 82000, loss: 0.285042
 >> iter 83000, loss: 0.310814
 >> iter 84000, loss: 0.204908
 >> iter 85000, loss: 0.231253
 >> iter 86000, loss: 0.284317
 >> iter 87000, loss: 0.232834
 >> iter 88000, loss: 0.236566
 >> iter 89000, loss: 0.341529
 >> iter 90000, loss: 0.204279
   Number of active neurons: 5
 >> iter 91000, loss: 0.228656
 >> iter 92000, loss: 0.350733
 >> iter 93000, loss: 0.289918
 >> iter 94000, loss: 0.170714
 >> iter 95000, loss: 0.369297
 >> iter 96000, loss: 0.386758
 >> iter 97000, loss: 0.349352
 >> iter 98000, loss: 0.241429
 >> iter 99000, loss: 0.331841
 >> iter 100000, loss: 0.233145
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.733419
 >> iter 2000, loss: 9.659146
 >> iter 3000, loss: 4.713446
 >> iter 4000, loss: 2.300349
 >> iter 5000, loss: 1.283971
 >> iter 6000, loss: 0.847185
 >> iter 7000, loss: 0.653996
 >> iter 8000, loss: 0.571813
 >> iter 9000, loss: 0.439871
 >> iter 10000, loss: 0.309503
   Number of active neurons: 4
 >> iter 11000, loss: 0.435216
 >> iter 12000, loss: 0.345691
 >> iter 13000, loss: 0.322755
 >> iter 14000, loss: 0.396829
 >> iter 15000, loss: 0.363999
 >> iter 16000, loss: 0.332416
 >> iter 17000, loss: 0.325065
 >> iter 18000, loss: 0.241710
 >> iter 19000, loss: 0.414843
 >> iter 20000, loss: 0.363196
   Number of active neurons: 4
 >> iter 21000, loss: 0.469976
 >> iter 22000, loss: 0.254889
 >> iter 23000, loss: 0.300269
 >> iter 24000, loss: 0.574769
 >> iter 25000, loss: 0.606129
 >> iter 26000, loss: 0.355421
 >> iter 27000, loss: 0.283968
 >> iter 28000, loss: 0.228203
 >> iter 29000, loss: 0.296321
 >> iter 30000, loss: 0.254171
   Number of active neurons: 3
 >> iter 31000, loss: 0.240464
 >> iter 32000, loss: 0.161832
 >> iter 33000, loss: 0.415505
 >> iter 34000, loss: 0.359421
 >> iter 35000, loss: 0.366565
 >> iter 36000, loss: 0.281357
 >> iter 37000, loss: 0.231394
 >> iter 38000, loss: 0.264493
 >> iter 39000, loss: 0.371922
 >> iter 40000, loss: 0.204808
   Number of active neurons: 3
 >> iter 41000, loss: 0.348698
 >> iter 42000, loss: 0.310749
 >> iter 43000, loss: 0.292231
 >> iter 44000, loss: 0.248202
 >> iter 45000, loss: 0.285606
 >> iter 46000, loss: 0.417111
 >> iter 47000, loss: 0.294098
 >> iter 48000, loss: 0.347970
 >> iter 49000, loss: 0.383448
 >> iter 50000, loss: 0.379333
   Number of active neurons: 3
 >> iter 51000, loss: 0.256620
 >> iter 52000, loss: 0.215740
 >> iter 53000, loss: 0.268428
 >> iter 54000, loss: 0.352541
 >> iter 55000, loss: 0.293383
 >> iter 56000, loss: 0.173522
 >> iter 57000, loss: 0.184024
 >> iter 58000, loss: 0.344109
 >> iter 59000, loss: 0.279122
 >> iter 60000, loss: 0.218302
   Number of active neurons: 3
 >> iter 61000, loss: 0.281915
 >> iter 62000, loss: 0.277633
 >> iter 63000, loss: 0.197480
 >> iter 64000, loss: 0.373042
 >> iter 65000, loss: 0.567599
 >> iter 66000, loss: 0.463445
 >> iter 67000, loss: 0.376558
 >> iter 68000, loss: 0.271244
 >> iter 69000, loss: 0.215354
 >> iter 70000, loss: 0.285765
   Number of active neurons: 3
 >> iter 71000, loss: 0.352250
 >> iter 72000, loss: 0.417678
 >> iter 73000, loss: 0.239508
 >> iter 74000, loss: 0.161609
 >> iter 75000, loss: 0.274644
 >> iter 76000, loss: 0.183343
 >> iter 77000, loss: 0.317555
 >> iter 78000, loss: 0.268020
 >> iter 79000, loss: 0.371311
 >> iter 80000, loss: 0.451289
   Number of active neurons: 3
 >> iter 81000, loss: 0.443236
 >> iter 82000, loss: 0.332296
 >> iter 83000, loss: 0.232449
 >> iter 84000, loss: 0.232188
 >> iter 85000, loss: 0.209405
 >> iter 86000, loss: 0.332663
 >> iter 87000, loss: 0.155388
 >> iter 88000, loss: 0.236498
 >> iter 89000, loss: 0.332365
 >> iter 90000, loss: 0.441196
   Number of active neurons: 3
 >> iter 91000, loss: 0.402158
 >> iter 92000, loss: 0.415797
 >> iter 93000, loss: 0.341006
 >> iter 94000, loss: 0.349951
 >> iter 95000, loss: 0.306978
 >> iter 96000, loss: 0.370387
 >> iter 97000, loss: 0.267032
 >> iter 98000, loss: 0.178323
 >> iter 99000, loss: 0.113012
 >> iter 100000, loss: 0.229087
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.326085
 >> iter 2000, loss: 8.381098
 >> iter 3000, loss: 3.911259
 >> iter 4000, loss: 1.895976
 >> iter 5000, loss: 0.987520
 >> iter 6000, loss: 0.589383
 >> iter 7000, loss: 0.503857
 >> iter 8000, loss: 0.398019
 >> iter 9000, loss: 0.347073
 >> iter 10000, loss: 0.331013
   Number of active neurons: 4
 >> iter 11000, loss: 0.404672
 >> iter 12000, loss: 0.309720
 >> iter 13000, loss: 0.447189
 >> iter 14000, loss: 0.274752
 >> iter 15000, loss: 0.414384
 >> iter 16000, loss: 0.307370
 >> iter 17000, loss: 0.246568
 >> iter 18000, loss: 0.311395
 >> iter 19000, loss: 0.309630
 >> iter 20000, loss: 0.473200
   Number of active neurons: 4
 >> iter 21000, loss: 0.386401
 >> iter 22000, loss: 0.388167
 >> iter 23000, loss: 0.231398
 >> iter 24000, loss: 0.234432
 >> iter 25000, loss: 0.365846
 >> iter 26000, loss: 0.294555
 >> iter 27000, loss: 0.290869
 >> iter 28000, loss: 0.245824
 >> iter 29000, loss: 0.199708
 >> iter 30000, loss: 0.260662
   Number of active neurons: 4
 >> iter 31000, loss: 0.227424
 >> iter 32000, loss: 0.198320
 >> iter 33000, loss: 0.237760
 >> iter 34000, loss: 0.225310
 >> iter 35000, loss: 0.268719
 >> iter 36000, loss: 0.316128
 >> iter 37000, loss: 0.153986
 >> iter 38000, loss: 0.198418
 >> iter 39000, loss: 0.129768
 >> iter 40000, loss: 0.318255
   Number of active neurons: 4
 >> iter 41000, loss: 0.271308
 >> iter 42000, loss: 0.463658
 >> iter 43000, loss: 0.419171
 >> iter 44000, loss: 0.243379
 >> iter 45000, loss: 0.261764
 >> iter 46000, loss: 0.351338
 >> iter 47000, loss: 0.266398
 >> iter 48000, loss: 0.466980
 >> iter 49000, loss: 0.394785
 >> iter 50000, loss: 0.333894
   Number of active neurons: 4
 >> iter 51000, loss: 0.402753
 >> iter 52000, loss: 0.339841
 >> iter 53000, loss: 0.246551
 >> iter 54000, loss: 0.165085
 >> iter 55000, loss: 0.246882
 >> iter 56000, loss: 0.263994
 >> iter 57000, loss: 0.210207
 >> iter 58000, loss: 0.227001
 >> iter 59000, loss: 0.161049
 >> iter 60000, loss: 0.136520
   Number of active neurons: 4
 >> iter 61000, loss: 0.311943
 >> iter 62000, loss: 0.221294
 >> iter 63000, loss: 0.306864
 >> iter 64000, loss: 0.271719
 >> iter 65000, loss: 0.216838
 >> iter 66000, loss: 0.266385
 >> iter 67000, loss: 0.237015
 >> iter 68000, loss: 0.198590
 >> iter 69000, loss: 0.214073
 >> iter 70000, loss: 0.196993
   Number of active neurons: 4
 >> iter 71000, loss: 0.270094
 >> iter 72000, loss: 0.216039
 >> iter 73000, loss: 0.299928
 >> iter 74000, loss: 0.224189
 >> iter 75000, loss: 0.272877
 >> iter 76000, loss: 0.431849
 >> iter 77000, loss: 0.291560
 >> iter 78000, loss: 0.262094
 >> iter 79000, loss: 0.598394
 >> iter 80000, loss: 0.380490
   Number of active neurons: 4
 >> iter 81000, loss: 0.233134
 >> iter 82000, loss: 0.413513
 >> iter 83000, loss: 0.384044
 >> iter 84000, loss: 0.213113
 >> iter 85000, loss: 0.346739
 >> iter 86000, loss: 0.221349
 >> iter 87000, loss: 0.378477
 >> iter 88000, loss: 0.341635
 >> iter 89000, loss: 0.326420
 >> iter 90000, loss: 0.197047
   Number of active neurons: 4
 >> iter 91000, loss: 0.294868
 >> iter 92000, loss: 0.201943
 >> iter 93000, loss: 0.318607
 >> iter 94000, loss: 0.371687
 >> iter 95000, loss: 0.402188
 >> iter 96000, loss: 0.351904
 >> iter 97000, loss: 0.391253
 >> iter 98000, loss: 0.347199
 >> iter 99000, loss: 0.248177
 >> iter 100000, loss: 0.151729
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.413611
 >> iter 2000, loss: 9.404262
 >> iter 3000, loss: 4.572873
 >> iter 4000, loss: 2.289781
 >> iter 5000, loss: 1.322004
 >> iter 6000, loss: 0.839796
 >> iter 7000, loss: 0.648813
 >> iter 8000, loss: 0.464561
 >> iter 9000, loss: 0.672039
 >> iter 10000, loss: 0.538324
   Number of active neurons: 4
 >> iter 11000, loss: 0.448094
 >> iter 12000, loss: 0.361841
 >> iter 13000, loss: 0.259836
 >> iter 14000, loss: 0.410532
 >> iter 15000, loss: 0.407848
 >> iter 16000, loss: 0.393196
 >> iter 17000, loss: 0.338156
 >> iter 18000, loss: 0.339626
 >> iter 19000, loss: 0.286899
 >> iter 20000, loss: 0.409125
   Number of active neurons: 4
 >> iter 21000, loss: 0.553603
 >> iter 22000, loss: 0.453451
 >> iter 23000, loss: 0.306376
 >> iter 24000, loss: 0.436862
 >> iter 25000, loss: 0.392119
 >> iter 26000, loss: 0.462570
 >> iter 27000, loss: 0.572917
 >> iter 28000, loss: 0.372161
 >> iter 29000, loss: 0.289943
 >> iter 30000, loss: 0.328087
   Number of active neurons: 4
 >> iter 31000, loss: 0.226334
 >> iter 32000, loss: 0.422540
 >> iter 33000, loss: 0.481604
 >> iter 34000, loss: 0.267914
 >> iter 35000, loss: 0.367201
 >> iter 36000, loss: 0.446676
 >> iter 37000, loss: 0.334446
 >> iter 38000, loss: 0.403198
 >> iter 39000, loss: 0.418861
 >> iter 40000, loss: 0.240546
   Number of active neurons: 3
 >> iter 41000, loss: 0.480721
 >> iter 42000, loss: 0.340246
 >> iter 43000, loss: 0.286558
 >> iter 44000, loss: 0.183597
 >> iter 45000, loss: 0.261626
 >> iter 46000, loss: 0.317050
 >> iter 47000, loss: 0.345791
 >> iter 48000, loss: 0.277225
 >> iter 49000, loss: 0.288518
 >> iter 50000, loss: 0.225483
   Number of active neurons: 3
 >> iter 51000, loss: 0.475360
 >> iter 52000, loss: 0.269579
 >> iter 53000, loss: 0.212800
 >> iter 54000, loss: 0.266137
 >> iter 55000, loss: 0.297069
 >> iter 56000, loss: 0.428779
 >> iter 57000, loss: 0.341882
 >> iter 58000, loss: 0.332715
 >> iter 59000, loss: 0.447534
 >> iter 60000, loss: 0.316000
   Number of active neurons: 3
 >> iter 61000, loss: 0.235020
 >> iter 62000, loss: 0.253156
 >> iter 63000, loss: 0.251794
 >> iter 64000, loss: 0.188559
 >> iter 65000, loss: 0.471514
 >> iter 66000, loss: 0.444405
 >> iter 67000, loss: 0.464017
 >> iter 68000, loss: 0.236245
 >> iter 69000, loss: 0.224068
 >> iter 70000, loss: 0.266137
   Number of active neurons: 3
 >> iter 71000, loss: 0.221010
 >> iter 72000, loss: 0.273583
 >> iter 73000, loss: 0.239249
 >> iter 74000, loss: 0.287211
 >> iter 75000, loss: 0.504530
 >> iter 76000, loss: 0.395397
 >> iter 77000, loss: 0.378367
 >> iter 78000, loss: 0.292459
 >> iter 79000, loss: 0.311550
 >> iter 80000, loss: 0.306732
   Number of active neurons: 3
 >> iter 81000, loss: 0.444755
 >> iter 82000, loss: 0.275422
 >> iter 83000, loss: 0.319984
 >> iter 84000, loss: 0.482736
 >> iter 85000, loss: 0.418124
 >> iter 86000, loss: 0.211477
 >> iter 87000, loss: 0.395525
 >> iter 88000, loss: 0.277012
 >> iter 89000, loss: 0.283094
 >> iter 90000, loss: 0.167256
   Number of active neurons: 3
 >> iter 91000, loss: 0.123046
 >> iter 92000, loss: 0.188185
 >> iter 93000, loss: 0.417105
 >> iter 94000, loss: 0.258853
 >> iter 95000, loss: 0.189202
 >> iter 96000, loss: 0.401409
 >> iter 97000, loss: 0.213170
 >> iter 98000, loss: 0.217568
 >> iter 99000, loss: 0.141646
 >> iter 100000, loss: 0.112482
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.010128
 >> iter 2000, loss: 9.302708
 >> iter 3000, loss: 4.408952
 >> iter 4000, loss: 2.180828
 >> iter 5000, loss: 1.190769
 >> iter 6000, loss: 0.555850
 >> iter 7000, loss: 0.623632
 >> iter 8000, loss: 0.430765
 >> iter 9000, loss: 0.549054
 >> iter 10000, loss: 0.289674
   Number of active neurons: 5
 >> iter 11000, loss: 0.248853
 >> iter 12000, loss: 0.284820
 >> iter 13000, loss: 0.407231
 >> iter 14000, loss: 0.451900
 >> iter 15000, loss: 0.442406
 >> iter 16000, loss: 0.396893
 >> iter 17000, loss: 0.309277
 >> iter 18000, loss: 0.189608
 >> iter 19000, loss: 0.298895
 >> iter 20000, loss: 0.403660
   Number of active neurons: 5
 >> iter 21000, loss: 0.383742
 >> iter 22000, loss: 0.329513
 >> iter 23000, loss: 0.381252
 >> iter 24000, loss: 0.398016
 >> iter 25000, loss: 0.348623
 >> iter 26000, loss: 0.346354
 >> iter 27000, loss: 0.209039
 >> iter 28000, loss: 0.246667
 >> iter 29000, loss: 0.395551
 >> iter 30000, loss: 0.328771
   Number of active neurons: 4
 >> iter 31000, loss: 0.376065
 >> iter 32000, loss: 0.208395
 >> iter 33000, loss: 0.527198
 >> iter 34000, loss: 0.506968
 >> iter 35000, loss: 0.466407
 >> iter 36000, loss: 0.451450
 >> iter 37000, loss: 0.455294
 >> iter 38000, loss: 0.343786
 >> iter 39000, loss: 0.243501
 >> iter 40000, loss: 0.253942
   Number of active neurons: 4
 >> iter 41000, loss: 0.315259
 >> iter 42000, loss: 0.374433
 >> iter 43000, loss: 0.203870
 >> iter 44000, loss: 0.329666
 >> iter 45000, loss: 0.312282
 >> iter 46000, loss: 0.256566
 >> iter 47000, loss: 0.257356
 >> iter 48000, loss: 0.498762
 >> iter 49000, loss: 0.371351
 >> iter 50000, loss: 0.355529
   Number of active neurons: 4
 >> iter 51000, loss: 0.267998
 >> iter 52000, loss: 0.370493
 >> iter 53000, loss: 0.290469
 >> iter 54000, loss: 0.269465
 >> iter 55000, loss: 0.244151
 >> iter 56000, loss: 0.449135
 >> iter 57000, loss: 0.292055
 >> iter 58000, loss: 0.183830
 >> iter 59000, loss: 0.151170
 >> iter 60000, loss: 0.305407
   Number of active neurons: 3
 >> iter 61000, loss: 0.505997
 >> iter 62000, loss: 0.297720
 >> iter 63000, loss: 0.219996
 >> iter 64000, loss: 0.233979
 >> iter 65000, loss: 0.151826
 >> iter 66000, loss: 0.321161
 >> iter 67000, loss: 0.245534
 >> iter 68000, loss: 0.245553
 >> iter 69000, loss: 0.205411
 >> iter 70000, loss: 0.236737
   Number of active neurons: 3
 >> iter 71000, loss: 0.311365
 >> iter 72000, loss: 0.224194
 >> iter 73000, loss: 0.267994
 >> iter 74000, loss: 0.288334
 >> iter 75000, loss: 0.415021
 >> iter 76000, loss: 0.285306
 >> iter 77000, loss: 0.229342
 >> iter 78000, loss: 0.262610
 >> iter 79000, loss: 0.211482
 >> iter 80000, loss: 0.233169
   Number of active neurons: 3
 >> iter 81000, loss: 0.266737
 >> iter 82000, loss: 0.230573
 >> iter 83000, loss: 0.185205
 >> iter 84000, loss: 0.322496
 >> iter 85000, loss: 0.290431
 >> iter 86000, loss: 0.323801
 >> iter 87000, loss: 0.251000
 >> iter 88000, loss: 0.491677
 >> iter 89000, loss: 0.302060
 >> iter 90000, loss: 0.330636
   Number of active neurons: 3
 >> iter 91000, loss: 0.184978
 >> iter 92000, loss: 0.205788
 >> iter 93000, loss: 0.243570
 >> iter 94000, loss: 0.316360
 >> iter 95000, loss: 0.312976
 >> iter 96000, loss: 0.190706
 >> iter 97000, loss: 0.166102
 >> iter 98000, loss: 0.215903
 >> iter 99000, loss: 0.171677
 >> iter 100000, loss: 0.133725
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.391061
 >> iter 2000, loss: 8.858128
 >> iter 3000, loss: 4.107964
 >> iter 4000, loss: 1.818029
 >> iter 5000, loss: 0.965876
 >> iter 6000, loss: 0.583794
 >> iter 7000, loss: 0.385697
 >> iter 8000, loss: 0.306948
 >> iter 9000, loss: 0.357795
 >> iter 10000, loss: 0.316849
   Number of active neurons: 4
 >> iter 11000, loss: 0.245047
 >> iter 12000, loss: 0.180637
 >> iter 13000, loss: 0.180767
 >> iter 14000, loss: 0.237407
 >> iter 15000, loss: 0.201984
 >> iter 16000, loss: 0.320219
 >> iter 17000, loss: 0.252658
 >> iter 18000, loss: 0.389300
 >> iter 19000, loss: 0.521305
 >> iter 20000, loss: 0.415252
   Number of active neurons: 3
 >> iter 21000, loss: 0.718938
 >> iter 22000, loss: 0.392335
 >> iter 23000, loss: 0.308827
 >> iter 24000, loss: 0.242125
 >> iter 25000, loss: 0.338611
 >> iter 26000, loss: 0.292385
 >> iter 27000, loss: 0.321489
 >> iter 28000, loss: 0.207615
 >> iter 29000, loss: 0.400869
 >> iter 30000, loss: 0.288146
   Number of active neurons: 3
 >> iter 31000, loss: 0.316744
 >> iter 32000, loss: 0.381227
 >> iter 33000, loss: 0.187352
 >> iter 34000, loss: 0.389217
 >> iter 35000, loss: 0.564842
 >> iter 36000, loss: 0.427737
 >> iter 37000, loss: 0.240192
 >> iter 38000, loss: 0.211530
 >> iter 39000, loss: 0.213752
 >> iter 40000, loss: 0.378287
   Number of active neurons: 3
 >> iter 41000, loss: 0.284707
 >> iter 42000, loss: 0.243872
 >> iter 43000, loss: 0.357457
 >> iter 44000, loss: 0.190037
 >> iter 45000, loss: 0.459691
 >> iter 46000, loss: 0.268635
 >> iter 47000, loss: 0.395981
 >> iter 48000, loss: 0.303659
 >> iter 49000, loss: 0.201317
 >> iter 50000, loss: 0.222922
   Number of active neurons: 3
 >> iter 51000, loss: 0.285127
 >> iter 52000, loss: 0.218327
 >> iter 53000, loss: 0.236616
 >> iter 54000, loss: 0.300130
 >> iter 55000, loss: 0.184205
 >> iter 56000, loss: 0.269314
 >> iter 57000, loss: 0.344864
 >> iter 58000, loss: 0.214703
 >> iter 59000, loss: 0.207695
 >> iter 60000, loss: 0.138468
   Number of active neurons: 3
 >> iter 61000, loss: 0.253636
 >> iter 62000, loss: 0.316452
 >> iter 63000, loss: 0.281474
 >> iter 64000, loss: 0.359486
 >> iter 65000, loss: 0.260828
 >> iter 66000, loss: 0.131465
 >> iter 67000, loss: 0.360460
 >> iter 68000, loss: 0.211381
 >> iter 69000, loss: 0.152157
 >> iter 70000, loss: 0.085340
   Number of active neurons: 3
 >> iter 71000, loss: 0.120238
 >> iter 72000, loss: 0.231906
 >> iter 73000, loss: 0.263545
 >> iter 74000, loss: 0.219266
 >> iter 75000, loss: 0.180346
 >> iter 76000, loss: 0.166175
 >> iter 77000, loss: 0.448086
 >> iter 78000, loss: 0.201778
 >> iter 79000, loss: 0.254097
 >> iter 80000, loss: 0.342993
   Number of active neurons: 3
 >> iter 81000, loss: 0.239291
 >> iter 82000, loss: 0.351897
 >> iter 83000, loss: 0.322155
 >> iter 84000, loss: 0.267324
 >> iter 85000, loss: 0.276443
 >> iter 86000, loss: 0.311547
 >> iter 87000, loss: 0.390425
 >> iter 88000, loss: 0.186090
 >> iter 89000, loss: 0.137415
 >> iter 90000, loss: 0.185874
   Number of active neurons: 3
 >> iter 91000, loss: 0.234833
 >> iter 92000, loss: 0.119217
 >> iter 93000, loss: 0.178503
 >> iter 94000, loss: 0.261054
 >> iter 95000, loss: 0.320186
 >> iter 96000, loss: 0.404780
 >> iter 97000, loss: 0.291901
 >> iter 98000, loss: 0.334398
 >> iter 99000, loss: 0.298504
 >> iter 100000, loss: 0.194039
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.812265
 >> iter 2000, loss: 8.778120
 >> iter 3000, loss: 3.747187
 >> iter 4000, loss: 1.726050
 >> iter 5000, loss: 1.007793
 >> iter 6000, loss: 0.575591
 >> iter 7000, loss: 0.480191
 >> iter 8000, loss: 0.277558
 >> iter 9000, loss: 0.392995
 >> iter 10000, loss: 0.455651
   Number of active neurons: 4
 >> iter 11000, loss: 0.450266
 >> iter 12000, loss: 0.469970
 >> iter 13000, loss: 0.294339
 >> iter 14000, loss: 0.488990
 >> iter 15000, loss: 0.348092
 >> iter 16000, loss: 0.590130
 >> iter 17000, loss: 0.582504
 >> iter 18000, loss: 0.433286
 >> iter 19000, loss: 0.528413
 >> iter 20000, loss: 0.359079
   Number of active neurons: 4
 >> iter 21000, loss: 0.353934
 >> iter 22000, loss: 0.264349
 >> iter 23000, loss: 0.300844
 >> iter 24000, loss: 0.320433
 >> iter 25000, loss: 0.354721
 >> iter 26000, loss: 0.205639
 >> iter 27000, loss: 0.210834
 >> iter 28000, loss: 0.218602
 >> iter 29000, loss: 0.309216
 >> iter 30000, loss: 0.221359
   Number of active neurons: 4
 >> iter 31000, loss: 0.285491
 >> iter 32000, loss: 0.319118
 >> iter 33000, loss: 0.297963
 >> iter 34000, loss: 0.394729
 >> iter 35000, loss: 0.449698
 >> iter 36000, loss: 0.210909
 >> iter 37000, loss: 0.231176
 >> iter 38000, loss: 0.300521
 >> iter 39000, loss: 0.244455
 >> iter 40000, loss: 0.208317
   Number of active neurons: 3
 >> iter 41000, loss: 0.440491
 >> iter 42000, loss: 0.408796
 >> iter 43000, loss: 0.346407
 >> iter 44000, loss: 0.349713
 >> iter 45000, loss: 0.279717
 >> iter 46000, loss: 0.386566
 >> iter 47000, loss: 0.227557
 >> iter 48000, loss: 0.205565
 >> iter 49000, loss: 0.366922
 >> iter 50000, loss: 0.336653
   Number of active neurons: 3
 >> iter 51000, loss: 0.370202
 >> iter 52000, loss: 0.249431
 >> iter 53000, loss: 0.145459
 >> iter 54000, loss: 0.242215
 >> iter 55000, loss: 0.292339
 >> iter 56000, loss: 0.478815
 >> iter 57000, loss: 0.301379
 >> iter 58000, loss: 0.442734
 >> iter 59000, loss: 0.346073
 >> iter 60000, loss: 0.345339
   Number of active neurons: 3
 >> iter 61000, loss: 0.239474
 >> iter 62000, loss: 0.426587
 >> iter 63000, loss: 0.299397
 >> iter 64000, loss: 0.288554
 >> iter 65000, loss: 0.376800
 >> iter 66000, loss: 0.190914
 >> iter 67000, loss: 0.126227
 >> iter 68000, loss: 0.225993
 >> iter 69000, loss: 0.239798
 >> iter 70000, loss: 0.446471
   Number of active neurons: 3
 >> iter 71000, loss: 0.244491
 >> iter 72000, loss: 0.223382
 >> iter 73000, loss: 0.434623
 >> iter 74000, loss: 0.259383
 >> iter 75000, loss: 0.266448
 >> iter 76000, loss: 0.212970
 >> iter 77000, loss: 0.257034
 >> iter 78000, loss: 0.196398
 >> iter 79000, loss: 0.241962
 >> iter 80000, loss: 0.196779
   Number of active neurons: 3
 >> iter 81000, loss: 0.251497
 >> iter 82000, loss: 0.193870
 >> iter 83000, loss: 0.109098
 >> iter 84000, loss: 0.190624
 >> iter 85000, loss: 0.285340
 >> iter 86000, loss: 0.176067
 >> iter 87000, loss: 0.215495
 >> iter 88000, loss: 0.259245
 >> iter 89000, loss: 0.293614
 >> iter 90000, loss: 0.450799
   Number of active neurons: 3
 >> iter 91000, loss: 0.195585
 >> iter 92000, loss: 0.191800
 >> iter 93000, loss: 0.313814
 >> iter 94000, loss: 0.327779
 >> iter 95000, loss: 0.208435
 >> iter 96000, loss: 0.355095
 >> iter 97000, loss: 0.253042
 >> iter 98000, loss: 0.203905
 >> iter 99000, loss: 0.145976
 >> iter 100000, loss: 0.250380
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.799178
 >> iter 2000, loss: 8.442798
 >> iter 3000, loss: 3.844575
 >> iter 4000, loss: 2.059184
 >> iter 5000, loss: 1.236199
 >> iter 6000, loss: 0.659977
 >> iter 7000, loss: 0.573580
 >> iter 8000, loss: 0.358120
 >> iter 9000, loss: 0.461244
 >> iter 10000, loss: 0.483482
   Number of active neurons: 4
 >> iter 11000, loss: 0.511869
 >> iter 12000, loss: 0.468529
 >> iter 13000, loss: 0.410269
 >> iter 14000, loss: 0.513967
 >> iter 15000, loss: 0.314595
 >> iter 16000, loss: 0.374082
 >> iter 17000, loss: 0.372418
 >> iter 18000, loss: 0.418848
 >> iter 19000, loss: 0.282897
 >> iter 20000, loss: 0.296578
   Number of active neurons: 4
 >> iter 21000, loss: 0.309860
 >> iter 22000, loss: 0.444303
 >> iter 23000, loss: 0.280984
 >> iter 24000, loss: 0.330490
 >> iter 25000, loss: 0.336978
 >> iter 26000, loss: 0.274921
 >> iter 27000, loss: 0.364921
 >> iter 28000, loss: 0.366157
 >> iter 29000, loss: 0.276448
 >> iter 30000, loss: 0.381144
   Number of active neurons: 4
 >> iter 31000, loss: 0.292951
 >> iter 32000, loss: 0.516176
 >> iter 33000, loss: 0.609996
 >> iter 34000, loss: 0.417336
 >> iter 35000, loss: 0.330596
 >> iter 36000, loss: 0.237696
 >> iter 37000, loss: 0.554045
 >> iter 38000, loss: 0.430390
 >> iter 39000, loss: 0.357216
 >> iter 40000, loss: 0.498155
   Number of active neurons: 4
 >> iter 41000, loss: 0.399681
 >> iter 42000, loss: 0.389061
 >> iter 43000, loss: 0.552659
 >> iter 44000, loss: 0.587058
 >> iter 45000, loss: 0.489493
 >> iter 46000, loss: 0.385543
 >> iter 47000, loss: 0.330507
 >> iter 48000, loss: 0.183275
 >> iter 49000, loss: 0.196532
 >> iter 50000, loss: 0.172946
   Number of active neurons: 4
 >> iter 51000, loss: 0.249480
 >> iter 52000, loss: 0.322995
 >> iter 53000, loss: 0.345784
 >> iter 54000, loss: 0.391807
 >> iter 55000, loss: 0.312065
 >> iter 56000, loss: 0.424695
 >> iter 57000, loss: 0.200502
 >> iter 58000, loss: 0.165671
 >> iter 59000, loss: 0.410476
 >> iter 60000, loss: 0.276405
   Number of active neurons: 4
 >> iter 61000, loss: 0.312596
 >> iter 62000, loss: 0.217372
 >> iter 63000, loss: 0.486359
 >> iter 64000, loss: 0.473661
 >> iter 65000, loss: 0.322395
 >> iter 66000, loss: 0.361666
 >> iter 67000, loss: 0.381600
 >> iter 68000, loss: 0.277583
 >> iter 69000, loss: 0.175599
 >> iter 70000, loss: 0.396409
   Number of active neurons: 4
 >> iter 71000, loss: 0.341987
 >> iter 72000, loss: 0.284107
 >> iter 73000, loss: 0.396032
 >> iter 74000, loss: 0.301970
 >> iter 75000, loss: 0.514435
 >> iter 76000, loss: 0.333704
 >> iter 77000, loss: 0.350339
 >> iter 78000, loss: 0.243835
 >> iter 79000, loss: 0.268281
 >> iter 80000, loss: 0.226144
   Number of active neurons: 4
 >> iter 81000, loss: 0.395818
 >> iter 82000, loss: 0.232091
 >> iter 83000, loss: 0.145303
 >> iter 84000, loss: 0.220618
 >> iter 85000, loss: 0.471794
 >> iter 86000, loss: 0.306017
 >> iter 87000, loss: 0.445087
 >> iter 88000, loss: 0.518696
 >> iter 89000, loss: 0.383297
 >> iter 90000, loss: 0.219307
   Number of active neurons: 4
 >> iter 91000, loss: 0.324869
 >> iter 92000, loss: 0.397010
 >> iter 93000, loss: 0.279507
 >> iter 94000, loss: 0.243225
 >> iter 95000, loss: 0.292149
 >> iter 96000, loss: 0.444125
 >> iter 97000, loss: 0.316849
 >> iter 98000, loss: 0.239182
 >> iter 99000, loss: 0.343215
 >> iter 100000, loss: 0.249412
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.572075
 >> iter 2000, loss: 8.396350
 >> iter 3000, loss: 3.974669
 >> iter 4000, loss: 1.964508
 >> iter 5000, loss: 0.940761
 >> iter 6000, loss: 0.625343
 >> iter 7000, loss: 0.504408
 >> iter 8000, loss: 0.617441
 >> iter 9000, loss: 0.492088
 >> iter 10000, loss: 0.407717
   Number of active neurons: 5
 >> iter 11000, loss: 0.261237
 >> iter 12000, loss: 0.250596
 >> iter 13000, loss: 0.269600
 >> iter 14000, loss: 0.485685
 >> iter 15000, loss: 0.396533
 >> iter 16000, loss: 0.277194
 >> iter 17000, loss: 0.277990
 >> iter 18000, loss: 0.344762
 >> iter 19000, loss: 0.294386
 >> iter 20000, loss: 0.228769
   Number of active neurons: 5
 >> iter 21000, loss: 0.369658
 >> iter 22000, loss: 0.299544
 >> iter 23000, loss: 0.281783
 >> iter 24000, loss: 0.298405
 >> iter 25000, loss: 0.352245
 >> iter 26000, loss: 0.356169
 >> iter 27000, loss: 0.243744
 >> iter 28000, loss: 0.575774
 >> iter 29000, loss: 0.433538
 >> iter 30000, loss: 0.319913
   Number of active neurons: 5
 >> iter 31000, loss: 0.338868
 >> iter 32000, loss: 0.336026
 >> iter 33000, loss: 0.323289
 >> iter 34000, loss: 0.287758
 >> iter 35000, loss: 0.378334
 >> iter 36000, loss: 0.356026
 >> iter 37000, loss: 0.323428
 >> iter 38000, loss: 0.483228
 >> iter 39000, loss: 0.297999
 >> iter 40000, loss: 0.215583
   Number of active neurons: 4
 >> iter 41000, loss: 0.134929
 >> iter 42000, loss: 0.414224
 >> iter 43000, loss: 0.262367
 >> iter 44000, loss: 0.252679
 >> iter 45000, loss: 0.311766
 >> iter 46000, loss: 0.250646
 >> iter 47000, loss: 0.256062
 >> iter 48000, loss: 0.277002
 >> iter 49000, loss: 0.320326
 >> iter 50000, loss: 0.227491
   Number of active neurons: 4
 >> iter 51000, loss: 0.212782
 >> iter 52000, loss: 0.441274
 >> iter 53000, loss: 0.261157
 >> iter 54000, loss: 0.272550
 >> iter 55000, loss: 0.150526
 >> iter 56000, loss: 0.198225
 >> iter 57000, loss: 0.259487
 >> iter 58000, loss: 0.123313
 >> iter 59000, loss: 0.216085
 >> iter 60000, loss: 0.337884
   Number of active neurons: 4
 >> iter 61000, loss: 0.266916
 >> iter 62000, loss: 0.479803
 >> iter 63000, loss: 0.260043
 >> iter 64000, loss: 0.236739
 >> iter 65000, loss: 0.347417
 >> iter 66000, loss: 0.211215
 >> iter 67000, loss: 0.184494
 >> iter 68000, loss: 0.216590
 >> iter 69000, loss: 0.259289
 >> iter 70000, loss: 0.366334
   Number of active neurons: 3
 >> iter 71000, loss: 0.399702
 >> iter 72000, loss: 0.254527
 >> iter 73000, loss: 0.284565
 >> iter 74000, loss: 0.217643
 >> iter 75000, loss: 0.160042
 >> iter 76000, loss: 0.254942
 >> iter 77000, loss: 0.386625
 >> iter 78000, loss: 0.328686
 >> iter 79000, loss: 0.174009
 >> iter 80000, loss: 0.418062
   Number of active neurons: 3
 >> iter 81000, loss: 0.227221
 >> iter 82000, loss: 0.305248
 >> iter 83000, loss: 0.291413
 >> iter 84000, loss: 0.277791
 >> iter 85000, loss: 0.379361
 >> iter 86000, loss: 0.437754
 >> iter 87000, loss: 0.289738
 >> iter 88000, loss: 0.312667
 >> iter 89000, loss: 0.290725
 >> iter 90000, loss: 0.256777
   Number of active neurons: 3
 >> iter 91000, loss: 0.296142
 >> iter 92000, loss: 0.271266
 >> iter 93000, loss: 0.191451
 >> iter 94000, loss: 0.296734
 >> iter 95000, loss: 0.250292
 >> iter 96000, loss: 0.400034
 >> iter 97000, loss: 0.266401
 >> iter 98000, loss: 0.188760
 >> iter 99000, loss: 0.153207
 >> iter 100000, loss: 0.265749
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.789789
 >> iter 2000, loss: 8.850628
 >> iter 3000, loss: 3.981598
 >> iter 4000, loss: 1.779869
 >> iter 5000, loss: 1.093220
 >> iter 6000, loss: 0.648830
 >> iter 7000, loss: 0.615069
 >> iter 8000, loss: 0.486917
 >> iter 9000, loss: 0.438611
 >> iter 10000, loss: 0.264988
   Number of active neurons: 7
 >> iter 11000, loss: 0.467481
 >> iter 12000, loss: 0.400738
 >> iter 13000, loss: 0.455681
 >> iter 14000, loss: 0.277852
 >> iter 15000, loss: 0.324028
 >> iter 16000, loss: 0.246032
 >> iter 17000, loss: 0.325430
 >> iter 18000, loss: 0.204428
 >> iter 19000, loss: 0.190725
 >> iter 20000, loss: 0.329293
   Number of active neurons: 6
 >> iter 21000, loss: 0.287348
 >> iter 22000, loss: 0.270967
 >> iter 23000, loss: 0.309537
 >> iter 24000, loss: 0.449162
 >> iter 25000, loss: 0.334653
 >> iter 26000, loss: 0.309044
 >> iter 27000, loss: 0.409222
 >> iter 28000, loss: 0.377966
 >> iter 29000, loss: 0.393045
 >> iter 30000, loss: 0.223952
   Number of active neurons: 6
 >> iter 31000, loss: 0.231713
 >> iter 32000, loss: 0.476047
 >> iter 33000, loss: 0.333541
 >> iter 34000, loss: 0.300026
 >> iter 35000, loss: 0.358751
 >> iter 36000, loss: 0.351289
 >> iter 37000, loss: 0.191681
 >> iter 38000, loss: 0.285080
 >> iter 39000, loss: 0.201591
 >> iter 40000, loss: 0.161301
   Number of active neurons: 6
 >> iter 41000, loss: 0.367123
 >> iter 42000, loss: 0.323598
 >> iter 43000, loss: 0.376159
 >> iter 44000, loss: 0.425341
 >> iter 45000, loss: 0.344403
 >> iter 46000, loss: 0.371726
 >> iter 47000, loss: 0.366708
 >> iter 48000, loss: 0.330842
 >> iter 49000, loss: 0.240729
 >> iter 50000, loss: 0.364233
   Number of active neurons: 4
 >> iter 51000, loss: 0.333995
 >> iter 52000, loss: 0.205799
 >> iter 53000, loss: 0.150348
 >> iter 54000, loss: 0.357192
 >> iter 55000, loss: 0.257993
 >> iter 56000, loss: 0.298538
 >> iter 57000, loss: 0.338545
 >> iter 58000, loss: 0.232755
 >> iter 59000, loss: 0.380465
 >> iter 60000, loss: 0.252330
   Number of active neurons: 4
 >> iter 61000, loss: 0.224506
 >> iter 62000, loss: 0.238071
 >> iter 63000, loss: 0.265399
 >> iter 64000, loss: 0.249519
 >> iter 65000, loss: 0.528389
 >> iter 66000, loss: 0.345233
 >> iter 67000, loss: 0.264422
 >> iter 68000, loss: 0.329009
 >> iter 69000, loss: 0.254084
 >> iter 70000, loss: 0.154815
   Number of active neurons: 3
 >> iter 71000, loss: 0.150573
 >> iter 72000, loss: 0.119879
 >> iter 73000, loss: 0.138962
 >> iter 74000, loss: 0.171718
 >> iter 75000, loss: 0.168545
 >> iter 76000, loss: 0.325409
 >> iter 77000, loss: 0.427055
 >> iter 78000, loss: 0.452380
 >> iter 79000, loss: 0.324156
 >> iter 80000, loss: 0.425707
   Number of active neurons: 3
 >> iter 81000, loss: 0.318609
 >> iter 82000, loss: 0.253946
 >> iter 83000, loss: 0.318326
 >> iter 84000, loss: 0.432458
 >> iter 85000, loss: 0.253092
 >> iter 86000, loss: 0.295444
 >> iter 87000, loss: 0.293793
 >> iter 88000, loss: 0.155876
 >> iter 89000, loss: 0.226430
 >> iter 90000, loss: 0.401208
   Number of active neurons: 3
 >> iter 91000, loss: 0.440741
 >> iter 92000, loss: 0.347110
 >> iter 93000, loss: 0.197438
 >> iter 94000, loss: 0.270780
 >> iter 95000, loss: 0.264981
 >> iter 96000, loss: 0.184474
 >> iter 97000, loss: 0.291118
 >> iter 98000, loss: 0.214119
 >> iter 99000, loss: 0.250911
 >> iter 100000, loss: 0.147456
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

