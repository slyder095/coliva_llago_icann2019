 > Problema: tomita6nueva
 > Args:
   - Hidden size: 4
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.958655
 >> iter 2000, loss: 15.235343
 >> iter 3000, loss: 13.813326
 >> iter 4000, loss: 13.313738
 >> iter 5000, loss: 13.099376
 >> iter 6000, loss: 13.030892
 >> iter 7000, loss: 12.988269
 >> iter 8000, loss: 12.985782
 >> iter 9000, loss: 12.969269
 >> iter 10000, loss: 12.977771
   Number of active neurons: 3
 >> iter 11000, loss: 12.962659
 >> iter 12000, loss: 12.977982
 >> iter 13000, loss: 12.962569
 >> iter 14000, loss: 12.974696
 >> iter 15000, loss: 12.965749
 >> iter 16000, loss: 12.981233
 >> iter 17000, loss: 12.957718
 >> iter 18000, loss: 12.977127
 >> iter 19000, loss: 12.963856
 >> iter 20000, loss: 12.976000
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 3
 >> iter 21000, loss: 12.983360
 >> iter 22000, loss: 12.973663
 >> iter 23000, loss: 12.947735
 >> iter 24000, loss: 12.964989
 >> iter 25000, loss: 12.952505
 >> iter 26000, loss: 12.963643
 >> iter 27000, loss: 12.951807
 >> iter 28000, loss: 12.972678
 >> iter 29000, loss: 12.954995
 >> iter 30000, loss: 12.971962
   Number of active neurons: 4
 >> iter 31000, loss: 12.946862
 >> iter 32000, loss: 12.966978
 >> iter 33000, loss: 12.957836
 >> iter 34000, loss: 12.970687
 >> iter 35000, loss: 12.956664
 >> iter 36000, loss: 12.969220
 >> iter 37000, loss: 12.948790
 >> iter 38000, loss: 12.973902
 >> iter 39000, loss: 12.945305
 >> iter 40000, loss: 12.972670
   Number of active neurons: 4
 >> iter 41000, loss: 12.954075
 >> iter 42000, loss: 12.975502
 >> iter 43000, loss: 12.950555
 >> iter 44000, loss: 12.967944
 >> iter 45000, loss: 12.951293
 >> iter 46000, loss: 12.972657
 >> iter 47000, loss: 12.948155
 >> iter 48000, loss: 12.978285
 >> iter 49000, loss: 12.954561
 >> iter 50000, loss: 12.982285
   Number of active neurons: 4
 >> iter 51000, loss: 12.951439
 >> iter 52000, loss: 12.980917
 >> iter 53000, loss: 12.955894
 >> iter 54000, loss: 12.970562
 >> iter 55000, loss: 12.942064
 >> iter 56000, loss: 12.972084
 >> iter 57000, loss: 12.947135
 >> iter 58000, loss: 12.973946
 >> iter 59000, loss: 12.949835
 >> iter 60000, loss: 12.969898
   Number of active neurons: 4
 >> iter 61000, loss: 12.943026
 >> iter 62000, loss: 12.973191
 >> iter 63000, loss: 12.952235
 >> iter 64000, loss: 12.980035
 >> iter 65000, loss: 12.954845
 >> iter 66000, loss: 12.982391
 >> iter 67000, loss: 12.954940
 >> iter 68000, loss: 12.984718
 >> iter 69000, loss: 12.957808
 >> iter 70000, loss: 12.980369
   Number of active neurons: 4
 >> iter 71000, loss: 12.952342
 >> iter 72000, loss: 12.979943
 >> iter 73000, loss: 12.948763
 >> iter 74000, loss: 12.979356
 >> iter 75000, loss: 12.950712
 >> iter 76000, loss: 12.979243
 >> iter 77000, loss: 12.954713
 >> iter 78000, loss: 12.981861
 >> iter 79000, loss: 12.951497
 >> iter 80000, loss: 12.983947
   Number of active neurons: 4
 >> iter 81000, loss: 12.944407
 >> iter 82000, loss: 12.984524
 >> iter 83000, loss: 12.943336
 >> iter 84000, loss: 12.982755
 >> iter 85000, loss: 12.950374
 >> iter 86000, loss: 12.977117
 >> iter 87000, loss: 12.952328
 >> iter 88000, loss: 12.976343
 >> iter 89000, loss: 12.950082
 >> iter 90000, loss: 12.980540
   Number of active neurons: 4
 >> iter 91000, loss: 12.948382
 >> iter 92000, loss: 12.977071
 >> iter 93000, loss: 12.947521
 >> iter 94000, loss: 12.978926
 >> iter 95000, loss: 12.956279
 >> iter 96000, loss: 12.982850
 >> iter 97000, loss: 12.953370
 >> iter 98000, loss: 12.982232
 >> iter 99000, loss: 12.948522
 >> iter 100000, loss: 12.978488
   Number of active neurons: 4
 >> iter 101000, loss: 12.950354
 >> iter 102000, loss: 12.984077
 >> iter 103000, loss: 12.954281
 >> iter 104000, loss: 12.985439
 >> iter 105000, loss: 12.948841
 >> iter 106000, loss: 12.986659
 >> iter 107000, loss: 12.952824
 >> iter 108000, loss: 12.992800
 >> iter 109000, loss: 12.951410
 >> iter 110000, loss: 12.991239
   Number of active neurons: 4
 >> iter 111000, loss: 12.952906
 >> iter 112000, loss: 12.984038
 >> iter 113000, loss: 12.951425
 >> iter 114000, loss: 12.981272
 >> iter 115000, loss: 12.946132
 >> iter 116000, loss: 12.987736
 >> iter 117000, loss: 12.946467
 >> iter 118000, loss: 12.985991
 >> iter 119000, loss: 12.940247
 >> iter 120000, loss: 12.981446
   Number of active neurons: 4
 >> iter 121000, loss: 12.940858
 >> iter 122000, loss: 12.984030
 >> iter 123000, loss: 12.936000
 >> iter 124000, loss: 12.975972
 >> iter 125000, loss: 12.932112
 >> iter 126000, loss: 12.981716
 >> iter 127000, loss: 12.937467
 >> iter 128000, loss: 12.974204
 >> iter 129000, loss: 12.928586
 >> iter 130000, loss: 12.980841
   Number of active neurons: 4
 >> iter 131000, loss: 12.934003
 >> iter 132000, loss: 12.982021
 >> iter 133000, loss: 12.937157
 >> iter 134000, loss: 12.988819
 >> iter 135000, loss: 12.934511
 >> iter 136000, loss: 12.987085
 >> iter 137000, loss: 12.933806
 >> iter 138000, loss: 12.983766
 >> iter 139000, loss: 12.936342
 >> iter 140000, loss: 12.979466
   Number of active neurons: 4
 >> iter 141000, loss: 12.930455
 >> iter 142000, loss: 12.985937
 >> iter 143000, loss: 12.936595
 >> iter 144000, loss: 12.991326
 >> iter 145000, loss: 12.939923
 >> iter 146000, loss: 12.991694
 >> iter 147000, loss: 12.940266
 >> iter 148000, loss: 12.990237
 >> iter 149000, loss: 12.942942
 >> iter 150000, loss: 12.991741
   Number of active neurons: 4
 >> iter 151000, loss: 12.941299
 >> iter 152000, loss: 12.990019
 >> iter 153000, loss: 12.946211
 >> iter 154000, loss: 12.994180
 >> iter 155000, loss: 12.947662
 >> iter 156000, loss: 12.993919
 >> iter 157000, loss: 12.942754
 >> iter 158000, loss: 12.994944
 >> iter 159000, loss: 12.939737
 >> iter 160000, loss: 12.987513
   Number of active neurons: 4
 >> iter 161000, loss: 12.933136
 >> iter 162000, loss: 12.990444
 >> iter 163000, loss: 12.938636
 >> iter 164000, loss: 12.989132
 >> iter 165000, loss: 12.936372
 >> iter 166000, loss: 12.979409
 >> iter 167000, loss: 12.934597
 >> iter 168000, loss: 12.980445
 >> iter 169000, loss: 12.934674
 >> iter 170000, loss: 12.986157
   Number of active neurons: 4
 >> iter 171000, loss: 12.936365
 >> iter 172000, loss: 12.989520
 >> iter 173000, loss: 12.931413
 >> iter 174000, loss: 12.982153
 >> iter 175000, loss: 12.928763
 >> iter 176000, loss: 12.981539
 >> iter 177000, loss: 12.925018
 >> iter 178000, loss: 12.984351
 >> iter 179000, loss: 12.936767
 >> iter 180000, loss: 12.986906
   Number of active neurons: 4
 >> iter 181000, loss: 12.933455
 >> iter 182000, loss: 12.991706
 >> iter 183000, loss: 12.938635
 >> iter 184000, loss: 12.991895
 >> iter 185000, loss: 12.935113
 >> iter 186000, loss: 12.993906
 >> iter 187000, loss: 12.936062
 >> iter 188000, loss: 12.989162
 >> iter 189000, loss: 12.924947
 >> iter 190000, loss: 12.980496
   Number of active neurons: 4
 >> iter 191000, loss: 12.926473
 >> iter 192000, loss: 12.977177
 >> iter 193000, loss: 12.932254
 >> iter 194000, loss: 12.984663
 >> iter 195000, loss: 12.937730
 >> iter 196000, loss: 12.980048
 >> iter 197000, loss: 12.929829
 >> iter 198000, loss: 12.980850
 >> iter 199000, loss: 12.935395
 >> iter 200000, loss: 12.984548
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 27.7254454911
   - Test - Long: 32.7583620819
   - Test - Big: 27.9837201628
   - Test - A: 33.6777548163
   - Test - B: 33.5577628158
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.914496
 >> iter 2000, loss: 15.256217
 >> iter 3000, loss: 13.871701
 >> iter 4000, loss: 13.379172
 >> iter 5000, loss: 13.172428
 >> iter 6000, loss: 13.099868
 >> iter 7000, loss: 13.071838
 >> iter 8000, loss: 13.084999
 >> iter 9000, loss: 13.066045
 >> iter 10000, loss: 13.075802
   Number of active neurons: 3
 >> iter 11000, loss: 13.049180
 >> iter 12000, loss: 13.051842
 >> iter 13000, loss: 13.046379
 >> iter 14000, loss: 13.080351
 >> iter 15000, loss: 13.045700
 >> iter 16000, loss: 13.058002
 >> iter 17000, loss: 13.053021
 >> iter 18000, loss: 13.059313
 >> iter 19000, loss: 13.048824
 >> iter 20000, loss: 13.062067
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 3
 >> iter 21000, loss: 13.082482
 >> iter 22000, loss: 13.033524
 >> iter 23000, loss: 12.984584
 >> iter 24000, loss: 12.978877
 >> iter 25000, loss: 12.958007
 >> iter 26000, loss: 12.972601
 >> iter 27000, loss: 12.952419
 >> iter 28000, loss: 12.975754
 >> iter 29000, loss: 12.962681
 >> iter 30000, loss: 12.974046
   Number of active neurons: 4
 >> iter 31000, loss: 12.953043
 >> iter 32000, loss: 12.968999
 >> iter 33000, loss: 12.956212
 >> iter 34000, loss: 12.964818
 >> iter 35000, loss: 12.953374
 >> iter 36000, loss: 12.974756
 >> iter 37000, loss: 12.957094
 >> iter 38000, loss: 12.974289
 >> iter 39000, loss: 12.948841
 >> iter 40000, loss: 12.957581
   Number of active neurons: 4
 >> iter 41000, loss: 12.946339
 >> iter 42000, loss: 12.964345
 >> iter 43000, loss: 12.950431
 >> iter 44000, loss: 12.971443
 >> iter 45000, loss: 12.948188
 >> iter 46000, loss: 12.979769
 >> iter 47000, loss: 12.948408
 >> iter 48000, loss: 12.974982
 >> iter 49000, loss: 12.952919
 >> iter 50000, loss: 12.975819
   Number of active neurons: 4
 >> iter 51000, loss: 12.945844
 >> iter 52000, loss: 12.974946
 >> iter 53000, loss: 12.945218
 >> iter 54000, loss: 12.969823
 >> iter 55000, loss: 12.942280
 >> iter 56000, loss: 12.977426
 >> iter 57000, loss: 12.934996
 >> iter 58000, loss: 12.976086
 >> iter 59000, loss: 12.937968
 >> iter 60000, loss: 12.969678
   Number of active neurons: 4
 >> iter 61000, loss: 12.942223
 >> iter 62000, loss: 12.983577
 >> iter 63000, loss: 12.951029
 >> iter 64000, loss: 12.984682
 >> iter 65000, loss: 12.950451
 >> iter 66000, loss: 12.979683
 >> iter 67000, loss: 12.948890
 >> iter 68000, loss: 12.980036
 >> iter 69000, loss: 12.953718
 >> iter 70000, loss: 12.981335
   Number of active neurons: 4
 >> iter 71000, loss: 12.949815
 >> iter 72000, loss: 12.977050
 >> iter 73000, loss: 12.944136
 >> iter 74000, loss: 12.974462
 >> iter 75000, loss: 12.946902
 >> iter 76000, loss: 12.972339
 >> iter 77000, loss: 12.946508
 >> iter 78000, loss: 12.986584
 >> iter 79000, loss: 12.948435
 >> iter 80000, loss: 12.972716
   Number of active neurons: 4
 >> iter 81000, loss: 12.944761
 >> iter 82000, loss: 12.979565
 >> iter 83000, loss: 12.948427
 >> iter 84000, loss: 12.977992
 >> iter 85000, loss: 12.953983
 >> iter 86000, loss: 12.987672
 >> iter 87000, loss: 12.955117
 >> iter 88000, loss: 12.990138
 >> iter 89000, loss: 12.956380
 >> iter 90000, loss: 12.983375
   Number of active neurons: 4
 >> iter 91000, loss: 12.953692
 >> iter 92000, loss: 12.987546
 >> iter 93000, loss: 12.955175
 >> iter 94000, loss: 12.987083
 >> iter 95000, loss: 12.951324
 >> iter 96000, loss: 12.982291
 >> iter 97000, loss: 12.956803
 >> iter 98000, loss: 12.991883
 >> iter 99000, loss: 12.958316
 >> iter 100000, loss: 12.979922
   Number of active neurons: 4
 >> iter 101000, loss: 12.954755
 >> iter 102000, loss: 12.976461
 >> iter 103000, loss: 12.956404
 >> iter 104000, loss: 12.989131
 >> iter 105000, loss: 12.955573
 >> iter 106000, loss: 12.992269
 >> iter 107000, loss: 12.955562
 >> iter 108000, loss: 12.985562
 >> iter 109000, loss: 12.947872
 >> iter 110000, loss: 12.983560
   Number of active neurons: 4
 >> iter 111000, loss: 12.948926
 >> iter 112000, loss: 12.981973
 >> iter 113000, loss: 12.948869
 >> iter 114000, loss: 12.977774
 >> iter 115000, loss: 12.943214
 >> iter 116000, loss: 12.974820
 >> iter 117000, loss: 12.939697
 >> iter 118000, loss: 12.982128
 >> iter 119000, loss: 12.939843
 >> iter 120000, loss: 12.973597
   Number of active neurons: 4
 >> iter 121000, loss: 12.936673
 >> iter 122000, loss: 12.974199
 >> iter 123000, loss: 12.930024
 >> iter 124000, loss: 12.977801
 >> iter 125000, loss: 12.934659
 >> iter 126000, loss: 12.981072
 >> iter 127000, loss: 12.933261
 >> iter 128000, loss: 12.979323
 >> iter 129000, loss: 12.934813
 >> iter 130000, loss: 12.981892
   Number of active neurons: 4
 >> iter 131000, loss: 12.938704
 >> iter 132000, loss: 12.984158
 >> iter 133000, loss: 12.940421
 >> iter 134000, loss: 12.987046
 >> iter 135000, loss: 12.935748
 >> iter 136000, loss: 12.981360
 >> iter 137000, loss: 12.931768
 >> iter 138000, loss: 12.979876
 >> iter 139000, loss: 12.930373
 >> iter 140000, loss: 12.983982
   Number of active neurons: 4
 >> iter 141000, loss: 12.935508
 >> iter 142000, loss: 12.985568
 >> iter 143000, loss: 12.941954
 >> iter 144000, loss: 12.988483
 >> iter 145000, loss: 12.939823
 >> iter 146000, loss: 12.986955
 >> iter 147000, loss: 12.943025
 >> iter 148000, loss: 12.999113
 >> iter 149000, loss: 12.941619
 >> iter 150000, loss: 12.986784
   Number of active neurons: 4
 >> iter 151000, loss: 12.939572
 >> iter 152000, loss: 12.984388
 >> iter 153000, loss: 12.946643
 >> iter 154000, loss: 12.990458
 >> iter 155000, loss: 12.946544
 >> iter 156000, loss: 12.993934
 >> iter 157000, loss: 12.941851
 >> iter 158000, loss: 12.996029
 >> iter 159000, loss: 12.936799
 >> iter 160000, loss: 12.999572
   Number of active neurons: 4
 >> iter 161000, loss: 12.941399
 >> iter 162000, loss: 12.994236
 >> iter 163000, loss: 12.935431
 >> iter 164000, loss: 12.985340
 >> iter 165000, loss: 12.933566
 >> iter 166000, loss: 12.981549
 >> iter 167000, loss: 12.929741
 >> iter 168000, loss: 12.977724
 >> iter 169000, loss: 12.930927
 >> iter 170000, loss: 12.978827
   Number of active neurons: 4
 >> iter 171000, loss: 12.934893
 >> iter 172000, loss: 12.986008
 >> iter 173000, loss: 12.935626
 >> iter 174000, loss: 12.987667
 >> iter 175000, loss: 12.939422
 >> iter 176000, loss: 12.988202
 >> iter 177000, loss: 12.931041
 >> iter 178000, loss: 12.975781
 >> iter 179000, loss: 12.939396
 >> iter 180000, loss: 12.981114
   Number of active neurons: 4
 >> iter 181000, loss: 12.935624
 >> iter 182000, loss: 12.989187
 >> iter 183000, loss: 12.930746
 >> iter 184000, loss: 12.990090
 >> iter 185000, loss: 12.938249
 >> iter 186000, loss: 12.991287
 >> iter 187000, loss: 12.929888
 >> iter 188000, loss: 12.990291
 >> iter 189000, loss: 12.930531
 >> iter 190000, loss: 12.989792
   Number of active neurons: 4
 >> iter 191000, loss: 12.932806
 >> iter 192000, loss: 12.989767
 >> iter 193000, loss: 12.934378
 >> iter 194000, loss: 12.984316
 >> iter 195000, loss: 12.932831
 >> iter 196000, loss: 12.981259
 >> iter 197000, loss: 12.933613
 >> iter 198000, loss: 12.979364
 >> iter 199000, loss: 12.927103
 >> iter 200000, loss: 12.976170
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 27.7254454911
   - Test - Long: 32.7583620819
   - Test - Big: 27.9837201628
   - Test - A: 33.6777548163
   - Test - B: 33.5577628158
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.925985
 >> iter 2000, loss: 15.238163
 >> iter 3000, loss: 13.845100
 >> iter 4000, loss: 13.333077
 >> iter 5000, loss: 13.123531
 >> iter 6000, loss: 13.051977
 >> iter 7000, loss: 13.014157
 >> iter 8000, loss: 13.006733
 >> iter 9000, loss: 12.991575
 >> iter 10000, loss: 13.004723
   Number of active neurons: 4
 >> iter 11000, loss: 12.983117
 >> iter 12000, loss: 12.989059
 >> iter 13000, loss: 12.977926
 >> iter 14000, loss: 12.995447
 >> iter 15000, loss: 12.981103
 >> iter 16000, loss: 12.989121
 >> iter 17000, loss: 12.979747
 >> iter 18000, loss: 12.987732
 >> iter 19000, loss: 12.979860
 >> iter 20000, loss: 12.990106
   Number of active neurons: 4
 >> iter 21000, loss: 12.969392
 >> iter 22000, loss: 12.979970
 >> iter 23000, loss: 12.964345
 >> iter 24000, loss: 12.983892
 >> iter 25000, loss: 12.965571
 >> iter 26000, loss: 12.965886
 >> iter 27000, loss: 12.950399
 >> iter 28000, loss: 12.972316
 >> iter 29000, loss: 12.959363
 >> iter 30000, loss: 12.983532
   Number of active neurons: 4
 >> iter 31000, loss: 12.959346
 >> iter 32000, loss: 12.974039
 >> iter 33000, loss: 12.961421
 >> iter 34000, loss: 12.973960
 >> iter 35000, loss: 12.947268
 >> iter 36000, loss: 12.964398
 >> iter 37000, loss: 12.954172
 >> iter 38000, loss: 12.964991
 >> iter 39000, loss: 12.955652
 >> iter 40000, loss: 12.969278
   Number of active neurons: 4
 >> iter 41000, loss: 12.949275
 >> iter 42000, loss: 12.970054
 >> iter 43000, loss: 12.943568
 >> iter 44000, loss: 12.971995
 >> iter 45000, loss: 12.949539
 >> iter 46000, loss: 12.978737
 >> iter 47000, loss: 12.950251
 >> iter 48000, loss: 12.976890
 >> iter 49000, loss: 12.945984
 >> iter 50000, loss: 12.973488
   Number of active neurons: 4
 >> iter 51000, loss: 12.948754
 >> iter 52000, loss: 12.979622
 >> iter 53000, loss: 12.947443
 >> iter 54000, loss: 12.966907
 >> iter 55000, loss: 12.948173
 >> iter 56000, loss: 12.978564
 >> iter 57000, loss: 12.940747
 >> iter 58000, loss: 12.968138
 >> iter 59000, loss: 12.941524
 >> iter 60000, loss: 12.974385
   Number of active neurons: 4
 >> iter 61000, loss: 12.950905
 >> iter 62000, loss: 12.972594
 >> iter 63000, loss: 12.944981
 >> iter 64000, loss: 12.967283
 >> iter 65000, loss: 12.949636
 >> iter 66000, loss: 12.975201
 >> iter 67000, loss: 12.942130
 >> iter 68000, loss: 12.964709
 >> iter 69000, loss: 12.942183
 >> iter 70000, loss: 12.976546
   Number of active neurons: 4
 >> iter 71000, loss: 12.944897
 >> iter 72000, loss: 12.968272
 >> iter 73000, loss: 12.944983
 >> iter 74000, loss: 12.981490
 >> iter 75000, loss: 12.939953
 >> iter 76000, loss: 12.978313
 >> iter 77000, loss: 12.951007
 >> iter 78000, loss: 12.980858
 >> iter 79000, loss: 12.949799
 >> iter 80000, loss: 12.978565
   Number of active neurons: 4
 >> iter 81000, loss: 12.948510
 >> iter 82000, loss: 12.977858
 >> iter 83000, loss: 12.946338
 >> iter 84000, loss: 12.986277
 >> iter 85000, loss: 12.953435
 >> iter 86000, loss: 12.978786
 >> iter 87000, loss: 12.942428
 >> iter 88000, loss: 12.979095
 >> iter 89000, loss: 12.951686
 >> iter 90000, loss: 12.985804
   Number of active neurons: 4
 >> iter 91000, loss: 12.953414
 >> iter 92000, loss: 12.984126
 >> iter 93000, loss: 12.953342
 >> iter 94000, loss: 12.985085
 >> iter 95000, loss: 12.958124
 >> iter 96000, loss: 12.983307
 >> iter 97000, loss: 12.958163
 >> iter 98000, loss: 12.987047
 >> iter 99000, loss: 12.957643
 >> iter 100000, loss: 12.982289
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 27.7494450111
   - Test - Long: 32.7683615819
   - Test - Big: 28.0257197428
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.888627
 >> iter 2000, loss: 15.211753
 >> iter 3000, loss: 13.811005
 >> iter 4000, loss: 13.299140
 >> iter 5000, loss: 13.090985
 >> iter 6000, loss: 13.023827
 >> iter 7000, loss: 12.984722
 >> iter 8000, loss: 12.983658
 >> iter 9000, loss: 12.967368
 >> iter 10000, loss: 12.979897
   Number of active neurons: 3
 >> iter 11000, loss: 12.966493
 >> iter 12000, loss: 12.980579
 >> iter 13000, loss: 12.960112
 >> iter 14000, loss: 12.977222
 >> iter 15000, loss: 12.954361
 >> iter 16000, loss: 12.971360
 >> iter 17000, loss: 12.963784
 >> iter 18000, loss: 12.974979
 >> iter 19000, loss: 12.968907
 >> iter 20000, loss: 12.975419
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 3
 >> iter 21000, loss: 12.972709
 >> iter 22000, loss: 12.967158
 >> iter 23000, loss: 12.906890
 >> iter 24000, loss: 12.804635
 >> iter 25000, loss: 12.337726
 >> iter 26000, loss: 11.971117
 >> iter 27000, loss: 11.753463
 >> iter 28000, loss: 11.520521
 >> iter 29000, loss: 11.222569
 >> iter 30000, loss: 11.030427
   Number of active neurons: 4
 >> iter 31000, loss: 10.924384
 >> iter 32000, loss: 10.845013
 >> iter 33000, loss: 10.772109
 >> iter 34000, loss: 10.755395
 >> iter 35000, loss: 10.704446
 >> iter 36000, loss: 10.698975
 >> iter 37000, loss: 10.674631
 >> iter 38000, loss: 10.681841
 >> iter 39000, loss: 10.654500
 >> iter 40000, loss: 10.661806
   Number of active neurons: 4
 >> iter 41000, loss: 10.638393
 >> iter 42000, loss: 10.670569
 >> iter 43000, loss: 10.631968
 >> iter 44000, loss: 10.660453
 >> iter 45000, loss: 10.657711
 >> iter 46000, loss: 10.703253
 >> iter 47000, loss: 10.672310
 >> iter 48000, loss: 10.667752
 >> iter 49000, loss: 10.602026
 >> iter 50000, loss: 10.635257
   Number of active neurons: 4
 >> iter 51000, loss: 10.592271
 >> iter 52000, loss: 10.654642
 >> iter 53000, loss: 10.602891
 >> iter 54000, loss: 10.652337
 >> iter 55000, loss: 10.634529
 >> iter 56000, loss: 10.631637
 >> iter 57000, loss: 10.600920
 >> iter 58000, loss: 10.637260
 >> iter 59000, loss: 10.599265
 >> iter 60000, loss: 10.644108
   Number of active neurons: 4
 >> iter 61000, loss: 10.617641
 >> iter 62000, loss: 10.660285
 >> iter 63000, loss: 10.626378
 >> iter 64000, loss: 10.653141
 >> iter 65000, loss: 10.594358
 >> iter 66000, loss: 10.635505
 >> iter 67000, loss: 10.610108
 >> iter 68000, loss: 10.661415
 >> iter 69000, loss: 10.613754
 >> iter 70000, loss: 10.635294
   Number of active neurons: 4
 >> iter 71000, loss: 10.603294
 >> iter 72000, loss: 10.639658
 >> iter 73000, loss: 10.618392
 >> iter 74000, loss: 10.650480
 >> iter 75000, loss: 10.611348
 >> iter 76000, loss: 10.678436
 >> iter 77000, loss: 10.620378
 >> iter 78000, loss: 10.663280
 >> iter 79000, loss: 10.615538
 >> iter 80000, loss: 10.636476
   Number of active neurons: 4
 >> iter 81000, loss: 10.650654
 >> iter 82000, loss: 10.665179
 >> iter 83000, loss: 10.603939
 >> iter 84000, loss: 10.660016
 >> iter 85000, loss: 10.603484
 >> iter 86000, loss: 10.649215
 >> iter 87000, loss: 10.629873
 >> iter 88000, loss: 10.647495
 >> iter 89000, loss: 10.619600
 >> iter 90000, loss: 10.664467
   Number of active neurons: 4
 >> iter 91000, loss: 10.652602
 >> iter 92000, loss: 10.628974
 >> iter 93000, loss: 10.610530
 >> iter 94000, loss: 10.656148
 >> iter 95000, loss: 10.608615
 >> iter 96000, loss: 10.662038
 >> iter 97000, loss: 10.601726
 >> iter 98000, loss: 10.665785
 >> iter 99000, loss: 10.616887
 >> iter 100000, loss: 10.639341
   Number of active neurons: 4
 >> iter 101000, loss: 10.600677
 >> iter 102000, loss: 10.667127
 >> iter 103000, loss: 10.608739
 >> iter 104000, loss: 10.649202
 >> iter 105000, loss: 10.616268
 >> iter 106000, loss: 10.633877
 >> iter 107000, loss: 10.614173
 >> iter 108000, loss: 10.641703
 >> iter 109000, loss: 10.602904
 >> iter 110000, loss: 10.616164
   Number of active neurons: 4
 >> iter 111000, loss: 10.619862
 >> iter 112000, loss: 10.651888
 >> iter 113000, loss: 10.607767
 >> iter 114000, loss: 10.642008
 >> iter 115000, loss: 10.610389
 >> iter 116000, loss: 10.645673
 >> iter 117000, loss: 10.610916
 >> iter 118000, loss: 10.649886
 >> iter 119000, loss: 10.618601
 >> iter 120000, loss: 10.657765
   Number of active neurons: 4
 >> iter 121000, loss: 10.579593
 >> iter 122000, loss: 10.611689
 >> iter 123000, loss: 10.569531
 >> iter 124000, loss: 10.645259
 >> iter 125000, loss: 10.584459
 >> iter 126000, loss: 10.651593
 >> iter 127000, loss: 10.573377
 >> iter 128000, loss: 10.643473
 >> iter 129000, loss: 10.593715
 >> iter 130000, loss: 10.629761
   Number of active neurons: 4
 >> iter 131000, loss: 10.615233
 >> iter 132000, loss: 10.605344
 >> iter 133000, loss: 10.567824
 >> iter 134000, loss: 10.644671
 >> iter 135000, loss: 10.574475
 >> iter 136000, loss: 10.615965
 >> iter 137000, loss: 10.576492
 >> iter 138000, loss: 10.627746
 >> iter 139000, loss: 10.582221
 >> iter 140000, loss: 10.622341
   Number of active neurons: 4
 >> iter 141000, loss: 10.572660
 >> iter 142000, loss: 10.623989
 >> iter 143000, loss: 10.608330
 >> iter 144000, loss: 10.693743
 >> iter 145000, loss: 10.613848
 >> iter 146000, loss: 10.651570
 >> iter 147000, loss: 10.588866
 >> iter 148000, loss: 10.659825
 >> iter 149000, loss: 10.594745
 >> iter 150000, loss: 10.652443
   Number of active neurons: 4
 >> iter 151000, loss: 10.586594
 >> iter 152000, loss: 10.611411
 >> iter 153000, loss: 10.599512
 >> iter 154000, loss: 10.625307
 >> iter 155000, loss: 10.587088
 >> iter 156000, loss: 10.606067
 >> iter 157000, loss: 10.591940
 >> iter 158000, loss: 10.613655
 >> iter 159000, loss: 10.582604
 >> iter 160000, loss: 10.631910
   Number of active neurons: 4
 >> iter 161000, loss: 10.598305
 >> iter 162000, loss: 10.625266
 >> iter 163000, loss: 10.597145
 >> iter 164000, loss: 10.612916
 >> iter 165000, loss: 10.551866
 >> iter 166000, loss: 10.618141
 >> iter 167000, loss: 10.594523
 >> iter 168000, loss: 10.608810
 >> iter 169000, loss: 10.559883
 >> iter 170000, loss: 10.598007
   Number of active neurons: 4
 >> iter 171000, loss: 10.567640
 >> iter 172000, loss: 10.618757
 >> iter 173000, loss: 10.570427
 >> iter 174000, loss: 10.628150
 >> iter 175000, loss: 10.603088
 >> iter 176000, loss: 10.647214
 >> iter 177000, loss: 10.579630
 >> iter 178000, loss: 10.622257
 >> iter 179000, loss: 10.564729
 >> iter 180000, loss: 10.642736
   Number of active neurons: 4
 >> iter 181000, loss: 10.583024
 >> iter 182000, loss: 10.650263
 >> iter 183000, loss: 10.600367
 >> iter 184000, loss: 10.665770
 >> iter 185000, loss: 10.601772
 >> iter 186000, loss: 10.635381
 >> iter 187000, loss: 10.570399
 >> iter 188000, loss: 10.620822
 >> iter 189000, loss: 10.554218
 >> iter 190000, loss: 10.645775
   Number of active neurons: 4
 >> iter 191000, loss: 10.553086
 >> iter 192000, loss: 10.603809
 >> iter 193000, loss: 10.557111
 >> iter 194000, loss: 10.649635
 >> iter 195000, loss: 10.569146
 >> iter 196000, loss: 10.664461
 >> iter 197000, loss: 10.573930
 >> iter 198000, loss: 10.663709
 >> iter 199000, loss: 10.586669
 >> iter 200000, loss: 10.642044
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 21.6075678486
   - Test - Long: 31.8934053297
   - Test - Big: 21.7037829622
   - Test - A: 32.5511632558
   - Test - B: 31.6378908073
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.965031
 >> iter 2000, loss: 15.269031
 >> iter 3000, loss: 13.841064
 >> iter 4000, loss: 13.328813
 >> iter 5000, loss: 13.125691
 >> iter 6000, loss: 13.054632
 >> iter 7000, loss: 13.002883
 >> iter 8000, loss: 13.004187
 >> iter 9000, loss: 12.982788
 >> iter 10000, loss: 12.990351
   Number of active neurons: 4
 >> iter 11000, loss: 12.979959
 >> iter 12000, loss: 12.989722
 >> iter 13000, loss: 12.977132
 >> iter 14000, loss: 12.989342
 >> iter 15000, loss: 12.974983
 >> iter 16000, loss: 12.977582
 >> iter 17000, loss: 12.957562
 >> iter 18000, loss: 12.962050
 >> iter 19000, loss: 12.950882
 >> iter 20000, loss: 12.965033
   Number of active neurons: 4
 >> iter 21000, loss: 12.948810
 >> iter 22000, loss: 12.964068
 >> iter 23000, loss: 12.947228
 >> iter 24000, loss: 12.968045
 >> iter 25000, loss: 12.949861
 >> iter 26000, loss: 12.961958
 >> iter 27000, loss: 12.948527
 >> iter 28000, loss: 12.958329
 >> iter 29000, loss: 12.953801
 >> iter 30000, loss: 12.961569
   Number of active neurons: 4
 >> iter 31000, loss: 12.950854
 >> iter 32000, loss: 12.966365
 >> iter 33000, loss: 12.950709
 >> iter 34000, loss: 12.963474
 >> iter 35000, loss: 12.944894
 >> iter 36000, loss: 12.958753
 >> iter 37000, loss: 12.951297
 >> iter 38000, loss: 12.964916
 >> iter 39000, loss: 12.948427
 >> iter 40000, loss: 12.972840
   Number of active neurons: 4
 >> iter 41000, loss: 12.947341
 >> iter 42000, loss: 12.965567
 >> iter 43000, loss: 12.945046
 >> iter 44000, loss: 12.976769
 >> iter 45000, loss: 12.952917
 >> iter 46000, loss: 12.973451
 >> iter 47000, loss: 12.949209
 >> iter 48000, loss: 12.976077
 >> iter 49000, loss: 12.946816
 >> iter 50000, loss: 12.972313
   Number of active neurons: 4
 >> iter 51000, loss: 12.947539
 >> iter 52000, loss: 12.970427
 >> iter 53000, loss: 12.944998
 >> iter 54000, loss: 12.974887
 >> iter 55000, loss: 12.936808
 >> iter 56000, loss: 12.972287
 >> iter 57000, loss: 12.948170
 >> iter 58000, loss: 12.960325
 >> iter 59000, loss: 12.945446
 >> iter 60000, loss: 12.975487
   Number of active neurons: 4
 >> iter 61000, loss: 12.951656
 >> iter 62000, loss: 12.974711
 >> iter 63000, loss: 12.943180
 >> iter 64000, loss: 12.972042
 >> iter 65000, loss: 12.948460
 >> iter 66000, loss: 12.978382
 >> iter 67000, loss: 12.950162
 >> iter 68000, loss: 12.979990
 >> iter 69000, loss: 12.948743
 >> iter 70000, loss: 12.980403
   Number of active neurons: 4
 >> iter 71000, loss: 12.948284
 >> iter 72000, loss: 12.978962
 >> iter 73000, loss: 12.951828
 >> iter 74000, loss: 12.980503
 >> iter 75000, loss: 12.946518
 >> iter 76000, loss: 12.972245
 >> iter 77000, loss: 12.944431
 >> iter 78000, loss: 12.965008
 >> iter 79000, loss: 12.943798
 >> iter 80000, loss: 12.971707
   Number of active neurons: 4
 >> iter 81000, loss: 12.939271
 >> iter 82000, loss: 12.973573
 >> iter 83000, loss: 12.951804
 >> iter 84000, loss: 12.977705
 >> iter 85000, loss: 12.946844
 >> iter 86000, loss: 12.981267
 >> iter 87000, loss: 12.947957
 >> iter 88000, loss: 12.980390
 >> iter 89000, loss: 12.952556
 >> iter 90000, loss: 12.987950
   Number of active neurons: 4
 >> iter 91000, loss: 12.953496
 >> iter 92000, loss: 12.982672
 >> iter 93000, loss: 12.952380
 >> iter 94000, loss: 12.984990
 >> iter 95000, loss: 12.957575
 >> iter 96000, loss: 12.984355
 >> iter 97000, loss: 12.952694
 >> iter 98000, loss: 12.986285
 >> iter 99000, loss: 12.954326
 >> iter 100000, loss: 12.979530
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 27.7254454911
   - Test - Long: 32.7583620819
   - Test - Big: 27.9837201628
   - Test - A: 33.6777548163
   - Test - B: 33.5577628158
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.960181
 >> iter 2000, loss: 15.290010
 >> iter 3000, loss: 13.862628
 >> iter 4000, loss: 13.344472
 >> iter 5000, loss: 13.122307
 >> iter 6000, loss: 13.039177
 >> iter 7000, loss: 13.006849
 >> iter 8000, loss: 13.002304
 >> iter 9000, loss: 12.986771
 >> iter 10000, loss: 12.990508
   Number of active neurons: 4
 >> iter 11000, loss: 12.984293
 >> iter 12000, loss: 12.987156
 >> iter 13000, loss: 12.968704
 >> iter 14000, loss: 12.972191
 >> iter 15000, loss: 12.960625
 >> iter 16000, loss: 12.983944
 >> iter 17000, loss: 12.977137
 >> iter 18000, loss: 12.984594
 >> iter 19000, loss: 12.958088
 >> iter 20000, loss: 12.970260
   Number of active neurons: 4
 >> iter 21000, loss: 12.959220
 >> iter 22000, loss: 12.968870
 >> iter 23000, loss: 12.952787
 >> iter 24000, loss: 12.960587
 >> iter 25000, loss: 12.956103
 >> iter 26000, loss: 12.965605
 >> iter 27000, loss: 12.956319
 >> iter 28000, loss: 12.964256
 >> iter 29000, loss: 12.954741
 >> iter 30000, loss: 12.973730
   Number of active neurons: 4
 >> iter 31000, loss: 12.953437
 >> iter 32000, loss: 12.973989
 >> iter 33000, loss: 12.952674
 >> iter 34000, loss: 12.967753
 >> iter 35000, loss: 12.954211
 >> iter 36000, loss: 12.959262
 >> iter 37000, loss: 12.952935
 >> iter 38000, loss: 12.967915
 >> iter 39000, loss: 12.953901
 >> iter 40000, loss: 12.972260
   Number of active neurons: 4
 >> iter 41000, loss: 12.950977
 >> iter 42000, loss: 12.968787
 >> iter 43000, loss: 12.950916
 >> iter 44000, loss: 12.973579
 >> iter 45000, loss: 12.937845
 >> iter 46000, loss: 12.974251
 >> iter 47000, loss: 12.950919
 >> iter 48000, loss: 12.974828
 >> iter 49000, loss: 12.953593
 >> iter 50000, loss: 12.982319
   Number of active neurons: 4
 >> iter 51000, loss: 12.956726
 >> iter 52000, loss: 12.981547
 >> iter 53000, loss: 12.949090
 >> iter 54000, loss: 12.973424
 >> iter 55000, loss: 12.944284
 >> iter 56000, loss: 12.972340
 >> iter 57000, loss: 12.943470
 >> iter 58000, loss: 12.974373
 >> iter 59000, loss: 12.942316
 >> iter 60000, loss: 12.972510
   Number of active neurons: 4
 >> iter 61000, loss: 12.946147
 >> iter 62000, loss: 12.977657
 >> iter 63000, loss: 12.951029
 >> iter 64000, loss: 12.978667
 >> iter 65000, loss: 12.948779
 >> iter 66000, loss: 12.976068
 >> iter 67000, loss: 12.947852
 >> iter 68000, loss: 12.977159
 >> iter 69000, loss: 12.953652
 >> iter 70000, loss: 12.979639
   Number of active neurons: 4
 >> iter 71000, loss: 12.949503
 >> iter 72000, loss: 12.973474
 >> iter 73000, loss: 12.939040
 >> iter 74000, loss: 12.971602
 >> iter 75000, loss: 12.941380
 >> iter 76000, loss: 12.971262
 >> iter 77000, loss: 12.949029
 >> iter 78000, loss: 12.977831
 >> iter 79000, loss: 12.947619
 >> iter 80000, loss: 12.978882
   Number of active neurons: 4
 >> iter 81000, loss: 12.942768
 >> iter 82000, loss: 12.971672
 >> iter 83000, loss: 12.951701
 >> iter 84000, loss: 12.978836
 >> iter 85000, loss: 12.951073
 >> iter 86000, loss: 12.979612
 >> iter 87000, loss: 12.953260
 >> iter 88000, loss: 12.988353
 >> iter 89000, loss: 12.951394
 >> iter 90000, loss: 12.982551
   Number of active neurons: 4
 >> iter 91000, loss: 12.957266
 >> iter 92000, loss: 12.987692
 >> iter 93000, loss: 12.955729
 >> iter 94000, loss: 12.988909
 >> iter 95000, loss: 12.954602
 >> iter 96000, loss: 12.987939
 >> iter 97000, loss: 12.950540
 >> iter 98000, loss: 12.986603
 >> iter 99000, loss: 12.954747
 >> iter 100000, loss: 12.985630
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 27.7254454911
   - Test - Long: 32.7583620819
   - Test - Big: 27.9837201628
   - Test - A: 33.6777548163
   - Test - B: 33.5577628158
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.881141
 >> iter 2000, loss: 15.220175
 >> iter 3000, loss: 13.833865
 >> iter 4000, loss: 13.339106
 >> iter 5000, loss: 13.118882
 >> iter 6000, loss: 13.042680
 >> iter 7000, loss: 12.991481
 >> iter 8000, loss: 12.986348
 >> iter 9000, loss: 12.980203
 >> iter 10000, loss: 12.984980
   Number of active neurons: 3
 >> iter 11000, loss: 12.971046
 >> iter 12000, loss: 12.977481
 >> iter 13000, loss: 12.959669
 >> iter 14000, loss: 12.977354
 >> iter 15000, loss: 12.963983
 >> iter 16000, loss: 12.978893
 >> iter 17000, loss: 12.965487
 >> iter 18000, loss: 12.968542
 >> iter 19000, loss: 12.954393
 >> iter 20000, loss: 12.976234
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 3
 >> iter 21000, loss: 12.969180
 >> iter 22000, loss: 12.969855
 >> iter 23000, loss: 12.932216
 >> iter 24000, loss: 12.814788
 >> iter 25000, loss: 12.603952
 >> iter 26000, loss: 12.301420
 >> iter 27000, loss: 11.780862
 >> iter 28000, loss: 11.446982
 >> iter 29000, loss: 11.128085
 >> iter 30000, loss: 11.026529
   Number of active neurons: 4
 >> iter 31000, loss: 10.942647
 >> iter 32000, loss: 10.861987
 >> iter 33000, loss: 10.797163
 >> iter 34000, loss: 10.791155
 >> iter 35000, loss: 10.697584
 >> iter 36000, loss: 10.659117
 >> iter 37000, loss: 10.606790
 >> iter 38000, loss: 10.580613
 >> iter 39000, loss: 10.371443
 >> iter 40000, loss: 10.426693
   Number of active neurons: 4
 >> iter 41000, loss: 10.272639
 >> iter 42000, loss: 10.202506
 >> iter 43000, loss: 10.054763
 >> iter 44000, loss: 10.176246
 >> iter 45000, loss: 10.040365
 >> iter 46000, loss: 10.117816
 >> iter 47000, loss: 9.984793
 >> iter 48000, loss: 9.989605
 >> iter 49000, loss: 9.969199
 >> iter 50000, loss: 10.149104
   Number of active neurons: 4
 >> iter 51000, loss: 10.052877
 >> iter 52000, loss: 10.031399
 >> iter 53000, loss: 9.437231
 >> iter 54000, loss: 8.870898
 >> iter 55000, loss: 8.564364
 >> iter 56000, loss: 8.360273
 >> iter 57000, loss: 8.148123
 >> iter 58000, loss: 7.946479
 >> iter 59000, loss: 7.698230
 >> iter 60000, loss: 7.641502
   Number of active neurons: 4
 >> iter 61000, loss: 7.808734
 >> iter 62000, loss: 7.766036
 >> iter 63000, loss: 7.641525
 >> iter 64000, loss: 7.678413
 >> iter 65000, loss: 7.513546
 >> iter 66000, loss: 7.463482
 >> iter 67000, loss: 7.632637
 >> iter 68000, loss: 7.362626
 >> iter 69000, loss: 7.271334
 >> iter 70000, loss: 7.201496
   Number of active neurons: 4
 >> iter 71000, loss: 7.068635
 >> iter 72000, loss: 7.117968
 >> iter 73000, loss: 7.362574
 >> iter 74000, loss: 7.467605
 >> iter 75000, loss: 7.196147
 >> iter 76000, loss: 7.217900
 >> iter 77000, loss: 7.053010
 >> iter 78000, loss: 7.135154
 >> iter 79000, loss: 7.074405
 >> iter 80000, loss: 7.325337
   Number of active neurons: 4
 >> iter 81000, loss: 7.154089
 >> iter 82000, loss: 7.236020
 >> iter 83000, loss: 7.239607
 >> iter 84000, loss: 7.008867
 >> iter 85000, loss: 6.981454
 >> iter 86000, loss: 7.159393
 >> iter 87000, loss: 6.873052
 >> iter 88000, loss: 6.996985
 >> iter 89000, loss: 7.090720
 >> iter 90000, loss: 7.110808
   Number of active neurons: 4
 >> iter 91000, loss: 7.070061
 >> iter 92000, loss: 6.990785
 >> iter 93000, loss: 6.964444
 >> iter 94000, loss: 7.130217
 >> iter 95000, loss: 7.158613
 >> iter 96000, loss: 7.014724
 >> iter 97000, loss: 7.003845
 >> iter 98000, loss: 7.034667
 >> iter 99000, loss: 6.856758
 >> iter 100000, loss: 7.105899
   Number of active neurons: 4
 >> iter 101000, loss: 7.161718
 >> iter 102000, loss: 7.052336
 >> iter 103000, loss: 7.383215
 >> iter 104000, loss: 7.159507
 >> iter 105000, loss: 6.845403
 >> iter 106000, loss: 6.906817
 >> iter 107000, loss: 6.881980
 >> iter 108000, loss: 6.969958
 >> iter 109000, loss: 6.936755
 >> iter 110000, loss: 7.001043
   Number of active neurons: 4
 >> iter 111000, loss: 6.923522
 >> iter 112000, loss: 7.067466
 >> iter 113000, loss: 7.061537
 >> iter 114000, loss: 7.139838
 >> iter 115000, loss: 6.928093
 >> iter 116000, loss: 7.077100
 >> iter 117000, loss: 6.878988
 >> iter 118000, loss: 6.930379
 >> iter 119000, loss: 6.885066
 >> iter 120000, loss: 7.199295
   Number of active neurons: 4
 >> iter 121000, loss: 6.859108
 >> iter 122000, loss: 6.986933
 >> iter 123000, loss: 6.968293
 >> iter 124000, loss: 7.117248
 >> iter 125000, loss: 6.914907
 >> iter 126000, loss: 6.915867
 >> iter 127000, loss: 6.819908
 >> iter 128000, loss: 6.917921
 >> iter 129000, loss: 6.830016
 >> iter 130000, loss: 6.936502
   Number of active neurons: 4
 >> iter 131000, loss: 6.999449
 >> iter 132000, loss: 6.929622
 >> iter 133000, loss: 6.913055
 >> iter 134000, loss: 6.888965
 >> iter 135000, loss: 6.803055
 >> iter 136000, loss: 6.823465
 >> iter 137000, loss: 6.836759
 >> iter 138000, loss: 6.982262
 >> iter 139000, loss: 6.818768
 >> iter 140000, loss: 6.902244
   Number of active neurons: 4
 >> iter 141000, loss: 6.797337
 >> iter 142000, loss: 6.965208
 >> iter 143000, loss: 6.977417
 >> iter 144000, loss: 6.895806
 >> iter 145000, loss: 6.813391
 >> iter 146000, loss: 6.970237
 >> iter 147000, loss: 6.922265
 >> iter 148000, loss: 7.154674
 >> iter 149000, loss: 6.961964
 >> iter 150000, loss: 6.943621
   Number of active neurons: 4
 >> iter 151000, loss: 7.035596
 >> iter 152000, loss: 7.002896
 >> iter 153000, loss: 6.946488
 >> iter 154000, loss: 7.081931
 >> iter 155000, loss: 6.951399
 >> iter 156000, loss: 6.880017
 >> iter 157000, loss: 6.715641
 >> iter 158000, loss: 7.021458
 >> iter 159000, loss: 6.908652
 >> iter 160000, loss: 6.868374
   Number of active neurons: 4
 >> iter 161000, loss: 6.927525
 >> iter 162000, loss: 6.978760
 >> iter 163000, loss: 6.814906
 >> iter 164000, loss: 6.949387
 >> iter 165000, loss: 6.976769
 >> iter 166000, loss: 6.838546
 >> iter 167000, loss: 6.701575
 >> iter 168000, loss: 6.834916
 >> iter 169000, loss: 6.979064
 >> iter 170000, loss: 6.946919
   Number of active neurons: 4
 >> iter 171000, loss: 7.096279
 >> iter 172000, loss: 7.126890
 >> iter 173000, loss: 6.880765
 >> iter 174000, loss: 6.914977
 >> iter 175000, loss: 6.812565
 >> iter 176000, loss: 7.015583
 >> iter 177000, loss: 6.995270
 >> iter 178000, loss: 7.009863
 >> iter 179000, loss: 6.887706
 >> iter 180000, loss: 6.947695
   Number of active neurons: 4
 >> iter 181000, loss: 6.797184
 >> iter 182000, loss: 6.875583
 >> iter 183000, loss: 6.871874
 >> iter 184000, loss: 6.971182
 >> iter 185000, loss: 6.863576
 >> iter 186000, loss: 6.965931
 >> iter 187000, loss: 6.877659
 >> iter 188000, loss: 6.933067
 >> iter 189000, loss: 6.832841
 >> iter 190000, loss: 6.887445
   Number of active neurons: 4
 >> iter 191000, loss: 6.685554
 >> iter 192000, loss: 6.962883
 >> iter 193000, loss: 6.912708
 >> iter 194000, loss: 6.917774
 >> iter 195000, loss: 6.917962
 >> iter 196000, loss: 7.059138
 >> iter 197000, loss: 6.846098
 >> iter 198000, loss: 7.016239
 >> iter 199000, loss: 6.873133
 >> iter 200000, loss: 6.914340
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 13.6877262455
   - Test - Long: 29.993500325
   - Test - Big: 13.6638633614
   - Test - A: 8.80607959469
   - Test - B: 7.5594960336
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.887305
 >> iter 2000, loss: 15.207116
 >> iter 3000, loss: 13.815341
 >> iter 4000, loss: 13.302489
 >> iter 5000, loss: 13.102150
 >> iter 6000, loss: 13.022294
 >> iter 7000, loss: 12.978812
 >> iter 8000, loss: 12.976971
 >> iter 9000, loss: 12.967412
 >> iter 10000, loss: 12.980103
   Number of active neurons: 3
 >> iter 11000, loss: 12.964909
 >> iter 12000, loss: 12.973952
 >> iter 13000, loss: 12.963767
 >> iter 14000, loss: 12.977386
 >> iter 15000, loss: 12.961914
 >> iter 16000, loss: 12.974918
 >> iter 17000, loss: 12.962476
 >> iter 18000, loss: 12.974346
 >> iter 19000, loss: 12.955440
 >> iter 20000, loss: 12.982247
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 3
 >> iter 21000, loss: 12.990346
 >> iter 22000, loss: 12.991826
 >> iter 23000, loss: 12.972807
 >> iter 24000, loss: 12.978691
 >> iter 25000, loss: 12.964501
 >> iter 26000, loss: 12.970765
 >> iter 27000, loss: 12.955652
 >> iter 28000, loss: 12.971781
 >> iter 29000, loss: 12.951620
 >> iter 30000, loss: 12.974989
   Number of active neurons: 3
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 3
 >> iter 31000, loss: 12.966301
 >> iter 32000, loss: 12.975904
 >> iter 33000, loss: 12.950977
 >> iter 34000, loss: 12.958914
 >> iter 35000, loss: 12.946154
 >> iter 36000, loss: 12.955372
 >> iter 37000, loss: 12.944229
 >> iter 38000, loss: 12.965216
 >> iter 39000, loss: 12.944195
 >> iter 40000, loss: 12.954685
   Number of active neurons: 4
 >> iter 41000, loss: 12.946738
 >> iter 42000, loss: 12.967481
 >> iter 43000, loss: 12.948711
 >> iter 44000, loss: 12.971817
 >> iter 45000, loss: 12.949606
 >> iter 46000, loss: 12.973171
 >> iter 47000, loss: 12.947533
 >> iter 48000, loss: 12.977618
 >> iter 49000, loss: 12.953265
 >> iter 50000, loss: 12.976565
   Number of active neurons: 4
 >> iter 51000, loss: 12.950987
 >> iter 52000, loss: 12.975178
 >> iter 53000, loss: 12.940914
 >> iter 54000, loss: 12.972626
 >> iter 55000, loss: 12.947390
 >> iter 56000, loss: 12.976347
 >> iter 57000, loss: 12.950875
 >> iter 58000, loss: 12.974532
 >> iter 59000, loss: 12.947649
 >> iter 60000, loss: 12.965647
   Number of active neurons: 4
 >> iter 61000, loss: 12.946629
 >> iter 62000, loss: 12.977797
 >> iter 63000, loss: 12.952239
 >> iter 64000, loss: 12.980882
 >> iter 65000, loss: 12.947900
 >> iter 66000, loss: 12.978636
 >> iter 67000, loss: 12.949704
 >> iter 68000, loss: 12.978755
 >> iter 69000, loss: 12.952459
 >> iter 70000, loss: 12.983841
   Number of active neurons: 4
 >> iter 71000, loss: 12.952772
 >> iter 72000, loss: 12.978799
 >> iter 73000, loss: 12.951603
 >> iter 74000, loss: 12.978488
 >> iter 75000, loss: 12.946046
 >> iter 76000, loss: 12.971903
 >> iter 77000, loss: 12.957107
 >> iter 78000, loss: 12.982756
 >> iter 79000, loss: 12.947797
 >> iter 80000, loss: 12.981196
   Number of active neurons: 4
 >> iter 81000, loss: 12.952004
 >> iter 82000, loss: 12.979813
 >> iter 83000, loss: 12.951383
 >> iter 84000, loss: 12.984822
 >> iter 85000, loss: 12.953091
 >> iter 86000, loss: 12.985020
 >> iter 87000, loss: 12.948491
 >> iter 88000, loss: 12.991097
 >> iter 89000, loss: 12.952995
 >> iter 90000, loss: 12.989209
   Number of active neurons: 4
 >> iter 91000, loss: 12.956963
 >> iter 92000, loss: 12.989600
 >> iter 93000, loss: 12.952631
 >> iter 94000, loss: 12.983499
 >> iter 95000, loss: 12.954226
 >> iter 96000, loss: 12.986388
 >> iter 97000, loss: 12.957305
 >> iter 98000, loss: 12.990907
 >> iter 99000, loss: 12.958918
 >> iter 100000, loss: 12.981284
   Number of active neurons: 4
 >> iter 101000, loss: 12.949498
 >> iter 102000, loss: 12.986952
 >> iter 103000, loss: 12.952172
 >> iter 104000, loss: 12.985838
 >> iter 105000, loss: 12.951077
 >> iter 106000, loss: 12.977978
 >> iter 107000, loss: 12.949560
 >> iter 108000, loss: 12.987680
 >> iter 109000, loss: 12.948095
 >> iter 110000, loss: 12.986801
   Number of active neurons: 4
 >> iter 111000, loss: 12.952439
 >> iter 112000, loss: 12.984482
 >> iter 113000, loss: 12.950005
 >> iter 114000, loss: 12.975582
 >> iter 115000, loss: 12.941082
 >> iter 116000, loss: 12.986111
 >> iter 117000, loss: 12.943979
 >> iter 118000, loss: 12.977084
 >> iter 119000, loss: 12.934905
 >> iter 120000, loss: 12.982240
   Number of active neurons: 4
 >> iter 121000, loss: 12.937323
 >> iter 122000, loss: 12.983550
 >> iter 123000, loss: 12.937734
 >> iter 124000, loss: 12.975692
 >> iter 125000, loss: 12.933631
 >> iter 126000, loss: 12.984748
 >> iter 127000, loss: 12.937032
 >> iter 128000, loss: 12.982081
 >> iter 129000, loss: 12.936739
 >> iter 130000, loss: 12.979249
   Number of active neurons: 4
 >> iter 131000, loss: 12.934583
 >> iter 132000, loss: 12.968255
 >> iter 133000, loss: 12.924630
 >> iter 134000, loss: 12.978472
 >> iter 135000, loss: 12.927674
 >> iter 136000, loss: 12.981980
 >> iter 137000, loss: 12.931931
 >> iter 138000, loss: 12.981477
 >> iter 139000, loss: 12.933970
 >> iter 140000, loss: 12.987936
   Number of active neurons: 4
 >> iter 141000, loss: 12.940445
 >> iter 142000, loss: 12.988056
 >> iter 143000, loss: 12.938016
 >> iter 144000, loss: 12.989267
 >> iter 145000, loss: 12.939852
 >> iter 146000, loss: 12.990000
 >> iter 147000, loss: 12.934186
 >> iter 148000, loss: 12.994009
 >> iter 149000, loss: 12.933840
 >> iter 150000, loss: 12.988925
   Number of active neurons: 4
 >> iter 151000, loss: 12.938282
 >> iter 152000, loss: 12.990288
 >> iter 153000, loss: 12.941524
 >> iter 154000, loss: 12.982215
 >> iter 155000, loss: 12.942975
 >> iter 156000, loss: 12.987439
 >> iter 157000, loss: 12.939412
 >> iter 158000, loss: 12.991583
 >> iter 159000, loss: 12.937835
 >> iter 160000, loss: 12.991513
   Number of active neurons: 4
 >> iter 161000, loss: 12.935050
 >> iter 162000, loss: 12.992402
 >> iter 163000, loss: 12.937558
 >> iter 164000, loss: 12.982729
 >> iter 165000, loss: 12.933921
 >> iter 166000, loss: 12.986292
 >> iter 167000, loss: 12.931753
 >> iter 168000, loss: 12.980435
 >> iter 169000, loss: 12.931287
 >> iter 170000, loss: 12.981452
   Number of active neurons: 4
 >> iter 171000, loss: 12.929912
 >> iter 172000, loss: 12.974013
 >> iter 173000, loss: 12.927901
 >> iter 174000, loss: 12.984435
 >> iter 175000, loss: 12.933505
 >> iter 176000, loss: 12.982515
 >> iter 177000, loss: 12.930925
 >> iter 178000, loss: 12.978943
 >> iter 179000, loss: 12.933177
 >> iter 180000, loss: 12.986674
   Number of active neurons: 4
 >> iter 181000, loss: 12.936440
 >> iter 182000, loss: 12.988160
 >> iter 183000, loss: 12.936352
 >> iter 184000, loss: 12.992950
 >> iter 185000, loss: 12.933912
 >> iter 186000, loss: 12.994022
 >> iter 187000, loss: 12.933978
 >> iter 188000, loss: 12.992273
 >> iter 189000, loss: 12.925394
 >> iter 190000, loss: 12.981820
   Number of active neurons: 4
 >> iter 191000, loss: 12.926622
 >> iter 192000, loss: 12.986927
 >> iter 193000, loss: 12.930541
 >> iter 194000, loss: 12.979390
 >> iter 195000, loss: 12.939324
 >> iter 196000, loss: 12.982317
 >> iter 197000, loss: 12.936033
 >> iter 198000, loss: 12.972717
 >> iter 199000, loss: 12.926349
 >> iter 200000, loss: 12.978000
   Number of active neurons: 4
 >> iter 201000, loss: 12.928583
 >> iter 202000, loss: 12.981974
 >> iter 203000, loss: 12.929403
 >> iter 204000, loss: 12.978143
 >> iter 205000, loss: 12.927046
 >> iter 206000, loss: 12.982801
 >> iter 207000, loss: 12.931236
 >> iter 208000, loss: 12.986281
 >> iter 209000, loss: 12.932891
 >> iter 210000, loss: 12.975753
   Number of active neurons: 4
 >> iter 211000, loss: 12.930489
 >> iter 212000, loss: 12.977901
 >> iter 213000, loss: 12.935440
 >> iter 214000, loss: 12.987563
 >> iter 215000, loss: 12.938411
 >> iter 216000, loss: 12.972250
 >> iter 217000, loss: 12.930728
 >> iter 218000, loss: 12.977300
 >> iter 219000, loss: 12.933345
 >> iter 220000, loss: 12.971016
   Number of active neurons: 4
 >> iter 221000, loss: 12.937203
 >> iter 222000, loss: 12.978657
 >> iter 223000, loss: 12.928746
 >> iter 224000, loss: 12.969507
 >> iter 225000, loss: 12.932413
 >> iter 226000, loss: 12.972210
 >> iter 227000, loss: 12.932103
 >> iter 228000, loss: 12.979397
 >> iter 229000, loss: 12.934497
 >> iter 230000, loss: 12.969142
   Number of active neurons: 4
 >> iter 231000, loss: 12.934122
 >> iter 232000, loss: 12.974426
 >> iter 233000, loss: 12.937513
 >> iter 234000, loss: 12.988517
 >> iter 235000, loss: 12.939786
 >> iter 236000, loss: 12.964727
 >> iter 237000, loss: 12.937858
 >> iter 238000, loss: 12.976705
 >> iter 239000, loss: 12.930376
 >> iter 240000, loss: 12.972154
   Number of active neurons: 4
 >> iter 241000, loss: 12.927745
 >> iter 242000, loss: 12.970087
 >> iter 243000, loss: 12.923070
 >> iter 244000, loss: 12.974416
 >> iter 245000, loss: 12.929569
 >> iter 246000, loss: 12.975635
 >> iter 247000, loss: 12.931269
 >> iter 248000, loss: 12.977414
 >> iter 249000, loss: 12.931139
 >> iter 250000, loss: 12.974684
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 27.7254454911
   - Test - Long: 32.7583620819
   - Test - Big: 27.9837201628
   - Test - A: 33.6777548163
   - Test - B: 33.5577628158
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.949374
 >> iter 2000, loss: 15.263130
 >> iter 3000, loss: 13.868062
 >> iter 4000, loss: 13.363796
 >> iter 5000, loss: 13.161804
 >> iter 6000, loss: 13.101598
 >> iter 7000, loss: 13.057867
 >> iter 8000, loss: 13.046170
 >> iter 9000, loss: 13.028936
 >> iter 10000, loss: 13.052770
   Number of active neurons: 2
 >> iter 11000, loss: 13.036472
 >> iter 12000, loss: 13.055049
 >> iter 13000, loss: 13.033352
 >> iter 14000, loss: 13.062352
 >> iter 15000, loss: 13.055898
   Number of active neurons: 2
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 13.067603
 >> iter 17000, loss: 13.012149
 >> iter 18000, loss: 12.991104
 >> iter 19000, loss: 12.941186
 >> iter 20000, loss: 12.777191
   Number of active neurons: 4
 >> iter 21000, loss: 12.031287
 >> iter 22000, loss: 11.536653
 >> iter 23000, loss: 11.160394
 >> iter 24000, loss: 11.027001
 >> iter 25000, loss: 10.848521
 >> iter 26000, loss: 10.825558
 >> iter 27000, loss: 10.726289
 >> iter 28000, loss: 10.772959
 >> iter 29000, loss: 10.700766
 >> iter 30000, loss: 10.773943
   Number of active neurons: 4
 >> iter 31000, loss: 10.683072
 >> iter 32000, loss: 10.734309
 >> iter 33000, loss: 10.662560
 >> iter 34000, loss: 10.700468
 >> iter 35000, loss: 10.625947
 >> iter 36000, loss: 10.664908
 >> iter 37000, loss: 10.631508
 >> iter 38000, loss: 10.687389
 >> iter 39000, loss: 10.684482
 >> iter 40000, loss: 10.742593
   Number of active neurons: 4
 >> iter 41000, loss: 10.649602
 >> iter 42000, loss: 10.699070
 >> iter 43000, loss: 10.579705
 >> iter 44000, loss: 10.659348
 >> iter 45000, loss: 10.578498
 >> iter 46000, loss: 10.656897
 >> iter 47000, loss: 10.622709
 >> iter 48000, loss: 10.720083
 >> iter 49000, loss: 10.636646
 >> iter 50000, loss: 10.694337
   Number of active neurons: 4
 >> iter 51000, loss: 10.627433
 >> iter 52000, loss: 10.661266
 >> iter 53000, loss: 10.628377
 >> iter 54000, loss: 10.695389
 >> iter 55000, loss: 10.597292
 >> iter 56000, loss: 10.700691
 >> iter 57000, loss: 10.607021
 >> iter 58000, loss: 10.648631
 >> iter 59000, loss: 10.608349
 >> iter 60000, loss: 10.673923
   Number of active neurons: 4
 >> iter 61000, loss: 10.581052
 >> iter 62000, loss: 10.680728
 >> iter 63000, loss: 10.581593
 >> iter 64000, loss: 10.671207
 >> iter 65000, loss: 10.592920
 >> iter 66000, loss: 10.662162
 >> iter 67000, loss: 10.631796
 >> iter 68000, loss: 10.711953
 >> iter 69000, loss: 10.594900
 >> iter 70000, loss: 10.700969
   Number of active neurons: 4
 >> iter 71000, loss: 10.592918
 >> iter 72000, loss: 10.700975
 >> iter 73000, loss: 10.613964
 >> iter 74000, loss: 10.682399
 >> iter 75000, loss: 10.593587
 >> iter 76000, loss: 10.704441
 >> iter 77000, loss: 10.595560
 >> iter 78000, loss: 10.699596
 >> iter 79000, loss: 10.588460
 >> iter 80000, loss: 10.690016
   Number of active neurons: 4
 >> iter 81000, loss: 10.570290
 >> iter 82000, loss: 10.670355
 >> iter 83000, loss: 10.601394
 >> iter 84000, loss: 10.658681
 >> iter 85000, loss: 10.591659
 >> iter 86000, loss: 10.645503
 >> iter 87000, loss: 10.596973
 >> iter 88000, loss: 10.704529
 >> iter 89000, loss: 10.595897
 >> iter 90000, loss: 10.725113
   Number of active neurons: 4
 >> iter 91000, loss: 10.608470
 >> iter 92000, loss: 10.691614
 >> iter 93000, loss: 10.613689
 >> iter 94000, loss: 10.699117
 >> iter 95000, loss: 10.608336
 >> iter 96000, loss: 10.649101
 >> iter 97000, loss: 10.588714
 >> iter 98000, loss: 10.666560
 >> iter 99000, loss: 10.567240
 >> iter 100000, loss: 10.654040
   Number of active neurons: 4
 >> iter 101000, loss: 10.607159
 >> iter 102000, loss: 10.686229
 >> iter 103000, loss: 10.584813
 >> iter 104000, loss: 10.694093
 >> iter 105000, loss: 10.600196
 >> iter 106000, loss: 10.672277
 >> iter 107000, loss: 10.560721
 >> iter 108000, loss: 10.685368
 >> iter 109000, loss: 10.569044
 >> iter 110000, loss: 10.658630
   Number of active neurons: 4
 >> iter 111000, loss: 10.561737
 >> iter 112000, loss: 10.687434
 >> iter 113000, loss: 10.589386
 >> iter 114000, loss: 10.658953
 >> iter 115000, loss: 10.573747
 >> iter 116000, loss: 10.654746
 >> iter 117000, loss: 10.573465
 >> iter 118000, loss: 10.685094
 >> iter 119000, loss: 10.569661
 >> iter 120000, loss: 10.678656
   Number of active neurons: 4
 >> iter 121000, loss: 10.573576
 >> iter 122000, loss: 10.652785
 >> iter 123000, loss: 10.590668
 >> iter 124000, loss: 10.673393
 >> iter 125000, loss: 10.586795
 >> iter 126000, loss: 10.696167
 >> iter 127000, loss: 10.559866
 >> iter 128000, loss: 10.671101
 >> iter 129000, loss: 10.590896
 >> iter 130000, loss: 10.703809
   Number of active neurons: 4
 >> iter 131000, loss: 10.571686
 >> iter 132000, loss: 10.661339
 >> iter 133000, loss: 10.586547
 >> iter 134000, loss: 10.684703
 >> iter 135000, loss: 10.561204
 >> iter 136000, loss: 10.677662
 >> iter 137000, loss: 10.551839
 >> iter 138000, loss: 10.695293
 >> iter 139000, loss: 10.622595
 >> iter 140000, loss: 10.703248
   Number of active neurons: 4
 >> iter 141000, loss: 10.563299
 >> iter 142000, loss: 10.693833
 >> iter 143000, loss: 10.595907
 >> iter 144000, loss: 10.683917
 >> iter 145000, loss: 10.564281
 >> iter 146000, loss: 10.673048
 >> iter 147000, loss: 10.573506
 >> iter 148000, loss: 10.672505
 >> iter 149000, loss: 10.571647
 >> iter 150000, loss: 10.678294
   Number of active neurons: 4
 >> iter 151000, loss: 10.527025
 >> iter 152000, loss: 10.679582
 >> iter 153000, loss: 10.566347
 >> iter 154000, loss: 10.659401
 >> iter 155000, loss: 10.575177
 >> iter 156000, loss: 10.659690
 >> iter 157000, loss: 10.542848
 >> iter 158000, loss: 10.668395
 >> iter 159000, loss: 10.537216
 >> iter 160000, loss: 10.690687
   Number of active neurons: 4
 >> iter 161000, loss: 10.574965
 >> iter 162000, loss: 10.671596
 >> iter 163000, loss: 10.537802
 >> iter 164000, loss: 10.680674
 >> iter 165000, loss: 10.551954
 >> iter 166000, loss: 10.651636
 >> iter 167000, loss: 10.554538
 >> iter 168000, loss: 10.646902
 >> iter 169000, loss: 10.542859
 >> iter 170000, loss: 10.656728
   Number of active neurons: 4
 >> iter 171000, loss: 10.564920
 >> iter 172000, loss: 10.672364
 >> iter 173000, loss: 10.550814
 >> iter 174000, loss: 10.676011
 >> iter 175000, loss: 10.513973
 >> iter 176000, loss: 10.652229
 >> iter 177000, loss: 10.514755
 >> iter 178000, loss: 10.639270
 >> iter 179000, loss: 10.543756
 >> iter 180000, loss: 10.681788
   Number of active neurons: 4
 >> iter 181000, loss: 10.574888
 >> iter 182000, loss: 10.705353
 >> iter 183000, loss: 10.559086
 >> iter 184000, loss: 10.694737
 >> iter 185000, loss: 10.561614
 >> iter 186000, loss: 10.679311
 >> iter 187000, loss: 10.550293
 >> iter 188000, loss: 10.683512
 >> iter 189000, loss: 10.583595
 >> iter 190000, loss: 10.691842
   Number of active neurons: 4
 >> iter 191000, loss: 10.534188
 >> iter 192000, loss: 10.691899
 >> iter 193000, loss: 10.540422
 >> iter 194000, loss: 10.704035
 >> iter 195000, loss: 10.557369
 >> iter 196000, loss: 10.669145
 >> iter 197000, loss: 10.527991
 >> iter 198000, loss: 10.650910
 >> iter 199000, loss: 10.557221
 >> iter 200000, loss: 10.702437
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 21.6135677286
   - Test - Long: 32.00339983
   - Test - Big: 21.8317816822
   - Test - A: 31.4245716952
   - Test - B: 32.5911605893
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.984466
 >> iter 2000, loss: 15.293803
 >> iter 3000, loss: 13.891106
 >> iter 4000, loss: 13.371467
 >> iter 5000, loss: 13.153706
 >> iter 6000, loss: 13.099133
 >> iter 7000, loss: 13.056383
 >> iter 8000, loss: 13.038356
 >> iter 9000, loss: 13.013040
 >> iter 10000, loss: 13.016963
   Number of active neurons: 4
 >> iter 11000, loss: 12.997957
 >> iter 12000, loss: 13.011255
 >> iter 13000, loss: 12.994867
 >> iter 14000, loss: 13.003159
 >> iter 15000, loss: 12.984953
 >> iter 16000, loss: 12.999817
 >> iter 17000, loss: 12.982308
 >> iter 18000, loss: 12.990563
 >> iter 19000, loss: 12.983629
 >> iter 20000, loss: 12.989974
   Number of active neurons: 4
 >> iter 21000, loss: 12.979619
 >> iter 22000, loss: 12.999869
 >> iter 23000, loss: 12.984695
 >> iter 24000, loss: 13.001532
 >> iter 25000, loss: 12.977939
 >> iter 26000, loss: 12.994130
 >> iter 27000, loss: 12.976049
 >> iter 28000, loss: 12.988312
 >> iter 29000, loss: 12.970433
 >> iter 30000, loss: 12.993787
   Number of active neurons: 4
 >> iter 31000, loss: 12.971902
 >> iter 32000, loss: 12.986948
 >> iter 33000, loss: 12.975217
 >> iter 34000, loss: 12.988936
 >> iter 35000, loss: 12.964985
 >> iter 36000, loss: 12.973803
 >> iter 37000, loss: 12.956923
 >> iter 38000, loss: 12.973149
 >> iter 39000, loss: 12.956971
 >> iter 40000, loss: 12.973614
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 3
 >> iter 41000, loss: 12.978669
 >> iter 42000, loss: 12.976845
 >> iter 43000, loss: 12.949855
 >> iter 44000, loss: 12.962699
 >> iter 45000, loss: 12.940319
 >> iter 46000, loss: 12.966159
 >> iter 47000, loss: 12.941805
 >> iter 48000, loss: 12.969541
 >> iter 49000, loss: 12.945454
 >> iter 50000, loss: 12.970171
   Number of active neurons: 4
 >> iter 51000, loss: 12.941683
 >> iter 52000, loss: 12.970218
 >> iter 53000, loss: 12.939249
 >> iter 54000, loss: 12.977303
 >> iter 55000, loss: 12.939478
 >> iter 56000, loss: 12.969273
 >> iter 57000, loss: 12.939652
 >> iter 58000, loss: 12.976627
 >> iter 59000, loss: 12.948636
 >> iter 60000, loss: 12.977330
   Number of active neurons: 4
 >> iter 61000, loss: 12.948110
 >> iter 62000, loss: 12.971896
 >> iter 63000, loss: 12.951732
 >> iter 64000, loss: 12.981346
 >> iter 65000, loss: 12.955608
 >> iter 66000, loss: 12.981869
 >> iter 67000, loss: 12.954750
 >> iter 68000, loss: 12.966639
 >> iter 69000, loss: 12.944783
 >> iter 70000, loss: 12.981941
   Number of active neurons: 4
 >> iter 71000, loss: 12.957729
 >> iter 72000, loss: 12.982864
 >> iter 73000, loss: 12.952372
 >> iter 74000, loss: 12.980668
 >> iter 75000, loss: 12.955240
 >> iter 76000, loss: 12.983941
 >> iter 77000, loss: 12.956520
 >> iter 78000, loss: 12.982178
 >> iter 79000, loss: 12.945485
 >> iter 80000, loss: 12.982950
   Number of active neurons: 4
 >> iter 81000, loss: 12.950811
 >> iter 82000, loss: 12.982079
 >> iter 83000, loss: 12.950716
 >> iter 84000, loss: 12.980823
 >> iter 85000, loss: 12.955407
 >> iter 86000, loss: 12.982346
 >> iter 87000, loss: 12.955297
 >> iter 88000, loss: 12.982444
 >> iter 89000, loss: 12.954453
 >> iter 90000, loss: 12.985430
   Number of active neurons: 4
 >> iter 91000, loss: 12.956173
 >> iter 92000, loss: 12.985451
 >> iter 93000, loss: 12.952220
 >> iter 94000, loss: 12.980841
 >> iter 95000, loss: 12.960414
 >> iter 96000, loss: 12.990567
 >> iter 97000, loss: 12.951392
 >> iter 98000, loss: 12.982353
 >> iter 99000, loss: 12.956170
 >> iter 100000, loss: 12.983686
   Number of active neurons: 4
 >> iter 101000, loss: 12.957619
 >> iter 102000, loss: 12.983626
 >> iter 103000, loss: 12.950073
 >> iter 104000, loss: 12.981587
 >> iter 105000, loss: 12.954793
 >> iter 106000, loss: 12.976994
 >> iter 107000, loss: 12.950427
 >> iter 108000, loss: 12.986670
 >> iter 109000, loss: 12.949758
 >> iter 110000, loss: 12.985652
   Number of active neurons: 4
 >> iter 111000, loss: 12.953213
 >> iter 112000, loss: 12.985699
 >> iter 113000, loss: 12.944470
 >> iter 114000, loss: 12.979764
 >> iter 115000, loss: 12.944952
 >> iter 116000, loss: 12.981511
 >> iter 117000, loss: 12.945812
 >> iter 118000, loss: 12.980573
 >> iter 119000, loss: 12.936076
 >> iter 120000, loss: 12.975170
   Number of active neurons: 4
 >> iter 121000, loss: 12.932385
 >> iter 122000, loss: 12.975874
 >> iter 123000, loss: 12.933785
 >> iter 124000, loss: 12.967899
 >> iter 125000, loss: 12.922702
 >> iter 126000, loss: 12.973160
 >> iter 127000, loss: 12.927418
 >> iter 128000, loss: 12.982482
 >> iter 129000, loss: 12.935107
 >> iter 130000, loss: 12.982398
   Number of active neurons: 4
 >> iter 131000, loss: 12.939683
 >> iter 132000, loss: 12.973341
 >> iter 133000, loss: 12.930664
 >> iter 134000, loss: 12.993530
 >> iter 135000, loss: 12.935002
 >> iter 136000, loss: 12.981376
 >> iter 137000, loss: 12.926297
 >> iter 138000, loss: 12.980332
 >> iter 139000, loss: 12.933613
 >> iter 140000, loss: 12.987585
   Number of active neurons: 4
 >> iter 141000, loss: 12.937501
 >> iter 142000, loss: 12.987742
 >> iter 143000, loss: 12.942919
 >> iter 144000, loss: 12.988276
 >> iter 145000, loss: 12.935849
 >> iter 146000, loss: 12.988112
 >> iter 147000, loss: 12.942325
 >> iter 148000, loss: 12.991105
 >> iter 149000, loss: 12.933592
 >> iter 150000, loss: 12.987157
   Number of active neurons: 4
 >> iter 151000, loss: 12.941595
 >> iter 152000, loss: 12.985013
 >> iter 153000, loss: 12.938311
 >> iter 154000, loss: 12.993641
 >> iter 155000, loss: 12.942863
 >> iter 156000, loss: 12.986527
 >> iter 157000, loss: 12.934643
 >> iter 158000, loss: 12.993777
 >> iter 159000, loss: 12.939032
 >> iter 160000, loss: 12.989523
   Number of active neurons: 4
 >> iter 161000, loss: 12.937111
 >> iter 162000, loss: 12.997528
 >> iter 163000, loss: 12.942448
 >> iter 164000, loss: 12.988563
 >> iter 165000, loss: 12.934174
 >> iter 166000, loss: 12.987357
 >> iter 167000, loss: 12.933906
 >> iter 168000, loss: 12.979832
 >> iter 169000, loss: 12.929814
 >> iter 170000, loss: 12.972481
   Number of active neurons: 4
 >> iter 171000, loss: 12.934655
 >> iter 172000, loss: 12.983940
 >> iter 173000, loss: 12.936530
 >> iter 174000, loss: 12.976780
 >> iter 175000, loss: 12.931436
 >> iter 176000, loss: 12.986571
 >> iter 177000, loss: 12.937877
 >> iter 178000, loss: 12.989495
 >> iter 179000, loss: 12.940372
 >> iter 180000, loss: 12.984358
   Number of active neurons: 4
 >> iter 181000, loss: 12.934864
 >> iter 182000, loss: 12.986925
 >> iter 183000, loss: 12.936417
 >> iter 184000, loss: 12.991136
 >> iter 185000, loss: 12.933132
 >> iter 186000, loss: 12.988350
 >> iter 187000, loss: 12.928037
 >> iter 188000, loss: 12.982466
 >> iter 189000, loss: 12.927069
 >> iter 190000, loss: 12.990898
   Number of active neurons: 4
 >> iter 191000, loss: 12.928142
 >> iter 192000, loss: 12.984341
 >> iter 193000, loss: 12.928016
 >> iter 194000, loss: 12.986677
 >> iter 195000, loss: 12.936021
 >> iter 196000, loss: 12.983536
 >> iter 197000, loss: 12.932258
 >> iter 198000, loss: 12.984437
 >> iter 199000, loss: 12.927991
 >> iter 200000, loss: 12.978887
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 27.7254454911
   - Test - Long: 32.7583620819
   - Test - Big: 27.9837201628
   - Test - A: 33.6777548163
   - Test - B: 33.5577628158
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.930886
 >> iter 2000, loss: 15.247451
 >> iter 3000, loss: 13.854566
 >> iter 4000, loss: 13.348890
 >> iter 5000, loss: 13.156063
 >> iter 6000, loss: 13.092020
 >> iter 7000, loss: 13.051225
 >> iter 8000, loss: 13.053784
 >> iter 9000, loss: 13.048222
 >> iter 10000, loss: 13.052147
   Number of active neurons: 2
 >> iter 11000, loss: 13.035395
 >> iter 12000, loss: 13.050188
 >> iter 13000, loss: 13.028165
 >> iter 14000, loss: 13.058664
 >> iter 15000, loss: 13.026753
 >> iter 16000, loss: 13.043966
 >> iter 17000, loss: 13.026498
 >> iter 18000, loss: 13.035722
 >> iter 19000, loss: 13.016423
 >> iter 20000, loss: 13.056064
   Number of active neurons: 2
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 2
 >> iter 21000, loss: 13.024451
 >> iter 22000, loss: 12.998676
 >> iter 23000, loss: 12.972479
 >> iter 24000, loss: 12.984754
 >> iter 25000, loss: 12.962010
 >> iter 26000, loss: 12.980255
 >> iter 27000, loss: 12.949936
 >> iter 28000, loss: 12.965966
 >> iter 29000, loss: 12.957322
 >> iter 30000, loss: 12.976457
   Number of active neurons: 3
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 3
 >> iter 31000, loss: 12.993449
 >> iter 32000, loss: 12.988473
 >> iter 33000, loss: 12.962725
 >> iter 34000, loss: 12.963049
 >> iter 35000, loss: 12.946187
 >> iter 36000, loss: 12.961424
 >> iter 37000, loss: 12.948278
 >> iter 38000, loss: 12.967256
 >> iter 39000, loss: 12.943633
 >> iter 40000, loss: 12.967888
   Number of active neurons: 4
 >> iter 41000, loss: 12.942722
 >> iter 42000, loss: 12.962509
 >> iter 43000, loss: 12.940525
 >> iter 44000, loss: 12.964339
 >> iter 45000, loss: 12.942729
 >> iter 46000, loss: 12.969219
 >> iter 47000, loss: 12.950400
 >> iter 48000, loss: 12.974476
 >> iter 49000, loss: 12.952040
 >> iter 50000, loss: 12.967077
   Number of active neurons: 4
 >> iter 51000, loss: 12.942318
 >> iter 52000, loss: 12.969958
 >> iter 53000, loss: 12.943565
 >> iter 54000, loss: 12.976375
 >> iter 55000, loss: 12.942826
 >> iter 56000, loss: 12.972630
 >> iter 57000, loss: 12.944508
 >> iter 58000, loss: 12.971012
 >> iter 59000, loss: 12.940855
 >> iter 60000, loss: 12.972479
   Number of active neurons: 4
 >> iter 61000, loss: 12.946445
 >> iter 62000, loss: 12.973517
 >> iter 63000, loss: 12.947515
 >> iter 64000, loss: 12.972937
 >> iter 65000, loss: 12.950696
 >> iter 66000, loss: 12.980634
 >> iter 67000, loss: 12.948847
 >> iter 68000, loss: 12.973295
 >> iter 69000, loss: 12.945031
 >> iter 70000, loss: 12.979972
   Number of active neurons: 4
 >> iter 71000, loss: 12.950627
 >> iter 72000, loss: 12.981246
 >> iter 73000, loss: 12.950624
 >> iter 74000, loss: 12.978054
 >> iter 75000, loss: 12.948372
 >> iter 76000, loss: 12.978622
 >> iter 77000, loss: 12.947103
 >> iter 78000, loss: 12.981800
 >> iter 79000, loss: 12.947549
 >> iter 80000, loss: 12.982489
   Number of active neurons: 4
 >> iter 81000, loss: 12.947812
 >> iter 82000, loss: 12.981723
 >> iter 83000, loss: 12.949530
 >> iter 84000, loss: 12.986054
 >> iter 85000, loss: 12.949286
 >> iter 86000, loss: 12.971281
 >> iter 87000, loss: 12.951538
 >> iter 88000, loss: 12.984551
 >> iter 89000, loss: 12.953853
 >> iter 90000, loss: 12.987304
   Number of active neurons: 4
 >> iter 91000, loss: 12.952507
 >> iter 92000, loss: 12.985357
 >> iter 93000, loss: 12.948341
 >> iter 94000, loss: 12.988419
 >> iter 95000, loss: 12.958907
 >> iter 96000, loss: 12.983987
 >> iter 97000, loss: 12.957181
 >> iter 98000, loss: 12.985282
 >> iter 99000, loss: 12.955503
 >> iter 100000, loss: 12.979584
   Number of active neurons: 4
 >> iter 101000, loss: 12.957902
 >> iter 102000, loss: 12.984752
 >> iter 103000, loss: 12.953652
 >> iter 104000, loss: 12.982741
 >> iter 105000, loss: 12.951660
 >> iter 106000, loss: 12.983023
 >> iter 107000, loss: 12.952574
 >> iter 108000, loss: 12.993032
 >> iter 109000, loss: 12.955260
 >> iter 110000, loss: 12.989979
   Number of active neurons: 4
 >> iter 111000, loss: 12.943672
 >> iter 112000, loss: 12.986211
 >> iter 113000, loss: 12.951079
 >> iter 114000, loss: 12.983922
 >> iter 115000, loss: 12.944228
 >> iter 116000, loss: 12.982176
 >> iter 117000, loss: 12.940316
 >> iter 118000, loss: 12.981878
 >> iter 119000, loss: 12.942296
 >> iter 120000, loss: 12.983215
   Number of active neurons: 4
 >> iter 121000, loss: 12.937609
 >> iter 122000, loss: 12.983736
 >> iter 123000, loss: 12.946719
 >> iter 124000, loss: 12.974878
 >> iter 125000, loss: 12.934604
 >> iter 126000, loss: 12.981587
 >> iter 127000, loss: 12.933339
 >> iter 128000, loss: 12.978743
 >> iter 129000, loss: 12.932880
 >> iter 130000, loss: 12.986920
   Number of active neurons: 4
 >> iter 131000, loss: 12.939329
 >> iter 132000, loss: 12.979347
 >> iter 133000, loss: 12.934917
 >> iter 134000, loss: 12.980338
 >> iter 135000, loss: 12.940178
 >> iter 136000, loss: 12.985064
 >> iter 137000, loss: 12.936671
 >> iter 138000, loss: 12.979005
 >> iter 139000, loss: 12.938820
 >> iter 140000, loss: 12.979606
   Number of active neurons: 4
 >> iter 141000, loss: 12.933986
 >> iter 142000, loss: 12.988392
 >> iter 143000, loss: 12.938403
 >> iter 144000, loss: 12.995056
 >> iter 145000, loss: 12.941875
 >> iter 146000, loss: 12.988548
 >> iter 147000, loss: 12.942690
 >> iter 148000, loss: 12.994872
 >> iter 149000, loss: 12.938858
 >> iter 150000, loss: 12.988360
   Number of active neurons: 4
 >> iter 151000, loss: 12.943214
 >> iter 152000, loss: 12.991036
 >> iter 153000, loss: 12.940270
 >> iter 154000, loss: 12.992027
 >> iter 155000, loss: 12.943274
 >> iter 156000, loss: 12.985244
 >> iter 157000, loss: 12.944238
 >> iter 158000, loss: 12.996275
 >> iter 159000, loss: 12.940552
 >> iter 160000, loss: 12.990093
   Number of active neurons: 4
 >> iter 161000, loss: 12.938045
 >> iter 162000, loss: 12.991417
 >> iter 163000, loss: 12.933513
 >> iter 164000, loss: 12.977991
 >> iter 165000, loss: 12.929950
 >> iter 166000, loss: 12.985864
 >> iter 167000, loss: 12.923219
 >> iter 168000, loss: 12.972918
 >> iter 169000, loss: 12.926640
 >> iter 170000, loss: 12.983728
   Number of active neurons: 4
 >> iter 171000, loss: 12.934858
 >> iter 172000, loss: 12.983585
 >> iter 173000, loss: 12.934256
 >> iter 174000, loss: 12.981527
 >> iter 175000, loss: 12.934339
 >> iter 176000, loss: 12.979576
 >> iter 177000, loss: 12.934929
 >> iter 178000, loss: 12.981622
 >> iter 179000, loss: 12.934004
 >> iter 180000, loss: 12.985676
   Number of active neurons: 4
 >> iter 181000, loss: 12.937462
 >> iter 182000, loss: 12.986204
 >> iter 183000, loss: 12.932550
 >> iter 184000, loss: 12.985800
 >> iter 185000, loss: 12.932719
 >> iter 186000, loss: 12.983025
 >> iter 187000, loss: 12.924118
 >> iter 188000, loss: 12.996746
 >> iter 189000, loss: 12.926870
 >> iter 190000, loss: 12.985355
   Number of active neurons: 4
 >> iter 191000, loss: 12.928717
 >> iter 192000, loss: 12.985951
 >> iter 193000, loss: 12.928352
 >> iter 194000, loss: 12.978520
 >> iter 195000, loss: 12.931533
 >> iter 196000, loss: 12.980595
 >> iter 197000, loss: 12.928333
 >> iter 198000, loss: 12.991864
 >> iter 199000, loss: 12.939951
 >> iter 200000, loss: 12.974475
   Number of active neurons: 4
 >> iter 201000, loss: 12.928313
 >> iter 202000, loss: 12.983325
 >> iter 203000, loss: 12.935192
 >> iter 204000, loss: 12.986695
 >> iter 205000, loss: 12.927715
 >> iter 206000, loss: 12.986715
 >> iter 207000, loss: 12.932283
 >> iter 208000, loss: 12.979090
 >> iter 209000, loss: 12.933940
 >> iter 210000, loss: 12.976801
   Number of active neurons: 4
 >> iter 211000, loss: 12.939342
 >> iter 212000, loss: 12.979041
 >> iter 213000, loss: 12.936620
 >> iter 214000, loss: 12.989674
 >> iter 215000, loss: 12.934644
 >> iter 216000, loss: 12.979929
 >> iter 217000, loss: 12.935800
 >> iter 218000, loss: 12.970341
 >> iter 219000, loss: 12.932434
 >> iter 220000, loss: 12.985291
   Number of active neurons: 4
 >> iter 221000, loss: 12.936149
 >> iter 222000, loss: 12.987984
 >> iter 223000, loss: 12.932523
 >> iter 224000, loss: 12.978029
 >> iter 225000, loss: 12.929012
 >> iter 226000, loss: 12.968858
 >> iter 227000, loss: 12.931482
 >> iter 228000, loss: 12.975289
 >> iter 229000, loss: 12.934379
 >> iter 230000, loss: 12.975455
   Number of active neurons: 4
 >> iter 231000, loss: 12.932699
 >> iter 232000, loss: 12.976720
 >> iter 233000, loss: 12.937765
 >> iter 234000, loss: 12.981645
 >> iter 235000, loss: 12.936462
 >> iter 236000, loss: 12.974116
 >> iter 237000, loss: 12.938854
 >> iter 238000, loss: 12.979973
 >> iter 239000, loss: 12.935053
 >> iter 240000, loss: 12.976357
   Number of active neurons: 4
 >> iter 241000, loss: 12.929476
 >> iter 242000, loss: 12.971118
 >> iter 243000, loss: 12.936685
 >> iter 244000, loss: 12.982174
 >> iter 245000, loss: 12.935750
 >> iter 246000, loss: 12.972200
 >> iter 247000, loss: 12.930563
 >> iter 248000, loss: 12.976556
 >> iter 249000, loss: 12.931882
 >> iter 250000, loss: 12.978403
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 27.7254454911
   - Test - Long: 32.7583620819
   - Test - Big: 27.9837201628
   - Test - A: 33.6777548163
   - Test - B: 33.5577628158
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.965698
 >> iter 2000, loss: 15.252202
 >> iter 3000, loss: 13.832304
 >> iter 4000, loss: 13.302320
 >> iter 5000, loss: 13.094537
 >> iter 6000, loss: 13.032087
 >> iter 7000, loss: 12.991192
 >> iter 8000, loss: 12.988246
 >> iter 9000, loss: 12.969843
 >> iter 10000, loss: 12.978838
   Number of active neurons: 3
 >> iter 11000, loss: 12.961445
 >> iter 12000, loss: 12.977377
 >> iter 13000, loss: 12.964563
 >> iter 14000, loss: 12.977397
 >> iter 15000, loss: 12.967514
 >> iter 16000, loss: 12.974734
 >> iter 17000, loss: 12.964198
 >> iter 18000, loss: 12.977645
 >> iter 19000, loss: 12.964015
 >> iter 20000, loss: 12.970429
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 3
 >> iter 21000, loss: 13.001849
 >> iter 22000, loss: 13.004158
 >> iter 23000, loss: 12.978133
 >> iter 24000, loss: 12.988859
 >> iter 25000, loss: 12.968040
 >> iter 26000, loss: 12.984308
 >> iter 27000, loss: 12.963031
 >> iter 28000, loss: 12.962201
 >> iter 29000, loss: 12.947614
 >> iter 30000, loss: 12.963180
   Number of active neurons: 4
 >> iter 31000, loss: 12.947980
 >> iter 32000, loss: 12.967492
 >> iter 33000, loss: 12.949120
 >> iter 34000, loss: 12.962948
 >> iter 35000, loss: 12.957114
 >> iter 36000, loss: 12.964587
 >> iter 37000, loss: 12.952555
 >> iter 38000, loss: 12.968788
 >> iter 39000, loss: 12.953692
 >> iter 40000, loss: 12.965192
   Number of active neurons: 4
 >> iter 41000, loss: 12.952000
 >> iter 42000, loss: 12.965547
 >> iter 43000, loss: 12.949253
 >> iter 44000, loss: 12.967805
 >> iter 45000, loss: 12.947060
 >> iter 46000, loss: 12.971203
 >> iter 47000, loss: 12.947357
 >> iter 48000, loss: 12.977529
 >> iter 49000, loss: 12.944075
 >> iter 50000, loss: 12.975358
   Number of active neurons: 4
 >> iter 51000, loss: 12.942284
 >> iter 52000, loss: 12.972147
 >> iter 53000, loss: 12.942675
 >> iter 54000, loss: 12.973737
 >> iter 55000, loss: 12.940576
 >> iter 56000, loss: 12.970610
 >> iter 57000, loss: 12.950152
 >> iter 58000, loss: 12.971150
 >> iter 59000, loss: 12.940806
 >> iter 60000, loss: 12.968957
   Number of active neurons: 4
 >> iter 61000, loss: 12.945644
 >> iter 62000, loss: 12.968612
 >> iter 63000, loss: 12.937938
 >> iter 64000, loss: 12.977318
 >> iter 65000, loss: 12.948296
 >> iter 66000, loss: 12.970490
 >> iter 67000, loss: 12.944419
 >> iter 68000, loss: 12.978766
 >> iter 69000, loss: 12.951199
 >> iter 70000, loss: 12.980005
   Number of active neurons: 4
 >> iter 71000, loss: 12.943955
 >> iter 72000, loss: 12.974247
 >> iter 73000, loss: 12.958673
 >> iter 74000, loss: 12.974208
 >> iter 75000, loss: 12.945096
 >> iter 76000, loss: 12.974395
 >> iter 77000, loss: 12.951063
 >> iter 78000, loss: 12.978851
 >> iter 79000, loss: 12.949599
 >> iter 80000, loss: 12.975394
   Number of active neurons: 4
 >> iter 81000, loss: 12.945672
 >> iter 82000, loss: 12.977612
 >> iter 83000, loss: 12.947797
 >> iter 84000, loss: 12.981672
 >> iter 85000, loss: 12.951304
 >> iter 86000, loss: 12.982059
 >> iter 87000, loss: 12.956806
 >> iter 88000, loss: 12.983322
 >> iter 89000, loss: 12.951189
 >> iter 90000, loss: 12.986772
   Number of active neurons: 4
 >> iter 91000, loss: 12.951863
 >> iter 92000, loss: 12.986415
 >> iter 93000, loss: 12.959956
 >> iter 94000, loss: 12.990526
 >> iter 95000, loss: 12.960333
 >> iter 96000, loss: 12.984566
 >> iter 97000, loss: 12.954218
 >> iter 98000, loss: 12.983471
 >> iter 99000, loss: 12.953475
 >> iter 100000, loss: 12.986181
   Number of active neurons: 4
 >> iter 101000, loss: 12.955075
 >> iter 102000, loss: 12.982454
 >> iter 103000, loss: 12.952134
 >> iter 104000, loss: 12.979011
 >> iter 105000, loss: 12.951130
 >> iter 106000, loss: 12.991035
 >> iter 107000, loss: 12.954700
 >> iter 108000, loss: 12.988284
 >> iter 109000, loss: 12.949486
 >> iter 110000, loss: 12.985528
   Number of active neurons: 4
 >> iter 111000, loss: 12.952085
 >> iter 112000, loss: 12.983586
 >> iter 113000, loss: 12.952520
 >> iter 114000, loss: 12.979518
 >> iter 115000, loss: 12.949460
 >> iter 116000, loss: 12.984909
 >> iter 117000, loss: 12.946265
 >> iter 118000, loss: 12.977820
 >> iter 119000, loss: 12.946017
 >> iter 120000, loss: 12.984041
   Number of active neurons: 4
 >> iter 121000, loss: 12.941456
 >> iter 122000, loss: 12.983868
 >> iter 123000, loss: 12.940245
 >> iter 124000, loss: 12.974490
 >> iter 125000, loss: 12.932835
 >> iter 126000, loss: 12.980002
 >> iter 127000, loss: 12.936453
 >> iter 128000, loss: 12.977898
 >> iter 129000, loss: 12.936030
 >> iter 130000, loss: 12.973278
   Number of active neurons: 4
 >> iter 131000, loss: 12.938547
 >> iter 132000, loss: 12.977988
 >> iter 133000, loss: 12.941403
 >> iter 134000, loss: 12.985461
 >> iter 135000, loss: 12.933627
 >> iter 136000, loss: 12.982701
 >> iter 137000, loss: 12.932574
 >> iter 138000, loss: 12.988976
 >> iter 139000, loss: 12.931526
 >> iter 140000, loss: 12.985034
   Number of active neurons: 4
 >> iter 141000, loss: 12.933988
 >> iter 142000, loss: 12.991004
 >> iter 143000, loss: 12.943441
 >> iter 144000, loss: 12.994383
 >> iter 145000, loss: 12.936798
 >> iter 146000, loss: 12.988671
 >> iter 147000, loss: 12.934657
 >> iter 148000, loss: 12.989109
 >> iter 149000, loss: 12.942687
 >> iter 150000, loss: 12.990366
   Number of active neurons: 4
 >> iter 151000, loss: 12.950783
 >> iter 152000, loss: 12.993712
 >> iter 153000, loss: 12.948183
 >> iter 154000, loss: 12.988062
 >> iter 155000, loss: 12.941008
 >> iter 156000, loss: 12.982604
 >> iter 157000, loss: 12.933789
 >> iter 158000, loss: 12.988236
 >> iter 159000, loss: 12.934759
 >> iter 160000, loss: 12.992556
   Number of active neurons: 4
 >> iter 161000, loss: 12.937535
 >> iter 162000, loss: 12.989547
 >> iter 163000, loss: 12.933047
 >> iter 164000, loss: 12.977451
 >> iter 165000, loss: 12.933295
 >> iter 166000, loss: 12.978446
 >> iter 167000, loss: 12.928110
 >> iter 168000, loss: 12.979888
 >> iter 169000, loss: 12.932005
 >> iter 170000, loss: 12.972792
   Number of active neurons: 4
 >> iter 171000, loss: 12.925911
 >> iter 172000, loss: 12.981689
 >> iter 173000, loss: 12.927830
 >> iter 174000, loss: 12.977887
 >> iter 175000, loss: 12.926136
 >> iter 176000, loss: 12.983042
 >> iter 177000, loss: 12.923887
 >> iter 178000, loss: 12.983027
 >> iter 179000, loss: 12.935060
 >> iter 180000, loss: 12.990883
   Number of active neurons: 4
 >> iter 181000, loss: 12.930473
 >> iter 182000, loss: 12.982510
 >> iter 183000, loss: 12.929694
 >> iter 184000, loss: 12.991257
 >> iter 185000, loss: 12.927240
 >> iter 186000, loss: 12.987798
 >> iter 187000, loss: 12.932942
 >> iter 188000, loss: 12.994492
 >> iter 189000, loss: 12.925137
 >> iter 190000, loss: 12.991365
   Number of active neurons: 4
 >> iter 191000, loss: 12.930592
 >> iter 192000, loss: 12.984692
 >> iter 193000, loss: 12.934058
 >> iter 194000, loss: 12.981842
 >> iter 195000, loss: 12.931182
 >> iter 196000, loss: 12.981137
 >> iter 197000, loss: 12.933399
 >> iter 198000, loss: 12.985987
 >> iter 199000, loss: 12.927424
 >> iter 200000, loss: 12.982079
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 27.7254454911
   - Test - Long: 32.7583620819
   - Test - Big: 27.9837201628
   - Test - A: 33.6777548163
   - Test - B: 33.5577628158
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.937594
 >> iter 2000, loss: 15.261884
 >> iter 3000, loss: 13.870174
 >> iter 4000, loss: 13.359451
 >> iter 5000, loss: 13.143465
 >> iter 6000, loss: 13.075936
 >> iter 7000, loss: 13.046126
 >> iter 8000, loss: 13.042707
 >> iter 9000, loss: 13.036504
 >> iter 10000, loss: 13.052950
   Number of active neurons: 2
 >> iter 11000, loss: 13.036766
 >> iter 12000, loss: 13.029238
 >> iter 13000, loss: 13.023615
 >> iter 14000, loss: 13.039615
 >> iter 15000, loss: 13.046652
 >> iter 16000, loss: 13.055499
 >> iter 17000, loss: 13.040057
 >> iter 18000, loss: 13.050119
 >> iter 19000, loss: 13.043077
 >> iter 20000, loss: 13.067290
   Number of active neurons: 2
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 2
 >> iter 21000, loss: 13.048950
 >> iter 22000, loss: 13.017741
 >> iter 23000, loss: 12.985707
 >> iter 24000, loss: 12.992592
 >> iter 25000, loss: 12.973274
 >> iter 26000, loss: 12.985034
 >> iter 27000, loss: 12.965506
 >> iter 28000, loss: 12.975687
 >> iter 29000, loss: 12.953675
 >> iter 30000, loss: 12.965338
   Number of active neurons: 4
 >> iter 31000, loss: 12.955823
 >> iter 32000, loss: 12.965980
 >> iter 33000, loss: 12.952192
 >> iter 34000, loss: 12.972500
 >> iter 35000, loss: 12.954503
 >> iter 36000, loss: 12.971451
 >> iter 37000, loss: 12.959628
 >> iter 38000, loss: 12.970132
 >> iter 39000, loss: 12.949785
 >> iter 40000, loss: 12.964670
   Number of active neurons: 4
 >> iter 41000, loss: 12.946218
 >> iter 42000, loss: 12.973293
 >> iter 43000, loss: 12.950076
 >> iter 44000, loss: 12.974473
 >> iter 45000, loss: 12.953010
 >> iter 46000, loss: 12.978233
 >> iter 47000, loss: 12.949890
 >> iter 48000, loss: 12.973546
 >> iter 49000, loss: 12.943997
 >> iter 50000, loss: 12.970727
   Number of active neurons: 4
 >> iter 51000, loss: 12.945764
 >> iter 52000, loss: 12.969158
 >> iter 53000, loss: 12.943991
 >> iter 54000, loss: 12.970550
 >> iter 55000, loss: 12.948369
 >> iter 56000, loss: 12.984940
 >> iter 57000, loss: 12.956016
 >> iter 58000, loss: 12.980408
 >> iter 59000, loss: 12.949771
 >> iter 60000, loss: 12.981422
   Number of active neurons: 4
 >> iter 61000, loss: 12.951342
 >> iter 62000, loss: 12.980687
 >> iter 63000, loss: 12.944041
 >> iter 64000, loss: 12.969388
 >> iter 65000, loss: 12.955414
 >> iter 66000, loss: 12.979455
 >> iter 67000, loss: 12.948898
 >> iter 68000, loss: 12.979355
 >> iter 69000, loss: 12.957358
 >> iter 70000, loss: 12.973609
   Number of active neurons: 4
 >> iter 71000, loss: 12.949365
 >> iter 72000, loss: 12.979385
 >> iter 73000, loss: 12.946456
 >> iter 74000, loss: 12.979073
 >> iter 75000, loss: 12.948167
 >> iter 76000, loss: 12.980967
 >> iter 77000, loss: 12.947376
 >> iter 78000, loss: 12.977271
 >> iter 79000, loss: 12.946394
 >> iter 80000, loss: 12.972360
   Number of active neurons: 4
 >> iter 81000, loss: 12.939931
 >> iter 82000, loss: 12.968804
 >> iter 83000, loss: 12.943319
 >> iter 84000, loss: 12.979933
 >> iter 85000, loss: 12.953929
 >> iter 86000, loss: 12.978239
 >> iter 87000, loss: 12.947580
 >> iter 88000, loss: 12.987787
 >> iter 89000, loss: 12.953934
 >> iter 90000, loss: 12.991095
   Number of active neurons: 4
 >> iter 91000, loss: 12.959304
 >> iter 92000, loss: 12.992142
 >> iter 93000, loss: 12.958208
 >> iter 94000, loss: 12.987235
 >> iter 95000, loss: 12.953708
 >> iter 96000, loss: 12.987841
 >> iter 97000, loss: 12.956892
 >> iter 98000, loss: 12.991891
 >> iter 99000, loss: 12.953094
 >> iter 100000, loss: 12.984821
   Number of active neurons: 4
 >> iter 101000, loss: 12.954033
 >> iter 102000, loss: 12.983558
 >> iter 103000, loss: 12.947161
 >> iter 104000, loss: 12.979716
 >> iter 105000, loss: 12.953253
 >> iter 106000, loss: 12.986574
 >> iter 107000, loss: 12.948104
 >> iter 108000, loss: 12.990101
 >> iter 109000, loss: 12.953111
 >> iter 110000, loss: 12.985627
   Number of active neurons: 4
 >> iter 111000, loss: 12.949232
 >> iter 112000, loss: 12.982038
 >> iter 113000, loss: 12.946902
 >> iter 114000, loss: 12.983022
 >> iter 115000, loss: 12.944628
 >> iter 116000, loss: 12.980193
 >> iter 117000, loss: 12.941394
 >> iter 118000, loss: 12.980978
 >> iter 119000, loss: 12.940915
 >> iter 120000, loss: 12.977900
   Number of active neurons: 4
 >> iter 121000, loss: 12.938903
 >> iter 122000, loss: 12.984438
 >> iter 123000, loss: 12.947779
 >> iter 124000, loss: 12.982525
 >> iter 125000, loss: 12.937114
 >> iter 126000, loss: 12.974536
 >> iter 127000, loss: 12.931898
 >> iter 128000, loss: 12.978184
 >> iter 129000, loss: 12.930080
 >> iter 130000, loss: 12.977135
   Number of active neurons: 4
 >> iter 131000, loss: 12.938349
 >> iter 132000, loss: 12.983371
 >> iter 133000, loss: 12.940449
 >> iter 134000, loss: 12.978449
 >> iter 135000, loss: 12.932329
 >> iter 136000, loss: 12.979633
 >> iter 137000, loss: 12.934011
 >> iter 138000, loss: 12.985712
 >> iter 139000, loss: 12.936298
 >> iter 140000, loss: 12.985533
   Number of active neurons: 4
 >> iter 141000, loss: 12.938873
 >> iter 142000, loss: 12.983934
 >> iter 143000, loss: 12.941068
 >> iter 144000, loss: 12.993138
 >> iter 145000, loss: 12.941575
 >> iter 146000, loss: 12.988061
 >> iter 147000, loss: 12.937487
 >> iter 148000, loss: 12.993243
 >> iter 149000, loss: 12.943769
 >> iter 150000, loss: 12.992107
   Number of active neurons: 4
 >> iter 151000, loss: 12.947244
 >> iter 152000, loss: 12.992666
 >> iter 153000, loss: 12.948557
 >> iter 154000, loss: 12.988393
 >> iter 155000, loss: 12.944440
 >> iter 156000, loss: 12.987875
 >> iter 157000, loss: 12.945758
 >> iter 158000, loss: 12.992474
 >> iter 159000, loss: 12.938630
 >> iter 160000, loss: 12.993609
   Number of active neurons: 4
 >> iter 161000, loss: 12.937990
 >> iter 162000, loss: 12.986173
 >> iter 163000, loss: 12.935647
 >> iter 164000, loss: 12.983676
 >> iter 165000, loss: 12.935128
 >> iter 166000, loss: 12.984173
 >> iter 167000, loss: 12.933466
 >> iter 168000, loss: 12.965655
 >> iter 169000, loss: 12.922525
 >> iter 170000, loss: 12.977592
   Number of active neurons: 4
 >> iter 171000, loss: 12.933020
 >> iter 172000, loss: 12.983510
 >> iter 173000, loss: 12.931426
 >> iter 174000, loss: 12.980856
 >> iter 175000, loss: 12.932177
 >> iter 176000, loss: 12.988900
 >> iter 177000, loss: 12.939587
 >> iter 178000, loss: 12.985326
 >> iter 179000, loss: 12.937885
 >> iter 180000, loss: 12.992328
   Number of active neurons: 4
 >> iter 181000, loss: 12.935652
 >> iter 182000, loss: 12.986760
 >> iter 183000, loss: 12.933422
 >> iter 184000, loss: 12.994395
 >> iter 185000, loss: 12.934660
 >> iter 186000, loss: 12.991122
 >> iter 187000, loss: 12.933107
 >> iter 188000, loss: 12.990456
 >> iter 189000, loss: 12.929381
 >> iter 190000, loss: 12.992302
   Number of active neurons: 4
 >> iter 191000, loss: 12.927971
 >> iter 192000, loss: 12.991377
 >> iter 193000, loss: 12.934046
 >> iter 194000, loss: 12.987265
 >> iter 195000, loss: 12.935355
 >> iter 196000, loss: 12.985389
 >> iter 197000, loss: 12.935242
 >> iter 198000, loss: 12.983958
 >> iter 199000, loss: 12.928949
 >> iter 200000, loss: 12.970689
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 27.7254454911
   - Test - Long: 32.7583620819
   - Test - Big: 27.9837201628
   - Test - A: 33.6777548163
   - Test - B: 33.5577628158
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.987268
 >> iter 2000, loss: 15.314126
 >> iter 3000, loss: 13.875998
 >> iter 4000, loss: 13.353949
 >> iter 5000, loss: 13.127895
 >> iter 6000, loss: 13.058277
 >> iter 7000, loss: 13.014029
 >> iter 8000, loss: 13.011929
 >> iter 9000, loss: 12.990579
 >> iter 10000, loss: 12.992482
   Number of active neurons: 4
 >> iter 11000, loss: 12.990769
 >> iter 12000, loss: 12.993279
 >> iter 13000, loss: 12.979568
 >> iter 14000, loss: 12.993895
 >> iter 15000, loss: 12.973553
 >> iter 16000, loss: 12.986221
 >> iter 17000, loss: 12.975132
 >> iter 18000, loss: 12.982133
 >> iter 19000, loss: 12.967773
 >> iter 20000, loss: 12.982512
   Number of active neurons: 4
 >> iter 21000, loss: 12.971932
 >> iter 22000, loss: 12.983181
 >> iter 23000, loss: 12.963597
 >> iter 24000, loss: 12.977421
 >> iter 25000, loss: 12.954855
 >> iter 26000, loss: 12.967817
 >> iter 27000, loss: 12.959808
 >> iter 28000, loss: 12.974268
 >> iter 29000, loss: 12.955568
 >> iter 30000, loss: 12.966323
   Number of active neurons: 4
 >> iter 31000, loss: 12.954919
 >> iter 32000, loss: 12.967507
 >> iter 33000, loss: 12.958801
 >> iter 34000, loss: 12.966854
 >> iter 35000, loss: 12.960950
 >> iter 36000, loss: 12.970159
 >> iter 37000, loss: 12.949717
 >> iter 38000, loss: 12.964799
 >> iter 39000, loss: 12.944705
 >> iter 40000, loss: 12.971831
   Number of active neurons: 4
 >> iter 41000, loss: 12.952036
 >> iter 42000, loss: 12.969830
 >> iter 43000, loss: 12.952420
 >> iter 44000, loss: 12.975151
 >> iter 45000, loss: 12.943596
 >> iter 46000, loss: 12.964713
 >> iter 47000, loss: 12.947657
 >> iter 48000, loss: 12.965742
 >> iter 49000, loss: 12.946242
 >> iter 50000, loss: 12.979439
   Number of active neurons: 4
 >> iter 51000, loss: 12.956986
 >> iter 52000, loss: 12.974100
 >> iter 53000, loss: 12.945773
 >> iter 54000, loss: 12.977978
 >> iter 55000, loss: 12.942648
 >> iter 56000, loss: 12.976267
 >> iter 57000, loss: 12.938409
 >> iter 58000, loss: 12.968167
 >> iter 59000, loss: 12.948985
 >> iter 60000, loss: 12.970191
   Number of active neurons: 4
 >> iter 61000, loss: 12.946340
 >> iter 62000, loss: 12.972503
 >> iter 63000, loss: 12.952122
 >> iter 64000, loss: 12.985315
 >> iter 65000, loss: 12.948310
 >> iter 66000, loss: 12.974609
 >> iter 67000, loss: 12.950839
 >> iter 68000, loss: 12.976723
 >> iter 69000, loss: 12.949362
 >> iter 70000, loss: 12.969313
   Number of active neurons: 4
 >> iter 71000, loss: 12.942736
 >> iter 72000, loss: 12.974827
 >> iter 73000, loss: 12.949339
 >> iter 74000, loss: 12.977079
 >> iter 75000, loss: 12.948339
 >> iter 76000, loss: 12.979549
 >> iter 77000, loss: 12.949040
 >> iter 78000, loss: 12.977310
 >> iter 79000, loss: 12.948270
 >> iter 80000, loss: 12.972158
   Number of active neurons: 4
 >> iter 81000, loss: 12.945274
 >> iter 82000, loss: 12.975407
 >> iter 83000, loss: 12.946685
 >> iter 84000, loss: 12.977176
 >> iter 85000, loss: 12.948627
 >> iter 86000, loss: 12.985647
 >> iter 87000, loss: 12.958147
 >> iter 88000, loss: 12.982458
 >> iter 89000, loss: 12.949403
 >> iter 90000, loss: 12.983528
   Number of active neurons: 4
 >> iter 91000, loss: 12.949908
 >> iter 92000, loss: 12.988704
 >> iter 93000, loss: 12.951788
 >> iter 94000, loss: 12.979191
 >> iter 95000, loss: 12.956556
 >> iter 96000, loss: 12.986504
 >> iter 97000, loss: 12.957868
 >> iter 98000, loss: 12.985546
 >> iter 99000, loss: 12.957637
 >> iter 100000, loss: 12.982430
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 27.7254454911
   - Test - Long: 32.7583620819
   - Test - Big: 27.9837201628
   - Test - A: 33.6777548163
   - Test - B: 33.5577628158
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.907160
 >> iter 2000, loss: 15.255157
 >> iter 3000, loss: 13.860449
 >> iter 4000, loss: 13.372203
 >> iter 5000, loss: 13.154731
 >> iter 6000, loss: 13.100012
 >> iter 7000, loss: 13.062915
 >> iter 8000, loss: 13.059400
 >> iter 9000, loss: 13.047461
 >> iter 10000, loss: 13.063390
   Number of active neurons: 2
 >> iter 11000, loss: 13.020188
 >> iter 12000, loss: 13.045004
 >> iter 13000, loss: 13.042544
 >> iter 14000, loss: 13.046856
 >> iter 15000, loss: 13.026973
 >> iter 16000, loss: 13.028295
 >> iter 17000, loss: 13.026274
 >> iter 18000, loss: 13.041101
 >> iter 19000, loss: 13.024334
 >> iter 20000, loss: 13.059049
   Number of active neurons: 2
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 2
 >> iter 21000, loss: 12.988187
 >> iter 22000, loss: 12.697762
 >> iter 23000, loss: 12.366037
 >> iter 24000, loss: 12.073727
 >> iter 25000, loss: 11.713827
 >> iter 26000, loss: 11.214084
 >> iter 27000, loss: 10.202885
 >> iter 28000, loss: 7.784725
 >> iter 29000, loss: 5.916093
 >> iter 30000, loss: 4.045094
   Number of active neurons: 4
 >> iter 31000, loss: 2.890747
 >> iter 32000, loss: 2.474954
 >> iter 33000, loss: 1.783254
 >> iter 34000, loss: 1.590822
 >> iter 35000, loss: 1.175921
 >> iter 36000, loss: 1.061802
 >> iter 37000, loss: 1.441548
 >> iter 38000, loss: 1.601328
 >> iter 39000, loss: 1.479201
 >> iter 40000, loss: 1.555376
   Number of active neurons: 4
 >> iter 41000, loss: 1.299937
 >> iter 42000, loss: 1.281985
 >> iter 43000, loss: 1.033204
 >> iter 44000, loss: 0.938677
 >> iter 45000, loss: 0.996562
 >> iter 46000, loss: 0.972927
 >> iter 47000, loss: 1.307464
 >> iter 48000, loss: 1.027954
 >> iter 49000, loss: 0.964754
 >> iter 50000, loss: 0.758163
   Number of active neurons: 4
 >> iter 51000, loss: 0.714484
 >> iter 52000, loss: 0.815456
 >> iter 53000, loss: 0.777785
 >> iter 54000, loss: 0.803228
 >> iter 55000, loss: 1.065106
 >> iter 56000, loss: 0.936407
 >> iter 57000, loss: 0.985749
 >> iter 58000, loss: 0.564799
 >> iter 59000, loss: 0.640113
 >> iter 60000, loss: 0.692513
   Number of active neurons: 4
 >> iter 61000, loss: 0.631857
 >> iter 62000, loss: 0.842531
 >> iter 63000, loss: 0.810645
 >> iter 64000, loss: 0.841405
 >> iter 65000, loss: 0.697484
 >> iter 66000, loss: 1.228930
 >> iter 67000, loss: 1.344415
 >> iter 68000, loss: 0.875708
 >> iter 69000, loss: 0.685791
 >> iter 70000, loss: 0.803002
   Number of active neurons: 4
 >> iter 71000, loss: 0.822263
 >> iter 72000, loss: 0.670744
 >> iter 73000, loss: 0.859306
 >> iter 74000, loss: 0.681042
 >> iter 75000, loss: 1.070559
 >> iter 76000, loss: 1.312403
 >> iter 77000, loss: 1.511661
 >> iter 78000, loss: 1.193420
 >> iter 79000, loss: 0.840017
 >> iter 80000, loss: 1.016512
   Number of active neurons: 4
 >> iter 81000, loss: 0.767733
 >> iter 82000, loss: 0.978814
 >> iter 83000, loss: 1.027823
 >> iter 84000, loss: 1.192837
 >> iter 85000, loss: 0.993839
 >> iter 86000, loss: 1.276317
 >> iter 87000, loss: 1.027283
 >> iter 88000, loss: 0.774529
 >> iter 89000, loss: 0.838811
 >> iter 90000, loss: 0.645193
   Number of active neurons: 4
 >> iter 91000, loss: 0.713146
 >> iter 92000, loss: 1.151349
 >> iter 93000, loss: 1.334391
 >> iter 94000, loss: 1.140329
 >> iter 95000, loss: 0.944020
 >> iter 96000, loss: 1.050046
 >> iter 97000, loss: 0.802868
 >> iter 98000, loss: 0.678962
 >> iter 99000, loss: 0.938141
 >> iter 100000, loss: 0.922139
   Number of active neurons: 4
 >> iter 101000, loss: 0.957578
 >> iter 102000, loss: 0.801559
 >> iter 103000, loss: 1.085737
 >> iter 104000, loss: 0.766796
 >> iter 105000, loss: 0.640436
 >> iter 106000, loss: 0.773753
 >> iter 107000, loss: 0.782896
 >> iter 108000, loss: 0.661262
 >> iter 109000, loss: 0.615118
 >> iter 110000, loss: 0.572327
   Number of active neurons: 4
 >> iter 111000, loss: 0.981658
 >> iter 112000, loss: 1.042594
 >> iter 113000, loss: 0.870990
 >> iter 114000, loss: 0.754551
 >> iter 115000, loss: 0.796300
 >> iter 116000, loss: 1.320350
 >> iter 117000, loss: 0.981363
 >> iter 118000, loss: 1.329532
 >> iter 119000, loss: 0.987802
 >> iter 120000, loss: 0.678682
   Number of active neurons: 4
 >> iter 121000, loss: 0.774188
 >> iter 122000, loss: 1.040935
 >> iter 123000, loss: 0.839233
 >> iter 124000, loss: 1.105096
 >> iter 125000, loss: 0.783046
 >> iter 126000, loss: 0.959396
 >> iter 127000, loss: 0.764889
 >> iter 128000, loss: 0.957387
 >> iter 129000, loss: 1.175304
 >> iter 130000, loss: 0.899487
   Number of active neurons: 4
 >> iter 131000, loss: 1.547837
 >> iter 132000, loss: 1.330678
 >> iter 133000, loss: 1.192882
 >> iter 134000, loss: 0.925351
 >> iter 135000, loss: 0.694743
 >> iter 136000, loss: 0.899217
 >> iter 137000, loss: 1.035546
 >> iter 138000, loss: 0.788278
 >> iter 139000, loss: 0.812365
 >> iter 140000, loss: 0.711354
   Number of active neurons: 4
 >> iter 141000, loss: 1.008299
 >> iter 142000, loss: 0.904622
 >> iter 143000, loss: 0.970990
 >> iter 144000, loss: 1.217794
 >> iter 145000, loss: 0.721447
 >> iter 146000, loss: 0.669186
 >> iter 147000, loss: 0.881822
 >> iter 148000, loss: 0.898275
 >> iter 149000, loss: 1.247104
 >> iter 150000, loss: 0.950641
   Number of active neurons: 4
 >> iter 151000, loss: 0.978296
 >> iter 152000, loss: 1.364501
 >> iter 153000, loss: 1.216375
 >> iter 154000, loss: 0.971229
 >> iter 155000, loss: 1.023950
 >> iter 156000, loss: 1.129223
 >> iter 157000, loss: 1.169389
 >> iter 158000, loss: 0.869035
 >> iter 159000, loss: 0.853096
 >> iter 160000, loss: 0.803796
   Number of active neurons: 4
 >> iter 161000, loss: 1.007197
 >> iter 162000, loss: 0.998386
 >> iter 163000, loss: 0.807951
 >> iter 164000, loss: 0.911744
 >> iter 165000, loss: 0.788660
 >> iter 166000, loss: 0.588021
 >> iter 167000, loss: 0.946667
 >> iter 168000, loss: 0.966458
 >> iter 169000, loss: 0.687978
 >> iter 170000, loss: 0.616051
   Number of active neurons: 4
 >> iter 171000, loss: 1.010736
 >> iter 172000, loss: 0.819849
 >> iter 173000, loss: 0.812120
 >> iter 174000, loss: 1.060335
 >> iter 175000, loss: 0.959501
 >> iter 176000, loss: 0.886304
 >> iter 177000, loss: 1.068648
 >> iter 178000, loss: 1.173280
 >> iter 179000, loss: 0.959378
 >> iter 180000, loss: 0.859188
   Number of active neurons: 4
 >> iter 181000, loss: 0.677736
 >> iter 182000, loss: 0.767873
 >> iter 183000, loss: 0.760661
 >> iter 184000, loss: 0.806491
 >> iter 185000, loss: 0.769755
 >> iter 186000, loss: 0.640002
 >> iter 187000, loss: 0.742809
 >> iter 188000, loss: 0.792938
 >> iter 189000, loss: 0.663825
 >> iter 190000, loss: 0.575923
   Number of active neurons: 4
 >> iter 191000, loss: 0.892844
 >> iter 192000, loss: 0.808177
 >> iter 193000, loss: 0.890909
 >> iter 194000, loss: 0.617057
 >> iter 195000, loss: 0.729412
 >> iter 196000, loss: 0.888757
 >> iter 197000, loss: 0.773275
 >> iter 198000, loss: 1.093799
 >> iter 199000, loss: 0.992636
 >> iter 200000, loss: 0.704950
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.916878
 >> iter 2000, loss: 15.257429
 >> iter 3000, loss: 13.890105
 >> iter 4000, loss: 13.379722
 >> iter 5000, loss: 13.161909
 >> iter 6000, loss: 13.105895
 >> iter 7000, loss: 13.072821
 >> iter 8000, loss: 13.075805
 >> iter 9000, loss: 13.069379
 >> iter 10000, loss: 13.064473
   Number of active neurons: 3
 >> iter 11000, loss: 13.049757
 >> iter 12000, loss: 13.059593
 >> iter 13000, loss: 13.044679
 >> iter 14000, loss: 13.072643
 >> iter 15000, loss: 13.056005
 >> iter 16000, loss: 13.061223
 >> iter 17000, loss: 13.051991
 >> iter 18000, loss: 13.031428
 >> iter 19000, loss: 12.982784
 >> iter 20000, loss: 12.994210
   Number of active neurons: 3
 >> iter 21000, loss: 12.974253
 >> iter 22000, loss: 12.986121
 >> iter 23000, loss: 12.964258
 >> iter 24000, loss: 12.979165
 >> iter 25000, loss: 12.957079
 >> iter 26000, loss: 12.979334
 >> iter 27000, loss: 12.965140
 >> iter 28000, loss: 12.978135
 >> iter 29000, loss: 12.963194
 >> iter 30000, loss: 12.983386
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 3
 >> iter 31000, loss: 12.980755
 >> iter 32000, loss: 12.990726
 >> iter 33000, loss: 12.974501
 >> iter 34000, loss: 12.982404
 >> iter 35000, loss: 12.968024
 >> iter 36000, loss: 12.967675
 >> iter 37000, loss: 12.949014
 >> iter 38000, loss: 12.973089
 >> iter 39000, loss: 12.951830
 >> iter 40000, loss: 12.970640
   Number of active neurons: 4
 >> iter 41000, loss: 12.946628
 >> iter 42000, loss: 12.967241
 >> iter 43000, loss: 12.952332
 >> iter 44000, loss: 12.976931
 >> iter 45000, loss: 12.956006
 >> iter 46000, loss: 12.974340
 >> iter 47000, loss: 12.949211
 >> iter 48000, loss: 12.981155
 >> iter 49000, loss: 12.959449
 >> iter 50000, loss: 12.988883
   Number of active neurons: 4
 >> iter 51000, loss: 12.958374
 >> iter 52000, loss: 12.975161
 >> iter 53000, loss: 12.948820
 >> iter 54000, loss: 12.973921
 >> iter 55000, loss: 12.949608
 >> iter 56000, loss: 12.977677
 >> iter 57000, loss: 12.952017
 >> iter 58000, loss: 12.980674
 >> iter 59000, loss: 12.943050
 >> iter 60000, loss: 12.970463
   Number of active neurons: 4
 >> iter 61000, loss: 12.943482
 >> iter 62000, loss: 12.974933
 >> iter 63000, loss: 12.951220
 >> iter 64000, loss: 12.980118
 >> iter 65000, loss: 12.951902
 >> iter 66000, loss: 12.984526
 >> iter 67000, loss: 12.951706
 >> iter 68000, loss: 12.982438
 >> iter 69000, loss: 12.960006
 >> iter 70000, loss: 12.974495
   Number of active neurons: 4
 >> iter 71000, loss: 12.945544
 >> iter 72000, loss: 12.983027
 >> iter 73000, loss: 12.956414
 >> iter 74000, loss: 12.987559
 >> iter 75000, loss: 12.949801
 >> iter 76000, loss: 12.978373
 >> iter 77000, loss: 12.955012
 >> iter 78000, loss: 12.977264
 >> iter 79000, loss: 12.947912
 >> iter 80000, loss: 12.974058
   Number of active neurons: 4
 >> iter 81000, loss: 12.947578
 >> iter 82000, loss: 12.982176
 >> iter 83000, loss: 12.954187
 >> iter 84000, loss: 12.988108
 >> iter 85000, loss: 12.950602
 >> iter 86000, loss: 12.986413
 >> iter 87000, loss: 12.952438
 >> iter 88000, loss: 12.978563
 >> iter 89000, loss: 12.952585
 >> iter 90000, loss: 12.988612
   Number of active neurons: 4
 >> iter 91000, loss: 12.955514
 >> iter 92000, loss: 12.985634
 >> iter 93000, loss: 12.950880
 >> iter 94000, loss: 12.988368
 >> iter 95000, loss: 12.958818
 >> iter 96000, loss: 12.984112
 >> iter 97000, loss: 12.954345
 >> iter 98000, loss: 12.994996
 >> iter 99000, loss: 12.961686
 >> iter 100000, loss: 12.990481
   Number of active neurons: 4
 >> iter 101000, loss: 12.952949
 >> iter 102000, loss: 12.988818
 >> iter 103000, loss: 12.952037
 >> iter 104000, loss: 12.989652
 >> iter 105000, loss: 12.953063
 >> iter 106000, loss: 12.983127
 >> iter 107000, loss: 12.948240
 >> iter 108000, loss: 12.988392
 >> iter 109000, loss: 12.952266
 >> iter 110000, loss: 12.988847
   Number of active neurons: 4
 >> iter 111000, loss: 12.954188
 >> iter 112000, loss: 12.981926
 >> iter 113000, loss: 12.946070
 >> iter 114000, loss: 12.986748
 >> iter 115000, loss: 12.947250
 >> iter 116000, loss: 12.977716
 >> iter 117000, loss: 12.934152
 >> iter 118000, loss: 12.973921
 >> iter 119000, loss: 12.938428
 >> iter 120000, loss: 12.979332
   Number of active neurons: 4
 >> iter 121000, loss: 12.931841
 >> iter 122000, loss: 12.977982
 >> iter 123000, loss: 12.936876
 >> iter 124000, loss: 12.983127
 >> iter 125000, loss: 12.935141
 >> iter 126000, loss: 12.985968
 >> iter 127000, loss: 12.939516
 >> iter 128000, loss: 12.976996
 >> iter 129000, loss: 12.936488
 >> iter 130000, loss: 12.973521
   Number of active neurons: 4
 >> iter 131000, loss: 12.929033
 >> iter 132000, loss: 12.971577
 >> iter 133000, loss: 12.932102
 >> iter 134000, loss: 12.983263
 >> iter 135000, loss: 12.932963
 >> iter 136000, loss: 12.987807
 >> iter 137000, loss: 12.936662
 >> iter 138000, loss: 12.984241
 >> iter 139000, loss: 12.938970
 >> iter 140000, loss: 12.987757
   Number of active neurons: 4
 >> iter 141000, loss: 12.939878
 >> iter 142000, loss: 12.985543
 >> iter 143000, loss: 12.934048
 >> iter 144000, loss: 12.985837
 >> iter 145000, loss: 12.936647
 >> iter 146000, loss: 12.992480
 >> iter 147000, loss: 12.937697
 >> iter 148000, loss: 12.991708
 >> iter 149000, loss: 12.937258
 >> iter 150000, loss: 12.983019
   Number of active neurons: 4
 >> iter 151000, loss: 12.934433
 >> iter 152000, loss: 12.991125
 >> iter 153000, loss: 12.943435
 >> iter 154000, loss: 12.992389
 >> iter 155000, loss: 12.946152
 >> iter 156000, loss: 12.983628
 >> iter 157000, loss: 12.939840
 >> iter 158000, loss: 12.985507
 >> iter 159000, loss: 12.939914
 >> iter 160000, loss: 12.993962
   Number of active neurons: 4
 >> iter 161000, loss: 12.934219
 >> iter 162000, loss: 12.990235
 >> iter 163000, loss: 12.934638
 >> iter 164000, loss: 12.989499
 >> iter 165000, loss: 12.931632
 >> iter 166000, loss: 12.986208
 >> iter 167000, loss: 12.934365
 >> iter 168000, loss: 12.978914
 >> iter 169000, loss: 12.936785
 >> iter 170000, loss: 12.978632
   Number of active neurons: 4
 >> iter 171000, loss: 12.930546
 >> iter 172000, loss: 12.986211
 >> iter 173000, loss: 12.938545
 >> iter 174000, loss: 12.981381
 >> iter 175000, loss: 12.934398
 >> iter 176000, loss: 12.981907
 >> iter 177000, loss: 12.928413
 >> iter 178000, loss: 12.981310
 >> iter 179000, loss: 12.932807
 >> iter 180000, loss: 12.987378
   Number of active neurons: 4
 >> iter 181000, loss: 12.934394
 >> iter 182000, loss: 12.986048
 >> iter 183000, loss: 12.932735
 >> iter 184000, loss: 12.989864
 >> iter 185000, loss: 12.932789
 >> iter 186000, loss: 12.981030
 >> iter 187000, loss: 12.926973
 >> iter 188000, loss: 12.984346
 >> iter 189000, loss: 12.925971
 >> iter 190000, loss: 12.980376
   Number of active neurons: 4
 >> iter 191000, loss: 12.921511
 >> iter 192000, loss: 12.974880
 >> iter 193000, loss: 12.933808
 >> iter 194000, loss: 12.978442
 >> iter 195000, loss: 12.930692
 >> iter 196000, loss: 12.983010
 >> iter 197000, loss: 12.934275
 >> iter 198000, loss: 12.988343
 >> iter 199000, loss: 12.928121
 >> iter 200000, loss: 12.980231
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 27.7494450111
   - Test - Long: 32.7683615819
   - Test - Big: 28.0257197428
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.884834
 >> iter 2000, loss: 15.231794
 >> iter 3000, loss: 13.854657
 >> iter 4000, loss: 13.345821
 >> iter 5000, loss: 13.154088
 >> iter 6000, loss: 13.089009
 >> iter 7000, loss: 13.049769
 >> iter 8000, loss: 13.050011
 >> iter 9000, loss: 13.037520
 >> iter 10000, loss: 13.046947
   Number of active neurons: 2
 >> iter 11000, loss: 13.039381
 >> iter 12000, loss: 13.044232
 >> iter 13000, loss: 13.029928
 >> iter 14000, loss: 13.043453
 >> iter 15000, loss: 13.024288
 >> iter 16000, loss: 13.051617
 >> iter 17000, loss: 13.031379
 >> iter 18000, loss: 13.058937
 >> iter 19000, loss: 13.031204
 >> iter 20000, loss: 13.048570
   Number of active neurons: 2
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 2
 >> iter 21000, loss: 13.038551
 >> iter 22000, loss: 13.011181
 >> iter 23000, loss: 12.974479
 >> iter 24000, loss: 12.983857
 >> iter 25000, loss: 12.966192
 >> iter 26000, loss: 12.977509
 >> iter 27000, loss: 12.968356
 >> iter 28000, loss: 12.983707
 >> iter 29000, loss: 12.974604
 >> iter 30000, loss: 12.984487
   Number of active neurons: 4
 >> iter 31000, loss: 12.973415
 >> iter 32000, loss: 12.987063
 >> iter 33000, loss: 12.966469
 >> iter 34000, loss: 12.985814
 >> iter 35000, loss: 12.958328
 >> iter 36000, loss: 12.969538
 >> iter 37000, loss: 12.949945
 >> iter 38000, loss: 12.970412
 >> iter 39000, loss: 12.952600
 >> iter 40000, loss: 12.975961
   Number of active neurons: 4
 >> iter 41000, loss: 12.953170
 >> iter 42000, loss: 12.967466
 >> iter 43000, loss: 12.951076
 >> iter 44000, loss: 12.969800
 >> iter 45000, loss: 12.949152
 >> iter 46000, loss: 12.971448
 >> iter 47000, loss: 12.942456
 >> iter 48000, loss: 12.976585
 >> iter 49000, loss: 12.952297
 >> iter 50000, loss: 12.973918
   Number of active neurons: 4
 >> iter 51000, loss: 12.947264
 >> iter 52000, loss: 12.978129
 >> iter 53000, loss: 12.943264
 >> iter 54000, loss: 12.969370
 >> iter 55000, loss: 12.940329
 >> iter 56000, loss: 12.971978
 >> iter 57000, loss: 12.951300
 >> iter 58000, loss: 12.979681
 >> iter 59000, loss: 12.949151
 >> iter 60000, loss: 12.970648
   Number of active neurons: 4
 >> iter 61000, loss: 12.945379
 >> iter 62000, loss: 12.973061
 >> iter 63000, loss: 12.947173
 >> iter 64000, loss: 12.973828
 >> iter 65000, loss: 12.949419
 >> iter 66000, loss: 12.982393
 >> iter 67000, loss: 12.950615
 >> iter 68000, loss: 12.973097
 >> iter 69000, loss: 12.950024
 >> iter 70000, loss: 12.972965
   Number of active neurons: 4
 >> iter 71000, loss: 12.947783
 >> iter 72000, loss: 12.981743
 >> iter 73000, loss: 12.950505
 >> iter 74000, loss: 12.977392
 >> iter 75000, loss: 12.950769
 >> iter 76000, loss: 12.972061
 >> iter 77000, loss: 12.949057
 >> iter 78000, loss: 12.976564
 >> iter 79000, loss: 12.949563
 >> iter 80000, loss: 12.975090
   Number of active neurons: 4
 >> iter 81000, loss: 12.954804
 >> iter 82000, loss: 12.979691
 >> iter 83000, loss: 12.947266
 >> iter 84000, loss: 12.978637
 >> iter 85000, loss: 12.955283
 >> iter 86000, loss: 12.985000
 >> iter 87000, loss: 12.956900
 >> iter 88000, loss: 12.986001
 >> iter 89000, loss: 12.951854
 >> iter 90000, loss: 12.984382
   Number of active neurons: 4
 >> iter 91000, loss: 12.952631
 >> iter 92000, loss: 12.988039
 >> iter 93000, loss: 12.953141
 >> iter 94000, loss: 12.982496
 >> iter 95000, loss: 12.950680
 >> iter 96000, loss: 12.974313
 >> iter 97000, loss: 12.952661
 >> iter 98000, loss: 12.990048
 >> iter 99000, loss: 12.960369
 >> iter 100000, loss: 12.982862
   Number of active neurons: 4
 >> iter 101000, loss: 12.951132
 >> iter 102000, loss: 12.982489
 >> iter 103000, loss: 12.954583
 >> iter 104000, loss: 12.981121
 >> iter 105000, loss: 12.941047
 >> iter 106000, loss: 12.977127
 >> iter 107000, loss: 12.945068
 >> iter 108000, loss: 12.974739
 >> iter 109000, loss: 12.945756
 >> iter 110000, loss: 12.981762
   Number of active neurons: 4
 >> iter 111000, loss: 12.943943
 >> iter 112000, loss: 12.985751
 >> iter 113000, loss: 12.945634
 >> iter 114000, loss: 12.974866
 >> iter 115000, loss: 12.941618
 >> iter 116000, loss: 12.988729
 >> iter 117000, loss: 12.949127
 >> iter 118000, loss: 12.976672
 >> iter 119000, loss: 12.937790
 >> iter 120000, loss: 12.976479
   Number of active neurons: 4
 >> iter 121000, loss: 12.940221
 >> iter 122000, loss: 12.974366
 >> iter 123000, loss: 12.933114
 >> iter 124000, loss: 12.982327
 >> iter 125000, loss: 12.934432
 >> iter 126000, loss: 12.980745
 >> iter 127000, loss: 12.939367
 >> iter 128000, loss: 12.984428
 >> iter 129000, loss: 12.935660
 >> iter 130000, loss: 12.980596
   Number of active neurons: 4
 >> iter 131000, loss: 12.935658
 >> iter 132000, loss: 12.977350
 >> iter 133000, loss: 12.933331
 >> iter 134000, loss: 12.978715
 >> iter 135000, loss: 12.930568
 >> iter 136000, loss: 12.984935
 >> iter 137000, loss: 12.932790
 >> iter 138000, loss: 12.980434
 >> iter 139000, loss: 12.926735
 >> iter 140000, loss: 12.986213
   Number of active neurons: 4
 >> iter 141000, loss: 12.941046
 >> iter 142000, loss: 12.985576
 >> iter 143000, loss: 12.937613
 >> iter 144000, loss: 12.987463
 >> iter 145000, loss: 12.931278
 >> iter 146000, loss: 12.982023
 >> iter 147000, loss: 12.939671
 >> iter 148000, loss: 12.993197
 >> iter 149000, loss: 12.938148
 >> iter 150000, loss: 12.984967
   Number of active neurons: 4
 >> iter 151000, loss: 12.936540
 >> iter 152000, loss: 12.988028
 >> iter 153000, loss: 12.941181
 >> iter 154000, loss: 12.988697
 >> iter 155000, loss: 12.942233
 >> iter 156000, loss: 12.994154
 >> iter 157000, loss: 12.941193
 >> iter 158000, loss: 12.992352
 >> iter 159000, loss: 12.938372
 >> iter 160000, loss: 12.996189
   Number of active neurons: 4
 >> iter 161000, loss: 12.930229
 >> iter 162000, loss: 12.989539
 >> iter 163000, loss: 12.932398
 >> iter 164000, loss: 12.981356
 >> iter 165000, loss: 12.933284
 >> iter 166000, loss: 12.980194
 >> iter 167000, loss: 12.926848
 >> iter 168000, loss: 12.981327
 >> iter 169000, loss: 12.933540
 >> iter 170000, loss: 12.979158
   Number of active neurons: 4
 >> iter 171000, loss: 12.930177
 >> iter 172000, loss: 12.978307
 >> iter 173000, loss: 12.928064
 >> iter 174000, loss: 12.975029
 >> iter 175000, loss: 12.935170
 >> iter 176000, loss: 12.990150
 >> iter 177000, loss: 12.931282
 >> iter 178000, loss: 12.990221
 >> iter 179000, loss: 12.937085
 >> iter 180000, loss: 12.986876
   Number of active neurons: 4
 >> iter 181000, loss: 12.930578
 >> iter 182000, loss: 12.990936
 >> iter 183000, loss: 12.934992
 >> iter 184000, loss: 12.989416
 >> iter 185000, loss: 12.928559
 >> iter 186000, loss: 12.988737
 >> iter 187000, loss: 12.926464
 >> iter 188000, loss: 12.989623
 >> iter 189000, loss: 12.924497
 >> iter 190000, loss: 12.983047
   Number of active neurons: 4
 >> iter 191000, loss: 12.920050
 >> iter 192000, loss: 12.983624
 >> iter 193000, loss: 12.928327
 >> iter 194000, loss: 12.982918
 >> iter 195000, loss: 12.934747
 >> iter 196000, loss: 12.982611
 >> iter 197000, loss: 12.929978
 >> iter 198000, loss: 12.983834
 >> iter 199000, loss: 12.928734
 >> iter 200000, loss: 12.985668
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 27.7494450111
   - Test - Long: 32.7683615819
   - Test - Big: 28.0257197428
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.878601
 >> iter 2000, loss: 15.225629
 >> iter 3000, loss: 13.862720
 >> iter 4000, loss: 13.362436
 >> iter 5000, loss: 13.153174
 >> iter 6000, loss: 13.100362
 >> iter 7000, loss: 13.059437
 >> iter 8000, loss: 13.040916
 >> iter 9000, loss: 13.029438
 >> iter 10000, loss: 13.051156
   Number of active neurons: 2
 >> iter 11000, loss: 13.038696
 >> iter 12000, loss: 13.021228
 >> iter 13000, loss: 13.031063
 >> iter 14000, loss: 13.053534
 >> iter 15000, loss: 13.035976
 >> iter 16000, loss: 13.041580
 >> iter 17000, loss: 13.031125
 >> iter 18000, loss: 13.061483
 >> iter 19000, loss: 13.044239
 >> iter 20000, loss: 13.059162
   Number of active neurons: 2
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 2
 >> iter 21000, loss: 13.072310
 >> iter 22000, loss: 13.037158
 >> iter 23000, loss: 12.976867
 >> iter 24000, loss: 12.972801
 >> iter 25000, loss: 12.952340
 >> iter 26000, loss: 12.961575
 >> iter 27000, loss: 12.949481
 >> iter 28000, loss: 12.962955
 >> iter 29000, loss: 12.949796
 >> iter 30000, loss: 12.971627
   Number of active neurons: 4
 >> iter 31000, loss: 12.956581
 >> iter 32000, loss: 12.977675
 >> iter 33000, loss: 12.958561
 >> iter 34000, loss: 12.969523
 >> iter 35000, loss: 12.958818
 >> iter 36000, loss: 12.967102
 >> iter 37000, loss: 12.955810
 >> iter 38000, loss: 12.960224
 >> iter 39000, loss: 12.946894
 >> iter 40000, loss: 12.970440
   Number of active neurons: 4
 >> iter 41000, loss: 12.954789
 >> iter 42000, loss: 12.965943
 >> iter 43000, loss: 12.953885
 >> iter 44000, loss: 12.972728
 >> iter 45000, loss: 12.949890
 >> iter 46000, loss: 12.976116
 >> iter 47000, loss: 12.955019
 >> iter 48000, loss: 12.972236
 >> iter 49000, loss: 12.948490
 >> iter 50000, loss: 12.978886
   Number of active neurons: 4
 >> iter 51000, loss: 12.949688
 >> iter 52000, loss: 12.978606
 >> iter 53000, loss: 12.945774
 >> iter 54000, loss: 12.981680
 >> iter 55000, loss: 12.942705
 >> iter 56000, loss: 12.975215
 >> iter 57000, loss: 12.946818
 >> iter 58000, loss: 12.974362
 >> iter 59000, loss: 12.952281
 >> iter 60000, loss: 12.977215
   Number of active neurons: 4
 >> iter 61000, loss: 12.947809
 >> iter 62000, loss: 12.977579
 >> iter 63000, loss: 12.952912
 >> iter 64000, loss: 12.979401
 >> iter 65000, loss: 12.943127
 >> iter 66000, loss: 12.976610
 >> iter 67000, loss: 12.952644
 >> iter 68000, loss: 12.976568
 >> iter 69000, loss: 12.956997
 >> iter 70000, loss: 12.982092
   Number of active neurons: 4
 >> iter 71000, loss: 12.953981
 >> iter 72000, loss: 12.977503
 >> iter 73000, loss: 12.947252
 >> iter 74000, loss: 12.983052
 >> iter 75000, loss: 12.951301
 >> iter 76000, loss: 12.976302
 >> iter 77000, loss: 12.953220
 >> iter 78000, loss: 12.983903
 >> iter 79000, loss: 12.948734
 >> iter 80000, loss: 12.977367
   Number of active neurons: 4
 >> iter 81000, loss: 12.949470
 >> iter 82000, loss: 12.976763
 >> iter 83000, loss: 12.944521
 >> iter 84000, loss: 12.983495
 >> iter 85000, loss: 12.954081
 >> iter 86000, loss: 12.982767
 >> iter 87000, loss: 12.947158
 >> iter 88000, loss: 12.981513
 >> iter 89000, loss: 12.956374
 >> iter 90000, loss: 12.989506
   Number of active neurons: 4
 >> iter 91000, loss: 12.948236
 >> iter 92000, loss: 12.981707
 >> iter 93000, loss: 12.952940
 >> iter 94000, loss: 12.985370
 >> iter 95000, loss: 12.956297
 >> iter 96000, loss: 12.984521
 >> iter 97000, loss: 12.951151
 >> iter 98000, loss: 12.976686
 >> iter 99000, loss: 12.953841
 >> iter 100000, loss: 12.980083
   Number of active neurons: 4
 >> iter 101000, loss: 12.950461
 >> iter 102000, loss: 12.974336
 >> iter 103000, loss: 12.950280
 >> iter 104000, loss: 12.981546
 >> iter 105000, loss: 12.946887
 >> iter 106000, loss: 12.981468
 >> iter 107000, loss: 12.953183
 >> iter 108000, loss: 12.987826
 >> iter 109000, loss: 12.951437
 >> iter 110000, loss: 12.984162
   Number of active neurons: 4
 >> iter 111000, loss: 12.952577
 >> iter 112000, loss: 12.984577
 >> iter 113000, loss: 12.954208
 >> iter 114000, loss: 12.975942
 >> iter 115000, loss: 12.938327
 >> iter 116000, loss: 12.976301
 >> iter 117000, loss: 12.936228
 >> iter 118000, loss: 12.979410
 >> iter 119000, loss: 12.939892
 >> iter 120000, loss: 12.975128
   Number of active neurons: 4
 >> iter 121000, loss: 12.934856
 >> iter 122000, loss: 12.977768
 >> iter 123000, loss: 12.933495
 >> iter 124000, loss: 12.978177
 >> iter 125000, loss: 12.935235
 >> iter 126000, loss: 12.980743
 >> iter 127000, loss: 12.941679
 >> iter 128000, loss: 12.978498
 >> iter 129000, loss: 12.933227
 >> iter 130000, loss: 12.971345
   Number of active neurons: 4
 >> iter 131000, loss: 12.935945
 >> iter 132000, loss: 12.979336
 >> iter 133000, loss: 12.938406
 >> iter 134000, loss: 12.975968
 >> iter 135000, loss: 12.935038
 >> iter 136000, loss: 12.981897
 >> iter 137000, loss: 12.934896
 >> iter 138000, loss: 12.990851
 >> iter 139000, loss: 12.942249
 >> iter 140000, loss: 12.988877
   Number of active neurons: 4
 >> iter 141000, loss: 12.935530
 >> iter 142000, loss: 12.987722
 >> iter 143000, loss: 12.933213
 >> iter 144000, loss: 12.990609
 >> iter 145000, loss: 12.935870
 >> iter 146000, loss: 12.991937
 >> iter 147000, loss: 12.940307
 >> iter 148000, loss: 12.985829
 >> iter 149000, loss: 12.942246
 >> iter 150000, loss: 12.989148
   Number of active neurons: 4
 >> iter 151000, loss: 12.939722
 >> iter 152000, loss: 12.979801
 >> iter 153000, loss: 12.935611
 >> iter 154000, loss: 12.986340
 >> iter 155000, loss: 12.938352
 >> iter 156000, loss: 12.992149
 >> iter 157000, loss: 12.944237
 >> iter 158000, loss: 12.999380
 >> iter 159000, loss: 12.936574
 >> iter 160000, loss: 12.992231
   Number of active neurons: 4
 >> iter 161000, loss: 12.933594
 >> iter 162000, loss: 12.994545
 >> iter 163000, loss: 12.937717
 >> iter 164000, loss: 12.978775
 >> iter 165000, loss: 12.930390
 >> iter 166000, loss: 12.978253
 >> iter 167000, loss: 12.930212
 >> iter 168000, loss: 12.979027
 >> iter 169000, loss: 12.934008
 >> iter 170000, loss: 12.985920
   Number of active neurons: 4
 >> iter 171000, loss: 12.934948
 >> iter 172000, loss: 12.980252
 >> iter 173000, loss: 12.933255
 >> iter 174000, loss: 12.980243
 >> iter 175000, loss: 12.931838
 >> iter 176000, loss: 12.982411
 >> iter 177000, loss: 12.935985
 >> iter 178000, loss: 12.987150
 >> iter 179000, loss: 12.932050
 >> iter 180000, loss: 12.982715
   Number of active neurons: 4
 >> iter 181000, loss: 12.931262
 >> iter 182000, loss: 12.986355
 >> iter 183000, loss: 12.930407
 >> iter 184000, loss: 12.981170
 >> iter 185000, loss: 12.930380
 >> iter 186000, loss: 12.990507
 >> iter 187000, loss: 12.924760
 >> iter 188000, loss: 12.982004
 >> iter 189000, loss: 12.925624
 >> iter 190000, loss: 12.990166
   Number of active neurons: 4
 >> iter 191000, loss: 12.920565
 >> iter 192000, loss: 12.978974
 >> iter 193000, loss: 12.932582
 >> iter 194000, loss: 12.978455
 >> iter 195000, loss: 12.920636
 >> iter 196000, loss: 12.979373
 >> iter 197000, loss: 12.931340
 >> iter 198000, loss: 12.972635
 >> iter 199000, loss: 12.924938
 >> iter 200000, loss: 12.977915
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 27.7254454911
   - Test - Long: 32.7583620819
   - Test - Big: 27.9837201628
   - Test - A: 33.6777548163
   - Test - B: 33.5577628158
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.971160
 >> iter 2000, loss: 15.274550
 >> iter 3000, loss: 13.877999
 >> iter 4000, loss: 13.350290
 >> iter 5000, loss: 13.140232
 >> iter 6000, loss: 13.094533
 >> iter 7000, loss: 13.052350
 >> iter 8000, loss: 13.054686
 >> iter 9000, loss: 13.027406
 >> iter 10000, loss: 13.040794
   Number of active neurons: 2
 >> iter 11000, loss: 13.034570
 >> iter 12000, loss: 13.045577
 >> iter 13000, loss: 13.029169
 >> iter 14000, loss: 13.060681
 >> iter 15000, loss: 13.036647
 >> iter 16000, loss: 13.051915
 >> iter 17000, loss: 13.034819
 >> iter 18000, loss: 13.037268
 >> iter 19000, loss: 13.026482
 >> iter 20000, loss: 13.046512
   Number of active neurons: 2
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 2
 >> iter 21000, loss: 13.063731
 >> iter 22000, loss: 13.028933
 >> iter 23000, loss: 12.816119
 >> iter 24000, loss: 12.615243
 >> iter 25000, loss: 12.335509
 >> iter 26000, loss: 12.011181
 >> iter 27000, loss: 11.410633
 >> iter 28000, loss: 11.142052
 >> iter 29000, loss: 10.878192
 >> iter 30000, loss: 10.771887
   Number of active neurons: 4
 >> iter 31000, loss: 10.598240
 >> iter 32000, loss: 10.597488
 >> iter 33000, loss: 10.429745
 >> iter 34000, loss: 10.527191
 >> iter 35000, loss: 10.375256
 >> iter 36000, loss: 10.433565
 >> iter 37000, loss: 10.309292
 >> iter 38000, loss: 10.395259
 >> iter 39000, loss: 10.279093
 >> iter 40000, loss: 10.361782
   Number of active neurons: 4
 >> iter 41000, loss: 10.251442
 >> iter 42000, loss: 10.332988
 >> iter 43000, loss: 10.270265
 >> iter 44000, loss: 10.333330
 >> iter 45000, loss: 10.260007
 >> iter 46000, loss: 10.350377
 >> iter 47000, loss: 10.231332
 >> iter 48000, loss: 10.335837
 >> iter 49000, loss: 10.278774
 >> iter 50000, loss: 10.330553
   Number of active neurons: 4
 >> iter 51000, loss: 10.215788
 >> iter 52000, loss: 10.339428
 >> iter 53000, loss: 10.191664
 >> iter 54000, loss: 10.323774
 >> iter 55000, loss: 10.178692
 >> iter 56000, loss: 10.307697
 >> iter 57000, loss: 10.192565
 >> iter 58000, loss: 10.303605
 >> iter 59000, loss: 10.185050
 >> iter 60000, loss: 10.332070
   Number of active neurons: 4
 >> iter 61000, loss: 10.157889
 >> iter 62000, loss: 10.305205
 >> iter 63000, loss: 10.179370
 >> iter 64000, loss: 10.294118
 >> iter 65000, loss: 10.203518
 >> iter 66000, loss: 10.332861
 >> iter 67000, loss: 10.224301
 >> iter 68000, loss: 10.337324
 >> iter 69000, loss: 10.184227
 >> iter 70000, loss: 10.333851
   Number of active neurons: 4
 >> iter 71000, loss: 10.198061
 >> iter 72000, loss: 10.325341
 >> iter 73000, loss: 10.155356
 >> iter 74000, loss: 10.273234
 >> iter 75000, loss: 10.139033
 >> iter 76000, loss: 10.330360
 >> iter 77000, loss: 10.166966
 >> iter 78000, loss: 10.283253
 >> iter 79000, loss: 10.163298
 >> iter 80000, loss: 10.285327
   Number of active neurons: 4
 >> iter 81000, loss: 10.171505
 >> iter 82000, loss: 10.335689
 >> iter 83000, loss: 10.166101
 >> iter 84000, loss: 10.315375
 >> iter 85000, loss: 10.192212
 >> iter 86000, loss: 10.300850
 >> iter 87000, loss: 10.216074
 >> iter 88000, loss: 10.323376
 >> iter 89000, loss: 10.210572
 >> iter 90000, loss: 10.289874
   Number of active neurons: 4
 >> iter 91000, loss: 10.144042
 >> iter 92000, loss: 10.271460
 >> iter 93000, loss: 10.195281
 >> iter 94000, loss: 10.331292
 >> iter 95000, loss: 10.185539
 >> iter 96000, loss: 10.293993
 >> iter 97000, loss: 10.202813
 >> iter 98000, loss: 10.293318
 >> iter 99000, loss: 10.191026
 >> iter 100000, loss: 10.288884
   Number of active neurons: 4
 >> iter 101000, loss: 10.177105
 >> iter 102000, loss: 10.314185
 >> iter 103000, loss: 10.164907
 >> iter 104000, loss: 10.275646
 >> iter 105000, loss: 10.166329
 >> iter 106000, loss: 10.303707
 >> iter 107000, loss: 10.164647
 >> iter 108000, loss: 10.303529
 >> iter 109000, loss: 10.160680
 >> iter 110000, loss: 10.322456
   Number of active neurons: 4
 >> iter 111000, loss: 10.207955
 >> iter 112000, loss: 10.322091
 >> iter 113000, loss: 10.193149
 >> iter 114000, loss: 10.326537
 >> iter 115000, loss: 10.164325
 >> iter 116000, loss: 10.298917
 >> iter 117000, loss: 10.199814
 >> iter 118000, loss: 10.328264
 >> iter 119000, loss: 10.158570
 >> iter 120000, loss: 10.311029
   Number of active neurons: 4
 >> iter 121000, loss: 10.115247
 >> iter 122000, loss: 10.273234
 >> iter 123000, loss: 10.139262
 >> iter 124000, loss: 10.312630
 >> iter 125000, loss: 10.198111
 >> iter 126000, loss: 10.336003
 >> iter 127000, loss: 10.186440
 >> iter 128000, loss: 10.301405
 >> iter 129000, loss: 10.117101
 >> iter 130000, loss: 10.307102
   Number of active neurons: 4
 >> iter 131000, loss: 10.143098
 >> iter 132000, loss: 10.253489
 >> iter 133000, loss: 10.132412
 >> iter 134000, loss: 10.307394
 >> iter 135000, loss: 10.131318
 >> iter 136000, loss: 10.343959
 >> iter 137000, loss: 10.206283
 >> iter 138000, loss: 10.328398
 >> iter 139000, loss: 10.141231
 >> iter 140000, loss: 10.310143
   Number of active neurons: 4
 >> iter 141000, loss: 10.141956
 >> iter 142000, loss: 10.312257
 >> iter 143000, loss: 10.154982
 >> iter 144000, loss: 10.308758
 >> iter 145000, loss: 10.128709
 >> iter 146000, loss: 10.306718
 >> iter 147000, loss: 10.175008
 >> iter 148000, loss: 10.301046
 >> iter 149000, loss: 10.139299
 >> iter 150000, loss: 10.292495
   Number of active neurons: 4
 >> iter 151000, loss: 10.122918
 >> iter 152000, loss: 10.313582
 >> iter 153000, loss: 10.160564
 >> iter 154000, loss: 10.327139
 >> iter 155000, loss: 10.161003
 >> iter 156000, loss: 10.278584
 >> iter 157000, loss: 10.144281
 >> iter 158000, loss: 10.290568
 >> iter 159000, loss: 10.193507
 >> iter 160000, loss: 10.309329
   Number of active neurons: 4
 >> iter 161000, loss: 10.099571
 >> iter 162000, loss: 10.289859
 >> iter 163000, loss: 10.134671
 >> iter 164000, loss: 10.291532
 >> iter 165000, loss: 10.154189
 >> iter 166000, loss: 10.326019
 >> iter 167000, loss: 10.178585
 >> iter 168000, loss: 10.291965
 >> iter 169000, loss: 10.192257
 >> iter 170000, loss: 10.293904
   Number of active neurons: 4
 >> iter 171000, loss: 10.101368
 >> iter 172000, loss: 10.252615
 >> iter 173000, loss: 10.123322
 >> iter 174000, loss: 10.287448
 >> iter 175000, loss: 10.147412
 >> iter 176000, loss: 10.280121
 >> iter 177000, loss: 10.131187
 >> iter 178000, loss: 10.278569
 >> iter 179000, loss: 10.147097
 >> iter 180000, loss: 10.262707
   Number of active neurons: 4
 >> iter 181000, loss: 10.137381
 >> iter 182000, loss: 10.321046
 >> iter 183000, loss: 10.167216
 >> iter 184000, loss: 10.316482
 >> iter 185000, loss: 10.132417
 >> iter 186000, loss: 10.299285
 >> iter 187000, loss: 10.135023
 >> iter 188000, loss: 10.325416
 >> iter 189000, loss: 10.110923
 >> iter 190000, loss: 10.287442
   Number of active neurons: 4
 >> iter 191000, loss: 10.099419
 >> iter 192000, loss: 10.255940
 >> iter 193000, loss: 10.110341
 >> iter 194000, loss: 10.297393
 >> iter 195000, loss: 10.141436
 >> iter 196000, loss: 10.288837
 >> iter 197000, loss: 10.150519
 >> iter 198000, loss: 10.294086
 >> iter 199000, loss: 10.137318
 >> iter 200000, loss: 10.304995
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 20.7035859283
   - Test - Long: 31.8634068297
   - Test - Big: 20.8577914221
   - Test - A: 31.417905473
   - Test - B: 32.5911605893
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.946089
 >> iter 2000, loss: 15.254781
 >> iter 3000, loss: 13.876390
 >> iter 4000, loss: 13.363514
 >> iter 5000, loss: 13.143653
 >> iter 6000, loss: 13.073968
 >> iter 7000, loss: 13.025942
 >> iter 8000, loss: 13.019196
 >> iter 9000, loss: 12.990704
 >> iter 10000, loss: 12.995654
   Number of active neurons: 3
 >> iter 11000, loss: 12.973953
 >> iter 12000, loss: 12.982011
 >> iter 13000, loss: 12.963127
 >> iter 14000, loss: 12.973556
 >> iter 15000, loss: 12.961063
 >> iter 16000, loss: 12.975453
 >> iter 17000, loss: 12.960461
 >> iter 18000, loss: 12.969206
 >> iter 19000, loss: 12.961616
 >> iter 20000, loss: 12.979059
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 3
 >> iter 21000, loss: 13.012311
 >> iter 22000, loss: 13.004725
 >> iter 23000, loss: 12.981112
 >> iter 24000, loss: 12.984985
 >> iter 25000, loss: 12.974080
 >> iter 26000, loss: 12.990266
 >> iter 27000, loss: 12.964931
 >> iter 28000, loss: 12.976677
 >> iter 29000, loss: 12.957681
 >> iter 30000, loss: 12.965500
   Number of active neurons: 4
 >> iter 31000, loss: 12.950780
 >> iter 32000, loss: 12.968867
 >> iter 33000, loss: 12.951295
 >> iter 34000, loss: 12.971909
 >> iter 35000, loss: 12.956256
 >> iter 36000, loss: 12.968979
 >> iter 37000, loss: 12.948054
 >> iter 38000, loss: 12.971091
 >> iter 39000, loss: 12.960300
 >> iter 40000, loss: 12.972102
   Number of active neurons: 4
 >> iter 41000, loss: 12.949992
 >> iter 42000, loss: 12.973772
 >> iter 43000, loss: 12.955027
 >> iter 44000, loss: 12.971318
 >> iter 45000, loss: 12.950190
 >> iter 46000, loss: 12.975721
 >> iter 47000, loss: 12.956096
 >> iter 48000, loss: 12.975270
 >> iter 49000, loss: 12.949723
 >> iter 50000, loss: 12.970637
   Number of active neurons: 4
 >> iter 51000, loss: 12.952488
 >> iter 52000, loss: 12.979505
 >> iter 53000, loss: 12.943022
 >> iter 54000, loss: 12.981356
 >> iter 55000, loss: 12.942388
 >> iter 56000, loss: 12.980916
 >> iter 57000, loss: 12.945623
 >> iter 58000, loss: 12.973606
 >> iter 59000, loss: 12.948195
 >> iter 60000, loss: 12.981825
   Number of active neurons: 4
 >> iter 61000, loss: 12.951466
 >> iter 62000, loss: 12.979180
 >> iter 63000, loss: 12.949314
 >> iter 64000, loss: 12.982255
 >> iter 65000, loss: 12.951678
 >> iter 66000, loss: 12.982772
 >> iter 67000, loss: 12.943724
 >> iter 68000, loss: 12.974896
 >> iter 69000, loss: 12.950644
 >> iter 70000, loss: 12.986341
   Number of active neurons: 4
 >> iter 71000, loss: 12.954866
 >> iter 72000, loss: 12.987022
 >> iter 73000, loss: 12.958450
 >> iter 74000, loss: 12.982814
 >> iter 75000, loss: 12.943245
 >> iter 76000, loss: 12.976395
 >> iter 77000, loss: 12.952286
 >> iter 78000, loss: 12.978207
 >> iter 79000, loss: 12.945068
 >> iter 80000, loss: 12.979865
   Number of active neurons: 4
 >> iter 81000, loss: 12.947042
 >> iter 82000, loss: 12.981018
 >> iter 83000, loss: 12.950389
 >> iter 84000, loss: 12.984857
 >> iter 85000, loss: 12.942695
 >> iter 86000, loss: 12.969497
 >> iter 87000, loss: 12.948410
 >> iter 88000, loss: 12.976839
 >> iter 89000, loss: 12.948566
 >> iter 90000, loss: 12.979044
   Number of active neurons: 4
 >> iter 91000, loss: 12.947784
 >> iter 92000, loss: 12.989109
 >> iter 93000, loss: 12.958534
 >> iter 94000, loss: 12.990889
 >> iter 95000, loss: 12.956911
 >> iter 96000, loss: 12.986348
 >> iter 97000, loss: 12.950187
 >> iter 98000, loss: 12.990852
 >> iter 99000, loss: 12.958010
 >> iter 100000, loss: 12.981672
   Number of active neurons: 4
 >> iter 101000, loss: 12.953659
 >> iter 102000, loss: 12.979280
 >> iter 103000, loss: 12.958256
 >> iter 104000, loss: 12.988444
 >> iter 105000, loss: 12.953590
 >> iter 106000, loss: 12.977632
 >> iter 107000, loss: 12.948163
 >> iter 108000, loss: 12.982875
 >> iter 109000, loss: 12.939167
 >> iter 110000, loss: 12.981396
   Number of active neurons: 4
 >> iter 111000, loss: 12.950051
 >> iter 112000, loss: 12.983068
 >> iter 113000, loss: 12.948173
 >> iter 114000, loss: 12.979904
 >> iter 115000, loss: 12.938312
 >> iter 116000, loss: 12.984988
 >> iter 117000, loss: 12.945462
 >> iter 118000, loss: 12.976180
 >> iter 119000, loss: 12.937898
 >> iter 120000, loss: 12.980880
   Number of active neurons: 4
 >> iter 121000, loss: 12.935241
 >> iter 122000, loss: 12.980101
 >> iter 123000, loss: 12.928233
 >> iter 124000, loss: 12.971492
 >> iter 125000, loss: 12.924930
 >> iter 126000, loss: 12.981049
 >> iter 127000, loss: 12.939074
 >> iter 128000, loss: 12.980390
 >> iter 129000, loss: 12.937351
 >> iter 130000, loss: 12.981904
   Number of active neurons: 4
 >> iter 131000, loss: 12.939205
 >> iter 132000, loss: 12.980458
 >> iter 133000, loss: 12.930071
 >> iter 134000, loss: 12.978001
 >> iter 135000, loss: 12.928142
 >> iter 136000, loss: 12.986162
 >> iter 137000, loss: 12.931747
 >> iter 138000, loss: 12.985855
 >> iter 139000, loss: 12.937370
 >> iter 140000, loss: 12.993154
   Number of active neurons: 4
 >> iter 141000, loss: 12.940136
 >> iter 142000, loss: 12.985512
 >> iter 143000, loss: 12.939456
 >> iter 144000, loss: 12.992900
 >> iter 145000, loss: 12.944442
 >> iter 146000, loss: 12.988116
 >> iter 147000, loss: 12.933202
 >> iter 148000, loss: 12.992062
 >> iter 149000, loss: 12.939272
 >> iter 150000, loss: 12.986783
   Number of active neurons: 4
 >> iter 151000, loss: 12.947428
 >> iter 152000, loss: 12.995110
 >> iter 153000, loss: 12.945146
 >> iter 154000, loss: 12.991886
 >> iter 155000, loss: 12.947408
 >> iter 156000, loss: 12.990522
 >> iter 157000, loss: 12.943253
 >> iter 158000, loss: 12.995424
 >> iter 159000, loss: 12.940107
 >> iter 160000, loss: 12.995522
   Number of active neurons: 4
 >> iter 161000, loss: 12.937124
 >> iter 162000, loss: 12.994534
 >> iter 163000, loss: 12.934379
 >> iter 164000, loss: 12.989328
 >> iter 165000, loss: 12.939313
 >> iter 166000, loss: 12.987110
 >> iter 167000, loss: 12.928090
 >> iter 168000, loss: 12.974248
 >> iter 169000, loss: 12.928349
 >> iter 170000, loss: 12.981965
   Number of active neurons: 4
 >> iter 171000, loss: 12.930288
 >> iter 172000, loss: 12.982886
 >> iter 173000, loss: 12.937884
 >> iter 174000, loss: 12.986645
 >> iter 175000, loss: 12.939653
 >> iter 176000, loss: 12.988940
 >> iter 177000, loss: 12.941686
 >> iter 178000, loss: 12.985587
 >> iter 179000, loss: 12.941765
 >> iter 180000, loss: 12.989061
   Number of active neurons: 4
 >> iter 181000, loss: 12.931511
 >> iter 182000, loss: 12.980882
 >> iter 183000, loss: 12.931239
 >> iter 184000, loss: 12.983746
 >> iter 185000, loss: 12.929589
 >> iter 186000, loss: 12.981875
 >> iter 187000, loss: 12.925809
 >> iter 188000, loss: 12.993308
 >> iter 189000, loss: 12.929111
 >> iter 190000, loss: 12.989374
   Number of active neurons: 4
 >> iter 191000, loss: 12.930289
 >> iter 192000, loss: 12.980240
 >> iter 193000, loss: 12.935031
 >> iter 194000, loss: 12.987126
 >> iter 195000, loss: 12.939527
 >> iter 196000, loss: 12.989432
 >> iter 197000, loss: 12.936759
 >> iter 198000, loss: 12.981565
 >> iter 199000, loss: 12.933051
 >> iter 200000, loss: 12.984973
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 27.7254454911
   - Test - Long: 32.7583620819
   - Test - Big: 27.9837201628
   - Test - A: 33.6777548163
   - Test - B: 33.5577628158

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

