 > Problema: tomita7nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.036052
 >> iter 2000, loss: 12.553334
 >> iter 3000, loss: 11.458995
 >> iter 4000, loss: 10.490760
 >> iter 5000, loss: 10.390151
 >> iter 6000, loss: 10.669296
 >> iter 7000, loss: 10.712733
 >> iter 8000, loss: 10.647566
 >> iter 9000, loss: 11.077102
 >> iter 10000, loss: 10.718320
   Number of active neurons: 2
 >> iter 11000, loss: 10.265039
 >> iter 12000, loss: 10.489005
 >> iter 13000, loss: 10.639639
 >> iter 14000, loss: 10.137246
 >> iter 15000, loss: 10.135863
 >> iter 16000, loss: 9.938157
 >> iter 17000, loss: 10.447431
 >> iter 18000, loss: 10.444676
 >> iter 19000, loss: 10.608103
 >> iter 20000, loss: 10.644206
   Number of active neurons: 2
 >> iter 21000, loss: 10.556129
 >> iter 22000, loss: 10.423387
 >> iter 23000, loss: 10.263790
 >> iter 24000, loss: 10.424202
 >> iter 25000, loss: 10.223481
 >> iter 26000, loss: 10.494967
 >> iter 27000, loss: 10.211134
 >> iter 28000, loss: 9.879575
 >> iter 29000, loss: 10.704110
 >> iter 30000, loss: 10.754665
   Number of active neurons: 2
 >> iter 31000, loss: 10.820326
 >> iter 32000, loss: 10.254490
 >> iter 33000, loss: 10.590615
 >> iter 34000, loss: 10.966781
 >> iter 35000, loss: 10.339799
 >> iter 36000, loss: 11.186722
 >> iter 37000, loss: 10.333239
 >> iter 38000, loss: 10.575428
 >> iter 39000, loss: 10.949107
 >> iter 40000, loss: 10.569263
   Number of active neurons: 2
 >> iter 41000, loss: 10.152927
 >> iter 42000, loss: 10.998601
 >> iter 43000, loss: 11.529819
 >> iter 44000, loss: 11.088982
 >> iter 45000, loss: 10.999405
 >> iter 46000, loss: 11.566974
 >> iter 47000, loss: 11.269627
 >> iter 48000, loss: 10.497502
 >> iter 49000, loss: 10.523388
 >> iter 50000, loss: 10.757888
   Number of active neurons: 2
 >> iter 51000, loss: 10.949476
 >> iter 52000, loss: 10.738137
 >> iter 53000, loss: 9.565129
 >> iter 54000, loss: 13.535881
 >> iter 55000, loss: 13.433684
 >> iter 56000, loss: 11.044818
 >> iter 57000, loss: 10.251905
 >> iter 58000, loss: 11.638378
 >> iter 59000, loss: 10.989621
 >> iter 60000, loss: 12.459816
   Number of active neurons: 2
 >> iter 61000, loss: 11.217853
 >> iter 62000, loss: 10.446938
 >> iter 63000, loss: 11.470160
 >> iter 64000, loss: 13.234681
 >> iter 65000, loss: 12.383094
 >> iter 66000, loss: 11.805984
 >> iter 67000, loss: 10.983885
 >> iter 68000, loss: 11.096001
 >> iter 69000, loss: 10.631273
 >> iter 70000, loss: 11.302325
   Number of active neurons: 2
 >> iter 71000, loss: 11.541129
 >> iter 72000, loss: 13.482270
 >> iter 73000, loss: 11.947415
 >> iter 74000, loss: 11.040417
 >> iter 75000, loss: 12.018237
 >> iter 76000, loss: 12.328735
 >> iter 77000, loss: 14.698218
 >> iter 78000, loss: 13.516219
 >> iter 79000, loss: 13.478053
 >> iter 80000, loss: 12.081351
   Number of active neurons: 2
 >> iter 81000, loss: 12.371821
 >> iter 82000, loss: 13.864226
 >> iter 83000, loss: 14.037711
 >> iter 84000, loss: 14.684623
 >> iter 85000, loss: 14.296235
 >> iter 86000, loss: 13.398592
 >> iter 87000, loss: 13.861062
 >> iter 88000, loss: 13.576497
 >> iter 89000, loss: 14.229162
 >> iter 90000, loss: 13.257193
   Number of active neurons: 2
 >> iter 91000, loss: 13.978658
 >> iter 92000, loss: 12.541811
 >> iter 93000, loss: 13.065530
 >> iter 94000, loss: 13.603933
 >> iter 95000, loss: 13.898445
 >> iter 96000, loss: 14.227435
 >> iter 97000, loss: 14.216124
 >> iter 98000, loss: 13.013530
 >> iter 99000, loss: 14.102982
 >> iter 100000, loss: 14.379204
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.520672
 >> iter 2000, loss: 12.643398
 >> iter 3000, loss: 11.331500
 >> iter 4000, loss: 10.816166
 >> iter 5000, loss: 10.819911
 >> iter 6000, loss: 10.964171
 >> iter 7000, loss: 10.805948
 >> iter 8000, loss: 10.560681
 >> iter 9000, loss: 11.061232
 >> iter 10000, loss: 10.878174
   Number of active neurons: 2
 >> iter 11000, loss: 11.160902
 >> iter 12000, loss: 10.939372
 >> iter 13000, loss: 11.785851
 >> iter 14000, loss: 11.761829
 >> iter 15000, loss: 11.835708
 >> iter 16000, loss: 11.596372
 >> iter 17000, loss: 11.835658
 >> iter 18000, loss: 11.661160
 >> iter 19000, loss: 12.069517
 >> iter 20000, loss: 12.134118
   Number of active neurons: 2
 >> iter 21000, loss: 12.248682
 >> iter 22000, loss: 12.035308
 >> iter 23000, loss: 12.785749
 >> iter 24000, loss: 12.107224
 >> iter 25000, loss: 12.224460
 >> iter 26000, loss: 12.705372
 >> iter 27000, loss: 12.434864
 >> iter 28000, loss: 12.104815
 >> iter 29000, loss: 12.509855
 >> iter 30000, loss: 13.014808
   Number of active neurons: 2
 >> iter 31000, loss: 12.940133
 >> iter 32000, loss: 13.102205
 >> iter 33000, loss: 12.862048
 >> iter 34000, loss: 12.607677
 >> iter 35000, loss: 13.276906
 >> iter 36000, loss: 13.253516
 >> iter 37000, loss: 13.119444
 >> iter 38000, loss: 12.648658
 >> iter 39000, loss: 13.022706
 >> iter 40000, loss: 13.072885
   Number of active neurons: 2
 >> iter 41000, loss: 13.209640
 >> iter 42000, loss: 12.460337
 >> iter 43000, loss: 13.496377
 >> iter 44000, loss: 13.489992
 >> iter 45000, loss: 13.059712
 >> iter 46000, loss: 13.935807
 >> iter 47000, loss: 14.135416
 >> iter 48000, loss: 13.035727
 >> iter 49000, loss: 13.666532
 >> iter 50000, loss: 13.069241
   Number of active neurons: 2
 >> iter 51000, loss: 12.696919
 >> iter 52000, loss: 13.255380
 >> iter 53000, loss: 13.465239
 >> iter 54000, loss: 13.855654
 >> iter 55000, loss: 13.443687
 >> iter 56000, loss: 13.509323
 >> iter 57000, loss: 13.937518
 >> iter 58000, loss: 13.605016
 >> iter 59000, loss: 13.184416
 >> iter 60000, loss: 13.384023
   Number of active neurons: 2
 >> iter 61000, loss: 13.758960
 >> iter 62000, loss: 12.651825
 >> iter 63000, loss: 13.529438
 >> iter 64000, loss: 13.341711
 >> iter 65000, loss: 14.287768
 >> iter 66000, loss: 13.371180
 >> iter 67000, loss: 13.438333
 >> iter 68000, loss: 13.099240
 >> iter 69000, loss: 12.364493
 >> iter 70000, loss: 13.418470
   Number of active neurons: 2
 >> iter 71000, loss: 14.013166
 >> iter 72000, loss: 13.216911
 >> iter 73000, loss: 15.143177
 >> iter 74000, loss: 14.480325
 >> iter 75000, loss: 14.569802
 >> iter 76000, loss: 14.267668
 >> iter 77000, loss: 14.303063
 >> iter 78000, loss: 14.294565
 >> iter 79000, loss: 13.824517
 >> iter 80000, loss: 14.070578
   Number of active neurons: 2
 >> iter 81000, loss: 13.988093
 >> iter 82000, loss: 14.624079
 >> iter 83000, loss: 14.983304
 >> iter 84000, loss: 15.432460
 >> iter 85000, loss: 15.205983
 >> iter 86000, loss: 14.427724
 >> iter 87000, loss: 14.005021
 >> iter 88000, loss: 14.480849
 >> iter 89000, loss: 14.128808
 >> iter 90000, loss: 13.652640
   Number of active neurons: 2
 >> iter 91000, loss: 13.296481
 >> iter 92000, loss: 13.973612
 >> iter 93000, loss: 15.152338
 >> iter 94000, loss: 15.075076
 >> iter 95000, loss: 14.687663
 >> iter 96000, loss: 13.603380
 >> iter 97000, loss: 13.928846
 >> iter 98000, loss: 13.176678
 >> iter 99000, loss: 13.805850
 >> iter 100000, loss: 13.940930
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 14.883702326
   - Test - Long: 3.22483875806
   - Test - Big: 15.0758492415
   - Test - A: 75.4616358909
   - Test - B: 65.3356442904
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.964278
 >> iter 2000, loss: 12.691392
 >> iter 3000, loss: 10.964386
 >> iter 4000, loss: 10.421394
 >> iter 5000, loss: 10.287857
 >> iter 6000, loss: 10.382165
 >> iter 7000, loss: 10.405478
 >> iter 8000, loss: 11.102825
 >> iter 9000, loss: 10.445396
 >> iter 10000, loss: 10.936743
   Number of active neurons: 2
 >> iter 11000, loss: 11.150239
 >> iter 12000, loss: 10.738623
 >> iter 13000, loss: 10.752688
 >> iter 14000, loss: 10.723887
 >> iter 15000, loss: 11.429487
 >> iter 16000, loss: 11.932511
 >> iter 17000, loss: 10.853175
 >> iter 18000, loss: 10.993254
 >> iter 19000, loss: 12.375967
 >> iter 20000, loss: 12.345420
   Number of active neurons: 2
 >> iter 21000, loss: 11.475693
 >> iter 22000, loss: 12.235466
 >> iter 23000, loss: 13.001782
 >> iter 24000, loss: 14.194611
 >> iter 25000, loss: 12.953437
 >> iter 26000, loss: 11.695230
 >> iter 27000, loss: 12.462130
 >> iter 28000, loss: 12.802867
 >> iter 29000, loss: 12.954350
 >> iter 30000, loss: 11.819802
   Number of active neurons: 2
 >> iter 31000, loss: 11.911370
 >> iter 32000, loss: 12.823177
 >> iter 33000, loss: 13.472641
 >> iter 34000, loss: 12.747333
 >> iter 35000, loss: 14.197476
 >> iter 36000, loss: 14.217066
 >> iter 37000, loss: 13.759554
 >> iter 38000, loss: 13.961181
 >> iter 39000, loss: 14.389092
 >> iter 40000, loss: 12.416961
   Number of active neurons: 2
 >> iter 41000, loss: 13.088492
 >> iter 42000, loss: 14.356041
 >> iter 43000, loss: 13.579923
 >> iter 44000, loss: 13.509923
 >> iter 45000, loss: 12.810460
 >> iter 46000, loss: 12.316499
 >> iter 47000, loss: 13.384076
 >> iter 48000, loss: 14.486398
 >> iter 49000, loss: 14.365685
 >> iter 50000, loss: 14.275779
   Number of active neurons: 2
 >> iter 51000, loss: 12.869619
 >> iter 52000, loss: 12.091103
 >> iter 53000, loss: 12.052463
 >> iter 54000, loss: 12.431599
 >> iter 55000, loss: 12.452260
 >> iter 56000, loss: 12.535140
 >> iter 57000, loss: 13.418813
 >> iter 58000, loss: 12.226688
 >> iter 59000, loss: 14.402152
 >> iter 60000, loss: 15.497849
   Number of active neurons: 2
 >> iter 61000, loss: 14.452152
 >> iter 62000, loss: 14.058694
 >> iter 63000, loss: 15.106456
 >> iter 64000, loss: 14.279971
 >> iter 65000, loss: 13.221886
 >> iter 66000, loss: 12.854464
 >> iter 67000, loss: 13.627492
 >> iter 68000, loss: 14.086607
 >> iter 69000, loss: 14.468329
 >> iter 70000, loss: 13.886162
   Number of active neurons: 2
 >> iter 71000, loss: 15.348253
 >> iter 72000, loss: 14.042874
 >> iter 73000, loss: 14.714745
 >> iter 74000, loss: 14.201179
 >> iter 75000, loss: 14.315647
 >> iter 76000, loss: 13.883952
 >> iter 77000, loss: 12.469209
 >> iter 78000, loss: 12.909045
 >> iter 79000, loss: 14.222971
 >> iter 80000, loss: 14.554413
   Number of active neurons: 2
 >> iter 81000, loss: 14.870679
 >> iter 82000, loss: 13.319261
 >> iter 83000, loss: 14.521529
 >> iter 84000, loss: 15.166457
 >> iter 85000, loss: 14.660028
 >> iter 86000, loss: 14.302971
 >> iter 87000, loss: 14.340874
 >> iter 88000, loss: 15.273319
 >> iter 89000, loss: 15.078403
 >> iter 90000, loss: 15.856964
   Number of active neurons: 2
 >> iter 91000, loss: 15.270058
 >> iter 92000, loss: 14.842055
 >> iter 93000, loss: 14.983726
 >> iter 94000, loss: 15.785662
 >> iter 95000, loss: 14.242236
 >> iter 96000, loss: 13.617820
 >> iter 97000, loss: 13.561871
 >> iter 98000, loss: 15.196048
 >> iter 99000, loss: 15.616898
 >> iter 100000, loss: 14.590762
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 11.1197776044
   - Test - Long: 2.34988250587
   - Test - Big: 11.2428875711
   - Test - A: 74.4950336644
   - Test - B: 65.2689820679
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.935108
 >> iter 2000, loss: 12.644575
 >> iter 3000, loss: 10.936069
 >> iter 4000, loss: 10.500589
 >> iter 5000, loss: 10.268604
 >> iter 6000, loss: 10.449586
 >> iter 7000, loss: 10.273617
 >> iter 8000, loss: 10.208425
 >> iter 9000, loss: 10.203096
 >> iter 10000, loss: 10.715754
   Number of active neurons: 2
 >> iter 11000, loss: 10.535489
 >> iter 12000, loss: 11.337655
 >> iter 13000, loss: 10.840650
 >> iter 14000, loss: 11.409979
 >> iter 15000, loss: 11.305289
 >> iter 16000, loss: 11.804686
 >> iter 17000, loss: 12.773257
 >> iter 18000, loss: 11.867733
 >> iter 19000, loss: 11.875892
 >> iter 20000, loss: 10.609049
   Number of active neurons: 2
 >> iter 21000, loss: 11.727312
 >> iter 22000, loss: 10.975892
 >> iter 23000, loss: 13.066128
 >> iter 24000, loss: 12.132074
 >> iter 25000, loss: 12.379137
 >> iter 26000, loss: 12.071404
 >> iter 27000, loss: 10.965940
 >> iter 28000, loss: 11.438776
 >> iter 29000, loss: 13.337364
 >> iter 30000, loss: 14.469602
   Number of active neurons: 2
 >> iter 31000, loss: 13.646118
 >> iter 32000, loss: 12.678237
 >> iter 33000, loss: 11.876394
 >> iter 34000, loss: 12.378482
 >> iter 35000, loss: 12.219835
 >> iter 36000, loss: 11.848599
 >> iter 37000, loss: 12.970254
 >> iter 38000, loss: 12.619259
 >> iter 39000, loss: 12.450816
 >> iter 40000, loss: 12.757776
   Number of active neurons: 2
 >> iter 41000, loss: 13.891687
 >> iter 42000, loss: 12.815108
 >> iter 43000, loss: 12.071150
 >> iter 44000, loss: 12.886136
 >> iter 45000, loss: 13.990908
 >> iter 46000, loss: 13.867045
 >> iter 47000, loss: 14.325025
 >> iter 48000, loss: 14.154252
 >> iter 49000, loss: 14.428116
 >> iter 50000, loss: 13.678115
   Number of active neurons: 2
 >> iter 51000, loss: 14.432672
 >> iter 52000, loss: 14.095549
 >> iter 53000, loss: 13.045143
 >> iter 54000, loss: 13.392202
 >> iter 55000, loss: 14.918548
 >> iter 56000, loss: 15.101583
 >> iter 57000, loss: 14.420136
 >> iter 58000, loss: 13.199863
 >> iter 59000, loss: 13.579612
 >> iter 60000, loss: 13.605308
   Number of active neurons: 2
 >> iter 61000, loss: 14.658999
 >> iter 62000, loss: 14.131766
 >> iter 63000, loss: 15.237976
 >> iter 64000, loss: 14.332946
 >> iter 65000, loss: 13.402514
 >> iter 66000, loss: 13.573600
 >> iter 67000, loss: 12.428736
 >> iter 68000, loss: 13.177362
 >> iter 69000, loss: 14.672224
 >> iter 70000, loss: 14.310824
   Number of active neurons: 2
 >> iter 71000, loss: 14.803000
 >> iter 72000, loss: 14.472929
 >> iter 73000, loss: 14.153206
 >> iter 74000, loss: 13.738682
 >> iter 75000, loss: 12.513147
 >> iter 76000, loss: 14.739708
 >> iter 77000, loss: 14.679929
 >> iter 78000, loss: 14.440175
 >> iter 79000, loss: 15.249759
 >> iter 80000, loss: 12.793572
   Number of active neurons: 2
 >> iter 81000, loss: 13.341510
 >> iter 82000, loss: 13.668089
 >> iter 83000, loss: 14.853475
 >> iter 84000, loss: 15.639012
 >> iter 85000, loss: 15.536288
 >> iter 86000, loss: 15.813647
 >> iter 87000, loss: 15.702684
 >> iter 88000, loss: 15.966649
 >> iter 89000, loss: 14.757892
 >> iter 90000, loss: 13.062963
   Number of active neurons: 2
 >> iter 91000, loss: 14.774859
 >> iter 92000, loss: 14.409538
 >> iter 93000, loss: 12.705228
 >> iter 94000, loss: 14.583356
 >> iter 95000, loss: 12.665945
 >> iter 96000, loss: 13.619170
 >> iter 97000, loss: 11.758502
 >> iter 98000, loss: 14.256016
 >> iter 99000, loss: 14.475530
 >> iter 100000, loss: 15.749099
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 11.3177736445
   - Test - Long: 2.35488225589
   - Test - Big: 11.4148858511
   - Test - A: 67.0221985201
   - Test - B: 65.2689820679
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.118875
 >> iter 2000, loss: 12.533377
 >> iter 3000, loss: 11.302113
 >> iter 4000, loss: 10.624227
 >> iter 5000, loss: 10.922287
 >> iter 6000, loss: 10.707021
 >> iter 7000, loss: 10.790726
 >> iter 8000, loss: 10.952613
 >> iter 9000, loss: 11.309694
 >> iter 10000, loss: 11.052773
   Number of active neurons: 2
 >> iter 11000, loss: 11.313648
 >> iter 12000, loss: 11.049795
 >> iter 13000, loss: 11.492250
 >> iter 14000, loss: 11.671631
 >> iter 15000, loss: 12.066085
 >> iter 16000, loss: 11.488793
 >> iter 17000, loss: 11.591504
 >> iter 18000, loss: 11.594391
 >> iter 19000, loss: 12.035389
 >> iter 20000, loss: 12.195885
   Number of active neurons: 2
 >> iter 21000, loss: 12.139056
 >> iter 22000, loss: 11.724058
 >> iter 23000, loss: 12.394719
 >> iter 24000, loss: 11.970884
 >> iter 25000, loss: 12.372987
 >> iter 26000, loss: 12.487293
 >> iter 27000, loss: 13.254666
 >> iter 28000, loss: 12.348101
 >> iter 29000, loss: 12.155173
 >> iter 30000, loss: 12.261452
   Number of active neurons: 2
 >> iter 31000, loss: 13.280731
 >> iter 32000, loss: 13.108801
 >> iter 33000, loss: 13.546326
 >> iter 34000, loss: 12.530210
 >> iter 35000, loss: 13.017693
 >> iter 36000, loss: 12.635568
 >> iter 37000, loss: 12.993974
 >> iter 38000, loss: 12.668542
 >> iter 39000, loss: 13.513950
 >> iter 40000, loss: 13.038448
   Number of active neurons: 2
 >> iter 41000, loss: 12.607054
 >> iter 42000, loss: 13.011603
 >> iter 43000, loss: 13.782316
 >> iter 44000, loss: 13.824478
 >> iter 45000, loss: 13.672126
 >> iter 46000, loss: 13.742101
 >> iter 47000, loss: 14.029392
 >> iter 48000, loss: 13.458018
 >> iter 49000, loss: 13.860656
 >> iter 50000, loss: 12.949505
   Number of active neurons: 2
 >> iter 51000, loss: 12.785098
 >> iter 52000, loss: 13.448510
 >> iter 53000, loss: 13.937990
 >> iter 54000, loss: 14.063572
 >> iter 55000, loss: 13.267047
 >> iter 56000, loss: 14.057791
 >> iter 57000, loss: 14.771813
 >> iter 58000, loss: 13.969997
 >> iter 59000, loss: 14.240739
 >> iter 60000, loss: 13.450268
   Number of active neurons: 2
 >> iter 61000, loss: 13.879253
 >> iter 62000, loss: 13.181290
 >> iter 63000, loss: 13.931882
 >> iter 64000, loss: 13.584441
 >> iter 65000, loss: 13.990838
 >> iter 66000, loss: 14.079790
 >> iter 67000, loss: 14.488383
 >> iter 68000, loss: 13.252369
 >> iter 69000, loss: 14.810708
 >> iter 70000, loss: 14.435253
   Number of active neurons: 2
 >> iter 71000, loss: 13.928154
 >> iter 72000, loss: 13.924607
 >> iter 73000, loss: 14.476765
 >> iter 74000, loss: 14.220131
 >> iter 75000, loss: 14.007834
 >> iter 76000, loss: 13.825588
 >> iter 77000, loss: 14.388511
 >> iter 78000, loss: 13.665422
 >> iter 79000, loss: 14.137141
 >> iter 80000, loss: 13.463493
   Number of active neurons: 2
 >> iter 81000, loss: 13.418678
 >> iter 82000, loss: 14.221485
 >> iter 83000, loss: 13.942795
 >> iter 84000, loss: 13.354101
 >> iter 85000, loss: 14.400814
 >> iter 86000, loss: 14.655046
 >> iter 87000, loss: 14.192823
 >> iter 88000, loss: 14.923532
 >> iter 89000, loss: 14.711785
 >> iter 90000, loss: 14.118081
   Number of active neurons: 2
 >> iter 91000, loss: 15.131515
 >> iter 92000, loss: 14.862088
 >> iter 93000, loss: 14.512101
 >> iter 94000, loss: 15.233949
 >> iter 95000, loss: 14.017218
 >> iter 96000, loss: 14.686624
 >> iter 97000, loss: 14.996194
 >> iter 98000, loss: 14.201908
 >> iter 99000, loss: 13.977030
 >> iter 100000, loss: 14.862315
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 36.0872782544
   - Test - Long: 14.014299285
   - Test - Big: 36.2146378536
   - Test - A: 68.342110526
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.871849
 >> iter 2000, loss: 11.830607
 >> iter 3000, loss: 8.629464
 >> iter 4000, loss: 6.916648
 >> iter 5000, loss: 6.394091
 >> iter 6000, loss: 6.082510
 >> iter 7000, loss: 5.903371
 >> iter 8000, loss: 6.021767
 >> iter 9000, loss: 6.452173
 >> iter 10000, loss: 6.212496
   Number of active neurons: 2
 >> iter 11000, loss: 6.223100
 >> iter 12000, loss: 6.019012
 >> iter 13000, loss: 5.955612
 >> iter 14000, loss: 6.025485
 >> iter 15000, loss: 6.076766
 >> iter 16000, loss: 5.908540
 >> iter 17000, loss: 6.099452
 >> iter 18000, loss: 5.682711
 >> iter 19000, loss: 5.787788
 >> iter 20000, loss: 5.693413
   Number of active neurons: 2
 >> iter 21000, loss: 5.923712
 >> iter 22000, loss: 5.788903
 >> iter 23000, loss: 5.800710
 >> iter 24000, loss: 5.810197
 >> iter 25000, loss: 5.852136
 >> iter 26000, loss: 5.716851
 >> iter 27000, loss: 5.710165
 >> iter 28000, loss: 5.842173
 >> iter 29000, loss: 6.013001
 >> iter 30000, loss: 5.728407
   Number of active neurons: 2
 >> iter 31000, loss: 5.823595
 >> iter 32000, loss: 5.686101
 >> iter 33000, loss: 5.484520
 >> iter 34000, loss: 5.390086
 >> iter 35000, loss: 5.643208
 >> iter 36000, loss: 5.638242
 >> iter 37000, loss: 5.656495
 >> iter 38000, loss: 5.662490
 >> iter 39000, loss: 5.763533
 >> iter 40000, loss: 5.632806
   Number of active neurons: 2
 >> iter 41000, loss: 5.670353
 >> iter 42000, loss: 5.467982
 >> iter 43000, loss: 5.962899
 >> iter 44000, loss: 5.587193
 >> iter 45000, loss: 5.623827
 >> iter 46000, loss: 5.496565
 >> iter 47000, loss: 5.565715
 >> iter 48000, loss: 5.671822
 >> iter 49000, loss: 5.729335
 >> iter 50000, loss: 5.705312
   Number of active neurons: 2
 >> iter 51000, loss: 5.954584
 >> iter 52000, loss: 5.735970
 >> iter 53000, loss: 5.668809
 >> iter 54000, loss: 5.532123
 >> iter 55000, loss: 5.643345
 >> iter 56000, loss: 5.693400
 >> iter 57000, loss: 5.681003
 >> iter 58000, loss: 5.620479
 >> iter 59000, loss: 5.602994
 >> iter 60000, loss: 5.536582
   Number of active neurons: 2
 >> iter 61000, loss: 5.515300
 >> iter 62000, loss: 5.398863
 >> iter 63000, loss: 5.497894
 >> iter 64000, loss: 5.605786
 >> iter 65000, loss: 5.729467
 >> iter 66000, loss: 5.711629
 >> iter 67000, loss: 5.755629
 >> iter 68000, loss: 5.525154
 >> iter 69000, loss: 5.630278
 >> iter 70000, loss: 5.673786
   Number of active neurons: 2
 >> iter 71000, loss: 5.709634
 >> iter 72000, loss: 5.651662
 >> iter 73000, loss: 5.868871
 >> iter 74000, loss: 5.809098
 >> iter 75000, loss: 5.637018
 >> iter 76000, loss: 5.545051
 >> iter 77000, loss: 5.659675
 >> iter 78000, loss: 5.696447
 >> iter 79000, loss: 5.782908
 >> iter 80000, loss: 5.830925
   Number of active neurons: 2
 >> iter 81000, loss: 6.008895
 >> iter 82000, loss: 5.898840
 >> iter 83000, loss: 5.780191
 >> iter 84000, loss: 5.647412
 >> iter 85000, loss: 5.825317
 >> iter 86000, loss: 5.657566
 >> iter 87000, loss: 5.903456
 >> iter 88000, loss: 5.592247
 >> iter 89000, loss: 5.842037
 >> iter 90000, loss: 5.779196
   Number of active neurons: 2
 >> iter 91000, loss: 5.902927
 >> iter 92000, loss: 6.022063
 >> iter 93000, loss: 6.001036
 >> iter 94000, loss: 5.854377
 >> iter 95000, loss: 6.283295
 >> iter 96000, loss: 5.896855
 >> iter 97000, loss: 5.879175
 >> iter 98000, loss: 6.018538
 >> iter 99000, loss: 6.035953
 >> iter 100000, loss: 5.972884
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 11.6457670847
   - Test - Long: 4.16479176041
   - Test - Big: 11.9318806812
   - Test - A: 18.978734751
   - Test - B: 25.3183121125
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.836784
 >> iter 2000, loss: 13.315890
 >> iter 3000, loss: 11.048332
 >> iter 4000, loss: 10.427298
 >> iter 5000, loss: 10.409114
 >> iter 6000, loss: 10.368236
 >> iter 7000, loss: 10.572197
 >> iter 8000, loss: 10.648337
 >> iter 9000, loss: 10.764261
 >> iter 10000, loss: 11.375076
   Number of active neurons: 2
 >> iter 11000, loss: 11.311286
 >> iter 12000, loss: 11.034243
 >> iter 13000, loss: 10.976650
 >> iter 14000, loss: 10.703382
 >> iter 15000, loss: 11.358519
 >> iter 16000, loss: 11.313930
 >> iter 17000, loss: 11.602389
 >> iter 18000, loss: 11.527882
 >> iter 19000, loss: 11.774880
 >> iter 20000, loss: 11.146062
   Number of active neurons: 2
 >> iter 21000, loss: 11.073528
 >> iter 22000, loss: 11.612263
 >> iter 23000, loss: 12.677597
 >> iter 24000, loss: 13.375284
 >> iter 25000, loss: 13.806634
 >> iter 26000, loss: 12.745651
 >> iter 27000, loss: 12.651405
 >> iter 28000, loss: 12.039370
 >> iter 29000, loss: 13.208515
 >> iter 30000, loss: 12.139958
   Number of active neurons: 2
 >> iter 31000, loss: 12.408745
 >> iter 32000, loss: 11.927843
 >> iter 33000, loss: 12.404144
 >> iter 34000, loss: 11.398010
 >> iter 35000, loss: 12.468172
 >> iter 36000, loss: 13.357143
 >> iter 37000, loss: 14.413267
 >> iter 38000, loss: 14.553753
 >> iter 39000, loss: 13.480695
 >> iter 40000, loss: 12.264762
   Number of active neurons: 2
 >> iter 41000, loss: 13.885672
 >> iter 42000, loss: 14.398586
 >> iter 43000, loss: 14.491065
 >> iter 44000, loss: 13.868425
 >> iter 45000, loss: 13.158247
 >> iter 46000, loss: 12.069857
 >> iter 47000, loss: 13.764073
 >> iter 48000, loss: 13.076156
 >> iter 49000, loss: 13.173135
 >> iter 50000, loss: 12.435892
   Number of active neurons: 2
 >> iter 51000, loss: 13.861955
 >> iter 52000, loss: 14.676387
 >> iter 53000, loss: 13.601207
 >> iter 54000, loss: 14.700483
 >> iter 55000, loss: 13.539198
 >> iter 56000, loss: 14.269230
 >> iter 57000, loss: 14.638742
 >> iter 58000, loss: 13.198299
 >> iter 59000, loss: 12.181183
 >> iter 60000, loss: 14.024326
   Number of active neurons: 2
 >> iter 61000, loss: 14.932827
 >> iter 62000, loss: 15.733835
 >> iter 63000, loss: 15.564538
 >> iter 64000, loss: 15.695417
 >> iter 65000, loss: 15.136079
 >> iter 66000, loss: 13.437062
 >> iter 67000, loss: 13.830556
 >> iter 68000, loss: 14.300482
 >> iter 69000, loss: 14.834244
 >> iter 70000, loss: 13.591753
   Number of active neurons: 2
 >> iter 71000, loss: 15.614196
 >> iter 72000, loss: 14.302947
 >> iter 73000, loss: 14.161675
 >> iter 74000, loss: 13.883469
 >> iter 75000, loss: 13.936204
 >> iter 76000, loss: 14.836708
 >> iter 77000, loss: 12.460233
 >> iter 78000, loss: 13.444594
 >> iter 79000, loss: 12.717279
 >> iter 80000, loss: 13.805870
   Number of active neurons: 2
 >> iter 81000, loss: 13.056168
 >> iter 82000, loss: 15.112693
 >> iter 83000, loss: 15.886605
 >> iter 84000, loss: 13.235872
 >> iter 85000, loss: 14.074576
 >> iter 86000, loss: 14.684421
 >> iter 87000, loss: 15.206528
 >> iter 88000, loss: 13.620264
 >> iter 89000, loss: 14.868213
 >> iter 90000, loss: 15.116507
   Number of active neurons: 2
 >> iter 91000, loss: 13.801856
 >> iter 92000, loss: 14.666759
 >> iter 93000, loss: 14.555516
 >> iter 94000, loss: 14.020000
 >> iter 95000, loss: 13.199143
 >> iter 96000, loss: 12.616196
 >> iter 97000, loss: 13.381551
 >> iter 98000, loss: 14.406972
 >> iter 99000, loss: 15.376044
 >> iter 100000, loss: 15.716593
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.979113
 >> iter 2000, loss: 13.299392
 >> iter 3000, loss: 11.069185
 >> iter 4000, loss: 10.425866
 >> iter 5000, loss: 10.226323
 >> iter 6000, loss: 11.108464
 >> iter 7000, loss: 11.112246
 >> iter 8000, loss: 10.811123
 >> iter 9000, loss: 10.697804
 >> iter 10000, loss: 10.317097
   Number of active neurons: 2
 >> iter 11000, loss: 10.592859
 >> iter 12000, loss: 10.429499
 >> iter 13000, loss: 10.925124
 >> iter 14000, loss: 10.758913
 >> iter 15000, loss: 11.078511
 >> iter 16000, loss: 10.594000
 >> iter 17000, loss: 11.105327
 >> iter 18000, loss: 11.201739
 >> iter 19000, loss: 10.597928
 >> iter 20000, loss: 11.188425
   Number of active neurons: 2
 >> iter 21000, loss: 11.462541
 >> iter 22000, loss: 11.486405
 >> iter 23000, loss: 13.290372
 >> iter 24000, loss: 12.334404
 >> iter 25000, loss: 12.938747
 >> iter 26000, loss: 12.094061
 >> iter 27000, loss: 11.804677
 >> iter 28000, loss: 12.141828
 >> iter 29000, loss: 11.657241
 >> iter 30000, loss: 11.131260
   Number of active neurons: 2
 >> iter 31000, loss: 10.550211
 >> iter 32000, loss: 11.638350
 >> iter 33000, loss: 13.040857
 >> iter 34000, loss: 12.207476
 >> iter 35000, loss: 11.278397
 >> iter 36000, loss: 11.269269
 >> iter 37000, loss: 12.972791
 >> iter 38000, loss: 13.652794
 >> iter 39000, loss: 12.583044
 >> iter 40000, loss: 12.837028
   Number of active neurons: 2
 >> iter 41000, loss: 12.815230
 >> iter 42000, loss: 12.621141
 >> iter 43000, loss: 10.775475
 >> iter 44000, loss: 11.720378
 >> iter 45000, loss: 13.261206
 >> iter 46000, loss: 14.169609
 >> iter 47000, loss: 12.370092
 >> iter 48000, loss: 13.074924
 >> iter 49000, loss: 13.904566
 >> iter 50000, loss: 14.320459
   Number of active neurons: 2
 >> iter 51000, loss: 15.071397
 >> iter 52000, loss: 12.905143
 >> iter 53000, loss: 13.592051
 >> iter 54000, loss: 13.747968
 >> iter 55000, loss: 13.451558
 >> iter 56000, loss: 13.369219
 >> iter 57000, loss: 12.258288
 >> iter 58000, loss: 11.475464
 >> iter 59000, loss: 12.728180
 >> iter 60000, loss: 13.300563
   Number of active neurons: 2
 >> iter 61000, loss: 13.125621
 >> iter 62000, loss: 12.403001
 >> iter 63000, loss: 14.109469
 >> iter 64000, loss: 13.084736
 >> iter 65000, loss: 13.023600
 >> iter 66000, loss: 12.286776
 >> iter 67000, loss: 12.040454
 >> iter 68000, loss: 13.949090
 >> iter 69000, loss: 13.668757
 >> iter 70000, loss: 15.095162
   Number of active neurons: 2
 >> iter 71000, loss: 14.136379
 >> iter 72000, loss: 15.204785
 >> iter 73000, loss: 14.087008
 >> iter 74000, loss: 13.959292
 >> iter 75000, loss: 14.368161
 >> iter 76000, loss: 13.670428
 >> iter 77000, loss: 14.970084
 >> iter 78000, loss: 13.966244
 >> iter 79000, loss: 15.345670
 >> iter 80000, loss: 13.435456
   Number of active neurons: 2
 >> iter 81000, loss: 14.221324
 >> iter 82000, loss: 13.908793
 >> iter 83000, loss: 12.655019
 >> iter 84000, loss: 14.528334
 >> iter 85000, loss: 14.981554
 >> iter 86000, loss: 13.880342
 >> iter 87000, loss: 12.961399
 >> iter 88000, loss: 13.283650
 >> iter 89000, loss: 11.854043
 >> iter 90000, loss: 13.759582
   Number of active neurons: 2
 >> iter 91000, loss: 14.430078
 >> iter 92000, loss: 13.165049
 >> iter 93000, loss: 15.053491
 >> iter 94000, loss: 15.115471
 >> iter 95000, loss: 15.912190
 >> iter 96000, loss: 14.570195
 >> iter 97000, loss: 14.793532
 >> iter 98000, loss: 13.187055
 >> iter 99000, loss: 15.180832
 >> iter 100000, loss: 15.710675
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 11.3497730045
   - Test - Long: 2.35488225589
   - Test - Big: 11.4598854011
   - Test - A: 74.5616958869
   - Test - B: 65.2689820679
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.788046
 >> iter 2000, loss: 12.310546
 >> iter 3000, loss: 10.847175
 >> iter 4000, loss: 10.045272
 >> iter 5000, loss: 10.075604
 >> iter 6000, loss: 10.221802
 >> iter 7000, loss: 10.216513
 >> iter 8000, loss: 10.344455
 >> iter 9000, loss: 11.359266
 >> iter 10000, loss: 11.457166
   Number of active neurons: 2
 >> iter 11000, loss: 11.166078
 >> iter 12000, loss: 11.325233
 >> iter 13000, loss: 10.670344
 >> iter 14000, loss: 10.819751
 >> iter 15000, loss: 10.446160
 >> iter 16000, loss: 11.683881
 >> iter 17000, loss: 11.840132
 >> iter 18000, loss: 10.890048
 >> iter 19000, loss: 12.307800
 >> iter 20000, loss: 11.910851
   Number of active neurons: 2
 >> iter 21000, loss: 12.691327
 >> iter 22000, loss: 12.393561
 >> iter 23000, loss: 11.840960
 >> iter 24000, loss: 11.115355
 >> iter 25000, loss: 10.903335
 >> iter 26000, loss: 11.210772
 >> iter 27000, loss: 12.593578
 >> iter 28000, loss: 11.400661
 >> iter 29000, loss: 11.228236
 >> iter 30000, loss: 12.056285
   Number of active neurons: 2
 >> iter 31000, loss: 12.032740
 >> iter 32000, loss: 12.218974
 >> iter 33000, loss: 13.657152
 >> iter 34000, loss: 14.110214
 >> iter 35000, loss: 14.343335
 >> iter 36000, loss: 13.323046
 >> iter 37000, loss: 13.334011
 >> iter 38000, loss: 12.556799
 >> iter 39000, loss: 14.001648
 >> iter 40000, loss: 12.316301
   Number of active neurons: 2
 >> iter 41000, loss: 13.767513
 >> iter 42000, loss: 14.810480
 >> iter 43000, loss: 13.674731
 >> iter 44000, loss: 12.400682
 >> iter 45000, loss: 12.998592
 >> iter 46000, loss: 13.118560
 >> iter 47000, loss: 13.821540
 >> iter 48000, loss: 13.420510
 >> iter 49000, loss: 14.764975
 >> iter 50000, loss: 13.060267
   Number of active neurons: 2
 >> iter 51000, loss: 12.627441
 >> iter 52000, loss: 12.476754
 >> iter 53000, loss: 13.782684
 >> iter 54000, loss: 14.812767
 >> iter 55000, loss: 14.744420
 >> iter 56000, loss: 13.037205
 >> iter 57000, loss: 12.731897
 >> iter 58000, loss: 10.729438
 >> iter 59000, loss: 13.147196
 >> iter 60000, loss: 14.537960
   Number of active neurons: 2
 >> iter 61000, loss: 15.666469
 >> iter 62000, loss: 14.079391
 >> iter 63000, loss: 14.624349
 >> iter 64000, loss: 14.411867
 >> iter 65000, loss: 14.064005
 >> iter 66000, loss: 14.184905
 >> iter 67000, loss: 11.748291
 >> iter 68000, loss: 13.222868
 >> iter 69000, loss: 13.194173
 >> iter 70000, loss: 13.624899
   Number of active neurons: 2
 >> iter 71000, loss: 12.182274
 >> iter 72000, loss: 14.508494
 >> iter 73000, loss: 15.532864
 >> iter 74000, loss: 13.261084
 >> iter 75000, loss: 14.479679
 >> iter 76000, loss: 14.222011
 >> iter 77000, loss: 15.174546
 >> iter 78000, loss: 15.473546
 >> iter 79000, loss: 13.792268
 >> iter 80000, loss: 13.742815
   Number of active neurons: 2
 >> iter 81000, loss: 13.982920
 >> iter 82000, loss: 12.542151
 >> iter 83000, loss: 14.552252
 >> iter 84000, loss: 14.847848
 >> iter 85000, loss: 13.846742
 >> iter 86000, loss: 12.498110
 >> iter 87000, loss: 14.856715
 >> iter 88000, loss: 15.278017
 >> iter 89000, loss: 14.536386
 >> iter 90000, loss: 14.464096
   Number of active neurons: 2
 >> iter 91000, loss: 15.479236
 >> iter 92000, loss: 14.421094
 >> iter 93000, loss: 13.499764
 >> iter 94000, loss: 16.151511
 >> iter 95000, loss: 15.170861
 >> iter 96000, loss: 15.262901
 >> iter 97000, loss: 15.099085
 >> iter 98000, loss: 13.372814
 >> iter 99000, loss: 13.952392
 >> iter 100000, loss: 14.073512
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 50.4433037797
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.780862
 >> iter 2000, loss: 12.606785
 >> iter 3000, loss: 10.983896
 >> iter 4000, loss: 10.361064
 >> iter 5000, loss: 10.426338
 >> iter 6000, loss: 10.216083
 >> iter 7000, loss: 10.317783
 >> iter 8000, loss: 10.433666
 >> iter 9000, loss: 10.487710
 >> iter 10000, loss: 10.860139
   Number of active neurons: 2
 >> iter 11000, loss: 10.564333
 >> iter 12000, loss: 10.972741
 >> iter 13000, loss: 10.854904
 >> iter 14000, loss: 11.150881
 >> iter 15000, loss: 10.961069
 >> iter 16000, loss: 11.661219
 >> iter 17000, loss: 12.163771
 >> iter 18000, loss: 11.455232
 >> iter 19000, loss: 11.344560
 >> iter 20000, loss: 11.266881
   Number of active neurons: 2
 >> iter 21000, loss: 12.625546
 >> iter 22000, loss: 12.439146
 >> iter 23000, loss: 12.098904
 >> iter 24000, loss: 11.553914
 >> iter 25000, loss: 12.456921
 >> iter 26000, loss: 12.363697
 >> iter 27000, loss: 12.349338
 >> iter 28000, loss: 12.335273
 >> iter 29000, loss: 13.806990
 >> iter 30000, loss: 14.002043
   Number of active neurons: 2
 >> iter 31000, loss: 12.914243
 >> iter 32000, loss: 12.960412
 >> iter 33000, loss: 11.687783
 >> iter 34000, loss: 12.431423
 >> iter 35000, loss: 13.458166
 >> iter 36000, loss: 13.590933
 >> iter 37000, loss: 13.997357
 >> iter 38000, loss: 13.550399
 >> iter 39000, loss: 12.918299
 >> iter 40000, loss: 12.385054
   Number of active neurons: 2
 >> iter 41000, loss: 13.540333
 >> iter 42000, loss: 13.896502
 >> iter 43000, loss: 13.475371
 >> iter 44000, loss: 12.516476
 >> iter 45000, loss: 13.505127
 >> iter 46000, loss: 13.163898
 >> iter 47000, loss: 14.098956
 >> iter 48000, loss: 13.496689
 >> iter 49000, loss: 12.629578
 >> iter 50000, loss: 14.132859
   Number of active neurons: 2
 >> iter 51000, loss: 14.716168
 >> iter 52000, loss: 15.413073
 >> iter 53000, loss: 12.379378
 >> iter 54000, loss: 12.782045
 >> iter 55000, loss: 13.562970
 >> iter 56000, loss: 13.361009
 >> iter 57000, loss: 12.493340
 >> iter 58000, loss: 14.433507
 >> iter 59000, loss: 14.068850
 >> iter 60000, loss: 14.799585
   Number of active neurons: 2
 >> iter 61000, loss: 14.794125
 >> iter 62000, loss: 15.014561
 >> iter 63000, loss: 13.783033
 >> iter 64000, loss: 14.017101
 >> iter 65000, loss: 13.294874
 >> iter 66000, loss: 14.898360
 >> iter 67000, loss: 15.450771
 >> iter 68000, loss: 13.195602
 >> iter 69000, loss: 14.492503
 >> iter 70000, loss: 12.986968
   Number of active neurons: 2
 >> iter 71000, loss: 14.211942
 >> iter 72000, loss: 14.147360
 >> iter 73000, loss: 14.597813
 >> iter 74000, loss: 14.402253
 >> iter 75000, loss: 14.925562
 >> iter 76000, loss: 12.555175
 >> iter 77000, loss: 13.138731
 >> iter 78000, loss: 14.589366
 >> iter 79000, loss: 13.995895
 >> iter 80000, loss: 14.091215
   Number of active neurons: 2
 >> iter 81000, loss: 14.796407
 >> iter 82000, loss: 13.605419
 >> iter 83000, loss: 13.465199
 >> iter 84000, loss: 14.013322
 >> iter 85000, loss: 13.605981
 >> iter 86000, loss: 14.886959
 >> iter 87000, loss: 14.507402
 >> iter 88000, loss: 15.798255
 >> iter 89000, loss: 15.695570
 >> iter 90000, loss: 15.932943
   Number of active neurons: 2
 >> iter 91000, loss: 14.556625
 >> iter 92000, loss: 14.882106
 >> iter 93000, loss: 14.594380
 >> iter 94000, loss: 14.437611
 >> iter 95000, loss: 15.782238
 >> iter 96000, loss: 16.325076
 >> iter 97000, loss: 16.110543
 >> iter 98000, loss: 15.087789
 >> iter 99000, loss: 15.806614
 >> iter 100000, loss: 14.642950
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.787922
 >> iter 2000, loss: 13.348884
 >> iter 3000, loss: 11.277290
 >> iter 4000, loss: 10.759412
 >> iter 5000, loss: 10.041715
 >> iter 6000, loss: 10.157732
 >> iter 7000, loss: 10.741304
 >> iter 8000, loss: 10.822405
 >> iter 9000, loss: 10.445335
 >> iter 10000, loss: 10.858281
   Number of active neurons: 2
 >> iter 11000, loss: 10.846617
 >> iter 12000, loss: 10.997313
 >> iter 13000, loss: 11.014434
 >> iter 14000, loss: 11.367470
 >> iter 15000, loss: 11.095036
 >> iter 16000, loss: 10.531014
 >> iter 17000, loss: 10.302984
 >> iter 18000, loss: 10.993915
 >> iter 19000, loss: 11.374006
 >> iter 20000, loss: 11.114623
   Number of active neurons: 2
 >> iter 21000, loss: 11.378992
 >> iter 22000, loss: 13.204671
 >> iter 23000, loss: 12.199753
 >> iter 24000, loss: 12.064296
 >> iter 25000, loss: 13.536856
 >> iter 26000, loss: 11.786133
 >> iter 27000, loss: 13.426748
 >> iter 28000, loss: 13.365095
 >> iter 29000, loss: 12.136297
 >> iter 30000, loss: 12.718883
   Number of active neurons: 2
 >> iter 31000, loss: 12.754603
 >> iter 32000, loss: 11.954985
 >> iter 33000, loss: 11.996216
 >> iter 34000, loss: 11.991198
 >> iter 35000, loss: 12.973955
 >> iter 36000, loss: 12.406567
 >> iter 37000, loss: 13.245330
 >> iter 38000, loss: 12.106659
 >> iter 39000, loss: 12.316065
 >> iter 40000, loss: 14.018121
   Number of active neurons: 2
 >> iter 41000, loss: 13.103914
 >> iter 42000, loss: 11.507396
 >> iter 43000, loss: 13.876858
 >> iter 44000, loss: 12.766141
 >> iter 45000, loss: 11.776064
 >> iter 46000, loss: 13.744094
 >> iter 47000, loss: 12.117053
 >> iter 48000, loss: 11.706469
 >> iter 49000, loss: 14.237171
 >> iter 50000, loss: 14.503510
   Number of active neurons: 2
 >> iter 51000, loss: 14.309543
 >> iter 52000, loss: 14.008671
 >> iter 53000, loss: 14.243774
 >> iter 54000, loss: 14.067667
 >> iter 55000, loss: 13.180541
 >> iter 56000, loss: 13.140295
 >> iter 57000, loss: 14.885530
 >> iter 58000, loss: 15.532282
 >> iter 59000, loss: 15.461621
 >> iter 60000, loss: 15.157948
   Number of active neurons: 2
 >> iter 61000, loss: 14.340313
 >> iter 62000, loss: 13.196364
 >> iter 63000, loss: 12.834349
 >> iter 64000, loss: 12.748743
 >> iter 65000, loss: 12.377852
 >> iter 66000, loss: 14.452416
 >> iter 67000, loss: 14.054588
 >> iter 68000, loss: 15.099781
 >> iter 69000, loss: 15.457730
 >> iter 70000, loss: 13.622209
   Number of active neurons: 2
 >> iter 71000, loss: 14.621590
 >> iter 72000, loss: 13.287081
 >> iter 73000, loss: 14.885947
 >> iter 74000, loss: 13.678622
 >> iter 75000, loss: 15.525520
 >> iter 76000, loss: 15.987119
 >> iter 77000, loss: 16.299838
 >> iter 78000, loss: 15.817132
 >> iter 79000, loss: 13.988977
 >> iter 80000, loss: 15.280591
   Number of active neurons: 2
 >> iter 81000, loss: 15.670130
 >> iter 82000, loss: 14.823432
 >> iter 83000, loss: 14.983899
 >> iter 84000, loss: 14.047740
 >> iter 85000, loss: 15.016165
 >> iter 86000, loss: 15.358720
 >> iter 87000, loss: 14.516325
 >> iter 88000, loss: 15.702366
 >> iter 89000, loss: 15.379711
 >> iter 90000, loss: 15.372865
   Number of active neurons: 2
 >> iter 91000, loss: 13.715817
 >> iter 92000, loss: 14.688198
 >> iter 93000, loss: 15.332148
 >> iter 94000, loss: 13.821177
 >> iter 95000, loss: 13.676422
 >> iter 96000, loss: 13.685654
 >> iter 97000, loss: 12.908291
 >> iter 98000, loss: 13.349187
 >> iter 99000, loss: 13.972363
 >> iter 100000, loss: 15.088590
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 12.0037599248
   - Test - Long: 2.56487175641
   - Test - Big: 12.1468785312
   - Test - A: 24.8850076662
   - Test - B: 65.2689820679
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.965021
 >> iter 2000, loss: 12.433514
 >> iter 3000, loss: 11.041740
 >> iter 4000, loss: 10.236958
 >> iter 5000, loss: 10.407503
 >> iter 6000, loss: 10.281778
 >> iter 7000, loss: 10.087752
 >> iter 8000, loss: 10.430585
 >> iter 9000, loss: 10.524955
 >> iter 10000, loss: 10.466337
   Number of active neurons: 2
 >> iter 11000, loss: 10.505409
 >> iter 12000, loss: 10.219111
 >> iter 13000, loss: 10.485260
 >> iter 14000, loss: 11.058137
 >> iter 15000, loss: 10.827523
 >> iter 16000, loss: 10.889757
 >> iter 17000, loss: 10.590843
 >> iter 18000, loss: 10.335599
 >> iter 19000, loss: 10.149671
 >> iter 20000, loss: 9.739051
   Number of active neurons: 2
 >> iter 21000, loss: 10.120753
 >> iter 22000, loss: 10.179982
 >> iter 23000, loss: 10.560448
 >> iter 24000, loss: 10.436258
 >> iter 25000, loss: 11.047188
 >> iter 26000, loss: 10.850173
 >> iter 27000, loss: 10.089253
 >> iter 28000, loss: 10.333398
 >> iter 29000, loss: 10.102658
 >> iter 30000, loss: 10.753562
   Number of active neurons: 2
 >> iter 31000, loss: 10.648623
 >> iter 32000, loss: 10.955770
 >> iter 33000, loss: 10.641512
 >> iter 34000, loss: 10.483463
 >> iter 35000, loss: 11.346909
 >> iter 36000, loss: 10.472146
 >> iter 37000, loss: 10.442432
 >> iter 38000, loss: 10.283915
 >> iter 39000, loss: 10.724222
 >> iter 40000, loss: 10.857087
   Number of active neurons: 2
 >> iter 41000, loss: 11.800759
 >> iter 42000, loss: 12.072247
 >> iter 43000, loss: 11.617465
 >> iter 44000, loss: 11.126710
 >> iter 45000, loss: 10.312308
 >> iter 46000, loss: 11.045280
 >> iter 47000, loss: 12.011374
 >> iter 48000, loss: 10.621586
 >> iter 49000, loss: 11.367569
 >> iter 50000, loss: 11.183649
   Number of active neurons: 2
 >> iter 51000, loss: 10.531083
 >> iter 52000, loss: 12.042603
 >> iter 53000, loss: 11.284549
 >> iter 54000, loss: 13.680236
 >> iter 55000, loss: 11.702639
 >> iter 56000, loss: 10.487724
 >> iter 57000, loss: 10.328333
 >> iter 58000, loss: 10.574339
 >> iter 59000, loss: 11.732903
 >> iter 60000, loss: 11.035611
   Number of active neurons: 2
 >> iter 61000, loss: 13.099602
 >> iter 62000, loss: 15.140435
 >> iter 63000, loss: 16.261863
 >> iter 64000, loss: 12.428972
 >> iter 65000, loss: 11.434103
 >> iter 66000, loss: 11.453725
 >> iter 67000, loss: 11.106578
 >> iter 68000, loss: 9.894045
 >> iter 69000, loss: 9.977743
 >> iter 70000, loss: 10.435701
   Number of active neurons: 2
 >> iter 71000, loss: 11.152895
 >> iter 72000, loss: 12.329971
 >> iter 73000, loss: 12.834688
 >> iter 74000, loss: 12.495327
 >> iter 75000, loss: 12.066866
 >> iter 76000, loss: 11.839999
 >> iter 77000, loss: 11.930226
 >> iter 78000, loss: 12.717728
 >> iter 79000, loss: 11.599272
 >> iter 80000, loss: 11.727785
   Number of active neurons: 2
 >> iter 81000, loss: 11.600780
 >> iter 82000, loss: 11.292378
 >> iter 83000, loss: 14.246320
 >> iter 84000, loss: 14.372839
 >> iter 85000, loss: 13.013787
 >> iter 86000, loss: 14.213713
 >> iter 87000, loss: 11.717805
 >> iter 88000, loss: 12.580706
 >> iter 89000, loss: 12.972111
 >> iter 90000, loss: 12.606669
   Number of active neurons: 2
 >> iter 91000, loss: 10.936829
 >> iter 92000, loss: 11.519385
 >> iter 93000, loss: 12.226250
 >> iter 94000, loss: 14.381267
 >> iter 95000, loss: 13.329297
 >> iter 96000, loss: 13.626969
 >> iter 97000, loss: 14.429954
 >> iter 98000, loss: 13.138824
 >> iter 99000, loss: 14.682427
 >> iter 100000, loss: 16.593915
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.923667
 >> iter 2000, loss: 12.758564
 >> iter 3000, loss: 10.837096
 >> iter 4000, loss: 10.601276
 >> iter 5000, loss: 10.358635
 >> iter 6000, loss: 10.203251
 >> iter 7000, loss: 10.519665
 >> iter 8000, loss: 10.527489
 >> iter 9000, loss: 10.924907
 >> iter 10000, loss: 10.838644
   Number of active neurons: 2
 >> iter 11000, loss: 10.766029
 >> iter 12000, loss: 10.913363
 >> iter 13000, loss: 11.164950
 >> iter 14000, loss: 11.066801
 >> iter 15000, loss: 10.435822
 >> iter 16000, loss: 11.594097
 >> iter 17000, loss: 11.388766
 >> iter 18000, loss: 11.362789
 >> iter 19000, loss: 11.947556
 >> iter 20000, loss: 11.519116
   Number of active neurons: 2
 >> iter 21000, loss: 10.941730
 >> iter 22000, loss: 10.985535
 >> iter 23000, loss: 12.525287
 >> iter 24000, loss: 12.814159
 >> iter 25000, loss: 12.580707
 >> iter 26000, loss: 11.861561
 >> iter 27000, loss: 11.600252
 >> iter 28000, loss: 11.393147
 >> iter 29000, loss: 12.566634
 >> iter 30000, loss: 11.755000
   Number of active neurons: 2
 >> iter 31000, loss: 12.210781
 >> iter 32000, loss: 12.190120
 >> iter 33000, loss: 13.293616
 >> iter 34000, loss: 13.731659
 >> iter 35000, loss: 12.258008
 >> iter 36000, loss: 12.856075
 >> iter 37000, loss: 12.610325
 >> iter 38000, loss: 13.155448
 >> iter 39000, loss: 13.441445
 >> iter 40000, loss: 14.602458
   Number of active neurons: 2
 >> iter 41000, loss: 12.782285
 >> iter 42000, loss: 12.526606
 >> iter 43000, loss: 12.197727
 >> iter 44000, loss: 12.564217
 >> iter 45000, loss: 13.480755
 >> iter 46000, loss: 13.365589
 >> iter 47000, loss: 13.419559
 >> iter 48000, loss: 13.973761
 >> iter 49000, loss: 12.982806
 >> iter 50000, loss: 14.374877
   Number of active neurons: 2
 >> iter 51000, loss: 14.695052
 >> iter 52000, loss: 13.625831
 >> iter 53000, loss: 14.474645
 >> iter 54000, loss: 14.799674
 >> iter 55000, loss: 14.880660
 >> iter 56000, loss: 12.929176
 >> iter 57000, loss: 13.345358
 >> iter 58000, loss: 12.490807
 >> iter 59000, loss: 13.807452
 >> iter 60000, loss: 13.797445
   Number of active neurons: 2
 >> iter 61000, loss: 14.163872
 >> iter 62000, loss: 12.009905
 >> iter 63000, loss: 12.814651
 >> iter 64000, loss: 13.502459
 >> iter 65000, loss: 14.539055
 >> iter 66000, loss: 15.403780
 >> iter 67000, loss: 14.933022
 >> iter 68000, loss: 12.730902
 >> iter 69000, loss: 14.266313
 >> iter 70000, loss: 12.963683
   Number of active neurons: 2
 >> iter 71000, loss: 14.913620
 >> iter 72000, loss: 13.533546
 >> iter 73000, loss: 13.787263
 >> iter 74000, loss: 13.558821
 >> iter 75000, loss: 12.599866
 >> iter 76000, loss: 13.335750
 >> iter 77000, loss: 14.312366
 >> iter 78000, loss: 15.634711
 >> iter 79000, loss: 14.601770
 >> iter 80000, loss: 13.808558
   Number of active neurons: 2
 >> iter 81000, loss: 14.830401
 >> iter 82000, loss: 14.827341
 >> iter 83000, loss: 15.145139
 >> iter 84000, loss: 13.118535
 >> iter 85000, loss: 14.706336
 >> iter 86000, loss: 13.212702
 >> iter 87000, loss: 12.239577
 >> iter 88000, loss: 13.667623
 >> iter 89000, loss: 14.083168
 >> iter 90000, loss: 14.323285
   Number of active neurons: 2
 >> iter 91000, loss: 14.313278
 >> iter 92000, loss: 15.113099
 >> iter 93000, loss: 15.875762
 >> iter 94000, loss: 15.322778
 >> iter 95000, loss: 15.315719
 >> iter 96000, loss: 15.030011
 >> iter 97000, loss: 15.081542
 >> iter 98000, loss: 15.461808
 >> iter 99000, loss: 13.830150
 >> iter 100000, loss: 13.930867
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.590403
 >> iter 2000, loss: 12.840982
 >> iter 3000, loss: 11.347819
 >> iter 4000, loss: 10.976523
 >> iter 5000, loss: 9.940037
 >> iter 6000, loss: 10.052810
 >> iter 7000, loss: 10.227257
 >> iter 8000, loss: 10.099215
 >> iter 9000, loss: 10.504052
 >> iter 10000, loss: 10.476712
   Number of active neurons: 2
 >> iter 11000, loss: 10.204048
 >> iter 12000, loss: 10.043547
 >> iter 13000, loss: 10.198414
 >> iter 14000, loss: 10.200864
 >> iter 15000, loss: 10.013196
 >> iter 16000, loss: 9.727269
 >> iter 17000, loss: 9.485849
 >> iter 18000, loss: 10.040763
 >> iter 19000, loss: 10.135229
 >> iter 20000, loss: 10.444789
   Number of active neurons: 2
 >> iter 21000, loss: 10.877655
 >> iter 22000, loss: 10.302333
 >> iter 23000, loss: 10.712286
 >> iter 24000, loss: 11.422222
 >> iter 25000, loss: 10.947707
 >> iter 26000, loss: 10.809106
 >> iter 27000, loss: 10.547349
 >> iter 28000, loss: 10.599447
 >> iter 29000, loss: 10.121884
 >> iter 30000, loss: 9.788999
   Number of active neurons: 2
 >> iter 31000, loss: 10.241554
 >> iter 32000, loss: 10.447006
 >> iter 33000, loss: 10.831935
 >> iter 34000, loss: 10.193430
 >> iter 35000, loss: 10.693735
 >> iter 36000, loss: 11.061307
 >> iter 37000, loss: 10.657463
 >> iter 38000, loss: 10.507032
 >> iter 39000, loss: 11.622014
 >> iter 40000, loss: 10.749966
   Number of active neurons: 2
 >> iter 41000, loss: 10.905224
 >> iter 42000, loss: 10.489027
 >> iter 43000, loss: 11.278037
 >> iter 44000, loss: 10.749269
 >> iter 45000, loss: 11.206830
 >> iter 46000, loss: 10.071103
 >> iter 47000, loss: 11.382918
 >> iter 48000, loss: 12.659306
 >> iter 49000, loss: 12.664211
 >> iter 50000, loss: 13.049672
   Number of active neurons: 2
 >> iter 51000, loss: 12.506068
 >> iter 52000, loss: 10.642693
 >> iter 53000, loss: 11.082494
 >> iter 54000, loss: 12.430444
 >> iter 55000, loss: 13.515004
 >> iter 56000, loss: 12.559905
 >> iter 57000, loss: 11.129656
 >> iter 58000, loss: 10.434995
 >> iter 59000, loss: 11.666076
 >> iter 60000, loss: 12.635255
   Number of active neurons: 2
 >> iter 61000, loss: 13.257960
 >> iter 62000, loss: 13.223824
 >> iter 63000, loss: 13.486604
 >> iter 64000, loss: 14.364647
 >> iter 65000, loss: 14.721295
 >> iter 66000, loss: 15.420251
 >> iter 67000, loss: 14.488605
 >> iter 68000, loss: 14.741051
 >> iter 69000, loss: 13.510137
 >> iter 70000, loss: 14.207072
   Number of active neurons: 2
 >> iter 71000, loss: 16.267153
 >> iter 72000, loss: 16.201591
 >> iter 73000, loss: 14.681238
 >> iter 74000, loss: 13.021726
 >> iter 75000, loss: 11.661460
 >> iter 76000, loss: 12.698105
 >> iter 77000, loss: 12.829896
 >> iter 78000, loss: 14.878103
 >> iter 79000, loss: 13.854936
 >> iter 80000, loss: 11.107637
   Number of active neurons: 2
 >> iter 81000, loss: 10.612275
 >> iter 82000, loss: 13.039756
 >> iter 83000, loss: 12.188829
 >> iter 84000, loss: 15.670679
 >> iter 85000, loss: 15.145796
 >> iter 86000, loss: 16.752406
 >> iter 87000, loss: 15.292954
 >> iter 88000, loss: 15.444314
 >> iter 89000, loss: 15.418651
 >> iter 90000, loss: 12.770482
   Number of active neurons: 2
 >> iter 91000, loss: 13.019069
 >> iter 92000, loss: 13.052560
 >> iter 93000, loss: 15.431390
 >> iter 94000, loss: 15.548594
 >> iter 95000, loss: 16.554194
 >> iter 96000, loss: 14.660663
 >> iter 97000, loss: 14.612361
 >> iter 98000, loss: 14.932012
 >> iter 99000, loss: 16.306315
 >> iter 100000, loss: 15.741968
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 43.6591268175
   - Test - Long: 62.9568521574
   - Test - Big: 43.5015649844
   - Test - A: 19.1920538631
   - Test - B: 63.5090993934
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.468855
 >> iter 2000, loss: 12.818798
 >> iter 3000, loss: 11.544195
 >> iter 4000, loss: 10.834860
 >> iter 5000, loss: 10.462781
 >> iter 6000, loss: 10.168280
 >> iter 7000, loss: 9.552033
 >> iter 8000, loss: 9.387723
 >> iter 9000, loss: 9.979416
 >> iter 10000, loss: 10.619225
   Number of active neurons: 2
 >> iter 11000, loss: 10.821104
 >> iter 12000, loss: 10.909379
 >> iter 13000, loss: 10.690698
 >> iter 14000, loss: 10.691188
 >> iter 15000, loss: 10.722516
 >> iter 16000, loss: 10.022141
 >> iter 17000, loss: 10.608466
 >> iter 18000, loss: 10.105541
 >> iter 19000, loss: 10.570913
 >> iter 20000, loss: 10.053517
   Number of active neurons: 2
 >> iter 21000, loss: 10.654066
 >> iter 22000, loss: 10.854840
 >> iter 23000, loss: 11.187971
 >> iter 24000, loss: 11.142341
 >> iter 25000, loss: 11.178338
 >> iter 26000, loss: 11.398755
 >> iter 27000, loss: 11.246429
 >> iter 28000, loss: 10.772272
 >> iter 29000, loss: 10.754750
 >> iter 30000, loss: 11.411275
   Number of active neurons: 2
 >> iter 31000, loss: 11.009607
 >> iter 32000, loss: 11.514047
 >> iter 33000, loss: 11.540263
 >> iter 34000, loss: 12.211937
 >> iter 35000, loss: 13.034610
 >> iter 36000, loss: 11.370650
 >> iter 37000, loss: 11.844688
 >> iter 38000, loss: 11.775103
 >> iter 39000, loss: 13.398037
 >> iter 40000, loss: 13.124749
   Number of active neurons: 2
 >> iter 41000, loss: 13.405821
 >> iter 42000, loss: 11.603097
 >> iter 43000, loss: 11.357771
 >> iter 44000, loss: 11.841624
 >> iter 45000, loss: 12.123617
 >> iter 46000, loss: 12.570374
 >> iter 47000, loss: 12.273200
 >> iter 48000, loss: 12.416898
 >> iter 49000, loss: 12.864191
 >> iter 50000, loss: 14.362915
   Number of active neurons: 2
 >> iter 51000, loss: 12.808622
 >> iter 52000, loss: 13.797561
 >> iter 53000, loss: 13.575312
 >> iter 54000, loss: 14.797978
 >> iter 55000, loss: 13.543775
 >> iter 56000, loss: 12.568642
 >> iter 57000, loss: 13.134437
 >> iter 58000, loss: 12.250830
 >> iter 59000, loss: 12.434077
 >> iter 60000, loss: 13.132999
   Number of active neurons: 2
 >> iter 61000, loss: 13.240977
 >> iter 62000, loss: 12.271946
 >> iter 63000, loss: 11.572018
 >> iter 64000, loss: 12.738186
 >> iter 65000, loss: 13.982676
 >> iter 66000, loss: 15.377082
 >> iter 67000, loss: 14.287007
 >> iter 68000, loss: 13.617055
 >> iter 69000, loss: 13.864391
 >> iter 70000, loss: 12.322368
   Number of active neurons: 2
 >> iter 71000, loss: 12.059747
 >> iter 72000, loss: 13.116195
 >> iter 73000, loss: 14.496581
 >> iter 74000, loss: 14.013864
 >> iter 75000, loss: 14.942111
 >> iter 76000, loss: 13.675799
 >> iter 77000, loss: 14.918124
 >> iter 78000, loss: 15.425656
 >> iter 79000, loss: 14.487983
 >> iter 80000, loss: 12.390485
   Number of active neurons: 2
 >> iter 81000, loss: 14.296119
 >> iter 82000, loss: 15.096210
 >> iter 83000, loss: 15.078449
 >> iter 84000, loss: 12.868379
 >> iter 85000, loss: 13.669521
 >> iter 86000, loss: 13.611465
 >> iter 87000, loss: 13.691723
 >> iter 88000, loss: 14.991517
 >> iter 89000, loss: 15.833100
 >> iter 90000, loss: 13.830870
   Number of active neurons: 2
 >> iter 91000, loss: 13.300385
 >> iter 92000, loss: 14.885913
 >> iter 93000, loss: 13.336227
 >> iter 94000, loss: 13.628881
 >> iter 95000, loss: 13.914957
 >> iter 96000, loss: 14.620746
 >> iter 97000, loss: 15.658175
 >> iter 98000, loss: 14.066984
 >> iter 99000, loss: 14.527005
 >> iter 100000, loss: 15.561721
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 9.7578048439
   - Test - Long: 2.1598920054
   - Test - Big: 9.91790082099
   - Test - A: 72.5484967669
   - Test - B: 65.2489834011
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.840330
 >> iter 2000, loss: 12.473169
 >> iter 3000, loss: 11.033269
 >> iter 4000, loss: 10.360395
 >> iter 5000, loss: 10.177056
 >> iter 6000, loss: 9.995083
 >> iter 7000, loss: 10.310514
 >> iter 8000, loss: 10.331742
 >> iter 9000, loss: 10.622955
 >> iter 10000, loss: 10.862090
   Number of active neurons: 2
 >> iter 11000, loss: 11.316249
 >> iter 12000, loss: 11.560138
 >> iter 13000, loss: 11.432165
 >> iter 14000, loss: 11.540591
 >> iter 15000, loss: 11.874313
 >> iter 16000, loss: 11.347066
 >> iter 17000, loss: 12.330846
 >> iter 18000, loss: 12.032488
 >> iter 19000, loss: 12.351398
 >> iter 20000, loss: 11.274429
   Number of active neurons: 2
 >> iter 21000, loss: 12.520556
 >> iter 22000, loss: 12.083738
 >> iter 23000, loss: 11.723968
 >> iter 24000, loss: 12.031746
 >> iter 25000, loss: 13.861500
 >> iter 26000, loss: 13.130758
 >> iter 27000, loss: 13.315231
 >> iter 28000, loss: 11.573061
 >> iter 29000, loss: 12.136838
 >> iter 30000, loss: 12.642529
   Number of active neurons: 2
 >> iter 31000, loss: 13.729552
 >> iter 32000, loss: 12.083550
 >> iter 33000, loss: 13.588687
 >> iter 34000, loss: 14.066002
 >> iter 35000, loss: 14.019222
 >> iter 36000, loss: 13.517350
 >> iter 37000, loss: 13.144118
 >> iter 38000, loss: 12.066052
 >> iter 39000, loss: 12.600534
 >> iter 40000, loss: 12.964417
   Number of active neurons: 2
 >> iter 41000, loss: 13.814641
 >> iter 42000, loss: 12.700180
 >> iter 43000, loss: 12.606076
 >> iter 44000, loss: 14.002917
 >> iter 45000, loss: 13.619705
 >> iter 46000, loss: 13.253314
 >> iter 47000, loss: 13.227926
 >> iter 48000, loss: 13.472294
 >> iter 49000, loss: 13.599749
 >> iter 50000, loss: 14.003372
   Number of active neurons: 2
 >> iter 51000, loss: 13.304992
 >> iter 52000, loss: 11.823759
 >> iter 53000, loss: 11.499428
 >> iter 54000, loss: 11.839030
 >> iter 55000, loss: 11.804453
 >> iter 56000, loss: 13.298902
 >> iter 57000, loss: 14.797422
 >> iter 58000, loss: 13.333440
 >> iter 59000, loss: 13.675223
 >> iter 60000, loss: 13.746059
   Number of active neurons: 2
 >> iter 61000, loss: 13.568444
 >> iter 62000, loss: 14.279107
 >> iter 63000, loss: 14.074428
 >> iter 64000, loss: 14.724936
 >> iter 65000, loss: 13.918981
 >> iter 66000, loss: 14.098420
 >> iter 67000, loss: 14.458607
 >> iter 68000, loss: 13.176013
 >> iter 69000, loss: 13.064303
 >> iter 70000, loss: 12.688028
   Number of active neurons: 2
 >> iter 71000, loss: 14.518902
 >> iter 72000, loss: 14.853103
 >> iter 73000, loss: 13.075355
 >> iter 74000, loss: 12.879065
 >> iter 75000, loss: 14.800074
 >> iter 76000, loss: 14.366685
 >> iter 77000, loss: 14.928609
 >> iter 78000, loss: 16.077611
 >> iter 79000, loss: 15.779911
 >> iter 80000, loss: 14.385478
   Number of active neurons: 2
 >> iter 81000, loss: 14.796617
 >> iter 82000, loss: 14.824956
 >> iter 83000, loss: 15.284708
 >> iter 84000, loss: 13.175018
 >> iter 85000, loss: 13.517161
 >> iter 86000, loss: 12.051075
 >> iter 87000, loss: 13.641313
 >> iter 88000, loss: 13.411633
 >> iter 89000, loss: 12.309618
 >> iter 90000, loss: 13.993178
   Number of active neurons: 2
 >> iter 91000, loss: 14.377106
 >> iter 92000, loss: 13.443169
 >> iter 93000, loss: 13.019416
 >> iter 94000, loss: 13.549494
 >> iter 95000, loss: 15.076059
 >> iter 96000, loss: 15.905618
 >> iter 97000, loss: 14.761691
 >> iter 98000, loss: 14.364146
 >> iter 99000, loss: 15.099193
 >> iter 100000, loss: 14.393748
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.677346
 >> iter 2000, loss: 13.284415
 >> iter 3000, loss: 11.736155
 >> iter 4000, loss: 10.586924
 >> iter 5000, loss: 10.099262
 >> iter 6000, loss: 10.516167
 >> iter 7000, loss: 10.357509
 >> iter 8000, loss: 10.732649
 >> iter 9000, loss: 10.237745
 >> iter 10000, loss: 9.223058
   Number of active neurons: 2
 >> iter 11000, loss: 9.100481
 >> iter 12000, loss: 9.319745
 >> iter 13000, loss: 9.358676
 >> iter 14000, loss: 9.566411
 >> iter 15000, loss: 10.201409
 >> iter 16000, loss: 9.398889
 >> iter 17000, loss: 9.972052
 >> iter 18000, loss: 9.885825
 >> iter 19000, loss: 9.759049
 >> iter 20000, loss: 9.437959
   Number of active neurons: 2
 >> iter 21000, loss: 9.754832
 >> iter 22000, loss: 9.511907
 >> iter 23000, loss: 9.297733
 >> iter 24000, loss: 9.645876
 >> iter 25000, loss: 10.180120
 >> iter 26000, loss: 10.016574
 >> iter 27000, loss: 10.631786
 >> iter 28000, loss: 11.561974
 >> iter 29000, loss: 10.782097
 >> iter 30000, loss: 11.469142
   Number of active neurons: 2
 >> iter 31000, loss: 10.696393
 >> iter 32000, loss: 11.710538
 >> iter 33000, loss: 11.068295
 >> iter 34000, loss: 10.751283
 >> iter 35000, loss: 13.207228
 >> iter 36000, loss: 12.743764
 >> iter 37000, loss: 12.248563
 >> iter 38000, loss: 11.731256
 >> iter 39000, loss: 10.454548
 >> iter 40000, loss: 11.101926
   Number of active neurons: 2
 >> iter 41000, loss: 11.675853
 >> iter 42000, loss: 11.564461
 >> iter 43000, loss: 10.928055
 >> iter 44000, loss: 14.182001
 >> iter 45000, loss: 13.754778
 >> iter 46000, loss: 14.075359
 >> iter 47000, loss: 11.282032
 >> iter 48000, loss: 11.247183
 >> iter 49000, loss: 11.526644
 >> iter 50000, loss: 10.803915
   Number of active neurons: 2
 >> iter 51000, loss: 11.463773
 >> iter 52000, loss: 15.010637
 >> iter 53000, loss: 12.852497
 >> iter 54000, loss: 13.881266
 >> iter 55000, loss: 15.767819
 >> iter 56000, loss: 11.839065
 >> iter 57000, loss: 12.961065
 >> iter 58000, loss: 14.188545
 >> iter 59000, loss: 13.662118
 >> iter 60000, loss: 13.581778
   Number of active neurons: 2
 >> iter 61000, loss: 12.356432
 >> iter 62000, loss: 11.907768
 >> iter 63000, loss: 12.503838
 >> iter 64000, loss: 14.740747
 >> iter 65000, loss: 15.272701
 >> iter 66000, loss: 15.387480
 >> iter 67000, loss: 15.553885
 >> iter 68000, loss: 15.421982
 >> iter 69000, loss: 16.307894
 >> iter 70000, loss: 17.188119
   Number of active neurons: 2
 >> iter 71000, loss: 14.725600
 >> iter 72000, loss: 11.982477
 >> iter 73000, loss: 13.291792
 >> iter 74000, loss: 12.484934
 >> iter 75000, loss: 11.711491
 >> iter 76000, loss: 12.286759
 >> iter 77000, loss: 13.457295
 >> iter 78000, loss: 13.912549
 >> iter 79000, loss: 16.215982
 >> iter 80000, loss: 17.126307
   Number of active neurons: 2
 >> iter 81000, loss: 14.694744
 >> iter 82000, loss: 14.760120
 >> iter 83000, loss: 13.659127
 >> iter 84000, loss: 14.313824
 >> iter 85000, loss: 14.853515
 >> iter 86000, loss: 13.045211
 >> iter 87000, loss: 11.828318
 >> iter 88000, loss: 12.207886
 >> iter 89000, loss: 12.958638
 >> iter 90000, loss: 13.521012
   Number of active neurons: 2
 >> iter 91000, loss: 12.756660
 >> iter 92000, loss: 12.637875
 >> iter 93000, loss: 12.191157
 >> iter 94000, loss: 13.698052
 >> iter 95000, loss: 13.003615
 >> iter 96000, loss: 15.969623
 >> iter 97000, loss: 15.717348
 >> iter 98000, loss: 15.733297
 >> iter 99000, loss: 15.408740
 >> iter 100000, loss: 14.543836
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 10.8937821244
   - Test - Long: 2.28988550572
   - Test - Big: 10.8268917311
   - Test - A: 73.5617625492
   - Test - B: 65.2689820679
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.967051
 >> iter 2000, loss: 12.187558
 >> iter 3000, loss: 10.751085
 >> iter 4000, loss: 9.829832
 >> iter 5000, loss: 10.108639
 >> iter 6000, loss: 9.150800
 >> iter 7000, loss: 9.191906
 >> iter 8000, loss: 8.804787
 >> iter 9000, loss: 9.092715
 >> iter 10000, loss: 9.075047
   Number of active neurons: 2
 >> iter 11000, loss: 9.317458
 >> iter 12000, loss: 9.561068
 >> iter 13000, loss: 10.282581
 >> iter 14000, loss: 10.451276
 >> iter 15000, loss: 9.807926
 >> iter 16000, loss: 10.284788
 >> iter 17000, loss: 10.078728
 >> iter 18000, loss: 9.999874
 >> iter 19000, loss: 8.825447
 >> iter 20000, loss: 8.888074
   Number of active neurons: 2
 >> iter 21000, loss: 9.911804
 >> iter 22000, loss: 9.245346
 >> iter 23000, loss: 8.668794
 >> iter 24000, loss: 10.012855
 >> iter 25000, loss: 10.473664
 >> iter 26000, loss: 11.101975
 >> iter 27000, loss: 11.566856
 >> iter 28000, loss: 10.401253
 >> iter 29000, loss: 9.877754
 >> iter 30000, loss: 9.658638
   Number of active neurons: 2
 >> iter 31000, loss: 9.289021
 >> iter 32000, loss: 8.742173
 >> iter 33000, loss: 9.360265
 >> iter 34000, loss: 9.446198
 >> iter 35000, loss: 9.197949
 >> iter 36000, loss: 10.642152
 >> iter 37000, loss: 9.825993
 >> iter 38000, loss: 8.496831
 >> iter 39000, loss: 8.410091
 >> iter 40000, loss: 7.636367
   Number of active neurons: 2
 >> iter 41000, loss: 6.709062
 >> iter 42000, loss: 5.706875
 >> iter 43000, loss: 5.449405
 >> iter 44000, loss: 4.975274
 >> iter 45000, loss: 5.051244
 >> iter 46000, loss: 5.025347
 >> iter 47000, loss: 5.366757
 >> iter 48000, loss: 4.970149
 >> iter 49000, loss: 4.993233
 >> iter 50000, loss: 5.199989
   Number of active neurons: 2
 >> iter 51000, loss: 5.275647
 >> iter 52000, loss: 5.031483
 >> iter 53000, loss: 6.392275
 >> iter 54000, loss: 6.549114
 >> iter 55000, loss: 5.529601
 >> iter 56000, loss: 4.950794
 >> iter 57000, loss: 5.143888
 >> iter 58000, loss: 4.804812
 >> iter 59000, loss: 4.831504
 >> iter 60000, loss: 4.749658
   Number of active neurons: 2
 >> iter 61000, loss: 5.367511
 >> iter 62000, loss: 4.921523
 >> iter 63000, loss: 4.806843
 >> iter 64000, loss: 4.542494
 >> iter 65000, loss: 4.852511
 >> iter 66000, loss: 4.661561
 >> iter 67000, loss: 5.443328
 >> iter 68000, loss: 5.159158
 >> iter 69000, loss: 5.027341
 >> iter 70000, loss: 4.764301
   Number of active neurons: 2
 >> iter 71000, loss: 4.576563
 >> iter 72000, loss: 4.497205
 >> iter 73000, loss: 4.862062
 >> iter 74000, loss: 4.746455
 >> iter 75000, loss: 4.884616
 >> iter 76000, loss: 4.725273
 >> iter 77000, loss: 4.823866
 >> iter 78000, loss: 4.763956
 >> iter 79000, loss: 5.084589
 >> iter 80000, loss: 6.041187
   Number of active neurons: 2
 >> iter 81000, loss: 5.339818
 >> iter 82000, loss: 5.133760
 >> iter 83000, loss: 5.067725
 >> iter 84000, loss: 4.632042
 >> iter 85000, loss: 4.750581
 >> iter 86000, loss: 4.562589
 >> iter 87000, loss: 4.615418
 >> iter 88000, loss: 4.522976
 >> iter 89000, loss: 4.891258
 >> iter 90000, loss: 4.771208
   Number of active neurons: 2
 >> iter 91000, loss: 4.730955
 >> iter 92000, loss: 4.683073
 >> iter 93000, loss: 4.854068
 >> iter 94000, loss: 4.690539
 >> iter 95000, loss: 4.616937
 >> iter 96000, loss: 4.512546
 >> iter 97000, loss: 4.348671
 >> iter 98000, loss: 4.447303
 >> iter 99000, loss: 4.644577
 >> iter 100000, loss: 4.660464
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 5.52988940221
   - Test - Long: 1.45492725364
   - Test - Big: 6.0139398606
   - Test - A: 26.4382374508
   - Test - B: 21.7185520965
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.626409
 >> iter 2000, loss: 12.608631
 >> iter 3000, loss: 10.274442
 >> iter 4000, loss: 9.309741
 >> iter 5000, loss: 9.060823
 >> iter 6000, loss: 8.916110
 >> iter 7000, loss: 10.060451
 >> iter 8000, loss: 10.606959
 >> iter 9000, loss: 11.281437
 >> iter 10000, loss: 9.953573
   Number of active neurons: 2
 >> iter 11000, loss: 11.159987
 >> iter 12000, loss: 9.815454
 >> iter 13000, loss: 9.583353
 >> iter 14000, loss: 12.550990
 >> iter 15000, loss: 10.728882
 >> iter 16000, loss: 9.968301
 >> iter 17000, loss: 11.318798
 >> iter 18000, loss: 11.276065
 >> iter 19000, loss: 10.037057
 >> iter 20000, loss: 12.030111
   Number of active neurons: 2
 >> iter 21000, loss: 11.304703
 >> iter 22000, loss: 13.946419
 >> iter 23000, loss: 15.772773
 >> iter 24000, loss: 17.002578
 >> iter 25000, loss: 14.712171
 >> iter 26000, loss: 12.662480
 >> iter 27000, loss: 11.779358
 >> iter 28000, loss: 11.016705
 >> iter 29000, loss: 14.825326
 >> iter 30000, loss: 16.649037
   Number of active neurons: 2
 >> iter 31000, loss: 17.253723
 >> iter 32000, loss: 13.774017
 >> iter 33000, loss: 11.353416
 >> iter 34000, loss: 10.731136
 >> iter 35000, loss: 13.796695
 >> iter 36000, loss: 13.346815
 >> iter 37000, loss: 11.299436
 >> iter 38000, loss: 12.135380
 >> iter 39000, loss: 12.381773
 >> iter 40000, loss: 11.387970
   Number of active neurons: 2
 >> iter 41000, loss: 12.239736
 >> iter 42000, loss: 14.875226
 >> iter 43000, loss: 14.572125
 >> iter 44000, loss: 16.124313
 >> iter 45000, loss: 15.170465
 >> iter 46000, loss: 12.200645
 >> iter 47000, loss: 12.653212
 >> iter 48000, loss: 14.981202
 >> iter 49000, loss: 16.011837
 >> iter 50000, loss: 15.136798
   Number of active neurons: 2
 >> iter 51000, loss: 16.705786
 >> iter 52000, loss: 17.336590
 >> iter 53000, loss: 17.513426
 >> iter 54000, loss: 13.109820
 >> iter 55000, loss: 14.021439
 >> iter 56000, loss: 13.160124
 >> iter 57000, loss: 13.153718
 >> iter 58000, loss: 14.402324
 >> iter 59000, loss: 13.254649
 >> iter 60000, loss: 15.621354
   Number of active neurons: 2
 >> iter 61000, loss: 15.458617
 >> iter 62000, loss: 15.385281
 >> iter 63000, loss: 16.800836
 >> iter 64000, loss: 17.369026
 >> iter 65000, loss: 16.869157
 >> iter 66000, loss: 17.395408
 >> iter 67000, loss: 17.537896
 >> iter 68000, loss: 15.044166
 >> iter 69000, loss: 13.836367
 >> iter 70000, loss: 16.280166
   Number of active neurons: 2
 >> iter 71000, loss: 17.128742
 >> iter 72000, loss: 17.490780
 >> iter 73000, loss: 17.571975
 >> iter 74000, loss: 17.655720
 >> iter 75000, loss: 17.628869
 >> iter 76000, loss: 17.677187
 >> iter 77000, loss: 17.635531
 >> iter 78000, loss: 17.679047
 >> iter 79000, loss: 17.637624
 >> iter 80000, loss: 16.058175
   Number of active neurons: 2
 >> iter 81000, loss: 14.191600
 >> iter 82000, loss: 14.532885
 >> iter 83000, loss: 16.480730
 >> iter 84000, loss: 17.251853
 >> iter 85000, loss: 17.478127
 >> iter 86000, loss: 17.614116
 >> iter 87000, loss: 17.612688
 >> iter 88000, loss: 16.305493
 >> iter 89000, loss: 16.610192
 >> iter 90000, loss: 17.290326
   Number of active neurons: 2
 >> iter 91000, loss: 14.796363
 >> iter 92000, loss: 16.616918
 >> iter 93000, loss: 17.251636
 >> iter 94000, loss: 17.533320
 >> iter 95000, loss: 14.690285
 >> iter 96000, loss: 16.591044
 >> iter 97000, loss: 17.242485
 >> iter 98000, loss: 17.525609
 >> iter 99000, loss: 17.585313
 >> iter 100000, loss: 17.661767
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.184395
 >> iter 2000, loss: 11.691526
 >> iter 3000, loss: 9.645871
 >> iter 4000, loss: 9.003273
 >> iter 5000, loss: 8.939679
 >> iter 6000, loss: 8.765581
 >> iter 7000, loss: 8.950108
 >> iter 8000, loss: 9.000075
 >> iter 9000, loss: 8.752539
 >> iter 10000, loss: 8.760269
   Number of active neurons: 2
 >> iter 11000, loss: 8.797245
 >> iter 12000, loss: 9.328032
 >> iter 13000, loss: 8.674650
 >> iter 14000, loss: 8.927240
 >> iter 15000, loss: 9.420493
 >> iter 16000, loss: 9.558853
 >> iter 17000, loss: 10.174095
 >> iter 18000, loss: 10.258777
 >> iter 19000, loss: 10.769892
 >> iter 20000, loss: 11.435403
   Number of active neurons: 2
 >> iter 21000, loss: 11.805424
 >> iter 22000, loss: 12.146156
 >> iter 23000, loss: 11.648672
 >> iter 24000, loss: 12.693982
 >> iter 25000, loss: 13.121010
 >> iter 26000, loss: 13.372723
 >> iter 27000, loss: 12.657528
 >> iter 28000, loss: 12.602154
 >> iter 29000, loss: 12.643895
 >> iter 30000, loss: 12.268029
   Number of active neurons: 2
 >> iter 31000, loss: 12.402907
 >> iter 32000, loss: 11.708861
 >> iter 33000, loss: 12.707983
 >> iter 34000, loss: 12.622251
 >> iter 35000, loss: 13.317388
 >> iter 36000, loss: 12.806628
 >> iter 37000, loss: 13.166143
 >> iter 38000, loss: 13.209993
 >> iter 39000, loss: 13.306485
 >> iter 40000, loss: 12.727961
   Number of active neurons: 2
 >> iter 41000, loss: 12.806568
 >> iter 42000, loss: 13.862939
 >> iter 43000, loss: 14.574144
 >> iter 44000, loss: 14.001002
 >> iter 45000, loss: 13.986299
 >> iter 46000, loss: 12.995331
 >> iter 47000, loss: 13.444676
 >> iter 48000, loss: 13.621861
 >> iter 49000, loss: 12.631474
 >> iter 50000, loss: 12.885750
   Number of active neurons: 2
 >> iter 51000, loss: 13.590207
 >> iter 52000, loss: 14.336934
 >> iter 53000, loss: 14.469036
 >> iter 54000, loss: 14.597607
 >> iter 55000, loss: 13.871388
 >> iter 56000, loss: 14.458064
 >> iter 57000, loss: 14.043174
 >> iter 58000, loss: 14.474942
 >> iter 59000, loss: 14.372876
 >> iter 60000, loss: 14.213337
   Number of active neurons: 2
 >> iter 61000, loss: 14.595498
 >> iter 62000, loss: 14.871788
 >> iter 63000, loss: 14.166190
 >> iter 64000, loss: 14.431476
 >> iter 65000, loss: 14.470246
 >> iter 66000, loss: 14.185546
 >> iter 67000, loss: 14.202590
 >> iter 68000, loss: 13.279189
 >> iter 69000, loss: 14.518625
 >> iter 70000, loss: 13.521930
   Number of active neurons: 2
 >> iter 71000, loss: 13.914812
 >> iter 72000, loss: 14.779843
 >> iter 73000, loss: 14.155426
 >> iter 74000, loss: 13.856103
 >> iter 75000, loss: 13.858128
 >> iter 76000, loss: 14.046728
 >> iter 77000, loss: 14.334493
 >> iter 78000, loss: 14.011870
 >> iter 79000, loss: 13.824353
 >> iter 80000, loss: 14.187730
   Number of active neurons: 2
 >> iter 81000, loss: 13.978140
 >> iter 82000, loss: 13.421235
 >> iter 83000, loss: 14.380431
 >> iter 84000, loss: 14.923587
 >> iter 85000, loss: 15.025751
 >> iter 86000, loss: 14.130817
 >> iter 87000, loss: 13.767543
 >> iter 88000, loss: 13.877985
 >> iter 89000, loss: 13.614181
 >> iter 90000, loss: 13.551736
   Number of active neurons: 2
 >> iter 91000, loss: 13.756901
 >> iter 92000, loss: 14.434597
 >> iter 93000, loss: 14.870409
 >> iter 94000, loss: 14.366811
 >> iter 95000, loss: 14.944081
 >> iter 96000, loss: 15.170704
 >> iter 97000, loss: 15.158467
 >> iter 98000, loss: 15.008442
 >> iter 99000, loss: 15.060361
 >> iter 100000, loss: 14.266964
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 55.4163055796
   - Test - B: 29.618025465

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

