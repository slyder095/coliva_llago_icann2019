 > Problema: tomita1nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 1e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.771788
 >> iter 2000, loss: 3.972183
 >> iter 3000, loss: 1.467380
 >> iter 4000, loss: 0.544466
 >> iter 5000, loss: 0.204312
 >> iter 6000, loss: 0.078605
 >> iter 7000, loss: 0.032091
 >> iter 8000, loss: 0.014660
 >> iter 9000, loss: 0.008125
 >> iter 10000, loss: 0.005512
   Number of active neurons: 5
 >> iter 11000, loss: 0.004495
 >> iter 12000, loss: 0.003968
 >> iter 13000, loss: 0.003755
 >> iter 14000, loss: 0.003551
 >> iter 15000, loss: 0.003473
 >> iter 16000, loss: 0.003338
 >> iter 17000, loss: 0.003293
 >> iter 18000, loss: 0.003179
 >> iter 19000, loss: 0.003138
 >> iter 20000, loss: 0.003038
   Number of active neurons: 5
 >> iter 21000, loss: 0.003009
 >> iter 22000, loss: 0.002920
 >> iter 23000, loss: 0.002899
 >> iter 24000, loss: 0.002817
 >> iter 25000, loss: 0.002804
 >> iter 26000, loss: 0.002734
 >> iter 27000, loss: 0.002726
 >> iter 28000, loss: 0.002664
 >> iter 29000, loss: 0.002660
 >> iter 30000, loss: 0.002605
   Number of active neurons: 5
 >> iter 31000, loss: 0.002605
 >> iter 32000, loss: 0.002555
 >> iter 33000, loss: 0.002559
 >> iter 34000, loss: 0.002513
 >> iter 35000, loss: 0.002522
 >> iter 36000, loss: 0.002477
 >> iter 37000, loss: 0.002488
 >> iter 38000, loss: 0.002445
 >> iter 39000, loss: 0.002458
 >> iter 40000, loss: 0.002416
   Number of active neurons: 4
 >> iter 41000, loss: 0.002431
 >> iter 42000, loss: 0.002392
 >> iter 43000, loss: 0.002405
 >> iter 44000, loss: 0.002370
 >> iter 45000, loss: 0.002385
 >> iter 46000, loss: 0.002349
 >> iter 47000, loss: 0.002364
 >> iter 48000, loss: 0.002331
 >> iter 49000, loss: 0.002347
 >> iter 50000, loss: 0.002312
   Number of active neurons: 3
 >> iter 51000, loss: 0.002328
 >> iter 52000, loss: 0.002295
 >> iter 53000, loss: 0.002310
 >> iter 54000, loss: 0.002283
 >> iter 55000, loss: 0.002293
 >> iter 56000, loss: 0.002268
 >> iter 57000, loss: 0.002281
 >> iter 58000, loss: 0.002252
 >> iter 59000, loss: 0.002266
 >> iter 60000, loss: 0.002239
   Number of active neurons: 3
 >> iter 61000, loss: 0.002252
 >> iter 62000, loss: 0.002226
 >> iter 63000, loss: 0.002238
 >> iter 64000, loss: 0.002210
 >> iter 65000, loss: 0.002224
 >> iter 66000, loss: 0.002198
 >> iter 67000, loss: 0.002210
 >> iter 68000, loss: 0.002187
 >> iter 69000, loss: 0.002199
 >> iter 70000, loss: 0.002173
   Number of active neurons: 3
 >> iter 71000, loss: 0.002185
 >> iter 72000, loss: 0.002161
 >> iter 73000, loss: 0.002173
 >> iter 74000, loss: 0.002148
 >> iter 75000, loss: 0.002161
 >> iter 76000, loss: 0.002136
 >> iter 77000, loss: 0.002149
 >> iter 78000, loss: 0.002124
 >> iter 79000, loss: 0.002140
 >> iter 80000, loss: 0.002112
   Number of active neurons: 3
 >> iter 81000, loss: 0.002131
 >> iter 82000, loss: 0.002100
 >> iter 83000, loss: 0.002122
 >> iter 84000, loss: 0.002089
 >> iter 85000, loss: 0.002111
 >> iter 86000, loss: 0.002077
 >> iter 87000, loss: 0.002098
 >> iter 88000, loss: 0.002064
 >> iter 89000, loss: 0.002085
 >> iter 90000, loss: 0.002054
   Number of active neurons: 3
 >> iter 91000, loss: 0.002074
 >> iter 92000, loss: 0.002044
 >> iter 93000, loss: 0.002065
 >> iter 94000, loss: 0.002034
 >> iter 95000, loss: 0.002057
 >> iter 96000, loss: 0.002022
 >> iter 97000, loss: 0.002046
 >> iter 98000, loss: 0.002010
 >> iter 99000, loss: 0.002036
 >> iter 100000, loss: 0.002002
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 10.694619
 >> iter 2000, loss: 3.942666
 >> iter 3000, loss: 1.455930
 >> iter 4000, loss: 0.539871
 >> iter 5000, loss: 0.202355
 >> iter 6000, loss: 0.077685
 >> iter 7000, loss: 0.031596
 >> iter 8000, loss: 0.014352
 >> iter 9000, loss: 0.007911
 >> iter 10000, loss: 0.005350
   Number of active neurons: 6
 >> iter 11000, loss: 0.004370
 >> iter 12000, loss: 0.003869
 >> iter 13000, loss: 0.003678
 >> iter 14000, loss: 0.003490
 >> iter 15000, loss: 0.003428
 >> iter 16000, loss: 0.003307
 >> iter 17000, loss: 0.003278
 >> iter 18000, loss: 0.003184
 >> iter 19000, loss: 0.003172
 >> iter 20000, loss: 0.003096
   Number of active neurons: 6
 >> iter 21000, loss: 0.003092
 >> iter 22000, loss: 0.003020
 >> iter 23000, loss: 0.003016
 >> iter 24000, loss: 0.002943
 >> iter 25000, loss: 0.002941
 >> iter 26000, loss: 0.002876
 >> iter 27000, loss: 0.002877
 >> iter 28000, loss: 0.002819
 >> iter 29000, loss: 0.002822
 >> iter 30000, loss: 0.002769
   Number of active neurons: 5
 >> iter 31000, loss: 0.002777
 >> iter 32000, loss: 0.002726
 >> iter 33000, loss: 0.002736
 >> iter 34000, loss: 0.002689
 >> iter 35000, loss: 0.002705
 >> iter 36000, loss: 0.002661
 >> iter 37000, loss: 0.002679
 >> iter 38000, loss: 0.002636
 >> iter 39000, loss: 0.002657
 >> iter 40000, loss: 0.002616
   Number of active neurons: 5
 >> iter 41000, loss: 0.002637
 >> iter 42000, loss: 0.002598
 >> iter 43000, loss: 0.002617
 >> iter 44000, loss: 0.002580
 >> iter 45000, loss: 0.002601
 >> iter 46000, loss: 0.002564
 >> iter 47000, loss: 0.002585
 >> iter 48000, loss: 0.002551
 >> iter 49000, loss: 0.002572
 >> iter 50000, loss: 0.002536
   Number of active neurons: 5
 >> iter 51000, loss: 0.002557
 >> iter 52000, loss: 0.002520
 >> iter 53000, loss: 0.002537
 >> iter 54000, loss: 0.002504
 >> iter 55000, loss: 0.002516
 >> iter 56000, loss: 0.002486
 >> iter 57000, loss: 0.002501
 >> iter 58000, loss: 0.002467
 >> iter 59000, loss: 0.002484
 >> iter 60000, loss: 0.002452
   Number of active neurons: 5
 >> iter 61000, loss: 0.002468
 >> iter 62000, loss: 0.002438
 >> iter 63000, loss: 0.002454
 >> iter 64000, loss: 0.002424
 >> iter 65000, loss: 0.002442
 >> iter 66000, loss: 0.002413
 >> iter 67000, loss: 0.002430
 >> iter 68000, loss: 0.002405
 >> iter 69000, loss: 0.002420
 >> iter 70000, loss: 0.002394
   Number of active neurons: 5
 >> iter 71000, loss: 0.002411
 >> iter 72000, loss: 0.002387
 >> iter 73000, loss: 0.002403
 >> iter 74000, loss: 0.002378
 >> iter 75000, loss: 0.002396
 >> iter 76000, loss: 0.002371
 >> iter 77000, loss: 0.002387
 >> iter 78000, loss: 0.002362
 >> iter 79000, loss: 0.002383
 >> iter 80000, loss: 0.002355
   Number of active neurons: 4
 >> iter 81000, loss: 0.002379
 >> iter 82000, loss: 0.002347
 >> iter 83000, loss: 0.002373
 >> iter 84000, loss: 0.002339
 >> iter 85000, loss: 0.002364
 >> iter 86000, loss: 0.002331
 >> iter 87000, loss: 0.002357
 >> iter 88000, loss: 0.002323
 >> iter 89000, loss: 0.002348
 >> iter 90000, loss: 0.002317
   Number of active neurons: 4
 >> iter 91000, loss: 0.002341
 >> iter 92000, loss: 0.002310
 >> iter 93000, loss: 0.002333
 >> iter 94000, loss: 0.002300
 >> iter 95000, loss: 0.002328
 >> iter 96000, loss: 0.002291
 >> iter 97000, loss: 0.002319
 >> iter 98000, loss: 0.002281
 >> iter 99000, loss: 0.002311
 >> iter 100000, loss: 0.002275
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.741640
 >> iter 2000, loss: 3.961461
 >> iter 3000, loss: 1.463646
 >> iter 4000, loss: 0.543241
 >> iter 5000, loss: 0.203966
 >> iter 6000, loss: 0.078560
 >> iter 7000, loss: 0.032134
 >> iter 8000, loss: 0.014724
 >> iter 9000, loss: 0.008180
 >> iter 10000, loss: 0.005559
   Number of active neurons: 7
 >> iter 11000, loss: 0.004527
 >> iter 12000, loss: 0.003991
 >> iter 13000, loss: 0.003762
 >> iter 14000, loss: 0.003551
 >> iter 15000, loss: 0.003463
 >> iter 16000, loss: 0.003328
 >> iter 17000, loss: 0.003282
 >> iter 18000, loss: 0.003180
 >> iter 19000, loss: 0.003153
 >> iter 20000, loss: 0.003072
   Number of active neurons: 6
 >> iter 21000, loss: 0.003052
 >> iter 22000, loss: 0.002975
 >> iter 23000, loss: 0.002963
 >> iter 24000, loss: 0.002895
 >> iter 25000, loss: 0.002892
 >> iter 26000, loss: 0.002835
 >> iter 27000, loss: 0.002836
 >> iter 28000, loss: 0.002786
 >> iter 29000, loss: 0.002791
 >> iter 30000, loss: 0.002747
   Number of active neurons: 5
 >> iter 31000, loss: 0.002756
 >> iter 32000, loss: 0.002716
 >> iter 33000, loss: 0.002728
 >> iter 34000, loss: 0.002691
 >> iter 35000, loss: 0.002707
 >> iter 36000, loss: 0.002671
 >> iter 37000, loss: 0.002689
 >> iter 38000, loss: 0.002653
 >> iter 39000, loss: 0.002672
 >> iter 40000, loss: 0.002636
   Number of active neurons: 5
 >> iter 41000, loss: 0.002656
 >> iter 42000, loss: 0.002623
 >> iter 43000, loss: 0.002641
 >> iter 44000, loss: 0.002611
 >> iter 45000, loss: 0.002629
 >> iter 46000, loss: 0.002598
 >> iter 47000, loss: 0.002616
 >> iter 48000, loss: 0.002587
 >> iter 49000, loss: 0.002606
 >> iter 50000, loss: 0.002576
   Number of active neurons: 4
 >> iter 51000, loss: 0.002596
 >> iter 52000, loss: 0.002568
 >> iter 53000, loss: 0.002585
 >> iter 54000, loss: 0.002559
 >> iter 55000, loss: 0.002571
 >> iter 56000, loss: 0.002548
 >> iter 57000, loss: 0.002562
 >> iter 58000, loss: 0.002535
 >> iter 59000, loss: 0.002550
 >> iter 60000, loss: 0.002523
   Number of active neurons: 4
 >> iter 61000, loss: 0.002536
 >> iter 62000, loss: 0.002510
 >> iter 63000, loss: 0.002523
 >> iter 64000, loss: 0.002495
 >> iter 65000, loss: 0.002510
 >> iter 66000, loss: 0.002483
 >> iter 67000, loss: 0.002495
 >> iter 68000, loss: 0.002470
 >> iter 69000, loss: 0.002479
 >> iter 70000, loss: 0.002452
   Number of active neurons: 3
 >> iter 71000, loss: 0.002463
 >> iter 72000, loss: 0.002438
 >> iter 73000, loss: 0.002448
 >> iter 74000, loss: 0.002422
 >> iter 75000, loss: 0.002432
 >> iter 76000, loss: 0.002405
 >> iter 77000, loss: 0.002414
 >> iter 78000, loss: 0.002386
 >> iter 79000, loss: 0.002399
 >> iter 80000, loss: 0.002369
   Number of active neurons: 3
 >> iter 81000, loss: 0.002385
 >> iter 82000, loss: 0.002352
 >> iter 83000, loss: 0.002369
 >> iter 84000, loss: 0.002333
 >> iter 85000, loss: 0.002349
 >> iter 86000, loss: 0.002314
 >> iter 87000, loss: 0.002331
 >> iter 88000, loss: 0.002296
 >> iter 89000, loss: 0.002313
 >> iter 90000, loss: 0.002280
   Number of active neurons: 3
 >> iter 91000, loss: 0.002295
 >> iter 92000, loss: 0.002262
 >> iter 93000, loss: 0.002277
 >> iter 94000, loss: 0.002243
 >> iter 95000, loss: 0.002263
 >> iter 96000, loss: 0.002226
 >> iter 97000, loss: 0.002247
 >> iter 98000, loss: 0.002209
 >> iter 99000, loss: 0.002231
 >> iter 100000, loss: 0.002196
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.687361
 >> iter 2000, loss: 3.940520
 >> iter 3000, loss: 1.455375
 >> iter 4000, loss: 0.539771
 >> iter 5000, loss: 0.202370
 >> iter 6000, loss: 0.077698
 >> iter 7000, loss: 0.031588
 >> iter 8000, loss: 0.014307
 >> iter 9000, loss: 0.007833
 >> iter 10000, loss: 0.005239
   Number of active neurons: 5
 >> iter 11000, loss: 0.004227
 >> iter 12000, loss: 0.003694
 >> iter 13000, loss: 0.003472
 >> iter 14000, loss: 0.003260
 >> iter 15000, loss: 0.003174
 >> iter 16000, loss: 0.003036
 >> iter 17000, loss: 0.002988
 >> iter 18000, loss: 0.002882
 >> iter 19000, loss: 0.002854
 >> iter 20000, loss: 0.002769
   Number of active neurons: 5
 >> iter 21000, loss: 0.002751
 >> iter 22000, loss: 0.002676
 >> iter 23000, loss: 0.002667
 >> iter 24000, loss: 0.002601
 >> iter 25000, loss: 0.002600
 >> iter 26000, loss: 0.002543
 >> iter 27000, loss: 0.002545
 >> iter 28000, loss: 0.002493
 >> iter 29000, loss: 0.002498
 >> iter 30000, loss: 0.002452
   Number of active neurons: 5
 >> iter 31000, loss: 0.002461
 >> iter 32000, loss: 0.002418
 >> iter 33000, loss: 0.002430
 >> iter 34000, loss: 0.002392
 >> iter 35000, loss: 0.002408
 >> iter 36000, loss: 0.002370
 >> iter 37000, loss: 0.002387
 >> iter 38000, loss: 0.002349
 >> iter 39000, loss: 0.002369
 >> iter 40000, loss: 0.002332
   Number of active neurons: 5
 >> iter 41000, loss: 0.002353
 >> iter 42000, loss: 0.002320
 >> iter 43000, loss: 0.002339
 >> iter 44000, loss: 0.002309
 >> iter 45000, loss: 0.002330
 >> iter 46000, loss: 0.002300
 >> iter 47000, loss: 0.002322
 >> iter 48000, loss: 0.002295
 >> iter 49000, loss: 0.002318
 >> iter 50000, loss: 0.002290
   Number of active neurons: 5
 >> iter 51000, loss: 0.002314
 >> iter 52000, loss: 0.002288
 >> iter 53000, loss: 0.002311
 >> iter 54000, loss: 0.002289
 >> iter 55000, loss: 0.002307
 >> iter 56000, loss: 0.002288
 >> iter 57000, loss: 0.002307
 >> iter 58000, loss: 0.002283
 >> iter 59000, loss: 0.002305
 >> iter 60000, loss: 0.002283
   Number of active neurons: 5
 >> iter 61000, loss: 0.002304
 >> iter 62000, loss: 0.002285
 >> iter 63000, loss: 0.002306
 >> iter 64000, loss: 0.002285
 >> iter 65000, loss: 0.002308
 >> iter 66000, loss: 0.002287
 >> iter 67000, loss: 0.002308
 >> iter 68000, loss: 0.002290
 >> iter 69000, loss: 0.002310
 >> iter 70000, loss: 0.002290
   Number of active neurons: 5
 >> iter 71000, loss: 0.002310
 >> iter 72000, loss: 0.002291
 >> iter 73000, loss: 0.002311
 >> iter 74000, loss: 0.002291
 >> iter 75000, loss: 0.002311
 >> iter 76000, loss: 0.002291
 >> iter 77000, loss: 0.002311
 >> iter 78000, loss: 0.002290
 >> iter 79000, loss: 0.002313
 >> iter 80000, loss: 0.002290
   Number of active neurons: 5
 >> iter 81000, loss: 0.002317
 >> iter 82000, loss: 0.002289
 >> iter 83000, loss: 0.002319
 >> iter 84000, loss: 0.002289
 >> iter 85000, loss: 0.002317
 >> iter 86000, loss: 0.002287
 >> iter 87000, loss: 0.002317
 >> iter 88000, loss: 0.002286
 >> iter 89000, loss: 0.002315
 >> iter 90000, loss: 0.002287
   Number of active neurons: 4
 >> iter 91000, loss: 0.002314
 >> iter 92000, loss: 0.002287
 >> iter 93000, loss: 0.002314
 >> iter 94000, loss: 0.002285
 >> iter 95000, loss: 0.002317
 >> iter 96000, loss: 0.002284
 >> iter 97000, loss: 0.002316
 >> iter 98000, loss: 0.002282
 >> iter 99000, loss: 0.002315
 >> iter 100000, loss: 0.002283
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.684187
 >> iter 2000, loss: 3.941585
 >> iter 3000, loss: 1.456992
 >> iter 4000, loss: 0.541204
 >> iter 5000, loss: 0.203497
 >> iter 6000, loss: 0.078588
 >> iter 7000, loss: 0.032286
 >> iter 8000, loss: 0.014885
 >> iter 9000, loss: 0.008308
 >> iter 10000, loss: 0.005653
   Number of active neurons: 4
 >> iter 11000, loss: 0.004582
 >> iter 12000, loss: 0.004019
 >> iter 13000, loss: 0.003765
 >> iter 14000, loss: 0.003541
 >> iter 15000, loss: 0.003436
 >> iter 16000, loss: 0.003292
 >> iter 17000, loss: 0.003230
 >> iter 18000, loss: 0.003119
 >> iter 19000, loss: 0.003077
 >> iter 20000, loss: 0.002990
   Number of active neurons: 4
 >> iter 21000, loss: 0.002961
 >> iter 22000, loss: 0.002887
 >> iter 23000, loss: 0.002870
 >> iter 24000, loss: 0.002806
 >> iter 25000, loss: 0.002797
 >> iter 26000, loss: 0.002741
 >> iter 27000, loss: 0.002737
 >> iter 28000, loss: 0.002687
 >> iter 29000, loss: 0.002684
 >> iter 30000, loss: 0.002638
   Number of active neurons: 4
 >> iter 31000, loss: 0.002639
 >> iter 32000, loss: 0.002596
 >> iter 33000, loss: 0.002600
 >> iter 34000, loss: 0.002560
 >> iter 35000, loss: 0.002568
 >> iter 36000, loss: 0.002528
 >> iter 37000, loss: 0.002537
 >> iter 38000, loss: 0.002498
 >> iter 39000, loss: 0.002508
 >> iter 40000, loss: 0.002468
   Number of active neurons: 3
 >> iter 41000, loss: 0.002479
 >> iter 42000, loss: 0.002442
 >> iter 43000, loss: 0.002452
 >> iter 44000, loss: 0.002417
 >> iter 45000, loss: 0.002427
 >> iter 46000, loss: 0.002393
 >> iter 47000, loss: 0.002404
 >> iter 48000, loss: 0.002373
 >> iter 49000, loss: 0.002384
 >> iter 50000, loss: 0.002352
   Number of active neurons: 3
 >> iter 51000, loss: 0.002365
 >> iter 52000, loss: 0.002335
 >> iter 53000, loss: 0.002345
 >> iter 54000, loss: 0.002320
 >> iter 55000, loss: 0.002326
 >> iter 56000, loss: 0.002302
 >> iter 57000, loss: 0.002311
 >> iter 58000, loss: 0.002283
 >> iter 59000, loss: 0.002294
 >> iter 60000, loss: 0.002267
   Number of active neurons: 3
 >> iter 61000, loss: 0.002276
 >> iter 62000, loss: 0.002252
 >> iter 63000, loss: 0.002261
 >> iter 64000, loss: 0.002235
 >> iter 65000, loss: 0.002246
 >> iter 66000, loss: 0.002222
 >> iter 67000, loss: 0.002231
 >> iter 68000, loss: 0.002211
 >> iter 69000, loss: 0.002218
 >> iter 70000, loss: 0.002195
   Number of active neurons: 3
 >> iter 71000, loss: 0.002204
 >> iter 72000, loss: 0.002183
 >> iter 73000, loss: 0.002192
 >> iter 74000, loss: 0.002171
 >> iter 75000, loss: 0.002182
 >> iter 76000, loss: 0.002160
 >> iter 77000, loss: 0.002169
 >> iter 78000, loss: 0.002147
 >> iter 79000, loss: 0.002160
 >> iter 80000, loss: 0.002137
   Number of active neurons: 3
 >> iter 81000, loss: 0.002153
 >> iter 82000, loss: 0.002128
 >> iter 83000, loss: 0.002145
 >> iter 84000, loss: 0.002119
 >> iter 85000, loss: 0.002136
 >> iter 86000, loss: 0.002110
 >> iter 87000, loss: 0.002128
 >> iter 88000, loss: 0.002101
 >> iter 89000, loss: 0.002119
 >> iter 90000, loss: 0.002094
   Number of active neurons: 3
 >> iter 91000, loss: 0.002110
 >> iter 92000, loss: 0.002086
 >> iter 93000, loss: 0.002102
 >> iter 94000, loss: 0.002077
 >> iter 95000, loss: 0.002097
 >> iter 96000, loss: 0.002070
 >> iter 97000, loss: 0.002090
 >> iter 98000, loss: 0.002062
 >> iter 99000, loss: 0.002084
 >> iter 100000, loss: 0.002058
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.726102
 >> iter 2000, loss: 3.956425
 >> iter 3000, loss: 1.462097
 >> iter 4000, loss: 0.542834
 >> iter 5000, loss: 0.203912
 >> iter 6000, loss: 0.078597
 >> iter 7000, loss: 0.032175
 >> iter 8000, loss: 0.014750
 >> iter 9000, loss: 0.008181
 >> iter 10000, loss: 0.005543
   Number of active neurons: 6
 >> iter 11000, loss: 0.004489
 >> iter 12000, loss: 0.003944
 >> iter 13000, loss: 0.003701
 >> iter 14000, loss: 0.003487
 >> iter 15000, loss: 0.003390
 >> iter 16000, loss: 0.003256
 >> iter 17000, loss: 0.003204
 >> iter 18000, loss: 0.003105
 >> iter 19000, loss: 0.003073
 >> iter 20000, loss: 0.002997
   Number of active neurons: 6
 >> iter 21000, loss: 0.002978
 >> iter 22000, loss: 0.002912
 >> iter 23000, loss: 0.002903
 >> iter 24000, loss: 0.002847
 >> iter 25000, loss: 0.002848
 >> iter 26000, loss: 0.002799
 >> iter 27000, loss: 0.002803
 >> iter 28000, loss: 0.002760
 >> iter 29000, loss: 0.002767
 >> iter 30000, loss: 0.002729
   Number of active neurons: 6
 >> iter 31000, loss: 0.002740
 >> iter 32000, loss: 0.002705
 >> iter 33000, loss: 0.002718
 >> iter 34000, loss: 0.002686
 >> iter 35000, loss: 0.002703
 >> iter 36000, loss: 0.002669
 >> iter 37000, loss: 0.002687
 >> iter 38000, loss: 0.002654
 >> iter 39000, loss: 0.002674
 >> iter 40000, loss: 0.002641
   Number of active neurons: 6
 >> iter 41000, loss: 0.002662
 >> iter 42000, loss: 0.002630
 >> iter 43000, loss: 0.002647
 >> iter 44000, loss: 0.002617
 >> iter 45000, loss: 0.002636
 >> iter 46000, loss: 0.002606
 >> iter 47000, loss: 0.002625
 >> iter 48000, loss: 0.002598
 >> iter 49000, loss: 0.002618
 >> iter 50000, loss: 0.002589
   Number of active neurons: 6
 >> iter 51000, loss: 0.002610
 >> iter 52000, loss: 0.002583
 >> iter 53000, loss: 0.002601
 >> iter 54000, loss: 0.002578
 >> iter 55000, loss: 0.002592
 >> iter 56000, loss: 0.002570
 >> iter 57000, loss: 0.002586
 >> iter 58000, loss: 0.002560
 >> iter 59000, loss: 0.002578
 >> iter 60000, loss: 0.002554
   Number of active neurons: 4
 >> iter 61000, loss: 0.002569
 >> iter 62000, loss: 0.002547
 >> iter 63000, loss: 0.002562
 >> iter 64000, loss: 0.002538
 >> iter 65000, loss: 0.002555
 >> iter 66000, loss: 0.002532
 >> iter 67000, loss: 0.002547
 >> iter 68000, loss: 0.002528
 >> iter 69000, loss: 0.002542
 >> iter 70000, loss: 0.002520
   Number of active neurons: 3
 >> iter 71000, loss: 0.002536
 >> iter 72000, loss: 0.002516
 >> iter 73000, loss: 0.002530
 >> iter 74000, loss: 0.002510
 >> iter 75000, loss: 0.002525
 >> iter 76000, loss: 0.002504
 >> iter 77000, loss: 0.002518
 >> iter 78000, loss: 0.002497
 >> iter 79000, loss: 0.002515
 >> iter 80000, loss: 0.002491
   Number of active neurons: 3
 >> iter 81000, loss: 0.002511
 >> iter 82000, loss: 0.002484
 >> iter 83000, loss: 0.002504
 >> iter 84000, loss: 0.002475
 >> iter 85000, loss: 0.002496
 >> iter 86000, loss: 0.002467
 >> iter 87000, loss: 0.002488
 >> iter 88000, loss: 0.002459
 >> iter 89000, loss: 0.002479
 >> iter 90000, loss: 0.002452
   Number of active neurons: 3
 >> iter 91000, loss: 0.002470
 >> iter 92000, loss: 0.002444
 >> iter 93000, loss: 0.002462
 >> iter 94000, loss: 0.002434
 >> iter 95000, loss: 0.002455
 >> iter 96000, loss: 0.002423
 >> iter 97000, loss: 0.002443
 >> iter 98000, loss: 0.002409
 >> iter 99000, loss: 0.002430
 >> iter 100000, loss: 0.002398
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.673997
 >> iter 2000, loss: 3.935833
 >> iter 3000, loss: 1.453784
 >> iter 4000, loss: 0.539288
 >> iter 5000, loss: 0.202266
 >> iter 6000, loss: 0.077720
 >> iter 7000, loss: 0.031643
 >> iter 8000, loss: 0.014369
 >> iter 9000, loss: 0.007888
 >> iter 10000, loss: 0.005289
   Number of active neurons: 5
 >> iter 11000, loss: 0.004269
 >> iter 12000, loss: 0.003736
 >> iter 13000, loss: 0.003513
 >> iter 14000, loss: 0.003307
 >> iter 15000, loss: 0.003225
 >> iter 16000, loss: 0.003094
 >> iter 17000, loss: 0.003051
 >> iter 18000, loss: 0.002950
 >> iter 19000, loss: 0.002922
 >> iter 20000, loss: 0.002840
   Number of active neurons: 5
 >> iter 21000, loss: 0.002821
 >> iter 22000, loss: 0.002748
 >> iter 23000, loss: 0.002740
 >> iter 24000, loss: 0.002676
 >> iter 25000, loss: 0.002676
 >> iter 26000, loss: 0.002621
 >> iter 27000, loss: 0.002623
 >> iter 28000, loss: 0.002574
 >> iter 29000, loss: 0.002579
 >> iter 30000, loss: 0.002534
   Number of active neurons: 5
 >> iter 31000, loss: 0.002543
 >> iter 32000, loss: 0.002503
 >> iter 33000, loss: 0.002515
 >> iter 34000, loss: 0.002478
 >> iter 35000, loss: 0.002494
 >> iter 36000, loss: 0.002457
 >> iter 37000, loss: 0.002473
 >> iter 38000, loss: 0.002436
 >> iter 39000, loss: 0.002455
 >> iter 40000, loss: 0.002419
   Number of active neurons: 5
 >> iter 41000, loss: 0.002439
 >> iter 42000, loss: 0.002407
 >> iter 43000, loss: 0.002426
 >> iter 44000, loss: 0.002396
 >> iter 45000, loss: 0.002416
 >> iter 46000, loss: 0.002386
 >> iter 47000, loss: 0.002407
 >> iter 48000, loss: 0.002379
 >> iter 49000, loss: 0.002400
 >> iter 50000, loss: 0.002371
   Number of active neurons: 5
 >> iter 51000, loss: 0.002390
 >> iter 52000, loss: 0.002362
 >> iter 53000, loss: 0.002380
 >> iter 54000, loss: 0.002356
 >> iter 55000, loss: 0.002371
 >> iter 56000, loss: 0.002349
 >> iter 57000, loss: 0.002365
 >> iter 58000, loss: 0.002341
 >> iter 59000, loss: 0.002359
 >> iter 60000, loss: 0.002335
   Number of active neurons: 5
 >> iter 61000, loss: 0.002352
 >> iter 62000, loss: 0.002330
 >> iter 63000, loss: 0.002346
 >> iter 64000, loss: 0.002323
 >> iter 65000, loss: 0.002341
 >> iter 66000, loss: 0.002319
 >> iter 67000, loss: 0.002336
 >> iter 68000, loss: 0.002318
 >> iter 69000, loss: 0.002333
 >> iter 70000, loss: 0.002313
   Number of active neurons: 5
 >> iter 71000, loss: 0.002330
 >> iter 72000, loss: 0.002312
 >> iter 73000, loss: 0.002326
 >> iter 74000, loss: 0.002307
 >> iter 75000, loss: 0.002323
 >> iter 76000, loss: 0.002304
 >> iter 77000, loss: 0.002319
 >> iter 78000, loss: 0.002297
 >> iter 79000, loss: 0.002317
 >> iter 80000, loss: 0.002294
   Number of active neurons: 4
 >> iter 81000, loss: 0.002317
 >> iter 82000, loss: 0.002291
 >> iter 83000, loss: 0.002317
 >> iter 84000, loss: 0.002290
 >> iter 85000, loss: 0.002315
 >> iter 86000, loss: 0.002288
 >> iter 87000, loss: 0.002314
 >> iter 88000, loss: 0.002286
 >> iter 89000, loss: 0.002312
 >> iter 90000, loss: 0.002286
   Number of active neurons: 4
 >> iter 91000, loss: 0.002310
 >> iter 92000, loss: 0.002286
 >> iter 93000, loss: 0.002310
 >> iter 94000, loss: 0.002283
 >> iter 95000, loss: 0.002311
 >> iter 96000, loss: 0.002282
 >> iter 97000, loss: 0.002310
 >> iter 98000, loss: 0.002279
 >> iter 99000, loss: 0.002309
 >> iter 100000, loss: 0.002280
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.687830
 >> iter 2000, loss: 3.940292
 >> iter 3000, loss: 1.455093
 >> iter 4000, loss: 0.539561
 >> iter 5000, loss: 0.202224
 >> iter 6000, loss: 0.077610
 >> iter 7000, loss: 0.031545
 >> iter 8000, loss: 0.014304
 >> iter 9000, loss: 0.007859
 >> iter 10000, loss: 0.005290
   Number of active neurons: 6
 >> iter 11000, loss: 0.004301
 >> iter 12000, loss: 0.003787
 >> iter 13000, loss: 0.003582
 >> iter 14000, loss: 0.003384
 >> iter 15000, loss: 0.003313
 >> iter 16000, loss: 0.003187
 >> iter 17000, loss: 0.003152
 >> iter 18000, loss: 0.003054
 >> iter 19000, loss: 0.003034
 >> iter 20000, loss: 0.002950
   Number of active neurons: 6
 >> iter 21000, loss: 0.002935
 >> iter 22000, loss: 0.002858
 >> iter 23000, loss: 0.002850
 >> iter 24000, loss: 0.002781
 >> iter 25000, loss: 0.002779
 >> iter 26000, loss: 0.002718
 >> iter 27000, loss: 0.002719
 >> iter 28000, loss: 0.002664
 >> iter 29000, loss: 0.002669
 >> iter 30000, loss: 0.002619
   Number of active neurons: 6
 >> iter 31000, loss: 0.002629
 >> iter 32000, loss: 0.002583
 >> iter 33000, loss: 0.002595
 >> iter 34000, loss: 0.002554
 >> iter 35000, loss: 0.002572
 >> iter 36000, loss: 0.002532
 >> iter 37000, loss: 0.002552
 >> iter 38000, loss: 0.002514
 >> iter 39000, loss: 0.002536
 >> iter 40000, loss: 0.002499
   Number of active neurons: 5
 >> iter 41000, loss: 0.002522
 >> iter 42000, loss: 0.002488
 >> iter 43000, loss: 0.002508
 >> iter 44000, loss: 0.002476
 >> iter 45000, loss: 0.002500
 >> iter 46000, loss: 0.002468
 >> iter 47000, loss: 0.002493
 >> iter 48000, loss: 0.002464
 >> iter 49000, loss: 0.002489
 >> iter 50000, loss: 0.002458
   Number of active neurons: 5
 >> iter 51000, loss: 0.002483
 >> iter 52000, loss: 0.002454
 >> iter 53000, loss: 0.002477
 >> iter 54000, loss: 0.002454
 >> iter 55000, loss: 0.002472
 >> iter 56000, loss: 0.002450
 >> iter 57000, loss: 0.002470
 >> iter 58000, loss: 0.002444
 >> iter 59000, loss: 0.002465
 >> iter 60000, loss: 0.002439
   Number of active neurons: 5
 >> iter 61000, loss: 0.002459
 >> iter 62000, loss: 0.002435
 >> iter 63000, loss: 0.002455
 >> iter 64000, loss: 0.002430
 >> iter 65000, loss: 0.002451
 >> iter 66000, loss: 0.002425
 >> iter 67000, loss: 0.002444
 >> iter 68000, loss: 0.002422
 >> iter 69000, loss: 0.002439
 >> iter 70000, loss: 0.002416
   Number of active neurons: 5
 >> iter 71000, loss: 0.002435
 >> iter 72000, loss: 0.002413
 >> iter 73000, loss: 0.002431
 >> iter 74000, loss: 0.002408
 >> iter 75000, loss: 0.002428
 >> iter 76000, loss: 0.002405
 >> iter 77000, loss: 0.002423
 >> iter 78000, loss: 0.002400
 >> iter 79000, loss: 0.002423
 >> iter 80000, loss: 0.002396
   Number of active neurons: 5
 >> iter 81000, loss: 0.002423
 >> iter 82000, loss: 0.002393
 >> iter 83000, loss: 0.002421
 >> iter 84000, loss: 0.002389
 >> iter 85000, loss: 0.002417
 >> iter 86000, loss: 0.002384
 >> iter 87000, loss: 0.002413
 >> iter 88000, loss: 0.002380
 >> iter 89000, loss: 0.002408
 >> iter 90000, loss: 0.002377
   Number of active neurons: 5
 >> iter 91000, loss: 0.002403
 >> iter 92000, loss: 0.002374
 >> iter 93000, loss: 0.002400
 >> iter 94000, loss: 0.002368
 >> iter 95000, loss: 0.002399
 >> iter 96000, loss: 0.002363
 >> iter 97000, loss: 0.002394
 >> iter 98000, loss: 0.002357
 >> iter 99000, loss: 0.002388
 >> iter 100000, loss: 0.002354
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.692391
 >> iter 2000, loss: 3.943626
 >> iter 3000, loss: 1.457253
 >> iter 4000, loss: 0.541011
 >> iter 5000, loss: 0.203244
 >> iter 6000, loss: 0.078382
 >> iter 7000, loss: 0.032147
 >> iter 8000, loss: 0.014802
 >> iter 9000, loss: 0.008277
 >> iter 10000, loss: 0.005659
   Number of active neurons: 7
 >> iter 11000, loss: 0.004625
 >> iter 12000, loss: 0.004087
 >> iter 13000, loss: 0.003857
 >> iter 14000, loss: 0.003646
 >> iter 15000, loss: 0.003556
 >> iter 16000, loss: 0.003417
 >> iter 17000, loss: 0.003364
 >> iter 18000, loss: 0.003258
 >> iter 19000, loss: 0.003224
 >> iter 20000, loss: 0.003141
   Number of active neurons: 7
 >> iter 21000, loss: 0.003121
 >> iter 22000, loss: 0.003051
 >> iter 23000, loss: 0.003042
 >> iter 24000, loss: 0.002980
 >> iter 25000, loss: 0.002980
 >> iter 26000, loss: 0.002926
 >> iter 27000, loss: 0.002928
 >> iter 28000, loss: 0.002880
 >> iter 29000, loss: 0.002885
 >> iter 30000, loss: 0.002841
   Number of active neurons: 4
 >> iter 31000, loss: 0.002849
 >> iter 32000, loss: 0.002808
 >> iter 33000, loss: 0.002817
 >> iter 34000, loss: 0.002777
 >> iter 35000, loss: 0.002790
 >> iter 36000, loss: 0.002751
 >> iter 37000, loss: 0.002766
 >> iter 38000, loss: 0.002727
 >> iter 39000, loss: 0.002744
 >> iter 40000, loss: 0.002706
   Number of active neurons: 4
 >> iter 41000, loss: 0.002724
 >> iter 42000, loss: 0.002689
 >> iter 43000, loss: 0.002706
 >> iter 44000, loss: 0.002673
 >> iter 45000, loss: 0.002690
 >> iter 46000, loss: 0.002658
 >> iter 47000, loss: 0.002674
 >> iter 48000, loss: 0.002644
 >> iter 49000, loss: 0.002660
 >> iter 50000, loss: 0.002628
   Number of active neurons: 3
 >> iter 51000, loss: 0.002645
 >> iter 52000, loss: 0.002615
 >> iter 53000, loss: 0.002630
 >> iter 54000, loss: 0.002605
 >> iter 55000, loss: 0.002615
 >> iter 56000, loss: 0.002591
 >> iter 57000, loss: 0.002604
 >> iter 58000, loss: 0.002576
 >> iter 59000, loss: 0.002591
 >> iter 60000, loss: 0.002564
   Number of active neurons: 3
 >> iter 61000, loss: 0.002577
 >> iter 62000, loss: 0.002551
 >> iter 63000, loss: 0.002564
 >> iter 64000, loss: 0.002536
 >> iter 65000, loss: 0.002550
 >> iter 66000, loss: 0.002523
 >> iter 67000, loss: 0.002534
 >> iter 68000, loss: 0.002510
 >> iter 69000, loss: 0.002518
 >> iter 70000, loss: 0.002489
   Number of active neurons: 3
 >> iter 71000, loss: 0.002496
 >> iter 72000, loss: 0.002468
 >> iter 73000, loss: 0.002475
 >> iter 74000, loss: 0.002447
 >> iter 75000, loss: 0.002455
 >> iter 76000, loss: 0.002427
 >> iter 77000, loss: 0.002434
 >> iter 78000, loss: 0.002406
 >> iter 79000, loss: 0.002417
 >> iter 80000, loss: 0.002386
   Number of active neurons: 3
 >> iter 81000, loss: 0.002399
 >> iter 82000, loss: 0.002365
 >> iter 83000, loss: 0.002378
 >> iter 84000, loss: 0.002341
 >> iter 85000, loss: 0.002353
 >> iter 86000, loss: 0.002316
 >> iter 87000, loss: 0.002328
 >> iter 88000, loss: 0.002292
 >> iter 89000, loss: 0.002304
 >> iter 90000, loss: 0.002270
   Number of active neurons: 3
 >> iter 91000, loss: 0.002281
 >> iter 92000, loss: 0.002248
 >> iter 93000, loss: 0.002259
 >> iter 94000, loss: 0.002224
 >> iter 95000, loss: 0.002238
 >> iter 96000, loss: 0.002201
 >> iter 97000, loss: 0.002218
 >> iter 98000, loss: 0.002181
 >> iter 99000, loss: 0.002200
 >> iter 100000, loss: 0.002167
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.703821
 >> iter 2000, loss: 3.945862
 >> iter 3000, loss: 1.456893
 >> iter 4000, loss: 0.540008
 >> iter 5000, loss: 0.202221
 >> iter 6000, loss: 0.077454
 >> iter 7000, loss: 0.031351
 >> iter 8000, loss: 0.014098
 >> iter 9000, loss: 0.007663
 >> iter 10000, loss: 0.005098
   Number of active neurons: 7
 >> iter 11000, loss: 0.004121
 >> iter 12000, loss: 0.003616
 >> iter 13000, loss: 0.003428
 >> iter 14000, loss: 0.003242
 >> iter 15000, loss: 0.003188
 >> iter 16000, loss: 0.003071
 >> iter 17000, loss: 0.003051
 >> iter 18000, loss: 0.002957
 >> iter 19000, loss: 0.002946
 >> iter 20000, loss: 0.002867
   Number of active neurons: 7
 >> iter 21000, loss: 0.002861
 >> iter 22000, loss: 0.002788
 >> iter 23000, loss: 0.002790
 >> iter 24000, loss: 0.002726
 >> iter 25000, loss: 0.002735
 >> iter 26000, loss: 0.002678
 >> iter 27000, loss: 0.002686
 >> iter 28000, loss: 0.002634
 >> iter 29000, loss: 0.002645
 >> iter 30000, loss: 0.002599
   Number of active neurons: 5
 >> iter 31000, loss: 0.002614
 >> iter 32000, loss: 0.002570
 >> iter 33000, loss: 0.002588
 >> iter 34000, loss: 0.002549
 >> iter 35000, loss: 0.002574
 >> iter 36000, loss: 0.002536
 >> iter 37000, loss: 0.002561
 >> iter 38000, loss: 0.002522
 >> iter 39000, loss: 0.002549
 >> iter 40000, loss: 0.002511
   Number of active neurons: 5
 >> iter 41000, loss: 0.002539
 >> iter 42000, loss: 0.002505
 >> iter 43000, loss: 0.002531
 >> iter 44000, loss: 0.002499
 >> iter 45000, loss: 0.002527
 >> iter 46000, loss: 0.002494
 >> iter 47000, loss: 0.002522
 >> iter 48000, loss: 0.002491
 >> iter 49000, loss: 0.002519
 >> iter 50000, loss: 0.002487
   Number of active neurons: 5
 >> iter 51000, loss: 0.002516
 >> iter 52000, loss: 0.002485
 >> iter 53000, loss: 0.002511
 >> iter 54000, loss: 0.002485
 >> iter 55000, loss: 0.002506
 >> iter 56000, loss: 0.002482
 >> iter 57000, loss: 0.002505
 >> iter 58000, loss: 0.002477
 >> iter 59000, loss: 0.002501
 >> iter 60000, loss: 0.002474
   Number of active neurons: 5
 >> iter 61000, loss: 0.002496
 >> iter 62000, loss: 0.002471
 >> iter 63000, loss: 0.002492
 >> iter 64000, loss: 0.002464
 >> iter 65000, loss: 0.002486
 >> iter 66000, loss: 0.002456
 >> iter 67000, loss: 0.002475
 >> iter 68000, loss: 0.002449
 >> iter 69000, loss: 0.002465
 >> iter 70000, loss: 0.002438
   Number of active neurons: 5
 >> iter 71000, loss: 0.002457
 >> iter 72000, loss: 0.002432
 >> iter 73000, loss: 0.002450
 >> iter 74000, loss: 0.002424
 >> iter 75000, loss: 0.002443
 >> iter 76000, loss: 0.002417
 >> iter 77000, loss: 0.002435
 >> iter 78000, loss: 0.002409
 >> iter 79000, loss: 0.002431
 >> iter 80000, loss: 0.002402
   Number of active neurons: 5
 >> iter 81000, loss: 0.002428
 >> iter 82000, loss: 0.002394
 >> iter 83000, loss: 0.002423
 >> iter 84000, loss: 0.002386
 >> iter 85000, loss: 0.002414
 >> iter 86000, loss: 0.002377
 >> iter 87000, loss: 0.002403
 >> iter 88000, loss: 0.002364
 >> iter 89000, loss: 0.002389
 >> iter 90000, loss: 0.002353
   Number of active neurons: 5
 >> iter 91000, loss: 0.002378
 >> iter 92000, loss: 0.002344
 >> iter 93000, loss: 0.002369
 >> iter 94000, loss: 0.002333
 >> iter 95000, loss: 0.002363
 >> iter 96000, loss: 0.002325
 >> iter 97000, loss: 0.002355
 >> iter 98000, loss: 0.002316
 >> iter 99000, loss: 0.002348
 >> iter 100000, loss: 0.002312
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.705170
 >> iter 2000, loss: 3.947433
 >> iter 3000, loss: 1.458131
 >> iter 4000, loss: 0.540951
 >> iter 5000, loss: 0.202922
 >> iter 6000, loss: 0.078008
 >> iter 7000, loss: 0.031788
 >> iter 8000, loss: 0.014469
 >> iter 9000, loss: 0.007971
 >> iter 10000, loss: 0.005373
   Number of active neurons: 5
 >> iter 11000, loss: 0.004350
 >> iter 12000, loss: 0.003817
 >> iter 13000, loss: 0.003591
 >> iter 14000, loss: 0.003385
 >> iter 15000, loss: 0.003300
 >> iter 16000, loss: 0.003168
 >> iter 17000, loss: 0.003122
 >> iter 18000, loss: 0.003017
 >> iter 19000, loss: 0.002986
 >> iter 20000, loss: 0.002899
   Number of active neurons: 5
 >> iter 21000, loss: 0.002876
 >> iter 22000, loss: 0.002796
 >> iter 23000, loss: 0.002782
 >> iter 24000, loss: 0.002713
 >> iter 25000, loss: 0.002709
 >> iter 26000, loss: 0.002650
 >> iter 27000, loss: 0.002651
 >> iter 28000, loss: 0.002599
 >> iter 29000, loss: 0.002603
 >> iter 30000, loss: 0.002555
   Number of active neurons: 4
 >> iter 31000, loss: 0.002562
 >> iter 32000, loss: 0.002517
 >> iter 33000, loss: 0.002526
 >> iter 34000, loss: 0.002484
 >> iter 35000, loss: 0.002496
 >> iter 36000, loss: 0.002454
 >> iter 37000, loss: 0.002467
 >> iter 38000, loss: 0.002426
 >> iter 39000, loss: 0.002441
 >> iter 40000, loss: 0.002400
   Number of active neurons: 4
 >> iter 41000, loss: 0.002416
 >> iter 42000, loss: 0.002378
 >> iter 43000, loss: 0.002393
 >> iter 44000, loss: 0.002359
 >> iter 45000, loss: 0.002375
 >> iter 46000, loss: 0.002342
 >> iter 47000, loss: 0.002357
 >> iter 48000, loss: 0.002326
 >> iter 49000, loss: 0.002343
 >> iter 50000, loss: 0.002311
   Number of active neurons: 4
 >> iter 51000, loss: 0.002330
 >> iter 52000, loss: 0.002299
 >> iter 53000, loss: 0.002316
 >> iter 54000, loss: 0.002290
 >> iter 55000, loss: 0.002303
 >> iter 56000, loss: 0.002280
 >> iter 57000, loss: 0.002296
 >> iter 58000, loss: 0.002270
 >> iter 59000, loss: 0.002288
 >> iter 60000, loss: 0.002263
   Number of active neurons: 4
 >> iter 61000, loss: 0.002280
 >> iter 62000, loss: 0.002257
 >> iter 63000, loss: 0.002274
 >> iter 64000, loss: 0.002249
 >> iter 65000, loss: 0.002268
 >> iter 66000, loss: 0.002244
 >> iter 67000, loss: 0.002262
 >> iter 68000, loss: 0.002241
 >> iter 69000, loss: 0.002256
 >> iter 70000, loss: 0.002234
   Number of active neurons: 4
 >> iter 71000, loss: 0.002251
 >> iter 72000, loss: 0.002230
 >> iter 73000, loss: 0.002246
 >> iter 74000, loss: 0.002224
 >> iter 75000, loss: 0.002242
 >> iter 76000, loss: 0.002219
 >> iter 77000, loss: 0.002236
 >> iter 78000, loss: 0.002213
 >> iter 79000, loss: 0.002234
 >> iter 80000, loss: 0.002208
   Number of active neurons: 4
 >> iter 81000, loss: 0.002232
 >> iter 82000, loss: 0.002203
 >> iter 83000, loss: 0.002229
 >> iter 84000, loss: 0.002197
 >> iter 85000, loss: 0.002222
 >> iter 86000, loss: 0.002190
 >> iter 87000, loss: 0.002216
 >> iter 88000, loss: 0.002184
 >> iter 89000, loss: 0.002209
 >> iter 90000, loss: 0.002180
   Number of active neurons: 4
 >> iter 91000, loss: 0.002204
 >> iter 92000, loss: 0.002176
 >> iter 93000, loss: 0.002200
 >> iter 94000, loss: 0.002170
 >> iter 95000, loss: 0.002198
 >> iter 96000, loss: 0.002165
 >> iter 97000, loss: 0.002195
 >> iter 98000, loss: 0.002161
 >> iter 99000, loss: 0.002192
 >> iter 100000, loss: 0.002160
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.695566
 >> iter 2000, loss: 3.943110
 >> iter 3000, loss: 1.456129
 >> iter 4000, loss: 0.539966
 >> iter 5000, loss: 0.202408
 >> iter 6000, loss: 0.077728
 >> iter 7000, loss: 0.031640
 >> iter 8000, loss: 0.014398
 >> iter 9000, loss: 0.007951
 >> iter 10000, loss: 0.005387
   Number of active neurons: 6
 >> iter 11000, loss: 0.004394
 >> iter 12000, loss: 0.003886
 >> iter 13000, loss: 0.003683
 >> iter 14000, loss: 0.003495
 >> iter 15000, loss: 0.003431
 >> iter 16000, loss: 0.003311
 >> iter 17000, loss: 0.003275
 >> iter 18000, loss: 0.003179
 >> iter 19000, loss: 0.003160
 >> iter 20000, loss: 0.003083
   Number of active neurons: 6
 >> iter 21000, loss: 0.003073
 >> iter 22000, loss: 0.003005
 >> iter 23000, loss: 0.003006
 >> iter 24000, loss: 0.002945
 >> iter 25000, loss: 0.002953
 >> iter 26000, loss: 0.002898
 >> iter 27000, loss: 0.002907
 >> iter 28000, loss: 0.002857
 >> iter 29000, loss: 0.002867
 >> iter 30000, loss: 0.002821
   Number of active neurons: 6
 >> iter 31000, loss: 0.002834
 >> iter 32000, loss: 0.002791
 >> iter 33000, loss: 0.002807
 >> iter 34000, loss: 0.002766
 >> iter 35000, loss: 0.002785
 >> iter 36000, loss: 0.002744
 >> iter 37000, loss: 0.002763
 >> iter 38000, loss: 0.002721
 >> iter 39000, loss: 0.002741
 >> iter 40000, loss: 0.002700
   Number of active neurons: 6
 >> iter 41000, loss: 0.002720
 >> iter 42000, loss: 0.002681
 >> iter 43000, loss: 0.002699
 >> iter 44000, loss: 0.002662
 >> iter 45000, loss: 0.002681
 >> iter 46000, loss: 0.002643
 >> iter 47000, loss: 0.002661
 >> iter 48000, loss: 0.002625
 >> iter 49000, loss: 0.002645
 >> iter 50000, loss: 0.002609
   Number of active neurons: 5
 >> iter 51000, loss: 0.002629
 >> iter 52000, loss: 0.002595
 >> iter 53000, loss: 0.002613
 >> iter 54000, loss: 0.002584
 >> iter 55000, loss: 0.002597
 >> iter 56000, loss: 0.002571
 >> iter 57000, loss: 0.002586
 >> iter 58000, loss: 0.002556
 >> iter 59000, loss: 0.002574
 >> iter 60000, loss: 0.002545
   Number of active neurons: 5
 >> iter 61000, loss: 0.002562
 >> iter 62000, loss: 0.002535
 >> iter 63000, loss: 0.002551
 >> iter 64000, loss: 0.002523
 >> iter 65000, loss: 0.002542
 >> iter 66000, loss: 0.002515
 >> iter 67000, loss: 0.002531
 >> iter 68000, loss: 0.002508
 >> iter 69000, loss: 0.002522
 >> iter 70000, loss: 0.002498
   Number of active neurons: 5
 >> iter 71000, loss: 0.002514
 >> iter 72000, loss: 0.002491
 >> iter 73000, loss: 0.002505
 >> iter 74000, loss: 0.002481
 >> iter 75000, loss: 0.002497
 >> iter 76000, loss: 0.002474
 >> iter 77000, loss: 0.002490
 >> iter 78000, loss: 0.002466
 >> iter 79000, loss: 0.002487
 >> iter 80000, loss: 0.002461
   Number of active neurons: 5
 >> iter 81000, loss: 0.002485
 >> iter 82000, loss: 0.002456
 >> iter 83000, loss: 0.002482
 >> iter 84000, loss: 0.002450
 >> iter 85000, loss: 0.002474
 >> iter 86000, loss: 0.002443
 >> iter 87000, loss: 0.002469
 >> iter 88000, loss: 0.002437
 >> iter 89000, loss: 0.002461
 >> iter 90000, loss: 0.002431
   Number of active neurons: 5
 >> iter 91000, loss: 0.002455
 >> iter 92000, loss: 0.002426
 >> iter 93000, loss: 0.002450
 >> iter 94000, loss: 0.002420
 >> iter 95000, loss: 0.002448
 >> iter 96000, loss: 0.002415
 >> iter 97000, loss: 0.002444
 >> iter 98000, loss: 0.002410
 >> iter 99000, loss: 0.002440
 >> iter 100000, loss: 0.002408
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.675467
 >> iter 2000, loss: 3.935550
 >> iter 3000, loss: 1.453219
 >> iter 4000, loss: 0.538781
 >> iter 5000, loss: 0.201867
 >> iter 6000, loss: 0.077425
 >> iter 7000, loss: 0.031425
 >> iter 8000, loss: 0.014222
 >> iter 9000, loss: 0.007789
 >> iter 10000, loss: 0.005237
   Number of active neurons: 8
 >> iter 11000, loss: 0.004249
 >> iter 12000, loss: 0.003751
 >> iter 13000, loss: 0.003552
 >> iter 14000, loss: 0.003370
 >> iter 15000, loss: 0.003305
 >> iter 16000, loss: 0.003192
 >> iter 17000, loss: 0.003162
 >> iter 18000, loss: 0.003078
 >> iter 19000, loss: 0.003065
 >> iter 20000, loss: 0.002998
   Number of active neurons: 8
 >> iter 21000, loss: 0.002992
 >> iter 22000, loss: 0.002931
 >> iter 23000, loss: 0.002931
 >> iter 24000, loss: 0.002877
 >> iter 25000, loss: 0.002885
 >> iter 26000, loss: 0.002840
 >> iter 27000, loss: 0.002851
 >> iter 28000, loss: 0.002811
 >> iter 29000, loss: 0.002824
 >> iter 30000, loss: 0.002788
   Number of active neurons: 7
 >> iter 31000, loss: 0.002805
 >> iter 32000, loss: 0.002771
 >> iter 33000, loss: 0.002788
 >> iter 34000, loss: 0.002756
 >> iter 35000, loss: 0.002778
 >> iter 36000, loss: 0.002745
 >> iter 37000, loss: 0.002767
 >> iter 38000, loss: 0.002733
 >> iter 39000, loss: 0.002758
 >> iter 40000, loss: 0.002725
   Number of active neurons: 7
 >> iter 41000, loss: 0.002752
 >> iter 42000, loss: 0.002723
 >> iter 43000, loss: 0.002748
 >> iter 44000, loss: 0.002721
 >> iter 45000, loss: 0.002747
 >> iter 46000, loss: 0.002720
 >> iter 47000, loss: 0.002747
 >> iter 48000, loss: 0.002722
 >> iter 49000, loss: 0.002750
 >> iter 50000, loss: 0.002723
   Number of active neurons: 7
 >> iter 51000, loss: 0.002752
 >> iter 52000, loss: 0.002726
 >> iter 53000, loss: 0.002753
 >> iter 54000, loss: 0.002732
 >> iter 55000, loss: 0.002753
 >> iter 56000, loss: 0.002733
 >> iter 57000, loss: 0.002756
 >> iter 58000, loss: 0.002731
 >> iter 59000, loss: 0.002755
 >> iter 60000, loss: 0.002731
   Number of active neurons: 7
 >> iter 61000, loss: 0.002753
 >> iter 62000, loss: 0.002731
 >> iter 63000, loss: 0.002753
 >> iter 64000, loss: 0.002729
 >> iter 65000, loss: 0.002753
 >> iter 66000, loss: 0.002729
 >> iter 67000, loss: 0.002750
 >> iter 68000, loss: 0.002728
 >> iter 69000, loss: 0.002745
 >> iter 70000, loss: 0.002720
   Number of active neurons: 6
 >> iter 71000, loss: 0.002740
 >> iter 72000, loss: 0.002718
 >> iter 73000, loss: 0.002737
 >> iter 74000, loss: 0.002714
 >> iter 75000, loss: 0.002734
 >> iter 76000, loss: 0.002711
 >> iter 77000, loss: 0.002730
 >> iter 78000, loss: 0.002706
 >> iter 79000, loss: 0.002729
 >> iter 80000, loss: 0.002702
   Number of active neurons: 6
 >> iter 81000, loss: 0.002729
 >> iter 82000, loss: 0.002698
 >> iter 83000, loss: 0.002726
 >> iter 84000, loss: 0.002693
 >> iter 85000, loss: 0.002720
 >> iter 86000, loss: 0.002687
 >> iter 87000, loss: 0.002714
 >> iter 88000, loss: 0.002680
 >> iter 89000, loss: 0.002706
 >> iter 90000, loss: 0.002676
   Number of active neurons: 6
 >> iter 91000, loss: 0.002700
 >> iter 92000, loss: 0.002671
 >> iter 93000, loss: 0.002695
 >> iter 94000, loss: 0.002664
 >> iter 95000, loss: 0.002692
 >> iter 96000, loss: 0.002658
 >> iter 97000, loss: 0.002688
 >> iter 98000, loss: 0.002652
 >> iter 99000, loss: 0.002684
 >> iter 100000, loss: 0.002651
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.760760
 >> iter 2000, loss: 3.967205
 >> iter 3000, loss: 1.465000
 >> iter 4000, loss: 0.543211
 >> iter 5000, loss: 0.203567
 >> iter 6000, loss: 0.078110
 >> iter 7000, loss: 0.031729
 >> iter 8000, loss: 0.014379
 >> iter 9000, loss: 0.007894
 >> iter 10000, loss: 0.005322
   Number of active neurons: 9
 >> iter 11000, loss: 0.004333
 >> iter 12000, loss: 0.003833
 >> iter 13000, loss: 0.003636
 >> iter 14000, loss: 0.003455
 >> iter 15000, loss: 0.003394
 >> iter 16000, loss: 0.003283
 >> iter 17000, loss: 0.003256
 >> iter 18000, loss: 0.003170
 >> iter 19000, loss: 0.003156
 >> iter 20000, loss: 0.003087
   Number of active neurons: 8
 >> iter 21000, loss: 0.003084
 >> iter 22000, loss: 0.003026
 >> iter 23000, loss: 0.003034
 >> iter 24000, loss: 0.002983
 >> iter 25000, loss: 0.002998
 >> iter 26000, loss: 0.002951
 >> iter 27000, loss: 0.002962
 >> iter 28000, loss: 0.002918
 >> iter 29000, loss: 0.002932
 >> iter 30000, loss: 0.002893
   Number of active neurons: 8
 >> iter 31000, loss: 0.002910
 >> iter 32000, loss: 0.002873
 >> iter 33000, loss: 0.002893
 >> iter 34000, loss: 0.002860
 >> iter 35000, loss: 0.002886
 >> iter 36000, loss: 0.002853
 >> iter 37000, loss: 0.002880
 >> iter 38000, loss: 0.002848
 >> iter 39000, loss: 0.002878
 >> iter 40000, loss: 0.002845
   Number of active neurons: 6
 >> iter 41000, loss: 0.002875
 >> iter 42000, loss: 0.002845
 >> iter 43000, loss: 0.002871
 >> iter 44000, loss: 0.002844
 >> iter 45000, loss: 0.002870
 >> iter 46000, loss: 0.002839
 >> iter 47000, loss: 0.002863
 >> iter 48000, loss: 0.002835
 >> iter 49000, loss: 0.002860
 >> iter 50000, loss: 0.002831
   Number of active neurons: 6
 >> iter 51000, loss: 0.002857
 >> iter 52000, loss: 0.002829
 >> iter 53000, loss: 0.002853
 >> iter 54000, loss: 0.002829
 >> iter 55000, loss: 0.002847
 >> iter 56000, loss: 0.002824
 >> iter 57000, loss: 0.002844
 >> iter 58000, loss: 0.002817
 >> iter 59000, loss: 0.002839
 >> iter 60000, loss: 0.002812
   Number of active neurons: 6
 >> iter 61000, loss: 0.002832
 >> iter 62000, loss: 0.002805
 >> iter 63000, loss: 0.002824
 >> iter 64000, loss: 0.002796
 >> iter 65000, loss: 0.002816
 >> iter 66000, loss: 0.002788
 >> iter 67000, loss: 0.002807
 >> iter 68000, loss: 0.002783
 >> iter 69000, loss: 0.002799
 >> iter 70000, loss: 0.002773
   Number of active neurons: 6
 >> iter 71000, loss: 0.002789
 >> iter 72000, loss: 0.002764
 >> iter 73000, loss: 0.002778
 >> iter 74000, loss: 0.002751
 >> iter 75000, loss: 0.002766
 >> iter 76000, loss: 0.002738
 >> iter 77000, loss: 0.002752
 >> iter 78000, loss: 0.002722
 >> iter 79000, loss: 0.002740
 >> iter 80000, loss: 0.002708
   Number of active neurons: 6
 >> iter 81000, loss: 0.002729
 >> iter 82000, loss: 0.002694
 >> iter 83000, loss: 0.002716
 >> iter 84000, loss: 0.002678
 >> iter 85000, loss: 0.002699
 >> iter 86000, loss: 0.002662
 >> iter 87000, loss: 0.002683
 >> iter 88000, loss: 0.002645
 >> iter 89000, loss: 0.002667
 >> iter 90000, loss: 0.002632
   Number of active neurons: 5
 >> iter 91000, loss: 0.002652
 >> iter 92000, loss: 0.002618
 >> iter 93000, loss: 0.002638
 >> iter 94000, loss: 0.002604
 >> iter 95000, loss: 0.002628
 >> iter 96000, loss: 0.002590
 >> iter 97000, loss: 0.002614
 >> iter 98000, loss: 0.002575
 >> iter 99000, loss: 0.002601
 >> iter 100000, loss: 0.002565
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.711677
 >> iter 2000, loss: 3.950015
 >> iter 3000, loss: 1.459230
 >> iter 4000, loss: 0.541487
 >> iter 5000, loss: 0.203239
 >> iter 6000, loss: 0.078237
 >> iter 7000, loss: 0.031981
 >> iter 8000, loss: 0.014644
 >> iter 9000, loss: 0.008140
 >> iter 10000, loss: 0.005536
   Number of active neurons: 4
 >> iter 11000, loss: 0.004521
 >> iter 12000, loss: 0.003993
 >> iter 13000, loss: 0.003781
 >> iter 14000, loss: 0.003579
 >> iter 15000, loss: 0.003505
 >> iter 16000, loss: 0.003373
 >> iter 17000, loss: 0.003332
 >> iter 18000, loss: 0.003222
 >> iter 19000, loss: 0.003188
 >> iter 20000, loss: 0.003089
   Number of active neurons: 3
 >> iter 21000, loss: 0.003055
 >> iter 22000, loss: 0.002960
 >> iter 23000, loss: 0.002934
 >> iter 24000, loss: 0.002849
 >> iter 25000, loss: 0.002834
 >> iter 26000, loss: 0.002762
 >> iter 27000, loss: 0.002750
 >> iter 28000, loss: 0.002686
 >> iter 29000, loss: 0.002680
 >> iter 30000, loss: 0.002622
   Number of active neurons: 3
 >> iter 31000, loss: 0.002618
 >> iter 32000, loss: 0.002562
 >> iter 33000, loss: 0.002562
 >> iter 34000, loss: 0.002510
 >> iter 35000, loss: 0.002514
 >> iter 36000, loss: 0.002463
 >> iter 37000, loss: 0.002469
 >> iter 38000, loss: 0.002421
 >> iter 39000, loss: 0.002431
 >> iter 40000, loss: 0.002384
   Number of active neurons: 3
 >> iter 41000, loss: 0.002395
 >> iter 42000, loss: 0.002351
 >> iter 43000, loss: 0.002360
 >> iter 44000, loss: 0.002319
 >> iter 45000, loss: 0.002329
 >> iter 46000, loss: 0.002287
 >> iter 47000, loss: 0.002298
 >> iter 48000, loss: 0.002259
 >> iter 49000, loss: 0.002271
 >> iter 50000, loss: 0.002231
   Number of active neurons: 3
 >> iter 51000, loss: 0.002245
 >> iter 52000, loss: 0.002207
 >> iter 53000, loss: 0.002219
 >> iter 54000, loss: 0.002186
 >> iter 55000, loss: 0.002195
 >> iter 56000, loss: 0.002163
 >> iter 57000, loss: 0.002174
 >> iter 58000, loss: 0.002140
 >> iter 59000, loss: 0.002153
 >> iter 60000, loss: 0.002120
   Number of active neurons: 3
 >> iter 61000, loss: 0.002131
 >> iter 62000, loss: 0.002100
 >> iter 63000, loss: 0.002112
 >> iter 64000, loss: 0.002080
 >> iter 65000, loss: 0.002094
 >> iter 66000, loss: 0.002063
 >> iter 67000, loss: 0.002076
 >> iter 68000, loss: 0.002049
 >> iter 69000, loss: 0.002061
 >> iter 70000, loss: 0.002033
   Number of active neurons: 3
 >> iter 71000, loss: 0.002046
 >> iter 72000, loss: 0.002021
 >> iter 73000, loss: 0.002034
 >> iter 74000, loss: 0.002007
 >> iter 75000, loss: 0.002021
 >> iter 76000, loss: 0.001995
 >> iter 77000, loss: 0.002009
 >> iter 78000, loss: 0.001983
 >> iter 79000, loss: 0.002001
 >> iter 80000, loss: 0.001973
   Number of active neurons: 3
 >> iter 81000, loss: 0.001995
 >> iter 82000, loss: 0.001964
 >> iter 83000, loss: 0.001988
 >> iter 84000, loss: 0.001955
 >> iter 85000, loss: 0.001979
 >> iter 86000, loss: 0.001947
 >> iter 87000, loss: 0.001972
 >> iter 88000, loss: 0.001940
 >> iter 89000, loss: 0.001965
 >> iter 90000, loss: 0.001935
   Number of active neurons: 3
 >> iter 91000, loss: 0.001959
 >> iter 92000, loss: 0.001931
 >> iter 93000, loss: 0.001955
 >> iter 94000, loss: 0.001925
 >> iter 95000, loss: 0.001954
 >> iter 96000, loss: 0.001921
 >> iter 97000, loss: 0.001951
 >> iter 98000, loss: 0.001917
 >> iter 99000, loss: 0.001948
 >> iter 100000, loss: 0.001917
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 10.659039
 >> iter 2000, loss: 3.929508
 >> iter 3000, loss: 1.451017
 >> iter 4000, loss: 0.537997
 >> iter 5000, loss: 0.201611
 >> iter 6000, loss: 0.077367
 >> iter 7000, loss: 0.031440
 >> iter 8000, loss: 0.014259
 >> iter 9000, loss: 0.007840
 >> iter 10000, loss: 0.005294
   Number of active neurons: 8
 >> iter 11000, loss: 0.004319
 >> iter 12000, loss: 0.003824
 >> iter 13000, loss: 0.003633
 >> iter 14000, loss: 0.003453
 >> iter 15000, loss: 0.003391
 >> iter 16000, loss: 0.003275
 >> iter 17000, loss: 0.003246
 >> iter 18000, loss: 0.003155
 >> iter 19000, loss: 0.003140
 >> iter 20000, loss: 0.003068
   Number of active neurons: 8
 >> iter 21000, loss: 0.003062
 >> iter 22000, loss: 0.002997
 >> iter 23000, loss: 0.002998
 >> iter 24000, loss: 0.002939
 >> iter 25000, loss: 0.002946
 >> iter 26000, loss: 0.002896
 >> iter 27000, loss: 0.002906
 >> iter 28000, loss: 0.002861
 >> iter 29000, loss: 0.002873
 >> iter 30000, loss: 0.002832
   Number of active neurons: 6
 >> iter 31000, loss: 0.002847
 >> iter 32000, loss: 0.002809
 >> iter 33000, loss: 0.002827
 >> iter 34000, loss: 0.002791
 >> iter 35000, loss: 0.002812
 >> iter 36000, loss: 0.002776
 >> iter 37000, loss: 0.002798
 >> iter 38000, loss: 0.002762
 >> iter 39000, loss: 0.002787
 >> iter 40000, loss: 0.002751
   Number of active neurons: 6
 >> iter 41000, loss: 0.002776
 >> iter 42000, loss: 0.002743
 >> iter 43000, loss: 0.002766
 >> iter 44000, loss: 0.002736
 >> iter 45000, loss: 0.002760
 >> iter 46000, loss: 0.002728
 >> iter 47000, loss: 0.002751
 >> iter 48000, loss: 0.002722
 >> iter 49000, loss: 0.002745
 >> iter 50000, loss: 0.002714
   Number of active neurons: 6
 >> iter 51000, loss: 0.002736
 >> iter 52000, loss: 0.002705
 >> iter 53000, loss: 0.002726
 >> iter 54000, loss: 0.002702
 >> iter 55000, loss: 0.002718
 >> iter 56000, loss: 0.002694
 >> iter 57000, loss: 0.002713
 >> iter 58000, loss: 0.002686
 >> iter 59000, loss: 0.002707
 >> iter 60000, loss: 0.002681
   Number of active neurons: 6
 >> iter 61000, loss: 0.002700
 >> iter 62000, loss: 0.002676
 >> iter 63000, loss: 0.002695
 >> iter 64000, loss: 0.002668
 >> iter 65000, loss: 0.002689
 >> iter 66000, loss: 0.002662
 >> iter 67000, loss: 0.002679
 >> iter 68000, loss: 0.002656
 >> iter 69000, loss: 0.002669
 >> iter 70000, loss: 0.002643
   Number of active neurons: 6
 >> iter 71000, loss: 0.002659
 >> iter 72000, loss: 0.002635
 >> iter 73000, loss: 0.002650
 >> iter 74000, loss: 0.002625
 >> iter 75000, loss: 0.002640
 >> iter 76000, loss: 0.002614
 >> iter 77000, loss: 0.002630
 >> iter 78000, loss: 0.002603
 >> iter 79000, loss: 0.002622
 >> iter 80000, loss: 0.002592
   Number of active neurons: 5
 >> iter 81000, loss: 0.002614
 >> iter 82000, loss: 0.002581
 >> iter 83000, loss: 0.002604
 >> iter 84000, loss: 0.002569
 >> iter 85000, loss: 0.002592
 >> iter 86000, loss: 0.002557
 >> iter 87000, loss: 0.002580
 >> iter 88000, loss: 0.002545
 >> iter 89000, loss: 0.002568
 >> iter 90000, loss: 0.002535
   Number of active neurons: 5
 >> iter 91000, loss: 0.002557
 >> iter 92000, loss: 0.002526
 >> iter 93000, loss: 0.002547
 >> iter 94000, loss: 0.002515
 >> iter 95000, loss: 0.002541
 >> iter 96000, loss: 0.002506
 >> iter 97000, loss: 0.002533
 >> iter 98000, loss: 0.002497
 >> iter 99000, loss: 0.002526
 >> iter 100000, loss: 0.002493
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.674401
 >> iter 2000, loss: 3.935682
 >> iter 3000, loss: 1.453566
 >> iter 4000, loss: 0.539090
 >> iter 5000, loss: 0.202104
 >> iter 6000, loss: 0.077587
 >> iter 7000, loss: 0.031530
 >> iter 8000, loss: 0.014272
 >> iter 9000, loss: 0.007806
 >> iter 10000, loss: 0.005219
   Number of active neurons: 5
 >> iter 11000, loss: 0.004208
 >> iter 12000, loss: 0.003680
 >> iter 13000, loss: 0.003461
 >> iter 14000, loss: 0.003258
 >> iter 15000, loss: 0.003179
 >> iter 16000, loss: 0.003051
 >> iter 17000, loss: 0.003008
 >> iter 18000, loss: 0.002905
 >> iter 19000, loss: 0.002874
 >> iter 20000, loss: 0.002790
   Number of active neurons: 5
 >> iter 21000, loss: 0.002774
 >> iter 22000, loss: 0.002703
 >> iter 23000, loss: 0.002698
 >> iter 24000, loss: 0.002636
 >> iter 25000, loss: 0.002637
 >> iter 26000, loss: 0.002582
 >> iter 27000, loss: 0.002584
 >> iter 28000, loss: 0.002533
 >> iter 29000, loss: 0.002536
 >> iter 30000, loss: 0.002488
   Number of active neurons: 5
 >> iter 31000, loss: 0.002494
 >> iter 32000, loss: 0.002450
 >> iter 33000, loss: 0.002460
 >> iter 34000, loss: 0.002421
 >> iter 35000, loss: 0.002437
 >> iter 36000, loss: 0.002399
 >> iter 37000, loss: 0.002416
 >> iter 38000, loss: 0.002380
 >> iter 39000, loss: 0.002400
 >> iter 40000, loss: 0.002364
   Number of active neurons: 5
 >> iter 41000, loss: 0.002386
 >> iter 42000, loss: 0.002355
 >> iter 43000, loss: 0.002376
 >> iter 44000, loss: 0.002347
 >> iter 45000, loss: 0.002370
 >> iter 46000, loss: 0.002340
 >> iter 47000, loss: 0.002363
 >> iter 48000, loss: 0.002335
 >> iter 49000, loss: 0.002358
 >> iter 50000, loss: 0.002328
   Number of active neurons: 5
 >> iter 51000, loss: 0.002351
 >> iter 52000, loss: 0.002323
 >> iter 53000, loss: 0.002344
 >> iter 54000, loss: 0.002320
 >> iter 55000, loss: 0.002336
 >> iter 56000, loss: 0.002314
 >> iter 57000, loss: 0.002332
 >> iter 58000, loss: 0.002306
 >> iter 59000, loss: 0.002326
 >> iter 60000, loss: 0.002302
   Number of active neurons: 4
 >> iter 61000, loss: 0.002320
 >> iter 62000, loss: 0.002297
 >> iter 63000, loss: 0.002316
 >> iter 64000, loss: 0.002291
 >> iter 65000, loss: 0.002312
 >> iter 66000, loss: 0.002288
 >> iter 67000, loss: 0.002307
 >> iter 68000, loss: 0.002287
 >> iter 69000, loss: 0.002304
 >> iter 70000, loss: 0.002282
   Number of active neurons: 4
 >> iter 71000, loss: 0.002301
 >> iter 72000, loss: 0.002279
 >> iter 73000, loss: 0.002296
 >> iter 74000, loss: 0.002273
 >> iter 75000, loss: 0.002291
 >> iter 76000, loss: 0.002268
 >> iter 77000, loss: 0.002284
 >> iter 78000, loss: 0.002260
 >> iter 79000, loss: 0.002281
 >> iter 80000, loss: 0.002254
   Number of active neurons: 4
 >> iter 81000, loss: 0.002278
 >> iter 82000, loss: 0.002249
 >> iter 83000, loss: 0.002276
 >> iter 84000, loss: 0.002244
 >> iter 85000, loss: 0.002271
 >> iter 86000, loss: 0.002239
 >> iter 87000, loss: 0.002267
 >> iter 88000, loss: 0.002235
 >> iter 89000, loss: 0.002262
 >> iter 90000, loss: 0.002232
   Number of active neurons: 4
 >> iter 91000, loss: 0.002258
 >> iter 92000, loss: 0.002229
 >> iter 93000, loss: 0.002256
 >> iter 94000, loss: 0.002225
 >> iter 95000, loss: 0.002255
 >> iter 96000, loss: 0.002221
 >> iter 97000, loss: 0.002252
 >> iter 98000, loss: 0.002217
 >> iter 99000, loss: 0.002249
 >> iter 100000, loss: 0.002215
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.687371
 >> iter 2000, loss: 3.941643
 >> iter 3000, loss: 1.456415
 >> iter 4000, loss: 0.540609
 >> iter 5000, loss: 0.203010
 >> iter 6000, loss: 0.078215
 >> iter 7000, loss: 0.032003
 >> iter 8000, loss: 0.014672
 >> iter 9000, loss: 0.008145
 >> iter 10000, loss: 0.005531
   Number of active neurons: 6
 >> iter 11000, loss: 0.004493
 >> iter 12000, loss: 0.003960
 >> iter 13000, loss: 0.003729
 >> iter 14000, loss: 0.003525
 >> iter 15000, loss: 0.003439
 >> iter 16000, loss: 0.003312
 >> iter 17000, loss: 0.003265
 >> iter 18000, loss: 0.003168
 >> iter 19000, loss: 0.003139
 >> iter 20000, loss: 0.003062
   Number of active neurons: 6
 >> iter 21000, loss: 0.003044
 >> iter 22000, loss: 0.002977
 >> iter 23000, loss: 0.002969
 >> iter 24000, loss: 0.002909
 >> iter 25000, loss: 0.002907
 >> iter 26000, loss: 0.002854
 >> iter 27000, loss: 0.002856
 >> iter 28000, loss: 0.002809
 >> iter 29000, loss: 0.002813
 >> iter 30000, loss: 0.002770
   Number of active neurons: 6
 >> iter 31000, loss: 0.002778
 >> iter 32000, loss: 0.002738
 >> iter 33000, loss: 0.002749
 >> iter 34000, loss: 0.002711
 >> iter 35000, loss: 0.002725
 >> iter 36000, loss: 0.002688
 >> iter 37000, loss: 0.002705
 >> iter 38000, loss: 0.002669
 >> iter 39000, loss: 0.002689
 >> iter 40000, loss: 0.002653
   Number of active neurons: 6
 >> iter 41000, loss: 0.002673
 >> iter 42000, loss: 0.002640
 >> iter 43000, loss: 0.002660
 >> iter 44000, loss: 0.002630
 >> iter 45000, loss: 0.002650
 >> iter 46000, loss: 0.002621
 >> iter 47000, loss: 0.002641
 >> iter 48000, loss: 0.002613
 >> iter 49000, loss: 0.002634
 >> iter 50000, loss: 0.002606
   Number of active neurons: 6
 >> iter 51000, loss: 0.002627
 >> iter 52000, loss: 0.002600
 >> iter 53000, loss: 0.002620
 >> iter 54000, loss: 0.002597
 >> iter 55000, loss: 0.002612
 >> iter 56000, loss: 0.002591
 >> iter 57000, loss: 0.002608
 >> iter 58000, loss: 0.002582
 >> iter 59000, loss: 0.002601
 >> iter 60000, loss: 0.002576
   Number of active neurons: 6
 >> iter 61000, loss: 0.002594
 >> iter 62000, loss: 0.002572
 >> iter 63000, loss: 0.002590
 >> iter 64000, loss: 0.002567
 >> iter 65000, loss: 0.002587
 >> iter 66000, loss: 0.002565
 >> iter 67000, loss: 0.002584
 >> iter 68000, loss: 0.002566
 >> iter 69000, loss: 0.002582
 >> iter 70000, loss: 0.002562
   Number of active neurons: 5
 >> iter 71000, loss: 0.002581
 >> iter 72000, loss: 0.002562
 >> iter 73000, loss: 0.002580
 >> iter 74000, loss: 0.002560
 >> iter 75000, loss: 0.002579
 >> iter 76000, loss: 0.002559
 >> iter 77000, loss: 0.002577
 >> iter 78000, loss: 0.002557
 >> iter 79000, loss: 0.002579
 >> iter 80000, loss: 0.002556
   Number of active neurons: 5
 >> iter 81000, loss: 0.002581
 >> iter 82000, loss: 0.002556
 >> iter 83000, loss: 0.002581
 >> iter 84000, loss: 0.002554
 >> iter 85000, loss: 0.002579
 >> iter 86000, loss: 0.002552
 >> iter 87000, loss: 0.002578
 >> iter 88000, loss: 0.002551
 >> iter 89000, loss: 0.002576
 >> iter 90000, loss: 0.002550
   Number of active neurons: 5
 >> iter 91000, loss: 0.002574
 >> iter 92000, loss: 0.002550
 >> iter 93000, loss: 0.002573
 >> iter 94000, loss: 0.002547
 >> iter 95000, loss: 0.002574
 >> iter 96000, loss: 0.002544
 >> iter 97000, loss: 0.002571
 >> iter 98000, loss: 0.002541
 >> iter 99000, loss: 0.002569
 >> iter 100000, loss: 0.002541
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.711256
 >> iter 2000, loss: 3.948459
 >> iter 3000, loss: 1.457763
 >> iter 4000, loss: 0.540266
 >> iter 5000, loss: 0.202259
 >> iter 6000, loss: 0.077422
 >> iter 7000, loss: 0.031294
 >> iter 8000, loss: 0.014047
 >> iter 9000, loss: 0.007616
 >> iter 10000, loss: 0.005065
   Number of active neurons: 7
 >> iter 11000, loss: 0.004094
 >> iter 12000, loss: 0.003599
 >> iter 13000, loss: 0.003412
 >> iter 14000, loss: 0.003232
 >> iter 15000, loss: 0.003178
 >> iter 16000, loss: 0.003064
 >> iter 17000, loss: 0.003037
 >> iter 18000, loss: 0.002944
 >> iter 19000, loss: 0.002930
 >> iter 20000, loss: 0.002855
   Number of active neurons: 7
 >> iter 21000, loss: 0.002850
 >> iter 22000, loss: 0.002783
 >> iter 23000, loss: 0.002786
 >> iter 24000, loss: 0.002725
 >> iter 25000, loss: 0.002734
 >> iter 26000, loss: 0.002682
 >> iter 27000, loss: 0.002694
 >> iter 28000, loss: 0.002649
 >> iter 29000, loss: 0.002664
 >> iter 30000, loss: 0.002622
   Number of active neurons: 7
 >> iter 31000, loss: 0.002640
 >> iter 32000, loss: 0.002602
 >> iter 33000, loss: 0.002623
 >> iter 34000, loss: 0.002587
 >> iter 35000, loss: 0.002613
 >> iter 36000, loss: 0.002578
 >> iter 37000, loss: 0.002607
 >> iter 38000, loss: 0.002575
 >> iter 39000, loss: 0.002606
 >> iter 40000, loss: 0.002574
   Number of active neurons: 7
 >> iter 41000, loss: 0.002606
 >> iter 42000, loss: 0.002577
 >> iter 43000, loss: 0.002606
 >> iter 44000, loss: 0.002578
 >> iter 45000, loss: 0.002608
 >> iter 46000, loss: 0.002579
 >> iter 47000, loss: 0.002609
 >> iter 48000, loss: 0.002582
 >> iter 49000, loss: 0.002612
 >> iter 50000, loss: 0.002584
   Number of active neurons: 7
 >> iter 51000, loss: 0.002614
 >> iter 52000, loss: 0.002587
 >> iter 53000, loss: 0.002615
 >> iter 54000, loss: 0.002592
 >> iter 55000, loss: 0.002616
 >> iter 56000, loss: 0.002595
 >> iter 57000, loss: 0.002620
 >> iter 58000, loss: 0.002595
 >> iter 59000, loss: 0.002622
 >> iter 60000, loss: 0.002598
   Number of active neurons: 7
 >> iter 61000, loss: 0.002623
 >> iter 62000, loss: 0.002600
 >> iter 63000, loss: 0.002625
 >> iter 64000, loss: 0.002600
 >> iter 65000, loss: 0.002627
 >> iter 66000, loss: 0.002603
 >> iter 67000, loss: 0.002627
 >> iter 68000, loss: 0.002607
 >> iter 69000, loss: 0.002628
 >> iter 70000, loss: 0.002606
   Number of active neurons: 7
 >> iter 71000, loss: 0.002629
 >> iter 72000, loss: 0.002608
 >> iter 73000, loss: 0.002631
 >> iter 74000, loss: 0.002609
 >> iter 75000, loss: 0.002632
 >> iter 76000, loss: 0.002609
 >> iter 77000, loss: 0.002632
 >> iter 78000, loss: 0.002608
 >> iter 79000, loss: 0.002634
 >> iter 80000, loss: 0.002607
   Number of active neurons: 6
 >> iter 81000, loss: 0.002636
 >> iter 82000, loss: 0.002605
 >> iter 83000, loss: 0.002638
 >> iter 84000, loss: 0.002604
 >> iter 85000, loss: 0.002636
 >> iter 86000, loss: 0.002603
 >> iter 87000, loss: 0.002635
 >> iter 88000, loss: 0.002601
 >> iter 89000, loss: 0.002633
 >> iter 90000, loss: 0.002602
   Number of active neurons: 6
 >> iter 91000, loss: 0.002632
 >> iter 92000, loss: 0.002602
 >> iter 93000, loss: 0.002631
 >> iter 94000, loss: 0.002598
 >> iter 95000, loss: 0.002632
 >> iter 96000, loss: 0.002595
 >> iter 97000, loss: 0.002629
 >> iter 98000, loss: 0.002591
 >> iter 99000, loss: 0.002627
 >> iter 100000, loss: 0.002592
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.703279
 >> iter 2000, loss: 3.946220
 >> iter 3000, loss: 1.457442
 >> iter 4000, loss: 0.540572
 >> iter 5000, loss: 0.202721
 >> iter 6000, loss: 0.077914
 >> iter 7000, loss: 0.031763
 >> iter 8000, loss: 0.014487
 >> iter 9000, loss: 0.008019
 >> iter 10000, loss: 0.005439
   Number of active neurons: 6
 >> iter 11000, loss: 0.004432
 >> iter 12000, loss: 0.003915
 >> iter 13000, loss: 0.003705
 >> iter 14000, loss: 0.003510
 >> iter 15000, loss: 0.003444
 >> iter 16000, loss: 0.003325
 >> iter 17000, loss: 0.003295
 >> iter 18000, loss: 0.003198
 >> iter 19000, loss: 0.003177
 >> iter 20000, loss: 0.003094
   Number of active neurons: 6
 >> iter 21000, loss: 0.003078
 >> iter 22000, loss: 0.003002
 >> iter 23000, loss: 0.002994
 >> iter 24000, loss: 0.002927
 >> iter 25000, loss: 0.002929
 >> iter 26000, loss: 0.002871
 >> iter 27000, loss: 0.002876
 >> iter 28000, loss: 0.002825
 >> iter 29000, loss: 0.002832
 >> iter 30000, loss: 0.002785
   Number of active neurons: 6
 >> iter 31000, loss: 0.002795
 >> iter 32000, loss: 0.002749
 >> iter 33000, loss: 0.002760
 >> iter 34000, loss: 0.002717
 >> iter 35000, loss: 0.002733
 >> iter 36000, loss: 0.002692
 >> iter 37000, loss: 0.002709
 >> iter 38000, loss: 0.002668
 >> iter 39000, loss: 0.002687
 >> iter 40000, loss: 0.002646
   Number of active neurons: 4
 >> iter 41000, loss: 0.002666
 >> iter 42000, loss: 0.002628
 >> iter 43000, loss: 0.002647
 >> iter 44000, loss: 0.002612
 >> iter 45000, loss: 0.002632
 >> iter 46000, loss: 0.002597
 >> iter 47000, loss: 0.002617
 >> iter 48000, loss: 0.002583
 >> iter 49000, loss: 0.002603
 >> iter 50000, loss: 0.002566
   Number of active neurons: 4
 >> iter 51000, loss: 0.002585
 >> iter 52000, loss: 0.002550
 >> iter 53000, loss: 0.002567
 >> iter 54000, loss: 0.002538
 >> iter 55000, loss: 0.002551
 >> iter 56000, loss: 0.002523
 >> iter 57000, loss: 0.002538
 >> iter 58000, loss: 0.002506
 >> iter 59000, loss: 0.002522
 >> iter 60000, loss: 0.002491
   Number of active neurons: 4
 >> iter 61000, loss: 0.002506
 >> iter 62000, loss: 0.002475
 >> iter 63000, loss: 0.002488
 >> iter 64000, loss: 0.002455
 >> iter 65000, loss: 0.002469
 >> iter 66000, loss: 0.002436
 >> iter 67000, loss: 0.002447
 >> iter 68000, loss: 0.002418
 >> iter 69000, loss: 0.002428
 >> iter 70000, loss: 0.002397
   Number of active neurons: 4
 >> iter 71000, loss: 0.002410
 >> iter 72000, loss: 0.002381
 >> iter 73000, loss: 0.002394
 >> iter 74000, loss: 0.002365
 >> iter 75000, loss: 0.002379
 >> iter 76000, loss: 0.002352
 >> iter 77000, loss: 0.002365
 >> iter 78000, loss: 0.002337
 >> iter 79000, loss: 0.002355
 >> iter 80000, loss: 0.002326
   Number of active neurons: 4
 >> iter 81000, loss: 0.002347
 >> iter 82000, loss: 0.002314
 >> iter 83000, loss: 0.002338
 >> iter 84000, loss: 0.002302
 >> iter 85000, loss: 0.002325
 >> iter 86000, loss: 0.002291
 >> iter 87000, loss: 0.002314
 >> iter 88000, loss: 0.002279
 >> iter 89000, loss: 0.002302
 >> iter 90000, loss: 0.002268
   Number of active neurons: 4
 >> iter 91000, loss: 0.002289
 >> iter 92000, loss: 0.002257
 >> iter 93000, loss: 0.002277
 >> iter 94000, loss: 0.002244
 >> iter 95000, loss: 0.002269
 >> iter 96000, loss: 0.002232
 >> iter 97000, loss: 0.002258
 >> iter 98000, loss: 0.002221
 >> iter 99000, loss: 0.002248
 >> iter 100000, loss: 0.002214
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

