 > Problema: tomita7nueva
 > Args:
   - Hidden size: 6
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.665059
 >> iter 2000, loss: 8.973981
 >> iter 3000, loss: 4.913107
 >> iter 4000, loss: 2.727337
 >> iter 5000, loss: 1.908094
 >> iter 6000, loss: 1.358885
 >> iter 7000, loss: 0.968680
 >> iter 8000, loss: 0.865405
 >> iter 9000, loss: 0.907081
 >> iter 10000, loss: 0.749670
   Number of active neurons: 4
 >> iter 11000, loss: 0.720081
 >> iter 12000, loss: 0.654407
 >> iter 13000, loss: 0.664753
 >> iter 14000, loss: 0.611388
 >> iter 15000, loss: 0.576527
 >> iter 16000, loss: 0.455105
 >> iter 17000, loss: 0.640330
 >> iter 18000, loss: 0.519712
 >> iter 19000, loss: 0.508383
 >> iter 20000, loss: 0.500373
   Number of active neurons: 4
 >> iter 21000, loss: 0.494312
 >> iter 22000, loss: 0.527114
 >> iter 23000, loss: 0.495397
 >> iter 24000, loss: 0.649696
 >> iter 25000, loss: 0.508529
 >> iter 26000, loss: 0.553349
 >> iter 27000, loss: 0.628259
 >> iter 28000, loss: 0.592418
 >> iter 29000, loss: 0.663391
 >> iter 30000, loss: 0.519078
   Number of active neurons: 4
 >> iter 31000, loss: 0.534921
 >> iter 32000, loss: 0.416580
 >> iter 33000, loss: 0.461839
 >> iter 34000, loss: 0.416979
 >> iter 35000, loss: 0.418058
 >> iter 36000, loss: 0.490311
 >> iter 37000, loss: 0.353153
 >> iter 38000, loss: 0.579381
 >> iter 39000, loss: 0.502449
 >> iter 40000, loss: 0.508098
   Number of active neurons: 4
 >> iter 41000, loss: 0.501256
 >> iter 42000, loss: 0.638105
 >> iter 43000, loss: 0.690509
 >> iter 44000, loss: 0.612392
 >> iter 45000, loss: 0.541757
 >> iter 46000, loss: 0.598070
 >> iter 47000, loss: 0.642843
 >> iter 48000, loss: 0.529427
 >> iter 49000, loss: 0.529063
 >> iter 50000, loss: 0.515617
   Number of active neurons: 4
 >> iter 51000, loss: 0.499240
 >> iter 52000, loss: 0.598580
 >> iter 53000, loss: 0.552016
 >> iter 54000, loss: 0.406167
 >> iter 55000, loss: 0.427342
 >> iter 56000, loss: 0.438500
 >> iter 57000, loss: 0.460178
 >> iter 58000, loss: 0.397989
 >> iter 59000, loss: 0.488366
 >> iter 60000, loss: 0.771293
   Number of active neurons: 4
 >> iter 61000, loss: 0.651733
 >> iter 62000, loss: 0.510962
 >> iter 63000, loss: 0.565101
 >> iter 64000, loss: 0.670827
 >> iter 65000, loss: 0.541920
 >> iter 66000, loss: 0.617500
 >> iter 67000, loss: 0.582891
 >> iter 68000, loss: 0.461976
 >> iter 69000, loss: 0.446663
 >> iter 70000, loss: 0.496323
   Number of active neurons: 4
 >> iter 71000, loss: 0.427586
 >> iter 72000, loss: 0.468097
 >> iter 73000, loss: 0.349137
 >> iter 74000, loss: 0.404958
 >> iter 75000, loss: 0.471015
 >> iter 76000, loss: 0.577288
 >> iter 77000, loss: 0.530917
 >> iter 78000, loss: 0.466182
 >> iter 79000, loss: 0.443078
 >> iter 80000, loss: 0.510536
   Number of active neurons: 4
 >> iter 81000, loss: 0.681531
 >> iter 82000, loss: 0.569527
 >> iter 83000, loss: 0.623826
 >> iter 84000, loss: 0.396038
 >> iter 85000, loss: 0.370617
 >> iter 86000, loss: 0.564186
 >> iter 87000, loss: 0.575851
 >> iter 88000, loss: 0.558454
 >> iter 89000, loss: 0.711412
 >> iter 90000, loss: 0.700688
   Number of active neurons: 5
 >> iter 91000, loss: 0.529068
 >> iter 92000, loss: 0.494104
 >> iter 93000, loss: 0.631885
 >> iter 94000, loss: 0.486194
 >> iter 95000, loss: 0.497570
 >> iter 96000, loss: 0.378349
 >> iter 97000, loss: 0.493956
 >> iter 98000, loss: 0.378177
 >> iter 99000, loss: 0.445855
 >> iter 100000, loss: 0.412627
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 17.1188587428
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.204447
 >> iter 2000, loss: 12.364080
 >> iter 3000, loss: 8.161080
 >> iter 4000, loss: 4.832967
 >> iter 5000, loss: 3.010430
 >> iter 6000, loss: 1.825688
 >> iter 7000, loss: 1.606985
 >> iter 8000, loss: 1.424364
 >> iter 9000, loss: 1.166931
 >> iter 10000, loss: 1.066894
   Number of active neurons: 5
 >> iter 11000, loss: 0.882650
 >> iter 12000, loss: 0.801563
 >> iter 13000, loss: 0.525136
 >> iter 14000, loss: 0.609523
 >> iter 15000, loss: 0.723782
 >> iter 16000, loss: 0.602786
 >> iter 17000, loss: 0.655589
 >> iter 18000, loss: 0.580044
 >> iter 19000, loss: 0.480818
 >> iter 20000, loss: 0.418778
   Number of active neurons: 5
 >> iter 21000, loss: 0.608596
 >> iter 22000, loss: 0.603398
 >> iter 23000, loss: 0.627737
 >> iter 24000, loss: 0.517179
 >> iter 25000, loss: 0.668648
 >> iter 26000, loss: 0.449663
 >> iter 27000, loss: 0.362597
 >> iter 28000, loss: 0.384551
 >> iter 29000, loss: 0.467364
 >> iter 30000, loss: 0.517132
   Number of active neurons: 5
 >> iter 31000, loss: 0.501881
 >> iter 32000, loss: 0.570296
 >> iter 33000, loss: 0.425650
 >> iter 34000, loss: 0.470110
 >> iter 35000, loss: 0.584020
 >> iter 36000, loss: 0.588862
 >> iter 37000, loss: 0.622313
 >> iter 38000, loss: 0.498465
 >> iter 39000, loss: 0.518172
 >> iter 40000, loss: 0.483305
   Number of active neurons: 5
 >> iter 41000, loss: 0.555615
 >> iter 42000, loss: 0.552906
 >> iter 43000, loss: 0.508487
 >> iter 44000, loss: 0.505925
 >> iter 45000, loss: 0.547943
 >> iter 46000, loss: 0.620946
 >> iter 47000, loss: 0.521309
 >> iter 48000, loss: 0.604498
 >> iter 49000, loss: 0.523100
 >> iter 50000, loss: 0.521055
   Number of active neurons: 5
 >> iter 51000, loss: 0.476362
 >> iter 52000, loss: 0.454195
 >> iter 53000, loss: 0.479771
 >> iter 54000, loss: 0.503732
 >> iter 55000, loss: 0.513391
 >> iter 56000, loss: 0.500200
 >> iter 57000, loss: 0.499748
 >> iter 58000, loss: 0.478616
 >> iter 59000, loss: 0.448070
 >> iter 60000, loss: 0.432462
   Number of active neurons: 5
 >> iter 61000, loss: 0.496280
 >> iter 62000, loss: 0.354972
 >> iter 63000, loss: 0.412515
 >> iter 64000, loss: 0.442000
 >> iter 65000, loss: 0.582488
 >> iter 66000, loss: 0.614108
 >> iter 67000, loss: 0.538735
 >> iter 68000, loss: 0.448323
 >> iter 69000, loss: 0.387112
 >> iter 70000, loss: 0.396279
   Number of active neurons: 5
 >> iter 71000, loss: 0.538843
 >> iter 72000, loss: 0.566196
 >> iter 73000, loss: 0.407035
 >> iter 74000, loss: 0.493480
 >> iter 75000, loss: 0.488889
 >> iter 76000, loss: 0.411398
 >> iter 77000, loss: 0.510793
 >> iter 78000, loss: 0.451466
 >> iter 79000, loss: 0.647270
 >> iter 80000, loss: 0.544267
   Number of active neurons: 4
 >> iter 81000, loss: 0.610439
 >> iter 82000, loss: 0.573796
 >> iter 83000, loss: 0.592615
 >> iter 84000, loss: 0.584234
 >> iter 85000, loss: 0.406552
 >> iter 86000, loss: 0.450467
 >> iter 87000, loss: 0.483096
 >> iter 88000, loss: 0.482007
 >> iter 89000, loss: 0.378237
 >> iter 90000, loss: 0.432185
   Number of active neurons: 4
 >> iter 91000, loss: 0.578955
 >> iter 92000, loss: 0.452548
 >> iter 93000, loss: 0.359027
 >> iter 94000, loss: 0.454562
 >> iter 95000, loss: 0.361899
 >> iter 96000, loss: 0.423090
 >> iter 97000, loss: 0.403256
 >> iter 98000, loss: 0.441449
 >> iter 99000, loss: 0.497459
 >> iter 100000, loss: 0.788313
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.280856
 >> iter 2000, loss: 10.226832
 >> iter 3000, loss: 5.848888
 >> iter 4000, loss: 3.138688
 >> iter 5000, loss: 1.669682
 >> iter 6000, loss: 1.105012
 >> iter 7000, loss: 0.711082
 >> iter 8000, loss: 0.441816
 >> iter 9000, loss: 0.406803
 >> iter 10000, loss: 0.461507
   Number of active neurons: 6
 >> iter 11000, loss: 0.536762
 >> iter 12000, loss: 0.408896
 >> iter 13000, loss: 0.447583
 >> iter 14000, loss: 0.519396
 >> iter 15000, loss: 0.535436
 >> iter 16000, loss: 0.473273
 >> iter 17000, loss: 0.469514
 >> iter 18000, loss: 0.500661
 >> iter 19000, loss: 0.457728
 >> iter 20000, loss: 0.470565
   Number of active neurons: 6
 >> iter 21000, loss: 0.450644
 >> iter 22000, loss: 0.480721
 >> iter 23000, loss: 0.388290
 >> iter 24000, loss: 0.422912
 >> iter 25000, loss: 0.484098
 >> iter 26000, loss: 0.524192
 >> iter 27000, loss: 0.432386
 >> iter 28000, loss: 0.384085
 >> iter 29000, loss: 0.400550
 >> iter 30000, loss: 0.369475
   Number of active neurons: 5
 >> iter 31000, loss: 0.372802
 >> iter 32000, loss: 0.421000
 >> iter 33000, loss: 0.411027
 >> iter 34000, loss: 0.386669
 >> iter 35000, loss: 0.291445
 >> iter 36000, loss: 0.326984
 >> iter 37000, loss: 0.382359
 >> iter 38000, loss: 0.517466
 >> iter 39000, loss: 0.433195
 >> iter 40000, loss: 0.435115
   Number of active neurons: 5
 >> iter 41000, loss: 0.476890
 >> iter 42000, loss: 0.519403
 >> iter 43000, loss: 0.548073
 >> iter 44000, loss: 0.516321
 >> iter 45000, loss: 0.408093
 >> iter 46000, loss: 0.415205
 >> iter 47000, loss: 0.347133
 >> iter 48000, loss: 0.400432
 >> iter 49000, loss: 0.274312
 >> iter 50000, loss: 0.324308
   Number of active neurons: 5
 >> iter 51000, loss: 0.242951
 >> iter 52000, loss: 0.344189
 >> iter 53000, loss: 0.452902
 >> iter 54000, loss: 0.465623
 >> iter 55000, loss: 0.302436
 >> iter 56000, loss: 0.394530
 >> iter 57000, loss: 0.423490
 >> iter 58000, loss: 0.407399
 >> iter 59000, loss: 0.381927
 >> iter 60000, loss: 0.359973
   Number of active neurons: 5
 >> iter 61000, loss: 0.312940
 >> iter 62000, loss: 0.325102
 >> iter 63000, loss: 0.425640
 >> iter 64000, loss: 0.390940
 >> iter 65000, loss: 0.312628
 >> iter 66000, loss: 0.333721
 >> iter 67000, loss: 0.486905
 >> iter 68000, loss: 0.412052
 >> iter 69000, loss: 0.334449
 >> iter 70000, loss: 0.316780
   Number of active neurons: 5
 >> iter 71000, loss: 0.366844
 >> iter 72000, loss: 0.367357
 >> iter 73000, loss: 0.409005
 >> iter 74000, loss: 0.404994
 >> iter 75000, loss: 0.402482
 >> iter 76000, loss: 0.348548
 >> iter 77000, loss: 0.482966
 >> iter 78000, loss: 0.303762
 >> iter 79000, loss: 0.284941
 >> iter 80000, loss: 0.281924
   Number of active neurons: 5
 >> iter 81000, loss: 0.448255
 >> iter 82000, loss: 0.296222
 >> iter 83000, loss: 0.389489
 >> iter 84000, loss: 0.319795
 >> iter 85000, loss: 0.224204
 >> iter 86000, loss: 0.309558
 >> iter 87000, loss: 0.269151
 >> iter 88000, loss: 0.277471
 >> iter 89000, loss: 0.256704
 >> iter 90000, loss: 0.330951
   Number of active neurons: 5
 >> iter 91000, loss: 0.303958
 >> iter 92000, loss: 0.371419
 >> iter 93000, loss: 0.270449
 >> iter 94000, loss: 0.301131
 >> iter 95000, loss: 0.287759
 >> iter 96000, loss: 0.273109
 >> iter 97000, loss: 0.289289
 >> iter 98000, loss: 0.381742
 >> iter 99000, loss: 0.308392
 >> iter 100000, loss: 0.312304
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.247754
 >> iter 2000, loss: 10.254153
 >> iter 3000, loss: 5.335503
 >> iter 4000, loss: 2.833094
 >> iter 5000, loss: 1.586487
 >> iter 6000, loss: 1.112613
 >> iter 7000, loss: 0.774267
 >> iter 8000, loss: 0.551550
 >> iter 9000, loss: 0.484565
 >> iter 10000, loss: 0.474490
   Number of active neurons: 5
 >> iter 11000, loss: 0.541042
 >> iter 12000, loss: 0.539449
 >> iter 13000, loss: 0.526833
 >> iter 14000, loss: 0.377204
 >> iter 15000, loss: 0.325294
 >> iter 16000, loss: 0.482354
 >> iter 17000, loss: 0.502677
 >> iter 18000, loss: 0.485995
 >> iter 19000, loss: 0.547332
 >> iter 20000, loss: 0.423781
   Number of active neurons: 5
 >> iter 21000, loss: 0.325711
 >> iter 22000, loss: 0.425187
 >> iter 23000, loss: 0.399535
 >> iter 24000, loss: 0.631893
 >> iter 25000, loss: 0.561562
 >> iter 26000, loss: 0.520501
 >> iter 27000, loss: 0.556686
 >> iter 28000, loss: 0.505944
 >> iter 29000, loss: 0.484461
 >> iter 30000, loss: 0.465759
   Number of active neurons: 6
 >> iter 31000, loss: 0.517397
 >> iter 32000, loss: 0.412654
 >> iter 33000, loss: 0.420614
 >> iter 34000, loss: 0.365860
 >> iter 35000, loss: 0.418024
 >> iter 36000, loss: 0.356044
 >> iter 37000, loss: 0.482699
 >> iter 38000, loss: 0.285719
 >> iter 39000, loss: 0.309102
 >> iter 40000, loss: 0.492256
   Number of active neurons: 5
 >> iter 41000, loss: 0.511030
 >> iter 42000, loss: 0.473576
 >> iter 43000, loss: 0.555587
 >> iter 44000, loss: 0.457810
 >> iter 45000, loss: 0.413210
 >> iter 46000, loss: 0.579418
 >> iter 47000, loss: 0.437628
 >> iter 48000, loss: 0.417173
 >> iter 49000, loss: 0.578563
 >> iter 50000, loss: 0.523449
   Number of active neurons: 5
 >> iter 51000, loss: 0.405155
 >> iter 52000, loss: 0.525280
 >> iter 53000, loss: 0.318674
 >> iter 54000, loss: 0.454416
 >> iter 55000, loss: 0.552199
 >> iter 56000, loss: 0.540569
 >> iter 57000, loss: 0.468017
 >> iter 58000, loss: 0.376854
 >> iter 59000, loss: 0.366631
 >> iter 60000, loss: 0.401047
   Number of active neurons: 5
 >> iter 61000, loss: 0.598825
 >> iter 62000, loss: 0.421323
 >> iter 63000, loss: 0.526373
 >> iter 64000, loss: 0.556949
 >> iter 65000, loss: 0.471420
 >> iter 66000, loss: 0.406269
 >> iter 67000, loss: 0.443699
 >> iter 68000, loss: 0.394675
 >> iter 69000, loss: 0.553353
 >> iter 70000, loss: 0.530182
   Number of active neurons: 5
 >> iter 71000, loss: 0.470815
 >> iter 72000, loss: 0.383978
 >> iter 73000, loss: 0.378883
 >> iter 74000, loss: 0.550018
 >> iter 75000, loss: 0.364562
 >> iter 76000, loss: 0.387092
 >> iter 77000, loss: 0.367530
 >> iter 78000, loss: 0.495219
 >> iter 79000, loss: 0.311051
 >> iter 80000, loss: 0.266105
   Number of active neurons: 5
 >> iter 81000, loss: 0.340569
 >> iter 82000, loss: 0.362360
 >> iter 83000, loss: 0.370703
 >> iter 84000, loss: 0.456251
 >> iter 85000, loss: 0.453121
 >> iter 86000, loss: 0.428750
 >> iter 87000, loss: 0.369028
 >> iter 88000, loss: 0.368648
 >> iter 89000, loss: 0.441994
 >> iter 90000, loss: 0.329977
   Number of active neurons: 5
 >> iter 91000, loss: 0.396799
 >> iter 92000, loss: 0.456093
 >> iter 93000, loss: 0.527544
 >> iter 94000, loss: 0.480627
 >> iter 95000, loss: 0.498395
 >> iter 96000, loss: 0.385736
 >> iter 97000, loss: 0.330071
 >> iter 98000, loss: 0.333073
 >> iter 99000, loss: 0.335624
 >> iter 100000, loss: 0.323800
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.176456
 >> iter 2000, loss: 12.809717
 >> iter 3000, loss: 8.883027
 >> iter 4000, loss: 6.117333
 >> iter 5000, loss: 3.995153
 >> iter 6000, loss: 2.258864
 >> iter 7000, loss: 1.471375
 >> iter 8000, loss: 1.097068
 >> iter 9000, loss: 0.952832
 >> iter 10000, loss: 0.772840
   Number of active neurons: 6
 >> iter 11000, loss: 0.694781
 >> iter 12000, loss: 0.641176
 >> iter 13000, loss: 0.539935
 >> iter 14000, loss: 0.496280
 >> iter 15000, loss: 0.607500
 >> iter 16000, loss: 0.585575
 >> iter 17000, loss: 0.549214
 >> iter 18000, loss: 0.472552
 >> iter 19000, loss: 0.435347
 >> iter 20000, loss: 0.406986
   Number of active neurons: 5
 >> iter 21000, loss: 0.539152
 >> iter 22000, loss: 0.778194
 >> iter 23000, loss: 0.534262
 >> iter 24000, loss: 0.508269
 >> iter 25000, loss: 0.545789
 >> iter 26000, loss: 0.584236
 >> iter 27000, loss: 0.514394
 >> iter 28000, loss: 0.497664
 >> iter 29000, loss: 0.529329
 >> iter 30000, loss: 0.466316
   Number of active neurons: 5
 >> iter 31000, loss: 0.521649
 >> iter 32000, loss: 0.525442
 >> iter 33000, loss: 0.470628
 >> iter 34000, loss: 0.415964
 >> iter 35000, loss: 0.611502
 >> iter 36000, loss: 0.472505
 >> iter 37000, loss: 0.337518
 >> iter 38000, loss: 0.631139
 >> iter 39000, loss: 0.538662
 >> iter 40000, loss: 0.428014
   Number of active neurons: 5
 >> iter 41000, loss: 0.459429
 >> iter 42000, loss: 0.472896
 >> iter 43000, loss: 0.526302
 >> iter 44000, loss: 0.517860
 >> iter 45000, loss: 0.564333
 >> iter 46000, loss: 0.557875
 >> iter 47000, loss: 0.451617
 >> iter 48000, loss: 0.450528
 >> iter 49000, loss: 0.481396
 >> iter 50000, loss: 0.529463
   Number of active neurons: 5
 >> iter 51000, loss: 0.480288
 >> iter 52000, loss: 0.484599
 >> iter 53000, loss: 0.389185
 >> iter 54000, loss: 0.287523
 >> iter 55000, loss: 0.311878
 >> iter 56000, loss: 0.311907
 >> iter 57000, loss: 0.329516
 >> iter 58000, loss: 0.418308
 >> iter 59000, loss: 0.508504
 >> iter 60000, loss: 0.479405
   Number of active neurons: 5
 >> iter 61000, loss: 0.411300
 >> iter 62000, loss: 0.349368
 >> iter 63000, loss: 0.516344
 >> iter 64000, loss: 0.548137
 >> iter 65000, loss: 0.535996
 >> iter 66000, loss: 0.559289
 >> iter 67000, loss: 0.560455
 >> iter 68000, loss: 0.441626
 >> iter 69000, loss: 0.471930
 >> iter 70000, loss: 0.424405
   Number of active neurons: 5
 >> iter 71000, loss: 0.498165
 >> iter 72000, loss: 0.378848
 >> iter 73000, loss: 0.506917
 >> iter 74000, loss: 0.419324
 >> iter 75000, loss: 0.507727
 >> iter 76000, loss: 0.543547
 >> iter 77000, loss: 0.449243
 >> iter 78000, loss: 0.559964
 >> iter 79000, loss: 0.427278
 >> iter 80000, loss: 0.388351
   Number of active neurons: 5
 >> iter 81000, loss: 0.368600
 >> iter 82000, loss: 0.357772
 >> iter 83000, loss: 0.558038
 >> iter 84000, loss: 0.508994
 >> iter 85000, loss: 0.555928
 >> iter 86000, loss: 0.533363
 >> iter 87000, loss: 0.550879
 >> iter 88000, loss: 0.674596
 >> iter 89000, loss: 0.485075
 >> iter 90000, loss: 0.473058
   Number of active neurons: 5
 >> iter 91000, loss: 0.389983
 >> iter 92000, loss: 0.343358
 >> iter 93000, loss: 0.484049
 >> iter 94000, loss: 0.469320
 >> iter 95000, loss: 0.534079
 >> iter 96000, loss: 0.448239
 >> iter 97000, loss: 0.364531
 >> iter 98000, loss: 0.451678
 >> iter 99000, loss: 0.525913
 >> iter 100000, loss: 0.494027
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.981645
 >> iter 2000, loss: 10.472385
 >> iter 3000, loss: 5.797479
 >> iter 4000, loss: 2.808773
 >> iter 5000, loss: 1.340548
 >> iter 6000, loss: 0.782877
 >> iter 7000, loss: 0.520255
 >> iter 8000, loss: 0.306650
 >> iter 9000, loss: 0.351015
 >> iter 10000, loss: 0.455326
   Number of active neurons: 6
 >> iter 11000, loss: 0.372520
 >> iter 12000, loss: 0.449779
 >> iter 13000, loss: 0.327963
 >> iter 14000, loss: 0.303934
 >> iter 15000, loss: 0.319694
 >> iter 16000, loss: 0.249386
 >> iter 17000, loss: 0.320992
 >> iter 18000, loss: 0.373775
 >> iter 19000, loss: 0.317711
 >> iter 20000, loss: 0.393861
   Number of active neurons: 5
 >> iter 21000, loss: 0.367888
 >> iter 22000, loss: 0.366215
 >> iter 23000, loss: 0.266954
 >> iter 24000, loss: 0.368562
 >> iter 25000, loss: 0.371337
 >> iter 26000, loss: 0.371144
 >> iter 27000, loss: 0.317651
 >> iter 28000, loss: 0.254748
 >> iter 29000, loss: 0.281926
 >> iter 30000, loss: 0.371647
   Number of active neurons: 5
 >> iter 31000, loss: 0.429141
 >> iter 32000, loss: 0.333499
 >> iter 33000, loss: 0.298996
 >> iter 34000, loss: 0.479863
 >> iter 35000, loss: 0.496645
 >> iter 36000, loss: 0.466020
 >> iter 37000, loss: 0.416910
 >> iter 38000, loss: 0.352140
 >> iter 39000, loss: 0.317487
 >> iter 40000, loss: 0.338982
   Number of active neurons: 5
 >> iter 41000, loss: 0.359465
 >> iter 42000, loss: 0.392634
 >> iter 43000, loss: 0.334342
 >> iter 44000, loss: 0.364397
 >> iter 45000, loss: 0.356870
 >> iter 46000, loss: 0.488175
 >> iter 47000, loss: 0.427992
 >> iter 48000, loss: 0.450579
 >> iter 49000, loss: 0.366189
 >> iter 50000, loss: 0.409514
   Number of active neurons: 4
 >> iter 51000, loss: 0.473116
 >> iter 52000, loss: 0.500716
 >> iter 53000, loss: 0.349845
 >> iter 54000, loss: 0.432260
 >> iter 55000, loss: 0.473210
 >> iter 56000, loss: 0.358303
 >> iter 57000, loss: 0.415031
 >> iter 58000, loss: 0.506994
 >> iter 59000, loss: 0.437935
 >> iter 60000, loss: 0.347019
   Number of active neurons: 4
 >> iter 61000, loss: 0.317281
 >> iter 62000, loss: 0.399366
 >> iter 63000, loss: 0.439081
 >> iter 64000, loss: 0.444591
 >> iter 65000, loss: 0.397143
 >> iter 66000, loss: 0.485419
 >> iter 67000, loss: 0.462913
 >> iter 68000, loss: 0.378416
 >> iter 69000, loss: 0.356969
 >> iter 70000, loss: 0.418082
   Number of active neurons: 4
 >> iter 71000, loss: 0.326523
 >> iter 72000, loss: 0.331149
 >> iter 73000, loss: 0.467773
 >> iter 74000, loss: 0.389643
 >> iter 75000, loss: 0.357232
 >> iter 76000, loss: 0.309109
 >> iter 77000, loss: 0.396243
 >> iter 78000, loss: 0.480511
 >> iter 79000, loss: 0.571772
 >> iter 80000, loss: 0.493584
   Number of active neurons: 4
 >> iter 81000, loss: 0.459898
 >> iter 82000, loss: 0.355910
 >> iter 83000, loss: 0.405083
 >> iter 84000, loss: 0.415086
 >> iter 85000, loss: 0.361550
 >> iter 86000, loss: 0.407601
 >> iter 87000, loss: 0.404067
 >> iter 88000, loss: 0.354162
 >> iter 89000, loss: 0.355177
 >> iter 90000, loss: 0.476856
   Number of active neurons: 4
 >> iter 91000, loss: 0.449422
 >> iter 92000, loss: 0.433583
 >> iter 93000, loss: 0.354032
 >> iter 94000, loss: 0.347112
 >> iter 95000, loss: 0.362836
 >> iter 96000, loss: 0.455148
 >> iter 97000, loss: 0.492503
 >> iter 98000, loss: 0.382082
 >> iter 99000, loss: 0.416458
 >> iter 100000, loss: 0.357936
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.311246
 >> iter 2000, loss: 10.869428
 >> iter 3000, loss: 7.930926
 >> iter 4000, loss: 5.758794
 >> iter 5000, loss: 3.022042
 >> iter 6000, loss: 1.653533
 >> iter 7000, loss: 0.995328
 >> iter 8000, loss: 0.605548
 >> iter 9000, loss: 0.501467
 >> iter 10000, loss: 0.498449
   Number of active neurons: 6
 >> iter 11000, loss: 0.513394
 >> iter 12000, loss: 0.421938
 >> iter 13000, loss: 0.434896
 >> iter 14000, loss: 0.391185
 >> iter 15000, loss: 0.408781
 >> iter 16000, loss: 0.374150
 >> iter 17000, loss: 0.342626
 >> iter 18000, loss: 0.332547
 >> iter 19000, loss: 0.325457
 >> iter 20000, loss: 0.273470
   Number of active neurons: 6
 >> iter 21000, loss: 0.301667
 >> iter 22000, loss: 0.259054
 >> iter 23000, loss: 0.418624
 >> iter 24000, loss: 0.426038
 >> iter 25000, loss: 0.476051
 >> iter 26000, loss: 0.349148
 >> iter 27000, loss: 0.398390
 >> iter 28000, loss: 0.355996
 >> iter 29000, loss: 0.352088
 >> iter 30000, loss: 0.260545
   Number of active neurons: 6
 >> iter 31000, loss: 0.257466
 >> iter 32000, loss: 0.364930
 >> iter 33000, loss: 0.358243
 >> iter 34000, loss: 0.394348
 >> iter 35000, loss: 0.375005
 >> iter 36000, loss: 0.391651
 >> iter 37000, loss: 0.244096
 >> iter 38000, loss: 0.267846
 >> iter 39000, loss: 0.332894
 >> iter 40000, loss: 0.345881
   Number of active neurons: 6
 >> iter 41000, loss: 0.374886
 >> iter 42000, loss: 0.309499
 >> iter 43000, loss: 0.361322
 >> iter 44000, loss: 0.311541
 >> iter 45000, loss: 0.411491
 >> iter 46000, loss: 0.311310
 >> iter 47000, loss: 0.283003
 >> iter 48000, loss: 0.376815
 >> iter 49000, loss: 0.347481
 >> iter 50000, loss: 0.361873
   Number of active neurons: 6
 >> iter 51000, loss: 0.305222
 >> iter 52000, loss: 0.310664
 >> iter 53000, loss: 0.374708
 >> iter 54000, loss: 0.376105
 >> iter 55000, loss: 0.385670
 >> iter 56000, loss: 0.434588
 >> iter 57000, loss: 0.370465
 >> iter 58000, loss: 0.474524
 >> iter 59000, loss: 0.390458
 >> iter 60000, loss: 0.380704
   Number of active neurons: 6
 >> iter 61000, loss: 0.456888
 >> iter 62000, loss: 0.332930
 >> iter 63000, loss: 0.365993
 >> iter 64000, loss: 0.266155
 >> iter 65000, loss: 0.300337
 >> iter 66000, loss: 0.458667
 >> iter 67000, loss: 0.464591
 >> iter 68000, loss: 0.326901
 >> iter 69000, loss: 0.506757
 >> iter 70000, loss: 0.440034
   Number of active neurons: 6
 >> iter 71000, loss: 0.428100
 >> iter 72000, loss: 0.457854
 >> iter 73000, loss: 0.431417
 >> iter 74000, loss: 0.324179
 >> iter 75000, loss: 0.358994
 >> iter 76000, loss: 0.302932
 >> iter 77000, loss: 0.388155
 >> iter 78000, loss: 0.351082
 >> iter 79000, loss: 0.312928
 >> iter 80000, loss: 0.431093
   Number of active neurons: 5
 >> iter 81000, loss: 0.427280
 >> iter 82000, loss: 0.359395
 >> iter 83000, loss: 0.476428
 >> iter 84000, loss: 0.511102
 >> iter 85000, loss: 0.459360
 >> iter 86000, loss: 0.431595
 >> iter 87000, loss: 0.416352
 >> iter 88000, loss: 0.410032
 >> iter 89000, loss: 0.530767
 >> iter 90000, loss: 0.416130
   Number of active neurons: 6
 >> iter 91000, loss: 0.415544
 >> iter 92000, loss: 0.451208
 >> iter 93000, loss: 0.434049
 >> iter 94000, loss: 0.543260
 >> iter 95000, loss: 0.504408
 >> iter 96000, loss: 0.421913
 >> iter 97000, loss: 0.384437
 >> iter 98000, loss: 0.371510
 >> iter 99000, loss: 0.393768
 >> iter 100000, loss: 0.338069
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.097045
 >> iter 2000, loss: 10.007239
 >> iter 3000, loss: 4.610035
 >> iter 4000, loss: 2.257491
 >> iter 5000, loss: 1.193792
 >> iter 6000, loss: 0.656156
 >> iter 7000, loss: 0.490077
 >> iter 8000, loss: 0.280055
 >> iter 9000, loss: 0.377690
 >> iter 10000, loss: 0.292869
   Number of active neurons: 5
 >> iter 11000, loss: 0.289555
 >> iter 12000, loss: 0.407229
 >> iter 13000, loss: 0.413857
 >> iter 14000, loss: 0.378328
 >> iter 15000, loss: 0.363437
 >> iter 16000, loss: 0.260663
 >> iter 17000, loss: 0.346246
 >> iter 18000, loss: 0.323846
 >> iter 19000, loss: 0.303324
 >> iter 20000, loss: 0.289352
   Number of active neurons: 5
 >> iter 21000, loss: 0.320832
 >> iter 22000, loss: 0.360078
 >> iter 23000, loss: 0.392698
 >> iter 24000, loss: 0.435492
 >> iter 25000, loss: 0.365832
 >> iter 26000, loss: 0.348024
 >> iter 27000, loss: 0.333731
 >> iter 28000, loss: 0.389624
 >> iter 29000, loss: 0.244935
 >> iter 30000, loss: 0.348899
   Number of active neurons: 5
 >> iter 31000, loss: 0.342402
 >> iter 32000, loss: 0.228467
 >> iter 33000, loss: 0.279317
 >> iter 34000, loss: 0.329835
 >> iter 35000, loss: 0.284270
 >> iter 36000, loss: 0.405402
 >> iter 37000, loss: 0.320742
 >> iter 38000, loss: 0.264448
 >> iter 39000, loss: 0.265117
 >> iter 40000, loss: 0.350066
   Number of active neurons: 5
 >> iter 41000, loss: 0.277543
 >> iter 42000, loss: 0.378503
 >> iter 43000, loss: 0.258792
 >> iter 44000, loss: 0.207663
 >> iter 45000, loss: 0.226798
 >> iter 46000, loss: 0.279971
 >> iter 47000, loss: 0.289733
 >> iter 48000, loss: 0.364476
 >> iter 49000, loss: 0.408324
 >> iter 50000, loss: 0.391129
   Number of active neurons: 5
 >> iter 51000, loss: 0.358502
 >> iter 52000, loss: 0.360874
 >> iter 53000, loss: 0.285423
 >> iter 54000, loss: 0.323383
 >> iter 55000, loss: 0.288427
 >> iter 56000, loss: 0.327778
 >> iter 57000, loss: 0.368455
 >> iter 58000, loss: 0.383216
 >> iter 59000, loss: 0.232240
 >> iter 60000, loss: 0.240223
   Number of active neurons: 5
 >> iter 61000, loss: 0.353960
 >> iter 62000, loss: 0.369468
 >> iter 63000, loss: 0.258439
 >> iter 64000, loss: 0.379277
 >> iter 65000, loss: 0.470321
 >> iter 66000, loss: 0.361526
 >> iter 67000, loss: 0.254041
 >> iter 68000, loss: 0.355583
 >> iter 69000, loss: 0.269420
 >> iter 70000, loss: 0.315938
   Number of active neurons: 5
 >> iter 71000, loss: 0.432178
 >> iter 72000, loss: 0.366317
 >> iter 73000, loss: 0.301112
 >> iter 74000, loss: 0.295227
 >> iter 75000, loss: 0.299899
 >> iter 76000, loss: 0.295789
 >> iter 77000, loss: 0.287388
 >> iter 78000, loss: 0.289022
 >> iter 79000, loss: 0.224813
 >> iter 80000, loss: 0.323686
   Number of active neurons: 5
 >> iter 81000, loss: 0.307295
 >> iter 82000, loss: 0.245320
 >> iter 83000, loss: 0.270532
 >> iter 84000, loss: 0.212036
 >> iter 85000, loss: 0.222977
 >> iter 86000, loss: 0.292269
 >> iter 87000, loss: 0.398222
 >> iter 88000, loss: 0.404074
 >> iter 89000, loss: 0.343847
 >> iter 90000, loss: 0.268263
   Number of active neurons: 5
 >> iter 91000, loss: 0.389125
 >> iter 92000, loss: 0.435041
 >> iter 93000, loss: 0.365053
 >> iter 94000, loss: 0.336353
 >> iter 95000, loss: 0.282278
 >> iter 96000, loss: 0.230049
 >> iter 97000, loss: 0.303860
 >> iter 98000, loss: 0.345465
 >> iter 99000, loss: 0.326156
 >> iter 100000, loss: 0.319099
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.644088
 >> iter 2000, loss: 10.376035
 >> iter 3000, loss: 5.983786
 >> iter 4000, loss: 3.183697
 >> iter 5000, loss: 2.177635
 >> iter 6000, loss: 1.531240
 >> iter 7000, loss: 1.261892
 >> iter 8000, loss: 1.009859
 >> iter 9000, loss: 0.935161
 >> iter 10000, loss: 0.741521
   Number of active neurons: 5
 >> iter 11000, loss: 0.852309
 >> iter 12000, loss: 0.816381
 >> iter 13000, loss: 0.888675
 >> iter 14000, loss: 0.709998
 >> iter 15000, loss: 0.654297
 >> iter 16000, loss: 0.599203
 >> iter 17000, loss: 0.684064
 >> iter 18000, loss: 0.677343
 >> iter 19000, loss: 0.760486
 >> iter 20000, loss: 0.673941
   Number of active neurons: 4
 >> iter 21000, loss: 0.689670
 >> iter 22000, loss: 0.597134
 >> iter 23000, loss: 0.551494
 >> iter 24000, loss: 0.696145
 >> iter 25000, loss: 0.575854
 >> iter 26000, loss: 0.503923
 >> iter 27000, loss: 0.665872
 >> iter 28000, loss: 0.574830
 >> iter 29000, loss: 0.621657
 >> iter 30000, loss: 0.640858
   Number of active neurons: 4
 >> iter 31000, loss: 0.619920
 >> iter 32000, loss: 0.780749
 >> iter 33000, loss: 0.736137
 >> iter 34000, loss: 0.688699
 >> iter 35000, loss: 0.680564
 >> iter 36000, loss: 0.793775
 >> iter 37000, loss: 0.831296
 >> iter 38000, loss: 0.927916
 >> iter 39000, loss: 0.753418
 >> iter 40000, loss: 0.875113
   Number of active neurons: 4
 >> iter 41000, loss: 0.847271
 >> iter 42000, loss: 0.738830
 >> iter 43000, loss: 0.743679
 >> iter 44000, loss: 0.706377
 >> iter 45000, loss: 0.615816
 >> iter 46000, loss: 0.791997
 >> iter 47000, loss: 0.768849
 >> iter 48000, loss: 0.694668
 >> iter 49000, loss: 0.791588
 >> iter 50000, loss: 0.752931
   Number of active neurons: 4
 >> iter 51000, loss: 0.927078
 >> iter 52000, loss: 0.877094
 >> iter 53000, loss: 0.736565
 >> iter 54000, loss: 0.731828
 >> iter 55000, loss: 0.733610
 >> iter 56000, loss: 0.792246
 >> iter 57000, loss: 0.753323
 >> iter 58000, loss: 0.701996
 >> iter 59000, loss: 0.720744
 >> iter 60000, loss: 0.726809
   Number of active neurons: 4
 >> iter 61000, loss: 0.849062
 >> iter 62000, loss: 0.660261
 >> iter 63000, loss: 0.786448
 >> iter 64000, loss: 0.665899
 >> iter 65000, loss: 0.692591
 >> iter 66000, loss: 0.607887
 >> iter 67000, loss: 0.500878
 >> iter 68000, loss: 0.565240
 >> iter 69000, loss: 0.664952
 >> iter 70000, loss: 0.596197
   Number of active neurons: 4
 >> iter 71000, loss: 0.578410
 >> iter 72000, loss: 0.620128
 >> iter 73000, loss: 0.663332
 >> iter 74000, loss: 0.679838
 >> iter 75000, loss: 0.705758
 >> iter 76000, loss: 0.615616
 >> iter 77000, loss: 0.490020
 >> iter 78000, loss: 0.481485
 >> iter 79000, loss: 0.559023
 >> iter 80000, loss: 0.568337
   Number of active neurons: 4
 >> iter 81000, loss: 0.632266
 >> iter 82000, loss: 0.498104
 >> iter 83000, loss: 0.439696
 >> iter 84000, loss: 0.457071
 >> iter 85000, loss: 0.444562
 >> iter 86000, loss: 0.455065
 >> iter 87000, loss: 0.372414
 >> iter 88000, loss: 0.343104
 >> iter 89000, loss: 0.461335
 >> iter 90000, loss: 0.371329
   Number of active neurons: 4
 >> iter 91000, loss: 0.518815
 >> iter 92000, loss: 0.416368
 >> iter 93000, loss: 0.425271
 >> iter 94000, loss: 0.386339
 >> iter 95000, loss: 0.450714
 >> iter 96000, loss: 0.407955
 >> iter 97000, loss: 0.319790
 >> iter 98000, loss: 0.302606
 >> iter 99000, loss: 0.473414
 >> iter 100000, loss: 0.504502
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.782900
 >> iter 2000, loss: 11.797551
 >> iter 3000, loss: 7.829949
 >> iter 4000, loss: 4.751154
 >> iter 5000, loss: 3.079907
 >> iter 6000, loss: 2.195178
 >> iter 7000, loss: 1.548566
 >> iter 8000, loss: 1.523442
 >> iter 9000, loss: 1.362277
 >> iter 10000, loss: 1.001432
   Number of active neurons: 6
 >> iter 11000, loss: 0.772378
 >> iter 12000, loss: 0.790194
 >> iter 13000, loss: 0.920208
 >> iter 14000, loss: 0.823632
 >> iter 15000, loss: 0.794133
 >> iter 16000, loss: 0.690654
 >> iter 17000, loss: 0.605479
 >> iter 18000, loss: 0.660459
 >> iter 19000, loss: 0.577869
 >> iter 20000, loss: 0.750141
   Number of active neurons: 6
 >> iter 21000, loss: 0.646793
 >> iter 22000, loss: 0.509103
 >> iter 23000, loss: 0.639286
 >> iter 24000, loss: 0.798738
 >> iter 25000, loss: 0.887447
 >> iter 26000, loss: 0.742031
 >> iter 27000, loss: 0.649367
 >> iter 28000, loss: 0.652882
 >> iter 29000, loss: 0.611877
 >> iter 30000, loss: 0.652032
   Number of active neurons: 6
 >> iter 31000, loss: 0.524517
 >> iter 32000, loss: 0.460120
 >> iter 33000, loss: 0.553049
 >> iter 34000, loss: 0.544993
 >> iter 35000, loss: 0.791293
 >> iter 36000, loss: 0.874317
 >> iter 37000, loss: 0.595966
 >> iter 38000, loss: 0.597370
 >> iter 39000, loss: 0.442724
 >> iter 40000, loss: 0.438648
   Number of active neurons: 6
 >> iter 41000, loss: 0.514671
 >> iter 42000, loss: 0.513902
 >> iter 43000, loss: 0.550331
 >> iter 44000, loss: 0.554037
 >> iter 45000, loss: 0.684360
 >> iter 46000, loss: 0.638196
 >> iter 47000, loss: 0.583952
 >> iter 48000, loss: 0.446875
 >> iter 49000, loss: 0.511940
 >> iter 50000, loss: 0.478193
   Number of active neurons: 6
 >> iter 51000, loss: 0.783866
 >> iter 52000, loss: 0.598394
 >> iter 53000, loss: 0.503096
 >> iter 54000, loss: 0.544211
 >> iter 55000, loss: 0.592391
 >> iter 56000, loss: 0.711793
 >> iter 57000, loss: 0.689721
 >> iter 58000, loss: 0.660882
 >> iter 59000, loss: 0.596478
 >> iter 60000, loss: 0.575751
   Number of active neurons: 6
 >> iter 61000, loss: 0.742610
 >> iter 62000, loss: 0.918336
 >> iter 63000, loss: 0.845705
 >> iter 64000, loss: 0.629108
 >> iter 65000, loss: 0.576019
 >> iter 66000, loss: 0.511374
 >> iter 67000, loss: 0.834656
 >> iter 68000, loss: 0.666091
 >> iter 69000, loss: 0.497453
 >> iter 70000, loss: 0.704682
   Number of active neurons: 6
 >> iter 71000, loss: 0.811338
 >> iter 72000, loss: 0.704266
 >> iter 73000, loss: 0.635699
 >> iter 74000, loss: 0.533307
 >> iter 75000, loss: 0.632989
 >> iter 76000, loss: 0.527376
 >> iter 77000, loss: 0.522990
 >> iter 78000, loss: 0.509563
 >> iter 79000, loss: 0.603471
 >> iter 80000, loss: 0.457337
   Number of active neurons: 5
 >> iter 81000, loss: 0.449321
 >> iter 82000, loss: 0.578398
 >> iter 83000, loss: 0.462140
 >> iter 84000, loss: 0.514030
 >> iter 85000, loss: 0.555581
 >> iter 86000, loss: 0.438291
 >> iter 87000, loss: 0.434726
 >> iter 88000, loss: 0.557890
 >> iter 89000, loss: 0.550651
 >> iter 90000, loss: 0.616043
   Number of active neurons: 5
 >> iter 91000, loss: 0.739433
 >> iter 92000, loss: 0.593601
 >> iter 93000, loss: 0.632704
 >> iter 94000, loss: 0.635934
 >> iter 95000, loss: 0.570983
 >> iter 96000, loss: 0.416243
 >> iter 97000, loss: 0.465541
 >> iter 98000, loss: 0.473857
 >> iter 99000, loss: 0.636968
 >> iter 100000, loss: 0.478757
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.542174
 >> iter 2000, loss: 11.201844
 >> iter 3000, loss: 6.324746
 >> iter 4000, loss: 3.340113
 >> iter 5000, loss: 2.047947
 >> iter 6000, loss: 1.489102
 >> iter 7000, loss: 0.951602
 >> iter 8000, loss: 0.767566
 >> iter 9000, loss: 0.733307
 >> iter 10000, loss: 0.665262
   Number of active neurons: 5
 >> iter 11000, loss: 0.646868
 >> iter 12000, loss: 0.695251
 >> iter 13000, loss: 0.731105
 >> iter 14000, loss: 0.653323
 >> iter 15000, loss: 0.767357
 >> iter 16000, loss: 0.677085
 >> iter 17000, loss: 0.534960
 >> iter 18000, loss: 0.504626
 >> iter 19000, loss: 0.589487
 >> iter 20000, loss: 0.567279
   Number of active neurons: 5
 >> iter 21000, loss: 0.364453
 >> iter 22000, loss: 0.360418
 >> iter 23000, loss: 0.411809
 >> iter 24000, loss: 0.367948
 >> iter 25000, loss: 0.472384
 >> iter 26000, loss: 0.402983
 >> iter 27000, loss: 0.401791
 >> iter 28000, loss: 0.432624
 >> iter 29000, loss: 0.561122
 >> iter 30000, loss: 0.673426
   Number of active neurons: 4
 >> iter 31000, loss: 0.562932
 >> iter 32000, loss: 0.543652
 >> iter 33000, loss: 0.490469
 >> iter 34000, loss: 0.495791
 >> iter 35000, loss: 0.400677
 >> iter 36000, loss: 0.497810
 >> iter 37000, loss: 0.472447
 >> iter 38000, loss: 0.434410
 >> iter 39000, loss: 0.390806
 >> iter 40000, loss: 0.453855
   Number of active neurons: 4
 >> iter 41000, loss: 0.438396
 >> iter 42000, loss: 0.369115
 >> iter 43000, loss: 0.439740
 >> iter 44000, loss: 0.481927
 >> iter 45000, loss: 0.511100
 >> iter 46000, loss: 0.605829
 >> iter 47000, loss: 0.558147
 >> iter 48000, loss: 0.608786
 >> iter 49000, loss: 0.710491
 >> iter 50000, loss: 0.578891
   Number of active neurons: 4
 >> iter 51000, loss: 0.487747
 >> iter 52000, loss: 0.699820
 >> iter 53000, loss: 0.581710
 >> iter 54000, loss: 0.762061
 >> iter 55000, loss: 0.673385
 >> iter 56000, loss: 0.573634
 >> iter 57000, loss: 0.548233
 >> iter 58000, loss: 0.578075
 >> iter 59000, loss: 0.546961
 >> iter 60000, loss: 0.656888
   Number of active neurons: 4
 >> iter 61000, loss: 0.628920
 >> iter 62000, loss: 0.591829
 >> iter 63000, loss: 0.596503
 >> iter 64000, loss: 0.517594
 >> iter 65000, loss: 0.497922
 >> iter 66000, loss: 0.516663
 >> iter 67000, loss: 0.594375
 >> iter 68000, loss: 0.599170
 >> iter 69000, loss: 0.586131
 >> iter 70000, loss: 0.519195
   Number of active neurons: 4
 >> iter 71000, loss: 0.606530
 >> iter 72000, loss: 0.574914
 >> iter 73000, loss: 0.805718
 >> iter 74000, loss: 0.654225
 >> iter 75000, loss: 0.755176
 >> iter 76000, loss: 0.592510
 >> iter 77000, loss: 0.542183
 >> iter 78000, loss: 0.518562
 >> iter 79000, loss: 0.601262
 >> iter 80000, loss: 0.529215
   Number of active neurons: 4
 >> iter 81000, loss: 0.760274
 >> iter 82000, loss: 0.715574
 >> iter 83000, loss: 0.616794
 >> iter 84000, loss: 0.555469
 >> iter 85000, loss: 0.474221
 >> iter 86000, loss: 0.519008
 >> iter 87000, loss: 0.518106
 >> iter 88000, loss: 0.518943
 >> iter 89000, loss: 0.622205
 >> iter 90000, loss: 0.646257
   Number of active neurons: 4
 >> iter 91000, loss: 0.648355
 >> iter 92000, loss: 0.488286
 >> iter 93000, loss: 0.506446
 >> iter 94000, loss: 0.544436
 >> iter 95000, loss: 0.560956
 >> iter 96000, loss: 0.621709
 >> iter 97000, loss: 0.549755
 >> iter 98000, loss: 0.603346
 >> iter 99000, loss: 0.590853
 >> iter 100000, loss: 0.417407
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 21.037301
 >> iter 2000, loss: 18.735218
 >> iter 3000, loss: 17.828263
 >> iter 4000, loss: 17.557539
 >> iter 5000, loss: 17.393953
 >> iter 6000, loss: 17.399766
 >> iter 7000, loss: 17.334485
 >> iter 8000, loss: 17.377683
 >> iter 9000, loss: 17.326842
 >> iter 10000, loss: 17.376461
   Number of active neurons: 0
 >> iter 11000, loss: 17.324224
 >> iter 12000, loss: 17.376003
 >> iter 13000, loss: 17.320235
 >> iter 14000, loss: 17.374907
 >> iter 15000, loss: 17.320795
 >> iter 16000, loss: 17.374885
 >> iter 17000, loss: 17.322167
 >> iter 18000, loss: 17.374665
 >> iter 19000, loss: 17.320916
 >> iter 20000, loss: 17.374841
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 17.317895
 >> iter 22000, loss: 17.373813
 >> iter 23000, loss: 17.319005
 >> iter 24000, loss: 17.375437
 >> iter 25000, loss: 17.318964
 >> iter 26000, loss: 17.373752
 >> iter 27000, loss: 17.324807
 >> iter 28000, loss: 17.373265
 >> iter 29000, loss: 17.323039
 >> iter 30000, loss: 17.372201
   Number of active neurons: 0
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 0
 >> iter 31000, loss: 17.322129
 >> iter 32000, loss: 17.371333
 >> iter 33000, loss: 17.328108
 >> iter 34000, loss: 17.370063
 >> iter 35000, loss: 17.327290
 >> iter 36000, loss: 17.375660
 >> iter 37000, loss: 17.327155
 >> iter 38000, loss: 17.375447
 >> iter 39000, loss: 17.331853
 >> iter 40000, loss: 17.376134
   Number of active neurons: 0
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 0
 >> iter 41000, loss: 17.328964
 >> iter 42000, loss: 17.375205
 >> iter 43000, loss: 17.329508
 >> iter 44000, loss: 17.372335
 >> iter 45000, loss: 17.329042
 >> iter 46000, loss: 17.371788
 >> iter 47000, loss: 17.330408
 >> iter 48000, loss: 17.369658
 >> iter 49000, loss: 17.330643
 >> iter 50000, loss: 17.371992
   Number of active neurons: 0
   SHOCK
   Setting new limit to 287500.0 iters...
   Number of active neurons: 0
 >> iter 51000, loss: 17.330305
 >> iter 52000, loss: 17.370316
 >> iter 53000, loss: 17.328930
 >> iter 54000, loss: 17.368894
 >> iter 55000, loss: 17.328161
 >> iter 56000, loss: 17.366936
 >> iter 57000, loss: 17.330334
 >> iter 58000, loss: 17.364328
 >> iter 59000, loss: 17.331780
 >> iter 60000, loss: 17.365080
   Number of active neurons: 0
   SHOCK
   Setting new limit to 293750.0 iters...
   Number of active neurons: 0
 >> iter 61000, loss: 17.332162
 >> iter 62000, loss: 17.365118
 >> iter 63000, loss: 17.332272
 >> iter 64000, loss: 17.370064
 >> iter 65000, loss: 17.332118
 >> iter 66000, loss: 17.374276
 >> iter 67000, loss: 17.332229
 >> iter 68000, loss: 17.370800
 >> iter 69000, loss: 17.331800
 >> iter 70000, loss: 17.366686
   Number of active neurons: 0
   SHOCK
   Setting new limit to 296875.0 iters...
   Number of active neurons: 0
 >> iter 71000, loss: 17.331987
 >> iter 72000, loss: 17.367659
 >> iter 73000, loss: 17.330803
 >> iter 74000, loss: 17.370948
 >> iter 75000, loss: 17.329140
 >> iter 76000, loss: 17.372050
 >> iter 77000, loss: 17.328300
 >> iter 78000, loss: 17.373002
 >> iter 79000, loss: 17.328921
 >> iter 80000, loss: 17.372404
   Number of active neurons: 0
   SHOCK
   Setting new limit to 298437.5 iters...
   Number of active neurons: 0
 >> iter 81000, loss: 17.329394
 >> iter 82000, loss: 17.370929
 >> iter 83000, loss: 17.328947
 >> iter 84000, loss: 17.367321
 >> iter 85000, loss: 17.325923
 >> iter 86000, loss: 17.363507
 >> iter 87000, loss: 17.325808
 >> iter 88000, loss: 17.357910
 >> iter 89000, loss: 17.323475
 >> iter 90000, loss: 17.358718
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299218.75 iters...
   Number of active neurons: 0
 >> iter 91000, loss: 17.327663
 >> iter 92000, loss: 17.355517
 >> iter 93000, loss: 17.325695
 >> iter 94000, loss: 17.363306
 >> iter 95000, loss: 17.326105
 >> iter 96000, loss: 17.362285
 >> iter 97000, loss: 17.329669
 >> iter 98000, loss: 17.360729
 >> iter 99000, loss: 17.327968
 >> iter 100000, loss: 17.368646
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299609.375 iters...
   Number of active neurons: 0
 >> iter 101000, loss: 17.330254
 >> iter 102000, loss: 17.364440
 >> iter 103000, loss: 17.331575
 >> iter 104000, loss: 17.361735
 >> iter 105000, loss: 17.330603
 >> iter 106000, loss: 17.359474
 >> iter 107000, loss: 17.329008
 >> iter 108000, loss: 17.359779
 >> iter 109000, loss: 17.331156
 >> iter 110000, loss: 17.359970
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299804.6875 iters...
   Number of active neurons: 0
 >> iter 111000, loss: 17.334597
 >> iter 112000, loss: 17.364575
 >> iter 113000, loss: 17.332460
 >> iter 114000, loss: 17.364046
 >> iter 115000, loss: 17.333116
 >> iter 116000, loss: 17.366707
 >> iter 117000, loss: 17.331650
 >> iter 118000, loss: 17.369021
 >> iter 119000, loss: 17.329913
 >> iter 120000, loss: 17.370849
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299902.34375 iters...
   Number of active neurons: 0
 >> iter 121000, loss: 17.332243
 >> iter 122000, loss: 17.370024
 >> iter 123000, loss: 17.330852
 >> iter 124000, loss: 17.368816
 >> iter 125000, loss: 17.333743
 >> iter 126000, loss: 17.369596
 >> iter 127000, loss: 17.332453
 >> iter 128000, loss: 17.370142
 >> iter 129000, loss: 17.331249
 >> iter 130000, loss: 17.371283
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299951.171875 iters...
   Number of active neurons: 0
 >> iter 131000, loss: 17.332339
 >> iter 132000, loss: 17.370564
 >> iter 133000, loss: 17.330894
 >> iter 134000, loss: 17.369574
 >> iter 135000, loss: 17.333121
 >> iter 136000, loss: 17.367120
 >> iter 137000, loss: 17.334685
 >> iter 138000, loss: 17.368479
 >> iter 139000, loss: 17.333746
 >> iter 140000, loss: 17.369112
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299975.585938 iters...
   Number of active neurons: 0
 >> iter 141000, loss: 17.335500
 >> iter 142000, loss: 17.367805
 >> iter 143000, loss: 17.335149
 >> iter 144000, loss: 17.368874
 >> iter 145000, loss: 17.334148
 >> iter 146000, loss: 17.369795
 >> iter 147000, loss: 17.331079
 >> iter 148000, loss: 17.370391
 >> iter 149000, loss: 17.329407
 >> iter 150000, loss: 17.370187
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299987.792969 iters...
   Number of active neurons: 0
 >> iter 151000, loss: 17.331164
 >> iter 152000, loss: 17.369095
 >> iter 153000, loss: 17.333826
 >> iter 154000, loss: 17.368185
 >> iter 155000, loss: 17.335649
 >> iter 156000, loss: 17.367973
 >> iter 157000, loss: 17.335939
 >> iter 158000, loss: 17.368329
 >> iter 159000, loss: 17.335607
 >> iter 160000, loss: 17.367870
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299993.896484 iters...
   Number of active neurons: 0
 >> iter 161000, loss: 17.334484
 >> iter 162000, loss: 17.369990
 >> iter 163000, loss: 17.335336
 >> iter 164000, loss: 17.371547
 >> iter 165000, loss: 17.335693
 >> iter 166000, loss: 17.371366
 >> iter 167000, loss: 17.335923
 >> iter 168000, loss: 17.370281
 >> iter 169000, loss: 17.336293
 >> iter 170000, loss: 17.370063
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299996.948242 iters...
   Number of active neurons: 0
 >> iter 171000, loss: 17.336256
 >> iter 172000, loss: 17.368394
 >> iter 173000, loss: 17.336231
 >> iter 174000, loss: 17.367266
 >> iter 175000, loss: 17.336050
 >> iter 176000, loss: 17.368885
 >> iter 177000, loss: 17.335565
 >> iter 178000, loss: 17.366075
 >> iter 179000, loss: 17.335386
 >> iter 180000, loss: 17.363386
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299998.474121 iters...
   Number of active neurons: 0
 >> iter 181000, loss: 17.335402
 >> iter 182000, loss: 17.363316
 >> iter 183000, loss: 17.336687
 >> iter 184000, loss: 17.359319
 >> iter 185000, loss: 17.336659
 >> iter 186000, loss: 17.356702
 >> iter 187000, loss: 17.336795
 >> iter 188000, loss: 17.355682
 >> iter 189000, loss: 17.336814
 >> iter 190000, loss: 17.363589
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.237061 iters...
   Number of active neurons: 0
 >> iter 191000, loss: 17.336741
 >> iter 192000, loss: 17.361589
 >> iter 193000, loss: 17.336933
 >> iter 194000, loss: 17.362199
 >> iter 195000, loss: 17.336833
 >> iter 196000, loss: 17.363635
 >> iter 197000, loss: 17.337265
 >> iter 198000, loss: 17.362699
 >> iter 199000, loss: 17.337095
 >> iter 200000, loss: 17.358390
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.61853 iters...
   Number of active neurons: 0
 >> iter 201000, loss: 17.338634
 >> iter 202000, loss: 17.359972
 >> iter 203000, loss: 17.338372
 >> iter 204000, loss: 17.361566
 >> iter 205000, loss: 17.339260
 >> iter 206000, loss: 17.359421
 >> iter 207000, loss: 17.339597
 >> iter 208000, loss: 17.358462
 >> iter 209000, loss: 17.338796
 >> iter 210000, loss: 17.357934
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.809265 iters...
   Number of active neurons: 0
 >> iter 211000, loss: 17.338451
 >> iter 212000, loss: 17.361791
 >> iter 213000, loss: 17.338465
 >> iter 214000, loss: 17.363977
 >> iter 215000, loss: 17.338653
 >> iter 216000, loss: 17.364955
 >> iter 217000, loss: 17.338337
 >> iter 218000, loss: 17.363797
 >> iter 219000, loss: 17.337428
 >> iter 220000, loss: 17.361192
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.904633 iters...
   Number of active neurons: 0
 >> iter 221000, loss: 17.336433
 >> iter 222000, loss: 17.359653
 >> iter 223000, loss: 17.337245
 >> iter 224000, loss: 17.361154
 >> iter 225000, loss: 17.335523
 >> iter 226000, loss: 17.361261
 >> iter 227000, loss: 17.336087
 >> iter 228000, loss: 17.359658
 >> iter 229000, loss: 17.336815
 >> iter 230000, loss: 17.357255
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.952316 iters...
   Number of active neurons: 0
 >> iter 231000, loss: 17.339906
 >> iter 232000, loss: 17.352943
 >> iter 233000, loss: 17.339884
 >> iter 234000, loss: 17.351925
 >> iter 235000, loss: 17.339733
 >> iter 236000, loss: 17.348036
 >> iter 237000, loss: 17.339430
 >> iter 238000, loss: 17.353122
 >> iter 239000, loss: 17.337862
 >> iter 240000, loss: 17.356699
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.976158 iters...
   Number of active neurons: 0
 >> iter 241000, loss: 17.339593
 >> iter 242000, loss: 17.356182
 >> iter 243000, loss: 17.339590
 >> iter 244000, loss: 17.357527
 >> iter 245000, loss: 17.339255
 >> iter 246000, loss: 17.357376
 >> iter 247000, loss: 17.339839
 >> iter 248000, loss: 17.353952
 >> iter 249000, loss: 17.339222
 >> iter 250000, loss: 17.353433
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.988079 iters...
   Number of active neurons: 0
 >> iter 251000, loss: 17.341380
 >> iter 252000, loss: 17.350636
 >> iter 253000, loss: 17.340444
 >> iter 254000, loss: 17.349073
 >> iter 255000, loss: 17.341108
 >> iter 256000, loss: 17.349776
 >> iter 257000, loss: 17.340128
 >> iter 258000, loss: 17.349799
 >> iter 259000, loss: 17.339937
 >> iter 260000, loss: 17.349291
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99404 iters...
   Number of active neurons: 0
 >> iter 261000, loss: 17.338084
 >> iter 262000, loss: 17.351607
 >> iter 263000, loss: 17.336910
 >> iter 264000, loss: 17.347373
 >> iter 265000, loss: 17.336400
 >> iter 266000, loss: 17.352046
 >> iter 267000, loss: 17.338993
 >> iter 268000, loss: 17.349296
 >> iter 269000, loss: 17.339961
 >> iter 270000, loss: 17.346900
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99702 iters...
   Number of active neurons: 0
 >> iter 271000, loss: 17.338359
 >> iter 272000, loss: 17.341545
 >> iter 273000, loss: 17.336065
 >> iter 274000, loss: 17.341839
 >> iter 275000, loss: 17.339576
 >> iter 276000, loss: 17.346790
 >> iter 277000, loss: 17.339396
 >> iter 278000, loss: 17.351248
 >> iter 279000, loss: 17.338330
 >> iter 280000, loss: 17.348349
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99851 iters...
   Number of active neurons: 0
 >> iter 281000, loss: 17.337130
 >> iter 282000, loss: 17.344877
 >> iter 283000, loss: 17.340174
 >> iter 284000, loss: 17.342081
 >> iter 285000, loss: 17.338221
 >> iter 286000, loss: 17.346972
 >> iter 287000, loss: 17.337313
 >> iter 288000, loss: 17.342089
 >> iter 289000, loss: 17.336385
 >> iter 290000, loss: 17.344366
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999255 iters...
   Number of active neurons: 0
 >> iter 291000, loss: 17.331527
 >> iter 292000, loss: 17.347785
 >> iter 293000, loss: 17.326791
 >> iter 294000, loss: 17.348628
 >> iter 295000, loss: 17.330889
 >> iter 296000, loss: 17.344618
 >> iter 297000, loss: 17.329363
 >> iter 298000, loss: 17.341681
 >> iter 299000, loss: 17.333407
 >> iter 300000, loss: 17.336053
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999627 iters...
   Number of active neurons: 0
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.245932
 >> iter 2000, loss: 10.829194
 >> iter 3000, loss: 6.986291
 >> iter 4000, loss: 4.106230
 >> iter 5000, loss: 2.256956
 >> iter 6000, loss: 1.307226
 >> iter 7000, loss: 0.747152
 >> iter 8000, loss: 0.533136
 >> iter 9000, loss: 0.398049
 >> iter 10000, loss: 0.317323
   Number of active neurons: 6
 >> iter 11000, loss: 0.313361
 >> iter 12000, loss: 0.383732
 >> iter 13000, loss: 0.365579
 >> iter 14000, loss: 0.285277
 >> iter 15000, loss: 0.352684
 >> iter 16000, loss: 0.313240
 >> iter 17000, loss: 0.242842
 >> iter 18000, loss: 0.269929
 >> iter 19000, loss: 0.381165
 >> iter 20000, loss: 0.359211
   Number of active neurons: 4
 >> iter 21000, loss: 0.336125
 >> iter 22000, loss: 0.280899
 >> iter 23000, loss: 0.255762
 >> iter 24000, loss: 0.346313
 >> iter 25000, loss: 0.363596
 >> iter 26000, loss: 0.301590
 >> iter 27000, loss: 0.287982
 >> iter 28000, loss: 0.326361
 >> iter 29000, loss: 0.329377
 >> iter 30000, loss: 0.313956
   Number of active neurons: 4
 >> iter 31000, loss: 0.362550
 >> iter 32000, loss: 0.397992
 >> iter 33000, loss: 0.373970
 >> iter 34000, loss: 0.347072
 >> iter 35000, loss: 0.317718
 >> iter 36000, loss: 0.313577
 >> iter 37000, loss: 0.365048
 >> iter 38000, loss: 0.394079
 >> iter 39000, loss: 0.399189
 >> iter 40000, loss: 0.324334
   Number of active neurons: 4
 >> iter 41000, loss: 0.418174
 >> iter 42000, loss: 0.325990
 >> iter 43000, loss: 0.287104
 >> iter 44000, loss: 0.257537
 >> iter 45000, loss: 0.430906
 >> iter 46000, loss: 0.443274
 >> iter 47000, loss: 0.538882
 >> iter 48000, loss: 0.388394
 >> iter 49000, loss: 0.325108
 >> iter 50000, loss: 0.319845
   Number of active neurons: 4
 >> iter 51000, loss: 0.329100
 >> iter 52000, loss: 0.371963
 >> iter 53000, loss: 0.372653
 >> iter 54000, loss: 0.281736
 >> iter 55000, loss: 0.310401
 >> iter 56000, loss: 0.298549
 >> iter 57000, loss: 0.284785
 >> iter 58000, loss: 0.351016
 >> iter 59000, loss: 0.300313
 >> iter 60000, loss: 0.330890
   Number of active neurons: 4
 >> iter 61000, loss: 0.331559
 >> iter 62000, loss: 0.403670
 >> iter 63000, loss: 0.511584
 >> iter 64000, loss: 0.523822
 >> iter 65000, loss: 0.353407
 >> iter 66000, loss: 0.222311
 >> iter 67000, loss: 0.272845
 >> iter 68000, loss: 0.412997
 >> iter 69000, loss: 0.294837
 >> iter 70000, loss: 0.216113
   Number of active neurons: 4
 >> iter 71000, loss: 0.283303
 >> iter 72000, loss: 0.376968
 >> iter 73000, loss: 0.357072
 >> iter 74000, loss: 0.347812
 >> iter 75000, loss: 0.276128
 >> iter 76000, loss: 0.464610
 >> iter 77000, loss: 0.419856
 >> iter 78000, loss: 0.279449
 >> iter 79000, loss: 0.442698
 >> iter 80000, loss: 0.428397
   Number of active neurons: 4
 >> iter 81000, loss: 0.373114
 >> iter 82000, loss: 0.375675
 >> iter 83000, loss: 0.344208
 >> iter 84000, loss: 0.340544
 >> iter 85000, loss: 0.323847
 >> iter 86000, loss: 0.331079
 >> iter 87000, loss: 0.321492
 >> iter 88000, loss: 0.335019
 >> iter 89000, loss: 0.383557
 >> iter 90000, loss: 0.379836
   Number of active neurons: 4
 >> iter 91000, loss: 0.381012
 >> iter 92000, loss: 0.323755
 >> iter 93000, loss: 0.288883
 >> iter 94000, loss: 0.306058
 >> iter 95000, loss: 0.494766
 >> iter 96000, loss: 0.406797
 >> iter 97000, loss: 0.312272
 >> iter 98000, loss: 0.256809
 >> iter 99000, loss: 0.372488
 >> iter 100000, loss: 0.364278
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.407495
 >> iter 2000, loss: 11.204721
 >> iter 3000, loss: 7.889483
 >> iter 4000, loss: 4.088469
 >> iter 5000, loss: 2.359253
 >> iter 6000, loss: 1.293589
 >> iter 7000, loss: 1.002791
 >> iter 8000, loss: 0.757597
 >> iter 9000, loss: 0.511901
 >> iter 10000, loss: 0.660782
   Number of active neurons: 4
 >> iter 11000, loss: 0.714442
 >> iter 12000, loss: 0.737400
 >> iter 13000, loss: 0.645131
 >> iter 14000, loss: 0.476286
 >> iter 15000, loss: 0.582376
 >> iter 16000, loss: 0.718973
 >> iter 17000, loss: 0.545533
 >> iter 18000, loss: 0.533752
 >> iter 19000, loss: 0.540520
 >> iter 20000, loss: 0.788203
   Number of active neurons: 4
 >> iter 21000, loss: 0.639778
 >> iter 22000, loss: 0.754160
 >> iter 23000, loss: 0.661716
 >> iter 24000, loss: 0.514039
 >> iter 25000, loss: 0.451455
 >> iter 26000, loss: 0.504079
 >> iter 27000, loss: 0.654626
 >> iter 28000, loss: 0.641973
 >> iter 29000, loss: 0.660739
 >> iter 30000, loss: 0.519852
   Number of active neurons: 4
 >> iter 31000, loss: 0.616942
 >> iter 32000, loss: 0.601885
 >> iter 33000, loss: 0.662576
 >> iter 34000, loss: 0.615869
 >> iter 35000, loss: 0.708791
 >> iter 36000, loss: 0.576157
 >> iter 37000, loss: 0.468386
 >> iter 38000, loss: 0.456319
 >> iter 39000, loss: 0.566653
 >> iter 40000, loss: 0.589319
   Number of active neurons: 4
 >> iter 41000, loss: 0.548968
 >> iter 42000, loss: 0.441604
 >> iter 43000, loss: 0.576924
 >> iter 44000, loss: 0.513288
 >> iter 45000, loss: 0.555769
 >> iter 46000, loss: 0.598689
 >> iter 47000, loss: 0.502325
 >> iter 48000, loss: 0.470229
 >> iter 49000, loss: 0.500307
 >> iter 50000, loss: 0.393982
   Number of active neurons: 4
 >> iter 51000, loss: 0.367713
 >> iter 52000, loss: 0.490794
 >> iter 53000, loss: 0.527920
 >> iter 54000, loss: 0.357208
 >> iter 55000, loss: 0.504900
 >> iter 56000, loss: 0.450000
 >> iter 57000, loss: 0.383960
 >> iter 58000, loss: 0.431819
 >> iter 59000, loss: 0.530151
 >> iter 60000, loss: 0.360377
   Number of active neurons: 4
 >> iter 61000, loss: 0.531199
 >> iter 62000, loss: 0.555922
 >> iter 63000, loss: 0.681424
 >> iter 64000, loss: 0.525913
 >> iter 65000, loss: 0.453228
 >> iter 66000, loss: 0.411353
 >> iter 67000, loss: 0.398238
 >> iter 68000, loss: 0.347812
 >> iter 69000, loss: 0.297896
 >> iter 70000, loss: 0.420752
   Number of active neurons: 4
 >> iter 71000, loss: 0.461084
 >> iter 72000, loss: 0.456210
 >> iter 73000, loss: 0.509698
 >> iter 74000, loss: 0.442680
 >> iter 75000, loss: 0.615774
 >> iter 76000, loss: 0.622865
 >> iter 77000, loss: 0.562444
 >> iter 78000, loss: 0.465214
 >> iter 79000, loss: 0.481228
 >> iter 80000, loss: 0.481923
   Number of active neurons: 4
 >> iter 81000, loss: 0.456709
 >> iter 82000, loss: 0.525243
 >> iter 83000, loss: 0.549454
 >> iter 84000, loss: 0.520578
 >> iter 85000, loss: 0.465967
 >> iter 86000, loss: 0.499243
 >> iter 87000, loss: 0.508254
 >> iter 88000, loss: 0.557834
 >> iter 89000, loss: 0.438475
 >> iter 90000, loss: 0.412530
   Number of active neurons: 4
 >> iter 91000, loss: 0.471601
 >> iter 92000, loss: 0.430772
 >> iter 93000, loss: 0.433180
 >> iter 94000, loss: 0.439799
 >> iter 95000, loss: 0.519912
 >> iter 96000, loss: 0.489790
 >> iter 97000, loss: 0.553782
 >> iter 98000, loss: 0.635122
 >> iter 99000, loss: 0.533846
 >> iter 100000, loss: 0.592540
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.321967
 >> iter 2000, loss: 11.862885
 >> iter 3000, loss: 8.682234
 >> iter 4000, loss: 6.383569
 >> iter 5000, loss: 4.284137
 >> iter 6000, loss: 2.784839
 >> iter 7000, loss: 1.767760
 >> iter 8000, loss: 1.420890
 >> iter 9000, loss: 1.091463
 >> iter 10000, loss: 0.935454
   Number of active neurons: 6
 >> iter 11000, loss: 0.889512
 >> iter 12000, loss: 0.860079
 >> iter 13000, loss: 0.725374
 >> iter 14000, loss: 0.966432
 >> iter 15000, loss: 0.831270
 >> iter 16000, loss: 0.623429
 >> iter 17000, loss: 0.547988
 >> iter 18000, loss: 0.752500
 >> iter 19000, loss: 0.622420
 >> iter 20000, loss: 0.543404
   Number of active neurons: 6
 >> iter 21000, loss: 0.658253
 >> iter 22000, loss: 0.685422
 >> iter 23000, loss: 0.518141
 >> iter 24000, loss: 0.398126
 >> iter 25000, loss: 0.559775
 >> iter 26000, loss: 0.773467
 >> iter 27000, loss: 0.707168
 >> iter 28000, loss: 0.552775
 >> iter 29000, loss: 0.416537
 >> iter 30000, loss: 0.513332
   Number of active neurons: 6
 >> iter 31000, loss: 0.553768
 >> iter 32000, loss: 0.573387
 >> iter 33000, loss: 0.610203
 >> iter 34000, loss: 0.481690
 >> iter 35000, loss: 0.448754
 >> iter 36000, loss: 0.306210
 >> iter 37000, loss: 0.367059
 >> iter 38000, loss: 0.457161
 >> iter 39000, loss: 0.439642
 >> iter 40000, loss: 0.479310
   Number of active neurons: 5
 >> iter 41000, loss: 0.481480
 >> iter 42000, loss: 0.454886
 >> iter 43000, loss: 0.467627
 >> iter 44000, loss: 0.565622
 >> iter 45000, loss: 0.570958
 >> iter 46000, loss: 0.512596
 >> iter 47000, loss: 0.474741
 >> iter 48000, loss: 0.406017
 >> iter 49000, loss: 0.425095
 >> iter 50000, loss: 0.504114
   Number of active neurons: 5
 >> iter 51000, loss: 0.661635
 >> iter 52000, loss: 0.491841
 >> iter 53000, loss: 0.462938
 >> iter 54000, loss: 0.508413
 >> iter 55000, loss: 0.534734
 >> iter 56000, loss: 0.462853
 >> iter 57000, loss: 0.343960
 >> iter 58000, loss: 0.348059
 >> iter 59000, loss: 0.527124
 >> iter 60000, loss: 0.384785
   Number of active neurons: 5
 >> iter 61000, loss: 0.295752
 >> iter 62000, loss: 0.416109
 >> iter 63000, loss: 0.306911
 >> iter 64000, loss: 0.395131
 >> iter 65000, loss: 0.446615
 >> iter 66000, loss: 0.481151
 >> iter 67000, loss: 0.547306
 >> iter 68000, loss: 0.492912
 >> iter 69000, loss: 0.416193
 >> iter 70000, loss: 0.620643
   Number of active neurons: 5
 >> iter 71000, loss: 0.729417
 >> iter 72000, loss: 0.666020
 >> iter 73000, loss: 0.595648
 >> iter 74000, loss: 0.513051
 >> iter 75000, loss: 0.579815
 >> iter 76000, loss: 0.660682
 >> iter 77000, loss: 0.488707
 >> iter 78000, loss: 0.538065
 >> iter 79000, loss: 0.484257
 >> iter 80000, loss: 0.434181
   Number of active neurons: 4
 >> iter 81000, loss: 0.384218
 >> iter 82000, loss: 0.458411
 >> iter 83000, loss: 0.437594
 >> iter 84000, loss: 0.470273
 >> iter 85000, loss: 0.499787
 >> iter 86000, loss: 0.402121
 >> iter 87000, loss: 0.438603
 >> iter 88000, loss: 0.412952
 >> iter 89000, loss: 0.386870
 >> iter 90000, loss: 0.680145
   Number of active neurons: 4
 >> iter 91000, loss: 0.587042
 >> iter 92000, loss: 0.500544
 >> iter 93000, loss: 0.506805
 >> iter 94000, loss: 0.464798
 >> iter 95000, loss: 0.622776
 >> iter 96000, loss: 0.517723
 >> iter 97000, loss: 0.516255
 >> iter 98000, loss: 0.506028
 >> iter 99000, loss: 0.397524
 >> iter 100000, loss: 0.495735
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.043353
 >> iter 2000, loss: 12.742974
 >> iter 3000, loss: 9.453702
 >> iter 4000, loss: 6.588631
 >> iter 5000, loss: 4.479042
 >> iter 6000, loss: 2.668061
 >> iter 7000, loss: 1.592012
 >> iter 8000, loss: 1.332856
 >> iter 9000, loss: 1.196716
 >> iter 10000, loss: 0.902035
   Number of active neurons: 6
 >> iter 11000, loss: 0.724292
 >> iter 12000, loss: 0.816075
 >> iter 13000, loss: 0.899066
 >> iter 14000, loss: 0.938072
 >> iter 15000, loss: 0.803838
 >> iter 16000, loss: 0.707191
 >> iter 17000, loss: 0.687812
 >> iter 18000, loss: 0.466821
 >> iter 19000, loss: 0.658821
 >> iter 20000, loss: 0.632335
   Number of active neurons: 6
 >> iter 21000, loss: 0.598160
 >> iter 22000, loss: 0.620957
 >> iter 23000, loss: 0.570675
 >> iter 24000, loss: 0.575836
 >> iter 25000, loss: 0.691018
 >> iter 26000, loss: 0.641087
 >> iter 27000, loss: 0.902113
 >> iter 28000, loss: 0.621312
 >> iter 29000, loss: 0.567957
 >> iter 30000, loss: 0.541743
   Number of active neurons: 6
 >> iter 31000, loss: 0.520706
 >> iter 32000, loss: 0.410391
 >> iter 33000, loss: 0.562108
 >> iter 34000, loss: 0.448796
 >> iter 35000, loss: 0.456681
 >> iter 36000, loss: 0.513041
 >> iter 37000, loss: 0.640429
 >> iter 38000, loss: 0.652802
 >> iter 39000, loss: 0.585071
 >> iter 40000, loss: 0.776472
   Number of active neurons: 6
 >> iter 41000, loss: 0.759620
 >> iter 42000, loss: 0.585306
 >> iter 43000, loss: 0.554937
 >> iter 44000, loss: 0.748664
 >> iter 45000, loss: 0.506430
 >> iter 46000, loss: 0.558799
 >> iter 47000, loss: 0.467465
 >> iter 48000, loss: 0.613906
 >> iter 49000, loss: 0.699214
 >> iter 50000, loss: 0.571360
   Number of active neurons: 6
 >> iter 51000, loss: 0.621642
 >> iter 52000, loss: 0.592306
 >> iter 53000, loss: 0.689117
 >> iter 54000, loss: 0.509688
 >> iter 55000, loss: 0.513352
 >> iter 56000, loss: 0.639958
 >> iter 57000, loss: 0.684442
 >> iter 58000, loss: 0.539995
 >> iter 59000, loss: 0.724328
 >> iter 60000, loss: 0.802414
   Number of active neurons: 5
 >> iter 61000, loss: 0.583487
 >> iter 62000, loss: 0.634303
 >> iter 63000, loss: 0.657489
 >> iter 64000, loss: 0.644386
 >> iter 65000, loss: 0.639179
 >> iter 66000, loss: 0.624716
 >> iter 67000, loss: 0.720436
 >> iter 68000, loss: 0.683535
 >> iter 69000, loss: 0.490068
 >> iter 70000, loss: 0.540572
   Number of active neurons: 5
 >> iter 71000, loss: 0.474631
 >> iter 72000, loss: 0.618242
 >> iter 73000, loss: 0.569036
 >> iter 74000, loss: 0.475553
 >> iter 75000, loss: 0.543333
 >> iter 76000, loss: 0.643429
 >> iter 77000, loss: 0.444583
 >> iter 78000, loss: 0.445014
 >> iter 79000, loss: 0.695396
 >> iter 80000, loss: 0.747734
   Number of active neurons: 5
 >> iter 81000, loss: 0.593990
 >> iter 82000, loss: 0.589999
 >> iter 83000, loss: 0.595510
 >> iter 84000, loss: 0.616485
 >> iter 85000, loss: 0.573179
 >> iter 86000, loss: 0.732466
 >> iter 87000, loss: 0.623823
 >> iter 88000, loss: 0.667107
 >> iter 89000, loss: 0.823029
 >> iter 90000, loss: 0.650021
   Number of active neurons: 5
 >> iter 91000, loss: 0.581765
 >> iter 92000, loss: 0.663456
 >> iter 93000, loss: 0.551392
 >> iter 94000, loss: 0.609065
 >> iter 95000, loss: 0.784122
 >> iter 96000, loss: 0.631795
 >> iter 97000, loss: 0.635761
 >> iter 98000, loss: 0.652368
 >> iter 99000, loss: 0.657068
 >> iter 100000, loss: 0.655882
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.068490
 >> iter 2000, loss: 9.492045
 >> iter 3000, loss: 4.223819
 >> iter 4000, loss: 2.056906
 >> iter 5000, loss: 1.046674
 >> iter 6000, loss: 0.558608
 >> iter 7000, loss: 0.369450
 >> iter 8000, loss: 0.357426
 >> iter 9000, loss: 0.353059
 >> iter 10000, loss: 0.382008
   Number of active neurons: 5
 >> iter 11000, loss: 0.351392
 >> iter 12000, loss: 0.325490
 >> iter 13000, loss: 0.330591
 >> iter 14000, loss: 0.250750
 >> iter 15000, loss: 0.295844
 >> iter 16000, loss: 0.285265
 >> iter 17000, loss: 0.269322
 >> iter 18000, loss: 0.268030
 >> iter 19000, loss: 0.283947
 >> iter 20000, loss: 0.263946
   Number of active neurons: 5
 >> iter 21000, loss: 0.366595
 >> iter 22000, loss: 0.232857
 >> iter 23000, loss: 0.216387
 >> iter 24000, loss: 0.196006
 >> iter 25000, loss: 0.282659
 >> iter 26000, loss: 0.231464
 >> iter 27000, loss: 0.200184
 >> iter 28000, loss: 0.244193
 >> iter 29000, loss: 0.238953
 >> iter 30000, loss: 0.262514
   Number of active neurons: 4
 >> iter 31000, loss: 0.293763
 >> iter 32000, loss: 0.290257
 >> iter 33000, loss: 0.351844
 >> iter 34000, loss: 0.266093
 >> iter 35000, loss: 0.361454
 >> iter 36000, loss: 0.308684
 >> iter 37000, loss: 0.244862
 >> iter 38000, loss: 0.237851
 >> iter 39000, loss: 0.332573
 >> iter 40000, loss: 0.308377
   Number of active neurons: 4
 >> iter 41000, loss: 0.340843
 >> iter 42000, loss: 0.298122
 >> iter 43000, loss: 0.253126
 >> iter 44000, loss: 0.246551
 >> iter 45000, loss: 0.250215
 >> iter 46000, loss: 0.300163
 >> iter 47000, loss: 0.436622
 >> iter 48000, loss: 0.262947
 >> iter 49000, loss: 0.292587
 >> iter 50000, loss: 0.288918
   Number of active neurons: 4
 >> iter 51000, loss: 0.304308
 >> iter 52000, loss: 0.212488
 >> iter 53000, loss: 0.202748
 >> iter 54000, loss: 0.264892
 >> iter 55000, loss: 0.289116
 >> iter 56000, loss: 0.253038
 >> iter 57000, loss: 0.268869
 >> iter 58000, loss: 0.241138
 >> iter 59000, loss: 0.173130
 >> iter 60000, loss: 0.213223
   Number of active neurons: 4
 >> iter 61000, loss: 0.218654
 >> iter 62000, loss: 0.270515
 >> iter 63000, loss: 0.279737
 >> iter 64000, loss: 0.231918
 >> iter 65000, loss: 0.256877
 >> iter 66000, loss: 0.265575
 >> iter 67000, loss: 0.294862
 >> iter 68000, loss: 0.266124
 >> iter 69000, loss: 0.195840
 >> iter 70000, loss: 0.241485
   Number of active neurons: 4
 >> iter 71000, loss: 0.252980
 >> iter 72000, loss: 0.219644
 >> iter 73000, loss: 0.257803
 >> iter 74000, loss: 0.248696
 >> iter 75000, loss: 0.238563
 >> iter 76000, loss: 0.172760
 >> iter 77000, loss: 0.248373
 >> iter 78000, loss: 0.242988
 >> iter 79000, loss: 0.286229
 >> iter 80000, loss: 0.248290
   Number of active neurons: 4
 >> iter 81000, loss: 0.291389
 >> iter 82000, loss: 0.210943
 >> iter 83000, loss: 0.264231
 >> iter 84000, loss: 0.376919
 >> iter 85000, loss: 0.257102
 >> iter 86000, loss: 0.203316
 >> iter 87000, loss: 0.338679
 >> iter 88000, loss: 0.378461
 >> iter 89000, loss: 0.321930
 >> iter 90000, loss: 0.339763
   Number of active neurons: 4
 >> iter 91000, loss: 0.288644
 >> iter 92000, loss: 0.341538
 >> iter 93000, loss: 0.269330
 >> iter 94000, loss: 0.198552
 >> iter 95000, loss: 0.269526
 >> iter 96000, loss: 0.222589
 >> iter 97000, loss: 0.269758
 >> iter 98000, loss: 0.220839
 >> iter 99000, loss: 0.189251
 >> iter 100000, loss: 0.214752
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.749073
 >> iter 2000, loss: 11.196467
 >> iter 3000, loss: 8.453138
 >> iter 4000, loss: 6.839704
 >> iter 5000, loss: 5.070423
 >> iter 6000, loss: 3.763096
 >> iter 7000, loss: 3.010549
 >> iter 8000, loss: 2.157299
 >> iter 9000, loss: 1.599941
 >> iter 10000, loss: 1.217204
   Number of active neurons: 6
 >> iter 11000, loss: 0.886516
 >> iter 12000, loss: 0.754560
 >> iter 13000, loss: 0.597323
 >> iter 14000, loss: 0.807112
 >> iter 15000, loss: 0.531929
 >> iter 16000, loss: 0.604113
 >> iter 17000, loss: 0.625088
 >> iter 18000, loss: 0.517039
 >> iter 19000, loss: 0.501023
 >> iter 20000, loss: 0.399219
   Number of active neurons: 6
 >> iter 21000, loss: 0.331566
 >> iter 22000, loss: 0.450360
 >> iter 23000, loss: 0.381570
 >> iter 24000, loss: 0.376183
 >> iter 25000, loss: 0.433678
 >> iter 26000, loss: 0.494762
 >> iter 27000, loss: 0.570298
 >> iter 28000, loss: 0.549703
 >> iter 29000, loss: 0.484543
 >> iter 30000, loss: 0.464905
   Number of active neurons: 6
 >> iter 31000, loss: 0.567759
 >> iter 32000, loss: 0.488708
 >> iter 33000, loss: 0.531209
 >> iter 34000, loss: 0.637043
 >> iter 35000, loss: 0.526101
 >> iter 36000, loss: 0.466875
 >> iter 37000, loss: 0.480625
 >> iter 38000, loss: 0.469685
 >> iter 39000, loss: 0.457228
 >> iter 40000, loss: 0.535842
   Number of active neurons: 6
 >> iter 41000, loss: 0.536808
 >> iter 42000, loss: 0.508956
 >> iter 43000, loss: 0.440343
 >> iter 44000, loss: 0.391923
 >> iter 45000, loss: 0.421395
 >> iter 46000, loss: 0.522423
 >> iter 47000, loss: 0.472968
 >> iter 48000, loss: 0.550872
 >> iter 49000, loss: 0.456553
 >> iter 50000, loss: 0.545329
   Number of active neurons: 5
 >> iter 51000, loss: 0.570547
 >> iter 52000, loss: 0.852539
 >> iter 53000, loss: 0.846405
 >> iter 54000, loss: 0.861317
 >> iter 55000, loss: 0.659539
 >> iter 56000, loss: 0.586966
 >> iter 57000, loss: 0.597294
 >> iter 58000, loss: 0.456420
 >> iter 59000, loss: 0.479461
 >> iter 60000, loss: 0.410991
   Number of active neurons: 5
 >> iter 61000, loss: 0.368084
 >> iter 62000, loss: 0.498183
 >> iter 63000, loss: 0.460961
 >> iter 64000, loss: 0.504100
 >> iter 65000, loss: 0.588572
 >> iter 66000, loss: 0.526975
 >> iter 67000, loss: 0.646083
 >> iter 68000, loss: 0.528184
 >> iter 69000, loss: 0.519106
 >> iter 70000, loss: 0.506134
   Number of active neurons: 5
 >> iter 71000, loss: 0.473907
 >> iter 72000, loss: 0.483667
 >> iter 73000, loss: 0.607155
 >> iter 74000, loss: 0.630589
 >> iter 75000, loss: 0.563643
 >> iter 76000, loss: 0.700414
 >> iter 77000, loss: 0.577579
 >> iter 78000, loss: 0.637819
 >> iter 79000, loss: 0.592861
 >> iter 80000, loss: 0.609262
   Number of active neurons: 5
 >> iter 81000, loss: 0.551223
 >> iter 82000, loss: 0.555782
 >> iter 83000, loss: 0.659598
 >> iter 84000, loss: 0.520978
 >> iter 85000, loss: 0.773680
 >> iter 86000, loss: 0.907099
 >> iter 87000, loss: 0.805723
 >> iter 88000, loss: 0.460130
 >> iter 89000, loss: 0.516757
 >> iter 90000, loss: 0.678693
   Number of active neurons: 4
 >> iter 91000, loss: 0.448198
 >> iter 92000, loss: 0.697344
 >> iter 93000, loss: 0.868321
 >> iter 94000, loss: 0.844627
 >> iter 95000, loss: 0.787647
 >> iter 96000, loss: 0.672750
 >> iter 97000, loss: 0.524466
 >> iter 98000, loss: 0.581357
 >> iter 99000, loss: 0.523523
 >> iter 100000, loss: 0.579188
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.725285
 >> iter 2000, loss: 11.464139
 >> iter 3000, loss: 7.800245
 >> iter 4000, loss: 4.216434
 >> iter 5000, loss: 2.390227
 >> iter 6000, loss: 1.448226
 >> iter 7000, loss: 1.159328
 >> iter 8000, loss: 0.849724
 >> iter 9000, loss: 0.662239
 >> iter 10000, loss: 0.478735
   Number of active neurons: 4
 >> iter 11000, loss: 0.574693
 >> iter 12000, loss: 0.558003
 >> iter 13000, loss: 0.562566
 >> iter 14000, loss: 0.525137
 >> iter 15000, loss: 0.427792
 >> iter 16000, loss: 0.435233
 >> iter 17000, loss: 0.424284
 >> iter 18000, loss: 0.442490
 >> iter 19000, loss: 0.487700
 >> iter 20000, loss: 0.485902
   Number of active neurons: 4
 >> iter 21000, loss: 0.486079
 >> iter 22000, loss: 0.458735
 >> iter 23000, loss: 0.555419
 >> iter 24000, loss: 0.700906
 >> iter 25000, loss: 0.659013
 >> iter 26000, loss: 0.658222
 >> iter 27000, loss: 0.493640
 >> iter 28000, loss: 0.698099
 >> iter 29000, loss: 0.641441
 >> iter 30000, loss: 0.544682
   Number of active neurons: 4
 >> iter 31000, loss: 0.594243
 >> iter 32000, loss: 0.555769
 >> iter 33000, loss: 0.577332
 >> iter 34000, loss: 0.597910
 >> iter 35000, loss: 0.429898
 >> iter 36000, loss: 0.366107
 >> iter 37000, loss: 0.411821
 >> iter 38000, loss: 0.420128
 >> iter 39000, loss: 0.461357
 >> iter 40000, loss: 0.423893
   Number of active neurons: 4
 >> iter 41000, loss: 0.495864
 >> iter 42000, loss: 0.467989
 >> iter 43000, loss: 0.504940
 >> iter 44000, loss: 0.451105
 >> iter 45000, loss: 0.486100
 >> iter 46000, loss: 0.456373
 >> iter 47000, loss: 0.424203
 >> iter 48000, loss: 0.473546
 >> iter 49000, loss: 0.465649
 >> iter 50000, loss: 0.601955
   Number of active neurons: 4
 >> iter 51000, loss: 0.768759
 >> iter 52000, loss: 0.725460
 >> iter 53000, loss: 0.655960
 >> iter 54000, loss: 0.556741
 >> iter 55000, loss: 0.522001
 >> iter 56000, loss: 0.547816
 >> iter 57000, loss: 0.537554
 >> iter 58000, loss: 0.580774
 >> iter 59000, loss: 0.569166
 >> iter 60000, loss: 0.589619
   Number of active neurons: 4
 >> iter 61000, loss: 0.529659
 >> iter 62000, loss: 0.361834
 >> iter 63000, loss: 0.398318
 >> iter 64000, loss: 0.527502
 >> iter 65000, loss: 0.598936
 >> iter 66000, loss: 0.422861
 >> iter 67000, loss: 0.646569
 >> iter 68000, loss: 0.573467
 >> iter 69000, loss: 0.465465
 >> iter 70000, loss: 0.607928
   Number of active neurons: 4
 >> iter 71000, loss: 0.538138
 >> iter 72000, loss: 0.414055
 >> iter 73000, loss: 0.454615
 >> iter 74000, loss: 0.445482
 >> iter 75000, loss: 0.511931
 >> iter 76000, loss: 0.518342
 >> iter 77000, loss: 0.601456
 >> iter 78000, loss: 0.518743
 >> iter 79000, loss: 0.446173
 >> iter 80000, loss: 0.552978
   Number of active neurons: 4
 >> iter 81000, loss: 0.495326
 >> iter 82000, loss: 0.413939
 >> iter 83000, loss: 0.479846
 >> iter 84000, loss: 0.422764
 >> iter 85000, loss: 0.453058
 >> iter 86000, loss: 0.478974
 >> iter 87000, loss: 0.473857
 >> iter 88000, loss: 0.473928
 >> iter 89000, loss: 0.616316
 >> iter 90000, loss: 0.418258
   Number of active neurons: 4
 >> iter 91000, loss: 0.368998
 >> iter 92000, loss: 0.446170
 >> iter 93000, loss: 0.667618
 >> iter 94000, loss: 0.663083
 >> iter 95000, loss: 0.497773
 >> iter 96000, loss: 0.573534
 >> iter 97000, loss: 0.436932
 >> iter 98000, loss: 0.568116
 >> iter 99000, loss: 0.498470
 >> iter 100000, loss: 0.401380
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.169447
 >> iter 2000, loss: 13.933193
 >> iter 3000, loss: 11.868545
 >> iter 4000, loss: 10.289437
 >> iter 5000, loss: 7.837383
 >> iter 6000, loss: 5.623897
 >> iter 7000, loss: 4.414724
 >> iter 8000, loss: 3.843455
 >> iter 9000, loss: 3.463280
 >> iter 10000, loss: 3.350133
   Number of active neurons: 5
 >> iter 11000, loss: 3.187671
 >> iter 12000, loss: 3.123441
 >> iter 13000, loss: 3.074497
 >> iter 14000, loss: 3.107881
 >> iter 15000, loss: 3.126743
 >> iter 16000, loss: 3.080841
 >> iter 17000, loss: 2.999633
 >> iter 18000, loss: 2.992440
 >> iter 19000, loss: 3.054708
 >> iter 20000, loss: 3.164216
   Number of active neurons: 5
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 5
 >> iter 21000, loss: 3.031963
 >> iter 22000, loss: 3.099620
 >> iter 23000, loss: 3.218052
 >> iter 24000, loss: 3.026905
 >> iter 25000, loss: 2.970195
 >> iter 26000, loss: 3.025533
 >> iter 27000, loss: 3.069922
 >> iter 28000, loss: 2.970532
 >> iter 29000, loss: 2.995939
 >> iter 30000, loss: 2.861613
   Number of active neurons: 4
 >> iter 31000, loss: 2.881909
 >> iter 32000, loss: 2.939308
 >> iter 33000, loss: 2.922263
 >> iter 34000, loss: 2.999157
 >> iter 35000, loss: 3.011967
   Number of active neurons: 4
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 36000, loss: 3.017657
 >> iter 37000, loss: 3.053755
 >> iter 38000, loss: 2.901539
 >> iter 39000, loss: 2.875522
 >> iter 40000, loss: 2.990660
   Number of active neurons: 4
 >> iter 41000, loss: 2.965434
 >> iter 42000, loss: 2.981451
 >> iter 43000, loss: 2.883730
 >> iter 44000, loss: 2.929394
 >> iter 45000, loss: 2.968304
 >> iter 46000, loss: 3.061814
 >> iter 47000, loss: 3.016894
 >> iter 48000, loss: 2.996361
 >> iter 49000, loss: 2.963848
 >> iter 50000, loss: 3.055119
   Number of active neurons: 4
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 4
 >> iter 51000, loss: 3.033918
 >> iter 52000, loss: 2.978349
 >> iter 53000, loss: 3.107479
 >> iter 54000, loss: 2.993386
 >> iter 55000, loss: 3.016989
 >> iter 56000, loss: 2.980251
 >> iter 57000, loss: 2.953050
 >> iter 58000, loss: 3.005486
 >> iter 59000, loss: 2.933567
 >> iter 60000, loss: 2.919131
   Number of active neurons: 4
 >> iter 61000, loss: 2.991981
 >> iter 62000, loss: 3.047948
 >> iter 63000, loss: 2.930116
 >> iter 64000, loss: 3.047107
 >> iter 65000, loss: 3.053258
   Number of active neurons: 4
   SHOCK
   Setting new limit to 287500.0 iters...
 >> iter 66000, loss: 3.033503
 >> iter 67000, loss: 3.101333
 >> iter 68000, loss: 3.143934
 >> iter 69000, loss: 2.940957
 >> iter 70000, loss: 2.895858
   Number of active neurons: 4
 >> iter 71000, loss: 2.856412
 >> iter 72000, loss: 3.039239
 >> iter 73000, loss: 2.945859
 >> iter 74000, loss: 2.965051
 >> iter 75000, loss: 2.953431
   Number of active neurons: 4
   SHOCK
   Setting new limit to 293750.0 iters...
 >> iter 76000, loss: 2.960384
 >> iter 77000, loss: 2.962703
 >> iter 78000, loss: 3.120501
 >> iter 79000, loss: 3.026475
 >> iter 80000, loss: 2.899335
   Number of active neurons: 5
 >> iter 81000, loss: 3.122788
 >> iter 82000, loss: 3.025455
 >> iter 83000, loss: 3.024929
 >> iter 84000, loss: 3.006229
 >> iter 85000, loss: 2.995603
   Number of active neurons: 4
   SHOCK
   Setting new limit to 296875.0 iters...
 >> iter 86000, loss: 3.083628
 >> iter 87000, loss: 3.032237
 >> iter 88000, loss: 2.971206
 >> iter 89000, loss: 2.939482
 >> iter 90000, loss: 2.990993
   Number of active neurons: 4
 >> iter 91000, loss: 2.889183
 >> iter 92000, loss: 2.924226
 >> iter 93000, loss: 2.986601
 >> iter 94000, loss: 2.943928
 >> iter 95000, loss: 3.170723
   Number of active neurons: 4
   SHOCK
   Setting new limit to 298437.5 iters...
 >> iter 96000, loss: 3.089971
 >> iter 97000, loss: 3.054099
 >> iter 98000, loss: 3.125319
 >> iter 99000, loss: 3.048229
 >> iter 100000, loss: 2.995005
   Number of active neurons: 4
 >> iter 101000, loss: 2.976908
 >> iter 102000, loss: 2.899117
 >> iter 103000, loss: 2.903547
 >> iter 104000, loss: 2.954254
 >> iter 105000, loss: 2.887656
 >> iter 106000, loss: 2.846737
 >> iter 107000, loss: 2.911454
 >> iter 108000, loss: 2.964086
 >> iter 109000, loss: 2.986469
 >> iter 110000, loss: 3.138997
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299218.75 iters...
   Number of active neurons: 4
 >> iter 111000, loss: 3.122096
 >> iter 112000, loss: 3.158559
 >> iter 113000, loss: 3.020629
 >> iter 114000, loss: 3.036099
 >> iter 115000, loss: 2.964518
 >> iter 116000, loss: 3.041004
 >> iter 117000, loss: 2.965051
 >> iter 118000, loss: 2.987914
 >> iter 119000, loss: 3.116880
 >> iter 120000, loss: 2.955551
   Number of active neurons: 4
 >> iter 121000, loss: 2.959614
 >> iter 122000, loss: 3.000055
 >> iter 123000, loss: 3.038876
 >> iter 124000, loss: 2.980639
 >> iter 125000, loss: 3.039981
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299609.375 iters...
 >> iter 126000, loss: 3.012515
 >> iter 127000, loss: 3.086714
 >> iter 128000, loss: 2.980411
 >> iter 129000, loss: 2.937880
 >> iter 130000, loss: 2.874298
   Number of active neurons: 5
 >> iter 131000, loss: 2.962898
 >> iter 132000, loss: 2.985693
 >> iter 133000, loss: 2.906985
 >> iter 134000, loss: 2.894319
 >> iter 135000, loss: 2.932484
   Number of active neurons: 5
   SHOCK
   Setting new limit to 299804.6875 iters...
 >> iter 136000, loss: 2.976036
 >> iter 137000, loss: 3.010267
 >> iter 138000, loss: 2.951455
 >> iter 139000, loss: 3.010527
 >> iter 140000, loss: 3.087200
   Number of active neurons: 5
   SHOCK
   Setting new limit to 299902.34375 iters...
   Number of active neurons: 5
 >> iter 141000, loss: 3.013227
 >> iter 142000, loss: 2.956722
 >> iter 143000, loss: 2.955759
 >> iter 144000, loss: 2.995852
 >> iter 145000, loss: 2.891395
 >> iter 146000, loss: 2.920900
 >> iter 147000, loss: 2.885392
 >> iter 148000, loss: 2.970614
 >> iter 149000, loss: 3.097960
 >> iter 150000, loss: 3.043991
   Number of active neurons: 5
   SHOCK
   Setting new limit to 299951.171875 iters...
   Number of active neurons: 5
 >> iter 151000, loss: 3.045767
 >> iter 152000, loss: 3.055376
 >> iter 153000, loss: 2.909568
 >> iter 154000, loss: 2.930442
 >> iter 155000, loss: 2.868098
 >> iter 156000, loss: 3.001773
 >> iter 157000, loss: 2.977244
 >> iter 158000, loss: 2.908906
 >> iter 159000, loss: 2.903193
 >> iter 160000, loss: 2.853051
   Number of active neurons: 4
 >> iter 161000, loss: 2.897252
 >> iter 162000, loss: 2.983680
 >> iter 163000, loss: 3.004790
 >> iter 164000, loss: 3.003334
 >> iter 165000, loss: 2.958651
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299975.585938 iters...
 >> iter 166000, loss: 3.123109
 >> iter 167000, loss: 3.014518
 >> iter 168000, loss: 2.947541
 >> iter 169000, loss: 2.926408
 >> iter 170000, loss: 3.012276
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299987.792969 iters...
   Number of active neurons: 4
 >> iter 171000, loss: 2.985009
 >> iter 172000, loss: 3.001825
 >> iter 173000, loss: 3.046961
 >> iter 174000, loss: 3.095428
 >> iter 175000, loss: 3.113497
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299993.896484 iters...
 >> iter 176000, loss: 3.021250
 >> iter 177000, loss: 2.925803
 >> iter 178000, loss: 2.932739
 >> iter 179000, loss: 2.816767
 >> iter 180000, loss: 2.940957
   Number of active neurons: 4
 >> iter 181000, loss: 2.873250
 >> iter 182000, loss: 2.946490
 >> iter 183000, loss: 2.862691
 >> iter 184000, loss: 2.902855
 >> iter 185000, loss: 2.931468
 >> iter 186000, loss: 2.948628
 >> iter 187000, loss: 2.849121
 >> iter 188000, loss: 3.007140
 >> iter 189000, loss: 3.050811
 >> iter 190000, loss: 3.092112
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299996.948242 iters...
   Number of active neurons: 4
 >> iter 191000, loss: 3.066310
 >> iter 192000, loss: 3.016462
 >> iter 193000, loss: 2.921244
 >> iter 194000, loss: 2.865572
 >> iter 195000, loss: 2.844713
 >> iter 196000, loss: 3.030903
 >> iter 197000, loss: 2.974188
 >> iter 198000, loss: 3.025371
 >> iter 199000, loss: 2.896090
 >> iter 200000, loss: 3.045459
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299998.474121 iters...
   Number of active neurons: 4
 >> iter 201000, loss: 2.945465
 >> iter 202000, loss: 3.019994
 >> iter 203000, loss: 3.037824
 >> iter 204000, loss: 3.053060
 >> iter 205000, loss: 3.108743
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299999.237061 iters...
 >> iter 206000, loss: 3.090551
 >> iter 207000, loss: 3.043218
 >> iter 208000, loss: 3.078595
 >> iter 209000, loss: 2.961275
 >> iter 210000, loss: 2.945036
   Number of active neurons: 4
 >> iter 211000, loss: 3.023508
 >> iter 212000, loss: 2.951101
 >> iter 213000, loss: 3.071572
 >> iter 214000, loss: 2.890127
 >> iter 215000, loss: 3.001787
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299999.61853 iters...
 >> iter 216000, loss: 3.011279
 >> iter 217000, loss: 3.089035
 >> iter 218000, loss: 2.940984
 >> iter 219000, loss: 2.956342
 >> iter 220000, loss: 2.979612
   Number of active neurons: 4
 >> iter 221000, loss: 2.921593
 >> iter 222000, loss: 2.886560
 >> iter 223000, loss: 2.927327
 >> iter 224000, loss: 2.982755
 >> iter 225000, loss: 2.985935
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299999.809265 iters...
 >> iter 226000, loss: 3.011154
 >> iter 227000, loss: 2.984038
 >> iter 228000, loss: 3.032938
 >> iter 229000, loss: 2.870946
 >> iter 230000, loss: 3.080417
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299999.904633 iters...
   Number of active neurons: 4
 >> iter 231000, loss: 3.015997
 >> iter 232000, loss: 2.973312
 >> iter 233000, loss: 3.045153
 >> iter 234000, loss: 2.991637
 >> iter 235000, loss: 3.012161
 >> iter 236000, loss: 2.996541
 >> iter 237000, loss: 2.918603
 >> iter 238000, loss: 3.121959
 >> iter 239000, loss: 3.067579
 >> iter 240000, loss: 3.025323
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299999.952316 iters...
   Number of active neurons: 4
 >> iter 241000, loss: 3.010465
 >> iter 242000, loss: 2.948716
 >> iter 243000, loss: 2.997773
 >> iter 244000, loss: 3.053989
 >> iter 245000, loss: 3.099431
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299999.976158 iters...
 >> iter 246000, loss: 3.120335
 >> iter 247000, loss: 3.097106
 >> iter 248000, loss: 3.094462
 >> iter 249000, loss: 3.058621
 >> iter 250000, loss: 3.020809
   Number of active neurons: 4
 >> iter 251000, loss: 2.937756
 >> iter 252000, loss: 2.934260
 >> iter 253000, loss: 2.937823
 >> iter 254000, loss: 3.057520
 >> iter 255000, loss: 3.013683
 >> iter 256000, loss: 3.030667
 >> iter 257000, loss: 2.959063
 >> iter 258000, loss: 2.910953
 >> iter 259000, loss: 3.079392
 >> iter 260000, loss: 3.119093
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299999.988079 iters...
   Number of active neurons: 4
 >> iter 261000, loss: 3.044001
 >> iter 262000, loss: 3.107378
 >> iter 263000, loss: 3.018712
 >> iter 264000, loss: 3.072674
 >> iter 265000, loss: 2.965160
 >> iter 266000, loss: 2.994611
 >> iter 267000, loss: 3.108675
 >> iter 268000, loss: 3.092145
 >> iter 269000, loss: 3.156595
 >> iter 270000, loss: 3.071406
   Number of active neurons: 6
 >> iter 271000, loss: 2.996883
 >> iter 272000, loss: 3.033004
 >> iter 273000, loss: 3.036641
 >> iter 274000, loss: 3.116176
 >> iter 275000, loss: 2.990788
 >> iter 276000, loss: 2.930545
 >> iter 277000, loss: 2.945119
 >> iter 278000, loss: 3.156289
 >> iter 279000, loss: 2.969983
 >> iter 280000, loss: 2.989237
   Number of active neurons: 4
 >> iter 281000, loss: 2.934398
 >> iter 282000, loss: 3.006613
 >> iter 283000, loss: 2.991953
 >> iter 284000, loss: 2.971438
 >> iter 285000, loss: 2.992522
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299999.99404 iters...
 >> iter 286000, loss: 3.030580
 >> iter 287000, loss: 3.097361
 >> iter 288000, loss: 3.061195
 >> iter 289000, loss: 2.977499
 >> iter 290000, loss: 3.035211
   Number of active neurons: 5
   SHOCK
   Setting new limit to 299999.99702 iters...
   Number of active neurons: 5
 >> iter 291000, loss: 2.971919
 >> iter 292000, loss: 3.067487
 >> iter 293000, loss: 2.992614
 >> iter 294000, loss: 2.945973
 >> iter 295000, loss: 2.928180
 >> iter 296000, loss: 2.899437
 >> iter 297000, loss: 2.920010
 >> iter 298000, loss: 2.989249
 >> iter 299000, loss: 2.883816
 >> iter 300000, loss: 2.940708
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299999.99851 iters...
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 4.81390372193
   - Test - Long: 0.17999100045
   - Test - Big: 5.0129498705
   - Test - A: 0.626624891674
   - Test - B: 8.14612359176

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

