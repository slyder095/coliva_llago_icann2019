 > Problema: tomita3nueva
 > Args:
   - Hidden size: 4
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.663508
 >> iter 2000, loss: 15.836378
 >> iter 3000, loss: 14.752040
 >> iter 4000, loss: 13.502326
 >> iter 5000, loss: 13.790914
 >> iter 6000, loss: 13.945684
 >> iter 7000, loss: 13.900036
 >> iter 8000, loss: 13.542203
 >> iter 9000, loss: 12.176398
 >> iter 10000, loss: 10.787936
   Number of active neurons: 4
 >> iter 11000, loss: 9.757908
 >> iter 12000, loss: 8.673808
 >> iter 13000, loss: 8.412496
 >> iter 14000, loss: 8.093057
 >> iter 15000, loss: 8.197871
 >> iter 16000, loss: 8.064159
 >> iter 17000, loss: 8.078164
 >> iter 18000, loss: 7.761578
 >> iter 19000, loss: 7.759416
 >> iter 20000, loss: 7.767216
   Number of active neurons: 4
 >> iter 21000, loss: 7.949052
 >> iter 22000, loss: 6.912403
 >> iter 23000, loss: 4.797719
 >> iter 24000, loss: 3.236540
 >> iter 25000, loss: 2.300015
 >> iter 26000, loss: 2.186155
 >> iter 27000, loss: 2.301425
 >> iter 28000, loss: 2.156341
 >> iter 29000, loss: 1.906304
 >> iter 30000, loss: 1.467881
   Number of active neurons: 4
 >> iter 31000, loss: 1.682179
 >> iter 32000, loss: 1.316837
 >> iter 33000, loss: 1.241528
 >> iter 34000, loss: 1.292235
 >> iter 35000, loss: 1.324217
 >> iter 36000, loss: 1.524052
 >> iter 37000, loss: 1.505818
 >> iter 38000, loss: 1.095167
 >> iter 39000, loss: 1.143683
 >> iter 40000, loss: 1.107887
   Number of active neurons: 4
 >> iter 41000, loss: 1.177392
 >> iter 42000, loss: 1.046132
 >> iter 43000, loss: 0.980216
 >> iter 44000, loss: 0.938212
 >> iter 45000, loss: 1.004413
 >> iter 46000, loss: 0.962398
 >> iter 47000, loss: 0.949905
 >> iter 48000, loss: 0.963600
 >> iter 49000, loss: 1.111731
 >> iter 50000, loss: 1.060194
   Number of active neurons: 4
 >> iter 51000, loss: 1.363382
 >> iter 52000, loss: 1.451774
 >> iter 53000, loss: 1.539322
 >> iter 54000, loss: 1.235355
 >> iter 55000, loss: 1.203739
 >> iter 56000, loss: 1.134556
 >> iter 57000, loss: 1.117710
 >> iter 58000, loss: 1.065391
 >> iter 59000, loss: 1.164720
 >> iter 60000, loss: 1.225336
   Number of active neurons: 4
 >> iter 61000, loss: 1.234759
 >> iter 62000, loss: 1.110868
 >> iter 63000, loss: 1.142851
 >> iter 64000, loss: 0.918389
 >> iter 65000, loss: 1.246810
 >> iter 66000, loss: 1.239306
 >> iter 67000, loss: 1.091022
 >> iter 68000, loss: 1.008762
 >> iter 69000, loss: 0.985403
 >> iter 70000, loss: 1.029578
   Number of active neurons: 4
 >> iter 71000, loss: 0.892575
 >> iter 72000, loss: 1.007824
 >> iter 73000, loss: 0.863399
 >> iter 74000, loss: 0.914542
 >> iter 75000, loss: 0.920346
 >> iter 76000, loss: 1.081298
 >> iter 77000, loss: 0.942176
 >> iter 78000, loss: 0.887934
 >> iter 79000, loss: 0.749714
 >> iter 80000, loss: 0.849537
   Number of active neurons: 4
 >> iter 81000, loss: 1.195564
 >> iter 82000, loss: 1.062841
 >> iter 83000, loss: 0.798726
 >> iter 84000, loss: 1.068726
 >> iter 85000, loss: 1.213920
 >> iter 86000, loss: 0.957755
 >> iter 87000, loss: 0.961652
 >> iter 88000, loss: 0.709427
 >> iter 89000, loss: 0.527797
 >> iter 90000, loss: 0.831663
   Number of active neurons: 4
 >> iter 91000, loss: 0.750034
 >> iter 92000, loss: 0.621275
 >> iter 93000, loss: 0.788152
 >> iter 94000, loss: 0.792607
 >> iter 95000, loss: 0.654534
 >> iter 96000, loss: 0.748128
 >> iter 97000, loss: 0.864505
 >> iter 98000, loss: 1.028107
 >> iter 99000, loss: 0.825372
 >> iter 100000, loss: 0.900635
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.479469
 >> iter 2000, loss: 15.731042
 >> iter 3000, loss: 14.501967
 >> iter 4000, loss: 13.990915
 >> iter 5000, loss: 14.334939
 >> iter 6000, loss: 14.140097
 >> iter 7000, loss: 13.667679
 >> iter 8000, loss: 13.237124
 >> iter 9000, loss: 13.558000
 >> iter 10000, loss: 11.316323
   Number of active neurons: 4
 >> iter 11000, loss: 7.785052
 >> iter 12000, loss: 3.797889
 >> iter 13000, loss: 1.763153
 >> iter 14000, loss: 1.199610
 >> iter 15000, loss: 0.813045
 >> iter 16000, loss: 0.568597
 >> iter 17000, loss: 0.499367
 >> iter 18000, loss: 0.521562
 >> iter 19000, loss: 0.522151
 >> iter 20000, loss: 0.421860
   Number of active neurons: 4
 >> iter 21000, loss: 0.506751
 >> iter 22000, loss: 0.487995
 >> iter 23000, loss: 0.396656
 >> iter 24000, loss: 0.313930
 >> iter 25000, loss: 0.334453
 >> iter 26000, loss: 0.418278
 >> iter 27000, loss: 0.443628
 >> iter 28000, loss: 0.377585
 >> iter 29000, loss: 0.509276
 >> iter 30000, loss: 0.318356
   Number of active neurons: 4
 >> iter 31000, loss: 0.527255
 >> iter 32000, loss: 0.377093
 >> iter 33000, loss: 0.392340
 >> iter 34000, loss: 0.311149
 >> iter 35000, loss: 0.418941
 >> iter 36000, loss: 0.489171
 >> iter 37000, loss: 0.574857
 >> iter 38000, loss: 0.364640
 >> iter 39000, loss: 0.291679
 >> iter 40000, loss: 0.350277
   Number of active neurons: 4
 >> iter 41000, loss: 0.433008
 >> iter 42000, loss: 0.414036
 >> iter 43000, loss: 0.496561
 >> iter 44000, loss: 0.441702
 >> iter 45000, loss: 0.388607
 >> iter 46000, loss: 0.588996
 >> iter 47000, loss: 0.414349
 >> iter 48000, loss: 0.454668
 >> iter 49000, loss: 0.407135
 >> iter 50000, loss: 0.323763
   Number of active neurons: 4
 >> iter 51000, loss: 0.424184
 >> iter 52000, loss: 0.329782
 >> iter 53000, loss: 0.312694
 >> iter 54000, loss: 0.340502
 >> iter 55000, loss: 0.442509
 >> iter 56000, loss: 0.360980
 >> iter 57000, loss: 0.443928
 >> iter 58000, loss: 0.400722
 >> iter 59000, loss: 0.374923
 >> iter 60000, loss: 0.522919
   Number of active neurons: 4
 >> iter 61000, loss: 0.521304
 >> iter 62000, loss: 0.401599
 >> iter 63000, loss: 0.318409
 >> iter 64000, loss: 0.401214
 >> iter 65000, loss: 0.407041
 >> iter 66000, loss: 0.493703
 >> iter 67000, loss: 0.402905
 >> iter 68000, loss: 0.422485
 >> iter 69000, loss: 0.323085
 >> iter 70000, loss: 0.234616
   Number of active neurons: 4
 >> iter 71000, loss: 0.397640
 >> iter 72000, loss: 0.348553
 >> iter 73000, loss: 0.291599
 >> iter 74000, loss: 0.442176
 >> iter 75000, loss: 0.310611
 >> iter 76000, loss: 0.321542
 >> iter 77000, loss: 0.415036
 >> iter 78000, loss: 0.404757
 >> iter 79000, loss: 0.414195
 >> iter 80000, loss: 0.307777
   Number of active neurons: 4
 >> iter 81000, loss: 0.406630
 >> iter 82000, loss: 0.418216
 >> iter 83000, loss: 0.391691
 >> iter 84000, loss: 0.320189
 >> iter 85000, loss: 0.403082
 >> iter 86000, loss: 0.364783
 >> iter 87000, loss: 0.321251
 >> iter 88000, loss: 0.372587
 >> iter 89000, loss: 0.429883
 >> iter 90000, loss: 0.298698
   Number of active neurons: 4
 >> iter 91000, loss: 0.441086
 >> iter 92000, loss: 0.347017
 >> iter 93000, loss: 0.266566
 >> iter 94000, loss: 0.202371
 >> iter 95000, loss: 0.494551
 >> iter 96000, loss: 0.496856
 >> iter 97000, loss: 0.280546
 >> iter 98000, loss: 0.248057
 >> iter 99000, loss: 0.303893
 >> iter 100000, loss: 0.395308
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 12.2125191654
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.152768
 >> iter 2000, loss: 15.661954
 >> iter 3000, loss: 14.366081
 >> iter 4000, loss: 13.930295
 >> iter 5000, loss: 13.669938
 >> iter 6000, loss: 13.465347
 >> iter 7000, loss: 13.616742
 >> iter 8000, loss: 12.217136
 >> iter 9000, loss: 11.011483
 >> iter 10000, loss: 10.393674
   Number of active neurons: 4
 >> iter 11000, loss: 10.313150
 >> iter 12000, loss: 9.650535
 >> iter 13000, loss: 9.361076
 >> iter 14000, loss: 8.873188
 >> iter 15000, loss: 8.685042
 >> iter 16000, loss: 7.529634
 >> iter 17000, loss: 5.110545
 >> iter 18000, loss: 3.539874
 >> iter 19000, loss: 2.657399
 >> iter 20000, loss: 1.769552
   Number of active neurons: 4
 >> iter 21000, loss: 1.021906
 >> iter 22000, loss: 0.683265
 >> iter 23000, loss: 0.598734
 >> iter 24000, loss: 0.434269
 >> iter 25000, loss: 0.414419
 >> iter 26000, loss: 0.350894
 >> iter 27000, loss: 0.320003
 >> iter 28000, loss: 0.394335
 >> iter 29000, loss: 0.294906
 >> iter 30000, loss: 0.299423
   Number of active neurons: 4
 >> iter 31000, loss: 0.298667
 >> iter 32000, loss: 0.332602
 >> iter 33000, loss: 0.331210
 >> iter 34000, loss: 0.364240
 >> iter 35000, loss: 0.313195
 >> iter 36000, loss: 0.343541
 >> iter 37000, loss: 0.260236
 >> iter 38000, loss: 0.298948
 >> iter 39000, loss: 0.298699
 >> iter 40000, loss: 0.378598
   Number of active neurons: 4
 >> iter 41000, loss: 0.286091
 >> iter 42000, loss: 0.239286
 >> iter 43000, loss: 0.456800
 >> iter 44000, loss: 0.422437
 >> iter 45000, loss: 0.414354
 >> iter 46000, loss: 0.349833
 >> iter 47000, loss: 0.418583
 >> iter 48000, loss: 0.313237
 >> iter 49000, loss: 0.393424
 >> iter 50000, loss: 0.421114
   Number of active neurons: 4
 >> iter 51000, loss: 0.388679
 >> iter 52000, loss: 0.393821
 >> iter 53000, loss: 0.502268
 >> iter 54000, loss: 0.327714
 >> iter 55000, loss: 0.387987
 >> iter 56000, loss: 0.560631
 >> iter 57000, loss: 0.467604
 >> iter 58000, loss: 0.358583
 >> iter 59000, loss: 0.397660
 >> iter 60000, loss: 0.330135
   Number of active neurons: 4
 >> iter 61000, loss: 0.408499
 >> iter 62000, loss: 0.359984
 >> iter 63000, loss: 0.453286
 >> iter 64000, loss: 0.402012
 >> iter 65000, loss: 0.342736
 >> iter 66000, loss: 0.296955
 >> iter 67000, loss: 0.372422
 >> iter 68000, loss: 0.275411
 >> iter 69000, loss: 0.299643
 >> iter 70000, loss: 0.278793
   Number of active neurons: 4
 >> iter 71000, loss: 0.444152
 >> iter 72000, loss: 0.329655
 >> iter 73000, loss: 0.347963
 >> iter 74000, loss: 0.328144
 >> iter 75000, loss: 0.242843
 >> iter 76000, loss: 0.279784
 >> iter 77000, loss: 0.468047
 >> iter 78000, loss: 0.383883
 >> iter 79000, loss: 0.664779
 >> iter 80000, loss: 0.382813
   Number of active neurons: 4
 >> iter 81000, loss: 0.275867
 >> iter 82000, loss: 0.357677
 >> iter 83000, loss: 0.343379
 >> iter 84000, loss: 0.300671
 >> iter 85000, loss: 0.234679
 >> iter 86000, loss: 0.321171
 >> iter 87000, loss: 0.314882
 >> iter 88000, loss: 0.329217
 >> iter 89000, loss: 0.326194
 >> iter 90000, loss: 0.295492
   Number of active neurons: 4
 >> iter 91000, loss: 0.334265
 >> iter 92000, loss: 0.448664
 >> iter 93000, loss: 0.312189
 >> iter 94000, loss: 0.266370
 >> iter 95000, loss: 0.310906
 >> iter 96000, loss: 0.309085
 >> iter 97000, loss: 0.320536
 >> iter 98000, loss: 0.227546
 >> iter 99000, loss: 0.286147
 >> iter 100000, loss: 0.250652
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.356228
 >> iter 2000, loss: 13.840018
 >> iter 3000, loss: 11.274211
 >> iter 4000, loss: 10.223330
 >> iter 5000, loss: 9.877539
 >> iter 6000, loss: 9.794966
 >> iter 7000, loss: 9.794397
 >> iter 8000, loss: 9.199871
 >> iter 9000, loss: 9.260515
 >> iter 10000, loss: 8.880613
   Number of active neurons: 3
 >> iter 11000, loss: 8.839826
 >> iter 12000, loss: 8.584232
 >> iter 13000, loss: 8.662404
 >> iter 14000, loss: 8.494576
 >> iter 15000, loss: 8.676604
 >> iter 16000, loss: 8.390509
 >> iter 17000, loss: 8.533578
 >> iter 18000, loss: 8.384122
 >> iter 19000, loss: 8.569313
 >> iter 20000, loss: 8.304160
   Number of active neurons: 3
 >> iter 21000, loss: 8.561840
 >> iter 22000, loss: 8.321164
 >> iter 23000, loss: 8.559690
 >> iter 24000, loss: 8.326202
 >> iter 25000, loss: 8.550394
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 7.918647
 >> iter 27000, loss: 5.323586
 >> iter 28000, loss: 3.139343
 >> iter 29000, loss: 1.874050
 >> iter 30000, loss: 1.164903
   Number of active neurons: 4
 >> iter 31000, loss: 0.779094
 >> iter 32000, loss: 0.558678
 >> iter 33000, loss: 0.523758
 >> iter 34000, loss: 0.488262
 >> iter 35000, loss: 0.400738
 >> iter 36000, loss: 0.564312
 >> iter 37000, loss: 0.531774
 >> iter 38000, loss: 0.274564
 >> iter 39000, loss: 0.350844
 >> iter 40000, loss: 0.439153
   Number of active neurons: 4
 >> iter 41000, loss: 0.389486
 >> iter 42000, loss: 0.347810
 >> iter 43000, loss: 0.401560
 >> iter 44000, loss: 0.379189
 >> iter 45000, loss: 0.365125
 >> iter 46000, loss: 0.339270
 >> iter 47000, loss: 0.384571
 >> iter 48000, loss: 0.364065
 >> iter 49000, loss: 0.515670
 >> iter 50000, loss: 0.375753
   Number of active neurons: 4
 >> iter 51000, loss: 0.391398
 >> iter 52000, loss: 0.364159
 >> iter 53000, loss: 0.364937
 >> iter 54000, loss: 0.309140
 >> iter 55000, loss: 0.438952
 >> iter 56000, loss: 0.410829
 >> iter 57000, loss: 0.267443
 >> iter 58000, loss: 0.266933
 >> iter 59000, loss: 0.296070
 >> iter 60000, loss: 0.390600
   Number of active neurons: 4
 >> iter 61000, loss: 0.351746
 >> iter 62000, loss: 0.350844
 >> iter 63000, loss: 0.331285
 >> iter 64000, loss: 0.413828
 >> iter 65000, loss: 0.402728
 >> iter 66000, loss: 0.364028
 >> iter 67000, loss: 0.327599
 >> iter 68000, loss: 0.453592
 >> iter 69000, loss: 0.315274
 >> iter 70000, loss: 0.269820
   Number of active neurons: 4
 >> iter 71000, loss: 0.213503
 >> iter 72000, loss: 0.256899
 >> iter 73000, loss: 0.208720
 >> iter 74000, loss: 0.279348
 >> iter 75000, loss: 0.560593
 >> iter 76000, loss: 0.508956
 >> iter 77000, loss: 0.331130
 >> iter 78000, loss: 0.413501
 >> iter 79000, loss: 0.306678
 >> iter 80000, loss: 0.382578
   Number of active neurons: 4
 >> iter 81000, loss: 0.499417
 >> iter 82000, loss: 0.426205
 >> iter 83000, loss: 0.423296
 >> iter 84000, loss: 0.509510
 >> iter 85000, loss: 0.615124
 >> iter 86000, loss: 0.628326
 >> iter 87000, loss: 0.479486
 >> iter 88000, loss: 0.516509
 >> iter 89000, loss: 0.410399
 >> iter 90000, loss: 0.379972
   Number of active neurons: 4
 >> iter 91000, loss: 0.412845
 >> iter 92000, loss: 0.422490
 >> iter 93000, loss: 0.520880
 >> iter 94000, loss: 0.465636
 >> iter 95000, loss: 0.484404
 >> iter 96000, loss: 0.344603
 >> iter 97000, loss: 0.611858
 >> iter 98000, loss: 0.491517
 >> iter 99000, loss: 0.393641
 >> iter 100000, loss: 0.291816
   Number of active neurons: 4
 >> iter 101000, loss: 0.331989
 >> iter 102000, loss: 0.336914
 >> iter 103000, loss: 0.426036
 >> iter 104000, loss: 0.410919
 >> iter 105000, loss: 0.308161
 >> iter 106000, loss: 0.332120
 >> iter 107000, loss: 0.391678
 >> iter 108000, loss: 0.581220
 >> iter 109000, loss: 0.337648
 >> iter 110000, loss: 0.357122
   Number of active neurons: 4
 >> iter 111000, loss: 0.388959
 >> iter 112000, loss: 0.296830
 >> iter 113000, loss: 0.314902
 >> iter 114000, loss: 0.289975
 >> iter 115000, loss: 0.240967
 >> iter 116000, loss: 0.348447
 >> iter 117000, loss: 0.354993
 >> iter 118000, loss: 0.456509
 >> iter 119000, loss: 0.277184
 >> iter 120000, loss: 0.266929
   Number of active neurons: 4
 >> iter 121000, loss: 0.289947
 >> iter 122000, loss: 0.296317
 >> iter 123000, loss: 0.380718
 >> iter 124000, loss: 0.371220
 >> iter 125000, loss: 0.332216
 >> iter 126000, loss: 0.335209
 >> iter 127000, loss: 0.368891
 >> iter 128000, loss: 0.420499
 >> iter 129000, loss: 0.438403
 >> iter 130000, loss: 0.356819
   Number of active neurons: 4
 >> iter 131000, loss: 0.510286
 >> iter 132000, loss: 0.380279
 >> iter 133000, loss: 0.336392
 >> iter 134000, loss: 0.407527
 >> iter 135000, loss: 0.354571
 >> iter 136000, loss: 0.389610
 >> iter 137000, loss: 0.330504
 >> iter 138000, loss: 0.304058
 >> iter 139000, loss: 0.298798
 >> iter 140000, loss: 0.403546
   Number of active neurons: 4
 >> iter 141000, loss: 0.299209
 >> iter 142000, loss: 0.464030
 >> iter 143000, loss: 0.336943
 >> iter 144000, loss: 0.443014
 >> iter 145000, loss: 0.405127
 >> iter 146000, loss: 0.350055
 >> iter 147000, loss: 0.402463
 >> iter 148000, loss: 0.453962
 >> iter 149000, loss: 0.484928
 >> iter 150000, loss: 0.411487
   Number of active neurons: 4
 >> iter 151000, loss: 0.242791
 >> iter 152000, loss: 0.420139
 >> iter 153000, loss: 0.568502
 >> iter 154000, loss: 0.474245
 >> iter 155000, loss: 0.347832
 >> iter 156000, loss: 0.447238
 >> iter 157000, loss: 0.442562
 >> iter 158000, loss: 0.379409
 >> iter 159000, loss: 0.391744
 >> iter 160000, loss: 0.421552
   Number of active neurons: 4
 >> iter 161000, loss: 0.309548
 >> iter 162000, loss: 0.236308
 >> iter 163000, loss: 0.322936
 >> iter 164000, loss: 0.344566
 >> iter 165000, loss: 0.293218
 >> iter 166000, loss: 0.325071
 >> iter 167000, loss: 0.385454
 >> iter 168000, loss: 0.418996
 >> iter 169000, loss: 0.364985
 >> iter 170000, loss: 0.465639
   Number of active neurons: 4
 >> iter 171000, loss: 0.366477
 >> iter 172000, loss: 0.451032
 >> iter 173000, loss: 0.410965
 >> iter 174000, loss: 0.320338
 >> iter 175000, loss: 0.219001
 >> iter 176000, loss: 0.335114
 >> iter 177000, loss: 0.294047
 >> iter 178000, loss: 0.310410
 >> iter 179000, loss: 0.339936
 >> iter 180000, loss: 0.412433
   Number of active neurons: 4
 >> iter 181000, loss: 0.359202
 >> iter 182000, loss: 0.248356
 >> iter 183000, loss: 0.385043
 >> iter 184000, loss: 0.383032
 >> iter 185000, loss: 0.443159
 >> iter 186000, loss: 0.398172
 >> iter 187000, loss: 0.243440
 >> iter 188000, loss: 0.231830
 >> iter 189000, loss: 0.343027
 >> iter 190000, loss: 0.366321
   Number of active neurons: 4
 >> iter 191000, loss: 0.480648
 >> iter 192000, loss: 0.399625
 >> iter 193000, loss: 0.538710
 >> iter 194000, loss: 0.469611
 >> iter 195000, loss: 0.541387
 >> iter 196000, loss: 0.436360
 >> iter 197000, loss: 0.389433
 >> iter 198000, loss: 0.373078
 >> iter 199000, loss: 0.355762
 >> iter 200000, loss: 0.350255
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.280722
 >> iter 2000, loss: 15.802064
 >> iter 3000, loss: 14.768393
 >> iter 4000, loss: 13.804045
 >> iter 5000, loss: 11.806401
 >> iter 6000, loss: 10.413822
 >> iter 7000, loss: 9.761276
 >> iter 8000, loss: 9.011156
 >> iter 9000, loss: 8.911181
 >> iter 10000, loss: 8.478342
   Number of active neurons: 4
 >> iter 11000, loss: 8.539068
 >> iter 12000, loss: 8.275877
 >> iter 13000, loss: 8.423943
 >> iter 14000, loss: 8.136247
 >> iter 15000, loss: 8.294336
 >> iter 16000, loss: 8.074820
 >> iter 17000, loss: 8.247898
 >> iter 18000, loss: 8.020133
 >> iter 19000, loss: 8.220666
 >> iter 20000, loss: 7.988470
   Number of active neurons: 4
 >> iter 21000, loss: 8.197306
 >> iter 22000, loss: 7.893333
 >> iter 23000, loss: 8.184419
 >> iter 24000, loss: 7.920173
 >> iter 25000, loss: 8.158833
 >> iter 26000, loss: 7.853525
 >> iter 27000, loss: 8.148594
 >> iter 28000, loss: 7.862831
 >> iter 29000, loss: 8.105377
 >> iter 30000, loss: 7.836993
   Number of active neurons: 4
 >> iter 31000, loss: 8.142043
 >> iter 32000, loss: 7.907543
 >> iter 33000, loss: 8.132955
 >> iter 34000, loss: 7.880668
 >> iter 35000, loss: 8.141668
 >> iter 36000, loss: 7.855607
 >> iter 37000, loss: 8.098635
 >> iter 38000, loss: 7.855218
 >> iter 39000, loss: 8.169691
 >> iter 40000, loss: 7.854352
   Number of active neurons: 4
 >> iter 41000, loss: 8.128372
 >> iter 42000, loss: 7.239774
 >> iter 43000, loss: 6.143664
 >> iter 44000, loss: 5.502611
 >> iter 45000, loss: 5.613720
 >> iter 46000, loss: 5.370741
 >> iter 47000, loss: 5.544890
 >> iter 48000, loss: 5.342617
 >> iter 49000, loss: 5.490700
 >> iter 50000, loss: 5.385223
   Number of active neurons: 4
 >> iter 51000, loss: 5.430320
 >> iter 52000, loss: 5.351409
 >> iter 53000, loss: 5.547683
 >> iter 54000, loss: 5.275881
 >> iter 55000, loss: 5.236161
 >> iter 56000, loss: 4.786374
 >> iter 57000, loss: 4.651413
 >> iter 58000, loss: 4.324550
 >> iter 59000, loss: 4.136511
 >> iter 60000, loss: 3.715501
   Number of active neurons: 4
 >> iter 61000, loss: 3.680221
 >> iter 62000, loss: 3.434186
 >> iter 63000, loss: 3.495980
 >> iter 64000, loss: 3.398550
 >> iter 65000, loss: 3.428570
 >> iter 66000, loss: 3.080389
 >> iter 67000, loss: 3.268484
 >> iter 68000, loss: 3.174901
 >> iter 69000, loss: 3.284347
 >> iter 70000, loss: 3.254307
   Number of active neurons: 4
 >> iter 71000, loss: 3.270925
 >> iter 72000, loss: 3.110472
 >> iter 73000, loss: 3.467950
 >> iter 74000, loss: 3.114441
 >> iter 75000, loss: 3.230523
 >> iter 76000, loss: 3.343200
 >> iter 77000, loss: 3.297805
 >> iter 78000, loss: 3.095843
 >> iter 79000, loss: 3.129980
 >> iter 80000, loss: 3.179334
   Number of active neurons: 4
 >> iter 81000, loss: 3.357031
 >> iter 82000, loss: 3.187262
 >> iter 83000, loss: 3.164150
 >> iter 84000, loss: 3.114169
 >> iter 85000, loss: 3.184981
 >> iter 86000, loss: 3.169758
 >> iter 87000, loss: 3.207226
 >> iter 88000, loss: 3.065458
 >> iter 89000, loss: 3.124950
 >> iter 90000, loss: 3.288108
   Number of active neurons: 4
 >> iter 91000, loss: 3.292216
 >> iter 92000, loss: 3.243771
 >> iter 93000, loss: 3.295141
 >> iter 94000, loss: 3.267366
 >> iter 95000, loss: 3.382547
 >> iter 96000, loss: 3.211070
 >> iter 97000, loss: 3.309244
 >> iter 98000, loss: 3.090129
 >> iter 99000, loss: 3.274632
 >> iter 100000, loss: 3.112047
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 4.13991720166
   - Test - Long: 1.30993450327
   - Test - Big: 4.39595604044
   - Test - A: 0.333311112592
   - Test - B: 14.8456769549
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.780108
 >> iter 2000, loss: 15.511884
 >> iter 3000, loss: 12.300666
 >> iter 4000, loss: 9.035145
 >> iter 5000, loss: 7.714921
 >> iter 6000, loss: 7.091136
 >> iter 7000, loss: 6.955479
 >> iter 8000, loss: 6.629264
 >> iter 9000, loss: 6.799433
 >> iter 10000, loss: 6.637415
   Number of active neurons: 4
 >> iter 11000, loss: 6.751015
 >> iter 12000, loss: 6.580848
 >> iter 13000, loss: 6.647949
 >> iter 14000, loss: 6.673062
 >> iter 15000, loss: 6.578808
 >> iter 16000, loss: 6.447901
 >> iter 17000, loss: 6.584638
 >> iter 18000, loss: 6.510347
 >> iter 19000, loss: 6.603591
 >> iter 20000, loss: 6.429735
   Number of active neurons: 4
 >> iter 21000, loss: 6.598969
 >> iter 22000, loss: 6.388938
 >> iter 23000, loss: 6.651492
 >> iter 24000, loss: 6.444116
 >> iter 25000, loss: 6.684123
 >> iter 26000, loss: 6.404519
 >> iter 27000, loss: 6.608487
 >> iter 28000, loss: 6.394810
 >> iter 29000, loss: 6.603791
 >> iter 30000, loss: 6.410407
   Number of active neurons: 4
 >> iter 31000, loss: 6.577220
 >> iter 32000, loss: 6.423183
 >> iter 33000, loss: 6.556120
 >> iter 34000, loss: 6.400004
 >> iter 35000, loss: 6.506057
 >> iter 36000, loss: 6.329965
 >> iter 37000, loss: 6.440722
 >> iter 38000, loss: 6.350694
 >> iter 39000, loss: 6.503396
 >> iter 40000, loss: 6.341333
   Number of active neurons: 4
 >> iter 41000, loss: 6.473498
 >> iter 42000, loss: 6.311062
 >> iter 43000, loss: 6.480968
 >> iter 44000, loss: 6.281769
 >> iter 45000, loss: 6.443676
 >> iter 46000, loss: 6.338817
 >> iter 47000, loss: 6.473984
 >> iter 48000, loss: 6.318967
 >> iter 49000, loss: 6.490304
 >> iter 50000, loss: 6.270576
   Number of active neurons: 4
 >> iter 51000, loss: 6.393720
 >> iter 52000, loss: 6.265964
 >> iter 53000, loss: 6.443159
 >> iter 54000, loss: 6.284211
 >> iter 55000, loss: 6.440292
 >> iter 56000, loss: 6.294017
 >> iter 57000, loss: 6.428457
 >> iter 58000, loss: 6.283540
 >> iter 59000, loss: 6.416096
 >> iter 60000, loss: 6.348763
   Number of active neurons: 4
 >> iter 61000, loss: 6.478511
 >> iter 62000, loss: 6.285266
 >> iter 63000, loss: 6.446582
 >> iter 64000, loss: 6.349776
 >> iter 65000, loss: 6.443232
 >> iter 66000, loss: 6.250889
 >> iter 67000, loss: 6.462204
 >> iter 68000, loss: 6.281161
 >> iter 69000, loss: 6.393877
 >> iter 70000, loss: 6.290268
   Number of active neurons: 4
 >> iter 71000, loss: 6.409680
 >> iter 72000, loss: 6.237236
 >> iter 73000, loss: 6.445053
 >> iter 74000, loss: 6.338636
 >> iter 75000, loss: 6.490653
 >> iter 76000, loss: 6.291596
 >> iter 77000, loss: 6.478994
 >> iter 78000, loss: 6.350803
 >> iter 79000, loss: 6.461812
 >> iter 80000, loss: 6.280533
   Number of active neurons: 4
 >> iter 81000, loss: 6.437396
 >> iter 82000, loss: 6.312510
 >> iter 83000, loss: 6.477384
 >> iter 84000, loss: 6.275836
 >> iter 85000, loss: 6.444944
 >> iter 86000, loss: 6.281584
 >> iter 87000, loss: 6.439704
 >> iter 88000, loss: 6.289662
 >> iter 89000, loss: 6.432151
 >> iter 90000, loss: 6.289486
   Number of active neurons: 4
 >> iter 91000, loss: 6.484858
 >> iter 92000, loss: 6.263120
 >> iter 93000, loss: 6.472545
 >> iter 94000, loss: 6.354008
 >> iter 95000, loss: 6.458682
 >> iter 96000, loss: 6.261807
 >> iter 97000, loss: 6.421617
 >> iter 98000, loss: 6.240340
 >> iter 99000, loss: 6.404634
 >> iter 100000, loss: 6.246479
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 9.46581068379
   - Test - Long: 1.89490525474
   - Test - Big: 9.16790832092
   - Test - A: 17.0521965202
   - Test - B: 0.659956002933
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.657843
 >> iter 2000, loss: 15.592398
 >> iter 3000, loss: 14.538031
 >> iter 4000, loss: 14.018815
 >> iter 5000, loss: 13.923302
 >> iter 6000, loss: 13.122666
 >> iter 7000, loss: 13.121482
 >> iter 8000, loss: 12.820744
 >> iter 9000, loss: 11.137577
 >> iter 10000, loss: 9.249963
   Number of active neurons: 4
 >> iter 11000, loss: 8.504739
 >> iter 12000, loss: 7.657789
 >> iter 13000, loss: 5.561204
 >> iter 14000, loss: 3.814891
 >> iter 15000, loss: 3.236266
 >> iter 16000, loss: 2.199866
 >> iter 17000, loss: 1.623467
 >> iter 18000, loss: 1.392819
 >> iter 19000, loss: 0.847229
 >> iter 20000, loss: 0.642493
   Number of active neurons: 4
 >> iter 21000, loss: 0.588863
 >> iter 22000, loss: 0.448853
 >> iter 23000, loss: 0.385317
 >> iter 24000, loss: 0.445037
 >> iter 25000, loss: 0.493931
 >> iter 26000, loss: 0.517263
 >> iter 27000, loss: 0.597913
 >> iter 28000, loss: 0.489287
 >> iter 29000, loss: 0.559596
 >> iter 30000, loss: 0.431024
   Number of active neurons: 4
 >> iter 31000, loss: 0.450217
 >> iter 32000, loss: 0.463223
 >> iter 33000, loss: 0.456874
 >> iter 34000, loss: 0.423818
 >> iter 35000, loss: 0.243313
 >> iter 36000, loss: 0.288742
 >> iter 37000, loss: 0.328238
 >> iter 38000, loss: 0.401372
 >> iter 39000, loss: 0.315078
 >> iter 40000, loss: 0.314943
   Number of active neurons: 4
 >> iter 41000, loss: 0.331507
 >> iter 42000, loss: 0.486523
 >> iter 43000, loss: 0.380600
 >> iter 44000, loss: 0.273459
 >> iter 45000, loss: 0.371564
 >> iter 46000, loss: 0.375401
 >> iter 47000, loss: 0.284568
 >> iter 48000, loss: 0.231964
 >> iter 49000, loss: 0.392465
 >> iter 50000, loss: 0.215899
   Number of active neurons: 4
 >> iter 51000, loss: 0.253159
 >> iter 52000, loss: 0.335436
 >> iter 53000, loss: 0.277297
 >> iter 54000, loss: 0.359595
 >> iter 55000, loss: 0.345672
 >> iter 56000, loss: 0.312207
 >> iter 57000, loss: 0.393120
 >> iter 58000, loss: 0.214363
 >> iter 59000, loss: 0.248672
 >> iter 60000, loss: 0.213939
   Number of active neurons: 4
 >> iter 61000, loss: 0.178024
 >> iter 62000, loss: 0.166559
 >> iter 63000, loss: 0.226464
 >> iter 64000, loss: 0.310982
 >> iter 65000, loss: 0.416128
 >> iter 66000, loss: 0.344486
 >> iter 67000, loss: 0.289904
 >> iter 68000, loss: 0.307359
 >> iter 69000, loss: 0.371924
 >> iter 70000, loss: 0.355243
   Number of active neurons: 4
 >> iter 71000, loss: 0.242397
 >> iter 72000, loss: 0.414772
 >> iter 73000, loss: 0.467652
 >> iter 74000, loss: 0.291686
 >> iter 75000, loss: 0.326404
 >> iter 76000, loss: 0.319655
 >> iter 77000, loss: 0.272449
 >> iter 78000, loss: 0.249794
 >> iter 79000, loss: 0.342870
 >> iter 80000, loss: 0.407402
   Number of active neurons: 4
 >> iter 81000, loss: 0.476717
 >> iter 82000, loss: 0.283175
 >> iter 83000, loss: 0.250133
 >> iter 84000, loss: 0.495151
 >> iter 85000, loss: 0.269236
 >> iter 86000, loss: 0.254006
 >> iter 87000, loss: 0.345371
 >> iter 88000, loss: 0.292877
 >> iter 89000, loss: 0.316866
 >> iter 90000, loss: 0.342001
   Number of active neurons: 4
 >> iter 91000, loss: 0.315501
 >> iter 92000, loss: 0.353633
 >> iter 93000, loss: 0.374973
 >> iter 94000, loss: 0.379716
 >> iter 95000, loss: 0.260862
 >> iter 96000, loss: 0.272480
 >> iter 97000, loss: 0.237188
 >> iter 98000, loss: 0.330146
 >> iter 99000, loss: 0.492641
 >> iter 100000, loss: 0.425498
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.561524
 >> iter 2000, loss: 14.761867
 >> iter 3000, loss: 11.984657
 >> iter 4000, loss: 10.701411
 >> iter 5000, loss: 10.431189
 >> iter 6000, loss: 10.025091
 >> iter 7000, loss: 9.896626
 >> iter 8000, loss: 9.625513
 >> iter 9000, loss: 8.245900
 >> iter 10000, loss: 5.186496
   Number of active neurons: 4
 >> iter 11000, loss: 3.892601
 >> iter 12000, loss: 2.971916
 >> iter 13000, loss: 2.052785
 >> iter 14000, loss: 1.590689
 >> iter 15000, loss: 1.010950
 >> iter 16000, loss: 0.860575
 >> iter 17000, loss: 0.787844
 >> iter 18000, loss: 0.734588
 >> iter 19000, loss: 0.521223
 >> iter 20000, loss: 0.537006
   Number of active neurons: 4
 >> iter 21000, loss: 0.505285
 >> iter 22000, loss: 0.363371
 >> iter 23000, loss: 0.627773
 >> iter 24000, loss: 0.523722
 >> iter 25000, loss: 0.448521
 >> iter 26000, loss: 0.337239
 >> iter 27000, loss: 0.505515
 >> iter 28000, loss: 0.614343
 >> iter 29000, loss: 0.635903
 >> iter 30000, loss: 0.574402
   Number of active neurons: 4
 >> iter 31000, loss: 0.566312
 >> iter 32000, loss: 0.599850
 >> iter 33000, loss: 0.515542
 >> iter 34000, loss: 0.370022
 >> iter 35000, loss: 0.309944
 >> iter 36000, loss: 0.433102
 >> iter 37000, loss: 0.477244
 >> iter 38000, loss: 0.505996
 >> iter 39000, loss: 0.430948
 >> iter 40000, loss: 0.385033
   Number of active neurons: 4
 >> iter 41000, loss: 0.281139
 >> iter 42000, loss: 0.437112
 >> iter 43000, loss: 0.320315
 >> iter 44000, loss: 0.402724
 >> iter 45000, loss: 0.357269
 >> iter 46000, loss: 0.444249
 >> iter 47000, loss: 0.372267
 >> iter 48000, loss: 0.513982
 >> iter 49000, loss: 0.462330
 >> iter 50000, loss: 0.553598
   Number of active neurons: 4
 >> iter 51000, loss: 0.559913
 >> iter 52000, loss: 0.703953
 >> iter 53000, loss: 0.481874
 >> iter 54000, loss: 0.407969
 >> iter 55000, loss: 0.427326
 >> iter 56000, loss: 0.483322
 >> iter 57000, loss: 0.360166
 >> iter 58000, loss: 0.255000
 >> iter 59000, loss: 0.327809
 >> iter 60000, loss: 0.697040
   Number of active neurons: 4
 >> iter 61000, loss: 0.555635
 >> iter 62000, loss: 0.497939
 >> iter 63000, loss: 0.442949
 >> iter 64000, loss: 0.439984
 >> iter 65000, loss: 0.422826
 >> iter 66000, loss: 0.442824
 >> iter 67000, loss: 0.352807
 >> iter 68000, loss: 0.374161
 >> iter 69000, loss: 0.331461
 >> iter 70000, loss: 0.373281
   Number of active neurons: 4
 >> iter 71000, loss: 0.586719
 >> iter 72000, loss: 0.498407
 >> iter 73000, loss: 0.333800
 >> iter 74000, loss: 0.384987
 >> iter 75000, loss: 0.503446
 >> iter 76000, loss: 0.518487
 >> iter 77000, loss: 0.626327
 >> iter 78000, loss: 0.398524
 >> iter 79000, loss: 0.429210
 >> iter 80000, loss: 0.325913
   Number of active neurons: 4
 >> iter 81000, loss: 0.320887
 >> iter 82000, loss: 0.369897
 >> iter 83000, loss: 0.329707
 >> iter 84000, loss: 0.319827
 >> iter 85000, loss: 0.292765
 >> iter 86000, loss: 0.405416
 >> iter 87000, loss: 0.389246
 >> iter 88000, loss: 0.405889
 >> iter 89000, loss: 0.439181
 >> iter 90000, loss: 0.344461
   Number of active neurons: 4
 >> iter 91000, loss: 0.587743
 >> iter 92000, loss: 0.384968
 >> iter 93000, loss: 0.193949
 >> iter 94000, loss: 0.337340
 >> iter 95000, loss: 0.361257
 >> iter 96000, loss: 0.352961
 >> iter 97000, loss: 0.377383
 >> iter 98000, loss: 0.324988
 >> iter 99000, loss: 0.390560
 >> iter 100000, loss: 0.287023
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.220758
 >> iter 2000, loss: 15.293980
 >> iter 3000, loss: 14.039798
 >> iter 4000, loss: 13.641159
 >> iter 5000, loss: 13.978891
 >> iter 6000, loss: 13.902140
 >> iter 7000, loss: 14.030746
 >> iter 8000, loss: 13.627350
 >> iter 9000, loss: 11.871395
 >> iter 10000, loss: 10.605476
   Number of active neurons: 3
 >> iter 11000, loss: 9.835521
 >> iter 12000, loss: 9.099476
 >> iter 13000, loss: 9.008950
 >> iter 14000, loss: 8.679418
 >> iter 15000, loss: 8.742473
 >> iter 16000, loss: 8.480589
 >> iter 17000, loss: 8.596875
 >> iter 18000, loss: 8.425870
 >> iter 19000, loss: 8.593711
 >> iter 20000, loss: 8.353287
   Number of active neurons: 3
 >> iter 21000, loss: 8.581957
 >> iter 22000, loss: 8.401789
 >> iter 23000, loss: 8.599252
 >> iter 24000, loss: 8.397414
 >> iter 25000, loss: 8.531236
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 7.773264
 >> iter 27000, loss: 6.282907
 >> iter 28000, loss: 4.383263
 >> iter 29000, loss: 3.276931
 >> iter 30000, loss: 2.677063
   Number of active neurons: 4
 >> iter 31000, loss: 2.483817
 >> iter 32000, loss: 2.223811
 >> iter 33000, loss: 2.247160
 >> iter 34000, loss: 2.112820
 >> iter 35000, loss: 2.161191
 >> iter 36000, loss: 2.187045
 >> iter 37000, loss: 2.137361
 >> iter 38000, loss: 2.221710
 >> iter 39000, loss: 2.340965
 >> iter 40000, loss: 2.223768
   Number of active neurons: 4
 >> iter 41000, loss: 2.189345
 >> iter 42000, loss: 2.273810
 >> iter 43000, loss: 2.202429
 >> iter 44000, loss: 2.301900
 >> iter 45000, loss: 2.320887
 >> iter 46000, loss: 2.206716
 >> iter 47000, loss: 2.223013
 >> iter 48000, loss: 2.189794
 >> iter 49000, loss: 2.113941
 >> iter 50000, loss: 2.286565
   Number of active neurons: 4
 >> iter 51000, loss: 2.334830
 >> iter 52000, loss: 2.433911
 >> iter 53000, loss: 2.321404
 >> iter 54000, loss: 2.349671
 >> iter 55000, loss: 2.270133
 >> iter 56000, loss: 2.354415
 >> iter 57000, loss: 2.245963
 >> iter 58000, loss: 2.241207
 >> iter 59000, loss: 2.366018
 >> iter 60000, loss: 2.400932
   Number of active neurons: 4
 >> iter 61000, loss: 2.402235
 >> iter 62000, loss: 2.243266
 >> iter 63000, loss: 2.092536
 >> iter 64000, loss: 2.096553
 >> iter 65000, loss: 2.070734
 >> iter 66000, loss: 2.150595
 >> iter 67000, loss: 1.990710
 >> iter 68000, loss: 2.200581
 >> iter 69000, loss: 1.976764
 >> iter 70000, loss: 2.135490
   Number of active neurons: 4
 >> iter 71000, loss: 1.992169
 >> iter 72000, loss: 1.968986
 >> iter 73000, loss: 1.840313
 >> iter 74000, loss: 1.914646
 >> iter 75000, loss: 2.024860
 >> iter 76000, loss: 1.925709
 >> iter 77000, loss: 1.953002
 >> iter 78000, loss: 2.092135
 >> iter 79000, loss: 2.087333
 >> iter 80000, loss: 1.899028
   Number of active neurons: 4
 >> iter 81000, loss: 1.833341
 >> iter 82000, loss: 1.918130
 >> iter 83000, loss: 1.963069
 >> iter 84000, loss: 1.951546
 >> iter 85000, loss: 2.029928
 >> iter 86000, loss: 2.079988
 >> iter 87000, loss: 2.094226
 >> iter 88000, loss: 1.973456
 >> iter 89000, loss: 1.898302
 >> iter 90000, loss: 2.017125
   Number of active neurons: 4
 >> iter 91000, loss: 1.919640
 >> iter 92000, loss: 1.843055
 >> iter 93000, loss: 1.882765
 >> iter 94000, loss: 1.956377
 >> iter 95000, loss: 1.835100
 >> iter 96000, loss: 1.868291
 >> iter 97000, loss: 1.795584
 >> iter 98000, loss: 1.748957
 >> iter 99000, loss: 1.787794
 >> iter 100000, loss: 1.911729
   Number of active neurons: 4
 >> iter 101000, loss: 1.965273
 >> iter 102000, loss: 1.937383
 >> iter 103000, loss: 1.933748
 >> iter 104000, loss: 2.041283
 >> iter 105000, loss: 1.846943
 >> iter 106000, loss: 1.801385
 >> iter 107000, loss: 1.919229
 >> iter 108000, loss: 1.940777
 >> iter 109000, loss: 1.783380
 >> iter 110000, loss: 1.829374
   Number of active neurons: 4
 >> iter 111000, loss: 1.883677
 >> iter 112000, loss: 1.989790
 >> iter 113000, loss: 1.994425
 >> iter 114000, loss: 1.863114
 >> iter 115000, loss: 1.956307
 >> iter 116000, loss: 2.014624
 >> iter 117000, loss: 2.053529
 >> iter 118000, loss: 2.056643
 >> iter 119000, loss: 1.968246
 >> iter 120000, loss: 1.894749
   Number of active neurons: 4
 >> iter 121000, loss: 1.725851
 >> iter 122000, loss: 1.905165
 >> iter 123000, loss: 1.826205
 >> iter 124000, loss: 1.827245
 >> iter 125000, loss: 1.898937
 >> iter 126000, loss: 2.002121
 >> iter 127000, loss: 1.850638
 >> iter 128000, loss: 1.931708
 >> iter 129000, loss: 1.949119
 >> iter 130000, loss: 1.885380
   Number of active neurons: 4
 >> iter 131000, loss: 2.001510
 >> iter 132000, loss: 1.961890
 >> iter 133000, loss: 1.739116
 >> iter 134000, loss: 1.939548
 >> iter 135000, loss: 1.949442
 >> iter 136000, loss: 1.920751
 >> iter 137000, loss: 2.058689
 >> iter 138000, loss: 1.947779
 >> iter 139000, loss: 1.862335
 >> iter 140000, loss: 1.913784
   Number of active neurons: 4
 >> iter 141000, loss: 2.078614
 >> iter 142000, loss: 1.947165
 >> iter 143000, loss: 1.841555
 >> iter 144000, loss: 1.888064
 >> iter 145000, loss: 1.896818
 >> iter 146000, loss: 1.969680
 >> iter 147000, loss: 1.926350
 >> iter 148000, loss: 1.934877
 >> iter 149000, loss: 1.808780
 >> iter 150000, loss: 1.884388
   Number of active neurons: 4
 >> iter 151000, loss: 1.867994
 >> iter 152000, loss: 1.883375
 >> iter 153000, loss: 1.842795
 >> iter 154000, loss: 1.933499
 >> iter 155000, loss: 1.827732
 >> iter 156000, loss: 1.996594
 >> iter 157000, loss: 1.944249
 >> iter 158000, loss: 1.745274
 >> iter 159000, loss: 1.724282
 >> iter 160000, loss: 1.977620
   Number of active neurons: 4
 >> iter 161000, loss: 1.760451
 >> iter 162000, loss: 1.796688
 >> iter 163000, loss: 1.934816
 >> iter 164000, loss: 1.880551
 >> iter 165000, loss: 1.964588
 >> iter 166000, loss: 2.149482
 >> iter 167000, loss: 1.985275
 >> iter 168000, loss: 1.979466
 >> iter 169000, loss: 1.957436
 >> iter 170000, loss: 1.985586
   Number of active neurons: 4
 >> iter 171000, loss: 1.821737
 >> iter 172000, loss: 2.035447
 >> iter 173000, loss: 1.917744
 >> iter 174000, loss: 1.953574
 >> iter 175000, loss: 1.915071
 >> iter 176000, loss: 1.875259
 >> iter 177000, loss: 1.820303
 >> iter 178000, loss: 1.814754
 >> iter 179000, loss: 1.799852
 >> iter 180000, loss: 1.993025
   Number of active neurons: 4
 >> iter 181000, loss: 1.939253
 >> iter 182000, loss: 1.950492
 >> iter 183000, loss: 2.004599
 >> iter 184000, loss: 1.997861
 >> iter 185000, loss: 1.804138
 >> iter 186000, loss: 2.104018
 >> iter 187000, loss: 1.952674
 >> iter 188000, loss: 2.023170
 >> iter 189000, loss: 2.080522
 >> iter 190000, loss: 2.109281
   Number of active neurons: 4
 >> iter 191000, loss: 1.938924
 >> iter 192000, loss: 2.028985
 >> iter 193000, loss: 1.973337
 >> iter 194000, loss: 2.080873
 >> iter 195000, loss: 1.913378
 >> iter 196000, loss: 1.985189
 >> iter 197000, loss: 2.030977
 >> iter 198000, loss: 2.200323
 >> iter 199000, loss: 1.989456
 >> iter 200000, loss: 2.115552
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 2.0039599208
   - Test - Long: 0.574971251437
   - Test - Big: 2.15597844022
   - Test - A: 0.0
   - Test - B: 14.8456769549
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.295737
 >> iter 2000, loss: 13.724926
 >> iter 3000, loss: 10.590686
 >> iter 4000, loss: 8.988469
 >> iter 5000, loss: 8.557651
 >> iter 6000, loss: 8.095021
 >> iter 7000, loss: 8.096645
 >> iter 8000, loss: 7.620819
 >> iter 9000, loss: 4.915646
 >> iter 10000, loss: 3.167586
   Number of active neurons: 4
 >> iter 11000, loss: 2.661375
 >> iter 12000, loss: 2.519993
 >> iter 13000, loss: 2.589398
 >> iter 14000, loss: 2.369575
 >> iter 15000, loss: 2.295206
 >> iter 16000, loss: 2.210852
 >> iter 17000, loss: 2.524227
 >> iter 18000, loss: 2.466836
 >> iter 19000, loss: 2.415788
 >> iter 20000, loss: 2.493595
   Number of active neurons: 4
 >> iter 21000, loss: 2.190504
 >> iter 22000, loss: 2.229471
 >> iter 23000, loss: 2.370813
 >> iter 24000, loss: 2.248371
 >> iter 25000, loss: 2.288925
 >> iter 26000, loss: 2.118693
 >> iter 27000, loss: 1.994578
 >> iter 28000, loss: 2.115280
 >> iter 29000, loss: 2.106583
 >> iter 30000, loss: 2.084079
   Number of active neurons: 4
 >> iter 31000, loss: 2.120735
 >> iter 32000, loss: 2.255420
 >> iter 33000, loss: 2.440633
 >> iter 34000, loss: 2.305232
 >> iter 35000, loss: 2.071699
 >> iter 36000, loss: 2.057741
 >> iter 37000, loss: 2.285543
 >> iter 38000, loss: 1.912493
 >> iter 39000, loss: 1.833338
 >> iter 40000, loss: 1.031335
   Number of active neurons: 4
 >> iter 41000, loss: 1.003363
 >> iter 42000, loss: 0.699922
 >> iter 43000, loss: 0.505393
 >> iter 44000, loss: 0.462558
 >> iter 45000, loss: 0.506588
 >> iter 46000, loss: 0.665090
 >> iter 47000, loss: 0.532551
 >> iter 48000, loss: 0.611414
 >> iter 49000, loss: 0.552660
 >> iter 50000, loss: 0.586118
   Number of active neurons: 4
 >> iter 51000, loss: 0.779683
 >> iter 52000, loss: 0.594180
 >> iter 53000, loss: 0.432285
 >> iter 54000, loss: 0.441675
 >> iter 55000, loss: 0.519459
 >> iter 56000, loss: 0.498569
 >> iter 57000, loss: 0.577483
 >> iter 58000, loss: 0.541572
 >> iter 59000, loss: 0.597616
 >> iter 60000, loss: 0.694778
   Number of active neurons: 4
 >> iter 61000, loss: 0.567668
 >> iter 62000, loss: 0.538457
 >> iter 63000, loss: 0.629475
 >> iter 64000, loss: 0.451661
 >> iter 65000, loss: 0.514905
 >> iter 66000, loss: 0.717057
 >> iter 67000, loss: 0.558242
 >> iter 68000, loss: 0.454618
 >> iter 69000, loss: 0.396125
 >> iter 70000, loss: 0.528023
   Number of active neurons: 4
 >> iter 71000, loss: 0.451293
 >> iter 72000, loss: 0.525515
 >> iter 73000, loss: 0.671212
 >> iter 74000, loss: 0.563982
 >> iter 75000, loss: 0.555455
 >> iter 76000, loss: 0.416540
 >> iter 77000, loss: 0.619976
 >> iter 78000, loss: 0.387642
 >> iter 79000, loss: 0.503717
 >> iter 80000, loss: 0.500866
   Number of active neurons: 4
 >> iter 81000, loss: 0.373316
 >> iter 82000, loss: 0.547145
 >> iter 83000, loss: 0.617622
 >> iter 84000, loss: 0.540551
 >> iter 85000, loss: 0.645838
 >> iter 86000, loss: 0.873713
 >> iter 87000, loss: 0.799213
 >> iter 88000, loss: 0.590859
 >> iter 89000, loss: 0.672200
 >> iter 90000, loss: 0.428259
   Number of active neurons: 4
 >> iter 91000, loss: 0.536384
 >> iter 92000, loss: 0.591820
 >> iter 93000, loss: 0.565721
 >> iter 94000, loss: 0.518661
 >> iter 95000, loss: 0.556874
 >> iter 96000, loss: 0.481223
 >> iter 97000, loss: 0.570220
 >> iter 98000, loss: 0.439865
 >> iter 99000, loss: 0.548470
 >> iter 100000, loss: 0.648040
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.167818
 >> iter 2000, loss: 13.781663
 >> iter 3000, loss: 10.688333
 >> iter 4000, loss: 8.712184
 >> iter 5000, loss: 6.719409
 >> iter 6000, loss: 5.494070
 >> iter 7000, loss: 5.218947
 >> iter 8000, loss: 4.694173
 >> iter 9000, loss: 4.299906
 >> iter 10000, loss: 3.555225
   Number of active neurons: 3
 >> iter 11000, loss: 3.026964
 >> iter 12000, loss: 2.786964
 >> iter 13000, loss: 2.533268
 >> iter 14000, loss: 2.583123
 >> iter 15000, loss: 2.427873
 >> iter 16000, loss: 2.415986
 >> iter 17000, loss: 2.415968
 >> iter 18000, loss: 2.404313
 >> iter 19000, loss: 2.310679
 >> iter 20000, loss: 2.216121
   Number of active neurons: 3
 >> iter 21000, loss: 2.315125
 >> iter 22000, loss: 2.396086
 >> iter 23000, loss: 2.405751
 >> iter 24000, loss: 2.396333
 >> iter 25000, loss: 2.386526
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 26000, loss: 2.492561
 >> iter 27000, loss: 2.423142
 >> iter 28000, loss: 2.260984
 >> iter 29000, loss: 2.175911
 >> iter 30000, loss: 2.004921
   Number of active neurons: 4
 >> iter 31000, loss: 2.341263
 >> iter 32000, loss: 2.217818
 >> iter 33000, loss: 2.446578
 >> iter 34000, loss: 2.099367
 >> iter 35000, loss: 2.379866
 >> iter 36000, loss: 2.067244
 >> iter 37000, loss: 1.996963
 >> iter 38000, loss: 1.899998
 >> iter 39000, loss: 1.937115
 >> iter 40000, loss: 1.904019
   Number of active neurons: 4
 >> iter 41000, loss: 1.863037
 >> iter 42000, loss: 2.065685
 >> iter 43000, loss: 2.044601
 >> iter 44000, loss: 1.965890
 >> iter 45000, loss: 1.958595
 >> iter 46000, loss: 2.055995
 >> iter 47000, loss: 2.001311
 >> iter 48000, loss: 2.006563
 >> iter 49000, loss: 2.050341
 >> iter 50000, loss: 2.067651
   Number of active neurons: 4
 >> iter 51000, loss: 1.985521
 >> iter 52000, loss: 2.112265
 >> iter 53000, loss: 1.916928
 >> iter 54000, loss: 2.006835
 >> iter 55000, loss: 1.985675
 >> iter 56000, loss: 2.007724
 >> iter 57000, loss: 2.165494
 >> iter 58000, loss: 2.014754
 >> iter 59000, loss: 1.928979
 >> iter 60000, loss: 2.119781
   Number of active neurons: 4
 >> iter 61000, loss: 1.926630
 >> iter 62000, loss: 2.073831
 >> iter 63000, loss: 1.947664
 >> iter 64000, loss: 2.154477
 >> iter 65000, loss: 2.022294
 >> iter 66000, loss: 1.873331
 >> iter 67000, loss: 2.087567
 >> iter 68000, loss: 2.149936
 >> iter 69000, loss: 2.087214
 >> iter 70000, loss: 2.137878
   Number of active neurons: 4
 >> iter 71000, loss: 2.045148
 >> iter 72000, loss: 2.183204
 >> iter 73000, loss: 2.384075
 >> iter 74000, loss: 2.244468
 >> iter 75000, loss: 1.985725
 >> iter 76000, loss: 1.995554
 >> iter 77000, loss: 1.993906
 >> iter 78000, loss: 2.013722
 >> iter 79000, loss: 1.994949
 >> iter 80000, loss: 2.395374
   Number of active neurons: 4
 >> iter 81000, loss: 2.081307
 >> iter 82000, loss: 2.101054
 >> iter 83000, loss: 2.178496
 >> iter 84000, loss: 2.030682
 >> iter 85000, loss: 1.992171
 >> iter 86000, loss: 2.181366
 >> iter 87000, loss: 2.121660
 >> iter 88000, loss: 1.992701
 >> iter 89000, loss: 1.989454
 >> iter 90000, loss: 1.860230
   Number of active neurons: 4
 >> iter 91000, loss: 1.849676
 >> iter 92000, loss: 1.887338
 >> iter 93000, loss: 1.842155
 >> iter 94000, loss: 1.929875
 >> iter 95000, loss: 1.987869
 >> iter 96000, loss: 1.878216
 >> iter 97000, loss: 1.990549
 >> iter 98000, loss: 1.983741
 >> iter 99000, loss: 1.982589
 >> iter 100000, loss: 2.043891
   Number of active neurons: 4
 >> iter 101000, loss: 2.137929
 >> iter 102000, loss: 2.281402
 >> iter 103000, loss: 2.119460
 >> iter 104000, loss: 2.077873
 >> iter 105000, loss: 1.944559
 >> iter 106000, loss: 1.869706
 >> iter 107000, loss: 2.007403
 >> iter 108000, loss: 2.206104
 >> iter 109000, loss: 2.226626
 >> iter 110000, loss: 2.076720
   Number of active neurons: 4
 >> iter 111000, loss: 1.884011
 >> iter 112000, loss: 2.146853
 >> iter 113000, loss: 2.425976
 >> iter 114000, loss: 2.325136
 >> iter 115000, loss: 2.041934
 >> iter 116000, loss: 2.138890
 >> iter 117000, loss: 1.972736
 >> iter 118000, loss: 2.251447
 >> iter 119000, loss: 2.130065
 >> iter 120000, loss: 1.974410
   Number of active neurons: 4
 >> iter 121000, loss: 2.073177
 >> iter 122000, loss: 2.412160
 >> iter 123000, loss: 2.063472
 >> iter 124000, loss: 1.947316
 >> iter 125000, loss: 2.093045
 >> iter 126000, loss: 1.992002
 >> iter 127000, loss: 2.069891
 >> iter 128000, loss: 1.969388
 >> iter 129000, loss: 1.986483
 >> iter 130000, loss: 2.109786
   Number of active neurons: 4
 >> iter 131000, loss: 1.904476
 >> iter 132000, loss: 2.155104
 >> iter 133000, loss: 2.044475
 >> iter 134000, loss: 2.166317
 >> iter 135000, loss: 2.061353
 >> iter 136000, loss: 2.262973
 >> iter 137000, loss: 2.058362
 >> iter 138000, loss: 2.085129
 >> iter 139000, loss: 2.025969
 >> iter 140000, loss: 2.024538
   Number of active neurons: 4
 >> iter 141000, loss: 2.002434
 >> iter 142000, loss: 2.055517
 >> iter 143000, loss: 1.991859
 >> iter 144000, loss: 2.118620
 >> iter 145000, loss: 2.117939
 >> iter 146000, loss: 2.330772
 >> iter 147000, loss: 2.069674
 >> iter 148000, loss: 2.127377
 >> iter 149000, loss: 1.891453
 >> iter 150000, loss: 2.133669
   Number of active neurons: 4
 >> iter 151000, loss: 1.956864
 >> iter 152000, loss: 2.158744
 >> iter 153000, loss: 1.866687
 >> iter 154000, loss: 2.091977
 >> iter 155000, loss: 2.138012
 >> iter 156000, loss: 2.310494
 >> iter 157000, loss: 2.195994
 >> iter 158000, loss: 2.234021
 >> iter 159000, loss: 1.979650
 >> iter 160000, loss: 1.940316
   Number of active neurons: 4
 >> iter 161000, loss: 1.926322
 >> iter 162000, loss: 2.131789
 >> iter 163000, loss: 2.192782
 >> iter 164000, loss: 2.141323
 >> iter 165000, loss: 2.099802
 >> iter 166000, loss: 1.966066
 >> iter 167000, loss: 1.817896
 >> iter 168000, loss: 2.070389
 >> iter 169000, loss: 2.068237
 >> iter 170000, loss: 2.118183
   Number of active neurons: 4
 >> iter 171000, loss: 1.986208
 >> iter 172000, loss: 1.951073
 >> iter 173000, loss: 1.844249
 >> iter 174000, loss: 2.377010
 >> iter 175000, loss: 2.136453
 >> iter 176000, loss: 2.143747
 >> iter 177000, loss: 2.013989
 >> iter 178000, loss: 2.000892
 >> iter 179000, loss: 1.930570
 >> iter 180000, loss: 2.304886
   Number of active neurons: 4
 >> iter 181000, loss: 2.404186
 >> iter 182000, loss: 2.290819
 >> iter 183000, loss: 2.172302
 >> iter 184000, loss: 2.140307
 >> iter 185000, loss: 1.990871
 >> iter 186000, loss: 1.972946
 >> iter 187000, loss: 1.950937
 >> iter 188000, loss: 2.196623
 >> iter 189000, loss: 1.928243
 >> iter 190000, loss: 1.954319
   Number of active neurons: 4
 >> iter 191000, loss: 2.115965
 >> iter 192000, loss: 2.273497
 >> iter 193000, loss: 2.210026
 >> iter 194000, loss: 2.271288
 >> iter 195000, loss: 2.156469
 >> iter 196000, loss: 2.147912
 >> iter 197000, loss: 1.902965
 >> iter 198000, loss: 2.043355
 >> iter 199000, loss: 1.909805
 >> iter 200000, loss: 2.126631
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 2.98394032119
   - Test - Long: 0.929953502325
   - Test - Big: 3.21696783032
   - Test - A: 0.0
   - Test - B: 50.583294447
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.178984
 >> iter 2000, loss: 12.527644
 >> iter 3000, loss: 6.569375
 >> iter 4000, loss: 3.251243
 >> iter 5000, loss: 1.883105
 >> iter 6000, loss: 1.266637
 >> iter 7000, loss: 0.918879
 >> iter 8000, loss: 0.775446
 >> iter 9000, loss: 0.692072
 >> iter 10000, loss: 0.674421
   Number of active neurons: 4
 >> iter 11000, loss: 0.543678
 >> iter 12000, loss: 0.546233
 >> iter 13000, loss: 0.476319
 >> iter 14000, loss: 0.369774
 >> iter 15000, loss: 0.324635
 >> iter 16000, loss: 0.367767
 >> iter 17000, loss: 0.308122
 >> iter 18000, loss: 0.292413
 >> iter 19000, loss: 0.438821
 >> iter 20000, loss: 0.395858
   Number of active neurons: 4
 >> iter 21000, loss: 0.499459
 >> iter 22000, loss: 0.411470
 >> iter 23000, loss: 0.435474
 >> iter 24000, loss: 0.294745
 >> iter 25000, loss: 0.362622
 >> iter 26000, loss: 0.379606
 >> iter 27000, loss: 0.301486
 >> iter 28000, loss: 0.403145
 >> iter 29000, loss: 0.468296
 >> iter 30000, loss: 0.445043
   Number of active neurons: 4
 >> iter 31000, loss: 0.400414
 >> iter 32000, loss: 0.286675
 >> iter 33000, loss: 0.434432
 >> iter 34000, loss: 0.368320
 >> iter 35000, loss: 0.497384
 >> iter 36000, loss: 0.326857
 >> iter 37000, loss: 0.281217
 >> iter 38000, loss: 0.318326
 >> iter 39000, loss: 0.513947
 >> iter 40000, loss: 0.354047
   Number of active neurons: 4
 >> iter 41000, loss: 0.595878
 >> iter 42000, loss: 0.502973
 >> iter 43000, loss: 0.482190
 >> iter 44000, loss: 0.303297
 >> iter 45000, loss: 0.347159
 >> iter 46000, loss: 0.352679
 >> iter 47000, loss: 0.313028
 >> iter 48000, loss: 0.340408
 >> iter 49000, loss: 0.348062
 >> iter 50000, loss: 0.319153
   Number of active neurons: 4
 >> iter 51000, loss: 0.415007
 >> iter 52000, loss: 0.519276
 >> iter 53000, loss: 0.317441
 >> iter 54000, loss: 0.471326
 >> iter 55000, loss: 0.443099
 >> iter 56000, loss: 0.443706
 >> iter 57000, loss: 0.314788
 >> iter 58000, loss: 0.287554
 >> iter 59000, loss: 0.422884
 >> iter 60000, loss: 0.496254
   Number of active neurons: 4
 >> iter 61000, loss: 0.431102
 >> iter 62000, loss: 0.360172
 >> iter 63000, loss: 0.424869
 >> iter 64000, loss: 0.449274
 >> iter 65000, loss: 0.401068
 >> iter 66000, loss: 0.429229
 >> iter 67000, loss: 0.368534
 >> iter 68000, loss: 0.357676
 >> iter 69000, loss: 0.325373
 >> iter 70000, loss: 0.231224
   Number of active neurons: 4
 >> iter 71000, loss: 0.427269
 >> iter 72000, loss: 0.290063
 >> iter 73000, loss: 0.319206
 >> iter 74000, loss: 0.193430
 >> iter 75000, loss: 0.401889
 >> iter 76000, loss: 0.256599
 >> iter 77000, loss: 0.407746
 >> iter 78000, loss: 0.448923
 >> iter 79000, loss: 0.247445
 >> iter 80000, loss: 0.264998
   Number of active neurons: 4
 >> iter 81000, loss: 0.540231
 >> iter 82000, loss: 0.424230
 >> iter 83000, loss: 0.324532
 >> iter 84000, loss: 0.222027
 >> iter 85000, loss: 0.425100
 >> iter 86000, loss: 0.293569
 >> iter 87000, loss: 0.309668
 >> iter 88000, loss: 0.382288
 >> iter 89000, loss: 0.376800
 >> iter 90000, loss: 0.345883
   Number of active neurons: 4
 >> iter 91000, loss: 0.332698
 >> iter 92000, loss: 0.320169
 >> iter 93000, loss: 0.286536
 >> iter 94000, loss: 0.237380
 >> iter 95000, loss: 0.201233
 >> iter 96000, loss: 0.299910
 >> iter 97000, loss: 0.398720
 >> iter 98000, loss: 0.266585
 >> iter 99000, loss: 0.196424
 >> iter 100000, loss: 0.192211
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.275291
 >> iter 2000, loss: 13.269357
 >> iter 3000, loss: 9.475908
 >> iter 4000, loss: 7.378079
 >> iter 5000, loss: 6.730314
 >> iter 6000, loss: 6.139568
 >> iter 7000, loss: 6.136577
 >> iter 8000, loss: 5.733675
 >> iter 9000, loss: 5.981604
 >> iter 10000, loss: 5.667559
   Number of active neurons: 3
 >> iter 11000, loss: 5.807825
 >> iter 12000, loss: 5.576175
 >> iter 13000, loss: 5.768812
 >> iter 14000, loss: 5.449838
 >> iter 15000, loss: 5.781927
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 5.026715
 >> iter 17000, loss: 4.590474
 >> iter 18000, loss: 3.813315
 >> iter 19000, loss: 3.810781
 >> iter 20000, loss: 3.488950
   Number of active neurons: 4
 >> iter 21000, loss: 3.659915
 >> iter 22000, loss: 3.380137
 >> iter 23000, loss: 3.540003
 >> iter 24000, loss: 3.440255
 >> iter 25000, loss: 3.594498
 >> iter 26000, loss: 3.377276
 >> iter 27000, loss: 3.563272
 >> iter 28000, loss: 3.448965
 >> iter 29000, loss: 3.581283
 >> iter 30000, loss: 3.388881
   Number of active neurons: 4
 >> iter 31000, loss: 3.567857
 >> iter 32000, loss: 3.447730
 >> iter 33000, loss: 3.600738
 >> iter 34000, loss: 3.401020
 >> iter 35000, loss: 3.570506
 >> iter 36000, loss: 3.436390
 >> iter 37000, loss: 3.573838
 >> iter 38000, loss: 3.413695
 >> iter 39000, loss: 3.546519
 >> iter 40000, loss: 3.423918
   Number of active neurons: 4
 >> iter 41000, loss: 3.687607
 >> iter 42000, loss: 3.498696
 >> iter 43000, loss: 3.668165
 >> iter 44000, loss: 3.456725
 >> iter 45000, loss: 3.553338
 >> iter 46000, loss: 3.477836
 >> iter 47000, loss: 3.653346
 >> iter 48000, loss: 3.454486
 >> iter 49000, loss: 3.551714
 >> iter 50000, loss: 3.465055
   Number of active neurons: 4
 >> iter 51000, loss: 3.533355
 >> iter 52000, loss: 3.496695
 >> iter 53000, loss: 3.649282
 >> iter 54000, loss: 3.475018
 >> iter 55000, loss: 3.539682
 >> iter 56000, loss: 3.440219
 >> iter 57000, loss: 3.550405
 >> iter 58000, loss: 3.505992
 >> iter 59000, loss: 3.595341
 >> iter 60000, loss: 3.639365
   Number of active neurons: 4
 >> iter 61000, loss: 3.574031
 >> iter 62000, loss: 3.516941
 >> iter 63000, loss: 3.616327
 >> iter 64000, loss: 3.466938
 >> iter 65000, loss: 3.627021
 >> iter 66000, loss: 3.562832
 >> iter 67000, loss: 3.617211
 >> iter 68000, loss: 3.466031
 >> iter 69000, loss: 3.613622
 >> iter 70000, loss: 3.527057
   Number of active neurons: 4
 >> iter 71000, loss: 3.601326
 >> iter 72000, loss: 3.596585
 >> iter 73000, loss: 3.660566
 >> iter 74000, loss: 3.542494
 >> iter 75000, loss: 3.600158
 >> iter 76000, loss: 3.495418
 >> iter 77000, loss: 3.634919
 >> iter 78000, loss: 3.493535
 >> iter 79000, loss: 3.612164
 >> iter 80000, loss: 3.515932
   Number of active neurons: 4
 >> iter 81000, loss: 3.589026
 >> iter 82000, loss: 3.513318
 >> iter 83000, loss: 3.630876
 >> iter 84000, loss: 3.615469
 >> iter 85000, loss: 3.617803
 >> iter 86000, loss: 3.536804
 >> iter 87000, loss: 3.603449
 >> iter 88000, loss: 3.503420
 >> iter 89000, loss: 3.617589
 >> iter 90000, loss: 3.559643
   Number of active neurons: 4
 >> iter 91000, loss: 3.632313
 >> iter 92000, loss: 3.545619
 >> iter 93000, loss: 3.584645
 >> iter 94000, loss: 3.447014
 >> iter 95000, loss: 3.511004
 >> iter 96000, loss: 3.518773
 >> iter 97000, loss: 3.566657
 >> iter 98000, loss: 3.609693
 >> iter 99000, loss: 3.609165
 >> iter 100000, loss: 3.494100
   Number of active neurons: 4
 >> iter 101000, loss: 3.606406
 >> iter 102000, loss: 3.549137
 >> iter 103000, loss: 3.538899
 >> iter 104000, loss: 3.535513
 >> iter 105000, loss: 3.607060
 >> iter 106000, loss: 3.503086
 >> iter 107000, loss: 3.581132
 >> iter 108000, loss: 3.472017
 >> iter 109000, loss: 3.637840
 >> iter 110000, loss: 3.516598
   Number of active neurons: 4
 >> iter 111000, loss: 3.576734
 >> iter 112000, loss: 3.479298
 >> iter 113000, loss: 3.518515
 >> iter 114000, loss: 3.443016
 >> iter 115000, loss: 3.535319
 >> iter 116000, loss: 3.515518
 >> iter 117000, loss: 3.705171
 >> iter 118000, loss: 3.590752
 >> iter 119000, loss: 3.573699
 >> iter 120000, loss: 3.472790
   Number of active neurons: 4
 >> iter 121000, loss: 3.530796
 >> iter 122000, loss: 3.570895
 >> iter 123000, loss: 3.552217
 >> iter 124000, loss: 3.513298
 >> iter 125000, loss: 3.612047
 >> iter 126000, loss: 3.558098
 >> iter 127000, loss: 3.664599
 >> iter 128000, loss: 3.564170
 >> iter 129000, loss: 3.571577
 >> iter 130000, loss: 3.609087
   Number of active neurons: 4
 >> iter 131000, loss: 3.586525
 >> iter 132000, loss: 3.550610
 >> iter 133000, loss: 3.525353
 >> iter 134000, loss: 3.505194
 >> iter 135000, loss: 3.545121
 >> iter 136000, loss: 3.476673
 >> iter 137000, loss: 3.501558
 >> iter 138000, loss: 3.489430
 >> iter 139000, loss: 3.507239
 >> iter 140000, loss: 3.497327
   Number of active neurons: 4
 >> iter 141000, loss: 3.664657
 >> iter 142000, loss: 3.578531
 >> iter 143000, loss: 3.683272
 >> iter 144000, loss: 3.562156
 >> iter 145000, loss: 3.539923
 >> iter 146000, loss: 3.479982
 >> iter 147000, loss: 3.519818
 >> iter 148000, loss: 3.506828
 >> iter 149000, loss: 3.563010
 >> iter 150000, loss: 3.557976
   Number of active neurons: 4
 >> iter 151000, loss: 3.628761
 >> iter 152000, loss: 3.529921
 >> iter 153000, loss: 3.595807
 >> iter 154000, loss: 3.554447
 >> iter 155000, loss: 3.577197
 >> iter 156000, loss: 3.583869
 >> iter 157000, loss: 3.660351
 >> iter 158000, loss: 3.562061
 >> iter 159000, loss: 3.706636
 >> iter 160000, loss: 3.654342
   Number of active neurons: 4
 >> iter 161000, loss: 3.576385
 >> iter 162000, loss: 3.499765
 >> iter 163000, loss: 3.532074
 >> iter 164000, loss: 3.511914
 >> iter 165000, loss: 3.677500
 >> iter 166000, loss: 3.524404
 >> iter 167000, loss: 3.510237
 >> iter 168000, loss: 3.530659
 >> iter 169000, loss: 3.557073
 >> iter 170000, loss: 3.524298
   Number of active neurons: 4
 >> iter 171000, loss: 3.514822
 >> iter 172000, loss: 3.557946
 >> iter 173000, loss: 3.562645
 >> iter 174000, loss: 3.619768
 >> iter 175000, loss: 3.570722
 >> iter 176000, loss: 3.606003
 >> iter 177000, loss: 3.549428
 >> iter 178000, loss: 3.518567
 >> iter 179000, loss: 3.523837
 >> iter 180000, loss: 3.537388
   Number of active neurons: 4
 >> iter 181000, loss: 3.583550
 >> iter 182000, loss: 3.529966
 >> iter 183000, loss: 3.600069
 >> iter 184000, loss: 3.554299
 >> iter 185000, loss: 3.657249
 >> iter 186000, loss: 3.473357
 >> iter 187000, loss: 3.573103
 >> iter 188000, loss: 3.460445
 >> iter 189000, loss: 3.671128
 >> iter 190000, loss: 3.580020
   Number of active neurons: 4
 >> iter 191000, loss: 3.640423
 >> iter 192000, loss: 3.631451
 >> iter 193000, loss: 3.654120
 >> iter 194000, loss: 3.567823
 >> iter 195000, loss: 3.593375
 >> iter 196000, loss: 3.487218
 >> iter 197000, loss: 3.589279
 >> iter 198000, loss: 3.477176
 >> iter 199000, loss: 3.618956
 >> iter 200000, loss: 3.531774
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 4.997900042
   - Test - Long: 1.46492675366
   - Test - Big: 4.9579504205
   - Test - A: 0.0
   - Test - B: 14.9723351777
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.797038
 >> iter 2000, loss: 16.692829
 >> iter 3000, loss: 15.433703
 >> iter 4000, loss: 14.120412
 >> iter 5000, loss: 13.961148
 >> iter 6000, loss: 12.768089
 >> iter 7000, loss: 8.795606
 >> iter 8000, loss: 5.297072
 >> iter 9000, loss: 4.111686
 >> iter 10000, loss: 3.374156
   Number of active neurons: 4
 >> iter 11000, loss: 2.794147
 >> iter 12000, loss: 2.414831
 >> iter 13000, loss: 2.518661
 >> iter 14000, loss: 2.288892
 >> iter 15000, loss: 2.469974
 >> iter 16000, loss: 2.175757
 >> iter 17000, loss: 2.351717
 >> iter 18000, loss: 2.306581
 >> iter 19000, loss: 2.214381
 >> iter 20000, loss: 2.267274
   Number of active neurons: 4
 >> iter 21000, loss: 2.318404
 >> iter 22000, loss: 2.138250
 >> iter 23000, loss: 2.237223
 >> iter 24000, loss: 2.249933
 >> iter 25000, loss: 2.239331
 >> iter 26000, loss: 1.979685
 >> iter 27000, loss: 2.058168
 >> iter 28000, loss: 1.872726
 >> iter 29000, loss: 2.051648
 >> iter 30000, loss: 1.965271
   Number of active neurons: 4
 >> iter 31000, loss: 2.122081
 >> iter 32000, loss: 1.984408
 >> iter 33000, loss: 2.148838
 >> iter 34000, loss: 1.965223
 >> iter 35000, loss: 2.122662
 >> iter 36000, loss: 2.042667
 >> iter 37000, loss: 2.196888
 >> iter 38000, loss: 2.129598
 >> iter 39000, loss: 2.162681
 >> iter 40000, loss: 1.890147
   Number of active neurons: 4
 >> iter 41000, loss: 2.166893
 >> iter 42000, loss: 2.022353
 >> iter 43000, loss: 2.025668
 >> iter 44000, loss: 2.028455
 >> iter 45000, loss: 2.189256
 >> iter 46000, loss: 1.943276
 >> iter 47000, loss: 2.087281
 >> iter 48000, loss: 1.898170
 >> iter 49000, loss: 2.071055
 >> iter 50000, loss: 1.929276
   Number of active neurons: 4
 >> iter 51000, loss: 2.088187
 >> iter 52000, loss: 2.011371
 >> iter 53000, loss: 1.992926
 >> iter 54000, loss: 1.839885
 >> iter 55000, loss: 2.164378
 >> iter 56000, loss: 2.007643
 >> iter 57000, loss: 2.027988
 >> iter 58000, loss: 2.028710
 >> iter 59000, loss: 1.989032
 >> iter 60000, loss: 1.964616
   Number of active neurons: 4
 >> iter 61000, loss: 2.047791
 >> iter 62000, loss: 2.182392
 >> iter 63000, loss: 2.208297
 >> iter 64000, loss: 2.071710
 >> iter 65000, loss: 2.327475
 >> iter 66000, loss: 2.028914
 >> iter 67000, loss: 2.244854
 >> iter 68000, loss: 1.979678
 >> iter 69000, loss: 2.194275
 >> iter 70000, loss: 2.020836
   Number of active neurons: 4
 >> iter 71000, loss: 1.982292
 >> iter 72000, loss: 1.861711
 >> iter 73000, loss: 2.203928
 >> iter 74000, loss: 2.198176
 >> iter 75000, loss: 2.366032
 >> iter 76000, loss: 2.011238
 >> iter 77000, loss: 2.034314
 >> iter 78000, loss: 1.840542
 >> iter 79000, loss: 2.086350
 >> iter 80000, loss: 1.902838
   Number of active neurons: 4
 >> iter 81000, loss: 2.222292
 >> iter 82000, loss: 2.059483
 >> iter 83000, loss: 2.011911
 >> iter 84000, loss: 2.056215
 >> iter 85000, loss: 2.096476
 >> iter 86000, loss: 1.971266
 >> iter 87000, loss: 2.131140
 >> iter 88000, loss: 1.986346
 >> iter 89000, loss: 2.052157
 >> iter 90000, loss: 1.943122
   Number of active neurons: 4
 >> iter 91000, loss: 2.057257
 >> iter 92000, loss: 2.050717
 >> iter 93000, loss: 2.075454
 >> iter 94000, loss: 1.924313
 >> iter 95000, loss: 2.115135
 >> iter 96000, loss: 1.941493
 >> iter 97000, loss: 1.991710
 >> iter 98000, loss: 2.017512
 >> iter 99000, loss: 2.322051
 >> iter 100000, loss: 2.017883
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 1.55996880062
   - Test - Long: 0.549972501375
   - Test - Big: 1.67098329017
   - Test - A: 0.333311112592
   - Test - B: 0.126658222785
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.989290
 >> iter 2000, loss: 14.976886
 >> iter 3000, loss: 12.950398
 >> iter 4000, loss: 10.616108
 >> iter 5000, loss: 9.290427
 >> iter 6000, loss: 8.131258
 >> iter 7000, loss: 6.572368
 >> iter 8000, loss: 4.310154
 >> iter 9000, loss: 2.626893
 >> iter 10000, loss: 2.276933
   Number of active neurons: 4
 >> iter 11000, loss: 1.674249
 >> iter 12000, loss: 1.493037
 >> iter 13000, loss: 1.499028
 >> iter 14000, loss: 1.272824
 >> iter 15000, loss: 1.407390
 >> iter 16000, loss: 1.116480
 >> iter 17000, loss: 1.292063
 >> iter 18000, loss: 1.133191
 >> iter 19000, loss: 1.222827
 >> iter 20000, loss: 1.177489
   Number of active neurons: 4
 >> iter 21000, loss: 1.170970
 >> iter 22000, loss: 0.945517
 >> iter 23000, loss: 1.070105
 >> iter 24000, loss: 1.111595
 >> iter 25000, loss: 1.293107
 >> iter 26000, loss: 0.860579
 >> iter 27000, loss: 1.033547
 >> iter 28000, loss: 0.828421
 >> iter 29000, loss: 0.861385
 >> iter 30000, loss: 0.556438
   Number of active neurons: 4
 >> iter 31000, loss: 0.582914
 >> iter 32000, loss: 0.811695
 >> iter 33000, loss: 1.068496
 >> iter 34000, loss: 0.966210
 >> iter 35000, loss: 0.739591
 >> iter 36000, loss: 0.834169
 >> iter 37000, loss: 0.596611
 >> iter 38000, loss: 0.571808
 >> iter 39000, loss: 0.624276
 >> iter 40000, loss: 0.573446
   Number of active neurons: 4
 >> iter 41000, loss: 0.556397
 >> iter 42000, loss: 0.747923
 >> iter 43000, loss: 0.747776
 >> iter 44000, loss: 0.579516
 >> iter 45000, loss: 0.605291
 >> iter 46000, loss: 0.722108
 >> iter 47000, loss: 0.873768
 >> iter 48000, loss: 0.734195
 >> iter 49000, loss: 0.922268
 >> iter 50000, loss: 0.806374
   Number of active neurons: 4
 >> iter 51000, loss: 0.629632
 >> iter 52000, loss: 0.762336
 >> iter 53000, loss: 0.712367
 >> iter 54000, loss: 0.726161
 >> iter 55000, loss: 0.657050
 >> iter 56000, loss: 0.576206
 >> iter 57000, loss: 0.650810
 >> iter 58000, loss: 0.570754
 >> iter 59000, loss: 0.573777
 >> iter 60000, loss: 0.569262
   Number of active neurons: 4
 >> iter 61000, loss: 0.871350
 >> iter 62000, loss: 0.938632
 >> iter 63000, loss: 0.921898
 >> iter 64000, loss: 0.843905
 >> iter 65000, loss: 0.513465
 >> iter 66000, loss: 0.642830
 >> iter 67000, loss: 0.591601
 >> iter 68000, loss: 0.621885
 >> iter 69000, loss: 0.638208
 >> iter 70000, loss: 0.692991
   Number of active neurons: 4
 >> iter 71000, loss: 0.568459
 >> iter 72000, loss: 0.609260
 >> iter 73000, loss: 0.514789
 >> iter 74000, loss: 0.664608
 >> iter 75000, loss: 0.754487
 >> iter 76000, loss: 0.726835
 >> iter 77000, loss: 0.826734
 >> iter 78000, loss: 0.591216
 >> iter 79000, loss: 0.761235
 >> iter 80000, loss: 0.568896
   Number of active neurons: 4
 >> iter 81000, loss: 0.657110
 >> iter 82000, loss: 0.623387
 >> iter 83000, loss: 0.648534
 >> iter 84000, loss: 0.726885
 >> iter 85000, loss: 0.633725
 >> iter 86000, loss: 0.755645
 >> iter 87000, loss: 0.842257
 >> iter 88000, loss: 0.740225
 >> iter 89000, loss: 0.814033
 >> iter 90000, loss: 0.625909
   Number of active neurons: 4
 >> iter 91000, loss: 0.836762
 >> iter 92000, loss: 0.660213
 >> iter 93000, loss: 0.588735
 >> iter 94000, loss: 0.509108
 >> iter 95000, loss: 0.599817
 >> iter 96000, loss: 0.598800
 >> iter 97000, loss: 0.695764
 >> iter 98000, loss: 0.617284
 >> iter 99000, loss: 0.461251
 >> iter 100000, loss: 0.437590
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.243402
 >> iter 2000, loss: 15.515536
 >> iter 3000, loss: 13.403821
 >> iter 4000, loss: 10.985727
 >> iter 5000, loss: 9.693235
 >> iter 6000, loss: 8.719556
 >> iter 7000, loss: 8.289462
 >> iter 8000, loss: 7.808609
 >> iter 9000, loss: 7.724177
 >> iter 10000, loss: 7.415699
   Number of active neurons: 4
 >> iter 11000, loss: 7.428757
 >> iter 12000, loss: 7.166891
 >> iter 13000, loss: 7.046971
 >> iter 14000, loss: 6.910555
 >> iter 15000, loss: 7.052034
 >> iter 16000, loss: 6.704179
 >> iter 17000, loss: 6.634385
 >> iter 18000, loss: 6.470565
 >> iter 19000, loss: 6.506401
 >> iter 20000, loss: 6.310079
   Number of active neurons: 4
 >> iter 21000, loss: 6.532986
 >> iter 22000, loss: 6.257089
 >> iter 23000, loss: 6.484310
 >> iter 24000, loss: 6.237904
 >> iter 25000, loss: 6.498163
 >> iter 26000, loss: 6.389063
 >> iter 27000, loss: 6.622596
 >> iter 28000, loss: 6.473104
 >> iter 29000, loss: 6.450858
 >> iter 30000, loss: 6.209038
   Number of active neurons: 4
 >> iter 31000, loss: 6.275986
 >> iter 32000, loss: 5.977195
 >> iter 33000, loss: 6.113924
 >> iter 34000, loss: 5.941764
 >> iter 35000, loss: 5.894118
 >> iter 36000, loss: 5.882764
 >> iter 37000, loss: 5.925256
 >> iter 38000, loss: 5.683160
 >> iter 39000, loss: 5.688150
 >> iter 40000, loss: 5.280645
   Number of active neurons: 4
 >> iter 41000, loss: 5.424868
 >> iter 42000, loss: 5.218061
 >> iter 43000, loss: 5.309756
 >> iter 44000, loss: 5.030076
 >> iter 45000, loss: 4.472759
 >> iter 46000, loss: 3.766542
 >> iter 47000, loss: 3.749367
 >> iter 48000, loss: 3.506752
 >> iter 49000, loss: 3.595045
 >> iter 50000, loss: 3.378440
   Number of active neurons: 4
 >> iter 51000, loss: 3.741073
 >> iter 52000, loss: 3.600513
 >> iter 53000, loss: 3.996942
 >> iter 54000, loss: 3.645314
 >> iter 55000, loss: 3.777119
 >> iter 56000, loss: 3.286308
 >> iter 57000, loss: 3.174162
 >> iter 58000, loss: 2.816590
 >> iter 59000, loss: 2.646878
 >> iter 60000, loss: 2.430282
   Number of active neurons: 4
 >> iter 61000, loss: 2.514015
 >> iter 62000, loss: 2.331181
 >> iter 63000, loss: 2.516337
 >> iter 64000, loss: 2.265708
 >> iter 65000, loss: 2.134752
 >> iter 66000, loss: 2.105684
 >> iter 67000, loss: 1.951494
 >> iter 68000, loss: 2.049764
 >> iter 69000, loss: 2.024985
 >> iter 70000, loss: 1.854366
   Number of active neurons: 4
 >> iter 71000, loss: 2.120703
 >> iter 72000, loss: 1.752705
 >> iter 73000, loss: 1.960182
 >> iter 74000, loss: 2.146498
 >> iter 75000, loss: 2.254563
 >> iter 76000, loss: 1.987791
 >> iter 77000, loss: 2.082804
 >> iter 78000, loss: 2.133598
 >> iter 79000, loss: 2.386032
 >> iter 80000, loss: 2.274359
   Number of active neurons: 4
 >> iter 81000, loss: 2.209686
 >> iter 82000, loss: 1.892475
 >> iter 83000, loss: 2.088575
 >> iter 84000, loss: 1.778837
 >> iter 85000, loss: 1.800404
 >> iter 86000, loss: 1.922683
 >> iter 87000, loss: 1.988336
 >> iter 88000, loss: 1.843003
 >> iter 89000, loss: 2.069742
 >> iter 90000, loss: 1.765274
   Number of active neurons: 4
 >> iter 91000, loss: 1.795624
 >> iter 92000, loss: 1.716420
 >> iter 93000, loss: 1.760959
 >> iter 94000, loss: 1.629772
 >> iter 95000, loss: 1.959228
 >> iter 96000, loss: 1.655647
 >> iter 97000, loss: 1.971452
 >> iter 98000, loss: 1.794434
 >> iter 99000, loss: 1.916085
 >> iter 100000, loss: 1.714954
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.417991640167
   - Test - Long: 0.204989750512
   - Test - Big: 0.309996900031
   - Test - A: 0.0
   - Test - B: 0.113325778281
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.178520
 >> iter 2000, loss: 14.748146
 >> iter 3000, loss: 12.846518
 >> iter 4000, loss: 8.467634
 >> iter 5000, loss: 4.137566
 >> iter 6000, loss: 2.141386
 >> iter 7000, loss: 1.421250
 >> iter 8000, loss: 1.070185
 >> iter 9000, loss: 0.736612
 >> iter 10000, loss: 0.514856
   Number of active neurons: 4
 >> iter 11000, loss: 0.441679
 >> iter 12000, loss: 0.382670
 >> iter 13000, loss: 0.323588
 >> iter 14000, loss: 0.278192
 >> iter 15000, loss: 0.494529
 >> iter 16000, loss: 0.365900
 >> iter 17000, loss: 0.558184
 >> iter 18000, loss: 0.459930
 >> iter 19000, loss: 0.408243
 >> iter 20000, loss: 0.468139
   Number of active neurons: 4
 >> iter 21000, loss: 0.325314
 >> iter 22000, loss: 0.290924
 >> iter 23000, loss: 0.435399
 >> iter 24000, loss: 0.326990
 >> iter 25000, loss: 0.322157
 >> iter 26000, loss: 0.334832
 >> iter 27000, loss: 0.371538
 >> iter 28000, loss: 0.314245
 >> iter 29000, loss: 0.261383
 >> iter 30000, loss: 0.311649
   Number of active neurons: 4
 >> iter 31000, loss: 0.351835
 >> iter 32000, loss: 0.325713
 >> iter 33000, loss: 0.288231
 >> iter 34000, loss: 0.394265
 >> iter 35000, loss: 0.362398
 >> iter 36000, loss: 0.500072
 >> iter 37000, loss: 0.410920
 >> iter 38000, loss: 0.215842
 >> iter 39000, loss: 0.498974
 >> iter 40000, loss: 0.344139
   Number of active neurons: 4
 >> iter 41000, loss: 0.282403
 >> iter 42000, loss: 0.339482
 >> iter 43000, loss: 0.361713
 >> iter 44000, loss: 0.378604
 >> iter 45000, loss: 0.300081
 >> iter 46000, loss: 0.295248
 >> iter 47000, loss: 0.461057
 >> iter 48000, loss: 0.413653
 >> iter 49000, loss: 0.416788
 >> iter 50000, loss: 0.419705
   Number of active neurons: 4
 >> iter 51000, loss: 0.537026
 >> iter 52000, loss: 0.440207
 >> iter 53000, loss: 0.419630
 >> iter 54000, loss: 0.405928
 >> iter 55000, loss: 0.467446
 >> iter 56000, loss: 0.373055
 >> iter 57000, loss: 0.502259
 >> iter 58000, loss: 0.383635
 >> iter 59000, loss: 0.435032
 >> iter 60000, loss: 0.479517
   Number of active neurons: 4
 >> iter 61000, loss: 0.320723
 >> iter 62000, loss: 0.358836
 >> iter 63000, loss: 0.375478
 >> iter 64000, loss: 0.250721
 >> iter 65000, loss: 0.186106
 >> iter 66000, loss: 0.269260
 >> iter 67000, loss: 0.161927
 >> iter 68000, loss: 0.393515
 >> iter 69000, loss: 0.471323
 >> iter 70000, loss: 0.385525
   Number of active neurons: 4
 >> iter 71000, loss: 0.361777
 >> iter 72000, loss: 0.332536
 >> iter 73000, loss: 0.366326
 >> iter 74000, loss: 0.221352
 >> iter 75000, loss: 0.289322
 >> iter 76000, loss: 0.356702
 >> iter 77000, loss: 0.362980
 >> iter 78000, loss: 0.453334
 >> iter 79000, loss: 0.297571
 >> iter 80000, loss: 0.394113
   Number of active neurons: 4
 >> iter 81000, loss: 0.542271
 >> iter 82000, loss: 0.454112
 >> iter 83000, loss: 0.337342
 >> iter 84000, loss: 0.318660
 >> iter 85000, loss: 0.348797
 >> iter 86000, loss: 0.364274
 >> iter 87000, loss: 0.317412
 >> iter 88000, loss: 0.344630
 >> iter 89000, loss: 0.352286
 >> iter 90000, loss: 0.373225
   Number of active neurons: 4
 >> iter 91000, loss: 0.443032
 >> iter 92000, loss: 0.357836
 >> iter 93000, loss: 0.428377
 >> iter 94000, loss: 0.377970
 >> iter 95000, loss: 0.334848
 >> iter 96000, loss: 0.465276
 >> iter 97000, loss: 0.337285
 >> iter 98000, loss: 0.247560
 >> iter 99000, loss: 0.576664
 >> iter 100000, loss: 0.483353
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.395578
 >> iter 2000, loss: 15.114999
 >> iter 3000, loss: 11.816573
 >> iter 4000, loss: 9.529921
 >> iter 5000, loss: 8.941397
 >> iter 6000, loss: 8.306910
 >> iter 7000, loss: 8.267292
 >> iter 8000, loss: 7.908577
 >> iter 9000, loss: 7.926121
 >> iter 10000, loss: 7.736018
   Number of active neurons: 3
 >> iter 11000, loss: 7.947784
 >> iter 12000, loss: 7.663936
 >> iter 13000, loss: 7.442080
 >> iter 14000, loss: 7.130011
 >> iter 15000, loss: 6.792404
 >> iter 16000, loss: 4.418672
 >> iter 17000, loss: 2.660119
 >> iter 18000, loss: 1.571014
 >> iter 19000, loss: 0.980510
 >> iter 20000, loss: 0.645321
   Number of active neurons: 4
 >> iter 21000, loss: 0.598290
 >> iter 22000, loss: 0.677917
 >> iter 23000, loss: 0.545688
 >> iter 24000, loss: 0.468437
 >> iter 25000, loss: 0.573598
 >> iter 26000, loss: 0.575872
 >> iter 27000, loss: 0.594473
 >> iter 28000, loss: 0.557580
 >> iter 29000, loss: 0.502274
 >> iter 30000, loss: 0.532652
   Number of active neurons: 4
 >> iter 31000, loss: 0.682013
 >> iter 32000, loss: 0.612129
 >> iter 33000, loss: 0.674443
 >> iter 34000, loss: 0.796623
 >> iter 35000, loss: 0.655755
 >> iter 36000, loss: 0.455143
 >> iter 37000, loss: 0.460488
 >> iter 38000, loss: 0.460670
 >> iter 39000, loss: 0.444525
 >> iter 40000, loss: 0.530326
   Number of active neurons: 4
 >> iter 41000, loss: 0.568965
 >> iter 42000, loss: 0.488125
 >> iter 43000, loss: 0.547846
 >> iter 44000, loss: 0.456037
 >> iter 45000, loss: 0.502701
 >> iter 46000, loss: 0.429691
 >> iter 47000, loss: 0.666038
 >> iter 48000, loss: 0.454646
 >> iter 49000, loss: 0.360248
 >> iter 50000, loss: 0.548964
   Number of active neurons: 4
 >> iter 51000, loss: 0.526749
 >> iter 52000, loss: 0.765087
 >> iter 53000, loss: 0.573423
 >> iter 54000, loss: 0.403340
 >> iter 55000, loss: 0.497429
 >> iter 56000, loss: 0.602597
 >> iter 57000, loss: 0.515364
 >> iter 58000, loss: 0.497028
 >> iter 59000, loss: 0.387491
 >> iter 60000, loss: 0.581100
   Number of active neurons: 4
 >> iter 61000, loss: 0.506457
 >> iter 62000, loss: 0.602055
 >> iter 63000, loss: 0.970832
 >> iter 64000, loss: 0.505500
 >> iter 65000, loss: 0.543925
 >> iter 66000, loss: 0.422796
 >> iter 67000, loss: 0.659229
 >> iter 68000, loss: 0.557950
 >> iter 69000, loss: 0.648988
 >> iter 70000, loss: 0.513261
   Number of active neurons: 4
 >> iter 71000, loss: 0.470907
 >> iter 72000, loss: 0.405562
 >> iter 73000, loss: 0.511886
 >> iter 74000, loss: 0.604983
 >> iter 75000, loss: 0.570364
 >> iter 76000, loss: 0.495654
 >> iter 77000, loss: 0.673377
 >> iter 78000, loss: 0.542660
 >> iter 79000, loss: 0.604984
 >> iter 80000, loss: 0.498983
   Number of active neurons: 4
 >> iter 81000, loss: 0.549356
 >> iter 82000, loss: 0.417654
 >> iter 83000, loss: 0.592615
 >> iter 84000, loss: 0.600096
 >> iter 85000, loss: 0.562398
 >> iter 86000, loss: 0.464448
 >> iter 87000, loss: 0.430227
 >> iter 88000, loss: 0.361579
 >> iter 89000, loss: 1.044245
 >> iter 90000, loss: 0.682031
   Number of active neurons: 4
 >> iter 91000, loss: 0.656945
 >> iter 92000, loss: 0.574762
 >> iter 93000, loss: 0.463071
 >> iter 94000, loss: 0.433790
 >> iter 95000, loss: 0.702700
 >> iter 96000, loss: 0.565254
 >> iter 97000, loss: 0.471426
 >> iter 98000, loss: 0.678596
 >> iter 99000, loss: 0.635996
 >> iter 100000, loss: 0.609061
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0239995200096
   - Test - Long: 0.0
   - Test - Big: 0.0539994600054
   - Test - A: 0.0
   - Test - B: 6.38624091727
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 21.128751
 >> iter 2000, loss: 18.814847
 >> iter 3000, loss: 17.949898
 >> iter 4000, loss: 17.646805
 >> iter 5000, loss: 17.518601
 >> iter 6000, loss: 17.489517
 >> iter 7000, loss: 17.461453
 >> iter 8000, loss: 17.468087
 >> iter 9000, loss: 17.452693
 >> iter 10000, loss: 17.464687
   Number of active neurons: 0
 >> iter 11000, loss: 17.448629
 >> iter 12000, loss: 17.463661
 >> iter 13000, loss: 17.450073
 >> iter 14000, loss: 17.463729
 >> iter 15000, loss: 17.448758
 >> iter 16000, loss: 17.465580
 >> iter 17000, loss: 17.449689
 >> iter 18000, loss: 17.465422
 >> iter 19000, loss: 17.453755
 >> iter 20000, loss: 17.465505
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 10.815921
 >> iter 22000, loss: 4.699213
 >> iter 23000, loss: 2.043897
 >> iter 24000, loss: 1.094883
 >> iter 25000, loss: 0.583430
 >> iter 26000, loss: 0.343991
 >> iter 27000, loss: 0.256309
 >> iter 28000, loss: 0.328072
 >> iter 29000, loss: 0.242494
 >> iter 30000, loss: 0.203832
   Number of active neurons: 4
 >> iter 31000, loss: 0.284362
 >> iter 32000, loss: 0.269235
 >> iter 33000, loss: 0.206063
 >> iter 34000, loss: 0.309856
 >> iter 35000, loss: 0.274124
 >> iter 36000, loss: 0.306573
 >> iter 37000, loss: 0.270289
 >> iter 38000, loss: 0.250424
 >> iter 39000, loss: 0.147193
 >> iter 40000, loss: 0.297861
   Number of active neurons: 4
 >> iter 41000, loss: 0.388907
 >> iter 42000, loss: 0.274147
 >> iter 43000, loss: 0.191653
 >> iter 44000, loss: 0.490626
 >> iter 45000, loss: 0.295383
 >> iter 46000, loss: 0.523238
 >> iter 47000, loss: 0.436075
 >> iter 48000, loss: 0.294609
 >> iter 49000, loss: 0.190501
 >> iter 50000, loss: 0.322826
   Number of active neurons: 4
 >> iter 51000, loss: 0.271766
 >> iter 52000, loss: 0.377666
 >> iter 53000, loss: 0.408137
 >> iter 54000, loss: 0.259114
 >> iter 55000, loss: 0.309258
 >> iter 56000, loss: 0.241688
 >> iter 57000, loss: 0.341389
 >> iter 58000, loss: 0.259694
 >> iter 59000, loss: 0.165918
 >> iter 60000, loss: 0.160068
   Number of active neurons: 4
 >> iter 61000, loss: 0.230238
 >> iter 62000, loss: 0.204414
 >> iter 63000, loss: 0.279792
 >> iter 64000, loss: 0.382318
 >> iter 65000, loss: 0.298478
 >> iter 66000, loss: 0.232922
 >> iter 67000, loss: 0.197185
 >> iter 68000, loss: 0.250987
 >> iter 69000, loss: 0.235888
 >> iter 70000, loss: 0.236782
   Number of active neurons: 4
 >> iter 71000, loss: 0.250079
 >> iter 72000, loss: 0.364397
 >> iter 73000, loss: 0.242911
 >> iter 74000, loss: 0.214165
 >> iter 75000, loss: 0.192534
 >> iter 76000, loss: 0.256246
 >> iter 77000, loss: 0.195387
 >> iter 78000, loss: 0.230649
 >> iter 79000, loss: 0.254815
 >> iter 80000, loss: 0.417925
   Number of active neurons: 4
 >> iter 81000, loss: 0.283036
 >> iter 82000, loss: 0.214813
 >> iter 83000, loss: 0.298081
 >> iter 84000, loss: 0.302085
 >> iter 85000, loss: 0.329214
 >> iter 86000, loss: 0.293548
 >> iter 87000, loss: 0.253202
 >> iter 88000, loss: 0.196222
 >> iter 89000, loss: 0.223694
 >> iter 90000, loss: 0.159528
   Number of active neurons: 4
 >> iter 91000, loss: 0.237166
 >> iter 92000, loss: 0.315084
 >> iter 93000, loss: 0.438386
 >> iter 94000, loss: 0.266635
 >> iter 95000, loss: 0.278880
 >> iter 96000, loss: 0.226396
 >> iter 97000, loss: 0.254982
 >> iter 98000, loss: 0.232473
 >> iter 99000, loss: 0.311900
 >> iter 100000, loss: 0.283535
   Number of active neurons: 4
 >> iter 101000, loss: 0.334345
 >> iter 102000, loss: 0.253578
 >> iter 103000, loss: 0.260843
 >> iter 104000, loss: 0.275706
 >> iter 105000, loss: 0.264748
 >> iter 106000, loss: 0.276876
 >> iter 107000, loss: 0.208166
 >> iter 108000, loss: 0.221279
 >> iter 109000, loss: 0.234273
 >> iter 110000, loss: 0.161541
   Number of active neurons: 4
 >> iter 111000, loss: 0.294261
 >> iter 112000, loss: 0.266134
 >> iter 113000, loss: 0.250118
 >> iter 114000, loss: 0.239933
 >> iter 115000, loss: 0.198985
 >> iter 116000, loss: 0.340630
 >> iter 117000, loss: 0.307854
 >> iter 118000, loss: 0.260847
 >> iter 119000, loss: 0.280222
 >> iter 120000, loss: 0.310605
   Number of active neurons: 4
 >> iter 121000, loss: 0.170842
 >> iter 122000, loss: 0.156378
 >> iter 123000, loss: 0.188828
 >> iter 124000, loss: 0.177229
 >> iter 125000, loss: 0.340001
 >> iter 126000, loss: 0.189924
 >> iter 127000, loss: 0.387486
 >> iter 128000, loss: 0.227263
 >> iter 129000, loss: 0.270205
 >> iter 130000, loss: 0.205231
   Number of active neurons: 4
 >> iter 131000, loss: 0.256489
 >> iter 132000, loss: 0.259686
 >> iter 133000, loss: 0.263465
 >> iter 134000, loss: 0.227098
 >> iter 135000, loss: 0.211478
 >> iter 136000, loss: 0.254713
 >> iter 137000, loss: 0.246230
 >> iter 138000, loss: 0.200819
 >> iter 139000, loss: 0.404941
 >> iter 140000, loss: 0.365004
   Number of active neurons: 4
 >> iter 141000, loss: 0.285675
 >> iter 142000, loss: 0.229428
 >> iter 143000, loss: 0.425693
 >> iter 144000, loss: 0.263495
 >> iter 145000, loss: 0.210184
 >> iter 146000, loss: 0.229046
 >> iter 147000, loss: 0.203071
 >> iter 148000, loss: 0.251250
 >> iter 149000, loss: 0.270330
 >> iter 150000, loss: 0.248776
   Number of active neurons: 4
 >> iter 151000, loss: 0.232847
 >> iter 152000, loss: 0.218974
 >> iter 153000, loss: 0.325259
 >> iter 154000, loss: 0.246853
 >> iter 155000, loss: 0.221827
 >> iter 156000, loss: 0.238999
 >> iter 157000, loss: 0.201007
 >> iter 158000, loss: 0.243439
 >> iter 159000, loss: 0.203434
 >> iter 160000, loss: 0.420771
   Number of active neurons: 4
 >> iter 161000, loss: 0.374391
 >> iter 162000, loss: 0.220143
 >> iter 163000, loss: 0.219027
 >> iter 164000, loss: 0.232738
 >> iter 165000, loss: 0.225193
 >> iter 166000, loss: 0.210411
 >> iter 167000, loss: 0.433390
 >> iter 168000, loss: 0.253677
 >> iter 169000, loss: 0.258863
 >> iter 170000, loss: 0.215366
   Number of active neurons: 4
 >> iter 171000, loss: 0.215724
 >> iter 172000, loss: 0.127044
 >> iter 173000, loss: 0.251003
 >> iter 174000, loss: 0.208091
 >> iter 175000, loss: 0.274766
 >> iter 176000, loss: 0.205048
 >> iter 177000, loss: 0.164760
 >> iter 178000, loss: 0.220156
 >> iter 179000, loss: 0.219703
 >> iter 180000, loss: 0.244574
   Number of active neurons: 4
 >> iter 181000, loss: 0.215106
 >> iter 182000, loss: 0.232697
 >> iter 183000, loss: 0.195997
 >> iter 184000, loss: 0.153537
 >> iter 185000, loss: 0.264151
 >> iter 186000, loss: 0.374305
 >> iter 187000, loss: 0.280706
 >> iter 188000, loss: 0.198629
 >> iter 189000, loss: 0.316873
 >> iter 190000, loss: 0.247655
   Number of active neurons: 4
 >> iter 191000, loss: 0.241643
 >> iter 192000, loss: 0.182424
 >> iter 193000, loss: 0.118115
 >> iter 194000, loss: 0.169274
 >> iter 195000, loss: 0.148348
 >> iter 196000, loss: 0.386580
 >> iter 197000, loss: 0.218141
 >> iter 198000, loss: 0.232546
 >> iter 199000, loss: 0.251727
 >> iter 200000, loss: 0.270229
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.840052
 >> iter 2000, loss: 14.566134
 >> iter 3000, loss: 8.409225
 >> iter 4000, loss: 3.897809
 >> iter 5000, loss: 1.819084
 >> iter 6000, loss: 1.140316
 >> iter 7000, loss: 0.732789
 >> iter 8000, loss: 0.718859
 >> iter 9000, loss: 0.556371
 >> iter 10000, loss: 0.550409
   Number of active neurons: 4
 >> iter 11000, loss: 0.470442
 >> iter 12000, loss: 0.424848
 >> iter 13000, loss: 0.381135
 >> iter 14000, loss: 0.373974
 >> iter 15000, loss: 0.493730
 >> iter 16000, loss: 0.362579
 >> iter 17000, loss: 0.503411
 >> iter 18000, loss: 0.432799
 >> iter 19000, loss: 0.310952
 >> iter 20000, loss: 0.237057
   Number of active neurons: 4
 >> iter 21000, loss: 0.330941
 >> iter 22000, loss: 0.360193
 >> iter 23000, loss: 0.472874
 >> iter 24000, loss: 0.350827
 >> iter 25000, loss: 0.368314
 >> iter 26000, loss: 0.388481
 >> iter 27000, loss: 0.410374
 >> iter 28000, loss: 0.380042
 >> iter 29000, loss: 0.283993
 >> iter 30000, loss: 0.313520
   Number of active neurons: 4
 >> iter 31000, loss: 0.376762
 >> iter 32000, loss: 0.260883
 >> iter 33000, loss: 0.383292
 >> iter 34000, loss: 0.522815
 >> iter 35000, loss: 0.515673
 >> iter 36000, loss: 0.382019
 >> iter 37000, loss: 0.363372
 >> iter 38000, loss: 0.364034
 >> iter 39000, loss: 0.498900
 >> iter 40000, loss: 0.482485
   Number of active neurons: 4
 >> iter 41000, loss: 0.319511
 >> iter 42000, loss: 0.509941
 >> iter 43000, loss: 0.303938
 >> iter 44000, loss: 0.452387
 >> iter 45000, loss: 0.493108
 >> iter 46000, loss: 0.416613
 >> iter 47000, loss: 0.371343
 >> iter 48000, loss: 0.346391
 >> iter 49000, loss: 0.316642
 >> iter 50000, loss: 0.372955
   Number of active neurons: 4
 >> iter 51000, loss: 0.438082
 >> iter 52000, loss: 0.323635
 >> iter 53000, loss: 0.334227
 >> iter 54000, loss: 0.253537
 >> iter 55000, loss: 0.448839
 >> iter 56000, loss: 0.423495
 >> iter 57000, loss: 0.529937
 >> iter 58000, loss: 0.280950
 >> iter 59000, loss: 0.386778
 >> iter 60000, loss: 0.385352
   Number of active neurons: 4
 >> iter 61000, loss: 0.514781
 >> iter 62000, loss: 0.437248
 >> iter 63000, loss: 0.327280
 >> iter 64000, loss: 0.403926
 >> iter 65000, loss: 0.420501
 >> iter 66000, loss: 0.375288
 >> iter 67000, loss: 0.422560
 >> iter 68000, loss: 0.499997
 >> iter 69000, loss: 0.467114
 >> iter 70000, loss: 0.335748
   Number of active neurons: 4
 >> iter 71000, loss: 0.411477
 >> iter 72000, loss: 0.240505
 >> iter 73000, loss: 0.475816
 >> iter 74000, loss: 0.326188
 >> iter 75000, loss: 0.477480
 >> iter 76000, loss: 0.398787
 >> iter 77000, loss: 0.366057
 >> iter 78000, loss: 0.342314
 >> iter 79000, loss: 0.293060
 >> iter 80000, loss: 0.375454
   Number of active neurons: 4
 >> iter 81000, loss: 0.361257
 >> iter 82000, loss: 0.374048
 >> iter 83000, loss: 0.297265
 >> iter 84000, loss: 0.410698
 >> iter 85000, loss: 0.437509
 >> iter 86000, loss: 0.372228
 >> iter 87000, loss: 0.371664
 >> iter 88000, loss: 0.403069
 >> iter 89000, loss: 0.504561
 >> iter 90000, loss: 0.396845
   Number of active neurons: 4
 >> iter 91000, loss: 0.380170
 >> iter 92000, loss: 0.295777
 >> iter 93000, loss: 0.302865
 >> iter 94000, loss: 0.373697
 >> iter 95000, loss: 0.415440
 >> iter 96000, loss: 0.370389
 >> iter 97000, loss: 0.405413
 >> iter 98000, loss: 0.321071
 >> iter 99000, loss: 0.286122
 >> iter 100000, loss: 0.486230
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 17.5188320779

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

