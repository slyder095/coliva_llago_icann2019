 > Problema: tomita7nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.382322
 >> iter 2000, loss: 14.141164
 >> iter 3000, loss: 13.262766
 >> iter 4000, loss: 11.468974
 >> iter 5000, loss: 11.690421
 >> iter 6000, loss: 12.183294
 >> iter 7000, loss: 11.394839
 >> iter 8000, loss: 10.970300
 >> iter 9000, loss: 10.933313
 >> iter 10000, loss: 10.895002
   Number of active neurons: 2
 >> iter 11000, loss: 11.132327
 >> iter 12000, loss: 11.034751
 >> iter 13000, loss: 11.165492
 >> iter 14000, loss: 10.275568
 >> iter 15000, loss: 10.112298
 >> iter 16000, loss: 10.847329
 >> iter 17000, loss: 10.897245
 >> iter 18000, loss: 10.949732
 >> iter 19000, loss: 11.058081
 >> iter 20000, loss: 12.075501
   Number of active neurons: 2
 >> iter 21000, loss: 11.594969
 >> iter 22000, loss: 11.211991
 >> iter 23000, loss: 10.661798
 >> iter 24000, loss: 11.077967
 >> iter 25000, loss: 11.290188
 >> iter 26000, loss: 10.579493
 >> iter 27000, loss: 12.230261
 >> iter 28000, loss: 11.776672
 >> iter 29000, loss: 12.190633
 >> iter 30000, loss: 10.750916
   Number of active neurons: 2
 >> iter 31000, loss: 10.696741
 >> iter 32000, loss: 10.410767
 >> iter 33000, loss: 11.554993
 >> iter 34000, loss: 10.673295
 >> iter 35000, loss: 10.158866
 >> iter 36000, loss: 10.394330
 >> iter 37000, loss: 10.452573
 >> iter 38000, loss: 11.143613
 >> iter 39000, loss: 11.516444
 >> iter 40000, loss: 10.535151
   Number of active neurons: 2
 >> iter 41000, loss: 11.221231
 >> iter 42000, loss: 10.807922
 >> iter 43000, loss: 11.515259
 >> iter 44000, loss: 10.864700
 >> iter 45000, loss: 11.861142
 >> iter 46000, loss: 11.494947
 >> iter 47000, loss: 11.598249
 >> iter 48000, loss: 13.101058
 >> iter 49000, loss: 11.531689
 >> iter 50000, loss: 11.278138
   Number of active neurons: 2
 >> iter 51000, loss: 10.776408
 >> iter 52000, loss: 10.387896
 >> iter 53000, loss: 11.992649
 >> iter 54000, loss: 12.000341
 >> iter 55000, loss: 11.660532
 >> iter 56000, loss: 10.483118
 >> iter 57000, loss: 10.176317
 >> iter 58000, loss: 10.728483
 >> iter 59000, loss: 10.856141
 >> iter 60000, loss: 10.204656
   Number of active neurons: 2
 >> iter 61000, loss: 10.494666
 >> iter 62000, loss: 10.911774
 >> iter 63000, loss: 11.188143
 >> iter 64000, loss: 10.978479
 >> iter 65000, loss: 11.054732
 >> iter 66000, loss: 10.334662
 >> iter 67000, loss: 11.014163
 >> iter 68000, loss: 10.805559
 >> iter 69000, loss: 11.007636
 >> iter 70000, loss: 12.652073
   Number of active neurons: 2
 >> iter 71000, loss: 10.847975
 >> iter 72000, loss: 11.130479
 >> iter 73000, loss: 11.258381
 >> iter 74000, loss: 10.974194
 >> iter 75000, loss: 10.542470
 >> iter 76000, loss: 10.286381
 >> iter 77000, loss: 10.687000
 >> iter 78000, loss: 11.092787
 >> iter 79000, loss: 11.171282
 >> iter 80000, loss: 12.400359
   Number of active neurons: 2
 >> iter 81000, loss: 11.516655
 >> iter 82000, loss: 11.684164
 >> iter 83000, loss: 11.117805
 >> iter 84000, loss: 11.676284
 >> iter 85000, loss: 10.560358
 >> iter 86000, loss: 10.569742
 >> iter 87000, loss: 11.891426
 >> iter 88000, loss: 10.774075
 >> iter 89000, loss: 10.936074
 >> iter 90000, loss: 11.209145
   Number of active neurons: 2
 >> iter 91000, loss: 10.768062
 >> iter 92000, loss: 10.294051
 >> iter 93000, loss: 10.396762
 >> iter 94000, loss: 11.129068
 >> iter 95000, loss: 10.522524
 >> iter 96000, loss: 10.512166
 >> iter 97000, loss: 10.830762
 >> iter 98000, loss: 10.979189
 >> iter 99000, loss: 10.111958
 >> iter 100000, loss: 10.180790
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 21.037291
 >> iter 2000, loss: 18.735213
 >> iter 3000, loss: 17.828261
 >> iter 4000, loss: 17.557538
 >> iter 5000, loss: 17.393953
 >> iter 6000, loss: 17.399766
 >> iter 7000, loss: 17.334485
 >> iter 8000, loss: 17.377683
 >> iter 9000, loss: 17.326842
 >> iter 10000, loss: 17.376461
   Number of active neurons: 0
 >> iter 11000, loss: 17.324224
 >> iter 12000, loss: 17.376003
 >> iter 13000, loss: 17.320235
 >> iter 14000, loss: 17.374907
 >> iter 15000, loss: 17.320795
 >> iter 16000, loss: 17.374885
 >> iter 17000, loss: 17.322167
 >> iter 18000, loss: 17.374664
 >> iter 19000, loss: 17.320916
 >> iter 20000, loss: 17.374841
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 14.628072
 >> iter 22000, loss: 12.623519
 >> iter 23000, loss: 12.078980
 >> iter 24000, loss: 11.886706
 >> iter 25000, loss: 11.187241
 >> iter 26000, loss: 11.342768
 >> iter 27000, loss: 13.292368
 >> iter 28000, loss: 12.666283
 >> iter 29000, loss: 11.113383
 >> iter 30000, loss: 8.964429
   Number of active neurons: 2
 >> iter 31000, loss: 8.412035
 >> iter 32000, loss: 8.098719
 >> iter 33000, loss: 8.108181
 >> iter 34000, loss: 7.028680
 >> iter 35000, loss: 6.824338
 >> iter 36000, loss: 6.857970
 >> iter 37000, loss: 6.666575
 >> iter 38000, loss: 8.161862
 >> iter 39000, loss: 7.586674
 >> iter 40000, loss: 6.621680
   Number of active neurons: 2
 >> iter 41000, loss: 7.883618
 >> iter 42000, loss: 7.639516
 >> iter 43000, loss: 7.489245
 >> iter 44000, loss: 7.013628
 >> iter 45000, loss: 7.645537
 >> iter 46000, loss: 7.203327
 >> iter 47000, loss: 6.956607
 >> iter 48000, loss: 7.112385
 >> iter 49000, loss: 8.231628
 >> iter 50000, loss: 6.913026
   Number of active neurons: 2
 >> iter 51000, loss: 6.645944
 >> iter 52000, loss: 6.490758
 >> iter 53000, loss: 6.910378
 >> iter 54000, loss: 6.836703
 >> iter 55000, loss: 6.280370
 >> iter 56000, loss: 5.669190
 >> iter 57000, loss: 5.925071
 >> iter 58000, loss: 5.934840
 >> iter 59000, loss: 6.858098
 >> iter 60000, loss: 6.666251
   Number of active neurons: 2
 >> iter 61000, loss: 6.309992
 >> iter 62000, loss: 5.956703
 >> iter 63000, loss: 6.207855
 >> iter 64000, loss: 7.362180
 >> iter 65000, loss: 6.849522
 >> iter 66000, loss: 6.326065
 >> iter 67000, loss: 6.754332
 >> iter 68000, loss: 8.667352
 >> iter 69000, loss: 7.731162
 >> iter 70000, loss: 6.788705
   Number of active neurons: 2
 >> iter 71000, loss: 7.033410
 >> iter 72000, loss: 6.730358
 >> iter 73000, loss: 6.775036
 >> iter 74000, loss: 6.049628
 >> iter 75000, loss: 5.962343
 >> iter 76000, loss: 5.560171
 >> iter 77000, loss: 5.711316
 >> iter 78000, loss: 6.011123
 >> iter 79000, loss: 6.083762
 >> iter 80000, loss: 5.922029
   Number of active neurons: 2
 >> iter 81000, loss: 6.014785
 >> iter 82000, loss: 5.902507
 >> iter 83000, loss: 6.286395
 >> iter 84000, loss: 6.976869
 >> iter 85000, loss: 7.146277
 >> iter 86000, loss: 6.419866
 >> iter 87000, loss: 6.576697
 >> iter 88000, loss: 6.127854
 >> iter 89000, loss: 6.127598
 >> iter 90000, loss: 6.192178
   Number of active neurons: 2
 >> iter 91000, loss: 6.555467
 >> iter 92000, loss: 7.105326
 >> iter 93000, loss: 8.067874
 >> iter 94000, loss: 9.299275
 >> iter 95000, loss: 8.364010
 >> iter 96000, loss: 6.988897
 >> iter 97000, loss: 6.282269
 >> iter 98000, loss: 5.832264
 >> iter 99000, loss: 5.735309
 >> iter 100000, loss: 5.957684
   Number of active neurons: 2
 >> iter 101000, loss: 5.850240
 >> iter 102000, loss: 5.947750
 >> iter 103000, loss: 5.961109
 >> iter 104000, loss: 5.794980
 >> iter 105000, loss: 5.628024
 >> iter 106000, loss: 5.585154
 >> iter 107000, loss: 6.269123
 >> iter 108000, loss: 6.907089
 >> iter 109000, loss: 6.726085
 >> iter 110000, loss: 6.581114
   Number of active neurons: 2
 >> iter 111000, loss: 6.700640
 >> iter 112000, loss: 6.469591
 >> iter 113000, loss: 6.626069
 >> iter 114000, loss: 6.189924
 >> iter 115000, loss: 6.358049
 >> iter 116000, loss: 6.549351
 >> iter 117000, loss: 6.320710
 >> iter 118000, loss: 5.920969
 >> iter 119000, loss: 6.298614
 >> iter 120000, loss: 6.316186
   Number of active neurons: 2
 >> iter 121000, loss: 7.534076
 >> iter 122000, loss: 7.968413
 >> iter 123000, loss: 10.406344
 >> iter 124000, loss: 15.040159
 >> iter 125000, loss: 16.690306
 >> iter 126000, loss: 17.338627
 >> iter 127000, loss: 17.428284
 >> iter 128000, loss: 16.832511
 >> iter 129000, loss: 15.390646
 >> iter 130000, loss: 14.689845
   Number of active neurons: 2
 >> iter 131000, loss: 14.449065
 >> iter 132000, loss: 14.463406
 >> iter 133000, loss: 14.764585
 >> iter 134000, loss: 14.480338
 >> iter 135000, loss: 14.616053
 >> iter 136000, loss: 14.505787
 >> iter 137000, loss: 14.561123
 >> iter 138000, loss: 14.311839
 >> iter 139000, loss: 14.437251
 >> iter 140000, loss: 14.746425
   Number of active neurons: 2
 >> iter 141000, loss: 15.306928
 >> iter 142000, loss: 14.884803
 >> iter 143000, loss: 14.947098
 >> iter 144000, loss: 14.915812
 >> iter 145000, loss: 14.542651
 >> iter 146000, loss: 14.342703
 >> iter 147000, loss: 14.550333
 >> iter 148000, loss: 14.309566
 >> iter 149000, loss: 14.446051
 >> iter 150000, loss: 14.357141
   Number of active neurons: 2
 >> iter 151000, loss: 14.420202
 >> iter 152000, loss: 12.255734
 >> iter 153000, loss: 12.335135
 >> iter 154000, loss: 11.499656
 >> iter 155000, loss: 12.570863
 >> iter 156000, loss: 11.661070
 >> iter 157000, loss: 11.007146
 >> iter 158000, loss: 10.224163
 >> iter 159000, loss: 10.517048
 >> iter 160000, loss: 10.140112
   Number of active neurons: 2
 >> iter 161000, loss: 10.792220
 >> iter 162000, loss: 10.894657
 >> iter 163000, loss: 11.577528
 >> iter 164000, loss: 11.404102
 >> iter 165000, loss: 12.526635
 >> iter 166000, loss: 11.145532
 >> iter 167000, loss: 11.112897
 >> iter 168000, loss: 11.433071
 >> iter 169000, loss: 12.686598
 >> iter 170000, loss: 11.685604
   Number of active neurons: 2
 >> iter 171000, loss: 11.529200
 >> iter 172000, loss: 13.689409
 >> iter 173000, loss: 13.023007
 >> iter 174000, loss: 12.186967
 >> iter 175000, loss: 11.637054
 >> iter 176000, loss: 12.456625
 >> iter 177000, loss: 11.883458
 >> iter 178000, loss: 11.510312
 >> iter 179000, loss: 10.469265
 >> iter 180000, loss: 10.414202
   Number of active neurons: 2
 >> iter 181000, loss: 10.902419
 >> iter 182000, loss: 11.242170
 >> iter 183000, loss: 11.786629
 >> iter 184000, loss: 11.473430
 >> iter 185000, loss: 11.666483
 >> iter 186000, loss: 12.095123
 >> iter 187000, loss: 11.792136
 >> iter 188000, loss: 11.397825
 >> iter 189000, loss: 12.185645
 >> iter 190000, loss: 11.931665
   Number of active neurons: 2
 >> iter 191000, loss: 12.203069
 >> iter 192000, loss: 12.132948
 >> iter 193000, loss: 12.088703
 >> iter 194000, loss: 13.836630
 >> iter 195000, loss: 13.816543
 >> iter 196000, loss: 12.489165
 >> iter 197000, loss: 11.409810
 >> iter 198000, loss: 11.926321
 >> iter 199000, loss: 12.952608
 >> iter 200000, loss: 14.161178
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.006291
 >> iter 2000, loss: 14.223670
 >> iter 3000, loss: 12.269423
 >> iter 4000, loss: 11.091574
 >> iter 5000, loss: 11.573084
 >> iter 6000, loss: 11.450319
 >> iter 7000, loss: 11.778669
 >> iter 8000, loss: 10.913150
 >> iter 9000, loss: 11.011140
 >> iter 10000, loss: 10.889841
   Number of active neurons: 2
 >> iter 11000, loss: 10.928508
 >> iter 12000, loss: 11.082655
 >> iter 13000, loss: 11.327964
 >> iter 14000, loss: 10.979291
 >> iter 15000, loss: 10.785977
 >> iter 16000, loss: 10.898285
 >> iter 17000, loss: 10.571617
 >> iter 18000, loss: 10.955458
 >> iter 19000, loss: 11.189402
 >> iter 20000, loss: 10.931737
   Number of active neurons: 2
 >> iter 21000, loss: 11.217745
 >> iter 22000, loss: 10.323101
 >> iter 23000, loss: 10.836522
 >> iter 24000, loss: 10.150065
 >> iter 25000, loss: 10.566263
 >> iter 26000, loss: 10.224896
 >> iter 27000, loss: 11.127062
 >> iter 28000, loss: 10.439304
 >> iter 29000, loss: 11.014968
 >> iter 30000, loss: 10.732216
   Number of active neurons: 2
 >> iter 31000, loss: 10.639602
 >> iter 32000, loss: 10.489592
 >> iter 33000, loss: 10.939535
 >> iter 34000, loss: 10.720141
 >> iter 35000, loss: 11.969724
 >> iter 36000, loss: 11.072423
 >> iter 37000, loss: 10.771309
 >> iter 38000, loss: 10.828419
 >> iter 39000, loss: 10.790842
 >> iter 40000, loss: 10.392313
   Number of active neurons: 2
 >> iter 41000, loss: 10.314619
 >> iter 42000, loss: 11.085989
 >> iter 43000, loss: 11.243556
 >> iter 44000, loss: 10.347960
 >> iter 45000, loss: 11.545697
 >> iter 46000, loss: 11.134609
 >> iter 47000, loss: 10.968998
 >> iter 48000, loss: 10.394660
 >> iter 49000, loss: 11.381202
 >> iter 50000, loss: 10.632379
   Number of active neurons: 2
 >> iter 51000, loss: 10.435081
 >> iter 52000, loss: 10.707647
 >> iter 53000, loss: 10.627074
 >> iter 54000, loss: 10.703914
 >> iter 55000, loss: 10.970428
 >> iter 56000, loss: 10.791027
 >> iter 57000, loss: 10.962400
 >> iter 58000, loss: 10.910135
 >> iter 59000, loss: 11.342968
 >> iter 60000, loss: 10.731207
   Number of active neurons: 2
 >> iter 61000, loss: 10.927942
 >> iter 62000, loss: 10.331981
 >> iter 63000, loss: 10.560657
 >> iter 64000, loss: 10.570423
 >> iter 65000, loss: 10.838846
 >> iter 66000, loss: 10.490707
 >> iter 67000, loss: 10.565240
 >> iter 68000, loss: 10.756220
 >> iter 69000, loss: 10.457170
 >> iter 70000, loss: 10.832569
   Number of active neurons: 2
 >> iter 71000, loss: 10.897739
 >> iter 72000, loss: 10.697096
 >> iter 73000, loss: 12.221428
 >> iter 74000, loss: 12.316485
 >> iter 75000, loss: 10.805319
 >> iter 76000, loss: 10.325250
 >> iter 77000, loss: 10.621307
 >> iter 78000, loss: 11.071464
 >> iter 79000, loss: 13.107495
 >> iter 80000, loss: 11.280076
   Number of active neurons: 2
 >> iter 81000, loss: 10.552658
 >> iter 82000, loss: 11.389570
 >> iter 83000, loss: 10.932391
 >> iter 84000, loss: 10.723981
 >> iter 85000, loss: 11.181935
 >> iter 86000, loss: 10.580679
 >> iter 87000, loss: 11.938551
 >> iter 88000, loss: 11.224837
 >> iter 89000, loss: 10.892433
 >> iter 90000, loss: 9.965336
   Number of active neurons: 2
 >> iter 91000, loss: 11.899347
 >> iter 92000, loss: 11.230714
 >> iter 93000, loss: 11.536673
 >> iter 94000, loss: 11.254900
 >> iter 95000, loss: 14.518033
 >> iter 96000, loss: 13.068893
 >> iter 97000, loss: 11.566936
 >> iter 98000, loss: 10.754149
 >> iter 99000, loss: 10.775104
 >> iter 100000, loss: 10.823034
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 13.5157296854
   - Test - Long: 3.22983850807
   - Test - Big: 13.8688613114
   - Test - A: 70.6219585361
   - Test - B: 57.4228384774
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 21.037297
 >> iter 2000, loss: 18.735216
 >> iter 3000, loss: 17.828262
 >> iter 4000, loss: 17.557539
 >> iter 5000, loss: 17.393953
 >> iter 6000, loss: 17.399767
 >> iter 7000, loss: 17.334485
 >> iter 8000, loss: 17.377683
 >> iter 9000, loss: 17.326842
 >> iter 10000, loss: 17.376461
   Number of active neurons: 0
 >> iter 11000, loss: 17.324224
 >> iter 12000, loss: 17.376003
 >> iter 13000, loss: 17.320235
 >> iter 14000, loss: 17.374907
 >> iter 15000, loss: 17.320795
 >> iter 16000, loss: 17.374885
 >> iter 17000, loss: 17.322167
 >> iter 18000, loss: 17.374665
 >> iter 19000, loss: 17.320916
 >> iter 20000, loss: 17.374841
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 13.396008
 >> iter 22000, loss: 12.045919
 >> iter 23000, loss: 11.724369
 >> iter 24000, loss: 11.708173
 >> iter 25000, loss: 11.549772
 >> iter 26000, loss: 11.551902
 >> iter 27000, loss: 11.653699
 >> iter 28000, loss: 11.434708
 >> iter 29000, loss: 11.375531
 >> iter 30000, loss: 11.480959
   Number of active neurons: 2
 >> iter 31000, loss: 11.226334
 >> iter 32000, loss: 10.784206
 >> iter 33000, loss: 11.116920
 >> iter 34000, loss: 11.541187
 >> iter 35000, loss: 11.706957
 >> iter 36000, loss: 11.414642
 >> iter 37000, loss: 10.780245
 >> iter 38000, loss: 10.469047
 >> iter 39000, loss: 10.840149
 >> iter 40000, loss: 10.323903
   Number of active neurons: 2
 >> iter 41000, loss: 11.039576
 >> iter 42000, loss: 10.528405
 >> iter 43000, loss: 10.534347
 >> iter 44000, loss: 10.531612
 >> iter 45000, loss: 10.529453
 >> iter 46000, loss: 10.625260
 >> iter 47000, loss: 10.930954
 >> iter 48000, loss: 10.928143
 >> iter 49000, loss: 11.310381
 >> iter 50000, loss: 10.701683
   Number of active neurons: 2
 >> iter 51000, loss: 11.432677
 >> iter 52000, loss: 10.864419
 >> iter 53000, loss: 10.914057
 >> iter 54000, loss: 11.285346
 >> iter 55000, loss: 11.425711
 >> iter 56000, loss: 10.607853
 >> iter 57000, loss: 10.826526
 >> iter 58000, loss: 11.455489
 >> iter 59000, loss: 11.209223
 >> iter 60000, loss: 10.830388
   Number of active neurons: 2
 >> iter 61000, loss: 10.678292
 >> iter 62000, loss: 10.739526
 >> iter 63000, loss: 11.091866
 >> iter 64000, loss: 11.127369
 >> iter 65000, loss: 10.753648
 >> iter 66000, loss: 10.559386
 >> iter 67000, loss: 10.664856
 >> iter 68000, loss: 10.763840
 >> iter 69000, loss: 11.346881
 >> iter 70000, loss: 12.054490
   Number of active neurons: 2
 >> iter 71000, loss: 11.935269
 >> iter 72000, loss: 11.137004
 >> iter 73000, loss: 10.749353
 >> iter 74000, loss: 10.692926
 >> iter 75000, loss: 11.026420
 >> iter 76000, loss: 10.951339
 >> iter 77000, loss: 11.312534
 >> iter 78000, loss: 10.260000
 >> iter 79000, loss: 10.610821
 >> iter 80000, loss: 10.746799
   Number of active neurons: 2
 >> iter 81000, loss: 10.757176
 >> iter 82000, loss: 11.704681
 >> iter 83000, loss: 10.804488
 >> iter 84000, loss: 10.643533
 >> iter 85000, loss: 10.278960
 >> iter 86000, loss: 10.708551
 >> iter 87000, loss: 12.464835
 >> iter 88000, loss: 11.236043
 >> iter 89000, loss: 10.708935
 >> iter 90000, loss: 11.017052
   Number of active neurons: 2
 >> iter 91000, loss: 12.265167
 >> iter 92000, loss: 11.447772
 >> iter 93000, loss: 10.883346
 >> iter 94000, loss: 10.591695
 >> iter 95000, loss: 11.240859
 >> iter 96000, loss: 11.336591
 >> iter 97000, loss: 11.887515
 >> iter 98000, loss: 10.677754
 >> iter 99000, loss: 11.072514
 >> iter 100000, loss: 11.668680
   Number of active neurons: 2
 >> iter 101000, loss: 12.475082
 >> iter 102000, loss: 11.033641
 >> iter 103000, loss: 10.731039
 >> iter 104000, loss: 10.524405
 >> iter 105000, loss: 10.718941
 >> iter 106000, loss: 10.469500
 >> iter 107000, loss: 10.600425
 >> iter 108000, loss: 11.367437
 >> iter 109000, loss: 10.866093
 >> iter 110000, loss: 10.407771
   Number of active neurons: 2
 >> iter 111000, loss: 10.404700
 >> iter 112000, loss: 13.656090
 >> iter 113000, loss: 14.778983
 >> iter 114000, loss: 11.600641
 >> iter 115000, loss: 10.846420
 >> iter 116000, loss: 10.287099
 >> iter 117000, loss: 10.843580
 >> iter 118000, loss: 10.335973
 >> iter 119000, loss: 10.117630
 >> iter 120000, loss: 10.744860
   Number of active neurons: 2
 >> iter 121000, loss: 10.236307
 >> iter 122000, loss: 10.592178
 >> iter 123000, loss: 10.920681
 >> iter 124000, loss: 10.984906
 >> iter 125000, loss: 11.018455
 >> iter 126000, loss: 10.831511
 >> iter 127000, loss: 10.653232
 >> iter 128000, loss: 10.108539
 >> iter 129000, loss: 10.593846
 >> iter 130000, loss: 11.272695
   Number of active neurons: 2
 >> iter 131000, loss: 11.047378
 >> iter 132000, loss: 11.024371
 >> iter 133000, loss: 10.426806
 >> iter 134000, loss: 10.436854
 >> iter 135000, loss: 11.603155
 >> iter 136000, loss: 10.927572
 >> iter 137000, loss: 10.772180
 >> iter 138000, loss: 12.404633
 >> iter 139000, loss: 11.386615
 >> iter 140000, loss: 12.861907
   Number of active neurons: 2
 >> iter 141000, loss: 11.164559
 >> iter 142000, loss: 11.374446
 >> iter 143000, loss: 11.014782
 >> iter 144000, loss: 10.733506
 >> iter 145000, loss: 10.278443
 >> iter 146000, loss: 10.109363
 >> iter 147000, loss: 11.354162
 >> iter 148000, loss: 10.705001
 >> iter 149000, loss: 10.730949
 >> iter 150000, loss: 10.868945
   Number of active neurons: 2
 >> iter 151000, loss: 11.443822
 >> iter 152000, loss: 10.568140
 >> iter 153000, loss: 10.764026
 >> iter 154000, loss: 11.850923
 >> iter 155000, loss: 11.419992
 >> iter 156000, loss: 10.934997
 >> iter 157000, loss: 11.854986
 >> iter 158000, loss: 13.083160
 >> iter 159000, loss: 12.234441
 >> iter 160000, loss: 11.828915
   Number of active neurons: 2
 >> iter 161000, loss: 11.351693
 >> iter 162000, loss: 11.112660
 >> iter 163000, loss: 10.635883
 >> iter 164000, loss: 10.628131
 >> iter 165000, loss: 10.762696
 >> iter 166000, loss: 10.217135
 >> iter 167000, loss: 10.495192
 >> iter 168000, loss: 10.695242
 >> iter 169000, loss: 10.780443
 >> iter 170000, loss: 11.526456
   Number of active neurons: 2
 >> iter 171000, loss: 11.265508
 >> iter 172000, loss: 14.311903
 >> iter 173000, loss: 12.176022
 >> iter 174000, loss: 13.040201
 >> iter 175000, loss: 11.797657
 >> iter 176000, loss: 11.336347
 >> iter 177000, loss: 10.659369
 >> iter 178000, loss: 11.283742
 >> iter 179000, loss: 10.589902
 >> iter 180000, loss: 14.497941
   Number of active neurons: 2
 >> iter 181000, loss: 12.186280
 >> iter 182000, loss: 11.167128
 >> iter 183000, loss: 10.553566
 >> iter 184000, loss: 11.254621
 >> iter 185000, loss: 11.564762
 >> iter 186000, loss: 11.702193
 >> iter 187000, loss: 11.198752
 >> iter 188000, loss: 11.840695
 >> iter 189000, loss: 10.646592
 >> iter 190000, loss: 10.225876
   Number of active neurons: 2
 >> iter 191000, loss: 10.970992
 >> iter 192000, loss: 11.387242
 >> iter 193000, loss: 10.475098
 >> iter 194000, loss: 10.920818
 >> iter 195000, loss: 12.342873
 >> iter 196000, loss: 11.231530
 >> iter 197000, loss: 10.908665
 >> iter 198000, loss: 10.986254
 >> iter 199000, loss: 11.118572
 >> iter 200000, loss: 11.551961
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.302969
 >> iter 2000, loss: 14.108286
 >> iter 3000, loss: 12.313100
 >> iter 4000, loss: 11.844010
 >> iter 5000, loss: 11.750844
 >> iter 6000, loss: 10.857048
 >> iter 7000, loss: 11.564956
 >> iter 8000, loss: 10.739429
 >> iter 9000, loss: 11.536618
 >> iter 10000, loss: 11.433188
   Number of active neurons: 2
 >> iter 11000, loss: 11.054672
 >> iter 12000, loss: 11.245231
 >> iter 13000, loss: 11.378774
 >> iter 14000, loss: 10.849741
 >> iter 15000, loss: 12.042051
 >> iter 16000, loss: 11.889276
 >> iter 17000, loss: 10.829561
 >> iter 18000, loss: 10.809019
 >> iter 19000, loss: 10.882498
 >> iter 20000, loss: 11.108381
   Number of active neurons: 2
 >> iter 21000, loss: 11.398677
 >> iter 22000, loss: 10.756621
 >> iter 23000, loss: 10.731585
 >> iter 24000, loss: 10.783527
 >> iter 25000, loss: 11.209081
 >> iter 26000, loss: 11.324532
 >> iter 27000, loss: 11.614836
 >> iter 28000, loss: 10.857913
 >> iter 29000, loss: 10.846480
 >> iter 30000, loss: 10.520842
   Number of active neurons: 2
 >> iter 31000, loss: 10.317646
 >> iter 32000, loss: 10.788285
 >> iter 33000, loss: 10.361092
 >> iter 34000, loss: 10.790971
 >> iter 35000, loss: 10.706283
 >> iter 36000, loss: 11.032951
 >> iter 37000, loss: 12.234575
 >> iter 38000, loss: 10.731787
 >> iter 39000, loss: 11.438032
 >> iter 40000, loss: 10.795960
   Number of active neurons: 2
 >> iter 41000, loss: 10.921213
 >> iter 42000, loss: 11.040022
 >> iter 43000, loss: 10.699157
 >> iter 44000, loss: 10.628994
 >> iter 45000, loss: 10.865495
 >> iter 46000, loss: 10.698737
 >> iter 47000, loss: 10.681552
 >> iter 48000, loss: 11.485876
 >> iter 49000, loss: 12.845808
 >> iter 50000, loss: 11.920761
   Number of active neurons: 2
 >> iter 51000, loss: 10.608448
 >> iter 52000, loss: 10.189353
 >> iter 53000, loss: 10.774718
 >> iter 54000, loss: 11.829118
 >> iter 55000, loss: 11.396665
 >> iter 56000, loss: 10.698583
 >> iter 57000, loss: 11.659326
 >> iter 58000, loss: 11.124601
 >> iter 59000, loss: 11.821422
 >> iter 60000, loss: 12.040596
   Number of active neurons: 2
 >> iter 61000, loss: 11.817887
 >> iter 62000, loss: 11.513421
 >> iter 63000, loss: 10.697798
 >> iter 64000, loss: 10.382313
 >> iter 65000, loss: 11.143045
 >> iter 66000, loss: 10.733623
 >> iter 67000, loss: 10.661901
 >> iter 68000, loss: 10.644388
 >> iter 69000, loss: 10.831191
 >> iter 70000, loss: 10.345704
   Number of active neurons: 2
 >> iter 71000, loss: 11.137886
 >> iter 72000, loss: 10.299007
 >> iter 73000, loss: 10.286791
 >> iter 74000, loss: 10.391955
 >> iter 75000, loss: 10.954316
 >> iter 76000, loss: 11.138267
 >> iter 77000, loss: 10.975748
 >> iter 78000, loss: 10.724963
 >> iter 79000, loss: 10.771998
 >> iter 80000, loss: 10.681577
   Number of active neurons: 2
 >> iter 81000, loss: 11.022708
 >> iter 82000, loss: 10.886404
 >> iter 83000, loss: 11.148826
 >> iter 84000, loss: 11.571960
 >> iter 85000, loss: 12.964693
 >> iter 86000, loss: 11.708237
 >> iter 87000, loss: 12.310787
 >> iter 88000, loss: 10.967175
 >> iter 89000, loss: 10.639041
 >> iter 90000, loss: 10.678281
   Number of active neurons: 2
 >> iter 91000, loss: 12.175159
 >> iter 92000, loss: 12.850266
 >> iter 93000, loss: 11.780887
 >> iter 94000, loss: 10.601918
 >> iter 95000, loss: 10.561796
 >> iter 96000, loss: 10.287116
 >> iter 97000, loss: 10.369823
 >> iter 98000, loss: 9.988487
 >> iter 99000, loss: 9.904577
 >> iter 100000, loss: 10.469710
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.181116
 >> iter 2000, loss: 13.719469
 >> iter 3000, loss: 12.342499
 >> iter 4000, loss: 11.132198
 >> iter 5000, loss: 10.987758
 >> iter 6000, loss: 10.862306
 >> iter 7000, loss: 10.945628
 >> iter 8000, loss: 10.206868
 >> iter 9000, loss: 10.051867
 >> iter 10000, loss: 10.965584
   Number of active neurons: 2
 >> iter 11000, loss: 10.940137
 >> iter 12000, loss: 10.524233
 >> iter 13000, loss: 10.682344
 >> iter 14000, loss: 10.934654
 >> iter 15000, loss: 11.975408
 >> iter 16000, loss: 11.090124
 >> iter 17000, loss: 11.142427
 >> iter 18000, loss: 10.676308
 >> iter 19000, loss: 11.417919
 >> iter 20000, loss: 10.627560
   Number of active neurons: 2
 >> iter 21000, loss: 11.313213
 >> iter 22000, loss: 10.781483
 >> iter 23000, loss: 10.358608
 >> iter 24000, loss: 10.297923
 >> iter 25000, loss: 11.430980
 >> iter 26000, loss: 11.120318
 >> iter 27000, loss: 11.236563
 >> iter 28000, loss: 10.722629
 >> iter 29000, loss: 10.793989
 >> iter 30000, loss: 10.935995
   Number of active neurons: 2
 >> iter 31000, loss: 10.561916
 >> iter 32000, loss: 10.138854
 >> iter 33000, loss: 10.636083
 >> iter 34000, loss: 12.092278
 >> iter 35000, loss: 10.805830
 >> iter 36000, loss: 10.271765
 >> iter 37000, loss: 11.289659
 >> iter 38000, loss: 10.838706
 >> iter 39000, loss: 10.408925
 >> iter 40000, loss: 10.975014
   Number of active neurons: 2
 >> iter 41000, loss: 10.973842
 >> iter 42000, loss: 10.934153
 >> iter 43000, loss: 10.514650
 >> iter 44000, loss: 11.046874
 >> iter 45000, loss: 12.092815
 >> iter 46000, loss: 11.499226
 >> iter 47000, loss: 11.001863
 >> iter 48000, loss: 12.338531
 >> iter 49000, loss: 11.091966
 >> iter 50000, loss: 10.601812
   Number of active neurons: 2
 >> iter 51000, loss: 11.952005
 >> iter 52000, loss: 11.689796
 >> iter 53000, loss: 11.232419
 >> iter 54000, loss: 10.878813
 >> iter 55000, loss: 10.395046
 >> iter 56000, loss: 10.572679
 >> iter 57000, loss: 11.000954
 >> iter 58000, loss: 10.992140
 >> iter 59000, loss: 10.562235
 >> iter 60000, loss: 10.590482
   Number of active neurons: 2
 >> iter 61000, loss: 10.551456
 >> iter 62000, loss: 10.024822
 >> iter 63000, loss: 11.031795
 >> iter 64000, loss: 11.767424
 >> iter 65000, loss: 11.547335
 >> iter 66000, loss: 10.880877
 >> iter 67000, loss: 11.078085
 >> iter 68000, loss: 11.390912
 >> iter 69000, loss: 10.588272
 >> iter 70000, loss: 10.281942
   Number of active neurons: 2
 >> iter 71000, loss: 11.935197
 >> iter 72000, loss: 11.220731
 >> iter 73000, loss: 10.787096
 >> iter 74000, loss: 10.549781
 >> iter 75000, loss: 10.774163
 >> iter 76000, loss: 10.293064
 >> iter 77000, loss: 10.944390
 >> iter 78000, loss: 10.865569
 >> iter 79000, loss: 11.017353
 >> iter 80000, loss: 10.344604
   Number of active neurons: 2
 >> iter 81000, loss: 11.921996
 >> iter 82000, loss: 11.789068
 >> iter 83000, loss: 11.085196
 >> iter 84000, loss: 10.905651
 >> iter 85000, loss: 11.519030
 >> iter 86000, loss: 10.402750
 >> iter 87000, loss: 11.115043
 >> iter 88000, loss: 11.202248
 >> iter 89000, loss: 11.666639
 >> iter 90000, loss: 10.753752
   Number of active neurons: 2
 >> iter 91000, loss: 10.749416
 >> iter 92000, loss: 10.413658
 >> iter 93000, loss: 10.967415
 >> iter 94000, loss: 13.364840
 >> iter 95000, loss: 14.095445
 >> iter 96000, loss: 13.944400
 >> iter 97000, loss: 12.173167
 >> iter 98000, loss: 11.103106
 >> iter 99000, loss: 10.569241
 >> iter 100000, loss: 10.252981
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 9.87780244395
   - Test - Long: 2.00489975501
   - Test - Big: 10.027899721
   - Test - A: 26.5915605626
   - Test - B: 66.0755949603
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.530464
 >> iter 2000, loss: 14.097207
 >> iter 3000, loss: 12.266753
 >> iter 4000, loss: 11.558660
 >> iter 5000, loss: 11.347183
 >> iter 6000, loss: 11.194728
 >> iter 7000, loss: 10.942423
 >> iter 8000, loss: 11.041327
 >> iter 9000, loss: 11.829281
 >> iter 10000, loss: 11.031820
   Number of active neurons: 2
 >> iter 11000, loss: 11.106854
 >> iter 12000, loss: 10.186879
 >> iter 13000, loss: 10.631442
 >> iter 14000, loss: 10.581743
 >> iter 15000, loss: 10.603255
 >> iter 16000, loss: 11.086191
 >> iter 17000, loss: 10.889459
 >> iter 18000, loss: 10.959268
 >> iter 19000, loss: 10.957368
 >> iter 20000, loss: 10.457824
   Number of active neurons: 2
 >> iter 21000, loss: 10.742957
 >> iter 22000, loss: 11.034360
 >> iter 23000, loss: 11.033919
 >> iter 24000, loss: 12.126530
 >> iter 25000, loss: 11.328982
 >> iter 26000, loss: 11.738287
 >> iter 27000, loss: 11.194172
 >> iter 28000, loss: 10.602785
 >> iter 29000, loss: 11.149936
 >> iter 30000, loss: 12.056297
   Number of active neurons: 2
 >> iter 31000, loss: 11.206303
 >> iter 32000, loss: 10.550051
 >> iter 33000, loss: 10.588715
 >> iter 34000, loss: 10.460212
 >> iter 35000, loss: 10.699124
 >> iter 36000, loss: 10.482149
 >> iter 37000, loss: 11.911796
 >> iter 38000, loss: 10.610861
 >> iter 39000, loss: 11.732891
 >> iter 40000, loss: 11.281191
   Number of active neurons: 2
 >> iter 41000, loss: 10.756708
 >> iter 42000, loss: 11.273508
 >> iter 43000, loss: 10.822492
 >> iter 44000, loss: 10.876096
 >> iter 45000, loss: 14.673392
 >> iter 46000, loss: 13.793390
 >> iter 47000, loss: 11.922737
 >> iter 48000, loss: 10.356985
 >> iter 49000, loss: 10.788479
 >> iter 50000, loss: 10.597841
   Number of active neurons: 2
 >> iter 51000, loss: 10.994991
 >> iter 52000, loss: 10.463293
 >> iter 53000, loss: 11.101384
 >> iter 54000, loss: 11.062997
 >> iter 55000, loss: 12.556125
 >> iter 56000, loss: 11.444569
 >> iter 57000, loss: 10.825861
 >> iter 58000, loss: 11.063329
 >> iter 59000, loss: 11.109334
 >> iter 60000, loss: 11.519861
   Number of active neurons: 2
 >> iter 61000, loss: 11.525186
 >> iter 62000, loss: 11.278451
 >> iter 63000, loss: 11.021387
 >> iter 64000, loss: 10.397546
 >> iter 65000, loss: 10.455889
 >> iter 66000, loss: 10.503616
 >> iter 67000, loss: 10.455666
 >> iter 68000, loss: 11.206088
 >> iter 69000, loss: 10.865390
 >> iter 70000, loss: 10.493335
   Number of active neurons: 2
 >> iter 71000, loss: 11.962238
 >> iter 72000, loss: 12.052135
 >> iter 73000, loss: 11.769528
 >> iter 74000, loss: 11.551537
 >> iter 75000, loss: 11.523869
 >> iter 76000, loss: 12.404567
 >> iter 77000, loss: 12.774181
 >> iter 78000, loss: 11.061235
 >> iter 79000, loss: 11.661167
 >> iter 80000, loss: 10.304673
   Number of active neurons: 2
 >> iter 81000, loss: 10.620448
 >> iter 82000, loss: 11.227600
 >> iter 83000, loss: 10.959384
 >> iter 84000, loss: 10.315115
 >> iter 85000, loss: 10.587421
 >> iter 86000, loss: 10.498300
 >> iter 87000, loss: 11.724417
 >> iter 88000, loss: 10.903571
 >> iter 89000, loss: 10.743048
 >> iter 90000, loss: 10.565704
   Number of active neurons: 2
 >> iter 91000, loss: 10.375000
 >> iter 92000, loss: 11.483639
 >> iter 93000, loss: 10.704456
 >> iter 94000, loss: 11.096272
 >> iter 95000, loss: 10.768730
 >> iter 96000, loss: 10.355009
 >> iter 97000, loss: 10.863369
 >> iter 98000, loss: 11.419764
 >> iter 99000, loss: 12.362768
 >> iter 100000, loss: 10.681070
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 21.037289
 >> iter 2000, loss: 18.735213
 >> iter 3000, loss: 17.828261
 >> iter 4000, loss: 17.557538
 >> iter 5000, loss: 17.393953
 >> iter 6000, loss: 17.399767
 >> iter 7000, loss: 17.334485
 >> iter 8000, loss: 17.377683
 >> iter 9000, loss: 17.326842
 >> iter 10000, loss: 17.376461
   Number of active neurons: 0
 >> iter 11000, loss: 17.324224
 >> iter 12000, loss: 17.376003
 >> iter 13000, loss: 17.320235
 >> iter 14000, loss: 17.374907
 >> iter 15000, loss: 17.320795
 >> iter 16000, loss: 17.374885
 >> iter 17000, loss: 17.322167
 >> iter 18000, loss: 17.374664
 >> iter 19000, loss: 17.320916
 >> iter 20000, loss: 17.374841
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 13.599636
 >> iter 22000, loss: 12.263851
 >> iter 23000, loss: 11.962185
 >> iter 24000, loss: 11.147096
 >> iter 25000, loss: 11.498045
 >> iter 26000, loss: 11.041670
 >> iter 27000, loss: 11.311449
 >> iter 28000, loss: 11.548365
 >> iter 29000, loss: 11.718197
 >> iter 30000, loss: 12.265566
   Number of active neurons: 2
 >> iter 31000, loss: 11.802408
 >> iter 32000, loss: 12.031658
 >> iter 33000, loss: 11.414311
 >> iter 34000, loss: 11.065670
 >> iter 35000, loss: 10.709769
 >> iter 36000, loss: 10.589888
 >> iter 37000, loss: 10.661867
 >> iter 38000, loss: 10.427484
 >> iter 39000, loss: 10.677808
 >> iter 40000, loss: 11.187512
   Number of active neurons: 2
 >> iter 41000, loss: 10.669253
 >> iter 42000, loss: 12.440499
 >> iter 43000, loss: 11.439374
 >> iter 44000, loss: 10.469729
 >> iter 45000, loss: 11.063697
 >> iter 46000, loss: 11.059605
 >> iter 47000, loss: 10.768899
 >> iter 48000, loss: 10.970075
 >> iter 49000, loss: 10.583842
 >> iter 50000, loss: 10.157048
   Number of active neurons: 2
 >> iter 51000, loss: 10.574244
 >> iter 52000, loss: 11.136186
 >> iter 53000, loss: 11.143213
 >> iter 54000, loss: 11.144228
 >> iter 55000, loss: 11.124874
 >> iter 56000, loss: 10.762985
 >> iter 57000, loss: 10.756319
 >> iter 58000, loss: 12.307505
 >> iter 59000, loss: 11.835610
 >> iter 60000, loss: 12.473166
   Number of active neurons: 2
 >> iter 61000, loss: 11.486337
 >> iter 62000, loss: 10.731594
 >> iter 63000, loss: 11.079894
 >> iter 64000, loss: 10.454374
 >> iter 65000, loss: 10.510828
 >> iter 66000, loss: 11.426550
 >> iter 67000, loss: 10.487920
 >> iter 68000, loss: 10.929932
 >> iter 69000, loss: 11.118980
 >> iter 70000, loss: 11.037284
   Number of active neurons: 2
 >> iter 71000, loss: 10.629038
 >> iter 72000, loss: 10.600371
 >> iter 73000, loss: 11.001876
 >> iter 74000, loss: 10.634301
 >> iter 75000, loss: 10.182200
 >> iter 76000, loss: 10.049469
 >> iter 77000, loss: 10.376937
 >> iter 78000, loss: 10.814132
 >> iter 79000, loss: 10.944139
 >> iter 80000, loss: 11.553705
   Number of active neurons: 2
 >> iter 81000, loss: 11.458209
 >> iter 82000, loss: 10.652585
 >> iter 83000, loss: 10.370090
 >> iter 84000, loss: 10.648605
 >> iter 85000, loss: 10.294318
 >> iter 86000, loss: 10.318319
 >> iter 87000, loss: 11.051812
 >> iter 88000, loss: 10.644940
 >> iter 89000, loss: 10.784532
 >> iter 90000, loss: 10.332499
   Number of active neurons: 2
 >> iter 91000, loss: 10.144536
 >> iter 92000, loss: 10.954231
 >> iter 93000, loss: 10.620497
 >> iter 94000, loss: 11.039837
 >> iter 95000, loss: 11.025760
 >> iter 96000, loss: 10.597219
 >> iter 97000, loss: 10.962153
 >> iter 98000, loss: 10.722290
 >> iter 99000, loss: 10.650456
 >> iter 100000, loss: 10.345594
   Number of active neurons: 2
 >> iter 101000, loss: 11.071330
 >> iter 102000, loss: 10.864970
 >> iter 103000, loss: 10.942279
 >> iter 104000, loss: 11.517381
 >> iter 105000, loss: 10.987513
 >> iter 106000, loss: 12.822515
 >> iter 107000, loss: 13.770121
 >> iter 108000, loss: 12.145980
 >> iter 109000, loss: 11.455799
 >> iter 110000, loss: 10.623964
   Number of active neurons: 2
 >> iter 111000, loss: 10.698930
 >> iter 112000, loss: 10.859815
 >> iter 113000, loss: 11.857347
 >> iter 114000, loss: 12.466802
 >> iter 115000, loss: 11.822450
 >> iter 116000, loss: 11.553680
 >> iter 117000, loss: 11.866406
 >> iter 118000, loss: 10.683298
 >> iter 119000, loss: 10.889122
 >> iter 120000, loss: 10.405003
   Number of active neurons: 2
 >> iter 121000, loss: 11.394702
 >> iter 122000, loss: 11.169494
 >> iter 123000, loss: 10.736723
 >> iter 124000, loss: 10.777902
 >> iter 125000, loss: 10.368046
 >> iter 126000, loss: 10.740516
 >> iter 127000, loss: 12.272741
 >> iter 128000, loss: 11.516645
 >> iter 129000, loss: 10.696285
 >> iter 130000, loss: 11.385788
   Number of active neurons: 2
 >> iter 131000, loss: 11.252591
 >> iter 132000, loss: 10.933741
 >> iter 133000, loss: 12.166691
 >> iter 134000, loss: 10.884316
 >> iter 135000, loss: 10.365238
 >> iter 136000, loss: 10.269830
 >> iter 137000, loss: 10.605692
 >> iter 138000, loss: 10.727779
 >> iter 139000, loss: 11.325895
 >> iter 140000, loss: 10.739835
   Number of active neurons: 2
 >> iter 141000, loss: 11.460176
 >> iter 142000, loss: 11.008739
 >> iter 143000, loss: 12.396281
 >> iter 144000, loss: 11.102096
 >> iter 145000, loss: 10.380930
 >> iter 146000, loss: 10.555737
 >> iter 147000, loss: 13.337418
 >> iter 148000, loss: 11.697338
 >> iter 149000, loss: 11.344176
 >> iter 150000, loss: 11.636648
   Number of active neurons: 2
 >> iter 151000, loss: 10.824357
 >> iter 152000, loss: 11.808642
 >> iter 153000, loss: 11.492558
 >> iter 154000, loss: 12.140557
 >> iter 155000, loss: 11.668497
 >> iter 156000, loss: 11.499151
 >> iter 157000, loss: 10.892981
 >> iter 158000, loss: 10.616509
 >> iter 159000, loss: 10.653218
 >> iter 160000, loss: 10.821360
   Number of active neurons: 2
 >> iter 161000, loss: 11.366618
 >> iter 162000, loss: 10.655988
 >> iter 163000, loss: 11.102834
 >> iter 164000, loss: 11.868053
 >> iter 165000, loss: 13.842587
 >> iter 166000, loss: 12.904637
 >> iter 167000, loss: 14.110697
 >> iter 168000, loss: 12.157187
 >> iter 169000, loss: 11.798282
 >> iter 170000, loss: 11.171988
   Number of active neurons: 2
 >> iter 171000, loss: 10.561395
 >> iter 172000, loss: 10.776291
 >> iter 173000, loss: 11.444790
 >> iter 174000, loss: 11.032442
 >> iter 175000, loss: 10.627160
 >> iter 176000, loss: 11.292559
 >> iter 177000, loss: 12.211121
 >> iter 178000, loss: 11.213851
 >> iter 179000, loss: 10.810575
 >> iter 180000, loss: 11.709398
   Number of active neurons: 2
 >> iter 181000, loss: 11.656334
 >> iter 182000, loss: 11.156167
 >> iter 183000, loss: 11.412280
 >> iter 184000, loss: 10.572197
 >> iter 185000, loss: 10.923118
 >> iter 186000, loss: 10.188859
 >> iter 187000, loss: 10.142878
 >> iter 188000, loss: 9.889043
 >> iter 189000, loss: 10.093059
 >> iter 190000, loss: 10.508405
   Number of active neurons: 2
 >> iter 191000, loss: 10.564068
 >> iter 192000, loss: 10.056012
 >> iter 193000, loss: 10.386062
 >> iter 194000, loss: 10.341889
 >> iter 195000, loss: 9.582562
 >> iter 196000, loss: 11.495104
 >> iter 197000, loss: 12.204657
 >> iter 198000, loss: 10.540223
 >> iter 199000, loss: 10.488785
 >> iter 200000, loss: 11.256263
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.303685
 >> iter 2000, loss: 14.429324
 >> iter 3000, loss: 14.380950
 >> iter 4000, loss: 13.675340
 >> iter 5000, loss: 14.374767
 >> iter 6000, loss: 14.996841
 >> iter 7000, loss: 13.620994
 >> iter 8000, loss: 11.154895
 >> iter 9000, loss: 13.532990
 >> iter 10000, loss: 14.048677
   Number of active neurons: 2
 >> iter 11000, loss: 13.107985
 >> iter 12000, loss: 11.007800
 >> iter 13000, loss: 13.877103
 >> iter 14000, loss: 13.970054
 >> iter 15000, loss: 13.240674
 >> iter 16000, loss: 14.710718
 >> iter 17000, loss: 15.056027
 >> iter 18000, loss: 13.226950
 >> iter 19000, loss: 15.142781
 >> iter 20000, loss: 14.819835
   Number of active neurons: 2
 >> iter 21000, loss: 14.626370
 >> iter 22000, loss: 13.144361
 >> iter 23000, loss: 11.230121
 >> iter 24000, loss: 10.870148
 >> iter 25000, loss: 10.594357
 >> iter 26000, loss: 10.494416
 >> iter 27000, loss: 11.125319
 >> iter 28000, loss: 10.995051
 >> iter 29000, loss: 10.545893
 >> iter 30000, loss: 10.461889
   Number of active neurons: 2
 >> iter 31000, loss: 10.963582
 >> iter 32000, loss: 10.984333
 >> iter 33000, loss: 11.304385
 >> iter 34000, loss: 10.633007
 >> iter 35000, loss: 11.127367
 >> iter 36000, loss: 10.788635
 >> iter 37000, loss: 11.286059
 >> iter 38000, loss: 11.609861
 >> iter 39000, loss: 11.715549
 >> iter 40000, loss: 11.221250
   Number of active neurons: 2
 >> iter 41000, loss: 11.416787
 >> iter 42000, loss: 11.933781
 >> iter 43000, loss: 11.063735
 >> iter 44000, loss: 11.569035
 >> iter 45000, loss: 10.788660
 >> iter 46000, loss: 10.790745
 >> iter 47000, loss: 10.814621
 >> iter 48000, loss: 10.421409
 >> iter 49000, loss: 11.155827
 >> iter 50000, loss: 10.479305
   Number of active neurons: 2
 >> iter 51000, loss: 10.314786
 >> iter 52000, loss: 10.585268
 >> iter 53000, loss: 10.291053
 >> iter 54000, loss: 10.179586
 >> iter 55000, loss: 10.511527
 >> iter 56000, loss: 11.136530
 >> iter 57000, loss: 10.453884
 >> iter 58000, loss: 11.994024
 >> iter 59000, loss: 12.177489
 >> iter 60000, loss: 11.338056
   Number of active neurons: 2
 >> iter 61000, loss: 12.562877
 >> iter 62000, loss: 11.595397
 >> iter 63000, loss: 11.316845
 >> iter 64000, loss: 11.143790
 >> iter 65000, loss: 10.464345
 >> iter 66000, loss: 10.714154
 >> iter 67000, loss: 13.493199
 >> iter 68000, loss: 13.002043
 >> iter 69000, loss: 11.028804
 >> iter 70000, loss: 11.366414
   Number of active neurons: 2
 >> iter 71000, loss: 11.662699
 >> iter 72000, loss: 10.596273
 >> iter 73000, loss: 10.496862
 >> iter 74000, loss: 10.553144
 >> iter 75000, loss: 10.200610
 >> iter 76000, loss: 11.219575
 >> iter 77000, loss: 10.845665
 >> iter 78000, loss: 11.275670
 >> iter 79000, loss: 11.414582
 >> iter 80000, loss: 10.947926
   Number of active neurons: 2
 >> iter 81000, loss: 11.027386
 >> iter 82000, loss: 10.614039
 >> iter 83000, loss: 10.311168
 >> iter 84000, loss: 11.312257
 >> iter 85000, loss: 11.517447
 >> iter 86000, loss: 11.587873
 >> iter 87000, loss: 10.877776
 >> iter 88000, loss: 10.248356
 >> iter 89000, loss: 10.495406
 >> iter 90000, loss: 10.317845
   Number of active neurons: 2
 >> iter 91000, loss: 12.199485
 >> iter 92000, loss: 10.998865
 >> iter 93000, loss: 10.838321
 >> iter 94000, loss: 10.943442
 >> iter 95000, loss: 11.469217
 >> iter 96000, loss: 10.727023
 >> iter 97000, loss: 10.792092
 >> iter 98000, loss: 10.292051
 >> iter 99000, loss: 10.314446
 >> iter 100000, loss: 10.676731
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 10.7777844443
   - Test - Long: 2.4798760062
   - Test - Big: 11.2038879611
   - Test - A: 26.4382374508
   - Test - B: 63.6424238384
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 21.037298
 >> iter 2000, loss: 18.735216
 >> iter 3000, loss: 17.828262
 >> iter 4000, loss: 17.557539
 >> iter 5000, loss: 17.393953
 >> iter 6000, loss: 17.399766
 >> iter 7000, loss: 17.334485
 >> iter 8000, loss: 17.377683
 >> iter 9000, loss: 17.326842
 >> iter 10000, loss: 17.376461
   Number of active neurons: 0
 >> iter 11000, loss: 17.324224
 >> iter 12000, loss: 17.376003
 >> iter 13000, loss: 17.320235
 >> iter 14000, loss: 17.374907
 >> iter 15000, loss: 17.320795
 >> iter 16000, loss: 17.374885
 >> iter 17000, loss: 17.322167
 >> iter 18000, loss: 17.374664
 >> iter 19000, loss: 17.320916
 >> iter 20000, loss: 17.374841
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 13.629636
 >> iter 22000, loss: 12.218809
 >> iter 23000, loss: 11.981413
 >> iter 24000, loss: 12.194747
 >> iter 25000, loss: 11.985771
 >> iter 26000, loss: 11.874012
 >> iter 27000, loss: 11.392567
 >> iter 28000, loss: 11.505176
 >> iter 29000, loss: 11.641398
 >> iter 30000, loss: 11.568122
   Number of active neurons: 2
 >> iter 31000, loss: 11.598918
 >> iter 32000, loss: 11.491242
 >> iter 33000, loss: 11.744647
 >> iter 34000, loss: 11.829822
 >> iter 35000, loss: 11.677300
 >> iter 36000, loss: 11.159238
 >> iter 37000, loss: 11.116494
 >> iter 38000, loss: 10.578824
 >> iter 39000, loss: 11.430878
 >> iter 40000, loss: 11.164113
   Number of active neurons: 2
 >> iter 41000, loss: 11.364848
 >> iter 42000, loss: 11.307924
 >> iter 43000, loss: 11.297324
 >> iter 44000, loss: 11.417136
 >> iter 45000, loss: 11.321697
 >> iter 46000, loss: 10.872191
 >> iter 47000, loss: 11.610796
 >> iter 48000, loss: 10.884946
 >> iter 49000, loss: 11.305762
 >> iter 50000, loss: 10.814985
   Number of active neurons: 2
 >> iter 51000, loss: 10.940630
 >> iter 52000, loss: 10.814375
 >> iter 53000, loss: 10.573199
 >> iter 54000, loss: 10.567159
 >> iter 55000, loss: 11.958142
 >> iter 56000, loss: 11.349711
 >> iter 57000, loss: 11.341486
 >> iter 58000, loss: 10.560952
 >> iter 59000, loss: 10.434945
 >> iter 60000, loss: 10.253841
   Number of active neurons: 2
 >> iter 61000, loss: 12.853955
 >> iter 62000, loss: 11.850812
 >> iter 63000, loss: 10.574402
 >> iter 64000, loss: 10.295622
 >> iter 65000, loss: 10.707401
 >> iter 66000, loss: 11.037751
 >> iter 67000, loss: 10.911745
 >> iter 68000, loss: 10.496442
 >> iter 69000, loss: 11.180711
 >> iter 70000, loss: 10.764858
   Number of active neurons: 2
 >> iter 71000, loss: 10.564269
 >> iter 72000, loss: 10.812535
 >> iter 73000, loss: 10.465933
 >> iter 74000, loss: 10.850880
 >> iter 75000, loss: 11.525624
 >> iter 76000, loss: 10.779503
 >> iter 77000, loss: 10.663753
 >> iter 78000, loss: 10.821883
 >> iter 79000, loss: 11.768805
 >> iter 80000, loss: 10.906584
   Number of active neurons: 2
 >> iter 81000, loss: 10.542672
 >> iter 82000, loss: 10.144164
 >> iter 83000, loss: 11.294058
 >> iter 84000, loss: 10.168668
 >> iter 85000, loss: 10.701916
 >> iter 86000, loss: 10.387026
 >> iter 87000, loss: 10.450796
 >> iter 88000, loss: 10.201551
 >> iter 89000, loss: 10.691857
 >> iter 90000, loss: 10.834352
   Number of active neurons: 2
 >> iter 91000, loss: 11.410760
 >> iter 92000, loss: 10.976603
 >> iter 93000, loss: 10.851069
 >> iter 94000, loss: 11.018229
 >> iter 95000, loss: 11.517736
 >> iter 96000, loss: 11.050094
 >> iter 97000, loss: 11.631922
 >> iter 98000, loss: 10.556989
 >> iter 99000, loss: 10.452915
 >> iter 100000, loss: 10.573424
   Number of active neurons: 2
 >> iter 101000, loss: 11.077745
 >> iter 102000, loss: 11.464884
 >> iter 103000, loss: 10.857233
 >> iter 104000, loss: 10.787520
 >> iter 105000, loss: 12.258932
 >> iter 106000, loss: 13.146775
 >> iter 107000, loss: 11.379019
 >> iter 108000, loss: 12.735045
 >> iter 109000, loss: 12.289104
 >> iter 110000, loss: 11.032779
   Number of active neurons: 2
 >> iter 111000, loss: 11.435966
 >> iter 112000, loss: 10.771960
 >> iter 113000, loss: 11.138868
 >> iter 114000, loss: 11.983643
 >> iter 115000, loss: 11.300440
 >> iter 116000, loss: 11.707933
 >> iter 117000, loss: 10.910920
 >> iter 118000, loss: 11.129248
 >> iter 119000, loss: 12.136696
 >> iter 120000, loss: 11.807888
   Number of active neurons: 2
 >> iter 121000, loss: 13.040142
 >> iter 122000, loss: 11.522806
 >> iter 123000, loss: 11.111929
 >> iter 124000, loss: 11.526802
 >> iter 125000, loss: 12.691057
 >> iter 126000, loss: 11.088571
 >> iter 127000, loss: 12.032295
 >> iter 128000, loss: 12.400468
 >> iter 129000, loss: 10.585251
 >> iter 130000, loss: 10.136165
   Number of active neurons: 2
 >> iter 131000, loss: 12.202039
 >> iter 132000, loss: 10.812777
 >> iter 133000, loss: 11.098743
 >> iter 134000, loss: 11.722305
 >> iter 135000, loss: 11.325086
 >> iter 136000, loss: 12.700375
 >> iter 137000, loss: 13.814084
 >> iter 138000, loss: 12.552569
 >> iter 139000, loss: 10.659883
 >> iter 140000, loss: 11.701774
   Number of active neurons: 2
 >> iter 141000, loss: 10.540225
 >> iter 142000, loss: 10.370174
 >> iter 143000, loss: 13.891714
 >> iter 144000, loss: 11.789418
 >> iter 145000, loss: 10.903947
 >> iter 146000, loss: 10.827709
 >> iter 147000, loss: 10.798423
 >> iter 148000, loss: 11.155342
 >> iter 149000, loss: 10.726486
 >> iter 150000, loss: 10.804369
   Number of active neurons: 2
 >> iter 151000, loss: 11.222811
 >> iter 152000, loss: 11.386656
 >> iter 153000, loss: 10.749177
 >> iter 154000, loss: 11.165311
 >> iter 155000, loss: 10.768742
 >> iter 156000, loss: 10.667910
 >> iter 157000, loss: 10.983559
 >> iter 158000, loss: 10.435221
 >> iter 159000, loss: 10.423223
 >> iter 160000, loss: 10.284107
   Number of active neurons: 2
 >> iter 161000, loss: 10.960502
 >> iter 162000, loss: 11.244619
 >> iter 163000, loss: 10.488419
 >> iter 164000, loss: 10.652112
 >> iter 165000, loss: 10.414441
 >> iter 166000, loss: 11.143923
 >> iter 167000, loss: 10.504847
 >> iter 168000, loss: 10.627401
 >> iter 169000, loss: 10.828011
 >> iter 170000, loss: 10.912355
   Number of active neurons: 2
 >> iter 171000, loss: 11.745087
 >> iter 172000, loss: 10.618622
 >> iter 173000, loss: 10.818198
 >> iter 174000, loss: 11.276842
 >> iter 175000, loss: 11.130924
 >> iter 176000, loss: 10.771598
 >> iter 177000, loss: 11.119920
 >> iter 178000, loss: 11.029354
 >> iter 179000, loss: 10.768665
 >> iter 180000, loss: 10.198922
   Number of active neurons: 2
 >> iter 181000, loss: 11.776886
 >> iter 182000, loss: 11.434877
 >> iter 183000, loss: 10.663725
 >> iter 184000, loss: 11.013943
 >> iter 185000, loss: 10.441200
 >> iter 186000, loss: 10.723134
 >> iter 187000, loss: 10.553037
 >> iter 188000, loss: 11.167706
 >> iter 189000, loss: 11.151314
 >> iter 190000, loss: 10.365894
   Number of active neurons: 2
 >> iter 191000, loss: 10.469804
 >> iter 192000, loss: 10.166438
 >> iter 193000, loss: 11.365092
 >> iter 194000, loss: 12.649483
 >> iter 195000, loss: 11.211254
 >> iter 196000, loss: 10.589274
 >> iter 197000, loss: 11.636753
 >> iter 198000, loss: 10.794070
 >> iter 199000, loss: 10.471588
 >> iter 200000, loss: 11.721397
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.065400
 >> iter 2000, loss: 15.260256
 >> iter 3000, loss: 14.663833
 >> iter 4000, loss: 14.221269
 >> iter 5000, loss: 13.708290
 >> iter 6000, loss: 12.094752
 >> iter 7000, loss: 11.969076
 >> iter 8000, loss: 11.524925
 >> iter 9000, loss: 10.671674
 >> iter 10000, loss: 11.782439
   Number of active neurons: 2
 >> iter 11000, loss: 11.343661
 >> iter 12000, loss: 11.531023
 >> iter 13000, loss: 11.809795
 >> iter 14000, loss: 12.446067
 >> iter 15000, loss: 12.304268
 >> iter 16000, loss: 12.290880
 >> iter 17000, loss: 11.980457
 >> iter 18000, loss: 11.753998
 >> iter 19000, loss: 11.549824
 >> iter 20000, loss: 12.108751
   Number of active neurons: 2
 >> iter 21000, loss: 12.441694
 >> iter 22000, loss: 11.361708
 >> iter 23000, loss: 11.114845
 >> iter 24000, loss: 11.913068
 >> iter 25000, loss: 11.566417
 >> iter 26000, loss: 10.692085
 >> iter 27000, loss: 10.944199
 >> iter 28000, loss: 11.267385
 >> iter 29000, loss: 11.288072
 >> iter 30000, loss: 11.364804
   Number of active neurons: 2
 >> iter 31000, loss: 11.743210
 >> iter 32000, loss: 10.954347
 >> iter 33000, loss: 10.280578
 >> iter 34000, loss: 10.373305
 >> iter 35000, loss: 10.784149
 >> iter 36000, loss: 11.035887
 >> iter 37000, loss: 10.664736
 >> iter 38000, loss: 10.915028
 >> iter 39000, loss: 10.915593
 >> iter 40000, loss: 10.906016
   Number of active neurons: 2
 >> iter 41000, loss: 11.549811
 >> iter 42000, loss: 11.128697
 >> iter 43000, loss: 10.863973
 >> iter 44000, loss: 11.570827
 >> iter 45000, loss: 10.870852
 >> iter 46000, loss: 11.068858
 >> iter 47000, loss: 10.729273
 >> iter 48000, loss: 10.668735
 >> iter 49000, loss: 13.442518
 >> iter 50000, loss: 11.912007
   Number of active neurons: 2
 >> iter 51000, loss: 10.970599
 >> iter 52000, loss: 10.524450
 >> iter 53000, loss: 10.955674
 >> iter 54000, loss: 11.482915
 >> iter 55000, loss: 11.146838
 >> iter 56000, loss: 10.977337
 >> iter 57000, loss: 10.924687
 >> iter 58000, loss: 10.686056
 >> iter 59000, loss: 10.948473
 >> iter 60000, loss: 10.476212
   Number of active neurons: 2
 >> iter 61000, loss: 11.459142
 >> iter 62000, loss: 10.655508
 >> iter 63000, loss: 10.441788
 >> iter 64000, loss: 10.102712
 >> iter 65000, loss: 12.902046
 >> iter 66000, loss: 13.706398
 >> iter 67000, loss: 11.290203
 >> iter 68000, loss: 11.151913
 >> iter 69000, loss: 11.233272
 >> iter 70000, loss: 10.572979
   Number of active neurons: 2
 >> iter 71000, loss: 10.353437
 >> iter 72000, loss: 9.901771
 >> iter 73000, loss: 10.268727
 >> iter 74000, loss: 10.779160
 >> iter 75000, loss: 11.249430
 >> iter 76000, loss: 10.492329
 >> iter 77000, loss: 11.305954
 >> iter 78000, loss: 11.460201
 >> iter 79000, loss: 11.810486
 >> iter 80000, loss: 10.936731
   Number of active neurons: 2
 >> iter 81000, loss: 11.105470
 >> iter 82000, loss: 10.547555
 >> iter 83000, loss: 11.994304
 >> iter 84000, loss: 11.252720
 >> iter 85000, loss: 10.858722
 >> iter 86000, loss: 10.802288
 >> iter 87000, loss: 10.465475
 >> iter 88000, loss: 10.529590
 >> iter 89000, loss: 11.552267
 >> iter 90000, loss: 11.188834
   Number of active neurons: 2
 >> iter 91000, loss: 10.759101
 >> iter 92000, loss: 11.731864
 >> iter 93000, loss: 11.361918
 >> iter 94000, loss: 10.654108
 >> iter 95000, loss: 10.961117
 >> iter 96000, loss: 10.473016
 >> iter 97000, loss: 10.694719
 >> iter 98000, loss: 11.557213
 >> iter 99000, loss: 12.812410
 >> iter 100000, loss: 11.396962
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.429664
 >> iter 2000, loss: 14.099805
 >> iter 3000, loss: 12.847360
 >> iter 4000, loss: 11.663880
 >> iter 5000, loss: 11.788978
 >> iter 6000, loss: 11.384619
 >> iter 7000, loss: 11.643882
 >> iter 8000, loss: 11.106981
 >> iter 9000, loss: 11.384379
 >> iter 10000, loss: 11.854604
   Number of active neurons: 2
 >> iter 11000, loss: 11.194014
 >> iter 12000, loss: 10.877701
 >> iter 13000, loss: 10.884524
 >> iter 14000, loss: 11.619230
 >> iter 15000, loss: 11.208483
 >> iter 16000, loss: 10.981807
 >> iter 17000, loss: 11.507429
 >> iter 18000, loss: 11.019726
 >> iter 19000, loss: 11.021514
 >> iter 20000, loss: 11.006827
   Number of active neurons: 2
 >> iter 21000, loss: 10.582379
 >> iter 22000, loss: 10.450395
 >> iter 23000, loss: 10.468803
 >> iter 24000, loss: 11.708120
 >> iter 25000, loss: 11.088783
 >> iter 26000, loss: 10.531900
 >> iter 27000, loss: 10.717768
 >> iter 28000, loss: 10.624502
 >> iter 29000, loss: 10.720668
 >> iter 30000, loss: 12.158294
   Number of active neurons: 2
 >> iter 31000, loss: 10.808111
 >> iter 32000, loss: 10.908009
 >> iter 33000, loss: 11.378405
 >> iter 34000, loss: 11.311839
 >> iter 35000, loss: 10.632166
 >> iter 36000, loss: 10.065142
 >> iter 37000, loss: 10.034218
 >> iter 38000, loss: 10.336278
 >> iter 39000, loss: 10.666018
 >> iter 40000, loss: 10.543275
   Number of active neurons: 2
 >> iter 41000, loss: 10.828056
 >> iter 42000, loss: 11.014827
 >> iter 43000, loss: 11.144828
 >> iter 44000, loss: 10.771874
 >> iter 45000, loss: 10.423786
 >> iter 46000, loss: 10.216232
 >> iter 47000, loss: 11.097896
 >> iter 48000, loss: 10.687222
 >> iter 49000, loss: 10.659438
 >> iter 50000, loss: 10.781262
   Number of active neurons: 2
 >> iter 51000, loss: 10.556276
 >> iter 52000, loss: 10.695501
 >> iter 53000, loss: 10.625419
 >> iter 54000, loss: 10.421288
 >> iter 55000, loss: 10.925479
 >> iter 56000, loss: 11.129053
 >> iter 57000, loss: 10.445760
 >> iter 58000, loss: 11.218464
 >> iter 59000, loss: 11.151591
 >> iter 60000, loss: 10.983277
   Number of active neurons: 2
 >> iter 61000, loss: 10.810066
 >> iter 62000, loss: 10.548554
 >> iter 63000, loss: 11.040171
 >> iter 64000, loss: 10.703130
 >> iter 65000, loss: 10.416795
 >> iter 66000, loss: 10.896523
 >> iter 67000, loss: 10.795455
 >> iter 68000, loss: 11.332457
 >> iter 69000, loss: 11.859761
 >> iter 70000, loss: 10.905993
   Number of active neurons: 2
 >> iter 71000, loss: 11.026879
 >> iter 72000, loss: 10.833583
 >> iter 73000, loss: 11.505015
 >> iter 74000, loss: 11.942033
 >> iter 75000, loss: 11.587768
 >> iter 76000, loss: 10.829445
 >> iter 77000, loss: 10.500454
 >> iter 78000, loss: 10.848458
 >> iter 79000, loss: 9.977996
 >> iter 80000, loss: 10.783340
   Number of active neurons: 2
 >> iter 81000, loss: 12.180568
 >> iter 82000, loss: 11.634795
 >> iter 83000, loss: 10.843793
 >> iter 84000, loss: 10.643715
 >> iter 85000, loss: 10.944824
 >> iter 86000, loss: 10.607475
 >> iter 87000, loss: 10.478621
 >> iter 88000, loss: 11.683235
 >> iter 89000, loss: 11.138243
 >> iter 90000, loss: 10.626977
   Number of active neurons: 2
 >> iter 91000, loss: 11.957372
 >> iter 92000, loss: 12.165095
 >> iter 93000, loss: 11.596143
 >> iter 94000, loss: 11.304556
 >> iter 95000, loss: 11.446861
 >> iter 96000, loss: 10.285823
 >> iter 97000, loss: 10.852628
 >> iter 98000, loss: 10.657812
 >> iter 99000, loss: 12.966693
 >> iter 100000, loss: 11.563709
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.473747
 >> iter 2000, loss: 14.114891
 >> iter 3000, loss: 12.541177
 >> iter 4000, loss: 11.408629
 >> iter 5000, loss: 11.285733
 >> iter 6000, loss: 10.795581
 >> iter 7000, loss: 10.731384
 >> iter 8000, loss: 11.040517
 >> iter 9000, loss: 11.582173
 >> iter 10000, loss: 11.436885
   Number of active neurons: 2
 >> iter 11000, loss: 11.148236
 >> iter 12000, loss: 11.653533
 >> iter 13000, loss: 11.260266
 >> iter 14000, loss: 11.221668
 >> iter 15000, loss: 11.102324
 >> iter 16000, loss: 12.374956
 >> iter 17000, loss: 12.205086
 >> iter 18000, loss: 12.097193
 >> iter 19000, loss: 11.333962
 >> iter 20000, loss: 11.806667
   Number of active neurons: 2
 >> iter 21000, loss: 11.663689
 >> iter 22000, loss: 10.957733
 >> iter 23000, loss: 10.846173
 >> iter 24000, loss: 10.607415
 >> iter 25000, loss: 10.791630
 >> iter 26000, loss: 11.122078
 >> iter 27000, loss: 11.196075
 >> iter 28000, loss: 10.947456
 >> iter 29000, loss: 11.227504
 >> iter 30000, loss: 12.025039
   Number of active neurons: 2
 >> iter 31000, loss: 10.634438
 >> iter 32000, loss: 11.371523
 >> iter 33000, loss: 11.205389
 >> iter 34000, loss: 10.515998
 >> iter 35000, loss: 10.780564
 >> iter 36000, loss: 10.565110
 >> iter 37000, loss: 11.337846
 >> iter 38000, loss: 10.566837
 >> iter 39000, loss: 10.709719
 >> iter 40000, loss: 10.239023
   Number of active neurons: 2
 >> iter 41000, loss: 10.739659
 >> iter 42000, loss: 10.644216
 >> iter 43000, loss: 10.964692
 >> iter 44000, loss: 11.361554
 >> iter 45000, loss: 10.673661
 >> iter 46000, loss: 10.558175
 >> iter 47000, loss: 11.479760
 >> iter 48000, loss: 11.064532
 >> iter 49000, loss: 11.203477
 >> iter 50000, loss: 10.700392
   Number of active neurons: 2
 >> iter 51000, loss: 10.561000
 >> iter 52000, loss: 11.232920
 >> iter 53000, loss: 12.067354
 >> iter 54000, loss: 10.951426
 >> iter 55000, loss: 10.253749
 >> iter 56000, loss: 10.575376
 >> iter 57000, loss: 11.091820
 >> iter 58000, loss: 11.057502
 >> iter 59000, loss: 10.203257
 >> iter 60000, loss: 10.068201
   Number of active neurons: 2
 >> iter 61000, loss: 11.736371
 >> iter 62000, loss: 11.105215
 >> iter 63000, loss: 11.675201
 >> iter 64000, loss: 10.615306
 >> iter 65000, loss: 10.573385
 >> iter 66000, loss: 10.053224
 >> iter 67000, loss: 10.250554
 >> iter 68000, loss: 10.878803
 >> iter 69000, loss: 10.838980
 >> iter 70000, loss: 10.190704
   Number of active neurons: 2
 >> iter 71000, loss: 10.851763
 >> iter 72000, loss: 10.458998
 >> iter 73000, loss: 10.756790
 >> iter 74000, loss: 11.029743
 >> iter 75000, loss: 10.704533
 >> iter 76000, loss: 11.448624
 >> iter 77000, loss: 11.737042
 >> iter 78000, loss: 11.575701
 >> iter 79000, loss: 11.439270
 >> iter 80000, loss: 10.657450
   Number of active neurons: 2
 >> iter 81000, loss: 11.136012
 >> iter 82000, loss: 10.943059
 >> iter 83000, loss: 10.729866
 >> iter 84000, loss: 10.580444
 >> iter 85000, loss: 10.762557
 >> iter 86000, loss: 10.429049
 >> iter 87000, loss: 10.128000
 >> iter 88000, loss: 10.269208
 >> iter 89000, loss: 11.580060
 >> iter 90000, loss: 11.459016
   Number of active neurons: 2
 >> iter 91000, loss: 11.383922
 >> iter 92000, loss: 10.601003
 >> iter 93000, loss: 10.369598
 >> iter 94000, loss: 10.582369
 >> iter 95000, loss: 10.335121
 >> iter 96000, loss: 10.834228
 >> iter 97000, loss: 10.502246
 >> iter 98000, loss: 10.546736
 >> iter 99000, loss: 11.141139
 >> iter 100000, loss: 10.865623
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 21.037298
 >> iter 2000, loss: 18.735216
 >> iter 3000, loss: 17.828262
 >> iter 4000, loss: 17.557539
 >> iter 5000, loss: 17.393953
 >> iter 6000, loss: 17.399767
 >> iter 7000, loss: 17.334485
 >> iter 8000, loss: 17.377683
 >> iter 9000, loss: 17.326842
 >> iter 10000, loss: 17.376461
   Number of active neurons: 0
 >> iter 11000, loss: 17.324224
 >> iter 12000, loss: 17.376003
 >> iter 13000, loss: 17.320235
 >> iter 14000, loss: 17.374907
 >> iter 15000, loss: 17.320795
 >> iter 16000, loss: 17.374885
 >> iter 17000, loss: 17.322167
 >> iter 18000, loss: 17.374664
 >> iter 19000, loss: 17.320916
 >> iter 20000, loss: 17.374841
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 13.987322
 >> iter 22000, loss: 12.237262
 >> iter 23000, loss: 12.003611
 >> iter 24000, loss: 11.184950
 >> iter 25000, loss: 11.219967
 >> iter 26000, loss: 10.943282
 >> iter 27000, loss: 11.411396
 >> iter 28000, loss: 11.658421
 >> iter 29000, loss: 11.952373
 >> iter 30000, loss: 11.355192
   Number of active neurons: 2
 >> iter 31000, loss: 11.145893
 >> iter 32000, loss: 11.435103
 >> iter 33000, loss: 11.210479
 >> iter 34000, loss: 11.013878
 >> iter 35000, loss: 11.707685
 >> iter 36000, loss: 11.935910
 >> iter 37000, loss: 11.309126
 >> iter 38000, loss: 12.049906
 >> iter 39000, loss: 11.221531
 >> iter 40000, loss: 10.892483
   Number of active neurons: 2
 >> iter 41000, loss: 11.731075
 >> iter 42000, loss: 10.868723
 >> iter 43000, loss: 10.819449
 >> iter 44000, loss: 10.446913
 >> iter 45000, loss: 10.559539
 >> iter 46000, loss: 10.554903
 >> iter 47000, loss: 10.945651
 >> iter 48000, loss: 10.669226
 >> iter 49000, loss: 10.896988
 >> iter 50000, loss: 10.938258
   Number of active neurons: 2
 >> iter 51000, loss: 11.198509
 >> iter 52000, loss: 10.793822
 >> iter 53000, loss: 11.381558
 >> iter 54000, loss: 10.592451
 >> iter 55000, loss: 10.407996
 >> iter 56000, loss: 11.467859
 >> iter 57000, loss: 11.810418
 >> iter 58000, loss: 11.396324
 >> iter 59000, loss: 10.584562
 >> iter 60000, loss: 10.738211
   Number of active neurons: 2
 >> iter 61000, loss: 10.634258
 >> iter 62000, loss: 10.747068
 >> iter 63000, loss: 10.585238
 >> iter 64000, loss: 10.641922
 >> iter 65000, loss: 10.849700
 >> iter 66000, loss: 11.097887
 >> iter 67000, loss: 10.859326
 >> iter 68000, loss: 10.778495
 >> iter 69000, loss: 11.603970
 >> iter 70000, loss: 10.905836
   Number of active neurons: 2
 >> iter 71000, loss: 10.482168
 >> iter 72000, loss: 10.835919
 >> iter 73000, loss: 11.202579
 >> iter 74000, loss: 10.587315
 >> iter 75000, loss: 10.667230
 >> iter 76000, loss: 10.734640
 >> iter 77000, loss: 11.059785
 >> iter 78000, loss: 10.807996
 >> iter 79000, loss: 10.940094
 >> iter 80000, loss: 11.075260
   Number of active neurons: 2
 >> iter 81000, loss: 10.554542
 >> iter 82000, loss: 11.569255
 >> iter 83000, loss: 11.041906
 >> iter 84000, loss: 11.535371
 >> iter 85000, loss: 12.045889
 >> iter 86000, loss: 11.256022
 >> iter 87000, loss: 11.796806
 >> iter 88000, loss: 11.231264
 >> iter 89000, loss: 10.783529
 >> iter 90000, loss: 10.589488
   Number of active neurons: 2
 >> iter 91000, loss: 11.110396
 >> iter 92000, loss: 10.755224
 >> iter 93000, loss: 9.977825
 >> iter 94000, loss: 11.268105
 >> iter 95000, loss: 10.858224
 >> iter 96000, loss: 10.802972
 >> iter 97000, loss: 10.783017
 >> iter 98000, loss: 10.596942
 >> iter 99000, loss: 10.526473
 >> iter 100000, loss: 10.246913
   Number of active neurons: 2
 >> iter 101000, loss: 10.529454
 >> iter 102000, loss: 10.187567
 >> iter 103000, loss: 10.579869
 >> iter 104000, loss: 10.751349
 >> iter 105000, loss: 11.060256
 >> iter 106000, loss: 10.832722
 >> iter 107000, loss: 11.015566
 >> iter 108000, loss: 10.809728
 >> iter 109000, loss: 13.082534
 >> iter 110000, loss: 11.191142
   Number of active neurons: 2
 >> iter 111000, loss: 11.935464
 >> iter 112000, loss: 12.126210
 >> iter 113000, loss: 11.291189
 >> iter 114000, loss: 10.981512
 >> iter 115000, loss: 14.058895
 >> iter 116000, loss: 13.000168
 >> iter 117000, loss: 11.252727
 >> iter 118000, loss: 10.319190
 >> iter 119000, loss: 10.444324
 >> iter 120000, loss: 11.980514
   Number of active neurons: 2
 >> iter 121000, loss: 13.429577
 >> iter 122000, loss: 10.835511
 >> iter 123000, loss: 11.020322
 >> iter 124000, loss: 10.473149
 >> iter 125000, loss: 10.057639
 >> iter 126000, loss: 10.983384
 >> iter 127000, loss: 11.401375
 >> iter 128000, loss: 11.998262
 >> iter 129000, loss: 10.732289
 >> iter 130000, loss: 11.288711
   Number of active neurons: 2
 >> iter 131000, loss: 11.543289
 >> iter 132000, loss: 11.049540
 >> iter 133000, loss: 11.550539
 >> iter 134000, loss: 10.698273
 >> iter 135000, loss: 10.548639
 >> iter 136000, loss: 10.364678
 >> iter 137000, loss: 10.947816
 >> iter 138000, loss: 11.312152
 >> iter 139000, loss: 13.481279
 >> iter 140000, loss: 11.266335
   Number of active neurons: 2
 >> iter 141000, loss: 11.067278
 >> iter 142000, loss: 11.050473
 >> iter 143000, loss: 11.969517
 >> iter 144000, loss: 11.366662
 >> iter 145000, loss: 11.349558
 >> iter 146000, loss: 11.711959
 >> iter 147000, loss: 12.515562
 >> iter 148000, loss: 12.838069
 >> iter 149000, loss: 11.301011
 >> iter 150000, loss: 14.295794
   Number of active neurons: 2
 >> iter 151000, loss: 12.376747
 >> iter 152000, loss: 11.017105
 >> iter 153000, loss: 10.162457
 >> iter 154000, loss: 11.230228
 >> iter 155000, loss: 12.046853
 >> iter 156000, loss: 11.370403
 >> iter 157000, loss: 11.694482
 >> iter 158000, loss: 11.240342
 >> iter 159000, loss: 11.144968
 >> iter 160000, loss: 10.255401
   Number of active neurons: 2
 >> iter 161000, loss: 10.143759
 >> iter 162000, loss: 10.430494
 >> iter 163000, loss: 10.182956
 >> iter 164000, loss: 11.041451
 >> iter 165000, loss: 11.826645
 >> iter 166000, loss: 10.042227
 >> iter 167000, loss: 10.377382
 >> iter 168000, loss: 10.133123
 >> iter 169000, loss: 10.194980
 >> iter 170000, loss: 10.914858
   Number of active neurons: 2
 >> iter 171000, loss: 10.944166
 >> iter 172000, loss: 10.235565
 >> iter 173000, loss: 10.379126
 >> iter 174000, loss: 10.170892
 >> iter 175000, loss: 10.671885
 >> iter 176000, loss: 11.131106
 >> iter 177000, loss: 10.709551
 >> iter 178000, loss: 11.897301
 >> iter 179000, loss: 12.155843
 >> iter 180000, loss: 13.744938
   Number of active neurons: 2
 >> iter 181000, loss: 11.641281
 >> iter 182000, loss: 11.841088
 >> iter 183000, loss: 10.480130
 >> iter 184000, loss: 10.474645
 >> iter 185000, loss: 10.260751
 >> iter 186000, loss: 10.445479
 >> iter 187000, loss: 10.433562
 >> iter 188000, loss: 10.638637
 >> iter 189000, loss: 11.683402
 >> iter 190000, loss: 11.209363
   Number of active neurons: 2
 >> iter 191000, loss: 11.717962
 >> iter 192000, loss: 10.819998
 >> iter 193000, loss: 12.267860
 >> iter 194000, loss: 11.755439
 >> iter 195000, loss: 12.490813
 >> iter 196000, loss: 11.017251
 >> iter 197000, loss: 10.651067
 >> iter 198000, loss: 11.549191
 >> iter 199000, loss: 13.923686
 >> iter 200000, loss: 11.917530
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 13.3017339653
   - Test - Long: 3.199840008
   - Test - Big: 13.7038629614
   - Test - A: 25.118325445
   - Test - B: 60.5159656023
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.887371
 >> iter 2000, loss: 14.296930
 >> iter 3000, loss: 12.980376
 >> iter 4000, loss: 12.446343
 >> iter 5000, loss: 11.815078
 >> iter 6000, loss: 11.347756
 >> iter 7000, loss: 11.601970
 >> iter 8000, loss: 11.136572
 >> iter 9000, loss: 10.974218
 >> iter 10000, loss: 11.663970
   Number of active neurons: 2
 >> iter 11000, loss: 11.653259
 >> iter 12000, loss: 11.630920
 >> iter 13000, loss: 11.274431
 >> iter 14000, loss: 11.185959
 >> iter 15000, loss: 10.801096
 >> iter 16000, loss: 11.025375
 >> iter 17000, loss: 11.256979
 >> iter 18000, loss: 11.212630
 >> iter 19000, loss: 11.104881
 >> iter 20000, loss: 11.014201
   Number of active neurons: 2
 >> iter 21000, loss: 10.900179
 >> iter 22000, loss: 10.674231
 >> iter 23000, loss: 10.902592
 >> iter 24000, loss: 11.082819
 >> iter 25000, loss: 11.499391
 >> iter 26000, loss: 10.682158
 >> iter 27000, loss: 10.750901
 >> iter 28000, loss: 11.505725
 >> iter 29000, loss: 11.239005
 >> iter 30000, loss: 10.793189
   Number of active neurons: 2
 >> iter 31000, loss: 10.662617
 >> iter 32000, loss: 10.215756
 >> iter 33000, loss: 10.755137
 >> iter 34000, loss: 10.602592
 >> iter 35000, loss: 11.074028
 >> iter 36000, loss: 11.337685
 >> iter 37000, loss: 10.781582
 >> iter 38000, loss: 10.254331
 >> iter 39000, loss: 11.346623
 >> iter 40000, loss: 10.664138
   Number of active neurons: 2
 >> iter 41000, loss: 10.495612
 >> iter 42000, loss: 10.568992
 >> iter 43000, loss: 11.100484
 >> iter 44000, loss: 11.012466
 >> iter 45000, loss: 10.949490
 >> iter 46000, loss: 10.814411
 >> iter 47000, loss: 12.065837
 >> iter 48000, loss: 11.339612
 >> iter 49000, loss: 10.639486
 >> iter 50000, loss: 10.839088
   Number of active neurons: 2
 >> iter 51000, loss: 11.362590
 >> iter 52000, loss: 10.777765
 >> iter 53000, loss: 10.928731
 >> iter 54000, loss: 10.551505
 >> iter 55000, loss: 10.928433
 >> iter 56000, loss: 10.385866
 >> iter 57000, loss: 10.540874
 >> iter 58000, loss: 10.945239
 >> iter 59000, loss: 10.197448
 >> iter 60000, loss: 10.051452
   Number of active neurons: 2
 >> iter 61000, loss: 11.071836
 >> iter 62000, loss: 11.179030
 >> iter 63000, loss: 11.546978
 >> iter 64000, loss: 11.092326
 >> iter 65000, loss: 10.636213
 >> iter 66000, loss: 10.628313
 >> iter 67000, loss: 12.431171
 >> iter 68000, loss: 14.119447
 >> iter 69000, loss: 12.431592
 >> iter 70000, loss: 10.615049
   Number of active neurons: 2
 >> iter 71000, loss: 10.449320
 >> iter 72000, loss: 10.320001
 >> iter 73000, loss: 10.673254
 >> iter 74000, loss: 11.681115
 >> iter 75000, loss: 10.472642
 >> iter 76000, loss: 10.319517
 >> iter 77000, loss: 10.640359
 >> iter 78000, loss: 10.149371
 >> iter 79000, loss: 12.165643
 >> iter 80000, loss: 12.063320
   Number of active neurons: 2
 >> iter 81000, loss: 10.888925
 >> iter 82000, loss: 10.869611
 >> iter 83000, loss: 10.874827
 >> iter 84000, loss: 10.624713
 >> iter 85000, loss: 10.862732
 >> iter 86000, loss: 12.106767
 >> iter 87000, loss: 12.002067
 >> iter 88000, loss: 11.273540
 >> iter 89000, loss: 10.561254
 >> iter 90000, loss: 11.350508
   Number of active neurons: 2
 >> iter 91000, loss: 12.964858
 >> iter 92000, loss: 11.915847
 >> iter 93000, loss: 11.325411
 >> iter 94000, loss: 11.060880
 >> iter 95000, loss: 12.138176
 >> iter 96000, loss: 11.328947
 >> iter 97000, loss: 12.260817
 >> iter 98000, loss: 12.083550
 >> iter 99000, loss: 11.853341
 >> iter 100000, loss: 11.021566
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 36.1872762545
   - Test - Long: 14.0342982851
   - Test - Big: 36.2056379436
   - Test - A: 19.1920538631
   - Test - B: 37.4508366109
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.436920
 >> iter 2000, loss: 13.720888
 >> iter 3000, loss: 13.393127
 >> iter 4000, loss: 11.884871
 >> iter 5000, loss: 11.990079
 >> iter 6000, loss: 11.176188
 >> iter 7000, loss: 11.036302
 >> iter 8000, loss: 10.797140
 >> iter 9000, loss: 11.281727
 >> iter 10000, loss: 10.916802
   Number of active neurons: 2
 >> iter 11000, loss: 11.304453
 >> iter 12000, loss: 11.105610
 >> iter 13000, loss: 10.570897
 >> iter 14000, loss: 11.437028
 >> iter 15000, loss: 11.158776
 >> iter 16000, loss: 11.256366
 >> iter 17000, loss: 11.486273
 >> iter 18000, loss: 11.002734
 >> iter 19000, loss: 10.981004
 >> iter 20000, loss: 10.645316
   Number of active neurons: 2
 >> iter 21000, loss: 10.656417
 >> iter 22000, loss: 10.734461
 >> iter 23000, loss: 10.537031
 >> iter 24000, loss: 10.624505
 >> iter 25000, loss: 11.325767
 >> iter 26000, loss: 11.257087
 >> iter 27000, loss: 10.995947
 >> iter 28000, loss: 10.716616
 >> iter 29000, loss: 11.214611
 >> iter 30000, loss: 11.297987
   Number of active neurons: 2
 >> iter 31000, loss: 10.871817
 >> iter 32000, loss: 11.252455
 >> iter 33000, loss: 11.486667
 >> iter 34000, loss: 10.529929
 >> iter 35000, loss: 11.721038
 >> iter 36000, loss: 10.731719
 >> iter 37000, loss: 11.524033
 >> iter 38000, loss: 10.243198
 >> iter 39000, loss: 11.009873
 >> iter 40000, loss: 11.184267
   Number of active neurons: 2
 >> iter 41000, loss: 11.109043
 >> iter 42000, loss: 10.854912
 >> iter 43000, loss: 10.829012
 >> iter 44000, loss: 10.256389
 >> iter 45000, loss: 10.434713
 >> iter 46000, loss: 9.876039
 >> iter 47000, loss: 10.749453
 >> iter 48000, loss: 10.712285
 >> iter 49000, loss: 11.058386
 >> iter 50000, loss: 10.242739
   Number of active neurons: 2
 >> iter 51000, loss: 10.089535
 >> iter 52000, loss: 10.783725
 >> iter 53000, loss: 10.993757
 >> iter 54000, loss: 11.253572
 >> iter 55000, loss: 10.491430
 >> iter 56000, loss: 11.257043
 >> iter 57000, loss: 11.189695
 >> iter 58000, loss: 10.548788
 >> iter 59000, loss: 10.493648
 >> iter 60000, loss: 10.624269
   Number of active neurons: 2
 >> iter 61000, loss: 10.500647
 >> iter 62000, loss: 10.742031
 >> iter 63000, loss: 11.579464
 >> iter 64000, loss: 10.505365
 >> iter 65000, loss: 10.999710
 >> iter 66000, loss: 11.429040
 >> iter 67000, loss: 11.165442
 >> iter 68000, loss: 11.065383
 >> iter 69000, loss: 10.809016
 >> iter 70000, loss: 11.049747
   Number of active neurons: 2
 >> iter 71000, loss: 10.476866
 >> iter 72000, loss: 11.068104
 >> iter 73000, loss: 11.107898
 >> iter 74000, loss: 11.370231
 >> iter 75000, loss: 12.612867
 >> iter 76000, loss: 11.533983
 >> iter 77000, loss: 10.600860
 >> iter 78000, loss: 10.578660
 >> iter 79000, loss: 10.347880
 >> iter 80000, loss: 10.535738
   Number of active neurons: 2
 >> iter 81000, loss: 10.882771
 >> iter 82000, loss: 10.764518
 >> iter 83000, loss: 10.841439
 >> iter 84000, loss: 11.634911
 >> iter 85000, loss: 10.960181
 >> iter 86000, loss: 10.325502
 >> iter 87000, loss: 11.027235
 >> iter 88000, loss: 10.499654
 >> iter 89000, loss: 10.581465
 >> iter 90000, loss: 10.630210
   Number of active neurons: 2
 >> iter 91000, loss: 10.497650
 >> iter 92000, loss: 10.396791
 >> iter 93000, loss: 13.580533
 >> iter 94000, loss: 11.849956
 >> iter 95000, loss: 15.187152
 >> iter 96000, loss: 13.320976
 >> iter 97000, loss: 13.048320
 >> iter 98000, loss: 11.227753
 >> iter 99000, loss: 11.124092
 >> iter 100000, loss: 11.507555
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 10.8377832443
   - Test - Long: 2.57987100645
   - Test - Big: 11.3068869311
   - Test - A: 13.6657556163
   - Test - B: 64.4423705086
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 21.037297
 >> iter 2000, loss: 18.735216
 >> iter 3000, loss: 17.828262
 >> iter 4000, loss: 17.557539
 >> iter 5000, loss: 17.393953
 >> iter 6000, loss: 17.399767
 >> iter 7000, loss: 17.334485
 >> iter 8000, loss: 17.377683
 >> iter 9000, loss: 17.326842
 >> iter 10000, loss: 17.376461
   Number of active neurons: 0
 >> iter 11000, loss: 17.324224
 >> iter 12000, loss: 17.376003
 >> iter 13000, loss: 17.320235
 >> iter 14000, loss: 17.374907
 >> iter 15000, loss: 17.320795
 >> iter 16000, loss: 17.374885
 >> iter 17000, loss: 17.322167
 >> iter 18000, loss: 17.374665
 >> iter 19000, loss: 17.320916
 >> iter 20000, loss: 17.374841
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 13.627245
 >> iter 22000, loss: 12.277553
 >> iter 23000, loss: 11.359303
 >> iter 24000, loss: 11.242206
 >> iter 25000, loss: 11.577393
 >> iter 26000, loss: 11.081223
 >> iter 27000, loss: 11.402566
 >> iter 28000, loss: 11.247588
 >> iter 29000, loss: 11.915007
 >> iter 30000, loss: 11.297840
   Number of active neurons: 2
 >> iter 31000, loss: 11.382405
 >> iter 32000, loss: 11.046337
 >> iter 33000, loss: 11.462121
 >> iter 34000, loss: 11.013332
 >> iter 35000, loss: 10.790851
 >> iter 36000, loss: 11.403331
 >> iter 37000, loss: 11.484360
 >> iter 38000, loss: 11.282832
 >> iter 39000, loss: 11.634166
 >> iter 40000, loss: 12.135641
   Number of active neurons: 2
 >> iter 41000, loss: 10.821325
 >> iter 42000, loss: 11.014784
 >> iter 43000, loss: 10.830854
 >> iter 44000, loss: 11.249705
 >> iter 45000, loss: 11.712619
 >> iter 46000, loss: 10.775750
 >> iter 47000, loss: 11.495621
 >> iter 48000, loss: 10.666274
 >> iter 49000, loss: 11.745274
 >> iter 50000, loss: 12.138400
   Number of active neurons: 2
 >> iter 51000, loss: 11.534823
 >> iter 52000, loss: 10.954607
 >> iter 53000, loss: 11.435857
 >> iter 54000, loss: 10.889267
 >> iter 55000, loss: 11.321613
 >> iter 56000, loss: 11.193320
 >> iter 57000, loss: 10.692953
 >> iter 58000, loss: 10.702779
 >> iter 59000, loss: 10.615948
 >> iter 60000, loss: 10.754877
   Number of active neurons: 2
 >> iter 61000, loss: 10.469713
 >> iter 62000, loss: 11.101596
 >> iter 63000, loss: 10.719239
 >> iter 64000, loss: 10.764593
 >> iter 65000, loss: 10.563329
 >> iter 66000, loss: 11.234965
 >> iter 67000, loss: 11.135654
 >> iter 68000, loss: 11.275124
 >> iter 69000, loss: 10.957861
 >> iter 70000, loss: 10.399387
   Number of active neurons: 2
 >> iter 71000, loss: 10.864324
 >> iter 72000, loss: 10.643424
 >> iter 73000, loss: 10.727722
 >> iter 74000, loss: 11.429013
 >> iter 75000, loss: 12.392063
 >> iter 76000, loss: 11.054833
 >> iter 77000, loss: 11.411554
 >> iter 78000, loss: 10.456675
 >> iter 79000, loss: 10.801422
 >> iter 80000, loss: 10.912802
   Number of active neurons: 2
 >> iter 81000, loss: 10.832178
 >> iter 82000, loss: 10.376031
 >> iter 83000, loss: 10.636820
 >> iter 84000, loss: 10.708388
 >> iter 85000, loss: 11.056742
 >> iter 86000, loss: 10.511563
 >> iter 87000, loss: 11.540460
 >> iter 88000, loss: 10.812589
 >> iter 89000, loss: 11.319670
 >> iter 90000, loss: 11.519547
   Number of active neurons: 2
 >> iter 91000, loss: 11.799474
 >> iter 92000, loss: 13.265337
 >> iter 93000, loss: 11.580644
 >> iter 94000, loss: 12.556735
 >> iter 95000, loss: 12.363144
 >> iter 96000, loss: 12.016090
 >> iter 97000, loss: 11.170460
 >> iter 98000, loss: 11.094715
 >> iter 99000, loss: 11.249544
 >> iter 100000, loss: 10.446345
   Number of active neurons: 2
 >> iter 101000, loss: 10.464750
 >> iter 102000, loss: 12.601468
 >> iter 103000, loss: 11.366639
 >> iter 104000, loss: 10.675996
 >> iter 105000, loss: 11.663051
 >> iter 106000, loss: 11.532149
 >> iter 107000, loss: 12.224841
 >> iter 108000, loss: 11.213556
 >> iter 109000, loss: 10.675712
 >> iter 110000, loss: 10.136044
   Number of active neurons: 2
 >> iter 111000, loss: 11.451708
 >> iter 112000, loss: 11.186959
 >> iter 113000, loss: 10.553991
 >> iter 114000, loss: 11.011295
 >> iter 115000, loss: 10.703189
 >> iter 116000, loss: 10.653018
 >> iter 117000, loss: 10.454839
 >> iter 118000, loss: 10.319267
 >> iter 119000, loss: 9.974434
 >> iter 120000, loss: 10.006925
   Number of active neurons: 2
 >> iter 121000, loss: 10.858663
 >> iter 122000, loss: 10.452412
 >> iter 123000, loss: 10.689208
 >> iter 124000, loss: 10.277711
 >> iter 125000, loss: 10.829628
 >> iter 126000, loss: 10.726018
 >> iter 127000, loss: 11.019632
 >> iter 128000, loss: 10.388884
 >> iter 129000, loss: 10.741431
 >> iter 130000, loss: 10.366848
   Number of active neurons: 2
 >> iter 131000, loss: 10.728252
 >> iter 132000, loss: 10.070449
 >> iter 133000, loss: 10.648957
 >> iter 134000, loss: 9.987315
 >> iter 135000, loss: 11.336748
 >> iter 136000, loss: 10.782615
 >> iter 137000, loss: 11.191520
 >> iter 138000, loss: 13.439064
 >> iter 139000, loss: 12.243899
 >> iter 140000, loss: 11.492863
   Number of active neurons: 2
 >> iter 141000, loss: 12.104994
 >> iter 142000, loss: 11.027656
 >> iter 143000, loss: 12.295623
 >> iter 144000, loss: 11.524037
 >> iter 145000, loss: 11.888338
 >> iter 146000, loss: 11.647503
 >> iter 147000, loss: 10.513407
 >> iter 148000, loss: 10.228026
 >> iter 149000, loss: 10.583960
 >> iter 150000, loss: 10.506592
   Number of active neurons: 2
 >> iter 151000, loss: 10.771198
 >> iter 152000, loss: 11.211774
 >> iter 153000, loss: 11.398183
 >> iter 154000, loss: 10.576363
 >> iter 155000, loss: 10.444797
 >> iter 156000, loss: 13.937834
 >> iter 157000, loss: 12.890559
 >> iter 158000, loss: 11.431145
 >> iter 159000, loss: 11.544419
 >> iter 160000, loss: 10.472390
   Number of active neurons: 2
 >> iter 161000, loss: 11.768985
 >> iter 162000, loss: 11.050246
 >> iter 163000, loss: 11.045837
 >> iter 164000, loss: 11.623471
 >> iter 165000, loss: 10.588087
 >> iter 166000, loss: 11.030509
 >> iter 167000, loss: 10.374530
 >> iter 168000, loss: 10.884104
 >> iter 169000, loss: 11.454693
 >> iter 170000, loss: 11.713240
   Number of active neurons: 2
 >> iter 171000, loss: 10.609544
 >> iter 172000, loss: 10.337185
 >> iter 173000, loss: 10.681288
 >> iter 174000, loss: 10.578960
 >> iter 175000, loss: 10.776142
 >> iter 176000, loss: 10.540873
 >> iter 177000, loss: 10.414928
 >> iter 178000, loss: 10.097804
 >> iter 179000, loss: 10.335834
 >> iter 180000, loss: 10.148526
   Number of active neurons: 2
 >> iter 181000, loss: 10.178486
 >> iter 182000, loss: 10.426994
 >> iter 183000, loss: 11.002786
 >> iter 184000, loss: 10.570871
 >> iter 185000, loss: 10.663183
 >> iter 186000, loss: 10.142491
 >> iter 187000, loss: 14.104669
 >> iter 188000, loss: 12.393159
 >> iter 189000, loss: 11.807732
 >> iter 190000, loss: 10.692734
   Number of active neurons: 2
 >> iter 191000, loss: 10.436950
 >> iter 192000, loss: 11.064835
 >> iter 193000, loss: 10.878283
 >> iter 194000, loss: 10.579613
 >> iter 195000, loss: 10.943668
 >> iter 196000, loss: 10.780034
 >> iter 197000, loss: 10.869176
 >> iter 198000, loss: 12.881598
 >> iter 199000, loss: 11.984909
 >> iter 200000, loss: 10.908470
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.426515
 >> iter 2000, loss: 14.041783
 >> iter 3000, loss: 12.485564
 >> iter 4000, loss: 11.764818
 >> iter 5000, loss: 11.644828
 >> iter 6000, loss: 11.850470
 >> iter 7000, loss: 11.681658
 >> iter 8000, loss: 11.074578
 >> iter 9000, loss: 11.329912
 >> iter 10000, loss: 11.387888
   Number of active neurons: 2
 >> iter 11000, loss: 11.337576
 >> iter 12000, loss: 11.205586
 >> iter 13000, loss: 12.068453
 >> iter 14000, loss: 11.558977
 >> iter 15000, loss: 11.903092
 >> iter 16000, loss: 10.755748
 >> iter 17000, loss: 10.625879
 >> iter 18000, loss: 10.896233
 >> iter 19000, loss: 11.055016
 >> iter 20000, loss: 10.827742
   Number of active neurons: 2
 >> iter 21000, loss: 11.308866
 >> iter 22000, loss: 12.481725
 >> iter 23000, loss: 11.649656
 >> iter 24000, loss: 10.930249
 >> iter 25000, loss: 11.592212
 >> iter 26000, loss: 10.956254
 >> iter 27000, loss: 10.757814
 >> iter 28000, loss: 10.880230
 >> iter 29000, loss: 10.485720
 >> iter 30000, loss: 10.701255
   Number of active neurons: 2
 >> iter 31000, loss: 11.157728
 >> iter 32000, loss: 11.311769
 >> iter 33000, loss: 11.044447
 >> iter 34000, loss: 10.814074
 >> iter 35000, loss: 11.079360
 >> iter 36000, loss: 11.841934
 >> iter 37000, loss: 11.793099
 >> iter 38000, loss: 10.898516
 >> iter 39000, loss: 10.577380
 >> iter 40000, loss: 10.601250
   Number of active neurons: 2
 >> iter 41000, loss: 11.850725
 >> iter 42000, loss: 10.688960
 >> iter 43000, loss: 10.851783
 >> iter 44000, loss: 10.584767
 >> iter 45000, loss: 11.997138
 >> iter 46000, loss: 10.805293
 >> iter 47000, loss: 11.197284
 >> iter 48000, loss: 10.343224
 >> iter 49000, loss: 11.816284
 >> iter 50000, loss: 10.894348
   Number of active neurons: 2
 >> iter 51000, loss: 11.568429
 >> iter 52000, loss: 12.041306
 >> iter 53000, loss: 11.573774
 >> iter 54000, loss: 11.547037
 >> iter 55000, loss: 11.176995
 >> iter 56000, loss: 11.258335
 >> iter 57000, loss: 11.233713
 >> iter 58000, loss: 10.363474
 >> iter 59000, loss: 10.577791
 >> iter 60000, loss: 10.628275
   Number of active neurons: 2
 >> iter 61000, loss: 10.659412
 >> iter 62000, loss: 10.527968
 >> iter 63000, loss: 10.494093
 >> iter 64000, loss: 10.478701
 >> iter 65000, loss: 10.548141
 >> iter 66000, loss: 10.919420
 >> iter 67000, loss: 12.347686
 >> iter 68000, loss: 10.884456
 >> iter 69000, loss: 10.367506
 >> iter 70000, loss: 13.223979
   Number of active neurons: 2
 >> iter 71000, loss: 12.878207
 >> iter 72000, loss: 11.673457
 >> iter 73000, loss: 11.051396
 >> iter 74000, loss: 10.761348
 >> iter 75000, loss: 10.935279
 >> iter 76000, loss: 11.006421
 >> iter 77000, loss: 10.323892
 >> iter 78000, loss: 10.381052
 >> iter 79000, loss: 10.711974
 >> iter 80000, loss: 10.964391
   Number of active neurons: 2
 >> iter 81000, loss: 10.311880
 >> iter 82000, loss: 9.960956
 >> iter 83000, loss: 11.683207
 >> iter 84000, loss: 11.091192
 >> iter 85000, loss: 11.677419
 >> iter 86000, loss: 10.960606
 >> iter 87000, loss: 10.702037
 >> iter 88000, loss: 10.570909
 >> iter 89000, loss: 10.438851
 >> iter 90000, loss: 10.462737
   Number of active neurons: 2
 >> iter 91000, loss: 10.826745
 >> iter 92000, loss: 10.694988
 >> iter 93000, loss: 11.933397
 >> iter 94000, loss: 10.879253
 >> iter 95000, loss: 10.593940
 >> iter 96000, loss: 10.648952
 >> iter 97000, loss: 10.711048
 >> iter 98000, loss: 11.381944
 >> iter 99000, loss: 10.454753
 >> iter 100000, loss: 10.270654
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.150237
 >> iter 2000, loss: 15.470051
 >> iter 3000, loss: 14.141068
 >> iter 4000, loss: 13.233863
 >> iter 5000, loss: 11.819442
 >> iter 6000, loss: 12.007270
 >> iter 7000, loss: 11.657308
 >> iter 8000, loss: 11.401504
 >> iter 9000, loss: 11.770356
 >> iter 10000, loss: 12.312231
   Number of active neurons: 2
 >> iter 11000, loss: 12.195274
 >> iter 12000, loss: 11.304440
 >> iter 13000, loss: 11.197282
 >> iter 14000, loss: 11.407276
 >> iter 15000, loss: 11.236149
 >> iter 16000, loss: 11.203054
 >> iter 17000, loss: 11.222003
 >> iter 18000, loss: 11.657453
 >> iter 19000, loss: 10.958735
 >> iter 20000, loss: 10.933407
   Number of active neurons: 2
 >> iter 21000, loss: 11.099842
 >> iter 22000, loss: 10.885453
 >> iter 23000, loss: 11.419322
 >> iter 24000, loss: 11.124803
 >> iter 25000, loss: 10.934758
 >> iter 26000, loss: 10.455281
 >> iter 27000, loss: 11.078091
 >> iter 28000, loss: 10.773091
 >> iter 29000, loss: 10.591219
 >> iter 30000, loss: 10.674302
   Number of active neurons: 2
 >> iter 31000, loss: 10.786906
 >> iter 32000, loss: 11.796870
 >> iter 33000, loss: 10.781821
 >> iter 34000, loss: 11.584854
 >> iter 35000, loss: 11.407912
 >> iter 36000, loss: 11.371893
 >> iter 37000, loss: 11.874452
 >> iter 38000, loss: 11.128982
 >> iter 39000, loss: 11.149847
 >> iter 40000, loss: 10.797872
   Number of active neurons: 2
 >> iter 41000, loss: 10.899431
 >> iter 42000, loss: 10.864272
 >> iter 43000, loss: 10.616326
 >> iter 44000, loss: 10.867488
 >> iter 45000, loss: 10.781734
 >> iter 46000, loss: 10.680938
 >> iter 47000, loss: 10.470715
 >> iter 48000, loss: 10.438153
 >> iter 49000, loss: 11.158875
 >> iter 50000, loss: 10.267341
   Number of active neurons: 2
 >> iter 51000, loss: 10.322248
 >> iter 52000, loss: 10.459341
 >> iter 53000, loss: 10.547589
 >> iter 54000, loss: 10.536912
 >> iter 55000, loss: 10.466871
 >> iter 56000, loss: 9.973825
 >> iter 57000, loss: 10.683611
 >> iter 58000, loss: 10.630918
 >> iter 59000, loss: 11.236518
 >> iter 60000, loss: 10.976955
   Number of active neurons: 2
 >> iter 61000, loss: 12.313120
 >> iter 62000, loss: 11.636480
 >> iter 63000, loss: 11.656315
 >> iter 64000, loss: 10.880052
 >> iter 65000, loss: 10.809122
 >> iter 66000, loss: 10.608022
 >> iter 67000, loss: 12.631145
 >> iter 68000, loss: 11.006175
 >> iter 69000, loss: 10.804787
 >> iter 70000, loss: 12.222062
   Number of active neurons: 2
 >> iter 71000, loss: 11.378198
 >> iter 72000, loss: 10.840016
 >> iter 73000, loss: 11.306789
 >> iter 74000, loss: 11.161901
 >> iter 75000, loss: 11.056526
 >> iter 76000, loss: 10.008724
 >> iter 77000, loss: 9.928625
 >> iter 78000, loss: 10.371528
 >> iter 79000, loss: 10.256335
 >> iter 80000, loss: 10.083702
   Number of active neurons: 2
 >> iter 81000, loss: 13.625204
 >> iter 82000, loss: 12.885243
 >> iter 83000, loss: 11.458320
 >> iter 84000, loss: 10.950371
 >> iter 85000, loss: 10.421305
 >> iter 86000, loss: 11.027616
 >> iter 87000, loss: 10.830293
 >> iter 88000, loss: 10.516519
 >> iter 89000, loss: 10.741211
 >> iter 90000, loss: 10.238459
   Number of active neurons: 2
 >> iter 91000, loss: 11.267135
 >> iter 92000, loss: 12.699763
 >> iter 93000, loss: 11.174772
 >> iter 94000, loss: 10.237568
 >> iter 95000, loss: 10.995432
 >> iter 96000, loss: 10.861239
 >> iter 97000, loss: 10.824552
 >> iter 98000, loss: 10.194939
 >> iter 99000, loss: 11.152591
 >> iter 100000, loss: 10.851671
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 11.9857602848
   - Test - Long: 2.75486225689
   - Test - Big: 12.4448755512
   - Test - A: 60.50929938
   - Test - B: 64.4290380641
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.734904
 >> iter 2000, loss: 13.410588
 >> iter 3000, loss: 12.318470
 >> iter 4000, loss: 12.001314
 >> iter 5000, loss: 11.628887
 >> iter 6000, loss: 11.679070
 >> iter 7000, loss: 11.732837
 >> iter 8000, loss: 11.403304
 >> iter 9000, loss: 11.744779
 >> iter 10000, loss: 12.028834
   Number of active neurons: 2
 >> iter 11000, loss: 11.278116
 >> iter 12000, loss: 11.091498
 >> iter 13000, loss: 12.515798
 >> iter 14000, loss: 11.432762
 >> iter 15000, loss: 11.914207
 >> iter 16000, loss: 10.614520
 >> iter 17000, loss: 10.353194
 >> iter 18000, loss: 9.937293
 >> iter 19000, loss: 10.498623
 >> iter 20000, loss: 10.761790
   Number of active neurons: 2
 >> iter 21000, loss: 12.322514
 >> iter 22000, loss: 14.291903
 >> iter 23000, loss: 14.629676
 >> iter 24000, loss: 16.579421
 >> iter 25000, loss: 15.482541
 >> iter 26000, loss: 13.339615
 >> iter 27000, loss: 11.627469
 >> iter 28000, loss: 10.944422
 >> iter 29000, loss: 10.591450
 >> iter 30000, loss: 10.387871
   Number of active neurons: 2
 >> iter 31000, loss: 10.454287
 >> iter 32000, loss: 10.055362
 >> iter 33000, loss: 10.517040
 >> iter 34000, loss: 10.949769
 >> iter 35000, loss: 11.421641
 >> iter 36000, loss: 12.036523
 >> iter 37000, loss: 11.213306
 >> iter 38000, loss: 10.857377
 >> iter 39000, loss: 11.048900
 >> iter 40000, loss: 10.611493
   Number of active neurons: 2
 >> iter 41000, loss: 11.253952
 >> iter 42000, loss: 11.031623
 >> iter 43000, loss: 11.316197
 >> iter 44000, loss: 11.239914
 >> iter 45000, loss: 11.040062
 >> iter 46000, loss: 11.340066
 >> iter 47000, loss: 11.594160
 >> iter 48000, loss: 11.265670
 >> iter 49000, loss: 13.067771
 >> iter 50000, loss: 12.883870
   Number of active neurons: 2
 >> iter 51000, loss: 11.642815
 >> iter 52000, loss: 11.097707
 >> iter 53000, loss: 10.899459
 >> iter 54000, loss: 10.412115
 >> iter 55000, loss: 11.025150
 >> iter 56000, loss: 10.652935
 >> iter 57000, loss: 11.518152
 >> iter 58000, loss: 12.046740
 >> iter 59000, loss: 12.088901
 >> iter 60000, loss: 10.905079
   Number of active neurons: 2
 >> iter 61000, loss: 11.046452
 >> iter 62000, loss: 10.831234
 >> iter 63000, loss: 10.544857
 >> iter 64000, loss: 11.355141
 >> iter 65000, loss: 13.722712
 >> iter 66000, loss: 11.290501
 >> iter 67000, loss: 10.415589
 >> iter 68000, loss: 10.041133
 >> iter 69000, loss: 10.632240
 >> iter 70000, loss: 10.630881
   Number of active neurons: 2
 >> iter 71000, loss: 10.712411
 >> iter 72000, loss: 11.365813
 >> iter 73000, loss: 10.767961
 >> iter 74000, loss: 10.558202
 >> iter 75000, loss: 11.396740
 >> iter 76000, loss: 10.932203
 >> iter 77000, loss: 10.937898
 >> iter 78000, loss: 10.479372
 >> iter 79000, loss: 11.005263
 >> iter 80000, loss: 10.213080
   Number of active neurons: 2
 >> iter 81000, loss: 10.685298
 >> iter 82000, loss: 11.475204
 >> iter 83000, loss: 12.930496
 >> iter 84000, loss: 12.217615
 >> iter 85000, loss: 10.881265
 >> iter 86000, loss: 11.259484
 >> iter 87000, loss: 11.683753
 >> iter 88000, loss: 10.543486
 >> iter 89000, loss: 11.298990
 >> iter 90000, loss: 10.771863
   Number of active neurons: 2
 >> iter 91000, loss: 11.537873
 >> iter 92000, loss: 10.791518
 >> iter 93000, loss: 11.752171
 >> iter 94000, loss: 10.865485
 >> iter 95000, loss: 10.980597
 >> iter 96000, loss: 10.607459
 >> iter 97000, loss: 10.273168
 >> iter 98000, loss: 10.070554
 >> iter 99000, loss: 11.323460
 >> iter 100000, loss: 10.398620
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

