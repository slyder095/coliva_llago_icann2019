 > Problema: tomita3nueva
 > Args:
   - Hidden size: 8
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.232128
 >> iter 2000, loss: 14.094667
 >> iter 3000, loss: 8.019817
 >> iter 4000, loss: 3.946170
 >> iter 5000, loss: 1.929193
 >> iter 6000, loss: 1.151443
 >> iter 7000, loss: 0.793669
 >> iter 8000, loss: 0.599473
 >> iter 9000, loss: 0.517850
 >> iter 10000, loss: 0.446704
   Number of active neurons: 4
 >> iter 11000, loss: 0.395208
 >> iter 12000, loss: 0.608149
 >> iter 13000, loss: 0.575326
 >> iter 14000, loss: 0.406689
 >> iter 15000, loss: 0.474977
 >> iter 16000, loss: 0.312715
 >> iter 17000, loss: 0.306984
 >> iter 18000, loss: 0.446073
 >> iter 19000, loss: 0.481884
 >> iter 20000, loss: 0.312213
   Number of active neurons: 4
 >> iter 21000, loss: 0.680414
 >> iter 22000, loss: 0.509319
 >> iter 23000, loss: 0.419615
 >> iter 24000, loss: 0.428517
 >> iter 25000, loss: 0.462981
 >> iter 26000, loss: 0.400888
 >> iter 27000, loss: 0.385694
 >> iter 28000, loss: 0.392370
 >> iter 29000, loss: 0.319658
 >> iter 30000, loss: 0.412374
   Number of active neurons: 4
 >> iter 31000, loss: 0.544454
 >> iter 32000, loss: 0.440041
 >> iter 33000, loss: 0.507983
 >> iter 34000, loss: 0.464850
 >> iter 35000, loss: 0.349250
 >> iter 36000, loss: 0.345398
 >> iter 37000, loss: 0.332986
 >> iter 38000, loss: 0.454224
 >> iter 39000, loss: 0.316796
 >> iter 40000, loss: 0.316722
   Number of active neurons: 4
 >> iter 41000, loss: 0.340846
 >> iter 42000, loss: 0.299364
 >> iter 43000, loss: 0.371376
 >> iter 44000, loss: 0.440612
 >> iter 45000, loss: 0.361800
 >> iter 46000, loss: 0.386582
 >> iter 47000, loss: 0.318419
 >> iter 48000, loss: 0.286903
 >> iter 49000, loss: 0.351658
 >> iter 50000, loss: 0.439249
   Number of active neurons: 4
 >> iter 51000, loss: 0.450987
 >> iter 52000, loss: 0.488524
 >> iter 53000, loss: 0.329505
 >> iter 54000, loss: 0.224133
 >> iter 55000, loss: 0.226611
 >> iter 56000, loss: 0.304325
 >> iter 57000, loss: 0.361146
 >> iter 58000, loss: 0.316089
 >> iter 59000, loss: 0.315802
 >> iter 60000, loss: 0.378284
   Number of active neurons: 4
 >> iter 61000, loss: 0.550359
 >> iter 62000, loss: 0.399493
 >> iter 63000, loss: 0.408227
 >> iter 64000, loss: 0.262016
 >> iter 65000, loss: 0.245628
 >> iter 66000, loss: 0.241499
 >> iter 67000, loss: 0.251304
 >> iter 68000, loss: 0.331682
 >> iter 69000, loss: 0.284497
 >> iter 70000, loss: 0.441513
   Number of active neurons: 4
 >> iter 71000, loss: 0.457427
 >> iter 72000, loss: 0.413258
 >> iter 73000, loss: 0.323245
 >> iter 74000, loss: 0.439226
 >> iter 75000, loss: 0.346153
 >> iter 76000, loss: 0.385818
 >> iter 77000, loss: 0.493064
 >> iter 78000, loss: 0.415692
 >> iter 79000, loss: 0.401711
 >> iter 80000, loss: 0.346827
   Number of active neurons: 4
 >> iter 81000, loss: 0.306511
 >> iter 82000, loss: 0.460908
 >> iter 83000, loss: 0.378474
 >> iter 84000, loss: 0.316954
 >> iter 85000, loss: 0.286764
 >> iter 86000, loss: 0.366511
 >> iter 87000, loss: 0.325577
 >> iter 88000, loss: 0.330785
 >> iter 89000, loss: 0.317783
 >> iter 90000, loss: 0.388884
   Number of active neurons: 4
 >> iter 91000, loss: 0.224211
 >> iter 92000, loss: 0.314864
 >> iter 93000, loss: 0.265900
 >> iter 94000, loss: 0.437786
 >> iter 95000, loss: 0.442821
 >> iter 96000, loss: 0.464224
 >> iter 97000, loss: 0.335746
 >> iter 98000, loss: 0.338119
 >> iter 99000, loss: 0.428934
 >> iter 100000, loss: 0.339330
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.929170
 >> iter 2000, loss: 13.702780
 >> iter 3000, loss: 9.945755
 >> iter 4000, loss: 7.603782
 >> iter 5000, loss: 6.400818
 >> iter 6000, loss: 5.925307
 >> iter 7000, loss: 5.734565
 >> iter 8000, loss: 4.863168
 >> iter 9000, loss: 3.831156
 >> iter 10000, loss: 2.363735
   Number of active neurons: 8
 >> iter 11000, loss: 1.399213
 >> iter 12000, loss: 0.739114
 >> iter 13000, loss: 0.399092
 >> iter 14000, loss: 0.256778
 >> iter 15000, loss: 0.386006
 >> iter 16000, loss: 0.272980
 >> iter 17000, loss: 0.213935
 >> iter 18000, loss: 0.237516
 >> iter 19000, loss: 0.209260
 >> iter 20000, loss: 0.179342
   Number of active neurons: 8
 >> iter 21000, loss: 0.231517
 >> iter 22000, loss: 0.285850
 >> iter 23000, loss: 0.228334
 >> iter 24000, loss: 0.344116
 >> iter 25000, loss: 0.363224
 >> iter 26000, loss: 0.315402
 >> iter 27000, loss: 0.332178
 >> iter 28000, loss: 0.262773
 >> iter 29000, loss: 0.203067
 >> iter 30000, loss: 0.288643
   Number of active neurons: 7
 >> iter 31000, loss: 0.261678
 >> iter 32000, loss: 0.214443
 >> iter 33000, loss: 0.231252
 >> iter 34000, loss: 0.262536
 >> iter 35000, loss: 0.208237
 >> iter 36000, loss: 0.303680
 >> iter 37000, loss: 0.254431
 >> iter 38000, loss: 0.292224
 >> iter 39000, loss: 0.267702
 >> iter 40000, loss: 0.218797
   Number of active neurons: 7
 >> iter 41000, loss: 0.321716
 >> iter 42000, loss: 0.272436
 >> iter 43000, loss: 0.514669
 >> iter 44000, loss: 0.427124
 >> iter 45000, loss: 0.286276
 >> iter 46000, loss: 0.334984
 >> iter 47000, loss: 0.313031
 >> iter 48000, loss: 0.245112
 >> iter 49000, loss: 0.348711
 >> iter 50000, loss: 0.294688
   Number of active neurons: 7
 >> iter 51000, loss: 0.222306
 >> iter 52000, loss: 0.250354
 >> iter 53000, loss: 0.248862
 >> iter 54000, loss: 0.246416
 >> iter 55000, loss: 0.248439
 >> iter 56000, loss: 0.429488
 >> iter 57000, loss: 0.509104
 >> iter 58000, loss: 0.408705
 >> iter 59000, loss: 0.334290
 >> iter 60000, loss: 0.316068
   Number of active neurons: 7
 >> iter 61000, loss: 0.415875
 >> iter 62000, loss: 0.248824
 >> iter 63000, loss: 0.245006
 >> iter 64000, loss: 0.259101
 >> iter 65000, loss: 0.186698
 >> iter 66000, loss: 0.262333
 >> iter 67000, loss: 0.199514
 >> iter 68000, loss: 0.236359
 >> iter 69000, loss: 0.190742
 >> iter 70000, loss: 0.166793
   Number of active neurons: 6
 >> iter 71000, loss: 0.211608
 >> iter 72000, loss: 0.141214
 >> iter 73000, loss: 0.167267
 >> iter 74000, loss: 0.244981
 >> iter 75000, loss: 0.324408
 >> iter 76000, loss: 0.354083
 >> iter 77000, loss: 0.177257
 >> iter 78000, loss: 0.209187
 >> iter 79000, loss: 0.348337
 >> iter 80000, loss: 0.356306
   Number of active neurons: 6
 >> iter 81000, loss: 0.251137
 >> iter 82000, loss: 0.321195
 >> iter 83000, loss: 0.179398
 >> iter 84000, loss: 0.261506
 >> iter 85000, loss: 0.212825
 >> iter 86000, loss: 0.366909
 >> iter 87000, loss: 0.275525
 >> iter 88000, loss: 0.277047
 >> iter 89000, loss: 0.396919
 >> iter 90000, loss: 0.252385
   Number of active neurons: 6
 >> iter 91000, loss: 0.379154
 >> iter 92000, loss: 0.462410
 >> iter 93000, loss: 0.360930
 >> iter 94000, loss: 0.272322
 >> iter 95000, loss: 0.247768
 >> iter 96000, loss: 0.231623
 >> iter 97000, loss: 0.243541
 >> iter 98000, loss: 0.194279
 >> iter 99000, loss: 0.140846
 >> iter 100000, loss: 0.207041
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.127894
 >> iter 2000, loss: 13.133293
 >> iter 3000, loss: 7.392396
 >> iter 4000, loss: 4.265397
 >> iter 5000, loss: 2.842825
 >> iter 6000, loss: 1.878723
 >> iter 7000, loss: 1.237616
 >> iter 8000, loss: 0.998917
 >> iter 9000, loss: 0.995789
 >> iter 10000, loss: 0.848752
   Number of active neurons: 6
 >> iter 11000, loss: 0.748051
 >> iter 12000, loss: 0.818757
 >> iter 13000, loss: 0.808733
 >> iter 14000, loss: 0.682074
 >> iter 15000, loss: 0.502790
 >> iter 16000, loss: 0.546516
 >> iter 17000, loss: 0.552836
 >> iter 18000, loss: 0.529544
 >> iter 19000, loss: 0.541932
 >> iter 20000, loss: 0.476996
   Number of active neurons: 6
 >> iter 21000, loss: 0.469965
 >> iter 22000, loss: 0.512777
 >> iter 23000, loss: 0.458550
 >> iter 24000, loss: 0.461933
 >> iter 25000, loss: 0.555461
 >> iter 26000, loss: 0.441332
 >> iter 27000, loss: 0.488389
 >> iter 28000, loss: 0.320445
 >> iter 29000, loss: 0.337951
 >> iter 30000, loss: 0.649605
   Number of active neurons: 6
 >> iter 31000, loss: 0.578235
 >> iter 32000, loss: 0.570539
 >> iter 33000, loss: 0.591983
 >> iter 34000, loss: 0.518128
 >> iter 35000, loss: 0.606513
 >> iter 36000, loss: 0.512957
 >> iter 37000, loss: 0.699796
 >> iter 38000, loss: 0.603888
 >> iter 39000, loss: 0.534583
 >> iter 40000, loss: 0.454573
   Number of active neurons: 6
 >> iter 41000, loss: 0.384442
 >> iter 42000, loss: 0.442539
 >> iter 43000, loss: 0.461321
 >> iter 44000, loss: 0.463710
 >> iter 45000, loss: 0.624879
 >> iter 46000, loss: 0.589620
 >> iter 47000, loss: 0.545412
 >> iter 48000, loss: 0.523457
 >> iter 49000, loss: 0.596626
 >> iter 50000, loss: 0.708621
   Number of active neurons: 6
 >> iter 51000, loss: 0.547372
 >> iter 52000, loss: 0.657043
 >> iter 53000, loss: 0.506622
 >> iter 54000, loss: 0.450515
 >> iter 55000, loss: 0.611610
 >> iter 56000, loss: 0.484854
 >> iter 57000, loss: 0.376460
 >> iter 58000, loss: 0.507525
 >> iter 59000, loss: 0.589838
 >> iter 60000, loss: 0.633608
   Number of active neurons: 6
 >> iter 61000, loss: 0.665855
 >> iter 62000, loss: 0.654181
 >> iter 63000, loss: 0.460795
 >> iter 64000, loss: 0.431018
 >> iter 65000, loss: 0.407005
 >> iter 66000, loss: 0.462843
 >> iter 67000, loss: 0.601347
 >> iter 68000, loss: 0.402645
 >> iter 69000, loss: 0.650603
 >> iter 70000, loss: 0.515339
   Number of active neurons: 6
 >> iter 71000, loss: 0.651066
 >> iter 72000, loss: 0.784286
 >> iter 73000, loss: 0.510195
 >> iter 74000, loss: 0.534026
 >> iter 75000, loss: 0.456417
 >> iter 76000, loss: 0.559574
 >> iter 77000, loss: 0.523364
 >> iter 78000, loss: 0.489670
 >> iter 79000, loss: 0.503235
 >> iter 80000, loss: 0.528294
   Number of active neurons: 6
 >> iter 81000, loss: 0.843524
 >> iter 82000, loss: 0.553265
 >> iter 83000, loss: 0.577183
 >> iter 84000, loss: 0.549608
 >> iter 85000, loss: 0.733053
 >> iter 86000, loss: 0.618514
 >> iter 87000, loss: 0.546025
 >> iter 88000, loss: 0.356057
 >> iter 89000, loss: 0.402111
 >> iter 90000, loss: 0.482847
   Number of active neurons: 6
 >> iter 91000, loss: 0.408482
 >> iter 92000, loss: 0.558042
 >> iter 93000, loss: 0.345545
 >> iter 94000, loss: 0.435755
 >> iter 95000, loss: 0.544373
 >> iter 96000, loss: 0.522255
 >> iter 97000, loss: 0.532076
 >> iter 98000, loss: 0.382637
 >> iter 99000, loss: 0.627176
 >> iter 100000, loss: 0.644600
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.186346
 >> iter 2000, loss: 12.954195
 >> iter 3000, loss: 8.088544
 >> iter 4000, loss: 5.126478
 >> iter 5000, loss: 3.438474
 >> iter 6000, loss: 2.063574
 >> iter 7000, loss: 1.423306
 >> iter 8000, loss: 0.880183
 >> iter 9000, loss: 0.889101
 >> iter 10000, loss: 0.811227
   Number of active neurons: 5
 >> iter 11000, loss: 0.563880
 >> iter 12000, loss: 0.617214
 >> iter 13000, loss: 0.505482
 >> iter 14000, loss: 0.627625
 >> iter 15000, loss: 0.574358
 >> iter 16000, loss: 0.523063
 >> iter 17000, loss: 0.429910
 >> iter 18000, loss: 0.434806
 >> iter 19000, loss: 0.386189
 >> iter 20000, loss: 0.365331
   Number of active neurons: 5
 >> iter 21000, loss: 0.250340
 >> iter 22000, loss: 0.377984
 >> iter 23000, loss: 0.358205
 >> iter 24000, loss: 0.230970
 >> iter 25000, loss: 0.188215
 >> iter 26000, loss: 0.256398
 >> iter 27000, loss: 0.354164
 >> iter 28000, loss: 0.280730
 >> iter 29000, loss: 0.250502
 >> iter 30000, loss: 0.298307
   Number of active neurons: 5
 >> iter 31000, loss: 0.330211
 >> iter 32000, loss: 0.475837
 >> iter 33000, loss: 0.444242
 >> iter 34000, loss: 0.383269
 >> iter 35000, loss: 0.303759
 >> iter 36000, loss: 0.429748
 >> iter 37000, loss: 0.593302
 >> iter 38000, loss: 0.479820
 >> iter 39000, loss: 0.272172
 >> iter 40000, loss: 0.406546
   Number of active neurons: 5
 >> iter 41000, loss: 0.362066
 >> iter 42000, loss: 0.261867
 >> iter 43000, loss: 0.174093
 >> iter 44000, loss: 0.353464
 >> iter 45000, loss: 0.282506
 >> iter 46000, loss: 0.231079
 >> iter 47000, loss: 0.349269
 >> iter 48000, loss: 0.256678
 >> iter 49000, loss: 0.292712
 >> iter 50000, loss: 0.429863
   Number of active neurons: 5
 >> iter 51000, loss: 0.338961
 >> iter 52000, loss: 0.253511
 >> iter 53000, loss: 0.240271
 >> iter 54000, loss: 0.287314
 >> iter 55000, loss: 0.275676
 >> iter 56000, loss: 0.336575
 >> iter 57000, loss: 0.464474
 >> iter 58000, loss: 0.465435
 >> iter 59000, loss: 0.578945
 >> iter 60000, loss: 0.296174
   Number of active neurons: 5
 >> iter 61000, loss: 0.337631
 >> iter 62000, loss: 0.263103
 >> iter 63000, loss: 0.423744
 >> iter 64000, loss: 0.278384
 >> iter 65000, loss: 0.329778
 >> iter 66000, loss: 0.331437
 >> iter 67000, loss: 0.494653
 >> iter 68000, loss: 0.422493
 >> iter 69000, loss: 0.298431
 >> iter 70000, loss: 0.231497
   Number of active neurons: 5
 >> iter 71000, loss: 0.200069
 >> iter 72000, loss: 0.286610
 >> iter 73000, loss: 0.268323
 >> iter 74000, loss: 0.309265
 >> iter 75000, loss: 0.221661
 >> iter 76000, loss: 0.394662
 >> iter 77000, loss: 0.494289
 >> iter 78000, loss: 0.361126
 >> iter 79000, loss: 0.450577
 >> iter 80000, loss: 0.364397
   Number of active neurons: 5
 >> iter 81000, loss: 0.346001
 >> iter 82000, loss: 0.429970
 >> iter 83000, loss: 0.391741
 >> iter 84000, loss: 0.317504
 >> iter 85000, loss: 0.354100
 >> iter 86000, loss: 0.379991
 >> iter 87000, loss: 0.272553
 >> iter 88000, loss: 0.187682
 >> iter 89000, loss: 0.289905
 >> iter 90000, loss: 0.328815
   Number of active neurons: 5
 >> iter 91000, loss: 0.332284
 >> iter 92000, loss: 0.334613
 >> iter 93000, loss: 0.241532
 >> iter 94000, loss: 0.338020
 >> iter 95000, loss: 0.426569
 >> iter 96000, loss: 0.404938
 >> iter 97000, loss: 0.360860
 >> iter 98000, loss: 0.233318
 >> iter 99000, loss: 0.264372
 >> iter 100000, loss: 0.304881
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.139339
 >> iter 2000, loss: 12.516882
 >> iter 3000, loss: 5.305216
 >> iter 4000, loss: 2.165015
 >> iter 5000, loss: 0.997077
 >> iter 6000, loss: 0.614132
 >> iter 7000, loss: 0.375446
 >> iter 8000, loss: 0.369648
 >> iter 9000, loss: 0.242536
 >> iter 10000, loss: 0.223898
   Number of active neurons: 6
 >> iter 11000, loss: 0.200166
 >> iter 12000, loss: 0.185765
 >> iter 13000, loss: 0.167717
 >> iter 14000, loss: 0.321743
 >> iter 15000, loss: 0.257798
 >> iter 16000, loss: 0.314683
 >> iter 17000, loss: 0.463054
 >> iter 18000, loss: 0.342823
 >> iter 19000, loss: 0.288098
 >> iter 20000, loss: 0.294058
   Number of active neurons: 6
 >> iter 21000, loss: 0.232930
 >> iter 22000, loss: 0.245216
 >> iter 23000, loss: 0.167598
 >> iter 24000, loss: 0.309068
 >> iter 25000, loss: 0.335895
 >> iter 26000, loss: 0.290231
 >> iter 27000, loss: 0.222466
 >> iter 28000, loss: 0.220211
 >> iter 29000, loss: 0.285744
 >> iter 30000, loss: 0.246942
   Number of active neurons: 6
 >> iter 31000, loss: 0.148713
 >> iter 32000, loss: 0.092173
 >> iter 33000, loss: 0.175985
 >> iter 34000, loss: 0.266089
 >> iter 35000, loss: 0.225925
 >> iter 36000, loss: 0.235707
 >> iter 37000, loss: 0.201975
 >> iter 38000, loss: 0.217628
 >> iter 39000, loss: 0.239458
 >> iter 40000, loss: 0.177645
   Number of active neurons: 5
 >> iter 41000, loss: 0.189941
 >> iter 42000, loss: 0.136636
 >> iter 43000, loss: 0.211387
 >> iter 44000, loss: 0.377260
 >> iter 45000, loss: 0.229762
 >> iter 46000, loss: 0.204332
 >> iter 47000, loss: 0.186094
 >> iter 48000, loss: 0.149938
 >> iter 49000, loss: 0.286389
 >> iter 50000, loss: 0.316047
   Number of active neurons: 5
 >> iter 51000, loss: 0.186786
 >> iter 52000, loss: 0.163340
 >> iter 53000, loss: 0.224568
 >> iter 54000, loss: 0.184017
 >> iter 55000, loss: 0.223320
 >> iter 56000, loss: 0.194209
 >> iter 57000, loss: 0.193825
 >> iter 58000, loss: 0.170738
 >> iter 59000, loss: 0.254386
 >> iter 60000, loss: 0.222891
   Number of active neurons: 5
 >> iter 61000, loss: 0.320223
 >> iter 62000, loss: 0.241865
 >> iter 63000, loss: 0.243063
 >> iter 64000, loss: 0.319886
 >> iter 65000, loss: 0.259699
 >> iter 66000, loss: 0.166535
 >> iter 67000, loss: 0.128726
 >> iter 68000, loss: 0.091714
 >> iter 69000, loss: 0.147722
 >> iter 70000, loss: 0.173180
   Number of active neurons: 5
 >> iter 71000, loss: 0.207661
 >> iter 72000, loss: 0.163315
 >> iter 73000, loss: 0.277984
 >> iter 74000, loss: 0.325076
 >> iter 75000, loss: 0.275438
 >> iter 76000, loss: 0.374507
 >> iter 77000, loss: 0.321677
 >> iter 78000, loss: 0.249109
 >> iter 79000, loss: 0.140389
 >> iter 80000, loss: 0.172545
   Number of active neurons: 5
 >> iter 81000, loss: 0.302146
 >> iter 82000, loss: 0.276465
 >> iter 83000, loss: 0.254427
 >> iter 84000, loss: 0.370311
 >> iter 85000, loss: 0.274010
 >> iter 86000, loss: 0.363562
 >> iter 87000, loss: 0.222913
 >> iter 88000, loss: 0.219147
 >> iter 89000, loss: 0.226301
 >> iter 90000, loss: 0.146114
   Number of active neurons: 4
 >> iter 91000, loss: 0.196562
 >> iter 92000, loss: 0.219037
 >> iter 93000, loss: 0.222278
 >> iter 94000, loss: 0.220386
 >> iter 95000, loss: 0.207742
 >> iter 96000, loss: 0.338751
 >> iter 97000, loss: 0.361670
 >> iter 98000, loss: 0.217647
 >> iter 99000, loss: 0.245147
 >> iter 100000, loss: 0.216873
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.162381
 >> iter 2000, loss: 12.653484
 >> iter 3000, loss: 9.363177
 >> iter 4000, loss: 7.697212
 >> iter 5000, loss: 7.047851
 >> iter 6000, loss: 6.587397
 >> iter 7000, loss: 6.534563
 >> iter 8000, loss: 6.359169
 >> iter 9000, loss: 6.394167
 >> iter 10000, loss: 6.321568
   Number of active neurons: 4
 >> iter 11000, loss: 6.343166
 >> iter 12000, loss: 6.262857
 >> iter 13000, loss: 6.398812
 >> iter 14000, loss: 6.277082
 >> iter 15000, loss: 6.327471
   Number of active neurons: 4
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 6.185448
 >> iter 17000, loss: 6.353689
 >> iter 18000, loss: 6.225270
 >> iter 19000, loss: 6.330312
 >> iter 20000, loss: 6.163810
   Number of active neurons: 4
 >> iter 21000, loss: 6.305446
 >> iter 22000, loss: 6.116429
 >> iter 23000, loss: 6.321930
 >> iter 24000, loss: 6.183022
 >> iter 25000, loss: 6.281338
   Number of active neurons: 4
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 26000, loss: 6.130662
 >> iter 27000, loss: 6.358762
 >> iter 28000, loss: 6.181151
 >> iter 29000, loss: 6.362624
 >> iter 30000, loss: 6.140640
   Number of active neurons: 4
 >> iter 31000, loss: 6.296268
 >> iter 32000, loss: 6.094980
 >> iter 33000, loss: 6.335759
 >> iter 34000, loss: 6.115423
 >> iter 35000, loss: 6.256192
   Number of active neurons: 4
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 36000, loss: 6.117526
 >> iter 37000, loss: 6.274794
 >> iter 38000, loss: 6.154727
 >> iter 39000, loss: 6.342365
 >> iter 40000, loss: 6.152491
   Number of active neurons: 4
 >> iter 41000, loss: 6.282456
 >> iter 42000, loss: 6.105162
 >> iter 43000, loss: 6.265836
 >> iter 44000, loss: 6.142106
 >> iter 45000, loss: 6.247648
   Number of active neurons: 4
   SHOCK
   Setting new limit to 287500.0 iters...
 >> iter 46000, loss: 6.116699
 >> iter 47000, loss: 6.267189
 >> iter 48000, loss: 6.168562
 >> iter 49000, loss: 6.292135
 >> iter 50000, loss: 6.139678
   Number of active neurons: 4
 >> iter 51000, loss: 6.326704
 >> iter 52000, loss: 6.147320
 >> iter 53000, loss: 6.319864
 >> iter 54000, loss: 6.108964
 >> iter 55000, loss: 6.261008
   Number of active neurons: 4
   SHOCK
   Setting new limit to 293750.0 iters...
 >> iter 56000, loss: 6.074981
 >> iter 57000, loss: 6.273263
 >> iter 58000, loss: 6.122900
 >> iter 59000, loss: 6.298494
 >> iter 60000, loss: 6.084961
   Number of active neurons: 4
 >> iter 61000, loss: 6.309160
 >> iter 62000, loss: 6.086100
 >> iter 63000, loss: 6.262825
 >> iter 64000, loss: 6.121885
 >> iter 65000, loss: 6.334610
   Number of active neurons: 4
   SHOCK
   Setting new limit to 296875.0 iters...
 >> iter 66000, loss: 6.131335
 >> iter 67000, loss: 6.276171
 >> iter 68000, loss: 6.095528
 >> iter 69000, loss: 6.244854
 >> iter 70000, loss: 6.145058
   Number of active neurons: 4
 >> iter 71000, loss: 6.307896
 >> iter 72000, loss: 6.151349
 >> iter 73000, loss: 6.354317
 >> iter 74000, loss: 6.109793
 >> iter 75000, loss: 6.309348
   Number of active neurons: 4
   SHOCK
   Setting new limit to 298437.5 iters...
 >> iter 76000, loss: 6.087973
 >> iter 77000, loss: 6.315526
 >> iter 78000, loss: 6.106652
 >> iter 79000, loss: 6.330698
 >> iter 80000, loss: 6.131358
   Number of active neurons: 4
 >> iter 81000, loss: 6.295617
 >> iter 82000, loss: 6.159269
 >> iter 83000, loss: 6.286306
 >> iter 84000, loss: 6.046052
 >> iter 85000, loss: 6.303941
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299218.75 iters...
 >> iter 86000, loss: 6.098736
 >> iter 87000, loss: 6.283565
 >> iter 88000, loss: 6.157332
 >> iter 89000, loss: 6.353702
 >> iter 90000, loss: 6.086695
   Number of active neurons: 4
 >> iter 91000, loss: 6.291875
 >> iter 92000, loss: 6.100260
 >> iter 93000, loss: 6.293462
 >> iter 94000, loss: 6.084868
 >> iter 95000, loss: 6.341363
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299609.375 iters...
 >> iter 96000, loss: 6.193656
 >> iter 97000, loss: 6.397965
 >> iter 98000, loss: 6.156269
 >> iter 99000, loss: 6.310480
 >> iter 100000, loss: 6.124881
   Number of active neurons: 4
 >> iter 101000, loss: 6.291159
 >> iter 102000, loss: 6.128076
 >> iter 103000, loss: 6.312586
 >> iter 104000, loss: 6.103952
 >> iter 105000, loss: 6.276115
   Number of active neurons: 4
   SHOCK
   Setting new limit to 299804.6875 iters...
 >> iter 106000, loss: 6.056682
 >> iter 107000, loss: 6.267856
 >> iter 108000, loss: 6.195486
 >> iter 109000, loss: 6.376583
 >> iter 110000, loss: 6.158954
   Number of active neurons: 6
 >> iter 111000, loss: 6.318716
 >> iter 112000, loss: 5.903148
 >> iter 113000, loss: 5.471916
 >> iter 114000, loss: 5.109609
 >> iter 115000, loss: 4.347539
 >> iter 116000, loss: 2.683862
 >> iter 117000, loss: 1.597717
 >> iter 118000, loss: 0.830965
 >> iter 119000, loss: 0.615183
 >> iter 120000, loss: 0.525733
   Number of active neurons: 6
 >> iter 121000, loss: 0.631413
 >> iter 122000, loss: 0.541472
 >> iter 123000, loss: 0.522770
 >> iter 124000, loss: 0.549569
 >> iter 125000, loss: 0.409095
 >> iter 126000, loss: 0.318926
 >> iter 127000, loss: 0.492262
 >> iter 128000, loss: 0.504697
 >> iter 129000, loss: 0.447449
 >> iter 130000, loss: 0.315036
   Number of active neurons: 6
 >> iter 131000, loss: 0.290297
 >> iter 132000, loss: 0.326307
 >> iter 133000, loss: 0.457109
 >> iter 134000, loss: 0.341627
 >> iter 135000, loss: 0.300124
 >> iter 136000, loss: 0.236667
 >> iter 137000, loss: 0.243867
 >> iter 138000, loss: 0.499645
 >> iter 139000, loss: 0.379993
 >> iter 140000, loss: 0.339967
   Number of active neurons: 6
 >> iter 141000, loss: 0.420476
 >> iter 142000, loss: 0.456767
 >> iter 143000, loss: 0.336331
 >> iter 144000, loss: 0.358343
 >> iter 145000, loss: 0.304499
 >> iter 146000, loss: 0.247584
 >> iter 147000, loss: 0.261479
 >> iter 148000, loss: 0.228828
 >> iter 149000, loss: 0.260697
 >> iter 150000, loss: 0.234894
   Number of active neurons: 6
 >> iter 151000, loss: 0.398603
 >> iter 152000, loss: 0.457736
 >> iter 153000, loss: 0.351458
 >> iter 154000, loss: 0.321422
 >> iter 155000, loss: 0.452692
 >> iter 156000, loss: 0.325738
 >> iter 157000, loss: 0.303189
 >> iter 158000, loss: 0.294881
 >> iter 159000, loss: 0.278959
 >> iter 160000, loss: 0.189103
   Number of active neurons: 5
 >> iter 161000, loss: 0.289325
 >> iter 162000, loss: 0.322016
 >> iter 163000, loss: 0.352702
 >> iter 164000, loss: 0.410516
 >> iter 165000, loss: 0.372156
 >> iter 166000, loss: 0.341331
 >> iter 167000, loss: 0.293931
 >> iter 168000, loss: 0.238408
 >> iter 169000, loss: 0.208317
 >> iter 170000, loss: 0.262789
   Number of active neurons: 5
 >> iter 171000, loss: 0.340990
 >> iter 172000, loss: 0.488658
 >> iter 173000, loss: 0.423177
 >> iter 174000, loss: 0.218904
 >> iter 175000, loss: 0.646594
 >> iter 176000, loss: 0.489833
 >> iter 177000, loss: 0.334845
 >> iter 178000, loss: 0.316553
 >> iter 179000, loss: 0.309187
 >> iter 180000, loss: 0.296410
   Number of active neurons: 5
 >> iter 181000, loss: 0.240557
 >> iter 182000, loss: 0.401832
 >> iter 183000, loss: 0.282801
 >> iter 184000, loss: 0.429803
 >> iter 185000, loss: 0.323216
 >> iter 186000, loss: 0.348729
 >> iter 187000, loss: 0.397658
 >> iter 188000, loss: 0.431184
 >> iter 189000, loss: 0.387080
 >> iter 190000, loss: 0.330652
   Number of active neurons: 5
 >> iter 191000, loss: 0.255027
 >> iter 192000, loss: 0.224994
 >> iter 193000, loss: 0.243570
 >> iter 194000, loss: 0.189476
 >> iter 195000, loss: 0.341464
 >> iter 196000, loss: 0.330634
 >> iter 197000, loss: 0.350127
 >> iter 198000, loss: 0.351694
 >> iter 199000, loss: 0.248195
 >> iter 200000, loss: 0.289045
   Number of active neurons: 5
 >> iter 201000, loss: 0.225163
 >> iter 202000, loss: 0.203724
 >> iter 203000, loss: 0.437835
 >> iter 204000, loss: 0.490747
 >> iter 205000, loss: 0.447749
 >> iter 206000, loss: 0.532102
 >> iter 207000, loss: 0.401616
 >> iter 208000, loss: 0.382063
 >> iter 209000, loss: 0.328587
 >> iter 210000, loss: 0.290997
   Number of active neurons: 5
 >> iter 211000, loss: 0.559903
 >> iter 212000, loss: 0.368381
 >> iter 213000, loss: 0.299671
 >> iter 214000, loss: 0.273609
 >> iter 215000, loss: 0.204495
 >> iter 216000, loss: 0.181421
 >> iter 217000, loss: 0.280316
 >> iter 218000, loss: 0.394442
 >> iter 219000, loss: 0.287256
 >> iter 220000, loss: 0.376902
   Number of active neurons: 5
 >> iter 221000, loss: 0.364183
 >> iter 222000, loss: 0.424952
 >> iter 223000, loss: 0.352813
 >> iter 224000, loss: 0.275085
 >> iter 225000, loss: 0.379783
 >> iter 226000, loss: 0.369889
 >> iter 227000, loss: 0.402673
 >> iter 228000, loss: 0.277545
 >> iter 229000, loss: 0.226939
 >> iter 230000, loss: 0.271909
   Number of active neurons: 5
 >> iter 231000, loss: 0.279480
 >> iter 232000, loss: 0.304341
 >> iter 233000, loss: 0.413539
 >> iter 234000, loss: 0.287556
 >> iter 235000, loss: 0.208587
 >> iter 236000, loss: 0.185655
 >> iter 237000, loss: 0.183272
 >> iter 238000, loss: 0.266196
 >> iter 239000, loss: 0.269731
 >> iter 240000, loss: 0.255300
   Number of active neurons: 5
 >> iter 241000, loss: 0.331016
 >> iter 242000, loss: 0.304245
 >> iter 243000, loss: 0.343783
 >> iter 244000, loss: 0.240520
 >> iter 245000, loss: 0.248901
 >> iter 246000, loss: 0.246678
 >> iter 247000, loss: 0.470722
 >> iter 248000, loss: 0.479957
 >> iter 249000, loss: 0.364262
 >> iter 250000, loss: 0.313424
   Number of active neurons: 5
 >> iter 251000, loss: 0.376152
 >> iter 252000, loss: 0.238141
 >> iter 253000, loss: 0.213580
 >> iter 254000, loss: 0.148821
 >> iter 255000, loss: 0.281839
 >> iter 256000, loss: 0.300665
 >> iter 257000, loss: 0.366549
 >> iter 258000, loss: 0.285269
 >> iter 259000, loss: 0.258414
 >> iter 260000, loss: 0.446381
   Number of active neurons: 5
 >> iter 261000, loss: 0.406606
 >> iter 262000, loss: 0.222910
 >> iter 263000, loss: 0.417206
 >> iter 264000, loss: 0.395149
 >> iter 265000, loss: 0.256412
 >> iter 266000, loss: 0.412261
 >> iter 267000, loss: 0.297616
 >> iter 268000, loss: 0.426599
 >> iter 269000, loss: 0.252144
 >> iter 270000, loss: 0.502626
   Number of active neurons: 5
 >> iter 271000, loss: 0.353338
 >> iter 272000, loss: 0.342819
 >> iter 273000, loss: 0.412856
 >> iter 274000, loss: 0.203804
 >> iter 275000, loss: 0.308130
 >> iter 276000, loss: 0.201640
 >> iter 277000, loss: 0.240796
 >> iter 278000, loss: 0.284242
 >> iter 279000, loss: 0.465785
 >> iter 280000, loss: 0.301960
   Number of active neurons: 5
 >> iter 281000, loss: 0.246611
 >> iter 282000, loss: 0.256885
 >> iter 283000, loss: 0.323266
 >> iter 284000, loss: 0.199733
 >> iter 285000, loss: 0.361483
 >> iter 286000, loss: 0.478599
 >> iter 287000, loss: 0.358129
 >> iter 288000, loss: 0.329432
 >> iter 289000, loss: 0.381429
 >> iter 290000, loss: 0.309325
   Number of active neurons: 5
 >> iter 291000, loss: 0.307054
 >> iter 292000, loss: 0.339948
 >> iter 293000, loss: 0.355493
 >> iter 294000, loss: 0.299314
 >> iter 295000, loss: 0.365847
 >> iter 296000, loss: 0.410075
 >> iter 297000, loss: 0.499341
 >> iter 298000, loss: 0.305307
 >> iter 299000, loss: 0.439591
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.180409
 >> iter 2000, loss: 14.132830
 >> iter 3000, loss: 9.675290
 >> iter 4000, loss: 5.479336
 >> iter 5000, loss: 2.492492
 >> iter 6000, loss: 1.342942
 >> iter 7000, loss: 0.694228
 >> iter 8000, loss: 0.378982
 >> iter 9000, loss: 0.354432
 >> iter 10000, loss: 0.300379
   Number of active neurons: 4
 >> iter 11000, loss: 0.472198
 >> iter 12000, loss: 0.320998
 >> iter 13000, loss: 0.249579
 >> iter 14000, loss: 0.250918
 >> iter 15000, loss: 0.468191
 >> iter 16000, loss: 0.424018
 >> iter 17000, loss: 0.354948
 >> iter 18000, loss: 0.280174
 >> iter 19000, loss: 0.405114
 >> iter 20000, loss: 0.321380
   Number of active neurons: 4
 >> iter 21000, loss: 0.179495
 >> iter 22000, loss: 0.381691
 >> iter 23000, loss: 0.288641
 >> iter 24000, loss: 0.227485
 >> iter 25000, loss: 0.317183
 >> iter 26000, loss: 0.334921
 >> iter 27000, loss: 0.358323
 >> iter 28000, loss: 0.310093
 >> iter 29000, loss: 0.414013
 >> iter 30000, loss: 0.424551
   Number of active neurons: 4
 >> iter 31000, loss: 0.267409
 >> iter 32000, loss: 0.251080
 >> iter 33000, loss: 0.180827
 >> iter 34000, loss: 0.199332
 >> iter 35000, loss: 0.267873
 >> iter 36000, loss: 0.278295
 >> iter 37000, loss: 0.271016
 >> iter 38000, loss: 0.206148
 >> iter 39000, loss: 0.271044
 >> iter 40000, loss: 0.200495
   Number of active neurons: 4
 >> iter 41000, loss: 0.352530
 >> iter 42000, loss: 0.349032
 >> iter 43000, loss: 0.308332
 >> iter 44000, loss: 0.284640
 >> iter 45000, loss: 0.447725
 >> iter 46000, loss: 0.360516
 >> iter 47000, loss: 0.370111
 >> iter 48000, loss: 0.284890
 >> iter 49000, loss: 0.228942
 >> iter 50000, loss: 0.205163
   Number of active neurons: 4
 >> iter 51000, loss: 0.296841
 >> iter 52000, loss: 0.179032
 >> iter 53000, loss: 0.143636
 >> iter 54000, loss: 0.189891
 >> iter 55000, loss: 0.237091
 >> iter 56000, loss: 0.197199
 >> iter 57000, loss: 0.302840
 >> iter 58000, loss: 0.215645
 >> iter 59000, loss: 0.234769
 >> iter 60000, loss: 0.161346
   Number of active neurons: 4
 >> iter 61000, loss: 0.208691
 >> iter 62000, loss: 0.329355
 >> iter 63000, loss: 0.335940
 >> iter 64000, loss: 0.364575
 >> iter 65000, loss: 0.260189
 >> iter 66000, loss: 0.323063
 >> iter 67000, loss: 0.352308
 >> iter 68000, loss: 0.297956
 >> iter 69000, loss: 0.297182
 >> iter 70000, loss: 0.192770
   Number of active neurons: 4
 >> iter 71000, loss: 0.176124
 >> iter 72000, loss: 0.119665
 >> iter 73000, loss: 0.269585
 >> iter 74000, loss: 0.322828
 >> iter 75000, loss: 0.236821
 >> iter 76000, loss: 0.205926
 >> iter 77000, loss: 0.198144
 >> iter 78000, loss: 0.207088
 >> iter 79000, loss: 0.239941
 >> iter 80000, loss: 0.219284
   Number of active neurons: 4
 >> iter 81000, loss: 0.145694
 >> iter 82000, loss: 0.235003
 >> iter 83000, loss: 0.291535
 >> iter 84000, loss: 0.391537
 >> iter 85000, loss: 0.371065
 >> iter 86000, loss: 0.209453
 >> iter 87000, loss: 0.260959
 >> iter 88000, loss: 0.243705
 >> iter 89000, loss: 0.315761
 >> iter 90000, loss: 0.239845
   Number of active neurons: 4
 >> iter 91000, loss: 0.268648
 >> iter 92000, loss: 0.215498
 >> iter 93000, loss: 0.288053
 >> iter 94000, loss: 0.195257
 >> iter 95000, loss: 0.269511
 >> iter 96000, loss: 0.279633
 >> iter 97000, loss: 0.262523
 >> iter 98000, loss: 0.224030
 >> iter 99000, loss: 0.352703
 >> iter 100000, loss: 0.361768
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.104187
 >> iter 2000, loss: 13.527138
 >> iter 3000, loss: 9.675638
 >> iter 4000, loss: 7.695988
 >> iter 5000, loss: 6.970437
 >> iter 6000, loss: 6.523309
 >> iter 7000, loss: 6.517666
 >> iter 8000, loss: 6.297466
 >> iter 9000, loss: 6.406177
 >> iter 10000, loss: 6.278409
   Number of active neurons: 5
 >> iter 11000, loss: 6.409798
 >> iter 12000, loss: 6.227813
 >> iter 13000, loss: 6.303221
 >> iter 14000, loss: 6.155274
 >> iter 15000, loss: 6.339703
   Number of active neurons: 5
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 6.221775
 >> iter 17000, loss: 6.318832
 >> iter 18000, loss: 6.218830
 >> iter 19000, loss: 6.357257
 >> iter 20000, loss: 6.338378
   Number of active neurons: 5
 >> iter 21000, loss: 6.501300
 >> iter 22000, loss: 6.226621
 >> iter 23000, loss: 6.377276
 >> iter 24000, loss: 6.184391
 >> iter 25000, loss: 6.338675
   Number of active neurons: 5
   SHOCK
   Setting new limit to 250000.0 iters...
 >> iter 26000, loss: 6.153499
 >> iter 27000, loss: 6.379700
 >> iter 28000, loss: 6.220175
 >> iter 29000, loss: 6.368231
 >> iter 30000, loss: 6.247546
   Number of active neurons: 5
 >> iter 31000, loss: 6.367157
 >> iter 32000, loss: 6.177155
 >> iter 33000, loss: 6.306526
 >> iter 34000, loss: 6.134771
 >> iter 35000, loss: 6.340834
   Number of active neurons: 5
   SHOCK
   Setting new limit to 275000.0 iters...
 >> iter 36000, loss: 6.187050
 >> iter 37000, loss: 6.337277
 >> iter 38000, loss: 6.203215
 >> iter 39000, loss: 6.348668
 >> iter 40000, loss: 6.201361
   Number of active neurons: 5
 >> iter 41000, loss: 6.375315
 >> iter 42000, loss: 6.200710
 >> iter 43000, loss: 6.437388
 >> iter 44000, loss: 6.215850
 >> iter 45000, loss: 6.346453
   Number of active neurons: 5
   SHOCK
   Setting new limit to 287500.0 iters...
 >> iter 46000, loss: 6.179233
 >> iter 47000, loss: 6.455475
 >> iter 48000, loss: 6.308392
 >> iter 49000, loss: 6.498455
 >> iter 50000, loss: 6.319529
   Number of active neurons: 5
 >> iter 51000, loss: 6.518068
 >> iter 52000, loss: 6.359141
 >> iter 53000, loss: 6.455724
 >> iter 54000, loss: 6.338715
 >> iter 55000, loss: 6.630421
   Number of active neurons: 6
   SHOCK
   Setting new limit to 293750.0 iters...
 >> iter 56000, loss: 6.358271
 >> iter 57000, loss: 6.568350
 >> iter 58000, loss: 6.434266
 >> iter 59000, loss: 6.501720
 >> iter 60000, loss: 6.499490
   Number of active neurons: 6
 >> iter 61000, loss: 6.521169
 >> iter 62000, loss: 6.303265
 >> iter 63000, loss: 6.456782
 >> iter 64000, loss: 6.426308
 >> iter 65000, loss: 6.008016
 >> iter 66000, loss: 4.674539
 >> iter 67000, loss: 3.156679
 >> iter 68000, loss: 1.824709
 >> iter 69000, loss: 0.923607
 >> iter 70000, loss: 0.598431
   Number of active neurons: 7
 >> iter 71000, loss: 0.770156
 >> iter 72000, loss: 0.608500
 >> iter 73000, loss: 1.250098
 >> iter 74000, loss: 0.671893
 >> iter 75000, loss: 1.104461
 >> iter 76000, loss: 0.833413
 >> iter 77000, loss: 0.729304
 >> iter 78000, loss: 0.723563
 >> iter 79000, loss: 0.596492
 >> iter 80000, loss: 0.386803
   Number of active neurons: 7
 >> iter 81000, loss: 0.633407
 >> iter 82000, loss: 0.694889
 >> iter 83000, loss: 0.692339
 >> iter 84000, loss: 0.486464
 >> iter 85000, loss: 0.679892
 >> iter 86000, loss: 0.426814
 >> iter 87000, loss: 0.364425
 >> iter 88000, loss: 0.748948
 >> iter 89000, loss: 0.532066
 >> iter 90000, loss: 0.335120
   Number of active neurons: 7
 >> iter 91000, loss: 0.433830
 >> iter 92000, loss: 0.468525
 >> iter 93000, loss: 0.530989
 >> iter 94000, loss: 0.484627
 >> iter 95000, loss: 0.506463
 >> iter 96000, loss: 0.272774
 >> iter 97000, loss: 0.427513
 >> iter 98000, loss: 0.424213
 >> iter 99000, loss: 0.481548
 >> iter 100000, loss: 0.488258
   Number of active neurons: 7
 >> iter 101000, loss: 0.523846
 >> iter 102000, loss: 0.643905
 >> iter 103000, loss: 0.597168
 >> iter 104000, loss: 0.383281
 >> iter 105000, loss: 0.483651
 >> iter 106000, loss: 0.320319
 >> iter 107000, loss: 0.458735
 >> iter 108000, loss: 0.506592
 >> iter 109000, loss: 0.437029
 >> iter 110000, loss: 0.397844
   Number of active neurons: 7
 >> iter 111000, loss: 0.402600
 >> iter 112000, loss: 0.497472
 >> iter 113000, loss: 0.545647
 >> iter 114000, loss: 0.440718
 >> iter 115000, loss: 0.609674
 >> iter 116000, loss: 0.505096
 >> iter 117000, loss: 0.528490
 >> iter 118000, loss: 0.428815
 >> iter 119000, loss: 0.428665
 >> iter 120000, loss: 0.339857
   Number of active neurons: 7
 >> iter 121000, loss: 0.313224
 >> iter 122000, loss: 0.252214
 >> iter 123000, loss: 0.416970
 >> iter 124000, loss: 0.443855
 >> iter 125000, loss: 0.401798
 >> iter 126000, loss: 0.323473
 >> iter 127000, loss: 0.383670
 >> iter 128000, loss: 0.654085
 >> iter 129000, loss: 0.392104
 >> iter 130000, loss: 0.289489
   Number of active neurons: 7
 >> iter 131000, loss: 0.543650
 >> iter 132000, loss: 0.288942
 >> iter 133000, loss: 0.318136
 >> iter 134000, loss: 0.313298
 >> iter 135000, loss: 0.450864
 >> iter 136000, loss: 0.436400
 >> iter 137000, loss: 0.365267
 >> iter 138000, loss: 0.390671
 >> iter 139000, loss: 0.445337
 >> iter 140000, loss: 0.472795
   Number of active neurons: 7
 >> iter 141000, loss: 0.646609
 >> iter 142000, loss: 0.349574
 >> iter 143000, loss: 0.297988
 >> iter 144000, loss: 0.348264
 >> iter 145000, loss: 0.267793
 >> iter 146000, loss: 0.486971
 >> iter 147000, loss: 0.350859
 >> iter 148000, loss: 0.357687
 >> iter 149000, loss: 0.444945
 >> iter 150000, loss: 0.362802
   Number of active neurons: 7
 >> iter 151000, loss: 0.422170
 >> iter 152000, loss: 0.392437
 >> iter 153000, loss: 0.403025
 >> iter 154000, loss: 0.395553
 >> iter 155000, loss: 0.348199
 >> iter 156000, loss: 0.392441
 >> iter 157000, loss: 0.532659
 >> iter 158000, loss: 0.539179
 >> iter 159000, loss: 0.419182
 >> iter 160000, loss: 0.520529
   Number of active neurons: 7
 >> iter 161000, loss: 0.460711
 >> iter 162000, loss: 0.610397
 >> iter 163000, loss: 0.550519
 >> iter 164000, loss: 0.528578
 >> iter 165000, loss: 0.321176
 >> iter 166000, loss: 0.365837
 >> iter 167000, loss: 0.682625
 >> iter 168000, loss: 0.499422
 >> iter 169000, loss: 0.464002
 >> iter 170000, loss: 0.366832
   Number of active neurons: 7
 >> iter 171000, loss: 0.418800
 >> iter 172000, loss: 0.305173
 >> iter 173000, loss: 0.369664
 >> iter 174000, loss: 0.323692
 >> iter 175000, loss: 0.226214
 >> iter 176000, loss: 0.712406
 >> iter 177000, loss: 0.391489
 >> iter 178000, loss: 0.386499
 >> iter 179000, loss: 0.354743
 >> iter 180000, loss: 0.349977
   Number of active neurons: 7
 >> iter 181000, loss: 0.368654
 >> iter 182000, loss: 0.403490
 >> iter 183000, loss: 0.641860
 >> iter 184000, loss: 0.385111
 >> iter 185000, loss: 0.530689
 >> iter 186000, loss: 0.473722
 >> iter 187000, loss: 0.503150
 >> iter 188000, loss: 0.488137
 >> iter 189000, loss: 0.300771
 >> iter 190000, loss: 0.379176
   Number of active neurons: 7
 >> iter 191000, loss: 0.315569
 >> iter 192000, loss: 0.332577
 >> iter 193000, loss: 0.376719
 >> iter 194000, loss: 0.261847
 >> iter 195000, loss: 0.613095
 >> iter 196000, loss: 0.310992
 >> iter 197000, loss: 0.231446
 >> iter 198000, loss: 0.242780
 >> iter 199000, loss: 0.342359
 >> iter 200000, loss: 0.319297
   Number of active neurons: 7
 >> iter 201000, loss: 0.358419
 >> iter 202000, loss: 0.465253
 >> iter 203000, loss: 0.522410
 >> iter 204000, loss: 0.495550
 >> iter 205000, loss: 0.498762
 >> iter 206000, loss: 0.377937
 >> iter 207000, loss: 0.431698
 >> iter 208000, loss: 0.255388
 >> iter 209000, loss: 0.237580
 >> iter 210000, loss: 0.343731
   Number of active neurons: 7
 >> iter 211000, loss: 0.418012
 >> iter 212000, loss: 0.285068
 >> iter 213000, loss: 0.344956
 >> iter 214000, loss: 0.245592
 >> iter 215000, loss: 0.378519
 >> iter 216000, loss: 0.263494
 >> iter 217000, loss: 0.331162
 >> iter 218000, loss: 0.276764
 >> iter 219000, loss: 0.347053
 >> iter 220000, loss: 0.308226
   Number of active neurons: 7
 >> iter 221000, loss: 0.372717
 >> iter 222000, loss: 0.300237
 >> iter 223000, loss: 0.238856
 >> iter 224000, loss: 0.349353
 >> iter 225000, loss: 0.426591
 >> iter 226000, loss: 0.327391
 >> iter 227000, loss: 0.263990
 >> iter 228000, loss: 0.326659
 >> iter 229000, loss: 0.286250
 >> iter 230000, loss: 0.341504
   Number of active neurons: 7
 >> iter 231000, loss: 0.259638
 >> iter 232000, loss: 0.291384
 >> iter 233000, loss: 0.326395
 >> iter 234000, loss: 0.290193
 >> iter 235000, loss: 0.288737
 >> iter 236000, loss: 0.229533
 >> iter 237000, loss: 0.182145
 >> iter 238000, loss: 0.220500
 >> iter 239000, loss: 0.348782
 >> iter 240000, loss: 0.242902
   Number of active neurons: 7
 >> iter 241000, loss: 0.303302
 >> iter 242000, loss: 0.249890
 >> iter 243000, loss: 0.281259
 >> iter 244000, loss: 0.322271
 >> iter 245000, loss: 0.250671
 >> iter 246000, loss: 0.225440
 >> iter 247000, loss: 0.270540
 >> iter 248000, loss: 0.246870
 >> iter 249000, loss: 0.301685
 >> iter 250000, loss: 0.223539
   Number of active neurons: 6
 >> iter 251000, loss: 0.161957
 >> iter 252000, loss: 0.464160
 >> iter 253000, loss: 0.355564
 >> iter 254000, loss: 0.250915
 >> iter 255000, loss: 0.156549
 >> iter 256000, loss: 0.141415
 >> iter 257000, loss: 0.359313
 >> iter 258000, loss: 0.226441
 >> iter 259000, loss: 0.275097
 >> iter 260000, loss: 0.255216
   Number of active neurons: 7
 >> iter 261000, loss: 0.252058
 >> iter 262000, loss: 0.171328
 >> iter 263000, loss: 0.173328
 >> iter 264000, loss: 0.189270
 >> iter 265000, loss: 0.249658
 >> iter 266000, loss: 0.298528
 >> iter 267000, loss: 0.272791
 >> iter 268000, loss: 0.266320
 >> iter 269000, loss: 0.169389
 >> iter 270000, loss: 0.232692
   Number of active neurons: 6
 >> iter 271000, loss: 0.240971
 >> iter 272000, loss: 0.187585
 >> iter 273000, loss: 0.168282
 >> iter 274000, loss: 0.227745
 >> iter 275000, loss: 0.274017
 >> iter 276000, loss: 0.262173
 >> iter 277000, loss: 0.291094
 >> iter 278000, loss: 0.310227
 >> iter 279000, loss: 0.232670
 >> iter 280000, loss: 0.315404
   Number of active neurons: 5
 >> iter 281000, loss: 0.273387
 >> iter 282000, loss: 0.312479
 >> iter 283000, loss: 0.190999
 >> iter 284000, loss: 0.173206
 >> iter 285000, loss: 0.128754
 >> iter 286000, loss: 0.160866
 >> iter 287000, loss: 0.133296
 >> iter 288000, loss: 0.173715
 >> iter 289000, loss: 0.352796
 >> iter 290000, loss: 0.281641
   Number of active neurons: 5
 >> iter 291000, loss: 0.332822
 >> iter 292000, loss: 0.243298
 >> iter 293000, loss: 0.189851
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.953505
 >> iter 2000, loss: 12.205543
 >> iter 3000, loss: 8.695796
 >> iter 4000, loss: 6.908254
 >> iter 5000, loss: 6.316441
 >> iter 6000, loss: 5.881110
 >> iter 7000, loss: 5.805784
 >> iter 8000, loss: 5.457599
 >> iter 9000, loss: 5.508933
 >> iter 10000, loss: 5.282081
   Number of active neurons: 3
 >> iter 11000, loss: 5.395158
 >> iter 12000, loss: 5.198470
 >> iter 13000, loss: 5.296395
 >> iter 14000, loss: 5.122015
 >> iter 15000, loss: 5.233949
 >> iter 16000, loss: 5.025047
 >> iter 17000, loss: 5.106733
 >> iter 18000, loss: 4.966195
 >> iter 19000, loss: 5.081628
 >> iter 20000, loss: 5.045259
   Number of active neurons: 3
 >> iter 21000, loss: 5.070021
 >> iter 22000, loss: 4.891132
 >> iter 23000, loss: 5.023585
 >> iter 24000, loss: 4.293239
 >> iter 25000, loss: 3.864739
 >> iter 26000, loss: 3.791678
 >> iter 27000, loss: 3.149150
 >> iter 28000, loss: 2.299232
 >> iter 29000, loss: 1.786431
 >> iter 30000, loss: 1.387043
   Number of active neurons: 7
 >> iter 31000, loss: 1.345519
 >> iter 32000, loss: 1.148131
 >> iter 33000, loss: 0.899305
 >> iter 34000, loss: 0.533302
 >> iter 35000, loss: 0.503109
 >> iter 36000, loss: 0.401701
 >> iter 37000, loss: 0.607120
 >> iter 38000, loss: 0.463303
 >> iter 39000, loss: 0.629586
 >> iter 40000, loss: 0.543102
   Number of active neurons: 8
 >> iter 41000, loss: 0.532458
 >> iter 42000, loss: 0.553588
 >> iter 43000, loss: 0.543410
 >> iter 44000, loss: 0.467926
 >> iter 45000, loss: 0.436083
 >> iter 46000, loss: 0.395182
 >> iter 47000, loss: 0.515251
 >> iter 48000, loss: 0.548654
 >> iter 49000, loss: 0.486521
 >> iter 50000, loss: 0.323699
   Number of active neurons: 8
 >> iter 51000, loss: 0.441444
 >> iter 52000, loss: 0.361747
 >> iter 53000, loss: 0.285351
 >> iter 54000, loss: 0.408950
 >> iter 55000, loss: 0.490078
 >> iter 56000, loss: 0.312481
 >> iter 57000, loss: 0.422739
 >> iter 58000, loss: 0.323950
 >> iter 59000, loss: 0.361375
 >> iter 60000, loss: 0.341989
   Number of active neurons: 7
 >> iter 61000, loss: 0.526259
 >> iter 62000, loss: 0.346008
 >> iter 63000, loss: 0.314237
 >> iter 64000, loss: 0.287435
 >> iter 65000, loss: 0.255974
 >> iter 66000, loss: 0.175110
 >> iter 67000, loss: 0.255976
 >> iter 68000, loss: 0.251775
 >> iter 69000, loss: 0.335483
 >> iter 70000, loss: 0.272378
   Number of active neurons: 7
 >> iter 71000, loss: 0.296417
 >> iter 72000, loss: 0.290508
 >> iter 73000, loss: 0.211185
 >> iter 74000, loss: 0.238015
 >> iter 75000, loss: 0.148250
 >> iter 76000, loss: 0.208954
 >> iter 77000, loss: 0.215376
 >> iter 78000, loss: 0.138709
 >> iter 79000, loss: 0.337540
 >> iter 80000, loss: 0.396736
   Number of active neurons: 5
 >> iter 81000, loss: 0.295439
 >> iter 82000, loss: 0.267824
 >> iter 83000, loss: 0.172410
 >> iter 84000, loss: 0.151892
 >> iter 85000, loss: 0.117913
 >> iter 86000, loss: 0.173452
 >> iter 87000, loss: 0.148815
 >> iter 88000, loss: 0.187729
 >> iter 89000, loss: 0.163087
 >> iter 90000, loss: 0.173542
   Number of active neurons: 5
 >> iter 91000, loss: 0.204416
 >> iter 92000, loss: 0.240631
 >> iter 93000, loss: 0.161425
 >> iter 94000, loss: 0.243269
 >> iter 95000, loss: 0.338845
 >> iter 96000, loss: 0.276283
 >> iter 97000, loss: 0.211111
 >> iter 98000, loss: 0.190436
 >> iter 99000, loss: 0.181534
 >> iter 100000, loss: 0.159881
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.031495
 >> iter 2000, loss: 13.953667
 >> iter 3000, loss: 10.949771
 >> iter 4000, loss: 8.355048
 >> iter 5000, loss: 7.318944
 >> iter 6000, loss: 5.816158
 >> iter 7000, loss: 4.233285
 >> iter 8000, loss: 2.547984
 >> iter 9000, loss: 1.834479
 >> iter 10000, loss: 1.251848
   Number of active neurons: 8
 >> iter 11000, loss: 1.005259
 >> iter 12000, loss: 1.632275
 >> iter 13000, loss: 1.058021
 >> iter 14000, loss: 0.827646
 >> iter 15000, loss: 0.724989
 >> iter 16000, loss: 0.933607
 >> iter 17000, loss: 0.767001
 >> iter 18000, loss: 0.850215
 >> iter 19000, loss: 0.535815
 >> iter 20000, loss: 0.532859
   Number of active neurons: 8
 >> iter 21000, loss: 0.442264
 >> iter 22000, loss: 0.484823
 >> iter 23000, loss: 0.580738
 >> iter 24000, loss: 0.765236
 >> iter 25000, loss: 0.736362
 >> iter 26000, loss: 0.711516
 >> iter 27000, loss: 0.910192
 >> iter 28000, loss: 0.939778
 >> iter 29000, loss: 0.643547
 >> iter 30000, loss: 0.675769
   Number of active neurons: 8
 >> iter 31000, loss: 0.585846
 >> iter 32000, loss: 0.573747
 >> iter 33000, loss: 0.471592
 >> iter 34000, loss: 0.338079
 >> iter 35000, loss: 0.540639
 >> iter 36000, loss: 0.777184
 >> iter 37000, loss: 0.588875
 >> iter 38000, loss: 0.578303
 >> iter 39000, loss: 0.708834
 >> iter 40000, loss: 0.646959
   Number of active neurons: 7
 >> iter 41000, loss: 0.484915
 >> iter 42000, loss: 0.386523
 >> iter 43000, loss: 0.657963
 >> iter 44000, loss: 0.554974
 >> iter 45000, loss: 0.506788
 >> iter 46000, loss: 0.509751
 >> iter 47000, loss: 0.510887
 >> iter 48000, loss: 0.385966
 >> iter 49000, loss: 0.344312
 >> iter 50000, loss: 0.354903
   Number of active neurons: 7
 >> iter 51000, loss: 0.351524
 >> iter 52000, loss: 0.382372
 >> iter 53000, loss: 0.283239
 >> iter 54000, loss: 0.567918
 >> iter 55000, loss: 0.551769
 >> iter 56000, loss: 0.680848
 >> iter 57000, loss: 0.622876
 >> iter 58000, loss: 0.590423
 >> iter 59000, loss: 0.575641
 >> iter 60000, loss: 0.460066
   Number of active neurons: 7
 >> iter 61000, loss: 0.365394
 >> iter 62000, loss: 0.314797
 >> iter 63000, loss: 0.358075
 >> iter 64000, loss: 0.327575
 >> iter 65000, loss: 0.292705
 >> iter 66000, loss: 0.384711
 >> iter 67000, loss: 0.344660
 >> iter 68000, loss: 0.361904
 >> iter 69000, loss: 0.535546
 >> iter 70000, loss: 0.517287
   Number of active neurons: 7
 >> iter 71000, loss: 0.530710
 >> iter 72000, loss: 0.499012
 >> iter 73000, loss: 0.370666
 >> iter 74000, loss: 0.390326
 >> iter 75000, loss: 0.536190
 >> iter 76000, loss: 0.511975
 >> iter 77000, loss: 0.313730
 >> iter 78000, loss: 0.442645
 >> iter 79000, loss: 0.447401
 >> iter 80000, loss: 0.499722
   Number of active neurons: 7
 >> iter 81000, loss: 0.428861
 >> iter 82000, loss: 0.379159
 >> iter 83000, loss: 0.393055
 >> iter 84000, loss: 0.373540
 >> iter 85000, loss: 0.370755
 >> iter 86000, loss: 0.266201
 >> iter 87000, loss: 0.433920
 >> iter 88000, loss: 0.370997
 >> iter 89000, loss: 0.416175
 >> iter 90000, loss: 0.383016
   Number of active neurons: 7
 >> iter 91000, loss: 0.325260
 >> iter 92000, loss: 0.381446
 >> iter 93000, loss: 0.331790
 >> iter 94000, loss: 0.469238
 >> iter 95000, loss: 0.663859
 >> iter 96000, loss: 0.458137
 >> iter 97000, loss: 0.421615
 >> iter 98000, loss: 0.498478
 >> iter 99000, loss: 0.538105
 >> iter 100000, loss: 0.523260
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.367050
 >> iter 2000, loss: 14.848353
 >> iter 3000, loss: 13.035084
 >> iter 4000, loss: 9.658463
 >> iter 5000, loss: 6.957110
 >> iter 6000, loss: 5.410681
 >> iter 7000, loss: 4.564212
 >> iter 8000, loss: 3.302632
 >> iter 9000, loss: 2.228876
 >> iter 10000, loss: 1.202885
   Number of active neurons: 7
 >> iter 11000, loss: 0.662170
 >> iter 12000, loss: 0.502538
 >> iter 13000, loss: 0.407104
 >> iter 14000, loss: 0.377479
 >> iter 15000, loss: 0.443133
 >> iter 16000, loss: 0.332861
 >> iter 17000, loss: 0.285986
 >> iter 18000, loss: 0.406157
 >> iter 19000, loss: 0.393520
 >> iter 20000, loss: 0.263023
   Number of active neurons: 7
 >> iter 21000, loss: 0.280827
 >> iter 22000, loss: 0.347951
 >> iter 23000, loss: 0.336276
 >> iter 24000, loss: 0.315263
 >> iter 25000, loss: 0.493442
 >> iter 26000, loss: 0.382651
 >> iter 27000, loss: 0.352856
 >> iter 28000, loss: 0.316781
 >> iter 29000, loss: 0.362605
 >> iter 30000, loss: 0.468477
   Number of active neurons: 6
 >> iter 31000, loss: 0.657419
 >> iter 32000, loss: 0.578494
 >> iter 33000, loss: 0.571420
 >> iter 34000, loss: 0.395915
 >> iter 35000, loss: 0.553671
 >> iter 36000, loss: 0.322137
 >> iter 37000, loss: 0.396209
 >> iter 38000, loss: 0.287587
 >> iter 39000, loss: 0.381241
 >> iter 40000, loss: 0.387215
   Number of active neurons: 5
 >> iter 41000, loss: 0.349405
 >> iter 42000, loss: 0.325156
 >> iter 43000, loss: 0.278783
 >> iter 44000, loss: 0.282887
 >> iter 45000, loss: 0.413582
 >> iter 46000, loss: 0.265558
 >> iter 47000, loss: 0.283592
 >> iter 48000, loss: 0.415759
 >> iter 49000, loss: 0.391235
 >> iter 50000, loss: 0.339403
   Number of active neurons: 5
 >> iter 51000, loss: 0.329330
 >> iter 52000, loss: 0.294737
 >> iter 53000, loss: 0.340768
 >> iter 54000, loss: 0.332983
 >> iter 55000, loss: 0.402447
 >> iter 56000, loss: 0.501495
 >> iter 57000, loss: 0.424100
 >> iter 58000, loss: 0.298695
 >> iter 59000, loss: 0.226566
 >> iter 60000, loss: 0.240747
   Number of active neurons: 5
 >> iter 61000, loss: 0.255479
 >> iter 62000, loss: 0.325812
 >> iter 63000, loss: 0.290856
 >> iter 64000, loss: 0.271230
 >> iter 65000, loss: 0.411230
 >> iter 66000, loss: 0.238322
 >> iter 67000, loss: 0.305525
 >> iter 68000, loss: 0.296539
 >> iter 69000, loss: 0.340162
 >> iter 70000, loss: 0.411271
   Number of active neurons: 5
 >> iter 71000, loss: 0.372217
 >> iter 72000, loss: 0.273881
 >> iter 73000, loss: 0.277427
 >> iter 74000, loss: 0.345110
 >> iter 75000, loss: 0.394614
 >> iter 76000, loss: 0.297115
 >> iter 77000, loss: 0.229008
 >> iter 78000, loss: 0.307367
 >> iter 79000, loss: 0.407092
 >> iter 80000, loss: 0.325860
   Number of active neurons: 5
 >> iter 81000, loss: 0.365266
 >> iter 82000, loss: 0.291195
 >> iter 83000, loss: 0.256414
 >> iter 84000, loss: 0.192601
 >> iter 85000, loss: 0.249905
 >> iter 86000, loss: 0.176971
 >> iter 87000, loss: 0.401506
 >> iter 88000, loss: 0.278920
 >> iter 89000, loss: 0.375677
 >> iter 90000, loss: 0.330057
   Number of active neurons: 5
 >> iter 91000, loss: 0.375482
 >> iter 92000, loss: 0.455472
 >> iter 93000, loss: 0.399899
 >> iter 94000, loss: 0.350602
 >> iter 95000, loss: 0.198452
 >> iter 96000, loss: 0.279269
 >> iter 97000, loss: 0.510953
 >> iter 98000, loss: 0.425226
 >> iter 99000, loss: 0.437428
 >> iter 100000, loss: 0.392784
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.700973
 >> iter 2000, loss: 9.617527
 >> iter 3000, loss: 4.025987
 >> iter 4000, loss: 1.954758
 >> iter 5000, loss: 1.075713
 >> iter 6000, loss: 0.610431
 >> iter 7000, loss: 0.584370
 >> iter 8000, loss: 0.475621
 >> iter 9000, loss: 0.366775
 >> iter 10000, loss: 0.341196
   Number of active neurons: 6
 >> iter 11000, loss: 0.335982
 >> iter 12000, loss: 0.207203
 >> iter 13000, loss: 0.272410
 >> iter 14000, loss: 0.466414
 >> iter 15000, loss: 0.436506
 >> iter 16000, loss: 0.410086
 >> iter 17000, loss: 0.470701
 >> iter 18000, loss: 0.361470
 >> iter 19000, loss: 0.249955
 >> iter 20000, loss: 0.321369
   Number of active neurons: 6
 >> iter 21000, loss: 0.395810
 >> iter 22000, loss: 0.300822
 >> iter 23000, loss: 0.284908
 >> iter 24000, loss: 0.235849
 >> iter 25000, loss: 0.321985
 >> iter 26000, loss: 0.236842
 >> iter 27000, loss: 0.237034
 >> iter 28000, loss: 0.264434
 >> iter 29000, loss: 0.362614
 >> iter 30000, loss: 0.295073
   Number of active neurons: 6
 >> iter 31000, loss: 0.361302
 >> iter 32000, loss: 0.491157
 >> iter 33000, loss: 0.397179
 >> iter 34000, loss: 0.372216
 >> iter 35000, loss: 0.386612
 >> iter 36000, loss: 0.243552
 >> iter 37000, loss: 0.305733
 >> iter 38000, loss: 0.337899
 >> iter 39000, loss: 0.336051
 >> iter 40000, loss: 0.388660
   Number of active neurons: 6
 >> iter 41000, loss: 0.329335
 >> iter 42000, loss: 0.314605
 >> iter 43000, loss: 0.421311
 >> iter 44000, loss: 0.329864
 >> iter 45000, loss: 0.360476
 >> iter 46000, loss: 0.329053
 >> iter 47000, loss: 0.334695
 >> iter 48000, loss: 0.263972
 >> iter 49000, loss: 0.510984
 >> iter 50000, loss: 0.338643
   Number of active neurons: 6
 >> iter 51000, loss: 0.453559
 >> iter 52000, loss: 0.331297
 >> iter 53000, loss: 0.401942
 >> iter 54000, loss: 0.328677
 >> iter 55000, loss: 0.266529
 >> iter 56000, loss: 0.258733
 >> iter 57000, loss: 0.285369
 >> iter 58000, loss: 0.307101
 >> iter 59000, loss: 0.262514
 >> iter 60000, loss: 0.391515
   Number of active neurons: 6
 >> iter 61000, loss: 0.305239
 >> iter 62000, loss: 0.173105
 >> iter 63000, loss: 0.300036
 >> iter 64000, loss: 0.315202
 >> iter 65000, loss: 0.265632
 >> iter 66000, loss: 0.328406
 >> iter 67000, loss: 0.370427
 >> iter 68000, loss: 0.421429
 >> iter 69000, loss: 0.436093
 >> iter 70000, loss: 0.224657
   Number of active neurons: 6
 >> iter 71000, loss: 0.311450
 >> iter 72000, loss: 0.318192
 >> iter 73000, loss: 0.288872
 >> iter 74000, loss: 0.285083
 >> iter 75000, loss: 0.356466
 >> iter 76000, loss: 0.385740
 >> iter 77000, loss: 0.337490
 >> iter 78000, loss: 0.427360
 >> iter 79000, loss: 0.430377
 >> iter 80000, loss: 0.442213
   Number of active neurons: 5
 >> iter 81000, loss: 0.425719
 >> iter 82000, loss: 0.228844
 >> iter 83000, loss: 0.416238
 >> iter 84000, loss: 0.315751
 >> iter 85000, loss: 0.268849
 >> iter 86000, loss: 0.395107
 >> iter 87000, loss: 0.279601
 >> iter 88000, loss: 0.270065
 >> iter 89000, loss: 0.263241
 >> iter 90000, loss: 0.420230
   Number of active neurons: 5
 >> iter 91000, loss: 0.433945
 >> iter 92000, loss: 0.328945
 >> iter 93000, loss: 0.332050
 >> iter 94000, loss: 0.351697
 >> iter 95000, loss: 0.358702
 >> iter 96000, loss: 0.409725
 >> iter 97000, loss: 0.276277
 >> iter 98000, loss: 0.387213
 >> iter 99000, loss: 0.314477
 >> iter 100000, loss: 0.384373
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.172058
 >> iter 2000, loss: 13.806629
 >> iter 3000, loss: 10.121272
 >> iter 4000, loss: 8.482468
 >> iter 5000, loss: 7.788872
 >> iter 6000, loss: 7.303429
 >> iter 7000, loss: 7.341355
 >> iter 8000, loss: 7.117824
 >> iter 9000, loss: 7.135021
 >> iter 10000, loss: 7.011679
   Number of active neurons: 4
 >> iter 11000, loss: 7.037987
 >> iter 12000, loss: 6.934737
 >> iter 13000, loss: 7.099689
 >> iter 14000, loss: 6.925054
 >> iter 15000, loss: 7.023320
   Number of active neurons: 4
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 6.838263
 >> iter 17000, loss: 6.955594
 >> iter 18000, loss: 6.569640
 >> iter 19000, loss: 6.678625
 >> iter 20000, loss: 6.318239
   Number of active neurons: 5
 >> iter 21000, loss: 6.367426
 >> iter 22000, loss: 4.372731
 >> iter 23000, loss: 2.362814
 >> iter 24000, loss: 1.344935
 >> iter 25000, loss: 0.947533
 >> iter 26000, loss: 0.562049
 >> iter 27000, loss: 0.645160
 >> iter 28000, loss: 0.511625
 >> iter 29000, loss: 0.519507
 >> iter 30000, loss: 0.452949
   Number of active neurons: 8
 >> iter 31000, loss: 0.382706
 >> iter 32000, loss: 0.431942
 >> iter 33000, loss: 0.508667
 >> iter 34000, loss: 0.441304
 >> iter 35000, loss: 0.579755
 >> iter 36000, loss: 0.425044
 >> iter 37000, loss: 0.465834
 >> iter 38000, loss: 0.483424
 >> iter 39000, loss: 0.449389
 >> iter 40000, loss: 0.455306
   Number of active neurons: 8
 >> iter 41000, loss: 0.528598
 >> iter 42000, loss: 0.358851
 >> iter 43000, loss: 0.290315
 >> iter 44000, loss: 0.449519
 >> iter 45000, loss: 0.482034
 >> iter 46000, loss: 0.526202
 >> iter 47000, loss: 0.527193
 >> iter 48000, loss: 0.374574
 >> iter 49000, loss: 0.460565
 >> iter 50000, loss: 0.317510
   Number of active neurons: 8
 >> iter 51000, loss: 0.381201
 >> iter 52000, loss: 0.608731
 >> iter 53000, loss: 0.610716
 >> iter 54000, loss: 0.522644
 >> iter 55000, loss: 0.419864
 >> iter 56000, loss: 0.423671
 >> iter 57000, loss: 0.500981
 >> iter 58000, loss: 0.325055
 >> iter 59000, loss: 0.492179
 >> iter 60000, loss: 0.522107
   Number of active neurons: 8
 >> iter 61000, loss: 0.427720
 >> iter 62000, loss: 0.392370
 >> iter 63000, loss: 0.453656
 >> iter 64000, loss: 0.497862
 >> iter 65000, loss: 0.372956
 >> iter 66000, loss: 0.329938
 >> iter 67000, loss: 0.408799
 >> iter 68000, loss: 0.437405
 >> iter 69000, loss: 0.378501
 >> iter 70000, loss: 0.340054
   Number of active neurons: 8
 >> iter 71000, loss: 0.473196
 >> iter 72000, loss: 0.404061
 >> iter 73000, loss: 0.370011
 >> iter 74000, loss: 0.490330
 >> iter 75000, loss: 0.485040
 >> iter 76000, loss: 0.355887
 >> iter 77000, loss: 0.475646
 >> iter 78000, loss: 0.401524
 >> iter 79000, loss: 0.451653
 >> iter 80000, loss: 0.362483
   Number of active neurons: 7
 >> iter 81000, loss: 0.400522
 >> iter 82000, loss: 0.334970
 >> iter 83000, loss: 0.326175
 >> iter 84000, loss: 0.428267
 >> iter 85000, loss: 0.419841
 >> iter 86000, loss: 0.301084
 >> iter 87000, loss: 0.410282
 >> iter 88000, loss: 0.355078
 >> iter 89000, loss: 0.354037
 >> iter 90000, loss: 0.361591
   Number of active neurons: 7
 >> iter 91000, loss: 0.635216
 >> iter 92000, loss: 0.449962
 >> iter 93000, loss: 0.377870
 >> iter 94000, loss: 0.300812
 >> iter 95000, loss: 0.266719
 >> iter 96000, loss: 0.316583
 >> iter 97000, loss: 0.384021
 >> iter 98000, loss: 0.386794
 >> iter 99000, loss: 0.418081
 >> iter 100000, loss: 0.307147
   Number of active neurons: 7
 >> iter 101000, loss: 0.437902
 >> iter 102000, loss: 0.374431
 >> iter 103000, loss: 0.326178
 >> iter 104000, loss: 0.325411
 >> iter 105000, loss: 0.372645
 >> iter 106000, loss: 0.448545
 >> iter 107000, loss: 0.281457
 >> iter 108000, loss: 0.282241
 >> iter 109000, loss: 0.358322
 >> iter 110000, loss: 0.391220
   Number of active neurons: 6
 >> iter 111000, loss: 0.425297
 >> iter 112000, loss: 0.348468
 >> iter 113000, loss: 0.487118
 >> iter 114000, loss: 0.384464
 >> iter 115000, loss: 0.387946
 >> iter 116000, loss: 0.341178
 >> iter 117000, loss: 0.316358
 >> iter 118000, loss: 0.228516
 >> iter 119000, loss: 0.354042
 >> iter 120000, loss: 0.395535
   Number of active neurons: 6
 >> iter 121000, loss: 0.346526
 >> iter 122000, loss: 0.430418
 >> iter 123000, loss: 0.498227
 >> iter 124000, loss: 0.316025
 >> iter 125000, loss: 0.264249
 >> iter 126000, loss: 0.380819
 >> iter 127000, loss: 0.345379
 >> iter 128000, loss: 0.444173
 >> iter 129000, loss: 0.413645
 >> iter 130000, loss: 0.302088
   Number of active neurons: 6
 >> iter 131000, loss: 0.278249
 >> iter 132000, loss: 0.414081
 >> iter 133000, loss: 0.372446
 >> iter 134000, loss: 0.465095
 >> iter 135000, loss: 0.343193
 >> iter 136000, loss: 0.489762
 >> iter 137000, loss: 0.400004
 >> iter 138000, loss: 0.343293
 >> iter 139000, loss: 0.514214
 >> iter 140000, loss: 0.574226
   Number of active neurons: 6
 >> iter 141000, loss: 0.335794
 >> iter 142000, loss: 0.274007
 >> iter 143000, loss: 0.351445
 >> iter 144000, loss: 0.284700
 >> iter 145000, loss: 0.316644
 >> iter 146000, loss: 0.399656
 >> iter 147000, loss: 0.385459
 >> iter 148000, loss: 0.473236
 >> iter 149000, loss: 0.308838
 >> iter 150000, loss: 0.347811
   Number of active neurons: 6
 >> iter 151000, loss: 0.410662
 >> iter 152000, loss: 0.370954
 >> iter 153000, loss: 0.295211
 >> iter 154000, loss: 0.283910
 >> iter 155000, loss: 0.535452
 >> iter 156000, loss: 0.417659
 >> iter 157000, loss: 0.368954
 >> iter 158000, loss: 0.321328
 >> iter 159000, loss: 0.374234
 >> iter 160000, loss: 0.348264
   Number of active neurons: 6
 >> iter 161000, loss: 0.275803
 >> iter 162000, loss: 0.276795
 >> iter 163000, loss: 0.310690
 >> iter 164000, loss: 0.305460
 >> iter 165000, loss: 0.290752
 >> iter 166000, loss: 0.331819
 >> iter 167000, loss: 0.372792
 >> iter 168000, loss: 0.319323
 >> iter 169000, loss: 0.374153
 >> iter 170000, loss: 0.380798
   Number of active neurons: 6
 >> iter 171000, loss: 0.410881
 >> iter 172000, loss: 0.511861
 >> iter 173000, loss: 0.436569
 >> iter 174000, loss: 0.466871
 >> iter 175000, loss: 0.460100
 >> iter 176000, loss: 0.356203
 >> iter 177000, loss: 0.434780
 >> iter 178000, loss: 0.298320
 >> iter 179000, loss: 0.322164
 >> iter 180000, loss: 0.369744
   Number of active neurons: 6
 >> iter 181000, loss: 0.330513
 >> iter 182000, loss: 0.364554
 >> iter 183000, loss: 0.308120
 >> iter 184000, loss: 0.322117
 >> iter 185000, loss: 0.339275
 >> iter 186000, loss: 0.356183
 >> iter 187000, loss: 0.277248
 >> iter 188000, loss: 0.353465
 >> iter 189000, loss: 0.375017
 >> iter 190000, loss: 0.474215
   Number of active neurons: 6
 >> iter 191000, loss: 0.363618
 >> iter 192000, loss: 0.253241
 >> iter 193000, loss: 0.497728
 >> iter 194000, loss: 0.390982
 >> iter 195000, loss: 0.367534
 >> iter 196000, loss: 0.398486
 >> iter 197000, loss: 0.338489
 >> iter 198000, loss: 0.372515
 >> iter 199000, loss: 0.468012
 >> iter 200000, loss: 0.427025
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.985029
 >> iter 2000, loss: 11.334680
 >> iter 3000, loss: 5.430525
 >> iter 4000, loss: 2.823480
 >> iter 5000, loss: 1.575523
 >> iter 6000, loss: 1.019392
 >> iter 7000, loss: 0.817101
 >> iter 8000, loss: 0.654647
 >> iter 9000, loss: 0.515367
 >> iter 10000, loss: 0.414228
   Number of active neurons: 4
 >> iter 11000, loss: 0.437952
 >> iter 12000, loss: 0.475565
 >> iter 13000, loss: 0.494115
 >> iter 14000, loss: 0.542709
 >> iter 15000, loss: 0.551832
 >> iter 16000, loss: 0.438603
 >> iter 17000, loss: 0.324583
 >> iter 18000, loss: 0.270786
 >> iter 19000, loss: 0.460707
 >> iter 20000, loss: 0.332996
   Number of active neurons: 4
 >> iter 21000, loss: 0.477334
 >> iter 22000, loss: 0.399293
 >> iter 23000, loss: 0.335027
 >> iter 24000, loss: 0.382777
 >> iter 25000, loss: 0.267521
 >> iter 26000, loss: 0.351783
 >> iter 27000, loss: 0.281304
 >> iter 28000, loss: 0.347537
 >> iter 29000, loss: 0.281187
 >> iter 30000, loss: 0.282697
   Number of active neurons: 4
 >> iter 31000, loss: 0.498661
 >> iter 32000, loss: 0.434832
 >> iter 33000, loss: 0.414785
 >> iter 34000, loss: 0.251304
 >> iter 35000, loss: 0.489748
 >> iter 36000, loss: 0.501401
 >> iter 37000, loss: 0.430544
 >> iter 38000, loss: 0.297939
 >> iter 39000, loss: 0.350151
 >> iter 40000, loss: 0.450670
   Number of active neurons: 4
 >> iter 41000, loss: 0.318970
 >> iter 42000, loss: 0.425860
 >> iter 43000, loss: 0.350466
 >> iter 44000, loss: 0.400526
 >> iter 45000, loss: 0.510681
 >> iter 46000, loss: 0.434524
 >> iter 47000, loss: 0.403825
 >> iter 48000, loss: 0.301036
 >> iter 49000, loss: 0.233315
 >> iter 50000, loss: 0.250555
   Number of active neurons: 4
 >> iter 51000, loss: 0.335966
 >> iter 52000, loss: 0.287714
 >> iter 53000, loss: 0.268075
 >> iter 54000, loss: 0.314287
 >> iter 55000, loss: 0.236598
 >> iter 56000, loss: 0.516780
 >> iter 57000, loss: 0.414973
 >> iter 58000, loss: 0.266421
 >> iter 59000, loss: 0.174339
 >> iter 60000, loss: 0.381570
   Number of active neurons: 4
 >> iter 61000, loss: 0.433749
 >> iter 62000, loss: 0.288404
 >> iter 63000, loss: 0.248480
 >> iter 64000, loss: 0.255625
 >> iter 65000, loss: 0.488639
 >> iter 66000, loss: 0.444580
 >> iter 67000, loss: 0.260100
 >> iter 68000, loss: 0.288700
 >> iter 69000, loss: 0.450507
 >> iter 70000, loss: 0.329647
   Number of active neurons: 4
 >> iter 71000, loss: 0.410534
 >> iter 72000, loss: 0.416457
 >> iter 73000, loss: 0.314322
 >> iter 74000, loss: 0.242307
 >> iter 75000, loss: 0.199088
 >> iter 76000, loss: 0.213180
 >> iter 77000, loss: 0.294968
 >> iter 78000, loss: 0.379420
 >> iter 79000, loss: 0.445124
 >> iter 80000, loss: 0.437956
   Number of active neurons: 4
 >> iter 81000, loss: 0.424803
 >> iter 82000, loss: 0.396957
 >> iter 83000, loss: 0.355756
 >> iter 84000, loss: 0.369037
 >> iter 85000, loss: 0.267418
 >> iter 86000, loss: 0.299312
 >> iter 87000, loss: 0.428542
 >> iter 88000, loss: 0.407964
 >> iter 89000, loss: 0.500134
 >> iter 90000, loss: 0.481385
   Number of active neurons: 4
 >> iter 91000, loss: 0.329105
 >> iter 92000, loss: 0.247756
 >> iter 93000, loss: 0.270315
 >> iter 94000, loss: 0.409998
 >> iter 95000, loss: 0.399992
 >> iter 96000, loss: 0.406533
 >> iter 97000, loss: 0.367587
 >> iter 98000, loss: 0.340497
 >> iter 99000, loss: 0.262753
 >> iter 100000, loss: 0.347458
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.325829
 >> iter 2000, loss: 14.328772
 >> iter 3000, loss: 10.896846
 >> iter 4000, loss: 5.765403
 >> iter 5000, loss: 2.620687
 >> iter 6000, loss: 1.549970
 >> iter 7000, loss: 0.779259
 >> iter 8000, loss: 0.595110
 >> iter 9000, loss: 0.524180
 >> iter 10000, loss: 0.493944
   Number of active neurons: 4
 >> iter 11000, loss: 0.555267
 >> iter 12000, loss: 0.563123
 >> iter 13000, loss: 0.567550
 >> iter 14000, loss: 0.415330
 >> iter 15000, loss: 0.460751
 >> iter 16000, loss: 0.314433
 >> iter 17000, loss: 0.370030
 >> iter 18000, loss: 0.311200
 >> iter 19000, loss: 0.268589
 >> iter 20000, loss: 0.275013
   Number of active neurons: 4
 >> iter 21000, loss: 0.385405
 >> iter 22000, loss: 0.319712
 >> iter 23000, loss: 0.423490
 >> iter 24000, loss: 0.380809
 >> iter 25000, loss: 0.329335
 >> iter 26000, loss: 0.332871
 >> iter 27000, loss: 0.519233
 >> iter 28000, loss: 0.493992
 >> iter 29000, loss: 0.381155
 >> iter 30000, loss: 0.338370
   Number of active neurons: 4
 >> iter 31000, loss: 0.331038
 >> iter 32000, loss: 0.408073
 >> iter 33000, loss: 0.294510
 >> iter 34000, loss: 0.359151
 >> iter 35000, loss: 0.335103
 >> iter 36000, loss: 0.283151
 >> iter 37000, loss: 0.504074
 >> iter 38000, loss: 0.380725
 >> iter 39000, loss: 0.431946
 >> iter 40000, loss: 0.306222
   Number of active neurons: 4
 >> iter 41000, loss: 0.214267
 >> iter 42000, loss: 0.340162
 >> iter 43000, loss: 0.398044
 >> iter 44000, loss: 0.309801
 >> iter 45000, loss: 0.352370
 >> iter 46000, loss: 0.444838
 >> iter 47000, loss: 0.308105
 >> iter 48000, loss: 0.184194
 >> iter 49000, loss: 0.287561
 >> iter 50000, loss: 0.368137
   Number of active neurons: 4
 >> iter 51000, loss: 0.231047
 >> iter 52000, loss: 0.309598
 >> iter 53000, loss: 0.385599
 >> iter 54000, loss: 0.358168
 >> iter 55000, loss: 0.291925
 >> iter 56000, loss: 0.487905
 >> iter 57000, loss: 0.388811
 >> iter 58000, loss: 0.302180
 >> iter 59000, loss: 0.339523
 >> iter 60000, loss: 0.443927
   Number of active neurons: 4
 >> iter 61000, loss: 0.395200
 >> iter 62000, loss: 0.459548
 >> iter 63000, loss: 0.394476
 >> iter 64000, loss: 0.328570
 >> iter 65000, loss: 0.490249
 >> iter 66000, loss: 0.316585
 >> iter 67000, loss: 0.256630
 >> iter 68000, loss: 0.354667
 >> iter 69000, loss: 0.276583
 >> iter 70000, loss: 0.340612
   Number of active neurons: 4
 >> iter 71000, loss: 0.326883
 >> iter 72000, loss: 0.262856
 >> iter 73000, loss: 0.407905
 >> iter 74000, loss: 0.342475
 >> iter 75000, loss: 0.387633
 >> iter 76000, loss: 0.458351
 >> iter 77000, loss: 0.413583
 >> iter 78000, loss: 0.327067
 >> iter 79000, loss: 0.410438
 >> iter 80000, loss: 0.373553
   Number of active neurons: 4
 >> iter 81000, loss: 0.447991
 >> iter 82000, loss: 0.415228
 >> iter 83000, loss: 0.305212
 >> iter 84000, loss: 0.340688
 >> iter 85000, loss: 0.344692
 >> iter 86000, loss: 0.556468
 >> iter 87000, loss: 0.475628
 >> iter 88000, loss: 0.444924
 >> iter 89000, loss: 0.309653
 >> iter 90000, loss: 0.365079
   Number of active neurons: 4
 >> iter 91000, loss: 0.473178
 >> iter 92000, loss: 0.363025
 >> iter 93000, loss: 0.327436
 >> iter 94000, loss: 0.451180
 >> iter 95000, loss: 0.582805
 >> iter 96000, loss: 0.597941
 >> iter 97000, loss: 0.477539
 >> iter 98000, loss: 0.362610
 >> iter 99000, loss: 0.351341
 >> iter 100000, loss: 0.232750
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.009999800004
   - Test - Long: 0.0
   - Test - Big: 0.0079999200008
   - Test - A: 0.0
   - Test - B: 13.4524365042
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.122651
 >> iter 2000, loss: 13.834768
 >> iter 3000, loss: 8.423894
 >> iter 4000, loss: 4.896859
 >> iter 5000, loss: 2.971695
 >> iter 6000, loss: 1.662355
 >> iter 7000, loss: 0.977834
 >> iter 8000, loss: 0.825759
 >> iter 9000, loss: 0.722792
 >> iter 10000, loss: 0.562486
   Number of active neurons: 6
 >> iter 11000, loss: 0.624398
 >> iter 12000, loss: 0.567086
 >> iter 13000, loss: 0.631839
 >> iter 14000, loss: 0.405554
 >> iter 15000, loss: 0.588711
 >> iter 16000, loss: 0.447174
 >> iter 17000, loss: 0.419908
 >> iter 18000, loss: 0.475626
 >> iter 19000, loss: 0.438627
 >> iter 20000, loss: 0.406875
   Number of active neurons: 6
 >> iter 21000, loss: 0.493187
 >> iter 22000, loss: 0.559685
 >> iter 23000, loss: 0.451056
 >> iter 24000, loss: 0.489250
 >> iter 25000, loss: 0.424763
 >> iter 26000, loss: 0.305573
 >> iter 27000, loss: 0.274963
 >> iter 28000, loss: 0.314608
 >> iter 29000, loss: 0.388779
 >> iter 30000, loss: 0.406419
   Number of active neurons: 6
 >> iter 31000, loss: 0.598551
 >> iter 32000, loss: 0.323380
 >> iter 33000, loss: 0.338447
 >> iter 34000, loss: 0.412063
 >> iter 35000, loss: 0.369618
 >> iter 36000, loss: 0.341916
 >> iter 37000, loss: 0.320453
 >> iter 38000, loss: 0.428512
 >> iter 39000, loss: 0.334264
 >> iter 40000, loss: 0.321385
   Number of active neurons: 6
 >> iter 41000, loss: 0.323101
 >> iter 42000, loss: 0.434462
 >> iter 43000, loss: 0.314436
 >> iter 44000, loss: 0.254015
 >> iter 45000, loss: 0.305825
 >> iter 46000, loss: 0.275162
 >> iter 47000, loss: 0.409303
 >> iter 48000, loss: 0.324793
 >> iter 49000, loss: 0.229120
 >> iter 50000, loss: 0.332480
   Number of active neurons: 6
 >> iter 51000, loss: 0.274889
 >> iter 52000, loss: 0.290432
 >> iter 53000, loss: 0.286197
 >> iter 54000, loss: 0.432009
 >> iter 55000, loss: 0.363312
 >> iter 56000, loss: 0.283439
 >> iter 57000, loss: 0.230878
 >> iter 58000, loss: 0.258017
 >> iter 59000, loss: 0.423869
 >> iter 60000, loss: 0.354614
   Number of active neurons: 5
 >> iter 61000, loss: 0.276356
 >> iter 62000, loss: 0.152264
 >> iter 63000, loss: 0.536638
 >> iter 64000, loss: 0.356564
 >> iter 65000, loss: 0.327887
 >> iter 66000, loss: 0.330833
 >> iter 67000, loss: 0.291421
 >> iter 68000, loss: 0.303648
 >> iter 69000, loss: 0.283098
 >> iter 70000, loss: 0.247323
   Number of active neurons: 5
 >> iter 71000, loss: 0.242462
 >> iter 72000, loss: 0.192173
 >> iter 73000, loss: 0.254574
 >> iter 74000, loss: 0.246632
 >> iter 75000, loss: 0.233191
 >> iter 76000, loss: 0.263169
 >> iter 77000, loss: 0.247617
 >> iter 78000, loss: 0.264065
 >> iter 79000, loss: 0.340647
 >> iter 80000, loss: 0.332634
   Number of active neurons: 5
 >> iter 81000, loss: 0.337621
 >> iter 82000, loss: 0.338152
 >> iter 83000, loss: 0.280693
 >> iter 84000, loss: 0.277398
 >> iter 85000, loss: 0.216717
 >> iter 86000, loss: 0.294571
 >> iter 87000, loss: 0.226826
 >> iter 88000, loss: 0.254195
 >> iter 89000, loss: 0.305974
 >> iter 90000, loss: 0.202868
   Number of active neurons: 5
 >> iter 91000, loss: 0.235382
 >> iter 92000, loss: 0.354709
 >> iter 93000, loss: 0.296817
 >> iter 94000, loss: 0.338740
 >> iter 95000, loss: 0.254306
 >> iter 96000, loss: 0.208893
 >> iter 97000, loss: 0.205881
 >> iter 98000, loss: 0.234903
 >> iter 99000, loss: 0.327093
 >> iter 100000, loss: 0.380154
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.310335
 >> iter 2000, loss: 13.853898
 >> iter 3000, loss: 7.613696
 >> iter 4000, loss: 3.977015
 >> iter 5000, loss: 2.023016
 >> iter 6000, loss: 1.200775
 >> iter 7000, loss: 0.978886
 >> iter 8000, loss: 0.700623
 >> iter 9000, loss: 0.733943
 >> iter 10000, loss: 0.643096
   Number of active neurons: 5
 >> iter 11000, loss: 0.458129
 >> iter 12000, loss: 0.435784
 >> iter 13000, loss: 0.356805
 >> iter 14000, loss: 0.324358
 >> iter 15000, loss: 0.357233
 >> iter 16000, loss: 0.476194
 >> iter 17000, loss: 0.311738
 >> iter 18000, loss: 0.535800
 >> iter 19000, loss: 0.545146
 >> iter 20000, loss: 0.410516
   Number of active neurons: 5
 >> iter 21000, loss: 0.326409
 >> iter 22000, loss: 0.468735
 >> iter 23000, loss: 0.410660
 >> iter 24000, loss: 0.548692
 >> iter 25000, loss: 0.431224
 >> iter 26000, loss: 0.469771
 >> iter 27000, loss: 0.376764
 >> iter 28000, loss: 0.353646
 >> iter 29000, loss: 0.340168
 >> iter 30000, loss: 0.522035
   Number of active neurons: 4
 >> iter 31000, loss: 0.533777
 >> iter 32000, loss: 0.456559
 >> iter 33000, loss: 0.507700
 >> iter 34000, loss: 0.362733
 >> iter 35000, loss: 0.325170
 >> iter 36000, loss: 0.347098
 >> iter 37000, loss: 0.305653
 >> iter 38000, loss: 0.314003
 >> iter 39000, loss: 0.229853
 >> iter 40000, loss: 0.212927
   Number of active neurons: 4
 >> iter 41000, loss: 0.218351
 >> iter 42000, loss: 0.269072
 >> iter 43000, loss: 0.378262
 >> iter 44000, loss: 0.391148
 >> iter 45000, loss: 0.476367
 >> iter 46000, loss: 0.321081
 >> iter 47000, loss: 0.438567
 >> iter 48000, loss: 0.314761
 >> iter 49000, loss: 0.482814
 >> iter 50000, loss: 0.364395
   Number of active neurons: 4
 >> iter 51000, loss: 0.330869
 >> iter 52000, loss: 0.318143
 >> iter 53000, loss: 0.314119
 >> iter 54000, loss: 0.521140
 >> iter 55000, loss: 0.467804
 >> iter 56000, loss: 0.557637
 >> iter 57000, loss: 0.586218
 >> iter 58000, loss: 0.339292
 >> iter 59000, loss: 0.416779
 >> iter 60000, loss: 0.435055
   Number of active neurons: 4
 >> iter 61000, loss: 0.463289
 >> iter 62000, loss: 0.298783
 >> iter 63000, loss: 0.354687
 >> iter 64000, loss: 0.405801
 >> iter 65000, loss: 0.337476
 >> iter 66000, loss: 0.284719
 >> iter 67000, loss: 0.275465
 >> iter 68000, loss: 0.471134
 >> iter 69000, loss: 0.555739
 >> iter 70000, loss: 0.536799
   Number of active neurons: 4
 >> iter 71000, loss: 0.430480
 >> iter 72000, loss: 0.340670
 >> iter 73000, loss: 0.417710
 >> iter 74000, loss: 0.444699
 >> iter 75000, loss: 0.515824
 >> iter 76000, loss: 0.424204
 >> iter 77000, loss: 0.348258
 >> iter 78000, loss: 0.569191
 >> iter 79000, loss: 0.607885
 >> iter 80000, loss: 0.465840
   Number of active neurons: 4
 >> iter 81000, loss: 0.362476
 >> iter 82000, loss: 0.386266
 >> iter 83000, loss: 0.301110
 >> iter 84000, loss: 0.391974
 >> iter 85000, loss: 0.441426
 >> iter 86000, loss: 0.321290
 >> iter 87000, loss: 0.353679
 >> iter 88000, loss: 0.467628
 >> iter 89000, loss: 0.357350
 >> iter 90000, loss: 0.313746
   Number of active neurons: 4
 >> iter 91000, loss: 0.271176
 >> iter 92000, loss: 0.446876
 >> iter 93000, loss: 0.280566
 >> iter 94000, loss: 0.314610
 >> iter 95000, loss: 0.327528
 >> iter 96000, loss: 0.273083
 >> iter 97000, loss: 0.224534
 >> iter 98000, loss: 0.360291
 >> iter 99000, loss: 0.351611
 >> iter 100000, loss: 0.307770
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0039999200016
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 13.0257982801
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.058354
 >> iter 2000, loss: 12.086283
 >> iter 3000, loss: 6.199751
 >> iter 4000, loss: 2.756041
 >> iter 5000, loss: 1.664461
 >> iter 6000, loss: 0.933312
 >> iter 7000, loss: 0.639995
 >> iter 8000, loss: 0.363642
 >> iter 9000, loss: 0.385792
 >> iter 10000, loss: 0.400716
   Number of active neurons: 5
 >> iter 11000, loss: 0.298279
 >> iter 12000, loss: 0.266976
 >> iter 13000, loss: 0.535455
 >> iter 14000, loss: 0.312396
 >> iter 15000, loss: 0.336064
 >> iter 16000, loss: 0.302257
 >> iter 17000, loss: 0.301088
 >> iter 18000, loss: 0.529031
 >> iter 19000, loss: 0.423012
 >> iter 20000, loss: 0.627565
   Number of active neurons: 5
 >> iter 21000, loss: 0.512275
 >> iter 22000, loss: 0.421310
 >> iter 23000, loss: 0.398481
 >> iter 24000, loss: 0.273145
 >> iter 25000, loss: 0.581084
 >> iter 26000, loss: 0.446517
 >> iter 27000, loss: 0.385576
 >> iter 28000, loss: 0.376957
 >> iter 29000, loss: 0.546078
 >> iter 30000, loss: 0.347427
   Number of active neurons: 5
 >> iter 31000, loss: 0.422496
 >> iter 32000, loss: 0.411774
 >> iter 33000, loss: 0.366771
 >> iter 34000, loss: 0.238589
 >> iter 35000, loss: 0.196292
 >> iter 36000, loss: 0.288256
 >> iter 37000, loss: 0.285475
 >> iter 38000, loss: 0.170106
 >> iter 39000, loss: 0.333030
 >> iter 40000, loss: 0.379813
   Number of active neurons: 5
 >> iter 41000, loss: 0.305361
 >> iter 42000, loss: 0.380099
 >> iter 43000, loss: 0.575836
 >> iter 44000, loss: 0.346816
 >> iter 45000, loss: 0.273872
 >> iter 46000, loss: 0.497888
 >> iter 47000, loss: 0.397591
 >> iter 48000, loss: 0.367314
 >> iter 49000, loss: 0.249157
 >> iter 50000, loss: 0.521995
   Number of active neurons: 5
 >> iter 51000, loss: 0.490997
 >> iter 52000, loss: 0.426914
 >> iter 53000, loss: 0.454624
 >> iter 54000, loss: 0.365883
 >> iter 55000, loss: 0.379148
 >> iter 56000, loss: 0.228946
 >> iter 57000, loss: 0.328206
 >> iter 58000, loss: 0.517558
 >> iter 59000, loss: 0.491608
 >> iter 60000, loss: 0.478818
   Number of active neurons: 5
 >> iter 61000, loss: 0.359006
 >> iter 62000, loss: 0.285103
 >> iter 63000, loss: 0.273269
 >> iter 64000, loss: 0.352090
 >> iter 65000, loss: 0.476850
 >> iter 66000, loss: 0.358614
 >> iter 67000, loss: 0.520793
 >> iter 68000, loss: 0.388753
 >> iter 69000, loss: 0.429247
 >> iter 70000, loss: 0.498553
   Number of active neurons: 5
 >> iter 71000, loss: 0.342920
 >> iter 72000, loss: 0.322497
 >> iter 73000, loss: 0.464527
 >> iter 74000, loss: 0.464415
 >> iter 75000, loss: 0.446072
 >> iter 76000, loss: 0.416773
 >> iter 77000, loss: 0.252888
 >> iter 78000, loss: 0.208961
 >> iter 79000, loss: 0.253053
 >> iter 80000, loss: 0.282397
   Number of active neurons: 5
 >> iter 81000, loss: 0.229970
 >> iter 82000, loss: 0.332967
 >> iter 83000, loss: 0.479653
 >> iter 84000, loss: 0.335262
 >> iter 85000, loss: 0.413567
 >> iter 86000, loss: 0.373971
 >> iter 87000, loss: 0.270197
 >> iter 88000, loss: 0.307162
 >> iter 89000, loss: 0.398081
 >> iter 90000, loss: 0.410277
   Number of active neurons: 5
 >> iter 91000, loss: 0.438320
 >> iter 92000, loss: 0.327888
 >> iter 93000, loss: 0.329748
 >> iter 94000, loss: 0.550270
 >> iter 95000, loss: 0.431336
 >> iter 96000, loss: 0.319980
 >> iter 97000, loss: 0.279243
 >> iter 98000, loss: 0.469029
 >> iter 99000, loss: 0.535036
 >> iter 100000, loss: 0.511767
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.256287
 >> iter 2000, loss: 13.128304
 >> iter 3000, loss: 6.760006
 >> iter 4000, loss: 2.991374
 >> iter 5000, loss: 1.751960
 >> iter 6000, loss: 0.867029
 >> iter 7000, loss: 0.767453
 >> iter 8000, loss: 0.454334
 >> iter 9000, loss: 0.391805
 >> iter 10000, loss: 0.376347
   Number of active neurons: 6
 >> iter 11000, loss: 0.430831
 >> iter 12000, loss: 0.343188
 >> iter 13000, loss: 0.298693
 >> iter 14000, loss: 0.358977
 >> iter 15000, loss: 0.258136
 >> iter 16000, loss: 0.226158
 >> iter 17000, loss: 0.188164
 >> iter 18000, loss: 0.198704
 >> iter 19000, loss: 0.264546
 >> iter 20000, loss: 0.220389
   Number of active neurons: 6
 >> iter 21000, loss: 0.421783
 >> iter 22000, loss: 0.383540
 >> iter 23000, loss: 0.316029
 >> iter 24000, loss: 0.331616
 >> iter 25000, loss: 0.342978
 >> iter 26000, loss: 0.253873
 >> iter 27000, loss: 0.432010
 >> iter 28000, loss: 0.335327
 >> iter 29000, loss: 0.238456
 >> iter 30000, loss: 0.213811
   Number of active neurons: 5
 >> iter 31000, loss: 0.212480
 >> iter 32000, loss: 0.403642
 >> iter 33000, loss: 0.430604
 >> iter 34000, loss: 0.265796
 >> iter 35000, loss: 0.245791
 >> iter 36000, loss: 0.342404
 >> iter 37000, loss: 0.286494
 >> iter 38000, loss: 0.299211
 >> iter 39000, loss: 0.291114
 >> iter 40000, loss: 0.482916
   Number of active neurons: 5
 >> iter 41000, loss: 0.374224
 >> iter 42000, loss: 0.344455
 >> iter 43000, loss: 0.455284
 >> iter 44000, loss: 0.281651
 >> iter 45000, loss: 0.307464
 >> iter 46000, loss: 0.222922
 >> iter 47000, loss: 0.444166
 >> iter 48000, loss: 0.424763
 >> iter 49000, loss: 0.368723
 >> iter 50000, loss: 0.346745
   Number of active neurons: 5
 >> iter 51000, loss: 0.379274
 >> iter 52000, loss: 0.293668
 >> iter 53000, loss: 0.249871
 >> iter 54000, loss: 0.216942
 >> iter 55000, loss: 0.360301
 >> iter 56000, loss: 0.360856
 >> iter 57000, loss: 0.382239
 >> iter 58000, loss: 0.238162
 >> iter 59000, loss: 0.177019
 >> iter 60000, loss: 0.261480
   Number of active neurons: 5
 >> iter 61000, loss: 0.211028
 >> iter 62000, loss: 0.269947
 >> iter 63000, loss: 0.268768
 >> iter 64000, loss: 0.216385
 >> iter 65000, loss: 0.308879
 >> iter 66000, loss: 0.278591
 >> iter 67000, loss: 0.297373
 >> iter 68000, loss: 0.238484
 >> iter 69000, loss: 0.302781
 >> iter 70000, loss: 0.256752
   Number of active neurons: 5
 >> iter 71000, loss: 0.197657
 >> iter 72000, loss: 0.243248
 >> iter 73000, loss: 0.241336
 >> iter 74000, loss: 0.372117
 >> iter 75000, loss: 0.222110
 >> iter 76000, loss: 0.275981
 >> iter 77000, loss: 0.297420
 >> iter 78000, loss: 0.222944
 >> iter 79000, loss: 0.228315
 >> iter 80000, loss: 0.225660
   Number of active neurons: 5
 >> iter 81000, loss: 0.240620
 >> iter 82000, loss: 0.195148
 >> iter 83000, loss: 0.132905
 >> iter 84000, loss: 0.136210
 >> iter 85000, loss: 0.127957
 >> iter 86000, loss: 0.145228
 >> iter 87000, loss: 0.123292
 >> iter 88000, loss: 0.227942
 >> iter 89000, loss: 0.263152
 >> iter 90000, loss: 0.222014
   Number of active neurons: 5
 >> iter 91000, loss: 0.229075
 >> iter 92000, loss: 0.353090
 >> iter 93000, loss: 0.256124
 >> iter 94000, loss: 0.214651
 >> iter 95000, loss: 0.218954
 >> iter 96000, loss: 0.261136
 >> iter 97000, loss: 0.395281
 >> iter 98000, loss: 0.237802
 >> iter 99000, loss: 0.218371
 >> iter 100000, loss: 0.272847
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.184369
 >> iter 2000, loss: 13.288217
 >> iter 3000, loss: 10.063764
 >> iter 4000, loss: 8.446647
 >> iter 5000, loss: 7.828787
 >> iter 6000, loss: 7.273240
 >> iter 7000, loss: 5.486778
 >> iter 8000, loss: 2.841303
 >> iter 9000, loss: 1.533573
 >> iter 10000, loss: 1.012163
   Number of active neurons: 5
 >> iter 11000, loss: 0.517982
 >> iter 12000, loss: 0.492704
 >> iter 13000, loss: 0.416246
 >> iter 14000, loss: 0.418120
 >> iter 15000, loss: 0.343467
 >> iter 16000, loss: 0.448531
 >> iter 17000, loss: 0.408891
 >> iter 18000, loss: 0.361919
 >> iter 19000, loss: 0.436680
 >> iter 20000, loss: 0.295760
   Number of active neurons: 5
 >> iter 21000, loss: 0.288542
 >> iter 22000, loss: 0.426869
 >> iter 23000, loss: 0.391609
 >> iter 24000, loss: 0.318117
 >> iter 25000, loss: 0.405535
 >> iter 26000, loss: 0.288781
 >> iter 27000, loss: 0.365421
 >> iter 28000, loss: 0.412138
 >> iter 29000, loss: 0.417957
 >> iter 30000, loss: 0.539210
   Number of active neurons: 4
 >> iter 31000, loss: 0.622975
 >> iter 32000, loss: 0.573284
 >> iter 33000, loss: 0.415027
 >> iter 34000, loss: 0.307471
 >> iter 35000, loss: 0.429168
 >> iter 36000, loss: 0.427061
 >> iter 37000, loss: 0.333823
 >> iter 38000, loss: 0.384886
 >> iter 39000, loss: 0.344231
 >> iter 40000, loss: 0.343657
   Number of active neurons: 5
 >> iter 41000, loss: 0.349323
 >> iter 42000, loss: 0.414491
 >> iter 43000, loss: 0.306040
 >> iter 44000, loss: 0.229116
 >> iter 45000, loss: 0.346443
 >> iter 46000, loss: 0.436380
 >> iter 47000, loss: 0.323590
 >> iter 48000, loss: 0.287363
 >> iter 49000, loss: 0.274779
 >> iter 50000, loss: 0.260288
   Number of active neurons: 4
 >> iter 51000, loss: 0.425628
 >> iter 52000, loss: 0.376764
 >> iter 53000, loss: 0.408930
 >> iter 54000, loss: 0.284453
 >> iter 55000, loss: 0.301023
 >> iter 56000, loss: 0.245711
 >> iter 57000, loss: 0.397255
 >> iter 58000, loss: 0.416784
 >> iter 59000, loss: 0.347459
 >> iter 60000, loss: 0.310856
   Number of active neurons: 4
 >> iter 61000, loss: 0.374881
 >> iter 62000, loss: 0.480180
 >> iter 63000, loss: 0.590958
 >> iter 64000, loss: 0.513153
 >> iter 65000, loss: 0.343278
 >> iter 66000, loss: 0.322467
 >> iter 67000, loss: 0.356314
 >> iter 68000, loss: 0.293487
 >> iter 69000, loss: 0.295624
 >> iter 70000, loss: 0.510986
   Number of active neurons: 4
 >> iter 71000, loss: 0.621783
 >> iter 72000, loss: 0.343521
 >> iter 73000, loss: 0.325651
 >> iter 74000, loss: 0.293453
 >> iter 75000, loss: 0.516496
 >> iter 76000, loss: 0.309299
 >> iter 77000, loss: 0.305773
 >> iter 78000, loss: 0.474838
 >> iter 79000, loss: 0.579502
 >> iter 80000, loss: 0.368516
   Number of active neurons: 4
 >> iter 81000, loss: 0.325405
 >> iter 82000, loss: 0.251460
 >> iter 83000, loss: 0.383916
 >> iter 84000, loss: 0.238519
 >> iter 85000, loss: 0.344805
 >> iter 86000, loss: 0.505742
 >> iter 87000, loss: 0.447989
 >> iter 88000, loss: 0.343412
 >> iter 89000, loss: 0.453166
 >> iter 90000, loss: 0.362429
   Number of active neurons: 4
 >> iter 91000, loss: 0.452170
 >> iter 92000, loss: 0.319586
 >> iter 93000, loss: 0.433058
 >> iter 94000, loss: 0.378558
 >> iter 95000, loss: 0.335726
 >> iter 96000, loss: 0.283660
 >> iter 97000, loss: 0.440831
 >> iter 98000, loss: 0.327293
 >> iter 99000, loss: 0.445918
 >> iter 100000, loss: 0.301065
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0039999200016
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 13.0257982801

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

