 > Problema: tomita6nueva
 > Args:
   - Hidden size: 6
   - Noise level: 0.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.652249
 >> iter 2000, loss: 15.093957
 >> iter 3000, loss: 13.751042
 >> iter 4000, loss: 13.254616
 >> iter 5000, loss: 13.058295
 >> iter 6000, loss: 12.989537
 >> iter 7000, loss: 12.955250
 >> iter 8000, loss: 12.946814
 >> iter 9000, loss: 12.719982
 >> iter 10000, loss: 11.384335
   Number of active neurons: 6
 >> iter 11000, loss: 10.179415
 >> iter 12000, loss: 4.465235
 >> iter 13000, loss: 1.681388
 >> iter 14000, loss: 0.643077
 >> iter 15000, loss: 0.254655
 >> iter 16000, loss: 0.108046
 >> iter 17000, loss: 0.051568
 >> iter 18000, loss: 0.029054
 >> iter 19000, loss: 0.019422
 >> iter 20000, loss: 0.014899
   Number of active neurons: 6
 >> iter 21000, loss: 0.012400
 >> iter 22000, loss: 0.010856
 >> iter 23000, loss: 0.009717
 >> iter 24000, loss: 0.008865
 >> iter 25000, loss: 0.008133
 >> iter 26000, loss: 0.007547
 >> iter 27000, loss: 0.007013
 >> iter 28000, loss: 0.006575
 >> iter 29000, loss: 0.006162
 >> iter 30000, loss: 0.005820
   Number of active neurons: 6
 >> iter 31000, loss: 0.005490
 >> iter 32000, loss: 0.005217
 >> iter 33000, loss: 0.004947
 >> iter 34000, loss: 0.004722
 >> iter 35000, loss: 0.004498
 >> iter 36000, loss: 0.004311
 >> iter 37000, loss: 0.004121
 >> iter 38000, loss: 0.003963
 >> iter 39000, loss: 0.003800
 >> iter 40000, loss: 0.003666
   Number of active neurons: 6
 >> iter 41000, loss: 0.003524
 >> iter 42000, loss: 0.003407
 >> iter 43000, loss: 0.003283
 >> iter 44000, loss: 0.003182
 >> iter 45000, loss: 0.003072
 >> iter 46000, loss: 0.002983
 >> iter 47000, loss: 0.002886
 >> iter 48000, loss: 0.002807
 >> iter 49000, loss: 0.002720
 >> iter 50000, loss: 0.002649
   Number of active neurons: 6
 >> iter 51000, loss: 0.002571
 >> iter 52000, loss: 0.002508
 >> iter 53000, loss: 0.002436
 >> iter 54000, loss: 0.002380
 >> iter 55000, loss: 0.002314
 >> iter 56000, loss: 0.002264
 >> iter 57000, loss: 0.002203
 >> iter 58000, loss: 0.002158
 >> iter 59000, loss: 0.002103
 >> iter 60000, loss: 0.002061
   Number of active neurons: 6
 >> iter 61000, loss: 0.002010
 >> iter 62000, loss: 0.001972
 >> iter 63000, loss: 0.001925
 >> iter 64000, loss: 0.001890
 >> iter 65000, loss: 0.001846
 >> iter 66000, loss: 0.001814
 >> iter 67000, loss: 0.001773
 >> iter 68000, loss: 0.001743
 >> iter 69000, loss: 0.001706
 >> iter 70000, loss: 0.001678
   Number of active neurons: 6
 >> iter 71000, loss: 0.001643
 >> iter 72000, loss: 0.001616
 >> iter 73000, loss: 0.001584
 >> iter 74000, loss: 0.001560
 >> iter 75000, loss: 0.001529
 >> iter 76000, loss: 0.001506
 >> iter 77000, loss: 0.001477
 >> iter 78000, loss: 0.001456
 >> iter 79000, loss: 0.001429
 >> iter 80000, loss: 0.001409
   Number of active neurons: 6
 >> iter 81000, loss: 0.001383
 >> iter 82000, loss: 0.001364
 >> iter 83000, loss: 0.001340
 >> iter 84000, loss: 0.001322
 >> iter 85000, loss: 0.001299
 >> iter 86000, loss: 0.001282
 >> iter 87000, loss: 0.001261
 >> iter 88000, loss: 0.001245
 >> iter 89000, loss: 0.001224
 >> iter 90000, loss: 0.001209
   Number of active neurons: 6
 >> iter 91000, loss: 0.001190
 >> iter 92000, loss: 0.001175
 >> iter 93000, loss: 0.001157
 >> iter 94000, loss: 0.001143
 >> iter 95000, loss: 0.001125
 >> iter 96000, loss: 0.001112
 >> iter 97000, loss: 0.001095
 >> iter 98000, loss: 0.001083
 >> iter 99000, loss: 0.001067
 >> iter 100000, loss: 0.001055
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.628782
 >> iter 2000, loss: 15.077720
 >> iter 3000, loss: 13.732692
 >> iter 4000, loss: 13.236941
 >> iter 5000, loss: 13.037976
 >> iter 6000, loss: 12.969851
 >> iter 7000, loss: 12.933266
 >> iter 8000, loss: 12.928217
 >> iter 9000, loss: 12.915634
 >> iter 10000, loss: 12.920066
   Number of active neurons: 3
 >> iter 11000, loss: 12.848864
 >> iter 12000, loss: 12.101497
 >> iter 13000, loss: 10.634874
 >> iter 14000, loss: 4.892560
 >> iter 15000, loss: 1.834417
 >> iter 16000, loss: 0.839951
 >> iter 17000, loss: 0.325571
 >> iter 18000, loss: 0.130837
 >> iter 19000, loss: 0.056780
 >> iter 20000, loss: 0.027897
   Number of active neurons: 6
 >> iter 21000, loss: 0.016191
 >> iter 22000, loss: 0.011045
 >> iter 23000, loss: 0.008544
 >> iter 24000, loss: 0.007121
 >> iter 25000, loss: 0.006210
 >> iter 26000, loss: 0.005540
 >> iter 27000, loss: 0.005028
 >> iter 28000, loss: 0.004603
 >> iter 29000, loss: 0.004255
 >> iter 30000, loss: 0.003947
   Number of active neurons: 6
 >> iter 31000, loss: 0.003691
 >> iter 32000, loss: 0.003457
 >> iter 33000, loss: 0.003261
 >> iter 34000, loss: 0.003076
 >> iter 35000, loss: 0.002920
 >> iter 36000, loss: 0.002770
 >> iter 37000, loss: 0.002644
 >> iter 38000, loss: 0.002520
 >> iter 39000, loss: 0.002417
 >> iter 40000, loss: 0.002313
   Number of active neurons: 6
 >> iter 41000, loss: 0.002227
 >> iter 42000, loss: 0.002137
 >> iter 43000, loss: 0.002063
 >> iter 44000, loss: 0.001986
 >> iter 45000, loss: 0.001923
 >> iter 46000, loss: 0.001855
 >> iter 47000, loss: 0.001800
 >> iter 48000, loss: 0.001741
 >> iter 49000, loss: 0.001692
 >> iter 50000, loss: 0.001640
   Number of active neurons: 6
 >> iter 51000, loss: 0.001597
 >> iter 52000, loss: 0.001549
 >> iter 53000, loss: 0.001511
 >> iter 54000, loss: 0.001469
 >> iter 55000, loss: 0.001435
 >> iter 56000, loss: 0.001396
 >> iter 57000, loss: 0.001366
 >> iter 58000, loss: 0.001330
 >> iter 59000, loss: 0.001303
 >> iter 60000, loss: 0.001271
   Number of active neurons: 6
 >> iter 61000, loss: 0.001246
 >> iter 62000, loss: 0.001216
 >> iter 63000, loss: 0.001193
 >> iter 64000, loss: 0.001166
 >> iter 65000, loss: 0.001146
 >> iter 66000, loss: 0.001120
 >> iter 67000, loss: 0.001101
 >> iter 68000, loss: 0.001077
 >> iter 69000, loss: 0.001060
 >> iter 70000, loss: 0.001037
   Number of active neurons: 6
 >> iter 71000, loss: 0.001022
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.629533
 >> iter 2000, loss: 15.057943
 >> iter 3000, loss: 13.713231
 >> iter 4000, loss: 13.222519
 >> iter 5000, loss: 13.028006
 >> iter 6000, loss: 12.963137
 >> iter 7000, loss: 12.928504
 >> iter 8000, loss: 12.925284
 >> iter 9000, loss: 12.913355
 >> iter 10000, loss: 12.920598
   Number of active neurons: 3
 >> iter 11000, loss: 12.909551
 >> iter 12000, loss: 12.803337
 >> iter 13000, loss: 9.546312
 >> iter 14000, loss: 3.644978
 >> iter 15000, loss: 1.397118
 >> iter 16000, loss: 0.549219
 >> iter 17000, loss: 0.228024
 >> iter 18000, loss: 0.104547
 >> iter 19000, loss: 0.055461
 >> iter 20000, loss: 0.035018
   Number of active neurons: 6
 >> iter 21000, loss: 0.025503
 >> iter 22000, loss: 0.020677
 >> iter 23000, loss: 0.017636
 >> iter 24000, loss: 0.015686
 >> iter 25000, loss: 0.014087
 >> iter 26000, loss: 0.012930
 >> iter 27000, loss: 0.011858
 >> iter 28000, loss: 0.011056
 >> iter 29000, loss: 0.010263
 >> iter 30000, loss: 0.009664
   Number of active neurons: 6
 >> iter 31000, loss: 0.009048
 >> iter 32000, loss: 0.008583
 >> iter 33000, loss: 0.008091
 >> iter 34000, loss: 0.007719
 >> iter 35000, loss: 0.007315
 >> iter 36000, loss: 0.007014
 >> iter 37000, loss: 0.006675
 >> iter 38000, loss: 0.006426
 >> iter 39000, loss: 0.006139
 >> iter 40000, loss: 0.005930
   Number of active neurons: 6
 >> iter 41000, loss: 0.005682
 >> iter 42000, loss: 0.005503
 >> iter 43000, loss: 0.005287
 >> iter 44000, loss: 0.005133
 >> iter 45000, loss: 0.004944
 >> iter 46000, loss: 0.004811
 >> iter 47000, loss: 0.004643
 >> iter 48000, loss: 0.004526
 >> iter 49000, loss: 0.004376
 >> iter 50000, loss: 0.004274
   Number of active neurons: 6
 >> iter 51000, loss: 0.004137
 >> iter 52000, loss: 0.004047
 >> iter 53000, loss: 0.003922
 >> iter 54000, loss: 0.003843
 >> iter 55000, loss: 0.003728
 >> iter 56000, loss: 0.003659
 >> iter 57000, loss: 0.003553
 >> iter 58000, loss: 0.003491
 >> iter 59000, loss: 0.003394
 >> iter 60000, loss: 0.003337
   Number of active neurons: 6
 >> iter 61000, loss: 0.003248
 >> iter 62000, loss: 0.003197
 >> iter 63000, loss: 0.003114
 >> iter 64000, loss: 0.003068
 >> iter 65000, loss: 0.002991
 >> iter 66000, loss: 0.002948
 >> iter 67000, loss: 0.002877
 >> iter 68000, loss: 0.002838
 >> iter 69000, loss: 0.002772
 >> iter 70000, loss: 0.002735
   Number of active neurons: 6
 >> iter 71000, loss: 0.002673
 >> iter 72000, loss: 0.002640
 >> iter 73000, loss: 0.002581
 >> iter 74000, loss: 0.002551
 >> iter 75000, loss: 0.002496
 >> iter 76000, loss: 0.002468
 >> iter 77000, loss: 0.002417
 >> iter 78000, loss: 0.002391
 >> iter 79000, loss: 0.002341
 >> iter 80000, loss: 0.002317
   Number of active neurons: 6
 >> iter 81000, loss: 0.002271
 >> iter 82000, loss: 0.002249
 >> iter 83000, loss: 0.002204
 >> iter 84000, loss: 0.002184
 >> iter 85000, loss: 0.002141
 >> iter 86000, loss: 0.002122
 >> iter 87000, loss: 0.002082
 >> iter 88000, loss: 0.002064
 >> iter 89000, loss: 0.002025
 >> iter 90000, loss: 0.002009
   Number of active neurons: 6
 >> iter 91000, loss: 0.001972
 >> iter 92000, loss: 0.001957
 >> iter 93000, loss: 0.001922
 >> iter 94000, loss: 0.001908
 >> iter 95000, loss: 0.001874
 >> iter 96000, loss: 0.001861
 >> iter 97000, loss: 0.001829
 >> iter 98000, loss: 0.001816
 >> iter 99000, loss: 0.001786
 >> iter 100000, loss: 0.001774
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.611665
 >> iter 2000, loss: 15.073612
 >> iter 3000, loss: 13.736299
 >> iter 4000, loss: 13.243542
 >> iter 5000, loss: 13.046208
 >> iter 6000, loss: 12.979073
 >> iter 7000, loss: 12.943121
 >> iter 8000, loss: 12.939014
 >> iter 9000, loss: 12.926367
 >> iter 10000, loss: 12.931905
   Number of active neurons: 4
 >> iter 11000, loss: 12.799166
 >> iter 12000, loss: 8.146654
 >> iter 13000, loss: 3.126332
 >> iter 14000, loss: 1.193492
 >> iter 15000, loss: 0.465859
 >> iter 16000, loss: 0.190899
 >> iter 17000, loss: 0.085557
 >> iter 18000, loss: 0.043973
 >> iter 19000, loss: 0.026839
 >> iter 20000, loss: 0.019092
   Number of active neurons: 6
 >> iter 21000, loss: 0.015179
 >> iter 22000, loss: 0.012855
 >> iter 23000, loss: 0.011311
 >> iter 24000, loss: 0.010169
 >> iter 25000, loss: 0.009258
 >> iter 26000, loss: 0.008517
 >> iter 27000, loss: 0.007876
 >> iter 28000, loss: 0.007347
 >> iter 29000, loss: 0.006864
 >> iter 30000, loss: 0.006462
   Number of active neurons: 6
 >> iter 31000, loss: 0.006080
 >> iter 32000, loss: 0.005765
 >> iter 33000, loss: 0.005458
 >> iter 34000, loss: 0.005205
 >> iter 35000, loss: 0.004950
 >> iter 36000, loss: 0.004743
 >> iter 37000, loss: 0.004528
 >> iter 38000, loss: 0.004357
 >> iter 39000, loss: 0.004172
 >> iter 40000, loss: 0.004030
   Number of active neurons: 6
 >> iter 41000, loss: 0.003869
 >> iter 42000, loss: 0.003746
 >> iter 43000, loss: 0.003606
 >> iter 44000, loss: 0.003500
 >> iter 45000, loss: 0.003377
 >> iter 46000, loss: 0.003286
 >> iter 47000, loss: 0.003174
 >> iter 48000, loss: 0.003094
 >> iter 49000, loss: 0.002994
 >> iter 50000, loss: 0.002925
   Number of active neurons: 6
 >> iter 51000, loss: 0.002834
 >> iter 52000, loss: 0.002772
 >> iter 53000, loss: 0.002689
 >> iter 54000, loss: 0.002635
 >> iter 55000, loss: 0.002558
 >> iter 56000, loss: 0.002510
 >> iter 57000, loss: 0.002440
 >> iter 58000, loss: 0.002396
 >> iter 59000, loss: 0.002332
 >> iter 60000, loss: 0.002293
   Number of active neurons: 6
 >> iter 61000, loss: 0.002233
 >> iter 62000, loss: 0.002198
 >> iter 63000, loss: 0.002142
 >> iter 64000, loss: 0.002110
 >> iter 65000, loss: 0.002058
 >> iter 66000, loss: 0.002028
 >> iter 67000, loss: 0.001981
 >> iter 68000, loss: 0.001953
 >> iter 69000, loss: 0.001909
 >> iter 70000, loss: 0.001883
   Number of active neurons: 6
 >> iter 71000, loss: 0.001842
 >> iter 72000, loss: 0.001818
 >> iter 73000, loss: 0.001779
 >> iter 74000, loss: 0.001758
 >> iter 75000, loss: 0.001720
 >> iter 76000, loss: 0.001701
 >> iter 77000, loss: 0.001666
 >> iter 78000, loss: 0.001648
 >> iter 79000, loss: 0.001614
 >> iter 80000, loss: 0.001598
   Number of active neurons: 6
 >> iter 81000, loss: 0.001566
 >> iter 82000, loss: 0.001551
 >> iter 83000, loss: 0.001520
 >> iter 84000, loss: 0.001506
 >> iter 85000, loss: 0.001477
 >> iter 86000, loss: 0.001465
 >> iter 87000, loss: 0.001436
 >> iter 88000, loss: 0.001425
 >> iter 89000, loss: 0.001397
 >> iter 90000, loss: 0.001387
   Number of active neurons: 6
 >> iter 91000, loss: 0.001361
 >> iter 92000, loss: 0.001351
 >> iter 93000, loss: 0.001326
 >> iter 94000, loss: 0.001317
 >> iter 95000, loss: 0.001293
 >> iter 96000, loss: 0.001285
 >> iter 97000, loss: 0.001262
 >> iter 98000, loss: 0.001254
 >> iter 99000, loss: 0.001232
 >> iter 100000, loss: 0.001224
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0049999500005
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.606478
 >> iter 2000, loss: 15.057977
 >> iter 3000, loss: 13.721601
 >> iter 4000, loss: 13.233741
 >> iter 5000, loss: 13.039565
 >> iter 6000, loss: 12.975037
 >> iter 7000, loss: 12.940277
 >> iter 8000, loss: 12.937255
 >> iter 9000, loss: 12.925125
 >> iter 10000, loss: 12.932388
   Number of active neurons: 4
 >> iter 11000, loss: 12.920788
 >> iter 12000, loss: 12.723401
 >> iter 13000, loss: 7.490538
 >> iter 14000, loss: 2.842781
 >> iter 15000, loss: 1.139382
 >> iter 16000, loss: 0.448112
 >> iter 17000, loss: 0.240714
 >> iter 18000, loss: 0.105829
 >> iter 19000, loss: 0.054598
 >> iter 20000, loss: 0.032004
   Number of active neurons: 6
 >> iter 21000, loss: 0.022272
 >> iter 22000, loss: 0.017276
 >> iter 23000, loss: 0.014343
 >> iter 24000, loss: 0.012377
 >> iter 25000, loss: 0.011472
 >> iter 26000, loss: 0.010325
 >> iter 27000, loss: 0.009322
 >> iter 28000, loss: 0.008499
 >> iter 29000, loss: 0.007938
 >> iter 30000, loss: 0.007346
   Number of active neurons: 6
 >> iter 31000, loss: 0.007588
 >> iter 32000, loss: 0.006915
 >> iter 33000, loss: 0.006404
 >> iter 34000, loss: 0.005951
 >> iter 35000, loss: 0.005635
 >> iter 36000, loss: 0.005320
 >> iter 37000, loss: 0.005090
 >> iter 38000, loss: 0.004843
 >> iter 39000, loss: 0.004672
 >> iter 40000, loss: 0.004459
   Number of active neurons: 6
 >> iter 41000, loss: 0.004606
 >> iter 42000, loss: 0.004326
 >> iter 43000, loss: 0.004122
 >> iter 44000, loss: 0.003912
 >> iter 45000, loss: 0.003792
 >> iter 46000, loss: 0.003631
 >> iter 47000, loss: 0.003559
 >> iter 48000, loss: 0.003414
 >> iter 49000, loss: 0.003410
 >> iter 50000, loss: 0.003265
   Number of active neurons: 6
 >> iter 51000, loss: 0.003196
 >> iter 52000, loss: 0.003065
 >> iter 53000, loss: 0.003026
 >> iter 54000, loss: 0.002910
 >> iter 55000, loss: 0.002858
 >> iter 56000, loss: 0.002755
 >> iter 57000, loss: 0.002724
 >> iter 58000, loss: 0.002627
 >> iter 59000, loss: 0.002593
 >> iter 60000, loss: 0.002505
   Number of active neurons: 6
 >> iter 61000, loss: 0.002481
 >> iter 62000, loss: 0.002399
 >> iter 63000, loss: 0.002371
 >> iter 64000, loss: 0.002296
 >> iter 65000, loss: 0.002277
 >> iter 66000, loss: 0.002205
 >> iter 67000, loss: 0.002186
 >> iter 68000, loss: 0.002119
 >> iter 69000, loss: 0.002104
 >> iter 70000, loss: 0.002040
   Number of active neurons: 6
 >> iter 71000, loss: 0.002026
 >> iter 72000, loss: 0.001966
 >> iter 73000, loss: 0.001954
 >> iter 74000, loss: 0.001899
 >> iter 75000, loss: 0.001886
 >> iter 76000, loss: 0.001834
 >> iter 77000, loss: 0.001825
 >> iter 78000, loss: 0.001775
 >> iter 79000, loss: 0.001765
 >> iter 80000, loss: 0.001719
   Number of active neurons: 6
 >> iter 81000, loss: 0.001711
 >> iter 82000, loss: 0.001666
 >> iter 83000, loss: 0.001658
 >> iter 84000, loss: 0.001616
 >> iter 85000, loss: 0.001609
 >> iter 86000, loss: 0.001570
 >> iter 87000, loss: 0.001563
 >> iter 88000, loss: 0.001526
 >> iter 89000, loss: 0.001519
 >> iter 90000, loss: 0.001484
   Number of active neurons: 6
 >> iter 91000, loss: 0.001478
 >> iter 92000, loss: 0.001444
 >> iter 93000, loss: 0.001439
 >> iter 94000, loss: 0.001406
 >> iter 95000, loss: 0.001402
 >> iter 96000, loss: 0.001371
 >> iter 97000, loss: 0.001367
 >> iter 98000, loss: 0.001337
 >> iter 99000, loss: 0.001333
 >> iter 100000, loss: 0.001304
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0069999300007
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.642379
 >> iter 2000, loss: 15.096105
 >> iter 3000, loss: 13.758508
 >> iter 4000, loss: 13.264318
 >> iter 5000, loss: 13.065733
 >> iter 6000, loss: 12.995706
 >> iter 7000, loss: 12.958199
 >> iter 8000, loss: 12.952981
 >> iter 9000, loss: 12.939703
 >> iter 10000, loss: 12.945719
   Number of active neurons: 5
 >> iter 11000, loss: 12.923253
 >> iter 12000, loss: 11.683505
 >> iter 13000, loss: 4.916691
 >> iter 14000, loss: 1.871340
 >> iter 15000, loss: 0.723560
 >> iter 16000, loss: 0.290690
 >> iter 17000, loss: 0.126776
 >> iter 18000, loss: 0.062182
 >> iter 19000, loss: 0.035579
 >> iter 20000, loss: 0.024119
   Number of active neurons: 6
 >> iter 21000, loss: 0.018409
 >> iter 22000, loss: 0.015335
 >> iter 23000, loss: 0.013271
 >> iter 24000, loss: 0.011884
 >> iter 25000, loss: 0.010719
 >> iter 26000, loss: 0.009857
 >> iter 27000, loss: 0.009053
 >> iter 28000, loss: 0.008448
 >> iter 29000, loss: 0.007848
 >> iter 30000, loss: 0.007393
   Number of active neurons: 6
 >> iter 31000, loss: 0.006924
 >> iter 32000, loss: 0.006570
 >> iter 33000, loss: 0.006195
 >> iter 34000, loss: 0.005912
 >> iter 35000, loss: 0.005602
 >> iter 36000, loss: 0.005372
 >> iter 37000, loss: 0.005111
 >> iter 38000, loss: 0.004922
 >> iter 39000, loss: 0.004700
 >> iter 40000, loss: 0.004542
   Number of active neurons: 6
 >> iter 41000, loss: 0.004349
 >> iter 42000, loss: 0.004213
 >> iter 43000, loss: 0.004047
 >> iter 44000, loss: 0.003929
 >> iter 45000, loss: 0.003784
 >> iter 46000, loss: 0.003682
 >> iter 47000, loss: 0.003552
 >> iter 48000, loss: 0.003462
 >> iter 49000, loss: 0.003347
 >> iter 50000, loss: 0.003269
   Number of active neurons: 6
 >> iter 51000, loss: 0.003163
 >> iter 52000, loss: 0.003094
 >> iter 53000, loss: 0.002998
 >> iter 54000, loss: 0.002938
 >> iter 55000, loss: 0.002850
 >> iter 56000, loss: 0.002796
 >> iter 57000, loss: 0.002716
 >> iter 58000, loss: 0.002667
 >> iter 59000, loss: 0.002593
 >> iter 60000, loss: 0.002549
   Number of active neurons: 6
 >> iter 61000, loss: 0.002481
 >> iter 62000, loss: 0.002441
 >> iter 63000, loss: 0.002378
 >> iter 64000, loss: 0.002344
 >> iter 65000, loss: 0.002284
 >> iter 66000, loss: 0.002252
 >> iter 67000, loss: 0.002197
 >> iter 68000, loss: 0.002167
 >> iter 69000, loss: 0.002116
 >> iter 70000, loss: 0.002088
   Number of active neurons: 6
 >> iter 71000, loss: 0.002041
 >> iter 72000, loss: 0.002014
 >> iter 73000, loss: 0.001970
 >> iter 74000, loss: 0.001947
 >> iter 75000, loss: 0.001904
 >> iter 76000, loss: 0.001883
 >> iter 77000, loss: 0.001844
 >> iter 78000, loss: 0.001824
 >> iter 79000, loss: 0.001786
 >> iter 80000, loss: 0.001767
   Number of active neurons: 6
 >> iter 81000, loss: 0.001732
 >> iter 82000, loss: 0.001714
 >> iter 83000, loss: 0.001681
 >> iter 84000, loss: 0.001665
 >> iter 85000, loss: 0.001633
 >> iter 86000, loss: 0.001618
 >> iter 87000, loss: 0.001587
 >> iter 88000, loss: 0.001573
 >> iter 89000, loss: 0.001544
 >> iter 90000, loss: 0.001531
   Number of active neurons: 6
 >> iter 91000, loss: 0.001504
 >> iter 92000, loss: 0.001491
 >> iter 93000, loss: 0.001466
 >> iter 94000, loss: 0.001453
 >> iter 95000, loss: 0.001429
 >> iter 96000, loss: 0.001417
 >> iter 97000, loss: 0.001395
 >> iter 98000, loss: 0.001383
 >> iter 99000, loss: 0.001361
 >> iter 100000, loss: 0.001350
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.633286
 >> iter 2000, loss: 15.093906
 >> iter 3000, loss: 13.759762
 >> iter 4000, loss: 13.267560
 >> iter 5000, loss: 13.073382
 >> iter 6000, loss: 13.005121
 >> iter 7000, loss: 12.971277
 >> iter 8000, loss: 12.966402
 >> iter 9000, loss: 12.955649
 >> iter 10000, loss: 12.962402
   Number of active neurons: 6
 >> iter 11000, loss: 12.952832
 >> iter 12000, loss: 12.959288
 >> iter 13000, loss: 12.950164
 >> iter 14000, loss: 12.958445
 >> iter 15000, loss: 12.951595
 >> iter 16000, loss: 12.958222
 >> iter 17000, loss: 12.952720
 >> iter 18000, loss: 12.956398
 >> iter 19000, loss: 12.949472
 >> iter 20000, loss: 12.956891
   Number of active neurons: 6
 >> iter 21000, loss: 12.938563
 >> iter 22000, loss: 12.634885
 >> iter 23000, loss: 9.556210
 >> iter 24000, loss: 3.603291
 >> iter 25000, loss: 1.357319
 >> iter 26000, loss: 0.519816
 >> iter 27000, loss: 0.206955
 >> iter 28000, loss: 0.088558
 >> iter 29000, loss: 0.043361
 >> iter 30000, loss: 0.024975
   Number of active neurons: 6
 >> iter 31000, loss: 0.017425
 >> iter 32000, loss: 0.013528
 >> iter 33000, loss: 0.011626
 >> iter 34000, loss: 0.010157
 >> iter 35000, loss: 0.009307
 >> iter 36000, loss: 0.008432
 >> iter 37000, loss: 0.007889
 >> iter 38000, loss: 0.007263
 >> iter 39000, loss: 0.006865
 >> iter 40000, loss: 0.006386
   Number of active neurons: 6
 >> iter 41000, loss: 0.006081
 >> iter 42000, loss: 0.005696
 >> iter 43000, loss: 0.005454
 >> iter 44000, loss: 0.005140
 >> iter 45000, loss: 0.004941
 >> iter 46000, loss: 0.004682
 >> iter 47000, loss: 0.004518
 >> iter 48000, loss: 0.004296
 >> iter 49000, loss: 0.004158
 >> iter 50000, loss: 0.003969
   Number of active neurons: 6
 >> iter 51000, loss: 0.003849
 >> iter 52000, loss: 0.003687
 >> iter 53000, loss: 0.003581
 >> iter 54000, loss: 0.003441
 >> iter 55000, loss: 0.003350
 >> iter 56000, loss: 0.003225
 >> iter 57000, loss: 0.003144
 >> iter 58000, loss: 0.003034
 >> iter 59000, loss: 0.002962
 >> iter 60000, loss: 0.002863
   Number of active neurons: 6
 >> iter 61000, loss: 0.002799
 >> iter 62000, loss: 0.002709
 >> iter 63000, loss: 0.002652
 >> iter 64000, loss: 0.002570
 >> iter 65000, loss: 0.002519
 >> iter 66000, loss: 0.002445
 >> iter 67000, loss: 0.002399
 >> iter 68000, loss: 0.002330
 >> iter 69000, loss: 0.002288
 >> iter 70000, loss: 0.002225
   Number of active neurons: 6
 >> iter 71000, loss: 0.002187
 >> iter 72000, loss: 0.002129
 >> iter 73000, loss: 0.002093
 >> iter 74000, loss: 0.002041
 >> iter 75000, loss: 0.002008
 >> iter 76000, loss: 0.001959
 >> iter 77000, loss: 0.001929
 >> iter 78000, loss: 0.001883
 >> iter 79000, loss: 0.001855
 >> iter 80000, loss: 0.001813
   Number of active neurons: 6
 >> iter 81000, loss: 0.001787
 >> iter 82000, loss: 0.001747
 >> iter 83000, loss: 0.001723
 >> iter 84000, loss: 0.001685
 >> iter 85000, loss: 0.001663
 >> iter 86000, loss: 0.001628
 >> iter 87000, loss: 0.001607
 >> iter 88000, loss: 0.001575
 >> iter 89000, loss: 0.001555
 >> iter 90000, loss: 0.001524
   Number of active neurons: 6
 >> iter 91000, loss: 0.001506
 >> iter 92000, loss: 0.001477
 >> iter 93000, loss: 0.001459
 >> iter 94000, loss: 0.001432
 >> iter 95000, loss: 0.001416
 >> iter 96000, loss: 0.001390
 >> iter 97000, loss: 0.001375
 >> iter 98000, loss: 0.001350
 >> iter 99000, loss: 0.001336
 >> iter 100000, loss: 0.001312
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.624420
 >> iter 2000, loss: 15.088651
 >> iter 3000, loss: 13.753745
 >> iter 4000, loss: 13.261727
 >> iter 5000, loss: 13.066473
 >> iter 6000, loss: 12.997452
 >> iter 7000, loss: 12.961670
 >> iter 8000, loss: 12.954361
 >> iter 9000, loss: 12.941811
 >> iter 10000, loss: 12.945603
   Number of active neurons: 5
 >> iter 11000, loss: 12.933604
 >> iter 12000, loss: 12.905348
 >> iter 13000, loss: 12.468452
 >> iter 14000, loss: 10.771305
 >> iter 15000, loss: 9.440645
 >> iter 16000, loss: 8.196271
 >> iter 17000, loss: 7.653834
 >> iter 18000, loss: 7.271755
 >> iter 19000, loss: 7.182920
 >> iter 20000, loss: 6.690829
   Number of active neurons: 6
 >> iter 21000, loss: 6.589776
 >> iter 22000, loss: 6.023097
 >> iter 23000, loss: 5.729516
 >> iter 24000, loss: 5.530511
 >> iter 25000, loss: 5.200606
 >> iter 26000, loss: 4.979765
 >> iter 27000, loss: 4.855780
 >> iter 28000, loss: 4.579501
 >> iter 29000, loss: 4.438468
 >> iter 30000, loss: 4.507910
   Number of active neurons: 6
 >> iter 31000, loss: 4.629352
 >> iter 32000, loss: 4.265717
 >> iter 33000, loss: 4.133064
 >> iter 34000, loss: 4.345945
 >> iter 35000, loss: 4.586091
 >> iter 36000, loss: 4.184243
 >> iter 37000, loss: 4.182013
 >> iter 38000, loss: 3.999317
 >> iter 39000, loss: 4.177013
 >> iter 40000, loss: 4.015694
   Number of active neurons: 6
 >> iter 41000, loss: 4.206515
 >> iter 42000, loss: 3.998328
 >> iter 43000, loss: 4.006058
 >> iter 44000, loss: 3.969100
 >> iter 45000, loss: 3.977007
 >> iter 46000, loss: 3.921761
 >> iter 47000, loss: 3.925722
 >> iter 48000, loss: 3.930650
 >> iter 49000, loss: 3.927407
 >> iter 50000, loss: 3.922793
   Number of active neurons: 6
 >> iter 51000, loss: 3.934783
 >> iter 52000, loss: 3.867582
 >> iter 53000, loss: 3.959140
 >> iter 54000, loss: 3.872225
 >> iter 55000, loss: 3.916135
 >> iter 56000, loss: 3.870145
 >> iter 57000, loss: 3.913755
 >> iter 58000, loss: 3.860903
 >> iter 59000, loss: 3.903498
 >> iter 60000, loss: 3.855862
   Number of active neurons: 6
 >> iter 61000, loss: 3.888252
 >> iter 62000, loss: 3.850533
 >> iter 63000, loss: 3.884331
 >> iter 64000, loss: 3.852216
 >> iter 65000, loss: 3.888018
 >> iter 66000, loss: 3.912141
 >> iter 67000, loss: 3.979273
 >> iter 68000, loss: 3.903484
 >> iter 69000, loss: 4.301729
 >> iter 70000, loss: 4.701057
   Number of active neurons: 6
 >> iter 71000, loss: 4.222604
 >> iter 72000, loss: 3.990458
 >> iter 73000, loss: 4.028881
 >> iter 74000, loss: 3.931704
 >> iter 75000, loss: 4.070501
 >> iter 76000, loss: 3.936065
 >> iter 77000, loss: 3.917841
 >> iter 78000, loss: 3.882309
 >> iter 79000, loss: 3.919613
 >> iter 80000, loss: 3.871210
   Number of active neurons: 6
 >> iter 81000, loss: 3.926738
 >> iter 82000, loss: 3.890099
 >> iter 83000, loss: 3.895144
 >> iter 84000, loss: 3.874735
 >> iter 85000, loss: 3.889548
 >> iter 86000, loss: 3.865840
 >> iter 87000, loss: 3.893919
 >> iter 88000, loss: 3.873128
 >> iter 89000, loss: 3.895657
 >> iter 90000, loss: 3.879398
   Number of active neurons: 6
 >> iter 91000, loss: 3.892855
 >> iter 92000, loss: 3.884953
 >> iter 93000, loss: 3.892173
 >> iter 94000, loss: 3.874235
 >> iter 95000, loss: 3.902149
 >> iter 96000, loss: 3.945751
 >> iter 97000, loss: 3.928008
 >> iter 98000, loss: 4.037217
 >> iter 99000, loss: 3.968232
 >> iter 100000, loss: 3.889004
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 7.65584688306
   - Test - Long: 27.2936353182
   - Test - Big: 7.69192308077
   - Test - A: 0.0
   - Test - B: 31.5978934738
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.623900
 >> iter 2000, loss: 15.078409
 >> iter 3000, loss: 13.742075
 >> iter 4000, loss: 13.249245
 >> iter 5000, loss: 13.055536
 >> iter 6000, loss: 12.988845
 >> iter 7000, loss: 12.955376
 >> iter 8000, loss: 12.950985
 >> iter 9000, loss: 12.940034
 >> iter 10000, loss: 12.945387
   Number of active neurons: 5
 >> iter 11000, loss: 12.913863
 >> iter 12000, loss: 12.318580
 >> iter 13000, loss: 5.798353
 >> iter 14000, loss: 2.216585
 >> iter 15000, loss: 0.857652
 >> iter 16000, loss: 0.347792
 >> iter 17000, loss: 0.149909
 >> iter 18000, loss: 0.074722
 >> iter 19000, loss: 0.042298
 >> iter 20000, loss: 0.028480
   Number of active neurons: 6
 >> iter 21000, loss: 0.021497
 >> iter 22000, loss: 0.017951
 >> iter 23000, loss: 0.015397
 >> iter 24000, loss: 0.013854
 >> iter 25000, loss: 0.012409
 >> iter 26000, loss: 0.011474
 >> iter 27000, loss: 0.010476
 >> iter 28000, loss: 0.009830
 >> iter 29000, loss: 0.009078
 >> iter 30000, loss: 0.008604
   Number of active neurons: 6
 >> iter 31000, loss: 0.008010
 >> iter 32000, loss: 0.007647
 >> iter 33000, loss: 0.007167
 >> iter 34000, loss: 0.006880
 >> iter 35000, loss: 0.006484
 >> iter 36000, loss: 0.006253
 >> iter 37000, loss: 0.005917
 >> iter 38000, loss: 0.005731
 >> iter 39000, loss: 0.005442
 >> iter 40000, loss: 0.005290
   Number of active neurons: 6
 >> iter 41000, loss: 0.005039
 >> iter 42000, loss: 0.004909
 >> iter 43000, loss: 0.004690
 >> iter 44000, loss: 0.004580
 >> iter 45000, loss: 0.004387
 >> iter 46000, loss: 0.004294
 >> iter 47000, loss: 0.004119
 >> iter 48000, loss: 0.004039
 >> iter 49000, loss: 0.003883
 >> iter 50000, loss: 0.003814
   Number of active neurons: 6
 >> iter 51000, loss: 0.003671
 >> iter 52000, loss: 0.003611
 >> iter 53000, loss: 0.003479
 >> iter 54000, loss: 0.003430
 >> iter 55000, loss: 0.003308
 >> iter 56000, loss: 0.003265
 >> iter 57000, loss: 0.003154
 >> iter 58000, loss: 0.003116
 >> iter 59000, loss: 0.003014
 >> iter 60000, loss: 0.002979
   Number of active neurons: 6
 >> iter 61000, loss: 0.002884
 >> iter 62000, loss: 0.002854
 >> iter 63000, loss: 0.002765
 >> iter 64000, loss: 0.002739
 >> iter 65000, loss: 0.002656
 >> iter 66000, loss: 0.002632
 >> iter 67000, loss: 0.002556
 >> iter 68000, loss: 0.002534
 >> iter 69000, loss: 0.002463
 >> iter 70000, loss: 0.002442
   Number of active neurons: 6
 >> iter 71000, loss: 0.002376
 >> iter 72000, loss: 0.002357
 >> iter 73000, loss: 0.002294
 >> iter 74000, loss: 0.002278
 >> iter 75000, loss: 0.002218
 >> iter 76000, loss: 0.002205
 >> iter 77000, loss: 0.002148
 >> iter 78000, loss: 0.002136
 >> iter 79000, loss: 0.002081
 >> iter 80000, loss: 0.002070
   Number of active neurons: 6
 >> iter 81000, loss: 0.002019
 >> iter 82000, loss: 0.002009
 >> iter 83000, loss: 0.001960
 >> iter 84000, loss: 0.001951
 >> iter 85000, loss: 0.001904
 >> iter 86000, loss: 0.001896
 >> iter 87000, loss: 0.001852
 >> iter 88000, loss: 0.001845
 >> iter 89000, loss: 0.001802
 >> iter 90000, loss: 0.001796
   Number of active neurons: 6
 >> iter 91000, loss: 0.001755
 >> iter 92000, loss: 0.001749
 >> iter 93000, loss: 0.001710
 >> iter 94000, loss: 0.001705
 >> iter 95000, loss: 0.001668
 >> iter 96000, loss: 0.001663
 >> iter 97000, loss: 0.001628
 >> iter 98000, loss: 0.001623
 >> iter 99000, loss: 0.001589
 >> iter 100000, loss: 0.001585
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.634229
 >> iter 2000, loss: 15.060516
 >> iter 3000, loss: 13.717369
 >> iter 4000, loss: 13.226608
 >> iter 5000, loss: 13.031469
 >> iter 6000, loss: 12.965808
 >> iter 7000, loss: 12.930734
 >> iter 8000, loss: 12.926559
 >> iter 9000, loss: 12.914071
 >> iter 10000, loss: 12.843667
   Number of active neurons: 5
 >> iter 11000, loss: 9.575654
 >> iter 12000, loss: 3.955652
 >> iter 13000, loss: 1.526660
 >> iter 14000, loss: 0.598992
 >> iter 15000, loss: 0.246063
 >> iter 16000, loss: 0.152135
 >> iter 17000, loss: 0.069992
 >> iter 18000, loss: 0.037601
 >> iter 19000, loss: 0.025629
 >> iter 20000, loss: 0.019173
   Number of active neurons: 6
 >> iter 21000, loss: 0.014781
 >> iter 22000, loss: 0.012228
 >> iter 23000, loss: 0.012172
 >> iter 24000, loss: 0.010359
 >> iter 25000, loss: 0.009008
 >> iter 26000, loss: 0.008135
 >> iter 27000, loss: 0.007411
 >> iter 28000, loss: 0.006913
 >> iter 29000, loss: 0.006426
 >> iter 30000, loss: 0.006090
   Number of active neurons: 6
 >> iter 31000, loss: 0.005706
 >> iter 32000, loss: 0.005473
 >> iter 33000, loss: 0.005154
 >> iter 34000, loss: 0.004979
 >> iter 35000, loss: 0.004701
 >> iter 36000, loss: 0.004587
 >> iter 37000, loss: 0.004332
 >> iter 38000, loss: 0.004257
 >> iter 39000, loss: 0.004018
 >> iter 40000, loss: 0.003975
   Number of active neurons: 6
 >> iter 41000, loss: 0.003751
 >> iter 42000, loss: 0.003725
 >> iter 43000, loss: 0.003524
 >> iter 44000, loss: 0.003538
 >> iter 45000, loss: 0.003324
 >> iter 46000, loss: 0.003319
 >> iter 47000, loss: 0.056125
 >> iter 48000, loss: 0.025537
 >> iter 49000, loss: 0.011466
 >> iter 50000, loss: 0.006225
   Number of active neurons: 6
 >> iter 51000, loss: 0.004199
 >> iter 52000, loss: 0.003417
 >> iter 53000, loss: 0.003049
 >> iter 54000, loss: 0.002888
 >> iter 55000, loss: 0.002759
 >> iter 56000, loss: 0.002690
 >> iter 57000, loss: 0.002608
 >> iter 58000, loss: 0.002555
 >> iter 59000, loss: 0.003707
 >> iter 60000, loss: 0.003163
   Number of active neurons: 6
 >> iter 61000, loss: 0.002736
 >> iter 62000, loss: 0.002530
 >> iter 63000, loss: 0.002380
 >> iter 64000, loss: 0.002308
 >> iter 65000, loss: 0.002225
 >> iter 66000, loss: 0.002183
 >> iter 67000, loss: 0.002119
 >> iter 68000, loss: 0.002085
 >> iter 69000, loss: 0.002029
 >> iter 70000, loss: 0.001998
   Number of active neurons: 6
 >> iter 71000, loss: 0.001948
 >> iter 72000, loss: 0.001920
 >> iter 73000, loss: 0.001873
 >> iter 74000, loss: 0.001851
 >> iter 75000, loss: 0.001805
 >> iter 76000, loss: 0.001785
 >> iter 77000, loss: 0.001743
 >> iter 78000, loss: 0.001725
 >> iter 79000, loss: 0.001685
 >> iter 80000, loss: 0.001670
   Number of active neurons: 6
 >> iter 81000, loss: 0.001631
 >> iter 82000, loss: 0.001617
 >> iter 83000, loss: 0.001581
 >> iter 84000, loss: 0.001568
 >> iter 85000, loss: 0.001534
 >> iter 86000, loss: 0.001524
 >> iter 87000, loss: 0.001489
 >> iter 88000, loss: 0.001481
 >> iter 89000, loss: 0.001448
 >> iter 90000, loss: 0.001441
   Number of active neurons: 6
 >> iter 91000, loss: 0.001410
 >> iter 92000, loss: 0.001403
 >> iter 93000, loss: 0.001373
 >> iter 94000, loss: 0.001367
 >> iter 95000, loss: 0.001338
 >> iter 96000, loss: 0.001333
 >> iter 97000, loss: 0.001306
 >> iter 98000, loss: 0.001301
 >> iter 99000, loss: 0.001274
 >> iter 100000, loss: 0.001270
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0339996600034
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.624928
 >> iter 2000, loss: 15.073937
 >> iter 3000, loss: 13.732577
 >> iter 4000, loss: 13.239972
 >> iter 5000, loss: 13.043369
 >> iter 6000, loss: 12.977198
 >> iter 7000, loss: 12.941679
 >> iter 8000, loss: 12.938137
 >> iter 9000, loss: 12.925612
 >> iter 10000, loss: 12.932787
   Number of active neurons: 4
 >> iter 11000, loss: 12.920691
 >> iter 12000, loss: 12.703404
 >> iter 13000, loss: 7.794811
 >> iter 14000, loss: 3.139067
 >> iter 15000, loss: 1.213972
 >> iter 16000, loss: 0.483247
 >> iter 17000, loss: 0.207326
 >> iter 18000, loss: 0.096989
 >> iter 19000, loss: 0.054107
 >> iter 20000, loss: 0.034177
   Number of active neurons: 6
 >> iter 21000, loss: 0.024710
 >> iter 22000, loss: 0.019645
 >> iter 23000, loss: 0.016622
 >> iter 24000, loss: 0.014563
 >> iter 25000, loss: 0.013041
 >> iter 26000, loss: 0.011850
 >> iter 27000, loss: 0.010867
 >> iter 28000, loss: 0.010057
 >> iter 29000, loss: 0.009348
 >> iter 30000, loss: 0.008748
   Number of active neurons: 6
 >> iter 31000, loss: 0.008207
 >> iter 32000, loss: 0.007743
 >> iter 33000, loss: 0.007318
 >> iter 34000, loss: 0.006947
 >> iter 35000, loss: 0.006604
 >> iter 36000, loss: 0.006301
 >> iter 37000, loss: 0.006017
 >> iter 38000, loss: 0.005764
 >> iter 39000, loss: 0.005527
 >> iter 40000, loss: 0.005314
   Number of active neurons: 6
 >> iter 41000, loss: 0.005111
 >> iter 42000, loss: 0.004926
 >> iter 43000, loss: 0.004752
 >> iter 44000, loss: 0.004592
 >> iter 45000, loss: 0.004441
 >> iter 46000, loss: 0.004301
 >> iter 47000, loss: 0.004168
 >> iter 48000, loss: 0.004043
 >> iter 49000, loss: 0.003926
 >> iter 50000, loss: 0.003816
   Number of active neurons: 6
 >> iter 51000, loss: 0.003710
 >> iter 52000, loss: 0.003612
 >> iter 53000, loss: 0.003515
 >> iter 54000, loss: 0.003428
 >> iter 55000, loss: 0.003340
 >> iter 56000, loss: 0.003261
 >> iter 57000, loss: 0.003182
 >> iter 58000, loss: 0.003110
 >> iter 59000, loss: 0.003038
 >> iter 60000, loss: 0.002972
   Number of active neurons: 6
 >> iter 61000, loss: 0.002906
 >> iter 62000, loss: 0.002846
 >> iter 63000, loss: 0.002784
 >> iter 64000, loss: 0.002730
 >> iter 65000, loss: 0.002674
 >> iter 66000, loss: 0.002622
 >> iter 67000, loss: 0.002571
 >> iter 68000, loss: 0.002523
 >> iter 69000, loss: 0.002476
 >> iter 70000, loss: 0.002430
   Number of active neurons: 6
 >> iter 71000, loss: 0.002388
 >> iter 72000, loss: 0.002345
 >> iter 73000, loss: 0.002304
 >> iter 74000, loss: 0.002266
 >> iter 75000, loss: 0.002228
 >> iter 76000, loss: 0.002191
 >> iter 77000, loss: 0.002156
 >> iter 78000, loss: 0.002121
 >> iter 79000, loss: 0.002088
 >> iter 80000, loss: 0.002056
   Number of active neurons: 6
 >> iter 81000, loss: 0.002024
 >> iter 82000, loss: 0.001994
 >> iter 83000, loss: 0.001964
 >> iter 84000, loss: 0.001935
 >> iter 85000, loss: 0.001908
 >> iter 86000, loss: 0.001880
 >> iter 87000, loss: 0.001854
 >> iter 88000, loss: 0.001829
 >> iter 89000, loss: 0.001803
 >> iter 90000, loss: 0.001779
   Number of active neurons: 6
 >> iter 91000, loss: 0.001756
 >> iter 92000, loss: 0.001732
 >> iter 93000, loss: 0.001711
 >> iter 94000, loss: 0.001688
 >> iter 95000, loss: 0.001668
 >> iter 96000, loss: 0.001646
 >> iter 97000, loss: 0.001627
 >> iter 98000, loss: 0.001605
 >> iter 99000, loss: 0.001588
 >> iter 100000, loss: 0.001567
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0069999300007
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.648761
 >> iter 2000, loss: 15.080631
 >> iter 3000, loss: 13.739246
 >> iter 4000, loss: 13.247389
 >> iter 5000, loss: 13.053839
 >> iter 6000, loss: 12.987318
 >> iter 7000, loss: 12.953473
 >> iter 8000, loss: 12.949347
 >> iter 9000, loss: 12.938097
 >> iter 10000, loss: 12.945250
   Number of active neurons: 4
 >> iter 11000, loss: 12.935340
 >> iter 12000, loss: 12.941784
 >> iter 13000, loss: 12.932476
 >> iter 14000, loss: 12.938314
 >> iter 15000, loss: 12.863148
 >> iter 16000, loss: 11.721865
 >> iter 17000, loss: 4.740280
 >> iter 18000, loss: 1.818854
 >> iter 19000, loss: 0.711097
 >> iter 20000, loss: 0.291551
   Number of active neurons: 6
 >> iter 21000, loss: 0.129971
 >> iter 22000, loss: 0.066550
 >> iter 23000, loss: 0.039986
 >> iter 24000, loss: 0.028313
 >> iter 25000, loss: 0.022155
 >> iter 26000, loss: 0.018801
 >> iter 27000, loss: 0.016351
 >> iter 28000, loss: 0.014764
 >> iter 29000, loss: 0.013310
 >> iter 30000, loss: 0.012312
   Number of active neurons: 6
 >> iter 31000, loss: 0.011291
 >> iter 32000, loss: 0.010584
 >> iter 33000, loss: 0.009815
 >> iter 34000, loss: 0.009285
 >> iter 35000, loss: 0.008678
 >> iter 36000, loss: 0.008271
 >> iter 37000, loss: 0.007776
 >> iter 38000, loss: 0.007455
 >> iter 39000, loss: 0.007047
 >> iter 40000, loss: 0.006787
   Number of active neurons: 6
 >> iter 41000, loss: 0.006441
 >> iter 42000, loss: 0.006224
 >> iter 43000, loss: 0.005929
 >> iter 44000, loss: 0.005748
 >> iter 45000, loss: 0.005493
 >> iter 46000, loss: 0.005342
 >> iter 47000, loss: 0.005116
 >> iter 48000, loss: 0.004986
 >> iter 49000, loss: 0.004787
 >> iter 50000, loss: 0.004677
   Number of active neurons: 6
 >> iter 51000, loss: 0.004496
 >> iter 52000, loss: 0.004401
 >> iter 53000, loss: 0.004237
 >> iter 54000, loss: 0.004157
 >> iter 55000, loss: 0.004007
 >> iter 56000, loss: 0.003938
 >> iter 57000, loss: 0.003801
 >> iter 58000, loss: 0.003740
 >> iter 59000, loss: 0.003615
 >> iter 60000, loss: 0.003561
   Number of active neurons: 6
 >> iter 61000, loss: 0.003447
 >> iter 62000, loss: 0.003398
 >> iter 63000, loss: 0.003291
 >> iter 64000, loss: 0.003249
 >> iter 65000, loss: 0.003151
 >> iter 66000, loss: 0.003112
 >> iter 67000, loss: 0.003023
 >> iter 68000, loss: 0.002987
 >> iter 69000, loss: 0.002903
 >> iter 70000, loss: 0.002870
   Number of active neurons: 6
 >> iter 71000, loss: 0.002793
 >> iter 72000, loss: 0.002763
 >> iter 73000, loss: 0.002689
 >> iter 74000, loss: 0.002664
 >> iter 75000, loss: 0.002594
 >> iter 76000, loss: 0.002572
 >> iter 77000, loss: 0.002506
 >> iter 78000, loss: 0.002486
 >> iter 79000, loss: 0.002423
 >> iter 80000, loss: 0.002404
   Number of active neurons: 6
 >> iter 81000, loss: 0.002346
 >> iter 82000, loss: 0.002328
 >> iter 83000, loss: 0.002272
 >> iter 84000, loss: 0.002257
 >> iter 85000, loss: 0.002204
 >> iter 86000, loss: 0.002190
 >> iter 87000, loss: 0.002139
 >> iter 88000, loss: 0.002126
 >> iter 89000, loss: 0.002078
 >> iter 90000, loss: 0.002066
   Number of active neurons: 6
 >> iter 91000, loss: 0.002020
 >> iter 92000, loss: 0.002010
 >> iter 93000, loss: 0.001966
 >> iter 94000, loss: 0.001956
 >> iter 95000, loss: 0.001914
 >> iter 96000, loss: 0.001905
 >> iter 97000, loss: 0.001866
 >> iter 98000, loss: 0.001856
 >> iter 99000, loss: 0.001819
 >> iter 100000, loss: 0.001810
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.630496
 >> iter 2000, loss: 15.090351
 >> iter 3000, loss: 13.749449
 >> iter 4000, loss: 13.254720
 >> iter 5000, loss: 13.053620
 >> iter 6000, loss: 12.984411
 >> iter 7000, loss: 12.945762
 >> iter 8000, loss: 12.940868
 >> iter 9000, loss: 12.926906
 >> iter 10000, loss: 12.933189
   Number of active neurons: 4
 >> iter 11000, loss: 12.918812
 >> iter 12000, loss: 12.272933
 >> iter 13000, loss: 5.289070
 >> iter 14000, loss: 2.005332
 >> iter 15000, loss: 0.768570
 >> iter 16000, loss: 0.305081
 >> iter 17000, loss: 0.128212
 >> iter 18000, loss: 0.060056
 >> iter 19000, loss: 0.032693
 >> iter 20000, loss: 0.021197
   Number of active neurons: 6
 >> iter 21000, loss: 0.015708
 >> iter 22000, loss: 0.012884
 >> iter 23000, loss: 0.011037
 >> iter 24000, loss: 0.009856
 >> iter 25000, loss: 0.008854
 >> iter 26000, loss: 0.008142
 >> iter 27000, loss: 0.007461
 >> iter 28000, loss: 0.006970
 >> iter 29000, loss: 0.006461
 >> iter 30000, loss: 0.006096
   Number of active neurons: 6
 >> iter 31000, loss: 0.005697
 >> iter 32000, loss: 0.005416
 >> iter 33000, loss: 0.005096
 >> iter 34000, loss: 0.004872
 >> iter 35000, loss: 0.004609
 >> iter 36000, loss: 0.004428
 >> iter 37000, loss: 0.004206
 >> iter 38000, loss: 0.004059
 >> iter 39000, loss: 0.003869
 >> iter 40000, loss: 0.003748
   Number of active neurons: 6
 >> iter 41000, loss: 0.003583
 >> iter 42000, loss: 0.003478
 >> iter 43000, loss: 0.003335
 >> iter 44000, loss: 0.003245
 >> iter 45000, loss: 0.003120
 >> iter 46000, loss: 0.003044
 >> iter 47000, loss: 0.002930
 >> iter 48000, loss: 0.002863
 >> iter 49000, loss: 0.002762
 >> iter 50000, loss: 0.002705
   Number of active neurons: 6
 >> iter 51000, loss: 0.002612
 >> iter 52000, loss: 0.002561
 >> iter 53000, loss: 0.002477
 >> iter 54000, loss: 0.002433
 >> iter 55000, loss: 0.002355
 >> iter 56000, loss: 0.002317
 >> iter 57000, loss: 0.002246
 >> iter 58000, loss: 0.002211
 >> iter 59000, loss: 0.002147
 >> iter 60000, loss: 0.002115
   Number of active neurons: 6
 >> iter 61000, loss: 0.002055
 >> iter 62000, loss: 0.002026
 >> iter 63000, loss: 0.001970
 >> iter 64000, loss: 0.001944
 >> iter 65000, loss: 0.001894
 >> iter 66000, loss: 0.001869
 >> iter 67000, loss: 0.001823
 >> iter 68000, loss: 0.001799
 >> iter 69000, loss: 0.001757
 >> iter 70000, loss: 0.001734
   Number of active neurons: 6
 >> iter 71000, loss: 0.001695
 >> iter 72000, loss: 0.001674
 >> iter 73000, loss: 0.001637
 >> iter 74000, loss: 0.001619
 >> iter 75000, loss: 0.001583
 >> iter 76000, loss: 0.001567
 >> iter 77000, loss: 0.001533
 >> iter 78000, loss: 0.001518
 >> iter 79000, loss: 0.001486
 >> iter 80000, loss: 0.001472
   Number of active neurons: 6
 >> iter 81000, loss: 0.001442
 >> iter 82000, loss: 0.001428
 >> iter 83000, loss: 0.001399
 >> iter 84000, loss: 0.001387
 >> iter 85000, loss: 0.001360
 >> iter 86000, loss: 0.001349
 >> iter 87000, loss: 0.001322
 >> iter 88000, loss: 0.001312
 >> iter 89000, loss: 0.001287
 >> iter 90000, loss: 0.001278
   Number of active neurons: 6
 >> iter 91000, loss: 0.001253
 >> iter 92000, loss: 0.001245
 >> iter 93000, loss: 0.001222
 >> iter 94000, loss: 0.001213
 >> iter 95000, loss: 0.001191
 >> iter 96000, loss: 0.001184
 >> iter 97000, loss: 0.001163
 >> iter 98000, loss: 0.001155
 >> iter 99000, loss: 0.001135
 >> iter 100000, loss: 0.001128
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.643279
 >> iter 2000, loss: 15.079808
 >> iter 3000, loss: 13.732158
 >> iter 4000, loss: 13.237326
 >> iter 5000, loss: 13.040763
 >> iter 6000, loss: 12.973689
 >> iter 7000, loss: 12.938486
 >> iter 8000, loss: 12.930987
 >> iter 9000, loss: 12.697680
 >> iter 10000, loss: 11.990153
   Number of active neurons: 6
 >> iter 11000, loss: 5.722518
 >> iter 12000, loss: 2.154063
 >> iter 13000, loss: 0.819656
 >> iter 14000, loss: 0.320322
 >> iter 15000, loss: 0.132358
 >> iter 16000, loss: 0.060359
 >> iter 17000, loss: 0.032071
 >> iter 18000, loss: 0.020227
 >> iter 19000, loss: 0.014892
 >> iter 20000, loss: 0.012063
   Number of active neurons: 6
 >> iter 21000, loss: 0.010411
 >> iter 22000, loss: 0.009225
 >> iter 23000, loss: 0.008373
 >> iter 24000, loss: 0.007645
 >> iter 25000, loss: 0.007077
 >> iter 26000, loss: 0.006556
 >> iter 27000, loss: 0.006139
 >> iter 28000, loss: 0.005741
 >> iter 29000, loss: 0.005420
 >> iter 30000, loss: 0.005106
   Number of active neurons: 6
 >> iter 31000, loss: 0.004851
 >> iter 32000, loss: 0.004595
 >> iter 33000, loss: 0.004390
 >> iter 34000, loss: 0.004177
 >> iter 35000, loss: 0.004006
 >> iter 36000, loss: 0.003826
 >> iter 37000, loss: 0.003682
 >> iter 38000, loss: 0.003529
 >> iter 39000, loss: 0.003407
 >> iter 40000, loss: 0.003275
   Number of active neurons: 6
 >> iter 41000, loss: 0.003170
 >> iter 42000, loss: 0.003054
 >> iter 43000, loss: 0.002962
 >> iter 44000, loss: 0.002860
 >> iter 45000, loss: 0.002780
 >> iter 46000, loss: 0.002689
 >> iter 47000, loss: 0.002619
 >> iter 48000, loss: 0.002537
 >> iter 49000, loss: 0.002475
 >> iter 50000, loss: 0.002401
   Number of active neurons: 6
 >> iter 51000, loss: 0.002345
 >> iter 52000, loss: 0.002279
 >> iter 53000, loss: 0.002227
 >> iter 54000, loss: 0.002168
 >> iter 55000, loss: 0.002121
 >> iter 56000, loss: 0.002067
 >> iter 57000, loss: 0.002024
 >> iter 58000, loss: 0.001975
 >> iter 59000, loss: 0.001936
 >> iter 60000, loss: 0.001890
   Number of active neurons: 6
 >> iter 61000, loss: 0.001855
 >> iter 62000, loss: 0.001812
 >> iter 63000, loss: 0.001780
 >> iter 64000, loss: 0.001740
 >> iter 65000, loss: 0.001710
 >> iter 66000, loss: 0.001674
 >> iter 67000, loss: 0.001646
 >> iter 68000, loss: 0.001612
 >> iter 69000, loss: 0.001586
 >> iter 70000, loss: 0.001555
   Number of active neurons: 6
 >> iter 71000, loss: 0.001530
 >> iter 72000, loss: 0.001501
 >> iter 73000, loss: 0.001478
 >> iter 74000, loss: 0.001451
 >> iter 75000, loss: 0.001429
 >> iter 76000, loss: 0.001404
 >> iter 77000, loss: 0.001384
 >> iter 78000, loss: 0.001360
 >> iter 79000, loss: 0.001341
 >> iter 80000, loss: 0.001318
   Number of active neurons: 6
 >> iter 81000, loss: 0.001300
 >> iter 82000, loss: 0.001278
 >> iter 83000, loss: 0.001262
 >> iter 84000, loss: 0.001242
 >> iter 85000, loss: 0.001226
 >> iter 86000, loss: 0.001206
 >> iter 87000, loss: 0.001192
 >> iter 88000, loss: 0.001173
 >> iter 89000, loss: 0.001159
 >> iter 90000, loss: 0.001142
   Number of active neurons: 6
 >> iter 91000, loss: 0.001129
 >> iter 92000, loss: 0.001112
 >> iter 93000, loss: 0.001100
 >> iter 94000, loss: 0.001084
 >> iter 95000, loss: 0.001072
 >> iter 96000, loss: 0.001057
 >> iter 97000, loss: 0.001046
 >> iter 98000, loss: 0.001031
 >> iter 99000, loss: 0.001021
 >> iter 100000, loss: 0.001006
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.643746
 >> iter 2000, loss: 15.099607
 >> iter 3000, loss: 13.754837
 >> iter 4000, loss: 13.256607
 >> iter 5000, loss: 13.055653
 >> iter 6000, loss: 12.985569
 >> iter 7000, loss: 12.948044
 >> iter 8000, loss: 12.942098
 >> iter 9000, loss: 12.928805
 >> iter 10000, loss: 12.934669
   Number of active neurons: 4
 >> iter 11000, loss: 12.923215
 >> iter 12000, loss: 12.844967
 >> iter 13000, loss: 9.578515
 >> iter 14000, loss: 3.630568
 >> iter 15000, loss: 1.375147
 >> iter 16000, loss: 0.554764
 >> iter 17000, loss: 0.224239
 >> iter 18000, loss: 0.098072
 >> iter 19000, loss: 0.048629
 >> iter 20000, loss: 0.028659
   Number of active neurons: 6
 >> iter 21000, loss: 0.020183
 >> iter 22000, loss: 0.015885
 >> iter 23000, loss: 0.013251
 >> iter 24000, loss: 0.011649
 >> iter 25000, loss: 0.010383
 >> iter 26000, loss: 0.009516
 >> iter 27000, loss: 0.008706
 >> iter 28000, loss: 0.008139
 >> iter 29000, loss: 0.007553
 >> iter 30000, loss: 0.007119
   Number of active neurons: 6
 >> iter 31000, loss: 0.006645
 >> iter 32000, loss: 0.006312
 >> iter 33000, loss: 0.005943
 >> iter 34000, loss: 0.005692
 >> iter 35000, loss: 0.005389
 >> iter 36000, loss: 0.005170
 >> iter 37000, loss: 0.004908
 >> iter 38000, loss: 0.004733
 >> iter 39000, loss: 0.004515
 >> iter 40000, loss: 0.004375
   Number of active neurons: 6
 >> iter 41000, loss: 0.004186
 >> iter 42000, loss: 0.004060
 >> iter 43000, loss: 0.003893
 >> iter 44000, loss: 0.003786
 >> iter 45000, loss: 0.003642
 >> iter 46000, loss: 0.003552
 >> iter 47000, loss: 0.003421
 >> iter 48000, loss: 0.003341
 >> iter 49000, loss: 0.003225
 >> iter 50000, loss: 0.003156
   Number of active neurons: 6
 >> iter 51000, loss: 0.003050
 >> iter 52000, loss: 0.002988
 >> iter 53000, loss: 0.002891
 >> iter 54000, loss: 0.002838
 >> iter 55000, loss: 0.002750
 >> iter 56000, loss: 0.002702
 >> iter 57000, loss: 0.002622
 >> iter 58000, loss: 0.002579
 >> iter 59000, loss: 0.002506
 >> iter 60000, loss: 0.002467
   Number of active neurons: 6
 >> iter 61000, loss: 0.002399
 >> iter 62000, loss: 0.002363
 >> iter 63000, loss: 0.002300
 >> iter 64000, loss: 0.002267
 >> iter 65000, loss: 0.002210
 >> iter 66000, loss: 0.002179
 >> iter 67000, loss: 0.002128
 >> iter 68000, loss: 0.002098
 >> iter 69000, loss: 0.002051
 >> iter 70000, loss: 0.002022
   Number of active neurons: 6
 >> iter 71000, loss: 0.001978
 >> iter 72000, loss: 0.001951
 >> iter 73000, loss: 0.001910
 >> iter 74000, loss: 0.001887
 >> iter 75000, loss: 0.001847
 >> iter 76000, loss: 0.001826
 >> iter 77000, loss: 0.001788
 >> iter 78000, loss: 0.001769
 >> iter 79000, loss: 0.001732
 >> iter 80000, loss: 0.001715
   Number of active neurons: 6
 >> iter 81000, loss: 0.001681
 >> iter 82000, loss: 0.001665
 >> iter 83000, loss: 0.001631
 >> iter 84000, loss: 0.001617
 >> iter 85000, loss: 0.001585
 >> iter 86000, loss: 0.001572
 >> iter 87000, loss: 0.001541
 >> iter 88000, loss: 0.001530
 >> iter 89000, loss: 0.001499
 >> iter 90000, loss: 0.001489
   Number of active neurons: 6
 >> iter 91000, loss: 0.001460
 >> iter 92000, loss: 0.001450
 >> iter 93000, loss: 0.001423
 >> iter 94000, loss: 0.001413
 >> iter 95000, loss: 0.001387
 >> iter 96000, loss: 0.001379
 >> iter 97000, loss: 0.001354
 >> iter 98000, loss: 0.001347
 >> iter 99000, loss: 0.001322
 >> iter 100000, loss: 0.001315
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0159998400016
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.593597
 >> iter 2000, loss: 15.080757
 >> iter 3000, loss: 13.751805
 >> iter 4000, loss: 13.259309
 >> iter 5000, loss: 13.060286
 >> iter 6000, loss: 12.990513
 >> iter 7000, loss: 12.953120
 >> iter 8000, loss: 12.947396
 >> iter 9000, loss: 12.933776
 >> iter 10000, loss: 12.939070
   Number of active neurons: 4
 >> iter 11000, loss: 12.926888
 >> iter 12000, loss: 12.824370
 >> iter 13000, loss: 8.603905
 >> iter 14000, loss: 3.327271
 >> iter 15000, loss: 1.273923
 >> iter 16000, loss: 0.500659
 >> iter 17000, loss: 0.207594
 >> iter 18000, loss: 0.094910
 >> iter 19000, loss: 0.050119
 >> iter 20000, loss: 0.031410
   Number of active neurons: 6
 >> iter 21000, loss: 0.022744
 >> iter 22000, loss: 0.018307
 >> iter 23000, loss: 0.015557
 >> iter 24000, loss: 0.013763
 >> iter 25000, loss: 0.012330
 >> iter 26000, loss: 0.011266
 >> iter 27000, loss: 0.010309
 >> iter 28000, loss: 0.009571
 >> iter 29000, loss: 0.008867
 >> iter 30000, loss: 0.008311
   Number of active neurons: 6
 >> iter 31000, loss: 0.007767
 >> iter 32000, loss: 0.007332
 >> iter 33000, loss: 0.006902
 >> iter 34000, loss: 0.006551
 >> iter 35000, loss: 0.006198
 >> iter 36000, loss: 0.005912
 >> iter 37000, loss: 0.005616
 >> iter 38000, loss: 0.005378
 >> iter 39000, loss: 0.005127
 >> iter 40000, loss: 0.004927
   Number of active neurons: 6
 >> iter 41000, loss: 0.004710
 >> iter 42000, loss: 0.004537
 >> iter 43000, loss: 0.004350
 >> iter 44000, loss: 0.004200
 >> iter 45000, loss: 0.004036
 >> iter 46000, loss: 0.003906
 >> iter 47000, loss: 0.003761
 >> iter 48000, loss: 0.003646
 >> iter 49000, loss: 0.003517
 >> iter 50000, loss: 0.003416
   Number of active neurons: 6
 >> iter 51000, loss: 0.003298
 >> iter 52000, loss: 0.003210
 >> iter 53000, loss: 0.003103
 >> iter 54000, loss: 0.003026
 >> iter 55000, loss: 0.002928
 >> iter 56000, loss: 0.002860
 >> iter 57000, loss: 0.002771
 >> iter 58000, loss: 0.002709
 >> iter 59000, loss: 0.002629
 >> iter 60000, loss: 0.002573
   Number of active neurons: 6
 >> iter 61000, loss: 0.002499
 >> iter 62000, loss: 0.002449
 >> iter 63000, loss: 0.002380
 >> iter 64000, loss: 0.002337
 >> iter 65000, loss: 0.002273
 >> iter 66000, loss: 0.002233
 >> iter 67000, loss: 0.002175
 >> iter 68000, loss: 0.002137
 >> iter 69000, loss: 0.002084
 >> iter 70000, loss: 0.002048
   Number of active neurons: 6
 >> iter 71000, loss: 0.002001
 >> iter 72000, loss: 0.001967
 >> iter 73000, loss: 0.001922
 >> iter 74000, loss: 0.001893
 >> iter 75000, loss: 0.001850
 >> iter 76000, loss: 0.001823
 >> iter 77000, loss: 0.001783
 >> iter 78000, loss: 0.001758
 >> iter 79000, loss: 0.001721
 >> iter 80000, loss: 0.001698
   Number of active neurons: 6
 >> iter 81000, loss: 0.001662
 >> iter 82000, loss: 0.001641
 >> iter 83000, loss: 0.001607
 >> iter 84000, loss: 0.001588
 >> iter 85000, loss: 0.001556
 >> iter 86000, loss: 0.001538
 >> iter 87000, loss: 0.001508
 >> iter 88000, loss: 0.001492
 >> iter 89000, loss: 0.001462
 >> iter 90000, loss: 0.001447
   Number of active neurons: 6
 >> iter 91000, loss: 0.001420
 >> iter 92000, loss: 0.001406
 >> iter 93000, loss: 0.001380
 >> iter 94000, loss: 0.001366
 >> iter 95000, loss: 0.001342
 >> iter 96000, loss: 0.001329
 >> iter 97000, loss: 0.001307
 >> iter 98000, loss: 0.001294
 >> iter 99000, loss: 0.001272
 >> iter 100000, loss: 0.001260
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.622210
 >> iter 2000, loss: 15.085519
 >> iter 3000, loss: 13.750165
 >> iter 4000, loss: 13.258236
 >> iter 5000, loss: 13.063881
 >> iter 6000, loss: 12.995398
 >> iter 7000, loss: 12.960465
 >> iter 8000, loss: 12.954559
 >> iter 9000, loss: 12.942770
 >> iter 10000, loss: 12.948980
   Number of active neurons: 5
 >> iter 11000, loss: 12.938827
 >> iter 12000, loss: 12.945086
 >> iter 13000, loss: 12.935520
 >> iter 14000, loss: 12.943697
 >> iter 15000, loss: 12.936612
 >> iter 16000, loss: 12.942471
 >> iter 17000, loss: 12.935464
 >> iter 18000, loss: 12.812239
 >> iter 19000, loss: 9.721133
 >> iter 20000, loss: 3.729859
   Number of active neurons: 6
 >> iter 21000, loss: 1.423234
 >> iter 22000, loss: 0.554563
 >> iter 23000, loss: 0.225939
 >> iter 24000, loss: 0.100561
 >> iter 25000, loss: 0.051053
 >> iter 26000, loss: 0.030962
 >> iter 27000, loss: 0.021724
 >> iter 28000, loss: 0.017257
 >> iter 29000, loss: 0.014477
 >> iter 30000, loss: 0.012803
   Number of active neurons: 6
 >> iter 31000, loss: 0.011401
 >> iter 32000, loss: 0.010408
 >> iter 33000, loss: 0.009492
 >> iter 34000, loss: 0.008812
 >> iter 35000, loss: 0.008145
 >> iter 36000, loss: 0.007633
 >> iter 37000, loss: 0.007122
 >> iter 38000, loss: 0.006728
 >> iter 39000, loss: 0.006327
 >> iter 40000, loss: 0.006012
   Number of active neurons: 6
 >> iter 41000, loss: 0.005688
 >> iter 42000, loss: 0.005428
 >> iter 43000, loss: 0.005162
 >> iter 44000, loss: 0.004946
 >> iter 45000, loss: 0.004725
 >> iter 46000, loss: 0.004542
 >> iter 47000, loss: 0.004353
 >> iter 48000, loss: 0.004196
 >> iter 49000, loss: 0.004035
 >> iter 50000, loss: 0.003900
   Number of active neurons: 6
 >> iter 51000, loss: 0.003758
 >> iter 52000, loss: 0.003639
 >> iter 53000, loss: 0.003514
 >> iter 54000, loss: 0.003412
 >> iter 55000, loss: 0.003300
 >> iter 56000, loss: 0.003210
 >> iter 57000, loss: 0.003111
 >> iter 58000, loss: 0.003030
 >> iter 59000, loss: 0.002942
 >> iter 60000, loss: 0.002869
   Number of active neurons: 6
 >> iter 61000, loss: 0.002790
 >> iter 62000, loss: 0.002724
 >> iter 63000, loss: 0.002651
 >> iter 64000, loss: 0.002591
 >> iter 65000, loss: 0.002528
 >> iter 66000, loss: 0.002471
 >> iter 67000, loss: 0.002414
 >> iter 68000, loss: 0.002362
 >> iter 69000, loss: 0.002310
 >> iter 70000, loss: 0.002260
   Number of active neurons: 6
 >> iter 71000, loss: 0.002214
 >> iter 72000, loss: 0.002169
 >> iter 73000, loss: 0.002125
 >> iter 74000, loss: 0.002084
 >> iter 75000, loss: 0.002043
 >> iter 76000, loss: 0.002006
 >> iter 77000, loss: 0.001968
 >> iter 78000, loss: 0.001933
 >> iter 79000, loss: 0.001897
 >> iter 80000, loss: 0.001865
   Number of active neurons: 6
 >> iter 81000, loss: 0.001832
 >> iter 82000, loss: 0.001801
 >> iter 83000, loss: 0.001770
 >> iter 84000, loss: 0.001742
 >> iter 85000, loss: 0.001712
 >> iter 86000, loss: 0.001686
 >> iter 87000, loss: 0.001658
 >> iter 88000, loss: 0.001633
 >> iter 89000, loss: 0.001607
 >> iter 90000, loss: 0.001584
   Number of active neurons: 6
 >> iter 91000, loss: 0.001560
 >> iter 92000, loss: 0.001537
 >> iter 93000, loss: 0.001515
 >> iter 94000, loss: 0.001493
 >> iter 95000, loss: 0.001472
 >> iter 96000, loss: 0.001451
 >> iter 97000, loss: 0.001432
 >> iter 98000, loss: 0.001412
 >> iter 99000, loss: 0.001394
 >> iter 100000, loss: 0.001374
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.609361
 >> iter 2000, loss: 15.088049
 >> iter 3000, loss: 13.754844
 >> iter 4000, loss: 13.261478
 >> iter 5000, loss: 13.066504
 >> iter 6000, loss: 12.997782
 >> iter 7000, loss: 12.963009
 >> iter 8000, loss: 12.956794
 >> iter 9000, loss: 12.944534
 >> iter 10000, loss: 12.949099
   Number of active neurons: 5
 >> iter 11000, loss: 12.938254
 >> iter 12000, loss: 12.939430
 >> iter 13000, loss: 12.839326
 >> iter 14000, loss: 12.242574
 >> iter 15000, loss: 10.992946
 >> iter 16000, loss: 9.951749
 >> iter 17000, loss: 9.499802
 >> iter 18000, loss: 8.842236
 >> iter 19000, loss: 8.397816
 >> iter 20000, loss: 8.456420
   Number of active neurons: 6
 >> iter 21000, loss: 7.695045
 >> iter 22000, loss: 7.589816
 >> iter 23000, loss: 7.062967
 >> iter 24000, loss: 6.716729
 >> iter 25000, loss: 7.032976
 >> iter 26000, loss: 6.717333
 >> iter 27000, loss: 6.572566
 >> iter 28000, loss: 6.137643
 >> iter 29000, loss: 6.130663
 >> iter 30000, loss: 6.254767
   Number of active neurons: 6
 >> iter 31000, loss: 5.812435
 >> iter 32000, loss: 5.465268
 >> iter 33000, loss: 5.236934
 >> iter 34000, loss: 5.127613
 >> iter 35000, loss: 4.991886
 >> iter 36000, loss: 4.934880
 >> iter 37000, loss: 4.900281
 >> iter 38000, loss: 4.969639
 >> iter 39000, loss: 4.908179
 >> iter 40000, loss: 4.918600
   Number of active neurons: 6
 >> iter 41000, loss: 4.886140
 >> iter 42000, loss: 4.879750
 >> iter 43000, loss: 4.905175
 >> iter 44000, loss: 4.981752
 >> iter 45000, loss: 4.900101
 >> iter 46000, loss: 5.145708
 >> iter 47000, loss: 5.001273
 >> iter 48000, loss: 5.260498
 >> iter 49000, loss: 5.020113
 >> iter 50000, loss: 4.932269
   Number of active neurons: 6
 >> iter 51000, loss: 4.883906
 >> iter 52000, loss: 4.889834
 >> iter 53000, loss: 4.863437
 >> iter 54000, loss: 4.869666
 >> iter 55000, loss: 4.849149
 >> iter 56000, loss: 4.870508
 >> iter 57000, loss: 4.850897
 >> iter 58000, loss: 4.868652
 >> iter 59000, loss: 4.851236
 >> iter 60000, loss: 4.866998
   Number of active neurons: 6
 >> iter 61000, loss: 4.847007
 >> iter 62000, loss: 4.865215
 >> iter 63000, loss: 4.844425
 >> iter 64000, loss: 4.861382
 >> iter 65000, loss: 4.848845
 >> iter 66000, loss: 4.854744
 >> iter 67000, loss: 4.848556
 >> iter 68000, loss: 4.855843
 >> iter 69000, loss: 4.842814
 >> iter 70000, loss: 4.850000
   Number of active neurons: 6
 >> iter 71000, loss: 4.843711
 >> iter 72000, loss: 4.846729
 >> iter 73000, loss: 4.840831
 >> iter 74000, loss: 4.852496
 >> iter 75000, loss: 4.839944
 >> iter 76000, loss: 4.858176
 >> iter 77000, loss: 4.851250
 >> iter 78000, loss: 4.862785
 >> iter 79000, loss: 4.846484
 >> iter 80000, loss: 4.863562
   Number of active neurons: 6
 >> iter 81000, loss: 4.840823
 >> iter 82000, loss: 4.863333
 >> iter 83000, loss: 4.851036
 >> iter 84000, loss: 4.873266
 >> iter 85000, loss: 4.856318
 >> iter 86000, loss: 4.867926
 >> iter 87000, loss: 4.860713
 >> iter 88000, loss: 4.874509
 >> iter 89000, loss: 4.856975
 >> iter 90000, loss: 4.886748
   Number of active neurons: 6
 >> iter 91000, loss: 4.859047
 >> iter 92000, loss: 4.884014
 >> iter 93000, loss: 4.859448
 >> iter 94000, loss: 4.883293
 >> iter 95000, loss: 4.868533
 >> iter 96000, loss: 4.881357
 >> iter 97000, loss: 4.868973
 >> iter 98000, loss: 4.875699
 >> iter 99000, loss: 4.870222
 >> iter 100000, loss: 4.870651
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 9.54380912382
   - Test - Long: 28.4385780711
   - Test - Big: 9.73390266097
   - Test - A: 0.0
   - Test - B: 31.604559696
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.655736
 >> iter 2000, loss: 15.079671
 >> iter 3000, loss: 13.735259
 >> iter 4000, loss: 13.240379
 >> iter 5000, loss: 13.045443
 >> iter 6000, loss: 12.977800
 >> iter 7000, loss: 12.943459
 >> iter 8000, loss: 12.938509
 >> iter 9000, loss: 12.927050
 >> iter 10000, loss: 12.933660
   Number of active neurons: 4
 >> iter 11000, loss: 12.923527
 >> iter 12000, loss: 12.929968
 >> iter 13000, loss: 12.920303
 >> iter 14000, loss: 12.928431
 >> iter 15000, loss: 12.921051
 >> iter 16000, loss: 12.909831
 >> iter 17000, loss: 12.329577
 >> iter 18000, loss: 5.301859
 >> iter 19000, loss: 2.108769
 >> iter 20000, loss: 0.865187
   Number of active neurons: 6
 >> iter 21000, loss: 0.350024
 >> iter 22000, loss: 0.152478
 >> iter 23000, loss: 0.075044
 >> iter 24000, loss: 0.043320
 >> iter 25000, loss: 0.029426
 >> iter 26000, loss: 0.022554
 >> iter 27000, loss: 0.018750
 >> iter 28000, loss: 0.016246
 >> iter 29000, loss: 0.014502
 >> iter 30000, loss: 0.013096
   Number of active neurons: 6
 >> iter 31000, loss: 0.012008
 >> iter 32000, loss: 0.011048
 >> iter 33000, loss: 0.010280
 >> iter 34000, loss: 0.009567
 >> iter 35000, loss: 0.008986
 >> iter 36000, loss: 0.008436
 >> iter 37000, loss: 0.007981
 >> iter 38000, loss: 0.007542
 >> iter 39000, loss: 0.007177
 >> iter 40000, loss: 0.006820
   Number of active neurons: 6
 >> iter 41000, loss: 0.006520
 >> iter 42000, loss: 0.006221
 >> iter 43000, loss: 0.005972
 >> iter 44000, loss: 0.005718
 >> iter 45000, loss: 0.005508
 >> iter 46000, loss: 0.005291
 >> iter 47000, loss: 0.005111
 >> iter 48000, loss: 0.004922
 >> iter 49000, loss: 0.004766
 >> iter 50000, loss: 0.004602
   Number of active neurons: 6
 >> iter 51000, loss: 0.004464
 >> iter 52000, loss: 0.004319
 >> iter 53000, loss: 0.004195
 >> iter 54000, loss: 0.004070
 >> iter 55000, loss: 0.003959
 >> iter 56000, loss: 0.003847
 >> iter 57000, loss: 0.003748
 >> iter 58000, loss: 0.003647
 >> iter 59000, loss: 0.003558
 >> iter 60000, loss: 0.003467
   Number of active neurons: 6
 >> iter 61000, loss: 0.003386
 >> iter 62000, loss: 0.003304
 >> iter 63000, loss: 0.003230
 >> iter 64000, loss: 0.003156
 >> iter 65000, loss: 0.003088
 >> iter 66000, loss: 0.003020
 >> iter 67000, loss: 0.002957
 >> iter 68000, loss: 0.002895
 >> iter 69000, loss: 0.002837
 >> iter 70000, loss: 0.002779
   Number of active neurons: 6
 >> iter 71000, loss: 0.002726
 >> iter 72000, loss: 0.002672
 >> iter 73000, loss: 0.002624
 >> iter 74000, loss: 0.002574
 >> iter 75000, loss: 0.002528
 >> iter 76000, loss: 0.002483
 >> iter 77000, loss: 0.002440
 >> iter 78000, loss: 0.002397
 >> iter 79000, loss: 0.002357
 >> iter 80000, loss: 0.002317
   Number of active neurons: 6
 >> iter 81000, loss: 0.002280
 >> iter 82000, loss: 0.002243
 >> iter 83000, loss: 0.002207
 >> iter 84000, loss: 0.002173
 >> iter 85000, loss: 0.002140
 >> iter 86000, loss: 0.002107
 >> iter 87000, loss: 0.002076
 >> iter 88000, loss: 0.002045
 >> iter 89000, loss: 0.002016
 >> iter 90000, loss: 0.001987
   Number of active neurons: 6
 >> iter 91000, loss: 0.001959
 >> iter 92000, loss: 0.001932
 >> iter 93000, loss: 0.001906
 >> iter 94000, loss: 0.001879
 >> iter 95000, loss: 0.001855
 >> iter 96000, loss: 0.001830
 >> iter 97000, loss: 0.001807
 >> iter 98000, loss: 0.001783
 >> iter 99000, loss: 0.001761
 >> iter 100000, loss: 0.001738
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00599994000061
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.632594
 >> iter 2000, loss: 15.098348
 >> iter 3000, loss: 13.757929
 >> iter 4000, loss: 13.260832
 >> iter 5000, loss: 13.058708
 >> iter 6000, loss: 12.988186
 >> iter 7000, loss: 12.949499
 >> iter 8000, loss: 12.943600
 >> iter 9000, loss: 12.929849
 >> iter 10000, loss: 12.935331
   Number of active neurons: 4
 >> iter 11000, loss: 12.909391
 >> iter 12000, loss: 11.433875
 >> iter 13000, loss: 4.412352
 >> iter 14000, loss: 1.679291
 >> iter 15000, loss: 0.650814
 >> iter 16000, loss: 0.262963
 >> iter 17000, loss: 0.114723
 >> iter 18000, loss: 0.056857
 >> iter 19000, loss: 0.033089
 >> iter 20000, loss: 0.022695
   Number of active neurons: 6
 >> iter 21000, loss: 0.017462
 >> iter 22000, loss: 0.014579
 >> iter 23000, loss: 0.012606
 >> iter 24000, loss: 0.011268
 >> iter 25000, loss: 0.010135
 >> iter 26000, loss: 0.009293
 >> iter 27000, loss: 0.008512
 >> iter 28000, loss: 0.007921
 >> iter 29000, loss: 0.007340
 >> iter 30000, loss: 0.006896
   Number of active neurons: 6
 >> iter 31000, loss: 0.006444
 >> iter 32000, loss: 0.006100
 >> iter 33000, loss: 0.005739
 >> iter 34000, loss: 0.005464
 >> iter 35000, loss: 0.005170
 >> iter 36000, loss: 0.004948
 >> iter 37000, loss: 0.004701
 >> iter 38000, loss: 0.004519
 >> iter 39000, loss: 0.004310
 >> iter 40000, loss: 0.004158
   Number of active neurons: 6
 >> iter 41000, loss: 0.003985
 >> iter 42000, loss: 0.003848
 >> iter 43000, loss: 0.003699
 >> iter 44000, loss: 0.003581
 >> iter 45000, loss: 0.003452
 >> iter 46000, loss: 0.003350
 >> iter 47000, loss: 0.003234
 >> iter 48000, loss: 0.003145
 >> iter 49000, loss: 0.003043
 >> iter 50000, loss: 0.002965
   Number of active neurons: 6
 >> iter 51000, loss: 0.002872
 >> iter 52000, loss: 0.002802
 >> iter 53000, loss: 0.002718
 >> iter 54000, loss: 0.002658
 >> iter 55000, loss: 0.002581
 >> iter 56000, loss: 0.002527
 >> iter 57000, loss: 0.002458
 >> iter 58000, loss: 0.002408
 >> iter 59000, loss: 0.002346
 >> iter 60000, loss: 0.002300
   Number of active neurons: 6
 >> iter 61000, loss: 0.002243
 >> iter 62000, loss: 0.002201
 >> iter 63000, loss: 0.002148
 >> iter 64000, loss: 0.002110
 >> iter 65000, loss: 0.002062
 >> iter 66000, loss: 0.002026
 >> iter 67000, loss: 0.001982
 >> iter 68000, loss: 0.001949
 >> iter 69000, loss: 0.001909
 >> iter 70000, loss: 0.001877
   Number of active neurons: 6
 >> iter 71000, loss: 0.001840
 >> iter 72000, loss: 0.001810
 >> iter 73000, loss: 0.001775
 >> iter 74000, loss: 0.001749
 >> iter 75000, loss: 0.001715
 >> iter 76000, loss: 0.001692
 >> iter 77000, loss: 0.001660
 >> iter 78000, loss: 0.001638
 >> iter 79000, loss: 0.001608
 >> iter 80000, loss: 0.001587
   Number of active neurons: 6
 >> iter 81000, loss: 0.001559
 >> iter 82000, loss: 0.001539
 >> iter 83000, loss: 0.001512
 >> iter 84000, loss: 0.001494
 >> iter 85000, loss: 0.001469
 >> iter 86000, loss: 0.001452
 >> iter 87000, loss: 0.001427
 >> iter 88000, loss: 0.001412
 >> iter 89000, loss: 0.001389
 >> iter 90000, loss: 0.001374
   Number of active neurons: 6
 >> iter 91000, loss: 0.001352
 >> iter 92000, loss: 0.001338
 >> iter 93000, loss: 0.001317
 >> iter 94000, loss: 0.001304
 >> iter 95000, loss: 0.001284
 >> iter 96000, loss: 0.001271
 >> iter 97000, loss: 0.001253
 >> iter 98000, loss: 0.001241
 >> iter 99000, loss: 0.001223
 >> iter 100000, loss: 0.001211
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

