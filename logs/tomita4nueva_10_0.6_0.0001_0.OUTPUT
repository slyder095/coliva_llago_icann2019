 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.732442
 >> iter 2000, loss: 8.499683
 >> iter 3000, loss: 3.840347
 >> iter 4000, loss: 1.745593
 >> iter 5000, loss: 0.960979
 >> iter 6000, loss: 0.896163
 >> iter 7000, loss: 0.591654
 >> iter 8000, loss: 0.325828
 >> iter 9000, loss: 0.285670
 >> iter 10000, loss: 0.336795
   Number of active neurons: 3
 >> iter 11000, loss: 0.305580
 >> iter 12000, loss: 0.573256
 >> iter 13000, loss: 0.463557
 >> iter 14000, loss: 0.276111
 >> iter 15000, loss: 0.345181
 >> iter 16000, loss: 0.274861
 >> iter 17000, loss: 0.405473
 >> iter 18000, loss: 0.410374
 >> iter 19000, loss: 0.427840
 >> iter 20000, loss: 0.357227
   Number of active neurons: 3
 >> iter 21000, loss: 0.200264
 >> iter 22000, loss: 0.272354
 >> iter 23000, loss: 0.306754
 >> iter 24000, loss: 0.250144
 >> iter 25000, loss: 0.176116
 >> iter 26000, loss: 0.278084
 >> iter 27000, loss: 0.439509
 >> iter 28000, loss: 0.350953
 >> iter 29000, loss: 0.251244
 >> iter 30000, loss: 0.231351
   Number of active neurons: 3
 >> iter 31000, loss: 0.411672
 >> iter 32000, loss: 0.434648
 >> iter 33000, loss: 0.286244
 >> iter 34000, loss: 0.291504
 >> iter 35000, loss: 0.320532
 >> iter 36000, loss: 0.265467
 >> iter 37000, loss: 0.373537
 >> iter 38000, loss: 0.320353
 >> iter 39000, loss: 0.226756
 >> iter 40000, loss: 0.219331
   Number of active neurons: 3
 >> iter 41000, loss: 0.192414
 >> iter 42000, loss: 0.166098
 >> iter 43000, loss: 0.148852
 >> iter 44000, loss: 0.183925
 >> iter 45000, loss: 0.179578
 >> iter 46000, loss: 0.241908
 >> iter 47000, loss: 0.321196
 >> iter 48000, loss: 0.377502
 >> iter 49000, loss: 0.431174
 >> iter 50000, loss: 0.251192
   Number of active neurons: 3
 >> iter 51000, loss: 0.133073
 >> iter 52000, loss: 0.290499
 >> iter 53000, loss: 0.213905
 >> iter 54000, loss: 0.287654
 >> iter 55000, loss: 0.136917
 >> iter 56000, loss: 0.338715
 >> iter 57000, loss: 0.444023
 >> iter 58000, loss: 0.290322
 >> iter 59000, loss: 0.215177
 >> iter 60000, loss: 0.196175
   Number of active neurons: 3
 >> iter 61000, loss: 0.123032
 >> iter 62000, loss: 0.081418
 >> iter 63000, loss: 0.158795
 >> iter 64000, loss: 0.218337
 >> iter 65000, loss: 0.241323
 >> iter 66000, loss: 0.283045
 >> iter 67000, loss: 0.405644
 >> iter 68000, loss: 0.372970
 >> iter 69000, loss: 0.248948
 >> iter 70000, loss: 0.182565
   Number of active neurons: 3
 >> iter 71000, loss: 0.210172
 >> iter 72000, loss: 0.308206
 >> iter 73000, loss: 0.348493
 >> iter 74000, loss: 0.303198
 >> iter 75000, loss: 0.288229
 >> iter 76000, loss: 0.171337
 >> iter 77000, loss: 0.139663
 >> iter 78000, loss: 0.228011
 >> iter 79000, loss: 0.189120
 >> iter 80000, loss: 0.433040
   Number of active neurons: 3
 >> iter 81000, loss: 0.293831
 >> iter 82000, loss: 0.306944
 >> iter 83000, loss: 0.446090
 >> iter 84000, loss: 0.330729
 >> iter 85000, loss: 0.230931
 >> iter 86000, loss: 0.319344
 >> iter 87000, loss: 0.331142
 >> iter 88000, loss: 0.267275
 >> iter 89000, loss: 0.238992
 >> iter 90000, loss: 0.262155
   Number of active neurons: 3
 >> iter 91000, loss: 0.306551
 >> iter 92000, loss: 0.345982
 >> iter 93000, loss: 0.360801
 >> iter 94000, loss: 0.400231
 >> iter 95000, loss: 0.273266
 >> iter 96000, loss: 0.239876
 >> iter 97000, loss: 0.185696
 >> iter 98000, loss: 0.180479
 >> iter 99000, loss: 0.250923
 >> iter 100000, loss: 0.286973
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.681300
 >> iter 2000, loss: 8.173502
 >> iter 3000, loss: 3.537061
 >> iter 4000, loss: 1.767203
 >> iter 5000, loss: 1.014798
 >> iter 6000, loss: 0.660551
 >> iter 7000, loss: 0.413020
 >> iter 8000, loss: 0.335360
 >> iter 9000, loss: 0.270102
 >> iter 10000, loss: 0.377900
   Number of active neurons: 6
 >> iter 11000, loss: 0.446563
 >> iter 12000, loss: 0.449531
 >> iter 13000, loss: 0.447875
 >> iter 14000, loss: 0.403601
 >> iter 15000, loss: 0.266043
 >> iter 16000, loss: 0.439549
 >> iter 17000, loss: 0.363458
 >> iter 18000, loss: 0.285499
 >> iter 19000, loss: 0.304076
 >> iter 20000, loss: 0.482043
   Number of active neurons: 4
 >> iter 21000, loss: 0.410250
 >> iter 22000, loss: 0.237472
 >> iter 23000, loss: 0.308711
 >> iter 24000, loss: 0.166638
 >> iter 25000, loss: 0.399178
 >> iter 26000, loss: 0.288553
 >> iter 27000, loss: 0.247281
 >> iter 28000, loss: 0.608695
 >> iter 29000, loss: 0.543376
 >> iter 30000, loss: 0.546034
   Number of active neurons: 4
 >> iter 31000, loss: 0.328983
 >> iter 32000, loss: 0.327468
 >> iter 33000, loss: 0.305761
 >> iter 34000, loss: 0.242022
 >> iter 35000, loss: 0.354164
 >> iter 36000, loss: 0.344999
 >> iter 37000, loss: 0.391892
 >> iter 38000, loss: 0.299761
 >> iter 39000, loss: 0.184041
 >> iter 40000, loss: 0.319354
   Number of active neurons: 4
 >> iter 41000, loss: 0.307074
 >> iter 42000, loss: 0.289876
 >> iter 43000, loss: 0.439515
 >> iter 44000, loss: 0.257358
 >> iter 45000, loss: 0.162083
 >> iter 46000, loss: 0.546773
 >> iter 47000, loss: 0.328001
 >> iter 48000, loss: 0.332604
 >> iter 49000, loss: 0.290774
 >> iter 50000, loss: 0.203648
   Number of active neurons: 3
 >> iter 51000, loss: 0.236298
 >> iter 52000, loss: 0.288634
 >> iter 53000, loss: 0.274667
 >> iter 54000, loss: 0.267601
 >> iter 55000, loss: 0.360573
 >> iter 56000, loss: 0.227576
 >> iter 57000, loss: 0.265318
 >> iter 58000, loss: 0.245523
 >> iter 59000, loss: 0.352972
 >> iter 60000, loss: 0.362090
   Number of active neurons: 3
 >> iter 61000, loss: 0.295499
 >> iter 62000, loss: 0.169639
 >> iter 63000, loss: 0.246594
 >> iter 64000, loss: 0.209764
 >> iter 65000, loss: 0.213334
 >> iter 66000, loss: 0.312691
 >> iter 67000, loss: 0.189733
 >> iter 68000, loss: 0.274591
 >> iter 69000, loss: 0.295755
 >> iter 70000, loss: 0.387956
   Number of active neurons: 3
 >> iter 71000, loss: 0.251496
 >> iter 72000, loss: 0.165354
 >> iter 73000, loss: 0.228300
 >> iter 74000, loss: 0.330825
 >> iter 75000, loss: 0.265388
 >> iter 76000, loss: 0.279950
 >> iter 77000, loss: 0.268704
 >> iter 78000, loss: 0.232803
 >> iter 79000, loss: 0.165983
 >> iter 80000, loss: 0.180378
   Number of active neurons: 3
 >> iter 81000, loss: 0.267086
 >> iter 82000, loss: 0.131021
 >> iter 83000, loss: 0.156217
 >> iter 84000, loss: 0.107032
 >> iter 85000, loss: 0.162320
 >> iter 86000, loss: 0.252653
 >> iter 87000, loss: 0.310518
 >> iter 88000, loss: 0.366063
 >> iter 89000, loss: 0.332341
 >> iter 90000, loss: 0.244206
   Number of active neurons: 3
 >> iter 91000, loss: 0.399229
 >> iter 92000, loss: 0.330596
 >> iter 93000, loss: 0.284214
 >> iter 94000, loss: 0.331769
 >> iter 95000, loss: 0.312802
 >> iter 96000, loss: 0.219372
 >> iter 97000, loss: 0.229192
 >> iter 98000, loss: 0.182255
 >> iter 99000, loss: 0.140487
 >> iter 100000, loss: 0.217476
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.066556
 >> iter 2000, loss: 9.903095
 >> iter 3000, loss: 4.999488
 >> iter 4000, loss: 2.561044
 >> iter 5000, loss: 1.593691
 >> iter 6000, loss: 1.311503
 >> iter 7000, loss: 0.959748
 >> iter 8000, loss: 0.863838
 >> iter 9000, loss: 0.729011
 >> iter 10000, loss: 0.539049
   Number of active neurons: 5
 >> iter 11000, loss: 0.637921
 >> iter 12000, loss: 0.603764
 >> iter 13000, loss: 0.564052
 >> iter 14000, loss: 0.731536
 >> iter 15000, loss: 0.743748
 >> iter 16000, loss: 0.439008
 >> iter 17000, loss: 0.430822
 >> iter 18000, loss: 0.528614
 >> iter 19000, loss: 0.601997
 >> iter 20000, loss: 0.670203
   Number of active neurons: 5
 >> iter 21000, loss: 0.668277
 >> iter 22000, loss: 0.530937
 >> iter 23000, loss: 0.529900
 >> iter 24000, loss: 0.329712
 >> iter 25000, loss: 0.427364
 >> iter 26000, loss: 0.515369
 >> iter 27000, loss: 0.428509
 >> iter 28000, loss: 0.424828
 >> iter 29000, loss: 0.610799
 >> iter 30000, loss: 0.477983
   Number of active neurons: 3
 >> iter 31000, loss: 0.331998
 >> iter 32000, loss: 0.525991
 >> iter 33000, loss: 0.381121
 >> iter 34000, loss: 0.735540
 >> iter 35000, loss: 0.503630
 >> iter 36000, loss: 0.381342
 >> iter 37000, loss: 0.469217
 >> iter 38000, loss: 0.513252
 >> iter 39000, loss: 0.411176
 >> iter 40000, loss: 0.762603
   Number of active neurons: 3
 >> iter 41000, loss: 0.648911
 >> iter 42000, loss: 0.592557
 >> iter 43000, loss: 0.667954
 >> iter 44000, loss: 0.543329
 >> iter 45000, loss: 0.626335
 >> iter 46000, loss: 0.601874
 >> iter 47000, loss: 0.452029
 >> iter 48000, loss: 0.340774
 >> iter 49000, loss: 0.363501
 >> iter 50000, loss: 0.294594
   Number of active neurons: 3
 >> iter 51000, loss: 0.482459
 >> iter 52000, loss: 0.485586
 >> iter 53000, loss: 0.453672
 >> iter 54000, loss: 0.541213
 >> iter 55000, loss: 0.516124
 >> iter 56000, loss: 0.467563
 >> iter 57000, loss: 0.365116
 >> iter 58000, loss: 0.327597
 >> iter 59000, loss: 0.539566
 >> iter 60000, loss: 0.568134
   Number of active neurons: 3
 >> iter 61000, loss: 0.617854
 >> iter 62000, loss: 0.681024
 >> iter 63000, loss: 0.720222
 >> iter 64000, loss: 0.458811
 >> iter 65000, loss: 0.468343
 >> iter 66000, loss: 0.548691
 >> iter 67000, loss: 0.601781
 >> iter 68000, loss: 0.701109
 >> iter 69000, loss: 0.493986
 >> iter 70000, loss: 0.359936
   Number of active neurons: 3
 >> iter 71000, loss: 0.438569
 >> iter 72000, loss: 0.529808
 >> iter 73000, loss: 0.471317
 >> iter 74000, loss: 0.471204
 >> iter 75000, loss: 0.716375
 >> iter 76000, loss: 0.608622
 >> iter 77000, loss: 0.595722
 >> iter 78000, loss: 0.384483
 >> iter 79000, loss: 0.434088
 >> iter 80000, loss: 0.554880
   Number of active neurons: 3
 >> iter 81000, loss: 0.553622
 >> iter 82000, loss: 0.561754
 >> iter 83000, loss: 0.604592
 >> iter 84000, loss: 0.539708
 >> iter 85000, loss: 0.400997
 >> iter 86000, loss: 0.632151
 >> iter 87000, loss: 0.433230
 >> iter 88000, loss: 0.546441
 >> iter 89000, loss: 0.472303
 >> iter 90000, loss: 0.385861
   Number of active neurons: 3
 >> iter 91000, loss: 0.408200
 >> iter 92000, loss: 0.360721
 >> iter 93000, loss: 0.324017
 >> iter 94000, loss: 0.292723
 >> iter 95000, loss: 0.502749
 >> iter 96000, loss: 0.491557
 >> iter 97000, loss: 0.621162
 >> iter 98000, loss: 0.726987
 >> iter 99000, loss: 0.794657
 >> iter 100000, loss: 0.777531
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.313711
 >> iter 2000, loss: 9.835056
 >> iter 3000, loss: 4.806846
 >> iter 4000, loss: 2.312635
 >> iter 5000, loss: 1.292089
 >> iter 6000, loss: 0.853452
 >> iter 7000, loss: 0.685740
 >> iter 8000, loss: 0.799367
 >> iter 9000, loss: 0.559037
 >> iter 10000, loss: 0.455466
   Number of active neurons: 7
 >> iter 11000, loss: 0.480921
 >> iter 12000, loss: 0.471519
 >> iter 13000, loss: 0.521786
 >> iter 14000, loss: 0.381874
 >> iter 15000, loss: 0.451068
 >> iter 16000, loss: 0.389446
 >> iter 17000, loss: 0.313254
 >> iter 18000, loss: 0.217588
 >> iter 19000, loss: 0.239860
 >> iter 20000, loss: 0.412315
   Number of active neurons: 6
 >> iter 21000, loss: 0.362269
 >> iter 22000, loss: 0.319656
 >> iter 23000, loss: 0.404072
 >> iter 24000, loss: 0.478219
 >> iter 25000, loss: 0.418189
 >> iter 26000, loss: 0.327510
 >> iter 27000, loss: 0.494241
 >> iter 28000, loss: 0.450721
 >> iter 29000, loss: 0.623663
 >> iter 30000, loss: 0.523586
   Number of active neurons: 5
 >> iter 31000, loss: 0.297646
 >> iter 32000, loss: 0.406437
 >> iter 33000, loss: 0.351217
 >> iter 34000, loss: 0.228110
 >> iter 35000, loss: 0.256846
 >> iter 36000, loss: 0.428548
 >> iter 37000, loss: 0.542478
 >> iter 38000, loss: 0.422121
 >> iter 39000, loss: 0.362974
 >> iter 40000, loss: 0.388319
   Number of active neurons: 4
 >> iter 41000, loss: 0.225237
 >> iter 42000, loss: 0.282034
 >> iter 43000, loss: 0.385478
 >> iter 44000, loss: 0.432014
 >> iter 45000, loss: 0.396739
 >> iter 46000, loss: 0.310504
 >> iter 47000, loss: 0.195656
 >> iter 48000, loss: 0.259544
 >> iter 49000, loss: 0.256770
 >> iter 50000, loss: 0.404298
   Number of active neurons: 4
 >> iter 51000, loss: 0.332237
 >> iter 52000, loss: 0.209382
 >> iter 53000, loss: 0.196793
 >> iter 54000, loss: 0.345921
 >> iter 55000, loss: 0.301655
 >> iter 56000, loss: 0.304100
 >> iter 57000, loss: 0.218914
 >> iter 58000, loss: 0.377480
 >> iter 59000, loss: 0.485335
 >> iter 60000, loss: 0.253071
   Number of active neurons: 4
 >> iter 61000, loss: 0.179493
 >> iter 62000, loss: 0.367888
 >> iter 63000, loss: 0.314285
 >> iter 64000, loss: 0.203188
 >> iter 65000, loss: 0.217096
 >> iter 66000, loss: 0.189738
 >> iter 67000, loss: 0.254678
 >> iter 68000, loss: 0.245420
 >> iter 69000, loss: 0.207755
 >> iter 70000, loss: 0.122450
   Number of active neurons: 4
 >> iter 71000, loss: 0.274548
 >> iter 72000, loss: 0.269079
 >> iter 73000, loss: 0.236081
 >> iter 74000, loss: 0.341811
 >> iter 75000, loss: 0.266646
 >> iter 76000, loss: 0.130128
 >> iter 77000, loss: 0.241696
 >> iter 78000, loss: 0.247408
 >> iter 79000, loss: 0.194494
 >> iter 80000, loss: 0.273227
   Number of active neurons: 4
 >> iter 81000, loss: 0.287677
 >> iter 82000, loss: 0.274165
 >> iter 83000, loss: 0.221316
 >> iter 84000, loss: 0.212847
 >> iter 85000, loss: 0.253663
 >> iter 86000, loss: 0.228796
 >> iter 87000, loss: 0.163227
 >> iter 88000, loss: 0.290547
 >> iter 89000, loss: 0.159103
 >> iter 90000, loss: 0.119271
   Number of active neurons: 4
 >> iter 91000, loss: 0.120887
 >> iter 92000, loss: 0.480244
 >> iter 93000, loss: 0.285697
 >> iter 94000, loss: 0.180908
 >> iter 95000, loss: 0.150365
 >> iter 96000, loss: 0.267178
 >> iter 97000, loss: 0.148192
 >> iter 98000, loss: 0.224649
 >> iter 99000, loss: 0.485522
 >> iter 100000, loss: 0.391698
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.224443
 >> iter 2000, loss: 10.297805
 >> iter 3000, loss: 4.827116
 >> iter 4000, loss: 2.354498
 >> iter 5000, loss: 1.238744
 >> iter 6000, loss: 0.753132
 >> iter 7000, loss: 0.433757
 >> iter 8000, loss: 0.424218
 >> iter 9000, loss: 0.330864
 >> iter 10000, loss: 0.309320
   Number of active neurons: 6
 >> iter 11000, loss: 0.298931
 >> iter 12000, loss: 0.303332
 >> iter 13000, loss: 0.377432
 >> iter 14000, loss: 0.237782
 >> iter 15000, loss: 0.430037
 >> iter 16000, loss: 0.278866
 >> iter 17000, loss: 0.358159
 >> iter 18000, loss: 0.275449
 >> iter 19000, loss: 0.294406
 >> iter 20000, loss: 0.434897
   Number of active neurons: 5
 >> iter 21000, loss: 0.317595
 >> iter 22000, loss: 0.284224
 >> iter 23000, loss: 0.257880
 >> iter 24000, loss: 0.232706
 >> iter 25000, loss: 0.304848
 >> iter 26000, loss: 0.282668
 >> iter 27000, loss: 0.229128
 >> iter 28000, loss: 0.148913
 >> iter 29000, loss: 0.307910
 >> iter 30000, loss: 0.241879
   Number of active neurons: 5
 >> iter 31000, loss: 0.305031
 >> iter 32000, loss: 0.313698
 >> iter 33000, loss: 0.293199
 >> iter 34000, loss: 0.313548
 >> iter 35000, loss: 0.271807
 >> iter 36000, loss: 0.239604
 >> iter 37000, loss: 0.401680
 >> iter 38000, loss: 0.186579
 >> iter 39000, loss: 0.198649
 >> iter 40000, loss: 0.272397
   Number of active neurons: 3
 >> iter 41000, loss: 0.318772
 >> iter 42000, loss: 0.242890
 >> iter 43000, loss: 0.212774
 >> iter 44000, loss: 0.215905
 >> iter 45000, loss: 0.210456
 >> iter 46000, loss: 0.166994
 >> iter 47000, loss: 0.206168
 >> iter 48000, loss: 0.112280
 >> iter 49000, loss: 0.216042
 >> iter 50000, loss: 0.259374
   Number of active neurons: 3
 >> iter 51000, loss: 0.192381
 >> iter 52000, loss: 0.283013
 >> iter 53000, loss: 0.501969
 >> iter 54000, loss: 0.248924
 >> iter 55000, loss: 0.243717
 >> iter 56000, loss: 0.395603
 >> iter 57000, loss: 0.189425
 >> iter 58000, loss: 0.445918
 >> iter 59000, loss: 0.331146
 >> iter 60000, loss: 0.313664
   Number of active neurons: 3
 >> iter 61000, loss: 0.213643
 >> iter 62000, loss: 0.292487
 >> iter 63000, loss: 0.316382
 >> iter 64000, loss: 0.367464
 >> iter 65000, loss: 0.195825
 >> iter 66000, loss: 0.158868
 >> iter 67000, loss: 0.233082
 >> iter 68000, loss: 0.195859
 >> iter 69000, loss: 0.180159
 >> iter 70000, loss: 0.281062
   Number of active neurons: 3
 >> iter 71000, loss: 0.199437
 >> iter 72000, loss: 0.109024
 >> iter 73000, loss: 0.189318
 >> iter 74000, loss: 0.100177
 >> iter 75000, loss: 0.151749
 >> iter 76000, loss: 0.409248
 >> iter 77000, loss: 0.347723
 >> iter 78000, loss: 0.343592
 >> iter 79000, loss: 0.414805
 >> iter 80000, loss: 0.223026
   Number of active neurons: 3
 >> iter 81000, loss: 0.333107
 >> iter 82000, loss: 0.242433
 >> iter 83000, loss: 0.235683
 >> iter 84000, loss: 0.231282
 >> iter 85000, loss: 0.274995
 >> iter 86000, loss: 0.415873
 >> iter 87000, loss: 0.441617
 >> iter 88000, loss: 0.289080
 >> iter 89000, loss: 0.255673
 >> iter 90000, loss: 0.254049
   Number of active neurons: 3
 >> iter 91000, loss: 0.154494
 >> iter 92000, loss: 0.209385
 >> iter 93000, loss: 0.282801
 >> iter 94000, loss: 0.312368
 >> iter 95000, loss: 0.153475
 >> iter 96000, loss: 0.114621
 >> iter 97000, loss: 0.325800
 >> iter 98000, loss: 0.332852
 >> iter 99000, loss: 0.180280
 >> iter 100000, loss: 0.183870
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 17.612805
 >> iter 2000, loss: 8.904089
 >> iter 3000, loss: 4.231196
 >> iter 4000, loss: 2.097776
 >> iter 5000, loss: 1.017678
 >> iter 6000, loss: 0.615457
 >> iter 7000, loss: 0.512485
 >> iter 8000, loss: 0.622184
 >> iter 9000, loss: 0.384032
 >> iter 10000, loss: 0.448437
   Number of active neurons: 5
 >> iter 11000, loss: 0.269581
 >> iter 12000, loss: 0.355984
 >> iter 13000, loss: 0.400713
 >> iter 14000, loss: 0.381860
 >> iter 15000, loss: 0.321144
 >> iter 16000, loss: 0.192931
 >> iter 17000, loss: 0.369829
 >> iter 18000, loss: 0.428401
 >> iter 19000, loss: 0.319668
 >> iter 20000, loss: 0.335233
   Number of active neurons: 5
 >> iter 21000, loss: 0.239740
 >> iter 22000, loss: 0.293706
 >> iter 23000, loss: 0.515730
 >> iter 24000, loss: 0.306522
 >> iter 25000, loss: 0.328442
 >> iter 26000, loss: 0.325778
 >> iter 27000, loss: 0.727783
 >> iter 28000, loss: 0.415703
 >> iter 29000, loss: 0.277464
 >> iter 30000, loss: 0.343685
   Number of active neurons: 5
 >> iter 31000, loss: 0.313622
 >> iter 32000, loss: 0.441534
 >> iter 33000, loss: 0.337373
 >> iter 34000, loss: 0.215544
 >> iter 35000, loss: 0.321226
 >> iter 36000, loss: 0.250029
 >> iter 37000, loss: 0.256677
 >> iter 38000, loss: 0.267499
 >> iter 39000, loss: 0.222143
 >> iter 40000, loss: 0.330809
   Number of active neurons: 4
 >> iter 41000, loss: 0.531406
 >> iter 42000, loss: 0.324187
 >> iter 43000, loss: 0.377355
 >> iter 44000, loss: 0.311581
 >> iter 45000, loss: 0.278765
 >> iter 46000, loss: 0.517995
 >> iter 47000, loss: 0.366279
 >> iter 48000, loss: 0.303519
 >> iter 49000, loss: 0.240051
 >> iter 50000, loss: 0.411314
   Number of active neurons: 3
 >> iter 51000, loss: 0.251004
 >> iter 52000, loss: 0.401095
 >> iter 53000, loss: 0.330585
 >> iter 54000, loss: 0.264329
 >> iter 55000, loss: 0.252636
 >> iter 56000, loss: 0.184513
 >> iter 57000, loss: 0.146311
 >> iter 58000, loss: 0.212353
 >> iter 59000, loss: 0.294675
 >> iter 60000, loss: 0.289736
   Number of active neurons: 3
 >> iter 61000, loss: 0.251091
 >> iter 62000, loss: 0.229448
 >> iter 63000, loss: 0.156187
 >> iter 64000, loss: 0.327482
 >> iter 65000, loss: 0.383750
 >> iter 66000, loss: 0.417965
 >> iter 67000, loss: 0.478903
 >> iter 68000, loss: 0.306767
 >> iter 69000, loss: 0.201109
 >> iter 70000, loss: 0.291474
   Number of active neurons: 3
 >> iter 71000, loss: 0.320663
 >> iter 72000, loss: 0.199951
 >> iter 73000, loss: 0.126436
 >> iter 74000, loss: 0.240872
 >> iter 75000, loss: 0.271473
 >> iter 76000, loss: 0.172205
 >> iter 77000, loss: 0.258365
 >> iter 78000, loss: 0.225545
 >> iter 79000, loss: 0.224684
 >> iter 80000, loss: 0.280400
   Number of active neurons: 3
 >> iter 81000, loss: 0.268372
 >> iter 82000, loss: 0.217527
 >> iter 83000, loss: 0.197758
 >> iter 84000, loss: 0.188495
 >> iter 85000, loss: 0.279767
 >> iter 86000, loss: 0.423407
 >> iter 87000, loss: 0.298866
 >> iter 88000, loss: 0.430555
 >> iter 89000, loss: 0.381038
 >> iter 90000, loss: 0.278678
   Number of active neurons: 3
 >> iter 91000, loss: 0.308889
 >> iter 92000, loss: 0.232179
 >> iter 93000, loss: 0.252371
 >> iter 94000, loss: 0.183425
 >> iter 95000, loss: 0.189701
 >> iter 96000, loss: 0.140648
 >> iter 97000, loss: 0.195241
 >> iter 98000, loss: 0.400616
 >> iter 99000, loss: 0.234554
 >> iter 100000, loss: 0.172374
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.315343
 >> iter 2000, loss: 9.183057
 >> iter 3000, loss: 4.285594
 >> iter 4000, loss: 2.069572
 >> iter 5000, loss: 1.097130
 >> iter 6000, loss: 0.617561
 >> iter 7000, loss: 0.303816
 >> iter 8000, loss: 0.570011
 >> iter 9000, loss: 0.597689
 >> iter 10000, loss: 0.623460
   Number of active neurons: 8
 >> iter 11000, loss: 0.572963
 >> iter 12000, loss: 0.436094
 >> iter 13000, loss: 0.343782
 >> iter 14000, loss: 0.442911
 >> iter 15000, loss: 0.271513
 >> iter 16000, loss: 0.533243
 >> iter 17000, loss: 0.459288
 >> iter 18000, loss: 0.357555
 >> iter 19000, loss: 0.459113
 >> iter 20000, loss: 0.369512
   Number of active neurons: 8
 >> iter 21000, loss: 0.264521
 >> iter 22000, loss: 0.207697
 >> iter 23000, loss: 0.350754
 >> iter 24000, loss: 0.402807
 >> iter 25000, loss: 0.271445
 >> iter 26000, loss: 0.366811
 >> iter 27000, loss: 0.366240
 >> iter 28000, loss: 0.444323
 >> iter 29000, loss: 0.369051
 >> iter 30000, loss: 0.365170
   Number of active neurons: 5
 >> iter 31000, loss: 0.321711
 >> iter 32000, loss: 0.443696
 >> iter 33000, loss: 0.369276
 >> iter 34000, loss: 0.377604
 >> iter 35000, loss: 0.312055
 >> iter 36000, loss: 0.339314
 >> iter 37000, loss: 0.218089
 >> iter 38000, loss: 0.266727
 >> iter 39000, loss: 0.261739
 >> iter 40000, loss: 0.451598
   Number of active neurons: 4
 >> iter 41000, loss: 0.233519
 >> iter 42000, loss: 0.336341
 >> iter 43000, loss: 0.334415
 >> iter 44000, loss: 0.219487
 >> iter 45000, loss: 0.303046
 >> iter 46000, loss: 0.182331
 >> iter 47000, loss: 0.168592
 >> iter 48000, loss: 0.170887
 >> iter 49000, loss: 0.276832
 >> iter 50000, loss: 0.261322
   Number of active neurons: 3
 >> iter 51000, loss: 0.203417
 >> iter 52000, loss: 0.126989
 >> iter 53000, loss: 0.292196
 >> iter 54000, loss: 0.396580
 >> iter 55000, loss: 0.224114
 >> iter 56000, loss: 0.260535
 >> iter 57000, loss: 0.274431
 >> iter 58000, loss: 0.232761
 >> iter 59000, loss: 0.187777
 >> iter 60000, loss: 0.141951
   Number of active neurons: 3
 >> iter 61000, loss: 0.304039
 >> iter 62000, loss: 0.343107
 >> iter 63000, loss: 0.315144
 >> iter 64000, loss: 0.250002
 >> iter 65000, loss: 0.331306
 >> iter 66000, loss: 0.271706
 >> iter 67000, loss: 0.215421
 >> iter 68000, loss: 0.267155
 >> iter 69000, loss: 0.158071
 >> iter 70000, loss: 0.218344
   Number of active neurons: 3
 >> iter 71000, loss: 0.146498
 >> iter 72000, loss: 0.152645
 >> iter 73000, loss: 0.243031
 >> iter 74000, loss: 0.221390
 >> iter 75000, loss: 0.250742
 >> iter 76000, loss: 0.261256
 >> iter 77000, loss: 0.436814
 >> iter 78000, loss: 0.292349
 >> iter 79000, loss: 0.171967
 >> iter 80000, loss: 0.230463
   Number of active neurons: 3
 >> iter 81000, loss: 0.284063
 >> iter 82000, loss: 0.266067
 >> iter 83000, loss: 0.175366
 >> iter 84000, loss: 0.213078
 >> iter 85000, loss: 0.208246
 >> iter 86000, loss: 0.204467
 >> iter 87000, loss: 0.173288
 >> iter 88000, loss: 0.193891
 >> iter 89000, loss: 0.289030
 >> iter 90000, loss: 0.205212
   Number of active neurons: 3
 >> iter 91000, loss: 0.150390
 >> iter 92000, loss: 0.187813
 >> iter 93000, loss: 0.356658
 >> iter 94000, loss: 0.206274
 >> iter 95000, loss: 0.290106
 >> iter 96000, loss: 0.360743
 >> iter 97000, loss: 0.287061
 >> iter 98000, loss: 0.197765
 >> iter 99000, loss: 0.185839
 >> iter 100000, loss: 0.245030
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.454607
 >> iter 2000, loss: 10.584783
 >> iter 3000, loss: 5.100838
 >> iter 4000, loss: 2.445250
 >> iter 5000, loss: 1.474227
 >> iter 6000, loss: 0.887114
 >> iter 7000, loss: 0.712703
 >> iter 8000, loss: 0.725610
 >> iter 9000, loss: 0.822587
 >> iter 10000, loss: 0.569622
   Number of active neurons: 8
 >> iter 11000, loss: 0.530441
 >> iter 12000, loss: 0.537023
 >> iter 13000, loss: 0.520205
 >> iter 14000, loss: 0.398081
 >> iter 15000, loss: 0.445741
 >> iter 16000, loss: 0.392387
 >> iter 17000, loss: 0.487374
 >> iter 18000, loss: 0.476550
 >> iter 19000, loss: 0.527477
 >> iter 20000, loss: 0.344764
   Number of active neurons: 8
 >> iter 21000, loss: 0.607909
 >> iter 22000, loss: 0.625456
 >> iter 23000, loss: 0.373746
 >> iter 24000, loss: 0.661650
 >> iter 25000, loss: 0.631939
 >> iter 26000, loss: 0.581798
 >> iter 27000, loss: 0.459855
 >> iter 28000, loss: 0.288773
 >> iter 29000, loss: 0.516375
 >> iter 30000, loss: 0.667480
   Number of active neurons: 9
 >> iter 31000, loss: 0.862595
 >> iter 32000, loss: 0.562890
 >> iter 33000, loss: 0.569534
 >> iter 34000, loss: 0.681219
 >> iter 35000, loss: 0.495984
 >> iter 36000, loss: 0.483347
 >> iter 37000, loss: 0.417752
 >> iter 38000, loss: 0.272030
 >> iter 39000, loss: 0.329074
 >> iter 40000, loss: 0.580785
   Number of active neurons: 9
 >> iter 41000, loss: 0.491207
 >> iter 42000, loss: 0.720534
 >> iter 43000, loss: 0.762522
 >> iter 44000, loss: 0.622053
 >> iter 45000, loss: 0.713836
 >> iter 46000, loss: 0.569213
 >> iter 47000, loss: 0.707401
 >> iter 48000, loss: 0.534762
 >> iter 49000, loss: 0.431844
 >> iter 50000, loss: 0.674389
   Number of active neurons: 9
 >> iter 51000, loss: 0.686298
 >> iter 52000, loss: 0.454493
 >> iter 53000, loss: 0.630656
 >> iter 54000, loss: 0.424370
 >> iter 55000, loss: 0.494080
 >> iter 56000, loss: 0.590005
 >> iter 57000, loss: 0.466109
 >> iter 58000, loss: 0.495295
 >> iter 59000, loss: 0.600927
 >> iter 60000, loss: 0.584942
   Number of active neurons: 9
 >> iter 61000, loss: 0.367561
 >> iter 62000, loss: 0.260808
 >> iter 63000, loss: 0.526181
 >> iter 64000, loss: 0.453577
 >> iter 65000, loss: 0.708563
 >> iter 66000, loss: 0.567886
 >> iter 67000, loss: 0.338582
 >> iter 68000, loss: 0.452038
 >> iter 69000, loss: 0.433342
 >> iter 70000, loss: 0.576942
   Number of active neurons: 10
 >> iter 71000, loss: 0.396406
 >> iter 72000, loss: 0.345405
 >> iter 73000, loss: 0.239725
 >> iter 74000, loss: 0.470823
 >> iter 75000, loss: 0.412672
 >> iter 76000, loss: 0.328471
 >> iter 77000, loss: 0.270644
 >> iter 78000, loss: 0.332914
 >> iter 79000, loss: 0.341194
 >> iter 80000, loss: 0.539726
   Number of active neurons: 6
 >> iter 81000, loss: 0.373686
 >> iter 82000, loss: 0.367795
 >> iter 83000, loss: 0.360913
 >> iter 84000, loss: 0.248325
 >> iter 85000, loss: 0.303193
 >> iter 86000, loss: 0.421326
 >> iter 87000, loss: 0.445116
 >> iter 88000, loss: 0.358554
 >> iter 89000, loss: 0.264272
 >> iter 90000, loss: 0.275948
   Number of active neurons: 8
 >> iter 91000, loss: 0.303994
 >> iter 92000, loss: 0.401222
 >> iter 93000, loss: 0.643495
 >> iter 94000, loss: 0.662728
 >> iter 95000, loss: 0.423473
 >> iter 96000, loss: 0.434246
 >> iter 97000, loss: 0.419373
 >> iter 98000, loss: 0.314103
 >> iter 99000, loss: 0.361133
 >> iter 100000, loss: 0.246794
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.713546
 >> iter 2000, loss: 8.714524
 >> iter 3000, loss: 3.746503
 >> iter 4000, loss: 1.925064
 >> iter 5000, loss: 1.015561
 >> iter 6000, loss: 0.538331
 >> iter 7000, loss: 0.668980
 >> iter 8000, loss: 0.393839
 >> iter 9000, loss: 0.456510
 >> iter 10000, loss: 0.448025
   Number of active neurons: 5
 >> iter 11000, loss: 0.302934
 >> iter 12000, loss: 0.328557
 >> iter 13000, loss: 0.227705
 >> iter 14000, loss: 0.224229
 >> iter 15000, loss: 0.310965
 >> iter 16000, loss: 0.284280
 >> iter 17000, loss: 0.227896
 >> iter 18000, loss: 0.517219
 >> iter 19000, loss: 0.409176
 >> iter 20000, loss: 0.324112
   Number of active neurons: 5
 >> iter 21000, loss: 0.430074
 >> iter 22000, loss: 0.290346
 >> iter 23000, loss: 0.459440
 >> iter 24000, loss: 0.367206
 >> iter 25000, loss: 0.405556
 >> iter 26000, loss: 0.470749
 >> iter 27000, loss: 0.259039
 >> iter 28000, loss: 0.563560
 >> iter 29000, loss: 0.356741
 >> iter 30000, loss: 0.355353
   Number of active neurons: 5
 >> iter 31000, loss: 0.401827
 >> iter 32000, loss: 0.333479
 >> iter 33000, loss: 0.407777
 >> iter 34000, loss: 0.376212
 >> iter 35000, loss: 0.417799
 >> iter 36000, loss: 0.369561
 >> iter 37000, loss: 0.318741
 >> iter 38000, loss: 0.318921
 >> iter 39000, loss: 0.252230
 >> iter 40000, loss: 0.440881
   Number of active neurons: 4
 >> iter 41000, loss: 0.486112
 >> iter 42000, loss: 0.397242
 >> iter 43000, loss: 0.496461
 >> iter 44000, loss: 0.400154
 >> iter 45000, loss: 0.317528
 >> iter 46000, loss: 0.344099
 >> iter 47000, loss: 0.213686
 >> iter 48000, loss: 0.187552
 >> iter 49000, loss: 0.253240
 >> iter 50000, loss: 0.287398
   Number of active neurons: 4
 >> iter 51000, loss: 0.302256
 >> iter 52000, loss: 0.373124
 >> iter 53000, loss: 0.365981
 >> iter 54000, loss: 0.380084
 >> iter 55000, loss: 0.348888
 >> iter 56000, loss: 0.253927
 >> iter 57000, loss: 0.245366
 >> iter 58000, loss: 0.225641
 >> iter 59000, loss: 0.233661
 >> iter 60000, loss: 0.520550
   Number of active neurons: 4
 >> iter 61000, loss: 0.409516
 >> iter 62000, loss: 0.436659
 >> iter 63000, loss: 0.422672
 >> iter 64000, loss: 0.459726
 >> iter 65000, loss: 0.264743
 >> iter 66000, loss: 0.239341
 >> iter 67000, loss: 0.273010
 >> iter 68000, loss: 0.652666
 >> iter 69000, loss: 0.313177
 >> iter 70000, loss: 0.435201
   Number of active neurons: 3
 >> iter 71000, loss: 0.302729
 >> iter 72000, loss: 0.313630
 >> iter 73000, loss: 0.417680
 >> iter 74000, loss: 0.281276
 >> iter 75000, loss: 0.269771
 >> iter 76000, loss: 0.373280
 >> iter 77000, loss: 0.271565
 >> iter 78000, loss: 0.171386
 >> iter 79000, loss: 0.383621
 >> iter 80000, loss: 0.353732
   Number of active neurons: 3
 >> iter 81000, loss: 0.167015
 >> iter 82000, loss: 0.269235
 >> iter 83000, loss: 0.291142
 >> iter 84000, loss: 0.288688
 >> iter 85000, loss: 0.188932
 >> iter 86000, loss: 0.291943
 >> iter 87000, loss: 0.247028
 >> iter 88000, loss: 0.338317
 >> iter 89000, loss: 0.296997
 >> iter 90000, loss: 0.258562
   Number of active neurons: 3
 >> iter 91000, loss: 0.313734
 >> iter 92000, loss: 0.245959
 >> iter 93000, loss: 0.273083
 >> iter 94000, loss: 0.262919
 >> iter 95000, loss: 0.156763
 >> iter 96000, loss: 0.210908
 >> iter 97000, loss: 0.146718
 >> iter 98000, loss: 0.220999
 >> iter 99000, loss: 0.225602
 >> iter 100000, loss: 0.259769
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.346397
 >> iter 2000, loss: 10.026906
 >> iter 3000, loss: 4.473052
 >> iter 4000, loss: 2.107817
 >> iter 5000, loss: 1.019353
 >> iter 6000, loss: 0.717222
 >> iter 7000, loss: 0.506688
 >> iter 8000, loss: 0.524078
 >> iter 9000, loss: 0.666843
 >> iter 10000, loss: 0.310397
   Number of active neurons: 4
 >> iter 11000, loss: 0.420825
 >> iter 12000, loss: 0.291133
 >> iter 13000, loss: 0.274511
 >> iter 14000, loss: 0.211669
 >> iter 15000, loss: 0.227490
 >> iter 16000, loss: 0.207132
 >> iter 17000, loss: 0.239748
 >> iter 18000, loss: 0.381650
 >> iter 19000, loss: 0.445266
 >> iter 20000, loss: 0.441760
   Number of active neurons: 4
 >> iter 21000, loss: 0.420616
 >> iter 22000, loss: 0.305792
 >> iter 23000, loss: 0.673774
 >> iter 24000, loss: 0.300687
 >> iter 25000, loss: 0.240094
 >> iter 26000, loss: 0.331321
 >> iter 27000, loss: 0.331368
 >> iter 28000, loss: 0.538924
 >> iter 29000, loss: 0.468188
 >> iter 30000, loss: 0.442102
   Number of active neurons: 4
 >> iter 31000, loss: 0.273891
 >> iter 32000, loss: 0.233351
 >> iter 33000, loss: 0.280115
 >> iter 34000, loss: 0.435759
 >> iter 35000, loss: 0.592111
 >> iter 36000, loss: 0.329845
 >> iter 37000, loss: 0.383888
 >> iter 38000, loss: 0.439910
 >> iter 39000, loss: 0.237971
 >> iter 40000, loss: 0.226157
   Number of active neurons: 4
 >> iter 41000, loss: 0.186983
 >> iter 42000, loss: 0.281263
 >> iter 43000, loss: 0.353318
 >> iter 44000, loss: 0.201180
 >> iter 45000, loss: 0.113109
 >> iter 46000, loss: 0.182945
 >> iter 47000, loss: 0.201670
 >> iter 48000, loss: 0.126799
 >> iter 49000, loss: 0.354641
 >> iter 50000, loss: 0.286711
   Number of active neurons: 4
 >> iter 51000, loss: 0.302872
 >> iter 52000, loss: 0.378414
 >> iter 53000, loss: 0.276815
 >> iter 54000, loss: 0.215731
 >> iter 55000, loss: 0.138880
 >> iter 56000, loss: 0.272353
 >> iter 57000, loss: 0.319284
 >> iter 58000, loss: 0.246099
 >> iter 59000, loss: 0.389727
 >> iter 60000, loss: 0.300752
   Number of active neurons: 4
 >> iter 61000, loss: 0.375221
 >> iter 62000, loss: 0.306547
 >> iter 63000, loss: 0.185676
 >> iter 64000, loss: 0.324212
 >> iter 65000, loss: 0.154409
 >> iter 66000, loss: 0.193057
 >> iter 67000, loss: 0.261086
 >> iter 68000, loss: 0.174309
 >> iter 69000, loss: 0.214219
 >> iter 70000, loss: 0.427971
   Number of active neurons: 3
 >> iter 71000, loss: 0.526514
 >> iter 72000, loss: 0.374804
 >> iter 73000, loss: 0.265540
 >> iter 74000, loss: 0.351177
 >> iter 75000, loss: 0.230300
 >> iter 76000, loss: 0.329176
 >> iter 77000, loss: 0.184340
 >> iter 78000, loss: 0.256101
 >> iter 79000, loss: 0.239353
 >> iter 80000, loss: 0.156530
   Number of active neurons: 3
 >> iter 81000, loss: 0.241337
 >> iter 82000, loss: 0.193667
 >> iter 83000, loss: 0.328551
 >> iter 84000, loss: 0.199922
 >> iter 85000, loss: 0.183659
 >> iter 86000, loss: 0.257536
 >> iter 87000, loss: 0.251081
 >> iter 88000, loss: 0.144747
 >> iter 89000, loss: 0.306412
 >> iter 90000, loss: 0.176727
   Number of active neurons: 3
 >> iter 91000, loss: 0.090807
 >> iter 92000, loss: 0.197249
 >> iter 93000, loss: 0.161641
 >> iter 94000, loss: 0.118812
 >> iter 95000, loss: 0.110861
 >> iter 96000, loss: 0.364994
 >> iter 97000, loss: 0.260063
 >> iter 98000, loss: 0.281461
 >> iter 99000, loss: 0.273487
 >> iter 100000, loss: 0.282624
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 20.524753
 >> iter 2000, loss: 17.595461
 >> iter 3000, loss: 13.169261
 >> iter 4000, loss: 7.734757
 >> iter 5000, loss: 3.865126
 >> iter 6000, loss: 2.019488
 >> iter 7000, loss: 1.516404
 >> iter 8000, loss: 1.316954
 >> iter 9000, loss: 0.754391
 >> iter 10000, loss: 0.676256
   Number of active neurons: 5
 >> iter 11000, loss: 0.731068
 >> iter 12000, loss: 0.706650
 >> iter 13000, loss: 0.489282
 >> iter 14000, loss: 0.486743
 >> iter 15000, loss: 0.403804
 >> iter 16000, loss: 0.494273
 >> iter 17000, loss: 0.660970
 >> iter 18000, loss: 0.532299
 >> iter 19000, loss: 0.622209
 >> iter 20000, loss: 0.568748
   Number of active neurons: 8
 >> iter 21000, loss: 0.460395
 >> iter 22000, loss: 0.544791
 >> iter 23000, loss: 0.503965
 >> iter 24000, loss: 0.573443
 >> iter 25000, loss: 0.618742
 >> iter 26000, loss: 0.484228
 >> iter 27000, loss: 0.423414
 >> iter 28000, loss: 0.481701
 >> iter 29000, loss: 0.756770
 >> iter 30000, loss: 0.605615
   Number of active neurons: 9
 >> iter 31000, loss: 0.423387
 >> iter 32000, loss: 0.452694
 >> iter 33000, loss: 0.589831
 >> iter 34000, loss: 0.687153
 >> iter 35000, loss: 0.617981
 >> iter 36000, loss: 0.584743
 >> iter 37000, loss: 0.759286
 >> iter 38000, loss: 0.585956
 >> iter 39000, loss: 0.409364
 >> iter 40000, loss: 0.351497
   Number of active neurons: 10
 >> iter 41000, loss: 0.498564
 >> iter 42000, loss: 0.411684
 >> iter 43000, loss: 0.539345
 >> iter 44000, loss: 0.458967
 >> iter 45000, loss: 0.523512
 >> iter 46000, loss: 0.454131
 >> iter 47000, loss: 0.599026
 >> iter 48000, loss: 0.494282
 >> iter 49000, loss: 0.560460
 >> iter 50000, loss: 0.670004
   Number of active neurons: 10
 >> iter 51000, loss: 0.515059
 >> iter 52000, loss: 0.559634
 >> iter 53000, loss: 0.567450
 >> iter 54000, loss: 0.309712
 >> iter 55000, loss: 0.467458
 >> iter 56000, loss: 0.296837
 >> iter 57000, loss: 0.506651
 >> iter 58000, loss: 0.574271
 >> iter 59000, loss: 0.561700
 >> iter 60000, loss: 0.481946
   Number of active neurons: 10
 >> iter 61000, loss: 0.309725
 >> iter 62000, loss: 0.342509
 >> iter 63000, loss: 0.259302
 >> iter 64000, loss: 0.444044
 >> iter 65000, loss: 0.368479
 >> iter 66000, loss: 0.288598
 >> iter 67000, loss: 0.468288
 >> iter 68000, loss: 0.483041
 >> iter 69000, loss: 0.371334
 >> iter 70000, loss: 0.389883
   Number of active neurons: 6
 >> iter 71000, loss: 0.457427
 >> iter 72000, loss: 0.635371
 >> iter 73000, loss: 0.467029
 >> iter 74000, loss: 0.278992
 >> iter 75000, loss: 0.335172
 >> iter 76000, loss: 0.377255
 >> iter 77000, loss: 0.417371
 >> iter 78000, loss: 0.605354
 >> iter 79000, loss: 0.378397
 >> iter 80000, loss: 0.577730
   Number of active neurons: 9
 >> iter 81000, loss: 0.302614
 >> iter 82000, loss: 0.367811
 >> iter 83000, loss: 0.297077
 >> iter 84000, loss: 0.392613
 >> iter 85000, loss: 0.404803
 >> iter 86000, loss: 0.289713
 >> iter 87000, loss: 0.414219
 >> iter 88000, loss: 0.399111
 >> iter 89000, loss: 0.256906
 >> iter 90000, loss: 0.257356
   Number of active neurons: 7
 >> iter 91000, loss: 0.249687
 >> iter 92000, loss: 0.509481
 >> iter 93000, loss: 0.471002
 >> iter 94000, loss: 0.447917
 >> iter 95000, loss: 0.230449
 >> iter 96000, loss: 0.393919
 >> iter 97000, loss: 0.423081
 >> iter 98000, loss: 0.446314
 >> iter 99000, loss: 0.285912
 >> iter 100000, loss: 0.372732
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.608524
 >> iter 2000, loss: 8.400602
 >> iter 3000, loss: 3.652361
 >> iter 4000, loss: 1.898609
 >> iter 5000, loss: 1.173187
 >> iter 6000, loss: 0.673184
 >> iter 7000, loss: 0.452033
 >> iter 8000, loss: 0.462720
 >> iter 9000, loss: 0.518697
 >> iter 10000, loss: 0.437969
   Number of active neurons: 4
 >> iter 11000, loss: 0.484755
 >> iter 12000, loss: 0.347264
 >> iter 13000, loss: 0.413015
 >> iter 14000, loss: 0.386863
 >> iter 15000, loss: 0.390246
 >> iter 16000, loss: 0.200086
 >> iter 17000, loss: 0.288474
 >> iter 18000, loss: 0.315953
 >> iter 19000, loss: 0.556978
 >> iter 20000, loss: 0.377975
   Number of active neurons: 4
 >> iter 21000, loss: 0.383494
 >> iter 22000, loss: 0.366207
 >> iter 23000, loss: 0.462300
 >> iter 24000, loss: 0.297752
 >> iter 25000, loss: 0.258715
 >> iter 26000, loss: 0.181159
 >> iter 27000, loss: 0.233728
 >> iter 28000, loss: 0.398033
 >> iter 29000, loss: 0.325091
 >> iter 30000, loss: 0.296885
   Number of active neurons: 3
 >> iter 31000, loss: 0.279881
 >> iter 32000, loss: 0.313150
 >> iter 33000, loss: 0.360386
 >> iter 34000, loss: 0.164581
 >> iter 35000, loss: 0.164001
 >> iter 36000, loss: 0.268880
 >> iter 37000, loss: 0.232744
 >> iter 38000, loss: 0.157446
 >> iter 39000, loss: 0.353136
 >> iter 40000, loss: 0.251756
   Number of active neurons: 3
 >> iter 41000, loss: 0.260607
 >> iter 42000, loss: 0.196541
 >> iter 43000, loss: 0.116289
 >> iter 44000, loss: 0.176684
 >> iter 45000, loss: 0.414523
 >> iter 46000, loss: 0.239379
 >> iter 47000, loss: 0.224924
 >> iter 48000, loss: 0.205043
 >> iter 49000, loss: 0.293025
 >> iter 50000, loss: 0.218563
   Number of active neurons: 3
 >> iter 51000, loss: 0.268398
 >> iter 52000, loss: 0.258663
 >> iter 53000, loss: 0.361144
 >> iter 54000, loss: 0.260998
 >> iter 55000, loss: 0.241213
 >> iter 56000, loss: 0.464616
 >> iter 57000, loss: 0.294765
 >> iter 58000, loss: 0.346528
 >> iter 59000, loss: 0.234403
 >> iter 60000, loss: 0.288188
   Number of active neurons: 3
 >> iter 61000, loss: 0.214084
 >> iter 62000, loss: 0.143498
 >> iter 63000, loss: 0.191570
 >> iter 64000, loss: 0.203976
 >> iter 65000, loss: 0.298968
 >> iter 66000, loss: 0.195305
 >> iter 67000, loss: 0.176998
 >> iter 68000, loss: 0.168622
 >> iter 69000, loss: 0.260847
 >> iter 70000, loss: 0.317665
   Number of active neurons: 3
 >> iter 71000, loss: 0.262045
 >> iter 72000, loss: 0.206554
 >> iter 73000, loss: 0.226586
 >> iter 74000, loss: 0.334133
 >> iter 75000, loss: 0.210639
 >> iter 76000, loss: 0.185160
 >> iter 77000, loss: 0.216948
 >> iter 78000, loss: 0.325532
 >> iter 79000, loss: 0.320680
 >> iter 80000, loss: 0.409923
   Number of active neurons: 3
 >> iter 81000, loss: 0.274446
 >> iter 82000, loss: 0.184476
 >> iter 83000, loss: 0.230892
 >> iter 84000, loss: 0.278263
 >> iter 85000, loss: 0.235591
 >> iter 86000, loss: 0.204900
 >> iter 87000, loss: 0.123454
 >> iter 88000, loss: 0.168864
 >> iter 89000, loss: 0.208555
 >> iter 90000, loss: 0.194524
   Number of active neurons: 3
 >> iter 91000, loss: 0.140841
 >> iter 92000, loss: 0.128194
 >> iter 93000, loss: 0.339042
 >> iter 94000, loss: 0.213451
 >> iter 95000, loss: 0.243715
 >> iter 96000, loss: 0.217367
 >> iter 97000, loss: 0.155280
 >> iter 98000, loss: 0.132690
 >> iter 99000, loss: 0.448607
 >> iter 100000, loss: 0.326428
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.789433
 >> iter 2000, loss: 8.929339
 >> iter 3000, loss: 4.158225
 >> iter 4000, loss: 2.190836
 >> iter 5000, loss: 1.172392
 >> iter 6000, loss: 0.820620
 >> iter 7000, loss: 0.672438
 >> iter 8000, loss: 0.499463
 >> iter 9000, loss: 0.351829
 >> iter 10000, loss: 0.518445
   Number of active neurons: 4
 >> iter 11000, loss: 0.349768
 >> iter 12000, loss: 0.289140
 >> iter 13000, loss: 0.343987
 >> iter 14000, loss: 0.515205
 >> iter 15000, loss: 0.422302
 >> iter 16000, loss: 0.305022
 >> iter 17000, loss: 0.269236
 >> iter 18000, loss: 0.212444
 >> iter 19000, loss: 0.115700
 >> iter 20000, loss: 0.139741
   Number of active neurons: 4
 >> iter 21000, loss: 0.245504
 >> iter 22000, loss: 0.204869
 >> iter 23000, loss: 0.335254
 >> iter 24000, loss: 0.318073
 >> iter 25000, loss: 0.292925
 >> iter 26000, loss: 0.320972
 >> iter 27000, loss: 0.292841
 >> iter 28000, loss: 0.271875
 >> iter 29000, loss: 0.153196
 >> iter 30000, loss: 0.188465
   Number of active neurons: 4
 >> iter 31000, loss: 0.318444
 >> iter 32000, loss: 0.251227
 >> iter 33000, loss: 0.244262
 >> iter 34000, loss: 0.269524
 >> iter 35000, loss: 0.327418
 >> iter 36000, loss: 0.254472
 >> iter 37000, loss: 0.132685
 >> iter 38000, loss: 0.156293
 >> iter 39000, loss: 0.258041
 >> iter 40000, loss: 0.197179
   Number of active neurons: 4
 >> iter 41000, loss: 0.231290
 >> iter 42000, loss: 0.198279
 >> iter 43000, loss: 0.219398
 >> iter 44000, loss: 0.119717
 >> iter 45000, loss: 0.480565
 >> iter 46000, loss: 0.326663
 >> iter 47000, loss: 0.293456
 >> iter 48000, loss: 0.456706
 >> iter 49000, loss: 0.321800
 >> iter 50000, loss: 0.248136
   Number of active neurons: 3
 >> iter 51000, loss: 0.210672
 >> iter 52000, loss: 0.203159
 >> iter 53000, loss: 0.213103
 >> iter 54000, loss: 0.382215
 >> iter 55000, loss: 0.345793
 >> iter 56000, loss: 0.288626
 >> iter 57000, loss: 0.265901
 >> iter 58000, loss: 0.545403
 >> iter 59000, loss: 0.440978
 >> iter 60000, loss: 0.293554
   Number of active neurons: 3
 >> iter 61000, loss: 0.221043
 >> iter 62000, loss: 0.239439
 >> iter 63000, loss: 0.246567
 >> iter 64000, loss: 0.436048
 >> iter 65000, loss: 0.278540
 >> iter 66000, loss: 0.155561
 >> iter 67000, loss: 0.458597
 >> iter 68000, loss: 0.276086
 >> iter 69000, loss: 0.240200
 >> iter 70000, loss: 0.205284
   Number of active neurons: 3
 >> iter 71000, loss: 0.213886
 >> iter 72000, loss: 0.126116
 >> iter 73000, loss: 0.232570
 >> iter 74000, loss: 0.203026
 >> iter 75000, loss: 0.235250
 >> iter 76000, loss: 0.370235
 >> iter 77000, loss: 0.387316
 >> iter 78000, loss: 0.249480
 >> iter 79000, loss: 0.254808
 >> iter 80000, loss: 0.359827
   Number of active neurons: 3
 >> iter 81000, loss: 0.259077
 >> iter 82000, loss: 0.161276
 >> iter 83000, loss: 0.439724
 >> iter 84000, loss: 0.307796
 >> iter 85000, loss: 0.176233
 >> iter 86000, loss: 0.317006
 >> iter 87000, loss: 0.296029
 >> iter 88000, loss: 0.405663
 >> iter 89000, loss: 0.240765
 >> iter 90000, loss: 0.147567
   Number of active neurons: 3
 >> iter 91000, loss: 0.192368
 >> iter 92000, loss: 0.109347
 >> iter 93000, loss: 0.163100
 >> iter 94000, loss: 0.321030
 >> iter 95000, loss: 0.278489
 >> iter 96000, loss: 0.254441
 >> iter 97000, loss: 0.278067
 >> iter 98000, loss: 0.279816
 >> iter 99000, loss: 0.436616
 >> iter 100000, loss: 0.222597
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.652023
 >> iter 2000, loss: 9.085074
 >> iter 3000, loss: 4.451036
 >> iter 4000, loss: 2.452670
 >> iter 5000, loss: 1.282953
 >> iter 6000, loss: 0.771243
 >> iter 7000, loss: 0.559411
 >> iter 8000, loss: 0.602829
 >> iter 9000, loss: 0.563179
 >> iter 10000, loss: 0.424347
   Number of active neurons: 6
 >> iter 11000, loss: 0.423097
 >> iter 12000, loss: 0.642140
 >> iter 13000, loss: 0.486057
 >> iter 14000, loss: 0.508246
 >> iter 15000, loss: 0.607173
 >> iter 16000, loss: 0.733670
 >> iter 17000, loss: 0.589413
 >> iter 18000, loss: 0.623029
 >> iter 19000, loss: 0.747738
 >> iter 20000, loss: 0.470299
   Number of active neurons: 5
 >> iter 21000, loss: 0.368366
 >> iter 22000, loss: 0.392041
 >> iter 23000, loss: 0.590657
 >> iter 24000, loss: 0.562990
 >> iter 25000, loss: 0.633833
 >> iter 26000, loss: 0.562645
 >> iter 27000, loss: 0.430612
 >> iter 28000, loss: 0.541054
 >> iter 29000, loss: 0.515405
 >> iter 30000, loss: 0.412139
   Number of active neurons: 5
 >> iter 31000, loss: 0.356632
 >> iter 32000, loss: 0.432133
 >> iter 33000, loss: 0.540362
 >> iter 34000, loss: 0.476253
 >> iter 35000, loss: 0.407234
 >> iter 36000, loss: 0.515965
 >> iter 37000, loss: 0.345239
 >> iter 38000, loss: 0.518667
 >> iter 39000, loss: 0.534223
 >> iter 40000, loss: 0.526317
   Number of active neurons: 4
 >> iter 41000, loss: 0.433868
 >> iter 42000, loss: 0.314859
 >> iter 43000, loss: 0.428906
 >> iter 44000, loss: 0.519301
 >> iter 45000, loss: 0.467370
 >> iter 46000, loss: 0.384178
 >> iter 47000, loss: 0.210979
 >> iter 48000, loss: 0.159381
 >> iter 49000, loss: 0.293339
 >> iter 50000, loss: 0.381708
   Number of active neurons: 4
 >> iter 51000, loss: 0.431849
 >> iter 52000, loss: 0.498870
 >> iter 53000, loss: 0.271352
 >> iter 54000, loss: 0.319044
 >> iter 55000, loss: 0.385234
 >> iter 56000, loss: 0.488184
 >> iter 57000, loss: 0.550371
 >> iter 58000, loss: 0.629040
 >> iter 59000, loss: 0.529907
 >> iter 60000, loss: 0.411053
   Number of active neurons: 4
 >> iter 61000, loss: 0.393042
 >> iter 62000, loss: 0.448517
 >> iter 63000, loss: 0.295889
 >> iter 64000, loss: 0.680989
 >> iter 65000, loss: 0.618719
 >> iter 66000, loss: 0.554996
 >> iter 67000, loss: 0.580941
 >> iter 68000, loss: 0.467339
 >> iter 69000, loss: 0.726228
 >> iter 70000, loss: 0.456395
   Number of active neurons: 4
 >> iter 71000, loss: 0.439951
 >> iter 72000, loss: 0.363421
 >> iter 73000, loss: 0.213982
 >> iter 74000, loss: 0.261465
 >> iter 75000, loss: 0.471762
 >> iter 76000, loss: 0.533767
 >> iter 77000, loss: 0.468141
 >> iter 78000, loss: 0.536570
 >> iter 79000, loss: 0.704653
 >> iter 80000, loss: 0.493930
   Number of active neurons: 4
 >> iter 81000, loss: 0.511291
 >> iter 82000, loss: 0.604790
 >> iter 83000, loss: 0.485718
 >> iter 84000, loss: 0.427885
 >> iter 85000, loss: 0.400727
 >> iter 86000, loss: 0.436715
 >> iter 87000, loss: 0.346001
 >> iter 88000, loss: 0.463971
 >> iter 89000, loss: 0.459228
 >> iter 90000, loss: 0.310418
   Number of active neurons: 4
 >> iter 91000, loss: 0.243498
 >> iter 92000, loss: 0.523008
 >> iter 93000, loss: 0.471986
 >> iter 94000, loss: 0.512412
 >> iter 95000, loss: 0.464165
 >> iter 96000, loss: 0.310074
 >> iter 97000, loss: 0.289085
 >> iter 98000, loss: 0.342281
 >> iter 99000, loss: 0.493042
 >> iter 100000, loss: 0.345386
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.788853
 >> iter 2000, loss: 9.250966
 >> iter 3000, loss: 4.394898
 >> iter 4000, loss: 2.006795
 >> iter 5000, loss: 1.184330
 >> iter 6000, loss: 0.781412
 >> iter 7000, loss: 0.596292
 >> iter 8000, loss: 0.512973
 >> iter 9000, loss: 0.551224
 >> iter 10000, loss: 0.444090
   Number of active neurons: 3
 >> iter 11000, loss: 0.445411
 >> iter 12000, loss: 0.475322
 >> iter 13000, loss: 0.471856
 >> iter 14000, loss: 0.437459
 >> iter 15000, loss: 0.366761
 >> iter 16000, loss: 0.266029
 >> iter 17000, loss: 0.318158
 >> iter 18000, loss: 0.262984
 >> iter 19000, loss: 0.253875
 >> iter 20000, loss: 0.407644
   Number of active neurons: 3
 >> iter 21000, loss: 0.198869
 >> iter 22000, loss: 0.397318
 >> iter 23000, loss: 0.280660
 >> iter 24000, loss: 0.354192
 >> iter 25000, loss: 0.314002
 >> iter 26000, loss: 0.283271
 >> iter 27000, loss: 0.327003
 >> iter 28000, loss: 0.221748
 >> iter 29000, loss: 0.167611
 >> iter 30000, loss: 0.256925
   Number of active neurons: 3
 >> iter 31000, loss: 0.375325
 >> iter 32000, loss: 0.426974
 >> iter 33000, loss: 0.323273
 >> iter 34000, loss: 0.185530
 >> iter 35000, loss: 0.410813
 >> iter 36000, loss: 0.228627
 >> iter 37000, loss: 0.277869
 >> iter 38000, loss: 0.348791
 >> iter 39000, loss: 0.217124
 >> iter 40000, loss: 0.219716
   Number of active neurons: 3
 >> iter 41000, loss: 0.288715
 >> iter 42000, loss: 0.315597
 >> iter 43000, loss: 0.571000
 >> iter 44000, loss: 0.395403
 >> iter 45000, loss: 0.290906
 >> iter 46000, loss: 0.264367
 >> iter 47000, loss: 0.452063
 >> iter 48000, loss: 0.427210
 >> iter 49000, loss: 0.383312
 >> iter 50000, loss: 0.212761
   Number of active neurons: 3
 >> iter 51000, loss: 0.298110
 >> iter 52000, loss: 0.247741
 >> iter 53000, loss: 0.313392
 >> iter 54000, loss: 0.360173
 >> iter 55000, loss: 0.227733
 >> iter 56000, loss: 0.389296
 >> iter 57000, loss: 0.355478
 >> iter 58000, loss: 0.310482
 >> iter 59000, loss: 0.375942
 >> iter 60000, loss: 0.260055
   Number of active neurons: 3
 >> iter 61000, loss: 0.164088
 >> iter 62000, loss: 0.235464
 >> iter 63000, loss: 0.310189
 >> iter 64000, loss: 0.208381
 >> iter 65000, loss: 0.131569
 >> iter 66000, loss: 0.080199
 >> iter 67000, loss: 0.330774
 >> iter 68000, loss: 0.225795
 >> iter 69000, loss: 0.201169
 >> iter 70000, loss: 0.255610
   Number of active neurons: 3
 >> iter 71000, loss: 0.259265
 >> iter 72000, loss: 0.209964
 >> iter 73000, loss: 0.267139
 >> iter 74000, loss: 0.285805
 >> iter 75000, loss: 0.147440
 >> iter 76000, loss: 0.302222
 >> iter 77000, loss: 0.257515
 >> iter 78000, loss: 0.274038
 >> iter 79000, loss: 0.234183
 >> iter 80000, loss: 0.320522
   Number of active neurons: 3
 >> iter 81000, loss: 0.287467
 >> iter 82000, loss: 0.313127
 >> iter 83000, loss: 0.206447
 >> iter 84000, loss: 0.403109
 >> iter 85000, loss: 0.214675
 >> iter 86000, loss: 0.106751
 >> iter 87000, loss: 0.241252
 >> iter 88000, loss: 0.302279
 >> iter 89000, loss: 0.175305
 >> iter 90000, loss: 0.127878
   Number of active neurons: 3
 >> iter 91000, loss: 0.154755
 >> iter 92000, loss: 0.140468
 >> iter 93000, loss: 0.151892
 >> iter 94000, loss: 0.255766
 >> iter 95000, loss: 0.224203
 >> iter 96000, loss: 0.251052
 >> iter 97000, loss: 0.350735
 >> iter 98000, loss: 0.290436
 >> iter 99000, loss: 0.303568
 >> iter 100000, loss: 0.265581
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.363543
 >> iter 2000, loss: 8.583781
 >> iter 3000, loss: 3.613675
 >> iter 4000, loss: 1.777086
 >> iter 5000, loss: 1.067943
 >> iter 6000, loss: 0.715595
 >> iter 7000, loss: 0.610713
 >> iter 8000, loss: 0.454307
 >> iter 9000, loss: 0.406261
 >> iter 10000, loss: 0.502911
   Number of active neurons: 6
 >> iter 11000, loss: 0.403366
 >> iter 12000, loss: 0.379887
 >> iter 13000, loss: 0.393050
 >> iter 14000, loss: 0.309035
 >> iter 15000, loss: 0.193098
 >> iter 16000, loss: 0.200500
 >> iter 17000, loss: 0.201347
 >> iter 18000, loss: 0.504760
 >> iter 19000, loss: 0.345394
 >> iter 20000, loss: 0.458369
   Number of active neurons: 5
 >> iter 21000, loss: 0.324885
 >> iter 22000, loss: 0.484066
 >> iter 23000, loss: 0.321225
 >> iter 24000, loss: 0.377675
 >> iter 25000, loss: 0.198039
 >> iter 26000, loss: 0.383735
 >> iter 27000, loss: 0.259207
 >> iter 28000, loss: 0.213991
 >> iter 29000, loss: 0.174779
 >> iter 30000, loss: 0.226987
   Number of active neurons: 4
 >> iter 31000, loss: 0.262024
 >> iter 32000, loss: 0.427771
 >> iter 33000, loss: 0.431470
 >> iter 34000, loss: 0.219371
 >> iter 35000, loss: 0.136752
 >> iter 36000, loss: 0.377680
 >> iter 37000, loss: 0.466478
 >> iter 38000, loss: 0.457871
 >> iter 39000, loss: 0.470577
 >> iter 40000, loss: 0.370823
   Number of active neurons: 3
 >> iter 41000, loss: 0.359823
 >> iter 42000, loss: 0.333134
 >> iter 43000, loss: 0.294493
 >> iter 44000, loss: 0.182521
 >> iter 45000, loss: 0.299387
 >> iter 46000, loss: 0.284063
 >> iter 47000, loss: 0.186137
 >> iter 48000, loss: 0.397795
 >> iter 49000, loss: 0.317185
 >> iter 50000, loss: 0.211891
   Number of active neurons: 3
 >> iter 51000, loss: 0.283420
 >> iter 52000, loss: 0.311810
 >> iter 53000, loss: 0.334071
 >> iter 54000, loss: 0.185532
 >> iter 55000, loss: 0.283526
 >> iter 56000, loss: 0.170392
 >> iter 57000, loss: 0.296354
 >> iter 58000, loss: 0.265073
 >> iter 59000, loss: 0.182007
 >> iter 60000, loss: 0.155197
   Number of active neurons: 3
 >> iter 61000, loss: 0.360641
 >> iter 62000, loss: 0.224752
 >> iter 63000, loss: 0.322381
 >> iter 64000, loss: 0.189836
 >> iter 65000, loss: 0.270675
 >> iter 66000, loss: 0.176828
 >> iter 67000, loss: 0.143336
 >> iter 68000, loss: 0.193032
 >> iter 69000, loss: 0.219637
 >> iter 70000, loss: 0.358379
   Number of active neurons: 3
 >> iter 71000, loss: 0.169520
 >> iter 72000, loss: 0.165200
 >> iter 73000, loss: 0.254769
 >> iter 74000, loss: 0.149549
 >> iter 75000, loss: 0.313752
 >> iter 76000, loss: 0.210572
 >> iter 77000, loss: 0.163554
 >> iter 78000, loss: 0.318459
 >> iter 79000, loss: 0.279235
 >> iter 80000, loss: 0.428401
   Number of active neurons: 3
 >> iter 81000, loss: 0.212607
 >> iter 82000, loss: 0.160147
 >> iter 83000, loss: 0.209973
 >> iter 84000, loss: 0.299141
 >> iter 85000, loss: 0.460839
 >> iter 86000, loss: 0.390300
 >> iter 87000, loss: 0.284736
 >> iter 88000, loss: 0.271395
 >> iter 89000, loss: 0.325979
 >> iter 90000, loss: 0.239339
   Number of active neurons: 3
 >> iter 91000, loss: 0.231505
 >> iter 92000, loss: 0.206380
 >> iter 93000, loss: 0.191434
 >> iter 94000, loss: 0.363622
 >> iter 95000, loss: 0.248033
 >> iter 96000, loss: 0.200227
 >> iter 97000, loss: 0.388392
 >> iter 98000, loss: 0.321450
 >> iter 99000, loss: 0.177103
 >> iter 100000, loss: 0.194755
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.681934
 >> iter 2000, loss: 9.470804
 >> iter 3000, loss: 4.294655
 >> iter 4000, loss: 2.077203
 >> iter 5000, loss: 1.066842
 >> iter 6000, loss: 0.545200
 >> iter 7000, loss: 0.259184
 >> iter 8000, loss: 0.487220
 >> iter 9000, loss: 0.342676
 >> iter 10000, loss: 0.264410
   Number of active neurons: 4
 >> iter 11000, loss: 0.355401
 >> iter 12000, loss: 0.489248
 >> iter 13000, loss: 0.375225
 >> iter 14000, loss: 0.236107
 >> iter 15000, loss: 0.172916
 >> iter 16000, loss: 0.295917
 >> iter 17000, loss: 0.330644
 >> iter 18000, loss: 0.381457
 >> iter 19000, loss: 0.456804
 >> iter 20000, loss: 0.653616
   Number of active neurons: 4
 >> iter 21000, loss: 0.278091
 >> iter 22000, loss: 0.377855
 >> iter 23000, loss: 0.355791
 >> iter 24000, loss: 0.186941
 >> iter 25000, loss: 0.289478
 >> iter 26000, loss: 0.442859
 >> iter 27000, loss: 0.372515
 >> iter 28000, loss: 0.288313
 >> iter 29000, loss: 0.307006
 >> iter 30000, loss: 0.569356
   Number of active neurons: 4
 >> iter 31000, loss: 0.460743
 >> iter 32000, loss: 0.309380
 >> iter 33000, loss: 0.175892
 >> iter 34000, loss: 0.155350
 >> iter 35000, loss: 0.247921
 >> iter 36000, loss: 0.402561
 >> iter 37000, loss: 0.441803
 >> iter 38000, loss: 0.252768
 >> iter 39000, loss: 0.415627
 >> iter 40000, loss: 0.268842
   Number of active neurons: 4
 >> iter 41000, loss: 0.230563
 >> iter 42000, loss: 0.368575
 >> iter 43000, loss: 0.230269
 >> iter 44000, loss: 0.299402
 >> iter 45000, loss: 0.297544
 >> iter 46000, loss: 0.173538
 >> iter 47000, loss: 0.258835
 >> iter 48000, loss: 0.182828
 >> iter 49000, loss: 0.112693
 >> iter 50000, loss: 0.130344
   Number of active neurons: 3
 >> iter 51000, loss: 0.120274
 >> iter 52000, loss: 0.072063
 >> iter 53000, loss: 0.082979
 >> iter 54000, loss: 0.220703
 >> iter 55000, loss: 0.167542
 >> iter 56000, loss: 0.159409
 >> iter 57000, loss: 0.209146
 >> iter 58000, loss: 0.213496
 >> iter 59000, loss: 0.317886
 >> iter 60000, loss: 0.361324
   Number of active neurons: 3
 >> iter 61000, loss: 0.351945
 >> iter 62000, loss: 0.316365
 >> iter 63000, loss: 0.186294
 >> iter 64000, loss: 0.270591
 >> iter 65000, loss: 0.221721
 >> iter 66000, loss: 0.299960
 >> iter 67000, loss: 0.393049
 >> iter 68000, loss: 0.387716
 >> iter 69000, loss: 0.364137
 >> iter 70000, loss: 0.165329
   Number of active neurons: 3
 >> iter 71000, loss: 0.236894
 >> iter 72000, loss: 0.124408
 >> iter 73000, loss: 0.266312
 >> iter 74000, loss: 0.150242
 >> iter 75000, loss: 0.084002
 >> iter 76000, loss: 0.179584
 >> iter 77000, loss: 0.304573
 >> iter 78000, loss: 0.285936
 >> iter 79000, loss: 0.167458
 >> iter 80000, loss: 0.187987
   Number of active neurons: 3
 >> iter 81000, loss: 0.273980
 >> iter 82000, loss: 0.212738
 >> iter 83000, loss: 0.344436
 >> iter 84000, loss: 0.324335
 >> iter 85000, loss: 0.464981
 >> iter 86000, loss: 0.437606
 >> iter 87000, loss: 0.230468
 >> iter 88000, loss: 0.448511
 >> iter 89000, loss: 0.422246
 >> iter 90000, loss: 0.229713
   Number of active neurons: 3
 >> iter 91000, loss: 0.294369
 >> iter 92000, loss: 0.236028
 >> iter 93000, loss: 0.153720
 >> iter 94000, loss: 0.150262
 >> iter 95000, loss: 0.095909
 >> iter 96000, loss: 0.067362
 >> iter 97000, loss: 0.265529
 >> iter 98000, loss: 0.233113
 >> iter 99000, loss: 0.223611
 >> iter 100000, loss: 0.280211
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.992040
 >> iter 2000, loss: 8.018883
 >> iter 3000, loss: 3.484447
 >> iter 4000, loss: 1.513779
 >> iter 5000, loss: 0.657547
 >> iter 6000, loss: 0.668989
 >> iter 7000, loss: 0.633485
 >> iter 8000, loss: 0.525844
 >> iter 9000, loss: 0.511226
 >> iter 10000, loss: 0.328752
   Number of active neurons: 6
 >> iter 11000, loss: 0.210573
 >> iter 12000, loss: 0.245022
 >> iter 13000, loss: 0.438014
 >> iter 14000, loss: 0.425609
 >> iter 15000, loss: 0.300193
 >> iter 16000, loss: 0.204321
 >> iter 17000, loss: 0.207310
 >> iter 18000, loss: 0.446597
 >> iter 19000, loss: 0.287229
 >> iter 20000, loss: 0.464571
   Number of active neurons: 6
 >> iter 21000, loss: 0.487747
 >> iter 22000, loss: 0.550261
 >> iter 23000, loss: 0.416470
 >> iter 24000, loss: 0.288887
 >> iter 25000, loss: 0.485658
 >> iter 26000, loss: 0.232108
 >> iter 27000, loss: 0.201642
 >> iter 28000, loss: 0.130457
 >> iter 29000, loss: 0.383476
 >> iter 30000, loss: 0.367778
   Number of active neurons: 6
 >> iter 31000, loss: 0.282516
 >> iter 32000, loss: 0.301404
 >> iter 33000, loss: 0.365409
 >> iter 34000, loss: 0.320550
 >> iter 35000, loss: 0.398981
 >> iter 36000, loss: 0.323484
 >> iter 37000, loss: 0.376283
 >> iter 38000, loss: 0.361118
 >> iter 39000, loss: 0.372869
 >> iter 40000, loss: 0.392219
   Number of active neurons: 5
 >> iter 41000, loss: 0.347328
 >> iter 42000, loss: 0.244892
 >> iter 43000, loss: 0.276802
 >> iter 44000, loss: 0.299506
 >> iter 45000, loss: 0.177685
 >> iter 46000, loss: 0.250990
 >> iter 47000, loss: 0.162041
 >> iter 48000, loss: 0.245842
 >> iter 49000, loss: 0.283753
 >> iter 50000, loss: 0.206383
   Number of active neurons: 5
 >> iter 51000, loss: 0.331418
 >> iter 52000, loss: 0.265307
 >> iter 53000, loss: 0.312912
 >> iter 54000, loss: 0.381562
 >> iter 55000, loss: 0.385537
 >> iter 56000, loss: 0.249807
 >> iter 57000, loss: 0.285106
 >> iter 58000, loss: 0.369274
 >> iter 59000, loss: 0.285309
 >> iter 60000, loss: 0.253603
   Number of active neurons: 4
 >> iter 61000, loss: 0.247225
 >> iter 62000, loss: 0.578599
 >> iter 63000, loss: 0.521547
 >> iter 64000, loss: 0.316253
 >> iter 65000, loss: 0.163472
 >> iter 66000, loss: 0.199458
 >> iter 67000, loss: 0.336474
 >> iter 68000, loss: 0.192773
 >> iter 69000, loss: 0.204816
 >> iter 70000, loss: 0.320496
   Number of active neurons: 4
 >> iter 71000, loss: 0.571074
 >> iter 72000, loss: 0.318187
 >> iter 73000, loss: 0.460880
 >> iter 74000, loss: 0.315633
 >> iter 75000, loss: 0.189195
 >> iter 76000, loss: 0.262333
 >> iter 77000, loss: 0.335799
 >> iter 78000, loss: 0.284847
 >> iter 79000, loss: 0.386114
 >> iter 80000, loss: 0.407283
   Number of active neurons: 4
 >> iter 81000, loss: 0.239129
 >> iter 82000, loss: 0.192920
 >> iter 83000, loss: 0.202764
 >> iter 84000, loss: 0.585046
 >> iter 85000, loss: 0.268137
 >> iter 86000, loss: 0.487744
 >> iter 87000, loss: 0.374127
 >> iter 88000, loss: 0.320393
 >> iter 89000, loss: 0.233028
 >> iter 90000, loss: 0.213534
   Number of active neurons: 3
 >> iter 91000, loss: 0.259435
 >> iter 92000, loss: 0.252928
 >> iter 93000, loss: 0.363619
 >> iter 94000, loss: 0.206627
 >> iter 95000, loss: 0.372037
 >> iter 96000, loss: 0.172000
 >> iter 97000, loss: 0.183048
 >> iter 98000, loss: 0.354746
 >> iter 99000, loss: 0.283093
 >> iter 100000, loss: 0.163992
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.313049
 >> iter 2000, loss: 10.686938
 >> iter 3000, loss: 4.984238
 >> iter 4000, loss: 2.328747
 >> iter 5000, loss: 1.151638
 >> iter 6000, loss: 0.762498
 >> iter 7000, loss: 0.378507
 >> iter 8000, loss: 0.259948
 >> iter 9000, loss: 0.406851
 >> iter 10000, loss: 0.375275
   Number of active neurons: 4
 >> iter 11000, loss: 0.286863
 >> iter 12000, loss: 0.357353
 >> iter 13000, loss: 0.369528
 >> iter 14000, loss: 0.252718
 >> iter 15000, loss: 0.289800
 >> iter 16000, loss: 0.639243
 >> iter 17000, loss: 0.341437
 >> iter 18000, loss: 0.173316
 >> iter 19000, loss: 0.275649
 >> iter 20000, loss: 0.385495
   Number of active neurons: 3
 >> iter 21000, loss: 0.352862
 >> iter 22000, loss: 0.167838
 >> iter 23000, loss: 0.183754
 >> iter 24000, loss: 0.509204
 >> iter 25000, loss: 0.274671
 >> iter 26000, loss: 0.222978
 >> iter 27000, loss: 0.128162
 >> iter 28000, loss: 0.136597
 >> iter 29000, loss: 0.143786
 >> iter 30000, loss: 0.250142
   Number of active neurons: 3
 >> iter 31000, loss: 0.277542
 >> iter 32000, loss: 0.332284
 >> iter 33000, loss: 0.221934
 >> iter 34000, loss: 0.341280
 >> iter 35000, loss: 0.254104
 >> iter 36000, loss: 0.295509
 >> iter 37000, loss: 0.358961
 >> iter 38000, loss: 0.296357
 >> iter 39000, loss: 0.347583
 >> iter 40000, loss: 0.237659
   Number of active neurons: 3
 >> iter 41000, loss: 0.153680
 >> iter 42000, loss: 0.264620
 >> iter 43000, loss: 0.245236
 >> iter 44000, loss: 0.144511
 >> iter 45000, loss: 0.197054
 >> iter 46000, loss: 0.168080
 >> iter 47000, loss: 0.156944
 >> iter 48000, loss: 0.388087
 >> iter 49000, loss: 0.415974
 >> iter 50000, loss: 0.356369
   Number of active neurons: 3
 >> iter 51000, loss: 0.280401
 >> iter 52000, loss: 0.187532
 >> iter 53000, loss: 0.305120
 >> iter 54000, loss: 0.191032
 >> iter 55000, loss: 0.199072
 >> iter 56000, loss: 0.312206
 >> iter 57000, loss: 0.309691
 >> iter 58000, loss: 0.330209
 >> iter 59000, loss: 0.355409
 >> iter 60000, loss: 0.290741
   Number of active neurons: 3
 >> iter 61000, loss: 0.182177
 >> iter 62000, loss: 0.215428
 >> iter 63000, loss: 0.100737
 >> iter 64000, loss: 0.265012
 >> iter 65000, loss: 0.359333
 >> iter 66000, loss: 0.396360
 >> iter 67000, loss: 0.300023
 >> iter 68000, loss: 0.334549
 >> iter 69000, loss: 0.155997
 >> iter 70000, loss: 0.276910
   Number of active neurons: 3
 >> iter 71000, loss: 0.163491
 >> iter 72000, loss: 0.216314
 >> iter 73000, loss: 0.316817
 >> iter 74000, loss: 0.174302
 >> iter 75000, loss: 0.168683
 >> iter 76000, loss: 0.196290
 >> iter 77000, loss: 0.219799
 >> iter 78000, loss: 0.276234
 >> iter 79000, loss: 0.388359
 >> iter 80000, loss: 0.257364
   Number of active neurons: 3
 >> iter 81000, loss: 0.354600
 >> iter 82000, loss: 0.379533
 >> iter 83000, loss: 0.231413
 >> iter 84000, loss: 0.306489
 >> iter 85000, loss: 0.258870
 >> iter 86000, loss: 0.428547
 >> iter 87000, loss: 0.303837
 >> iter 88000, loss: 0.202447
 >> iter 89000, loss: 0.324062
 >> iter 90000, loss: 0.324179
   Number of active neurons: 3
 >> iter 91000, loss: 0.287115
 >> iter 92000, loss: 0.162299
 >> iter 93000, loss: 0.217256
 >> iter 94000, loss: 0.217879
 >> iter 95000, loss: 0.241686
 >> iter 96000, loss: 0.213202
 >> iter 97000, loss: 0.181621
 >> iter 98000, loss: 0.131364
 >> iter 99000, loss: 0.123463
 >> iter 100000, loss: 0.106811
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.228955
 >> iter 2000, loss: 8.514142
 >> iter 3000, loss: 3.753267
 >> iter 4000, loss: 1.797638
 >> iter 5000, loss: 1.020906
 >> iter 6000, loss: 0.930147
 >> iter 7000, loss: 0.626830
 >> iter 8000, loss: 0.538718
 >> iter 9000, loss: 0.553761
 >> iter 10000, loss: 0.294811
   Number of active neurons: 6
 >> iter 11000, loss: 0.410750
 >> iter 12000, loss: 0.394817
 >> iter 13000, loss: 0.539068
 >> iter 14000, loss: 0.433713
 >> iter 15000, loss: 0.387682
 >> iter 16000, loss: 0.228422
 >> iter 17000, loss: 0.380648
 >> iter 18000, loss: 0.333260
 >> iter 19000, loss: 0.329826
 >> iter 20000, loss: 0.183048
   Number of active neurons: 6
 >> iter 21000, loss: 0.309417
 >> iter 22000, loss: 0.220640
 >> iter 23000, loss: 0.171072
 >> iter 24000, loss: 0.241742
 >> iter 25000, loss: 0.520745
 >> iter 26000, loss: 0.323787
 >> iter 27000, loss: 0.291468
 >> iter 28000, loss: 0.302414
 >> iter 29000, loss: 0.333734
 >> iter 30000, loss: 0.385460
   Number of active neurons: 6
 >> iter 31000, loss: 0.256563
 >> iter 32000, loss: 0.276142
 >> iter 33000, loss: 0.293695
 >> iter 34000, loss: 0.323658
 >> iter 35000, loss: 0.302816
 >> iter 36000, loss: 0.228229
 >> iter 37000, loss: 0.233609
 >> iter 38000, loss: 0.239866
 >> iter 39000, loss: 0.242359
 >> iter 40000, loss: 0.477919
   Number of active neurons: 4
 >> iter 41000, loss: 0.427634
 >> iter 42000, loss: 0.231634
 >> iter 43000, loss: 0.335493
 >> iter 44000, loss: 0.395534
 >> iter 45000, loss: 0.292030
 >> iter 46000, loss: 0.218192
 >> iter 47000, loss: 0.236091
 >> iter 48000, loss: 0.203936
 >> iter 49000, loss: 0.408712
 >> iter 50000, loss: 0.250137
   Number of active neurons: 4
 >> iter 51000, loss: 0.311007
 >> iter 52000, loss: 0.450676
 >> iter 53000, loss: 0.355995
 >> iter 54000, loss: 0.330096
 >> iter 55000, loss: 0.244822
 >> iter 56000, loss: 0.417068
 >> iter 57000, loss: 0.420368
 >> iter 58000, loss: 0.352229
 >> iter 59000, loss: 0.354838
 >> iter 60000, loss: 0.271522
   Number of active neurons: 3
 >> iter 61000, loss: 0.226220
 >> iter 62000, loss: 0.391372
 >> iter 63000, loss: 0.266755
 >> iter 64000, loss: 0.195599
 >> iter 65000, loss: 0.132402
 >> iter 66000, loss: 0.194988
 >> iter 67000, loss: 0.341224
 >> iter 68000, loss: 0.476434
 >> iter 69000, loss: 0.338159
 >> iter 70000, loss: 0.261065
   Number of active neurons: 3
 >> iter 71000, loss: 0.264784
 >> iter 72000, loss: 0.186828
 >> iter 73000, loss: 0.126196
 >> iter 74000, loss: 0.283176
 >> iter 75000, loss: 0.255708
 >> iter 76000, loss: 0.304557
 >> iter 77000, loss: 0.427669
 >> iter 78000, loss: 0.259884
 >> iter 79000, loss: 0.281944
 >> iter 80000, loss: 0.217850
   Number of active neurons: 3
 >> iter 81000, loss: 0.190947
 >> iter 82000, loss: 0.102610
 >> iter 83000, loss: 0.141439
 >> iter 84000, loss: 0.419585
 >> iter 85000, loss: 0.333070
 >> iter 86000, loss: 0.300207
 >> iter 87000, loss: 0.234462
 >> iter 88000, loss: 0.218666
 >> iter 89000, loss: 0.251591
 >> iter 90000, loss: 0.208557
   Number of active neurons: 3
 >> iter 91000, loss: 0.140713
 >> iter 92000, loss: 0.087419
 >> iter 93000, loss: 0.199942
 >> iter 94000, loss: 0.180488
 >> iter 95000, loss: 0.194535
 >> iter 96000, loss: 0.134573
 >> iter 97000, loss: 0.317035
 >> iter 98000, loss: 0.201611
 >> iter 99000, loss: 0.311568
 >> iter 100000, loss: 0.370160
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

