 > Problema: tomita3nueva
 > Args:
   - Hidden size: 18
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.134279
 >> iter 2000, loss: 12.317683
 >> iter 3000, loss: 6.165599
 >> iter 4000, loss: 2.780829
 >> iter 5000, loss: 1.468192
 >> iter 6000, loss: 0.667002
 >> iter 7000, loss: 0.599925
 >> iter 8000, loss: 0.353010
 >> iter 9000, loss: 0.457748
 >> iter 10000, loss: 0.380332
   Number of active neurons: 9
 >> iter 11000, loss: 0.290751
 >> iter 12000, loss: 0.342597
 >> iter 13000, loss: 0.296274
 >> iter 14000, loss: 0.236019
 >> iter 15000, loss: 0.245246
 >> iter 16000, loss: 0.214206
 >> iter 17000, loss: 0.288539
 >> iter 18000, loss: 0.282360
 >> iter 19000, loss: 0.192971
 >> iter 20000, loss: 0.193429
   Number of active neurons: 9
 >> iter 21000, loss: 0.298248
 >> iter 22000, loss: 0.254257
 >> iter 23000, loss: 0.151241
 >> iter 24000, loss: 0.136621
 >> iter 25000, loss: 0.164573
 >> iter 26000, loss: 0.208324
 >> iter 27000, loss: 0.287396
 >> iter 28000, loss: 0.284464
 >> iter 29000, loss: 0.280628
 >> iter 30000, loss: 0.326718
   Number of active neurons: 8
 >> iter 31000, loss: 0.208529
 >> iter 32000, loss: 0.219412
 >> iter 33000, loss: 0.271552
 >> iter 34000, loss: 0.257767
 >> iter 35000, loss: 0.156119
 >> iter 36000, loss: 0.161360
 >> iter 37000, loss: 0.139206
 >> iter 38000, loss: 0.255522
 >> iter 39000, loss: 0.189649
 >> iter 40000, loss: 0.196292
   Number of active neurons: 7
 >> iter 41000, loss: 0.163241
 >> iter 42000, loss: 0.220531
 >> iter 43000, loss: 0.164162
 >> iter 44000, loss: 0.187778
 >> iter 45000, loss: 0.182317
 >> iter 46000, loss: 0.404052
 >> iter 47000, loss: 0.210586
 >> iter 48000, loss: 0.197725
 >> iter 49000, loss: 0.213421
 >> iter 50000, loss: 0.168541
   Number of active neurons: 7
 >> iter 51000, loss: 0.351040
 >> iter 52000, loss: 0.277662
 >> iter 53000, loss: 0.283968
 >> iter 54000, loss: 0.384364
 >> iter 55000, loss: 0.235461
 >> iter 56000, loss: 0.263141
 >> iter 57000, loss: 0.252427
 >> iter 58000, loss: 0.300515
 >> iter 59000, loss: 0.215873
 >> iter 60000, loss: 0.299950
   Number of active neurons: 6
 >> iter 61000, loss: 0.220120
 >> iter 62000, loss: 0.179048
 >> iter 63000, loss: 0.214826
 >> iter 64000, loss: 0.198158
 >> iter 65000, loss: 0.252209
 >> iter 66000, loss: 0.230591
 >> iter 67000, loss: 0.184916
 >> iter 68000, loss: 0.211717
 >> iter 69000, loss: 0.201262
 >> iter 70000, loss: 0.287601
   Number of active neurons: 5
 >> iter 71000, loss: 0.233468
 >> iter 72000, loss: 0.193992
 >> iter 73000, loss: 0.201289
 >> iter 74000, loss: 0.373059
 >> iter 75000, loss: 0.521713
 >> iter 76000, loss: 0.343457
 >> iter 77000, loss: 0.340280
 >> iter 78000, loss: 0.472901
 >> iter 79000, loss: 0.344163
 >> iter 80000, loss: 0.506205
   Number of active neurons: 5
 >> iter 81000, loss: 0.293940
 >> iter 82000, loss: 0.159555
 >> iter 83000, loss: 0.250659
 >> iter 84000, loss: 0.175756
 >> iter 85000, loss: 0.269585
 >> iter 86000, loss: 0.324783
 >> iter 87000, loss: 0.233655
 >> iter 88000, loss: 0.197968
 >> iter 89000, loss: 0.180606
 >> iter 90000, loss: 0.214922
   Number of active neurons: 5
 >> iter 91000, loss: 0.316354
 >> iter 92000, loss: 0.275056
 >> iter 93000, loss: 0.345808
 >> iter 94000, loss: 0.237392
 >> iter 95000, loss: 0.203608
 >> iter 96000, loss: 0.139225
 >> iter 97000, loss: 0.246625
 >> iter 98000, loss: 0.322890
 >> iter 99000, loss: 0.200059
 >> iter 100000, loss: 0.284201
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.372981
 >> iter 2000, loss: 11.215859
 >> iter 3000, loss: 5.200335
 >> iter 4000, loss: 2.232396
 >> iter 5000, loss: 1.093213
 >> iter 6000, loss: 0.577900
 >> iter 7000, loss: 0.418563
 >> iter 8000, loss: 0.316638
 >> iter 9000, loss: 0.220527
 >> iter 10000, loss: 0.243401
   Number of active neurons: 9
 >> iter 11000, loss: 0.264020
 >> iter 12000, loss: 0.229241
 >> iter 13000, loss: 0.273211
 >> iter 14000, loss: 0.362174
 >> iter 15000, loss: 0.240153
 >> iter 16000, loss: 0.264904
 >> iter 17000, loss: 0.177422
 >> iter 18000, loss: 0.157418
 >> iter 19000, loss: 0.247608
 >> iter 20000, loss: 0.328960
   Number of active neurons: 9
 >> iter 21000, loss: 0.297461
 >> iter 22000, loss: 0.200245
 >> iter 23000, loss: 0.333335
 >> iter 24000, loss: 0.375402
 >> iter 25000, loss: 0.341238
 >> iter 26000, loss: 0.300889
 >> iter 27000, loss: 0.193601
 >> iter 28000, loss: 0.261256
 >> iter 29000, loss: 0.293919
 >> iter 30000, loss: 0.280520
   Number of active neurons: 5
 >> iter 31000, loss: 0.207469
 >> iter 32000, loss: 0.199999
 >> iter 33000, loss: 0.189255
 >> iter 34000, loss: 0.285433
 >> iter 35000, loss: 0.259102
 >> iter 36000, loss: 0.177673
 >> iter 37000, loss: 0.134563
 >> iter 38000, loss: 0.198269
 >> iter 39000, loss: 0.384241
 >> iter 40000, loss: 0.366564
   Number of active neurons: 5
 >> iter 41000, loss: 0.250284
 >> iter 42000, loss: 0.254194
 >> iter 43000, loss: 0.252676
 >> iter 44000, loss: 0.171318
 >> iter 45000, loss: 0.298637
 >> iter 46000, loss: 0.229554
 >> iter 47000, loss: 0.201121
 >> iter 48000, loss: 0.254628
 >> iter 49000, loss: 0.187273
 >> iter 50000, loss: 0.290799
   Number of active neurons: 5
 >> iter 51000, loss: 0.259468
 >> iter 52000, loss: 0.184403
 >> iter 53000, loss: 0.330401
 >> iter 54000, loss: 0.192329
 >> iter 55000, loss: 0.188990
 >> iter 56000, loss: 0.266738
 >> iter 57000, loss: 0.231807
 >> iter 58000, loss: 0.212709
 >> iter 59000, loss: 0.225940
 >> iter 60000, loss: 0.185963
   Number of active neurons: 5
 >> iter 61000, loss: 0.278463
 >> iter 62000, loss: 0.299372
 >> iter 63000, loss: 0.252410
 >> iter 64000, loss: 0.184509
 >> iter 65000, loss: 0.148283
 >> iter 66000, loss: 0.211983
 >> iter 67000, loss: 0.345469
 >> iter 68000, loss: 0.252632
 >> iter 69000, loss: 0.244033
 >> iter 70000, loss: 0.288927
   Number of active neurons: 5
 >> iter 71000, loss: 0.223574
 >> iter 72000, loss: 0.164630
 >> iter 73000, loss: 0.144662
 >> iter 74000, loss: 0.148988
 >> iter 75000, loss: 0.230036
 >> iter 76000, loss: 0.348559
 >> iter 77000, loss: 0.371578
 >> iter 78000, loss: 0.294020
 >> iter 79000, loss: 0.228951
 >> iter 80000, loss: 0.129201
   Number of active neurons: 5
 >> iter 81000, loss: 0.140709
 >> iter 82000, loss: 0.194495
 >> iter 83000, loss: 0.183538
 >> iter 84000, loss: 0.240527
 >> iter 85000, loss: 0.237756
 >> iter 86000, loss: 0.291948
 >> iter 87000, loss: 0.243232
 >> iter 88000, loss: 0.170241
 >> iter 89000, loss: 0.331895
 >> iter 90000, loss: 0.188408
   Number of active neurons: 5
 >> iter 91000, loss: 0.146083
 >> iter 92000, loss: 0.259610
 >> iter 93000, loss: 0.253324
 >> iter 94000, loss: 0.194053
 >> iter 95000, loss: 0.162536
 >> iter 96000, loss: 0.248227
 >> iter 97000, loss: 0.185539
 >> iter 98000, loss: 0.177286
 >> iter 99000, loss: 0.166999
 >> iter 100000, loss: 0.175098
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.020729
 >> iter 2000, loss: 10.790379
 >> iter 3000, loss: 5.231338
 >> iter 4000, loss: 2.528804
 >> iter 5000, loss: 1.461869
 >> iter 6000, loss: 0.775661
 >> iter 7000, loss: 0.546095
 >> iter 8000, loss: 0.494052
 >> iter 9000, loss: 0.526785
 >> iter 10000, loss: 0.381889
   Number of active neurons: 8
 >> iter 11000, loss: 0.548696
 >> iter 12000, loss: 0.332174
 >> iter 13000, loss: 0.271670
 >> iter 14000, loss: 0.453596
 >> iter 15000, loss: 0.457302
 >> iter 16000, loss: 0.456794
 >> iter 17000, loss: 0.547460
 >> iter 18000, loss: 0.561441
 >> iter 19000, loss: 0.417482
 >> iter 20000, loss: 0.341497
   Number of active neurons: 8
 >> iter 21000, loss: 0.404671
 >> iter 22000, loss: 0.422754
 >> iter 23000, loss: 0.622451
 >> iter 24000, loss: 0.578664
 >> iter 25000, loss: 0.331596
 >> iter 26000, loss: 0.280229
 >> iter 27000, loss: 0.479989
 >> iter 28000, loss: 0.336556
 >> iter 29000, loss: 0.489290
 >> iter 30000, loss: 0.331188
   Number of active neurons: 8
 >> iter 31000, loss: 0.333540
 >> iter 32000, loss: 0.234212
 >> iter 33000, loss: 0.433725
 >> iter 34000, loss: 0.331988
 >> iter 35000, loss: 0.348482
 >> iter 36000, loss: 0.315709
 >> iter 37000, loss: 0.259040
 >> iter 38000, loss: 0.243273
 >> iter 39000, loss: 0.424404
 >> iter 40000, loss: 0.289694
   Number of active neurons: 8
 >> iter 41000, loss: 0.344871
 >> iter 42000, loss: 0.243555
 >> iter 43000, loss: 0.295558
 >> iter 44000, loss: 0.278946
 >> iter 45000, loss: 0.327625
 >> iter 46000, loss: 0.181737
 >> iter 47000, loss: 0.224509
 >> iter 48000, loss: 0.305850
 >> iter 49000, loss: 0.261366
 >> iter 50000, loss: 0.264054
   Number of active neurons: 6
 >> iter 51000, loss: 0.231484
 >> iter 52000, loss: 0.287084
 >> iter 53000, loss: 0.187304
 >> iter 54000, loss: 0.304209
 >> iter 55000, loss: 0.295870
 >> iter 56000, loss: 0.203610
 >> iter 57000, loss: 0.161318
 >> iter 58000, loss: 0.280667
 >> iter 59000, loss: 0.250137
 >> iter 60000, loss: 0.188341
   Number of active neurons: 6
 >> iter 61000, loss: 0.160271
 >> iter 62000, loss: 0.125537
 >> iter 63000, loss: 0.289503
 >> iter 64000, loss: 0.255987
 >> iter 65000, loss: 0.316882
 >> iter 66000, loss: 0.172728
 >> iter 67000, loss: 0.123516
 >> iter 68000, loss: 0.167554
 >> iter 69000, loss: 0.135075
 >> iter 70000, loss: 0.264652
   Number of active neurons: 5
 >> iter 71000, loss: 0.227509
 >> iter 72000, loss: 0.162113
 >> iter 73000, loss: 0.193165
 >> iter 74000, loss: 0.238878
 >> iter 75000, loss: 0.171414
 >> iter 76000, loss: 0.287847
 >> iter 77000, loss: 0.403293
 >> iter 78000, loss: 0.326913
 >> iter 79000, loss: 0.196145
 >> iter 80000, loss: 0.217259
   Number of active neurons: 5
 >> iter 81000, loss: 0.393978
 >> iter 82000, loss: 0.284018
 >> iter 83000, loss: 0.270773
 >> iter 84000, loss: 0.247132
 >> iter 85000, loss: 0.205285
 >> iter 86000, loss: 0.152135
 >> iter 87000, loss: 0.281096
 >> iter 88000, loss: 0.275332
 >> iter 89000, loss: 0.446900
 >> iter 90000, loss: 0.253784
   Number of active neurons: 5
 >> iter 91000, loss: 0.250142
 >> iter 92000, loss: 0.202679
 >> iter 93000, loss: 0.194265
 >> iter 94000, loss: 0.231190
 >> iter 95000, loss: 0.273294
 >> iter 96000, loss: 0.135210
 >> iter 97000, loss: 0.190813
 >> iter 98000, loss: 0.194518
 >> iter 99000, loss: 0.313772
 >> iter 100000, loss: 0.193823
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.934854
 >> iter 2000, loss: 10.628504
 >> iter 3000, loss: 5.158022
 >> iter 4000, loss: 2.521787
 >> iter 5000, loss: 1.372002
 >> iter 6000, loss: 1.031588
 >> iter 7000, loss: 0.710014
 >> iter 8000, loss: 0.615080
 >> iter 9000, loss: 0.503726
 >> iter 10000, loss: 0.686786
   Number of active neurons: 11
 >> iter 11000, loss: 0.474464
 >> iter 12000, loss: 0.450216
 >> iter 13000, loss: 0.316236
 >> iter 14000, loss: 0.332219
 >> iter 15000, loss: 0.518104
 >> iter 16000, loss: 0.594229
 >> iter 17000, loss: 0.619521
 >> iter 18000, loss: 0.597092
 >> iter 19000, loss: 0.474906
 >> iter 20000, loss: 0.252772
   Number of active neurons: 9
 >> iter 21000, loss: 0.362710
 >> iter 22000, loss: 0.269549
 >> iter 23000, loss: 0.292101
 >> iter 24000, loss: 0.214684
 >> iter 25000, loss: 0.313663
 >> iter 26000, loss: 0.257054
 >> iter 27000, loss: 0.308579
 >> iter 28000, loss: 0.356898
 >> iter 29000, loss: 0.376361
 >> iter 30000, loss: 0.254110
   Number of active neurons: 8
 >> iter 31000, loss: 0.348653
 >> iter 32000, loss: 0.285976
 >> iter 33000, loss: 0.336474
 >> iter 34000, loss: 0.267414
 >> iter 35000, loss: 0.164926
 >> iter 36000, loss: 0.230041
 >> iter 37000, loss: 0.299749
 >> iter 38000, loss: 0.413704
 >> iter 39000, loss: 0.308437
 >> iter 40000, loss: 0.345586
   Number of active neurons: 6
 >> iter 41000, loss: 0.337485
 >> iter 42000, loss: 0.219921
 >> iter 43000, loss: 0.296667
 >> iter 44000, loss: 0.257008
 >> iter 45000, loss: 0.211919
 >> iter 46000, loss: 0.219810
 >> iter 47000, loss: 0.177320
 >> iter 48000, loss: 0.319982
 >> iter 49000, loss: 0.411600
 >> iter 50000, loss: 0.405858
   Number of active neurons: 6
 >> iter 51000, loss: 0.273354
 >> iter 52000, loss: 0.271089
 >> iter 53000, loss: 0.327848
 >> iter 54000, loss: 0.245294
 >> iter 55000, loss: 0.242638
 >> iter 56000, loss: 0.291477
 >> iter 57000, loss: 0.231606
 >> iter 58000, loss: 0.399946
 >> iter 59000, loss: 0.397233
 >> iter 60000, loss: 0.335535
   Number of active neurons: 6
 >> iter 61000, loss: 0.330593
 >> iter 62000, loss: 0.279046
 >> iter 63000, loss: 0.344832
 >> iter 64000, loss: 0.424073
 >> iter 65000, loss: 0.445955
 >> iter 66000, loss: 0.411766
 >> iter 67000, loss: 0.288828
 >> iter 68000, loss: 0.442281
 >> iter 69000, loss: 0.424384
 >> iter 70000, loss: 0.273879
   Number of active neurons: 6
 >> iter 71000, loss: 0.169543
 >> iter 72000, loss: 0.242992
 >> iter 73000, loss: 0.505152
 >> iter 74000, loss: 0.337961
 >> iter 75000, loss: 0.263668
 >> iter 76000, loss: 0.366384
 >> iter 77000, loss: 0.464941
 >> iter 78000, loss: 0.387851
 >> iter 79000, loss: 0.294673
 >> iter 80000, loss: 0.300564
   Number of active neurons: 6
 >> iter 81000, loss: 0.232395
 >> iter 82000, loss: 0.408749
 >> iter 83000, loss: 0.314136
 >> iter 84000, loss: 0.323052
 >> iter 85000, loss: 0.336228
 >> iter 86000, loss: 0.243828
 >> iter 87000, loss: 0.241092
 >> iter 88000, loss: 0.218728
 >> iter 89000, loss: 0.355499
 >> iter 90000, loss: 0.275067
   Number of active neurons: 6
 >> iter 91000, loss: 0.315600
 >> iter 92000, loss: 0.358318
 >> iter 93000, loss: 0.350374
 >> iter 94000, loss: 0.296160
 >> iter 95000, loss: 0.288502
 >> iter 96000, loss: 0.228245
 >> iter 97000, loss: 0.297655
 >> iter 98000, loss: 0.275377
 >> iter 99000, loss: 0.306280
 >> iter 100000, loss: 0.177572
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.091194
 >> iter 2000, loss: 11.354172
 >> iter 3000, loss: 5.232241
 >> iter 4000, loss: 2.622389
 >> iter 5000, loss: 1.589152
 >> iter 6000, loss: 0.969049
 >> iter 7000, loss: 0.755349
 >> iter 8000, loss: 0.607394
 >> iter 9000, loss: 0.822558
 >> iter 10000, loss: 0.680289
   Number of active neurons: 7
 >> iter 11000, loss: 0.618854
 >> iter 12000, loss: 0.607564
 >> iter 13000, loss: 0.415956
 >> iter 14000, loss: 0.349445
 >> iter 15000, loss: 0.447874
 >> iter 16000, loss: 0.526611
 >> iter 17000, loss: 0.413456
 >> iter 18000, loss: 0.394504
 >> iter 19000, loss: 0.509910
 >> iter 20000, loss: 0.439724
   Number of active neurons: 7
 >> iter 21000, loss: 0.489196
 >> iter 22000, loss: 0.314169
 >> iter 23000, loss: 0.345184
 >> iter 24000, loss: 0.314372
 >> iter 25000, loss: 0.354364
 >> iter 26000, loss: 0.398662
 >> iter 27000, loss: 0.324066
 >> iter 28000, loss: 0.312004
 >> iter 29000, loss: 0.561933
 >> iter 30000, loss: 0.390880
   Number of active neurons: 7
 >> iter 31000, loss: 0.522353
 >> iter 32000, loss: 0.480263
 >> iter 33000, loss: 0.499836
 >> iter 34000, loss: 0.546976
 >> iter 35000, loss: 0.631493
 >> iter 36000, loss: 0.582216
 >> iter 37000, loss: 0.608807
 >> iter 38000, loss: 0.429682
 >> iter 39000, loss: 0.379118
 >> iter 40000, loss: 0.438012
   Number of active neurons: 7
 >> iter 41000, loss: 0.488006
 >> iter 42000, loss: 0.425029
 >> iter 43000, loss: 0.407464
 >> iter 44000, loss: 0.399621
 >> iter 45000, loss: 0.589666
 >> iter 46000, loss: 0.357386
 >> iter 47000, loss: 0.731118
 >> iter 48000, loss: 0.405056
 >> iter 49000, loss: 0.427051
 >> iter 50000, loss: 0.318010
   Number of active neurons: 7
 >> iter 51000, loss: 0.443694
 >> iter 52000, loss: 0.369156
 >> iter 53000, loss: 0.406445
 >> iter 54000, loss: 0.262913
 >> iter 55000, loss: 0.582041
 >> iter 56000, loss: 0.429000
 >> iter 57000, loss: 0.456585
 >> iter 58000, loss: 0.378629
 >> iter 59000, loss: 0.293254
 >> iter 60000, loss: 0.270442
   Number of active neurons: 7
 >> iter 61000, loss: 0.444937
 >> iter 62000, loss: 0.319749
 >> iter 63000, loss: 0.333423
 >> iter 64000, loss: 0.279300
 >> iter 65000, loss: 0.243696
 >> iter 66000, loss: 0.319250
 >> iter 67000, loss: 0.284126
 >> iter 68000, loss: 0.315610
 >> iter 69000, loss: 0.610073
 >> iter 70000, loss: 0.490245
   Number of active neurons: 7
 >> iter 71000, loss: 0.419941
 >> iter 72000, loss: 0.343072
 >> iter 73000, loss: 0.270650
 >> iter 74000, loss: 0.433964
 >> iter 75000, loss: 0.325377
 >> iter 76000, loss: 0.323583
 >> iter 77000, loss: 0.321496
 >> iter 78000, loss: 0.241377
 >> iter 79000, loss: 0.260101
 >> iter 80000, loss: 0.248956
   Number of active neurons: 7
 >> iter 81000, loss: 0.617341
 >> iter 82000, loss: 0.345833
 >> iter 83000, loss: 0.279797
 >> iter 84000, loss: 0.408809
 >> iter 85000, loss: 0.466610
 >> iter 86000, loss: 0.297121
 >> iter 87000, loss: 0.276601
 >> iter 88000, loss: 0.193991
 >> iter 89000, loss: 0.202230
 >> iter 90000, loss: 0.208822
   Number of active neurons: 7
 >> iter 91000, loss: 0.225955
 >> iter 92000, loss: 0.281890
 >> iter 93000, loss: 0.337820
 >> iter 94000, loss: 0.371768
 >> iter 95000, loss: 0.352149
 >> iter 96000, loss: 0.319542
 >> iter 97000, loss: 0.355274
 >> iter 98000, loss: 0.414533
 >> iter 99000, loss: 0.252665
 >> iter 100000, loss: 0.289683
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.071944
 >> iter 2000, loss: 13.607714
 >> iter 3000, loss: 6.869838
 >> iter 4000, loss: 3.371702
 >> iter 5000, loss: 1.547111
 >> iter 6000, loss: 0.824156
 >> iter 7000, loss: 0.437789
 >> iter 8000, loss: 0.296258
 >> iter 9000, loss: 0.355676
 >> iter 10000, loss: 0.327222
   Number of active neurons: 6
 >> iter 11000, loss: 0.267055
 >> iter 12000, loss: 0.270475
 >> iter 13000, loss: 0.247866
 >> iter 14000, loss: 0.240027
 >> iter 15000, loss: 0.214270
 >> iter 16000, loss: 0.251729
 >> iter 17000, loss: 0.278379
 >> iter 18000, loss: 0.220365
 >> iter 19000, loss: 0.265670
 >> iter 20000, loss: 0.390799
   Number of active neurons: 5
 >> iter 21000, loss: 0.272419
 >> iter 22000, loss: 0.416857
 >> iter 23000, loss: 0.379946
 >> iter 24000, loss: 0.248584
 >> iter 25000, loss: 0.346156
 >> iter 26000, loss: 0.321878
 >> iter 27000, loss: 0.266653
 >> iter 28000, loss: 0.331832
 >> iter 29000, loss: 0.228290
 >> iter 30000, loss: 0.230164
   Number of active neurons: 5
 >> iter 31000, loss: 0.264207
 >> iter 32000, loss: 0.189544
 >> iter 33000, loss: 0.186718
 >> iter 34000, loss: 0.175220
 >> iter 35000, loss: 0.275122
 >> iter 36000, loss: 0.181080
 >> iter 37000, loss: 0.120456
 >> iter 38000, loss: 0.256330
 >> iter 39000, loss: 0.352490
 >> iter 40000, loss: 0.215521
   Number of active neurons: 4
 >> iter 41000, loss: 0.217872
 >> iter 42000, loss: 0.359154
 >> iter 43000, loss: 0.263484
 >> iter 44000, loss: 0.419422
 >> iter 45000, loss: 0.442172
 >> iter 46000, loss: 0.388374
 >> iter 47000, loss: 0.347126
 >> iter 48000, loss: 0.270465
 >> iter 49000, loss: 0.234709
 >> iter 50000, loss: 0.195522
   Number of active neurons: 4
 >> iter 51000, loss: 0.187674
 >> iter 52000, loss: 0.260168
 >> iter 53000, loss: 0.205118
 >> iter 54000, loss: 0.150628
 >> iter 55000, loss: 0.313532
 >> iter 56000, loss: 0.269280
 >> iter 57000, loss: 0.286755
 >> iter 58000, loss: 0.340712
 >> iter 59000, loss: 0.267118
 >> iter 60000, loss: 0.316937
   Number of active neurons: 4
 >> iter 61000, loss: 0.260128
 >> iter 62000, loss: 0.253272
 >> iter 63000, loss: 0.379637
 >> iter 64000, loss: 0.272037
 >> iter 65000, loss: 0.201923
 >> iter 66000, loss: 0.226168
 >> iter 67000, loss: 0.333598
 >> iter 68000, loss: 0.237313
 >> iter 69000, loss: 0.268288
 >> iter 70000, loss: 0.381604
   Number of active neurons: 4
 >> iter 71000, loss: 0.297546
 >> iter 72000, loss: 0.246849
 >> iter 73000, loss: 0.238583
 >> iter 74000, loss: 0.310669
 >> iter 75000, loss: 0.377520
 >> iter 76000, loss: 0.472024
 >> iter 77000, loss: 0.317098
 >> iter 78000, loss: 0.250156
 >> iter 79000, loss: 0.231085
 >> iter 80000, loss: 0.203466
   Number of active neurons: 4
 >> iter 81000, loss: 0.251041
 >> iter 82000, loss: 0.306793
 >> iter 83000, loss: 0.330794
 >> iter 84000, loss: 0.289996
 >> iter 85000, loss: 0.310305
 >> iter 86000, loss: 0.296517
 >> iter 87000, loss: 0.214567
 >> iter 88000, loss: 0.217339
 >> iter 89000, loss: 0.326477
 >> iter 90000, loss: 0.437805
   Number of active neurons: 4
 >> iter 91000, loss: 0.264545
 >> iter 92000, loss: 0.357974
 >> iter 93000, loss: 0.293645
 >> iter 94000, loss: 0.181768
 >> iter 95000, loss: 0.162413
 >> iter 96000, loss: 0.378410
 >> iter 97000, loss: 0.233122
 >> iter 98000, loss: 0.237695
 >> iter 99000, loss: 0.162598
 >> iter 100000, loss: 0.276563
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.154019
 >> iter 2000, loss: 12.855879
 >> iter 3000, loss: 6.123473
 >> iter 4000, loss: 2.626079
 >> iter 5000, loss: 1.375387
 >> iter 6000, loss: 0.748946
 >> iter 7000, loss: 0.376121
 >> iter 8000, loss: 0.295066
 >> iter 9000, loss: 0.377038
 >> iter 10000, loss: 0.418819
   Number of active neurons: 9
 >> iter 11000, loss: 0.296586
 >> iter 12000, loss: 0.337050
 >> iter 13000, loss: 0.342436
 >> iter 14000, loss: 0.259213
 >> iter 15000, loss: 0.215842
 >> iter 16000, loss: 0.245468
 >> iter 17000, loss: 0.265850
 >> iter 18000, loss: 0.195654
 >> iter 19000, loss: 0.282094
 >> iter 20000, loss: 0.217116
   Number of active neurons: 9
 >> iter 21000, loss: 0.220710
 >> iter 22000, loss: 0.337115
 >> iter 23000, loss: 0.243889
 >> iter 24000, loss: 0.299911
 >> iter 25000, loss: 0.387780
 >> iter 26000, loss: 0.263607
 >> iter 27000, loss: 0.245598
 >> iter 28000, loss: 0.231558
 >> iter 29000, loss: 0.226502
 >> iter 30000, loss: 0.195452
   Number of active neurons: 8
 >> iter 31000, loss: 0.218449
 >> iter 32000, loss: 0.296289
 >> iter 33000, loss: 0.175718
 >> iter 34000, loss: 0.258111
 >> iter 35000, loss: 0.249952
 >> iter 36000, loss: 0.206034
 >> iter 37000, loss: 0.151924
 >> iter 38000, loss: 0.174602
 >> iter 39000, loss: 0.167047
 >> iter 40000, loss: 0.209038
   Number of active neurons: 7
 >> iter 41000, loss: 0.219342
 >> iter 42000, loss: 0.225740
 >> iter 43000, loss: 0.255429
 >> iter 44000, loss: 0.279056
 >> iter 45000, loss: 0.251053
 >> iter 46000, loss: 0.151565
 >> iter 47000, loss: 0.178368
 >> iter 48000, loss: 0.184445
 >> iter 49000, loss: 0.334133
 >> iter 50000, loss: 0.346481
   Number of active neurons: 7
 >> iter 51000, loss: 0.257420
 >> iter 52000, loss: 0.191553
 >> iter 53000, loss: 0.181758
 >> iter 54000, loss: 0.181527
 >> iter 55000, loss: 0.149638
 >> iter 56000, loss: 0.120125
 >> iter 57000, loss: 0.251456
 >> iter 58000, loss: 0.288703
 >> iter 59000, loss: 0.347779
 >> iter 60000, loss: 0.230718
   Number of active neurons: 7
 >> iter 61000, loss: 0.260239
 >> iter 62000, loss: 0.377275
 >> iter 63000, loss: 0.272639
 >> iter 64000, loss: 0.258789
 >> iter 65000, loss: 0.191704
 >> iter 66000, loss: 0.147926
 >> iter 67000, loss: 0.194908
 >> iter 68000, loss: 0.318975
 >> iter 69000, loss: 0.333598
 >> iter 70000, loss: 0.231206
   Number of active neurons: 7
 >> iter 71000, loss: 0.292132
 >> iter 72000, loss: 0.204693
 >> iter 73000, loss: 0.231511
 >> iter 74000, loss: 0.192311
 >> iter 75000, loss: 0.162940
 >> iter 76000, loss: 0.153450
 >> iter 77000, loss: 0.275127
 >> iter 78000, loss: 0.185542
 >> iter 79000, loss: 0.226705
 >> iter 80000, loss: 0.156500
   Number of active neurons: 7
 >> iter 81000, loss: 0.154189
 >> iter 82000, loss: 0.106642
 >> iter 83000, loss: 0.173084
 >> iter 84000, loss: 0.244671
 >> iter 85000, loss: 0.241324
 >> iter 86000, loss: 0.161094
 >> iter 87000, loss: 0.176841
 >> iter 88000, loss: 0.163747
 >> iter 89000, loss: 0.177518
 >> iter 90000, loss: 0.322214
   Number of active neurons: 7
 >> iter 91000, loss: 0.181488
 >> iter 92000, loss: 0.148785
 >> iter 93000, loss: 0.247101
 >> iter 94000, loss: 0.175690
 >> iter 95000, loss: 0.270377
 >> iter 96000, loss: 0.333317
 >> iter 97000, loss: 0.351859
 >> iter 98000, loss: 0.208727
 >> iter 99000, loss: 0.243544
 >> iter 100000, loss: 0.340829
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.105327
 >> iter 2000, loss: 11.888009
 >> iter 3000, loss: 5.704660
 >> iter 4000, loss: 3.097954
 >> iter 5000, loss: 1.584762
 >> iter 6000, loss: 0.837031
 >> iter 7000, loss: 0.589102
 >> iter 8000, loss: 0.629165
 >> iter 9000, loss: 0.403950
 >> iter 10000, loss: 0.544646
   Number of active neurons: 12
 >> iter 11000, loss: 0.366288
 >> iter 12000, loss: 0.514380
 >> iter 13000, loss: 0.563884
 >> iter 14000, loss: 0.344287
 >> iter 15000, loss: 0.504827
 >> iter 16000, loss: 0.498138
 >> iter 17000, loss: 0.343849
 >> iter 18000, loss: 0.343728
 >> iter 19000, loss: 0.231694
 >> iter 20000, loss: 0.228701
   Number of active neurons: 11
 >> iter 21000, loss: 0.403454
 >> iter 22000, loss: 0.297422
 >> iter 23000, loss: 0.361666
 >> iter 24000, loss: 0.293709
 >> iter 25000, loss: 0.196731
 >> iter 26000, loss: 0.269740
 >> iter 27000, loss: 0.268721
 >> iter 28000, loss: 0.344583
 >> iter 29000, loss: 0.350417
 >> iter 30000, loss: 0.339361
   Number of active neurons: 10
 >> iter 31000, loss: 0.274358
 >> iter 32000, loss: 0.222144
 >> iter 33000, loss: 0.312669
 >> iter 34000, loss: 0.224784
 >> iter 35000, loss: 0.257575
 >> iter 36000, loss: 0.280310
 >> iter 37000, loss: 0.558647
 >> iter 38000, loss: 0.558926
 >> iter 39000, loss: 0.375829
 >> iter 40000, loss: 0.280848
   Number of active neurons: 10
 >> iter 41000, loss: 0.287871
 >> iter 42000, loss: 0.214020
 >> iter 43000, loss: 0.291666
 >> iter 44000, loss: 0.358681
 >> iter 45000, loss: 0.194267
 >> iter 46000, loss: 0.169407
 >> iter 47000, loss: 0.113345
 >> iter 48000, loss: 0.233213
 >> iter 49000, loss: 0.178116
 >> iter 50000, loss: 0.162741
   Number of active neurons: 9
 >> iter 51000, loss: 0.271608
 >> iter 52000, loss: 0.219788
 >> iter 53000, loss: 0.323005
 >> iter 54000, loss: 0.273526
 >> iter 55000, loss: 0.221603
 >> iter 56000, loss: 0.144668
 >> iter 57000, loss: 0.114004
 >> iter 58000, loss: 0.246780
 >> iter 59000, loss: 0.188105
 >> iter 60000, loss: 0.244718
   Number of active neurons: 7
 >> iter 61000, loss: 0.157663
 >> iter 62000, loss: 0.222716
 >> iter 63000, loss: 0.327191
 >> iter 64000, loss: 0.211157
 >> iter 65000, loss: 0.210745
 >> iter 66000, loss: 0.188291
 >> iter 67000, loss: 0.325580
 >> iter 68000, loss: 0.189039
 >> iter 69000, loss: 0.371661
 >> iter 70000, loss: 0.432165
   Number of active neurons: 7
 >> iter 71000, loss: 0.402019
 >> iter 72000, loss: 0.299916
 >> iter 73000, loss: 0.220976
 >> iter 74000, loss: 0.345677
 >> iter 75000, loss: 0.266573
 >> iter 76000, loss: 0.308572
 >> iter 77000, loss: 0.308406
 >> iter 78000, loss: 0.251076
 >> iter 79000, loss: 0.237453
 >> iter 80000, loss: 0.267855
   Number of active neurons: 7
 >> iter 81000, loss: 0.223417
 >> iter 82000, loss: 0.164760
 >> iter 83000, loss: 0.287980
 >> iter 84000, loss: 0.198470
 >> iter 85000, loss: 0.334488
 >> iter 86000, loss: 0.324168
 >> iter 87000, loss: 0.346448
 >> iter 88000, loss: 0.212970
 >> iter 89000, loss: 0.374868
 >> iter 90000, loss: 0.331586
   Number of active neurons: 6
 >> iter 91000, loss: 0.214418
 >> iter 92000, loss: 0.204228
 >> iter 93000, loss: 0.213739
 >> iter 94000, loss: 0.179135
 >> iter 95000, loss: 0.160811
 >> iter 96000, loss: 0.278853
 >> iter 97000, loss: 0.293389
 >> iter 98000, loss: 0.195458
 >> iter 99000, loss: 0.229435
 >> iter 100000, loss: 0.237167
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.895903
 >> iter 2000, loss: 10.020704
 >> iter 3000, loss: 4.399856
 >> iter 4000, loss: 1.961816
 >> iter 5000, loss: 1.058578
 >> iter 6000, loss: 0.624337
 >> iter 7000, loss: 0.490481
 >> iter 8000, loss: 0.547803
 >> iter 9000, loss: 0.345882
 >> iter 10000, loss: 0.483299
   Number of active neurons: 8
 >> iter 11000, loss: 0.483629
 >> iter 12000, loss: 0.315929
 >> iter 13000, loss: 0.468414
 >> iter 14000, loss: 0.378461
 >> iter 15000, loss: 0.410891
 >> iter 16000, loss: 0.403675
 >> iter 17000, loss: 0.463382
 >> iter 18000, loss: 0.340163
 >> iter 19000, loss: 0.291699
 >> iter 20000, loss: 0.224540
   Number of active neurons: 8
 >> iter 21000, loss: 0.329346
 >> iter 22000, loss: 0.263361
 >> iter 23000, loss: 0.262980
 >> iter 24000, loss: 0.385815
 >> iter 25000, loss: 0.343285
 >> iter 26000, loss: 0.286742
 >> iter 27000, loss: 0.380184
 >> iter 28000, loss: 0.303972
 >> iter 29000, loss: 0.274777
 >> iter 30000, loss: 0.338709
   Number of active neurons: 8
 >> iter 31000, loss: 0.218668
 >> iter 32000, loss: 0.353791
 >> iter 33000, loss: 0.295440
 >> iter 34000, loss: 0.296316
 >> iter 35000, loss: 0.249941
 >> iter 36000, loss: 0.299307
 >> iter 37000, loss: 0.225364
 >> iter 38000, loss: 0.340078
 >> iter 39000, loss: 0.271428
 >> iter 40000, loss: 0.158679
   Number of active neurons: 8
 >> iter 41000, loss: 0.129248
 >> iter 42000, loss: 0.339516
 >> iter 43000, loss: 0.399153
 >> iter 44000, loss: 0.291715
 >> iter 45000, loss: 0.263254
 >> iter 46000, loss: 0.190617
 >> iter 47000, loss: 0.559472
 >> iter 48000, loss: 0.436260
 >> iter 49000, loss: 0.224494
 >> iter 50000, loss: 0.418787
   Number of active neurons: 8
 >> iter 51000, loss: 0.242979
 >> iter 52000, loss: 0.169374
 >> iter 53000, loss: 0.156938
 >> iter 54000, loss: 0.211171
 >> iter 55000, loss: 0.184288
 >> iter 56000, loss: 0.158314
 >> iter 57000, loss: 0.182965
 >> iter 58000, loss: 0.270767
 >> iter 59000, loss: 0.442719
 >> iter 60000, loss: 0.260654
   Number of active neurons: 8
 >> iter 61000, loss: 0.145730
 >> iter 62000, loss: 0.243794
 >> iter 63000, loss: 0.556460
 >> iter 64000, loss: 0.348483
 >> iter 65000, loss: 0.212688
 >> iter 66000, loss: 0.209397
 >> iter 67000, loss: 0.243633
 >> iter 68000, loss: 0.226703
 >> iter 69000, loss: 0.122339
 >> iter 70000, loss: 0.161553
   Number of active neurons: 6
 >> iter 71000, loss: 0.155708
 >> iter 72000, loss: 0.229405
 >> iter 73000, loss: 0.239404
 >> iter 74000, loss: 0.181676
 >> iter 75000, loss: 0.165172
 >> iter 76000, loss: 0.172435
 >> iter 77000, loss: 0.225579
 >> iter 78000, loss: 0.210611
 >> iter 79000, loss: 0.189059
 >> iter 80000, loss: 0.240516
   Number of active neurons: 4
 >> iter 81000, loss: 0.339541
 >> iter 82000, loss: 0.227133
 >> iter 83000, loss: 0.135699
 >> iter 84000, loss: 0.193636
 >> iter 85000, loss: 0.216352
 >> iter 86000, loss: 0.228486
 >> iter 87000, loss: 0.215251
 >> iter 88000, loss: 0.232201
 >> iter 89000, loss: 0.189806
 >> iter 90000, loss: 0.177616
   Number of active neurons: 4
 >> iter 91000, loss: 0.181824
 >> iter 92000, loss: 0.173604
 >> iter 93000, loss: 0.224109
 >> iter 94000, loss: 0.233754
 >> iter 95000, loss: 0.173635
 >> iter 96000, loss: 0.200598
 >> iter 97000, loss: 0.197949
 >> iter 98000, loss: 0.265137
 >> iter 99000, loss: 0.276725
 >> iter 100000, loss: 0.272507
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.023375
 >> iter 2000, loss: 11.400982
 >> iter 3000, loss: 5.511240
 >> iter 4000, loss: 2.433928
 >> iter 5000, loss: 1.364390
 >> iter 6000, loss: 0.815127
 >> iter 7000, loss: 0.846414
 >> iter 8000, loss: 0.512895
 >> iter 9000, loss: 0.452495
 >> iter 10000, loss: 0.619195
   Number of active neurons: 9
 >> iter 11000, loss: 0.416698
 >> iter 12000, loss: 0.364189
 >> iter 13000, loss: 0.370748
 >> iter 14000, loss: 0.443494
 >> iter 15000, loss: 0.386900
 >> iter 16000, loss: 0.242770
 >> iter 17000, loss: 0.300500
 >> iter 18000, loss: 0.404012
 >> iter 19000, loss: 0.443973
 >> iter 20000, loss: 0.347420
   Number of active neurons: 8
 >> iter 21000, loss: 0.469070
 >> iter 22000, loss: 0.316672
 >> iter 23000, loss: 0.451918
 >> iter 24000, loss: 0.423703
 >> iter 25000, loss: 0.261171
 >> iter 26000, loss: 0.297179
 >> iter 27000, loss: 0.492600
 >> iter 28000, loss: 0.329507
 >> iter 29000, loss: 0.241845
 >> iter 30000, loss: 0.325724
   Number of active neurons: 8
 >> iter 31000, loss: 0.233925
 >> iter 32000, loss: 0.334106
 >> iter 33000, loss: 0.276422
 >> iter 34000, loss: 0.358635
 >> iter 35000, loss: 0.244308
 >> iter 36000, loss: 0.224444
 >> iter 37000, loss: 0.184591
 >> iter 38000, loss: 0.300909
 >> iter 39000, loss: 0.210662
 >> iter 40000, loss: 0.259002
   Number of active neurons: 8
 >> iter 41000, loss: 0.296100
 >> iter 42000, loss: 0.331990
 >> iter 43000, loss: 0.192685
 >> iter 44000, loss: 0.249341
 >> iter 45000, loss: 0.292285
 >> iter 46000, loss: 0.193094
 >> iter 47000, loss: 0.326775
 >> iter 48000, loss: 0.271778
 >> iter 49000, loss: 0.216477
 >> iter 50000, loss: 0.177907
   Number of active neurons: 8
 >> iter 51000, loss: 0.307381
 >> iter 52000, loss: 0.285907
 >> iter 53000, loss: 0.389778
 >> iter 54000, loss: 0.312158
 >> iter 55000, loss: 0.447816
 >> iter 56000, loss: 0.372688
 >> iter 57000, loss: 0.419744
 >> iter 58000, loss: 0.381920
 >> iter 59000, loss: 0.328417
 >> iter 60000, loss: 0.448285
   Number of active neurons: 8
 >> iter 61000, loss: 0.260828
 >> iter 62000, loss: 0.366554
 >> iter 63000, loss: 0.381787
 >> iter 64000, loss: 0.506943
 >> iter 65000, loss: 0.409068
 >> iter 66000, loss: 0.352418
 >> iter 67000, loss: 0.287997
 >> iter 68000, loss: 0.483921
 >> iter 69000, loss: 0.339235
 >> iter 70000, loss: 0.240585
   Number of active neurons: 8
 >> iter 71000, loss: 0.288415
 >> iter 72000, loss: 0.248908
 >> iter 73000, loss: 0.345701
 >> iter 74000, loss: 0.231253
 >> iter 75000, loss: 0.246177
 >> iter 76000, loss: 0.308547
 >> iter 77000, loss: 0.403206
 >> iter 78000, loss: 0.346014
 >> iter 79000, loss: 0.363214
 >> iter 80000, loss: 0.368743
   Number of active neurons: 8
 >> iter 81000, loss: 0.333624
 >> iter 82000, loss: 0.507178
 >> iter 83000, loss: 0.451031
 >> iter 84000, loss: 0.318556
 >> iter 85000, loss: 0.298027
 >> iter 86000, loss: 0.356486
 >> iter 87000, loss: 0.303875
 >> iter 88000, loss: 0.252842
 >> iter 89000, loss: 0.551919
 >> iter 90000, loss: 0.455683
   Number of active neurons: 8
 >> iter 91000, loss: 0.355751
 >> iter 92000, loss: 0.276619
 >> iter 93000, loss: 0.317760
 >> iter 94000, loss: 0.220466
 >> iter 95000, loss: 0.296110
 >> iter 96000, loss: 0.334207
 >> iter 97000, loss: 0.299014
 >> iter 98000, loss: 0.275600
 >> iter 99000, loss: 0.199174
 >> iter 100000, loss: 0.305388
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.355746
 >> iter 2000, loss: 11.919899
 >> iter 3000, loss: 5.376383
 >> iter 4000, loss: 2.221283
 >> iter 5000, loss: 1.080807
 >> iter 6000, loss: 0.487300
 >> iter 7000, loss: 0.272477
 >> iter 8000, loss: 0.292457
 >> iter 9000, loss: 0.295166
 >> iter 10000, loss: 0.220640
   Number of active neurons: 9
 >> iter 11000, loss: 0.302038
 >> iter 12000, loss: 0.263153
 >> iter 13000, loss: 0.188309
 >> iter 14000, loss: 0.200491
 >> iter 15000, loss: 0.239186
 >> iter 16000, loss: 0.180078
 >> iter 17000, loss: 0.291728
 >> iter 18000, loss: 0.250398
 >> iter 19000, loss: 0.404255
 >> iter 20000, loss: 0.287607
   Number of active neurons: 8
 >> iter 21000, loss: 0.352636
 >> iter 22000, loss: 0.239060
 >> iter 23000, loss: 0.353915
 >> iter 24000, loss: 0.216876
 >> iter 25000, loss: 0.334241
 >> iter 26000, loss: 0.240506
 >> iter 27000, loss: 0.272514
 >> iter 28000, loss: 0.214059
 >> iter 29000, loss: 0.469696
 >> iter 30000, loss: 0.254682
   Number of active neurons: 8
 >> iter 31000, loss: 0.384632
 >> iter 32000, loss: 0.367129
 >> iter 33000, loss: 0.340582
 >> iter 34000, loss: 0.294413
 >> iter 35000, loss: 0.284969
 >> iter 36000, loss: 0.359511
 >> iter 37000, loss: 0.262958
 >> iter 38000, loss: 0.185815
 >> iter 39000, loss: 0.344436
 >> iter 40000, loss: 0.273960
   Number of active neurons: 8
 >> iter 41000, loss: 0.205563
 >> iter 42000, loss: 0.140350
 >> iter 43000, loss: 0.288552
 >> iter 44000, loss: 0.237463
 >> iter 45000, loss: 0.232913
 >> iter 46000, loss: 0.216597
 >> iter 47000, loss: 0.252138
 >> iter 48000, loss: 0.192370
 >> iter 49000, loss: 0.258204
 >> iter 50000, loss: 0.199218
   Number of active neurons: 7
 >> iter 51000, loss: 0.295105
 >> iter 52000, loss: 0.213207
 >> iter 53000, loss: 0.275898
 >> iter 54000, loss: 0.248718
 >> iter 55000, loss: 0.381824
 >> iter 56000, loss: 0.247253
 >> iter 57000, loss: 0.160323
 >> iter 58000, loss: 0.268403
 >> iter 59000, loss: 0.308512
 >> iter 60000, loss: 0.245626
   Number of active neurons: 6
 >> iter 61000, loss: 0.249110
 >> iter 62000, loss: 0.332516
 >> iter 63000, loss: 0.166329
 >> iter 64000, loss: 0.199739
 >> iter 65000, loss: 0.187764
 >> iter 66000, loss: 0.297448
 >> iter 67000, loss: 0.287393
 >> iter 68000, loss: 0.352531
 >> iter 69000, loss: 0.314876
 >> iter 70000, loss: 0.237732
   Number of active neurons: 6
 >> iter 71000, loss: 0.147230
 >> iter 72000, loss: 0.243415
 >> iter 73000, loss: 0.181658
 >> iter 74000, loss: 0.449758
 >> iter 75000, loss: 0.421793
 >> iter 76000, loss: 0.271461
 >> iter 77000, loss: 0.405360
 >> iter 78000, loss: 0.236900
 >> iter 79000, loss: 0.172908
 >> iter 80000, loss: 0.268518
   Number of active neurons: 6
 >> iter 81000, loss: 0.288595
 >> iter 82000, loss: 0.166112
 >> iter 83000, loss: 0.235472
 >> iter 84000, loss: 0.184695
 >> iter 85000, loss: 0.159139
 >> iter 86000, loss: 0.142319
 >> iter 87000, loss: 0.249850
 >> iter 88000, loss: 0.434882
 >> iter 89000, loss: 0.263920
 >> iter 90000, loss: 0.331659
   Number of active neurons: 6
 >> iter 91000, loss: 0.297897
 >> iter 92000, loss: 0.372264
 >> iter 93000, loss: 0.433498
 >> iter 94000, loss: 0.278797
 >> iter 95000, loss: 0.275917
 >> iter 96000, loss: 0.330678
 >> iter 97000, loss: 0.188153
 >> iter 98000, loss: 0.141930
 >> iter 99000, loss: 0.240701
 >> iter 100000, loss: 0.275689
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.964497
 >> iter 2000, loss: 11.079364
 >> iter 3000, loss: 5.341547
 >> iter 4000, loss: 2.331955
 >> iter 5000, loss: 1.226130
 >> iter 6000, loss: 1.110655
 >> iter 7000, loss: 0.623739
 >> iter 8000, loss: 0.502576
 >> iter 9000, loss: 0.386145
 >> iter 10000, loss: 0.366051
   Number of active neurons: 11
 >> iter 11000, loss: 0.588151
 >> iter 12000, loss: 0.415427
 >> iter 13000, loss: 0.411485
 >> iter 14000, loss: 0.420183
 >> iter 15000, loss: 0.207925
 >> iter 16000, loss: 0.200519
 >> iter 17000, loss: 0.273022
 >> iter 18000, loss: 0.206771
 >> iter 19000, loss: 0.153304
 >> iter 20000, loss: 0.177535
   Number of active neurons: 10
 >> iter 21000, loss: 0.130234
 >> iter 22000, loss: 0.246296
 >> iter 23000, loss: 0.164998
 >> iter 24000, loss: 0.538888
 >> iter 25000, loss: 0.269929
 >> iter 26000, loss: 0.264475
 >> iter 27000, loss: 0.196846
 >> iter 28000, loss: 0.215986
 >> iter 29000, loss: 0.266367
 >> iter 30000, loss: 0.349321
   Number of active neurons: 9
 >> iter 31000, loss: 0.261328
 >> iter 32000, loss: 0.170002
 >> iter 33000, loss: 0.199609
 >> iter 34000, loss: 0.222547
 >> iter 35000, loss: 0.139654
 >> iter 36000, loss: 0.282882
 >> iter 37000, loss: 0.198937
 >> iter 38000, loss: 0.254685
 >> iter 39000, loss: 0.338848
 >> iter 40000, loss: 0.229421
   Number of active neurons: 9
 >> iter 41000, loss: 0.146712
 >> iter 42000, loss: 0.267654
 >> iter 43000, loss: 0.298439
 >> iter 44000, loss: 0.180983
 >> iter 45000, loss: 0.206602
 >> iter 46000, loss: 0.178048
 >> iter 47000, loss: 0.281435
 >> iter 48000, loss: 0.250680
 >> iter 49000, loss: 0.240558
 >> iter 50000, loss: 0.260050
   Number of active neurons: 8
 >> iter 51000, loss: 0.202850
 >> iter 52000, loss: 0.156679
 >> iter 53000, loss: 0.242207
 >> iter 54000, loss: 0.167996
 >> iter 55000, loss: 0.145708
 >> iter 56000, loss: 0.202708
 >> iter 57000, loss: 0.322741
 >> iter 58000, loss: 0.171781
 >> iter 59000, loss: 0.220823
 >> iter 60000, loss: 0.129045
   Number of active neurons: 7
 >> iter 61000, loss: 0.176113
 >> iter 62000, loss: 0.116876
 >> iter 63000, loss: 0.375916
 >> iter 64000, loss: 0.265087
 >> iter 65000, loss: 0.422445
 >> iter 66000, loss: 0.274037
 >> iter 67000, loss: 0.176346
 >> iter 68000, loss: 0.308873
 >> iter 69000, loss: 0.342477
 >> iter 70000, loss: 0.239895
   Number of active neurons: 7
 >> iter 71000, loss: 0.143401
 >> iter 72000, loss: 0.172439
 >> iter 73000, loss: 0.142343
 >> iter 74000, loss: 0.119680
 >> iter 75000, loss: 0.126117
 >> iter 76000, loss: 0.147058
 >> iter 77000, loss: 0.360551
 >> iter 78000, loss: 0.265552
 >> iter 79000, loss: 0.185809
 >> iter 80000, loss: 0.187018
   Number of active neurons: 7
 >> iter 81000, loss: 0.146184
 >> iter 82000, loss: 0.109223
 >> iter 83000, loss: 0.221730
 >> iter 84000, loss: 0.498042
 >> iter 85000, loss: 0.274049
 >> iter 86000, loss: 0.444512
 >> iter 87000, loss: 0.295685
 >> iter 88000, loss: 0.211348
 >> iter 89000, loss: 0.187154
 >> iter 90000, loss: 0.126351
   Number of active neurons: 6
 >> iter 91000, loss: 0.199297
 >> iter 92000, loss: 0.264755
 >> iter 93000, loss: 0.170799
 >> iter 94000, loss: 0.216489
 >> iter 95000, loss: 0.142025
 >> iter 96000, loss: 0.136521
 >> iter 97000, loss: 0.226843
 >> iter 98000, loss: 0.196805
 >> iter 99000, loss: 0.176821
 >> iter 100000, loss: 0.194553
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.985080
 >> iter 2000, loss: 13.314442
 >> iter 3000, loss: 9.187344
 >> iter 4000, loss: 4.797882
 >> iter 5000, loss: 2.495807
 >> iter 6000, loss: 1.271936
 >> iter 7000, loss: 0.755703
 >> iter 8000, loss: 0.488416
 >> iter 9000, loss: 0.466491
 >> iter 10000, loss: 0.291294
   Number of active neurons: 7
 >> iter 11000, loss: 0.278657
 >> iter 12000, loss: 0.202610
 >> iter 13000, loss: 0.279569
 >> iter 14000, loss: 0.228984
 >> iter 15000, loss: 0.195906
 >> iter 16000, loss: 0.207891
 >> iter 17000, loss: 0.214393
 >> iter 18000, loss: 0.217335
 >> iter 19000, loss: 0.260844
 >> iter 20000, loss: 0.188962
   Number of active neurons: 7
 >> iter 21000, loss: 0.200775
 >> iter 22000, loss: 0.174415
 >> iter 23000, loss: 0.198822
 >> iter 24000, loss: 0.116024
 >> iter 25000, loss: 0.284116
 >> iter 26000, loss: 0.263846
 >> iter 27000, loss: 0.195594
 >> iter 28000, loss: 0.154938
 >> iter 29000, loss: 0.400118
 >> iter 30000, loss: 0.332470
   Number of active neurons: 7
 >> iter 31000, loss: 0.226442
 >> iter 32000, loss: 0.238770
 >> iter 33000, loss: 0.170406
 >> iter 34000, loss: 0.209511
 >> iter 35000, loss: 0.308936
 >> iter 36000, loss: 0.202207
 >> iter 37000, loss: 0.308874
 >> iter 38000, loss: 0.165072
 >> iter 39000, loss: 0.157462
 >> iter 40000, loss: 0.175413
   Number of active neurons: 7
 >> iter 41000, loss: 0.202977
 >> iter 42000, loss: 0.332065
 >> iter 43000, loss: 0.262541
 >> iter 44000, loss: 0.235789
 >> iter 45000, loss: 0.181854
 >> iter 46000, loss: 0.105602
 >> iter 47000, loss: 0.141938
 >> iter 48000, loss: 0.319673
 >> iter 49000, loss: 0.236367
 >> iter 50000, loss: 0.234843
   Number of active neurons: 7
 >> iter 51000, loss: 0.249510
 >> iter 52000, loss: 0.479036
 >> iter 53000, loss: 0.266180
 >> iter 54000, loss: 0.193522
 >> iter 55000, loss: 0.248425
 >> iter 56000, loss: 0.251720
 >> iter 57000, loss: 0.330925
 >> iter 58000, loss: 0.252524
 >> iter 59000, loss: 0.210117
 >> iter 60000, loss: 0.231107
   Number of active neurons: 7
 >> iter 61000, loss: 0.164368
 >> iter 62000, loss: 0.150747
 >> iter 63000, loss: 0.223061
 >> iter 64000, loss: 0.208648
 >> iter 65000, loss: 0.148139
 >> iter 66000, loss: 0.241079
 >> iter 67000, loss: 0.303302
 >> iter 68000, loss: 0.256242
 >> iter 69000, loss: 0.218310
 >> iter 70000, loss: 0.195831
   Number of active neurons: 7
 >> iter 71000, loss: 0.226640
 >> iter 72000, loss: 0.215528
 >> iter 73000, loss: 0.159184
 >> iter 74000, loss: 0.208039
 >> iter 75000, loss: 0.213144
 >> iter 76000, loss: 0.193496
 >> iter 77000, loss: 0.297500
 >> iter 78000, loss: 0.318688
 >> iter 79000, loss: 0.231580
 >> iter 80000, loss: 0.176856
   Number of active neurons: 7
 >> iter 81000, loss: 0.176295
 >> iter 82000, loss: 0.274886
 >> iter 83000, loss: 0.283916
 >> iter 84000, loss: 0.243597
 >> iter 85000, loss: 0.212705
 >> iter 86000, loss: 0.197094
 >> iter 87000, loss: 0.279144
 >> iter 88000, loss: 0.290306
 >> iter 89000, loss: 0.173058
 >> iter 90000, loss: 0.150275
   Number of active neurons: 7
 >> iter 91000, loss: 0.173255
 >> iter 92000, loss: 0.212949
 >> iter 93000, loss: 0.306577
 >> iter 94000, loss: 0.307363
 >> iter 95000, loss: 0.305519
 >> iter 96000, loss: 0.176660
 >> iter 97000, loss: 0.147233
 >> iter 98000, loss: 0.171650
 >> iter 99000, loss: 0.139381
 >> iter 100000, loss: 0.214147
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.018803
 >> iter 2000, loss: 10.719014
 >> iter 3000, loss: 4.967815
 >> iter 4000, loss: 2.237336
 >> iter 5000, loss: 1.180124
 >> iter 6000, loss: 0.673233
 >> iter 7000, loss: 0.455070
 >> iter 8000, loss: 0.358396
 >> iter 9000, loss: 0.330381
 >> iter 10000, loss: 0.259086
   Number of active neurons: 9
 >> iter 11000, loss: 0.351772
 >> iter 12000, loss: 0.536193
 >> iter 13000, loss: 0.398640
 >> iter 14000, loss: 0.397264
 >> iter 15000, loss: 0.337993
 >> iter 16000, loss: 0.294067
 >> iter 17000, loss: 0.339051
 >> iter 18000, loss: 0.246462
 >> iter 19000, loss: 0.260441
 >> iter 20000, loss: 0.217086
   Number of active neurons: 9
 >> iter 21000, loss: 0.339670
 >> iter 22000, loss: 0.309231
 >> iter 23000, loss: 0.371788
 >> iter 24000, loss: 0.216979
 >> iter 25000, loss: 0.322876
 >> iter 26000, loss: 0.256461
 >> iter 27000, loss: 0.204322
 >> iter 28000, loss: 0.189803
 >> iter 29000, loss: 0.268215
 >> iter 30000, loss: 0.236542
   Number of active neurons: 9
 >> iter 31000, loss: 0.274595
 >> iter 32000, loss: 0.229659
 >> iter 33000, loss: 0.229724
 >> iter 34000, loss: 0.328320
 >> iter 35000, loss: 0.306860
 >> iter 36000, loss: 0.301124
 >> iter 37000, loss: 0.278235
 >> iter 38000, loss: 0.259927
 >> iter 39000, loss: 0.308416
 >> iter 40000, loss: 0.279738
   Number of active neurons: 8
 >> iter 41000, loss: 0.185763
 >> iter 42000, loss: 0.247557
 >> iter 43000, loss: 0.231540
 >> iter 44000, loss: 0.173992
 >> iter 45000, loss: 0.273265
 >> iter 46000, loss: 0.211096
 >> iter 47000, loss: 0.360097
 >> iter 48000, loss: 0.243639
 >> iter 49000, loss: 0.341043
 >> iter 50000, loss: 0.305314
   Number of active neurons: 7
 >> iter 51000, loss: 0.227656
 >> iter 52000, loss: 0.180627
 >> iter 53000, loss: 0.190615
 >> iter 54000, loss: 0.215956
 >> iter 55000, loss: 0.219115
 >> iter 56000, loss: 0.202849
 >> iter 57000, loss: 0.200446
 >> iter 58000, loss: 0.313601
 >> iter 59000, loss: 0.421238
 >> iter 60000, loss: 0.570954
   Number of active neurons: 7
 >> iter 61000, loss: 0.406230
 >> iter 62000, loss: 0.353485
 >> iter 63000, loss: 0.238930
 >> iter 64000, loss: 0.216381
 >> iter 65000, loss: 0.393305
 >> iter 66000, loss: 0.361144
 >> iter 67000, loss: 0.295243
 >> iter 68000, loss: 0.258346
 >> iter 69000, loss: 0.192411
 >> iter 70000, loss: 0.344036
   Number of active neurons: 7
 >> iter 71000, loss: 0.324040
 >> iter 72000, loss: 0.245346
 >> iter 73000, loss: 0.324343
 >> iter 74000, loss: 0.299665
 >> iter 75000, loss: 0.303524
 >> iter 76000, loss: 0.278275
 >> iter 77000, loss: 0.312372
 >> iter 78000, loss: 0.199713
 >> iter 79000, loss: 0.194077
 >> iter 80000, loss: 0.174744
   Number of active neurons: 6
 >> iter 81000, loss: 0.249948
 >> iter 82000, loss: 0.207227
 >> iter 83000, loss: 0.305576
 >> iter 84000, loss: 0.363398
 >> iter 85000, loss: 0.284107
 >> iter 86000, loss: 0.401283
 >> iter 87000, loss: 0.391456
 >> iter 88000, loss: 0.239657
 >> iter 89000, loss: 0.266628
 >> iter 90000, loss: 0.352443
   Number of active neurons: 5
 >> iter 91000, loss: 0.213249
 >> iter 92000, loss: 0.147752
 >> iter 93000, loss: 0.129531
 >> iter 94000, loss: 0.250414
 >> iter 95000, loss: 0.349764
 >> iter 96000, loss: 0.276944
 >> iter 97000, loss: 0.329976
 >> iter 98000, loss: 0.294458
 >> iter 99000, loss: 0.272216
 >> iter 100000, loss: 0.413637
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.845120
 >> iter 2000, loss: 10.806429
 >> iter 3000, loss: 4.893623
 >> iter 4000, loss: 2.339272
 >> iter 5000, loss: 1.164994
 >> iter 6000, loss: 0.610513
 >> iter 7000, loss: 0.424054
 >> iter 8000, loss: 0.283662
 >> iter 9000, loss: 0.332069
 >> iter 10000, loss: 0.468482
   Number of active neurons: 9
 >> iter 11000, loss: 0.260027
 >> iter 12000, loss: 0.484231
 >> iter 13000, loss: 0.323095
 >> iter 14000, loss: 0.230190
 >> iter 15000, loss: 0.288416
 >> iter 16000, loss: 0.347152
 >> iter 17000, loss: 0.526599
 >> iter 18000, loss: 0.446523
 >> iter 19000, loss: 0.376117
 >> iter 20000, loss: 0.245317
   Number of active neurons: 9
 >> iter 21000, loss: 0.275848
 >> iter 22000, loss: 0.244143
 >> iter 23000, loss: 0.279487
 >> iter 24000, loss: 0.261657
 >> iter 25000, loss: 0.305365
 >> iter 26000, loss: 0.383684
 >> iter 27000, loss: 0.412404
 >> iter 28000, loss: 0.318530
 >> iter 29000, loss: 0.328468
 >> iter 30000, loss: 0.207275
   Number of active neurons: 9
 >> iter 31000, loss: 0.244119
 >> iter 32000, loss: 0.327117
 >> iter 33000, loss: 0.270692
 >> iter 34000, loss: 0.292626
 >> iter 35000, loss: 0.211409
 >> iter 36000, loss: 0.276442
 >> iter 37000, loss: 0.315392
 >> iter 38000, loss: 0.393156
 >> iter 39000, loss: 0.462387
 >> iter 40000, loss: 0.337733
   Number of active neurons: 8
 >> iter 41000, loss: 0.394275
 >> iter 42000, loss: 0.388817
 >> iter 43000, loss: 0.351619
 >> iter 44000, loss: 0.287369
 >> iter 45000, loss: 0.281887
 >> iter 46000, loss: 0.352758
 >> iter 47000, loss: 0.446407
 >> iter 48000, loss: 0.288570
 >> iter 49000, loss: 0.353909
 >> iter 50000, loss: 0.261057
   Number of active neurons: 8
 >> iter 51000, loss: 0.275503
 >> iter 52000, loss: 0.247708
 >> iter 53000, loss: 0.270298
 >> iter 54000, loss: 0.240608
 >> iter 55000, loss: 0.291729
 >> iter 56000, loss: 0.345408
 >> iter 57000, loss: 0.234930
 >> iter 58000, loss: 0.304290
 >> iter 59000, loss: 0.431710
 >> iter 60000, loss: 0.269308
   Number of active neurons: 7
 >> iter 61000, loss: 0.444344
 >> iter 62000, loss: 0.267013
 >> iter 63000, loss: 0.206085
 >> iter 64000, loss: 0.165702
 >> iter 65000, loss: 0.239249
 >> iter 66000, loss: 0.284955
 >> iter 67000, loss: 0.368918
 >> iter 68000, loss: 0.289217
 >> iter 69000, loss: 0.211034
 >> iter 70000, loss: 0.256272
   Number of active neurons: 6
 >> iter 71000, loss: 0.285097
 >> iter 72000, loss: 0.319677
 >> iter 73000, loss: 0.342625
 >> iter 74000, loss: 0.326209
 >> iter 75000, loss: 0.277792
 >> iter 76000, loss: 0.246094
 >> iter 77000, loss: 0.224502
 >> iter 78000, loss: 0.249315
 >> iter 79000, loss: 0.373676
 >> iter 80000, loss: 0.359346
   Number of active neurons: 6
 >> iter 81000, loss: 0.407214
 >> iter 82000, loss: 0.330391
 >> iter 83000, loss: 0.328677
 >> iter 84000, loss: 0.296568
 >> iter 85000, loss: 0.204285
 >> iter 86000, loss: 0.274555
 >> iter 87000, loss: 0.269980
 >> iter 88000, loss: 0.240853
 >> iter 89000, loss: 0.181662
 >> iter 90000, loss: 0.213631
   Number of active neurons: 6
 >> iter 91000, loss: 0.131756
 >> iter 92000, loss: 0.201236
 >> iter 93000, loss: 0.272493
 >> iter 94000, loss: 0.380700
 >> iter 95000, loss: 0.240390
 >> iter 96000, loss: 0.261996
 >> iter 97000, loss: 0.169335
 >> iter 98000, loss: 0.203453
 >> iter 99000, loss: 0.200682
 >> iter 100000, loss: 0.167312
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.082144
 >> iter 2000, loss: 11.135338
 >> iter 3000, loss: 5.354604
 >> iter 4000, loss: 2.530523
 >> iter 5000, loss: 1.655138
 >> iter 6000, loss: 1.078223
 >> iter 7000, loss: 0.741900
 >> iter 8000, loss: 0.565152
 >> iter 9000, loss: 0.451876
 >> iter 10000, loss: 0.555677
   Number of active neurons: 7
 >> iter 11000, loss: 0.460059
 >> iter 12000, loss: 0.501686
 >> iter 13000, loss: 0.624297
 >> iter 14000, loss: 0.711431
 >> iter 15000, loss: 0.661579
 >> iter 16000, loss: 0.439691
 >> iter 17000, loss: 0.358048
 >> iter 18000, loss: 0.521242
 >> iter 19000, loss: 0.458498
 >> iter 20000, loss: 0.522568
   Number of active neurons: 7
 >> iter 21000, loss: 0.517472
 >> iter 22000, loss: 0.718168
 >> iter 23000, loss: 0.467127
 >> iter 24000, loss: 0.391213
 >> iter 25000, loss: 0.409598
 >> iter 26000, loss: 0.397934
 >> iter 27000, loss: 0.470660
 >> iter 28000, loss: 0.656421
 >> iter 29000, loss: 0.565732
 >> iter 30000, loss: 0.427936
   Number of active neurons: 7
 >> iter 31000, loss: 0.407091
 >> iter 32000, loss: 0.375474
 >> iter 33000, loss: 0.474909
 >> iter 34000, loss: 0.597239
 >> iter 35000, loss: 0.423345
 >> iter 36000, loss: 0.448891
 >> iter 37000, loss: 0.365608
 >> iter 38000, loss: 0.298508
 >> iter 39000, loss: 0.504397
 >> iter 40000, loss: 0.395082
   Number of active neurons: 7
 >> iter 41000, loss: 0.332681
 >> iter 42000, loss: 0.481558
 >> iter 43000, loss: 0.416288
 >> iter 44000, loss: 0.426317
 >> iter 45000, loss: 0.360866
 >> iter 46000, loss: 0.392612
 >> iter 47000, loss: 0.358343
 >> iter 48000, loss: 0.322139
 >> iter 49000, loss: 0.453992
 >> iter 50000, loss: 0.540964
   Number of active neurons: 7
 >> iter 51000, loss: 0.612460
 >> iter 52000, loss: 0.417910
 >> iter 53000, loss: 0.372852
 >> iter 54000, loss: 0.272199
 >> iter 55000, loss: 0.317194
 >> iter 56000, loss: 0.286259
 >> iter 57000, loss: 0.413732
 >> iter 58000, loss: 0.422882
 >> iter 59000, loss: 0.393655
 >> iter 60000, loss: 0.433866
   Number of active neurons: 7
 >> iter 61000, loss: 0.488286
 >> iter 62000, loss: 0.550046
 >> iter 63000, loss: 0.591427
 >> iter 64000, loss: 0.499732
 >> iter 65000, loss: 0.256295
 >> iter 66000, loss: 0.288597
 >> iter 67000, loss: 0.332984
 >> iter 68000, loss: 0.331217
 >> iter 69000, loss: 0.479827
 >> iter 70000, loss: 0.358590
   Number of active neurons: 6
 >> iter 71000, loss: 0.323491
 >> iter 72000, loss: 0.290684
 >> iter 73000, loss: 0.268740
 >> iter 74000, loss: 0.291141
 >> iter 75000, loss: 0.368649
 >> iter 76000, loss: 0.290212
 >> iter 77000, loss: 0.368155
 >> iter 78000, loss: 0.397723
 >> iter 79000, loss: 0.485397
 >> iter 80000, loss: 0.453626
   Number of active neurons: 6
 >> iter 81000, loss: 0.514906
 >> iter 82000, loss: 0.303174
 >> iter 83000, loss: 0.359015
 >> iter 84000, loss: 0.430620
 >> iter 85000, loss: 0.522180
 >> iter 86000, loss: 0.565197
 >> iter 87000, loss: 0.490428
 >> iter 88000, loss: 0.330463
 >> iter 89000, loss: 0.300560
 >> iter 90000, loss: 0.429568
   Number of active neurons: 6
 >> iter 91000, loss: 0.324748
 >> iter 92000, loss: 0.377728
 >> iter 93000, loss: 0.434292
 >> iter 94000, loss: 0.360434
 >> iter 95000, loss: 0.451407
 >> iter 96000, loss: 0.494411
 >> iter 97000, loss: 0.522011
 >> iter 98000, loss: 0.390875
 >> iter 99000, loss: 0.349156
 >> iter 100000, loss: 0.428157
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.043863
 >> iter 2000, loss: 11.742490
 >> iter 3000, loss: 5.591206
 >> iter 4000, loss: 2.374078
 >> iter 5000, loss: 1.138749
 >> iter 6000, loss: 0.688374
 >> iter 7000, loss: 0.602133
 >> iter 8000, loss: 0.417763
 >> iter 9000, loss: 0.395289
 >> iter 10000, loss: 0.420344
   Number of active neurons: 10
 >> iter 11000, loss: 0.502560
 >> iter 12000, loss: 0.467956
 >> iter 13000, loss: 0.257628
 >> iter 14000, loss: 0.315227
 >> iter 15000, loss: 0.237210
 >> iter 16000, loss: 0.351936
 >> iter 17000, loss: 0.266545
 >> iter 18000, loss: 0.215356
 >> iter 19000, loss: 0.257487
 >> iter 20000, loss: 0.209119
   Number of active neurons: 9
 >> iter 21000, loss: 0.436270
 >> iter 22000, loss: 0.304810
 >> iter 23000, loss: 0.347629
 >> iter 24000, loss: 0.350825
 >> iter 25000, loss: 0.401952
 >> iter 26000, loss: 0.286184
 >> iter 27000, loss: 0.329817
 >> iter 28000, loss: 0.333342
 >> iter 29000, loss: 0.512238
 >> iter 30000, loss: 0.361990
   Number of active neurons: 8
 >> iter 31000, loss: 0.454968
 >> iter 32000, loss: 0.359655
 >> iter 33000, loss: 0.223351
 >> iter 34000, loss: 0.241059
 >> iter 35000, loss: 0.289965
 >> iter 36000, loss: 0.292461
 >> iter 37000, loss: 0.237808
 >> iter 38000, loss: 0.234292
 >> iter 39000, loss: 0.192782
 >> iter 40000, loss: 0.206460
   Number of active neurons: 8
 >> iter 41000, loss: 0.224551
 >> iter 42000, loss: 0.321885
 >> iter 43000, loss: 0.377393
 >> iter 44000, loss: 0.373295
 >> iter 45000, loss: 0.259390
 >> iter 46000, loss: 0.300984
 >> iter 47000, loss: 0.207811
 >> iter 48000, loss: 0.322408
 >> iter 49000, loss: 0.251688
 >> iter 50000, loss: 0.320734
   Number of active neurons: 8
 >> iter 51000, loss: 0.226791
 >> iter 52000, loss: 0.212917
 >> iter 53000, loss: 0.394008
 >> iter 54000, loss: 0.229584
 >> iter 55000, loss: 0.265982
 >> iter 56000, loss: 0.180190
 >> iter 57000, loss: 0.338509
 >> iter 58000, loss: 0.242955
 >> iter 59000, loss: 0.282073
 >> iter 60000, loss: 0.231012
   Number of active neurons: 7
 >> iter 61000, loss: 0.178550
 >> iter 62000, loss: 0.186055
 >> iter 63000, loss: 0.146710
 >> iter 64000, loss: 0.180217
 >> iter 65000, loss: 0.336110
 >> iter 66000, loss: 0.260398
 >> iter 67000, loss: 0.281587
 >> iter 68000, loss: 0.402066
 >> iter 69000, loss: 0.280979
 >> iter 70000, loss: 0.329718
   Number of active neurons: 6
 >> iter 71000, loss: 0.354966
 >> iter 72000, loss: 0.233657
 >> iter 73000, loss: 0.196181
 >> iter 74000, loss: 0.196225
 >> iter 75000, loss: 0.134952
 >> iter 76000, loss: 0.178522
 >> iter 77000, loss: 0.222315
 >> iter 78000, loss: 0.204536
 >> iter 79000, loss: 0.241304
 >> iter 80000, loss: 0.238191
   Number of active neurons: 6
 >> iter 81000, loss: 0.255912
 >> iter 82000, loss: 0.158974
 >> iter 83000, loss: 0.167048
 >> iter 84000, loss: 0.106203
 >> iter 85000, loss: 0.120753
 >> iter 86000, loss: 0.161231
 >> iter 87000, loss: 0.117767
 >> iter 88000, loss: 0.166121
 >> iter 89000, loss: 0.321657
 >> iter 90000, loss: 0.192332
   Number of active neurons: 6
 >> iter 91000, loss: 0.297180
 >> iter 92000, loss: 0.221641
 >> iter 93000, loss: 0.196133
 >> iter 94000, loss: 0.188094
 >> iter 95000, loss: 0.130880
 >> iter 96000, loss: 0.289422
 >> iter 97000, loss: 0.385906
 >> iter 98000, loss: 0.212505
 >> iter 99000, loss: 0.191673
 >> iter 100000, loss: 0.255616
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.262469
 >> iter 2000, loss: 10.719824
 >> iter 3000, loss: 5.012690
 >> iter 4000, loss: 2.456745
 >> iter 5000, loss: 1.406852
 >> iter 6000, loss: 0.705724
 >> iter 7000, loss: 0.620287
 >> iter 8000, loss: 0.775477
 >> iter 9000, loss: 0.505317
 >> iter 10000, loss: 0.569641
   Number of active neurons: 8
 >> iter 11000, loss: 0.631689
 >> iter 12000, loss: 0.491327
 >> iter 13000, loss: 0.511581
 >> iter 14000, loss: 0.604597
 >> iter 15000, loss: 0.499180
 >> iter 16000, loss: 0.409806
 >> iter 17000, loss: 0.381059
 >> iter 18000, loss: 0.228428
 >> iter 19000, loss: 0.303049
 >> iter 20000, loss: 0.375460
   Number of active neurons: 8
 >> iter 21000, loss: 0.311064
 >> iter 22000, loss: 0.322075
 >> iter 23000, loss: 0.328730
 >> iter 24000, loss: 0.438161
 >> iter 25000, loss: 0.437975
 >> iter 26000, loss: 0.403339
 >> iter 27000, loss: 0.450629
 >> iter 28000, loss: 0.510879
 >> iter 29000, loss: 0.383556
 >> iter 30000, loss: 0.306977
   Number of active neurons: 7
 >> iter 31000, loss: 0.247408
 >> iter 32000, loss: 0.227954
 >> iter 33000, loss: 0.410415
 >> iter 34000, loss: 0.520741
 >> iter 35000, loss: 0.344132
 >> iter 36000, loss: 0.455894
 >> iter 37000, loss: 0.506234
 >> iter 38000, loss: 0.326299
 >> iter 39000, loss: 0.365897
 >> iter 40000, loss: 0.300944
   Number of active neurons: 7
 >> iter 41000, loss: 0.194322
 >> iter 42000, loss: 0.393793
 >> iter 43000, loss: 0.290328
 >> iter 44000, loss: 0.356197
 >> iter 45000, loss: 0.275918
 >> iter 46000, loss: 0.444528
 >> iter 47000, loss: 0.326853
 >> iter 48000, loss: 0.369062
 >> iter 49000, loss: 0.295680
 >> iter 50000, loss: 0.255602
   Number of active neurons: 7
 >> iter 51000, loss: 0.292635
 >> iter 52000, loss: 0.371255
 >> iter 53000, loss: 0.310199
 >> iter 54000, loss: 0.368111
 >> iter 55000, loss: 0.414109
 >> iter 56000, loss: 0.404786
 >> iter 57000, loss: 0.350217
 >> iter 58000, loss: 0.430328
 >> iter 59000, loss: 0.383088
 >> iter 60000, loss: 0.465988
   Number of active neurons: 7
 >> iter 61000, loss: 0.508694
 >> iter 62000, loss: 0.534082
 >> iter 63000, loss: 0.369790
 >> iter 64000, loss: 0.293176
 >> iter 65000, loss: 0.520547
 >> iter 66000, loss: 0.412725
 >> iter 67000, loss: 0.352256
 >> iter 68000, loss: 0.316419
 >> iter 69000, loss: 0.340558
 >> iter 70000, loss: 0.280893
   Number of active neurons: 7
 >> iter 71000, loss: 0.345654
 >> iter 72000, loss: 0.479406
 >> iter 73000, loss: 0.407932
 >> iter 74000, loss: 0.407995
 >> iter 75000, loss: 0.481740
 >> iter 76000, loss: 0.303078
 >> iter 77000, loss: 0.369895
 >> iter 78000, loss: 0.248132
 >> iter 79000, loss: 0.525757
 >> iter 80000, loss: 0.426999
   Number of active neurons: 7
 >> iter 81000, loss: 0.502151
 >> iter 82000, loss: 0.452959
 >> iter 83000, loss: 0.383571
 >> iter 84000, loss: 0.381026
 >> iter 85000, loss: 0.405787
 >> iter 86000, loss: 0.263245
 >> iter 87000, loss: 0.391864
 >> iter 88000, loss: 0.440478
 >> iter 89000, loss: 0.382969
 >> iter 90000, loss: 0.245077
   Number of active neurons: 7
 >> iter 91000, loss: 0.346883
 >> iter 92000, loss: 0.443359
 >> iter 93000, loss: 0.295033
 >> iter 94000, loss: 0.425544
 >> iter 95000, loss: 0.336027
 >> iter 96000, loss: 0.296838
 >> iter 97000, loss: 0.306484
 >> iter 98000, loss: 0.401060
 >> iter 99000, loss: 0.497109
 >> iter 100000, loss: 0.433067
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.225073
 >> iter 2000, loss: 11.303627
 >> iter 3000, loss: 5.313624
 >> iter 4000, loss: 2.328287
 >> iter 5000, loss: 1.048212
 >> iter 6000, loss: 0.608132
 >> iter 7000, loss: 0.469750
 >> iter 8000, loss: 0.552570
 >> iter 9000, loss: 0.297831
 >> iter 10000, loss: 0.311709
   Number of active neurons: 9
 >> iter 11000, loss: 0.391643
 >> iter 12000, loss: 0.310224
 >> iter 13000, loss: 0.352621
 >> iter 14000, loss: 0.241612
 >> iter 15000, loss: 0.289189
 >> iter 16000, loss: 0.191535
 >> iter 17000, loss: 0.216572
 >> iter 18000, loss: 0.325989
 >> iter 19000, loss: 0.248746
 >> iter 20000, loss: 0.174165
   Number of active neurons: 8
 >> iter 21000, loss: 0.442227
 >> iter 22000, loss: 0.270111
 >> iter 23000, loss: 0.254151
 >> iter 24000, loss: 0.222335
 >> iter 25000, loss: 0.414887
 >> iter 26000, loss: 0.308429
 >> iter 27000, loss: 0.284470
 >> iter 28000, loss: 0.229018
 >> iter 29000, loss: 0.221084
 >> iter 30000, loss: 0.254158
   Number of active neurons: 7
 >> iter 31000, loss: 0.400782
 >> iter 32000, loss: 0.456541
 >> iter 33000, loss: 0.387205
 >> iter 34000, loss: 0.297652
 >> iter 35000, loss: 0.346568
 >> iter 36000, loss: 0.252054
 >> iter 37000, loss: 0.157982
 >> iter 38000, loss: 0.187994
 >> iter 39000, loss: 0.244693
 >> iter 40000, loss: 0.414731
   Number of active neurons: 6
 >> iter 41000, loss: 0.249506
 >> iter 42000, loss: 0.383376
 >> iter 43000, loss: 0.235997
 >> iter 44000, loss: 0.356971
 >> iter 45000, loss: 0.224632
 >> iter 46000, loss: 0.198644
 >> iter 47000, loss: 0.367975
 >> iter 48000, loss: 0.355338
 >> iter 49000, loss: 0.352103
 >> iter 50000, loss: 0.361979
   Number of active neurons: 6
 >> iter 51000, loss: 0.317074
 >> iter 52000, loss: 0.209121
 >> iter 53000, loss: 0.165498
 >> iter 54000, loss: 0.140606
 >> iter 55000, loss: 0.334400
 >> iter 56000, loss: 0.299541
 >> iter 57000, loss: 0.291313
 >> iter 58000, loss: 0.351484
 >> iter 59000, loss: 0.250783
 >> iter 60000, loss: 0.187627
   Number of active neurons: 6
 >> iter 61000, loss: 0.193218
 >> iter 62000, loss: 0.201067
 >> iter 63000, loss: 0.127806
 >> iter 64000, loss: 0.211152
 >> iter 65000, loss: 0.288369
 >> iter 66000, loss: 0.218140
 >> iter 67000, loss: 0.256333
 >> iter 68000, loss: 0.238810
 >> iter 69000, loss: 0.173951
 >> iter 70000, loss: 0.176712
   Number of active neurons: 6
 >> iter 71000, loss: 0.246746
 >> iter 72000, loss: 0.246947
 >> iter 73000, loss: 0.221777
 >> iter 74000, loss: 0.311375
 >> iter 75000, loss: 0.220513
 >> iter 76000, loss: 0.228756
 >> iter 77000, loss: 0.154856
 >> iter 78000, loss: 0.218923
 >> iter 79000, loss: 0.239371
 >> iter 80000, loss: 0.232365
   Number of active neurons: 5
 >> iter 81000, loss: 0.169076
 >> iter 82000, loss: 0.178584
 >> iter 83000, loss: 0.242983
 >> iter 84000, loss: 0.209258
 >> iter 85000, loss: 0.229057
 >> iter 86000, loss: 0.128155
 >> iter 87000, loss: 0.165507
 >> iter 88000, loss: 0.316574
 >> iter 89000, loss: 0.232668
 >> iter 90000, loss: 0.291736
   Number of active neurons: 5
 >> iter 91000, loss: 0.177335
 >> iter 92000, loss: 0.195374
 >> iter 93000, loss: 0.176408
 >> iter 94000, loss: 0.238710
 >> iter 95000, loss: 0.288354
 >> iter 96000, loss: 0.271650
 >> iter 97000, loss: 0.225512
 >> iter 98000, loss: 0.233107
 >> iter 99000, loss: 0.190369
 >> iter 100000, loss: 0.228226
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.943878
 >> iter 2000, loss: 10.732154
 >> iter 3000, loss: 4.737338
 >> iter 4000, loss: 2.093701
 >> iter 5000, loss: 1.008247
 >> iter 6000, loss: 0.562772
 >> iter 7000, loss: 0.519863
 >> iter 8000, loss: 0.284694
 >> iter 9000, loss: 0.409854
 >> iter 10000, loss: 0.280471
   Number of active neurons: 9
 >> iter 11000, loss: 0.264911
 >> iter 12000, loss: 0.325595
 >> iter 13000, loss: 0.314083
 >> iter 14000, loss: 0.243292
 >> iter 15000, loss: 0.315902
 >> iter 16000, loss: 0.287953
 >> iter 17000, loss: 0.316014
 >> iter 18000, loss: 0.266921
 >> iter 19000, loss: 0.209049
 >> iter 20000, loss: 0.231952
   Number of active neurons: 9
 >> iter 21000, loss: 0.145434
 >> iter 22000, loss: 0.201930
 >> iter 23000, loss: 0.322035
 >> iter 24000, loss: 0.324402
 >> iter 25000, loss: 0.316702
 >> iter 26000, loss: 0.237811
 >> iter 27000, loss: 0.312200
 >> iter 28000, loss: 0.320380
 >> iter 29000, loss: 0.318534
 >> iter 30000, loss: 0.236155
   Number of active neurons: 8
 >> iter 31000, loss: 0.271817
 >> iter 32000, loss: 0.180369
 >> iter 33000, loss: 0.233717
 >> iter 34000, loss: 0.287756
 >> iter 35000, loss: 0.275504
 >> iter 36000, loss: 0.226981
 >> iter 37000, loss: 0.340825
 >> iter 38000, loss: 0.359722
 >> iter 39000, loss: 0.200365
 >> iter 40000, loss: 0.240792
   Number of active neurons: 7
 >> iter 41000, loss: 0.323996
 >> iter 42000, loss: 0.270094
 >> iter 43000, loss: 0.289263
 >> iter 44000, loss: 0.283653
 >> iter 45000, loss: 0.338271
 >> iter 46000, loss: 0.313766
 >> iter 47000, loss: 0.200348
 >> iter 48000, loss: 0.265702
 >> iter 49000, loss: 0.169250
 >> iter 50000, loss: 0.164174
   Number of active neurons: 7
 >> iter 51000, loss: 0.311138
 >> iter 52000, loss: 0.274552
 >> iter 53000, loss: 0.247463
 >> iter 54000, loss: 0.292414
 >> iter 55000, loss: 0.312564
 >> iter 56000, loss: 0.195234
 >> iter 57000, loss: 0.256954
 >> iter 58000, loss: 0.238752
 >> iter 59000, loss: 0.276702
 >> iter 60000, loss: 0.217514
   Number of active neurons: 4
 >> iter 61000, loss: 0.201328
 >> iter 62000, loss: 0.313537
 >> iter 63000, loss: 0.189439
 >> iter 64000, loss: 0.370013
 >> iter 65000, loss: 0.220289
 >> iter 66000, loss: 0.214019
 >> iter 67000, loss: 0.235061
 >> iter 68000, loss: 0.180317
 >> iter 69000, loss: 0.258573
 >> iter 70000, loss: 0.206074
   Number of active neurons: 4
 >> iter 71000, loss: 0.137029
 >> iter 72000, loss: 0.204525
 >> iter 73000, loss: 0.255020
 >> iter 74000, loss: 0.162016
 >> iter 75000, loss: 0.266840
 >> iter 76000, loss: 0.233650
 >> iter 77000, loss: 0.185575
 >> iter 78000, loss: 0.174680
 >> iter 79000, loss: 0.196739
 >> iter 80000, loss: 0.152471
   Number of active neurons: 4
 >> iter 81000, loss: 0.242064
 >> iter 82000, loss: 0.255014
 >> iter 83000, loss: 0.162891
 >> iter 84000, loss: 0.121903
 >> iter 85000, loss: 0.224955
 >> iter 86000, loss: 0.203054
 >> iter 87000, loss: 0.171842
 >> iter 88000, loss: 0.201740
 >> iter 89000, loss: 0.143790
 >> iter 90000, loss: 0.125664
   Number of active neurons: 4
 >> iter 91000, loss: 0.156901
 >> iter 92000, loss: 0.247972
 >> iter 93000, loss: 0.249549
 >> iter 94000, loss: 0.176284
 >> iter 95000, loss: 0.113019
 >> iter 96000, loss: 0.237774
 >> iter 97000, loss: 0.279539
 >> iter 98000, loss: 0.217237
 >> iter 99000, loss: 0.249604
 >> iter 100000, loss: 0.239705
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

