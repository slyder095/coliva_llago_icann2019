 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.8
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.574031
 >> iter 2000, loss: 10.001332
 >> iter 3000, loss: 7.362037
 >> iter 4000, loss: 5.560020
 >> iter 5000, loss: 3.682206
 >> iter 6000, loss: 2.365717
 >> iter 7000, loss: 1.505362
 >> iter 8000, loss: 1.127611
 >> iter 9000, loss: 0.875714
 >> iter 10000, loss: 0.672084
   Number of active neurons: 10
 >> iter 11000, loss: 0.588751
 >> iter 12000, loss: 0.506090
 >> iter 13000, loss: 0.446386
 >> iter 14000, loss: 0.368648
 >> iter 15000, loss: 0.315347
 >> iter 16000, loss: 0.344884
 >> iter 17000, loss: 0.435947
 >> iter 18000, loss: 0.302933
 >> iter 19000, loss: 0.271645
 >> iter 20000, loss: 0.167621
   Number of active neurons: 10
 >> iter 21000, loss: 0.218845
 >> iter 22000, loss: 0.234975
 >> iter 23000, loss: 0.208175
 >> iter 24000, loss: 0.246898
 >> iter 25000, loss: 0.200508
 >> iter 26000, loss: 0.183859
 >> iter 27000, loss: 0.156080
 >> iter 28000, loss: 0.154119
 >> iter 29000, loss: 0.180250
 >> iter 30000, loss: 0.167026
   Number of active neurons: 10
 >> iter 31000, loss: 0.126246
 >> iter 32000, loss: 0.177987
 >> iter 33000, loss: 0.098880
 >> iter 34000, loss: 0.162678
 >> iter 35000, loss: 0.172158
 >> iter 36000, loss: 0.151184
 >> iter 37000, loss: 0.128160
 >> iter 38000, loss: 0.061474
 >> iter 39000, loss: 0.084256
 >> iter 40000, loss: 0.215182
   Number of active neurons: 10
 >> iter 41000, loss: 0.167594
 >> iter 42000, loss: 0.177645
 >> iter 43000, loss: 0.134388
 >> iter 44000, loss: 0.126152
 >> iter 45000, loss: 0.054827
 >> iter 46000, loss: 0.031534
 >> iter 47000, loss: 0.101821
 >> iter 48000, loss: 0.050068
 >> iter 49000, loss: 0.100489
 >> iter 50000, loss: 0.204208
   Number of active neurons: 10
 >> iter 51000, loss: 0.084632
 >> iter 52000, loss: 0.080910
 >> iter 53000, loss: 0.089886
 >> iter 54000, loss: 0.060909
 >> iter 55000, loss: 0.045167
 >> iter 56000, loss: 0.071224
 >> iter 57000, loss: 0.035030
 >> iter 58000, loss: 0.034963
 >> iter 59000, loss: 0.024247
 >> iter 60000, loss: 0.013340
   Number of active neurons: 10
 >> iter 61000, loss: 0.028019
 >> iter 62000, loss: 0.015652
 >> iter 63000, loss: 0.018828
 >> iter 64000, loss: 0.010691
 >> iter 65000, loss: 0.006339
 >> iter 66000, loss: 0.009733
 >> iter 67000, loss: 0.157267
 >> iter 68000, loss: 0.234691
 >> iter 69000, loss: 0.131013
 >> iter 70000, loss: 0.101268
   Number of active neurons: 10
 >> iter 71000, loss: 0.081773
 >> iter 72000, loss: 0.062902
 >> iter 73000, loss: 0.043038
 >> iter 74000, loss: 0.071251
 >> iter 75000, loss: 0.112940
 >> iter 76000, loss: 0.059906
 >> iter 77000, loss: 0.039556
 >> iter 78000, loss: 0.064473
 >> iter 79000, loss: 0.028736
 >> iter 80000, loss: 0.078410
   Number of active neurons: 10
 >> iter 81000, loss: 0.033349
 >> iter 82000, loss: 0.015314
 >> iter 83000, loss: 0.067435
 >> iter 84000, loss: 0.061516
 >> iter 85000, loss: 0.036056
 >> iter 86000, loss: 0.119679
 >> iter 87000, loss: 0.048133
 >> iter 88000, loss: 0.048011
 >> iter 89000, loss: 0.052133
 >> iter 90000, loss: 0.034410
   Number of active neurons: 10
 >> iter 91000, loss: 0.126611
 >> iter 92000, loss: 0.188465
 >> iter 93000, loss: 0.085231
 >> iter 94000, loss: 0.074010
 >> iter 95000, loss: 0.034012
 >> iter 96000, loss: 0.015676
 >> iter 97000, loss: 0.029971
 >> iter 98000, loss: 0.013880
 >> iter 99000, loss: 0.026408
 >> iter 100000, loss: 0.012314
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.590215
 >> iter 2000, loss: 9.980185
 >> iter 3000, loss: 7.358260
 >> iter 4000, loss: 5.872951
 >> iter 5000, loss: 3.119388
 >> iter 6000, loss: 1.512228
 >> iter 7000, loss: 0.786126
 >> iter 8000, loss: 0.605061
 >> iter 9000, loss: 0.315139
 >> iter 10000, loss: 0.234941
   Number of active neurons: 10
 >> iter 11000, loss: 0.227852
 >> iter 12000, loss: 0.141410
 >> iter 13000, loss: 0.277205
 >> iter 14000, loss: 0.211048
 >> iter 15000, loss: 0.121142
 >> iter 16000, loss: 0.144667
 >> iter 17000, loss: 0.137361
 >> iter 18000, loss: 0.101067
 >> iter 19000, loss: 0.106435
 >> iter 20000, loss: 0.099327
   Number of active neurons: 10
 >> iter 21000, loss: 0.129049
 >> iter 22000, loss: 0.147392
 >> iter 23000, loss: 0.073767
 >> iter 24000, loss: 0.048946
 >> iter 25000, loss: 0.033694
 >> iter 26000, loss: 0.018419
 >> iter 27000, loss: 0.059763
 >> iter 28000, loss: 0.103502
 >> iter 29000, loss: 0.057916
 >> iter 30000, loss: 0.033575
   Number of active neurons: 10
 >> iter 31000, loss: 0.026147
 >> iter 32000, loss: 0.012800
 >> iter 33000, loss: 0.188626
 >> iter 34000, loss: 0.124930
 >> iter 35000, loss: 0.083930
 >> iter 36000, loss: 0.035520
 >> iter 37000, loss: 0.040450
 >> iter 38000, loss: 0.057935
 >> iter 39000, loss: 0.025576
 >> iter 40000, loss: 0.012313
   Number of active neurons: 10
 >> iter 41000, loss: 0.101922
 >> iter 42000, loss: 0.062512
 >> iter 43000, loss: 0.173707
 >> iter 44000, loss: 0.081167
 >> iter 45000, loss: 0.039870
 >> iter 46000, loss: 0.020877
 >> iter 47000, loss: 0.022235
 >> iter 48000, loss: 0.029719
 >> iter 49000, loss: 0.040244
 >> iter 50000, loss: 0.017676
   Number of active neurons: 10
 >> iter 51000, loss: 0.008544
 >> iter 52000, loss: 0.004798
 >> iter 53000, loss: 0.003358
 >> iter 54000, loss: 0.002697
 >> iter 55000, loss: 0.003641
 >> iter 56000, loss: 0.027410
 >> iter 57000, loss: 0.027491
 >> iter 58000, loss: 0.012288
 >> iter 59000, loss: 0.059105
 >> iter 60000, loss: 0.023613
   Number of active neurons: 10
 >> iter 61000, loss: 0.037237
 >> iter 62000, loss: 0.017796
 >> iter 63000, loss: 0.009070
 >> iter 64000, loss: 0.022901
 >> iter 65000, loss: 0.029203
 >> iter 66000, loss: 0.019560
 >> iter 67000, loss: 0.063258
 >> iter 68000, loss: 0.025456
 >> iter 69000, loss: 0.011908
 >> iter 70000, loss: 0.026727
   Number of active neurons: 10
 >> iter 71000, loss: 0.053918
 >> iter 72000, loss: 0.033129
 >> iter 73000, loss: 0.035422
 >> iter 74000, loss: 0.021152
 >> iter 75000, loss: 0.014217
 >> iter 76000, loss: 0.007431
 >> iter 77000, loss: 0.011123
 >> iter 78000, loss: 0.062878
 >> iter 79000, loss: 0.044549
 >> iter 80000, loss: 0.018783
   Number of active neurons: 10
 >> iter 81000, loss: 0.008597
 >> iter 82000, loss: 0.004704
 >> iter 83000, loss: 0.096892
 >> iter 84000, loss: 0.038195
 >> iter 85000, loss: 0.037154
 >> iter 86000, loss: 0.023128
 >> iter 87000, loss: 0.085231
 >> iter 88000, loss: 0.079876
 >> iter 89000, loss: 0.032259
 >> iter 90000, loss: 0.014189
   Number of active neurons: 10
 >> iter 91000, loss: 0.038578
 >> iter 92000, loss: 0.027210
 >> iter 93000, loss: 0.011849
 >> iter 94000, loss: 0.005961
 >> iter 95000, loss: 0.003627
 >> iter 96000, loss: 0.002647
 >> iter 97000, loss: 0.028734
 >> iter 98000, loss: 0.012404
 >> iter 99000, loss: 0.014113
 >> iter 100000, loss: 0.006415
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.161477
 >> iter 2000, loss: 10.156675
 >> iter 3000, loss: 6.659465
 >> iter 4000, loss: 3.310843
 >> iter 5000, loss: 1.582816
 >> iter 6000, loss: 0.740657
 >> iter 7000, loss: 0.542370
 >> iter 8000, loss: 0.274627
 >> iter 9000, loss: 0.141927
 >> iter 10000, loss: 0.117213
   Number of active neurons: 10
 >> iter 11000, loss: 0.137569
 >> iter 12000, loss: 0.221493
 >> iter 13000, loss: 0.140499
 >> iter 14000, loss: 0.081662
 >> iter 15000, loss: 0.059903
 >> iter 16000, loss: 0.041624
 >> iter 17000, loss: 0.023595
 >> iter 18000, loss: 0.112090
 >> iter 19000, loss: 0.070819
 >> iter 20000, loss: 0.035146
   Number of active neurons: 10
 >> iter 21000, loss: 0.123318
 >> iter 22000, loss: 0.097183
 >> iter 23000, loss: 0.051782
 >> iter 24000, loss: 0.074490
 >> iter 25000, loss: 0.060762
 >> iter 26000, loss: 0.027934
 >> iter 27000, loss: 0.030207
 >> iter 28000, loss: 0.015259
 >> iter 29000, loss: 0.009460
 >> iter 30000, loss: 0.026843
   Number of active neurons: 10
 >> iter 31000, loss: 0.019199
 >> iter 32000, loss: 0.023530
 >> iter 33000, loss: 0.028236
 >> iter 34000, loss: 0.034948
 >> iter 35000, loss: 0.016755
 >> iter 36000, loss: 0.008775
 >> iter 37000, loss: 0.005718
 >> iter 38000, loss: 0.004602
 >> iter 39000, loss: 0.003645
 >> iter 40000, loss: 0.003155
   Number of active neurons: 10
 >> iter 41000, loss: 0.003088
 >> iter 42000, loss: 0.007107
 >> iter 43000, loss: 0.062158
 >> iter 44000, loss: 0.046345
 >> iter 45000, loss: 0.092381
 >> iter 46000, loss: 0.048543
 >> iter 47000, loss: 0.032306
 >> iter 48000, loss: 0.016780
 >> iter 49000, loss: 0.008700
 >> iter 50000, loss: 0.034913
   Number of active neurons: 10
 >> iter 51000, loss: 0.026981
 >> iter 52000, loss: 0.064140
 >> iter 53000, loss: 0.027858
 >> iter 54000, loss: 0.017994
 >> iter 55000, loss: 0.010902
 >> iter 56000, loss: 0.047723
 >> iter 57000, loss: 0.025273
 >> iter 58000, loss: 0.013915
 >> iter 59000, loss: 0.008311
 >> iter 60000, loss: 0.004831
   Number of active neurons: 10
 >> iter 61000, loss: 0.003626
 >> iter 62000, loss: 0.002921
 >> iter 63000, loss: 0.014430
 >> iter 64000, loss: 0.006847
 >> iter 65000, loss: 0.004143
 >> iter 66000, loss: 0.007079
 >> iter 67000, loss: 0.003868
 >> iter 68000, loss: 0.003099
 >> iter 69000, loss: 0.002257
 >> iter 70000, loss: 0.001959
   Number of active neurons: 10
 >> iter 71000, loss: 0.001841
 >> iter 72000, loss: 0.001650
 >> iter 73000, loss: 0.025552
 >> iter 74000, loss: 0.010855
 >> iter 75000, loss: 0.008880
 >> iter 76000, loss: 0.008953
 >> iter 77000, loss: 0.004526
 >> iter 78000, loss: 0.004481
 >> iter 79000, loss: 0.002777
 >> iter 80000, loss: 0.002075
   Number of active neurons: 10
 >> iter 81000, loss: 0.019067
 >> iter 82000, loss: 0.066428
 >> iter 83000, loss: 0.067438
 >> iter 84000, loss: 0.028315
 >> iter 85000, loss: 0.012132
 >> iter 86000, loss: 0.006126
 >> iter 87000, loss: 0.003766
 >> iter 88000, loss: 0.002589
 >> iter 89000, loss: 0.032254
 >> iter 90000, loss: 0.037989
   Number of active neurons: 10
 >> iter 91000, loss: 0.015743
 >> iter 92000, loss: 0.050177
 >> iter 93000, loss: 0.019962
 >> iter 94000, loss: 0.008727
 >> iter 95000, loss: 0.004486
 >> iter 96000, loss: 0.031818
 >> iter 97000, loss: 0.013134
 >> iter 98000, loss: 0.006140
 >> iter 99000, loss: 0.028054
 >> iter 100000, loss: 0.011673
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.665247
 >> iter 2000, loss: 9.948210
 >> iter 3000, loss: 7.013375
 >> iter 4000, loss: 4.873858
 >> iter 5000, loss: 3.541943
 >> iter 6000, loss: 2.162053
 >> iter 7000, loss: 1.199200
 >> iter 8000, loss: 0.819306
 >> iter 9000, loss: 0.820568
 >> iter 10000, loss: 0.417779
   Number of active neurons: 10
 >> iter 11000, loss: 0.345431
 >> iter 12000, loss: 0.312637
 >> iter 13000, loss: 0.224045
 >> iter 14000, loss: 0.153253
 >> iter 15000, loss: 0.104506
 >> iter 16000, loss: 0.068079
 >> iter 17000, loss: 0.093539
 >> iter 18000, loss: 0.102152
 >> iter 19000, loss: 0.105870
 >> iter 20000, loss: 0.076655
   Number of active neurons: 10
 >> iter 21000, loss: 0.122176
 >> iter 22000, loss: 0.059701
 >> iter 23000, loss: 0.160238
 >> iter 24000, loss: 0.165195
 >> iter 25000, loss: 0.120980
 >> iter 26000, loss: 0.112457
 >> iter 27000, loss: 0.077372
 >> iter 28000, loss: 0.075842
 >> iter 29000, loss: 0.049422
 >> iter 30000, loss: 0.026619
   Number of active neurons: 10
 >> iter 31000, loss: 0.117154
 >> iter 32000, loss: 0.061707
 >> iter 33000, loss: 0.033996
 >> iter 34000, loss: 0.050507
 >> iter 35000, loss: 0.059676
 >> iter 36000, loss: 0.058717
 >> iter 37000, loss: 0.040166
 >> iter 38000, loss: 0.023881
 >> iter 39000, loss: 0.015543
 >> iter 40000, loss: 0.019739
   Number of active neurons: 10
 >> iter 41000, loss: 0.019990
 >> iter 42000, loss: 0.011186
 >> iter 43000, loss: 0.014969
 >> iter 44000, loss: 0.032560
 >> iter 45000, loss: 0.015223
 >> iter 46000, loss: 0.017051
 >> iter 47000, loss: 0.008330
 >> iter 48000, loss: 0.005296
 >> iter 49000, loss: 0.049835
 >> iter 50000, loss: 0.055127
   Number of active neurons: 10
 >> iter 51000, loss: 0.158813
 >> iter 52000, loss: 0.090023
 >> iter 53000, loss: 0.046672
 >> iter 54000, loss: 0.019683
 >> iter 55000, loss: 0.033953
 >> iter 56000, loss: 0.021056
 >> iter 57000, loss: 0.033514
 >> iter 58000, loss: 0.046858
 >> iter 59000, loss: 0.062090
 >> iter 60000, loss: 0.050799
   Number of active neurons: 10
 >> iter 61000, loss: 0.043133
 >> iter 62000, loss: 0.018398
 >> iter 63000, loss: 0.014286
 >> iter 64000, loss: 0.007500
 >> iter 65000, loss: 0.009037
 >> iter 66000, loss: 0.012018
 >> iter 67000, loss: 0.030359
 >> iter 68000, loss: 0.023246
 >> iter 69000, loss: 0.011961
 >> iter 70000, loss: 0.006699
   Number of active neurons: 10
 >> iter 71000, loss: 0.004279
 >> iter 72000, loss: 0.003226
 >> iter 73000, loss: 0.002569
 >> iter 74000, loss: 0.002239
 >> iter 75000, loss: 0.066891
 >> iter 76000, loss: 0.026552
 >> iter 77000, loss: 0.011410
 >> iter 78000, loss: 0.005633
 >> iter 79000, loss: 0.003390
 >> iter 80000, loss: 0.002660
   Number of active neurons: 10
 >> iter 81000, loss: 0.002136
 >> iter 82000, loss: 0.027306
 >> iter 83000, loss: 0.011363
 >> iter 84000, loss: 0.005331
 >> iter 85000, loss: 0.003015
 >> iter 86000, loss: 0.006999
 >> iter 87000, loss: 0.056228
 >> iter 88000, loss: 0.022036
 >> iter 89000, loss: 0.013805
 >> iter 90000, loss: 0.101595
   Number of active neurons: 10
 >> iter 91000, loss: 0.039229
 >> iter 92000, loss: 0.016118
 >> iter 93000, loss: 0.007561
 >> iter 94000, loss: 0.013234
 >> iter 95000, loss: 0.006168
 >> iter 96000, loss: 0.003469
 >> iter 97000, loss: 0.002471
 >> iter 98000, loss: 0.009277
 >> iter 99000, loss: 0.004709
 >> iter 100000, loss: 0.002830
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.890339
 >> iter 2000, loss: 10.130074
 >> iter 3000, loss: 6.790135
 >> iter 4000, loss: 4.090029
 >> iter 5000, loss: 2.157953
 >> iter 6000, loss: 1.224820
 >> iter 7000, loss: 0.750051
 >> iter 8000, loss: 0.484868
 >> iter 9000, loss: 0.342712
 >> iter 10000, loss: 0.206115
   Number of active neurons: 10
 >> iter 11000, loss: 0.150596
 >> iter 12000, loss: 0.111281
 >> iter 13000, loss: 0.109152
 >> iter 14000, loss: 0.148146
 >> iter 15000, loss: 0.101385
 >> iter 16000, loss: 0.151985
 >> iter 17000, loss: 0.093018
 >> iter 18000, loss: 0.172498
 >> iter 19000, loss: 0.125804
 >> iter 20000, loss: 0.074901
   Number of active neurons: 10
 >> iter 21000, loss: 0.033208
 >> iter 22000, loss: 0.119158
 >> iter 23000, loss: 0.110704
 >> iter 24000, loss: 0.103759
 >> iter 25000, loss: 0.106209
 >> iter 26000, loss: 0.057183
 >> iter 27000, loss: 0.051057
 >> iter 28000, loss: 0.070729
 >> iter 29000, loss: 0.036662
 >> iter 30000, loss: 0.026428
   Number of active neurons: 10
 >> iter 31000, loss: 0.015415
 >> iter 32000, loss: 0.024047
 >> iter 33000, loss: 0.018947
 >> iter 34000, loss: 0.019274
 >> iter 35000, loss: 0.045690
 >> iter 36000, loss: 0.073032
 >> iter 37000, loss: 0.038080
 >> iter 38000, loss: 0.017627
 >> iter 39000, loss: 0.008589
 >> iter 40000, loss: 0.023528
   Number of active neurons: 10
 >> iter 41000, loss: 0.067695
 >> iter 42000, loss: 0.051311
 >> iter 43000, loss: 0.021476
 >> iter 44000, loss: 0.012034
 >> iter 45000, loss: 0.023743
 >> iter 46000, loss: 0.020015
 >> iter 47000, loss: 0.009273
 >> iter 48000, loss: 0.014541
 >> iter 49000, loss: 0.026840
 >> iter 50000, loss: 0.028366
   Number of active neurons: 10
 >> iter 51000, loss: 0.013286
 >> iter 52000, loss: 0.034950
 >> iter 53000, loss: 0.014982
 >> iter 54000, loss: 0.007336
 >> iter 55000, loss: 0.004204
 >> iter 56000, loss: 0.018798
 >> iter 57000, loss: 0.009192
 >> iter 58000, loss: 0.021463
 >> iter 59000, loss: 0.038543
 >> iter 60000, loss: 0.016452
   Number of active neurons: 10
 >> iter 61000, loss: 0.049176
 >> iter 62000, loss: 0.114436
 >> iter 63000, loss: 0.046534
 >> iter 64000, loss: 0.038172
 >> iter 65000, loss: 0.063839
 >> iter 66000, loss: 0.052971
 >> iter 67000, loss: 0.021841
 >> iter 68000, loss: 0.010379
 >> iter 69000, loss: 0.051438
 >> iter 70000, loss: 0.040258
   Number of active neurons: 10
 >> iter 71000, loss: 0.016763
 >> iter 72000, loss: 0.099613
 >> iter 73000, loss: 0.048797
 >> iter 74000, loss: 0.057517
 >> iter 75000, loss: 0.028406
 >> iter 76000, loss: 0.071031
 >> iter 77000, loss: 0.029275
 >> iter 78000, loss: 0.058820
 >> iter 79000, loss: 0.026238
 >> iter 80000, loss: 0.011679
   Number of active neurons: 10
 >> iter 81000, loss: 0.005918
 >> iter 82000, loss: 0.017971
 >> iter 83000, loss: 0.042748
 >> iter 84000, loss: 0.018975
 >> iter 85000, loss: 0.019459
 >> iter 86000, loss: 0.043014
 >> iter 87000, loss: 0.017941
 >> iter 88000, loss: 0.013032
 >> iter 89000, loss: 0.007671
 >> iter 90000, loss: 0.037824
   Number of active neurons: 10
 >> iter 91000, loss: 0.022326
 >> iter 92000, loss: 0.049976
 >> iter 93000, loss: 0.025593
 >> iter 94000, loss: 0.016675
 >> iter 95000, loss: 0.023526
 >> iter 96000, loss: 0.030163
 >> iter 97000, loss: 0.013199
 >> iter 98000, loss: 0.020345
 >> iter 99000, loss: 0.064750
 >> iter 100000, loss: 0.030731
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.558767
 >> iter 2000, loss: 10.044567
 >> iter 3000, loss: 6.947373
 >> iter 4000, loss: 4.803285
 >> iter 5000, loss: 3.198509
 >> iter 6000, loss: 2.055949
 >> iter 7000, loss: 1.489517
 >> iter 8000, loss: 1.274860
 >> iter 9000, loss: 1.065992
 >> iter 10000, loss: 0.996953
   Number of active neurons: 10
 >> iter 11000, loss: 0.647206
 >> iter 12000, loss: 0.519835
 >> iter 13000, loss: 0.395706
 >> iter 14000, loss: 0.417031
 >> iter 15000, loss: 0.320584
 >> iter 16000, loss: 0.459872
 >> iter 17000, loss: 0.467235
 >> iter 18000, loss: 0.303675
 >> iter 19000, loss: 0.172917
 >> iter 20000, loss: 0.260787
   Number of active neurons: 10
 >> iter 21000, loss: 0.303900
 >> iter 22000, loss: 0.179217
 >> iter 23000, loss: 0.301463
 >> iter 24000, loss: 0.234541
 >> iter 25000, loss: 0.213240
 >> iter 26000, loss: 0.137454
 >> iter 27000, loss: 0.140065
 >> iter 28000, loss: 0.268159
 >> iter 29000, loss: 0.185961
 >> iter 30000, loss: 0.157271
   Number of active neurons: 10
 >> iter 31000, loss: 0.187296
 >> iter 32000, loss: 0.260952
 >> iter 33000, loss: 0.229728
 >> iter 34000, loss: 0.149543
 >> iter 35000, loss: 0.095621
 >> iter 36000, loss: 0.140868
 >> iter 37000, loss: 0.205153
 >> iter 38000, loss: 0.194427
 >> iter 39000, loss: 0.133375
 >> iter 40000, loss: 0.100902
   Number of active neurons: 10
 >> iter 41000, loss: 0.123743
 >> iter 42000, loss: 0.078397
 >> iter 43000, loss: 0.120158
 >> iter 44000, loss: 0.317348
 >> iter 45000, loss: 0.167245
 >> iter 46000, loss: 0.084196
 >> iter 47000, loss: 0.101281
 >> iter 48000, loss: 0.066398
 >> iter 49000, loss: 0.087828
 >> iter 50000, loss: 0.080257
   Number of active neurons: 10
 >> iter 51000, loss: 0.042908
 >> iter 52000, loss: 0.043012
 >> iter 53000, loss: 0.019293
 >> iter 54000, loss: 0.025701
 >> iter 55000, loss: 0.014127
 >> iter 56000, loss: 0.007432
 >> iter 57000, loss: 0.004766
 >> iter 58000, loss: 0.015391
 >> iter 59000, loss: 0.138186
 >> iter 60000, loss: 0.111232
   Number of active neurons: 10
 >> iter 61000, loss: 0.073372
 >> iter 62000, loss: 0.135111
 >> iter 63000, loss: 0.153726
 >> iter 64000, loss: 0.074556
 >> iter 65000, loss: 0.061310
 >> iter 66000, loss: 0.075411
 >> iter 67000, loss: 0.109738
 >> iter 68000, loss: 0.109123
 >> iter 69000, loss: 0.071176
 >> iter 70000, loss: 0.163830
   Number of active neurons: 10
 >> iter 71000, loss: 0.106176
 >> iter 72000, loss: 0.500181
 >> iter 73000, loss: 0.334155
 >> iter 74000, loss: 0.199622
 >> iter 75000, loss: 0.222917
 >> iter 76000, loss: 0.324171
 >> iter 77000, loss: 0.142099
 >> iter 78000, loss: 0.102170
 >> iter 79000, loss: 0.121090
 >> iter 80000, loss: 0.093274
   Number of active neurons: 10
 >> iter 81000, loss: 0.070814
 >> iter 82000, loss: 0.103656
 >> iter 83000, loss: 0.073703
 >> iter 84000, loss: 0.111197
 >> iter 85000, loss: 0.071815
 >> iter 86000, loss: 0.033492
 >> iter 87000, loss: 0.030113
 >> iter 88000, loss: 0.029986
 >> iter 89000, loss: 0.026943
 >> iter 90000, loss: 0.051683
   Number of active neurons: 10
 >> iter 91000, loss: 0.076066
 >> iter 92000, loss: 0.076102
 >> iter 93000, loss: 0.064979
 >> iter 94000, loss: 0.103618
 >> iter 95000, loss: 0.063248
 >> iter 96000, loss: 0.038354
 >> iter 97000, loss: 0.036371
 >> iter 98000, loss: 0.035490
 >> iter 99000, loss: 0.032734
 >> iter 100000, loss: 0.014474
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.553438
 >> iter 2000, loss: 9.790857
 >> iter 3000, loss: 6.552618
 >> iter 4000, loss: 3.935788
 >> iter 5000, loss: 2.241756
 >> iter 6000, loss: 1.282558
 >> iter 7000, loss: 0.743878
 >> iter 8000, loss: 0.469045
 >> iter 9000, loss: 0.504182
 >> iter 10000, loss: 0.313195
   Number of active neurons: 10
 >> iter 11000, loss: 0.239114
 >> iter 12000, loss: 0.199919
 >> iter 13000, loss: 0.168942
 >> iter 14000, loss: 0.125858
 >> iter 15000, loss: 0.151593
 >> iter 16000, loss: 0.163230
 >> iter 17000, loss: 0.149897
 >> iter 18000, loss: 0.197331
 >> iter 19000, loss: 0.144564
 >> iter 20000, loss: 0.216048
   Number of active neurons: 10
 >> iter 21000, loss: 0.181154
 >> iter 22000, loss: 0.145240
 >> iter 23000, loss: 0.102691
 >> iter 24000, loss: 0.141663
 >> iter 25000, loss: 0.108643
 >> iter 26000, loss: 0.156983
 >> iter 27000, loss: 0.125947
 >> iter 28000, loss: 0.129886
 >> iter 29000, loss: 0.137187
 >> iter 30000, loss: 0.154167
   Number of active neurons: 10
 >> iter 31000, loss: 0.088796
 >> iter 32000, loss: 0.040987
 >> iter 33000, loss: 0.121927
 >> iter 34000, loss: 0.108434
 >> iter 35000, loss: 0.099376
 >> iter 36000, loss: 0.096519
 >> iter 37000, loss: 0.056809
 >> iter 38000, loss: 0.030649
 >> iter 39000, loss: 0.056379
 >> iter 40000, loss: 0.043125
   Number of active neurons: 10
 >> iter 41000, loss: 0.053253
 >> iter 42000, loss: 0.053203
 >> iter 43000, loss: 0.070710
 >> iter 44000, loss: 0.092098
 >> iter 45000, loss: 0.074220
 >> iter 46000, loss: 0.047731
 >> iter 47000, loss: 0.059718
 >> iter 48000, loss: 0.042796
 >> iter 49000, loss: 0.019442
 >> iter 50000, loss: 0.031156
   Number of active neurons: 10
 >> iter 51000, loss: 0.033258
 >> iter 52000, loss: 0.030617
 >> iter 53000, loss: 0.059316
 >> iter 54000, loss: 0.025782
 >> iter 55000, loss: 0.073238
 >> iter 56000, loss: 0.030021
 >> iter 57000, loss: 0.030281
 >> iter 58000, loss: 0.061597
 >> iter 59000, loss: 0.077892
 >> iter 60000, loss: 0.044834
   Number of active neurons: 10
 >> iter 61000, loss: 0.064115
 >> iter 62000, loss: 0.027804
 >> iter 63000, loss: 0.056413
 >> iter 64000, loss: 0.025360
 >> iter 65000, loss: 0.011947
 >> iter 66000, loss: 0.006625
 >> iter 67000, loss: 0.004964
 >> iter 68000, loss: 0.032705
 >> iter 69000, loss: 0.048107
 >> iter 70000, loss: 0.039834
   Number of active neurons: 10
 >> iter 71000, loss: 0.017430
 >> iter 72000, loss: 0.012418
 >> iter 73000, loss: 0.034240
 >> iter 74000, loss: 0.050982
 >> iter 75000, loss: 0.041607
 >> iter 76000, loss: 0.072561
 >> iter 77000, loss: 0.063564
 >> iter 78000, loss: 0.049530
 >> iter 79000, loss: 0.021415
 >> iter 80000, loss: 0.010371
   Number of active neurons: 10
 >> iter 81000, loss: 0.006048
 >> iter 82000, loss: 0.004071
 >> iter 83000, loss: 0.012931
 >> iter 84000, loss: 0.006715
 >> iter 85000, loss: 0.003980
 >> iter 86000, loss: 0.036213
 >> iter 87000, loss: 0.085382
 >> iter 88000, loss: 0.046970
 >> iter 89000, loss: 0.019551
 >> iter 90000, loss: 0.037409
   Number of active neurons: 10
 >> iter 91000, loss: 0.047144
 >> iter 92000, loss: 0.032392
 >> iter 93000, loss: 0.014122
 >> iter 94000, loss: 0.007173
 >> iter 95000, loss: 0.029816
 >> iter 96000, loss: 0.012808
 >> iter 97000, loss: 0.006536
 >> iter 98000, loss: 0.003920
 >> iter 99000, loss: 0.017354
 >> iter 100000, loss: 0.007833
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.556288
 >> iter 2000, loss: 10.507138
 >> iter 3000, loss: 6.342876
 >> iter 4000, loss: 3.092244
 >> iter 5000, loss: 1.552262
 >> iter 6000, loss: 0.985022
 >> iter 7000, loss: 0.497774
 >> iter 8000, loss: 0.377755
 >> iter 9000, loss: 0.316923
 >> iter 10000, loss: 0.254121
   Number of active neurons: 10
 >> iter 11000, loss: 0.185133
 >> iter 12000, loss: 0.168632
 >> iter 13000, loss: 0.099335
 >> iter 14000, loss: 0.090474
 >> iter 15000, loss: 0.094994
 >> iter 16000, loss: 0.095282
 >> iter 17000, loss: 0.120840
 >> iter 18000, loss: 0.065501
 >> iter 19000, loss: 0.100611
 >> iter 20000, loss: 0.060033
   Number of active neurons: 10
 >> iter 21000, loss: 0.028503
 >> iter 22000, loss: 0.021779
 >> iter 23000, loss: 0.082313
 >> iter 24000, loss: 0.058005
 >> iter 25000, loss: 0.053375
 >> iter 26000, loss: 0.057080
 >> iter 27000, loss: 0.074711
 >> iter 28000, loss: 0.150806
 >> iter 29000, loss: 0.112536
 >> iter 30000, loss: 0.110502
   Number of active neurons: 10
 >> iter 31000, loss: 0.063610
 >> iter 32000, loss: 0.065421
 >> iter 33000, loss: 0.044713
 >> iter 34000, loss: 0.040962
 >> iter 35000, loss: 0.081653
 >> iter 36000, loss: 0.038433
 >> iter 37000, loss: 0.035478
 >> iter 38000, loss: 0.035305
 >> iter 39000, loss: 0.069399
 >> iter 40000, loss: 0.051529
   Number of active neurons: 10
 >> iter 41000, loss: 0.039271
 >> iter 42000, loss: 0.017709
 >> iter 43000, loss: 0.029068
 >> iter 44000, loss: 0.013652
 >> iter 45000, loss: 0.028291
 >> iter 46000, loss: 0.012988
 >> iter 47000, loss: 0.007045
 >> iter 48000, loss: 0.005106
 >> iter 49000, loss: 0.012582
 >> iter 50000, loss: 0.008478
   Number of active neurons: 10
 >> iter 51000, loss: 0.027365
 >> iter 52000, loss: 0.023288
 >> iter 53000, loss: 0.068694
 >> iter 54000, loss: 0.027775
 >> iter 55000, loss: 0.025105
 >> iter 56000, loss: 0.014650
 >> iter 57000, loss: 0.007534
 >> iter 58000, loss: 0.004593
 >> iter 59000, loss: 0.003482
 >> iter 60000, loss: 0.002639
   Number of active neurons: 10
 >> iter 61000, loss: 0.002277
 >> iter 62000, loss: 0.001981
 >> iter 63000, loss: 0.002374
 >> iter 64000, loss: 0.002096
 >> iter 65000, loss: 0.001827
 >> iter 66000, loss: 0.001927
 >> iter 67000, loss: 0.092415
 >> iter 68000, loss: 0.035773
 >> iter 69000, loss: 0.017149
 >> iter 70000, loss: 0.050234
   Number of active neurons: 10
 >> iter 71000, loss: 0.019853
 >> iter 72000, loss: 0.010457
 >> iter 73000, loss: 0.036242
 >> iter 74000, loss: 0.039535
 >> iter 75000, loss: 0.037094
 >> iter 76000, loss: 0.051292
 >> iter 77000, loss: 0.020829
 >> iter 78000, loss: 0.009506
 >> iter 79000, loss: 0.005033
 >> iter 80000, loss: 0.003474
   Number of active neurons: 10
 >> iter 81000, loss: 0.002589
 >> iter 82000, loss: 0.002225
 >> iter 83000, loss: 0.001943
 >> iter 84000, loss: 0.002054
 >> iter 85000, loss: 0.001768
 >> iter 86000, loss: 0.001731
 >> iter 87000, loss: 0.001660
 >> iter 88000, loss: 0.003005
 >> iter 89000, loss: 0.002147
 >> iter 90000, loss: 0.001697
   Number of active neurons: 10
 >> iter 91000, loss: 0.001600
 >> iter 92000, loss: 0.001385
 >> iter 93000, loss: 0.024259
 >> iter 94000, loss: 0.028561
 >> iter 95000, loss: 0.011726
 >> iter 96000, loss: 0.005330
 >> iter 97000, loss: 0.002959
 >> iter 98000, loss: 0.015760
 >> iter 99000, loss: 0.016871
 >> iter 100000, loss: 0.012672
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 18.143588
 >> iter 2000, loss: 10.547079
 >> iter 3000, loss: 6.553319
 >> iter 4000, loss: 3.529881
 >> iter 5000, loss: 2.362704
 >> iter 6000, loss: 1.466044
 >> iter 7000, loss: 1.175746
 >> iter 8000, loss: 0.708797
 >> iter 9000, loss: 0.565889
 >> iter 10000, loss: 0.550425
   Number of active neurons: 10
 >> iter 11000, loss: 0.473465
 >> iter 12000, loss: 0.379198
 >> iter 13000, loss: 0.531774
 >> iter 14000, loss: 0.401323
 >> iter 15000, loss: 0.467612
 >> iter 16000, loss: 0.375838
 >> iter 17000, loss: 0.251826
 >> iter 18000, loss: 0.144968
 >> iter 19000, loss: 0.182760
 >> iter 20000, loss: 0.109091
   Number of active neurons: 10
 >> iter 21000, loss: 0.132499
 >> iter 22000, loss: 0.186219
 >> iter 23000, loss: 0.221508
 >> iter 24000, loss: 0.186348
 >> iter 25000, loss: 0.169838
 >> iter 26000, loss: 0.176870
 >> iter 27000, loss: 0.089981
 >> iter 28000, loss: 0.103013
 >> iter 29000, loss: 0.101691
 >> iter 30000, loss: 0.148858
   Number of active neurons: 10
 >> iter 31000, loss: 0.080084
 >> iter 32000, loss: 0.091077
 >> iter 33000, loss: 0.082686
 >> iter 34000, loss: 0.114116
 >> iter 35000, loss: 0.077420
 >> iter 36000, loss: 0.088906
 >> iter 37000, loss: 0.047848
 >> iter 38000, loss: 0.112034
 >> iter 39000, loss: 0.125947
 >> iter 40000, loss: 0.067827
   Number of active neurons: 10
 >> iter 41000, loss: 0.038581
 >> iter 42000, loss: 0.021845
 >> iter 43000, loss: 0.017785
 >> iter 44000, loss: 0.010012
 >> iter 45000, loss: 0.032216
 >> iter 46000, loss: 0.013999
 >> iter 47000, loss: 0.044247
 >> iter 48000, loss: 0.018800
 >> iter 49000, loss: 0.057846
 >> iter 50000, loss: 0.091027
   Number of active neurons: 10
 >> iter 51000, loss: 0.132602
 >> iter 52000, loss: 0.106318
 >> iter 53000, loss: 0.056366
 >> iter 54000, loss: 0.093167
 >> iter 55000, loss: 0.064381
 >> iter 56000, loss: 0.035686
 >> iter 57000, loss: 0.063496
 >> iter 58000, loss: 0.054260
 >> iter 59000, loss: 0.109613
 >> iter 60000, loss: 0.065163
   Number of active neurons: 10
 >> iter 61000, loss: 0.051015
 >> iter 62000, loss: 0.022671
 >> iter 63000, loss: 0.023483
 >> iter 64000, loss: 0.022881
 >> iter 65000, loss: 0.011306
 >> iter 66000, loss: 0.006960
 >> iter 67000, loss: 0.006635
 >> iter 68000, loss: 0.034555
 >> iter 69000, loss: 0.062125
 >> iter 70000, loss: 0.046141
   Number of active neurons: 10
 >> iter 71000, loss: 0.019422
 >> iter 72000, loss: 0.009323
 >> iter 73000, loss: 0.035898
 >> iter 74000, loss: 0.032303
 >> iter 75000, loss: 0.052393
 >> iter 76000, loss: 0.056990
 >> iter 77000, loss: 0.052797
 >> iter 78000, loss: 0.051736
 >> iter 79000, loss: 0.097531
 >> iter 80000, loss: 0.077275
   Number of active neurons: 10
 >> iter 81000, loss: 0.072377
 >> iter 82000, loss: 0.087857
 >> iter 83000, loss: 0.036904
 >> iter 84000, loss: 0.016291
 >> iter 85000, loss: 0.038297
 >> iter 86000, loss: 0.085434
 >> iter 87000, loss: 0.139925
 >> iter 88000, loss: 0.061724
 >> iter 89000, loss: 0.050159
 >> iter 90000, loss: 0.053967
   Number of active neurons: 10
 >> iter 91000, loss: 0.023170
 >> iter 92000, loss: 0.028743
 >> iter 93000, loss: 0.013200
 >> iter 94000, loss: 0.041796
 >> iter 95000, loss: 0.018072
 >> iter 96000, loss: 0.008726
 >> iter 97000, loss: 0.046792
 >> iter 98000, loss: 0.051651
 >> iter 99000, loss: 0.021278
 >> iter 100000, loss: 0.009720
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.709324
 >> iter 2000, loss: 9.972410
 >> iter 3000, loss: 6.631322
 >> iter 4000, loss: 4.227461
 >> iter 5000, loss: 2.194826
 >> iter 6000, loss: 0.977766
 >> iter 7000, loss: 0.535575
 >> iter 8000, loss: 0.395364
 >> iter 9000, loss: 0.280341
 >> iter 10000, loss: 0.300669
   Number of active neurons: 10
 >> iter 11000, loss: 0.243811
 >> iter 12000, loss: 0.153053
 >> iter 13000, loss: 0.125212
 >> iter 14000, loss: 0.075738
 >> iter 15000, loss: 0.097284
 >> iter 16000, loss: 0.046957
 >> iter 17000, loss: 0.025639
 >> iter 18000, loss: 0.060295
 >> iter 19000, loss: 0.042536
 >> iter 20000, loss: 0.069973
   Number of active neurons: 10
 >> iter 21000, loss: 0.057040
 >> iter 22000, loss: 0.130990
 >> iter 23000, loss: 0.056325
 >> iter 24000, loss: 0.104280
 >> iter 25000, loss: 0.062165
 >> iter 26000, loss: 0.048367
 >> iter 27000, loss: 0.048798
 >> iter 28000, loss: 0.030787
 >> iter 29000, loss: 0.113414
 >> iter 30000, loss: 0.070566
   Number of active neurons: 10
 >> iter 31000, loss: 0.108147
 >> iter 32000, loss: 0.171211
 >> iter 33000, loss: 0.104964
 >> iter 34000, loss: 0.045244
 >> iter 35000, loss: 0.024581
 >> iter 36000, loss: 0.027069
 >> iter 37000, loss: 0.014671
 >> iter 38000, loss: 0.170483
 >> iter 39000, loss: 0.108969
 >> iter 40000, loss: 0.085964
   Number of active neurons: 10
 >> iter 41000, loss: 0.064531
 >> iter 42000, loss: 0.029858
 >> iter 43000, loss: 0.057560
 >> iter 44000, loss: 0.026715
 >> iter 45000, loss: 0.039054
 >> iter 46000, loss: 0.018368
 >> iter 47000, loss: 0.033872
 >> iter 48000, loss: 0.067830
 >> iter 49000, loss: 0.046746
 >> iter 50000, loss: 0.027551
   Number of active neurons: 10
 >> iter 51000, loss: 0.015932
 >> iter 52000, loss: 0.033102
 >> iter 53000, loss: 0.015953
 >> iter 54000, loss: 0.017091
 >> iter 55000, loss: 0.086850
 >> iter 56000, loss: 0.059213
 >> iter 57000, loss: 0.067726
 >> iter 58000, loss: 0.032915
 >> iter 59000, loss: 0.027574
 >> iter 60000, loss: 0.012778
   Number of active neurons: 10
 >> iter 61000, loss: 0.007291
 >> iter 62000, loss: 0.004977
 >> iter 63000, loss: 0.012665
 >> iter 64000, loss: 0.007365
 >> iter 65000, loss: 0.004660
 >> iter 66000, loss: 0.003468
 >> iter 67000, loss: 0.003117
 >> iter 68000, loss: 0.003209
 >> iter 69000, loss: 0.002715
 >> iter 70000, loss: 0.002409
   Number of active neurons: 10
 >> iter 71000, loss: 0.056344
 >> iter 72000, loss: 0.051519
 >> iter 73000, loss: 0.031947
 >> iter 74000, loss: 0.044741
 >> iter 75000, loss: 0.103095
 >> iter 76000, loss: 0.041669
 >> iter 77000, loss: 0.031555
 >> iter 78000, loss: 0.066690
 >> iter 79000, loss: 0.050675
 >> iter 80000, loss: 0.022158
   Number of active neurons: 10
 >> iter 81000, loss: 0.010807
 >> iter 82000, loss: 0.024498
 >> iter 83000, loss: 0.023320
 >> iter 84000, loss: 0.020267
 >> iter 85000, loss: 0.038925
 >> iter 86000, loss: 0.037191
 >> iter 87000, loss: 0.025933
 >> iter 88000, loss: 0.011670
 >> iter 89000, loss: 0.006354
 >> iter 90000, loss: 0.004039
   Number of active neurons: 10
 >> iter 91000, loss: 0.056494
 >> iter 92000, loss: 0.024502
 >> iter 93000, loss: 0.017887
 >> iter 94000, loss: 0.008372
 >> iter 95000, loss: 0.064785
 >> iter 96000, loss: 0.043644
 >> iter 97000, loss: 0.062058
 >> iter 98000, loss: 0.025285
 >> iter 99000, loss: 0.011197
 >> iter 100000, loss: 0.005843
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.613773
 >> iter 2000, loss: 9.906100
 >> iter 3000, loss: 5.936160
 >> iter 4000, loss: 3.049907
 >> iter 5000, loss: 1.500882
 >> iter 6000, loss: 0.825609
 >> iter 7000, loss: 0.533486
 >> iter 8000, loss: 0.438744
 >> iter 9000, loss: 0.259394
 >> iter 10000, loss: 0.197838
   Number of active neurons: 10
 >> iter 11000, loss: 0.241535
 >> iter 12000, loss: 0.179693
 >> iter 13000, loss: 0.119896
 >> iter 14000, loss: 0.095628
 >> iter 15000, loss: 0.090052
 >> iter 16000, loss: 0.092980
 >> iter 17000, loss: 0.103761
 >> iter 18000, loss: 0.123194
 >> iter 19000, loss: 0.095936
 >> iter 20000, loss: 0.071417
   Number of active neurons: 10
 >> iter 21000, loss: 0.096460
 >> iter 22000, loss: 0.058069
 >> iter 23000, loss: 0.028663
 >> iter 24000, loss: 0.055867
 >> iter 25000, loss: 0.071317
 >> iter 26000, loss: 0.115990
 >> iter 27000, loss: 0.077086
 >> iter 28000, loss: 0.095842
 >> iter 29000, loss: 0.044803
 >> iter 30000, loss: 0.027969
   Number of active neurons: 10
 >> iter 31000, loss: 0.051219
 >> iter 32000, loss: 0.067380
 >> iter 33000, loss: 0.052800
 >> iter 34000, loss: 0.043872
 >> iter 35000, loss: 0.036583
 >> iter 36000, loss: 0.041193
 >> iter 37000, loss: 0.019041
 >> iter 38000, loss: 0.010828
 >> iter 39000, loss: 0.021751
 >> iter 40000, loss: 0.062987
   Number of active neurons: 10
 >> iter 41000, loss: 0.233556
 >> iter 42000, loss: 0.094632
 >> iter 43000, loss: 0.089378
 >> iter 44000, loss: 0.075798
 >> iter 45000, loss: 0.037839
 >> iter 46000, loss: 0.042009
 >> iter 47000, loss: 0.019382
 >> iter 48000, loss: 0.049639
 >> iter 49000, loss: 0.034424
 >> iter 50000, loss: 0.016191
   Number of active neurons: 10
 >> iter 51000, loss: 0.132268
 >> iter 52000, loss: 0.062472
 >> iter 53000, loss: 0.026974
 >> iter 54000, loss: 0.012950
 >> iter 55000, loss: 0.080031
 >> iter 56000, loss: 0.035429
 >> iter 57000, loss: 0.025313
 >> iter 58000, loss: 0.017015
 >> iter 59000, loss: 0.035941
 >> iter 60000, loss: 0.015888
   Number of active neurons: 10
 >> iter 61000, loss: 0.011498
 >> iter 62000, loss: 0.006519
 >> iter 63000, loss: 0.004679
 >> iter 64000, loss: 0.003847
 >> iter 65000, loss: 0.004771
 >> iter 66000, loss: 0.076792
 >> iter 67000, loss: 0.088474
 >> iter 68000, loss: 0.035228
 >> iter 69000, loss: 0.015757
 >> iter 70000, loss: 0.009843
   Number of active neurons: 10
 >> iter 71000, loss: 0.005879
 >> iter 72000, loss: 0.065543
 >> iter 73000, loss: 0.026504
 >> iter 74000, loss: 0.020803
 >> iter 75000, loss: 0.051911
 >> iter 76000, loss: 0.082676
 >> iter 77000, loss: 0.108269
 >> iter 78000, loss: 0.059809
 >> iter 79000, loss: 0.027614
 >> iter 80000, loss: 0.026980
   Number of active neurons: 10
 >> iter 81000, loss: 0.012737
 >> iter 82000, loss: 0.009574
 >> iter 83000, loss: 0.006395
 >> iter 84000, loss: 0.014984
 >> iter 85000, loss: 0.025769
 >> iter 86000, loss: 0.011474
 >> iter 87000, loss: 0.006014
 >> iter 88000, loss: 0.007631
 >> iter 89000, loss: 0.004631
 >> iter 90000, loss: 0.025637
   Number of active neurons: 10
 >> iter 91000, loss: 0.011360
 >> iter 92000, loss: 0.005649
 >> iter 93000, loss: 0.003856
 >> iter 94000, loss: 0.002655
 >> iter 95000, loss: 0.010865
 >> iter 96000, loss: 0.005657
 >> iter 97000, loss: 0.003340
 >> iter 98000, loss: 0.002264
 >> iter 99000, loss: 0.007050
 >> iter 100000, loss: 0.021392
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 16.897456
 >> iter 2000, loss: 10.197800
 >> iter 3000, loss: 7.498264
 >> iter 4000, loss: 5.310400
 >> iter 5000, loss: 3.063861
 >> iter 6000, loss: 1.730595
 >> iter 7000, loss: 0.982558
 >> iter 8000, loss: 0.721061
 >> iter 9000, loss: 0.502780
 >> iter 10000, loss: 0.380455
   Number of active neurons: 10
 >> iter 11000, loss: 0.365855
 >> iter 12000, loss: 0.324860
 >> iter 13000, loss: 0.256721
 >> iter 14000, loss: 0.164577
 >> iter 15000, loss: 0.132877
 >> iter 16000, loss: 0.125901
 >> iter 17000, loss: 0.142821
 >> iter 18000, loss: 0.080798
 >> iter 19000, loss: 0.079099
 >> iter 20000, loss: 0.115545
   Number of active neurons: 10
 >> iter 21000, loss: 0.133627
 >> iter 22000, loss: 0.071471
 >> iter 23000, loss: 0.041839
 >> iter 24000, loss: 0.052448
 >> iter 25000, loss: 0.063229
 >> iter 26000, loss: 0.190307
 >> iter 27000, loss: 0.102703
 >> iter 28000, loss: 0.114738
 >> iter 29000, loss: 0.065727
 >> iter 30000, loss: 0.064034
   Number of active neurons: 10
 >> iter 31000, loss: 0.037684
 >> iter 32000, loss: 0.068416
 >> iter 33000, loss: 0.093463
 >> iter 34000, loss: 0.110321
 >> iter 35000, loss: 0.066408
 >> iter 36000, loss: 0.056228
 >> iter 37000, loss: 0.041967
 >> iter 38000, loss: 0.019551
 >> iter 39000, loss: 0.023131
 >> iter 40000, loss: 0.045994
   Number of active neurons: 10
 >> iter 41000, loss: 0.073562
 >> iter 42000, loss: 0.059480
 >> iter 43000, loss: 0.096163
 >> iter 44000, loss: 0.062262
 >> iter 45000, loss: 0.032327
 >> iter 46000, loss: 0.016165
 >> iter 47000, loss: 0.026172
 >> iter 48000, loss: 0.080446
 >> iter 49000, loss: 0.075537
 >> iter 50000, loss: 0.068259
   Number of active neurons: 10
 >> iter 51000, loss: 0.046051
 >> iter 52000, loss: 0.075651
 >> iter 53000, loss: 0.107285
 >> iter 54000, loss: 0.051782
 >> iter 55000, loss: 0.167324
 >> iter 56000, loss: 0.067348
 >> iter 57000, loss: 0.076080
 >> iter 58000, loss: 0.075422
 >> iter 59000, loss: 0.081389
 >> iter 60000, loss: 0.064101
   Number of active neurons: 10
 >> iter 61000, loss: 0.084432
 >> iter 62000, loss: 0.052342
 >> iter 63000, loss: 0.065453
 >> iter 64000, loss: 0.028747
 >> iter 65000, loss: 0.032263
 >> iter 66000, loss: 0.058132
 >> iter 67000, loss: 0.028414
 >> iter 68000, loss: 0.080025
 >> iter 69000, loss: 0.052435
 >> iter 70000, loss: 0.024184
   Number of active neurons: 10
 >> iter 71000, loss: 0.039045
 >> iter 72000, loss: 0.044740
 >> iter 73000, loss: 0.041353
 >> iter 74000, loss: 0.033165
 >> iter 75000, loss: 0.021530
 >> iter 76000, loss: 0.052477
 >> iter 77000, loss: 0.052074
 >> iter 78000, loss: 0.045883
 >> iter 79000, loss: 0.028528
 >> iter 80000, loss: 0.019578
   Number of active neurons: 10
 >> iter 81000, loss: 0.014812
 >> iter 82000, loss: 0.015086
 >> iter 83000, loss: 0.160682
 >> iter 84000, loss: 0.063222
 >> iter 85000, loss: 0.026641
 >> iter 86000, loss: 0.063629
 >> iter 87000, loss: 0.032376
 >> iter 88000, loss: 0.031296
 >> iter 89000, loss: 0.048031
 >> iter 90000, loss: 0.021918
   Number of active neurons: 10
 >> iter 91000, loss: 0.011336
 >> iter 92000, loss: 0.006358
 >> iter 93000, loss: 0.006296
 >> iter 94000, loss: 0.023117
 >> iter 95000, loss: 0.010862
 >> iter 96000, loss: 0.005726
 >> iter 97000, loss: 0.004092
 >> iter 98000, loss: 0.018389
 >> iter 99000, loss: 0.046602
 >> iter 100000, loss: 0.028724
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.480458
 >> iter 2000, loss: 9.934947
 >> iter 3000, loss: 7.363655
 >> iter 4000, loss: 5.900204
 >> iter 5000, loss: 4.113099
 >> iter 6000, loss: 2.349574
 >> iter 7000, loss: 1.542225
 >> iter 8000, loss: 1.209203
 >> iter 9000, loss: 0.889882
 >> iter 10000, loss: 0.537830
   Number of active neurons: 10
 >> iter 11000, loss: 0.505113
 >> iter 12000, loss: 0.500813
 >> iter 13000, loss: 0.361480
 >> iter 14000, loss: 0.253341
 >> iter 15000, loss: 0.207625
 >> iter 16000, loss: 0.254951
 >> iter 17000, loss: 0.165050
 >> iter 18000, loss: 0.213353
 >> iter 19000, loss: 0.113561
 >> iter 20000, loss: 0.082518
   Number of active neurons: 10
 >> iter 21000, loss: 0.182861
 >> iter 22000, loss: 0.149076
 >> iter 23000, loss: 0.136985
 >> iter 24000, loss: 0.197232
 >> iter 25000, loss: 0.155896
 >> iter 26000, loss: 0.080223
 >> iter 27000, loss: 0.064390
 >> iter 28000, loss: 0.065707
 >> iter 29000, loss: 0.061103
 >> iter 30000, loss: 0.095355
   Number of active neurons: 10
 >> iter 31000, loss: 0.046237
 >> iter 32000, loss: 0.116219
 >> iter 33000, loss: 0.099386
 >> iter 34000, loss: 0.062478
 >> iter 35000, loss: 0.051595
 >> iter 36000, loss: 0.095037
 >> iter 37000, loss: 0.119718
 >> iter 38000, loss: 0.080436
 >> iter 39000, loss: 0.092014
 >> iter 40000, loss: 0.060203
   Number of active neurons: 10
 >> iter 41000, loss: 0.028392
 >> iter 42000, loss: 0.035295
 >> iter 43000, loss: 0.086595
 >> iter 44000, loss: 0.055448
 >> iter 45000, loss: 0.052243
 >> iter 46000, loss: 0.066173
 >> iter 47000, loss: 0.071998
 >> iter 48000, loss: 0.037275
 >> iter 49000, loss: 0.017955
 >> iter 50000, loss: 0.011651
   Number of active neurons: 10
 >> iter 51000, loss: 0.020433
 >> iter 52000, loss: 0.021195
 >> iter 53000, loss: 0.047514
 >> iter 54000, loss: 0.045690
 >> iter 55000, loss: 0.031700
 >> iter 56000, loss: 0.015032
 >> iter 57000, loss: 0.025627
 >> iter 58000, loss: 0.017679
 >> iter 59000, loss: 0.009266
 >> iter 60000, loss: 0.026609
   Number of active neurons: 10
 >> iter 61000, loss: 0.067749
 >> iter 62000, loss: 0.040701
 >> iter 63000, loss: 0.057098
 >> iter 64000, loss: 0.023747
 >> iter 65000, loss: 0.028219
 >> iter 66000, loss: 0.013074
 >> iter 67000, loss: 0.017978
 >> iter 68000, loss: 0.059546
 >> iter 69000, loss: 0.036274
 >> iter 70000, loss: 0.049982
   Number of active neurons: 10
 >> iter 71000, loss: 0.055638
 >> iter 72000, loss: 0.038773
 >> iter 73000, loss: 0.016735
 >> iter 74000, loss: 0.008164
 >> iter 75000, loss: 0.018704
 >> iter 76000, loss: 0.027051
 >> iter 77000, loss: 0.018222
 >> iter 78000, loss: 0.053462
 >> iter 79000, loss: 0.050013
 >> iter 80000, loss: 0.037174
   Number of active neurons: 10
 >> iter 81000, loss: 0.068169
 >> iter 82000, loss: 0.041365
 >> iter 83000, loss: 0.065032
 >> iter 84000, loss: 0.026688
 >> iter 85000, loss: 0.012252
 >> iter 86000, loss: 0.006508
 >> iter 87000, loss: 0.030045
 >> iter 88000, loss: 0.038362
 >> iter 89000, loss: 0.049347
 >> iter 90000, loss: 0.021043
   Number of active neurons: 10
 >> iter 91000, loss: 0.009823
 >> iter 92000, loss: 0.023837
 >> iter 93000, loss: 0.010624
 >> iter 94000, loss: 0.012219
 >> iter 95000, loss: 0.018696
 >> iter 96000, loss: 0.008605
 >> iter 97000, loss: 0.004871
 >> iter 98000, loss: 0.035349
 >> iter 99000, loss: 0.037675
 >> iter 100000, loss: 0.056473
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.950032
 >> iter 2000, loss: 10.247859
 >> iter 3000, loss: 7.397709
 >> iter 4000, loss: 5.244534
 >> iter 5000, loss: 3.281651
 >> iter 6000, loss: 1.910077
 >> iter 7000, loss: 1.391994
 >> iter 8000, loss: 1.076536
 >> iter 9000, loss: 1.042552
 >> iter 10000, loss: 0.703256
   Number of active neurons: 10
 >> iter 11000, loss: 0.652600
 >> iter 12000, loss: 0.534007
 >> iter 13000, loss: 0.472164
 >> iter 14000, loss: 0.355110
 >> iter 15000, loss: 0.316333
 >> iter 16000, loss: 0.298074
 >> iter 17000, loss: 0.289079
 >> iter 18000, loss: 0.578977
 >> iter 19000, loss: 0.383338
 >> iter 20000, loss: 0.321462
   Number of active neurons: 10
 >> iter 21000, loss: 0.363584
 >> iter 22000, loss: 0.289967
 >> iter 23000, loss: 0.300451
 >> iter 24000, loss: 0.380808
 >> iter 25000, loss: 0.236422
 >> iter 26000, loss: 0.191592
 >> iter 27000, loss: 0.235830
 >> iter 28000, loss: 0.268532
 >> iter 29000, loss: 0.270051
 >> iter 30000, loss: 0.330828
   Number of active neurons: 10
 >> iter 31000, loss: 0.209120
 >> iter 32000, loss: 0.208697
 >> iter 33000, loss: 0.168655
 >> iter 34000, loss: 0.146335
 >> iter 35000, loss: 0.085560
 >> iter 36000, loss: 0.097005
 >> iter 37000, loss: 0.083006
 >> iter 38000, loss: 0.090179
 >> iter 39000, loss: 0.108319
 >> iter 40000, loss: 0.118845
   Number of active neurons: 10
 >> iter 41000, loss: 0.122098
 >> iter 42000, loss: 0.195428
 >> iter 43000, loss: 0.146772
 >> iter 44000, loss: 0.101779
 >> iter 45000, loss: 0.126997
 >> iter 46000, loss: 0.111623
 >> iter 47000, loss: 0.080183
 >> iter 48000, loss: 0.095136
 >> iter 49000, loss: 0.046023
 >> iter 50000, loss: 0.027618
   Number of active neurons: 10
 >> iter 51000, loss: 0.047482
 >> iter 52000, loss: 0.076732
 >> iter 53000, loss: 0.037716
 >> iter 54000, loss: 0.050265
 >> iter 55000, loss: 0.024618
 >> iter 56000, loss: 0.050510
 >> iter 57000, loss: 0.093296
 >> iter 58000, loss: 0.056342
 >> iter 59000, loss: 0.034914
 >> iter 60000, loss: 0.077364
   Number of active neurons: 10
 >> iter 61000, loss: 0.078966
 >> iter 62000, loss: 0.049653
 >> iter 63000, loss: 0.024604
 >> iter 64000, loss: 0.035458
 >> iter 65000, loss: 0.069264
 >> iter 66000, loss: 0.030725
 >> iter 67000, loss: 0.039526
 >> iter 68000, loss: 0.058268
 >> iter 69000, loss: 0.154215
 >> iter 70000, loss: 0.103828
   Number of active neurons: 10
 >> iter 71000, loss: 0.083376
 >> iter 72000, loss: 0.109368
 >> iter 73000, loss: 0.118877
 >> iter 74000, loss: 0.063689
 >> iter 75000, loss: 0.028878
 >> iter 76000, loss: 0.055081
 >> iter 77000, loss: 0.101833
 >> iter 78000, loss: 0.079096
 >> iter 79000, loss: 0.048816
 >> iter 80000, loss: 0.092469
   Number of active neurons: 10
 >> iter 81000, loss: 0.084254
 >> iter 82000, loss: 0.110710
 >> iter 83000, loss: 0.118880
 >> iter 84000, loss: 0.062477
 >> iter 85000, loss: 0.081106
 >> iter 86000, loss: 0.052019
 >> iter 87000, loss: 0.033222
 >> iter 88000, loss: 0.099963
 >> iter 89000, loss: 0.094914
 >> iter 90000, loss: 0.083888
   Number of active neurons: 10
 >> iter 91000, loss: 0.050767
 >> iter 92000, loss: 0.084202
 >> iter 93000, loss: 0.037052
 >> iter 94000, loss: 0.052944
 >> iter 95000, loss: 0.117414
 >> iter 96000, loss: 0.089708
 >> iter 97000, loss: 0.038417
 >> iter 98000, loss: 0.077938
 >> iter 99000, loss: 0.055253
 >> iter 100000, loss: 0.040676
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.749303
 >> iter 2000, loss: 10.100618
 >> iter 3000, loss: 7.317304
 >> iter 4000, loss: 5.350486
 >> iter 5000, loss: 4.091359
 >> iter 6000, loss: 3.109508
 >> iter 7000, loss: 2.630064
 >> iter 8000, loss: 1.961780
 >> iter 9000, loss: 1.708125
 >> iter 10000, loss: 1.410323
   Number of active neurons: 10
 >> iter 11000, loss: 1.283238
 >> iter 12000, loss: 1.013583
 >> iter 13000, loss: 0.764449
 >> iter 14000, loss: 0.737836
 >> iter 15000, loss: 0.618416
 >> iter 16000, loss: 0.546080
 >> iter 17000, loss: 0.562008
 >> iter 18000, loss: 0.364483
 >> iter 19000, loss: 0.402701
 >> iter 20000, loss: 0.473935
   Number of active neurons: 10
 >> iter 21000, loss: 0.409094
 >> iter 22000, loss: 0.253860
 >> iter 23000, loss: 0.194821
 >> iter 24000, loss: 0.213070
 >> iter 25000, loss: 0.188440
 >> iter 26000, loss: 0.139622
 >> iter 27000, loss: 0.156023
 >> iter 28000, loss: 0.214223
 >> iter 29000, loss: 0.145912
 >> iter 30000, loss: 0.150963
   Number of active neurons: 10
 >> iter 31000, loss: 0.091045
 >> iter 32000, loss: 0.083435
 >> iter 33000, loss: 0.179235
 >> iter 34000, loss: 0.219999
 >> iter 35000, loss: 0.171331
 >> iter 36000, loss: 0.149191
 >> iter 37000, loss: 0.083069
 >> iter 38000, loss: 0.064481
 >> iter 39000, loss: 0.050090
 >> iter 40000, loss: 0.055619
   Number of active neurons: 10
 >> iter 41000, loss: 0.089327
 >> iter 42000, loss: 0.053366
 >> iter 43000, loss: 0.023972
 >> iter 44000, loss: 0.065434
 >> iter 45000, loss: 0.089330
 >> iter 46000, loss: 0.044284
 >> iter 47000, loss: 0.074152
 >> iter 48000, loss: 0.047905
 >> iter 49000, loss: 0.085767
 >> iter 50000, loss: 0.079248
   Number of active neurons: 10
 >> iter 51000, loss: 0.073483
 >> iter 52000, loss: 0.073801
 >> iter 53000, loss: 0.125014
 >> iter 54000, loss: 0.128460
 >> iter 55000, loss: 0.064707
 >> iter 56000, loss: 0.080321
 >> iter 57000, loss: 0.081703
 >> iter 58000, loss: 0.059422
 >> iter 59000, loss: 0.029234
 >> iter 60000, loss: 0.042026
   Number of active neurons: 10
 >> iter 61000, loss: 0.124962
 >> iter 62000, loss: 0.054147
 >> iter 63000, loss: 0.049330
 >> iter 64000, loss: 0.113927
 >> iter 65000, loss: 0.083009
 >> iter 66000, loss: 0.048373
 >> iter 67000, loss: 0.099540
 >> iter 68000, loss: 0.042019
 >> iter 69000, loss: 0.070672
 >> iter 70000, loss: 0.050165
   Number of active neurons: 10
 >> iter 71000, loss: 0.044921
 >> iter 72000, loss: 0.117224
 >> iter 73000, loss: 0.084461
 >> iter 74000, loss: 0.046910
 >> iter 75000, loss: 0.060684
 >> iter 76000, loss: 0.040181
 >> iter 77000, loss: 0.018435
 >> iter 78000, loss: 0.009792
 >> iter 79000, loss: 0.006942
 >> iter 80000, loss: 0.005064
   Number of active neurons: 10
 >> iter 81000, loss: 0.015843
 >> iter 82000, loss: 0.023877
 >> iter 83000, loss: 0.031290
 >> iter 84000, loss: 0.013710
 >> iter 85000, loss: 0.007411
 >> iter 86000, loss: 0.041091
 >> iter 87000, loss: 0.059934
 >> iter 88000, loss: 0.027856
 >> iter 89000, loss: 0.012640
 >> iter 90000, loss: 0.007572
   Number of active neurons: 10
 >> iter 91000, loss: 0.053497
 >> iter 92000, loss: 0.080950
 >> iter 93000, loss: 0.066500
 >> iter 94000, loss: 0.027198
 >> iter 95000, loss: 0.043886
 >> iter 96000, loss: 0.018691
 >> iter 97000, loss: 0.090447
 >> iter 98000, loss: 0.048930
 >> iter 99000, loss: 0.050794
 >> iter 100000, loss: 0.022148
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.760614
 >> iter 2000, loss: 9.915728
 >> iter 3000, loss: 6.769821
 >> iter 4000, loss: 4.075926
 >> iter 5000, loss: 2.135696
 >> iter 6000, loss: 1.231687
 >> iter 7000, loss: 0.671671
 >> iter 8000, loss: 0.544744
 >> iter 9000, loss: 0.424275
 >> iter 10000, loss: 0.302664
   Number of active neurons: 10
 >> iter 11000, loss: 0.240954
 >> iter 12000, loss: 0.196188
 >> iter 13000, loss: 0.190772
 >> iter 14000, loss: 0.164545
 >> iter 15000, loss: 0.159195
 >> iter 16000, loss: 0.134640
 >> iter 17000, loss: 0.098869
 >> iter 18000, loss: 0.079312
 >> iter 19000, loss: 0.075443
 >> iter 20000, loss: 0.093685
   Number of active neurons: 10
 >> iter 21000, loss: 0.091030
 >> iter 22000, loss: 0.091383
 >> iter 23000, loss: 0.111974
 >> iter 24000, loss: 0.072060
 >> iter 25000, loss: 0.049890
 >> iter 26000, loss: 0.100117
 >> iter 27000, loss: 0.085433
 >> iter 28000, loss: 0.147220
 >> iter 29000, loss: 0.108536
 >> iter 30000, loss: 0.067415
   Number of active neurons: 10
 >> iter 31000, loss: 0.032609
 >> iter 32000, loss: 0.077135
 >> iter 33000, loss: 0.037723
 >> iter 34000, loss: 0.044244
 >> iter 35000, loss: 0.053327
 >> iter 36000, loss: 0.092670
 >> iter 37000, loss: 0.057453
 >> iter 38000, loss: 0.031884
 >> iter 39000, loss: 0.016198
 >> iter 40000, loss: 0.031945
   Number of active neurons: 10
 >> iter 41000, loss: 0.043980
 >> iter 42000, loss: 0.052989
 >> iter 43000, loss: 0.042043
 >> iter 44000, loss: 0.028267
 >> iter 45000, loss: 0.014213
 >> iter 46000, loss: 0.023188
 >> iter 47000, loss: 0.026775
 >> iter 48000, loss: 0.014555
 >> iter 49000, loss: 0.013274
 >> iter 50000, loss: 0.010331
   Number of active neurons: 10
 >> iter 51000, loss: 0.022375
 >> iter 52000, loss: 0.045616
 >> iter 53000, loss: 0.036521
 >> iter 54000, loss: 0.051321
 >> iter 55000, loss: 0.042737
 >> iter 56000, loss: 0.018438
 >> iter 57000, loss: 0.013788
 >> iter 58000, loss: 0.007716
 >> iter 59000, loss: 0.005214
 >> iter 60000, loss: 0.056712
   Number of active neurons: 10
 >> iter 61000, loss: 0.041549
 >> iter 62000, loss: 0.039439
 >> iter 63000, loss: 0.023210
 >> iter 64000, loss: 0.043122
 >> iter 65000, loss: 0.019936
 >> iter 66000, loss: 0.017967
 >> iter 67000, loss: 0.019909
 >> iter 68000, loss: 0.010531
 >> iter 69000, loss: 0.030592
 >> iter 70000, loss: 0.040536
   Number of active neurons: 10
 >> iter 71000, loss: 0.017476
 >> iter 72000, loss: 0.023301
 >> iter 73000, loss: 0.046351
 >> iter 74000, loss: 0.070026
 >> iter 75000, loss: 0.042492
 >> iter 76000, loss: 0.048395
 >> iter 77000, loss: 0.020837
 >> iter 78000, loss: 0.035694
 >> iter 79000, loss: 0.037241
 >> iter 80000, loss: 0.036701
   Number of active neurons: 10
 >> iter 81000, loss: 0.021614
 >> iter 82000, loss: 0.010834
 >> iter 83000, loss: 0.024808
 >> iter 84000, loss: 0.011840
 >> iter 85000, loss: 0.006443
 >> iter 86000, loss: 0.020253
 >> iter 87000, loss: 0.046100
 >> iter 88000, loss: 0.019889
 >> iter 89000, loss: 0.059408
 >> iter 90000, loss: 0.024773
   Number of active neurons: 10
 >> iter 91000, loss: 0.010988
 >> iter 92000, loss: 0.031458
 >> iter 93000, loss: 0.046169
 >> iter 94000, loss: 0.019542
 >> iter 95000, loss: 0.015007
 >> iter 96000, loss: 0.007384
 >> iter 97000, loss: 0.009815
 >> iter 98000, loss: 0.005299
 >> iter 99000, loss: 0.003699
 >> iter 100000, loss: 0.089028
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.617441
 >> iter 2000, loss: 9.935140
 >> iter 3000, loss: 7.006359
 >> iter 4000, loss: 4.575948
 >> iter 5000, loss: 2.606191
 >> iter 6000, loss: 1.528604
 >> iter 7000, loss: 0.896702
 >> iter 8000, loss: 0.764164
 >> iter 9000, loss: 0.528702
 >> iter 10000, loss: 0.478389
   Number of active neurons: 10
 >> iter 11000, loss: 0.403773
 >> iter 12000, loss: 0.323174
 >> iter 13000, loss: 0.287569
 >> iter 14000, loss: 0.286449
 >> iter 15000, loss: 0.193203
 >> iter 16000, loss: 0.223217
 >> iter 17000, loss: 0.328770
 >> iter 18000, loss: 0.282716
 >> iter 19000, loss: 0.208616
 >> iter 20000, loss: 0.220173
   Number of active neurons: 10
 >> iter 21000, loss: 0.115140
 >> iter 22000, loss: 0.183506
 >> iter 23000, loss: 0.130264
 >> iter 24000, loss: 0.126264
 >> iter 25000, loss: 0.062018
 >> iter 26000, loss: 0.059110
 >> iter 27000, loss: 0.066752
 >> iter 28000, loss: 0.033246
 >> iter 29000, loss: 0.089908
 >> iter 30000, loss: 0.121835
   Number of active neurons: 10
 >> iter 31000, loss: 0.064261
 >> iter 32000, loss: 0.106050
 >> iter 33000, loss: 0.134793
 >> iter 34000, loss: 0.091051
 >> iter 35000, loss: 0.077224
 >> iter 36000, loss: 0.072274
 >> iter 37000, loss: 0.075901
 >> iter 38000, loss: 0.058367
 >> iter 39000, loss: 0.062976
 >> iter 40000, loss: 0.041375
   Number of active neurons: 10
 >> iter 41000, loss: 0.065356
 >> iter 42000, loss: 0.027726
 >> iter 43000, loss: 0.029933
 >> iter 44000, loss: 0.092402
 >> iter 45000, loss: 0.085921
 >> iter 46000, loss: 0.057166
 >> iter 47000, loss: 0.047526
 >> iter 48000, loss: 0.092541
 >> iter 49000, loss: 0.052480
 >> iter 50000, loss: 0.047297
   Number of active neurons: 10
 >> iter 51000, loss: 0.021269
 >> iter 52000, loss: 0.082194
 >> iter 53000, loss: 0.056756
 >> iter 54000, loss: 0.101446
 >> iter 55000, loss: 0.115869
 >> iter 56000, loss: 0.047684
 >> iter 57000, loss: 0.043430
 >> iter 58000, loss: 0.115162
 >> iter 59000, loss: 0.073695
 >> iter 60000, loss: 0.105246
   Number of active neurons: 10
 >> iter 61000, loss: 0.103683
 >> iter 62000, loss: 0.093364
 >> iter 63000, loss: 0.044044
 >> iter 64000, loss: 0.044279
 >> iter 65000, loss: 0.019590
 >> iter 66000, loss: 0.047649
 >> iter 67000, loss: 0.067857
 >> iter 68000, loss: 0.064270
 >> iter 69000, loss: 0.089941
 >> iter 70000, loss: 0.052478
   Number of active neurons: 10
 >> iter 71000, loss: 0.070685
 >> iter 72000, loss: 0.032118
 >> iter 73000, loss: 0.015504
 >> iter 74000, loss: 0.092840
 >> iter 75000, loss: 0.051024
 >> iter 76000, loss: 0.021819
 >> iter 77000, loss: 0.010480
 >> iter 78000, loss: 0.021838
 >> iter 79000, loss: 0.010421
 >> iter 80000, loss: 0.029215
   Number of active neurons: 10
 >> iter 81000, loss: 0.012906
 >> iter 82000, loss: 0.009042
 >> iter 83000, loss: 0.065047
 >> iter 84000, loss: 0.037835
 >> iter 85000, loss: 0.016456
 >> iter 86000, loss: 0.015889
 >> iter 87000, loss: 0.015999
 >> iter 88000, loss: 0.025667
 >> iter 89000, loss: 0.015832
 >> iter 90000, loss: 0.061605
   Number of active neurons: 10
 >> iter 91000, loss: 0.028338
 >> iter 92000, loss: 0.015564
 >> iter 93000, loss: 0.008665
 >> iter 94000, loss: 0.029024
 >> iter 95000, loss: 0.017386
 >> iter 96000, loss: 0.008785
 >> iter 97000, loss: 0.049997
 >> iter 98000, loss: 0.021902
 >> iter 99000, loss: 0.010521
 >> iter 100000, loss: 0.005222
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.518155
 >> iter 2000, loss: 9.762273
 >> iter 3000, loss: 5.477122
 >> iter 4000, loss: 2.700375
 >> iter 5000, loss: 1.372264
 >> iter 6000, loss: 0.753527
 >> iter 7000, loss: 0.649225
 >> iter 8000, loss: 0.397832
 >> iter 9000, loss: 0.381228
 >> iter 10000, loss: 0.171658
   Number of active neurons: 10
 >> iter 11000, loss: 0.200021
 >> iter 12000, loss: 0.140025
 >> iter 13000, loss: 0.160077
 >> iter 14000, loss: 0.112089
 >> iter 15000, loss: 0.103739
 >> iter 16000, loss: 0.096598
 >> iter 17000, loss: 0.062804
 >> iter 18000, loss: 0.072977
 >> iter 19000, loss: 0.061594
 >> iter 20000, loss: 0.072879
   Number of active neurons: 10
 >> iter 21000, loss: 0.037160
 >> iter 22000, loss: 0.061464
 >> iter 23000, loss: 0.031322
 >> iter 24000, loss: 0.164626
 >> iter 25000, loss: 0.105595
 >> iter 26000, loss: 0.045836
 >> iter 27000, loss: 0.022580
 >> iter 28000, loss: 0.065564
 >> iter 29000, loss: 0.101909
 >> iter 30000, loss: 0.081406
   Number of active neurons: 10
 >> iter 31000, loss: 0.084061
 >> iter 32000, loss: 0.048989
 >> iter 33000, loss: 0.023985
 >> iter 34000, loss: 0.083081
 >> iter 35000, loss: 0.073678
 >> iter 36000, loss: 0.054962
 >> iter 37000, loss: 0.025791
 >> iter 38000, loss: 0.013820
 >> iter 39000, loss: 0.008738
 >> iter 40000, loss: 0.036249
   Number of active neurons: 10
 >> iter 41000, loss: 0.082439
 >> iter 42000, loss: 0.034775
 >> iter 43000, loss: 0.023321
 >> iter 44000, loss: 0.022686
 >> iter 45000, loss: 0.012523
 >> iter 46000, loss: 0.013009
 >> iter 47000, loss: 0.031753
 >> iter 48000, loss: 0.019267
 >> iter 49000, loss: 0.009868
 >> iter 50000, loss: 0.007473
   Number of active neurons: 10
 >> iter 51000, loss: 0.068006
 >> iter 52000, loss: 0.036242
 >> iter 53000, loss: 0.016448
 >> iter 54000, loss: 0.027856
 >> iter 55000, loss: 0.060802
 >> iter 56000, loss: 0.025886
 >> iter 57000, loss: 0.039096
 >> iter 58000, loss: 0.024160
 >> iter 59000, loss: 0.012538
 >> iter 60000, loss: 0.007191
   Number of active neurons: 10
 >> iter 61000, loss: 0.005005
 >> iter 62000, loss: 0.016642
 >> iter 63000, loss: 0.047481
 >> iter 64000, loss: 0.026301
 >> iter 65000, loss: 0.019614
 >> iter 66000, loss: 0.009290
 >> iter 67000, loss: 0.012193
 >> iter 68000, loss: 0.006740
 >> iter 69000, loss: 0.004753
 >> iter 70000, loss: 0.003847
   Number of active neurons: 10
 >> iter 71000, loss: 0.003311
 >> iter 72000, loss: 0.023822
 >> iter 73000, loss: 0.049609
 >> iter 74000, loss: 0.023754
 >> iter 75000, loss: 0.032378
 >> iter 76000, loss: 0.026982
 >> iter 77000, loss: 0.023776
 >> iter 78000, loss: 0.010621
 >> iter 79000, loss: 0.005804
 >> iter 80000, loss: 0.005975
   Number of active neurons: 10
 >> iter 81000, loss: 0.003933
 >> iter 82000, loss: 0.021641
 >> iter 83000, loss: 0.010034
 >> iter 84000, loss: 0.005585
 >> iter 85000, loss: 0.004065
 >> iter 86000, loss: 0.035130
 >> iter 87000, loss: 0.123105
 >> iter 88000, loss: 0.047942
 >> iter 89000, loss: 0.020236
 >> iter 90000, loss: 0.009625
   Number of active neurons: 10
 >> iter 91000, loss: 0.010761
 >> iter 92000, loss: 0.005980
 >> iter 93000, loss: 0.004163
 >> iter 94000, loss: 0.021025
 >> iter 95000, loss: 0.018503
 >> iter 96000, loss: 0.008696
 >> iter 97000, loss: 0.039822
 >> iter 98000, loss: 0.029366
 >> iter 99000, loss: 0.013257
 >> iter 100000, loss: 0.024041
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.374763
 >> iter 2000, loss: 9.654737
 >> iter 3000, loss: 6.177080
 >> iter 4000, loss: 3.541493
 >> iter 5000, loss: 1.818472
 >> iter 6000, loss: 0.904962
 >> iter 7000, loss: 0.700096
 >> iter 8000, loss: 0.485157
 >> iter 9000, loss: 0.356022
 >> iter 10000, loss: 0.221599
   Number of active neurons: 10
 >> iter 11000, loss: 0.256164
 >> iter 12000, loss: 0.155681
 >> iter 13000, loss: 0.203505
 >> iter 14000, loss: 0.203309
 >> iter 15000, loss: 0.177051
 >> iter 16000, loss: 0.090804
 >> iter 17000, loss: 0.049861
 >> iter 18000, loss: 0.096555
 >> iter 19000, loss: 0.098987
 >> iter 20000, loss: 0.108333
   Number of active neurons: 10
 >> iter 21000, loss: 0.065117
 >> iter 22000, loss: 0.042845
 >> iter 23000, loss: 0.161523
 >> iter 24000, loss: 0.137676
 >> iter 25000, loss: 0.108492
 >> iter 26000, loss: 0.059918
 >> iter 27000, loss: 0.032177
 >> iter 28000, loss: 0.053144
 >> iter 29000, loss: 0.051856
 >> iter 30000, loss: 0.096199
   Number of active neurons: 10
 >> iter 31000, loss: 0.135458
 >> iter 32000, loss: 0.170911
 >> iter 33000, loss: 0.081510
 >> iter 34000, loss: 0.042642
 >> iter 35000, loss: 0.038668
 >> iter 36000, loss: 0.067283
 >> iter 37000, loss: 0.108442
 >> iter 38000, loss: 0.048867
 >> iter 39000, loss: 0.072331
 >> iter 40000, loss: 0.038750
   Number of active neurons: 10
 >> iter 41000, loss: 0.035861
 >> iter 42000, loss: 0.036530
 >> iter 43000, loss: 0.043518
 >> iter 44000, loss: 0.021012
 >> iter 45000, loss: 0.026570
 >> iter 46000, loss: 0.012866
 >> iter 47000, loss: 0.007060
 >> iter 48000, loss: 0.057134
 >> iter 49000, loss: 0.056812
 >> iter 50000, loss: 0.067060
   Number of active neurons: 10
 >> iter 51000, loss: 0.085013
 >> iter 52000, loss: 0.098804
 >> iter 53000, loss: 0.063330
 >> iter 54000, loss: 0.079126
 >> iter 55000, loss: 0.055405
 >> iter 56000, loss: 0.042671
 >> iter 57000, loss: 0.024398
 >> iter 58000, loss: 0.079174
 >> iter 59000, loss: 0.033993
 >> iter 60000, loss: 0.015833
   Number of active neurons: 10
 >> iter 61000, loss: 0.033511
 >> iter 62000, loss: 0.096816
 >> iter 63000, loss: 0.156579
 >> iter 64000, loss: 0.108172
 >> iter 65000, loss: 0.044582
 >> iter 66000, loss: 0.020110
 >> iter 67000, loss: 0.010893
 >> iter 68000, loss: 0.006349
 >> iter 69000, loss: 0.031706
 >> iter 70000, loss: 0.066100
   Number of active neurons: 10
 >> iter 71000, loss: 0.046584
 >> iter 72000, loss: 0.019705
 >> iter 73000, loss: 0.019996
 >> iter 74000, loss: 0.009257
 >> iter 75000, loss: 0.037589
 >> iter 76000, loss: 0.016647
 >> iter 77000, loss: 0.009757
 >> iter 78000, loss: 0.022727
 >> iter 79000, loss: 0.044684
 >> iter 80000, loss: 0.018570
   Number of active neurons: 10
 >> iter 81000, loss: 0.008779
 >> iter 82000, loss: 0.004856
 >> iter 83000, loss: 0.011997
 >> iter 84000, loss: 0.025760
 >> iter 85000, loss: 0.034319
 >> iter 86000, loss: 0.051789
 >> iter 87000, loss: 0.035083
 >> iter 88000, loss: 0.015153
 >> iter 89000, loss: 0.046196
 >> iter 90000, loss: 0.019344
   Number of active neurons: 10
 >> iter 91000, loss: 0.058922
 >> iter 92000, loss: 0.024529
 >> iter 93000, loss: 0.011259
 >> iter 94000, loss: 0.005789
 >> iter 95000, loss: 0.050748
 >> iter 96000, loss: 0.020443
 >> iter 97000, loss: 0.012636
 >> iter 98000, loss: 0.007252
 >> iter 99000, loss: 0.020670
 >> iter 100000, loss: 0.014682
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 16.836814
 >> iter 2000, loss: 10.037251
 >> iter 3000, loss: 7.522784
 >> iter 4000, loss: 5.860210
 >> iter 5000, loss: 4.347403
 >> iter 6000, loss: 2.919931
 >> iter 7000, loss: 1.862036
 >> iter 8000, loss: 1.034275
 >> iter 9000, loss: 0.737396
 >> iter 10000, loss: 0.509907
   Number of active neurons: 10
 >> iter 11000, loss: 0.307445
 >> iter 12000, loss: 0.219853
 >> iter 13000, loss: 0.291875
 >> iter 14000, loss: 0.190749
 >> iter 15000, loss: 0.105245
 >> iter 16000, loss: 0.096909
 >> iter 17000, loss: 0.088197
 >> iter 18000, loss: 0.042378
 >> iter 19000, loss: 0.050923
 >> iter 20000, loss: 0.097564
   Number of active neurons: 10
 >> iter 21000, loss: 0.127938
 >> iter 22000, loss: 0.067788
 >> iter 23000, loss: 0.071068
 >> iter 24000, loss: 0.111330
 >> iter 25000, loss: 0.120692
 >> iter 26000, loss: 0.095418
 >> iter 27000, loss: 0.094917
 >> iter 28000, loss: 0.112253
 >> iter 29000, loss: 0.067475
 >> iter 30000, loss: 0.032237
   Number of active neurons: 10
 >> iter 31000, loss: 0.043739
 >> iter 32000, loss: 0.051286
 >> iter 33000, loss: 0.072100
 >> iter 34000, loss: 0.030712
 >> iter 35000, loss: 0.037523
 >> iter 36000, loss: 0.040140
 >> iter 37000, loss: 0.064334
 >> iter 38000, loss: 0.060648
 >> iter 39000, loss: 0.038193
 >> iter 40000, loss: 0.018398
   Number of active neurons: 10
 >> iter 41000, loss: 0.052486
 >> iter 42000, loss: 0.031481
 >> iter 43000, loss: 0.055119
 >> iter 44000, loss: 0.085539
 >> iter 45000, loss: 0.085535
 >> iter 46000, loss: 0.035395
 >> iter 47000, loss: 0.086754
 >> iter 48000, loss: 0.040390
 >> iter 49000, loss: 0.024398
 >> iter 50000, loss: 0.016901
   Number of active neurons: 10
 >> iter 51000, loss: 0.069164
 >> iter 52000, loss: 0.036947
 >> iter 53000, loss: 0.016396
 >> iter 54000, loss: 0.008301
 >> iter 55000, loss: 0.105582
 >> iter 56000, loss: 0.042493
 >> iter 57000, loss: 0.022965
 >> iter 58000, loss: 0.035996
 >> iter 59000, loss: 0.041080
 >> iter 60000, loss: 0.049013
   Number of active neurons: 10
 >> iter 61000, loss: 0.020661
 >> iter 62000, loss: 0.009468
 >> iter 63000, loss: 0.016562
 >> iter 64000, loss: 0.008072
 >> iter 65000, loss: 0.013726
 >> iter 66000, loss: 0.019508
 >> iter 67000, loss: 0.010912
 >> iter 68000, loss: 0.022031
 >> iter 69000, loss: 0.010532
 >> iter 70000, loss: 0.005519
   Number of active neurons: 10
 >> iter 71000, loss: 0.016429
 >> iter 72000, loss: 0.007610
 >> iter 73000, loss: 0.034255
 >> iter 74000, loss: 0.014404
 >> iter 75000, loss: 0.006930
 >> iter 76000, loss: 0.024043
 >> iter 77000, loss: 0.010813
 >> iter 78000, loss: 0.022830
 >> iter 79000, loss: 0.010309
 >> iter 80000, loss: 0.007691
   Number of active neurons: 10
 >> iter 81000, loss: 0.005877
 >> iter 82000, loss: 0.083227
 >> iter 83000, loss: 0.073218
 >> iter 84000, loss: 0.029466
 >> iter 85000, loss: 0.012837
 >> iter 86000, loss: 0.033507
 >> iter 87000, loss: 0.014096
 >> iter 88000, loss: 0.006506
 >> iter 89000, loss: 0.003683
 >> iter 90000, loss: 0.002699
   Number of active neurons: 10
 >> iter 91000, loss: 0.003444
 >> iter 92000, loss: 0.012967
 >> iter 93000, loss: 0.006015
 >> iter 94000, loss: 0.033683
 >> iter 95000, loss: 0.014727
 >> iter 96000, loss: 0.006631
 >> iter 97000, loss: 0.040934
 >> iter 98000, loss: 0.016672
 >> iter 99000, loss: 0.007709
 >> iter 100000, loss: 0.004186
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

