 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 4e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.423961
 >> iter 2000, loss: 7.449602
 >> iter 3000, loss: 2.846111
 >> iter 4000, loss: 1.078258
 >> iter 5000, loss: 0.419264
 >> iter 6000, loss: 0.238104
 >> iter 7000, loss: 0.105286
 >> iter 8000, loss: 0.054907
 >> iter 9000, loss: 0.035618
 >> iter 10000, loss: 0.028915
   Number of active neurons: 9
 >> iter 11000, loss: 0.081642
 >> iter 12000, loss: 0.046049
 >> iter 13000, loss: 0.046316
 >> iter 14000, loss: 0.032080
 >> iter 15000, loss: 0.026207
 >> iter 16000, loss: 0.040977
 >> iter 17000, loss: 0.096368
 >> iter 18000, loss: 0.051248
 >> iter 19000, loss: 0.034620
 >> iter 20000, loss: 0.032237
   Number of active neurons: 9
 >> iter 21000, loss: 0.026523
 >> iter 22000, loss: 0.025953
 >> iter 23000, loss: 0.022299
 >> iter 24000, loss: 0.022170
 >> iter 25000, loss: 0.034122
 >> iter 26000, loss: 0.025339
 >> iter 27000, loss: 0.024375
 >> iter 28000, loss: 0.022831
 >> iter 29000, loss: 0.026962
 >> iter 30000, loss: 0.022547
   Number of active neurons: 8
 >> iter 31000, loss: 0.111962
 >> iter 32000, loss: 0.131688
 >> iter 33000, loss: 0.061430
 >> iter 34000, loss: 0.038663
 >> iter 35000, loss: 0.027310
 >> iter 36000, loss: 0.025317
 >> iter 37000, loss: 0.022198
 >> iter 38000, loss: 0.023550
 >> iter 39000, loss: 0.022174
 >> iter 40000, loss: 0.022328
   Number of active neurons: 8
 >> iter 41000, loss: 0.021012
 >> iter 42000, loss: 0.023007
 >> iter 43000, loss: 0.147910
 >> iter 44000, loss: 0.071950
 >> iter 45000, loss: 0.039755
 >> iter 46000, loss: 0.027158
 >> iter 47000, loss: 0.023114
 >> iter 48000, loss: 0.020874
 >> iter 49000, loss: 0.022285
 >> iter 50000, loss: 0.019469
   Number of active neurons: 7
 >> iter 51000, loss: 0.019081
 >> iter 52000, loss: 0.020889
 >> iter 53000, loss: 0.019617
 >> iter 54000, loss: 0.020735
 >> iter 55000, loss: 0.019391
 >> iter 56000, loss: 0.020273
 >> iter 57000, loss: 0.019055
 >> iter 58000, loss: 0.019472
 >> iter 59000, loss: 0.018586
 >> iter 60000, loss: 0.018550
   Number of active neurons: 7
 >> iter 61000, loss: 0.018080
 >> iter 62000, loss: 0.018220
 >> iter 63000, loss: 0.018039
 >> iter 64000, loss: 0.017616
 >> iter 65000, loss: 0.020159
 >> iter 66000, loss: 0.017858
 >> iter 67000, loss: 0.210518
 >> iter 68000, loss: 0.089000
 >> iter 69000, loss: 0.044106
 >> iter 70000, loss: 0.027648
   Number of active neurons: 7
 >> iter 71000, loss: 0.022007
 >> iter 72000, loss: 0.019445
 >> iter 73000, loss: 0.070362
 >> iter 74000, loss: 0.037737
 >> iter 75000, loss: 0.092807
 >> iter 76000, loss: 0.046889
 >> iter 77000, loss: 0.093684
 >> iter 78000, loss: 0.047675
 >> iter 79000, loss: 0.088076
 >> iter 80000, loss: 0.045720
   Number of active neurons: 7
 >> iter 81000, loss: 0.068510
 >> iter 82000, loss: 0.038183
 >> iter 83000, loss: 0.030666
 >> iter 84000, loss: 0.022957
 >> iter 85000, loss: 0.022737
 >> iter 86000, loss: 0.019370
 >> iter 87000, loss: 0.018394
 >> iter 88000, loss: 0.017651
 >> iter 89000, loss: 0.017718
 >> iter 90000, loss: 0.017323
   Number of active neurons: 6
 >> iter 91000, loss: 0.017446
 >> iter 92000, loss: 0.017197
 >> iter 93000, loss: 0.017274
 >> iter 94000, loss: 0.017107
 >> iter 95000, loss: 0.017221
 >> iter 96000, loss: 0.017039
 >> iter 97000, loss: 0.017151
 >> iter 98000, loss: 0.016968
 >> iter 99000, loss: 0.017086
 >> iter 100000, loss: 0.016883
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0019999600008
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 22.0718618759
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.004168
 >> iter 2000, loss: 8.193486
 >> iter 3000, loss: 3.115889
 >> iter 4000, loss: 1.175674
 >> iter 5000, loss: 0.455348
 >> iter 6000, loss: 0.186789
 >> iter 7000, loss: 0.086517
 >> iter 8000, loss: 0.048244
 >> iter 9000, loss: 0.033763
 >> iter 10000, loss: 0.027672
   Number of active neurons: 9
 >> iter 11000, loss: 0.025300
 >> iter 12000, loss: 0.023908
 >> iter 13000, loss: 0.023192
 >> iter 14000, loss: 0.022587
 >> iter 15000, loss: 0.022239
 >> iter 16000, loss: 0.021798
 >> iter 17000, loss: 0.021482
 >> iter 18000, loss: 0.021053
 >> iter 19000, loss: 0.020789
 >> iter 20000, loss: 0.020372
   Number of active neurons: 8
 >> iter 21000, loss: 0.020168
 >> iter 22000, loss: 0.019755
 >> iter 23000, loss: 0.019580
 >> iter 24000, loss: 0.019221
 >> iter 25000, loss: 0.019156
 >> iter 26000, loss: 0.018858
 >> iter 27000, loss: 0.018864
 >> iter 28000, loss: 0.018603
 >> iter 29000, loss: 0.018600
 >> iter 30000, loss: 0.018342
   Number of active neurons: 8
 >> iter 31000, loss: 0.018377
 >> iter 32000, loss: 0.018096
 >> iter 33000, loss: 0.018107
 >> iter 34000, loss: 0.017861
 >> iter 35000, loss: 0.017902
 >> iter 36000, loss: 0.017698
 >> iter 37000, loss: 0.017805
 >> iter 38000, loss: 0.017604
 >> iter 39000, loss: 0.017722
 >> iter 40000, loss: 0.017536
   Number of active neurons: 8
 >> iter 41000, loss: 0.017657
 >> iter 42000, loss: 0.017454
 >> iter 43000, loss: 0.017543
 >> iter 44000, loss: 0.017339
 >> iter 45000, loss: 0.017401
 >> iter 46000, loss: 0.017205
 >> iter 47000, loss: 0.017256
 >> iter 48000, loss: 0.017109
 >> iter 49000, loss: 0.017149
 >> iter 50000, loss: 0.017015
   Number of active neurons: 8
 >> iter 51000, loss: 0.017044
 >> iter 52000, loss: 0.016931
 >> iter 53000, loss: 0.016928
 >> iter 54000, loss: 0.016800
 >> iter 55000, loss: 0.016787
 >> iter 56000, loss: 0.016642
 >> iter 57000, loss: 0.016624
 >> iter 58000, loss: 0.016476
 >> iter 59000, loss: 0.016478
 >> iter 60000, loss: 0.016391
   Number of active neurons: 8
 >> iter 61000, loss: 0.016413
 >> iter 62000, loss: 0.016308
 >> iter 63000, loss: 0.016327
 >> iter 64000, loss: 0.016252
 >> iter 65000, loss: 0.016284
 >> iter 66000, loss: 0.016233
 >> iter 67000, loss: 0.016279
 >> iter 68000, loss: 0.016239
 >> iter 69000, loss: 0.016281
 >> iter 70000, loss: 0.016253
   Number of active neurons: 8
 >> iter 71000, loss: 0.016306
 >> iter 72000, loss: 0.016261
 >> iter 73000, loss: 0.016290
 >> iter 74000, loss: 0.016207
 >> iter 75000, loss: 0.016231
 >> iter 76000, loss: 0.016174
 >> iter 77000, loss: 0.016199
 >> iter 78000, loss: 0.016152
 >> iter 79000, loss: 0.016184
 >> iter 80000, loss: 0.016143
   Number of active neurons: 8
 >> iter 81000, loss: 0.016181
 >> iter 82000, loss: 0.016157
 >> iter 83000, loss: 0.016196
 >> iter 84000, loss: 0.016171
 >> iter 85000, loss: 0.016223
 >> iter 86000, loss: 0.016199
 >> iter 87000, loss: 0.016245
 >> iter 88000, loss: 0.016219
 >> iter 89000, loss: 0.016251
 >> iter 90000, loss: 0.016216
   Number of active neurons: 8
 >> iter 91000, loss: 0.016254
 >> iter 92000, loss: 0.016219
 >> iter 93000, loss: 0.016270
 >> iter 94000, loss: 0.016232
 >> iter 95000, loss: 0.016312
 >> iter 96000, loss: 0.016245
 >> iter 97000, loss: 0.016331
 >> iter 98000, loss: 0.016257
 >> iter 99000, loss: 0.016357
 >> iter 100000, loss: 0.016265
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.995485
 >> iter 2000, loss: 10.163594
 >> iter 3000, loss: 3.823302
 >> iter 4000, loss: 1.436902
 >> iter 5000, loss: 0.552092
 >> iter 6000, loss: 0.222991
 >> iter 7000, loss: 0.100463
 >> iter 8000, loss: 0.053887
 >> iter 9000, loss: 0.036344
 >> iter 10000, loss: 0.029294
   Number of active neurons: 9
 >> iter 11000, loss: 0.026305
 >> iter 12000, loss: 0.025720
 >> iter 13000, loss: 0.024089
 >> iter 14000, loss: 0.024683
 >> iter 15000, loss: 0.022968
 >> iter 16000, loss: 0.022635
 >> iter 17000, loss: 0.022081
 >> iter 18000, loss: 0.021746
 >> iter 19000, loss: 0.021686
 >> iter 20000, loss: 0.021285
   Number of active neurons: 9
 >> iter 21000, loss: 0.021661
 >> iter 22000, loss: 0.021067
 >> iter 23000, loss: 0.036791
 >> iter 24000, loss: 0.025532
 >> iter 25000, loss: 0.021977
 >> iter 26000, loss: 0.020677
 >> iter 27000, loss: 0.033632
 >> iter 28000, loss: 0.027925
 >> iter 29000, loss: 0.022074
 >> iter 30000, loss: 0.020063
   Number of active neurons: 8
 >> iter 31000, loss: 0.019883
 >> iter 32000, loss: 0.019494
 >> iter 33000, loss: 0.019924
 >> iter 34000, loss: 0.019452
 >> iter 35000, loss: 0.020292
 >> iter 36000, loss: 0.019266
 >> iter 37000, loss: 0.087074
 >> iter 38000, loss: 0.060763
 >> iter 39000, loss: 0.091792
 >> iter 40000, loss: 0.045841
   Number of active neurons: 8
 >> iter 41000, loss: 0.029602
 >> iter 42000, loss: 0.023189
 >> iter 43000, loss: 0.021334
 >> iter 44000, loss: 0.020129
 >> iter 45000, loss: 0.020107
 >> iter 46000, loss: 0.019566
 >> iter 47000, loss: 0.019779
 >> iter 48000, loss: 0.019367
 >> iter 49000, loss: 0.019564
 >> iter 50000, loss: 0.019150
   Number of active neurons: 8
 >> iter 51000, loss: 0.019335
 >> iter 52000, loss: 0.018995
 >> iter 53000, loss: 0.019191
 >> iter 54000, loss: 0.018861
 >> iter 55000, loss: 0.019052
 >> iter 56000, loss: 0.018739
 >> iter 57000, loss: 0.018937
 >> iter 58000, loss: 0.018621
 >> iter 59000, loss: 0.018803
 >> iter 60000, loss: 0.018507
   Number of active neurons: 8
 >> iter 61000, loss: 0.018682
 >> iter 62000, loss: 0.018368
 >> iter 63000, loss: 0.018526
 >> iter 64000, loss: 0.018208
 >> iter 65000, loss: 0.018355
 >> iter 66000, loss: 0.018048
 >> iter 67000, loss: 0.018161
 >> iter 68000, loss: 0.017864
 >> iter 69000, loss: 0.017961
 >> iter 70000, loss: 0.017697
   Number of active neurons: 8
 >> iter 71000, loss: 0.017826
 >> iter 72000, loss: 0.017568
 >> iter 73000, loss: 0.017719
 >> iter 74000, loss: 0.017442
 >> iter 75000, loss: 0.017551
 >> iter 76000, loss: 0.017314
 >> iter 77000, loss: 0.017418
 >> iter 78000, loss: 0.017170
 >> iter 79000, loss: 0.017246
 >> iter 80000, loss: 0.017015
   Number of active neurons: 8
 >> iter 81000, loss: 0.017108
 >> iter 82000, loss: 0.016912
 >> iter 83000, loss: 0.017014
 >> iter 84000, loss: 0.016825
 >> iter 85000, loss: 0.016946
 >> iter 86000, loss: 0.016764
 >> iter 87000, loss: 0.016877
 >> iter 88000, loss: 0.016710
 >> iter 89000, loss: 0.016794
 >> iter 90000, loss: 0.016640
   Number of active neurons: 8
 >> iter 91000, loss: 0.016729
 >> iter 92000, loss: 0.016583
 >> iter 93000, loss: 0.016676
 >> iter 94000, loss: 0.016527
 >> iter 95000, loss: 0.016637
 >> iter 96000, loss: 0.016463
 >> iter 97000, loss: 0.016572
 >> iter 98000, loss: 0.016392
 >> iter 99000, loss: 0.016505
 >> iter 100000, loss: 0.016317
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 15.9922671822
   - Test - B: 21.2919138724
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.843711
 >> iter 2000, loss: 7.894326
 >> iter 3000, loss: 2.943134
 >> iter 4000, loss: 1.106978
 >> iter 5000, loss: 0.426529
 >> iter 6000, loss: 0.174043
 >> iter 7000, loss: 0.079391
 >> iter 8000, loss: 0.043479
 >> iter 9000, loss: 0.029920
 >> iter 10000, loss: 0.024294
   Number of active neurons: 9
 >> iter 11000, loss: 0.022092
 >> iter 12000, loss: 0.020810
 >> iter 13000, loss: 0.020289
 >> iter 14000, loss: 0.019720
 >> iter 15000, loss: 0.019535
 >> iter 16000, loss: 0.019119
 >> iter 17000, loss: 0.284968
 >> iter 18000, loss: 0.119074
 >> iter 19000, loss: 0.057328
 >> iter 20000, loss: 0.033866
   Number of active neurons: 9
 >> iter 21000, loss: 0.120731
 >> iter 22000, loss: 0.056844
 >> iter 23000, loss: 0.034101
 >> iter 24000, loss: 0.024073
 >> iter 25000, loss: 0.021521
 >> iter 26000, loss: 0.019106
 >> iter 27000, loss: 0.019334
 >> iter 28000, loss: 0.018054
 >> iter 29000, loss: 0.018616
 >> iter 30000, loss: 0.017553
   Number of active neurons: 9
 >> iter 31000, loss: 0.035512
 >> iter 32000, loss: 0.023725
 >> iter 33000, loss: 0.124647
 >> iter 34000, loss: 0.057404
 >> iter 35000, loss: 0.032459
 >> iter 36000, loss: 0.025496
 >> iter 37000, loss: 0.020502
 >> iter 38000, loss: 0.026307
 >> iter 39000, loss: 0.020344
 >> iter 40000, loss: 0.019383
   Number of active neurons: 6
 >> iter 41000, loss: 0.017777
 >> iter 42000, loss: 0.018567
 >> iter 43000, loss: 0.017538
 >> iter 44000, loss: 0.018356
 >> iter 45000, loss: 0.017517
 >> iter 46000, loss: 0.018263
 >> iter 47000, loss: 0.017504
 >> iter 48000, loss: 0.018225
 >> iter 49000, loss: 0.017515
 >> iter 50000, loss: 0.018162
   Number of active neurons: 6
 >> iter 51000, loss: 0.017499
 >> iter 52000, loss: 0.018120
 >> iter 53000, loss: 0.017476
 >> iter 54000, loss: 0.018026
 >> iter 55000, loss: 0.017411
 >> iter 56000, loss: 0.017888
 >> iter 57000, loss: 0.017335
 >> iter 58000, loss: 0.017751
 >> iter 59000, loss: 0.017241
 >> iter 60000, loss: 0.017644
   Number of active neurons: 6
 >> iter 61000, loss: 0.017153
 >> iter 62000, loss: 0.017577
 >> iter 63000, loss: 0.017098
 >> iter 64000, loss: 0.017462
 >> iter 65000, loss: 0.017015
 >> iter 66000, loss: 0.017371
 >> iter 67000, loss: 0.016927
 >> iter 68000, loss: 0.017262
 >> iter 69000, loss: 0.016806
 >> iter 70000, loss: 0.017295
   Number of active neurons: 6
 >> iter 71000, loss: 0.016813
 >> iter 72000, loss: 0.016940
 >> iter 73000, loss: 0.016585
 >> iter 74000, loss: 0.016852
 >> iter 75000, loss: 0.016473
 >> iter 76000, loss: 0.017004
 >> iter 77000, loss: 0.016508
 >> iter 78000, loss: 0.016676
 >> iter 79000, loss: 0.016290
 >> iter 80000, loss: 0.016652
   Number of active neurons: 6
 >> iter 81000, loss: 0.016275
 >> iter 82000, loss: 0.017084
 >> iter 83000, loss: 0.016371
 >> iter 84000, loss: 0.016479
 >> iter 85000, loss: 0.016160
 >> iter 86000, loss: 0.016536
 >> iter 87000, loss: 0.016154
 >> iter 88000, loss: 0.016376
 >> iter 89000, loss: 0.016087
 >> iter 90000, loss: 0.017684
   Number of active neurons: 6
 >> iter 91000, loss: 0.016559
 >> iter 92000, loss: 0.016519
 >> iter 93000, loss: 0.016095
 >> iter 94000, loss: 0.017725
 >> iter 95000, loss: 0.016537
 >> iter 96000, loss: 0.016503
 >> iter 97000, loss: 0.016076
 >> iter 98000, loss: 0.016873
 >> iter 99000, loss: 0.016172
 >> iter 100000, loss: 0.016541
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0029999700003
   - Test - A: 0.0
   - Test - B: 13.9190720619
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.321028
 >> iter 2000, loss: 7.647679
 >> iter 3000, loss: 2.862865
 >> iter 4000, loss: 1.082149
 >> iter 5000, loss: 0.445129
 >> iter 6000, loss: 0.182750
 >> iter 7000, loss: 0.084638
 >> iter 8000, loss: 0.047472
 >> iter 9000, loss: 0.033186
 >> iter 10000, loss: 0.027649
   Number of active neurons: 8
 >> iter 11000, loss: 0.025066
 >> iter 12000, loss: 0.023980
 >> iter 13000, loss: 0.023167
 >> iter 14000, loss: 0.022854
 >> iter 15000, loss: 0.022217
 >> iter 16000, loss: 0.022030
 >> iter 17000, loss: 0.021521
 >> iter 18000, loss: 0.021453
 >> iter 19000, loss: 0.021036
 >> iter 20000, loss: 0.020971
   Number of active neurons: 8
 >> iter 21000, loss: 0.020718
 >> iter 22000, loss: 0.020513
 >> iter 23000, loss: 0.020433
 >> iter 24000, loss: 0.020172
 >> iter 25000, loss: 0.020225
 >> iter 26000, loss: 0.019971
 >> iter 27000, loss: 0.032509
 >> iter 28000, loss: 0.023323
 >> iter 29000, loss: 0.023732
 >> iter 30000, loss: 0.020514
   Number of active neurons: 8
 >> iter 31000, loss: 0.021728
 >> iter 32000, loss: 0.019684
 >> iter 33000, loss: 0.019902
 >> iter 34000, loss: 0.018913
 >> iter 35000, loss: 0.019245
 >> iter 36000, loss: 0.018581
 >> iter 37000, loss: 0.019336
 >> iter 38000, loss: 0.018520
 >> iter 39000, loss: 0.019376
 >> iter 40000, loss: 0.018432
   Number of active neurons: 7
 >> iter 41000, loss: 0.019330
 >> iter 42000, loss: 0.018325
 >> iter 43000, loss: 0.018815
 >> iter 44000, loss: 0.018097
 >> iter 45000, loss: 0.018996
 >> iter 46000, loss: 0.018101
 >> iter 47000, loss: 0.018898
 >> iter 48000, loss: 0.018046
 >> iter 49000, loss: 0.018723
 >> iter 50000, loss: 0.017958
   Number of active neurons: 7
 >> iter 51000, loss: 0.018536
 >> iter 52000, loss: 0.017868
 >> iter 53000, loss: 0.018365
 >> iter 54000, loss: 0.017762
 >> iter 55000, loss: 0.018249
 >> iter 56000, loss: 0.017675
 >> iter 57000, loss: 0.018228
 >> iter 58000, loss: 0.017606
 >> iter 59000, loss: 0.018295
 >> iter 60000, loss: 0.017558
   Number of active neurons: 7
 >> iter 61000, loss: 0.018388
 >> iter 62000, loss: 0.017535
 >> iter 63000, loss: 0.018351
 >> iter 64000, loss: 0.017503
 >> iter 65000, loss: 0.018171
 >> iter 66000, loss: 0.017430
 >> iter 67000, loss: 0.018023
 >> iter 68000, loss: 0.017391
 >> iter 69000, loss: 0.017570
 >> iter 70000, loss: 0.017309
   Number of active neurons: 7
 >> iter 71000, loss: 0.018576
 >> iter 72000, loss: 0.017512
 >> iter 73000, loss: 0.018976
 >> iter 74000, loss: 0.017881
 >> iter 75000, loss: 0.107381
 >> iter 76000, loss: 0.051496
 >> iter 77000, loss: 0.029939
 >> iter 78000, loss: 0.022581
 >> iter 79000, loss: 0.019622
 >> iter 80000, loss: 0.018666
   Number of active neurons: 6
 >> iter 81000, loss: 0.018349
 >> iter 82000, loss: 0.018245
 >> iter 83000, loss: 0.018200
 >> iter 84000, loss: 0.018159
 >> iter 85000, loss: 0.018170
 >> iter 86000, loss: 0.018097
 >> iter 87000, loss: 0.018091
 >> iter 88000, loss: 0.017977
 >> iter 89000, loss: 0.017925
 >> iter 90000, loss: 0.017789
   Number of active neurons: 7
 >> iter 91000, loss: 0.017744
 >> iter 92000, loss: 0.017599
 >> iter 93000, loss: 0.017555
 >> iter 94000, loss: 0.017383
 >> iter 95000, loss: 0.017344
 >> iter 96000, loss: 0.017157
 >> iter 97000, loss: 0.017138
 >> iter 98000, loss: 0.016986
 >> iter 99000, loss: 0.016997
 >> iter 100000, loss: 0.016843
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.10665955603
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.392351
 >> iter 2000, loss: 7.416407
 >> iter 3000, loss: 2.769564
 >> iter 4000, loss: 1.043581
 >> iter 5000, loss: 0.409116
 >> iter 6000, loss: 0.167191
 >> iter 7000, loss: 0.079770
 >> iter 8000, loss: 0.043247
 >> iter 9000, loss: 0.070134
 >> iter 10000, loss: 0.041295
   Number of active neurons: 7
 >> iter 11000, loss: 0.028535
 >> iter 12000, loss: 0.022294
 >> iter 13000, loss: 0.026953
 >> iter 14000, loss: 0.021609
 >> iter 15000, loss: 0.025033
 >> iter 16000, loss: 0.020720
 >> iter 17000, loss: 0.022295
 >> iter 18000, loss: 0.019659
 >> iter 19000, loss: 0.022123
 >> iter 20000, loss: 0.019666
   Number of active neurons: 6
 >> iter 21000, loss: 0.021314
 >> iter 22000, loss: 0.024920
 >> iter 23000, loss: 0.023432
 >> iter 24000, loss: 0.020274
 >> iter 25000, loss: 0.021456
 >> iter 26000, loss: 0.018636
 >> iter 27000, loss: 0.019583
 >> iter 28000, loss: 0.018046
 >> iter 29000, loss: 0.023033
 >> iter 30000, loss: 0.019102
   Number of active neurons: 6
 >> iter 31000, loss: 0.072535
 >> iter 32000, loss: 0.038256
 >> iter 33000, loss: 0.080842
 >> iter 34000, loss: 0.041274
 >> iter 35000, loss: 0.084103
 >> iter 36000, loss: 0.042576
 >> iter 37000, loss: 0.086080
 >> iter 38000, loss: 0.043019
 >> iter 39000, loss: 0.081598
 >> iter 40000, loss: 0.041582
   Number of active neurons: 6
 >> iter 41000, loss: 0.027092
 >> iter 42000, loss: 0.021062
 >> iter 43000, loss: 0.019308
 >> iter 44000, loss: 0.018035
 >> iter 45000, loss: 0.017978
 >> iter 46000, loss: 0.017436
 >> iter 47000, loss: 0.017672
 >> iter 48000, loss: 0.017243
 >> iter 49000, loss: 0.017519
 >> iter 50000, loss: 0.017118
   Number of active neurons: 6
 >> iter 51000, loss: 0.017403
 >> iter 52000, loss: 0.017047
 >> iter 53000, loss: 0.017296
 >> iter 54000, loss: 0.016947
 >> iter 55000, loss: 0.017183
 >> iter 56000, loss: 0.016856
 >> iter 57000, loss: 0.017088
 >> iter 58000, loss: 0.016765
 >> iter 59000, loss: 0.016976
 >> iter 60000, loss: 0.016679
   Number of active neurons: 6
 >> iter 61000, loss: 0.016864
 >> iter 62000, loss: 0.016563
 >> iter 63000, loss: 0.016748
 >> iter 64000, loss: 0.016453
 >> iter 65000, loss: 0.016611
 >> iter 66000, loss: 0.016327
 >> iter 67000, loss: 0.016495
 >> iter 68000, loss: 0.016258
 >> iter 69000, loss: 0.016383
 >> iter 70000, loss: 0.016142
   Number of active neurons: 6
 >> iter 71000, loss: 0.016261
 >> iter 72000, loss: 0.016026
 >> iter 73000, loss: 0.016156
 >> iter 74000, loss: 0.015925
 >> iter 75000, loss: 0.016066
 >> iter 76000, loss: 0.015862
 >> iter 77000, loss: 0.015972
 >> iter 78000, loss: 0.015776
 >> iter 79000, loss: 0.015883
 >> iter 80000, loss: 0.015699
   Number of active neurons: 6
 >> iter 81000, loss: 0.015926
 >> iter 82000, loss: 0.015659
 >> iter 83000, loss: 0.015930
 >> iter 84000, loss: 0.015553
 >> iter 85000, loss: 0.024989
 >> iter 86000, loss: 0.018650
 >> iter 87000, loss: 0.016561
 >> iter 88000, loss: 0.015659
 >> iter 89000, loss: 0.015548
 >> iter 90000, loss: 0.015300
   Number of active neurons: 6
 >> iter 91000, loss: 0.015275
 >> iter 92000, loss: 0.015622
 >> iter 93000, loss: 0.021047
 >> iter 94000, loss: 0.017622
 >> iter 95000, loss: 0.016126
 >> iter 96000, loss: 0.077635
 >> iter 97000, loss: 0.170161
 >> iter 98000, loss: 0.074412
 >> iter 99000, loss: 0.037781
 >> iter 100000, loss: 0.024291
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0399980001
   - Test - Big: 0.0039999600004
   - Test - A: 0.0
   - Test - B: 17.4121725218
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.718130
 >> iter 2000, loss: 7.866365
 >> iter 3000, loss: 2.938262
 >> iter 4000, loss: 1.109290
 >> iter 5000, loss: 0.428832
 >> iter 6000, loss: 0.176877
 >> iter 7000, loss: 0.081442
 >> iter 8000, loss: 0.046812
 >> iter 9000, loss: 0.049092
 >> iter 10000, loss: 0.035246
   Number of active neurons: 8
 >> iter 11000, loss: 0.050017
 >> iter 12000, loss: 0.036874
 >> iter 13000, loss: 0.026509
 >> iter 14000, loss: 0.023278
 >> iter 15000, loss: 0.070117
 >> iter 16000, loss: 0.062750
 >> iter 17000, loss: 0.035653
 >> iter 18000, loss: 0.028146
 >> iter 19000, loss: 0.022806
 >> iter 20000, loss: 0.025419
   Number of active neurons: 7
 >> iter 21000, loss: 0.021579
 >> iter 22000, loss: 0.028964
 >> iter 23000, loss: 0.022190
 >> iter 24000, loss: 0.176037
 >> iter 25000, loss: 0.077331
 >> iter 26000, loss: 0.075405
 >> iter 27000, loss: 0.040332
 >> iter 28000, loss: 0.035355
 >> iter 29000, loss: 0.024808
 >> iter 30000, loss: 0.032902
   Number of active neurons: 7
 >> iter 31000, loss: 0.023798
 >> iter 32000, loss: 0.031267
 >> iter 33000, loss: 0.023183
 >> iter 34000, loss: 0.031144
 >> iter 35000, loss: 0.023026
 >> iter 36000, loss: 0.029656
 >> iter 37000, loss: 0.022431
 >> iter 38000, loss: 0.027329
 >> iter 39000, loss: 0.022202
 >> iter 40000, loss: 0.027471
   Number of active neurons: 7
 >> iter 41000, loss: 0.023219
 >> iter 42000, loss: 0.026472
 >> iter 43000, loss: 0.097878
 >> iter 44000, loss: 0.051581
 >> iter 45000, loss: 0.030892
 >> iter 46000, loss: 0.027753
 >> iter 47000, loss: 0.023788
 >> iter 48000, loss: 0.023613
 >> iter 49000, loss: 0.034398
 >> iter 50000, loss: 0.027523
   Number of active neurons: 7
 >> iter 51000, loss: 0.021216
 >> iter 52000, loss: 0.024503
 >> iter 53000, loss: 0.020750
 >> iter 54000, loss: 0.024604
 >> iter 55000, loss: 0.021657
 >> iter 56000, loss: 0.024702
 >> iter 57000, loss: 0.162066
 >> iter 58000, loss: 0.080816
 >> iter 59000, loss: 0.040951
 >> iter 60000, loss: 0.028894
   Number of active neurons: 7
 >> iter 61000, loss: 0.022217
 >> iter 62000, loss: 0.022710
 >> iter 63000, loss: 0.232111
 >> iter 64000, loss: 0.136051
 >> iter 65000, loss: 0.062309
 >> iter 66000, loss: 0.036960
 >> iter 67000, loss: 0.025476
 >> iter 68000, loss: 0.023360
 >> iter 69000, loss: 0.244451
 >> iter 70000, loss: 0.110545
   Number of active neurons: 7
 >> iter 71000, loss: 0.294826
 >> iter 72000, loss: 0.130141
 >> iter 73000, loss: 0.074869
 >> iter 74000, loss: 0.042675
 >> iter 75000, loss: 0.027140
 >> iter 76000, loss: 0.042186
 >> iter 77000, loss: 0.277347
 >> iter 78000, loss: 0.117300
 >> iter 79000, loss: 0.180074
 >> iter 80000, loss: 0.080677
   Number of active neurons: 7
 >> iter 81000, loss: 0.041480
 >> iter 82000, loss: 0.027040
 >> iter 83000, loss: 0.021228
 >> iter 84000, loss: 0.019273
 >> iter 85000, loss: 0.017908
 >> iter 86000, loss: 0.037108
 >> iter 87000, loss: 0.024145
 >> iter 88000, loss: 0.021069
 >> iter 89000, loss: 0.018032
 >> iter 90000, loss: 0.035457
   Number of active neurons: 6
 >> iter 91000, loss: 0.023021
 >> iter 92000, loss: 0.031895
 >> iter 93000, loss: 0.021350
 >> iter 94000, loss: 0.018964
 >> iter 95000, loss: 0.016453
 >> iter 96000, loss: 0.073242
 >> iter 97000, loss: 0.037290
 >> iter 98000, loss: 0.024601
 >> iter 99000, loss: 0.019125
 >> iter 100000, loss: 0.068501
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0319993600128
   - Test - Long: 0.0
   - Test - Big: 0.0219997800022
   - Test - A: 0.213319112059
   - Test - B: 21.0252649823
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.875246
 >> iter 2000, loss: 8.910515
 >> iter 3000, loss: 3.331699
 >> iter 4000, loss: 1.255286
 >> iter 5000, loss: 0.492902
 >> iter 6000, loss: 0.201440
 >> iter 7000, loss: 0.092707
 >> iter 8000, loss: 0.051342
 >> iter 9000, loss: 0.038592
 >> iter 10000, loss: 0.029740
   Number of active neurons: 9
 >> iter 11000, loss: 0.026717
 >> iter 12000, loss: 0.024885
 >> iter 13000, loss: 0.027043
 >> iter 14000, loss: 0.024372
 >> iter 15000, loss: 0.023702
 >> iter 16000, loss: 0.022993
 >> iter 17000, loss: 0.023342
 >> iter 18000, loss: 0.022192
 >> iter 19000, loss: 0.024904
 >> iter 20000, loss: 0.022644
   Number of active neurons: 8
 >> iter 21000, loss: 0.023095
 >> iter 22000, loss: 0.024780
 >> iter 23000, loss: 0.024960
 >> iter 24000, loss: 0.022230
 >> iter 25000, loss: 0.021026
 >> iter 26000, loss: 0.020498
 >> iter 27000, loss: 0.020551
 >> iter 28000, loss: 0.022605
 >> iter 29000, loss: 0.021146
 >> iter 30000, loss: 0.020031
   Number of active neurons: 8
 >> iter 31000, loss: 0.020323
 >> iter 32000, loss: 0.019831
 >> iter 33000, loss: 0.020284
 >> iter 34000, loss: 0.019930
 >> iter 35000, loss: 0.158090
 >> iter 36000, loss: 0.071095
 >> iter 37000, loss: 0.108322
 >> iter 38000, loss: 0.052762
 >> iter 39000, loss: 0.036143
 >> iter 40000, loss: 0.025504
   Number of active neurons: 7
 >> iter 41000, loss: 0.022006
 >> iter 42000, loss: 0.020615
 >> iter 43000, loss: 0.020922
 >> iter 44000, loss: 0.019940
 >> iter 45000, loss: 0.019777
 >> iter 46000, loss: 0.019538
 >> iter 47000, loss: 0.019509
 >> iter 48000, loss: 0.019311
 >> iter 49000, loss: 0.019200
 >> iter 50000, loss: 0.413144
   Number of active neurons: 7
 >> iter 51000, loss: 0.167298
 >> iter 52000, loss: 0.075211
 >> iter 53000, loss: 0.040939
 >> iter 54000, loss: 0.028322
 >> iter 55000, loss: 0.023464
 >> iter 56000, loss: 0.021719
 >> iter 57000, loss: 0.020941
 >> iter 58000, loss: 0.020594
 >> iter 59000, loss: 0.020435
 >> iter 60000, loss: 0.020254
   Number of active neurons: 7
 >> iter 61000, loss: 0.020244
 >> iter 62000, loss: 0.020061
 >> iter 63000, loss: 0.020096
 >> iter 64000, loss: 0.019883
 >> iter 65000, loss: 0.019928
 >> iter 66000, loss: 0.019698
 >> iter 67000, loss: 0.019709
 >> iter 68000, loss: 0.019460
 >> iter 69000, loss: 0.019448
 >> iter 70000, loss: 0.019232
   Number of active neurons: 7
 >> iter 71000, loss: 0.019252
 >> iter 72000, loss: 0.019003
 >> iter 73000, loss: 0.019031
 >> iter 74000, loss: 0.018746
 >> iter 75000, loss: 0.018776
 >> iter 76000, loss: 0.018472
 >> iter 77000, loss: 0.018476
 >> iter 78000, loss: 0.018152
 >> iter 79000, loss: 0.018176
 >> iter 80000, loss: 0.017862
   Number of active neurons: 6
 >> iter 81000, loss: 0.017909
 >> iter 82000, loss: 0.017602
 >> iter 83000, loss: 0.017624
 >> iter 84000, loss: 0.017325
 >> iter 85000, loss: 0.017377
 >> iter 86000, loss: 0.017085
 >> iter 87000, loss: 0.017135
 >> iter 88000, loss: 0.016922
 >> iter 89000, loss: 0.017005
 >> iter 90000, loss: 0.016834
   Number of active neurons: 5
 >> iter 91000, loss: 0.016933
 >> iter 92000, loss: 0.016773
 >> iter 93000, loss: 0.016872
 >> iter 94000, loss: 0.016705
 >> iter 95000, loss: 0.016840
 >> iter 96000, loss: 0.016647
 >> iter 97000, loss: 0.016783
 >> iter 98000, loss: 0.016586
 >> iter 99000, loss: 0.016732
 >> iter 100000, loss: 0.016516
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 17.7321511899
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.667566
 >> iter 2000, loss: 7.602507
 >> iter 3000, loss: 3.023517
 >> iter 4000, loss: 1.148265
 >> iter 5000, loss: 0.494224
 >> iter 6000, loss: 0.200070
 >> iter 7000, loss: 0.139458
 >> iter 8000, loss: 0.067010
 >> iter 9000, loss: 0.040559
 >> iter 10000, loss: 0.056860
   Number of active neurons: 9
 >> iter 11000, loss: 0.035019
 >> iter 12000, loss: 0.027804
 >> iter 13000, loss: 0.023771
 >> iter 14000, loss: 0.023035
 >> iter 15000, loss: 0.021616
 >> iter 16000, loss: 0.021725
 >> iter 17000, loss: 0.020863
 >> iter 18000, loss: 0.021245
 >> iter 19000, loss: 0.020568
 >> iter 20000, loss: 0.025646
   Number of active neurons: 8
 >> iter 21000, loss: 0.022272
 >> iter 22000, loss: 0.106553
 >> iter 23000, loss: 0.050983
 >> iter 24000, loss: 0.030725
 >> iter 25000, loss: 0.023476
 >> iter 26000, loss: 0.072651
 >> iter 27000, loss: 0.039752
 >> iter 28000, loss: 0.027306
 >> iter 29000, loss: 0.022756
 >> iter 30000, loss: 0.021004
   Number of active neurons: 8
 >> iter 31000, loss: 0.020247
 >> iter 32000, loss: 0.020445
 >> iter 33000, loss: 0.019940
 >> iter 34000, loss: 0.020255
 >> iter 35000, loss: 0.019788
 >> iter 36000, loss: 0.020766
 >> iter 37000, loss: 0.019999
 >> iter 38000, loss: 0.019890
 >> iter 39000, loss: 0.019404
 >> iter 40000, loss: 0.021013
   Number of active neurons: 8
 >> iter 41000, loss: 0.019930
 >> iter 42000, loss: 0.063592
 >> iter 43000, loss: 0.035525
 >> iter 44000, loss: 0.025198
 >> iter 45000, loss: 0.021357
 >> iter 46000, loss: 0.020458
 >> iter 47000, loss: 0.019503
 >> iter 48000, loss: 0.019410
 >> iter 49000, loss: 0.018956
 >> iter 50000, loss: 0.019195
   Number of active neurons: 6
 >> iter 51000, loss: 0.018815
 >> iter 52000, loss: 0.059624
 >> iter 53000, loss: 0.033623
 >> iter 54000, loss: 0.024212
 >> iter 55000, loss: 0.020467
 >> iter 56000, loss: 0.019410
 >> iter 57000, loss: 0.018552
 >> iter 58000, loss: 0.018504
 >> iter 59000, loss: 0.018044
 >> iter 60000, loss: 0.018100
   Number of active neurons: 6
 >> iter 61000, loss: 0.017769
 >> iter 62000, loss: 0.017760
 >> iter 63000, loss: 0.017484
 >> iter 64000, loss: 0.017474
 >> iter 65000, loss: 0.017168
 >> iter 66000, loss: 0.043232
 >> iter 67000, loss: 0.026439
 >> iter 68000, loss: 0.020837
 >> iter 69000, loss: 0.018273
 >> iter 70000, loss: 0.017397
   Number of active neurons: 6
 >> iter 71000, loss: 0.016917
 >> iter 72000, loss: 0.028197
 >> iter 73000, loss: 0.020640
 >> iter 74000, loss: 0.018129
 >> iter 75000, loss: 0.017050
 >> iter 76000, loss: 0.016711
 >> iter 77000, loss: 0.016654
 >> iter 78000, loss: 0.049970
 >> iter 79000, loss: 0.028975
 >> iter 80000, loss: 0.021496
   Number of active neurons: 6
 >> iter 81000, loss: 0.018414
 >> iter 82000, loss: 0.017382
 >> iter 83000, loss: 0.016802
 >> iter 84000, loss: 0.016829
 >> iter 85000, loss: 0.016551
 >> iter 86000, loss: 0.016681
 >> iter 87000, loss: 0.016454
 >> iter 88000, loss: 0.016620
 >> iter 89000, loss: 0.016394
 >> iter 90000, loss: 0.016574
   Number of active neurons: 6
 >> iter 91000, loss: 0.016351
 >> iter 92000, loss: 0.016530
 >> iter 93000, loss: 0.016325
 >> iter 94000, loss: 0.016486
 >> iter 95000, loss: 0.016324
 >> iter 96000, loss: 0.016442
 >> iter 97000, loss: 0.016291
 >> iter 98000, loss: 0.016413
 >> iter 99000, loss: 0.016277
 >> iter 100000, loss: 0.016393
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 19.1920538631
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.501444
 >> iter 2000, loss: 7.745756
 >> iter 3000, loss: 2.914019
 >> iter 4000, loss: 1.099380
 >> iter 5000, loss: 0.425968
 >> iter 6000, loss: 0.175235
 >> iter 7000, loss: 0.081588
 >> iter 8000, loss: 0.045929
 >> iter 9000, loss: 0.032185
 >> iter 10000, loss: 0.026557
   Number of active neurons: 8
 >> iter 11000, loss: 0.023962
 >> iter 12000, loss: 0.023926
 >> iter 13000, loss: 0.022069
 >> iter 14000, loss: 0.022662
 >> iter 15000, loss: 0.021121
 >> iter 16000, loss: 0.021965
 >> iter 17000, loss: 0.020532
 >> iter 18000, loss: 0.021519
 >> iter 19000, loss: 0.020137
 >> iter 20000, loss: 0.021193
   Number of active neurons: 8
 >> iter 21000, loss: 0.019920
 >> iter 22000, loss: 0.057305
 >> iter 23000, loss: 0.033707
 >> iter 24000, loss: 0.026092
 >> iter 25000, loss: 0.021764
 >> iter 26000, loss: 0.021640
 >> iter 27000, loss: 0.020018
 >> iter 28000, loss: 0.044352
 >> iter 29000, loss: 0.028208
 >> iter 30000, loss: 0.025712
   Number of active neurons: 7
 >> iter 31000, loss: 0.021549
 >> iter 32000, loss: 0.063325
 >> iter 33000, loss: 0.035357
 >> iter 34000, loss: 0.046148
 >> iter 35000, loss: 0.028600
 >> iter 36000, loss: 0.037961
 >> iter 37000, loss: 0.025120
 >> iter 38000, loss: 0.022108
 >> iter 39000, loss: 0.019337
 >> iter 40000, loss: 0.020202
   Number of active neurons: 6
 >> iter 41000, loss: 0.018942
 >> iter 42000, loss: 0.035053
 >> iter 43000, loss: 0.024105
 >> iter 44000, loss: 0.021603
 >> iter 45000, loss: 0.018922
 >> iter 46000, loss: 0.038267
 >> iter 47000, loss: 0.024531
 >> iter 48000, loss: 0.020924
 >> iter 49000, loss: 0.018094
 >> iter 50000, loss: 0.018391
   Number of active neurons: 6
 >> iter 51000, loss: 0.017150
 >> iter 52000, loss: 0.019142
 >> iter 53000, loss: 0.017192
 >> iter 54000, loss: 0.047859
 >> iter 55000, loss: 0.028239
 >> iter 56000, loss: 0.022029
 >> iter 57000, loss: 0.018484
 >> iter 58000, loss: 0.018271
 >> iter 59000, loss: 0.016874
 >> iter 60000, loss: 0.017818
   Number of active neurons: 6
 >> iter 61000, loss: 0.016853
 >> iter 62000, loss: 0.018226
 >> iter 63000, loss: 0.017137
 >> iter 64000, loss: 0.017570
 >> iter 65000, loss: 0.127291
 >> iter 66000, loss: 0.090369
 >> iter 67000, loss: 0.043360
 >> iter 68000, loss: 0.026806
 >> iter 69000, loss: 0.020099
 >> iter 70000, loss: 0.124744
   Number of active neurons: 6
 >> iter 71000, loss: 0.059336
 >> iter 72000, loss: 0.032333
 >> iter 73000, loss: 0.022496
 >> iter 74000, loss: 0.019727
 >> iter 75000, loss: 0.017872
 >> iter 76000, loss: 0.017968
 >> iter 77000, loss: 0.017053
 >> iter 78000, loss: 0.017705
 >> iter 79000, loss: 0.016914
 >> iter 80000, loss: 0.017578
   Number of active neurons: 6
 >> iter 81000, loss: 0.016878
 >> iter 82000, loss: 0.097974
 >> iter 83000, loss: 0.241493
 >> iter 84000, loss: 0.133738
 >> iter 85000, loss: 0.076949
 >> iter 86000, loss: 0.039522
 >> iter 87000, loss: 0.025610
 >> iter 88000, loss: 0.030577
 >> iter 89000, loss: 0.022215
 >> iter 90000, loss: 0.020268
   Number of active neurons: 6
 >> iter 91000, loss: 0.018517
 >> iter 92000, loss: 0.018263
 >> iter 93000, loss: 0.017718
 >> iter 94000, loss: 0.018274
 >> iter 95000, loss: 0.017537
 >> iter 96000, loss: 0.018095
 >> iter 97000, loss: 0.017379
 >> iter 98000, loss: 0.017986
 >> iter 99000, loss: 0.017229
 >> iter 100000, loss: 0.017815
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0029999700003
   - Test - A: 0.0
   - Test - B: 20.8119458703
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.697205
 >> iter 2000, loss: 7.570760
 >> iter 3000, loss: 2.825955
 >> iter 4000, loss: 1.069508
 >> iter 5000, loss: 0.414415
 >> iter 6000, loss: 0.174184
 >> iter 7000, loss: 0.080459
 >> iter 8000, loss: 0.046135
 >> iter 9000, loss: 0.031319
 >> iter 10000, loss: 0.026404
   Number of active neurons: 9
 >> iter 11000, loss: 0.023121
 >> iter 12000, loss: 0.023147
 >> iter 13000, loss: 0.021376
 >> iter 14000, loss: 0.022321
 >> iter 15000, loss: 0.132115
 >> iter 16000, loss: 0.065486
 >> iter 17000, loss: 0.036129
 >> iter 18000, loss: 0.026182
 >> iter 19000, loss: 0.021581
 >> iter 20000, loss: 0.147069
   Number of active neurons: 7
 >> iter 21000, loss: 0.067785
 >> iter 22000, loss: 0.038678
 >> iter 23000, loss: 0.026963
 >> iter 24000, loss: 0.430348
 >> iter 25000, loss: 0.177682
 >> iter 26000, loss: 0.082159
 >> iter 27000, loss: 0.043974
 >> iter 28000, loss: 0.030627
 >> iter 29000, loss: 0.023776
 >> iter 30000, loss: 0.022265
   Number of active neurons: 7
 >> iter 31000, loss: 0.025910
 >> iter 32000, loss: 0.021661
 >> iter 33000, loss: 0.019714
 >> iter 34000, loss: 0.231711
 >> iter 35000, loss: 0.100211
 >> iter 36000, loss: 0.052516
 >> iter 37000, loss: 0.032159
 >> iter 38000, loss: 0.026346
 >> iter 39000, loss: 0.021936
 >> iter 40000, loss: 0.021755
   Number of active neurons: 7
 >> iter 41000, loss: 0.019843
 >> iter 42000, loss: 0.019821
 >> iter 43000, loss: 0.097054
 >> iter 44000, loss: 0.068756
 >> iter 45000, loss: 0.037401
 >> iter 46000, loss: 0.026381
 >> iter 47000, loss: 0.118559
 >> iter 48000, loss: 0.055932
 >> iter 49000, loss: 0.033276
 >> iter 50000, loss: 0.118950
   Number of active neurons: 7
 >> iter 51000, loss: 0.056595
 >> iter 52000, loss: 0.033813
 >> iter 53000, loss: 0.025087
 >> iter 54000, loss: 0.022200
 >> iter 55000, loss: 0.090093
 >> iter 56000, loss: 0.045221
 >> iter 57000, loss: 0.148050
 >> iter 58000, loss: 0.148594
 >> iter 59000, loss: 0.067894
 >> iter 60000, loss: 0.039440
   Number of active neurons: 7
 >> iter 61000, loss: 0.027219
 >> iter 62000, loss: 0.023310
 >> iter 63000, loss: 0.020936
 >> iter 64000, loss: 0.020451
 >> iter 65000, loss: 0.019133
 >> iter 66000, loss: 0.020377
 >> iter 67000, loss: 0.019377
 >> iter 68000, loss: 0.020275
 >> iter 69000, loss: 0.100791
 >> iter 70000, loss: 0.049627
   Number of active neurons: 6
 >> iter 71000, loss: 0.029949
 >> iter 72000, loss: 0.024549
 >> iter 73000, loss: 0.020667
 >> iter 74000, loss: 0.020372
 >> iter 75000, loss: 0.019704
 >> iter 76000, loss: 0.020012
 >> iter 77000, loss: 0.019097
 >> iter 78000, loss: 0.020194
 >> iter 79000, loss: 0.019080
 >> iter 80000, loss: 0.020151
   Number of active neurons: 6
 >> iter 81000, loss: 0.018872
 >> iter 82000, loss: 0.018498
 >> iter 83000, loss: 0.033185
 >> iter 84000, loss: 0.025543
 >> iter 85000, loss: 0.036034
 >> iter 86000, loss: 0.025955
 >> iter 87000, loss: 0.032332
 >> iter 88000, loss: 0.024347
 >> iter 89000, loss: 0.020042
 >> iter 90000, loss: 0.017572
   Number of active neurons: 6
 >> iter 91000, loss: 0.099689
 >> iter 92000, loss: 0.245083
 >> iter 93000, loss: 0.102912
 >> iter 94000, loss: 0.049936
 >> iter 95000, loss: 0.030330
 >> iter 96000, loss: 0.023001
 >> iter 97000, loss: 0.020296
 >> iter 98000, loss: 0.064615
 >> iter 99000, loss: 0.035858
 >> iter 100000, loss: 0.025106
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 12.1991867209
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.711159
 >> iter 2000, loss: 7.362489
 >> iter 3000, loss: 2.742450
 >> iter 4000, loss: 1.034354
 >> iter 5000, loss: 0.467565
 >> iter 6000, loss: 0.189111
 >> iter 7000, loss: 0.085428
 >> iter 8000, loss: 0.045711
 >> iter 9000, loss: 0.033860
 >> iter 10000, loss: 0.026868
   Number of active neurons: 8
 >> iter 11000, loss: 0.022436
 >> iter 12000, loss: 0.069415
 >> iter 13000, loss: 0.037500
 >> iter 14000, loss: 0.029262
 >> iter 15000, loss: 0.031808
 >> iter 16000, loss: 0.024439
 >> iter 17000, loss: 0.019918
 >> iter 18000, loss: 0.090769
 >> iter 19000, loss: 0.044797
 >> iter 20000, loss: 0.106981
   Number of active neurons: 7
 >> iter 21000, loss: 0.077314
 >> iter 22000, loss: 0.173110
 >> iter 23000, loss: 0.079766
 >> iter 24000, loss: 0.099298
 >> iter 25000, loss: 0.049827
 >> iter 26000, loss: 0.034709
 >> iter 27000, loss: 0.033698
 >> iter 28000, loss: 0.027626
 >> iter 29000, loss: 0.025831
 >> iter 30000, loss: 0.063770
   Number of active neurons: 7
 >> iter 31000, loss: 0.191620
 >> iter 32000, loss: 0.085497
 >> iter 33000, loss: 0.051433
 >> iter 34000, loss: 0.034192
 >> iter 35000, loss: 0.032005
 >> iter 36000, loss: 0.036389
 >> iter 37000, loss: 0.024779
 >> iter 38000, loss: 0.020449
 >> iter 39000, loss: 0.026102
 >> iter 40000, loss: 0.025011
   Number of active neurons: 7
 >> iter 41000, loss: 0.026627
 >> iter 42000, loss: 0.137907
 >> iter 43000, loss: 0.062691
 >> iter 44000, loss: 0.099875
 >> iter 45000, loss: 0.049474
 >> iter 46000, loss: 0.048303
 >> iter 47000, loss: 0.033575
 >> iter 48000, loss: 0.023506
 >> iter 49000, loss: 0.021998
 >> iter 50000, loss: 0.038955
   Number of active neurons: 6
 >> iter 51000, loss: 0.025214
 >> iter 52000, loss: 0.036033
 >> iter 53000, loss: 0.024079
 >> iter 54000, loss: 0.033751
 >> iter 55000, loss: 0.023008
 >> iter 56000, loss: 0.019196
 >> iter 57000, loss: 0.017627
 >> iter 58000, loss: 0.016980
 >> iter 59000, loss: 0.018291
 >> iter 60000, loss: 0.017570
   Number of active neurons: 6
 >> iter 61000, loss: 0.017090
 >> iter 62000, loss: 0.016731
 >> iter 63000, loss: 0.016413
 >> iter 64000, loss: 0.016272
 >> iter 65000, loss: 0.016045
 >> iter 66000, loss: 0.015916
 >> iter 67000, loss: 0.015864
 >> iter 68000, loss: 0.015986
 >> iter 69000, loss: 0.016379
 >> iter 70000, loss: 0.024318
   Number of active neurons: 6
 >> iter 71000, loss: 0.024813
 >> iter 72000, loss: 0.021705
 >> iter 73000, loss: 0.017750
 >> iter 74000, loss: 0.018476
 >> iter 75000, loss: 0.021616
 >> iter 76000, loss: 0.027951
 >> iter 77000, loss: 0.028349
 >> iter 78000, loss: 0.023797
 >> iter 79000, loss: 0.022895
 >> iter 80000, loss: 0.020939
   Number of active neurons: 5
 >> iter 81000, loss: 0.017767
 >> iter 82000, loss: 0.019247
 >> iter 83000, loss: 0.017195
 >> iter 84000, loss: 0.139620
 >> iter 85000, loss: 0.063967
 >> iter 86000, loss: 0.050778
 >> iter 87000, loss: 0.028878
 >> iter 88000, loss: 0.023816
 >> iter 89000, loss: 0.018809
 >> iter 90000, loss: 0.019390
   Number of active neurons: 5
 >> iter 91000, loss: 0.017090
 >> iter 92000, loss: 0.019010
 >> iter 93000, loss: 0.016875
 >> iter 94000, loss: 0.018831
 >> iter 95000, loss: 0.016822
 >> iter 96000, loss: 0.019006
 >> iter 97000, loss: 0.016792
 >> iter 98000, loss: 0.019126
 >> iter 99000, loss: 0.016904
 >> iter 100000, loss: 0.019581
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 18.4454369709
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.062224
 >> iter 2000, loss: 7.033900
 >> iter 3000, loss: 2.615248
 >> iter 4000, loss: 0.986021
 >> iter 5000, loss: 0.390301
 >> iter 6000, loss: 0.158799
 >> iter 7000, loss: 0.077093
 >> iter 8000, loss: 0.040735
 >> iter 9000, loss: 0.031468
 >> iter 10000, loss: 0.022900
   Number of active neurons: 8
 >> iter 11000, loss: 0.021394
 >> iter 12000, loss: 0.018865
 >> iter 13000, loss: 0.018992
 >> iter 14000, loss: 0.019867
 >> iter 15000, loss: 0.020871
 >> iter 16000, loss: 0.017728
 >> iter 17000, loss: 0.026841
 >> iter 18000, loss: 0.076088
 >> iter 19000, loss: 0.038286
 >> iter 20000, loss: 0.068727
   Number of active neurons: 7
 >> iter 21000, loss: 0.036029
 >> iter 22000, loss: 0.023875
 >> iter 23000, loss: 0.019968
 >> iter 24000, loss: 0.066589
 >> iter 25000, loss: 0.035663
 >> iter 26000, loss: 0.024103
 >> iter 27000, loss: 0.020342
 >> iter 28000, loss: 0.062218
 >> iter 29000, loss: 0.034079
 >> iter 30000, loss: 0.023519
   Number of active neurons: 7
 >> iter 31000, loss: 0.020535
 >> iter 32000, loss: 0.018236
 >> iter 33000, loss: 0.099088
 >> iter 34000, loss: 0.047699
 >> iter 35000, loss: 0.029042
 >> iter 36000, loss: 0.021614
 >> iter 37000, loss: 0.022000
 >> iter 38000, loss: 0.018336
 >> iter 39000, loss: 0.017664
 >> iter 40000, loss: 0.017030
   Number of active neurons: 7
 >> iter 41000, loss: 0.050392
 >> iter 42000, loss: 0.028294
 >> iter 43000, loss: 0.020845
 >> iter 44000, loss: 0.017847
 >> iter 45000, loss: 0.017325
 >> iter 46000, loss: 0.016704
 >> iter 47000, loss: 0.017057
 >> iter 48000, loss: 0.016665
 >> iter 49000, loss: 0.251782
 >> iter 50000, loss: 0.102541
   Number of active neurons: 7
 >> iter 51000, loss: 0.047866
 >> iter 52000, loss: 0.027843
 >> iter 53000, loss: 0.020914
 >> iter 54000, loss: 0.018317
 >> iter 55000, loss: 0.017487
 >> iter 56000, loss: 0.017076
 >> iter 57000, loss: 0.017143
 >> iter 58000, loss: 0.016890
 >> iter 59000, loss: 0.245329
 >> iter 60000, loss: 0.103243
   Number of active neurons: 7
 >> iter 61000, loss: 0.048982
 >> iter 62000, loss: 0.028899
 >> iter 63000, loss: 0.021769
 >> iter 64000, loss: 0.018962
 >> iter 65000, loss: 0.018145
 >> iter 66000, loss: 0.017533
 >> iter 67000, loss: 0.017482
 >> iter 68000, loss: 0.017143
 >> iter 69000, loss: 0.017176
 >> iter 70000, loss: 0.016889
   Number of active neurons: 7
 >> iter 71000, loss: 0.018469
 >> iter 72000, loss: 0.017096
 >> iter 73000, loss: 0.016851
 >> iter 74000, loss: 0.016443
 >> iter 75000, loss: 0.114483
 >> iter 76000, loss: 0.052682
 >> iter 77000, loss: 0.029937
 >> iter 78000, loss: 0.021449
 >> iter 79000, loss: 0.082305
 >> iter 80000, loss: 0.040926
   Number of active neurons: 6
 >> iter 81000, loss: 0.025567
 >> iter 82000, loss: 0.019863
 >> iter 83000, loss: 0.017894
 >> iter 84000, loss: 0.016973
 >> iter 85000, loss: 0.016902
 >> iter 86000, loss: 0.016515
 >> iter 87000, loss: 0.016697
 >> iter 88000, loss: 0.016373
 >> iter 89000, loss: 0.016659
 >> iter 90000, loss: 0.016299
   Number of active neurons: 6
 >> iter 91000, loss: 0.101421
 >> iter 92000, loss: 0.047941
 >> iter 93000, loss: 0.027142
 >> iter 94000, loss: 0.019637
 >> iter 95000, loss: 0.017158
 >> iter 96000, loss: 0.016105
 >> iter 97000, loss: 0.271680
 >> iter 98000, loss: 0.111950
 >> iter 99000, loss: 0.051361
 >> iter 100000, loss: 0.029284
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 14.292380508
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.020299
 >> iter 2000, loss: 8.303977
 >> iter 3000, loss: 3.201487
 >> iter 4000, loss: 1.208428
 >> iter 5000, loss: 0.469713
 >> iter 6000, loss: 0.193115
 >> iter 7000, loss: 0.095796
 >> iter 8000, loss: 0.051858
 >> iter 9000, loss: 0.034268
 >> iter 10000, loss: 0.027831
   Number of active neurons: 9
 >> iter 11000, loss: 0.024085
 >> iter 12000, loss: 0.023059
 >> iter 13000, loss: 0.030657
 >> iter 14000, loss: 0.025866
 >> iter 15000, loss: 0.029694
 >> iter 16000, loss: 0.024271
 >> iter 17000, loss: 0.167123
 >> iter 18000, loss: 0.087709
 >> iter 19000, loss: 0.219745
 >> iter 20000, loss: 0.099883
   Number of active neurons: 8
 >> iter 21000, loss: 0.051485
 >> iter 22000, loss: 0.036944
 >> iter 23000, loss: 0.026861
 >> iter 24000, loss: 0.027755
 >> iter 25000, loss: 0.022873
 >> iter 26000, loss: 0.025932
 >> iter 27000, loss: 0.021858
 >> iter 28000, loss: 0.025377
 >> iter 29000, loss: 0.021488
 >> iter 30000, loss: 0.025613
   Number of active neurons: 8
 >> iter 31000, loss: 0.021506
 >> iter 32000, loss: 0.025843
 >> iter 33000, loss: 0.021512
 >> iter 34000, loss: 0.025966
 >> iter 35000, loss: 0.021474
 >> iter 36000, loss: 0.025795
 >> iter 37000, loss: 0.022040
 >> iter 38000, loss: 0.025645
 >> iter 39000, loss: 0.024978
 >> iter 40000, loss: 0.021652
   Number of active neurons: 8
 >> iter 41000, loss: 0.143923
 >> iter 42000, loss: 0.067042
 >> iter 43000, loss: 0.154819
 >> iter 44000, loss: 0.071919
 >> iter 45000, loss: 0.108191
 >> iter 46000, loss: 0.054447
 >> iter 47000, loss: 0.097717
 >> iter 48000, loss: 0.050237
 >> iter 49000, loss: 0.093286
 >> iter 50000, loss: 0.048299
   Number of active neurons: 8
 >> iter 51000, loss: 0.090576
 >> iter 52000, loss: 0.047189
 >> iter 53000, loss: 0.089247
 >> iter 54000, loss: 0.046592
 >> iter 55000, loss: 0.088282
 >> iter 56000, loss: 0.046177
 >> iter 57000, loss: 0.088157
 >> iter 58000, loss: 0.046100
 >> iter 59000, loss: 0.087092
 >> iter 60000, loss: 0.045528
   Number of active neurons: 6
 >> iter 61000, loss: 0.086877
 >> iter 62000, loss: 0.045264
 >> iter 63000, loss: 0.086443
 >> iter 64000, loss: 0.044898
 >> iter 65000, loss: 0.085832
 >> iter 66000, loss: 0.044531
 >> iter 67000, loss: 0.086867
 >> iter 68000, loss: 0.045377
 >> iter 69000, loss: 0.031759
 >> iter 70000, loss: 0.024377
   Number of active neurons: 6
 >> iter 71000, loss: 0.022414
 >> iter 72000, loss: 0.021093
 >> iter 73000, loss: 0.055893
 >> iter 74000, loss: 0.033819
 >> iter 75000, loss: 0.062687
 >> iter 76000, loss: 0.035191
 >> iter 77000, loss: 0.059894
 >> iter 78000, loss: 0.034617
 >> iter 79000, loss: 0.025276
 >> iter 80000, loss: 0.020662
   Number of active neurons: 6
 >> iter 81000, loss: 0.021161
 >> iter 82000, loss: 0.021315
 >> iter 83000, loss: 0.024080
 >> iter 84000, loss: 0.022723
 >> iter 85000, loss: 0.039414
 >> iter 86000, loss: 0.027369
 >> iter 87000, loss: 0.049562
 >> iter 88000, loss: 0.031438
 >> iter 89000, loss: 0.037093
 >> iter 90000, loss: 0.026254
   Number of active neurons: 6
 >> iter 91000, loss: 0.046942
 >> iter 92000, loss: 0.030291
 >> iter 93000, loss: 0.027206
 >> iter 94000, loss: 0.023655
 >> iter 95000, loss: 0.024857
 >> iter 96000, loss: 0.022102
 >> iter 97000, loss: 0.024634
 >> iter 98000, loss: 0.022369
 >> iter 99000, loss: 0.025786
 >> iter 100000, loss: 0.022592
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 22.7118192121
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.415762
 >> iter 2000, loss: 7.189324
 >> iter 3000, loss: 2.684768
 >> iter 4000, loss: 1.008691
 >> iter 5000, loss: 0.428298
 >> iter 6000, loss: 0.173427
 >> iter 7000, loss: 0.114725
 >> iter 8000, loss: 0.056178
 >> iter 9000, loss: 0.048542
 >> iter 10000, loss: 0.030438
   Number of active neurons: 6
 >> iter 11000, loss: 0.032670
 >> iter 12000, loss: 0.024010
 >> iter 13000, loss: 0.027695
 >> iter 14000, loss: 0.022006
 >> iter 15000, loss: 0.024763
 >> iter 16000, loss: 0.020279
 >> iter 17000, loss: 0.023123
 >> iter 18000, loss: 0.019566
 >> iter 19000, loss: 0.025957
 >> iter 20000, loss: 0.020037
   Number of active neurons: 6
 >> iter 21000, loss: 0.023344
 >> iter 22000, loss: 0.018917
 >> iter 23000, loss: 0.026567
 >> iter 24000, loss: 0.020146
 >> iter 25000, loss: 0.024527
 >> iter 26000, loss: 0.019352
 >> iter 27000, loss: 0.018093
 >> iter 28000, loss: 0.016908
 >> iter 29000, loss: 0.017594
 >> iter 30000, loss: 0.016740
   Number of active neurons: 6
 >> iter 31000, loss: 0.016736
 >> iter 32000, loss: 0.016518
 >> iter 33000, loss: 0.019859
 >> iter 34000, loss: 0.038603
 >> iter 35000, loss: 0.024574
 >> iter 36000, loss: 0.043958
 >> iter 37000, loss: 0.028536
 >> iter 38000, loss: 0.022851
 >> iter 39000, loss: 0.019340
 >> iter 40000, loss: 0.079954
   Number of active neurons: 6
 >> iter 41000, loss: 0.040466
 >> iter 42000, loss: 0.079620
 >> iter 43000, loss: 0.040897
 >> iter 44000, loss: 0.057566
 >> iter 45000, loss: 0.032530
 >> iter 46000, loss: 0.023326
 >> iter 47000, loss: 0.020558
 >> iter 48000, loss: 0.019125
 >> iter 49000, loss: 0.019377
 >> iter 50000, loss: 0.024445
   Number of active neurons: 6
 >> iter 51000, loss: 0.023184
 >> iter 52000, loss: 0.020189
 >> iter 53000, loss: 0.021565
 >> iter 54000, loss: 0.025055
 >> iter 55000, loss: 0.018856
 >> iter 56000, loss: 0.019175
 >> iter 57000, loss: 0.032556
 >> iter 58000, loss: 0.023918
 >> iter 59000, loss: 0.023472
 >> iter 60000, loss: 0.021255
   Number of active neurons: 6
 >> iter 61000, loss: 0.021375
 >> iter 62000, loss: 0.020827
 >> iter 63000, loss: 0.018511
 >> iter 64000, loss: 0.019986
 >> iter 65000, loss: 0.021734
 >> iter 66000, loss: 0.083842
 >> iter 67000, loss: 0.047597
 >> iter 68000, loss: 0.099244
 >> iter 69000, loss: 0.047730
 >> iter 70000, loss: 0.029971
   Number of active neurons: 5
 >> iter 71000, loss: 0.021383
 >> iter 72000, loss: 0.029382
 >> iter 73000, loss: 0.020888
 >> iter 74000, loss: 0.032475
 >> iter 75000, loss: 0.022595
 >> iter 76000, loss: 0.020385
 >> iter 77000, loss: 0.017838
 >> iter 78000, loss: 0.056849
 >> iter 79000, loss: 0.032048
 >> iter 80000, loss: 0.049524
   Number of active neurons: 5
 >> iter 81000, loss: 0.028721
 >> iter 82000, loss: 0.021513
 >> iter 83000, loss: 0.018433
 >> iter 84000, loss: 0.041516
 >> iter 85000, loss: 0.025421
 >> iter 86000, loss: 0.020095
 >> iter 87000, loss: 0.017607
 >> iter 88000, loss: 0.017637
 >> iter 89000, loss: 0.016916
 >> iter 90000, loss: 0.017471
   Number of active neurons: 5
 >> iter 91000, loss: 0.016853
 >> iter 92000, loss: 0.017167
 >> iter 93000, loss: 0.016868
 >> iter 94000, loss: 0.016800
 >> iter 95000, loss: 0.016570
 >> iter 96000, loss: 0.016547
 >> iter 97000, loss: 0.016551
 >> iter 98000, loss: 0.016421
 >> iter 99000, loss: 0.016523
 >> iter 100000, loss: 0.016311
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 20.6252916472
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.473683
 >> iter 2000, loss: 7.554705
 >> iter 3000, loss: 2.959099
 >> iter 4000, loss: 1.120310
 >> iter 5000, loss: 0.435256
 >> iter 6000, loss: 0.179559
 >> iter 7000, loss: 0.087724
 >> iter 8000, loss: 0.049466
 >> iter 9000, loss: 0.275165
 >> iter 10000, loss: 0.122824
   Number of active neurons: 8
 >> iter 11000, loss: 0.061165
 >> iter 12000, loss: 0.037691
 >> iter 13000, loss: 0.092603
 >> iter 14000, loss: 0.048725
 >> iter 15000, loss: 0.031561
 >> iter 16000, loss: 0.025020
 >> iter 17000, loss: 0.063210
 >> iter 18000, loss: 0.039859
 >> iter 19000, loss: 0.027514
 >> iter 20000, loss: 0.026272
   Number of active neurons: 7
 >> iter 21000, loss: 0.065306
 >> iter 22000, loss: 0.040567
 >> iter 23000, loss: 0.027288
 >> iter 24000, loss: 0.025389
 >> iter 25000, loss: 0.053571
 >> iter 26000, loss: 0.035064
 >> iter 27000, loss: 0.024765
 >> iter 28000, loss: 0.024193
 >> iter 29000, loss: 0.068192
 >> iter 30000, loss: 0.041200
   Number of active neurons: 7
 >> iter 31000, loss: 0.026619
 >> iter 32000, loss: 0.415816
 >> iter 33000, loss: 0.168012
 >> iter 34000, loss: 0.075217
 >> iter 35000, loss: 0.040135
 >> iter 36000, loss: 0.030284
 >> iter 37000, loss: 0.023007
 >> iter 38000, loss: 0.023594
 >> iter 39000, loss: 0.020275
 >> iter 40000, loss: 0.022267
   Number of active neurons: 7
 >> iter 41000, loss: 0.371916
 >> iter 42000, loss: 0.154253
 >> iter 43000, loss: 0.069989
 >> iter 44000, loss: 0.041564
 >> iter 45000, loss: 0.027621
 >> iter 46000, loss: 0.025989
 >> iter 47000, loss: 0.021543
 >> iter 48000, loss: 0.023474
 >> iter 49000, loss: 0.020439
 >> iter 50000, loss: 0.022626
   Number of active neurons: 6
 >> iter 51000, loss: 0.020005
 >> iter 52000, loss: 0.022154
 >> iter 53000, loss: 0.019747
 >> iter 54000, loss: 0.021908
 >> iter 55000, loss: 0.019550
 >> iter 56000, loss: 0.021417
 >> iter 57000, loss: 0.019263
 >> iter 58000, loss: 0.021106
 >> iter 59000, loss: 0.150391
 >> iter 60000, loss: 0.070226
   Number of active neurons: 6
 >> iter 61000, loss: 0.037761
 >> iter 62000, loss: 0.028674
 >> iter 63000, loss: 0.022211
 >> iter 64000, loss: 0.023116
 >> iter 65000, loss: 0.100402
 >> iter 66000, loss: 0.052797
 >> iter 67000, loss: 0.031799
 >> iter 68000, loss: 0.028534
 >> iter 69000, loss: 0.022349
 >> iter 70000, loss: 0.023947
   Number of active neurons: 6
 >> iter 71000, loss: 0.020563
 >> iter 72000, loss: 0.023351
 >> iter 73000, loss: 0.020235
 >> iter 74000, loss: 0.022781
 >> iter 75000, loss: 0.020019
 >> iter 76000, loss: 0.079263
 >> iter 77000, loss: 0.042764
 >> iter 78000, loss: 0.034251
 >> iter 79000, loss: 0.416604
 >> iter 80000, loss: 0.201977
   Number of active neurons: 6
 >> iter 81000, loss: 0.088226
 >> iter 82000, loss: 0.045261
 >> iter 83000, loss: 0.029160
 >> iter 84000, loss: 0.024213
 >> iter 85000, loss: 0.020952
 >> iter 86000, loss: 0.020662
 >> iter 87000, loss: 0.019627
 >> iter 88000, loss: 0.019059
 >> iter 89000, loss: 0.199381
 >> iter 90000, loss: 0.089119
   Number of active neurons: 6
 >> iter 91000, loss: 0.046213
 >> iter 92000, loss: 0.029753
 >> iter 93000, loss: 0.141915
 >> iter 94000, loss: 0.067361
 >> iter 95000, loss: 0.037748
 >> iter 96000, loss: 0.026577
 >> iter 97000, loss: 0.022309
 >> iter 98000, loss: 0.020962
 >> iter 99000, loss: 0.019836
 >> iter 100000, loss: 0.025879
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.039999200016
   - Test - Long: 0.174991250437
   - Test - Big: 0.0319996800032
   - Test - A: 0.0
   - Test - B: 17.5588294114
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.375457
 >> iter 2000, loss: 8.654604
 >> iter 3000, loss: 3.346321
 >> iter 4000, loss: 1.261285
 >> iter 5000, loss: 0.484781
 >> iter 6000, loss: 0.196499
 >> iter 7000, loss: 0.089217
 >> iter 8000, loss: 0.048907
 >> iter 9000, loss: 0.033256
 >> iter 10000, loss: 0.031638
   Number of active neurons: 10
 >> iter 11000, loss: 0.025904
 >> iter 12000, loss: 0.094419
 >> iter 13000, loss: 0.049411
 >> iter 14000, loss: 0.039745
 >> iter 15000, loss: 0.028328
 >> iter 16000, loss: 0.028413
 >> iter 17000, loss: 0.023742
 >> iter 18000, loss: 0.070574
 >> iter 19000, loss: 0.039297
 >> iter 20000, loss: 0.034988
   Number of active neurons: 9
 >> iter 21000, loss: 0.025825
 >> iter 22000, loss: 0.026210
 >> iter 23000, loss: 0.022275
 >> iter 24000, loss: 0.023977
 >> iter 25000, loss: 0.021190
 >> iter 26000, loss: 0.022908
 >> iter 27000, loss: 0.020557
 >> iter 28000, loss: 0.099776
 >> iter 29000, loss: 0.050047
 >> iter 30000, loss: 0.032941
   Number of active neurons: 8
 >> iter 31000, loss: 0.024726
 >> iter 32000, loss: 0.142628
 >> iter 33000, loss: 0.065687
 >> iter 34000, loss: 0.037789
 >> iter 35000, loss: 0.026321
 >> iter 36000, loss: 0.070441
 >> iter 37000, loss: 0.038227
 >> iter 38000, loss: 0.026996
 >> iter 39000, loss: 0.022080
 >> iter 40000, loss: 0.042113
   Number of active neurons: 7
 >> iter 41000, loss: 0.027608
 >> iter 42000, loss: 0.023201
 >> iter 43000, loss: 0.020402
 >> iter 44000, loss: 0.046015
 >> iter 45000, loss: 0.029191
 >> iter 46000, loss: 0.047948
 >> iter 47000, loss: 0.030009
 >> iter 48000, loss: 0.047091
 >> iter 49000, loss: 0.029707
 >> iter 50000, loss: 0.044820
   Number of active neurons: 7
 >> iter 51000, loss: 0.028871
 >> iter 52000, loss: 0.042492
 >> iter 53000, loss: 0.028088
 >> iter 54000, loss: 0.047638
 >> iter 55000, loss: 0.030196
 >> iter 56000, loss: 0.040187
 >> iter 57000, loss: 0.247351
 >> iter 58000, loss: 0.106053
 >> iter 59000, loss: 0.052062
 >> iter 60000, loss: 0.031951
   Number of active neurons: 7
 >> iter 61000, loss: 0.023892
 >> iter 62000, loss: 0.048256
 >> iter 63000, loss: 0.030494
 >> iter 64000, loss: 0.045934
 >> iter 65000, loss: 0.029601
 >> iter 66000, loss: 0.023914
 >> iter 67000, loss: 0.020746
 >> iter 68000, loss: 0.051545
 >> iter 69000, loss: 0.031431
 >> iter 70000, loss: 0.063593
   Number of active neurons: 7
 >> iter 71000, loss: 0.036079
 >> iter 72000, loss: 0.059867
 >> iter 73000, loss: 0.034844
 >> iter 74000, loss: 0.060567
 >> iter 75000, loss: 0.035167
 >> iter 76000, loss: 0.061412
 >> iter 77000, loss: 0.035361
 >> iter 78000, loss: 0.063620
 >> iter 79000, loss: 0.036391
 >> iter 80000, loss: 0.064186
   Number of active neurons: 7
 >> iter 81000, loss: 0.036144
 >> iter 82000, loss: 0.083366
 >> iter 83000, loss: 0.043365
 >> iter 84000, loss: 0.065442
 >> iter 85000, loss: 0.037623
 >> iter 86000, loss: 0.026889
 >> iter 87000, loss: 0.027176
 >> iter 88000, loss: 0.113208
 >> iter 89000, loss: 0.054611
 >> iter 90000, loss: 0.033530
   Number of active neurons: 7
 >> iter 91000, loss: 0.032114
 >> iter 92000, loss: 0.024321
 >> iter 93000, loss: 0.022078
 >> iter 94000, loss: 0.020135
 >> iter 95000, loss: 0.054008
 >> iter 96000, loss: 0.234293
 >> iter 97000, loss: 0.188754
 >> iter 98000, loss: 0.083518
 >> iter 99000, loss: 0.042934
 >> iter 100000, loss: 0.080662
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 15.2123191787
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.556087
 >> iter 2000, loss: 7.751854
 >> iter 3000, loss: 2.901402
 >> iter 4000, loss: 1.103309
 >> iter 5000, loss: 0.427502
 >> iter 6000, loss: 0.184103
 >> iter 7000, loss: 0.085382
 >> iter 8000, loss: 0.053990
 >> iter 9000, loss: 0.035702
 >> iter 10000, loss: 0.037507
   Number of active neurons: 9
 >> iter 11000, loss: 0.028715
 >> iter 12000, loss: 0.035567
 >> iter 13000, loss: 0.112576
 >> iter 14000, loss: 0.065025
 >> iter 15000, loss: 0.038177
 >> iter 16000, loss: 0.036709
 >> iter 17000, loss: 0.027071
 >> iter 18000, loss: 0.030945
 >> iter 19000, loss: 0.024679
 >> iter 20000, loss: 0.028346
   Number of active neurons: 8
 >> iter 21000, loss: 0.023356
 >> iter 22000, loss: 0.185150
 >> iter 23000, loss: 0.080996
 >> iter 24000, loss: 0.122731
 >> iter 25000, loss: 0.108213
 >> iter 26000, loss: 0.052728
 >> iter 27000, loss: 0.031836
 >> iter 28000, loss: 0.044282
 >> iter 29000, loss: 0.028562
 >> iter 30000, loss: 0.023410
   Number of active neurons: 8
 >> iter 31000, loss: 0.035611
 >> iter 32000, loss: 0.025753
 >> iter 33000, loss: 0.021037
 >> iter 34000, loss: 0.020585
 >> iter 35000, loss: 0.019372
 >> iter 36000, loss: 0.020189
 >> iter 37000, loss: 0.019136
 >> iter 38000, loss: 0.019932
 >> iter 39000, loss: 0.018913
 >> iter 40000, loss: 0.124587
   Number of active neurons: 7
 >> iter 41000, loss: 0.536097
 >> iter 42000, loss: 0.213505
 >> iter 43000, loss: 0.092081
 >> iter 44000, loss: 0.046865
 >> iter 45000, loss: 0.029640
 >> iter 46000, loss: 0.025226
 >> iter 47000, loss: 0.021290
 >> iter 48000, loss: 0.021982
 >> iter 49000, loss: 0.019802
 >> iter 50000, loss: 0.021268
   Number of active neurons: 7
 >> iter 51000, loss: 0.038140
 >> iter 52000, loss: 0.028016
 >> iter 53000, loss: 0.021643
 >> iter 54000, loss: 0.164367
 >> iter 55000, loss: 0.073893
 >> iter 56000, loss: 0.314912
 >> iter 57000, loss: 0.189995
 >> iter 58000, loss: 0.084807
 >> iter 59000, loss: 0.045125
 >> iter 60000, loss: 0.059519
   Number of active neurons: 6
 >> iter 61000, loss: 0.034906
 >> iter 62000, loss: 0.025579
 >> iter 63000, loss: 0.021904
 >> iter 64000, loss: 0.120492
 >> iter 65000, loss: 0.058637
 >> iter 66000, loss: 0.045138
 >> iter 67000, loss: 0.029676
 >> iter 68000, loss: 0.094110
 >> iter 69000, loss: 0.048686
 >> iter 70000, loss: 0.031365
   Number of active neurons: 6
 >> iter 71000, loss: 0.024461
 >> iter 72000, loss: 0.228574
 >> iter 73000, loss: 0.101313
 >> iter 74000, loss: 0.052549
 >> iter 75000, loss: 0.214712
 >> iter 76000, loss: 0.113405
 >> iter 77000, loss: 0.057040
 >> iter 78000, loss: 0.035441
 >> iter 79000, loss: 0.026978
 >> iter 80000, loss: 0.054350
   Number of active neurons: 6
 >> iter 81000, loss: 0.034225
 >> iter 82000, loss: 0.137509
 >> iter 83000, loss: 0.066323
 >> iter 84000, loss: 0.039079
 >> iter 85000, loss: 0.028402
 >> iter 86000, loss: 0.023976
 >> iter 87000, loss: 0.029687
 >> iter 88000, loss: 0.034265
 >> iter 89000, loss: 0.025473
 >> iter 90000, loss: 0.022188
   Number of active neurons: 5
 >> iter 91000, loss: 0.020643
 >> iter 92000, loss: 0.069971
 >> iter 93000, loss: 0.038775
 >> iter 94000, loss: 0.037962
 >> iter 95000, loss: 0.026652
 >> iter 96000, loss: 0.023461
 >> iter 97000, loss: 0.020924
 >> iter 98000, loss: 0.019222
 >> iter 99000, loss: 0.031927
 >> iter 100000, loss: 0.028203
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0029999700003
   - Test - A: 0.0
   - Test - B: 21.4385707619
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.907190
 >> iter 2000, loss: 8.340988
 >> iter 3000, loss: 3.105785
 >> iter 4000, loss: 1.165748
 >> iter 5000, loss: 0.447808
 >> iter 6000, loss: 0.181289
 >> iter 7000, loss: 0.087555
 >> iter 8000, loss: 0.117149
 >> iter 9000, loss: 0.057751
 >> iter 10000, loss: 0.072908
   Number of active neurons: 8
 >> iter 11000, loss: 0.041832
 >> iter 12000, loss: 0.028776
 >> iter 13000, loss: 0.031036
 >> iter 14000, loss: 0.024103
 >> iter 15000, loss: 0.022043
 >> iter 16000, loss: 0.020278
 >> iter 17000, loss: 0.104403
 >> iter 18000, loss: 0.051323
 >> iter 19000, loss: 0.037024
 >> iter 20000, loss: 0.026053
   Number of active neurons: 8
 >> iter 21000, loss: 0.021993
 >> iter 22000, loss: 0.021128
 >> iter 23000, loss: 0.023145
 >> iter 24000, loss: 0.020418
 >> iter 25000, loss: 0.019517
 >> iter 26000, loss: 0.119905
 >> iter 27000, loss: 0.060151
 >> iter 28000, loss: 0.034200
 >> iter 29000, loss: 0.024605
 >> iter 30000, loss: 0.021008
   Number of active neurons: 7
 >> iter 31000, loss: 0.019726
 >> iter 32000, loss: 0.019154
 >> iter 33000, loss: 0.019000
 >> iter 34000, loss: 0.018867
 >> iter 35000, loss: 0.018923
 >> iter 36000, loss: 0.018802
 >> iter 37000, loss: 0.018881
 >> iter 38000, loss: 0.018702
 >> iter 39000, loss: 0.018739
 >> iter 40000, loss: 0.018599
   Number of active neurons: 7
 >> iter 41000, loss: 0.018566
 >> iter 42000, loss: 0.018360
 >> iter 43000, loss: 0.018244
 >> iter 44000, loss: 0.018121
 >> iter 45000, loss: 0.017914
 >> iter 46000, loss: 0.018977
 >> iter 47000, loss: 0.017971
 >> iter 48000, loss: 0.017913
 >> iter 49000, loss: 0.017573
 >> iter 50000, loss: 0.023943
   Number of active neurons: 7
 >> iter 51000, loss: 0.023435
 >> iter 52000, loss: 0.019582
 >> iter 53000, loss: 0.017898
 >> iter 54000, loss: 0.018517
 >> iter 55000, loss: 0.017532
 >> iter 56000, loss: 0.018387
 >> iter 57000, loss: 0.032732
 >> iter 58000, loss: 0.024305
 >> iter 59000, loss: 0.165089
 >> iter 60000, loss: 0.072643
   Number of active neurons: 5
 >> iter 61000, loss: 0.037950
 >> iter 62000, loss: 0.026203
 >> iter 63000, loss: 0.122289
 >> iter 64000, loss: 0.057111
 >> iter 65000, loss: 0.131440
 >> iter 66000, loss: 0.061977
 >> iter 67000, loss: 0.034232
 >> iter 68000, loss: 0.025463
 >> iter 69000, loss: 0.020321
 >> iter 70000, loss: 0.019784
   Number of active neurons: 5
 >> iter 71000, loss: 0.018139
 >> iter 72000, loss: 0.018254
 >> iter 73000, loss: 0.017089
 >> iter 74000, loss: 0.017245
 >> iter 75000, loss: 0.016596
 >> iter 76000, loss: 0.016666
 >> iter 77000, loss: 0.016287
 >> iter 78000, loss: 0.016445
 >> iter 79000, loss: 0.016161
 >> iter 80000, loss: 0.016335
   Number of active neurons: 5
 >> iter 81000, loss: 0.016089
 >> iter 82000, loss: 0.016267
 >> iter 83000, loss: 0.016027
 >> iter 84000, loss: 0.016209
 >> iter 85000, loss: 0.015995
 >> iter 86000, loss: 0.016182
 >> iter 87000, loss: 0.015974
 >> iter 88000, loss: 0.016165
 >> iter 89000, loss: 0.015971
 >> iter 90000, loss: 0.016149
   Number of active neurons: 5
 >> iter 91000, loss: 0.015977
 >> iter 92000, loss: 0.016114
 >> iter 93000, loss: 0.016019
 >> iter 94000, loss: 0.016081
 >> iter 95000, loss: 0.016031
 >> iter 96000, loss: 0.016022
 >> iter 97000, loss: 0.015983
 >> iter 98000, loss: 0.015951
 >> iter 99000, loss: 0.015944
 >> iter 100000, loss: 0.015874
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0019999600008
   - Test - Long: 0.0
   - Test - Big: 0.0029999700003
   - Test - A: 0.0
   - Test - B: 21.2852476502
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.913287
 >> iter 2000, loss: 8.105007
 >> iter 3000, loss: 3.020027
 >> iter 4000, loss: 1.135999
 >> iter 5000, loss: 0.438978
 >> iter 6000, loss: 0.185929
 >> iter 7000, loss: 0.084976
 >> iter 8000, loss: 0.047111
 >> iter 9000, loss: 0.033050
 >> iter 10000, loss: 0.027212
   Number of active neurons: 9
 >> iter 11000, loss: 0.025002
 >> iter 12000, loss: 0.023700
 >> iter 13000, loss: 0.023261
 >> iter 14000, loss: 0.022681
 >> iter 15000, loss: 0.022549
 >> iter 16000, loss: 0.022095
 >> iter 17000, loss: 0.022064
 >> iter 18000, loss: 0.021609
 >> iter 19000, loss: 0.021616
 >> iter 20000, loss: 0.021277
   Number of active neurons: 8
 >> iter 21000, loss: 0.021432
 >> iter 22000, loss: 0.021110
 >> iter 23000, loss: 0.021277
 >> iter 24000, loss: 0.020933
 >> iter 25000, loss: 0.021095
 >> iter 26000, loss: 0.020759
 >> iter 27000, loss: 0.020967
 >> iter 28000, loss: 0.020647
 >> iter 29000, loss: 0.020837
 >> iter 30000, loss: 0.020483
   Number of active neurons: 8
 >> iter 31000, loss: 0.020691
 >> iter 32000, loss: 0.020339
 >> iter 33000, loss: 0.020559
 >> iter 34000, loss: 0.020251
 >> iter 35000, loss: 0.020426
 >> iter 36000, loss: 0.020114
 >> iter 37000, loss: 0.020302
 >> iter 38000, loss: 0.019992
 >> iter 39000, loss: 0.020167
 >> iter 40000, loss: 0.019886
   Number of active neurons: 8
 >> iter 41000, loss: 0.020054
 >> iter 42000, loss: 0.019787
 >> iter 43000, loss: 0.019931
 >> iter 44000, loss: 0.019660
 >> iter 45000, loss: 0.019761
 >> iter 46000, loss: 0.019458
 >> iter 47000, loss: 0.019545
 >> iter 48000, loss: 0.019265
 >> iter 49000, loss: 0.019341
 >> iter 50000, loss: 0.019062
   Number of active neurons: 8
 >> iter 51000, loss: 0.019089
 >> iter 52000, loss: 0.018776
 >> iter 53000, loss: 0.018740
 >> iter 54000, loss: 0.018439
 >> iter 55000, loss: 0.018414
 >> iter 56000, loss: 0.018132
 >> iter 57000, loss: 0.018124
 >> iter 58000, loss: 0.017856
 >> iter 59000, loss: 0.017869
 >> iter 60000, loss: 0.017638
   Number of active neurons: 7
 >> iter 61000, loss: 0.017674
 >> iter 62000, loss: 0.017446
 >> iter 63000, loss: 0.017489
 >> iter 64000, loss: 0.017259
 >> iter 65000, loss: 0.017323
 >> iter 66000, loss: 0.017128
 >> iter 67000, loss: 0.017195
 >> iter 68000, loss: 0.016990
 >> iter 69000, loss: 0.017048
 >> iter 70000, loss: 0.016862
   Number of active neurons: 6
 >> iter 71000, loss: 0.016954
 >> iter 72000, loss: 0.016757
 >> iter 73000, loss: 0.016852
 >> iter 74000, loss: 0.016610
 >> iter 75000, loss: 0.016688
 >> iter 76000, loss: 0.016476
 >> iter 77000, loss: 0.016560
 >> iter 78000, loss: 0.016356
 >> iter 79000, loss: 0.016453
 >> iter 80000, loss: 0.016249
   Number of active neurons: 6
 >> iter 81000, loss: 0.016350
 >> iter 82000, loss: 0.016147
 >> iter 83000, loss: 0.016234
 >> iter 84000, loss: 0.016025
 >> iter 85000, loss: 0.016131
 >> iter 86000, loss: 0.015938
 >> iter 87000, loss: 0.016041
 >> iter 88000, loss: 0.015864
 >> iter 89000, loss: 0.015941
 >> iter 90000, loss: 0.015761
   Number of active neurons: 6
 >> iter 91000, loss: 0.015845
 >> iter 92000, loss: 0.015682
 >> iter 93000, loss: 0.015787
 >> iter 94000, loss: 0.015633
 >> iter 95000, loss: 0.015770
 >> iter 96000, loss: 0.015594
 >> iter 97000, loss: 0.015737
 >> iter 98000, loss: 0.015560
 >> iter 99000, loss: 0.015713
 >> iter 100000, loss: 0.015533
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 16.7322178521

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

