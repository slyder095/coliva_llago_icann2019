 > Problema: tomita2nueva
 > Args:
   - Hidden size: 20
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.350298
 >> iter 2000, loss: 4.459014
 >> iter 3000, loss: 1.794855
 >> iter 4000, loss: 0.757911
 >> iter 5000, loss: 0.375684
 >> iter 6000, loss: 0.197529
 >> iter 7000, loss: 0.127902
 >> iter 8000, loss: 0.073229
 >> iter 9000, loss: 0.106849
 >> iter 10000, loss: 0.073125
   Number of active neurons: 9
 >> iter 11000, loss: 0.070211
 >> iter 12000, loss: 0.072781
 >> iter 13000, loss: 0.069378
 >> iter 14000, loss: 0.067848
 >> iter 15000, loss: 0.059299
 >> iter 16000, loss: 0.072824
 >> iter 17000, loss: 0.068840
 >> iter 18000, loss: 0.065867
 >> iter 19000, loss: 0.106364
 >> iter 20000, loss: 0.087510
   Number of active neurons: 5
 >> iter 21000, loss: 0.059885
 >> iter 22000, loss: 0.056664
 >> iter 23000, loss: 0.063932
 >> iter 24000, loss: 0.063160
 >> iter 25000, loss: 0.058724
 >> iter 26000, loss: 0.058125
 >> iter 27000, loss: 0.052334
 >> iter 28000, loss: 0.062184
 >> iter 29000, loss: 0.075453
 >> iter 30000, loss: 0.071173
   Number of active neurons: 5
 >> iter 31000, loss: 0.062925
 >> iter 32000, loss: 0.048345
 >> iter 33000, loss: 0.055368
 >> iter 34000, loss: 0.049717
 >> iter 35000, loss: 0.059734
 >> iter 36000, loss: 0.054707
 >> iter 37000, loss: 0.053413
 >> iter 38000, loss: 0.047847
 >> iter 39000, loss: 0.041356
 >> iter 40000, loss: 0.062709
   Number of active neurons: 5
 >> iter 41000, loss: 0.054140
 >> iter 42000, loss: 0.061760
 >> iter 43000, loss: 0.051955
 >> iter 44000, loss: 0.050171
 >> iter 45000, loss: 0.068055
 >> iter 46000, loss: 0.069212
 >> iter 47000, loss: 0.069960
 >> iter 48000, loss: 0.059870
 >> iter 49000, loss: 0.050906
 >> iter 50000, loss: 0.065414
   Number of active neurons: 5
 >> iter 51000, loss: 0.055958
 >> iter 52000, loss: 0.067869
 >> iter 53000, loss: 0.073971
 >> iter 54000, loss: 0.064877
 >> iter 55000, loss: 0.051763
 >> iter 56000, loss: 0.050428
 >> iter 57000, loss: 0.067936
 >> iter 58000, loss: 0.065233
 >> iter 59000, loss: 0.064955
 >> iter 60000, loss: 0.049601
   Number of active neurons: 5
 >> iter 61000, loss: 0.059592
 >> iter 62000, loss: 0.059040
 >> iter 63000, loss: 0.072776
 >> iter 64000, loss: 0.056730
 >> iter 65000, loss: 0.077588
 >> iter 66000, loss: 0.055815
 >> iter 67000, loss: 0.067952
 >> iter 68000, loss: 0.062683
 >> iter 69000, loss: 0.068003
 >> iter 70000, loss: 0.055946
   Number of active neurons: 5
 >> iter 71000, loss: 0.048332
 >> iter 72000, loss: 0.047542
 >> iter 73000, loss: 0.059478
 >> iter 74000, loss: 0.077217
 >> iter 75000, loss: 0.057336
 >> iter 76000, loss: 0.060303
 >> iter 77000, loss: 0.053317
 >> iter 78000, loss: 0.051284
 >> iter 79000, loss: 0.049392
 >> iter 80000, loss: 0.047370
   Number of active neurons: 5
 >> iter 81000, loss: 0.043489
 >> iter 82000, loss: 0.076711
 >> iter 83000, loss: 0.057334
 >> iter 84000, loss: 0.046568
 >> iter 85000, loss: 0.042385
 >> iter 86000, loss: 0.048230
 >> iter 87000, loss: 0.051942
 >> iter 88000, loss: 0.055011
 >> iter 89000, loss: 0.046871
 >> iter 90000, loss: 0.042515
   Number of active neurons: 5
 >> iter 91000, loss: 0.056810
 >> iter 92000, loss: 0.038224
 >> iter 93000, loss: 0.045146
 >> iter 94000, loss: 0.054312
 >> iter 95000, loss: 0.054628
 >> iter 96000, loss: 0.078322
 >> iter 97000, loss: 0.056999
 >> iter 98000, loss: 0.060161
 >> iter 99000, loss: 0.060700
 >> iter 100000, loss: 0.045541
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 11.391086
 >> iter 2000, loss: 4.528021
 >> iter 3000, loss: 1.828028
 >> iter 4000, loss: 0.779803
 >> iter 5000, loss: 0.393603
 >> iter 6000, loss: 0.232926
 >> iter 7000, loss: 0.168165
 >> iter 8000, loss: 0.128328
 >> iter 9000, loss: 0.105866
 >> iter 10000, loss: 0.105315
   Number of active neurons: 11
 >> iter 11000, loss: 0.103794
 >> iter 12000, loss: 0.106952
 >> iter 13000, loss: 0.118935
 >> iter 14000, loss: 0.115284
 >> iter 15000, loss: 0.110140
 >> iter 16000, loss: 0.090351
 >> iter 17000, loss: 0.074568
 >> iter 18000, loss: 0.086664
 >> iter 19000, loss: 0.081734
 >> iter 20000, loss: 0.070540
   Number of active neurons: 9
 >> iter 21000, loss: 0.066762
 >> iter 22000, loss: 0.068315
 >> iter 23000, loss: 0.053684
 >> iter 24000, loss: 0.053898
 >> iter 25000, loss: 0.077614
 >> iter 26000, loss: 0.062590
 >> iter 27000, loss: 0.073061
 >> iter 28000, loss: 0.058793
 >> iter 29000, loss: 0.086688
 >> iter 30000, loss: 0.071542
   Number of active neurons: 8
 >> iter 31000, loss: 0.063373
 >> iter 32000, loss: 0.058938
 >> iter 33000, loss: 0.049559
 >> iter 34000, loss: 0.047043
 >> iter 35000, loss: 0.061703
 >> iter 36000, loss: 0.075753
 >> iter 37000, loss: 0.069093
 >> iter 38000, loss: 0.045982
 >> iter 39000, loss: 0.051503
 >> iter 40000, loss: 0.059420
   Number of active neurons: 7
 >> iter 41000, loss: 0.041657
 >> iter 42000, loss: 0.044137
 >> iter 43000, loss: 0.057032
 >> iter 44000, loss: 0.081349
 >> iter 45000, loss: 0.066899
 >> iter 46000, loss: 0.057929
 >> iter 47000, loss: 0.052314
 >> iter 48000, loss: 0.056562
 >> iter 49000, loss: 0.045914
 >> iter 50000, loss: 0.033912
   Number of active neurons: 4
 >> iter 51000, loss: 0.052759
 >> iter 52000, loss: 0.059759
 >> iter 53000, loss: 0.080806
 >> iter 54000, loss: 0.075589
 >> iter 55000, loss: 0.057283
 >> iter 56000, loss: 0.054197
 >> iter 57000, loss: 0.046044
 >> iter 58000, loss: 0.075374
 >> iter 59000, loss: 0.062885
 >> iter 60000, loss: 0.047185
   Number of active neurons: 4
 >> iter 61000, loss: 0.054007
 >> iter 62000, loss: 0.059263
 >> iter 63000, loss: 0.055795
 >> iter 64000, loss: 0.058190
 >> iter 65000, loss: 0.062893
 >> iter 66000, loss: 0.066134
 >> iter 67000, loss: 0.049661
 >> iter 68000, loss: 0.050250
 >> iter 69000, loss: 0.048308
 >> iter 70000, loss: 0.040038
   Number of active neurons: 3
 >> iter 71000, loss: 0.038021
 >> iter 72000, loss: 0.051510
 >> iter 73000, loss: 0.044929
 >> iter 74000, loss: 0.037229
 >> iter 75000, loss: 0.045793
 >> iter 76000, loss: 0.046801
 >> iter 77000, loss: 0.040597
 >> iter 78000, loss: 0.056710
 >> iter 79000, loss: 0.041222
 >> iter 80000, loss: 0.044411
   Number of active neurons: 3
 >> iter 81000, loss: 0.044302
 >> iter 82000, loss: 0.039651
 >> iter 83000, loss: 0.044526
 >> iter 84000, loss: 0.041770
 >> iter 85000, loss: 0.043151
 >> iter 86000, loss: 0.040077
 >> iter 87000, loss: 0.049294
 >> iter 88000, loss: 0.036737
 >> iter 89000, loss: 0.032877
 >> iter 90000, loss: 0.048902
   Number of active neurons: 3
 >> iter 91000, loss: 0.048486
 >> iter 92000, loss: 0.047009
 >> iter 93000, loss: 0.055659
 >> iter 94000, loss: 0.062538
 >> iter 95000, loss: 0.045292
 >> iter 96000, loss: 0.042898
 >> iter 97000, loss: 0.040164
 >> iter 98000, loss: 0.036430
 >> iter 99000, loss: 0.041099
 >> iter 100000, loss: 0.035917
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.339071
 >> iter 2000, loss: 4.493215
 >> iter 3000, loss: 1.793546
 >> iter 4000, loss: 0.769413
 >> iter 5000, loss: 0.358688
 >> iter 6000, loss: 0.202716
 >> iter 7000, loss: 0.125738
 >> iter 8000, loss: 0.111909
 >> iter 9000, loss: 0.114766
 >> iter 10000, loss: 0.085677
   Number of active neurons: 9
 >> iter 11000, loss: 0.077089
 >> iter 12000, loss: 0.101455
 >> iter 13000, loss: 0.085314
 >> iter 14000, loss: 0.065676
 >> iter 15000, loss: 0.061174
 >> iter 16000, loss: 0.056860
 >> iter 17000, loss: 0.054286
 >> iter 18000, loss: 0.056248
 >> iter 19000, loss: 0.051745
 >> iter 20000, loss: 0.041949
   Number of active neurons: 5
 >> iter 21000, loss: 0.044474
 >> iter 22000, loss: 0.066889
 >> iter 23000, loss: 0.058440
 >> iter 24000, loss: 0.042652
 >> iter 25000, loss: 0.048593
 >> iter 26000, loss: 0.036872
 >> iter 27000, loss: 0.058063
 >> iter 28000, loss: 0.060221
 >> iter 29000, loss: 0.042410
 >> iter 30000, loss: 0.054842
   Number of active neurons: 5
 >> iter 31000, loss: 0.065525
 >> iter 32000, loss: 0.060655
 >> iter 33000, loss: 0.071902
 >> iter 34000, loss: 0.066949
 >> iter 35000, loss: 0.046325
 >> iter 36000, loss: 0.049799
 >> iter 37000, loss: 0.039633
 >> iter 38000, loss: 0.037717
 >> iter 39000, loss: 0.044597
 >> iter 40000, loss: 0.053131
   Number of active neurons: 3
 >> iter 41000, loss: 0.058617
 >> iter 42000, loss: 0.051410
 >> iter 43000, loss: 0.038993
 >> iter 44000, loss: 0.058913
 >> iter 45000, loss: 0.053988
 >> iter 46000, loss: 0.054149
 >> iter 47000, loss: 0.046386
 >> iter 48000, loss: 0.046186
 >> iter 49000, loss: 0.041330
 >> iter 50000, loss: 0.058021
   Number of active neurons: 3
 >> iter 51000, loss: 0.050632
 >> iter 52000, loss: 0.048244
 >> iter 53000, loss: 0.042378
 >> iter 54000, loss: 0.039212
 >> iter 55000, loss: 0.062236
 >> iter 56000, loss: 0.041182
 >> iter 57000, loss: 0.063576
 >> iter 58000, loss: 0.061879
 >> iter 59000, loss: 0.049809
 >> iter 60000, loss: 0.044171
   Number of active neurons: 2
 >> iter 61000, loss: 0.053473
 >> iter 62000, loss: 0.037601
 >> iter 63000, loss: 0.054733
 >> iter 64000, loss: 0.043862
 >> iter 65000, loss: 0.047020
 >> iter 66000, loss: 0.046844
 >> iter 67000, loss: 0.041560
 >> iter 68000, loss: 0.031291
 >> iter 69000, loss: 0.033220
 >> iter 70000, loss: 0.038172
   Number of active neurons: 2
 >> iter 71000, loss: 0.043987
 >> iter 72000, loss: 0.032635
 >> iter 73000, loss: 0.046256
 >> iter 74000, loss: 0.049736
 >> iter 75000, loss: 0.031419
 >> iter 76000, loss: 0.033094
 >> iter 77000, loss: 0.032699
 >> iter 78000, loss: 0.049523
 >> iter 79000, loss: 0.040912
 >> iter 80000, loss: 0.041054
   Number of active neurons: 2
 >> iter 81000, loss: 0.048131
 >> iter 82000, loss: 0.035987
 >> iter 83000, loss: 0.051157
 >> iter 84000, loss: 0.053444
 >> iter 85000, loss: 0.048491
 >> iter 86000, loss: 0.068955
 >> iter 87000, loss: 0.048605
 >> iter 88000, loss: 0.040567
 >> iter 89000, loss: 0.044303
 >> iter 90000, loss: 0.048562
   Number of active neurons: 2
 >> iter 91000, loss: 0.043651
 >> iter 92000, loss: 0.054754
 >> iter 93000, loss: 0.048630
 >> iter 94000, loss: 0.033070
 >> iter 95000, loss: 0.028674
 >> iter 96000, loss: 0.048072
 >> iter 97000, loss: 0.039651
 >> iter 98000, loss: 0.038773
 >> iter 99000, loss: 0.039707
 >> iter 100000, loss: 0.035271
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.342574
 >> iter 2000, loss: 4.492399
 >> iter 3000, loss: 1.818962
 >> iter 4000, loss: 0.781821
 >> iter 5000, loss: 0.391048
 >> iter 6000, loss: 0.217360
 >> iter 7000, loss: 0.129984
 >> iter 8000, loss: 0.096920
 >> iter 9000, loss: 0.095286
 >> iter 10000, loss: 0.082627
   Number of active neurons: 10
 >> iter 11000, loss: 0.079158
 >> iter 12000, loss: 0.088073
 >> iter 13000, loss: 0.084499
 >> iter 14000, loss: 0.061724
 >> iter 15000, loss: 0.059621
 >> iter 16000, loss: 0.050305
 >> iter 17000, loss: 0.068106
 >> iter 18000, loss: 0.074511
 >> iter 19000, loss: 0.078987
 >> iter 20000, loss: 0.053807
   Number of active neurons: 6
 >> iter 21000, loss: 0.042949
 >> iter 22000, loss: 0.058929
 >> iter 23000, loss: 0.075574
 >> iter 24000, loss: 0.061984
 >> iter 25000, loss: 0.058503
 >> iter 26000, loss: 0.065377
 >> iter 27000, loss: 0.059506
 >> iter 28000, loss: 0.041172
 >> iter 29000, loss: 0.040347
 >> iter 30000, loss: 0.057411
   Number of active neurons: 6
 >> iter 31000, loss: 0.055780
 >> iter 32000, loss: 0.067869
 >> iter 33000, loss: 0.048937
 >> iter 34000, loss: 0.069747
 >> iter 35000, loss: 0.059340
 >> iter 36000, loss: 0.046960
 >> iter 37000, loss: 0.046616
 >> iter 38000, loss: 0.056056
 >> iter 39000, loss: 0.051185
 >> iter 40000, loss: 0.062542
   Number of active neurons: 6
 >> iter 41000, loss: 0.059873
 >> iter 42000, loss: 0.065141
 >> iter 43000, loss: 0.066883
 >> iter 44000, loss: 0.048880
 >> iter 45000, loss: 0.067564
 >> iter 46000, loss: 0.051007
 >> iter 47000, loss: 0.057497
 >> iter 48000, loss: 0.050478
 >> iter 49000, loss: 0.046058
 >> iter 50000, loss: 0.061151
   Number of active neurons: 6
 >> iter 51000, loss: 0.057532
 >> iter 52000, loss: 0.048852
 >> iter 53000, loss: 0.058539
 >> iter 54000, loss: 0.055494
 >> iter 55000, loss: 0.049924
 >> iter 56000, loss: 0.050879
 >> iter 57000, loss: 0.074454
 >> iter 58000, loss: 0.063969
 >> iter 59000, loss: 0.050825
 >> iter 60000, loss: 0.053872
   Number of active neurons: 5
 >> iter 61000, loss: 0.049914
 >> iter 62000, loss: 0.040306
 >> iter 63000, loss: 0.043066
 >> iter 64000, loss: 0.045043
 >> iter 65000, loss: 0.048858
 >> iter 66000, loss: 0.054894
 >> iter 67000, loss: 0.052680
 >> iter 68000, loss: 0.049075
 >> iter 69000, loss: 0.048524
 >> iter 70000, loss: 0.051752
   Number of active neurons: 4
 >> iter 71000, loss: 0.049894
 >> iter 72000, loss: 0.038795
 >> iter 73000, loss: 0.046827
 >> iter 74000, loss: 0.044396
 >> iter 75000, loss: 0.041597
 >> iter 76000, loss: 0.037431
 >> iter 77000, loss: 0.046787
 >> iter 78000, loss: 0.048638
 >> iter 79000, loss: 0.057009
 >> iter 80000, loss: 0.050306
   Number of active neurons: 4
 >> iter 81000, loss: 0.055477
 >> iter 82000, loss: 0.039343
 >> iter 83000, loss: 0.043611
 >> iter 84000, loss: 0.036916
 >> iter 85000, loss: 0.043711
 >> iter 86000, loss: 0.044336
 >> iter 87000, loss: 0.047314
 >> iter 88000, loss: 0.049148
 >> iter 89000, loss: 0.040150
 >> iter 90000, loss: 0.033905
   Number of active neurons: 4
 >> iter 91000, loss: 0.043327
 >> iter 92000, loss: 0.037471
 >> iter 93000, loss: 0.030424
 >> iter 94000, loss: 0.031778
 >> iter 95000, loss: 0.052987
 >> iter 96000, loss: 0.044345
 >> iter 97000, loss: 0.043877
 >> iter 98000, loss: 0.054333
 >> iter 99000, loss: 0.071643
 >> iter 100000, loss: 0.043328
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455179
   Number of active neurons: 0
 >> iter 1000, loss: 11.298985
 >> iter 2000, loss: 4.485382
 >> iter 3000, loss: 1.774407
 >> iter 4000, loss: 0.737070
 >> iter 5000, loss: 0.351203
 >> iter 6000, loss: 0.209694
 >> iter 7000, loss: 0.136977
 >> iter 8000, loss: 0.105163
 >> iter 9000, loss: 0.092889
 >> iter 10000, loss: 0.063225
   Number of active neurons: 9
 >> iter 11000, loss: 0.064691
 >> iter 12000, loss: 0.084114
 >> iter 13000, loss: 0.056534
 >> iter 14000, loss: 0.069049
 >> iter 15000, loss: 0.060828
 >> iter 16000, loss: 0.061229
 >> iter 17000, loss: 0.080584
 >> iter 18000, loss: 0.057725
 >> iter 19000, loss: 0.074030
 >> iter 20000, loss: 0.061200
   Number of active neurons: 7
 >> iter 21000, loss: 0.076828
 >> iter 22000, loss: 0.062253
 >> iter 23000, loss: 0.048845
 >> iter 24000, loss: 0.060355
 >> iter 25000, loss: 0.050807
 >> iter 26000, loss: 0.046667
 >> iter 27000, loss: 0.059770
 >> iter 28000, loss: 0.078700
 >> iter 29000, loss: 0.081890
 >> iter 30000, loss: 0.064185
   Number of active neurons: 6
 >> iter 31000, loss: 0.063380
 >> iter 32000, loss: 0.051923
 >> iter 33000, loss: 0.059796
 >> iter 34000, loss: 0.066427
 >> iter 35000, loss: 0.060135
 >> iter 36000, loss: 0.067301
 >> iter 37000, loss: 0.058504
 >> iter 38000, loss: 0.056974
 >> iter 39000, loss: 0.045406
 >> iter 40000, loss: 0.049046
   Number of active neurons: 6
 >> iter 41000, loss: 0.037489
 >> iter 42000, loss: 0.048574
 >> iter 43000, loss: 0.045536
 >> iter 44000, loss: 0.070483
 >> iter 45000, loss: 0.055456
 >> iter 46000, loss: 0.057879
 >> iter 47000, loss: 0.056053
 >> iter 48000, loss: 0.044961
 >> iter 49000, loss: 0.056204
 >> iter 50000, loss: 0.054182
   Number of active neurons: 4
 >> iter 51000, loss: 0.050498
 >> iter 52000, loss: 0.054236
 >> iter 53000, loss: 0.043522
 >> iter 54000, loss: 0.033349
 >> iter 55000, loss: 0.049799
 >> iter 56000, loss: 0.052164
 >> iter 57000, loss: 0.045747
 >> iter 58000, loss: 0.046963
 >> iter 59000, loss: 0.041715
 >> iter 60000, loss: 0.045692
   Number of active neurons: 4
 >> iter 61000, loss: 0.048808
 >> iter 62000, loss: 0.044391
 >> iter 63000, loss: 0.049334
 >> iter 64000, loss: 0.043966
 >> iter 65000, loss: 0.034755
 >> iter 66000, loss: 0.035022
 >> iter 67000, loss: 0.037556
 >> iter 68000, loss: 0.046419
 >> iter 69000, loss: 0.060827
 >> iter 70000, loss: 0.056678
   Number of active neurons: 4
 >> iter 71000, loss: 0.047516
 >> iter 72000, loss: 0.040969
 >> iter 73000, loss: 0.044861
 >> iter 74000, loss: 0.037606
 >> iter 75000, loss: 0.034390
 >> iter 76000, loss: 0.047220
 >> iter 77000, loss: 0.038793
 >> iter 78000, loss: 0.035231
 >> iter 79000, loss: 0.070662
 >> iter 80000, loss: 0.053210
   Number of active neurons: 4
 >> iter 81000, loss: 0.054811
 >> iter 82000, loss: 0.049875
 >> iter 83000, loss: 0.046094
 >> iter 84000, loss: 0.067013
 >> iter 85000, loss: 0.086900
 >> iter 86000, loss: 0.059960
 >> iter 87000, loss: 0.052155
 >> iter 88000, loss: 0.043937
 >> iter 89000, loss: 0.044405
 >> iter 90000, loss: 0.035062
   Number of active neurons: 3
 >> iter 91000, loss: 0.042406
 >> iter 92000, loss: 0.044658
 >> iter 93000, loss: 0.047469
 >> iter 94000, loss: 0.045017
 >> iter 95000, loss: 0.038965
 >> iter 96000, loss: 0.028652
 >> iter 97000, loss: 0.040822
 >> iter 98000, loss: 0.045101
 >> iter 99000, loss: 0.037524
 >> iter 100000, loss: 0.028150
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.367966
 >> iter 2000, loss: 4.517094
 >> iter 3000, loss: 1.817919
 >> iter 4000, loss: 0.778562
 >> iter 5000, loss: 0.366086
 >> iter 6000, loss: 0.202763
 >> iter 7000, loss: 0.120224
 >> iter 8000, loss: 0.118031
 >> iter 9000, loss: 0.099847
 >> iter 10000, loss: 0.103868
   Number of active neurons: 9
 >> iter 11000, loss: 0.077355
 >> iter 12000, loss: 0.065429
 >> iter 13000, loss: 0.080646
 >> iter 14000, loss: 0.077729
 >> iter 15000, loss: 0.070721
 >> iter 16000, loss: 0.054538
 >> iter 17000, loss: 0.051087
 >> iter 18000, loss: 0.069187
 >> iter 19000, loss: 0.070876
 >> iter 20000, loss: 0.074923
   Number of active neurons: 7
 >> iter 21000, loss: 0.082544
 >> iter 22000, loss: 0.082981
 >> iter 23000, loss: 0.058795
 >> iter 24000, loss: 0.040604
 >> iter 25000, loss: 0.055453
 >> iter 26000, loss: 0.078668
 >> iter 27000, loss: 0.078198
 >> iter 28000, loss: 0.055983
 >> iter 29000, loss: 0.051467
 >> iter 30000, loss: 0.051746
   Number of active neurons: 5
 >> iter 31000, loss: 0.078408
 >> iter 32000, loss: 0.061374
 >> iter 33000, loss: 0.048500
 >> iter 34000, loss: 0.054364
 >> iter 35000, loss: 0.049652
 >> iter 36000, loss: 0.043028
 >> iter 37000, loss: 0.044159
 >> iter 38000, loss: 0.045445
 >> iter 39000, loss: 0.038390
 >> iter 40000, loss: 0.036119
   Number of active neurons: 5
 >> iter 41000, loss: 0.047734
 >> iter 42000, loss: 0.049697
 >> iter 43000, loss: 0.063619
 >> iter 44000, loss: 0.053908
 >> iter 45000, loss: 0.048881
 >> iter 46000, loss: 0.056220
 >> iter 47000, loss: 0.054615
 >> iter 48000, loss: 0.059738
 >> iter 49000, loss: 0.056470
 >> iter 50000, loss: 0.041691
   Number of active neurons: 4
 >> iter 51000, loss: 0.043969
 >> iter 52000, loss: 0.061779
 >> iter 53000, loss: 0.049440
 >> iter 54000, loss: 0.058721
 >> iter 55000, loss: 0.050296
 >> iter 56000, loss: 0.040617
 >> iter 57000, loss: 0.057472
 >> iter 58000, loss: 0.064648
 >> iter 59000, loss: 0.061979
 >> iter 60000, loss: 0.047262
   Number of active neurons: 3
 >> iter 61000, loss: 0.040643
 >> iter 62000, loss: 0.064622
 >> iter 63000, loss: 0.056636
 >> iter 64000, loss: 0.041994
 >> iter 65000, loss: 0.050990
 >> iter 66000, loss: 0.047259
 >> iter 67000, loss: 0.043392
 >> iter 68000, loss: 0.048789
 >> iter 69000, loss: 0.035152
 >> iter 70000, loss: 0.049946
   Number of active neurons: 2
 >> iter 71000, loss: 0.045588
 >> iter 72000, loss: 0.035868
 >> iter 73000, loss: 0.051036
 >> iter 74000, loss: 0.078342
 >> iter 75000, loss: 0.054882
 >> iter 76000, loss: 0.051933
 >> iter 77000, loss: 0.055009
 >> iter 78000, loss: 0.054042
 >> iter 79000, loss: 0.077155
 >> iter 80000, loss: 0.049633
   Number of active neurons: 2
 >> iter 81000, loss: 0.057903
 >> iter 82000, loss: 0.040486
 >> iter 83000, loss: 0.033000
 >> iter 84000, loss: 0.053148
 >> iter 85000, loss: 0.048355
 >> iter 86000, loss: 0.048594
 >> iter 87000, loss: 0.046881
 >> iter 88000, loss: 0.039841
 >> iter 89000, loss: 0.046477
 >> iter 90000, loss: 0.048101
   Number of active neurons: 2
 >> iter 91000, loss: 0.059990
 >> iter 92000, loss: 0.051985
 >> iter 93000, loss: 0.043008
 >> iter 94000, loss: 0.050907
 >> iter 95000, loss: 0.044080
 >> iter 96000, loss: 0.056657
 >> iter 97000, loss: 0.037284
 >> iter 98000, loss: 0.038176
 >> iter 99000, loss: 0.043611
 >> iter 100000, loss: 0.056505
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 11.364203
 >> iter 2000, loss: 4.491822
 >> iter 3000, loss: 1.818837
 >> iter 4000, loss: 0.752920
 >> iter 5000, loss: 0.345833
 >> iter 6000, loss: 0.185586
 >> iter 7000, loss: 0.098075
 >> iter 8000, loss: 0.072251
 >> iter 9000, loss: 0.062976
 >> iter 10000, loss: 0.065933
   Number of active neurons: 8
 >> iter 11000, loss: 0.066416
 >> iter 12000, loss: 0.072625
 >> iter 13000, loss: 0.056204
 >> iter 14000, loss: 0.055433
 >> iter 15000, loss: 0.064159
 >> iter 16000, loss: 0.049407
 >> iter 17000, loss: 0.046989
 >> iter 18000, loss: 0.060638
 >> iter 19000, loss: 0.056261
 >> iter 20000, loss: 0.044541
   Number of active neurons: 6
 >> iter 21000, loss: 0.061608
 >> iter 22000, loss: 0.047480
 >> iter 23000, loss: 0.051804
 >> iter 24000, loss: 0.045380
 >> iter 25000, loss: 0.058587
 >> iter 26000, loss: 0.061322
 >> iter 27000, loss: 0.043500
 >> iter 28000, loss: 0.057555
 >> iter 29000, loss: 0.063095
 >> iter 30000, loss: 0.045394
   Number of active neurons: 4
 >> iter 31000, loss: 0.038853
 >> iter 32000, loss: 0.052412
 >> iter 33000, loss: 0.049781
 >> iter 34000, loss: 0.067222
 >> iter 35000, loss: 0.050447
 >> iter 36000, loss: 0.055040
 >> iter 37000, loss: 0.044049
 >> iter 38000, loss: 0.046792
 >> iter 39000, loss: 0.088356
 >> iter 40000, loss: 0.078781
   Number of active neurons: 4
 >> iter 41000, loss: 0.059394
 >> iter 42000, loss: 0.047331
 >> iter 43000, loss: 0.046601
 >> iter 44000, loss: 0.058489
 >> iter 45000, loss: 0.066206
 >> iter 46000, loss: 0.066508
 >> iter 47000, loss: 0.052612
 >> iter 48000, loss: 0.047554
 >> iter 49000, loss: 0.050401
 >> iter 50000, loss: 0.050761
   Number of active neurons: 4
 >> iter 51000, loss: 0.054758
 >> iter 52000, loss: 0.051817
 >> iter 53000, loss: 0.043251
 >> iter 54000, loss: 0.049372
 >> iter 55000, loss: 0.044944
 >> iter 56000, loss: 0.046756
 >> iter 57000, loss: 0.042655
 >> iter 58000, loss: 0.041906
 >> iter 59000, loss: 0.038409
 >> iter 60000, loss: 0.061375
   Number of active neurons: 4
 >> iter 61000, loss: 0.050717
 >> iter 62000, loss: 0.066106
 >> iter 63000, loss: 0.046937
 >> iter 64000, loss: 0.038720
 >> iter 65000, loss: 0.051664
 >> iter 66000, loss: 0.053414
 >> iter 67000, loss: 0.037062
 >> iter 68000, loss: 0.050136
 >> iter 69000, loss: 0.050095
 >> iter 70000, loss: 0.038662
   Number of active neurons: 4
 >> iter 71000, loss: 0.089584
 >> iter 72000, loss: 0.062980
 >> iter 73000, loss: 0.047480
 >> iter 74000, loss: 0.054908
 >> iter 75000, loss: 0.061932
 >> iter 76000, loss: 0.051272
 >> iter 77000, loss: 0.048524
 >> iter 78000, loss: 0.044509
 >> iter 79000, loss: 0.036612
 >> iter 80000, loss: 0.053031
   Number of active neurons: 3
 >> iter 81000, loss: 0.035346
 >> iter 82000, loss: 0.056057
 >> iter 83000, loss: 0.045241
 >> iter 84000, loss: 0.047548
 >> iter 85000, loss: 0.035604
 >> iter 86000, loss: 0.030933
 >> iter 87000, loss: 0.037068
 >> iter 88000, loss: 0.043045
 >> iter 89000, loss: 0.035536
 >> iter 90000, loss: 0.045409
   Number of active neurons: 3
 >> iter 91000, loss: 0.048347
 >> iter 92000, loss: 0.041086
 >> iter 93000, loss: 0.036297
 >> iter 94000, loss: 0.062946
 >> iter 95000, loss: 0.066996
 >> iter 96000, loss: 0.065299
 >> iter 97000, loss: 0.051708
 >> iter 98000, loss: 0.057100
 >> iter 99000, loss: 0.049269
 >> iter 100000, loss: 0.053208
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 11.347348
 >> iter 2000, loss: 4.495976
 >> iter 3000, loss: 1.799014
 >> iter 4000, loss: 0.774565
 >> iter 5000, loss: 0.371133
 >> iter 6000, loss: 0.219643
 >> iter 7000, loss: 0.129981
 >> iter 8000, loss: 0.112460
 >> iter 9000, loss: 0.107995
 >> iter 10000, loss: 0.081325
   Number of active neurons: 10
 >> iter 11000, loss: 0.082299
 >> iter 12000, loss: 0.079879
 >> iter 13000, loss: 0.082064
 >> iter 14000, loss: 0.077140
 >> iter 15000, loss: 0.056721
 >> iter 16000, loss: 0.060337
 >> iter 17000, loss: 0.066077
 >> iter 18000, loss: 0.064045
 >> iter 19000, loss: 0.060363
 >> iter 20000, loss: 0.079222
   Number of active neurons: 7
 >> iter 21000, loss: 0.082631
 >> iter 22000, loss: 0.064939
 >> iter 23000, loss: 0.076905
 >> iter 24000, loss: 0.072501
 >> iter 25000, loss: 0.068602
 >> iter 26000, loss: 0.064529
 >> iter 27000, loss: 0.044149
 >> iter 28000, loss: 0.047319
 >> iter 29000, loss: 0.080218
 >> iter 30000, loss: 0.052350
   Number of active neurons: 6
 >> iter 31000, loss: 0.057407
 >> iter 32000, loss: 0.068025
 >> iter 33000, loss: 0.068363
 >> iter 34000, loss: 0.065339
 >> iter 35000, loss: 0.055399
 >> iter 36000, loss: 0.044325
 >> iter 37000, loss: 0.049290
 >> iter 38000, loss: 0.045956
 >> iter 39000, loss: 0.033015
 >> iter 40000, loss: 0.028898
   Number of active neurons: 4
 >> iter 41000, loss: 0.031242
 >> iter 42000, loss: 0.064064
 >> iter 43000, loss: 0.059004
 >> iter 44000, loss: 0.049907
 >> iter 45000, loss: 0.057577
 >> iter 46000, loss: 0.048291
 >> iter 47000, loss: 0.065720
 >> iter 48000, loss: 0.048877
 >> iter 49000, loss: 0.046093
 >> iter 50000, loss: 0.072764
   Number of active neurons: 4
 >> iter 51000, loss: 0.047750
 >> iter 52000, loss: 0.045033
 >> iter 53000, loss: 0.047164
 >> iter 54000, loss: 0.068598
 >> iter 55000, loss: 0.047059
 >> iter 56000, loss: 0.050884
 >> iter 57000, loss: 0.054654
 >> iter 58000, loss: 0.048043
 >> iter 59000, loss: 0.045105
 >> iter 60000, loss: 0.036026
   Number of active neurons: 4
 >> iter 61000, loss: 0.051413
 >> iter 62000, loss: 0.053761
 >> iter 63000, loss: 0.040088
 >> iter 64000, loss: 0.035465
 >> iter 65000, loss: 0.039194
 >> iter 66000, loss: 0.035884
 >> iter 67000, loss: 0.040260
 >> iter 68000, loss: 0.044115
 >> iter 69000, loss: 0.033235
 >> iter 70000, loss: 0.027588
   Number of active neurons: 3
 >> iter 71000, loss: 0.039641
 >> iter 72000, loss: 0.030272
 >> iter 73000, loss: 0.052759
 >> iter 74000, loss: 0.048109
 >> iter 75000, loss: 0.043076
 >> iter 76000, loss: 0.050373
 >> iter 77000, loss: 0.060557
 >> iter 78000, loss: 0.041230
 >> iter 79000, loss: 0.042891
 >> iter 80000, loss: 0.043857
   Number of active neurons: 3
 >> iter 81000, loss: 0.037554
 >> iter 82000, loss: 0.061099
 >> iter 83000, loss: 0.034821
 >> iter 84000, loss: 0.034524
 >> iter 85000, loss: 0.078146
 >> iter 86000, loss: 0.047614
 >> iter 87000, loss: 0.050414
 >> iter 88000, loss: 0.038889
 >> iter 89000, loss: 0.028652
 >> iter 90000, loss: 0.033499
   Number of active neurons: 3
 >> iter 91000, loss: 0.051373
 >> iter 92000, loss: 0.047192
 >> iter 93000, loss: 0.044884
 >> iter 94000, loss: 0.035895
 >> iter 95000, loss: 0.051460
 >> iter 96000, loss: 0.044516
 >> iter 97000, loss: 0.034893
 >> iter 98000, loss: 0.037836
 >> iter 99000, loss: 0.047167
 >> iter 100000, loss: 0.055427
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.297258
 >> iter 2000, loss: 4.485082
 >> iter 3000, loss: 1.807498
 >> iter 4000, loss: 0.762682
 >> iter 5000, loss: 0.368372
 >> iter 6000, loss: 0.215794
 >> iter 7000, loss: 0.163302
 >> iter 8000, loss: 0.112363
 >> iter 9000, loss: 0.082040
 >> iter 10000, loss: 0.088376
   Number of active neurons: 9
 >> iter 11000, loss: 0.095431
 >> iter 12000, loss: 0.090468
 >> iter 13000, loss: 0.103375
 >> iter 14000, loss: 0.078987
 >> iter 15000, loss: 0.067121
 >> iter 16000, loss: 0.071038
 >> iter 17000, loss: 0.080535
 >> iter 18000, loss: 0.093364
 >> iter 19000, loss: 0.074438
 >> iter 20000, loss: 0.052317
   Number of active neurons: 7
 >> iter 21000, loss: 0.049590
 >> iter 22000, loss: 0.057541
 >> iter 23000, loss: 0.054139
 >> iter 24000, loss: 0.040840
 >> iter 25000, loss: 0.051845
 >> iter 26000, loss: 0.064303
 >> iter 27000, loss: 0.063902
 >> iter 28000, loss: 0.066531
 >> iter 29000, loss: 0.079531
 >> iter 30000, loss: 0.057546
   Number of active neurons: 5
 >> iter 31000, loss: 0.073020
 >> iter 32000, loss: 0.050763
 >> iter 33000, loss: 0.058606
 >> iter 34000, loss: 0.040772
 >> iter 35000, loss: 0.059036
 >> iter 36000, loss: 0.054388
 >> iter 37000, loss: 0.045963
 >> iter 38000, loss: 0.043172
 >> iter 39000, loss: 0.062848
 >> iter 40000, loss: 0.042595
   Number of active neurons: 5
 >> iter 41000, loss: 0.049196
 >> iter 42000, loss: 0.058711
 >> iter 43000, loss: 0.053008
 >> iter 44000, loss: 0.054974
 >> iter 45000, loss: 0.045793
 >> iter 46000, loss: 0.045764
 >> iter 47000, loss: 0.049697
 >> iter 48000, loss: 0.039240
 >> iter 49000, loss: 0.048396
 >> iter 50000, loss: 0.049264
   Number of active neurons: 3
 >> iter 51000, loss: 0.052925
 >> iter 52000, loss: 0.044264
 >> iter 53000, loss: 0.044427
 >> iter 54000, loss: 0.048870
 >> iter 55000, loss: 0.058931
 >> iter 56000, loss: 0.048971
 >> iter 57000, loss: 0.050922
 >> iter 58000, loss: 0.053316
 >> iter 59000, loss: 0.051169
 >> iter 60000, loss: 0.072183
   Number of active neurons: 2
 >> iter 61000, loss: 0.048627
 >> iter 62000, loss: 0.035858
 >> iter 63000, loss: 0.042936
 >> iter 64000, loss: 0.054799
 >> iter 65000, loss: 0.039136
 >> iter 66000, loss: 0.053961
 >> iter 67000, loss: 0.052496
 >> iter 68000, loss: 0.082012
 >> iter 69000, loss: 0.064055
 >> iter 70000, loss: 0.051865
   Number of active neurons: 2
 >> iter 71000, loss: 0.040794
 >> iter 72000, loss: 0.029486
 >> iter 73000, loss: 0.056718
 >> iter 74000, loss: 0.054324
 >> iter 75000, loss: 0.066355
 >> iter 76000, loss: 0.057373
 >> iter 77000, loss: 0.056861
 >> iter 78000, loss: 0.041691
 >> iter 79000, loss: 0.048753
 >> iter 80000, loss: 0.042824
   Number of active neurons: 2
 >> iter 81000, loss: 0.053504
 >> iter 82000, loss: 0.055365
 >> iter 83000, loss: 0.049188
 >> iter 84000, loss: 0.039633
 >> iter 85000, loss: 0.034394
 >> iter 86000, loss: 0.035218
 >> iter 87000, loss: 0.071663
 >> iter 88000, loss: 0.048560
 >> iter 89000, loss: 0.043144
 >> iter 90000, loss: 0.040416
   Number of active neurons: 2
 >> iter 91000, loss: 0.038510
 >> iter 92000, loss: 0.044437
 >> iter 93000, loss: 0.046646
 >> iter 94000, loss: 0.043023
 >> iter 95000, loss: 0.044436
 >> iter 96000, loss: 0.066601
 >> iter 97000, loss: 0.052570
 >> iter 98000, loss: 0.056690
 >> iter 99000, loss: 0.048498
 >> iter 100000, loss: 0.033962
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.264735
 >> iter 2000, loss: 4.444990
 >> iter 3000, loss: 1.736541
 >> iter 4000, loss: 0.739022
 >> iter 5000, loss: 0.348023
 >> iter 6000, loss: 0.179848
 >> iter 7000, loss: 0.143507
 >> iter 8000, loss: 0.110258
 >> iter 9000, loss: 0.086525
 >> iter 10000, loss: 0.086957
   Number of active neurons: 9
 >> iter 11000, loss: 0.074253
 >> iter 12000, loss: 0.077658
 >> iter 13000, loss: 0.063617
 >> iter 14000, loss: 0.087589
 >> iter 15000, loss: 0.073266
 >> iter 16000, loss: 0.064121
 >> iter 17000, loss: 0.077447
 >> iter 18000, loss: 0.070785
 >> iter 19000, loss: 0.064866
 >> iter 20000, loss: 0.048255
   Number of active neurons: 5
 >> iter 21000, loss: 0.048268
 >> iter 22000, loss: 0.068554
 >> iter 23000, loss: 0.067126
 >> iter 24000, loss: 0.059925
 >> iter 25000, loss: 0.069916
 >> iter 26000, loss: 0.052400
 >> iter 27000, loss: 0.047241
 >> iter 28000, loss: 0.037308
 >> iter 29000, loss: 0.046023
 >> iter 30000, loss: 0.042374
   Number of active neurons: 3
 >> iter 31000, loss: 0.064827
 >> iter 32000, loss: 0.048971
 >> iter 33000, loss: 0.049509
 >> iter 34000, loss: 0.046385
 >> iter 35000, loss: 0.039836
 >> iter 36000, loss: 0.050086
 >> iter 37000, loss: 0.047240
 >> iter 38000, loss: 0.039742
 >> iter 39000, loss: 0.055799
 >> iter 40000, loss: 0.056176
   Number of active neurons: 3
 >> iter 41000, loss: 0.049933
 >> iter 42000, loss: 0.052504
 >> iter 43000, loss: 0.048117
 >> iter 44000, loss: 0.059066
 >> iter 45000, loss: 0.052874
 >> iter 46000, loss: 0.054445
 >> iter 47000, loss: 0.051165
 >> iter 48000, loss: 0.066628
 >> iter 49000, loss: 0.046668
 >> iter 50000, loss: 0.053448
   Number of active neurons: 3
 >> iter 51000, loss: 0.035870
 >> iter 52000, loss: 0.043055
 >> iter 53000, loss: 0.054809
 >> iter 54000, loss: 0.045774
 >> iter 55000, loss: 0.049079
 >> iter 56000, loss: 0.071399
 >> iter 57000, loss: 0.057860
 >> iter 58000, loss: 0.046990
 >> iter 59000, loss: 0.038163
 >> iter 60000, loss: 0.040513
   Number of active neurons: 3
 >> iter 61000, loss: 0.039576
 >> iter 62000, loss: 0.058471
 >> iter 63000, loss: 0.055083
 >> iter 64000, loss: 0.061261
 >> iter 65000, loss: 0.046313
 >> iter 66000, loss: 0.045331
 >> iter 67000, loss: 0.044944
 >> iter 68000, loss: 0.055624
 >> iter 69000, loss: 0.039416
 >> iter 70000, loss: 0.049454
   Number of active neurons: 3
 >> iter 71000, loss: 0.055435
 >> iter 72000, loss: 0.051366
 >> iter 73000, loss: 0.054200
 >> iter 74000, loss: 0.045838
 >> iter 75000, loss: 0.044275
 >> iter 76000, loss: 0.063066
 >> iter 77000, loss: 0.045298
 >> iter 78000, loss: 0.054726
 >> iter 79000, loss: 0.055341
 >> iter 80000, loss: 0.051276
   Number of active neurons: 2
 >> iter 81000, loss: 0.047717
 >> iter 82000, loss: 0.052906
 >> iter 83000, loss: 0.035249
 >> iter 84000, loss: 0.038075
 >> iter 85000, loss: 0.035007
 >> iter 86000, loss: 0.038608
 >> iter 87000, loss: 0.041785
 >> iter 88000, loss: 0.033443
 >> iter 89000, loss: 0.037952
 >> iter 90000, loss: 0.038651
   Number of active neurons: 2
 >> iter 91000, loss: 0.037886
 >> iter 92000, loss: 0.039242
 >> iter 93000, loss: 0.045976
 >> iter 94000, loss: 0.034497
 >> iter 95000, loss: 0.043056
 >> iter 96000, loss: 0.035497
 >> iter 97000, loss: 0.032998
 >> iter 98000, loss: 0.052751
 >> iter 99000, loss: 0.047049
 >> iter 100000, loss: 0.048340
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.357334
 >> iter 2000, loss: 4.446927
 >> iter 3000, loss: 1.752011
 >> iter 4000, loss: 0.751151
 >> iter 5000, loss: 0.361404
 >> iter 6000, loss: 0.193994
 >> iter 7000, loss: 0.140384
 >> iter 8000, loss: 0.107348
 >> iter 9000, loss: 0.074920
 >> iter 10000, loss: 0.084268
   Number of active neurons: 8
 >> iter 11000, loss: 0.070384
 >> iter 12000, loss: 0.077445
 >> iter 13000, loss: 0.077268
 >> iter 14000, loss: 0.058359
 >> iter 15000, loss: 0.061870
 >> iter 16000, loss: 0.056842
 >> iter 17000, loss: 0.071012
 >> iter 18000, loss: 0.060203
 >> iter 19000, loss: 0.069820
 >> iter 20000, loss: 0.067977
   Number of active neurons: 7
 >> iter 21000, loss: 0.064005
 >> iter 22000, loss: 0.049319
 >> iter 23000, loss: 0.064564
 >> iter 24000, loss: 0.084423
 >> iter 25000, loss: 0.057842
 >> iter 26000, loss: 0.060662
 >> iter 27000, loss: 0.050161
 >> iter 28000, loss: 0.056056
 >> iter 29000, loss: 0.055252
 >> iter 30000, loss: 0.050627
   Number of active neurons: 7
 >> iter 31000, loss: 0.070845
 >> iter 32000, loss: 0.047430
 >> iter 33000, loss: 0.041737
 >> iter 34000, loss: 0.046575
 >> iter 35000, loss: 0.041241
 >> iter 36000, loss: 0.059332
 >> iter 37000, loss: 0.047816
 >> iter 38000, loss: 0.044699
 >> iter 39000, loss: 0.051163
 >> iter 40000, loss: 0.078568
   Number of active neurons: 5
 >> iter 41000, loss: 0.061228
 >> iter 42000, loss: 0.051099
 >> iter 43000, loss: 0.045790
 >> iter 44000, loss: 0.044203
 >> iter 45000, loss: 0.058647
 >> iter 46000, loss: 0.039020
 >> iter 47000, loss: 0.048370
 >> iter 48000, loss: 0.052772
 >> iter 49000, loss: 0.068148
 >> iter 50000, loss: 0.060342
   Number of active neurons: 3
 >> iter 51000, loss: 0.053762
 >> iter 52000, loss: 0.045895
 >> iter 53000, loss: 0.044785
 >> iter 54000, loss: 0.052457
 >> iter 55000, loss: 0.046863
 >> iter 56000, loss: 0.047436
 >> iter 57000, loss: 0.034915
 >> iter 58000, loss: 0.054880
 >> iter 59000, loss: 0.040113
 >> iter 60000, loss: 0.039598
   Number of active neurons: 3
 >> iter 61000, loss: 0.044316
 >> iter 62000, loss: 0.051480
 >> iter 63000, loss: 0.059713
 >> iter 64000, loss: 0.038403
 >> iter 65000, loss: 0.046635
 >> iter 66000, loss: 0.054370
 >> iter 67000, loss: 0.047425
 >> iter 68000, loss: 0.060353
 >> iter 69000, loss: 0.049762
 >> iter 70000, loss: 0.044080
   Number of active neurons: 3
 >> iter 71000, loss: 0.043561
 >> iter 72000, loss: 0.042568
 >> iter 73000, loss: 0.040997
 >> iter 74000, loss: 0.032957
 >> iter 75000, loss: 0.040882
 >> iter 76000, loss: 0.044712
 >> iter 77000, loss: 0.047406
 >> iter 78000, loss: 0.058494
 >> iter 79000, loss: 0.049185
 >> iter 80000, loss: 0.057466
   Number of active neurons: 3
 >> iter 81000, loss: 0.053013
 >> iter 82000, loss: 0.055604
 >> iter 83000, loss: 0.071860
 >> iter 84000, loss: 0.050237
 >> iter 85000, loss: 0.059525
 >> iter 86000, loss: 0.062670
 >> iter 87000, loss: 0.040582
 >> iter 88000, loss: 0.047564
 >> iter 89000, loss: 0.051740
 >> iter 90000, loss: 0.046597
   Number of active neurons: 3
 >> iter 91000, loss: 0.040037
 >> iter 92000, loss: 0.044293
 >> iter 93000, loss: 0.045871
 >> iter 94000, loss: 0.049055
 >> iter 95000, loss: 0.047126
 >> iter 96000, loss: 0.039094
 >> iter 97000, loss: 0.038327
 >> iter 98000, loss: 0.042323
 >> iter 99000, loss: 0.048060
 >> iter 100000, loss: 0.037799
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.366556
 >> iter 2000, loss: 4.492118
 >> iter 3000, loss: 1.787635
 >> iter 4000, loss: 0.760711
 >> iter 5000, loss: 0.364840
 >> iter 6000, loss: 0.197486
 >> iter 7000, loss: 0.123945
 >> iter 8000, loss: 0.091141
 >> iter 9000, loss: 0.104266
 >> iter 10000, loss: 0.075004
   Number of active neurons: 8
 >> iter 11000, loss: 0.067736
 >> iter 12000, loss: 0.061819
 >> iter 13000, loss: 0.079965
 >> iter 14000, loss: 0.072790
 >> iter 15000, loss: 0.056538
 >> iter 16000, loss: 0.078909
 >> iter 17000, loss: 0.072926
 >> iter 18000, loss: 0.065200
 >> iter 19000, loss: 0.049277
 >> iter 20000, loss: 0.041652
   Number of active neurons: 8
 >> iter 21000, loss: 0.038385
 >> iter 22000, loss: 0.052211
 >> iter 23000, loss: 0.052509
 >> iter 24000, loss: 0.052772
 >> iter 25000, loss: 0.061394
 >> iter 26000, loss: 0.046865
 >> iter 27000, loss: 0.055576
 >> iter 28000, loss: 0.059288
 >> iter 29000, loss: 0.050687
 >> iter 30000, loss: 0.049609
   Number of active neurons: 5
 >> iter 31000, loss: 0.045312
 >> iter 32000, loss: 0.051561
 >> iter 33000, loss: 0.050994
 >> iter 34000, loss: 0.053215
 >> iter 35000, loss: 0.050328
 >> iter 36000, loss: 0.037483
 >> iter 37000, loss: 0.030668
 >> iter 38000, loss: 0.037457
 >> iter 39000, loss: 0.060723
 >> iter 40000, loss: 0.054334
   Number of active neurons: 5
 >> iter 41000, loss: 0.063648
 >> iter 42000, loss: 0.041863
 >> iter 43000, loss: 0.039079
 >> iter 44000, loss: 0.037776
 >> iter 45000, loss: 0.033743
 >> iter 46000, loss: 0.026313
 >> iter 47000, loss: 0.056799
 >> iter 48000, loss: 0.045557
 >> iter 49000, loss: 0.046182
 >> iter 50000, loss: 0.054131
   Number of active neurons: 4
 >> iter 51000, loss: 0.045243
 >> iter 52000, loss: 0.053382
 >> iter 53000, loss: 0.047283
 >> iter 54000, loss: 0.046360
 >> iter 55000, loss: 0.053957
 >> iter 56000, loss: 0.054231
 >> iter 57000, loss: 0.061199
 >> iter 58000, loss: 0.042000
 >> iter 59000, loss: 0.032454
 >> iter 60000, loss: 0.035734
   Number of active neurons: 3
 >> iter 61000, loss: 0.038226
 >> iter 62000, loss: 0.055890
 >> iter 63000, loss: 0.039865
 >> iter 64000, loss: 0.049321
 >> iter 65000, loss: 0.044995
 >> iter 66000, loss: 0.036054
 >> iter 67000, loss: 0.043418
 >> iter 68000, loss: 0.052678
 >> iter 69000, loss: 0.039869
 >> iter 70000, loss: 0.040698
   Number of active neurons: 2
 >> iter 71000, loss: 0.037372
 >> iter 72000, loss: 0.037471
 >> iter 73000, loss: 0.054708
 >> iter 74000, loss: 0.050154
 >> iter 75000, loss: 0.048800
 >> iter 76000, loss: 0.051065
 >> iter 77000, loss: 0.045041
 >> iter 78000, loss: 0.050830
 >> iter 79000, loss: 0.051684
 >> iter 80000, loss: 0.076477
   Number of active neurons: 2
 >> iter 81000, loss: 0.059075
 >> iter 82000, loss: 0.046068
 >> iter 83000, loss: 0.043514
 >> iter 84000, loss: 0.043227
 >> iter 85000, loss: 0.032048
 >> iter 86000, loss: 0.036677
 >> iter 87000, loss: 0.033075
 >> iter 88000, loss: 0.042727
 >> iter 89000, loss: 0.038367
 >> iter 90000, loss: 0.058824
   Number of active neurons: 2
 >> iter 91000, loss: 0.044428
 >> iter 92000, loss: 0.054724
 >> iter 93000, loss: 0.038247
 >> iter 94000, loss: 0.058795
 >> iter 95000, loss: 0.053547
 >> iter 96000, loss: 0.038189
 >> iter 97000, loss: 0.039998
 >> iter 98000, loss: 0.030086
 >> iter 99000, loss: 0.062536
 >> iter 100000, loss: 0.049373
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 11.327425
 >> iter 2000, loss: 4.484993
 >> iter 3000, loss: 1.844061
 >> iter 4000, loss: 0.775251
 >> iter 5000, loss: 0.398070
 >> iter 6000, loss: 0.209414
 >> iter 7000, loss: 0.139224
 >> iter 8000, loss: 0.096704
 >> iter 9000, loss: 0.092456
 >> iter 10000, loss: 0.098608
   Number of active neurons: 10
 >> iter 11000, loss: 0.093053
 >> iter 12000, loss: 0.092959
 >> iter 13000, loss: 0.093256
 >> iter 14000, loss: 0.079031
 >> iter 15000, loss: 0.077180
 >> iter 16000, loss: 0.060952
 >> iter 17000, loss: 0.073881
 >> iter 18000, loss: 0.070278
 >> iter 19000, loss: 0.059351
 >> iter 20000, loss: 0.058559
   Number of active neurons: 8
 >> iter 21000, loss: 0.049955
 >> iter 22000, loss: 0.079196
 >> iter 23000, loss: 0.051007
 >> iter 24000, loss: 0.051597
 >> iter 25000, loss: 0.054279
 >> iter 26000, loss: 0.045526
 >> iter 27000, loss: 0.051818
 >> iter 28000, loss: 0.039229
 >> iter 29000, loss: 0.057393
 >> iter 30000, loss: 0.070763
   Number of active neurons: 6
 >> iter 31000, loss: 0.059669
 >> iter 32000, loss: 0.058036
 >> iter 33000, loss: 0.060651
 >> iter 34000, loss: 0.047077
 >> iter 35000, loss: 0.053579
 >> iter 36000, loss: 0.050959
 >> iter 37000, loss: 0.042033
 >> iter 38000, loss: 0.045100
 >> iter 39000, loss: 0.050752
 >> iter 40000, loss: 0.054849
   Number of active neurons: 5
 >> iter 41000, loss: 0.039805
 >> iter 42000, loss: 0.042499
 >> iter 43000, loss: 0.037204
 >> iter 44000, loss: 0.037191
 >> iter 45000, loss: 0.057622
 >> iter 46000, loss: 0.049135
 >> iter 47000, loss: 0.039104
 >> iter 48000, loss: 0.050669
 >> iter 49000, loss: 0.048475
 >> iter 50000, loss: 0.042585
   Number of active neurons: 4
 >> iter 51000, loss: 0.038934
 >> iter 52000, loss: 0.050196
 >> iter 53000, loss: 0.038374
 >> iter 54000, loss: 0.051355
 >> iter 55000, loss: 0.051972
 >> iter 56000, loss: 0.058459
 >> iter 57000, loss: 0.043972
 >> iter 58000, loss: 0.052368
 >> iter 59000, loss: 0.044574
 >> iter 60000, loss: 0.053428
   Number of active neurons: 3
 >> iter 61000, loss: 0.034732
 >> iter 62000, loss: 0.046759
 >> iter 63000, loss: 0.043792
 >> iter 64000, loss: 0.043981
 >> iter 65000, loss: 0.055810
 >> iter 66000, loss: 0.051963
 >> iter 67000, loss: 0.054336
 >> iter 68000, loss: 0.044997
 >> iter 69000, loss: 0.037491
 >> iter 70000, loss: 0.035558
   Number of active neurons: 3
 >> iter 71000, loss: 0.050555
 >> iter 72000, loss: 0.036269
 >> iter 73000, loss: 0.042606
 >> iter 74000, loss: 0.031775
 >> iter 75000, loss: 0.048163
 >> iter 76000, loss: 0.038350
 >> iter 77000, loss: 0.039093
 >> iter 78000, loss: 0.052381
 >> iter 79000, loss: 0.058037
 >> iter 80000, loss: 0.055667
   Number of active neurons: 2
 >> iter 81000, loss: 0.055747
 >> iter 82000, loss: 0.038898
 >> iter 83000, loss: 0.056740
 >> iter 84000, loss: 0.046434
 >> iter 85000, loss: 0.043863
 >> iter 86000, loss: 0.040263
 >> iter 87000, loss: 0.059659
 >> iter 88000, loss: 0.052792
 >> iter 89000, loss: 0.035404
 >> iter 90000, loss: 0.044275
   Number of active neurons: 2
 >> iter 91000, loss: 0.047429
 >> iter 92000, loss: 0.050692
 >> iter 93000, loss: 0.049772
 >> iter 94000, loss: 0.045695
 >> iter 95000, loss: 0.034561
 >> iter 96000, loss: 0.046987
 >> iter 97000, loss: 0.054189
 >> iter 98000, loss: 0.059317
 >> iter 99000, loss: 0.071998
 >> iter 100000, loss: 0.062181
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.273883
 >> iter 2000, loss: 4.476791
 >> iter 3000, loss: 1.788377
 >> iter 4000, loss: 0.774549
 >> iter 5000, loss: 0.410667
 >> iter 6000, loss: 0.229398
 >> iter 7000, loss: 0.149457
 >> iter 8000, loss: 0.114936
 >> iter 9000, loss: 0.106858
 >> iter 10000, loss: 0.086407
   Number of active neurons: 11
 >> iter 11000, loss: 0.096473
 >> iter 12000, loss: 0.120148
 >> iter 13000, loss: 0.086337
 >> iter 14000, loss: 0.066436
 >> iter 15000, loss: 0.096095
 >> iter 16000, loss: 0.096301
 >> iter 17000, loss: 0.084149
 >> iter 18000, loss: 0.073786
 >> iter 19000, loss: 0.057014
 >> iter 20000, loss: 0.073181
   Number of active neurons: 6
 >> iter 21000, loss: 0.085134
 >> iter 22000, loss: 0.052271
 >> iter 23000, loss: 0.055208
 >> iter 24000, loss: 0.059320
 >> iter 25000, loss: 0.046157
 >> iter 26000, loss: 0.057433
 >> iter 27000, loss: 0.040782
 >> iter 28000, loss: 0.048668
 >> iter 29000, loss: 0.067209
 >> iter 30000, loss: 0.072691
   Number of active neurons: 5
 >> iter 31000, loss: 0.058375
 >> iter 32000, loss: 0.048017
 >> iter 33000, loss: 0.048242
 >> iter 34000, loss: 0.049129
 >> iter 35000, loss: 0.057847
 >> iter 36000, loss: 0.080490
 >> iter 37000, loss: 0.057974
 >> iter 38000, loss: 0.044502
 >> iter 39000, loss: 0.044883
 >> iter 40000, loss: 0.063456
   Number of active neurons: 5
 >> iter 41000, loss: 0.042437
 >> iter 42000, loss: 0.054664
 >> iter 43000, loss: 0.075818
 >> iter 44000, loss: 0.061279
 >> iter 45000, loss: 0.045224
 >> iter 46000, loss: 0.057085
 >> iter 47000, loss: 0.057079
 >> iter 48000, loss: 0.059955
 >> iter 49000, loss: 0.056855
 >> iter 50000, loss: 0.045582
   Number of active neurons: 5
 >> iter 51000, loss: 0.048990
 >> iter 52000, loss: 0.047844
 >> iter 53000, loss: 0.049833
 >> iter 54000, loss: 0.039421
 >> iter 55000, loss: 0.047890
 >> iter 56000, loss: 0.052768
 >> iter 57000, loss: 0.040273
 >> iter 58000, loss: 0.054875
 >> iter 59000, loss: 0.070072
 >> iter 60000, loss: 0.049123
   Number of active neurons: 3
 >> iter 61000, loss: 0.079459
 >> iter 62000, loss: 0.051406
 >> iter 63000, loss: 0.059472
 >> iter 64000, loss: 0.048735
 >> iter 65000, loss: 0.051717
 >> iter 66000, loss: 0.043858
 >> iter 67000, loss: 0.046966
 >> iter 68000, loss: 0.051680
 >> iter 69000, loss: 0.057267
 >> iter 70000, loss: 0.045626
   Number of active neurons: 2
 >> iter 71000, loss: 0.031611
 >> iter 72000, loss: 0.037803
 >> iter 73000, loss: 0.045737
 >> iter 74000, loss: 0.052981
 >> iter 75000, loss: 0.059110
 >> iter 76000, loss: 0.044209
 >> iter 77000, loss: 0.045383
 >> iter 78000, loss: 0.033436
 >> iter 79000, loss: 0.050006
 >> iter 80000, loss: 0.042447
   Number of active neurons: 2
 >> iter 81000, loss: 0.050246
 >> iter 82000, loss: 0.048383
 >> iter 83000, loss: 0.040842
 >> iter 84000, loss: 0.029617
 >> iter 85000, loss: 0.052753
 >> iter 86000, loss: 0.042663
 >> iter 87000, loss: 0.046952
 >> iter 88000, loss: 0.048483
 >> iter 89000, loss: 0.050186
 >> iter 90000, loss: 0.058967
   Number of active neurons: 2
 >> iter 91000, loss: 0.043579
 >> iter 92000, loss: 0.045009
 >> iter 93000, loss: 0.044801
 >> iter 94000, loss: 0.047722
 >> iter 95000, loss: 0.061011
 >> iter 96000, loss: 0.041328
 >> iter 97000, loss: 0.029162
 >> iter 98000, loss: 0.035467
 >> iter 99000, loss: 0.050166
 >> iter 100000, loss: 0.039829
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 11.311452
 >> iter 2000, loss: 4.458122
 >> iter 3000, loss: 1.784420
 >> iter 4000, loss: 0.746066
 >> iter 5000, loss: 0.357183
 >> iter 6000, loss: 0.193840
 >> iter 7000, loss: 0.131815
 >> iter 8000, loss: 0.123758
 >> iter 9000, loss: 0.119206
 >> iter 10000, loss: 0.102498
   Number of active neurons: 8
 >> iter 11000, loss: 0.103680
 >> iter 12000, loss: 0.101065
 >> iter 13000, loss: 0.085723
 >> iter 14000, loss: 0.064732
 >> iter 15000, loss: 0.072444
 >> iter 16000, loss: 0.066028
 >> iter 17000, loss: 0.091002
 >> iter 18000, loss: 0.090828
 >> iter 19000, loss: 0.068405
 >> iter 20000, loss: 0.051867
   Number of active neurons: 7
 >> iter 21000, loss: 0.063166
 >> iter 22000, loss: 0.075883
 >> iter 23000, loss: 0.104700
 >> iter 24000, loss: 0.069624
 >> iter 25000, loss: 0.075595
 >> iter 26000, loss: 0.056470
 >> iter 27000, loss: 0.052280
 >> iter 28000, loss: 0.043143
 >> iter 29000, loss: 0.041046
 >> iter 30000, loss: 0.036031
   Number of active neurons: 5
 >> iter 31000, loss: 0.036123
 >> iter 32000, loss: 0.035756
 >> iter 33000, loss: 0.037974
 >> iter 34000, loss: 0.054901
 >> iter 35000, loss: 0.060591
 >> iter 36000, loss: 0.076777
 >> iter 37000, loss: 0.058188
 >> iter 38000, loss: 0.058775
 >> iter 39000, loss: 0.050768
 >> iter 40000, loss: 0.053461
   Number of active neurons: 5
 >> iter 41000, loss: 0.042805
 >> iter 42000, loss: 0.049575
 >> iter 43000, loss: 0.046667
 >> iter 44000, loss: 0.045959
 >> iter 45000, loss: 0.054289
 >> iter 46000, loss: 0.051227
 >> iter 47000, loss: 0.097030
 >> iter 48000, loss: 0.055773
 >> iter 49000, loss: 0.041257
 >> iter 50000, loss: 0.045595
   Number of active neurons: 5
 >> iter 51000, loss: 0.060575
 >> iter 52000, loss: 0.063245
 >> iter 53000, loss: 0.067382
 >> iter 54000, loss: 0.048058
 >> iter 55000, loss: 0.048291
 >> iter 56000, loss: 0.053840
 >> iter 57000, loss: 0.053490
 >> iter 58000, loss: 0.052840
 >> iter 59000, loss: 0.074210
 >> iter 60000, loss: 0.050938
   Number of active neurons: 4
 >> iter 61000, loss: 0.051552
 >> iter 62000, loss: 0.051884
 >> iter 63000, loss: 0.035941
 >> iter 64000, loss: 0.035902
 >> iter 65000, loss: 0.064565
 >> iter 66000, loss: 0.053041
 >> iter 67000, loss: 0.050909
 >> iter 68000, loss: 0.043661
 >> iter 69000, loss: 0.035024
 >> iter 70000, loss: 0.042981
   Number of active neurons: 3
 >> iter 71000, loss: 0.046643
 >> iter 72000, loss: 0.034706
 >> iter 73000, loss: 0.048119
 >> iter 74000, loss: 0.035196
 >> iter 75000, loss: 0.031602
 >> iter 76000, loss: 0.040112
 >> iter 77000, loss: 0.054117
 >> iter 78000, loss: 0.053513
 >> iter 79000, loss: 0.052158
 >> iter 80000, loss: 0.045130
   Number of active neurons: 3
 >> iter 81000, loss: 0.041988
 >> iter 82000, loss: 0.050177
 >> iter 83000, loss: 0.045035
 >> iter 84000, loss: 0.036842
 >> iter 85000, loss: 0.041413
 >> iter 86000, loss: 0.065186
 >> iter 87000, loss: 0.068464
 >> iter 88000, loss: 0.054902
 >> iter 89000, loss: 0.073534
 >> iter 90000, loss: 0.052464
   Number of active neurons: 2
 >> iter 91000, loss: 0.060446
 >> iter 92000, loss: 0.043877
 >> iter 93000, loss: 0.032504
 >> iter 94000, loss: 0.051383
 >> iter 95000, loss: 0.032935
 >> iter 96000, loss: 0.038434
 >> iter 97000, loss: 0.033898
 >> iter 98000, loss: 0.037720
 >> iter 99000, loss: 0.052220
 >> iter 100000, loss: 0.038671
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455180
   Number of active neurons: 0
 >> iter 1000, loss: 11.415901
 >> iter 2000, loss: 4.500742
 >> iter 3000, loss: 1.880613
 >> iter 4000, loss: 0.830136
 >> iter 5000, loss: 0.374664
 >> iter 6000, loss: 0.204402
 >> iter 7000, loss: 0.181918
 >> iter 8000, loss: 0.155045
 >> iter 9000, loss: 0.128160
 >> iter 10000, loss: 0.115685
   Number of active neurons: 11
 >> iter 11000, loss: 0.108365
 >> iter 12000, loss: 0.092051
 >> iter 13000, loss: 0.095553
 >> iter 14000, loss: 0.078262
 >> iter 15000, loss: 0.078418
 >> iter 16000, loss: 0.075713
 >> iter 17000, loss: 0.060796
 >> iter 18000, loss: 0.071091
 >> iter 19000, loss: 0.083138
 >> iter 20000, loss: 0.060318
   Number of active neurons: 7
 >> iter 21000, loss: 0.086375
 >> iter 22000, loss: 0.070007
 >> iter 23000, loss: 0.068948
 >> iter 24000, loss: 0.053658
 >> iter 25000, loss: 0.071804
 >> iter 26000, loss: 0.051239
 >> iter 27000, loss: 0.047324
 >> iter 28000, loss: 0.058707
 >> iter 29000, loss: 0.052718
 >> iter 30000, loss: 0.040539
   Number of active neurons: 5
 >> iter 31000, loss: 0.046767
 >> iter 32000, loss: 0.053782
 >> iter 33000, loss: 0.049064
 >> iter 34000, loss: 0.063745
 >> iter 35000, loss: 0.082387
 >> iter 36000, loss: 0.065742
 >> iter 37000, loss: 0.047108
 >> iter 38000, loss: 0.049740
 >> iter 39000, loss: 0.054135
 >> iter 40000, loss: 0.049769
   Number of active neurons: 4
 >> iter 41000, loss: 0.036309
 >> iter 42000, loss: 0.032937
 >> iter 43000, loss: 0.046000
 >> iter 44000, loss: 0.037229
 >> iter 45000, loss: 0.057996
 >> iter 46000, loss: 0.051530
 >> iter 47000, loss: 0.062897
 >> iter 48000, loss: 0.041755
 >> iter 49000, loss: 0.049336
 >> iter 50000, loss: 0.044615
   Number of active neurons: 4
 >> iter 51000, loss: 0.051997
 >> iter 52000, loss: 0.072332
 >> iter 53000, loss: 0.055866
 >> iter 54000, loss: 0.062911
 >> iter 55000, loss: 0.068132
 >> iter 56000, loss: 0.048901
 >> iter 57000, loss: 0.042886
 >> iter 58000, loss: 0.070392
 >> iter 59000, loss: 0.047217
 >> iter 60000, loss: 0.039919
   Number of active neurons: 4
 >> iter 61000, loss: 0.045536
 >> iter 62000, loss: 0.043443
 >> iter 63000, loss: 0.042656
 >> iter 64000, loss: 0.061936
 >> iter 65000, loss: 0.062170
 >> iter 66000, loss: 0.051216
 >> iter 67000, loss: 0.044065
 >> iter 68000, loss: 0.078619
 >> iter 69000, loss: 0.063969
 >> iter 70000, loss: 0.058157
   Number of active neurons: 4
 >> iter 71000, loss: 0.044581
 >> iter 72000, loss: 0.041910
 >> iter 73000, loss: 0.039866
 >> iter 74000, loss: 0.030290
 >> iter 75000, loss: 0.032930
 >> iter 76000, loss: 0.042179
 >> iter 77000, loss: 0.046562
 >> iter 78000, loss: 0.043614
 >> iter 79000, loss: 0.044199
 >> iter 80000, loss: 0.036067
   Number of active neurons: 4
 >> iter 81000, loss: 0.040492
 >> iter 82000, loss: 0.060216
 >> iter 83000, loss: 0.059340
 >> iter 84000, loss: 0.051656
 >> iter 85000, loss: 0.051690
 >> iter 86000, loss: 0.042194
 >> iter 87000, loss: 0.062592
 >> iter 88000, loss: 0.043773
 >> iter 89000, loss: 0.054566
 >> iter 90000, loss: 0.066454
   Number of active neurons: 3
 >> iter 91000, loss: 0.058183
 >> iter 92000, loss: 0.050092
 >> iter 93000, loss: 0.056620
 >> iter 94000, loss: 0.052288
 >> iter 95000, loss: 0.050463
 >> iter 96000, loss: 0.057543
 >> iter 97000, loss: 0.050407
 >> iter 98000, loss: 0.042962
 >> iter 99000, loss: 0.053908
 >> iter 100000, loss: 0.040667
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455161
   Number of active neurons: 0
 >> iter 1000, loss: 11.335655
 >> iter 2000, loss: 4.474415
 >> iter 3000, loss: 1.819485
 >> iter 4000, loss: 0.763224
 >> iter 5000, loss: 0.376856
 >> iter 6000, loss: 0.197256
 >> iter 7000, loss: 0.127644
 >> iter 8000, loss: 0.121451
 >> iter 9000, loss: 0.101722
 >> iter 10000, loss: 0.098181
   Number of active neurons: 8
 >> iter 11000, loss: 0.081625
 >> iter 12000, loss: 0.063689
 >> iter 13000, loss: 0.079663
 >> iter 14000, loss: 0.098707
 >> iter 15000, loss: 0.082703
 >> iter 16000, loss: 0.078840
 >> iter 17000, loss: 0.075616
 >> iter 18000, loss: 0.068541
 >> iter 19000, loss: 0.069136
 >> iter 20000, loss: 0.077145
   Number of active neurons: 7
 >> iter 21000, loss: 0.065922
 >> iter 22000, loss: 0.054014
 >> iter 23000, loss: 0.053646
 >> iter 24000, loss: 0.051857
 >> iter 25000, loss: 0.078474
 >> iter 26000, loss: 0.082504
 >> iter 27000, loss: 0.092938
 >> iter 28000, loss: 0.067345
 >> iter 29000, loss: 0.049460
 >> iter 30000, loss: 0.053323
   Number of active neurons: 7
 >> iter 31000, loss: 0.076736
 >> iter 32000, loss: 0.065303
 >> iter 33000, loss: 0.047425
 >> iter 34000, loss: 0.056955
 >> iter 35000, loss: 0.064453
 >> iter 36000, loss: 0.056214
 >> iter 37000, loss: 0.090928
 >> iter 38000, loss: 0.076063
 >> iter 39000, loss: 0.071679
 >> iter 40000, loss: 0.066850
   Number of active neurons: 6
 >> iter 41000, loss: 0.061011
 >> iter 42000, loss: 0.053352
 >> iter 43000, loss: 0.047111
 >> iter 44000, loss: 0.047974
 >> iter 45000, loss: 0.043851
 >> iter 46000, loss: 0.061450
 >> iter 47000, loss: 0.042395
 >> iter 48000, loss: 0.058899
 >> iter 49000, loss: 0.069392
 >> iter 50000, loss: 0.045614
   Number of active neurons: 5
 >> iter 51000, loss: 0.054872
 >> iter 52000, loss: 0.087819
 >> iter 53000, loss: 0.055926
 >> iter 54000, loss: 0.051462
 >> iter 55000, loss: 0.056429
 >> iter 56000, loss: 0.064876
 >> iter 57000, loss: 0.051553
 >> iter 58000, loss: 0.042449
 >> iter 59000, loss: 0.041489
 >> iter 60000, loss: 0.041459
   Number of active neurons: 5
 >> iter 61000, loss: 0.060254
 >> iter 62000, loss: 0.059863
 >> iter 63000, loss: 0.049419
 >> iter 64000, loss: 0.055017
 >> iter 65000, loss: 0.040831
 >> iter 66000, loss: 0.059338
 >> iter 67000, loss: 0.074938
 >> iter 68000, loss: 0.054956
 >> iter 69000, loss: 0.048026
 >> iter 70000, loss: 0.054757
   Number of active neurons: 5
 >> iter 71000, loss: 0.041138
 >> iter 72000, loss: 0.037793
 >> iter 73000, loss: 0.035354
 >> iter 74000, loss: 0.030490
 >> iter 75000, loss: 0.040696
 >> iter 76000, loss: 0.056751
 >> iter 77000, loss: 0.042182
 >> iter 78000, loss: 0.041239
 >> iter 79000, loss: 0.056045
 >> iter 80000, loss: 0.037692
   Number of active neurons: 4
 >> iter 81000, loss: 0.050255
 >> iter 82000, loss: 0.046643
 >> iter 83000, loss: 0.061754
 >> iter 84000, loss: 0.063627
 >> iter 85000, loss: 0.065012
 >> iter 86000, loss: 0.066103
 >> iter 87000, loss: 0.061324
 >> iter 88000, loss: 0.061730
 >> iter 89000, loss: 0.052262
 >> iter 90000, loss: 0.057465
   Number of active neurons: 4
 >> iter 91000, loss: 0.040046
 >> iter 92000, loss: 0.043717
 >> iter 93000, loss: 0.037626
 >> iter 94000, loss: 0.049702
 >> iter 95000, loss: 0.034683
 >> iter 96000, loss: 0.048598
 >> iter 97000, loss: 0.045330
 >> iter 98000, loss: 0.039479
 >> iter 99000, loss: 0.043107
 >> iter 100000, loss: 0.063268
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.357900
 >> iter 2000, loss: 4.515765
 >> iter 3000, loss: 1.815641
 >> iter 4000, loss: 0.759070
 >> iter 5000, loss: 0.396727
 >> iter 6000, loss: 0.202518
 >> iter 7000, loss: 0.135983
 >> iter 8000, loss: 0.101965
 >> iter 9000, loss: 0.081500
 >> iter 10000, loss: 0.095692
   Number of active neurons: 9
 >> iter 11000, loss: 0.086910
 >> iter 12000, loss: 0.077101
 >> iter 13000, loss: 0.077731
 >> iter 14000, loss: 0.103534
 >> iter 15000, loss: 0.080728
 >> iter 16000, loss: 0.068913
 >> iter 17000, loss: 0.066402
 >> iter 18000, loss: 0.071221
 >> iter 19000, loss: 0.055658
 >> iter 20000, loss: 0.069178
   Number of active neurons: 8
 >> iter 21000, loss: 0.057842
 >> iter 22000, loss: 0.057972
 >> iter 23000, loss: 0.048403
 >> iter 24000, loss: 0.044774
 >> iter 25000, loss: 0.073366
 >> iter 26000, loss: 0.057075
 >> iter 27000, loss: 0.058679
 >> iter 28000, loss: 0.043825
 >> iter 29000, loss: 0.077429
 >> iter 30000, loss: 0.075205
   Number of active neurons: 6
 >> iter 31000, loss: 0.050971
 >> iter 32000, loss: 0.062992
 >> iter 33000, loss: 0.050425
 >> iter 34000, loss: 0.044734
 >> iter 35000, loss: 0.039618
 >> iter 36000, loss: 0.042691
 >> iter 37000, loss: 0.096109
 >> iter 38000, loss: 0.073668
 >> iter 39000, loss: 0.059281
 >> iter 40000, loss: 0.052061
   Number of active neurons: 6
 >> iter 41000, loss: 0.041103
 >> iter 42000, loss: 0.060368
 >> iter 43000, loss: 0.063111
 >> iter 44000, loss: 0.055167
 >> iter 45000, loss: 0.052740
 >> iter 46000, loss: 0.050983
 >> iter 47000, loss: 0.066536
 >> iter 48000, loss: 0.069033
 >> iter 49000, loss: 0.054892
 >> iter 50000, loss: 0.083664
   Number of active neurons: 4
 >> iter 51000, loss: 0.055034
 >> iter 52000, loss: 0.048200
 >> iter 53000, loss: 0.043400
 >> iter 54000, loss: 0.049361
 >> iter 55000, loss: 0.062670
 >> iter 56000, loss: 0.050125
 >> iter 57000, loss: 0.083946
 >> iter 58000, loss: 0.073854
 >> iter 59000, loss: 0.062943
 >> iter 60000, loss: 0.040850
   Number of active neurons: 4
 >> iter 61000, loss: 0.041598
 >> iter 62000, loss: 0.047462
 >> iter 63000, loss: 0.035965
 >> iter 64000, loss: 0.040067
 >> iter 65000, loss: 0.061382
 >> iter 66000, loss: 0.058362
 >> iter 67000, loss: 0.066047
 >> iter 68000, loss: 0.045724
 >> iter 69000, loss: 0.054613
 >> iter 70000, loss: 0.047871
   Number of active neurons: 4
 >> iter 71000, loss: 0.042475
 >> iter 72000, loss: 0.045455
 >> iter 73000, loss: 0.052955
 >> iter 74000, loss: 0.048512
 >> iter 75000, loss: 0.043443
 >> iter 76000, loss: 0.047133
 >> iter 77000, loss: 0.048470
 >> iter 78000, loss: 0.062162
 >> iter 79000, loss: 0.060632
 >> iter 80000, loss: 0.053878
   Number of active neurons: 4
 >> iter 81000, loss: 0.043320
 >> iter 82000, loss: 0.035603
 >> iter 83000, loss: 0.028913
 >> iter 84000, loss: 0.033014
 >> iter 85000, loss: 0.054152
 >> iter 86000, loss: 0.046666
 >> iter 87000, loss: 0.054119
 >> iter 88000, loss: 0.053314
 >> iter 89000, loss: 0.044048
 >> iter 90000, loss: 0.044646
   Number of active neurons: 4
 >> iter 91000, loss: 0.039974
 >> iter 92000, loss: 0.045705
 >> iter 93000, loss: 0.052416
 >> iter 94000, loss: 0.053403
 >> iter 95000, loss: 0.046741
 >> iter 96000, loss: 0.053805
 >> iter 97000, loss: 0.052789
 >> iter 98000, loss: 0.044734
 >> iter 99000, loss: 0.048700
 >> iter 100000, loss: 0.041663
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 11.345746
 >> iter 2000, loss: 4.466225
 >> iter 3000, loss: 1.788177
 >> iter 4000, loss: 0.783568
 >> iter 5000, loss: 0.371481
 >> iter 6000, loss: 0.197731
 >> iter 7000, loss: 0.137195
 >> iter 8000, loss: 0.114332
 >> iter 9000, loss: 0.110439
 >> iter 10000, loss: 0.085939
   Number of active neurons: 10
 >> iter 11000, loss: 0.107486
 >> iter 12000, loss: 0.089989
 >> iter 13000, loss: 0.074193
 >> iter 14000, loss: 0.092267
 >> iter 15000, loss: 0.083168
 >> iter 16000, loss: 0.094075
 >> iter 17000, loss: 0.075913
 >> iter 18000, loss: 0.071121
 >> iter 19000, loss: 0.103408
 >> iter 20000, loss: 0.069847
   Number of active neurons: 9
 >> iter 21000, loss: 0.071412
 >> iter 22000, loss: 0.076015
 >> iter 23000, loss: 0.097713
 >> iter 24000, loss: 0.063645
 >> iter 25000, loss: 0.050381
 >> iter 26000, loss: 0.052912
 >> iter 27000, loss: 0.077251
 >> iter 28000, loss: 0.062417
 >> iter 29000, loss: 0.080410
 >> iter 30000, loss: 0.078723
   Number of active neurons: 8
 >> iter 31000, loss: 0.067835
 >> iter 32000, loss: 0.073870
 >> iter 33000, loss: 0.062290
 >> iter 34000, loss: 0.055068
 >> iter 35000, loss: 0.063184
 >> iter 36000, loss: 0.051329
 >> iter 37000, loss: 0.049680
 >> iter 38000, loss: 0.048214
 >> iter 39000, loss: 0.039265
 >> iter 40000, loss: 0.059132
   Number of active neurons: 6
 >> iter 41000, loss: 0.075247
 >> iter 42000, loss: 0.055626
 >> iter 43000, loss: 0.063404
 >> iter 44000, loss: 0.045724
 >> iter 45000, loss: 0.039765
 >> iter 46000, loss: 0.050656
 >> iter 47000, loss: 0.067252
 >> iter 48000, loss: 0.044126
 >> iter 49000, loss: 0.063088
 >> iter 50000, loss: 0.065359
   Number of active neurons: 6
 >> iter 51000, loss: 0.055674
 >> iter 52000, loss: 0.083645
 >> iter 53000, loss: 0.066664
 >> iter 54000, loss: 0.053077
 >> iter 55000, loss: 0.079262
 >> iter 56000, loss: 0.049901
 >> iter 57000, loss: 0.051717
 >> iter 58000, loss: 0.056914
 >> iter 59000, loss: 0.062527
 >> iter 60000, loss: 0.076095
   Number of active neurons: 6
 >> iter 61000, loss: 0.058581
 >> iter 62000, loss: 0.071159
 >> iter 63000, loss: 0.075572
 >> iter 64000, loss: 0.061748
 >> iter 65000, loss: 0.054181
 >> iter 66000, loss: 0.053828
 >> iter 67000, loss: 0.041634
 >> iter 68000, loss: 0.042030
 >> iter 69000, loss: 0.046823
 >> iter 70000, loss: 0.063317
   Number of active neurons: 5
 >> iter 71000, loss: 0.055113
 >> iter 72000, loss: 0.079739
 >> iter 73000, loss: 0.073469
 >> iter 74000, loss: 0.053903
 >> iter 75000, loss: 0.057746
 >> iter 76000, loss: 0.049813
 >> iter 77000, loss: 0.063045
 >> iter 78000, loss: 0.054797
 >> iter 79000, loss: 0.045106
 >> iter 80000, loss: 0.048635
   Number of active neurons: 5
 >> iter 81000, loss: 0.040077
 >> iter 82000, loss: 0.035283
 >> iter 83000, loss: 0.039807
 >> iter 84000, loss: 0.040843
 >> iter 85000, loss: 0.040057
 >> iter 86000, loss: 0.061038
 >> iter 87000, loss: 0.056006
 >> iter 88000, loss: 0.040785
 >> iter 89000, loss: 0.039825
 >> iter 90000, loss: 0.049214
   Number of active neurons: 3
 >> iter 91000, loss: 0.038653
 >> iter 92000, loss: 0.032651
 >> iter 93000, loss: 0.040322
 >> iter 94000, loss: 0.028494
 >> iter 95000, loss: 0.037768
 >> iter 96000, loss: 0.032321
 >> iter 97000, loss: 0.033396
 >> iter 98000, loss: 0.042997
 >> iter 99000, loss: 0.055709
 >> iter 100000, loss: 0.042731
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.341864
 >> iter 2000, loss: 4.482033
 >> iter 3000, loss: 1.832187
 >> iter 4000, loss: 0.768438
 >> iter 5000, loss: 0.335912
 >> iter 6000, loss: 0.173945
 >> iter 7000, loss: 0.113840
 >> iter 8000, loss: 0.088847
 >> iter 9000, loss: 0.097661
 >> iter 10000, loss: 0.100837
   Number of active neurons: 8
 >> iter 11000, loss: 0.082296
 >> iter 12000, loss: 0.083711
 >> iter 13000, loss: 0.061984
 >> iter 14000, loss: 0.065366
 >> iter 15000, loss: 0.053360
 >> iter 16000, loss: 0.071124
 >> iter 17000, loss: 0.053330
 >> iter 18000, loss: 0.052179
 >> iter 19000, loss: 0.045677
 >> iter 20000, loss: 0.054276
   Number of active neurons: 5
 >> iter 21000, loss: 0.074234
 >> iter 22000, loss: 0.048165
 >> iter 23000, loss: 0.042119
 >> iter 24000, loss: 0.055705
 >> iter 25000, loss: 0.076931
 >> iter 26000, loss: 0.058212
 >> iter 27000, loss: 0.082854
 >> iter 28000, loss: 0.061160
 >> iter 29000, loss: 0.054303
 >> iter 30000, loss: 0.042630
   Number of active neurons: 5
 >> iter 31000, loss: 0.053220
 >> iter 32000, loss: 0.040930
 >> iter 33000, loss: 0.045279
 >> iter 34000, loss: 0.054953
 >> iter 35000, loss: 0.047958
 >> iter 36000, loss: 0.050951
 >> iter 37000, loss: 0.044506
 >> iter 38000, loss: 0.042545
 >> iter 39000, loss: 0.042965
 >> iter 40000, loss: 0.051414
   Number of active neurons: 4
 >> iter 41000, loss: 0.049012
 >> iter 42000, loss: 0.043591
 >> iter 43000, loss: 0.041094
 >> iter 44000, loss: 0.042000
 >> iter 45000, loss: 0.062318
 >> iter 46000, loss: 0.054226
 >> iter 47000, loss: 0.055208
 >> iter 48000, loss: 0.041975
 >> iter 49000, loss: 0.044753
 >> iter 50000, loss: 0.049022
   Number of active neurons: 3
 >> iter 51000, loss: 0.042572
 >> iter 52000, loss: 0.060137
 >> iter 53000, loss: 0.048857
 >> iter 54000, loss: 0.054497
 >> iter 55000, loss: 0.045313
 >> iter 56000, loss: 0.056675
 >> iter 57000, loss: 0.050300
 >> iter 58000, loss: 0.045338
 >> iter 59000, loss: 0.053623
 >> iter 60000, loss: 0.038734
   Number of active neurons: 2
 >> iter 61000, loss: 0.055334
 >> iter 62000, loss: 0.046546
 >> iter 63000, loss: 0.037638
 >> iter 64000, loss: 0.041386
 >> iter 65000, loss: 0.058137
 >> iter 66000, loss: 0.048795
 >> iter 67000, loss: 0.051596
 >> iter 68000, loss: 0.047076
 >> iter 69000, loss: 0.046877
 >> iter 70000, loss: 0.041626
   Number of active neurons: 2
 >> iter 71000, loss: 0.034762
 >> iter 72000, loss: 0.047092
 >> iter 73000, loss: 0.042470
 >> iter 74000, loss: 0.039722
 >> iter 75000, loss: 0.032336
 >> iter 76000, loss: 0.031980
 >> iter 77000, loss: 0.041175
 >> iter 78000, loss: 0.045265
 >> iter 79000, loss: 0.043881
 >> iter 80000, loss: 0.059004
   Number of active neurons: 2
 >> iter 81000, loss: 0.040670
 >> iter 82000, loss: 0.036179
 >> iter 83000, loss: 0.041491
 >> iter 84000, loss: 0.055015
 >> iter 85000, loss: 0.050781
 >> iter 86000, loss: 0.035752
 >> iter 87000, loss: 0.030611
 >> iter 88000, loss: 0.037624
 >> iter 89000, loss: 0.029774
 >> iter 90000, loss: 0.030819
   Number of active neurons: 2
 >> iter 91000, loss: 0.023318
 >> iter 92000, loss: 0.040748
 >> iter 93000, loss: 0.068087
 >> iter 94000, loss: 0.049589
 >> iter 95000, loss: 0.050107
 >> iter 96000, loss: 0.051030
 >> iter 97000, loss: 0.059337
 >> iter 98000, loss: 0.045999
 >> iter 99000, loss: 0.040435
 >> iter 100000, loss: 0.047493
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

