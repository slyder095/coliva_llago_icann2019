 > Problema: tomita1nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 8e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.785677
 >> iter 2000, loss: 3.986724
 >> iter 3000, loss: 1.482786
 >> iter 4000, loss: 0.560381
 >> iter 5000, loss: 0.220914
 >> iter 6000, loss: 0.095316
 >> iter 7000, loss: 0.049050
 >> iter 8000, loss: 0.031320
 >> iter 9000, loss: 0.024673
 >> iter 10000, loss: 0.021481
   Number of active neurons: 3
 >> iter 11000, loss: 0.020243
 >> iter 12000, loss: 0.019097
 >> iter 13000, loss: 0.018604
 >> iter 14000, loss: 0.017812
 >> iter 15000, loss: 0.017577
 >> iter 16000, loss: 0.017027
 >> iter 17000, loss: 0.016960
 >> iter 18000, loss: 0.016555
 >> iter 19000, loss: 0.016587
 >> iter 20000, loss: 0.016292
   Number of active neurons: 2
 >> iter 21000, loss: 0.016369
 >> iter 22000, loss: 0.016089
 >> iter 23000, loss: 0.016168
 >> iter 24000, loss: 0.015862
 >> iter 25000, loss: 0.015897
 >> iter 26000, loss: 0.015506
 >> iter 27000, loss: 0.015429
 >> iter 28000, loss: 0.015020
 >> iter 29000, loss: 0.014959
 >> iter 30000, loss: 0.014600
   Number of active neurons: 2
 >> iter 31000, loss: 0.014614
 >> iter 32000, loss: 0.014349
 >> iter 33000, loss: 0.014433
 >> iter 34000, loss: 0.014225
 >> iter 35000, loss: 0.014354
 >> iter 36000, loss: 0.014164
 >> iter 37000, loss: 0.014292
 >> iter 38000, loss: 0.014092
 >> iter 39000, loss: 0.014242
 >> iter 40000, loss: 0.014058
   Number of active neurons: 2
 >> iter 41000, loss: 0.014219
 >> iter 42000, loss: 0.014055
 >> iter 43000, loss: 0.014204
 >> iter 44000, loss: 0.014037
 >> iter 45000, loss: 0.014187
 >> iter 46000, loss: 0.014037
 >> iter 47000, loss: 0.014192
 >> iter 48000, loss: 0.014052
 >> iter 49000, loss: 0.014208
 >> iter 50000, loss: 0.014059
   Number of active neurons: 2
 >> iter 51000, loss: 0.014217
 >> iter 52000, loss: 0.014076
 >> iter 53000, loss: 0.014222
 >> iter 54000, loss: 0.014106
 >> iter 55000, loss: 0.014229
 >> iter 56000, loss: 0.014119
 >> iter 57000, loss: 0.014254
 >> iter 58000, loss: 0.014126
 >> iter 59000, loss: 0.014272
 >> iter 60000, loss: 0.014150
   Number of active neurons: 2
 >> iter 61000, loss: 0.014285
 >> iter 62000, loss: 0.014171
 >> iter 63000, loss: 0.014309
 >> iter 64000, loss: 0.014184
 >> iter 65000, loss: 0.014332
 >> iter 66000, loss: 0.014213
 >> iter 67000, loss: 0.014352
 >> iter 68000, loss: 0.014253
 >> iter 69000, loss: 0.014381
 >> iter 70000, loss: 0.014275
   Number of active neurons: 2
 >> iter 71000, loss: 0.014412
 >> iter 72000, loss: 0.014315
 >> iter 73000, loss: 0.014447
 >> iter 74000, loss: 0.014346
 >> iter 75000, loss: 0.014485
 >> iter 76000, loss: 0.014385
 >> iter 77000, loss: 0.014520
 >> iter 78000, loss: 0.014417
 >> iter 79000, loss: 0.014576
 >> iter 80000, loss: 0.014463
   Number of active neurons: 2
 >> iter 81000, loss: 0.014636
 >> iter 82000, loss: 0.014511
 >> iter 83000, loss: 0.014692
 >> iter 84000, loss: 0.014556
 >> iter 85000, loss: 0.014733
 >> iter 86000, loss: 0.014599
 >> iter 87000, loss: 0.014779
 >> iter 88000, loss: 0.014643
 >> iter 89000, loss: 0.014816
 >> iter 90000, loss: 0.014692
   Number of active neurons: 2
 >> iter 91000, loss: 0.014854
 >> iter 92000, loss: 0.014732
 >> iter 93000, loss: 0.014886
 >> iter 94000, loss: 0.014751
 >> iter 95000, loss: 0.014913
 >> iter 96000, loss: 0.014750
 >> iter 97000, loss: 0.014900
 >> iter 98000, loss: 0.014714
 >> iter 99000, loss: 0.014840
 >> iter 100000, loss: 0.014634
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.728638
 >> iter 2000, loss: 3.965184
 >> iter 3000, loss: 1.474034
 >> iter 4000, loss: 0.556191
 >> iter 5000, loss: 0.218386
 >> iter 6000, loss: 0.093553
 >> iter 7000, loss: 0.047625
 >> iter 8000, loss: 0.030123
 >> iter 9000, loss: 0.023595
 >> iter 10000, loss: 0.020633
   Number of active neurons: 4
 >> iter 11000, loss: 0.019617
 >> iter 12000, loss: 0.018849
 >> iter 13000, loss: 0.018808
 >> iter 14000, loss: 0.018483
 >> iter 15000, loss: 0.018651
 >> iter 16000, loss: 0.018411
 >> iter 17000, loss: 0.018613
 >> iter 18000, loss: 0.018414
 >> iter 19000, loss: 0.018595
 >> iter 20000, loss: 0.018391
   Number of active neurons: 3
 >> iter 21000, loss: 0.018526
 >> iter 22000, loss: 0.018269
 >> iter 23000, loss: 0.018340
 >> iter 24000, loss: 0.017965
 >> iter 25000, loss: 0.017919
 >> iter 26000, loss: 0.017514
 >> iter 27000, loss: 0.017464
 >> iter 28000, loss: 0.017106
 >> iter 29000, loss: 0.017106
 >> iter 30000, loss: 0.016811
   Number of active neurons: 2
 >> iter 31000, loss: 0.016835
 >> iter 32000, loss: 0.016531
 >> iter 33000, loss: 0.016467
 >> iter 34000, loss: 0.016048
 >> iter 35000, loss: 0.015951
 >> iter 36000, loss: 0.015557
 >> iter 37000, loss: 0.015503
 >> iter 38000, loss: 0.015190
 >> iter 39000, loss: 0.015241
 >> iter 40000, loss: 0.015006
   Number of active neurons: 2
 >> iter 41000, loss: 0.015112
 >> iter 42000, loss: 0.014927
 >> iter 43000, loss: 0.015050
 >> iter 44000, loss: 0.014897
 >> iter 45000, loss: 0.015030
 >> iter 46000, loss: 0.014886
 >> iter 47000, loss: 0.015023
 >> iter 48000, loss: 0.014892
 >> iter 49000, loss: 0.015033
 >> iter 50000, loss: 0.014897
   Number of active neurons: 2
 >> iter 51000, loss: 0.015041
 >> iter 52000, loss: 0.014913
 >> iter 53000, loss: 0.015041
 >> iter 54000, loss: 0.014932
 >> iter 55000, loss: 0.015030
 >> iter 56000, loss: 0.014919
 >> iter 57000, loss: 0.015013
 >> iter 58000, loss: 0.014870
 >> iter 59000, loss: 0.014950
 >> iter 60000, loss: 0.014783
   Number of active neurons: 1
 >> iter 61000, loss: 0.014807
 >> iter 62000, loss: 0.014560
 >> iter 63000, loss: 0.014408
 >> iter 64000, loss: 0.013999
 >> iter 65000, loss: 0.013820
 >> iter 66000, loss: 0.013432
 >> iter 67000, loss: 0.013253
 >> iter 68000, loss: 0.012927
 >> iter 69000, loss: 0.012821
 >> iter 70000, loss: 0.012573
   Number of active neurons: 1
 >> iter 71000, loss: 0.012538
 >> iter 72000, loss: 0.012347
 >> iter 73000, loss: 0.012344
 >> iter 74000, loss: 0.012178
 >> iter 75000, loss: 0.012203
 >> iter 76000, loss: 0.012054
 >> iter 77000, loss: 0.012089
 >> iter 78000, loss: 0.011948
 >> iter 79000, loss: 0.012011
 >> iter 80000, loss: 0.011868
   Number of active neurons: 1
 >> iter 81000, loss: 0.011948
 >> iter 82000, loss: 0.011800
 >> iter 83000, loss: 0.011892
 >> iter 84000, loss: 0.011738
 >> iter 85000, loss: 0.011832
 >> iter 86000, loss: 0.011682
 >> iter 87000, loss: 0.011782
 >> iter 88000, loss: 0.011634
 >> iter 89000, loss: 0.011734
 >> iter 90000, loss: 0.011597
   Number of active neurons: 1
 >> iter 91000, loss: 0.011695
 >> iter 92000, loss: 0.011564
 >> iter 93000, loss: 0.011664
 >> iter 94000, loss: 0.011527
 >> iter 95000, loss: 0.011645
 >> iter 96000, loss: 0.011495
 >> iter 97000, loss: 0.011619
 >> iter 98000, loss: 0.011466
 >> iter 99000, loss: 0.011597
 >> iter 100000, loss: 0.011456
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.695697
 >> iter 2000, loss: 3.953836
 >> iter 3000, loss: 1.470208
 >> iter 4000, loss: 0.554882
 >> iter 5000, loss: 0.217738
 >> iter 6000, loss: 0.093014
 >> iter 7000, loss: 0.047093
 >> iter 8000, loss: 0.029780
 >> iter 9000, loss: 0.023531
 >> iter 10000, loss: 0.020830
   Number of active neurons: 3
 >> iter 11000, loss: 0.019909
 >> iter 12000, loss: 0.019095
 >> iter 13000, loss: 0.018819
 >> iter 14000, loss: 0.018218
 >> iter 15000, loss: 0.018014
 >> iter 16000, loss: 0.017407
 >> iter 17000, loss: 0.017150
 >> iter 18000, loss: 0.016484
 >> iter 19000, loss: 0.016175
 >> iter 20000, loss: 0.015646
   Number of active neurons: 2
 >> iter 21000, loss: 0.015484
 >> iter 22000, loss: 0.015107
 >> iter 23000, loss: 0.015097
 >> iter 24000, loss: 0.014831
 >> iter 25000, loss: 0.014908
 >> iter 26000, loss: 0.014705
 >> iter 27000, loss: 0.014813
 >> iter 28000, loss: 0.014639
 >> iter 29000, loss: 0.014755
 >> iter 30000, loss: 0.014594
   Number of active neurons: 2
 >> iter 31000, loss: 0.014723
 >> iter 32000, loss: 0.014568
 >> iter 33000, loss: 0.014703
 >> iter 34000, loss: 0.014555
 >> iter 35000, loss: 0.014705
 >> iter 36000, loss: 0.014551
 >> iter 37000, loss: 0.014706
 >> iter 38000, loss: 0.014552
 >> iter 39000, loss: 0.014717
 >> iter 40000, loss: 0.014564
   Number of active neurons: 2
 >> iter 41000, loss: 0.014729
 >> iter 42000, loss: 0.014586
 >> iter 43000, loss: 0.014743
 >> iter 44000, loss: 0.014615
 >> iter 45000, loss: 0.014770
 >> iter 46000, loss: 0.014642
 >> iter 47000, loss: 0.014796
 >> iter 48000, loss: 0.014678
 >> iter 49000, loss: 0.014834
 >> iter 50000, loss: 0.014709
   Number of active neurons: 2
 >> iter 51000, loss: 0.014866
 >> iter 52000, loss: 0.014750
 >> iter 53000, loss: 0.014892
 >> iter 54000, loss: 0.014796
 >> iter 55000, loss: 0.014911
 >> iter 56000, loss: 0.014815
 >> iter 57000, loss: 0.014933
 >> iter 58000, loss: 0.014812
 >> iter 59000, loss: 0.014926
 >> iter 60000, loss: 0.014794
   Number of active neurons: 1
 >> iter 61000, loss: 0.014873
 >> iter 62000, loss: 0.014721
 >> iter 63000, loss: 0.014761
 >> iter 64000, loss: 0.014519
 >> iter 65000, loss: 0.014398
 >> iter 66000, loss: 0.014000
 >> iter 67000, loss: 0.013820
 >> iter 68000, loss: 0.013454
 >> iter 69000, loss: 0.013267
 >> iter 70000, loss: 0.012927
   Number of active neurons: 1
 >> iter 71000, loss: 0.012822
 >> iter 72000, loss: 0.012576
 >> iter 73000, loss: 0.012533
 >> iter 74000, loss: 0.012336
 >> iter 75000, loss: 0.012336
 >> iter 76000, loss: 0.012169
 >> iter 77000, loss: 0.012190
 >> iter 78000, loss: 0.012037
 >> iter 79000, loss: 0.012091
 >> iter 80000, loss: 0.011941
   Number of active neurons: 1
 >> iter 81000, loss: 0.012015
 >> iter 82000, loss: 0.011861
 >> iter 83000, loss: 0.011948
 >> iter 84000, loss: 0.011790
 >> iter 85000, loss: 0.011880
 >> iter 86000, loss: 0.011727
 >> iter 87000, loss: 0.011825
 >> iter 88000, loss: 0.011674
 >> iter 89000, loss: 0.011771
 >> iter 90000, loss: 0.011632
   Number of active neurons: 1
 >> iter 91000, loss: 0.011728
 >> iter 92000, loss: 0.011595
 >> iter 93000, loss: 0.011693
 >> iter 94000, loss: 0.011555
 >> iter 95000, loss: 0.011671
 >> iter 96000, loss: 0.011520
 >> iter 97000, loss: 0.011642
 >> iter 98000, loss: 0.011488
 >> iter 99000, loss: 0.011618
 >> iter 100000, loss: 0.011475
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.749089
 >> iter 2000, loss: 3.972370
 >> iter 3000, loss: 1.476477
 >> iter 4000, loss: 0.556872
 >> iter 5000, loss: 0.218400
 >> iter 6000, loss: 0.093329
 >> iter 7000, loss: 0.047403
 >> iter 8000, loss: 0.030077
 >> iter 9000, loss: 0.023870
 >> iter 10000, loss: 0.021234
   Number of active neurons: 4
 >> iter 11000, loss: 0.020503
 >> iter 12000, loss: 0.019909
 >> iter 13000, loss: 0.019964
 >> iter 14000, loss: 0.019629
 >> iter 15000, loss: 0.019736
 >> iter 16000, loss: 0.019336
 >> iter 17000, loss: 0.019311
 >> iter 18000, loss: 0.018836
 >> iter 19000, loss: 0.018730
 >> iter 20000, loss: 0.018231
   Number of active neurons: 3
 >> iter 21000, loss: 0.018085
 >> iter 22000, loss: 0.017622
 >> iter 23000, loss: 0.017555
 >> iter 24000, loss: 0.017189
 >> iter 25000, loss: 0.017239
 >> iter 26000, loss: 0.016981
 >> iter 27000, loss: 0.017085
 >> iter 28000, loss: 0.016868
 >> iter 29000, loss: 0.016971
 >> iter 30000, loss: 0.016752
   Number of active neurons: 2
 >> iter 31000, loss: 0.016837
 >> iter 32000, loss: 0.016586
 >> iter 33000, loss: 0.016606
 >> iter 34000, loss: 0.016236
 >> iter 35000, loss: 0.016142
 >> iter 36000, loss: 0.015740
 >> iter 37000, loss: 0.015672
 >> iter 38000, loss: 0.015318
 >> iter 39000, loss: 0.015336
 >> iter 40000, loss: 0.015076
   Number of active neurons: 2
 >> iter 41000, loss: 0.015165
 >> iter 42000, loss: 0.014968
 >> iter 43000, loss: 0.015083
 >> iter 44000, loss: 0.014925
 >> iter 45000, loss: 0.015054
 >> iter 46000, loss: 0.014907
 >> iter 47000, loss: 0.015042
 >> iter 48000, loss: 0.014910
 >> iter 49000, loss: 0.015049
 >> iter 50000, loss: 0.014912
   Number of active neurons: 2
 >> iter 51000, loss: 0.015054
 >> iter 52000, loss: 0.014925
 >> iter 53000, loss: 0.015051
 >> iter 54000, loss: 0.014941
 >> iter 55000, loss: 0.015035
 >> iter 56000, loss: 0.014921
 >> iter 57000, loss: 0.015011
 >> iter 58000, loss: 0.014862
 >> iter 59000, loss: 0.014935
 >> iter 60000, loss: 0.014758
   Number of active neurons: 1
 >> iter 61000, loss: 0.014764
 >> iter 62000, loss: 0.014468
 >> iter 63000, loss: 0.014286
 >> iter 64000, loss: 0.013877
 >> iter 65000, loss: 0.013703
 >> iter 66000, loss: 0.013313
 >> iter 67000, loss: 0.013147
 >> iter 68000, loss: 0.012842
 >> iter 69000, loss: 0.012753
 >> iter 70000, loss: 0.012518
   Number of active neurons: 1
 >> iter 71000, loss: 0.012492
 >> iter 72000, loss: 0.012309
 >> iter 73000, loss: 0.012312
 >> iter 74000, loss: 0.012151
 >> iter 75000, loss: 0.012178
 >> iter 76000, loss: 0.012032
 >> iter 77000, loss: 0.012070
 >> iter 78000, loss: 0.011931
 >> iter 79000, loss: 0.011995
 >> iter 80000, loss: 0.011854
   Number of active neurons: 1
 >> iter 81000, loss: 0.011935
 >> iter 82000, loss: 0.011787
 >> iter 83000, loss: 0.011880
 >> iter 84000, loss: 0.011727
 >> iter 85000, loss: 0.011821
 >> iter 86000, loss: 0.011672
 >> iter 87000, loss: 0.011773
 >> iter 88000, loss: 0.011625
 >> iter 89000, loss: 0.011726
 >> iter 90000, loss: 0.011590
   Number of active neurons: 1
 >> iter 91000, loss: 0.011688
 >> iter 92000, loss: 0.011558
 >> iter 93000, loss: 0.011657
 >> iter 94000, loss: 0.011521
 >> iter 95000, loss: 0.011639
 >> iter 96000, loss: 0.011490
 >> iter 97000, loss: 0.011614
 >> iter 98000, loss: 0.011462
 >> iter 99000, loss: 0.011593
 >> iter 100000, loss: 0.011452
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.694296
 >> iter 2000, loss: 3.951794
 >> iter 3000, loss: 1.468274
 >> iter 4000, loss: 0.553153
 >> iter 5000, loss: 0.216370
 >> iter 6000, loss: 0.091881
 >> iter 7000, loss: 0.046126
 >> iter 8000, loss: 0.028768
 >> iter 9000, loss: 0.022476
 >> iter 10000, loss: 0.019770
   Number of active neurons: 4
 >> iter 11000, loss: 0.019014
 >> iter 12000, loss: 0.018429
 >> iter 13000, loss: 0.018480
 >> iter 14000, loss: 0.018166
 >> iter 15000, loss: 0.018353
 >> iter 16000, loss: 0.018128
 >> iter 17000, loss: 0.018348
 >> iter 18000, loss: 0.018145
 >> iter 19000, loss: 0.018348
 >> iter 20000, loss: 0.018157
   Number of active neurons: 3
 >> iter 21000, loss: 0.018305
 >> iter 22000, loss: 0.018065
 >> iter 23000, loss: 0.018192
 >> iter 24000, loss: 0.017910
 >> iter 25000, loss: 0.017977
 >> iter 26000, loss: 0.017626
 >> iter 27000, loss: 0.017505
 >> iter 28000, loss: 0.016944
 >> iter 29000, loss: 0.016637
 >> iter 30000, loss: 0.016012
   Number of active neurons: 2
 >> iter 31000, loss: 0.015755
 >> iter 32000, loss: 0.015266
 >> iter 33000, loss: 0.015164
 >> iter 34000, loss: 0.014845
 >> iter 35000, loss: 0.014879
 >> iter 36000, loss: 0.014639
 >> iter 37000, loss: 0.014734
 >> iter 38000, loss: 0.014531
 >> iter 39000, loss: 0.014661
 >> iter 40000, loss: 0.014474
   Number of active neurons: 2
 >> iter 41000, loss: 0.014615
 >> iter 42000, loss: 0.014445
 >> iter 43000, loss: 0.014584
 >> iter 44000, loss: 0.014432
 >> iter 45000, loss: 0.014573
 >> iter 46000, loss: 0.014423
 >> iter 47000, loss: 0.014566
 >> iter 48000, loss: 0.014428
 >> iter 49000, loss: 0.014576
 >> iter 50000, loss: 0.014433
   Number of active neurons: 2
 >> iter 51000, loss: 0.014587
 >> iter 52000, loss: 0.014456
 >> iter 53000, loss: 0.014600
 >> iter 54000, loss: 0.014493
 >> iter 55000, loss: 0.014617
 >> iter 56000, loss: 0.014518
 >> iter 57000, loss: 0.014654
 >> iter 58000, loss: 0.014539
 >> iter 59000, loss: 0.014687
 >> iter 60000, loss: 0.014578
   Number of active neurons: 2
 >> iter 61000, loss: 0.014716
 >> iter 62000, loss: 0.014615
 >> iter 63000, loss: 0.014756
 >> iter 64000, loss: 0.014644
 >> iter 65000, loss: 0.014792
 >> iter 66000, loss: 0.014686
 >> iter 67000, loss: 0.014823
 >> iter 68000, loss: 0.014736
 >> iter 69000, loss: 0.014858
 >> iter 70000, loss: 0.014759
   Number of active neurons: 2
 >> iter 71000, loss: 0.014885
 >> iter 72000, loss: 0.014791
 >> iter 73000, loss: 0.014902
 >> iter 74000, loss: 0.014794
 >> iter 75000, loss: 0.014896
 >> iter 76000, loss: 0.014774
 >> iter 77000, loss: 0.014849
 >> iter 78000, loss: 0.014697
 >> iter 79000, loss: 0.014753
 >> iter 80000, loss: 0.014515
   Number of active neurons: 1
 >> iter 81000, loss: 0.014418
 >> iter 82000, loss: 0.014007
 >> iter 83000, loss: 0.013858
 >> iter 84000, loss: 0.013452
 >> iter 85000, loss: 0.013302
 >> iter 86000, loss: 0.012929
 >> iter 87000, loss: 0.012853
 >> iter 88000, loss: 0.012566
 >> iter 89000, loss: 0.012557
 >> iter 90000, loss: 0.012333
   Number of active neurons: 1
 >> iter 91000, loss: 0.012359
 >> iter 92000, loss: 0.012169
 >> iter 93000, loss: 0.012218
 >> iter 94000, loss: 0.012039
 >> iter 95000, loss: 0.012119
 >> iter 96000, loss: 0.011937
 >> iter 97000, loss: 0.012031
 >> iter 98000, loss: 0.011852
 >> iter 99000, loss: 0.011958
 >> iter 100000, loss: 0.011795
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.734180
 >> iter 2000, loss: 3.970418
 >> iter 3000, loss: 1.478660
 >> iter 4000, loss: 0.560523
 >> iter 5000, loss: 0.222484
 >> iter 6000, loss: 0.097398
 >> iter 7000, loss: 0.051257
 >> iter 8000, loss: 0.033686
 >> iter 9000, loss: 0.027155
 >> iter 10000, loss: 0.024100
   Number of active neurons: 2
 >> iter 11000, loss: 0.022851
 >> iter 12000, loss: 0.021762
 >> iter 13000, loss: 0.021314
 >> iter 14000, loss: 0.020516
 >> iter 15000, loss: 0.020028
 >> iter 16000, loss: 0.019035
 >> iter 17000, loss: 0.018387
 >> iter 18000, loss: 0.017499
 >> iter 19000, loss: 0.017058
 >> iter 20000, loss: 0.016490
   Number of active neurons: 2
 >> iter 21000, loss: 0.016308
 >> iter 22000, loss: 0.015941
 >> iter 23000, loss: 0.015899
 >> iter 24000, loss: 0.015613
 >> iter 25000, loss: 0.015619
 >> iter 26000, loss: 0.015356
 >> iter 27000, loss: 0.015337
 >> iter 28000, loss: 0.015027
 >> iter 29000, loss: 0.014849
 >> iter 30000, loss: 0.014376
   Number of active neurons: 1
 >> iter 31000, loss: 0.014151
 >> iter 32000, loss: 0.013698
 >> iter 33000, loss: 0.013508
 >> iter 34000, loss: 0.013142
 >> iter 35000, loss: 0.013053
 >> iter 36000, loss: 0.012766
 >> iter 37000, loss: 0.012745
 >> iter 38000, loss: 0.012508
 >> iter 39000, loss: 0.012533
 >> iter 40000, loss: 0.012325
   Number of active neurons: 1
 >> iter 41000, loss: 0.012370
 >> iter 42000, loss: 0.012187
 >> iter 43000, loss: 0.012240
 >> iter 44000, loss: 0.012078
 >> iter 45000, loss: 0.012138
 >> iter 46000, loss: 0.011982
 >> iter 47000, loss: 0.012047
 >> iter 48000, loss: 0.011904
 >> iter 49000, loss: 0.011976
 >> iter 50000, loss: 0.011830
   Number of active neurons: 1
 >> iter 51000, loss: 0.011909
 >> iter 52000, loss: 0.011773
 >> iter 53000, loss: 0.011846
 >> iter 54000, loss: 0.011731
 >> iter 55000, loss: 0.011789
 >> iter 56000, loss: 0.011681
 >> iter 57000, loss: 0.011751
 >> iter 58000, loss: 0.011630
 >> iter 59000, loss: 0.011711
 >> iter 60000, loss: 0.011596
   Number of active neurons: 1
 >> iter 61000, loss: 0.011669
 >> iter 62000, loss: 0.011561
 >> iter 63000, loss: 0.011639
 >> iter 64000, loss: 0.011522
 >> iter 65000, loss: 0.011608
 >> iter 66000, loss: 0.011497
 >> iter 67000, loss: 0.011577
 >> iter 68000, loss: 0.011481
 >> iter 69000, loss: 0.011554
 >> iter 70000, loss: 0.011452
   Number of active neurons: 1
 >> iter 71000, loss: 0.011532
 >> iter 72000, loss: 0.011437
 >> iter 73000, loss: 0.011514
 >> iter 74000, loss: 0.011416
 >> iter 75000, loss: 0.011498
 >> iter 76000, loss: 0.011400
 >> iter 77000, loss: 0.011480
 >> iter 78000, loss: 0.011379
 >> iter 79000, loss: 0.011478
 >> iter 80000, loss: 0.011369
   Number of active neurons: 1
 >> iter 81000, loss: 0.011479
 >> iter 82000, loss: 0.011359
 >> iter 83000, loss: 0.011476
 >> iter 84000, loss: 0.011347
 >> iter 85000, loss: 0.011463
 >> iter 86000, loss: 0.011335
 >> iter 87000, loss: 0.011455
 >> iter 88000, loss: 0.011326
 >> iter 89000, loss: 0.011444
 >> iter 90000, loss: 0.011324
   Number of active neurons: 1
 >> iter 91000, loss: 0.011437
 >> iter 92000, loss: 0.011321
 >> iter 93000, loss: 0.011434
 >> iter 94000, loss: 0.011311
 >> iter 95000, loss: 0.011441
 >> iter 96000, loss: 0.011303
 >> iter 97000, loss: 0.011438
 >> iter 98000, loss: 0.011296
 >> iter 99000, loss: 0.011436
 >> iter 100000, loss: 0.011304
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.692720
 >> iter 2000, loss: 3.951395
 >> iter 3000, loss: 1.468407
 >> iter 4000, loss: 0.553387
 >> iter 5000, loss: 0.216525
 >> iter 6000, loss: 0.091892
 >> iter 7000, loss: 0.046048
 >> iter 8000, loss: 0.028671
 >> iter 9000, loss: 0.022408
 >> iter 10000, loss: 0.019671
   Number of active neurons: 4
 >> iter 11000, loss: 0.018894
 >> iter 12000, loss: 0.018258
 >> iter 13000, loss: 0.018314
 >> iter 14000, loss: 0.017995
 >> iter 15000, loss: 0.018176
 >> iter 16000, loss: 0.017910
 >> iter 17000, loss: 0.018087
 >> iter 18000, loss: 0.017815
 >> iter 19000, loss: 0.017901
 >> iter 20000, loss: 0.017520
   Number of active neurons: 3
 >> iter 21000, loss: 0.017518
 >> iter 22000, loss: 0.017113
 >> iter 23000, loss: 0.017061
 >> iter 24000, loss: 0.016587
 >> iter 25000, loss: 0.016428
 >> iter 26000, loss: 0.015882
 >> iter 27000, loss: 0.015754
 >> iter 28000, loss: 0.015262
 >> iter 29000, loss: 0.015150
 >> iter 30000, loss: 0.014711
   Number of active neurons: 2
 >> iter 31000, loss: 0.014657
 >> iter 32000, loss: 0.014301
 >> iter 33000, loss: 0.014345
 >> iter 34000, loss: 0.014070
 >> iter 35000, loss: 0.014181
 >> iter 36000, loss: 0.013932
 >> iter 37000, loss: 0.014069
 >> iter 38000, loss: 0.013834
 >> iter 39000, loss: 0.013992
 >> iter 40000, loss: 0.013760
   Number of active neurons: 2
 >> iter 41000, loss: 0.013924
 >> iter 42000, loss: 0.013709
 >> iter 43000, loss: 0.013865
 >> iter 44000, loss: 0.013662
 >> iter 45000, loss: 0.013829
 >> iter 46000, loss: 0.013621
 >> iter 47000, loss: 0.013788
 >> iter 48000, loss: 0.013592
 >> iter 49000, loss: 0.013766
 >> iter 50000, loss: 0.013563
   Number of active neurons: 2
 >> iter 51000, loss: 0.013740
 >> iter 52000, loss: 0.013545
 >> iter 53000, loss: 0.013713
 >> iter 54000, loss: 0.013546
 >> iter 55000, loss: 0.013690
 >> iter 56000, loss: 0.013534
 >> iter 57000, loss: 0.013689
 >> iter 58000, loss: 0.013512
 >> iter 59000, loss: 0.013678
 >> iter 60000, loss: 0.013507
   Number of active neurons: 2
 >> iter 61000, loss: 0.013664
 >> iter 62000, loss: 0.013502
 >> iter 63000, loss: 0.013658
 >> iter 64000, loss: 0.013487
 >> iter 65000, loss: 0.013655
 >> iter 66000, loss: 0.013487
 >> iter 67000, loss: 0.013644
 >> iter 68000, loss: 0.013496
 >> iter 69000, loss: 0.013643
 >> iter 70000, loss: 0.013486
   Number of active neurons: 2
 >> iter 71000, loss: 0.013642
 >> iter 72000, loss: 0.013493
 >> iter 73000, loss: 0.013644
 >> iter 74000, loss: 0.013491
 >> iter 75000, loss: 0.013648
 >> iter 76000, loss: 0.013495
 >> iter 77000, loss: 0.013648
 >> iter 78000, loss: 0.013492
 >> iter 79000, loss: 0.013672
 >> iter 80000, loss: 0.013502
   Number of active neurons: 2
 >> iter 81000, loss: 0.013699
 >> iter 82000, loss: 0.013512
 >> iter 83000, loss: 0.013723
 >> iter 84000, loss: 0.013521
 >> iter 85000, loss: 0.013731
 >> iter 86000, loss: 0.013532
 >> iter 87000, loss: 0.013746
 >> iter 88000, loss: 0.013547
 >> iter 89000, loss: 0.013758
 >> iter 90000, loss: 0.013575
   Number of active neurons: 2
 >> iter 91000, loss: 0.013777
 >> iter 92000, loss: 0.013605
 >> iter 93000, loss: 0.013809
 >> iter 94000, loss: 0.013628
 >> iter 95000, loss: 0.013855
 >> iter 96000, loss: 0.013660
 >> iter 97000, loss: 0.013892
 >> iter 98000, loss: 0.013694
 >> iter 99000, loss: 0.013931
 >> iter 100000, loss: 0.013751
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.686149
 >> iter 2000, loss: 3.949956
 >> iter 3000, loss: 1.468063
 >> iter 4000, loss: 0.553313
 >> iter 5000, loss: 0.216359
 >> iter 6000, loss: 0.091707
 >> iter 7000, loss: 0.045731
 >> iter 8000, loss: 0.028245
 >> iter 9000, loss: 0.021758
 >> iter 10000, loss: 0.018852
   Number of active neurons: 3
 >> iter 11000, loss: 0.017833
 >> iter 12000, loss: 0.017100
 >> iter 13000, loss: 0.017026
 >> iter 14000, loss: 0.016706
 >> iter 15000, loss: 0.016812
 >> iter 16000, loss: 0.016573
 >> iter 17000, loss: 0.016729
 >> iter 18000, loss: 0.016534
 >> iter 19000, loss: 0.016693
 >> iter 20000, loss: 0.016518
   Number of active neurons: 2
 >> iter 21000, loss: 0.016638
 >> iter 22000, loss: 0.016433
 >> iter 23000, loss: 0.016554
 >> iter 24000, loss: 0.016321
 >> iter 25000, loss: 0.016403
 >> iter 26000, loss: 0.016115
 >> iter 27000, loss: 0.016062
 >> iter 28000, loss: 0.015656
 >> iter 29000, loss: 0.015563
 >> iter 30000, loss: 0.015192
   Number of active neurons: 2
 >> iter 31000, loss: 0.015145
 >> iter 32000, loss: 0.014857
 >> iter 33000, loss: 0.014901
 >> iter 34000, loss: 0.014689
 >> iter 35000, loss: 0.014794
 >> iter 36000, loss: 0.014608
 >> iter 37000, loss: 0.014739
 >> iter 38000, loss: 0.014567
 >> iter 39000, loss: 0.014719
 >> iter 40000, loss: 0.014553
   Number of active neurons: 2
 >> iter 41000, loss: 0.014709
 >> iter 42000, loss: 0.014556
 >> iter 43000, loss: 0.014706
 >> iter 44000, loss: 0.014570
 >> iter 45000, loss: 0.014721
 >> iter 46000, loss: 0.014586
 >> iter 47000, loss: 0.014737
 >> iter 48000, loss: 0.014613
 >> iter 49000, loss: 0.014768
 >> iter 50000, loss: 0.014639
   Number of active neurons: 2
 >> iter 51000, loss: 0.014797
 >> iter 52000, loss: 0.014678
 >> iter 53000, loss: 0.014825
 >> iter 54000, loss: 0.014729
 >> iter 55000, loss: 0.014852
 >> iter 56000, loss: 0.014761
 >> iter 57000, loss: 0.014893
 >> iter 58000, loss: 0.014782
 >> iter 59000, loss: 0.014920
 >> iter 60000, loss: 0.014810
   Number of active neurons: 2
 >> iter 61000, loss: 0.014929
 >> iter 62000, loss: 0.014819
 >> iter 63000, loss: 0.014928
 >> iter 64000, loss: 0.014792
 >> iter 65000, loss: 0.014887
 >> iter 66000, loss: 0.014732
 >> iter 67000, loss: 0.014780
 >> iter 68000, loss: 0.014588
 >> iter 69000, loss: 0.014485
 >> iter 70000, loss: 0.014103
   Number of active neurons: 1
 >> iter 71000, loss: 0.013916
 >> iter 72000, loss: 0.013548
 >> iter 73000, loss: 0.013360
 >> iter 74000, loss: 0.013009
 >> iter 75000, loss: 0.012886
 >> iter 76000, loss: 0.012623
 >> iter 77000, loss: 0.012572
 >> iter 78000, loss: 0.012363
 >> iter 79000, loss: 0.012374
 >> iter 80000, loss: 0.012190
   Number of active neurons: 1
 >> iter 81000, loss: 0.012236
 >> iter 82000, loss: 0.012060
 >> iter 83000, loss: 0.012130
 >> iter 84000, loss: 0.011957
 >> iter 85000, loss: 0.012033
 >> iter 86000, loss: 0.011869
 >> iter 87000, loss: 0.011956
 >> iter 88000, loss: 0.011797
 >> iter 89000, loss: 0.011887
 >> iter 90000, loss: 0.011740
   Number of active neurons: 1
 >> iter 91000, loss: 0.011829
 >> iter 92000, loss: 0.011690
 >> iter 93000, loss: 0.011782
 >> iter 94000, loss: 0.011639
 >> iter 95000, loss: 0.011750
 >> iter 96000, loss: 0.011594
 >> iter 97000, loss: 0.011712
 >> iter 98000, loss: 0.011554
 >> iter 99000, loss: 0.011680
 >> iter 100000, loss: 0.011534
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.695050
 >> iter 2000, loss: 3.952957
 >> iter 3000, loss: 1.469162
 >> iter 4000, loss: 0.553920
 >> iter 5000, loss: 0.216964
 >> iter 6000, loss: 0.092450
 >> iter 7000, loss: 0.046687
 >> iter 8000, loss: 0.029392
 >> iter 9000, loss: 0.023095
 >> iter 10000, loss: 0.020296
   Number of active neurons: 2
 >> iter 11000, loss: 0.019289
 >> iter 12000, loss: 0.018383
 >> iter 13000, loss: 0.018026
 >> iter 14000, loss: 0.017282
 >> iter 15000, loss: 0.016900
 >> iter 16000, loss: 0.016169
 >> iter 17000, loss: 0.015854
 >> iter 18000, loss: 0.015296
 >> iter 19000, loss: 0.015173
 >> iter 20000, loss: 0.014836
   Number of active neurons: 2
 >> iter 21000, loss: 0.014833
 >> iter 22000, loss: 0.014569
 >> iter 23000, loss: 0.014647
 >> iter 24000, loss: 0.014437
 >> iter 25000, loss: 0.014560
 >> iter 26000, loss: 0.014385
 >> iter 27000, loss: 0.014499
 >> iter 28000, loss: 0.014325
 >> iter 29000, loss: 0.014455
 >> iter 30000, loss: 0.014301
   Number of active neurons: 2
 >> iter 31000, loss: 0.014440
 >> iter 32000, loss: 0.014287
 >> iter 33000, loss: 0.014427
 >> iter 34000, loss: 0.014277
 >> iter 35000, loss: 0.014429
 >> iter 36000, loss: 0.014271
 >> iter 37000, loss: 0.014426
 >> iter 38000, loss: 0.014267
 >> iter 39000, loss: 0.014431
 >> iter 40000, loss: 0.014271
   Number of active neurons: 2
 >> iter 41000, loss: 0.014435
 >> iter 42000, loss: 0.014285
 >> iter 43000, loss: 0.014440
 >> iter 44000, loss: 0.014304
 >> iter 45000, loss: 0.014459
 >> iter 46000, loss: 0.014322
 >> iter 47000, loss: 0.014477
 >> iter 48000, loss: 0.014349
 >> iter 49000, loss: 0.014507
 >> iter 50000, loss: 0.014374
   Number of active neurons: 2
 >> iter 51000, loss: 0.014537
 >> iter 52000, loss: 0.014414
 >> iter 53000, loss: 0.014565
 >> iter 54000, loss: 0.014467
 >> iter 55000, loss: 0.014596
 >> iter 56000, loss: 0.014504
 >> iter 57000, loss: 0.014645
 >> iter 58000, loss: 0.014536
 >> iter 59000, loss: 0.014688
 >> iter 60000, loss: 0.014585
   Number of active neurons: 2
 >> iter 61000, loss: 0.014725
 >> iter 62000, loss: 0.014629
 >> iter 63000, loss: 0.014771
 >> iter 64000, loss: 0.014662
 >> iter 65000, loss: 0.014810
 >> iter 66000, loss: 0.014706
 >> iter 67000, loss: 0.014841
 >> iter 68000, loss: 0.014753
 >> iter 69000, loss: 0.014870
 >> iter 70000, loss: 0.014768
   Number of active neurons: 2
 >> iter 71000, loss: 0.014885
 >> iter 72000, loss: 0.014782
 >> iter 73000, loss: 0.014876
 >> iter 74000, loss: 0.014752
 >> iter 75000, loss: 0.014826
 >> iter 76000, loss: 0.014672
 >> iter 77000, loss: 0.014694
 >> iter 78000, loss: 0.014429
 >> iter 79000, loss: 0.014284
 >> iter 80000, loss: 0.013885
   Number of active neurons: 1
 >> iter 81000, loss: 0.013735
 >> iter 82000, loss: 0.013338
 >> iter 83000, loss: 0.013198
 >> iter 84000, loss: 0.012842
 >> iter 85000, loss: 0.012780
 >> iter 86000, loss: 0.012508
 >> iter 87000, loss: 0.012512
 >> iter 88000, loss: 0.012287
 >> iter 89000, loss: 0.012323
 >> iter 90000, loss: 0.012135
   Number of active neurons: 1
 >> iter 91000, loss: 0.012188
 >> iter 92000, loss: 0.012019
 >> iter 93000, loss: 0.012085
 >> iter 94000, loss: 0.011920
 >> iter 95000, loss: 0.012011
 >> iter 96000, loss: 0.011838
 >> iter 97000, loss: 0.011940
 >> iter 98000, loss: 0.011768
 >> iter 99000, loss: 0.011880
 >> iter 100000, loss: 0.011723
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.694143
 >> iter 2000, loss: 3.952638
 >> iter 3000, loss: 1.469022
 >> iter 4000, loss: 0.553605
 >> iter 5000, loss: 0.216394
 >> iter 6000, loss: 0.091577
 >> iter 7000, loss: 0.045504
 >> iter 8000, loss: 0.027953
 >> iter 9000, loss: 0.021467
 >> iter 10000, loss: 0.018568
   Number of active neurons: 3
 >> iter 11000, loss: 0.017594
 >> iter 12000, loss: 0.016863
 >> iter 13000, loss: 0.016809
 >> iter 14000, loss: 0.016475
 >> iter 15000, loss: 0.016610
 >> iter 16000, loss: 0.016351
 >> iter 17000, loss: 0.016499
 >> iter 18000, loss: 0.016273
 >> iter 19000, loss: 0.016439
 >> iter 20000, loss: 0.016247
   Number of active neurons: 3
 >> iter 21000, loss: 0.016409
 >> iter 22000, loss: 0.016210
 >> iter 23000, loss: 0.016370
 >> iter 24000, loss: 0.016158
 >> iter 25000, loss: 0.016307
 >> iter 26000, loss: 0.016088
 >> iter 27000, loss: 0.016195
 >> iter 28000, loss: 0.015929
 >> iter 29000, loss: 0.015947
 >> iter 30000, loss: 0.015562
   Number of active neurons: 2
 >> iter 31000, loss: 0.015471
 >> iter 32000, loss: 0.015086
 >> iter 33000, loss: 0.015027
 >> iter 34000, loss: 0.014687
 >> iter 35000, loss: 0.014699
 >> iter 36000, loss: 0.014446
 >> iter 37000, loss: 0.014541
 >> iter 38000, loss: 0.014338
 >> iter 39000, loss: 0.014472
 >> iter 40000, loss: 0.014285
   Number of active neurons: 2
 >> iter 41000, loss: 0.014430
 >> iter 42000, loss: 0.014260
 >> iter 43000, loss: 0.014401
 >> iter 44000, loss: 0.014249
 >> iter 45000, loss: 0.014393
 >> iter 46000, loss: 0.014241
 >> iter 47000, loss: 0.014386
 >> iter 48000, loss: 0.014245
 >> iter 49000, loss: 0.014394
 >> iter 50000, loss: 0.014248
   Number of active neurons: 2
 >> iter 51000, loss: 0.014402
 >> iter 52000, loss: 0.014266
 >> iter 53000, loss: 0.014410
 >> iter 54000, loss: 0.014299
 >> iter 55000, loss: 0.014422
 >> iter 56000, loss: 0.014319
 >> iter 57000, loss: 0.014454
 >> iter 58000, loss: 0.014333
 >> iter 59000, loss: 0.014481
 >> iter 60000, loss: 0.014366
   Number of active neurons: 2
 >> iter 61000, loss: 0.014504
 >> iter 62000, loss: 0.014398
 >> iter 63000, loss: 0.014539
 >> iter 64000, loss: 0.014423
 >> iter 65000, loss: 0.014573
 >> iter 66000, loss: 0.014463
 >> iter 67000, loss: 0.014605
 >> iter 68000, loss: 0.014516
 >> iter 69000, loss: 0.014646
 >> iter 70000, loss: 0.014549
   Number of active neurons: 2
 >> iter 71000, loss: 0.014688
 >> iter 72000, loss: 0.014600
 >> iter 73000, loss: 0.014732
 >> iter 74000, loss: 0.014639
 >> iter 75000, loss: 0.014775
 >> iter 76000, loss: 0.014681
 >> iter 77000, loss: 0.014810
 >> iter 78000, loss: 0.014711
 >> iter 79000, loss: 0.014859
 >> iter 80000, loss: 0.014746
   Number of active neurons: 2
 >> iter 81000, loss: 0.014899
 >> iter 82000, loss: 0.014766
 >> iter 83000, loss: 0.014916
 >> iter 84000, loss: 0.014761
 >> iter 85000, loss: 0.014887
 >> iter 86000, loss: 0.014714
 >> iter 87000, loss: 0.014810
 >> iter 88000, loss: 0.014598
 >> iter 89000, loss: 0.014585
 >> iter 90000, loss: 0.014211
   Number of active neurons: 1
 >> iter 91000, loss: 0.014051
 >> iter 92000, loss: 0.013652
 >> iter 93000, loss: 0.013501
 >> iter 94000, loss: 0.013106
 >> iter 95000, loss: 0.013005
 >> iter 96000, loss: 0.012678
 >> iter 97000, loss: 0.012663
 >> iter 98000, loss: 0.012399
 >> iter 99000, loss: 0.012439
 >> iter 100000, loss: 0.012224
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.743116
 >> iter 2000, loss: 3.970728
 >> iter 3000, loss: 1.476206
 >> iter 4000, loss: 0.557222
 >> iter 5000, loss: 0.218995
 >> iter 6000, loss: 0.094142
 >> iter 7000, loss: 0.048385
 >> iter 8000, loss: 0.031240
 >> iter 9000, loss: 0.025163
 >> iter 10000, loss: 0.022572
   Number of active neurons: 4
 >> iter 11000, loss: 0.021752
 >> iter 12000, loss: 0.021005
 >> iter 13000, loss: 0.020847
 >> iter 14000, loss: 0.020314
 >> iter 15000, loss: 0.020216
 >> iter 16000, loss: 0.019666
 >> iter 17000, loss: 0.019475
 >> iter 18000, loss: 0.018880
 >> iter 19000, loss: 0.018613
 >> iter 20000, loss: 0.017924
   Number of active neurons: 2
 >> iter 21000, loss: 0.017485
 >> iter 22000, loss: 0.016762
 >> iter 23000, loss: 0.016413
 >> iter 24000, loss: 0.015860
 >> iter 25000, loss: 0.015732
 >> iter 26000, loss: 0.015390
 >> iter 27000, loss: 0.015403
 >> iter 28000, loss: 0.015170
 >> iter 29000, loss: 0.015243
 >> iter 30000, loss: 0.015058
   Number of active neurons: 2
 >> iter 31000, loss: 0.015167
 >> iter 32000, loss: 0.015004
 >> iter 33000, loss: 0.015127
 >> iter 34000, loss: 0.014978
 >> iter 35000, loss: 0.015118
 >> iter 36000, loss: 0.014965
 >> iter 37000, loss: 0.015111
 >> iter 38000, loss: 0.014958
 >> iter 39000, loss: 0.015112
 >> iter 40000, loss: 0.014957
   Number of active neurons: 2
 >> iter 41000, loss: 0.015105
 >> iter 42000, loss: 0.014957
 >> iter 43000, loss: 0.015090
 >> iter 44000, loss: 0.014949
 >> iter 45000, loss: 0.015067
 >> iter 46000, loss: 0.014914
 >> iter 47000, loss: 0.015011
 >> iter 48000, loss: 0.014844
 >> iter 49000, loss: 0.014906
 >> iter 50000, loss: 0.014690
   Number of active neurons: 1
 >> iter 51000, loss: 0.014648
 >> iter 52000, loss: 0.014258
 >> iter 53000, loss: 0.014069
 >> iter 54000, loss: 0.013683
 >> iter 55000, loss: 0.013488
 >> iter 56000, loss: 0.013126
 >> iter 57000, loss: 0.012991
 >> iter 58000, loss: 0.012704
 >> iter 59000, loss: 0.012657
 >> iter 60000, loss: 0.012436
   Number of active neurons: 1
 >> iter 61000, loss: 0.012427
 >> iter 62000, loss: 0.012249
 >> iter 63000, loss: 0.012269
 >> iter 64000, loss: 0.012102
 >> iter 65000, loss: 0.012146
 >> iter 66000, loss: 0.011996
 >> iter 67000, loss: 0.012043
 >> iter 68000, loss: 0.011917
 >> iter 69000, loss: 0.011963
 >> iter 70000, loss: 0.011835
   Number of active neurons: 1
 >> iter 71000, loss: 0.011893
 >> iter 72000, loss: 0.011777
 >> iter 73000, loss: 0.011834
 >> iter 74000, loss: 0.011716
 >> iter 75000, loss: 0.011781
 >> iter 76000, loss: 0.011666
 >> iter 77000, loss: 0.011731
 >> iter 78000, loss: 0.011616
 >> iter 79000, loss: 0.011701
 >> iter 80000, loss: 0.011579
   Number of active neurons: 1
 >> iter 81000, loss: 0.011677
 >> iter 82000, loss: 0.011546
 >> iter 83000, loss: 0.011653
 >> iter 84000, loss: 0.011514
 >> iter 85000, loss: 0.011621
 >> iter 86000, loss: 0.011483
 >> iter 87000, loss: 0.011595
 >> iter 88000, loss: 0.011458
 >> iter 89000, loss: 0.011568
 >> iter 90000, loss: 0.011441
   Number of active neurons: 1
 >> iter 91000, loss: 0.011548
 >> iter 92000, loss: 0.011425
 >> iter 93000, loss: 0.011533
 >> iter 94000, loss: 0.011404
 >> iter 95000, loss: 0.011528
 >> iter 96000, loss: 0.011386
 >> iter 97000, loss: 0.011516
 >> iter 98000, loss: 0.011369
 >> iter 99000, loss: 0.011505
 >> iter 100000, loss: 0.011369
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 10.727012
 >> iter 2000, loss: 3.963965
 >> iter 3000, loss: 1.473309
 >> iter 4000, loss: 0.555736
 >> iter 5000, loss: 0.218074
 >> iter 6000, loss: 0.093314
 >> iter 7000, loss: 0.047521
 >> iter 8000, loss: 0.030250
 >> iter 9000, loss: 0.024082
 >> iter 10000, loss: 0.021423
   Number of active neurons: 4
 >> iter 11000, loss: 0.020597
 >> iter 12000, loss: 0.019875
 >> iter 13000, loss: 0.019821
 >> iter 14000, loss: 0.019401
 >> iter 15000, loss: 0.019432
 >> iter 16000, loss: 0.018976
 >> iter 17000, loss: 0.018888
 >> iter 18000, loss: 0.018368
 >> iter 19000, loss: 0.018218
 >> iter 20000, loss: 0.017719
   Number of active neurons: 3
 >> iter 21000, loss: 0.017617
 >> iter 22000, loss: 0.017213
 >> iter 23000, loss: 0.017232
 >> iter 24000, loss: 0.016950
 >> iter 25000, loss: 0.017076
 >> iter 26000, loss: 0.016872
 >> iter 27000, loss: 0.017032
 >> iter 28000, loss: 0.016859
 >> iter 29000, loss: 0.017022
 >> iter 30000, loss: 0.016858
   Number of active neurons: 3
 >> iter 31000, loss: 0.017028
 >> iter 32000, loss: 0.016863
 >> iter 33000, loss: 0.017028
 >> iter 34000, loss: 0.016861
 >> iter 35000, loss: 0.017025
 >> iter 36000, loss: 0.016834
 >> iter 37000, loss: 0.016976
 >> iter 38000, loss: 0.016756
 >> iter 39000, loss: 0.016865
 >> iter 40000, loss: 0.016589
   Number of active neurons: 2
 >> iter 41000, loss: 0.016563
 >> iter 42000, loss: 0.016155
 >> iter 43000, loss: 0.016074
 >> iter 44000, loss: 0.015710
 >> iter 45000, loss: 0.015653
 >> iter 46000, loss: 0.015358
 >> iter 47000, loss: 0.015390
 >> iter 48000, loss: 0.015183
 >> iter 49000, loss: 0.015271
 >> iter 50000, loss: 0.015096
   Number of active neurons: 2
 >> iter 51000, loss: 0.015211
 >> iter 52000, loss: 0.015063
 >> iter 53000, loss: 0.015173
 >> iter 54000, loss: 0.015051
 >> iter 55000, loss: 0.015137
 >> iter 56000, loss: 0.015016
 >> iter 57000, loss: 0.015100
 >> iter 58000, loss: 0.014948
 >> iter 59000, loss: 0.015019
 >> iter 60000, loss: 0.014842
   Number of active neurons: 1
 >> iter 61000, loss: 0.014854
 >> iter 62000, loss: 0.014589
 >> iter 63000, loss: 0.014417
 >> iter 64000, loss: 0.014000
 >> iter 65000, loss: 0.013816
 >> iter 66000, loss: 0.013421
 >> iter 67000, loss: 0.013243
 >> iter 68000, loss: 0.012923
 >> iter 69000, loss: 0.012822
 >> iter 70000, loss: 0.012577
   Number of active neurons: 1
 >> iter 71000, loss: 0.012544
 >> iter 72000, loss: 0.012355
 >> iter 73000, loss: 0.012354
 >> iter 74000, loss: 0.012188
 >> iter 75000, loss: 0.012213
 >> iter 76000, loss: 0.012064
 >> iter 77000, loss: 0.012099
 >> iter 78000, loss: 0.011958
 >> iter 79000, loss: 0.012021
 >> iter 80000, loss: 0.011878
   Number of active neurons: 1
 >> iter 81000, loss: 0.011957
 >> iter 82000, loss: 0.011808
 >> iter 83000, loss: 0.011900
 >> iter 84000, loss: 0.011746
 >> iter 85000, loss: 0.011839
 >> iter 86000, loss: 0.011689
 >> iter 87000, loss: 0.011789
 >> iter 88000, loss: 0.011640
 >> iter 89000, loss: 0.011740
 >> iter 90000, loss: 0.011603
   Number of active neurons: 1
 >> iter 91000, loss: 0.011701
 >> iter 92000, loss: 0.011569
 >> iter 93000, loss: 0.011669
 >> iter 94000, loss: 0.011532
 >> iter 95000, loss: 0.011649
 >> iter 96000, loss: 0.011499
 >> iter 97000, loss: 0.011623
 >> iter 98000, loss: 0.011470
 >> iter 99000, loss: 0.011601
 >> iter 100000, loss: 0.011459
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.716941
 >> iter 2000, loss: 3.964419
 >> iter 3000, loss: 1.476166
 >> iter 4000, loss: 0.558910
 >> iter 5000, loss: 0.220784
 >> iter 6000, loss: 0.095293
 >> iter 7000, loss: 0.048435
 >> iter 8000, loss: 0.030089
 >> iter 9000, loss: 0.022755
 >> iter 10000, loss: 0.019206
   Number of active neurons: 2
 >> iter 11000, loss: 0.017634
 >> iter 12000, loss: 0.016511
 >> iter 13000, loss: 0.016094
 >> iter 14000, loss: 0.015582
 >> iter 15000, loss: 0.015514
 >> iter 16000, loss: 0.015214
 >> iter 17000, loss: 0.015270
 >> iter 18000, loss: 0.015056
 >> iter 19000, loss: 0.015154
 >> iter 20000, loss: 0.014987
   Number of active neurons: 2
 >> iter 21000, loss: 0.015101
 >> iter 22000, loss: 0.014941
 >> iter 23000, loss: 0.015073
 >> iter 24000, loss: 0.014915
 >> iter 25000, loss: 0.015060
 >> iter 26000, loss: 0.014914
 >> iter 27000, loss: 0.015056
 >> iter 28000, loss: 0.014917
 >> iter 29000, loss: 0.015051
 >> iter 30000, loss: 0.014915
   Number of active neurons: 2
 >> iter 31000, loss: 0.015054
 >> iter 32000, loss: 0.014918
 >> iter 33000, loss: 0.015056
 >> iter 34000, loss: 0.014923
 >> iter 35000, loss: 0.015068
 >> iter 36000, loss: 0.014923
 >> iter 37000, loss: 0.015063
 >> iter 38000, loss: 0.014910
 >> iter 39000, loss: 0.015045
 >> iter 40000, loss: 0.014878
   Number of active neurons: 1
 >> iter 41000, loss: 0.014990
 >> iter 42000, loss: 0.014809
 >> iter 43000, loss: 0.014875
 >> iter 44000, loss: 0.014663
 >> iter 45000, loss: 0.014612
 >> iter 46000, loss: 0.014214
 >> iter 47000, loss: 0.014033
 >> iter 48000, loss: 0.013632
 >> iter 49000, loss: 0.013464
 >> iter 50000, loss: 0.013078
   Number of active neurons: 1
 >> iter 51000, loss: 0.012965
 >> iter 52000, loss: 0.012676
 >> iter 53000, loss: 0.012631
 >> iter 54000, loss: 0.012422
 >> iter 55000, loss: 0.012405
 >> iter 56000, loss: 0.012236
 >> iter 57000, loss: 0.012255
 >> iter 58000, loss: 0.012092
 >> iter 59000, loss: 0.012137
 >> iter 60000, loss: 0.011990
   Number of active neurons: 1
 >> iter 61000, loss: 0.012037
 >> iter 62000, loss: 0.011904
 >> iter 63000, loss: 0.011959
 >> iter 64000, loss: 0.011823
 >> iter 65000, loss: 0.011890
 >> iter 66000, loss: 0.011762
 >> iter 67000, loss: 0.011826
 >> iter 68000, loss: 0.011716
 >> iter 69000, loss: 0.011775
 >> iter 70000, loss: 0.011660
   Number of active neurons: 1
 >> iter 71000, loss: 0.011728
 >> iter 72000, loss: 0.011622
 >> iter 73000, loss: 0.011688
 >> iter 74000, loss: 0.011580
 >> iter 75000, loss: 0.011652
 >> iter 76000, loss: 0.011545
 >> iter 77000, loss: 0.011617
 >> iter 78000, loss: 0.011508
 >> iter 79000, loss: 0.011600
 >> iter 80000, loss: 0.011484
   Number of active neurons: 1
 >> iter 81000, loss: 0.011587
 >> iter 82000, loss: 0.011461
 >> iter 83000, loss: 0.011573
 >> iter 84000, loss: 0.011438
 >> iter 85000, loss: 0.011549
 >> iter 86000, loss: 0.011416
 >> iter 87000, loss: 0.011532
 >> iter 88000, loss: 0.011398
 >> iter 89000, loss: 0.011512
 >> iter 90000, loss: 0.011388
   Number of active neurons: 1
 >> iter 91000, loss: 0.011497
 >> iter 92000, loss: 0.011378
 >> iter 93000, loss: 0.011488
 >> iter 94000, loss: 0.011362
 >> iter 95000, loss: 0.011489
 >> iter 96000, loss: 0.011348
 >> iter 97000, loss: 0.011480
 >> iter 98000, loss: 0.011336
 >> iter 99000, loss: 0.011474
 >> iter 100000, loss: 0.011340
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.764509
 >> iter 2000, loss: 3.979266
 >> iter 3000, loss: 1.479353
 >> iter 4000, loss: 0.558112
 >> iter 5000, loss: 0.218889
 >> iter 6000, loss: 0.093465
 >> iter 7000, loss: 0.047234
 >> iter 8000, loss: 0.029693
 >> iter 9000, loss: 0.023176
 >> iter 10000, loss: 0.020181
   Number of active neurons: 3
 >> iter 11000, loss: 0.019015
 >> iter 12000, loss: 0.018061
 >> iter 13000, loss: 0.017776
 >> iter 14000, loss: 0.017303
 >> iter 15000, loss: 0.017328
 >> iter 16000, loss: 0.017056
 >> iter 17000, loss: 0.017196
 >> iter 18000, loss: 0.017001
 >> iter 19000, loss: 0.017171
 >> iter 20000, loss: 0.017018
   Number of active neurons: 3
 >> iter 21000, loss: 0.017196
 >> iter 22000, loss: 0.017045
 >> iter 23000, loss: 0.017237
 >> iter 24000, loss: 0.017082
 >> iter 25000, loss: 0.017283
 >> iter 26000, loss: 0.017138
 >> iter 27000, loss: 0.017328
 >> iter 28000, loss: 0.017186
 >> iter 29000, loss: 0.017357
 >> iter 30000, loss: 0.017208
   Number of active neurons: 2
 >> iter 31000, loss: 0.017369
 >> iter 32000, loss: 0.017205
 >> iter 33000, loss: 0.017338
 >> iter 34000, loss: 0.017149
 >> iter 35000, loss: 0.017244
 >> iter 36000, loss: 0.016978
 >> iter 37000, loss: 0.016903
 >> iter 38000, loss: 0.016476
 >> iter 39000, loss: 0.016373
 >> iter 40000, loss: 0.015958
   Number of active neurons: 1
 >> iter 41000, loss: 0.015863
 >> iter 42000, loss: 0.015516
 >> iter 43000, loss: 0.015463
 >> iter 44000, loss: 0.015160
 >> iter 45000, loss: 0.015074
 >> iter 46000, loss: 0.014645
 >> iter 47000, loss: 0.014409
 >> iter 48000, loss: 0.013954
 >> iter 49000, loss: 0.013741
 >> iter 50000, loss: 0.013321
   Number of active neurons: 1
 >> iter 51000, loss: 0.013184
 >> iter 52000, loss: 0.012874
 >> iter 53000, loss: 0.012812
 >> iter 54000, loss: 0.012588
 >> iter 55000, loss: 0.012559
 >> iter 56000, loss: 0.012379
 >> iter 57000, loss: 0.012390
 >> iter 58000, loss: 0.012219
 >> iter 59000, loss: 0.012256
 >> iter 60000, loss: 0.012103
   Number of active neurons: 1
 >> iter 61000, loss: 0.012143
 >> iter 62000, loss: 0.012004
 >> iter 63000, loss: 0.012055
 >> iter 64000, loss: 0.011913
 >> iter 65000, loss: 0.011976
 >> iter 66000, loss: 0.011842
 >> iter 67000, loss: 0.011903
 >> iter 68000, loss: 0.011788
 >> iter 69000, loss: 0.011843
 >> iter 70000, loss: 0.011724
   Number of active neurons: 1
 >> iter 71000, loss: 0.011789
 >> iter 72000, loss: 0.011680
 >> iter 73000, loss: 0.011743
 >> iter 74000, loss: 0.011631
 >> iter 75000, loss: 0.011701
 >> iter 76000, loss: 0.011591
 >> iter 77000, loss: 0.011660
 >> iter 78000, loss: 0.011549
 >> iter 79000, loss: 0.011639
 >> iter 80000, loss: 0.011520
   Number of active neurons: 1
 >> iter 81000, loss: 0.011622
 >> iter 82000, loss: 0.011493
 >> iter 83000, loss: 0.011604
 >> iter 84000, loss: 0.011467
 >> iter 85000, loss: 0.011577
 >> iter 86000, loss: 0.011442
 >> iter 87000, loss: 0.011556
 >> iter 88000, loss: 0.011421
 >> iter 89000, loss: 0.011533
 >> iter 90000, loss: 0.011408
   Number of active neurons: 1
 >> iter 91000, loss: 0.011517
 >> iter 92000, loss: 0.011396
 >> iter 93000, loss: 0.011505
 >> iter 94000, loss: 0.011378
 >> iter 95000, loss: 0.011504
 >> iter 96000, loss: 0.011363
 >> iter 97000, loss: 0.011494
 >> iter 98000, loss: 0.011349
 >> iter 99000, loss: 0.011486
 >> iter 100000, loss: 0.011351
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.733000
 >> iter 2000, loss: 3.966023
 >> iter 3000, loss: 1.474004
 >> iter 4000, loss: 0.555679
 >> iter 5000, loss: 0.217733
 >> iter 6000, loss: 0.092727
 >> iter 7000, loss: 0.046787
 >> iter 8000, loss: 0.029336
 >> iter 9000, loss: 0.023125
 >> iter 10000, loss: 0.020396
   Number of active neurons: 4
 >> iter 11000, loss: 0.019606
 >> iter 12000, loss: 0.018871
 >> iter 13000, loss: 0.018848
 >> iter 14000, loss: 0.018378
 >> iter 15000, loss: 0.018378
 >> iter 16000, loss: 0.017884
 >> iter 17000, loss: 0.017846
 >> iter 18000, loss: 0.017360
 >> iter 19000, loss: 0.017339
 >> iter 20000, loss: 0.016904
   Number of active neurons: 3
 >> iter 21000, loss: 0.016901
 >> iter 22000, loss: 0.016518
 >> iter 23000, loss: 0.016597
 >> iter 24000, loss: 0.016306
 >> iter 25000, loss: 0.016465
 >> iter 26000, loss: 0.016237
 >> iter 27000, loss: 0.016416
 >> iter 28000, loss: 0.016214
 >> iter 29000, loss: 0.016375
 >> iter 30000, loss: 0.016155
   Number of active neurons: 3
 >> iter 31000, loss: 0.016318
 >> iter 32000, loss: 0.016112
 >> iter 33000, loss: 0.016285
 >> iter 34000, loss: 0.016088
 >> iter 35000, loss: 0.016269
 >> iter 36000, loss: 0.016057
 >> iter 37000, loss: 0.016225
 >> iter 38000, loss: 0.016000
 >> iter 39000, loss: 0.016153
 >> iter 40000, loss: 0.015904
   Number of active neurons: 2
 >> iter 41000, loss: 0.016016
 >> iter 42000, loss: 0.015740
 >> iter 43000, loss: 0.015718
 >> iter 44000, loss: 0.015299
 >> iter 45000, loss: 0.015227
 >> iter 46000, loss: 0.014849
 >> iter 47000, loss: 0.014811
 >> iter 48000, loss: 0.014514
 >> iter 49000, loss: 0.014568
 >> iter 50000, loss: 0.014325
   Number of active neurons: 2
 >> iter 51000, loss: 0.014421
 >> iter 52000, loss: 0.014240
 >> iter 53000, loss: 0.014358
 >> iter 54000, loss: 0.014219
 >> iter 55000, loss: 0.014325
 >> iter 56000, loss: 0.014199
 >> iter 57000, loss: 0.014319
 >> iter 58000, loss: 0.014178
 >> iter 59000, loss: 0.014312
 >> iter 60000, loss: 0.014177
   Number of active neurons: 2
 >> iter 61000, loss: 0.014302
 >> iter 62000, loss: 0.014177
 >> iter 63000, loss: 0.014306
 >> iter 64000, loss: 0.014171
 >> iter 65000, loss: 0.014310
 >> iter 66000, loss: 0.014181
 >> iter 67000, loss: 0.014313
 >> iter 68000, loss: 0.014205
 >> iter 69000, loss: 0.014326
 >> iter 70000, loss: 0.014210
   Number of active neurons: 2
 >> iter 71000, loss: 0.014341
 >> iter 72000, loss: 0.014235
 >> iter 73000, loss: 0.014362
 >> iter 74000, loss: 0.014252
 >> iter 75000, loss: 0.014386
 >> iter 76000, loss: 0.014277
 >> iter 77000, loss: 0.014408
 >> iter 78000, loss: 0.014297
 >> iter 79000, loss: 0.014452
 >> iter 80000, loss: 0.014331
   Number of active neurons: 2
 >> iter 81000, loss: 0.014501
 >> iter 82000, loss: 0.014368
 >> iter 83000, loss: 0.014548
 >> iter 84000, loss: 0.014404
 >> iter 85000, loss: 0.014581
 >> iter 86000, loss: 0.014440
 >> iter 87000, loss: 0.014623
 >> iter 88000, loss: 0.014481
 >> iter 89000, loss: 0.014660
 >> iter 90000, loss: 0.014533
   Number of active neurons: 2
 >> iter 91000, loss: 0.014705
 >> iter 92000, loss: 0.014584
 >> iter 93000, loss: 0.014753
 >> iter 94000, loss: 0.014624
 >> iter 95000, loss: 0.014813
 >> iter 96000, loss: 0.014665
 >> iter 97000, loss: 0.014855
 >> iter 98000, loss: 0.014700
 >> iter 99000, loss: 0.014892
 >> iter 100000, loss: 0.014748
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.756241
 >> iter 2000, loss: 3.976211
 >> iter 3000, loss: 1.478617
 >> iter 4000, loss: 0.558354
 >> iter 5000, loss: 0.219510
 >> iter 6000, loss: 0.094186
 >> iter 7000, loss: 0.047966
 >> iter 8000, loss: 0.030295
 >> iter 9000, loss: 0.023601
 >> iter 10000, loss: 0.020423
   Number of active neurons: 3
 >> iter 11000, loss: 0.019065
 >> iter 12000, loss: 0.017996
 >> iter 13000, loss: 0.017664
 >> iter 14000, loss: 0.017172
 >> iter 15000, loss: 0.017172
 >> iter 16000, loss: 0.016870
 >> iter 17000, loss: 0.016986
 >> iter 18000, loss: 0.016771
 >> iter 19000, loss: 0.016904
 >> iter 20000, loss: 0.016711
   Number of active neurons: 2
 >> iter 21000, loss: 0.016826
 >> iter 22000, loss: 0.016607
 >> iter 23000, loss: 0.016696
 >> iter 24000, loss: 0.016431
 >> iter 25000, loss: 0.016460
 >> iter 26000, loss: 0.016080
 >> iter 27000, loss: 0.015981
 >> iter 28000, loss: 0.015590
 >> iter 29000, loss: 0.015509
 >> iter 30000, loss: 0.015171
   Number of active neurons: 2
 >> iter 31000, loss: 0.015174
 >> iter 32000, loss: 0.014930
 >> iter 33000, loss: 0.015004
 >> iter 34000, loss: 0.014816
 >> iter 35000, loss: 0.014937
 >> iter 36000, loss: 0.014764
 >> iter 37000, loss: 0.014903
 >> iter 38000, loss: 0.014740
 >> iter 39000, loss: 0.014896
 >> iter 40000, loss: 0.014738
   Number of active neurons: 2
 >> iter 41000, loss: 0.014896
 >> iter 42000, loss: 0.014750
 >> iter 43000, loss: 0.014901
 >> iter 44000, loss: 0.014771
 >> iter 45000, loss: 0.014920
 >> iter 46000, loss: 0.014790
 >> iter 47000, loss: 0.014937
 >> iter 48000, loss: 0.014816
 >> iter 49000, loss: 0.014962
 >> iter 50000, loss: 0.014832
   Number of active neurons: 2
 >> iter 51000, loss: 0.014977
 >> iter 52000, loss: 0.014853
 >> iter 53000, loss: 0.014978
 >> iter 54000, loss: 0.014867
 >> iter 55000, loss: 0.014956
 >> iter 56000, loss: 0.014836
 >> iter 57000, loss: 0.014912
 >> iter 58000, loss: 0.014747
 >> iter 59000, loss: 0.014791
 >> iter 60000, loss: 0.014553
   Number of active neurons: 1
 >> iter 61000, loss: 0.014417
 >> iter 62000, loss: 0.014024
 >> iter 63000, loss: 0.013841
 >> iter 64000, loss: 0.013452
 >> iter 65000, loss: 0.013281
 >> iter 66000, loss: 0.012934
 >> iter 67000, loss: 0.012831
 >> iter 68000, loss: 0.012587
 >> iter 69000, loss: 0.012542
 >> iter 70000, loss: 0.012343
   Number of active neurons: 1
 >> iter 71000, loss: 0.012344
 >> iter 72000, loss: 0.012182
 >> iter 73000, loss: 0.012201
 >> iter 74000, loss: 0.012052
 >> iter 75000, loss: 0.012090
 >> iter 76000, loss: 0.011952
 >> iter 77000, loss: 0.011997
 >> iter 78000, loss: 0.011863
 >> iter 79000, loss: 0.011933
 >> iter 80000, loss: 0.011796
   Number of active neurons: 1
 >> iter 81000, loss: 0.011881
 >> iter 82000, loss: 0.011737
 >> iter 83000, loss: 0.011833
 >> iter 84000, loss: 0.011683
 >> iter 85000, loss: 0.011780
 >> iter 86000, loss: 0.011633
 >> iter 87000, loss: 0.011736
 >> iter 88000, loss: 0.011591
 >> iter 89000, loss: 0.011694
 >> iter 90000, loss: 0.011559
   Number of active neurons: 1
 >> iter 91000, loss: 0.011659
 >> iter 92000, loss: 0.011530
 >> iter 93000, loss: 0.011632
 >> iter 94000, loss: 0.011497
 >> iter 95000, loss: 0.011616
 >> iter 96000, loss: 0.011468
 >> iter 97000, loss: 0.011594
 >> iter 98000, loss: 0.011443
 >> iter 99000, loss: 0.011575
 >> iter 100000, loss: 0.011435
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.816949
 >> iter 2000, loss: 3.997246
 >> iter 3000, loss: 1.485215
 >> iter 4000, loss: 0.559358
 >> iter 5000, loss: 0.218437
 >> iter 6000, loss: 0.092348
 >> iter 7000, loss: 0.046014
 >> iter 8000, loss: 0.028483
 >> iter 9000, loss: 0.022198
 >> iter 10000, loss: 0.019402
   Number of active neurons: 3
 >> iter 11000, loss: 0.018526
 >> iter 12000, loss: 0.017786
 >> iter 13000, loss: 0.017725
 >> iter 14000, loss: 0.017291
 >> iter 15000, loss: 0.017332
 >> iter 16000, loss: 0.016957
 >> iter 17000, loss: 0.017015
 >> iter 18000, loss: 0.016640
 >> iter 19000, loss: 0.016691
 >> iter 20000, loss: 0.016390
   Number of active neurons: 3
 >> iter 21000, loss: 0.016509
 >> iter 22000, loss: 0.016277
 >> iter 23000, loss: 0.016441
 >> iter 24000, loss: 0.016219
 >> iter 25000, loss: 0.016412
 >> iter 26000, loss: 0.016232
 >> iter 27000, loss: 0.016433
 >> iter 28000, loss: 0.016246
 >> iter 29000, loss: 0.016426
 >> iter 30000, loss: 0.016258
   Number of active neurons: 3
 >> iter 31000, loss: 0.016454
 >> iter 32000, loss: 0.016295
 >> iter 33000, loss: 0.016492
 >> iter 34000, loss: 0.016320
 >> iter 35000, loss: 0.016519
 >> iter 36000, loss: 0.016353
 >> iter 37000, loss: 0.016554
 >> iter 38000, loss: 0.016380
 >> iter 39000, loss: 0.016579
 >> iter 40000, loss: 0.016392
   Number of active neurons: 3
 >> iter 41000, loss: 0.016575
 >> iter 42000, loss: 0.016388
 >> iter 43000, loss: 0.016541
 >> iter 44000, loss: 0.016351
 >> iter 45000, loss: 0.016476
 >> iter 46000, loss: 0.016255
 >> iter 47000, loss: 0.016335
 >> iter 48000, loss: 0.016064
 >> iter 49000, loss: 0.016009
 >> iter 50000, loss: 0.015609
   Number of active neurons: 2
 >> iter 51000, loss: 0.015542
 >> iter 52000, loss: 0.015188
 >> iter 53000, loss: 0.015137
 >> iter 54000, loss: 0.014874
 >> iter 55000, loss: 0.014889
 >> iter 56000, loss: 0.014709
 >> iter 57000, loss: 0.014788
 >> iter 58000, loss: 0.014627
 >> iter 59000, loss: 0.014743
 >> iter 60000, loss: 0.014604
   Number of active neurons: 2
 >> iter 61000, loss: 0.014720
 >> iter 62000, loss: 0.014599
 >> iter 63000, loss: 0.014724
 >> iter 64000, loss: 0.014595
 >> iter 65000, loss: 0.014734
 >> iter 66000, loss: 0.014614
 >> iter 67000, loss: 0.014745
 >> iter 68000, loss: 0.014649
 >> iter 69000, loss: 0.014770
 >> iter 70000, loss: 0.014666
   Number of active neurons: 2
 >> iter 71000, loss: 0.014798
 >> iter 72000, loss: 0.014704
 >> iter 73000, loss: 0.014829
 >> iter 74000, loss: 0.014731
 >> iter 75000, loss: 0.014861
 >> iter 76000, loss: 0.014762
 >> iter 77000, loss: 0.014886
 >> iter 78000, loss: 0.014782
 >> iter 79000, loss: 0.014923
 >> iter 80000, loss: 0.014805
   Number of active neurons: 2
 >> iter 81000, loss: 0.014951
 >> iter 82000, loss: 0.014812
 >> iter 83000, loss: 0.014953
 >> iter 84000, loss: 0.014790
 >> iter 85000, loss: 0.014903
 >> iter 86000, loss: 0.014716
 >> iter 87000, loss: 0.014792
 >> iter 88000, loss: 0.014535
 >> iter 89000, loss: 0.014446
 >> iter 90000, loss: 0.014034
   Number of active neurons: 1
 >> iter 91000, loss: 0.013874
 >> iter 92000, loss: 0.013480
 >> iter 93000, loss: 0.013322
 >> iter 94000, loss: 0.012950
 >> iter 95000, loss: 0.012880
 >> iter 96000, loss: 0.012580
 >> iter 97000, loss: 0.012585
 >> iter 98000, loss: 0.012336
 >> iter 99000, loss: 0.012386
 >> iter 100000, loss: 0.012179
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.719779
 >> iter 2000, loss: 3.962117
 >> iter 3000, loss: 1.473241
 >> iter 4000, loss: 0.556197
 >> iter 5000, loss: 0.218583
 >> iter 6000, loss: 0.093623
 >> iter 7000, loss: 0.047533
 >> iter 8000, loss: 0.029927
 >> iter 9000, loss: 0.023410
 >> iter 10000, loss: 0.020410
   Number of active neurons: 4
 >> iter 11000, loss: 0.019363
 >> iter 12000, loss: 0.018543
 >> iter 13000, loss: 0.018418
 >> iter 14000, loss: 0.017977
 >> iter 15000, loss: 0.017917
 >> iter 16000, loss: 0.017385
 >> iter 17000, loss: 0.017200
 >> iter 18000, loss: 0.016572
 >> iter 19000, loss: 0.016323
 >> iter 20000, loss: 0.015693
   Number of active neurons: 2
 >> iter 21000, loss: 0.015455
 >> iter 22000, loss: 0.014915
 >> iter 23000, loss: 0.014817
 >> iter 24000, loss: 0.014426
 >> iter 25000, loss: 0.014466
 >> iter 26000, loss: 0.014178
 >> iter 27000, loss: 0.014274
 >> iter 28000, loss: 0.014031
 >> iter 29000, loss: 0.014148
 >> iter 30000, loss: 0.013923
   Number of active neurons: 2
 >> iter 31000, loss: 0.014056
 >> iter 32000, loss: 0.013840
 >> iter 33000, loss: 0.013982
 >> iter 34000, loss: 0.013773
 >> iter 35000, loss: 0.013933
 >> iter 36000, loss: 0.013718
 >> iter 37000, loss: 0.013881
 >> iter 38000, loss: 0.013666
 >> iter 39000, loss: 0.013842
 >> iter 40000, loss: 0.013625
   Number of active neurons: 2
 >> iter 41000, loss: 0.013802
 >> iter 42000, loss: 0.013598
 >> iter 43000, loss: 0.013765
 >> iter 44000, loss: 0.013573
 >> iter 45000, loss: 0.013748
 >> iter 46000, loss: 0.013549
 >> iter 47000, loss: 0.013724
 >> iter 48000, loss: 0.013537
 >> iter 49000, loss: 0.013717
 >> iter 50000, loss: 0.013523
   Number of active neurons: 2
 >> iter 51000, loss: 0.013705
 >> iter 52000, loss: 0.013519
 >> iter 53000, loss: 0.013691
 >> iter 54000, loss: 0.013533
 >> iter 55000, loss: 0.013680
 >> iter 56000, loss: 0.013533
 >> iter 57000, loss: 0.013691
 >> iter 58000, loss: 0.013525
 >> iter 59000, loss: 0.013692
 >> iter 60000, loss: 0.013533
   Number of active neurons: 2
 >> iter 61000, loss: 0.013690
 >> iter 62000, loss: 0.013541
 >> iter 63000, loss: 0.013698
 >> iter 64000, loss: 0.013539
 >> iter 65000, loss: 0.013707
 >> iter 66000, loss: 0.013554
 >> iter 67000, loss: 0.013712
 >> iter 68000, loss: 0.013580
 >> iter 69000, loss: 0.013726
 >> iter 70000, loss: 0.013588
   Number of active neurons: 2
 >> iter 71000, loss: 0.013743
 >> iter 72000, loss: 0.013615
 >> iter 73000, loss: 0.013765
 >> iter 74000, loss: 0.013636
 >> iter 75000, loss: 0.013790
 >> iter 76000, loss: 0.013665
 >> iter 77000, loss: 0.013815
 >> iter 78000, loss: 0.013689
 >> iter 79000, loss: 0.013865
 >> iter 80000, loss: 0.013729
   Number of active neurons: 2
 >> iter 81000, loss: 0.013916
 >> iter 82000, loss: 0.013744
 >> iter 83000, loss: 0.013930
 >> iter 84000, loss: 0.013757
 >> iter 85000, loss: 0.013948
 >> iter 86000, loss: 0.013783
 >> iter 87000, loss: 0.013981
 >> iter 88000, loss: 0.013814
 >> iter 89000, loss: 0.013985
 >> iter 90000, loss: 0.013829
   Number of active neurons: 2
 >> iter 91000, loss: 0.014009
 >> iter 92000, loss: 0.013864
 >> iter 93000, loss: 0.014043
 >> iter 94000, loss: 0.013885
 >> iter 95000, loss: 0.014083
 >> iter 96000, loss: 0.013905
 >> iter 97000, loss: 0.014107
 >> iter 98000, loss: 0.013921
 >> iter 99000, loss: 0.014129
 >> iter 100000, loss: 0.013956
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.717648
 >> iter 2000, loss: 3.961961
 >> iter 3000, loss: 1.472821
 >> iter 4000, loss: 0.555457
 >> iter 5000, loss: 0.217669
 >> iter 6000, loss: 0.092874
 >> iter 7000, loss: 0.047040
 >> iter 8000, loss: 0.029803
 >> iter 9000, loss: 0.023571
 >> iter 10000, loss: 0.020889
   Number of active neurons: 4
 >> iter 11000, loss: 0.020047
 >> iter 12000, loss: 0.019409
 >> iter 13000, loss: 0.019421
 >> iter 14000, loss: 0.019138
 >> iter 15000, loss: 0.019314
 >> iter 16000, loss: 0.019110
 >> iter 17000, loss: 0.019307
 >> iter 18000, loss: 0.019112
 >> iter 19000, loss: 0.019272
 >> iter 20000, loss: 0.019062
   Number of active neurons: 3
 >> iter 21000, loss: 0.019151
 >> iter 22000, loss: 0.018817
 >> iter 23000, loss: 0.018761
 >> iter 24000, loss: 0.018347
 >> iter 25000, loss: 0.018278
 >> iter 26000, loss: 0.017902
 >> iter 27000, loss: 0.017871
 >> iter 28000, loss: 0.017547
 >> iter 29000, loss: 0.017495
 >> iter 30000, loss: 0.017051
   Number of active neurons: 1
 >> iter 31000, loss: 0.016840
 >> iter 32000, loss: 0.016351
 >> iter 33000, loss: 0.016123
 >> iter 34000, loss: 0.015652
 >> iter 35000, loss: 0.015413
 >> iter 36000, loss: 0.014844
 >> iter 37000, loss: 0.014544
 >> iter 38000, loss: 0.014019
 >> iter 39000, loss: 0.013784
 >> iter 40000, loss: 0.013353
   Number of active neurons: 1
 >> iter 41000, loss: 0.013229
 >> iter 42000, loss: 0.012913
 >> iter 43000, loss: 0.012864
 >> iter 44000, loss: 0.012623
 >> iter 45000, loss: 0.012620
 >> iter 46000, loss: 0.012415
 >> iter 47000, loss: 0.012440
 >> iter 48000, loss: 0.012263
 >> iter 49000, loss: 0.012307
 >> iter 50000, loss: 0.012137
   Number of active neurons: 1
 >> iter 51000, loss: 0.012195
 >> iter 52000, loss: 0.012041
 >> iter 53000, loss: 0.012097
 >> iter 54000, loss: 0.011967
 >> iter 55000, loss: 0.012011
 >> iter 56000, loss: 0.011890
 >> iter 57000, loss: 0.011947
 >> iter 58000, loss: 0.011816
 >> iter 59000, loss: 0.011886
 >> iter 60000, loss: 0.011761
   Number of active neurons: 1
 >> iter 61000, loss: 0.011825
 >> iter 62000, loss: 0.011708
 >> iter 63000, loss: 0.011777
 >> iter 64000, loss: 0.011653
 >> iter 65000, loss: 0.011732
 >> iter 66000, loss: 0.011613
 >> iter 67000, loss: 0.011687
 >> iter 68000, loss: 0.011585
 >> iter 69000, loss: 0.011652
 >> iter 70000, loss: 0.011544
   Number of active neurons: 1
 >> iter 71000, loss: 0.011619
 >> iter 72000, loss: 0.011519
 >> iter 73000, loss: 0.011592
 >> iter 74000, loss: 0.011489
 >> iter 75000, loss: 0.011567
 >> iter 76000, loss: 0.011465
 >> iter 77000, loss: 0.011541
 >> iter 78000, loss: 0.011437
 >> iter 79000, loss: 0.011532
 >> iter 80000, loss: 0.011420
   Number of active neurons: 1
 >> iter 81000, loss: 0.011527
 >> iter 82000, loss: 0.011404
 >> iter 83000, loss: 0.011520
 >> iter 84000, loss: 0.011388
 >> iter 85000, loss: 0.011502
 >> iter 86000, loss: 0.011371
 >> iter 87000, loss: 0.011489
 >> iter 88000, loss: 0.011358
 >> iter 89000, loss: 0.011474
 >> iter 90000, loss: 0.011352
   Number of active neurons: 1
 >> iter 91000, loss: 0.011464
 >> iter 92000, loss: 0.011347
 >> iter 93000, loss: 0.011458
 >> iter 94000, loss: 0.011334
 >> iter 95000, loss: 0.011462
 >> iter 96000, loss: 0.011324
 >> iter 97000, loss: 0.011457
 >> iter 98000, loss: 0.011314
 >> iter 99000, loss: 0.011453
 >> iter 100000, loss: 0.011320
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.720145
 >> iter 2000, loss: 3.962193
 >> iter 3000, loss: 1.473492
 >> iter 4000, loss: 0.556749
 >> iter 5000, loss: 0.219446
 >> iter 6000, loss: 0.094744
 >> iter 7000, loss: 0.048847
 >> iter 8000, loss: 0.031325
 >> iter 9000, loss: 0.024818
 >> iter 10000, loss: 0.021724
   Number of active neurons: 3
 >> iter 11000, loss: 0.020443
 >> iter 12000, loss: 0.019215
 >> iter 13000, loss: 0.018661
 >> iter 14000, loss: 0.017817
 >> iter 15000, loss: 0.017531
 >> iter 16000, loss: 0.016936
 >> iter 17000, loss: 0.016849
 >> iter 18000, loss: 0.016455
 >> iter 19000, loss: 0.016483
 >> iter 20000, loss: 0.016177
   Number of active neurons: 2
 >> iter 21000, loss: 0.016218
 >> iter 22000, loss: 0.015897
 >> iter 23000, loss: 0.015882
 >> iter 24000, loss: 0.015457
 >> iter 25000, loss: 0.015383
 >> iter 26000, loss: 0.014979
 >> iter 27000, loss: 0.014928
 >> iter 28000, loss: 0.014594
 >> iter 29000, loss: 0.014621
 >> iter 30000, loss: 0.014374
   Number of active neurons: 2
 >> iter 31000, loss: 0.014465
 >> iter 32000, loss: 0.014265
 >> iter 33000, loss: 0.014380
 >> iter 34000, loss: 0.014182
 >> iter 35000, loss: 0.014311
 >> iter 36000, loss: 0.014127
 >> iter 37000, loss: 0.014276
 >> iter 38000, loss: 0.014103
 >> iter 39000, loss: 0.014268
 >> iter 40000, loss: 0.014080
   Number of active neurons: 2
 >> iter 41000, loss: 0.014233
 >> iter 42000, loss: 0.014074
 >> iter 43000, loss: 0.014229
 >> iter 44000, loss: 0.014085
 >> iter 45000, loss: 0.014239
 >> iter 46000, loss: 0.014090
 >> iter 47000, loss: 0.014242
 >> iter 48000, loss: 0.014103
 >> iter 49000, loss: 0.014257
 >> iter 50000, loss: 0.014110
   Number of active neurons: 2
 >> iter 51000, loss: 0.014267
 >> iter 52000, loss: 0.014129
 >> iter 53000, loss: 0.014275
 >> iter 54000, loss: 0.014161
 >> iter 55000, loss: 0.014285
 >> iter 56000, loss: 0.014179
 >> iter 57000, loss: 0.014315
 >> iter 58000, loss: 0.014190
 >> iter 59000, loss: 0.014337
 >> iter 60000, loss: 0.014219
   Number of active neurons: 2
 >> iter 61000, loss: 0.014356
 >> iter 62000, loss: 0.014246
 >> iter 63000, loss: 0.014385
 >> iter 64000, loss: 0.014264
 >> iter 65000, loss: 0.014413
 >> iter 66000, loss: 0.014298
 >> iter 67000, loss: 0.014439
 >> iter 68000, loss: 0.014345
 >> iter 69000, loss: 0.014475
 >> iter 70000, loss: 0.014372
   Number of active neurons: 2
 >> iter 71000, loss: 0.014511
 >> iter 72000, loss: 0.014419
 >> iter 73000, loss: 0.014552
 >> iter 74000, loss: 0.014455
 >> iter 75000, loss: 0.014595
 >> iter 76000, loss: 0.014499
 >> iter 77000, loss: 0.014634
 >> iter 78000, loss: 0.014536
 >> iter 79000, loss: 0.014694
 >> iter 80000, loss: 0.014585
   Number of active neurons: 2
 >> iter 81000, loss: 0.014756
 >> iter 82000, loss: 0.014633
 >> iter 83000, loss: 0.014810
 >> iter 84000, loss: 0.014675
 >> iter 85000, loss: 0.014845
 >> iter 86000, loss: 0.014710
 >> iter 87000, loss: 0.014879
 >> iter 88000, loss: 0.014738
 >> iter 89000, loss: 0.014894
 >> iter 90000, loss: 0.014759
   Number of active neurons: 1
 >> iter 91000, loss: 0.014894
 >> iter 92000, loss: 0.014750
 >> iter 93000, loss: 0.014861
 >> iter 94000, loss: 0.014684
 >> iter 95000, loss: 0.014774
 >> iter 96000, loss: 0.014511
 >> iter 97000, loss: 0.014446
 >> iter 98000, loss: 0.014014
 >> iter 99000, loss: 0.013886
 >> iter 100000, loss: 0.013478
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

