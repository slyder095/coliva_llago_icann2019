 > Problema: tomita7nueva
 > Args:
   - Hidden size: 12
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.775205
 >> iter 2000, loss: 10.037457
 >> iter 3000, loss: 6.197702
 >> iter 4000, loss: 3.384008
 >> iter 5000, loss: 1.946260
 >> iter 6000, loss: 0.943290
 >> iter 7000, loss: 0.591149
 >> iter 8000, loss: 0.374576
 >> iter 9000, loss: 0.779602
 >> iter 10000, loss: 0.480608
   Number of active neurons: 8
 >> iter 11000, loss: 0.409748
 >> iter 12000, loss: 0.437579
 >> iter 13000, loss: 0.438736
 >> iter 14000, loss: 0.311036
 >> iter 15000, loss: 0.261982
 >> iter 16000, loss: 0.378399
 >> iter 17000, loss: 0.350113
 >> iter 18000, loss: 0.344287
 >> iter 19000, loss: 0.395380
 >> iter 20000, loss: 0.384010
   Number of active neurons: 8
 >> iter 21000, loss: 0.477697
 >> iter 22000, loss: 0.402287
 >> iter 23000, loss: 0.432374
 >> iter 24000, loss: 0.343479
 >> iter 25000, loss: 0.413509
 >> iter 26000, loss: 0.344719
 >> iter 27000, loss: 0.260761
 >> iter 28000, loss: 0.356205
 >> iter 29000, loss: 0.372108
 >> iter 30000, loss: 0.308843
   Number of active neurons: 8
 >> iter 31000, loss: 0.254244
 >> iter 32000, loss: 0.278631
 >> iter 33000, loss: 0.344720
 >> iter 34000, loss: 0.425163
 >> iter 35000, loss: 0.474311
 >> iter 36000, loss: 0.479133
 >> iter 37000, loss: 0.456540
 >> iter 38000, loss: 0.332561
 >> iter 39000, loss: 0.283740
 >> iter 40000, loss: 0.328789
   Number of active neurons: 8
 >> iter 41000, loss: 0.402553
 >> iter 42000, loss: 0.352741
 >> iter 43000, loss: 0.389301
 >> iter 44000, loss: 0.344434
 >> iter 45000, loss: 0.243768
 >> iter 46000, loss: 0.396670
 >> iter 47000, loss: 0.301381
 >> iter 48000, loss: 0.421880
 >> iter 49000, loss: 0.384301
 >> iter 50000, loss: 0.328506
   Number of active neurons: 8
 >> iter 51000, loss: 0.327267
 >> iter 52000, loss: 0.305513
 >> iter 53000, loss: 0.225557
 >> iter 54000, loss: 0.409526
 >> iter 55000, loss: 0.321980
 >> iter 56000, loss: 0.298108
 >> iter 57000, loss: 0.336650
 >> iter 58000, loss: 0.278152
 >> iter 59000, loss: 0.323427
 >> iter 60000, loss: 0.251823
   Number of active neurons: 8
 >> iter 61000, loss: 0.358234
 >> iter 62000, loss: 0.289392
 >> iter 63000, loss: 0.345091
 >> iter 64000, loss: 0.366800
 >> iter 65000, loss: 0.371252
 >> iter 66000, loss: 0.309985
 >> iter 67000, loss: 0.308758
 >> iter 68000, loss: 0.280176
 >> iter 69000, loss: 0.352217
 >> iter 70000, loss: 0.339594
   Number of active neurons: 8
 >> iter 71000, loss: 0.340887
 >> iter 72000, loss: 0.316229
 >> iter 73000, loss: 0.203173
 >> iter 74000, loss: 0.312662
 >> iter 75000, loss: 0.384603
 >> iter 76000, loss: 0.329132
 >> iter 77000, loss: 0.318063
 >> iter 78000, loss: 0.307366
 >> iter 79000, loss: 0.381140
 >> iter 80000, loss: 0.428614
   Number of active neurons: 8
 >> iter 81000, loss: 0.297302
 >> iter 82000, loss: 0.237592
 >> iter 83000, loss: 0.280304
 >> iter 84000, loss: 0.438536
 >> iter 85000, loss: 0.446340
 >> iter 86000, loss: 0.350332
 >> iter 87000, loss: 0.357194
 >> iter 88000, loss: 0.319623
 >> iter 89000, loss: 0.287929
 >> iter 90000, loss: 0.271830
   Number of active neurons: 8
 >> iter 91000, loss: 0.272891
 >> iter 92000, loss: 0.325254
 >> iter 93000, loss: 0.343547
 >> iter 94000, loss: 0.277762
 >> iter 95000, loss: 0.294901
 >> iter 96000, loss: 0.339182
 >> iter 97000, loss: 0.375010
 >> iter 98000, loss: 0.300145
 >> iter 99000, loss: 0.311198
 >> iter 100000, loss: 0.455018
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.437385
 >> iter 2000, loss: 13.052573
 >> iter 3000, loss: 9.748426
 >> iter 4000, loss: 6.655961
 >> iter 5000, loss: 3.481893
 >> iter 6000, loss: 1.736956
 >> iter 7000, loss: 0.908313
 >> iter 8000, loss: 0.602640
 >> iter 9000, loss: 0.403820
 >> iter 10000, loss: 0.399644
   Number of active neurons: 5
 >> iter 11000, loss: 0.329429
 >> iter 12000, loss: 0.328331
 >> iter 13000, loss: 0.330022
 >> iter 14000, loss: 0.285614
 >> iter 15000, loss: 0.252670
 >> iter 16000, loss: 0.351309
 >> iter 17000, loss: 0.346391
 >> iter 18000, loss: 0.237753
 >> iter 19000, loss: 0.271317
 >> iter 20000, loss: 0.208763
   Number of active neurons: 5
 >> iter 21000, loss: 0.198399
 >> iter 22000, loss: 0.221405
 >> iter 23000, loss: 0.389474
 >> iter 24000, loss: 0.496295
 >> iter 25000, loss: 0.418188
 >> iter 26000, loss: 0.316020
 >> iter 27000, loss: 0.385397
 >> iter 28000, loss: 0.318245
 >> iter 29000, loss: 0.290617
 >> iter 30000, loss: 0.390973
   Number of active neurons: 5
 >> iter 31000, loss: 0.426615
 >> iter 32000, loss: 0.407489
 >> iter 33000, loss: 0.362332
 >> iter 34000, loss: 0.390655
 >> iter 35000, loss: 0.427571
 >> iter 36000, loss: 0.347121
 >> iter 37000, loss: 0.275616
 >> iter 38000, loss: 0.406194
 >> iter 39000, loss: 0.437200
 >> iter 40000, loss: 0.334121
   Number of active neurons: 5
 >> iter 41000, loss: 0.386564
 >> iter 42000, loss: 0.333524
 >> iter 43000, loss: 0.316033
 >> iter 44000, loss: 0.305721
 >> iter 45000, loss: 0.302498
 >> iter 46000, loss: 0.320325
 >> iter 47000, loss: 0.345849
 >> iter 48000, loss: 0.268702
 >> iter 49000, loss: 0.318707
 >> iter 50000, loss: 0.361452
   Number of active neurons: 5
 >> iter 51000, loss: 0.353101
 >> iter 52000, loss: 0.334443
 >> iter 53000, loss: 0.407367
 >> iter 54000, loss: 0.313261
 >> iter 55000, loss: 0.334647
 >> iter 56000, loss: 0.377172
 >> iter 57000, loss: 0.352150
 >> iter 58000, loss: 0.401846
 >> iter 59000, loss: 0.308730
 >> iter 60000, loss: 0.300349
   Number of active neurons: 5
 >> iter 61000, loss: 0.390191
 >> iter 62000, loss: 0.354917
 >> iter 63000, loss: 0.556598
 >> iter 64000, loss: 0.540047
 >> iter 65000, loss: 0.388345
 >> iter 66000, loss: 0.387480
 >> iter 67000, loss: 0.451202
 >> iter 68000, loss: 0.405983
 >> iter 69000, loss: 0.326748
 >> iter 70000, loss: 0.239488
   Number of active neurons: 5
 >> iter 71000, loss: 0.434632
 >> iter 72000, loss: 0.525212
 >> iter 73000, loss: 0.508644
 >> iter 74000, loss: 0.447394
 >> iter 75000, loss: 0.442090
 >> iter 76000, loss: 0.490566
 >> iter 77000, loss: 0.465098
 >> iter 78000, loss: 0.442987
 >> iter 79000, loss: 0.413455
 >> iter 80000, loss: 0.316569
   Number of active neurons: 4
 >> iter 81000, loss: 0.333625
 >> iter 82000, loss: 0.288702
 >> iter 83000, loss: 0.329041
 >> iter 84000, loss: 0.349062
 >> iter 85000, loss: 0.397016
 >> iter 86000, loss: 0.303325
 >> iter 87000, loss: 0.454786
 >> iter 88000, loss: 0.360611
 >> iter 89000, loss: 0.475339
 >> iter 90000, loss: 0.521602
   Number of active neurons: 4
 >> iter 91000, loss: 0.502303
 >> iter 92000, loss: 0.466527
 >> iter 93000, loss: 0.374447
 >> iter 94000, loss: 0.505665
 >> iter 95000, loss: 0.524145
 >> iter 96000, loss: 0.479579
 >> iter 97000, loss: 0.367865
 >> iter 98000, loss: 0.391215
 >> iter 99000, loss: 0.496243
 >> iter 100000, loss: 0.407423
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.179316
 >> iter 2000, loss: 10.425969
 >> iter 3000, loss: 7.228354
 >> iter 4000, loss: 3.986150
 >> iter 5000, loss: 1.886496
 >> iter 6000, loss: 0.973839
 >> iter 7000, loss: 0.633490
 >> iter 8000, loss: 0.428967
 >> iter 9000, loss: 0.326284
 >> iter 10000, loss: 0.421716
   Number of active neurons: 12
 >> iter 11000, loss: 0.337653
 >> iter 12000, loss: 0.269946
 >> iter 13000, loss: 0.340259
 >> iter 14000, loss: 0.247243
 >> iter 15000, loss: 0.192161
 >> iter 16000, loss: 0.210033
 >> iter 17000, loss: 0.254250
 >> iter 18000, loss: 0.325393
 >> iter 19000, loss: 0.392939
 >> iter 20000, loss: 0.311513
   Number of active neurons: 10
 >> iter 21000, loss: 0.382017
 >> iter 22000, loss: 0.444196
 >> iter 23000, loss: 0.405330
 >> iter 24000, loss: 0.367813
 >> iter 25000, loss: 0.507789
 >> iter 26000, loss: 0.346712
 >> iter 27000, loss: 0.467290
 >> iter 28000, loss: 0.360118
 >> iter 29000, loss: 0.422924
 >> iter 30000, loss: 0.370153
   Number of active neurons: 10
 >> iter 31000, loss: 0.362606
 >> iter 32000, loss: 0.446590
 >> iter 33000, loss: 0.352011
 >> iter 34000, loss: 0.313448
 >> iter 35000, loss: 0.269204
 >> iter 36000, loss: 0.259631
 >> iter 37000, loss: 0.231523
 >> iter 38000, loss: 0.268410
 >> iter 39000, loss: 0.388147
 >> iter 40000, loss: 0.262033
   Number of active neurons: 9
 >> iter 41000, loss: 0.205101
 >> iter 42000, loss: 0.318074
 >> iter 43000, loss: 0.334529
 >> iter 44000, loss: 0.301174
 >> iter 45000, loss: 0.359408
 >> iter 46000, loss: 0.261612
 >> iter 47000, loss: 0.444951
 >> iter 48000, loss: 0.396740
 >> iter 49000, loss: 0.372857
 >> iter 50000, loss: 0.355894
   Number of active neurons: 9
 >> iter 51000, loss: 0.292358
 >> iter 52000, loss: 0.331155
 >> iter 53000, loss: 0.304059
 >> iter 54000, loss: 0.330528
 >> iter 55000, loss: 0.325721
 >> iter 56000, loss: 0.198580
 >> iter 57000, loss: 0.347370
 >> iter 58000, loss: 0.229575
 >> iter 59000, loss: 0.226763
 >> iter 60000, loss: 0.290947
   Number of active neurons: 9
 >> iter 61000, loss: 0.304977
 >> iter 62000, loss: 0.355325
 >> iter 63000, loss: 0.378623
 >> iter 64000, loss: 0.293645
 >> iter 65000, loss: 0.360396
 >> iter 66000, loss: 0.394754
 >> iter 67000, loss: 0.364580
 >> iter 68000, loss: 0.229520
 >> iter 69000, loss: 0.379407
 >> iter 70000, loss: 0.419946
   Number of active neurons: 8
 >> iter 71000, loss: 0.475885
 >> iter 72000, loss: 0.312821
 >> iter 73000, loss: 0.214001
 >> iter 74000, loss: 0.196435
 >> iter 75000, loss: 0.314701
 >> iter 76000, loss: 0.321179
 >> iter 77000, loss: 0.273668
 >> iter 78000, loss: 0.215068
 >> iter 79000, loss: 0.239961
 >> iter 80000, loss: 0.271525
   Number of active neurons: 8
 >> iter 81000, loss: 0.284559
 >> iter 82000, loss: 0.246076
 >> iter 83000, loss: 0.311542
 >> iter 84000, loss: 0.256198
 >> iter 85000, loss: 0.271113
 >> iter 86000, loss: 0.274380
 >> iter 87000, loss: 0.338914
 >> iter 88000, loss: 0.249180
 >> iter 89000, loss: 0.274620
 >> iter 90000, loss: 0.206745
   Number of active neurons: 8
 >> iter 91000, loss: 0.236145
 >> iter 92000, loss: 0.308142
 >> iter 93000, loss: 0.283096
 >> iter 94000, loss: 0.297860
 >> iter 95000, loss: 0.218420
 >> iter 96000, loss: 0.213770
 >> iter 97000, loss: 0.371193
 >> iter 98000, loss: 0.384622
 >> iter 99000, loss: 0.292258
 >> iter 100000, loss: 0.321203
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.205219
 >> iter 2000, loss: 10.825493
 >> iter 3000, loss: 8.074027
 >> iter 4000, loss: 5.275018
 >> iter 5000, loss: 2.706786
 >> iter 6000, loss: 1.424509
 >> iter 7000, loss: 0.791816
 >> iter 8000, loss: 0.526024
 >> iter 9000, loss: 0.484855
 >> iter 10000, loss: 0.448309
   Number of active neurons: 4
 >> iter 11000, loss: 0.373293
 >> iter 12000, loss: 0.321510
 >> iter 13000, loss: 0.299411
 >> iter 14000, loss: 0.380510
 >> iter 15000, loss: 0.386892
 >> iter 16000, loss: 0.283304
 >> iter 17000, loss: 0.361755
 >> iter 18000, loss: 0.344241
 >> iter 19000, loss: 0.348287
 >> iter 20000, loss: 0.349511
   Number of active neurons: 4
 >> iter 21000, loss: 0.265240
 >> iter 22000, loss: 0.284038
 >> iter 23000, loss: 0.281161
 >> iter 24000, loss: 0.319094
 >> iter 25000, loss: 0.289532
 >> iter 26000, loss: 0.307989
 >> iter 27000, loss: 0.385990
 >> iter 28000, loss: 0.365886
 >> iter 29000, loss: 0.338402
 >> iter 30000, loss: 0.359169
   Number of active neurons: 4
 >> iter 31000, loss: 0.372519
 >> iter 32000, loss: 0.269206
 >> iter 33000, loss: 0.307506
 >> iter 34000, loss: 0.316009
 >> iter 35000, loss: 0.241629
 >> iter 36000, loss: 0.314604
 >> iter 37000, loss: 0.306300
 >> iter 38000, loss: 0.349015
 >> iter 39000, loss: 0.451638
 >> iter 40000, loss: 0.509141
   Number of active neurons: 4
 >> iter 41000, loss: 0.471660
 >> iter 42000, loss: 0.505658
 >> iter 43000, loss: 0.418706
 >> iter 44000, loss: 0.416648
 >> iter 45000, loss: 0.425126
 >> iter 46000, loss: 0.431381
 >> iter 47000, loss: 0.408920
 >> iter 48000, loss: 0.418566
 >> iter 49000, loss: 0.492892
 >> iter 50000, loss: 0.461663
   Number of active neurons: 4
 >> iter 51000, loss: 0.374871
 >> iter 52000, loss: 0.294981
 >> iter 53000, loss: 0.374547
 >> iter 54000, loss: 0.482685
 >> iter 55000, loss: 0.454105
 >> iter 56000, loss: 0.341697
 >> iter 57000, loss: 0.372831
 >> iter 58000, loss: 0.380291
 >> iter 59000, loss: 0.498214
 >> iter 60000, loss: 0.528703
   Number of active neurons: 4
 >> iter 61000, loss: 0.388264
 >> iter 62000, loss: 0.391421
 >> iter 63000, loss: 0.409603
 >> iter 64000, loss: 0.373320
 >> iter 65000, loss: 0.404268
 >> iter 66000, loss: 0.403662
 >> iter 67000, loss: 0.374893
 >> iter 68000, loss: 0.346345
 >> iter 69000, loss: 0.357406
 >> iter 70000, loss: 0.353530
   Number of active neurons: 4
 >> iter 71000, loss: 0.340774
 >> iter 72000, loss: 0.431175
 >> iter 73000, loss: 0.414888
 >> iter 74000, loss: 0.437895
 >> iter 75000, loss: 0.456521
 >> iter 76000, loss: 0.348953
 >> iter 77000, loss: 0.401813
 >> iter 78000, loss: 0.429530
 >> iter 79000, loss: 0.365439
 >> iter 80000, loss: 0.411070
   Number of active neurons: 4
 >> iter 81000, loss: 0.353313
 >> iter 82000, loss: 0.356717
 >> iter 83000, loss: 0.491634
 >> iter 84000, loss: 0.313147
 >> iter 85000, loss: 0.427485
 >> iter 86000, loss: 0.437702
 >> iter 87000, loss: 0.288168
 >> iter 88000, loss: 0.253635
 >> iter 89000, loss: 0.270943
 >> iter 90000, loss: 0.257484
   Number of active neurons: 4
 >> iter 91000, loss: 0.294068
 >> iter 92000, loss: 0.314129
 >> iter 93000, loss: 0.356290
 >> iter 94000, loss: 0.362948
 >> iter 95000, loss: 0.452009
 >> iter 96000, loss: 0.435648
 >> iter 97000, loss: 0.359537
 >> iter 98000, loss: 0.483908
 >> iter 99000, loss: 0.365546
 >> iter 100000, loss: 0.360034
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.873442
 >> iter 2000, loss: 10.025869
 >> iter 3000, loss: 5.783469
 >> iter 4000, loss: 2.726796
 >> iter 5000, loss: 1.400151
 >> iter 6000, loss: 0.722260
 >> iter 7000, loss: 0.468236
 >> iter 8000, loss: 0.368181
 >> iter 9000, loss: 0.577885
 >> iter 10000, loss: 0.465907
   Number of active neurons: 10
 >> iter 11000, loss: 0.336952
 >> iter 12000, loss: 0.324961
 >> iter 13000, loss: 0.401651
 >> iter 14000, loss: 0.307937
 >> iter 15000, loss: 0.273784
 >> iter 16000, loss: 0.224164
 >> iter 17000, loss: 0.215819
 >> iter 18000, loss: 0.288812
 >> iter 19000, loss: 0.346093
 >> iter 20000, loss: 0.255958
   Number of active neurons: 10
 >> iter 21000, loss: 0.310106
 >> iter 22000, loss: 0.286436
 >> iter 23000, loss: 0.250373
 >> iter 24000, loss: 0.454902
 >> iter 25000, loss: 0.405899
 >> iter 26000, loss: 0.434053
 >> iter 27000, loss: 0.387197
 >> iter 28000, loss: 0.367433
 >> iter 29000, loss: 0.279349
 >> iter 30000, loss: 0.290059
   Number of active neurons: 9
 >> iter 31000, loss: 0.313482
 >> iter 32000, loss: 0.257731
 >> iter 33000, loss: 0.301343
 >> iter 34000, loss: 0.239079
 >> iter 35000, loss: 0.325304
 >> iter 36000, loss: 0.434133
 >> iter 37000, loss: 0.285163
 >> iter 38000, loss: 0.272867
 >> iter 39000, loss: 0.234731
 >> iter 40000, loss: 0.271036
   Number of active neurons: 9
 >> iter 41000, loss: 0.235164
 >> iter 42000, loss: 0.305194
 >> iter 43000, loss: 0.283644
 >> iter 44000, loss: 0.321184
 >> iter 45000, loss: 0.230231
 >> iter 46000, loss: 0.204041
 >> iter 47000, loss: 0.226764
 >> iter 48000, loss: 0.250618
 >> iter 49000, loss: 0.272016
 >> iter 50000, loss: 0.338496
   Number of active neurons: 9
 >> iter 51000, loss: 0.288824
 >> iter 52000, loss: 0.362796
 >> iter 53000, loss: 0.274826
 >> iter 54000, loss: 0.326246
 >> iter 55000, loss: 0.275407
 >> iter 56000, loss: 0.307735
 >> iter 57000, loss: 0.334916
 >> iter 58000, loss: 0.300875
 >> iter 59000, loss: 0.263645
 >> iter 60000, loss: 0.212836
   Number of active neurons: 9
 >> iter 61000, loss: 0.257533
 >> iter 62000, loss: 0.238402
 >> iter 63000, loss: 0.201560
 >> iter 64000, loss: 0.377640
 >> iter 65000, loss: 0.289374
 >> iter 66000, loss: 0.368302
 >> iter 67000, loss: 0.448245
 >> iter 68000, loss: 0.302674
 >> iter 69000, loss: 0.340684
 >> iter 70000, loss: 0.294707
   Number of active neurons: 9
 >> iter 71000, loss: 0.158412
 >> iter 72000, loss: 0.166775
 >> iter 73000, loss: 0.307721
 >> iter 74000, loss: 0.255096
 >> iter 75000, loss: 0.246500
 >> iter 76000, loss: 0.274983
 >> iter 77000, loss: 0.277067
 >> iter 78000, loss: 0.288374
 >> iter 79000, loss: 0.275134
 >> iter 80000, loss: 0.235530
   Number of active neurons: 9
 >> iter 81000, loss: 0.343601
 >> iter 82000, loss: 0.258224
 >> iter 83000, loss: 0.304429
 >> iter 84000, loss: 0.267603
 >> iter 85000, loss: 0.234754
 >> iter 86000, loss: 0.295180
 >> iter 87000, loss: 0.246027
 >> iter 88000, loss: 0.246817
 >> iter 89000, loss: 0.263836
 >> iter 90000, loss: 0.251333
   Number of active neurons: 9
 >> iter 91000, loss: 0.260912
 >> iter 92000, loss: 0.281843
 >> iter 93000, loss: 0.320524
 >> iter 94000, loss: 0.376685
 >> iter 95000, loss: 0.285062
 >> iter 96000, loss: 0.283821
 >> iter 97000, loss: 0.282130
 >> iter 98000, loss: 0.237389
 >> iter 99000, loss: 0.250075
 >> iter 100000, loss: 0.217854
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.413145
 >> iter 2000, loss: 10.508430
 >> iter 3000, loss: 6.603331
 >> iter 4000, loss: 3.322189
 >> iter 5000, loss: 1.709328
 >> iter 6000, loss: 1.121968
 >> iter 7000, loss: 0.643457
 >> iter 8000, loss: 0.537709
 >> iter 9000, loss: 0.530578
 >> iter 10000, loss: 0.402935
   Number of active neurons: 6
 >> iter 11000, loss: 0.495028
 >> iter 12000, loss: 0.398492
 >> iter 13000, loss: 0.480246
 >> iter 14000, loss: 0.344855
 >> iter 15000, loss: 0.506548
 >> iter 16000, loss: 0.532919
 >> iter 17000, loss: 0.495501
 >> iter 18000, loss: 0.510262
 >> iter 19000, loss: 0.530854
 >> iter 20000, loss: 0.488027
   Number of active neurons: 6
 >> iter 21000, loss: 0.365236
 >> iter 22000, loss: 0.377784
 >> iter 23000, loss: 0.542426
 >> iter 24000, loss: 0.333666
 >> iter 25000, loss: 0.379771
 >> iter 26000, loss: 0.404934
 >> iter 27000, loss: 0.443192
 >> iter 28000, loss: 0.487230
 >> iter 29000, loss: 0.512101
 >> iter 30000, loss: 0.605136
   Number of active neurons: 6
 >> iter 31000, loss: 0.541581
 >> iter 32000, loss: 0.426351
 >> iter 33000, loss: 0.346997
 >> iter 34000, loss: 0.369222
 >> iter 35000, loss: 0.360313
 >> iter 36000, loss: 0.387464
 >> iter 37000, loss: 0.403168
 >> iter 38000, loss: 0.366727
 >> iter 39000, loss: 0.544407
 >> iter 40000, loss: 0.531934
   Number of active neurons: 6
 >> iter 41000, loss: 0.451483
 >> iter 42000, loss: 0.331984
 >> iter 43000, loss: 0.467581
 >> iter 44000, loss: 0.409537
 >> iter 45000, loss: 0.388047
 >> iter 46000, loss: 0.293402
 >> iter 47000, loss: 0.295087
 >> iter 48000, loss: 0.268868
 >> iter 49000, loss: 0.264657
 >> iter 50000, loss: 0.382669
   Number of active neurons: 5
 >> iter 51000, loss: 0.530732
 >> iter 52000, loss: 0.434891
 >> iter 53000, loss: 0.493239
 >> iter 54000, loss: 0.448026
 >> iter 55000, loss: 0.370564
 >> iter 56000, loss: 0.324213
 >> iter 57000, loss: 0.401943
 >> iter 58000, loss: 0.582173
 >> iter 59000, loss: 0.542559
 >> iter 60000, loss: 0.365009
   Number of active neurons: 5
 >> iter 61000, loss: 0.374740
 >> iter 62000, loss: 0.362557
 >> iter 63000, loss: 0.351027
 >> iter 64000, loss: 0.353282
 >> iter 65000, loss: 0.357322
 >> iter 66000, loss: 0.352661
 >> iter 67000, loss: 0.422055
 >> iter 68000, loss: 0.326185
 >> iter 69000, loss: 0.313696
 >> iter 70000, loss: 0.320796
   Number of active neurons: 6
 >> iter 71000, loss: 0.364584
 >> iter 72000, loss: 0.459173
 >> iter 73000, loss: 0.427230
 >> iter 74000, loss: 0.378097
 >> iter 75000, loss: 0.373904
 >> iter 76000, loss: 0.320904
 >> iter 77000, loss: 0.400389
 >> iter 78000, loss: 0.401912
 >> iter 79000, loss: 0.375000
 >> iter 80000, loss: 0.380849
   Number of active neurons: 5
 >> iter 81000, loss: 0.415488
 >> iter 82000, loss: 0.457960
 >> iter 83000, loss: 0.451246
 >> iter 84000, loss: 0.379955
 >> iter 85000, loss: 0.317468
 >> iter 86000, loss: 0.404306
 >> iter 87000, loss: 0.379563
 >> iter 88000, loss: 0.336135
 >> iter 89000, loss: 0.357714
 >> iter 90000, loss: 0.336872
   Number of active neurons: 5
 >> iter 91000, loss: 0.467288
 >> iter 92000, loss: 0.349348
 >> iter 93000, loss: 0.312714
 >> iter 94000, loss: 0.361099
 >> iter 95000, loss: 0.348516
 >> iter 96000, loss: 0.304058
 >> iter 97000, loss: 0.284719
 >> iter 98000, loss: 0.322872
 >> iter 99000, loss: 0.367965
 >> iter 100000, loss: 0.349066
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.765255
 >> iter 2000, loss: 11.183539
 >> iter 3000, loss: 7.796005
 >> iter 4000, loss: 4.499451
 >> iter 5000, loss: 2.243141
 >> iter 6000, loss: 1.099474
 >> iter 7000, loss: 0.675604
 >> iter 8000, loss: 0.411752
 >> iter 9000, loss: 0.529457
 >> iter 10000, loss: 0.420329
   Number of active neurons: 10
 >> iter 11000, loss: 0.449327
 >> iter 12000, loss: 0.328289
 >> iter 13000, loss: 0.383203
 >> iter 14000, loss: 0.327010
 >> iter 15000, loss: 0.382536
 >> iter 16000, loss: 0.365879
 >> iter 17000, loss: 0.248509
 >> iter 18000, loss: 0.327963
 >> iter 19000, loss: 0.259586
 >> iter 20000, loss: 0.299244
   Number of active neurons: 9
 >> iter 21000, loss: 0.323895
 >> iter 22000, loss: 0.413846
 >> iter 23000, loss: 0.277450
 >> iter 24000, loss: 0.285906
 >> iter 25000, loss: 0.455743
 >> iter 26000, loss: 0.321318
 >> iter 27000, loss: 0.257438
 >> iter 28000, loss: 0.382179
 >> iter 29000, loss: 0.319510
 >> iter 30000, loss: 0.243641
   Number of active neurons: 8
 >> iter 31000, loss: 0.385870
 >> iter 32000, loss: 0.375930
 >> iter 33000, loss: 0.316544
 >> iter 34000, loss: 0.312147
 >> iter 35000, loss: 0.210091
 >> iter 36000, loss: 0.339791
 >> iter 37000, loss: 0.305857
 >> iter 38000, loss: 0.246453
 >> iter 39000, loss: 0.263863
 >> iter 40000, loss: 0.317642
   Number of active neurons: 8
 >> iter 41000, loss: 0.302178
 >> iter 42000, loss: 0.271000
 >> iter 43000, loss: 0.283377
 >> iter 44000, loss: 0.370788
 >> iter 45000, loss: 0.314918
 >> iter 46000, loss: 0.269108
 >> iter 47000, loss: 0.241613
 >> iter 48000, loss: 0.179565
 >> iter 49000, loss: 0.330012
 >> iter 50000, loss: 0.364930
   Number of active neurons: 8
 >> iter 51000, loss: 0.371722
 >> iter 52000, loss: 0.362163
 >> iter 53000, loss: 0.386792
 >> iter 54000, loss: 0.440208
 >> iter 55000, loss: 0.358287
 >> iter 56000, loss: 0.297932
 >> iter 57000, loss: 0.224766
 >> iter 58000, loss: 0.300638
 >> iter 59000, loss: 0.354397
 >> iter 60000, loss: 0.296885
   Number of active neurons: 7
 >> iter 61000, loss: 0.301614
 >> iter 62000, loss: 0.312669
 >> iter 63000, loss: 0.323067
 >> iter 64000, loss: 0.323160
 >> iter 65000, loss: 0.377382
 >> iter 66000, loss: 0.318153
 >> iter 67000, loss: 0.286261
 >> iter 68000, loss: 0.329748
 >> iter 69000, loss: 0.352430
 >> iter 70000, loss: 0.318652
   Number of active neurons: 7
 >> iter 71000, loss: 0.291928
 >> iter 72000, loss: 0.247847
 >> iter 73000, loss: 0.283586
 >> iter 74000, loss: 0.242472
 >> iter 75000, loss: 0.179058
 >> iter 76000, loss: 0.363523
 >> iter 77000, loss: 0.236425
 >> iter 78000, loss: 0.218880
 >> iter 79000, loss: 0.210312
 >> iter 80000, loss: 0.278826
   Number of active neurons: 7
 >> iter 81000, loss: 0.351381
 >> iter 82000, loss: 0.342680
 >> iter 83000, loss: 0.298512
 >> iter 84000, loss: 0.330465
 >> iter 85000, loss: 0.324354
 >> iter 86000, loss: 0.282257
 >> iter 87000, loss: 0.192449
 >> iter 88000, loss: 0.198624
 >> iter 89000, loss: 0.259675
 >> iter 90000, loss: 0.251506
   Number of active neurons: 6
 >> iter 91000, loss: 0.292510
 >> iter 92000, loss: 0.361695
 >> iter 93000, loss: 0.292438
 >> iter 94000, loss: 0.367420
 >> iter 95000, loss: 0.333891
 >> iter 96000, loss: 0.304259
 >> iter 97000, loss: 0.276617
 >> iter 98000, loss: 0.228223
 >> iter 99000, loss: 0.252113
 >> iter 100000, loss: 0.335246
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 17.397807
 >> iter 2000, loss: 10.385679
 >> iter 3000, loss: 6.160257
 >> iter 4000, loss: 3.968173
 >> iter 5000, loss: 2.365637
 >> iter 6000, loss: 1.382711
 >> iter 7000, loss: 0.953971
 >> iter 8000, loss: 0.712924
 >> iter 9000, loss: 0.577922
 >> iter 10000, loss: 0.710323
   Number of active neurons: 6
 >> iter 11000, loss: 0.505896
 >> iter 12000, loss: 0.445476
 >> iter 13000, loss: 0.417416
 >> iter 14000, loss: 0.328034
 >> iter 15000, loss: 0.353235
 >> iter 16000, loss: 0.407932
 >> iter 17000, loss: 0.339011
 >> iter 18000, loss: 0.279912
 >> iter 19000, loss: 0.301348
 >> iter 20000, loss: 0.474665
   Number of active neurons: 6
 >> iter 21000, loss: 0.600811
 >> iter 22000, loss: 0.598400
 >> iter 23000, loss: 0.447894
 >> iter 24000, loss: 0.394512
 >> iter 25000, loss: 0.390945
 >> iter 26000, loss: 0.464721
 >> iter 27000, loss: 0.424975
 >> iter 28000, loss: 0.407787
 >> iter 29000, loss: 0.661141
 >> iter 30000, loss: 0.801088
   Number of active neurons: 6
 >> iter 31000, loss: 0.538473
 >> iter 32000, loss: 0.500420
 >> iter 33000, loss: 0.440621
 >> iter 34000, loss: 0.425690
 >> iter 35000, loss: 0.442776
 >> iter 36000, loss: 0.473355
 >> iter 37000, loss: 0.573747
 >> iter 38000, loss: 0.638557
 >> iter 39000, loss: 0.453665
 >> iter 40000, loss: 0.366995
   Number of active neurons: 6
 >> iter 41000, loss: 0.570522
 >> iter 42000, loss: 0.471680
 >> iter 43000, loss: 0.455895
 >> iter 44000, loss: 0.473997
 >> iter 45000, loss: 0.614525
 >> iter 46000, loss: 0.499209
 >> iter 47000, loss: 0.560326
 >> iter 48000, loss: 0.653253
 >> iter 49000, loss: 0.466306
 >> iter 50000, loss: 0.555632
   Number of active neurons: 6
 >> iter 51000, loss: 0.394190
 >> iter 52000, loss: 0.405078
 >> iter 53000, loss: 0.616434
 >> iter 54000, loss: 0.512821
 >> iter 55000, loss: 0.509747
 >> iter 56000, loss: 0.448999
 >> iter 57000, loss: 0.418927
 >> iter 58000, loss: 0.485281
 >> iter 59000, loss: 0.456616
 >> iter 60000, loss: 0.513935
   Number of active neurons: 5
 >> iter 61000, loss: 0.524430
 >> iter 62000, loss: 0.508297
 >> iter 63000, loss: 0.455916
 >> iter 64000, loss: 0.510766
 >> iter 65000, loss: 0.484023
 >> iter 66000, loss: 0.429191
 >> iter 67000, loss: 0.482097
 >> iter 68000, loss: 0.534371
 >> iter 69000, loss: 0.406109
 >> iter 70000, loss: 0.340800
   Number of active neurons: 5
 >> iter 71000, loss: 0.405065
 >> iter 72000, loss: 0.587238
 >> iter 73000, loss: 0.565407
 >> iter 74000, loss: 0.568487
 >> iter 75000, loss: 0.563190
 >> iter 76000, loss: 0.526104
 >> iter 77000, loss: 0.524705
 >> iter 78000, loss: 0.597821
 >> iter 79000, loss: 0.528811
 >> iter 80000, loss: 0.754638
   Number of active neurons: 5
 >> iter 81000, loss: 0.823067
 >> iter 82000, loss: 0.655229
 >> iter 83000, loss: 0.717368
 >> iter 84000, loss: 0.507913
 >> iter 85000, loss: 0.598728
 >> iter 86000, loss: 0.654918
 >> iter 87000, loss: 0.724395
 >> iter 88000, loss: 0.638867
 >> iter 89000, loss: 0.534427
 >> iter 90000, loss: 0.580487
   Number of active neurons: 5
 >> iter 91000, loss: 0.512583
 >> iter 92000, loss: 0.568618
 >> iter 93000, loss: 0.685546
 >> iter 94000, loss: 0.649724
 >> iter 95000, loss: 0.696760
 >> iter 96000, loss: 0.455480
 >> iter 97000, loss: 0.508882
 >> iter 98000, loss: 0.711504
 >> iter 99000, loss: 0.704401
 >> iter 100000, loss: 0.614483
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.139270
 >> iter 2000, loss: 10.972709
 >> iter 3000, loss: 6.642292
 >> iter 4000, loss: 3.297267
 >> iter 5000, loss: 1.742553
 >> iter 6000, loss: 0.904276
 >> iter 7000, loss: 0.614073
 >> iter 8000, loss: 0.367816
 >> iter 9000, loss: 0.282406
 >> iter 10000, loss: 0.257028
   Number of active neurons: 7
 >> iter 11000, loss: 0.216234
 >> iter 12000, loss: 0.175088
 >> iter 13000, loss: 0.274793
 >> iter 14000, loss: 0.256314
 >> iter 15000, loss: 0.261337
 >> iter 16000, loss: 0.173719
 >> iter 17000, loss: 0.287880
 >> iter 18000, loss: 0.249407
 >> iter 19000, loss: 0.291324
 >> iter 20000, loss: 0.258888
   Number of active neurons: 7
 >> iter 21000, loss: 0.295930
 >> iter 22000, loss: 0.305507
 >> iter 23000, loss: 0.248972
 >> iter 24000, loss: 0.248712
 >> iter 25000, loss: 0.214903
 >> iter 26000, loss: 0.259828
 >> iter 27000, loss: 0.248835
 >> iter 28000, loss: 0.233865
 >> iter 29000, loss: 0.233439
 >> iter 30000, loss: 0.294309
   Number of active neurons: 7
 >> iter 31000, loss: 0.311158
 >> iter 32000, loss: 0.191755
 >> iter 33000, loss: 0.294501
 >> iter 34000, loss: 0.288930
 >> iter 35000, loss: 0.203389
 >> iter 36000, loss: 0.184875
 >> iter 37000, loss: 0.206581
 >> iter 38000, loss: 0.242633
 >> iter 39000, loss: 0.277850
 >> iter 40000, loss: 0.372427
   Number of active neurons: 7
 >> iter 41000, loss: 0.358744
 >> iter 42000, loss: 0.371713
 >> iter 43000, loss: 0.219026
 >> iter 44000, loss: 0.314437
 >> iter 45000, loss: 0.241952
 >> iter 46000, loss: 0.263566
 >> iter 47000, loss: 0.356014
 >> iter 48000, loss: 0.310925
 >> iter 49000, loss: 0.307335
 >> iter 50000, loss: 0.254820
   Number of active neurons: 7
 >> iter 51000, loss: 0.309290
 >> iter 52000, loss: 0.364489
 >> iter 53000, loss: 0.310411
 >> iter 54000, loss: 0.241534
 >> iter 55000, loss: 0.281786
 >> iter 56000, loss: 0.283042
 >> iter 57000, loss: 0.236439
 >> iter 58000, loss: 0.227510
 >> iter 59000, loss: 0.290458
 >> iter 60000, loss: 0.264030
   Number of active neurons: 7
 >> iter 61000, loss: 0.287849
 >> iter 62000, loss: 0.352706
 >> iter 63000, loss: 0.305521
 >> iter 64000, loss: 0.356336
 >> iter 65000, loss: 0.271219
 >> iter 66000, loss: 0.312615
 >> iter 67000, loss: 0.339392
 >> iter 68000, loss: 0.248992
 >> iter 69000, loss: 0.183016
 >> iter 70000, loss: 0.220925
   Number of active neurons: 7
 >> iter 71000, loss: 0.212802
 >> iter 72000, loss: 0.247453
 >> iter 73000, loss: 0.270745
 >> iter 74000, loss: 0.229724
 >> iter 75000, loss: 0.268705
 >> iter 76000, loss: 0.275104
 >> iter 77000, loss: 0.193240
 >> iter 78000, loss: 0.229266
 >> iter 79000, loss: 0.355816
 >> iter 80000, loss: 0.277191
   Number of active neurons: 6
 >> iter 81000, loss: 0.273025
 >> iter 82000, loss: 0.372486
 >> iter 83000, loss: 0.302069
 >> iter 84000, loss: 0.326893
 >> iter 85000, loss: 0.290859
 >> iter 86000, loss: 0.312552
 >> iter 87000, loss: 0.219713
 >> iter 88000, loss: 0.220524
 >> iter 89000, loss: 0.274832
 >> iter 90000, loss: 0.335212
   Number of active neurons: 6
 >> iter 91000, loss: 0.334482
 >> iter 92000, loss: 0.345265
 >> iter 93000, loss: 0.294469
 >> iter 94000, loss: 0.333345
 >> iter 95000, loss: 0.367485
 >> iter 96000, loss: 0.362841
 >> iter 97000, loss: 0.236968
 >> iter 98000, loss: 0.317938
 >> iter 99000, loss: 0.260589
 >> iter 100000, loss: 0.239407
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.471735
 >> iter 2000, loss: 10.964555
 >> iter 3000, loss: 6.285881
 >> iter 4000, loss: 3.425837
 >> iter 5000, loss: 2.246465
 >> iter 6000, loss: 1.412255
 >> iter 7000, loss: 1.019017
 >> iter 8000, loss: 0.740045
 >> iter 9000, loss: 0.603200
 >> iter 10000, loss: 0.618335
   Number of active neurons: 12
 >> iter 11000, loss: 0.571662
 >> iter 12000, loss: 0.357241
 >> iter 13000, loss: 0.560090
 >> iter 14000, loss: 0.360982
 >> iter 15000, loss: 0.239984
 >> iter 16000, loss: 0.302099
 >> iter 17000, loss: 0.349271
 >> iter 18000, loss: 0.382165
 >> iter 19000, loss: 0.443632
 >> iter 20000, loss: 0.315613
   Number of active neurons: 11
 >> iter 21000, loss: 0.396663
 >> iter 22000, loss: 0.444409
 >> iter 23000, loss: 0.372686
 >> iter 24000, loss: 0.322147
 >> iter 25000, loss: 0.311121
 >> iter 26000, loss: 0.395207
 >> iter 27000, loss: 0.475205
 >> iter 28000, loss: 0.383184
 >> iter 29000, loss: 0.375517
 >> iter 30000, loss: 0.408081
   Number of active neurons: 9
 >> iter 31000, loss: 0.414935
 >> iter 32000, loss: 0.413557
 >> iter 33000, loss: 0.325527
 >> iter 34000, loss: 0.310651
 >> iter 35000, loss: 0.330074
 >> iter 36000, loss: 0.321695
 >> iter 37000, loss: 0.344356
 >> iter 38000, loss: 0.273106
 >> iter 39000, loss: 0.377690
 >> iter 40000, loss: 0.301483
   Number of active neurons: 8
 >> iter 41000, loss: 0.289542
 >> iter 42000, loss: 0.430250
 >> iter 43000, loss: 0.319881
 >> iter 44000, loss: 0.238270
 >> iter 45000, loss: 0.361059
 >> iter 46000, loss: 0.395108
 >> iter 47000, loss: 0.321843
 >> iter 48000, loss: 0.262923
 >> iter 49000, loss: 0.314308
 >> iter 50000, loss: 0.262626
   Number of active neurons: 8
 >> iter 51000, loss: 0.307918
 >> iter 52000, loss: 0.322145
 >> iter 53000, loss: 0.332091
 >> iter 54000, loss: 0.289349
 >> iter 55000, loss: 0.262766
 >> iter 56000, loss: 0.237145
 >> iter 57000, loss: 0.295588
 >> iter 58000, loss: 0.275618
 >> iter 59000, loss: 0.380601
 >> iter 60000, loss: 0.347781
   Number of active neurons: 8
 >> iter 61000, loss: 0.309640
 >> iter 62000, loss: 0.217410
 >> iter 63000, loss: 0.282894
 >> iter 64000, loss: 0.227981
 >> iter 65000, loss: 0.209396
 >> iter 66000, loss: 0.180569
 >> iter 67000, loss: 0.196328
 >> iter 68000, loss: 0.213643
 >> iter 69000, loss: 0.302376
 >> iter 70000, loss: 0.218494
   Number of active neurons: 7
 >> iter 71000, loss: 0.316015
 >> iter 72000, loss: 0.191622
 >> iter 73000, loss: 0.261285
 >> iter 74000, loss: 0.190246
 >> iter 75000, loss: 0.241708
 >> iter 76000, loss: 0.227933
 >> iter 77000, loss: 0.263500
 >> iter 78000, loss: 0.380649
 >> iter 79000, loss: 0.287184
 >> iter 80000, loss: 0.310037
   Number of active neurons: 7
 >> iter 81000, loss: 0.395331
 >> iter 82000, loss: 0.314955
 >> iter 83000, loss: 0.279632
 >> iter 84000, loss: 0.209699
 >> iter 85000, loss: 0.250121
 >> iter 86000, loss: 0.169512
 >> iter 87000, loss: 0.126956
 >> iter 88000, loss: 0.179712
 >> iter 89000, loss: 0.253827
 >> iter 90000, loss: 0.207016
   Number of active neurons: 7
 >> iter 91000, loss: 0.174413
 >> iter 92000, loss: 0.200990
 >> iter 93000, loss: 0.147298
 >> iter 94000, loss: 0.204375
 >> iter 95000, loss: 0.187258
 >> iter 96000, loss: 0.141627
 >> iter 97000, loss: 0.239240
 >> iter 98000, loss: 0.309128
 >> iter 99000, loss: 0.303271
 >> iter 100000, loss: 0.292219
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.552524
 >> iter 2000, loss: 11.340568
 >> iter 3000, loss: 8.066731
 >> iter 4000, loss: 5.030217
 >> iter 5000, loss: 3.001490
 >> iter 6000, loss: 2.101261
 >> iter 7000, loss: 1.263971
 >> iter 8000, loss: 1.120216
 >> iter 9000, loss: 0.788319
 >> iter 10000, loss: 0.614540
   Number of active neurons: 6
 >> iter 11000, loss: 0.610451
 >> iter 12000, loss: 0.675751
 >> iter 13000, loss: 0.773624
 >> iter 14000, loss: 0.544634
 >> iter 15000, loss: 0.471267
 >> iter 16000, loss: 0.455325
 >> iter 17000, loss: 0.499750
 >> iter 18000, loss: 0.515635
 >> iter 19000, loss: 0.533142
 >> iter 20000, loss: 0.596862
   Number of active neurons: 6
 >> iter 21000, loss: 0.458400
 >> iter 22000, loss: 0.535422
 >> iter 23000, loss: 0.587495
 >> iter 24000, loss: 0.506583
 >> iter 25000, loss: 0.534870
 >> iter 26000, loss: 0.680289
 >> iter 27000, loss: 0.624244
 >> iter 28000, loss: 0.535270
 >> iter 29000, loss: 0.707882
 >> iter 30000, loss: 0.685458
   Number of active neurons: 6
 >> iter 31000, loss: 0.829977
 >> iter 32000, loss: 0.717506
 >> iter 33000, loss: 0.508931
 >> iter 34000, loss: 0.635149
 >> iter 35000, loss: 0.565141
 >> iter 36000, loss: 0.588996
 >> iter 37000, loss: 0.582577
 >> iter 38000, loss: 0.630633
 >> iter 39000, loss: 0.569637
 >> iter 40000, loss: 0.413428
   Number of active neurons: 6
 >> iter 41000, loss: 0.638284
 >> iter 42000, loss: 0.725689
 >> iter 43000, loss: 0.598486
 >> iter 44000, loss: 0.550770
 >> iter 45000, loss: 0.533039
 >> iter 46000, loss: 0.625991
 >> iter 47000, loss: 0.599450
 >> iter 48000, loss: 0.552392
 >> iter 49000, loss: 0.447355
 >> iter 50000, loss: 0.422383
   Number of active neurons: 4
 >> iter 51000, loss: 0.429004
 >> iter 52000, loss: 0.503281
 >> iter 53000, loss: 0.517362
 >> iter 54000, loss: 0.500974
 >> iter 55000, loss: 0.436127
 >> iter 56000, loss: 0.448595
 >> iter 57000, loss: 0.422542
 >> iter 58000, loss: 0.436853
 >> iter 59000, loss: 0.445197
 >> iter 60000, loss: 0.403279
   Number of active neurons: 4
 >> iter 61000, loss: 0.585533
 >> iter 62000, loss: 0.771399
 >> iter 63000, loss: 0.565003
 >> iter 64000, loss: 0.479486
 >> iter 65000, loss: 0.476229
 >> iter 66000, loss: 0.420498
 >> iter 67000, loss: 0.407842
 >> iter 68000, loss: 0.397502
 >> iter 69000, loss: 0.365119
 >> iter 70000, loss: 0.416602
   Number of active neurons: 4
 >> iter 71000, loss: 0.634320
 >> iter 72000, loss: 0.509639
 >> iter 73000, loss: 0.560479
 >> iter 74000, loss: 0.453896
 >> iter 75000, loss: 0.499269
 >> iter 76000, loss: 0.456709
 >> iter 77000, loss: 0.480646
 >> iter 78000, loss: 0.365686
 >> iter 79000, loss: 0.363860
 >> iter 80000, loss: 0.403647
   Number of active neurons: 4
 >> iter 81000, loss: 0.297015
 >> iter 82000, loss: 0.456298
 >> iter 83000, loss: 0.445987
 >> iter 84000, loss: 0.380050
 >> iter 85000, loss: 0.397996
 >> iter 86000, loss: 0.431952
 >> iter 87000, loss: 0.487014
 >> iter 88000, loss: 0.419693
 >> iter 89000, loss: 0.454690
 >> iter 90000, loss: 0.421548
   Number of active neurons: 4
 >> iter 91000, loss: 0.607597
 >> iter 92000, loss: 0.464495
 >> iter 93000, loss: 0.418882
 >> iter 94000, loss: 0.433282
 >> iter 95000, loss: 0.515558
 >> iter 96000, loss: 0.448365
 >> iter 97000, loss: 0.569105
 >> iter 98000, loss: 0.439180
 >> iter 99000, loss: 0.415860
 >> iter 100000, loss: 0.440083
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.587823
 >> iter 2000, loss: 9.777822
 >> iter 3000, loss: 5.984036
 >> iter 4000, loss: 3.472872
 >> iter 5000, loss: 2.058997
 >> iter 6000, loss: 1.380782
 >> iter 7000, loss: 1.086740
 >> iter 8000, loss: 0.726717
 >> iter 9000, loss: 0.589106
 >> iter 10000, loss: 0.500310
   Number of active neurons: 6
 >> iter 11000, loss: 0.379241
 >> iter 12000, loss: 0.465683
 >> iter 13000, loss: 0.414291
 >> iter 14000, loss: 0.598408
 >> iter 15000, loss: 0.595132
 >> iter 16000, loss: 0.436276
 >> iter 17000, loss: 0.529303
 >> iter 18000, loss: 0.517646
 >> iter 19000, loss: 0.770286
 >> iter 20000, loss: 0.572620
   Number of active neurons: 6
 >> iter 21000, loss: 0.534966
 >> iter 22000, loss: 0.552143
 >> iter 23000, loss: 0.466074
 >> iter 24000, loss: 0.441794
 >> iter 25000, loss: 0.681752
 >> iter 26000, loss: 0.532076
 >> iter 27000, loss: 0.674823
 >> iter 28000, loss: 0.636258
 >> iter 29000, loss: 0.490543
 >> iter 30000, loss: 0.385907
   Number of active neurons: 6
 >> iter 31000, loss: 0.470161
 >> iter 32000, loss: 0.639706
 >> iter 33000, loss: 0.587812
 >> iter 34000, loss: 0.592368
 >> iter 35000, loss: 0.486724
 >> iter 36000, loss: 0.617010
 >> iter 37000, loss: 0.624295
 >> iter 38000, loss: 0.580503
 >> iter 39000, loss: 0.431680
 >> iter 40000, loss: 0.467887
   Number of active neurons: 4
 >> iter 41000, loss: 0.387142
 >> iter 42000, loss: 0.337277
 >> iter 43000, loss: 0.522231
 >> iter 44000, loss: 0.523357
 >> iter 45000, loss: 0.572744
 >> iter 46000, loss: 0.586499
 >> iter 47000, loss: 0.525511
 >> iter 48000, loss: 0.603890
 >> iter 49000, loss: 0.560122
 >> iter 50000, loss: 0.486227
   Number of active neurons: 4
 >> iter 51000, loss: 0.561084
 >> iter 52000, loss: 0.504550
 >> iter 53000, loss: 0.411468
 >> iter 54000, loss: 0.545817
 >> iter 55000, loss: 0.543259
 >> iter 56000, loss: 0.566701
 >> iter 57000, loss: 0.608510
 >> iter 58000, loss: 0.580697
 >> iter 59000, loss: 0.452660
 >> iter 60000, loss: 0.553680
   Number of active neurons: 4
 >> iter 61000, loss: 0.555364
 >> iter 62000, loss: 0.487105
 >> iter 63000, loss: 0.535568
 >> iter 64000, loss: 0.494595
 >> iter 65000, loss: 0.484688
 >> iter 66000, loss: 0.508280
 >> iter 67000, loss: 0.550301
 >> iter 68000, loss: 0.628979
 >> iter 69000, loss: 0.590495
 >> iter 70000, loss: 0.530928
   Number of active neurons: 4
 >> iter 71000, loss: 0.574051
 >> iter 72000, loss: 0.590856
 >> iter 73000, loss: 0.518022
 >> iter 74000, loss: 0.483775
 >> iter 75000, loss: 0.521771
 >> iter 76000, loss: 0.429090
 >> iter 77000, loss: 0.613396
 >> iter 78000, loss: 0.453557
 >> iter 79000, loss: 0.509522
 >> iter 80000, loss: 0.502675
   Number of active neurons: 4
 >> iter 81000, loss: 0.543224
 >> iter 82000, loss: 0.507797
 >> iter 83000, loss: 0.545215
 >> iter 84000, loss: 0.411459
 >> iter 85000, loss: 0.453366
 >> iter 86000, loss: 0.618336
 >> iter 87000, loss: 0.476463
 >> iter 88000, loss: 0.426461
 >> iter 89000, loss: 0.351259
 >> iter 90000, loss: 0.544897
   Number of active neurons: 4
 >> iter 91000, loss: 0.622580
 >> iter 92000, loss: 0.514817
 >> iter 93000, loss: 0.468258
 >> iter 94000, loss: 0.368461
 >> iter 95000, loss: 0.394414
 >> iter 96000, loss: 0.516903
 >> iter 97000, loss: 0.534065
 >> iter 98000, loss: 0.472926
 >> iter 99000, loss: 0.420802
 >> iter 100000, loss: 0.411098
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.691207
 >> iter 2000, loss: 9.979806
 >> iter 3000, loss: 5.198077
 >> iter 4000, loss: 2.731106
 >> iter 5000, loss: 1.384422
 >> iter 6000, loss: 0.954702
 >> iter 7000, loss: 0.785149
 >> iter 8000, loss: 0.573170
 >> iter 9000, loss: 0.445320
 >> iter 10000, loss: 0.361273
   Number of active neurons: 9
 >> iter 11000, loss: 0.473252
 >> iter 12000, loss: 0.388706
 >> iter 13000, loss: 0.315171
 >> iter 14000, loss: 0.377176
 >> iter 15000, loss: 0.361727
 >> iter 16000, loss: 0.372924
 >> iter 17000, loss: 0.298036
 >> iter 18000, loss: 0.259589
 >> iter 19000, loss: 0.186876
 >> iter 20000, loss: 0.383308
   Number of active neurons: 9
 >> iter 21000, loss: 0.324797
 >> iter 22000, loss: 0.537530
 >> iter 23000, loss: 0.489811
 >> iter 24000, loss: 0.399896
 >> iter 25000, loss: 0.395738
 >> iter 26000, loss: 0.315650
 >> iter 27000, loss: 0.293995
 >> iter 28000, loss: 0.295544
 >> iter 29000, loss: 0.291438
 >> iter 30000, loss: 0.320095
   Number of active neurons: 9
 >> iter 31000, loss: 0.301248
 >> iter 32000, loss: 0.239016
 >> iter 33000, loss: 0.240522
 >> iter 34000, loss: 0.339119
 >> iter 35000, loss: 0.325009
 >> iter 36000, loss: 0.382551
 >> iter 37000, loss: 0.423366
 >> iter 38000, loss: 0.329394
 >> iter 39000, loss: 0.357177
 >> iter 40000, loss: 0.393629
   Number of active neurons: 9
 >> iter 41000, loss: 0.339218
 >> iter 42000, loss: 0.364744
 >> iter 43000, loss: 0.331070
 >> iter 44000, loss: 0.307556
 >> iter 45000, loss: 0.297236
 >> iter 46000, loss: 0.320305
 >> iter 47000, loss: 0.410486
 >> iter 48000, loss: 0.345947
 >> iter 49000, loss: 0.498842
 >> iter 50000, loss: 0.299798
   Number of active neurons: 9
 >> iter 51000, loss: 0.349942
 >> iter 52000, loss: 0.272008
 >> iter 53000, loss: 0.185808
 >> iter 54000, loss: 0.342311
 >> iter 55000, loss: 0.299330
 >> iter 56000, loss: 0.336038
 >> iter 57000, loss: 0.494498
 >> iter 58000, loss: 0.419586
 >> iter 59000, loss: 0.342894
 >> iter 60000, loss: 0.245136
   Number of active neurons: 9
 >> iter 61000, loss: 0.292026
 >> iter 62000, loss: 0.257691
 >> iter 63000, loss: 0.288368
 >> iter 64000, loss: 0.328893
 >> iter 65000, loss: 0.313303
 >> iter 66000, loss: 0.347618
 >> iter 67000, loss: 0.293747
 >> iter 68000, loss: 0.326919
 >> iter 69000, loss: 0.359969
 >> iter 70000, loss: 0.352671
   Number of active neurons: 9
 >> iter 71000, loss: 0.429031
 >> iter 72000, loss: 0.290374
 >> iter 73000, loss: 0.505900
 >> iter 74000, loss: 0.375101
 >> iter 75000, loss: 0.429350
 >> iter 76000, loss: 0.306198
 >> iter 77000, loss: 0.335095
 >> iter 78000, loss: 0.233735
 >> iter 79000, loss: 0.308872
 >> iter 80000, loss: 0.301203
   Number of active neurons: 9
 >> iter 81000, loss: 0.284183
 >> iter 82000, loss: 0.366804
 >> iter 83000, loss: 0.251548
 >> iter 84000, loss: 0.257898
 >> iter 85000, loss: 0.190006
 >> iter 86000, loss: 0.349445
 >> iter 87000, loss: 0.248069
 >> iter 88000, loss: 0.261219
 >> iter 89000, loss: 0.296482
 >> iter 90000, loss: 0.352560
   Number of active neurons: 9
 >> iter 91000, loss: 0.346994
 >> iter 92000, loss: 0.353676
 >> iter 93000, loss: 0.295197
 >> iter 94000, loss: 0.285227
 >> iter 95000, loss: 0.365774
 >> iter 96000, loss: 0.318433
 >> iter 97000, loss: 0.390962
 >> iter 98000, loss: 0.258044
 >> iter 99000, loss: 0.243476
 >> iter 100000, loss: 0.385985
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 17.077610
 >> iter 2000, loss: 9.751851
 >> iter 3000, loss: 5.597886
 >> iter 4000, loss: 3.169645
 >> iter 5000, loss: 2.052965
 >> iter 6000, loss: 1.428456
 >> iter 7000, loss: 1.088686
 >> iter 8000, loss: 0.788912
 >> iter 9000, loss: 0.705181
 >> iter 10000, loss: 0.803358
   Number of active neurons: 6
 >> iter 11000, loss: 0.712595
 >> iter 12000, loss: 0.732144
 >> iter 13000, loss: 0.584474
 >> iter 14000, loss: 0.569435
 >> iter 15000, loss: 0.534685
 >> iter 16000, loss: 0.595829
 >> iter 17000, loss: 0.479081
 >> iter 18000, loss: 0.477981
 >> iter 19000, loss: 0.504582
 >> iter 20000, loss: 0.659676
   Number of active neurons: 6
 >> iter 21000, loss: 0.474693
 >> iter 22000, loss: 0.400861
 >> iter 23000, loss: 0.400731
 >> iter 24000, loss: 0.412369
 >> iter 25000, loss: 0.456336
 >> iter 26000, loss: 0.613255
 >> iter 27000, loss: 0.564958
 >> iter 28000, loss: 0.463057
 >> iter 29000, loss: 0.523708
 >> iter 30000, loss: 0.575052
   Number of active neurons: 6
 >> iter 31000, loss: 0.637397
 >> iter 32000, loss: 0.574577
 >> iter 33000, loss: 0.659362
 >> iter 34000, loss: 0.535651
 >> iter 35000, loss: 0.389989
 >> iter 36000, loss: 0.441090
 >> iter 37000, loss: 0.456657
 >> iter 38000, loss: 0.797531
 >> iter 39000, loss: 0.684659
 >> iter 40000, loss: 0.580536
   Number of active neurons: 6
 >> iter 41000, loss: 0.397461
 >> iter 42000, loss: 0.437959
 >> iter 43000, loss: 0.705155
 >> iter 44000, loss: 0.642735
 >> iter 45000, loss: 0.562730
 >> iter 46000, loss: 0.864118
 >> iter 47000, loss: 0.830062
 >> iter 48000, loss: 0.611724
 >> iter 49000, loss: 0.578861
 >> iter 50000, loss: 0.768955
   Number of active neurons: 7
 >> iter 51000, loss: 0.624514
 >> iter 52000, loss: 0.530326
 >> iter 53000, loss: 0.579646
 >> iter 54000, loss: 0.563229
 >> iter 55000, loss: 0.571730
 >> iter 56000, loss: 0.404090
 >> iter 57000, loss: 0.413741
 >> iter 58000, loss: 0.418088
 >> iter 59000, loss: 0.438541
 >> iter 60000, loss: 0.333196
   Number of active neurons: 6
 >> iter 61000, loss: 0.358989
 >> iter 62000, loss: 0.484562
 >> iter 63000, loss: 0.616555
 >> iter 64000, loss: 0.566186
 >> iter 65000, loss: 0.549581
 >> iter 66000, loss: 0.718163
 >> iter 67000, loss: 0.681432
 >> iter 68000, loss: 0.645009
 >> iter 69000, loss: 0.567070
 >> iter 70000, loss: 0.565134
   Number of active neurons: 6
 >> iter 71000, loss: 0.488909
 >> iter 72000, loss: 0.315717
 >> iter 73000, loss: 0.547020
 >> iter 74000, loss: 0.685508
 >> iter 75000, loss: 0.544397
 >> iter 76000, loss: 0.650041
 >> iter 77000, loss: 0.649330
 >> iter 78000, loss: 0.666774
 >> iter 79000, loss: 0.825242
 >> iter 80000, loss: 0.615083
   Number of active neurons: 6
 >> iter 81000, loss: 0.560979
 >> iter 82000, loss: 0.753570
 >> iter 83000, loss: 0.749204
 >> iter 84000, loss: 0.719964
 >> iter 85000, loss: 0.653488
 >> iter 86000, loss: 0.689266
 >> iter 87000, loss: 0.692070
 >> iter 88000, loss: 0.810211
 >> iter 89000, loss: 0.693905
 >> iter 90000, loss: 0.647127
   Number of active neurons: 6
 >> iter 91000, loss: 0.916723
 >> iter 92000, loss: 0.680481
 >> iter 93000, loss: 0.658317
 >> iter 94000, loss: 0.715683
 >> iter 95000, loss: 0.687260
 >> iter 96000, loss: 0.565135
 >> iter 97000, loss: 0.576102
 >> iter 98000, loss: 0.470795
 >> iter 99000, loss: 0.472722
 >> iter 100000, loss: 0.522997
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.129913
 >> iter 2000, loss: 10.511247
 >> iter 3000, loss: 7.408728
 >> iter 4000, loss: 4.750383
 >> iter 5000, loss: 2.762560
 >> iter 6000, loss: 1.692142
 >> iter 7000, loss: 1.413275
 >> iter 8000, loss: 1.055601
 >> iter 9000, loss: 0.747881
 >> iter 10000, loss: 0.639175
   Number of active neurons: 7
 >> iter 11000, loss: 0.544565
 >> iter 12000, loss: 0.534296
 >> iter 13000, loss: 0.489829
 >> iter 14000, loss: 0.530322
 >> iter 15000, loss: 0.507881
 >> iter 16000, loss: 0.499995
 >> iter 17000, loss: 0.485558
 >> iter 18000, loss: 0.561466
 >> iter 19000, loss: 0.527183
 >> iter 20000, loss: 0.772333
   Number of active neurons: 6
 >> iter 21000, loss: 0.588748
 >> iter 22000, loss: 0.477347
 >> iter 23000, loss: 0.539740
 >> iter 24000, loss: 0.463110
 >> iter 25000, loss: 0.479691
 >> iter 26000, loss: 0.525109
 >> iter 27000, loss: 0.520540
 >> iter 28000, loss: 0.466445
 >> iter 29000, loss: 0.550756
 >> iter 30000, loss: 0.393529
   Number of active neurons: 6
 >> iter 31000, loss: 0.545494
 >> iter 32000, loss: 0.453428
 >> iter 33000, loss: 0.501713
 >> iter 34000, loss: 0.356815
 >> iter 35000, loss: 0.431941
 >> iter 36000, loss: 0.432498
 >> iter 37000, loss: 0.505229
 >> iter 38000, loss: 0.546926
 >> iter 39000, loss: 0.517569
 >> iter 40000, loss: 0.437457
   Number of active neurons: 5
 >> iter 41000, loss: 0.495634
 >> iter 42000, loss: 0.521618
 >> iter 43000, loss: 0.366444
 >> iter 44000, loss: 0.377766
 >> iter 45000, loss: 0.455666
 >> iter 46000, loss: 0.332798
 >> iter 47000, loss: 0.348050
 >> iter 48000, loss: 0.356327
 >> iter 49000, loss: 0.466096
 >> iter 50000, loss: 0.426014
   Number of active neurons: 5
 >> iter 51000, loss: 0.517535
 >> iter 52000, loss: 0.504362
 >> iter 53000, loss: 0.501577
 >> iter 54000, loss: 0.455081
 >> iter 55000, loss: 0.366487
 >> iter 56000, loss: 0.369439
 >> iter 57000, loss: 0.376529
 >> iter 58000, loss: 0.491054
 >> iter 59000, loss: 0.444497
 >> iter 60000, loss: 0.462919
   Number of active neurons: 4
 >> iter 61000, loss: 0.484663
 >> iter 62000, loss: 0.393383
 >> iter 63000, loss: 0.465039
 >> iter 64000, loss: 0.437520
 >> iter 65000, loss: 0.570184
 >> iter 66000, loss: 0.498450
 >> iter 67000, loss: 0.494985
 >> iter 68000, loss: 0.617030
 >> iter 69000, loss: 0.594045
 >> iter 70000, loss: 0.439141
   Number of active neurons: 4
 >> iter 71000, loss: 0.530731
 >> iter 72000, loss: 0.540635
 >> iter 73000, loss: 0.505147
 >> iter 74000, loss: 0.534162
 >> iter 75000, loss: 0.429855
 >> iter 76000, loss: 0.449791
 >> iter 77000, loss: 0.410944
 >> iter 78000, loss: 0.428682
 >> iter 79000, loss: 0.419862
 >> iter 80000, loss: 0.517330
   Number of active neurons: 4
 >> iter 81000, loss: 0.677235
 >> iter 82000, loss: 0.566438
 >> iter 83000, loss: 0.568971
 >> iter 84000, loss: 0.609883
 >> iter 85000, loss: 0.548148
 >> iter 86000, loss: 0.536572
 >> iter 87000, loss: 0.437690
 >> iter 88000, loss: 0.524447
 >> iter 89000, loss: 0.455648
 >> iter 90000, loss: 0.403381
   Number of active neurons: 9
 >> iter 91000, loss: 0.523452
 >> iter 92000, loss: 0.402611
 >> iter 93000, loss: 0.335814
 >> iter 94000, loss: 0.405552
 >> iter 95000, loss: 0.379000
 >> iter 96000, loss: 0.388155
 >> iter 97000, loss: 0.306952
 >> iter 98000, loss: 0.362132
 >> iter 99000, loss: 0.399781
 >> iter 100000, loss: 0.525574
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.103588
 >> iter 2000, loss: 10.155677
 >> iter 3000, loss: 7.001448
 >> iter 4000, loss: 3.694500
 >> iter 5000, loss: 1.834680
 >> iter 6000, loss: 1.035411
 >> iter 7000, loss: 0.794521
 >> iter 8000, loss: 0.551246
 >> iter 9000, loss: 0.528659
 >> iter 10000, loss: 0.416504
   Number of active neurons: 6
 >> iter 11000, loss: 0.345033
 >> iter 12000, loss: 0.446617
 >> iter 13000, loss: 0.329147
 >> iter 14000, loss: 0.309792
 >> iter 15000, loss: 0.289729
 >> iter 16000, loss: 0.192056
 >> iter 17000, loss: 0.334431
 >> iter 18000, loss: 0.233346
 >> iter 19000, loss: 0.340219
 >> iter 20000, loss: 0.374449
   Number of active neurons: 6
 >> iter 21000, loss: 0.310076
 >> iter 22000, loss: 0.279027
 >> iter 23000, loss: 0.193146
 >> iter 24000, loss: 0.253050
 >> iter 25000, loss: 0.259539
 >> iter 26000, loss: 0.223116
 >> iter 27000, loss: 0.230426
 >> iter 28000, loss: 0.230880
 >> iter 29000, loss: 0.311085
 >> iter 30000, loss: 0.260466
   Number of active neurons: 6
 >> iter 31000, loss: 0.248411
 >> iter 32000, loss: 0.232525
 >> iter 33000, loss: 0.238730
 >> iter 34000, loss: 0.279010
 >> iter 35000, loss: 0.277120
 >> iter 36000, loss: 0.225048
 >> iter 37000, loss: 0.313728
 >> iter 38000, loss: 0.293392
 >> iter 39000, loss: 0.455834
 >> iter 40000, loss: 0.273587
   Number of active neurons: 6
 >> iter 41000, loss: 0.277280
 >> iter 42000, loss: 0.279225
 >> iter 43000, loss: 0.229297
 >> iter 44000, loss: 0.267087
 >> iter 45000, loss: 0.299213
 >> iter 46000, loss: 0.366306
 >> iter 47000, loss: 0.403201
 >> iter 48000, loss: 0.310224
 >> iter 49000, loss: 0.400690
 >> iter 50000, loss: 0.377914
   Number of active neurons: 6
 >> iter 51000, loss: 0.382379
 >> iter 52000, loss: 0.258323
 >> iter 53000, loss: 0.287297
 >> iter 54000, loss: 0.298338
 >> iter 55000, loss: 0.361637
 >> iter 56000, loss: 0.297671
 >> iter 57000, loss: 0.326560
 >> iter 58000, loss: 0.264649
 >> iter 59000, loss: 0.350947
 >> iter 60000, loss: 0.365198
   Number of active neurons: 6
 >> iter 61000, loss: 0.342394
 >> iter 62000, loss: 0.322856
 >> iter 63000, loss: 0.351171
 >> iter 64000, loss: 0.273302
 >> iter 65000, loss: 0.307235
 >> iter 66000, loss: 0.247331
 >> iter 67000, loss: 0.303816
 >> iter 68000, loss: 0.302561
 >> iter 69000, loss: 0.426562
 >> iter 70000, loss: 0.429118
   Number of active neurons: 6
 >> iter 71000, loss: 0.384435
 >> iter 72000, loss: 0.380025
 >> iter 73000, loss: 0.416768
 >> iter 74000, loss: 0.327610
 >> iter 75000, loss: 0.349403
 >> iter 76000, loss: 0.432396
 >> iter 77000, loss: 0.299080
 >> iter 78000, loss: 0.272658
 >> iter 79000, loss: 0.251876
 >> iter 80000, loss: 0.289804
   Number of active neurons: 6
 >> iter 81000, loss: 0.407927
 >> iter 82000, loss: 0.419082
 >> iter 83000, loss: 0.332133
 >> iter 84000, loss: 0.197500
 >> iter 85000, loss: 0.431096
 >> iter 86000, loss: 0.329213
 >> iter 87000, loss: 0.433640
 >> iter 88000, loss: 0.310932
 >> iter 89000, loss: 0.348232
 >> iter 90000, loss: 0.370246
   Number of active neurons: 6
 >> iter 91000, loss: 0.424546
 >> iter 92000, loss: 0.339172
 >> iter 93000, loss: 0.352207
 >> iter 94000, loss: 0.447595
 >> iter 95000, loss: 0.428441
 >> iter 96000, loss: 0.462852
 >> iter 97000, loss: 0.389717
 >> iter 98000, loss: 0.395115
 >> iter 99000, loss: 0.447429
 >> iter 100000, loss: 0.425341
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 15.0656622892
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.644651
 >> iter 2000, loss: 9.781265
 >> iter 3000, loss: 5.606842
 >> iter 4000, loss: 3.290625
 >> iter 5000, loss: 1.857955
 >> iter 6000, loss: 0.975142
 >> iter 7000, loss: 0.627841
 >> iter 8000, loss: 0.515270
 >> iter 9000, loss: 0.429234
 >> iter 10000, loss: 0.462333
   Number of active neurons: 8
 >> iter 11000, loss: 0.389499
 >> iter 12000, loss: 0.383919
 >> iter 13000, loss: 0.374542
 >> iter 14000, loss: 0.375745
 >> iter 15000, loss: 0.484251
 >> iter 16000, loss: 0.441141
 >> iter 17000, loss: 0.399986
 >> iter 18000, loss: 0.310836
 >> iter 19000, loss: 0.289945
 >> iter 20000, loss: 0.434938
   Number of active neurons: 8
 >> iter 21000, loss: 0.452470
 >> iter 22000, loss: 0.431242
 >> iter 23000, loss: 0.332197
 >> iter 24000, loss: 0.285262
 >> iter 25000, loss: 0.245613
 >> iter 26000, loss: 0.224189
 >> iter 27000, loss: 0.341313
 >> iter 28000, loss: 0.318283
 >> iter 29000, loss: 0.222858
 >> iter 30000, loss: 0.230932
   Number of active neurons: 8
 >> iter 31000, loss: 0.173299
 >> iter 32000, loss: 0.271383
 >> iter 33000, loss: 0.290929
 >> iter 34000, loss: 0.225654
 >> iter 35000, loss: 0.209964
 >> iter 36000, loss: 0.370384
 >> iter 37000, loss: 0.279710
 >> iter 38000, loss: 0.240533
 >> iter 39000, loss: 0.193517
 >> iter 40000, loss: 0.347060
   Number of active neurons: 8
 >> iter 41000, loss: 0.203498
 >> iter 42000, loss: 0.188743
 >> iter 43000, loss: 0.255934
 >> iter 44000, loss: 0.268593
 >> iter 45000, loss: 0.255849
 >> iter 46000, loss: 0.307558
 >> iter 47000, loss: 0.284552
 >> iter 48000, loss: 0.303175
 >> iter 49000, loss: 0.252687
 >> iter 50000, loss: 0.295567
   Number of active neurons: 8
 >> iter 51000, loss: 0.267818
 >> iter 52000, loss: 0.360371
 >> iter 53000, loss: 0.360598
 >> iter 54000, loss: 0.305321
 >> iter 55000, loss: 0.341657
 >> iter 56000, loss: 0.232995
 >> iter 57000, loss: 0.161370
 >> iter 58000, loss: 0.186031
 >> iter 59000, loss: 0.228919
 >> iter 60000, loss: 0.202144
   Number of active neurons: 7
 >> iter 61000, loss: 0.220151
 >> iter 62000, loss: 0.242693
 >> iter 63000, loss: 0.158088
 >> iter 64000, loss: 0.204952
 >> iter 65000, loss: 0.246214
 >> iter 66000, loss: 0.267777
 >> iter 67000, loss: 0.253616
 >> iter 68000, loss: 0.266686
 >> iter 69000, loss: 0.335194
 >> iter 70000, loss: 0.299325
   Number of active neurons: 7
 >> iter 71000, loss: 0.291706
 >> iter 72000, loss: 0.269797
 >> iter 73000, loss: 0.309479
 >> iter 74000, loss: 0.270885
 >> iter 75000, loss: 0.268853
 >> iter 76000, loss: 0.181748
 >> iter 77000, loss: 0.177898
 >> iter 78000, loss: 0.299671
 >> iter 79000, loss: 0.196498
 >> iter 80000, loss: 0.251338
   Number of active neurons: 7
 >> iter 81000, loss: 0.245450
 >> iter 82000, loss: 0.207618
 >> iter 83000, loss: 0.229532
 >> iter 84000, loss: 0.221154
 >> iter 85000, loss: 0.263787
 >> iter 86000, loss: 0.315800
 >> iter 87000, loss: 0.263393
 >> iter 88000, loss: 0.171091
 >> iter 89000, loss: 0.196079
 >> iter 90000, loss: 0.213906
   Number of active neurons: 7
 >> iter 91000, loss: 0.201891
 >> iter 92000, loss: 0.198108
 >> iter 93000, loss: 0.192675
 >> iter 94000, loss: 0.313945
 >> iter 95000, loss: 0.165691
 >> iter 96000, loss: 0.206089
 >> iter 97000, loss: 0.159132
 >> iter 98000, loss: 0.240074
 >> iter 99000, loss: 0.214580
 >> iter 100000, loss: 0.322090
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.740186
 >> iter 2000, loss: 9.609068
 >> iter 3000, loss: 5.583275
 >> iter 4000, loss: 3.133412
 >> iter 5000, loss: 1.990542
 >> iter 6000, loss: 1.321113
 >> iter 7000, loss: 1.192689
 >> iter 8000, loss: 0.962385
 >> iter 9000, loss: 0.798746
 >> iter 10000, loss: 0.709418
   Number of active neurons: 7
 >> iter 11000, loss: 0.504029
 >> iter 12000, loss: 0.578477
 >> iter 13000, loss: 0.496447
 >> iter 14000, loss: 0.470551
 >> iter 15000, loss: 0.583656
 >> iter 16000, loss: 0.518922
 >> iter 17000, loss: 0.430751
 >> iter 18000, loss: 0.464699
 >> iter 19000, loss: 0.423537
 >> iter 20000, loss: 0.380208
   Number of active neurons: 7
 >> iter 21000, loss: 0.419278
 >> iter 22000, loss: 0.320391
 >> iter 23000, loss: 0.295726
 >> iter 24000, loss: 0.364346
 >> iter 25000, loss: 0.347987
 >> iter 26000, loss: 0.289838
 >> iter 27000, loss: 0.373618
 >> iter 28000, loss: 0.394818
 >> iter 29000, loss: 0.531688
 >> iter 30000, loss: 0.525462
   Number of active neurons: 7
 >> iter 31000, loss: 0.498227
 >> iter 32000, loss: 0.457377
 >> iter 33000, loss: 0.474313
 >> iter 34000, loss: 0.583987
 >> iter 35000, loss: 0.495171
 >> iter 36000, loss: 0.524351
 >> iter 37000, loss: 0.574279
 >> iter 38000, loss: 0.471210
 >> iter 39000, loss: 0.386792
 >> iter 40000, loss: 0.368690
   Number of active neurons: 7
 >> iter 41000, loss: 0.362202
 >> iter 42000, loss: 0.345710
 >> iter 43000, loss: 0.418994
 >> iter 44000, loss: 0.473646
 >> iter 45000, loss: 0.367708
 >> iter 46000, loss: 0.366873
 >> iter 47000, loss: 0.486836
 >> iter 48000, loss: 0.499760
 >> iter 49000, loss: 0.356979
 >> iter 50000, loss: 0.298481
   Number of active neurons: 7
 >> iter 51000, loss: 0.315617
 >> iter 52000, loss: 0.475904
 >> iter 53000, loss: 0.437105
 >> iter 54000, loss: 0.380347
 >> iter 55000, loss: 0.303246
 >> iter 56000, loss: 0.293192
 >> iter 57000, loss: 0.409968
 >> iter 58000, loss: 0.492885
 >> iter 59000, loss: 0.386054
 >> iter 60000, loss: 0.502778
   Number of active neurons: 7
 >> iter 61000, loss: 0.497535
 >> iter 62000, loss: 0.476860
 >> iter 63000, loss: 0.532469
 >> iter 64000, loss: 0.568782
 >> iter 65000, loss: 0.436638
 >> iter 66000, loss: 0.519637
 >> iter 67000, loss: 0.428375
 >> iter 68000, loss: 0.332076
 >> iter 69000, loss: 0.369130
 >> iter 70000, loss: 0.481207
   Number of active neurons: 6
 >> iter 71000, loss: 0.507697
 >> iter 72000, loss: 0.373899
 >> iter 73000, loss: 0.341301
 >> iter 74000, loss: 0.341058
 >> iter 75000, loss: 0.425148
 >> iter 76000, loss: 0.367728
 >> iter 77000, loss: 0.364854
 >> iter 78000, loss: 0.435816
 >> iter 79000, loss: 0.434375
 >> iter 80000, loss: 0.397000
   Number of active neurons: 6
 >> iter 81000, loss: 0.363714
 >> iter 82000, loss: 0.457062
 >> iter 83000, loss: 0.384935
 >> iter 84000, loss: 0.288731
 >> iter 85000, loss: 0.388458
 >> iter 86000, loss: 0.303833
 >> iter 87000, loss: 0.316536
 >> iter 88000, loss: 0.358508
 >> iter 89000, loss: 0.370200
 >> iter 90000, loss: 0.501471
   Number of active neurons: 6
 >> iter 91000, loss: 0.429582
 >> iter 92000, loss: 0.458611
 >> iter 93000, loss: 0.390392
 >> iter 94000, loss: 0.465343
 >> iter 95000, loss: 0.368315
 >> iter 96000, loss: 0.512267
 >> iter 97000, loss: 0.463723
 >> iter 98000, loss: 0.442165
 >> iter 99000, loss: 0.354569
 >> iter 100000, loss: 0.281074
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.851224
 >> iter 2000, loss: 10.475698
 >> iter 3000, loss: 6.321506
 >> iter 4000, loss: 3.636224
 >> iter 5000, loss: 2.065923
 >> iter 6000, loss: 1.362672
 >> iter 7000, loss: 0.878521
 >> iter 8000, loss: 0.615533
 >> iter 9000, loss: 0.453978
 >> iter 10000, loss: 0.622775
   Number of active neurons: 5
 >> iter 11000, loss: 0.583695
 >> iter 12000, loss: 0.402805
 >> iter 13000, loss: 0.460727
 >> iter 14000, loss: 0.369297
 >> iter 15000, loss: 0.370740
 >> iter 16000, loss: 0.381933
 >> iter 17000, loss: 0.357597
 >> iter 18000, loss: 0.407113
 >> iter 19000, loss: 0.468191
 >> iter 20000, loss: 0.497732
   Number of active neurons: 5
 >> iter 21000, loss: 0.603608
 >> iter 22000, loss: 0.371027
 >> iter 23000, loss: 0.468638
 >> iter 24000, loss: 0.410484
 >> iter 25000, loss: 0.400441
 >> iter 26000, loss: 0.405272
 >> iter 27000, loss: 0.269547
 >> iter 28000, loss: 0.389223
 >> iter 29000, loss: 0.369455
 >> iter 30000, loss: 0.383958
   Number of active neurons: 5
 >> iter 31000, loss: 0.356695
 >> iter 32000, loss: 0.379984
 >> iter 33000, loss: 0.375025
 >> iter 34000, loss: 0.459003
 >> iter 35000, loss: 0.379031
 >> iter 36000, loss: 0.392575
 >> iter 37000, loss: 0.318258
 >> iter 38000, loss: 0.342665
 >> iter 39000, loss: 0.266992
 >> iter 40000, loss: 0.276865
   Number of active neurons: 5
 >> iter 41000, loss: 0.272304
 >> iter 42000, loss: 0.464923
 >> iter 43000, loss: 0.391097
 >> iter 44000, loss: 0.355488
 >> iter 45000, loss: 0.462319
 >> iter 46000, loss: 0.352992
 >> iter 47000, loss: 0.437869
 >> iter 48000, loss: 0.375202
 >> iter 49000, loss: 0.316962
 >> iter 50000, loss: 0.311962
   Number of active neurons: 5
 >> iter 51000, loss: 0.360340
 >> iter 52000, loss: 0.418256
 >> iter 53000, loss: 0.426133
 >> iter 54000, loss: 0.398081
 >> iter 55000, loss: 0.432343
 >> iter 56000, loss: 0.418668
 >> iter 57000, loss: 0.333421
 >> iter 58000, loss: 0.264382
 >> iter 59000, loss: 0.398669
 >> iter 60000, loss: 0.464198
   Number of active neurons: 5
 >> iter 61000, loss: 0.600350
 >> iter 62000, loss: 0.489668
 >> iter 63000, loss: 0.349466
 >> iter 64000, loss: 0.360523
 >> iter 65000, loss: 0.398076
 >> iter 66000, loss: 0.363046
 >> iter 67000, loss: 0.544401
 >> iter 68000, loss: 0.502204
 >> iter 69000, loss: 0.423874
 >> iter 70000, loss: 0.382559
   Number of active neurons: 5
 >> iter 71000, loss: 0.448987
 >> iter 72000, loss: 0.475177
 >> iter 73000, loss: 0.461603
 >> iter 74000, loss: 0.423530
 >> iter 75000, loss: 0.336934
 >> iter 76000, loss: 0.462760
 >> iter 77000, loss: 0.510409
 >> iter 78000, loss: 0.390221
 >> iter 79000, loss: 0.496581
 >> iter 80000, loss: 0.616406
   Number of active neurons: 5
 >> iter 81000, loss: 0.664614
 >> iter 82000, loss: 0.489245
 >> iter 83000, loss: 0.346241
 >> iter 84000, loss: 0.419795
 >> iter 85000, loss: 0.385977
 >> iter 86000, loss: 0.430780
 >> iter 87000, loss: 0.431628
 >> iter 88000, loss: 0.395990
 >> iter 89000, loss: 0.486838
 >> iter 90000, loss: 0.338624
   Number of active neurons: 5
 >> iter 91000, loss: 0.490226
 >> iter 92000, loss: 0.475049
 >> iter 93000, loss: 0.389849
 >> iter 94000, loss: 0.378550
 >> iter 95000, loss: 0.413073
 >> iter 96000, loss: 0.422373
 >> iter 97000, loss: 0.456988
 >> iter 98000, loss: 0.325332
 >> iter 99000, loss: 0.331470
 >> iter 100000, loss: 0.443584
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.429676
 >> iter 2000, loss: 10.627336
 >> iter 3000, loss: 7.167799
 >> iter 4000, loss: 3.538617
 >> iter 5000, loss: 1.646530
 >> iter 6000, loss: 0.941148
 >> iter 7000, loss: 0.561382
 >> iter 8000, loss: 0.370073
 >> iter 9000, loss: 0.313652
 >> iter 10000, loss: 0.224127
   Number of active neurons: 7
 >> iter 11000, loss: 0.298944
 >> iter 12000, loss: 0.269979
 >> iter 13000, loss: 0.333941
 >> iter 14000, loss: 0.326515
 >> iter 15000, loss: 0.287713
 >> iter 16000, loss: 0.295826
 >> iter 17000, loss: 0.276271
 >> iter 18000, loss: 0.320564
 >> iter 19000, loss: 0.399940
 >> iter 20000, loss: 0.313611
   Number of active neurons: 7
 >> iter 21000, loss: 0.248499
 >> iter 22000, loss: 0.323763
 >> iter 23000, loss: 0.341902
 >> iter 24000, loss: 0.452598
 >> iter 25000, loss: 0.364011
 >> iter 26000, loss: 0.356726
 >> iter 27000, loss: 0.273654
 >> iter 28000, loss: 0.390274
 >> iter 29000, loss: 0.266556
 >> iter 30000, loss: 0.239612
   Number of active neurons: 6
 >> iter 31000, loss: 0.261209
 >> iter 32000, loss: 0.228386
 >> iter 33000, loss: 0.252409
 >> iter 34000, loss: 0.297386
 >> iter 35000, loss: 0.348150
 >> iter 36000, loss: 0.415433
 >> iter 37000, loss: 0.304802
 >> iter 38000, loss: 0.350286
 >> iter 39000, loss: 0.383404
 >> iter 40000, loss: 0.393300
   Number of active neurons: 6
 >> iter 41000, loss: 0.301226
 >> iter 42000, loss: 0.374044
 >> iter 43000, loss: 0.417161
 >> iter 44000, loss: 0.357992
 >> iter 45000, loss: 0.335846
 >> iter 46000, loss: 0.356285
 >> iter 47000, loss: 0.368029
 >> iter 48000, loss: 0.395101
 >> iter 49000, loss: 0.320895
 >> iter 50000, loss: 0.337167
   Number of active neurons: 6
 >> iter 51000, loss: 0.325723
 >> iter 52000, loss: 0.284791
 >> iter 53000, loss: 0.316703
 >> iter 54000, loss: 0.364164
 >> iter 55000, loss: 0.447477
 >> iter 56000, loss: 0.271749
 >> iter 57000, loss: 0.261989
 >> iter 58000, loss: 0.243711
 >> iter 59000, loss: 0.422875
 >> iter 60000, loss: 0.419997
   Number of active neurons: 6
 >> iter 61000, loss: 0.532559
 >> iter 62000, loss: 0.422585
 >> iter 63000, loss: 0.298188
 >> iter 64000, loss: 0.318368
 >> iter 65000, loss: 0.330881
 >> iter 66000, loss: 0.435251
 >> iter 67000, loss: 0.401338
 >> iter 68000, loss: 0.320252
 >> iter 69000, loss: 0.241463
 >> iter 70000, loss: 0.354919
   Number of active neurons: 6
 >> iter 71000, loss: 0.421147
 >> iter 72000, loss: 0.430853
 >> iter 73000, loss: 0.531619
 >> iter 74000, loss: 0.403925
 >> iter 75000, loss: 0.334947
 >> iter 76000, loss: 0.347697
 >> iter 77000, loss: 0.264862
 >> iter 78000, loss: 0.250811
 >> iter 79000, loss: 0.276208
 >> iter 80000, loss: 0.456167
   Number of active neurons: 6
 >> iter 81000, loss: 0.343224
 >> iter 82000, loss: 0.314482
 >> iter 83000, loss: 0.240405
 >> iter 84000, loss: 0.320714
 >> iter 85000, loss: 0.379026
 >> iter 86000, loss: 0.346329
 >> iter 87000, loss: 0.273480
 >> iter 88000, loss: 0.390620
 >> iter 89000, loss: 0.475627
 >> iter 90000, loss: 0.427557
   Number of active neurons: 6
 >> iter 91000, loss: 0.453331
 >> iter 92000, loss: 0.459241
 >> iter 93000, loss: 0.637634
 >> iter 94000, loss: 0.479279
 >> iter 95000, loss: 0.438065
 >> iter 96000, loss: 0.319450
 >> iter 97000, loss: 0.382320
 >> iter 98000, loss: 0.368914
 >> iter 99000, loss: 0.484024
 >> iter 100000, loss: 0.416960
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

