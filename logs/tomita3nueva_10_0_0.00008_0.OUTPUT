 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 8e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.617971
 >> iter 2000, loss: 7.808648
 >> iter 3000, loss: 2.939764
 >> iter 4000, loss: 1.112977
 >> iter 5000, loss: 0.438993
 >> iter 6000, loss: 0.210068
 >> iter 7000, loss: 0.159434
 >> iter 8000, loss: 0.086011
 >> iter 9000, loss: 0.078644
 >> iter 10000, loss: 0.055200
   Number of active neurons: 7
 >> iter 11000, loss: 0.159236
 >> iter 12000, loss: 0.082321
 >> iter 13000, loss: 0.117616
 >> iter 14000, loss: 0.127511
 >> iter 15000, loss: 0.164845
 >> iter 16000, loss: 0.084950
 >> iter 17000, loss: 0.085899
 >> iter 18000, loss: 0.102591
 >> iter 19000, loss: 0.105465
 >> iter 20000, loss: 0.087918
   Number of active neurons: 6
 >> iter 21000, loss: 0.097224
 >> iter 22000, loss: 0.063930
 >> iter 23000, loss: 0.151266
 >> iter 24000, loss: 0.078955
 >> iter 25000, loss: 0.053031
 >> iter 26000, loss: 0.041422
 >> iter 27000, loss: 0.078152
 >> iter 28000, loss: 0.050551
 >> iter 29000, loss: 0.116652
 >> iter 30000, loss: 0.064096
   Number of active neurons: 6
 >> iter 31000, loss: 0.054339
 >> iter 32000, loss: 0.040834
 >> iter 33000, loss: 0.077857
 >> iter 34000, loss: 0.050227
 >> iter 35000, loss: 0.063105
 >> iter 36000, loss: 0.044888
 >> iter 37000, loss: 0.085846
 >> iter 38000, loss: 0.053075
 >> iter 39000, loss: 0.043636
 >> iter 40000, loss: 0.038205
   Number of active neurons: 6
 >> iter 41000, loss: 0.036691
 >> iter 42000, loss: 0.035935
 >> iter 43000, loss: 0.037321
 >> iter 44000, loss: 0.035831
 >> iter 45000, loss: 0.040934
 >> iter 46000, loss: 0.036134
 >> iter 47000, loss: 0.037701
 >> iter 48000, loss: 0.035525
 >> iter 49000, loss: 0.037930
 >> iter 50000, loss: 0.035408
   Number of active neurons: 6
 >> iter 51000, loss: 0.038272
 >> iter 52000, loss: 0.034915
 >> iter 53000, loss: 0.038736
 >> iter 54000, loss: 0.035002
 >> iter 55000, loss: 0.039976
 >> iter 56000, loss: 0.035552
 >> iter 57000, loss: 0.042624
 >> iter 58000, loss: 0.037712
 >> iter 59000, loss: 0.042595
 >> iter 60000, loss: 0.037585
   Number of active neurons: 6
 >> iter 61000, loss: 0.052677
 >> iter 62000, loss: 0.041101
 >> iter 63000, loss: 0.044040
 >> iter 64000, loss: 0.038750
 >> iter 65000, loss: 0.063487
 >> iter 66000, loss: 0.060532
 >> iter 67000, loss: 0.060048
 >> iter 68000, loss: 0.042811
 >> iter 69000, loss: 0.041695
 >> iter 70000, loss: 0.061117
   Number of active neurons: 6
 >> iter 71000, loss: 0.047219
 >> iter 72000, loss: 0.039590
 >> iter 73000, loss: 0.096555
 >> iter 74000, loss: 0.056381
 >> iter 75000, loss: 0.075325
 >> iter 76000, loss: 0.049252
 >> iter 77000, loss: 0.062061
 >> iter 78000, loss: 0.044452
 >> iter 79000, loss: 0.049061
 >> iter 80000, loss: 0.071180
   Number of active neurons: 6
 >> iter 81000, loss: 0.157091
 >> iter 82000, loss: 0.082535
 >> iter 83000, loss: 0.095847
 >> iter 84000, loss: 0.097462
 >> iter 85000, loss: 0.094971
 >> iter 86000, loss: 0.057282
 >> iter 87000, loss: 0.099322
 >> iter 88000, loss: 0.059544
 >> iter 89000, loss: 0.096851
 >> iter 90000, loss: 0.057638
   Number of active neurons: 6
 >> iter 91000, loss: 0.179828
 >> iter 92000, loss: 0.088462
 >> iter 93000, loss: 0.054841
 >> iter 94000, loss: 0.041238
 >> iter 95000, loss: 0.097017
 >> iter 96000, loss: 0.103864
 >> iter 97000, loss: 0.069243
 >> iter 98000, loss: 0.047343
 >> iter 99000, loss: 0.089473
 >> iter 100000, loss: 0.053295
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 21.4052396507
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.825979
 >> iter 2000, loss: 8.056708
 >> iter 3000, loss: 3.068124
 >> iter 4000, loss: 1.174898
 >> iter 5000, loss: 0.493955
 >> iter 6000, loss: 0.215706
 >> iter 7000, loss: 0.211443
 >> iter 8000, loss: 0.108449
 >> iter 9000, loss: 0.225719
 >> iter 10000, loss: 0.114046
   Number of active neurons: 7
 >> iter 11000, loss: 0.239393
 >> iter 12000, loss: 0.159601
 >> iter 13000, loss: 0.492847
 >> iter 14000, loss: 0.215098
 >> iter 15000, loss: 0.258468
 >> iter 16000, loss: 0.253831
 >> iter 17000, loss: 0.137297
 >> iter 18000, loss: 0.074118
 >> iter 19000, loss: 0.076235
 >> iter 20000, loss: 0.059392
   Number of active neurons: 6
 >> iter 21000, loss: 0.086172
 >> iter 22000, loss: 0.054462
 >> iter 23000, loss: 0.210297
 >> iter 24000, loss: 0.102002
 >> iter 25000, loss: 0.240222
 >> iter 26000, loss: 0.114326
 >> iter 27000, loss: 0.244054
 >> iter 28000, loss: 0.115803
 >> iter 29000, loss: 0.246452
 >> iter 30000, loss: 0.115921
   Number of active neurons: 6
 >> iter 31000, loss: 0.238695
 >> iter 32000, loss: 0.114189
 >> iter 33000, loss: 0.121511
 >> iter 34000, loss: 0.068824
 >> iter 35000, loss: 0.093499
 >> iter 36000, loss: 0.056894
 >> iter 37000, loss: 0.214439
 >> iter 38000, loss: 0.103597
 >> iter 39000, loss: 0.122233
 >> iter 40000, loss: 0.067742
   Number of active neurons: 6
 >> iter 41000, loss: 0.211709
 >> iter 42000, loss: 0.105600
 >> iter 43000, loss: 0.115230
 >> iter 44000, loss: 0.067275
 >> iter 45000, loss: 0.252681
 >> iter 46000, loss: 0.117924
 >> iter 47000, loss: 0.140493
 >> iter 48000, loss: 0.072614
 >> iter 49000, loss: 0.140393
 >> iter 50000, loss: 0.074898
   Number of active neurons: 6
 >> iter 51000, loss: 0.207630
 >> iter 52000, loss: 0.176292
 >> iter 53000, loss: 0.263523
 >> iter 54000, loss: 0.121894
 >> iter 55000, loss: 0.229038
 >> iter 56000, loss: 0.109346
 >> iter 57000, loss: 0.242121
 >> iter 58000, loss: 0.112977
 >> iter 59000, loss: 0.104595
 >> iter 60000, loss: 0.062440
   Number of active neurons: 6
 >> iter 61000, loss: 0.090381
 >> iter 62000, loss: 0.054739
 >> iter 63000, loss: 0.217771
 >> iter 64000, loss: 0.103547
 >> iter 65000, loss: 0.103407
 >> iter 66000, loss: 0.061268
 >> iter 67000, loss: 0.086271
 >> iter 68000, loss: 0.055321
 >> iter 69000, loss: 0.169515
 >> iter 70000, loss: 0.086466
   Number of active neurons: 6
 >> iter 71000, loss: 0.177362
 >> iter 72000, loss: 0.097585
 >> iter 73000, loss: 0.105711
 >> iter 74000, loss: 0.061916
 >> iter 75000, loss: 0.263692
 >> iter 76000, loss: 0.136933
 >> iter 77000, loss: 0.108721
 >> iter 78000, loss: 0.163396
 >> iter 79000, loss: 0.117038
 >> iter 80000, loss: 0.174275
   Number of active neurons: 6
 >> iter 81000, loss: 0.120222
 >> iter 82000, loss: 0.067016
 >> iter 83000, loss: 0.485932
 >> iter 84000, loss: 0.205055
 >> iter 85000, loss: 0.131384
 >> iter 86000, loss: 0.071632
 >> iter 87000, loss: 0.186387
 >> iter 88000, loss: 0.091845
 >> iter 89000, loss: 0.123084
 >> iter 90000, loss: 0.065689
   Number of active neurons: 6
 >> iter 91000, loss: 0.166243
 >> iter 92000, loss: 0.083103
 >> iter 93000, loss: 0.181641
 >> iter 94000, loss: 0.087939
 >> iter 95000, loss: 0.084701
 >> iter 96000, loss: 0.053214
 >> iter 97000, loss: 0.248594
 >> iter 98000, loss: 0.114173
 >> iter 99000, loss: 0.093706
 >> iter 100000, loss: 0.057447
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0089999100009
   - Test - A: 0.0
   - Test - B: 13.2857809479
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.967870
 >> iter 2000, loss: 8.016597
 >> iter 3000, loss: 3.015801
 >> iter 4000, loss: 1.155651
 >> iter 5000, loss: 0.847793
 >> iter 6000, loss: 0.365982
 >> iter 7000, loss: 0.282407
 >> iter 8000, loss: 0.145130
 >> iter 9000, loss: 0.144705
 >> iter 10000, loss: 0.113803
   Number of active neurons: 7
 >> iter 11000, loss: 0.244234
 >> iter 12000, loss: 0.135885
 >> iter 13000, loss: 0.163994
 >> iter 14000, loss: 0.107593
 >> iter 15000, loss: 0.066762
 >> iter 16000, loss: 0.114689
 >> iter 17000, loss: 0.069709
 >> iter 18000, loss: 0.095113
 >> iter 19000, loss: 0.113961
 >> iter 20000, loss: 0.330748
   Number of active neurons: 7
 >> iter 21000, loss: 0.154515
 >> iter 22000, loss: 0.160142
 >> iter 23000, loss: 0.238732
 >> iter 24000, loss: 0.134779
 >> iter 25000, loss: 0.100275
 >> iter 26000, loss: 0.101405
 >> iter 27000, loss: 0.130613
 >> iter 28000, loss: 0.075917
 >> iter 29000, loss: 0.065003
 >> iter 30000, loss: 0.051269
   Number of active neurons: 6
 >> iter 31000, loss: 0.232784
 >> iter 32000, loss: 0.150230
 >> iter 33000, loss: 0.081942
 >> iter 34000, loss: 0.103246
 >> iter 35000, loss: 0.064312
 >> iter 36000, loss: 0.112301
 >> iter 37000, loss: 0.068218
 >> iter 38000, loss: 0.073714
 >> iter 39000, loss: 0.167228
 >> iter 40000, loss: 0.149745
   Number of active neurons: 6
 >> iter 41000, loss: 0.092822
 >> iter 42000, loss: 0.081124
 >> iter 43000, loss: 0.069361
 >> iter 44000, loss: 0.153916
 >> iter 45000, loss: 0.092644
 >> iter 46000, loss: 0.135493
 >> iter 47000, loss: 0.081713
 >> iter 48000, loss: 0.117610
 >> iter 49000, loss: 0.073105
 >> iter 50000, loss: 0.088812
   Number of active neurons: 5
 >> iter 51000, loss: 0.058740
 >> iter 52000, loss: 0.102132
 >> iter 53000, loss: 0.064982
 >> iter 54000, loss: 0.053708
 >> iter 55000, loss: 0.045837
 >> iter 56000, loss: 0.048435
 >> iter 57000, loss: 0.194837
 >> iter 58000, loss: 0.096732
 >> iter 59000, loss: 0.064499
 >> iter 60000, loss: 0.066941
   Number of active neurons: 5
 >> iter 61000, loss: 0.045757
 >> iter 62000, loss: 0.060233
 >> iter 63000, loss: 0.095930
 >> iter 64000, loss: 0.055214
 >> iter 65000, loss: 0.065618
 >> iter 66000, loss: 0.084752
 >> iter 67000, loss: 0.060269
 >> iter 68000, loss: 0.042195
 >> iter 69000, loss: 0.051723
 >> iter 70000, loss: 0.044388
   Number of active neurons: 4
 >> iter 71000, loss: 0.055722
 >> iter 72000, loss: 0.135513
 >> iter 73000, loss: 0.082970
 >> iter 74000, loss: 0.067425
 >> iter 75000, loss: 0.053384
 >> iter 76000, loss: 0.104319
 >> iter 77000, loss: 0.061029
 >> iter 78000, loss: 0.107534
 >> iter 79000, loss: 0.066847
 >> iter 80000, loss: 0.107081
   Number of active neurons: 4
 >> iter 81000, loss: 0.062938
 >> iter 82000, loss: 0.106329
 >> iter 83000, loss: 0.060480
 >> iter 84000, loss: 0.059840
 >> iter 85000, loss: 0.061712
 >> iter 86000, loss: 0.103498
 >> iter 87000, loss: 0.058624
 >> iter 88000, loss: 0.056606
 >> iter 89000, loss: 0.061002
 >> iter 90000, loss: 0.041599
   Number of active neurons: 4
 >> iter 91000, loss: 0.052993
 >> iter 92000, loss: 0.116771
 >> iter 93000, loss: 0.066254
 >> iter 94000, loss: 0.042697
 >> iter 95000, loss: 0.055853
 >> iter 96000, loss: 0.038882
 >> iter 97000, loss: 0.085411
 >> iter 98000, loss: 0.049337
 >> iter 99000, loss: 0.101800
 >> iter 100000, loss: 0.057907
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.04999900002
   - Test - Long: 0.0
   - Test - Big: 0.0129998700013
   - Test - A: 0.0
   - Test - B: 13.685754283
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.969361
 >> iter 2000, loss: 8.552612
 >> iter 3000, loss: 3.215497
 >> iter 4000, loss: 1.286909
 >> iter 5000, loss: 0.552073
 >> iter 6000, loss: 0.253182
 >> iter 7000, loss: 0.225374
 >> iter 8000, loss: 0.177940
 >> iter 9000, loss: 0.113814
 >> iter 10000, loss: 0.068939
   Number of active neurons: 6
 >> iter 11000, loss: 0.260595
 >> iter 12000, loss: 0.124374
 >> iter 13000, loss: 0.082331
 >> iter 14000, loss: 0.066416
 >> iter 15000, loss: 0.050335
 >> iter 16000, loss: 0.132690
 >> iter 17000, loss: 0.073957
 >> iter 18000, loss: 0.051775
 >> iter 19000, loss: 0.043494
 >> iter 20000, loss: 0.046105
   Number of active neurons: 6
 >> iter 21000, loss: 0.038820
 >> iter 22000, loss: 0.036494
 >> iter 23000, loss: 0.036089
 >> iter 24000, loss: 0.035646
 >> iter 25000, loss: 0.035742
 >> iter 26000, loss: 0.035462
 >> iter 27000, loss: 0.035539
 >> iter 28000, loss: 0.035331
 >> iter 29000, loss: 0.035296
 >> iter 30000, loss: 0.035054
   Number of active neurons: 6
 >> iter 31000, loss: 0.034958
 >> iter 32000, loss: 0.034699
 >> iter 33000, loss: 0.034552
 >> iter 34000, loss: 0.034152
 >> iter 35000, loss: 0.033833
 >> iter 36000, loss: 0.033056
 >> iter 37000, loss: 0.032912
 >> iter 38000, loss: 0.032159
 >> iter 39000, loss: 0.041277
 >> iter 40000, loss: 0.035202
   Number of active neurons: 6
 >> iter 41000, loss: 0.057039
 >> iter 42000, loss: 0.040920
 >> iter 43000, loss: 0.035524
 >> iter 44000, loss: 0.033460
 >> iter 45000, loss: 0.033095
 >> iter 46000, loss: 0.032685
 >> iter 47000, loss: 0.032943
 >> iter 48000, loss: 0.032810
 >> iter 49000, loss: 0.033142
 >> iter 50000, loss: 0.033051
   Number of active neurons: 6
 >> iter 51000, loss: 0.033360
 >> iter 52000, loss: 0.033180
 >> iter 53000, loss: 0.033388
 >> iter 54000, loss: 0.033151
 >> iter 55000, loss: 0.033340
 >> iter 56000, loss: 0.032951
 >> iter 57000, loss: 0.033086
 >> iter 58000, loss: 0.032728
 >> iter 59000, loss: 0.032887
 >> iter 60000, loss: 0.032571
   Number of active neurons: 6
 >> iter 61000, loss: 0.032754
 >> iter 62000, loss: 0.032426
 >> iter 63000, loss: 0.032648
 >> iter 64000, loss: 0.032340
 >> iter 65000, loss: 0.032572
 >> iter 66000, loss: 0.032279
 >> iter 67000, loss: 0.032533
 >> iter 68000, loss: 0.032252
 >> iter 69000, loss: 0.032487
 >> iter 70000, loss: 0.032178
   Number of active neurons: 6
 >> iter 71000, loss: 0.032348
 >> iter 72000, loss: 0.032004
 >> iter 73000, loss: 0.032123
 >> iter 74000, loss: 0.031745
 >> iter 75000, loss: 0.031900
 >> iter 76000, loss: 0.031577
 >> iter 77000, loss: 0.031748
 >> iter 78000, loss: 0.031434
 >> iter 79000, loss: 0.031544
 >> iter 80000, loss: 0.031155
   Number of active neurons: 6
 >> iter 81000, loss: 0.031243
 >> iter 82000, loss: 0.030883
 >> iter 83000, loss: 0.030967
 >> iter 84000, loss: 0.030608
 >> iter 85000, loss: 0.030685
 >> iter 86000, loss: 0.030317
 >> iter 87000, loss: 0.030347
 >> iter 88000, loss: 0.029914
 >> iter 89000, loss: 0.029879
 >> iter 90000, loss: 0.029481
   Number of active neurons: 6
 >> iter 91000, loss: 0.029498
 >> iter 92000, loss: 0.029131
 >> iter 93000, loss: 0.029186
 >> iter 94000, loss: 0.028843
 >> iter 95000, loss: 0.028937
 >> iter 96000, loss: 0.028494
 >> iter 97000, loss: 0.028439
 >> iter 98000, loss: 0.027887
 >> iter 99000, loss: 0.027856
 >> iter 100000, loss: 0.027335
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 10.2793147124
   - Test - B: 20.3919738684
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.838794
 >> iter 2000, loss: 7.828666
 >> iter 3000, loss: 3.039009
 >> iter 4000, loss: 1.159510
 >> iter 5000, loss: 0.507510
 >> iter 6000, loss: 0.218550
 >> iter 7000, loss: 0.108444
 >> iter 8000, loss: 0.071830
 >> iter 9000, loss: 0.107931
 >> iter 10000, loss: 0.073277
   Number of active neurons: 7
 >> iter 11000, loss: 0.104043
 >> iter 12000, loss: 0.079281
 >> iter 13000, loss: 0.093573
 >> iter 14000, loss: 0.066441
 >> iter 15000, loss: 0.060026
 >> iter 16000, loss: 0.065825
 >> iter 17000, loss: 0.071392
 >> iter 18000, loss: 0.057514
 >> iter 19000, loss: 0.047183
 >> iter 20000, loss: 0.048687
   Number of active neurons: 7
 >> iter 21000, loss: 0.064017
 >> iter 22000, loss: 0.048430
 >> iter 23000, loss: 0.115627
 >> iter 24000, loss: 0.065185
 >> iter 25000, loss: 0.050816
 >> iter 26000, loss: 0.043578
 >> iter 27000, loss: 0.062664
 >> iter 28000, loss: 0.047531
 >> iter 29000, loss: 0.043949
 >> iter 30000, loss: 0.040339
   Number of active neurons: 6
 >> iter 31000, loss: 0.039518
 >> iter 32000, loss: 0.042450
 >> iter 33000, loss: 0.039560
 >> iter 34000, loss: 0.037177
 >> iter 35000, loss: 0.037947
 >> iter 36000, loss: 0.036653
 >> iter 37000, loss: 0.039628
 >> iter 38000, loss: 0.037352
 >> iter 39000, loss: 0.041403
 >> iter 40000, loss: 0.038051
   Number of active neurons: 6
 >> iter 41000, loss: 0.106662
 >> iter 42000, loss: 0.063779
 >> iter 43000, loss: 0.119469
 >> iter 44000, loss: 0.069190
 >> iter 45000, loss: 0.190578
 >> iter 46000, loss: 0.096750
 >> iter 47000, loss: 0.181012
 >> iter 48000, loss: 0.092994
 >> iter 49000, loss: 0.145995
 >> iter 50000, loss: 0.081001
   Number of active neurons: 6
 >> iter 51000, loss: 0.133407
 >> iter 52000, loss: 0.075208
 >> iter 53000, loss: 0.157112
 >> iter 54000, loss: 0.083844
 >> iter 55000, loss: 0.129056
 >> iter 56000, loss: 0.075517
 >> iter 57000, loss: 0.053717
 >> iter 58000, loss: 0.044642
 >> iter 59000, loss: 0.041587
 >> iter 60000, loss: 0.037665
   Number of active neurons: 6
 >> iter 61000, loss: 0.037858
 >> iter 62000, loss: 0.036007
 >> iter 63000, loss: 0.037192
 >> iter 64000, loss: 0.035445
 >> iter 65000, loss: 0.037174
 >> iter 66000, loss: 0.035292
 >> iter 67000, loss: 0.036556
 >> iter 68000, loss: 0.135428
 >> iter 69000, loss: 0.072892
 >> iter 70000, loss: 0.048776
   Number of active neurons: 6
 >> iter 71000, loss: 0.041395
 >> iter 72000, loss: 0.037199
 >> iter 73000, loss: 0.036460
 >> iter 74000, loss: 0.035213
 >> iter 75000, loss: 0.035519
 >> iter 76000, loss: 0.069975
 >> iter 77000, loss: 0.049217
 >> iter 78000, loss: 0.089334
 >> iter 79000, loss: 0.056925
 >> iter 80000, loss: 0.087139
   Number of active neurons: 6
 >> iter 81000, loss: 0.060971
 >> iter 82000, loss: 0.045527
 >> iter 83000, loss: 0.040285
 >> iter 84000, loss: 0.037791
 >> iter 85000, loss: 0.094936
 >> iter 86000, loss: 0.108961
 >> iter 87000, loss: 0.127905
 >> iter 88000, loss: 0.071132
 >> iter 89000, loss: 0.112602
 >> iter 90000, loss: 0.066544
   Number of active neurons: 5
 >> iter 91000, loss: 0.108714
 >> iter 92000, loss: 0.063472
 >> iter 93000, loss: 0.105278
 >> iter 94000, loss: 0.062123
 >> iter 95000, loss: 0.098064
 >> iter 96000, loss: 0.059004
 >> iter 97000, loss: 0.069111
 >> iter 98000, loss: 0.047217
 >> iter 99000, loss: 0.039430
 >> iter 100000, loss: 0.035833
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.00599988000241
   - Test - Long: 0.0
   - Test - Big: 0.0049999500005
   - Test - A: 3.10645956936
   - Test - B: 22.7918138791
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.710173
 >> iter 2000, loss: 7.920097
 >> iter 3000, loss: 2.971001
 >> iter 4000, loss: 1.128337
 >> iter 5000, loss: 0.448975
 >> iter 6000, loss: 0.194340
 >> iter 7000, loss: 0.101433
 >> iter 8000, loss: 0.064554
 >> iter 9000, loss: 0.054245
 >> iter 10000, loss: 0.046052
   Number of active neurons: 9
 >> iter 11000, loss: 0.045343
 >> iter 12000, loss: 0.041213
 >> iter 13000, loss: 0.041806
 >> iter 14000, loss: 0.039649
 >> iter 15000, loss: 0.040043
 >> iter 16000, loss: 0.039514
 >> iter 17000, loss: 0.041099
 >> iter 18000, loss: 0.039276
 >> iter 19000, loss: 0.039481
 >> iter 20000, loss: 0.039029
   Number of active neurons: 7
 >> iter 21000, loss: 0.039773
 >> iter 22000, loss: 0.072390
 >> iter 23000, loss: 0.055917
 >> iter 24000, loss: 0.045052
 >> iter 25000, loss: 0.050478
 >> iter 26000, loss: 0.044127
 >> iter 27000, loss: 0.041552
 >> iter 28000, loss: 0.041169
 >> iter 29000, loss: 0.038963
 >> iter 30000, loss: 0.041360
   Number of active neurons: 7
 >> iter 31000, loss: 0.039264
 >> iter 32000, loss: 0.045338
 >> iter 33000, loss: 0.040113
 >> iter 34000, loss: 0.042777
 >> iter 35000, loss: 0.039797
 >> iter 36000, loss: 0.043822
 >> iter 37000, loss: 0.038834
 >> iter 38000, loss: 0.042138
 >> iter 39000, loss: 0.039898
 >> iter 40000, loss: 0.040492
   Number of active neurons: 6
 >> iter 41000, loss: 0.038806
 >> iter 42000, loss: 0.041191
 >> iter 43000, loss: 0.037660
 >> iter 44000, loss: 0.042822
 >> iter 45000, loss: 0.037714
 >> iter 46000, loss: 0.042560
 >> iter 47000, loss: 0.038182
 >> iter 48000, loss: 0.040381
 >> iter 49000, loss: 0.037506
 >> iter 50000, loss: 0.045970
   Number of active neurons: 6
 >> iter 51000, loss: 0.039872
 >> iter 52000, loss: 0.071321
 >> iter 53000, loss: 0.049048
 >> iter 54000, loss: 0.093077
 >> iter 55000, loss: 0.057330
 >> iter 56000, loss: 0.050872
 >> iter 57000, loss: 0.042308
 >> iter 58000, loss: 0.092334
 >> iter 59000, loss: 0.058584
 >> iter 60000, loss: 0.105498
   Number of active neurons: 6
 >> iter 61000, loss: 0.121109
 >> iter 62000, loss: 0.073736
 >> iter 63000, loss: 0.103870
 >> iter 64000, loss: 0.071891
 >> iter 65000, loss: 0.103531
 >> iter 66000, loss: 0.070469
 >> iter 67000, loss: 0.101650
 >> iter 68000, loss: 0.072726
 >> iter 69000, loss: 0.103594
 >> iter 70000, loss: 0.073198
   Number of active neurons: 6
 >> iter 71000, loss: 0.114411
 >> iter 72000, loss: 0.072748
 >> iter 73000, loss: 0.098225
 >> iter 74000, loss: 0.069779
 >> iter 75000, loss: 0.103260
 >> iter 76000, loss: 0.071642
 >> iter 77000, loss: 0.103466
 >> iter 78000, loss: 0.069940
 >> iter 79000, loss: 0.103104
 >> iter 80000, loss: 0.073330
   Number of active neurons: 6
 >> iter 81000, loss: 0.122421
 >> iter 82000, loss: 0.094538
 >> iter 83000, loss: 0.065510
 >> iter 84000, loss: 0.062206
 >> iter 85000, loss: 0.093418
 >> iter 86000, loss: 0.060786
 >> iter 87000, loss: 0.148249
 >> iter 88000, loss: 0.077312
 >> iter 89000, loss: 0.145273
 >> iter 90000, loss: 0.076458
   Number of active neurons: 5
 >> iter 91000, loss: 0.050639
 >> iter 92000, loss: 0.040534
 >> iter 93000, loss: 0.036655
 >> iter 94000, loss: 0.034873
 >> iter 95000, loss: 0.034226
 >> iter 96000, loss: 0.033597
 >> iter 97000, loss: 0.033395
 >> iter 98000, loss: 0.032946
 >> iter 99000, loss: 0.032866
 >> iter 100000, loss: 0.032456
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.897244
 >> iter 2000, loss: 7.745306
 >> iter 3000, loss: 2.982315
 >> iter 4000, loss: 1.139801
 >> iter 5000, loss: 0.545060
 >> iter 6000, loss: 0.249848
 >> iter 7000, loss: 0.288637
 >> iter 8000, loss: 0.185830
 >> iter 9000, loss: 0.107911
 >> iter 10000, loss: 0.067991
   Number of active neurons: 7
 >> iter 11000, loss: 0.315146
 >> iter 12000, loss: 0.158691
 >> iter 13000, loss: 0.211985
 >> iter 14000, loss: 0.131832
 >> iter 15000, loss: 0.122018
 >> iter 16000, loss: 0.155720
 >> iter 17000, loss: 0.222976
 >> iter 18000, loss: 0.108263
 >> iter 19000, loss: 0.139094
 >> iter 20000, loss: 0.080780
   Number of active neurons: 7
 >> iter 21000, loss: 0.107367
 >> iter 22000, loss: 0.081602
 >> iter 23000, loss: 0.265217
 >> iter 24000, loss: 0.180529
 >> iter 25000, loss: 0.212307
 >> iter 26000, loss: 0.111197
 >> iter 27000, loss: 0.132666
 >> iter 28000, loss: 0.075771
 >> iter 29000, loss: 0.162715
 >> iter 30000, loss: 0.119438
   Number of active neurons: 7
 >> iter 31000, loss: 0.234738
 >> iter 32000, loss: 0.114712
 >> iter 33000, loss: 0.169499
 >> iter 34000, loss: 0.133525
 >> iter 35000, loss: 0.140786
 >> iter 36000, loss: 0.141925
 >> iter 37000, loss: 0.082602
 >> iter 38000, loss: 0.091049
 >> iter 39000, loss: 0.186799
 >> iter 40000, loss: 0.114472
   Number of active neurons: 7
 >> iter 41000, loss: 0.163610
 >> iter 42000, loss: 0.086478
 >> iter 43000, loss: 0.057180
 >> iter 44000, loss: 0.045473
 >> iter 45000, loss: 0.050865
 >> iter 46000, loss: 0.047003
 >> iter 47000, loss: 0.048267
 >> iter 48000, loss: 0.046876
 >> iter 49000, loss: 0.042694
 >> iter 50000, loss: 0.181477
   Number of active neurons: 6
 >> iter 51000, loss: 0.092279
 >> iter 52000, loss: 0.059184
 >> iter 53000, loss: 0.048780
 >> iter 54000, loss: 0.047321
 >> iter 55000, loss: 0.315880
 >> iter 56000, loss: 0.147722
 >> iter 57000, loss: 0.088321
 >> iter 58000, loss: 0.115541
 >> iter 59000, loss: 0.179835
 >> iter 60000, loss: 0.116172
   Number of active neurons: 4
 >> iter 61000, loss: 0.238343
 >> iter 62000, loss: 0.119595
 >> iter 63000, loss: 0.100022
 >> iter 64000, loss: 0.065420
 >> iter 65000, loss: 0.204884
 >> iter 66000, loss: 0.104485
 >> iter 67000, loss: 0.149337
 >> iter 68000, loss: 0.107141
 >> iter 69000, loss: 0.135682
 >> iter 70000, loss: 0.092168
   Number of active neurons: 4
 >> iter 71000, loss: 0.235375
 >> iter 72000, loss: 0.143552
 >> iter 73000, loss: 0.093233
 >> iter 74000, loss: 0.084578
 >> iter 75000, loss: 0.392062
 >> iter 76000, loss: 0.177173
 >> iter 77000, loss: 0.264467
 >> iter 78000, loss: 0.130044
 >> iter 79000, loss: 0.173168
 >> iter 80000, loss: 0.098443
   Number of active neurons: 4
 >> iter 81000, loss: 0.112123
 >> iter 82000, loss: 0.083400
 >> iter 83000, loss: 0.103918
 >> iter 84000, loss: 0.075623
 >> iter 85000, loss: 0.066447
 >> iter 86000, loss: 0.117863
 >> iter 87000, loss: 0.120629
 >> iter 88000, loss: 0.072786
 >> iter 89000, loss: 0.052109
 >> iter 90000, loss: 0.082826
   Number of active neurons: 5
 >> iter 91000, loss: 0.138943
 >> iter 92000, loss: 0.093931
 >> iter 93000, loss: 0.148252
 >> iter 94000, loss: 0.084724
 >> iter 95000, loss: 0.118813
 >> iter 96000, loss: 0.102254
 >> iter 97000, loss: 0.112881
 >> iter 98000, loss: 0.066120
 >> iter 99000, loss: 0.273956
 >> iter 100000, loss: 0.126481
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.00599988000241
   - Test - Long: 0.424978751062
   - Test - Big: 0.0239997600024
   - Test - A: 0.0
   - Test - B: 21.5052329845
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.018072
 >> iter 2000, loss: 9.946715
 >> iter 3000, loss: 4.027281
 >> iter 4000, loss: 1.709430
 >> iter 5000, loss: 0.671319
 >> iter 6000, loss: 0.291486
 >> iter 7000, loss: 0.140284
 >> iter 8000, loss: 0.185967
 >> iter 9000, loss: 0.100197
 >> iter 10000, loss: 0.068448
   Number of active neurons: 8
 >> iter 11000, loss: 0.054480
 >> iter 12000, loss: 0.047708
 >> iter 13000, loss: 0.086640
 >> iter 14000, loss: 0.058596
 >> iter 15000, loss: 0.049020
 >> iter 16000, loss: 0.063832
 >> iter 17000, loss: 0.184336
 >> iter 18000, loss: 0.183595
 >> iter 19000, loss: 0.144049
 >> iter 20000, loss: 0.247033
   Number of active neurons: 8
 >> iter 21000, loss: 0.165909
 >> iter 22000, loss: 0.134098
 >> iter 23000, loss: 0.177248
 >> iter 24000, loss: 0.131566
 >> iter 25000, loss: 0.151627
 >> iter 26000, loss: 0.242046
 >> iter 27000, loss: 0.200471
 >> iter 28000, loss: 0.216268
 >> iter 29000, loss: 0.215791
 >> iter 30000, loss: 0.165340
   Number of active neurons: 7
 >> iter 31000, loss: 0.199790
 >> iter 32000, loss: 0.127051
 >> iter 33000, loss: 0.240516
 >> iter 34000, loss: 0.282655
 >> iter 35000, loss: 0.371059
 >> iter 36000, loss: 0.181945
 >> iter 37000, loss: 0.186547
 >> iter 38000, loss: 0.275722
 >> iter 39000, loss: 0.193736
 >> iter 40000, loss: 0.180737
   Number of active neurons: 7
 >> iter 41000, loss: 0.161915
 >> iter 42000, loss: 0.190875
 >> iter 43000, loss: 0.114282
 >> iter 44000, loss: 0.129313
 >> iter 45000, loss: 0.127652
 >> iter 46000, loss: 0.156297
 >> iter 47000, loss: 0.091926
 >> iter 48000, loss: 0.145411
 >> iter 49000, loss: 0.098703
 >> iter 50000, loss: 0.120457
   Number of active neurons: 6
 >> iter 51000, loss: 0.074961
 >> iter 52000, loss: 0.136949
 >> iter 53000, loss: 0.081736
 >> iter 54000, loss: 0.133454
 >> iter 55000, loss: 0.205569
 >> iter 56000, loss: 0.105033
 >> iter 57000, loss: 0.069478
 >> iter 58000, loss: 0.051752
 >> iter 59000, loss: 0.049380
 >> iter 60000, loss: 0.074825
   Number of active neurons: 6
 >> iter 61000, loss: 0.081413
 >> iter 62000, loss: 0.054130
 >> iter 63000, loss: 0.221716
 >> iter 64000, loss: 0.110398
 >> iter 65000, loss: 0.185373
 >> iter 66000, loss: 0.094106
 >> iter 67000, loss: 0.067170
 >> iter 68000, loss: 0.049447
 >> iter 69000, loss: 0.077817
 >> iter 70000, loss: 0.052623
   Number of active neurons: 6
 >> iter 71000, loss: 0.182337
 >> iter 72000, loss: 0.093120
 >> iter 73000, loss: 0.131972
 >> iter 74000, loss: 0.074344
 >> iter 75000, loss: 0.112251
 >> iter 76000, loss: 0.065949
 >> iter 77000, loss: 0.066508
 >> iter 78000, loss: 0.075777
 >> iter 79000, loss: 0.185456
 >> iter 80000, loss: 0.093952
   Number of active neurons: 6
 >> iter 81000, loss: 0.068630
 >> iter 82000, loss: 0.049343
 >> iter 83000, loss: 0.045653
 >> iter 84000, loss: 0.041774
 >> iter 85000, loss: 0.067322
 >> iter 86000, loss: 0.048093
 >> iter 87000, loss: 0.054410
 >> iter 88000, loss: 0.043176
 >> iter 89000, loss: 0.250778
 >> iter 90000, loss: 0.120430
   Number of active neurons: 6
 >> iter 91000, loss: 0.074811
 >> iter 92000, loss: 0.051519
 >> iter 93000, loss: 0.053799
 >> iter 94000, loss: 0.043304
 >> iter 95000, loss: 0.054258
 >> iter 96000, loss: 0.043386
 >> iter 97000, loss: 0.058440
 >> iter 98000, loss: 0.046157
 >> iter 99000, loss: 0.260813
 >> iter 100000, loss: 0.120986
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0039999200016
   - Test - Long: 0.169991500425
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 28.3647756816
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.743505
 >> iter 2000, loss: 7.759758
 >> iter 3000, loss: 2.956222
 >> iter 4000, loss: 1.132007
 >> iter 5000, loss: 0.450970
 >> iter 6000, loss: 0.205612
 >> iter 7000, loss: 0.198007
 >> iter 8000, loss: 0.125783
 >> iter 9000, loss: 0.077159
 >> iter 10000, loss: 0.085816
   Number of active neurons: 8
 >> iter 11000, loss: 0.178454
 >> iter 12000, loss: 0.120898
 >> iter 13000, loss: 0.072520
 >> iter 14000, loss: 0.115272
 >> iter 15000, loss: 0.115833
 >> iter 16000, loss: 0.093210
 >> iter 17000, loss: 0.061867
 >> iter 18000, loss: 0.163918
 >> iter 19000, loss: 0.353874
 >> iter 20000, loss: 0.185447
   Number of active neurons: 8
 >> iter 21000, loss: 0.096579
 >> iter 22000, loss: 0.110940
 >> iter 23000, loss: 0.207176
 >> iter 24000, loss: 0.106581
 >> iter 25000, loss: 0.395649
 >> iter 26000, loss: 0.223178
 >> iter 27000, loss: 0.109644
 >> iter 28000, loss: 0.068068
 >> iter 29000, loss: 0.228840
 >> iter 30000, loss: 0.112546
   Number of active neurons: 8
 >> iter 31000, loss: 0.091353
 >> iter 32000, loss: 0.060289
 >> iter 33000, loss: 0.134929
 >> iter 34000, loss: 0.074957
 >> iter 35000, loss: 0.122044
 >> iter 36000, loss: 0.069875
 >> iter 37000, loss: 0.469205
 >> iter 38000, loss: 0.205215
 >> iter 39000, loss: 0.135612
 >> iter 40000, loss: 0.076863
   Number of active neurons: 7
 >> iter 41000, loss: 0.059288
 >> iter 42000, loss: 0.076195
 >> iter 43000, loss: 0.096097
 >> iter 44000, loss: 0.115256
 >> iter 45000, loss: 0.067331
 >> iter 46000, loss: 0.050231
 >> iter 47000, loss: 0.099671
 >> iter 48000, loss: 0.090801
 >> iter 49000, loss: 0.111057
 >> iter 50000, loss: 0.264629
   Number of active neurons: 7
 >> iter 51000, loss: 0.125786
 >> iter 52000, loss: 0.132775
 >> iter 53000, loss: 0.075661
 >> iter 54000, loss: 0.096055
 >> iter 55000, loss: 0.109632
 >> iter 56000, loss: 0.077040
 >> iter 57000, loss: 0.100646
 >> iter 58000, loss: 0.147909
 >> iter 59000, loss: 0.171274
 >> iter 60000, loss: 0.115516
   Number of active neurons: 7
 >> iter 61000, loss: 0.068366
 >> iter 62000, loss: 0.049970
 >> iter 63000, loss: 0.043631
 >> iter 64000, loss: 0.039625
 >> iter 65000, loss: 0.048801
 >> iter 66000, loss: 0.117966
 >> iter 67000, loss: 0.068502
 >> iter 68000, loss: 0.090140
 >> iter 69000, loss: 0.095780
 >> iter 70000, loss: 0.078483
   Number of active neurons: 6
 >> iter 71000, loss: 0.199070
 >> iter 72000, loss: 0.126766
 >> iter 73000, loss: 0.304131
 >> iter 74000, loss: 0.145026
 >> iter 75000, loss: 0.250462
 >> iter 76000, loss: 0.152227
 >> iter 77000, loss: 0.204498
 >> iter 78000, loss: 0.104209
 >> iter 79000, loss: 0.113133
 >> iter 80000, loss: 0.069912
   Number of active neurons: 6
 >> iter 81000, loss: 0.116282
 >> iter 82000, loss: 0.080483
 >> iter 83000, loss: 0.366961
 >> iter 84000, loss: 0.244512
 >> iter 85000, loss: 0.271246
 >> iter 86000, loss: 0.132336
 >> iter 87000, loss: 0.229565
 >> iter 88000, loss: 0.145354
 >> iter 89000, loss: 0.131571
 >> iter 90000, loss: 0.079729
   Number of active neurons: 5
 >> iter 91000, loss: 0.153600
 >> iter 92000, loss: 0.086532
 >> iter 93000, loss: 0.103121
 >> iter 94000, loss: 0.070066
 >> iter 95000, loss: 0.193746
 >> iter 96000, loss: 0.116293
 >> iter 97000, loss: 0.075755
 >> iter 98000, loss: 0.075449
 >> iter 99000, loss: 0.337384
 >> iter 100000, loss: 0.156818
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0319993600128
   - Test - Long: 0.37998100095
   - Test - Big: 0.0339996600034
   - Test - A: 4.3063795747
   - Test - B: 22.8584761016
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.790099
 >> iter 2000, loss: 8.093744
 >> iter 3000, loss: 3.073481
 >> iter 4000, loss: 1.166154
 >> iter 5000, loss: 0.495626
 >> iter 6000, loss: 0.212042
 >> iter 7000, loss: 0.119240
 >> iter 8000, loss: 0.069912
 >> iter 9000, loss: 0.071957
 >> iter 10000, loss: 0.051176
   Number of active neurons: 6
 >> iter 11000, loss: 0.046832
 >> iter 12000, loss: 0.040807
 >> iter 13000, loss: 0.040550
 >> iter 14000, loss: 0.039643
 >> iter 15000, loss: 0.041806
 >> iter 16000, loss: 0.040762
 >> iter 17000, loss: 0.071600
 >> iter 18000, loss: 0.051065
 >> iter 19000, loss: 0.048574
 >> iter 20000, loss: 0.040480
   Number of active neurons: 6
 >> iter 21000, loss: 0.055430
 >> iter 22000, loss: 0.042513
 >> iter 23000, loss: 0.178333
 >> iter 24000, loss: 0.092106
 >> iter 25000, loss: 0.057252
 >> iter 26000, loss: 0.052284
 >> iter 27000, loss: 0.043809
 >> iter 28000, loss: 0.042590
 >> iter 29000, loss: 0.042057
 >> iter 30000, loss: 0.043298
   Number of active neurons: 6
 >> iter 31000, loss: 0.041739
 >> iter 32000, loss: 0.042617
 >> iter 33000, loss: 0.052643
 >> iter 34000, loss: 0.050359
 >> iter 35000, loss: 0.082136
 >> iter 36000, loss: 0.059937
 >> iter 37000, loss: 0.045581
 >> iter 38000, loss: 0.046234
 >> iter 39000, loss: 0.173088
 >> iter 40000, loss: 0.094666
   Number of active neurons: 6
 >> iter 41000, loss: 0.057665
 >> iter 42000, loss: 0.052438
 >> iter 43000, loss: 0.041122
 >> iter 44000, loss: 0.047190
 >> iter 45000, loss: 0.039324
 >> iter 46000, loss: 0.047959
 >> iter 47000, loss: 0.045944
 >> iter 48000, loss: 0.049428
 >> iter 49000, loss: 0.048546
 >> iter 50000, loss: 0.051534
   Number of active neurons: 6
 >> iter 51000, loss: 0.071395
 >> iter 52000, loss: 0.061626
 >> iter 53000, loss: 0.092498
 >> iter 54000, loss: 0.072851
 >> iter 55000, loss: 0.103634
 >> iter 56000, loss: 0.063637
 >> iter 57000, loss: 0.100596
 >> iter 58000, loss: 0.062363
 >> iter 59000, loss: 0.098833
 >> iter 60000, loss: 0.061725
   Number of active neurons: 5
 >> iter 61000, loss: 0.098816
 >> iter 62000, loss: 0.061165
 >> iter 63000, loss: 0.098757
 >> iter 64000, loss: 0.060321
 >> iter 65000, loss: 0.098495
 >> iter 66000, loss: 0.060128
 >> iter 67000, loss: 0.093751
 >> iter 68000, loss: 0.058440
 >> iter 69000, loss: 0.045426
 >> iter 70000, loss: 0.040008
   Number of active neurons: 5
 >> iter 71000, loss: 0.036954
 >> iter 72000, loss: 0.036377
 >> iter 73000, loss: 0.034982
 >> iter 74000, loss: 0.035373
 >> iter 75000, loss: 0.034371
 >> iter 76000, loss: 0.034874
 >> iter 77000, loss: 0.034036
 >> iter 78000, loss: 0.034340
 >> iter 79000, loss: 0.033732
 >> iter 80000, loss: 0.033635
   Number of active neurons: 5
 >> iter 81000, loss: 0.033500
 >> iter 82000, loss: 0.033407
 >> iter 83000, loss: 0.033428
 >> iter 84000, loss: 0.033335
 >> iter 85000, loss: 0.033411
 >> iter 86000, loss: 0.033323
 >> iter 87000, loss: 0.033393
 >> iter 88000, loss: 0.033338
 >> iter 89000, loss: 0.033406
 >> iter 90000, loss: 0.033372
   Number of active neurons: 5
 >> iter 91000, loss: 0.033435
 >> iter 92000, loss: 0.033346
 >> iter 93000, loss: 0.033363
 >> iter 94000, loss: 0.033235
 >> iter 95000, loss: 0.033345
 >> iter 96000, loss: 0.033191
 >> iter 97000, loss: 0.033360
 >> iter 98000, loss: 0.033213
 >> iter 99000, loss: 0.033417
 >> iter 100000, loss: 0.033209
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.143801
 >> iter 2000, loss: 8.533183
 >> iter 3000, loss: 3.193183
 >> iter 4000, loss: 1.210330
 >> iter 5000, loss: 0.477876
 >> iter 6000, loss: 0.208794
 >> iter 7000, loss: 0.105814
 >> iter 8000, loss: 0.071490
 >> iter 9000, loss: 0.053310
 >> iter 10000, loss: 0.045449
   Number of active neurons: 8
 >> iter 11000, loss: 0.046537
 >> iter 12000, loss: 0.042251
 >> iter 13000, loss: 0.046417
 >> iter 14000, loss: 0.041624
 >> iter 15000, loss: 0.049980
 >> iter 16000, loss: 0.041689
 >> iter 17000, loss: 0.127844
 >> iter 18000, loss: 0.080315
 >> iter 19000, loss: 0.064731
 >> iter 20000, loss: 0.048190
   Number of active neurons: 8
 >> iter 21000, loss: 0.077741
 >> iter 22000, loss: 0.057735
 >> iter 23000, loss: 0.103882
 >> iter 24000, loss: 0.060385
 >> iter 25000, loss: 0.082272
 >> iter 26000, loss: 0.051336
 >> iter 27000, loss: 0.041107
 >> iter 28000, loss: 0.037411
 >> iter 29000, loss: 0.036066
 >> iter 30000, loss: 0.035930
   Number of active neurons: 7
 >> iter 31000, loss: 0.193888
 >> iter 32000, loss: 0.092503
 >> iter 33000, loss: 0.056358
 >> iter 34000, loss: 0.043388
 >> iter 35000, loss: 0.161167
 >> iter 36000, loss: 0.080869
 >> iter 37000, loss: 0.052037
 >> iter 38000, loss: 0.041901
 >> iter 39000, loss: 0.037494
 >> iter 40000, loss: 0.040335
   Number of active neurons: 7
 >> iter 41000, loss: 0.050427
 >> iter 42000, loss: 0.038474
 >> iter 43000, loss: 0.034781
 >> iter 44000, loss: 0.036304
 >> iter 45000, loss: 0.071164
 >> iter 46000, loss: 0.046449
 >> iter 47000, loss: 0.037766
 >> iter 48000, loss: 0.085456
 >> iter 49000, loss: 0.061457
 >> iter 50000, loss: 0.042993
   Number of active neurons: 7
 >> iter 51000, loss: 0.034958
 >> iter 52000, loss: 0.035734
 >> iter 53000, loss: 0.145250
 >> iter 54000, loss: 0.074311
 >> iter 55000, loss: 0.048682
 >> iter 56000, loss: 0.043487
 >> iter 57000, loss: 0.037060
 >> iter 58000, loss: 0.039940
 >> iter 59000, loss: 0.093361
 >> iter 60000, loss: 0.068666
   Number of active neurons: 7
 >> iter 61000, loss: 0.215652
 >> iter 62000, loss: 0.101234
 >> iter 63000, loss: 0.096997
 >> iter 64000, loss: 0.056475
 >> iter 65000, loss: 0.041783
 >> iter 66000, loss: 0.042111
 >> iter 67000, loss: 0.044609
 >> iter 68000, loss: 0.042039
 >> iter 69000, loss: 0.071873
 >> iter 70000, loss: 0.052849
   Number of active neurons: 7
 >> iter 71000, loss: 0.191133
 >> iter 72000, loss: 0.104566
 >> iter 73000, loss: 0.059860
 >> iter 74000, loss: 0.047888
 >> iter 75000, loss: 0.039101
 >> iter 76000, loss: 0.039189
 >> iter 77000, loss: 0.037810
 >> iter 78000, loss: 0.041370
 >> iter 79000, loss: 0.035929
 >> iter 80000, loss: 0.116003
   Number of active neurons: 7
 >> iter 81000, loss: 0.077237
 >> iter 82000, loss: 0.057413
 >> iter 83000, loss: 0.040520
 >> iter 84000, loss: 0.037542
 >> iter 85000, loss: 0.034230
 >> iter 86000, loss: 0.038260
 >> iter 87000, loss: 0.034583
 >> iter 88000, loss: 0.033437
 >> iter 89000, loss: 0.032877
 >> iter 90000, loss: 0.032643
   Number of active neurons: 7
 >> iter 91000, loss: 0.098467
 >> iter 92000, loss: 0.058463
 >> iter 93000, loss: 0.041939
 >> iter 94000, loss: 0.036051
 >> iter 95000, loss: 0.182254
 >> iter 96000, loss: 0.088477
 >> iter 97000, loss: 0.054504
 >> iter 98000, loss: 0.049770
 >> iter 99000, loss: 0.038978
 >> iter 100000, loss: 0.038518
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 16.0455969602
   - Test - B: 20.6319578695
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.672451
 >> iter 2000, loss: 8.167539
 >> iter 3000, loss: 3.190631
 >> iter 4000, loss: 1.220823
 >> iter 5000, loss: 0.567071
 >> iter 6000, loss: 0.267481
 >> iter 7000, loss: 0.217090
 >> iter 8000, loss: 0.167823
 >> iter 9000, loss: 0.178928
 >> iter 10000, loss: 0.136150
   Number of active neurons: 7
 >> iter 11000, loss: 0.163560
 >> iter 12000, loss: 0.134745
 >> iter 13000, loss: 0.191922
 >> iter 14000, loss: 0.130026
 >> iter 15000, loss: 0.187927
 >> iter 16000, loss: 0.124982
 >> iter 17000, loss: 0.147714
 >> iter 18000, loss: 0.089365
 >> iter 19000, loss: 0.167513
 >> iter 20000, loss: 0.097613
   Number of active neurons: 7
 >> iter 21000, loss: 0.156088
 >> iter 22000, loss: 0.093397
 >> iter 23000, loss: 0.134408
 >> iter 24000, loss: 0.084750
 >> iter 25000, loss: 0.131005
 >> iter 26000, loss: 0.084260
 >> iter 27000, loss: 0.138781
 >> iter 28000, loss: 0.086551
 >> iter 29000, loss: 0.135031
 >> iter 30000, loss: 0.119149
   Number of active neurons: 7
 >> iter 31000, loss: 0.154261
 >> iter 32000, loss: 0.130188
 >> iter 33000, loss: 0.155412
 >> iter 34000, loss: 0.098902
 >> iter 35000, loss: 0.141604
 >> iter 36000, loss: 0.090587
 >> iter 37000, loss: 0.137051
 >> iter 38000, loss: 0.087572
 >> iter 39000, loss: 0.135253
 >> iter 40000, loss: 0.086485
   Number of active neurons: 7
 >> iter 41000, loss: 0.132807
 >> iter 42000, loss: 0.085270
 >> iter 43000, loss: 0.133657
 >> iter 44000, loss: 0.086838
 >> iter 45000, loss: 0.133539
 >> iter 46000, loss: 0.085076
 >> iter 47000, loss: 0.135591
 >> iter 48000, loss: 0.089858
 >> iter 49000, loss: 0.133319
 >> iter 50000, loss: 0.085665
   Number of active neurons: 7
 >> iter 51000, loss: 0.135785
 >> iter 52000, loss: 0.092363
 >> iter 53000, loss: 0.132273
 >> iter 54000, loss: 0.091050
 >> iter 55000, loss: 0.132695
 >> iter 56000, loss: 0.087416
 >> iter 57000, loss: 0.134045
 >> iter 58000, loss: 0.086913
 >> iter 59000, loss: 0.145576
 >> iter 60000, loss: 0.107700
   Number of active neurons: 7
 >> iter 61000, loss: 0.208796
 >> iter 62000, loss: 0.109276
 >> iter 63000, loss: 0.266151
 >> iter 64000, loss: 0.159184
 >> iter 65000, loss: 0.151227
 >> iter 66000, loss: 0.092635
 >> iter 67000, loss: 0.207680
 >> iter 68000, loss: 0.117180
 >> iter 69000, loss: 0.135611
 >> iter 70000, loss: 0.109609
   Number of active neurons: 7
 >> iter 71000, loss: 0.130998
 >> iter 72000, loss: 0.107641
 >> iter 73000, loss: 0.130638
 >> iter 74000, loss: 0.110059
 >> iter 75000, loss: 0.130236
 >> iter 76000, loss: 0.112100
 >> iter 77000, loss: 0.131211
 >> iter 78000, loss: 0.114636
 >> iter 79000, loss: 0.129895
 >> iter 80000, loss: 0.130445
   Number of active neurons: 7
 >> iter 81000, loss: 0.136297
 >> iter 82000, loss: 0.122544
 >> iter 83000, loss: 0.133672
 >> iter 84000, loss: 0.189207
 >> iter 85000, loss: 0.180311
 >> iter 86000, loss: 0.098152
 >> iter 87000, loss: 0.132266
 >> iter 88000, loss: 0.148619
 >> iter 89000, loss: 0.145036
 >> iter 90000, loss: 0.083505
   Number of active neurons: 7
 >> iter 91000, loss: 0.145446
 >> iter 92000, loss: 0.083502
 >> iter 93000, loss: 0.148491
 >> iter 94000, loss: 0.084704
 >> iter 95000, loss: 0.059094
 >> iter 96000, loss: 0.049040
 >> iter 97000, loss: 0.044144
 >> iter 98000, loss: 0.042065
 >> iter 99000, loss: 0.040834
 >> iter 100000, loss: 0.039992
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 20.4586360909
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.019053
 >> iter 2000, loss: 8.881599
 >> iter 3000, loss: 3.336108
 >> iter 4000, loss: 1.268604
 >> iter 5000, loss: 0.499748
 >> iter 6000, loss: 0.213721
 >> iter 7000, loss: 0.107037
 >> iter 8000, loss: 0.066747
 >> iter 9000, loss: 0.051483
 >> iter 10000, loss: 0.045232
   Number of active neurons: 6
 >> iter 11000, loss: 0.042290
 >> iter 12000, loss: 0.040946
 >> iter 13000, loss: 0.040078
 >> iter 14000, loss: 0.040363
 >> iter 15000, loss: 0.039364
 >> iter 16000, loss: 0.038940
 >> iter 17000, loss: 0.038565
 >> iter 18000, loss: 0.038346
 >> iter 19000, loss: 0.038154
 >> iter 20000, loss: 0.038261
   Number of active neurons: 6
 >> iter 21000, loss: 0.037923
 >> iter 22000, loss: 0.039698
 >> iter 23000, loss: 0.038248
 >> iter 24000, loss: 0.037465
 >> iter 25000, loss: 0.037674
 >> iter 26000, loss: 0.036841
 >> iter 27000, loss: 0.037269
 >> iter 28000, loss: 0.036677
 >> iter 29000, loss: 0.040952
 >> iter 30000, loss: 0.037535
   Number of active neurons: 6
 >> iter 31000, loss: 0.051242
 >> iter 32000, loss: 0.041141
 >> iter 33000, loss: 0.262327
 >> iter 34000, loss: 0.118845
 >> iter 35000, loss: 0.067174
 >> iter 36000, loss: 0.052471
 >> iter 37000, loss: 0.047815
 >> iter 38000, loss: 0.043925
 >> iter 39000, loss: 0.038548
 >> iter 40000, loss: 0.058354
   Number of active neurons: 6
 >> iter 41000, loss: 0.044278
 >> iter 42000, loss: 0.048912
 >> iter 43000, loss: 0.189375
 >> iter 44000, loss: 0.092395
 >> iter 45000, loss: 0.075790
 >> iter 46000, loss: 0.092296
 >> iter 47000, loss: 0.059071
 >> iter 48000, loss: 0.062573
 >> iter 49000, loss: 0.048420
 >> iter 50000, loss: 0.043825
   Number of active neurons: 6
 >> iter 51000, loss: 0.039177
 >> iter 52000, loss: 0.099659
 >> iter 53000, loss: 0.059098
 >> iter 54000, loss: 0.107920
 >> iter 55000, loss: 0.112734
 >> iter 56000, loss: 0.109911
 >> iter 57000, loss: 0.115827
 >> iter 58000, loss: 0.074735
 >> iter 59000, loss: 0.102782
 >> iter 60000, loss: 0.067371
   Number of active neurons: 6
 >> iter 61000, loss: 0.100459
 >> iter 62000, loss: 0.067398
 >> iter 63000, loss: 0.101156
 >> iter 64000, loss: 0.069429
 >> iter 65000, loss: 0.101619
 >> iter 66000, loss: 0.070066
 >> iter 67000, loss: 0.102283
 >> iter 68000, loss: 0.072198
 >> iter 69000, loss: 0.104303
 >> iter 70000, loss: 0.083089
   Number of active neurons: 6
 >> iter 71000, loss: 0.116570
 >> iter 72000, loss: 0.084869
 >> iter 73000, loss: 0.125253
 >> iter 74000, loss: 0.078257
 >> iter 75000, loss: 0.106471
 >> iter 76000, loss: 0.068755
 >> iter 77000, loss: 0.104098
 >> iter 78000, loss: 0.067664
 >> iter 79000, loss: 0.104336
 >> iter 80000, loss: 0.067023
   Number of active neurons: 6
 >> iter 81000, loss: 0.104327
 >> iter 82000, loss: 0.066511
 >> iter 83000, loss: 0.102942
 >> iter 84000, loss: 0.064738
 >> iter 85000, loss: 0.098541
 >> iter 86000, loss: 0.073869
 >> iter 87000, loss: 0.049223
 >> iter 88000, loss: 0.039919
 >> iter 89000, loss: 0.124989
 >> iter 90000, loss: 0.067798
   Number of active neurons: 5
 >> iter 91000, loss: 0.046697
 >> iter 92000, loss: 0.038573
 >> iter 93000, loss: 0.035637
 >> iter 94000, loss: 0.034294
 >> iter 95000, loss: 0.033887
 >> iter 96000, loss: 0.033447
 >> iter 97000, loss: 0.033386
 >> iter 98000, loss: 0.033056
 >> iter 99000, loss: 0.033055
 >> iter 100000, loss: 0.032725
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.000440
 >> iter 2000, loss: 8.690692
 >> iter 3000, loss: 3.262889
 >> iter 4000, loss: 1.239356
 >> iter 5000, loss: 0.486322
 >> iter 6000, loss: 0.210013
 >> iter 7000, loss: 0.102752
 >> iter 8000, loss: 0.063840
 >> iter 9000, loss: 0.051749
 >> iter 10000, loss: 0.119607
   Number of active neurons: 6
 >> iter 11000, loss: 0.068000
 >> iter 12000, loss: 0.125689
 >> iter 13000, loss: 0.068644
 >> iter 14000, loss: 0.054112
 >> iter 15000, loss: 0.042160
 >> iter 16000, loss: 0.056112
 >> iter 17000, loss: 0.043178
 >> iter 18000, loss: 0.053039
 >> iter 19000, loss: 0.042594
 >> iter 20000, loss: 0.053376
   Number of active neurons: 6
 >> iter 21000, loss: 0.044415
 >> iter 22000, loss: 0.050819
 >> iter 23000, loss: 0.048127
 >> iter 24000, loss: 0.092594
 >> iter 25000, loss: 0.131294
 >> iter 26000, loss: 0.073014
 >> iter 27000, loss: 0.114657
 >> iter 28000, loss: 0.067305
 >> iter 29000, loss: 0.076252
 >> iter 30000, loss: 0.152931
   Number of active neurons: 6
 >> iter 31000, loss: 0.086863
 >> iter 32000, loss: 0.059431
 >> iter 33000, loss: 0.127630
 >> iter 34000, loss: 0.202614
 >> iter 35000, loss: 0.172717
 >> iter 36000, loss: 0.241454
 >> iter 37000, loss: 0.118463
 >> iter 38000, loss: 0.106661
 >> iter 39000, loss: 0.065516
 >> iter 40000, loss: 0.054179
   Number of active neurons: 6
 >> iter 41000, loss: 0.165909
 >> iter 42000, loss: 0.095464
 >> iter 43000, loss: 0.090224
 >> iter 44000, loss: 0.067237
 >> iter 45000, loss: 0.214974
 >> iter 46000, loss: 0.192097
 >> iter 47000, loss: 0.224860
 >> iter 48000, loss: 0.120458
 >> iter 49000, loss: 0.180372
 >> iter 50000, loss: 0.193939
   Number of active neurons: 6
 >> iter 51000, loss: 0.288722
 >> iter 52000, loss: 0.142601
 >> iter 53000, loss: 0.319857
 >> iter 54000, loss: 0.150986
 >> iter 55000, loss: 0.334954
 >> iter 56000, loss: 0.155530
 >> iter 57000, loss: 0.198594
 >> iter 58000, loss: 0.108072
 >> iter 59000, loss: 0.132461
 >> iter 60000, loss: 0.081472
   Number of active neurons: 5
 >> iter 61000, loss: 0.318425
 >> iter 62000, loss: 0.145880
 >> iter 63000, loss: 0.250551
 >> iter 64000, loss: 0.126223
 >> iter 65000, loss: 0.285533
 >> iter 66000, loss: 0.149368
 >> iter 67000, loss: 0.089522
 >> iter 68000, loss: 0.057982
 >> iter 69000, loss: 0.043904
 >> iter 70000, loss: 0.038367
   Number of active neurons: 5
 >> iter 71000, loss: 0.183786
 >> iter 72000, loss: 0.089723
 >> iter 73000, loss: 0.054569
 >> iter 74000, loss: 0.041886
 >> iter 75000, loss: 0.264007
 >> iter 76000, loss: 0.120384
 >> iter 77000, loss: 0.119394
 >> iter 78000, loss: 0.129765
 >> iter 79000, loss: 0.089342
 >> iter 80000, loss: 0.056746
   Number of active neurons: 5
 >> iter 81000, loss: 0.057052
 >> iter 82000, loss: 0.040962
 >> iter 83000, loss: 0.606351
 >> iter 84000, loss: 0.281627
 >> iter 85000, loss: 0.321645
 >> iter 86000, loss: 0.143240
 >> iter 87000, loss: 0.127675
 >> iter 88000, loss: 0.069956
 >> iter 89000, loss: 0.204471
 >> iter 90000, loss: 0.101959
   Number of active neurons: 5
 >> iter 91000, loss: 0.201292
 >> iter 92000, loss: 0.116998
 >> iter 93000, loss: 0.206048
 >> iter 94000, loss: 0.106866
 >> iter 95000, loss: 0.116846
 >> iter 96000, loss: 0.076506
 >> iter 97000, loss: 0.058758
 >> iter 98000, loss: 0.046179
 >> iter 99000, loss: 0.037634
 >> iter 100000, loss: 0.040860
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 13.8457436171
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.912236
 >> iter 2000, loss: 7.791219
 >> iter 3000, loss: 2.977263
 >> iter 4000, loss: 1.135750
 >> iter 5000, loss: 0.529309
 >> iter 6000, loss: 0.230966
 >> iter 7000, loss: 0.200020
 >> iter 8000, loss: 0.108009
 >> iter 9000, loss: 0.167311
 >> iter 10000, loss: 0.094834
   Number of active neurons: 8
 >> iter 11000, loss: 0.148719
 >> iter 12000, loss: 0.084901
 >> iter 13000, loss: 0.141717
 >> iter 14000, loss: 0.081129
 >> iter 15000, loss: 0.144152
 >> iter 16000, loss: 0.080303
 >> iter 17000, loss: 0.106132
 >> iter 18000, loss: 0.067869
 >> iter 19000, loss: 0.055254
 >> iter 20000, loss: 0.053469
   Number of active neurons: 8
 >> iter 21000, loss: 0.050714
 >> iter 22000, loss: 0.049027
 >> iter 23000, loss: 0.042737
 >> iter 24000, loss: 0.045870
 >> iter 25000, loss: 0.041017
 >> iter 26000, loss: 0.039167
 >> iter 27000, loss: 0.038280
 >> iter 28000, loss: 0.037918
 >> iter 29000, loss: 0.037873
 >> iter 30000, loss: 0.037645
   Number of active neurons: 8
 >> iter 31000, loss: 0.037606
 >> iter 32000, loss: 0.037213
 >> iter 33000, loss: 0.037069
 >> iter 34000, loss: 0.036616
 >> iter 35000, loss: 0.036391
 >> iter 36000, loss: 0.035888
 >> iter 37000, loss: 0.035627
 >> iter 38000, loss: 0.035168
 >> iter 39000, loss: 0.035003
 >> iter 40000, loss: 0.034577
   Number of active neurons: 8
 >> iter 41000, loss: 0.034477
 >> iter 42000, loss: 0.034091
 >> iter 43000, loss: 0.034076
 >> iter 44000, loss: 0.033777
 >> iter 45000, loss: 0.033912
 >> iter 46000, loss: 0.033650
 >> iter 47000, loss: 0.033849
 >> iter 48000, loss: 0.033649
 >> iter 49000, loss: 0.033862
 >> iter 50000, loss: 0.033684
   Number of active neurons: 8
 >> iter 51000, loss: 0.033913
 >> iter 52000, loss: 0.033788
 >> iter 53000, loss: 0.033962
 >> iter 54000, loss: 0.033737
 >> iter 55000, loss: 0.033883
 >> iter 56000, loss: 0.033670
 >> iter 57000, loss: 0.033802
 >> iter 58000, loss: 0.033579
 >> iter 59000, loss: 0.033670
 >> iter 60000, loss: 0.033508
   Number of active neurons: 8
 >> iter 61000, loss: 0.033646
 >> iter 62000, loss: 0.033517
 >> iter 63000, loss: 0.033694
 >> iter 64000, loss: 0.033611
 >> iter 65000, loss: 0.033766
 >> iter 66000, loss: 0.033708
 >> iter 67000, loss: 0.033823
 >> iter 68000, loss: 0.033774
 >> iter 69000, loss: 0.033793
 >> iter 70000, loss: 0.033777
   Number of active neurons: 8
 >> iter 71000, loss: 0.033639
 >> iter 72000, loss: 0.042626
 >> iter 73000, loss: 0.036009
 >> iter 74000, loss: 0.043285
 >> iter 75000, loss: 0.036041
 >> iter 76000, loss: 0.033653
 >> iter 77000, loss: 0.032508
 >> iter 78000, loss: 0.049766
 >> iter 79000, loss: 0.037305
 >> iter 80000, loss: 0.032858
   Number of active neurons: 8
 >> iter 81000, loss: 0.031199
 >> iter 82000, loss: 0.030871
 >> iter 83000, loss: 0.030386
 >> iter 84000, loss: 0.040364
 >> iter 85000, loss: 0.033030
 >> iter 86000, loss: 0.030373
 >> iter 87000, loss: 0.029193
 >> iter 88000, loss: 0.028751
 >> iter 89000, loss: 0.028147
 >> iter 90000, loss: 0.027969
   Number of active neurons: 8
 >> iter 91000, loss: 0.027489
 >> iter 92000, loss: 0.027405
 >> iter 93000, loss: 0.026961
 >> iter 94000, loss: 0.027225
 >> iter 95000, loss: 0.026619
 >> iter 96000, loss: 0.026406
 >> iter 97000, loss: 0.026213
 >> iter 98000, loss: 0.026122
 >> iter 99000, loss: 0.025968
 >> iter 100000, loss: 0.025860
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 17.838810746
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.912588
 >> iter 2000, loss: 8.288666
 >> iter 3000, loss: 3.104828
 >> iter 4000, loss: 1.179703
 >> iter 5000, loss: 0.470936
 >> iter 6000, loss: 0.202403
 >> iter 7000, loss: 0.192474
 >> iter 8000, loss: 0.099343
 >> iter 9000, loss: 0.148253
 >> iter 10000, loss: 0.082470
   Number of active neurons: 7
 >> iter 11000, loss: 0.137176
 >> iter 12000, loss: 0.078893
 >> iter 13000, loss: 0.166661
 >> iter 14000, loss: 0.090329
 >> iter 15000, loss: 0.146433
 >> iter 16000, loss: 0.080381
 >> iter 17000, loss: 0.056813
 >> iter 18000, loss: 0.046613
 >> iter 19000, loss: 0.043393
 >> iter 20000, loss: 0.040817
   Number of active neurons: 7
 >> iter 21000, loss: 0.040372
 >> iter 22000, loss: 0.038902
 >> iter 23000, loss: 0.038639
 >> iter 24000, loss: 0.037495
 >> iter 25000, loss: 0.037259
 >> iter 26000, loss: 0.036251
 >> iter 27000, loss: 0.036075
 >> iter 28000, loss: 0.035182
 >> iter 29000, loss: 0.122887
 >> iter 30000, loss: 0.084485
   Number of active neurons: 7
 >> iter 31000, loss: 0.052671
 >> iter 32000, loss: 0.040826
 >> iter 33000, loss: 0.037093
 >> iter 34000, loss: 0.034961
 >> iter 35000, loss: 0.034632
 >> iter 36000, loss: 0.033638
 >> iter 37000, loss: 0.033727
 >> iter 38000, loss: 0.033074
 >> iter 39000, loss: 0.033172
 >> iter 40000, loss: 0.032512
   Number of active neurons: 7
 >> iter 41000, loss: 0.032625
 >> iter 42000, loss: 0.046378
 >> iter 43000, loss: 0.036403
 >> iter 44000, loss: 0.032936
 >> iter 45000, loss: 0.032314
 >> iter 46000, loss: 0.037314
 >> iter 47000, loss: 0.033651
 >> iter 48000, loss: 0.033563
 >> iter 49000, loss: 0.032011
 >> iter 50000, loss: 0.031340
   Number of active neurons: 7
 >> iter 51000, loss: 0.031234
 >> iter 52000, loss: 0.052372
 >> iter 53000, loss: 0.039221
 >> iter 54000, loss: 0.034191
 >> iter 55000, loss: 0.032640
 >> iter 56000, loss: 0.045630
 >> iter 57000, loss: 0.036292
 >> iter 58000, loss: 0.032994
 >> iter 59000, loss: 0.032101
 >> iter 60000, loss: 0.031619
   Number of active neurons: 7
 >> iter 61000, loss: 0.031575
 >> iter 62000, loss: 0.031363
 >> iter 63000, loss: 0.031314
 >> iter 64000, loss: 0.033816
 >> iter 65000, loss: 0.031796
 >> iter 66000, loss: 0.031250
 >> iter 67000, loss: 0.031393
 >> iter 68000, loss: 0.031315
 >> iter 69000, loss: 0.031452
 >> iter 70000, loss: 0.031352
   Number of active neurons: 7
 >> iter 71000, loss: 0.031485
 >> iter 72000, loss: 0.031347
 >> iter 73000, loss: 0.031499
 >> iter 74000, loss: 0.031350
 >> iter 75000, loss: 0.031518
 >> iter 76000, loss: 0.031394
 >> iter 77000, loss: 0.031540
 >> iter 78000, loss: 0.031413
 >> iter 79000, loss: 0.031565
 >> iter 80000, loss: 0.031437
   Number of active neurons: 7
 >> iter 81000, loss: 0.031588
 >> iter 82000, loss: 0.031485
 >> iter 83000, loss: 0.031640
 >> iter 84000, loss: 0.031529
 >> iter 85000, loss: 0.031699
 >> iter 86000, loss: 0.031581
 >> iter 87000, loss: 0.031709
 >> iter 88000, loss: 0.031584
 >> iter 89000, loss: 0.031680
 >> iter 90000, loss: 0.031551
   Number of active neurons: 7
 >> iter 91000, loss: 0.031656
 >> iter 92000, loss: 0.031529
 >> iter 93000, loss: 0.031663
 >> iter 94000, loss: 0.031529
 >> iter 95000, loss: 0.031714
 >> iter 96000, loss: 0.031531
 >> iter 97000, loss: 0.031729
 >> iter 98000, loss: 0.031550
 >> iter 99000, loss: 0.031785
 >> iter 100000, loss: 0.031593
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 7.11952536498
   - Test - B: 8.64609026065
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.878419
 >> iter 2000, loss: 9.341650
 >> iter 3000, loss: 4.536389
 >> iter 4000, loss: 2.356571
 >> iter 5000, loss: 1.223835
 >> iter 6000, loss: 0.625145
 >> iter 7000, loss: 0.481596
 >> iter 8000, loss: 0.467814
 >> iter 9000, loss: 0.486319
 >> iter 10000, loss: 0.269828
   Number of active neurons: 9
 >> iter 11000, loss: 0.325139
 >> iter 12000, loss: 0.150557
 >> iter 13000, loss: 0.083207
 >> iter 14000, loss: 0.054125
 >> iter 15000, loss: 0.091462
 >> iter 16000, loss: 0.061616
 >> iter 17000, loss: 0.097318
 >> iter 18000, loss: 0.061504
 >> iter 19000, loss: 0.053890
 >> iter 20000, loss: 0.039252
   Number of active neurons: 6
 >> iter 21000, loss: 0.062331
 >> iter 22000, loss: 0.045634
 >> iter 23000, loss: 0.064386
 >> iter 24000, loss: 0.087258
 >> iter 25000, loss: 0.072232
 >> iter 26000, loss: 0.046943
 >> iter 27000, loss: 0.058563
 >> iter 28000, loss: 0.077089
 >> iter 29000, loss: 0.199539
 >> iter 30000, loss: 0.096957
   Number of active neurons: 5
 >> iter 31000, loss: 0.062127
 >> iter 32000, loss: 0.043088
 >> iter 33000, loss: 0.104852
 >> iter 34000, loss: 0.066351
 >> iter 35000, loss: 0.110725
 >> iter 36000, loss: 0.094305
 >> iter 37000, loss: 0.082195
 >> iter 38000, loss: 0.110994
 >> iter 39000, loss: 0.105631
 >> iter 40000, loss: 0.072582
   Number of active neurons: 5
 >> iter 41000, loss: 0.106837
 >> iter 42000, loss: 0.096932
 >> iter 43000, loss: 0.080660
 >> iter 44000, loss: 0.067059
 >> iter 45000, loss: 0.134745
 >> iter 46000, loss: 0.073040
 >> iter 47000, loss: 0.377471
 >> iter 48000, loss: 0.171419
 >> iter 49000, loss: 0.150047
 >> iter 50000, loss: 0.081039
   Number of active neurons: 5
 >> iter 51000, loss: 0.079008
 >> iter 52000, loss: 0.167099
 >> iter 53000, loss: 0.087275
 >> iter 54000, loss: 0.158619
 >> iter 55000, loss: 0.109524
 >> iter 56000, loss: 0.165330
 >> iter 57000, loss: 0.094212
 >> iter 58000, loss: 0.162257
 >> iter 59000, loss: 0.113517
 >> iter 60000, loss: 0.095133
   Number of active neurons: 5
 >> iter 61000, loss: 0.072676
 >> iter 62000, loss: 0.063579
 >> iter 63000, loss: 0.060804
 >> iter 64000, loss: 0.142949
 >> iter 65000, loss: 0.144625
 >> iter 66000, loss: 0.158124
 >> iter 67000, loss: 0.123785
 >> iter 68000, loss: 0.103150
 >> iter 69000, loss: 0.063490
 >> iter 70000, loss: 0.072314
   Number of active neurons: 5
 >> iter 71000, loss: 0.067809
 >> iter 72000, loss: 0.065019
 >> iter 73000, loss: 0.060490
 >> iter 74000, loss: 0.070972
 >> iter 75000, loss: 0.061877
 >> iter 76000, loss: 0.130253
 >> iter 77000, loss: 0.111521
 >> iter 78000, loss: 0.065910
 >> iter 79000, loss: 0.079919
 >> iter 80000, loss: 0.051486
   Number of active neurons: 5
 >> iter 81000, loss: 0.080256
 >> iter 82000, loss: 0.052668
 >> iter 83000, loss: 0.070295
 >> iter 84000, loss: 0.078155
 >> iter 85000, loss: 0.085732
 >> iter 86000, loss: 0.091594
 >> iter 87000, loss: 0.089422
 >> iter 88000, loss: 0.090108
 >> iter 89000, loss: 0.061911
 >> iter 90000, loss: 0.052118
   Number of active neurons: 5
 >> iter 91000, loss: 0.070471
 >> iter 92000, loss: 0.146136
 >> iter 93000, loss: 0.098405
 >> iter 94000, loss: 0.058525
 >> iter 95000, loss: 0.069345
 >> iter 96000, loss: 0.079558
 >> iter 97000, loss: 0.060898
 >> iter 98000, loss: 0.071834
 >> iter 99000, loss: 0.069340
 >> iter 100000, loss: 0.078454
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0239995200096
   - Test - Long: 0.0449977501125
   - Test - Big: 0.0159998400016
   - Test - A: 22.4651689887
   - Test - B: 0.0733284447704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.676661
 >> iter 2000, loss: 7.872167
 >> iter 3000, loss: 2.984893
 >> iter 4000, loss: 1.143023
 >> iter 5000, loss: 0.462487
 >> iter 6000, loss: 0.221505
 >> iter 7000, loss: 0.125426
 >> iter 8000, loss: 0.074791
 >> iter 9000, loss: 0.113536
 >> iter 10000, loss: 0.069276
   Number of active neurons: 6
 >> iter 11000, loss: 0.112082
 >> iter 12000, loss: 0.068230
 >> iter 13000, loss: 0.154238
 >> iter 14000, loss: 0.083995
 >> iter 15000, loss: 0.057828
 >> iter 16000, loss: 0.047815
 >> iter 17000, loss: 0.222370
 >> iter 18000, loss: 0.111532
 >> iter 19000, loss: 0.171638
 >> iter 20000, loss: 0.091264
   Number of active neurons: 5
 >> iter 21000, loss: 0.069475
 >> iter 22000, loss: 0.050731
 >> iter 23000, loss: 0.051594
 >> iter 24000, loss: 0.043719
 >> iter 25000, loss: 0.050584
 >> iter 26000, loss: 0.064265
 >> iter 27000, loss: 0.053462
 >> iter 28000, loss: 0.043050
 >> iter 29000, loss: 0.238507
 >> iter 30000, loss: 0.119916
   Number of active neurons: 4
 >> iter 31000, loss: 0.067404
 >> iter 32000, loss: 0.047312
 >> iter 33000, loss: 0.065383
 >> iter 34000, loss: 0.063671
 >> iter 35000, loss: 0.120743
 >> iter 36000, loss: 0.076440
 >> iter 37000, loss: 0.078610
 >> iter 38000, loss: 0.057945
 >> iter 39000, loss: 0.119487
 >> iter 40000, loss: 0.175645
   Number of active neurons: 4
 >> iter 41000, loss: 0.191057
 >> iter 42000, loss: 0.159015
 >> iter 43000, loss: 0.194796
 >> iter 44000, loss: 0.157312
 >> iter 45000, loss: 0.129652
 >> iter 46000, loss: 0.162392
 >> iter 47000, loss: 0.215094
 >> iter 48000, loss: 0.273595
 >> iter 49000, loss: 0.328358
 >> iter 50000, loss: 0.153893
   Number of active neurons: 4
 >> iter 51000, loss: 0.121732
 >> iter 52000, loss: 0.136510
 >> iter 53000, loss: 0.159326
 >> iter 54000, loss: 0.166772
 >> iter 55000, loss: 0.174208
 >> iter 56000, loss: 0.121187
 >> iter 57000, loss: 0.156439
 >> iter 58000, loss: 0.096210
 >> iter 59000, loss: 0.203351
 >> iter 60000, loss: 0.178925
   Number of active neurons: 4
 >> iter 61000, loss: 0.349915
 >> iter 62000, loss: 0.169078
 >> iter 63000, loss: 0.240059
 >> iter 64000, loss: 0.139889
 >> iter 65000, loss: 0.135414
 >> iter 66000, loss: 0.109143
 >> iter 67000, loss: 0.326429
 >> iter 68000, loss: 0.219396
 >> iter 69000, loss: 0.270824
 >> iter 70000, loss: 0.151379
   Number of active neurons: 4
 >> iter 71000, loss: 0.263373
 >> iter 72000, loss: 0.125635
 >> iter 73000, loss: 0.299301
 >> iter 74000, loss: 0.133111
 >> iter 75000, loss: 0.084080
 >> iter 76000, loss: 0.054030
 >> iter 77000, loss: 0.198277
 >> iter 78000, loss: 0.100250
 >> iter 79000, loss: 0.059904
 >> iter 80000, loss: 0.124786
   Number of active neurons: 4
 >> iter 81000, loss: 0.067376
 >> iter 82000, loss: 0.106891
 >> iter 83000, loss: 0.089360
 >> iter 84000, loss: 0.081459
 >> iter 85000, loss: 0.049745
 >> iter 86000, loss: 0.221748
 >> iter 87000, loss: 0.184325
 >> iter 88000, loss: 0.103723
 >> iter 89000, loss: 0.281315
 >> iter 90000, loss: 0.184470
   Number of active neurons: 4
 >> iter 91000, loss: 0.264071
 >> iter 92000, loss: 0.209712
 >> iter 93000, loss: 0.344379
 >> iter 94000, loss: 0.208960
 >> iter 95000, loss: 0.339504
 >> iter 96000, loss: 0.197762
 >> iter 97000, loss: 0.121061
 >> iter 98000, loss: 0.068774
 >> iter 99000, loss: 0.203143
 >> iter 100000, loss: 0.132118
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0259994800104
   - Test - Long: 0.0249987500625
   - Test - Big: 0.0479995200048
   - Test - A: 0.0
   - Test - B: 22.1385240984
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.721377
 >> iter 2000, loss: 7.879477
 >> iter 3000, loss: 3.031124
 >> iter 4000, loss: 1.155738
 >> iter 5000, loss: 0.525564
 >> iter 6000, loss: 0.226234
 >> iter 7000, loss: 0.162095
 >> iter 8000, loss: 0.087095
 >> iter 9000, loss: 0.058240
 >> iter 10000, loss: 0.048203
   Number of active neurons: 6
 >> iter 11000, loss: 0.221375
 >> iter 12000, loss: 0.109586
 >> iter 13000, loss: 0.071661
 >> iter 14000, loss: 0.052804
 >> iter 15000, loss: 0.121964
 >> iter 16000, loss: 0.072517
 >> iter 17000, loss: 0.126393
 >> iter 18000, loss: 0.074829
 >> iter 19000, loss: 0.128699
 >> iter 20000, loss: 0.076170
   Number of active neurons: 6
 >> iter 21000, loss: 0.241137
 >> iter 22000, loss: 0.119550
 >> iter 23000, loss: 0.151905
 >> iter 24000, loss: 0.083421
 >> iter 25000, loss: 0.134823
 >> iter 26000, loss: 0.080774
 >> iter 27000, loss: 0.281570
 >> iter 28000, loss: 0.137365
 >> iter 29000, loss: 0.153013
 >> iter 30000, loss: 0.088875
   Number of active neurons: 6
 >> iter 31000, loss: 0.314530
 >> iter 32000, loss: 0.150576
 >> iter 33000, loss: 0.164345
 >> iter 34000, loss: 0.091593
 >> iter 35000, loss: 0.138847
 >> iter 36000, loss: 0.079402
 >> iter 37000, loss: 0.096987
 >> iter 38000, loss: 0.061821
 >> iter 39000, loss: 0.053584
 >> iter 40000, loss: 0.045442
   Number of active neurons: 6
 >> iter 41000, loss: 0.041407
 >> iter 42000, loss: 0.038373
 >> iter 43000, loss: 0.038681
 >> iter 44000, loss: 0.036781
 >> iter 45000, loss: 0.036817
 >> iter 46000, loss: 0.035597
 >> iter 47000, loss: 0.035837
 >> iter 48000, loss: 0.034725
 >> iter 49000, loss: 0.034945
 >> iter 50000, loss: 0.034082
   Number of active neurons: 6
 >> iter 51000, loss: 0.034256
 >> iter 52000, loss: 0.033745
 >> iter 53000, loss: 0.034019
 >> iter 54000, loss: 0.033663
 >> iter 55000, loss: 0.033522
 >> iter 56000, loss: 0.033195
 >> iter 57000, loss: 0.033304
 >> iter 58000, loss: 0.033031
 >> iter 59000, loss: 0.033104
 >> iter 60000, loss: 0.032857
   Number of active neurons: 6
 >> iter 61000, loss: 0.032924
 >> iter 62000, loss: 0.032660
 >> iter 63000, loss: 0.032758
 >> iter 64000, loss: 0.032528
 >> iter 65000, loss: 0.032633
 >> iter 66000, loss: 0.032405
 >> iter 67000, loss: 0.032504
 >> iter 68000, loss: 0.032300
 >> iter 69000, loss: 0.032325
 >> iter 70000, loss: 0.032097
   Number of active neurons: 6
 >> iter 71000, loss: 0.032188
 >> iter 72000, loss: 0.031985
 >> iter 73000, loss: 0.032124
 >> iter 74000, loss: 0.031889
 >> iter 75000, loss: 0.032024
 >> iter 76000, loss: 0.031825
 >> iter 77000, loss: 0.031935
 >> iter 78000, loss: 0.031752
 >> iter 79000, loss: 0.031870
 >> iter 80000, loss: 0.031701
   Number of active neurons: 6
 >> iter 81000, loss: 0.031829
 >> iter 82000, loss: 0.031699
 >> iter 83000, loss: 0.031760
 >> iter 84000, loss: 0.031547
 >> iter 85000, loss: 0.031623
 >> iter 86000, loss: 0.031432
 >> iter 87000, loss: 0.031531
 >> iter 88000, loss: 0.031389
 >> iter 89000, loss: 0.031502
 >> iter 90000, loss: 0.031389
   Number of active neurons: 6
 >> iter 91000, loss: 0.031502
 >> iter 92000, loss: 0.031406
 >> iter 93000, loss: 0.031525
 >> iter 94000, loss: 0.031419
 >> iter 95000, loss: 0.031572
 >> iter 96000, loss: 0.031417
 >> iter 97000, loss: 0.031530
 >> iter 98000, loss: 0.031257
 >> iter 99000, loss: 0.031304
 >> iter 100000, loss: 0.030962
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.166584
 >> iter 2000, loss: 8.708875
 >> iter 3000, loss: 3.321635
 >> iter 4000, loss: 1.271619
 >> iter 5000, loss: 0.540844
 >> iter 6000, loss: 0.241320
 >> iter 7000, loss: 0.262104
 >> iter 8000, loss: 0.126081
 >> iter 9000, loss: 0.147232
 >> iter 10000, loss: 0.084409
   Number of active neurons: 7
 >> iter 11000, loss: 0.154222
 >> iter 12000, loss: 0.093762
 >> iter 13000, loss: 0.311785
 >> iter 14000, loss: 0.154876
 >> iter 15000, loss: 0.300327
 >> iter 16000, loss: 0.143792
 >> iter 17000, loss: 0.232161
 >> iter 18000, loss: 0.261669
 >> iter 19000, loss: 0.249294
 >> iter 20000, loss: 0.123034
   Number of active neurons: 6
 >> iter 21000, loss: 0.127430
 >> iter 22000, loss: 0.072625
 >> iter 23000, loss: 0.184673
 >> iter 24000, loss: 0.334760
 >> iter 25000, loss: 0.295119
 >> iter 26000, loss: 0.166666
 >> iter 27000, loss: 0.244003
 >> iter 28000, loss: 0.117424
 >> iter 29000, loss: 0.231380
 >> iter 30000, loss: 0.204293
   Number of active neurons: 6
 >> iter 31000, loss: 0.106866
 >> iter 32000, loss: 0.130916
 >> iter 33000, loss: 0.073958
 >> iter 34000, loss: 0.089807
 >> iter 35000, loss: 0.057784
 >> iter 36000, loss: 0.112404
 >> iter 37000, loss: 0.106264
 >> iter 38000, loss: 0.065237
 >> iter 39000, loss: 0.192838
 >> iter 40000, loss: 0.099394
   Number of active neurons: 6
 >> iter 41000, loss: 0.197691
 >> iter 42000, loss: 0.107329
 >> iter 43000, loss: 0.268158
 >> iter 44000, loss: 0.128546
 >> iter 45000, loss: 0.072153
 >> iter 46000, loss: 0.079163
 >> iter 47000, loss: 0.213409
 >> iter 48000, loss: 0.124054
 >> iter 49000, loss: 0.394271
 >> iter 50000, loss: 0.173107
   Number of active neurons: 6
 >> iter 51000, loss: 0.206319
 >> iter 52000, loss: 0.103303
 >> iter 53000, loss: 0.154952
 >> iter 54000, loss: 0.081771
 >> iter 55000, loss: 0.108012
 >> iter 56000, loss: 0.097472
 >> iter 57000, loss: 0.151653
 >> iter 58000, loss: 0.093494
 >> iter 59000, loss: 0.111904
 >> iter 60000, loss: 0.070723
   Number of active neurons: 5
 >> iter 61000, loss: 0.196442
 >> iter 62000, loss: 0.150494
 >> iter 63000, loss: 0.109008
 >> iter 64000, loss: 0.096204
 >> iter 65000, loss: 0.120636
 >> iter 66000, loss: 0.070301
 >> iter 67000, loss: 0.067325
 >> iter 68000, loss: 0.082193
 >> iter 69000, loss: 0.080189
 >> iter 70000, loss: 0.074794
   Number of active neurons: 5
 >> iter 71000, loss: 0.178465
 >> iter 72000, loss: 0.089274
 >> iter 73000, loss: 0.054778
 >> iter 74000, loss: 0.061523
 >> iter 75000, loss: 0.061709
 >> iter 76000, loss: 0.053162
 >> iter 77000, loss: 0.093026
 >> iter 78000, loss: 0.055817
 >> iter 79000, loss: 0.090460
 >> iter 80000, loss: 0.053315
   Number of active neurons: 5
 >> iter 81000, loss: 0.095123
 >> iter 82000, loss: 0.063146
 >> iter 83000, loss: 0.081336
 >> iter 84000, loss: 0.085279
 >> iter 85000, loss: 0.102438
 >> iter 86000, loss: 0.134403
 >> iter 87000, loss: 0.140315
 >> iter 88000, loss: 0.094299
 >> iter 89000, loss: 0.081307
 >> iter 90000, loss: 0.070314
   Number of active neurons: 5
 >> iter 91000, loss: 0.058531
 >> iter 92000, loss: 0.102020
 >> iter 93000, loss: 0.058854
 >> iter 94000, loss: 0.042594
 >> iter 95000, loss: 0.036132
 >> iter 96000, loss: 0.074527
 >> iter 97000, loss: 0.047440
 >> iter 98000, loss: 0.078645
 >> iter 99000, loss: 0.049339
 >> iter 100000, loss: 0.067460
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0959980800384
   - Test - Long: 0.1599920004
   - Test - Big: 0.0379996200038
   - Test - A: 0.0
   - Test - B: 11.859209386

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

