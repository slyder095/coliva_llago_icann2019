 > Problema: tomita6nueva
 > Args:
   - Hidden size: 10
   - Noise level: 1.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.200169
 >> iter 2000, loss: 15.632159
 >> iter 3000, loss: 14.156193
 >> iter 4000, loss: 13.572860
 >> iter 5000, loss: 13.293988
 >> iter 6000, loss: 13.190994
 >> iter 7000, loss: 13.120547
 >> iter 8000, loss: 13.092645
 >> iter 9000, loss: 13.063410
 >> iter 10000, loss: 13.074320
   Number of active neurons: 10
 >> iter 11000, loss: 13.061620
 >> iter 12000, loss: 13.045991
 >> iter 13000, loss: 13.038431
 >> iter 14000, loss: 13.052234
 >> iter 15000, loss: 13.040117
 >> iter 16000, loss: 13.038998
 >> iter 17000, loss: 13.028520
 >> iter 18000, loss: 13.032394
 >> iter 19000, loss: 13.031056
 >> iter 20000, loss: 13.035825
   Number of active neurons: 10
 >> iter 21000, loss: 13.011893
 >> iter 22000, loss: 13.029577
 >> iter 23000, loss: 13.011171
 >> iter 24000, loss: 13.018251
 >> iter 25000, loss: 12.995173
 >> iter 26000, loss: 13.007960
 >> iter 27000, loss: 12.993905
 >> iter 28000, loss: 13.011206
 >> iter 29000, loss: 12.995835
 >> iter 30000, loss: 13.006577
   Number of active neurons: 10
 >> iter 31000, loss: 12.993644
 >> iter 32000, loss: 13.014350
 >> iter 33000, loss: 12.991956
 >> iter 34000, loss: 13.003148
 >> iter 35000, loss: 12.991007
 >> iter 36000, loss: 12.997686
 >> iter 37000, loss: 12.992165
 >> iter 38000, loss: 13.005495
 >> iter 39000, loss: 12.984922
 >> iter 40000, loss: 12.996694
   Number of active neurons: 10
 >> iter 41000, loss: 12.978176
 >> iter 42000, loss: 12.991084
 >> iter 43000, loss: 12.972100
 >> iter 44000, loss: 12.972346
 >> iter 45000, loss: 12.932996
 >> iter 46000, loss: 12.928427
 >> iter 47000, loss: 12.890023
 >> iter 48000, loss: 12.850817
 >> iter 49000, loss: 12.807400
 >> iter 50000, loss: 12.562046
   Number of active neurons: 10
 >> iter 51000, loss: 11.883377
 >> iter 52000, loss: 11.445059
 >> iter 53000, loss: 11.117664
 >> iter 54000, loss: 10.979779
 >> iter 55000, loss: 10.746907
 >> iter 56000, loss: 10.719175
 >> iter 57000, loss: 10.617173
 >> iter 58000, loss: 10.649587
 >> iter 59000, loss: 10.556550
 >> iter 60000, loss: 10.582691
   Number of active neurons: 10
 >> iter 61000, loss: 10.478661
 >> iter 62000, loss: 10.561456
 >> iter 63000, loss: 10.465761
 >> iter 64000, loss: 10.540158
 >> iter 65000, loss: 10.429233
 >> iter 66000, loss: 10.504630
 >> iter 67000, loss: 10.421657
 >> iter 68000, loss: 10.470252
 >> iter 69000, loss: 10.360525
 >> iter 70000, loss: 10.446256
   Number of active neurons: 10
 >> iter 71000, loss: 10.330467
 >> iter 72000, loss: 10.394526
 >> iter 73000, loss: 10.336936
 >> iter 74000, loss: 10.369084
 >> iter 75000, loss: 10.280055
 >> iter 76000, loss: 10.381634
 >> iter 77000, loss: 10.292328
 >> iter 78000, loss: 10.253121
 >> iter 79000, loss: 10.118491
 >> iter 80000, loss: 10.095587
   Number of active neurons: 10
 >> iter 81000, loss: 9.928449
 >> iter 82000, loss: 9.905468
 >> iter 83000, loss: 9.770798
 >> iter 84000, loss: 9.832180
 >> iter 85000, loss: 9.728945
 >> iter 86000, loss: 9.824299
 >> iter 87000, loss: 9.623297
 >> iter 88000, loss: 9.592067
 >> iter 89000, loss: 9.361036
 >> iter 90000, loss: 9.237619
   Number of active neurons: 10
 >> iter 91000, loss: 9.112508
 >> iter 92000, loss: 9.039427
 >> iter 93000, loss: 8.344284
 >> iter 94000, loss: 8.026159
 >> iter 95000, loss: 7.649506
 >> iter 96000, loss: 7.276276
 >> iter 97000, loss: 7.135534
 >> iter 98000, loss: 6.993473
 >> iter 99000, loss: 6.939330
 >> iter 100000, loss: 7.124420
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 11.3397732045
   - Test - Long: 29.2935353232
   - Test - Big: 11.4578854211
   - Test - A: 0.419972001867
   - Test - B: 31.6112259183
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.196992
 >> iter 2000, loss: 15.664147
 >> iter 3000, loss: 14.117642
 >> iter 4000, loss: 13.510011
 >> iter 5000, loss: 13.249635
 >> iter 6000, loss: 13.152605
 >> iter 7000, loss: 13.111894
 >> iter 8000, loss: 13.091836
 >> iter 9000, loss: 13.070471
 >> iter 10000, loss: 13.060718
   Number of active neurons: 10
 >> iter 11000, loss: 13.039131
 >> iter 12000, loss: 13.049100
 >> iter 13000, loss: 13.028349
 >> iter 14000, loss: 13.041490
 >> iter 15000, loss: 13.019077
 >> iter 16000, loss: 13.023627
 >> iter 17000, loss: 13.021121
 >> iter 18000, loss: 13.026611
 >> iter 19000, loss: 13.005916
 >> iter 20000, loss: 13.016061
   Number of active neurons: 10
 >> iter 21000, loss: 13.000892
 >> iter 22000, loss: 13.007370
 >> iter 23000, loss: 12.989457
 >> iter 24000, loss: 13.002770
 >> iter 25000, loss: 12.979614
 >> iter 26000, loss: 12.989302
 >> iter 27000, loss: 12.985650
 >> iter 28000, loss: 12.994714
 >> iter 29000, loss: 12.976085
 >> iter 30000, loss: 12.993815
   Number of active neurons: 10
 >> iter 31000, loss: 12.978895
 >> iter 32000, loss: 12.990719
 >> iter 33000, loss: 12.978478
 >> iter 34000, loss: 12.991570
 >> iter 35000, loss: 12.979450
 >> iter 36000, loss: 12.990693
 >> iter 37000, loss: 12.980382
 >> iter 38000, loss: 12.992978
 >> iter 39000, loss: 12.976105
 >> iter 40000, loss: 12.983839
   Number of active neurons: 10
 >> iter 41000, loss: 12.974710
 >> iter 42000, loss: 12.977840
 >> iter 43000, loss: 12.945133
 >> iter 44000, loss: 12.937491
 >> iter 45000, loss: 12.859718
 >> iter 46000, loss: 12.673755
 >> iter 47000, loss: 12.033339
 >> iter 48000, loss: 11.580820
 >> iter 49000, loss: 11.218752
 >> iter 50000, loss: 11.120509
   Number of active neurons: 10
 >> iter 51000, loss: 10.930073
 >> iter 52000, loss: 10.901068
 >> iter 53000, loss: 10.738508
 >> iter 54000, loss: 10.703366
 >> iter 55000, loss: 10.543253
 >> iter 56000, loss: 10.561044
 >> iter 57000, loss: 10.441879
 >> iter 58000, loss: 10.507281
 >> iter 59000, loss: 10.409117
 >> iter 60000, loss: 10.477388
   Number of active neurons: 10
 >> iter 61000, loss: 10.338063
 >> iter 62000, loss: 10.387660
 >> iter 63000, loss: 10.265330
 >> iter 64000, loss: 10.357138
 >> iter 65000, loss: 10.217003
 >> iter 66000, loss: 10.245024
 >> iter 67000, loss: 10.110612
 >> iter 68000, loss: 10.158517
 >> iter 69000, loss: 10.038962
 >> iter 70000, loss: 10.110355
   Number of active neurons: 10
 >> iter 71000, loss: 9.845409
 >> iter 72000, loss: 9.691126
 >> iter 73000, loss: 9.401999
 >> iter 74000, loss: 9.278638
 >> iter 75000, loss: 9.070220
 >> iter 76000, loss: 9.025754
 >> iter 77000, loss: 8.974750
 >> iter 78000, loss: 8.954170
 >> iter 79000, loss: 8.855468
 >> iter 80000, loss: 8.903189
   Number of active neurons: 10
 >> iter 81000, loss: 8.866232
 >> iter 82000, loss: 8.888297
 >> iter 83000, loss: 8.795979
 >> iter 84000, loss: 8.902286
 >> iter 85000, loss: 8.790476
 >> iter 86000, loss: 8.822775
 >> iter 87000, loss: 8.847590
 >> iter 88000, loss: 8.893885
 >> iter 89000, loss: 8.819826
 >> iter 90000, loss: 8.848166
   Number of active neurons: 10
 >> iter 91000, loss: 8.868225
 >> iter 92000, loss: 8.931643
 >> iter 93000, loss: 8.963231
 >> iter 94000, loss: 8.915741
 >> iter 95000, loss: 8.823462
 >> iter 96000, loss: 8.882591
 >> iter 97000, loss: 8.851730
 >> iter 98000, loss: 8.928731
 >> iter 99000, loss: 8.836539
 >> iter 100000, loss: 8.896398
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 16.8776624468
   - Test - Long: 31.1684415779
   - Test - Big: 16.8578314217
   - Test - A: 11.5458969402
   - Test - B: 31.6245583628
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.136320
 >> iter 2000, loss: 15.699119
 >> iter 3000, loss: 14.151482
 >> iter 4000, loss: 13.533315
 >> iter 5000, loss: 13.255292
 >> iter 6000, loss: 13.160179
 >> iter 7000, loss: 13.100174
 >> iter 8000, loss: 13.073293
 >> iter 9000, loss: 13.049207
 >> iter 10000, loss: 13.059688
   Number of active neurons: 10
 >> iter 11000, loss: 13.042258
 >> iter 12000, loss: 13.039215
 >> iter 13000, loss: 13.032253
 >> iter 14000, loss: 13.046642
 >> iter 15000, loss: 13.037767
 >> iter 16000, loss: 13.043385
 >> iter 17000, loss: 13.041059
 >> iter 18000, loss: 13.038218
 >> iter 19000, loss: 13.027749
 >> iter 20000, loss: 13.045867
   Number of active neurons: 10
 >> iter 21000, loss: 13.021666
 >> iter 22000, loss: 13.044868
 >> iter 23000, loss: 13.023484
 >> iter 24000, loss: 13.039885
 >> iter 25000, loss: 13.028538
 >> iter 26000, loss: 13.035153
 >> iter 27000, loss: 13.026378
 >> iter 28000, loss: 13.033293
 >> iter 29000, loss: 13.020379
 >> iter 30000, loss: 13.040553
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 13.023166
 >> iter 32000, loss: 13.035229
 >> iter 33000, loss: 13.026511
 >> iter 34000, loss: 13.030929
 >> iter 35000, loss: 13.025873
 >> iter 36000, loss: 13.031605
 >> iter 37000, loss: 13.022260
 >> iter 38000, loss: 13.028825
 >> iter 39000, loss: 13.015022
 >> iter 40000, loss: 13.027846
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 9
 >> iter 41000, loss: 13.008861
 >> iter 42000, loss: 13.029677
 >> iter 43000, loss: 13.011844
 >> iter 44000, loss: 13.027549
 >> iter 45000, loss: 13.013771
 >> iter 46000, loss: 13.029751
 >> iter 47000, loss: 13.007486
 >> iter 48000, loss: 13.025660
 >> iter 49000, loss: 13.005279
 >> iter 50000, loss: 13.028435
   Number of active neurons: 10
 >> iter 51000, loss: 13.004164
 >> iter 52000, loss: 13.017472
 >> iter 53000, loss: 12.957661
 >> iter 54000, loss: 12.474022
 >> iter 55000, loss: 11.790611
 >> iter 56000, loss: 11.472257
 >> iter 57000, loss: 11.170876
 >> iter 58000, loss: 11.105647
 >> iter 59000, loss: 10.918993
 >> iter 60000, loss: 10.881318
   Number of active neurons: 10
 >> iter 61000, loss: 10.733459
 >> iter 62000, loss: 10.752971
 >> iter 63000, loss: 10.618099
 >> iter 64000, loss: 10.612466
 >> iter 65000, loss: 10.472471
 >> iter 66000, loss: 10.472667
 >> iter 67000, loss: 10.320159
 >> iter 68000, loss: 10.175163
 >> iter 69000, loss: 9.824960
 >> iter 70000, loss: 9.793541
   Number of active neurons: 10
 >> iter 71000, loss: 9.433461
 >> iter 72000, loss: 9.097798
 >> iter 73000, loss: 8.470282
 >> iter 74000, loss: 8.186118
 >> iter 75000, loss: 7.945640
 >> iter 76000, loss: 8.012931
 >> iter 77000, loss: 7.504242
 >> iter 78000, loss: 7.152044
 >> iter 79000, loss: 7.215724
 >> iter 80000, loss: 6.849506
   Number of active neurons: 10
 >> iter 81000, loss: 6.989885
 >> iter 82000, loss: 6.878392
 >> iter 83000, loss: 6.637512
 >> iter 84000, loss: 6.412744
 >> iter 85000, loss: 6.339968
 >> iter 86000, loss: 6.436537
 >> iter 87000, loss: 6.480315
 >> iter 88000, loss: 6.265014
 >> iter 89000, loss: 6.024442
 >> iter 90000, loss: 5.900449
   Number of active neurons: 10
 >> iter 91000, loss: 5.909616
 >> iter 92000, loss: 5.905127
 >> iter 93000, loss: 5.919004
 >> iter 94000, loss: 5.917032
 >> iter 95000, loss: 5.850166
 >> iter 96000, loss: 5.935610
 >> iter 97000, loss: 5.879854
 >> iter 98000, loss: 5.929247
 >> iter 99000, loss: 5.743898
 >> iter 100000, loss: 5.810210
   Number of active neurons: 10
 >> iter 101000, loss: 5.693378
 >> iter 102000, loss: 5.663156
 >> iter 103000, loss: 5.604742
 >> iter 104000, loss: 5.607401
 >> iter 105000, loss: 5.477149
 >> iter 106000, loss: 5.516914
 >> iter 107000, loss: 5.444468
 >> iter 108000, loss: 5.596205
 >> iter 109000, loss: 5.562267
 >> iter 110000, loss: 5.741024
   Number of active neurons: 10
 >> iter 111000, loss: 5.595792
 >> iter 112000, loss: 5.455800
 >> iter 113000, loss: 5.341822
 >> iter 114000, loss: 5.418886
 >> iter 115000, loss: 5.450602
 >> iter 116000, loss: 5.473296
 >> iter 117000, loss: 5.431590
 >> iter 118000, loss: 5.481349
 >> iter 119000, loss: 5.551234
 >> iter 120000, loss: 5.563343
   Number of active neurons: 10
 >> iter 121000, loss: 5.622501
 >> iter 122000, loss: 5.631162
 >> iter 123000, loss: 5.602629
 >> iter 124000, loss: 5.596555
 >> iter 125000, loss: 5.467233
 >> iter 126000, loss: 5.462937
 >> iter 127000, loss: 5.406668
 >> iter 128000, loss: 5.529454
 >> iter 129000, loss: 5.395860
 >> iter 130000, loss: 5.811548
   Number of active neurons: 10
 >> iter 131000, loss: 5.628628
 >> iter 132000, loss: 5.460095
 >> iter 133000, loss: 5.601048
 >> iter 134000, loss: 5.778083
 >> iter 135000, loss: 5.519438
 >> iter 136000, loss: 5.570766
 >> iter 137000, loss: 5.463063
 >> iter 138000, loss: 5.615092
 >> iter 139000, loss: 5.467487
 >> iter 140000, loss: 5.666833
   Number of active neurons: 10
 >> iter 141000, loss: 5.503153
 >> iter 142000, loss: 5.485011
 >> iter 143000, loss: 5.271865
 >> iter 144000, loss: 5.530637
 >> iter 145000, loss: 5.445495
 >> iter 146000, loss: 5.758685
 >> iter 147000, loss: 5.404033
 >> iter 148000, loss: 5.502216
 >> iter 149000, loss: 5.446787
 >> iter 150000, loss: 5.630367
   Number of active neurons: 10
 >> iter 151000, loss: 5.497075
 >> iter 152000, loss: 5.641530
 >> iter 153000, loss: 5.553102
 >> iter 154000, loss: 5.624260
 >> iter 155000, loss: 5.457815
 >> iter 156000, loss: 5.647932
 >> iter 157000, loss: 5.430531
 >> iter 158000, loss: 5.487845
 >> iter 159000, loss: 5.458970
 >> iter 160000, loss: 5.530949
   Number of active neurons: 10
 >> iter 161000, loss: 5.399278
 >> iter 162000, loss: 5.436174
 >> iter 163000, loss: 5.378138
 >> iter 164000, loss: 5.488286
 >> iter 165000, loss: 5.372420
 >> iter 166000, loss: 5.484372
 >> iter 167000, loss: 5.541754
 >> iter 168000, loss: 5.593555
 >> iter 169000, loss: 5.529597
 >> iter 170000, loss: 5.392988
   Number of active neurons: 10
 >> iter 171000, loss: 3.619790
 >> iter 172000, loss: 2.324182
 >> iter 173000, loss: 1.727829
 >> iter 174000, loss: 1.618964
 >> iter 175000, loss: 1.112603
 >> iter 176000, loss: 0.826121
 >> iter 177000, loss: 1.062094
 >> iter 178000, loss: 1.124771
 >> iter 179000, loss: 0.781611
 >> iter 180000, loss: 0.826605
   Number of active neurons: 10
 >> iter 181000, loss: 0.964090
 >> iter 182000, loss: 0.870987
 >> iter 183000, loss: 0.741256
 >> iter 184000, loss: 0.633068
 >> iter 185000, loss: 0.669814
 >> iter 186000, loss: 0.703395
 >> iter 187000, loss: 0.529678
 >> iter 188000, loss: 0.468007
 >> iter 189000, loss: 0.538513
 >> iter 190000, loss: 0.336892
   Number of active neurons: 10
 >> iter 191000, loss: 0.426240
 >> iter 192000, loss: 0.425193
 >> iter 193000, loss: 0.491153
 >> iter 194000, loss: 0.289847
 >> iter 195000, loss: 0.331383
 >> iter 196000, loss: 0.285396
 >> iter 197000, loss: 0.491063
 >> iter 198000, loss: 0.685036
 >> iter 199000, loss: 0.456071
 >> iter 200000, loss: 0.656133
   Number of active neurons: 10
 >> iter 201000, loss: 0.421304
 >> iter 202000, loss: 0.456122
 >> iter 203000, loss: 0.390339
 >> iter 204000, loss: 0.396409
 >> iter 205000, loss: 0.639306
 >> iter 206000, loss: 0.768324
 >> iter 207000, loss: 0.767009
 >> iter 208000, loss: 0.661100
 >> iter 209000, loss: 0.459197
 >> iter 210000, loss: 0.298714
   Number of active neurons: 10
 >> iter 211000, loss: 0.515540
 >> iter 212000, loss: 0.465507
 >> iter 213000, loss: 0.532569
 >> iter 214000, loss: 0.279665
 >> iter 215000, loss: 0.252975
 >> iter 216000, loss: 0.272701
 >> iter 217000, loss: 0.220686
 >> iter 218000, loss: 0.454125
 >> iter 219000, loss: 0.451492
 >> iter 220000, loss: 0.338372
   Number of active neurons: 10
 >> iter 221000, loss: 0.347091
 >> iter 222000, loss: 0.173420
 >> iter 223000, loss: 0.297326
 >> iter 224000, loss: 0.386370
 >> iter 225000, loss: 0.218212
 >> iter 226000, loss: 0.157849
 >> iter 227000, loss: 0.133884
 >> iter 228000, loss: 0.283692
 >> iter 229000, loss: 0.164411
 >> iter 230000, loss: 0.312619
   Number of active neurons: 10
 >> iter 231000, loss: 0.249536
 >> iter 232000, loss: 0.469801
 >> iter 233000, loss: 0.403265
 >> iter 234000, loss: 0.245824
 >> iter 235000, loss: 0.243557
 >> iter 236000, loss: 0.178345
 >> iter 237000, loss: 0.145688
 >> iter 238000, loss: 0.162060
 >> iter 239000, loss: 0.321825
 >> iter 240000, loss: 0.260264
   Number of active neurons: 10
 >> iter 241000, loss: 0.334207
 >> iter 242000, loss: 0.302326
 >> iter 243000, loss: 0.193594
 >> iter 244000, loss: 0.253575
 >> iter 245000, loss: 0.156766
 >> iter 246000, loss: 0.308681
 >> iter 247000, loss: 0.268575
 >> iter 248000, loss: 0.148435
 >> iter 249000, loss: 0.238726
 >> iter 250000, loss: 0.272919
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 19.210071
 >> iter 2000, loss: 15.597656
 >> iter 3000, loss: 14.111206
 >> iter 4000, loss: 13.529905
 >> iter 5000, loss: 13.272013
 >> iter 6000, loss: 13.177742
 >> iter 7000, loss: 13.118191
 >> iter 8000, loss: 13.114442
 >> iter 9000, loss: 13.085213
 >> iter 10000, loss: 13.082525
   Number of active neurons: 10
 >> iter 11000, loss: 13.059719
 >> iter 12000, loss: 13.063380
 >> iter 13000, loss: 13.033032
 >> iter 14000, loss: 13.041635
 >> iter 15000, loss: 13.023606
 >> iter 16000, loss: 13.032538
 >> iter 17000, loss: 13.021273
 >> iter 18000, loss: 13.029867
 >> iter 19000, loss: 13.010325
 >> iter 20000, loss: 13.019084
   Number of active neurons: 10
 >> iter 21000, loss: 13.009100
 >> iter 22000, loss: 13.027805
 >> iter 23000, loss: 13.010975
 >> iter 24000, loss: 13.022037
 >> iter 25000, loss: 13.004459
 >> iter 26000, loss: 13.019470
 >> iter 27000, loss: 12.996715
 >> iter 28000, loss: 13.009865
 >> iter 29000, loss: 13.004330
 >> iter 30000, loss: 13.011393
   Number of active neurons: 10
 >> iter 31000, loss: 12.998653
 >> iter 32000, loss: 13.009333
 >> iter 33000, loss: 12.999869
 >> iter 34000, loss: 13.008774
 >> iter 35000, loss: 12.997652
 >> iter 36000, loss: 13.007741
 >> iter 37000, loss: 13.002784
 >> iter 38000, loss: 13.011423
 >> iter 39000, loss: 12.995293
 >> iter 40000, loss: 13.004208
   Number of active neurons: 10
 >> iter 41000, loss: 12.985356
 >> iter 42000, loss: 13.007378
 >> iter 43000, loss: 12.989612
 >> iter 44000, loss: 13.005205
 >> iter 45000, loss: 12.985697
 >> iter 46000, loss: 12.995328
 >> iter 47000, loss: 12.951725
 >> iter 48000, loss: 12.929790
 >> iter 49000, loss: 12.904778
 >> iter 50000, loss: 12.860086
   Number of active neurons: 10
 >> iter 51000, loss: 12.800428
 >> iter 52000, loss: 12.760260
 >> iter 53000, loss: 12.514715
 >> iter 54000, loss: 12.064520
 >> iter 55000, loss: 11.629543
 >> iter 56000, loss: 11.412542
 >> iter 57000, loss: 11.151926
 >> iter 58000, loss: 11.099216
 >> iter 59000, loss: 10.940214
 >> iter 60000, loss: 10.878506
   Number of active neurons: 10
 >> iter 61000, loss: 10.682191
 >> iter 62000, loss: 10.660731
 >> iter 63000, loss: 10.383517
 >> iter 64000, loss: 10.294608
 >> iter 65000, loss: 10.069935
 >> iter 66000, loss: 10.051884
 >> iter 67000, loss: 9.903122
 >> iter 68000, loss: 9.980732
 >> iter 69000, loss: 9.782532
 >> iter 70000, loss: 9.823329
   Number of active neurons: 10
 >> iter 71000, loss: 9.693000
 >> iter 72000, loss: 9.813651
 >> iter 73000, loss: 9.710924
 >> iter 74000, loss: 9.746330
 >> iter 75000, loss: 9.642372
 >> iter 76000, loss: 9.701832
 >> iter 77000, loss: 9.559358
 >> iter 78000, loss: 9.672775
 >> iter 79000, loss: 9.516380
 >> iter 80000, loss: 9.608031
   Number of active neurons: 10
 >> iter 81000, loss: 9.498692
 >> iter 82000, loss: 9.546929
 >> iter 83000, loss: 9.447941
 >> iter 84000, loss: 9.514817
 >> iter 85000, loss: 9.402970
 >> iter 86000, loss: 9.481402
 >> iter 87000, loss: 9.373231
 >> iter 88000, loss: 9.470380
 >> iter 89000, loss: 9.364080
 >> iter 90000, loss: 9.452663
   Number of active neurons: 10
 >> iter 91000, loss: 9.359955
 >> iter 92000, loss: 9.464945
 >> iter 93000, loss: 9.381231
 >> iter 94000, loss: 9.444043
 >> iter 95000, loss: 9.320398
 >> iter 96000, loss: 9.450099
 >> iter 97000, loss: 9.338174
 >> iter 98000, loss: 9.429514
 >> iter 99000, loss: 9.320737
 >> iter 100000, loss: 9.390027
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 18.2536349273
   - Test - Long: 31.4634268287
   - Test - Big: 18.2298177018
   - Test - A: 30.3579761349
   - Test - B: 31.631224585
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.117488
 >> iter 2000, loss: 15.646144
 >> iter 3000, loss: 14.152219
 >> iter 4000, loss: 13.555559
 >> iter 5000, loss: 13.292244
 >> iter 6000, loss: 13.199845
 >> iter 7000, loss: 13.137035
 >> iter 8000, loss: 13.107401
 >> iter 9000, loss: 13.093036
 >> iter 10000, loss: 13.091957
   Number of active neurons: 10
 >> iter 11000, loss: 13.068119
 >> iter 12000, loss: 13.075815
 >> iter 13000, loss: 13.053949
 >> iter 14000, loss: 13.061378
 >> iter 15000, loss: 13.046516
 >> iter 16000, loss: 13.057844
 >> iter 17000, loss: 13.043644
 >> iter 18000, loss: 13.048385
 >> iter 19000, loss: 13.040238
 >> iter 20000, loss: 13.057981
   Number of active neurons: 10
 >> iter 21000, loss: 13.039220
 >> iter 22000, loss: 13.052522
 >> iter 23000, loss: 13.048504
 >> iter 24000, loss: 13.056110
 >> iter 25000, loss: 13.047074
 >> iter 26000, loss: 13.068552
 >> iter 27000, loss: 13.043319
 >> iter 28000, loss: 13.059532
 >> iter 29000, loss: 13.039989
 >> iter 30000, loss: 13.054853
   Number of active neurons: 10
 >> iter 31000, loss: 13.041635
 >> iter 32000, loss: 13.058865
 >> iter 33000, loss: 13.047129
 >> iter 34000, loss: 13.059733
 >> iter 35000, loss: 13.043269
 >> iter 36000, loss: 13.046981
 >> iter 37000, loss: 13.039162
 >> iter 38000, loss: 13.051514
 >> iter 39000, loss: 13.041424
 >> iter 40000, loss: 13.053908
   Number of active neurons: 10
 >> iter 41000, loss: 13.045015
 >> iter 42000, loss: 13.056337
 >> iter 43000, loss: 13.037882
 >> iter 44000, loss: 13.054481
 >> iter 45000, loss: 13.030435
 >> iter 46000, loss: 13.054040
 >> iter 47000, loss: 13.030705
 >> iter 48000, loss: 13.054024
 >> iter 49000, loss: 13.032329
 >> iter 50000, loss: 13.053265
   Number of active neurons: 10
 >> iter 51000, loss: 13.033772
 >> iter 52000, loss: 13.047801
 >> iter 53000, loss: 13.027983
 >> iter 54000, loss: 13.051243
 >> iter 55000, loss: 13.022470
 >> iter 56000, loss: 13.030024
 >> iter 57000, loss: 12.990138
 >> iter 58000, loss: 12.971332
 >> iter 59000, loss: 12.929504
 >> iter 60000, loss: 12.897204
   Number of active neurons: 10
 >> iter 61000, loss: 12.786624
 >> iter 62000, loss: 12.322392
 >> iter 63000, loss: 11.764237
 >> iter 64000, loss: 11.497256
 >> iter 65000, loss: 11.253547
 >> iter 66000, loss: 11.212490
 >> iter 67000, loss: 11.079538
 >> iter 68000, loss: 11.141418
 >> iter 69000, loss: 11.002383
 >> iter 70000, loss: 11.015203
   Number of active neurons: 10
 >> iter 71000, loss: 10.896718
 >> iter 72000, loss: 10.977606
 >> iter 73000, loss: 10.832134
 >> iter 74000, loss: 10.893695
 >> iter 75000, loss: 10.756813
 >> iter 76000, loss: 10.709342
 >> iter 77000, loss: 10.415683
 >> iter 78000, loss: 10.376086
 >> iter 79000, loss: 10.096502
 >> iter 80000, loss: 9.989887
   Number of active neurons: 10
 >> iter 81000, loss: 9.781747
 >> iter 82000, loss: 9.816679
 >> iter 83000, loss: 9.607817
 >> iter 84000, loss: 9.567060
 >> iter 85000, loss: 9.418216
 >> iter 86000, loss: 9.422107
 >> iter 87000, loss: 9.324071
 >> iter 88000, loss: 9.412583
 >> iter 89000, loss: 9.342919
 >> iter 90000, loss: 9.236979
   Number of active neurons: 10
 >> iter 91000, loss: 9.070086
 >> iter 92000, loss: 9.158554
 >> iter 93000, loss: 9.026027
 >> iter 94000, loss: 9.107670
 >> iter 95000, loss: 9.015307
 >> iter 96000, loss: 8.988413
 >> iter 97000, loss: 8.951554
 >> iter 98000, loss: 8.980521
 >> iter 99000, loss: 8.841967
 >> iter 100000, loss: 8.904728
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 17.475650487
   - Test - Long: 31.3084345783
   - Test - Big: 17.4658253417
   - Test - A: 15.1189920672
   - Test - B: 31.6445570295
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.148978
 >> iter 2000, loss: 15.655757
 >> iter 3000, loss: 14.138990
 >> iter 4000, loss: 13.551572
 >> iter 5000, loss: 13.284163
 >> iter 6000, loss: 13.189065
 >> iter 7000, loss: 13.119850
 >> iter 8000, loss: 13.095477
 >> iter 9000, loss: 13.063936
 >> iter 10000, loss: 13.080103
   Number of active neurons: 10
 >> iter 11000, loss: 13.057772
 >> iter 12000, loss: 13.051783
 >> iter 13000, loss: 13.041710
 >> iter 14000, loss: 13.058643
 >> iter 15000, loss: 13.032878
 >> iter 16000, loss: 13.044238
 >> iter 17000, loss: 13.021688
 >> iter 18000, loss: 13.033149
 >> iter 19000, loss: 13.016230
 >> iter 20000, loss: 13.019956
   Number of active neurons: 10
 >> iter 21000, loss: 13.002370
 >> iter 22000, loss: 13.020590
 >> iter 23000, loss: 13.004340
 >> iter 24000, loss: 13.021527
 >> iter 25000, loss: 12.998604
 >> iter 26000, loss: 13.012735
 >> iter 27000, loss: 13.000654
 >> iter 28000, loss: 13.012650
 >> iter 29000, loss: 12.990594
 >> iter 30000, loss: 13.008004
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 12.993941
 >> iter 32000, loss: 13.003884
 >> iter 33000, loss: 12.998892
 >> iter 34000, loss: 13.013229
 >> iter 35000, loss: 12.996672
 >> iter 36000, loss: 13.002647
 >> iter 37000, loss: 12.990174
 >> iter 38000, loss: 13.006242
 >> iter 39000, loss: 12.993476
 >> iter 40000, loss: 13.005914
   Number of active neurons: 9
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 9
 >> iter 41000, loss: 12.989134
 >> iter 42000, loss: 13.010882
 >> iter 43000, loss: 12.994941
 >> iter 44000, loss: 13.009879
 >> iter 45000, loss: 12.986015
 >> iter 46000, loss: 13.010780
 >> iter 47000, loss: 12.986464
 >> iter 48000, loss: 13.015191
 >> iter 49000, loss: 12.985515
 >> iter 50000, loss: 13.012865
   Number of active neurons: 8
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 8
 >> iter 51000, loss: 12.989333
 >> iter 52000, loss: 13.012148
 >> iter 53000, loss: 12.985620
 >> iter 54000, loss: 13.014195
 >> iter 55000, loss: 12.983562
 >> iter 56000, loss: 13.009160
 >> iter 57000, loss: 12.986155
 >> iter 58000, loss: 13.011345
 >> iter 59000, loss: 12.982350
 >> iter 60000, loss: 13.006315
   Number of active neurons: 10
 >> iter 61000, loss: 12.988083
 >> iter 62000, loss: 13.011655
 >> iter 63000, loss: 12.987593
 >> iter 64000, loss: 13.010823
 >> iter 65000, loss: 12.976703
 >> iter 66000, loss: 12.990338
 >> iter 67000, loss: 12.949766
 >> iter 68000, loss: 12.947968
 >> iter 69000, loss: 12.899319
 >> iter 70000, loss: 12.872655
   Number of active neurons: 10
 >> iter 71000, loss: 12.822335
 >> iter 72000, loss: 12.787407
 >> iter 73000, loss: 12.716849
 >> iter 74000, loss: 12.606986
 >> iter 75000, loss: 12.350618
 >> iter 76000, loss: 12.147918
 >> iter 77000, loss: 11.694870
 >> iter 78000, loss: 11.458963
 >> iter 79000, loss: 11.190716
 >> iter 80000, loss: 11.110034
   Number of active neurons: 10
 >> iter 81000, loss: 10.910983
 >> iter 82000, loss: 10.924843
 >> iter 83000, loss: 10.783344
 >> iter 84000, loss: 10.808993
 >> iter 85000, loss: 10.684319
 >> iter 86000, loss: 10.703267
 >> iter 87000, loss: 10.573587
 >> iter 88000, loss: 10.591638
 >> iter 89000, loss: 10.442852
 >> iter 90000, loss: 10.488925
   Number of active neurons: 10
 >> iter 91000, loss: 10.395576
 >> iter 92000, loss: 10.437063
 >> iter 93000, loss: 10.275534
 >> iter 94000, loss: 10.199508
 >> iter 95000, loss: 9.918157
 >> iter 96000, loss: 9.848880
 >> iter 97000, loss: 9.642337
 >> iter 98000, loss: 9.614825
 >> iter 99000, loss: 9.513180
 >> iter 100000, loss: 9.479640
   Number of active neurons: 10
 >> iter 101000, loss: 9.380197
 >> iter 102000, loss: 9.389382
 >> iter 103000, loss: 9.243339
 >> iter 104000, loss: 9.322289
 >> iter 105000, loss: 9.229278
 >> iter 106000, loss: 9.301309
 >> iter 107000, loss: 9.174108
 >> iter 108000, loss: 9.234458
 >> iter 109000, loss: 9.044477
 >> iter 110000, loss: 9.154919
   Number of active neurons: 10
 >> iter 111000, loss: 9.009662
 >> iter 112000, loss: 9.143746
 >> iter 113000, loss: 8.961685
 >> iter 114000, loss: 9.054497
 >> iter 115000, loss: 8.947050
 >> iter 116000, loss: 9.029502
 >> iter 117000, loss: 8.899622
 >> iter 118000, loss: 9.027438
 >> iter 119000, loss: 8.941388
 >> iter 120000, loss: 9.009991
   Number of active neurons: 10
 >> iter 121000, loss: 8.876506
 >> iter 122000, loss: 8.973003
 >> iter 123000, loss: 8.839988
 >> iter 124000, loss: 8.953959
 >> iter 125000, loss: 8.850714
 >> iter 126000, loss: 8.950261
 >> iter 127000, loss: 8.861994
 >> iter 128000, loss: 8.903964
 >> iter 129000, loss: 8.805843
 >> iter 130000, loss: 8.886304
   Number of active neurons: 10
 >> iter 131000, loss: 8.783881
 >> iter 132000, loss: 8.903461
 >> iter 133000, loss: 8.827392
 >> iter 134000, loss: 8.905824
 >> iter 135000, loss: 8.752210
 >> iter 136000, loss: 8.931203
 >> iter 137000, loss: 8.788000
 >> iter 138000, loss: 8.883093
 >> iter 139000, loss: 8.766681
 >> iter 140000, loss: 8.890076
   Number of active neurons: 10
 >> iter 141000, loss: 8.837679
 >> iter 142000, loss: 8.911637
 >> iter 143000, loss: 8.757690
 >> iter 144000, loss: 8.893065
 >> iter 145000, loss: 8.797240
 >> iter 146000, loss: 8.894352
 >> iter 147000, loss: 8.748211
 >> iter 148000, loss: 8.913573
 >> iter 149000, loss: 8.753735
 >> iter 150000, loss: 8.771428
   Number of active neurons: 10
 >> iter 151000, loss: 8.653397
 >> iter 152000, loss: 8.661500
 >> iter 153000, loss: 8.489804
 >> iter 154000, loss: 8.776679
 >> iter 155000, loss: 8.407466
 >> iter 156000, loss: 8.586213
 >> iter 157000, loss: 8.317505
 >> iter 158000, loss: 8.557640
 >> iter 159000, loss: 8.324044
 >> iter 160000, loss: 8.486210
   Number of active neurons: 10
 >> iter 161000, loss: 8.341627
 >> iter 162000, loss: 8.479949
 >> iter 163000, loss: 8.267376
 >> iter 164000, loss: 8.426969
 >> iter 165000, loss: 8.242571
 >> iter 166000, loss: 8.421161
 >> iter 167000, loss: 8.263466
 >> iter 168000, loss: 8.381477
 >> iter 169000, loss: 8.047583
 >> iter 170000, loss: 8.153568
   Number of active neurons: 10
 >> iter 171000, loss: 7.939606
 >> iter 172000, loss: 7.981692
 >> iter 173000, loss: 7.745206
 >> iter 174000, loss: 7.810326
 >> iter 175000, loss: 7.541383
 >> iter 176000, loss: 7.727212
 >> iter 177000, loss: 7.532578
 >> iter 178000, loss: 7.759448
 >> iter 179000, loss: 7.541631
 >> iter 180000, loss: 7.777080
   Number of active neurons: 10
 >> iter 181000, loss: 7.542207
 >> iter 182000, loss: 7.684690
 >> iter 183000, loss: 7.688299
 >> iter 184000, loss: 7.733333
 >> iter 185000, loss: 7.506161
 >> iter 186000, loss: 7.727400
 >> iter 187000, loss: 7.457806
 >> iter 188000, loss: 7.496334
 >> iter 189000, loss: 7.141595
 >> iter 190000, loss: 7.296188
   Number of active neurons: 10
 >> iter 191000, loss: 7.049152
 >> iter 192000, loss: 7.290910
 >> iter 193000, loss: 7.032146
 >> iter 194000, loss: 7.220669
 >> iter 195000, loss: 6.993874
 >> iter 196000, loss: 7.305353
 >> iter 197000, loss: 7.046593
 >> iter 198000, loss: 7.268578
 >> iter 199000, loss: 7.046748
 >> iter 200000, loss: 7.272033
   Number of active neurons: 10
 >> iter 201000, loss: 7.072540
 >> iter 202000, loss: 7.299438
 >> iter 203000, loss: 7.055518
 >> iter 204000, loss: 7.422033
 >> iter 205000, loss: 7.104179
 >> iter 206000, loss: 7.361645
 >> iter 207000, loss: 7.076563
 >> iter 208000, loss: 7.299830
 >> iter 209000, loss: 7.073699
 >> iter 210000, loss: 7.246856
   Number of active neurons: 10
 >> iter 211000, loss: 7.073725
 >> iter 212000, loss: 7.384523
 >> iter 213000, loss: 7.146881
 >> iter 214000, loss: 7.356605
 >> iter 215000, loss: 7.104503
 >> iter 216000, loss: 7.336867
 >> iter 217000, loss: 7.142865
 >> iter 218000, loss: 7.268115
 >> iter 219000, loss: 7.119889
 >> iter 220000, loss: 7.206872
   Number of active neurons: 10
 >> iter 221000, loss: 7.045305
 >> iter 222000, loss: 7.267092
 >> iter 223000, loss: 7.057494
 >> iter 224000, loss: 7.144068
 >> iter 225000, loss: 6.984628
 >> iter 226000, loss: 7.236816
 >> iter 227000, loss: 7.037468
 >> iter 228000, loss: 7.172694
 >> iter 229000, loss: 7.013334
 >> iter 230000, loss: 7.188529
   Number of active neurons: 10
 >> iter 231000, loss: 6.967673
 >> iter 232000, loss: 7.114195
 >> iter 233000, loss: 6.971836
 >> iter 234000, loss: 7.099767
 >> iter 235000, loss: 6.919908
 >> iter 236000, loss: 7.126979
 >> iter 237000, loss: 6.989314
 >> iter 238000, loss: 7.138958
 >> iter 239000, loss: 6.922190
 >> iter 240000, loss: 7.089752
   Number of active neurons: 10
 >> iter 241000, loss: 6.876770
 >> iter 242000, loss: 7.075182
 >> iter 243000, loss: 6.906606
 >> iter 244000, loss: 7.062762
 >> iter 245000, loss: 6.888143
 >> iter 246000, loss: 7.084230
 >> iter 247000, loss: 6.915563
 >> iter 248000, loss: 7.058484
 >> iter 249000, loss: 6.758625
 >> iter 250000, loss: 6.838386
   Number of active neurons: 10
 >> iter 251000, loss: 6.799656
 >> iter 252000, loss: 6.912006
 >> iter 253000, loss: 6.660550
 >> iter 254000, loss: 6.842316
 >> iter 255000, loss: 6.667587
 >> iter 256000, loss: 6.833301
 >> iter 257000, loss: 6.648850
 >> iter 258000, loss: 6.771782
 >> iter 259000, loss: 6.629170
 >> iter 260000, loss: 6.762100
   Number of active neurons: 10
 >> iter 261000, loss: 6.596206
 >> iter 262000, loss: 6.730147
 >> iter 263000, loss: 6.619759
 >> iter 264000, loss: 6.812101
 >> iter 265000, loss: 6.655436
 >> iter 266000, loss: 6.798249
 >> iter 267000, loss: 6.770502
 >> iter 268000, loss: 6.884434
 >> iter 269000, loss: 6.692053
 >> iter 270000, loss: 6.944620
   Number of active neurons: 10
 >> iter 271000, loss: 6.763701
 >> iter 272000, loss: 6.868535
 >> iter 273000, loss: 6.686561
 >> iter 274000, loss: 6.810327
 >> iter 275000, loss: 6.720005
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 13.9017219656
   - Test - Long: 30.4784760762
   - Test - Big: 14.0068599314
   - Test - A: 7.99946670222
   - Test - B: 31.6112259183
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.151729
 >> iter 2000, loss: 15.604788
 >> iter 3000, loss: 14.145198
 >> iter 4000, loss: 13.541703
 >> iter 5000, loss: 13.274289
 >> iter 6000, loss: 13.177772
 >> iter 7000, loss: 13.130774
 >> iter 8000, loss: 13.117867
 >> iter 9000, loss: 13.099887
 >> iter 10000, loss: 13.098310
   Number of active neurons: 10
 >> iter 11000, loss: 13.072557
 >> iter 12000, loss: 13.080861
 >> iter 13000, loss: 13.059467
 >> iter 14000, loss: 13.064494
 >> iter 15000, loss: 13.047673
 >> iter 16000, loss: 13.049370
 >> iter 17000, loss: 13.046966
 >> iter 18000, loss: 13.051810
 >> iter 19000, loss: 13.032701
 >> iter 20000, loss: 13.052233
   Number of active neurons: 10
 >> iter 21000, loss: 13.033229
 >> iter 22000, loss: 13.049440
 >> iter 23000, loss: 13.030901
 >> iter 24000, loss: 13.035878
 >> iter 25000, loss: 13.023964
 >> iter 26000, loss: 13.028565
 >> iter 27000, loss: 13.015940
 >> iter 28000, loss: 13.033963
 >> iter 29000, loss: 13.018476
 >> iter 30000, loss: 13.027177
   Number of active neurons: 10
 >> iter 31000, loss: 13.014840
 >> iter 32000, loss: 13.022520
 >> iter 33000, loss: 13.002662
 >> iter 34000, loss: 12.993801
 >> iter 35000, loss: 12.867008
 >> iter 36000, loss: 12.352682
 >> iter 37000, loss: 11.787852
 >> iter 38000, loss: 11.471762
 >> iter 39000, loss: 11.164159
 >> iter 40000, loss: 11.048905
   Number of active neurons: 10
 >> iter 41000, loss: 10.875154
 >> iter 42000, loss: 10.864922
 >> iter 43000, loss: 10.754703
 >> iter 44000, loss: 10.731306
 >> iter 45000, loss: 10.562101
 >> iter 46000, loss: 10.563258
 >> iter 47000, loss: 10.461419
 >> iter 48000, loss: 10.486385
 >> iter 49000, loss: 10.334759
 >> iter 50000, loss: 10.291265
   Number of active neurons: 10
 >> iter 51000, loss: 9.861534
 >> iter 52000, loss: 9.665032
 >> iter 53000, loss: 9.161282
 >> iter 54000, loss: 9.098894
 >> iter 55000, loss: 8.817880
 >> iter 56000, loss: 8.789229
 >> iter 57000, loss: 8.557073
 >> iter 58000, loss: 8.628014
 >> iter 59000, loss: 8.498860
 >> iter 60000, loss: 8.562364
   Number of active neurons: 10
 >> iter 61000, loss: 8.422935
 >> iter 62000, loss: 8.493273
 >> iter 63000, loss: 8.416679
 >> iter 64000, loss: 8.579385
 >> iter 65000, loss: 8.327598
 >> iter 66000, loss: 8.448187
 >> iter 67000, loss: 8.275189
 >> iter 68000, loss: 8.267300
 >> iter 69000, loss: 7.998667
 >> iter 70000, loss: 8.227317
   Number of active neurons: 10
 >> iter 71000, loss: 7.988508
 >> iter 72000, loss: 7.932951
 >> iter 73000, loss: 7.675306
 >> iter 74000, loss: 7.716238
 >> iter 75000, loss: 7.156962
 >> iter 76000, loss: 7.273305
 >> iter 77000, loss: 7.203818
 >> iter 78000, loss: 6.706503
 >> iter 79000, loss: 6.550727
 >> iter 80000, loss: 6.814583
   Number of active neurons: 10
 >> iter 81000, loss: 6.768846
 >> iter 82000, loss: 6.730475
 >> iter 83000, loss: 5.861964
 >> iter 84000, loss: 5.313534
 >> iter 85000, loss: 4.530621
 >> iter 86000, loss: 2.876280
 >> iter 87000, loss: 2.182133
 >> iter 88000, loss: 1.518802
 >> iter 89000, loss: 1.468951
 >> iter 90000, loss: 1.861510
   Number of active neurons: 10
 >> iter 91000, loss: 1.765547
 >> iter 92000, loss: 1.318279
 >> iter 93000, loss: 1.108798
 >> iter 94000, loss: 0.901639
 >> iter 95000, loss: 0.835569
 >> iter 96000, loss: 0.960560
 >> iter 97000, loss: 0.801035
 >> iter 98000, loss: 0.556638
 >> iter 99000, loss: 0.497172
 >> iter 100000, loss: 0.684288
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.179658
 >> iter 2000, loss: 15.649394
 >> iter 3000, loss: 14.116678
 >> iter 4000, loss: 13.507537
 >> iter 5000, loss: 13.268557
 >> iter 6000, loss: 13.163473
 >> iter 7000, loss: 13.095399
 >> iter 8000, loss: 13.081142
 >> iter 9000, loss: 13.067072
 >> iter 10000, loss: 13.061172
   Number of active neurons: 10
 >> iter 11000, loss: 13.042295
 >> iter 12000, loss: 13.044990
 >> iter 13000, loss: 13.033004
 >> iter 14000, loss: 13.040160
 >> iter 15000, loss: 13.024041
 >> iter 16000, loss: 13.031816
 >> iter 17000, loss: 13.010357
 >> iter 18000, loss: 13.020446
 >> iter 19000, loss: 13.007210
 >> iter 20000, loss: 13.018128
   Number of active neurons: 10
 >> iter 21000, loss: 13.003674
 >> iter 22000, loss: 13.012393
 >> iter 23000, loss: 13.001823
 >> iter 24000, loss: 13.008636
 >> iter 25000, loss: 12.991490
 >> iter 26000, loss: 13.003074
 >> iter 27000, loss: 12.985784
 >> iter 28000, loss: 12.999152
 >> iter 29000, loss: 12.983441
 >> iter 30000, loss: 12.997959
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 31000, loss: 12.984008
 >> iter 32000, loss: 12.998139
 >> iter 33000, loss: 12.986207
 >> iter 34000, loss: 12.993364
 >> iter 35000, loss: 12.977075
 >> iter 36000, loss: 12.982819
 >> iter 37000, loss: 12.978525
 >> iter 38000, loss: 12.990414
 >> iter 39000, loss: 12.972175
 >> iter 40000, loss: 12.986128
   Number of active neurons: 7
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 7
 >> iter 41000, loss: 12.971464
 >> iter 42000, loss: 12.981126
 >> iter 43000, loss: 12.962505
 >> iter 44000, loss: 12.948731
 >> iter 45000, loss: 12.915143
 >> iter 46000, loss: 12.907056
 >> iter 47000, loss: 12.846191
 >> iter 48000, loss: 12.827408
 >> iter 49000, loss: 12.764421
 >> iter 50000, loss: 12.704830
   Number of active neurons: 10
 >> iter 51000, loss: 12.635794
 >> iter 52000, loss: 12.545524
 >> iter 53000, loss: 12.458046
 >> iter 54000, loss: 12.386536
 >> iter 55000, loss: 12.262586
 >> iter 56000, loss: 12.079163
 >> iter 57000, loss: 11.878349
 >> iter 58000, loss: 11.731146
 >> iter 59000, loss: 11.528589
 >> iter 60000, loss: 11.397064
   Number of active neurons: 10
 >> iter 61000, loss: 11.282169
 >> iter 62000, loss: 11.264724
 >> iter 63000, loss: 11.131387
 >> iter 64000, loss: 11.120246
 >> iter 65000, loss: 11.010505
 >> iter 66000, loss: 10.947573
 >> iter 67000, loss: 10.833363
 >> iter 68000, loss: 10.759811
 >> iter 69000, loss: 10.575358
 >> iter 70000, loss: 10.474497
   Number of active neurons: 10
 >> iter 71000, loss: 10.236799
 >> iter 72000, loss: 9.997317
 >> iter 73000, loss: 9.637406
 >> iter 74000, loss: 9.576267
 >> iter 75000, loss: 9.502753
 >> iter 76000, loss: 9.349422
 >> iter 77000, loss: 8.897271
 >> iter 78000, loss: 8.766543
 >> iter 79000, loss: 8.700968
 >> iter 80000, loss: 8.668972
   Number of active neurons: 10
 >> iter 81000, loss: 8.602526
 >> iter 82000, loss: 8.494506
 >> iter 83000, loss: 8.435520
 >> iter 84000, loss: 8.307101
 >> iter 85000, loss: 8.143966
 >> iter 86000, loss: 8.540160
 >> iter 87000, loss: 8.390355
 >> iter 88000, loss: 7.950207
 >> iter 89000, loss: 7.504723
 >> iter 90000, loss: 7.322577
   Number of active neurons: 10
 >> iter 91000, loss: 7.089143
 >> iter 92000, loss: 6.715844
 >> iter 93000, loss: 6.531809
 >> iter 94000, loss: 5.760270
 >> iter 95000, loss: 4.614344
 >> iter 96000, loss: 4.157248
 >> iter 97000, loss: 3.647777
 >> iter 98000, loss: 3.117049
 >> iter 99000, loss: 3.215693
 >> iter 100000, loss: 3.521029
   Number of active neurons: 10
 >> iter 101000, loss: 3.384407
 >> iter 102000, loss: 3.293846
 >> iter 103000, loss: 3.338255
 >> iter 104000, loss: 2.832114
 >> iter 105000, loss: 2.841874
 >> iter 106000, loss: 2.576581
 >> iter 107000, loss: 2.639012
 >> iter 108000, loss: 2.720893
 >> iter 109000, loss: 2.785411
 >> iter 110000, loss: 2.558824
   Number of active neurons: 10
 >> iter 111000, loss: 2.560193
 >> iter 112000, loss: 2.248267
 >> iter 113000, loss: 2.647093
 >> iter 114000, loss: 2.203637
 >> iter 115000, loss: 2.302094
 >> iter 116000, loss: 2.252410
 >> iter 117000, loss: 2.198617
 >> iter 118000, loss: 1.901116
 >> iter 119000, loss: 2.140998
 >> iter 120000, loss: 2.175675
   Number of active neurons: 10
 >> iter 121000, loss: 2.154414
 >> iter 122000, loss: 1.911054
 >> iter 123000, loss: 1.866630
 >> iter 124000, loss: 2.022962
 >> iter 125000, loss: 1.865768
 >> iter 126000, loss: 2.091221
 >> iter 127000, loss: 2.176082
 >> iter 128000, loss: 2.177325
 >> iter 129000, loss: 1.963423
 >> iter 130000, loss: 1.962735
   Number of active neurons: 10
 >> iter 131000, loss: 2.011822
 >> iter 132000, loss: 1.822790
 >> iter 133000, loss: 1.912014
 >> iter 134000, loss: 1.655641
 >> iter 135000, loss: 1.873749
 >> iter 136000, loss: 1.806295
 >> iter 137000, loss: 1.906318
 >> iter 138000, loss: 1.982824
 >> iter 139000, loss: 1.886702
 >> iter 140000, loss: 1.890131
   Number of active neurons: 10
 >> iter 141000, loss: 1.616487
 >> iter 142000, loss: 1.808304
 >> iter 143000, loss: 2.024175
 >> iter 144000, loss: 1.953497
 >> iter 145000, loss: 1.672382
 >> iter 146000, loss: 1.743880
 >> iter 147000, loss: 1.690113
 >> iter 148000, loss: 1.797782
 >> iter 149000, loss: 1.843641
 >> iter 150000, loss: 2.000200
   Number of active neurons: 10
 >> iter 151000, loss: 1.786272
 >> iter 152000, loss: 2.047490
 >> iter 153000, loss: 2.012139
 >> iter 154000, loss: 1.661363
 >> iter 155000, loss: 1.918519
 >> iter 156000, loss: 1.500940
 >> iter 157000, loss: 1.331330
 >> iter 158000, loss: 1.560544
 >> iter 159000, loss: 1.597720
 >> iter 160000, loss: 1.664673
   Number of active neurons: 10
 >> iter 161000, loss: 1.655562
 >> iter 162000, loss: 1.590441
 >> iter 163000, loss: 1.461188
 >> iter 164000, loss: 1.420866
 >> iter 165000, loss: 1.426267
 >> iter 166000, loss: 1.295864
 >> iter 167000, loss: 1.845724
 >> iter 168000, loss: 1.800410
 >> iter 169000, loss: 1.648921
 >> iter 170000, loss: 1.535255
   Number of active neurons: 10
 >> iter 171000, loss: 1.571860
 >> iter 172000, loss: 1.432628
 >> iter 173000, loss: 1.215355
 >> iter 174000, loss: 1.245240
 >> iter 175000, loss: 1.374055
 >> iter 176000, loss: 1.646138
 >> iter 177000, loss: 1.370944
 >> iter 178000, loss: 1.384629
 >> iter 179000, loss: 1.310905
 >> iter 180000, loss: 1.258767
   Number of active neurons: 10
 >> iter 181000, loss: 1.542932
 >> iter 182000, loss: 1.156386
 >> iter 183000, loss: 1.409344
 >> iter 184000, loss: 1.044950
 >> iter 185000, loss: 0.804682
 >> iter 186000, loss: 0.549989
 >> iter 187000, loss: 0.673820
 >> iter 188000, loss: 0.661598
 >> iter 189000, loss: 0.674585
 >> iter 190000, loss: 0.816416
   Number of active neurons: 10
 >> iter 191000, loss: 0.833465
 >> iter 192000, loss: 0.859250
 >> iter 193000, loss: 0.567340
 >> iter 194000, loss: 0.923162
 >> iter 195000, loss: 0.658682
 >> iter 196000, loss: 0.653074
 >> iter 197000, loss: 0.617532
 >> iter 198000, loss: 0.505319
 >> iter 199000, loss: 0.512275
 >> iter 200000, loss: 0.698383
   Number of active neurons: 10
 >> iter 201000, loss: 0.510417
 >> iter 202000, loss: 0.321194
 >> iter 203000, loss: 0.436313
 >> iter 204000, loss: 0.722398
 >> iter 205000, loss: 0.596744
 >> iter 206000, loss: 0.424237
 >> iter 207000, loss: 0.426644
 >> iter 208000, loss: 0.346135
 >> iter 209000, loss: 0.219619
 >> iter 210000, loss: 0.463118
   Number of active neurons: 10
 >> iter 211000, loss: 0.466184
 >> iter 212000, loss: 0.379783
 >> iter 213000, loss: 0.369914
 >> iter 214000, loss: 0.409843
 >> iter 215000, loss: 0.450520
 >> iter 216000, loss: 0.697000
 >> iter 217000, loss: 0.582974
 >> iter 218000, loss: 0.358123
 >> iter 219000, loss: 0.359170
 >> iter 220000, loss: 0.416502
   Number of active neurons: 10
 >> iter 221000, loss: 0.485467
 >> iter 222000, loss: 0.333650
 >> iter 223000, loss: 0.456244
 >> iter 224000, loss: 0.375887
 >> iter 225000, loss: 0.508996
 >> iter 226000, loss: 0.512570
 >> iter 227000, loss: 0.538751
 >> iter 228000, loss: 0.405401
 >> iter 229000, loss: 0.280695
 >> iter 230000, loss: 0.175358
   Number of active neurons: 10
 >> iter 231000, loss: 0.348269
 >> iter 232000, loss: 0.465480
 >> iter 233000, loss: 0.569586
 >> iter 234000, loss: 0.632683
 >> iter 235000, loss: 0.539147
 >> iter 236000, loss: 0.670531
 >> iter 237000, loss: 0.423319
 >> iter 238000, loss: 0.271259
 >> iter 239000, loss: 0.432329
 >> iter 240000, loss: 0.212734
   Number of active neurons: 10
 >> iter 241000, loss: 0.221576
 >> iter 242000, loss: 0.139501
 >> iter 243000, loss: 0.212190
 >> iter 244000, loss: 0.317870
 >> iter 245000, loss: 0.438089
 >> iter 246000, loss: 0.314282
 >> iter 247000, loss: 0.246248
 >> iter 248000, loss: 0.336555
 >> iter 249000, loss: 0.184502
 >> iter 250000, loss: 0.208161
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0019999600008
   - Test - Long: 0.0
   - Test - Big: 0.0039999600004
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.136313
 >> iter 2000, loss: 15.533881
 >> iter 3000, loss: 14.049033
 >> iter 4000, loss: 13.489715
 >> iter 5000, loss: 13.240430
 >> iter 6000, loss: 13.164612
 >> iter 7000, loss: 13.105072
 >> iter 8000, loss: 13.090518
 >> iter 9000, loss: 13.067211
 >> iter 10000, loss: 13.060073
   Number of active neurons: 10
 >> iter 11000, loss: 13.043555
 >> iter 12000, loss: 13.051479
 >> iter 13000, loss: 13.046024
 >> iter 14000, loss: 13.049321
 >> iter 15000, loss: 13.032233
 >> iter 16000, loss: 13.043639
 >> iter 17000, loss: 13.035431
 >> iter 18000, loss: 13.045644
 >> iter 19000, loss: 13.031331
 >> iter 20000, loss: 13.042023
   Number of active neurons: 10
 >> iter 21000, loss: 13.026050
 >> iter 22000, loss: 13.032902
 >> iter 23000, loss: 13.022059
 >> iter 24000, loss: 13.030078
 >> iter 25000, loss: 13.017763
 >> iter 26000, loss: 13.030803
 >> iter 27000, loss: 13.013914
 >> iter 28000, loss: 13.020300
 >> iter 29000, loss: 13.012701
 >> iter 30000, loss: 13.023733
   Number of active neurons: 10
 >> iter 31000, loss: 13.006939
 >> iter 32000, loss: 13.021778
 >> iter 33000, loss: 13.016559
 >> iter 34000, loss: 13.026185
 >> iter 35000, loss: 13.014599
 >> iter 36000, loss: 13.028738
 >> iter 37000, loss: 13.019171
 >> iter 38000, loss: 13.023342
 >> iter 39000, loss: 13.005980
 >> iter 40000, loss: 13.019837
   Number of active neurons: 10
 >> iter 41000, loss: 13.008347
 >> iter 42000, loss: 13.027311
 >> iter 43000, loss: 13.010827
 >> iter 44000, loss: 13.030112
 >> iter 45000, loss: 13.009493
 >> iter 46000, loss: 13.030567
 >> iter 47000, loss: 13.007095
 >> iter 48000, loss: 13.030090
 >> iter 49000, loss: 13.002980
 >> iter 50000, loss: 13.031804
   Number of active neurons: 10
 >> iter 51000, loss: 13.002579
 >> iter 52000, loss: 13.022072
 >> iter 53000, loss: 12.999714
 >> iter 54000, loss: 13.023993
 >> iter 55000, loss: 12.989693
 >> iter 56000, loss: 13.024911
 >> iter 57000, loss: 12.991649
 >> iter 58000, loss: 13.018060
 >> iter 59000, loss: 12.992789
 >> iter 60000, loss: 13.022563
   Number of active neurons: 10
 >> iter 61000, loss: 12.998314
 >> iter 62000, loss: 13.026562
 >> iter 63000, loss: 12.996177
 >> iter 64000, loss: 13.026560
 >> iter 65000, loss: 13.002626
 >> iter 66000, loss: 13.022797
 >> iter 67000, loss: 12.991244
 >> iter 68000, loss: 13.024860
 >> iter 69000, loss: 13.003617
 >> iter 70000, loss: 13.033644
   Number of active neurons: 10
 >> iter 71000, loss: 13.003089
 >> iter 72000, loss: 13.032431
 >> iter 73000, loss: 13.001658
 >> iter 74000, loss: 13.030818
 >> iter 75000, loss: 12.995447
 >> iter 76000, loss: 13.030666
 >> iter 77000, loss: 13.006069
 >> iter 78000, loss: 13.030525
 >> iter 79000, loss: 12.997803
 >> iter 80000, loss: 13.028215
   Number of active neurons: 10
 >> iter 81000, loss: 13.000713
 >> iter 82000, loss: 13.026045
 >> iter 83000, loss: 12.995430
 >> iter 84000, loss: 13.029456
 >> iter 85000, loss: 13.002698
 >> iter 86000, loss: 13.024840
 >> iter 87000, loss: 12.999945
 >> iter 88000, loss: 13.026301
 >> iter 89000, loss: 13.002411
 >> iter 90000, loss: 13.027493
   Number of active neurons: 10
 >> iter 91000, loss: 13.004507
 >> iter 92000, loss: 13.030194
 >> iter 93000, loss: 12.998382
 >> iter 94000, loss: 13.026139
 >> iter 95000, loss: 12.995751
 >> iter 96000, loss: 13.019125
 >> iter 97000, loss: 12.996835
 >> iter 98000, loss: 13.028025
 >> iter 99000, loss: 12.998971
 >> iter 100000, loss: 13.023641
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 27.7494450111
   - Test - Long: 32.7683615819
   - Test - Big: 28.0257197428
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455160
   Number of active neurons: 0
 >> iter 1000, loss: 19.169984
 >> iter 2000, loss: 15.621212
 >> iter 3000, loss: 14.121390
 >> iter 4000, loss: 13.514989
 >> iter 5000, loss: 13.257134
 >> iter 6000, loss: 13.164452
 >> iter 7000, loss: 13.108273
 >> iter 8000, loss: 13.084834
 >> iter 9000, loss: 13.064541
 >> iter 10000, loss: 13.044710
   Number of active neurons: 10
 >> iter 11000, loss: 13.027701
 >> iter 12000, loss: 13.037381
 >> iter 13000, loss: 13.017508
 >> iter 14000, loss: 13.030939
 >> iter 15000, loss: 13.011718
 >> iter 16000, loss: 13.017219
 >> iter 17000, loss: 13.002634
 >> iter 18000, loss: 13.006736
 >> iter 19000, loss: 12.996504
 >> iter 20000, loss: 13.011422
   Number of active neurons: 10
 >> iter 21000, loss: 12.997450
 >> iter 22000, loss: 13.016113
 >> iter 23000, loss: 12.993559
 >> iter 24000, loss: 13.007330
 >> iter 25000, loss: 12.991053
 >> iter 26000, loss: 13.002481
 >> iter 27000, loss: 12.988210
 >> iter 28000, loss: 13.006308
 >> iter 29000, loss: 12.993405
 >> iter 30000, loss: 13.005134
   Number of active neurons: 10
 >> iter 31000, loss: 12.991815
 >> iter 32000, loss: 12.989365
 >> iter 33000, loss: 12.987740
 >> iter 34000, loss: 13.004011
 >> iter 35000, loss: 12.990826
 >> iter 36000, loss: 12.999340
 >> iter 37000, loss: 12.992512
 >> iter 38000, loss: 13.010256
 >> iter 39000, loss: 12.991062
 >> iter 40000, loss: 13.009387
   Number of active neurons: 10
 >> iter 41000, loss: 12.990347
 >> iter 42000, loss: 13.007067
 >> iter 43000, loss: 12.986554
 >> iter 44000, loss: 13.009989
 >> iter 45000, loss: 12.981787
 >> iter 46000, loss: 13.003352
 >> iter 47000, loss: 12.987565
 >> iter 48000, loss: 13.008864
 >> iter 49000, loss: 12.984478
 >> iter 50000, loss: 13.014055
   Number of active neurons: 10
 >> iter 51000, loss: 12.983491
 >> iter 52000, loss: 13.007937
 >> iter 53000, loss: 12.977894
 >> iter 54000, loss: 13.011736
 >> iter 55000, loss: 12.979023
 >> iter 56000, loss: 13.003418
 >> iter 57000, loss: 12.981406
 >> iter 58000, loss: 13.004027
 >> iter 59000, loss: 12.977227
 >> iter 60000, loss: 13.002079
   Number of active neurons: 10
 >> iter 61000, loss: 12.978938
 >> iter 62000, loss: 13.014122
 >> iter 63000, loss: 12.985050
 >> iter 64000, loss: 13.006002
 >> iter 65000, loss: 12.982258
 >> iter 66000, loss: 13.003442
 >> iter 67000, loss: 12.972399
 >> iter 68000, loss: 12.953298
 >> iter 69000, loss: 12.869657
 >> iter 70000, loss: 12.775788
   Number of active neurons: 10
 >> iter 71000, loss: 12.602478
 >> iter 72000, loss: 12.477295
 >> iter 73000, loss: 12.264655
 >> iter 74000, loss: 12.104897
 >> iter 75000, loss: 11.759591
 >> iter 76000, loss: 11.458740
 >> iter 77000, loss: 11.160244
 >> iter 78000, loss: 11.054688
 >> iter 79000, loss: 10.879770
 >> iter 80000, loss: 10.882833
   Number of active neurons: 10
 >> iter 81000, loss: 10.791338
 >> iter 82000, loss: 10.788603
 >> iter 83000, loss: 10.690592
 >> iter 84000, loss: 10.713549
 >> iter 85000, loss: 10.642342
 >> iter 86000, loss: 10.723275
 >> iter 87000, loss: 10.590598
 >> iter 88000, loss: 10.626042
 >> iter 89000, loss: 10.539852
 >> iter 90000, loss: 10.626636
   Number of active neurons: 10
 >> iter 91000, loss: 10.504700
 >> iter 92000, loss: 10.553247
 >> iter 93000, loss: 10.469855
 >> iter 94000, loss: 10.539345
 >> iter 95000, loss: 10.445363
 >> iter 96000, loss: 10.501603
 >> iter 97000, loss: 10.429504
 >> iter 98000, loss: 10.475873
 >> iter 99000, loss: 10.446305
 >> iter 100000, loss: 10.404777
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 20.8695826083
   - Test - Long: 31.8584070796
   - Test - Big: 20.9937900621
   - Test - A: 31.4245716952
   - Test - B: 30.7646156923
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.158571
 >> iter 2000, loss: 15.597935
 >> iter 3000, loss: 14.095583
 >> iter 4000, loss: 13.501896
 >> iter 5000, loss: 13.275332
 >> iter 6000, loss: 13.173149
 >> iter 7000, loss: 13.121917
 >> iter 8000, loss: 13.105511
 >> iter 9000, loss: 13.078646
 >> iter 10000, loss: 13.083763
   Number of active neurons: 10
 >> iter 11000, loss: 13.054341
 >> iter 12000, loss: 13.056753
 >> iter 13000, loss: 13.039190
 >> iter 14000, loss: 13.054627
 >> iter 15000, loss: 13.045956
 >> iter 16000, loss: 13.050228
 >> iter 17000, loss: 13.039093
 >> iter 18000, loss: 13.034803
 >> iter 19000, loss: 13.034060
 >> iter 20000, loss: 13.033890
   Number of active neurons: 10
 >> iter 21000, loss: 13.022788
 >> iter 22000, loss: 13.035577
 >> iter 23000, loss: 13.018102
 >> iter 24000, loss: 13.035368
 >> iter 25000, loss: 13.021132
 >> iter 26000, loss: 13.028757
 >> iter 27000, loss: 13.019303
 >> iter 28000, loss: 13.030258
 >> iter 29000, loss: 13.013122
 >> iter 30000, loss: 13.027170
   Number of active neurons: 10
 >> iter 31000, loss: 13.013941
 >> iter 32000, loss: 13.019064
 >> iter 33000, loss: 13.006979
 >> iter 34000, loss: 13.028055
 >> iter 35000, loss: 13.018660
 >> iter 36000, loss: 13.007108
 >> iter 37000, loss: 12.996339
 >> iter 38000, loss: 13.017235
 >> iter 39000, loss: 12.999166
 >> iter 40000, loss: 13.013645
   Number of active neurons: 10
 >> iter 41000, loss: 12.995614
 >> iter 42000, loss: 13.010107
 >> iter 43000, loss: 12.989704
 >> iter 44000, loss: 13.000909
 >> iter 45000, loss: 12.983334
 >> iter 46000, loss: 12.992464
 >> iter 47000, loss: 12.954391
 >> iter 48000, loss: 12.939084
 >> iter 49000, loss: 12.896791
 >> iter 50000, loss: 12.855445
   Number of active neurons: 10
 >> iter 51000, loss: 12.785562
 >> iter 52000, loss: 12.717367
 >> iter 53000, loss: 12.328572
 >> iter 54000, loss: 11.915290
 >> iter 55000, loss: 11.591061
 >> iter 56000, loss: 11.488469
 >> iter 57000, loss: 11.312816
 >> iter 58000, loss: 11.329726
 >> iter 59000, loss: 11.214275
 >> iter 60000, loss: 11.229907
   Number of active neurons: 10
 >> iter 61000, loss: 11.093330
 >> iter 62000, loss: 11.076252
 >> iter 63000, loss: 10.930054
 >> iter 64000, loss: 10.929225
 >> iter 65000, loss: 10.657665
 >> iter 66000, loss: 10.517768
 >> iter 67000, loss: 10.218118
 >> iter 68000, loss: 10.049076
 >> iter 69000, loss: 9.803841
 >> iter 70000, loss: 9.790615
   Number of active neurons: 10
 >> iter 71000, loss: 9.608243
 >> iter 72000, loss: 9.593563
 >> iter 73000, loss: 9.399097
 >> iter 74000, loss: 9.427615
 >> iter 75000, loss: 9.255138
 >> iter 76000, loss: 9.310935
 >> iter 77000, loss: 9.187003
 >> iter 78000, loss: 9.291481
 >> iter 79000, loss: 9.148638
 >> iter 80000, loss: 9.214530
   Number of active neurons: 10
 >> iter 81000, loss: 9.173376
 >> iter 82000, loss: 9.190113
 >> iter 83000, loss: 9.075806
 >> iter 84000, loss: 9.144105
 >> iter 85000, loss: 9.051201
 >> iter 86000, loss: 9.108423
 >> iter 87000, loss: 9.030391
 >> iter 88000, loss: 9.135989
 >> iter 89000, loss: 9.045074
 >> iter 90000, loss: 9.147732
   Number of active neurons: 10
 >> iter 91000, loss: 9.016043
 >> iter 92000, loss: 9.117372
 >> iter 93000, loss: 9.027495
 >> iter 94000, loss: 9.085118
 >> iter 95000, loss: 9.038057
 >> iter 96000, loss: 9.105379
 >> iter 97000, loss: 8.998329
 >> iter 98000, loss: 9.084889
 >> iter 99000, loss: 9.016252
 >> iter 100000, loss: 9.123754
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 18.5476290474
   - Test - Long: 31.5334233288
   - Test - Big: 18.5628143719
   - Test - A: 30.3579761349
   - Test - B: 31.6445570295
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.166568
 >> iter 2000, loss: 15.624402
 >> iter 3000, loss: 14.141008
 >> iter 4000, loss: 13.526927
 >> iter 5000, loss: 13.260242
 >> iter 6000, loss: 13.159094
 >> iter 7000, loss: 13.094590
 >> iter 8000, loss: 13.079949
 >> iter 9000, loss: 13.051240
 >> iter 10000, loss: 13.040437
   Number of active neurons: 8
 >> iter 11000, loss: 13.022121
 >> iter 12000, loss: 13.028378
 >> iter 13000, loss: 12.998760
 >> iter 14000, loss: 13.017952
 >> iter 15000, loss: 13.016245
 >> iter 16000, loss: 13.016251
 >> iter 17000, loss: 13.006426
 >> iter 18000, loss: 13.012788
 >> iter 19000, loss: 12.998538
 >> iter 20000, loss: 13.006582
   Number of active neurons: 9
 >> iter 21000, loss: 12.992884
 >> iter 22000, loss: 13.011914
 >> iter 23000, loss: 12.988084
 >> iter 24000, loss: 13.004908
 >> iter 25000, loss: 12.986162
 >> iter 26000, loss: 12.993614
 >> iter 27000, loss: 12.978872
 >> iter 28000, loss: 12.987193
 >> iter 29000, loss: 12.977176
 >> iter 30000, loss: 12.992179
   Number of active neurons: 8
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 8
 >> iter 31000, loss: 12.981519
 >> iter 32000, loss: 12.997527
 >> iter 33000, loss: 12.983905
 >> iter 34000, loss: 12.987546
 >> iter 35000, loss: 12.976717
 >> iter 36000, loss: 12.978725
 >> iter 37000, loss: 12.972848
 >> iter 38000, loss: 12.973128
 >> iter 39000, loss: 12.955013
 >> iter 40000, loss: 12.925630
   Number of active neurons: 10
 >> iter 41000, loss: 12.893708
 >> iter 42000, loss: 12.875593
 >> iter 43000, loss: 12.831950
 >> iter 44000, loss: 12.794142
 >> iter 45000, loss: 12.717851
 >> iter 46000, loss: 12.485558
 >> iter 47000, loss: 11.909754
 >> iter 48000, loss: 11.573974
 >> iter 49000, loss: 11.272961
 >> iter 50000, loss: 11.140350
   Number of active neurons: 10
 >> iter 51000, loss: 10.888188
 >> iter 52000, loss: 10.871954
 >> iter 53000, loss: 10.596403
 >> iter 54000, loss: 10.392908
 >> iter 55000, loss: 10.057670
 >> iter 56000, loss: 9.936733
 >> iter 57000, loss: 9.876966
 >> iter 58000, loss: 9.619609
 >> iter 59000, loss: 9.290387
 >> iter 60000, loss: 9.228188
   Number of active neurons: 10
 >> iter 61000, loss: 8.716748
 >> iter 62000, loss: 8.498742
 >> iter 63000, loss: 8.147477
 >> iter 64000, loss: 8.011779
 >> iter 65000, loss: 7.810435
 >> iter 66000, loss: 7.507934
 >> iter 67000, loss: 7.359917
 >> iter 68000, loss: 7.135346
 >> iter 69000, loss: 6.899127
 >> iter 70000, loss: 6.391320
   Number of active neurons: 10
 >> iter 71000, loss: 5.147505
 >> iter 72000, loss: 3.889311
 >> iter 73000, loss: 3.219480
 >> iter 74000, loss: 2.720089
 >> iter 75000, loss: 2.148272
 >> iter 76000, loss: 1.780901
 >> iter 77000, loss: 1.836984
 >> iter 78000, loss: 1.594685
 >> iter 79000, loss: 1.490757
 >> iter 80000, loss: 1.214271
   Number of active neurons: 10
 >> iter 81000, loss: 1.308172
 >> iter 82000, loss: 0.722482
 >> iter 83000, loss: 0.980231
 >> iter 84000, loss: 1.349693
 >> iter 85000, loss: 1.189716
 >> iter 86000, loss: 0.946529
 >> iter 87000, loss: 0.767180
 >> iter 88000, loss: 0.720313
 >> iter 89000, loss: 0.788561
 >> iter 90000, loss: 0.779202
   Number of active neurons: 10
 >> iter 91000, loss: 0.663928
 >> iter 92000, loss: 0.919959
 >> iter 93000, loss: 0.748238
 >> iter 94000, loss: 0.538463
 >> iter 95000, loss: 0.676116
 >> iter 96000, loss: 0.574023
 >> iter 97000, loss: 0.910074
 >> iter 98000, loss: 0.869842
 >> iter 99000, loss: 0.779421
 >> iter 100000, loss: 0.895704
   Number of active neurons: 10
 >> iter 101000, loss: 0.898608
 >> iter 102000, loss: 0.747676
 >> iter 103000, loss: 0.774943
 >> iter 104000, loss: 0.834954
 >> iter 105000, loss: 0.834136
 >> iter 106000, loss: 0.603212
 >> iter 107000, loss: 0.525371
 >> iter 108000, loss: 0.476725
 >> iter 109000, loss: 0.392602
 >> iter 110000, loss: 0.366605
   Number of active neurons: 10
 >> iter 111000, loss: 0.508805
 >> iter 112000, loss: 0.475823
 >> iter 113000, loss: 0.452831
 >> iter 114000, loss: 0.429870
 >> iter 115000, loss: 0.296962
 >> iter 116000, loss: 0.745507
 >> iter 117000, loss: 0.598680
 >> iter 118000, loss: 0.571211
 >> iter 119000, loss: 0.340100
 >> iter 120000, loss: 0.219966
   Number of active neurons: 10
 >> iter 121000, loss: 0.279378
 >> iter 122000, loss: 0.295818
 >> iter 123000, loss: 0.315463
 >> iter 124000, loss: 0.310025
 >> iter 125000, loss: 0.293118
 >> iter 126000, loss: 0.256392
 >> iter 127000, loss: 0.537568
 >> iter 128000, loss: 0.342607
 >> iter 129000, loss: 0.380112
 >> iter 130000, loss: 0.281588
   Number of active neurons: 10
 >> iter 131000, loss: 0.221121
 >> iter 132000, loss: 0.282838
 >> iter 133000, loss: 0.348382
 >> iter 134000, loss: 0.230078
 >> iter 135000, loss: 0.278781
 >> iter 136000, loss: 0.221234
 >> iter 137000, loss: 0.501041
 >> iter 138000, loss: 0.342201
 >> iter 139000, loss: 0.279025
 >> iter 140000, loss: 0.283990
   Number of active neurons: 10
 >> iter 141000, loss: 0.275317
 >> iter 142000, loss: 0.152472
 >> iter 143000, loss: 0.358879
 >> iter 144000, loss: 0.270092
 >> iter 145000, loss: 0.249535
 >> iter 146000, loss: 0.255044
 >> iter 147000, loss: 0.319155
 >> iter 148000, loss: 0.464076
 >> iter 149000, loss: 0.278464
 >> iter 150000, loss: 0.200457
   Number of active neurons: 10
 >> iter 151000, loss: 0.114956
 >> iter 152000, loss: 0.216922
 >> iter 153000, loss: 0.140518
 >> iter 154000, loss: 0.606271
 >> iter 155000, loss: 0.355921
 >> iter 156000, loss: 0.254536
 >> iter 157000, loss: 0.273724
 >> iter 158000, loss: 0.323282
 >> iter 159000, loss: 0.162734
 >> iter 160000, loss: 0.093137
   Number of active neurons: 10
 >> iter 161000, loss: 0.061065
 >> iter 162000, loss: 0.145980
 >> iter 163000, loss: 0.125336
 >> iter 164000, loss: 0.114346
 >> iter 165000, loss: 0.368854
 >> iter 166000, loss: 0.219244
 >> iter 167000, loss: 0.288813
 >> iter 168000, loss: 0.133553
 >> iter 169000, loss: 0.183679
 >> iter 170000, loss: 0.237813
   Number of active neurons: 10
 >> iter 171000, loss: 0.221038
 >> iter 172000, loss: 0.177964
 >> iter 173000, loss: 0.134497
 >> iter 174000, loss: 0.117110
 >> iter 175000, loss: 0.149793
 >> iter 176000, loss: 0.173289
 >> iter 177000, loss: 0.209612
 >> iter 178000, loss: 0.091160
 >> iter 179000, loss: 0.049568
 >> iter 180000, loss: 0.035587
   Number of active neurons: 10
 >> iter 181000, loss: 0.095408
 >> iter 182000, loss: 0.288993
 >> iter 183000, loss: 0.261264
 >> iter 184000, loss: 0.237033
 >> iter 185000, loss: 0.180707
 >> iter 186000, loss: 0.165255
 >> iter 187000, loss: 0.134530
 >> iter 188000, loss: 0.346599
 >> iter 189000, loss: 0.145071
 >> iter 190000, loss: 0.078414
   Number of active neurons: 10
 >> iter 191000, loss: 0.038985
 >> iter 192000, loss: 0.056000
 >> iter 193000, loss: 0.031187
 >> iter 194000, loss: 0.070604
 >> iter 195000, loss: 0.142503
 >> iter 196000, loss: 0.067529
 >> iter 197000, loss: 0.110637
 >> iter 198000, loss: 0.077744
 >> iter 199000, loss: 0.134912
 >> iter 200000, loss: 0.208326
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 19.112740
 >> iter 2000, loss: 15.632447
 >> iter 3000, loss: 14.127006
 >> iter 4000, loss: 13.522280
 >> iter 5000, loss: 13.248048
 >> iter 6000, loss: 13.147346
 >> iter 7000, loss: 13.113812
 >> iter 8000, loss: 13.088936
 >> iter 9000, loss: 13.057260
 >> iter 10000, loss: 13.054583
   Number of active neurons: 10
 >> iter 11000, loss: 13.037635
 >> iter 12000, loss: 13.046427
 >> iter 13000, loss: 13.027512
 >> iter 14000, loss: 13.031333
 >> iter 15000, loss: 13.023783
 >> iter 16000, loss: 13.042058
 >> iter 17000, loss: 13.035697
 >> iter 18000, loss: 13.039388
 >> iter 19000, loss: 13.027683
 >> iter 20000, loss: 13.027806
   Number of active neurons: 10
 >> iter 21000, loss: 13.013558
 >> iter 22000, loss: 13.022201
 >> iter 23000, loss: 13.009830
 >> iter 24000, loss: 13.011503
 >> iter 25000, loss: 12.996305
 >> iter 26000, loss: 13.010224
 >> iter 27000, loss: 12.995236
 >> iter 28000, loss: 13.008297
 >> iter 29000, loss: 12.985133
 >> iter 30000, loss: 12.995375
   Number of active neurons: 10
 >> iter 31000, loss: 12.975012
 >> iter 32000, loss: 12.997366
 >> iter 33000, loss: 12.981713
 >> iter 34000, loss: 12.999878
 >> iter 35000, loss: 12.983195
 >> iter 36000, loss: 12.997877
 >> iter 37000, loss: 12.983590
 >> iter 38000, loss: 12.992958
 >> iter 39000, loss: 12.975220
 >> iter 40000, loss: 12.990012
   Number of active neurons: 10
 >> iter 41000, loss: 12.973835
 >> iter 42000, loss: 12.989905
 >> iter 43000, loss: 12.969221
 >> iter 44000, loss: 12.995636
 >> iter 45000, loss: 12.971000
 >> iter 46000, loss: 12.998991
 >> iter 47000, loss: 12.967926
 >> iter 48000, loss: 12.998189
 >> iter 49000, loss: 12.969308
 >> iter 50000, loss: 12.999745
   Number of active neurons: 10
 >> iter 51000, loss: 12.966886
 >> iter 52000, loss: 12.990903
 >> iter 53000, loss: 12.965530
 >> iter 54000, loss: 12.991851
 >> iter 55000, loss: 12.963454
 >> iter 56000, loss: 12.995567
 >> iter 57000, loss: 12.966154
 >> iter 58000, loss: 12.998823
 >> iter 59000, loss: 12.961918
 >> iter 60000, loss: 12.991083
   Number of active neurons: 10
 >> iter 61000, loss: 12.964228
 >> iter 62000, loss: 12.993711
 >> iter 63000, loss: 12.970795
 >> iter 64000, loss: 12.998737
 >> iter 65000, loss: 12.969829
 >> iter 66000, loss: 12.994416
 >> iter 67000, loss: 12.971406
 >> iter 68000, loss: 12.991296
 >> iter 69000, loss: 12.972018
 >> iter 70000, loss: 12.996799
   Number of active neurons: 10
 >> iter 71000, loss: 12.970051
 >> iter 72000, loss: 12.993783
 >> iter 73000, loss: 12.966794
 >> iter 74000, loss: 12.998224
 >> iter 75000, loss: 12.968723
 >> iter 76000, loss: 12.995067
 >> iter 77000, loss: 12.973641
 >> iter 78000, loss: 12.992736
 >> iter 79000, loss: 12.967898
 >> iter 80000, loss: 12.992848
   Number of active neurons: 10
 >> iter 81000, loss: 12.964922
 >> iter 82000, loss: 12.994996
 >> iter 83000, loss: 12.969553
 >> iter 84000, loss: 12.996266
 >> iter 85000, loss: 12.970724
 >> iter 86000, loss: 12.993504
 >> iter 87000, loss: 12.973662
 >> iter 88000, loss: 13.000729
 >> iter 89000, loss: 12.971791
 >> iter 90000, loss: 13.006929
   Number of active neurons: 10
 >> iter 91000, loss: 12.975806
 >> iter 92000, loss: 12.999005
 >> iter 93000, loss: 12.973028
 >> iter 94000, loss: 12.996626
 >> iter 95000, loss: 12.973224
 >> iter 96000, loss: 12.995754
 >> iter 97000, loss: 12.973324
 >> iter 98000, loss: 12.997184
 >> iter 99000, loss: 12.972396
 >> iter 100000, loss: 12.997793
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 27.7494450111
   - Test - Long: 32.7683615819
   - Test - Big: 28.0257197428
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.196181
 >> iter 2000, loss: 15.597958
 >> iter 3000, loss: 14.113270
 >> iter 4000, loss: 13.518002
 >> iter 5000, loss: 13.270251
 >> iter 6000, loss: 13.156733
 >> iter 7000, loss: 13.116290
 >> iter 8000, loss: 13.098727
 >> iter 9000, loss: 13.081779
 >> iter 10000, loss: 13.086279
   Number of active neurons: 10
 >> iter 11000, loss: 13.057644
 >> iter 12000, loss: 13.052517
 >> iter 13000, loss: 13.039475
 >> iter 14000, loss: 13.042149
 >> iter 15000, loss: 13.035449
 >> iter 16000, loss: 13.042795
 >> iter 17000, loss: 13.025582
 >> iter 18000, loss: 13.034355
 >> iter 19000, loss: 13.028245
 >> iter 20000, loss: 13.034383
   Number of active neurons: 10
 >> iter 21000, loss: 13.014497
 >> iter 22000, loss: 13.025454
 >> iter 23000, loss: 13.018140
 >> iter 24000, loss: 13.037877
 >> iter 25000, loss: 13.020177
 >> iter 26000, loss: 13.029551
 >> iter 27000, loss: 13.014799
 >> iter 28000, loss: 13.031852
 >> iter 29000, loss: 13.019385
 >> iter 30000, loss: 13.023004
   Number of active neurons: 10
 >> iter 31000, loss: 13.016710
 >> iter 32000, loss: 13.035464
 >> iter 33000, loss: 13.016109
 >> iter 34000, loss: 13.028575
 >> iter 35000, loss: 13.018171
 >> iter 36000, loss: 13.023080
 >> iter 37000, loss: 13.012187
 >> iter 38000, loss: 13.023403
 >> iter 39000, loss: 13.010254
 >> iter 40000, loss: 13.023073
   Number of active neurons: 10
 >> iter 41000, loss: 13.007556
 >> iter 42000, loss: 13.027441
 >> iter 43000, loss: 13.002359
 >> iter 44000, loss: 13.022529
 >> iter 45000, loss: 13.002439
 >> iter 46000, loss: 13.023067
 >> iter 47000, loss: 13.001210
 >> iter 48000, loss: 13.019944
 >> iter 49000, loss: 12.996640
 >> iter 50000, loss: 13.017166
   Number of active neurons: 9
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 9
 >> iter 51000, loss: 12.993976
 >> iter 52000, loss: 13.016474
 >> iter 53000, loss: 12.994434
 >> iter 54000, loss: 13.019118
 >> iter 55000, loss: 12.991359
 >> iter 56000, loss: 13.014707
 >> iter 57000, loss: 12.992945
 >> iter 58000, loss: 13.016879
 >> iter 59000, loss: 12.988973
 >> iter 60000, loss: 13.009741
   Number of active neurons: 10
 >> iter 61000, loss: 12.988612
 >> iter 62000, loss: 13.015812
 >> iter 63000, loss: 12.990000
 >> iter 64000, loss: 13.013702
 >> iter 65000, loss: 12.992479
 >> iter 66000, loss: 13.010399
 >> iter 67000, loss: 12.981048
 >> iter 68000, loss: 12.989477
 >> iter 69000, loss: 12.962619
 >> iter 70000, loss: 12.957703
   Number of active neurons: 10
 >> iter 71000, loss: 12.898362
 >> iter 72000, loss: 12.874040
 >> iter 73000, loss: 12.792894
 >> iter 74000, loss: 12.719744
 >> iter 75000, loss: 12.633693
 >> iter 76000, loss: 12.603823
 >> iter 77000, loss: 12.562989
 >> iter 78000, loss: 12.365535
 >> iter 79000, loss: 11.761257
 >> iter 80000, loss: 11.448646
   Number of active neurons: 10
 >> iter 81000, loss: 11.177559
 >> iter 82000, loss: 11.118959
 >> iter 83000, loss: 10.942264
 >> iter 84000, loss: 11.003874
 >> iter 85000, loss: 10.886283
 >> iter 86000, loss: 10.890123
 >> iter 87000, loss: 10.787105
 >> iter 88000, loss: 10.802468
 >> iter 89000, loss: 10.650231
 >> iter 90000, loss: 10.692605
   Number of active neurons: 10
 >> iter 91000, loss: 10.576290
 >> iter 92000, loss: 10.587579
 >> iter 93000, loss: 10.431637
 >> iter 94000, loss: 10.467288
 >> iter 95000, loss: 10.333278
 >> iter 96000, loss: 10.368862
 >> iter 97000, loss: 10.252726
 >> iter 98000, loss: 10.269825
 >> iter 99000, loss: 10.151629
 >> iter 100000, loss: 10.251412
   Number of active neurons: 10
 >> iter 101000, loss: 10.173434
 >> iter 102000, loss: 10.192535
 >> iter 103000, loss: 10.137411
 >> iter 104000, loss: 10.185068
 >> iter 105000, loss: 10.232965
 >> iter 106000, loss: 10.278841
 >> iter 107000, loss: 10.130523
 >> iter 108000, loss: 10.152112
 >> iter 109000, loss: 10.048742
 >> iter 110000, loss: 10.210733
   Number of active neurons: 10
 >> iter 111000, loss: 10.020157
 >> iter 112000, loss: 10.073558
 >> iter 113000, loss: 10.033101
 >> iter 114000, loss: 10.127512
 >> iter 115000, loss: 9.993552
 >> iter 116000, loss: 10.138232
 >> iter 117000, loss: 10.031843
 >> iter 118000, loss: 10.147478
 >> iter 119000, loss: 9.973339
 >> iter 120000, loss: 10.081264
   Number of active neurons: 10
 >> iter 121000, loss: 9.939609
 >> iter 122000, loss: 10.058203
 >> iter 123000, loss: 10.005879
 >> iter 124000, loss: 10.127670
 >> iter 125000, loss: 9.922949
 >> iter 126000, loss: 10.099824
 >> iter 127000, loss: 9.924943
 >> iter 128000, loss: 10.033211
 >> iter 129000, loss: 9.875381
 >> iter 130000, loss: 10.040725
   Number of active neurons: 10
 >> iter 131000, loss: 9.880992
 >> iter 132000, loss: 9.974127
 >> iter 133000, loss: 9.849673
 >> iter 134000, loss: 9.921012
 >> iter 135000, loss: 9.874999
 >> iter 136000, loss: 10.030490
 >> iter 137000, loss: 9.876808
 >> iter 138000, loss: 10.022652
 >> iter 139000, loss: 9.826830
 >> iter 140000, loss: 10.000878
   Number of active neurons: 10
 >> iter 141000, loss: 9.884546
 >> iter 142000, loss: 9.965725
 >> iter 143000, loss: 9.837469
 >> iter 144000, loss: 9.977978
 >> iter 145000, loss: 9.789658
 >> iter 146000, loss: 9.928649
 >> iter 147000, loss: 9.820328
 >> iter 148000, loss: 9.931352
 >> iter 149000, loss: 9.749270
 >> iter 150000, loss: 9.878578
   Number of active neurons: 10
 >> iter 151000, loss: 9.637879
 >> iter 152000, loss: 9.804537
 >> iter 153000, loss: 9.756259
 >> iter 154000, loss: 9.876874
 >> iter 155000, loss: 9.735010
 >> iter 156000, loss: 9.849619
 >> iter 157000, loss: 9.751545
 >> iter 158000, loss: 9.813830
 >> iter 159000, loss: 9.687790
 >> iter 160000, loss: 9.939741
   Number of active neurons: 10
 >> iter 161000, loss: 9.735975
 >> iter 162000, loss: 9.904870
 >> iter 163000, loss: 9.713795
 >> iter 164000, loss: 9.885463
 >> iter 165000, loss: 9.703521
 >> iter 166000, loss: 9.727702
 >> iter 167000, loss: 9.593310
 >> iter 168000, loss: 9.711317
 >> iter 169000, loss: 9.584823
 >> iter 170000, loss: 9.643720
   Number of active neurons: 10
 >> iter 171000, loss: 9.533482
 >> iter 172000, loss: 9.643982
 >> iter 173000, loss: 9.398341
 >> iter 174000, loss: 9.531944
 >> iter 175000, loss: 9.369945
 >> iter 176000, loss: 9.527722
 >> iter 177000, loss: 9.465095
 >> iter 178000, loss: 9.525299
 >> iter 179000, loss: 9.412374
 >> iter 180000, loss: 9.623022
   Number of active neurons: 10
 >> iter 181000, loss: 9.429533
 >> iter 182000, loss: 9.459148
 >> iter 183000, loss: 9.444365
 >> iter 184000, loss: 9.577913
 >> iter 185000, loss: 9.390740
 >> iter 186000, loss: 9.452580
 >> iter 187000, loss: 9.296424
 >> iter 188000, loss: 9.496205
 >> iter 189000, loss: 9.271795
 >> iter 190000, loss: 9.342647
   Number of active neurons: 10
 >> iter 191000, loss: 9.235714
 >> iter 192000, loss: 9.405729
 >> iter 193000, loss: 9.277894
 >> iter 194000, loss: 9.350418
 >> iter 195000, loss: 9.173994
 >> iter 196000, loss: 9.273493
 >> iter 197000, loss: 9.164691
 >> iter 198000, loss: 9.329719
 >> iter 199000, loss: 9.132843
 >> iter 200000, loss: 9.253642
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 15.9276814464
   - Test - Long: 30.8734563272
   - Test - Big: 15.9448405516
   - Test - A: 10.9259382708
   - Test - B: 31.6245583628
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.160338
 >> iter 2000, loss: 15.648705
 >> iter 3000, loss: 14.126299
 >> iter 4000, loss: 13.519416
 >> iter 5000, loss: 13.278296
 >> iter 6000, loss: 13.170220
 >> iter 7000, loss: 13.107671
 >> iter 8000, loss: 13.097899
 >> iter 9000, loss: 13.067637
 >> iter 10000, loss: 13.066334
   Number of active neurons: 10
 >> iter 11000, loss: 13.056992
 >> iter 12000, loss: 13.060474
 >> iter 13000, loss: 13.043580
 >> iter 14000, loss: 13.051180
 >> iter 15000, loss: 13.035286
 >> iter 16000, loss: 13.037844
 >> iter 17000, loss: 13.035240
 >> iter 18000, loss: 13.036046
 >> iter 19000, loss: 13.026936
 >> iter 20000, loss: 13.039733
   Number of active neurons: 10
 >> iter 21000, loss: 13.020857
 >> iter 22000, loss: 13.031126
 >> iter 23000, loss: 13.015167
 >> iter 24000, loss: 13.028875
 >> iter 25000, loss: 13.006063
 >> iter 26000, loss: 13.027577
 >> iter 27000, loss: 13.014243
 >> iter 28000, loss: 13.027046
 >> iter 29000, loss: 13.016324
 >> iter 30000, loss: 13.019766
   Number of active neurons: 10
 >> iter 31000, loss: 13.017217
 >> iter 32000, loss: 13.027459
 >> iter 33000, loss: 13.016300
 >> iter 34000, loss: 13.030271
 >> iter 35000, loss: 13.007815
 >> iter 36000, loss: 13.018616
 >> iter 37000, loss: 13.006647
 >> iter 38000, loss: 13.023932
 >> iter 39000, loss: 13.006202
 >> iter 40000, loss: 13.026203
   Number of active neurons: 10
 >> iter 41000, loss: 13.006140
 >> iter 42000, loss: 13.023129
 >> iter 43000, loss: 13.007596
 >> iter 44000, loss: 13.026886
 >> iter 45000, loss: 13.004718
 >> iter 46000, loss: 13.019362
 >> iter 47000, loss: 12.996252
 >> iter 48000, loss: 13.029238
 >> iter 49000, loss: 13.000030
 >> iter 50000, loss: 13.030855
   Number of active neurons: 10
 >> iter 51000, loss: 13.008801
 >> iter 52000, loss: 13.028323
 >> iter 53000, loss: 12.995038
 >> iter 54000, loss: 13.022540
 >> iter 55000, loss: 12.992574
 >> iter 56000, loss: 13.021324
 >> iter 57000, loss: 12.989298
 >> iter 58000, loss: 13.021939
 >> iter 59000, loss: 13.003875
 >> iter 60000, loss: 13.037589
   Number of active neurons: 10
 >> iter 61000, loss: 13.010945
 >> iter 62000, loss: 13.030006
 >> iter 63000, loss: 13.003334
 >> iter 64000, loss: 13.027094
 >> iter 65000, loss: 13.010256
 >> iter 66000, loss: 13.022649
 >> iter 67000, loss: 12.999539
 >> iter 68000, loss: 13.029429
 >> iter 69000, loss: 13.006541
 >> iter 70000, loss: 13.033054
   Number of active neurons: 10
 >> iter 71000, loss: 13.005003
 >> iter 72000, loss: 13.021092
 >> iter 73000, loss: 12.998727
 >> iter 74000, loss: 13.032379
 >> iter 75000, loss: 13.000044
 >> iter 76000, loss: 13.022603
 >> iter 77000, loss: 13.003758
 >> iter 78000, loss: 13.027327
 >> iter 79000, loss: 13.002996
 >> iter 80000, loss: 13.029491
   Number of active neurons: 10
 >> iter 81000, loss: 13.001214
 >> iter 82000, loss: 13.027768
 >> iter 83000, loss: 13.004760
 >> iter 84000, loss: 13.038282
 >> iter 85000, loss: 13.009004
 >> iter 86000, loss: 13.032638
 >> iter 87000, loss: 13.004539
 >> iter 88000, loss: 13.029720
 >> iter 89000, loss: 13.001055
 >> iter 90000, loss: 13.040157
   Number of active neurons: 10
 >> iter 91000, loss: 13.013505
 >> iter 92000, loss: 13.037494
 >> iter 93000, loss: 13.007905
 >> iter 94000, loss: 13.037596
 >> iter 95000, loss: 13.014928
 >> iter 96000, loss: 13.040140
 >> iter 97000, loss: 13.005491
 >> iter 98000, loss: 13.037119
 >> iter 99000, loss: 13.010938
 >> iter 100000, loss: 13.039040
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 27.7494450111
   - Test - Long: 32.7683615819
   - Test - Big: 28.0257197428
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.164171
 >> iter 2000, loss: 15.637615
 >> iter 3000, loss: 14.150389
 >> iter 4000, loss: 13.547380
 >> iter 5000, loss: 13.286567
 >> iter 6000, loss: 13.208662
 >> iter 7000, loss: 13.145443
 >> iter 8000, loss: 13.131106
 >> iter 9000, loss: 13.099466
 >> iter 10000, loss: 13.093899
   Number of active neurons: 10
 >> iter 11000, loss: 13.076641
 >> iter 12000, loss: 13.072745
 >> iter 13000, loss: 13.064192
 >> iter 14000, loss: 13.066750
 >> iter 15000, loss: 13.057789
 >> iter 16000, loss: 13.063262
 >> iter 17000, loss: 13.048163
 >> iter 18000, loss: 13.059238
 >> iter 19000, loss: 13.040376
 >> iter 20000, loss: 13.052797
   Number of active neurons: 10
 >> iter 21000, loss: 13.044754
 >> iter 22000, loss: 13.054619
 >> iter 23000, loss: 13.019885
 >> iter 24000, loss: 13.041957
 >> iter 25000, loss: 13.029989
 >> iter 26000, loss: 13.045208
 >> iter 27000, loss: 13.024836
 >> iter 28000, loss: 13.040096
 >> iter 29000, loss: 13.025408
 >> iter 30000, loss: 13.039391
   Number of active neurons: 10
 >> iter 31000, loss: 13.019604
 >> iter 32000, loss: 13.035523
 >> iter 33000, loss: 13.025161
 >> iter 34000, loss: 13.027318
 >> iter 35000, loss: 13.014107
 >> iter 36000, loss: 13.027914
 >> iter 37000, loss: 13.012155
 >> iter 38000, loss: 13.032238
 >> iter 39000, loss: 13.015221
 >> iter 40000, loss: 13.037574
   Number of active neurons: 10
 >> iter 41000, loss: 13.012256
 >> iter 42000, loss: 13.017773
 >> iter 43000, loss: 13.003407
 >> iter 44000, loss: 13.030660
 >> iter 45000, loss: 13.010937
 >> iter 46000, loss: 13.029179
 >> iter 47000, loss: 13.006386
 >> iter 48000, loss: 13.032827
 >> iter 49000, loss: 13.008863
 >> iter 50000, loss: 13.033911
   Number of active neurons: 10
 >> iter 51000, loss: 13.008302
 >> iter 52000, loss: 13.032047
 >> iter 53000, loss: 13.000926
 >> iter 54000, loss: 13.028677
 >> iter 55000, loss: 12.999283
 >> iter 56000, loss: 13.026581
 >> iter 57000, loss: 13.005098
 >> iter 58000, loss: 13.029465
 >> iter 59000, loss: 13.005565
 >> iter 60000, loss: 13.028316
   Number of active neurons: 10
 >> iter 61000, loss: 13.000742
 >> iter 62000, loss: 13.025360
 >> iter 63000, loss: 13.005595
 >> iter 64000, loss: 13.023390
 >> iter 65000, loss: 13.000713
 >> iter 66000, loss: 13.025177
 >> iter 67000, loss: 13.000782
 >> iter 68000, loss: 13.022082
 >> iter 69000, loss: 13.001602
 >> iter 70000, loss: 13.033170
   Number of active neurons: 10
 >> iter 71000, loss: 13.003158
 >> iter 72000, loss: 13.031193
 >> iter 73000, loss: 12.999915
 >> iter 74000, loss: 13.028660
 >> iter 75000, loss: 13.005464
 >> iter 76000, loss: 13.033742
 >> iter 77000, loss: 13.008608
 >> iter 78000, loss: 13.033027
 >> iter 79000, loss: 12.999851
 >> iter 80000, loss: 13.026020
   Number of active neurons: 10
 >> iter 81000, loss: 13.000363
 >> iter 82000, loss: 13.030036
 >> iter 83000, loss: 13.001856
 >> iter 84000, loss: 13.029250
 >> iter 85000, loss: 13.003646
 >> iter 86000, loss: 13.027640
 >> iter 87000, loss: 13.004724
 >> iter 88000, loss: 13.034426
 >> iter 89000, loss: 13.003685
 >> iter 90000, loss: 13.033868
   Number of active neurons: 10
 >> iter 91000, loss: 13.005204
 >> iter 92000, loss: 13.031116
 >> iter 93000, loss: 13.009976
 >> iter 94000, loss: 13.035416
 >> iter 95000, loss: 13.011258
 >> iter 96000, loss: 13.036885
 >> iter 97000, loss: 13.010126
 >> iter 98000, loss: 13.039591
 >> iter 99000, loss: 13.009875
 >> iter 100000, loss: 13.034569
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 27.7494450111
   - Test - Long: 32.7683615819
   - Test - Big: 28.0257197428
   - Test - A: 33.6844210386
   - Test - B: 33.5644290381
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.134773
 >> iter 2000, loss: 15.624486
 >> iter 3000, loss: 14.139419
 >> iter 4000, loss: 13.562978
 >> iter 5000, loss: 13.299897
 >> iter 6000, loss: 13.190573
 >> iter 7000, loss: 13.121852
 >> iter 8000, loss: 13.094197
 >> iter 9000, loss: 13.079891
 >> iter 10000, loss: 13.070028
   Number of active neurons: 10
 >> iter 11000, loss: 13.053338
 >> iter 12000, loss: 13.050395
 >> iter 13000, loss: 13.037029
 >> iter 14000, loss: 13.047506
 >> iter 15000, loss: 13.039713
 >> iter 16000, loss: 13.046425
 >> iter 17000, loss: 13.027028
 >> iter 18000, loss: 13.036070
 >> iter 19000, loss: 13.032292
 >> iter 20000, loss: 13.042327
   Number of active neurons: 10
 >> iter 21000, loss: 13.019735
 >> iter 22000, loss: 13.039272
 >> iter 23000, loss: 13.021356
 >> iter 24000, loss: 13.047677
 >> iter 25000, loss: 13.026243
 >> iter 26000, loss: 13.032088
 >> iter 27000, loss: 13.016645
 >> iter 28000, loss: 13.029249
 >> iter 29000, loss: 13.017952
 >> iter 30000, loss: 13.032000
   Number of active neurons: 10
 >> iter 31000, loss: 13.016742
 >> iter 32000, loss: 13.034338
 >> iter 33000, loss: 13.017032
 >> iter 34000, loss: 13.029605
 >> iter 35000, loss: 13.020588
 >> iter 36000, loss: 13.020987
 >> iter 37000, loss: 13.014070
 >> iter 38000, loss: 13.017144
 >> iter 39000, loss: 12.998624
 >> iter 40000, loss: 13.009034
   Number of active neurons: 10
 >> iter 41000, loss: 12.981681
 >> iter 42000, loss: 12.973697
 >> iter 43000, loss: 12.938528
 >> iter 44000, loss: 12.919340
 >> iter 45000, loss: 12.886326
 >> iter 46000, loss: 12.847872
 >> iter 47000, loss: 12.802632
 >> iter 48000, loss: 12.734900
 >> iter 49000, loss: 12.621005
 >> iter 50000, loss: 12.401213
   Number of active neurons: 10
 >> iter 51000, loss: 11.977050
 >> iter 52000, loss: 11.637598
 >> iter 53000, loss: 11.331982
 >> iter 54000, loss: 11.212178
 >> iter 55000, loss: 10.990928
 >> iter 56000, loss: 10.923206
 >> iter 57000, loss: 10.767098
 >> iter 58000, loss: 10.770034
 >> iter 59000, loss: 10.641876
 >> iter 60000, loss: 10.634822
   Number of active neurons: 10
 >> iter 61000, loss: 10.471191
 >> iter 62000, loss: 10.435087
 >> iter 63000, loss: 10.221004
 >> iter 64000, loss: 10.202900
 >> iter 65000, loss: 10.008090
 >> iter 66000, loss: 10.020711
 >> iter 67000, loss: 9.779168
 >> iter 68000, loss: 9.795216
 >> iter 69000, loss: 9.503982
 >> iter 70000, loss: 9.379629
   Number of active neurons: 10
 >> iter 71000, loss: 9.158774
 >> iter 72000, loss: 9.135682
 >> iter 73000, loss: 8.951910
 >> iter 74000, loss: 9.017380
 >> iter 75000, loss: 8.895562
 >> iter 76000, loss: 8.926379
 >> iter 77000, loss: 8.823410
 >> iter 78000, loss: 8.902056
 >> iter 79000, loss: 8.796968
 >> iter 80000, loss: 8.904371
   Number of active neurons: 10
 >> iter 81000, loss: 8.790558
 >> iter 82000, loss: 8.794706
 >> iter 83000, loss: 8.767424
 >> iter 84000, loss: 8.819725
 >> iter 85000, loss: 8.689577
 >> iter 86000, loss: 8.804127
 >> iter 87000, loss: 8.689564
 >> iter 88000, loss: 8.858825
 >> iter 89000, loss: 8.718595
 >> iter 90000, loss: 8.842709
   Number of active neurons: 10
 >> iter 91000, loss: 8.705652
 >> iter 92000, loss: 8.742895
 >> iter 93000, loss: 8.661097
 >> iter 94000, loss: 8.732332
 >> iter 95000, loss: 8.684069
 >> iter 96000, loss: 8.717819
 >> iter 97000, loss: 8.646134
 >> iter 98000, loss: 8.746145
 >> iter 99000, loss: 8.641805
 >> iter 100000, loss: 8.680892
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 17.8416431671
   - Test - Long: 31.4084295785
   - Test - Big: 17.8448215518
   - Test - A: 15.4789680688
   - Test - B: 31.6445570295
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455163
   Number of active neurons: 0
 >> iter 1000, loss: 19.077608
 >> iter 2000, loss: 15.568219
 >> iter 3000, loss: 14.075274
 >> iter 4000, loss: 13.491800
 >> iter 5000, loss: 13.231690
 >> iter 6000, loss: 13.129205
 >> iter 7000, loss: 13.083191
 >> iter 8000, loss: 13.067959
 >> iter 9000, loss: 13.050966
 >> iter 10000, loss: 13.066707
   Number of active neurons: 10
 >> iter 11000, loss: 13.032887
 >> iter 12000, loss: 13.041741
 >> iter 13000, loss: 13.026627
 >> iter 14000, loss: 13.029578
 >> iter 15000, loss: 13.021579
 >> iter 16000, loss: 13.027676
 >> iter 17000, loss: 13.014708
 >> iter 18000, loss: 13.029525
 >> iter 19000, loss: 13.013520
 >> iter 20000, loss: 13.024336
   Number of active neurons: 10
 >> iter 21000, loss: 13.003553
 >> iter 22000, loss: 13.013988
 >> iter 23000, loss: 13.002440
 >> iter 24000, loss: 13.004349
 >> iter 25000, loss: 12.989531
 >> iter 26000, loss: 13.008837
 >> iter 27000, loss: 12.993627
 >> iter 28000, loss: 13.007040
 >> iter 29000, loss: 12.994279
 >> iter 30000, loss: 12.998252
   Number of active neurons: 10
 >> iter 31000, loss: 12.972595
 >> iter 32000, loss: 12.979923
 >> iter 33000, loss: 12.932950
 >> iter 34000, loss: 12.894401
 >> iter 35000, loss: 12.832247
 >> iter 36000, loss: 12.768787
 >> iter 37000, loss: 12.348997
 >> iter 38000, loss: 11.758238
 >> iter 39000, loss: 11.267057
 >> iter 40000, loss: 11.066851
   Number of active neurons: 10
 >> iter 41000, loss: 10.784194
 >> iter 42000, loss: 10.636236
 >> iter 43000, loss: 10.383656
 >> iter 44000, loss: 10.292637
 >> iter 45000, loss: 10.072780
 >> iter 46000, loss: 10.079246
 >> iter 47000, loss: 9.893534
 >> iter 48000, loss: 9.820915
 >> iter 49000, loss: 9.586901
 >> iter 50000, loss: 9.541540
   Number of active neurons: 10
 >> iter 51000, loss: 9.368671
 >> iter 52000, loss: 9.407941
 >> iter 53000, loss: 9.293393
 >> iter 54000, loss: 9.418981
 >> iter 55000, loss: 9.264239
 >> iter 56000, loss: 9.316464
 >> iter 57000, loss: 9.157586
 >> iter 58000, loss: 9.194358
 >> iter 59000, loss: 9.080425
 >> iter 60000, loss: 9.136001
   Number of active neurons: 10
 >> iter 61000, loss: 9.109805
 >> iter 62000, loss: 9.208359
 >> iter 63000, loss: 9.109334
 >> iter 64000, loss: 9.183323
 >> iter 65000, loss: 9.078779
 >> iter 66000, loss: 9.106459
 >> iter 67000, loss: 8.983803
 >> iter 68000, loss: 9.100158
 >> iter 69000, loss: 8.888861
 >> iter 70000, loss: 9.056340
   Number of active neurons: 10
 >> iter 71000, loss: 8.853645
 >> iter 72000, loss: 8.922600
 >> iter 73000, loss: 8.855216
 >> iter 74000, loss: 8.869684
 >> iter 75000, loss: 8.713516
 >> iter 76000, loss: 8.775463
 >> iter 77000, loss: 8.713144
 >> iter 78000, loss: 8.802551
 >> iter 79000, loss: 8.670112
 >> iter 80000, loss: 8.910867
   Number of active neurons: 10
 >> iter 81000, loss: 8.634578
 >> iter 82000, loss: 8.699122
 >> iter 83000, loss: 8.553240
 >> iter 84000, loss: 8.661187
 >> iter 85000, loss: 8.598438
 >> iter 86000, loss: 8.545560
 >> iter 87000, loss: 8.482522
 >> iter 88000, loss: 8.627732
 >> iter 89000, loss: 8.465905
 >> iter 90000, loss: 8.433642
   Number of active neurons: 10
 >> iter 91000, loss: 8.374989
 >> iter 92000, loss: 8.430734
 >> iter 93000, loss: 8.421383
 >> iter 94000, loss: 8.356912
 >> iter 95000, loss: 8.363062
 >> iter 96000, loss: 8.326259
 >> iter 97000, loss: 8.311758
 >> iter 98000, loss: 8.355301
 >> iter 99000, loss: 8.246705
 >> iter 100000, loss: 8.216064
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 16.2716745665
   - Test - Long: 30.9734513274
   - Test - Big: 16.2448375516
   - Test - A: 8.62609159389
   - Test - B: 31.6378908073
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.235343
 >> iter 2000, loss: 15.666628
 >> iter 3000, loss: 14.160289
 >> iter 4000, loss: 13.565425
 >> iter 5000, loss: 13.297252
 >> iter 6000, loss: 13.187983
 >> iter 7000, loss: 13.128491
 >> iter 8000, loss: 13.105770
 >> iter 9000, loss: 13.090291
 >> iter 10000, loss: 13.093365
   Number of active neurons: 10
 >> iter 11000, loss: 13.072603
 >> iter 12000, loss: 13.077836
 >> iter 13000, loss: 13.063906
 >> iter 14000, loss: 13.061241
 >> iter 15000, loss: 13.053878
 >> iter 16000, loss: 13.064996
 >> iter 17000, loss: 13.062033
 >> iter 18000, loss: 13.058412
 >> iter 19000, loss: 13.051330
 >> iter 20000, loss: 13.060273
   Number of active neurons: 10
 >> iter 21000, loss: 13.044256
 >> iter 22000, loss: 13.051635
 >> iter 23000, loss: 13.036195
 >> iter 24000, loss: 13.048938
 >> iter 25000, loss: 13.030487
 >> iter 26000, loss: 13.044080
 >> iter 27000, loss: 13.036146
 >> iter 28000, loss: 13.043526
 >> iter 29000, loss: 13.028513
 >> iter 30000, loss: 13.039722
   Number of active neurons: 10
 >> iter 31000, loss: 13.025317
 >> iter 32000, loss: 13.042882
 >> iter 33000, loss: 13.025318
 >> iter 34000, loss: 13.031740
 >> iter 35000, loss: 13.018558
 >> iter 36000, loss: 13.028208
 >> iter 37000, loss: 13.019464
 >> iter 38000, loss: 13.029103
 >> iter 39000, loss: 13.011328
 >> iter 40000, loss: 13.029018
   Number of active neurons: 10
 >> iter 41000, loss: 13.008469
 >> iter 42000, loss: 13.023891
 >> iter 43000, loss: 13.003363
 >> iter 44000, loss: 13.023786
 >> iter 45000, loss: 13.001690
 >> iter 46000, loss: 13.018974
 >> iter 47000, loss: 12.995708
 >> iter 48000, loss: 13.018803
 >> iter 49000, loss: 13.002765
 >> iter 50000, loss: 13.016963
   Number of active neurons: 10
 >> iter 51000, loss: 12.980411
 >> iter 52000, loss: 12.995541
 >> iter 53000, loss: 12.970421
 >> iter 54000, loss: 12.985612
 >> iter 55000, loss: 12.937503
 >> iter 56000, loss: 12.933324
 >> iter 57000, loss: 12.884830
 >> iter 58000, loss: 12.855712
 >> iter 59000, loss: 12.812004
 >> iter 60000, loss: 12.768231
   Number of active neurons: 10
 >> iter 61000, loss: 12.711651
 >> iter 62000, loss: 12.660769
 >> iter 63000, loss: 12.609990
 >> iter 64000, loss: 12.565446
 >> iter 65000, loss: 12.512192
 >> iter 66000, loss: 12.142386
 >> iter 67000, loss: 11.663778
 >> iter 68000, loss: 11.389992
 >> iter 69000, loss: 11.150861
 >> iter 70000, loss: 11.029568
   Number of active neurons: 10
 >> iter 71000, loss: 10.890352
 >> iter 72000, loss: 10.820734
 >> iter 73000, loss: 10.649072
 >> iter 74000, loss: 10.633005
 >> iter 75000, loss: 10.454541
 >> iter 76000, loss: 10.484967
 >> iter 77000, loss: 10.301474
 >> iter 78000, loss: 10.345768
 >> iter 79000, loss: 10.205382
 >> iter 80000, loss: 10.309228
   Number of active neurons: 10
 >> iter 81000, loss: 10.129293
 >> iter 82000, loss: 10.120808
 >> iter 83000, loss: 10.040755
 >> iter 84000, loss: 10.083743
 >> iter 85000, loss: 9.921345
 >> iter 86000, loss: 9.975402
 >> iter 87000, loss: 9.821019
 >> iter 88000, loss: 9.869059
 >> iter 89000, loss: 9.754725
 >> iter 90000, loss: 9.783810
   Number of active neurons: 10
 >> iter 91000, loss: 9.702688
 >> iter 92000, loss: 9.696908
 >> iter 93000, loss: 9.597427
 >> iter 94000, loss: 9.637398
 >> iter 95000, loss: 9.721976
 >> iter 96000, loss: 9.697744
 >> iter 97000, loss: 9.492256
 >> iter 98000, loss: 9.457624
 >> iter 99000, loss: 9.284370
 >> iter 100000, loss: 9.349360
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 16.8696626067
   - Test - Long: 31.0734463277
   - Test - Big: 16.7908320917
   - Test - A: 31.391240584
   - Test - B: 31.6245583628
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.227612
 >> iter 2000, loss: 15.689484
 >> iter 3000, loss: 14.156700
 >> iter 4000, loss: 13.551324
 >> iter 5000, loss: 13.285545
 >> iter 6000, loss: 13.178680
 >> iter 7000, loss: 13.110389
 >> iter 8000, loss: 13.101293
 >> iter 9000, loss: 13.073079
 >> iter 10000, loss: 13.090643
   Number of active neurons: 10
 >> iter 11000, loss: 13.070957
 >> iter 12000, loss: 13.074871
 >> iter 13000, loss: 13.056538
 >> iter 14000, loss: 13.070760
 >> iter 15000, loss: 13.056608
 >> iter 16000, loss: 13.065986
 >> iter 17000, loss: 13.055546
 >> iter 18000, loss: 13.055621
 >> iter 19000, loss: 13.037756
 >> iter 20000, loss: 13.058853
   Number of active neurons: 10
 >> iter 21000, loss: 13.042979
 >> iter 22000, loss: 13.057434
 >> iter 23000, loss: 13.045987
 >> iter 24000, loss: 13.056533
 >> iter 25000, loss: 13.041142
 >> iter 26000, loss: 13.052429
 >> iter 27000, loss: 13.032148
 >> iter 28000, loss: 13.046229
 >> iter 29000, loss: 13.034231
 >> iter 30000, loss: 13.045761
   Number of active neurons: 10
 >> iter 31000, loss: 13.032915
 >> iter 32000, loss: 13.059260
 >> iter 33000, loss: 13.041380
 >> iter 34000, loss: 13.044586
 >> iter 35000, loss: 13.020826
 >> iter 36000, loss: 13.035917
 >> iter 37000, loss: 13.024910
 >> iter 38000, loss: 13.034872
 >> iter 39000, loss: 13.017152
 >> iter 40000, loss: 13.031715
   Number of active neurons: 10
 >> iter 41000, loss: 13.018758
 >> iter 42000, loss: 13.037815
 >> iter 43000, loss: 13.018560
 >> iter 44000, loss: 13.027861
 >> iter 45000, loss: 13.010416
 >> iter 46000, loss: 13.032220
 >> iter 47000, loss: 13.007997
 >> iter 48000, loss: 13.033628
 >> iter 49000, loss: 13.015649
 >> iter 50000, loss: 13.034982
   Number of active neurons: 10
 >> iter 51000, loss: 13.004918
 >> iter 52000, loss: 13.026844
 >> iter 53000, loss: 12.995090
 >> iter 54000, loss: 12.987662
 >> iter 55000, loss: 12.910637
 >> iter 56000, loss: 12.550014
 >> iter 57000, loss: 11.904706
 >> iter 58000, loss: 11.593140
 >> iter 59000, loss: 11.253404
 >> iter 60000, loss: 11.163930
   Number of active neurons: 10
 >> iter 61000, loss: 10.965224
 >> iter 62000, loss: 10.996605
 >> iter 63000, loss: 10.936237
 >> iter 64000, loss: 10.982017
 >> iter 65000, loss: 10.828967
 >> iter 66000, loss: 10.789605
 >> iter 67000, loss: 10.671448
 >> iter 68000, loss: 10.660701
 >> iter 69000, loss: 10.520971
 >> iter 70000, loss: 10.544183
   Number of active neurons: 10
 >> iter 71000, loss: 10.459966
 >> iter 72000, loss: 10.461446
 >> iter 73000, loss: 10.319991
 >> iter 74000, loss: 10.155872
 >> iter 75000, loss: 9.782575
 >> iter 76000, loss: 9.476081
 >> iter 77000, loss: 9.149461
 >> iter 78000, loss: 8.759676
 >> iter 79000, loss: 8.051008
 >> iter 80000, loss: 7.687086
   Number of active neurons: 10
 >> iter 81000, loss: 7.400073
 >> iter 82000, loss: 7.310490
 >> iter 83000, loss: 6.985814
 >> iter 84000, loss: 6.889486
 >> iter 85000, loss: 6.651548
 >> iter 86000, loss: 6.529441
 >> iter 87000, loss: 6.410332
 >> iter 88000, loss: 6.347931
 >> iter 89000, loss: 6.267253
 >> iter 90000, loss: 6.402051
   Number of active neurons: 10
 >> iter 91000, loss: 6.116049
 >> iter 92000, loss: 6.098537
 >> iter 93000, loss: 6.056914
 >> iter 94000, loss: 6.099027
 >> iter 95000, loss: 5.987852
 >> iter 96000, loss: 6.113482
 >> iter 97000, loss: 5.201500
 >> iter 98000, loss: 3.008438
 >> iter 99000, loss: 1.677327
 >> iter 100000, loss: 1.617655
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.167996640067
   - Test - Long: 0.254987250637
   - Test - Big: 0.144998550015
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

