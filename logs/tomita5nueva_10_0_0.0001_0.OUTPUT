 > Problema: tomita5nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.577976
 >> iter 2000, loss: 10.494484
 >> iter 3000, loss: 8.622930
 >> iter 4000, loss: 7.894418
 >> iter 5000, loss: 7.651699
 >> iter 6000, loss: 7.526792
 >> iter 7000, loss: 7.099139
 >> iter 8000, loss: 6.616747
 >> iter 9000, loss: 6.273835
 >> iter 10000, loss: 5.865991
   Number of active neurons: 4
 >> iter 11000, loss: 2.406974
 >> iter 12000, loss: 0.975268
 >> iter 13000, loss: 0.426774
 >> iter 14000, loss: 0.214332
 >> iter 15000, loss: 0.133620
 >> iter 16000, loss: 0.109969
 >> iter 17000, loss: 0.092825
 >> iter 18000, loss: 0.094783
 >> iter 19000, loss: 0.084340
 >> iter 20000, loss: 0.086335
   Number of active neurons: 4
 >> iter 21000, loss: 0.077494
 >> iter 22000, loss: 0.072681
 >> iter 23000, loss: 0.069699
 >> iter 24000, loss: 0.066845
 >> iter 25000, loss: 0.065344
 >> iter 26000, loss: 0.063661
 >> iter 27000, loss: 0.063043
 >> iter 28000, loss: 0.062037
 >> iter 29000, loss: 0.061758
 >> iter 30000, loss: 0.061066
   Number of active neurons: 4
 >> iter 31000, loss: 0.060965
 >> iter 32000, loss: 0.060359
 >> iter 33000, loss: 0.060366
 >> iter 34000, loss: 0.059843
 >> iter 35000, loss: 0.059889
 >> iter 36000, loss: 0.059451
 >> iter 37000, loss: 0.059489
 >> iter 38000, loss: 0.059122
 >> iter 39000, loss: 0.059173
 >> iter 40000, loss: 0.058893
   Number of active neurons: 4
 >> iter 41000, loss: 0.058967
 >> iter 42000, loss: 0.058732
 >> iter 43000, loss: 0.058774
 >> iter 44000, loss: 0.058536
 >> iter 45000, loss: 0.058518
 >> iter 46000, loss: 0.058269
 >> iter 47000, loss: 0.058220
 >> iter 48000, loss: 0.057947
 >> iter 49000, loss: 0.057806
 >> iter 50000, loss: 0.057443
   Number of active neurons: 4
 >> iter 51000, loss: 0.057366
 >> iter 52000, loss: 0.057098
 >> iter 53000, loss: 0.057099
 >> iter 54000, loss: 0.056894
 >> iter 55000, loss: 0.056947
 >> iter 56000, loss: 0.056786
 >> iter 57000, loss: 0.056870
 >> iter 58000, loss: 0.056720
 >> iter 59000, loss: 0.056825
 >> iter 60000, loss: 0.056693
   Number of active neurons: 4
 >> iter 61000, loss: 0.056812
 >> iter 62000, loss: 0.056685
 >> iter 63000, loss: 0.056829
 >> iter 64000, loss: 0.056710
 >> iter 65000, loss: 0.056865
 >> iter 66000, loss: 0.056757
 >> iter 67000, loss: 0.056934
 >> iter 68000, loss: 0.056828
 >> iter 69000, loss: 0.057015
 >> iter 70000, loss: 0.056907
   Number of active neurons: 4
 >> iter 71000, loss: 0.057115
 >> iter 72000, loss: 0.056958
 >> iter 73000, loss: 0.057079
 >> iter 74000, loss: 0.056753
 >> iter 75000, loss: 0.056709
 >> iter 76000, loss: 0.056300
 >> iter 77000, loss: 0.056308
 >> iter 78000, loss: 0.055951
 >> iter 79000, loss: 0.056028
 >> iter 80000, loss: 0.055727
   Number of active neurons: 4
 >> iter 81000, loss: 0.055853
 >> iter 82000, loss: 0.055571
 >> iter 83000, loss: 0.055730
 >> iter 84000, loss: 0.055461
 >> iter 85000, loss: 0.055657
 >> iter 86000, loss: 0.055384
 >> iter 87000, loss: 0.055583
 >> iter 88000, loss: 0.055322
 >> iter 89000, loss: 0.055512
 >> iter 90000, loss: 0.055264
   Number of active neurons: 4
 >> iter 91000, loss: 0.055457
 >> iter 92000, loss: 0.055211
 >> iter 93000, loss: 0.055412
 >> iter 94000, loss: 0.055170
 >> iter 95000, loss: 0.055359
 >> iter 96000, loss: 0.055121
 >> iter 97000, loss: 0.055324
 >> iter 98000, loss: 0.055076
 >> iter 99000, loss: 0.055306
 >> iter 100000, loss: 0.055036
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.629951
 >> iter 2000, loss: 10.522622
 >> iter 3000, loss: 8.647258
 >> iter 4000, loss: 7.942614
 >> iter 5000, loss: 7.694956
 >> iter 6000, loss: 7.699781
 >> iter 7000, loss: 7.461170
 >> iter 8000, loss: 6.171207
 >> iter 9000, loss: 3.972707
 >> iter 10000, loss: 1.740175
   Number of active neurons: 5
 >> iter 11000, loss: 0.788296
 >> iter 12000, loss: 0.376340
 >> iter 13000, loss: 0.206482
 >> iter 14000, loss: 0.162541
 >> iter 15000, loss: 0.301334
 >> iter 16000, loss: 0.262575
 >> iter 17000, loss: 0.379207
 >> iter 18000, loss: 0.617695
 >> iter 19000, loss: 0.469630
 >> iter 20000, loss: 0.232637
   Number of active neurons: 5
 >> iter 21000, loss: 0.234953
 >> iter 22000, loss: 0.148410
 >> iter 23000, loss: 0.160128
 >> iter 24000, loss: 0.101999
 >> iter 25000, loss: 0.149237
 >> iter 26000, loss: 0.095046
 >> iter 27000, loss: 0.096422
 >> iter 28000, loss: 0.069023
 >> iter 29000, loss: 0.059147
 >> iter 30000, loss: 0.054476
   Number of active neurons: 5
 >> iter 31000, loss: 0.054106
 >> iter 32000, loss: 0.052442
 >> iter 33000, loss: 0.053320
 >> iter 34000, loss: 0.052940
 >> iter 35000, loss: 0.054690
 >> iter 36000, loss: 0.053683
 >> iter 37000, loss: 0.055435
 >> iter 38000, loss: 0.054024
 >> iter 39000, loss: 0.055627
 >> iter 40000, loss: 0.054465
   Number of active neurons: 5
 >> iter 41000, loss: 0.055775
 >> iter 42000, loss: 0.054509
 >> iter 43000, loss: 0.055485
 >> iter 44000, loss: 0.054401
 >> iter 45000, loss: 0.055945
 >> iter 46000, loss: 0.054670
 >> iter 47000, loss: 0.055014
 >> iter 48000, loss: 0.054368
 >> iter 49000, loss: 0.054480
 >> iter 50000, loss: 0.053916
   Number of active neurons: 5
 >> iter 51000, loss: 0.056116
 >> iter 52000, loss: 0.053915
 >> iter 53000, loss: 0.084256
 >> iter 54000, loss: 0.065185
 >> iter 55000, loss: 0.060636
 >> iter 56000, loss: 0.055321
 >> iter 57000, loss: 0.055670
 >> iter 58000, loss: 0.053617
 >> iter 59000, loss: 0.055776
 >> iter 60000, loss: 0.052887
   Number of active neurons: 5
 >> iter 61000, loss: 0.057679
 >> iter 62000, loss: 0.054198
 >> iter 63000, loss: 0.056082
 >> iter 64000, loss: 0.053309
 >> iter 65000, loss: 0.054751
 >> iter 66000, loss: 0.065551
 >> iter 67000, loss: 0.061237
 >> iter 68000, loss: 0.056227
 >> iter 69000, loss: 0.055878
 >> iter 70000, loss: 0.055885
   Number of active neurons: 5
 >> iter 71000, loss: 0.055902
 >> iter 72000, loss: 0.054912
 >> iter 73000, loss: 0.061577
 >> iter 74000, loss: 0.056339
 >> iter 75000, loss: 0.060654
 >> iter 76000, loss: 0.063692
 >> iter 77000, loss: 0.062408
 >> iter 78000, loss: 0.056635
 >> iter 79000, loss: 0.061935
 >> iter 80000, loss: 0.054392
   Number of active neurons: 5
 >> iter 81000, loss: 0.119274
 >> iter 82000, loss: 0.081180
 >> iter 83000, loss: 0.072780
 >> iter 84000, loss: 0.066829
 >> iter 85000, loss: 0.070977
 >> iter 86000, loss: 0.057466
 >> iter 87000, loss: 0.079940
 >> iter 88000, loss: 0.152297
 >> iter 89000, loss: 0.145541
 >> iter 90000, loss: 0.185250
   Number of active neurons: 5
 >> iter 91000, loss: 0.152101
 >> iter 92000, loss: 0.161124
 >> iter 93000, loss: 0.127125
 >> iter 94000, loss: 0.149793
 >> iter 95000, loss: 0.150156
 >> iter 96000, loss: 0.163852
 >> iter 97000, loss: 0.126081
 >> iter 98000, loss: 0.140234
 >> iter 99000, loss: 0.110750
 >> iter 100000, loss: 0.132777
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0089999100009
   - Test - A: 13.8790747284
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.598587
 >> iter 2000, loss: 10.509505
 >> iter 3000, loss: 8.644181
 >> iter 4000, loss: 7.924112
 >> iter 5000, loss: 7.680505
 >> iter 6000, loss: 7.576584
 >> iter 7000, loss: 7.236422
 >> iter 8000, loss: 6.237198
 >> iter 9000, loss: 2.526765
 >> iter 10000, loss: 1.016583
   Number of active neurons: 5
 >> iter 11000, loss: 0.439135
 >> iter 12000, loss: 0.215616
 >> iter 13000, loss: 0.129262
 >> iter 14000, loss: 0.096704
 >> iter 15000, loss: 0.080128
 >> iter 16000, loss: 0.075642
 >> iter 17000, loss: 0.080809
 >> iter 18000, loss: 0.187086
 >> iter 19000, loss: 0.112346
 >> iter 20000, loss: 0.203906
   Number of active neurons: 4
 >> iter 21000, loss: 0.172096
 >> iter 22000, loss: 0.210587
 >> iter 23000, loss: 0.119370
 >> iter 24000, loss: 0.085056
 >> iter 25000, loss: 0.089713
 >> iter 26000, loss: 0.341949
 >> iter 27000, loss: 0.190795
 >> iter 28000, loss: 0.386219
 >> iter 29000, loss: 0.206990
 >> iter 30000, loss: 0.403594
   Number of active neurons: 4
 >> iter 31000, loss: 0.214776
 >> iter 32000, loss: 0.337392
 >> iter 33000, loss: 0.192558
 >> iter 34000, loss: 0.321687
 >> iter 35000, loss: 0.293461
 >> iter 36000, loss: 0.974065
 >> iter 37000, loss: 0.424384
 >> iter 38000, loss: 0.299438
 >> iter 39000, loss: 0.182350
 >> iter 40000, loss: 0.114278
   Number of active neurons: 5
 >> iter 41000, loss: 0.134230
 >> iter 42000, loss: 0.123817
 >> iter 43000, loss: 0.250376
 >> iter 44000, loss: 0.275674
 >> iter 45000, loss: 0.660084
 >> iter 46000, loss: 3.051820
 >> iter 47000, loss: 1.196230
 >> iter 48000, loss: 0.499851
 >> iter 49000, loss: 0.286585
 >> iter 50000, loss: 0.152177
   Number of active neurons: 4
 >> iter 51000, loss: 0.178089
 >> iter 52000, loss: 0.128543
 >> iter 53000, loss: 0.242620
 >> iter 54000, loss: 0.320066
 >> iter 55000, loss: 0.181706
 >> iter 56000, loss: 0.129176
 >> iter 57000, loss: 0.400217
 >> iter 58000, loss: 0.352589
 >> iter 59000, loss: 0.256445
 >> iter 60000, loss: 0.187907
   Number of active neurons: 4
 >> iter 61000, loss: 0.334434
 >> iter 62000, loss: 0.898643
 >> iter 63000, loss: 0.448162
 >> iter 64000, loss: 0.378401
 >> iter 65000, loss: 0.230130
 >> iter 66000, loss: 0.248780
 >> iter 67000, loss: 0.554552
 >> iter 68000, loss: 0.456919
 >> iter 69000, loss: 0.456372
 >> iter 70000, loss: 0.621014
   Number of active neurons: 4
 >> iter 71000, loss: 0.332529
 >> iter 72000, loss: 0.314992
 >> iter 73000, loss: 0.473534
 >> iter 74000, loss: 1.886193
 >> iter 75000, loss: 6.156618
   Number of active neurons: 4
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 76000, loss: 2.339904
 >> iter 77000, loss: 0.910958
 >> iter 78000, loss: 0.376684
 >> iter 79000, loss: 0.175845
 >> iter 80000, loss: 0.099158
   Number of active neurons: 4
 >> iter 81000, loss: 0.069246
 >> iter 82000, loss: 0.056984
 >> iter 83000, loss: 0.051802
 >> iter 84000, loss: 0.049357
 >> iter 85000, loss: 0.048228
 >> iter 86000, loss: 0.047625
 >> iter 87000, loss: 0.047343
 >> iter 88000, loss: 0.047209
 >> iter 89000, loss: 0.047128
 >> iter 90000, loss: 0.047086
   Number of active neurons: 4
 >> iter 91000, loss: 0.046923
 >> iter 92000, loss: 0.046862
 >> iter 93000, loss: 0.046651
 >> iter 94000, loss: 0.046586
 >> iter 95000, loss: 0.046339
 >> iter 96000, loss: 0.046205
 >> iter 97000, loss: 0.045782
 >> iter 98000, loss: 0.045573
 >> iter 99000, loss: 0.045159
 >> iter 100000, loss: 0.045012
   Number of active neurons: 4
 >> iter 101000, loss: 0.044622
 >> iter 102000, loss: 0.044505
 >> iter 103000, loss: 0.044157
 >> iter 104000, loss: 0.044124
 >> iter 105000, loss: 0.043833
 >> iter 106000, loss: 0.043784
 >> iter 107000, loss: 0.043468
 >> iter 108000, loss: 0.043446
 >> iter 109000, loss: 0.043168
 >> iter 110000, loss: 0.043196
   Number of active neurons: 4
 >> iter 111000, loss: 0.042964
 >> iter 112000, loss: 0.042996
 >> iter 113000, loss: 0.042741
 >> iter 114000, loss: 0.042774
 >> iter 115000, loss: 0.042558
 >> iter 116000, loss: 0.042625
 >> iter 117000, loss: 0.042449
 >> iter 118000, loss: 0.042544
 >> iter 119000, loss: 0.042391
 >> iter 120000, loss: 0.042492
   Number of active neurons: 4
 >> iter 121000, loss: 0.042355
 >> iter 122000, loss: 0.042468
 >> iter 123000, loss: 0.042335
 >> iter 124000, loss: 0.042452
 >> iter 125000, loss: 0.042327
 >> iter 126000, loss: 0.042436
 >> iter 127000, loss: 0.042321
 >> iter 128000, loss: 0.042422
 >> iter 129000, loss: 0.042308
 >> iter 130000, loss: 0.042413
   Number of active neurons: 4
 >> iter 131000, loss: 0.042302
 >> iter 132000, loss: 0.042414
 >> iter 133000, loss: 0.042298
 >> iter 134000, loss: 0.042409
 >> iter 135000, loss: 0.042290
 >> iter 136000, loss: 0.042411
 >> iter 137000, loss: 0.042284
 >> iter 138000, loss: 0.042416
 >> iter 139000, loss: 0.042280
 >> iter 140000, loss: 0.042411
   Number of active neurons: 4
 >> iter 141000, loss: 0.042274
 >> iter 142000, loss: 0.042415
 >> iter 143000, loss: 0.042271
 >> iter 144000, loss: 0.042421
 >> iter 145000, loss: 0.042276
 >> iter 146000, loss: 0.042424
 >> iter 147000, loss: 0.042276
 >> iter 148000, loss: 0.042440
 >> iter 149000, loss: 0.042271
 >> iter 150000, loss: 0.042452
   Number of active neurons: 4
 >> iter 151000, loss: 0.042285
 >> iter 152000, loss: 0.042472
 >> iter 153000, loss: 0.042304
 >> iter 154000, loss: 0.042493
 >> iter 155000, loss: 0.042326
 >> iter 156000, loss: 0.042516
 >> iter 157000, loss: 0.042353
 >> iter 158000, loss: 0.042546
 >> iter 159000, loss: 0.042380
 >> iter 160000, loss: 0.042581
   Number of active neurons: 4
 >> iter 161000, loss: 0.042411
 >> iter 162000, loss: 0.042618
 >> iter 163000, loss: 0.042458
 >> iter 164000, loss: 0.042663
 >> iter 165000, loss: 0.042508
 >> iter 166000, loss: 0.042718
 >> iter 167000, loss: 0.042566
 >> iter 168000, loss: 0.042783
 >> iter 169000, loss: 0.042633
 >> iter 170000, loss: 0.042858
   Number of active neurons: 4
 >> iter 171000, loss: 0.042718
 >> iter 172000, loss: 0.042944
 >> iter 173000, loss: 0.042778
 >> iter 174000, loss: 0.042996
 >> iter 175000, loss: 0.042842
 >> iter 176000, loss: 0.043027
 >> iter 177000, loss: 0.042860
 >> iter 178000, loss: 0.043019
 >> iter 179000, loss: 0.042856
 >> iter 180000, loss: 0.042969
   Number of active neurons: 4
 >> iter 181000, loss: 0.042785
 >> iter 182000, loss: 0.042809
 >> iter 183000, loss: 0.042450
 >> iter 184000, loss: 0.042217
 >> iter 185000, loss: 0.041829
 >> iter 186000, loss: 0.041645
 >> iter 187000, loss: 0.041337
 >> iter 188000, loss: 0.041242
 >> iter 189000, loss: 0.041032
 >> iter 190000, loss: 0.041010
   Number of active neurons: 3
 >> iter 191000, loss: 0.040857
 >> iter 192000, loss: 0.040869
 >> iter 193000, loss: 0.040740
 >> iter 194000, loss: 0.040770
 >> iter 195000, loss: 0.040658
 >> iter 196000, loss: 0.040691
 >> iter 197000, loss: 0.040596
 >> iter 198000, loss: 0.040636
 >> iter 199000, loss: 0.040553
 >> iter 200000, loss: 0.040597
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.618398
 >> iter 2000, loss: 10.532374
 >> iter 3000, loss: 8.657904
 >> iter 4000, loss: 7.945158
 >> iter 5000, loss: 7.708907
 >> iter 6000, loss: 7.522326
 >> iter 7000, loss: 5.451574
 >> iter 8000, loss: 2.101521
 >> iter 9000, loss: 0.827663
 >> iter 10000, loss: 0.348901
   Number of active neurons: 5
 >> iter 11000, loss: 0.169160
 >> iter 12000, loss: 0.100575
 >> iter 13000, loss: 0.073948
 >> iter 14000, loss: 0.062649
 >> iter 15000, loss: 0.057812
 >> iter 16000, loss: 0.055173
 >> iter 17000, loss: 0.053757
 >> iter 18000, loss: 0.052512
 >> iter 19000, loss: 0.051961
 >> iter 20000, loss: 0.051490
   Number of active neurons: 5
 >> iter 21000, loss: 0.051214
 >> iter 22000, loss: 0.050846
 >> iter 23000, loss: 0.050628
 >> iter 24000, loss: 0.050423
 >> iter 25000, loss: 0.050174
 >> iter 26000, loss: 0.049900
 >> iter 27000, loss: 0.049605
 >> iter 28000, loss: 0.049419
 >> iter 29000, loss: 0.049181
 >> iter 30000, loss: 0.049080
   Number of active neurons: 5
 >> iter 31000, loss: 0.048871
 >> iter 32000, loss: 0.048779
 >> iter 33000, loss: 0.048542
 >> iter 34000, loss: 0.048369
 >> iter 35000, loss: 0.047982
 >> iter 36000, loss: 0.047654
 >> iter 37000, loss: 0.047124
 >> iter 38000, loss: 0.046765
 >> iter 39000, loss: 0.046340
 >> iter 40000, loss: 0.046147
   Number of active neurons: 5
 >> iter 41000, loss: 0.045863
 >> iter 42000, loss: 0.045732
 >> iter 43000, loss: 0.045385
 >> iter 44000, loss: 0.045153
 >> iter 45000, loss: 0.044820
 >> iter 46000, loss: 0.044684
 >> iter 47000, loss: 0.044435
 >> iter 48000, loss: 0.044348
 >> iter 49000, loss: 0.044156
 >> iter 50000, loss: 0.044110
   Number of active neurons: 5
 >> iter 51000, loss: 0.043949
 >> iter 52000, loss: 0.043909
 >> iter 53000, loss: 0.043683
 >> iter 54000, loss: 0.043618
 >> iter 55000, loss: 0.043425
 >> iter 56000, loss: 0.043441
 >> iter 57000, loss: 0.043267
 >> iter 58000, loss: 0.043245
 >> iter 59000, loss: 0.043039
 >> iter 60000, loss: 0.043063
   Number of active neurons: 5
 >> iter 61000, loss: 0.042920
 >> iter 62000, loss: 0.042984
 >> iter 63000, loss: 0.042876
 >> iter 64000, loss: 0.042962
 >> iter 65000, loss: 0.042874
 >> iter 66000, loss: 0.042960
 >> iter 67000, loss: 0.042875
 >> iter 68000, loss: 0.042967
 >> iter 69000, loss: 0.042870
 >> iter 70000, loss: 0.042888
   Number of active neurons: 5
 >> iter 71000, loss: 0.042748
 >> iter 72000, loss: 0.042786
 >> iter 73000, loss: 0.042689
 >> iter 74000, loss: 0.042761
 >> iter 75000, loss: 0.042696
 >> iter 76000, loss: 0.042788
 >> iter 77000, loss: 0.042730
 >> iter 78000, loss: 0.042831
 >> iter 79000, loss: 0.042795
 >> iter 80000, loss: 0.042889
   Number of active neurons: 5
 >> iter 81000, loss: 0.042850
 >> iter 82000, loss: 0.042956
 >> iter 83000, loss: 0.042910
 >> iter 84000, loss: 0.043020
 >> iter 85000, loss: 0.042977
 >> iter 86000, loss: 0.043098
 >> iter 87000, loss: 0.043048
 >> iter 88000, loss: 0.043168
 >> iter 89000, loss: 0.043122
 >> iter 90000, loss: 0.043243
   Number of active neurons: 5
 >> iter 91000, loss: 0.043193
 >> iter 92000, loss: 0.043322
 >> iter 93000, loss: 0.043268
 >> iter 94000, loss: 0.043394
 >> iter 95000, loss: 0.043359
 >> iter 96000, loss: 0.043470
 >> iter 97000, loss: 0.043446
 >> iter 98000, loss: 0.043552
 >> iter 99000, loss: 0.043532
 >> iter 100000, loss: 0.043638
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.576570
 >> iter 2000, loss: 10.506083
 >> iter 3000, loss: 8.643808
 >> iter 4000, loss: 7.944156
 >> iter 5000, loss: 7.702863
 >> iter 6000, loss: 7.525317
 >> iter 7000, loss: 7.050849
 >> iter 8000, loss: 2.805245
 >> iter 9000, loss: 1.085996
 >> iter 10000, loss: 0.441467
   Number of active neurons: 6
 >> iter 11000, loss: 0.200408
 >> iter 12000, loss: 0.109569
 >> iter 13000, loss: 0.075245
 >> iter 14000, loss: 0.061852
 >> iter 15000, loss: 0.056847
 >> iter 16000, loss: 0.054671
 >> iter 17000, loss: 0.054001
 >> iter 18000, loss: 0.053550
 >> iter 19000, loss: 0.053547
 >> iter 20000, loss: 0.053289
   Number of active neurons: 6
 >> iter 21000, loss: 0.053162
 >> iter 22000, loss: 0.052938
 >> iter 23000, loss: 0.052968
 >> iter 24000, loss: 0.052910
 >> iter 25000, loss: 0.052890
 >> iter 26000, loss: 0.052696
 >> iter 27000, loss: 0.052390
 >> iter 28000, loss: 0.051853
 >> iter 29000, loss: 0.051315
 >> iter 30000, loss: 0.050767
   Number of active neurons: 6
 >> iter 31000, loss: 0.050322
 >> iter 32000, loss: 0.049918
 >> iter 33000, loss: 0.049634
 >> iter 34000, loss: 0.049353
 >> iter 35000, loss: 0.049179
 >> iter 36000, loss: 0.048956
 >> iter 37000, loss: 0.048718
 >> iter 38000, loss: 0.048426
 >> iter 39000, loss: 0.048116
 >> iter 40000, loss: 0.047669
   Number of active neurons: 6
 >> iter 41000, loss: 0.047275
 >> iter 42000, loss: 0.047036
 >> iter 43000, loss: 0.046880
 >> iter 44000, loss: 0.046770
 >> iter 45000, loss: 0.046689
 >> iter 46000, loss: 0.046622
 >> iter 47000, loss: 0.046567
 >> iter 48000, loss: 0.046508
 >> iter 49000, loss: 0.046482
 >> iter 50000, loss: 0.046447
   Number of active neurons: 6
 >> iter 51000, loss: 0.046431
 >> iter 52000, loss: 0.046409
 >> iter 53000, loss: 0.046382
 >> iter 54000, loss: 0.046403
 >> iter 55000, loss: 0.046293
 >> iter 56000, loss: 0.046153
 >> iter 57000, loss: 0.045888
 >> iter 58000, loss: 0.045827
 >> iter 59000, loss: 0.045628
 >> iter 60000, loss: 0.045630
   Number of active neurons: 5
 >> iter 61000, loss: 0.045417
 >> iter 62000, loss: 0.045359
 >> iter 63000, loss: 0.045004
 >> iter 64000, loss: 0.044779
 >> iter 65000, loss: 0.044384
 >> iter 66000, loss: 0.044282
 >> iter 67000, loss: 0.044023
 >> iter 68000, loss: 0.044035
 >> iter 69000, loss: 0.043837
 >> iter 70000, loss: 0.043891
   Number of active neurons: 6
 >> iter 71000, loss: 0.043639
 >> iter 72000, loss: 0.043535
 >> iter 73000, loss: 0.043221
 >> iter 74000, loss: 0.043185
 >> iter 75000, loss: 0.042958
 >> iter 76000, loss: 0.042983
 >> iter 77000, loss: 0.042791
 >> iter 78000, loss: 0.042844
 >> iter 79000, loss: 0.042690
 >> iter 80000, loss: 0.042745
   Number of active neurons: 6
 >> iter 81000, loss: 0.042598
 >> iter 82000, loss: 0.042672
 >> iter 83000, loss: 0.042479
 >> iter 84000, loss: 0.042510
 >> iter 85000, loss: 0.042341
 >> iter 86000, loss: 0.042420
 >> iter 87000, loss: 0.042281
 >> iter 88000, loss: 0.042384
 >> iter 89000, loss: 0.042263
 >> iter 90000, loss: 0.042380
   Number of active neurons: 6
 >> iter 91000, loss: 0.042261
 >> iter 92000, loss: 0.042391
 >> iter 93000, loss: 0.042270
 >> iter 94000, loss: 0.042396
 >> iter 95000, loss: 0.042292
 >> iter 96000, loss: 0.042406
 >> iter 97000, loss: 0.042307
 >> iter 98000, loss: 0.042416
 >> iter 99000, loss: 0.042319
 >> iter 100000, loss: 0.042426
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.670281
 >> iter 2000, loss: 10.533877
 >> iter 3000, loss: 8.649549
 >> iter 4000, loss: 7.915340
 >> iter 5000, loss: 7.689870
 >> iter 6000, loss: 7.596963
 >> iter 7000, loss: 7.428645
 >> iter 8000, loss: 5.658616
 >> iter 9000, loss: 2.165955
 >> iter 10000, loss: 0.844707
   Number of active neurons: 5
 >> iter 11000, loss: 0.349973
 >> iter 12000, loss: 0.164027
 >> iter 13000, loss: 0.093567
 >> iter 14000, loss: 0.066255
 >> iter 15000, loss: 0.055564
 >> iter 16000, loss: 0.050959
 >> iter 17000, loss: 0.048955
 >> iter 18000, loss: 0.047756
 >> iter 19000, loss: 0.047026
 >> iter 20000, loss: 0.046373
   Number of active neurons: 5
 >> iter 21000, loss: 0.045948
 >> iter 22000, loss: 0.045558
 >> iter 23000, loss: 0.045247
 >> iter 24000, loss: 0.044979
 >> iter 25000, loss: 0.044714
 >> iter 26000, loss: 0.044471
 >> iter 27000, loss: 0.044186
 >> iter 28000, loss: 0.044009
 >> iter 29000, loss: 0.043782
 >> iter 30000, loss: 0.043676
   Number of active neurons: 5
 >> iter 31000, loss: 0.043471
 >> iter 32000, loss: 0.043356
 >> iter 33000, loss: 0.043130
 >> iter 34000, loss: 0.042952
 >> iter 35000, loss: 0.042652
 >> iter 36000, loss: 0.042415
 >> iter 37000, loss: 0.042093
 >> iter 38000, loss: 0.041904
 >> iter 39000, loss: 0.041587
 >> iter 40000, loss: 0.041367
   Number of active neurons: 5
 >> iter 41000, loss: 0.041050
 >> iter 42000, loss: 0.040810
 >> iter 43000, loss: 0.040545
 >> iter 44000, loss: 0.040434
 >> iter 45000, loss: 0.040278
 >> iter 46000, loss: 0.040248
 >> iter 47000, loss: 0.040135
 >> iter 48000, loss: 0.040124
 >> iter 49000, loss: 0.040032
 >> iter 50000, loss: 0.040033
   Number of active neurons: 5
 >> iter 51000, loss: 0.039917
 >> iter 52000, loss: 0.039811
 >> iter 53000, loss: 0.039564
 >> iter 54000, loss: 0.039498
 >> iter 55000, loss: 0.039266
 >> iter 56000, loss: 0.039263
 >> iter 57000, loss: 0.039025
 >> iter 58000, loss: 0.038992
 >> iter 59000, loss: 0.038701
 >> iter 60000, loss: 0.038728
   Number of active neurons: 5
 >> iter 61000, loss: 0.038482
 >> iter 62000, loss: 0.038547
 >> iter 63000, loss: 0.038308
 >> iter 64000, loss: 0.038402
 >> iter 65000, loss: 0.038154
 >> iter 66000, loss: 0.038256
 >> iter 67000, loss: 0.037987
 >> iter 68000, loss: 0.038097
 >> iter 69000, loss: 0.037814
 >> iter 70000, loss: 0.037916
   Number of active neurons: 5
 >> iter 71000, loss: 0.037623
 >> iter 72000, loss: 0.037732
 >> iter 73000, loss: 0.037435
 >> iter 74000, loss: 0.037550
 >> iter 75000, loss: 0.037249
 >> iter 76000, loss: 0.037372
 >> iter 77000, loss: 0.037054
 >> iter 78000, loss: 0.037059
 >> iter 79000, loss: 0.036642
 >> iter 80000, loss: 0.036684
   Number of active neurons: 5
 >> iter 81000, loss: 0.036358
 >> iter 82000, loss: 0.036490
 >> iter 83000, loss: 0.036205
 >> iter 84000, loss: 0.036381
 >> iter 85000, loss: 0.036119
 >> iter 86000, loss: 0.036318
 >> iter 87000, loss: 0.036063
 >> iter 88000, loss: 0.036272
 >> iter 89000, loss: 0.036023
 >> iter 90000, loss: 0.036240
   Number of active neurons: 5
 >> iter 91000, loss: 0.035992
 >> iter 92000, loss: 0.036222
 >> iter 93000, loss: 0.035973
 >> iter 94000, loss: 0.036198
 >> iter 95000, loss: 0.035968
 >> iter 96000, loss: 0.036196
 >> iter 97000, loss: 0.035962
 >> iter 98000, loss: 0.036189
 >> iter 99000, loss: 0.035959
 >> iter 100000, loss: 0.036184
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.580235
 >> iter 2000, loss: 10.504531
 >> iter 3000, loss: 8.643795
 >> iter 4000, loss: 7.945619
 >> iter 5000, loss: 7.713213
 >> iter 6000, loss: 7.628874
 >> iter 7000, loss: 7.562812
 >> iter 8000, loss: 7.316110
 >> iter 9000, loss: 4.594024
 >> iter 10000, loss: 1.769764
   Number of active neurons: 5
 >> iter 11000, loss: 0.701307
 >> iter 12000, loss: 0.299258
 >> iter 13000, loss: 0.147675
 >> iter 14000, loss: 0.090073
 >> iter 15000, loss: 0.068098
 >> iter 16000, loss: 0.059582
 >> iter 17000, loss: 0.056295
 >> iter 18000, loss: 0.054890
 >> iter 19000, loss: 0.054279
 >> iter 20000, loss: 0.053833
   Number of active neurons: 5
 >> iter 21000, loss: 0.053596
 >> iter 22000, loss: 0.053335
 >> iter 23000, loss: 0.053112
 >> iter 24000, loss: 0.052931
 >> iter 25000, loss: 0.052643
 >> iter 26000, loss: 0.052395
 >> iter 27000, loss: 0.052042
 >> iter 28000, loss: 0.051742
 >> iter 29000, loss: 0.051365
 >> iter 30000, loss: 0.051066
   Number of active neurons: 5
 >> iter 31000, loss: 0.050630
 >> iter 32000, loss: 0.050200
 >> iter 33000, loss: 0.049633
 >> iter 34000, loss: 0.049133
 >> iter 35000, loss: 0.048586
 >> iter 36000, loss: 0.048063
 >> iter 37000, loss: 0.047514
 >> iter 38000, loss: 0.047165
 >> iter 39000, loss: 0.046759
 >> iter 40000, loss: 0.046447
   Number of active neurons: 5
 >> iter 41000, loss: 0.045967
 >> iter 42000, loss: 0.045683
 >> iter 43000, loss: 0.045342
 >> iter 44000, loss: 0.045162
 >> iter 45000, loss: 0.044897
 >> iter 46000, loss: 0.044771
 >> iter 47000, loss: 0.044466
 >> iter 48000, loss: 0.044256
 >> iter 49000, loss: 0.043885
 >> iter 50000, loss: 0.043647
   Number of active neurons: 5
 >> iter 51000, loss: 0.043314
 >> iter 52000, loss: 0.043140
 >> iter 53000, loss: 0.042863
 >> iter 54000, loss: 0.042728
 >> iter 55000, loss: 0.042515
 >> iter 56000, loss: 0.042506
 >> iter 57000, loss: 0.042375
 >> iter 58000, loss: 0.042435
 >> iter 59000, loss: 0.042337
 >> iter 60000, loss: 0.042424
   Number of active neurons: 5
 >> iter 61000, loss: 0.042343
 >> iter 62000, loss: 0.042436
 >> iter 63000, loss: 0.042360
 >> iter 64000, loss: 0.042460
 >> iter 65000, loss: 0.042389
 >> iter 66000, loss: 0.042485
 >> iter 67000, loss: 0.042409
 >> iter 68000, loss: 0.042511
 >> iter 69000, loss: 0.042434
 >> iter 70000, loss: 0.042532
   Number of active neurons: 5
 >> iter 71000, loss: 0.042460
 >> iter 72000, loss: 0.042559
 >> iter 73000, loss: 0.042487
 >> iter 74000, loss: 0.042582
 >> iter 75000, loss: 0.042512
 >> iter 76000, loss: 0.042608
 >> iter 77000, loss: 0.042530
 >> iter 78000, loss: 0.042625
 >> iter 79000, loss: 0.042562
 >> iter 80000, loss: 0.042646
   Number of active neurons: 5
 >> iter 81000, loss: 0.042578
 >> iter 82000, loss: 0.042671
 >> iter 83000, loss: 0.042595
 >> iter 84000, loss: 0.042693
 >> iter 85000, loss: 0.042617
 >> iter 86000, loss: 0.042726
 >> iter 87000, loss: 0.042644
 >> iter 88000, loss: 0.042751
 >> iter 89000, loss: 0.042671
 >> iter 90000, loss: 0.042779
   Number of active neurons: 5
 >> iter 91000, loss: 0.042695
 >> iter 92000, loss: 0.042811
 >> iter 93000, loss: 0.042722
 >> iter 94000, loss: 0.042833
 >> iter 95000, loss: 0.042761
 >> iter 96000, loss: 0.042860
 >> iter 97000, loss: 0.042796
 >> iter 98000, loss: 0.042890
 >> iter 99000, loss: 0.042830
 >> iter 100000, loss: 0.042924
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.594065
 >> iter 2000, loss: 10.500327
 >> iter 3000, loss: 8.626300
 >> iter 4000, loss: 7.901406
 >> iter 5000, loss: 7.666147
 >> iter 6000, loss: 7.603644
 >> iter 7000, loss: 7.592393
 >> iter 8000, loss: 7.241917
 >> iter 9000, loss: 3.354877
 >> iter 10000, loss: 1.301659
   Number of active neurons: 5
 >> iter 11000, loss: 0.526763
 >> iter 12000, loss: 0.234484
 >> iter 13000, loss: 0.123840
 >> iter 14000, loss: 0.081176
 >> iter 15000, loss: 0.064622
 >> iter 16000, loss: 0.057854
 >> iter 17000, loss: 0.055271
 >> iter 18000, loss: 0.054062
 >> iter 19000, loss: 0.053666
 >> iter 20000, loss: 0.053169
   Number of active neurons: 4
 >> iter 21000, loss: 0.052911
 >> iter 22000, loss: 0.052534
 >> iter 23000, loss: 0.052047
 >> iter 24000, loss: 0.051429
 >> iter 25000, loss: 0.050789
 >> iter 26000, loss: 0.050155
 >> iter 27000, loss: 0.049497
 >> iter 28000, loss: 0.048997
 >> iter 29000, loss: 0.048505
 >> iter 30000, loss: 0.048170
   Number of active neurons: 5
 >> iter 31000, loss: 0.047787
 >> iter 32000, loss: 0.047535
 >> iter 33000, loss: 0.047114
 >> iter 34000, loss: 0.046759
 >> iter 35000, loss: 0.046382
 >> iter 36000, loss: 0.046156
 >> iter 37000, loss: 0.045870
 >> iter 38000, loss: 0.045743
 >> iter 39000, loss: 0.045347
 >> iter 40000, loss: 0.045111
   Number of active neurons: 5
 >> iter 41000, loss: 0.044740
 >> iter 42000, loss: 0.044578
 >> iter 43000, loss: 0.044292
 >> iter 44000, loss: 0.044190
 >> iter 45000, loss: 0.043949
 >> iter 46000, loss: 0.043895
 >> iter 47000, loss: 0.043687
 >> iter 48000, loss: 0.043651
 >> iter 49000, loss: 0.043479
 >> iter 50000, loss: 0.043474
   Number of active neurons: 5
 >> iter 51000, loss: 0.043295
 >> iter 52000, loss: 0.043175
 >> iter 53000, loss: 0.042881
 >> iter 54000, loss: 0.042819
 >> iter 55000, loss: 0.042594
 >> iter 56000, loss: 0.042591
 >> iter 57000, loss: 0.042344
 >> iter 58000, loss: 0.042352
 >> iter 59000, loss: 0.042167
 >> iter 60000, loss: 0.042240
   Number of active neurons: 5
 >> iter 61000, loss: 0.042104
 >> iter 62000, loss: 0.042207
 >> iter 63000, loss: 0.042093
 >> iter 64000, loss: 0.042215
 >> iter 65000, loss: 0.042111
 >> iter 66000, loss: 0.042233
 >> iter 67000, loss: 0.042127
 >> iter 68000, loss: 0.042255
 >> iter 69000, loss: 0.042148
 >> iter 70000, loss: 0.042273
   Number of active neurons: 5
 >> iter 71000, loss: 0.042171
 >> iter 72000, loss: 0.042295
 >> iter 73000, loss: 0.042191
 >> iter 74000, loss: 0.042311
 >> iter 75000, loss: 0.042208
 >> iter 76000, loss: 0.042328
 >> iter 77000, loss: 0.042216
 >> iter 78000, loss: 0.042336
 >> iter 79000, loss: 0.042240
 >> iter 80000, loss: 0.042345
   Number of active neurons: 5
 >> iter 81000, loss: 0.042242
 >> iter 82000, loss: 0.042356
 >> iter 83000, loss: 0.042245
 >> iter 84000, loss: 0.042362
 >> iter 85000, loss: 0.042250
 >> iter 86000, loss: 0.042378
 >> iter 87000, loss: 0.042259
 >> iter 88000, loss: 0.042385
 >> iter 89000, loss: 0.042267
 >> iter 90000, loss: 0.042394
   Number of active neurons: 5
 >> iter 91000, loss: 0.042270
 >> iter 92000, loss: 0.042404
 >> iter 93000, loss: 0.042275
 >> iter 94000, loss: 0.042402
 >> iter 95000, loss: 0.042290
 >> iter 96000, loss: 0.042406
 >> iter 97000, loss: 0.042299
 >> iter 98000, loss: 0.042409
 >> iter 99000, loss: 0.042293
 >> iter 100000, loss: 0.042392
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.802765
 >> iter 2000, loss: 10.587861
 >> iter 3000, loss: 8.662765
 >> iter 4000, loss: 7.917529
 >> iter 5000, loss: 7.669912
 >> iter 6000, loss: 7.600486
 >> iter 7000, loss: 7.381334
 >> iter 8000, loss: 3.852910
 >> iter 9000, loss: 1.479682
 >> iter 10000, loss: 0.587132
   Number of active neurons: 6
 >> iter 11000, loss: 0.252663
 >> iter 12000, loss: 0.126583
 >> iter 13000, loss: 0.078676
 >> iter 14000, loss: 0.059959
 >> iter 15000, loss: 0.052502
 >> iter 16000, loss: 0.049225
 >> iter 17000, loss: 0.047828
 >> iter 18000, loss: 0.046989
 >> iter 19000, loss: 0.046564
 >> iter 20000, loss: 0.046164
   Number of active neurons: 5
 >> iter 21000, loss: 0.045901
 >> iter 22000, loss: 0.045616
 >> iter 23000, loss: 0.045386
 >> iter 24000, loss: 0.045104
 >> iter 25000, loss: 0.044835
 >> iter 26000, loss: 0.044567
 >> iter 27000, loss: 0.044256
 >> iter 28000, loss: 0.043997
 >> iter 29000, loss: 0.043740
 >> iter 30000, loss: 0.043581
   Number of active neurons: 5
 >> iter 31000, loss: 0.043376
 >> iter 32000, loss: 0.043256
 >> iter 33000, loss: 0.043077
 >> iter 34000, loss: 0.042967
 >> iter 35000, loss: 0.042799
 >> iter 36000, loss: 0.042705
 >> iter 37000, loss: 0.042533
 >> iter 38000, loss: 0.042479
 >> iter 39000, loss: 0.042289
 >> iter 40000, loss: 0.042244
   Number of active neurons: 5
 >> iter 41000, loss: 0.042064
 >> iter 42000, loss: 0.042015
 >> iter 43000, loss: 0.041848
 >> iter 44000, loss: 0.041800
 >> iter 45000, loss: 0.041633
 >> iter 46000, loss: 0.041590
 >> iter 47000, loss: 0.041422
 >> iter 48000, loss: 0.041320
 >> iter 49000, loss: 0.041076
 >> iter 50000, loss: 0.040983
   Number of active neurons: 5
 >> iter 51000, loss: 0.040784
 >> iter 52000, loss: 0.040605
 >> iter 53000, loss: 0.040294
 >> iter 54000, loss: 0.040241
 >> iter 55000, loss: 0.040013
 >> iter 56000, loss: 0.040062
 >> iter 57000, loss: 0.039866
 >> iter 58000, loss: 0.039954
 >> iter 59000, loss: 0.039757
 >> iter 60000, loss: 0.039853
   Number of active neurons: 5
 >> iter 61000, loss: 0.039651
 >> iter 62000, loss: 0.039745
 >> iter 63000, loss: 0.039534
 >> iter 64000, loss: 0.039640
 >> iter 65000, loss: 0.039419
 >> iter 66000, loss: 0.039521
 >> iter 67000, loss: 0.039290
 >> iter 68000, loss: 0.039401
 >> iter 69000, loss: 0.039163
 >> iter 70000, loss: 0.039270
   Number of active neurons: 5
 >> iter 71000, loss: 0.039029
 >> iter 72000, loss: 0.039142
 >> iter 73000, loss: 0.038897
 >> iter 74000, loss: 0.039009
 >> iter 75000, loss: 0.038759
 >> iter 76000, loss: 0.038875
 >> iter 77000, loss: 0.038615
 >> iter 78000, loss: 0.038736
 >> iter 79000, loss: 0.038489
 >> iter 80000, loss: 0.038603
   Number of active neurons: 5
 >> iter 81000, loss: 0.038343
 >> iter 82000, loss: 0.038471
 >> iter 83000, loss: 0.038196
 >> iter 84000, loss: 0.038334
 >> iter 85000, loss: 0.038054
 >> iter 86000, loss: 0.038206
 >> iter 87000, loss: 0.037917
 >> iter 88000, loss: 0.038073
 >> iter 89000, loss: 0.037781
 >> iter 90000, loss: 0.037858
   Number of active neurons: 5
 >> iter 91000, loss: 0.037423
 >> iter 92000, loss: 0.037490
 >> iter 93000, loss: 0.037129
 >> iter 94000, loss: 0.037264
 >> iter 95000, loss: 0.036974
 >> iter 96000, loss: 0.037145
 >> iter 97000, loss: 0.036874
 >> iter 98000, loss: 0.037060
 >> iter 99000, loss: 0.036803
 >> iter 100000, loss: 0.036995
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.671273
 >> iter 2000, loss: 10.547662
 >> iter 3000, loss: 8.661122
 >> iter 4000, loss: 7.951404
 >> iter 5000, loss: 7.719653
 >> iter 6000, loss: 7.607044
 >> iter 7000, loss: 7.429757
 >> iter 8000, loss: 7.122586
 >> iter 9000, loss: 4.237077
 >> iter 10000, loss: 1.619692
   Number of active neurons: 6
 >> iter 11000, loss: 0.636829
 >> iter 12000, loss: 0.269526
 >> iter 13000, loss: 0.132314
 >> iter 14000, loss: 0.080683
 >> iter 15000, loss: 0.061327
 >> iter 16000, loss: 0.053812
 >> iter 17000, loss: 0.050972
 >> iter 18000, loss: 0.049572
 >> iter 19000, loss: 0.048859
 >> iter 20000, loss: 0.048101
   Number of active neurons: 6
 >> iter 21000, loss: 0.047488
 >> iter 22000, loss: 0.046666
 >> iter 23000, loss: 0.045969
 >> iter 24000, loss: 0.045321
 >> iter 25000, loss: 0.044716
 >> iter 26000, loss: 0.044189
 >> iter 27000, loss: 0.043809
 >> iter 28000, loss: 0.043514
 >> iter 29000, loss: 0.043211
 >> iter 30000, loss: 0.042939
   Number of active neurons: 6
 >> iter 31000, loss: 0.042693
 >> iter 32000, loss: 0.042510
 >> iter 33000, loss: 0.042325
 >> iter 34000, loss: 0.042180
 >> iter 35000, loss: 0.042016
 >> iter 36000, loss: 0.041895
 >> iter 37000, loss: 0.041726
 >> iter 38000, loss: 0.041647
 >> iter 39000, loss: 0.041458
 >> iter 40000, loss: 0.041392
   Number of active neurons: 6
 >> iter 41000, loss: 0.041208
 >> iter 42000, loss: 0.041145
 >> iter 43000, loss: 0.040972
 >> iter 44000, loss: 0.040915
 >> iter 45000, loss: 0.040739
 >> iter 46000, loss: 0.040696
 >> iter 47000, loss: 0.040518
 >> iter 48000, loss: 0.040475
 >> iter 49000, loss: 0.040305
 >> iter 50000, loss: 0.040280
   Number of active neurons: 6
 >> iter 51000, loss: 0.040094
 >> iter 52000, loss: 0.039963
 >> iter 53000, loss: 0.039614
 >> iter 54000, loss: 0.039534
 >> iter 55000, loss: 0.039260
 >> iter 56000, loss: 0.039287
 >> iter 57000, loss: 0.039050
 >> iter 58000, loss: 0.039124
 >> iter 59000, loss: 0.038892
 >> iter 60000, loss: 0.038982
   Number of active neurons: 6
 >> iter 61000, loss: 0.038747
 >> iter 62000, loss: 0.038841
 >> iter 63000, loss: 0.038600
 >> iter 64000, loss: 0.038709
 >> iter 65000, loss: 0.038460
 >> iter 66000, loss: 0.038571
 >> iter 67000, loss: 0.038314
 >> iter 68000, loss: 0.038438
 >> iter 69000, loss: 0.038177
 >> iter 70000, loss: 0.038300
   Number of active neurons: 6
 >> iter 71000, loss: 0.038038
 >> iter 72000, loss: 0.038170
 >> iter 73000, loss: 0.037905
 >> iter 74000, loss: 0.038040
 >> iter 75000, loss: 0.037773
 >> iter 76000, loss: 0.037913
 >> iter 77000, loss: 0.037640
 >> iter 78000, loss: 0.037788
 >> iter 79000, loss: 0.037527
 >> iter 80000, loss: 0.037626
   Number of active neurons: 6
 >> iter 81000, loss: 0.037223
 >> iter 82000, loss: 0.037254
 >> iter 83000, loss: 0.036902
 >> iter 84000, loss: 0.037023
 >> iter 85000, loss: 0.036735
 >> iter 86000, loss: 0.036908
 >> iter 87000, loss: 0.036643
 >> iter 88000, loss: 0.036837
 >> iter 89000, loss: 0.036584
 >> iter 90000, loss: 0.036789
   Number of active neurons: 6
 >> iter 91000, loss: 0.036538
 >> iter 92000, loss: 0.036757
 >> iter 93000, loss: 0.036505
 >> iter 94000, loss: 0.036721
 >> iter 95000, loss: 0.036487
 >> iter 96000, loss: 0.036706
 >> iter 97000, loss: 0.036468
 >> iter 98000, loss: 0.036685
 >> iter 99000, loss: 0.036452
 >> iter 100000, loss: 0.036666
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.660804
 >> iter 2000, loss: 10.527492
 >> iter 3000, loss: 8.634285
 >> iter 4000, loss: 7.912078
 >> iter 5000, loss: 7.700192
 >> iter 6000, loss: 7.842497
 >> iter 7000, loss: 8.282706
 >> iter 8000, loss: 7.880275
 >> iter 9000, loss: 8.411655
 >> iter 10000, loss: 8.236903
   Number of active neurons: 5
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 5
 >> iter 11000, loss: 8.468789
 >> iter 12000, loss: 7.013238
 >> iter 13000, loss: 6.027769
 >> iter 14000, loss: 6.175551
 >> iter 15000, loss: 6.167129
 >> iter 16000, loss: 5.935821
 >> iter 17000, loss: 5.753325
 >> iter 18000, loss: 5.565885
 >> iter 19000, loss: 5.283389
 >> iter 20000, loss: 5.205489
   Number of active neurons: 5
 >> iter 21000, loss: 4.976070
 >> iter 22000, loss: 4.883708
 >> iter 23000, loss: 4.396072
 >> iter 24000, loss: 4.233972
 >> iter 25000, loss: 3.420750
 >> iter 26000, loss: 2.194293
 >> iter 27000, loss: 1.390816
 >> iter 28000, loss: 0.846602
 >> iter 29000, loss: 0.468528
 >> iter 30000, loss: 0.403996
   Number of active neurons: 8
 >> iter 31000, loss: 0.462237
 >> iter 32000, loss: 0.252551
 >> iter 33000, loss: 0.320144
 >> iter 34000, loss: 0.189917
 >> iter 35000, loss: 0.314364
 >> iter 36000, loss: 0.185888
 >> iter 37000, loss: 0.621105
 >> iter 38000, loss: 0.384712
 >> iter 39000, loss: 0.250096
 >> iter 40000, loss: 0.383656
   Number of active neurons: 8
 >> iter 41000, loss: 0.495068
 >> iter 42000, loss: 0.470817
 >> iter 43000, loss: 0.543430
 >> iter 44000, loss: 0.904143
 >> iter 45000, loss: 0.425207
 >> iter 46000, loss: 0.534278
 >> iter 47000, loss: 0.482458
 >> iter 48000, loss: 0.383408
 >> iter 49000, loss: 0.276408
 >> iter 50000, loss: 0.289029
   Number of active neurons: 7
 >> iter 51000, loss: 2.809961
 >> iter 52000, loss: 1.397747
 >> iter 53000, loss: 0.685326
 >> iter 54000, loss: 0.667119
 >> iter 55000, loss: 0.404463
 >> iter 56000, loss: 0.348263
 >> iter 57000, loss: 1.412015
 >> iter 58000, loss: 0.860344
 >> iter 59000, loss: 0.537583
 >> iter 60000, loss: 0.400146
   Number of active neurons: 8
 >> iter 61000, loss: 0.309017
 >> iter 62000, loss: 0.195593
 >> iter 63000, loss: 0.118962
 >> iter 64000, loss: 0.119599
 >> iter 65000, loss: 0.087808
 >> iter 66000, loss: 0.075860
 >> iter 67000, loss: 0.069839
 >> iter 68000, loss: 0.067559
 >> iter 69000, loss: 0.065502
 >> iter 70000, loss: 0.064092
   Number of active neurons: 7
 >> iter 71000, loss: 0.062667
 >> iter 72000, loss: 0.061710
 >> iter 73000, loss: 0.060828
 >> iter 74000, loss: 0.060345
 >> iter 75000, loss: 0.059904
 >> iter 76000, loss: 0.060019
 >> iter 77000, loss: 0.060166
 >> iter 78000, loss: 0.060422
 >> iter 79000, loss: 0.060430
 >> iter 80000, loss: 0.060566
   Number of active neurons: 7
 >> iter 81000, loss: 0.060442
 >> iter 82000, loss: 0.060327
 >> iter 83000, loss: 0.059979
 >> iter 84000, loss: 0.059713
 >> iter 85000, loss: 0.059319
 >> iter 86000, loss: 0.059129
 >> iter 87000, loss: 0.058954
 >> iter 88000, loss: 0.058937
 >> iter 89000, loss: 0.058720
 >> iter 90000, loss: 0.058604
   Number of active neurons: 7
 >> iter 91000, loss: 0.058166
 >> iter 92000, loss: 0.057537
 >> iter 93000, loss: 0.056628
 >> iter 94000, loss: 0.055716
 >> iter 95000, loss: 0.054715
 >> iter 96000, loss: 0.054043
 >> iter 97000, loss: 0.053488
 >> iter 98000, loss: 0.053052
 >> iter 99000, loss: 0.052537
 >> iter 100000, loss: 0.051923
   Number of active neurons: 7
 >> iter 101000, loss: 0.051199
 >> iter 102000, loss: 0.050560
 >> iter 103000, loss: 0.049829
 >> iter 104000, loss: 0.049108
 >> iter 105000, loss: 0.048259
 >> iter 106000, loss: 0.047455
 >> iter 107000, loss: 0.046633
 >> iter 108000, loss: 0.045944
 >> iter 109000, loss: 0.045274
 >> iter 110000, loss: 0.044723
   Number of active neurons: 6
 >> iter 111000, loss: 0.044249
 >> iter 112000, loss: 0.043955
 >> iter 113000, loss: 0.043675
 >> iter 114000, loss: 0.043468
 >> iter 115000, loss: 0.043232
 >> iter 116000, loss: 0.043068
 >> iter 117000, loss: 0.042884
 >> iter 118000, loss: 0.042757
 >> iter 119000, loss: 0.042589
 >> iter 120000, loss: 0.042429
   Number of active neurons: 6
 >> iter 121000, loss: 0.042253
 >> iter 122000, loss: 0.042133
 >> iter 123000, loss: 0.041997
 >> iter 124000, loss: 0.041910
 >> iter 125000, loss: 0.041801
 >> iter 126000, loss: 0.041727
 >> iter 127000, loss: 0.041642
 >> iter 128000, loss: 0.041574
 >> iter 129000, loss: 0.041502
 >> iter 130000, loss: 0.041446
   Number of active neurons: 6
 >> iter 131000, loss: 0.041385
 >> iter 132000, loss: 0.041338
 >> iter 133000, loss: 0.041286
 >> iter 134000, loss: 0.041243
 >> iter 135000, loss: 0.041193
 >> iter 136000, loss: 0.041164
 >> iter 137000, loss: 0.041112
 >> iter 138000, loss: 0.041094
 >> iter 139000, loss: 0.041040
 >> iter 140000, loss: 0.041023
   Number of active neurons: 6
 >> iter 141000, loss: 0.040971
 >> iter 142000, loss: 0.040963
 >> iter 143000, loss: 0.040909
 >> iter 144000, loss: 0.040910
 >> iter 145000, loss: 0.040858
 >> iter 146000, loss: 0.040860
 >> iter 147000, loss: 0.040808
 >> iter 148000, loss: 0.040821
 >> iter 149000, loss: 0.040754
 >> iter 150000, loss: 0.040782
   Number of active neurons: 6
 >> iter 151000, loss: 0.040718
 >> iter 152000, loss: 0.040751
 >> iter 153000, loss: 0.040686
 >> iter 154000, loss: 0.040720
 >> iter 155000, loss: 0.040656
 >> iter 156000, loss: 0.040691
 >> iter 157000, loss: 0.040628
 >> iter 158000, loss: 0.040664
 >> iter 159000, loss: 0.040598
 >> iter 160000, loss: 0.040641
   Number of active neurons: 6
 >> iter 161000, loss: 0.040569
 >> iter 162000, loss: 0.040615
 >> iter 163000, loss: 0.040547
 >> iter 164000, loss: 0.040592
 >> iter 165000, loss: 0.040524
 >> iter 166000, loss: 0.040573
 >> iter 167000, loss: 0.040500
 >> iter 168000, loss: 0.040556
 >> iter 169000, loss: 0.040478
 >> iter 170000, loss: 0.040541
   Number of active neurons: 6
 >> iter 171000, loss: 0.040462
 >> iter 172000, loss: 0.040534
 >> iter 173000, loss: 0.040445
 >> iter 174000, loss: 0.040516
 >> iter 175000, loss: 0.040433
 >> iter 176000, loss: 0.040502
 >> iter 177000, loss: 0.040417
 >> iter 178000, loss: 0.040482
 >> iter 179000, loss: 0.040408
 >> iter 180000, loss: 0.040470
   Number of active neurons: 6
 >> iter 181000, loss: 0.040399
 >> iter 182000, loss: 0.040456
 >> iter 183000, loss: 0.040389
 >> iter 184000, loss: 0.040441
 >> iter 185000, loss: 0.040374
 >> iter 186000, loss: 0.040434
 >> iter 187000, loss: 0.040364
 >> iter 188000, loss: 0.040427
 >> iter 189000, loss: 0.040357
 >> iter 190000, loss: 0.040416
   Number of active neurons: 6
 >> iter 191000, loss: 0.040351
 >> iter 192000, loss: 0.040408
 >> iter 193000, loss: 0.040340
 >> iter 194000, loss: 0.040396
 >> iter 195000, loss: 0.040332
 >> iter 196000, loss: 0.040381
 >> iter 197000, loss: 0.040325
 >> iter 198000, loss: 0.040374
 >> iter 199000, loss: 0.040325
 >> iter 200000, loss: 0.040374
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.648217
 >> iter 2000, loss: 10.519108
 >> iter 3000, loss: 8.631833
 >> iter 4000, loss: 7.897342
 >> iter 5000, loss: 7.670858
 >> iter 6000, loss: 7.511679
 >> iter 7000, loss: 7.033424
 >> iter 8000, loss: 6.479443
 >> iter 9000, loss: 5.982167
 >> iter 10000, loss: 5.540319
   Number of active neurons: 4
 >> iter 11000, loss: 5.213686
 >> iter 12000, loss: 4.795643
 >> iter 13000, loss: 4.646089
 >> iter 14000, loss: 4.519084
 >> iter 15000, loss: 4.100697
 >> iter 16000, loss: 3.771915
 >> iter 17000, loss: 3.831030
 >> iter 18000, loss: 3.661178
 >> iter 19000, loss: 2.472165
 >> iter 20000, loss: 0.972521
   Number of active neurons: 4
 >> iter 21000, loss: 0.405817
 >> iter 22000, loss: 0.190946
 >> iter 23000, loss: 0.108175
 >> iter 24000, loss: 0.075492
 >> iter 25000, loss: 0.061852
 >> iter 26000, loss: 0.055627
 >> iter 27000, loss: 0.052497
 >> iter 28000, loss: 0.050696
 >> iter 29000, loss: 0.049499
 >> iter 30000, loss: 0.048503
   Number of active neurons: 4
 >> iter 31000, loss: 0.047749
 >> iter 32000, loss: 0.047033
 >> iter 33000, loss: 0.046543
 >> iter 34000, loss: 0.046044
 >> iter 35000, loss: 0.045747
 >> iter 36000, loss: 0.045348
 >> iter 37000, loss: 0.045092
 >> iter 38000, loss: 0.044821
 >> iter 39000, loss: 0.044722
 >> iter 40000, loss: 0.044517
   Number of active neurons: 4
 >> iter 41000, loss: 0.044473
 >> iter 42000, loss: 0.044344
 >> iter 43000, loss: 0.044329
 >> iter 44000, loss: 0.044204
 >> iter 45000, loss: 0.044162
 >> iter 46000, loss: 0.044031
 >> iter 47000, loss: 0.043953
 >> iter 48000, loss: 0.043789
 >> iter 49000, loss: 0.043657
 >> iter 50000, loss: 0.043459
   Number of active neurons: 4
 >> iter 51000, loss: 0.043330
 >> iter 52000, loss: 0.043152
 >> iter 53000, loss: 0.043026
 >> iter 54000, loss: 0.042860
 >> iter 55000, loss: 0.042697
 >> iter 56000, loss: 0.042408
 >> iter 57000, loss: 0.042142
 >> iter 58000, loss: 0.041936
 >> iter 59000, loss: 0.041812
 >> iter 60000, loss: 0.041717
   Number of active neurons: 4
 >> iter 61000, loss: 0.041658
 >> iter 62000, loss: 0.041607
 >> iter 63000, loss: 0.041568
 >> iter 64000, loss: 0.041529
 >> iter 65000, loss: 0.041494
 >> iter 66000, loss: 0.041455
 >> iter 67000, loss: 0.041414
 >> iter 68000, loss: 0.041380
 >> iter 69000, loss: 0.041342
 >> iter 70000, loss: 0.041273
   Number of active neurons: 4
 >> iter 71000, loss: 0.041095
 >> iter 72000, loss: 0.040867
 >> iter 73000, loss: 0.040677
 >> iter 74000, loss: 0.040539
 >> iter 75000, loss: 0.040448
 >> iter 76000, loss: 0.040381
 >> iter 77000, loss: 0.040344
 >> iter 78000, loss: 0.040312
 >> iter 79000, loss: 0.040300
 >> iter 80000, loss: 0.040285
   Number of active neurons: 4
 >> iter 81000, loss: 0.040279
 >> iter 82000, loss: 0.040282
 >> iter 83000, loss: 0.040277
 >> iter 84000, loss: 0.040285
 >> iter 85000, loss: 0.040285
 >> iter 86000, loss: 0.040289
 >> iter 87000, loss: 0.040291
 >> iter 88000, loss: 0.040298
 >> iter 89000, loss: 0.040293
 >> iter 90000, loss: 0.040305
   Number of active neurons: 4
 >> iter 91000, loss: 0.040297
 >> iter 92000, loss: 0.040312
 >> iter 93000, loss: 0.040301
 >> iter 94000, loss: 0.040314
 >> iter 95000, loss: 0.040302
 >> iter 96000, loss: 0.040315
 >> iter 97000, loss: 0.040308
 >> iter 98000, loss: 0.040319
 >> iter 99000, loss: 0.040317
 >> iter 100000, loss: 0.040325
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.610366
 >> iter 2000, loss: 10.493830
 >> iter 3000, loss: 8.613147
 >> iter 4000, loss: 7.889864
 >> iter 5000, loss: 7.647445
 >> iter 6000, loss: 7.527241
 >> iter 7000, loss: 7.520986
 >> iter 8000, loss: 7.514515
 >> iter 9000, loss: 7.482926
 >> iter 10000, loss: 7.388475
   Number of active neurons: 3
 >> iter 11000, loss: 7.262074
 >> iter 12000, loss: 7.104666
 >> iter 13000, loss: 6.890942
 >> iter 14000, loss: 6.767252
 >> iter 15000, loss: 6.683875
 >> iter 16000, loss: 6.674790
 >> iter 17000, loss: 6.680044
 >> iter 18000, loss: 6.761037
 >> iter 19000, loss: 6.813764
 >> iter 20000, loss: 6.761420
   Number of active neurons: 3
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 3
 >> iter 21000, loss: 6.743848
 >> iter 22000, loss: 7.017546
 >> iter 23000, loss: 7.282711
 >> iter 24000, loss: 6.907084
 >> iter 25000, loss: 6.316275
 >> iter 26000, loss: 5.791746
 >> iter 27000, loss: 2.896337
 >> iter 28000, loss: 1.265315
 >> iter 29000, loss: 0.975438
 >> iter 30000, loss: 0.542668
   Number of active neurons: 6
 >> iter 31000, loss: 0.240934
 >> iter 32000, loss: 0.119173
 >> iter 33000, loss: 0.071249
 >> iter 34000, loss: 0.052541
 >> iter 35000, loss: 0.045375
 >> iter 36000, loss: 0.042360
 >> iter 37000, loss: 0.041250
 >> iter 38000, loss: 0.040751
 >> iter 39000, loss: 0.040551
 >> iter 40000, loss: 0.040455
   Number of active neurons: 6
 >> iter 41000, loss: 0.040369
 >> iter 42000, loss: 0.040274
 >> iter 43000, loss: 0.040232
 >> iter 44000, loss: 0.040381
 >> iter 45000, loss: 0.040519
 >> iter 46000, loss: 0.040609
 >> iter 47000, loss: 0.040438
 >> iter 48000, loss: 0.040240
 >> iter 49000, loss: 0.039939
 >> iter 50000, loss: 0.039644
   Number of active neurons: 6
 >> iter 51000, loss: 0.039324
 >> iter 52000, loss: 0.039178
 >> iter 53000, loss: 0.038959
 >> iter 54000, loss: 0.038959
 >> iter 55000, loss: 0.038770
 >> iter 56000, loss: 0.038845
 >> iter 57000, loss: 0.038674
 >> iter 58000, loss: 0.038808
 >> iter 59000, loss: 0.038646
 >> iter 60000, loss: 0.038810
   Number of active neurons: 6
 >> iter 61000, loss: 0.038627
 >> iter 62000, loss: 0.038787
 >> iter 63000, loss: 0.038564
 >> iter 64000, loss: 0.038715
 >> iter 65000, loss: 0.038442
 >> iter 66000, loss: 0.038573
 >> iter 67000, loss: 0.038265
 >> iter 68000, loss: 0.038377
 >> iter 69000, loss: 0.038053
 >> iter 70000, loss: 0.038161
   Number of active neurons: 6
 >> iter 71000, loss: 0.037846
 >> iter 72000, loss: 0.037968
 >> iter 73000, loss: 0.037666
 >> iter 74000, loss: 0.037802
 >> iter 75000, loss: 0.037512
 >> iter 76000, loss: 0.037657
 >> iter 77000, loss: 0.037373
 >> iter 78000, loss: 0.037525
 >> iter 79000, loss: 0.037265
 >> iter 80000, loss: 0.037411
   Number of active neurons: 6
 >> iter 81000, loss: 0.037151
 >> iter 82000, loss: 0.037307
 >> iter 83000, loss: 0.037042
 >> iter 84000, loss: 0.037207
 >> iter 85000, loss: 0.036949
 >> iter 86000, loss: 0.037086
 >> iter 87000, loss: 0.036718
 >> iter 88000, loss: 0.036803
 >> iter 89000, loss: 0.036494
 >> iter 90000, loss: 0.036651
   Number of active neurons: 6
 >> iter 91000, loss: 0.036387
 >> iter 92000, loss: 0.036587
 >> iter 93000, loss: 0.036292
 >> iter 94000, loss: 0.036454
 >> iter 95000, loss: 0.036200
 >> iter 96000, loss: 0.036412
 >> iter 97000, loss: 0.036182
 >> iter 98000, loss: 0.036408
 >> iter 99000, loss: 0.036190
 >> iter 100000, loss: 0.036416
   Number of active neurons: 6
 >> iter 101000, loss: 0.036198
 >> iter 102000, loss: 0.036425
 >> iter 103000, loss: 0.036206
 >> iter 104000, loss: 0.036431
 >> iter 105000, loss: 0.036207
 >> iter 106000, loss: 0.036424
 >> iter 107000, loss: 0.036212
 >> iter 108000, loss: 0.036431
 >> iter 109000, loss: 0.036210
 >> iter 110000, loss: 0.036429
   Number of active neurons: 6
 >> iter 111000, loss: 0.036222
 >> iter 112000, loss: 0.036425
 >> iter 113000, loss: 0.036223
 >> iter 114000, loss: 0.036422
 >> iter 115000, loss: 0.036226
 >> iter 116000, loss: 0.036414
 >> iter 117000, loss: 0.036224
 >> iter 118000, loss: 0.036415
 >> iter 119000, loss: 0.036220
 >> iter 120000, loss: 0.036406
   Number of active neurons: 6
 >> iter 121000, loss: 0.036216
 >> iter 122000, loss: 0.036402
 >> iter 123000, loss: 0.036212
 >> iter 124000, loss: 0.036392
 >> iter 125000, loss: 0.036211
 >> iter 126000, loss: 0.036383
 >> iter 127000, loss: 0.036207
 >> iter 128000, loss: 0.036374
 >> iter 129000, loss: 0.036204
 >> iter 130000, loss: 0.036366
   Number of active neurons: 6
 >> iter 131000, loss: 0.036201
 >> iter 132000, loss: 0.036369
 >> iter 133000, loss: 0.036197
 >> iter 134000, loss: 0.036359
 >> iter 135000, loss: 0.036188
 >> iter 136000, loss: 0.036358
 >> iter 137000, loss: 0.036181
 >> iter 138000, loss: 0.036354
 >> iter 139000, loss: 0.036171
 >> iter 140000, loss: 0.036345
   Number of active neurons: 6
 >> iter 141000, loss: 0.036162
 >> iter 142000, loss: 0.036342
 >> iter 143000, loss: 0.036152
 >> iter 144000, loss: 0.036336
 >> iter 145000, loss: 0.036145
 >> iter 146000, loss: 0.036328
 >> iter 147000, loss: 0.036134
 >> iter 148000, loss: 0.036325
 >> iter 149000, loss: 0.036117
 >> iter 150000, loss: 0.036321
   Number of active neurons: 6
 >> iter 151000, loss: 0.036107
 >> iter 152000, loss: 0.036318
 >> iter 153000, loss: 0.036104
 >> iter 154000, loss: 0.036319
 >> iter 155000, loss: 0.036095
 >> iter 156000, loss: 0.036307
 >> iter 157000, loss: 0.036092
 >> iter 158000, loss: 0.036300
 >> iter 159000, loss: 0.036082
 >> iter 160000, loss: 0.036299
   Number of active neurons: 6
 >> iter 161000, loss: 0.036068
 >> iter 162000, loss: 0.036295
 >> iter 163000, loss: 0.036061
 >> iter 164000, loss: 0.036291
 >> iter 165000, loss: 0.036055
 >> iter 166000, loss: 0.036284
 >> iter 167000, loss: 0.036046
 >> iter 168000, loss: 0.036278
 >> iter 169000, loss: 0.036032
 >> iter 170000, loss: 0.036272
   Number of active neurons: 6
 >> iter 171000, loss: 0.036029
 >> iter 172000, loss: 0.036285
 >> iter 173000, loss: 0.036021
 >> iter 174000, loss: 0.036267
 >> iter 175000, loss: 0.036029
 >> iter 176000, loss: 0.036265
 >> iter 177000, loss: 0.036020
 >> iter 178000, loss: 0.036249
 >> iter 179000, loss: 0.036015
 >> iter 180000, loss: 0.036241
   Number of active neurons: 6
 >> iter 181000, loss: 0.036010
 >> iter 182000, loss: 0.036228
 >> iter 183000, loss: 0.036003
 >> iter 184000, loss: 0.036219
 >> iter 185000, loss: 0.035993
 >> iter 186000, loss: 0.036210
 >> iter 187000, loss: 0.035990
 >> iter 188000, loss: 0.036202
 >> iter 189000, loss: 0.035986
 >> iter 190000, loss: 0.036189
   Number of active neurons: 6
 >> iter 191000, loss: 0.035983
 >> iter 192000, loss: 0.036182
 >> iter 193000, loss: 0.035971
 >> iter 194000, loss: 0.036169
 >> iter 195000, loss: 0.035964
 >> iter 196000, loss: 0.036159
 >> iter 197000, loss: 0.035960
 >> iter 198000, loss: 0.036153
 >> iter 199000, loss: 0.035959
 >> iter 200000, loss: 0.036153
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.622404
 >> iter 2000, loss: 10.518594
 >> iter 3000, loss: 8.646760
 >> iter 4000, loss: 7.943600
 >> iter 5000, loss: 7.710381
 >> iter 6000, loss: 7.575971
 >> iter 7000, loss: 7.126273
 >> iter 8000, loss: 3.188470
 >> iter 9000, loss: 1.280137
 >> iter 10000, loss: 0.545911
   Number of active neurons: 5
 >> iter 11000, loss: 0.263943
 >> iter 12000, loss: 0.152647
 >> iter 13000, loss: 0.108161
 >> iter 14000, loss: 0.088373
 >> iter 15000, loss: 0.079746
 >> iter 16000, loss: 0.074560
 >> iter 17000, loss: 0.072242
 >> iter 18000, loss: 0.070053
 >> iter 19000, loss: 0.069104
 >> iter 20000, loss: 0.067702
   Number of active neurons: 5
 >> iter 21000, loss: 0.067123
 >> iter 22000, loss: 0.065950
 >> iter 23000, loss: 0.065401
 >> iter 24000, loss: 0.064401
 >> iter 25000, loss: 0.063991
 >> iter 26000, loss: 0.063210
 >> iter 27000, loss: 0.062829
 >> iter 28000, loss: 0.062066
 >> iter 29000, loss: 0.061739
 >> iter 30000, loss: 0.061122
   Number of active neurons: 5
 >> iter 31000, loss: 0.060910
 >> iter 32000, loss: 0.060446
 >> iter 33000, loss: 0.060187
 >> iter 34000, loss: 0.059608
 >> iter 35000, loss: 0.059375
 >> iter 36000, loss: 0.058919
 >> iter 37000, loss: 0.058759
 >> iter 38000, loss: 0.058343
 >> iter 39000, loss: 0.058246
 >> iter 40000, loss: 0.057897
   Number of active neurons: 5
 >> iter 41000, loss: 0.057883
 >> iter 42000, loss: 0.057570
 >> iter 43000, loss: 0.057552
 >> iter 44000, loss: 0.057199
 >> iter 45000, loss: 0.057048
 >> iter 46000, loss: 0.056611
 >> iter 47000, loss: 0.056525
 >> iter 48000, loss: 0.056175
 >> iter 49000, loss: 0.056244
 >> iter 50000, loss: 0.055972
   Number of active neurons: 4
 >> iter 51000, loss: 0.056047
 >> iter 52000, loss: 0.055721
 >> iter 53000, loss: 0.055686
 >> iter 54000, loss: 0.055266
 >> iter 55000, loss: 0.055297
 >> iter 56000, loss: 0.054929
 >> iter 57000, loss: 0.054983
 >> iter 58000, loss: 0.054666
 >> iter 59000, loss: 0.054741
 >> iter 60000, loss: 0.054500
   Number of active neurons: 4
 >> iter 61000, loss: 0.054598
 >> iter 62000, loss: 0.054372
 >> iter 63000, loss: 0.054485
 >> iter 64000, loss: 0.054302
 >> iter 65000, loss: 0.054401
 >> iter 66000, loss: 0.054215
 >> iter 67000, loss: 0.054313
 >> iter 68000, loss: 0.054158
 >> iter 69000, loss: 0.054267
 >> iter 70000, loss: 0.054119
   Number of active neurons: 4
 >> iter 71000, loss: 0.054221
 >> iter 72000, loss: 0.054079
 >> iter 73000, loss: 0.054198
 >> iter 74000, loss: 0.054039
 >> iter 75000, loss: 0.054171
 >> iter 76000, loss: 0.054009
 >> iter 77000, loss: 0.054151
 >> iter 78000, loss: 0.053992
 >> iter 79000, loss: 0.054124
 >> iter 80000, loss: 0.053981
   Number of active neurons: 4
 >> iter 81000, loss: 0.054092
 >> iter 82000, loss: 0.053961
 >> iter 83000, loss: 0.054085
 >> iter 84000, loss: 0.053937
 >> iter 85000, loss: 0.054062
 >> iter 86000, loss: 0.053924
 >> iter 87000, loss: 0.054055
 >> iter 88000, loss: 0.053922
 >> iter 89000, loss: 0.054023
 >> iter 90000, loss: 0.053912
   Number of active neurons: 4
 >> iter 91000, loss: 0.054012
 >> iter 92000, loss: 0.053908
 >> iter 93000, loss: 0.053995
 >> iter 94000, loss: 0.053882
 >> iter 95000, loss: 0.053982
 >> iter 96000, loss: 0.053876
 >> iter 97000, loss: 0.053972
 >> iter 98000, loss: 0.053878
 >> iter 99000, loss: 0.053952
 >> iter 100000, loss: 0.053890
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.621018
 >> iter 2000, loss: 10.519065
 >> iter 3000, loss: 8.639186
 >> iter 4000, loss: 7.909394
 >> iter 5000, loss: 7.658149
 >> iter 6000, loss: 7.367696
 >> iter 7000, loss: 6.112899
 >> iter 8000, loss: 2.477888
 >> iter 9000, loss: 1.002546
 >> iter 10000, loss: 0.433862
   Number of active neurons: 5
 >> iter 11000, loss: 0.214661
 >> iter 12000, loss: 0.127456
 >> iter 13000, loss: 0.093037
 >> iter 14000, loss: 0.077805
 >> iter 15000, loss: 0.072388
 >> iter 16000, loss: 0.080306
 >> iter 17000, loss: 0.089340
 >> iter 18000, loss: 0.085550
 >> iter 19000, loss: 0.225802
 >> iter 20000, loss: 0.125266
   Number of active neurons: 5
 >> iter 21000, loss: 0.105995
 >> iter 22000, loss: 0.126420
 >> iter 23000, loss: 0.550514
 >> iter 24000, loss: 0.287250
 >> iter 25000, loss: 0.149224
 >> iter 26000, loss: 0.199105
 >> iter 27000, loss: 0.180052
 >> iter 28000, loss: 0.119269
 >> iter 29000, loss: 0.087451
 >> iter 30000, loss: 0.088379
   Number of active neurons: 4
 >> iter 31000, loss: 0.599489
 >> iter 32000, loss: 0.273519
 >> iter 33000, loss: 0.151712
 >> iter 34000, loss: 0.220349
 >> iter 35000, loss: 0.456530
 >> iter 36000, loss: 0.472670
 >> iter 37000, loss: 0.550623
 >> iter 38000, loss: 0.395195
 >> iter 39000, loss: 0.283040
 >> iter 40000, loss: 0.270308
   Number of active neurons: 4
 >> iter 41000, loss: 0.429296
 >> iter 42000, loss: 0.355653
 >> iter 43000, loss: 0.451486
 >> iter 44000, loss: 0.409882
 >> iter 45000, loss: 0.388174
 >> iter 46000, loss: 0.250645
 >> iter 47000, loss: 0.454591
 >> iter 48000, loss: 0.389478
 >> iter 49000, loss: 0.209601
 >> iter 50000, loss: 0.158766
   Number of active neurons: 4
 >> iter 51000, loss: 0.418180
 >> iter 52000, loss: 1.318818
 >> iter 53000, loss: 0.683052
 >> iter 54000, loss: 0.360974
 >> iter 55000, loss: 0.212828
 >> iter 56000, loss: 0.172048
 >> iter 57000, loss: 0.110229
 >> iter 58000, loss: 0.136529
 >> iter 59000, loss: 0.097518
 >> iter 60000, loss: 0.101042
   Number of active neurons: 4
 >> iter 61000, loss: 0.228644
 >> iter 62000, loss: 0.435207
 >> iter 63000, loss: 0.427234
 >> iter 64000, loss: 0.391764
 >> iter 65000, loss: 0.393885
 >> iter 66000, loss: 1.856087
 >> iter 67000, loss: 0.778858
 >> iter 68000, loss: 0.363369
 >> iter 69000, loss: 0.227816
 >> iter 70000, loss: 0.322683
   Number of active neurons: 4
 >> iter 71000, loss: 0.198622
 >> iter 72000, loss: 0.142498
 >> iter 73000, loss: 0.115711
 >> iter 74000, loss: 0.261552
 >> iter 75000, loss: 0.422449
 >> iter 76000, loss: 0.383973
 >> iter 77000, loss: 0.224407
 >> iter 78000, loss: 0.313866
 >> iter 79000, loss: 0.287052
 >> iter 80000, loss: 0.336163
   Number of active neurons: 4
 >> iter 81000, loss: 0.737193
 >> iter 82000, loss: 0.718241
 >> iter 83000, loss: 0.371925
 >> iter 84000, loss: 0.239471
 >> iter 85000, loss: 0.249056
 >> iter 86000, loss: 0.291308
 >> iter 87000, loss: 0.303243
 >> iter 88000, loss: 0.322389
 >> iter 89000, loss: 0.216815
 >> iter 90000, loss: 0.820840
   Number of active neurons: 5
 >> iter 91000, loss: 6.948966
 >> iter 92000, loss: 7.048165
 >> iter 93000, loss: 6.604278
 >> iter 94000, loss: 6.177263
 >> iter 95000, loss: 5.869305
 >> iter 96000, loss: 5.780368
 >> iter 97000, loss: 4.567954
 >> iter 98000, loss: 1.834424
 >> iter 99000, loss: 0.832428
 >> iter 100000, loss: 0.366608
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.00599988000241
   - Test - Long: 0.0649967501625
   - Test - Big: 0.0509994900051
   - Test - A: 0.0
   - Test - B: 12.3325111659
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.702862
 >> iter 2000, loss: 10.560177
 >> iter 3000, loss: 8.669122
 >> iter 4000, loss: 7.938579
 >> iter 5000, loss: 7.685214
 >> iter 6000, loss: 7.532229
 >> iter 7000, loss: 7.225599
 >> iter 8000, loss: 5.132426
 >> iter 9000, loss: 2.028651
 >> iter 10000, loss: 0.806665
   Number of active neurons: 6
 >> iter 11000, loss: 0.345549
 >> iter 12000, loss: 0.170136
 >> iter 13000, loss: 0.103323
 >> iter 14000, loss: 0.076591
 >> iter 15000, loss: 0.066031
 >> iter 16000, loss: 0.060822
 >> iter 17000, loss: 0.058677
 >> iter 18000, loss: 0.056973
 >> iter 19000, loss: 0.056320
 >> iter 20000, loss: 0.055364
   Number of active neurons: 6
 >> iter 21000, loss: 0.054920
 >> iter 22000, loss: 0.054020
 >> iter 23000, loss: 0.053511
 >> iter 24000, loss: 0.052618
 >> iter 25000, loss: 0.052087
 >> iter 26000, loss: 0.051315
 >> iter 27000, loss: 0.050785
 >> iter 28000, loss: 0.049999
 >> iter 29000, loss: 0.049379
 >> iter 30000, loss: 0.048699
   Number of active neurons: 6
 >> iter 31000, loss: 0.048161
 >> iter 32000, loss: 0.047582
 >> iter 33000, loss: 0.047210
 >> iter 34000, loss: 0.046815
 >> iter 35000, loss: 0.046536
 >> iter 36000, loss: 0.046252
 >> iter 37000, loss: 0.045998
 >> iter 38000, loss: 0.045804
 >> iter 39000, loss: 0.045591
 >> iter 40000, loss: 0.045471
   Number of active neurons: 6
 >> iter 41000, loss: 0.045291
 >> iter 42000, loss: 0.045214
 >> iter 43000, loss: 0.045051
 >> iter 44000, loss: 0.045018
 >> iter 45000, loss: 0.044836
 >> iter 46000, loss: 0.044774
 >> iter 47000, loss: 0.044593
 >> iter 48000, loss: 0.044579
 >> iter 49000, loss: 0.044444
 >> iter 50000, loss: 0.044476
   Number of active neurons: 6
 >> iter 51000, loss: 0.044367
 >> iter 52000, loss: 0.044418
 >> iter 53000, loss: 0.044168
 >> iter 54000, loss: 0.044092
 >> iter 55000, loss: 0.043828
 >> iter 56000, loss: 0.043807
 >> iter 57000, loss: 0.043635
 >> iter 58000, loss: 0.043746
 >> iter 59000, loss: 0.043625
 >> iter 60000, loss: 0.043732
   Number of active neurons: 6
 >> iter 61000, loss: 0.043552
 >> iter 62000, loss: 0.043538
 >> iter 63000, loss: 0.043136
 >> iter 64000, loss: 0.043065
 >> iter 65000, loss: 0.042761
 >> iter 66000, loss: 0.042853
 >> iter 67000, loss: 0.042633
 >> iter 68000, loss: 0.042805
 >> iter 69000, loss: 0.042640
 >> iter 70000, loss: 0.042777
   Number of active neurons: 6
 >> iter 71000, loss: 0.042495
 >> iter 72000, loss: 0.042603
 >> iter 73000, loss: 0.042396
 >> iter 74000, loss: 0.042581
 >> iter 75000, loss: 0.042423
 >> iter 76000, loss: 0.042637
 >> iter 77000, loss: 0.042485
 >> iter 78000, loss: 0.042666
 >> iter 79000, loss: 0.042278
 >> iter 80000, loss: 0.042190
   Number of active neurons: 6
 >> iter 81000, loss: 0.041696
 >> iter 82000, loss: 0.041646
 >> iter 83000, loss: 0.041183
 >> iter 84000, loss: 0.041186
 >> iter 85000, loss: 0.040716
 >> iter 86000, loss: 0.040671
 >> iter 87000, loss: 0.040158
 >> iter 88000, loss: 0.040078
 >> iter 89000, loss: 0.039500
 >> iter 90000, loss: 0.039351
   Number of active neurons: 5
 >> iter 91000, loss: 0.038758
 >> iter 92000, loss: 0.038696
 >> iter 93000, loss: 0.038085
 >> iter 94000, loss: 0.037888
 >> iter 95000, loss: 0.037214
 >> iter 96000, loss: 0.037044
 >> iter 97000, loss: 0.036418
 >> iter 98000, loss: 0.036308
 >> iter 99000, loss: 0.035744
 >> iter 100000, loss: 0.035695
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.573307
 >> iter 2000, loss: 10.491124
 >> iter 3000, loss: 8.621208
 >> iter 4000, loss: 7.896550
 >> iter 5000, loss: 7.660742
 >> iter 6000, loss: 7.598130
 >> iter 7000, loss: 7.558589
 >> iter 8000, loss: 7.415191
 >> iter 9000, loss: 6.498473
 >> iter 10000, loss: 2.509434
   Number of active neurons: 5
 >> iter 11000, loss: 0.974598
 >> iter 12000, loss: 0.398572
 >> iter 13000, loss: 0.182428
 >> iter 14000, loss: 0.100672
 >> iter 15000, loss: 0.069311
 >> iter 16000, loss: 0.056841
 >> iter 17000, loss: 0.051902
 >> iter 18000, loss: 0.049681
 >> iter 19000, loss: 0.048748
 >> iter 20000, loss: 0.048048
   Number of active neurons: 5
 >> iter 21000, loss: 0.047681
 >> iter 22000, loss: 0.047315
 >> iter 23000, loss: 0.047152
 >> iter 24000, loss: 0.046892
 >> iter 25000, loss: 0.046689
 >> iter 26000, loss: 0.046378
 >> iter 27000, loss: 0.046186
 >> iter 28000, loss: 0.045998
 >> iter 29000, loss: 0.045859
 >> iter 30000, loss: 0.045742
   Number of active neurons: 5
 >> iter 31000, loss: 0.045625
 >> iter 32000, loss: 0.045529
 >> iter 33000, loss: 0.045425
 >> iter 34000, loss: 0.045336
 >> iter 35000, loss: 0.045242
 >> iter 36000, loss: 0.045167
 >> iter 37000, loss: 0.045076
 >> iter 38000, loss: 0.045039
 >> iter 39000, loss: 0.044941
 >> iter 40000, loss: 0.044918
   Number of active neurons: 5
 >> iter 41000, loss: 0.044822
 >> iter 42000, loss: 0.044701
 >> iter 43000, loss: 0.044563
 >> iter 44000, loss: 0.044491
 >> iter 45000, loss: 0.044434
 >> iter 46000, loss: 0.044426
 >> iter 47000, loss: 0.044414
 >> iter 48000, loss: 0.044426
 >> iter 49000, loss: 0.044453
 >> iter 50000, loss: 0.044493
   Number of active neurons: 5
 >> iter 51000, loss: 0.044540
 >> iter 52000, loss: 0.044594
 >> iter 53000, loss: 0.044643
 >> iter 54000, loss: 0.044691
 >> iter 55000, loss: 0.044625
 >> iter 56000, loss: 0.044709
 >> iter 57000, loss: 0.044704
 >> iter 58000, loss: 0.044868
 >> iter 59000, loss: 0.044904
 >> iter 60000, loss: 0.045109
   Number of active neurons: 5
 >> iter 61000, loss: 0.045133
 >> iter 62000, loss: 0.045329
 >> iter 63000, loss: 0.045407
 >> iter 64000, loss: 0.045677
 >> iter 65000, loss: 0.045806
 >> iter 66000, loss: 0.046110
 >> iter 67000, loss: 0.046273
 >> iter 68000, loss: 0.046606
 >> iter 69000, loss: 0.046775
 >> iter 70000, loss: 0.047080
   Number of active neurons: 4
 >> iter 71000, loss: 0.047123
 >> iter 72000, loss: 0.047138
 >> iter 73000, loss: 0.046894
 >> iter 74000, loss: 0.046798
 >> iter 75000, loss: 0.046527
 >> iter 76000, loss: 0.046427
 >> iter 77000, loss: 0.046093
 >> iter 78000, loss: 0.045915
 >> iter 79000, loss: 0.045459
 >> iter 80000, loss: 0.045193
   Number of active neurons: 5
 >> iter 81000, loss: 0.044789
 >> iter 82000, loss: 0.044693
 >> iter 83000, loss: 0.044409
 >> iter 84000, loss: 0.044418
 >> iter 85000, loss: 0.044196
 >> iter 86000, loss: 0.044258
 >> iter 87000, loss: 0.044058
 >> iter 88000, loss: 0.044102
 >> iter 89000, loss: 0.043754
 >> iter 90000, loss: 0.043677
   Number of active neurons: 5
 >> iter 91000, loss: 0.043354
 >> iter 92000, loss: 0.043358
 >> iter 93000, loss: 0.043096
 >> iter 94000, loss: 0.043132
 >> iter 95000, loss: 0.042909
 >> iter 96000, loss: 0.042960
 >> iter 97000, loss: 0.042769
 >> iter 98000, loss: 0.042837
 >> iter 99000, loss: 0.042664
 >> iter 100000, loss: 0.042735
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.603366
 >> iter 2000, loss: 10.519295
 >> iter 3000, loss: 8.640726
 >> iter 4000, loss: 7.910362
 >> iter 5000, loss: 7.671001
 >> iter 6000, loss: 7.624588
 >> iter 7000, loss: 7.647646
 >> iter 8000, loss: 5.744074
 >> iter 9000, loss: 2.224986
 >> iter 10000, loss: 0.878074
   Number of active neurons: 4
 >> iter 11000, loss: 0.370650
 >> iter 12000, loss: 0.178286
 >> iter 13000, loss: 0.104339
 >> iter 14000, loss: 0.074833
 >> iter 15000, loss: 0.062581
 >> iter 16000, loss: 0.056903
 >> iter 17000, loss: 0.054118
 >> iter 18000, loss: 0.052431
 >> iter 19000, loss: 0.051380
 >> iter 20000, loss: 0.050466
   Number of active neurons: 4
 >> iter 21000, loss: 0.049552
 >> iter 22000, loss: 0.048767
 >> iter 23000, loss: 0.048126
 >> iter 24000, loss: 0.047687
 >> iter 25000, loss: 0.047160
 >> iter 26000, loss: 0.046773
 >> iter 27000, loss: 0.046349
 >> iter 28000, loss: 0.046039
 >> iter 29000, loss: 0.045613
 >> iter 30000, loss: 0.045363
   Number of active neurons: 4
 >> iter 31000, loss: 0.045039
 >> iter 32000, loss: 0.044883
 >> iter 33000, loss: 0.044633
 >> iter 34000, loss: 0.044526
 >> iter 35000, loss: 0.044320
 >> iter 36000, loss: 0.044249
 >> iter 37000, loss: 0.044062
 >> iter 38000, loss: 0.044042
 >> iter 39000, loss: 0.043854
 >> iter 40000, loss: 0.043854
   Number of active neurons: 4
 >> iter 41000, loss: 0.043687
 >> iter 42000, loss: 0.043694
 >> iter 43000, loss: 0.043542
 >> iter 44000, loss: 0.043565
 >> iter 45000, loss: 0.043421
 >> iter 46000, loss: 0.043459
 >> iter 47000, loss: 0.043324
 >> iter 48000, loss: 0.043358
 >> iter 49000, loss: 0.043241
 >> iter 50000, loss: 0.043290
   Number of active neurons: 4
 >> iter 51000, loss: 0.043180
 >> iter 52000, loss: 0.043233
 >> iter 53000, loss: 0.043117
 >> iter 54000, loss: 0.043198
 >> iter 55000, loss: 0.043065
 >> iter 56000, loss: 0.043165
 >> iter 57000, loss: 0.043028
 >> iter 58000, loss: 0.043139
 >> iter 59000, loss: 0.042998
 >> iter 60000, loss: 0.043113
   Number of active neurons: 4
 >> iter 61000, loss: 0.042975
 >> iter 62000, loss: 0.043087
 >> iter 63000, loss: 0.042950
 >> iter 64000, loss: 0.043069
 >> iter 65000, loss: 0.042925
 >> iter 66000, loss: 0.042966
 >> iter 67000, loss: 0.042626
 >> iter 68000, loss: 0.042556
 >> iter 69000, loss: 0.042261
 >> iter 70000, loss: 0.042289
   Number of active neurons: 4
 >> iter 71000, loss: 0.042087
 >> iter 72000, loss: 0.042183
 >> iter 73000, loss: 0.042024
 >> iter 74000, loss: 0.042149
 >> iter 75000, loss: 0.042011
 >> iter 76000, loss: 0.042151
 >> iter 77000, loss: 0.042013
 >> iter 78000, loss: 0.042159
 >> iter 79000, loss: 0.042041
 >> iter 80000, loss: 0.042174
   Number of active neurons: 4
 >> iter 81000, loss: 0.042050
 >> iter 82000, loss: 0.042192
 >> iter 83000, loss: 0.042059
 >> iter 84000, loss: 0.042206
 >> iter 85000, loss: 0.042070
 >> iter 86000, loss: 0.042228
 >> iter 87000, loss: 0.042084
 >> iter 88000, loss: 0.042240
 >> iter 89000, loss: 0.042095
 >> iter 90000, loss: 0.042253
   Number of active neurons: 4
 >> iter 91000, loss: 0.042100
 >> iter 92000, loss: 0.042265
 >> iter 93000, loss: 0.042108
 >> iter 94000, loss: 0.042265
 >> iter 95000, loss: 0.042123
 >> iter 96000, loss: 0.042271
 >> iter 97000, loss: 0.042130
 >> iter 98000, loss: 0.042274
 >> iter 99000, loss: 0.042136
 >> iter 100000, loss: 0.042278
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.638110
 >> iter 2000, loss: 10.516233
 >> iter 3000, loss: 8.632566
 >> iter 4000, loss: 7.908054
 >> iter 5000, loss: 7.669448
 >> iter 6000, loss: 7.643976
 >> iter 7000, loss: 7.708702
 >> iter 8000, loss: 7.502753
 >> iter 9000, loss: 6.711776
 >> iter 10000, loss: 2.593743
   Number of active neurons: 5
 >> iter 11000, loss: 1.001511
 >> iter 12000, loss: 0.405289
 >> iter 13000, loss: 0.182244
 >> iter 14000, loss: 0.098208
 >> iter 15000, loss: 0.066412
 >> iter 16000, loss: 0.054056
 >> iter 17000, loss: 0.049191
 >> iter 18000, loss: 0.047036
 >> iter 19000, loss: 0.045956
 >> iter 20000, loss: 0.045295
   Number of active neurons: 5
 >> iter 21000, loss: 0.044862
 >> iter 22000, loss: 0.044447
 >> iter 23000, loss: 0.044042
 >> iter 24000, loss: 0.043716
 >> iter 25000, loss: 0.043367
 >> iter 26000, loss: 0.043145
 >> iter 27000, loss: 0.042885
 >> iter 28000, loss: 0.042754
 >> iter 29000, loss: 0.042528
 >> iter 30000, loss: 0.042444
   Number of active neurons: 5
 >> iter 31000, loss: 0.042240
 >> iter 32000, loss: 0.042180
 >> iter 33000, loss: 0.041993
 >> iter 34000, loss: 0.041942
 >> iter 35000, loss: 0.041764
 >> iter 36000, loss: 0.041734
 >> iter 37000, loss: 0.041507
 >> iter 38000, loss: 0.041480
 >> iter 39000, loss: 0.041251
 >> iter 40000, loss: 0.041288
   Number of active neurons: 5
 >> iter 41000, loss: 0.041087
 >> iter 42000, loss: 0.041145
 >> iter 43000, loss: 0.040957
 >> iter 44000, loss: 0.041016
 >> iter 45000, loss: 0.040756
 >> iter 46000, loss: 0.040733
 >> iter 47000, loss: 0.040460
 >> iter 48000, loss: 0.040460
 >> iter 49000, loss: 0.040215
 >> iter 50000, loss: 0.040236
   Number of active neurons: 5
 >> iter 51000, loss: 0.039998
 >> iter 52000, loss: 0.040011
 >> iter 53000, loss: 0.039744
 >> iter 54000, loss: 0.039759
 >> iter 55000, loss: 0.039469
 >> iter 56000, loss: 0.039514
 >> iter 57000, loss: 0.039222
 >> iter 58000, loss: 0.039285
 >> iter 59000, loss: 0.038992
 >> iter 60000, loss: 0.039061
   Number of active neurons: 5
 >> iter 61000, loss: 0.038768
 >> iter 62000, loss: 0.038840
 >> iter 63000, loss: 0.038471
 >> iter 64000, loss: 0.038376
 >> iter 65000, loss: 0.037937
 >> iter 66000, loss: 0.037971
 >> iter 67000, loss: 0.037646
 >> iter 68000, loss: 0.037773
 >> iter 69000, loss: 0.037490
 >> iter 70000, loss: 0.037591
   Number of active neurons: 5
 >> iter 71000, loss: 0.037179
 >> iter 72000, loss: 0.037223
 >> iter 73000, loss: 0.036891
 >> iter 74000, loss: 0.037016
 >> iter 75000, loss: 0.036744
 >> iter 76000, loss: 0.036910
 >> iter 77000, loss: 0.036660
 >> iter 78000, loss: 0.036847
 >> iter 79000, loss: 0.036621
 >> iter 80000, loss: 0.036807
   Number of active neurons: 5
 >> iter 81000, loss: 0.036579
 >> iter 82000, loss: 0.036777
 >> iter 83000, loss: 0.036541
 >> iter 84000, loss: 0.036748
 >> iter 85000, loss: 0.036515
 >> iter 86000, loss: 0.036729
 >> iter 87000, loss: 0.036495
 >> iter 88000, loss: 0.036712
 >> iter 89000, loss: 0.036477
 >> iter 90000, loss: 0.036696
   Number of active neurons: 5
 >> iter 91000, loss: 0.036459
 >> iter 92000, loss: 0.036688
 >> iter 93000, loss: 0.036446
 >> iter 94000, loss: 0.036668
 >> iter 95000, loss: 0.036442
 >> iter 96000, loss: 0.036666
 >> iter 97000, loss: 0.036434
 >> iter 98000, loss: 0.036655
 >> iter 99000, loss: 0.036426
 >> iter 100000, loss: 0.036643
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.697986
 >> iter 2000, loss: 10.566042
 >> iter 3000, loss: 8.662411
 >> iter 4000, loss: 7.977431
 >> iter 5000, loss: 7.981425
 >> iter 6000, loss: 7.904907
 >> iter 7000, loss: 6.918605
 >> iter 8000, loss: 2.711437
 >> iter 9000, loss: 1.063977
 >> iter 10000, loss: 0.441215
   Number of active neurons: 7
 >> iter 11000, loss: 0.205370
 >> iter 12000, loss: 0.114814
 >> iter 13000, loss: 0.079529
 >> iter 14000, loss: 0.064933
 >> iter 15000, loss: 0.058644
 >> iter 16000, loss: 0.055448
 >> iter 17000, loss: 0.053675
 >> iter 18000, loss: 0.052270
 >> iter 19000, loss: 0.051418
 >> iter 20000, loss: 0.050654
   Number of active neurons: 7
 >> iter 21000, loss: 0.050198
 >> iter 22000, loss: 0.049677
 >> iter 23000, loss: 0.049407
 >> iter 24000, loss: 0.049034
 >> iter 25000, loss: 0.048836
 >> iter 26000, loss: 0.048528
 >> iter 27000, loss: 0.048300
 >> iter 28000, loss: 0.047889
 >> iter 29000, loss: 0.047485
 >> iter 30000, loss: 0.047037
   Number of active neurons: 7
 >> iter 31000, loss: 0.046686
 >> iter 32000, loss: 0.046180
 >> iter 33000, loss: 0.045786
 >> iter 34000, loss: 0.045394
 >> iter 35000, loss: 0.045150
 >> iter 36000, loss: 0.044878
 >> iter 37000, loss: 0.044710
 >> iter 38000, loss: 0.044507
 >> iter 39000, loss: 0.044397
 >> iter 40000, loss: 0.044232
   Number of active neurons: 7
 >> iter 41000, loss: 0.044156
 >> iter 42000, loss: 0.044020
 >> iter 43000, loss: 0.043966
 >> iter 44000, loss: 0.043846
 >> iter 45000, loss: 0.043798
 >> iter 46000, loss: 0.043684
 >> iter 47000, loss: 0.043549
 >> iter 48000, loss: 0.043355
 >> iter 49000, loss: 0.043238
 >> iter 50000, loss: 0.043089
   Number of active neurons: 7
 >> iter 51000, loss: 0.043025
 >> iter 52000, loss: 0.042915
 >> iter 53000, loss: 0.042881
 >> iter 54000, loss: 0.042758
 >> iter 55000, loss: 0.042659
 >> iter 56000, loss: 0.042536
 >> iter 57000, loss: 0.042503
 >> iter 58000, loss: 0.042447
 >> iter 59000, loss: 0.042460
 >> iter 60000, loss: 0.042434
   Number of active neurons: 7
 >> iter 61000, loss: 0.042461
 >> iter 62000, loss: 0.042448
 >> iter 63000, loss: 0.042481
 >> iter 64000, loss: 0.042472
 >> iter 65000, loss: 0.042505
 >> iter 66000, loss: 0.042494
 >> iter 67000, loss: 0.042523
 >> iter 68000, loss: 0.042516
 >> iter 69000, loss: 0.042550
 >> iter 70000, loss: 0.042537
   Number of active neurons: 7
 >> iter 71000, loss: 0.042569
 >> iter 72000, loss: 0.042556
 >> iter 73000, loss: 0.042590
 >> iter 74000, loss: 0.042575
 >> iter 75000, loss: 0.042613
 >> iter 76000, loss: 0.042593
 >> iter 77000, loss: 0.042632
 >> iter 78000, loss: 0.042612
 >> iter 79000, loss: 0.042647
 >> iter 80000, loss: 0.042630
   Number of active neurons: 7
 >> iter 81000, loss: 0.042660
 >> iter 82000, loss: 0.042652
 >> iter 83000, loss: 0.042678
 >> iter 84000, loss: 0.042675
 >> iter 85000, loss: 0.042705
 >> iter 86000, loss: 0.042695
 >> iter 87000, loss: 0.042729
 >> iter 88000, loss: 0.042724
 >> iter 89000, loss: 0.042749
 >> iter 90000, loss: 0.042751
   Number of active neurons: 7
 >> iter 91000, loss: 0.042775
 >> iter 92000, loss: 0.042784
 >> iter 93000, loss: 0.042805
 >> iter 94000, loss: 0.042814
 >> iter 95000, loss: 0.042838
 >> iter 96000, loss: 0.042849
 >> iter 97000, loss: 0.042880
 >> iter 98000, loss: 0.042892
 >> iter 99000, loss: 0.042930
 >> iter 100000, loss: 0.042943
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

