 > Problema: tomita7nueva
 > Args:
   - Hidden size: 4
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.982308
 >> iter 2000, loss: 11.205842
 >> iter 3000, loss: 8.571710
 >> iter 4000, loss: 6.245315
 >> iter 5000, loss: 4.384235
 >> iter 6000, loss: 3.180689
 >> iter 7000, loss: 2.209403
 >> iter 8000, loss: 1.681229
 >> iter 9000, loss: 1.111730
 >> iter 10000, loss: 0.977419
   Number of active neurons: 4
 >> iter 11000, loss: 0.722091
 >> iter 12000, loss: 0.690942
 >> iter 13000, loss: 0.668676
 >> iter 14000, loss: 0.519205
 >> iter 15000, loss: 0.422903
 >> iter 16000, loss: 0.489882
 >> iter 17000, loss: 0.649687
 >> iter 18000, loss: 0.665882
 >> iter 19000, loss: 0.677432
 >> iter 20000, loss: 0.477017
   Number of active neurons: 4
 >> iter 21000, loss: 0.517823
 >> iter 22000, loss: 0.543800
 >> iter 23000, loss: 0.599433
 >> iter 24000, loss: 0.557818
 >> iter 25000, loss: 0.421079
 >> iter 26000, loss: 0.493990
 >> iter 27000, loss: 0.496657
 >> iter 28000, loss: 0.518572
 >> iter 29000, loss: 0.493824
 >> iter 30000, loss: 0.525428
   Number of active neurons: 4
 >> iter 31000, loss: 0.495481
 >> iter 32000, loss: 0.516364
 >> iter 33000, loss: 0.513416
 >> iter 34000, loss: 0.477113
 >> iter 35000, loss: 0.612998
 >> iter 36000, loss: 0.424808
 >> iter 37000, loss: 0.427952
 >> iter 38000, loss: 0.473873
 >> iter 39000, loss: 0.526984
 >> iter 40000, loss: 0.505094
   Number of active neurons: 4
 >> iter 41000, loss: 0.467964
 >> iter 42000, loss: 0.513218
 >> iter 43000, loss: 0.487919
 >> iter 44000, loss: 0.453992
 >> iter 45000, loss: 0.479798
 >> iter 46000, loss: 0.448610
 >> iter 47000, loss: 0.552196
 >> iter 48000, loss: 0.587196
 >> iter 49000, loss: 0.582429
 >> iter 50000, loss: 0.454411
   Number of active neurons: 4
 >> iter 51000, loss: 0.445974
 >> iter 52000, loss: 0.442802
 >> iter 53000, loss: 0.440540
 >> iter 54000, loss: 0.402832
 >> iter 55000, loss: 0.306856
 >> iter 56000, loss: 0.297296
 >> iter 57000, loss: 0.459704
 >> iter 58000, loss: 0.532000
 >> iter 59000, loss: 0.505348
 >> iter 60000, loss: 0.489867
   Number of active neurons: 4
 >> iter 61000, loss: 0.491790
 >> iter 62000, loss: 0.462085
 >> iter 63000, loss: 0.521422
 >> iter 64000, loss: 0.509650
 >> iter 65000, loss: 0.614285
 >> iter 66000, loss: 0.487934
 >> iter 67000, loss: 0.550408
 >> iter 68000, loss: 0.461661
 >> iter 69000, loss: 0.368964
 >> iter 70000, loss: 0.456199
   Number of active neurons: 4
 >> iter 71000, loss: 0.468654
 >> iter 72000, loss: 0.646275
 >> iter 73000, loss: 0.526682
 >> iter 74000, loss: 0.423850
 >> iter 75000, loss: 0.409396
 >> iter 76000, loss: 0.653996
 >> iter 77000, loss: 0.600206
 >> iter 78000, loss: 0.553176
 >> iter 79000, loss: 0.514583
 >> iter 80000, loss: 0.390836
   Number of active neurons: 4
 >> iter 81000, loss: 0.436466
 >> iter 82000, loss: 0.477279
 >> iter 83000, loss: 0.449290
 >> iter 84000, loss: 0.556672
 >> iter 85000, loss: 0.526990
 >> iter 86000, loss: 0.663515
 >> iter 87000, loss: 0.493424
 >> iter 88000, loss: 0.386328
 >> iter 89000, loss: 0.469628
 >> iter 90000, loss: 0.395039
   Number of active neurons: 4
 >> iter 91000, loss: 0.520294
 >> iter 92000, loss: 0.457908
 >> iter 93000, loss: 0.333287
 >> iter 94000, loss: 0.422561
 >> iter 95000, loss: 0.481868
 >> iter 96000, loss: 0.412114
 >> iter 97000, loss: 0.332699
 >> iter 98000, loss: 0.450836
 >> iter 99000, loss: 0.476365
 >> iter 100000, loss: 0.401319
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 21.037300
 >> iter 2000, loss: 18.735217
 >> iter 3000, loss: 17.828262
 >> iter 4000, loss: 17.557539
 >> iter 5000, loss: 17.393953
 >> iter 6000, loss: 17.399767
 >> iter 7000, loss: 17.334485
 >> iter 8000, loss: 17.377683
 >> iter 9000, loss: 17.326842
 >> iter 10000, loss: 17.376461
   Number of active neurons: 0
 >> iter 11000, loss: 17.324224
 >> iter 12000, loss: 17.376003
 >> iter 13000, loss: 17.320235
 >> iter 14000, loss: 17.374907
 >> iter 15000, loss: 17.320795
 >> iter 16000, loss: 17.374885
 >> iter 17000, loss: 17.322167
 >> iter 18000, loss: 17.374664
 >> iter 19000, loss: 17.320916
 >> iter 20000, loss: 17.374841
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 17.317895
 >> iter 22000, loss: 17.373813
 >> iter 23000, loss: 17.319005
 >> iter 24000, loss: 17.375436
 >> iter 25000, loss: 17.318964
 >> iter 26000, loss: 17.373752
 >> iter 27000, loss: 17.324807
 >> iter 28000, loss: 17.373264
 >> iter 29000, loss: 17.323039
 >> iter 30000, loss: 17.372201
   Number of active neurons: 0
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 0
 >> iter 31000, loss: 17.322129
 >> iter 32000, loss: 17.371332
 >> iter 33000, loss: 17.328108
 >> iter 34000, loss: 17.370063
 >> iter 35000, loss: 17.327290
 >> iter 36000, loss: 17.375660
 >> iter 37000, loss: 17.327154
 >> iter 38000, loss: 17.375447
 >> iter 39000, loss: 17.331852
 >> iter 40000, loss: 17.376134
   Number of active neurons: 0
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 0
 >> iter 41000, loss: 17.328963
 >> iter 42000, loss: 17.375205
 >> iter 43000, loss: 17.329508
 >> iter 44000, loss: 17.372335
 >> iter 45000, loss: 17.329042
 >> iter 46000, loss: 17.371788
 >> iter 47000, loss: 17.330408
 >> iter 48000, loss: 17.369658
 >> iter 49000, loss: 17.330643
 >> iter 50000, loss: 17.371992
   Number of active neurons: 0
   SHOCK
   Setting new limit to 287500.0 iters...
   Number of active neurons: 0
 >> iter 51000, loss: 17.330305
 >> iter 52000, loss: 17.370316
 >> iter 53000, loss: 17.328930
 >> iter 54000, loss: 17.368894
 >> iter 55000, loss: 17.328161
 >> iter 56000, loss: 17.366936
 >> iter 57000, loss: 17.330334
 >> iter 58000, loss: 17.364328
 >> iter 59000, loss: 17.331780
 >> iter 60000, loss: 17.365080
   Number of active neurons: 0
   SHOCK
   Setting new limit to 293750.0 iters...
   Number of active neurons: 0
 >> iter 61000, loss: 17.332162
 >> iter 62000, loss: 17.365118
 >> iter 63000, loss: 17.332271
 >> iter 64000, loss: 17.370064
 >> iter 65000, loss: 17.332118
 >> iter 66000, loss: 17.374276
 >> iter 67000, loss: 17.332229
 >> iter 68000, loss: 17.370799
 >> iter 69000, loss: 17.331800
 >> iter 70000, loss: 17.366686
   Number of active neurons: 0
   SHOCK
   Setting new limit to 296875.0 iters...
   Number of active neurons: 0
 >> iter 71000, loss: 17.331986
 >> iter 72000, loss: 17.367659
 >> iter 73000, loss: 17.330803
 >> iter 74000, loss: 17.370948
 >> iter 75000, loss: 17.329140
 >> iter 76000, loss: 17.372050
 >> iter 77000, loss: 17.328300
 >> iter 78000, loss: 17.373002
 >> iter 79000, loss: 17.328922
 >> iter 80000, loss: 17.372404
   Number of active neurons: 0
   SHOCK
   Setting new limit to 298437.5 iters...
   Number of active neurons: 0
 >> iter 81000, loss: 17.329394
 >> iter 82000, loss: 17.370929
 >> iter 83000, loss: 17.328947
 >> iter 84000, loss: 17.367321
 >> iter 85000, loss: 17.325923
 >> iter 86000, loss: 17.363506
 >> iter 87000, loss: 17.325808
 >> iter 88000, loss: 17.357910
 >> iter 89000, loss: 17.323475
 >> iter 90000, loss: 17.358718
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299218.75 iters...
   Number of active neurons: 0
 >> iter 91000, loss: 17.327662
 >> iter 92000, loss: 17.355516
 >> iter 93000, loss: 17.325695
 >> iter 94000, loss: 17.363306
 >> iter 95000, loss: 17.326105
 >> iter 96000, loss: 17.362285
 >> iter 97000, loss: 17.329668
 >> iter 98000, loss: 17.360728
 >> iter 99000, loss: 17.327967
 >> iter 100000, loss: 17.368646
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299609.375 iters...
   Number of active neurons: 0
 >> iter 101000, loss: 17.330254
 >> iter 102000, loss: 17.364440
 >> iter 103000, loss: 17.331574
 >> iter 104000, loss: 17.361735
 >> iter 105000, loss: 17.330603
 >> iter 106000, loss: 17.359474
 >> iter 107000, loss: 17.329008
 >> iter 108000, loss: 17.359779
 >> iter 109000, loss: 17.331155
 >> iter 110000, loss: 17.359970
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299804.6875 iters...
   Number of active neurons: 0
 >> iter 111000, loss: 17.334597
 >> iter 112000, loss: 17.364575
 >> iter 113000, loss: 17.332460
 >> iter 114000, loss: 17.364045
 >> iter 115000, loss: 17.333115
 >> iter 116000, loss: 17.366706
 >> iter 117000, loss: 17.331649
 >> iter 118000, loss: 17.369020
 >> iter 119000, loss: 17.329913
 >> iter 120000, loss: 17.370849
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299902.34375 iters...
   Number of active neurons: 0
 >> iter 121000, loss: 17.332243
 >> iter 122000, loss: 17.370025
 >> iter 123000, loss: 17.330852
 >> iter 124000, loss: 17.368817
 >> iter 125000, loss: 17.333743
 >> iter 126000, loss: 17.369596
 >> iter 127000, loss: 17.332453
 >> iter 128000, loss: 17.370141
 >> iter 129000, loss: 17.331249
 >> iter 130000, loss: 17.371283
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299951.171875 iters...
   Number of active neurons: 0
 >> iter 131000, loss: 17.332339
 >> iter 132000, loss: 17.370564
 >> iter 133000, loss: 17.330895
 >> iter 134000, loss: 17.369574
 >> iter 135000, loss: 17.333121
 >> iter 136000, loss: 17.367121
 >> iter 137000, loss: 17.334685
 >> iter 138000, loss: 17.368479
 >> iter 139000, loss: 17.333746
 >> iter 140000, loss: 17.369112
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299975.585938 iters...
   Number of active neurons: 0
 >> iter 141000, loss: 17.335499
 >> iter 142000, loss: 17.367805
 >> iter 143000, loss: 17.335148
 >> iter 144000, loss: 17.368873
 >> iter 145000, loss: 17.334148
 >> iter 146000, loss: 17.369795
 >> iter 147000, loss: 17.331078
 >> iter 148000, loss: 17.370390
 >> iter 149000, loss: 17.329407
 >> iter 150000, loss: 17.370187
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299987.792969 iters...
   Number of active neurons: 0
 >> iter 151000, loss: 17.331164
 >> iter 152000, loss: 17.369095
 >> iter 153000, loss: 17.333826
 >> iter 154000, loss: 17.368185
 >> iter 155000, loss: 17.335648
 >> iter 156000, loss: 17.367973
 >> iter 157000, loss: 17.335939
 >> iter 158000, loss: 17.368329
 >> iter 159000, loss: 17.335607
 >> iter 160000, loss: 17.367869
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299993.896484 iters...
   Number of active neurons: 0
 >> iter 161000, loss: 17.334484
 >> iter 162000, loss: 17.369990
 >> iter 163000, loss: 17.335336
 >> iter 164000, loss: 17.371547
 >> iter 165000, loss: 17.335693
 >> iter 166000, loss: 17.371365
 >> iter 167000, loss: 17.335922
 >> iter 168000, loss: 17.370281
 >> iter 169000, loss: 17.336293
 >> iter 170000, loss: 17.370063
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299996.948242 iters...
   Number of active neurons: 0
 >> iter 171000, loss: 17.336256
 >> iter 172000, loss: 17.368395
 >> iter 173000, loss: 17.336231
 >> iter 174000, loss: 17.367266
 >> iter 175000, loss: 17.336050
 >> iter 176000, loss: 17.368885
 >> iter 177000, loss: 17.335565
 >> iter 178000, loss: 17.366075
 >> iter 179000, loss: 17.335386
 >> iter 180000, loss: 17.363386
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299998.474121 iters...
   Number of active neurons: 0
 >> iter 181000, loss: 17.335402
 >> iter 182000, loss: 17.363316
 >> iter 183000, loss: 17.336686
 >> iter 184000, loss: 17.359318
 >> iter 185000, loss: 17.336658
 >> iter 186000, loss: 17.356702
 >> iter 187000, loss: 17.336795
 >> iter 188000, loss: 17.355682
 >> iter 189000, loss: 17.336814
 >> iter 190000, loss: 17.363589
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.237061 iters...
   Number of active neurons: 0
 >> iter 191000, loss: 17.336741
 >> iter 192000, loss: 17.361589
 >> iter 193000, loss: 17.336933
 >> iter 194000, loss: 17.362199
 >> iter 195000, loss: 17.336832
 >> iter 196000, loss: 17.363635
 >> iter 197000, loss: 17.337265
 >> iter 198000, loss: 17.362698
 >> iter 199000, loss: 17.337094
 >> iter 200000, loss: 17.358390
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.61853 iters...
   Number of active neurons: 0
 >> iter 201000, loss: 17.338634
 >> iter 202000, loss: 17.359971
 >> iter 203000, loss: 17.338371
 >> iter 204000, loss: 17.361566
 >> iter 205000, loss: 17.339260
 >> iter 206000, loss: 17.359421
 >> iter 207000, loss: 17.339597
 >> iter 208000, loss: 17.358462
 >> iter 209000, loss: 17.338796
 >> iter 210000, loss: 17.357934
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.809265 iters...
   Number of active neurons: 0
 >> iter 211000, loss: 17.338451
 >> iter 212000, loss: 17.361791
 >> iter 213000, loss: 17.338465
 >> iter 214000, loss: 17.363977
 >> iter 215000, loss: 17.338653
 >> iter 216000, loss: 17.364955
 >> iter 217000, loss: 17.338337
 >> iter 218000, loss: 17.363797
 >> iter 219000, loss: 17.337428
 >> iter 220000, loss: 17.361192
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.904633 iters...
   Number of active neurons: 0
 >> iter 221000, loss: 17.336433
 >> iter 222000, loss: 17.359653
 >> iter 223000, loss: 17.337245
 >> iter 224000, loss: 17.361153
 >> iter 225000, loss: 17.335523
 >> iter 226000, loss: 17.361261
 >> iter 227000, loss: 17.336087
 >> iter 228000, loss: 17.359657
 >> iter 229000, loss: 17.336815
 >> iter 230000, loss: 17.357254
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.952316 iters...
   Number of active neurons: 0
 >> iter 231000, loss: 17.339906
 >> iter 232000, loss: 17.352942
 >> iter 233000, loss: 17.339884
 >> iter 234000, loss: 17.351925
 >> iter 235000, loss: 17.339732
 >> iter 236000, loss: 17.348036
 >> iter 237000, loss: 17.339430
 >> iter 238000, loss: 17.353122
 >> iter 239000, loss: 17.337861
 >> iter 240000, loss: 17.356699
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.976158 iters...
   Number of active neurons: 0
 >> iter 241000, loss: 17.339592
 >> iter 242000, loss: 17.356182
 >> iter 243000, loss: 17.339589
 >> iter 244000, loss: 17.357527
 >> iter 245000, loss: 17.339255
 >> iter 246000, loss: 17.357376
 >> iter 247000, loss: 17.339839
 >> iter 248000, loss: 17.353952
 >> iter 249000, loss: 17.339222
 >> iter 250000, loss: 17.353433
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.988079 iters...
   Number of active neurons: 0
 >> iter 251000, loss: 17.341380
 >> iter 252000, loss: 17.350636
 >> iter 253000, loss: 17.340444
 >> iter 254000, loss: 17.349073
 >> iter 255000, loss: 17.341108
 >> iter 256000, loss: 17.349776
 >> iter 257000, loss: 17.340128
 >> iter 258000, loss: 17.349799
 >> iter 259000, loss: 17.339936
 >> iter 260000, loss: 17.349291
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99404 iters...
   Number of active neurons: 0
 >> iter 261000, loss: 17.338083
 >> iter 262000, loss: 17.351607
 >> iter 263000, loss: 17.336910
 >> iter 264000, loss: 17.347372
 >> iter 265000, loss: 17.336400
 >> iter 266000, loss: 17.352046
 >> iter 267000, loss: 17.338993
 >> iter 268000, loss: 17.349296
 >> iter 269000, loss: 17.339960
 >> iter 270000, loss: 17.346900
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99702 iters...
   Number of active neurons: 0
 >> iter 271000, loss: 17.338358
 >> iter 272000, loss: 17.341545
 >> iter 273000, loss: 17.336064
 >> iter 274000, loss: 17.341839
 >> iter 275000, loss: 17.339575
 >> iter 276000, loss: 17.346790
 >> iter 277000, loss: 17.339396
 >> iter 278000, loss: 17.351248
 >> iter 279000, loss: 17.338329
 >> iter 280000, loss: 17.348349
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99851 iters...
   Number of active neurons: 0
 >> iter 281000, loss: 17.337130
 >> iter 282000, loss: 17.344876
 >> iter 283000, loss: 17.340174
 >> iter 284000, loss: 17.342082
 >> iter 285000, loss: 17.338221
 >> iter 286000, loss: 17.346972
 >> iter 287000, loss: 17.337313
 >> iter 288000, loss: 17.342089
 >> iter 289000, loss: 17.336385
 >> iter 290000, loss: 17.344366
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999255 iters...
   Number of active neurons: 0
 >> iter 291000, loss: 17.331526
 >> iter 292000, loss: 17.347784
 >> iter 293000, loss: 17.326790
 >> iter 294000, loss: 17.348628
 >> iter 295000, loss: 17.330889
 >> iter 296000, loss: 17.344618
 >> iter 297000, loss: 17.329363
 >> iter 298000, loss: 17.341681
 >> iter 299000, loss: 17.333407
 >> iter 300000, loss: 17.336052
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999627 iters...
   Number of active neurons: 0
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.318576
 >> iter 2000, loss: 12.870249
 >> iter 3000, loss: 9.871480
 >> iter 4000, loss: 7.481477
 >> iter 5000, loss: 5.848494
 >> iter 6000, loss: 4.483325
 >> iter 7000, loss: 3.833469
 >> iter 8000, loss: 3.413399
 >> iter 9000, loss: 3.313727
 >> iter 10000, loss: 3.143851
   Number of active neurons: 4
 >> iter 11000, loss: 3.022142
 >> iter 12000, loss: 3.100492
 >> iter 13000, loss: 3.103000
 >> iter 14000, loss: 2.968763
 >> iter 15000, loss: 2.981008
 >> iter 16000, loss: 2.924696
 >> iter 17000, loss: 2.424556
 >> iter 18000, loss: 2.448690
 >> iter 19000, loss: 2.260229
 >> iter 20000, loss: 2.305825
   Number of active neurons: 4
 >> iter 21000, loss: 2.222341
 >> iter 22000, loss: 2.125770
 >> iter 23000, loss: 1.975869
 >> iter 24000, loss: 2.087104
 >> iter 25000, loss: 2.141836
 >> iter 26000, loss: 1.939234
 >> iter 27000, loss: 1.290966
 >> iter 28000, loss: 1.043948
 >> iter 29000, loss: 0.957327
 >> iter 30000, loss: 0.845332
   Number of active neurons: 4
 >> iter 31000, loss: 1.000023
 >> iter 32000, loss: 1.164948
 >> iter 33000, loss: 0.965748
 >> iter 34000, loss: 0.825979
 >> iter 35000, loss: 0.730040
 >> iter 36000, loss: 0.736183
 >> iter 37000, loss: 0.764597
 >> iter 38000, loss: 0.880025
 >> iter 39000, loss: 0.703694
 >> iter 40000, loss: 0.780777
   Number of active neurons: 4
 >> iter 41000, loss: 0.822393
 >> iter 42000, loss: 0.715131
 >> iter 43000, loss: 0.822542
 >> iter 44000, loss: 0.610132
 >> iter 45000, loss: 0.583855
 >> iter 46000, loss: 0.608205
 >> iter 47000, loss: 0.636323
 >> iter 48000, loss: 0.735098
 >> iter 49000, loss: 0.570941
 >> iter 50000, loss: 0.535127
   Number of active neurons: 4
 >> iter 51000, loss: 0.734766
 >> iter 52000, loss: 0.821314
 >> iter 53000, loss: 0.633286
 >> iter 54000, loss: 0.673868
 >> iter 55000, loss: 0.858550
 >> iter 56000, loss: 1.009825
 >> iter 57000, loss: 0.988382
 >> iter 58000, loss: 0.660819
 >> iter 59000, loss: 0.758923
 >> iter 60000, loss: 0.796478
   Number of active neurons: 4
 >> iter 61000, loss: 0.810185
 >> iter 62000, loss: 0.666953
 >> iter 63000, loss: 0.648914
 >> iter 64000, loss: 0.565610
 >> iter 65000, loss: 0.557882
 >> iter 66000, loss: 0.529558
 >> iter 67000, loss: 0.495215
 >> iter 68000, loss: 0.619872
 >> iter 69000, loss: 0.687590
 >> iter 70000, loss: 0.653031
   Number of active neurons: 4
 >> iter 71000, loss: 0.577667
 >> iter 72000, loss: 0.567478
 >> iter 73000, loss: 0.569935
 >> iter 74000, loss: 0.597872
 >> iter 75000, loss: 0.424210
 >> iter 76000, loss: 0.549259
 >> iter 77000, loss: 0.511579
 >> iter 78000, loss: 0.469686
 >> iter 79000, loss: 0.575952
 >> iter 80000, loss: 0.559223
   Number of active neurons: 4
 >> iter 81000, loss: 0.572348
 >> iter 82000, loss: 0.710175
 >> iter 83000, loss: 0.621679
 >> iter 84000, loss: 0.629104
 >> iter 85000, loss: 0.588921
 >> iter 86000, loss: 0.517295
 >> iter 87000, loss: 0.568523
 >> iter 88000, loss: 0.523909
 >> iter 89000, loss: 0.595632
 >> iter 90000, loss: 0.704659
   Number of active neurons: 4
 >> iter 91000, loss: 0.628957
 >> iter 92000, loss: 0.452405
 >> iter 93000, loss: 0.375470
 >> iter 94000, loss: 0.506357
 >> iter 95000, loss: 0.608958
 >> iter 96000, loss: 0.476093
 >> iter 97000, loss: 0.454415
 >> iter 98000, loss: 0.483208
 >> iter 99000, loss: 0.577581
 >> iter 100000, loss: 0.624728
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 8.33277781481
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.973996
 >> iter 2000, loss: 11.899228
 >> iter 3000, loss: 9.167366
 >> iter 4000, loss: 7.504740
 >> iter 5000, loss: 5.607935
 >> iter 6000, loss: 3.771232
 >> iter 7000, loss: 2.424355
 >> iter 8000, loss: 1.309993
 >> iter 9000, loss: 0.844375
 >> iter 10000, loss: 0.455432
   Number of active neurons: 4
 >> iter 11000, loss: 0.334193
 >> iter 12000, loss: 0.315450
 >> iter 13000, loss: 0.340983
 >> iter 14000, loss: 0.265903
 >> iter 15000, loss: 0.247830
 >> iter 16000, loss: 0.335125
 >> iter 17000, loss: 0.246292
 >> iter 18000, loss: 0.261626
 >> iter 19000, loss: 0.274557
 >> iter 20000, loss: 0.355265
   Number of active neurons: 4
 >> iter 21000, loss: 0.306275
 >> iter 22000, loss: 0.179738
 >> iter 23000, loss: 0.291915
 >> iter 24000, loss: 0.237575
 >> iter 25000, loss: 0.189261
 >> iter 26000, loss: 0.217861
 >> iter 27000, loss: 0.343873
 >> iter 28000, loss: 0.253056
 >> iter 29000, loss: 0.301335
 >> iter 30000, loss: 0.391765
   Number of active neurons: 4
 >> iter 31000, loss: 0.481488
 >> iter 32000, loss: 0.447896
 >> iter 33000, loss: 0.317156
 >> iter 34000, loss: 0.298471
 >> iter 35000, loss: 0.399582
 >> iter 36000, loss: 0.385944
 >> iter 37000, loss: 0.476821
 >> iter 38000, loss: 0.351155
 >> iter 39000, loss: 0.279094
 >> iter 40000, loss: 0.308033
   Number of active neurons: 4
 >> iter 41000, loss: 0.289276
 >> iter 42000, loss: 0.435668
 >> iter 43000, loss: 0.490868
 >> iter 44000, loss: 0.614733
 >> iter 45000, loss: 0.573175
 >> iter 46000, loss: 0.486385
 >> iter 47000, loss: 0.369901
 >> iter 48000, loss: 0.333759
 >> iter 49000, loss: 0.270342
 >> iter 50000, loss: 0.316044
   Number of active neurons: 4
 >> iter 51000, loss: 0.402745
 >> iter 52000, loss: 0.418062
 >> iter 53000, loss: 0.433159
 >> iter 54000, loss: 0.328146
 >> iter 55000, loss: 0.457208
 >> iter 56000, loss: 0.426515
 >> iter 57000, loss: 0.338396
 >> iter 58000, loss: 0.447146
 >> iter 59000, loss: 0.373707
 >> iter 60000, loss: 0.365502
   Number of active neurons: 4
 >> iter 61000, loss: 0.410344
 >> iter 62000, loss: 0.312467
 >> iter 63000, loss: 0.380485
 >> iter 64000, loss: 0.362291
 >> iter 65000, loss: 0.367664
 >> iter 66000, loss: 0.402460
 >> iter 67000, loss: 0.374826
 >> iter 68000, loss: 0.478705
 >> iter 69000, loss: 0.383499
 >> iter 70000, loss: 0.389465
   Number of active neurons: 4
 >> iter 71000, loss: 0.597261
 >> iter 72000, loss: 0.444759
 >> iter 73000, loss: 0.431528
 >> iter 74000, loss: 0.332694
 >> iter 75000, loss: 0.337527
 >> iter 76000, loss: 0.390418
 >> iter 77000, loss: 0.535274
 >> iter 78000, loss: 0.374502
 >> iter 79000, loss: 0.412051
 >> iter 80000, loss: 0.379469
   Number of active neurons: 4
 >> iter 81000, loss: 0.419932
 >> iter 82000, loss: 0.435173
 >> iter 83000, loss: 0.412524
 >> iter 84000, loss: 0.432134
 >> iter 85000, loss: 0.432195
 >> iter 86000, loss: 0.416789
 >> iter 87000, loss: 0.311648
 >> iter 88000, loss: 0.410760
 >> iter 89000, loss: 0.273896
 >> iter 90000, loss: 0.322799
   Number of active neurons: 4
 >> iter 91000, loss: 0.305666
 >> iter 92000, loss: 0.373269
 >> iter 93000, loss: 0.348613
 >> iter 94000, loss: 0.308207
 >> iter 95000, loss: 0.580111
 >> iter 96000, loss: 0.526596
 >> iter 97000, loss: 0.382193
 >> iter 98000, loss: 0.428184
 >> iter 99000, loss: 0.473329
 >> iter 100000, loss: 0.341339
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.402629
 >> iter 2000, loss: 11.667298
 >> iter 3000, loss: 9.693019
 >> iter 4000, loss: 9.049805
 >> iter 5000, loss: 8.977990
 >> iter 6000, loss: 8.172094
 >> iter 7000, loss: 6.165502
 >> iter 8000, loss: 3.795623
 >> iter 9000, loss: 2.160806
 >> iter 10000, loss: 1.459816
   Number of active neurons: 4
 >> iter 11000, loss: 0.993914
 >> iter 12000, loss: 0.727262
 >> iter 13000, loss: 0.629528
 >> iter 14000, loss: 0.450535
 >> iter 15000, loss: 0.504911
 >> iter 16000, loss: 0.432467
 >> iter 17000, loss: 0.475376
 >> iter 18000, loss: 0.644929
 >> iter 19000, loss: 0.502864
 >> iter 20000, loss: 0.473494
   Number of active neurons: 4
 >> iter 21000, loss: 0.556831
 >> iter 22000, loss: 0.554493
 >> iter 23000, loss: 0.473282
 >> iter 24000, loss: 0.512894
 >> iter 25000, loss: 0.522097
 >> iter 26000, loss: 0.404076
 >> iter 27000, loss: 0.411619
 >> iter 28000, loss: 0.421996
 >> iter 29000, loss: 0.438556
 >> iter 30000, loss: 0.452619
   Number of active neurons: 4
 >> iter 31000, loss: 0.355821
 >> iter 32000, loss: 0.358526
 >> iter 33000, loss: 0.289204
 >> iter 34000, loss: 0.426955
 >> iter 35000, loss: 0.308639
 >> iter 36000, loss: 0.365852
 >> iter 37000, loss: 0.387378
 >> iter 38000, loss: 0.384261
 >> iter 39000, loss: 0.516504
 >> iter 40000, loss: 0.338347
   Number of active neurons: 4
 >> iter 41000, loss: 0.335197
 >> iter 42000, loss: 0.344061
 >> iter 43000, loss: 0.369597
 >> iter 44000, loss: 0.239080
 >> iter 45000, loss: 0.333315
 >> iter 46000, loss: 0.374995
 >> iter 47000, loss: 0.285371
 >> iter 48000, loss: 0.282529
 >> iter 49000, loss: 0.345490
 >> iter 50000, loss: 0.432596
   Number of active neurons: 4
 >> iter 51000, loss: 0.464943
 >> iter 52000, loss: 0.314683
 >> iter 53000, loss: 0.479044
 >> iter 54000, loss: 0.431725
 >> iter 55000, loss: 0.490218
 >> iter 56000, loss: 0.425020
 >> iter 57000, loss: 0.411672
 >> iter 58000, loss: 0.475612
 >> iter 59000, loss: 0.428580
 >> iter 60000, loss: 0.502010
   Number of active neurons: 4
 >> iter 61000, loss: 0.532233
 >> iter 62000, loss: 0.437646
 >> iter 63000, loss: 0.482243
 >> iter 64000, loss: 0.470080
 >> iter 65000, loss: 0.479416
 >> iter 66000, loss: 0.480542
 >> iter 67000, loss: 0.520984
 >> iter 68000, loss: 0.555605
 >> iter 69000, loss: 0.697698
 >> iter 70000, loss: 0.681421
   Number of active neurons: 4
 >> iter 71000, loss: 0.708115
 >> iter 72000, loss: 0.526322
 >> iter 73000, loss: 0.643427
 >> iter 74000, loss: 0.595725
 >> iter 75000, loss: 0.670538
 >> iter 76000, loss: 0.518087
 >> iter 77000, loss: 0.574752
 >> iter 78000, loss: 0.726700
 >> iter 79000, loss: 0.537199
 >> iter 80000, loss: 0.596264
   Number of active neurons: 4
 >> iter 81000, loss: 0.601192
 >> iter 82000, loss: 0.549697
 >> iter 83000, loss: 0.622697
 >> iter 84000, loss: 0.521672
 >> iter 85000, loss: 0.566303
 >> iter 86000, loss: 0.421214
 >> iter 87000, loss: 0.428732
 >> iter 88000, loss: 0.416964
 >> iter 89000, loss: 0.500321
 >> iter 90000, loss: 0.543674
   Number of active neurons: 4
 >> iter 91000, loss: 0.700171
 >> iter 92000, loss: 0.546227
 >> iter 93000, loss: 0.557118
 >> iter 94000, loss: 0.482502
 >> iter 95000, loss: 0.352081
 >> iter 96000, loss: 0.473815
 >> iter 97000, loss: 0.666515
 >> iter 98000, loss: 0.648390
 >> iter 99000, loss: 0.555717
 >> iter 100000, loss: 0.551718
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.706475
 >> iter 2000, loss: 13.601724
 >> iter 3000, loss: 10.215309
 >> iter 4000, loss: 8.831631
 >> iter 5000, loss: 7.717511
 >> iter 6000, loss: 7.106574
 >> iter 7000, loss: 8.433588
 >> iter 8000, loss: 6.934312
 >> iter 9000, loss: 4.091444
 >> iter 10000, loss: 2.423086
   Number of active neurons: 4
 >> iter 11000, loss: 1.537432
 >> iter 12000, loss: 1.039447
 >> iter 13000, loss: 0.722696
 >> iter 14000, loss: 0.789363
 >> iter 15000, loss: 0.799253
 >> iter 16000, loss: 0.741902
 >> iter 17000, loss: 0.656378
 >> iter 18000, loss: 0.684476
 >> iter 19000, loss: 0.793780
 >> iter 20000, loss: 0.678286
   Number of active neurons: 4
 >> iter 21000, loss: 0.675198
 >> iter 22000, loss: 0.615719
 >> iter 23000, loss: 0.706507
 >> iter 24000, loss: 0.851442
 >> iter 25000, loss: 0.946971
 >> iter 26000, loss: 0.809830
 >> iter 27000, loss: 0.686857
 >> iter 28000, loss: 0.649382
 >> iter 29000, loss: 0.611971
 >> iter 30000, loss: 0.712500
   Number of active neurons: 4
 >> iter 31000, loss: 0.602516
 >> iter 32000, loss: 0.634790
 >> iter 33000, loss: 0.620176
 >> iter 34000, loss: 0.811205
 >> iter 35000, loss: 0.683112
 >> iter 36000, loss: 0.670444
 >> iter 37000, loss: 0.780749
 >> iter 38000, loss: 0.851410
 >> iter 39000, loss: 0.800653
 >> iter 40000, loss: 0.714195
   Number of active neurons: 4
 >> iter 41000, loss: 0.604901
 >> iter 42000, loss: 0.633321
 >> iter 43000, loss: 0.629317
 >> iter 44000, loss: 0.642306
 >> iter 45000, loss: 0.655776
 >> iter 46000, loss: 0.531365
 >> iter 47000, loss: 0.453324
 >> iter 48000, loss: 0.731532
 >> iter 49000, loss: 0.689878
 >> iter 50000, loss: 0.883939
   Number of active neurons: 4
 >> iter 51000, loss: 0.687116
 >> iter 52000, loss: 0.563350
 >> iter 53000, loss: 0.941566
 >> iter 54000, loss: 0.712951
 >> iter 55000, loss: 0.610258
 >> iter 56000, loss: 0.672334
 >> iter 57000, loss: 0.642205
 >> iter 58000, loss: 0.668478
 >> iter 59000, loss: 0.727552
 >> iter 60000, loss: 0.785971
   Number of active neurons: 4
 >> iter 61000, loss: 0.807759
 >> iter 62000, loss: 0.723464
 >> iter 63000, loss: 0.699207
 >> iter 64000, loss: 0.724348
 >> iter 65000, loss: 0.628574
 >> iter 66000, loss: 0.693508
 >> iter 67000, loss: 0.777925
 >> iter 68000, loss: 0.731708
 >> iter 69000, loss: 0.764628
 >> iter 70000, loss: 0.635012
   Number of active neurons: 4
 >> iter 71000, loss: 0.507449
 >> iter 72000, loss: 0.475808
 >> iter 73000, loss: 0.528366
 >> iter 74000, loss: 0.572733
 >> iter 75000, loss: 0.647687
 >> iter 76000, loss: 0.509542
 >> iter 77000, loss: 0.662692
 >> iter 78000, loss: 0.587043
 >> iter 79000, loss: 0.682823
 >> iter 80000, loss: 0.692691
   Number of active neurons: 4
 >> iter 81000, loss: 0.566829
 >> iter 82000, loss: 0.478858
 >> iter 83000, loss: 0.567320
 >> iter 84000, loss: 0.650045
 >> iter 85000, loss: 0.696155
 >> iter 86000, loss: 0.742090
 >> iter 87000, loss: 0.622282
 >> iter 88000, loss: 0.710512
 >> iter 89000, loss: 0.652944
 >> iter 90000, loss: 0.675214
   Number of active neurons: 4
 >> iter 91000, loss: 0.669154
 >> iter 92000, loss: 0.643744
 >> iter 93000, loss: 0.593878
 >> iter 94000, loss: 0.544795
 >> iter 95000, loss: 0.749638
 >> iter 96000, loss: 0.626146
 >> iter 97000, loss: 0.615588
 >> iter 98000, loss: 0.685211
 >> iter 99000, loss: 0.691635
 >> iter 100000, loss: 0.669779
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.612274
 >> iter 2000, loss: 11.545349
 >> iter 3000, loss: 5.772836
 >> iter 4000, loss: 2.397438
 >> iter 5000, loss: 1.156989
 >> iter 6000, loss: 0.579622
 >> iter 7000, loss: 0.344887
 >> iter 8000, loss: 0.414259
 >> iter 9000, loss: 0.479027
 >> iter 10000, loss: 0.337107
   Number of active neurons: 4
 >> iter 11000, loss: 0.358093
 >> iter 12000, loss: 0.352548
 >> iter 13000, loss: 0.358835
 >> iter 14000, loss: 0.293548
 >> iter 15000, loss: 0.283791
 >> iter 16000, loss: 0.193091
 >> iter 17000, loss: 0.213542
 >> iter 18000, loss: 0.265708
 >> iter 19000, loss: 0.196199
 >> iter 20000, loss: 0.275128
   Number of active neurons: 4
 >> iter 21000, loss: 0.264753
 >> iter 22000, loss: 0.224343
 >> iter 23000, loss: 0.241157
 >> iter 24000, loss: 0.217301
 >> iter 25000, loss: 0.351408
 >> iter 26000, loss: 0.325275
 >> iter 27000, loss: 0.383795
 >> iter 28000, loss: 0.314438
 >> iter 29000, loss: 0.304681
 >> iter 30000, loss: 0.199241
   Number of active neurons: 4
 >> iter 31000, loss: 0.223782
 >> iter 32000, loss: 0.339721
 >> iter 33000, loss: 0.254565
 >> iter 34000, loss: 0.226093
 >> iter 35000, loss: 0.259005
 >> iter 36000, loss: 0.331866
 >> iter 37000, loss: 0.303312
 >> iter 38000, loss: 0.307206
 >> iter 39000, loss: 0.363862
 >> iter 40000, loss: 0.312102
   Number of active neurons: 4
 >> iter 41000, loss: 0.320404
 >> iter 42000, loss: 0.289503
 >> iter 43000, loss: 0.226663
 >> iter 44000, loss: 0.199124
 >> iter 45000, loss: 0.213038
 >> iter 46000, loss: 0.197311
 >> iter 47000, loss: 0.265312
 >> iter 48000, loss: 0.223756
 >> iter 49000, loss: 0.283725
 >> iter 50000, loss: 0.249449
   Number of active neurons: 4
 >> iter 51000, loss: 0.267757
 >> iter 52000, loss: 0.280886
 >> iter 53000, loss: 0.168902
 >> iter 54000, loss: 0.289921
 >> iter 55000, loss: 0.227842
 >> iter 56000, loss: 0.220331
 >> iter 57000, loss: 0.273066
 >> iter 58000, loss: 0.221148
 >> iter 59000, loss: 0.306834
 >> iter 60000, loss: 0.328342
   Number of active neurons: 4
 >> iter 61000, loss: 0.239828
 >> iter 62000, loss: 0.225993
 >> iter 63000, loss: 0.295383
 >> iter 64000, loss: 0.293871
 >> iter 65000, loss: 0.270117
 >> iter 66000, loss: 0.150762
 >> iter 67000, loss: 0.252371
 >> iter 68000, loss: 0.171985
 >> iter 69000, loss: 0.175678
 >> iter 70000, loss: 0.180145
   Number of active neurons: 4
 >> iter 71000, loss: 0.274429
 >> iter 72000, loss: 0.237578
 >> iter 73000, loss: 0.292357
 >> iter 74000, loss: 0.275404
 >> iter 75000, loss: 0.251098
 >> iter 76000, loss: 0.199467
 >> iter 77000, loss: 0.167209
 >> iter 78000, loss: 0.326814
 >> iter 79000, loss: 0.227018
 >> iter 80000, loss: 0.269049
   Number of active neurons: 4
 >> iter 81000, loss: 0.276522
 >> iter 82000, loss: 0.238610
 >> iter 83000, loss: 0.220356
 >> iter 84000, loss: 0.239580
 >> iter 85000, loss: 0.205392
 >> iter 86000, loss: 0.328186
 >> iter 87000, loss: 0.274822
 >> iter 88000, loss: 0.396146
 >> iter 89000, loss: 0.246622
 >> iter 90000, loss: 0.261109
   Number of active neurons: 4
 >> iter 91000, loss: 0.229215
 >> iter 92000, loss: 0.242339
 >> iter 93000, loss: 0.246025
 >> iter 94000, loss: 0.259050
 >> iter 95000, loss: 0.313303
 >> iter 96000, loss: 0.256681
 >> iter 97000, loss: 0.273370
 >> iter 98000, loss: 0.230685
 >> iter 99000, loss: 0.213406
 >> iter 100000, loss: 0.258708
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.630548
 >> iter 2000, loss: 10.458180
 >> iter 3000, loss: 5.657495
 >> iter 4000, loss: 3.214167
 >> iter 5000, loss: 1.831167
 >> iter 6000, loss: 1.291014
 >> iter 7000, loss: 1.136639
 >> iter 8000, loss: 0.882710
 >> iter 9000, loss: 0.948689
 >> iter 10000, loss: 0.664916
   Number of active neurons: 4
 >> iter 11000, loss: 0.612613
 >> iter 12000, loss: 0.464418
 >> iter 13000, loss: 0.460811
 >> iter 14000, loss: 0.465362
 >> iter 15000, loss: 0.486486
 >> iter 16000, loss: 0.487804
 >> iter 17000, loss: 0.521531
 >> iter 18000, loss: 0.470844
 >> iter 19000, loss: 0.461300
 >> iter 20000, loss: 0.441130
   Number of active neurons: 4
 >> iter 21000, loss: 0.417426
 >> iter 22000, loss: 0.377927
 >> iter 23000, loss: 0.432811
 >> iter 24000, loss: 0.356459
 >> iter 25000, loss: 0.418687
 >> iter 26000, loss: 0.445362
 >> iter 27000, loss: 0.418059
 >> iter 28000, loss: 0.431626
 >> iter 29000, loss: 0.408743
 >> iter 30000, loss: 0.347139
   Number of active neurons: 4
 >> iter 31000, loss: 0.399687
 >> iter 32000, loss: 0.415814
 >> iter 33000, loss: 0.381818
 >> iter 34000, loss: 0.356376
 >> iter 35000, loss: 0.358991
 >> iter 36000, loss: 0.444233
 >> iter 37000, loss: 0.371755
 >> iter 38000, loss: 0.496764
 >> iter 39000, loss: 0.506516
 >> iter 40000, loss: 0.610927
   Number of active neurons: 4
 >> iter 41000, loss: 0.527086
 >> iter 42000, loss: 0.381918
 >> iter 43000, loss: 0.377285
 >> iter 44000, loss: 0.442873
 >> iter 45000, loss: 0.469304
 >> iter 46000, loss: 0.474129
 >> iter 47000, loss: 0.560762
 >> iter 48000, loss: 0.461038
 >> iter 49000, loss: 0.472423
 >> iter 50000, loss: 0.489919
   Number of active neurons: 4
 >> iter 51000, loss: 0.528010
 >> iter 52000, loss: 0.491025
 >> iter 53000, loss: 0.602986
 >> iter 54000, loss: 0.536943
 >> iter 55000, loss: 0.540758
 >> iter 56000, loss: 0.369139
 >> iter 57000, loss: 0.348685
 >> iter 58000, loss: 0.590995
 >> iter 59000, loss: 0.505066
 >> iter 60000, loss: 0.498780
   Number of active neurons: 4
 >> iter 61000, loss: 0.454656
 >> iter 62000, loss: 0.471713
 >> iter 63000, loss: 0.483938
 >> iter 64000, loss: 0.489663
 >> iter 65000, loss: 0.470208
 >> iter 66000, loss: 0.674174
 >> iter 67000, loss: 0.520558
 >> iter 68000, loss: 0.572715
 >> iter 69000, loss: 0.679919
 >> iter 70000, loss: 0.522384
   Number of active neurons: 4
 >> iter 71000, loss: 0.517862
 >> iter 72000, loss: 0.526466
 >> iter 73000, loss: 0.498560
 >> iter 74000, loss: 0.507211
 >> iter 75000, loss: 0.555713
 >> iter 76000, loss: 0.509086
 >> iter 77000, loss: 0.681346
 >> iter 78000, loss: 0.648146
 >> iter 79000, loss: 0.624758
 >> iter 80000, loss: 0.539933
   Number of active neurons: 4
 >> iter 81000, loss: 0.529528
 >> iter 82000, loss: 0.394821
 >> iter 83000, loss: 0.408838
 >> iter 84000, loss: 0.475444
 >> iter 85000, loss: 0.520108
 >> iter 86000, loss: 0.462154
 >> iter 87000, loss: 0.555187
 >> iter 88000, loss: 0.636287
 >> iter 89000, loss: 0.624228
 >> iter 90000, loss: 0.503982
   Number of active neurons: 4
 >> iter 91000, loss: 0.447090
 >> iter 92000, loss: 0.499584
 >> iter 93000, loss: 0.321847
 >> iter 94000, loss: 0.411994
 >> iter 95000, loss: 0.589521
 >> iter 96000, loss: 0.622688
 >> iter 97000, loss: 0.730315
 >> iter 98000, loss: 0.607347
 >> iter 99000, loss: 0.665439
 >> iter 100000, loss: 0.572200
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 21.2852476502
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.028830
 >> iter 2000, loss: 12.861769
 >> iter 3000, loss: 10.428432
 >> iter 4000, loss: 8.034856
 >> iter 5000, loss: 5.843907
 >> iter 6000, loss: 4.317116
 >> iter 7000, loss: 3.588031
 >> iter 8000, loss: 3.499662
 >> iter 9000, loss: 3.310150
 >> iter 10000, loss: 3.106174
   Number of active neurons: 4
 >> iter 11000, loss: 3.053585
 >> iter 12000, loss: 3.200927
 >> iter 13000, loss: 3.013863
 >> iter 14000, loss: 3.004717
 >> iter 15000, loss: 3.070450
 >> iter 16000, loss: 3.040978
 >> iter 17000, loss: 2.949668
 >> iter 18000, loss: 2.931072
 >> iter 19000, loss: 2.955173
 >> iter 20000, loss: 2.971070
   Number of active neurons: 4
 >> iter 21000, loss: 2.907966
 >> iter 22000, loss: 3.120269
 >> iter 23000, loss: 3.019179
 >> iter 24000, loss: 3.033262
 >> iter 25000, loss: 2.997901
 >> iter 26000, loss: 3.098185
 >> iter 27000, loss: 3.049362
 >> iter 28000, loss: 2.980335
 >> iter 29000, loss: 2.969153
 >> iter 30000, loss: 2.961188
   Number of active neurons: 4
 >> iter 31000, loss: 2.971328
 >> iter 32000, loss: 2.847082
 >> iter 33000, loss: 2.875411
 >> iter 34000, loss: 3.032631
 >> iter 35000, loss: 3.076224
 >> iter 36000, loss: 2.880784
 >> iter 37000, loss: 2.916987
 >> iter 38000, loss: 2.952045
 >> iter 39000, loss: 3.008179
 >> iter 40000, loss: 2.924252
   Number of active neurons: 4
 >> iter 41000, loss: 2.978682
 >> iter 42000, loss: 3.068561
 >> iter 43000, loss: 2.922271
 >> iter 44000, loss: 2.974147
 >> iter 45000, loss: 2.954714
 >> iter 46000, loss: 2.880159
 >> iter 47000, loss: 2.925930
 >> iter 48000, loss: 2.986669
 >> iter 49000, loss: 3.024935
 >> iter 50000, loss: 3.202494
   Number of active neurons: 4
 >> iter 51000, loss: 3.018679
 >> iter 52000, loss: 3.076138
 >> iter 53000, loss: 2.964813
 >> iter 54000, loss: 3.106896
 >> iter 55000, loss: 3.010940
 >> iter 56000, loss: 3.114421
 >> iter 57000, loss: 2.976190
 >> iter 58000, loss: 3.108321
 >> iter 59000, loss: 2.958158
 >> iter 60000, loss: 2.999129
   Number of active neurons: 4
 >> iter 61000, loss: 2.910706
 >> iter 62000, loss: 2.969845
 >> iter 63000, loss: 2.930836
 >> iter 64000, loss: 2.918558
 >> iter 65000, loss: 2.876567
 >> iter 66000, loss: 3.013902
 >> iter 67000, loss: 2.956676
 >> iter 68000, loss: 2.950996
 >> iter 69000, loss: 2.946345
 >> iter 70000, loss: 2.991940
   Number of active neurons: 4
 >> iter 71000, loss: 2.967236
 >> iter 72000, loss: 3.025023
 >> iter 73000, loss: 2.975010
 >> iter 74000, loss: 2.976445
 >> iter 75000, loss: 3.062355
 >> iter 76000, loss: 3.072530
 >> iter 77000, loss: 3.085250
 >> iter 78000, loss: 3.013171
 >> iter 79000, loss: 2.980303
 >> iter 80000, loss: 2.880750
   Number of active neurons: 4
 >> iter 81000, loss: 2.902330
 >> iter 82000, loss: 2.896565
 >> iter 83000, loss: 2.992506
 >> iter 84000, loss: 3.101738
 >> iter 85000, loss: 3.114927
 >> iter 86000, loss: 2.961121
 >> iter 87000, loss: 2.968582
 >> iter 88000, loss: 2.931024
 >> iter 89000, loss: 3.075483
 >> iter 90000, loss: 3.189527
   Number of active neurons: 4
 >> iter 91000, loss: 3.014956
 >> iter 92000, loss: 2.952630
 >> iter 93000, loss: 3.018811
 >> iter 94000, loss: 2.926325
 >> iter 95000, loss: 3.010934
 >> iter 96000, loss: 3.035735
 >> iter 97000, loss: 2.925796
 >> iter 98000, loss: 2.958036
 >> iter 99000, loss: 2.928724
 >> iter 100000, loss: 3.004240
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 4.87790244195
   - Test - Long: 0.17999100045
   - Test - Big: 5.08594914051
   - Test - A: 0.626624891674
   - Test - B: 13.8990733951
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 21.037304
 >> iter 2000, loss: 18.735218
 >> iter 3000, loss: 17.828263
 >> iter 4000, loss: 17.557539
 >> iter 5000, loss: 17.393953
 >> iter 6000, loss: 17.399767
 >> iter 7000, loss: 17.334485
 >> iter 8000, loss: 17.377683
 >> iter 9000, loss: 17.326842
 >> iter 10000, loss: 17.376461
   Number of active neurons: 0
 >> iter 11000, loss: 17.324224
 >> iter 12000, loss: 17.376003
 >> iter 13000, loss: 17.320235
 >> iter 14000, loss: 17.374906
 >> iter 15000, loss: 17.320795
 >> iter 16000, loss: 17.374885
 >> iter 17000, loss: 17.322167
 >> iter 18000, loss: 17.374664
 >> iter 19000, loss: 17.320916
 >> iter 20000, loss: 17.374841
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 17.317895
 >> iter 22000, loss: 17.373813
 >> iter 23000, loss: 17.319005
 >> iter 24000, loss: 17.375437
 >> iter 25000, loss: 17.318964
 >> iter 26000, loss: 17.373752
 >> iter 27000, loss: 17.324807
 >> iter 28000, loss: 17.373265
 >> iter 29000, loss: 17.323039
 >> iter 30000, loss: 17.372201
   Number of active neurons: 0
   SHOCK
   Setting new limit to 250000.0 iters...
   Number of active neurons: 0
 >> iter 31000, loss: 17.322129
 >> iter 32000, loss: 17.371332
 >> iter 33000, loss: 17.328108
 >> iter 34000, loss: 17.370062
 >> iter 35000, loss: 17.327290
 >> iter 36000, loss: 17.375660
 >> iter 37000, loss: 17.327154
 >> iter 38000, loss: 17.375447
 >> iter 39000, loss: 17.331852
 >> iter 40000, loss: 17.376134
   Number of active neurons: 0
   SHOCK
   Setting new limit to 275000.0 iters...
   Number of active neurons: 0
 >> iter 41000, loss: 17.328963
 >> iter 42000, loss: 17.375205
 >> iter 43000, loss: 17.329508
 >> iter 44000, loss: 17.372335
 >> iter 45000, loss: 17.329042
 >> iter 46000, loss: 17.371789
 >> iter 47000, loss: 17.330408
 >> iter 48000, loss: 17.369658
 >> iter 49000, loss: 17.330643
 >> iter 50000, loss: 17.371992
   Number of active neurons: 0
   SHOCK
   Setting new limit to 287500.0 iters...
   Number of active neurons: 0
 >> iter 51000, loss: 17.330305
 >> iter 52000, loss: 17.370316
 >> iter 53000, loss: 17.328930
 >> iter 54000, loss: 17.368894
 >> iter 55000, loss: 17.328161
 >> iter 56000, loss: 17.366936
 >> iter 57000, loss: 17.330334
 >> iter 58000, loss: 17.364327
 >> iter 59000, loss: 17.331779
 >> iter 60000, loss: 17.365080
   Number of active neurons: 0
   SHOCK
   Setting new limit to 293750.0 iters...
   Number of active neurons: 0
 >> iter 61000, loss: 17.332162
 >> iter 62000, loss: 17.365119
 >> iter 63000, loss: 17.332271
 >> iter 64000, loss: 17.370064
 >> iter 65000, loss: 17.332118
 >> iter 66000, loss: 17.374276
 >> iter 67000, loss: 17.332229
 >> iter 68000, loss: 17.370799
 >> iter 69000, loss: 17.331800
 >> iter 70000, loss: 17.366686
   Number of active neurons: 0
   SHOCK
   Setting new limit to 296875.0 iters...
   Number of active neurons: 0
 >> iter 71000, loss: 17.331986
 >> iter 72000, loss: 17.367659
 >> iter 73000, loss: 17.330803
 >> iter 74000, loss: 17.370948
 >> iter 75000, loss: 17.329140
 >> iter 76000, loss: 17.372050
 >> iter 77000, loss: 17.328300
 >> iter 78000, loss: 17.373002
 >> iter 79000, loss: 17.328921
 >> iter 80000, loss: 17.372404
   Number of active neurons: 0
   SHOCK
   Setting new limit to 298437.5 iters...
   Number of active neurons: 0
 >> iter 81000, loss: 17.329394
 >> iter 82000, loss: 17.370928
 >> iter 83000, loss: 17.328947
 >> iter 84000, loss: 17.367320
 >> iter 85000, loss: 17.325923
 >> iter 86000, loss: 17.363506
 >> iter 87000, loss: 17.325808
 >> iter 88000, loss: 17.357910
 >> iter 89000, loss: 17.323475
 >> iter 90000, loss: 17.358718
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299218.75 iters...
   Number of active neurons: 0
 >> iter 91000, loss: 17.327662
 >> iter 92000, loss: 17.355517
 >> iter 93000, loss: 17.325695
 >> iter 94000, loss: 17.363306
 >> iter 95000, loss: 17.326105
 >> iter 96000, loss: 17.362284
 >> iter 97000, loss: 17.329669
 >> iter 98000, loss: 17.360729
 >> iter 99000, loss: 17.327968
 >> iter 100000, loss: 17.368646
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299609.375 iters...
   Number of active neurons: 0
 >> iter 101000, loss: 17.330254
 >> iter 102000, loss: 17.364440
 >> iter 103000, loss: 17.331574
 >> iter 104000, loss: 17.361735
 >> iter 105000, loss: 17.330603
 >> iter 106000, loss: 17.359473
 >> iter 107000, loss: 17.329008
 >> iter 108000, loss: 17.359779
 >> iter 109000, loss: 17.331156
 >> iter 110000, loss: 17.359970
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299804.6875 iters...
   Number of active neurons: 0
 >> iter 111000, loss: 17.334597
 >> iter 112000, loss: 17.364575
 >> iter 113000, loss: 17.332460
 >> iter 114000, loss: 17.364045
 >> iter 115000, loss: 17.333115
 >> iter 116000, loss: 17.366707
 >> iter 117000, loss: 17.331649
 >> iter 118000, loss: 17.369021
 >> iter 119000, loss: 17.329913
 >> iter 120000, loss: 17.370849
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299902.34375 iters...
   Number of active neurons: 0
 >> iter 121000, loss: 17.332243
 >> iter 122000, loss: 17.370025
 >> iter 123000, loss: 17.330852
 >> iter 124000, loss: 17.368817
 >> iter 125000, loss: 17.333743
 >> iter 126000, loss: 17.369595
 >> iter 127000, loss: 17.332453
 >> iter 128000, loss: 17.370142
 >> iter 129000, loss: 17.331248
 >> iter 130000, loss: 17.371283
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299951.171875 iters...
   Number of active neurons: 0
 >> iter 131000, loss: 17.332339
 >> iter 132000, loss: 17.370564
 >> iter 133000, loss: 17.330895
 >> iter 134000, loss: 17.369574
 >> iter 135000, loss: 17.333121
 >> iter 136000, loss: 17.367121
 >> iter 137000, loss: 17.334685
 >> iter 138000, loss: 17.368479
 >> iter 139000, loss: 17.333745
 >> iter 140000, loss: 17.369112
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299975.585938 iters...
   Number of active neurons: 0
 >> iter 141000, loss: 17.335499
 >> iter 142000, loss: 17.367805
 >> iter 143000, loss: 17.335149
 >> iter 144000, loss: 17.368874
 >> iter 145000, loss: 17.334148
 >> iter 146000, loss: 17.369795
 >> iter 147000, loss: 17.331079
 >> iter 148000, loss: 17.370390
 >> iter 149000, loss: 17.329407
 >> iter 150000, loss: 17.370188
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299987.792969 iters...
   Number of active neurons: 0
 >> iter 151000, loss: 17.331164
 >> iter 152000, loss: 17.369095
 >> iter 153000, loss: 17.333826
 >> iter 154000, loss: 17.368185
 >> iter 155000, loss: 17.335648
 >> iter 156000, loss: 17.367973
 >> iter 157000, loss: 17.335939
 >> iter 158000, loss: 17.368329
 >> iter 159000, loss: 17.335607
 >> iter 160000, loss: 17.367869
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299993.896484 iters...
   Number of active neurons: 0
 >> iter 161000, loss: 17.334484
 >> iter 162000, loss: 17.369989
 >> iter 163000, loss: 17.335336
 >> iter 164000, loss: 17.371547
 >> iter 165000, loss: 17.335693
 >> iter 166000, loss: 17.371366
 >> iter 167000, loss: 17.335923
 >> iter 168000, loss: 17.370281
 >> iter 169000, loss: 17.336293
 >> iter 170000, loss: 17.370063
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299996.948242 iters...
   Number of active neurons: 0
 >> iter 171000, loss: 17.336256
 >> iter 172000, loss: 17.368394
 >> iter 173000, loss: 17.336231
 >> iter 174000, loss: 17.367266
 >> iter 175000, loss: 17.336050
 >> iter 176000, loss: 17.368885
 >> iter 177000, loss: 17.335565
 >> iter 178000, loss: 17.366075
 >> iter 179000, loss: 17.335386
 >> iter 180000, loss: 17.363386
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299998.474121 iters...
   Number of active neurons: 0
 >> iter 181000, loss: 17.335402
 >> iter 182000, loss: 17.363316
 >> iter 183000, loss: 17.336686
 >> iter 184000, loss: 17.359318
 >> iter 185000, loss: 17.336658
 >> iter 186000, loss: 17.356702
 >> iter 187000, loss: 17.336795
 >> iter 188000, loss: 17.355682
 >> iter 189000, loss: 17.336814
 >> iter 190000, loss: 17.363589
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.237061 iters...
   Number of active neurons: 0
 >> iter 191000, loss: 17.336741
 >> iter 192000, loss: 17.361589
 >> iter 193000, loss: 17.336933
 >> iter 194000, loss: 17.362199
 >> iter 195000, loss: 17.336833
 >> iter 196000, loss: 17.363635
 >> iter 197000, loss: 17.337265
 >> iter 198000, loss: 17.362698
 >> iter 199000, loss: 17.337094
 >> iter 200000, loss: 17.358390
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.61853 iters...
   Number of active neurons: 0
 >> iter 201000, loss: 17.338634
 >> iter 202000, loss: 17.359971
 >> iter 203000, loss: 17.338372
 >> iter 204000, loss: 17.361566
 >> iter 205000, loss: 17.339260
 >> iter 206000, loss: 17.359421
 >> iter 207000, loss: 17.339597
 >> iter 208000, loss: 17.358462
 >> iter 209000, loss: 17.338796
 >> iter 210000, loss: 17.357933
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.809265 iters...
   Number of active neurons: 0
 >> iter 211000, loss: 17.338451
 >> iter 212000, loss: 17.361791
 >> iter 213000, loss: 17.338465
 >> iter 214000, loss: 17.363977
 >> iter 215000, loss: 17.338653
 >> iter 216000, loss: 17.364955
 >> iter 217000, loss: 17.338337
 >> iter 218000, loss: 17.363797
 >> iter 219000, loss: 17.337428
 >> iter 220000, loss: 17.361192
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.904633 iters...
   Number of active neurons: 0
 >> iter 221000, loss: 17.336433
 >> iter 222000, loss: 17.359653
 >> iter 223000, loss: 17.337245
 >> iter 224000, loss: 17.361153
 >> iter 225000, loss: 17.335523
 >> iter 226000, loss: 17.361261
 >> iter 227000, loss: 17.336087
 >> iter 228000, loss: 17.359658
 >> iter 229000, loss: 17.336815
 >> iter 230000, loss: 17.357255
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.952316 iters...
   Number of active neurons: 0
 >> iter 231000, loss: 17.339906
 >> iter 232000, loss: 17.352942
 >> iter 233000, loss: 17.339884
 >> iter 234000, loss: 17.351925
 >> iter 235000, loss: 17.339732
 >> iter 236000, loss: 17.348037
 >> iter 237000, loss: 17.339430
 >> iter 238000, loss: 17.353121
 >> iter 239000, loss: 17.337862
 >> iter 240000, loss: 17.356699
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.976158 iters...
   Number of active neurons: 0
 >> iter 241000, loss: 17.339593
 >> iter 242000, loss: 17.356182
 >> iter 243000, loss: 17.339589
 >> iter 244000, loss: 17.357527
 >> iter 245000, loss: 17.339255
 >> iter 246000, loss: 17.357376
 >> iter 247000, loss: 17.339839
 >> iter 248000, loss: 17.353952
 >> iter 249000, loss: 17.339222
 >> iter 250000, loss: 17.353433
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.988079 iters...
   Number of active neurons: 0
 >> iter 251000, loss: 17.341380
 >> iter 252000, loss: 17.350635
 >> iter 253000, loss: 17.340444
 >> iter 254000, loss: 17.349073
 >> iter 255000, loss: 17.341108
 >> iter 256000, loss: 17.349777
 >> iter 257000, loss: 17.340128
 >> iter 258000, loss: 17.349799
 >> iter 259000, loss: 17.339936
 >> iter 260000, loss: 17.349291
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99404 iters...
   Number of active neurons: 0
 >> iter 261000, loss: 17.338083
 >> iter 262000, loss: 17.351607
 >> iter 263000, loss: 17.336910
 >> iter 264000, loss: 17.347373
 >> iter 265000, loss: 17.336400
 >> iter 266000, loss: 17.352046
 >> iter 267000, loss: 17.338993
 >> iter 268000, loss: 17.349296
 >> iter 269000, loss: 17.339961
 >> iter 270000, loss: 17.346900
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99702 iters...
   Number of active neurons: 0
 >> iter 271000, loss: 17.338358
 >> iter 272000, loss: 17.341545
 >> iter 273000, loss: 17.336064
 >> iter 274000, loss: 17.341839
 >> iter 275000, loss: 17.339575
 >> iter 276000, loss: 17.346790
 >> iter 277000, loss: 17.339396
 >> iter 278000, loss: 17.351248
 >> iter 279000, loss: 17.338329
 >> iter 280000, loss: 17.348349
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.99851 iters...
   Number of active neurons: 0
 >> iter 281000, loss: 17.337130
 >> iter 282000, loss: 17.344877
 >> iter 283000, loss: 17.340174
 >> iter 284000, loss: 17.342082
 >> iter 285000, loss: 17.338221
 >> iter 286000, loss: 17.346971
 >> iter 287000, loss: 17.337313
 >> iter 288000, loss: 17.342089
 >> iter 289000, loss: 17.336385
 >> iter 290000, loss: 17.344366
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999255 iters...
   Number of active neurons: 0
 >> iter 291000, loss: 17.331526
 >> iter 292000, loss: 17.347784
 >> iter 293000, loss: 17.326790
 >> iter 294000, loss: 17.348628
 >> iter 295000, loss: 17.330889
 >> iter 296000, loss: 17.344618
 >> iter 297000, loss: 17.329363
 >> iter 298000, loss: 17.341681
 >> iter 299000, loss: 17.333407
 >> iter 300000, loss: 17.336052
   Number of active neurons: 0
   SHOCK
   Setting new limit to 299999.999627 iters...
   Number of active neurons: 0
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 44.5091098178
   - Test - Long: 92.2553872306
   - Test - Big: 44.5945540545
   - Test - A: 19.1920538631
   - Test - B: 29.618025465
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.453197
 >> iter 2000, loss: 12.672529
 >> iter 3000, loss: 10.130361
 >> iter 4000, loss: 8.532242
 >> iter 5000, loss: 6.694056
 >> iter 6000, loss: 3.823192
 >> iter 7000, loss: 1.951652
 >> iter 8000, loss: 1.118761
 >> iter 9000, loss: 0.829222
 >> iter 10000, loss: 0.722155
   Number of active neurons: 4
 >> iter 11000, loss: 0.488689
 >> iter 12000, loss: 0.415147
 >> iter 13000, loss: 0.352371
 >> iter 14000, loss: 0.331001
 >> iter 15000, loss: 0.286276
 >> iter 16000, loss: 0.308200
 >> iter 17000, loss: 0.298090
 >> iter 18000, loss: 0.431663
 >> iter 19000, loss: 0.408314
 >> iter 20000, loss: 0.327163
   Number of active neurons: 4
 >> iter 21000, loss: 0.431483
 >> iter 22000, loss: 0.459938
 >> iter 23000, loss: 0.354382
 >> iter 24000, loss: 0.336571
 >> iter 25000, loss: 0.334247
 >> iter 26000, loss: 0.334901
 >> iter 27000, loss: 0.334053
 >> iter 28000, loss: 0.364994
 >> iter 29000, loss: 0.358181
 >> iter 30000, loss: 0.421361
   Number of active neurons: 4
 >> iter 31000, loss: 0.353956
 >> iter 32000, loss: 0.372985
 >> iter 33000, loss: 0.307050
 >> iter 34000, loss: 0.406169
 >> iter 35000, loss: 0.352820
 >> iter 36000, loss: 0.392526
 >> iter 37000, loss: 0.371669
 >> iter 38000, loss: 0.361292
 >> iter 39000, loss: 0.370752
 >> iter 40000, loss: 0.444957
   Number of active neurons: 4
 >> iter 41000, loss: 0.344828
 >> iter 42000, loss: 0.418314
 >> iter 43000, loss: 0.408729
 >> iter 44000, loss: 0.381903
 >> iter 45000, loss: 0.454942
 >> iter 46000, loss: 0.426755
 >> iter 47000, loss: 0.371976
 >> iter 48000, loss: 0.390158
 >> iter 49000, loss: 0.428579
 >> iter 50000, loss: 0.323883
   Number of active neurons: 4
 >> iter 51000, loss: 0.447594
 >> iter 52000, loss: 0.404464
 >> iter 53000, loss: 0.429368
 >> iter 54000, loss: 0.402696
 >> iter 55000, loss: 0.368965
 >> iter 56000, loss: 0.572235
 >> iter 57000, loss: 0.544611
 >> iter 58000, loss: 0.495311
 >> iter 59000, loss: 0.493020
 >> iter 60000, loss: 0.346291
   Number of active neurons: 4
 >> iter 61000, loss: 0.337363
 >> iter 62000, loss: 0.398474
 >> iter 63000, loss: 0.387765
 >> iter 64000, loss: 0.346534
 >> iter 65000, loss: 0.517138
 >> iter 66000, loss: 0.394973
 >> iter 67000, loss: 0.396930
 >> iter 68000, loss: 0.463551
 >> iter 69000, loss: 0.469792
 >> iter 70000, loss: 0.412302
   Number of active neurons: 4
 >> iter 71000, loss: 0.387505
 >> iter 72000, loss: 0.423338
 >> iter 73000, loss: 0.438287
 >> iter 74000, loss: 0.442037
 >> iter 75000, loss: 0.481351
 >> iter 76000, loss: 0.459419
 >> iter 77000, loss: 0.391524
 >> iter 78000, loss: 0.374991
 >> iter 79000, loss: 0.369071
 >> iter 80000, loss: 0.319192
   Number of active neurons: 4
 >> iter 81000, loss: 0.277993
 >> iter 82000, loss: 0.356184
 >> iter 83000, loss: 0.334132
 >> iter 84000, loss: 0.395287
 >> iter 85000, loss: 0.462173
 >> iter 86000, loss: 0.401363
 >> iter 87000, loss: 0.340809
 >> iter 88000, loss: 0.319913
 >> iter 89000, loss: 0.285292
 >> iter 90000, loss: 0.334293
   Number of active neurons: 4
 >> iter 91000, loss: 0.363789
 >> iter 92000, loss: 0.405161
 >> iter 93000, loss: 0.409740
 >> iter 94000, loss: 0.409949
 >> iter 95000, loss: 0.439586
 >> iter 96000, loss: 0.343096
 >> iter 97000, loss: 0.357933
 >> iter 98000, loss: 0.343397
 >> iter 99000, loss: 0.429238
 >> iter 100000, loss: 0.435532
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.949212
 >> iter 2000, loss: 11.480902
 >> iter 3000, loss: 9.143589
 >> iter 4000, loss: 5.885932
 >> iter 5000, loss: 3.078002
 >> iter 6000, loss: 1.693824
 >> iter 7000, loss: 1.105581
 >> iter 8000, loss: 0.751598
 >> iter 9000, loss: 0.682505
 >> iter 10000, loss: 0.594745
   Number of active neurons: 4
 >> iter 11000, loss: 0.545452
 >> iter 12000, loss: 0.469246
 >> iter 13000, loss: 0.396584
 >> iter 14000, loss: 0.419938
 >> iter 15000, loss: 0.527888
 >> iter 16000, loss: 0.367643
 >> iter 17000, loss: 0.317631
 >> iter 18000, loss: 0.410426
 >> iter 19000, loss: 0.487594
 >> iter 20000, loss: 0.340248
   Number of active neurons: 4
 >> iter 21000, loss: 0.436458
 >> iter 22000, loss: 0.481305
 >> iter 23000, loss: 0.429193
 >> iter 24000, loss: 0.418690
 >> iter 25000, loss: 0.586052
 >> iter 26000, loss: 0.519132
 >> iter 27000, loss: 0.498844
 >> iter 28000, loss: 0.348433
 >> iter 29000, loss: 0.418193
 >> iter 30000, loss: 0.461561
   Number of active neurons: 4
 >> iter 31000, loss: 0.415291
 >> iter 32000, loss: 0.384123
 >> iter 33000, loss: 0.440223
 >> iter 34000, loss: 0.418054
 >> iter 35000, loss: 0.402522
 >> iter 36000, loss: 0.420156
 >> iter 37000, loss: 0.390428
 >> iter 38000, loss: 0.425699
 >> iter 39000, loss: 0.411684
 >> iter 40000, loss: 0.563799
   Number of active neurons: 4
 >> iter 41000, loss: 0.502660
 >> iter 42000, loss: 0.364813
 >> iter 43000, loss: 0.397958
 >> iter 44000, loss: 0.543722
 >> iter 45000, loss: 0.649538
 >> iter 46000, loss: 0.512707
 >> iter 47000, loss: 0.423541
 >> iter 48000, loss: 0.370326
 >> iter 49000, loss: 0.432333
 >> iter 50000, loss: 0.468803
   Number of active neurons: 4
 >> iter 51000, loss: 0.455935
 >> iter 52000, loss: 0.420105
 >> iter 53000, loss: 0.312186
 >> iter 54000, loss: 0.294477
 >> iter 55000, loss: 0.338658
 >> iter 56000, loss: 0.319604
 >> iter 57000, loss: 0.310894
 >> iter 58000, loss: 0.357629
 >> iter 59000, loss: 0.388098
 >> iter 60000, loss: 0.441882
   Number of active neurons: 4
 >> iter 61000, loss: 0.354492
 >> iter 62000, loss: 0.358366
 >> iter 63000, loss: 0.444024
 >> iter 64000, loss: 0.437086
 >> iter 65000, loss: 0.424244
 >> iter 66000, loss: 0.456133
 >> iter 67000, loss: 0.475179
 >> iter 68000, loss: 0.407349
 >> iter 69000, loss: 0.305668
 >> iter 70000, loss: 0.343835
   Number of active neurons: 4
 >> iter 71000, loss: 0.464252
 >> iter 72000, loss: 0.508294
 >> iter 73000, loss: 0.385595
 >> iter 74000, loss: 0.337350
 >> iter 75000, loss: 0.472243
 >> iter 76000, loss: 0.541398
 >> iter 77000, loss: 0.493167
 >> iter 78000, loss: 0.317092
 >> iter 79000, loss: 0.484124
 >> iter 80000, loss: 0.327929
   Number of active neurons: 4
 >> iter 81000, loss: 0.468096
 >> iter 82000, loss: 0.633161
 >> iter 83000, loss: 0.524873
 >> iter 84000, loss: 0.405403
 >> iter 85000, loss: 0.368551
 >> iter 86000, loss: 0.332200
 >> iter 87000, loss: 0.369391
 >> iter 88000, loss: 0.391885
 >> iter 89000, loss: 0.310954
 >> iter 90000, loss: 0.385384
   Number of active neurons: 4
 >> iter 91000, loss: 0.378188
 >> iter 92000, loss: 0.332656
 >> iter 93000, loss: 0.417330
 >> iter 94000, loss: 0.576590
 >> iter 95000, loss: 0.404839
 >> iter 96000, loss: 0.444209
 >> iter 97000, loss: 0.423450
 >> iter 98000, loss: 0.426000
 >> iter 99000, loss: 0.408355
 >> iter 100000, loss: 0.359603
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.640054
 >> iter 2000, loss: 11.770100
 >> iter 3000, loss: 7.941741
 >> iter 4000, loss: 5.556958
 >> iter 5000, loss: 4.291958
 >> iter 6000, loss: 2.980739
 >> iter 7000, loss: 2.661563
 >> iter 8000, loss: 2.224394
 >> iter 9000, loss: 1.528025
 >> iter 10000, loss: 1.336460
   Number of active neurons: 4
 >> iter 11000, loss: 0.825169
 >> iter 12000, loss: 0.499030
 >> iter 13000, loss: 0.468095
 >> iter 14000, loss: 0.342475
 >> iter 15000, loss: 0.267119
 >> iter 16000, loss: 0.182890
 >> iter 17000, loss: 0.157812
 >> iter 18000, loss: 0.223488
 >> iter 19000, loss: 0.197954
 >> iter 20000, loss: 0.196175
   Number of active neurons: 4
 >> iter 21000, loss: 0.223546
 >> iter 22000, loss: 0.213021
 >> iter 23000, loss: 0.207190
 >> iter 24000, loss: 0.233816
 >> iter 25000, loss: 0.193200
 >> iter 26000, loss: 0.229523
 >> iter 27000, loss: 0.308233
 >> iter 28000, loss: 0.316764
 >> iter 29000, loss: 0.340895
 >> iter 30000, loss: 0.309881
   Number of active neurons: 4
 >> iter 31000, loss: 0.339355
 >> iter 32000, loss: 0.415661
 >> iter 33000, loss: 0.395687
 >> iter 34000, loss: 0.302057
 >> iter 35000, loss: 0.430801
 >> iter 36000, loss: 0.303409
 >> iter 37000, loss: 0.312725
 >> iter 38000, loss: 0.311738
 >> iter 39000, loss: 0.453453
 >> iter 40000, loss: 0.363450
   Number of active neurons: 4
 >> iter 41000, loss: 0.347804
 >> iter 42000, loss: 0.368765
 >> iter 43000, loss: 0.446738
 >> iter 44000, loss: 0.306434
 >> iter 45000, loss: 0.300961
 >> iter 46000, loss: 0.285914
 >> iter 47000, loss: 0.338526
 >> iter 48000, loss: 0.380081
 >> iter 49000, loss: 0.292030
 >> iter 50000, loss: 0.414032
   Number of active neurons: 4
 >> iter 51000, loss: 0.470265
 >> iter 52000, loss: 0.470600
 >> iter 53000, loss: 0.359333
 >> iter 54000, loss: 0.440878
 >> iter 55000, loss: 0.499373
 >> iter 56000, loss: 0.453096
 >> iter 57000, loss: 0.415363
 >> iter 58000, loss: 0.398205
 >> iter 59000, loss: 0.299219
 >> iter 60000, loss: 0.416396
   Number of active neurons: 4
 >> iter 61000, loss: 0.493271
 >> iter 62000, loss: 0.414051
 >> iter 63000, loss: 0.338756
 >> iter 64000, loss: 0.431275
 >> iter 65000, loss: 0.387935
 >> iter 66000, loss: 0.370122
 >> iter 67000, loss: 0.291638
 >> iter 68000, loss: 0.339117
 >> iter 69000, loss: 0.399575
 >> iter 70000, loss: 0.307405
   Number of active neurons: 4
 >> iter 71000, loss: 0.287859
 >> iter 72000, loss: 0.283905
 >> iter 73000, loss: 0.347642
 >> iter 74000, loss: 0.276407
 >> iter 75000, loss: 0.375404
 >> iter 76000, loss: 0.286821
 >> iter 77000, loss: 0.256085
 >> iter 78000, loss: 0.452798
 >> iter 79000, loss: 0.279339
 >> iter 80000, loss: 0.246765
   Number of active neurons: 4
 >> iter 81000, loss: 0.406315
 >> iter 82000, loss: 0.278309
 >> iter 83000, loss: 0.307016
 >> iter 84000, loss: 0.393623
 >> iter 85000, loss: 0.354015
 >> iter 86000, loss: 0.332635
 >> iter 87000, loss: 0.384231
 >> iter 88000, loss: 0.441236
 >> iter 89000, loss: 0.392899
 >> iter 90000, loss: 0.215805
   Number of active neurons: 4
 >> iter 91000, loss: 0.292003
 >> iter 92000, loss: 0.405916
 >> iter 93000, loss: 0.463935
 >> iter 94000, loss: 0.441659
 >> iter 95000, loss: 0.408200
 >> iter 96000, loss: 0.385406
 >> iter 97000, loss: 0.408302
 >> iter 98000, loss: 0.443956
 >> iter 99000, loss: 0.443863
 >> iter 100000, loss: 0.542915
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.910250
 >> iter 2000, loss: 14.248402
 >> iter 3000, loss: 10.187790
 >> iter 4000, loss: 7.335483
 >> iter 5000, loss: 4.046322
 >> iter 6000, loss: 1.983812
 >> iter 7000, loss: 0.969857
 >> iter 8000, loss: 0.680483
 >> iter 9000, loss: 0.490942
 >> iter 10000, loss: 0.370484
   Number of active neurons: 4
 >> iter 11000, loss: 0.541426
 >> iter 12000, loss: 0.457978
 >> iter 13000, loss: 0.415061
 >> iter 14000, loss: 0.392949
 >> iter 15000, loss: 0.318462
 >> iter 16000, loss: 0.328199
 >> iter 17000, loss: 0.316437
 >> iter 18000, loss: 0.538472
 >> iter 19000, loss: 0.488289
 >> iter 20000, loss: 0.481827
   Number of active neurons: 4
 >> iter 21000, loss: 0.358344
 >> iter 22000, loss: 0.407727
 >> iter 23000, loss: 0.417524
 >> iter 24000, loss: 0.278745
 >> iter 25000, loss: 0.251076
 >> iter 26000, loss: 0.256522
 >> iter 27000, loss: 0.292098
 >> iter 28000, loss: 0.313169
 >> iter 29000, loss: 0.287791
 >> iter 30000, loss: 0.418233
   Number of active neurons: 4
 >> iter 31000, loss: 0.501981
 >> iter 32000, loss: 0.414412
 >> iter 33000, loss: 0.468319
 >> iter 34000, loss: 0.394423
 >> iter 35000, loss: 0.345195
 >> iter 36000, loss: 0.356023
 >> iter 37000, loss: 0.424621
 >> iter 38000, loss: 0.368333
 >> iter 39000, loss: 0.345173
 >> iter 40000, loss: 0.427353
   Number of active neurons: 4
 >> iter 41000, loss: 0.333869
 >> iter 42000, loss: 0.455715
 >> iter 43000, loss: 0.422605
 >> iter 44000, loss: 0.334490
 >> iter 45000, loss: 0.378239
 >> iter 46000, loss: 0.347269
 >> iter 47000, loss: 0.299613
 >> iter 48000, loss: 0.227090
 >> iter 49000, loss: 0.461460
 >> iter 50000, loss: 0.424789
   Number of active neurons: 4
 >> iter 51000, loss: 0.381854
 >> iter 52000, loss: 0.414028
 >> iter 53000, loss: 0.382049
 >> iter 54000, loss: 0.330204
 >> iter 55000, loss: 0.422992
 >> iter 56000, loss: 0.350378
 >> iter 57000, loss: 0.455369
 >> iter 58000, loss: 0.460510
 >> iter 59000, loss: 0.332857
 >> iter 60000, loss: 0.417853
   Number of active neurons: 4
 >> iter 61000, loss: 0.475686
 >> iter 62000, loss: 0.358440
 >> iter 63000, loss: 0.524254
 >> iter 64000, loss: 0.356553
 >> iter 65000, loss: 0.467897
 >> iter 66000, loss: 0.364226
 >> iter 67000, loss: 0.400535
 >> iter 68000, loss: 0.384886
 >> iter 69000, loss: 0.292488
 >> iter 70000, loss: 0.399126
   Number of active neurons: 4
 >> iter 71000, loss: 0.422536
 >> iter 72000, loss: 0.436873
 >> iter 73000, loss: 0.392274
 >> iter 74000, loss: 0.408257
 >> iter 75000, loss: 0.332044
 >> iter 76000, loss: 0.307978
 >> iter 77000, loss: 0.364503
 >> iter 78000, loss: 0.314517
 >> iter 79000, loss: 0.329477
 >> iter 80000, loss: 0.402098
   Number of active neurons: 4
 >> iter 81000, loss: 0.344635
 >> iter 82000, loss: 0.421294
 >> iter 83000, loss: 0.310096
 >> iter 84000, loss: 0.390785
 >> iter 85000, loss: 0.404927
 >> iter 86000, loss: 0.412757
 >> iter 87000, loss: 0.403992
 >> iter 88000, loss: 0.454780
 >> iter 89000, loss: 0.455438
 >> iter 90000, loss: 0.357139
   Number of active neurons: 4
 >> iter 91000, loss: 0.408516
 >> iter 92000, loss: 0.380748
 >> iter 93000, loss: 0.411868
 >> iter 94000, loss: 0.496384
 >> iter 95000, loss: 0.434507
 >> iter 96000, loss: 0.389296
 >> iter 97000, loss: 0.477444
 >> iter 98000, loss: 0.418244
 >> iter 99000, loss: 0.466617
 >> iter 100000, loss: 0.542992
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.968474
 >> iter 2000, loss: 12.939677
 >> iter 3000, loss: 9.365249
 >> iter 4000, loss: 6.256919
 >> iter 5000, loss: 4.972003
 >> iter 6000, loss: 4.002103
 >> iter 7000, loss: 3.696620
 >> iter 8000, loss: 3.375652
 >> iter 9000, loss: 3.245614
 >> iter 10000, loss: 3.116099
   Number of active neurons: 4
 >> iter 11000, loss: 3.126737
 >> iter 12000, loss: 3.129405
 >> iter 13000, loss: 3.258063
 >> iter 14000, loss: 3.193804
 >> iter 15000, loss: 3.175628
 >> iter 16000, loss: 3.004626
 >> iter 17000, loss: 3.038779
 >> iter 18000, loss: 3.138397
 >> iter 19000, loss: 3.030950
 >> iter 20000, loss: 3.121200
   Number of active neurons: 4
 >> iter 21000, loss: 3.055242
 >> iter 22000, loss: 3.030886
 >> iter 23000, loss: 3.061010
 >> iter 24000, loss: 2.993795
 >> iter 25000, loss: 3.054716
 >> iter 26000, loss: 2.933533
 >> iter 27000, loss: 2.927587
 >> iter 28000, loss: 3.056527
 >> iter 29000, loss: 2.959801
 >> iter 30000, loss: 3.074411
   Number of active neurons: 4
 >> iter 31000, loss: 3.009903
 >> iter 32000, loss: 3.071638
 >> iter 33000, loss: 3.065060
 >> iter 34000, loss: 2.978573
 >> iter 35000, loss: 3.001099
 >> iter 36000, loss: 2.984643
 >> iter 37000, loss: 2.947954
 >> iter 38000, loss: 2.876191
 >> iter 39000, loss: 2.970344
 >> iter 40000, loss: 3.163424
   Number of active neurons: 4
 >> iter 41000, loss: 3.107195
 >> iter 42000, loss: 3.066337
 >> iter 43000, loss: 2.995067
 >> iter 44000, loss: 2.999747
 >> iter 45000, loss: 2.952154
 >> iter 46000, loss: 2.972882
 >> iter 47000, loss: 2.989663
 >> iter 48000, loss: 3.032158
 >> iter 49000, loss: 2.975372
 >> iter 50000, loss: 3.107401
   Number of active neurons: 4
 >> iter 51000, loss: 2.975609
 >> iter 52000, loss: 3.013414
 >> iter 53000, loss: 3.054194
 >> iter 54000, loss: 3.070186
 >> iter 55000, loss: 2.981354
 >> iter 56000, loss: 2.918772
 >> iter 57000, loss: 3.007869
 >> iter 58000, loss: 3.036596
 >> iter 59000, loss: 2.962751
 >> iter 60000, loss: 2.893752
   Number of active neurons: 4
 >> iter 61000, loss: 2.828668
 >> iter 62000, loss: 2.903901
 >> iter 63000, loss: 2.942682
 >> iter 64000, loss: 3.003244
 >> iter 65000, loss: 3.054918
 >> iter 66000, loss: 3.130356
 >> iter 67000, loss: 3.036510
 >> iter 68000, loss: 3.043937
 >> iter 69000, loss: 2.982380
 >> iter 70000, loss: 2.971258
   Number of active neurons: 4
 >> iter 71000, loss: 2.910318
 >> iter 72000, loss: 2.918037
 >> iter 73000, loss: 3.092676
 >> iter 74000, loss: 3.074785
 >> iter 75000, loss: 2.962240
 >> iter 76000, loss: 3.132118
 >> iter 77000, loss: 2.950860
 >> iter 78000, loss: 2.911404
 >> iter 79000, loss: 3.068479
 >> iter 80000, loss: 2.993651
   Number of active neurons: 4
 >> iter 81000, loss: 2.987253
 >> iter 82000, loss: 3.093457
 >> iter 83000, loss: 3.190123
 >> iter 84000, loss: 2.989275
 >> iter 85000, loss: 2.933387
 >> iter 86000, loss: 2.913673
 >> iter 87000, loss: 2.938223
 >> iter 88000, loss: 3.098782
 >> iter 89000, loss: 3.129426
 >> iter 90000, loss: 3.039382
   Number of active neurons: 4
 >> iter 91000, loss: 3.066423
 >> iter 92000, loss: 2.986192
 >> iter 93000, loss: 2.987396
 >> iter 94000, loss: 2.925669
 >> iter 95000, loss: 2.956651
 >> iter 96000, loss: 2.923712
 >> iter 97000, loss: 3.033467
 >> iter 98000, loss: 2.968483
 >> iter 99000, loss: 3.023682
 >> iter 100000, loss: 3.023971
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 4.87790244195
   - Test - Long: 0.17999100045
   - Test - Big: 5.08594914051
   - Test - A: 0.626624891674
   - Test - B: 13.8990733951
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.339277
 >> iter 2000, loss: 10.821535
 >> iter 3000, loss: 5.943860
 >> iter 4000, loss: 3.302670
 >> iter 5000, loss: 1.934759
 >> iter 6000, loss: 1.273774
 >> iter 7000, loss: 1.146271
 >> iter 8000, loss: 0.955631
 >> iter 9000, loss: 0.830739
 >> iter 10000, loss: 0.659805
   Number of active neurons: 4
 >> iter 11000, loss: 0.572421
 >> iter 12000, loss: 0.566801
 >> iter 13000, loss: 0.430575
 >> iter 14000, loss: 0.469308
 >> iter 15000, loss: 0.384634
 >> iter 16000, loss: 0.445652
 >> iter 17000, loss: 0.339747
 >> iter 18000, loss: 0.500679
 >> iter 19000, loss: 0.473639
 >> iter 20000, loss: 0.492009
   Number of active neurons: 4
 >> iter 21000, loss: 0.511252
 >> iter 22000, loss: 0.593048
 >> iter 23000, loss: 0.413213
 >> iter 24000, loss: 0.407811
 >> iter 25000, loss: 0.427818
 >> iter 26000, loss: 0.416700
 >> iter 27000, loss: 0.306286
 >> iter 28000, loss: 0.324828
 >> iter 29000, loss: 0.361965
 >> iter 30000, loss: 0.557471
   Number of active neurons: 4
 >> iter 31000, loss: 0.478022
 >> iter 32000, loss: 0.476278
 >> iter 33000, loss: 0.445323
 >> iter 34000, loss: 0.417476
 >> iter 35000, loss: 0.312063
 >> iter 36000, loss: 0.540181
 >> iter 37000, loss: 0.361451
 >> iter 38000, loss: 0.399479
 >> iter 39000, loss: 0.347537
 >> iter 40000, loss: 0.393554
   Number of active neurons: 4
 >> iter 41000, loss: 0.378887
 >> iter 42000, loss: 0.331206
 >> iter 43000, loss: 0.341355
 >> iter 44000, loss: 0.456713
 >> iter 45000, loss: 0.519455
 >> iter 46000, loss: 0.545700
 >> iter 47000, loss: 0.390837
 >> iter 48000, loss: 0.317367
 >> iter 49000, loss: 0.335479
 >> iter 50000, loss: 0.465017
   Number of active neurons: 4
 >> iter 51000, loss: 0.514750
 >> iter 52000, loss: 0.464213
 >> iter 53000, loss: 0.422797
 >> iter 54000, loss: 0.363237
 >> iter 55000, loss: 0.513016
 >> iter 56000, loss: 0.394040
 >> iter 57000, loss: 0.556424
 >> iter 58000, loss: 0.522297
 >> iter 59000, loss: 0.396547
 >> iter 60000, loss: 0.470683
   Number of active neurons: 4
 >> iter 61000, loss: 0.619155
 >> iter 62000, loss: 0.486941
 >> iter 63000, loss: 0.534979
 >> iter 64000, loss: 0.537358
 >> iter 65000, loss: 0.687882
 >> iter 66000, loss: 0.534532
 >> iter 67000, loss: 0.477632
 >> iter 68000, loss: 0.380356
 >> iter 69000, loss: 0.412293
 >> iter 70000, loss: 0.491723
   Number of active neurons: 4
 >> iter 71000, loss: 0.457642
 >> iter 72000, loss: 0.563492
 >> iter 73000, loss: 0.462419
 >> iter 74000, loss: 0.350153
 >> iter 75000, loss: 0.421324
 >> iter 76000, loss: 0.450865
 >> iter 77000, loss: 0.481878
 >> iter 78000, loss: 0.313478
 >> iter 79000, loss: 0.393062
 >> iter 80000, loss: 0.455873
   Number of active neurons: 4
 >> iter 81000, loss: 0.460870
 >> iter 82000, loss: 0.434262
 >> iter 83000, loss: 0.311703
 >> iter 84000, loss: 0.439087
 >> iter 85000, loss: 0.311717
 >> iter 86000, loss: 0.373777
 >> iter 87000, loss: 0.363441
 >> iter 88000, loss: 0.426281
 >> iter 89000, loss: 0.483890
 >> iter 90000, loss: 0.543271
   Number of active neurons: 4
 >> iter 91000, loss: 0.566979
 >> iter 92000, loss: 0.578141
 >> iter 93000, loss: 0.494748
 >> iter 94000, loss: 0.332503
 >> iter 95000, loss: 0.405368
 >> iter 96000, loss: 0.367009
 >> iter 97000, loss: 0.425726
 >> iter 98000, loss: 0.391050
 >> iter 99000, loss: 0.342969
 >> iter 100000, loss: 0.562837
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.205724
 >> iter 2000, loss: 13.641678
 >> iter 3000, loss: 11.353173
 >> iter 4000, loss: 9.851356
 >> iter 5000, loss: 9.915236
 >> iter 6000, loss: 7.362284
 >> iter 7000, loss: 5.570525
 >> iter 8000, loss: 4.295454
 >> iter 9000, loss: 3.548166
 >> iter 10000, loss: 3.216316
   Number of active neurons: 4
 >> iter 11000, loss: 3.198490
 >> iter 12000, loss: 2.953086
 >> iter 13000, loss: 2.912931
 >> iter 14000, loss: 2.919406
 >> iter 15000, loss: 2.908215
 >> iter 16000, loss: 2.999739
 >> iter 17000, loss: 2.915951
 >> iter 18000, loss: 2.939276
 >> iter 19000, loss: 2.917862
 >> iter 20000, loss: 2.934287
   Number of active neurons: 4
 >> iter 21000, loss: 2.932418
 >> iter 22000, loss: 2.857019
 >> iter 23000, loss: 3.031648
 >> iter 24000, loss: 2.941562
 >> iter 25000, loss: 2.936213
 >> iter 26000, loss: 3.146962
 >> iter 27000, loss: 3.115724
 >> iter 28000, loss: 2.980964
 >> iter 29000, loss: 2.914937
 >> iter 30000, loss: 2.914914
   Number of active neurons: 4
 >> iter 31000, loss: 2.919925
 >> iter 32000, loss: 3.001270
 >> iter 33000, loss: 2.896461
 >> iter 34000, loss: 2.913610
 >> iter 35000, loss: 2.937513
 >> iter 36000, loss: 2.860900
 >> iter 37000, loss: 2.884230
 >> iter 38000, loss: 2.971255
 >> iter 39000, loss: 2.931664
 >> iter 40000, loss: 3.002761
   Number of active neurons: 4
 >> iter 41000, loss: 2.927559
 >> iter 42000, loss: 3.048653
 >> iter 43000, loss: 2.958038
 >> iter 44000, loss: 2.980577
 >> iter 45000, loss: 2.948342
 >> iter 46000, loss: 3.004650
 >> iter 47000, loss: 3.013844
 >> iter 48000, loss: 2.986317
 >> iter 49000, loss: 2.894907
 >> iter 50000, loss: 2.864787
   Number of active neurons: 4
 >> iter 51000, loss: 3.017799
 >> iter 52000, loss: 3.100877
 >> iter 53000, loss: 2.962350
 >> iter 54000, loss: 2.882442
 >> iter 55000, loss: 2.943995
 >> iter 56000, loss: 2.916780
 >> iter 57000, loss: 2.938357
 >> iter 58000, loss: 2.972523
 >> iter 59000, loss: 2.939906
 >> iter 60000, loss: 2.980138
   Number of active neurons: 4
 >> iter 61000, loss: 2.894583
 >> iter 62000, loss: 2.892861
 >> iter 63000, loss: 2.857712
 >> iter 64000, loss: 3.244104
 >> iter 65000, loss: 3.165225
 >> iter 66000, loss: 3.168623
 >> iter 67000, loss: 3.075595
 >> iter 68000, loss: 2.929135
 >> iter 69000, loss: 2.964183
 >> iter 70000, loss: 2.944783
   Number of active neurons: 4
 >> iter 71000, loss: 2.831167
 >> iter 72000, loss: 2.909801
 >> iter 73000, loss: 2.851508
 >> iter 74000, loss: 2.896079
 >> iter 75000, loss: 2.921021
 >> iter 76000, loss: 2.953994
 >> iter 77000, loss: 3.098741
 >> iter 78000, loss: 3.008157
 >> iter 79000, loss: 2.988452
 >> iter 80000, loss: 2.935316
   Number of active neurons: 4
 >> iter 81000, loss: 2.903138
 >> iter 82000, loss: 3.010736
 >> iter 83000, loss: 2.921133
 >> iter 84000, loss: 2.921522
 >> iter 85000, loss: 2.905830
 >> iter 86000, loss: 2.967215
 >> iter 87000, loss: 3.028897
 >> iter 88000, loss: 3.036010
 >> iter 89000, loss: 3.040029
 >> iter 90000, loss: 3.045201
   Number of active neurons: 4
 >> iter 91000, loss: 2.982540
 >> iter 92000, loss: 3.025702
 >> iter 93000, loss: 3.045638
 >> iter 94000, loss: 3.018694
 >> iter 95000, loss: 3.016895
 >> iter 96000, loss: 2.986966
 >> iter 97000, loss: 2.936538
 >> iter 98000, loss: 2.932666
 >> iter 99000, loss: 3.105661
 >> iter 100000, loss: 3.115839
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 4.87790244195
   - Test - Long: 0.17999100045
   - Test - Big: 5.08594914051
   - Test - A: 0.626624891674
   - Test - B: 13.8990733951
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 17.689053
 >> iter 2000, loss: 11.704117
 >> iter 3000, loss: 7.643109
 >> iter 4000, loss: 4.192925
 >> iter 5000, loss: 2.586392
 >> iter 6000, loss: 1.476107
 >> iter 7000, loss: 1.150457
 >> iter 8000, loss: 0.920168
 >> iter 9000, loss: 0.704259
 >> iter 10000, loss: 0.726504
   Number of active neurons: 4
 >> iter 11000, loss: 0.610624
 >> iter 12000, loss: 0.436888
 >> iter 13000, loss: 0.565417
 >> iter 14000, loss: 0.589698
 >> iter 15000, loss: 0.583674
 >> iter 16000, loss: 0.601435
 >> iter 17000, loss: 0.461573
 >> iter 18000, loss: 0.476777
 >> iter 19000, loss: 0.641007
 >> iter 20000, loss: 0.696130
   Number of active neurons: 4
 >> iter 21000, loss: 0.687446
 >> iter 22000, loss: 0.548989
 >> iter 23000, loss: 0.677278
 >> iter 24000, loss: 0.511641
 >> iter 25000, loss: 0.731874
 >> iter 26000, loss: 0.657029
 >> iter 27000, loss: 0.550959
 >> iter 28000, loss: 0.449809
 >> iter 29000, loss: 0.438302
 >> iter 30000, loss: 0.434716
   Number of active neurons: 4
 >> iter 31000, loss: 0.345238
 >> iter 32000, loss: 0.317634
 >> iter 33000, loss: 0.321609
 >> iter 34000, loss: 0.301914
 >> iter 35000, loss: 0.243615
 >> iter 36000, loss: 0.190093
 >> iter 37000, loss: 0.282204
 >> iter 38000, loss: 0.225451
 >> iter 39000, loss: 0.198881
 >> iter 40000, loss: 0.211290
   Number of active neurons: 4
 >> iter 41000, loss: 0.238057
 >> iter 42000, loss: 0.350736
 >> iter 43000, loss: 0.324174
 >> iter 44000, loss: 0.278578
 >> iter 45000, loss: 0.228198
 >> iter 46000, loss: 0.323124
 >> iter 47000, loss: 0.264270
 >> iter 48000, loss: 0.383714
 >> iter 49000, loss: 0.380939
 >> iter 50000, loss: 0.431875
   Number of active neurons: 4
 >> iter 51000, loss: 0.573843
 >> iter 52000, loss: 0.462214
 >> iter 53000, loss: 0.448759
 >> iter 54000, loss: 0.408675
 >> iter 55000, loss: 0.473152
 >> iter 56000, loss: 0.438746
 >> iter 57000, loss: 0.423363
 >> iter 58000, loss: 0.497095
 >> iter 59000, loss: 0.455319
 >> iter 60000, loss: 0.367186
   Number of active neurons: 4
 >> iter 61000, loss: 0.404217
 >> iter 62000, loss: 0.396568
 >> iter 63000, loss: 0.405525
 >> iter 64000, loss: 0.410637
 >> iter 65000, loss: 0.427297
 >> iter 66000, loss: 0.481349
 >> iter 67000, loss: 0.467051
 >> iter 68000, loss: 0.452652
 >> iter 69000, loss: 0.431084
 >> iter 70000, loss: 0.366946
   Number of active neurons: 4
 >> iter 71000, loss: 0.379309
 >> iter 72000, loss: 0.380670
 >> iter 73000, loss: 0.434857
 >> iter 74000, loss: 0.435154
 >> iter 75000, loss: 0.522262
 >> iter 76000, loss: 0.382481
 >> iter 77000, loss: 0.437805
 >> iter 78000, loss: 0.445309
 >> iter 79000, loss: 0.392345
 >> iter 80000, loss: 0.482381
   Number of active neurons: 4
 >> iter 81000, loss: 0.360331
 >> iter 82000, loss: 0.410539
 >> iter 83000, loss: 0.372549
 >> iter 84000, loss: 0.386752
 >> iter 85000, loss: 0.341258
 >> iter 86000, loss: 0.417718
 >> iter 87000, loss: 0.413790
 >> iter 88000, loss: 0.302883
 >> iter 89000, loss: 0.445075
 >> iter 90000, loss: 0.346483
   Number of active neurons: 4
 >> iter 91000, loss: 0.339448
 >> iter 92000, loss: 0.408509
 >> iter 93000, loss: 0.475830
 >> iter 94000, loss: 0.431054
 >> iter 95000, loss: 0.456789
 >> iter 96000, loss: 0.455247
 >> iter 97000, loss: 0.502232
 >> iter 98000, loss: 0.552043
 >> iter 99000, loss: 0.447822
 >> iter 100000, loss: 0.476361
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.179996400072
   - Test - Long: 0.0649967501625
   - Test - Big: 0.158998410016
   - Test - A: 0.0
   - Test - B: 21.0919272049
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.011355
 >> iter 2000, loss: 12.099502
 >> iter 3000, loss: 10.167047
 >> iter 4000, loss: 8.392871
 >> iter 5000, loss: 6.522475
 >> iter 6000, loss: 3.661302
 >> iter 7000, loss: 2.181089
 >> iter 8000, loss: 1.224657
 >> iter 9000, loss: 0.926779
 >> iter 10000, loss: 0.706510
   Number of active neurons: 4
 >> iter 11000, loss: 0.757898
 >> iter 12000, loss: 0.642109
 >> iter 13000, loss: 0.608640
 >> iter 14000, loss: 0.533166
 >> iter 15000, loss: 0.553950
 >> iter 16000, loss: 0.476816
 >> iter 17000, loss: 0.445455
 >> iter 18000, loss: 0.448854
 >> iter 19000, loss: 0.526062
 >> iter 20000, loss: 0.580181
   Number of active neurons: 4
 >> iter 21000, loss: 0.610823
 >> iter 22000, loss: 0.526424
 >> iter 23000, loss: 0.621750
 >> iter 24000, loss: 0.489709
 >> iter 25000, loss: 0.563089
 >> iter 26000, loss: 0.530898
 >> iter 27000, loss: 0.518962
 >> iter 28000, loss: 0.530623
 >> iter 29000, loss: 0.500178
 >> iter 30000, loss: 0.567441
   Number of active neurons: 4
 >> iter 31000, loss: 0.544221
 >> iter 32000, loss: 0.620061
 >> iter 33000, loss: 0.616760
 >> iter 34000, loss: 0.585617
 >> iter 35000, loss: 0.570915
 >> iter 36000, loss: 0.534701
 >> iter 37000, loss: 0.688460
 >> iter 38000, loss: 0.668073
 >> iter 39000, loss: 0.598376
 >> iter 40000, loss: 0.561675
   Number of active neurons: 4
 >> iter 41000, loss: 0.645377
 >> iter 42000, loss: 0.684673
 >> iter 43000, loss: 0.598467
 >> iter 44000, loss: 0.619889
 >> iter 45000, loss: 0.682151
 >> iter 46000, loss: 0.689243
 >> iter 47000, loss: 0.600610
 >> iter 48000, loss: 0.524214
 >> iter 49000, loss: 0.492133
 >> iter 50000, loss: 0.463310
   Number of active neurons: 4
 >> iter 51000, loss: 0.586785
 >> iter 52000, loss: 0.596567
 >> iter 53000, loss: 0.654507
 >> iter 54000, loss: 0.480740
 >> iter 55000, loss: 0.529471
 >> iter 56000, loss: 0.580789
 >> iter 57000, loss: 0.694570
 >> iter 58000, loss: 0.615380
 >> iter 59000, loss: 0.637611
 >> iter 60000, loss: 0.636684
   Number of active neurons: 4
 >> iter 61000, loss: 0.510427
 >> iter 62000, loss: 0.586917
 >> iter 63000, loss: 0.606995
 >> iter 64000, loss: 0.579738
 >> iter 65000, loss: 0.454793
 >> iter 66000, loss: 0.565995
 >> iter 67000, loss: 0.544698
 >> iter 68000, loss: 0.564509
 >> iter 69000, loss: 0.804023
 >> iter 70000, loss: 0.550828
   Number of active neurons: 4
 >> iter 71000, loss: 0.509784
 >> iter 72000, loss: 0.701748
 >> iter 73000, loss: 0.768784
 >> iter 74000, loss: 0.603623
 >> iter 75000, loss: 0.639775
 >> iter 76000, loss: 0.645301
 >> iter 77000, loss: 0.652012
 >> iter 78000, loss: 0.589342
 >> iter 79000, loss: 0.574293
 >> iter 80000, loss: 0.537318
   Number of active neurons: 4
 >> iter 81000, loss: 0.746606
 >> iter 82000, loss: 0.521003
 >> iter 83000, loss: 0.525266
 >> iter 84000, loss: 0.463114
 >> iter 85000, loss: 0.609690
 >> iter 86000, loss: 0.547306
 >> iter 87000, loss: 0.531595
 >> iter 88000, loss: 0.426566
 >> iter 89000, loss: 0.558213
 >> iter 90000, loss: 0.483037
   Number of active neurons: 4
 >> iter 91000, loss: 0.565841
 >> iter 92000, loss: 0.434372
 >> iter 93000, loss: 0.583651
 >> iter 94000, loss: 0.681472
 >> iter 95000, loss: 0.667289
 >> iter 96000, loss: 0.662570
 >> iter 97000, loss: 0.551544
 >> iter 98000, loss: 0.509049
 >> iter 99000, loss: 0.498968
 >> iter 100000, loss: 0.488693
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.492968
 >> iter 2000, loss: 13.762529
 >> iter 3000, loss: 11.759355
 >> iter 4000, loss: 8.054385
 >> iter 5000, loss: 5.250749
 >> iter 6000, loss: 3.102137
 >> iter 7000, loss: 1.914010
 >> iter 8000, loss: 1.299077
 >> iter 9000, loss: 1.027074
 >> iter 10000, loss: 1.042606
   Number of active neurons: 4
 >> iter 11000, loss: 0.699296
 >> iter 12000, loss: 0.696073
 >> iter 13000, loss: 0.722021
 >> iter 14000, loss: 0.635679
 >> iter 15000, loss: 0.661256
 >> iter 16000, loss: 0.686284
 >> iter 17000, loss: 0.663098
 >> iter 18000, loss: 0.618370
 >> iter 19000, loss: 0.658577
 >> iter 20000, loss: 0.712844
   Number of active neurons: 4
 >> iter 21000, loss: 0.708239
 >> iter 22000, loss: 0.602084
 >> iter 23000, loss: 0.557854
 >> iter 24000, loss: 0.633797
 >> iter 25000, loss: 0.613035
 >> iter 26000, loss: 0.574947
 >> iter 27000, loss: 0.724316
 >> iter 28000, loss: 0.693049
 >> iter 29000, loss: 0.573701
 >> iter 30000, loss: 0.562784
   Number of active neurons: 4
 >> iter 31000, loss: 0.579175
 >> iter 32000, loss: 0.619087
 >> iter 33000, loss: 0.824829
 >> iter 34000, loss: 0.698936
 >> iter 35000, loss: 0.679014
 >> iter 36000, loss: 0.655920
 >> iter 37000, loss: 0.649055
 >> iter 38000, loss: 0.787439
 >> iter 39000, loss: 0.761190
 >> iter 40000, loss: 0.801493
   Number of active neurons: 4
 >> iter 41000, loss: 0.849736
 >> iter 42000, loss: 0.622017
 >> iter 43000, loss: 0.705486
 >> iter 44000, loss: 0.643008
 >> iter 45000, loss: 0.667852
 >> iter 46000, loss: 0.739149
 >> iter 47000, loss: 0.801770
 >> iter 48000, loss: 0.732609
 >> iter 49000, loss: 0.656029
 >> iter 50000, loss: 0.625518
   Number of active neurons: 4
 >> iter 51000, loss: 0.619276
 >> iter 52000, loss: 0.831715
 >> iter 53000, loss: 0.725288
 >> iter 54000, loss: 0.584996
 >> iter 55000, loss: 0.463543
 >> iter 56000, loss: 0.541736
 >> iter 57000, loss: 0.501779
 >> iter 58000, loss: 0.608772
 >> iter 59000, loss: 0.800872
 >> iter 60000, loss: 0.669477
   Number of active neurons: 4
 >> iter 61000, loss: 0.524758
 >> iter 62000, loss: 0.676759
 >> iter 63000, loss: 0.591552
 >> iter 64000, loss: 0.517429
 >> iter 65000, loss: 0.540964
 >> iter 66000, loss: 0.619262
 >> iter 67000, loss: 0.578781
 >> iter 68000, loss: 0.638134
 >> iter 69000, loss: 0.595609
 >> iter 70000, loss: 0.652297
   Number of active neurons: 4
 >> iter 71000, loss: 0.718613
 >> iter 72000, loss: 0.653249
 >> iter 73000, loss: 0.606665
 >> iter 74000, loss: 0.879746
 >> iter 75000, loss: 0.763591
 >> iter 76000, loss: 0.730826
 >> iter 77000, loss: 0.518932
 >> iter 78000, loss: 0.569431
 >> iter 79000, loss: 0.958434
 >> iter 80000, loss: 0.839829
   Number of active neurons: 4
 >> iter 81000, loss: 0.837810
 >> iter 82000, loss: 0.740255
 >> iter 83000, loss: 0.667370
 >> iter 84000, loss: 0.530726
 >> iter 85000, loss: 0.532514
 >> iter 86000, loss: 0.571396
 >> iter 87000, loss: 0.437580
 >> iter 88000, loss: 0.557353
 >> iter 89000, loss: 0.513202
 >> iter 90000, loss: 0.661049
   Number of active neurons: 4
 >> iter 91000, loss: 0.643147
 >> iter 92000, loss: 0.541861
 >> iter 93000, loss: 0.738183
 >> iter 94000, loss: 0.516866
 >> iter 95000, loss: 0.507186
 >> iter 96000, loss: 0.557241
 >> iter 97000, loss: 0.633004
 >> iter 98000, loss: 0.557922
 >> iter 99000, loss: 0.555594
 >> iter 100000, loss: 0.711705
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 17.8454769682

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

