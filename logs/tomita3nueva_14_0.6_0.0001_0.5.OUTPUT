 > Problema: tomita3nueva
 > Args:
   - Hidden size: 14
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.117616
 >> iter 2000, loss: 11.503982
 >> iter 3000, loss: 5.350499
 >> iter 4000, loss: 2.409498
 >> iter 5000, loss: 1.495951
 >> iter 6000, loss: 0.916981
 >> iter 7000, loss: 0.852456
 >> iter 8000, loss: 0.518335
 >> iter 9000, loss: 0.450159
 >> iter 10000, loss: 0.335301
   Number of active neurons: 7
 >> iter 11000, loss: 0.343386
 >> iter 12000, loss: 0.301345
 >> iter 13000, loss: 0.344507
 >> iter 14000, loss: 0.358877
 >> iter 15000, loss: 0.277653
 >> iter 16000, loss: 0.267519
 >> iter 17000, loss: 0.261634
 >> iter 18000, loss: 0.336789
 >> iter 19000, loss: 0.263898
 >> iter 20000, loss: 0.279441
   Number of active neurons: 7
 >> iter 21000, loss: 0.365679
 >> iter 22000, loss: 0.434445
 >> iter 23000, loss: 0.517451
 >> iter 24000, loss: 0.462508
 >> iter 25000, loss: 0.317817
 >> iter 26000, loss: 0.289072
 >> iter 27000, loss: 0.371495
 >> iter 28000, loss: 0.456462
 >> iter 29000, loss: 0.325099
 >> iter 30000, loss: 0.391337
   Number of active neurons: 7
 >> iter 31000, loss: 0.295553
 >> iter 32000, loss: 0.285158
 >> iter 33000, loss: 0.542831
 >> iter 34000, loss: 0.494234
 >> iter 35000, loss: 0.325781
 >> iter 36000, loss: 0.310652
 >> iter 37000, loss: 0.383124
 >> iter 38000, loss: 0.305032
 >> iter 39000, loss: 0.458926
 >> iter 40000, loss: 0.419351
   Number of active neurons: 6
 >> iter 41000, loss: 0.376456
 >> iter 42000, loss: 0.418602
 >> iter 43000, loss: 0.374386
 >> iter 44000, loss: 0.310677
 >> iter 45000, loss: 0.264903
 >> iter 46000, loss: 0.382060
 >> iter 47000, loss: 0.259813
 >> iter 48000, loss: 0.428490
 >> iter 49000, loss: 0.418173
 >> iter 50000, loss: 0.297497
   Number of active neurons: 6
 >> iter 51000, loss: 0.269885
 >> iter 52000, loss: 0.462003
 >> iter 53000, loss: 0.377320
 >> iter 54000, loss: 0.279475
 >> iter 55000, loss: 0.334999
 >> iter 56000, loss: 0.256199
 >> iter 57000, loss: 0.293232
 >> iter 58000, loss: 0.507281
 >> iter 59000, loss: 0.419453
 >> iter 60000, loss: 0.298500
   Number of active neurons: 6
 >> iter 61000, loss: 0.173842
 >> iter 62000, loss: 0.201039
 >> iter 63000, loss: 0.211064
 >> iter 64000, loss: 0.355379
 >> iter 65000, loss: 0.377135
 >> iter 66000, loss: 0.473159
 >> iter 67000, loss: 0.362874
 >> iter 68000, loss: 0.238182
 >> iter 69000, loss: 0.319900
 >> iter 70000, loss: 0.328139
   Number of active neurons: 6
 >> iter 71000, loss: 0.308825
 >> iter 72000, loss: 0.308828
 >> iter 73000, loss: 0.311315
 >> iter 74000, loss: 0.320586
 >> iter 75000, loss: 0.377697
 >> iter 76000, loss: 0.281327
 >> iter 77000, loss: 0.421089
 >> iter 78000, loss: 0.304666
 >> iter 79000, loss: 0.368832
 >> iter 80000, loss: 0.552409
   Number of active neurons: 6
 >> iter 81000, loss: 0.413834
 >> iter 82000, loss: 0.308070
 >> iter 83000, loss: 0.347216
 >> iter 84000, loss: 0.220580
 >> iter 85000, loss: 0.222581
 >> iter 86000, loss: 0.216659
 >> iter 87000, loss: 0.202435
 >> iter 88000, loss: 0.289549
 >> iter 89000, loss: 0.251622
 >> iter 90000, loss: 0.255268
   Number of active neurons: 6
 >> iter 91000, loss: 0.251987
 >> iter 92000, loss: 0.204477
 >> iter 93000, loss: 0.438838
 >> iter 94000, loss: 0.286496
 >> iter 95000, loss: 0.270108
 >> iter 96000, loss: 0.179005
 >> iter 97000, loss: 0.175638
 >> iter 98000, loss: 0.235523
 >> iter 99000, loss: 0.317171
 >> iter 100000, loss: 0.372785
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.002671
 >> iter 2000, loss: 11.815492
 >> iter 3000, loss: 5.370111
 >> iter 4000, loss: 2.639115
 >> iter 5000, loss: 1.252026
 >> iter 6000, loss: 0.821595
 >> iter 7000, loss: 0.664737
 >> iter 8000, loss: 0.576208
 >> iter 9000, loss: 0.489481
 >> iter 10000, loss: 0.512027
   Number of active neurons: 5
 >> iter 11000, loss: 0.530986
 >> iter 12000, loss: 0.495885
 >> iter 13000, loss: 0.427796
 >> iter 14000, loss: 0.413107
 >> iter 15000, loss: 0.450513
 >> iter 16000, loss: 0.492210
 >> iter 17000, loss: 0.558732
 >> iter 18000, loss: 0.413960
 >> iter 19000, loss: 0.360474
 >> iter 20000, loss: 0.486740
   Number of active neurons: 5
 >> iter 21000, loss: 0.401599
 >> iter 22000, loss: 0.408533
 >> iter 23000, loss: 0.325983
 >> iter 24000, loss: 0.364205
 >> iter 25000, loss: 0.366618
 >> iter 26000, loss: 0.409732
 >> iter 27000, loss: 0.395335
 >> iter 28000, loss: 0.436543
 >> iter 29000, loss: 0.280400
 >> iter 30000, loss: 0.321523
   Number of active neurons: 5
 >> iter 31000, loss: 0.429916
 >> iter 32000, loss: 0.324013
 >> iter 33000, loss: 0.398417
 >> iter 34000, loss: 0.424458
 >> iter 35000, loss: 0.510799
 >> iter 36000, loss: 0.510735
 >> iter 37000, loss: 0.403170
 >> iter 38000, loss: 0.450101
 >> iter 39000, loss: 0.648451
 >> iter 40000, loss: 0.520583
   Number of active neurons: 5
 >> iter 41000, loss: 0.580263
 >> iter 42000, loss: 0.435855
 >> iter 43000, loss: 0.420814
 >> iter 44000, loss: 0.314777
 >> iter 45000, loss: 0.307252
 >> iter 46000, loss: 0.311762
 >> iter 47000, loss: 0.362662
 >> iter 48000, loss: 0.541070
 >> iter 49000, loss: 0.461397
 >> iter 50000, loss: 0.401244
   Number of active neurons: 5
 >> iter 51000, loss: 0.235584
 >> iter 52000, loss: 0.330674
 >> iter 53000, loss: 0.382572
 >> iter 54000, loss: 0.486530
 >> iter 55000, loss: 0.376842
 >> iter 56000, loss: 0.423619
 >> iter 57000, loss: 0.378876
 >> iter 58000, loss: 0.288809
 >> iter 59000, loss: 0.408169
 >> iter 60000, loss: 0.419102
   Number of active neurons: 5
 >> iter 61000, loss: 0.526735
 >> iter 62000, loss: 0.397878
 >> iter 63000, loss: 0.290006
 >> iter 64000, loss: 0.367315
 >> iter 65000, loss: 0.409461
 >> iter 66000, loss: 0.349148
 >> iter 67000, loss: 0.429731
 >> iter 68000, loss: 0.469915
 >> iter 69000, loss: 0.360795
 >> iter 70000, loss: 0.423640
   Number of active neurons: 5
 >> iter 71000, loss: 0.360902
 >> iter 72000, loss: 0.352319
 >> iter 73000, loss: 0.315808
 >> iter 74000, loss: 0.333590
 >> iter 75000, loss: 0.261514
 >> iter 76000, loss: 0.337475
 >> iter 77000, loss: 0.294427
 >> iter 78000, loss: 0.411301
 >> iter 79000, loss: 0.433749
 >> iter 80000, loss: 0.435578
   Number of active neurons: 4
 >> iter 81000, loss: 0.360234
 >> iter 82000, loss: 0.324456
 >> iter 83000, loss: 0.350833
 >> iter 84000, loss: 0.354529
 >> iter 85000, loss: 0.484035
 >> iter 86000, loss: 0.236943
 >> iter 87000, loss: 0.374044
 >> iter 88000, loss: 0.345566
 >> iter 89000, loss: 0.639156
 >> iter 90000, loss: 0.458038
   Number of active neurons: 4
 >> iter 91000, loss: 0.344180
 >> iter 92000, loss: 0.277040
 >> iter 93000, loss: 0.412977
 >> iter 94000, loss: 0.473346
 >> iter 95000, loss: 0.302309
 >> iter 96000, loss: 0.320689
 >> iter 97000, loss: 0.333945
 >> iter 98000, loss: 0.230796
 >> iter 99000, loss: 0.354526
 >> iter 100000, loss: 0.276507
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0039999200016
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 13.0257982801
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.109171
 >> iter 2000, loss: 11.514478
 >> iter 3000, loss: 5.816700
 >> iter 4000, loss: 2.812293
 >> iter 5000, loss: 1.399965
 >> iter 6000, loss: 1.005965
 >> iter 7000, loss: 0.636241
 >> iter 8000, loss: 0.494366
 >> iter 9000, loss: 0.503141
 >> iter 10000, loss: 0.406985
   Number of active neurons: 8
 >> iter 11000, loss: 0.407336
 >> iter 12000, loss: 0.403788
 >> iter 13000, loss: 0.635395
 >> iter 14000, loss: 0.698404
 >> iter 15000, loss: 0.532475
 >> iter 16000, loss: 0.332145
 >> iter 17000, loss: 0.496855
 >> iter 18000, loss: 0.392801
 >> iter 19000, loss: 0.323829
 >> iter 20000, loss: 0.354527
   Number of active neurons: 8
 >> iter 21000, loss: 0.277083
 >> iter 22000, loss: 0.333960
 >> iter 23000, loss: 0.488196
 >> iter 24000, loss: 0.420282
 >> iter 25000, loss: 0.460100
 >> iter 26000, loss: 0.420242
 >> iter 27000, loss: 0.326309
 >> iter 28000, loss: 0.409474
 >> iter 29000, loss: 0.468587
 >> iter 30000, loss: 0.544681
   Number of active neurons: 8
 >> iter 31000, loss: 0.361133
 >> iter 32000, loss: 0.446557
 >> iter 33000, loss: 0.467493
 >> iter 34000, loss: 0.532380
 >> iter 35000, loss: 0.467590
 >> iter 36000, loss: 0.629782
 >> iter 37000, loss: 0.544984
 >> iter 38000, loss: 0.397734
 >> iter 39000, loss: 0.416144
 >> iter 40000, loss: 0.377277
   Number of active neurons: 8
 >> iter 41000, loss: 0.275847
 >> iter 42000, loss: 0.399278
 >> iter 43000, loss: 0.357742
 >> iter 44000, loss: 0.284824
 >> iter 45000, loss: 0.465025
 >> iter 46000, loss: 0.479430
 >> iter 47000, loss: 0.405609
 >> iter 48000, loss: 0.514385
 >> iter 49000, loss: 0.423589
 >> iter 50000, loss: 0.324757
   Number of active neurons: 8
 >> iter 51000, loss: 0.302298
 >> iter 52000, loss: 0.327532
 >> iter 53000, loss: 0.300943
 >> iter 54000, loss: 0.383815
 >> iter 55000, loss: 0.294313
 >> iter 56000, loss: 0.421917
 >> iter 57000, loss: 0.451584
 >> iter 58000, loss: 0.454281
 >> iter 59000, loss: 0.312981
 >> iter 60000, loss: 0.329662
   Number of active neurons: 8
 >> iter 61000, loss: 0.420250
 >> iter 62000, loss: 0.314269
 >> iter 63000, loss: 0.235413
 >> iter 64000, loss: 0.262444
 >> iter 65000, loss: 0.369924
 >> iter 66000, loss: 0.297834
 >> iter 67000, loss: 0.349636
 >> iter 68000, loss: 0.355782
 >> iter 69000, loss: 0.424785
 >> iter 70000, loss: 0.343541
   Number of active neurons: 8
 >> iter 71000, loss: 0.292779
 >> iter 72000, loss: 0.382408
 >> iter 73000, loss: 0.528965
 >> iter 74000, loss: 0.303504
 >> iter 75000, loss: 0.320850
 >> iter 76000, loss: 0.428023
 >> iter 77000, loss: 0.298010
 >> iter 78000, loss: 0.326377
 >> iter 79000, loss: 0.625111
 >> iter 80000, loss: 0.417451
   Number of active neurons: 8
 >> iter 81000, loss: 0.268429
 >> iter 82000, loss: 0.264660
 >> iter 83000, loss: 0.331915
 >> iter 84000, loss: 0.402210
 >> iter 85000, loss: 0.300532
 >> iter 86000, loss: 0.336244
 >> iter 87000, loss: 0.554933
 >> iter 88000, loss: 0.473961
 >> iter 89000, loss: 0.418914
 >> iter 90000, loss: 0.410276
   Number of active neurons: 7
 >> iter 91000, loss: 0.268461
 >> iter 92000, loss: 0.306113
 >> iter 93000, loss: 0.334168
 >> iter 94000, loss: 0.397113
 >> iter 95000, loss: 0.482355
 >> iter 96000, loss: 0.376861
 >> iter 97000, loss: 0.285819
 >> iter 98000, loss: 0.372552
 >> iter 99000, loss: 0.345816
 >> iter 100000, loss: 0.327708
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.241956
 >> iter 2000, loss: 10.995450
 >> iter 3000, loss: 5.026752
 >> iter 4000, loss: 2.320633
 >> iter 5000, loss: 1.095078
 >> iter 6000, loss: 0.634982
 >> iter 7000, loss: 0.397135
 >> iter 8000, loss: 0.292283
 >> iter 9000, loss: 0.346829
 >> iter 10000, loss: 0.265658
   Number of active neurons: 8
 >> iter 11000, loss: 0.445192
 >> iter 12000, loss: 0.293679
 >> iter 13000, loss: 0.184364
 >> iter 14000, loss: 0.338754
 >> iter 15000, loss: 0.257245
 >> iter 16000, loss: 0.269789
 >> iter 17000, loss: 0.376213
 >> iter 18000, loss: 0.215709
 >> iter 19000, loss: 0.265623
 >> iter 20000, loss: 0.198404
   Number of active neurons: 8
 >> iter 21000, loss: 0.221514
 >> iter 22000, loss: 0.261890
 >> iter 23000, loss: 0.249386
 >> iter 24000, loss: 0.199918
 >> iter 25000, loss: 0.379290
 >> iter 26000, loss: 0.494095
 >> iter 27000, loss: 0.519244
 >> iter 28000, loss: 0.374702
 >> iter 29000, loss: 0.240996
 >> iter 30000, loss: 0.377521
   Number of active neurons: 8
 >> iter 31000, loss: 0.463259
 >> iter 32000, loss: 0.266374
 >> iter 33000, loss: 0.376998
 >> iter 34000, loss: 0.282919
 >> iter 35000, loss: 0.364921
 >> iter 36000, loss: 0.243049
 >> iter 37000, loss: 0.482175
 >> iter 38000, loss: 0.315069
 >> iter 39000, loss: 0.402113
 >> iter 40000, loss: 0.230512
   Number of active neurons: 8
 >> iter 41000, loss: 0.228745
 >> iter 42000, loss: 0.229592
 >> iter 43000, loss: 0.317471
 >> iter 44000, loss: 0.302789
 >> iter 45000, loss: 0.227487
 >> iter 46000, loss: 0.251135
 >> iter 47000, loss: 0.357405
 >> iter 48000, loss: 0.330152
 >> iter 49000, loss: 0.275714
 >> iter 50000, loss: 0.178695
   Number of active neurons: 8
 >> iter 51000, loss: 0.248182
 >> iter 52000, loss: 0.187749
 >> iter 53000, loss: 0.232760
 >> iter 54000, loss: 0.281689
 >> iter 55000, loss: 0.228731
 >> iter 56000, loss: 0.241773
 >> iter 57000, loss: 0.279859
 >> iter 58000, loss: 0.205216
 >> iter 59000, loss: 0.333134
 >> iter 60000, loss: 0.268641
   Number of active neurons: 8
 >> iter 61000, loss: 0.236912
 >> iter 62000, loss: 0.334965
 >> iter 63000, loss: 0.283717
 >> iter 64000, loss: 0.238525
 >> iter 65000, loss: 0.210780
 >> iter 66000, loss: 0.206860
 >> iter 67000, loss: 0.158492
 >> iter 68000, loss: 0.179573
 >> iter 69000, loss: 0.155925
 >> iter 70000, loss: 0.299503
   Number of active neurons: 7
 >> iter 71000, loss: 0.206890
 >> iter 72000, loss: 0.279077
 >> iter 73000, loss: 0.145751
 >> iter 74000, loss: 0.195612
 >> iter 75000, loss: 0.292652
 >> iter 76000, loss: 0.173005
 >> iter 77000, loss: 0.285109
 >> iter 78000, loss: 0.309983
 >> iter 79000, loss: 0.219241
 >> iter 80000, loss: 0.357293
   Number of active neurons: 7
 >> iter 81000, loss: 0.293598
 >> iter 82000, loss: 0.260321
 >> iter 83000, loss: 0.340715
 >> iter 84000, loss: 0.258200
 >> iter 85000, loss: 0.150742
 >> iter 86000, loss: 0.230979
 >> iter 87000, loss: 0.241399
 >> iter 88000, loss: 0.372200
 >> iter 89000, loss: 0.205838
 >> iter 90000, loss: 0.223054
   Number of active neurons: 6
 >> iter 91000, loss: 0.158377
 >> iter 92000, loss: 0.162616
 >> iter 93000, loss: 0.251978
 >> iter 94000, loss: 0.226956
 >> iter 95000, loss: 0.311383
 >> iter 96000, loss: 0.276006
 >> iter 97000, loss: 0.214996
 >> iter 98000, loss: 0.258511
 >> iter 99000, loss: 0.212496
 >> iter 100000, loss: 0.197692
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.000452
 >> iter 2000, loss: 10.516204
 >> iter 3000, loss: 4.838090
 >> iter 4000, loss: 2.073151
 >> iter 5000, loss: 1.118500
 >> iter 6000, loss: 0.653444
 >> iter 7000, loss: 0.433092
 >> iter 8000, loss: 0.293254
 >> iter 9000, loss: 0.309171
 >> iter 10000, loss: 0.244307
   Number of active neurons: 6
 >> iter 11000, loss: 0.226653
 >> iter 12000, loss: 0.325633
 >> iter 13000, loss: 0.315586
 >> iter 14000, loss: 0.326643
 >> iter 15000, loss: 0.248701
 >> iter 16000, loss: 0.243747
 >> iter 17000, loss: 0.171289
 >> iter 18000, loss: 0.494875
 >> iter 19000, loss: 0.314125
 >> iter 20000, loss: 0.411226
   Number of active neurons: 6
 >> iter 21000, loss: 0.277716
 >> iter 22000, loss: 0.297001
 >> iter 23000, loss: 0.186943
 >> iter 24000, loss: 0.162628
 >> iter 25000, loss: 0.240876
 >> iter 26000, loss: 0.197044
 >> iter 27000, loss: 0.240131
 >> iter 28000, loss: 0.235605
 >> iter 29000, loss: 0.182700
 >> iter 30000, loss: 0.138107
   Number of active neurons: 6
 >> iter 31000, loss: 0.217048
 >> iter 32000, loss: 0.263524
 >> iter 33000, loss: 0.316620
 >> iter 34000, loss: 0.224761
 >> iter 35000, loss: 0.182885
 >> iter 36000, loss: 0.136451
 >> iter 37000, loss: 0.178623
 >> iter 38000, loss: 0.228824
 >> iter 39000, loss: 0.197006
 >> iter 40000, loss: 0.218253
   Number of active neurons: 5
 >> iter 41000, loss: 0.183179
 >> iter 42000, loss: 0.194588
 >> iter 43000, loss: 0.243452
 >> iter 44000, loss: 0.205517
 >> iter 45000, loss: 0.338993
 >> iter 46000, loss: 0.334697
 >> iter 47000, loss: 0.222580
 >> iter 48000, loss: 0.225377
 >> iter 49000, loss: 0.188739
 >> iter 50000, loss: 0.226848
   Number of active neurons: 5
 >> iter 51000, loss: 0.220955
 >> iter 52000, loss: 0.162139
 >> iter 53000, loss: 0.181485
 >> iter 54000, loss: 0.317554
 >> iter 55000, loss: 0.260046
 >> iter 56000, loss: 0.247649
 >> iter 57000, loss: 0.264844
 >> iter 58000, loss: 0.174108
 >> iter 59000, loss: 0.250200
 >> iter 60000, loss: 0.316195
   Number of active neurons: 4
 >> iter 61000, loss: 0.292378
 >> iter 62000, loss: 0.233493
 >> iter 63000, loss: 0.229936
 >> iter 64000, loss: 0.252999
 >> iter 65000, loss: 0.210939
 >> iter 66000, loss: 0.197582
 >> iter 67000, loss: 0.205658
 >> iter 68000, loss: 0.152288
 >> iter 69000, loss: 0.267237
 >> iter 70000, loss: 0.259607
   Number of active neurons: 4
 >> iter 71000, loss: 0.240450
 >> iter 72000, loss: 0.167229
 >> iter 73000, loss: 0.284101
 >> iter 74000, loss: 0.211161
 >> iter 75000, loss: 0.172485
 >> iter 76000, loss: 0.242506
 >> iter 77000, loss: 0.248948
 >> iter 78000, loss: 0.253787
 >> iter 79000, loss: 0.306220
 >> iter 80000, loss: 0.191502
   Number of active neurons: 4
 >> iter 81000, loss: 0.246246
 >> iter 82000, loss: 0.247054
 >> iter 83000, loss: 0.251978
 >> iter 84000, loss: 0.201266
 >> iter 85000, loss: 0.213942
 >> iter 86000, loss: 0.206656
 >> iter 87000, loss: 0.213523
 >> iter 88000, loss: 0.226288
 >> iter 89000, loss: 0.166405
 >> iter 90000, loss: 0.202904
   Number of active neurons: 4
 >> iter 91000, loss: 0.174732
 >> iter 92000, loss: 0.195749
 >> iter 93000, loss: 0.319221
 >> iter 94000, loss: 0.290659
 >> iter 95000, loss: 0.220522
 >> iter 96000, loss: 0.344297
 >> iter 97000, loss: 0.259758
 >> iter 98000, loss: 0.268543
 >> iter 99000, loss: 0.417224
 >> iter 100000, loss: 0.257030
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.245596
 >> iter 2000, loss: 13.851582
 >> iter 3000, loss: 6.840138
 >> iter 4000, loss: 3.190648
 >> iter 5000, loss: 1.896142
 >> iter 6000, loss: 1.021723
 >> iter 7000, loss: 0.741263
 >> iter 8000, loss: 0.578266
 >> iter 9000, loss: 0.469771
 >> iter 10000, loss: 0.393553
   Number of active neurons: 9
 >> iter 11000, loss: 0.454932
 >> iter 12000, loss: 0.432936
 >> iter 13000, loss: 0.439313
 >> iter 14000, loss: 0.403341
 >> iter 15000, loss: 0.329631
 >> iter 16000, loss: 0.367852
 >> iter 17000, loss: 0.407558
 >> iter 18000, loss: 0.351240
 >> iter 19000, loss: 0.362339
 >> iter 20000, loss: 0.360785
   Number of active neurons: 9
 >> iter 21000, loss: 0.414484
 >> iter 22000, loss: 0.243703
 >> iter 23000, loss: 0.300649
 >> iter 24000, loss: 0.346101
 >> iter 25000, loss: 0.370173
 >> iter 26000, loss: 0.220377
 >> iter 27000, loss: 0.262029
 >> iter 28000, loss: 0.176445
 >> iter 29000, loss: 0.275566
 >> iter 30000, loss: 0.259104
   Number of active neurons: 8
 >> iter 31000, loss: 0.377412
 >> iter 32000, loss: 0.246566
 >> iter 33000, loss: 0.245433
 >> iter 34000, loss: 0.362801
 >> iter 35000, loss: 0.273676
 >> iter 36000, loss: 0.187401
 >> iter 37000, loss: 0.187902
 >> iter 38000, loss: 0.160116
 >> iter 39000, loss: 0.218078
 >> iter 40000, loss: 0.289391
   Number of active neurons: 7
 >> iter 41000, loss: 0.224385
 >> iter 42000, loss: 0.238375
 >> iter 43000, loss: 0.222935
 >> iter 44000, loss: 0.201503
 >> iter 45000, loss: 0.314054
 >> iter 46000, loss: 0.245408
 >> iter 47000, loss: 0.205662
 >> iter 48000, loss: 0.212186
 >> iter 49000, loss: 0.125061
 >> iter 50000, loss: 0.111491
   Number of active neurons: 6
 >> iter 51000, loss: 0.172410
 >> iter 52000, loss: 0.226889
 >> iter 53000, loss: 0.391454
 >> iter 54000, loss: 0.337931
 >> iter 55000, loss: 0.285425
 >> iter 56000, loss: 0.270223
 >> iter 57000, loss: 0.275231
 >> iter 58000, loss: 0.216806
 >> iter 59000, loss: 0.253703
 >> iter 60000, loss: 0.276773
   Number of active neurons: 5
 >> iter 61000, loss: 0.281855
 >> iter 62000, loss: 0.204628
 >> iter 63000, loss: 0.199843
 >> iter 64000, loss: 0.254574
 >> iter 65000, loss: 0.453531
 >> iter 66000, loss: 0.414193
 >> iter 67000, loss: 0.254300
 >> iter 68000, loss: 0.205599
 >> iter 69000, loss: 0.131777
 >> iter 70000, loss: 0.275309
   Number of active neurons: 5
 >> iter 71000, loss: 0.287179
 >> iter 72000, loss: 0.232978
 >> iter 73000, loss: 0.148661
 >> iter 74000, loss: 0.125245
 >> iter 75000, loss: 0.245728
 >> iter 76000, loss: 0.194755
 >> iter 77000, loss: 0.148542
 >> iter 78000, loss: 0.104007
 >> iter 79000, loss: 0.204236
 >> iter 80000, loss: 0.157345
   Number of active neurons: 4
 >> iter 81000, loss: 0.150380
 >> iter 82000, loss: 0.184349
 >> iter 83000, loss: 0.194320
 >> iter 84000, loss: 0.143709
 >> iter 85000, loss: 0.085931
 >> iter 86000, loss: 0.245265
 >> iter 87000, loss: 0.233060
 >> iter 88000, loss: 0.277719
 >> iter 89000, loss: 0.162453
 >> iter 90000, loss: 0.324817
   Number of active neurons: 4
 >> iter 91000, loss: 0.212500
 >> iter 92000, loss: 0.171773
 >> iter 93000, loss: 0.254370
 >> iter 94000, loss: 0.224882
 >> iter 95000, loss: 0.226826
 >> iter 96000, loss: 0.268515
 >> iter 97000, loss: 0.195372
 >> iter 98000, loss: 0.191173
 >> iter 99000, loss: 0.310193
 >> iter 100000, loss: 0.280455
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.181446
 >> iter 2000, loss: 10.481999
 >> iter 3000, loss: 4.258123
 >> iter 4000, loss: 1.811250
 >> iter 5000, loss: 0.887038
 >> iter 6000, loss: 0.519458
 >> iter 7000, loss: 0.418654
 >> iter 8000, loss: 0.392655
 >> iter 9000, loss: 0.275155
 >> iter 10000, loss: 0.228085
   Number of active neurons: 8
 >> iter 11000, loss: 0.260630
 >> iter 12000, loss: 0.181192
 >> iter 13000, loss: 0.263254
 >> iter 14000, loss: 0.184043
 >> iter 15000, loss: 0.481477
 >> iter 16000, loss: 0.386631
 >> iter 17000, loss: 0.279902
 >> iter 18000, loss: 0.261044
 >> iter 19000, loss: 0.301037
 >> iter 20000, loss: 0.311948
   Number of active neurons: 8
 >> iter 21000, loss: 0.255339
 >> iter 22000, loss: 0.265270
 >> iter 23000, loss: 0.216367
 >> iter 24000, loss: 0.234345
 >> iter 25000, loss: 0.156531
 >> iter 26000, loss: 0.189525
 >> iter 27000, loss: 0.286596
 >> iter 28000, loss: 0.402028
 >> iter 29000, loss: 0.292516
 >> iter 30000, loss: 0.338767
   Number of active neurons: 8
 >> iter 31000, loss: 0.381768
 >> iter 32000, loss: 0.218259
 >> iter 33000, loss: 0.209016
 >> iter 34000, loss: 0.186945
 >> iter 35000, loss: 0.247670
 >> iter 36000, loss: 0.222555
 >> iter 37000, loss: 0.255775
 >> iter 38000, loss: 0.235381
 >> iter 39000, loss: 0.195212
 >> iter 40000, loss: 0.226840
   Number of active neurons: 6
 >> iter 41000, loss: 0.346918
 >> iter 42000, loss: 0.382203
 >> iter 43000, loss: 0.443257
 >> iter 44000, loss: 0.246739
 >> iter 45000, loss: 0.227410
 >> iter 46000, loss: 0.143973
 >> iter 47000, loss: 0.244287
 >> iter 48000, loss: 0.253760
 >> iter 49000, loss: 0.279355
 >> iter 50000, loss: 0.258869
   Number of active neurons: 6
 >> iter 51000, loss: 0.191866
 >> iter 52000, loss: 0.295351
 >> iter 53000, loss: 0.468868
 >> iter 54000, loss: 0.268107
 >> iter 55000, loss: 0.376580
 >> iter 56000, loss: 0.416268
 >> iter 57000, loss: 0.282415
 >> iter 58000, loss: 0.198374
 >> iter 59000, loss: 0.174665
 >> iter 60000, loss: 0.288549
   Number of active neurons: 6
 >> iter 61000, loss: 0.339911
 >> iter 62000, loss: 0.235088
 >> iter 63000, loss: 0.246927
 >> iter 64000, loss: 0.234916
 >> iter 65000, loss: 0.202577
 >> iter 66000, loss: 0.153306
 >> iter 67000, loss: 0.136630
 >> iter 68000, loss: 0.187881
 >> iter 69000, loss: 0.260897
 >> iter 70000, loss: 0.301134
   Number of active neurons: 6
 >> iter 71000, loss: 0.284739
 >> iter 72000, loss: 0.189848
 >> iter 73000, loss: 0.106905
 >> iter 74000, loss: 0.196706
 >> iter 75000, loss: 0.179370
 >> iter 76000, loss: 0.171500
 >> iter 77000, loss: 0.193400
 >> iter 78000, loss: 0.178896
 >> iter 79000, loss: 0.202574
 >> iter 80000, loss: 0.211128
   Number of active neurons: 6
 >> iter 81000, loss: 0.205850
 >> iter 82000, loss: 0.321180
 >> iter 83000, loss: 0.270614
 >> iter 84000, loss: 0.223092
 >> iter 85000, loss: 0.255824
 >> iter 86000, loss: 0.229812
 >> iter 87000, loss: 0.262444
 >> iter 88000, loss: 0.270867
 >> iter 89000, loss: 0.288639
 >> iter 90000, loss: 0.216806
   Number of active neurons: 6
 >> iter 91000, loss: 0.158819
 >> iter 92000, loss: 0.102324
 >> iter 93000, loss: 0.098630
 >> iter 94000, loss: 0.315188
 >> iter 95000, loss: 0.425180
 >> iter 96000, loss: 0.279723
 >> iter 97000, loss: 0.289964
 >> iter 98000, loss: 0.385208
 >> iter 99000, loss: 0.375446
 >> iter 100000, loss: 0.231537
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.132081
 >> iter 2000, loss: 11.058181
 >> iter 3000, loss: 5.055307
 >> iter 4000, loss: 2.757622
 >> iter 5000, loss: 1.449188
 >> iter 6000, loss: 0.991616
 >> iter 7000, loss: 0.585434
 >> iter 8000, loss: 0.453866
 >> iter 9000, loss: 0.448532
 >> iter 10000, loss: 0.455495
   Number of active neurons: 10
 >> iter 11000, loss: 0.471090
 >> iter 12000, loss: 0.361104
 >> iter 13000, loss: 0.297666
 >> iter 14000, loss: 0.411383
 >> iter 15000, loss: 0.472423
 >> iter 16000, loss: 0.323233
 >> iter 17000, loss: 0.444958
 >> iter 18000, loss: 0.347992
 >> iter 19000, loss: 0.286799
 >> iter 20000, loss: 0.355276
   Number of active neurons: 10
 >> iter 21000, loss: 0.336515
 >> iter 22000, loss: 0.360875
 >> iter 23000, loss: 0.422500
 >> iter 24000, loss: 0.507086
 >> iter 25000, loss: 0.436773
 >> iter 26000, loss: 0.264782
 >> iter 27000, loss: 0.268254
 >> iter 28000, loss: 0.331377
 >> iter 29000, loss: 0.272760
 >> iter 30000, loss: 0.216966
   Number of active neurons: 10
 >> iter 31000, loss: 0.477364
 >> iter 32000, loss: 0.363515
 >> iter 33000, loss: 0.294975
 >> iter 34000, loss: 0.279710
 >> iter 35000, loss: 0.444877
 >> iter 36000, loss: 0.401516
 >> iter 37000, loss: 0.299756
 >> iter 38000, loss: 0.283708
 >> iter 39000, loss: 0.217797
 >> iter 40000, loss: 0.405057
   Number of active neurons: 9
 >> iter 41000, loss: 0.417425
 >> iter 42000, loss: 0.368603
 >> iter 43000, loss: 0.429517
 >> iter 44000, loss: 0.294830
 >> iter 45000, loss: 0.299541
 >> iter 46000, loss: 0.203800
 >> iter 47000, loss: 0.477302
 >> iter 48000, loss: 0.379646
 >> iter 49000, loss: 0.258817
 >> iter 50000, loss: 0.355651
   Number of active neurons: 9
 >> iter 51000, loss: 0.269482
 >> iter 52000, loss: 0.267570
 >> iter 53000, loss: 0.429383
 >> iter 54000, loss: 0.411235
 >> iter 55000, loss: 0.438449
 >> iter 56000, loss: 0.250641
 >> iter 57000, loss: 0.352310
 >> iter 58000, loss: 0.232666
 >> iter 59000, loss: 0.341367
 >> iter 60000, loss: 0.208736
   Number of active neurons: 9
 >> iter 61000, loss: 0.142342
 >> iter 62000, loss: 0.310381
 >> iter 63000, loss: 0.351267
 >> iter 64000, loss: 0.286974
 >> iter 65000, loss: 0.230879
 >> iter 66000, loss: 0.461886
 >> iter 67000, loss: 0.390070
 >> iter 68000, loss: 0.306106
 >> iter 69000, loss: 0.220485
 >> iter 70000, loss: 0.208296
   Number of active neurons: 7
 >> iter 71000, loss: 0.328467
 >> iter 72000, loss: 0.409334
 >> iter 73000, loss: 0.390203
 >> iter 74000, loss: 0.370925
 >> iter 75000, loss: 0.235933
 >> iter 76000, loss: 0.363592
 >> iter 77000, loss: 0.359237
 >> iter 78000, loss: 0.458044
 >> iter 79000, loss: 0.337605
 >> iter 80000, loss: 0.372167
   Number of active neurons: 7
 >> iter 81000, loss: 0.511829
 >> iter 82000, loss: 0.425712
 >> iter 83000, loss: 0.320417
 >> iter 84000, loss: 0.253670
 >> iter 85000, loss: 0.314175
 >> iter 86000, loss: 0.382993
 >> iter 87000, loss: 0.256417
 >> iter 88000, loss: 0.256406
 >> iter 89000, loss: 0.255789
 >> iter 90000, loss: 0.253870
   Number of active neurons: 7
 >> iter 91000, loss: 0.458188
 >> iter 92000, loss: 0.335743
 >> iter 93000, loss: 0.232595
 >> iter 94000, loss: 0.271366
 >> iter 95000, loss: 0.245423
 >> iter 96000, loss: 0.271537
 >> iter 97000, loss: 0.155149
 >> iter 98000, loss: 0.266758
 >> iter 99000, loss: 0.220944
 >> iter 100000, loss: 0.212302
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.023035
 >> iter 2000, loss: 11.205615
 >> iter 3000, loss: 5.288983
 >> iter 4000, loss: 2.285548
 >> iter 5000, loss: 1.192426
 >> iter 6000, loss: 0.823169
 >> iter 7000, loss: 0.608546
 >> iter 8000, loss: 0.567791
 >> iter 9000, loss: 0.437835
 >> iter 10000, loss: 0.462553
   Number of active neurons: 8
 >> iter 11000, loss: 0.486641
 >> iter 12000, loss: 0.354977
 >> iter 13000, loss: 0.453745
 >> iter 14000, loss: 0.449067
 >> iter 15000, loss: 0.346246
 >> iter 16000, loss: 0.339699
 >> iter 17000, loss: 0.429968
 >> iter 18000, loss: 0.521035
 >> iter 19000, loss: 0.473948
 >> iter 20000, loss: 0.403831
   Number of active neurons: 7
 >> iter 21000, loss: 0.352940
 >> iter 22000, loss: 0.362740
 >> iter 23000, loss: 0.303599
 >> iter 24000, loss: 0.441753
 >> iter 25000, loss: 0.291001
 >> iter 26000, loss: 0.327452
 >> iter 27000, loss: 0.177023
 >> iter 28000, loss: 0.391409
 >> iter 29000, loss: 0.387593
 >> iter 30000, loss: 0.298273
   Number of active neurons: 6
 >> iter 31000, loss: 0.263329
 >> iter 32000, loss: 0.200273
 >> iter 33000, loss: 0.171445
 >> iter 34000, loss: 0.183040
 >> iter 35000, loss: 0.104901
 >> iter 36000, loss: 0.123129
 >> iter 37000, loss: 0.179755
 >> iter 38000, loss: 0.121641
 >> iter 39000, loss: 0.115031
 >> iter 40000, loss: 0.107075
   Number of active neurons: 6
 >> iter 41000, loss: 0.320352
 >> iter 42000, loss: 0.219425
 >> iter 43000, loss: 0.211594
 >> iter 44000, loss: 0.313925
 >> iter 45000, loss: 0.270088
 >> iter 46000, loss: 0.244951
 >> iter 47000, loss: 0.177393
 >> iter 48000, loss: 0.127145
 >> iter 49000, loss: 0.285471
 >> iter 50000, loss: 0.188940
   Number of active neurons: 5
 >> iter 51000, loss: 0.255031
 >> iter 52000, loss: 0.242468
 >> iter 53000, loss: 0.214723
 >> iter 54000, loss: 0.278432
 >> iter 55000, loss: 0.158575
 >> iter 56000, loss: 0.162076
 >> iter 57000, loss: 0.205151
 >> iter 58000, loss: 0.246515
 >> iter 59000, loss: 0.191092
 >> iter 60000, loss: 0.175304
   Number of active neurons: 4
 >> iter 61000, loss: 0.197738
 >> iter 62000, loss: 0.185854
 >> iter 63000, loss: 0.190188
 >> iter 64000, loss: 0.215452
 >> iter 65000, loss: 0.333408
 >> iter 66000, loss: 0.315599
 >> iter 67000, loss: 0.183380
 >> iter 68000, loss: 0.191352
 >> iter 69000, loss: 0.245073
 >> iter 70000, loss: 0.300488
   Number of active neurons: 4
 >> iter 71000, loss: 0.239778
 >> iter 72000, loss: 0.315222
 >> iter 73000, loss: 0.226727
 >> iter 74000, loss: 0.179262
 >> iter 75000, loss: 0.242139
 >> iter 76000, loss: 0.288222
 >> iter 77000, loss: 0.274262
 >> iter 78000, loss: 0.169227
 >> iter 79000, loss: 0.298038
 >> iter 80000, loss: 0.185546
   Number of active neurons: 4
 >> iter 81000, loss: 0.144867
 >> iter 82000, loss: 0.147791
 >> iter 83000, loss: 0.156147
 >> iter 84000, loss: 0.350661
 >> iter 85000, loss: 0.183867
 >> iter 86000, loss: 0.198395
 >> iter 87000, loss: 0.176902
 >> iter 88000, loss: 0.150529
 >> iter 89000, loss: 0.221914
 >> iter 90000, loss: 0.248172
   Number of active neurons: 4
 >> iter 91000, loss: 0.320049
 >> iter 92000, loss: 0.420452
 >> iter 93000, loss: 0.307185
 >> iter 94000, loss: 0.241077
 >> iter 95000, loss: 0.194480
 >> iter 96000, loss: 0.154720
 >> iter 97000, loss: 0.204847
 >> iter 98000, loss: 0.184942
 >> iter 99000, loss: 0.165215
 >> iter 100000, loss: 0.209396
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.988860
 >> iter 2000, loss: 13.193540
 >> iter 3000, loss: 6.372448
 >> iter 4000, loss: 3.169286
 >> iter 5000, loss: 1.569584
 >> iter 6000, loss: 0.907822
 >> iter 7000, loss: 0.656454
 >> iter 8000, loss: 0.572192
 >> iter 9000, loss: 0.473454
 >> iter 10000, loss: 0.290189
   Number of active neurons: 7
 >> iter 11000, loss: 0.362674
 >> iter 12000, loss: 0.337239
 >> iter 13000, loss: 0.391092
 >> iter 14000, loss: 0.443823
 >> iter 15000, loss: 0.284270
 >> iter 16000, loss: 0.286904
 >> iter 17000, loss: 0.364784
 >> iter 18000, loss: 0.326660
 >> iter 19000, loss: 0.502149
 >> iter 20000, loss: 0.321083
   Number of active neurons: 7
 >> iter 21000, loss: 0.383679
 >> iter 22000, loss: 0.234921
 >> iter 23000, loss: 0.249292
 >> iter 24000, loss: 0.191588
 >> iter 25000, loss: 0.209914
 >> iter 26000, loss: 0.287053
 >> iter 27000, loss: 0.339736
 >> iter 28000, loss: 0.311845
 >> iter 29000, loss: 0.285539
 >> iter 30000, loss: 0.357942
   Number of active neurons: 7
 >> iter 31000, loss: 0.424018
 >> iter 32000, loss: 0.310110
 >> iter 33000, loss: 0.296278
 >> iter 34000, loss: 0.259135
 >> iter 35000, loss: 0.224510
 >> iter 36000, loss: 0.437452
 >> iter 37000, loss: 0.380915
 >> iter 38000, loss: 0.320392
 >> iter 39000, loss: 0.253177
 >> iter 40000, loss: 0.270681
   Number of active neurons: 7
 >> iter 41000, loss: 0.248466
 >> iter 42000, loss: 0.359896
 >> iter 43000, loss: 0.289129
 >> iter 44000, loss: 0.205534
 >> iter 45000, loss: 0.363581
 >> iter 46000, loss: 0.254390
 >> iter 47000, loss: 0.207088
 >> iter 48000, loss: 0.196191
 >> iter 49000, loss: 0.270877
 >> iter 50000, loss: 0.236988
   Number of active neurons: 7
 >> iter 51000, loss: 0.274029
 >> iter 52000, loss: 0.469036
 >> iter 53000, loss: 0.238882
 >> iter 54000, loss: 0.219355
 >> iter 55000, loss: 0.364305
 >> iter 56000, loss: 0.488237
 >> iter 57000, loss: 0.293332
 >> iter 58000, loss: 0.298240
 >> iter 59000, loss: 0.507753
 >> iter 60000, loss: 0.376965
   Number of active neurons: 7
 >> iter 61000, loss: 0.330120
 >> iter 62000, loss: 0.248846
 >> iter 63000, loss: 0.194355
 >> iter 64000, loss: 0.159862
 >> iter 65000, loss: 0.329594
 >> iter 66000, loss: 0.196326
 >> iter 67000, loss: 0.206004
 >> iter 68000, loss: 0.333890
 >> iter 69000, loss: 0.354183
 >> iter 70000, loss: 0.233832
   Number of active neurons: 7
 >> iter 71000, loss: 0.255912
 >> iter 72000, loss: 0.312945
 >> iter 73000, loss: 0.349730
 >> iter 74000, loss: 0.257397
 >> iter 75000, loss: 0.377943
 >> iter 76000, loss: 0.281964
 >> iter 77000, loss: 0.286424
 >> iter 78000, loss: 0.174769
 >> iter 79000, loss: 0.233205
 >> iter 80000, loss: 0.252663
   Number of active neurons: 6
 >> iter 81000, loss: 0.313921
 >> iter 82000, loss: 0.413403
 >> iter 83000, loss: 0.421176
 >> iter 84000, loss: 0.315556
 >> iter 85000, loss: 0.355375
 >> iter 86000, loss: 0.221288
 >> iter 87000, loss: 0.264809
 >> iter 88000, loss: 0.229375
 >> iter 89000, loss: 0.209278
 >> iter 90000, loss: 0.164156
   Number of active neurons: 6
 >> iter 91000, loss: 0.261293
 >> iter 92000, loss: 0.336210
 >> iter 93000, loss: 0.249890
 >> iter 94000, loss: 0.247457
 >> iter 95000, loss: 0.305541
 >> iter 96000, loss: 0.244817
 >> iter 97000, loss: 0.323637
 >> iter 98000, loss: 0.431937
 >> iter 99000, loss: 0.357680
 >> iter 100000, loss: 0.245385
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.050935
 >> iter 2000, loss: 11.109451
 >> iter 3000, loss: 5.294370
 >> iter 4000, loss: 2.694179
 >> iter 5000, loss: 1.411511
 >> iter 6000, loss: 0.943243
 >> iter 7000, loss: 0.542665
 >> iter 8000, loss: 0.609379
 >> iter 9000, loss: 0.497109
 >> iter 10000, loss: 0.315845
   Number of active neurons: 7
 >> iter 11000, loss: 0.277523
 >> iter 12000, loss: 0.269527
 >> iter 13000, loss: 0.221370
 >> iter 14000, loss: 0.260699
 >> iter 15000, loss: 0.359724
 >> iter 16000, loss: 0.286241
 >> iter 17000, loss: 0.285071
 >> iter 18000, loss: 0.157527
 >> iter 19000, loss: 0.355962
 >> iter 20000, loss: 0.261496
   Number of active neurons: 7
 >> iter 21000, loss: 0.182251
 >> iter 22000, loss: 0.272131
 >> iter 23000, loss: 0.437433
 >> iter 24000, loss: 0.340387
 >> iter 25000, loss: 0.241758
 >> iter 26000, loss: 0.306579
 >> iter 27000, loss: 0.288359
 >> iter 28000, loss: 0.220883
 >> iter 29000, loss: 0.254565
 >> iter 30000, loss: 0.413572
   Number of active neurons: 7
 >> iter 31000, loss: 0.338617
 >> iter 32000, loss: 0.227518
 >> iter 33000, loss: 0.308641
 >> iter 34000, loss: 0.254329
 >> iter 35000, loss: 0.252554
 >> iter 36000, loss: 0.279699
 >> iter 37000, loss: 0.227670
 >> iter 38000, loss: 0.301008
 >> iter 39000, loss: 0.309719
 >> iter 40000, loss: 0.249221
   Number of active neurons: 7
 >> iter 41000, loss: 0.199530
 >> iter 42000, loss: 0.279053
 >> iter 43000, loss: 0.239296
 >> iter 44000, loss: 0.233033
 >> iter 45000, loss: 0.285796
 >> iter 46000, loss: 0.180540
 >> iter 47000, loss: 0.244347
 >> iter 48000, loss: 0.247153
 >> iter 49000, loss: 0.188318
 >> iter 50000, loss: 0.232792
   Number of active neurons: 6
 >> iter 51000, loss: 0.207536
 >> iter 52000, loss: 0.196644
 >> iter 53000, loss: 0.174791
 >> iter 54000, loss: 0.252528
 >> iter 55000, loss: 0.178794
 >> iter 56000, loss: 0.229157
 >> iter 57000, loss: 0.168235
 >> iter 58000, loss: 0.126084
 >> iter 59000, loss: 0.296940
 >> iter 60000, loss: 0.307798
   Number of active neurons: 6
 >> iter 61000, loss: 0.276364
 >> iter 62000, loss: 0.292747
 >> iter 63000, loss: 0.212558
 >> iter 64000, loss: 0.185459
 >> iter 65000, loss: 0.260811
 >> iter 66000, loss: 0.369260
 >> iter 67000, loss: 0.341059
 >> iter 68000, loss: 0.391435
 >> iter 69000, loss: 0.263719
 >> iter 70000, loss: 0.369199
   Number of active neurons: 6
 >> iter 71000, loss: 0.232343
 >> iter 72000, loss: 0.186365
 >> iter 73000, loss: 0.260523
 >> iter 74000, loss: 0.242764
 >> iter 75000, loss: 0.210125
 >> iter 76000, loss: 0.247087
 >> iter 77000, loss: 0.357604
 >> iter 78000, loss: 0.262823
 >> iter 79000, loss: 0.313702
 >> iter 80000, loss: 0.309861
   Number of active neurons: 6
 >> iter 81000, loss: 0.244137
 >> iter 82000, loss: 0.305451
 >> iter 83000, loss: 0.257333
 >> iter 84000, loss: 0.219247
 >> iter 85000, loss: 0.139205
 >> iter 86000, loss: 0.209902
 >> iter 87000, loss: 0.395183
 >> iter 88000, loss: 0.283132
 >> iter 89000, loss: 0.224297
 >> iter 90000, loss: 0.232050
   Number of active neurons: 5
 >> iter 91000, loss: 0.147230
 >> iter 92000, loss: 0.159638
 >> iter 93000, loss: 0.472298
 >> iter 94000, loss: 0.318675
 >> iter 95000, loss: 0.342012
 >> iter 96000, loss: 0.209007
 >> iter 97000, loss: 0.279482
 >> iter 98000, loss: 0.150014
 >> iter 99000, loss: 0.183307
 >> iter 100000, loss: 0.239091
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.998848
 >> iter 2000, loss: 12.642638
 >> iter 3000, loss: 6.174693
 >> iter 4000, loss: 3.052697
 >> iter 5000, loss: 1.521432
 >> iter 6000, loss: 1.038194
 >> iter 7000, loss: 0.676662
 >> iter 8000, loss: 0.634962
 >> iter 9000, loss: 0.583804
 >> iter 10000, loss: 0.409454
   Number of active neurons: 7
 >> iter 11000, loss: 0.403598
 >> iter 12000, loss: 0.274733
 >> iter 13000, loss: 0.229325
 >> iter 14000, loss: 0.241811
 >> iter 15000, loss: 0.269089
 >> iter 16000, loss: 0.250248
 >> iter 17000, loss: 0.329358
 >> iter 18000, loss: 0.435229
 >> iter 19000, loss: 0.313741
 >> iter 20000, loss: 0.275179
   Number of active neurons: 7
 >> iter 21000, loss: 0.187943
 >> iter 22000, loss: 0.381211
 >> iter 23000, loss: 0.400725
 >> iter 24000, loss: 0.368230
 >> iter 25000, loss: 0.376595
 >> iter 26000, loss: 0.292308
 >> iter 27000, loss: 0.389953
 >> iter 28000, loss: 0.303673
 >> iter 29000, loss: 0.275662
 >> iter 30000, loss: 0.327087
   Number of active neurons: 6
 >> iter 31000, loss: 0.351380
 >> iter 32000, loss: 0.259110
 >> iter 33000, loss: 0.343373
 >> iter 34000, loss: 0.263479
 >> iter 35000, loss: 0.144129
 >> iter 36000, loss: 0.242109
 >> iter 37000, loss: 0.283992
 >> iter 38000, loss: 0.286110
 >> iter 39000, loss: 0.237079
 >> iter 40000, loss: 0.179465
   Number of active neurons: 6
 >> iter 41000, loss: 0.154387
 >> iter 42000, loss: 0.291367
 >> iter 43000, loss: 0.337694
 >> iter 44000, loss: 0.254944
 >> iter 45000, loss: 0.373945
 >> iter 46000, loss: 0.284463
 >> iter 47000, loss: 0.197941
 >> iter 48000, loss: 0.188910
 >> iter 49000, loss: 0.176363
 >> iter 50000, loss: 0.205605
   Number of active neurons: 6
 >> iter 51000, loss: 0.210539
 >> iter 52000, loss: 0.285967
 >> iter 53000, loss: 0.278107
 >> iter 54000, loss: 0.174453
 >> iter 55000, loss: 0.203727
 >> iter 56000, loss: 0.155347
 >> iter 57000, loss: 0.241761
 >> iter 58000, loss: 0.256402
 >> iter 59000, loss: 0.226215
 >> iter 60000, loss: 0.402618
   Number of active neurons: 5
 >> iter 61000, loss: 0.269057
 >> iter 62000, loss: 0.289494
 >> iter 63000, loss: 0.171671
 >> iter 64000, loss: 0.143010
 >> iter 65000, loss: 0.111402
 >> iter 66000, loss: 0.146888
 >> iter 67000, loss: 0.180169
 >> iter 68000, loss: 0.169758
 >> iter 69000, loss: 0.182541
 >> iter 70000, loss: 0.190233
   Number of active neurons: 4
 >> iter 71000, loss: 0.143535
 >> iter 72000, loss: 0.316544
 >> iter 73000, loss: 0.278238
 >> iter 74000, loss: 0.220801
 >> iter 75000, loss: 0.229249
 >> iter 76000, loss: 0.177057
 >> iter 77000, loss: 0.290871
 >> iter 78000, loss: 0.209607
 >> iter 79000, loss: 0.167716
 >> iter 80000, loss: 0.322528
   Number of active neurons: 4
 >> iter 81000, loss: 0.388071
 >> iter 82000, loss: 0.236750
 >> iter 83000, loss: 0.294366
 >> iter 84000, loss: 0.221800
 >> iter 85000, loss: 0.262680
 >> iter 86000, loss: 0.265099
 >> iter 87000, loss: 0.250771
 >> iter 88000, loss: 0.203583
 >> iter 89000, loss: 0.140142
 >> iter 90000, loss: 0.152828
   Number of active neurons: 4
 >> iter 91000, loss: 0.211739
 >> iter 92000, loss: 0.178993
 >> iter 93000, loss: 0.217297
 >> iter 94000, loss: 0.138081
 >> iter 95000, loss: 0.194009
 >> iter 96000, loss: 0.214291
 >> iter 97000, loss: 0.204191
 >> iter 98000, loss: 0.183651
 >> iter 99000, loss: 0.185137
 >> iter 100000, loss: 0.167801
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.234327
 >> iter 2000, loss: 11.844800
 >> iter 3000, loss: 6.502752
 >> iter 4000, loss: 3.736949
 >> iter 5000, loss: 2.219587
 >> iter 6000, loss: 1.567435
 >> iter 7000, loss: 0.926915
 >> iter 8000, loss: 0.827877
 >> iter 9000, loss: 0.721411
 >> iter 10000, loss: 0.683165
   Number of active neurons: 6
 >> iter 11000, loss: 0.470146
 >> iter 12000, loss: 0.379192
 >> iter 13000, loss: 0.465874
 >> iter 14000, loss: 0.355720
 >> iter 15000, loss: 0.517929
 >> iter 16000, loss: 0.462204
 >> iter 17000, loss: 0.533976
 >> iter 18000, loss: 0.437195
 >> iter 19000, loss: 0.664145
 >> iter 20000, loss: 0.513901
   Number of active neurons: 6
 >> iter 21000, loss: 0.349731
 >> iter 22000, loss: 0.442570
 >> iter 23000, loss: 0.365870
 >> iter 24000, loss: 0.460006
 >> iter 25000, loss: 0.543428
 >> iter 26000, loss: 0.598047
 >> iter 27000, loss: 0.451834
 >> iter 28000, loss: 0.481417
 >> iter 29000, loss: 0.402410
 >> iter 30000, loss: 0.364109
   Number of active neurons: 6
 >> iter 31000, loss: 0.208181
 >> iter 32000, loss: 0.305266
 >> iter 33000, loss: 0.294886
 >> iter 34000, loss: 0.409479
 >> iter 35000, loss: 0.326031
 >> iter 36000, loss: 0.355379
 >> iter 37000, loss: 0.369366
 >> iter 38000, loss: 0.282075
 >> iter 39000, loss: 0.579358
 >> iter 40000, loss: 0.640467
   Number of active neurons: 6
 >> iter 41000, loss: 0.412543
 >> iter 42000, loss: 0.411369
 >> iter 43000, loss: 0.339846
 >> iter 44000, loss: 0.490894
 >> iter 45000, loss: 0.303957
 >> iter 46000, loss: 0.550696
 >> iter 47000, loss: 0.461077
 >> iter 48000, loss: 0.517861
 >> iter 49000, loss: 0.561628
 >> iter 50000, loss: 0.475776
   Number of active neurons: 6
 >> iter 51000, loss: 0.518701
 >> iter 52000, loss: 0.462230
 >> iter 53000, loss: 0.484095
 >> iter 54000, loss: 0.413052
 >> iter 55000, loss: 0.449390
 >> iter 56000, loss: 0.397763
 >> iter 57000, loss: 0.453844
 >> iter 58000, loss: 0.352130
 >> iter 59000, loss: 0.463862
 >> iter 60000, loss: 0.312517
   Number of active neurons: 6
 >> iter 61000, loss: 0.458934
 >> iter 62000, loss: 0.492326
 >> iter 63000, loss: 0.633733
 >> iter 64000, loss: 0.562560
 >> iter 65000, loss: 0.449885
 >> iter 66000, loss: 0.491162
 >> iter 67000, loss: 0.484374
 >> iter 68000, loss: 0.382809
 >> iter 69000, loss: 0.276718
 >> iter 70000, loss: 0.296195
   Number of active neurons: 6
 >> iter 71000, loss: 0.435928
 >> iter 72000, loss: 0.479987
 >> iter 73000, loss: 0.474093
 >> iter 74000, loss: 0.555324
 >> iter 75000, loss: 0.541223
 >> iter 76000, loss: 0.535259
 >> iter 77000, loss: 0.563371
 >> iter 78000, loss: 0.445812
 >> iter 79000, loss: 0.311123
 >> iter 80000, loss: 0.303155
   Number of active neurons: 6
 >> iter 81000, loss: 0.378067
 >> iter 82000, loss: 0.255127
 >> iter 83000, loss: 0.233460
 >> iter 84000, loss: 0.172453
 >> iter 85000, loss: 0.240202
 >> iter 86000, loss: 0.294633
 >> iter 87000, loss: 0.258263
 >> iter 88000, loss: 0.211890
 >> iter 89000, loss: 0.147711
 >> iter 90000, loss: 0.156855
   Number of active neurons: 6
 >> iter 91000, loss: 0.123200
 >> iter 92000, loss: 0.306685
 >> iter 93000, loss: 0.211369
 >> iter 94000, loss: 0.237054
 >> iter 95000, loss: 0.168987
 >> iter 96000, loss: 0.424502
 >> iter 97000, loss: 0.371126
 >> iter 98000, loss: 0.291651
 >> iter 99000, loss: 0.205752
 >> iter 100000, loss: 0.290476
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.984486
 >> iter 2000, loss: 12.567011
 >> iter 3000, loss: 6.016951
 >> iter 4000, loss: 2.590499
 >> iter 5000, loss: 1.232920
 >> iter 6000, loss: 0.755078
 >> iter 7000, loss: 0.348051
 >> iter 8000, loss: 0.377446
 >> iter 9000, loss: 0.431386
 >> iter 10000, loss: 0.397898
   Number of active neurons: 8
 >> iter 11000, loss: 0.350334
 >> iter 12000, loss: 0.416745
 >> iter 13000, loss: 0.428246
 >> iter 14000, loss: 0.371020
 >> iter 15000, loss: 0.268571
 >> iter 16000, loss: 0.346521
 >> iter 17000, loss: 0.411802
 >> iter 18000, loss: 0.338079
 >> iter 19000, loss: 0.266025
 >> iter 20000, loss: 0.272992
   Number of active neurons: 8
 >> iter 21000, loss: 0.183565
 >> iter 22000, loss: 0.181510
 >> iter 23000, loss: 0.289025
 >> iter 24000, loss: 0.417311
 >> iter 25000, loss: 0.403988
 >> iter 26000, loss: 0.363132
 >> iter 27000, loss: 0.292338
 >> iter 28000, loss: 0.176514
 >> iter 29000, loss: 0.225675
 >> iter 30000, loss: 0.241050
   Number of active neurons: 8
 >> iter 31000, loss: 0.222651
 >> iter 32000, loss: 0.217483
 >> iter 33000, loss: 0.202951
 >> iter 34000, loss: 0.170849
 >> iter 35000, loss: 0.155870
 >> iter 36000, loss: 0.298142
 >> iter 37000, loss: 0.291753
 >> iter 38000, loss: 0.326015
 >> iter 39000, loss: 0.293838
 >> iter 40000, loss: 0.263601
   Number of active neurons: 7
 >> iter 41000, loss: 0.296363
 >> iter 42000, loss: 0.281512
 >> iter 43000, loss: 0.270908
 >> iter 44000, loss: 0.459068
 >> iter 45000, loss: 0.394698
 >> iter 46000, loss: 0.323749
 >> iter 47000, loss: 0.349717
 >> iter 48000, loss: 0.228681
 >> iter 49000, loss: 0.175602
 >> iter 50000, loss: 0.117068
   Number of active neurons: 7
 >> iter 51000, loss: 0.291156
 >> iter 52000, loss: 0.221298
 >> iter 53000, loss: 0.214003
 >> iter 54000, loss: 0.306917
 >> iter 55000, loss: 0.317695
 >> iter 56000, loss: 0.323320
 >> iter 57000, loss: 0.262093
 >> iter 58000, loss: 0.285148
 >> iter 59000, loss: 0.187266
 >> iter 60000, loss: 0.300322
   Number of active neurons: 7
 >> iter 61000, loss: 0.227606
 >> iter 62000, loss: 0.187741
 >> iter 63000, loss: 0.449383
 >> iter 64000, loss: 0.401734
 >> iter 65000, loss: 0.246622
 >> iter 66000, loss: 0.273333
 >> iter 67000, loss: 0.409676
 >> iter 68000, loss: 0.345181
 >> iter 69000, loss: 0.233167
 >> iter 70000, loss: 0.248797
   Number of active neurons: 7
 >> iter 71000, loss: 0.353606
 >> iter 72000, loss: 0.340088
 >> iter 73000, loss: 0.355920
 >> iter 74000, loss: 0.273453
 >> iter 75000, loss: 0.227251
 >> iter 76000, loss: 0.205472
 >> iter 77000, loss: 0.401018
 >> iter 78000, loss: 0.225574
 >> iter 79000, loss: 0.192545
 >> iter 80000, loss: 0.426494
   Number of active neurons: 6
 >> iter 81000, loss: 0.256731
 >> iter 82000, loss: 0.269704
 >> iter 83000, loss: 0.458587
 >> iter 84000, loss: 0.308462
 >> iter 85000, loss: 0.383482
 >> iter 86000, loss: 0.372074
 >> iter 87000, loss: 0.311087
 >> iter 88000, loss: 0.370640
 >> iter 89000, loss: 0.320547
 >> iter 90000, loss: 0.328382
   Number of active neurons: 6
 >> iter 91000, loss: 0.410122
 >> iter 92000, loss: 0.238338
 >> iter 93000, loss: 0.278160
 >> iter 94000, loss: 0.350723
 >> iter 95000, loss: 0.310212
 >> iter 96000, loss: 0.261757
 >> iter 97000, loss: 0.293939
 >> iter 98000, loss: 0.306123
 >> iter 99000, loss: 0.388588
 >> iter 100000, loss: 0.333332
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.103498
 >> iter 2000, loss: 10.316543
 >> iter 3000, loss: 4.408763
 >> iter 4000, loss: 2.045690
 >> iter 5000, loss: 1.147366
 >> iter 6000, loss: 0.604557
 >> iter 7000, loss: 0.290883
 >> iter 8000, loss: 0.358736
 >> iter 9000, loss: 0.488303
 >> iter 10000, loss: 0.500156
   Number of active neurons: 10
 >> iter 11000, loss: 0.416704
 >> iter 12000, loss: 0.297420
 >> iter 13000, loss: 0.305291
 >> iter 14000, loss: 0.551280
 >> iter 15000, loss: 0.338642
 >> iter 16000, loss: 0.256535
 >> iter 17000, loss: 0.420638
 >> iter 18000, loss: 0.251015
 >> iter 19000, loss: 0.288775
 >> iter 20000, loss: 0.375778
   Number of active neurons: 10
 >> iter 21000, loss: 0.191958
 >> iter 22000, loss: 0.373495
 >> iter 23000, loss: 0.428144
 >> iter 24000, loss: 0.249633
 >> iter 25000, loss: 0.282288
 >> iter 26000, loss: 0.293990
 >> iter 27000, loss: 0.240812
 >> iter 28000, loss: 0.259337
 >> iter 29000, loss: 0.281125
 >> iter 30000, loss: 0.331680
   Number of active neurons: 10
 >> iter 31000, loss: 0.328818
 >> iter 32000, loss: 0.248106
 >> iter 33000, loss: 0.293470
 >> iter 34000, loss: 0.306842
 >> iter 35000, loss: 0.279948
 >> iter 36000, loss: 0.253089
 >> iter 37000, loss: 0.384673
 >> iter 38000, loss: 0.209368
 >> iter 39000, loss: 0.354589
 >> iter 40000, loss: 0.291038
   Number of active neurons: 10
 >> iter 41000, loss: 0.377794
 >> iter 42000, loss: 0.289230
 >> iter 43000, loss: 0.208527
 >> iter 44000, loss: 0.284633
 >> iter 45000, loss: 0.232775
 >> iter 46000, loss: 0.409323
 >> iter 47000, loss: 0.440524
 >> iter 48000, loss: 0.310780
 >> iter 49000, loss: 0.204476
 >> iter 50000, loss: 0.180811
   Number of active neurons: 9
 >> iter 51000, loss: 0.376938
 >> iter 52000, loss: 0.299670
 >> iter 53000, loss: 0.247537
 >> iter 54000, loss: 0.311398
 >> iter 55000, loss: 0.333261
 >> iter 56000, loss: 0.571249
 >> iter 57000, loss: 0.457769
 >> iter 58000, loss: 0.408103
 >> iter 59000, loss: 0.481849
 >> iter 60000, loss: 0.509427
   Number of active neurons: 9
 >> iter 61000, loss: 0.308247
 >> iter 62000, loss: 0.285447
 >> iter 63000, loss: 0.224423
 >> iter 64000, loss: 0.536124
 >> iter 65000, loss: 0.396180
 >> iter 66000, loss: 0.353373
 >> iter 67000, loss: 0.342847
 >> iter 68000, loss: 0.288547
 >> iter 69000, loss: 0.219630
 >> iter 70000, loss: 0.332211
   Number of active neurons: 8
 >> iter 71000, loss: 0.304218
 >> iter 72000, loss: 0.257980
 >> iter 73000, loss: 0.289188
 >> iter 74000, loss: 0.262879
 >> iter 75000, loss: 0.360669
 >> iter 76000, loss: 0.324015
 >> iter 77000, loss: 0.497535
 >> iter 78000, loss: 0.375340
 >> iter 79000, loss: 0.312087
 >> iter 80000, loss: 0.267161
   Number of active neurons: 8
 >> iter 81000, loss: 0.191782
 >> iter 82000, loss: 0.321369
 >> iter 83000, loss: 0.468098
 >> iter 84000, loss: 0.395220
 >> iter 85000, loss: 0.343757
 >> iter 86000, loss: 0.296243
 >> iter 87000, loss: 0.220303
 >> iter 88000, loss: 0.229003
 >> iter 89000, loss: 0.292070
 >> iter 90000, loss: 0.334460
   Number of active neurons: 7
 >> iter 91000, loss: 0.298826
 >> iter 92000, loss: 0.293016
 >> iter 93000, loss: 0.265747
 >> iter 94000, loss: 0.347374
 >> iter 95000, loss: 0.293684
 >> iter 96000, loss: 0.244539
 >> iter 97000, loss: 0.211930
 >> iter 98000, loss: 0.421120
 >> iter 99000, loss: 0.578286
 >> iter 100000, loss: 0.336655
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.200048
 >> iter 2000, loss: 11.798588
 >> iter 3000, loss: 5.497412
 >> iter 4000, loss: 2.366616
 >> iter 5000, loss: 1.103585
 >> iter 6000, loss: 0.643196
 >> iter 7000, loss: 0.454854
 >> iter 8000, loss: 0.337303
 >> iter 9000, loss: 0.281570
 >> iter 10000, loss: 0.233939
   Number of active neurons: 5
 >> iter 11000, loss: 0.216784
 >> iter 12000, loss: 0.162030
 >> iter 13000, loss: 0.209735
 >> iter 14000, loss: 0.173652
 >> iter 15000, loss: 0.263715
 >> iter 16000, loss: 0.315463
 >> iter 17000, loss: 0.292848
 >> iter 18000, loss: 0.253891
 >> iter 19000, loss: 0.232311
 >> iter 20000, loss: 0.340566
   Number of active neurons: 5
 >> iter 21000, loss: 0.225738
 >> iter 22000, loss: 0.223955
 >> iter 23000, loss: 0.455150
 >> iter 24000, loss: 0.489596
 >> iter 25000, loss: 0.389813
 >> iter 26000, loss: 0.201426
 >> iter 27000, loss: 0.427712
 >> iter 28000, loss: 0.259428
 >> iter 29000, loss: 0.259479
 >> iter 30000, loss: 0.248552
   Number of active neurons: 5
 >> iter 31000, loss: 0.268852
 >> iter 32000, loss: 0.270609
 >> iter 33000, loss: 0.400887
 >> iter 34000, loss: 0.233029
 >> iter 35000, loss: 0.236235
 >> iter 36000, loss: 0.203159
 >> iter 37000, loss: 0.187716
 >> iter 38000, loss: 0.160458
 >> iter 39000, loss: 0.217982
 >> iter 40000, loss: 0.206948
   Number of active neurons: 5
 >> iter 41000, loss: 0.279944
 >> iter 42000, loss: 0.204107
 >> iter 43000, loss: 0.351089
 >> iter 44000, loss: 0.318361
 >> iter 45000, loss: 0.231769
 >> iter 46000, loss: 0.282495
 >> iter 47000, loss: 0.215391
 >> iter 48000, loss: 0.194025
 >> iter 49000, loss: 0.133268
 >> iter 50000, loss: 0.211016
   Number of active neurons: 5
 >> iter 51000, loss: 0.295289
 >> iter 52000, loss: 0.352740
 >> iter 53000, loss: 0.186490
 >> iter 54000, loss: 0.161708
 >> iter 55000, loss: 0.172964
 >> iter 56000, loss: 0.190913
 >> iter 57000, loss: 0.168206
 >> iter 58000, loss: 0.172735
 >> iter 59000, loss: 0.338568
 >> iter 60000, loss: 0.229246
   Number of active neurons: 5
 >> iter 61000, loss: 0.242872
 >> iter 62000, loss: 0.232341
 >> iter 63000, loss: 0.161712
 >> iter 64000, loss: 0.189906
 >> iter 65000, loss: 0.168643
 >> iter 66000, loss: 0.250567
 >> iter 67000, loss: 0.215123
 >> iter 68000, loss: 0.264953
 >> iter 69000, loss: 0.215376
 >> iter 70000, loss: 0.227378
   Number of active neurons: 5
 >> iter 71000, loss: 0.337797
 >> iter 72000, loss: 0.297493
 >> iter 73000, loss: 0.227372
 >> iter 74000, loss: 0.186485
 >> iter 75000, loss: 0.177239
 >> iter 76000, loss: 0.262075
 >> iter 77000, loss: 0.221648
 >> iter 78000, loss: 0.169863
 >> iter 79000, loss: 0.318909
 >> iter 80000, loss: 0.219206
   Number of active neurons: 5
 >> iter 81000, loss: 0.167884
 >> iter 82000, loss: 0.177355
 >> iter 83000, loss: 0.537942
 >> iter 84000, loss: 0.293588
 >> iter 85000, loss: 0.306021
 >> iter 86000, loss: 0.281139
 >> iter 87000, loss: 0.251887
 >> iter 88000, loss: 0.224383
 >> iter 89000, loss: 0.171332
 >> iter 90000, loss: 0.197472
   Number of active neurons: 4
 >> iter 91000, loss: 0.150974
 >> iter 92000, loss: 0.223311
 >> iter 93000, loss: 0.291256
 >> iter 94000, loss: 0.228735
 >> iter 95000, loss: 0.176627
 >> iter 96000, loss: 0.190791
 >> iter 97000, loss: 0.177067
 >> iter 98000, loss: 0.291478
 >> iter 99000, loss: 0.243529
 >> iter 100000, loss: 0.156342
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.080576
 >> iter 2000, loss: 11.124009
 >> iter 3000, loss: 5.763977
 >> iter 4000, loss: 2.805615
 >> iter 5000, loss: 1.620193
 >> iter 6000, loss: 0.900896
 >> iter 7000, loss: 0.830159
 >> iter 8000, loss: 0.619330
 >> iter 9000, loss: 0.684096
 >> iter 10000, loss: 0.486323
   Number of active neurons: 7
 >> iter 11000, loss: 0.436657
 >> iter 12000, loss: 0.644251
 >> iter 13000, loss: 0.475937
 >> iter 14000, loss: 0.557930
 >> iter 15000, loss: 0.524474
 >> iter 16000, loss: 0.467375
 >> iter 17000, loss: 0.368609
 >> iter 18000, loss: 0.478870
 >> iter 19000, loss: 0.628169
 >> iter 20000, loss: 0.579645
   Number of active neurons: 6
 >> iter 21000, loss: 0.531698
 >> iter 22000, loss: 0.378209
 >> iter 23000, loss: 0.473464
 >> iter 24000, loss: 0.426277
 >> iter 25000, loss: 0.570848
 >> iter 26000, loss: 0.543295
 >> iter 27000, loss: 0.588646
 >> iter 28000, loss: 0.358340
 >> iter 29000, loss: 0.498086
 >> iter 30000, loss: 0.511567
   Number of active neurons: 6
 >> iter 31000, loss: 0.426695
 >> iter 32000, loss: 0.647779
 >> iter 33000, loss: 0.655686
 >> iter 34000, loss: 0.463934
 >> iter 35000, loss: 0.416447
 >> iter 36000, loss: 0.381129
 >> iter 37000, loss: 0.448783
 >> iter 38000, loss: 0.435368
 >> iter 39000, loss: 0.500072
 >> iter 40000, loss: 0.424924
   Number of active neurons: 6
 >> iter 41000, loss: 0.415063
 >> iter 42000, loss: 0.406441
 >> iter 43000, loss: 0.378528
 >> iter 44000, loss: 0.397542
 >> iter 45000, loss: 0.379728
 >> iter 46000, loss: 0.432338
 >> iter 47000, loss: 0.471523
 >> iter 48000, loss: 0.367646
 >> iter 49000, loss: 0.354468
 >> iter 50000, loss: 0.333840
   Number of active neurons: 6
 >> iter 51000, loss: 0.442586
 >> iter 52000, loss: 0.330320
 >> iter 53000, loss: 0.539761
 >> iter 54000, loss: 0.538234
 >> iter 55000, loss: 0.574784
 >> iter 56000, loss: 0.421732
 >> iter 57000, loss: 0.421489
 >> iter 58000, loss: 0.491306
 >> iter 59000, loss: 0.454568
 >> iter 60000, loss: 0.639872
   Number of active neurons: 6
 >> iter 61000, loss: 0.493391
 >> iter 62000, loss: 0.459039
 >> iter 63000, loss: 0.468461
 >> iter 64000, loss: 0.366675
 >> iter 65000, loss: 0.344702
 >> iter 66000, loss: 0.469965
 >> iter 67000, loss: 0.454725
 >> iter 68000, loss: 0.454739
 >> iter 69000, loss: 0.466211
 >> iter 70000, loss: 0.521647
   Number of active neurons: 6
 >> iter 71000, loss: 0.672683
 >> iter 72000, loss: 0.400688
 >> iter 73000, loss: 0.519271
 >> iter 74000, loss: 0.433831
 >> iter 75000, loss: 0.442151
 >> iter 76000, loss: 0.451234
 >> iter 77000, loss: 0.361989
 >> iter 78000, loss: 0.311237
 >> iter 79000, loss: 0.522941
 >> iter 80000, loss: 0.371262
   Number of active neurons: 6
 >> iter 81000, loss: 0.271009
 >> iter 82000, loss: 0.475413
 >> iter 83000, loss: 0.483193
 >> iter 84000, loss: 0.311780
 >> iter 85000, loss: 0.505647
 >> iter 86000, loss: 0.408628
 >> iter 87000, loss: 0.505798
 >> iter 88000, loss: 0.473345
 >> iter 89000, loss: 0.643945
 >> iter 90000, loss: 0.501653
   Number of active neurons: 6
 >> iter 91000, loss: 0.474231
 >> iter 92000, loss: 0.565449
 >> iter 93000, loss: 0.405835
 >> iter 94000, loss: 0.428567
 >> iter 95000, loss: 0.345602
 >> iter 96000, loss: 0.310252
 >> iter 97000, loss: 0.368615
 >> iter 98000, loss: 0.418726
 >> iter 99000, loss: 0.391979
 >> iter 100000, loss: 0.437299
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.089430
 >> iter 2000, loss: 9.752877
 >> iter 3000, loss: 4.622077
 >> iter 4000, loss: 2.159032
 >> iter 5000, loss: 1.253636
 >> iter 6000, loss: 0.758996
 >> iter 7000, loss: 0.417319
 >> iter 8000, loss: 0.327222
 >> iter 9000, loss: 0.513744
 >> iter 10000, loss: 0.321483
   Number of active neurons: 9
 >> iter 11000, loss: 0.339551
 >> iter 12000, loss: 0.316606
 >> iter 13000, loss: 0.400098
 >> iter 14000, loss: 0.356999
 >> iter 15000, loss: 0.223440
 >> iter 16000, loss: 0.361083
 >> iter 17000, loss: 0.450230
 >> iter 18000, loss: 0.439083
 >> iter 19000, loss: 0.293339
 >> iter 20000, loss: 0.242277
   Number of active neurons: 9
 >> iter 21000, loss: 0.310575
 >> iter 22000, loss: 0.316174
 >> iter 23000, loss: 0.385475
 >> iter 24000, loss: 0.412241
 >> iter 25000, loss: 0.297167
 >> iter 26000, loss: 0.372793
 >> iter 27000, loss: 0.193557
 >> iter 28000, loss: 0.401178
 >> iter 29000, loss: 0.320581
 >> iter 30000, loss: 0.298855
   Number of active neurons: 9
 >> iter 31000, loss: 0.222782
 >> iter 32000, loss: 0.282208
 >> iter 33000, loss: 0.231428
 >> iter 34000, loss: 0.261265
 >> iter 35000, loss: 0.262504
 >> iter 36000, loss: 0.419424
 >> iter 37000, loss: 0.285252
 >> iter 38000, loss: 0.355206
 >> iter 39000, loss: 0.544971
 >> iter 40000, loss: 0.355557
   Number of active neurons: 9
 >> iter 41000, loss: 0.233251
 >> iter 42000, loss: 0.244081
 >> iter 43000, loss: 0.326994
 >> iter 44000, loss: 0.282106
 >> iter 45000, loss: 0.225344
 >> iter 46000, loss: 0.182485
 >> iter 47000, loss: 0.420691
 >> iter 48000, loss: 0.250944
 >> iter 49000, loss: 0.345235
 >> iter 50000, loss: 0.295248
   Number of active neurons: 8
 >> iter 51000, loss: 0.204616
 >> iter 52000, loss: 0.202667
 >> iter 53000, loss: 0.173423
 >> iter 54000, loss: 0.256460
 >> iter 55000, loss: 0.400682
 >> iter 56000, loss: 0.395257
 >> iter 57000, loss: 0.290956
 >> iter 58000, loss: 0.223172
 >> iter 59000, loss: 0.281641
 >> iter 60000, loss: 0.206931
   Number of active neurons: 7
 >> iter 61000, loss: 0.288528
 >> iter 62000, loss: 0.251379
 >> iter 63000, loss: 0.228810
 >> iter 64000, loss: 0.222791
 >> iter 65000, loss: 0.187351
 >> iter 66000, loss: 0.224766
 >> iter 67000, loss: 0.343013
 >> iter 68000, loss: 0.271674
 >> iter 69000, loss: 0.188128
 >> iter 70000, loss: 0.245286
   Number of active neurons: 7
 >> iter 71000, loss: 0.218587
 >> iter 72000, loss: 0.157241
 >> iter 73000, loss: 0.369444
 >> iter 74000, loss: 0.237164
 >> iter 75000, loss: 0.259698
 >> iter 76000, loss: 0.172266
 >> iter 77000, loss: 0.154061
 >> iter 78000, loss: 0.145706
 >> iter 79000, loss: 0.208827
 >> iter 80000, loss: 0.187317
   Number of active neurons: 7
 >> iter 81000, loss: 0.285689
 >> iter 82000, loss: 0.258910
 >> iter 83000, loss: 0.320053
 >> iter 84000, loss: 0.311457
 >> iter 85000, loss: 0.419834
 >> iter 86000, loss: 0.320730
 >> iter 87000, loss: 0.198094
 >> iter 88000, loss: 0.238376
 >> iter 89000, loss: 0.320062
 >> iter 90000, loss: 0.230599
   Number of active neurons: 7
 >> iter 91000, loss: 0.244092
 >> iter 92000, loss: 0.304759
 >> iter 93000, loss: 0.199477
 >> iter 94000, loss: 0.218960
 >> iter 95000, loss: 0.287568
 >> iter 96000, loss: 0.285948
 >> iter 97000, loss: 0.256569
 >> iter 98000, loss: 0.203697
 >> iter 99000, loss: 0.169867
 >> iter 100000, loss: 0.146689
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.032422
 >> iter 2000, loss: 13.853460
 >> iter 3000, loss: 10.525793
 >> iter 4000, loss: 5.849997
 >> iter 5000, loss: 2.850473
 >> iter 6000, loss: 1.449095
 >> iter 7000, loss: 0.909288
 >> iter 8000, loss: 0.576438
 >> iter 9000, loss: 0.348903
 >> iter 10000, loss: 0.346793
   Number of active neurons: 8
 >> iter 11000, loss: 0.403528
 >> iter 12000, loss: 0.500909
 >> iter 13000, loss: 0.502835
 >> iter 14000, loss: 0.281453
 >> iter 15000, loss: 0.296654
 >> iter 16000, loss: 0.247239
 >> iter 17000, loss: 0.313425
 >> iter 18000, loss: 0.289504
 >> iter 19000, loss: 0.405618
 >> iter 20000, loss: 0.252932
   Number of active neurons: 7
 >> iter 21000, loss: 0.217542
 >> iter 22000, loss: 0.208972
 >> iter 23000, loss: 0.191418
 >> iter 24000, loss: 0.237884
 >> iter 25000, loss: 0.226587
 >> iter 26000, loss: 0.316467
 >> iter 27000, loss: 0.246282
 >> iter 28000, loss: 0.285520
 >> iter 29000, loss: 0.261716
 >> iter 30000, loss: 0.189961
   Number of active neurons: 6
 >> iter 31000, loss: 0.175158
 >> iter 32000, loss: 0.293420
 >> iter 33000, loss: 0.306796
 >> iter 34000, loss: 0.249048
 >> iter 35000, loss: 0.337545
 >> iter 36000, loss: 0.251213
 >> iter 37000, loss: 0.230491
 >> iter 38000, loss: 0.262697
 >> iter 39000, loss: 0.318572
 >> iter 40000, loss: 0.233822
   Number of active neurons: 6
 >> iter 41000, loss: 0.180954
 >> iter 42000, loss: 0.278970
 >> iter 43000, loss: 0.187595
 >> iter 44000, loss: 0.297939
 >> iter 45000, loss: 0.238154
 >> iter 46000, loss: 0.353436
 >> iter 47000, loss: 0.317989
 >> iter 48000, loss: 0.360538
 >> iter 49000, loss: 0.272284
 >> iter 50000, loss: 0.225560
   Number of active neurons: 5
 >> iter 51000, loss: 0.251823
 >> iter 52000, loss: 0.196332
 >> iter 53000, loss: 0.179924
 >> iter 54000, loss: 0.299100
 >> iter 55000, loss: 0.253841
 >> iter 56000, loss: 0.235337
 >> iter 57000, loss: 0.149910
 >> iter 58000, loss: 0.177632
 >> iter 59000, loss: 0.159029
 >> iter 60000, loss: 0.334122
   Number of active neurons: 5
 >> iter 61000, loss: 0.290730
 >> iter 62000, loss: 0.214233
 >> iter 63000, loss: 0.137847
 >> iter 64000, loss: 0.156365
 >> iter 65000, loss: 0.248044
 >> iter 66000, loss: 0.236425
 >> iter 67000, loss: 0.186826
 >> iter 68000, loss: 0.249195
 >> iter 69000, loss: 0.176639
 >> iter 70000, loss: 0.179617
   Number of active neurons: 5
 >> iter 71000, loss: 0.260786
 >> iter 72000, loss: 0.179725
 >> iter 73000, loss: 0.237543
 >> iter 74000, loss: 0.249152
 >> iter 75000, loss: 0.154147
 >> iter 76000, loss: 0.196722
 >> iter 77000, loss: 0.251411
 >> iter 78000, loss: 0.176619
 >> iter 79000, loss: 0.222405
 >> iter 80000, loss: 0.200030
   Number of active neurons: 5
 >> iter 81000, loss: 0.235827
 >> iter 82000, loss: 0.324175
 >> iter 83000, loss: 0.230080
 >> iter 84000, loss: 0.202706
 >> iter 85000, loss: 0.198381
 >> iter 86000, loss: 0.223460
 >> iter 87000, loss: 0.211785
 >> iter 88000, loss: 0.156745
 >> iter 89000, loss: 0.225653
 >> iter 90000, loss: 0.225279
   Number of active neurons: 4
 >> iter 91000, loss: 0.273884
 >> iter 92000, loss: 0.151915
 >> iter 93000, loss: 0.384745
 >> iter 94000, loss: 0.190912
 >> iter 95000, loss: 0.313705
 >> iter 96000, loss: 0.295373
 >> iter 97000, loss: 0.222827
 >> iter 98000, loss: 0.246425
 >> iter 99000, loss: 0.154226
 >> iter 100000, loss: 0.148640
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 18.968848
 >> iter 2000, loss: 11.272361
 >> iter 3000, loss: 5.581980
 >> iter 4000, loss: 2.665747
 >> iter 5000, loss: 1.612997
 >> iter 6000, loss: 1.058514
 >> iter 7000, loss: 0.701797
 >> iter 8000, loss: 0.602468
 >> iter 9000, loss: 0.532849
 >> iter 10000, loss: 0.603358
   Number of active neurons: 6
 >> iter 11000, loss: 0.352696
 >> iter 12000, loss: 0.445868
 >> iter 13000, loss: 0.567342
 >> iter 14000, loss: 0.393708
 >> iter 15000, loss: 0.516127
 >> iter 16000, loss: 0.531465
 >> iter 17000, loss: 0.484018
 >> iter 18000, loss: 0.472178
 >> iter 19000, loss: 0.352481
 >> iter 20000, loss: 0.494437
   Number of active neurons: 6
 >> iter 21000, loss: 0.510794
 >> iter 22000, loss: 0.502235
 >> iter 23000, loss: 0.441332
 >> iter 24000, loss: 0.249082
 >> iter 25000, loss: 0.376717
 >> iter 26000, loss: 0.490087
 >> iter 27000, loss: 0.434665
 >> iter 28000, loss: 0.325289
 >> iter 29000, loss: 0.304483
 >> iter 30000, loss: 0.321541
   Number of active neurons: 6
 >> iter 31000, loss: 0.472051
 >> iter 32000, loss: 0.510130
 >> iter 33000, loss: 0.352301
 >> iter 34000, loss: 0.380994
 >> iter 35000, loss: 0.316522
 >> iter 36000, loss: 0.315006
 >> iter 37000, loss: 0.554564
 >> iter 38000, loss: 0.466604
 >> iter 39000, loss: 0.421001
 >> iter 40000, loss: 0.387637
   Number of active neurons: 6
 >> iter 41000, loss: 0.655749
 >> iter 42000, loss: 0.478406
 >> iter 43000, loss: 0.476850
 >> iter 44000, loss: 0.336923
 >> iter 45000, loss: 0.380940
 >> iter 46000, loss: 0.372439
 >> iter 47000, loss: 0.367316
 >> iter 48000, loss: 0.500667
 >> iter 49000, loss: 0.561320
 >> iter 50000, loss: 0.370119
   Number of active neurons: 6
 >> iter 51000, loss: 0.372063
 >> iter 52000, loss: 0.403374
 >> iter 53000, loss: 0.403682
 >> iter 54000, loss: 0.497216
 >> iter 55000, loss: 0.353632
 >> iter 56000, loss: 0.277499
 >> iter 57000, loss: 0.316691
 >> iter 58000, loss: 0.402051
 >> iter 59000, loss: 0.529211
 >> iter 60000, loss: 0.379591
   Number of active neurons: 6
 >> iter 61000, loss: 0.416103
 >> iter 62000, loss: 0.408526
 >> iter 63000, loss: 0.361672
 >> iter 64000, loss: 0.369820
 >> iter 65000, loss: 0.404099
 >> iter 66000, loss: 0.291338
 >> iter 67000, loss: 0.333438
 >> iter 68000, loss: 0.405107
 >> iter 69000, loss: 0.426821
 >> iter 70000, loss: 0.373709
   Number of active neurons: 6
 >> iter 71000, loss: 0.499434
 >> iter 72000, loss: 0.412746
 >> iter 73000, loss: 0.380982
 >> iter 74000, loss: 0.290311
 >> iter 75000, loss: 0.456414
 >> iter 76000, loss: 0.484312
 >> iter 77000, loss: 0.334174
 >> iter 78000, loss: 0.329961
 >> iter 79000, loss: 0.351808
 >> iter 80000, loss: 0.371380
   Number of active neurons: 6
 >> iter 81000, loss: 0.420167
 >> iter 82000, loss: 0.392746
 >> iter 83000, loss: 0.384163
 >> iter 84000, loss: 0.323348
 >> iter 85000, loss: 0.478320
 >> iter 86000, loss: 0.362790
 >> iter 87000, loss: 0.294935
 >> iter 88000, loss: 0.361290
 >> iter 89000, loss: 0.375393
 >> iter 90000, loss: 0.392605
   Number of active neurons: 6
 >> iter 91000, loss: 0.279171
 >> iter 92000, loss: 0.292969
 >> iter 93000, loss: 0.408857
 >> iter 94000, loss: 0.419997
 >> iter 95000, loss: 0.424662
 >> iter 96000, loss: 0.357462
 >> iter 97000, loss: 0.269776
 >> iter 98000, loss: 0.351641
 >> iter 99000, loss: 0.302712
 >> iter 100000, loss: 0.329005
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

