 > Problema: tomita3nueva
 > Args:
   - Hidden size: 18
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.004187
 >> iter 2000, loss: 11.177857
 >> iter 3000, loss: 5.709830
 >> iter 4000, loss: 3.045747
 >> iter 5000, loss: 1.849856
 >> iter 6000, loss: 1.248789
 >> iter 7000, loss: 0.873176
 >> iter 8000, loss: 0.662113
 >> iter 9000, loss: 0.525916
 >> iter 10000, loss: 0.624300
   Number of active neurons: 7
 >> iter 11000, loss: 0.559029
 >> iter 12000, loss: 0.562716
 >> iter 13000, loss: 0.575859
 >> iter 14000, loss: 0.520435
 >> iter 15000, loss: 0.545876
 >> iter 16000, loss: 0.689117
 >> iter 17000, loss: 0.567209
 >> iter 18000, loss: 0.480282
 >> iter 19000, loss: 0.396035
 >> iter 20000, loss: 0.594957
   Number of active neurons: 7
 >> iter 21000, loss: 0.590250
 >> iter 22000, loss: 0.495404
 >> iter 23000, loss: 0.667137
 >> iter 24000, loss: 0.476945
 >> iter 25000, loss: 0.487745
 >> iter 26000, loss: 0.645893
 >> iter 27000, loss: 0.658022
 >> iter 28000, loss: 0.354174
 >> iter 29000, loss: 0.560765
 >> iter 30000, loss: 0.588704
   Number of active neurons: 7
 >> iter 31000, loss: 0.648430
 >> iter 32000, loss: 0.526902
 >> iter 33000, loss: 0.447565
 >> iter 34000, loss: 0.434993
 >> iter 35000, loss: 0.557981
 >> iter 36000, loss: 0.579581
 >> iter 37000, loss: 0.572381
 >> iter 38000, loss: 0.493144
 >> iter 39000, loss: 0.687372
 >> iter 40000, loss: 0.468252
   Number of active neurons: 7
 >> iter 41000, loss: 0.550207
 >> iter 42000, loss: 0.396849
 >> iter 43000, loss: 0.478919
 >> iter 44000, loss: 0.501156
 >> iter 45000, loss: 0.750529
 >> iter 46000, loss: 0.478183
 >> iter 47000, loss: 0.355556
 >> iter 48000, loss: 0.281718
 >> iter 49000, loss: 0.437212
 >> iter 50000, loss: 0.398409
   Number of active neurons: 7
 >> iter 51000, loss: 0.499184
 >> iter 52000, loss: 0.626781
 >> iter 53000, loss: 0.673479
 >> iter 54000, loss: 0.721575
 >> iter 55000, loss: 0.570342
 >> iter 56000, loss: 0.522655
 >> iter 57000, loss: 0.573317
 >> iter 58000, loss: 0.623135
 >> iter 59000, loss: 0.401417
 >> iter 60000, loss: 0.370285
   Number of active neurons: 7
 >> iter 61000, loss: 0.370614
 >> iter 62000, loss: 0.494700
 >> iter 63000, loss: 0.475087
 >> iter 64000, loss: 0.627383
 >> iter 65000, loss: 0.555827
 >> iter 66000, loss: 0.475314
 >> iter 67000, loss: 0.339025
 >> iter 68000, loss: 0.655895
 >> iter 69000, loss: 0.413948
 >> iter 70000, loss: 0.462517
   Number of active neurons: 7
 >> iter 71000, loss: 0.369513
 >> iter 72000, loss: 0.279332
 >> iter 73000, loss: 0.369344
 >> iter 74000, loss: 0.351446
 >> iter 75000, loss: 0.471521
 >> iter 76000, loss: 0.442041
 >> iter 77000, loss: 0.444048
 >> iter 78000, loss: 0.397083
 >> iter 79000, loss: 0.375807
 >> iter 80000, loss: 0.355904
   Number of active neurons: 7
 >> iter 81000, loss: 0.423679
 >> iter 82000, loss: 0.362887
 >> iter 83000, loss: 0.327050
 >> iter 84000, loss: 0.312033
 >> iter 85000, loss: 0.297604
 >> iter 86000, loss: 0.259451
 >> iter 87000, loss: 0.374902
 >> iter 88000, loss: 0.306851
 >> iter 89000, loss: 0.271733
 >> iter 90000, loss: 0.310547
   Number of active neurons: 7
 >> iter 91000, loss: 0.341562
 >> iter 92000, loss: 0.482246
 >> iter 93000, loss: 0.505597
 >> iter 94000, loss: 0.400124
 >> iter 95000, loss: 0.242614
 >> iter 96000, loss: 0.292328
 >> iter 97000, loss: 0.334885
 >> iter 98000, loss: 0.411301
 >> iter 99000, loss: 0.498118
 >> iter 100000, loss: 0.359174
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.127345
 >> iter 2000, loss: 11.827657
 >> iter 3000, loss: 5.738865
 >> iter 4000, loss: 2.813575
 >> iter 5000, loss: 1.505433
 >> iter 6000, loss: 0.807461
 >> iter 7000, loss: 0.660348
 >> iter 8000, loss: 0.517748
 >> iter 9000, loss: 0.522889
 >> iter 10000, loss: 0.453658
   Number of active neurons: 8
 >> iter 11000, loss: 0.416807
 >> iter 12000, loss: 0.325639
 >> iter 13000, loss: 0.404019
 >> iter 14000, loss: 0.523415
 >> iter 15000, loss: 0.336301
 >> iter 16000, loss: 0.243477
 >> iter 17000, loss: 0.169854
 >> iter 18000, loss: 0.334328
 >> iter 19000, loss: 0.395307
 >> iter 20000, loss: 0.348493
   Number of active neurons: 8
 >> iter 21000, loss: 0.247650
 >> iter 22000, loss: 0.304801
 >> iter 23000, loss: 0.337550
 >> iter 24000, loss: 0.375908
 >> iter 25000, loss: 0.388132
 >> iter 26000, loss: 0.352107
 >> iter 27000, loss: 0.321217
 >> iter 28000, loss: 0.354048
 >> iter 29000, loss: 0.417847
 >> iter 30000, loss: 0.295582
   Number of active neurons: 8
 >> iter 31000, loss: 0.318922
 >> iter 32000, loss: 0.222612
 >> iter 33000, loss: 0.291171
 >> iter 34000, loss: 0.258239
 >> iter 35000, loss: 0.304633
 >> iter 36000, loss: 0.241214
 >> iter 37000, loss: 0.287419
 >> iter 38000, loss: 0.227386
 >> iter 39000, loss: 0.406977
 >> iter 40000, loss: 0.241946
   Number of active neurons: 8
 >> iter 41000, loss: 0.174727
 >> iter 42000, loss: 0.246206
 >> iter 43000, loss: 0.210181
 >> iter 44000, loss: 0.401438
 >> iter 45000, loss: 0.299819
 >> iter 46000, loss: 0.348112
 >> iter 47000, loss: 0.378729
 >> iter 48000, loss: 0.210423
 >> iter 49000, loss: 0.123908
 >> iter 50000, loss: 0.190855
   Number of active neurons: 7
 >> iter 51000, loss: 0.230633
 >> iter 52000, loss: 0.264566
 >> iter 53000, loss: 0.296553
 >> iter 54000, loss: 0.227682
 >> iter 55000, loss: 0.288885
 >> iter 56000, loss: 0.371250
 >> iter 57000, loss: 0.262347
 >> iter 58000, loss: 0.260159
 >> iter 59000, loss: 0.208973
 >> iter 60000, loss: 0.360428
   Number of active neurons: 6
 >> iter 61000, loss: 0.285008
 >> iter 62000, loss: 0.360433
 >> iter 63000, loss: 0.310718
 >> iter 64000, loss: 0.376664
 >> iter 65000, loss: 0.314490
 >> iter 66000, loss: 0.219430
 >> iter 67000, loss: 0.280336
 >> iter 68000, loss: 0.245541
 >> iter 69000, loss: 0.209165
 >> iter 70000, loss: 0.206873
   Number of active neurons: 6
 >> iter 71000, loss: 0.170608
 >> iter 72000, loss: 0.279334
 >> iter 73000, loss: 0.210044
 >> iter 74000, loss: 0.176857
 >> iter 75000, loss: 0.169098
 >> iter 76000, loss: 0.250062
 >> iter 77000, loss: 0.362853
 >> iter 78000, loss: 0.304544
 >> iter 79000, loss: 0.279777
 >> iter 80000, loss: 0.182975
   Number of active neurons: 6
 >> iter 81000, loss: 0.280800
 >> iter 82000, loss: 0.167487
 >> iter 83000, loss: 0.165793
 >> iter 84000, loss: 0.179186
 >> iter 85000, loss: 0.321063
 >> iter 86000, loss: 0.340284
 >> iter 87000, loss: 0.413908
 >> iter 88000, loss: 0.251202
 >> iter 89000, loss: 0.369770
 >> iter 90000, loss: 0.206025
   Number of active neurons: 6
 >> iter 91000, loss: 0.168163
 >> iter 92000, loss: 0.188531
 >> iter 93000, loss: 0.196763
 >> iter 94000, loss: 0.316574
 >> iter 95000, loss: 0.289526
 >> iter 96000, loss: 0.235214
 >> iter 97000, loss: 0.192542
 >> iter 98000, loss: 0.147482
 >> iter 99000, loss: 0.196924
 >> iter 100000, loss: 0.211475
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.944669
 >> iter 2000, loss: 9.968766
 >> iter 3000, loss: 4.342712
 >> iter 4000, loss: 2.035068
 >> iter 5000, loss: 1.085622
 >> iter 6000, loss: 0.552277
 >> iter 7000, loss: 0.553722
 >> iter 8000, loss: 0.462845
 >> iter 9000, loss: 0.421405
 >> iter 10000, loss: 0.375325
   Number of active neurons: 8
 >> iter 11000, loss: 0.373894
 >> iter 12000, loss: 0.673359
 >> iter 13000, loss: 0.581323
 >> iter 14000, loss: 0.482383
 >> iter 15000, loss: 0.334777
 >> iter 16000, loss: 0.244227
 >> iter 17000, loss: 0.267235
 >> iter 18000, loss: 0.276064
 >> iter 19000, loss: 0.274319
 >> iter 20000, loss: 0.287166
   Number of active neurons: 8
 >> iter 21000, loss: 0.486090
 >> iter 22000, loss: 0.417380
 >> iter 23000, loss: 0.341548
 >> iter 24000, loss: 0.257119
 >> iter 25000, loss: 0.628217
 >> iter 26000, loss: 0.464341
 >> iter 27000, loss: 0.449482
 >> iter 28000, loss: 0.392890
 >> iter 29000, loss: 0.387819
 >> iter 30000, loss: 0.308464
   Number of active neurons: 8
 >> iter 31000, loss: 0.370931
 >> iter 32000, loss: 0.399512
 >> iter 33000, loss: 0.347575
 >> iter 34000, loss: 0.434782
 >> iter 35000, loss: 0.356204
 >> iter 36000, loss: 0.321583
 >> iter 37000, loss: 0.358427
 >> iter 38000, loss: 0.411768
 >> iter 39000, loss: 0.359547
 >> iter 40000, loss: 0.285953
   Number of active neurons: 8
 >> iter 41000, loss: 0.432274
 >> iter 42000, loss: 0.371602
 >> iter 43000, loss: 0.400949
 >> iter 44000, loss: 0.314648
 >> iter 45000, loss: 0.423031
 >> iter 46000, loss: 0.393045
 >> iter 47000, loss: 0.291389
 >> iter 48000, loss: 0.236991
 >> iter 49000, loss: 0.374050
 >> iter 50000, loss: 0.464174
   Number of active neurons: 8
 >> iter 51000, loss: 0.371623
 >> iter 52000, loss: 0.333226
 >> iter 53000, loss: 0.302816
 >> iter 54000, loss: 0.343528
 >> iter 55000, loss: 0.283679
 >> iter 56000, loss: 0.322040
 >> iter 57000, loss: 0.217779
 >> iter 58000, loss: 0.230913
 >> iter 59000, loss: 0.299175
 >> iter 60000, loss: 0.271080
   Number of active neurons: 8
 >> iter 61000, loss: 0.334223
 >> iter 62000, loss: 0.234229
 >> iter 63000, loss: 0.248605
 >> iter 64000, loss: 0.285022
 >> iter 65000, loss: 0.366860
 >> iter 66000, loss: 0.317421
 >> iter 67000, loss: 0.166187
 >> iter 68000, loss: 0.227632
 >> iter 69000, loss: 0.160119
 >> iter 70000, loss: 0.214372
   Number of active neurons: 7
 >> iter 71000, loss: 0.216522
 >> iter 72000, loss: 0.284357
 >> iter 73000, loss: 0.206251
 >> iter 74000, loss: 0.209593
 >> iter 75000, loss: 0.230721
 >> iter 76000, loss: 0.224266
 >> iter 77000, loss: 0.300191
 >> iter 78000, loss: 0.322036
 >> iter 79000, loss: 0.330519
 >> iter 80000, loss: 0.312924
   Number of active neurons: 6
 >> iter 81000, loss: 0.186321
 >> iter 82000, loss: 0.163361
 >> iter 83000, loss: 0.273071
 >> iter 84000, loss: 0.231019
 >> iter 85000, loss: 0.160202
 >> iter 86000, loss: 0.158769
 >> iter 87000, loss: 0.157714
 >> iter 88000, loss: 0.236061
 >> iter 89000, loss: 0.260527
 >> iter 90000, loss: 0.386385
   Number of active neurons: 6
 >> iter 91000, loss: 0.348728
 >> iter 92000, loss: 0.335961
 >> iter 93000, loss: 0.249318
 >> iter 94000, loss: 0.213322
 >> iter 95000, loss: 0.178481
 >> iter 96000, loss: 0.148845
 >> iter 97000, loss: 0.192144
 >> iter 98000, loss: 0.114303
 >> iter 99000, loss: 0.253866
 >> iter 100000, loss: 0.185960
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.119700
 >> iter 2000, loss: 13.441857
 >> iter 3000, loss: 7.390301
 >> iter 4000, loss: 3.543747
 >> iter 5000, loss: 1.731731
 >> iter 6000, loss: 0.883974
 >> iter 7000, loss: 0.592197
 >> iter 8000, loss: 0.443734
 >> iter 9000, loss: 0.430417
 >> iter 10000, loss: 0.385681
   Number of active neurons: 10
 >> iter 11000, loss: 0.452002
 >> iter 12000, loss: 0.354727
 >> iter 13000, loss: 0.572263
 >> iter 14000, loss: 0.329638
 >> iter 15000, loss: 0.273377
 >> iter 16000, loss: 0.224071
 >> iter 17000, loss: 0.319459
 >> iter 18000, loss: 0.391104
 >> iter 19000, loss: 0.327304
 >> iter 20000, loss: 0.311263
   Number of active neurons: 10
 >> iter 21000, loss: 0.338228
 >> iter 22000, loss: 0.236603
 >> iter 23000, loss: 0.252599
 >> iter 24000, loss: 0.158687
 >> iter 25000, loss: 0.313161
 >> iter 26000, loss: 0.390339
 >> iter 27000, loss: 0.224068
 >> iter 28000, loss: 0.402009
 >> iter 29000, loss: 0.528407
 >> iter 30000, loss: 0.361567
   Number of active neurons: 9
 >> iter 31000, loss: 0.371828
 >> iter 32000, loss: 0.253315
 >> iter 33000, loss: 0.554236
 >> iter 34000, loss: 0.479021
 >> iter 35000, loss: 0.329806
 >> iter 36000, loss: 0.319018
 >> iter 37000, loss: 0.210388
 >> iter 38000, loss: 0.304164
 >> iter 39000, loss: 0.420380
 >> iter 40000, loss: 0.356661
   Number of active neurons: 9
 >> iter 41000, loss: 0.359582
 >> iter 42000, loss: 0.218548
 >> iter 43000, loss: 0.191560
 >> iter 44000, loss: 0.446616
 >> iter 45000, loss: 0.286954
 >> iter 46000, loss: 0.325527
 >> iter 47000, loss: 0.459145
 >> iter 48000, loss: 0.246697
 >> iter 49000, loss: 0.340301
 >> iter 50000, loss: 0.236585
   Number of active neurons: 9
 >> iter 51000, loss: 0.201552
 >> iter 52000, loss: 0.277430
 >> iter 53000, loss: 0.244990
 >> iter 54000, loss: 0.184276
 >> iter 55000, loss: 0.217006
 >> iter 56000, loss: 0.329991
 >> iter 57000, loss: 0.296202
 >> iter 58000, loss: 0.226512
 >> iter 59000, loss: 0.199081
 >> iter 60000, loss: 0.281365
   Number of active neurons: 9
 >> iter 61000, loss: 0.204122
 >> iter 62000, loss: 0.308662
 >> iter 63000, loss: 0.231850
 >> iter 64000, loss: 0.332804
 >> iter 65000, loss: 0.453629
 >> iter 66000, loss: 0.308788
 >> iter 67000, loss: 0.229636
 >> iter 68000, loss: 0.329479
 >> iter 69000, loss: 0.281075
 >> iter 70000, loss: 0.296516
   Number of active neurons: 9
 >> iter 71000, loss: 0.353575
 >> iter 72000, loss: 0.261877
 >> iter 73000, loss: 0.233593
 >> iter 74000, loss: 0.249039
 >> iter 75000, loss: 0.185784
 >> iter 76000, loss: 0.184944
 >> iter 77000, loss: 0.313097
 >> iter 78000, loss: 0.231711
 >> iter 79000, loss: 0.425673
 >> iter 80000, loss: 0.307484
   Number of active neurons: 9
 >> iter 81000, loss: 0.246182
 >> iter 82000, loss: 0.275942
 >> iter 83000, loss: 0.447438
 >> iter 84000, loss: 0.343680
 >> iter 85000, loss: 0.173005
 >> iter 86000, loss: 0.158678
 >> iter 87000, loss: 0.472097
 >> iter 88000, loss: 0.291205
 >> iter 89000, loss: 0.193595
 >> iter 90000, loss: 0.179957
   Number of active neurons: 9
 >> iter 91000, loss: 0.283328
 >> iter 92000, loss: 0.453891
 >> iter 93000, loss: 0.257337
 >> iter 94000, loss: 0.347113
 >> iter 95000, loss: 0.274921
 >> iter 96000, loss: 0.321614
 >> iter 97000, loss: 0.302373
 >> iter 98000, loss: 0.197259
 >> iter 99000, loss: 0.226917
 >> iter 100000, loss: 0.269259
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 18.981471
 >> iter 2000, loss: 11.222232
 >> iter 3000, loss: 5.277123
 >> iter 4000, loss: 2.451425
 >> iter 5000, loss: 1.223226
 >> iter 6000, loss: 0.681464
 >> iter 7000, loss: 0.587345
 >> iter 8000, loss: 0.370230
 >> iter 9000, loss: 0.327717
 >> iter 10000, loss: 0.358178
   Number of active neurons: 9
 >> iter 11000, loss: 0.259941
 >> iter 12000, loss: 0.888451
 >> iter 13000, loss: 0.552728
 >> iter 14000, loss: 0.433093
 >> iter 15000, loss: 0.348073
 >> iter 16000, loss: 0.283583
 >> iter 17000, loss: 0.404771
 >> iter 18000, loss: 0.662552
 >> iter 19000, loss: 0.562657
 >> iter 20000, loss: 0.703056
   Number of active neurons: 9
 >> iter 21000, loss: 0.420113
 >> iter 22000, loss: 0.562857
 >> iter 23000, loss: 0.469261
 >> iter 24000, loss: 0.274133
 >> iter 25000, loss: 0.468920
 >> iter 26000, loss: 0.430120
 >> iter 27000, loss: 0.401021
 >> iter 28000, loss: 0.351756
 >> iter 29000, loss: 0.333988
 >> iter 30000, loss: 0.279361
   Number of active neurons: 8
 >> iter 31000, loss: 0.530732
 >> iter 32000, loss: 0.396558
 >> iter 33000, loss: 0.410409
 >> iter 34000, loss: 0.414167
 >> iter 35000, loss: 0.330836
 >> iter 36000, loss: 0.251770
 >> iter 37000, loss: 0.373507
 >> iter 38000, loss: 0.334110
 >> iter 39000, loss: 0.240452
 >> iter 40000, loss: 0.266267
   Number of active neurons: 8
 >> iter 41000, loss: 0.336693
 >> iter 42000, loss: 0.330185
 >> iter 43000, loss: 0.315235
 >> iter 44000, loss: 0.407745
 >> iter 45000, loss: 0.348409
 >> iter 46000, loss: 0.433648
 >> iter 47000, loss: 0.382803
 >> iter 48000, loss: 0.384216
 >> iter 49000, loss: 0.248297
 >> iter 50000, loss: 0.384181
   Number of active neurons: 8
 >> iter 51000, loss: 0.411395
 >> iter 52000, loss: 0.429582
 >> iter 53000, loss: 0.301642
 >> iter 54000, loss: 0.360545
 >> iter 55000, loss: 0.445652
 >> iter 56000, loss: 0.317891
 >> iter 57000, loss: 0.293136
 >> iter 58000, loss: 0.320736
 >> iter 59000, loss: 0.313128
 >> iter 60000, loss: 0.432816
   Number of active neurons: 8
 >> iter 61000, loss: 0.429881
 >> iter 62000, loss: 0.351786
 >> iter 63000, loss: 0.410497
 >> iter 64000, loss: 0.434540
 >> iter 65000, loss: 0.392068
 >> iter 66000, loss: 0.280299
 >> iter 67000, loss: 0.284261
 >> iter 68000, loss: 0.320024
 >> iter 69000, loss: 0.249700
 >> iter 70000, loss: 0.408190
   Number of active neurons: 8
 >> iter 71000, loss: 0.356458
 >> iter 72000, loss: 0.395069
 >> iter 73000, loss: 0.348063
 >> iter 74000, loss: 0.279960
 >> iter 75000, loss: 0.311969
 >> iter 76000, loss: 0.357075
 >> iter 77000, loss: 0.226027
 >> iter 78000, loss: 0.275333
 >> iter 79000, loss: 0.367135
 >> iter 80000, loss: 0.420928
   Number of active neurons: 8
 >> iter 81000, loss: 0.349184
 >> iter 82000, loss: 0.288889
 >> iter 83000, loss: 0.458758
 >> iter 84000, loss: 0.415480
 >> iter 85000, loss: 0.301665
 >> iter 86000, loss: 0.232804
 >> iter 87000, loss: 0.362201
 >> iter 88000, loss: 0.209272
 >> iter 89000, loss: 0.253103
 >> iter 90000, loss: 0.476497
   Number of active neurons: 8
 >> iter 91000, loss: 0.461278
 >> iter 92000, loss: 0.296137
 >> iter 93000, loss: 0.356342
 >> iter 94000, loss: 0.378312
 >> iter 95000, loss: 0.260856
 >> iter 96000, loss: 0.318307
 >> iter 97000, loss: 0.292774
 >> iter 98000, loss: 0.358460
 >> iter 99000, loss: 0.292450
 >> iter 100000, loss: 0.363094
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.063905
 >> iter 2000, loss: 11.526801
 >> iter 3000, loss: 5.144858
 >> iter 4000, loss: 2.282874
 >> iter 5000, loss: 1.133657
 >> iter 6000, loss: 0.659305
 >> iter 7000, loss: 0.577350
 >> iter 8000, loss: 0.491848
 >> iter 9000, loss: 0.345527
 >> iter 10000, loss: 0.266045
   Number of active neurons: 10
 >> iter 11000, loss: 0.284465
 >> iter 12000, loss: 0.305411
 >> iter 13000, loss: 0.237970
 >> iter 14000, loss: 0.237803
 >> iter 15000, loss: 0.311148
 >> iter 16000, loss: 0.389424
 >> iter 17000, loss: 0.297256
 >> iter 18000, loss: 0.260790
 >> iter 19000, loss: 0.231031
 >> iter 20000, loss: 0.241669
   Number of active neurons: 9
 >> iter 21000, loss: 0.294840
 >> iter 22000, loss: 0.187406
 >> iter 23000, loss: 0.377841
 >> iter 24000, loss: 0.326266
 >> iter 25000, loss: 0.216411
 >> iter 26000, loss: 0.194278
 >> iter 27000, loss: 0.262411
 >> iter 28000, loss: 0.278891
 >> iter 29000, loss: 0.221907
 >> iter 30000, loss: 0.325408
   Number of active neurons: 7
 >> iter 31000, loss: 0.230906
 >> iter 32000, loss: 0.193169
 >> iter 33000, loss: 0.319838
 >> iter 34000, loss: 0.237830
 >> iter 35000, loss: 0.210452
 >> iter 36000, loss: 0.282029
 >> iter 37000, loss: 0.284256
 >> iter 38000, loss: 0.263454
 >> iter 39000, loss: 0.264985
 >> iter 40000, loss: 0.271530
   Number of active neurons: 7
 >> iter 41000, loss: 0.243714
 >> iter 42000, loss: 0.203118
 >> iter 43000, loss: 0.237178
 >> iter 44000, loss: 0.192281
 >> iter 45000, loss: 0.254988
 >> iter 46000, loss: 0.358914
 >> iter 47000, loss: 0.330100
 >> iter 48000, loss: 0.231157
 >> iter 49000, loss: 0.155717
 >> iter 50000, loss: 0.136497
   Number of active neurons: 5
 >> iter 51000, loss: 0.236478
 >> iter 52000, loss: 0.297332
 >> iter 53000, loss: 0.228099
 >> iter 54000, loss: 0.163905
 >> iter 55000, loss: 0.172894
 >> iter 56000, loss: 0.133514
 >> iter 57000, loss: 0.189261
 >> iter 58000, loss: 0.151076
 >> iter 59000, loss: 0.208944
 >> iter 60000, loss: 0.173938
   Number of active neurons: 5
 >> iter 61000, loss: 0.181509
 >> iter 62000, loss: 0.243209
 >> iter 63000, loss: 0.219677
 >> iter 64000, loss: 0.368152
 >> iter 65000, loss: 0.305493
 >> iter 66000, loss: 0.254488
 >> iter 67000, loss: 0.252059
 >> iter 68000, loss: 0.290620
 >> iter 69000, loss: 0.201719
 >> iter 70000, loss: 0.157264
   Number of active neurons: 5
 >> iter 71000, loss: 0.205033
 >> iter 72000, loss: 0.193501
 >> iter 73000, loss: 0.239078
 >> iter 74000, loss: 0.249976
 >> iter 75000, loss: 0.282690
 >> iter 76000, loss: 0.224711
 >> iter 77000, loss: 0.186265
 >> iter 78000, loss: 0.286479
 >> iter 79000, loss: 0.217814
 >> iter 80000, loss: 0.124743
   Number of active neurons: 4
 >> iter 81000, loss: 0.222582
 >> iter 82000, loss: 0.195055
 >> iter 83000, loss: 0.145904
 >> iter 84000, loss: 0.115848
 >> iter 85000, loss: 0.194170
 >> iter 86000, loss: 0.167239
 >> iter 87000, loss: 0.116692
 >> iter 88000, loss: 0.205947
 >> iter 89000, loss: 0.235630
 >> iter 90000, loss: 0.236866
   Number of active neurons: 4
 >> iter 91000, loss: 0.375112
 >> iter 92000, loss: 0.239846
 >> iter 93000, loss: 0.178658
 >> iter 94000, loss: 0.133767
 >> iter 95000, loss: 0.213106
 >> iter 96000, loss: 0.336365
 >> iter 97000, loss: 0.234327
 >> iter 98000, loss: 0.168781
 >> iter 99000, loss: 0.197007
 >> iter 100000, loss: 0.173544
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 19.138750
 >> iter 2000, loss: 10.345944
 >> iter 3000, loss: 4.495004
 >> iter 4000, loss: 1.997494
 >> iter 5000, loss: 1.078486
 >> iter 6000, loss: 0.647750
 >> iter 7000, loss: 0.512968
 >> iter 8000, loss: 0.468676
 >> iter 9000, loss: 0.380428
 >> iter 10000, loss: 0.316481
   Number of active neurons: 7
 >> iter 11000, loss: 0.282474
 >> iter 12000, loss: 0.253863
 >> iter 13000, loss: 0.375172
 >> iter 14000, loss: 0.366551
 >> iter 15000, loss: 0.458210
 >> iter 16000, loss: 0.396974
 >> iter 17000, loss: 0.630346
 >> iter 18000, loss: 0.385325
 >> iter 19000, loss: 0.281843
 >> iter 20000, loss: 0.288453
   Number of active neurons: 7
 >> iter 21000, loss: 0.492341
 >> iter 22000, loss: 0.437791
 >> iter 23000, loss: 0.468612
 >> iter 24000, loss: 0.429069
 >> iter 25000, loss: 0.275496
 >> iter 26000, loss: 0.384644
 >> iter 27000, loss: 0.384094
 >> iter 28000, loss: 0.307549
 >> iter 29000, loss: 0.329703
 >> iter 30000, loss: 0.337042
   Number of active neurons: 7
 >> iter 31000, loss: 0.364150
 >> iter 32000, loss: 0.416651
 >> iter 33000, loss: 0.405431
 >> iter 34000, loss: 0.311147
 >> iter 35000, loss: 0.280017
 >> iter 36000, loss: 0.255174
 >> iter 37000, loss: 0.253868
 >> iter 38000, loss: 0.356059
 >> iter 39000, loss: 0.506605
 >> iter 40000, loss: 0.321620
   Number of active neurons: 7
 >> iter 41000, loss: 0.377143
 >> iter 42000, loss: 0.247548
 >> iter 43000, loss: 0.270515
 >> iter 44000, loss: 0.275031
 >> iter 45000, loss: 0.315445
 >> iter 46000, loss: 0.346171
 >> iter 47000, loss: 0.281258
 >> iter 48000, loss: 0.364603
 >> iter 49000, loss: 0.277920
 >> iter 50000, loss: 0.250876
   Number of active neurons: 7
 >> iter 51000, loss: 0.214544
 >> iter 52000, loss: 0.279466
 >> iter 53000, loss: 0.232574
 >> iter 54000, loss: 0.255478
 >> iter 55000, loss: 0.261252
 >> iter 56000, loss: 0.220334
 >> iter 57000, loss: 0.250504
 >> iter 58000, loss: 0.363748
 >> iter 59000, loss: 0.216323
 >> iter 60000, loss: 0.243086
   Number of active neurons: 7
 >> iter 61000, loss: 0.296429
 >> iter 62000, loss: 0.260444
 >> iter 63000, loss: 0.197828
 >> iter 64000, loss: 0.336413
 >> iter 65000, loss: 0.347975
 >> iter 66000, loss: 0.220263
 >> iter 67000, loss: 0.305449
 >> iter 68000, loss: 0.254958
 >> iter 69000, loss: 0.193781
 >> iter 70000, loss: 0.130990
   Number of active neurons: 5
 >> iter 71000, loss: 0.124835
 >> iter 72000, loss: 0.092642
 >> iter 73000, loss: 0.196735
 >> iter 74000, loss: 0.245196
 >> iter 75000, loss: 0.176474
 >> iter 76000, loss: 0.145960
 >> iter 77000, loss: 0.133664
 >> iter 78000, loss: 0.191441
 >> iter 79000, loss: 0.181278
 >> iter 80000, loss: 0.223486
   Number of active neurons: 5
 >> iter 81000, loss: 0.251121
 >> iter 82000, loss: 0.296925
 >> iter 83000, loss: 0.181459
 >> iter 84000, loss: 0.285311
 >> iter 85000, loss: 0.234393
 >> iter 86000, loss: 0.230696
 >> iter 87000, loss: 0.256886
 >> iter 88000, loss: 0.214242
 >> iter 89000, loss: 0.170450
 >> iter 90000, loss: 0.187612
   Number of active neurons: 5
 >> iter 91000, loss: 0.189991
 >> iter 92000, loss: 0.182922
 >> iter 93000, loss: 0.114713
 >> iter 94000, loss: 0.242559
 >> iter 95000, loss: 0.209828
 >> iter 96000, loss: 0.149819
 >> iter 97000, loss: 0.214344
 >> iter 98000, loss: 0.224082
 >> iter 99000, loss: 0.261535
 >> iter 100000, loss: 0.151759
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.914863
 >> iter 2000, loss: 10.734841
 >> iter 3000, loss: 5.619785
 >> iter 4000, loss: 2.922439
 >> iter 5000, loss: 1.493277
 >> iter 6000, loss: 1.071950
 >> iter 7000, loss: 0.878176
 >> iter 8000, loss: 0.623320
 >> iter 9000, loss: 0.547967
 >> iter 10000, loss: 0.616030
   Number of active neurons: 7
 >> iter 11000, loss: 0.451924
 >> iter 12000, loss: 0.254353
 >> iter 13000, loss: 0.799207
 >> iter 14000, loss: 0.659515
 >> iter 15000, loss: 0.550558
 >> iter 16000, loss: 0.496935
 >> iter 17000, loss: 0.521059
 >> iter 18000, loss: 0.464477
 >> iter 19000, loss: 0.359037
 >> iter 20000, loss: 0.468659
   Number of active neurons: 7
 >> iter 21000, loss: 0.708042
 >> iter 22000, loss: 0.506069
 >> iter 23000, loss: 0.376896
 >> iter 24000, loss: 0.622669
 >> iter 25000, loss: 0.542187
 >> iter 26000, loss: 0.361789
 >> iter 27000, loss: 0.281439
 >> iter 28000, loss: 0.430649
 >> iter 29000, loss: 0.516564
 >> iter 30000, loss: 0.523751
   Number of active neurons: 7
 >> iter 31000, loss: 0.473069
 >> iter 32000, loss: 0.396359
 >> iter 33000, loss: 0.413625
 >> iter 34000, loss: 0.415048
 >> iter 35000, loss: 0.369309
 >> iter 36000, loss: 0.386992
 >> iter 37000, loss: 0.598147
 >> iter 38000, loss: 0.635625
 >> iter 39000, loss: 0.600256
 >> iter 40000, loss: 0.555822
   Number of active neurons: 7
 >> iter 41000, loss: 0.496130
 >> iter 42000, loss: 0.453338
 >> iter 43000, loss: 0.354212
 >> iter 44000, loss: 0.416730
 >> iter 45000, loss: 0.483512
 >> iter 46000, loss: 0.380337
 >> iter 47000, loss: 0.275983
 >> iter 48000, loss: 0.309671
 >> iter 49000, loss: 0.274850
 >> iter 50000, loss: 0.320047
   Number of active neurons: 7
 >> iter 51000, loss: 0.531145
 >> iter 52000, loss: 0.318904
 >> iter 53000, loss: 0.331970
 >> iter 54000, loss: 0.565315
 >> iter 55000, loss: 0.455342
 >> iter 56000, loss: 0.423914
 >> iter 57000, loss: 0.232700
 >> iter 58000, loss: 0.290739
 >> iter 59000, loss: 0.453496
 >> iter 60000, loss: 0.363352
   Number of active neurons: 7
 >> iter 61000, loss: 0.342125
 >> iter 62000, loss: 0.358109
 >> iter 63000, loss: 0.371522
 >> iter 64000, loss: 0.523622
 >> iter 65000, loss: 0.456066
 >> iter 66000, loss: 0.256589
 >> iter 67000, loss: 0.311742
 >> iter 68000, loss: 0.403261
 >> iter 69000, loss: 0.439748
 >> iter 70000, loss: 0.317992
   Number of active neurons: 7
 >> iter 71000, loss: 0.659961
 >> iter 72000, loss: 0.466852
 >> iter 73000, loss: 0.437177
 >> iter 74000, loss: 0.318813
 >> iter 75000, loss: 0.451360
 >> iter 76000, loss: 0.466769
 >> iter 77000, loss: 0.485130
 >> iter 78000, loss: 0.306974
 >> iter 79000, loss: 0.436297
 >> iter 80000, loss: 0.410190
   Number of active neurons: 7
 >> iter 81000, loss: 0.488837
 >> iter 82000, loss: 0.450209
 >> iter 83000, loss: 0.286420
 >> iter 84000, loss: 0.315824
 >> iter 85000, loss: 0.332143
 >> iter 86000, loss: 0.482205
 >> iter 87000, loss: 0.434882
 >> iter 88000, loss: 0.398335
 >> iter 89000, loss: 0.488199
 >> iter 90000, loss: 0.421374
   Number of active neurons: 6
 >> iter 91000, loss: 0.354358
 >> iter 92000, loss: 0.351957
 >> iter 93000, loss: 0.306297
 >> iter 94000, loss: 0.446358
 >> iter 95000, loss: 0.340883
 >> iter 96000, loss: 0.340892
 >> iter 97000, loss: 0.365654
 >> iter 98000, loss: 0.422250
 >> iter 99000, loss: 0.323348
 >> iter 100000, loss: 0.388479
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.066770
 >> iter 2000, loss: 12.501309
 >> iter 3000, loss: 6.036540
 >> iter 4000, loss: 2.832627
 >> iter 5000, loss: 1.721781
 >> iter 6000, loss: 0.994033
 >> iter 7000, loss: 0.790507
 >> iter 8000, loss: 0.870970
 >> iter 9000, loss: 0.739853
 >> iter 10000, loss: 0.696019
   Number of active neurons: 9
 >> iter 11000, loss: 0.410575
 >> iter 12000, loss: 0.459036
 >> iter 13000, loss: 0.440265
 >> iter 14000, loss: 0.345801
 >> iter 15000, loss: 0.364008
 >> iter 16000, loss: 0.449696
 >> iter 17000, loss: 0.519311
 >> iter 18000, loss: 0.375515
 >> iter 19000, loss: 0.491877
 >> iter 20000, loss: 0.545715
   Number of active neurons: 9
 >> iter 21000, loss: 0.538632
 >> iter 22000, loss: 0.405613
 >> iter 23000, loss: 0.326027
 >> iter 24000, loss: 0.383023
 >> iter 25000, loss: 0.411559
 >> iter 26000, loss: 0.408034
 >> iter 27000, loss: 0.368999
 >> iter 28000, loss: 0.269711
 >> iter 29000, loss: 0.618485
 >> iter 30000, loss: 0.385496
   Number of active neurons: 8
 >> iter 31000, loss: 0.345082
 >> iter 32000, loss: 0.306543
 >> iter 33000, loss: 0.333179
 >> iter 34000, loss: 0.364736
 >> iter 35000, loss: 0.312994
 >> iter 36000, loss: 0.262587
 >> iter 37000, loss: 0.274326
 >> iter 38000, loss: 0.399002
 >> iter 39000, loss: 0.346939
 >> iter 40000, loss: 0.366335
   Number of active neurons: 8
 >> iter 41000, loss: 0.251572
 >> iter 42000, loss: 0.252082
 >> iter 43000, loss: 0.539610
 >> iter 44000, loss: 0.409604
 >> iter 45000, loss: 0.438575
 >> iter 46000, loss: 0.337097
 >> iter 47000, loss: 0.434944
 >> iter 48000, loss: 0.466511
 >> iter 49000, loss: 0.531443
 >> iter 50000, loss: 0.378488
   Number of active neurons: 8
 >> iter 51000, loss: 0.561817
 >> iter 52000, loss: 0.494066
 >> iter 53000, loss: 0.330959
 >> iter 54000, loss: 0.302658
 >> iter 55000, loss: 0.521569
 >> iter 56000, loss: 0.501266
 >> iter 57000, loss: 0.455280
 >> iter 58000, loss: 0.360149
 >> iter 59000, loss: 0.424432
 >> iter 60000, loss: 0.345126
   Number of active neurons: 8
 >> iter 61000, loss: 0.363055
 >> iter 62000, loss: 0.529148
 >> iter 63000, loss: 0.321816
 >> iter 64000, loss: 0.329238
 >> iter 65000, loss: 0.385874
 >> iter 66000, loss: 0.468373
 >> iter 67000, loss: 0.303205
 >> iter 68000, loss: 0.327449
 >> iter 69000, loss: 0.325120
 >> iter 70000, loss: 0.435761
   Number of active neurons: 8
 >> iter 71000, loss: 0.593636
 >> iter 72000, loss: 0.325347
 >> iter 73000, loss: 0.473446
 >> iter 74000, loss: 0.274053
 >> iter 75000, loss: 0.193222
 >> iter 76000, loss: 0.184474
 >> iter 77000, loss: 0.437339
 >> iter 78000, loss: 0.385992
 >> iter 79000, loss: 0.340469
 >> iter 80000, loss: 0.379622
   Number of active neurons: 8
 >> iter 81000, loss: 0.238980
 >> iter 82000, loss: 0.306309
 >> iter 83000, loss: 0.228466
 >> iter 84000, loss: 0.253803
 >> iter 85000, loss: 0.167695
 >> iter 86000, loss: 0.352020
 >> iter 87000, loss: 0.381762
 >> iter 88000, loss: 0.223892
 >> iter 89000, loss: 0.274927
 >> iter 90000, loss: 0.247038
   Number of active neurons: 8
 >> iter 91000, loss: 0.295962
 >> iter 92000, loss: 0.330576
 >> iter 93000, loss: 0.237384
 >> iter 94000, loss: 0.345360
 >> iter 95000, loss: 0.260357
 >> iter 96000, loss: 0.358227
 >> iter 97000, loss: 0.342347
 >> iter 98000, loss: 0.216693
 >> iter 99000, loss: 0.255098
 >> iter 100000, loss: 0.182590
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.098048
 >> iter 2000, loss: 13.661182
 >> iter 3000, loss: 6.708279
 >> iter 4000, loss: 2.839382
 >> iter 5000, loss: 1.634984
 >> iter 6000, loss: 0.888510
 >> iter 7000, loss: 0.562434
 >> iter 8000, loss: 0.505891
 >> iter 9000, loss: 0.321863
 >> iter 10000, loss: 0.412153
   Number of active neurons: 7
 >> iter 11000, loss: 0.357429
 >> iter 12000, loss: 0.406326
 >> iter 13000, loss: 0.298162
 >> iter 14000, loss: 0.284967
 >> iter 15000, loss: 0.198940
 >> iter 16000, loss: 0.135313
 >> iter 17000, loss: 0.188355
 >> iter 18000, loss: 0.140500
 >> iter 19000, loss: 0.212087
 >> iter 20000, loss: 0.237416
   Number of active neurons: 7
 >> iter 21000, loss: 0.196329
 >> iter 22000, loss: 0.345183
 >> iter 23000, loss: 0.308748
 >> iter 24000, loss: 0.194676
 >> iter 25000, loss: 0.274790
 >> iter 26000, loss: 0.266382
 >> iter 27000, loss: 0.313622
 >> iter 28000, loss: 0.330924
 >> iter 29000, loss: 0.303090
 >> iter 30000, loss: 0.241989
   Number of active neurons: 7
 >> iter 31000, loss: 0.211664
 >> iter 32000, loss: 0.159401
 >> iter 33000, loss: 0.375364
 >> iter 34000, loss: 0.252680
 >> iter 35000, loss: 0.215406
 >> iter 36000, loss: 0.347061
 >> iter 37000, loss: 0.284272
 >> iter 38000, loss: 0.170907
 >> iter 39000, loss: 0.194306
 >> iter 40000, loss: 0.185901
   Number of active neurons: 7
 >> iter 41000, loss: 0.248867
 >> iter 42000, loss: 0.356905
 >> iter 43000, loss: 0.212020
 >> iter 44000, loss: 0.152314
 >> iter 45000, loss: 0.288952
 >> iter 46000, loss: 0.253320
 >> iter 47000, loss: 0.151700
 >> iter 48000, loss: 0.202001
 >> iter 49000, loss: 0.130291
 >> iter 50000, loss: 0.105405
   Number of active neurons: 7
 >> iter 51000, loss: 0.128524
 >> iter 52000, loss: 0.275480
 >> iter 53000, loss: 0.228989
 >> iter 54000, loss: 0.262715
 >> iter 55000, loss: 0.307437
 >> iter 56000, loss: 0.197363
 >> iter 57000, loss: 0.155656
 >> iter 58000, loss: 0.163380
 >> iter 59000, loss: 0.190578
 >> iter 60000, loss: 0.178243
   Number of active neurons: 7
 >> iter 61000, loss: 0.180322
 >> iter 62000, loss: 0.139844
 >> iter 63000, loss: 0.328344
 >> iter 64000, loss: 0.248081
 >> iter 65000, loss: 0.404137
 >> iter 66000, loss: 0.243051
 >> iter 67000, loss: 0.180227
 >> iter 68000, loss: 0.130264
 >> iter 69000, loss: 0.173527
 >> iter 70000, loss: 0.229679
   Number of active neurons: 7
 >> iter 71000, loss: 0.240391
 >> iter 72000, loss: 0.221859
 >> iter 73000, loss: 0.195409
 >> iter 74000, loss: 0.178948
 >> iter 75000, loss: 0.189764
 >> iter 76000, loss: 0.166912
 >> iter 77000, loss: 0.156281
 >> iter 78000, loss: 0.234303
 >> iter 79000, loss: 0.414310
 >> iter 80000, loss: 0.253606
   Number of active neurons: 6
 >> iter 81000, loss: 0.237762
 >> iter 82000, loss: 0.263363
 >> iter 83000, loss: 0.249229
 >> iter 84000, loss: 0.223048
 >> iter 85000, loss: 0.225988
 >> iter 86000, loss: 0.168478
 >> iter 87000, loss: 0.183490
 >> iter 88000, loss: 0.153851
 >> iter 89000, loss: 0.124175
 >> iter 90000, loss: 0.223862
   Number of active neurons: 6
 >> iter 91000, loss: 0.323556
 >> iter 92000, loss: 0.179121
 >> iter 93000, loss: 0.285522
 >> iter 94000, loss: 0.220026
 >> iter 95000, loss: 0.304512
 >> iter 96000, loss: 0.179682
 >> iter 97000, loss: 0.183565
 >> iter 98000, loss: 0.134664
 >> iter 99000, loss: 0.169251
 >> iter 100000, loss: 0.322900
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.299249
 >> iter 2000, loss: 12.578269
 >> iter 3000, loss: 6.059786
 >> iter 4000, loss: 2.482950
 >> iter 5000, loss: 1.508367
 >> iter 6000, loss: 0.741722
 >> iter 7000, loss: 0.381060
 >> iter 8000, loss: 0.299756
 >> iter 9000, loss: 0.372350
 >> iter 10000, loss: 0.405278
   Number of active neurons: 12
 >> iter 11000, loss: 0.241956
 >> iter 12000, loss: 0.212062
 >> iter 13000, loss: 0.313171
 >> iter 14000, loss: 0.357009
 >> iter 15000, loss: 0.282877
 >> iter 16000, loss: 0.567299
 >> iter 17000, loss: 0.382719
 >> iter 18000, loss: 0.243596
 >> iter 19000, loss: 0.277502
 >> iter 20000, loss: 0.249122
   Number of active neurons: 10
 >> iter 21000, loss: 0.447291
 >> iter 22000, loss: 0.311551
 >> iter 23000, loss: 0.244375
 >> iter 24000, loss: 0.435393
 >> iter 25000, loss: 0.402960
 >> iter 26000, loss: 0.318602
 >> iter 27000, loss: 0.241681
 >> iter 28000, loss: 0.226403
 >> iter 29000, loss: 0.251392
 >> iter 30000, loss: 0.207939
   Number of active neurons: 10
 >> iter 31000, loss: 0.253583
 >> iter 32000, loss: 0.307240
 >> iter 33000, loss: 0.291763
 >> iter 34000, loss: 0.181321
 >> iter 35000, loss: 0.215891
 >> iter 36000, loss: 0.266902
 >> iter 37000, loss: 0.229741
 >> iter 38000, loss: 0.411940
 >> iter 39000, loss: 0.319737
 >> iter 40000, loss: 0.432696
   Number of active neurons: 10
 >> iter 41000, loss: 0.335917
 >> iter 42000, loss: 0.346304
 >> iter 43000, loss: 0.439031
 >> iter 44000, loss: 0.332224
 >> iter 45000, loss: 0.213011
 >> iter 46000, loss: 0.326856
 >> iter 47000, loss: 0.320554
 >> iter 48000, loss: 0.311883
 >> iter 49000, loss: 0.293497
 >> iter 50000, loss: 0.346948
   Number of active neurons: 10
 >> iter 51000, loss: 0.280158
 >> iter 52000, loss: 0.268263
 >> iter 53000, loss: 0.259384
 >> iter 54000, loss: 0.315905
 >> iter 55000, loss: 0.197385
 >> iter 56000, loss: 0.275312
 >> iter 57000, loss: 0.263499
 >> iter 58000, loss: 0.312319
 >> iter 59000, loss: 0.434509
 >> iter 60000, loss: 0.211158
   Number of active neurons: 10
 >> iter 61000, loss: 0.360340
 >> iter 62000, loss: 0.222067
 >> iter 63000, loss: 0.267083
 >> iter 64000, loss: 0.259733
 >> iter 65000, loss: 0.248320
 >> iter 66000, loss: 0.201987
 >> iter 67000, loss: 0.210832
 >> iter 68000, loss: 0.193503
 >> iter 69000, loss: 0.247231
 >> iter 70000, loss: 0.232554
   Number of active neurons: 9
 >> iter 71000, loss: 0.217874
 >> iter 72000, loss: 0.227902
 >> iter 73000, loss: 0.279786
 >> iter 74000, loss: 0.274526
 >> iter 75000, loss: 0.207844
 >> iter 76000, loss: 0.390822
 >> iter 77000, loss: 0.295831
 >> iter 78000, loss: 0.280932
 >> iter 79000, loss: 0.295373
 >> iter 80000, loss: 0.207808
   Number of active neurons: 9
 >> iter 81000, loss: 0.224659
 >> iter 82000, loss: 0.291805
 >> iter 83000, loss: 0.349283
 >> iter 84000, loss: 0.228448
 >> iter 85000, loss: 0.486988
 >> iter 86000, loss: 0.309049
 >> iter 87000, loss: 0.248314
 >> iter 88000, loss: 0.257561
 >> iter 89000, loss: 0.154083
 >> iter 90000, loss: 0.170362
   Number of active neurons: 9
 >> iter 91000, loss: 0.291358
 >> iter 92000, loss: 0.354894
 >> iter 93000, loss: 0.254534
 >> iter 94000, loss: 0.228279
 >> iter 95000, loss: 0.265458
 >> iter 96000, loss: 0.163509
 >> iter 97000, loss: 0.198242
 >> iter 98000, loss: 0.223684
 >> iter 99000, loss: 0.234075
 >> iter 100000, loss: 0.279527
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.158113
 >> iter 2000, loss: 11.362818
 >> iter 3000, loss: 4.850909
 >> iter 4000, loss: 2.115852
 >> iter 5000, loss: 1.004213
 >> iter 6000, loss: 0.592466
 >> iter 7000, loss: 0.680291
 >> iter 8000, loss: 0.417255
 >> iter 9000, loss: 0.463994
 >> iter 10000, loss: 0.256103
   Number of active neurons: 10
 >> iter 11000, loss: 0.268121
 >> iter 12000, loss: 0.200417
 >> iter 13000, loss: 0.189214
 >> iter 14000, loss: 0.270235
 >> iter 15000, loss: 0.379904
 >> iter 16000, loss: 0.273784
 >> iter 17000, loss: 0.224939
 >> iter 18000, loss: 0.400549
 >> iter 19000, loss: 0.256881
 >> iter 20000, loss: 0.350952
   Number of active neurons: 8
 >> iter 21000, loss: 0.361464
 >> iter 22000, loss: 0.335505
 >> iter 23000, loss: 0.286739
 >> iter 24000, loss: 0.178305
 >> iter 25000, loss: 0.279840
 >> iter 26000, loss: 0.272780
 >> iter 27000, loss: 0.313996
 >> iter 28000, loss: 0.372404
 >> iter 29000, loss: 0.217865
 >> iter 30000, loss: 0.288960
   Number of active neurons: 8
 >> iter 31000, loss: 0.284092
 >> iter 32000, loss: 0.251109
 >> iter 33000, loss: 0.323349
 >> iter 34000, loss: 0.493840
 >> iter 35000, loss: 0.281679
 >> iter 36000, loss: 0.194081
 >> iter 37000, loss: 0.275735
 >> iter 38000, loss: 0.164171
 >> iter 39000, loss: 0.214675
 >> iter 40000, loss: 0.400519
   Number of active neurons: 7
 >> iter 41000, loss: 0.216371
 >> iter 42000, loss: 0.307943
 >> iter 43000, loss: 0.226893
 >> iter 44000, loss: 0.179046
 >> iter 45000, loss: 0.237114
 >> iter 46000, loss: 0.174411
 >> iter 47000, loss: 0.214896
 >> iter 48000, loss: 0.165158
 >> iter 49000, loss: 0.271057
 >> iter 50000, loss: 0.209153
   Number of active neurons: 6
 >> iter 51000, loss: 0.291920
 >> iter 52000, loss: 0.231432
 >> iter 53000, loss: 0.353333
 >> iter 54000, loss: 0.336958
 >> iter 55000, loss: 0.215568
 >> iter 56000, loss: 0.254224
 >> iter 57000, loss: 0.264211
 >> iter 58000, loss: 0.320333
 >> iter 59000, loss: 0.377901
 >> iter 60000, loss: 0.350584
   Number of active neurons: 6
 >> iter 61000, loss: 0.211049
 >> iter 62000, loss: 0.392659
 >> iter 63000, loss: 0.334317
 >> iter 64000, loss: 0.176973
 >> iter 65000, loss: 0.269853
 >> iter 66000, loss: 0.267381
 >> iter 67000, loss: 0.160159
 >> iter 68000, loss: 0.181963
 >> iter 69000, loss: 0.143514
 >> iter 70000, loss: 0.169481
   Number of active neurons: 6
 >> iter 71000, loss: 0.219958
 >> iter 72000, loss: 0.486709
 >> iter 73000, loss: 0.295235
 >> iter 74000, loss: 0.224339
 >> iter 75000, loss: 0.206720
 >> iter 76000, loss: 0.370024
 >> iter 77000, loss: 0.290203
 >> iter 78000, loss: 0.211127
 >> iter 79000, loss: 0.226827
 >> iter 80000, loss: 0.215016
   Number of active neurons: 6
 >> iter 81000, loss: 0.209902
 >> iter 82000, loss: 0.159491
 >> iter 83000, loss: 0.194142
 >> iter 84000, loss: 0.222758
 >> iter 85000, loss: 0.132343
 >> iter 86000, loss: 0.276006
 >> iter 87000, loss: 0.291298
 >> iter 88000, loss: 0.535846
 >> iter 89000, loss: 0.316451
 >> iter 90000, loss: 0.212862
   Number of active neurons: 6
 >> iter 91000, loss: 0.232250
 >> iter 92000, loss: 0.341522
 >> iter 93000, loss: 0.319628
 >> iter 94000, loss: 0.193693
 >> iter 95000, loss: 0.352182
 >> iter 96000, loss: 0.198797
 >> iter 97000, loss: 0.193345
 >> iter 98000, loss: 0.159137
 >> iter 99000, loss: 0.285412
 >> iter 100000, loss: 0.216584
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.005694
 >> iter 2000, loss: 10.334499
 >> iter 3000, loss: 4.783637
 >> iter 4000, loss: 2.140546
 >> iter 5000, loss: 1.237041
 >> iter 6000, loss: 0.867577
 >> iter 7000, loss: 0.518581
 >> iter 8000, loss: 0.462260
 >> iter 9000, loss: 0.616487
 >> iter 10000, loss: 0.532145
   Number of active neurons: 9
 >> iter 11000, loss: 0.302969
 >> iter 12000, loss: 0.318039
 >> iter 13000, loss: 0.480498
 >> iter 14000, loss: 0.333985
 >> iter 15000, loss: 0.219818
 >> iter 16000, loss: 0.379969
 >> iter 17000, loss: 0.417483
 >> iter 18000, loss: 0.361840
 >> iter 19000, loss: 0.416059
 >> iter 20000, loss: 0.365123
   Number of active neurons: 8
 >> iter 21000, loss: 0.411770
 >> iter 22000, loss: 0.355932
 >> iter 23000, loss: 0.365557
 >> iter 24000, loss: 0.386087
 >> iter 25000, loss: 0.503018
 >> iter 26000, loss: 0.356968
 >> iter 27000, loss: 0.301143
 >> iter 28000, loss: 0.483390
 >> iter 29000, loss: 0.356649
 >> iter 30000, loss: 0.278909
   Number of active neurons: 8
 >> iter 31000, loss: 0.333738
 >> iter 32000, loss: 0.286591
 >> iter 33000, loss: 0.361288
 >> iter 34000, loss: 0.366968
 >> iter 35000, loss: 0.240570
 >> iter 36000, loss: 0.289955
 >> iter 37000, loss: 0.262698
 >> iter 38000, loss: 0.298358
 >> iter 39000, loss: 0.504475
 >> iter 40000, loss: 0.392521
   Number of active neurons: 8
 >> iter 41000, loss: 0.407696
 >> iter 42000, loss: 0.313194
 >> iter 43000, loss: 0.315696
 >> iter 44000, loss: 0.286333
 >> iter 45000, loss: 0.384941
 >> iter 46000, loss: 0.337482
 >> iter 47000, loss: 0.386955
 >> iter 48000, loss: 0.327847
 >> iter 49000, loss: 0.283518
 >> iter 50000, loss: 0.298462
   Number of active neurons: 7
 >> iter 51000, loss: 0.531627
 >> iter 52000, loss: 0.393885
 >> iter 53000, loss: 0.339765
 >> iter 54000, loss: 0.321305
 >> iter 55000, loss: 0.531467
 >> iter 56000, loss: 0.503026
 >> iter 57000, loss: 0.292288
 >> iter 58000, loss: 0.305729
 >> iter 59000, loss: 0.303740
 >> iter 60000, loss: 0.243430
   Number of active neurons: 7
 >> iter 61000, loss: 0.239396
 >> iter 62000, loss: 0.379374
 >> iter 63000, loss: 0.293846
 >> iter 64000, loss: 0.269113
 >> iter 65000, loss: 0.188038
 >> iter 66000, loss: 0.372550
 >> iter 67000, loss: 0.298417
 >> iter 68000, loss: 0.287396
 >> iter 69000, loss: 0.396011
 >> iter 70000, loss: 0.419811
   Number of active neurons: 7
 >> iter 71000, loss: 0.286417
 >> iter 72000, loss: 0.282382
 >> iter 73000, loss: 0.277446
 >> iter 74000, loss: 0.185476
 >> iter 75000, loss: 0.233473
 >> iter 76000, loss: 0.208251
 >> iter 77000, loss: 0.313840
 >> iter 78000, loss: 0.310803
 >> iter 79000, loss: 0.350992
 >> iter 80000, loss: 0.319017
   Number of active neurons: 6
 >> iter 81000, loss: 0.226134
 >> iter 82000, loss: 0.194375
 >> iter 83000, loss: 0.321265
 >> iter 84000, loss: 0.187387
 >> iter 85000, loss: 0.297795
 >> iter 86000, loss: 0.308997
 >> iter 87000, loss: 0.213367
 >> iter 88000, loss: 0.197815
 >> iter 89000, loss: 0.275829
 >> iter 90000, loss: 0.244433
   Number of active neurons: 6
 >> iter 91000, loss: 0.266774
 >> iter 92000, loss: 0.253672
 >> iter 93000, loss: 0.185284
 >> iter 94000, loss: 0.199863
 >> iter 95000, loss: 0.281520
 >> iter 96000, loss: 0.174002
 >> iter 97000, loss: 0.257314
 >> iter 98000, loss: 0.278524
 >> iter 99000, loss: 0.292311
 >> iter 100000, loss: 0.280278
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.164124
 >> iter 2000, loss: 10.986378
 >> iter 3000, loss: 4.671199
 >> iter 4000, loss: 2.026783
 >> iter 5000, loss: 1.140954
 >> iter 6000, loss: 0.613711
 >> iter 7000, loss: 0.607839
 >> iter 8000, loss: 0.378940
 >> iter 9000, loss: 0.297278
 >> iter 10000, loss: 0.436039
   Number of active neurons: 11
 >> iter 11000, loss: 0.341368
 >> iter 12000, loss: 0.347643
 >> iter 13000, loss: 0.245068
 >> iter 14000, loss: 0.226684
 >> iter 15000, loss: 0.191513
 >> iter 16000, loss: 0.239046
 >> iter 17000, loss: 0.264832
 >> iter 18000, loss: 0.396040
 >> iter 19000, loss: 0.473275
 >> iter 20000, loss: 0.276542
   Number of active neurons: 9
 >> iter 21000, loss: 0.222501
 >> iter 22000, loss: 0.202612
 >> iter 23000, loss: 0.331619
 >> iter 24000, loss: 0.243206
 >> iter 25000, loss: 0.214789
 >> iter 26000, loss: 0.238954
 >> iter 27000, loss: 0.282592
 >> iter 28000, loss: 0.292215
 >> iter 29000, loss: 0.217364
 >> iter 30000, loss: 0.191471
   Number of active neurons: 8
 >> iter 31000, loss: 0.322822
 >> iter 32000, loss: 0.252509
 >> iter 33000, loss: 0.252185
 >> iter 34000, loss: 0.205873
 >> iter 35000, loss: 0.320194
 >> iter 36000, loss: 0.394236
 >> iter 37000, loss: 0.375536
 >> iter 38000, loss: 0.220581
 >> iter 39000, loss: 0.169992
 >> iter 40000, loss: 0.155165
   Number of active neurons: 6
 >> iter 41000, loss: 0.233514
 >> iter 42000, loss: 0.230917
 >> iter 43000, loss: 0.225645
 >> iter 44000, loss: 0.288717
 >> iter 45000, loss: 0.221236
 >> iter 46000, loss: 0.378718
 >> iter 47000, loss: 0.262817
 >> iter 48000, loss: 0.170214
 >> iter 49000, loss: 0.123654
 >> iter 50000, loss: 0.251896
   Number of active neurons: 6
 >> iter 51000, loss: 0.219255
 >> iter 52000, loss: 0.235078
 >> iter 53000, loss: 0.306338
 >> iter 54000, loss: 0.266439
 >> iter 55000, loss: 0.355632
 >> iter 56000, loss: 0.379038
 >> iter 57000, loss: 0.222727
 >> iter 58000, loss: 0.275931
 >> iter 59000, loss: 0.363170
 >> iter 60000, loss: 0.236484
   Number of active neurons: 6
 >> iter 61000, loss: 0.212452
 >> iter 62000, loss: 0.360091
 >> iter 63000, loss: 0.231522
 >> iter 64000, loss: 0.385561
 >> iter 65000, loss: 0.243411
 >> iter 66000, loss: 0.150215
 >> iter 67000, loss: 0.152081
 >> iter 68000, loss: 0.109708
 >> iter 69000, loss: 0.087237
 >> iter 70000, loss: 0.138960
   Number of active neurons: 6
 >> iter 71000, loss: 0.248239
 >> iter 72000, loss: 0.188855
 >> iter 73000, loss: 0.152902
 >> iter 74000, loss: 0.169535
 >> iter 75000, loss: 0.340787
 >> iter 76000, loss: 0.305210
 >> iter 77000, loss: 0.258978
 >> iter 78000, loss: 0.213726
 >> iter 79000, loss: 0.126199
 >> iter 80000, loss: 0.160244
   Number of active neurons: 6
 >> iter 81000, loss: 0.180845
 >> iter 82000, loss: 0.155252
 >> iter 83000, loss: 0.209856
 >> iter 84000, loss: 0.255142
 >> iter 85000, loss: 0.222190
 >> iter 86000, loss: 0.158012
 >> iter 87000, loss: 0.128484
 >> iter 88000, loss: 0.176865
 >> iter 89000, loss: 0.341693
 >> iter 90000, loss: 0.215663
   Number of active neurons: 6
 >> iter 91000, loss: 0.151230
 >> iter 92000, loss: 0.286820
 >> iter 93000, loss: 0.196182
 >> iter 94000, loss: 0.259381
 >> iter 95000, loss: 0.218263
 >> iter 96000, loss: 0.196953
 >> iter 97000, loss: 0.147254
 >> iter 98000, loss: 0.307426
 >> iter 99000, loss: 0.271955
 >> iter 100000, loss: 0.328240
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.197046
 >> iter 2000, loss: 14.651803
 >> iter 3000, loss: 12.055268
 >> iter 4000, loss: 8.663151
 >> iter 5000, loss: 6.282235
 >> iter 6000, loss: 4.188459
 >> iter 7000, loss: 3.162668
 >> iter 8000, loss: 1.745151
 >> iter 9000, loss: 0.985318
 >> iter 10000, loss: 0.784184
   Number of active neurons: 12
 >> iter 11000, loss: 0.733361
 >> iter 12000, loss: 0.675396
 >> iter 13000, loss: 0.497728
 >> iter 14000, loss: 0.411542
 >> iter 15000, loss: 0.420556
 >> iter 16000, loss: 0.510923
 >> iter 17000, loss: 0.498842
 >> iter 18000, loss: 0.495552
 >> iter 19000, loss: 0.472637
 >> iter 20000, loss: 0.450708
   Number of active neurons: 12
 >> iter 21000, loss: 0.344849
 >> iter 22000, loss: 0.290216
 >> iter 23000, loss: 0.343972
 >> iter 24000, loss: 0.532265
 >> iter 25000, loss: 0.441513
 >> iter 26000, loss: 0.362362
 >> iter 27000, loss: 0.647749
 >> iter 28000, loss: 0.518323
 >> iter 29000, loss: 0.487943
 >> iter 30000, loss: 0.434806
   Number of active neurons: 12
 >> iter 31000, loss: 0.477614
 >> iter 32000, loss: 0.437340
 >> iter 33000, loss: 0.366419
 >> iter 34000, loss: 0.434862
 >> iter 35000, loss: 0.418928
 >> iter 36000, loss: 0.331702
 >> iter 37000, loss: 0.568544
 >> iter 38000, loss: 0.475997
 >> iter 39000, loss: 0.418404
 >> iter 40000, loss: 0.337417
   Number of active neurons: 10
 >> iter 41000, loss: 0.432915
 >> iter 42000, loss: 0.355204
 >> iter 43000, loss: 0.441212
 >> iter 44000, loss: 0.391938
 >> iter 45000, loss: 0.453770
 >> iter 46000, loss: 0.294589
 >> iter 47000, loss: 0.417575
 >> iter 48000, loss: 0.366461
 >> iter 49000, loss: 0.412303
 >> iter 50000, loss: 0.499376
   Number of active neurons: 9
 >> iter 51000, loss: 0.350502
 >> iter 52000, loss: 0.359606
 >> iter 53000, loss: 0.291464
 >> iter 54000, loss: 0.294976
 >> iter 55000, loss: 0.440246
 >> iter 56000, loss: 0.356004
 >> iter 57000, loss: 0.453277
 >> iter 58000, loss: 0.392910
 >> iter 59000, loss: 0.417947
 >> iter 60000, loss: 0.472085
   Number of active neurons: 8
 >> iter 61000, loss: 0.594893
 >> iter 62000, loss: 0.370134
 >> iter 63000, loss: 0.389916
 >> iter 64000, loss: 0.348504
 >> iter 65000, loss: 0.563714
 >> iter 66000, loss: 0.314173
 >> iter 67000, loss: 0.332280
 >> iter 68000, loss: 0.349973
 >> iter 69000, loss: 0.392541
 >> iter 70000, loss: 0.404174
   Number of active neurons: 8
 >> iter 71000, loss: 0.256011
 >> iter 72000, loss: 0.371498
 >> iter 73000, loss: 0.241904
 >> iter 74000, loss: 0.314056
 >> iter 75000, loss: 0.352876
 >> iter 76000, loss: 0.418600
 >> iter 77000, loss: 0.405828
 >> iter 78000, loss: 0.308504
 >> iter 79000, loss: 0.326053
 >> iter 80000, loss: 0.361812
   Number of active neurons: 8
 >> iter 81000, loss: 0.495300
 >> iter 82000, loss: 0.589208
 >> iter 83000, loss: 0.640951
 >> iter 84000, loss: 0.454686
 >> iter 85000, loss: 0.344971
 >> iter 86000, loss: 0.257083
 >> iter 87000, loss: 0.224750
 >> iter 88000, loss: 0.273145
 >> iter 89000, loss: 0.358575
 >> iter 90000, loss: 0.336271
   Number of active neurons: 7
 >> iter 91000, loss: 0.276041
 >> iter 92000, loss: 0.226581
 >> iter 93000, loss: 0.340875
 >> iter 94000, loss: 0.302771
 >> iter 95000, loss: 0.304081
 >> iter 96000, loss: 0.376736
 >> iter 97000, loss: 0.324650
 >> iter 98000, loss: 0.217894
 >> iter 99000, loss: 0.152951
 >> iter 100000, loss: 0.109055
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.083405
 >> iter 2000, loss: 11.218653
 >> iter 3000, loss: 4.992605
 >> iter 4000, loss: 2.065925
 >> iter 5000, loss: 1.068196
 >> iter 6000, loss: 0.556218
 >> iter 7000, loss: 0.432055
 >> iter 8000, loss: 0.230307
 >> iter 9000, loss: 0.323459
 >> iter 10000, loss: 0.274841
   Number of active neurons: 10
 >> iter 11000, loss: 0.238840
 >> iter 12000, loss: 0.224383
 >> iter 13000, loss: 0.288890
 >> iter 14000, loss: 0.171439
 >> iter 15000, loss: 0.316146
 >> iter 16000, loss: 0.394459
 >> iter 17000, loss: 0.324466
 >> iter 18000, loss: 0.391755
 >> iter 19000, loss: 0.340214
 >> iter 20000, loss: 0.220424
   Number of active neurons: 8
 >> iter 21000, loss: 0.227854
 >> iter 22000, loss: 0.213651
 >> iter 23000, loss: 0.427269
 >> iter 24000, loss: 0.375756
 >> iter 25000, loss: 0.213051
 >> iter 26000, loss: 0.147228
 >> iter 27000, loss: 0.243387
 >> iter 28000, loss: 0.242724
 >> iter 29000, loss: 0.353504
 >> iter 30000, loss: 0.314521
   Number of active neurons: 6
 >> iter 31000, loss: 0.292839
 >> iter 32000, loss: 0.179675
 >> iter 33000, loss: 0.178980
 >> iter 34000, loss: 0.123369
 >> iter 35000, loss: 0.205340
 >> iter 36000, loss: 0.180659
 >> iter 37000, loss: 0.215913
 >> iter 38000, loss: 0.145715
 >> iter 39000, loss: 0.201541
 >> iter 40000, loss: 0.201067
   Number of active neurons: 6
 >> iter 41000, loss: 0.228650
 >> iter 42000, loss: 0.225253
 >> iter 43000, loss: 0.243178
 >> iter 44000, loss: 0.224448
 >> iter 45000, loss: 0.322616
 >> iter 46000, loss: 0.183395
 >> iter 47000, loss: 0.357727
 >> iter 48000, loss: 0.220253
 >> iter 49000, loss: 0.276002
 >> iter 50000, loss: 0.221734
   Number of active neurons: 6
 >> iter 51000, loss: 0.229145
 >> iter 52000, loss: 0.239085
 >> iter 53000, loss: 0.185356
 >> iter 54000, loss: 0.268837
 >> iter 55000, loss: 0.195240
 >> iter 56000, loss: 0.261332
 >> iter 57000, loss: 0.241673
 >> iter 58000, loss: 0.199634
 >> iter 59000, loss: 0.208470
 >> iter 60000, loss: 0.204147
   Number of active neurons: 6
 >> iter 61000, loss: 0.449362
 >> iter 62000, loss: 0.332975
 >> iter 63000, loss: 0.231477
 >> iter 64000, loss: 0.231565
 >> iter 65000, loss: 0.144756
 >> iter 66000, loss: 0.155754
 >> iter 67000, loss: 0.205942
 >> iter 68000, loss: 0.244954
 >> iter 69000, loss: 0.182547
 >> iter 70000, loss: 0.328017
   Number of active neurons: 6
 >> iter 71000, loss: 0.217617
 >> iter 72000, loss: 0.176701
 >> iter 73000, loss: 0.425023
 >> iter 74000, loss: 0.328856
 >> iter 75000, loss: 0.261014
 >> iter 76000, loss: 0.351725
 >> iter 77000, loss: 0.198687
 >> iter 78000, loss: 0.222567
 >> iter 79000, loss: 0.149889
 >> iter 80000, loss: 0.258572
   Number of active neurons: 5
 >> iter 81000, loss: 0.227288
 >> iter 82000, loss: 0.247981
 >> iter 83000, loss: 0.320811
 >> iter 84000, loss: 0.237606
 >> iter 85000, loss: 0.222235
 >> iter 86000, loss: 0.257160
 >> iter 87000, loss: 0.208947
 >> iter 88000, loss: 0.160486
 >> iter 89000, loss: 0.234758
 >> iter 90000, loss: 0.200247
   Number of active neurons: 5
 >> iter 91000, loss: 0.196892
 >> iter 92000, loss: 0.289253
 >> iter 93000, loss: 0.194270
 >> iter 94000, loss: 0.198811
 >> iter 95000, loss: 0.229182
 >> iter 96000, loss: 0.247453
 >> iter 97000, loss: 0.255819
 >> iter 98000, loss: 0.207756
 >> iter 99000, loss: 0.202474
 >> iter 100000, loss: 0.189455
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.192637
 >> iter 2000, loss: 10.969985
 >> iter 3000, loss: 4.900409
 >> iter 4000, loss: 2.067490
 >> iter 5000, loss: 0.982352
 >> iter 6000, loss: 0.689456
 >> iter 7000, loss: 0.516172
 >> iter 8000, loss: 0.345837
 >> iter 9000, loss: 0.252701
 >> iter 10000, loss: 0.432564
   Number of active neurons: 10
 >> iter 11000, loss: 0.401822
 >> iter 12000, loss: 0.261296
 >> iter 13000, loss: 0.287917
 >> iter 14000, loss: 0.237870
 >> iter 15000, loss: 0.500291
 >> iter 16000, loss: 0.379786
 >> iter 17000, loss: 0.407827
 >> iter 18000, loss: 0.362904
 >> iter 19000, loss: 0.362253
 >> iter 20000, loss: 0.288498
   Number of active neurons: 8
 >> iter 21000, loss: 0.380250
 >> iter 22000, loss: 0.308543
 >> iter 23000, loss: 0.322669
 >> iter 24000, loss: 0.333402
 >> iter 25000, loss: 0.326382
 >> iter 26000, loss: 0.298120
 >> iter 27000, loss: 0.217330
 >> iter 28000, loss: 0.296626
 >> iter 29000, loss: 0.407147
 >> iter 30000, loss: 0.230158
   Number of active neurons: 8
 >> iter 31000, loss: 0.144776
 >> iter 32000, loss: 0.256074
 >> iter 33000, loss: 0.284465
 >> iter 34000, loss: 0.331179
 >> iter 35000, loss: 0.230264
 >> iter 36000, loss: 0.155594
 >> iter 37000, loss: 0.224376
 >> iter 38000, loss: 0.361309
 >> iter 39000, loss: 0.309294
 >> iter 40000, loss: 0.383025
   Number of active neurons: 8
 >> iter 41000, loss: 0.272931
 >> iter 42000, loss: 0.187180
 >> iter 43000, loss: 0.240054
 >> iter 44000, loss: 0.335830
 >> iter 45000, loss: 0.343457
 >> iter 46000, loss: 0.345631
 >> iter 47000, loss: 0.288440
 >> iter 48000, loss: 0.183281
 >> iter 49000, loss: 0.147868
 >> iter 50000, loss: 0.243618
   Number of active neurons: 7
 >> iter 51000, loss: 0.384217
 >> iter 52000, loss: 0.190741
 >> iter 53000, loss: 0.342971
 >> iter 54000, loss: 0.190490
 >> iter 55000, loss: 0.220476
 >> iter 56000, loss: 0.222324
 >> iter 57000, loss: 0.444763
 >> iter 58000, loss: 0.336656
 >> iter 59000, loss: 0.273025
 >> iter 60000, loss: 0.291984
   Number of active neurons: 7
 >> iter 61000, loss: 0.216793
 >> iter 62000, loss: 0.248156
 >> iter 63000, loss: 0.283082
 >> iter 64000, loss: 0.327746
 >> iter 65000, loss: 0.179466
 >> iter 66000, loss: 0.163486
 >> iter 67000, loss: 0.212940
 >> iter 68000, loss: 0.247958
 >> iter 69000, loss: 0.195230
 >> iter 70000, loss: 0.154695
   Number of active neurons: 6
 >> iter 71000, loss: 0.295236
 >> iter 72000, loss: 0.304114
 >> iter 73000, loss: 0.225578
 >> iter 74000, loss: 0.308885
 >> iter 75000, loss: 0.244061
 >> iter 76000, loss: 0.370648
 >> iter 77000, loss: 0.361498
 >> iter 78000, loss: 0.279821
 >> iter 79000, loss: 0.190873
 >> iter 80000, loss: 0.134945
   Number of active neurons: 6
 >> iter 81000, loss: 0.236516
 >> iter 82000, loss: 0.258183
 >> iter 83000, loss: 0.288971
 >> iter 84000, loss: 0.242792
 >> iter 85000, loss: 0.168729
 >> iter 86000, loss: 0.278549
 >> iter 87000, loss: 0.217479
 >> iter 88000, loss: 0.318088
 >> iter 89000, loss: 0.194616
 >> iter 90000, loss: 0.209699
   Number of active neurons: 5
 >> iter 91000, loss: 0.197445
 >> iter 92000, loss: 0.157323
 >> iter 93000, loss: 0.246879
 >> iter 94000, loss: 0.202260
 >> iter 95000, loss: 0.160063
 >> iter 96000, loss: 0.295859
 >> iter 97000, loss: 0.303594
 >> iter 98000, loss: 0.152115
 >> iter 99000, loss: 0.188721
 >> iter 100000, loss: 0.164609
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.209452
 >> iter 2000, loss: 10.720827
 >> iter 3000, loss: 4.685951
 >> iter 4000, loss: 2.286871
 >> iter 5000, loss: 1.168063
 >> iter 6000, loss: 0.758254
 >> iter 7000, loss: 0.783854
 >> iter 8000, loss: 0.449960
 >> iter 9000, loss: 0.581350
 >> iter 10000, loss: 0.380456
   Number of active neurons: 8
 >> iter 11000, loss: 0.358205
 >> iter 12000, loss: 0.461257
 >> iter 13000, loss: 0.493212
 >> iter 14000, loss: 0.399433
 >> iter 15000, loss: 0.665390
 >> iter 16000, loss: 0.453311
 >> iter 17000, loss: 0.444788
 >> iter 18000, loss: 0.333833
 >> iter 19000, loss: 0.521677
 >> iter 20000, loss: 0.458037
   Number of active neurons: 7
 >> iter 21000, loss: 0.324679
 >> iter 22000, loss: 0.398537
 >> iter 23000, loss: 0.399933
 >> iter 24000, loss: 0.375470
 >> iter 25000, loss: 0.545676
 >> iter 26000, loss: 0.502519
 >> iter 27000, loss: 0.407370
 >> iter 28000, loss: 0.404653
 >> iter 29000, loss: 0.514909
 >> iter 30000, loss: 0.585227
   Number of active neurons: 7
 >> iter 31000, loss: 0.427760
 >> iter 32000, loss: 0.436749
 >> iter 33000, loss: 0.550351
 >> iter 34000, loss: 0.502888
 >> iter 35000, loss: 0.465396
 >> iter 36000, loss: 0.318528
 >> iter 37000, loss: 0.477083
 >> iter 38000, loss: 0.312539
 >> iter 39000, loss: 0.379626
 >> iter 40000, loss: 0.217312
   Number of active neurons: 7
 >> iter 41000, loss: 0.168473
 >> iter 42000, loss: 0.235140
 >> iter 43000, loss: 0.370873
 >> iter 44000, loss: 0.372530
 >> iter 45000, loss: 0.480614
 >> iter 46000, loss: 0.473047
 >> iter 47000, loss: 0.464385
 >> iter 48000, loss: 0.313094
 >> iter 49000, loss: 0.232606
 >> iter 50000, loss: 0.216026
   Number of active neurons: 7
 >> iter 51000, loss: 0.196352
 >> iter 52000, loss: 0.246462
 >> iter 53000, loss: 0.230455
 >> iter 54000, loss: 0.163000
 >> iter 55000, loss: 0.234756
 >> iter 56000, loss: 0.205555
 >> iter 57000, loss: 0.298972
 >> iter 58000, loss: 0.282588
 >> iter 59000, loss: 0.432533
 >> iter 60000, loss: 0.339119
   Number of active neurons: 7
 >> iter 61000, loss: 0.224896
 >> iter 62000, loss: 0.282159
 >> iter 63000, loss: 0.287965
 >> iter 64000, loss: 0.269900
 >> iter 65000, loss: 0.419419
 >> iter 66000, loss: 0.317797
 >> iter 67000, loss: 0.225393
 >> iter 68000, loss: 0.225809
 >> iter 69000, loss: 0.272725
 >> iter 70000, loss: 0.205161
   Number of active neurons: 7
 >> iter 71000, loss: 0.278192
 >> iter 72000, loss: 0.296395
 >> iter 73000, loss: 0.208948
 >> iter 74000, loss: 0.173521
 >> iter 75000, loss: 0.294037
 >> iter 76000, loss: 0.205067
 >> iter 77000, loss: 0.362904
 >> iter 78000, loss: 0.237238
 >> iter 79000, loss: 0.197732
 >> iter 80000, loss: 0.213488
   Number of active neurons: 7
 >> iter 81000, loss: 0.305976
 >> iter 82000, loss: 0.282721
 >> iter 83000, loss: 0.311391
 >> iter 84000, loss: 0.222869
 >> iter 85000, loss: 0.268377
 >> iter 86000, loss: 0.345943
 >> iter 87000, loss: 0.343137
 >> iter 88000, loss: 0.277594
 >> iter 89000, loss: 0.432191
 >> iter 90000, loss: 0.232514
   Number of active neurons: 7
 >> iter 91000, loss: 0.250821
 >> iter 92000, loss: 0.268250
 >> iter 93000, loss: 0.241083
 >> iter 94000, loss: 0.328139
 >> iter 95000, loss: 0.249542
 >> iter 96000, loss: 0.214908
 >> iter 97000, loss: 0.137116
 >> iter 98000, loss: 0.207072
 >> iter 99000, loss: 0.217326
 >> iter 100000, loss: 0.298794
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.120649
 >> iter 2000, loss: 10.311436
 >> iter 3000, loss: 4.843477
 >> iter 4000, loss: 2.224777
 >> iter 5000, loss: 1.011689
 >> iter 6000, loss: 0.629302
 >> iter 7000, loss: 0.489911
 >> iter 8000, loss: 0.439952
 >> iter 9000, loss: 0.503658
 >> iter 10000, loss: 0.453022
   Number of active neurons: 7
 >> iter 11000, loss: 0.509568
 >> iter 12000, loss: 0.372199
 >> iter 13000, loss: 0.417468
 >> iter 14000, loss: 0.374757
 >> iter 15000, loss: 0.274344
 >> iter 16000, loss: 0.362097
 >> iter 17000, loss: 0.320337
 >> iter 18000, loss: 0.607645
 >> iter 19000, loss: 0.403099
 >> iter 20000, loss: 0.323951
   Number of active neurons: 7
 >> iter 21000, loss: 0.304254
 >> iter 22000, loss: 0.216515
 >> iter 23000, loss: 0.414614
 >> iter 24000, loss: 0.399372
 >> iter 25000, loss: 0.353839
 >> iter 26000, loss: 0.353669
 >> iter 27000, loss: 0.298333
 >> iter 28000, loss: 0.174095
 >> iter 29000, loss: 0.153730
 >> iter 30000, loss: 0.353038
   Number of active neurons: 7
 >> iter 31000, loss: 0.296034
 >> iter 32000, loss: 0.221293
 >> iter 33000, loss: 0.327946
 >> iter 34000, loss: 0.312222
 >> iter 35000, loss: 0.245725
 >> iter 36000, loss: 0.262102
 >> iter 37000, loss: 0.228531
 >> iter 38000, loss: 0.238597
 >> iter 39000, loss: 0.366883
 >> iter 40000, loss: 0.288563
   Number of active neurons: 7
 >> iter 41000, loss: 0.375732
 >> iter 42000, loss: 0.323159
 >> iter 43000, loss: 0.308796
 >> iter 44000, loss: 0.232860
 >> iter 45000, loss: 0.299799
 >> iter 46000, loss: 0.316271
 >> iter 47000, loss: 0.262468
 >> iter 48000, loss: 0.260810
 >> iter 49000, loss: 0.301688
 >> iter 50000, loss: 0.265045
   Number of active neurons: 7
 >> iter 51000, loss: 0.202611
 >> iter 52000, loss: 0.273155
 >> iter 53000, loss: 0.228520
 >> iter 54000, loss: 0.285336
 >> iter 55000, loss: 0.233328
 >> iter 56000, loss: 0.377700
 >> iter 57000, loss: 0.286223
 >> iter 58000, loss: 0.256912
 >> iter 59000, loss: 0.200632
 >> iter 60000, loss: 0.527506
   Number of active neurons: 6
 >> iter 61000, loss: 0.305888
 >> iter 62000, loss: 0.349377
 >> iter 63000, loss: 0.252922
 >> iter 64000, loss: 0.235144
 >> iter 65000, loss: 0.304365
 >> iter 66000, loss: 0.234689
 >> iter 67000, loss: 0.179926
 >> iter 68000, loss: 0.286115
 >> iter 69000, loss: 0.251887
 >> iter 70000, loss: 0.308821
   Number of active neurons: 6
 >> iter 71000, loss: 0.421842
 >> iter 72000, loss: 0.307540
 >> iter 73000, loss: 0.264915
 >> iter 74000, loss: 0.323953
 >> iter 75000, loss: 0.417339
 >> iter 76000, loss: 0.299104
 >> iter 77000, loss: 0.267274
 >> iter 78000, loss: 0.383440
 >> iter 79000, loss: 0.305184
 >> iter 80000, loss: 0.167495
   Number of active neurons: 6
 >> iter 81000, loss: 0.363881
 >> iter 82000, loss: 0.289472
 >> iter 83000, loss: 0.290845
 >> iter 84000, loss: 0.292882
 >> iter 85000, loss: 0.280630
 >> iter 86000, loss: 0.333478
 >> iter 87000, loss: 0.334046
 >> iter 88000, loss: 0.202698
 >> iter 89000, loss: 0.166539
 >> iter 90000, loss: 0.336832
   Number of active neurons: 6
 >> iter 91000, loss: 0.287571
 >> iter 92000, loss: 0.202072
 >> iter 93000, loss: 0.257774
 >> iter 94000, loss: 0.275305
 >> iter 95000, loss: 0.383037
 >> iter 96000, loss: 0.463986
 >> iter 97000, loss: 0.278880
 >> iter 98000, loss: 0.188845
 >> iter 99000, loss: 0.155959
 >> iter 100000, loss: 0.153894
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.121394
 >> iter 2000, loss: 11.495833
 >> iter 3000, loss: 5.085269
 >> iter 4000, loss: 2.527123
 >> iter 5000, loss: 1.322372
 >> iter 6000, loss: 0.623146
 >> iter 7000, loss: 0.546457
 >> iter 8000, loss: 0.492260
 >> iter 9000, loss: 0.351513
 >> iter 10000, loss: 0.201593
   Number of active neurons: 9
 >> iter 11000, loss: 0.254389
 >> iter 12000, loss: 0.274864
 >> iter 13000, loss: 0.239444
 >> iter 14000, loss: 0.187951
 >> iter 15000, loss: 0.343365
 >> iter 16000, loss: 0.371297
 >> iter 17000, loss: 0.299769
 >> iter 18000, loss: 0.242683
 >> iter 19000, loss: 0.425719
 >> iter 20000, loss: 0.270830
   Number of active neurons: 9
 >> iter 21000, loss: 0.239050
 >> iter 22000, loss: 0.354224
 >> iter 23000, loss: 0.339778
 >> iter 24000, loss: 0.181965
 >> iter 25000, loss: 0.245573
 >> iter 26000, loss: 0.289693
 >> iter 27000, loss: 0.236043
 >> iter 28000, loss: 0.289200
 >> iter 29000, loss: 0.154769
 >> iter 30000, loss: 0.171681
   Number of active neurons: 9
 >> iter 31000, loss: 0.230697
 >> iter 32000, loss: 0.236967
 >> iter 33000, loss: 0.242889
 >> iter 34000, loss: 0.183653
 >> iter 35000, loss: 0.145485
 >> iter 36000, loss: 0.361732
 >> iter 37000, loss: 0.299446
 >> iter 38000, loss: 0.354142
 >> iter 39000, loss: 0.206014
 >> iter 40000, loss: 0.217116
   Number of active neurons: 8
 >> iter 41000, loss: 0.183284
 >> iter 42000, loss: 0.152636
 >> iter 43000, loss: 0.147696
 >> iter 44000, loss: 0.126994
 >> iter 45000, loss: 0.477558
 >> iter 46000, loss: 0.346821
 >> iter 47000, loss: 0.176692
 >> iter 48000, loss: 0.249270
 >> iter 49000, loss: 0.204106
 >> iter 50000, loss: 0.249806
   Number of active neurons: 8
 >> iter 51000, loss: 0.157176
 >> iter 52000, loss: 0.257097
 >> iter 53000, loss: 0.245506
 >> iter 54000, loss: 0.273534
 >> iter 55000, loss: 0.222096
 >> iter 56000, loss: 0.218582
 >> iter 57000, loss: 0.295788
 >> iter 58000, loss: 0.215084
 >> iter 59000, loss: 0.342825
 >> iter 60000, loss: 0.201984
   Number of active neurons: 7
 >> iter 61000, loss: 0.270607
 >> iter 62000, loss: 0.241959
 >> iter 63000, loss: 0.196658
 >> iter 64000, loss: 0.308610
 >> iter 65000, loss: 0.352807
 >> iter 66000, loss: 0.296341
 >> iter 67000, loss: 0.255281
 >> iter 68000, loss: 0.192870
 >> iter 69000, loss: 0.151729
 >> iter 70000, loss: 0.199570
   Number of active neurons: 7
 >> iter 71000, loss: 0.362215
 >> iter 72000, loss: 0.233889
 >> iter 73000, loss: 0.200554
 >> iter 74000, loss: 0.270923
 >> iter 75000, loss: 0.248014
 >> iter 76000, loss: 0.172885
 >> iter 77000, loss: 0.366352
 >> iter 78000, loss: 0.223838
 >> iter 79000, loss: 0.239613
 >> iter 80000, loss: 0.213252
   Number of active neurons: 7
 >> iter 81000, loss: 0.137133
 >> iter 82000, loss: 0.166058
 >> iter 83000, loss: 0.363962
 >> iter 84000, loss: 0.251376
 >> iter 85000, loss: 0.154878
 >> iter 86000, loss: 0.228611
 >> iter 87000, loss: 0.175300
 >> iter 88000, loss: 0.143694
 >> iter 89000, loss: 0.168962
 >> iter 90000, loss: 0.158502
   Number of active neurons: 7
 >> iter 91000, loss: 0.150714
 >> iter 92000, loss: 0.179577
 >> iter 93000, loss: 0.253585
 >> iter 94000, loss: 0.199440
 >> iter 95000, loss: 0.301361
 >> iter 96000, loss: 0.278415
 >> iter 97000, loss: 0.300547
 >> iter 98000, loss: 0.194098
 >> iter 99000, loss: 0.381474
 >> iter 100000, loss: 0.236014
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

