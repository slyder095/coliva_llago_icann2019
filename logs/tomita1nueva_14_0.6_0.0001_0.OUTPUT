 > Problema: tomita1nueva
 > Args:
   - Hidden size: 14
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.958405
 >> iter 2000, loss: 4.078567
 >> iter 3000, loss: 1.534663
 >> iter 4000, loss: 0.599416
 >> iter 5000, loss: 0.246079
 >> iter 6000, loss: 0.110505
 >> iter 7000, loss: 0.064989
 >> iter 8000, loss: 0.045439
 >> iter 9000, loss: 0.034718
 >> iter 10000, loss: 0.034343
   Number of active neurons: 5
 >> iter 11000, loss: 0.031207
 >> iter 12000, loss: 0.031407
 >> iter 13000, loss: 0.029963
 >> iter 14000, loss: 0.030690
 >> iter 15000, loss: 0.030342
 >> iter 16000, loss: 0.027731
 >> iter 17000, loss: 0.028958
 >> iter 18000, loss: 0.029376
 >> iter 19000, loss: 0.028701
 >> iter 20000, loss: 0.028436
   Number of active neurons: 3
 >> iter 21000, loss: 0.026904
 >> iter 22000, loss: 0.027093
 >> iter 23000, loss: 0.031353
 >> iter 24000, loss: 0.030057
 >> iter 25000, loss: 0.027253
 >> iter 26000, loss: 0.025531
 >> iter 27000, loss: 0.028839
 >> iter 28000, loss: 0.026367
 >> iter 29000, loss: 0.024602
 >> iter 30000, loss: 0.029772
   Number of active neurons: 2
 >> iter 31000, loss: 0.022642
 >> iter 32000, loss: 0.025713
 >> iter 33000, loss: 0.021620
 >> iter 34000, loss: 0.022367
 >> iter 35000, loss: 0.027088
 >> iter 36000, loss: 0.024557
 >> iter 37000, loss: 0.027286
 >> iter 38000, loss: 0.022733
 >> iter 39000, loss: 0.027761
 >> iter 40000, loss: 0.023216
   Number of active neurons: 2
 >> iter 41000, loss: 0.033485
 >> iter 42000, loss: 0.027558
 >> iter 43000, loss: 0.026613
 >> iter 44000, loss: 0.022167
 >> iter 45000, loss: 0.022116
 >> iter 46000, loss: 0.020688
 >> iter 47000, loss: 0.032314
 >> iter 48000, loss: 0.032316
 >> iter 49000, loss: 0.028913
 >> iter 50000, loss: 0.023480
   Number of active neurons: 2
 >> iter 51000, loss: 0.020320
 >> iter 52000, loss: 0.019395
 >> iter 53000, loss: 0.020328
 >> iter 54000, loss: 0.021334
 >> iter 55000, loss: 0.022356
 >> iter 56000, loss: 0.029265
 >> iter 57000, loss: 0.024464
 >> iter 58000, loss: 0.020945
 >> iter 59000, loss: 0.035689
 >> iter 60000, loss: 0.032821
   Number of active neurons: 2
 >> iter 61000, loss: 0.025531
 >> iter 62000, loss: 0.024079
 >> iter 63000, loss: 0.025513
 >> iter 64000, loss: 0.021393
 >> iter 65000, loss: 0.022598
 >> iter 66000, loss: 0.021608
 >> iter 67000, loss: 0.021841
 >> iter 68000, loss: 0.021230
 >> iter 69000, loss: 0.023651
 >> iter 70000, loss: 0.022119
   Number of active neurons: 2
 >> iter 71000, loss: 0.020357
 >> iter 72000, loss: 0.020395
 >> iter 73000, loss: 0.035075
 >> iter 74000, loss: 0.034035
 >> iter 75000, loss: 0.025293
 >> iter 76000, loss: 0.033578
 >> iter 77000, loss: 0.046008
 >> iter 78000, loss: 0.033630
 >> iter 79000, loss: 0.027107
 >> iter 80000, loss: 0.030446
   Number of active neurons: 2
 >> iter 81000, loss: 0.032559
 >> iter 82000, loss: 0.026369
 >> iter 83000, loss: 0.040265
 >> iter 84000, loss: 0.031693
 >> iter 85000, loss: 0.024870
 >> iter 86000, loss: 0.025235
 >> iter 87000, loss: 0.037367
 >> iter 88000, loss: 0.031252
 >> iter 89000, loss: 0.029852
 >> iter 90000, loss: 0.024013
   Number of active neurons: 2
 >> iter 91000, loss: 0.023273
 >> iter 92000, loss: 0.023854
 >> iter 93000, loss: 0.047368
 >> iter 94000, loss: 0.031843
 >> iter 95000, loss: 0.022699
 >> iter 96000, loss: 0.027453
 >> iter 97000, loss: 0.022992
 >> iter 98000, loss: 0.021496
 >> iter 99000, loss: 0.019300
 >> iter 100000, loss: 0.019854
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.888834
 >> iter 2000, loss: 4.049210
 >> iter 3000, loss: 1.535239
 >> iter 4000, loss: 0.593602
 >> iter 5000, loss: 0.254672
 >> iter 6000, loss: 0.123282
 >> iter 7000, loss: 0.064623
 >> iter 8000, loss: 0.042113
 >> iter 9000, loss: 0.037663
 >> iter 10000, loss: 0.030994
   Number of active neurons: 5
 >> iter 11000, loss: 0.037286
 >> iter 12000, loss: 0.030826
 >> iter 13000, loss: 0.030368
 >> iter 14000, loss: 0.030280
 >> iter 15000, loss: 0.031212
 >> iter 16000, loss: 0.031828
 >> iter 17000, loss: 0.027068
 >> iter 18000, loss: 0.027900
 >> iter 19000, loss: 0.026917
 >> iter 20000, loss: 0.032117
   Number of active neurons: 2
 >> iter 21000, loss: 0.025401
 >> iter 22000, loss: 0.024164
 >> iter 23000, loss: 0.022197
 >> iter 24000, loss: 0.031842
 >> iter 25000, loss: 0.030128
 >> iter 26000, loss: 0.024054
 >> iter 27000, loss: 0.024163
 >> iter 28000, loss: 0.021825
 >> iter 29000, loss: 0.022052
 >> iter 30000, loss: 0.021694
   Number of active neurons: 2
 >> iter 31000, loss: 0.020348
 >> iter 32000, loss: 0.024052
 >> iter 33000, loss: 0.026659
 >> iter 34000, loss: 0.021660
 >> iter 35000, loss: 0.021871
 >> iter 36000, loss: 0.021725
 >> iter 37000, loss: 0.020516
 >> iter 38000, loss: 0.021390
 >> iter 39000, loss: 0.021129
 >> iter 40000, loss: 0.024114
   Number of active neurons: 2
 >> iter 41000, loss: 0.031457
 >> iter 42000, loss: 0.023042
 >> iter 43000, loss: 0.022419
 >> iter 44000, loss: 0.022748
 >> iter 45000, loss: 0.021188
 >> iter 46000, loss: 0.020961
 >> iter 47000, loss: 0.021558
 >> iter 48000, loss: 0.042385
 >> iter 49000, loss: 0.029496
 >> iter 50000, loss: 0.029148
   Number of active neurons: 2
 >> iter 51000, loss: 0.027074
 >> iter 52000, loss: 0.033695
 >> iter 53000, loss: 0.025496
 >> iter 54000, loss: 0.023005
 >> iter 55000, loss: 0.024151
 >> iter 56000, loss: 0.022322
 >> iter 57000, loss: 0.021732
 >> iter 58000, loss: 0.026447
 >> iter 59000, loss: 0.023396
 >> iter 60000, loss: 0.021150
   Number of active neurons: 2
 >> iter 61000, loss: 0.021390
 >> iter 62000, loss: 0.024570
 >> iter 63000, loss: 0.028351
 >> iter 64000, loss: 0.023660
 >> iter 65000, loss: 0.021834
 >> iter 66000, loss: 0.027435
 >> iter 67000, loss: 0.029113
 >> iter 68000, loss: 0.024291
 >> iter 69000, loss: 0.021842
 >> iter 70000, loss: 0.029446
   Number of active neurons: 2
 >> iter 71000, loss: 0.053840
 >> iter 72000, loss: 0.033758
 >> iter 73000, loss: 0.026155
 >> iter 74000, loss: 0.030503
 >> iter 75000, loss: 0.028226
 >> iter 76000, loss: 0.037920
 >> iter 77000, loss: 0.026019
 >> iter 78000, loss: 0.023181
 >> iter 79000, loss: 0.032958
 >> iter 80000, loss: 0.039881
   Number of active neurons: 2
 >> iter 81000, loss: 0.035562
 >> iter 82000, loss: 0.026360
 >> iter 83000, loss: 0.021382
 >> iter 84000, loss: 0.020929
 >> iter 85000, loss: 0.024541
 >> iter 86000, loss: 0.063823
 >> iter 87000, loss: 0.038131
 >> iter 88000, loss: 0.029175
 >> iter 89000, loss: 0.028279
 >> iter 90000, loss: 0.027347
   Number of active neurons: 2
 >> iter 91000, loss: 0.022920
 >> iter 92000, loss: 0.022896
 >> iter 93000, loss: 0.024076
 >> iter 94000, loss: 0.029248
 >> iter 95000, loss: 0.025557
 >> iter 96000, loss: 0.028898
 >> iter 97000, loss: 0.023227
 >> iter 98000, loss: 0.025199
 >> iter 99000, loss: 0.023024
 >> iter 100000, loss: 0.025324
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.953144
 >> iter 2000, loss: 4.081343
 >> iter 3000, loss: 1.525428
 >> iter 4000, loss: 0.589929
 >> iter 5000, loss: 0.235502
 >> iter 6000, loss: 0.105266
 >> iter 7000, loss: 0.058475
 >> iter 8000, loss: 0.037883
 >> iter 9000, loss: 0.033212
 >> iter 10000, loss: 0.043196
   Number of active neurons: 3
 >> iter 11000, loss: 0.031777
 >> iter 12000, loss: 0.026604
 >> iter 13000, loss: 0.032129
 >> iter 14000, loss: 0.026792
 >> iter 15000, loss: 0.025131
 >> iter 16000, loss: 0.026854
 >> iter 17000, loss: 0.027760
 >> iter 18000, loss: 0.025435
 >> iter 19000, loss: 0.024557
 >> iter 20000, loss: 0.024453
   Number of active neurons: 3
 >> iter 21000, loss: 0.023837
 >> iter 22000, loss: 0.032352
 >> iter 23000, loss: 0.027392
 >> iter 24000, loss: 0.024558
 >> iter 25000, loss: 0.025835
 >> iter 26000, loss: 0.027904
 >> iter 27000, loss: 0.025703
 >> iter 28000, loss: 0.026389
 >> iter 29000, loss: 0.027918
 >> iter 30000, loss: 0.036970
   Number of active neurons: 3
 >> iter 31000, loss: 0.030196
 >> iter 32000, loss: 0.030995
 >> iter 33000, loss: 0.026616
 >> iter 34000, loss: 0.026349
 >> iter 35000, loss: 0.024031
 >> iter 36000, loss: 0.022915
 >> iter 37000, loss: 0.052683
 >> iter 38000, loss: 0.036617
 >> iter 39000, loss: 0.027731
 >> iter 40000, loss: 0.026252
   Number of active neurons: 2
 >> iter 41000, loss: 0.054451
 >> iter 42000, loss: 0.033929
 >> iter 43000, loss: 0.040280
 >> iter 44000, loss: 0.028816
 >> iter 45000, loss: 0.028788
 >> iter 46000, loss: 0.022800
 >> iter 47000, loss: 0.026822
 >> iter 48000, loss: 0.023192
 >> iter 49000, loss: 0.040585
 >> iter 50000, loss: 0.028912
   Number of active neurons: 2
 >> iter 51000, loss: 0.028277
 >> iter 52000, loss: 0.023840
 >> iter 53000, loss: 0.021893
 >> iter 54000, loss: 0.039749
 >> iter 55000, loss: 0.027692
 >> iter 56000, loss: 0.025295
 >> iter 57000, loss: 0.026108
 >> iter 58000, loss: 0.030183
 >> iter 59000, loss: 0.025744
 >> iter 60000, loss: 0.028767
   Number of active neurons: 2
 >> iter 61000, loss: 0.028156
 >> iter 62000, loss: 0.028301
 >> iter 63000, loss: 0.027799
 >> iter 64000, loss: 0.036243
 >> iter 65000, loss: 0.030803
 >> iter 66000, loss: 0.024105
 >> iter 67000, loss: 0.032671
 >> iter 68000, loss: 0.024582
 >> iter 69000, loss: 0.029575
 >> iter 70000, loss: 0.024855
   Number of active neurons: 2
 >> iter 71000, loss: 0.024232
 >> iter 72000, loss: 0.027682
 >> iter 73000, loss: 0.028849
 >> iter 74000, loss: 0.036855
 >> iter 75000, loss: 0.035734
 >> iter 76000, loss: 0.032432
 >> iter 77000, loss: 0.064604
 >> iter 78000, loss: 0.039313
 >> iter 79000, loss: 0.027872
 >> iter 80000, loss: 0.030134
   Number of active neurons: 2
 >> iter 81000, loss: 0.026531
 >> iter 82000, loss: 0.022159
 >> iter 83000, loss: 0.021399
 >> iter 84000, loss: 0.025603
 >> iter 85000, loss: 0.031623
 >> iter 86000, loss: 0.024452
 >> iter 87000, loss: 0.024762
 >> iter 88000, loss: 0.021463
 >> iter 89000, loss: 0.022762
 >> iter 90000, loss: 0.027157
   Number of active neurons: 1
 >> iter 91000, loss: 0.024022
 >> iter 92000, loss: 0.022095
 >> iter 93000, loss: 0.031991
 >> iter 94000, loss: 0.034734
 >> iter 95000, loss: 0.025042
 >> iter 96000, loss: 0.043890
 >> iter 97000, loss: 0.031829
 >> iter 98000, loss: 0.026663
 >> iter 99000, loss: 0.022170
 >> iter 100000, loss: 0.018434
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.990555
 >> iter 2000, loss: 4.104353
 >> iter 3000, loss: 1.536860
 >> iter 4000, loss: 0.588470
 >> iter 5000, loss: 0.248439
 >> iter 6000, loss: 0.110867
 >> iter 7000, loss: 0.064835
 >> iter 8000, loss: 0.042019
 >> iter 9000, loss: 0.040218
 >> iter 10000, loss: 0.034016
   Number of active neurons: 3
 >> iter 11000, loss: 0.032677
 >> iter 12000, loss: 0.028615
 >> iter 13000, loss: 0.027110
 >> iter 14000, loss: 0.024476
 >> iter 15000, loss: 0.025993
 >> iter 16000, loss: 0.028520
 >> iter 17000, loss: 0.027664
 >> iter 18000, loss: 0.025395
 >> iter 19000, loss: 0.023284
 >> iter 20000, loss: 0.025776
   Number of active neurons: 3
 >> iter 21000, loss: 0.025334
 >> iter 22000, loss: 0.033716
 >> iter 23000, loss: 0.027210
 >> iter 24000, loss: 0.023433
 >> iter 25000, loss: 0.022954
 >> iter 26000, loss: 0.057636
 >> iter 27000, loss: 0.036049
 >> iter 28000, loss: 0.033208
 >> iter 29000, loss: 0.027674
 >> iter 30000, loss: 0.022716
   Number of active neurons: 2
 >> iter 31000, loss: 0.021944
 >> iter 32000, loss: 0.025001
 >> iter 33000, loss: 0.032427
 >> iter 34000, loss: 0.028236
 >> iter 35000, loss: 0.023983
 >> iter 36000, loss: 0.021992
 >> iter 37000, loss: 0.020670
 >> iter 38000, loss: 0.022956
 >> iter 39000, loss: 0.022939
 >> iter 40000, loss: 0.024011
   Number of active neurons: 2
 >> iter 41000, loss: 0.024070
 >> iter 42000, loss: 0.029336
 >> iter 43000, loss: 0.023148
 >> iter 44000, loss: 0.021812
 >> iter 45000, loss: 0.022313
 >> iter 46000, loss: 0.022240
 >> iter 47000, loss: 0.043199
 >> iter 48000, loss: 0.037566
 >> iter 49000, loss: 0.027860
 >> iter 50000, loss: 0.025032
   Number of active neurons: 2
 >> iter 51000, loss: 0.020835
 >> iter 52000, loss: 0.024247
 >> iter 53000, loss: 0.034293
 >> iter 54000, loss: 0.035522
 >> iter 55000, loss: 0.034092
 >> iter 56000, loss: 0.026942
 >> iter 57000, loss: 0.027963
 >> iter 58000, loss: 0.024489
 >> iter 59000, loss: 0.020450
 >> iter 60000, loss: 0.023935
   Number of active neurons: 2
 >> iter 61000, loss: 0.022949
 >> iter 62000, loss: 0.021457
 >> iter 63000, loss: 0.021360
 >> iter 64000, loss: 0.021719
 >> iter 65000, loss: 0.021035
 >> iter 66000, loss: 0.023351
 >> iter 67000, loss: 0.022646
 >> iter 68000, loss: 0.022684
 >> iter 69000, loss: 0.024167
 >> iter 70000, loss: 0.036349
   Number of active neurons: 2
 >> iter 71000, loss: 0.027560
 >> iter 72000, loss: 0.023423
 >> iter 73000, loss: 0.023420
 >> iter 74000, loss: 0.032861
 >> iter 75000, loss: 0.055527
 >> iter 76000, loss: 0.044926
 >> iter 77000, loss: 0.031344
 >> iter 78000, loss: 0.025321
 >> iter 79000, loss: 0.026987
 >> iter 80000, loss: 0.027482
   Number of active neurons: 2
 >> iter 81000, loss: 0.024040
 >> iter 82000, loss: 0.021192
 >> iter 83000, loss: 0.022072
 >> iter 84000, loss: 0.023276
 >> iter 85000, loss: 0.027093
 >> iter 86000, loss: 0.022022
 >> iter 87000, loss: 0.024123
 >> iter 88000, loss: 0.044956
 >> iter 89000, loss: 0.036501
 >> iter 90000, loss: 0.026078
   Number of active neurons: 2
 >> iter 91000, loss: 0.023254
 >> iter 92000, loss: 0.022898
 >> iter 93000, loss: 0.044997
 >> iter 94000, loss: 0.034676
 >> iter 95000, loss: 0.027122
 >> iter 96000, loss: 0.025268
 >> iter 97000, loss: 0.023727
 >> iter 98000, loss: 0.029618
 >> iter 99000, loss: 0.024753
 >> iter 100000, loss: 0.026144
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 10.942398
 >> iter 2000, loss: 4.069212
 >> iter 3000, loss: 1.542124
 >> iter 4000, loss: 0.588484
 >> iter 5000, loss: 0.248062
 >> iter 6000, loss: 0.113987
 >> iter 7000, loss: 0.062597
 >> iter 8000, loss: 0.042026
 >> iter 9000, loss: 0.034726
 >> iter 10000, loss: 0.032277
   Number of active neurons: 5
 >> iter 11000, loss: 0.031228
 >> iter 12000, loss: 0.027975
 >> iter 13000, loss: 0.038011
 >> iter 14000, loss: 0.029364
 >> iter 15000, loss: 0.026999
 >> iter 16000, loss: 0.027094
 >> iter 17000, loss: 0.024647
 >> iter 18000, loss: 0.024676
 >> iter 19000, loss: 0.030840
 >> iter 20000, loss: 0.028348
   Number of active neurons: 3
 >> iter 21000, loss: 0.027148
 >> iter 22000, loss: 0.029981
 >> iter 23000, loss: 0.027936
 >> iter 24000, loss: 0.025368
 >> iter 25000, loss: 0.025036
 >> iter 26000, loss: 0.026617
 >> iter 27000, loss: 0.026972
 >> iter 28000, loss: 0.025993
 >> iter 29000, loss: 0.023480
 >> iter 30000, loss: 0.027714
   Number of active neurons: 3
 >> iter 31000, loss: 0.026942
 >> iter 32000, loss: 0.024084
 >> iter 33000, loss: 0.043219
 >> iter 34000, loss: 0.030774
 >> iter 35000, loss: 0.027041
 >> iter 36000, loss: 0.027299
 >> iter 37000, loss: 0.028504
 >> iter 38000, loss: 0.030613
 >> iter 39000, loss: 0.027686
 >> iter 40000, loss: 0.026434
   Number of active neurons: 3
 >> iter 41000, loss: 0.021617
 >> iter 42000, loss: 0.020798
 >> iter 43000, loss: 0.022410
 >> iter 44000, loss: 0.022146
 >> iter 45000, loss: 0.022659
 >> iter 46000, loss: 0.023054
 >> iter 47000, loss: 0.039756
 >> iter 48000, loss: 0.027381
 >> iter 49000, loss: 0.022744
 >> iter 50000, loss: 0.027160
   Number of active neurons: 2
 >> iter 51000, loss: 0.023391
 >> iter 52000, loss: 0.024018
 >> iter 53000, loss: 0.025984
 >> iter 54000, loss: 0.024143
 >> iter 55000, loss: 0.022783
 >> iter 56000, loss: 0.023170
 >> iter 57000, loss: 0.025402
 >> iter 58000, loss: 0.023594
 >> iter 59000, loss: 0.026150
 >> iter 60000, loss: 0.021861
   Number of active neurons: 2
 >> iter 61000, loss: 0.023076
 >> iter 62000, loss: 0.021315
 >> iter 63000, loss: 0.020513
 >> iter 64000, loss: 0.019832
 >> iter 65000, loss: 0.026658
 >> iter 66000, loss: 0.023915
 >> iter 67000, loss: 0.021693
 >> iter 68000, loss: 0.026354
 >> iter 69000, loss: 0.023515
 >> iter 70000, loss: 0.025735
   Number of active neurons: 2
 >> iter 71000, loss: 0.021396
 >> iter 72000, loss: 0.036335
 >> iter 73000, loss: 0.028301
 >> iter 74000, loss: 0.025493
 >> iter 75000, loss: 0.029747
 >> iter 76000, loss: 0.024849
 >> iter 77000, loss: 0.020368
 >> iter 78000, loss: 0.021124
 >> iter 79000, loss: 0.020612
 >> iter 80000, loss: 0.021581
   Number of active neurons: 2
 >> iter 81000, loss: 0.035924
 >> iter 82000, loss: 0.028281
 >> iter 83000, loss: 0.022785
 >> iter 84000, loss: 0.022394
 >> iter 85000, loss: 0.022839
 >> iter 86000, loss: 0.022183
 >> iter 87000, loss: 0.051185
 >> iter 88000, loss: 0.035653
 >> iter 89000, loss: 0.037255
 >> iter 90000, loss: 0.026721
   Number of active neurons: 2
 >> iter 91000, loss: 0.042693
 >> iter 92000, loss: 0.033140
 >> iter 93000, loss: 0.040572
 >> iter 94000, loss: 0.028218
 >> iter 95000, loss: 0.023894
 >> iter 96000, loss: 0.022134
 >> iter 97000, loss: 0.021106
 >> iter 98000, loss: 0.020327
 >> iter 99000, loss: 0.034284
 >> iter 100000, loss: 0.028768
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.908134
 >> iter 2000, loss: 4.053087
 >> iter 3000, loss: 1.517675
 >> iter 4000, loss: 0.584128
 >> iter 5000, loss: 0.250044
 >> iter 6000, loss: 0.114799
 >> iter 7000, loss: 0.062984
 >> iter 8000, loss: 0.040647
 >> iter 9000, loss: 0.034238
 >> iter 10000, loss: 0.030394
   Number of active neurons: 4
 >> iter 11000, loss: 0.032950
 >> iter 12000, loss: 0.031653
 >> iter 13000, loss: 0.031764
 >> iter 14000, loss: 0.033078
 >> iter 15000, loss: 0.028519
 >> iter 16000, loss: 0.027242
 >> iter 17000, loss: 0.030214
 >> iter 18000, loss: 0.025827
 >> iter 19000, loss: 0.049316
 >> iter 20000, loss: 0.035064
   Number of active neurons: 3
 >> iter 21000, loss: 0.032373
 >> iter 22000, loss: 0.026371
 >> iter 23000, loss: 0.027520
 >> iter 24000, loss: 0.026030
 >> iter 25000, loss: 0.025942
 >> iter 26000, loss: 0.024175
 >> iter 27000, loss: 0.022092
 >> iter 28000, loss: 0.021641
 >> iter 29000, loss: 0.023386
 >> iter 30000, loss: 0.065635
   Number of active neurons: 1
 >> iter 31000, loss: 0.037243
 >> iter 32000, loss: 0.032060
 >> iter 33000, loss: 0.023704
 >> iter 34000, loss: 0.046270
 >> iter 35000, loss: 0.031496
 >> iter 36000, loss: 0.042230
 >> iter 37000, loss: 0.028230
 >> iter 38000, loss: 0.037442
 >> iter 39000, loss: 0.024500
 >> iter 40000, loss: 0.036973
   Number of active neurons: 1
 >> iter 41000, loss: 0.047686
 >> iter 42000, loss: 0.029617
 >> iter 43000, loss: 0.024334
 >> iter 44000, loss: 0.022727
 >> iter 45000, loss: 0.018582
 >> iter 46000, loss: 0.018721
 >> iter 47000, loss: 0.029887
 >> iter 48000, loss: 0.025042
 >> iter 49000, loss: 0.020505
 >> iter 50000, loss: 0.017338
   Number of active neurons: 1
 >> iter 51000, loss: 0.020956
 >> iter 52000, loss: 0.018611
 >> iter 53000, loss: 0.017901
 >> iter 54000, loss: 0.019104
 >> iter 55000, loss: 0.019875
 >> iter 56000, loss: 0.017411
 >> iter 57000, loss: 0.031212
 >> iter 58000, loss: 0.023533
 >> iter 59000, loss: 0.053218
 >> iter 60000, loss: 0.028909
   Number of active neurons: 1
 >> iter 61000, loss: 0.024219
 >> iter 62000, loss: 0.021323
 >> iter 63000, loss: 0.018400
 >> iter 64000, loss: 0.018627
 >> iter 65000, loss: 0.019484
 >> iter 66000, loss: 0.018117
 >> iter 67000, loss: 0.018791
 >> iter 68000, loss: 0.017606
 >> iter 69000, loss: 0.017250
 >> iter 70000, loss: 0.021591
   Number of active neurons: 1
 >> iter 71000, loss: 0.045627
 >> iter 72000, loss: 0.046689
 >> iter 73000, loss: 0.030553
 >> iter 74000, loss: 0.025396
 >> iter 75000, loss: 0.024620
 >> iter 76000, loss: 0.024235
 >> iter 77000, loss: 0.019029
 >> iter 78000, loss: 0.025745
 >> iter 79000, loss: 0.038364
 >> iter 80000, loss: 0.025532
   Number of active neurons: 1
 >> iter 81000, loss: 0.023391
 >> iter 82000, loss: 0.027603
 >> iter 83000, loss: 0.024159
 >> iter 84000, loss: 0.020697
 >> iter 85000, loss: 0.019085
 >> iter 86000, loss: 0.030590
 >> iter 87000, loss: 0.021270
 >> iter 88000, loss: 0.018164
 >> iter 89000, loss: 0.033621
 >> iter 90000, loss: 0.023398
   Number of active neurons: 1
 >> iter 91000, loss: 0.018231
 >> iter 92000, loss: 0.017550
 >> iter 93000, loss: 0.029447
 >> iter 94000, loss: 0.022224
 >> iter 95000, loss: 0.025837
 >> iter 96000, loss: 0.022590
 >> iter 97000, loss: 0.021065
 >> iter 98000, loss: 0.020965
 >> iter 99000, loss: 0.022290
 >> iter 100000, loss: 0.026715
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.940798
 >> iter 2000, loss: 4.078067
 >> iter 3000, loss: 1.538389
 >> iter 4000, loss: 0.589405
 >> iter 5000, loss: 0.240440
 >> iter 6000, loss: 0.111904
 >> iter 7000, loss: 0.061432
 >> iter 8000, loss: 0.041137
 >> iter 9000, loss: 0.036707
 >> iter 10000, loss: 0.030651
   Number of active neurons: 4
 >> iter 11000, loss: 0.029725
 >> iter 12000, loss: 0.030315
 >> iter 13000, loss: 0.028327
 >> iter 14000, loss: 0.026298
 >> iter 15000, loss: 0.026841
 >> iter 16000, loss: 0.027714
 >> iter 17000, loss: 0.027222
 >> iter 18000, loss: 0.034412
 >> iter 19000, loss: 0.037305
 >> iter 20000, loss: 0.027438
   Number of active neurons: 4
 >> iter 21000, loss: 0.029755
 >> iter 22000, loss: 0.024978
 >> iter 23000, loss: 0.026471
 >> iter 24000, loss: 0.023674
 >> iter 25000, loss: 0.027643
 >> iter 26000, loss: 0.036324
 >> iter 27000, loss: 0.031876
 >> iter 28000, loss: 0.036163
 >> iter 29000, loss: 0.029985
 >> iter 30000, loss: 0.026285
   Number of active neurons: 3
 >> iter 31000, loss: 0.029967
 >> iter 32000, loss: 0.025223
 >> iter 33000, loss: 0.022512
 >> iter 34000, loss: 0.024957
 >> iter 35000, loss: 0.026933
 >> iter 36000, loss: 0.027075
 >> iter 37000, loss: 0.024498
 >> iter 38000, loss: 0.031686
 >> iter 39000, loss: 0.034124
 >> iter 40000, loss: 0.028760
   Number of active neurons: 3
 >> iter 41000, loss: 0.028332
 >> iter 42000, loss: 0.025533
 >> iter 43000, loss: 0.023277
 >> iter 44000, loss: 0.023537
 >> iter 45000, loss: 0.022539
 >> iter 46000, loss: 0.022910
 >> iter 47000, loss: 0.023176
 >> iter 48000, loss: 0.026488
 >> iter 49000, loss: 0.027795
 >> iter 50000, loss: 0.028927
   Number of active neurons: 3
 >> iter 51000, loss: 0.027447
 >> iter 52000, loss: 0.024029
 >> iter 53000, loss: 0.024284
 >> iter 54000, loss: 0.023417
 >> iter 55000, loss: 0.024440
 >> iter 56000, loss: 0.024347
 >> iter 57000, loss: 0.026947
 >> iter 58000, loss: 0.029717
 >> iter 59000, loss: 0.025055
 >> iter 60000, loss: 0.025962
   Number of active neurons: 3
 >> iter 61000, loss: 0.024424
 >> iter 62000, loss: 0.023925
 >> iter 63000, loss: 0.026821
 >> iter 64000, loss: 0.030184
 >> iter 65000, loss: 0.045464
 >> iter 66000, loss: 0.031915
 >> iter 67000, loss: 0.030441
 >> iter 68000, loss: 0.032939
 >> iter 69000, loss: 0.025135
 >> iter 70000, loss: 0.022097
   Number of active neurons: 2
 >> iter 71000, loss: 0.023307
 >> iter 72000, loss: 0.023105
 >> iter 73000, loss: 0.021230
 >> iter 74000, loss: 0.022454
 >> iter 75000, loss: 0.022121
 >> iter 76000, loss: 0.034874
 >> iter 77000, loss: 0.027495
 >> iter 78000, loss: 0.024789
 >> iter 79000, loss: 0.022199
 >> iter 80000, loss: 0.021680
   Number of active neurons: 2
 >> iter 81000, loss: 0.022325
 >> iter 82000, loss: 0.020478
 >> iter 83000, loss: 0.021392
 >> iter 84000, loss: 0.060635
 >> iter 85000, loss: 0.045481
 >> iter 86000, loss: 0.033909
 >> iter 87000, loss: 0.036085
 >> iter 88000, loss: 0.028506
 >> iter 89000, loss: 0.022959
 >> iter 90000, loss: 0.029081
   Number of active neurons: 2
 >> iter 91000, loss: 0.025958
 >> iter 92000, loss: 0.021455
 >> iter 93000, loss: 0.023550
 >> iter 94000, loss: 0.028679
 >> iter 95000, loss: 0.038378
 >> iter 96000, loss: 0.028495
 >> iter 97000, loss: 0.025563
 >> iter 98000, loss: 0.023149
 >> iter 99000, loss: 0.031146
 >> iter 100000, loss: 0.031057
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.945062
 >> iter 2000, loss: 4.070593
 >> iter 3000, loss: 1.528984
 >> iter 4000, loss: 0.582979
 >> iter 5000, loss: 0.242035
 >> iter 6000, loss: 0.114816
 >> iter 7000, loss: 0.065300
 >> iter 8000, loss: 0.048915
 >> iter 9000, loss: 0.061711
 >> iter 10000, loss: 0.047106
   Number of active neurons: 4
 >> iter 11000, loss: 0.038563
 >> iter 12000, loss: 0.030642
 >> iter 13000, loss: 0.035376
 >> iter 14000, loss: 0.031086
 >> iter 15000, loss: 0.030204
 >> iter 16000, loss: 0.030895
 >> iter 17000, loss: 0.027585
 >> iter 18000, loss: 0.025197
 >> iter 19000, loss: 0.024674
 >> iter 20000, loss: 0.029138
   Number of active neurons: 3
 >> iter 21000, loss: 0.024871
 >> iter 22000, loss: 0.023482
 >> iter 23000, loss: 0.042022
 >> iter 24000, loss: 0.041258
 >> iter 25000, loss: 0.029706
 >> iter 26000, loss: 0.026396
 >> iter 27000, loss: 0.041514
 >> iter 28000, loss: 0.037094
 >> iter 29000, loss: 0.030535
 >> iter 30000, loss: 0.023232
   Number of active neurons: 2
 >> iter 31000, loss: 0.029389
 >> iter 32000, loss: 0.026111
 >> iter 33000, loss: 0.029134
 >> iter 34000, loss: 0.027322
 >> iter 35000, loss: 0.022491
 >> iter 36000, loss: 0.020580
 >> iter 37000, loss: 0.022628
 >> iter 38000, loss: 0.021146
 >> iter 39000, loss: 0.020135
 >> iter 40000, loss: 0.028136
   Number of active neurons: 2
 >> iter 41000, loss: 0.023901
 >> iter 42000, loss: 0.041943
 >> iter 43000, loss: 0.035322
 >> iter 44000, loss: 0.027245
 >> iter 45000, loss: 0.026398
 >> iter 46000, loss: 0.033876
 >> iter 47000, loss: 0.024576
 >> iter 48000, loss: 0.022761
 >> iter 49000, loss: 0.023562
 >> iter 50000, loss: 0.026688
   Number of active neurons: 2
 >> iter 51000, loss: 0.023677
 >> iter 52000, loss: 0.039401
 >> iter 53000, loss: 0.029224
 >> iter 54000, loss: 0.023333
 >> iter 55000, loss: 0.022337
 >> iter 56000, loss: 0.020240
 >> iter 57000, loss: 0.028322
 >> iter 58000, loss: 0.023177
 >> iter 59000, loss: 0.021976
 >> iter 60000, loss: 0.020759
   Number of active neurons: 1
 >> iter 61000, loss: 0.024030
 >> iter 62000, loss: 0.025300
 >> iter 63000, loss: 0.019172
 >> iter 64000, loss: 0.017207
 >> iter 65000, loss: 0.020705
 >> iter 66000, loss: 0.018761
 >> iter 67000, loss: 0.030229
 >> iter 68000, loss: 0.063546
 >> iter 69000, loss: 0.034906
 >> iter 70000, loss: 0.033336
   Number of active neurons: 1
 >> iter 71000, loss: 0.022133
 >> iter 72000, loss: 0.018159
 >> iter 73000, loss: 0.021241
 >> iter 74000, loss: 0.018869
 >> iter 75000, loss: 0.022601
 >> iter 76000, loss: 0.032701
 >> iter 77000, loss: 0.038174
 >> iter 78000, loss: 0.024284
 >> iter 79000, loss: 0.019885
 >> iter 80000, loss: 0.032475
   Number of active neurons: 1
 >> iter 81000, loss: 0.022190
 >> iter 82000, loss: 0.020932
 >> iter 83000, loss: 0.019520
 >> iter 84000, loss: 0.024762
 >> iter 85000, loss: 0.019615
 >> iter 86000, loss: 0.018803
 >> iter 87000, loss: 0.026239
 >> iter 88000, loss: 0.020095
 >> iter 89000, loss: 0.022781
 >> iter 90000, loss: 0.019290
   Number of active neurons: 1
 >> iter 91000, loss: 0.020037
 >> iter 92000, loss: 0.018261
 >> iter 93000, loss: 0.019655
 >> iter 94000, loss: 0.037195
 >> iter 95000, loss: 0.037662
 >> iter 96000, loss: 0.031656
 >> iter 97000, loss: 0.023160
 >> iter 98000, loss: 0.024423
 >> iter 99000, loss: 0.046077
 >> iter 100000, loss: 0.027465
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.980675
 >> iter 2000, loss: 4.090738
 >> iter 3000, loss: 1.537275
 >> iter 4000, loss: 0.595570
 >> iter 5000, loss: 0.239260
 >> iter 6000, loss: 0.113605
 >> iter 7000, loss: 0.061988
 >> iter 8000, loss: 0.056105
 >> iter 9000, loss: 0.041414
 >> iter 10000, loss: 0.034058
   Number of active neurons: 4
 >> iter 11000, loss: 0.031884
 >> iter 12000, loss: 0.036906
 >> iter 13000, loss: 0.030124
 >> iter 14000, loss: 0.044242
 >> iter 15000, loss: 0.034630
 >> iter 16000, loss: 0.028190
 >> iter 17000, loss: 0.028679
 >> iter 18000, loss: 0.025772
 >> iter 19000, loss: 0.026246
 >> iter 20000, loss: 0.025423
   Number of active neurons: 4
 >> iter 21000, loss: 0.025868
 >> iter 22000, loss: 0.031045
 >> iter 23000, loss: 0.028517
 >> iter 24000, loss: 0.029265
 >> iter 25000, loss: 0.032260
 >> iter 26000, loss: 0.031146
 >> iter 27000, loss: 0.027510
 >> iter 28000, loss: 0.025092
 >> iter 29000, loss: 0.025460
 >> iter 30000, loss: 0.024337
   Number of active neurons: 4
 >> iter 31000, loss: 0.027761
 >> iter 32000, loss: 0.028721
 >> iter 33000, loss: 0.035910
 >> iter 34000, loss: 0.029222
 >> iter 35000, loss: 0.025236
 >> iter 36000, loss: 0.029595
 >> iter 37000, loss: 0.050700
 >> iter 38000, loss: 0.034845
 >> iter 39000, loss: 0.040399
 >> iter 40000, loss: 0.048762
   Number of active neurons: 2
 >> iter 41000, loss: 0.029549
 >> iter 42000, loss: 0.024477
 >> iter 43000, loss: 0.025840
 >> iter 44000, loss: 0.022944
 >> iter 45000, loss: 0.023490
 >> iter 46000, loss: 0.022632
 >> iter 47000, loss: 0.022267
 >> iter 48000, loss: 0.023009
 >> iter 49000, loss: 0.022052
 >> iter 50000, loss: 0.024678
   Number of active neurons: 2
 >> iter 51000, loss: 0.060017
 >> iter 52000, loss: 0.048945
 >> iter 53000, loss: 0.031728
 >> iter 54000, loss: 0.029179
 >> iter 55000, loss: 0.030855
 >> iter 56000, loss: 0.024750
 >> iter 57000, loss: 0.022242
 >> iter 58000, loss: 0.020207
 >> iter 59000, loss: 0.020164
 >> iter 60000, loss: 0.023451
   Number of active neurons: 1
 >> iter 61000, loss: 0.025860
 >> iter 62000, loss: 0.022164
 >> iter 63000, loss: 0.022309
 >> iter 64000, loss: 0.019214
 >> iter 65000, loss: 0.040320
 >> iter 66000, loss: 0.026015
 >> iter 67000, loss: 0.020746
 >> iter 68000, loss: 0.020017
 >> iter 69000, loss: 0.020014
 >> iter 70000, loss: 0.025375
   Number of active neurons: 1
 >> iter 71000, loss: 0.023546
 >> iter 72000, loss: 0.019616
 >> iter 73000, loss: 0.020899
 >> iter 74000, loss: 0.020032
 >> iter 75000, loss: 0.022412
 >> iter 76000, loss: 0.019599
 >> iter 77000, loss: 0.024503
 >> iter 78000, loss: 0.020233
 >> iter 79000, loss: 0.017073
 >> iter 80000, loss: 0.019609
   Number of active neurons: 1
 >> iter 81000, loss: 0.035722
 >> iter 82000, loss: 0.030433
 >> iter 83000, loss: 0.023410
 >> iter 84000, loss: 0.022845
 >> iter 85000, loss: 0.020126
 >> iter 86000, loss: 0.051155
 >> iter 87000, loss: 0.031916
 >> iter 88000, loss: 0.023365
 >> iter 89000, loss: 0.019325
 >> iter 90000, loss: 0.019707
   Number of active neurons: 1
 >> iter 91000, loss: 0.021035
 >> iter 92000, loss: 0.018277
 >> iter 93000, loss: 0.019147
 >> iter 94000, loss: 0.017178
 >> iter 95000, loss: 0.029779
 >> iter 96000, loss: 0.027444
 >> iter 97000, loss: 0.023383
 >> iter 98000, loss: 0.041074
 >> iter 99000, loss: 0.025898
 >> iter 100000, loss: 0.022129
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.999767
 >> iter 2000, loss: 4.088052
 >> iter 3000, loss: 1.543031
 >> iter 4000, loss: 0.590411
 >> iter 5000, loss: 0.239882
 >> iter 6000, loss: 0.109023
 >> iter 7000, loss: 0.061311
 >> iter 8000, loss: 0.043746
 >> iter 9000, loss: 0.037035
 >> iter 10000, loss: 0.032616
   Number of active neurons: 5
 >> iter 11000, loss: 0.049884
 >> iter 12000, loss: 0.052393
 >> iter 13000, loss: 0.041064
 >> iter 14000, loss: 0.037661
 >> iter 15000, loss: 0.030686
 >> iter 16000, loss: 0.046330
 >> iter 17000, loss: 0.036909
 >> iter 18000, loss: 0.035064
 >> iter 19000, loss: 0.033933
 >> iter 20000, loss: 0.027738
   Number of active neurons: 4
 >> iter 21000, loss: 0.024893
 >> iter 22000, loss: 0.025525
 >> iter 23000, loss: 0.028013
 >> iter 24000, loss: 0.023102
 >> iter 25000, loss: 0.023542
 >> iter 26000, loss: 0.027501
 >> iter 27000, loss: 0.024196
 >> iter 28000, loss: 0.030509
 >> iter 29000, loss: 0.030464
 >> iter 30000, loss: 0.025910
   Number of active neurons: 3
 >> iter 31000, loss: 0.032590
 >> iter 32000, loss: 0.036459
 >> iter 33000, loss: 0.032707
 >> iter 34000, loss: 0.028827
 >> iter 35000, loss: 0.024985
 >> iter 36000, loss: 0.024095
 >> iter 37000, loss: 0.034961
 >> iter 38000, loss: 0.027488
 >> iter 39000, loss: 0.026082
 >> iter 40000, loss: 0.025284
   Number of active neurons: 3
 >> iter 41000, loss: 0.023289
 >> iter 42000, loss: 0.024493
 >> iter 43000, loss: 0.025884
 >> iter 44000, loss: 0.028114
 >> iter 45000, loss: 0.040937
 >> iter 46000, loss: 0.030234
 >> iter 47000, loss: 0.024929
 >> iter 48000, loss: 0.023239
 >> iter 49000, loss: 0.024515
 >> iter 50000, loss: 0.021731
   Number of active neurons: 2
 >> iter 51000, loss: 0.023251
 >> iter 52000, loss: 0.026007
 >> iter 53000, loss: 0.041037
 >> iter 54000, loss: 0.046323
 >> iter 55000, loss: 0.032680
 >> iter 56000, loss: 0.041021
 >> iter 57000, loss: 0.027628
 >> iter 58000, loss: 0.023460
 >> iter 59000, loss: 0.034340
 >> iter 60000, loss: 0.029710
   Number of active neurons: 2
 >> iter 61000, loss: 0.024592
 >> iter 62000, loss: 0.021969
 >> iter 63000, loss: 0.026842
 >> iter 64000, loss: 0.034356
 >> iter 65000, loss: 0.026114
 >> iter 66000, loss: 0.025961
 >> iter 67000, loss: 0.023959
 >> iter 68000, loss: 0.025811
 >> iter 69000, loss: 0.029348
 >> iter 70000, loss: 0.023301
   Number of active neurons: 2
 >> iter 71000, loss: 0.022138
 >> iter 72000, loss: 0.019957
 >> iter 73000, loss: 0.038970
 >> iter 74000, loss: 0.036181
 >> iter 75000, loss: 0.030780
 >> iter 76000, loss: 0.023600
 >> iter 77000, loss: 0.025718
 >> iter 78000, loss: 0.028310
 >> iter 79000, loss: 0.025332
 >> iter 80000, loss: 0.024336
   Number of active neurons: 1
 >> iter 81000, loss: 0.027648
 >> iter 82000, loss: 0.021510
 >> iter 83000, loss: 0.022742
 >> iter 84000, loss: 0.019942
 >> iter 85000, loss: 0.023529
 >> iter 86000, loss: 0.020589
 >> iter 87000, loss: 0.019295
 >> iter 88000, loss: 0.019523
 >> iter 89000, loss: 0.018194
 >> iter 90000, loss: 0.023532
   Number of active neurons: 1
 >> iter 91000, loss: 0.026080
 >> iter 92000, loss: 0.021253
 >> iter 93000, loss: 0.027463
 >> iter 94000, loss: 0.026145
 >> iter 95000, loss: 0.021095
 >> iter 96000, loss: 0.017689
 >> iter 97000, loss: 0.019151
 >> iter 98000, loss: 0.023611
 >> iter 99000, loss: 0.019951
 >> iter 100000, loss: 0.017587
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.983938
 >> iter 2000, loss: 4.082266
 >> iter 3000, loss: 1.534425
 >> iter 4000, loss: 0.595851
 >> iter 5000, loss: 0.239635
 >> iter 6000, loss: 0.113316
 >> iter 7000, loss: 0.061796
 >> iter 8000, loss: 0.044272
 >> iter 9000, loss: 0.052216
 >> iter 10000, loss: 0.052366
   Number of active neurons: 6
 >> iter 11000, loss: 0.041938
 >> iter 12000, loss: 0.033622
 >> iter 13000, loss: 0.039521
 >> iter 14000, loss: 0.031235
 >> iter 15000, loss: 0.028357
 >> iter 16000, loss: 0.045309
 >> iter 17000, loss: 0.032550
 >> iter 18000, loss: 0.029116
 >> iter 19000, loss: 0.028359
 >> iter 20000, loss: 0.027805
   Number of active neurons: 4
 >> iter 21000, loss: 0.030183
 >> iter 22000, loss: 0.031694
 >> iter 23000, loss: 0.026610
 >> iter 24000, loss: 0.024659
 >> iter 25000, loss: 0.027184
 >> iter 26000, loss: 0.039027
 >> iter 27000, loss: 0.031371
 >> iter 28000, loss: 0.026733
 >> iter 29000, loss: 0.027285
 >> iter 30000, loss: 0.027112
   Number of active neurons: 3
 >> iter 31000, loss: 0.035261
 >> iter 32000, loss: 0.026757
 >> iter 33000, loss: 0.025716
 >> iter 34000, loss: 0.023975
 >> iter 35000, loss: 0.024090
 >> iter 36000, loss: 0.025879
 >> iter 37000, loss: 0.023717
 >> iter 38000, loss: 0.026946
 >> iter 39000, loss: 0.025968
 >> iter 40000, loss: 0.031841
   Number of active neurons: 3
 >> iter 41000, loss: 0.040461
 >> iter 42000, loss: 0.028488
 >> iter 43000, loss: 0.026087
 >> iter 44000, loss: 0.023956
 >> iter 45000, loss: 0.024000
 >> iter 46000, loss: 0.036315
 >> iter 47000, loss: 0.029736
 >> iter 48000, loss: 0.024296
 >> iter 49000, loss: 0.023547
 >> iter 50000, loss: 0.025289
   Number of active neurons: 3
 >> iter 51000, loss: 0.027679
 >> iter 52000, loss: 0.028708
 >> iter 53000, loss: 0.028014
 >> iter 54000, loss: 0.027491
 >> iter 55000, loss: 0.027071
 >> iter 56000, loss: 0.025883
 >> iter 57000, loss: 0.023204
 >> iter 58000, loss: 0.021869
 >> iter 59000, loss: 0.025744
 >> iter 60000, loss: 0.022956
   Number of active neurons: 2
 >> iter 61000, loss: 0.027266
 >> iter 62000, loss: 0.023601
 >> iter 63000, loss: 0.039074
 >> iter 64000, loss: 0.031931
 >> iter 65000, loss: 0.025979
 >> iter 66000, loss: 0.023179
 >> iter 67000, loss: 0.020938
 >> iter 68000, loss: 0.020539
 >> iter 69000, loss: 0.021118
 >> iter 70000, loss: 0.021036
   Number of active neurons: 2
 >> iter 71000, loss: 0.024664
 >> iter 72000, loss: 0.070471
 >> iter 73000, loss: 0.041118
 >> iter 74000, loss: 0.036461
 >> iter 75000, loss: 0.026260
 >> iter 76000, loss: 0.022743
 >> iter 77000, loss: 0.022554
 >> iter 78000, loss: 0.021669
 >> iter 79000, loss: 0.025576
 >> iter 80000, loss: 0.024025
   Number of active neurons: 2
 >> iter 81000, loss: 0.027449
 >> iter 82000, loss: 0.026341
 >> iter 83000, loss: 0.024574
 >> iter 84000, loss: 0.028195
 >> iter 85000, loss: 0.023302
 >> iter 86000, loss: 0.034029
 >> iter 87000, loss: 0.028339
 >> iter 88000, loss: 0.037144
 >> iter 89000, loss: 0.029435
 >> iter 90000, loss: 0.023288
   Number of active neurons: 1
 >> iter 91000, loss: 0.045796
 >> iter 92000, loss: 0.035693
 >> iter 93000, loss: 0.026459
 >> iter 94000, loss: 0.021639
 >> iter 95000, loss: 0.019446
 >> iter 96000, loss: 0.018399
 >> iter 97000, loss: 0.017548
 >> iter 98000, loss: 0.026642
 >> iter 99000, loss: 0.027959
 >> iter 100000, loss: 0.025741
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.010835
 >> iter 2000, loss: 4.091656
 >> iter 3000, loss: 1.544856
 >> iter 4000, loss: 0.590769
 >> iter 5000, loss: 0.236827
 >> iter 6000, loss: 0.114234
 >> iter 7000, loss: 0.061698
 >> iter 8000, loss: 0.043946
 >> iter 9000, loss: 0.036212
 >> iter 10000, loss: 0.029191
   Number of active neurons: 4
 >> iter 11000, loss: 0.029468
 >> iter 12000, loss: 0.030821
 >> iter 13000, loss: 0.026374
 >> iter 14000, loss: 0.027189
 >> iter 15000, loss: 0.027274
 >> iter 16000, loss: 0.030830
 >> iter 17000, loss: 0.029998
 >> iter 18000, loss: 0.026721
 >> iter 19000, loss: 0.028547
 >> iter 20000, loss: 0.027818
   Number of active neurons: 4
 >> iter 21000, loss: 0.029722
 >> iter 22000, loss: 0.026684
 >> iter 23000, loss: 0.025264
 >> iter 24000, loss: 0.030214
 >> iter 25000, loss: 0.028882
 >> iter 26000, loss: 0.028681
 >> iter 27000, loss: 0.026035
 >> iter 28000, loss: 0.026818
 >> iter 29000, loss: 0.049634
 >> iter 30000, loss: 0.035775
   Number of active neurons: 4
 >> iter 31000, loss: 0.028394
 >> iter 32000, loss: 0.027456
 >> iter 33000, loss: 0.029030
 >> iter 34000, loss: 0.028615
 >> iter 35000, loss: 0.025194
 >> iter 36000, loss: 0.028717
 >> iter 37000, loss: 0.027527
 >> iter 38000, loss: 0.025867
 >> iter 39000, loss: 0.028684
 >> iter 40000, loss: 0.052426
   Number of active neurons: 3
 >> iter 41000, loss: 0.042860
 >> iter 42000, loss: 0.036107
 >> iter 43000, loss: 0.029635
 >> iter 44000, loss: 0.030162
 >> iter 45000, loss: 0.037018
 >> iter 46000, loss: 0.027266
 >> iter 47000, loss: 0.027584
 >> iter 48000, loss: 0.024780
 >> iter 49000, loss: 0.021789
 >> iter 50000, loss: 0.024575
   Number of active neurons: 2
 >> iter 51000, loss: 0.023020
 >> iter 52000, loss: 0.022277
 >> iter 53000, loss: 0.021997
 >> iter 54000, loss: 0.020435
 >> iter 55000, loss: 0.020686
 >> iter 56000, loss: 0.021583
 >> iter 57000, loss: 0.020262
 >> iter 58000, loss: 0.021363
 >> iter 59000, loss: 0.024384
 >> iter 60000, loss: 0.024938
   Number of active neurons: 2
 >> iter 61000, loss: 0.025062
 >> iter 62000, loss: 0.022109
 >> iter 63000, loss: 0.036188
 >> iter 64000, loss: 0.052718
 >> iter 65000, loss: 0.053745
 >> iter 66000, loss: 0.033794
 >> iter 67000, loss: 0.025894
 >> iter 68000, loss: 0.020073
 >> iter 69000, loss: 0.022720
 >> iter 70000, loss: 0.028430
   Number of active neurons: 1
 >> iter 71000, loss: 0.023220
 >> iter 72000, loss: 0.018540
 >> iter 73000, loss: 0.017477
 >> iter 74000, loss: 0.020910
 >> iter 75000, loss: 0.024528
 >> iter 76000, loss: 0.036960
 >> iter 77000, loss: 0.023915
 >> iter 78000, loss: 0.030213
 >> iter 79000, loss: 0.023489
 >> iter 80000, loss: 0.021746
   Number of active neurons: 1
 >> iter 81000, loss: 0.021875
 >> iter 82000, loss: 0.017840
 >> iter 83000, loss: 0.020472
 >> iter 84000, loss: 0.019912
 >> iter 85000, loss: 0.027080
 >> iter 86000, loss: 0.031478
 >> iter 87000, loss: 0.022620
 >> iter 88000, loss: 0.029170
 >> iter 89000, loss: 0.020138
 >> iter 90000, loss: 0.019764
   Number of active neurons: 1
 >> iter 91000, loss: 0.024160
 >> iter 92000, loss: 0.018623
 >> iter 93000, loss: 0.023321
 >> iter 94000, loss: 0.028388
 >> iter 95000, loss: 0.030230
 >> iter 96000, loss: 0.025489
 >> iter 97000, loss: 0.021833
 >> iter 98000, loss: 0.019163
 >> iter 99000, loss: 0.032347
 >> iter 100000, loss: 0.022877
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.933923
 >> iter 2000, loss: 4.068746
 >> iter 3000, loss: 1.525424
 >> iter 4000, loss: 0.581865
 >> iter 5000, loss: 0.234081
 >> iter 6000, loss: 0.107871
 >> iter 7000, loss: 0.073593
 >> iter 8000, loss: 0.044242
 >> iter 9000, loss: 0.034738
 >> iter 10000, loss: 0.030462
   Number of active neurons: 3
 >> iter 11000, loss: 0.026678
 >> iter 12000, loss: 0.026274
 >> iter 13000, loss: 0.025183
 >> iter 14000, loss: 0.025794
 >> iter 15000, loss: 0.027376
 >> iter 16000, loss: 0.028428
 >> iter 17000, loss: 0.028136
 >> iter 18000, loss: 0.027333
 >> iter 19000, loss: 0.032005
 >> iter 20000, loss: 0.028152
   Number of active neurons: 3
 >> iter 21000, loss: 0.033659
 >> iter 22000, loss: 0.029401
 >> iter 23000, loss: 0.025661
 >> iter 24000, loss: 0.025906
 >> iter 25000, loss: 0.030135
 >> iter 26000, loss: 0.035181
 >> iter 27000, loss: 0.029704
 >> iter 28000, loss: 0.030364
 >> iter 29000, loss: 0.026326
 >> iter 30000, loss: 0.028599
   Number of active neurons: 3
 >> iter 31000, loss: 0.026170
 >> iter 32000, loss: 0.025372
 >> iter 33000, loss: 0.025542
 >> iter 34000, loss: 0.023020
 >> iter 35000, loss: 0.025104
 >> iter 36000, loss: 0.025372
 >> iter 37000, loss: 0.024678
 >> iter 38000, loss: 0.024141
 >> iter 39000, loss: 0.023615
 >> iter 40000, loss: 0.025784
   Number of active neurons: 3
 >> iter 41000, loss: 0.029457
 >> iter 42000, loss: 0.030305
 >> iter 43000, loss: 0.026846
 >> iter 44000, loss: 0.023670
 >> iter 45000, loss: 0.032470
 >> iter 46000, loss: 0.024158
 >> iter 47000, loss: 0.024209
 >> iter 48000, loss: 0.030162
 >> iter 49000, loss: 0.023736
 >> iter 50000, loss: 0.026433
   Number of active neurons: 2
 >> iter 51000, loss: 0.028620
 >> iter 52000, loss: 0.032669
 >> iter 53000, loss: 0.029025
 >> iter 54000, loss: 0.025321
 >> iter 55000, loss: 0.023172
 >> iter 56000, loss: 0.025147
 >> iter 57000, loss: 0.027068
 >> iter 58000, loss: 0.022665
 >> iter 59000, loss: 0.026893
 >> iter 60000, loss: 0.023334
   Number of active neurons: 2
 >> iter 61000, loss: 0.034271
 >> iter 62000, loss: 0.026321
 >> iter 63000, loss: 0.023399
 >> iter 64000, loss: 0.021203
 >> iter 65000, loss: 0.023630
 >> iter 66000, loss: 0.022786
 >> iter 67000, loss: 0.023641
 >> iter 68000, loss: 0.022342
 >> iter 69000, loss: 0.020120
 >> iter 70000, loss: 0.030560
   Number of active neurons: 1
 >> iter 71000, loss: 0.024895
 >> iter 72000, loss: 0.021965
 >> iter 73000, loss: 0.022569
 >> iter 74000, loss: 0.019847
 >> iter 75000, loss: 0.018512
 >> iter 76000, loss: 0.019907
 >> iter 77000, loss: 0.020119
 >> iter 78000, loss: 0.020009
 >> iter 79000, loss: 0.022985
 >> iter 80000, loss: 0.017754
   Number of active neurons: 1
 >> iter 81000, loss: 0.017355
 >> iter 82000, loss: 0.022651
 >> iter 83000, loss: 0.021325
 >> iter 84000, loss: 0.017571
 >> iter 85000, loss: 0.025997
 >> iter 86000, loss: 0.022305
 >> iter 87000, loss: 0.023648
 >> iter 88000, loss: 0.018397
 >> iter 89000, loss: 0.016665
 >> iter 90000, loss: 0.017781
   Number of active neurons: 1
 >> iter 91000, loss: 0.027153
 >> iter 92000, loss: 0.019397
 >> iter 93000, loss: 0.017531
 >> iter 94000, loss: 0.019281
 >> iter 95000, loss: 0.021042
 >> iter 96000, loss: 0.020734
 >> iter 97000, loss: 0.031256
 >> iter 98000, loss: 0.025377
 >> iter 99000, loss: 0.020034
 >> iter 100000, loss: 0.017852
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.979597
 >> iter 2000, loss: 4.106093
 >> iter 3000, loss: 1.540559
 >> iter 4000, loss: 0.600802
 >> iter 5000, loss: 0.275694
 >> iter 6000, loss: 0.129496
 >> iter 7000, loss: 0.069232
 >> iter 8000, loss: 0.047476
 >> iter 9000, loss: 0.043881
 >> iter 10000, loss: 0.051805
   Number of active neurons: 5
 >> iter 11000, loss: 0.045641
 >> iter 12000, loss: 0.040312
 >> iter 13000, loss: 0.032694
 >> iter 14000, loss: 0.030073
 >> iter 15000, loss: 0.029756
 >> iter 16000, loss: 0.027133
 >> iter 17000, loss: 0.024652
 >> iter 18000, loss: 0.023785
 >> iter 19000, loss: 0.039935
 >> iter 20000, loss: 0.033670
   Number of active neurons: 2
 >> iter 21000, loss: 0.026821
 >> iter 22000, loss: 0.025838
 >> iter 23000, loss: 0.030544
 >> iter 24000, loss: 0.025570
 >> iter 25000, loss: 0.023983
 >> iter 26000, loss: 0.026511
 >> iter 27000, loss: 0.026293
 >> iter 28000, loss: 0.022771
 >> iter 29000, loss: 0.023354
 >> iter 30000, loss: 0.023611
   Number of active neurons: 2
 >> iter 31000, loss: 0.024277
 >> iter 32000, loss: 0.022074
 >> iter 33000, loss: 0.020434
 >> iter 34000, loss: 0.020588
 >> iter 35000, loss: 0.037521
 >> iter 36000, loss: 0.027059
 >> iter 37000, loss: 0.032840
 >> iter 38000, loss: 0.028360
 >> iter 39000, loss: 0.032478
 >> iter 40000, loss: 0.025920
   Number of active neurons: 2
 >> iter 41000, loss: 0.024488
 >> iter 42000, loss: 0.023234
 >> iter 43000, loss: 0.028069
 >> iter 44000, loss: 0.028846
 >> iter 45000, loss: 0.023919
 >> iter 46000, loss: 0.025418
 >> iter 47000, loss: 0.020631
 >> iter 48000, loss: 0.024450
 >> iter 49000, loss: 0.026342
 >> iter 50000, loss: 0.021952
   Number of active neurons: 2
 >> iter 51000, loss: 0.020418
 >> iter 52000, loss: 0.021300
 >> iter 53000, loss: 0.026864
 >> iter 54000, loss: 0.022688
 >> iter 55000, loss: 0.032686
 >> iter 56000, loss: 0.032368
 >> iter 57000, loss: 0.025578
 >> iter 58000, loss: 0.023673
 >> iter 59000, loss: 0.038772
 >> iter 60000, loss: 0.027520
   Number of active neurons: 2
 >> iter 61000, loss: 0.022618
 >> iter 62000, loss: 0.024801
 >> iter 63000, loss: 0.032118
 >> iter 64000, loss: 0.025253
 >> iter 65000, loss: 0.023644
 >> iter 66000, loss: 0.023240
 >> iter 67000, loss: 0.020994
 >> iter 68000, loss: 0.020548
 >> iter 69000, loss: 0.030361
 >> iter 70000, loss: 0.024950
   Number of active neurons: 2
 >> iter 71000, loss: 0.024628
 >> iter 72000, loss: 0.029171
 >> iter 73000, loss: 0.025440
 >> iter 74000, loss: 0.025769
 >> iter 75000, loss: 0.025167
 >> iter 76000, loss: 0.035174
 >> iter 77000, loss: 0.028254
 >> iter 78000, loss: 0.048656
 >> iter 79000, loss: 0.032305
 >> iter 80000, loss: 0.023963
   Number of active neurons: 1
 >> iter 81000, loss: 0.021106
 >> iter 82000, loss: 0.027630
 >> iter 83000, loss: 0.023002
 >> iter 84000, loss: 0.023872
 >> iter 85000, loss: 0.022048
 >> iter 86000, loss: 0.021038
 >> iter 87000, loss: 0.046456
 >> iter 88000, loss: 0.028364
 >> iter 89000, loss: 0.021952
 >> iter 90000, loss: 0.029949
   Number of active neurons: 1
 >> iter 91000, loss: 0.023663
 >> iter 92000, loss: 0.021235
 >> iter 93000, loss: 0.023834
 >> iter 94000, loss: 0.019093
 >> iter 95000, loss: 0.018235
 >> iter 96000, loss: 0.025877
 >> iter 97000, loss: 0.029040
 >> iter 98000, loss: 0.024431
 >> iter 99000, loss: 0.021402
 >> iter 100000, loss: 0.018911
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.069301
 >> iter 2000, loss: 4.123524
 >> iter 3000, loss: 1.544958
 >> iter 4000, loss: 0.591127
 >> iter 5000, loss: 0.241456
 >> iter 6000, loss: 0.110948
 >> iter 7000, loss: 0.064983
 >> iter 8000, loss: 0.051948
 >> iter 9000, loss: 0.037421
 >> iter 10000, loss: 0.032692
   Number of active neurons: 6
 >> iter 11000, loss: 0.032279
 >> iter 12000, loss: 0.034066
 >> iter 13000, loss: 0.031121
 >> iter 14000, loss: 0.039613
 >> iter 15000, loss: 0.040073
 >> iter 16000, loss: 0.032876
 >> iter 17000, loss: 0.032629
 >> iter 18000, loss: 0.046072
 >> iter 19000, loss: 0.034249
 >> iter 20000, loss: 0.033311
   Number of active neurons: 4
 >> iter 21000, loss: 0.028527
 >> iter 22000, loss: 0.026091
 >> iter 23000, loss: 0.026118
 >> iter 24000, loss: 0.029363
 >> iter 25000, loss: 0.025628
 >> iter 26000, loss: 0.024145
 >> iter 27000, loss: 0.023720
 >> iter 28000, loss: 0.025141
 >> iter 29000, loss: 0.024093
 >> iter 30000, loss: 0.030175
   Number of active neurons: 3
 >> iter 31000, loss: 0.034175
 >> iter 32000, loss: 0.025928
 >> iter 33000, loss: 0.024816
 >> iter 34000, loss: 0.023239
 >> iter 35000, loss: 0.023951
 >> iter 36000, loss: 0.024440
 >> iter 37000, loss: 0.023928
 >> iter 38000, loss: 0.027840
 >> iter 39000, loss: 0.024083
 >> iter 40000, loss: 0.022160
   Number of active neurons: 3
 >> iter 41000, loss: 0.024824
 >> iter 42000, loss: 0.023529
 >> iter 43000, loss: 0.032015
 >> iter 44000, loss: 0.030883
 >> iter 45000, loss: 0.025317
 >> iter 46000, loss: 0.028550
 >> iter 47000, loss: 0.052089
 >> iter 48000, loss: 0.032113
 >> iter 49000, loss: 0.024125
 >> iter 50000, loss: 0.024256
   Number of active neurons: 2
 >> iter 51000, loss: 0.021610
 >> iter 52000, loss: 0.029305
 >> iter 53000, loss: 0.027342
 >> iter 54000, loss: 0.027375
 >> iter 55000, loss: 0.031132
 >> iter 56000, loss: 0.039997
 >> iter 57000, loss: 0.030596
 >> iter 58000, loss: 0.025331
 >> iter 59000, loss: 0.023977
 >> iter 60000, loss: 0.029307
   Number of active neurons: 2
 >> iter 61000, loss: 0.023744
 >> iter 62000, loss: 0.021325
 >> iter 63000, loss: 0.031104
 >> iter 64000, loss: 0.027107
 >> iter 65000, loss: 0.024818
 >> iter 66000, loss: 0.024578
 >> iter 67000, loss: 0.025579
 >> iter 68000, loss: 0.031575
 >> iter 69000, loss: 0.026906
 >> iter 70000, loss: 0.023750
   Number of active neurons: 1
 >> iter 71000, loss: 0.043424
 >> iter 72000, loss: 0.028822
 >> iter 73000, loss: 0.030534
 >> iter 74000, loss: 0.031161
 >> iter 75000, loss: 0.023141
 >> iter 76000, loss: 0.034815
 >> iter 77000, loss: 0.023960
 >> iter 78000, loss: 0.034261
 >> iter 79000, loss: 0.024308
 >> iter 80000, loss: 0.033875
   Number of active neurons: 1
 >> iter 81000, loss: 0.026577
 >> iter 82000, loss: 0.022524
 >> iter 83000, loss: 0.019696
 >> iter 84000, loss: 0.017230
 >> iter 85000, loss: 0.018446
 >> iter 86000, loss: 0.022570
 >> iter 87000, loss: 0.018479
 >> iter 88000, loss: 0.019652
 >> iter 89000, loss: 0.019085
 >> iter 90000, loss: 0.017957
   Number of active neurons: 1
 >> iter 91000, loss: 0.030365
 >> iter 92000, loss: 0.021614
 >> iter 93000, loss: 0.026266
 >> iter 94000, loss: 0.023653
 >> iter 95000, loss: 0.019227
 >> iter 96000, loss: 0.020701
 >> iter 97000, loss: 0.017741
 >> iter 98000, loss: 0.020837
 >> iter 99000, loss: 0.018133
 >> iter 100000, loss: 0.017728
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 11.021470
 >> iter 2000, loss: 4.108528
 >> iter 3000, loss: 1.555194
 >> iter 4000, loss: 0.595222
 >> iter 5000, loss: 0.242647
 >> iter 6000, loss: 0.113037
 >> iter 7000, loss: 0.066691
 >> iter 8000, loss: 0.042838
 >> iter 9000, loss: 0.034585
 >> iter 10000, loss: 0.032641
   Number of active neurons: 4
 >> iter 11000, loss: 0.030728
 >> iter 12000, loss: 0.026854
 >> iter 13000, loss: 0.027158
 >> iter 14000, loss: 0.028247
 >> iter 15000, loss: 0.029408
 >> iter 16000, loss: 0.027188
 >> iter 17000, loss: 0.027481
 >> iter 18000, loss: 0.027809
 >> iter 19000, loss: 0.024704
 >> iter 20000, loss: 0.024276
   Number of active neurons: 3
 >> iter 21000, loss: 0.031551
 >> iter 22000, loss: 0.027890
 >> iter 23000, loss: 0.025180
 >> iter 24000, loss: 0.033895
 >> iter 25000, loss: 0.039021
 >> iter 26000, loss: 0.027519
 >> iter 27000, loss: 0.025395
 >> iter 28000, loss: 0.025521
 >> iter 29000, loss: 0.024482
 >> iter 30000, loss: 0.030075
   Number of active neurons: 3
 >> iter 31000, loss: 0.024400
 >> iter 32000, loss: 0.028897
 >> iter 33000, loss: 0.025347
 >> iter 34000, loss: 0.024711
 >> iter 35000, loss: 0.029216
 >> iter 36000, loss: 0.033089
 >> iter 37000, loss: 0.025794
 >> iter 38000, loss: 0.028630
 >> iter 39000, loss: 0.034882
 >> iter 40000, loss: 0.026220
   Number of active neurons: 3
 >> iter 41000, loss: 0.024269
 >> iter 42000, loss: 0.023971
 >> iter 43000, loss: 0.025915
 >> iter 44000, loss: 0.021707
 >> iter 45000, loss: 0.030357
 >> iter 46000, loss: 0.054166
 >> iter 47000, loss: 0.032984
 >> iter 48000, loss: 0.027464
 >> iter 49000, loss: 0.023980
 >> iter 50000, loss: 0.026685
   Number of active neurons: 2
 >> iter 51000, loss: 0.029760
 >> iter 52000, loss: 0.024570
 >> iter 53000, loss: 0.025391
 >> iter 54000, loss: 0.020811
 >> iter 55000, loss: 0.020448
 >> iter 56000, loss: 0.027772
 >> iter 57000, loss: 0.023509
 >> iter 58000, loss: 0.023729
 >> iter 59000, loss: 0.032625
 >> iter 60000, loss: 0.027141
   Number of active neurons: 2
 >> iter 61000, loss: 0.044272
 >> iter 62000, loss: 0.031552
 >> iter 63000, loss: 0.024701
 >> iter 64000, loss: 0.023528
 >> iter 65000, loss: 0.021934
 >> iter 66000, loss: 0.033441
 >> iter 67000, loss: 0.026721
 >> iter 68000, loss: 0.024298
 >> iter 69000, loss: 0.026587
 >> iter 70000, loss: 0.026001
   Number of active neurons: 2
 >> iter 71000, loss: 0.022754
 >> iter 72000, loss: 0.023667
 >> iter 73000, loss: 0.025210
 >> iter 74000, loss: 0.023660
 >> iter 75000, loss: 0.023527
 >> iter 76000, loss: 0.027765
 >> iter 77000, loss: 0.021876
 >> iter 78000, loss: 0.022800
 >> iter 79000, loss: 0.019972
 >> iter 80000, loss: 0.022412
   Number of active neurons: 2
 >> iter 81000, loss: 0.027826
 >> iter 82000, loss: 0.023927
 >> iter 83000, loss: 0.024613
 >> iter 84000, loss: 0.021882
 >> iter 85000, loss: 0.023366
 >> iter 86000, loss: 0.020990
 >> iter 87000, loss: 0.023236
 >> iter 88000, loss: 0.026531
 >> iter 89000, loss: 0.036034
 >> iter 90000, loss: 0.025487
   Number of active neurons: 2
 >> iter 91000, loss: 0.024767
 >> iter 92000, loss: 0.024652
 >> iter 93000, loss: 0.022461
 >> iter 94000, loss: 0.023315
 >> iter 95000, loss: 0.023507
 >> iter 96000, loss: 0.020726
 >> iter 97000, loss: 0.020416
 >> iter 98000, loss: 0.021231
 >> iter 99000, loss: 0.023557
 >> iter 100000, loss: 0.022252
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.943679
 >> iter 2000, loss: 4.075358
 >> iter 3000, loss: 1.546602
 >> iter 4000, loss: 0.588535
 >> iter 5000, loss: 0.237918
 >> iter 6000, loss: 0.109116
 >> iter 7000, loss: 0.064707
 >> iter 8000, loss: 0.052562
 >> iter 9000, loss: 0.040544
 >> iter 10000, loss: 0.036303
   Number of active neurons: 6
 >> iter 11000, loss: 0.033107
 >> iter 12000, loss: 0.029244
 >> iter 13000, loss: 0.029403
 >> iter 14000, loss: 0.033221
 >> iter 15000, loss: 0.031476
 >> iter 16000, loss: 0.031333
 >> iter 17000, loss: 0.028385
 >> iter 18000, loss: 0.037051
 >> iter 19000, loss: 0.031155
 >> iter 20000, loss: 0.029824
   Number of active neurons: 4
 >> iter 21000, loss: 0.028076
 >> iter 22000, loss: 0.036589
 >> iter 23000, loss: 0.033915
 >> iter 24000, loss: 0.031376
 >> iter 25000, loss: 0.037889
 >> iter 26000, loss: 0.035404
 >> iter 27000, loss: 0.031913
 >> iter 28000, loss: 0.027309
 >> iter 29000, loss: 0.039361
 >> iter 30000, loss: 0.039162
   Number of active neurons: 3
 >> iter 31000, loss: 0.034156
 >> iter 32000, loss: 0.032623
 >> iter 33000, loss: 0.030943
 >> iter 34000, loss: 0.027505
 >> iter 35000, loss: 0.025559
 >> iter 36000, loss: 0.077072
 >> iter 37000, loss: 0.043701
 >> iter 38000, loss: 0.038072
 >> iter 39000, loss: 0.028265
 >> iter 40000, loss: 0.037052
   Number of active neurons: 2
 >> iter 41000, loss: 0.027784
 >> iter 42000, loss: 0.029308
 >> iter 43000, loss: 0.024755
 >> iter 44000, loss: 0.024998
 >> iter 45000, loss: 0.055661
 >> iter 46000, loss: 0.041297
 >> iter 47000, loss: 0.031492
 >> iter 48000, loss: 0.029960
 >> iter 49000, loss: 0.030630
 >> iter 50000, loss: 0.029532
   Number of active neurons: 2
 >> iter 51000, loss: 0.023085
 >> iter 52000, loss: 0.028454
 >> iter 53000, loss: 0.028160
 >> iter 54000, loss: 0.059982
 >> iter 55000, loss: 0.038649
 >> iter 56000, loss: 0.034096
 >> iter 57000, loss: 0.025919
 >> iter 58000, loss: 0.021874
 >> iter 59000, loss: 0.020861
 >> iter 60000, loss: 0.034002
   Number of active neurons: 2
 >> iter 61000, loss: 0.028705
 >> iter 62000, loss: 0.024955
 >> iter 63000, loss: 0.023679
 >> iter 64000, loss: 0.021111
 >> iter 65000, loss: 0.022218
 >> iter 66000, loss: 0.024144
 >> iter 67000, loss: 0.034543
 >> iter 68000, loss: 0.028464
 >> iter 69000, loss: 0.024166
 >> iter 70000, loss: 0.024355
   Number of active neurons: 2
 >> iter 71000, loss: 0.021838
 >> iter 72000, loss: 0.020177
 >> iter 73000, loss: 0.020985
 >> iter 74000, loss: 0.022926
 >> iter 75000, loss: 0.030302
 >> iter 76000, loss: 0.023114
 >> iter 77000, loss: 0.036478
 >> iter 78000, loss: 0.026390
 >> iter 79000, loss: 0.023511
 >> iter 80000, loss: 0.026857
   Number of active neurons: 1
 >> iter 81000, loss: 0.022752
 >> iter 82000, loss: 0.026430
 >> iter 83000, loss: 0.023680
 >> iter 84000, loss: 0.019257
 >> iter 85000, loss: 0.016834
 >> iter 86000, loss: 0.019871
 >> iter 87000, loss: 0.021343
 >> iter 88000, loss: 0.019851
 >> iter 89000, loss: 0.018448
 >> iter 90000, loss: 0.024049
   Number of active neurons: 1
 >> iter 91000, loss: 0.051137
 >> iter 92000, loss: 0.033400
 >> iter 93000, loss: 0.023241
 >> iter 94000, loss: 0.019386
 >> iter 95000, loss: 0.040098
 >> iter 96000, loss: 0.025813
 >> iter 97000, loss: 0.046887
 >> iter 98000, loss: 0.029213
 >> iter 99000, loss: 0.033042
 >> iter 100000, loss: 0.023100
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.955097
 >> iter 2000, loss: 4.095888
 >> iter 3000, loss: 1.541992
 >> iter 4000, loss: 0.590151
 >> iter 5000, loss: 0.236087
 >> iter 6000, loss: 0.105826
 >> iter 7000, loss: 0.058139
 >> iter 8000, loss: 0.040949
 >> iter 9000, loss: 0.035793
 >> iter 10000, loss: 0.040779
   Number of active neurons: 4
 >> iter 11000, loss: 0.034804
 >> iter 12000, loss: 0.030966
 >> iter 13000, loss: 0.030853
 >> iter 14000, loss: 0.029009
 >> iter 15000, loss: 0.027578
 >> iter 16000, loss: 0.048751
 >> iter 17000, loss: 0.039233
 >> iter 18000, loss: 0.031099
 >> iter 19000, loss: 0.026663
 >> iter 20000, loss: 0.037185
   Number of active neurons: 3
 >> iter 21000, loss: 0.030756
 >> iter 22000, loss: 0.027997
 >> iter 23000, loss: 0.042752
 >> iter 24000, loss: 0.030748
 >> iter 25000, loss: 0.027701
 >> iter 26000, loss: 0.029254
 >> iter 27000, loss: 0.025693
 >> iter 28000, loss: 0.032578
 >> iter 29000, loss: 0.028591
 >> iter 30000, loss: 0.026117
   Number of active neurons: 3
 >> iter 31000, loss: 0.026531
 >> iter 32000, loss: 0.029501
 >> iter 33000, loss: 0.048240
 >> iter 34000, loss: 0.035919
 >> iter 35000, loss: 0.030350
 >> iter 36000, loss: 0.026709
 >> iter 37000, loss: 0.026368
 >> iter 38000, loss: 0.025255
 >> iter 39000, loss: 0.022054
 >> iter 40000, loss: 0.021264
   Number of active neurons: 2
 >> iter 41000, loss: 0.021285
 >> iter 42000, loss: 0.040567
 >> iter 43000, loss: 0.031437
 >> iter 44000, loss: 0.040771
 >> iter 45000, loss: 0.029156
 >> iter 46000, loss: 0.022001
 >> iter 47000, loss: 0.021535
 >> iter 48000, loss: 0.025228
 >> iter 49000, loss: 0.021874
 >> iter 50000, loss: 0.022667
   Number of active neurons: 1
 >> iter 51000, loss: 0.021160
 >> iter 52000, loss: 0.018557
 >> iter 53000, loss: 0.017334
 >> iter 54000, loss: 0.019878
 >> iter 55000, loss: 0.018091
 >> iter 56000, loss: 0.016379
 >> iter 57000, loss: 0.023449
 >> iter 58000, loss: 0.029564
 >> iter 59000, loss: 0.026801
 >> iter 60000, loss: 0.030007
   Number of active neurons: 1
 >> iter 61000, loss: 0.022030
 >> iter 62000, loss: 0.022607
 >> iter 63000, loss: 0.019685
 >> iter 64000, loss: 0.024386
 >> iter 65000, loss: 0.020314
 >> iter 66000, loss: 0.026932
 >> iter 67000, loss: 0.023296
 >> iter 68000, loss: 0.017717
 >> iter 69000, loss: 0.054011
 >> iter 70000, loss: 0.032041
   Number of active neurons: 1
 >> iter 71000, loss: 0.035603
 >> iter 72000, loss: 0.024420
 >> iter 73000, loss: 0.021057
 >> iter 74000, loss: 0.020363
 >> iter 75000, loss: 0.018796
 >> iter 76000, loss: 0.020262
 >> iter 77000, loss: 0.031509
 >> iter 78000, loss: 0.025370
 >> iter 79000, loss: 0.019221
 >> iter 80000, loss: 0.016935
   Number of active neurons: 1
 >> iter 81000, loss: 0.017016
 >> iter 82000, loss: 0.018171
 >> iter 83000, loss: 0.020584
 >> iter 84000, loss: 0.019689
 >> iter 85000, loss: 0.026119
 >> iter 86000, loss: 0.020796
 >> iter 87000, loss: 0.019769
 >> iter 88000, loss: 0.017864
 >> iter 89000, loss: 0.017702
 >> iter 90000, loss: 0.020805
   Number of active neurons: 1
 >> iter 91000, loss: 0.018746
 >> iter 92000, loss: 0.021952
 >> iter 93000, loss: 0.018012
 >> iter 94000, loss: 0.019739
 >> iter 95000, loss: 0.019189
 >> iter 96000, loss: 0.030702
 >> iter 97000, loss: 0.024181
 >> iter 98000, loss: 0.020017
 >> iter 99000, loss: 0.021260
 >> iter 100000, loss: 0.024289
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.946098
 >> iter 2000, loss: 4.107293
 >> iter 3000, loss: 1.541360
 >> iter 4000, loss: 0.601253
 >> iter 5000, loss: 0.263082
 >> iter 6000, loss: 0.121651
 >> iter 7000, loss: 0.078523
 >> iter 8000, loss: 0.048839
 >> iter 9000, loss: 0.039872
 >> iter 10000, loss: 0.036466
   Number of active neurons: 7
 >> iter 11000, loss: 0.036056
 >> iter 12000, loss: 0.037780
 >> iter 13000, loss: 0.038077
 >> iter 14000, loss: 0.031801
 >> iter 15000, loss: 0.031267
 >> iter 16000, loss: 0.040124
 >> iter 17000, loss: 0.039973
 >> iter 18000, loss: 0.034961
 >> iter 19000, loss: 0.030734
 >> iter 20000, loss: 0.051828
   Number of active neurons: 3
 >> iter 21000, loss: 0.050286
 >> iter 22000, loss: 0.033942
 >> iter 23000, loss: 0.028702
 >> iter 24000, loss: 0.042978
 >> iter 25000, loss: 0.031383
 >> iter 26000, loss: 0.027974
 >> iter 27000, loss: 0.024561
 >> iter 28000, loss: 0.027941
 >> iter 29000, loss: 0.033621
 >> iter 30000, loss: 0.028562
   Number of active neurons: 2
 >> iter 31000, loss: 0.031494
 >> iter 32000, loss: 0.025718
 >> iter 33000, loss: 0.023101
 >> iter 34000, loss: 0.023234
 >> iter 35000, loss: 0.021680
 >> iter 36000, loss: 0.026875
 >> iter 37000, loss: 0.024809
 >> iter 38000, loss: 0.021578
 >> iter 39000, loss: 0.025160
 >> iter 40000, loss: 0.039221
   Number of active neurons: 1
 >> iter 41000, loss: 0.031369
 >> iter 42000, loss: 0.026180
 >> iter 43000, loss: 0.023744
 >> iter 44000, loss: 0.020924
 >> iter 45000, loss: 0.019249
 >> iter 46000, loss: 0.020137
 >> iter 47000, loss: 0.022701
 >> iter 48000, loss: 0.022681
 >> iter 49000, loss: 0.018187
 >> iter 50000, loss: 0.025276
   Number of active neurons: 1
 >> iter 51000, loss: 0.030628
 >> iter 52000, loss: 0.033778
 >> iter 53000, loss: 0.023020
 >> iter 54000, loss: 0.019518
 >> iter 55000, loss: 0.017963
 >> iter 56000, loss: 0.021434
 >> iter 57000, loss: 0.021581
 >> iter 58000, loss: 0.019573
 >> iter 59000, loss: 0.019639
 >> iter 60000, loss: 0.016641
   Number of active neurons: 1
 >> iter 61000, loss: 0.017701
 >> iter 62000, loss: 0.028443
 >> iter 63000, loss: 0.037558
 >> iter 64000, loss: 0.054630
 >> iter 65000, loss: 0.034933
 >> iter 66000, loss: 0.023585
 >> iter 67000, loss: 0.019488
 >> iter 68000, loss: 0.023720
 >> iter 69000, loss: 0.021154
 >> iter 70000, loss: 0.036655
   Number of active neurons: 1
 >> iter 71000, loss: 0.027039
 >> iter 72000, loss: 0.024839
 >> iter 73000, loss: 0.020756
 >> iter 74000, loss: 0.018396
 >> iter 75000, loss: 0.018122
 >> iter 76000, loss: 0.017312
 >> iter 77000, loss: 0.017924
 >> iter 78000, loss: 0.022559
 >> iter 79000, loss: 0.021993
 >> iter 80000, loss: 0.020285
   Number of active neurons: 1
 >> iter 81000, loss: 0.020615
 >> iter 82000, loss: 0.018309
 >> iter 83000, loss: 0.017252
 >> iter 84000, loss: 0.019161
 >> iter 85000, loss: 0.019052
 >> iter 86000, loss: 0.018033
 >> iter 87000, loss: 0.016433
 >> iter 88000, loss: 0.017849
 >> iter 89000, loss: 0.016456
 >> iter 90000, loss: 0.020879
   Number of active neurons: 1
 >> iter 91000, loss: 0.020908
 >> iter 92000, loss: 0.019093
 >> iter 93000, loss: 0.023645
 >> iter 94000, loss: 0.021758
 >> iter 95000, loss: 0.019436
 >> iter 96000, loss: 0.019590
 >> iter 97000, loss: 0.016995
 >> iter 98000, loss: 0.020035
 >> iter 99000, loss: 0.025452
 >> iter 100000, loss: 0.018998
   Number of active neurons: 1
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.003542
 >> iter 2000, loss: 4.095017
 >> iter 3000, loss: 1.535971
 >> iter 4000, loss: 0.592650
 >> iter 5000, loss: 0.236657
 >> iter 6000, loss: 0.106288
 >> iter 7000, loss: 0.058799
 >> iter 8000, loss: 0.046349
 >> iter 9000, loss: 0.034745
 >> iter 10000, loss: 0.032999
   Number of active neurons: 5
 >> iter 11000, loss: 0.028016
 >> iter 12000, loss: 0.027986
 >> iter 13000, loss: 0.030410
 >> iter 14000, loss: 0.033050
 >> iter 15000, loss: 0.031249
 >> iter 16000, loss: 0.044615
 >> iter 17000, loss: 0.031703
 >> iter 18000, loss: 0.027476
 >> iter 19000, loss: 0.031928
 >> iter 20000, loss: 0.026915
   Number of active neurons: 3
 >> iter 21000, loss: 0.027391
 >> iter 22000, loss: 0.029800
 >> iter 23000, loss: 0.032755
 >> iter 24000, loss: 0.026233
 >> iter 25000, loss: 0.024037
 >> iter 26000, loss: 0.024205
 >> iter 27000, loss: 0.037445
 >> iter 28000, loss: 0.027478
 >> iter 29000, loss: 0.024233
 >> iter 30000, loss: 0.025086
   Number of active neurons: 2
 >> iter 31000, loss: 0.023738
 >> iter 32000, loss: 0.027321
 >> iter 33000, loss: 0.025383
 >> iter 34000, loss: 0.025805
 >> iter 35000, loss: 0.024064
 >> iter 36000, loss: 0.023242
 >> iter 37000, loss: 0.022643
 >> iter 38000, loss: 0.020199
 >> iter 39000, loss: 0.022044
 >> iter 40000, loss: 0.020604
   Number of active neurons: 2
 >> iter 41000, loss: 0.025694
 >> iter 42000, loss: 0.022865
 >> iter 43000, loss: 0.024717
 >> iter 44000, loss: 0.023707
 >> iter 45000, loss: 0.032195
 >> iter 46000, loss: 0.025869
 >> iter 47000, loss: 0.030570
 >> iter 48000, loss: 0.024719
 >> iter 49000, loss: 0.027071
 >> iter 50000, loss: 0.021247
   Number of active neurons: 2
 >> iter 51000, loss: 0.027243
 >> iter 52000, loss: 0.022655
 >> iter 53000, loss: 0.026708
 >> iter 54000, loss: 0.023931
 >> iter 55000, loss: 0.020554
 >> iter 56000, loss: 0.032776
 >> iter 57000, loss: 0.029695
 >> iter 58000, loss: 0.028088
 >> iter 59000, loss: 0.031250
 >> iter 60000, loss: 0.025385
   Number of active neurons: 2
 >> iter 61000, loss: 0.023392
 >> iter 62000, loss: 0.021765
 >> iter 63000, loss: 0.021975
 >> iter 64000, loss: 0.022369
 >> iter 65000, loss: 0.024259
 >> iter 66000, loss: 0.022894
 >> iter 67000, loss: 0.024730
 >> iter 68000, loss: 0.023451
 >> iter 69000, loss: 0.022158
 >> iter 70000, loss: 0.021065
   Number of active neurons: 2
 >> iter 71000, loss: 0.020132
 >> iter 72000, loss: 0.022539
 >> iter 73000, loss: 0.023908
 >> iter 74000, loss: 0.036799
 >> iter 75000, loss: 0.026351
 >> iter 76000, loss: 0.030565
 >> iter 77000, loss: 0.024885
 >> iter 78000, loss: 0.025880
 >> iter 79000, loss: 0.026702
 >> iter 80000, loss: 0.022052
   Number of active neurons: 2
 >> iter 81000, loss: 0.032434
 >> iter 82000, loss: 0.024510
 >> iter 83000, loss: 0.037256
 >> iter 84000, loss: 0.030886
 >> iter 85000, loss: 0.027606
 >> iter 86000, loss: 0.039633
 >> iter 87000, loss: 0.029804
 >> iter 88000, loss: 0.023718
 >> iter 89000, loss: 0.022868
 >> iter 90000, loss: 0.020179
   Number of active neurons: 2
 >> iter 91000, loss: 0.020966
 >> iter 92000, loss: 0.024759
 >> iter 93000, loss: 0.031346
 >> iter 94000, loss: 0.035328
 >> iter 95000, loss: 0.026283
 >> iter 96000, loss: 0.025984
 >> iter 97000, loss: 0.025372
 >> iter 98000, loss: 0.021400
 >> iter 99000, loss: 0.022400
 >> iter 100000, loss: 0.028496
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

