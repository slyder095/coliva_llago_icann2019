 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 1e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.910505
 >> iter 2000, loss: 6.548516
 >> iter 3000, loss: 2.424397
 >> iter 4000, loss: 0.900133
 >> iter 5000, loss: 0.337357
 >> iter 6000, loss: 0.129156
 >> iter 7000, loss: 0.051958
 >> iter 8000, loss: 0.023054
 >> iter 9000, loss: 0.012148
 >> iter 10000, loss: 0.007863
   Number of active neurons: 9
 >> iter 11000, loss: 0.006142
 >> iter 12000, loss: 0.005340
 >> iter 13000, loss: 0.004960
 >> iter 14000, loss: 0.004701
 >> iter 15000, loss: 0.004559
 >> iter 16000, loss: 0.004412
 >> iter 17000, loss: 0.017671
 >> iter 18000, loss: 0.009501
 >> iter 19000, loss: 0.006336
 >> iter 20000, loss: 0.005038
   Number of active neurons: 9
 >> iter 21000, loss: 0.004497
 >> iter 22000, loss: 0.004246
 >> iter 23000, loss: 0.004238
 >> iter 24000, loss: 0.004460
 >> iter 25000, loss: 0.004031
 >> iter 26000, loss: 0.003893
 >> iter 27000, loss: 0.003798
 >> iter 28000, loss: 0.009059
 >> iter 29000, loss: 0.016835
 >> iter 30000, loss: 0.008564
   Number of active neurons: 7
 >> iter 31000, loss: 0.005535
 >> iter 32000, loss: 0.004457
 >> iter 33000, loss: 0.003882
 >> iter 34000, loss: 0.003732
 >> iter 35000, loss: 0.022414
 >> iter 36000, loss: 0.013935
 >> iter 37000, loss: 0.326222
 >> iter 38000, loss: 0.126030
 >> iter 39000, loss: 0.051057
 >> iter 40000, loss: 0.022722
   Number of active neurons: 6
 >> iter 41000, loss: 0.011915
 >> iter 42000, loss: 0.007632
 >> iter 43000, loss: 0.005893
 >> iter 44000, loss: 0.005070
 >> iter 45000, loss: 0.004688
 >> iter 46000, loss: 0.004397
 >> iter 47000, loss: 0.004207
 >> iter 48000, loss: 0.004044
 >> iter 49000, loss: 0.004674
 >> iter 50000, loss: 0.004150
   Number of active neurons: 6
 >> iter 51000, loss: 0.109943
 >> iter 52000, loss: 0.044544
 >> iter 53000, loss: 0.073292
 >> iter 54000, loss: 0.030854
 >> iter 55000, loss: 0.014793
 >> iter 56000, loss: 0.008453
 >> iter 57000, loss: 0.005938
 >> iter 58000, loss: 0.004856
 >> iter 59000, loss: 0.004411
 >> iter 60000, loss: 0.004097
   Number of active neurons: 6
 >> iter 61000, loss: 0.003973
 >> iter 62000, loss: 0.003872
 >> iter 63000, loss: 0.003780
 >> iter 64000, loss: 0.003733
 >> iter 65000, loss: 0.003595
 >> iter 66000, loss: 0.142036
 >> iter 67000, loss: 0.054982
 >> iter 68000, loss: 0.022747
 >> iter 69000, loss: 0.010785
 >> iter 70000, loss: 0.144449
   Number of active neurons: 6
 >> iter 71000, loss: 0.056006
 >> iter 72000, loss: 0.023258
 >> iter 73000, loss: 0.011083
 >> iter 74000, loss: 0.142064
 >> iter 75000, loss: 0.055281
 >> iter 76000, loss: 0.023130
 >> iter 77000, loss: 0.011062
 >> iter 78000, loss: 0.088258
 >> iter 79000, loss: 0.039881
 >> iter 80000, loss: 0.017614
   Number of active neurons: 5
 >> iter 81000, loss: 0.009123
 >> iter 82000, loss: 0.066513
 >> iter 83000, loss: 0.027539
 >> iter 84000, loss: 0.013373
 >> iter 85000, loss: 0.007532
 >> iter 86000, loss: 0.005387
 >> iter 87000, loss: 0.230907
 >> iter 88000, loss: 0.184226
 >> iter 89000, loss: 0.229952
 >> iter 90000, loss: 0.185474
   Number of active neurons: 7
 >> iter 91000, loss: 0.076006
 >> iter 92000, loss: 0.034859
 >> iter 93000, loss: 0.017274
 >> iter 94000, loss: 0.010172
 >> iter 95000, loss: 0.007192
 >> iter 96000, loss: 0.005805
 >> iter 97000, loss: 0.005107
 >> iter 98000, loss: 0.004689
 >> iter 99000, loss: 0.004396
 >> iter 100000, loss: 0.004198
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.026756
 >> iter 2000, loss: 6.054769
 >> iter 3000, loss: 2.242283
 >> iter 4000, loss: 0.834027
 >> iter 5000, loss: 0.313962
 >> iter 6000, loss: 0.121246
 >> iter 7000, loss: 0.049705
 >> iter 8000, loss: 0.022729
 >> iter 9000, loss: 0.012514
 >> iter 10000, loss: 0.008379
   Number of active neurons: 9
 >> iter 11000, loss: 0.006725
 >> iter 12000, loss: 0.005865
 >> iter 13000, loss: 0.005463
 >> iter 14000, loss: 0.005135
 >> iter 15000, loss: 0.004981
 >> iter 16000, loss: 0.004767
 >> iter 17000, loss: 0.004652
 >> iter 18000, loss: 0.004493
 >> iter 19000, loss: 0.005735
 >> iter 20000, loss: 0.004768
   Number of active neurons: 7
 >> iter 21000, loss: 0.004327
 >> iter 22000, loss: 0.004080
 >> iter 23000, loss: 0.003957
 >> iter 24000, loss: 0.003850
 >> iter 25000, loss: 0.003793
 >> iter 26000, loss: 0.003725
 >> iter 27000, loss: 0.003693
 >> iter 28000, loss: 0.003633
 >> iter 29000, loss: 0.003623
 >> iter 30000, loss: 0.003579
   Number of active neurons: 6
 >> iter 31000, loss: 0.003535
 >> iter 32000, loss: 0.003476
 >> iter 33000, loss: 0.006921
 >> iter 34000, loss: 0.005424
 >> iter 35000, loss: 0.004056
 >> iter 36000, loss: 0.003498
 >> iter 37000, loss: 0.003298
 >> iter 38000, loss: 0.003206
 >> iter 39000, loss: 0.003180
 >> iter 40000, loss: 0.003156
   Number of active neurons: 6
 >> iter 41000, loss: 0.003150
 >> iter 42000, loss: 0.003148
 >> iter 43000, loss: 0.003137
 >> iter 44000, loss: 0.003138
 >> iter 45000, loss: 0.003119
 >> iter 46000, loss: 0.003127
 >> iter 47000, loss: 0.003092
 >> iter 48000, loss: 0.003098
 >> iter 49000, loss: 0.003066
 >> iter 50000, loss: 0.003068
   Number of active neurons: 6
 >> iter 51000, loss: 0.003034
 >> iter 52000, loss: 0.003041
 >> iter 53000, loss: 0.003016
 >> iter 54000, loss: 0.003037
 >> iter 55000, loss: 0.002977
 >> iter 56000, loss: 0.002967
 >> iter 57000, loss: 0.002966
 >> iter 58000, loss: 0.003612
 >> iter 59000, loss: 0.003127
 >> iter 60000, loss: 0.002952
   Number of active neurons: 5
 >> iter 61000, loss: 0.002940
 >> iter 62000, loss: 0.003403
 >> iter 63000, loss: 0.003011
 >> iter 64000, loss: 0.002870
 >> iter 65000, loss: 0.002994
 >> iter 66000, loss: 0.004961
 >> iter 67000, loss: 0.003613
 >> iter 68000, loss: 0.003106
 >> iter 69000, loss: 0.002924
 >> iter 70000, loss: 0.002839
   Number of active neurons: 4
 >> iter 71000, loss: 0.004456
 >> iter 72000, loss: 0.005656
 >> iter 73000, loss: 0.003943
 >> iter 74000, loss: 0.003283
 >> iter 75000, loss: 0.303620
 >> iter 76000, loss: 0.116003
 >> iter 77000, loss: 0.046456
 >> iter 78000, loss: 0.020543
 >> iter 79000, loss: 0.010751
 >> iter 80000, loss: 0.006959
   Number of active neurons: 3
 >> iter 81000, loss: 0.005398
 >> iter 82000, loss: 0.004711
 >> iter 83000, loss: 0.004351
 >> iter 84000, loss: 0.004140
 >> iter 85000, loss: 0.003989
 >> iter 86000, loss: 0.003860
 >> iter 87000, loss: 0.003777
 >> iter 88000, loss: 0.003660
 >> iter 89000, loss: 0.003619
 >> iter 90000, loss: 0.003505
   Number of active neurons: 3
 >> iter 91000, loss: 0.137398
 >> iter 92000, loss: 0.054007
 >> iter 93000, loss: 0.022965
 >> iter 94000, loss: 0.011364
 >> iter 95000, loss: 0.006948
 >> iter 96000, loss: 0.005140
 >> iter 97000, loss: 0.004414
 >> iter 98000, loss: 0.004000
 >> iter 99000, loss: 0.003813
 >> iter 100000, loss: 0.003641
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00999990000101
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.067044
 >> iter 2000, loss: 6.206131
 >> iter 3000, loss: 2.296641
 >> iter 4000, loss: 0.853018
 >> iter 5000, loss: 0.320107
 >> iter 6000, loss: 0.122878
 >> iter 7000, loss: 0.049729
 >> iter 8000, loss: 0.022278
 >> iter 9000, loss: 0.011915
 >> iter 10000, loss: 0.007798
   Number of active neurons: 6
 >> iter 11000, loss: 0.006153
 >> iter 12000, loss: 0.005348
 >> iter 13000, loss: 0.004991
 >> iter 14000, loss: 0.004715
 >> iter 15000, loss: 0.004577
 >> iter 16000, loss: 0.004429
 >> iter 17000, loss: 0.004637
 >> iter 18000, loss: 0.147593
 >> iter 19000, loss: 0.057136
 >> iter 20000, loss: 0.023744
   Number of active neurons: 5
 >> iter 21000, loss: 0.011401
 >> iter 22000, loss: 0.006796
 >> iter 23000, loss: 0.283338
 >> iter 24000, loss: 0.111720
 >> iter 25000, loss: 0.046304
 >> iter 26000, loss: 0.021443
 >> iter 27000, loss: 0.011775
 >> iter 28000, loss: 0.007911
 >> iter 29000, loss: 0.006178
 >> iter 30000, loss: 0.005472
   Number of active neurons: 6
 >> iter 31000, loss: 0.007253
 >> iter 32000, loss: 0.042693
 >> iter 33000, loss: 0.018924
 >> iter 34000, loss: 0.009884
 >> iter 35000, loss: 0.024653
 >> iter 36000, loss: 0.014555
 >> iter 37000, loss: 0.007957
 >> iter 38000, loss: 0.005365
 >> iter 39000, loss: 0.066861
 >> iter 40000, loss: 0.027475
   Number of active neurons: 5
 >> iter 41000, loss: 0.012830
 >> iter 42000, loss: 0.007319
 >> iter 43000, loss: 0.005202
 >> iter 44000, loss: 0.004364
 >> iter 45000, loss: 0.056169
 >> iter 46000, loss: 0.023652
 >> iter 47000, loss: 0.025343
 >> iter 48000, loss: 0.011978
 >> iter 49000, loss: 0.006928
 >> iter 50000, loss: 0.005031
   Number of active neurons: 5
 >> iter 51000, loss: 0.004294
 >> iter 52000, loss: 0.004022
 >> iter 53000, loss: 0.106073
 >> iter 54000, loss: 0.042355
 >> iter 55000, loss: 0.028490
 >> iter 56000, loss: 0.013451
 >> iter 57000, loss: 0.007685
 >> iter 58000, loss: 0.005460
 >> iter 59000, loss: 0.096515
 >> iter 60000, loss: 0.039324
   Number of active neurons: 6
 >> iter 61000, loss: 0.017791
 >> iter 62000, loss: 0.009557
 >> iter 63000, loss: 0.261834
 >> iter 64000, loss: 0.103832
 >> iter 65000, loss: 0.053190
 >> iter 66000, loss: 0.024472
 >> iter 67000, loss: 0.013090
 >> iter 68000, loss: 0.008313
 >> iter 69000, loss: 0.006246
 >> iter 70000, loss: 0.005255
   Number of active neurons: 6
 >> iter 71000, loss: 0.004806
 >> iter 72000, loss: 0.004395
 >> iter 73000, loss: 0.004178
 >> iter 74000, loss: 0.003972
 >> iter 75000, loss: 0.055123
 >> iter 76000, loss: 0.022952
 >> iter 77000, loss: 0.010961
 >> iter 78000, loss: 0.006423
 >> iter 79000, loss: 0.004696
 >> iter 80000, loss: 0.003982
   Number of active neurons: 6
 >> iter 81000, loss: 0.096426
 >> iter 82000, loss: 0.038885
 >> iter 83000, loss: 0.017387
 >> iter 84000, loss: 0.009238
 >> iter 85000, loss: 0.006108
 >> iter 86000, loss: 0.004794
 >> iter 87000, loss: 0.287314
 >> iter 88000, loss: 0.112199
 >> iter 89000, loss: 0.046299
 >> iter 90000, loss: 0.021229
   Number of active neurons: 6
 >> iter 91000, loss: 0.011497
 >> iter 92000, loss: 0.007530
 >> iter 93000, loss: 0.005839
 >> iter 94000, loss: 0.004973
 >> iter 95000, loss: 0.289850
 >> iter 96000, loss: 0.112605
 >> iter 97000, loss: 0.046186
 >> iter 98000, loss: 0.021003
 >> iter 99000, loss: 0.011289
 >> iter 100000, loss: 0.007357
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.564210
 >> iter 2000, loss: 6.445200
 >> iter 3000, loss: 2.384041
 >> iter 4000, loss: 0.884715
 >> iter 5000, loss: 0.331394
 >> iter 6000, loss: 0.126754
 >> iter 7000, loss: 0.051008
 >> iter 8000, loss: 0.022577
 >> iter 9000, loss: 0.011870
 >> iter 10000, loss: 0.007657
   Number of active neurons: 9
 >> iter 11000, loss: 0.006342
 >> iter 12000, loss: 0.005354
 >> iter 13000, loss: 0.004853
 >> iter 14000, loss: 0.004523
 >> iter 15000, loss: 0.004354
 >> iter 16000, loss: 0.004193
 >> iter 17000, loss: 0.035137
 >> iter 18000, loss: 0.015888
 >> iter 19000, loss: 0.008574
 >> iter 20000, loss: 0.005721
   Number of active neurons: 8
 >> iter 21000, loss: 0.004595
 >> iter 22000, loss: 0.004096
 >> iter 23000, loss: 0.003866
 >> iter 24000, loss: 0.003723
 >> iter 25000, loss: 0.003644
 >> iter 26000, loss: 0.003576
 >> iter 27000, loss: 0.003547
 >> iter 28000, loss: 0.003497
 >> iter 29000, loss: 0.003492
 >> iter 30000, loss: 0.003443
   Number of active neurons: 6
 >> iter 31000, loss: 0.003386
 >> iter 32000, loss: 0.003371
 >> iter 33000, loss: 0.005156
 >> iter 34000, loss: 0.067894
 >> iter 35000, loss: 0.027727
 >> iter 36000, loss: 0.012652
 >> iter 37000, loss: 0.070335
 >> iter 38000, loss: 0.028561
 >> iter 39000, loss: 0.013014
 >> iter 40000, loss: 0.007144
   Number of active neurons: 5
 >> iter 41000, loss: 0.004921
 >> iter 42000, loss: 0.004020
 >> iter 43000, loss: 0.003671
 >> iter 44000, loss: 0.003496
 >> iter 45000, loss: 0.003442
 >> iter 46000, loss: 0.003379
 >> iter 47000, loss: 0.004409
 >> iter 48000, loss: 0.003871
 >> iter 49000, loss: 0.003548
 >> iter 50000, loss: 0.003383
   Number of active neurons: 5
 >> iter 51000, loss: 0.003564
 >> iter 52000, loss: 0.003396
 >> iter 53000, loss: 0.003213
 >> iter 54000, loss: 0.003128
 >> iter 55000, loss: 0.003080
 >> iter 56000, loss: 0.003052
 >> iter 57000, loss: 0.125571
 >> iter 58000, loss: 0.134342
 >> iter 59000, loss: 0.052302
 >> iter 60000, loss: 0.021853
   Number of active neurons: 5
 >> iter 61000, loss: 0.010498
 >> iter 62000, loss: 0.006222
 >> iter 63000, loss: 0.004592
 >> iter 64000, loss: 0.003928
 >> iter 65000, loss: 0.003709
 >> iter 66000, loss: 0.003538
 >> iter 67000, loss: 0.003416
 >> iter 68000, loss: 0.003342
 >> iter 69000, loss: 0.003346
 >> iter 70000, loss: 0.003264
   Number of active neurons: 5
 >> iter 71000, loss: 0.003193
 >> iter 72000, loss: 0.003135
 >> iter 73000, loss: 0.003121
 >> iter 74000, loss: 0.003339
 >> iter 75000, loss: 0.003102
 >> iter 76000, loss: 0.003008
 >> iter 77000, loss: 0.051973
 >> iter 78000, loss: 0.021342
 >> iter 79000, loss: 0.024167
 >> iter 80000, loss: 0.011002
   Number of active neurons: 5
 >> iter 81000, loss: 0.034206
 >> iter 82000, loss: 0.014928
 >> iter 83000, loss: 0.007707
 >> iter 84000, loss: 0.004912
 >> iter 85000, loss: 0.003856
 >> iter 86000, loss: 0.003377
 >> iter 87000, loss: 0.003240
 >> iter 88000, loss: 0.003075
 >> iter 89000, loss: 0.003065
 >> iter 90000, loss: 0.002953
   Number of active neurons: 5
 >> iter 91000, loss: 0.004793
 >> iter 92000, loss: 0.003738
 >> iter 93000, loss: 0.251072
 >> iter 94000, loss: 0.096914
 >> iter 95000, loss: 0.039486
 >> iter 96000, loss: 0.017849
 >> iter 97000, loss: 0.009646
 >> iter 98000, loss: 0.006363
 >> iter 99000, loss: 0.005033
 >> iter 100000, loss: 0.004368
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.330564
 >> iter 2000, loss: 5.675277
 >> iter 3000, loss: 2.116226
 >> iter 4000, loss: 0.787145
 >> iter 5000, loss: 0.304794
 >> iter 6000, loss: 0.117739
 >> iter 7000, loss: 0.048202
 >> iter 8000, loss: 0.021946
 >> iter 9000, loss: 0.012031
 >> iter 10000, loss: 0.007982
   Number of active neurons: 8
 >> iter 11000, loss: 0.006351
 >> iter 12000, loss: 0.005504
 >> iter 13000, loss: 0.005124
 >> iter 14000, loss: 0.004810
 >> iter 15000, loss: 0.004661
 >> iter 16000, loss: 0.004475
 >> iter 17000, loss: 0.004394
 >> iter 18000, loss: 0.004262
 >> iter 19000, loss: 0.004210
 >> iter 20000, loss: 0.004106
   Number of active neurons: 8
 >> iter 21000, loss: 0.004071
 >> iter 22000, loss: 0.003994
 >> iter 23000, loss: 0.003965
 >> iter 24000, loss: 0.003915
 >> iter 25000, loss: 0.003872
 >> iter 26000, loss: 0.003816
 >> iter 27000, loss: 0.003768
 >> iter 28000, loss: 0.003749
 >> iter 29000, loss: 0.003687
 >> iter 30000, loss: 0.003659
   Number of active neurons: 6
 >> iter 31000, loss: 0.003606
 >> iter 32000, loss: 0.003617
 >> iter 33000, loss: 0.003548
 >> iter 34000, loss: 0.115861
 >> iter 35000, loss: 0.045863
 >> iter 36000, loss: 0.019628
 >> iter 37000, loss: 0.009838
 >> iter 38000, loss: 0.006111
 >> iter 39000, loss: 0.004700
 >> iter 40000, loss: 0.004107
   Number of active neurons: 7
 >> iter 41000, loss: 0.003859
 >> iter 42000, loss: 0.003747
 >> iter 43000, loss: 0.003644
 >> iter 44000, loss: 0.003616
 >> iter 45000, loss: 0.003530
 >> iter 46000, loss: 0.003524
 >> iter 47000, loss: 0.003439
 >> iter 48000, loss: 0.003443
 >> iter 49000, loss: 0.003360
 >> iter 50000, loss: 0.003351
   Number of active neurons: 6
 >> iter 51000, loss: 0.003285
 >> iter 52000, loss: 0.003300
 >> iter 53000, loss: 0.003230
 >> iter 54000, loss: 0.107355
 >> iter 55000, loss: 0.041939
 >> iter 56000, loss: 0.017770
 >> iter 57000, loss: 0.008835
 >> iter 58000, loss: 0.005503
 >> iter 59000, loss: 0.004225
 >> iter 60000, loss: 0.003765
   Number of active neurons: 5
 >> iter 61000, loss: 0.003506
 >> iter 62000, loss: 0.003406
 >> iter 63000, loss: 0.003325
 >> iter 64000, loss: 0.006554
 >> iter 65000, loss: 0.004290
 >> iter 66000, loss: 0.003418
 >> iter 67000, loss: 0.003100
 >> iter 68000, loss: 0.002970
 >> iter 69000, loss: 0.002938
 >> iter 70000, loss: 0.002921
   Number of active neurons: 5
 >> iter 71000, loss: 0.002928
 >> iter 72000, loss: 0.002931
 >> iter 73000, loss: 0.002926
 >> iter 74000, loss: 0.002938
 >> iter 75000, loss: 0.002915
 >> iter 76000, loss: 0.002901
 >> iter 77000, loss: 0.002885
 >> iter 78000, loss: 0.002868
 >> iter 79000, loss: 0.002850
 >> iter 80000, loss: 0.002839
   Number of active neurons: 4
 >> iter 81000, loss: 0.002828
 >> iter 82000, loss: 0.002807
 >> iter 83000, loss: 0.002797
 >> iter 84000, loss: 0.002777
 >> iter 85000, loss: 0.002778
 >> iter 86000, loss: 0.002755
 >> iter 87000, loss: 0.002760
 >> iter 88000, loss: 0.002728
 >> iter 89000, loss: 0.002809
 >> iter 90000, loss: 0.002695
   Number of active neurons: 4
 >> iter 91000, loss: 0.002671
 >> iter 92000, loss: 0.002666
 >> iter 93000, loss: 0.002674
 >> iter 94000, loss: 0.002712
 >> iter 95000, loss: 0.002635
 >> iter 96000, loss: 0.002615
 >> iter 97000, loss: 0.002624
 >> iter 98000, loss: 0.002648
 >> iter 99000, loss: 0.002613
 >> iter 100000, loss: 0.003548
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 15.990936
 >> iter 2000, loss: 5.950221
 >> iter 3000, loss: 2.211767
 >> iter 4000, loss: 0.821146
 >> iter 5000, loss: 0.319005
 >> iter 6000, loss: 0.122410
 >> iter 7000, loss: 0.050031
 >> iter 8000, loss: 0.022278
 >> iter 9000, loss: 0.011729
 >> iter 10000, loss: 0.007521
   Number of active neurons: 7
 >> iter 11000, loss: 0.006079
 >> iter 12000, loss: 0.005170
 >> iter 13000, loss: 0.004732
 >> iter 14000, loss: 0.004434
 >> iter 15000, loss: 0.004370
 >> iter 16000, loss: 0.004181
 >> iter 17000, loss: 0.004080
 >> iter 18000, loss: 0.003973
 >> iter 19000, loss: 0.009302
 >> iter 20000, loss: 0.005874
   Number of active neurons: 6
 >> iter 21000, loss: 0.004557
 >> iter 22000, loss: 0.004075
 >> iter 23000, loss: 0.003836
 >> iter 24000, loss: 0.003686
 >> iter 25000, loss: 0.003928
 >> iter 26000, loss: 0.003646
 >> iter 27000, loss: 0.003508
 >> iter 28000, loss: 0.003412
 >> iter 29000, loss: 0.409644
 >> iter 30000, loss: 0.158361
   Number of active neurons: 7
 >> iter 31000, loss: 0.063833
 >> iter 32000, loss: 0.027973
 >> iter 33000, loss: 0.014216
 >> iter 34000, loss: 0.008711
 >> iter 35000, loss: 0.006438
 >> iter 36000, loss: 0.005352
 >> iter 37000, loss: 0.004820
 >> iter 38000, loss: 0.004458
 >> iter 39000, loss: 0.004252
 >> iter 40000, loss: 0.004055
   Number of active neurons: 7
 >> iter 41000, loss: 0.003941
 >> iter 42000, loss: 0.003806
 >> iter 43000, loss: 0.003794
 >> iter 44000, loss: 0.003617
 >> iter 45000, loss: 0.003538
 >> iter 46000, loss: 0.003451
 >> iter 47000, loss: 0.021659
 >> iter 48000, loss: 0.010319
 >> iter 49000, loss: 0.006071
 >> iter 50000, loss: 0.004465
   Number of active neurons: 6
 >> iter 51000, loss: 0.003828
 >> iter 52000, loss: 0.003546
 >> iter 53000, loss: 0.010217
 >> iter 54000, loss: 0.005846
 >> iter 55000, loss: 0.004206
 >> iter 56000, loss: 0.003591
 >> iter 57000, loss: 0.003347
 >> iter 58000, loss: 0.003214
 >> iter 59000, loss: 0.017533
 >> iter 60000, loss: 0.008587
   Number of active neurons: 6
 >> iter 61000, loss: 0.005211
 >> iter 62000, loss: 0.003960
 >> iter 63000, loss: 0.009812
 >> iter 64000, loss: 0.005537
 >> iter 65000, loss: 0.003941
 >> iter 66000, loss: 0.003349
 >> iter 67000, loss: 0.003124
 >> iter 68000, loss: 0.003027
 >> iter 69000, loss: 0.007960
 >> iter 70000, loss: 0.004790
   Number of active neurons: 6
 >> iter 71000, loss: 0.003586
 >> iter 72000, loss: 0.003141
 >> iter 73000, loss: 0.002964
 >> iter 74000, loss: 0.002887
 >> iter 75000, loss: 0.008018
 >> iter 76000, loss: 0.004733
 >> iter 77000, loss: 0.003499
 >> iter 78000, loss: 0.003057
 >> iter 79000, loss: 0.002865
 >> iter 80000, loss: 0.002780
   Number of active neurons: 6
 >> iter 81000, loss: 0.035317
 >> iter 82000, loss: 0.014824
 >> iter 83000, loss: 0.007239
 >> iter 84000, loss: 0.004440
 >> iter 85000, loss: 0.003402
 >> iter 86000, loss: 0.003027
 >> iter 87000, loss: 0.002885
 >> iter 88000, loss: 0.002832
 >> iter 89000, loss: 0.062042
 >> iter 90000, loss: 0.024851
   Number of active neurons: 6
 >> iter 91000, loss: 0.011074
 >> iter 92000, loss: 0.005947
 >> iter 93000, loss: 0.004030
 >> iter 94000, loss: 0.003312
 >> iter 95000, loss: 0.003027
 >> iter 96000, loss: 0.002918
 >> iter 97000, loss: 0.002858
 >> iter 98000, loss: 0.002828
 >> iter 99000, loss: 0.002806
 >> iter 100000, loss: 0.002775
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0159998400016
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.839227
 >> iter 2000, loss: 6.497061
 >> iter 3000, loss: 2.437950
 >> iter 4000, loss: 0.906602
 >> iter 5000, loss: 0.340551
 >> iter 6000, loss: 0.130837
 >> iter 7000, loss: 0.052964
 >> iter 8000, loss: 0.023678
 >> iter 9000, loss: 0.019472
 >> iter 10000, loss: 0.010757
   Number of active neurons: 8
 >> iter 11000, loss: 0.104918
 >> iter 12000, loss: 0.043897
 >> iter 13000, loss: 0.020510
 >> iter 14000, loss: 0.011297
 >> iter 15000, loss: 0.007611
 >> iter 16000, loss: 0.005951
 >> iter 17000, loss: 0.005226
 >> iter 18000, loss: 0.004748
 >> iter 19000, loss: 0.018018
 >> iter 20000, loss: 0.009427
   Number of active neurons: 8
 >> iter 21000, loss: 0.006232
 >> iter 22000, loss: 0.004834
 >> iter 23000, loss: 0.050214
 >> iter 24000, loss: 0.021591
 >> iter 25000, loss: 0.010870
 >> iter 26000, loss: 0.006624
 >> iter 27000, loss: 0.049160
 >> iter 28000, loss: 0.021059
 >> iter 29000, loss: 0.097604
 >> iter 30000, loss: 0.039609
   Number of active neurons: 7
 >> iter 31000, loss: 0.196230
 >> iter 32000, loss: 0.076471
 >> iter 33000, loss: 0.031880
 >> iter 34000, loss: 0.015029
 >> iter 35000, loss: 0.028392
 >> iter 36000, loss: 0.013773
 >> iter 37000, loss: 0.087238
 >> iter 38000, loss: 0.035669
 >> iter 39000, loss: 0.016381
 >> iter 40000, loss: 0.008970
   Number of active neurons: 7
 >> iter 41000, loss: 0.050334
 >> iter 42000, loss: 0.021601
 >> iter 43000, loss: 0.024872
 >> iter 44000, loss: 0.012195
 >> iter 45000, loss: 0.079371
 >> iter 46000, loss: 0.032463
 >> iter 47000, loss: 0.014955
 >> iter 48000, loss: 0.008290
 >> iter 49000, loss: 0.005740
 >> iter 50000, loss: 0.004663
   Number of active neurons: 7
 >> iter 51000, loss: 0.144978
 >> iter 52000, loss: 0.057089
 >> iter 53000, loss: 0.024311
 >> iter 54000, loss: 0.011934
 >> iter 55000, loss: 0.007232
 >> iter 56000, loss: 0.005334
 >> iter 57000, loss: 0.086248
 >> iter 58000, loss: 0.034592
 >> iter 59000, loss: 0.015385
 >> iter 60000, loss: 0.008156
   Number of active neurons: 6
 >> iter 61000, loss: 0.005438
 >> iter 62000, loss: 0.004352
 >> iter 63000, loss: 0.003940
 >> iter 64000, loss: 0.003710
 >> iter 65000, loss: 0.014500
 >> iter 66000, loss: 0.007708
 >> iter 67000, loss: 0.005188
 >> iter 68000, loss: 0.004111
 >> iter 69000, loss: 0.003743
 >> iter 70000, loss: 0.003490
   Number of active neurons: 5
 >> iter 71000, loss: 0.003439
 >> iter 72000, loss: 0.003319
 >> iter 73000, loss: 0.015871
 >> iter 74000, loss: 0.017119
 >> iter 75000, loss: 0.008384
 >> iter 76000, loss: 0.005829
 >> iter 77000, loss: 0.004153
 >> iter 78000, loss: 0.003531
 >> iter 79000, loss: 0.003301
 >> iter 80000, loss: 0.003499
   Number of active neurons: 5
 >> iter 81000, loss: 0.003368
 >> iter 82000, loss: 0.003475
 >> iter 83000, loss: 0.003189
 >> iter 84000, loss: 0.002994
 >> iter 85000, loss: 0.002959
 >> iter 86000, loss: 0.002942
 >> iter 87000, loss: 0.002892
 >> iter 88000, loss: 0.003113
 >> iter 89000, loss: 0.002940
 >> iter 90000, loss: 0.003442
   Number of active neurons: 4
 >> iter 91000, loss: 0.102547
 >> iter 92000, loss: 0.276003
 >> iter 93000, loss: 0.106534
 >> iter 94000, loss: 0.044891
 >> iter 95000, loss: 0.020228
 >> iter 96000, loss: 0.010951
 >> iter 97000, loss: 0.007090
 >> iter 98000, loss: 0.005727
 >> iter 99000, loss: 0.004798
 >> iter 100000, loss: 0.004573
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 14.988501
 >> iter 2000, loss: 5.551696
 >> iter 3000, loss: 2.065735
 >> iter 4000, loss: 0.769121
 >> iter 5000, loss: 0.290008
 >> iter 6000, loss: 0.112413
 >> iter 7000, loss: 0.046423
 >> iter 8000, loss: 0.021517
 >> iter 9000, loss: 0.012067
 >> iter 10000, loss: 0.008218
   Number of active neurons: 6
 >> iter 11000, loss: 0.006651
 >> iter 12000, loss: 0.005822
 >> iter 13000, loss: 0.005432
 >> iter 14000, loss: 0.005103
 >> iter 15000, loss: 0.004933
 >> iter 16000, loss: 0.004726
 >> iter 17000, loss: 0.004621
 >> iter 18000, loss: 0.004468
 >> iter 19000, loss: 0.004394
 >> iter 20000, loss: 0.004268
   Number of active neurons: 6
 >> iter 21000, loss: 0.004213
 >> iter 22000, loss: 0.004112
 >> iter 23000, loss: 0.004066
 >> iter 24000, loss: 0.003977
 >> iter 25000, loss: 0.003938
 >> iter 26000, loss: 0.003858
 >> iter 27000, loss: 0.003825
 >> iter 28000, loss: 0.003747
 >> iter 29000, loss: 0.003719
 >> iter 30000, loss: 0.003655
   Number of active neurons: 6
 >> iter 31000, loss: 0.003629
 >> iter 32000, loss: 0.003569
 >> iter 33000, loss: 0.003548
 >> iter 34000, loss: 0.003496
 >> iter 35000, loss: 0.003481
 >> iter 36000, loss: 0.003435
 >> iter 37000, loss: 0.003422
 >> iter 38000, loss: 0.003376
 >> iter 39000, loss: 0.003365
 >> iter 40000, loss: 0.003322
   Number of active neurons: 6
 >> iter 41000, loss: 0.003309
 >> iter 42000, loss: 0.003269
 >> iter 43000, loss: 0.003256
 >> iter 44000, loss: 0.003219
 >> iter 45000, loss: 0.003210
 >> iter 46000, loss: 0.003177
 >> iter 47000, loss: 0.003167
 >> iter 48000, loss: 0.003132
 >> iter 49000, loss: 0.003160
 >> iter 50000, loss: 0.003112
   Number of active neurons: 6
 >> iter 51000, loss: 0.003079
 >> iter 52000, loss: 0.003028
 >> iter 53000, loss: 0.003043
 >> iter 54000, loss: 0.003003
 >> iter 55000, loss: 0.003002
 >> iter 56000, loss: 0.002950
 >> iter 57000, loss: 0.002949
 >> iter 58000, loss: 0.002905
 >> iter 59000, loss: 0.003060
 >> iter 60000, loss: 0.002959
   Number of active neurons: 6
 >> iter 61000, loss: 0.002874
 >> iter 62000, loss: 0.002796
 >> iter 63000, loss: 0.002782
 >> iter 64000, loss: 0.002753
 >> iter 65000, loss: 0.002937
 >> iter 66000, loss: 0.002847
 >> iter 67000, loss: 0.002750
 >> iter 68000, loss: 0.002682
 >> iter 69000, loss: 0.002694
 >> iter 70000, loss: 0.002655
   Number of active neurons: 5
 >> iter 71000, loss: 0.002735
 >> iter 72000, loss: 0.002680
 >> iter 73000, loss: 0.002675
 >> iter 74000, loss: 0.002636
 >> iter 75000, loss: 0.002671
 >> iter 76000, loss: 0.002640
 >> iter 77000, loss: 0.002652
 >> iter 78000, loss: 0.002622
 >> iter 79000, loss: 0.120943
 >> iter 80000, loss: 0.046495
   Number of active neurons: 5
 >> iter 81000, loss: 0.019063
 >> iter 82000, loss: 0.008940
 >> iter 83000, loss: 0.005195
 >> iter 84000, loss: 0.003803
 >> iter 85000, loss: 0.003272
 >> iter 86000, loss: 0.003073
 >> iter 87000, loss: 0.002983
 >> iter 88000, loss: 0.002933
 >> iter 89000, loss: 0.002915
 >> iter 90000, loss: 0.002878
   Number of active neurons: 5
 >> iter 91000, loss: 0.002877
 >> iter 92000, loss: 0.002840
 >> iter 93000, loss: 0.002847
 >> iter 94000, loss: 0.002808
 >> iter 95000, loss: 0.148565
 >> iter 96000, loss: 0.057062
 >> iter 97000, loss: 0.023247
 >> iter 98000, loss: 0.010704
 >> iter 99000, loss: 0.006038
 >> iter 100000, loss: 0.004266
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.336336
 >> iter 2000, loss: 6.471175
 >> iter 3000, loss: 2.394011
 >> iter 4000, loss: 0.888334
 >> iter 5000, loss: 0.332688
 >> iter 6000, loss: 0.127176
 >> iter 7000, loss: 0.051058
 >> iter 8000, loss: 0.022547
 >> iter 9000, loss: 0.011828
 >> iter 10000, loss: 0.007605
   Number of active neurons: 9
 >> iter 11000, loss: 0.005960
 >> iter 12000, loss: 0.005156
 >> iter 13000, loss: 0.004807
 >> iter 14000, loss: 0.004545
 >> iter 15000, loss: 0.201749
 >> iter 16000, loss: 0.079292
 >> iter 17000, loss: 0.033245
 >> iter 18000, loss: 0.015770
 >> iter 19000, loss: 0.009059
 >> iter 20000, loss: 0.006338
   Number of active neurons: 8
 >> iter 21000, loss: 0.005220
 >> iter 22000, loss: 0.004668
 >> iter 23000, loss: 0.004412
 >> iter 24000, loss: 0.004231
 >> iter 25000, loss: 0.004139
 >> iter 26000, loss: 0.004061
 >> iter 27000, loss: 0.003944
 >> iter 28000, loss: 0.003912
 >> iter 29000, loss: 0.193483
 >> iter 30000, loss: 0.075685
   Number of active neurons: 7
 >> iter 31000, loss: 0.031538
 >> iter 32000, loss: 0.014897
 >> iter 33000, loss: 0.008470
 >> iter 34000, loss: 0.005954
 >> iter 35000, loss: 0.004832
 >> iter 36000, loss: 0.026582
 >> iter 37000, loss: 0.012428
 >> iter 38000, loss: 0.007046
 >> iter 39000, loss: 0.004999
 >> iter 40000, loss: 0.005509
   Number of active neurons: 5
 >> iter 41000, loss: 0.004296
 >> iter 42000, loss: 0.003793
 >> iter 43000, loss: 0.003566
 >> iter 44000, loss: 0.273235
 >> iter 45000, loss: 0.105704
 >> iter 46000, loss: 0.042818
 >> iter 47000, loss: 0.019154
 >> iter 48000, loss: 0.010104
 >> iter 49000, loss: 0.006545
 >> iter 50000, loss: 0.005131
   Number of active neurons: 5
 >> iter 51000, loss: 0.004419
 >> iter 52000, loss: 0.049080
 >> iter 53000, loss: 0.021038
 >> iter 54000, loss: 0.010572
 >> iter 55000, loss: 0.006455
 >> iter 56000, loss: 0.006247
 >> iter 57000, loss: 0.004655
 >> iter 58000, loss: 0.003955
 >> iter 59000, loss: 0.003658
 >> iter 60000, loss: 0.056926
   Number of active neurons: 5
 >> iter 61000, loss: 0.023856
 >> iter 62000, loss: 0.011866
 >> iter 63000, loss: 0.006815
 >> iter 64000, loss: 0.005778
 >> iter 65000, loss: 0.004356
 >> iter 66000, loss: 0.003744
 >> iter 67000, loss: 0.003468
 >> iter 68000, loss: 0.271459
 >> iter 69000, loss: 0.106357
 >> iter 70000, loss: 0.043541
   Number of active neurons: 5
 >> iter 71000, loss: 0.019685
 >> iter 72000, loss: 0.010422
 >> iter 73000, loss: 0.006751
 >> iter 74000, loss: 0.005171
 >> iter 75000, loss: 0.004455
 >> iter 76000, loss: 0.004056
 >> iter 77000, loss: 0.003823
 >> iter 78000, loss: 0.003671
 >> iter 79000, loss: 0.003524
 >> iter 80000, loss: 0.003611
   Number of active neurons: 4
 >> iter 81000, loss: 0.003382
 >> iter 82000, loss: 0.003298
 >> iter 83000, loss: 0.003181
 >> iter 84000, loss: 0.003469
 >> iter 85000, loss: 0.003177
 >> iter 86000, loss: 0.003204
 >> iter 87000, loss: 0.003028
 >> iter 88000, loss: 0.003553
 >> iter 89000, loss: 0.003123
 >> iter 90000, loss: 0.003802
   Number of active neurons: 4
 >> iter 91000, loss: 0.003185
 >> iter 92000, loss: 0.004050
 >> iter 93000, loss: 0.003245
 >> iter 94000, loss: 0.004252
 >> iter 95000, loss: 0.003295
 >> iter 96000, loss: 0.004166
 >> iter 97000, loss: 0.003253
 >> iter 98000, loss: 0.004472
 >> iter 99000, loss: 0.003362
 >> iter 100000, loss: 0.004334
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 14.861650
 >> iter 2000, loss: 5.535593
 >> iter 3000, loss: 2.057826
 >> iter 4000, loss: 0.764230
 >> iter 5000, loss: 0.298162
 >> iter 6000, loss: 0.114590
 >> iter 7000, loss: 0.054896
 >> iter 8000, loss: 0.024091
 >> iter 9000, loss: 0.012423
 >> iter 10000, loss: 0.007788
   Number of active neurons: 7
 >> iter 11000, loss: 0.014291
 >> iter 12000, loss: 0.008370
 >> iter 13000, loss: 0.009660
 >> iter 14000, loss: 0.006494
 >> iter 15000, loss: 0.008217
 >> iter 16000, loss: 0.005587
 >> iter 17000, loss: 0.004539
 >> iter 18000, loss: 0.004042
 >> iter 19000, loss: 0.003832
 >> iter 20000, loss: 0.003694
   Number of active neurons: 7
 >> iter 21000, loss: 0.003636
 >> iter 22000, loss: 0.004446
 >> iter 23000, loss: 0.003801
 >> iter 24000, loss: 0.003533
 >> iter 25000, loss: 0.003468
 >> iter 26000, loss: 0.189220
 >> iter 27000, loss: 0.072722
 >> iter 28000, loss: 0.029555
 >> iter 29000, loss: 0.013537
 >> iter 30000, loss: 0.007484
   Number of active neurons: 7
 >> iter 31000, loss: 0.005203
 >> iter 32000, loss: 0.004276
 >> iter 33000, loss: 0.003916
 >> iter 34000, loss: 0.003736
 >> iter 35000, loss: 0.003628
 >> iter 36000, loss: 0.003992
 >> iter 37000, loss: 0.003586
 >> iter 38000, loss: 0.003406
 >> iter 39000, loss: 0.005154
 >> iter 40000, loss: 0.078700
   Number of active neurons: 6
 >> iter 41000, loss: 0.031582
 >> iter 42000, loss: 0.014084
 >> iter 43000, loss: 0.007574
 >> iter 44000, loss: 0.005090
 >> iter 45000, loss: 0.004155
 >> iter 46000, loss: 0.003740
 >> iter 47000, loss: 0.040412
 >> iter 48000, loss: 0.017178
 >> iter 49000, loss: 0.008537
 >> iter 50000, loss: 0.005305
   Number of active neurons: 6
 >> iter 51000, loss: 0.004084
 >> iter 52000, loss: 0.003620
 >> iter 53000, loss: 0.003419
 >> iter 54000, loss: 0.003451
 >> iter 55000, loss: 0.003287
 >> iter 56000, loss: 0.003219
 >> iter 57000, loss: 0.070114
 >> iter 58000, loss: 0.028068
 >> iter 59000, loss: 0.012547
 >> iter 60000, loss: 0.006769
   Number of active neurons: 6
 >> iter 61000, loss: 0.004620
 >> iter 62000, loss: 0.003786
 >> iter 63000, loss: 0.003470
 >> iter 64000, loss: 0.003321
 >> iter 65000, loss: 0.003281
 >> iter 66000, loss: 0.003193
 >> iter 67000, loss: 0.034009
 >> iter 68000, loss: 0.014769
 >> iter 69000, loss: 0.007611
 >> iter 70000, loss: 0.004914
   Number of active neurons: 6
 >> iter 71000, loss: 0.003891
 >> iter 72000, loss: 0.171452
 >> iter 73000, loss: 0.066296
 >> iter 74000, loss: 0.027269
 >> iter 75000, loss: 0.012695
 >> iter 76000, loss: 0.007164
 >> iter 77000, loss: 0.005015
 >> iter 78000, loss: 0.004120
 >> iter 79000, loss: 0.003727
 >> iter 80000, loss: 0.003516
   Number of active neurons: 6
 >> iter 81000, loss: 0.003401
 >> iter 82000, loss: 0.003316
 >> iter 83000, loss: 0.003261
 >> iter 84000, loss: 0.053265
 >> iter 85000, loss: 0.021849
 >> iter 86000, loss: 0.010160
 >> iter 87000, loss: 0.006539
 >> iter 88000, loss: 0.004373
 >> iter 89000, loss: 0.003856
 >> iter 90000, loss: 0.003293
   Number of active neurons: 6
 >> iter 91000, loss: 0.005246
 >> iter 92000, loss: 0.003790
 >> iter 93000, loss: 0.003298
 >> iter 94000, loss: 0.003009
 >> iter 95000, loss: 0.002982
 >> iter 96000, loss: 0.002881
 >> iter 97000, loss: 0.002857
 >> iter 98000, loss: 0.007764
 >> iter 99000, loss: 0.004432
 >> iter 100000, loss: 0.003221
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.455645
 >> iter 2000, loss: 5.740407
 >> iter 3000, loss: 2.135570
 >> iter 4000, loss: 0.795699
 >> iter 5000, loss: 0.303936
 >> iter 6000, loss: 0.118225
 >> iter 7000, loss: 0.049057
 >> iter 8000, loss: 0.022841
 >> iter 9000, loss: 0.012839
 >> iter 10000, loss: 0.008722
   Number of active neurons: 7
 >> iter 11000, loss: 0.007035
 >> iter 12000, loss: 0.006134
 >> iter 13000, loss: 0.005716
 >> iter 14000, loss: 0.005369
 >> iter 15000, loss: 0.005196
 >> iter 16000, loss: 0.004983
 >> iter 17000, loss: 0.004880
 >> iter 18000, loss: 0.004726
 >> iter 19000, loss: 0.004659
 >> iter 20000, loss: 0.004534
   Number of active neurons: 7
 >> iter 21000, loss: 0.004484
 >> iter 22000, loss: 0.004380
 >> iter 23000, loss: 0.004345
 >> iter 24000, loss: 0.004246
 >> iter 25000, loss: 0.004399
 >> iter 26000, loss: 0.004162
 >> iter 27000, loss: 0.004062
 >> iter 28000, loss: 0.003965
 >> iter 29000, loss: 0.009280
 >> iter 30000, loss: 0.055592
   Number of active neurons: 7
 >> iter 31000, loss: 0.023156
 >> iter 32000, loss: 0.011116
 >> iter 33000, loss: 0.006664
 >> iter 34000, loss: 0.004957
 >> iter 35000, loss: 0.004326
 >> iter 36000, loss: 0.004026
 >> iter 37000, loss: 0.009672
 >> iter 38000, loss: 0.298053
 >> iter 39000, loss: 0.114430
 >> iter 40000, loss: 0.046194
   Number of active neurons: 6
 >> iter 41000, loss: 0.020693
 >> iter 42000, loss: 0.011005
 >> iter 43000, loss: 0.007222
 >> iter 44000, loss: 0.005636
 >> iter 45000, loss: 0.004917
 >> iter 46000, loss: 0.004525
 >> iter 47000, loss: 0.004294
 >> iter 48000, loss: 0.004121
 >> iter 49000, loss: 0.003999
 >> iter 50000, loss: 0.003885
   Number of active neurons: 5
 >> iter 51000, loss: 0.003805
 >> iter 52000, loss: 0.003712
 >> iter 53000, loss: 0.003654
 >> iter 54000, loss: 0.003573
 >> iter 55000, loss: 0.003531
 >> iter 56000, loss: 0.003455
 >> iter 57000, loss: 0.003426
 >> iter 58000, loss: 0.003353
 >> iter 59000, loss: 0.003334
 >> iter 60000, loss: 0.003271
   Number of active neurons: 5
 >> iter 61000, loss: 0.003261
 >> iter 62000, loss: 0.003199
 >> iter 63000, loss: 0.003174
 >> iter 64000, loss: 0.003117
 >> iter 65000, loss: 0.003154
 >> iter 66000, loss: 0.003413
 >> iter 67000, loss: 0.003111
 >> iter 68000, loss: 0.002989
 >> iter 69000, loss: 0.003181
 >> iter 70000, loss: 0.003012
   Number of active neurons: 4
 >> iter 71000, loss: 0.002905
 >> iter 72000, loss: 0.002858
 >> iter 73000, loss: 0.002827
 >> iter 74000, loss: 0.002814
 >> iter 75000, loss: 0.002816
 >> iter 76000, loss: 0.368507
 >> iter 77000, loss: 0.138598
 >> iter 78000, loss: 0.053816
 >> iter 79000, loss: 0.022507
 >> iter 80000, loss: 0.010855
   Number of active neurons: 4
 >> iter 81000, loss: 0.006491
 >> iter 82000, loss: 0.004798
 >> iter 83000, loss: 0.004125
 >> iter 84000, loss: 0.003815
 >> iter 85000, loss: 0.003662
 >> iter 86000, loss: 0.003561
 >> iter 87000, loss: 0.003492
 >> iter 88000, loss: 0.003432
 >> iter 89000, loss: 0.003378
 >> iter 90000, loss: 0.003334
   Number of active neurons: 3
 >> iter 91000, loss: 0.003279
 >> iter 92000, loss: 0.003251
 >> iter 93000, loss: 0.003196
 >> iter 94000, loss: 0.003181
 >> iter 95000, loss: 0.003119
 >> iter 96000, loss: 0.003112
 >> iter 97000, loss: 0.003044
 >> iter 98000, loss: 0.054426
 >> iter 99000, loss: 0.022052
 >> iter 100000, loss: 0.010102
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.634547
 >> iter 2000, loss: 6.579106
 >> iter 3000, loss: 2.564934
 >> iter 4000, loss: 0.965044
 >> iter 5000, loss: 0.366669
 >> iter 6000, loss: 0.143651
 >> iter 7000, loss: 0.060108
 >> iter 8000, loss: 0.028295
 >> iter 9000, loss: 0.015946
 >> iter 10000, loss: 0.010829
   Number of active neurons: 8
 >> iter 11000, loss: 0.008604
 >> iter 12000, loss: 0.007430
 >> iter 13000, loss: 0.006791
 >> iter 14000, loss: 0.006314
 >> iter 15000, loss: 0.006004
 >> iter 16000, loss: 0.005709
 >> iter 17000, loss: 0.005508
 >> iter 18000, loss: 0.005294
 >> iter 19000, loss: 0.005149
 >> iter 20000, loss: 0.004976
   Number of active neurons: 7
 >> iter 21000, loss: 0.004864
 >> iter 22000, loss: 0.004724
 >> iter 23000, loss: 0.004634
 >> iter 24000, loss: 0.004516
 >> iter 25000, loss: 0.004445
 >> iter 26000, loss: 0.004346
 >> iter 27000, loss: 0.004288
 >> iter 28000, loss: 0.004199
 >> iter 29000, loss: 0.004154
 >> iter 30000, loss: 0.004079
   Number of active neurons: 6
 >> iter 31000, loss: 0.004041
 >> iter 32000, loss: 0.003973
 >> iter 33000, loss: 0.003946
 >> iter 34000, loss: 0.003881
 >> iter 35000, loss: 0.003864
 >> iter 36000, loss: 0.003798
 >> iter 37000, loss: 0.003786
 >> iter 38000, loss: 0.003719
 >> iter 39000, loss: 0.003713
 >> iter 40000, loss: 0.003649
   Number of active neurons: 6
 >> iter 41000, loss: 0.003643
 >> iter 42000, loss: 0.003589
 >> iter 43000, loss: 0.003581
 >> iter 44000, loss: 0.003535
 >> iter 45000, loss: 0.003524
 >> iter 46000, loss: 0.003482
 >> iter 47000, loss: 0.003465
 >> iter 48000, loss: 0.003432
 >> iter 49000, loss: 0.003407
 >> iter 50000, loss: 0.003380
   Number of active neurons: 6
 >> iter 51000, loss: 0.003352
 >> iter 52000, loss: 0.003326
 >> iter 53000, loss: 0.003299
 >> iter 54000, loss: 0.003279
 >> iter 55000, loss: 0.003244
 >> iter 56000, loss: 0.261949
 >> iter 57000, loss: 0.143302
 >> iter 58000, loss: 0.056601
 >> iter 59000, loss: 0.024407
 >> iter 60000, loss: 0.012299
   Number of active neurons: 5
 >> iter 61000, loss: 0.045336
 >> iter 62000, loss: 0.020035
 >> iter 63000, loss: 0.010560
 >> iter 64000, loss: 0.006890
 >> iter 65000, loss: 0.005532
 >> iter 66000, loss: 0.004808
 >> iter 67000, loss: 0.004525
 >> iter 68000, loss: 0.004280
 >> iter 69000, loss: 0.004204
 >> iter 70000, loss: 0.004031
   Number of active neurons: 4
 >> iter 71000, loss: 0.003976
 >> iter 72000, loss: 0.003842
 >> iter 73000, loss: 0.003836
 >> iter 74000, loss: 0.003699
 >> iter 75000, loss: 0.003678
 >> iter 76000, loss: 0.003568
 >> iter 77000, loss: 0.003584
 >> iter 78000, loss: 0.003463
 >> iter 79000, loss: 0.003460
 >> iter 80000, loss: 0.003365
   Number of active neurons: 3
 >> iter 81000, loss: 0.003391
 >> iter 82000, loss: 0.003287
 >> iter 83000, loss: 0.003292
 >> iter 84000, loss: 0.003212
 >> iter 85000, loss: 0.003233
 >> iter 86000, loss: 0.003150
 >> iter 87000, loss: 0.003158
 >> iter 88000, loss: 0.003087
 >> iter 89000, loss: 0.003105
 >> iter 90000, loss: 0.003038
   Number of active neurons: 3
 >> iter 91000, loss: 0.003050
 >> iter 92000, loss: 0.002992
 >> iter 93000, loss: 0.003004
 >> iter 94000, loss: 0.002953
 >> iter 95000, loss: 0.002957
 >> iter 96000, loss: 0.002909
 >> iter 97000, loss: 0.002906
 >> iter 98000, loss: 0.002860
 >> iter 99000, loss: 0.002855
 >> iter 100000, loss: 0.002814
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.352463
 >> iter 2000, loss: 6.118548
 >> iter 3000, loss: 2.273804
 >> iter 4000, loss: 0.849125
 >> iter 5000, loss: 0.321680
 >> iter 6000, loss: 0.125647
 >> iter 7000, loss: 0.052514
 >> iter 8000, loss: 0.024719
 >> iter 9000, loss: 0.014039
 >> iter 10000, loss: 0.009598
   Number of active neurons: 6
 >> iter 11000, loss: 0.007731
 >> iter 12000, loss: 0.006697
 >> iter 13000, loss: 0.006166
 >> iter 14000, loss: 0.005729
 >> iter 15000, loss: 0.005469
 >> iter 16000, loss: 0.005188
 >> iter 17000, loss: 0.005012
 >> iter 18000, loss: 0.004803
 >> iter 19000, loss: 0.004672
 >> iter 20000, loss: 0.004507
   Number of active neurons: 6
 >> iter 21000, loss: 0.004404
 >> iter 22000, loss: 0.004272
 >> iter 23000, loss: 0.004185
 >> iter 24000, loss: 0.004075
 >> iter 25000, loss: 0.004003
 >> iter 26000, loss: 0.003914
 >> iter 27000, loss: 0.003852
 >> iter 28000, loss: 0.003777
 >> iter 29000, loss: 0.003719
 >> iter 30000, loss: 0.003668
   Number of active neurons: 6
 >> iter 31000, loss: 0.003608
 >> iter 32000, loss: 0.003574
 >> iter 33000, loss: 0.003513
 >> iter 34000, loss: 0.003495
 >> iter 35000, loss: 0.003432
 >> iter 36000, loss: 0.003429
 >> iter 37000, loss: 0.003359
 >> iter 38000, loss: 0.003356
 >> iter 39000, loss: 0.003287
 >> iter 40000, loss: 0.003290
   Number of active neurons: 6
 >> iter 41000, loss: 0.003219
 >> iter 42000, loss: 0.003244
 >> iter 43000, loss: 0.003164
 >> iter 44000, loss: 0.003195
 >> iter 45000, loss: 0.003112
 >> iter 46000, loss: 0.003152
 >> iter 47000, loss: 0.003064
 >> iter 48000, loss: 0.003113
 >> iter 49000, loss: 0.003021
 >> iter 50000, loss: 0.003077
   Number of active neurons: 5
 >> iter 51000, loss: 0.002981
 >> iter 52000, loss: 0.003070
 >> iter 53000, loss: 0.002951
 >> iter 54000, loss: 0.003036
 >> iter 55000, loss: 0.002912
 >> iter 56000, loss: 0.003001
 >> iter 57000, loss: 0.002874
 >> iter 58000, loss: 0.002973
 >> iter 59000, loss: 0.002839
 >> iter 60000, loss: 0.002937
   Number of active neurons: 5
 >> iter 61000, loss: 0.002801
 >> iter 62000, loss: 0.002895
 >> iter 63000, loss: 0.002764
 >> iter 64000, loss: 0.002839
 >> iter 65000, loss: 0.002723
 >> iter 66000, loss: 0.002808
 >> iter 67000, loss: 0.002690
 >> iter 68000, loss: 0.002780
 >> iter 69000, loss: 0.002662
 >> iter 70000, loss: 0.002768
   Number of active neurons: 5
 >> iter 71000, loss: 0.002636
 >> iter 72000, loss: 0.002732
 >> iter 73000, loss: 0.002602
 >> iter 74000, loss: 0.002785
 >> iter 75000, loss: 0.002669
 >> iter 76000, loss: 0.113285
 >> iter 77000, loss: 0.043413
 >> iter 78000, loss: 0.019832
 >> iter 79000, loss: 0.008915
 >> iter 80000, loss: 0.004922
   Number of active neurons: 4
 >> iter 81000, loss: 0.003433
 >> iter 82000, loss: 0.002974
 >> iter 83000, loss: 0.002713
 >> iter 84000, loss: 0.002863
 >> iter 85000, loss: 0.034339
 >> iter 86000, loss: 0.014495
 >> iter 87000, loss: 0.007116
 >> iter 88000, loss: 0.004730
 >> iter 89000, loss: 0.003401
 >> iter 90000, loss: 0.002985
   Number of active neurons: 4
 >> iter 91000, loss: 0.002711
 >> iter 92000, loss: 0.002736
 >> iter 93000, loss: 0.002588
 >> iter 94000, loss: 0.002638
 >> iter 95000, loss: 0.002536
 >> iter 96000, loss: 0.002626
 >> iter 97000, loss: 0.002526
 >> iter 98000, loss: 0.002617
 >> iter 99000, loss: 0.002490
 >> iter 100000, loss: 0.002545
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0069999300007
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.805385
 >> iter 2000, loss: 6.138265
 >> iter 3000, loss: 2.332586
 >> iter 4000, loss: 0.868465
 >> iter 5000, loss: 0.326819
 >> iter 6000, loss: 0.125923
 >> iter 7000, loss: 0.051206
 >> iter 8000, loss: 0.023081
 >> iter 9000, loss: 0.012375
 >> iter 10000, loss: 0.008099
   Number of active neurons: 8
 >> iter 11000, loss: 0.006335
 >> iter 12000, loss: 0.005503
 >> iter 13000, loss: 0.005048
 >> iter 14000, loss: 0.004844
 >> iter 15000, loss: 0.004673
 >> iter 16000, loss: 0.005323
 >> iter 17000, loss: 0.004559
 >> iter 18000, loss: 0.004310
 >> iter 19000, loss: 0.004065
 >> iter 20000, loss: 0.004088
   Number of active neurons: 7
 >> iter 21000, loss: 0.131415
 >> iter 22000, loss: 0.051631
 >> iter 23000, loss: 0.286170
 >> iter 24000, loss: 0.113163
 >> iter 25000, loss: 0.046583
 >> iter 26000, loss: 0.020929
 >> iter 27000, loss: 0.140138
 >> iter 28000, loss: 0.079557
 >> iter 29000, loss: 0.090763
 >> iter 30000, loss: 0.038001
   Number of active neurons: 7
 >> iter 31000, loss: 0.017979
 >> iter 32000, loss: 0.010178
 >> iter 33000, loss: 0.007022
 >> iter 34000, loss: 0.005634
 >> iter 35000, loss: 0.004946
 >> iter 36000, loss: 0.004569
 >> iter 37000, loss: 0.004299
 >> iter 38000, loss: 0.004180
 >> iter 39000, loss: 0.003964
 >> iter 40000, loss: 0.003963
   Number of active neurons: 6
 >> iter 41000, loss: 0.003728
 >> iter 42000, loss: 0.003711
 >> iter 43000, loss: 0.003546
 >> iter 44000, loss: 0.003775
 >> iter 45000, loss: 0.003455
 >> iter 46000, loss: 0.003426
 >> iter 47000, loss: 0.003266
 >> iter 48000, loss: 0.003323
 >> iter 49000, loss: 0.003170
 >> iter 50000, loss: 0.003221
   Number of active neurons: 6
 >> iter 51000, loss: 0.003099
 >> iter 52000, loss: 0.075112
 >> iter 53000, loss: 0.156858
 >> iter 54000, loss: 0.061005
 >> iter 55000, loss: 0.025271
 >> iter 56000, loss: 0.011844
 >> iter 57000, loss: 0.006760
 >> iter 58000, loss: 0.004761
 >> iter 59000, loss: 0.003965
 >> iter 60000, loss: 0.003600
   Number of active neurons: 7
 >> iter 61000, loss: 0.003437
 >> iter 62000, loss: 0.003336
 >> iter 63000, loss: 0.003275
 >> iter 64000, loss: 0.003269
 >> iter 65000, loss: 0.003183
 >> iter 66000, loss: 0.003190
 >> iter 67000, loss: 0.003155
 >> iter 68000, loss: 0.007961
 >> iter 69000, loss: 0.004875
 >> iter 70000, loss: 0.003699
   Number of active neurons: 5
 >> iter 71000, loss: 0.003245
 >> iter 72000, loss: 0.003054
 >> iter 73000, loss: 0.002966
 >> iter 74000, loss: 0.002936
 >> iter 75000, loss: 0.003113
 >> iter 76000, loss: 0.034983
 >> iter 77000, loss: 0.015038
 >> iter 78000, loss: 0.009429
 >> iter 79000, loss: 0.005169
 >> iter 80000, loss: 0.003603
   Number of active neurons: 4
 >> iter 81000, loss: 0.003019
 >> iter 82000, loss: 0.002874
 >> iter 83000, loss: 0.002769
 >> iter 84000, loss: 0.002845
 >> iter 85000, loss: 0.002687
 >> iter 86000, loss: 0.002707
 >> iter 87000, loss: 0.036121
 >> iter 88000, loss: 0.150310
 >> iter 89000, loss: 0.057363
 >> iter 90000, loss: 0.023229
   Number of active neurons: 4
 >> iter 91000, loss: 0.010432
 >> iter 92000, loss: 0.005723
 >> iter 93000, loss: 0.034881
 >> iter 94000, loss: 0.017353
 >> iter 95000, loss: 0.008341
 >> iter 96000, loss: 0.004960
 >> iter 97000, loss: 0.003688
 >> iter 98000, loss: 0.003236
 >> iter 99000, loss: 0.035040
 >> iter 100000, loss: 0.015045
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.164457
 >> iter 2000, loss: 5.636285
 >> iter 3000, loss: 2.151552
 >> iter 4000, loss: 0.801523
 >> iter 5000, loss: 0.302386
 >> iter 6000, loss: 0.117203
 >> iter 7000, loss: 0.048347
 >> iter 8000, loss: 0.022331
 >> iter 9000, loss: 0.012435
 >> iter 10000, loss: 0.008404
   Number of active neurons: 7
 >> iter 11000, loss: 0.006759
 >> iter 12000, loss: 0.005903
 >> iter 13000, loss: 0.005500
 >> iter 14000, loss: 0.005180
 >> iter 15000, loss: 0.005011
 >> iter 16000, loss: 0.004823
 >> iter 17000, loss: 0.004721
 >> iter 18000, loss: 0.004596
 >> iter 19000, loss: 0.004524
 >> iter 20000, loss: 0.004433
   Number of active neurons: 4
 >> iter 21000, loss: 0.004375
 >> iter 22000, loss: 0.004314
 >> iter 23000, loss: 0.004267
 >> iter 24000, loss: 0.004220
 >> iter 25000, loss: 0.004148
 >> iter 26000, loss: 0.004086
 >> iter 27000, loss: 0.004164
 >> iter 28000, loss: 0.004178
 >> iter 29000, loss: 0.003962
 >> iter 30000, loss: 0.003833
   Number of active neurons: 4
 >> iter 31000, loss: 0.003807
 >> iter 32000, loss: 0.003768
 >> iter 33000, loss: 0.003708
 >> iter 34000, loss: 0.003630
 >> iter 35000, loss: 0.296438
 >> iter 36000, loss: 0.114048
 >> iter 37000, loss: 0.046315
 >> iter 38000, loss: 0.020918
 >> iter 39000, loss: 0.011303
 >> iter 40000, loss: 0.007506
   Number of active neurons: 4
 >> iter 41000, loss: 0.005963
 >> iter 42000, loss: 0.005235
 >> iter 43000, loss: 0.004869
 >> iter 44000, loss: 0.004613
 >> iter 45000, loss: 0.004447
 >> iter 46000, loss: 0.004292
 >> iter 47000, loss: 0.004180
 >> iter 48000, loss: 0.004063
 >> iter 49000, loss: 0.003977
 >> iter 50000, loss: 0.003882
   Number of active neurons: 4
 >> iter 51000, loss: 0.003816
 >> iter 52000, loss: 0.003737
 >> iter 53000, loss: 0.003687
 >> iter 54000, loss: 0.003617
 >> iter 55000, loss: 0.003579
 >> iter 56000, loss: 0.003513
 >> iter 57000, loss: 0.003482
 >> iter 58000, loss: 0.003423
 >> iter 59000, loss: 0.003397
 >> iter 60000, loss: 0.003345
   Number of active neurons: 4
 >> iter 61000, loss: 0.003336
 >> iter 62000, loss: 0.003293
 >> iter 63000, loss: 0.003263
 >> iter 64000, loss: 0.003215
 >> iter 65000, loss: 0.026196
 >> iter 66000, loss: 0.011735
 >> iter 67000, loss: 0.619484
 >> iter 68000, loss: 0.238039
 >> iter 69000, loss: 0.094422
 >> iter 70000, loss: 0.040085
   Number of active neurons: 4
 >> iter 71000, loss: 0.019324
 >> iter 72000, loss: 0.011108
 >> iter 73000, loss: 0.007752
 >> iter 74000, loss: 0.006205
 >> iter 75000, loss: 0.005445
 >> iter 76000, loss: 0.004967
 >> iter 77000, loss: 0.004670
 >> iter 78000, loss: 0.004415
 >> iter 79000, loss: 0.004238
 >> iter 80000, loss: 0.004066
   Number of active neurons: 3
 >> iter 81000, loss: 0.003943
 >> iter 82000, loss: 0.003818
 >> iter 83000, loss: 0.003726
 >> iter 84000, loss: 0.003630
 >> iter 85000, loss: 0.003558
 >> iter 86000, loss: 0.003482
 >> iter 87000, loss: 0.003426
 >> iter 88000, loss: 0.003358
 >> iter 89000, loss: 0.003318
 >> iter 90000, loss: 0.003254
   Number of active neurons: 3
 >> iter 91000, loss: 0.003227
 >> iter 92000, loss: 0.003163
 >> iter 93000, loss: 0.003139
 >> iter 94000, loss: 0.003082
 >> iter 95000, loss: 0.003064
 >> iter 96000, loss: 0.003012
 >> iter 97000, loss: 0.002997
 >> iter 98000, loss: 0.002949
 >> iter 99000, loss: 0.002941
 >> iter 100000, loss: 0.002894
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.630416
 >> iter 2000, loss: 5.990511
 >> iter 3000, loss: 2.216024
 >> iter 4000, loss: 0.822792
 >> iter 5000, loss: 0.308564
 >> iter 6000, loss: 0.118350
 >> iter 7000, loss: 0.047862
 >> iter 8000, loss: 0.021456
 >> iter 9000, loss: 0.011521
 >> iter 10000, loss: 0.007596
   Number of active neurons: 7
 >> iter 11000, loss: 0.006049
 >> iter 12000, loss: 0.005305
 >> iter 13000, loss: 0.004979
 >> iter 14000, loss: 0.004733
 >> iter 15000, loss: 0.004615
 >> iter 16000, loss: 0.004467
 >> iter 17000, loss: 0.004461
 >> iter 18000, loss: 0.004312
 >> iter 19000, loss: 0.004225
 >> iter 20000, loss: 0.004122
   Number of active neurons: 6
 >> iter 21000, loss: 0.078117
 >> iter 22000, loss: 0.031863
 >> iter 23000, loss: 0.393938
 >> iter 24000, loss: 0.154500
 >> iter 25000, loss: 0.063163
 >> iter 26000, loss: 0.028132
 >> iter 27000, loss: 0.014519
 >> iter 28000, loss: 0.008999
 >> iter 29000, loss: 0.006681
 >> iter 30000, loss: 0.005576
   Number of active neurons: 7
 >> iter 31000, loss: 0.005025
 >> iter 32000, loss: 0.004666
 >> iter 33000, loss: 0.004448
 >> iter 34000, loss: 0.004258
 >> iter 35000, loss: 0.004135
 >> iter 36000, loss: 0.004011
 >> iter 37000, loss: 0.003927
 >> iter 38000, loss: 0.003834
 >> iter 39000, loss: 0.003771
 >> iter 40000, loss: 0.003695
   Number of active neurons: 5
 >> iter 41000, loss: 0.003647
 >> iter 42000, loss: 0.003586
 >> iter 43000, loss: 0.003547
 >> iter 44000, loss: 0.003491
 >> iter 45000, loss: 0.007558
 >> iter 46000, loss: 0.004914
 >> iter 47000, loss: 0.242866
 >> iter 48000, loss: 0.093953
 >> iter 49000, loss: 0.038802
 >> iter 50000, loss: 0.017788
   Number of active neurons: 5
 >> iter 51000, loss: 0.009754
 >> iter 52000, loss: 0.006586
 >> iter 53000, loss: 0.005247
 >> iter 54000, loss: 0.004623
 >> iter 55000, loss: 0.004274
 >> iter 56000, loss: 0.004056
 >> iter 57000, loss: 0.003891
 >> iter 58000, loss: 0.003762
 >> iter 59000, loss: 0.003651
 >> iter 60000, loss: 0.003556
   Number of active neurons: 4
 >> iter 61000, loss: 0.469225
 >> iter 62000, loss: 0.182872
 >> iter 63000, loss: 0.073981
 >> iter 64000, loss: 0.032360
 >> iter 65000, loss: 0.016212
 >> iter 66000, loss: 0.009706
 >> iter 67000, loss: 0.006949
 >> iter 68000, loss: 0.005647
 >> iter 69000, loss: 0.004968
 >> iter 70000, loss: 0.004546
   Number of active neurons: 4
 >> iter 71000, loss: 0.004263
 >> iter 72000, loss: 0.004046
 >> iter 73000, loss: 0.003876
 >> iter 74000, loss: 0.003736
 >> iter 75000, loss: 0.003611
 >> iter 76000, loss: 0.003512
 >> iter 77000, loss: 0.003416
 >> iter 78000, loss: 0.003343
 >> iter 79000, loss: 0.003266
 >> iter 80000, loss: 0.003198
   Number of active neurons: 4
 >> iter 81000, loss: 0.003120
 >> iter 82000, loss: 0.139846
 >> iter 83000, loss: 0.054424
 >> iter 84000, loss: 0.022823
 >> iter 85000, loss: 0.010980
 >> iter 86000, loss: 0.006522
 >> iter 87000, loss: 0.004730
 >> iter 88000, loss: 0.004001
 >> iter 89000, loss: 0.003621
 >> iter 90000, loss: 0.129259
   Number of active neurons: 4
 >> iter 91000, loss: 0.050708
 >> iter 92000, loss: 0.021532
 >> iter 93000, loss: 0.010549
 >> iter 94000, loss: 0.006368
 >> iter 95000, loss: 0.004679
 >> iter 96000, loss: 0.003973
 >> iter 97000, loss: 0.003610
 >> iter 98000, loss: 0.003414
 >> iter 99000, loss: 0.003278
 >> iter 100000, loss: 0.003165
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0139998600014
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.440183
 >> iter 2000, loss: 5.749565
 >> iter 3000, loss: 2.135731
 >> iter 4000, loss: 0.794032
 >> iter 5000, loss: 0.307470
 >> iter 6000, loss: 0.118622
 >> iter 7000, loss: 0.048437
 >> iter 8000, loss: 0.022018
 >> iter 9000, loss: 0.012786
 >> iter 10000, loss: 0.008315
   Number of active neurons: 8
 >> iter 11000, loss: 0.006471
 >> iter 12000, loss: 0.005584
 >> iter 13000, loss: 0.005159
 >> iter 14000, loss: 0.004874
 >> iter 15000, loss: 0.004710
 >> iter 16000, loss: 0.004569
 >> iter 17000, loss: 0.005290
 >> iter 18000, loss: 0.004867
 >> iter 19000, loss: 0.004501
 >> iter 20000, loss: 0.004312
   Number of active neurons: 8
 >> iter 21000, loss: 0.004185
 >> iter 22000, loss: 0.004093
 >> iter 23000, loss: 0.271256
 >> iter 24000, loss: 0.107295
 >> iter 25000, loss: 0.044986
 >> iter 26000, loss: 0.021077
 >> iter 27000, loss: 0.011743
 >> iter 28000, loss: 0.007932
 >> iter 29000, loss: 0.006297
 >> iter 30000, loss: 0.005503
   Number of active neurons: 8
 >> iter 31000, loss: 0.005077
 >> iter 32000, loss: 0.004801
 >> iter 33000, loss: 0.004619
 >> iter 34000, loss: 0.004472
 >> iter 35000, loss: 0.006111
 >> iter 36000, loss: 0.109553
 >> iter 37000, loss: 0.044184
 >> iter 38000, loss: 0.019701
 >> iter 39000, loss: 0.010417
 >> iter 40000, loss: 0.006810
   Number of active neurons: 7
 >> iter 41000, loss: 0.005353
 >> iter 42000, loss: 0.004732
 >> iter 43000, loss: 0.004459
 >> iter 44000, loss: 0.004268
 >> iter 45000, loss: 0.164664
 >> iter 46000, loss: 0.150014
 >> iter 47000, loss: 0.060431
 >> iter 48000, loss: 0.026458
 >> iter 49000, loss: 0.013408
 >> iter 50000, loss: 0.008271
   Number of active neurons: 6
 >> iter 51000, loss: 0.006156
 >> iter 52000, loss: 0.005217
 >> iter 53000, loss: 0.004743
 >> iter 54000, loss: 0.004476
 >> iter 55000, loss: 0.004290
 >> iter 56000, loss: 0.004157
 >> iter 57000, loss: 0.004040
 >> iter 58000, loss: 0.003949
 >> iter 59000, loss: 0.003888
 >> iter 60000, loss: 0.003799
   Number of active neurons: 6
 >> iter 61000, loss: 0.282128
 >> iter 62000, loss: 0.110416
 >> iter 63000, loss: 0.045576
 >> iter 64000, loss: 0.020935
 >> iter 65000, loss: 0.011389
 >> iter 66000, loss: 0.007536
 >> iter 67000, loss: 0.005888
 >> iter 68000, loss: 0.005097
 >> iter 69000, loss: 0.004680
 >> iter 70000, loss: 0.004403
   Number of active neurons: 6
 >> iter 71000, loss: 0.056480
 >> iter 72000, loss: 0.024016
 >> iter 73000, loss: 0.011778
 >> iter 74000, loss: 0.007079
 >> iter 75000, loss: 0.005219
 >> iter 76000, loss: 0.004433
 >> iter 77000, loss: 0.005272
 >> iter 78000, loss: 0.004451
 >> iter 79000, loss: 0.004037
 >> iter 80000, loss: 0.003805
   Number of active neurons: 6
 >> iter 81000, loss: 0.048382
 >> iter 82000, loss: 0.147429
 >> iter 83000, loss: 0.057729
 >> iter 84000, loss: 0.024263
 >> iter 85000, loss: 0.011725
 >> iter 86000, loss: 0.006953
 >> iter 87000, loss: 0.005099
 >> iter 88000, loss: 0.004323
 >> iter 89000, loss: 0.003986
 >> iter 90000, loss: 0.003804
   Number of active neurons: 6
 >> iter 91000, loss: 0.003702
 >> iter 92000, loss: 0.003629
 >> iter 93000, loss: 0.003567
 >> iter 94000, loss: 0.003519
 >> iter 95000, loss: 0.003461
 >> iter 96000, loss: 0.003423
 >> iter 97000, loss: 0.003384
 >> iter 98000, loss: 0.003328
 >> iter 99000, loss: 0.006425
 >> iter 100000, loss: 0.004369
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 15.748929
 >> iter 2000, loss: 6.019254
 >> iter 3000, loss: 2.227199
 >> iter 4000, loss: 0.827377
 >> iter 5000, loss: 0.311317
 >> iter 6000, loss: 0.119652
 >> iter 7000, loss: 0.048554
 >> iter 8000, loss: 0.021832
 >> iter 9000, loss: 0.011781
 >> iter 10000, loss: 0.007739
   Number of active neurons: 9
 >> iter 11000, loss: 0.006173
 >> iter 12000, loss: 0.005352
 >> iter 13000, loss: 0.005007
 >> iter 14000, loss: 0.004707
 >> iter 15000, loss: 0.245130
 >> iter 16000, loss: 0.096761
 >> iter 17000, loss: 0.040656
 >> iter 18000, loss: 0.019207
 >> iter 19000, loss: 0.010861
 >> iter 20000, loss: 0.007434
   Number of active neurons: 8
 >> iter 21000, loss: 0.005963
 >> iter 22000, loss: 0.005213
 >> iter 23000, loss: 0.004825
 >> iter 24000, loss: 0.004524
 >> iter 25000, loss: 0.221177
 >> iter 26000, loss: 0.085871
 >> iter 27000, loss: 0.035361
 >> iter 28000, loss: 0.016353
 >> iter 29000, loss: 0.009124
 >> iter 30000, loss: 0.006258
   Number of active neurons: 7
 >> iter 31000, loss: 0.005081
 >> iter 32000, loss: 0.004515
 >> iter 33000, loss: 0.004250
 >> iter 34000, loss: 0.004039
 >> iter 35000, loss: 0.003953
 >> iter 36000, loss: 0.003794
 >> iter 37000, loss: 0.028961
 >> iter 38000, loss: 0.013102
 >> iter 39000, loss: 0.007192
 >> iter 40000, loss: 0.004954
   Number of active neurons: 7
 >> iter 41000, loss: 0.004111
 >> iter 42000, loss: 0.003743
 >> iter 43000, loss: 0.003620
 >> iter 44000, loss: 0.003474
 >> iter 45000, loss: 0.014580
 >> iter 46000, loss: 0.007607
 >> iter 47000, loss: 0.047014
 >> iter 48000, loss: 0.019806
 >> iter 49000, loss: 0.009686
 >> iter 50000, loss: 0.005899
   Number of active neurons: 6
 >> iter 51000, loss: 0.004478
 >> iter 52000, loss: 0.003885
 >> iter 53000, loss: 0.004244
 >> iter 54000, loss: 0.003637
 >> iter 55000, loss: 0.003450
 >> iter 56000, loss: 0.003294
 >> iter 57000, loss: 0.018584
 >> iter 58000, loss: 0.050554
 >> iter 59000, loss: 0.020987
 >> iter 60000, loss: 0.010015
   Number of active neurons: 6
 >> iter 61000, loss: 0.005958
 >> iter 62000, loss: 0.004368
 >> iter 63000, loss: 0.105881
 >> iter 64000, loss: 0.041730
 >> iter 65000, loss: 0.017974
 >> iter 66000, loss: 0.009085
 >> iter 67000, loss: 0.005766
 >> iter 68000, loss: 0.004454
 >> iter 69000, loss: 0.003948
 >> iter 70000, loss: 0.003684
   Number of active neurons: 6
 >> iter 71000, loss: 0.003584
 >> iter 72000, loss: 0.003467
 >> iter 73000, loss: 0.003434
 >> iter 74000, loss: 0.024775
 >> iter 75000, loss: 0.055609
 >> iter 76000, loss: 0.023044
 >> iter 77000, loss: 0.010958
 >> iter 78000, loss: 0.006412
 >> iter 79000, loss: 0.004697
 >> iter 80000, loss: 0.053711
   Number of active neurons: 5
 >> iter 81000, loss: 0.057286
 >> iter 82000, loss: 0.023774
 >> iter 83000, loss: 0.011316
 >> iter 84000, loss: 0.006607
 >> iter 85000, loss: 0.004817
 >> iter 86000, loss: 0.004086
 >> iter 87000, loss: 0.003768
 >> iter 88000, loss: 0.194048
 >> iter 89000, loss: 0.075540
 >> iter 90000, loss: 0.032881
   Number of active neurons: 6
 >> iter 91000, loss: 0.015366
 >> iter 92000, loss: 0.008652
 >> iter 93000, loss: 0.006031
 >> iter 94000, loss: 0.004902
 >> iter 95000, loss: 0.004387
 >> iter 96000, loss: 0.004088
 >> iter 97000, loss: 0.003889
 >> iter 98000, loss: 0.072090
 >> iter 99000, loss: 0.029276
 >> iter 100000, loss: 0.013849
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 15.610770
 >> iter 2000, loss: 5.820124
 >> iter 3000, loss: 2.226262
 >> iter 4000, loss: 0.829972
 >> iter 5000, loss: 0.312946
 >> iter 6000, loss: 0.121086
 >> iter 7000, loss: 0.049688
 >> iter 8000, loss: 0.022748
 >> iter 9000, loss: 0.012482
 >> iter 10000, loss: 0.008334
   Number of active neurons: 7
 >> iter 11000, loss: 0.006621
 >> iter 12000, loss: 0.005754
 >> iter 13000, loss: 0.005325
 >> iter 14000, loss: 0.005003
 >> iter 15000, loss: 0.004815
 >> iter 16000, loss: 0.004624
 >> iter 17000, loss: 0.004511
 >> iter 18000, loss: 0.004377
 >> iter 19000, loss: 0.004301
 >> iter 20000, loss: 0.004190
   Number of active neurons: 6
 >> iter 21000, loss: 0.004133
 >> iter 22000, loss: 0.004040
 >> iter 23000, loss: 0.003993
 >> iter 24000, loss: 0.003912
 >> iter 25000, loss: 0.003875
 >> iter 26000, loss: 0.003803
 >> iter 27000, loss: 0.003776
 >> iter 28000, loss: 0.003704
 >> iter 29000, loss: 0.003683
 >> iter 30000, loss: 0.003621
   Number of active neurons: 5
 >> iter 31000, loss: 0.003602
 >> iter 32000, loss: 0.003541
 >> iter 33000, loss: 0.003525
 >> iter 34000, loss: 0.003469
 >> iter 35000, loss: 0.003455
 >> iter 36000, loss: 0.003406
 >> iter 37000, loss: 0.003395
 >> iter 38000, loss: 0.003353
 >> iter 39000, loss: 0.003336
 >> iter 40000, loss: 0.003298
   Number of active neurons: 5
 >> iter 41000, loss: 0.003291
 >> iter 42000, loss: 0.005528
 >> iter 43000, loss: 0.004098
 >> iter 44000, loss: 0.004523
 >> iter 45000, loss: 0.003585
 >> iter 46000, loss: 0.003227
 >> iter 47000, loss: 0.003112
 >> iter 48000, loss: 0.003081
 >> iter 49000, loss: 0.003075
 >> iter 50000, loss: 0.003357
   Number of active neurons: 5
 >> iter 51000, loss: 0.003116
 >> iter 52000, loss: 0.003049
 >> iter 53000, loss: 0.003003
 >> iter 54000, loss: 0.003008
 >> iter 55000, loss: 0.002973
 >> iter 56000, loss: 0.002974
 >> iter 57000, loss: 0.002939
 >> iter 58000, loss: 0.059715
 >> iter 59000, loss: 0.024079
 >> iter 60000, loss: 0.010923
   Number of active neurons: 4
 >> iter 61000, loss: 0.006082
 >> iter 62000, loss: 0.004274
 >> iter 63000, loss: 0.003608
 >> iter 64000, loss: 0.003342
 >> iter 65000, loss: 0.003238
 >> iter 66000, loss: 0.003193
 >> iter 67000, loss: 0.003143
 >> iter 68000, loss: 0.003157
 >> iter 69000, loss: 0.003074
 >> iter 70000, loss: 0.003101
   Number of active neurons: 4
 >> iter 71000, loss: 0.003021
 >> iter 72000, loss: 0.002985
 >> iter 73000, loss: 0.002953
 >> iter 74000, loss: 0.003037
 >> iter 75000, loss: 0.002940
 >> iter 76000, loss: 0.002913
 >> iter 77000, loss: 0.002881
 >> iter 78000, loss: 0.002919
 >> iter 79000, loss: 0.002864
 >> iter 80000, loss: 0.070887
   Number of active neurons: 5
 >> iter 81000, loss: 0.032519
 >> iter 82000, loss: 0.014133
 >> iter 83000, loss: 0.007310
 >> iter 84000, loss: 0.004753
 >> iter 85000, loss: 0.003779
 >> iter 86000, loss: 0.003395
 >> iter 87000, loss: 0.003226
 >> iter 88000, loss: 0.003153
 >> iter 89000, loss: 0.003091
 >> iter 90000, loss: 0.090923
   Number of active neurons: 4
 >> iter 91000, loss: 0.035859
 >> iter 92000, loss: 0.091265
 >> iter 93000, loss: 0.036328
 >> iter 94000, loss: 0.098586
 >> iter 95000, loss: 0.039341
 >> iter 96000, loss: 0.017310
 >> iter 97000, loss: 0.009070
 >> iter 98000, loss: 0.005903
 >> iter 99000, loss: 0.004658
 >> iter 100000, loss: 0.004109
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.510511
 >> iter 2000, loss: 6.418986
 >> iter 3000, loss: 2.388856
 >> iter 4000, loss: 0.891801
 >> iter 5000, loss: 0.337213
 >> iter 6000, loss: 0.131135
 >> iter 7000, loss: 0.054203
 >> iter 8000, loss: 0.025060
 >> iter 9000, loss: 0.013801
 >> iter 10000, loss: 0.009285
   Number of active neurons: 7
 >> iter 11000, loss: 0.007231
 >> iter 12000, loss: 0.006312
 >> iter 13000, loss: 0.005651
 >> iter 14000, loss: 0.005328
 >> iter 15000, loss: 0.004963
 >> iter 16000, loss: 0.004788
 >> iter 17000, loss: 0.004526
 >> iter 18000, loss: 0.004454
 >> iter 19000, loss: 0.004217
 >> iter 20000, loss: 0.004108
   Number of active neurons: 6
 >> iter 21000, loss: 0.003957
 >> iter 22000, loss: 0.003941
 >> iter 23000, loss: 0.003782
 >> iter 24000, loss: 0.003708
 >> iter 25000, loss: 0.003614
 >> iter 26000, loss: 0.003610
 >> iter 27000, loss: 0.003502
 >> iter 28000, loss: 0.003486
 >> iter 29000, loss: 0.003391
 >> iter 30000, loss: 0.003473
   Number of active neurons: 5
 >> iter 31000, loss: 0.003346
 >> iter 32000, loss: 0.003382
 >> iter 33000, loss: 0.003227
 >> iter 34000, loss: 0.069179
 >> iter 35000, loss: 0.317746
 >> iter 36000, loss: 0.121331
 >> iter 37000, loss: 0.048580
 >> iter 38000, loss: 0.021428
 >> iter 39000, loss: 0.011185
 >> iter 40000, loss: 0.007237
   Number of active neurons: 6
 >> iter 41000, loss: 0.005589
 >> iter 42000, loss: 0.005014
 >> iter 43000, loss: 0.004513
 >> iter 44000, loss: 0.004382
 >> iter 45000, loss: 0.004085
 >> iter 46000, loss: 0.004041
 >> iter 47000, loss: 0.003822
 >> iter 48000, loss: 0.003940
 >> iter 49000, loss: 0.003648
 >> iter 50000, loss: 0.003683
   Number of active neurons: 4
 >> iter 51000, loss: 0.003464
 >> iter 52000, loss: 0.003474
 >> iter 53000, loss: 0.003326
 >> iter 54000, loss: 0.006453
 >> iter 55000, loss: 0.004417
 >> iter 56000, loss: 0.003633
 >> iter 57000, loss: 0.003297
 >> iter 58000, loss: 0.003853
 >> iter 59000, loss: 0.003597
 >> iter 60000, loss: 0.003324
   Number of active neurons: 4
 >> iter 61000, loss: 0.003060
 >> iter 62000, loss: 0.008480
 >> iter 63000, loss: 0.004985
 >> iter 64000, loss: 0.003644
 >> iter 65000, loss: 0.003128
 >> iter 66000, loss: 0.003000
 >> iter 67000, loss: 0.002839
 >> iter 68000, loss: 0.003027
 >> iter 69000, loss: 0.002801
 >> iter 70000, loss: 0.002816
   Number of active neurons: 4
 >> iter 71000, loss: 0.002709
 >> iter 72000, loss: 0.127458
 >> iter 73000, loss: 0.048835
 >> iter 74000, loss: 0.019847
 >> iter 75000, loss: 0.009159
 >> iter 76000, loss: 0.005228
 >> iter 77000, loss: 0.003735
 >> iter 78000, loss: 0.138340
 >> iter 79000, loss: 0.052962
 >> iter 80000, loss: 0.021467
   Number of active neurons: 4
 >> iter 81000, loss: 0.009900
 >> iter 82000, loss: 0.136137
 >> iter 83000, loss: 0.052324
 >> iter 84000, loss: 0.021356
 >> iter 85000, loss: 0.009901
 >> iter 86000, loss: 0.005640
 >> iter 87000, loss: 0.004072
 >> iter 88000, loss: 0.137892
 >> iter 89000, loss: 0.052950
 >> iter 90000, loss: 0.021581
   Number of active neurons: 4
 >> iter 91000, loss: 0.010028
 >> iter 92000, loss: 0.005757
 >> iter 93000, loss: 0.004076
 >> iter 94000, loss: 0.003485
 >> iter 95000, loss: 0.003184
 >> iter 96000, loss: 0.135399
 >> iter 97000, loss: 0.051990
 >> iter 98000, loss: 0.021195
 >> iter 99000, loss: 0.009830
 >> iter 100000, loss: 0.005655
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0029999700003
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

