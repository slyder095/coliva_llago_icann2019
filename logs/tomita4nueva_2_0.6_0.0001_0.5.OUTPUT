 > Problema: tomita4nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.066272
 >> iter 2000, loss: 11.615452
 >> iter 3000, loss: 8.336413
 >> iter 4000, loss: 7.222390
 >> iter 5000, loss: 6.389221
 >> iter 6000, loss: 6.045323
 >> iter 7000, loss: 5.894684
 >> iter 8000, loss: 5.733412
 >> iter 9000, loss: 5.708228
 >> iter 10000, loss: 5.892522
   Number of active neurons: 2
 >> iter 11000, loss: 5.421709
 >> iter 12000, loss: 5.398863
 >> iter 13000, loss: 5.528647
 >> iter 14000, loss: 5.170438
 >> iter 15000, loss: 5.501730
 >> iter 16000, loss: 5.533276
 >> iter 17000, loss: 5.224077
 >> iter 18000, loss: 5.120926
 >> iter 19000, loss: 5.442113
 >> iter 20000, loss: 5.513917
   Number of active neurons: 2
 >> iter 21000, loss: 5.135058
 >> iter 22000, loss: 4.953780
 >> iter 23000, loss: 5.023367
 >> iter 24000, loss: 5.281895
 >> iter 25000, loss: 5.185172
 >> iter 26000, loss: 4.600752
 >> iter 27000, loss: 4.388706
 >> iter 28000, loss: 4.709667
 >> iter 29000, loss: 5.116474
 >> iter 30000, loss: 4.809550
   Number of active neurons: 2
 >> iter 31000, loss: 4.783113
 >> iter 32000, loss: 4.803794
 >> iter 33000, loss: 5.100200
 >> iter 34000, loss: 4.831651
 >> iter 35000, loss: 5.164379
 >> iter 36000, loss: 5.052357
 >> iter 37000, loss: 4.753210
 >> iter 38000, loss: 4.793587
 >> iter 39000, loss: 4.438776
 >> iter 40000, loss: 4.972796
   Number of active neurons: 2
 >> iter 41000, loss: 4.896098
 >> iter 42000, loss: 4.874685
 >> iter 43000, loss: 4.645228
 >> iter 44000, loss: 5.199942
 >> iter 45000, loss: 4.639174
 >> iter 46000, loss: 4.816460
 >> iter 47000, loss: 4.682638
 >> iter 48000, loss: 4.901469
 >> iter 49000, loss: 4.950482
 >> iter 50000, loss: 4.807030
   Number of active neurons: 2
 >> iter 51000, loss: 4.499077
 >> iter 52000, loss: 4.665040
 >> iter 53000, loss: 4.585374
 >> iter 54000, loss: 4.797331
 >> iter 55000, loss: 4.534701
 >> iter 56000, loss: 4.794077
 >> iter 57000, loss: 4.881023
 >> iter 58000, loss: 4.842725
 >> iter 59000, loss: 4.690399
 >> iter 60000, loss: 4.951578
   Number of active neurons: 2
 >> iter 61000, loss: 4.660702
 >> iter 62000, loss: 4.493084
 >> iter 63000, loss: 4.479367
 >> iter 64000, loss: 4.353348
 >> iter 65000, loss: 4.048553
 >> iter 66000, loss: 4.517898
 >> iter 67000, loss: 4.592358
 >> iter 68000, loss: 4.503024
 >> iter 69000, loss: 4.670828
 >> iter 70000, loss: 4.602929
   Number of active neurons: 2
 >> iter 71000, loss: 4.241970
 >> iter 72000, loss: 4.110129
 >> iter 73000, loss: 4.290415
 >> iter 74000, loss: 4.332124
 >> iter 75000, loss: 4.529398
 >> iter 76000, loss: 4.386417
 >> iter 77000, loss: 4.022681
 >> iter 78000, loss: 4.242757
 >> iter 79000, loss: 4.083467
 >> iter 80000, loss: 4.253561
   Number of active neurons: 2
 >> iter 81000, loss: 4.332679
 >> iter 82000, loss: 4.516467
 >> iter 83000, loss: 3.962711
 >> iter 84000, loss: 4.111081
 >> iter 85000, loss: 4.538796
 >> iter 86000, loss: 4.363513
 >> iter 87000, loss: 4.066115
 >> iter 88000, loss: 4.126259
 >> iter 89000, loss: 4.035770
 >> iter 90000, loss: 4.179981
   Number of active neurons: 2
 >> iter 91000, loss: 4.078439
 >> iter 92000, loss: 4.468728
 >> iter 93000, loss: 4.601702
 >> iter 94000, loss: 4.115648
 >> iter 95000, loss: 4.253438
 >> iter 96000, loss: 4.029711
 >> iter 97000, loss: 4.165695
 >> iter 98000, loss: 4.030614
 >> iter 99000, loss: 3.905710
 >> iter 100000, loss: 4.283417
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.720604
 >> iter 2000, loss: 12.585411
 >> iter 3000, loss: 9.373432
 >> iter 4000, loss: 7.659632
 >> iter 5000, loss: 6.897297
 >> iter 6000, loss: 6.512511
 >> iter 7000, loss: 5.801879
 >> iter 8000, loss: 5.872353
 >> iter 9000, loss: 5.931540
 >> iter 10000, loss: 5.515878
   Number of active neurons: 2
 >> iter 11000, loss: 5.377650
 >> iter 12000, loss: 5.235276
 >> iter 13000, loss: 5.228990
 >> iter 14000, loss: 5.229964
 >> iter 15000, loss: 5.095857
 >> iter 16000, loss: 4.874058
 >> iter 17000, loss: 4.467234
 >> iter 18000, loss: 4.244585
 >> iter 19000, loss: 4.534574
 >> iter 20000, loss: 4.057555
   Number of active neurons: 2
 >> iter 21000, loss: 4.460207
 >> iter 22000, loss: 4.273269
 >> iter 23000, loss: 4.346734
 >> iter 24000, loss: 4.115088
 >> iter 25000, loss: 4.052665
 >> iter 26000, loss: 4.152214
 >> iter 27000, loss: 4.126560
 >> iter 28000, loss: 4.014143
 >> iter 29000, loss: 4.137066
 >> iter 30000, loss: 4.284779
   Number of active neurons: 2
 >> iter 31000, loss: 4.434022
 >> iter 32000, loss: 4.284279
 >> iter 33000, loss: 4.345966
 >> iter 34000, loss: 3.941248
 >> iter 35000, loss: 4.018157
 >> iter 36000, loss: 3.949856
 >> iter 37000, loss: 3.558088
 >> iter 38000, loss: 3.869235
 >> iter 39000, loss: 3.858868
 >> iter 40000, loss: 4.295797
   Number of active neurons: 2
 >> iter 41000, loss: 4.141858
 >> iter 42000, loss: 4.019727
 >> iter 43000, loss: 3.796155
 >> iter 44000, loss: 3.730106
 >> iter 45000, loss: 3.523548
 >> iter 46000, loss: 3.625813
 >> iter 47000, loss: 3.590278
 >> iter 48000, loss: 3.542524
 >> iter 49000, loss: 3.708185
 >> iter 50000, loss: 3.687929
   Number of active neurons: 2
 >> iter 51000, loss: 3.664388
 >> iter 52000, loss: 3.632278
 >> iter 53000, loss: 3.764805
 >> iter 54000, loss: 3.854805
 >> iter 55000, loss: 3.684917
 >> iter 56000, loss: 3.889733
 >> iter 57000, loss: 3.922697
 >> iter 58000, loss: 3.371550
 >> iter 59000, loss: 3.282923
 >> iter 60000, loss: 3.253982
   Number of active neurons: 2
 >> iter 61000, loss: 3.075646
 >> iter 62000, loss: 3.345079
 >> iter 63000, loss: 3.390821
 >> iter 64000, loss: 3.405289
 >> iter 65000, loss: 3.109370
 >> iter 66000, loss: 3.305849
 >> iter 67000, loss: 3.658445
 >> iter 68000, loss: 3.793495
 >> iter 69000, loss: 3.430459
 >> iter 70000, loss: 3.748438
   Number of active neurons: 2
 >> iter 71000, loss: 3.444105
 >> iter 72000, loss: 3.384134
 >> iter 73000, loss: 3.044188
 >> iter 74000, loss: 3.038816
 >> iter 75000, loss: 3.585012
 >> iter 76000, loss: 3.256074
 >> iter 77000, loss: 3.300315
 >> iter 78000, loss: 3.246718
 >> iter 79000, loss: 3.192733
 >> iter 80000, loss: 3.207287
   Number of active neurons: 2
 >> iter 81000, loss: 3.262915
 >> iter 82000, loss: 3.401612
 >> iter 83000, loss: 3.467885
 >> iter 84000, loss: 3.399366
 >> iter 85000, loss: 3.886624
 >> iter 86000, loss: 3.570877
 >> iter 87000, loss: 3.425558
 >> iter 88000, loss: 3.290257
 >> iter 89000, loss: 3.162066
 >> iter 90000, loss: 3.457105
   Number of active neurons: 2
 >> iter 91000, loss: 3.122332
 >> iter 92000, loss: 3.183887
 >> iter 93000, loss: 3.535023
 >> iter 94000, loss: 3.729693
 >> iter 95000, loss: 3.499725
 >> iter 96000, loss: 3.418012
 >> iter 97000, loss: 3.162439
 >> iter 98000, loss: 3.405943
 >> iter 99000, loss: 3.609408
 >> iter 100000, loss: 3.665736
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.567240
 >> iter 2000, loss: 12.069863
 >> iter 3000, loss: 9.102535
 >> iter 4000, loss: 7.531950
 >> iter 5000, loss: 6.919484
 >> iter 6000, loss: 6.504612
 >> iter 7000, loss: 5.811718
 >> iter 8000, loss: 6.027158
 >> iter 9000, loss: 5.875830
 >> iter 10000, loss: 5.461185
   Number of active neurons: 2
 >> iter 11000, loss: 5.451214
 >> iter 12000, loss: 5.467336
 >> iter 13000, loss: 4.636157
 >> iter 14000, loss: 4.871375
 >> iter 15000, loss: 4.773949
 >> iter 16000, loss: 4.588466
 >> iter 17000, loss: 4.348798
 >> iter 18000, loss: 4.304643
 >> iter 19000, loss: 4.666365
 >> iter 20000, loss: 4.396878
   Number of active neurons: 2
 >> iter 21000, loss: 4.545263
 >> iter 22000, loss: 4.234105
 >> iter 23000, loss: 4.413366
 >> iter 24000, loss: 4.250987
 >> iter 25000, loss: 3.942456
 >> iter 26000, loss: 3.868876
 >> iter 27000, loss: 4.257393
 >> iter 28000, loss: 4.451342
 >> iter 29000, loss: 4.126833
 >> iter 30000, loss: 4.338221
   Number of active neurons: 2
 >> iter 31000, loss: 4.327115
 >> iter 32000, loss: 4.311804
 >> iter 33000, loss: 4.554815
 >> iter 34000, loss: 4.143166
 >> iter 35000, loss: 4.055415
 >> iter 36000, loss: 3.978691
 >> iter 37000, loss: 3.644256
 >> iter 38000, loss: 3.462458
 >> iter 39000, loss: 3.975252
 >> iter 40000, loss: 4.009913
   Number of active neurons: 2
 >> iter 41000, loss: 3.811251
 >> iter 42000, loss: 3.690269
 >> iter 43000, loss: 3.594227
 >> iter 44000, loss: 3.579462
 >> iter 45000, loss: 3.634630
 >> iter 46000, loss: 3.608432
 >> iter 47000, loss: 4.056352
 >> iter 48000, loss: 3.864164
 >> iter 49000, loss: 4.190621
 >> iter 50000, loss: 3.783849
   Number of active neurons: 2
 >> iter 51000, loss: 3.954020
 >> iter 52000, loss: 4.487299
 >> iter 53000, loss: 4.407373
 >> iter 54000, loss: 4.001513
 >> iter 55000, loss: 4.010315
 >> iter 56000, loss: 3.713250
 >> iter 57000, loss: 3.903616
 >> iter 58000, loss: 4.152914
 >> iter 59000, loss: 3.902838
 >> iter 60000, loss: 3.843235
   Number of active neurons: 2
 >> iter 61000, loss: 3.857253
 >> iter 62000, loss: 3.737896
 >> iter 63000, loss: 3.491886
 >> iter 64000, loss: 3.533126
 >> iter 65000, loss: 3.675455
 >> iter 66000, loss: 3.453709
 >> iter 67000, loss: 3.596924
 >> iter 68000, loss: 3.832275
 >> iter 69000, loss: 3.916755
 >> iter 70000, loss: 4.163831
   Number of active neurons: 2
 >> iter 71000, loss: 3.798949
 >> iter 72000, loss: 3.660570
 >> iter 73000, loss: 3.812626
 >> iter 74000, loss: 3.653397
 >> iter 75000, loss: 3.449435
 >> iter 76000, loss: 3.172815
 >> iter 77000, loss: 3.152569
 >> iter 78000, loss: 3.629876
 >> iter 79000, loss: 3.676903
 >> iter 80000, loss: 3.582176
   Number of active neurons: 2
 >> iter 81000, loss: 3.149034
 >> iter 82000, loss: 3.493216
 >> iter 83000, loss: 3.259006
 >> iter 84000, loss: 3.354759
 >> iter 85000, loss: 3.469646
 >> iter 86000, loss: 3.699991
 >> iter 87000, loss: 3.356133
 >> iter 88000, loss: 3.405184
 >> iter 89000, loss: 3.169763
 >> iter 90000, loss: 3.241505
   Number of active neurons: 2
 >> iter 91000, loss: 3.242763
 >> iter 92000, loss: 3.589252
 >> iter 93000, loss: 3.565497
 >> iter 94000, loss: 3.575440
 >> iter 95000, loss: 3.323835
 >> iter 96000, loss: 3.151812
 >> iter 97000, loss: 3.071432
 >> iter 98000, loss: 3.252265
 >> iter 99000, loss: 3.266767
 >> iter 100000, loss: 3.249957
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 20.524762
 >> iter 2000, loss: 17.268534
 >> iter 3000, loss: 11.768304
 >> iter 4000, loss: 8.553535
 >> iter 5000, loss: 7.376664
 >> iter 6000, loss: 6.660422
 >> iter 7000, loss: 6.423518
 >> iter 8000, loss: 5.946031
 >> iter 9000, loss: 5.641759
 >> iter 10000, loss: 5.548122
   Number of active neurons: 2
 >> iter 11000, loss: 5.366376
 >> iter 12000, loss: 4.984592
 >> iter 13000, loss: 4.654383
 >> iter 14000, loss: 5.120458
 >> iter 15000, loss: 5.072366
 >> iter 16000, loss: 5.084849
 >> iter 17000, loss: 5.169497
 >> iter 18000, loss: 5.278202
 >> iter 19000, loss: 4.944460
 >> iter 20000, loss: 4.346873
   Number of active neurons: 2
 >> iter 21000, loss: 4.958436
 >> iter 22000, loss: 4.130735
 >> iter 23000, loss: 4.725283
 >> iter 24000, loss: 4.272443
 >> iter 25000, loss: 4.134491
 >> iter 26000, loss: 4.037463
 >> iter 27000, loss: 4.186531
 >> iter 28000, loss: 4.220666
 >> iter 29000, loss: 4.608617
 >> iter 30000, loss: 4.326910
   Number of active neurons: 2
 >> iter 31000, loss: 4.239393
 >> iter 32000, loss: 4.080056
 >> iter 33000, loss: 4.293088
 >> iter 34000, loss: 3.811280
 >> iter 35000, loss: 3.756302
 >> iter 36000, loss: 4.109262
 >> iter 37000, loss: 4.315250
 >> iter 38000, loss: 4.046941
 >> iter 39000, loss: 3.872251
 >> iter 40000, loss: 3.705070
   Number of active neurons: 2
 >> iter 41000, loss: 3.945523
 >> iter 42000, loss: 3.589614
 >> iter 43000, loss: 3.948304
 >> iter 44000, loss: 3.764444
 >> iter 45000, loss: 3.639080
 >> iter 46000, loss: 3.809639
 >> iter 47000, loss: 3.954920
 >> iter 48000, loss: 3.952463
 >> iter 49000, loss: 4.074571
 >> iter 50000, loss: 4.128084
   Number of active neurons: 2
 >> iter 51000, loss: 3.735416
 >> iter 52000, loss: 3.859921
 >> iter 53000, loss: 3.927241
 >> iter 54000, loss: 3.332336
 >> iter 55000, loss: 3.781555
 >> iter 56000, loss: 3.794986
 >> iter 57000, loss: 3.834650
 >> iter 58000, loss: 3.416131
 >> iter 59000, loss: 3.689155
 >> iter 60000, loss: 3.361084
   Number of active neurons: 2
 >> iter 61000, loss: 3.135270
 >> iter 62000, loss: 3.494146
 >> iter 63000, loss: 3.091878
 >> iter 64000, loss: 3.078435
 >> iter 65000, loss: 3.387294
 >> iter 66000, loss: 3.157159
 >> iter 67000, loss: 3.268689
 >> iter 68000, loss: 3.408076
 >> iter 69000, loss: 2.914714
 >> iter 70000, loss: 3.314362
   Number of active neurons: 2
 >> iter 71000, loss: 3.413663
 >> iter 72000, loss: 3.626135
 >> iter 73000, loss: 3.333347
 >> iter 74000, loss: 3.530995
 >> iter 75000, loss: 3.200656
 >> iter 76000, loss: 3.013986
 >> iter 77000, loss: 3.452291
 >> iter 78000, loss: 3.563102
 >> iter 79000, loss: 3.403102
 >> iter 80000, loss: 3.537198
   Number of active neurons: 2
 >> iter 81000, loss: 3.380748
 >> iter 82000, loss: 3.301236
 >> iter 83000, loss: 3.391880
 >> iter 84000, loss: 3.522646
 >> iter 85000, loss: 3.310411
 >> iter 86000, loss: 3.429914
 >> iter 87000, loss: 3.379635
 >> iter 88000, loss: 3.562826
 >> iter 89000, loss: 3.224770
 >> iter 90000, loss: 3.616469
   Number of active neurons: 2
 >> iter 91000, loss: 3.469625
 >> iter 92000, loss: 3.489115
 >> iter 93000, loss: 3.331262
 >> iter 94000, loss: 3.070972
 >> iter 95000, loss: 3.163317
 >> iter 96000, loss: 3.397550
 >> iter 97000, loss: 3.262005
 >> iter 98000, loss: 3.086715
 >> iter 99000, loss: 2.999973
 >> iter 100000, loss: 3.438142
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524760
 >> iter 2000, loss: 18.054276
 >> iter 3000, loss: 17.068459
 >> iter 4000, loss: 16.779361
 >> iter 5000, loss: 16.602166
 >> iter 6000, loss: 16.598186
 >> iter 7000, loss: 16.539945
 >> iter 8000, loss: 15.639737
 >> iter 9000, loss: 11.614128
 >> iter 10000, loss: 8.789806
   Number of active neurons: 2
 >> iter 11000, loss: 7.270216
 >> iter 12000, loss: 6.649495
 >> iter 13000, loss: 6.466262
 >> iter 14000, loss: 5.945061
 >> iter 15000, loss: 5.883584
 >> iter 16000, loss: 5.555519
 >> iter 17000, loss: 5.378201
 >> iter 18000, loss: 4.821919
 >> iter 19000, loss: 5.057622
 >> iter 20000, loss: 4.748504
   Number of active neurons: 2
 >> iter 21000, loss: 4.888090
 >> iter 22000, loss: 4.723082
 >> iter 23000, loss: 4.739727
 >> iter 24000, loss: 4.235634
 >> iter 25000, loss: 4.329117
 >> iter 26000, loss: 4.364313
 >> iter 27000, loss: 4.480902
 >> iter 28000, loss: 4.544357
 >> iter 29000, loss: 4.365199
 >> iter 30000, loss: 4.146231
   Number of active neurons: 2
 >> iter 31000, loss: 4.437343
 >> iter 32000, loss: 4.308231
 >> iter 33000, loss: 4.218803
 >> iter 34000, loss: 4.395495
 >> iter 35000, loss: 4.141508
 >> iter 36000, loss: 3.986589
 >> iter 37000, loss: 3.934590
 >> iter 38000, loss: 4.020808
 >> iter 39000, loss: 3.949255
 >> iter 40000, loss: 4.003432
   Number of active neurons: 2
 >> iter 41000, loss: 4.045631
 >> iter 42000, loss: 4.238272
 >> iter 43000, loss: 4.029136
 >> iter 44000, loss: 3.806693
 >> iter 45000, loss: 4.029834
 >> iter 46000, loss: 3.890101
 >> iter 47000, loss: 3.960830
 >> iter 48000, loss: 3.930277
 >> iter 49000, loss: 4.137806
 >> iter 50000, loss: 4.085658
   Number of active neurons: 2
 >> iter 51000, loss: 3.956174
 >> iter 52000, loss: 4.115368
 >> iter 53000, loss: 3.492389
 >> iter 54000, loss: 3.745809
 >> iter 55000, loss: 3.914084
 >> iter 56000, loss: 4.012613
 >> iter 57000, loss: 3.767606
 >> iter 58000, loss: 3.691409
 >> iter 59000, loss: 3.467904
 >> iter 60000, loss: 3.684054
   Number of active neurons: 2
 >> iter 61000, loss: 3.576491
 >> iter 62000, loss: 3.574978
 >> iter 63000, loss: 3.343131
 >> iter 64000, loss: 3.621936
 >> iter 65000, loss: 3.595768
 >> iter 66000, loss: 3.508582
 >> iter 67000, loss: 3.393484
 >> iter 68000, loss: 3.826461
 >> iter 69000, loss: 3.379827
 >> iter 70000, loss: 3.734531
   Number of active neurons: 2
 >> iter 71000, loss: 3.527842
 >> iter 72000, loss: 3.320998
 >> iter 73000, loss: 3.457574
 >> iter 74000, loss: 3.288132
 >> iter 75000, loss: 3.356074
 >> iter 76000, loss: 3.563292
 >> iter 77000, loss: 3.821908
 >> iter 78000, loss: 3.764663
 >> iter 79000, loss: 3.470760
 >> iter 80000, loss: 3.827053
   Number of active neurons: 2
 >> iter 81000, loss: 3.579133
 >> iter 82000, loss: 3.418402
 >> iter 83000, loss: 3.484468
 >> iter 84000, loss: 3.138768
 >> iter 85000, loss: 3.266892
 >> iter 86000, loss: 3.459342
 >> iter 87000, loss: 3.067466
 >> iter 88000, loss: 3.459988
 >> iter 89000, loss: 3.038569
 >> iter 90000, loss: 3.528403
   Number of active neurons: 2
 >> iter 91000, loss: 3.213099
 >> iter 92000, loss: 3.205888
 >> iter 93000, loss: 3.485983
 >> iter 94000, loss: 3.391779
 >> iter 95000, loss: 3.173662
 >> iter 96000, loss: 3.436904
 >> iter 97000, loss: 2.964217
 >> iter 98000, loss: 3.039185
 >> iter 99000, loss: 3.163575
 >> iter 100000, loss: 3.721409
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524758
 >> iter 2000, loss: 18.054280
 >> iter 3000, loss: 17.068462
 >> iter 4000, loss: 16.779362
 >> iter 5000, loss: 16.602167
 >> iter 6000, loss: 16.598184
 >> iter 7000, loss: 16.539944
 >> iter 8000, loss: 15.302942
 >> iter 9000, loss: 10.904194
 >> iter 10000, loss: 8.278199
   Number of active neurons: 2
 >> iter 11000, loss: 7.224111
 >> iter 12000, loss: 6.384474
 >> iter 13000, loss: 5.912943
 >> iter 14000, loss: 5.783761
 >> iter 15000, loss: 5.876329
 >> iter 16000, loss: 5.781697
 >> iter 17000, loss: 5.367251
 >> iter 18000, loss: 5.461331
 >> iter 19000, loss: 5.044548
 >> iter 20000, loss: 5.210565
   Number of active neurons: 2
 >> iter 21000, loss: 5.215976
 >> iter 22000, loss: 5.239648
 >> iter 23000, loss: 5.092088
 >> iter 24000, loss: 4.968634
 >> iter 25000, loss: 4.961014
 >> iter 26000, loss: 5.253199
 >> iter 27000, loss: 4.938496
 >> iter 28000, loss: 5.095110
 >> iter 29000, loss: 4.746172
 >> iter 30000, loss: 4.868812
   Number of active neurons: 2
 >> iter 31000, loss: 4.601855
 >> iter 32000, loss: 5.079943
 >> iter 33000, loss: 4.990263
 >> iter 34000, loss: 4.944514
 >> iter 35000, loss: 4.888656
 >> iter 36000, loss: 4.877673
 >> iter 37000, loss: 4.643259
 >> iter 38000, loss: 4.368891
 >> iter 39000, loss: 4.614340
 >> iter 40000, loss: 4.348552
   Number of active neurons: 2
 >> iter 41000, loss: 4.521141
 >> iter 42000, loss: 5.035300
 >> iter 43000, loss: 5.104905
 >> iter 44000, loss: 4.744460
 >> iter 45000, loss: 4.573392
 >> iter 46000, loss: 4.368660
 >> iter 47000, loss: 4.641354
 >> iter 48000, loss: 4.954307
 >> iter 49000, loss: 4.935725
 >> iter 50000, loss: 4.929201
   Number of active neurons: 2
 >> iter 51000, loss: 4.906076
 >> iter 52000, loss: 4.855778
 >> iter 53000, loss: 4.844030
 >> iter 54000, loss: 4.937216
 >> iter 55000, loss: 5.069901
 >> iter 56000, loss: 4.864757
 >> iter 57000, loss: 4.496027
 >> iter 58000, loss: 4.583630
 >> iter 59000, loss: 4.605915
 >> iter 60000, loss: 4.498501
   Number of active neurons: 2
 >> iter 61000, loss: 4.399914
 >> iter 62000, loss: 4.738090
 >> iter 63000, loss: 4.476046
 >> iter 64000, loss: 4.923830
 >> iter 65000, loss: 4.505381
 >> iter 66000, loss: 4.377218
 >> iter 67000, loss: 4.654263
 >> iter 68000, loss: 4.439495
 >> iter 69000, loss: 4.529075
 >> iter 70000, loss: 4.698888
   Number of active neurons: 2
 >> iter 71000, loss: 4.527339
 >> iter 72000, loss: 4.866408
 >> iter 73000, loss: 4.518989
 >> iter 74000, loss: 4.673755
 >> iter 75000, loss: 4.675438
 >> iter 76000, loss: 4.299967
 >> iter 77000, loss: 4.403605
 >> iter 78000, loss: 4.617288
 >> iter 79000, loss: 4.955548
 >> iter 80000, loss: 4.829321
   Number of active neurons: 2
 >> iter 81000, loss: 4.699430
 >> iter 82000, loss: 4.393095
 >> iter 83000, loss: 4.129090
 >> iter 84000, loss: 4.133535
 >> iter 85000, loss: 3.842747
 >> iter 86000, loss: 4.038243
 >> iter 87000, loss: 4.384747
 >> iter 88000, loss: 4.545320
 >> iter 89000, loss: 4.230247
 >> iter 90000, loss: 4.243298
   Number of active neurons: 2
 >> iter 91000, loss: 3.976091
 >> iter 92000, loss: 4.108623
 >> iter 93000, loss: 3.991278
 >> iter 94000, loss: 4.407074
 >> iter 95000, loss: 4.415932
 >> iter 96000, loss: 4.310129
 >> iter 97000, loss: 4.322853
 >> iter 98000, loss: 4.265663
 >> iter 99000, loss: 3.938198
 >> iter 100000, loss: 3.955830
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.007550
 >> iter 2000, loss: 11.576539
 >> iter 3000, loss: 8.258412
 >> iter 4000, loss: 7.492925
 >> iter 5000, loss: 6.775313
 >> iter 6000, loss: 6.266432
 >> iter 7000, loss: 6.191102
 >> iter 8000, loss: 5.827172
 >> iter 9000, loss: 5.647125
 >> iter 10000, loss: 5.412729
   Number of active neurons: 2
 >> iter 11000, loss: 5.492718
 >> iter 12000, loss: 5.440135
 >> iter 13000, loss: 5.303828
 >> iter 14000, loss: 4.892206
 >> iter 15000, loss: 4.437049
 >> iter 16000, loss: 4.563272
 >> iter 17000, loss: 4.808441
 >> iter 18000, loss: 4.588403
 >> iter 19000, loss: 4.573950
 >> iter 20000, loss: 4.202374
   Number of active neurons: 2
 >> iter 21000, loss: 3.990025
 >> iter 22000, loss: 4.506817
 >> iter 23000, loss: 4.201553
 >> iter 24000, loss: 3.872452
 >> iter 25000, loss: 4.155627
 >> iter 26000, loss: 4.082766
 >> iter 27000, loss: 4.360807
 >> iter 28000, loss: 4.259772
 >> iter 29000, loss: 4.316275
 >> iter 30000, loss: 4.535814
   Number of active neurons: 2
 >> iter 31000, loss: 4.380192
 >> iter 32000, loss: 4.366967
 >> iter 33000, loss: 4.037889
 >> iter 34000, loss: 4.117453
 >> iter 35000, loss: 3.945433
 >> iter 36000, loss: 4.004306
 >> iter 37000, loss: 3.948706
 >> iter 38000, loss: 3.844922
 >> iter 39000, loss: 3.672726
 >> iter 40000, loss: 4.152360
   Number of active neurons: 2
 >> iter 41000, loss: 3.997911
 >> iter 42000, loss: 3.447205
 >> iter 43000, loss: 3.406015
 >> iter 44000, loss: 3.436589
 >> iter 45000, loss: 3.577500
 >> iter 46000, loss: 3.806278
 >> iter 47000, loss: 3.445877
 >> iter 48000, loss: 3.416360
 >> iter 49000, loss: 3.575766
 >> iter 50000, loss: 3.365056
   Number of active neurons: 2
 >> iter 51000, loss: 3.484996
 >> iter 52000, loss: 3.724304
 >> iter 53000, loss: 3.697424
 >> iter 54000, loss: 3.553309
 >> iter 55000, loss: 3.644567
 >> iter 56000, loss: 3.818285
 >> iter 57000, loss: 3.676170
 >> iter 58000, loss: 3.616375
 >> iter 59000, loss: 3.560653
 >> iter 60000, loss: 3.684240
   Number of active neurons: 2
 >> iter 61000, loss: 3.448107
 >> iter 62000, loss: 3.619332
 >> iter 63000, loss: 3.595786
 >> iter 64000, loss: 3.827842
 >> iter 65000, loss: 3.650280
 >> iter 66000, loss: 3.532607
 >> iter 67000, loss: 3.529798
 >> iter 68000, loss: 3.462673
 >> iter 69000, loss: 3.356367
 >> iter 70000, loss: 3.460735
   Number of active neurons: 2
 >> iter 71000, loss: 3.441389
 >> iter 72000, loss: 2.928963
 >> iter 73000, loss: 3.281443
 >> iter 74000, loss: 3.458344
 >> iter 75000, loss: 2.998214
 >> iter 76000, loss: 3.400903
 >> iter 77000, loss: 3.326910
 >> iter 78000, loss: 3.236642
 >> iter 79000, loss: 3.451907
 >> iter 80000, loss: 3.492508
   Number of active neurons: 2
 >> iter 81000, loss: 3.557776
 >> iter 82000, loss: 3.753372
 >> iter 83000, loss: 3.372763
 >> iter 84000, loss: 3.685042
 >> iter 85000, loss: 3.338651
 >> iter 86000, loss: 3.816910
 >> iter 87000, loss: 3.344579
 >> iter 88000, loss: 2.925724
 >> iter 89000, loss: 3.408186
 >> iter 90000, loss: 3.382685
   Number of active neurons: 2
 >> iter 91000, loss: 3.310339
 >> iter 92000, loss: 3.581136
 >> iter 93000, loss: 3.425178
 >> iter 94000, loss: 3.655287
 >> iter 95000, loss: 3.308580
 >> iter 96000, loss: 3.153916
 >> iter 97000, loss: 3.290872
 >> iter 98000, loss: 3.098862
 >> iter 99000, loss: 3.063202
 >> iter 100000, loss: 3.436395
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524758
 >> iter 2000, loss: 18.054277
 >> iter 3000, loss: 17.068460
 >> iter 4000, loss: 16.779358
 >> iter 5000, loss: 16.602165
 >> iter 6000, loss: 16.598181
 >> iter 7000, loss: 16.539942
 >> iter 8000, loss: 16.570967
 >> iter 9000, loss: 16.532181
 >> iter 10000, loss: 15.936294
   Number of active neurons: 2
 >> iter 11000, loss: 11.598527
 >> iter 12000, loss: 8.749277
 >> iter 13000, loss: 7.401336
 >> iter 14000, loss: 6.245579
 >> iter 15000, loss: 5.642255
 >> iter 16000, loss: 5.469882
 >> iter 17000, loss: 5.090231
 >> iter 18000, loss: 4.925449
 >> iter 19000, loss: 4.849237
 >> iter 20000, loss: 4.977606
   Number of active neurons: 2
 >> iter 21000, loss: 5.306863
 >> iter 22000, loss: 5.409669
 >> iter 23000, loss: 5.268330
 >> iter 24000, loss: 5.167584
 >> iter 25000, loss: 5.321412
 >> iter 26000, loss: 5.384329
 >> iter 27000, loss: 5.106354
 >> iter 28000, loss: 5.395732
 >> iter 29000, loss: 5.243427
 >> iter 30000, loss: 5.142495
   Number of active neurons: 2
 >> iter 31000, loss: 4.926730
 >> iter 32000, loss: 5.274535
 >> iter 33000, loss: 4.677004
 >> iter 34000, loss: 4.695238
 >> iter 35000, loss: 4.712836
 >> iter 36000, loss: 4.758262
 >> iter 37000, loss: 4.749655
 >> iter 38000, loss: 4.822641
 >> iter 39000, loss: 4.796495
 >> iter 40000, loss: 4.940525
   Number of active neurons: 2
 >> iter 41000, loss: 4.577523
 >> iter 42000, loss: 4.793000
 >> iter 43000, loss: 4.544838
 >> iter 44000, loss: 4.876281
 >> iter 45000, loss: 4.828052
 >> iter 46000, loss: 4.644967
 >> iter 47000, loss: 4.647330
 >> iter 48000, loss: 4.966870
 >> iter 49000, loss: 4.783391
 >> iter 50000, loss: 4.805532
   Number of active neurons: 2
 >> iter 51000, loss: 4.760548
 >> iter 52000, loss: 5.082266
 >> iter 53000, loss: 4.595185
 >> iter 54000, loss: 4.668317
 >> iter 55000, loss: 4.502769
 >> iter 56000, loss: 4.357504
 >> iter 57000, loss: 4.308732
 >> iter 58000, loss: 4.804824
 >> iter 59000, loss: 4.897717
 >> iter 60000, loss: 4.663736
   Number of active neurons: 2
 >> iter 61000, loss: 4.408976
 >> iter 62000, loss: 4.585466
 >> iter 63000, loss: 4.757482
 >> iter 64000, loss: 4.457988
 >> iter 65000, loss: 4.724750
 >> iter 66000, loss: 4.299094
 >> iter 67000, loss: 4.211258
 >> iter 68000, loss: 4.583686
 >> iter 69000, loss: 4.480559
 >> iter 70000, loss: 4.693446
   Number of active neurons: 2
 >> iter 71000, loss: 4.539506
 >> iter 72000, loss: 4.544297
 >> iter 73000, loss: 4.712120
 >> iter 74000, loss: 4.986975
 >> iter 75000, loss: 4.353605
 >> iter 76000, loss: 4.459552
 >> iter 77000, loss: 4.525346
 >> iter 78000, loss: 4.308920
 >> iter 79000, loss: 4.080003
 >> iter 80000, loss: 4.149404
   Number of active neurons: 2
 >> iter 81000, loss: 3.876527
 >> iter 82000, loss: 4.628431
 >> iter 83000, loss: 4.406090
 >> iter 84000, loss: 4.343712
 >> iter 85000, loss: 4.411949
 >> iter 86000, loss: 4.269463
 >> iter 87000, loss: 4.246607
 >> iter 88000, loss: 4.188562
 >> iter 89000, loss: 4.184008
 >> iter 90000, loss: 4.609746
   Number of active neurons: 2
 >> iter 91000, loss: 4.395551
 >> iter 92000, loss: 4.302060
 >> iter 93000, loss: 3.981227
 >> iter 94000, loss: 3.984066
 >> iter 95000, loss: 3.719768
 >> iter 96000, loss: 3.936977
 >> iter 97000, loss: 4.170681
 >> iter 98000, loss: 4.300715
 >> iter 99000, loss: 4.329391
 >> iter 100000, loss: 4.322349
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524761
 >> iter 2000, loss: 18.054277
 >> iter 3000, loss: 17.068460
 >> iter 4000, loss: 16.779362
 >> iter 5000, loss: 16.602168
 >> iter 6000, loss: 16.598184
 >> iter 7000, loss: 16.539944
 >> iter 8000, loss: 16.570967
 >> iter 9000, loss: 16.532180
 >> iter 10000, loss: 16.581927
   Number of active neurons: 0
 >> iter 11000, loss: 16.532518
 >> iter 12000, loss: 16.591970
 >> iter 13000, loss: 16.533414
 >> iter 14000, loss: 16.598211
 >> iter 15000, loss: 16.533573
 >> iter 16000, loss: 16.603666
 >> iter 17000, loss: 16.535595
 >> iter 18000, loss: 16.598709
 >> iter 19000, loss: 16.535932
 >> iter 20000, loss: 15.947851
   Number of active neurons: 1
 >> iter 21000, loss: 11.668174
 >> iter 22000, loss: 8.617508
 >> iter 23000, loss: 7.246560
 >> iter 24000, loss: 6.716076
 >> iter 25000, loss: 6.050475
 >> iter 26000, loss: 5.551078
 >> iter 27000, loss: 5.385386
 >> iter 28000, loss: 5.577395
 >> iter 29000, loss: 5.416579
 >> iter 30000, loss: 5.088624
   Number of active neurons: 2
 >> iter 31000, loss: 5.036605
 >> iter 32000, loss: 4.558416
 >> iter 33000, loss: 4.345119
 >> iter 34000, loss: 4.370814
 >> iter 35000, loss: 4.492707
 >> iter 36000, loss: 4.803994
 >> iter 37000, loss: 4.202977
 >> iter 38000, loss: 4.556764
 >> iter 39000, loss: 4.880756
 >> iter 40000, loss: 4.097677
   Number of active neurons: 2
 >> iter 41000, loss: 3.874357
 >> iter 42000, loss: 4.089373
 >> iter 43000, loss: 3.891641
 >> iter 44000, loss: 3.971129
 >> iter 45000, loss: 3.678141
 >> iter 46000, loss: 4.030665
 >> iter 47000, loss: 4.391637
 >> iter 48000, loss: 4.081060
 >> iter 49000, loss: 3.975135
 >> iter 50000, loss: 4.458505
   Number of active neurons: 2
 >> iter 51000, loss: 4.451345
 >> iter 52000, loss: 4.517950
 >> iter 53000, loss: 4.445251
 >> iter 54000, loss: 4.380220
 >> iter 55000, loss: 4.159501
 >> iter 56000, loss: 4.112905
 >> iter 57000, loss: 3.946681
 >> iter 58000, loss: 3.627818
 >> iter 59000, loss: 3.428216
 >> iter 60000, loss: 3.840040
   Number of active neurons: 2
 >> iter 61000, loss: 3.909162
 >> iter 62000, loss: 4.359344
 >> iter 63000, loss: 3.735548
 >> iter 64000, loss: 3.857512
 >> iter 65000, loss: 3.290405
 >> iter 66000, loss: 3.972598
 >> iter 67000, loss: 3.853076
 >> iter 68000, loss: 3.902032
 >> iter 69000, loss: 3.876255
 >> iter 70000, loss: 3.447678
   Number of active neurons: 2
 >> iter 71000, loss: 3.234033
 >> iter 72000, loss: 3.762483
 >> iter 73000, loss: 3.824497
 >> iter 74000, loss: 3.469824
 >> iter 75000, loss: 3.338576
 >> iter 76000, loss: 3.957353
 >> iter 77000, loss: 3.389281
 >> iter 78000, loss: 3.757806
 >> iter 79000, loss: 3.703223
 >> iter 80000, loss: 3.668214
   Number of active neurons: 2
 >> iter 81000, loss: 3.560125
 >> iter 82000, loss: 3.781955
 >> iter 83000, loss: 3.952458
 >> iter 84000, loss: 3.867319
 >> iter 85000, loss: 3.559817
 >> iter 86000, loss: 3.897106
 >> iter 87000, loss: 3.617186
 >> iter 88000, loss: 3.778249
 >> iter 89000, loss: 3.763052
 >> iter 90000, loss: 3.458237
   Number of active neurons: 2
 >> iter 91000, loss: 3.416012
 >> iter 92000, loss: 3.368135
 >> iter 93000, loss: 3.171485
 >> iter 94000, loss: 3.535670
 >> iter 95000, loss: 3.507566
 >> iter 96000, loss: 3.729504
 >> iter 97000, loss: 3.429447
 >> iter 98000, loss: 3.299397
 >> iter 99000, loss: 3.687917
 >> iter 100000, loss: 3.403843
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 20.524763
 >> iter 2000, loss: 18.054275
 >> iter 3000, loss: 17.068459
 >> iter 4000, loss: 16.779357
 >> iter 5000, loss: 16.602164
 >> iter 6000, loss: 16.598182
 >> iter 7000, loss: 16.539943
 >> iter 8000, loss: 16.570972
 >> iter 9000, loss: 16.532183
 >> iter 10000, loss: 16.581924
   Number of active neurons: 0
 >> iter 11000, loss: 16.532516
 >> iter 12000, loss: 16.591968
 >> iter 13000, loss: 16.533412
 >> iter 14000, loss: 16.598195
 >> iter 15000, loss: 16.533567
 >> iter 16000, loss: 16.603664
 >> iter 17000, loss: 16.535594
 >> iter 18000, loss: 16.598714
 >> iter 19000, loss: 16.535933
 >> iter 20000, loss: 16.602338
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 12.542046
 >> iter 22000, loss: 9.165666
 >> iter 23000, loss: 7.329398
 >> iter 24000, loss: 6.490895
 >> iter 25000, loss: 6.376732
 >> iter 26000, loss: 5.943259
 >> iter 27000, loss: 5.938029
 >> iter 28000, loss: 5.926921
 >> iter 29000, loss: 5.557010
 >> iter 30000, loss: 5.642726
   Number of active neurons: 2
 >> iter 31000, loss: 5.322803
 >> iter 32000, loss: 5.220829
 >> iter 33000, loss: 5.248262
 >> iter 34000, loss: 5.510694
 >> iter 35000, loss: 5.180267
 >> iter 36000, loss: 4.852510
 >> iter 37000, loss: 4.950127
 >> iter 38000, loss: 5.016158
 >> iter 39000, loss: 4.990188
 >> iter 40000, loss: 4.892737
   Number of active neurons: 2
 >> iter 41000, loss: 4.782469
 >> iter 42000, loss: 5.119629
 >> iter 43000, loss: 5.119763
 >> iter 44000, loss: 4.896189
 >> iter 45000, loss: 4.670838
 >> iter 46000, loss: 4.507537
 >> iter 47000, loss: 4.389163
 >> iter 48000, loss: 4.566983
 >> iter 49000, loss: 4.686638
 >> iter 50000, loss: 5.274963
   Number of active neurons: 2
 >> iter 51000, loss: 4.822433
 >> iter 52000, loss: 4.715356
 >> iter 53000, loss: 4.436968
 >> iter 54000, loss: 4.724694
 >> iter 55000, loss: 4.687639
 >> iter 56000, loss: 4.822876
 >> iter 57000, loss: 4.966656
 >> iter 58000, loss: 4.930830
 >> iter 59000, loss: 4.576371
 >> iter 60000, loss: 4.725480
   Number of active neurons: 2
 >> iter 61000, loss: 4.743897
 >> iter 62000, loss: 4.627866
 >> iter 63000, loss: 4.866326
 >> iter 64000, loss: 4.730154
 >> iter 65000, loss: 4.798425
 >> iter 66000, loss: 4.693129
 >> iter 67000, loss: 4.610076
 >> iter 68000, loss: 4.878722
 >> iter 69000, loss: 4.976485
 >> iter 70000, loss: 4.996647
   Number of active neurons: 2
 >> iter 71000, loss: 4.863813
 >> iter 72000, loss: 5.097383
 >> iter 73000, loss: 4.665903
 >> iter 74000, loss: 4.829651
 >> iter 75000, loss: 4.704059
 >> iter 76000, loss: 4.643921
 >> iter 77000, loss: 4.532633
 >> iter 78000, loss: 4.931751
 >> iter 79000, loss: 4.786947
 >> iter 80000, loss: 4.796596
   Number of active neurons: 2
 >> iter 81000, loss: 4.649219
 >> iter 82000, loss: 4.890907
 >> iter 83000, loss: 4.896031
 >> iter 84000, loss: 4.514330
 >> iter 85000, loss: 4.589490
 >> iter 86000, loss: 4.486294
 >> iter 87000, loss: 4.561283
 >> iter 88000, loss: 4.722158
 >> iter 89000, loss: 4.686484
 >> iter 90000, loss: 4.642524
   Number of active neurons: 2
 >> iter 91000, loss: 4.211682
 >> iter 92000, loss: 4.545863
 >> iter 93000, loss: 4.287322
 >> iter 94000, loss: 4.277585
 >> iter 95000, loss: 4.406196
 >> iter 96000, loss: 4.355776
 >> iter 97000, loss: 4.139976
 >> iter 98000, loss: 4.562050
 >> iter 99000, loss: 4.560580
 >> iter 100000, loss: 4.541423
   Number of active neurons: 2
 >> iter 101000, loss: 4.119439
 >> iter 102000, loss: 4.534977
 >> iter 103000, loss: 4.539279
 >> iter 104000, loss: 4.865209
 >> iter 105000, loss: 4.771347
 >> iter 106000, loss: 4.909563
 >> iter 107000, loss: 4.537083
 >> iter 108000, loss: 4.654897
 >> iter 109000, loss: 4.461326
 >> iter 110000, loss: 4.417297
   Number of active neurons: 2
 >> iter 111000, loss: 4.313524
 >> iter 112000, loss: 4.290808
 >> iter 113000, loss: 4.078047
 >> iter 114000, loss: 4.080952
 >> iter 115000, loss: 4.023724
 >> iter 116000, loss: 3.775244
 >> iter 117000, loss: 4.495602
 >> iter 118000, loss: 4.199072
 >> iter 119000, loss: 4.277670
 >> iter 120000, loss: 4.439034
   Number of active neurons: 2
 >> iter 121000, loss: 4.335382
 >> iter 122000, loss: 4.141758
 >> iter 123000, loss: 3.923277
 >> iter 124000, loss: 4.206339
 >> iter 125000, loss: 4.387088
 >> iter 126000, loss: 4.550010
 >> iter 127000, loss: 4.336940
 >> iter 128000, loss: 4.281358
 >> iter 129000, loss: 3.856475
 >> iter 130000, loss: 4.132624
   Number of active neurons: 2
 >> iter 131000, loss: 4.337147
 >> iter 132000, loss: 4.419899
 >> iter 133000, loss: 4.348739
 >> iter 134000, loss: 4.476073
 >> iter 135000, loss: 4.376439
 >> iter 136000, loss: 4.423182
 >> iter 137000, loss: 4.102199
 >> iter 138000, loss: 4.073483
 >> iter 139000, loss: 4.009648
 >> iter 140000, loss: 4.248217
   Number of active neurons: 2
 >> iter 141000, loss: 4.340389
 >> iter 142000, loss: 4.191540
 >> iter 143000, loss: 4.458796
 >> iter 144000, loss: 4.065835
 >> iter 145000, loss: 4.587450
 >> iter 146000, loss: 4.543185
 >> iter 147000, loss: 4.325081
 >> iter 148000, loss: 4.220138
 >> iter 149000, loss: 3.879879
 >> iter 150000, loss: 4.049665
   Number of active neurons: 2
 >> iter 151000, loss: 4.013286
 >> iter 152000, loss: 4.198276
 >> iter 153000, loss: 3.705474
 >> iter 154000, loss: 4.092428
 >> iter 155000, loss: 4.048163
 >> iter 156000, loss: 4.025711
 >> iter 157000, loss: 3.888309
 >> iter 158000, loss: 3.748092
 >> iter 159000, loss: 4.234962
 >> iter 160000, loss: 4.125462
   Number of active neurons: 2
 >> iter 161000, loss: 4.144756
 >> iter 162000, loss: 4.005805
 >> iter 163000, loss: 4.133774
 >> iter 164000, loss: 4.124903
 >> iter 165000, loss: 4.110556
 >> iter 166000, loss: 3.840900
 >> iter 167000, loss: 3.971970
 >> iter 168000, loss: 3.907085
 >> iter 169000, loss: 3.839619
 >> iter 170000, loss: 4.056439
   Number of active neurons: 2
 >> iter 171000, loss: 3.744723
 >> iter 172000, loss: 3.706762
 >> iter 173000, loss: 3.522589
 >> iter 174000, loss: 4.262805
 >> iter 175000, loss: 3.708811
 >> iter 176000, loss: 4.064896
 >> iter 177000, loss: 3.919026
 >> iter 178000, loss: 3.978961
 >> iter 179000, loss: 3.475843
 >> iter 180000, loss: 3.953126
   Number of active neurons: 2
 >> iter 181000, loss: 3.947422
 >> iter 182000, loss: 3.879546
 >> iter 183000, loss: 3.812862
 >> iter 184000, loss: 3.962827
 >> iter 185000, loss: 3.991187
 >> iter 186000, loss: 4.047965
 >> iter 187000, loss: 4.042413
 >> iter 188000, loss: 4.208270
 >> iter 189000, loss: 3.856579
 >> iter 190000, loss: 4.061126
   Number of active neurons: 2
 >> iter 191000, loss: 3.911191
 >> iter 192000, loss: 4.410589
 >> iter 193000, loss: 4.328498
 >> iter 194000, loss: 3.609054
 >> iter 195000, loss: 3.176769
 >> iter 196000, loss: 3.334338
 >> iter 197000, loss: 3.496347
 >> iter 198000, loss: 3.748431
 >> iter 199000, loss: 3.901519
 >> iter 200000, loss: 4.370373
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.604761
 >> iter 2000, loss: 12.209345
 >> iter 3000, loss: 8.964344
 >> iter 4000, loss: 7.090932
 >> iter 5000, loss: 6.522538
 >> iter 6000, loss: 6.664866
 >> iter 7000, loss: 6.053498
 >> iter 8000, loss: 5.537253
 >> iter 9000, loss: 5.256322
 >> iter 10000, loss: 4.879187
   Number of active neurons: 2
 >> iter 11000, loss: 4.683990
 >> iter 12000, loss: 4.691564
 >> iter 13000, loss: 5.185801
 >> iter 14000, loss: 5.180668
 >> iter 15000, loss: 4.933692
 >> iter 16000, loss: 4.843311
 >> iter 17000, loss: 4.612802
 >> iter 18000, loss: 4.880707
 >> iter 19000, loss: 4.834276
 >> iter 20000, loss: 4.803992
   Number of active neurons: 2
 >> iter 21000, loss: 4.446562
 >> iter 22000, loss: 4.440443
 >> iter 23000, loss: 4.454043
 >> iter 24000, loss: 4.663531
 >> iter 25000, loss: 4.556614
 >> iter 26000, loss: 4.429868
 >> iter 27000, loss: 4.198239
 >> iter 28000, loss: 4.030677
 >> iter 29000, loss: 4.338099
 >> iter 30000, loss: 3.928233
   Number of active neurons: 2
 >> iter 31000, loss: 4.155387
 >> iter 32000, loss: 4.369561
 >> iter 33000, loss: 4.073358
 >> iter 34000, loss: 3.958587
 >> iter 35000, loss: 4.006375
 >> iter 36000, loss: 3.826380
 >> iter 37000, loss: 3.728948
 >> iter 38000, loss: 3.701273
 >> iter 39000, loss: 3.660274
 >> iter 40000, loss: 3.928479
   Number of active neurons: 2
 >> iter 41000, loss: 4.167702
 >> iter 42000, loss: 3.714652
 >> iter 43000, loss: 3.357493
 >> iter 44000, loss: 3.785943
 >> iter 45000, loss: 3.812698
 >> iter 46000, loss: 3.565559
 >> iter 47000, loss: 3.875055
 >> iter 48000, loss: 4.155204
 >> iter 49000, loss: 3.809849
 >> iter 50000, loss: 4.047335
   Number of active neurons: 2
 >> iter 51000, loss: 3.752144
 >> iter 52000, loss: 3.950556
 >> iter 53000, loss: 3.744895
 >> iter 54000, loss: 3.717192
 >> iter 55000, loss: 3.682785
 >> iter 56000, loss: 3.844220
 >> iter 57000, loss: 3.565831
 >> iter 58000, loss: 3.500008
 >> iter 59000, loss: 3.611021
 >> iter 60000, loss: 3.257522
   Number of active neurons: 2
 >> iter 61000, loss: 3.568248
 >> iter 62000, loss: 3.519900
 >> iter 63000, loss: 3.411042
 >> iter 64000, loss: 3.656301
 >> iter 65000, loss: 3.474711
 >> iter 66000, loss: 3.643750
 >> iter 67000, loss: 3.162648
 >> iter 68000, loss: 3.617682
 >> iter 69000, loss: 3.671910
 >> iter 70000, loss: 3.205915
   Number of active neurons: 2
 >> iter 71000, loss: 3.287387
 >> iter 72000, loss: 3.321179
 >> iter 73000, loss: 3.311480
 >> iter 74000, loss: 3.308796
 >> iter 75000, loss: 2.908199
 >> iter 76000, loss: 3.310478
 >> iter 77000, loss: 3.527439
 >> iter 78000, loss: 3.969721
 >> iter 79000, loss: 3.344095
 >> iter 80000, loss: 3.438020
   Number of active neurons: 2
 >> iter 81000, loss: 3.495554
 >> iter 82000, loss: 3.071551
 >> iter 83000, loss: 2.879858
 >> iter 84000, loss: 3.308570
 >> iter 85000, loss: 3.571272
 >> iter 86000, loss: 3.685496
 >> iter 87000, loss: 3.329069
 >> iter 88000, loss: 3.281546
 >> iter 89000, loss: 3.159514
 >> iter 90000, loss: 3.521873
   Number of active neurons: 2
 >> iter 91000, loss: 3.475926
 >> iter 92000, loss: 3.181440
 >> iter 93000, loss: 3.320318
 >> iter 94000, loss: 3.687309
 >> iter 95000, loss: 3.583057
 >> iter 96000, loss: 3.109482
 >> iter 97000, loss: 3.219180
 >> iter 98000, loss: 3.526174
 >> iter 99000, loss: 3.608343
 >> iter 100000, loss: 3.485632
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524757
 >> iter 2000, loss: 18.054275
 >> iter 3000, loss: 17.068459
 >> iter 4000, loss: 16.779361
 >> iter 5000, loss: 16.602167
 >> iter 6000, loss: 16.598195
 >> iter 7000, loss: 16.539948
 >> iter 8000, loss: 16.080539
 >> iter 9000, loss: 12.073431
 >> iter 10000, loss: 8.977350
   Number of active neurons: 2
 >> iter 11000, loss: 7.142502
 >> iter 12000, loss: 6.478078
 >> iter 13000, loss: 6.269312
 >> iter 14000, loss: 5.680608
 >> iter 15000, loss: 5.274838
 >> iter 16000, loss: 5.124289
 >> iter 17000, loss: 5.078175
 >> iter 18000, loss: 4.990772
 >> iter 19000, loss: 4.821326
 >> iter 20000, loss: 4.838161
   Number of active neurons: 2
 >> iter 21000, loss: 4.768528
 >> iter 22000, loss: 4.624092
 >> iter 23000, loss: 4.679760
 >> iter 24000, loss: 4.461104
 >> iter 25000, loss: 5.110839
 >> iter 26000, loss: 4.935658
 >> iter 27000, loss: 4.930551
 >> iter 28000, loss: 4.722879
 >> iter 29000, loss: 4.495714
 >> iter 30000, loss: 4.375973
   Number of active neurons: 2
 >> iter 31000, loss: 4.237523
 >> iter 32000, loss: 4.519493
 >> iter 33000, loss: 4.699337
 >> iter 34000, loss: 4.500421
 >> iter 35000, loss: 4.197022
 >> iter 36000, loss: 4.302407
 >> iter 37000, loss: 4.730313
 >> iter 38000, loss: 4.872372
 >> iter 39000, loss: 4.563209
 >> iter 40000, loss: 4.043593
   Number of active neurons: 2
 >> iter 41000, loss: 4.175860
 >> iter 42000, loss: 4.462282
 >> iter 43000, loss: 4.371251
 >> iter 44000, loss: 4.228006
 >> iter 45000, loss: 3.964712
 >> iter 46000, loss: 4.038191
 >> iter 47000, loss: 4.015269
 >> iter 48000, loss: 4.208522
 >> iter 49000, loss: 3.795657
 >> iter 50000, loss: 3.583255
   Number of active neurons: 2
 >> iter 51000, loss: 3.705213
 >> iter 52000, loss: 4.152467
 >> iter 53000, loss: 4.149124
 >> iter 54000, loss: 3.650628
 >> iter 55000, loss: 3.857242
 >> iter 56000, loss: 3.907348
 >> iter 57000, loss: 4.039567
 >> iter 58000, loss: 3.875034
 >> iter 59000, loss: 3.620515
 >> iter 60000, loss: 3.960834
   Number of active neurons: 2
 >> iter 61000, loss: 3.749439
 >> iter 62000, loss: 3.907963
 >> iter 63000, loss: 4.156208
 >> iter 64000, loss: 3.960326
 >> iter 65000, loss: 4.047769
 >> iter 66000, loss: 3.818857
 >> iter 67000, loss: 3.783851
 >> iter 68000, loss: 3.984183
 >> iter 69000, loss: 4.067273
 >> iter 70000, loss: 3.566109
   Number of active neurons: 2
 >> iter 71000, loss: 3.821652
 >> iter 72000, loss: 4.296691
 >> iter 73000, loss: 3.702511
 >> iter 74000, loss: 3.582363
 >> iter 75000, loss: 3.800434
 >> iter 76000, loss: 3.935772
 >> iter 77000, loss: 3.791711
 >> iter 78000, loss: 4.081017
 >> iter 79000, loss: 3.577932
 >> iter 80000, loss: 3.948429
   Number of active neurons: 2
 >> iter 81000, loss: 3.602887
 >> iter 82000, loss: 3.284761
 >> iter 83000, loss: 3.070550
 >> iter 84000, loss: 3.363002
 >> iter 85000, loss: 3.715405
 >> iter 86000, loss: 3.487266
 >> iter 87000, loss: 3.606187
 >> iter 88000, loss: 3.645838
 >> iter 89000, loss: 3.074205
 >> iter 90000, loss: 3.211112
   Number of active neurons: 2
 >> iter 91000, loss: 3.515659
 >> iter 92000, loss: 3.583620
 >> iter 93000, loss: 3.422326
 >> iter 94000, loss: 3.746150
 >> iter 95000, loss: 3.641095
 >> iter 96000, loss: 3.912423
 >> iter 97000, loss: 3.281444
 >> iter 98000, loss: 3.274276
 >> iter 99000, loss: 3.248137
 >> iter 100000, loss: 3.170888
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524759
 >> iter 2000, loss: 18.054270
 >> iter 3000, loss: 17.068457
 >> iter 4000, loss: 16.779359
 >> iter 5000, loss: 16.602165
 >> iter 6000, loss: 15.850467
 >> iter 7000, loss: 11.607611
 >> iter 8000, loss: 8.671310
 >> iter 9000, loss: 7.136085
 >> iter 10000, loss: 6.904891
   Number of active neurons: 2
 >> iter 11000, loss: 6.143220
 >> iter 12000, loss: 5.545729
 >> iter 13000, loss: 5.511918
 >> iter 14000, loss: 4.965500
 >> iter 15000, loss: 5.289815
 >> iter 16000, loss: 4.989298
 >> iter 17000, loss: 5.137209
 >> iter 18000, loss: 5.080659
 >> iter 19000, loss: 5.197449
 >> iter 20000, loss: 4.889345
   Number of active neurons: 2
 >> iter 21000, loss: 4.831309
 >> iter 22000, loss: 5.289733
 >> iter 23000, loss: 5.075420
 >> iter 24000, loss: 4.968460
 >> iter 25000, loss: 4.864679
 >> iter 26000, loss: 5.184268
 >> iter 27000, loss: 5.128167
 >> iter 28000, loss: 5.205737
 >> iter 29000, loss: 4.667589
 >> iter 30000, loss: 4.952836
   Number of active neurons: 2
 >> iter 31000, loss: 4.947187
 >> iter 32000, loss: 4.768400
 >> iter 33000, loss: 4.789262
 >> iter 34000, loss: 5.368333
 >> iter 35000, loss: 5.102954
 >> iter 36000, loss: 4.840252
 >> iter 37000, loss: 4.756270
 >> iter 38000, loss: 4.558615
 >> iter 39000, loss: 4.365178
 >> iter 40000, loss: 4.392325
   Number of active neurons: 2
 >> iter 41000, loss: 4.625465
 >> iter 42000, loss: 4.725832
 >> iter 43000, loss: 4.409138
 >> iter 44000, loss: 4.621573
 >> iter 45000, loss: 4.582190
 >> iter 46000, loss: 4.499092
 >> iter 47000, loss: 4.379006
 >> iter 48000, loss: 4.453337
 >> iter 49000, loss: 4.895641
 >> iter 50000, loss: 5.196043
   Number of active neurons: 2
 >> iter 51000, loss: 4.998646
 >> iter 52000, loss: 4.824660
 >> iter 53000, loss: 4.105456
 >> iter 54000, loss: 4.495733
 >> iter 55000, loss: 4.467095
 >> iter 56000, loss: 4.582769
 >> iter 57000, loss: 4.407606
 >> iter 58000, loss: 4.240323
 >> iter 59000, loss: 4.297407
 >> iter 60000, loss: 4.328739
   Number of active neurons: 2
 >> iter 61000, loss: 4.342288
 >> iter 62000, loss: 4.457951
 >> iter 63000, loss: 4.656430
 >> iter 64000, loss: 4.454064
 >> iter 65000, loss: 4.476477
 >> iter 66000, loss: 4.574087
 >> iter 67000, loss: 4.240476
 >> iter 68000, loss: 4.441859
 >> iter 69000, loss: 4.250559
 >> iter 70000, loss: 4.711632
   Number of active neurons: 2
 >> iter 71000, loss: 4.246008
 >> iter 72000, loss: 4.165017
 >> iter 73000, loss: 4.431746
 >> iter 74000, loss: 4.214099
 >> iter 75000, loss: 4.154446
 >> iter 76000, loss: 3.961231
 >> iter 77000, loss: 4.081354
 >> iter 78000, loss: 4.355719
 >> iter 79000, loss: 4.373898
 >> iter 80000, loss: 4.114040
   Number of active neurons: 2
 >> iter 81000, loss: 4.048420
 >> iter 82000, loss: 4.439635
 >> iter 83000, loss: 4.165598
 >> iter 84000, loss: 3.950405
 >> iter 85000, loss: 3.725283
 >> iter 86000, loss: 4.045865
 >> iter 87000, loss: 4.366866
 >> iter 88000, loss: 4.266304
 >> iter 89000, loss: 4.015614
 >> iter 90000, loss: 4.279234
   Number of active neurons: 2
 >> iter 91000, loss: 3.868214
 >> iter 92000, loss: 4.557462
 >> iter 93000, loss: 4.302074
 >> iter 94000, loss: 4.366503
 >> iter 95000, loss: 4.215120
 >> iter 96000, loss: 3.930911
 >> iter 97000, loss: 4.040519
 >> iter 98000, loss: 3.983936
 >> iter 99000, loss: 4.202299
 >> iter 100000, loss: 4.192300
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.375549
 >> iter 2000, loss: 14.083921
 >> iter 3000, loss: 10.274134
 >> iter 4000, loss: 8.286391
 >> iter 5000, loss: 6.974672
 >> iter 6000, loss: 5.979436
 >> iter 7000, loss: 6.036684
 >> iter 8000, loss: 6.224026
 >> iter 9000, loss: 5.508217
 >> iter 10000, loss: 5.434571
   Number of active neurons: 2
 >> iter 11000, loss: 5.059627
 >> iter 12000, loss: 5.385713
 >> iter 13000, loss: 5.174262
 >> iter 14000, loss: 4.961363
 >> iter 15000, loss: 5.092458
 >> iter 16000, loss: 5.048323
 >> iter 17000, loss: 5.181184
 >> iter 18000, loss: 5.309966
 >> iter 19000, loss: 4.943856
 >> iter 20000, loss: 4.474267
   Number of active neurons: 2
 >> iter 21000, loss: 4.735286
 >> iter 22000, loss: 4.722383
 >> iter 23000, loss: 4.601717
 >> iter 24000, loss: 4.674772
 >> iter 25000, loss: 4.514652
 >> iter 26000, loss: 4.574668
 >> iter 27000, loss: 4.389045
 >> iter 28000, loss: 4.590793
 >> iter 29000, loss: 4.703757
 >> iter 30000, loss: 4.774595
   Number of active neurons: 2
 >> iter 31000, loss: 4.427423
 >> iter 32000, loss: 4.438748
 >> iter 33000, loss: 4.478812
 >> iter 34000, loss: 4.434929
 >> iter 35000, loss: 4.351246
 >> iter 36000, loss: 4.730990
 >> iter 37000, loss: 4.436765
 >> iter 38000, loss: 4.368905
 >> iter 39000, loss: 4.202071
 >> iter 40000, loss: 4.674218
   Number of active neurons: 2
 >> iter 41000, loss: 4.729663
 >> iter 42000, loss: 4.721215
 >> iter 43000, loss: 4.569250
 >> iter 44000, loss: 4.474182
 >> iter 45000, loss: 4.566004
 >> iter 46000, loss: 4.720350
 >> iter 47000, loss: 4.476232
 >> iter 48000, loss: 4.457053
 >> iter 49000, loss: 4.525540
 >> iter 50000, loss: 4.406432
   Number of active neurons: 2
 >> iter 51000, loss: 4.468207
 >> iter 52000, loss: 4.656937
 >> iter 53000, loss: 4.285203
 >> iter 54000, loss: 4.688472
 >> iter 55000, loss: 4.548184
 >> iter 56000, loss: 4.436526
 >> iter 57000, loss: 4.722062
 >> iter 58000, loss: 4.467736
 >> iter 59000, loss: 4.463170
 >> iter 60000, loss: 4.306677
   Number of active neurons: 2
 >> iter 61000, loss: 4.153654
 >> iter 62000, loss: 4.140413
 >> iter 63000, loss: 4.300565
 >> iter 64000, loss: 4.417503
 >> iter 65000, loss: 4.120183
 >> iter 66000, loss: 3.988441
 >> iter 67000, loss: 4.019654
 >> iter 68000, loss: 4.093082
 >> iter 69000, loss: 4.233773
 >> iter 70000, loss: 4.861540
   Number of active neurons: 2
 >> iter 71000, loss: 4.454695
 >> iter 72000, loss: 4.130189
 >> iter 73000, loss: 4.404358
 >> iter 74000, loss: 4.414877
 >> iter 75000, loss: 4.002208
 >> iter 76000, loss: 4.302107
 >> iter 77000, loss: 4.329043
 >> iter 78000, loss: 4.099751
 >> iter 79000, loss: 4.211971
 >> iter 80000, loss: 4.124475
   Number of active neurons: 2
 >> iter 81000, loss: 3.759062
 >> iter 82000, loss: 4.147189
 >> iter 83000, loss: 4.391827
 >> iter 84000, loss: 4.140368
 >> iter 85000, loss: 4.023290
 >> iter 86000, loss: 3.784972
 >> iter 87000, loss: 4.003205
 >> iter 88000, loss: 3.999822
 >> iter 89000, loss: 4.016463
 >> iter 90000, loss: 3.993420
   Number of active neurons: 2
 >> iter 91000, loss: 4.389311
 >> iter 92000, loss: 4.280744
 >> iter 93000, loss: 3.688963
 >> iter 94000, loss: 3.951027
 >> iter 95000, loss: 3.728828
 >> iter 96000, loss: 4.017574
 >> iter 97000, loss: 4.149074
 >> iter 98000, loss: 4.088471
 >> iter 99000, loss: 3.868606
 >> iter 100000, loss: 4.238167
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 20.524758
 >> iter 2000, loss: 18.054279
 >> iter 3000, loss: 17.068461
 >> iter 4000, loss: 16.779361
 >> iter 5000, loss: 16.602167
 >> iter 6000, loss: 16.598184
 >> iter 7000, loss: 16.539943
 >> iter 8000, loss: 16.570972
 >> iter 9000, loss: 16.532183
 >> iter 10000, loss: 16.581925
   Number of active neurons: 0
 >> iter 11000, loss: 16.532517
 >> iter 12000, loss: 16.591971
 >> iter 13000, loss: 16.533413
 >> iter 14000, loss: 16.598202
 >> iter 15000, loss: 16.533570
 >> iter 16000, loss: 16.603668
 >> iter 17000, loss: 16.535596
 >> iter 18000, loss: 16.598714
 >> iter 19000, loss: 16.535934
 >> iter 20000, loss: 16.602348
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 12.146856
 >> iter 22000, loss: 8.988609
 >> iter 23000, loss: 7.470171
 >> iter 24000, loss: 6.817417
 >> iter 25000, loss: 6.318580
 >> iter 26000, loss: 6.220446
 >> iter 27000, loss: 5.857430
 >> iter 28000, loss: 5.722594
 >> iter 29000, loss: 5.411770
 >> iter 30000, loss: 5.650347
   Number of active neurons: 2
 >> iter 31000, loss: 5.666599
 >> iter 32000, loss: 4.958657
 >> iter 33000, loss: 5.265488
 >> iter 34000, loss: 5.148691
 >> iter 35000, loss: 5.246567
 >> iter 36000, loss: 5.160595
 >> iter 37000, loss: 5.197688
 >> iter 38000, loss: 5.119685
 >> iter 39000, loss: 5.237035
 >> iter 40000, loss: 5.539333
   Number of active neurons: 2
 >> iter 41000, loss: 5.143375
 >> iter 42000, loss: 5.156529
 >> iter 43000, loss: 4.892536
 >> iter 44000, loss: 5.023711
 >> iter 45000, loss: 5.001369
 >> iter 46000, loss: 4.867938
 >> iter 47000, loss: 4.688606
 >> iter 48000, loss: 4.825523
 >> iter 49000, loss: 4.761423
 >> iter 50000, loss: 4.914461
   Number of active neurons: 2
 >> iter 51000, loss: 4.988290
 >> iter 52000, loss: 5.095975
 >> iter 53000, loss: 5.042629
 >> iter 54000, loss: 5.025568
 >> iter 55000, loss: 4.906320
 >> iter 56000, loss: 5.025506
 >> iter 57000, loss: 5.053205
 >> iter 58000, loss: 4.972190
 >> iter 59000, loss: 5.375849
 >> iter 60000, loss: 5.158518
   Number of active neurons: 2
 >> iter 61000, loss: 4.750113
 >> iter 62000, loss: 4.998693
 >> iter 63000, loss: 4.845485
 >> iter 64000, loss: 4.663289
 >> iter 65000, loss: 4.616039
 >> iter 66000, loss: 4.838686
 >> iter 67000, loss: 4.626785
 >> iter 68000, loss: 4.611626
 >> iter 69000, loss: 4.782006
 >> iter 70000, loss: 4.796055
   Number of active neurons: 2
 >> iter 71000, loss: 4.980316
 >> iter 72000, loss: 4.476227
 >> iter 73000, loss: 4.617958
 >> iter 74000, loss: 4.743299
 >> iter 75000, loss: 4.496411
 >> iter 76000, loss: 4.667576
 >> iter 77000, loss: 4.408840
 >> iter 78000, loss: 4.414264
 >> iter 79000, loss: 4.453491
 >> iter 80000, loss: 4.638597
   Number of active neurons: 2
 >> iter 81000, loss: 4.568570
 >> iter 82000, loss: 4.805322
 >> iter 83000, loss: 4.493906
 >> iter 84000, loss: 4.618469
 >> iter 85000, loss: 4.267982
 >> iter 86000, loss: 4.777863
 >> iter 87000, loss: 4.475218
 >> iter 88000, loss: 4.888676
 >> iter 89000, loss: 4.689979
 >> iter 90000, loss: 4.903913
   Number of active neurons: 2
 >> iter 91000, loss: 4.169072
 >> iter 92000, loss: 4.070360
 >> iter 93000, loss: 4.336917
 >> iter 94000, loss: 4.766794
 >> iter 95000, loss: 4.447965
 >> iter 96000, loss: 4.326874
 >> iter 97000, loss: 4.738374
 >> iter 98000, loss: 4.670676
 >> iter 99000, loss: 4.418311
 >> iter 100000, loss: 4.238324
   Number of active neurons: 2
 >> iter 101000, loss: 4.269563
 >> iter 102000, loss: 4.322741
 >> iter 103000, loss: 4.333031
 >> iter 104000, loss: 4.455380
 >> iter 105000, loss: 3.997101
 >> iter 106000, loss: 4.014384
 >> iter 107000, loss: 4.025497
 >> iter 108000, loss: 4.364461
 >> iter 109000, loss: 4.122987
 >> iter 110000, loss: 4.039191
   Number of active neurons: 2
 >> iter 111000, loss: 3.831819
 >> iter 112000, loss: 4.362293
 >> iter 113000, loss: 4.332415
 >> iter 114000, loss: 4.174644
 >> iter 115000, loss: 4.094735
 >> iter 116000, loss: 4.020975
 >> iter 117000, loss: 4.065744
 >> iter 118000, loss: 4.137743
 >> iter 119000, loss: 3.796414
 >> iter 120000, loss: 3.680870
   Number of active neurons: 2
 >> iter 121000, loss: 3.731343
 >> iter 122000, loss: 4.411912
 >> iter 123000, loss: 3.946456
 >> iter 124000, loss: 4.206176
 >> iter 125000, loss: 3.799330
 >> iter 126000, loss: 4.087069
 >> iter 127000, loss: 4.122833
 >> iter 128000, loss: 4.338040
 >> iter 129000, loss: 4.156527
 >> iter 130000, loss: 3.977624
   Number of active neurons: 2
 >> iter 131000, loss: 3.929522
 >> iter 132000, loss: 4.268338
 >> iter 133000, loss: 4.238207
 >> iter 134000, loss: 4.458593
 >> iter 135000, loss: 4.359310
 >> iter 136000, loss: 4.334803
 >> iter 137000, loss: 4.142903
 >> iter 138000, loss: 4.200806
 >> iter 139000, loss: 4.342250
 >> iter 140000, loss: 4.533651
   Number of active neurons: 2
 >> iter 141000, loss: 4.329966
 >> iter 142000, loss: 4.298024
 >> iter 143000, loss: 4.527562
 >> iter 144000, loss: 4.650612
 >> iter 145000, loss: 4.323146
 >> iter 146000, loss: 4.432165
 >> iter 147000, loss: 3.930777
 >> iter 148000, loss: 3.953392
 >> iter 149000, loss: 3.668252
 >> iter 150000, loss: 3.634524
   Number of active neurons: 2
 >> iter 151000, loss: 4.042419
 >> iter 152000, loss: 4.116008
 >> iter 153000, loss: 3.983132
 >> iter 154000, loss: 4.021084
 >> iter 155000, loss: 4.246808
 >> iter 156000, loss: 3.930650
 >> iter 157000, loss: 3.818693
 >> iter 158000, loss: 4.018955
 >> iter 159000, loss: 3.622811
 >> iter 160000, loss: 3.687564
   Number of active neurons: 2
 >> iter 161000, loss: 3.851245
 >> iter 162000, loss: 3.995041
 >> iter 163000, loss: 3.626925
 >> iter 164000, loss: 3.860898
 >> iter 165000, loss: 3.908779
 >> iter 166000, loss: 4.191230
 >> iter 167000, loss: 3.929551
 >> iter 168000, loss: 4.106537
 >> iter 169000, loss: 4.165888
 >> iter 170000, loss: 4.453796
   Number of active neurons: 2
 >> iter 171000, loss: 3.999581
 >> iter 172000, loss: 4.230748
 >> iter 173000, loss: 3.934816
 >> iter 174000, loss: 4.155249
 >> iter 175000, loss: 4.009408
 >> iter 176000, loss: 4.010941
 >> iter 177000, loss: 3.341333
 >> iter 178000, loss: 3.443743
 >> iter 179000, loss: 3.628405
 >> iter 180000, loss: 3.760522
   Number of active neurons: 2
 >> iter 181000, loss: 3.895661
 >> iter 182000, loss: 3.881001
 >> iter 183000, loss: 3.656773
 >> iter 184000, loss: 3.868989
 >> iter 185000, loss: 3.968475
 >> iter 186000, loss: 4.134892
 >> iter 187000, loss: 3.992461
 >> iter 188000, loss: 4.260204
 >> iter 189000, loss: 4.038469
 >> iter 190000, loss: 4.374013
   Number of active neurons: 2
 >> iter 191000, loss: 4.114325
 >> iter 192000, loss: 4.087667
 >> iter 193000, loss: 3.723352
 >> iter 194000, loss: 3.995057
 >> iter 195000, loss: 3.818457
 >> iter 196000, loss: 3.831896
 >> iter 197000, loss: 3.655211
 >> iter 198000, loss: 3.988234
 >> iter 199000, loss: 4.064560
 >> iter 200000, loss: 3.652122
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.946315
 >> iter 2000, loss: 12.322449
 >> iter 3000, loss: 8.689233
 >> iter 4000, loss: 7.170562
 >> iter 5000, loss: 6.464749
 >> iter 6000, loss: 6.282939
 >> iter 7000, loss: 6.096519
 >> iter 8000, loss: 5.663231
 >> iter 9000, loss: 5.740600
 >> iter 10000, loss: 5.766428
   Number of active neurons: 2
 >> iter 11000, loss: 5.823333
 >> iter 12000, loss: 5.564895
 >> iter 13000, loss: 5.185377
 >> iter 14000, loss: 4.788466
 >> iter 15000, loss: 4.907184
 >> iter 16000, loss: 5.030577
 >> iter 17000, loss: 5.035859
 >> iter 18000, loss: 4.899852
 >> iter 19000, loss: 5.028279
 >> iter 20000, loss: 5.492245
   Number of active neurons: 2
 >> iter 21000, loss: 5.158998
 >> iter 22000, loss: 4.681446
 >> iter 23000, loss: 4.920341
 >> iter 24000, loss: 4.999284
 >> iter 25000, loss: 4.696358
 >> iter 26000, loss: 5.039204
 >> iter 27000, loss: 5.154071
 >> iter 28000, loss: 4.829292
 >> iter 29000, loss: 4.843886
 >> iter 30000, loss: 4.963947
   Number of active neurons: 2
 >> iter 31000, loss: 4.923450
 >> iter 32000, loss: 4.906218
 >> iter 33000, loss: 5.071500
 >> iter 34000, loss: 4.807276
 >> iter 35000, loss: 4.887230
 >> iter 36000, loss: 4.937344
 >> iter 37000, loss: 4.662311
 >> iter 38000, loss: 4.724302
 >> iter 39000, loss: 4.934567
 >> iter 40000, loss: 4.738707
   Number of active neurons: 2
 >> iter 41000, loss: 4.450392
 >> iter 42000, loss: 4.676073
 >> iter 43000, loss: 4.727297
 >> iter 44000, loss: 4.914992
 >> iter 45000, loss: 4.520810
 >> iter 46000, loss: 4.609107
 >> iter 47000, loss: 4.644725
 >> iter 48000, loss: 5.070053
 >> iter 49000, loss: 4.946360
 >> iter 50000, loss: 4.961186
   Number of active neurons: 2
 >> iter 51000, loss: 4.879999
 >> iter 52000, loss: 4.664812
 >> iter 53000, loss: 4.717894
 >> iter 54000, loss: 4.639987
 >> iter 55000, loss: 4.143826
 >> iter 56000, loss: 4.374717
 >> iter 57000, loss: 4.627282
 >> iter 58000, loss: 4.032894
 >> iter 59000, loss: 3.928061
 >> iter 60000, loss: 3.858576
   Number of active neurons: 2
 >> iter 61000, loss: 4.151592
 >> iter 62000, loss: 4.512753
 >> iter 63000, loss: 4.504600
 >> iter 64000, loss: 4.771884
 >> iter 65000, loss: 4.109347
 >> iter 66000, loss: 4.797721
 >> iter 67000, loss: 4.315063
 >> iter 68000, loss: 4.543518
 >> iter 69000, loss: 4.620474
 >> iter 70000, loss: 4.461503
   Number of active neurons: 2
 >> iter 71000, loss: 4.563688
 >> iter 72000, loss: 4.146560
 >> iter 73000, loss: 4.254999
 >> iter 74000, loss: 4.307985
 >> iter 75000, loss: 4.010123
 >> iter 76000, loss: 4.110705
 >> iter 77000, loss: 4.373192
 >> iter 78000, loss: 4.349946
 >> iter 79000, loss: 4.305484
 >> iter 80000, loss: 4.859182
   Number of active neurons: 2
 >> iter 81000, loss: 4.224383
 >> iter 82000, loss: 4.384103
 >> iter 83000, loss: 4.401745
 >> iter 84000, loss: 4.019405
 >> iter 85000, loss: 4.507081
 >> iter 86000, loss: 4.346022
 >> iter 87000, loss: 4.232682
 >> iter 88000, loss: 4.461014
 >> iter 89000, loss: 4.007161
 >> iter 90000, loss: 4.144207
   Number of active neurons: 2
 >> iter 91000, loss: 4.259218
 >> iter 92000, loss: 4.202035
 >> iter 93000, loss: 3.939591
 >> iter 94000, loss: 4.449370
 >> iter 95000, loss: 3.884117
 >> iter 96000, loss: 4.465732
 >> iter 97000, loss: 4.690922
 >> iter 98000, loss: 4.386749
 >> iter 99000, loss: 4.271425
 >> iter 100000, loss: 4.181042
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 20.524759
 >> iter 2000, loss: 18.054273
 >> iter 3000, loss: 17.068459
 >> iter 4000, loss: 16.779361
 >> iter 5000, loss: 16.602167
 >> iter 6000, loss: 16.598182
 >> iter 7000, loss: 16.539942
 >> iter 8000, loss: 16.570968
 >> iter 9000, loss: 16.532180
 >> iter 10000, loss: 16.581927
   Number of active neurons: 0
 >> iter 11000, loss: 16.532517
 >> iter 12000, loss: 16.591980
 >> iter 13000, loss: 16.533417
 >> iter 14000, loss: 16.598200
 >> iter 15000, loss: 16.533569
 >> iter 16000, loss: 16.603665
 >> iter 17000, loss: 16.535594
 >> iter 18000, loss: 16.598710
 >> iter 19000, loss: 16.535932
 >> iter 20000, loss: 16.602346
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 12.521785
 >> iter 22000, loss: 9.098535
 >> iter 23000, loss: 7.596371
 >> iter 24000, loss: 6.803572
 >> iter 25000, loss: 6.311757
 >> iter 26000, loss: 6.109263
 >> iter 27000, loss: 5.523749
 >> iter 28000, loss: 5.765196
 >> iter 29000, loss: 5.613266
 >> iter 30000, loss: 5.398689
   Number of active neurons: 2
 >> iter 31000, loss: 5.440863
 >> iter 32000, loss: 5.267481
 >> iter 33000, loss: 4.853316
 >> iter 34000, loss: 5.077652
 >> iter 35000, loss: 4.955036
 >> iter 36000, loss: 4.826119
 >> iter 37000, loss: 4.989811
 >> iter 38000, loss: 5.424374
 >> iter 39000, loss: 5.524079
 >> iter 40000, loss: 5.197911
   Number of active neurons: 2
 >> iter 41000, loss: 5.133420
 >> iter 42000, loss: 4.922883
 >> iter 43000, loss: 4.693396
 >> iter 44000, loss: 4.984209
 >> iter 45000, loss: 4.789571
 >> iter 46000, loss: 4.285812
 >> iter 47000, loss: 4.364798
 >> iter 48000, loss: 4.557854
 >> iter 49000, loss: 4.599839
 >> iter 50000, loss: 4.778448
   Number of active neurons: 2
 >> iter 51000, loss: 4.601220
 >> iter 52000, loss: 4.736998
 >> iter 53000, loss: 4.586802
 >> iter 54000, loss: 4.704800
 >> iter 55000, loss: 4.528615
 >> iter 56000, loss: 4.427506
 >> iter 57000, loss: 4.714586
 >> iter 58000, loss: 4.724566
 >> iter 59000, loss: 4.706382
 >> iter 60000, loss: 4.855315
   Number of active neurons: 2
 >> iter 61000, loss: 4.635689
 >> iter 62000, loss: 4.661941
 >> iter 63000, loss: 4.290367
 >> iter 64000, loss: 4.583036
 >> iter 65000, loss: 4.373823
 >> iter 66000, loss: 4.693612
 >> iter 67000, loss: 4.794569
 >> iter 68000, loss: 4.788892
 >> iter 69000, loss: 4.440114
 >> iter 70000, loss: 4.926904
   Number of active neurons: 2
 >> iter 71000, loss: 4.849732
 >> iter 72000, loss: 4.629823
 >> iter 73000, loss: 4.542686
 >> iter 74000, loss: 4.861782
 >> iter 75000, loss: 4.806261
 >> iter 76000, loss: 4.873457
 >> iter 77000, loss: 4.659655
 >> iter 78000, loss: 4.702212
 >> iter 79000, loss: 4.455018
 >> iter 80000, loss: 4.446691
   Number of active neurons: 2
 >> iter 81000, loss: 4.495850
 >> iter 82000, loss: 4.774245
 >> iter 83000, loss: 4.615076
 >> iter 84000, loss: 4.546189
 >> iter 85000, loss: 4.764985
 >> iter 86000, loss: 4.615774
 >> iter 87000, loss: 4.474633
 >> iter 88000, loss: 4.481634
 >> iter 89000, loss: 4.229945
 >> iter 90000, loss: 4.768776
   Number of active neurons: 2
 >> iter 91000, loss: 4.509591
 >> iter 92000, loss: 4.305196
 >> iter 93000, loss: 4.171824
 >> iter 94000, loss: 4.408579
 >> iter 95000, loss: 4.635550
 >> iter 96000, loss: 4.854318
 >> iter 97000, loss: 4.580284
 >> iter 98000, loss: 4.674915
 >> iter 99000, loss: 4.445039
 >> iter 100000, loss: 4.587124
   Number of active neurons: 2
 >> iter 101000, loss: 4.377630
 >> iter 102000, loss: 4.451252
 >> iter 103000, loss: 4.373849
 >> iter 104000, loss: 4.375982
 >> iter 105000, loss: 4.396820
 >> iter 106000, loss: 4.300990
 >> iter 107000, loss: 4.270671
 >> iter 108000, loss: 4.452639
 >> iter 109000, loss: 4.076119
 >> iter 110000, loss: 4.118188
   Number of active neurons: 2
 >> iter 111000, loss: 4.262933
 >> iter 112000, loss: 4.254915
 >> iter 113000, loss: 4.207013
 >> iter 114000, loss: 4.132630
 >> iter 115000, loss: 4.185261
 >> iter 116000, loss: 4.136824
 >> iter 117000, loss: 4.137427
 >> iter 118000, loss: 4.190313
 >> iter 119000, loss: 4.138284
 >> iter 120000, loss: 4.137818
   Number of active neurons: 2
 >> iter 121000, loss: 4.191048
 >> iter 122000, loss: 3.823087
 >> iter 123000, loss: 3.820663
 >> iter 124000, loss: 3.602961
 >> iter 125000, loss: 4.023371
 >> iter 126000, loss: 4.006056
 >> iter 127000, loss: 4.046516
 >> iter 128000, loss: 4.033032
 >> iter 129000, loss: 4.046303
 >> iter 130000, loss: 4.193598
   Number of active neurons: 2
 >> iter 131000, loss: 4.241464
 >> iter 132000, loss: 4.086657
 >> iter 133000, loss: 4.011466
 >> iter 134000, loss: 4.332325
 >> iter 135000, loss: 4.264452
 >> iter 136000, loss: 4.237551
 >> iter 137000, loss: 3.922167
 >> iter 138000, loss: 3.824025
 >> iter 139000, loss: 3.588768
 >> iter 140000, loss: 3.732183
   Number of active neurons: 2
 >> iter 141000, loss: 4.147332
 >> iter 142000, loss: 4.230429
 >> iter 143000, loss: 4.087689
 >> iter 144000, loss: 4.076474
 >> iter 145000, loss: 3.690329
 >> iter 146000, loss: 3.973532
 >> iter 147000, loss: 3.962818
 >> iter 148000, loss: 4.172643
 >> iter 149000, loss: 4.003170
 >> iter 150000, loss: 4.097356
   Number of active neurons: 2
 >> iter 151000, loss: 4.090325
 >> iter 152000, loss: 3.998609
 >> iter 153000, loss: 3.907500
 >> iter 154000, loss: 4.219681
 >> iter 155000, loss: 4.356214
 >> iter 156000, loss: 3.841031
 >> iter 157000, loss: 3.904761
 >> iter 158000, loss: 4.062520
 >> iter 159000, loss: 3.915451
 >> iter 160000, loss: 4.224193
   Number of active neurons: 2
 >> iter 161000, loss: 3.911514
 >> iter 162000, loss: 4.102847
 >> iter 163000, loss: 3.921574
 >> iter 164000, loss: 3.787236
 >> iter 165000, loss: 3.755748
 >> iter 166000, loss: 3.789669
 >> iter 167000, loss: 3.950157
 >> iter 168000, loss: 4.209766
 >> iter 169000, loss: 4.213730
 >> iter 170000, loss: 3.996071
   Number of active neurons: 2
 >> iter 171000, loss: 3.918868
 >> iter 172000, loss: 4.381916
 >> iter 173000, loss: 3.877376
 >> iter 174000, loss: 4.232713
 >> iter 175000, loss: 4.324641
 >> iter 176000, loss: 4.187456
 >> iter 177000, loss: 4.574523
 >> iter 178000, loss: 4.041849
 >> iter 179000, loss: 4.159548
 >> iter 180000, loss: 4.119407
   Number of active neurons: 2
 >> iter 181000, loss: 4.060424
 >> iter 182000, loss: 3.896952
 >> iter 183000, loss: 3.786206
 >> iter 184000, loss: 3.630595
 >> iter 185000, loss: 3.518895
 >> iter 186000, loss: 3.952787
 >> iter 187000, loss: 3.542119
 >> iter 188000, loss: 3.899810
 >> iter 189000, loss: 3.852187
 >> iter 190000, loss: 4.090221
   Number of active neurons: 2
 >> iter 191000, loss: 3.415204
 >> iter 192000, loss: 4.004024
 >> iter 193000, loss: 3.481682
 >> iter 194000, loss: 3.767666
 >> iter 195000, loss: 4.123968
 >> iter 196000, loss: 4.166162
 >> iter 197000, loss: 3.851538
 >> iter 198000, loss: 3.760579
 >> iter 199000, loss: 3.780882
 >> iter 200000, loss: 3.980851
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.974848
 >> iter 2000, loss: 12.293825
 >> iter 3000, loss: 8.742943
 >> iter 4000, loss: 7.067610
 >> iter 5000, loss: 6.331801
 >> iter 6000, loss: 5.894122
 >> iter 7000, loss: 5.743106
 >> iter 8000, loss: 5.665121
 >> iter 9000, loss: 5.623608
 >> iter 10000, loss: 5.366486
   Number of active neurons: 2
 >> iter 11000, loss: 5.546982
 >> iter 12000, loss: 4.928432
 >> iter 13000, loss: 4.962281
 >> iter 14000, loss: 5.121183
 >> iter 15000, loss: 5.236753
 >> iter 16000, loss: 4.983493
 >> iter 17000, loss: 4.699668
 >> iter 18000, loss: 5.067888
 >> iter 19000, loss: 5.265684
 >> iter 20000, loss: 5.297325
   Number of active neurons: 2
 >> iter 21000, loss: 5.260089
 >> iter 22000, loss: 5.367458
 >> iter 23000, loss: 4.941956
 >> iter 24000, loss: 5.136882
 >> iter 25000, loss: 5.008411
 >> iter 26000, loss: 4.844886
 >> iter 27000, loss: 5.091472
 >> iter 28000, loss: 5.108237
 >> iter 29000, loss: 5.077911
 >> iter 30000, loss: 4.919240
   Number of active neurons: 2
 >> iter 31000, loss: 4.740553
 >> iter 32000, loss: 5.091167
 >> iter 33000, loss: 5.079344
 >> iter 34000, loss: 5.048804
 >> iter 35000, loss: 4.628178
 >> iter 36000, loss: 4.886264
 >> iter 37000, loss: 4.929021
 >> iter 38000, loss: 4.740510
 >> iter 39000, loss: 4.823594
 >> iter 40000, loss: 4.877272
   Number of active neurons: 2
 >> iter 41000, loss: 4.789520
 >> iter 42000, loss: 4.733590
 >> iter 43000, loss: 4.758671
 >> iter 44000, loss: 4.648370
 >> iter 45000, loss: 4.750765
 >> iter 46000, loss: 4.638123
 >> iter 47000, loss: 4.939971
 >> iter 48000, loss: 4.818472
 >> iter 49000, loss: 5.083291
 >> iter 50000, loss: 4.336231
   Number of active neurons: 2
 >> iter 51000, loss: 4.471462
 >> iter 52000, loss: 4.440233
 >> iter 53000, loss: 3.839689
 >> iter 54000, loss: 4.436461
 >> iter 55000, loss: 4.513244
 >> iter 56000, loss: 4.134406
 >> iter 57000, loss: 4.510015
 >> iter 58000, loss: 4.380665
 >> iter 59000, loss: 4.319082
 >> iter 60000, loss: 4.351022
   Number of active neurons: 2
 >> iter 61000, loss: 4.255510
 >> iter 62000, loss: 4.818027
 >> iter 63000, loss: 4.578673
 >> iter 64000, loss: 4.544724
 >> iter 65000, loss: 4.137087
 >> iter 66000, loss: 4.219697
 >> iter 67000, loss: 4.687364
 >> iter 68000, loss: 4.299282
 >> iter 69000, loss: 4.122291
 >> iter 70000, loss: 4.427248
   Number of active neurons: 2
 >> iter 71000, loss: 4.755838
 >> iter 72000, loss: 4.517982
 >> iter 73000, loss: 4.676155
 >> iter 74000, loss: 4.697012
 >> iter 75000, loss: 4.590734
 >> iter 76000, loss: 4.459689
 >> iter 77000, loss: 4.485602
 >> iter 78000, loss: 4.413347
 >> iter 79000, loss: 4.364353
 >> iter 80000, loss: 4.247747
   Number of active neurons: 2
 >> iter 81000, loss: 4.197341
 >> iter 82000, loss: 4.523108
 >> iter 83000, loss: 4.410347
 >> iter 84000, loss: 4.580497
 >> iter 85000, loss: 4.108271
 >> iter 86000, loss: 4.276321
 >> iter 87000, loss: 4.224360
 >> iter 88000, loss: 4.138604
 >> iter 89000, loss: 3.929201
 >> iter 90000, loss: 4.284921
   Number of active neurons: 2
 >> iter 91000, loss: 4.037570
 >> iter 92000, loss: 3.764869
 >> iter 93000, loss: 4.043643
 >> iter 94000, loss: 4.260326
 >> iter 95000, loss: 3.951592
 >> iter 96000, loss: 3.938038
 >> iter 97000, loss: 3.773536
 >> iter 98000, loss: 4.282321
 >> iter 99000, loss: 4.165019
 >> iter 100000, loss: 4.464987
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.189112
 >> iter 2000, loss: 12.217643
 >> iter 3000, loss: 8.651791
 >> iter 4000, loss: 7.213292
 >> iter 5000, loss: 6.544935
 >> iter 6000, loss: 6.204163
 >> iter 7000, loss: 5.637014
 >> iter 8000, loss: 5.460226
 >> iter 9000, loss: 5.544320
 >> iter 10000, loss: 5.840177
   Number of active neurons: 2
 >> iter 11000, loss: 5.378085
 >> iter 12000, loss: 5.030239
 >> iter 13000, loss: 4.798557
 >> iter 14000, loss: 5.086361
 >> iter 15000, loss: 4.931155
 >> iter 16000, loss: 4.415701
 >> iter 17000, loss: 4.443956
 >> iter 18000, loss: 4.301761
 >> iter 19000, loss: 4.507636
 >> iter 20000, loss: 4.363491
   Number of active neurons: 2
 >> iter 21000, loss: 4.068355
 >> iter 22000, loss: 4.090221
 >> iter 23000, loss: 4.299740
 >> iter 24000, loss: 4.154367
 >> iter 25000, loss: 3.877616
 >> iter 26000, loss: 4.376873
 >> iter 27000, loss: 4.343583
 >> iter 28000, loss: 4.207157
 >> iter 29000, loss: 3.796793
 >> iter 30000, loss: 3.751102
   Number of active neurons: 2
 >> iter 31000, loss: 4.144055
 >> iter 32000, loss: 4.244667
 >> iter 33000, loss: 3.940570
 >> iter 34000, loss: 3.928187
 >> iter 35000, loss: 3.926779
 >> iter 36000, loss: 3.978357
 >> iter 37000, loss: 3.704822
 >> iter 38000, loss: 3.885993
 >> iter 39000, loss: 3.828627
 >> iter 40000, loss: 3.659075
   Number of active neurons: 2
 >> iter 41000, loss: 3.948360
 >> iter 42000, loss: 3.959271
 >> iter 43000, loss: 3.787208
 >> iter 44000, loss: 3.719668
 >> iter 45000, loss: 3.652386
 >> iter 46000, loss: 3.849988
 >> iter 47000, loss: 3.703254
 >> iter 48000, loss: 3.928428
 >> iter 49000, loss: 3.940451
 >> iter 50000, loss: 3.920728
   Number of active neurons: 2
 >> iter 51000, loss: 3.647415
 >> iter 52000, loss: 3.450151
 >> iter 53000, loss: 3.638316
 >> iter 54000, loss: 3.825014
 >> iter 55000, loss: 3.721949
 >> iter 56000, loss: 3.746417
 >> iter 57000, loss: 3.767053
 >> iter 58000, loss: 3.877202
 >> iter 59000, loss: 3.350314
 >> iter 60000, loss: 3.349439
   Number of active neurons: 2
 >> iter 61000, loss: 3.556944
 >> iter 62000, loss: 3.286563
 >> iter 63000, loss: 3.373549
 >> iter 64000, loss: 3.783479
 >> iter 65000, loss: 3.846942
 >> iter 66000, loss: 3.579681
 >> iter 67000, loss: 3.596057
 >> iter 68000, loss: 3.549316
 >> iter 69000, loss: 3.730378
 >> iter 70000, loss: 3.409469
   Number of active neurons: 2
 >> iter 71000, loss: 3.439979
 >> iter 72000, loss: 3.806685
 >> iter 73000, loss: 3.488030
 >> iter 74000, loss: 3.673575
 >> iter 75000, loss: 3.692095
 >> iter 76000, loss: 3.496854
 >> iter 77000, loss: 3.829499
 >> iter 78000, loss: 3.838908
 >> iter 79000, loss: 3.453340
 >> iter 80000, loss: 3.512257
   Number of active neurons: 2
 >> iter 81000, loss: 3.312101
 >> iter 82000, loss: 3.391876
 >> iter 83000, loss: 3.388957
 >> iter 84000, loss: 3.467470
 >> iter 85000, loss: 3.444655
 >> iter 86000, loss: 3.406025
 >> iter 87000, loss: 3.311126
 >> iter 88000, loss: 3.330841
 >> iter 89000, loss: 3.507438
 >> iter 90000, loss: 3.638258
   Number of active neurons: 2
 >> iter 91000, loss: 3.266617
 >> iter 92000, loss: 2.892878
 >> iter 93000, loss: 3.301450
 >> iter 94000, loss: 3.526630
 >> iter 95000, loss: 3.218414
 >> iter 96000, loss: 3.287454
 >> iter 97000, loss: 3.367306
 >> iter 98000, loss: 3.783273
 >> iter 99000, loss: 3.614062
 >> iter 100000, loss: 3.285958
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 20.524759
 >> iter 2000, loss: 18.054275
 >> iter 3000, loss: 17.068459
 >> iter 4000, loss: 16.779365
 >> iter 5000, loss: 16.602169
 >> iter 6000, loss: 16.598189
 >> iter 7000, loss: 16.539944
 >> iter 8000, loss: 16.570962
 >> iter 9000, loss: 16.532179
 >> iter 10000, loss: 16.581928
   Number of active neurons: 0
 >> iter 11000, loss: 16.532518
 >> iter 12000, loss: 16.591972
 >> iter 13000, loss: 16.533415
 >> iter 14000, loss: 16.598198
 >> iter 15000, loss: 16.533569
 >> iter 16000, loss: 15.738686
 >> iter 17000, loss: 12.816966
 >> iter 18000, loss: 9.729297
 >> iter 19000, loss: 8.189920
 >> iter 20000, loss: 6.916146
   Number of active neurons: 2
 >> iter 21000, loss: 6.317458
 >> iter 22000, loss: 6.237316
 >> iter 23000, loss: 5.610739
 >> iter 24000, loss: 5.472475
 >> iter 25000, loss: 5.114489
 >> iter 26000, loss: 5.185969
 >> iter 27000, loss: 4.763306
 >> iter 28000, loss: 4.946472
 >> iter 29000, loss: 4.789131
 >> iter 30000, loss: 4.976062
   Number of active neurons: 2
 >> iter 31000, loss: 4.703229
 >> iter 32000, loss: 4.544950
 >> iter 33000, loss: 4.502342
 >> iter 34000, loss: 4.574855
 >> iter 35000, loss: 4.313724
 >> iter 36000, loss: 4.533867
 >> iter 37000, loss: 4.293706
 >> iter 38000, loss: 4.259685
 >> iter 39000, loss: 4.132908
 >> iter 40000, loss: 4.250012
   Number of active neurons: 2
 >> iter 41000, loss: 4.426860
 >> iter 42000, loss: 4.369840
 >> iter 43000, loss: 4.359201
 >> iter 44000, loss: 4.628988
 >> iter 45000, loss: 4.290703
 >> iter 46000, loss: 4.145295
 >> iter 47000, loss: 4.011883
 >> iter 48000, loss: 3.882764
 >> iter 49000, loss: 3.810045
 >> iter 50000, loss: 3.599586
   Number of active neurons: 2
 >> iter 51000, loss: 3.651488
 >> iter 52000, loss: 3.635920
 >> iter 53000, loss: 3.797076
 >> iter 54000, loss: 3.807060
 >> iter 55000, loss: 3.837350
 >> iter 56000, loss: 3.761342
 >> iter 57000, loss: 3.756892
 >> iter 58000, loss: 3.484248
 >> iter 59000, loss: 3.606948
 >> iter 60000, loss: 3.892845
   Number of active neurons: 2
 >> iter 61000, loss: 3.644377
 >> iter 62000, loss: 3.651775
 >> iter 63000, loss: 3.323221
 >> iter 64000, loss: 3.251018
 >> iter 65000, loss: 3.191532
 >> iter 66000, loss: 3.348831
 >> iter 67000, loss: 3.331503
 >> iter 68000, loss: 3.789095
 >> iter 69000, loss: 3.330133
 >> iter 70000, loss: 3.375416
   Number of active neurons: 2
 >> iter 71000, loss: 3.383733
 >> iter 72000, loss: 3.405505
 >> iter 73000, loss: 3.755814
 >> iter 74000, loss: 3.869742
 >> iter 75000, loss: 3.483982
 >> iter 76000, loss: 3.757353
 >> iter 77000, loss: 3.212304
 >> iter 78000, loss: 3.548304
 >> iter 79000, loss: 3.518193
 >> iter 80000, loss: 3.567787
   Number of active neurons: 2
 >> iter 81000, loss: 3.386459
 >> iter 82000, loss: 3.722380
 >> iter 83000, loss: 2.976001
 >> iter 84000, loss: 3.260357
 >> iter 85000, loss: 3.170759
 >> iter 86000, loss: 3.467776
 >> iter 87000, loss: 3.328775
 >> iter 88000, loss: 3.457633
 >> iter 89000, loss: 3.456769
 >> iter 90000, loss: 3.322915
   Number of active neurons: 2
 >> iter 91000, loss: 3.363514
 >> iter 92000, loss: 3.586669
 >> iter 93000, loss: 3.280284
 >> iter 94000, loss: 3.609912
 >> iter 95000, loss: 3.323195
 >> iter 96000, loss: 3.145087
 >> iter 97000, loss: 3.157749
 >> iter 98000, loss: 3.229364
 >> iter 99000, loss: 3.201529
 >> iter 100000, loss: 3.288206
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

