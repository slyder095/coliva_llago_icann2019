 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.5
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.816777
 >> iter 2000, loss: 9.932876
 >> iter 3000, loss: 4.030796
 >> iter 4000, loss: 1.690639
 >> iter 5000, loss: 0.716369
 >> iter 6000, loss: 0.287243
 >> iter 7000, loss: 0.137044
 >> iter 8000, loss: 0.171890
 >> iter 9000, loss: 0.074162
 >> iter 10000, loss: 0.052829
   Number of active neurons: 10
 >> iter 11000, loss: 0.028506
 >> iter 12000, loss: 0.019412
 >> iter 13000, loss: 0.012452
 >> iter 14000, loss: 0.021335
 >> iter 15000, loss: 0.012520
 >> iter 16000, loss: 0.011739
 >> iter 17000, loss: 0.008195
 >> iter 18000, loss: 0.006279
 >> iter 19000, loss: 0.005452
 >> iter 20000, loss: 0.005451
   Number of active neurons: 10
 >> iter 21000, loss: 0.005022
 >> iter 22000, loss: 0.004271
 >> iter 23000, loss: 0.004380
 >> iter 24000, loss: 0.003885
 >> iter 25000, loss: 0.020444
 >> iter 26000, loss: 0.009916
 >> iter 27000, loss: 0.005650
 >> iter 28000, loss: 0.004033
 >> iter 29000, loss: 0.003403
 >> iter 30000, loss: 0.004929
   Number of active neurons: 10
 >> iter 31000, loss: 0.004825
 >> iter 32000, loss: 0.004068
 >> iter 33000, loss: 0.003215
 >> iter 34000, loss: 0.004925
 >> iter 35000, loss: 0.003549
 >> iter 36000, loss: 0.002997
 >> iter 37000, loss: 0.002535
 >> iter 38000, loss: 0.002284
 >> iter 39000, loss: 0.002245
 >> iter 40000, loss: 0.002043
   Number of active neurons: 10
 >> iter 41000, loss: 0.002129
 >> iter 42000, loss: 0.002045
 >> iter 43000, loss: 0.020207
 >> iter 44000, loss: 0.008780
 >> iter 45000, loss: 0.004601
 >> iter 46000, loss: 0.004473
 >> iter 47000, loss: 0.002933
 >> iter 48000, loss: 0.002206
 >> iter 49000, loss: 0.006170
 >> iter 50000, loss: 0.003807
   Number of active neurons: 10
 >> iter 51000, loss: 0.011933
 >> iter 52000, loss: 0.005602
 >> iter 53000, loss: 0.003225
 >> iter 54000, loss: 0.002379
 >> iter 55000, loss: 0.001920
 >> iter 56000, loss: 0.001605
 >> iter 57000, loss: 0.001617
 >> iter 58000, loss: 0.001483
 >> iter 59000, loss: 0.001441
 >> iter 60000, loss: 0.001418
   Number of active neurons: 10
 >> iter 61000, loss: 0.001944
 >> iter 62000, loss: 0.001492
 >> iter 63000, loss: 0.001338
 >> iter 64000, loss: 0.001266
 >> iter 65000, loss: 0.001240
 >> iter 66000, loss: 0.001161
 >> iter 67000, loss: 0.001238
 >> iter 68000, loss: 0.001213
 >> iter 69000, loss: 0.001142
 >> iter 70000, loss: 0.001109
   Number of active neurons: 10
 >> iter 71000, loss: 0.001854
 >> iter 72000, loss: 0.002387
 >> iter 73000, loss: 0.002061
 >> iter 74000, loss: 0.001437
 >> iter 75000, loss: 0.001158
 >> iter 76000, loss: 0.001262
 >> iter 77000, loss: 0.001093
 >> iter 78000, loss: 0.001018
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.711986
 >> iter 2000, loss: 10.043025
 >> iter 3000, loss: 4.180508
 >> iter 4000, loss: 1.650040
 >> iter 5000, loss: 0.798347
 >> iter 6000, loss: 0.352650
 >> iter 7000, loss: 0.292381
 >> iter 8000, loss: 0.130780
 >> iter 9000, loss: 0.224314
 >> iter 10000, loss: 0.096638
   Number of active neurons: 10
 >> iter 11000, loss: 0.044854
 >> iter 12000, loss: 0.026725
 >> iter 13000, loss: 0.016273
 >> iter 14000, loss: 0.011167
 >> iter 15000, loss: 0.008667
 >> iter 16000, loss: 0.007273
 >> iter 17000, loss: 0.006292
 >> iter 18000, loss: 0.006416
 >> iter 19000, loss: 0.006226
 >> iter 20000, loss: 0.008186
   Number of active neurons: 10
 >> iter 21000, loss: 0.006340
 >> iter 22000, loss: 0.005088
 >> iter 23000, loss: 0.023177
 >> iter 24000, loss: 0.011333
 >> iter 25000, loss: 0.006672
 >> iter 26000, loss: 0.004619
 >> iter 27000, loss: 0.032929
 >> iter 28000, loss: 0.014465
 >> iter 29000, loss: 0.007444
 >> iter 30000, loss: 0.008260
   Number of active neurons: 10
 >> iter 31000, loss: 0.004940
 >> iter 32000, loss: 0.003709
 >> iter 33000, loss: 0.003129
 >> iter 34000, loss: 0.002866
 >> iter 35000, loss: 0.029626
 >> iter 36000, loss: 0.021567
 >> iter 37000, loss: 0.010971
 >> iter 38000, loss: 0.005808
 >> iter 39000, loss: 0.003768
 >> iter 40000, loss: 0.002968
   Number of active neurons: 10
 >> iter 41000, loss: 0.002501
 >> iter 42000, loss: 0.002247
 >> iter 43000, loss: 0.002032
 >> iter 44000, loss: 0.002024
 >> iter 45000, loss: 0.001937
 >> iter 46000, loss: 0.001843
 >> iter 47000, loss: 0.001783
 >> iter 48000, loss: 0.001797
 >> iter 49000, loss: 0.001922
 >> iter 50000, loss: 0.001677
   Number of active neurons: 10
 >> iter 51000, loss: 0.001815
 >> iter 52000, loss: 0.001635
 >> iter 53000, loss: 0.001560
 >> iter 54000, loss: 0.001483
 >> iter 55000, loss: 0.001395
 >> iter 56000, loss: 0.089130
 >> iter 57000, loss: 0.061993
 >> iter 58000, loss: 0.057718
 >> iter 59000, loss: 0.029333
 >> iter 60000, loss: 0.029103
   Number of active neurons: 10
 >> iter 61000, loss: 0.012240
 >> iter 62000, loss: 0.030901
 >> iter 63000, loss: 0.012759
 >> iter 64000, loss: 0.005937
 >> iter 65000, loss: 0.007934
 >> iter 66000, loss: 0.004354
 >> iter 67000, loss: 0.005116
 >> iter 68000, loss: 0.004004
 >> iter 69000, loss: 0.002512
 >> iter 70000, loss: 0.002023
   Number of active neurons: 10
 >> iter 71000, loss: 0.005591
 >> iter 72000, loss: 0.003337
 >> iter 73000, loss: 0.004217
 >> iter 74000, loss: 0.002578
 >> iter 75000, loss: 0.001807
 >> iter 76000, loss: 0.006583
 >> iter 77000, loss: 0.004637
 >> iter 78000, loss: 0.002697
 >> iter 79000, loss: 0.001977
 >> iter 80000, loss: 0.001870
   Number of active neurons: 10
 >> iter 81000, loss: 0.001551
 >> iter 82000, loss: 0.015136
 >> iter 83000, loss: 0.006774
 >> iter 84000, loss: 0.003827
 >> iter 85000, loss: 0.032327
 >> iter 86000, loss: 0.015203
 >> iter 87000, loss: 0.006777
 >> iter 88000, loss: 0.003332
 >> iter 89000, loss: 0.002201
 >> iter 90000, loss: 0.001739
   Number of active neurons: 10
 >> iter 91000, loss: 0.002359
 >> iter 92000, loss: 0.001629
 >> iter 93000, loss: 0.001384
 >> iter 94000, loss: 0.001221
 >> iter 95000, loss: 0.001174
 >> iter 96000, loss: 0.001105
 >> iter 97000, loss: 0.001115
 >> iter 98000, loss: 0.001052
 >> iter 99000, loss: 0.001068
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.830484
 >> iter 2000, loss: 8.755663
 >> iter 3000, loss: 3.474175
 >> iter 4000, loss: 1.418463
 >> iter 5000, loss: 0.604234
 >> iter 6000, loss: 0.247128
 >> iter 7000, loss: 0.112053
 >> iter 8000, loss: 0.071291
 >> iter 9000, loss: 0.064508
 >> iter 10000, loss: 0.039759
   Number of active neurons: 10
 >> iter 11000, loss: 0.019542
 >> iter 12000, loss: 0.011518
 >> iter 13000, loss: 0.020307
 >> iter 14000, loss: 0.011759
 >> iter 15000, loss: 0.007317
 >> iter 16000, loss: 0.005380
 >> iter 17000, loss: 0.008120
 >> iter 18000, loss: 0.005498
 >> iter 19000, loss: 0.004150
 >> iter 20000, loss: 0.004511
   Number of active neurons: 10
 >> iter 21000, loss: 0.003747
 >> iter 22000, loss: 0.003172
 >> iter 23000, loss: 0.003056
 >> iter 24000, loss: 0.003237
 >> iter 25000, loss: 0.004638
 >> iter 26000, loss: 0.003639
 >> iter 27000, loss: 0.002865
 >> iter 28000, loss: 0.002435
 >> iter 29000, loss: 0.003266
 >> iter 30000, loss: 0.002920
   Number of active neurons: 10
 >> iter 31000, loss: 0.002211
 >> iter 32000, loss: 0.001953
 >> iter 33000, loss: 0.001778
 >> iter 34000, loss: 0.067186
 >> iter 35000, loss: 0.026412
 >> iter 36000, loss: 0.011112
 >> iter 37000, loss: 0.005321
 >> iter 38000, loss: 0.003195
 >> iter 39000, loss: 0.002262
 >> iter 40000, loss: 0.001899
   Number of active neurons: 10
 >> iter 41000, loss: 0.001716
 >> iter 42000, loss: 0.001551
 >> iter 43000, loss: 0.049864
 >> iter 44000, loss: 0.020103
 >> iter 45000, loss: 0.008718
 >> iter 46000, loss: 0.004399
 >> iter 47000, loss: 0.002588
 >> iter 48000, loss: 0.001947
 >> iter 49000, loss: 0.001969
 >> iter 50000, loss: 0.001545
   Number of active neurons: 10
 >> iter 51000, loss: 0.001480
 >> iter 52000, loss: 0.001258
 >> iter 53000, loss: 0.001183
 >> iter 54000, loss: 0.001095
 >> iter 55000, loss: 0.001077
 >> iter 56000, loss: 0.001030
 >> iter 57000, loss: 0.001024
 >> iter 58000, loss: 0.001025
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.650149
 >> iter 2000, loss: 12.742898
 >> iter 3000, loss: 5.774444
 >> iter 4000, loss: 2.467216
 >> iter 5000, loss: 1.066397
 >> iter 6000, loss: 0.492652
 >> iter 7000, loss: 0.215612
 >> iter 8000, loss: 0.137900
 >> iter 9000, loss: 0.073903
 >> iter 10000, loss: 0.053628
   Number of active neurons: 10
 >> iter 11000, loss: 0.031275
 >> iter 12000, loss: 0.023087
 >> iter 13000, loss: 0.030234
 >> iter 14000, loss: 0.106294
 >> iter 15000, loss: 0.048042
 >> iter 16000, loss: 0.024284
 >> iter 17000, loss: 0.014250
 >> iter 18000, loss: 0.087784
 >> iter 19000, loss: 0.037656
 >> iter 20000, loss: 0.024789
   Number of active neurons: 10
 >> iter 21000, loss: 0.028794
 >> iter 22000, loss: 0.017552
 >> iter 23000, loss: 0.010540
 >> iter 24000, loss: 0.014084
 >> iter 25000, loss: 0.018434
 >> iter 26000, loss: 0.014118
 >> iter 27000, loss: 0.009755
 >> iter 28000, loss: 0.073938
 >> iter 29000, loss: 0.044547
 >> iter 30000, loss: 0.021872
   Number of active neurons: 10
 >> iter 31000, loss: 0.026062
 >> iter 32000, loss: 0.012587
 >> iter 33000, loss: 0.007699
 >> iter 34000, loss: 0.010377
 >> iter 35000, loss: 0.013063
 >> iter 36000, loss: 0.009444
 >> iter 37000, loss: 0.006046
 >> iter 38000, loss: 0.026743
 >> iter 39000, loss: 0.062933
 >> iter 40000, loss: 0.025947
   Number of active neurons: 10
 >> iter 41000, loss: 0.011713
 >> iter 42000, loss: 0.056588
 >> iter 43000, loss: 0.023505
 >> iter 44000, loss: 0.011295
 >> iter 45000, loss: 0.006587
 >> iter 46000, loss: 0.004327
 >> iter 47000, loss: 0.011570
 >> iter 48000, loss: 0.006055
 >> iter 49000, loss: 0.003985
 >> iter 50000, loss: 0.003182
   Number of active neurons: 10
 >> iter 51000, loss: 0.002774
 >> iter 52000, loss: 0.002628
 >> iter 53000, loss: 0.002509
 >> iter 54000, loss: 0.002522
 >> iter 55000, loss: 0.002451
 >> iter 56000, loss: 0.002307
 >> iter 57000, loss: 0.002182
 >> iter 58000, loss: 0.002143
 >> iter 59000, loss: 0.002050
 >> iter 60000, loss: 0.001984
   Number of active neurons: 10
 >> iter 61000, loss: 0.003003
 >> iter 62000, loss: 0.016399
 >> iter 63000, loss: 0.007718
 >> iter 64000, loss: 0.004537
 >> iter 65000, loss: 0.003024
 >> iter 66000, loss: 0.002190
 >> iter 67000, loss: 0.001914
 >> iter 68000, loss: 0.001764
 >> iter 69000, loss: 0.001694
 >> iter 70000, loss: 0.001661
   Number of active neurons: 10
 >> iter 71000, loss: 0.001703
 >> iter 72000, loss: 0.001592
 >> iter 73000, loss: 0.001735
 >> iter 74000, loss: 0.001774
 >> iter 75000, loss: 0.001594
 >> iter 76000, loss: 0.015653
 >> iter 77000, loss: 0.020418
 >> iter 78000, loss: 0.008638
 >> iter 79000, loss: 0.005029
 >> iter 80000, loss: 0.002943
   Number of active neurons: 10
 >> iter 81000, loss: 0.002281
 >> iter 82000, loss: 0.001821
 >> iter 83000, loss: 0.003029
 >> iter 84000, loss: 0.002639
 >> iter 85000, loss: 0.002283
 >> iter 86000, loss: 0.001748
 >> iter 87000, loss: 0.001594
 >> iter 88000, loss: 0.007120
 >> iter 89000, loss: 0.003647
 >> iter 90000, loss: 0.002370
   Number of active neurons: 10
 >> iter 91000, loss: 0.001688
 >> iter 92000, loss: 0.001407
 >> iter 93000, loss: 0.001536
 >> iter 94000, loss: 0.001368
 >> iter 95000, loss: 0.001332
 >> iter 96000, loss: 0.001212
 >> iter 97000, loss: 0.001188
 >> iter 98000, loss: 0.001171
 >> iter 99000, loss: 0.001195
 >> iter 100000, loss: 0.001360
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.969446
 >> iter 2000, loss: 10.658436
 >> iter 3000, loss: 4.077903
 >> iter 4000, loss: 1.533034
 >> iter 5000, loss: 0.668986
 >> iter 6000, loss: 0.284014
 >> iter 7000, loss: 0.123343
 >> iter 8000, loss: 0.077523
 >> iter 9000, loss: 0.072087
 >> iter 10000, loss: 0.140440
   Number of active neurons: 10
 >> iter 11000, loss: 0.101627
 >> iter 12000, loss: 0.199253
 >> iter 13000, loss: 0.105270
 >> iter 14000, loss: 0.067300
 >> iter 15000, loss: 0.037279
 >> iter 16000, loss: 0.017928
 >> iter 17000, loss: 0.010715
 >> iter 18000, loss: 0.007412
 >> iter 19000, loss: 0.005949
 >> iter 20000, loss: 0.005103
   Number of active neurons: 10
 >> iter 21000, loss: 0.005794
 >> iter 22000, loss: 0.004631
 >> iter 23000, loss: 0.004068
 >> iter 24000, loss: 0.003549
 >> iter 25000, loss: 0.003294
 >> iter 26000, loss: 0.003178
 >> iter 27000, loss: 0.014011
 >> iter 28000, loss: 0.031564
 >> iter 29000, loss: 0.013656
 >> iter 30000, loss: 0.007600
   Number of active neurons: 10
 >> iter 31000, loss: 0.004611
 >> iter 32000, loss: 0.003185
 >> iter 33000, loss: 0.002634
 >> iter 34000, loss: 0.002352
 >> iter 35000, loss: 0.002118
 >> iter 36000, loss: 0.001940
 >> iter 37000, loss: 0.001998
 >> iter 38000, loss: 0.001881
 >> iter 39000, loss: 0.003033
 >> iter 40000, loss: 0.002374
   Number of active neurons: 10
 >> iter 41000, loss: 0.001982
 >> iter 42000, loss: 0.001739
 >> iter 43000, loss: 0.001680
 >> iter 44000, loss: 0.001806
 >> iter 45000, loss: 0.001621
 >> iter 46000, loss: 0.014521
 >> iter 47000, loss: 0.006374
 >> iter 48000, loss: 0.003425
 >> iter 49000, loss: 0.003009
 >> iter 50000, loss: 0.001967
   Number of active neurons: 10
 >> iter 51000, loss: 0.001618
 >> iter 52000, loss: 0.001401
 >> iter 53000, loss: 0.001398
 >> iter 54000, loss: 0.001322
 >> iter 55000, loss: 0.001213
 >> iter 56000, loss: 0.001150
 >> iter 57000, loss: 0.001172
 >> iter 58000, loss: 0.001122
 >> iter 59000, loss: 0.001048
 >> iter 60000, loss: 0.001028
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.657406
 >> iter 2000, loss: 9.419214
 >> iter 3000, loss: 3.805725
 >> iter 4000, loss: 1.611772
 >> iter 5000, loss: 0.787739
 >> iter 6000, loss: 0.311031
 >> iter 7000, loss: 0.269411
 >> iter 8000, loss: 0.181528
 >> iter 9000, loss: 0.078546
 >> iter 10000, loss: 0.036812
   Number of active neurons: 10
 >> iter 11000, loss: 0.156468
 >> iter 12000, loss: 0.075446
 >> iter 13000, loss: 0.062440
 >> iter 14000, loss: 0.093355
 >> iter 15000, loss: 0.050070
 >> iter 16000, loss: 0.140411
 >> iter 17000, loss: 0.058412
 >> iter 18000, loss: 0.026383
 >> iter 19000, loss: 0.013999
 >> iter 20000, loss: 0.010942
   Number of active neurons: 10
 >> iter 21000, loss: 0.007488
 >> iter 22000, loss: 0.005842
 >> iter 23000, loss: 0.005137
 >> iter 24000, loss: 0.007160
 >> iter 25000, loss: 0.051876
 >> iter 26000, loss: 0.021779
 >> iter 27000, loss: 0.012289
 >> iter 28000, loss: 0.006852
 >> iter 29000, loss: 0.006175
 >> iter 30000, loss: 0.028557
   Number of active neurons: 10
 >> iter 31000, loss: 0.012636
 >> iter 32000, loss: 0.006565
 >> iter 33000, loss: 0.004154
 >> iter 34000, loss: 0.003202
 >> iter 35000, loss: 0.002792
 >> iter 36000, loss: 0.002470
 >> iter 37000, loss: 0.008142
 >> iter 38000, loss: 0.004418
 >> iter 39000, loss: 0.003841
 >> iter 40000, loss: 0.002890
   Number of active neurons: 10
 >> iter 41000, loss: 0.002433
 >> iter 42000, loss: 0.002167
 >> iter 43000, loss: 0.001967
 >> iter 44000, loss: 0.001821
 >> iter 45000, loss: 0.001726
 >> iter 46000, loss: 0.001678
 >> iter 47000, loss: 0.001638
 >> iter 48000, loss: 0.089947
 >> iter 49000, loss: 0.034845
 >> iter 50000, loss: 0.014685
   Number of active neurons: 10
 >> iter 51000, loss: 0.007801
 >> iter 52000, loss: 0.004128
 >> iter 53000, loss: 0.017870
 >> iter 54000, loss: 0.008702
 >> iter 55000, loss: 0.006431
 >> iter 56000, loss: 0.003440
 >> iter 57000, loss: 0.002288
 >> iter 58000, loss: 0.001723
 >> iter 59000, loss: 0.001478
 >> iter 60000, loss: 0.001422
   Number of active neurons: 10
 >> iter 61000, loss: 0.007659
 >> iter 62000, loss: 0.003859
 >> iter 63000, loss: 0.003133
 >> iter 64000, loss: 0.001899
 >> iter 65000, loss: 0.001509
 >> iter 66000, loss: 0.001343
 >> iter 67000, loss: 0.001212
 >> iter 68000, loss: 0.001133
 >> iter 69000, loss: 0.001115
 >> iter 70000, loss: 0.001172
   Number of active neurons: 10
 >> iter 71000, loss: 0.001068
 >> iter 72000, loss: 0.001043
 >> iter 73000, loss: 0.001376
 >> iter 74000, loss: 0.001123
 >> iter 75000, loss: 0.001097
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.055001
 >> iter 2000, loss: 10.603628
 >> iter 3000, loss: 4.403599
 >> iter 4000, loss: 1.779573
 >> iter 5000, loss: 0.695893
 >> iter 6000, loss: 0.287208
 >> iter 7000, loss: 0.219955
 >> iter 8000, loss: 0.277619
 >> iter 9000, loss: 0.112864
 >> iter 10000, loss: 0.066067
   Number of active neurons: 10
 >> iter 11000, loss: 0.031867
 >> iter 12000, loss: 0.018294
 >> iter 13000, loss: 0.012306
 >> iter 14000, loss: 0.019613
 >> iter 15000, loss: 0.011821
 >> iter 16000, loss: 0.018133
 >> iter 17000, loss: 0.016161
 >> iter 18000, loss: 0.009814
 >> iter 19000, loss: 0.006843
 >> iter 20000, loss: 0.006449
   Number of active neurons: 10
 >> iter 21000, loss: 0.005561
 >> iter 22000, loss: 0.004493
 >> iter 23000, loss: 0.004412
 >> iter 24000, loss: 0.004123
 >> iter 25000, loss: 0.003922
 >> iter 26000, loss: 0.003416
 >> iter 27000, loss: 0.003215
 >> iter 28000, loss: 0.002997
 >> iter 29000, loss: 0.002861
 >> iter 30000, loss: 0.002705
   Number of active neurons: 10
 >> iter 31000, loss: 0.002677
 >> iter 32000, loss: 0.002573
 >> iter 33000, loss: 0.050863
 >> iter 34000, loss: 0.020777
 >> iter 35000, loss: 0.009232
 >> iter 36000, loss: 0.004846
 >> iter 37000, loss: 0.010202
 >> iter 38000, loss: 0.005877
 >> iter 39000, loss: 0.003600
 >> iter 40000, loss: 0.002617
   Number of active neurons: 10
 >> iter 41000, loss: 0.003696
 >> iter 42000, loss: 0.002610
 >> iter 43000, loss: 0.002125
 >> iter 44000, loss: 0.001893
 >> iter 45000, loss: 0.001818
 >> iter 46000, loss: 0.001779
 >> iter 47000, loss: 0.001684
 >> iter 48000, loss: 0.001743
 >> iter 49000, loss: 0.001741
 >> iter 50000, loss: 0.001584
   Number of active neurons: 10
 >> iter 51000, loss: 0.001542
 >> iter 52000, loss: 0.001424
 >> iter 53000, loss: 0.001447
 >> iter 54000, loss: 0.001373
 >> iter 55000, loss: 0.001375
 >> iter 56000, loss: 0.001313
 >> iter 57000, loss: 0.001324
 >> iter 58000, loss: 0.001296
 >> iter 59000, loss: 0.001264
 >> iter 60000, loss: 0.001266
   Number of active neurons: 10
 >> iter 61000, loss: 0.003910
 >> iter 62000, loss: 0.010828
 >> iter 63000, loss: 0.004828
 >> iter 64000, loss: 0.002538
 >> iter 65000, loss: 0.001728
 >> iter 66000, loss: 0.001346
 >> iter 67000, loss: 0.001273
 >> iter 68000, loss: 0.001150
 >> iter 69000, loss: 0.001405
 >> iter 70000, loss: 0.001173
   Number of active neurons: 10
 >> iter 71000, loss: 0.001068
 >> iter 72000, loss: 0.001047
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.789465
 >> iter 2000, loss: 9.160891
 >> iter 3000, loss: 3.851624
 >> iter 4000, loss: 1.758976
 >> iter 5000, loss: 0.755265
 >> iter 6000, loss: 0.445027
 >> iter 7000, loss: 0.182862
 >> iter 8000, loss: 0.077825
 >> iter 9000, loss: 0.037396
 >> iter 10000, loss: 0.027027
   Number of active neurons: 10
 >> iter 11000, loss: 0.080178
 >> iter 12000, loss: 0.123718
 >> iter 13000, loss: 0.052580
 >> iter 14000, loss: 0.024675
 >> iter 15000, loss: 0.014324
 >> iter 16000, loss: 0.009304
 >> iter 17000, loss: 0.049906
 >> iter 18000, loss: 0.022658
 >> iter 19000, loss: 0.011595
 >> iter 20000, loss: 0.007191
   Number of active neurons: 10
 >> iter 21000, loss: 0.005410
 >> iter 22000, loss: 0.004393
 >> iter 23000, loss: 0.003898
 >> iter 24000, loss: 0.011904
 >> iter 25000, loss: 0.016111
 >> iter 26000, loss: 0.009354
 >> iter 27000, loss: 0.012266
 >> iter 28000, loss: 0.007428
 >> iter 29000, loss: 0.004699
 >> iter 30000, loss: 0.004000
   Number of active neurons: 10
 >> iter 31000, loss: 0.003920
 >> iter 32000, loss: 0.016411
 >> iter 33000, loss: 0.007808
 >> iter 34000, loss: 0.004870
 >> iter 35000, loss: 0.003172
 >> iter 36000, loss: 0.003319
 >> iter 37000, loss: 0.002732
 >> iter 38000, loss: 0.002290
 >> iter 39000, loss: 0.043227
 >> iter 40000, loss: 0.027026
   Number of active neurons: 10
 >> iter 41000, loss: 0.011504
 >> iter 42000, loss: 0.005629
 >> iter 43000, loss: 0.003427
 >> iter 44000, loss: 0.002415
 >> iter 45000, loss: 0.001983
 >> iter 46000, loss: 0.033475
 >> iter 47000, loss: 0.013627
 >> iter 48000, loss: 0.006511
 >> iter 49000, loss: 0.003552
 >> iter 50000, loss: 0.002356
   Number of active neurons: 10
 >> iter 51000, loss: 0.001906
 >> iter 52000, loss: 0.001786
 >> iter 53000, loss: 0.001613
 >> iter 54000, loss: 0.003227
 >> iter 55000, loss: 0.003711
 >> iter 56000, loss: 0.002572
 >> iter 57000, loss: 0.048122
 >> iter 58000, loss: 0.019000
 >> iter 59000, loss: 0.008221
 >> iter 60000, loss: 0.004116
   Number of active neurons: 10
 >> iter 61000, loss: 0.002713
 >> iter 62000, loss: 0.001986
 >> iter 63000, loss: 0.001994
 >> iter 64000, loss: 0.001617
 >> iter 65000, loss: 0.001451
 >> iter 66000, loss: 0.001395
 >> iter 67000, loss: 0.017915
 >> iter 68000, loss: 0.007666
 >> iter 69000, loss: 0.003894
 >> iter 70000, loss: 0.002620
   Number of active neurons: 10
 >> iter 71000, loss: 0.001758
 >> iter 72000, loss: 0.001416
 >> iter 73000, loss: 0.003068
 >> iter 74000, loss: 0.004463
 >> iter 75000, loss: 0.002571
 >> iter 76000, loss: 0.001735
 >> iter 77000, loss: 0.001898
 >> iter 78000, loss: 0.001549
 >> iter 79000, loss: 0.001411
 >> iter 80000, loss: 0.001269
   Number of active neurons: 10
 >> iter 81000, loss: 0.001092
 >> iter 82000, loss: 0.001029
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.826713
 >> iter 2000, loss: 9.043604
 >> iter 3000, loss: 3.538361
 >> iter 4000, loss: 1.386080
 >> iter 5000, loss: 0.563933
 >> iter 6000, loss: 0.267815
 >> iter 7000, loss: 0.134097
 >> iter 8000, loss: 0.083747
 >> iter 9000, loss: 0.054847
 >> iter 10000, loss: 0.102383
   Number of active neurons: 10
 >> iter 11000, loss: 0.045597
 >> iter 12000, loss: 0.045850
 >> iter 13000, loss: 0.211478
 >> iter 14000, loss: 0.084886
 >> iter 15000, loss: 0.037231
 >> iter 16000, loss: 0.141351
 >> iter 17000, loss: 0.131360
 >> iter 18000, loss: 0.123385
 >> iter 19000, loss: 0.051185
 >> iter 20000, loss: 0.048966
   Number of active neurons: 10
 >> iter 21000, loss: 0.022110
 >> iter 22000, loss: 0.012649
 >> iter 23000, loss: 0.008912
 >> iter 24000, loss: 0.006119
 >> iter 25000, loss: 0.004813
 >> iter 26000, loss: 0.003901
 >> iter 27000, loss: 0.003499
 >> iter 28000, loss: 0.003404
 >> iter 29000, loss: 0.003222
 >> iter 30000, loss: 0.047710
   Number of active neurons: 10
 >> iter 31000, loss: 0.019635
 >> iter 32000, loss: 0.009184
 >> iter 33000, loss: 0.025422
 >> iter 34000, loss: 0.011311
 >> iter 35000, loss: 0.005917
 >> iter 36000, loss: 0.006877
 >> iter 37000, loss: 0.004236
 >> iter 38000, loss: 0.003565
 >> iter 39000, loss: 0.075765
 >> iter 40000, loss: 0.036458
   Number of active neurons: 10
 >> iter 41000, loss: 0.015113
 >> iter 42000, loss: 0.007086
 >> iter 43000, loss: 0.003993
 >> iter 44000, loss: 0.006339
 >> iter 45000, loss: 0.003792
 >> iter 46000, loss: 0.002645
 >> iter 47000, loss: 0.002091
 >> iter 48000, loss: 0.001909
 >> iter 49000, loss: 0.001746
 >> iter 50000, loss: 0.001757
   Number of active neurons: 10
 >> iter 51000, loss: 0.001535
 >> iter 52000, loss: 0.001449
 >> iter 53000, loss: 0.001466
 >> iter 54000, loss: 0.001506
 >> iter 55000, loss: 0.001384
 >> iter 56000, loss: 0.001323
 >> iter 57000, loss: 0.001759
 >> iter 58000, loss: 0.001459
 >> iter 59000, loss: 0.001290
 >> iter 60000, loss: 0.001281
   Number of active neurons: 10
 >> iter 61000, loss: 0.001514
 >> iter 62000, loss: 0.001315
 >> iter 63000, loss: 0.001272
 >> iter 64000, loss: 0.001351
 >> iter 65000, loss: 0.001315
 >> iter 66000, loss: 0.001147
 >> iter 67000, loss: 0.001135
 >> iter 68000, loss: 0.001008
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.363356
 >> iter 2000, loss: 8.687567
 >> iter 3000, loss: 3.901992
 >> iter 4000, loss: 1.884275
 >> iter 5000, loss: 0.884498
 >> iter 6000, loss: 0.685131
 >> iter 7000, loss: 0.394230
 >> iter 8000, loss: 0.185367
 >> iter 9000, loss: 0.175136
 >> iter 10000, loss: 0.180603
   Number of active neurons: 10
 >> iter 11000, loss: 0.082166
 >> iter 12000, loss: 0.039993
 >> iter 13000, loss: 0.194325
 >> iter 14000, loss: 0.080706
 >> iter 15000, loss: 0.148520
 >> iter 16000, loss: 0.098530
 >> iter 17000, loss: 0.083217
 >> iter 18000, loss: 0.038117
 >> iter 19000, loss: 0.106560
 >> iter 20000, loss: 0.060871
   Number of active neurons: 10
 >> iter 21000, loss: 0.085216
 >> iter 22000, loss: 0.036126
 >> iter 23000, loss: 0.017015
 >> iter 24000, loss: 0.009279
 >> iter 25000, loss: 0.009264
 >> iter 26000, loss: 0.006617
 >> iter 27000, loss: 0.004626
 >> iter 28000, loss: 0.004351
 >> iter 29000, loss: 0.087340
 >> iter 30000, loss: 0.039119
   Number of active neurons: 10
 >> iter 31000, loss: 0.016839
 >> iter 32000, loss: 0.082393
 >> iter 33000, loss: 0.036110
 >> iter 34000, loss: 0.065828
 >> iter 35000, loss: 0.131605
 >> iter 36000, loss: 0.058104
 >> iter 37000, loss: 0.160769
 >> iter 38000, loss: 0.065746
 >> iter 39000, loss: 0.027250
 >> iter 40000, loss: 0.013926
   Number of active neurons: 10
 >> iter 41000, loss: 0.025238
 >> iter 42000, loss: 0.013299
 >> iter 43000, loss: 0.006973
 >> iter 44000, loss: 0.004464
 >> iter 45000, loss: 0.003220
 >> iter 46000, loss: 0.084170
 >> iter 47000, loss: 0.092978
 >> iter 48000, loss: 0.036601
 >> iter 49000, loss: 0.015392
 >> iter 50000, loss: 0.014018
   Number of active neurons: 10
 >> iter 51000, loss: 0.006794
 >> iter 52000, loss: 0.004047
 >> iter 53000, loss: 0.002894
 >> iter 54000, loss: 0.002587
 >> iter 55000, loss: 0.017516
 >> iter 56000, loss: 0.016581
 >> iter 57000, loss: 0.015218
 >> iter 58000, loss: 0.007373
 >> iter 59000, loss: 0.003963
 >> iter 60000, loss: 0.022768
   Number of active neurons: 10
 >> iter 61000, loss: 0.050107
 >> iter 62000, loss: 0.022384
 >> iter 63000, loss: 0.010814
 >> iter 64000, loss: 0.094119
 >> iter 65000, loss: 0.036323
 >> iter 66000, loss: 0.015860
 >> iter 67000, loss: 0.007510
 >> iter 68000, loss: 0.003951
 >> iter 69000, loss: 0.002560
 >> iter 70000, loss: 0.002038
   Number of active neurons: 10
 >> iter 71000, loss: 0.001748
 >> iter 72000, loss: 0.003011
 >> iter 73000, loss: 0.014986
 >> iter 74000, loss: 0.006466
 >> iter 75000, loss: 0.003273
 >> iter 76000, loss: 0.002041
 >> iter 77000, loss: 0.065952
 >> iter 78000, loss: 0.025882
 >> iter 79000, loss: 0.010882
 >> iter 80000, loss: 0.072695
   Number of active neurons: 10
 >> iter 81000, loss: 0.028114
 >> iter 82000, loss: 0.011472
 >> iter 83000, loss: 0.005232
 >> iter 84000, loss: 0.002840
 >> iter 85000, loss: 0.003285
 >> iter 86000, loss: 0.002086
 >> iter 87000, loss: 0.014774
 >> iter 88000, loss: 0.006262
 >> iter 89000, loss: 0.003144
 >> iter 90000, loss: 0.002025
   Number of active neurons: 10
 >> iter 91000, loss: 0.001516
 >> iter 92000, loss: 0.001270
 >> iter 93000, loss: 0.001153
 >> iter 94000, loss: 0.001114
 >> iter 95000, loss: 0.008647
 >> iter 96000, loss: 0.003944
 >> iter 97000, loss: 0.002158
 >> iter 98000, loss: 0.001503
 >> iter 99000, loss: 0.001145
 >> iter 100000, loss: 0.001113
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.640565
 >> iter 2000, loss: 9.294473
 >> iter 3000, loss: 3.710082
 >> iter 4000, loss: 1.515886
 >> iter 5000, loss: 0.752414
 >> iter 6000, loss: 0.413362
 >> iter 7000, loss: 0.180809
 >> iter 8000, loss: 0.174493
 >> iter 9000, loss: 0.085858
 >> iter 10000, loss: 0.041116
   Number of active neurons: 10
 >> iter 11000, loss: 0.022207
 >> iter 12000, loss: 0.045628
 >> iter 13000, loss: 0.067547
 >> iter 14000, loss: 0.030610
 >> iter 15000, loss: 0.016018
 >> iter 16000, loss: 0.015091
 >> iter 17000, loss: 0.067378
 >> iter 18000, loss: 0.030413
 >> iter 19000, loss: 0.028946
 >> iter 20000, loss: 0.014789
   Number of active neurons: 10
 >> iter 21000, loss: 0.009171
 >> iter 22000, loss: 0.007330
 >> iter 23000, loss: 0.012041
 >> iter 24000, loss: 0.056997
 >> iter 25000, loss: 0.076019
 >> iter 26000, loss: 0.036207
 >> iter 27000, loss: 0.015777
 >> iter 28000, loss: 0.008185
 >> iter 29000, loss: 0.005312
 >> iter 30000, loss: 0.004252
   Number of active neurons: 10
 >> iter 31000, loss: 0.003462
 >> iter 32000, loss: 0.006841
 >> iter 33000, loss: 0.004476
 >> iter 34000, loss: 0.003399
 >> iter 35000, loss: 0.003064
 >> iter 36000, loss: 0.002718
 >> iter 37000, loss: 0.005161
 >> iter 38000, loss: 0.054952
 >> iter 39000, loss: 0.036820
 >> iter 40000, loss: 0.017451
   Number of active neurons: 10
 >> iter 41000, loss: 0.033784
 >> iter 42000, loss: 0.031888
 >> iter 43000, loss: 0.032109
 >> iter 44000, loss: 0.013530
 >> iter 45000, loss: 0.017335
 >> iter 46000, loss: 0.007932
 >> iter 47000, loss: 0.014717
 >> iter 48000, loss: 0.084172
 >> iter 49000, loss: 0.036309
 >> iter 50000, loss: 0.015450
   Number of active neurons: 10
 >> iter 51000, loss: 0.010404
 >> iter 52000, loss: 0.005456
 >> iter 53000, loss: 0.003491
 >> iter 54000, loss: 0.002785
 >> iter 55000, loss: 0.002671
 >> iter 56000, loss: 0.064605
 >> iter 57000, loss: 0.026042
 >> iter 58000, loss: 0.136358
 >> iter 59000, loss: 0.058209
 >> iter 60000, loss: 0.023485
   Number of active neurons: 10
 >> iter 61000, loss: 0.010337
 >> iter 62000, loss: 0.005408
 >> iter 63000, loss: 0.003357
 >> iter 64000, loss: 0.002533
 >> iter 65000, loss: 0.002544
 >> iter 66000, loss: 0.002160
 >> iter 67000, loss: 0.002109
 >> iter 68000, loss: 0.002658
 >> iter 69000, loss: 0.002517
 >> iter 70000, loss: 0.002786
   Number of active neurons: 10
 >> iter 71000, loss: 0.002176
 >> iter 72000, loss: 0.071766
 >> iter 73000, loss: 0.027996
 >> iter 74000, loss: 0.014605
 >> iter 75000, loss: 0.006639
 >> iter 76000, loss: 0.003473
 >> iter 77000, loss: 0.002653
 >> iter 78000, loss: 0.002226
 >> iter 79000, loss: 0.001696
 >> iter 80000, loss: 0.001470
   Number of active neurons: 10
 >> iter 81000, loss: 0.001352
 >> iter 82000, loss: 0.001253
 >> iter 83000, loss: 0.001322
 >> iter 84000, loss: 0.001161
 >> iter 85000, loss: 0.041440
 >> iter 86000, loss: 0.016262
 >> iter 87000, loss: 0.006841
 >> iter 88000, loss: 0.003308
 >> iter 89000, loss: 0.002121
 >> iter 90000, loss: 0.001499
   Number of active neurons: 10
 >> iter 91000, loss: 0.001262
 >> iter 92000, loss: 0.001212
 >> iter 93000, loss: 0.020204
 >> iter 94000, loss: 0.008170
 >> iter 95000, loss: 0.003765
 >> iter 96000, loss: 0.002096
 >> iter 97000, loss: 0.001427
 >> iter 98000, loss: 0.001261
 >> iter 99000, loss: 0.001113
 >> iter 100000, loss: 0.001043
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.155413
 >> iter 2000, loss: 9.601230
 >> iter 3000, loss: 3.743565
 >> iter 4000, loss: 1.429602
 >> iter 5000, loss: 0.547156
 >> iter 6000, loss: 0.247098
 >> iter 7000, loss: 0.307025
 >> iter 8000, loss: 0.125829
 >> iter 9000, loss: 0.060193
 >> iter 10000, loss: 0.035903
   Number of active neurons: 10
 >> iter 11000, loss: 0.019585
 >> iter 12000, loss: 0.012407
 >> iter 13000, loss: 0.011363
 >> iter 14000, loss: 0.008468
 >> iter 15000, loss: 0.007149
 >> iter 16000, loss: 0.006424
 >> iter 17000, loss: 0.005468
 >> iter 18000, loss: 0.008408
 >> iter 19000, loss: 0.020217
 >> iter 20000, loss: 0.011726
   Number of active neurons: 10
 >> iter 21000, loss: 0.027286
 >> iter 22000, loss: 0.012629
 >> iter 23000, loss: 0.007534
 >> iter 24000, loss: 0.030038
 >> iter 25000, loss: 0.069392
 >> iter 26000, loss: 0.028269
 >> iter 27000, loss: 0.012786
 >> iter 28000, loss: 0.006910
 >> iter 29000, loss: 0.004686
 >> iter 30000, loss: 0.003531
   Number of active neurons: 10
 >> iter 31000, loss: 0.003093
 >> iter 32000, loss: 0.003057
 >> iter 33000, loss: 0.002727
 >> iter 34000, loss: 0.002473
 >> iter 35000, loss: 0.047695
 >> iter 36000, loss: 0.030300
 >> iter 37000, loss: 0.061812
 >> iter 38000, loss: 0.025570
 >> iter 39000, loss: 0.012386
 >> iter 40000, loss: 0.006594
   Number of active neurons: 10
 >> iter 41000, loss: 0.004004
 >> iter 42000, loss: 0.192700
 >> iter 43000, loss: 0.076118
 >> iter 44000, loss: 0.090338
 >> iter 45000, loss: 0.035811
 >> iter 46000, loss: 0.015325
 >> iter 47000, loss: 0.007868
 >> iter 48000, loss: 0.004718
 >> iter 49000, loss: 0.003524
 >> iter 50000, loss: 0.002844
   Number of active neurons: 10
 >> iter 51000, loss: 0.002590
 >> iter 52000, loss: 0.002445
 >> iter 53000, loss: 0.002210
 >> iter 54000, loss: 0.002016
 >> iter 55000, loss: 0.002424
 >> iter 56000, loss: 0.002204
 >> iter 57000, loss: 0.002039
 >> iter 58000, loss: 0.002134
 >> iter 59000, loss: 0.001902
 >> iter 60000, loss: 0.001747
   Number of active neurons: 10
 >> iter 61000, loss: 0.001633
 >> iter 62000, loss: 0.001536
 >> iter 63000, loss: 0.001563
 >> iter 64000, loss: 0.001459
 >> iter 65000, loss: 0.001438
 >> iter 66000, loss: 0.001453
 >> iter 67000, loss: 0.001318
 >> iter 68000, loss: 0.001330
 >> iter 69000, loss: 0.001249
 >> iter 70000, loss: 0.001354
   Number of active neurons: 10
 >> iter 71000, loss: 0.001279
 >> iter 72000, loss: 0.001212
 >> iter 73000, loss: 0.001189
 >> iter 74000, loss: 0.001193
 >> iter 75000, loss: 0.001154
 >> iter 76000, loss: 0.001105
 >> iter 77000, loss: 0.001060
 >> iter 78000, loss: 0.001065
 >> iter 79000, loss: 0.001005
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.718964
 >> iter 2000, loss: 9.433784
 >> iter 3000, loss: 3.887656
 >> iter 4000, loss: 1.641008
 >> iter 5000, loss: 0.789654
 >> iter 6000, loss: 0.322841
 >> iter 7000, loss: 0.145833
 >> iter 8000, loss: 0.286552
 >> iter 9000, loss: 0.227164
 >> iter 10000, loss: 0.094739
   Number of active neurons: 10
 >> iter 11000, loss: 0.266294
 >> iter 12000, loss: 0.118450
 >> iter 13000, loss: 0.053623
 >> iter 14000, loss: 0.045410
 >> iter 15000, loss: 0.096990
 >> iter 16000, loss: 0.130907
 >> iter 17000, loss: 0.060605
 >> iter 18000, loss: 0.027428
 >> iter 19000, loss: 0.017573
 >> iter 20000, loss: 0.012606
   Number of active neurons: 10
 >> iter 21000, loss: 0.008731
 >> iter 22000, loss: 0.027008
 >> iter 23000, loss: 0.021615
 >> iter 24000, loss: 0.011212
 >> iter 25000, loss: 0.006702
 >> iter 26000, loss: 0.004932
 >> iter 27000, loss: 0.004193
 >> iter 28000, loss: 0.003888
 >> iter 29000, loss: 0.004322
 >> iter 30000, loss: 0.003745
   Number of active neurons: 10
 >> iter 31000, loss: 0.013209
 >> iter 32000, loss: 0.007987
 >> iter 33000, loss: 0.004706
 >> iter 34000, loss: 0.003549
 >> iter 35000, loss: 0.002903
 >> iter 36000, loss: 0.003607
 >> iter 37000, loss: 0.008924
 >> iter 38000, loss: 0.005053
 >> iter 39000, loss: 0.003247
 >> iter 40000, loss: 0.002470
   Number of active neurons: 10
 >> iter 41000, loss: 0.002152
 >> iter 42000, loss: 0.013878
 >> iter 43000, loss: 0.006612
 >> iter 44000, loss: 0.003718
 >> iter 45000, loss: 0.004839
 >> iter 46000, loss: 0.005712
 >> iter 47000, loss: 0.003305
 >> iter 48000, loss: 0.002349
 >> iter 49000, loss: 0.001876
 >> iter 50000, loss: 0.018687
   Number of active neurons: 10
 >> iter 51000, loss: 0.008227
 >> iter 52000, loss: 0.004236
 >> iter 53000, loss: 0.002596
 >> iter 54000, loss: 0.001966
 >> iter 55000, loss: 0.001840
 >> iter 56000, loss: 0.001784
 >> iter 57000, loss: 0.001620
 >> iter 58000, loss: 0.001473
 >> iter 59000, loss: 0.001700
 >> iter 60000, loss: 0.001786
   Number of active neurons: 10
 >> iter 61000, loss: 0.001509
 >> iter 62000, loss: 0.001317
 >> iter 63000, loss: 0.001536
 >> iter 64000, loss: 0.001404
 >> iter 65000, loss: 0.001266
 >> iter 66000, loss: 0.001196
 >> iter 67000, loss: 0.001118
 >> iter 68000, loss: 0.022685
 >> iter 69000, loss: 0.009385
 >> iter 70000, loss: 0.004918
   Number of active neurons: 10
 >> iter 71000, loss: 0.002476
 >> iter 72000, loss: 0.001554
 >> iter 73000, loss: 0.001671
 >> iter 74000, loss: 0.001326
 >> iter 75000, loss: 0.002611
 >> iter 76000, loss: 0.001726
 >> iter 77000, loss: 0.001296
 >> iter 78000, loss: 0.001084
 >> iter 79000, loss: 0.001215
 >> iter 80000, loss: 0.002266
   Number of active neurons: 10
 >> iter 81000, loss: 0.007142
 >> iter 82000, loss: 0.003401
 >> iter 83000, loss: 0.001887
 >> iter 84000, loss: 0.001313
 >> iter 85000, loss: 0.001107
 >> iter 86000, loss: 0.001363
 >> iter 87000, loss: 0.001344
 >> iter 88000, loss: 0.001011
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.849554
 >> iter 2000, loss: 9.632578
 >> iter 3000, loss: 3.888843
 >> iter 4000, loss: 1.605189
 >> iter 5000, loss: 0.623091
 >> iter 6000, loss: 0.247808
 >> iter 7000, loss: 0.103463
 >> iter 8000, loss: 0.049366
 >> iter 9000, loss: 0.127409
 >> iter 10000, loss: 0.054743
   Number of active neurons: 10
 >> iter 11000, loss: 0.050416
 >> iter 12000, loss: 0.074646
 >> iter 13000, loss: 0.033461
 >> iter 14000, loss: 0.016785
 >> iter 15000, loss: 0.011749
 >> iter 16000, loss: 0.008373
 >> iter 17000, loss: 0.024975
 >> iter 18000, loss: 0.012905
 >> iter 19000, loss: 0.007866
 >> iter 20000, loss: 0.007735
   Number of active neurons: 10
 >> iter 21000, loss: 0.012156
 >> iter 22000, loss: 0.072889
 >> iter 23000, loss: 0.030209
 >> iter 24000, loss: 0.013574
 >> iter 25000, loss: 0.007217
 >> iter 26000, loss: 0.005049
 >> iter 27000, loss: 0.004288
 >> iter 28000, loss: 0.003608
 >> iter 29000, loss: 0.003253
 >> iter 30000, loss: 0.002812
   Number of active neurons: 10
 >> iter 31000, loss: 0.002672
 >> iter 32000, loss: 0.002499
 >> iter 33000, loss: 0.002647
 >> iter 34000, loss: 0.002473
 >> iter 35000, loss: 0.002218
 >> iter 36000, loss: 0.002118
 >> iter 37000, loss: 0.002072
 >> iter 38000, loss: 0.001945
 >> iter 39000, loss: 0.001843
 >> iter 40000, loss: 0.001849
   Number of active neurons: 10
 >> iter 41000, loss: 0.001782
 >> iter 42000, loss: 0.001701
 >> iter 43000, loss: 0.001650
 >> iter 44000, loss: 0.001602
 >> iter 45000, loss: 0.001672
 >> iter 46000, loss: 0.001572
 >> iter 47000, loss: 0.001528
 >> iter 48000, loss: 0.001459
 >> iter 49000, loss: 0.001429
 >> iter 50000, loss: 0.001401
   Number of active neurons: 10
 >> iter 51000, loss: 0.001413
 >> iter 52000, loss: 0.003042
 >> iter 53000, loss: 0.001970
 >> iter 54000, loss: 0.001668
 >> iter 55000, loss: 0.001428
 >> iter 56000, loss: 0.001392
 >> iter 57000, loss: 0.001308
 >> iter 58000, loss: 0.001282
 >> iter 59000, loss: 0.001229
 >> iter 60000, loss: 0.001164
   Number of active neurons: 10
 >> iter 61000, loss: 0.001123
 >> iter 62000, loss: 0.001101
 >> iter 63000, loss: 0.001814
 >> iter 64000, loss: 0.001396
 >> iter 65000, loss: 0.001219
 >> iter 66000, loss: 0.002270
 >> iter 67000, loss: 0.001787
 >> iter 68000, loss: 0.001630
 >> iter 69000, loss: 0.107996
 >> iter 70000, loss: 0.040675
   Number of active neurons: 10
 >> iter 71000, loss: 0.015795
 >> iter 72000, loss: 0.006552
 >> iter 73000, loss: 0.003261
 >> iter 74000, loss: 0.001961
 >> iter 75000, loss: 0.001384
 >> iter 76000, loss: 0.001169
 >> iter 77000, loss: 0.001053
 >> iter 78000, loss: 0.001003
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.540670
 >> iter 2000, loss: 8.780254
 >> iter 3000, loss: 3.601653
 >> iter 4000, loss: 1.560314
 >> iter 5000, loss: 0.669476
 >> iter 6000, loss: 0.272581
 >> iter 7000, loss: 0.154065
 >> iter 8000, loss: 0.081367
 >> iter 9000, loss: 0.038820
 >> iter 10000, loss: 0.022117
   Number of active neurons: 10
 >> iter 11000, loss: 0.014712
 >> iter 12000, loss: 0.011791
 >> iter 13000, loss: 0.041021
 >> iter 14000, loss: 0.042711
 >> iter 15000, loss: 0.025493
 >> iter 16000, loss: 0.012966
 >> iter 17000, loss: 0.008469
 >> iter 18000, loss: 0.005769
 >> iter 19000, loss: 0.004986
 >> iter 20000, loss: 0.004829
   Number of active neurons: 10
 >> iter 21000, loss: 0.004044
 >> iter 22000, loss: 0.003498
 >> iter 23000, loss: 0.070795
 >> iter 24000, loss: 0.034862
 >> iter 25000, loss: 0.015132
 >> iter 26000, loss: 0.007733
 >> iter 27000, loss: 0.041454
 >> iter 28000, loss: 0.019230
 >> iter 29000, loss: 0.101919
 >> iter 30000, loss: 0.040895
   Number of active neurons: 10
 >> iter 31000, loss: 0.018019
 >> iter 32000, loss: 0.008705
 >> iter 33000, loss: 0.010638
 >> iter 34000, loss: 0.005458
 >> iter 35000, loss: 0.003411
 >> iter 36000, loss: 0.003530
 >> iter 37000, loss: 0.002751
 >> iter 38000, loss: 0.002505
 >> iter 39000, loss: 0.002726
 >> iter 40000, loss: 0.002557
   Number of active neurons: 10
 >> iter 41000, loss: 0.002117
 >> iter 42000, loss: 0.001858
 >> iter 43000, loss: 0.001737
 >> iter 44000, loss: 0.001608
 >> iter 45000, loss: 0.002381
 >> iter 46000, loss: 0.001989
 >> iter 47000, loss: 0.002110
 >> iter 48000, loss: 0.001789
 >> iter 49000, loss: 0.001555
 >> iter 50000, loss: 0.001662
   Number of active neurons: 10
 >> iter 51000, loss: 0.001504
 >> iter 52000, loss: 0.001379
 >> iter 53000, loss: 0.001434
 >> iter 54000, loss: 0.001393
 >> iter 55000, loss: 0.001317
 >> iter 56000, loss: 0.001349
 >> iter 57000, loss: 0.015266
 >> iter 58000, loss: 0.011697
 >> iter 59000, loss: 0.006938
 >> iter 60000, loss: 0.003626
   Number of active neurons: 10
 >> iter 61000, loss: 0.002061
 >> iter 62000, loss: 0.002052
 >> iter 63000, loss: 0.001634
 >> iter 64000, loss: 0.001365
 >> iter 65000, loss: 0.001132
 >> iter 66000, loss: 0.020737
 >> iter 67000, loss: 0.008818
 >> iter 68000, loss: 0.013594
 >> iter 69000, loss: 0.006097
 >> iter 70000, loss: 0.002995
   Number of active neurons: 10
 >> iter 71000, loss: 0.001757
 >> iter 72000, loss: 0.002531
 >> iter 73000, loss: 0.029182
 >> iter 74000, loss: 0.017889
 >> iter 75000, loss: 0.007526
 >> iter 76000, loss: 0.003540
 >> iter 77000, loss: 0.001997
 >> iter 78000, loss: 0.001399
 >> iter 79000, loss: 0.001144
 >> iter 80000, loss: 0.001024
   Number of active neurons: 10
 >> iter 81000, loss: 0.001112
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.378566
 >> iter 2000, loss: 8.905051
 >> iter 3000, loss: 3.635685
 >> iter 4000, loss: 1.426448
 >> iter 5000, loss: 0.657795
 >> iter 6000, loss: 0.296326
 >> iter 7000, loss: 0.171429
 >> iter 8000, loss: 0.078823
 >> iter 9000, loss: 0.065531
 >> iter 10000, loss: 0.091977
   Number of active neurons: 10
 >> iter 11000, loss: 0.073962
 >> iter 12000, loss: 0.108527
 >> iter 13000, loss: 0.047434
 >> iter 14000, loss: 0.036777
 >> iter 15000, loss: 0.023102
 >> iter 16000, loss: 0.037633
 >> iter 17000, loss: 0.018582
 >> iter 18000, loss: 0.010895
 >> iter 19000, loss: 0.017679
 >> iter 20000, loss: 0.012037
   Number of active neurons: 10
 >> iter 21000, loss: 0.007685
 >> iter 22000, loss: 0.006271
 >> iter 23000, loss: 0.005119
 >> iter 24000, loss: 0.004454
 >> iter 25000, loss: 0.004254
 >> iter 26000, loss: 0.004304
 >> iter 27000, loss: 0.015062
 >> iter 28000, loss: 0.018177
 >> iter 29000, loss: 0.018077
 >> iter 30000, loss: 0.010376
   Number of active neurons: 10
 >> iter 31000, loss: 0.006085
 >> iter 32000, loss: 0.004117
 >> iter 33000, loss: 0.003981
 >> iter 34000, loss: 0.003631
 >> iter 35000, loss: 0.003168
 >> iter 36000, loss: 0.003055
 >> iter 37000, loss: 0.002747
 >> iter 38000, loss: 0.006365
 >> iter 39000, loss: 0.025307
 >> iter 40000, loss: 0.011211
   Number of active neurons: 10
 >> iter 41000, loss: 0.005649
 >> iter 42000, loss: 0.003715
 >> iter 43000, loss: 0.002714
 >> iter 44000, loss: 0.018213
 >> iter 45000, loss: 0.008190
 >> iter 46000, loss: 0.005132
 >> iter 47000, loss: 0.003308
 >> iter 48000, loss: 0.002393
 >> iter 49000, loss: 0.002086
 >> iter 50000, loss: 0.002125
   Number of active neurons: 10
 >> iter 51000, loss: 0.001890
 >> iter 52000, loss: 0.001977
 >> iter 53000, loss: 0.001748
 >> iter 54000, loss: 0.001710
 >> iter 55000, loss: 0.001787
 >> iter 56000, loss: 0.001632
 >> iter 57000, loss: 0.001528
 >> iter 58000, loss: 0.001971
 >> iter 59000, loss: 0.003944
 >> iter 60000, loss: 0.002499
   Number of active neurons: 10
 >> iter 61000, loss: 0.002172
 >> iter 62000, loss: 0.001776
 >> iter 63000, loss: 0.001594
 >> iter 64000, loss: 0.001600
 >> iter 65000, loss: 0.018039
 >> iter 66000, loss: 0.007835
 >> iter 67000, loss: 0.004280
 >> iter 68000, loss: 0.002721
 >> iter 69000, loss: 0.012864
 >> iter 70000, loss: 0.005865
   Number of active neurons: 10
 >> iter 71000, loss: 0.003252
 >> iter 72000, loss: 0.002045
 >> iter 73000, loss: 0.001560
 >> iter 74000, loss: 0.001367
 >> iter 75000, loss: 0.001535
 >> iter 76000, loss: 0.062175
 >> iter 77000, loss: 0.024131
 >> iter 78000, loss: 0.009986
 >> iter 79000, loss: 0.004505
 >> iter 80000, loss: 0.002389
   Number of active neurons: 10
 >> iter 81000, loss: 0.001735
 >> iter 82000, loss: 0.001693
 >> iter 83000, loss: 0.001451
 >> iter 84000, loss: 0.001207
 >> iter 85000, loss: 0.001817
 >> iter 86000, loss: 0.048895
 >> iter 87000, loss: 0.019178
 >> iter 88000, loss: 0.008075
 >> iter 89000, loss: 0.005388
 >> iter 90000, loss: 0.005797
   Number of active neurons: 10
 >> iter 91000, loss: 0.002958
 >> iter 92000, loss: 0.001787
 >> iter 93000, loss: 0.001495
 >> iter 94000, loss: 0.001250
 >> iter 95000, loss: 0.001177
 >> iter 96000, loss: 0.001139
 >> iter 97000, loss: 0.001222
 >> iter 98000, loss: 0.001298
 >> iter 99000, loss: 0.001076
 >> iter 100000, loss: 0.001022
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.171428
 >> iter 2000, loss: 9.762262
 >> iter 3000, loss: 3.688236
 >> iter 4000, loss: 1.463323
 >> iter 5000, loss: 0.558641
 >> iter 6000, loss: 0.253920
 >> iter 7000, loss: 0.183510
 >> iter 8000, loss: 0.076809
 >> iter 9000, loss: 0.046730
 >> iter 10000, loss: 0.023785
   Number of active neurons: 10
 >> iter 11000, loss: 0.014682
 >> iter 12000, loss: 0.010134
 >> iter 13000, loss: 0.008084
 >> iter 14000, loss: 0.008839
 >> iter 15000, loss: 0.008156
 >> iter 16000, loss: 0.012615
 >> iter 17000, loss: 0.009946
 >> iter 18000, loss: 0.011136
 >> iter 19000, loss: 0.009536
 >> iter 20000, loss: 0.006640
   Number of active neurons: 10
 >> iter 21000, loss: 0.004788
 >> iter 22000, loss: 0.003984
 >> iter 23000, loss: 0.005000
 >> iter 24000, loss: 0.063477
 >> iter 25000, loss: 0.025998
 >> iter 26000, loss: 0.012363
 >> iter 27000, loss: 0.006458
 >> iter 28000, loss: 0.004115
 >> iter 29000, loss: 0.003182
 >> iter 30000, loss: 0.002821
   Number of active neurons: 10
 >> iter 31000, loss: 0.002551
 >> iter 32000, loss: 0.002454
 >> iter 33000, loss: 0.002289
 >> iter 34000, loss: 0.002386
 >> iter 35000, loss: 0.002261
 >> iter 36000, loss: 0.002041
 >> iter 37000, loss: 0.002056
 >> iter 38000, loss: 0.001890
 >> iter 39000, loss: 0.002077
 >> iter 40000, loss: 0.002002
   Number of active neurons: 10
 >> iter 41000, loss: 0.001804
 >> iter 42000, loss: 0.001663
 >> iter 43000, loss: 0.166361
 >> iter 44000, loss: 0.063163
 >> iter 45000, loss: 0.025288
 >> iter 46000, loss: 0.010700
 >> iter 47000, loss: 0.005464
 >> iter 48000, loss: 0.003201
 >> iter 49000, loss: 0.002459
 >> iter 50000, loss: 0.002075
   Number of active neurons: 10
 >> iter 51000, loss: 0.018331
 >> iter 52000, loss: 0.011915
 >> iter 53000, loss: 0.005692
 >> iter 54000, loss: 0.003073
 >> iter 55000, loss: 0.002118
 >> iter 56000, loss: 0.002057
 >> iter 57000, loss: 0.012396
 >> iter 58000, loss: 0.005590
 >> iter 59000, loss: 0.002984
 >> iter 60000, loss: 0.002024
   Number of active neurons: 10
 >> iter 61000, loss: 0.001631
 >> iter 62000, loss: 0.001441
 >> iter 63000, loss: 0.001575
 >> iter 64000, loss: 0.001406
 >> iter 65000, loss: 0.001308
 >> iter 66000, loss: 0.001654
 >> iter 67000, loss: 0.001381
 >> iter 68000, loss: 0.001264
 >> iter 69000, loss: 0.001217
 >> iter 70000, loss: 0.003696
   Number of active neurons: 10
 >> iter 71000, loss: 0.002121
 >> iter 72000, loss: 0.001654
 >> iter 73000, loss: 0.001381
 >> iter 74000, loss: 0.001183
 >> iter 75000, loss: 0.002603
 >> iter 76000, loss: 0.012691
 >> iter 77000, loss: 0.006162
 >> iter 78000, loss: 0.003141
 >> iter 79000, loss: 0.002635
 >> iter 80000, loss: 0.001693
   Number of active neurons: 10
 >> iter 81000, loss: 0.163135
 >> iter 82000, loss: 0.086094
 >> iter 83000, loss: 0.032788
 >> iter 84000, loss: 0.012996
 >> iter 85000, loss: 0.005711
 >> iter 86000, loss: 0.003001
 >> iter 87000, loss: 0.001978
 >> iter 88000, loss: 0.001681
 >> iter 89000, loss: 0.001409
 >> iter 90000, loss: 0.001989
   Number of active neurons: 10
 >> iter 91000, loss: 0.002270
 >> iter 92000, loss: 0.001594
 >> iter 93000, loss: 0.001328
 >> iter 94000, loss: 0.001313
 >> iter 95000, loss: 0.001168
 >> iter 96000, loss: 0.001647
 >> iter 97000, loss: 0.001504
 >> iter 98000, loss: 0.001240
 >> iter 99000, loss: 0.001407
 >> iter 100000, loss: 0.001295
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.895210
 >> iter 2000, loss: 10.407633
 >> iter 3000, loss: 4.575359
 >> iter 4000, loss: 1.875319
 >> iter 5000, loss: 1.168601
 >> iter 6000, loss: 0.529565
 >> iter 7000, loss: 0.300206
 >> iter 8000, loss: 0.131988
 >> iter 9000, loss: 0.063132
 >> iter 10000, loss: 0.034158
   Number of active neurons: 10
 >> iter 11000, loss: 0.065273
 >> iter 12000, loss: 0.101815
 >> iter 13000, loss: 0.072180
 >> iter 14000, loss: 0.031171
 >> iter 15000, loss: 0.015427
 >> iter 16000, loss: 0.010323
 >> iter 17000, loss: 0.006667
 >> iter 18000, loss: 0.004892
 >> iter 19000, loss: 0.048989
 >> iter 20000, loss: 0.021022
   Number of active neurons: 10
 >> iter 21000, loss: 0.009836
 >> iter 22000, loss: 0.191021
 >> iter 23000, loss: 0.081415
 >> iter 24000, loss: 0.037217
 >> iter 25000, loss: 0.016578
 >> iter 26000, loss: 0.008229
 >> iter 27000, loss: 0.004857
 >> iter 28000, loss: 0.003497
 >> iter 29000, loss: 0.003746
 >> iter 30000, loss: 0.006071
   Number of active neurons: 10
 >> iter 31000, loss: 0.003756
 >> iter 32000, loss: 0.002695
 >> iter 33000, loss: 0.003971
 >> iter 34000, loss: 0.004455
 >> iter 35000, loss: 0.002741
 >> iter 36000, loss: 0.002422
 >> iter 37000, loss: 0.003003
 >> iter 38000, loss: 0.002397
 >> iter 39000, loss: 0.001822
 >> iter 40000, loss: 0.001931
   Number of active neurons: 10
 >> iter 41000, loss: 0.001571
 >> iter 42000, loss: 0.009014
 >> iter 43000, loss: 0.012712
 >> iter 44000, loss: 0.005751
 >> iter 45000, loss: 0.047928
 >> iter 46000, loss: 0.020438
 >> iter 47000, loss: 0.028126
 >> iter 48000, loss: 0.020790
 >> iter 49000, loss: 0.061903
 >> iter 50000, loss: 0.025452
   Number of active neurons: 10
 >> iter 51000, loss: 0.010430
 >> iter 52000, loss: 0.005009
 >> iter 53000, loss: 0.002741
 >> iter 54000, loss: 0.049376
 >> iter 55000, loss: 0.081136
 >> iter 56000, loss: 0.031625
 >> iter 57000, loss: 0.013005
 >> iter 58000, loss: 0.006062
 >> iter 59000, loss: 0.009045
 >> iter 60000, loss: 0.050203
   Number of active neurons: 10
 >> iter 61000, loss: 0.020668
 >> iter 62000, loss: 0.009326
 >> iter 63000, loss: 0.006784
 >> iter 64000, loss: 0.059776
 >> iter 65000, loss: 0.023516
 >> iter 66000, loss: 0.010313
 >> iter 67000, loss: 0.004954
 >> iter 68000, loss: 0.003113
 >> iter 69000, loss: 0.022384
 >> iter 70000, loss: 0.009331
   Number of active neurons: 10
 >> iter 71000, loss: 0.004399
 >> iter 72000, loss: 0.002707
 >> iter 73000, loss: 0.011087
 >> iter 74000, loss: 0.116215
 >> iter 75000, loss: 0.044327
 >> iter 76000, loss: 0.103348
 >> iter 77000, loss: 0.040074
 >> iter 78000, loss: 0.017527
 >> iter 79000, loss: 0.033356
 >> iter 80000, loss: 0.013985
   Number of active neurons: 10
 >> iter 81000, loss: 0.006701
 >> iter 82000, loss: 0.003580
 >> iter 83000, loss: 0.003790
 >> iter 84000, loss: 0.002431
 >> iter 85000, loss: 0.002095
 >> iter 86000, loss: 0.001624
 >> iter 87000, loss: 0.008126
 >> iter 88000, loss: 0.003940
 >> iter 89000, loss: 0.002209
 >> iter 90000, loss: 0.070563
   Number of active neurons: 10
 >> iter 91000, loss: 0.027776
 >> iter 92000, loss: 0.011274
 >> iter 93000, loss: 0.011135
 >> iter 94000, loss: 0.008651
 >> iter 95000, loss: 0.004153
 >> iter 96000, loss: 0.002447
 >> iter 97000, loss: 0.001687
 >> iter 98000, loss: 0.001579
 >> iter 99000, loss: 0.006835
 >> iter 100000, loss: 0.003219
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.889370
 >> iter 2000, loss: 8.684764
 >> iter 3000, loss: 3.395526
 >> iter 4000, loss: 1.307168
 >> iter 5000, loss: 0.540369
 >> iter 6000, loss: 0.216749
 >> iter 7000, loss: 0.087800
 >> iter 8000, loss: 0.066559
 >> iter 9000, loss: 0.039814
 >> iter 10000, loss: 0.042314
   Number of active neurons: 10
 >> iter 11000, loss: 0.036417
 >> iter 12000, loss: 0.020216
 >> iter 13000, loss: 0.010791
 >> iter 14000, loss: 0.052206
 >> iter 15000, loss: 0.022453
 >> iter 16000, loss: 0.011919
 >> iter 17000, loss: 0.014766
 >> iter 18000, loss: 0.059687
 >> iter 19000, loss: 0.025049
 >> iter 20000, loss: 0.011828
   Number of active neurons: 10
 >> iter 21000, loss: 0.006627
 >> iter 22000, loss: 0.004907
 >> iter 23000, loss: 0.003864
 >> iter 24000, loss: 0.004403
 >> iter 25000, loss: 0.004196
 >> iter 26000, loss: 0.006911
 >> iter 27000, loss: 0.004627
 >> iter 28000, loss: 0.003379
 >> iter 29000, loss: 0.002716
 >> iter 30000, loss: 0.005349
   Number of active neurons: 10
 >> iter 31000, loss: 0.003246
 >> iter 32000, loss: 0.072142
 >> iter 33000, loss: 0.028752
 >> iter 34000, loss: 0.012051
 >> iter 35000, loss: 0.005680
 >> iter 36000, loss: 0.003301
 >> iter 37000, loss: 0.005208
 >> iter 38000, loss: 0.003345
 >> iter 39000, loss: 0.002493
 >> iter 40000, loss: 0.001977
   Number of active neurons: 10
 >> iter 41000, loss: 0.001704
 >> iter 42000, loss: 0.001585
 >> iter 43000, loss: 0.001514
 >> iter 44000, loss: 0.001329
 >> iter 45000, loss: 0.001416
 >> iter 46000, loss: 0.001307
 >> iter 47000, loss: 0.001259
 >> iter 48000, loss: 0.001280
 >> iter 49000, loss: 0.001329
 >> iter 50000, loss: 0.001210
   Number of active neurons: 10
 >> iter 51000, loss: 0.001170
 >> iter 52000, loss: 0.001179
 >> iter 53000, loss: 0.001191
 >> iter 54000, loss: 0.001130
 >> iter 55000, loss: 0.001029
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.847646
 >> iter 2000, loss: 9.158765
 >> iter 3000, loss: 3.455223
 >> iter 4000, loss: 1.312153
 >> iter 5000, loss: 0.583996
 >> iter 6000, loss: 0.241766
 >> iter 7000, loss: 0.123539
 >> iter 8000, loss: 0.069792
 >> iter 9000, loss: 0.033385
 >> iter 10000, loss: 0.038562
   Number of active neurons: 10
 >> iter 11000, loss: 0.022529
 >> iter 12000, loss: 0.022334
 >> iter 13000, loss: 0.079432
 >> iter 14000, loss: 0.045297
 >> iter 15000, loss: 0.022337
 >> iter 16000, loss: 0.011796
 >> iter 17000, loss: 0.009693
 >> iter 18000, loss: 0.006390
 >> iter 19000, loss: 0.011432
 >> iter 20000, loss: 0.007023
   Number of active neurons: 10
 >> iter 21000, loss: 0.005066
 >> iter 22000, loss: 0.004557
 >> iter 23000, loss: 0.003760
 >> iter 24000, loss: 0.003367
 >> iter 25000, loss: 0.003066
 >> iter 26000, loss: 0.002960
 >> iter 27000, loss: 0.002762
 >> iter 28000, loss: 0.081808
 >> iter 29000, loss: 0.032149
 >> iter 30000, loss: 0.013594
   Number of active neurons: 10
 >> iter 31000, loss: 0.006847
 >> iter 32000, loss: 0.004019
 >> iter 33000, loss: 0.002819
 >> iter 34000, loss: 0.002300
 >> iter 35000, loss: 0.002061
 >> iter 36000, loss: 0.004171
 >> iter 37000, loss: 0.002832
 >> iter 38000, loss: 0.002665
 >> iter 39000, loss: 0.002171
 >> iter 40000, loss: 0.003934
   Number of active neurons: 10
 >> iter 41000, loss: 0.002926
 >> iter 42000, loss: 0.002159
 >> iter 43000, loss: 0.001793
 >> iter 44000, loss: 0.001634
 >> iter 45000, loss: 0.001447
 >> iter 46000, loss: 0.001382
 >> iter 47000, loss: 0.001391
 >> iter 48000, loss: 0.001302
 >> iter 49000, loss: 0.001362
 >> iter 50000, loss: 0.001323
   Number of active neurons: 10
 >> iter 51000, loss: 0.001522
 >> iter 52000, loss: 0.011826
 >> iter 53000, loss: 0.005336
 >> iter 54000, loss: 0.002850
 >> iter 55000, loss: 0.045323
 >> iter 56000, loss: 0.018758
 >> iter 57000, loss: 0.008356
 >> iter 58000, loss: 0.004302
 >> iter 59000, loss: 0.002451
 >> iter 60000, loss: 0.001839
   Number of active neurons: 10
 >> iter 61000, loss: 0.001465
 >> iter 62000, loss: 0.001479
 >> iter 63000, loss: 0.001187
 >> iter 64000, loss: 0.001039
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

