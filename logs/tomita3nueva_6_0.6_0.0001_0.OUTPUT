 > Problema: tomita3nueva
 > Args:
   - Hidden size: 6
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.326879
 >> iter 2000, loss: 14.805535
 >> iter 3000, loss: 11.221412
 >> iter 4000, loss: 7.370555
 >> iter 5000, loss: 4.459574
 >> iter 6000, loss: 2.178480
 >> iter 7000, loss: 1.068577
 >> iter 8000, loss: 0.707863
 >> iter 9000, loss: 0.669682
 >> iter 10000, loss: 0.438852
   Number of active neurons: 6
 >> iter 11000, loss: 0.412368
 >> iter 12000, loss: 0.257380
 >> iter 13000, loss: 0.284351
 >> iter 14000, loss: 0.284825
 >> iter 15000, loss: 0.281368
 >> iter 16000, loss: 0.210239
 >> iter 17000, loss: 0.573117
 >> iter 18000, loss: 0.590920
 >> iter 19000, loss: 0.437200
 >> iter 20000, loss: 0.457442
   Number of active neurons: 6
 >> iter 21000, loss: 0.354816
 >> iter 22000, loss: 0.269246
 >> iter 23000, loss: 0.323516
 >> iter 24000, loss: 0.426621
 >> iter 25000, loss: 0.428741
 >> iter 26000, loss: 0.299535
 >> iter 27000, loss: 0.294066
 >> iter 28000, loss: 0.197428
 >> iter 29000, loss: 0.233871
 >> iter 30000, loss: 0.288705
   Number of active neurons: 6
 >> iter 31000, loss: 0.348874
 >> iter 32000, loss: 0.302267
 >> iter 33000, loss: 0.318293
 >> iter 34000, loss: 0.295687
 >> iter 35000, loss: 0.230074
 >> iter 36000, loss: 0.232152
 >> iter 37000, loss: 0.263182
 >> iter 38000, loss: 0.319621
 >> iter 39000, loss: 0.235396
 >> iter 40000, loss: 0.398048
   Number of active neurons: 6
 >> iter 41000, loss: 0.433892
 >> iter 42000, loss: 0.307356
 >> iter 43000, loss: 0.315965
 >> iter 44000, loss: 0.206892
 >> iter 45000, loss: 0.194600
 >> iter 46000, loss: 0.145054
 >> iter 47000, loss: 0.174674
 >> iter 48000, loss: 0.472767
 >> iter 49000, loss: 0.282204
 >> iter 50000, loss: 0.446320
   Number of active neurons: 6
 >> iter 51000, loss: 0.383750
 >> iter 52000, loss: 0.276002
 >> iter 53000, loss: 0.267516
 >> iter 54000, loss: 0.314614
 >> iter 55000, loss: 0.218241
 >> iter 56000, loss: 0.188488
 >> iter 57000, loss: 0.265277
 >> iter 58000, loss: 0.229015
 >> iter 59000, loss: 0.279882
 >> iter 60000, loss: 0.199490
   Number of active neurons: 6
 >> iter 61000, loss: 0.487000
 >> iter 62000, loss: 0.375810
 >> iter 63000, loss: 0.390133
 >> iter 64000, loss: 0.298312
 >> iter 65000, loss: 0.480785
 >> iter 66000, loss: 0.489257
 >> iter 67000, loss: 0.380965
 >> iter 68000, loss: 0.288698
 >> iter 69000, loss: 0.225975
 >> iter 70000, loss: 0.176777
   Number of active neurons: 6
 >> iter 71000, loss: 0.203229
 >> iter 72000, loss: 0.222638
 >> iter 73000, loss: 0.340498
 >> iter 74000, loss: 0.447136
 >> iter 75000, loss: 0.340672
 >> iter 76000, loss: 0.287676
 >> iter 77000, loss: 0.292377
 >> iter 78000, loss: 0.203176
 >> iter 79000, loss: 0.393862
 >> iter 80000, loss: 0.328537
   Number of active neurons: 6
 >> iter 81000, loss: 0.374448
 >> iter 82000, loss: 0.460195
 >> iter 83000, loss: 0.307561
 >> iter 84000, loss: 0.196879
 >> iter 85000, loss: 0.167077
 >> iter 86000, loss: 0.208050
 >> iter 87000, loss: 0.163042
 >> iter 88000, loss: 0.135324
 >> iter 89000, loss: 0.218636
 >> iter 90000, loss: 0.276465
   Number of active neurons: 6
 >> iter 91000, loss: 0.268398
 >> iter 92000, loss: 0.357250
 >> iter 93000, loss: 0.302211
 >> iter 94000, loss: 0.174500
 >> iter 95000, loss: 0.192329
 >> iter 96000, loss: 0.289840
 >> iter 97000, loss: 0.231519
 >> iter 98000, loss: 0.144821
 >> iter 99000, loss: 0.469899
 >> iter 100000, loss: 0.333623
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.017609
 >> iter 2000, loss: 12.912496
 >> iter 3000, loss: 6.982893
 >> iter 4000, loss: 3.476067
 >> iter 5000, loss: 1.972471
 >> iter 6000, loss: 1.196934
 >> iter 7000, loss: 0.652162
 >> iter 8000, loss: 0.578475
 >> iter 9000, loss: 0.602076
 >> iter 10000, loss: 0.564814
   Number of active neurons: 5
 >> iter 11000, loss: 0.543753
 >> iter 12000, loss: 0.645849
 >> iter 13000, loss: 0.599405
 >> iter 14000, loss: 0.432964
 >> iter 15000, loss: 0.414688
 >> iter 16000, loss: 0.461775
 >> iter 17000, loss: 0.621040
 >> iter 18000, loss: 0.424941
 >> iter 19000, loss: 0.246689
 >> iter 20000, loss: 0.268548
   Number of active neurons: 5
 >> iter 21000, loss: 0.307262
 >> iter 22000, loss: 0.257303
 >> iter 23000, loss: 0.191635
 >> iter 24000, loss: 0.203857
 >> iter 25000, loss: 0.354815
 >> iter 26000, loss: 0.233687
 >> iter 27000, loss: 0.327726
 >> iter 28000, loss: 0.393072
 >> iter 29000, loss: 0.380250
 >> iter 30000, loss: 0.448477
   Number of active neurons: 5
 >> iter 31000, loss: 0.271304
 >> iter 32000, loss: 0.239398
 >> iter 33000, loss: 0.407815
 >> iter 34000, loss: 0.270810
 >> iter 35000, loss: 0.212062
 >> iter 36000, loss: 0.278321
 >> iter 37000, loss: 0.335703
 >> iter 38000, loss: 0.325824
 >> iter 39000, loss: 0.281355
 >> iter 40000, loss: 0.220627
   Number of active neurons: 4
 >> iter 41000, loss: 0.293154
 >> iter 42000, loss: 0.246768
 >> iter 43000, loss: 0.355304
 >> iter 44000, loss: 0.506818
 >> iter 45000, loss: 0.307766
 >> iter 46000, loss: 0.367668
 >> iter 47000, loss: 0.282960
 >> iter 48000, loss: 0.337924
 >> iter 49000, loss: 0.437260
 >> iter 50000, loss: 0.284125
   Number of active neurons: 4
 >> iter 51000, loss: 0.384076
 >> iter 52000, loss: 0.692843
 >> iter 53000, loss: 0.492069
 >> iter 54000, loss: 0.400716
 >> iter 55000, loss: 0.258871
 >> iter 56000, loss: 0.289948
 >> iter 57000, loss: 0.246210
 >> iter 58000, loss: 0.250358
 >> iter 59000, loss: 0.263517
 >> iter 60000, loss: 0.205685
   Number of active neurons: 4
 >> iter 61000, loss: 0.160304
 >> iter 62000, loss: 0.247613
 >> iter 63000, loss: 0.245625
 >> iter 64000, loss: 0.206198
 >> iter 65000, loss: 0.143184
 >> iter 66000, loss: 0.209553
 >> iter 67000, loss: 0.186117
 >> iter 68000, loss: 0.126487
 >> iter 69000, loss: 0.141503
 >> iter 70000, loss: 0.135089
   Number of active neurons: 4
 >> iter 71000, loss: 0.448478
 >> iter 72000, loss: 0.357710
 >> iter 73000, loss: 0.207010
 >> iter 74000, loss: 0.249332
 >> iter 75000, loss: 0.212018
 >> iter 76000, loss: 0.161535
 >> iter 77000, loss: 0.119458
 >> iter 78000, loss: 0.158038
 >> iter 79000, loss: 0.235466
 >> iter 80000, loss: 0.303848
   Number of active neurons: 4
 >> iter 81000, loss: 0.254372
 >> iter 82000, loss: 0.347235
 >> iter 83000, loss: 0.267823
 >> iter 84000, loss: 0.153948
 >> iter 85000, loss: 0.182987
 >> iter 86000, loss: 0.183648
 >> iter 87000, loss: 0.153579
 >> iter 88000, loss: 0.312986
 >> iter 89000, loss: 0.416325
 >> iter 90000, loss: 0.240391
   Number of active neurons: 4
 >> iter 91000, loss: 0.274010
 >> iter 92000, loss: 0.257227
 >> iter 93000, loss: 0.217549
 >> iter 94000, loss: 0.224365
 >> iter 95000, loss: 0.233956
 >> iter 96000, loss: 0.223514
 >> iter 97000, loss: 0.190075
 >> iter 98000, loss: 0.198439
 >> iter 99000, loss: 0.246419
 >> iter 100000, loss: 0.275513
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.253788
 >> iter 2000, loss: 13.908200
 >> iter 3000, loss: 9.670224
 >> iter 4000, loss: 6.208315
 >> iter 5000, loss: 4.151959
 >> iter 6000, loss: 3.226214
 >> iter 7000, loss: 1.972329
 >> iter 8000, loss: 1.416663
 >> iter 9000, loss: 1.374129
 >> iter 10000, loss: 1.210597
   Number of active neurons: 6
 >> iter 11000, loss: 1.131471
 >> iter 12000, loss: 0.983031
 >> iter 13000, loss: 1.126728
 >> iter 14000, loss: 0.801049
 >> iter 15000, loss: 0.712669
 >> iter 16000, loss: 0.864840
 >> iter 17000, loss: 1.291486
 >> iter 18000, loss: 1.311912
 >> iter 19000, loss: 0.995994
 >> iter 20000, loss: 0.684624
   Number of active neurons: 6
 >> iter 21000, loss: 0.622139
 >> iter 22000, loss: 0.605798
 >> iter 23000, loss: 0.670651
 >> iter 24000, loss: 0.688199
 >> iter 25000, loss: 0.723085
 >> iter 26000, loss: 0.681159
 >> iter 27000, loss: 0.824731
 >> iter 28000, loss: 0.814739
 >> iter 29000, loss: 0.642799
 >> iter 30000, loss: 0.877977
   Number of active neurons: 6
 >> iter 31000, loss: 1.142878
 >> iter 32000, loss: 0.844970
 >> iter 33000, loss: 0.717181
 >> iter 34000, loss: 0.742091
 >> iter 35000, loss: 0.689131
 >> iter 36000, loss: 0.603006
 >> iter 37000, loss: 0.662348
 >> iter 38000, loss: 1.003607
 >> iter 39000, loss: 1.068054
 >> iter 40000, loss: 0.802241
   Number of active neurons: 6
 >> iter 41000, loss: 0.626917
 >> iter 42000, loss: 0.701653
 >> iter 43000, loss: 0.613367
 >> iter 44000, loss: 0.533955
 >> iter 45000, loss: 0.844907
 >> iter 46000, loss: 0.721669
 >> iter 47000, loss: 0.812257
 >> iter 48000, loss: 0.744754
 >> iter 49000, loss: 0.515861
 >> iter 50000, loss: 0.843816
   Number of active neurons: 6
 >> iter 51000, loss: 0.554674
 >> iter 52000, loss: 0.642474
 >> iter 53000, loss: 0.859619
 >> iter 54000, loss: 0.779982
 >> iter 55000, loss: 0.583744
 >> iter 56000, loss: 0.608609
 >> iter 57000, loss: 0.499214
 >> iter 58000, loss: 0.485844
 >> iter 59000, loss: 0.700784
 >> iter 60000, loss: 0.678977
   Number of active neurons: 6
 >> iter 61000, loss: 0.644868
 >> iter 62000, loss: 0.636005
 >> iter 63000, loss: 0.734394
 >> iter 64000, loss: 0.606986
 >> iter 65000, loss: 0.549781
 >> iter 66000, loss: 0.555155
 >> iter 67000, loss: 0.541415
 >> iter 68000, loss: 0.570586
 >> iter 69000, loss: 0.440390
 >> iter 70000, loss: 0.648944
   Number of active neurons: 6
 >> iter 71000, loss: 0.569497
 >> iter 72000, loss: 0.538935
 >> iter 73000, loss: 0.572322
 >> iter 74000, loss: 0.628733
 >> iter 75000, loss: 0.750608
 >> iter 76000, loss: 0.657888
 >> iter 77000, loss: 0.509000
 >> iter 78000, loss: 0.547141
 >> iter 79000, loss: 0.674695
 >> iter 80000, loss: 0.620658
   Number of active neurons: 6
 >> iter 81000, loss: 0.651007
 >> iter 82000, loss: 0.555238
 >> iter 83000, loss: 0.570967
 >> iter 84000, loss: 0.543593
 >> iter 85000, loss: 0.529579
 >> iter 86000, loss: 0.490593
 >> iter 87000, loss: 0.569190
 >> iter 88000, loss: 0.578738
 >> iter 89000, loss: 0.549937
 >> iter 90000, loss: 0.623790
   Number of active neurons: 6
 >> iter 91000, loss: 0.643113
 >> iter 92000, loss: 0.659955
 >> iter 93000, loss: 0.631548
 >> iter 94000, loss: 0.630743
 >> iter 95000, loss: 0.532995
 >> iter 96000, loss: 0.533470
 >> iter 97000, loss: 0.479366
 >> iter 98000, loss: 0.487137
 >> iter 99000, loss: 0.640736
 >> iter 100000, loss: 0.659307
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.497463
 >> iter 2000, loss: 14.518559
 >> iter 3000, loss: 9.146076
 >> iter 4000, loss: 4.892971
 >> iter 5000, loss: 2.710323
 >> iter 6000, loss: 1.546565
 >> iter 7000, loss: 1.453160
 >> iter 8000, loss: 0.824642
 >> iter 9000, loss: 0.475739
 >> iter 10000, loss: 0.765635
   Number of active neurons: 5
 >> iter 11000, loss: 0.446720
 >> iter 12000, loss: 0.476784
 >> iter 13000, loss: 0.522798
 >> iter 14000, loss: 0.480382
 >> iter 15000, loss: 0.454652
 >> iter 16000, loss: 0.488062
 >> iter 17000, loss: 0.301701
 >> iter 18000, loss: 0.393282
 >> iter 19000, loss: 0.472510
 >> iter 20000, loss: 0.522930
   Number of active neurons: 5
 >> iter 21000, loss: 0.552526
 >> iter 22000, loss: 0.571292
 >> iter 23000, loss: 0.400659
 >> iter 24000, loss: 0.319565
 >> iter 25000, loss: 0.542055
 >> iter 26000, loss: 0.447665
 >> iter 27000, loss: 0.425204
 >> iter 28000, loss: 0.567450
 >> iter 29000, loss: 0.414796
 >> iter 30000, loss: 0.400200
   Number of active neurons: 5
 >> iter 31000, loss: 0.305819
 >> iter 32000, loss: 0.455166
 >> iter 33000, loss: 0.414765
 >> iter 34000, loss: 0.259375
 >> iter 35000, loss: 0.376365
 >> iter 36000, loss: 0.257884
 >> iter 37000, loss: 0.284317
 >> iter 38000, loss: 0.315802
 >> iter 39000, loss: 0.238284
 >> iter 40000, loss: 0.413737
   Number of active neurons: 5
 >> iter 41000, loss: 0.411708
 >> iter 42000, loss: 0.338239
 >> iter 43000, loss: 0.268023
 >> iter 44000, loss: 0.285074
 >> iter 45000, loss: 0.324137
 >> iter 46000, loss: 0.362774
 >> iter 47000, loss: 0.460028
 >> iter 48000, loss: 0.466679
 >> iter 49000, loss: 0.358811
 >> iter 50000, loss: 0.312340
   Number of active neurons: 5
 >> iter 51000, loss: 0.421034
 >> iter 52000, loss: 0.350136
 >> iter 53000, loss: 0.228849
 >> iter 54000, loss: 0.380500
 >> iter 55000, loss: 0.347078
 >> iter 56000, loss: 0.282476
 >> iter 57000, loss: 0.302203
 >> iter 58000, loss: 0.274748
 >> iter 59000, loss: 0.312996
 >> iter 60000, loss: 0.491090
   Number of active neurons: 5
 >> iter 61000, loss: 0.386191
 >> iter 62000, loss: 0.378486
 >> iter 63000, loss: 0.332421
 >> iter 64000, loss: 0.526509
 >> iter 65000, loss: 0.409045
 >> iter 66000, loss: 0.287186
 >> iter 67000, loss: 0.220144
 >> iter 68000, loss: 0.412247
 >> iter 69000, loss: 0.468733
 >> iter 70000, loss: 0.331313
   Number of active neurons: 5
 >> iter 71000, loss: 0.329025
 >> iter 72000, loss: 0.365442
 >> iter 73000, loss: 0.313990
 >> iter 74000, loss: 0.277878
 >> iter 75000, loss: 0.373264
 >> iter 76000, loss: 0.353249
 >> iter 77000, loss: 0.237506
 >> iter 78000, loss: 0.267475
 >> iter 79000, loss: 0.393256
 >> iter 80000, loss: 0.324118
   Number of active neurons: 5
 >> iter 81000, loss: 0.289894
 >> iter 82000, loss: 0.293951
 >> iter 83000, loss: 0.354919
 >> iter 84000, loss: 0.301032
 >> iter 85000, loss: 0.393433
 >> iter 86000, loss: 0.333017
 >> iter 87000, loss: 0.452882
 >> iter 88000, loss: 0.497822
 >> iter 89000, loss: 0.493176
 >> iter 90000, loss: 0.453994
   Number of active neurons: 5
 >> iter 91000, loss: 0.453004
 >> iter 92000, loss: 0.274346
 >> iter 93000, loss: 0.281043
 >> iter 94000, loss: 0.311161
 >> iter 95000, loss: 0.236098
 >> iter 96000, loss: 0.239493
 >> iter 97000, loss: 0.225456
 >> iter 98000, loss: 0.295975
 >> iter 99000, loss: 0.273218
 >> iter 100000, loss: 0.332124
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.247559
 >> iter 2000, loss: 13.960596
 >> iter 3000, loss: 10.764532
 >> iter 4000, loss: 9.069925
 >> iter 5000, loss: 8.653600
 >> iter 6000, loss: 8.189987
 >> iter 7000, loss: 8.278477
 >> iter 8000, loss: 8.077496
 >> iter 9000, loss: 8.219286
 >> iter 10000, loss: 7.987123
   Number of active neurons: 3
 >> iter 11000, loss: 8.058825
 >> iter 12000, loss: 7.979693
 >> iter 13000, loss: 8.038979
 >> iter 14000, loss: 7.973113
 >> iter 15000, loss: 7.924411
 >> iter 16000, loss: 7.808609
 >> iter 17000, loss: 7.635070
 >> iter 18000, loss: 7.219707
 >> iter 19000, loss: 6.281423
 >> iter 20000, loss: 5.160729
   Number of active neurons: 3
 >> iter 21000, loss: 4.761756
 >> iter 22000, loss: 4.433334
 >> iter 23000, loss: 4.325678
 >> iter 24000, loss: 2.729378
 >> iter 25000, loss: 1.970610
 >> iter 26000, loss: 1.293324
 >> iter 27000, loss: 0.900526
 >> iter 28000, loss: 0.620258
 >> iter 29000, loss: 0.755126
 >> iter 30000, loss: 0.563372
   Number of active neurons: 4
 >> iter 31000, loss: 0.427458
 >> iter 32000, loss: 0.359136
 >> iter 33000, loss: 0.588641
 >> iter 34000, loss: 0.395983
 >> iter 35000, loss: 0.571032
 >> iter 36000, loss: 0.539235
 >> iter 37000, loss: 0.528495
 >> iter 38000, loss: 0.403522
 >> iter 39000, loss: 0.561119
 >> iter 40000, loss: 0.658078
   Number of active neurons: 4
 >> iter 41000, loss: 0.548526
 >> iter 42000, loss: 0.541266
 >> iter 43000, loss: 0.557796
 >> iter 44000, loss: 0.602684
 >> iter 45000, loss: 0.516290
 >> iter 46000, loss: 0.516456
 >> iter 47000, loss: 0.477141
 >> iter 48000, loss: 0.527225
 >> iter 49000, loss: 0.654311
 >> iter 50000, loss: 0.518296
   Number of active neurons: 4
 >> iter 51000, loss: 0.432843
 >> iter 52000, loss: 0.613736
 >> iter 53000, loss: 0.502553
 >> iter 54000, loss: 0.475458
 >> iter 55000, loss: 0.527359
 >> iter 56000, loss: 0.508425
 >> iter 57000, loss: 0.422547
 >> iter 58000, loss: 0.571057
 >> iter 59000, loss: 0.580789
 >> iter 60000, loss: 0.508168
   Number of active neurons: 4
 >> iter 61000, loss: 0.409233
 >> iter 62000, loss: 0.490092
 >> iter 63000, loss: 0.673783
 >> iter 64000, loss: 0.666132
 >> iter 65000, loss: 0.710591
 >> iter 66000, loss: 0.409630
 >> iter 67000, loss: 0.364928
 >> iter 68000, loss: 0.390678
 >> iter 69000, loss: 0.449010
 >> iter 70000, loss: 0.339613
   Number of active neurons: 4
 >> iter 71000, loss: 0.313311
 >> iter 72000, loss: 0.445573
 >> iter 73000, loss: 0.514442
 >> iter 74000, loss: 0.580662
 >> iter 75000, loss: 0.744663
 >> iter 76000, loss: 0.582342
 >> iter 77000, loss: 0.483002
 >> iter 78000, loss: 0.473604
 >> iter 79000, loss: 0.595399
 >> iter 80000, loss: 0.469544
   Number of active neurons: 5
 >> iter 81000, loss: 0.386062
 >> iter 82000, loss: 0.341409
 >> iter 83000, loss: 0.423776
 >> iter 84000, loss: 0.413903
 >> iter 85000, loss: 0.378924
 >> iter 86000, loss: 0.331358
 >> iter 87000, loss: 0.417497
 >> iter 88000, loss: 0.405226
 >> iter 89000, loss: 0.419765
 >> iter 90000, loss: 0.598387
   Number of active neurons: 4
 >> iter 91000, loss: 0.475561
 >> iter 92000, loss: 0.404937
 >> iter 93000, loss: 0.539825
 >> iter 94000, loss: 0.459998
 >> iter 95000, loss: 0.525220
 >> iter 96000, loss: 0.365178
 >> iter 97000, loss: 0.539115
 >> iter 98000, loss: 0.462277
 >> iter 99000, loss: 0.637395
 >> iter 100000, loss: 0.469237
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.583382
 >> iter 2000, loss: 15.618118
 >> iter 3000, loss: 13.766170
 >> iter 4000, loss: 10.560657
 >> iter 5000, loss: 5.612115
 >> iter 6000, loss: 2.974965
 >> iter 7000, loss: 1.836817
 >> iter 8000, loss: 1.268735
 >> iter 9000, loss: 1.070953
 >> iter 10000, loss: 0.687051
   Number of active neurons: 4
 >> iter 11000, loss: 0.666820
 >> iter 12000, loss: 0.634754
 >> iter 13000, loss: 0.455391
 >> iter 14000, loss: 0.505664
 >> iter 15000, loss: 0.576372
 >> iter 16000, loss: 0.472860
 >> iter 17000, loss: 0.492326
 >> iter 18000, loss: 0.649387
 >> iter 19000, loss: 0.440378
 >> iter 20000, loss: 0.482423
   Number of active neurons: 4
 >> iter 21000, loss: 0.513718
 >> iter 22000, loss: 0.491917
 >> iter 23000, loss: 0.367552
 >> iter 24000, loss: 0.327359
 >> iter 25000, loss: 0.488293
 >> iter 26000, loss: 0.591552
 >> iter 27000, loss: 0.621332
 >> iter 28000, loss: 0.648903
 >> iter 29000, loss: 0.549492
 >> iter 30000, loss: 0.451074
   Number of active neurons: 4
 >> iter 31000, loss: 0.500418
 >> iter 32000, loss: 0.450735
 >> iter 33000, loss: 0.576558
 >> iter 34000, loss: 0.581003
 >> iter 35000, loss: 0.513887
 >> iter 36000, loss: 0.586191
 >> iter 37000, loss: 0.473064
 >> iter 38000, loss: 0.739748
 >> iter 39000, loss: 0.639686
 >> iter 40000, loss: 0.568469
   Number of active neurons: 4
 >> iter 41000, loss: 0.334048
 >> iter 42000, loss: 0.371413
 >> iter 43000, loss: 0.324334
 >> iter 44000, loss: 0.316362
 >> iter 45000, loss: 0.426807
 >> iter 46000, loss: 0.497404
 >> iter 47000, loss: 0.562956
 >> iter 48000, loss: 0.523400
 >> iter 49000, loss: 0.489731
 >> iter 50000, loss: 0.564564
   Number of active neurons: 4
 >> iter 51000, loss: 0.616410
 >> iter 52000, loss: 0.681615
 >> iter 53000, loss: 0.448103
 >> iter 54000, loss: 0.624660
 >> iter 55000, loss: 0.449647
 >> iter 56000, loss: 0.389847
 >> iter 57000, loss: 0.445435
 >> iter 58000, loss: 0.464376
 >> iter 59000, loss: 0.450698
 >> iter 60000, loss: 0.394769
   Number of active neurons: 4
 >> iter 61000, loss: 0.388955
 >> iter 62000, loss: 0.452249
 >> iter 63000, loss: 0.454507
 >> iter 64000, loss: 0.514478
 >> iter 65000, loss: 0.502731
 >> iter 66000, loss: 0.557012
 >> iter 67000, loss: 0.610782
 >> iter 68000, loss: 0.525689
 >> iter 69000, loss: 0.467725
 >> iter 70000, loss: 0.469146
   Number of active neurons: 4
 >> iter 71000, loss: 0.488001
 >> iter 72000, loss: 0.389355
 >> iter 73000, loss: 0.394476
 >> iter 74000, loss: 0.407530
 >> iter 75000, loss: 0.646327
 >> iter 76000, loss: 0.593632
 >> iter 77000, loss: 0.470992
 >> iter 78000, loss: 0.352315
 >> iter 79000, loss: 0.429078
 >> iter 80000, loss: 0.353470
   Number of active neurons: 4
 >> iter 81000, loss: 0.392051
 >> iter 82000, loss: 0.413871
 >> iter 83000, loss: 0.471695
 >> iter 84000, loss: 0.330972
 >> iter 85000, loss: 0.514682
 >> iter 86000, loss: 0.515526
 >> iter 87000, loss: 0.259745
 >> iter 88000, loss: 0.556818
 >> iter 89000, loss: 0.409962
 >> iter 90000, loss: 0.342984
   Number of active neurons: 4
 >> iter 91000, loss: 0.432784
 >> iter 92000, loss: 0.405561
 >> iter 93000, loss: 0.405691
 >> iter 94000, loss: 0.414925
 >> iter 95000, loss: 0.499028
 >> iter 96000, loss: 0.501989
 >> iter 97000, loss: 0.522934
 >> iter 98000, loss: 0.588525
 >> iter 99000, loss: 0.422091
 >> iter 100000, loss: 0.442264
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.421071
 >> iter 2000, loss: 13.153026
 >> iter 3000, loss: 9.559728
 >> iter 4000, loss: 7.646306
 >> iter 5000, loss: 6.503624
 >> iter 6000, loss: 5.748095
 >> iter 7000, loss: 5.609229
 >> iter 8000, loss: 5.212823
 >> iter 9000, loss: 5.314638
 >> iter 10000, loss: 5.010147
   Number of active neurons: 4
 >> iter 11000, loss: 4.764598
 >> iter 12000, loss: 4.113082
 >> iter 13000, loss: 4.174828
 >> iter 14000, loss: 3.863513
 >> iter 15000, loss: 4.041141
 >> iter 16000, loss: 3.695813
 >> iter 17000, loss: 3.697759
 >> iter 18000, loss: 3.070807
 >> iter 19000, loss: 2.738085
 >> iter 20000, loss: 2.194414
   Number of active neurons: 5
 >> iter 21000, loss: 2.084162
 >> iter 22000, loss: 2.095549
 >> iter 23000, loss: 2.030021
 >> iter 24000, loss: 1.596574
 >> iter 25000, loss: 1.718497
 >> iter 26000, loss: 0.978607
 >> iter 27000, loss: 0.944136
 >> iter 28000, loss: 0.775374
 >> iter 29000, loss: 0.642387
 >> iter 30000, loss: 0.616196
   Number of active neurons: 6
 >> iter 31000, loss: 0.622119
 >> iter 32000, loss: 0.603351
 >> iter 33000, loss: 0.375808
 >> iter 34000, loss: 0.226655
 >> iter 35000, loss: 0.408025
 >> iter 36000, loss: 0.440100
 >> iter 37000, loss: 0.393842
 >> iter 38000, loss: 0.292445
 >> iter 39000, loss: 0.304346
 >> iter 40000, loss: 0.258973
   Number of active neurons: 5
 >> iter 41000, loss: 0.258567
 >> iter 42000, loss: 0.371535
 >> iter 43000, loss: 0.421843
 >> iter 44000, loss: 0.313542
 >> iter 45000, loss: 0.340081
 >> iter 46000, loss: 0.239039
 >> iter 47000, loss: 0.359943
 >> iter 48000, loss: 0.251560
 >> iter 49000, loss: 0.411283
 >> iter 50000, loss: 0.448876
   Number of active neurons: 5
 >> iter 51000, loss: 0.412492
 >> iter 52000, loss: 0.280229
 >> iter 53000, loss: 0.375761
 >> iter 54000, loss: 0.299325
 >> iter 55000, loss: 0.257796
 >> iter 56000, loss: 0.387101
 >> iter 57000, loss: 0.313305
 >> iter 58000, loss: 0.249526
 >> iter 59000, loss: 0.215796
 >> iter 60000, loss: 0.193264
   Number of active neurons: 5
 >> iter 61000, loss: 0.158161
 >> iter 62000, loss: 0.187702
 >> iter 63000, loss: 0.187526
 >> iter 64000, loss: 0.183998
 >> iter 65000, loss: 0.173032
 >> iter 66000, loss: 0.222847
 >> iter 67000, loss: 0.199960
 >> iter 68000, loss: 0.224870
 >> iter 69000, loss: 0.216640
 >> iter 70000, loss: 0.201687
   Number of active neurons: 5
 >> iter 71000, loss: 0.281391
 >> iter 72000, loss: 0.262478
 >> iter 73000, loss: 0.196337
 >> iter 74000, loss: 0.177442
 >> iter 75000, loss: 0.180179
 >> iter 76000, loss: 0.237117
 >> iter 77000, loss: 0.130582
 >> iter 78000, loss: 0.122870
 >> iter 79000, loss: 0.121162
 >> iter 80000, loss: 0.240370
   Number of active neurons: 5
 >> iter 81000, loss: 0.210150
 >> iter 82000, loss: 0.236369
 >> iter 83000, loss: 0.202130
 >> iter 84000, loss: 0.296308
 >> iter 85000, loss: 0.258446
 >> iter 86000, loss: 0.164144
 >> iter 87000, loss: 0.230115
 >> iter 88000, loss: 0.200018
 >> iter 89000, loss: 0.179416
 >> iter 90000, loss: 0.392102
   Number of active neurons: 5
 >> iter 91000, loss: 0.234105
 >> iter 92000, loss: 0.153025
 >> iter 93000, loss: 0.269134
 >> iter 94000, loss: 0.189940
 >> iter 95000, loss: 0.141669
 >> iter 96000, loss: 0.236131
 >> iter 97000, loss: 0.183102
 >> iter 98000, loss: 0.171803
 >> iter 99000, loss: 0.206794
 >> iter 100000, loss: 0.152935
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.170229
 >> iter 2000, loss: 14.792961
 >> iter 3000, loss: 11.709087
 >> iter 4000, loss: 9.087024
 >> iter 5000, loss: 8.107671
 >> iter 6000, loss: 7.451980
 >> iter 7000, loss: 7.304468
 >> iter 8000, loss: 7.024431
 >> iter 9000, loss: 7.092221
 >> iter 10000, loss: 6.889758
   Number of active neurons: 5
 >> iter 11000, loss: 6.906288
 >> iter 12000, loss: 6.591324
 >> iter 13000, loss: 6.789371
 >> iter 14000, loss: 6.531829
 >> iter 15000, loss: 6.556558
 >> iter 16000, loss: 6.347152
 >> iter 17000, loss: 6.502820
 >> iter 18000, loss: 6.427959
 >> iter 19000, loss: 6.562916
 >> iter 20000, loss: 6.429029
   Number of active neurons: 5
 >> iter 21000, loss: 6.301919
 >> iter 22000, loss: 5.014805
 >> iter 23000, loss: 4.553362
 >> iter 24000, loss: 3.974071
 >> iter 25000, loss: 2.693892
 >> iter 26000, loss: 1.482481
 >> iter 27000, loss: 0.974104
 >> iter 28000, loss: 0.781569
 >> iter 29000, loss: 0.568140
 >> iter 30000, loss: 0.637559
   Number of active neurons: 6
 >> iter 31000, loss: 0.498783
 >> iter 32000, loss: 0.663181
 >> iter 33000, loss: 0.766624
 >> iter 34000, loss: 0.586733
 >> iter 35000, loss: 0.438289
 >> iter 36000, loss: 0.469899
 >> iter 37000, loss: 0.536457
 >> iter 38000, loss: 0.554266
 >> iter 39000, loss: 0.391224
 >> iter 40000, loss: 0.429620
   Number of active neurons: 6
 >> iter 41000, loss: 0.720724
 >> iter 42000, loss: 0.658987
 >> iter 43000, loss: 0.527463
 >> iter 44000, loss: 0.359874
 >> iter 45000, loss: 0.660566
 >> iter 46000, loss: 0.518445
 >> iter 47000, loss: 0.636050
 >> iter 48000, loss: 0.480307
 >> iter 49000, loss: 0.430259
 >> iter 50000, loss: 0.643393
   Number of active neurons: 5
 >> iter 51000, loss: 0.412883
 >> iter 52000, loss: 0.424532
 >> iter 53000, loss: 0.437623
 >> iter 54000, loss: 0.359638
 >> iter 55000, loss: 0.316426
 >> iter 56000, loss: 0.346162
 >> iter 57000, loss: 0.319660
 >> iter 58000, loss: 0.572079
 >> iter 59000, loss: 0.507821
 >> iter 60000, loss: 0.656331
   Number of active neurons: 5
 >> iter 61000, loss: 0.390232
 >> iter 62000, loss: 0.408925
 >> iter 63000, loss: 0.362360
 >> iter 64000, loss: 0.308890
 >> iter 65000, loss: 0.349151
 >> iter 66000, loss: 0.353325
 >> iter 67000, loss: 0.478376
 >> iter 68000, loss: 0.452516
 >> iter 69000, loss: 0.530126
 >> iter 70000, loss: 0.474661
   Number of active neurons: 5
 >> iter 71000, loss: 0.688899
 >> iter 72000, loss: 0.594145
 >> iter 73000, loss: 0.402436
 >> iter 74000, loss: 0.325897
 >> iter 75000, loss: 0.439454
 >> iter 76000, loss: 0.411790
 >> iter 77000, loss: 0.353505
 >> iter 78000, loss: 0.396619
 >> iter 79000, loss: 0.339522
 >> iter 80000, loss: 0.544692
   Number of active neurons: 5
 >> iter 81000, loss: 0.455709
 >> iter 82000, loss: 0.391401
 >> iter 83000, loss: 0.343167
 >> iter 84000, loss: 0.377233
 >> iter 85000, loss: 0.400889
 >> iter 86000, loss: 0.481817
 >> iter 87000, loss: 0.324228
 >> iter 88000, loss: 0.371535
 >> iter 89000, loss: 0.380136
 >> iter 90000, loss: 0.451392
   Number of active neurons: 5
 >> iter 91000, loss: 0.525450
 >> iter 92000, loss: 0.456990
 >> iter 93000, loss: 0.473351
 >> iter 94000, loss: 0.574158
 >> iter 95000, loss: 0.380481
 >> iter 96000, loss: 0.271664
 >> iter 97000, loss: 0.337647
 >> iter 98000, loss: 0.316129
 >> iter 99000, loss: 0.320252
 >> iter 100000, loss: 0.306301
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.151435
 >> iter 2000, loss: 15.558424
 >> iter 3000, loss: 14.011341
 >> iter 4000, loss: 10.937413
 >> iter 5000, loss: 5.877476
 >> iter 6000, loss: 2.853370
 >> iter 7000, loss: 1.557902
 >> iter 8000, loss: 0.984129
 >> iter 9000, loss: 0.560078
 >> iter 10000, loss: 0.457841
   Number of active neurons: 5
 >> iter 11000, loss: 0.306445
 >> iter 12000, loss: 0.354018
 >> iter 13000, loss: 0.568815
 >> iter 14000, loss: 0.469011
 >> iter 15000, loss: 0.460959
 >> iter 16000, loss: 0.436634
 >> iter 17000, loss: 0.440709
 >> iter 18000, loss: 0.302343
 >> iter 19000, loss: 0.266881
 >> iter 20000, loss: 0.387449
   Number of active neurons: 5
 >> iter 21000, loss: 0.380626
 >> iter 22000, loss: 0.454834
 >> iter 23000, loss: 0.393538
 >> iter 24000, loss: 0.417217
 >> iter 25000, loss: 0.289986
 >> iter 26000, loss: 0.348515
 >> iter 27000, loss: 0.487551
 >> iter 28000, loss: 0.388170
 >> iter 29000, loss: 0.317266
 >> iter 30000, loss: 0.323266
   Number of active neurons: 5
 >> iter 31000, loss: 0.365449
 >> iter 32000, loss: 0.458688
 >> iter 33000, loss: 0.386953
 >> iter 34000, loss: 0.366136
 >> iter 35000, loss: 0.388278
 >> iter 36000, loss: 0.494882
 >> iter 37000, loss: 0.389658
 >> iter 38000, loss: 0.437091
 >> iter 39000, loss: 0.523248
 >> iter 40000, loss: 0.495363
   Number of active neurons: 5
 >> iter 41000, loss: 0.560472
 >> iter 42000, loss: 0.515544
 >> iter 43000, loss: 0.415031
 >> iter 44000, loss: 0.344974
 >> iter 45000, loss: 0.313092
 >> iter 46000, loss: 0.276618
 >> iter 47000, loss: 0.308829
 >> iter 48000, loss: 0.305092
 >> iter 49000, loss: 0.361376
 >> iter 50000, loss: 0.311667
   Number of active neurons: 4
 >> iter 51000, loss: 0.380372
 >> iter 52000, loss: 0.468430
 >> iter 53000, loss: 0.391510
 >> iter 54000, loss: 0.334729
 >> iter 55000, loss: 0.368524
 >> iter 56000, loss: 0.364469
 >> iter 57000, loss: 0.343058
 >> iter 58000, loss: 0.471751
 >> iter 59000, loss: 0.432286
 >> iter 60000, loss: 0.581156
   Number of active neurons: 4
 >> iter 61000, loss: 0.452150
 >> iter 62000, loss: 0.520277
 >> iter 63000, loss: 0.508881
 >> iter 64000, loss: 0.444284
 >> iter 65000, loss: 0.392463
 >> iter 66000, loss: 0.286491
 >> iter 67000, loss: 0.400386
 >> iter 68000, loss: 0.403636
 >> iter 69000, loss: 0.344728
 >> iter 70000, loss: 0.508916
   Number of active neurons: 4
 >> iter 71000, loss: 0.452435
 >> iter 72000, loss: 0.308802
 >> iter 73000, loss: 0.305760
 >> iter 74000, loss: 0.333991
 >> iter 75000, loss: 0.304475
 >> iter 76000, loss: 0.347813
 >> iter 77000, loss: 0.363782
 >> iter 78000, loss: 0.373582
 >> iter 79000, loss: 0.305997
 >> iter 80000, loss: 0.321133
   Number of active neurons: 4
 >> iter 81000, loss: 0.224092
 >> iter 82000, loss: 0.353177
 >> iter 83000, loss: 0.323519
 >> iter 84000, loss: 0.389136
 >> iter 85000, loss: 0.523593
 >> iter 86000, loss: 0.351070
 >> iter 87000, loss: 0.397106
 >> iter 88000, loss: 0.437057
 >> iter 89000, loss: 0.296065
 >> iter 90000, loss: 0.320417
   Number of active neurons: 4
 >> iter 91000, loss: 0.302126
 >> iter 92000, loss: 0.329122
 >> iter 93000, loss: 0.331897
 >> iter 94000, loss: 0.436970
 >> iter 95000, loss: 0.371917
 >> iter 96000, loss: 0.348240
 >> iter 97000, loss: 0.299416
 >> iter 98000, loss: 0.400160
 >> iter 99000, loss: 0.400324
 >> iter 100000, loss: 0.359753
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 10.2726484901
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.119276
 >> iter 2000, loss: 14.409112
 >> iter 3000, loss: 10.266327
 >> iter 4000, loss: 6.355401
 >> iter 5000, loss: 3.636445
 >> iter 6000, loss: 2.056085
 >> iter 7000, loss: 1.338836
 >> iter 8000, loss: 1.112649
 >> iter 9000, loss: 0.864545
 >> iter 10000, loss: 0.627012
   Number of active neurons: 5
 >> iter 11000, loss: 0.690607
 >> iter 12000, loss: 0.672784
 >> iter 13000, loss: 0.907794
 >> iter 14000, loss: 0.673062
 >> iter 15000, loss: 0.604924
 >> iter 16000, loss: 0.458707
 >> iter 17000, loss: 0.631683
 >> iter 18000, loss: 0.483161
 >> iter 19000, loss: 0.507130
 >> iter 20000, loss: 0.533854
   Number of active neurons: 5
 >> iter 21000, loss: 0.740315
 >> iter 22000, loss: 0.587618
 >> iter 23000, loss: 0.670411
 >> iter 24000, loss: 0.603793
 >> iter 25000, loss: 0.669628
 >> iter 26000, loss: 0.704038
 >> iter 27000, loss: 0.615821
 >> iter 28000, loss: 0.547821
 >> iter 29000, loss: 0.647102
 >> iter 30000, loss: 0.508229
   Number of active neurons: 5
 >> iter 31000, loss: 0.576326
 >> iter 32000, loss: 0.674603
 >> iter 33000, loss: 0.707795
 >> iter 34000, loss: 0.710727
 >> iter 35000, loss: 0.766182
 >> iter 36000, loss: 0.527513
 >> iter 37000, loss: 0.476750
 >> iter 38000, loss: 0.573508
 >> iter 39000, loss: 0.622614
 >> iter 40000, loss: 0.565397
   Number of active neurons: 5
 >> iter 41000, loss: 0.626197
 >> iter 42000, loss: 0.570351
 >> iter 43000, loss: 0.514691
 >> iter 44000, loss: 0.531420
 >> iter 45000, loss: 0.411605
 >> iter 46000, loss: 0.481280
 >> iter 47000, loss: 0.562371
 >> iter 48000, loss: 0.491161
 >> iter 49000, loss: 0.376948
 >> iter 50000, loss: 0.425246
   Number of active neurons: 5
 >> iter 51000, loss: 0.624391
 >> iter 52000, loss: 0.533013
 >> iter 53000, loss: 0.586332
 >> iter 54000, loss: 0.463141
 >> iter 55000, loss: 0.509837
 >> iter 56000, loss: 0.436629
 >> iter 57000, loss: 0.614824
 >> iter 58000, loss: 0.701957
 >> iter 59000, loss: 0.502569
 >> iter 60000, loss: 0.634713
   Number of active neurons: 5
 >> iter 61000, loss: 0.548492
 >> iter 62000, loss: 0.479624
 >> iter 63000, loss: 0.300517
 >> iter 64000, loss: 0.637602
 >> iter 65000, loss: 0.425148
 >> iter 66000, loss: 0.444974
 >> iter 67000, loss: 0.690249
 >> iter 68000, loss: 0.639023
 >> iter 69000, loss: 0.562697
 >> iter 70000, loss: 0.364257
   Number of active neurons: 5
 >> iter 71000, loss: 0.593383
 >> iter 72000, loss: 0.491136
 >> iter 73000, loss: 0.419182
 >> iter 74000, loss: 0.630060
 >> iter 75000, loss: 0.561921
 >> iter 76000, loss: 0.512027
 >> iter 77000, loss: 0.460179
 >> iter 78000, loss: 0.484039
 >> iter 79000, loss: 0.484305
 >> iter 80000, loss: 0.368637
   Number of active neurons: 5
 >> iter 81000, loss: 0.576666
 >> iter 82000, loss: 0.424260
 >> iter 83000, loss: 0.431664
 >> iter 84000, loss: 0.538281
 >> iter 85000, loss: 0.468356
 >> iter 86000, loss: 0.672933
 >> iter 87000, loss: 0.507767
 >> iter 88000, loss: 0.512610
 >> iter 89000, loss: 0.506146
 >> iter 90000, loss: 0.495119
   Number of active neurons: 5
 >> iter 91000, loss: 0.463428
 >> iter 92000, loss: 0.486837
 >> iter 93000, loss: 0.409713
 >> iter 94000, loss: 0.575879
 >> iter 95000, loss: 0.472087
 >> iter 96000, loss: 0.345063
 >> iter 97000, loss: 0.473023
 >> iter 98000, loss: 0.404206
 >> iter 99000, loss: 0.467161
 >> iter 100000, loss: 0.588092
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.352833
 >> iter 2000, loss: 14.748433
 >> iter 3000, loss: 11.883069
 >> iter 4000, loss: 10.412840
 >> iter 5000, loss: 10.020275
 >> iter 6000, loss: 9.916270
 >> iter 7000, loss: 10.089636
 >> iter 8000, loss: 9.665565
 >> iter 9000, loss: 8.914791
 >> iter 10000, loss: 8.224598
   Number of active neurons: 3
 >> iter 11000, loss: 6.536768
 >> iter 12000, loss: 4.593657
 >> iter 13000, loss: 3.745650
 >> iter 14000, loss: 3.034568
 >> iter 15000, loss: 2.425955
 >> iter 16000, loss: 1.438211
 >> iter 17000, loss: 1.088762
 >> iter 18000, loss: 0.818735
 >> iter 19000, loss: 0.821266
 >> iter 20000, loss: 0.744501
   Number of active neurons: 5
 >> iter 21000, loss: 0.816806
 >> iter 22000, loss: 0.657503
 >> iter 23000, loss: 0.707297
 >> iter 24000, loss: 0.641718
 >> iter 25000, loss: 0.766814
 >> iter 26000, loss: 0.501356
 >> iter 27000, loss: 0.557356
 >> iter 28000, loss: 0.489611
 >> iter 29000, loss: 0.579514
 >> iter 30000, loss: 0.443486
   Number of active neurons: 5
 >> iter 31000, loss: 0.416622
 >> iter 32000, loss: 0.388833
 >> iter 33000, loss: 0.399380
 >> iter 34000, loss: 0.435502
 >> iter 35000, loss: 0.370903
 >> iter 36000, loss: 0.580203
 >> iter 37000, loss: 0.379035
 >> iter 38000, loss: 0.328461
 >> iter 39000, loss: 0.508055
 >> iter 40000, loss: 0.536584
   Number of active neurons: 5
 >> iter 41000, loss: 0.578718
 >> iter 42000, loss: 0.538942
 >> iter 43000, loss: 0.395055
 >> iter 44000, loss: 0.373892
 >> iter 45000, loss: 0.303106
 >> iter 46000, loss: 0.296106
 >> iter 47000, loss: 0.383465
 >> iter 48000, loss: 0.367305
 >> iter 49000, loss: 0.427507
 >> iter 50000, loss: 0.298300
   Number of active neurons: 5
 >> iter 51000, loss: 0.406005
 >> iter 52000, loss: 0.480923
 >> iter 53000, loss: 0.429405
 >> iter 54000, loss: 0.381491
 >> iter 55000, loss: 0.349805
 >> iter 56000, loss: 0.318050
 >> iter 57000, loss: 0.470318
 >> iter 58000, loss: 0.488220
 >> iter 59000, loss: 0.474040
 >> iter 60000, loss: 0.399051
   Number of active neurons: 5
 >> iter 61000, loss: 0.360388
 >> iter 62000, loss: 0.281735
 >> iter 63000, loss: 0.236140
 >> iter 64000, loss: 0.503011
 >> iter 65000, loss: 0.417726
 >> iter 66000, loss: 0.340754
 >> iter 67000, loss: 0.476628
 >> iter 68000, loss: 0.451622
 >> iter 69000, loss: 0.507215
 >> iter 70000, loss: 0.486381
   Number of active neurons: 5
 >> iter 71000, loss: 0.417692
 >> iter 72000, loss: 0.373904
 >> iter 73000, loss: 0.341891
 >> iter 74000, loss: 0.432531
 >> iter 75000, loss: 0.571930
 >> iter 76000, loss: 0.387166
 >> iter 77000, loss: 0.248400
 >> iter 78000, loss: 0.236188
 >> iter 79000, loss: 0.324696
 >> iter 80000, loss: 0.474181
   Number of active neurons: 5
 >> iter 81000, loss: 0.440425
 >> iter 82000, loss: 0.426962
 >> iter 83000, loss: 0.357656
 >> iter 84000, loss: 0.455960
 >> iter 85000, loss: 0.432010
 >> iter 86000, loss: 0.414840
 >> iter 87000, loss: 0.326622
 >> iter 88000, loss: 0.390024
 >> iter 89000, loss: 0.372617
 >> iter 90000, loss: 0.501139
   Number of active neurons: 5
 >> iter 91000, loss: 0.442723
 >> iter 92000, loss: 0.391476
 >> iter 93000, loss: 0.394376
 >> iter 94000, loss: 0.352372
 >> iter 95000, loss: 0.366885
 >> iter 96000, loss: 0.306020
 >> iter 97000, loss: 0.545604
 >> iter 98000, loss: 0.547862
 >> iter 99000, loss: 0.471951
 >> iter 100000, loss: 0.351388
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.217772
 >> iter 2000, loss: 14.435407
 >> iter 3000, loss: 10.945410
 >> iter 4000, loss: 7.105481
 >> iter 5000, loss: 5.114185
 >> iter 6000, loss: 3.989864
 >> iter 7000, loss: 3.582416
 >> iter 8000, loss: 2.798464
 >> iter 9000, loss: 1.617871
 >> iter 10000, loss: 0.984585
   Number of active neurons: 6
 >> iter 11000, loss: 0.557777
 >> iter 12000, loss: 0.393070
 >> iter 13000, loss: 0.403773
 >> iter 14000, loss: 0.353699
 >> iter 15000, loss: 0.350685
 >> iter 16000, loss: 0.311617
 >> iter 17000, loss: 0.544335
 >> iter 18000, loss: 0.341387
 >> iter 19000, loss: 0.335020
 >> iter 20000, loss: 0.296567
   Number of active neurons: 6
 >> iter 21000, loss: 0.336404
 >> iter 22000, loss: 0.254661
 >> iter 23000, loss: 0.415609
 >> iter 24000, loss: 0.321099
 >> iter 25000, loss: 0.405983
 >> iter 26000, loss: 0.369777
 >> iter 27000, loss: 0.245321
 >> iter 28000, loss: 0.314841
 >> iter 29000, loss: 0.279456
 >> iter 30000, loss: 0.302648
   Number of active neurons: 6
 >> iter 31000, loss: 0.322235
 >> iter 32000, loss: 0.257377
 >> iter 33000, loss: 0.280105
 >> iter 34000, loss: 0.413082
 >> iter 35000, loss: 0.223799
 >> iter 36000, loss: 0.281028
 >> iter 37000, loss: 0.370534
 >> iter 38000, loss: 0.386065
 >> iter 39000, loss: 0.270020
 >> iter 40000, loss: 0.190424
   Number of active neurons: 6
 >> iter 41000, loss: 0.173623
 >> iter 42000, loss: 0.241812
 >> iter 43000, loss: 0.317660
 >> iter 44000, loss: 0.249091
 >> iter 45000, loss: 0.219038
 >> iter 46000, loss: 0.174896
 >> iter 47000, loss: 0.218375
 >> iter 48000, loss: 0.244911
 >> iter 49000, loss: 0.310504
 >> iter 50000, loss: 0.185046
   Number of active neurons: 6
 >> iter 51000, loss: 0.307069
 >> iter 52000, loss: 0.246926
 >> iter 53000, loss: 0.258262
 >> iter 54000, loss: 0.390508
 >> iter 55000, loss: 0.260853
 >> iter 56000, loss: 0.374469
 >> iter 57000, loss: 0.287130
 >> iter 58000, loss: 0.210040
 >> iter 59000, loss: 0.232365
 >> iter 60000, loss: 0.233024
   Number of active neurons: 6
 >> iter 61000, loss: 0.206351
 >> iter 62000, loss: 0.214686
 >> iter 63000, loss: 0.270405
 >> iter 64000, loss: 0.266168
 >> iter 65000, loss: 0.177537
 >> iter 66000, loss: 0.322345
 >> iter 67000, loss: 0.292892
 >> iter 68000, loss: 0.330546
 >> iter 69000, loss: 0.269979
 >> iter 70000, loss: 0.278258
   Number of active neurons: 6
 >> iter 71000, loss: 0.253727
 >> iter 72000, loss: 0.244105
 >> iter 73000, loss: 0.242112
 >> iter 74000, loss: 0.259185
 >> iter 75000, loss: 0.340355
 >> iter 76000, loss: 0.224586
 >> iter 77000, loss: 0.266099
 >> iter 78000, loss: 0.259938
 >> iter 79000, loss: 0.365618
 >> iter 80000, loss: 0.309210
   Number of active neurons: 6
 >> iter 81000, loss: 0.345375
 >> iter 82000, loss: 0.221529
 >> iter 83000, loss: 0.212688
 >> iter 84000, loss: 0.179558
 >> iter 85000, loss: 0.241864
 >> iter 86000, loss: 0.200053
 >> iter 87000, loss: 0.311498
 >> iter 88000, loss: 0.214939
 >> iter 89000, loss: 0.233605
 >> iter 90000, loss: 0.184829
   Number of active neurons: 6
 >> iter 91000, loss: 0.367495
 >> iter 92000, loss: 0.193855
 >> iter 93000, loss: 0.250354
 >> iter 94000, loss: 0.275840
 >> iter 95000, loss: 0.316971
 >> iter 96000, loss: 0.196531
 >> iter 97000, loss: 0.234394
 >> iter 98000, loss: 0.324339
 >> iter 99000, loss: 0.260816
 >> iter 100000, loss: 0.306120
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.827974
 >> iter 2000, loss: 11.650941
 >> iter 3000, loss: 7.474484
 >> iter 4000, loss: 3.927069
 >> iter 5000, loss: 2.174941
 >> iter 6000, loss: 1.630931
 >> iter 7000, loss: 1.023227
 >> iter 8000, loss: 0.905483
 >> iter 9000, loss: 0.786020
 >> iter 10000, loss: 0.666772
   Number of active neurons: 6
 >> iter 11000, loss: 0.520000
 >> iter 12000, loss: 0.601863
 >> iter 13000, loss: 0.579868
 >> iter 14000, loss: 0.501080
 >> iter 15000, loss: 0.376871
 >> iter 16000, loss: 0.443037
 >> iter 17000, loss: 0.358441
 >> iter 18000, loss: 0.432520
 >> iter 19000, loss: 0.647195
 >> iter 20000, loss: 0.611736
   Number of active neurons: 6
 >> iter 21000, loss: 0.522213
 >> iter 22000, loss: 0.513441
 >> iter 23000, loss: 0.409595
 >> iter 24000, loss: 0.373461
 >> iter 25000, loss: 0.395323
 >> iter 26000, loss: 0.410671
 >> iter 27000, loss: 0.329731
 >> iter 28000, loss: 0.438765
 >> iter 29000, loss: 0.452651
 >> iter 30000, loss: 0.375442
   Number of active neurons: 6
 >> iter 31000, loss: 0.419591
 >> iter 32000, loss: 0.402687
 >> iter 33000, loss: 0.382449
 >> iter 34000, loss: 0.442851
 >> iter 35000, loss: 0.491458
 >> iter 36000, loss: 0.417699
 >> iter 37000, loss: 0.420978
 >> iter 38000, loss: 0.382873
 >> iter 39000, loss: 0.614379
 >> iter 40000, loss: 0.406493
   Number of active neurons: 6
 >> iter 41000, loss: 0.348242
 >> iter 42000, loss: 0.431604
 >> iter 43000, loss: 0.359583
 >> iter 44000, loss: 0.526592
 >> iter 45000, loss: 0.536752
 >> iter 46000, loss: 0.464641
 >> iter 47000, loss: 0.473285
 >> iter 48000, loss: 0.622592
 >> iter 49000, loss: 0.564968
 >> iter 50000, loss: 0.403612
   Number of active neurons: 6
 >> iter 51000, loss: 0.345410
 >> iter 52000, loss: 0.353099
 >> iter 53000, loss: 0.475415
 >> iter 54000, loss: 0.433335
 >> iter 55000, loss: 0.384424
 >> iter 56000, loss: 0.331380
 >> iter 57000, loss: 0.404867
 >> iter 58000, loss: 0.404565
 >> iter 59000, loss: 0.574170
 >> iter 60000, loss: 0.418190
   Number of active neurons: 6
 >> iter 61000, loss: 0.310597
 >> iter 62000, loss: 0.565174
 >> iter 63000, loss: 0.437312
 >> iter 64000, loss: 0.404321
 >> iter 65000, loss: 0.341498
 >> iter 66000, loss: 0.331466
 >> iter 67000, loss: 0.404021
 >> iter 68000, loss: 0.375149
 >> iter 69000, loss: 0.699892
 >> iter 70000, loss: 0.477307
   Number of active neurons: 6
 >> iter 71000, loss: 0.637337
 >> iter 72000, loss: 0.543150
 >> iter 73000, loss: 0.432353
 >> iter 74000, loss: 0.273111
 >> iter 75000, loss: 0.539282
 >> iter 76000, loss: 0.433779
 >> iter 77000, loss: 0.385770
 >> iter 78000, loss: 0.607952
 >> iter 79000, loss: 0.525198
 >> iter 80000, loss: 0.409239
   Number of active neurons: 6
 >> iter 81000, loss: 0.425564
 >> iter 82000, loss: 0.400750
 >> iter 83000, loss: 0.458359
 >> iter 84000, loss: 0.406352
 >> iter 85000, loss: 0.382062
 >> iter 86000, loss: 0.321193
 >> iter 87000, loss: 0.335848
 >> iter 88000, loss: 0.393197
 >> iter 89000, loss: 0.331814
 >> iter 90000, loss: 0.322643
   Number of active neurons: 6
 >> iter 91000, loss: 0.518475
 >> iter 92000, loss: 0.360785
 >> iter 93000, loss: 0.397484
 >> iter 94000, loss: 0.234427
 >> iter 95000, loss: 0.429618
 >> iter 96000, loss: 0.361217
 >> iter 97000, loss: 0.378855
 >> iter 98000, loss: 0.621021
 >> iter 99000, loss: 0.469582
 >> iter 100000, loss: 0.407286
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.132243
 >> iter 2000, loss: 13.509525
 >> iter 3000, loss: 11.229993
 >> iter 4000, loss: 10.076368
 >> iter 5000, loss: 9.212793
 >> iter 6000, loss: 8.418706
 >> iter 7000, loss: 8.309824
 >> iter 8000, loss: 8.106085
 >> iter 9000, loss: 8.264130
 >> iter 10000, loss: 8.054523
   Number of active neurons: 3
 >> iter 11000, loss: 8.053216
 >> iter 12000, loss: 7.953428
 >> iter 13000, loss: 8.066339
 >> iter 14000, loss: 7.809707
 >> iter 15000, loss: 7.988904
 >> iter 16000, loss: 7.812717
 >> iter 17000, loss: 7.856567
 >> iter 18000, loss: 7.706891
 >> iter 19000, loss: 7.852460
 >> iter 20000, loss: 7.642790
   Number of active neurons: 3
 >> iter 21000, loss: 7.838572
 >> iter 22000, loss: 7.515302
 >> iter 23000, loss: 7.209101
 >> iter 24000, loss: 6.981484
 >> iter 25000, loss: 6.789678
 >> iter 26000, loss: 4.863828
 >> iter 27000, loss: 3.069838
 >> iter 28000, loss: 1.818297
 >> iter 29000, loss: 1.021564
 >> iter 30000, loss: 0.513131
   Number of active neurons: 6
 >> iter 31000, loss: 0.659297
 >> iter 32000, loss: 0.434434
 >> iter 33000, loss: 0.479839
 >> iter 34000, loss: 0.363168
 >> iter 35000, loss: 0.423896
 >> iter 36000, loss: 0.436099
 >> iter 37000, loss: 0.411602
 >> iter 38000, loss: 0.419355
 >> iter 39000, loss: 0.561026
 >> iter 40000, loss: 0.461441
   Number of active neurons: 6
 >> iter 41000, loss: 0.375217
 >> iter 42000, loss: 0.363409
 >> iter 43000, loss: 0.592845
 >> iter 44000, loss: 0.459813
 >> iter 45000, loss: 0.404795
 >> iter 46000, loss: 0.439821
 >> iter 47000, loss: 0.698447
 >> iter 48000, loss: 0.722932
 >> iter 49000, loss: 0.437865
 >> iter 50000, loss: 0.456228
   Number of active neurons: 6
 >> iter 51000, loss: 0.349502
 >> iter 52000, loss: 0.390377
 >> iter 53000, loss: 0.314319
 >> iter 54000, loss: 0.400348
 >> iter 55000, loss: 0.344574
 >> iter 56000, loss: 0.323336
 >> iter 57000, loss: 0.547451
 >> iter 58000, loss: 0.529627
 >> iter 59000, loss: 0.478483
 >> iter 60000, loss: 0.465703
   Number of active neurons: 6
 >> iter 61000, loss: 0.431731
 >> iter 62000, loss: 0.535639
 >> iter 63000, loss: 0.483152
 >> iter 64000, loss: 0.377859
 >> iter 65000, loss: 0.480959
 >> iter 66000, loss: 0.390938
 >> iter 67000, loss: 0.651418
 >> iter 68000, loss: 0.466473
 >> iter 69000, loss: 0.358615
 >> iter 70000, loss: 0.444317
   Number of active neurons: 6
 >> iter 71000, loss: 0.349880
 >> iter 72000, loss: 0.441284
 >> iter 73000, loss: 0.360438
 >> iter 74000, loss: 0.411390
 >> iter 75000, loss: 0.373386
 >> iter 76000, loss: 0.312357
 >> iter 77000, loss: 0.353607
 >> iter 78000, loss: 0.377530
 >> iter 79000, loss: 0.457546
 >> iter 80000, loss: 0.419527
   Number of active neurons: 6
 >> iter 81000, loss: 0.443369
 >> iter 82000, loss: 0.438070
 >> iter 83000, loss: 0.580480
 >> iter 84000, loss: 0.442366
 >> iter 85000, loss: 0.664610
 >> iter 86000, loss: 0.426717
 >> iter 87000, loss: 0.450261
 >> iter 88000, loss: 0.406971
 >> iter 89000, loss: 0.400871
 >> iter 90000, loss: 0.459791
   Number of active neurons: 6
 >> iter 91000, loss: 0.521410
 >> iter 92000, loss: 0.725386
 >> iter 93000, loss: 0.693243
 >> iter 94000, loss: 0.567662
 >> iter 95000, loss: 0.480087
 >> iter 96000, loss: 0.537431
 >> iter 97000, loss: 0.498069
 >> iter 98000, loss: 0.401156
 >> iter 99000, loss: 0.348321
 >> iter 100000, loss: 0.277309
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.504410
 >> iter 2000, loss: 12.491768
 >> iter 3000, loss: 6.133257
 >> iter 4000, loss: 3.099006
 >> iter 5000, loss: 1.778989
 >> iter 6000, loss: 1.145644
 >> iter 7000, loss: 0.924314
 >> iter 8000, loss: 0.645601
 >> iter 9000, loss: 0.620115
 >> iter 10000, loss: 0.515699
   Number of active neurons: 5
 >> iter 11000, loss: 0.445486
 >> iter 12000, loss: 0.508578
 >> iter 13000, loss: 0.623626
 >> iter 14000, loss: 0.508590
 >> iter 15000, loss: 0.501045
 >> iter 16000, loss: 0.451089
 >> iter 17000, loss: 0.476123
 >> iter 18000, loss: 0.662007
 >> iter 19000, loss: 0.444068
 >> iter 20000, loss: 0.460034
   Number of active neurons: 5
 >> iter 21000, loss: 0.352268
 >> iter 22000, loss: 0.396723
 >> iter 23000, loss: 0.382396
 >> iter 24000, loss: 0.467527
 >> iter 25000, loss: 0.488631
 >> iter 26000, loss: 0.545581
 >> iter 27000, loss: 0.373945
 >> iter 28000, loss: 0.434051
 >> iter 29000, loss: 0.347565
 >> iter 30000, loss: 0.260083
   Number of active neurons: 5
 >> iter 31000, loss: 0.477075
 >> iter 32000, loss: 0.364804
 >> iter 33000, loss: 0.370709
 >> iter 34000, loss: 0.351693
 >> iter 35000, loss: 0.369094
 >> iter 36000, loss: 0.441437
 >> iter 37000, loss: 0.370394
 >> iter 38000, loss: 0.417559
 >> iter 39000, loss: 0.523707
 >> iter 40000, loss: 0.454053
   Number of active neurons: 5
 >> iter 41000, loss: 0.369331
 >> iter 42000, loss: 0.413011
 >> iter 43000, loss: 0.432864
 >> iter 44000, loss: 0.314234
 >> iter 45000, loss: 0.325815
 >> iter 46000, loss: 0.241561
 >> iter 47000, loss: 0.359186
 >> iter 48000, loss: 0.267499
 >> iter 49000, loss: 0.299682
 >> iter 50000, loss: 0.322161
   Number of active neurons: 5
 >> iter 51000, loss: 0.380322
 >> iter 52000, loss: 0.430562
 >> iter 53000, loss: 0.377290
 >> iter 54000, loss: 0.423129
 >> iter 55000, loss: 0.309645
 >> iter 56000, loss: 0.295314
 >> iter 57000, loss: 0.308827
 >> iter 58000, loss: 0.531375
 >> iter 59000, loss: 0.336580
 >> iter 60000, loss: 0.404134
   Number of active neurons: 5
 >> iter 61000, loss: 0.476966
 >> iter 62000, loss: 0.496326
 >> iter 63000, loss: 0.492453
 >> iter 64000, loss: 0.429623
 >> iter 65000, loss: 0.380358
 >> iter 66000, loss: 0.394669
 >> iter 67000, loss: 0.264957
 >> iter 68000, loss: 0.333052
 >> iter 69000, loss: 0.442724
 >> iter 70000, loss: 0.330971
   Number of active neurons: 5
 >> iter 71000, loss: 0.220346
 >> iter 72000, loss: 0.352427
 >> iter 73000, loss: 0.432244
 >> iter 74000, loss: 0.411532
 >> iter 75000, loss: 0.388409
 >> iter 76000, loss: 0.375977
 >> iter 77000, loss: 0.405778
 >> iter 78000, loss: 0.448347
 >> iter 79000, loss: 0.317813
 >> iter 80000, loss: 0.435673
   Number of active neurons: 5
 >> iter 81000, loss: 0.323812
 >> iter 82000, loss: 0.319935
 >> iter 83000, loss: 0.374832
 >> iter 84000, loss: 0.368026
 >> iter 85000, loss: 0.399943
 >> iter 86000, loss: 0.335729
 >> iter 87000, loss: 0.401986
 >> iter 88000, loss: 0.301686
 >> iter 89000, loss: 0.520448
 >> iter 90000, loss: 0.425584
   Number of active neurons: 5
 >> iter 91000, loss: 0.382365
 >> iter 92000, loss: 0.483825
 >> iter 93000, loss: 0.456157
 >> iter 94000, loss: 0.471545
 >> iter 95000, loss: 0.355094
 >> iter 96000, loss: 0.258175
 >> iter 97000, loss: 0.405277
 >> iter 98000, loss: 0.276689
 >> iter 99000, loss: 0.248297
 >> iter 100000, loss: 0.216916
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.061119
 >> iter 2000, loss: 13.816148
 >> iter 3000, loss: 11.687473
 >> iter 4000, loss: 10.408522
 >> iter 5000, loss: 10.024754
 >> iter 6000, loss: 9.515465
 >> iter 7000, loss: 9.577265
 >> iter 8000, loss: 9.327304
 >> iter 9000, loss: 9.412658
 >> iter 10000, loss: 9.139067
   Number of active neurons: 2
 >> iter 11000, loss: 9.257491
 >> iter 12000, loss: 9.108201
 >> iter 13000, loss: 9.278845
 >> iter 14000, loss: 9.093518
 >> iter 15000, loss: 8.959070
 >> iter 16000, loss: 6.525812
 >> iter 17000, loss: 5.300010
 >> iter 18000, loss: 4.773563
 >> iter 19000, loss: 4.033200
 >> iter 20000, loss: 2.973278
   Number of active neurons: 5
 >> iter 21000, loss: 2.747686
 >> iter 22000, loss: 2.134735
 >> iter 23000, loss: 1.655576
 >> iter 24000, loss: 1.049252
 >> iter 25000, loss: 0.897274
 >> iter 26000, loss: 0.598519
 >> iter 27000, loss: 0.459462
 >> iter 28000, loss: 0.332408
 >> iter 29000, loss: 0.344877
 >> iter 30000, loss: 0.359778
   Number of active neurons: 5
 >> iter 31000, loss: 0.319657
 >> iter 32000, loss: 0.277989
 >> iter 33000, loss: 0.200126
 >> iter 34000, loss: 0.315448
 >> iter 35000, loss: 0.287295
 >> iter 36000, loss: 0.212988
 >> iter 37000, loss: 0.256959
 >> iter 38000, loss: 0.291466
 >> iter 39000, loss: 0.276842
 >> iter 40000, loss: 0.238759
   Number of active neurons: 5
 >> iter 41000, loss: 0.258875
 >> iter 42000, loss: 0.248883
 >> iter 43000, loss: 0.428365
 >> iter 44000, loss: 0.514194
 >> iter 45000, loss: 0.451141
 >> iter 46000, loss: 0.386731
 >> iter 47000, loss: 0.458535
 >> iter 48000, loss: 0.407806
 >> iter 49000, loss: 0.304613
 >> iter 50000, loss: 0.408088
   Number of active neurons: 5
 >> iter 51000, loss: 0.360196
 >> iter 52000, loss: 0.516069
 >> iter 53000, loss: 0.590872
 >> iter 54000, loss: 0.422438
 >> iter 55000, loss: 0.527150
 >> iter 56000, loss: 0.405318
 >> iter 57000, loss: 0.553521
 >> iter 58000, loss: 0.378275
 >> iter 59000, loss: 0.478971
 >> iter 60000, loss: 0.375866
   Number of active neurons: 4
 >> iter 61000, loss: 0.442690
 >> iter 62000, loss: 0.440425
 >> iter 63000, loss: 0.370269
 >> iter 64000, loss: 0.475612
 >> iter 65000, loss: 0.402017
 >> iter 66000, loss: 0.384671
 >> iter 67000, loss: 0.302485
 >> iter 68000, loss: 0.416896
 >> iter 69000, loss: 0.334265
 >> iter 70000, loss: 0.338201
   Number of active neurons: 4
 >> iter 71000, loss: 0.465240
 >> iter 72000, loss: 0.452959
 >> iter 73000, loss: 0.454760
 >> iter 74000, loss: 0.296644
 >> iter 75000, loss: 0.228065
 >> iter 76000, loss: 0.367209
 >> iter 77000, loss: 0.367687
 >> iter 78000, loss: 0.368611
 >> iter 79000, loss: 0.408400
 >> iter 80000, loss: 0.342434
   Number of active neurons: 4
 >> iter 81000, loss: 0.360195
 >> iter 82000, loss: 0.338263
 >> iter 83000, loss: 0.584977
 >> iter 84000, loss: 0.535428
 >> iter 85000, loss: 0.377931
 >> iter 86000, loss: 0.316272
 >> iter 87000, loss: 0.366173
 >> iter 88000, loss: 0.341396
 >> iter 89000, loss: 0.331879
 >> iter 90000, loss: 0.435249
   Number of active neurons: 4
 >> iter 91000, loss: 0.458975
 >> iter 92000, loss: 0.469512
 >> iter 93000, loss: 0.333525
 >> iter 94000, loss: 0.485620
 >> iter 95000, loss: 0.337817
 >> iter 96000, loss: 0.345519
 >> iter 97000, loss: 0.391871
 >> iter 98000, loss: 0.500738
 >> iter 99000, loss: 0.478578
 >> iter 100000, loss: 0.434319
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.176447
 >> iter 2000, loss: 14.530802
 >> iter 3000, loss: 8.791620
 >> iter 4000, loss: 4.924843
 >> iter 5000, loss: 2.731487
 >> iter 6000, loss: 1.642811
 >> iter 7000, loss: 1.068244
 >> iter 8000, loss: 0.845049
 >> iter 9000, loss: 0.573807
 >> iter 10000, loss: 0.348313
   Number of active neurons: 5
 >> iter 11000, loss: 0.252493
 >> iter 12000, loss: 0.242737
 >> iter 13000, loss: 0.137917
 >> iter 14000, loss: 0.184425
 >> iter 15000, loss: 0.257900
 >> iter 16000, loss: 0.270728
 >> iter 17000, loss: 0.278769
 >> iter 18000, loss: 0.234715
 >> iter 19000, loss: 0.159573
 >> iter 20000, loss: 0.140910
   Number of active neurons: 5
 >> iter 21000, loss: 0.214361
 >> iter 22000, loss: 0.455129
 >> iter 23000, loss: 0.547651
 >> iter 24000, loss: 0.433185
 >> iter 25000, loss: 0.244010
 >> iter 26000, loss: 0.137459
 >> iter 27000, loss: 0.172722
 >> iter 28000, loss: 0.165235
 >> iter 29000, loss: 0.269019
 >> iter 30000, loss: 0.242706
   Number of active neurons: 5
 >> iter 31000, loss: 0.250305
 >> iter 32000, loss: 0.302137
 >> iter 33000, loss: 0.436876
 >> iter 34000, loss: 0.608607
 >> iter 35000, loss: 0.308848
 >> iter 36000, loss: 0.248372
 >> iter 37000, loss: 0.199438
 >> iter 38000, loss: 0.322139
 >> iter 39000, loss: 0.326278
 >> iter 40000, loss: 0.387813
   Number of active neurons: 5
 >> iter 41000, loss: 0.350526
 >> iter 42000, loss: 0.196181
 >> iter 43000, loss: 0.178956
 >> iter 44000, loss: 0.172008
 >> iter 45000, loss: 0.489381
 >> iter 46000, loss: 0.332317
 >> iter 47000, loss: 0.207522
 >> iter 48000, loss: 0.242754
 >> iter 49000, loss: 0.386829
 >> iter 50000, loss: 0.322002
   Number of active neurons: 5
 >> iter 51000, loss: 0.212388
 >> iter 52000, loss: 0.259383
 >> iter 53000, loss: 0.216108
 >> iter 54000, loss: 0.232786
 >> iter 55000, loss: 0.193051
 >> iter 56000, loss: 0.214650
 >> iter 57000, loss: 0.205531
 >> iter 58000, loss: 0.182282
 >> iter 59000, loss: 0.243717
 >> iter 60000, loss: 0.191554
   Number of active neurons: 5
 >> iter 61000, loss: 0.323358
 >> iter 62000, loss: 0.313305
 >> iter 63000, loss: 0.223209
 >> iter 64000, loss: 0.201952
 >> iter 65000, loss: 0.316412
 >> iter 66000, loss: 0.258112
 >> iter 67000, loss: 0.283387
 >> iter 68000, loss: 0.433323
 >> iter 69000, loss: 0.236003
 >> iter 70000, loss: 0.268654
   Number of active neurons: 5
 >> iter 71000, loss: 0.291920
 >> iter 72000, loss: 0.297573
 >> iter 73000, loss: 0.227241
 >> iter 74000, loss: 0.167949
 >> iter 75000, loss: 0.186731
 >> iter 76000, loss: 0.213134
 >> iter 77000, loss: 0.195233
 >> iter 78000, loss: 0.143825
 >> iter 79000, loss: 0.207146
 >> iter 80000, loss: 0.412112
   Number of active neurons: 4
 >> iter 81000, loss: 0.278711
 >> iter 82000, loss: 0.218154
 >> iter 83000, loss: 0.120389
 >> iter 84000, loss: 0.156797
 >> iter 85000, loss: 0.324383
 >> iter 86000, loss: 0.398945
 >> iter 87000, loss: 0.300075
 >> iter 88000, loss: 0.256008
 >> iter 89000, loss: 0.169954
 >> iter 90000, loss: 0.220581
   Number of active neurons: 4
 >> iter 91000, loss: 0.282790
 >> iter 92000, loss: 0.231713
 >> iter 93000, loss: 0.285587
 >> iter 94000, loss: 0.398594
 >> iter 95000, loss: 0.249852
 >> iter 96000, loss: 0.408622
 >> iter 97000, loss: 0.263299
 >> iter 98000, loss: 0.249714
 >> iter 99000, loss: 0.184221
 >> iter 100000, loss: 0.270172
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.128906
 >> iter 2000, loss: 15.415107
 >> iter 3000, loss: 12.323017
 >> iter 4000, loss: 10.543468
 >> iter 5000, loss: 9.984026
 >> iter 6000, loss: 9.506292
 >> iter 7000, loss: 8.768213
 >> iter 8000, loss: 8.276215
 >> iter 9000, loss: 8.200529
 >> iter 10000, loss: 7.828377
   Number of active neurons: 3
 >> iter 11000, loss: 7.931185
 >> iter 12000, loss: 7.797103
 >> iter 13000, loss: 7.863455
 >> iter 14000, loss: 6.594102
 >> iter 15000, loss: 5.680329
 >> iter 16000, loss: 4.515595
 >> iter 17000, loss: 2.755383
 >> iter 18000, loss: 1.420686
 >> iter 19000, loss: 0.922597
 >> iter 20000, loss: 0.592893
   Number of active neurons: 6
 >> iter 21000, loss: 0.462712
 >> iter 22000, loss: 0.384160
 >> iter 23000, loss: 0.246516
 >> iter 24000, loss: 0.497721
 >> iter 25000, loss: 0.474313
 >> iter 26000, loss: 0.531623
 >> iter 27000, loss: 0.423164
 >> iter 28000, loss: 0.359483
 >> iter 29000, loss: 0.526305
 >> iter 30000, loss: 0.363267
   Number of active neurons: 6
 >> iter 31000, loss: 0.586050
 >> iter 32000, loss: 0.406128
 >> iter 33000, loss: 0.441595
 >> iter 34000, loss: 0.347386
 >> iter 35000, loss: 0.301337
 >> iter 36000, loss: 0.354118
 >> iter 37000, loss: 0.323886
 >> iter 38000, loss: 0.481880
 >> iter 39000, loss: 0.527294
 >> iter 40000, loss: 0.378797
   Number of active neurons: 5
 >> iter 41000, loss: 0.524272
 >> iter 42000, loss: 0.454694
 >> iter 43000, loss: 0.341435
 >> iter 44000, loss: 0.292567
 >> iter 45000, loss: 0.357976
 >> iter 46000, loss: 0.382602
 >> iter 47000, loss: 0.420540
 >> iter 48000, loss: 0.426714
 >> iter 49000, loss: 0.518678
 >> iter 50000, loss: 0.425424
   Number of active neurons: 5
 >> iter 51000, loss: 0.522411
 >> iter 52000, loss: 0.386363
 >> iter 53000, loss: 0.450609
 >> iter 54000, loss: 0.421546
 >> iter 55000, loss: 0.581178
 >> iter 56000, loss: 0.566775
 >> iter 57000, loss: 0.400232
 >> iter 58000, loss: 0.420365
 >> iter 59000, loss: 0.452210
 >> iter 60000, loss: 0.372937
   Number of active neurons: 4
 >> iter 61000, loss: 0.347138
 >> iter 62000, loss: 0.300950
 >> iter 63000, loss: 0.502703
 >> iter 64000, loss: 0.436141
 >> iter 65000, loss: 0.658558
 >> iter 66000, loss: 0.510263
 >> iter 67000, loss: 0.347214
 >> iter 68000, loss: 0.503104
 >> iter 69000, loss: 0.416971
 >> iter 70000, loss: 0.367423
   Number of active neurons: 4
 >> iter 71000, loss: 0.347713
 >> iter 72000, loss: 0.336625
 >> iter 73000, loss: 0.499009
 >> iter 74000, loss: 0.325533
 >> iter 75000, loss: 0.377620
 >> iter 76000, loss: 0.388892
 >> iter 77000, loss: 0.516438
 >> iter 78000, loss: 0.364323
 >> iter 79000, loss: 0.296768
 >> iter 80000, loss: 0.329913
   Number of active neurons: 4
 >> iter 81000, loss: 0.383505
 >> iter 82000, loss: 0.458042
 >> iter 83000, loss: 0.527551
 >> iter 84000, loss: 0.425688
 >> iter 85000, loss: 0.379717
 >> iter 86000, loss: 0.409382
 >> iter 87000, loss: 0.480342
 >> iter 88000, loss: 0.416821
 >> iter 89000, loss: 0.363276
 >> iter 90000, loss: 0.268980
   Number of active neurons: 4
 >> iter 91000, loss: 0.504638
 >> iter 92000, loss: 0.495969
 >> iter 93000, loss: 0.531365
 >> iter 94000, loss: 0.418438
 >> iter 95000, loss: 0.450016
 >> iter 96000, loss: 0.432534
 >> iter 97000, loss: 0.526744
 >> iter 98000, loss: 0.403897
 >> iter 99000, loss: 0.521883
 >> iter 100000, loss: 0.383571
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.254273
 >> iter 2000, loss: 13.492141
 >> iter 3000, loss: 9.740675
 >> iter 4000, loss: 6.596643
 >> iter 5000, loss: 5.395279
 >> iter 6000, loss: 4.544549
 >> iter 7000, loss: 4.242027
 >> iter 8000, loss: 3.626130
 >> iter 9000, loss: 2.995339
 >> iter 10000, loss: 2.260826
   Number of active neurons: 5
 >> iter 11000, loss: 1.587079
 >> iter 12000, loss: 1.036947
 >> iter 13000, loss: 0.955791
 >> iter 14000, loss: 0.663006
 >> iter 15000, loss: 0.590132
 >> iter 16000, loss: 0.495971
 >> iter 17000, loss: 0.517334
 >> iter 18000, loss: 0.551836
 >> iter 19000, loss: 0.604626
 >> iter 20000, loss: 0.430750
   Number of active neurons: 5
 >> iter 21000, loss: 0.258262
 >> iter 22000, loss: 0.337232
 >> iter 23000, loss: 0.340459
 >> iter 24000, loss: 0.386492
 >> iter 25000, loss: 0.301286
 >> iter 26000, loss: 0.336391
 >> iter 27000, loss: 0.325065
 >> iter 28000, loss: 0.197161
 >> iter 29000, loss: 0.364818
 >> iter 30000, loss: 0.348363
   Number of active neurons: 5
 >> iter 31000, loss: 0.387192
 >> iter 32000, loss: 0.261653
 >> iter 33000, loss: 0.231844
 >> iter 34000, loss: 0.236123
 >> iter 35000, loss: 0.291894
 >> iter 36000, loss: 0.166615
 >> iter 37000, loss: 0.130064
 >> iter 38000, loss: 0.156543
 >> iter 39000, loss: 0.188082
 >> iter 40000, loss: 0.171800
   Number of active neurons: 5
 >> iter 41000, loss: 0.175828
 >> iter 42000, loss: 0.224276
 >> iter 43000, loss: 0.245784
 >> iter 44000, loss: 0.198621
 >> iter 45000, loss: 0.207543
 >> iter 46000, loss: 0.352777
 >> iter 47000, loss: 0.405634
 >> iter 48000, loss: 0.421371
 >> iter 49000, loss: 0.439358
 >> iter 50000, loss: 0.382704
   Number of active neurons: 5
 >> iter 51000, loss: 0.361169
 >> iter 52000, loss: 0.199606
 >> iter 53000, loss: 0.124641
 >> iter 54000, loss: 0.193172
 >> iter 55000, loss: 0.199272
 >> iter 56000, loss: 0.233783
 >> iter 57000, loss: 0.397475
 >> iter 58000, loss: 0.394356
 >> iter 59000, loss: 0.306856
 >> iter 60000, loss: 0.283288
   Number of active neurons: 5
 >> iter 61000, loss: 0.186703
 >> iter 62000, loss: 0.257629
 >> iter 63000, loss: 0.280117
 >> iter 64000, loss: 0.269225
 >> iter 65000, loss: 0.209338
 >> iter 66000, loss: 0.182296
 >> iter 67000, loss: 0.267638
 >> iter 68000, loss: 0.221990
 >> iter 69000, loss: 0.199054
 >> iter 70000, loss: 0.210650
   Number of active neurons: 5
 >> iter 71000, loss: 0.193007
 >> iter 72000, loss: 0.204232
 >> iter 73000, loss: 0.205320
 >> iter 74000, loss: 0.269118
 >> iter 75000, loss: 0.207036
 >> iter 76000, loss: 0.141065
 >> iter 77000, loss: 0.152186
 >> iter 78000, loss: 0.243223
 >> iter 79000, loss: 0.170789
 >> iter 80000, loss: 0.152592
   Number of active neurons: 5
 >> iter 81000, loss: 0.137523
 >> iter 82000, loss: 0.168460
 >> iter 83000, loss: 0.387375
 >> iter 84000, loss: 0.406504
 >> iter 85000, loss: 0.234352
 >> iter 86000, loss: 0.268564
 >> iter 87000, loss: 0.226326
 >> iter 88000, loss: 0.181935
 >> iter 89000, loss: 0.220878
 >> iter 90000, loss: 0.246477
   Number of active neurons: 5
 >> iter 91000, loss: 0.417817
 >> iter 92000, loss: 0.265677
 >> iter 93000, loss: 0.205037
 >> iter 94000, loss: 0.215054
 >> iter 95000, loss: 0.241810
 >> iter 96000, loss: 0.266950
 >> iter 97000, loss: 0.204497
 >> iter 98000, loss: 0.244122
 >> iter 99000, loss: 0.322896
 >> iter 100000, loss: 0.198665
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.336199
 >> iter 2000, loss: 13.953840
 >> iter 3000, loss: 9.657649
 >> iter 4000, loss: 5.028445
 >> iter 5000, loss: 2.673544
 >> iter 6000, loss: 1.533023
 >> iter 7000, loss: 1.000575
 >> iter 8000, loss: 0.819266
 >> iter 9000, loss: 0.715382
 >> iter 10000, loss: 0.620597
   Number of active neurons: 6
 >> iter 11000, loss: 0.442795
 >> iter 12000, loss: 0.392594
 >> iter 13000, loss: 0.530446
 >> iter 14000, loss: 0.379417
 >> iter 15000, loss: 0.870394
 >> iter 16000, loss: 0.625447
 >> iter 17000, loss: 0.592334
 >> iter 18000, loss: 0.449301
 >> iter 19000, loss: 0.495282
 >> iter 20000, loss: 0.462674
   Number of active neurons: 6
 >> iter 21000, loss: 0.546472
 >> iter 22000, loss: 0.533943
 >> iter 23000, loss: 0.818263
 >> iter 24000, loss: 0.689138
 >> iter 25000, loss: 0.543030
 >> iter 26000, loss: 0.536880
 >> iter 27000, loss: 0.513725
 >> iter 28000, loss: 0.471045
 >> iter 29000, loss: 0.572230
 >> iter 30000, loss: 0.376675
   Number of active neurons: 6
 >> iter 31000, loss: 0.368692
 >> iter 32000, loss: 0.402256
 >> iter 33000, loss: 0.365410
 >> iter 34000, loss: 0.385489
 >> iter 35000, loss: 0.406559
 >> iter 36000, loss: 0.469943
 >> iter 37000, loss: 0.366975
 >> iter 38000, loss: 0.400704
 >> iter 39000, loss: 0.407301
 >> iter 40000, loss: 0.462863
   Number of active neurons: 6
 >> iter 41000, loss: 0.309550
 >> iter 42000, loss: 0.278458
 >> iter 43000, loss: 0.359930
 >> iter 44000, loss: 0.445016
 >> iter 45000, loss: 0.636266
 >> iter 46000, loss: 0.641784
 >> iter 47000, loss: 0.497920
 >> iter 48000, loss: 0.540426
 >> iter 49000, loss: 0.598411
 >> iter 50000, loss: 0.411390
   Number of active neurons: 6
 >> iter 51000, loss: 0.406163
 >> iter 52000, loss: 0.414390
 >> iter 53000, loss: 0.400202
 >> iter 54000, loss: 0.568693
 >> iter 55000, loss: 0.529661
 >> iter 56000, loss: 0.578766
 >> iter 57000, loss: 0.480296
 >> iter 58000, loss: 0.349563
 >> iter 59000, loss: 0.321628
 >> iter 60000, loss: 0.360352
   Number of active neurons: 6
 >> iter 61000, loss: 0.534089
 >> iter 62000, loss: 0.654414
 >> iter 63000, loss: 0.619054
 >> iter 64000, loss: 0.526855
 >> iter 65000, loss: 0.396155
 >> iter 66000, loss: 0.311517
 >> iter 67000, loss: 0.436649
 >> iter 68000, loss: 0.315205
 >> iter 69000, loss: 0.523259
 >> iter 70000, loss: 0.552751
   Number of active neurons: 6
 >> iter 71000, loss: 0.542224
 >> iter 72000, loss: 0.439857
 >> iter 73000, loss: 0.553104
 >> iter 74000, loss: 0.440014
 >> iter 75000, loss: 0.401856
 >> iter 76000, loss: 0.458071
 >> iter 77000, loss: 0.458783
 >> iter 78000, loss: 0.376311
 >> iter 79000, loss: 0.457474
 >> iter 80000, loss: 0.440665
   Number of active neurons: 6
 >> iter 81000, loss: 0.541469
 >> iter 82000, loss: 0.568783
 >> iter 83000, loss: 0.467580
 >> iter 84000, loss: 0.524353
 >> iter 85000, loss: 0.528079
 >> iter 86000, loss: 0.341568
 >> iter 87000, loss: 0.551364
 >> iter 88000, loss: 0.394789
 >> iter 89000, loss: 0.475810
 >> iter 90000, loss: 0.435222
   Number of active neurons: 6
 >> iter 91000, loss: 0.455175
 >> iter 92000, loss: 0.327549
 >> iter 93000, loss: 0.416915
 >> iter 94000, loss: 0.409036
 >> iter 95000, loss: 0.402415
 >> iter 96000, loss: 0.442957
 >> iter 97000, loss: 0.368407
 >> iter 98000, loss: 0.289607
 >> iter 99000, loss: 0.270401
 >> iter 100000, loss: 0.165410
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

