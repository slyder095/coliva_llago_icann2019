 > Problema: tomita7nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 1e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.839819
 >> iter 2000, loss: 7.167695
 >> iter 3000, loss: 2.671828
 >> iter 4000, loss: 0.999788
 >> iter 5000, loss: 0.380035
 >> iter 6000, loss: 0.149098
 >> iter 7000, loss: 0.062912
 >> iter 8000, loss: 0.029936
 >> iter 9000, loss: 0.017290
 >> iter 10000, loss: 0.011907
   Number of active neurons: 10
 >> iter 11000, loss: 0.009682
 >> iter 12000, loss: 0.008385
 >> iter 13000, loss: 0.007771
 >> iter 14000, loss: 0.007212
 >> iter 15000, loss: 0.006930
 >> iter 16000, loss: 0.006579
 >> iter 17000, loss: 0.006419
 >> iter 18000, loss: 0.006159
 >> iter 19000, loss: 0.006051
 >> iter 20000, loss: 0.005844
   Number of active neurons: 10
 >> iter 21000, loss: 0.005774
 >> iter 22000, loss: 0.005597
 >> iter 23000, loss: 0.005550
 >> iter 24000, loss: 0.005403
 >> iter 25000, loss: 0.005380
 >> iter 26000, loss: 0.005248
 >> iter 27000, loss: 0.005231
 >> iter 28000, loss: 0.005115
 >> iter 29000, loss: 0.005112
 >> iter 30000, loss: 0.005016
   Number of active neurons: 10
 >> iter 31000, loss: 0.005027
 >> iter 32000, loss: 0.004950
 >> iter 33000, loss: 0.004951
 >> iter 34000, loss: 0.004892
 >> iter 35000, loss: 0.004882
 >> iter 36000, loss: 0.004803
 >> iter 37000, loss: 0.004818
 >> iter 38000, loss: 0.004784
 >> iter 39000, loss: 0.004756
 >> iter 40000, loss: 0.004664
   Number of active neurons: 10
 >> iter 41000, loss: 0.004696
 >> iter 42000, loss: 0.004653
 >> iter 43000, loss: 0.004640
 >> iter 44000, loss: 0.004565
 >> iter 45000, loss: 0.004578
 >> iter 46000, loss: 0.004534
 >> iter 47000, loss: 0.004518
 >> iter 48000, loss: 0.004478
 >> iter 49000, loss: 0.004453
 >> iter 50000, loss: 0.004429
   Number of active neurons: 10
 >> iter 51000, loss: 0.004398
 >> iter 52000, loss: 0.004376
 >> iter 53000, loss: 0.004343
 >> iter 54000, loss: 0.004327
 >> iter 55000, loss: 0.004318
 >> iter 56000, loss: 0.004310
 >> iter 57000, loss: 0.004314
 >> iter 58000, loss: 0.004382
 >> iter 59000, loss: 0.004291
 >> iter 60000, loss: 0.004268
   Number of active neurons: 10
 >> iter 61000, loss: 0.004264
 >> iter 62000, loss: 0.004365
 >> iter 63000, loss: 0.004261
 >> iter 64000, loss: 0.050719
 >> iter 65000, loss: 0.021996
 >> iter 66000, loss: 0.011080
 >> iter 67000, loss: 0.006964
 >> iter 68000, loss: 0.005346
 >> iter 69000, loss: 0.004781
 >> iter 70000, loss: 0.004528
   Number of active neurons: 10
 >> iter 71000, loss: 0.004501
 >> iter 72000, loss: 0.004496
 >> iter 73000, loss: 0.004475
 >> iter 74000, loss: 0.004436
 >> iter 75000, loss: 0.004435
 >> iter 76000, loss: 0.088488
 >> iter 77000, loss: 0.035674
 >> iter 78000, loss: 0.016187
 >> iter 79000, loss: 0.008722
 >> iter 80000, loss: 0.005858
   Number of active neurons: 10
 >> iter 81000, loss: 0.004829
 >> iter 82000, loss: 0.090720
 >> iter 83000, loss: 0.037222
 >> iter 84000, loss: 0.016909
 >> iter 85000, loss: 0.009169
 >> iter 86000, loss: 0.006319
 >> iter 87000, loss: 0.005033
 >> iter 88000, loss: 0.004434
 >> iter 89000, loss: 0.004325
 >> iter 90000, loss: 0.004193
   Number of active neurons: 10
 >> iter 91000, loss: 0.004150
 >> iter 92000, loss: 0.084785
 >> iter 93000, loss: 0.034673
 >> iter 94000, loss: 0.015686
 >> iter 95000, loss: 0.008482
 >> iter 96000, loss: 0.046426
 >> iter 97000, loss: 0.058856
 >> iter 98000, loss: 0.024626
 >> iter 99000, loss: 0.011684
 >> iter 100000, loss: 0.008247
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 40.2506499567
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.163227
 >> iter 2000, loss: 7.217658
 >> iter 3000, loss: 2.819736
 >> iter 4000, loss: 1.100044
 >> iter 5000, loss: 0.482889
 >> iter 6000, loss: 0.223838
 >> iter 7000, loss: 0.159051
 >> iter 8000, loss: 0.068634
 >> iter 9000, loss: 0.111458
 >> iter 10000, loss: 0.120519
   Number of active neurons: 10
 >> iter 11000, loss: 0.095610
 >> iter 12000, loss: 0.041337
 >> iter 13000, loss: 0.020333
 >> iter 14000, loss: 0.012174
 >> iter 15000, loss: 0.008585
 >> iter 16000, loss: 0.007437
 >> iter 17000, loss: 0.006474
 >> iter 18000, loss: 0.005835
 >> iter 19000, loss: 0.005573
 >> iter 20000, loss: 0.023096
   Number of active neurons: 10
 >> iter 21000, loss: 0.015097
 >> iter 22000, loss: 0.009309
 >> iter 23000, loss: 0.006817
 >> iter 24000, loss: 0.007006
 >> iter 25000, loss: 0.005886
 >> iter 26000, loss: 0.050138
 >> iter 27000, loss: 0.076263
 >> iter 28000, loss: 0.067147
 >> iter 29000, loss: 0.134741
 >> iter 30000, loss: 0.075711
   Number of active neurons: 10
 >> iter 31000, loss: 0.063137
 >> iter 32000, loss: 0.031218
 >> iter 33000, loss: 0.128293
 >> iter 34000, loss: 0.054783
 >> iter 35000, loss: 0.051505
 >> iter 36000, loss: 0.024051
 >> iter 37000, loss: 0.025793
 >> iter 38000, loss: 0.027743
 >> iter 39000, loss: 0.062024
 >> iter 40000, loss: 0.051536
   Number of active neurons: 10
 >> iter 41000, loss: 0.036356
 >> iter 42000, loss: 0.017326
 >> iter 43000, loss: 0.073403
 >> iter 44000, loss: 0.032366
 >> iter 45000, loss: 0.016154
 >> iter 46000, loss: 0.012046
 >> iter 47000, loss: 0.036845
 >> iter 48000, loss: 0.017104
 >> iter 49000, loss: 0.013063
 >> iter 50000, loss: 0.008040
   Number of active neurons: 10
 >> iter 51000, loss: 0.006006
 >> iter 52000, loss: 0.046127
 >> iter 53000, loss: 0.106909
 >> iter 54000, loss: 0.044452
 >> iter 55000, loss: 0.052117
 >> iter 56000, loss: 0.065031
 >> iter 57000, loss: 0.053579
 >> iter 58000, loss: 0.042220
 >> iter 59000, loss: 0.043474
 >> iter 60000, loss: 0.020830
   Number of active neurons: 10
 >> iter 61000, loss: 0.011584
 >> iter 62000, loss: 0.007661
 >> iter 63000, loss: 0.006040
 >> iter 64000, loss: 0.005177
 >> iter 65000, loss: 0.042550
 >> iter 66000, loss: 0.019592
 >> iter 67000, loss: 0.010552
 >> iter 68000, loss: 0.006861
 >> iter 69000, loss: 0.005364
 >> iter 70000, loss: 0.050552
   Number of active neurons: 10
 >> iter 71000, loss: 0.022871
 >> iter 72000, loss: 0.011699
 >> iter 73000, loss: 0.007193
 >> iter 74000, loss: 0.005336
 >> iter 75000, loss: 0.004564
 >> iter 76000, loss: 0.096794
 >> iter 77000, loss: 0.061787
 >> iter 78000, loss: 0.026756
 >> iter 79000, loss: 0.013264
 >> iter 80000, loss: 0.032198
   Number of active neurons: 10
 >> iter 81000, loss: 0.015766
 >> iter 82000, loss: 0.013693
 >> iter 83000, loss: 0.008165
 >> iter 84000, loss: 0.005816
 >> iter 85000, loss: 0.004849
 >> iter 86000, loss: 0.051542
 >> iter 87000, loss: 0.022154
 >> iter 88000, loss: 0.015465
 >> iter 89000, loss: 0.008700
 >> iter 90000, loss: 0.005928
   Number of active neurons: 10
 >> iter 91000, loss: 0.004805
 >> iter 92000, loss: 0.004344
 >> iter 93000, loss: 0.004137
 >> iter 94000, loss: 0.004020
 >> iter 95000, loss: 0.003985
 >> iter 96000, loss: 0.003948
 >> iter 97000, loss: 0.003958
 >> iter 98000, loss: 0.003948
 >> iter 99000, loss: 0.003970
 >> iter 100000, loss: 0.003968
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 15.1456569562
   - Test - B: 15.7789480701
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.636810
 >> iter 2000, loss: 8.761984
 >> iter 3000, loss: 3.431593
 >> iter 4000, loss: 1.273954
 >> iter 5000, loss: 0.475523
 >> iter 6000, loss: 0.202426
 >> iter 7000, loss: 0.079787
 >> iter 8000, loss: 0.033256
 >> iter 9000, loss: 0.015716
 >> iter 10000, loss: 0.229753
   Number of active neurons: 10
 >> iter 11000, loss: 0.093679
 >> iter 12000, loss: 0.039670
 >> iter 13000, loss: 0.023400
 >> iter 14000, loss: 0.012473
 >> iter 15000, loss: 0.007971
 >> iter 16000, loss: 0.005914
 >> iter 17000, loss: 0.005050
 >> iter 18000, loss: 0.034231
 >> iter 19000, loss: 0.015798
 >> iter 20000, loss: 0.008601
   Number of active neurons: 10
 >> iter 21000, loss: 0.005840
 >> iter 22000, loss: 0.031954
 >> iter 23000, loss: 0.014847
 >> iter 24000, loss: 0.008254
 >> iter 25000, loss: 0.232324
 >> iter 26000, loss: 0.091734
 >> iter 27000, loss: 0.038049
 >> iter 28000, loss: 0.066999
 >> iter 29000, loss: 0.028856
 >> iter 30000, loss: 0.013895
   Number of active neurons: 10
 >> iter 31000, loss: 0.008092
 >> iter 32000, loss: 0.020610
 >> iter 33000, loss: 0.093895
 >> iter 34000, loss: 0.037979
 >> iter 35000, loss: 0.016941
 >> iter 36000, loss: 0.008905
 >> iter 37000, loss: 0.005892
 >> iter 38000, loss: 0.004621
 >> iter 39000, loss: 0.004150
 >> iter 40000, loss: 0.467259
   Number of active neurons: 10
 >> iter 41000, loss: 0.179470
 >> iter 42000, loss: 0.081668
 >> iter 43000, loss: 0.034510
 >> iter 44000, loss: 0.016270
 >> iter 45000, loss: 0.009255
 >> iter 46000, loss: 0.006373
 >> iter 47000, loss: 0.005181
 >> iter 48000, loss: 0.088986
 >> iter 49000, loss: 0.036984
 >> iter 50000, loss: 0.016979
   Number of active neurons: 10
 >> iter 51000, loss: 0.016401
 >> iter 52000, loss: 0.008998
 >> iter 53000, loss: 0.006108
 >> iter 54000, loss: 0.015647
 >> iter 55000, loss: 0.008532
 >> iter 56000, loss: 0.005566
 >> iter 57000, loss: 0.041928
 >> iter 58000, loss: 0.028373
 >> iter 59000, loss: 0.013484
 >> iter 60000, loss: 0.007485
   Number of active neurons: 10
 >> iter 61000, loss: 0.005194
 >> iter 62000, loss: 0.004243
 >> iter 63000, loss: 0.003888
 >> iter 64000, loss: 0.003715
 >> iter 65000, loss: 0.003641
 >> iter 66000, loss: 0.003544
 >> iter 67000, loss: 0.003536
 >> iter 68000, loss: 0.139881
 >> iter 69000, loss: 0.055740
 >> iter 70000, loss: 0.024036
   Number of active neurons: 10
 >> iter 71000, loss: 0.012060
 >> iter 72000, loss: 0.046822
 >> iter 73000, loss: 0.020851
 >> iter 74000, loss: 0.041801
 >> iter 75000, loss: 0.019642
 >> iter 76000, loss: 0.010292
 >> iter 77000, loss: 0.006638
 >> iter 78000, loss: 0.005128
 >> iter 79000, loss: 0.004455
 >> iter 80000, loss: 0.004065
   Number of active neurons: 10
 >> iter 81000, loss: 0.030785
 >> iter 82000, loss: 0.014025
 >> iter 83000, loss: 0.007633
 >> iter 84000, loss: 0.005111
 >> iter 85000, loss: 0.019941
 >> iter 86000, loss: 0.009929
 >> iter 87000, loss: 0.006027
 >> iter 88000, loss: 0.004437
 >> iter 89000, loss: 0.021175
 >> iter 90000, loss: 0.010191
   Number of active neurons: 10
 >> iter 91000, loss: 0.006086
 >> iter 92000, loss: 0.004477
 >> iter 93000, loss: 0.003905
 >> iter 94000, loss: 0.003627
 >> iter 95000, loss: 0.003560
 >> iter 96000, loss: 0.069102
 >> iter 97000, loss: 0.028050
 >> iter 98000, loss: 0.012630
 >> iter 99000, loss: 0.006916
 >> iter 100000, loss: 0.004709
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 20.3053129791
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.095165
 >> iter 2000, loss: 6.846359
 >> iter 3000, loss: 2.610868
 >> iter 4000, loss: 0.977331
 >> iter 5000, loss: 0.408890
 >> iter 6000, loss: 0.160489
 >> iter 7000, loss: 0.067286
 >> iter 8000, loss: 0.046358
 >> iter 9000, loss: 0.024056
 >> iter 10000, loss: 0.014468
   Number of active neurons: 10
 >> iter 11000, loss: 0.010604
 >> iter 12000, loss: 0.008574
 >> iter 13000, loss: 0.007872
 >> iter 14000, loss: 0.007127
 >> iter 15000, loss: 0.112586
 >> iter 16000, loss: 0.046585
 >> iter 17000, loss: 0.021805
 >> iter 18000, loss: 0.046290
 >> iter 19000, loss: 0.021782
 >> iter 20000, loss: 0.042953
   Number of active neurons: 10
 >> iter 21000, loss: 0.020850
 >> iter 22000, loss: 0.055338
 >> iter 23000, loss: 0.025727
 >> iter 24000, loss: 0.013932
 >> iter 25000, loss: 0.009866
 >> iter 26000, loss: 0.007496
 >> iter 27000, loss: 0.006511
 >> iter 28000, loss: 0.037390
 >> iter 29000, loss: 0.018049
 >> iter 30000, loss: 0.010197
   Number of active neurons: 10
 >> iter 31000, loss: 0.019354
 >> iter 32000, loss: 0.010561
 >> iter 33000, loss: 0.007246
 >> iter 34000, loss: 0.006101
 >> iter 35000, loss: 0.005547
 >> iter 36000, loss: 0.242267
 >> iter 37000, loss: 0.095827
 >> iter 38000, loss: 0.087418
 >> iter 39000, loss: 0.037808
 >> iter 40000, loss: 0.018002
   Number of active neurons: 10
 >> iter 41000, loss: 0.010454
 >> iter 42000, loss: 0.011301
 >> iter 43000, loss: 0.007759
 >> iter 44000, loss: 0.096133
 >> iter 45000, loss: 0.043139
 >> iter 46000, loss: 0.020210
 >> iter 47000, loss: 0.011045
 >> iter 48000, loss: 0.045437
 >> iter 49000, loss: 0.020912
 >> iter 50000, loss: 0.010853
   Number of active neurons: 10
 >> iter 51000, loss: 0.006972
 >> iter 52000, loss: 0.790379
 >> iter 53000, loss: 0.937827
 >> iter 54000, loss: 0.358361
 >> iter 55000, loss: 0.140802
 >> iter 56000, loss: 0.058422
 >> iter 57000, loss: 0.077883
 >> iter 58000, loss: 0.034473
 >> iter 59000, loss: 0.017628
 >> iter 60000, loss: 0.010760
   Number of active neurons: 10
 >> iter 61000, loss: 0.008023
 >> iter 62000, loss: 0.006622
 >> iter 63000, loss: 0.006056
 >> iter 64000, loss: 0.005586
 >> iter 65000, loss: 0.005415
 >> iter 66000, loss: 0.005116
 >> iter 67000, loss: 0.005075
 >> iter 68000, loss: 0.004852
 >> iter 69000, loss: 0.004900
 >> iter 70000, loss: 0.004699
   Number of active neurons: 10
 >> iter 71000, loss: 0.004779
 >> iter 72000, loss: 0.083106
 >> iter 73000, loss: 0.034214
 >> iter 74000, loss: 0.015743
 >> iter 75000, loss: 0.008905
 >> iter 76000, loss: 0.321886
 >> iter 77000, loss: 0.127766
 >> iter 78000, loss: 0.056547
 >> iter 79000, loss: 0.025514
 >> iter 80000, loss: 0.013357
   Number of active neurons: 10
 >> iter 81000, loss: 0.008648
 >> iter 82000, loss: 0.006574
 >> iter 83000, loss: 0.005784
 >> iter 84000, loss: 0.005231
 >> iter 85000, loss: 0.005076
 >> iter 86000, loss: 0.004820
 >> iter 87000, loss: 0.004798
 >> iter 88000, loss: 0.004646
 >> iter 89000, loss: 0.004670
 >> iter 90000, loss: 0.004661
   Number of active neurons: 10
 >> iter 91000, loss: 0.004615
 >> iter 92000, loss: 0.005245
 >> iter 93000, loss: 0.005014
 >> iter 94000, loss: 0.105202
 >> iter 95000, loss: 0.042963
 >> iter 96000, loss: 0.019112
 >> iter 97000, loss: 0.018067
 >> iter 98000, loss: 0.009813
 >> iter 99000, loss: 0.006585
 >> iter 100000, loss: 0.005148
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 18.0121325245
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.332187
 >> iter 2000, loss: 7.692590
 >> iter 3000, loss: 2.849810
 >> iter 4000, loss: 1.057524
 >> iter 5000, loss: 0.395795
 >> iter 6000, loss: 0.150898
 >> iter 7000, loss: 0.060173
 >> iter 8000, loss: 0.026190
 >> iter 9000, loss: 0.013432
 >> iter 10000, loss: 0.317524
   Number of active neurons: 10
 >> iter 11000, loss: 0.128548
 >> iter 12000, loss: 0.053831
 >> iter 13000, loss: 0.024828
 >> iter 14000, loss: 0.013222
 >> iter 15000, loss: 0.008483
 >> iter 16000, loss: 0.006346
 >> iter 17000, loss: 0.005371
 >> iter 18000, loss: 0.004809
 >> iter 19000, loss: 0.004516
 >> iter 20000, loss: 0.004291
   Number of active neurons: 10
 >> iter 21000, loss: 0.099815
 >> iter 22000, loss: 0.040135
 >> iter 23000, loss: 0.017833
 >> iter 24000, loss: 0.009390
 >> iter 25000, loss: 0.006192
 >> iter 26000, loss: 0.004883
 >> iter 27000, loss: 0.004357
 >> iter 28000, loss: 0.004070
 >> iter 29000, loss: 0.003939
 >> iter 30000, loss: 0.003815
   Number of active neurons: 10
 >> iter 31000, loss: 0.003752
 >> iter 32000, loss: 0.003685
 >> iter 33000, loss: 0.003628
 >> iter 34000, loss: 0.105691
 >> iter 35000, loss: 0.042458
 >> iter 36000, loss: 0.045953
 >> iter 37000, loss: 0.020315
 >> iter 38000, loss: 0.010446
 >> iter 39000, loss: 0.006587
 >> iter 40000, loss: 0.004999
   Number of active neurons: 10
 >> iter 41000, loss: 0.103523
 >> iter 42000, loss: 0.041496
 >> iter 43000, loss: 0.018249
 >> iter 44000, loss: 0.009461
 >> iter 45000, loss: 0.006107
 >> iter 46000, loss: 0.004756
 >> iter 47000, loss: 0.004201
 >> iter 48000, loss: 0.003926
 >> iter 49000, loss: 0.003792
 >> iter 50000, loss: 0.003921
   Number of active neurons: 10
 >> iter 51000, loss: 0.090405
 >> iter 52000, loss: 0.036084
 >> iter 53000, loss: 0.015820
 >> iter 54000, loss: 0.008239
 >> iter 55000, loss: 0.005401
 >> iter 56000, loss: 0.004314
 >> iter 57000, loss: 0.003893
 >> iter 58000, loss: 0.044528
 >> iter 59000, loss: 0.019280
 >> iter 60000, loss: 0.009720
   Number of active neurons: 10
 >> iter 61000, loss: 0.006082
 >> iter 62000, loss: 0.004647
 >> iter 63000, loss: 0.004072
 >> iter 64000, loss: 0.003792
 >> iter 65000, loss: 0.101241
 >> iter 66000, loss: 0.040278
 >> iter 67000, loss: 0.017492
 >> iter 68000, loss: 0.008948
 >> iter 69000, loss: 0.005735
 >> iter 70000, loss: 0.004483
   Number of active neurons: 10
 >> iter 71000, loss: 0.003984
 >> iter 72000, loss: 0.334111
 >> iter 73000, loss: 0.129705
 >> iter 74000, loss: 0.162517
 >> iter 75000, loss: 0.084074
 >> iter 76000, loss: 0.065027
 >> iter 77000, loss: 0.028893
 >> iter 78000, loss: 0.014611
 >> iter 79000, loss: 0.008871
 >> iter 80000, loss: 0.006647
   Number of active neurons: 10
 >> iter 81000, loss: 0.005433
 >> iter 82000, loss: 0.004770
 >> iter 83000, loss: 0.004407
 >> iter 84000, loss: 0.004163
 >> iter 85000, loss: 0.004013
 >> iter 86000, loss: 0.003944
 >> iter 87000, loss: 0.003840
 >> iter 88000, loss: 0.003831
 >> iter 89000, loss: 0.003753
 >> iter 90000, loss: 0.003775
   Number of active neurons: 10
 >> iter 91000, loss: 0.003682
 >> iter 92000, loss: 0.102224
 >> iter 93000, loss: 0.041124
 >> iter 94000, loss: 0.018272
 >> iter 95000, loss: 0.009628
 >> iter 96000, loss: 0.006307
 >> iter 97000, loss: 0.004972
 >> iter 98000, loss: 0.004518
 >> iter 99000, loss: 0.004193
 >> iter 100000, loss: 0.004025
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 1.89320711953
   - Test - B: 9.64602359843
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.085792
 >> iter 2000, loss: 9.449900
 >> iter 3000, loss: 3.702051
 >> iter 4000, loss: 1.383296
 >> iter 5000, loss: 0.842198
 >> iter 6000, loss: 0.403938
 >> iter 7000, loss: 0.158040
 >> iter 8000, loss: 0.078462
 >> iter 9000, loss: 0.092936
 >> iter 10000, loss: 0.041116
   Number of active neurons: 10
 >> iter 11000, loss: 0.056056
 >> iter 12000, loss: 0.026365
 >> iter 13000, loss: 0.043507
 >> iter 14000, loss: 0.034886
 >> iter 15000, loss: 0.017084
 >> iter 16000, loss: 0.067505
 >> iter 17000, loss: 0.048544
 >> iter 18000, loss: 0.021985
 >> iter 19000, loss: 0.015244
 >> iter 20000, loss: 0.009027
   Number of active neurons: 10
 >> iter 21000, loss: 0.060690
 >> iter 22000, loss: 0.026788
 >> iter 23000, loss: 0.039650
 >> iter 24000, loss: 0.029980
 >> iter 25000, loss: 0.014995
 >> iter 26000, loss: 0.008645
 >> iter 27000, loss: 0.067573
 >> iter 28000, loss: 0.029380
 >> iter 29000, loss: 0.048244
 >> iter 30000, loss: 0.021616
   Number of active neurons: 10
 >> iter 31000, loss: 0.123977
 >> iter 32000, loss: 0.053513
 >> iter 33000, loss: 0.023929
 >> iter 34000, loss: 0.012355
 >> iter 35000, loss: 0.007832
 >> iter 36000, loss: 0.005868
 >> iter 37000, loss: 0.005060
 >> iter 38000, loss: 0.004568
 >> iter 39000, loss: 0.004370
 >> iter 40000, loss: 0.004159
   Number of active neurons: 10
 >> iter 41000, loss: 0.004104
 >> iter 42000, loss: 0.003969
 >> iter 43000, loss: 0.003965
 >> iter 44000, loss: 0.003871
 >> iter 45000, loss: 0.003885
 >> iter 46000, loss: 0.003799
 >> iter 47000, loss: 0.003829
 >> iter 48000, loss: 0.003753
 >> iter 49000, loss: 0.003788
 >> iter 50000, loss: 0.003706
   Number of active neurons: 10
 >> iter 51000, loss: 0.003746
 >> iter 52000, loss: 0.003665
 >> iter 53000, loss: 0.003716
 >> iter 54000, loss: 0.003638
 >> iter 55000, loss: 0.003696
 >> iter 56000, loss: 0.003618
 >> iter 57000, loss: 0.003704
 >> iter 58000, loss: 0.003604
 >> iter 59000, loss: 0.003665
 >> iter 60000, loss: 0.003588
   Number of active neurons: 10
 >> iter 61000, loss: 0.038776
 >> iter 62000, loss: 0.017535
 >> iter 63000, loss: 0.009227
 >> iter 64000, loss: 0.005887
 >> iter 65000, loss: 0.004607
 >> iter 66000, loss: 0.004007
 >> iter 67000, loss: 0.107254
 >> iter 68000, loss: 0.042806
 >> iter 69000, loss: 0.018795
 >> iter 70000, loss: 0.009584
   Number of active neurons: 10
 >> iter 71000, loss: 0.096367
 >> iter 72000, loss: 0.039188
 >> iter 73000, loss: 0.063013
 >> iter 74000, loss: 0.026785
 >> iter 75000, loss: 0.012943
 >> iter 76000, loss: 0.007573
 >> iter 77000, loss: 0.079867
 >> iter 78000, loss: 0.034751
 >> iter 79000, loss: 0.016560
 >> iter 80000, loss: 0.009275
   Number of active neurons: 9
 >> iter 81000, loss: 0.006371
 >> iter 82000, loss: 0.005068
 >> iter 83000, loss: 0.038140
 >> iter 84000, loss: 0.017503
 >> iter 85000, loss: 0.032573
 >> iter 86000, loss: 0.015234
 >> iter 87000, loss: 0.008460
 >> iter 88000, loss: 0.005704
 >> iter 89000, loss: 0.031497
 >> iter 90000, loss: 0.014558
   Number of active neurons: 9
 >> iter 91000, loss: 0.008025
 >> iter 92000, loss: 0.005415
 >> iter 93000, loss: 0.031389
 >> iter 94000, loss: 0.014544
 >> iter 95000, loss: 0.008010
 >> iter 96000, loss: 0.005374
 >> iter 97000, loss: 0.130297
 >> iter 98000, loss: 0.057726
 >> iter 99000, loss: 0.024776
 >> iter 100000, loss: 0.012054
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 17.4988334111
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.199201
 >> iter 2000, loss: 8.744925
 >> iter 3000, loss: 3.353172
 >> iter 4000, loss: 1.249652
 >> iter 5000, loss: 0.469245
 >> iter 6000, loss: 0.179483
 >> iter 7000, loss: 0.071707
 >> iter 8000, loss: 0.031199
 >> iter 9000, loss: 0.015824
 >> iter 10000, loss: 0.009720
   Number of active neurons: 10
 >> iter 11000, loss: 0.073295
 >> iter 12000, loss: 0.031419
 >> iter 13000, loss: 0.015436
 >> iter 14000, loss: 0.009174
 >> iter 15000, loss: 0.006664
 >> iter 16000, loss: 0.005491
 >> iter 17000, loss: 0.005006
 >> iter 18000, loss: 0.004655
 >> iter 19000, loss: 0.004526
 >> iter 20000, loss: 0.004346
   Number of active neurons: 10
 >> iter 21000, loss: 0.004302
 >> iter 22000, loss: 0.004167
 >> iter 23000, loss: 0.004165
 >> iter 24000, loss: 0.004053
 >> iter 25000, loss: 0.004060
 >> iter 26000, loss: 0.003971
 >> iter 27000, loss: 0.004098
 >> iter 28000, loss: 0.003968
 >> iter 29000, loss: 0.003922
 >> iter 30000, loss: 0.003840
   Number of active neurons: 10
 >> iter 31000, loss: 0.003934
 >> iter 32000, loss: 0.003813
 >> iter 33000, loss: 0.287645
 >> iter 34000, loss: 0.110738
 >> iter 35000, loss: 0.044777
 >> iter 36000, loss: 0.019942
 >> iter 37000, loss: 0.010636
 >> iter 38000, loss: 0.006924
 >> iter 39000, loss: 0.005521
 >> iter 40000, loss: 0.004803
   Number of active neurons: 10
 >> iter 41000, loss: 0.004564
 >> iter 42000, loss: 0.004318
 >> iter 43000, loss: 0.004325
 >> iter 44000, loss: 0.004144
 >> iter 45000, loss: 0.004145
 >> iter 46000, loss: 0.004021
 >> iter 47000, loss: 0.474186
 >> iter 48000, loss: 0.183725
 >> iter 49000, loss: 0.073606
 >> iter 50000, loss: 0.031801
   Number of active neurons: 10
 >> iter 51000, loss: 0.015869
 >> iter 52000, loss: 0.009521
 >> iter 53000, loss: 0.006968
 >> iter 54000, loss: 0.005764
 >> iter 55000, loss: 0.005243
 >> iter 56000, loss: 0.004847
 >> iter 57000, loss: 0.079099
 >> iter 58000, loss: 0.033239
 >> iter 59000, loss: 0.015661
 >> iter 60000, loss: 0.008761
   Number of active neurons: 10
 >> iter 61000, loss: 0.082141
 >> iter 62000, loss: 0.034729
 >> iter 63000, loss: 0.016173
 >> iter 64000, loss: 0.008909
 >> iter 65000, loss: 0.006025
 >> iter 66000, loss: 0.004804
 >> iter 67000, loss: 0.004273
 >> iter 68000, loss: 0.004003
 >> iter 69000, loss: 0.003852
 >> iter 70000, loss: 0.205169
   Number of active neurons: 10
 >> iter 71000, loss: 0.080776
 >> iter 72000, loss: 0.033823
 >> iter 73000, loss: 0.016113
 >> iter 74000, loss: 0.009193
 >> iter 75000, loss: 0.006479
 >> iter 76000, loss: 0.005252
 >> iter 77000, loss: 0.004718
 >> iter 78000, loss: 0.004382
 >> iter 79000, loss: 0.004217
 >> iter 80000, loss: 0.030428
   Number of active neurons: 10
 >> iter 81000, loss: 0.099834
 >> iter 82000, loss: 0.041042
 >> iter 83000, loss: 0.018568
 >> iter 84000, loss: 0.009846
 >> iter 85000, loss: 0.006456
 >> iter 86000, loss: 0.005000
 >> iter 87000, loss: 0.004406
 >> iter 88000, loss: 0.004074
 >> iter 89000, loss: 0.165280
 >> iter 90000, loss: 0.064958
   Number of active neurons: 10
 >> iter 91000, loss: 0.027401
 >> iter 92000, loss: 0.013227
 >> iter 93000, loss: 0.007853
 >> iter 94000, loss: 0.005747
 >> iter 95000, loss: 0.004858
 >> iter 96000, loss: 0.011739
 >> iter 97000, loss: 0.007000
 >> iter 98000, loss: 0.006847
 >> iter 99000, loss: 0.005080
 >> iter 100000, loss: 0.004297
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0019999600008
   - Test - Long: 0.0
   - Test - Big: 0.00599994000061
   - Test - A: 19.3787080861
   - Test - B: 17.7454836344
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.871025
 >> iter 2000, loss: 7.998143
 >> iter 3000, loss: 3.053077
 >> iter 4000, loss: 1.134366
 >> iter 5000, loss: 0.424086
 >> iter 6000, loss: 0.161091
 >> iter 7000, loss: 0.063549
 >> iter 8000, loss: 0.027098
 >> iter 9000, loss: 0.103065
 >> iter 10000, loss: 0.043042
   Number of active neurons: 10
 >> iter 11000, loss: 0.019871
 >> iter 12000, loss: 0.010757
 >> iter 13000, loss: 0.159082
 >> iter 14000, loss: 0.064071
 >> iter 15000, loss: 0.027728
 >> iter 16000, loss: 0.013733
 >> iter 17000, loss: 0.143739
 >> iter 18000, loss: 0.058366
 >> iter 19000, loss: 0.025737
 >> iter 20000, loss: 0.013093
   Number of active neurons: 10
 >> iter 21000, loss: 0.008586
 >> iter 22000, loss: 0.006165
 >> iter 23000, loss: 0.005113
 >> iter 24000, loss: 0.004562
 >> iter 25000, loss: 0.004330
 >> iter 26000, loss: 0.004138
 >> iter 27000, loss: 0.189326
 >> iter 28000, loss: 0.112993
 >> iter 29000, loss: 0.046904
 >> iter 30000, loss: 0.021255
   Number of active neurons: 10
 >> iter 31000, loss: 0.011274
 >> iter 32000, loss: 0.007208
 >> iter 33000, loss: 0.005529
 >> iter 34000, loss: 0.004719
 >> iter 35000, loss: 0.085259
 >> iter 36000, loss: 0.034372
 >> iter 37000, loss: 0.015490
 >> iter 38000, loss: 0.008371
 >> iter 39000, loss: 0.092549
 >> iter 40000, loss: 0.061239
   Number of active neurons: 10
 >> iter 41000, loss: 0.025802
 >> iter 42000, loss: 0.012450
 >> iter 43000, loss: 0.146612
 >> iter 44000, loss: 0.059166
 >> iter 45000, loss: 0.083075
 >> iter 46000, loss: 0.035576
 >> iter 47000, loss: 0.047221
 >> iter 48000, loss: 0.021570
 >> iter 49000, loss: 0.011425
 >> iter 50000, loss: 0.007297
   Number of active neurons: 10
 >> iter 51000, loss: 0.005606
 >> iter 52000, loss: 0.004809
 >> iter 53000, loss: 0.004439
 >> iter 54000, loss: 0.004192
 >> iter 55000, loss: 0.177334
 >> iter 56000, loss: 0.097365
 >> iter 57000, loss: 0.040265
 >> iter 58000, loss: 0.018349
 >> iter 59000, loss: 0.009854
 >> iter 60000, loss: 0.006445
   Number of active neurons: 10
 >> iter 61000, loss: 0.005053
 >> iter 62000, loss: 0.004406
 >> iter 63000, loss: 0.005712
 >> iter 64000, loss: 0.004548
 >> iter 65000, loss: 0.003875
 >> iter 66000, loss: 0.003546
 >> iter 67000, loss: 0.003418
 >> iter 68000, loss: 0.003346
 >> iter 69000, loss: 0.003338
 >> iter 70000, loss: 0.003314
   Number of active neurons: 10
 >> iter 71000, loss: 0.003326
 >> iter 72000, loss: 0.003310
 >> iter 73000, loss: 0.003327
 >> iter 74000, loss: 0.003307
 >> iter 75000, loss: 0.022872
 >> iter 76000, loss: 0.010718
 >> iter 77000, loss: 0.006058
 >> iter 78000, loss: 0.004268
 >> iter 79000, loss: 0.003583
 >> iter 80000, loss: 0.003299
   Number of active neurons: 10
 >> iter 81000, loss: 0.003194
 >> iter 82000, loss: 0.003142
 >> iter 83000, loss: 0.003138
 >> iter 84000, loss: 0.003125
 >> iter 85000, loss: 0.003137
 >> iter 86000, loss: 0.003132
 >> iter 87000, loss: 0.091270
 >> iter 88000, loss: 0.037122
 >> iter 89000, loss: 0.016295
 >> iter 90000, loss: 0.008314
   Number of active neurons: 9
 >> iter 91000, loss: 0.005225
 >> iter 92000, loss: 0.003983
 >> iter 93000, loss: 0.003492
 >> iter 94000, loss: 0.003271
 >> iter 95000, loss: 0.003193
 >> iter 96000, loss: 0.003144
 >> iter 97000, loss: 0.003141
 >> iter 98000, loss: 0.003118
 >> iter 99000, loss: 0.043299
 >> iter 100000, loss: 0.018407
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 16.7722151857
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.156873
 >> iter 2000, loss: 8.769586
 >> iter 3000, loss: 3.622056
 >> iter 4000, loss: 1.393589
 >> iter 5000, loss: 0.521932
 >> iter 6000, loss: 0.209128
 >> iter 7000, loss: 0.082442
 >> iter 8000, loss: 0.034702
 >> iter 9000, loss: 0.016744
 >> iter 10000, loss: 0.009646
   Number of active neurons: 10
 >> iter 11000, loss: 0.006892
 >> iter 12000, loss: 0.005583
 >> iter 13000, loss: 0.005053
 >> iter 14000, loss: 0.004654
 >> iter 15000, loss: 0.004504
 >> iter 16000, loss: 0.027303
 >> iter 17000, loss: 0.223972
 >> iter 18000, loss: 0.089170
 >> iter 19000, loss: 0.086883
 >> iter 20000, loss: 0.037215
   Number of active neurons: 10
 >> iter 21000, loss: 0.017876
 >> iter 22000, loss: 0.010145
 >> iter 23000, loss: 0.027156
 >> iter 24000, loss: 0.013438
 >> iter 25000, loss: 0.008088
 >> iter 26000, loss: 0.006483
 >> iter 27000, loss: 0.005203
 >> iter 28000, loss: 0.004502
 >> iter 29000, loss: 0.004201
 >> iter 30000, loss: 0.003957
   Number of active neurons: 10
 >> iter 31000, loss: 0.003862
 >> iter 32000, loss: 0.003726
 >> iter 33000, loss: 0.003696
 >> iter 34000, loss: 0.003598
 >> iter 35000, loss: 0.123483
 >> iter 36000, loss: 0.093586
 >> iter 37000, loss: 0.038321
 >> iter 38000, loss: 0.017278
 >> iter 39000, loss: 0.009265
 >> iter 40000, loss: 0.006098
   Number of active neurons: 10
 >> iter 41000, loss: 0.004838
 >> iter 42000, loss: 0.004294
 >> iter 43000, loss: 0.004020
 >> iter 44000, loss: 0.014112
 >> iter 45000, loss: 0.007697
 >> iter 46000, loss: 0.005190
 >> iter 47000, loss: 0.004219
 >> iter 48000, loss: 0.003825
 >> iter 49000, loss: 0.003628
 >> iter 50000, loss: 0.003531
   Number of active neurons: 10
 >> iter 51000, loss: 0.025084
 >> iter 52000, loss: 0.011739
 >> iter 53000, loss: 0.006669
 >> iter 54000, loss: 0.004687
 >> iter 55000, loss: 0.154060
 >> iter 56000, loss: 0.085882
 >> iter 57000, loss: 0.077403
 >> iter 58000, loss: 0.032876
 >> iter 59000, loss: 0.043275
 >> iter 60000, loss: 0.019674
   Number of active neurons: 9
 >> iter 61000, loss: 0.010324
 >> iter 62000, loss: 0.006573
 >> iter 63000, loss: 0.005047
 >> iter 64000, loss: 0.004342
 >> iter 65000, loss: 0.037662
 >> iter 66000, loss: 0.016661
 >> iter 67000, loss: 0.008735
 >> iter 68000, loss: 0.091387
 >> iter 69000, loss: 0.064526
 >> iter 70000, loss: 0.027485
   Number of active neurons: 9
 >> iter 71000, loss: 0.186037
 >> iter 72000, loss: 0.105148
 >> iter 73000, loss: 0.043723
 >> iter 74000, loss: 0.020098
 >> iter 75000, loss: 0.010908
 >> iter 76000, loss: 0.007157
 >> iter 77000, loss: 0.005580
 >> iter 78000, loss: 0.013672
 >> iter 79000, loss: 0.007874
 >> iter 80000, loss: 0.005486
   Number of active neurons: 9
 >> iter 81000, loss: 0.004524
 >> iter 82000, loss: 0.004054
 >> iter 83000, loss: 0.023570
 >> iter 84000, loss: 0.011128
 >> iter 85000, loss: 0.006521
 >> iter 86000, loss: 0.004722
 >> iter 87000, loss: 0.004020
 >> iter 88000, loss: 0.003679
 >> iter 89000, loss: 0.098656
 >> iter 90000, loss: 0.040064
   Number of active neurons: 9
 >> iter 91000, loss: 0.194170
 >> iter 92000, loss: 0.082377
 >> iter 93000, loss: 0.034770
 >> iter 94000, loss: 0.016738
 >> iter 95000, loss: 0.009532
 >> iter 96000, loss: 0.006454
 >> iter 97000, loss: 0.037561
 >> iter 98000, loss: 0.016959
 >> iter 99000, loss: 0.009081
 >> iter 100000, loss: 0.006003
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.00799984000319
   - Test - Long: 0.0
   - Test - Big: 0.0159998400016
   - Test - A: 1.58656089594
   - Test - B: 0.486634224385
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.164843
 >> iter 2000, loss: 8.118623
 >> iter 3000, loss: 3.107938
 >> iter 4000, loss: 1.244829
 >> iter 5000, loss: 0.469942
 >> iter 6000, loss: 0.347989
 >> iter 7000, loss: 0.140720
 >> iter 8000, loss: 0.059321
 >> iter 9000, loss: 0.027951
 >> iter 10000, loss: 0.015266
   Number of active neurons: 10
 >> iter 11000, loss: 0.010149
 >> iter 12000, loss: 0.007695
 >> iter 13000, loss: 0.006595
 >> iter 14000, loss: 0.005859
 >> iter 15000, loss: 0.005504
 >> iter 16000, loss: 0.005160
 >> iter 17000, loss: 0.005019
 >> iter 18000, loss: 0.004750
 >> iter 19000, loss: 0.193215
 >> iter 20000, loss: 0.075741
   Number of active neurons: 10
 >> iter 21000, loss: 0.031936
 >> iter 22000, loss: 0.026952
 >> iter 23000, loss: 0.085039
 >> iter 24000, loss: 0.035999
 >> iter 25000, loss: 0.049026
 >> iter 26000, loss: 0.022367
 >> iter 27000, loss: 0.012053
 >> iter 28000, loss: 0.007531
 >> iter 29000, loss: 0.006285
 >> iter 30000, loss: 0.005082
   Number of active neurons: 10
 >> iter 31000, loss: 0.031313
 >> iter 32000, loss: 0.014542
 >> iter 33000, loss: 0.009627
 >> iter 34000, loss: 0.006422
 >> iter 35000, loss: 0.063539
 >> iter 36000, loss: 0.027137
 >> iter 37000, loss: 0.013396
 >> iter 38000, loss: 0.007812
 >> iter 39000, loss: 0.005731
 >> iter 40000, loss: 0.004721
   Number of active neurons: 10
 >> iter 41000, loss: 0.004432
 >> iter 42000, loss: 0.004135
 >> iter 43000, loss: 0.004123
 >> iter 44000, loss: 0.003969
 >> iter 45000, loss: 0.003999
 >> iter 46000, loss: 0.003878
 >> iter 47000, loss: 0.003916
 >> iter 48000, loss: 0.003814
 >> iter 49000, loss: 0.003863
 >> iter 50000, loss: 0.003770
   Number of active neurons: 10
 >> iter 51000, loss: 0.003831
 >> iter 52000, loss: 0.003739
 >> iter 53000, loss: 0.003791
 >> iter 54000, loss: 0.003701
 >> iter 55000, loss: 0.003766
 >> iter 56000, loss: 0.003673
 >> iter 57000, loss: 0.003746
 >> iter 58000, loss: 0.003653
 >> iter 59000, loss: 0.003727
 >> iter 60000, loss: 0.003634
   Number of active neurons: 10
 >> iter 61000, loss: 0.003711
 >> iter 62000, loss: 0.003626
 >> iter 63000, loss: 0.003698
 >> iter 64000, loss: 0.003613
 >> iter 65000, loss: 0.003683
 >> iter 66000, loss: 0.003605
 >> iter 67000, loss: 0.003686
 >> iter 68000, loss: 0.059131
 >> iter 69000, loss: 0.024756
 >> iter 70000, loss: 0.011718
   Number of active neurons: 10
 >> iter 71000, loss: 0.006875
 >> iter 72000, loss: 0.004980
 >> iter 73000, loss: 0.004322
 >> iter 74000, loss: 0.003991
 >> iter 75000, loss: 0.354739
 >> iter 76000, loss: 0.177634
 >> iter 77000, loss: 0.070891
 >> iter 78000, loss: 0.029965
 >> iter 79000, loss: 0.014384
 >> iter 80000, loss: 0.008258
   Number of active neurons: 10
 >> iter 81000, loss: 0.005857
 >> iter 82000, loss: 0.004792
 >> iter 83000, loss: 0.004368
 >> iter 84000, loss: 0.004099
 >> iter 85000, loss: 0.004004
 >> iter 86000, loss: 0.003896
 >> iter 87000, loss: 0.003864
 >> iter 88000, loss: 0.003789
 >> iter 89000, loss: 0.003781
 >> iter 90000, loss: 0.003731
   Number of active neurons: 10
 >> iter 91000, loss: 0.003736
 >> iter 92000, loss: 0.003692
 >> iter 93000, loss: 0.087740
 >> iter 94000, loss: 0.035153
 >> iter 95000, loss: 0.015593
 >> iter 96000, loss: 0.008267
 >> iter 97000, loss: 0.005604
 >> iter 98000, loss: 0.004539
 >> iter 99000, loss: 0.089882
 >> iter 100000, loss: 0.036406
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 10.3993067129
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 15.973139
 >> iter 2000, loss: 7.004092
 >> iter 3000, loss: 2.705839
 >> iter 4000, loss: 1.011893
 >> iter 5000, loss: 0.504032
 >> iter 6000, loss: 0.203762
 >> iter 7000, loss: 0.307135
 >> iter 8000, loss: 0.124154
 >> iter 9000, loss: 0.515111
 >> iter 10000, loss: 0.353716
   Number of active neurons: 10
 >> iter 11000, loss: 0.234310
 >> iter 12000, loss: 0.099244
 >> iter 13000, loss: 0.075070
 >> iter 14000, loss: 0.046123
 >> iter 15000, loss: 0.039035
 >> iter 16000, loss: 0.028507
 >> iter 17000, loss: 0.032810
 >> iter 18000, loss: 0.017163
 >> iter 19000, loss: 0.019429
 >> iter 20000, loss: 0.011385
   Number of active neurons: 10
 >> iter 21000, loss: 0.008257
 >> iter 22000, loss: 0.006524
 >> iter 23000, loss: 0.005637
 >> iter 24000, loss: 0.004940
 >> iter 25000, loss: 0.176107
 >> iter 26000, loss: 0.090589
 >> iter 27000, loss: 0.038204
 >> iter 28000, loss: 0.017820
 >> iter 29000, loss: 0.010929
 >> iter 30000, loss: 0.007434
   Number of active neurons: 10
 >> iter 31000, loss: 0.005826
 >> iter 32000, loss: 0.005221
 >> iter 33000, loss: 0.004795
 >> iter 34000, loss: 0.043124
 >> iter 35000, loss: 0.019126
 >> iter 36000, loss: 0.009810
 >> iter 37000, loss: 0.204796
 >> iter 38000, loss: 0.151309
 >> iter 39000, loss: 0.062079
 >> iter 40000, loss: 0.027306
   Number of active neurons: 10
 >> iter 41000, loss: 0.073981
 >> iter 42000, loss: 0.042574
 >> iter 43000, loss: 0.019677
 >> iter 44000, loss: 0.010571
 >> iter 45000, loss: 0.008423
 >> iter 46000, loss: 0.006210
 >> iter 47000, loss: 0.005173
 >> iter 48000, loss: 0.004526
 >> iter 49000, loss: 0.059073
 >> iter 50000, loss: 0.025189
   Number of active neurons: 10
 >> iter 51000, loss: 0.012119
 >> iter 52000, loss: 0.021325
 >> iter 53000, loss: 0.010555
 >> iter 54000, loss: 0.045916
 >> iter 55000, loss: 0.021271
 >> iter 56000, loss: 0.010509
 >> iter 57000, loss: 0.006297
 >> iter 58000, loss: 0.004734
 >> iter 59000, loss: 0.239391
 >> iter 60000, loss: 0.093727
   Number of active neurons: 10
 >> iter 61000, loss: 0.037786
 >> iter 62000, loss: 0.016844
 >> iter 63000, loss: 0.008875
 >> iter 64000, loss: 0.005788
 >> iter 65000, loss: 0.004487
 >> iter 66000, loss: 0.003950
 >> iter 67000, loss: 0.040694
 >> iter 68000, loss: 0.017591
 >> iter 69000, loss: 0.008829
 >> iter 70000, loss: 0.005438
   Number of active neurons: 10
 >> iter 71000, loss: 0.106604
 >> iter 72000, loss: 0.043119
 >> iter 73000, loss: 0.018807
 >> iter 74000, loss: 0.009520
 >> iter 75000, loss: 0.005926
 >> iter 76000, loss: 0.013159
 >> iter 77000, loss: 0.007148
 >> iter 78000, loss: 0.004845
 >> iter 79000, loss: 0.076141
 >> iter 80000, loss: 0.030779
   Number of active neurons: 10
 >> iter 81000, loss: 0.013810
 >> iter 82000, loss: 0.007430
 >> iter 83000, loss: 0.005046
 >> iter 84000, loss: 0.004079
 >> iter 85000, loss: 0.007170
 >> iter 86000, loss: 0.004862
 >> iter 87000, loss: 0.003873
 >> iter 88000, loss: 0.003457
 >> iter 89000, loss: 0.072198
 >> iter 90000, loss: 0.029061
   Number of active neurons: 10
 >> iter 91000, loss: 0.013026
 >> iter 92000, loss: 0.007040
 >> iter 93000, loss: 0.004878
 >> iter 94000, loss: 0.003945
 >> iter 95000, loss: 0.156099
 >> iter 96000, loss: 0.060786
 >> iter 97000, loss: 0.024977
 >> iter 98000, loss: 0.011578
 >> iter 99000, loss: 0.006563
 >> iter 100000, loss: 0.004635
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.009999500025
   - Test - Big: 0.00999990000101
   - Test - A: 41.0039330711
   - Test - B: 17.4988334111
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.248972
 >> iter 2000, loss: 7.933188
 >> iter 3000, loss: 2.955676
 >> iter 4000, loss: 1.100334
 >> iter 5000, loss: 0.413553
 >> iter 6000, loss: 0.158404
 >> iter 7000, loss: 0.063803
 >> iter 8000, loss: 0.028011
 >> iter 9000, loss: 0.014649
 >> iter 10000, loss: 0.009146
   Number of active neurons: 10
 >> iter 11000, loss: 0.007100
 >> iter 12000, loss: 0.005931
 >> iter 13000, loss: 0.005562
 >> iter 14000, loss: 0.005108
 >> iter 15000, loss: 0.005037
 >> iter 16000, loss: 0.004744
 >> iter 17000, loss: 0.004758
 >> iter 18000, loss: 0.004527
 >> iter 19000, loss: 0.004575
 >> iter 20000, loss: 0.004386
   Number of active neurons: 10
 >> iter 21000, loss: 0.004454
 >> iter 22000, loss: 0.004291
 >> iter 23000, loss: 0.004369
 >> iter 24000, loss: 0.004227
 >> iter 25000, loss: 0.004312
 >> iter 26000, loss: 0.004186
 >> iter 27000, loss: 0.004269
 >> iter 28000, loss: 0.004151
 >> iter 29000, loss: 0.004232
 >> iter 30000, loss: 0.004126
   Number of active neurons: 10
 >> iter 31000, loss: 0.004215
 >> iter 32000, loss: 0.004105
 >> iter 33000, loss: 0.004188
 >> iter 34000, loss: 0.004096
 >> iter 35000, loss: 0.004173
 >> iter 36000, loss: 0.004076
 >> iter 37000, loss: 0.004168
 >> iter 38000, loss: 0.004057
 >> iter 39000, loss: 0.004152
 >> iter 40000, loss: 0.004037
   Number of active neurons: 10
 >> iter 41000, loss: 0.004139
 >> iter 42000, loss: 0.004024
 >> iter 43000, loss: 0.004128
 >> iter 44000, loss: 0.004019
 >> iter 45000, loss: 0.004113
 >> iter 46000, loss: 0.004003
 >> iter 47000, loss: 0.004094
 >> iter 48000, loss: 0.003987
 >> iter 49000, loss: 0.004071
 >> iter 50000, loss: 0.003968
   Number of active neurons: 10
 >> iter 51000, loss: 0.004047
 >> iter 52000, loss: 0.003946
 >> iter 53000, loss: 0.004021
 >> iter 54000, loss: 0.003927
 >> iter 55000, loss: 0.003999
 >> iter 56000, loss: 0.003911
 >> iter 57000, loss: 0.003976
 >> iter 58000, loss: 0.003896
 >> iter 59000, loss: 0.003954
 >> iter 60000, loss: 0.003880
   Number of active neurons: 10
 >> iter 61000, loss: 0.003947
 >> iter 62000, loss: 0.003879
 >> iter 63000, loss: 0.003938
 >> iter 64000, loss: 0.003870
 >> iter 65000, loss: 0.003931
 >> iter 66000, loss: 0.003863
 >> iter 67000, loss: 0.003917
 >> iter 68000, loss: 0.003854
 >> iter 69000, loss: 0.003906
 >> iter 70000, loss: 0.448735
   Number of active neurons: 10
 >> iter 71000, loss: 0.176207
 >> iter 72000, loss: 0.071912
 >> iter 73000, loss: 0.032076
 >> iter 74000, loss: 0.016410
 >> iter 75000, loss: 0.010181
 >> iter 76000, loss: 0.007391
 >> iter 77000, loss: 0.006327
 >> iter 78000, loss: 0.005500
 >> iter 79000, loss: 0.005108
 >> iter 80000, loss: 0.004778
   Number of active neurons: 10
 >> iter 81000, loss: 0.004667
 >> iter 82000, loss: 0.004497
 >> iter 83000, loss: 0.004469
 >> iter 84000, loss: 0.004345
 >> iter 85000, loss: 0.004349
 >> iter 86000, loss: 0.004258
 >> iter 87000, loss: 0.004275
 >> iter 88000, loss: 0.004195
 >> iter 89000, loss: 0.004226
 >> iter 90000, loss: 0.004156
   Number of active neurons: 10
 >> iter 91000, loss: 0.004178
 >> iter 92000, loss: 0.004105
 >> iter 93000, loss: 0.004133
 >> iter 94000, loss: 0.004057
 >> iter 95000, loss: 0.004094
 >> iter 96000, loss: 0.004018
 >> iter 97000, loss: 0.004062
 >> iter 98000, loss: 0.003993
 >> iter 99000, loss: 0.004031
 >> iter 100000, loss: 0.003965
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 12.7924805013
   - Test - B: 21.4785680955
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.370662
 >> iter 2000, loss: 6.693233
 >> iter 3000, loss: 2.480559
 >> iter 4000, loss: 0.984793
 >> iter 5000, loss: 0.371688
 >> iter 6000, loss: 0.143354
 >> iter 7000, loss: 0.058336
 >> iter 8000, loss: 0.026413
 >> iter 9000, loss: 0.061050
 >> iter 10000, loss: 0.027772
   Number of active neurons: 10
 >> iter 11000, loss: 0.014368
 >> iter 12000, loss: 0.008877
 >> iter 13000, loss: 0.006679
 >> iter 14000, loss: 0.005614
 >> iter 15000, loss: 0.098979
 >> iter 16000, loss: 0.065479
 >> iter 17000, loss: 0.028163
 >> iter 18000, loss: 0.013987
 >> iter 19000, loss: 0.008521
 >> iter 20000, loss: 0.006246
   Number of active neurons: 10
 >> iter 21000, loss: 0.132881
 >> iter 22000, loss: 0.076094
 >> iter 23000, loss: 0.032173
 >> iter 24000, loss: 0.015362
 >> iter 25000, loss: 0.008967
 >> iter 26000, loss: 0.006344
 >> iter 27000, loss: 0.005329
 >> iter 28000, loss: 0.004836
 >> iter 29000, loss: 0.193365
 >> iter 30000, loss: 0.075796
   Number of active neurons: 10
 >> iter 31000, loss: 0.031847
 >> iter 32000, loss: 0.015232
 >> iter 33000, loss: 0.197359
 >> iter 34000, loss: 0.128484
 >> iter 35000, loss: 0.052716
 >> iter 36000, loss: 0.023931
 >> iter 37000, loss: 0.012735
 >> iter 38000, loss: 0.008144
 >> iter 39000, loss: 0.032348
 >> iter 40000, loss: 0.015253
   Number of active neurons: 10
 >> iter 41000, loss: 0.008732
 >> iter 42000, loss: 0.006097
 >> iter 43000, loss: 0.005090
 >> iter 44000, loss: 0.004584
 >> iter 45000, loss: 0.004387
 >> iter 46000, loss: 0.004206
 >> iter 47000, loss: 0.004155
 >> iter 48000, loss: 0.004034
 >> iter 49000, loss: 0.344516
 >> iter 50000, loss: 0.139010
   Number of active neurons: 10
 >> iter 51000, loss: 0.055983
 >> iter 52000, loss: 0.024552
 >> iter 53000, loss: 0.012629
 >> iter 54000, loss: 0.007901
 >> iter 55000, loss: 0.006037
 >> iter 56000, loss: 0.005293
 >> iter 57000, loss: 0.383840
 >> iter 58000, loss: 0.153324
 >> iter 59000, loss: 0.062643
 >> iter 60000, loss: 0.027869
   Number of active neurons: 10
 >> iter 61000, loss: 0.014485
 >> iter 62000, loss: 0.009086
 >> iter 63000, loss: 0.086692
 >> iter 64000, loss: 0.035788
 >> iter 65000, loss: 0.016716
 >> iter 66000, loss: 0.009426
 >> iter 67000, loss: 0.006632
 >> iter 68000, loss: 0.005426
 >> iter 69000, loss: 0.004943
 >> iter 70000, loss: 0.004609
   Number of active neurons: 10
 >> iter 71000, loss: 0.027137
 >> iter 72000, loss: 0.029221
 >> iter 73000, loss: 0.100071
 >> iter 74000, loss: 0.041715
 >> iter 75000, loss: 0.019011
 >> iter 76000, loss: 0.010089
 >> iter 77000, loss: 0.006600
 >> iter 78000, loss: 0.005064
 >> iter 79000, loss: 0.004442
 >> iter 80000, loss: 0.004067
   Number of active neurons: 9
 >> iter 81000, loss: 0.003930
 >> iter 82000, loss: 0.003774
 >> iter 83000, loss: 0.075640
 >> iter 84000, loss: 0.030998
 >> iter 85000, loss: 0.107505
 >> iter 86000, loss: 0.043087
 >> iter 87000, loss: 0.019145
 >> iter 88000, loss: 0.009921
 >> iter 89000, loss: 0.006585
 >> iter 90000, loss: 0.005104
   Number of active neurons: 9
 >> iter 91000, loss: 0.004505
 >> iter 92000, loss: 0.004170
 >> iter 93000, loss: 0.098615
 >> iter 94000, loss: 0.039517
 >> iter 95000, loss: 0.094266
 >> iter 96000, loss: 0.038022
 >> iter 97000, loss: 0.099853
 >> iter 98000, loss: 0.040422
 >> iter 99000, loss: 0.018231
 >> iter 100000, loss: 0.009711
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0249987500625
   - Test - Big: 0.0159998400016
   - Test - A: 50.4699686688
   - Test - B: 18.5987600827
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 16.342956
 >> iter 2000, loss: 7.910662
 >> iter 3000, loss: 2.975736
 >> iter 4000, loss: 1.108703
 >> iter 5000, loss: 0.426696
 >> iter 6000, loss: 0.164586
 >> iter 7000, loss: 0.066692
 >> iter 8000, loss: 0.029535
 >> iter 9000, loss: 0.054128
 >> iter 10000, loss: 0.026756
   Number of active neurons: 10
 >> iter 11000, loss: 0.014565
 >> iter 12000, loss: 0.009397
 >> iter 13000, loss: 0.007387
 >> iter 14000, loss: 0.006230
 >> iter 15000, loss: 0.005934
 >> iter 16000, loss: 0.005425
 >> iter 17000, loss: 0.005340
 >> iter 18000, loss: 0.005082
 >> iter 19000, loss: 0.005057
 >> iter 20000, loss: 0.004862
   Number of active neurons: 10
 >> iter 21000, loss: 0.004948
 >> iter 22000, loss: 0.004755
 >> iter 23000, loss: 0.004953
 >> iter 24000, loss: 0.004671
 >> iter 25000, loss: 0.004854
 >> iter 26000, loss: 0.004599
 >> iter 27000, loss: 0.004796
 >> iter 28000, loss: 0.004550
 >> iter 29000, loss: 0.004773
 >> iter 30000, loss: 0.004517
   Number of active neurons: 10
 >> iter 31000, loss: 0.004672
 >> iter 32000, loss: 0.004452
 >> iter 33000, loss: 0.004645
 >> iter 34000, loss: 0.004420
 >> iter 35000, loss: 0.004600
 >> iter 36000, loss: 0.004380
 >> iter 37000, loss: 0.004561
 >> iter 38000, loss: 0.004345
 >> iter 39000, loss: 0.004473
 >> iter 40000, loss: 0.004286
   Number of active neurons: 10
 >> iter 41000, loss: 0.004421
 >> iter 42000, loss: 0.004242
 >> iter 43000, loss: 0.004430
 >> iter 44000, loss: 0.004235
 >> iter 45000, loss: 0.004386
 >> iter 46000, loss: 0.004202
 >> iter 47000, loss: 0.004356
 >> iter 48000, loss: 0.004174
 >> iter 49000, loss: 0.004298
 >> iter 50000, loss: 0.004133
   Number of active neurons: 10
 >> iter 51000, loss: 0.004269
 >> iter 52000, loss: 0.004101
 >> iter 53000, loss: 0.004232
 >> iter 54000, loss: 0.004067
 >> iter 55000, loss: 0.004169
 >> iter 56000, loss: 0.004035
 >> iter 57000, loss: 0.004214
 >> iter 58000, loss: 0.004041
 >> iter 59000, loss: 0.004199
 >> iter 60000, loss: 0.004027
   Number of active neurons: 10
 >> iter 61000, loss: 0.004152
 >> iter 62000, loss: 0.004021
 >> iter 63000, loss: 0.140367
 >> iter 64000, loss: 0.055565
 >> iter 65000, loss: 0.166294
 >> iter 66000, loss: 0.065784
 >> iter 67000, loss: 0.027935
 >> iter 68000, loss: 0.013519
 >> iter 69000, loss: 0.008103
 >> iter 70000, loss: 0.005900
   Number of active neurons: 10
 >> iter 71000, loss: 0.005114
 >> iter 72000, loss: 0.004661
 >> iter 73000, loss: 0.045475
 >> iter 74000, loss: 0.020364
 >> iter 75000, loss: 0.010665
 >> iter 76000, loss: 0.006801
 >> iter 77000, loss: 0.005375
 >> iter 78000, loss: 0.004705
 >> iter 79000, loss: 0.004506
 >> iter 80000, loss: 0.004319
   Number of active neurons: 10
 >> iter 81000, loss: 0.004326
 >> iter 82000, loss: 0.004218
 >> iter 83000, loss: 0.004277
 >> iter 84000, loss: 0.004296
 >> iter 85000, loss: 0.004203
 >> iter 86000, loss: 0.004107
 >> iter 87000, loss: 0.004150
 >> iter 88000, loss: 0.004684
 >> iter 89000, loss: 0.004286
 >> iter 90000, loss: 0.004102
   Number of active neurons: 10
 >> iter 91000, loss: 0.004083
 >> iter 92000, loss: 0.022812
 >> iter 93000, loss: 0.011345
 >> iter 94000, loss: 0.006856
 >> iter 95000, loss: 0.005201
 >> iter 96000, loss: 0.004495
 >> iter 97000, loss: 0.004280
 >> iter 98000, loss: 0.004135
 >> iter 99000, loss: 0.004113
 >> iter 100000, loss: 0.123498
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 6.65288980735
   - Test - B: 18.3521098593
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.145951
 >> iter 2000, loss: 7.245808
 >> iter 3000, loss: 2.695907
 >> iter 4000, loss: 1.004318
 >> iter 5000, loss: 0.415229
 >> iter 6000, loss: 0.160506
 >> iter 7000, loss: 0.112520
 >> iter 8000, loss: 0.047659
 >> iter 9000, loss: 0.105314
 >> iter 10000, loss: 0.046624
   Number of active neurons: 10
 >> iter 11000, loss: 0.058192
 >> iter 12000, loss: 0.027542
 >> iter 13000, loss: 0.039204
 >> iter 14000, loss: 0.019573
 >> iter 15000, loss: 0.074775
 >> iter 16000, loss: 0.033255
 >> iter 17000, loss: 0.016542
 >> iter 18000, loss: 0.009722
 >> iter 19000, loss: 0.038975
 >> iter 20000, loss: 0.018690
   Number of active neurons: 10
 >> iter 21000, loss: 0.010428
 >> iter 22000, loss: 0.007014
 >> iter 23000, loss: 0.006408
 >> iter 24000, loss: 0.005447
 >> iter 25000, loss: 0.005001
 >> iter 26000, loss: 0.004693
 >> iter 27000, loss: 0.004606
 >> iter 28000, loss: 0.004468
 >> iter 29000, loss: 0.042491
 >> iter 30000, loss: 0.018935
   Number of active neurons: 10
 >> iter 31000, loss: 0.100528
 >> iter 32000, loss: 0.041048
 >> iter 33000, loss: 0.108703
 >> iter 34000, loss: 0.044958
 >> iter 35000, loss: 0.020363
 >> iter 36000, loss: 0.010817
 >> iter 37000, loss: 0.007183
 >> iter 38000, loss: 0.005629
 >> iter 39000, loss: 0.094906
 >> iter 40000, loss: 0.039462
   Number of active neurons: 10
 >> iter 41000, loss: 0.019236
 >> iter 42000, loss: 0.010440
 >> iter 43000, loss: 0.006894
 >> iter 44000, loss: 0.005352
 >> iter 45000, loss: 0.004751
 >> iter 46000, loss: 0.004404
 >> iter 47000, loss: 0.004290
 >> iter 48000, loss: 0.004160
 >> iter 49000, loss: 0.004148
 >> iter 50000, loss: 0.004075
   Number of active neurons: 10
 >> iter 51000, loss: 0.059835
 >> iter 52000, loss: 0.025354
 >> iter 53000, loss: 0.012260
 >> iter 54000, loss: 0.007270
 >> iter 55000, loss: 0.027493
 >> iter 56000, loss: 0.013335
 >> iter 57000, loss: 0.007689
 >> iter 58000, loss: 0.005490
 >> iter 59000, loss: 0.004644
 >> iter 60000, loss: 0.004253
   Number of active neurons: 10
 >> iter 61000, loss: 0.316786
 >> iter 62000, loss: 0.158968
 >> iter 63000, loss: 0.063259
 >> iter 64000, loss: 0.027160
 >> iter 65000, loss: 0.013530
 >> iter 66000, loss: 0.008207
 >> iter 67000, loss: 0.007341
 >> iter 68000, loss: 0.005881
 >> iter 69000, loss: 0.005081
 >> iter 70000, loss: 0.004613
   Number of active neurons: 10
 >> iter 71000, loss: 0.004407
 >> iter 72000, loss: 0.004231
 >> iter 73000, loss: 0.004159
 >> iter 74000, loss: 0.004059
 >> iter 75000, loss: 0.004031
 >> iter 76000, loss: 0.003970
 >> iter 77000, loss: 0.107316
 >> iter 78000, loss: 0.086183
 >> iter 79000, loss: 0.056748
 >> iter 80000, loss: 0.039475
   Number of active neurons: 10
 >> iter 81000, loss: 0.018422
 >> iter 82000, loss: 0.009724
 >> iter 83000, loss: 0.006303
 >> iter 84000, loss: 0.004879
 >> iter 85000, loss: 0.004297
 >> iter 86000, loss: 0.004001
 >> iter 87000, loss: 0.038477
 >> iter 88000, loss: 0.016894
 >> iter 89000, loss: 0.008702
 >> iter 90000, loss: 0.005572
   Number of active neurons: 10
 >> iter 91000, loss: 0.004388
 >> iter 92000, loss: 0.003916
 >> iter 93000, loss: 0.005631
 >> iter 94000, loss: 0.280305
 >> iter 95000, loss: 0.109156
 >> iter 96000, loss: 0.044431
 >> iter 97000, loss: 0.026787
 >> iter 98000, loss: 0.013702
 >> iter 99000, loss: 0.008259
 >> iter 100000, loss: 0.005968
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 14.425704953
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 16.258286
 >> iter 2000, loss: 7.587239
 >> iter 3000, loss: 2.966036
 >> iter 4000, loss: 1.202589
 >> iter 5000, loss: 0.542087
 >> iter 6000, loss: 0.218449
 >> iter 7000, loss: 0.094159
 >> iter 8000, loss: 0.044803
 >> iter 9000, loss: 0.025779
 >> iter 10000, loss: 0.017444
   Number of active neurons: 10
 >> iter 11000, loss: 0.014140
 >> iter 12000, loss: 0.011534
 >> iter 13000, loss: 0.010676
 >> iter 14000, loss: 0.048317
 >> iter 15000, loss: 0.037768
 >> iter 16000, loss: 0.020887
 >> iter 17000, loss: 0.014200
 >> iter 18000, loss: 0.010598
 >> iter 19000, loss: 0.017463
 >> iter 20000, loss: 0.011446
   Number of active neurons: 10
 >> iter 21000, loss: 0.032983
 >> iter 22000, loss: 0.017588
 >> iter 23000, loss: 0.011564
 >> iter 24000, loss: 0.211787
 >> iter 25000, loss: 0.135253
 >> iter 26000, loss: 0.055536
 >> iter 27000, loss: 0.025578
 >> iter 28000, loss: 0.013182
 >> iter 29000, loss: 0.153344
 >> iter 30000, loss: 0.060977
   Number of active neurons: 10
 >> iter 31000, loss: 0.028760
 >> iter 32000, loss: 0.014154
 >> iter 33000, loss: 0.128619
 >> iter 34000, loss: 0.051810
 >> iter 35000, loss: 0.077256
 >> iter 36000, loss: 0.037538
 >> iter 37000, loss: 0.046973
 >> iter 38000, loss: 0.020505
 >> iter 39000, loss: 0.010143
 >> iter 40000, loss: 0.006079
   Number of active neurons: 10
 >> iter 41000, loss: 0.004478
 >> iter 42000, loss: 0.003801
 >> iter 43000, loss: 0.003645
 >> iter 44000, loss: 0.003426
 >> iter 45000, loss: 0.040353
 >> iter 46000, loss: 0.017528
 >> iter 47000, loss: 0.008770
 >> iter 48000, loss: 0.005428
 >> iter 49000, loss: 0.004155
 >> iter 50000, loss: 0.003620
   Number of active neurons: 10
 >> iter 51000, loss: 0.005399
 >> iter 52000, loss: 0.004194
 >> iter 53000, loss: 0.003646
 >> iter 54000, loss: 0.003394
 >> iter 55000, loss: 0.003286
 >> iter 56000, loss: 0.003226
 >> iter 57000, loss: 0.003209
 >> iter 58000, loss: 0.003189
 >> iter 59000, loss: 0.028036
 >> iter 60000, loss: 0.012727
   Number of active neurons: 10
 >> iter 61000, loss: 0.006880
 >> iter 62000, loss: 0.004666
 >> iter 63000, loss: 0.039552
 >> iter 64000, loss: 0.017246
 >> iter 65000, loss: 0.008686
 >> iter 66000, loss: 0.005228
 >> iter 67000, loss: 0.026282
 >> iter 68000, loss: 0.012137
 >> iter 69000, loss: 0.006692
 >> iter 70000, loss: 0.004599
   Number of active neurons: 10
 >> iter 71000, loss: 0.003813
 >> iter 72000, loss: 0.003493
 >> iter 73000, loss: 0.044087
 >> iter 74000, loss: 0.040805
 >> iter 75000, loss: 0.017583
 >> iter 76000, loss: 0.008706
 >> iter 77000, loss: 0.005372
 >> iter 78000, loss: 0.004098
 >> iter 79000, loss: 0.003641
 >> iter 80000, loss: 0.003455
   Number of active neurons: 9
 >> iter 81000, loss: 0.043088
 >> iter 82000, loss: 0.018657
 >> iter 83000, loss: 0.009248
 >> iter 84000, loss: 0.005648
 >> iter 85000, loss: 0.004323
 >> iter 86000, loss: 0.003775
 >> iter 87000, loss: 0.003567
 >> iter 88000, loss: 0.003470
 >> iter 89000, loss: 0.040741
 >> iter 90000, loss: 0.017596
   Number of active neurons: 9
 >> iter 91000, loss: 0.008883
 >> iter 92000, loss: 0.005575
 >> iter 93000, loss: 0.004356
 >> iter 94000, loss: 0.003846
 >> iter 95000, loss: 0.031116
 >> iter 96000, loss: 0.014330
 >> iter 97000, loss: 0.007763
 >> iter 98000, loss: 0.005202
 >> iter 99000, loss: 0.004234
 >> iter 100000, loss: 0.003815
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 44.9903339777
   - Test - B: 17.125524965
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.093591
 >> iter 2000, loss: 7.207858
 >> iter 3000, loss: 2.711283
 >> iter 4000, loss: 1.094655
 >> iter 5000, loss: 0.500005
 >> iter 6000, loss: 0.199672
 >> iter 7000, loss: 0.104158
 >> iter 8000, loss: 0.047108
 >> iter 9000, loss: 0.024135
 >> iter 10000, loss: 0.014327
   Number of active neurons: 10
 >> iter 11000, loss: 0.011866
 >> iter 12000, loss: 0.009167
 >> iter 13000, loss: 0.007764
 >> iter 14000, loss: 0.006824
 >> iter 15000, loss: 0.006450
 >> iter 16000, loss: 0.006083
 >> iter 17000, loss: 0.005950
 >> iter 18000, loss: 0.047313
 >> iter 19000, loss: 0.021630
 >> iter 20000, loss: 0.012148
   Number of active neurons: 10
 >> iter 21000, loss: 0.008594
 >> iter 22000, loss: 0.006692
 >> iter 23000, loss: 0.112378
 >> iter 24000, loss: 0.097045
 >> iter 25000, loss: 0.058496
 >> iter 26000, loss: 0.027167
 >> iter 27000, loss: 0.031092
 >> iter 28000, loss: 0.017009
 >> iter 29000, loss: 0.012194
 >> iter 30000, loss: 0.008634
   Number of active neurons: 10
 >> iter 31000, loss: 0.006965
 >> iter 32000, loss: 0.006061
 >> iter 33000, loss: 0.005822
 >> iter 34000, loss: 0.005461
 >> iter 35000, loss: 0.184479
 >> iter 36000, loss: 0.106330
 >> iter 37000, loss: 0.085405
 >> iter 38000, loss: 0.037837
 >> iter 39000, loss: 0.018645
 >> iter 40000, loss: 0.010819
   Number of active neurons: 10
 >> iter 41000, loss: 0.007771
 >> iter 42000, loss: 0.006323
 >> iter 43000, loss: 0.005857
 >> iter 44000, loss: 0.005424
 >> iter 45000, loss: 0.005420
 >> iter 46000, loss: 0.005156
 >> iter 47000, loss: 0.008497
 >> iter 48000, loss: 0.006463
 >> iter 49000, loss: 0.005639
 >> iter 50000, loss: 0.005232
   Number of active neurons: 10
 >> iter 51000, loss: 0.005181
 >> iter 52000, loss: 0.164725
 >> iter 53000, loss: 0.187747
 >> iter 54000, loss: 0.078111
 >> iter 55000, loss: 0.034167
 >> iter 56000, loss: 0.017071
 >> iter 57000, loss: 0.010513
 >> iter 58000, loss: 0.007716
 >> iter 59000, loss: 0.006588
 >> iter 60000, loss: 0.005942
   Number of active neurons: 10
 >> iter 61000, loss: 0.005681
 >> iter 62000, loss: 0.005419
 >> iter 63000, loss: 0.005330
 >> iter 64000, loss: 0.005164
 >> iter 65000, loss: 0.005133
 >> iter 66000, loss: 0.005014
 >> iter 67000, loss: 0.005018
 >> iter 68000, loss: 0.004934
 >> iter 69000, loss: 0.004942
 >> iter 70000, loss: 0.004895
   Number of active neurons: 10
 >> iter 71000, loss: 0.004886
 >> iter 72000, loss: 0.004876
 >> iter 73000, loss: 0.004851
 >> iter 74000, loss: 0.004866
 >> iter 75000, loss: 0.004843
 >> iter 76000, loss: 0.141597
 >> iter 77000, loss: 0.058946
 >> iter 78000, loss: 0.025758
 >> iter 79000, loss: 0.013125
 >> iter 80000, loss: 0.008180
   Number of active neurons: 10
 >> iter 81000, loss: 0.006369
 >> iter 82000, loss: 0.005514
 >> iter 83000, loss: 0.005309
 >> iter 84000, loss: 0.005044
 >> iter 85000, loss: 0.005057
 >> iter 86000, loss: 0.004938
 >> iter 87000, loss: 0.004997
 >> iter 88000, loss: 0.004911
 >> iter 89000, loss: 0.004979
 >> iter 90000, loss: 0.004922
   Number of active neurons: 10
 >> iter 91000, loss: 0.004952
 >> iter 92000, loss: 0.004937
 >> iter 93000, loss: 0.004948
 >> iter 94000, loss: 0.004944
 >> iter 95000, loss: 0.004922
 >> iter 96000, loss: 0.135764
 >> iter 97000, loss: 0.058048
 >> iter 98000, loss: 0.024905
 >> iter 99000, loss: 0.062160
 >> iter 100000, loss: 0.026964
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 5.53963069129
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 15.507661
 >> iter 2000, loss: 6.420491
 >> iter 3000, loss: 2.424626
 >> iter 4000, loss: 0.903113
 >> iter 5000, loss: 0.408844
 >> iter 6000, loss: 0.158494
 >> iter 7000, loss: 0.103289
 >> iter 8000, loss: 0.044191
 >> iter 9000, loss: 0.209468
 >> iter 10000, loss: 0.083224
   Number of active neurons: 10
 >> iter 11000, loss: 0.035751
 >> iter 12000, loss: 0.219565
 >> iter 13000, loss: 0.110762
 >> iter 14000, loss: 0.047223
 >> iter 15000, loss: 0.022709
 >> iter 16000, loss: 0.012838
 >> iter 17000, loss: 0.008891
 >> iter 18000, loss: 0.007000
 >> iter 19000, loss: 0.006190
 >> iter 20000, loss: 0.005611
   Number of active neurons: 10
 >> iter 21000, loss: 0.011842
 >> iter 22000, loss: 0.007509
 >> iter 23000, loss: 0.005899
 >> iter 24000, loss: 0.005124
 >> iter 25000, loss: 0.004885
 >> iter 26000, loss: 0.004643
 >> iter 27000, loss: 0.004607
 >> iter 28000, loss: 0.004465
 >> iter 29000, loss: 0.004461
 >> iter 30000, loss: 0.004336
   Number of active neurons: 10
 >> iter 31000, loss: 0.049817
 >> iter 32000, loss: 0.021894
 >> iter 33000, loss: 0.011368
 >> iter 34000, loss: 0.007212
 >> iter 35000, loss: 0.005645
 >> iter 36000, loss: 0.004878
 >> iter 37000, loss: 0.004614
 >> iter 38000, loss: 0.004421
 >> iter 39000, loss: 0.004338
 >> iter 40000, loss: 0.004195
   Number of active neurons: 9
 >> iter 41000, loss: 0.004189
 >> iter 42000, loss: 0.004113
 >> iter 43000, loss: 0.004119
 >> iter 44000, loss: 0.004055
 >> iter 45000, loss: 0.004063
 >> iter 46000, loss: 0.004003
 >> iter 47000, loss: 0.004017
 >> iter 48000, loss: 0.003961
 >> iter 49000, loss: 0.003981
 >> iter 50000, loss: 0.003923
   Number of active neurons: 9
 >> iter 51000, loss: 0.003946
 >> iter 52000, loss: 0.003890
 >> iter 53000, loss: 0.003912
 >> iter 54000, loss: 0.003856
 >> iter 55000, loss: 0.003881
 >> iter 56000, loss: 0.003820
 >> iter 57000, loss: 0.003845
 >> iter 58000, loss: 0.003787
 >> iter 59000, loss: 0.003817
 >> iter 60000, loss: 0.003758
   Number of active neurons: 9
 >> iter 61000, loss: 0.003799
 >> iter 62000, loss: 0.003739
 >> iter 63000, loss: 0.003782
 >> iter 64000, loss: 0.003719
 >> iter 65000, loss: 0.003765
 >> iter 66000, loss: 0.003702
 >> iter 67000, loss: 0.003744
 >> iter 68000, loss: 0.003681
 >> iter 69000, loss: 0.367239
 >> iter 70000, loss: 0.156594
   Number of active neurons: 9
 >> iter 71000, loss: 0.149931
 >> iter 72000, loss: 0.060224
 >> iter 73000, loss: 0.026580
 >> iter 74000, loss: 0.013726
 >> iter 75000, loss: 0.080793
 >> iter 76000, loss: 0.033692
 >> iter 77000, loss: 0.016035
 >> iter 78000, loss: 0.009256
 >> iter 79000, loss: 0.516125
 >> iter 80000, loss: 0.227839
   Number of active neurons: 8
 >> iter 81000, loss: 0.092093
 >> iter 82000, loss: 0.039949
 >> iter 83000, loss: 0.019756
 >> iter 84000, loss: 0.011573
 >> iter 85000, loss: 0.008189
 >> iter 86000, loss: 0.006565
 >> iter 87000, loss: 0.005782
 >> iter 88000, loss: 0.005257
 >> iter 89000, loss: 0.004973
 >> iter 90000, loss: 0.004706
   Number of active neurons: 8
 >> iter 91000, loss: 0.004547
 >> iter 92000, loss: 0.004379
 >> iter 93000, loss: 0.004287
 >> iter 94000, loss: 0.004163
 >> iter 95000, loss: 0.004100
 >> iter 96000, loss: 0.004000
 >> iter 97000, loss: 0.003960
 >> iter 98000, loss: 0.003876
 >> iter 99000, loss: 0.003846
 >> iter 100000, loss: 0.003771
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 22.3985067662
   - Test - B: 37.8374775015
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.922235
 >> iter 2000, loss: 6.687361
 >> iter 3000, loss: 2.676759
 >> iter 4000, loss: 1.212556
 >> iter 5000, loss: 0.469553
 >> iter 6000, loss: 0.181563
 >> iter 7000, loss: 0.073833
 >> iter 8000, loss: 0.032908
 >> iter 9000, loss: 0.017310
 >> iter 10000, loss: 0.010936
   Number of active neurons: 10
 >> iter 11000, loss: 0.008367
 >> iter 12000, loss: 0.007025
 >> iter 13000, loss: 0.006431
 >> iter 14000, loss: 0.005933
 >> iter 15000, loss: 0.005724
 >> iter 16000, loss: 0.005432
 >> iter 17000, loss: 0.005336
 >> iter 18000, loss: 0.005121
 >> iter 19000, loss: 0.005070
 >> iter 20000, loss: 0.004894
   Number of active neurons: 10
 >> iter 21000, loss: 0.004877
 >> iter 22000, loss: 0.004727
 >> iter 23000, loss: 0.004724
 >> iter 24000, loss: 0.040713
 >> iter 25000, loss: 0.018609
 >> iter 26000, loss: 0.010065
 >> iter 27000, loss: 0.006878
 >> iter 28000, loss: 0.005500
 >> iter 29000, loss: 0.005040
 >> iter 30000, loss: 0.004718
   Number of active neurons: 10
 >> iter 31000, loss: 0.004663
 >> iter 32000, loss: 0.004504
 >> iter 33000, loss: 0.004513
 >> iter 34000, loss: 0.004397
 >> iter 35000, loss: 0.004420
 >> iter 36000, loss: 0.004338
 >> iter 37000, loss: 0.004347
 >> iter 38000, loss: 0.164681
 >> iter 39000, loss: 0.066119
 >> iter 40000, loss: 0.028598
   Number of active neurons: 10
 >> iter 41000, loss: 0.014315
 >> iter 42000, loss: 0.008627
 >> iter 43000, loss: 0.006415
 >> iter 44000, loss: 0.005344
 >> iter 45000, loss: 0.004946
 >> iter 46000, loss: 0.004603
 >> iter 47000, loss: 0.004503
 >> iter 48000, loss: 0.004334
 >> iter 49000, loss: 0.004306
 >> iter 50000, loss: 0.004193
   Number of active neurons: 10
 >> iter 51000, loss: 0.004187
 >> iter 52000, loss: 0.004104
 >> iter 53000, loss: 0.004112
 >> iter 54000, loss: 0.004064
 >> iter 55000, loss: 0.004068
 >> iter 56000, loss: 0.004069
 >> iter 57000, loss: 0.004036
 >> iter 58000, loss: 0.004065
 >> iter 59000, loss: 0.004001
 >> iter 60000, loss: 0.003995
   Number of active neurons: 10
 >> iter 61000, loss: 0.003951
 >> iter 62000, loss: 0.063330
 >> iter 63000, loss: 0.156109
 >> iter 64000, loss: 0.062273
 >> iter 65000, loss: 0.026621
 >> iter 66000, loss: 0.012943
 >> iter 67000, loss: 0.007749
 >> iter 68000, loss: 0.005642
 >> iter 69000, loss: 0.004820
 >> iter 70000, loss: 0.004424
   Number of active neurons: 9
 >> iter 71000, loss: 0.004249
 >> iter 72000, loss: 0.004147
 >> iter 73000, loss: 0.004088
 >> iter 74000, loss: 0.004044
 >> iter 75000, loss: 0.004033
 >> iter 76000, loss: 0.004002
 >> iter 77000, loss: 0.004013
 >> iter 78000, loss: 0.003969
 >> iter 79000, loss: 0.003996
 >> iter 80000, loss: 0.003942
   Number of active neurons: 9
 >> iter 81000, loss: 0.003994
 >> iter 82000, loss: 0.003925
 >> iter 83000, loss: 0.004136
 >> iter 84000, loss: 0.003961
 >> iter 85000, loss: 0.442439
 >> iter 86000, loss: 0.168747
 >> iter 87000, loss: 0.066471
 >> iter 88000, loss: 0.028202
 >> iter 89000, loss: 0.013813
 >> iter 90000, loss: 0.008256
   Number of active neurons: 8
 >> iter 91000, loss: 0.006079
 >> iter 92000, loss: 0.005132
 >> iter 93000, loss: 0.004725
 >> iter 94000, loss: 0.004476
 >> iter 95000, loss: 0.004366
 >> iter 96000, loss: 0.004274
 >> iter 97000, loss: 0.004225
 >> iter 98000, loss: 0.004175
 >> iter 99000, loss: 0.004133
 >> iter 100000, loss: 0.004074
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0089999100009
   - Test - A: 0.0333311112592
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.991114
 >> iter 2000, loss: 7.117473
 >> iter 3000, loss: 2.725721
 >> iter 4000, loss: 1.105866
 >> iter 5000, loss: 0.444633
 >> iter 6000, loss: 0.173337
 >> iter 7000, loss: 0.090114
 >> iter 8000, loss: 0.039146
 >> iter 9000, loss: 0.039207
 >> iter 10000, loss: 0.019705
   Number of active neurons: 10
 >> iter 11000, loss: 0.031890
 >> iter 12000, loss: 0.016486
 >> iter 13000, loss: 0.028301
 >> iter 14000, loss: 0.014769
 >> iter 15000, loss: 0.009154
 >> iter 16000, loss: 0.006682
 >> iter 17000, loss: 0.027079
 >> iter 18000, loss: 0.013699
 >> iter 19000, loss: 0.082801
 >> iter 20000, loss: 0.034231
   Number of active neurons: 10
 >> iter 21000, loss: 0.037433
 >> iter 22000, loss: 0.017661
 >> iter 23000, loss: 0.009898
 >> iter 24000, loss: 0.006709
 >> iter 25000, loss: 0.025865
 >> iter 26000, loss: 0.013188
 >> iter 27000, loss: 0.008059
 >> iter 28000, loss: 0.005881
 >> iter 29000, loss: 0.005004
 >> iter 30000, loss: 0.004513
   Number of active neurons: 10
 >> iter 31000, loss: 0.053120
 >> iter 32000, loss: 0.023253
 >> iter 33000, loss: 0.011713
 >> iter 34000, loss: 0.007153
 >> iter 35000, loss: 0.005398
 >> iter 36000, loss: 0.004582
 >> iter 37000, loss: 0.004285
 >> iter 38000, loss: 0.004051
 >> iter 39000, loss: 0.004015
 >> iter 40000, loss: 0.003894
   Number of active neurons: 10
 >> iter 41000, loss: 0.003866
 >> iter 42000, loss: 0.003776
 >> iter 43000, loss: 0.003784
 >> iter 44000, loss: 0.003718
 >> iter 45000, loss: 0.003738
 >> iter 46000, loss: 0.003683
 >> iter 47000, loss: 0.003709
 >> iter 48000, loss: 0.003667
 >> iter 49000, loss: 0.003692
 >> iter 50000, loss: 0.003655
   Number of active neurons: 10
 >> iter 51000, loss: 0.003674
 >> iter 52000, loss: 0.003643
 >> iter 53000, loss: 0.003666
 >> iter 54000, loss: 0.003640
 >> iter 55000, loss: 0.003665
 >> iter 56000, loss: 0.003640
 >> iter 57000, loss: 0.003667
 >> iter 58000, loss: 0.003641
 >> iter 59000, loss: 0.003662
 >> iter 60000, loss: 0.003638
   Number of active neurons: 10
 >> iter 61000, loss: 0.003662
 >> iter 62000, loss: 0.003639
 >> iter 63000, loss: 0.003658
 >> iter 64000, loss: 0.003638
 >> iter 65000, loss: 0.003653
 >> iter 66000, loss: 0.003653
 >> iter 67000, loss: 0.003645
 >> iter 68000, loss: 0.003688
 >> iter 69000, loss: 0.003636
 >> iter 70000, loss: 0.003760
   Number of active neurons: 10
 >> iter 71000, loss: 0.003642
 >> iter 72000, loss: 0.003653
 >> iter 73000, loss: 0.003591
 >> iter 74000, loss: 0.003688
 >> iter 75000, loss: 0.003596
 >> iter 76000, loss: 0.003660
 >> iter 77000, loss: 0.003576
 >> iter 78000, loss: 0.003599
 >> iter 79000, loss: 0.003550
 >> iter 80000, loss: 0.003598
   Number of active neurons: 10
 >> iter 81000, loss: 0.003543
 >> iter 82000, loss: 0.003540
 >> iter 83000, loss: 0.003522
 >> iter 84000, loss: 0.003563
 >> iter 85000, loss: 0.003524
 >> iter 86000, loss: 0.003522
 >> iter 87000, loss: 0.003511
 >> iter 88000, loss: 0.003520
 >> iter 89000, loss: 0.003508
 >> iter 90000, loss: 0.003495
   Number of active neurons: 10
 >> iter 91000, loss: 0.003499
 >> iter 92000, loss: 0.003478
 >> iter 93000, loss: 0.003502
 >> iter 94000, loss: 0.003461
 >> iter 95000, loss: 0.003515
 >> iter 96000, loss: 0.003443
 >> iter 97000, loss: 0.003515
 >> iter 98000, loss: 0.003425
 >> iter 99000, loss: 0.046319
 >> iter 100000, loss: 0.019602
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 14.4590360643

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

