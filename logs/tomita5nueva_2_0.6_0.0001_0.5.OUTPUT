 > Problema: tomita5nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.301406
 >> iter 2000, loss: 14.545034
 >> iter 3000, loss: 13.155958
 >> iter 4000, loss: 12.646605
 >> iter 5000, loss: 12.457957
 >> iter 6000, loss: 12.367119
 >> iter 7000, loss: 12.355950
 >> iter 8000, loss: 12.338950
 >> iter 9000, loss: 12.349990
 >> iter 10000, loss: 12.335215
   Number of active neurons: 1
 >> iter 11000, loss: 12.343375
 >> iter 12000, loss: 12.337020
 >> iter 13000, loss: 12.349927
 >> iter 14000, loss: 12.335488
 >> iter 15000, loss: 12.342319
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 9.907244
 >> iter 17000, loss: 8.473496
 >> iter 18000, loss: 7.890945
 >> iter 19000, loss: 7.757247
 >> iter 20000, loss: 7.666401
   Number of active neurons: 2
 >> iter 21000, loss: 7.568976
 >> iter 22000, loss: 7.577859
 >> iter 23000, loss: 7.533074
 >> iter 24000, loss: 7.502246
 >> iter 25000, loss: 7.528976
 >> iter 26000, loss: 7.518280
 >> iter 27000, loss: 7.515793
 >> iter 28000, loss: 7.488076
 >> iter 29000, loss: 7.500582
 >> iter 30000, loss: 7.483580
   Number of active neurons: 2
 >> iter 31000, loss: 7.519113
 >> iter 32000, loss: 7.497597
 >> iter 33000, loss: 7.502838
 >> iter 34000, loss: 7.495586
 >> iter 35000, loss: 7.521188
 >> iter 36000, loss: 7.492461
 >> iter 37000, loss: 7.502363
 >> iter 38000, loss: 7.482838
 >> iter 39000, loss: 7.491422
 >> iter 40000, loss: 7.494484
   Number of active neurons: 2
 >> iter 41000, loss: 7.524493
 >> iter 42000, loss: 7.521963
 >> iter 43000, loss: 7.555233
 >> iter 44000, loss: 7.508292
 >> iter 45000, loss: 7.501121
 >> iter 46000, loss: 7.515524
 >> iter 47000, loss: 7.561623
 >> iter 48000, loss: 7.535761
 >> iter 49000, loss: 7.528282
 >> iter 50000, loss: 7.499248
   Number of active neurons: 2
 >> iter 51000, loss: 7.500749
 >> iter 52000, loss: 7.509883
 >> iter 53000, loss: 7.543137
 >> iter 54000, loss: 7.490103
 >> iter 55000, loss: 7.510201
 >> iter 56000, loss: 7.499457
 >> iter 57000, loss: 7.514312
 >> iter 58000, loss: 7.485746
 >> iter 59000, loss: 7.507755
 >> iter 60000, loss: 7.485744
   Number of active neurons: 2
 >> iter 61000, loss: 7.495267
 >> iter 62000, loss: 7.486114
 >> iter 63000, loss: 7.499926
 >> iter 64000, loss: 7.539501
 >> iter 65000, loss: 7.513834
 >> iter 66000, loss: 7.508680
 >> iter 67000, loss: 7.541995
 >> iter 68000, loss: 7.496928
 >> iter 69000, loss: 7.502072
 >> iter 70000, loss: 7.480973
   Number of active neurons: 2
 >> iter 71000, loss: 7.494537
 >> iter 72000, loss: 7.496104
 >> iter 73000, loss: 7.518735
 >> iter 74000, loss: 7.494986
 >> iter 75000, loss: 7.497375
 >> iter 76000, loss: 7.478998
 >> iter 77000, loss: 7.496846
 >> iter 78000, loss: 7.487889
 >> iter 79000, loss: 7.492699
 >> iter 80000, loss: 7.479905
   Number of active neurons: 2
 >> iter 81000, loss: 7.548673
 >> iter 82000, loss: 7.504433
 >> iter 83000, loss: 7.500790
 >> iter 84000, loss: 7.481964
 >> iter 85000, loss: 7.523943
 >> iter 86000, loss: 7.492895
 >> iter 87000, loss: 7.540176
 >> iter 88000, loss: 7.503630
 >> iter 89000, loss: 7.492898
 >> iter 90000, loss: 7.480306
   Number of active neurons: 2
 >> iter 91000, loss: 7.487095
 >> iter 92000, loss: 7.481825
 >> iter 93000, loss: 7.484693
 >> iter 94000, loss: 7.481012
 >> iter 95000, loss: 7.483248
 >> iter 96000, loss: 7.479732
 >> iter 97000, loss: 7.516330
 >> iter 98000, loss: 7.499748
 >> iter 99000, loss: 7.493139
 >> iter 100000, loss: 7.489234
   Number of active neurons: 2
 >> iter 101000, loss: 7.488933
 >> iter 102000, loss: 7.486038
 >> iter 103000, loss: 7.485121
 >> iter 104000, loss: 7.486169
 >> iter 105000, loss: 7.494094
 >> iter 106000, loss: 7.565852
 >> iter 107000, loss: 7.527718
 >> iter 108000, loss: 7.507840
 >> iter 109000, loss: 7.511929
 >> iter 110000, loss: 7.490941
   Number of active neurons: 2
 >> iter 111000, loss: 7.498732
 >> iter 112000, loss: 7.487112
 >> iter 113000, loss: 7.487135
 >> iter 114000, loss: 7.491676
 >> iter 115000, loss: 7.548725
 >> iter 116000, loss: 7.505051
 >> iter 117000, loss: 7.504218
 >> iter 118000, loss: 7.487575
 >> iter 119000, loss: 7.511022
 >> iter 120000, loss: 7.501580
   Number of active neurons: 2
 >> iter 121000, loss: 7.508808
 >> iter 122000, loss: 7.489413
 >> iter 123000, loss: 7.501886
 >> iter 124000, loss: 7.503998
 >> iter 125000, loss: 7.500670
 >> iter 126000, loss: 7.525049
 >> iter 127000, loss: 7.515682
 >> iter 128000, loss: 7.497193
 >> iter 129000, loss: 7.511878
 >> iter 130000, loss: 7.495964
   Number of active neurons: 2
 >> iter 131000, loss: 7.496874
 >> iter 132000, loss: 7.483399
 >> iter 133000, loss: 7.493949
 >> iter 134000, loss: 7.485034
 >> iter 135000, loss: 7.493683
 >> iter 136000, loss: 7.485280
 >> iter 137000, loss: 7.497792
 >> iter 138000, loss: 7.483449
 >> iter 139000, loss: 7.497905
 >> iter 140000, loss: 7.508443
   Number of active neurons: 2
 >> iter 141000, loss: 7.504660
 >> iter 142000, loss: 7.488298
 >> iter 143000, loss: 7.497026
 >> iter 144000, loss: 7.488469
 >> iter 145000, loss: 7.494177
 >> iter 146000, loss: 7.485736
 >> iter 147000, loss: 7.488771
 >> iter 148000, loss: 7.489304
 >> iter 149000, loss: 7.494762
 >> iter 150000, loss: 7.489885
   Number of active neurons: 2
 >> iter 151000, loss: 7.521648
 >> iter 152000, loss: 7.500452
 >> iter 153000, loss: 7.502486
 >> iter 154000, loss: 7.495356
 >> iter 155000, loss: 7.493664
 >> iter 156000, loss: 7.488105
 >> iter 157000, loss: 7.527945
 >> iter 158000, loss: 7.503411
 >> iter 159000, loss: 7.493890
 >> iter 160000, loss: 7.490513
   Number of active neurons: 2
 >> iter 161000, loss: 7.498781
 >> iter 162000, loss: 7.496322
 >> iter 163000, loss: 7.487744
 >> iter 164000, loss: 7.496279
 >> iter 165000, loss: 7.498249
 >> iter 166000, loss: 7.495485
 >> iter 167000, loss: 7.495186
 >> iter 168000, loss: 7.495403
 >> iter 169000, loss: 7.491709
 >> iter 170000, loss: 7.504193
   Number of active neurons: 2
 >> iter 171000, loss: 7.490782
 >> iter 172000, loss: 7.497366
 >> iter 173000, loss: 7.491147
 >> iter 174000, loss: 7.495212
 >> iter 175000, loss: 7.497228
 >> iter 176000, loss: 7.502056
 >> iter 177000, loss: 7.492958
 >> iter 178000, loss: 7.494999
 >> iter 179000, loss: 7.509308
 >> iter 180000, loss: 7.504927
   Number of active neurons: 2
 >> iter 181000, loss: 7.494068
 >> iter 182000, loss: 7.498615
 >> iter 183000, loss: 7.541358
 >> iter 184000, loss: 7.523661
 >> iter 185000, loss: 7.497719
 >> iter 186000, loss: 7.496088
 >> iter 187000, loss: 7.489491
 >> iter 188000, loss: 7.499299
 >> iter 189000, loss: 7.490905
 >> iter 190000, loss: 7.492731
   Number of active neurons: 2
 >> iter 191000, loss: 7.502139
 >> iter 192000, loss: 7.505257
 >> iter 193000, loss: 7.554652
 >> iter 194000, loss: 7.519278
 >> iter 195000, loss: 7.512614
 >> iter 196000, loss: 7.505046
 >> iter 197000, loss: 7.500584
 >> iter 198000, loss: 7.561082
 >> iter 199000, loss: 7.516368
 >> iter 200000, loss: 7.503070
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 21.2595748085
   - Test - Long: 24.4987750612
   - Test - Big: 21.1897881021
   - Test - A: 32.8911405906
   - Test - B: 33.404439704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.941987
 >> iter 2000, loss: 13.046977
 >> iter 3000, loss: 9.623605
 >> iter 4000, loss: 8.304632
 >> iter 5000, loss: 7.834006
 >> iter 6000, loss: 7.663678
 >> iter 7000, loss: 7.582385
 >> iter 8000, loss: 7.542518
 >> iter 9000, loss: 7.536485
 >> iter 10000, loss: 7.494522
   Number of active neurons: 2
 >> iter 11000, loss: 7.498539
 >> iter 12000, loss: 7.521043
 >> iter 13000, loss: 7.510973
 >> iter 14000, loss: 7.501084
 >> iter 15000, loss: 7.503176
 >> iter 16000, loss: 7.517975
 >> iter 17000, loss: 7.510244
 >> iter 18000, loss: 7.544099
 >> iter 19000, loss: 7.526306
 >> iter 20000, loss: 7.511718
   Number of active neurons: 2
 >> iter 21000, loss: 7.509654
 >> iter 22000, loss: 7.492786
 >> iter 23000, loss: 7.504612
 >> iter 24000, loss: 7.526353
 >> iter 25000, loss: 7.511261
 >> iter 26000, loss: 7.491279
 >> iter 27000, loss: 7.495228
 >> iter 28000, loss: 7.542293
 >> iter 29000, loss: 7.529537
 >> iter 30000, loss: 7.502183
   Number of active neurons: 2
 >> iter 31000, loss: 7.537994
 >> iter 32000, loss: 7.613813
 >> iter 33000, loss: 7.547015
 >> iter 34000, loss: 7.516486
 >> iter 35000, loss: 7.514585
 >> iter 36000, loss: 7.545710
 >> iter 37000, loss: 7.521751
 >> iter 38000, loss: 7.494633
 >> iter 39000, loss: 7.500196
 >> iter 40000, loss: 7.518529
   Number of active neurons: 2
 >> iter 41000, loss: 7.508607
 >> iter 42000, loss: 7.500006
 >> iter 43000, loss: 7.503271
 >> iter 44000, loss: 7.483512
 >> iter 45000, loss: 7.493865
 >> iter 46000, loss: 7.494004
 >> iter 47000, loss: 7.495233
 >> iter 48000, loss: 7.477860
 >> iter 49000, loss: 7.512800
 >> iter 50000, loss: 7.490610
   Number of active neurons: 2
 >> iter 51000, loss: 7.515481
 >> iter 52000, loss: 7.486947
 >> iter 53000, loss: 7.493858
 >> iter 54000, loss: 7.480408
 >> iter 55000, loss: 7.528949
 >> iter 56000, loss: 7.491830
 >> iter 57000, loss: 7.499997
 >> iter 58000, loss: 7.489067
 >> iter 59000, loss: 7.494285
 >> iter 60000, loss: 7.496615
   Number of active neurons: 2
 >> iter 61000, loss: 7.498014
 >> iter 62000, loss: 7.480572
 >> iter 63000, loss: 7.497895
 >> iter 64000, loss: 7.492444
 >> iter 65000, loss: 7.498271
 >> iter 66000, loss: 7.503113
 >> iter 67000, loss: 7.539937
 >> iter 68000, loss: 7.495056
 >> iter 69000, loss: 7.495162
 >> iter 70000, loss: 7.478425
   Number of active neurons: 2
 >> iter 71000, loss: 7.492655
 >> iter 72000, loss: 7.478797
 >> iter 73000, loss: 7.489218
 >> iter 74000, loss: 7.478298
 >> iter 75000, loss: 7.510106
 >> iter 76000, loss: 7.482537
 >> iter 77000, loss: 7.528469
 >> iter 78000, loss: 7.490829
 >> iter 79000, loss: 7.497525
 >> iter 80000, loss: 7.492659
   Number of active neurons: 2
 >> iter 81000, loss: 7.540040
 >> iter 82000, loss: 7.499378
 >> iter 83000, loss: 7.501681
 >> iter 84000, loss: 7.522005
 >> iter 85000, loss: 7.504113
 >> iter 86000, loss: 7.484083
 >> iter 87000, loss: 7.491650
 >> iter 88000, loss: 7.493908
 >> iter 89000, loss: 7.493762
 >> iter 90000, loss: 7.482972
   Number of active neurons: 2
 >> iter 91000, loss: 7.490126
 >> iter 92000, loss: 7.484595
 >> iter 93000, loss: 7.483165
 >> iter 94000, loss: 7.487865
 >> iter 95000, loss: 7.497311
 >> iter 96000, loss: 7.486449
 >> iter 97000, loss: 7.497207
 >> iter 98000, loss: 7.488713
 >> iter 99000, loss: 7.487623
 >> iter 100000, loss: 7.503067
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 21.2595748085
   - Test - Long: 24.4987750612
   - Test - Big: 21.1897881021
   - Test - A: 32.8911405906
   - Test - B: 33.404439704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.885837
 >> iter 2000, loss: 17.133107
 >> iter 3000, loss: 16.091471
 >> iter 4000, loss: 15.738357
 >> iter 5000, loss: 15.576448
 >> iter 6000, loss: 15.548319
 >> iter 7000, loss: 15.509153
 >> iter 8000, loss: 15.522199
 >> iter 9000, loss: 15.499980
 >> iter 10000, loss: 15.519671
   Number of active neurons: 0
 >> iter 11000, loss: 15.498914
 >> iter 12000, loss: 15.519357
 >> iter 13000, loss: 15.498091
 >> iter 14000, loss: 15.520943
 >> iter 15000, loss: 15.499989
 >> iter 16000, loss: 15.521799
 >> iter 17000, loss: 15.498550
 >> iter 18000, loss: 15.521958
 >> iter 19000, loss: 15.499585
 >> iter 20000, loss: 15.521415
   Number of active neurons: 0
   SHOCK
   Setting new limit to 200000.0 iters...
   Number of active neurons: 0
 >> iter 21000, loss: 13.284925
 >> iter 22000, loss: 12.271430
 >> iter 23000, loss: 11.445788
 >> iter 24000, loss: 9.030868
 >> iter 25000, loss: 8.106351
 >> iter 26000, loss: 7.723868
 >> iter 27000, loss: 7.582253
 >> iter 28000, loss: 7.521352
 >> iter 29000, loss: 7.522003
 >> iter 30000, loss: 7.497634
   Number of active neurons: 2
 >> iter 31000, loss: 7.533047
 >> iter 32000, loss: 7.548094
 >> iter 33000, loss: 7.520683
 >> iter 34000, loss: 7.514874
 >> iter 35000, loss: 7.536845
 >> iter 36000, loss: 7.503936
 >> iter 37000, loss: 7.514704
 >> iter 38000, loss: 7.489750
 >> iter 39000, loss: 7.508006
 >> iter 40000, loss: 7.531466
   Number of active neurons: 2
 >> iter 41000, loss: 7.528688
 >> iter 42000, loss: 7.499420
 >> iter 43000, loss: 7.514831
 >> iter 44000, loss: 7.487683
 >> iter 45000, loss: 7.499919
 >> iter 46000, loss: 7.571507
 >> iter 47000, loss: 7.551497
 >> iter 48000, loss: 7.522763
 >> iter 49000, loss: 7.511755
 >> iter 50000, loss: 7.511648
   Number of active neurons: 2
 >> iter 51000, loss: 7.510231
 >> iter 52000, loss: 7.535363
 >> iter 53000, loss: 7.524839
 >> iter 54000, loss: 7.502167
 >> iter 55000, loss: 7.506504
 >> iter 56000, loss: 7.508375
 >> iter 57000, loss: 7.506283
 >> iter 58000, loss: 7.486780
 >> iter 59000, loss: 7.494630
 >> iter 60000, loss: 7.495433
   Number of active neurons: 2
 >> iter 61000, loss: 7.503480
 >> iter 62000, loss: 7.508170
 >> iter 63000, loss: 7.515511
 >> iter 64000, loss: 7.486873
 >> iter 65000, loss: 7.541274
 >> iter 66000, loss: 7.534670
 >> iter 67000, loss: 7.530177
 >> iter 68000, loss: 7.526018
 >> iter 69000, loss: 7.510768
 >> iter 70000, loss: 7.486108
   Number of active neurons: 2
 >> iter 71000, loss: 7.502152
 >> iter 72000, loss: 7.484043
 >> iter 73000, loss: 7.521284
 >> iter 74000, loss: 7.500136
 >> iter 75000, loss: 7.498804
 >> iter 76000, loss: 7.494470
 >> iter 77000, loss: 7.498364
 >> iter 78000, loss: 7.479589
 >> iter 79000, loss: 7.519164
 >> iter 80000, loss: 7.502397
   Number of active neurons: 2
 >> iter 81000, loss: 7.500785
 >> iter 82000, loss: 7.486947
 >> iter 83000, loss: 7.526302
 >> iter 84000, loss: 7.514689
 >> iter 85000, loss: 7.503661
 >> iter 86000, loss: 7.488152
 >> iter 87000, loss: 7.496128
 >> iter 88000, loss: 7.497320
 >> iter 89000, loss: 7.494048
 >> iter 90000, loss: 7.483221
   Number of active neurons: 2
 >> iter 91000, loss: 7.514165
 >> iter 92000, loss: 7.503639
 >> iter 93000, loss: 7.519112
 >> iter 94000, loss: 7.502393
 >> iter 95000, loss: 7.492883
 >> iter 96000, loss: 7.513613
 >> iter 97000, loss: 7.503632
 >> iter 98000, loss: 7.503866
 >> iter 99000, loss: 7.557710
 >> iter 100000, loss: 7.515370
   Number of active neurons: 2
 >> iter 101000, loss: 7.498725
 >> iter 102000, loss: 7.489214
 >> iter 103000, loss: 7.486701
 >> iter 104000, loss: 7.486410
 >> iter 105000, loss: 7.488173
 >> iter 106000, loss: 7.572765
 >> iter 107000, loss: 7.520142
 >> iter 108000, loss: 7.502296
 >> iter 109000, loss: 7.512387
 >> iter 110000, loss: 7.491063
   Number of active neurons: 2
 >> iter 111000, loss: 7.488898
 >> iter 112000, loss: 7.488184
 >> iter 113000, loss: 7.486387
 >> iter 114000, loss: 7.484129
 >> iter 115000, loss: 7.493839
 >> iter 116000, loss: 7.487502
 >> iter 117000, loss: 7.494307
 >> iter 118000, loss: 7.497829
 >> iter 119000, loss: 7.494689
 >> iter 120000, loss: 7.483797
   Number of active neurons: 2
 >> iter 121000, loss: 7.490550
 >> iter 122000, loss: 7.479586
 >> iter 123000, loss: 7.487563
 >> iter 124000, loss: 7.493031
 >> iter 125000, loss: 7.498224
 >> iter 126000, loss: 7.520925
 >> iter 127000, loss: 7.506241
 >> iter 128000, loss: 7.500706
 >> iter 129000, loss: 7.540674
 >> iter 130000, loss: 7.534249
   Number of active neurons: 2
 >> iter 131000, loss: 7.525203
 >> iter 132000, loss: 7.497870
 >> iter 133000, loss: 7.508982
 >> iter 134000, loss: 7.488314
 >> iter 135000, loss: 7.495900
 >> iter 136000, loss: 7.483917
 >> iter 137000, loss: 7.500596
 >> iter 138000, loss: 7.513301
 >> iter 139000, loss: 7.508624
 >> iter 140000, loss: 7.492709
   Number of active neurons: 2
 >> iter 141000, loss: 7.523484
 >> iter 142000, loss: 7.495314
 >> iter 143000, loss: 7.548760
 >> iter 144000, loss: 7.506134
 >> iter 145000, loss: 7.502865
 >> iter 146000, loss: 7.495713
 >> iter 147000, loss: 7.510953
 >> iter 148000, loss: 7.502449
 >> iter 149000, loss: 7.494299
 >> iter 150000, loss: 7.505816
   Number of active neurons: 2
 >> iter 151000, loss: 7.498147
 >> iter 152000, loss: 7.487730
 >> iter 153000, loss: 7.492204
 >> iter 154000, loss: 7.488397
 >> iter 155000, loss: 7.515061
 >> iter 156000, loss: 7.501512
 >> iter 157000, loss: 7.497818
 >> iter 158000, loss: 7.491259
 >> iter 159000, loss: 7.492937
 >> iter 160000, loss: 7.490169
   Number of active neurons: 2
 >> iter 161000, loss: 7.485715
 >> iter 162000, loss: 7.506339
 >> iter 163000, loss: 7.495257
 >> iter 164000, loss: 7.490582
 >> iter 165000, loss: 7.492807
 >> iter 166000, loss: 7.491976
 >> iter 167000, loss: 7.498014
 >> iter 168000, loss: 7.497502
 >> iter 169000, loss: 7.521259
 >> iter 170000, loss: 7.507241
   Number of active neurons: 2
 >> iter 171000, loss: 7.492847
 >> iter 172000, loss: 7.498548
 >> iter 173000, loss: 7.492203
 >> iter 174000, loss: 7.504170
 >> iter 175000, loss: 7.529981
 >> iter 176000, loss: 7.510129
 >> iter 177000, loss: 7.489939
 >> iter 178000, loss: 7.494666
 >> iter 179000, loss: 7.498155
 >> iter 180000, loss: 7.527349
   Number of active neurons: 2
 >> iter 181000, loss: 7.508744
 >> iter 182000, loss: 7.500989
 >> iter 183000, loss: 7.500548
 >> iter 184000, loss: 7.498287
 >> iter 185000, loss: 7.484872
 >> iter 186000, loss: 7.492487
 >> iter 187000, loss: 7.494025
 >> iter 188000, loss: 7.499422
 >> iter 189000, loss: 7.490653
 >> iter 190000, loss: 7.493064
   Number of active neurons: 2
 >> iter 191000, loss: 7.505165
 >> iter 192000, loss: 7.507316
 >> iter 193000, loss: 7.502093
 >> iter 194000, loss: 7.497786
 >> iter 195000, loss: 7.488631
 >> iter 196000, loss: 7.494277
 >> iter 197000, loss: 7.489705
 >> iter 198000, loss: 7.505460
 >> iter 199000, loss: 7.493453
 >> iter 200000, loss: 7.499781
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 21.2595748085
   - Test - Long: 24.4987750612
   - Test - Big: 21.1897881021
   - Test - A: 32.8911405906
   - Test - B: 33.404439704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.974254
 >> iter 2000, loss: 13.979769
 >> iter 3000, loss: 12.446766
 >> iter 4000, loss: 11.188617
 >> iter 5000, loss: 8.924727
 >> iter 6000, loss: 8.043281
 >> iter 7000, loss: 7.739435
 >> iter 8000, loss: 7.591919
 >> iter 9000, loss: 7.565764
 >> iter 10000, loss: 7.538663
   Number of active neurons: 2
 >> iter 11000, loss: 7.524931
 >> iter 12000, loss: 7.499474
 >> iter 13000, loss: 7.594007
 >> iter 14000, loss: 7.559864
 >> iter 15000, loss: 7.565251
 >> iter 16000, loss: 7.539064
 >> iter 17000, loss: 7.519389
 >> iter 18000, loss: 7.493537
 >> iter 19000, loss: 7.496855
 >> iter 20000, loss: 7.496299
   Number of active neurons: 2
 >> iter 21000, loss: 7.547304
 >> iter 22000, loss: 7.535639
 >> iter 23000, loss: 7.551706
 >> iter 24000, loss: 7.495542
 >> iter 25000, loss: 7.501139
 >> iter 26000, loss: 7.501943
 >> iter 27000, loss: 7.552414
 >> iter 28000, loss: 7.516547
 >> iter 29000, loss: 7.507318
 >> iter 30000, loss: 7.485113
   Number of active neurons: 2
 >> iter 31000, loss: 7.500917
 >> iter 32000, loss: 7.500572
 >> iter 33000, loss: 7.509326
 >> iter 34000, loss: 7.549366
 >> iter 35000, loss: 7.530731
 >> iter 36000, loss: 7.504383
 >> iter 37000, loss: 7.518954
 >> iter 38000, loss: 7.516694
 >> iter 39000, loss: 7.520017
 >> iter 40000, loss: 7.493139
   Number of active neurons: 2
 >> iter 41000, loss: 7.503805
 >> iter 42000, loss: 7.488795
 >> iter 43000, loss: 7.494291
 >> iter 44000, loss: 7.513996
 >> iter 45000, loss: 7.527473
 >> iter 46000, loss: 7.497248
 >> iter 47000, loss: 7.501557
 >> iter 48000, loss: 7.477233
 >> iter 49000, loss: 7.491397
 >> iter 50000, loss: 7.526361
   Number of active neurons: 2
 >> iter 51000, loss: 7.539790
 >> iter 52000, loss: 7.495192
 >> iter 53000, loss: 7.501493
 >> iter 54000, loss: 7.478278
 >> iter 55000, loss: 7.500986
 >> iter 56000, loss: 7.493642
 >> iter 57000, loss: 7.496485
 >> iter 58000, loss: 7.479981
 >> iter 59000, loss: 7.493780
 >> iter 60000, loss: 7.477416
   Number of active neurons: 2
 >> iter 61000, loss: 7.513050
 >> iter 62000, loss: 7.500643
 >> iter 63000, loss: 7.504751
 >> iter 64000, loss: 7.486698
 >> iter 65000, loss: 7.494362
 >> iter 66000, loss: 7.479216
 >> iter 67000, loss: 7.494786
 >> iter 68000, loss: 7.478177
 >> iter 69000, loss: 7.497390
 >> iter 70000, loss: 7.480056
   Number of active neurons: 2
 >> iter 71000, loss: 7.502634
 >> iter 72000, loss: 7.509757
 >> iter 73000, loss: 7.504836
 >> iter 74000, loss: 7.487481
 >> iter 75000, loss: 7.507512
 >> iter 76000, loss: 7.482189
 >> iter 77000, loss: 7.495692
 >> iter 78000, loss: 7.481095
 >> iter 79000, loss: 7.492001
 >> iter 80000, loss: 7.480202
   Number of active neurons: 2
 >> iter 81000, loss: 7.488265
 >> iter 82000, loss: 7.495636
 >> iter 83000, loss: 7.497046
 >> iter 84000, loss: 7.485795
 >> iter 85000, loss: 7.490002
 >> iter 86000, loss: 7.479348
 >> iter 87000, loss: 7.487568
 >> iter 88000, loss: 7.481534
 >> iter 89000, loss: 7.488895
 >> iter 90000, loss: 7.481417
   Number of active neurons: 2
 >> iter 91000, loss: 7.488010
 >> iter 92000, loss: 7.504005
 >> iter 93000, loss: 7.504870
 >> iter 94000, loss: 7.492418
 >> iter 95000, loss: 7.486305
 >> iter 96000, loss: 7.504151
 >> iter 97000, loss: 7.586864
 >> iter 98000, loss: 7.568084
 >> iter 99000, loss: 7.525993
 >> iter 100000, loss: 7.505828
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 21.2595748085
   - Test - Long: 24.4987750612
   - Test - Big: 21.1897881021
   - Test - A: 32.8911405906
   - Test - B: 33.404439704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.322672
 >> iter 2000, loss: 14.557177
 >> iter 3000, loss: 13.175437
 >> iter 4000, loss: 12.650013
 >> iter 5000, loss: 12.454638
 >> iter 6000, loss: 12.379772
 >> iter 7000, loss: 12.356642
 >> iter 8000, loss: 12.338847
 >> iter 9000, loss: 12.344673
 >> iter 10000, loss: 12.322488
   Number of active neurons: 1
 >> iter 11000, loss: 12.337571
 >> iter 12000, loss: 12.334252
 >> iter 13000, loss: 12.348225
 >> iter 14000, loss: 12.332009
 >> iter 15000, loss: 12.338942
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 12.017382
 >> iter 17000, loss: 11.833096
 >> iter 18000, loss: 11.685439
 >> iter 19000, loss: 11.648863
 >> iter 20000, loss: 11.631162
   Number of active neurons: 2
 >> iter 21000, loss: 11.624968
 >> iter 22000, loss: 11.357965
 >> iter 23000, loss: 9.008870
 >> iter 24000, loss: 8.088867
 >> iter 25000, loss: 7.753775
 >> iter 26000, loss: 7.583154
 >> iter 27000, loss: 7.560207
 >> iter 28000, loss: 7.555419
 >> iter 29000, loss: 7.551760
 >> iter 30000, loss: 7.521507
   Number of active neurons: 2
 >> iter 31000, loss: 7.511601
 >> iter 32000, loss: 7.488144
 >> iter 33000, loss: 7.496264
 >> iter 34000, loss: 7.503093
 >> iter 35000, loss: 7.506410
 >> iter 36000, loss: 7.499387
 >> iter 37000, loss: 7.508667
 >> iter 38000, loss: 7.499163
 >> iter 39000, loss: 7.512701
 >> iter 40000, loss: 7.486275
   Number of active neurons: 2
 >> iter 41000, loss: 7.541289
 >> iter 42000, loss: 7.498520
 >> iter 43000, loss: 7.500463
 >> iter 44000, loss: 7.476603
 >> iter 45000, loss: 7.490734
 >> iter 46000, loss: 7.481811
 >> iter 47000, loss: 7.496893
 >> iter 48000, loss: 7.525129
 >> iter 49000, loss: 7.511959
 >> iter 50000, loss: 7.489407
   Number of active neurons: 2
 >> iter 51000, loss: 7.502233
 >> iter 52000, loss: 7.491370
 >> iter 53000, loss: 7.499572
 >> iter 54000, loss: 7.514844
 >> iter 55000, loss: 7.588638
 >> iter 56000, loss: 7.510809
 >> iter 57000, loss: 7.517823
 >> iter 58000, loss: 7.527015
 >> iter 59000, loss: 7.570135
 >> iter 60000, loss: 7.536513
   Number of active neurons: 2
 >> iter 61000, loss: 7.510541
 >> iter 62000, loss: 7.481496
 >> iter 63000, loss: 7.502655
 >> iter 64000, loss: 7.500407
 >> iter 65000, loss: 7.499642
 >> iter 66000, loss: 7.508583
 >> iter 67000, loss: 7.505609
 >> iter 68000, loss: 7.518428
 >> iter 69000, loss: 7.507278
 >> iter 70000, loss: 7.500388
   Number of active neurons: 2
 >> iter 71000, loss: 7.516048
 >> iter 72000, loss: 7.515812
 >> iter 73000, loss: 7.510067
 >> iter 74000, loss: 7.497067
 >> iter 75000, loss: 7.502639
 >> iter 76000, loss: 7.483219
 >> iter 77000, loss: 7.489171
 >> iter 78000, loss: 7.479203
 >> iter 79000, loss: 7.491792
 >> iter 80000, loss: 7.474775
   Number of active neurons: 2
 >> iter 81000, loss: 7.482431
 >> iter 82000, loss: 7.513448
 >> iter 83000, loss: 7.514204
 >> iter 84000, loss: 7.516389
 >> iter 85000, loss: 7.505486
 >> iter 86000, loss: 7.493821
 >> iter 87000, loss: 7.492877
 >> iter 88000, loss: 7.495241
 >> iter 89000, loss: 7.512597
 >> iter 90000, loss: 7.489552
   Number of active neurons: 2
 >> iter 91000, loss: 7.491929
 >> iter 92000, loss: 7.490974
 >> iter 93000, loss: 7.489321
 >> iter 94000, loss: 7.500793
 >> iter 95000, loss: 7.490410
 >> iter 96000, loss: 7.483693
 >> iter 97000, loss: 7.485340
 >> iter 98000, loss: 7.482761
 >> iter 99000, loss: 7.501650
 >> iter 100000, loss: 7.487243
   Number of active neurons: 2
 >> iter 101000, loss: 7.503079
 >> iter 102000, loss: 7.502971
 >> iter 103000, loss: 7.492165
 >> iter 104000, loss: 7.515431
 >> iter 105000, loss: 7.498664
 >> iter 106000, loss: 7.488149
 >> iter 107000, loss: 7.505996
 >> iter 108000, loss: 7.487001
 >> iter 109000, loss: 7.486381
 >> iter 110000, loss: 7.551565
   Number of active neurons: 2
 >> iter 111000, loss: 7.517849
 >> iter 112000, loss: 7.499696
 >> iter 113000, loss: 7.498746
 >> iter 114000, loss: 7.494157
 >> iter 115000, loss: 7.492868
 >> iter 116000, loss: 7.486809
 >> iter 117000, loss: 7.500087
 >> iter 118000, loss: 7.486029
 >> iter 119000, loss: 7.494101
 >> iter 120000, loss: 7.481845
   Number of active neurons: 2
 >> iter 121000, loss: 7.489871
 >> iter 122000, loss: 7.481969
 >> iter 123000, loss: 7.491038
 >> iter 124000, loss: 7.511454
 >> iter 125000, loss: 7.499492
 >> iter 126000, loss: 7.485058
 >> iter 127000, loss: 7.489828
 >> iter 128000, loss: 7.499732
 >> iter 129000, loss: 7.504185
 >> iter 130000, loss: 7.492096
   Number of active neurons: 2
 >> iter 131000, loss: 7.498304
 >> iter 132000, loss: 7.504838
 >> iter 133000, loss: 7.577536
 >> iter 134000, loss: 7.525979
 >> iter 135000, loss: 7.511506
 >> iter 136000, loss: 7.506185
 >> iter 137000, loss: 7.506702
 >> iter 138000, loss: 7.494504
 >> iter 139000, loss: 7.494657
 >> iter 140000, loss: 7.482759
   Number of active neurons: 2
 >> iter 141000, loss: 7.499465
 >> iter 142000, loss: 7.484650
 >> iter 143000, loss: 7.492617
 >> iter 144000, loss: 7.482235
 >> iter 145000, loss: 7.493924
 >> iter 146000, loss: 7.489405
 >> iter 147000, loss: 7.500754
 >> iter 148000, loss: 7.491428
 >> iter 149000, loss: 7.494258
 >> iter 150000, loss: 7.488020
   Number of active neurons: 2
 >> iter 151000, loss: 7.497576
 >> iter 152000, loss: 7.492935
 >> iter 153000, loss: 7.491599
 >> iter 154000, loss: 7.486598
 >> iter 155000, loss: 7.489759
 >> iter 156000, loss: 7.513884
 >> iter 157000, loss: 7.531408
 >> iter 158000, loss: 7.504638
 >> iter 159000, loss: 7.497177
 >> iter 160000, loss: 7.519705
   Number of active neurons: 2
 >> iter 161000, loss: 7.499612
 >> iter 162000, loss: 7.533228
 >> iter 163000, loss: 7.505571
 >> iter 164000, loss: 7.534761
 >> iter 165000, loss: 7.505846
 >> iter 166000, loss: 7.514362
 >> iter 167000, loss: 7.498492
 >> iter 168000, loss: 7.502213
 >> iter 169000, loss: 7.505703
 >> iter 170000, loss: 7.507826
   Number of active neurons: 2
 >> iter 171000, loss: 7.491978
 >> iter 172000, loss: 7.496607
 >> iter 173000, loss: 7.511706
 >> iter 174000, loss: 7.505248
 >> iter 175000, loss: 7.495815
 >> iter 176000, loss: 7.510574
 >> iter 177000, loss: 7.522872
 >> iter 178000, loss: 7.523895
 >> iter 179000, loss: 7.497804
 >> iter 180000, loss: 7.497784
   Number of active neurons: 2
 >> iter 181000, loss: 7.492996
 >> iter 182000, loss: 7.508920
 >> iter 183000, loss: 7.523213
 >> iter 184000, loss: 7.527540
 >> iter 185000, loss: 7.518517
 >> iter 186000, loss: 7.517335
 >> iter 187000, loss: 7.524414
 >> iter 188000, loss: 7.509767
 >> iter 189000, loss: 7.494590
 >> iter 190000, loss: 7.565596
   Number of active neurons: 2
 >> iter 191000, loss: 7.513354
 >> iter 192000, loss: 7.511897
 >> iter 193000, loss: 7.494320
 >> iter 194000, loss: 7.539937
 >> iter 195000, loss: 7.575698
 >> iter 196000, loss: 7.521703
 >> iter 197000, loss: 7.500888
 >> iter 198000, loss: 7.500207
 >> iter 199000, loss: 7.559743
 >> iter 200000, loss: 7.522809
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 21.2595748085
   - Test - Long: 24.4987750612
   - Test - Big: 21.1897881021
   - Test - A: 32.8911405906
   - Test - B: 33.404439704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.287852
 >> iter 2000, loss: 14.539148
 >> iter 3000, loss: 13.151759
 >> iter 4000, loss: 12.635514
 >> iter 5000, loss: 12.449335
 >> iter 6000, loss: 12.378289
 >> iter 7000, loss: 12.359240
 >> iter 8000, loss: 12.338117
 >> iter 9000, loss: 12.342207
 >> iter 10000, loss: 12.333207
   Number of active neurons: 1
 >> iter 11000, loss: 12.347716
 >> iter 12000, loss: 12.331552
 >> iter 13000, loss: 12.343016
 >> iter 14000, loss: 12.333645
 >> iter 15000, loss: 12.346306
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 11.940149
 >> iter 17000, loss: 11.780775
 >> iter 18000, loss: 11.665390
 >> iter 19000, loss: 11.598990
 >> iter 20000, loss: 11.559285
   Number of active neurons: 2
 >> iter 21000, loss: 9.166802
 >> iter 22000, loss: 8.134264
 >> iter 23000, loss: 7.749652
 >> iter 24000, loss: 7.598223
 >> iter 25000, loss: 7.558303
 >> iter 26000, loss: 7.515099
 >> iter 27000, loss: 7.528955
 >> iter 28000, loss: 7.496225
 >> iter 29000, loss: 7.502041
 >> iter 30000, loss: 7.484824
   Number of active neurons: 2
 >> iter 31000, loss: 7.508747
 >> iter 32000, loss: 7.503822
 >> iter 33000, loss: 7.542890
 >> iter 34000, loss: 7.535124
 >> iter 35000, loss: 7.518072
 >> iter 36000, loss: 7.514089
 >> iter 37000, loss: 7.508135
 >> iter 38000, loss: 7.487272
 >> iter 39000, loss: 7.498767
 >> iter 40000, loss: 7.482146
   Number of active neurons: 2
 >> iter 41000, loss: 7.496221
 >> iter 42000, loss: 7.492161
 >> iter 43000, loss: 7.498806
 >> iter 44000, loss: 7.482284
 >> iter 45000, loss: 7.495881
 >> iter 46000, loss: 7.478781
 >> iter 47000, loss: 7.496956
 >> iter 48000, loss: 7.479572
 >> iter 49000, loss: 7.503978
 >> iter 50000, loss: 7.477179
   Number of active neurons: 2
 >> iter 51000, loss: 7.493847
 >> iter 52000, loss: 7.477641
 >> iter 53000, loss: 7.495937
 >> iter 54000, loss: 7.483812
 >> iter 55000, loss: 7.497452
 >> iter 56000, loss: 7.479273
 >> iter 57000, loss: 7.490116
 >> iter 58000, loss: 7.488915
 >> iter 59000, loss: 7.520600
 >> iter 60000, loss: 7.496008
   Number of active neurons: 2
 >> iter 61000, loss: 7.538274
 >> iter 62000, loss: 7.497555
 >> iter 63000, loss: 7.566207
 >> iter 64000, loss: 7.504872
 >> iter 65000, loss: 7.500373
 >> iter 66000, loss: 7.500782
 >> iter 67000, loss: 7.508523
 >> iter 68000, loss: 7.497647
 >> iter 69000, loss: 7.523180
 >> iter 70000, loss: 7.496439
   Number of active neurons: 2
 >> iter 71000, loss: 7.505355
 >> iter 72000, loss: 7.496528
 >> iter 73000, loss: 7.494582
 >> iter 74000, loss: 7.478573
 >> iter 75000, loss: 7.503437
 >> iter 76000, loss: 7.499909
 >> iter 77000, loss: 7.494111
 >> iter 78000, loss: 7.484339
 >> iter 79000, loss: 7.494056
 >> iter 80000, loss: 7.496834
   Number of active neurons: 2
 >> iter 81000, loss: 7.491282
 >> iter 82000, loss: 7.488636
 >> iter 83000, loss: 7.492601
 >> iter 84000, loss: 7.514831
 >> iter 85000, loss: 7.529443
 >> iter 86000, loss: 7.533503
 >> iter 87000, loss: 7.515063
 >> iter 88000, loss: 7.510092
 >> iter 89000, loss: 7.528895
 >> iter 90000, loss: 7.523826
   Number of active neurons: 2
 >> iter 91000, loss: 7.505011
 >> iter 92000, loss: 7.503364
 >> iter 93000, loss: 7.491401
 >> iter 94000, loss: 7.500147
 >> iter 95000, loss: 7.489633
 >> iter 96000, loss: 7.490286
 >> iter 97000, loss: 7.489397
 >> iter 98000, loss: 7.518319
 >> iter 99000, loss: 7.501018
 >> iter 100000, loss: 7.491812
   Number of active neurons: 2
 >> iter 101000, loss: 7.490308
 >> iter 102000, loss: 7.483835
 >> iter 103000, loss: 7.488223
 >> iter 104000, loss: 7.482870
 >> iter 105000, loss: 7.493413
 >> iter 106000, loss: 7.486904
 >> iter 107000, loss: 7.515806
 >> iter 108000, loss: 7.499336
 >> iter 109000, loss: 7.494136
 >> iter 110000, loss: 7.486860
   Number of active neurons: 2
 >> iter 111000, loss: 7.491591
 >> iter 112000, loss: 7.494343
 >> iter 113000, loss: 7.486811
 >> iter 114000, loss: 7.574173
 >> iter 115000, loss: 7.523150
 >> iter 116000, loss: 7.492605
 >> iter 117000, loss: 7.516419
 >> iter 118000, loss: 7.495073
 >> iter 119000, loss: 7.496605
 >> iter 120000, loss: 7.486618
   Number of active neurons: 2
 >> iter 121000, loss: 7.493312
 >> iter 122000, loss: 7.479745
 >> iter 123000, loss: 7.485092
 >> iter 124000, loss: 7.480909
 >> iter 125000, loss: 7.490307
 >> iter 126000, loss: 7.486443
 >> iter 127000, loss: 7.492789
 >> iter 128000, loss: 7.511881
 >> iter 129000, loss: 7.517355
 >> iter 130000, loss: 7.495330
   Number of active neurons: 2
 >> iter 131000, loss: 7.508384
 >> iter 132000, loss: 7.536584
 >> iter 133000, loss: 7.522970
 >> iter 134000, loss: 7.504783
 >> iter 135000, loss: 7.508823
 >> iter 136000, loss: 7.491236
 >> iter 137000, loss: 7.496967
 >> iter 138000, loss: 7.484991
 >> iter 139000, loss: 7.516550
 >> iter 140000, loss: 7.502241
   Number of active neurons: 2
 >> iter 141000, loss: 7.502193
 >> iter 142000, loss: 7.486964
 >> iter 143000, loss: 7.516229
 >> iter 144000, loss: 7.536388
 >> iter 145000, loss: 7.515989
 >> iter 146000, loss: 7.492349
 >> iter 147000, loss: 7.515546
 >> iter 148000, loss: 7.505845
 >> iter 149000, loss: 7.502480
 >> iter 150000, loss: 7.509641
   Number of active neurons: 2
 >> iter 151000, loss: 7.503552
 >> iter 152000, loss: 7.494322
 >> iter 153000, loss: 7.534553
 >> iter 154000, loss: 7.508828
 >> iter 155000, loss: 7.505144
 >> iter 156000, loss: 7.494441
 >> iter 157000, loss: 7.493693
 >> iter 158000, loss: 7.489328
 >> iter 159000, loss: 7.497433
 >> iter 160000, loss: 7.501917
   Number of active neurons: 2
 >> iter 161000, loss: 7.505156
 >> iter 162000, loss: 7.509076
 >> iter 163000, loss: 7.489154
 >> iter 164000, loss: 7.493703
 >> iter 165000, loss: 7.511346
 >> iter 166000, loss: 7.500084
 >> iter 167000, loss: 7.496467
 >> iter 168000, loss: 7.497022
 >> iter 169000, loss: 7.498980
 >> iter 170000, loss: 7.495774
   Number of active neurons: 2
 >> iter 171000, loss: 7.486844
 >> iter 172000, loss: 7.493105
 >> iter 173000, loss: 7.485144
 >> iter 174000, loss: 7.494000
 >> iter 175000, loss: 7.512931
 >> iter 176000, loss: 7.509069
 >> iter 177000, loss: 7.492811
 >> iter 178000, loss: 7.495807
 >> iter 179000, loss: 7.485566
 >> iter 180000, loss: 7.500907
   Number of active neurons: 2
 >> iter 181000, loss: 7.499262
 >> iter 182000, loss: 7.498509
 >> iter 183000, loss: 7.490561
 >> iter 184000, loss: 7.524912
 >> iter 185000, loss: 7.499105
 >> iter 186000, loss: 7.498755
 >> iter 187000, loss: 7.496766
 >> iter 188000, loss: 7.497674
 >> iter 189000, loss: 7.513754
 >> iter 190000, loss: 7.508633
   Number of active neurons: 2
 >> iter 191000, loss: 7.515695
 >> iter 192000, loss: 7.505336
 >> iter 193000, loss: 7.574732
 >> iter 194000, loss: 7.539343
 >> iter 195000, loss: 7.506024
 >> iter 196000, loss: 7.501828
 >> iter 197000, loss: 7.531894
 >> iter 198000, loss: 7.515554
 >> iter 199000, loss: 7.496954
 >> iter 200000, loss: 7.496212
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 21.2595748085
   - Test - Long: 24.4987750612
   - Test - Big: 21.1897881021
   - Test - A: 32.8911405906
   - Test - B: 33.404439704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.275870
 >> iter 2000, loss: 14.541972
 >> iter 3000, loss: 13.164505
 >> iter 4000, loss: 12.637215
 >> iter 5000, loss: 12.456934
 >> iter 6000, loss: 12.382485
 >> iter 7000, loss: 12.354959
 >> iter 8000, loss: 12.333049
 >> iter 9000, loss: 12.342722
 >> iter 10000, loss: 12.327231
   Number of active neurons: 1
 >> iter 11000, loss: 12.340882
 >> iter 12000, loss: 12.327011
 >> iter 13000, loss: 12.341045
 >> iter 14000, loss: 12.334776
 >> iter 15000, loss: 12.335492
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 12.007087
 >> iter 17000, loss: 11.743812
 >> iter 18000, loss: 11.661743
 >> iter 19000, loss: 11.608204
 >> iter 20000, loss: 10.379582
   Number of active neurons: 2
 >> iter 21000, loss: 8.599241
 >> iter 22000, loss: 7.906910
 >> iter 23000, loss: 7.657769
 >> iter 24000, loss: 7.554570
 >> iter 25000, loss: 7.524568
 >> iter 26000, loss: 7.517680
 >> iter 27000, loss: 7.506376
 >> iter 28000, loss: 7.548453
 >> iter 29000, loss: 7.533235
 >> iter 30000, loss: 7.518970
   Number of active neurons: 2
 >> iter 31000, loss: 7.508124
 >> iter 32000, loss: 7.591666
 >> iter 33000, loss: 7.674276
 >> iter 34000, loss: 7.580607
 >> iter 35000, loss: 7.555440
 >> iter 36000, loss: 7.506701
 >> iter 37000, loss: 7.528284
 >> iter 38000, loss: 7.494613
 >> iter 39000, loss: 7.501181
 >> iter 40000, loss: 7.521413
   Number of active neurons: 2
 >> iter 41000, loss: 7.537350
 >> iter 42000, loss: 7.493754
 >> iter 43000, loss: 7.498691
 >> iter 44000, loss: 7.482453
 >> iter 45000, loss: 7.522512
 >> iter 46000, loss: 7.511210
 >> iter 47000, loss: 7.511043
 >> iter 48000, loss: 7.482738
 >> iter 49000, loss: 7.503440
 >> iter 50000, loss: 7.477149
   Number of active neurons: 2
 >> iter 51000, loss: 7.514232
 >> iter 52000, loss: 7.482031
 >> iter 53000, loss: 7.507622
 >> iter 54000, loss: 7.496224
 >> iter 55000, loss: 7.497649
 >> iter 56000, loss: 7.487227
 >> iter 57000, loss: 7.497685
 >> iter 58000, loss: 7.477714
 >> iter 59000, loss: 7.491156
 >> iter 60000, loss: 7.478418
   Number of active neurons: 2
 >> iter 61000, loss: 7.494001
 >> iter 62000, loss: 7.519243
 >> iter 63000, loss: 7.512693
 >> iter 64000, loss: 7.497147
 >> iter 65000, loss: 7.507085
 >> iter 66000, loss: 7.489549
 >> iter 67000, loss: 7.493976
 >> iter 68000, loss: 7.478609
 >> iter 69000, loss: 7.540600
 >> iter 70000, loss: 7.509923
   Number of active neurons: 2
 >> iter 71000, loss: 7.508169
 >> iter 72000, loss: 7.484000
 >> iter 73000, loss: 7.582813
 >> iter 74000, loss: 7.512431
 >> iter 75000, loss: 7.506258
 >> iter 76000, loss: 7.488200
 >> iter 77000, loss: 7.495730
 >> iter 78000, loss: 7.483675
 >> iter 79000, loss: 7.490918
 >> iter 80000, loss: 7.518147
   Number of active neurons: 2
 >> iter 81000, loss: 7.531664
 >> iter 82000, loss: 7.495781
 >> iter 83000, loss: 7.491605
 >> iter 84000, loss: 7.509061
 >> iter 85000, loss: 7.508619
 >> iter 86000, loss: 7.492993
 >> iter 87000, loss: 7.508405
 >> iter 88000, loss: 7.488953
 >> iter 89000, loss: 7.488440
 >> iter 90000, loss: 7.522176
   Number of active neurons: 2
 >> iter 91000, loss: 7.566161
 >> iter 92000, loss: 7.517308
 >> iter 93000, loss: 7.507878
 >> iter 94000, loss: 7.494624
 >> iter 95000, loss: 7.549388
 >> iter 96000, loss: 7.557081
 >> iter 97000, loss: 7.514866
 >> iter 98000, loss: 7.501218
 >> iter 99000, loss: 7.499845
 >> iter 100000, loss: 7.496982
   Number of active neurons: 2
 >> iter 101000, loss: 7.495157
 >> iter 102000, loss: 7.493320
 >> iter 103000, loss: 7.490307
 >> iter 104000, loss: 7.485378
 >> iter 105000, loss: 7.485455
 >> iter 106000, loss: 7.483164
 >> iter 107000, loss: 7.485986
 >> iter 108000, loss: 7.494919
 >> iter 109000, loss: 7.491888
 >> iter 110000, loss: 7.484791
   Number of active neurons: 2
 >> iter 111000, loss: 7.485049
 >> iter 112000, loss: 7.485232
 >> iter 113000, loss: 7.487230
 >> iter 114000, loss: 7.481595
 >> iter 115000, loss: 7.492485
 >> iter 116000, loss: 7.485641
 >> iter 117000, loss: 7.521188
 >> iter 118000, loss: 7.492499
 >> iter 119000, loss: 7.506586
 >> iter 120000, loss: 7.489752
   Number of active neurons: 2
 >> iter 121000, loss: 7.500533
 >> iter 122000, loss: 7.485331
 >> iter 123000, loss: 7.493446
 >> iter 124000, loss: 7.483850
 >> iter 125000, loss: 7.490981
 >> iter 126000, loss: 7.501924
 >> iter 127000, loss: 7.502187
 >> iter 128000, loss: 7.486718
 >> iter 129000, loss: 7.503246
 >> iter 130000, loss: 7.495012
   Number of active neurons: 2
 >> iter 131000, loss: 7.496736
 >> iter 132000, loss: 7.483905
 >> iter 133000, loss: 7.504933
 >> iter 134000, loss: 7.517565
 >> iter 135000, loss: 7.507025
 >> iter 136000, loss: 7.488135
 >> iter 137000, loss: 7.503015
 >> iter 138000, loss: 7.490271
 >> iter 139000, loss: 7.503644
 >> iter 140000, loss: 7.488416
   Number of active neurons: 2
 >> iter 141000, loss: 7.498664
 >> iter 142000, loss: 7.487175
 >> iter 143000, loss: 7.492282
 >> iter 144000, loss: 7.487139
 >> iter 145000, loss: 7.490679
 >> iter 146000, loss: 7.485607
 >> iter 147000, loss: 7.489936
 >> iter 148000, loss: 7.484655
 >> iter 149000, loss: 7.487186
 >> iter 150000, loss: 7.487236
   Number of active neurons: 2
 >> iter 151000, loss: 7.510673
 >> iter 152000, loss: 7.500167
 >> iter 153000, loss: 7.494354
 >> iter 154000, loss: 7.488555
 >> iter 155000, loss: 7.491242
 >> iter 156000, loss: 7.495721
 >> iter 157000, loss: 7.527016
 >> iter 158000, loss: 7.513318
 >> iter 159000, loss: 7.498126
 >> iter 160000, loss: 7.496097
   Number of active neurons: 2
 >> iter 161000, loss: 7.491399
 >> iter 162000, loss: 7.486981
 >> iter 163000, loss: 7.533158
 >> iter 164000, loss: 7.509778
 >> iter 165000, loss: 7.495153
 >> iter 166000, loss: 7.518350
 >> iter 167000, loss: 7.540423
 >> iter 168000, loss: 7.515647
 >> iter 169000, loss: 7.503157
 >> iter 170000, loss: 7.547162
   Number of active neurons: 2
 >> iter 171000, loss: 7.519380
 >> iter 172000, loss: 7.516730
 >> iter 173000, loss: 7.499963
 >> iter 174000, loss: 7.503175
 >> iter 175000, loss: 7.495901
 >> iter 176000, loss: 7.494545
 >> iter 177000, loss: 7.534994
 >> iter 178000, loss: 7.531756
 >> iter 179000, loss: 7.510654
 >> iter 180000, loss: 7.497915
   Number of active neurons: 2
 >> iter 181000, loss: 7.497353
 >> iter 182000, loss: 7.501689
 >> iter 183000, loss: 7.493519
 >> iter 184000, loss: 7.510738
 >> iter 185000, loss: 7.495477
 >> iter 186000, loss: 7.522478
 >> iter 187000, loss: 7.504765
 >> iter 188000, loss: 7.536135
 >> iter 189000, loss: 7.527764
 >> iter 190000, loss: 7.505637
   Number of active neurons: 2
 >> iter 191000, loss: 7.494874
 >> iter 192000, loss: 7.505452
 >> iter 193000, loss: 7.491371
 >> iter 194000, loss: 7.507137
 >> iter 195000, loss: 7.505905
 >> iter 196000, loss: 7.500378
 >> iter 197000, loss: 7.492313
 >> iter 198000, loss: 7.496440
 >> iter 199000, loss: 7.502611
 >> iter 200000, loss: 7.557283
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 21.2595748085
   - Test - Long: 24.4987750612
   - Test - Big: 21.1897881021
   - Test - A: 32.8911405906
   - Test - B: 33.404439704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.253435
 >> iter 2000, loss: 14.533039
 >> iter 3000, loss: 13.163048
 >> iter 4000, loss: 12.645985
 >> iter 5000, loss: 12.448607
 >> iter 6000, loss: 12.378695
 >> iter 7000, loss: 12.359591
 >> iter 8000, loss: 12.339432
 >> iter 9000, loss: 12.339225
 >> iter 10000, loss: 12.332684
   Number of active neurons: 1
 >> iter 11000, loss: 12.343436
 >> iter 12000, loss: 12.328703
 >> iter 13000, loss: 12.347276
 >> iter 14000, loss: 12.329648
 >> iter 15000, loss: 12.342157
   Number of active neurons: 1
   SHOCK
   Setting new limit to 200000.0 iters...
 >> iter 16000, loss: 12.151940
 >> iter 17000, loss: 11.886515
 >> iter 18000, loss: 11.744970
 >> iter 19000, loss: 11.649113
 >> iter 20000, loss: 11.595401
   Number of active neurons: 2
 >> iter 21000, loss: 11.597101
 >> iter 22000, loss: 9.538111
 >> iter 23000, loss: 8.276530
 >> iter 24000, loss: 7.840015
 >> iter 25000, loss: 7.638635
 >> iter 26000, loss: 7.538773
 >> iter 27000, loss: 7.521017
 >> iter 28000, loss: 7.517234
 >> iter 29000, loss: 7.518945
 >> iter 30000, loss: 7.530536
   Number of active neurons: 2
 >> iter 31000, loss: 7.523358
 >> iter 32000, loss: 7.494548
 >> iter 33000, loss: 7.564646
 >> iter 34000, loss: 7.531446
 >> iter 35000, loss: 7.515210
 >> iter 36000, loss: 7.495913
 >> iter 37000, loss: 7.506904
 >> iter 38000, loss: 7.502217
 >> iter 39000, loss: 7.514516
 >> iter 40000, loss: 7.490848
   Number of active neurons: 2
 >> iter 41000, loss: 7.520861
 >> iter 42000, loss: 7.508271
 >> iter 43000, loss: 7.504695
 >> iter 44000, loss: 7.500991
 >> iter 45000, loss: 7.502089
 >> iter 46000, loss: 7.535770
 >> iter 47000, loss: 7.513342
 >> iter 48000, loss: 7.504959
 >> iter 49000, loss: 7.506390
 >> iter 50000, loss: 7.481583
   Number of active neurons: 2
 >> iter 51000, loss: 7.500336
 >> iter 52000, loss: 7.481202
 >> iter 53000, loss: 7.495258
 >> iter 54000, loss: 7.507508
 >> iter 55000, loss: 7.600900
 >> iter 56000, loss: 7.518165
 >> iter 57000, loss: 7.508931
 >> iter 58000, loss: 7.479930
 >> iter 59000, loss: 7.524456
 >> iter 60000, loss: 7.507923
   Number of active neurons: 2
 >> iter 61000, loss: 7.508260
 >> iter 62000, loss: 7.482460
 >> iter 63000, loss: 7.509516
 >> iter 64000, loss: 7.493771
 >> iter 65000, loss: 7.508739
 >> iter 66000, loss: 7.484821
 >> iter 67000, loss: 7.500183
 >> iter 68000, loss: 7.481107
 >> iter 69000, loss: 7.491064
 >> iter 70000, loss: 7.504331
   Number of active neurons: 2
 >> iter 71000, loss: 7.506713
 >> iter 72000, loss: 7.508289
 >> iter 73000, loss: 7.511475
 >> iter 74000, loss: 7.502849
 >> iter 75000, loss: 7.500333
 >> iter 76000, loss: 7.486199
 >> iter 77000, loss: 7.492867
 >> iter 78000, loss: 7.536508
 >> iter 79000, loss: 7.508042
 >> iter 80000, loss: 7.487616
   Number of active neurons: 2
 >> iter 81000, loss: 7.489394
 >> iter 82000, loss: 7.476553
 >> iter 83000, loss: 7.499081
 >> iter 84000, loss: 7.501844
 >> iter 85000, loss: 7.518271
 >> iter 86000, loss: 7.507850
 >> iter 87000, loss: 7.509179
 >> iter 88000, loss: 7.491441
 >> iter 89000, loss: 7.493053
 >> iter 90000, loss: 7.493601
   Number of active neurons: 2
 >> iter 91000, loss: 7.488405
 >> iter 92000, loss: 7.495640
 >> iter 93000, loss: 7.487971
 >> iter 94000, loss: 7.508521
 >> iter 95000, loss: 7.499694
 >> iter 96000, loss: 7.488581
 >> iter 97000, loss: 7.488697
 >> iter 98000, loss: 7.479608
 >> iter 99000, loss: 7.503476
 >> iter 100000, loss: 7.496807
   Number of active neurons: 2
 >> iter 101000, loss: 7.494604
 >> iter 102000, loss: 7.484226
 >> iter 103000, loss: 7.484808
 >> iter 104000, loss: 7.488902
 >> iter 105000, loss: 7.483550
 >> iter 106000, loss: 7.493116
 >> iter 107000, loss: 7.537814
 >> iter 108000, loss: 7.519414
 >> iter 109000, loss: 7.508257
 >> iter 110000, loss: 7.549253
   Number of active neurons: 2
 >> iter 111000, loss: 7.514950
 >> iter 112000, loss: 7.508662
 >> iter 113000, loss: 7.493749
 >> iter 114000, loss: 7.483215
 >> iter 115000, loss: 7.492508
 >> iter 116000, loss: 7.481947
 >> iter 117000, loss: 7.516970
 >> iter 118000, loss: 7.495158
 >> iter 119000, loss: 7.504385
 >> iter 120000, loss: 7.484544
   Number of active neurons: 2
 >> iter 121000, loss: 7.490379
 >> iter 122000, loss: 7.550027
 >> iter 123000, loss: 7.537839
 >> iter 124000, loss: 7.509331
 >> iter 125000, loss: 7.516971
 >> iter 126000, loss: 7.508802
 >> iter 127000, loss: 7.499855
 >> iter 128000, loss: 7.484842
 >> iter 129000, loss: 7.497126
 >> iter 130000, loss: 7.489554
   Number of active neurons: 2
 >> iter 131000, loss: 7.495346
 >> iter 132000, loss: 7.484717
 >> iter 133000, loss: 7.491457
 >> iter 134000, loss: 7.497556
 >> iter 135000, loss: 7.498380
 >> iter 136000, loss: 7.489526
 >> iter 137000, loss: 7.494877
 >> iter 138000, loss: 7.489470
 >> iter 139000, loss: 7.496700
 >> iter 140000, loss: 7.494279
   Number of active neurons: 2
 >> iter 141000, loss: 7.499053
 >> iter 142000, loss: 7.485076
 >> iter 143000, loss: 7.500745
 >> iter 144000, loss: 7.481251
 >> iter 145000, loss: 7.497475
 >> iter 146000, loss: 7.481795
 >> iter 147000, loss: 7.501842
 >> iter 148000, loss: 7.509112
 >> iter 149000, loss: 7.497062
 >> iter 150000, loss: 7.490621
   Number of active neurons: 2
 >> iter 151000, loss: 7.492206
 >> iter 152000, loss: 7.491865
 >> iter 153000, loss: 7.531770
 >> iter 154000, loss: 7.507863
 >> iter 155000, loss: 7.498778
 >> iter 156000, loss: 7.487845
 >> iter 157000, loss: 7.527039
 >> iter 158000, loss: 7.502297
 >> iter 159000, loss: 7.495555
 >> iter 160000, loss: 7.501106
   Number of active neurons: 2
 >> iter 161000, loss: 7.534347
 >> iter 162000, loss: 7.509208
 >> iter 163000, loss: 7.491614
 >> iter 164000, loss: 7.490691
 >> iter 165000, loss: 7.534591
 >> iter 166000, loss: 7.513965
 >> iter 167000, loss: 7.498527
 >> iter 168000, loss: 7.494358
 >> iter 169000, loss: 7.485906
 >> iter 170000, loss: 7.493639
   Number of active neurons: 2
 >> iter 171000, loss: 7.500990
 >> iter 172000, loss: 7.522997
 >> iter 173000, loss: 7.518297
 >> iter 174000, loss: 7.506374
 >> iter 175000, loss: 7.498005
 >> iter 176000, loss: 7.518286
 >> iter 177000, loss: 7.497949
 >> iter 178000, loss: 7.496576
 >> iter 179000, loss: 7.489880
 >> iter 180000, loss: 7.507343
   Number of active neurons: 2
 >> iter 181000, loss: 7.495476
 >> iter 182000, loss: 7.498567
 >> iter 183000, loss: 7.487270
 >> iter 184000, loss: 7.488887
 >> iter 185000, loss: 7.509822
 >> iter 186000, loss: 7.508224
 >> iter 187000, loss: 7.513701
 >> iter 188000, loss: 7.505424
 >> iter 189000, loss: 7.509206
 >> iter 190000, loss: 7.500788
   Number of active neurons: 2
 >> iter 191000, loss: 7.493665
 >> iter 192000, loss: 7.497029
 >> iter 193000, loss: 7.538560
 >> iter 194000, loss: 7.509668
 >> iter 195000, loss: 7.505532
 >> iter 196000, loss: 7.502790
 >> iter 197000, loss: 7.492491
 >> iter 198000, loss: 7.514251
 >> iter 199000, loss: 7.493199
 >> iter 200000, loss: 7.494306
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 21.2595748085
   - Test - Long: 24.4987750612
   - Test - Big: 21.1897881021
   - Test - A: 32.8911405906
   - Test - B: 33.404439704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.486764
 >> iter 2000, loss: 10.844646
 >> iter 3000, loss: 8.808470
 >> iter 4000, loss: 7.998722
 >> iter 5000, loss: 7.708014
 >> iter 6000, loss: 7.623953
 >> iter 7000, loss: 7.547300
 >> iter 8000, loss: 7.500141
 >> iter 9000, loss: 7.543137
 >> iter 10000, loss: 7.528959
   Number of active neurons: 2
 >> iter 11000, loss: 7.561801
 >> iter 12000, loss: 7.520925
 >> iter 13000, loss: 7.541197
 >> iter 14000, loss: 7.571762
 >> iter 15000, loss: 7.580029
 >> iter 16000, loss: 7.527611
 >> iter 17000, loss: 7.617274
 >> iter 18000, loss: 7.527273
 >> iter 19000, loss: 7.514113
 >> iter 20000, loss: 7.505392
   Number of active neurons: 2
 >> iter 21000, loss: 7.509445
 >> iter 22000, loss: 7.522433
 >> iter 23000, loss: 7.579353
 >> iter 24000, loss: 7.515296
 >> iter 25000, loss: 7.513393
 >> iter 26000, loss: 7.487168
 >> iter 27000, loss: 7.515653
 >> iter 28000, loss: 7.488208
 >> iter 29000, loss: 7.515166
 >> iter 30000, loss: 7.491833
   Number of active neurons: 2
 >> iter 31000, loss: 7.494423
 >> iter 32000, loss: 7.547190
 >> iter 33000, loss: 7.559744
 >> iter 34000, loss: 7.564598
 >> iter 35000, loss: 7.557371
 >> iter 36000, loss: 7.546749
 >> iter 37000, loss: 7.544708
 >> iter 38000, loss: 7.534101
 >> iter 39000, loss: 7.519351
 >> iter 40000, loss: 7.489741
   Number of active neurons: 2
 >> iter 41000, loss: 7.506423
 >> iter 42000, loss: 7.494565
 >> iter 43000, loss: 7.497559
 >> iter 44000, loss: 7.492384
 >> iter 45000, loss: 7.544515
 >> iter 46000, loss: 7.526908
 >> iter 47000, loss: 7.517745
 >> iter 48000, loss: 7.519412
 >> iter 49000, loss: 7.525740
 >> iter 50000, loss: 7.510219
   Number of active neurons: 2
 >> iter 51000, loss: 7.505022
 >> iter 52000, loss: 7.515174
 >> iter 53000, loss: 7.514296
 >> iter 54000, loss: 7.514901
 >> iter 55000, loss: 7.520125
 >> iter 56000, loss: 7.550206
 >> iter 57000, loss: 7.539330
 >> iter 58000, loss: 7.573874
 >> iter 59000, loss: 7.555080
 >> iter 60000, loss: 7.507653
   Number of active neurons: 2
 >> iter 61000, loss: 7.498433
 >> iter 62000, loss: 7.526817
 >> iter 63000, loss: 7.526889
 >> iter 64000, loss: 7.499619
 >> iter 65000, loss: 7.539587
 >> iter 66000, loss: 7.492082
 >> iter 67000, loss: 7.503116
 >> iter 68000, loss: 7.482563
 >> iter 69000, loss: 7.497918
 >> iter 70000, loss: 7.487811
   Number of active neurons: 2
 >> iter 71000, loss: 7.528347
 >> iter 72000, loss: 7.512104
 >> iter 73000, loss: 7.503652
 >> iter 74000, loss: 7.478281
 >> iter 75000, loss: 7.510437
 >> iter 76000, loss: 7.514161
 >> iter 77000, loss: 7.502145
 >> iter 78000, loss: 7.517638
 >> iter 79000, loss: 7.526222
 >> iter 80000, loss: 7.491963
   Number of active neurons: 2
 >> iter 81000, loss: 7.495432
 >> iter 82000, loss: 7.497921
 >> iter 83000, loss: 7.527964
 >> iter 84000, loss: 7.497112
 >> iter 85000, loss: 7.493979
 >> iter 86000, loss: 7.483099
 >> iter 87000, loss: 7.483989
 >> iter 88000, loss: 7.481139
 >> iter 89000, loss: 7.484854
 >> iter 90000, loss: 7.562623
   Number of active neurons: 2
 >> iter 91000, loss: 7.511206
 >> iter 92000, loss: 7.516680
 >> iter 93000, loss: 7.524221
 >> iter 94000, loss: 7.503359
 >> iter 95000, loss: 7.495684
 >> iter 96000, loss: 7.486221
 >> iter 97000, loss: 7.502818
 >> iter 98000, loss: 7.491898
 >> iter 99000, loss: 7.514898
 >> iter 100000, loss: 7.514579
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 21.2595748085
   - Test - Long: 24.4987750612
   - Test - Big: 21.1897881021
   - Test - A: 32.8911405906
   - Test - B: 33.404439704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.256351
 >> iter 2000, loss: 10.780097
 >> iter 3000, loss: 8.720611
 >> iter 4000, loss: 7.970381
 >> iter 5000, loss: 7.682189
 >> iter 6000, loss: 7.567633
 >> iter 7000, loss: 7.523912
 >> iter 8000, loss: 7.557014
 >> iter 9000, loss: 7.531363
 >> iter 10000, loss: 7.493895
   Number of active neurons: 2
 >> iter 11000, loss: 7.509522
 >> iter 12000, loss: 7.486609
 >> iter 13000, loss: 7.508985
 >> iter 14000, loss: 7.490685
 >> iter 15000, loss: 7.508805
 >> iter 16000, loss: 7.482503
 >> iter 17000, loss: 7.498638
 >> iter 18000, loss: 7.478932
 >> iter 19000, loss: 7.522086
 >> iter 20000, loss: 7.495680
   Number of active neurons: 2
 >> iter 21000, loss: 7.531124
 >> iter 22000, loss: 7.509605
 >> iter 23000, loss: 7.529308
 >> iter 24000, loss: 7.538416
 >> iter 25000, loss: 7.535002
 >> iter 26000, loss: 7.536832
 >> iter 27000, loss: 7.530486
 >> iter 28000, loss: 7.512349
 >> iter 29000, loss: 7.502193
 >> iter 30000, loss: 7.478741
   Number of active neurons: 2
 >> iter 31000, loss: 7.545499
 >> iter 32000, loss: 7.534949
 >> iter 33000, loss: 7.557603
 >> iter 34000, loss: 7.505489
 >> iter 35000, loss: 7.560049
 >> iter 36000, loss: 7.506303
 >> iter 37000, loss: 7.536765
 >> iter 38000, loss: 7.501742
 >> iter 39000, loss: 7.506098
 >> iter 40000, loss: 7.490435
   Number of active neurons: 2
 >> iter 41000, loss: 7.495293
 >> iter 42000, loss: 7.500871
 >> iter 43000, loss: 7.516709
 >> iter 44000, loss: 7.487529
 >> iter 45000, loss: 7.513235
 >> iter 46000, loss: 7.484995
 >> iter 47000, loss: 7.500523
 >> iter 48000, loss: 7.473726
 >> iter 49000, loss: 7.494109
 >> iter 50000, loss: 7.505424
   Number of active neurons: 2
 >> iter 51000, loss: 7.500808
 >> iter 52000, loss: 7.477022
 >> iter 53000, loss: 7.486639
 >> iter 54000, loss: 7.481271
 >> iter 55000, loss: 7.495473
 >> iter 56000, loss: 7.508119
 >> iter 57000, loss: 7.567348
 >> iter 58000, loss: 7.555061
 >> iter 59000, loss: 7.611844
 >> iter 60000, loss: 7.544349
   Number of active neurons: 2
 >> iter 61000, loss: 7.558998
 >> iter 62000, loss: 7.498032
 >> iter 63000, loss: 7.520067
 >> iter 64000, loss: 7.507383
 >> iter 65000, loss: 7.514547
 >> iter 66000, loss: 7.497407
 >> iter 67000, loss: 7.494504
 >> iter 68000, loss: 7.478412
 >> iter 69000, loss: 7.490842
 >> iter 70000, loss: 7.490322
   Number of active neurons: 2
 >> iter 71000, loss: 7.567613
 >> iter 72000, loss: 7.508694
 >> iter 73000, loss: 7.503635
 >> iter 74000, loss: 7.490185
 >> iter 75000, loss: 7.499310
 >> iter 76000, loss: 7.483924
 >> iter 77000, loss: 7.483531
 >> iter 78000, loss: 7.492205
 >> iter 79000, loss: 7.534664
 >> iter 80000, loss: 7.496260
   Number of active neurons: 2
 >> iter 81000, loss: 7.501181
 >> iter 82000, loss: 7.509892
 >> iter 83000, loss: 7.506557
 >> iter 84000, loss: 7.480869
 >> iter 85000, loss: 7.486306
 >> iter 86000, loss: 7.476735
 >> iter 87000, loss: 7.492579
 >> iter 88000, loss: 7.488524
 >> iter 89000, loss: 7.494786
 >> iter 90000, loss: 7.484291
   Number of active neurons: 2
 >> iter 91000, loss: 7.497576
 >> iter 92000, loss: 7.484349
 >> iter 93000, loss: 7.502631
 >> iter 94000, loss: 7.487775
 >> iter 95000, loss: 7.483800
 >> iter 96000, loss: 7.532539
 >> iter 97000, loss: 7.519479
 >> iter 98000, loss: 7.542209
 >> iter 99000, loss: 7.505704
 >> iter 100000, loss: 7.521489
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 21.2595748085
   - Test - Long: 24.4987750612
   - Test - Big: 21.1897881021
   - Test - A: 32.8911405906
   - Test - B: 33.404439704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.351600
 >> iter 2000, loss: 10.853006
 >> iter 3000, loss: 8.793036
 >> iter 4000, loss: 7.995495
 >> iter 5000, loss: 7.748484
 >> iter 6000, loss: 7.578758
 >> iter 7000, loss: 7.573360
 >> iter 8000, loss: 7.541475
 >> iter 9000, loss: 7.528702
 >> iter 10000, loss: 7.494965
   Number of active neurons: 2
 >> iter 11000, loss: 7.567942
 >> iter 12000, loss: 7.511081
 >> iter 13000, loss: 7.510337
 >> iter 14000, loss: 7.503585
 >> iter 15000, loss: 7.527864
 >> iter 16000, loss: 7.501491
 >> iter 17000, loss: 7.533099
 >> iter 18000, loss: 7.505495
 >> iter 19000, loss: 7.511873
 >> iter 20000, loss: 7.482847
   Number of active neurons: 2
 >> iter 21000, loss: 7.652603
 >> iter 22000, loss: 7.599927
 >> iter 23000, loss: 7.561977
 >> iter 24000, loss: 7.515985
 >> iter 25000, loss: 7.503047
 >> iter 26000, loss: 7.489525
 >> iter 27000, loss: 7.495143
 >> iter 28000, loss: 7.488146
 >> iter 29000, loss: 7.547893
 >> iter 30000, loss: 7.512721
   Number of active neurons: 2
 >> iter 31000, loss: 7.522091
 >> iter 32000, loss: 7.488626
 >> iter 33000, loss: 7.545161
 >> iter 34000, loss: 7.542726
 >> iter 35000, loss: 7.553728
 >> iter 36000, loss: 7.507989
 >> iter 37000, loss: 7.533716
 >> iter 38000, loss: 7.493767
 >> iter 39000, loss: 7.495581
 >> iter 40000, loss: 7.518162
   Number of active neurons: 2
 >> iter 41000, loss: 7.518045
 >> iter 42000, loss: 7.509141
 >> iter 43000, loss: 7.509732
 >> iter 44000, loss: 7.495517
 >> iter 45000, loss: 7.531959
 >> iter 46000, loss: 7.511733
 >> iter 47000, loss: 7.500269
 >> iter 48000, loss: 7.512584
 >> iter 49000, loss: 7.505856
 >> iter 50000, loss: 7.492938
   Number of active neurons: 2
 >> iter 51000, loss: 7.537000
 >> iter 52000, loss: 7.508845
 >> iter 53000, loss: 7.528292
 >> iter 54000, loss: 7.485444
 >> iter 55000, loss: 7.528206
 >> iter 56000, loss: 7.491232
 >> iter 57000, loss: 7.525876
 >> iter 58000, loss: 7.496135
 >> iter 59000, loss: 7.513812
 >> iter 60000, loss: 7.527954
   Number of active neurons: 2
 >> iter 61000, loss: 7.513067
 >> iter 62000, loss: 7.487903
 >> iter 63000, loss: 7.492009
 >> iter 64000, loss: 7.575188
 >> iter 65000, loss: 7.528174
 >> iter 66000, loss: 7.496985
 >> iter 67000, loss: 7.493533
 >> iter 68000, loss: 7.481659
 >> iter 69000, loss: 7.559551
 >> iter 70000, loss: 7.501738
   Number of active neurons: 2
 >> iter 71000, loss: 7.517282
 >> iter 72000, loss: 7.487475
 >> iter 73000, loss: 7.507005
 >> iter 74000, loss: 7.488503
 >> iter 75000, loss: 7.503333
 >> iter 76000, loss: 7.477270
 >> iter 77000, loss: 7.486602
 >> iter 78000, loss: 7.471649
 >> iter 79000, loss: 7.507503
 >> iter 80000, loss: 7.505904
   Number of active neurons: 2
 >> iter 81000, loss: 7.506612
 >> iter 82000, loss: 7.530373
 >> iter 83000, loss: 7.504102
 >> iter 84000, loss: 7.479857
 >> iter 85000, loss: 7.487323
 >> iter 86000, loss: 7.485746
 >> iter 87000, loss: 7.538156
 >> iter 88000, loss: 7.539342
 >> iter 89000, loss: 7.516643
 >> iter 90000, loss: 7.490209
   Number of active neurons: 2
 >> iter 91000, loss: 7.546546
 >> iter 92000, loss: 7.530593
 >> iter 93000, loss: 7.509751
 >> iter 94000, loss: 7.529637
 >> iter 95000, loss: 7.525486
 >> iter 96000, loss: 7.586746
 >> iter 97000, loss: 7.568190
 >> iter 98000, loss: 7.511483
 >> iter 99000, loss: 7.496244
 >> iter 100000, loss: 7.521848
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 21.5315693686
   - Test - Long: 24.7387630618
   - Test - Big: 21.3947860521
   - Test - A: 16.3455769615
   - Test - B: 15.8589427372
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.151613
 >> iter 2000, loss: 10.778771
 >> iter 3000, loss: 8.715703
 >> iter 4000, loss: 7.930929
 >> iter 5000, loss: 7.673838
 >> iter 6000, loss: 7.568890
 >> iter 7000, loss: 7.537080
 >> iter 8000, loss: 7.532088
 >> iter 9000, loss: 7.553856
 >> iter 10000, loss: 7.519912
   Number of active neurons: 2
 >> iter 11000, loss: 7.514795
 >> iter 12000, loss: 7.498053
 >> iter 13000, loss: 7.501209
 >> iter 14000, loss: 7.520854
 >> iter 15000, loss: 7.505050
 >> iter 16000, loss: 7.493958
 >> iter 17000, loss: 7.543432
 >> iter 18000, loss: 7.506310
 >> iter 19000, loss: 7.577366
 >> iter 20000, loss: 7.507796
   Number of active neurons: 2
 >> iter 21000, loss: 7.522728
 >> iter 22000, loss: 7.488229
 >> iter 23000, loss: 7.505698
 >> iter 24000, loss: 7.500299
 >> iter 25000, loss: 7.512996
 >> iter 26000, loss: 7.495189
 >> iter 27000, loss: 7.630407
 >> iter 28000, loss: 7.532931
 >> iter 29000, loss: 7.515674
 >> iter 30000, loss: 7.509191
   Number of active neurons: 2
 >> iter 31000, loss: 7.549198
 >> iter 32000, loss: 7.498036
 >> iter 33000, loss: 7.523083
 >> iter 34000, loss: 7.510297
 >> iter 35000, loss: 7.556471
 >> iter 36000, loss: 7.515153
 >> iter 37000, loss: 7.513921
 >> iter 38000, loss: 7.514483
 >> iter 39000, loss: 7.506955
 >> iter 40000, loss: 7.484569
   Number of active neurons: 2
 >> iter 41000, loss: 7.541698
 >> iter 42000, loss: 7.528756
 >> iter 43000, loss: 7.532968
 >> iter 44000, loss: 7.517478
 >> iter 45000, loss: 7.560621
 >> iter 46000, loss: 7.506911
 >> iter 47000, loss: 7.563153
 >> iter 48000, loss: 7.503833
 >> iter 49000, loss: 7.532638
 >> iter 50000, loss: 7.489989
   Number of active neurons: 2
 >> iter 51000, loss: 7.492697
 >> iter 52000, loss: 7.487249
 >> iter 53000, loss: 7.502049
 >> iter 54000, loss: 7.473561
 >> iter 55000, loss: 7.486617
 >> iter 56000, loss: 7.470851
 >> iter 57000, loss: 7.540054
 >> iter 58000, loss: 7.532715
 >> iter 59000, loss: 7.509745
 >> iter 60000, loss: 7.500318
   Number of active neurons: 2
 >> iter 61000, loss: 7.561300
 >> iter 62000, loss: 7.509933
 >> iter 63000, loss: 7.512566
 >> iter 64000, loss: 7.492291
 >> iter 65000, loss: 7.492322
 >> iter 66000, loss: 7.516900
 >> iter 67000, loss: 7.557399
 >> iter 68000, loss: 7.503546
 >> iter 69000, loss: 7.517250
 >> iter 70000, loss: 7.517080
   Number of active neurons: 2
 >> iter 71000, loss: 7.506081
 >> iter 72000, loss: 7.536470
 >> iter 73000, loss: 7.535365
 >> iter 74000, loss: 7.495183
 >> iter 75000, loss: 7.560589
 >> iter 76000, loss: 7.506336
 >> iter 77000, loss: 7.540524
 >> iter 78000, loss: 7.499760
 >> iter 79000, loss: 7.539359
 >> iter 80000, loss: 7.572532
   Number of active neurons: 2
 >> iter 81000, loss: 7.530547
 >> iter 82000, loss: 7.494063
 >> iter 83000, loss: 7.505152
 >> iter 84000, loss: 7.490890
 >> iter 85000, loss: 7.492315
 >> iter 86000, loss: 7.509956
 >> iter 87000, loss: 7.506516
 >> iter 88000, loss: 7.488964
 >> iter 89000, loss: 7.486040
 >> iter 90000, loss: 7.502453
   Number of active neurons: 2
 >> iter 91000, loss: 7.518944
 >> iter 92000, loss: 7.503272
 >> iter 93000, loss: 7.516531
 >> iter 94000, loss: 7.495527
 >> iter 95000, loss: 7.499660
 >> iter 96000, loss: 7.509523
 >> iter 97000, loss: 7.495940
 >> iter 98000, loss: 7.511416
 >> iter 99000, loss: 7.493369
 >> iter 100000, loss: 7.485324
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 21.5315693686
   - Test - Long: 24.7387630618
   - Test - Big: 21.3947860521
   - Test - A: 16.3455769615
   - Test - B: 15.8589427372
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.736392
 >> iter 2000, loss: 11.490588
 >> iter 3000, loss: 8.999657
 >> iter 4000, loss: 8.087724
 >> iter 5000, loss: 7.750385
 >> iter 6000, loss: 7.599142
 >> iter 7000, loss: 7.569533
 >> iter 8000, loss: 7.607817
 >> iter 9000, loss: 7.563171
 >> iter 10000, loss: 7.545949
   Number of active neurons: 2
 >> iter 11000, loss: 7.527247
 >> iter 12000, loss: 7.494867
 >> iter 13000, loss: 7.546713
 >> iter 14000, loss: 7.497882
 >> iter 15000, loss: 7.552226
 >> iter 16000, loss: 7.505491
 >> iter 17000, loss: 7.506898
 >> iter 18000, loss: 7.513324
 >> iter 19000, loss: 7.525521
 >> iter 20000, loss: 7.499041
   Number of active neurons: 2
 >> iter 21000, loss: 7.497132
 >> iter 22000, loss: 7.507325
 >> iter 23000, loss: 7.512430
 >> iter 24000, loss: 7.499026
 >> iter 25000, loss: 7.501246
 >> iter 26000, loss: 7.484574
 >> iter 27000, loss: 7.494214
 >> iter 28000, loss: 7.536589
 >> iter 29000, loss: 7.511534
 >> iter 30000, loss: 7.492617
   Number of active neurons: 2
 >> iter 31000, loss: 7.505968
 >> iter 32000, loss: 7.578193
 >> iter 33000, loss: 7.531333
 >> iter 34000, loss: 7.508578
 >> iter 35000, loss: 7.502974
 >> iter 36000, loss: 7.533996
 >> iter 37000, loss: 7.523662
 >> iter 38000, loss: 7.495929
 >> iter 39000, loss: 7.509173
 >> iter 40000, loss: 7.489551
   Number of active neurons: 2
 >> iter 41000, loss: 7.498002
 >> iter 42000, loss: 7.493954
 >> iter 43000, loss: 7.496395
 >> iter 44000, loss: 7.502365
 >> iter 45000, loss: 7.501967
 >> iter 46000, loss: 7.485912
 >> iter 47000, loss: 7.509349
 >> iter 48000, loss: 7.512680
 >> iter 49000, loss: 7.528971
 >> iter 50000, loss: 7.491891
   Number of active neurons: 2
 >> iter 51000, loss: 7.516128
 >> iter 52000, loss: 7.524601
 >> iter 53000, loss: 7.508445
 >> iter 54000, loss: 7.483049
 >> iter 55000, loss: 7.528293
 >> iter 56000, loss: 7.527064
 >> iter 57000, loss: 7.511174
 >> iter 58000, loss: 7.510189
 >> iter 59000, loss: 7.501377
 >> iter 60000, loss: 7.511467
   Number of active neurons: 2
 >> iter 61000, loss: 7.522631
 >> iter 62000, loss: 7.499220
 >> iter 63000, loss: 7.501670
 >> iter 64000, loss: 7.504101
 >> iter 65000, loss: 7.503366
 >> iter 66000, loss: 7.483839
 >> iter 67000, loss: 7.492693
 >> iter 68000, loss: 7.536006
 >> iter 69000, loss: 7.512407
 >> iter 70000, loss: 7.484796
   Number of active neurons: 2
 >> iter 71000, loss: 7.492838
 >> iter 72000, loss: 7.494415
 >> iter 73000, loss: 7.497560
 >> iter 74000, loss: 7.488812
 >> iter 75000, loss: 7.515741
 >> iter 76000, loss: 7.502886
 >> iter 77000, loss: 7.498681
 >> iter 78000, loss: 7.483427
 >> iter 79000, loss: 7.497978
 >> iter 80000, loss: 7.483395
   Number of active neurons: 2
 >> iter 81000, loss: 7.488012
 >> iter 82000, loss: 7.479930
 >> iter 83000, loss: 7.485100
 >> iter 84000, loss: 7.493503
 >> iter 85000, loss: 7.495463
 >> iter 86000, loss: 7.502063
 >> iter 87000, loss: 7.508935
 >> iter 88000, loss: 7.491846
 >> iter 89000, loss: 7.490313
 >> iter 90000, loss: 7.482668
   Number of active neurons: 2
 >> iter 91000, loss: 7.514287
 >> iter 92000, loss: 7.496335
 >> iter 93000, loss: 7.504191
 >> iter 94000, loss: 7.490921
 >> iter 95000, loss: 7.488462
 >> iter 96000, loss: 7.483234
 >> iter 97000, loss: 7.485516
 >> iter 98000, loss: 7.507052
 >> iter 99000, loss: 7.511494
 >> iter 100000, loss: 7.491332
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 21.5315693686
   - Test - Long: 24.7387630618
   - Test - Big: 21.3947860521
   - Test - A: 16.3455769615
   - Test - B: 15.8589427372
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 16.605571
 >> iter 2000, loss: 11.138488
 >> iter 3000, loss: 8.884349
 >> iter 4000, loss: 8.076815
 >> iter 5000, loss: 7.736789
 >> iter 6000, loss: 7.569697
 >> iter 7000, loss: 7.525098
 >> iter 8000, loss: 7.493790
 >> iter 9000, loss: 7.494155
 >> iter 10000, loss: 7.479808
   Number of active neurons: 2
 >> iter 11000, loss: 7.506718
 >> iter 12000, loss: 7.504267
 >> iter 13000, loss: 7.549637
 >> iter 14000, loss: 7.507166
 >> iter 15000, loss: 7.516907
 >> iter 16000, loss: 7.492594
 >> iter 17000, loss: 7.524472
 >> iter 18000, loss: 7.489086
 >> iter 19000, loss: 7.523088
 >> iter 20000, loss: 7.506887
   Number of active neurons: 2
 >> iter 21000, loss: 7.519041
 >> iter 22000, loss: 7.493151
 >> iter 23000, loss: 7.499848
 >> iter 24000, loss: 7.477823
 >> iter 25000, loss: 7.506254
 >> iter 26000, loss: 7.498488
 >> iter 27000, loss: 7.539437
 >> iter 28000, loss: 7.530293
 >> iter 29000, loss: 7.524829
 >> iter 30000, loss: 7.491269
   Number of active neurons: 2
 >> iter 31000, loss: 7.539508
 >> iter 32000, loss: 7.500537
 >> iter 33000, loss: 7.534926
 >> iter 34000, loss: 7.521120
 >> iter 35000, loss: 7.538827
 >> iter 36000, loss: 7.498572
 >> iter 37000, loss: 7.538255
 >> iter 38000, loss: 7.492359
 >> iter 39000, loss: 7.532899
 >> iter 40000, loss: 7.488619
   Number of active neurons: 2
 >> iter 41000, loss: 7.507234
 >> iter 42000, loss: 7.512548
 >> iter 43000, loss: 7.524090
 >> iter 44000, loss: 7.490172
 >> iter 45000, loss: 7.498716
 >> iter 46000, loss: 7.483793
 >> iter 47000, loss: 7.496369
 >> iter 48000, loss: 7.475125
 >> iter 49000, loss: 7.540574
 >> iter 50000, loss: 7.540074
   Number of active neurons: 2
 >> iter 51000, loss: 7.518530
 >> iter 52000, loss: 7.482476
 >> iter 53000, loss: 7.506490
 >> iter 54000, loss: 7.497204
 >> iter 55000, loss: 7.501694
 >> iter 56000, loss: 7.484427
 >> iter 57000, loss: 7.510345
 >> iter 58000, loss: 7.490833
 >> iter 59000, loss: 7.488879
 >> iter 60000, loss: 7.502640
   Number of active neurons: 2
 >> iter 61000, loss: 7.493747
 >> iter 62000, loss: 7.476766
 >> iter 63000, loss: 7.489001
 >> iter 64000, loss: 7.509967
 >> iter 65000, loss: 7.558493
 >> iter 66000, loss: 7.578421
 >> iter 67000, loss: 7.537722
 >> iter 68000, loss: 7.499395
 >> iter 69000, loss: 7.500958
 >> iter 70000, loss: 7.482518
   Number of active neurons: 2
 >> iter 71000, loss: 7.515320
 >> iter 72000, loss: 7.525802
 >> iter 73000, loss: 7.518872
 >> iter 74000, loss: 7.530863
 >> iter 75000, loss: 7.510831
 >> iter 76000, loss: 7.483796
 >> iter 77000, loss: 7.488542
 >> iter 78000, loss: 7.471502
 >> iter 79000, loss: 7.571381
 >> iter 80000, loss: 7.527511
   Number of active neurons: 2
 >> iter 81000, loss: 7.504908
 >> iter 82000, loss: 7.497544
 >> iter 83000, loss: 7.504471
 >> iter 84000, loss: 7.484330
 >> iter 85000, loss: 7.491930
 >> iter 86000, loss: 7.536079
 >> iter 87000, loss: 7.509908
 >> iter 88000, loss: 7.493369
 >> iter 89000, loss: 7.485868
 >> iter 90000, loss: 7.477408
   Number of active neurons: 2
 >> iter 91000, loss: 7.482437
 >> iter 92000, loss: 7.485593
 >> iter 93000, loss: 7.490643
 >> iter 94000, loss: 7.491887
 >> iter 95000, loss: 7.520596
 >> iter 96000, loss: 7.516646
 >> iter 97000, loss: 7.501342
 >> iter 98000, loss: 7.495017
 >> iter 99000, loss: 7.501464
 >> iter 100000, loss: 7.487363
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 21.5315693686
   - Test - Long: 24.7387630618
   - Test - Big: 21.3947860521
   - Test - A: 16.3455769615
   - Test - B: 15.8589427372
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.130991
 >> iter 2000, loss: 10.706473
 >> iter 3000, loss: 8.818418
 >> iter 4000, loss: 8.011068
 >> iter 5000, loss: 7.708219
 >> iter 6000, loss: 7.589338
 >> iter 7000, loss: 7.549964
 >> iter 8000, loss: 7.520513
 >> iter 9000, loss: 7.543570
 >> iter 10000, loss: 7.579093
   Number of active neurons: 2
 >> iter 11000, loss: 7.531452
 >> iter 12000, loss: 7.544703
 >> iter 13000, loss: 7.569368
 >> iter 14000, loss: 7.590133
 >> iter 15000, loss: 7.564544
 >> iter 16000, loss: 7.516865
 >> iter 17000, loss: 7.506266
 >> iter 18000, loss: 7.492624
 >> iter 19000, loss: 7.500890
 >> iter 20000, loss: 7.494723
   Number of active neurons: 2
 >> iter 21000, loss: 7.489879
 >> iter 22000, loss: 7.486244
 >> iter 23000, loss: 7.515169
 >> iter 24000, loss: 7.518370
 >> iter 25000, loss: 7.559176
 >> iter 26000, loss: 7.511508
 >> iter 27000, loss: 7.500493
 >> iter 28000, loss: 7.484574
 >> iter 29000, loss: 7.527895
 >> iter 30000, loss: 7.534408
   Number of active neurons: 2
 >> iter 31000, loss: 7.531117
 >> iter 32000, loss: 7.503450
 >> iter 33000, loss: 7.574828
 >> iter 34000, loss: 7.511512
 >> iter 35000, loss: 7.512032
 >> iter 36000, loss: 7.517610
 >> iter 37000, loss: 7.501541
 >> iter 38000, loss: 7.479608
 >> iter 39000, loss: 7.514782
 >> iter 40000, loss: 7.499540
   Number of active neurons: 2
 >> iter 41000, loss: 7.525673
 >> iter 42000, loss: 7.487729
 >> iter 43000, loss: 7.553049
 >> iter 44000, loss: 7.496570
 >> iter 45000, loss: 7.497028
 >> iter 46000, loss: 7.482035
 >> iter 47000, loss: 7.561062
 >> iter 48000, loss: 7.521945
 >> iter 49000, loss: 7.572307
 >> iter 50000, loss: 7.512968
   Number of active neurons: 2
 >> iter 51000, loss: 7.508029
 >> iter 52000, loss: 7.506690
 >> iter 53000, loss: 7.504481
 >> iter 54000, loss: 7.546267
 >> iter 55000, loss: 7.534353
 >> iter 56000, loss: 7.496808
 >> iter 57000, loss: 7.512890
 >> iter 58000, loss: 7.484721
 >> iter 59000, loss: 7.538245
 >> iter 60000, loss: 7.523026
   Number of active neurons: 2
 >> iter 61000, loss: 7.508333
 >> iter 62000, loss: 7.481306
 >> iter 63000, loss: 7.531105
 >> iter 64000, loss: 7.499752
 >> iter 65000, loss: 7.510644
 >> iter 66000, loss: 7.528418
 >> iter 67000, loss: 7.548676
 >> iter 68000, loss: 7.532477
 >> iter 69000, loss: 7.546942
 >> iter 70000, loss: 7.520646
   Number of active neurons: 2
 >> iter 71000, loss: 7.517468
 >> iter 72000, loss: 7.500442
 >> iter 73000, loss: 7.552716
 >> iter 74000, loss: 7.507521
 >> iter 75000, loss: 7.532645
 >> iter 76000, loss: 7.493124
 >> iter 77000, loss: 7.494675
 >> iter 78000, loss: 7.495314
 >> iter 79000, loss: 7.497935
 >> iter 80000, loss: 7.484953
   Number of active neurons: 2
 >> iter 81000, loss: 7.489502
 >> iter 82000, loss: 7.482670
 >> iter 83000, loss: 7.533870
 >> iter 84000, loss: 7.519086
 >> iter 85000, loss: 7.510584
 >> iter 86000, loss: 7.486815
 >> iter 87000, loss: 7.485892
 >> iter 88000, loss: 7.496044
 >> iter 89000, loss: 7.497708
 >> iter 90000, loss: 7.479455
   Number of active neurons: 2
 >> iter 91000, loss: 7.482668
 >> iter 92000, loss: 7.532235
 >> iter 93000, loss: 7.585763
 >> iter 94000, loss: 7.526306
 >> iter 95000, loss: 7.502192
 >> iter 96000, loss: 7.485981
 >> iter 97000, loss: 7.512600
 >> iter 98000, loss: 7.511815
 >> iter 99000, loss: 7.540173
 >> iter 100000, loss: 7.537281
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 21.5315693686
   - Test - Long: 24.7387630618
   - Test - Big: 21.3947860521
   - Test - A: 16.3455769615
   - Test - B: 15.8589427372
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.111357
 >> iter 2000, loss: 10.725914
 >> iter 3000, loss: 8.762583
 >> iter 4000, loss: 7.972445
 >> iter 5000, loss: 7.687348
 >> iter 6000, loss: 7.562025
 >> iter 7000, loss: 7.600396
 >> iter 8000, loss: 7.536962
 >> iter 9000, loss: 7.563397
 >> iter 10000, loss: 7.507114
   Number of active neurons: 2
 >> iter 11000, loss: 7.513790
 >> iter 12000, loss: 7.516472
 >> iter 13000, loss: 7.554396
 >> iter 14000, loss: 7.522817
 >> iter 15000, loss: 7.530173
 >> iter 16000, loss: 7.507051
 >> iter 17000, loss: 7.524147
 >> iter 18000, loss: 7.607187
 >> iter 19000, loss: 7.568134
 >> iter 20000, loss: 7.506529
   Number of active neurons: 2
 >> iter 21000, loss: 7.537164
 >> iter 22000, loss: 7.505150
 >> iter 23000, loss: 7.530044
 >> iter 24000, loss: 7.489615
 >> iter 25000, loss: 7.526699
 >> iter 26000, loss: 7.531112
 >> iter 27000, loss: 7.509169
 >> iter 28000, loss: 7.530880
 >> iter 29000, loss: 7.531452
 >> iter 30000, loss: 7.495020
   Number of active neurons: 2
 >> iter 31000, loss: 7.501799
 >> iter 32000, loss: 7.501372
 >> iter 33000, loss: 7.497642
 >> iter 34000, loss: 7.509998
 >> iter 35000, loss: 7.502004
 >> iter 36000, loss: 7.547602
 >> iter 37000, loss: 7.544571
 >> iter 38000, loss: 7.545524
 >> iter 39000, loss: 7.555127
 >> iter 40000, loss: 7.533707
   Number of active neurons: 2
 >> iter 41000, loss: 7.557387
 >> iter 42000, loss: 7.564422
 >> iter 43000, loss: 7.539009
 >> iter 44000, loss: 7.506101
 >> iter 45000, loss: 7.505233
 >> iter 46000, loss: 7.486279
 >> iter 47000, loss: 7.493634
 >> iter 48000, loss: 7.506585
 >> iter 49000, loss: 7.514438
 >> iter 50000, loss: 7.501576
   Number of active neurons: 2
 >> iter 51000, loss: 7.499775
 >> iter 52000, loss: 7.486335
 >> iter 53000, loss: 7.526544
 >> iter 54000, loss: 7.518506
 >> iter 55000, loss: 7.530396
 >> iter 56000, loss: 7.485098
 >> iter 57000, loss: 7.499410
 >> iter 58000, loss: 7.490947
 >> iter 59000, loss: 7.501044
 >> iter 60000, loss: 7.476490
   Number of active neurons: 2
 >> iter 61000, loss: 7.511719
 >> iter 62000, loss: 7.523374
 >> iter 63000, loss: 7.508048
 >> iter 64000, loss: 7.486321
 >> iter 65000, loss: 7.621669
 >> iter 66000, loss: 7.531657
 >> iter 67000, loss: 7.512286
 >> iter 68000, loss: 7.508836
 >> iter 69000, loss: 7.501378
 >> iter 70000, loss: 7.503618
   Number of active neurons: 2
 >> iter 71000, loss: 7.506850
 >> iter 72000, loss: 7.488947
 >> iter 73000, loss: 7.534921
 >> iter 74000, loss: 7.487999
 >> iter 75000, loss: 7.491544
 >> iter 76000, loss: 7.499369
 >> iter 77000, loss: 7.514372
 >> iter 78000, loss: 7.499865
 >> iter 79000, loss: 7.532835
 >> iter 80000, loss: 7.523592
   Number of active neurons: 2
 >> iter 81000, loss: 7.533830
 >> iter 82000, loss: 7.494087
 >> iter 83000, loss: 7.492188
 >> iter 84000, loss: 7.481565
 >> iter 85000, loss: 7.515704
 >> iter 86000, loss: 7.498509
 >> iter 87000, loss: 7.490626
 >> iter 88000, loss: 7.488703
 >> iter 89000, loss: 7.501328
 >> iter 90000, loss: 7.485033
   Number of active neurons: 2
 >> iter 91000, loss: 7.510530
 >> iter 92000, loss: 7.522547
 >> iter 93000, loss: 7.514284
 >> iter 94000, loss: 7.492412
 >> iter 95000, loss: 7.495499
 >> iter 96000, loss: 7.483901
 >> iter 97000, loss: 7.480624
 >> iter 98000, loss: 7.500800
 >> iter 99000, loss: 7.491280
 >> iter 100000, loss: 7.493614
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 21.1355772885
   - Test - Long: 24.6287685616
   - Test - Big: 21.1687883121
   - Test - A: 33.0977934804
   - Test - B: 15.7056196254
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.147537
 >> iter 2000, loss: 11.112804
 >> iter 3000, loss: 8.846203
 >> iter 4000, loss: 8.000630
 >> iter 5000, loss: 7.708575
 >> iter 6000, loss: 7.573099
 >> iter 7000, loss: 7.531582
 >> iter 8000, loss: 7.562082
 >> iter 9000, loss: 7.549122
 >> iter 10000, loss: 7.501255
   Number of active neurons: 2
 >> iter 11000, loss: 7.508554
 >> iter 12000, loss: 7.533728
 >> iter 13000, loss: 7.513790
 >> iter 14000, loss: 7.488581
 >> iter 15000, loss: 7.576203
 >> iter 16000, loss: 7.537756
 >> iter 17000, loss: 7.515692
 >> iter 18000, loss: 7.501790
 >> iter 19000, loss: 7.514082
 >> iter 20000, loss: 7.512333
   Number of active neurons: 2
 >> iter 21000, loss: 7.506753
 >> iter 22000, loss: 7.536171
 >> iter 23000, loss: 7.533682
 >> iter 24000, loss: 7.520584
 >> iter 25000, loss: 7.517688
 >> iter 26000, loss: 7.498576
 >> iter 27000, loss: 7.507336
 >> iter 28000, loss: 7.487977
 >> iter 29000, loss: 7.495121
 >> iter 30000, loss: 7.505647
   Number of active neurons: 2
 >> iter 31000, loss: 7.526617
 >> iter 32000, loss: 7.511538
 >> iter 33000, loss: 7.545602
 >> iter 34000, loss: 7.522794
 >> iter 35000, loss: 7.512017
 >> iter 36000, loss: 7.514729
 >> iter 37000, loss: 7.499919
 >> iter 38000, loss: 7.492086
 >> iter 39000, loss: 7.550243
 >> iter 40000, loss: 7.501301
   Number of active neurons: 2
 >> iter 41000, loss: 7.501741
 >> iter 42000, loss: 7.480477
 >> iter 43000, loss: 7.509918
 >> iter 44000, loss: 7.486854
 >> iter 45000, loss: 7.498340
 >> iter 46000, loss: 7.483261
 >> iter 47000, loss: 7.503046
 >> iter 48000, loss: 7.481079
 >> iter 49000, loss: 7.508419
 >> iter 50000, loss: 7.484156
   Number of active neurons: 2
 >> iter 51000, loss: 7.503011
 >> iter 52000, loss: 7.492900
 >> iter 53000, loss: 7.507650
 >> iter 54000, loss: 7.482996
 >> iter 55000, loss: 7.499259
 >> iter 56000, loss: 7.478467
 >> iter 57000, loss: 7.488341
 >> iter 58000, loss: 7.474464
 >> iter 59000, loss: 7.488924
 >> iter 60000, loss: 7.521724
   Number of active neurons: 2
 >> iter 61000, loss: 7.513114
 >> iter 62000, loss: 7.485505
 >> iter 63000, loss: 7.496471
 >> iter 64000, loss: 7.478385
 >> iter 65000, loss: 7.491066
 >> iter 66000, loss: 7.476586
 >> iter 67000, loss: 7.490921
 >> iter 68000, loss: 7.476728
 >> iter 69000, loss: 7.522228
 >> iter 70000, loss: 7.498725
   Number of active neurons: 2
 >> iter 71000, loss: 7.528245
 >> iter 72000, loss: 7.488069
 >> iter 73000, loss: 7.495173
 >> iter 74000, loss: 7.488799
 >> iter 75000, loss: 7.507186
 >> iter 76000, loss: 7.491134
 >> iter 77000, loss: 7.493353
 >> iter 78000, loss: 7.513336
 >> iter 79000, loss: 7.512390
 >> iter 80000, loss: 7.524037
   Number of active neurons: 2
 >> iter 81000, loss: 7.505939
 >> iter 82000, loss: 7.485387
 >> iter 83000, loss: 7.497100
 >> iter 84000, loss: 7.546152
 >> iter 85000, loss: 7.511144
 >> iter 86000, loss: 7.497929
 >> iter 87000, loss: 7.495208
 >> iter 88000, loss: 7.505059
 >> iter 89000, loss: 7.494245
 >> iter 90000, loss: 7.491416
   Number of active neurons: 2
 >> iter 91000, loss: 7.489724
 >> iter 92000, loss: 7.492743
 >> iter 93000, loss: 7.486619
 >> iter 94000, loss: 7.484300
 >> iter 95000, loss: 7.484808
 >> iter 96000, loss: 7.501821
 >> iter 97000, loss: 7.494970
 >> iter 98000, loss: 7.486344
 >> iter 99000, loss: 7.508561
 >> iter 100000, loss: 7.489708
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 21.2595748085
   - Test - Long: 24.4987750612
   - Test - Big: 21.1897881021
   - Test - A: 32.8911405906
   - Test - B: 33.404439704
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.748526
 >> iter 2000, loss: 11.052845
 >> iter 3000, loss: 8.847218
 >> iter 4000, loss: 8.006560
 >> iter 5000, loss: 7.699021
 >> iter 6000, loss: 7.558184
 >> iter 7000, loss: 7.519899
 >> iter 8000, loss: 7.505169
 >> iter 9000, loss: 7.503340
 >> iter 10000, loss: 7.506431
   Number of active neurons: 2
 >> iter 11000, loss: 7.512874
 >> iter 12000, loss: 7.492331
 >> iter 13000, loss: 7.507610
 >> iter 14000, loss: 7.491515
 >> iter 15000, loss: 7.497108
 >> iter 16000, loss: 7.529092
 >> iter 17000, loss: 7.513263
 >> iter 18000, loss: 7.491118
 >> iter 19000, loss: 7.504876
 >> iter 20000, loss: 7.480766
   Number of active neurons: 2
 >> iter 21000, loss: 7.492883
 >> iter 22000, loss: 7.513399
 >> iter 23000, loss: 7.562668
 >> iter 24000, loss: 7.525164
 >> iter 25000, loss: 7.555757
 >> iter 26000, loss: 7.516002
 >> iter 27000, loss: 7.515605
 >> iter 28000, loss: 7.490851
 >> iter 29000, loss: 7.496238
 >> iter 30000, loss: 7.480346
   Number of active neurons: 2
 >> iter 31000, loss: 7.519113
 >> iter 32000, loss: 7.493548
 >> iter 33000, loss: 7.505242
 >> iter 34000, loss: 7.508700
 >> iter 35000, loss: 7.538628
 >> iter 36000, loss: 7.505320
 >> iter 37000, loss: 7.505452
 >> iter 38000, loss: 7.485541
 >> iter 39000, loss: 7.497794
 >> iter 40000, loss: 7.490692
   Number of active neurons: 2
 >> iter 41000, loss: 7.504086
 >> iter 42000, loss: 7.542878
 >> iter 43000, loss: 7.535112
 >> iter 44000, loss: 7.530521
 >> iter 45000, loss: 7.514722
 >> iter 46000, loss: 7.504681
 >> iter 47000, loss: 7.500138
 >> iter 48000, loss: 7.482726
 >> iter 49000, loss: 7.507112
 >> iter 50000, loss: 7.505910
   Number of active neurons: 2
 >> iter 51000, loss: 7.512867
 >> iter 52000, loss: 7.482642
 >> iter 53000, loss: 7.495301
 >> iter 54000, loss: 7.527240
 >> iter 55000, loss: 7.512435
 >> iter 56000, loss: 7.488740
 >> iter 57000, loss: 7.502080
 >> iter 58000, loss: 7.481990
 >> iter 59000, loss: 7.535886
 >> iter 60000, loss: 7.519353
   Number of active neurons: 2
 >> iter 61000, loss: 7.516239
 >> iter 62000, loss: 7.511438
 >> iter 63000, loss: 7.507354
 >> iter 64000, loss: 7.504612
 >> iter 65000, loss: 7.532624
 >> iter 66000, loss: 7.519871
 >> iter 67000, loss: 7.514991
 >> iter 68000, loss: 7.488486
 >> iter 69000, loss: 7.504495
 >> iter 70000, loss: 7.497363
   Number of active neurons: 2
 >> iter 71000, loss: 7.513342
 >> iter 72000, loss: 7.492024
 >> iter 73000, loss: 7.499536
 >> iter 74000, loss: 7.486406
 >> iter 75000, loss: 7.501505
 >> iter 76000, loss: 7.482000
 >> iter 77000, loss: 7.507658
 >> iter 78000, loss: 7.487098
 >> iter 79000, loss: 7.501235
 >> iter 80000, loss: 7.486332
   Number of active neurons: 2
 >> iter 81000, loss: 7.491553
 >> iter 82000, loss: 7.488974
 >> iter 83000, loss: 7.495324
 >> iter 84000, loss: 7.521554
 >> iter 85000, loss: 7.529901
 >> iter 86000, loss: 7.500439
 >> iter 87000, loss: 7.493553
 >> iter 88000, loss: 7.480663
 >> iter 89000, loss: 7.515708
 >> iter 90000, loss: 7.492245
   Number of active neurons: 2
 >> iter 91000, loss: 7.510518
 >> iter 92000, loss: 7.493902
 >> iter 93000, loss: 7.488627
 >> iter 94000, loss: 7.510769
 >> iter 95000, loss: 7.517752
 >> iter 96000, loss: 7.514140
 >> iter 97000, loss: 7.496777
 >> iter 98000, loss: 7.515139
 >> iter 99000, loss: 7.529118
 >> iter 100000, loss: 7.499948
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 21.5315693686
   - Test - Long: 24.7387630618
   - Test - Big: 21.3947860521
   - Test - A: 16.3455769615
   - Test - B: 15.8589427372
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.040157
 >> iter 2000, loss: 13.995113
 >> iter 3000, loss: 11.646397
 >> iter 4000, loss: 9.089892
 >> iter 5000, loss: 8.110028
 >> iter 6000, loss: 7.730415
 >> iter 7000, loss: 7.588064
 >> iter 8000, loss: 7.542578
 >> iter 9000, loss: 7.580041
 >> iter 10000, loss: 7.516227
   Number of active neurons: 2
 >> iter 11000, loss: 7.519091
 >> iter 12000, loss: 7.504395
 >> iter 13000, loss: 7.556254
 >> iter 14000, loss: 7.526615
 >> iter 15000, loss: 7.550792
 >> iter 16000, loss: 7.522526
 >> iter 17000, loss: 7.537353
 >> iter 18000, loss: 7.500206
 >> iter 19000, loss: 7.507849
 >> iter 20000, loss: 7.485622
   Number of active neurons: 2
 >> iter 21000, loss: 7.501097
 >> iter 22000, loss: 7.490722
 >> iter 23000, loss: 7.520683
 >> iter 24000, loss: 7.539400
 >> iter 25000, loss: 7.555478
 >> iter 26000, loss: 7.501116
 >> iter 27000, loss: 7.531049
 >> iter 28000, loss: 7.496043
 >> iter 29000, loss: 7.500310
 >> iter 30000, loss: 7.531454
   Number of active neurons: 2
 >> iter 31000, loss: 7.513842
 >> iter 32000, loss: 7.489515
 >> iter 33000, loss: 7.512430
 >> iter 34000, loss: 7.489915
 >> iter 35000, loss: 7.501222
 >> iter 36000, loss: 7.488722
 >> iter 37000, loss: 7.495196
 >> iter 38000, loss: 7.480975
 >> iter 39000, loss: 7.506709
 >> iter 40000, loss: 7.517354
   Number of active neurons: 2
 >> iter 41000, loss: 7.532512
 >> iter 42000, loss: 7.502901
 >> iter 43000, loss: 7.502178
 >> iter 44000, loss: 7.481099
 >> iter 45000, loss: 7.503859
 >> iter 46000, loss: 7.568992
 >> iter 47000, loss: 7.529366
 >> iter 48000, loss: 7.493706
 >> iter 49000, loss: 7.514380
 >> iter 50000, loss: 7.481027
   Number of active neurons: 2
 >> iter 51000, loss: 7.496707
 >> iter 52000, loss: 7.490197
 >> iter 53000, loss: 7.497521
 >> iter 54000, loss: 7.473923
 >> iter 55000, loss: 7.568438
 >> iter 56000, loss: 7.504619
 >> iter 57000, loss: 7.509969
 >> iter 58000, loss: 7.542010
 >> iter 59000, loss: 7.516078
 >> iter 60000, loss: 7.506493
   Number of active neurons: 2
 >> iter 61000, loss: 7.505400
 >> iter 62000, loss: 7.484974
 >> iter 63000, loss: 7.488246
 >> iter 64000, loss: 7.492040
 >> iter 65000, loss: 7.514964
 >> iter 66000, loss: 7.518726
 >> iter 67000, loss: 7.509598
 >> iter 68000, loss: 7.496305
 >> iter 69000, loss: 7.502432
 >> iter 70000, loss: 7.479624
   Number of active neurons: 2
 >> iter 71000, loss: 7.490431
 >> iter 72000, loss: 7.506738
 >> iter 73000, loss: 7.506911
 >> iter 74000, loss: 7.483664
 >> iter 75000, loss: 7.636018
 >> iter 76000, loss: 7.537129
 >> iter 77000, loss: 7.561220
 >> iter 78000, loss: 7.503955
 >> iter 79000, loss: 7.506468
 >> iter 80000, loss: 7.491542
   Number of active neurons: 2
 >> iter 81000, loss: 7.505708
 >> iter 82000, loss: 7.484345
 >> iter 83000, loss: 7.519377
 >> iter 84000, loss: 7.491417
 >> iter 85000, loss: 7.493289
 >> iter 86000, loss: 7.484695
 >> iter 87000, loss: 7.488239
 >> iter 88000, loss: 7.507882
 >> iter 89000, loss: 7.531008
 >> iter 90000, loss: 7.532892
   Number of active neurons: 2
 >> iter 91000, loss: 7.513729
 >> iter 92000, loss: 7.516692
 >> iter 93000, loss: 7.510338
 >> iter 94000, loss: 7.496471
 >> iter 95000, loss: 7.507438
 >> iter 96000, loss: 7.503474
 >> iter 97000, loss: 7.496089
 >> iter 98000, loss: 7.491567
 >> iter 99000, loss: 7.496240
 >> iter 100000, loss: 7.489254
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 21.5315693686
   - Test - Long: 24.7387630618
   - Test - Big: 21.3947860521
   - Test - A: 16.3455769615
   - Test - B: 15.8589427372
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.584727
 >> iter 2000, loss: 10.987686
 >> iter 3000, loss: 8.896431
 >> iter 4000, loss: 8.037171
 >> iter 5000, loss: 7.730742
 >> iter 6000, loss: 7.582690
 >> iter 7000, loss: 7.557382
 >> iter 8000, loss: 7.510013
 >> iter 9000, loss: 7.506422
 >> iter 10000, loss: 7.535337
   Number of active neurons: 2
 >> iter 11000, loss: 7.517487
 >> iter 12000, loss: 7.572541
 >> iter 13000, loss: 7.528676
 >> iter 14000, loss: 7.499680
 >> iter 15000, loss: 7.534477
 >> iter 16000, loss: 7.516295
 >> iter 17000, loss: 7.510761
 >> iter 18000, loss: 7.486989
 >> iter 19000, loss: 7.502054
 >> iter 20000, loss: 7.483203
   Number of active neurons: 2
 >> iter 21000, loss: 7.490428
 >> iter 22000, loss: 7.479364
 >> iter 23000, loss: 7.524957
 >> iter 24000, loss: 7.499764
 >> iter 25000, loss: 7.505346
 >> iter 26000, loss: 7.504336
 >> iter 27000, loss: 7.573821
 >> iter 28000, loss: 7.555992
 >> iter 29000, loss: 7.533813
 >> iter 30000, loss: 7.496475
   Number of active neurons: 2
 >> iter 31000, loss: 7.501621
 >> iter 32000, loss: 7.484806
 >> iter 33000, loss: 7.500910
 >> iter 34000, loss: 7.483461
 >> iter 35000, loss: 7.503663
 >> iter 36000, loss: 7.488227
 >> iter 37000, loss: 7.502538
 >> iter 38000, loss: 7.477877
 >> iter 39000, loss: 7.492975
 >> iter 40000, loss: 7.478070
   Number of active neurons: 2
 >> iter 41000, loss: 7.496239
 >> iter 42000, loss: 7.488457
 >> iter 43000, loss: 7.497156
 >> iter 44000, loss: 7.484893
 >> iter 45000, loss: 7.493107
 >> iter 46000, loss: 7.500203
 >> iter 47000, loss: 7.499228
 >> iter 48000, loss: 7.478096
 >> iter 49000, loss: 7.500580
 >> iter 50000, loss: 7.481979
   Number of active neurons: 2
 >> iter 51000, loss: 7.497696
 >> iter 52000, loss: 7.530157
 >> iter 53000, loss: 7.517137
 >> iter 54000, loss: 7.511016
 >> iter 55000, loss: 7.506613
 >> iter 56000, loss: 7.484590
 >> iter 57000, loss: 7.501533
 >> iter 58000, loss: 7.503966
 >> iter 59000, loss: 7.501134
 >> iter 60000, loss: 7.496459
   Number of active neurons: 2
 >> iter 61000, loss: 7.504747
 >> iter 62000, loss: 7.490193
 >> iter 63000, loss: 7.498462
 >> iter 64000, loss: 7.478160
 >> iter 65000, loss: 7.488673
 >> iter 66000, loss: 7.540695
 >> iter 67000, loss: 7.534610
 >> iter 68000, loss: 7.570128
 >> iter 69000, loss: 7.539455
 >> iter 70000, loss: 7.523632
   Number of active neurons: 2
 >> iter 71000, loss: 7.510664
 >> iter 72000, loss: 7.486523
 >> iter 73000, loss: 7.498089
 >> iter 74000, loss: 7.514538
 >> iter 75000, loss: 7.504059
 >> iter 76000, loss: 7.492470
 >> iter 77000, loss: 7.494966
 >> iter 78000, loss: 7.484514
 >> iter 79000, loss: 7.491357
 >> iter 80000, loss: 7.479408
   Number of active neurons: 2
 >> iter 81000, loss: 7.493701
 >> iter 82000, loss: 7.493538
 >> iter 83000, loss: 7.494238
 >> iter 84000, loss: 7.483987
 >> iter 85000, loss: 7.487580
 >> iter 86000, loss: 7.484314
 >> iter 87000, loss: 7.500455
 >> iter 88000, loss: 7.529567
 >> iter 89000, loss: 7.512683
 >> iter 90000, loss: 7.494703
   Number of active neurons: 2
 >> iter 91000, loss: 7.491981
 >> iter 92000, loss: 7.488936
 >> iter 93000, loss: 7.485294
 >> iter 94000, loss: 7.481678
 >> iter 95000, loss: 7.489031
 >> iter 96000, loss: 7.481791
 >> iter 97000, loss: 7.492015
 >> iter 98000, loss: 7.504516
 >> iter 99000, loss: 7.493501
 >> iter 100000, loss: 7.489760
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 21.5315693686
   - Test - Long: 24.7387630618
   - Test - Big: 21.3947860521
   - Test - A: 16.3455769615
   - Test - B: 15.8589427372

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

