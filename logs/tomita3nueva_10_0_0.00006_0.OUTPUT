 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 6e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.705217
 >> iter 2000, loss: 7.705849
 >> iter 3000, loss: 2.879894
 >> iter 4000, loss: 1.091804
 >> iter 5000, loss: 0.436658
 >> iter 6000, loss: 0.183018
 >> iter 7000, loss: 0.088614
 >> iter 8000, loss: 0.052895
 >> iter 9000, loss: 0.039322
 >> iter 10000, loss: 0.033684
   Number of active neurons: 8
 >> iter 11000, loss: 0.031423
 >> iter 12000, loss: 0.029996
 >> iter 13000, loss: 0.029656
 >> iter 14000, loss: 0.028914
 >> iter 15000, loss: 0.029150
 >> iter 16000, loss: 0.028172
 >> iter 17000, loss: 0.028606
 >> iter 18000, loss: 0.027751
 >> iter 19000, loss: 0.100865
 >> iter 20000, loss: 0.054354
   Number of active neurons: 7
 >> iter 21000, loss: 0.038448
 >> iter 22000, loss: 0.031204
 >> iter 23000, loss: 0.122286
 >> iter 24000, loss: 0.063679
 >> iter 25000, loss: 0.042432
 >> iter 26000, loss: 0.032458
 >> iter 27000, loss: 0.119827
 >> iter 28000, loss: 0.073250
 >> iter 29000, loss: 0.044695
 >> iter 30000, loss: 0.033400
   Number of active neurons: 6
 >> iter 31000, loss: 0.030291
 >> iter 32000, loss: 0.028093
 >> iter 33000, loss: 0.310027
 >> iter 34000, loss: 0.130510
 >> iter 35000, loss: 0.063967
 >> iter 36000, loss: 0.039898
 >> iter 37000, loss: 0.031640
 >> iter 38000, loss: 0.028702
 >> iter 39000, loss: 0.027313
 >> iter 40000, loss: 0.026887
   Number of active neurons: 6
 >> iter 41000, loss: 0.026375
 >> iter 42000, loss: 0.026388
 >> iter 43000, loss: 0.026077
 >> iter 44000, loss: 0.026173
 >> iter 45000, loss: 0.026068
 >> iter 46000, loss: 0.026274
 >> iter 47000, loss: 0.026079
 >> iter 48000, loss: 0.026320
 >> iter 49000, loss: 0.026026
 >> iter 50000, loss: 0.026253
   Number of active neurons: 6
 >> iter 51000, loss: 0.025932
 >> iter 52000, loss: 0.026200
 >> iter 53000, loss: 0.204838
 >> iter 54000, loss: 0.098664
 >> iter 55000, loss: 0.051029
 >> iter 56000, loss: 0.034888
 >> iter 57000, loss: 0.028616
 >> iter 58000, loss: 0.027762
 >> iter 59000, loss: 0.026222
 >> iter 60000, loss: 0.027537
   Number of active neurons: 6
 >> iter 61000, loss: 0.026162
 >> iter 62000, loss: 0.027740
 >> iter 63000, loss: 0.098078
 >> iter 64000, loss: 0.053371
 >> iter 65000, loss: 0.035576
 >> iter 66000, loss: 0.030627
 >> iter 67000, loss: 0.027732
 >> iter 68000, loss: 0.027369
 >> iter 69000, loss: 0.038772
 >> iter 70000, loss: 0.029385
   Number of active neurons: 6
 >> iter 71000, loss: 0.029725
 >> iter 72000, loss: 0.027239
 >> iter 73000, loss: 0.025346
 >> iter 74000, loss: 0.055026
 >> iter 75000, loss: 0.034610
 >> iter 76000, loss: 0.029344
 >> iter 77000, loss: 0.032680
 >> iter 78000, loss: 0.027652
 >> iter 79000, loss: 0.024986
 >> iter 80000, loss: 0.044862
   Number of active neurons: 6
 >> iter 81000, loss: 0.047582
 >> iter 82000, loss: 0.033271
 >> iter 83000, loss: 0.027247
 >> iter 84000, loss: 0.026552
 >> iter 85000, loss: 0.038470
 >> iter 86000, loss: 0.030160
 >> iter 87000, loss: 0.027233
 >> iter 88000, loss: 0.038218
 >> iter 89000, loss: 0.028991
 >> iter 90000, loss: 0.060103
   Number of active neurons: 6
 >> iter 91000, loss: 0.036899
 >> iter 92000, loss: 0.045115
 >> iter 93000, loss: 0.030795
 >> iter 94000, loss: 0.027845
 >> iter 95000, loss: 0.025052
 >> iter 96000, loss: 0.025207
 >> iter 97000, loss: 0.024527
 >> iter 98000, loss: 0.025523
 >> iter 99000, loss: 0.025370
 >> iter 100000, loss: 0.026425
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.673288447437
   - Test - B: 21.4719018732
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.926344
 >> iter 2000, loss: 8.688701
 >> iter 3000, loss: 3.276976
 >> iter 4000, loss: 1.251098
 >> iter 5000, loss: 0.493599
 >> iter 6000, loss: 0.209213
 >> iter 7000, loss: 0.102601
 >> iter 8000, loss: 0.061512
 >> iter 9000, loss: 0.045932
 >> iter 10000, loss: 0.039332
   Number of active neurons: 6
 >> iter 11000, loss: 0.036709
 >> iter 12000, loss: 0.035130
 >> iter 13000, loss: 0.034472
 >> iter 14000, loss: 0.033864
 >> iter 15000, loss: 0.033462
 >> iter 16000, loss: 0.033242
 >> iter 17000, loss: 0.032697
 >> iter 18000, loss: 0.032437
 >> iter 19000, loss: 0.032007
 >> iter 20000, loss: 0.031761
   Number of active neurons: 6
 >> iter 21000, loss: 0.031442
 >> iter 22000, loss: 0.031196
 >> iter 23000, loss: 0.030917
 >> iter 24000, loss: 0.030603
 >> iter 25000, loss: 0.030373
 >> iter 26000, loss: 0.029993
 >> iter 27000, loss: 0.029817
 >> iter 28000, loss: 0.029449
 >> iter 29000, loss: 0.029357
 >> iter 30000, loss: 0.029003
   Number of active neurons: 6
 >> iter 31000, loss: 0.029034
 >> iter 32000, loss: 0.028666
 >> iter 33000, loss: 0.028817
 >> iter 34000, loss: 0.028408
 >> iter 35000, loss: 0.052457
 >> iter 36000, loss: 0.036444
 >> iter 37000, loss: 0.051566
 >> iter 38000, loss: 0.035514
 >> iter 39000, loss: 0.030372
 >> iter 40000, loss: 0.030300
   Number of active neurons: 6
 >> iter 41000, loss: 0.028097
 >> iter 42000, loss: 0.030123
 >> iter 43000, loss: 0.028036
 >> iter 44000, loss: 0.027538
 >> iter 45000, loss: 0.027479
 >> iter 46000, loss: 0.032442
 >> iter 47000, loss: 0.028634
 >> iter 48000, loss: 0.027345
 >> iter 49000, loss: 0.026960
 >> iter 50000, loss: 0.026523
   Number of active neurons: 6
 >> iter 51000, loss: 0.026468
 >> iter 52000, loss: 0.026152
 >> iter 53000, loss: 0.026207
 >> iter 54000, loss: 0.025920
 >> iter 55000, loss: 0.026026
 >> iter 56000, loss: 0.025826
 >> iter 57000, loss: 0.025984
 >> iter 58000, loss: 0.025795
 >> iter 59000, loss: 0.025948
 >> iter 60000, loss: 0.025739
   Number of active neurons: 6
 >> iter 61000, loss: 0.025857
 >> iter 62000, loss: 0.025657
 >> iter 63000, loss: 0.025802
 >> iter 64000, loss: 0.025652
 >> iter 65000, loss: 0.025758
 >> iter 66000, loss: 0.025618
 >> iter 67000, loss: 0.025755
 >> iter 68000, loss: 0.025642
 >> iter 69000, loss: 0.025751
 >> iter 70000, loss: 0.025649
   Number of active neurons: 6
 >> iter 71000, loss: 0.025772
 >> iter 72000, loss: 0.025667
 >> iter 73000, loss: 0.025782
 >> iter 74000, loss: 0.025678
 >> iter 75000, loss: 0.025775
 >> iter 76000, loss: 0.025688
 >> iter 77000, loss: 0.025766
 >> iter 78000, loss: 0.025665
 >> iter 79000, loss: 0.025733
 >> iter 80000, loss: 0.025643
   Number of active neurons: 6
 >> iter 81000, loss: 0.025692
 >> iter 82000, loss: 0.025584
 >> iter 83000, loss: 0.025607
 >> iter 84000, loss: 0.025513
 >> iter 85000, loss: 0.025563
 >> iter 86000, loss: 0.025489
 >> iter 87000, loss: 0.025524
 >> iter 88000, loss: 0.025478
 >> iter 89000, loss: 0.025491
 >> iter 90000, loss: 0.025449
   Number of active neurons: 6
 >> iter 91000, loss: 0.025428
 >> iter 92000, loss: 0.025350
 >> iter 93000, loss: 0.025328
 >> iter 94000, loss: 0.025257
 >> iter 95000, loss: 0.025262
 >> iter 96000, loss: 0.025166
 >> iter 97000, loss: 0.025164
 >> iter 98000, loss: 0.025074
 >> iter 99000, loss: 0.025050
 >> iter 100000, loss: 0.024918
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.313312445837
   - Test - B: 6.75954936338
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.121400
 >> iter 2000, loss: 7.152241
 >> iter 3000, loss: 2.678046
 >> iter 4000, loss: 1.011095
 >> iter 5000, loss: 0.403657
 >> iter 6000, loss: 0.169256
 >> iter 7000, loss: 0.093353
 >> iter 8000, loss: 0.053352
 >> iter 9000, loss: 0.048657
 >> iter 10000, loss: 0.036152
   Number of active neurons: 8
 >> iter 11000, loss: 0.034982
 >> iter 12000, loss: 0.030690
 >> iter 13000, loss: 0.032404
 >> iter 14000, loss: 0.029359
 >> iter 15000, loss: 0.031588
 >> iter 16000, loss: 0.028398
 >> iter 17000, loss: 0.029891
 >> iter 18000, loss: 0.027144
 >> iter 19000, loss: 0.028202
 >> iter 20000, loss: 0.026054
   Number of active neurons: 8
 >> iter 21000, loss: 0.027427
 >> iter 22000, loss: 0.025679
 >> iter 23000, loss: 0.027092
 >> iter 24000, loss: 0.025619
 >> iter 25000, loss: 0.026533
 >> iter 26000, loss: 0.025336
 >> iter 27000, loss: 0.027541
 >> iter 28000, loss: 0.025636
 >> iter 29000, loss: 0.028437
 >> iter 30000, loss: 0.025951
   Number of active neurons: 6
 >> iter 31000, loss: 0.028751
 >> iter 32000, loss: 0.026266
 >> iter 33000, loss: 0.027419
 >> iter 34000, loss: 0.026127
 >> iter 35000, loss: 0.024824
 >> iter 36000, loss: 0.025745
 >> iter 37000, loss: 0.024672
 >> iter 38000, loss: 0.026074
 >> iter 39000, loss: 0.024793
 >> iter 40000, loss: 0.026339
   Number of active neurons: 6
 >> iter 41000, loss: 0.024876
 >> iter 42000, loss: 0.026504
 >> iter 43000, loss: 0.024975
 >> iter 44000, loss: 0.026596
 >> iter 45000, loss: 0.025169
 >> iter 46000, loss: 0.026651
 >> iter 47000, loss: 0.025296
 >> iter 48000, loss: 0.026711
 >> iter 49000, loss: 0.025464
 >> iter 50000, loss: 0.026769
   Number of active neurons: 5
 >> iter 51000, loss: 0.029683
 >> iter 52000, loss: 0.027504
 >> iter 53000, loss: 0.205074
 >> iter 54000, loss: 0.092722
 >> iter 55000, loss: 0.049471
 >> iter 56000, loss: 0.036135
 >> iter 57000, loss: 0.028820
 >> iter 58000, loss: 0.028722
 >> iter 59000, loss: 0.026660
 >> iter 60000, loss: 0.027856
   Number of active neurons: 5
 >> iter 61000, loss: 0.026633
 >> iter 62000, loss: 0.027728
 >> iter 63000, loss: 0.026510
 >> iter 64000, loss: 0.027594
 >> iter 65000, loss: 0.026407
 >> iter 66000, loss: 0.027274
 >> iter 67000, loss: 0.026204
 >> iter 68000, loss: 0.027003
 >> iter 69000, loss: 0.025939
 >> iter 70000, loss: 0.026719
   Number of active neurons: 5
 >> iter 71000, loss: 0.025668
 >> iter 72000, loss: 0.026441
 >> iter 73000, loss: 0.025410
 >> iter 74000, loss: 0.026211
 >> iter 75000, loss: 0.025102
 >> iter 76000, loss: 0.025917
 >> iter 77000, loss: 0.024987
 >> iter 78000, loss: 0.025803
 >> iter 79000, loss: 0.024586
 >> iter 80000, loss: 0.025336
   Number of active neurons: 5
 >> iter 81000, loss: 0.024559
 >> iter 82000, loss: 0.025136
 >> iter 83000, loss: 0.024464
 >> iter 84000, loss: 0.024970
 >> iter 85000, loss: 0.024509
 >> iter 86000, loss: 0.024700
 >> iter 87000, loss: 0.024513
 >> iter 88000, loss: 0.024415
 >> iter 89000, loss: 0.024503
 >> iter 90000, loss: 0.024293
   Number of active neurons: 5
 >> iter 91000, loss: 0.024582
 >> iter 92000, loss: 0.024175
 >> iter 93000, loss: 0.114976
 >> iter 94000, loss: 0.058399
 >> iter 95000, loss: 0.037230
 >> iter 96000, loss: 0.029246
 >> iter 97000, loss: 0.026898
 >> iter 98000, loss: 0.024943
 >> iter 99000, loss: 0.142259
 >> iter 100000, loss: 0.066420
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 17.4521698553
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.749201
 >> iter 2000, loss: 8.568363
 >> iter 3000, loss: 3.339744
 >> iter 4000, loss: 1.297644
 >> iter 5000, loss: 0.572819
 >> iter 6000, loss: 0.238613
 >> iter 7000, loss: 0.111588
 >> iter 8000, loss: 0.067598
 >> iter 9000, loss: 0.045339
 >> iter 10000, loss: 0.041398
   Number of active neurons: 6
 >> iter 11000, loss: 0.034032
 >> iter 12000, loss: 0.033653
 >> iter 13000, loss: 0.030215
 >> iter 14000, loss: 0.031855
 >> iter 15000, loss: 0.028999
 >> iter 16000, loss: 0.031321
 >> iter 17000, loss: 0.028595
 >> iter 18000, loss: 0.029862
 >> iter 19000, loss: 0.027881
 >> iter 20000, loss: 0.029462
   Number of active neurons: 6
 >> iter 21000, loss: 0.028083
 >> iter 22000, loss: 0.028522
 >> iter 23000, loss: 0.027271
 >> iter 24000, loss: 0.032254
 >> iter 25000, loss: 0.028473
 >> iter 26000, loss: 0.036125
 >> iter 27000, loss: 0.030243
 >> iter 28000, loss: 0.037697
 >> iter 29000, loss: 0.053286
 >> iter 30000, loss: 0.043742
   Number of active neurons: 5
 >> iter 31000, loss: 0.049155
 >> iter 32000, loss: 0.037200
 >> iter 33000, loss: 0.053449
 >> iter 34000, loss: 0.036403
 >> iter 35000, loss: 0.049257
 >> iter 36000, loss: 0.034818
 >> iter 37000, loss: 0.050807
 >> iter 38000, loss: 0.035327
 >> iter 39000, loss: 0.052475
 >> iter 40000, loss: 0.037762
   Number of active neurons: 5
 >> iter 41000, loss: 0.049779
 >> iter 42000, loss: 0.036865
 >> iter 43000, loss: 0.112127
 >> iter 44000, loss: 0.058397
 >> iter 45000, loss: 0.038524
 >> iter 46000, loss: 0.031376
 >> iter 47000, loss: 0.029919
 >> iter 48000, loss: 0.027779
 >> iter 49000, loss: 0.028777
 >> iter 50000, loss: 0.026804
   Number of active neurons: 5
 >> iter 51000, loss: 0.084786
 >> iter 52000, loss: 0.048114
 >> iter 53000, loss: 0.034773
 >> iter 54000, loss: 0.029285
 >> iter 55000, loss: 0.027454
 >> iter 56000, loss: 0.026288
 >> iter 57000, loss: 0.026085
 >> iter 58000, loss: 0.025590
 >> iter 59000, loss: 0.025664
 >> iter 60000, loss: 0.025238
   Number of active neurons: 5
 >> iter 61000, loss: 0.025369
 >> iter 62000, loss: 0.024915
 >> iter 63000, loss: 0.025036
 >> iter 64000, loss: 0.024566
 >> iter 65000, loss: 0.024691
 >> iter 66000, loss: 0.024297
 >> iter 67000, loss: 0.024461
 >> iter 68000, loss: 0.024105
 >> iter 69000, loss: 0.024265
 >> iter 70000, loss: 0.023935
   Number of active neurons: 5
 >> iter 71000, loss: 0.024116
 >> iter 72000, loss: 0.023779
 >> iter 73000, loss: 0.023973
 >> iter 74000, loss: 0.023641
 >> iter 75000, loss: 0.023834
 >> iter 76000, loss: 0.023544
 >> iter 77000, loss: 0.023710
 >> iter 78000, loss: 0.023433
 >> iter 79000, loss: 0.023599
 >> iter 80000, loss: 0.023326
   Number of active neurons: 5
 >> iter 81000, loss: 0.023484
 >> iter 82000, loss: 0.023238
 >> iter 83000, loss: 0.023393
 >> iter 84000, loss: 0.023148
 >> iter 85000, loss: 0.023314
 >> iter 86000, loss: 0.023076
 >> iter 87000, loss: 0.023231
 >> iter 88000, loss: 0.023024
 >> iter 89000, loss: 0.023161
 >> iter 90000, loss: 0.022961
   Number of active neurons: 5
 >> iter 91000, loss: 0.023090
 >> iter 92000, loss: 0.022898
 >> iter 93000, loss: 0.023033
 >> iter 94000, loss: 0.022838
 >> iter 95000, loss: 0.023009
 >> iter 96000, loss: 0.022777
 >> iter 97000, loss: 0.022955
 >> iter 98000, loss: 0.022723
 >> iter 99000, loss: 0.022917
 >> iter 100000, loss: 0.022684
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 15.1456569562
   - Test - B: 20.4186387574
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.910220
 >> iter 2000, loss: 8.643437
 >> iter 3000, loss: 3.376452
 >> iter 4000, loss: 1.281650
 >> iter 5000, loss: 0.610224
 >> iter 6000, loss: 0.247787
 >> iter 7000, loss: 0.145590
 >> iter 8000, loss: 0.077973
 >> iter 9000, loss: 0.270136
 >> iter 10000, loss: 0.123328
   Number of active neurons: 9
 >> iter 11000, loss: 0.067126
 >> iter 12000, loss: 0.045078
 >> iter 13000, loss: 0.036518
 >> iter 14000, loss: 0.032283
 >> iter 15000, loss: 0.030644
 >> iter 16000, loss: 0.029690
 >> iter 17000, loss: 0.028961
 >> iter 18000, loss: 0.029911
 >> iter 19000, loss: 0.028665
 >> iter 20000, loss: 0.029148
   Number of active neurons: 7
 >> iter 21000, loss: 0.028232
 >> iter 22000, loss: 0.028393
 >> iter 23000, loss: 0.027379
 >> iter 24000, loss: 0.063415
 >> iter 25000, loss: 0.102991
 >> iter 26000, loss: 0.086926
 >> iter 27000, loss: 0.048742
 >> iter 28000, loss: 0.035453
 >> iter 29000, loss: 0.030036
 >> iter 30000, loss: 0.028034
   Number of active neurons: 6
 >> iter 31000, loss: 0.027437
 >> iter 32000, loss: 0.041585
 >> iter 33000, loss: 0.037058
 >> iter 34000, loss: 0.029392
 >> iter 35000, loss: 0.026679
 >> iter 36000, loss: 0.025871
 >> iter 37000, loss: 0.025766
 >> iter 38000, loss: 0.042514
 >> iter 39000, loss: 0.031386
 >> iter 40000, loss: 0.027914
   Number of active neurons: 6
 >> iter 41000, loss: 0.026308
 >> iter 42000, loss: 0.025960
 >> iter 43000, loss: 0.025591
 >> iter 44000, loss: 0.072690
 >> iter 45000, loss: 0.042681
 >> iter 46000, loss: 0.060439
 >> iter 47000, loss: 0.038545
 >> iter 48000, loss: 0.089646
 >> iter 49000, loss: 0.050238
 >> iter 50000, loss: 0.080589
   Number of active neurons: 6
 >> iter 51000, loss: 0.046862
 >> iter 52000, loss: 0.034394
 >> iter 53000, loss: 0.029359
 >> iter 54000, loss: 0.045691
 >> iter 55000, loss: 0.033061
 >> iter 56000, loss: 0.074103
 >> iter 57000, loss: 0.043344
 >> iter 58000, loss: 0.036665
 >> iter 59000, loss: 0.029569
 >> iter 60000, loss: 0.028998
   Number of active neurons: 6
 >> iter 61000, loss: 0.026678
 >> iter 62000, loss: 0.028581
 >> iter 63000, loss: 0.123319
 >> iter 64000, loss: 0.062457
 >> iter 65000, loss: 0.039135
 >> iter 66000, loss: 0.031935
 >> iter 67000, loss: 0.031565
 >> iter 68000, loss: 0.057605
 >> iter 69000, loss: 0.037684
 >> iter 70000, loss: 0.032648
   Number of active neurons: 6
 >> iter 71000, loss: 0.028694
 >> iter 72000, loss: 0.069059
 >> iter 73000, loss: 0.157254
 >> iter 74000, loss: 0.076414
 >> iter 75000, loss: 0.045129
 >> iter 76000, loss: 0.037691
 >> iter 77000, loss: 0.030292
 >> iter 78000, loss: 0.030179
 >> iter 79000, loss: 0.027572
 >> iter 80000, loss: 0.032700
   Number of active neurons: 6
 >> iter 81000, loss: 0.237499
 >> iter 82000, loss: 0.108276
 >> iter 83000, loss: 0.185627
 >> iter 84000, loss: 0.090104
 >> iter 85000, loss: 0.052250
 >> iter 86000, loss: 0.047026
 >> iter 87000, loss: 0.116168
 >> iter 88000, loss: 0.064577
 >> iter 89000, loss: 0.041706
 >> iter 90000, loss: 0.038872
   Number of active neurons: 6
 >> iter 91000, loss: 0.032133
 >> iter 92000, loss: 0.031823
 >> iter 93000, loss: 0.029041
 >> iter 94000, loss: 0.030415
 >> iter 95000, loss: 0.078385
 >> iter 96000, loss: 0.048172
 >> iter 97000, loss: 0.084810
 >> iter 98000, loss: 0.048994
 >> iter 99000, loss: 0.352999
 >> iter 100000, loss: 0.200385
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.019999600008
   - Test - Long: 0.05999700015
   - Test - Big: 0.0159998400016
   - Test - A: 0.0
   - Test - B: 18.5787614159
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 18.614235
 >> iter 2000, loss: 7.460174
 >> iter 3000, loss: 2.803317
 >> iter 4000, loss: 1.066469
 >> iter 5000, loss: 0.420019
 >> iter 6000, loss: 0.181740
 >> iter 7000, loss: 0.090229
 >> iter 8000, loss: 0.057864
 >> iter 9000, loss: 0.043006
 >> iter 10000, loss: 0.043690
   Number of active neurons: 9
 >> iter 11000, loss: 0.036820
 >> iter 12000, loss: 0.036830
 >> iter 13000, loss: 0.033252
 >> iter 14000, loss: 0.032159
 >> iter 15000, loss: 0.031304
 >> iter 16000, loss: 0.030788
 >> iter 17000, loss: 0.030738
 >> iter 18000, loss: 0.030389
 >> iter 19000, loss: 0.030302
 >> iter 20000, loss: 0.029813
   Number of active neurons: 9
 >> iter 21000, loss: 0.029385
 >> iter 22000, loss: 0.028890
 >> iter 23000, loss: 0.028698
 >> iter 24000, loss: 0.028448
 >> iter 25000, loss: 0.028155
 >> iter 26000, loss: 0.027786
 >> iter 27000, loss: 0.027516
 >> iter 28000, loss: 0.027270
 >> iter 29000, loss: 0.027102
 >> iter 30000, loss: 0.026878
   Number of active neurons: 9
 >> iter 31000, loss: 0.026752
 >> iter 32000, loss: 0.026540
 >> iter 33000, loss: 0.026465
 >> iter 34000, loss: 0.026269
 >> iter 35000, loss: 0.026187
 >> iter 36000, loss: 0.025964
 >> iter 37000, loss: 0.025885
 >> iter 38000, loss: 0.025671
 >> iter 39000, loss: 0.025637
 >> iter 40000, loss: 0.025440
   Number of active neurons: 9
 >> iter 41000, loss: 0.025374
 >> iter 42000, loss: 0.025086
 >> iter 43000, loss: 0.025001
 >> iter 44000, loss: 0.024758
 >> iter 45000, loss: 0.024748
 >> iter 46000, loss: 0.024516
 >> iter 47000, loss: 0.024550
 >> iter 48000, loss: 0.024325
 >> iter 49000, loss: 0.024344
 >> iter 50000, loss: 0.024188
   Number of active neurons: 9
 >> iter 51000, loss: 0.024259
 >> iter 52000, loss: 0.024183
 >> iter 53000, loss: 0.024258
 >> iter 54000, loss: 0.024158
 >> iter 55000, loss: 0.024255
 >> iter 56000, loss: 0.024163
 >> iter 57000, loss: 0.024281
 >> iter 58000, loss: 0.024188
 >> iter 59000, loss: 0.024319
 >> iter 60000, loss: 0.024227
   Number of active neurons: 9
 >> iter 61000, loss: 0.024332
 >> iter 62000, loss: 0.024182
 >> iter 63000, loss: 0.024300
 >> iter 64000, loss: 0.024173
 >> iter 65000, loss: 0.024282
 >> iter 66000, loss: 0.024130
 >> iter 67000, loss: 0.024218
 >> iter 68000, loss: 0.024052
 >> iter 69000, loss: 0.024136
 >> iter 70000, loss: 0.024004
   Number of active neurons: 9
 >> iter 71000, loss: 0.024114
 >> iter 72000, loss: 0.023986
 >> iter 73000, loss: 0.024111
 >> iter 74000, loss: 0.023985
 >> iter 75000, loss: 0.024109
 >> iter 76000, loss: 0.023959
 >> iter 77000, loss: 0.024052
 >> iter 78000, loss: 0.023919
 >> iter 79000, loss: 0.024028
 >> iter 80000, loss: 0.023912
   Number of active neurons: 9
 >> iter 81000, loss: 0.024031
 >> iter 82000, loss: 0.023913
 >> iter 83000, loss: 0.023995
 >> iter 84000, loss: 0.023881
 >> iter 85000, loss: 0.023970
 >> iter 86000, loss: 0.023878
 >> iter 87000, loss: 0.023962
 >> iter 88000, loss: 0.023904
 >> iter 89000, loss: 0.023981
 >> iter 90000, loss: 0.023941
   Number of active neurons: 9
 >> iter 91000, loss: 0.024019
 >> iter 92000, loss: 0.023989
 >> iter 93000, loss: 0.024071
 >> iter 94000, loss: 0.024047
 >> iter 95000, loss: 0.024124
 >> iter 96000, loss: 0.024088
 >> iter 97000, loss: 0.024160
 >> iter 98000, loss: 0.024144
 >> iter 99000, loss: 0.024210
 >> iter 100000, loss: 0.024207
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 15.7589494034
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.566603
 >> iter 2000, loss: 7.461204
 >> iter 3000, loss: 2.798527
 >> iter 4000, loss: 1.057114
 >> iter 5000, loss: 0.418384
 >> iter 6000, loss: 0.182988
 >> iter 7000, loss: 0.086096
 >> iter 8000, loss: 0.061713
 >> iter 9000, loss: 0.072464
 >> iter 10000, loss: 0.053033
   Number of active neurons: 6
 >> iter 11000, loss: 0.063942
 >> iter 12000, loss: 0.041911
 >> iter 13000, loss: 0.060501
 >> iter 14000, loss: 0.039294
 >> iter 15000, loss: 0.041302
 >> iter 16000, loss: 0.034329
 >> iter 17000, loss: 0.035870
 >> iter 18000, loss: 0.036612
 >> iter 19000, loss: 0.038096
 >> iter 20000, loss: 0.090234
   Number of active neurons: 6
 >> iter 21000, loss: 0.059876
 >> iter 22000, loss: 0.095249
 >> iter 23000, loss: 0.061375
 >> iter 24000, loss: 0.040873
 >> iter 25000, loss: 0.043583
 >> iter 26000, loss: 0.034934
 >> iter 27000, loss: 0.076958
 >> iter 28000, loss: 0.045555
 >> iter 29000, loss: 0.035420
 >> iter 30000, loss: 0.030708
   Number of active neurons: 6
 >> iter 31000, loss: 0.038645
 >> iter 32000, loss: 0.031125
 >> iter 33000, loss: 0.041153
 >> iter 34000, loss: 0.032331
 >> iter 35000, loss: 0.038344
 >> iter 36000, loss: 0.031001
 >> iter 37000, loss: 0.035135
 >> iter 38000, loss: 0.029426
 >> iter 39000, loss: 0.031622
 >> iter 40000, loss: 0.027631
   Number of active neurons: 6
 >> iter 41000, loss: 0.029430
 >> iter 42000, loss: 0.026451
 >> iter 43000, loss: 0.028351
 >> iter 44000, loss: 0.025659
 >> iter 45000, loss: 0.229904
 >> iter 46000, loss: 0.190846
 >> iter 47000, loss: 0.087813
 >> iter 48000, loss: 0.049552
 >> iter 49000, loss: 0.040577
 >> iter 50000, loss: 0.030804
   Number of active neurons: 6
 >> iter 51000, loss: 0.027450
 >> iter 52000, loss: 0.025859
 >> iter 53000, loss: 0.112995
 >> iter 54000, loss: 0.057458
 >> iter 55000, loss: 0.037222
 >> iter 56000, loss: 0.029376
 >> iter 57000, loss: 0.042363
 >> iter 58000, loss: 0.030753
 >> iter 59000, loss: 0.028519
 >> iter 60000, loss: 0.025455
   Number of active neurons: 5
 >> iter 61000, loss: 0.025997
 >> iter 62000, loss: 0.024640
 >> iter 63000, loss: 0.090030
 >> iter 64000, loss: 0.048832
 >> iter 65000, loss: 0.035673
 >> iter 66000, loss: 0.027925
 >> iter 67000, loss: 0.026874
 >> iter 68000, loss: 0.025011
 >> iter 69000, loss: 0.027051
 >> iter 70000, loss: 0.024802
   Number of active neurons: 5
 >> iter 71000, loss: 0.100321
 >> iter 72000, loss: 0.101396
 >> iter 73000, loss: 0.531002
 >> iter 74000, loss: 0.281502
 >> iter 75000, loss: 0.120622
 >> iter 76000, loss: 0.062503
 >> iter 77000, loss: 0.039147
 >> iter 78000, loss: 0.045100
 >> iter 79000, loss: 0.031906
 >> iter 80000, loss: 0.039911
   Number of active neurons: 5
 >> iter 81000, loss: 0.029699
 >> iter 82000, loss: 0.035897
 >> iter 83000, loss: 0.027873
 >> iter 84000, loss: 0.027125
 >> iter 85000, loss: 0.025366
 >> iter 86000, loss: 0.025597
 >> iter 87000, loss: 0.025694
 >> iter 88000, loss: 0.025284
 >> iter 89000, loss: 0.036772
 >> iter 90000, loss: 0.044901
   Number of active neurons: 5
 >> iter 91000, loss: 0.193722
 >> iter 92000, loss: 0.099024
 >> iter 93000, loss: 0.057101
 >> iter 94000, loss: 0.081446
 >> iter 95000, loss: 0.046434
 >> iter 96000, loss: 0.035888
 >> iter 97000, loss: 0.029362
 >> iter 98000, loss: 0.028831
 >> iter 99000, loss: 0.026613
 >> iter 100000, loss: 0.053016
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 21.3852409839
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.065258
 >> iter 2000, loss: 8.300865
 >> iter 3000, loss: 3.179540
 >> iter 4000, loss: 1.211949
 >> iter 5000, loss: 0.477497
 >> iter 6000, loss: 0.202939
 >> iter 7000, loss: 0.099524
 >> iter 8000, loss: 0.059877
 >> iter 9000, loss: 0.044718
 >> iter 10000, loss: 0.038327
   Number of active neurons: 7
 >> iter 11000, loss: 0.035765
 >> iter 12000, loss: 0.034208
 >> iter 13000, loss: 0.033538
 >> iter 14000, loss: 0.032789
 >> iter 15000, loss: 0.032431
 >> iter 16000, loss: 0.031791
 >> iter 17000, loss: 0.031501
 >> iter 18000, loss: 0.030964
 >> iter 19000, loss: 0.030783
 >> iter 20000, loss: 0.030354
   Number of active neurons: 7
 >> iter 21000, loss: 0.030300
 >> iter 22000, loss: 0.029929
 >> iter 23000, loss: 0.029831
 >> iter 24000, loss: 0.029540
 >> iter 25000, loss: 0.029514
 >> iter 26000, loss: 0.029303
 >> iter 27000, loss: 0.029329
 >> iter 28000, loss: 0.029160
 >> iter 29000, loss: 0.029206
 >> iter 30000, loss: 0.029000
   Number of active neurons: 7
 >> iter 31000, loss: 0.028955
 >> iter 32000, loss: 0.028675
 >> iter 33000, loss: 0.028616
 >> iter 34000, loss: 0.028356
 >> iter 35000, loss: 0.028311
 >> iter 36000, loss: 0.028056
 >> iter 37000, loss: 0.027983
 >> iter 38000, loss: 0.027717
 >> iter 39000, loss: 0.027620
 >> iter 40000, loss: 0.027280
   Number of active neurons: 7
 >> iter 41000, loss: 0.027143
 >> iter 42000, loss: 0.026823
 >> iter 43000, loss: 0.026694
 >> iter 44000, loss: 0.026372
 >> iter 45000, loss: 0.026276
 >> iter 46000, loss: 0.026026
 >> iter 47000, loss: 0.026061
 >> iter 48000, loss: 0.025873
 >> iter 49000, loss: 0.025906
 >> iter 50000, loss: 0.025749
   Number of active neurons: 7
 >> iter 51000, loss: 0.025803
 >> iter 52000, loss: 0.025682
 >> iter 53000, loss: 0.025709
 >> iter 54000, loss: 0.025541
 >> iter 55000, loss: 0.025576
 >> iter 56000, loss: 0.025406
 >> iter 57000, loss: 0.025443
 >> iter 58000, loss: 0.025281
 >> iter 59000, loss: 0.025349
 >> iter 60000, loss: 0.025219
   Number of active neurons: 7
 >> iter 61000, loss: 0.025291
 >> iter 62000, loss: 0.025130
 >> iter 63000, loss: 0.025232
 >> iter 64000, loss: 0.025093
 >> iter 65000, loss: 0.025202
 >> iter 66000, loss: 0.025071
 >> iter 67000, loss: 0.025179
 >> iter 68000, loss: 0.025031
 >> iter 69000, loss: 0.025119
 >> iter 70000, loss: 0.024994
   Number of active neurons: 7
 >> iter 71000, loss: 0.025060
 >> iter 72000, loss: 0.024906
 >> iter 73000, loss: 0.024967
 >> iter 74000, loss: 0.024834
 >> iter 75000, loss: 0.024903
 >> iter 76000, loss: 0.024787
 >> iter 77000, loss: 0.024838
 >> iter 78000, loss: 0.024754
 >> iter 79000, loss: 0.024815
 >> iter 80000, loss: 0.024756
   Number of active neurons: 7
 >> iter 81000, loss: 0.024819
 >> iter 82000, loss: 0.024795
 >> iter 83000, loss: 0.024851
 >> iter 84000, loss: 0.024843
 >> iter 85000, loss: 0.024898
 >> iter 86000, loss: 0.024920
 >> iter 87000, loss: 0.024945
 >> iter 88000, loss: 0.025010
 >> iter 89000, loss: 0.025002
 >> iter 90000, loss: 0.025091
   Number of active neurons: 7
 >> iter 91000, loss: 0.025043
 >> iter 92000, loss: 0.025157
 >> iter 93000, loss: 0.024985
 >> iter 94000, loss: 0.025135
 >> iter 95000, loss: 0.024894
 >> iter 96000, loss: 0.028003
 >> iter 97000, loss: 0.025763
 >> iter 98000, loss: 0.027209
 >> iter 99000, loss: 0.025397
 >> iter 100000, loss: 0.025589
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 15.7589494034
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.915999
 >> iter 2000, loss: 8.005020
 >> iter 3000, loss: 2.985101
 >> iter 4000, loss: 1.126063
 >> iter 5000, loss: 0.438910
 >> iter 6000, loss: 0.185455
 >> iter 7000, loss: 0.090488
 >> iter 8000, loss: 0.055439
 >> iter 9000, loss: 0.041160
 >> iter 10000, loss: 0.045214
   Number of active neurons: 9
 >> iter 11000, loss: 0.037150
 >> iter 12000, loss: 0.051360
 >> iter 13000, loss: 0.039148
 >> iter 14000, loss: 0.042437
 >> iter 15000, loss: 0.035740
 >> iter 16000, loss: 0.039251
 >> iter 17000, loss: 0.034274
 >> iter 18000, loss: 0.035484
 >> iter 19000, loss: 0.032570
 >> iter 20000, loss: 0.113680
   Number of active neurons: 8
 >> iter 21000, loss: 0.060767
 >> iter 22000, loss: 0.041201
 >> iter 23000, loss: 0.034232
 >> iter 24000, loss: 0.031581
 >> iter 25000, loss: 0.030601
 >> iter 26000, loss: 0.030760
 >> iter 27000, loss: 0.030011
 >> iter 28000, loss: 0.030368
 >> iter 29000, loss: 0.029625
 >> iter 30000, loss: 0.030054
   Number of active neurons: 8
 >> iter 31000, loss: 0.029334
 >> iter 32000, loss: 0.038567
 >> iter 33000, loss: 0.124985
 >> iter 34000, loss: 0.064251
 >> iter 35000, loss: 0.041930
 >> iter 36000, loss: 0.033805
 >> iter 37000, loss: 0.030547
 >> iter 38000, loss: 0.029709
 >> iter 39000, loss: 0.028968
 >> iter 40000, loss: 0.029016
   Number of active neurons: 8
 >> iter 41000, loss: 0.028619
 >> iter 42000, loss: 0.028613
 >> iter 43000, loss: 0.028360
 >> iter 44000, loss: 0.028198
 >> iter 45000, loss: 0.028102
 >> iter 46000, loss: 0.115035
 >> iter 47000, loss: 0.342239
 >> iter 48000, loss: 0.143151
 >> iter 49000, loss: 0.070128
 >> iter 50000, loss: 0.043752
   Number of active neurons: 8
 >> iter 51000, loss: 0.034285
 >> iter 52000, loss: 0.030738
 >> iter 53000, loss: 0.029500
 >> iter 54000, loss: 0.028972
 >> iter 55000, loss: 0.306703
 >> iter 56000, loss: 0.403035
 >> iter 57000, loss: 0.169341
 >> iter 58000, loss: 0.082581
 >> iter 59000, loss: 0.050113
 >> iter 60000, loss: 0.037741
   Number of active neurons: 8
 >> iter 61000, loss: 0.032954
 >> iter 62000, loss: 0.030575
 >> iter 63000, loss: 0.029722
 >> iter 64000, loss: 0.028915
 >> iter 65000, loss: 0.029074
 >> iter 66000, loss: 0.028224
 >> iter 67000, loss: 0.198437
 >> iter 68000, loss: 0.090282
 >> iter 69000, loss: 0.051188
 >> iter 70000, loss: 0.036665
   Number of active neurons: 7
 >> iter 71000, loss: 0.337293
 >> iter 72000, loss: 0.143712
 >> iter 73000, loss: 0.136705
 >> iter 74000, loss: 0.067635
 >> iter 75000, loss: 0.043158
 >> iter 76000, loss: 0.034062
 >> iter 77000, loss: 0.229288
 >> iter 78000, loss: 0.102643
 >> iter 79000, loss: 0.056249
 >> iter 80000, loss: 0.038981
   Number of active neurons: 7
 >> iter 81000, loss: 0.041863
 >> iter 82000, loss: 0.032954
 >> iter 83000, loss: 0.304431
 >> iter 84000, loss: 0.130633
 >> iter 85000, loss: 0.066554
 >> iter 86000, loss: 0.042889
 >> iter 87000, loss: 0.212115
 >> iter 88000, loss: 0.096377
 >> iter 89000, loss: 0.053740
 >> iter 90000, loss: 0.037831
   Number of active neurons: 7
 >> iter 91000, loss: 0.184009
 >> iter 92000, loss: 0.086175
 >> iter 93000, loss: 0.058591
 >> iter 94000, loss: 0.039489
 >> iter 95000, loss: 0.090852
 >> iter 96000, loss: 0.049342
 >> iter 97000, loss: 0.081162
 >> iter 98000, loss: 0.044928
 >> iter 99000, loss: 0.033212
 >> iter 100000, loss: 0.029149
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 5.2196520232
   - Test - B: 8.8327444837
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.886235
 >> iter 2000, loss: 8.044288
 >> iter 3000, loss: 3.009962
 >> iter 4000, loss: 1.141552
 >> iter 5000, loss: 0.445553
 >> iter 6000, loss: 0.189743
 >> iter 7000, loss: 0.090982
 >> iter 8000, loss: 0.056206
 >> iter 9000, loss: 0.039849
 >> iter 10000, loss: 0.036206
   Number of active neurons: 7
 >> iter 11000, loss: 0.031607
 >> iter 12000, loss: 0.032572
 >> iter 13000, loss: 0.029899
 >> iter 14000, loss: 0.031682
 >> iter 15000, loss: 0.029196
 >> iter 16000, loss: 0.030565
 >> iter 17000, loss: 0.028392
 >> iter 18000, loss: 0.029404
 >> iter 19000, loss: 0.029905
 >> iter 20000, loss: 0.029577
   Number of active neurons: 6
 >> iter 21000, loss: 0.032238
 >> iter 22000, loss: 0.029858
 >> iter 23000, loss: 0.029304
 >> iter 24000, loss: 0.029015
 >> iter 25000, loss: 0.038817
 >> iter 26000, loss: 0.033520
 >> iter 27000, loss: 0.030532
 >> iter 28000, loss: 0.031077
 >> iter 29000, loss: 0.620309
 >> iter 30000, loss: 0.257245
   Number of active neurons: 6
 >> iter 31000, loss: 0.128448
 >> iter 32000, loss: 0.069869
 >> iter 33000, loss: 0.050675
 >> iter 34000, loss: 0.075002
 >> iter 35000, loss: 0.109251
 >> iter 36000, loss: 0.063665
 >> iter 37000, loss: 0.078573
 >> iter 38000, loss: 0.049672
 >> iter 39000, loss: 0.097712
 >> iter 40000, loss: 0.057961
   Number of active neurons: 6
 >> iter 41000, loss: 0.105056
 >> iter 42000, loss: 0.117145
 >> iter 43000, loss: 0.066187
 >> iter 44000, loss: 0.047078
 >> iter 45000, loss: 0.098765
 >> iter 46000, loss: 0.090512
 >> iter 47000, loss: 0.116356
 >> iter 48000, loss: 0.065524
 >> iter 49000, loss: 0.105462
 >> iter 50000, loss: 0.061274
   Number of active neurons: 6
 >> iter 51000, loss: 0.109717
 >> iter 52000, loss: 0.062805
 >> iter 53000, loss: 0.113275
 >> iter 54000, loss: 0.064236
 >> iter 55000, loss: 0.115381
 >> iter 56000, loss: 0.065194
 >> iter 57000, loss: 0.115784
 >> iter 58000, loss: 0.065319
 >> iter 59000, loss: 0.113454
 >> iter 60000, loss: 0.068055
   Number of active neurons: 6
 >> iter 61000, loss: 0.160709
 >> iter 62000, loss: 0.093163
 >> iter 63000, loss: 0.119230
 >> iter 64000, loss: 0.072354
 >> iter 65000, loss: 0.092646
 >> iter 66000, loss: 0.059743
 >> iter 67000, loss: 0.040256
 >> iter 68000, loss: 0.087049
 >> iter 69000, loss: 0.117834
 >> iter 70000, loss: 0.067129
   Number of active neurons: 6
 >> iter 71000, loss: 0.177254
 >> iter 72000, loss: 0.086307
 >> iter 73000, loss: 0.050478
 >> iter 74000, loss: 0.234934
 >> iter 75000, loss: 0.106445
 >> iter 76000, loss: 0.061756
 >> iter 77000, loss: 0.041023
 >> iter 78000, loss: 0.040468
 >> iter 79000, loss: 0.151358
 >> iter 80000, loss: 0.189923
   Number of active neurons: 6
 >> iter 81000, loss: 0.088510
 >> iter 82000, loss: 0.052939
 >> iter 83000, loss: 0.037224
 >> iter 84000, loss: 0.197252
 >> iter 85000, loss: 0.092047
 >> iter 86000, loss: 0.055924
 >> iter 87000, loss: 0.038187
 >> iter 88000, loss: 0.033235
 >> iter 89000, loss: 0.029185
 >> iter 90000, loss: 0.028132
   Number of active neurons: 6
 >> iter 91000, loss: 0.079250
 >> iter 92000, loss: 0.091831
 >> iter 93000, loss: 0.051121
 >> iter 94000, loss: 0.037303
 >> iter 95000, loss: 0.030672
 >> iter 96000, loss: 0.254292
 >> iter 97000, loss: 0.111028
 >> iter 98000, loss: 0.059486
 >> iter 99000, loss: 0.042174
 >> iter 100000, loss: 0.033331
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0179996400072
   - Test - Long: 0.0
   - Test - Big: 0.0049999500005
   - Test - A: 0.0466635557629
   - Test - B: 7.34617692154
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.630213
 >> iter 2000, loss: 7.600335
 >> iter 3000, loss: 2.842674
 >> iter 4000, loss: 1.076017
 >> iter 5000, loss: 0.421139
 >> iter 6000, loss: 0.177511
 >> iter 7000, loss: 0.086711
 >> iter 8000, loss: 0.052217
 >> iter 9000, loss: 0.039013
 >> iter 10000, loss: 0.033372
   Number of active neurons: 7
 >> iter 11000, loss: 0.031086
 >> iter 12000, loss: 0.029565
 >> iter 13000, loss: 0.039766
 >> iter 14000, loss: 0.032131
 >> iter 15000, loss: 0.127793
 >> iter 16000, loss: 0.065318
 >> iter 17000, loss: 0.042003
 >> iter 18000, loss: 0.034557
 >> iter 19000, loss: 0.030993
 >> iter 20000, loss: 0.029411
   Number of active neurons: 5
 >> iter 21000, loss: 0.039421
 >> iter 22000, loss: 0.031517
 >> iter 23000, loss: 0.029852
 >> iter 24000, loss: 0.027218
 >> iter 25000, loss: 0.027601
 >> iter 26000, loss: 0.025845
 >> iter 27000, loss: 0.139391
 >> iter 28000, loss: 0.101540
 >> iter 29000, loss: 0.061609
 >> iter 30000, loss: 0.039587
   Number of active neurons: 5
 >> iter 31000, loss: 0.257338
 >> iter 32000, loss: 0.114080
 >> iter 33000, loss: 0.061119
 >> iter 34000, loss: 0.040190
 >> iter 35000, loss: 0.032775
 >> iter 36000, loss: 0.028919
 >> iter 37000, loss: 0.028029
 >> iter 38000, loss: 0.026688
 >> iter 39000, loss: 0.041612
 >> iter 40000, loss: 0.038187
   Number of active neurons: 5
 >> iter 41000, loss: 0.037136
 >> iter 42000, loss: 0.103580
 >> iter 43000, loss: 0.064672
 >> iter 44000, loss: 0.051957
 >> iter 45000, loss: 0.035595
 >> iter 46000, loss: 0.109119
 >> iter 47000, loss: 0.057195
 >> iter 48000, loss: 0.038992
 >> iter 49000, loss: 0.031472
 >> iter 50000, loss: 0.028306
   Number of active neurons: 5
 >> iter 51000, loss: 0.042541
 >> iter 52000, loss: 0.032973
 >> iter 53000, loss: 0.033027
 >> iter 54000, loss: 0.029711
 >> iter 55000, loss: 0.129860
 >> iter 56000, loss: 0.066367
 >> iter 57000, loss: 0.041173
 >> iter 58000, loss: 0.032718
 >> iter 59000, loss: 0.028597
 >> iter 60000, loss: 0.027592
   Number of active neurons: 5
 >> iter 61000, loss: 0.031563
 >> iter 62000, loss: 0.048770
 >> iter 63000, loss: 0.116414
 >> iter 64000, loss: 0.062661
 >> iter 65000, loss: 0.039967
 >> iter 66000, loss: 0.034997
 >> iter 67000, loss: 0.104320
 >> iter 68000, loss: 0.057240
 >> iter 69000, loss: 0.038470
 >> iter 70000, loss: 0.076217
   Number of active neurons: 5
 >> iter 71000, loss: 0.044345
 >> iter 72000, loss: 0.034184
 >> iter 73000, loss: 0.108012
 >> iter 74000, loss: 0.074286
 >> iter 75000, loss: 0.129286
 >> iter 76000, loss: 0.079400
 >> iter 77000, loss: 0.047877
 >> iter 78000, loss: 0.037605
 >> iter 79000, loss: 0.030925
 >> iter 80000, loss: 0.221333
   Number of active neurons: 5
 >> iter 81000, loss: 0.101211
 >> iter 82000, loss: 0.057492
 >> iter 83000, loss: 0.039659
 >> iter 84000, loss: 0.034217
 >> iter 85000, loss: 0.047890
 >> iter 86000, loss: 0.038928
 >> iter 87000, loss: 0.046271
 >> iter 88000, loss: 0.037272
 >> iter 89000, loss: 0.051051
 >> iter 90000, loss: 0.038352
   Number of active neurons: 4
 >> iter 91000, loss: 0.052219
 >> iter 92000, loss: 0.038166
 >> iter 93000, loss: 0.045651
 >> iter 94000, loss: 0.035765
 >> iter 95000, loss: 0.068346
 >> iter 96000, loss: 0.044364
 >> iter 97000, loss: 0.306703
 >> iter 98000, loss: 0.134766
 >> iter 99000, loss: 0.067653
 >> iter 100000, loss: 0.044704
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.00599988000241
   - Test - Long: 0.1199940003
   - Test - Big: 0.0449995500045
   - Test - A: 0.0
   - Test - B: 21.49190054
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.846303
 >> iter 2000, loss: 8.678101
 >> iter 3000, loss: 3.260287
 >> iter 4000, loss: 1.239275
 >> iter 5000, loss: 0.487847
 >> iter 6000, loss: 0.208193
 >> iter 7000, loss: 0.103133
 >> iter 8000, loss: 0.065273
 >> iter 9000, loss: 0.048410
 >> iter 10000, loss: 0.113211
   Number of active neurons: 8
 >> iter 11000, loss: 0.063912
 >> iter 12000, loss: 0.081394
 >> iter 13000, loss: 0.054789
 >> iter 14000, loss: 0.042468
 >> iter 15000, loss: 0.042085
 >> iter 16000, loss: 0.036347
 >> iter 17000, loss: 0.048304
 >> iter 18000, loss: 0.039658
 >> iter 19000, loss: 0.123195
 >> iter 20000, loss: 0.066703
   Number of active neurons: 7
 >> iter 21000, loss: 0.048054
 >> iter 22000, loss: 0.040907
 >> iter 23000, loss: 0.036241
 >> iter 24000, loss: 0.035261
 >> iter 25000, loss: 0.174169
 >> iter 26000, loss: 0.092953
 >> iter 27000, loss: 0.054049
 >> iter 28000, loss: 0.110202
 >> iter 29000, loss: 0.220956
 >> iter 30000, loss: 0.104322
   Number of active neurons: 6
 >> iter 31000, loss: 0.114296
 >> iter 32000, loss: 0.078607
 >> iter 33000, loss: 0.052710
 >> iter 34000, loss: 0.050658
 >> iter 35000, loss: 0.037881
 >> iter 36000, loss: 0.039282
 >> iter 37000, loss: 0.162293
 >> iter 38000, loss: 0.080415
 >> iter 39000, loss: 0.108314
 >> iter 40000, loss: 0.069838
   Number of active neurons: 6
 >> iter 41000, loss: 0.102310
 >> iter 42000, loss: 0.072786
 >> iter 43000, loss: 0.103088
 >> iter 44000, loss: 0.075138
 >> iter 45000, loss: 0.105558
 >> iter 46000, loss: 0.064849
 >> iter 47000, loss: 0.107334
 >> iter 48000, loss: 0.064646
 >> iter 49000, loss: 0.111094
 >> iter 50000, loss: 0.064783
   Number of active neurons: 6
 >> iter 51000, loss: 0.097983
 >> iter 52000, loss: 0.057428
 >> iter 53000, loss: 0.093010
 >> iter 54000, loss: 0.054327
 >> iter 55000, loss: 0.090387
 >> iter 56000, loss: 0.052744
 >> iter 57000, loss: 0.077092
 >> iter 58000, loss: 0.047417
 >> iter 59000, loss: 0.035823
 >> iter 60000, loss: 0.030883
   Number of active neurons: 5
 >> iter 61000, loss: 0.028729
 >> iter 62000, loss: 0.027477
 >> iter 63000, loss: 0.026790
 >> iter 64000, loss: 0.026189
 >> iter 65000, loss: 0.025775
 >> iter 66000, loss: 0.025323
 >> iter 67000, loss: 0.025037
 >> iter 68000, loss: 0.024709
 >> iter 69000, loss: 0.024475
 >> iter 70000, loss: 0.024164
   Number of active neurons: 5
 >> iter 71000, loss: 0.023942
 >> iter 72000, loss: 0.023588
 >> iter 73000, loss: 0.023397
 >> iter 74000, loss: 0.023068
 >> iter 75000, loss: 0.022933
 >> iter 76000, loss: 0.022659
 >> iter 77000, loss: 0.022550
 >> iter 78000, loss: 0.022313
 >> iter 79000, loss: 0.022230
 >> iter 80000, loss: 0.021997
   Number of active neurons: 5
 >> iter 81000, loss: 0.021927
 >> iter 82000, loss: 0.021700
 >> iter 83000, loss: 0.021613
 >> iter 84000, loss: 0.021379
 >> iter 85000, loss: 0.021342
 >> iter 86000, loss: 0.021132
 >> iter 87000, loss: 0.021120
 >> iter 88000, loss: 0.020930
 >> iter 89000, loss: 0.020927
 >> iter 90000, loss: 0.020701
   Number of active neurons: 5
 >> iter 91000, loss: 0.020650
 >> iter 92000, loss: 0.020431
 >> iter 93000, loss: 0.020402
 >> iter 94000, loss: 0.020197
 >> iter 95000, loss: 0.020210
 >> iter 96000, loss: 0.019997
 >> iter 97000, loss: 0.020030
 >> iter 98000, loss: 0.019820
 >> iter 99000, loss: 0.019866
 >> iter 100000, loss: 0.019661
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.670227
 >> iter 2000, loss: 7.470779
 >> iter 3000, loss: 2.804296
 >> iter 4000, loss: 1.059512
 >> iter 5000, loss: 0.449130
 >> iter 6000, loss: 0.189912
 >> iter 7000, loss: 0.096359
 >> iter 8000, loss: 0.059454
 >> iter 9000, loss: 0.044598
 >> iter 10000, loss: 0.037564
   Number of active neurons: 8
 >> iter 11000, loss: 0.038336
 >> iter 12000, loss: 0.034527
 >> iter 13000, loss: 0.030834
 >> iter 14000, loss: 0.029421
 >> iter 15000, loss: 0.028664
 >> iter 16000, loss: 0.028100
 >> iter 17000, loss: 0.037553
 >> iter 18000, loss: 0.031959
 >> iter 19000, loss: 0.036811
 >> iter 20000, loss: 0.032178
   Number of active neurons: 7
 >> iter 21000, loss: 0.035473
 >> iter 22000, loss: 0.032813
 >> iter 23000, loss: 0.032940
 >> iter 24000, loss: 0.028901
 >> iter 25000, loss: 0.031963
 >> iter 26000, loss: 0.027479
 >> iter 27000, loss: 0.025880
 >> iter 28000, loss: 0.025648
 >> iter 29000, loss: 0.025946
 >> iter 30000, loss: 0.025456
   Number of active neurons: 6
 >> iter 31000, loss: 0.026085
 >> iter 32000, loss: 0.024999
 >> iter 33000, loss: 0.026047
 >> iter 34000, loss: 0.024996
 >> iter 35000, loss: 0.164763
 >> iter 36000, loss: 0.078328
 >> iter 37000, loss: 0.044767
 >> iter 38000, loss: 0.031616
 >> iter 39000, loss: 0.027795
 >> iter 40000, loss: 0.026186
   Number of active neurons: 5
 >> iter 41000, loss: 0.241044
 >> iter 42000, loss: 0.106671
 >> iter 43000, loss: 0.060032
 >> iter 44000, loss: 0.039837
 >> iter 45000, loss: 0.035397
 >> iter 46000, loss: 0.030820
 >> iter 47000, loss: 0.221842
 >> iter 48000, loss: 0.100251
 >> iter 49000, loss: 0.059411
 >> iter 50000, loss: 0.037402
   Number of active neurons: 5
 >> iter 51000, loss: 0.036003
 >> iter 52000, loss: 0.029499
 >> iter 53000, loss: 0.132905
 >> iter 54000, loss: 0.065595
 >> iter 55000, loss: 0.048001
 >> iter 56000, loss: 0.041018
 >> iter 57000, loss: 0.047170
 >> iter 58000, loss: 0.031719
 >> iter 59000, loss: 0.045611
 >> iter 60000, loss: 0.031963
   Number of active neurons: 5
 >> iter 61000, loss: 0.031417
 >> iter 62000, loss: 0.035665
 >> iter 63000, loss: 0.032201
 >> iter 64000, loss: 0.056198
 >> iter 65000, loss: 0.039071
 >> iter 66000, loss: 0.030585
 >> iter 67000, loss: 0.030949
 >> iter 68000, loss: 0.059037
 >> iter 69000, loss: 0.039218
 >> iter 70000, loss: 0.059520
   Number of active neurons: 5
 >> iter 71000, loss: 0.040430
 >> iter 72000, loss: 0.031245
 >> iter 73000, loss: 0.047895
 >> iter 74000, loss: 0.033238
 >> iter 75000, loss: 0.028100
 >> iter 76000, loss: 0.054264
 >> iter 77000, loss: 0.036291
 >> iter 78000, loss: 0.029012
 >> iter 79000, loss: 0.029541
 >> iter 80000, loss: 0.050340
   Number of active neurons: 5
 >> iter 81000, loss: 0.034063
 >> iter 82000, loss: 0.039563
 >> iter 83000, loss: 0.030650
 >> iter 84000, loss: 0.035684
 >> iter 85000, loss: 0.035654
 >> iter 86000, loss: 0.028153
 >> iter 87000, loss: 0.037561
 >> iter 88000, loss: 0.028488
 >> iter 89000, loss: 0.027977
 >> iter 90000, loss: 0.025246
   Number of active neurons: 5
 >> iter 91000, loss: 0.073912
 >> iter 92000, loss: 0.042258
 >> iter 93000, loss: 0.038276
 >> iter 94000, loss: 0.029181
 >> iter 95000, loss: 0.028100
 >> iter 96000, loss: 0.085983
 >> iter 97000, loss: 0.068881
 >> iter 98000, loss: 0.040878
 >> iter 99000, loss: 0.032538
 >> iter 100000, loss: 0.027344
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 21.4052396507
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.891668
 >> iter 2000, loss: 8.143820
 >> iter 3000, loss: 3.052238
 >> iter 4000, loss: 1.155364
 >> iter 5000, loss: 0.452115
 >> iter 6000, loss: 0.191281
 >> iter 7000, loss: 0.093090
 >> iter 8000, loss: 0.098292
 >> iter 9000, loss: 0.058529
 >> iter 10000, loss: 0.043160
   Number of active neurons: 8
 >> iter 11000, loss: 0.037426
 >> iter 12000, loss: 0.069478
 >> iter 13000, loss: 0.047009
 >> iter 14000, loss: 0.038431
 >> iter 15000, loss: 0.035386
 >> iter 16000, loss: 0.033783
 >> iter 17000, loss: 0.033597
 >> iter 18000, loss: 0.032628
 >> iter 19000, loss: 0.034788
 >> iter 20000, loss: 0.032191
   Number of active neurons: 7
 >> iter 21000, loss: 0.031862
 >> iter 22000, loss: 0.031088
 >> iter 23000, loss: 0.032381
 >> iter 24000, loss: 0.031271
 >> iter 25000, loss: 0.182675
 >> iter 26000, loss: 0.087606
 >> iter 27000, loss: 0.054625
 >> iter 28000, loss: 0.039692
 >> iter 29000, loss: 0.039640
 >> iter 30000, loss: 0.033547
   Number of active neurons: 6
 >> iter 31000, loss: 0.044550
 >> iter 32000, loss: 0.034955
 >> iter 33000, loss: 0.039666
 >> iter 34000, loss: 0.033008
 >> iter 35000, loss: 0.117993
 >> iter 36000, loss: 0.061650
 >> iter 37000, loss: 0.047575
 >> iter 38000, loss: 0.035920
 >> iter 39000, loss: 0.036001
 >> iter 40000, loss: 0.031750
   Number of active neurons: 5
 >> iter 41000, loss: 0.040524
 >> iter 42000, loss: 0.033314
 >> iter 43000, loss: 0.033656
 >> iter 44000, loss: 0.030798
 >> iter 45000, loss: 0.048152
 >> iter 46000, loss: 0.038406
 >> iter 47000, loss: 0.056524
 >> iter 48000, loss: 0.042178
 >> iter 49000, loss: 0.069248
 >> iter 50000, loss: 0.048207
   Number of active neurons: 5
 >> iter 51000, loss: 0.074300
 >> iter 52000, loss: 0.049674
 >> iter 53000, loss: 0.081333
 >> iter 54000, loss: 0.055163
 >> iter 55000, loss: 0.077891
 >> iter 56000, loss: 0.052843
 >> iter 57000, loss: 0.084031
 >> iter 58000, loss: 0.067149
 >> iter 59000, loss: 0.077996
 >> iter 60000, loss: 0.079104
   Number of active neurons: 5
 >> iter 61000, loss: 0.093990
 >> iter 62000, loss: 0.059282
 >> iter 63000, loss: 0.086231
 >> iter 64000, loss: 0.099727
 >> iter 65000, loss: 0.099157
 >> iter 66000, loss: 0.060950
 >> iter 67000, loss: 0.082648
 >> iter 68000, loss: 0.055073
 >> iter 69000, loss: 0.074835
 >> iter 70000, loss: 0.049481
   Number of active neurons: 5
 >> iter 71000, loss: 0.035522
 >> iter 72000, loss: 0.031463
 >> iter 73000, loss: 0.198253
 >> iter 74000, loss: 0.100635
 >> iter 75000, loss: 0.054815
 >> iter 76000, loss: 0.039941
 >> iter 77000, loss: 0.166327
 >> iter 78000, loss: 0.079616
 >> iter 79000, loss: 0.250569
 >> iter 80000, loss: 0.169569
   Number of active neurons: 5
 >> iter 81000, loss: 0.079862
 >> iter 82000, loss: 0.046227
 >> iter 83000, loss: 0.049871
 >> iter 84000, loss: 0.039597
 >> iter 85000, loss: 0.030364
 >> iter 86000, loss: 0.048279
 >> iter 87000, loss: 0.165114
 >> iter 88000, loss: 0.080747
 >> iter 89000, loss: 0.142577
 >> iter 90000, loss: 0.072225
   Number of active neurons: 5
 >> iter 91000, loss: 0.204969
 >> iter 92000, loss: 0.163220
 >> iter 93000, loss: 0.077696
 >> iter 94000, loss: 0.048287
 >> iter 95000, loss: 0.034917
 >> iter 96000, loss: 0.029528
 >> iter 97000, loss: 0.041350
 >> iter 98000, loss: 0.076945
 >> iter 99000, loss: 0.049516
 >> iter 100000, loss: 0.072418
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0039999600004
   - Test - A: 6.43290447304
   - Test - B: 5.37964135724
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.014425
 >> iter 2000, loss: 9.217307
 >> iter 3000, loss: 3.442456
 >> iter 4000, loss: 1.296981
 >> iter 5000, loss: 0.502557
 >> iter 6000, loss: 0.208083
 >> iter 7000, loss: 0.100786
 >> iter 8000, loss: 0.058628
 >> iter 9000, loss: 0.046616
 >> iter 10000, loss: 0.037938
   Number of active neurons: 8
 >> iter 11000, loss: 0.040488
 >> iter 12000, loss: 0.034930
 >> iter 13000, loss: 0.038336
 >> iter 14000, loss: 0.038438
 >> iter 15000, loss: 0.033292
 >> iter 16000, loss: 0.032725
 >> iter 17000, loss: 0.031343
 >> iter 18000, loss: 0.042075
 >> iter 19000, loss: 0.034689
 >> iter 20000, loss: 0.103357
   Number of active neurons: 8
 >> iter 21000, loss: 0.058839
 >> iter 22000, loss: 0.130869
 >> iter 23000, loss: 0.185624
 >> iter 24000, loss: 0.113928
 >> iter 25000, loss: 0.065679
 >> iter 26000, loss: 0.047735
 >> iter 27000, loss: 0.038544
 >> iter 28000, loss: 0.034776
 >> iter 29000, loss: 0.032827
 >> iter 30000, loss: 0.031707
   Number of active neurons: 6
 >> iter 31000, loss: 0.031194
 >> iter 32000, loss: 0.030404
 >> iter 33000, loss: 0.030012
 >> iter 34000, loss: 0.029329
 >> iter 35000, loss: 0.028960
 >> iter 36000, loss: 0.028449
 >> iter 37000, loss: 0.028323
 >> iter 38000, loss: 0.027839
 >> iter 39000, loss: 0.027862
 >> iter 40000, loss: 0.027395
   Number of active neurons: 5
 >> iter 41000, loss: 0.027501
 >> iter 42000, loss: 0.027062
 >> iter 43000, loss: 0.027206
 >> iter 44000, loss: 0.026807
 >> iter 45000, loss: 0.026970
 >> iter 46000, loss: 0.026572
 >> iter 47000, loss: 0.026716
 >> iter 48000, loss: 0.026376
 >> iter 49000, loss: 0.026489
 >> iter 50000, loss: 0.026151
   Number of active neurons: 6
 >> iter 51000, loss: 0.026229
 >> iter 52000, loss: 0.025936
 >> iter 53000, loss: 0.025991
 >> iter 54000, loss: 0.025718
 >> iter 55000, loss: 0.025780
 >> iter 56000, loss: 0.025491
 >> iter 57000, loss: 0.025549
 >> iter 58000, loss: 0.025295
 >> iter 59000, loss: 0.025373
 >> iter 60000, loss: 0.025157
   Number of active neurons: 6
 >> iter 61000, loss: 0.025256
 >> iter 62000, loss: 0.025026
 >> iter 63000, loss: 0.025154
 >> iter 64000, loss: 0.024943
 >> iter 65000, loss: 0.025067
 >> iter 66000, loss: 0.024865
 >> iter 67000, loss: 0.024988
 >> iter 68000, loss: 0.024790
 >> iter 69000, loss: 0.024895
 >> iter 70000, loss: 0.024710
   Number of active neurons: 6
 >> iter 71000, loss: 0.024836
 >> iter 72000, loss: 0.024626
 >> iter 73000, loss: 0.024770
 >> iter 74000, loss: 0.024558
 >> iter 75000, loss: 0.024708
 >> iter 76000, loss: 0.024522
 >> iter 77000, loss: 0.024650
 >> iter 78000, loss: 0.024458
 >> iter 79000, loss: 0.024596
 >> iter 80000, loss: 0.024396
   Number of active neurons: 6
 >> iter 81000, loss: 0.024534
 >> iter 82000, loss: 0.024353
 >> iter 83000, loss: 0.024490
 >> iter 84000, loss: 0.024303
 >> iter 85000, loss: 0.024458
 >> iter 86000, loss: 0.024273
 >> iter 87000, loss: 0.024393
 >> iter 88000, loss: 0.024206
 >> iter 89000, loss: 0.024272
 >> iter 90000, loss: 0.024107
   Number of active neurons: 6
 >> iter 91000, loss: 0.024180
 >> iter 92000, loss: 0.024039
 >> iter 93000, loss: 0.024130
 >> iter 94000, loss: 0.023993
 >> iter 95000, loss: 0.024120
 >> iter 96000, loss: 0.023952
 >> iter 97000, loss: 0.024080
 >> iter 98000, loss: 0.023916
 >> iter 99000, loss: 0.024065
 >> iter 100000, loss: 0.023891
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 1.13325778281
   - Test - B: 16.5122325178
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.779332
 >> iter 2000, loss: 7.932589
 >> iter 3000, loss: 2.965926
 >> iter 4000, loss: 1.151759
 >> iter 5000, loss: 0.449639
 >> iter 6000, loss: 0.188420
 >> iter 7000, loss: 0.091345
 >> iter 8000, loss: 0.054107
 >> iter 9000, loss: 0.040101
 >> iter 10000, loss: 0.131934
   Number of active neurons: 8
 >> iter 11000, loss: 0.172011
 >> iter 12000, loss: 0.085229
 >> iter 13000, loss: 0.051606
 >> iter 14000, loss: 0.039097
 >> iter 15000, loss: 0.044666
 >> iter 16000, loss: 0.036280
 >> iter 17000, loss: 0.033558
 >> iter 18000, loss: 0.037728
 >> iter 19000, loss: 0.037731
 >> iter 20000, loss: 0.047672
   Number of active neurons: 7
 >> iter 21000, loss: 0.038000
 >> iter 22000, loss: 0.040782
 >> iter 23000, loss: 0.090204
 >> iter 24000, loss: 0.052233
 >> iter 25000, loss: 0.093067
 >> iter 26000, loss: 0.053099
 >> iter 27000, loss: 0.107124
 >> iter 28000, loss: 0.058211
 >> iter 29000, loss: 0.086757
 >> iter 30000, loss: 0.049955
   Number of active neurons: 6
 >> iter 31000, loss: 0.094225
 >> iter 32000, loss: 0.053398
 >> iter 33000, loss: 0.072372
 >> iter 34000, loss: 0.044697
 >> iter 35000, loss: 0.135052
 >> iter 36000, loss: 0.067933
 >> iter 37000, loss: 0.049528
 >> iter 38000, loss: 0.035997
 >> iter 39000, loss: 0.038560
 >> iter 40000, loss: 0.031860
   Number of active neurons: 6
 >> iter 41000, loss: 0.037246
 >> iter 42000, loss: 0.031098
 >> iter 43000, loss: 0.103973
 >> iter 44000, loss: 0.056548
 >> iter 45000, loss: 0.042009
 >> iter 46000, loss: 0.032944
 >> iter 47000, loss: 0.186860
 >> iter 48000, loss: 0.087768
 >> iter 49000, loss: 0.105905
 >> iter 50000, loss: 0.058194
   Number of active neurons: 6
 >> iter 51000, loss: 0.254310
 >> iter 52000, loss: 0.115936
 >> iter 53000, loss: 0.135619
 >> iter 54000, loss: 0.072021
 >> iter 55000, loss: 0.102728
 >> iter 56000, loss: 0.059387
 >> iter 57000, loss: 0.098127
 >> iter 58000, loss: 0.057411
 >> iter 59000, loss: 0.255973
 >> iter 60000, loss: 0.118881
   Number of active neurons: 6
 >> iter 61000, loss: 0.070651
 >> iter 62000, loss: 0.047476
 >> iter 63000, loss: 0.041799
 >> iter 64000, loss: 0.035609
 >> iter 65000, loss: 0.196061
 >> iter 66000, loss: 0.094107
 >> iter 67000, loss: 0.114843
 >> iter 68000, loss: 0.064178
 >> iter 69000, loss: 0.165204
 >> iter 70000, loss: 0.083099
   Number of active neurons: 6
 >> iter 71000, loss: 0.061438
 >> iter 72000, loss: 0.042573
 >> iter 73000, loss: 0.100395
 >> iter 74000, loss: 0.057490
 >> iter 75000, loss: 0.151561
 >> iter 76000, loss: 0.076745
 >> iter 77000, loss: 0.110705
 >> iter 78000, loss: 0.063184
 >> iter 79000, loss: 0.095242
 >> iter 80000, loss: 0.054587
   Number of active neurons: 6
 >> iter 81000, loss: 0.099873
 >> iter 82000, loss: 0.056524
 >> iter 83000, loss: 0.042172
 >> iter 84000, loss: 0.034326
 >> iter 85000, loss: 0.038656
 >> iter 86000, loss: 0.032851
 >> iter 87000, loss: 0.030685
 >> iter 88000, loss: 0.029580
 >> iter 89000, loss: 0.029016
 >> iter 90000, loss: 0.028743
   Number of active neurons: 6
 >> iter 91000, loss: 0.028471
 >> iter 92000, loss: 0.028373
 >> iter 93000, loss: 0.028174
 >> iter 94000, loss: 0.028105
 >> iter 95000, loss: 0.027994
 >> iter 96000, loss: 0.027871
 >> iter 97000, loss: 0.027778
 >> iter 98000, loss: 0.027606
 >> iter 99000, loss: 0.027508
 >> iter 100000, loss: 0.027289
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 16.3522431838
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.056477
 >> iter 2000, loss: 8.708910
 >> iter 3000, loss: 3.263744
 >> iter 4000, loss: 1.230920
 >> iter 5000, loss: 0.712940
 >> iter 6000, loss: 0.288293
 >> iter 7000, loss: 0.129452
 >> iter 8000, loss: 0.069833
 >> iter 9000, loss: 0.047710
 >> iter 10000, loss: 0.038844
   Number of active neurons: 9
 >> iter 11000, loss: 0.035555
 >> iter 12000, loss: 0.035566
 >> iter 13000, loss: 0.125097
 >> iter 14000, loss: 0.066372
 >> iter 15000, loss: 0.045583
 >> iter 16000, loss: 0.038802
 >> iter 17000, loss: 0.139803
 >> iter 18000, loss: 0.071572
 >> iter 19000, loss: 0.047118
 >> iter 20000, loss: 0.038815
   Number of active neurons: 8
 >> iter 21000, loss: 0.034733
 >> iter 22000, loss: 0.033911
 >> iter 23000, loss: 0.161360
 >> iter 24000, loss: 0.202438
 >> iter 25000, loss: 0.095647
 >> iter 26000, loss: 0.055185
 >> iter 27000, loss: 0.040296
 >> iter 28000, loss: 0.034392
 >> iter 29000, loss: 0.031781
 >> iter 30000, loss: 0.031053
   Number of active neurons: 8
 >> iter 31000, loss: 0.030347
 >> iter 32000, loss: 0.030527
 >> iter 33000, loss: 0.056432
 >> iter 34000, loss: 0.039694
 >> iter 35000, loss: 0.034040
 >> iter 36000, loss: 0.106463
 >> iter 37000, loss: 0.057607
 >> iter 38000, loss: 0.040356
 >> iter 39000, loss: 0.033437
 >> iter 40000, loss: 0.105890
   Number of active neurons: 7
 >> iter 41000, loss: 0.057916
 >> iter 42000, loss: 0.041554
 >> iter 43000, loss: 0.033991
 >> iter 44000, loss: 0.185744
 >> iter 45000, loss: 0.088649
 >> iter 46000, loss: 0.053758
 >> iter 47000, loss: 0.039043
 >> iter 48000, loss: 0.034523
 >> iter 49000, loss: 0.032275
 >> iter 50000, loss: 0.031535
   Number of active neurons: 7
 >> iter 51000, loss: 0.032430
 >> iter 52000, loss: 0.053700
 >> iter 53000, loss: 0.037037
 >> iter 54000, loss: 0.033155
 >> iter 55000, loss: 0.030431
 >> iter 56000, loss: 0.059476
 >> iter 57000, loss: 0.040224
 >> iter 58000, loss: 0.062230
 >> iter 59000, loss: 0.041689
 >> iter 60000, loss: 0.046543
   Number of active neurons: 7
 >> iter 61000, loss: 0.035733
 >> iter 62000, loss: 0.057706
 >> iter 63000, loss: 0.039971
 >> iter 64000, loss: 0.034189
 >> iter 65000, loss: 0.042266
 >> iter 66000, loss: 0.038186
 >> iter 67000, loss: 0.068092
 >> iter 68000, loss: 0.045967
 >> iter 69000, loss: 0.057665
 >> iter 70000, loss: 0.070947
   Number of active neurons: 7
 >> iter 71000, loss: 0.043852
 >> iter 72000, loss: 0.036214
 >> iter 73000, loss: 0.042556
 >> iter 74000, loss: 0.039347
 >> iter 75000, loss: 0.045964
 >> iter 76000, loss: 0.041191
 >> iter 77000, loss: 0.047428
 >> iter 78000, loss: 0.040434
 >> iter 79000, loss: 0.058517
 >> iter 80000, loss: 0.044472
   Number of active neurons: 7
 >> iter 81000, loss: 0.061801
 >> iter 82000, loss: 0.043999
 >> iter 83000, loss: 0.061563
 >> iter 84000, loss: 0.045132
 >> iter 85000, loss: 0.073573
 >> iter 86000, loss: 0.047670
 >> iter 87000, loss: 0.042426
 >> iter 88000, loss: 0.057081
 >> iter 89000, loss: 0.046417
 >> iter 90000, loss: 0.039705
   Number of active neurons: 7
 >> iter 91000, loss: 0.067875
 >> iter 92000, loss: 0.047207
 >> iter 93000, loss: 0.049291
 >> iter 94000, loss: 0.039814
 >> iter 95000, loss: 0.061737
 >> iter 96000, loss: 0.045154
 >> iter 97000, loss: 0.035112
 >> iter 98000, loss: 0.034902
 >> iter 99000, loss: 0.037435
 >> iter 100000, loss: 0.036578
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 21.6652223185
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.883714
 >> iter 2000, loss: 8.512008
 >> iter 3000, loss: 3.182122
 >> iter 4000, loss: 1.199777
 >> iter 5000, loss: 0.468640
 >> iter 6000, loss: 0.193122
 >> iter 7000, loss: 0.092064
 >> iter 8000, loss: 0.052591
 >> iter 9000, loss: 0.039305
 >> iter 10000, loss: 0.032485
   Number of active neurons: 6
 >> iter 11000, loss: 0.031556
 >> iter 12000, loss: 0.033735
 >> iter 13000, loss: 0.031615
 >> iter 14000, loss: 0.027894
 >> iter 15000, loss: 0.031871
 >> iter 16000, loss: 0.028137
 >> iter 17000, loss: 0.026982
 >> iter 18000, loss: 0.026193
 >> iter 19000, loss: 0.026089
 >> iter 20000, loss: 0.025766
   Number of active neurons: 6
 >> iter 21000, loss: 0.025635
 >> iter 22000, loss: 0.025506
 >> iter 23000, loss: 0.025279
 >> iter 24000, loss: 0.024938
 >> iter 25000, loss: 0.025718
 >> iter 26000, loss: 0.024961
 >> iter 27000, loss: 0.030075
 >> iter 28000, loss: 0.084906
 >> iter 29000, loss: 0.050012
 >> iter 30000, loss: 0.035600
   Number of active neurons: 6
 >> iter 31000, loss: 0.034812
 >> iter 32000, loss: 0.028755
 >> iter 33000, loss: 0.031670
 >> iter 34000, loss: 0.027705
 >> iter 35000, loss: 0.030719
 >> iter 36000, loss: 0.027010
 >> iter 37000, loss: 0.028862
 >> iter 38000, loss: 0.025609
 >> iter 39000, loss: 0.026527
 >> iter 40000, loss: 0.024165
   Number of active neurons: 6
 >> iter 41000, loss: 0.026078
 >> iter 42000, loss: 0.023971
 >> iter 43000, loss: 0.026016
 >> iter 44000, loss: 0.043344
 >> iter 45000, loss: 0.037069
 >> iter 46000, loss: 0.028711
 >> iter 47000, loss: 0.025810
 >> iter 48000, loss: 0.034787
 >> iter 49000, loss: 0.031629
 >> iter 50000, loss: 0.027010
   Number of active neurons: 6
 >> iter 51000, loss: 0.028066
 >> iter 52000, loss: 0.061859
 >> iter 53000, loss: 0.038098
 >> iter 54000, loss: 0.062169
 >> iter 55000, loss: 0.039494
 >> iter 56000, loss: 0.073394
 >> iter 57000, loss: 0.043930
 >> iter 58000, loss: 0.034832
 >> iter 59000, loss: 0.034674
 >> iter 60000, loss: 0.032028
   Number of active neurons: 5
 >> iter 61000, loss: 0.033411
 >> iter 62000, loss: 0.031059
 >> iter 63000, loss: 0.033903
 >> iter 64000, loss: 0.032581
 >> iter 65000, loss: 0.034236
 >> iter 66000, loss: 0.156746
 >> iter 67000, loss: 0.085023
 >> iter 68000, loss: 0.063272
 >> iter 69000, loss: 0.044674
 >> iter 70000, loss: 0.033671
   Number of active neurons: 5
 >> iter 71000, loss: 0.033645
 >> iter 72000, loss: 0.029306
 >> iter 73000, loss: 0.032821
 >> iter 74000, loss: 0.028802
 >> iter 75000, loss: 0.034025
 >> iter 76000, loss: 0.029197
 >> iter 77000, loss: 0.032988
 >> iter 78000, loss: 0.110410
 >> iter 79000, loss: 0.087326
 >> iter 80000, loss: 0.048990
   Number of active neurons: 5
 >> iter 81000, loss: 0.041752
 >> iter 82000, loss: 0.030962
 >> iter 83000, loss: 0.059023
 >> iter 84000, loss: 0.037695
 >> iter 85000, loss: 0.029133
 >> iter 86000, loss: 0.037101
 >> iter 87000, loss: 0.033741
 >> iter 88000, loss: 0.027410
 >> iter 89000, loss: 0.030386
 >> iter 90000, loss: 0.026243
   Number of active neurons: 5
 >> iter 91000, loss: 0.050848
 >> iter 92000, loss: 0.033673
 >> iter 93000, loss: 0.035009
 >> iter 94000, loss: 0.027824
 >> iter 95000, loss: 0.048849
 >> iter 96000, loss: 0.032554
 >> iter 97000, loss: 0.047608
 >> iter 98000, loss: 0.032222
 >> iter 99000, loss: 0.028560
 >> iter 100000, loss: 0.025313
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 21.3852409839
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.370684
 >> iter 2000, loss: 7.702775
 >> iter 3000, loss: 2.985170
 >> iter 4000, loss: 1.135022
 >> iter 5000, loss: 0.499526
 >> iter 6000, loss: 0.209162
 >> iter 7000, loss: 0.098373
 >> iter 8000, loss: 0.058853
 >> iter 9000, loss: 0.040848
 >> iter 10000, loss: 0.035763
   Number of active neurons: 7
 >> iter 11000, loss: 0.031021
 >> iter 12000, loss: 0.030260
 >> iter 13000, loss: 0.028293
 >> iter 14000, loss: 0.028248
 >> iter 15000, loss: 0.027037
 >> iter 16000, loss: 0.027053
 >> iter 17000, loss: 0.026162
 >> iter 18000, loss: 0.025791
 >> iter 19000, loss: 0.025552
 >> iter 20000, loss: 0.025430
   Number of active neurons: 6
 >> iter 21000, loss: 0.025322
 >> iter 22000, loss: 0.025343
 >> iter 23000, loss: 0.025284
 >> iter 24000, loss: 0.025365
 >> iter 25000, loss: 0.025341
 >> iter 26000, loss: 0.025355
 >> iter 27000, loss: 0.025666
 >> iter 28000, loss: 0.025466
 >> iter 29000, loss: 0.025907
 >> iter 30000, loss: 0.025465
   Number of active neurons: 6
 >> iter 31000, loss: 0.026161
 >> iter 32000, loss: 0.025430
 >> iter 33000, loss: 0.025375
 >> iter 34000, loss: 0.025016
 >> iter 35000, loss: 0.042572
 >> iter 36000, loss: 0.030956
 >> iter 37000, loss: 0.030128
 >> iter 38000, loss: 0.026606
 >> iter 39000, loss: 0.042180
 >> iter 40000, loss: 0.032269
   Number of active neurons: 6
 >> iter 41000, loss: 0.044525
 >> iter 42000, loss: 0.033248
 >> iter 43000, loss: 0.034098
 >> iter 44000, loss: 0.029199
 >> iter 45000, loss: 0.028359
 >> iter 46000, loss: 0.026372
 >> iter 47000, loss: 0.029398
 >> iter 48000, loss: 0.026518
 >> iter 49000, loss: 0.047573
 >> iter 50000, loss: 0.035143
   Number of active neurons: 6
 >> iter 51000, loss: 0.027929
 >> iter 52000, loss: 0.025977
 >> iter 53000, loss: 0.150809
 >> iter 54000, loss: 0.139757
 >> iter 55000, loss: 0.068288
 >> iter 56000, loss: 0.042811
 >> iter 57000, loss: 0.033100
 >> iter 58000, loss: 0.027840
 >> iter 59000, loss: 0.025810
 >> iter 60000, loss: 0.025237
   Number of active neurons: 6
 >> iter 61000, loss: 0.024747
 >> iter 62000, loss: 0.024562
 >> iter 63000, loss: 0.024370
 >> iter 64000, loss: 0.024357
 >> iter 65000, loss: 0.024517
 >> iter 66000, loss: 0.024331
 >> iter 67000, loss: 0.024211
 >> iter 68000, loss: 0.024439
 >> iter 69000, loss: 0.024010
 >> iter 70000, loss: 0.024287
   Number of active neurons: 6
 >> iter 71000, loss: 0.024199
 >> iter 72000, loss: 0.024334
 >> iter 73000, loss: 0.023861
 >> iter 74000, loss: 0.024440
 >> iter 75000, loss: 0.024068
 >> iter 76000, loss: 0.024460
 >> iter 77000, loss: 0.023870
 >> iter 78000, loss: 0.024422
 >> iter 79000, loss: 0.024286
 >> iter 80000, loss: 0.024314
   Number of active neurons: 6
 >> iter 81000, loss: 0.023775
 >> iter 82000, loss: 0.024490
 >> iter 83000, loss: 0.023839
 >> iter 84000, loss: 0.024269
 >> iter 85000, loss: 0.024026
 >> iter 86000, loss: 0.024306
 >> iter 87000, loss: 0.023743
 >> iter 88000, loss: 0.024480
 >> iter 89000, loss: 0.023861
 >> iter 90000, loss: 0.024369
   Number of active neurons: 6
 >> iter 91000, loss: 0.023791
 >> iter 92000, loss: 0.024255
 >> iter 93000, loss: 0.023716
 >> iter 94000, loss: 0.024228
 >> iter 95000, loss: 0.023735
 >> iter 96000, loss: 0.024228
 >> iter 97000, loss: 0.023765
 >> iter 98000, loss: 0.024460
 >> iter 99000, loss: 0.023876
 >> iter 100000, loss: 0.024698
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.019999600008
   - Test - Long: 0.0
   - Test - Big: 0.0049999500005
   - Test - A: 0.0
   - Test - B: 14.7990133991
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.695104
 >> iter 2000, loss: 7.646560
 >> iter 3000, loss: 2.903484
 >> iter 4000, loss: 1.098273
 >> iter 5000, loss: 0.456280
 >> iter 6000, loss: 0.190304
 >> iter 7000, loss: 0.093139
 >> iter 8000, loss: 0.054293
 >> iter 9000, loss: 0.041262
 >> iter 10000, loss: 0.034293
   Number of active neurons: 8
 >> iter 11000, loss: 0.080216
 >> iter 12000, loss: 0.049480
 >> iter 13000, loss: 0.083542
 >> iter 14000, loss: 0.050923
 >> iter 15000, loss: 0.092412
 >> iter 16000, loss: 0.053580
 >> iter 17000, loss: 0.427132
 >> iter 18000, loss: 0.184118
 >> iter 19000, loss: 0.113037
 >> iter 20000, loss: 0.060954
   Number of active neurons: 7
 >> iter 21000, loss: 0.129303
 >> iter 22000, loss: 0.066880
 >> iter 23000, loss: 0.054142
 >> iter 24000, loss: 0.037982
 >> iter 25000, loss: 0.071620
 >> iter 26000, loss: 0.044626
 >> iter 27000, loss: 0.225800
 >> iter 28000, loss: 0.104721
 >> iter 29000, loss: 0.060188
 >> iter 30000, loss: 0.043978
   Number of active neurons: 7
 >> iter 31000, loss: 0.038100
 >> iter 32000, loss: 0.034748
 >> iter 33000, loss: 0.252298
 >> iter 34000, loss: 0.116411
 >> iter 35000, loss: 0.093809
 >> iter 36000, loss: 0.055140
 >> iter 37000, loss: 0.064219
 >> iter 38000, loss: 0.044157
 >> iter 39000, loss: 0.041106
 >> iter 40000, loss: 0.035392
   Number of active neurons: 7
 >> iter 41000, loss: 0.034739
 >> iter 42000, loss: 0.034473
 >> iter 43000, loss: 0.038645
 >> iter 44000, loss: 0.036283
 >> iter 45000, loss: 0.173749
 >> iter 46000, loss: 0.085225
 >> iter 47000, loss: 0.055487
 >> iter 48000, loss: 0.041875
 >> iter 49000, loss: 0.070049
 >> iter 50000, loss: 0.046746
   Number of active neurons: 6
 >> iter 51000, loss: 0.041880
 >> iter 52000, loss: 0.036385
 >> iter 53000, loss: 0.033335
 >> iter 54000, loss: 0.034085
 >> iter 55000, loss: 0.042160
 >> iter 56000, loss: 0.038825
 >> iter 57000, loss: 0.042523
 >> iter 58000, loss: 0.036577
 >> iter 59000, loss: 0.041707
 >> iter 60000, loss: 0.055768
   Number of active neurons: 5
 >> iter 61000, loss: 0.048549
 >> iter 62000, loss: 0.108331
 >> iter 63000, loss: 0.104001
 >> iter 64000, loss: 0.056606
 >> iter 65000, loss: 0.051151
 >> iter 66000, loss: 0.036528
 >> iter 67000, loss: 0.042693
 >> iter 68000, loss: 0.043455
 >> iter 69000, loss: 0.152117
 >> iter 70000, loss: 0.081299
   Number of active neurons: 5
 >> iter 71000, loss: 0.048002
 >> iter 72000, loss: 0.230223
 >> iter 73000, loss: 0.357326
 >> iter 74000, loss: 0.158783
 >> iter 75000, loss: 0.078575
 >> iter 76000, loss: 0.050100
 >> iter 77000, loss: 0.149445
 >> iter 78000, loss: 0.079103
 >> iter 79000, loss: 0.047226
 >> iter 80000, loss: 0.041592
   Number of active neurons: 5
 >> iter 81000, loss: 0.067329
 >> iter 82000, loss: 0.047682
 >> iter 83000, loss: 0.043620
 >> iter 84000, loss: 0.048054
 >> iter 85000, loss: 0.144936
 >> iter 86000, loss: 0.076008
 >> iter 87000, loss: 0.052971
 >> iter 88000, loss: 0.044442
 >> iter 89000, loss: 0.204088
 >> iter 90000, loss: 0.107819
   Number of active neurons: 5
 >> iter 91000, loss: 0.087458
 >> iter 92000, loss: 0.057130
 >> iter 93000, loss: 0.069240
 >> iter 94000, loss: 0.047409
 >> iter 95000, loss: 0.085452
 >> iter 96000, loss: 0.052328
 >> iter 97000, loss: 0.295020
 >> iter 98000, loss: 0.130593
 >> iter 99000, loss: 0.183782
 >> iter 100000, loss: 0.089804
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00599994000061
   - Test - A: 7.33951069929
   - Test - B: 20.8919405373

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

