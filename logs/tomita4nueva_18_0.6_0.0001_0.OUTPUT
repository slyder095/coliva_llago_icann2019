 > Problema: tomita4nueva
 > Args:
   - Hidden size: 18
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.247735
 >> iter 2000, loss: 8.494665
 >> iter 3000, loss: 3.804337
 >> iter 4000, loss: 1.796337
 >> iter 5000, loss: 1.199178
 >> iter 6000, loss: 0.818989
 >> iter 7000, loss: 0.590611
 >> iter 8000, loss: 0.457162
 >> iter 9000, loss: 0.257569
 >> iter 10000, loss: 0.375895
   Number of active neurons: 5
 >> iter 11000, loss: 0.339671
 >> iter 12000, loss: 0.324887
 >> iter 13000, loss: 0.247452
 >> iter 14000, loss: 0.385851
 >> iter 15000, loss: 0.333633
 >> iter 16000, loss: 0.348595
 >> iter 17000, loss: 0.500505
 >> iter 18000, loss: 0.512011
 >> iter 19000, loss: 0.277271
 >> iter 20000, loss: 0.289393
   Number of active neurons: 4
 >> iter 21000, loss: 0.238724
 >> iter 22000, loss: 0.261890
 >> iter 23000, loss: 0.219225
 >> iter 24000, loss: 0.335328
 >> iter 25000, loss: 0.356758
 >> iter 26000, loss: 0.421652
 >> iter 27000, loss: 0.368878
 >> iter 28000, loss: 0.282474
 >> iter 29000, loss: 0.279602
 >> iter 30000, loss: 0.397598
   Number of active neurons: 4
 >> iter 31000, loss: 0.382496
 >> iter 32000, loss: 0.341821
 >> iter 33000, loss: 0.203470
 >> iter 34000, loss: 0.285062
 >> iter 35000, loss: 0.296569
 >> iter 36000, loss: 0.169461
 >> iter 37000, loss: 0.120434
 >> iter 38000, loss: 0.119742
 >> iter 39000, loss: 0.471756
 >> iter 40000, loss: 0.251991
   Number of active neurons: 4
 >> iter 41000, loss: 0.245614
 >> iter 42000, loss: 0.462631
 >> iter 43000, loss: 0.357757
 >> iter 44000, loss: 0.287931
 >> iter 45000, loss: 0.185680
 >> iter 46000, loss: 0.263282
 >> iter 47000, loss: 0.209932
 >> iter 48000, loss: 0.275085
 >> iter 49000, loss: 0.300338
 >> iter 50000, loss: 0.228325
   Number of active neurons: 4
 >> iter 51000, loss: 0.211253
 >> iter 52000, loss: 0.253400
 >> iter 53000, loss: 0.226289
 >> iter 54000, loss: 0.279906
 >> iter 55000, loss: 0.206125
 >> iter 56000, loss: 0.231991
 >> iter 57000, loss: 0.201553
 >> iter 58000, loss: 0.253105
 >> iter 59000, loss: 0.323942
 >> iter 60000, loss: 0.274918
   Number of active neurons: 4
 >> iter 61000, loss: 0.337595
 >> iter 62000, loss: 0.169666
 >> iter 63000, loss: 0.377760
 >> iter 64000, loss: 0.320397
 >> iter 65000, loss: 0.210672
 >> iter 66000, loss: 0.133357
 >> iter 67000, loss: 0.272809
 >> iter 68000, loss: 0.133849
 >> iter 69000, loss: 0.327024
 >> iter 70000, loss: 0.285654
   Number of active neurons: 4
 >> iter 71000, loss: 0.295281
 >> iter 72000, loss: 0.282168
 >> iter 73000, loss: 0.324132
 >> iter 74000, loss: 0.376958
 >> iter 75000, loss: 0.222694
 >> iter 76000, loss: 0.254185
 >> iter 77000, loss: 0.230816
 >> iter 78000, loss: 0.192994
 >> iter 79000, loss: 0.261773
 >> iter 80000, loss: 0.266098
   Number of active neurons: 4
 >> iter 81000, loss: 0.309209
 >> iter 82000, loss: 0.236620
 >> iter 83000, loss: 0.226935
 >> iter 84000, loss: 0.142571
 >> iter 85000, loss: 0.211429
 >> iter 86000, loss: 0.303168
 >> iter 87000, loss: 0.192267
 >> iter 88000, loss: 0.150730
 >> iter 89000, loss: 0.358250
 >> iter 90000, loss: 0.263888
   Number of active neurons: 3
 >> iter 91000, loss: 0.141488
 >> iter 92000, loss: 0.130212
 >> iter 93000, loss: 0.227217
 >> iter 94000, loss: 0.176674
 >> iter 95000, loss: 0.278820
 >> iter 96000, loss: 0.165214
 >> iter 97000, loss: 0.347354
 >> iter 98000, loss: 0.187823
 >> iter 99000, loss: 0.193798
 >> iter 100000, loss: 0.464730
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.695812
 >> iter 2000, loss: 9.083346
 >> iter 3000, loss: 4.275548
 >> iter 4000, loss: 2.113142
 >> iter 5000, loss: 1.146714
 >> iter 6000, loss: 0.864219
 >> iter 7000, loss: 0.560675
 >> iter 8000, loss: 0.579266
 >> iter 9000, loss: 0.403428
 >> iter 10000, loss: 0.381830
   Number of active neurons: 5
 >> iter 11000, loss: 0.364307
 >> iter 12000, loss: 0.543697
 >> iter 13000, loss: 0.504034
 >> iter 14000, loss: 0.298703
 >> iter 15000, loss: 0.278719
 >> iter 16000, loss: 0.313376
 >> iter 17000, loss: 0.222949
 >> iter 18000, loss: 0.240673
 >> iter 19000, loss: 0.238707
 >> iter 20000, loss: 0.348433
   Number of active neurons: 5
 >> iter 21000, loss: 0.416064
 >> iter 22000, loss: 0.438311
 >> iter 23000, loss: 0.271455
 >> iter 24000, loss: 0.302192
 >> iter 25000, loss: 0.210520
 >> iter 26000, loss: 0.241354
 >> iter 27000, loss: 0.239526
 >> iter 28000, loss: 0.245981
 >> iter 29000, loss: 0.262163
 >> iter 30000, loss: 0.459207
   Number of active neurons: 5
 >> iter 31000, loss: 0.430511
 >> iter 32000, loss: 0.214844
 >> iter 33000, loss: 0.356165
 >> iter 34000, loss: 0.319246
 >> iter 35000, loss: 0.474030
 >> iter 36000, loss: 0.341211
 >> iter 37000, loss: 0.310108
 >> iter 38000, loss: 0.202569
 >> iter 39000, loss: 0.411344
 >> iter 40000, loss: 0.342611
   Number of active neurons: 5
 >> iter 41000, loss: 0.314098
 >> iter 42000, loss: 0.251823
 >> iter 43000, loss: 0.318814
 >> iter 44000, loss: 0.238449
 >> iter 45000, loss: 0.297888
 >> iter 46000, loss: 0.253970
 >> iter 47000, loss: 0.362392
 >> iter 48000, loss: 0.656173
 >> iter 49000, loss: 0.487837
 >> iter 50000, loss: 0.278154
   Number of active neurons: 4
 >> iter 51000, loss: 0.157395
 >> iter 52000, loss: 0.500529
 >> iter 53000, loss: 0.276254
 >> iter 54000, loss: 0.275724
 >> iter 55000, loss: 0.291921
 >> iter 56000, loss: 0.202448
 >> iter 57000, loss: 0.210807
 >> iter 58000, loss: 0.182830
 >> iter 59000, loss: 0.205728
 >> iter 60000, loss: 0.166387
   Number of active neurons: 3
 >> iter 61000, loss: 0.245293
 >> iter 62000, loss: 0.207658
 >> iter 63000, loss: 0.264682
 >> iter 64000, loss: 0.471762
 >> iter 65000, loss: 0.339500
 >> iter 66000, loss: 0.189322
 >> iter 67000, loss: 0.688719
 >> iter 68000, loss: 0.324211
 >> iter 69000, loss: 0.320738
 >> iter 70000, loss: 0.274555
   Number of active neurons: 3
 >> iter 71000, loss: 0.139552
 >> iter 72000, loss: 0.227660
 >> iter 73000, loss: 0.189454
 >> iter 74000, loss: 0.209386
 >> iter 75000, loss: 0.198125
 >> iter 76000, loss: 0.192878
 >> iter 77000, loss: 0.232516
 >> iter 78000, loss: 0.123449
 >> iter 79000, loss: 0.317563
 >> iter 80000, loss: 0.356204
   Number of active neurons: 3
 >> iter 81000, loss: 0.307033
 >> iter 82000, loss: 0.344322
 >> iter 83000, loss: 0.232365
 >> iter 84000, loss: 0.460807
 >> iter 85000, loss: 0.572923
 >> iter 86000, loss: 0.456512
 >> iter 87000, loss: 0.242231
 >> iter 88000, loss: 0.173801
 >> iter 89000, loss: 0.237510
 >> iter 90000, loss: 0.197427
   Number of active neurons: 3
 >> iter 91000, loss: 0.274115
 >> iter 92000, loss: 0.315442
 >> iter 93000, loss: 0.148984
 >> iter 94000, loss: 0.131481
 >> iter 95000, loss: 0.372760
 >> iter 96000, loss: 0.382999
 >> iter 97000, loss: 0.222204
 >> iter 98000, loss: 0.344496
 >> iter 99000, loss: 0.290132
 >> iter 100000, loss: 0.166777
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.455670
 >> iter 2000, loss: 8.283217
 >> iter 3000, loss: 3.665903
 >> iter 4000, loss: 1.623830
 >> iter 5000, loss: 1.050475
 >> iter 6000, loss: 0.595141
 >> iter 7000, loss: 0.521996
 >> iter 8000, loss: 0.375592
 >> iter 9000, loss: 0.381476
 >> iter 10000, loss: 0.433862
   Number of active neurons: 8
 >> iter 11000, loss: 0.387163
 >> iter 12000, loss: 0.289808
 >> iter 13000, loss: 0.276997
 >> iter 14000, loss: 0.604589
 >> iter 15000, loss: 0.337421
 >> iter 16000, loss: 0.435102
 >> iter 17000, loss: 0.384604
 >> iter 18000, loss: 0.367307
 >> iter 19000, loss: 0.570389
 >> iter 20000, loss: 0.401410
   Number of active neurons: 7
 >> iter 21000, loss: 0.449067
 >> iter 22000, loss: 0.447701
 >> iter 23000, loss: 0.359500
 >> iter 24000, loss: 0.259684
 >> iter 25000, loss: 0.349676
 >> iter 26000, loss: 0.437401
 >> iter 27000, loss: 0.517855
 >> iter 28000, loss: 0.463941
 >> iter 29000, loss: 0.387947
 >> iter 30000, loss: 0.519168
   Number of active neurons: 7
 >> iter 31000, loss: 0.397846
 >> iter 32000, loss: 0.257154
 >> iter 33000, loss: 0.327983
 >> iter 34000, loss: 0.301237
 >> iter 35000, loss: 0.375564
 >> iter 36000, loss: 0.263685
 >> iter 37000, loss: 0.356760
 >> iter 38000, loss: 0.255422
 >> iter 39000, loss: 0.439791
 >> iter 40000, loss: 0.315056
   Number of active neurons: 7
 >> iter 41000, loss: 0.283999
 >> iter 42000, loss: 0.242200
 >> iter 43000, loss: 0.372583
 >> iter 44000, loss: 0.403523
 >> iter 45000, loss: 0.377259
 >> iter 46000, loss: 0.412957
 >> iter 47000, loss: 0.511615
 >> iter 48000, loss: 0.575079
 >> iter 49000, loss: 0.506874
 >> iter 50000, loss: 0.359299
   Number of active neurons: 6
 >> iter 51000, loss: 0.322628
 >> iter 52000, loss: 0.267183
 >> iter 53000, loss: 0.551193
 >> iter 54000, loss: 0.376180
 >> iter 55000, loss: 0.281057
 >> iter 56000, loss: 0.249568
 >> iter 57000, loss: 0.242910
 >> iter 58000, loss: 0.245511
 >> iter 59000, loss: 0.215665
 >> iter 60000, loss: 0.191066
   Number of active neurons: 5
 >> iter 61000, loss: 0.253735
 >> iter 62000, loss: 0.163098
 >> iter 63000, loss: 0.099118
 >> iter 64000, loss: 0.169678
 >> iter 65000, loss: 0.435115
 >> iter 66000, loss: 0.556460
 >> iter 67000, loss: 0.316407
 >> iter 68000, loss: 0.351190
 >> iter 69000, loss: 0.281648
 >> iter 70000, loss: 0.285355
   Number of active neurons: 5
 >> iter 71000, loss: 0.283267
 >> iter 72000, loss: 0.395380
 >> iter 73000, loss: 0.267340
 >> iter 74000, loss: 0.247190
 >> iter 75000, loss: 0.158612
 >> iter 76000, loss: 0.287313
 >> iter 77000, loss: 0.511399
 >> iter 78000, loss: 0.300744
 >> iter 79000, loss: 0.323978
 >> iter 80000, loss: 0.188803
   Number of active neurons: 4
 >> iter 81000, loss: 0.351638
 >> iter 82000, loss: 0.251603
 >> iter 83000, loss: 0.191066
 >> iter 84000, loss: 0.137054
 >> iter 85000, loss: 0.238971
 >> iter 86000, loss: 0.166584
 >> iter 87000, loss: 0.257126
 >> iter 88000, loss: 0.229997
 >> iter 89000, loss: 0.418866
 >> iter 90000, loss: 0.540661
   Number of active neurons: 4
 >> iter 91000, loss: 0.308391
 >> iter 92000, loss: 0.171322
 >> iter 93000, loss: 0.277819
 >> iter 94000, loss: 0.167115
 >> iter 95000, loss: 0.274457
 >> iter 96000, loss: 0.217924
 >> iter 97000, loss: 0.232454
 >> iter 98000, loss: 0.211864
 >> iter 99000, loss: 0.199456
 >> iter 100000, loss: 0.359733
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.448258
 >> iter 2000, loss: 8.728016
 >> iter 3000, loss: 4.122411
 >> iter 4000, loss: 2.170039
 >> iter 5000, loss: 1.079386
 >> iter 6000, loss: 0.801822
 >> iter 7000, loss: 0.677074
 >> iter 8000, loss: 0.510123
 >> iter 9000, loss: 0.346423
 >> iter 10000, loss: 0.609949
   Number of active neurons: 6
 >> iter 11000, loss: 0.418566
 >> iter 12000, loss: 0.308644
 >> iter 13000, loss: 0.391349
 >> iter 14000, loss: 0.464296
 >> iter 15000, loss: 0.291380
 >> iter 16000, loss: 0.220669
 >> iter 17000, loss: 0.227412
 >> iter 18000, loss: 0.280534
 >> iter 19000, loss: 0.257812
 >> iter 20000, loss: 0.387046
   Number of active neurons: 6
 >> iter 21000, loss: 0.282261
 >> iter 22000, loss: 0.343162
 >> iter 23000, loss: 0.261779
 >> iter 24000, loss: 0.257830
 >> iter 25000, loss: 0.312737
 >> iter 26000, loss: 0.381873
 >> iter 27000, loss: 0.182471
 >> iter 28000, loss: 0.337536
 >> iter 29000, loss: 0.348646
 >> iter 30000, loss: 0.413053
   Number of active neurons: 6
 >> iter 31000, loss: 0.407969
 >> iter 32000, loss: 0.310820
 >> iter 33000, loss: 0.287479
 >> iter 34000, loss: 0.416133
 >> iter 35000, loss: 0.299787
 >> iter 36000, loss: 0.250366
 >> iter 37000, loss: 0.273553
 >> iter 38000, loss: 0.385861
 >> iter 39000, loss: 0.363656
 >> iter 40000, loss: 0.481667
   Number of active neurons: 5
 >> iter 41000, loss: 0.274911
 >> iter 42000, loss: 0.290277
 >> iter 43000, loss: 0.275041
 >> iter 44000, loss: 0.385140
 >> iter 45000, loss: 0.291044
 >> iter 46000, loss: 0.271267
 >> iter 47000, loss: 0.393507
 >> iter 48000, loss: 0.329539
 >> iter 49000, loss: 0.250548
 >> iter 50000, loss: 0.279187
   Number of active neurons: 4
 >> iter 51000, loss: 0.502354
 >> iter 52000, loss: 0.393037
 >> iter 53000, loss: 0.602734
 >> iter 54000, loss: 0.499511
 >> iter 55000, loss: 0.323525
 >> iter 56000, loss: 0.184532
 >> iter 57000, loss: 0.463929
 >> iter 58000, loss: 0.275937
 >> iter 59000, loss: 0.217870
 >> iter 60000, loss: 0.262981
   Number of active neurons: 4
 >> iter 61000, loss: 0.183943
 >> iter 62000, loss: 0.179100
 >> iter 63000, loss: 0.268301
 >> iter 64000, loss: 0.245859
 >> iter 65000, loss: 0.196241
 >> iter 66000, loss: 0.222868
 >> iter 67000, loss: 0.185284
 >> iter 68000, loss: 0.094394
 >> iter 69000, loss: 0.192472
 >> iter 70000, loss: 0.198589
   Number of active neurons: 4
 >> iter 71000, loss: 0.480771
 >> iter 72000, loss: 0.344612
 >> iter 73000, loss: 0.307329
 >> iter 74000, loss: 0.632775
 >> iter 75000, loss: 0.312175
 >> iter 76000, loss: 0.310552
 >> iter 77000, loss: 0.247161
 >> iter 78000, loss: 0.180351
 >> iter 79000, loss: 0.245090
 >> iter 80000, loss: 0.295945
   Number of active neurons: 4
 >> iter 81000, loss: 0.365244
 >> iter 82000, loss: 0.393237
 >> iter 83000, loss: 0.289879
 >> iter 84000, loss: 0.189622
 >> iter 85000, loss: 0.197608
 >> iter 86000, loss: 0.436447
 >> iter 87000, loss: 0.251216
 >> iter 88000, loss: 0.185324
 >> iter 89000, loss: 0.362653
 >> iter 90000, loss: 0.290126
   Number of active neurons: 3
 >> iter 91000, loss: 0.424904
 >> iter 92000, loss: 0.263953
 >> iter 93000, loss: 0.209587
 >> iter 94000, loss: 0.211543
 >> iter 95000, loss: 0.196376
 >> iter 96000, loss: 0.304802
 >> iter 97000, loss: 0.229264
 >> iter 98000, loss: 0.281396
 >> iter 99000, loss: 0.200065
 >> iter 100000, loss: 0.178808
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.106098
 >> iter 2000, loss: 8.577893
 >> iter 3000, loss: 3.919374
 >> iter 4000, loss: 1.979963
 >> iter 5000, loss: 0.975855
 >> iter 6000, loss: 0.584662
 >> iter 7000, loss: 0.350589
 >> iter 8000, loss: 0.547248
 >> iter 9000, loss: 0.504938
 >> iter 10000, loss: 0.409865
   Number of active neurons: 6
 >> iter 11000, loss: 0.326505
 >> iter 12000, loss: 0.177685
 >> iter 13000, loss: 0.154237
 >> iter 14000, loss: 0.245789
 >> iter 15000, loss: 0.138369
 >> iter 16000, loss: 0.244443
 >> iter 17000, loss: 0.232476
 >> iter 18000, loss: 0.292895
 >> iter 19000, loss: 0.293995
 >> iter 20000, loss: 0.149332
   Number of active neurons: 4
 >> iter 21000, loss: 0.315232
 >> iter 22000, loss: 0.459103
 >> iter 23000, loss: 0.471928
 >> iter 24000, loss: 0.426862
 >> iter 25000, loss: 0.346158
 >> iter 26000, loss: 0.355354
 >> iter 27000, loss: 0.573961
 >> iter 28000, loss: 0.697217
 >> iter 29000, loss: 0.375935
 >> iter 30000, loss: 0.253265
   Number of active neurons: 4
 >> iter 31000, loss: 0.381790
 >> iter 32000, loss: 0.385917
 >> iter 33000, loss: 0.302181
 >> iter 34000, loss: 0.253029
 >> iter 35000, loss: 0.442968
 >> iter 36000, loss: 0.235356
 >> iter 37000, loss: 0.309439
 >> iter 38000, loss: 0.469178
 >> iter 39000, loss: 0.287206
 >> iter 40000, loss: 0.227686
   Number of active neurons: 4
 >> iter 41000, loss: 0.284604
 >> iter 42000, loss: 0.299409
 >> iter 43000, loss: 0.296667
 >> iter 44000, loss: 0.230564
 >> iter 45000, loss: 0.355038
 >> iter 46000, loss: 0.281040
 >> iter 47000, loss: 0.220021
 >> iter 48000, loss: 0.373300
 >> iter 49000, loss: 0.366305
 >> iter 50000, loss: 0.469090
   Number of active neurons: 3
 >> iter 51000, loss: 0.337030
 >> iter 52000, loss: 0.336925
 >> iter 53000, loss: 0.190218
 >> iter 54000, loss: 0.357601
 >> iter 55000, loss: 0.264272
 >> iter 56000, loss: 0.249987
 >> iter 57000, loss: 0.234445
 >> iter 58000, loss: 0.145941
 >> iter 59000, loss: 0.225229
 >> iter 60000, loss: 0.248405
   Number of active neurons: 3
 >> iter 61000, loss: 0.299359
 >> iter 62000, loss: 0.245783
 >> iter 63000, loss: 0.225898
 >> iter 64000, loss: 0.164507
 >> iter 65000, loss: 0.098464
 >> iter 66000, loss: 0.149095
 >> iter 67000, loss: 0.244185
 >> iter 68000, loss: 0.298792
 >> iter 69000, loss: 0.380055
 >> iter 70000, loss: 0.341274
   Number of active neurons: 3
 >> iter 71000, loss: 0.276817
 >> iter 72000, loss: 0.243022
 >> iter 73000, loss: 0.466937
 >> iter 74000, loss: 0.216521
 >> iter 75000, loss: 0.294332
 >> iter 76000, loss: 0.356992
 >> iter 77000, loss: 0.286127
 >> iter 78000, loss: 0.412488
 >> iter 79000, loss: 0.277089
 >> iter 80000, loss: 0.294981
   Number of active neurons: 3
 >> iter 81000, loss: 0.243991
 >> iter 82000, loss: 0.312462
 >> iter 83000, loss: 0.312586
 >> iter 84000, loss: 0.221608
 >> iter 85000, loss: 0.218648
 >> iter 86000, loss: 0.131794
 >> iter 87000, loss: 0.317401
 >> iter 88000, loss: 0.185650
 >> iter 89000, loss: 0.277111
 >> iter 90000, loss: 0.177556
   Number of active neurons: 3
 >> iter 91000, loss: 0.225297
 >> iter 92000, loss: 0.162200
 >> iter 93000, loss: 0.129694
 >> iter 94000, loss: 0.399467
 >> iter 95000, loss: 0.268523
 >> iter 96000, loss: 0.136433
 >> iter 97000, loss: 0.122164
 >> iter 98000, loss: 0.100251
 >> iter 99000, loss: 0.089789
 >> iter 100000, loss: 0.221418
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 17.823287
 >> iter 2000, loss: 10.727532
 >> iter 3000, loss: 5.319947
 >> iter 4000, loss: 2.553547
 >> iter 5000, loss: 1.229931
 >> iter 6000, loss: 0.730262
 >> iter 7000, loss: 0.458760
 >> iter 8000, loss: 0.381863
 >> iter 9000, loss: 0.241849
 >> iter 10000, loss: 0.300978
   Number of active neurons: 6
 >> iter 11000, loss: 0.262724
 >> iter 12000, loss: 0.285172
 >> iter 13000, loss: 0.149166
 >> iter 14000, loss: 0.436784
 >> iter 15000, loss: 0.421336
 >> iter 16000, loss: 0.281322
 >> iter 17000, loss: 0.322829
 >> iter 18000, loss: 0.250766
 >> iter 19000, loss: 0.389792
 >> iter 20000, loss: 0.272813
   Number of active neurons: 4
 >> iter 21000, loss: 0.339996
 >> iter 22000, loss: 0.242554
 >> iter 23000, loss: 0.161569
 >> iter 24000, loss: 0.288153
 >> iter 25000, loss: 0.176742
 >> iter 26000, loss: 0.120135
 >> iter 27000, loss: 0.134849
 >> iter 28000, loss: 0.114579
 >> iter 29000, loss: 0.276297
 >> iter 30000, loss: 0.238154
   Number of active neurons: 3
 >> iter 31000, loss: 0.296683
 >> iter 32000, loss: 0.301982
 >> iter 33000, loss: 0.467310
 >> iter 34000, loss: 0.271560
 >> iter 35000, loss: 0.260524
 >> iter 36000, loss: 0.143894
 >> iter 37000, loss: 0.254547
 >> iter 38000, loss: 0.235922
 >> iter 39000, loss: 0.138855
 >> iter 40000, loss: 0.201399
   Number of active neurons: 3
 >> iter 41000, loss: 0.276047
 >> iter 42000, loss: 0.223928
 >> iter 43000, loss: 0.168397
 >> iter 44000, loss: 0.173586
 >> iter 45000, loss: 0.103690
 >> iter 46000, loss: 0.095570
 >> iter 47000, loss: 0.140006
 >> iter 48000, loss: 0.385034
 >> iter 49000, loss: 0.278189
 >> iter 50000, loss: 0.191502
   Number of active neurons: 3
 >> iter 51000, loss: 0.371930
 >> iter 52000, loss: 0.206235
 >> iter 53000, loss: 0.235186
 >> iter 54000, loss: 0.190236
 >> iter 55000, loss: 0.177978
 >> iter 56000, loss: 0.222335
 >> iter 57000, loss: 0.202546
 >> iter 58000, loss: 0.298440
 >> iter 59000, loss: 0.370211
 >> iter 60000, loss: 0.270324
   Number of active neurons: 3
 >> iter 61000, loss: 0.239072
 >> iter 62000, loss: 0.264688
 >> iter 63000, loss: 0.177713
 >> iter 64000, loss: 0.094672
 >> iter 65000, loss: 0.181813
 >> iter 66000, loss: 0.378888
 >> iter 67000, loss: 0.398693
 >> iter 68000, loss: 0.344626
 >> iter 69000, loss: 0.319395
 >> iter 70000, loss: 0.236986
   Number of active neurons: 3
 >> iter 71000, loss: 0.219566
 >> iter 72000, loss: 0.242499
 >> iter 73000, loss: 0.244561
 >> iter 74000, loss: 0.286669
 >> iter 75000, loss: 0.256895
 >> iter 76000, loss: 0.248615
 >> iter 77000, loss: 0.508594
 >> iter 78000, loss: 0.263132
 >> iter 79000, loss: 0.331206
 >> iter 80000, loss: 0.163914
   Number of active neurons: 3
 >> iter 81000, loss: 0.119715
 >> iter 82000, loss: 0.200984
 >> iter 83000, loss: 0.195451
 >> iter 84000, loss: 0.150775
 >> iter 85000, loss: 0.213763
 >> iter 86000, loss: 0.275293
 >> iter 87000, loss: 0.276689
 >> iter 88000, loss: 0.304797
 >> iter 89000, loss: 0.292929
 >> iter 90000, loss: 0.427599
   Number of active neurons: 3
 >> iter 91000, loss: 0.266477
 >> iter 92000, loss: 0.291127
 >> iter 93000, loss: 0.341778
 >> iter 94000, loss: 0.355416
 >> iter 95000, loss: 0.189618
 >> iter 96000, loss: 0.169755
 >> iter 97000, loss: 0.183880
 >> iter 98000, loss: 0.161450
 >> iter 99000, loss: 0.194269
 >> iter 100000, loss: 0.109363
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.639395
 >> iter 2000, loss: 8.656101
 >> iter 3000, loss: 4.108701
 >> iter 4000, loss: 1.837327
 >> iter 5000, loss: 1.030502
 >> iter 6000, loss: 0.763943
 >> iter 7000, loss: 0.430195
 >> iter 8000, loss: 0.380474
 >> iter 9000, loss: 0.294153
 >> iter 10000, loss: 0.471257
   Number of active neurons: 5
 >> iter 11000, loss: 0.454403
 >> iter 12000, loss: 0.588822
 >> iter 13000, loss: 0.351613
 >> iter 14000, loss: 0.215699
 >> iter 15000, loss: 0.273619
 >> iter 16000, loss: 0.281761
 >> iter 17000, loss: 0.254966
 >> iter 18000, loss: 0.288572
 >> iter 19000, loss: 0.225797
 >> iter 20000, loss: 0.217175
   Number of active neurons: 5
 >> iter 21000, loss: 0.333101
 >> iter 22000, loss: 0.290019
 >> iter 23000, loss: 0.308283
 >> iter 24000, loss: 0.500387
 >> iter 25000, loss: 0.375230
 >> iter 26000, loss: 0.250085
 >> iter 27000, loss: 0.176616
 >> iter 28000, loss: 0.330727
 >> iter 29000, loss: 0.369901
 >> iter 30000, loss: 0.355824
   Number of active neurons: 4
 >> iter 31000, loss: 0.290784
 >> iter 32000, loss: 0.225965
 >> iter 33000, loss: 0.298543
 >> iter 34000, loss: 0.175372
 >> iter 35000, loss: 0.183011
 >> iter 36000, loss: 0.184953
 >> iter 37000, loss: 0.296932
 >> iter 38000, loss: 0.205578
 >> iter 39000, loss: 0.237114
 >> iter 40000, loss: 0.256005
   Number of active neurons: 4
 >> iter 41000, loss: 0.340355
 >> iter 42000, loss: 0.244586
 >> iter 43000, loss: 0.274348
 >> iter 44000, loss: 0.326147
 >> iter 45000, loss: 0.431913
 >> iter 46000, loss: 0.372523
 >> iter 47000, loss: 0.289590
 >> iter 48000, loss: 0.368776
 >> iter 49000, loss: 0.325882
 >> iter 50000, loss: 0.404876
   Number of active neurons: 4
 >> iter 51000, loss: 0.200721
 >> iter 52000, loss: 0.266044
 >> iter 53000, loss: 0.197328
 >> iter 54000, loss: 0.145138
 >> iter 55000, loss: 0.191031
 >> iter 56000, loss: 0.297781
 >> iter 57000, loss: 0.185288
 >> iter 58000, loss: 0.145873
 >> iter 59000, loss: 0.170518
 >> iter 60000, loss: 0.222740
   Number of active neurons: 3
 >> iter 61000, loss: 0.156416
 >> iter 62000, loss: 0.249353
 >> iter 63000, loss: 0.214861
 >> iter 64000, loss: 0.183063
 >> iter 65000, loss: 0.381780
 >> iter 66000, loss: 0.319160
 >> iter 67000, loss: 0.256002
 >> iter 68000, loss: 0.152864
 >> iter 69000, loss: 0.197601
 >> iter 70000, loss: 0.215154
   Number of active neurons: 3
 >> iter 71000, loss: 0.261766
 >> iter 72000, loss: 0.489752
 >> iter 73000, loss: 0.313275
 >> iter 74000, loss: 0.314669
 >> iter 75000, loss: 0.352876
 >> iter 76000, loss: 0.250339
 >> iter 77000, loss: 0.233249
 >> iter 78000, loss: 0.346850
 >> iter 79000, loss: 0.253019
 >> iter 80000, loss: 0.294957
   Number of active neurons: 3
 >> iter 81000, loss: 0.194970
 >> iter 82000, loss: 0.101274
 >> iter 83000, loss: 0.093442
 >> iter 84000, loss: 0.076250
 >> iter 85000, loss: 0.289608
 >> iter 86000, loss: 0.242778
 >> iter 87000, loss: 0.151192
 >> iter 88000, loss: 0.409626
 >> iter 89000, loss: 0.224227
 >> iter 90000, loss: 0.297911
   Number of active neurons: 3
 >> iter 91000, loss: 0.261342
 >> iter 92000, loss: 0.282034
 >> iter 93000, loss: 0.191822
 >> iter 94000, loss: 0.178572
 >> iter 95000, loss: 0.271122
 >> iter 96000, loss: 0.202810
 >> iter 97000, loss: 0.129000
 >> iter 98000, loss: 0.301288
 >> iter 99000, loss: 0.179095
 >> iter 100000, loss: 0.222934
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.686405
 >> iter 2000, loss: 8.798540
 >> iter 3000, loss: 4.073617
 >> iter 4000, loss: 1.795420
 >> iter 5000, loss: 1.027182
 >> iter 6000, loss: 0.784284
 >> iter 7000, loss: 0.474713
 >> iter 8000, loss: 0.350362
 >> iter 9000, loss: 0.355413
 >> iter 10000, loss: 0.378228
   Number of active neurons: 6
 >> iter 11000, loss: 0.283579
 >> iter 12000, loss: 0.194379
 >> iter 13000, loss: 0.249231
 >> iter 14000, loss: 0.222025
 >> iter 15000, loss: 0.352625
 >> iter 16000, loss: 0.275128
 >> iter 17000, loss: 0.304270
 >> iter 18000, loss: 0.313185
 >> iter 19000, loss: 0.388953
 >> iter 20000, loss: 0.262531
   Number of active neurons: 5
 >> iter 21000, loss: 0.276343
 >> iter 22000, loss: 0.190136
 >> iter 23000, loss: 0.412061
 >> iter 24000, loss: 0.350325
 >> iter 25000, loss: 0.280648
 >> iter 26000, loss: 0.331006
 >> iter 27000, loss: 0.293389
 >> iter 28000, loss: 0.376967
 >> iter 29000, loss: 0.360200
 >> iter 30000, loss: 0.301336
   Number of active neurons: 4
 >> iter 31000, loss: 0.332885
 >> iter 32000, loss: 0.288721
 >> iter 33000, loss: 0.212162
 >> iter 34000, loss: 0.249132
 >> iter 35000, loss: 0.213630
 >> iter 36000, loss: 0.184923
 >> iter 37000, loss: 0.330815
 >> iter 38000, loss: 0.351463
 >> iter 39000, loss: 0.246274
 >> iter 40000, loss: 0.327276
   Number of active neurons: 4
 >> iter 41000, loss: 0.270367
 >> iter 42000, loss: 0.174951
 >> iter 43000, loss: 0.140406
 >> iter 44000, loss: 0.112441
 >> iter 45000, loss: 0.194998
 >> iter 46000, loss: 0.198250
 >> iter 47000, loss: 0.206689
 >> iter 48000, loss: 0.291446
 >> iter 49000, loss: 0.209103
 >> iter 50000, loss: 0.163623
   Number of active neurons: 4
 >> iter 51000, loss: 0.252596
 >> iter 52000, loss: 0.252599
 >> iter 53000, loss: 0.271362
 >> iter 54000, loss: 0.244118
 >> iter 55000, loss: 0.235631
 >> iter 56000, loss: 0.223749
 >> iter 57000, loss: 0.190190
 >> iter 58000, loss: 0.122786
 >> iter 59000, loss: 0.160092
 >> iter 60000, loss: 0.472356
   Number of active neurons: 4
 >> iter 61000, loss: 0.288312
 >> iter 62000, loss: 0.201108
 >> iter 63000, loss: 0.326706
 >> iter 64000, loss: 0.585571
 >> iter 65000, loss: 0.537199
 >> iter 66000, loss: 0.371568
 >> iter 67000, loss: 0.318250
 >> iter 68000, loss: 0.326663
 >> iter 69000, loss: 0.239045
 >> iter 70000, loss: 0.429275
   Number of active neurons: 3
 >> iter 71000, loss: 0.386748
 >> iter 72000, loss: 0.244107
 >> iter 73000, loss: 0.321503
 >> iter 74000, loss: 0.312389
 >> iter 75000, loss: 0.324016
 >> iter 76000, loss: 0.249118
 >> iter 77000, loss: 0.252679
 >> iter 78000, loss: 0.184274
 >> iter 79000, loss: 0.245736
 >> iter 80000, loss: 0.347223
   Number of active neurons: 3
 >> iter 81000, loss: 0.270431
 >> iter 82000, loss: 0.489545
 >> iter 83000, loss: 0.288574
 >> iter 84000, loss: 0.166976
 >> iter 85000, loss: 0.303918
 >> iter 86000, loss: 0.296169
 >> iter 87000, loss: 0.349706
 >> iter 88000, loss: 0.500732
 >> iter 89000, loss: 0.310336
 >> iter 90000, loss: 0.200084
   Number of active neurons: 3
 >> iter 91000, loss: 0.384108
 >> iter 92000, loss: 0.470745
 >> iter 93000, loss: 0.290587
 >> iter 94000, loss: 0.220135
 >> iter 95000, loss: 0.220596
 >> iter 96000, loss: 0.237679
 >> iter 97000, loss: 0.157358
 >> iter 98000, loss: 0.228825
 >> iter 99000, loss: 0.169975
 >> iter 100000, loss: 0.228731
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.491165
 >> iter 2000, loss: 8.845119
 >> iter 3000, loss: 3.995772
 >> iter 4000, loss: 1.761121
 >> iter 5000, loss: 0.994558
 >> iter 6000, loss: 0.688877
 >> iter 7000, loss: 0.567803
 >> iter 8000, loss: 0.287063
 >> iter 9000, loss: 0.353611
 >> iter 10000, loss: 0.518988
   Number of active neurons: 5
 >> iter 11000, loss: 0.442334
 >> iter 12000, loss: 0.323906
 >> iter 13000, loss: 0.479109
 >> iter 14000, loss: 0.369748
 >> iter 15000, loss: 0.507934
 >> iter 16000, loss: 0.405309
 >> iter 17000, loss: 0.302807
 >> iter 18000, loss: 0.265607
 >> iter 19000, loss: 0.309187
 >> iter 20000, loss: 0.322740
   Number of active neurons: 5
 >> iter 21000, loss: 0.355473
 >> iter 22000, loss: 0.172871
 >> iter 23000, loss: 0.299145
 >> iter 24000, loss: 0.244913
 >> iter 25000, loss: 0.222635
 >> iter 26000, loss: 0.377731
 >> iter 27000, loss: 0.496844
 >> iter 28000, loss: 0.258252
 >> iter 29000, loss: 0.344174
 >> iter 30000, loss: 0.341545
   Number of active neurons: 5
 >> iter 31000, loss: 0.342199
 >> iter 32000, loss: 0.274521
 >> iter 33000, loss: 0.334342
 >> iter 34000, loss: 0.231052
 >> iter 35000, loss: 0.180487
 >> iter 36000, loss: 0.298958
 >> iter 37000, loss: 0.283544
 >> iter 38000, loss: 0.407020
 >> iter 39000, loss: 0.234970
 >> iter 40000, loss: 0.307935
   Number of active neurons: 4
 >> iter 41000, loss: 0.288196
 >> iter 42000, loss: 0.373206
 >> iter 43000, loss: 0.230367
 >> iter 44000, loss: 0.199144
 >> iter 45000, loss: 0.495346
 >> iter 46000, loss: 0.308356
 >> iter 47000, loss: 0.298392
 >> iter 48000, loss: 0.236076
 >> iter 49000, loss: 0.418653
 >> iter 50000, loss: 0.294494
   Number of active neurons: 3
 >> iter 51000, loss: 0.455058
 >> iter 52000, loss: 0.325932
 >> iter 53000, loss: 0.245336
 >> iter 54000, loss: 0.305186
 >> iter 55000, loss: 0.262809
 >> iter 56000, loss: 0.432928
 >> iter 57000, loss: 0.319956
 >> iter 58000, loss: 0.331222
 >> iter 59000, loss: 0.317147
 >> iter 60000, loss: 0.275948
   Number of active neurons: 3
 >> iter 61000, loss: 0.268360
 >> iter 62000, loss: 0.217074
 >> iter 63000, loss: 0.356336
 >> iter 64000, loss: 0.454618
 >> iter 65000, loss: 0.345336
 >> iter 66000, loss: 0.250785
 >> iter 67000, loss: 0.190959
 >> iter 68000, loss: 0.224563
 >> iter 69000, loss: 0.228227
 >> iter 70000, loss: 0.268383
   Number of active neurons: 3
 >> iter 71000, loss: 0.270196
 >> iter 72000, loss: 0.307464
 >> iter 73000, loss: 0.335619
 >> iter 74000, loss: 0.263807
 >> iter 75000, loss: 0.315662
 >> iter 76000, loss: 0.171977
 >> iter 77000, loss: 0.172621
 >> iter 78000, loss: 0.245980
 >> iter 79000, loss: 0.196944
 >> iter 80000, loss: 0.439803
   Number of active neurons: 3
 >> iter 81000, loss: 0.422876
 >> iter 82000, loss: 0.328102
 >> iter 83000, loss: 0.261267
 >> iter 84000, loss: 0.232148
 >> iter 85000, loss: 0.317828
 >> iter 86000, loss: 0.209300
 >> iter 87000, loss: 0.168541
 >> iter 88000, loss: 0.168280
 >> iter 89000, loss: 0.258093
 >> iter 90000, loss: 0.204254
   Number of active neurons: 3
 >> iter 91000, loss: 0.308653
 >> iter 92000, loss: 0.448564
 >> iter 93000, loss: 0.435555
 >> iter 94000, loss: 0.480529
 >> iter 95000, loss: 0.342042
 >> iter 96000, loss: 0.344409
 >> iter 97000, loss: 0.261153
 >> iter 98000, loss: 0.166461
 >> iter 99000, loss: 0.285563
 >> iter 100000, loss: 0.289619
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.125881
 >> iter 2000, loss: 9.593005
 >> iter 3000, loss: 4.504492
 >> iter 4000, loss: 2.354082
 >> iter 5000, loss: 1.584172
 >> iter 6000, loss: 0.867166
 >> iter 7000, loss: 0.530972
 >> iter 8000, loss: 0.542548
 >> iter 9000, loss: 0.339365
 >> iter 10000, loss: 0.391485
   Number of active neurons: 5
 >> iter 11000, loss: 0.338113
 >> iter 12000, loss: 0.539148
 >> iter 13000, loss: 0.487233
 >> iter 14000, loss: 0.442170
 >> iter 15000, loss: 0.530864
 >> iter 16000, loss: 0.395317
 >> iter 17000, loss: 0.270158
 >> iter 18000, loss: 0.443599
 >> iter 19000, loss: 0.618787
 >> iter 20000, loss: 0.672579
   Number of active neurons: 5
 >> iter 21000, loss: 0.618741
 >> iter 22000, loss: 0.575980
 >> iter 23000, loss: 0.512243
 >> iter 24000, loss: 0.620211
 >> iter 25000, loss: 0.503743
 >> iter 26000, loss: 0.372262
 >> iter 27000, loss: 0.287940
 >> iter 28000, loss: 0.470917
 >> iter 29000, loss: 0.409921
 >> iter 30000, loss: 0.493331
   Number of active neurons: 5
 >> iter 31000, loss: 0.515057
 >> iter 32000, loss: 0.508375
 >> iter 33000, loss: 0.744582
 >> iter 34000, loss: 0.466096
 >> iter 35000, loss: 0.392362
 >> iter 36000, loss: 0.254445
 >> iter 37000, loss: 0.290780
 >> iter 38000, loss: 0.342726
 >> iter 39000, loss: 0.358214
 >> iter 40000, loss: 0.599960
   Number of active neurons: 5
 >> iter 41000, loss: 0.438421
 >> iter 42000, loss: 0.442745
 >> iter 43000, loss: 0.428105
 >> iter 44000, loss: 0.284673
 >> iter 45000, loss: 0.376430
 >> iter 46000, loss: 0.258037
 >> iter 47000, loss: 0.322413
 >> iter 48000, loss: 0.504820
 >> iter 49000, loss: 0.587432
 >> iter 50000, loss: 0.320212
   Number of active neurons: 5
 >> iter 51000, loss: 0.279347
 >> iter 52000, loss: 0.384255
 >> iter 53000, loss: 0.292204
 >> iter 54000, loss: 0.224276
 >> iter 55000, loss: 0.261065
 >> iter 56000, loss: 0.389524
 >> iter 57000, loss: 0.590279
 >> iter 58000, loss: 0.272903
 >> iter 59000, loss: 0.165661
 >> iter 60000, loss: 0.408722
   Number of active neurons: 5
 >> iter 61000, loss: 0.324672
 >> iter 62000, loss: 0.403252
 >> iter 63000, loss: 0.422114
 >> iter 64000, loss: 0.368475
 >> iter 65000, loss: 0.372597
 >> iter 66000, loss: 0.259294
 >> iter 67000, loss: 0.446125
 >> iter 68000, loss: 0.314899
 >> iter 69000, loss: 0.374925
 >> iter 70000, loss: 0.256714
   Number of active neurons: 5
 >> iter 71000, loss: 0.224664
 >> iter 72000, loss: 0.308943
 >> iter 73000, loss: 0.212339
 >> iter 74000, loss: 0.240822
 >> iter 75000, loss: 0.343767
 >> iter 76000, loss: 0.422015
 >> iter 77000, loss: 0.424304
 >> iter 78000, loss: 0.317216
 >> iter 79000, loss: 0.405451
 >> iter 80000, loss: 0.427808
   Number of active neurons: 4
 >> iter 81000, loss: 0.274007
 >> iter 82000, loss: 0.302526
 >> iter 83000, loss: 0.339871
 >> iter 84000, loss: 0.559587
 >> iter 85000, loss: 0.286772
 >> iter 86000, loss: 0.295438
 >> iter 87000, loss: 0.253064
 >> iter 88000, loss: 0.301726
 >> iter 89000, loss: 0.549624
 >> iter 90000, loss: 0.627705
   Number of active neurons: 4
 >> iter 91000, loss: 0.509019
 >> iter 92000, loss: 0.431703
 >> iter 93000, loss: 0.369746
 >> iter 94000, loss: 0.416251
 >> iter 95000, loss: 0.483304
 >> iter 96000, loss: 0.539523
 >> iter 97000, loss: 0.475281
 >> iter 98000, loss: 0.338277
 >> iter 99000, loss: 0.450013
 >> iter 100000, loss: 0.378566
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.535519
 >> iter 2000, loss: 8.301624
 >> iter 3000, loss: 3.634400
 >> iter 4000, loss: 1.695199
 >> iter 5000, loss: 0.895419
 >> iter 6000, loss: 0.702342
 >> iter 7000, loss: 0.371235
 >> iter 8000, loss: 0.426040
 >> iter 9000, loss: 0.306744
 >> iter 10000, loss: 0.581856
   Number of active neurons: 6
 >> iter 11000, loss: 0.336949
 >> iter 12000, loss: 0.464161
 >> iter 13000, loss: 0.513917
 >> iter 14000, loss: 0.347820
 >> iter 15000, loss: 0.482678
 >> iter 16000, loss: 0.358525
 >> iter 17000, loss: 0.389439
 >> iter 18000, loss: 0.327005
 >> iter 19000, loss: 0.320129
 >> iter 20000, loss: 0.281469
   Number of active neurons: 6
 >> iter 21000, loss: 0.300254
 >> iter 22000, loss: 0.286750
 >> iter 23000, loss: 0.226084
 >> iter 24000, loss: 0.242435
 >> iter 25000, loss: 0.240085
 >> iter 26000, loss: 0.589316
 >> iter 27000, loss: 0.407799
 >> iter 28000, loss: 0.373708
 >> iter 29000, loss: 0.303788
 >> iter 30000, loss: 0.370228
   Number of active neurons: 5
 >> iter 31000, loss: 0.388295
 >> iter 32000, loss: 0.312523
 >> iter 33000, loss: 0.396283
 >> iter 34000, loss: 0.325797
 >> iter 35000, loss: 0.423158
 >> iter 36000, loss: 0.612471
 >> iter 37000, loss: 0.429234
 >> iter 38000, loss: 0.392909
 >> iter 39000, loss: 0.300606
 >> iter 40000, loss: 0.330366
   Number of active neurons: 3
 >> iter 41000, loss: 0.391202
 >> iter 42000, loss: 0.362380
 >> iter 43000, loss: 0.301378
 >> iter 44000, loss: 0.252702
 >> iter 45000, loss: 0.210877
 >> iter 46000, loss: 0.159647
 >> iter 47000, loss: 0.207973
 >> iter 48000, loss: 0.199613
 >> iter 49000, loss: 0.324966
 >> iter 50000, loss: 0.338739
   Number of active neurons: 3
 >> iter 51000, loss: 0.240509
 >> iter 52000, loss: 0.408011
 >> iter 53000, loss: 0.293541
 >> iter 54000, loss: 0.279714
 >> iter 55000, loss: 0.317407
 >> iter 56000, loss: 0.325128
 >> iter 57000, loss: 0.266460
 >> iter 58000, loss: 0.159734
 >> iter 59000, loss: 0.191514
 >> iter 60000, loss: 0.215201
   Number of active neurons: 3
 >> iter 61000, loss: 0.214041
 >> iter 62000, loss: 0.337704
 >> iter 63000, loss: 0.232481
 >> iter 64000, loss: 0.176031
 >> iter 65000, loss: 0.098556
 >> iter 66000, loss: 0.175189
 >> iter 67000, loss: 0.183987
 >> iter 68000, loss: 0.215935
 >> iter 69000, loss: 0.153317
 >> iter 70000, loss: 0.506681
   Number of active neurons: 3
 >> iter 71000, loss: 0.523288
 >> iter 72000, loss: 0.687930
 >> iter 73000, loss: 0.381245
 >> iter 74000, loss: 0.289130
 >> iter 75000, loss: 0.468408
 >> iter 76000, loss: 0.366954
 >> iter 77000, loss: 0.303984
 >> iter 78000, loss: 0.166296
 >> iter 79000, loss: 0.204200
 >> iter 80000, loss: 0.309821
   Number of active neurons: 3
 >> iter 81000, loss: 0.377538
 >> iter 82000, loss: 0.251513
 >> iter 83000, loss: 0.474021
 >> iter 84000, loss: 0.331178
 >> iter 85000, loss: 0.307992
 >> iter 86000, loss: 0.187872
 >> iter 87000, loss: 0.213388
 >> iter 88000, loss: 0.221021
 >> iter 89000, loss: 0.237051
 >> iter 90000, loss: 0.386409
   Number of active neurons: 3
 >> iter 91000, loss: 0.308292
 >> iter 92000, loss: 0.206077
 >> iter 93000, loss: 0.358431
 >> iter 94000, loss: 0.282132
 >> iter 95000, loss: 0.350806
 >> iter 96000, loss: 0.272024
 >> iter 97000, loss: 0.330443
 >> iter 98000, loss: 0.200416
 >> iter 99000, loss: 0.260125
 >> iter 100000, loss: 0.403547
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.624481
 >> iter 2000, loss: 8.304780
 >> iter 3000, loss: 4.072867
 >> iter 4000, loss: 1.971185
 >> iter 5000, loss: 1.076110
 >> iter 6000, loss: 0.711112
 >> iter 7000, loss: 0.486834
 >> iter 8000, loss: 0.340659
 >> iter 9000, loss: 0.474039
 >> iter 10000, loss: 0.668861
   Number of active neurons: 5
 >> iter 11000, loss: 0.496238
 >> iter 12000, loss: 0.362429
 >> iter 13000, loss: 0.545630
 >> iter 14000, loss: 0.517509
 >> iter 15000, loss: 0.289960
 >> iter 16000, loss: 0.286406
 >> iter 17000, loss: 0.318779
 >> iter 18000, loss: 0.316367
 >> iter 19000, loss: 0.320236
 >> iter 20000, loss: 0.325527
   Number of active neurons: 5
 >> iter 21000, loss: 0.280128
 >> iter 22000, loss: 0.631198
 >> iter 23000, loss: 0.304145
 >> iter 24000, loss: 0.192913
 >> iter 25000, loss: 0.371457
 >> iter 26000, loss: 0.241129
 >> iter 27000, loss: 0.385525
 >> iter 28000, loss: 0.382336
 >> iter 29000, loss: 0.390338
 >> iter 30000, loss: 0.407684
   Number of active neurons: 5
 >> iter 31000, loss: 0.414752
 >> iter 32000, loss: 0.400875
 >> iter 33000, loss: 0.261095
 >> iter 34000, loss: 0.280561
 >> iter 35000, loss: 0.290362
 >> iter 36000, loss: 0.193569
 >> iter 37000, loss: 0.270152
 >> iter 38000, loss: 0.169999
 >> iter 39000, loss: 0.258187
 >> iter 40000, loss: 0.180279
   Number of active neurons: 5
 >> iter 41000, loss: 0.153976
 >> iter 42000, loss: 0.109052
 >> iter 43000, loss: 0.162365
 >> iter 44000, loss: 0.341302
 >> iter 45000, loss: 0.297032
 >> iter 46000, loss: 0.280722
 >> iter 47000, loss: 0.386633
 >> iter 48000, loss: 0.224519
 >> iter 49000, loss: 0.289122
 >> iter 50000, loss: 0.243088
   Number of active neurons: 5
 >> iter 51000, loss: 0.335558
 >> iter 52000, loss: 0.356256
 >> iter 53000, loss: 0.264702
 >> iter 54000, loss: 0.248683
 >> iter 55000, loss: 0.420293
 >> iter 56000, loss: 0.339880
 >> iter 57000, loss: 0.339155
 >> iter 58000, loss: 0.195322
 >> iter 59000, loss: 0.121235
 >> iter 60000, loss: 0.220567
   Number of active neurons: 5
 >> iter 61000, loss: 0.169246
 >> iter 62000, loss: 0.185390
 >> iter 63000, loss: 0.293408
 >> iter 64000, loss: 0.329874
 >> iter 65000, loss: 0.328904
 >> iter 66000, loss: 0.463204
 >> iter 67000, loss: 0.207294
 >> iter 68000, loss: 0.152570
 >> iter 69000, loss: 0.306652
 >> iter 70000, loss: 0.291356
   Number of active neurons: 5
 >> iter 71000, loss: 0.385969
 >> iter 72000, loss: 0.422338
 >> iter 73000, loss: 0.223682
 >> iter 74000, loss: 0.293591
 >> iter 75000, loss: 0.168896
 >> iter 76000, loss: 0.116164
 >> iter 77000, loss: 0.322944
 >> iter 78000, loss: 0.340733
 >> iter 79000, loss: 0.387117
 >> iter 80000, loss: 0.231755
   Number of active neurons: 3
 >> iter 81000, loss: 0.203194
 >> iter 82000, loss: 0.180532
 >> iter 83000, loss: 0.238671
 >> iter 84000, loss: 0.323292
 >> iter 85000, loss: 0.214720
 >> iter 86000, loss: 0.117738
 >> iter 87000, loss: 0.165061
 >> iter 88000, loss: 0.194343
 >> iter 89000, loss: 0.404240
 >> iter 90000, loss: 0.204794
   Number of active neurons: 3
 >> iter 91000, loss: 0.109703
 >> iter 92000, loss: 0.469741
 >> iter 93000, loss: 0.342126
 >> iter 94000, loss: 0.229188
 >> iter 95000, loss: 0.177731
 >> iter 96000, loss: 0.371252
 >> iter 97000, loss: 0.218511
 >> iter 98000, loss: 0.191948
 >> iter 99000, loss: 0.255264
 >> iter 100000, loss: 0.342055
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.287378
 >> iter 2000, loss: 8.951989
 >> iter 3000, loss: 3.946924
 >> iter 4000, loss: 1.807987
 >> iter 5000, loss: 0.942818
 >> iter 6000, loss: 0.652343
 >> iter 7000, loss: 0.568508
 >> iter 8000, loss: 0.700432
 >> iter 9000, loss: 0.403094
 >> iter 10000, loss: 0.308288
   Number of active neurons: 6
 >> iter 11000, loss: 0.623035
 >> iter 12000, loss: 0.539553
 >> iter 13000, loss: 0.357130
 >> iter 14000, loss: 0.312524
 >> iter 15000, loss: 0.237625
 >> iter 16000, loss: 0.302469
 >> iter 17000, loss: 0.486726
 >> iter 18000, loss: 0.399779
 >> iter 19000, loss: 0.342796
 >> iter 20000, loss: 0.412496
   Number of active neurons: 6
 >> iter 21000, loss: 0.385720
 >> iter 22000, loss: 0.251764
 >> iter 23000, loss: 0.179656
 >> iter 24000, loss: 0.268251
 >> iter 25000, loss: 0.220664
 >> iter 26000, loss: 0.289701
 >> iter 27000, loss: 0.442504
 >> iter 28000, loss: 0.342397
 >> iter 29000, loss: 0.331717
 >> iter 30000, loss: 0.384925
   Number of active neurons: 4
 >> iter 31000, loss: 0.304167
 >> iter 32000, loss: 0.222057
 >> iter 33000, loss: 0.328516
 >> iter 34000, loss: 0.266650
 >> iter 35000, loss: 0.311507
 >> iter 36000, loss: 0.183050
 >> iter 37000, loss: 0.209763
 >> iter 38000, loss: 0.347628
 >> iter 39000, loss: 0.405773
 >> iter 40000, loss: 0.599776
   Number of active neurons: 4
 >> iter 41000, loss: 0.489345
 >> iter 42000, loss: 0.390688
 >> iter 43000, loss: 0.215188
 >> iter 44000, loss: 0.458973
 >> iter 45000, loss: 0.532122
 >> iter 46000, loss: 0.368245
 >> iter 47000, loss: 0.308443
 >> iter 48000, loss: 0.354168
 >> iter 49000, loss: 0.400581
 >> iter 50000, loss: 0.291845
   Number of active neurons: 4
 >> iter 51000, loss: 0.446360
 >> iter 52000, loss: 0.279589
 >> iter 53000, loss: 0.321572
 >> iter 54000, loss: 0.256184
 >> iter 55000, loss: 0.297464
 >> iter 56000, loss: 0.284629
 >> iter 57000, loss: 0.328115
 >> iter 58000, loss: 0.257025
 >> iter 59000, loss: 0.303254
 >> iter 60000, loss: 0.228056
   Number of active neurons: 4
 >> iter 61000, loss: 0.167512
 >> iter 62000, loss: 0.282185
 >> iter 63000, loss: 0.300362
 >> iter 64000, loss: 0.294712
 >> iter 65000, loss: 0.173888
 >> iter 66000, loss: 0.124202
 >> iter 67000, loss: 0.150441
 >> iter 68000, loss: 0.157225
 >> iter 69000, loss: 0.217643
 >> iter 70000, loss: 0.278691
   Number of active neurons: 4
 >> iter 71000, loss: 0.400043
 >> iter 72000, loss: 0.448779
 >> iter 73000, loss: 0.290037
 >> iter 74000, loss: 0.332596
 >> iter 75000, loss: 0.302861
 >> iter 76000, loss: 0.277150
 >> iter 77000, loss: 0.361603
 >> iter 78000, loss: 0.350479
 >> iter 79000, loss: 0.247906
 >> iter 80000, loss: 0.329281
   Number of active neurons: 4
 >> iter 81000, loss: 0.294479
 >> iter 82000, loss: 0.171866
 >> iter 83000, loss: 0.221798
 >> iter 84000, loss: 0.253950
 >> iter 85000, loss: 0.497106
 >> iter 86000, loss: 0.330588
 >> iter 87000, loss: 0.392952
 >> iter 88000, loss: 0.237719
 >> iter 89000, loss: 0.320759
 >> iter 90000, loss: 0.426446
   Number of active neurons: 4
 >> iter 91000, loss: 0.326416
 >> iter 92000, loss: 0.466941
 >> iter 93000, loss: 0.301058
 >> iter 94000, loss: 0.339024
 >> iter 95000, loss: 0.400463
 >> iter 96000, loss: 0.185756
 >> iter 97000, loss: 0.132646
 >> iter 98000, loss: 0.110342
 >> iter 99000, loss: 0.218024
 >> iter 100000, loss: 0.215756
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 17.867855
 >> iter 2000, loss: 8.437448
 >> iter 3000, loss: 3.937015
 >> iter 4000, loss: 2.067330
 >> iter 5000, loss: 0.970112
 >> iter 6000, loss: 0.599497
 >> iter 7000, loss: 0.492674
 >> iter 8000, loss: 0.333651
 >> iter 9000, loss: 0.492758
 >> iter 10000, loss: 0.495518
   Number of active neurons: 6
 >> iter 11000, loss: 0.468413
 >> iter 12000, loss: 0.414713
 >> iter 13000, loss: 0.319377
 >> iter 14000, loss: 0.269856
 >> iter 15000, loss: 0.221955
 >> iter 16000, loss: 0.266042
 >> iter 17000, loss: 0.262242
 >> iter 18000, loss: 0.197772
 >> iter 19000, loss: 0.351635
 >> iter 20000, loss: 0.426713
   Number of active neurons: 5
 >> iter 21000, loss: 0.338131
 >> iter 22000, loss: 0.365990
 >> iter 23000, loss: 0.399445
 >> iter 24000, loss: 0.288625
 >> iter 25000, loss: 0.304209
 >> iter 26000, loss: 0.284847
 >> iter 27000, loss: 0.272532
 >> iter 28000, loss: 0.274374
 >> iter 29000, loss: 0.204183
 >> iter 30000, loss: 0.243913
   Number of active neurons: 5
 >> iter 31000, loss: 0.368275
 >> iter 32000, loss: 0.314420
 >> iter 33000, loss: 0.219864
 >> iter 34000, loss: 0.479311
 >> iter 35000, loss: 0.285222
 >> iter 36000, loss: 0.283096
 >> iter 37000, loss: 0.328916
 >> iter 38000, loss: 0.322414
 >> iter 39000, loss: 0.374727
 >> iter 40000, loss: 0.198812
   Number of active neurons: 4
 >> iter 41000, loss: 0.318888
 >> iter 42000, loss: 0.289905
 >> iter 43000, loss: 0.438679
 >> iter 44000, loss: 0.300989
 >> iter 45000, loss: 0.254468
 >> iter 46000, loss: 0.353080
 >> iter 47000, loss: 0.203679
 >> iter 48000, loss: 0.302721
 >> iter 49000, loss: 0.179648
 >> iter 50000, loss: 0.109532
   Number of active neurons: 4
 >> iter 51000, loss: 0.208717
 >> iter 52000, loss: 0.246178
 >> iter 53000, loss: 0.302513
 >> iter 54000, loss: 0.364133
 >> iter 55000, loss: 0.210907
 >> iter 56000, loss: 0.190986
 >> iter 57000, loss: 0.252494
 >> iter 58000, loss: 0.215468
 >> iter 59000, loss: 0.185690
 >> iter 60000, loss: 0.380247
   Number of active neurons: 4
 >> iter 61000, loss: 0.285601
 >> iter 62000, loss: 0.204556
 >> iter 63000, loss: 0.254940
 >> iter 64000, loss: 0.338896
 >> iter 65000, loss: 0.210472
 >> iter 66000, loss: 0.535345
 >> iter 67000, loss: 0.298658
 >> iter 68000, loss: 0.189298
 >> iter 69000, loss: 0.187806
 >> iter 70000, loss: 0.313142
   Number of active neurons: 4
 >> iter 71000, loss: 0.326113
 >> iter 72000, loss: 0.208173
 >> iter 73000, loss: 0.265914
 >> iter 74000, loss: 0.160827
 >> iter 75000, loss: 0.147162
 >> iter 76000, loss: 0.088237
 >> iter 77000, loss: 0.152789
 >> iter 78000, loss: 0.260271
 >> iter 79000, loss: 0.188576
 >> iter 80000, loss: 0.184644
   Number of active neurons: 4
 >> iter 81000, loss: 0.265167
 >> iter 82000, loss: 0.240025
 >> iter 83000, loss: 0.192295
 >> iter 84000, loss: 0.193147
 >> iter 85000, loss: 0.297804
 >> iter 86000, loss: 0.357208
 >> iter 87000, loss: 0.281552
 >> iter 88000, loss: 0.247470
 >> iter 89000, loss: 0.253547
 >> iter 90000, loss: 0.229627
   Number of active neurons: 4
 >> iter 91000, loss: 0.208250
 >> iter 92000, loss: 0.232905
 >> iter 93000, loss: 0.148130
 >> iter 94000, loss: 0.201895
 >> iter 95000, loss: 0.170502
 >> iter 96000, loss: 0.131218
 >> iter 97000, loss: 0.149460
 >> iter 98000, loss: 0.428650
 >> iter 99000, loss: 0.326830
 >> iter 100000, loss: 0.178780
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 17.350127
 >> iter 2000, loss: 9.624062
 >> iter 3000, loss: 4.500833
 >> iter 4000, loss: 2.335928
 >> iter 5000, loss: 1.096493
 >> iter 6000, loss: 0.980210
 >> iter 7000, loss: 0.713803
 >> iter 8000, loss: 0.383562
 >> iter 9000, loss: 0.257051
 >> iter 10000, loss: 0.247882
   Number of active neurons: 5
 >> iter 11000, loss: 0.441723
 >> iter 12000, loss: 0.438522
 >> iter 13000, loss: 0.336010
 >> iter 14000, loss: 0.487664
 >> iter 15000, loss: 0.418327
 >> iter 16000, loss: 0.256950
 >> iter 17000, loss: 0.326982
 >> iter 18000, loss: 0.412223
 >> iter 19000, loss: 0.383530
 >> iter 20000, loss: 0.424171
   Number of active neurons: 5
 >> iter 21000, loss: 0.384192
 >> iter 22000, loss: 0.566583
 >> iter 23000, loss: 0.411707
 >> iter 24000, loss: 0.365313
 >> iter 25000, loss: 0.297852
 >> iter 26000, loss: 0.293501
 >> iter 27000, loss: 0.315631
 >> iter 28000, loss: 0.263705
 >> iter 29000, loss: 0.259881
 >> iter 30000, loss: 0.240261
   Number of active neurons: 5
 >> iter 31000, loss: 0.284355
 >> iter 32000, loss: 0.229837
 >> iter 33000, loss: 0.299079
 >> iter 34000, loss: 0.305321
 >> iter 35000, loss: 0.406749
 >> iter 36000, loss: 0.509305
 >> iter 37000, loss: 0.402930
 >> iter 38000, loss: 0.380172
 >> iter 39000, loss: 0.380930
 >> iter 40000, loss: 0.346252
   Number of active neurons: 5
 >> iter 41000, loss: 0.312882
 >> iter 42000, loss: 0.283549
 >> iter 43000, loss: 0.263578
 >> iter 44000, loss: 0.288675
 >> iter 45000, loss: 0.340711
 >> iter 46000, loss: 0.326475
 >> iter 47000, loss: 0.406297
 >> iter 48000, loss: 0.313541
 >> iter 49000, loss: 0.297638
 >> iter 50000, loss: 0.255315
   Number of active neurons: 5
 >> iter 51000, loss: 0.230365
 >> iter 52000, loss: 0.404227
 >> iter 53000, loss: 0.261250
 >> iter 54000, loss: 0.224039
 >> iter 55000, loss: 0.192238
 >> iter 56000, loss: 0.228776
 >> iter 57000, loss: 0.299319
 >> iter 58000, loss: 0.338304
 >> iter 59000, loss: 0.244987
 >> iter 60000, loss: 0.317127
   Number of active neurons: 5
 >> iter 61000, loss: 0.355213
 >> iter 62000, loss: 0.292445
 >> iter 63000, loss: 0.265562
 >> iter 64000, loss: 0.176085
 >> iter 65000, loss: 0.178627
 >> iter 66000, loss: 0.344308
 >> iter 67000, loss: 0.497975
 >> iter 68000, loss: 0.439519
 >> iter 69000, loss: 0.400029
 >> iter 70000, loss: 0.202820
   Number of active neurons: 5
 >> iter 71000, loss: 0.301465
 >> iter 72000, loss: 0.438533
 >> iter 73000, loss: 0.306759
 >> iter 74000, loss: 0.271226
 >> iter 75000, loss: 0.378549
 >> iter 76000, loss: 0.230109
 >> iter 77000, loss: 0.250388
 >> iter 78000, loss: 0.187061
 >> iter 79000, loss: 0.317043
 >> iter 80000, loss: 0.509076
   Number of active neurons: 4
 >> iter 81000, loss: 0.470915
 >> iter 82000, loss: 0.450709
 >> iter 83000, loss: 0.359781
 >> iter 84000, loss: 0.225085
 >> iter 85000, loss: 0.198494
 >> iter 86000, loss: 0.314788
 >> iter 87000, loss: 0.464623
 >> iter 88000, loss: 0.263574
 >> iter 89000, loss: 0.227772
 >> iter 90000, loss: 0.177508
   Number of active neurons: 4
 >> iter 91000, loss: 0.146649
 >> iter 92000, loss: 0.241508
 >> iter 93000, loss: 0.205929
 >> iter 94000, loss: 0.321631
 >> iter 95000, loss: 0.378357
 >> iter 96000, loss: 0.276646
 >> iter 97000, loss: 0.559774
 >> iter 98000, loss: 0.371634
 >> iter 99000, loss: 0.280949
 >> iter 100000, loss: 0.269852
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 18.479379
 >> iter 2000, loss: 11.614169
 >> iter 3000, loss: 6.380627
 >> iter 4000, loss: 2.847191
 >> iter 5000, loss: 1.505744
 >> iter 6000, loss: 0.900586
 >> iter 7000, loss: 0.622277
 >> iter 8000, loss: 0.609886
 >> iter 9000, loss: 0.443235
 >> iter 10000, loss: 0.274669
   Number of active neurons: 7
 >> iter 11000, loss: 0.424408
 >> iter 12000, loss: 0.454236
 >> iter 13000, loss: 0.442873
 >> iter 14000, loss: 0.489314
 >> iter 15000, loss: 0.391476
 >> iter 16000, loss: 0.301544
 >> iter 17000, loss: 0.279362
 >> iter 18000, loss: 0.471381
 >> iter 19000, loss: 0.451037
 >> iter 20000, loss: 0.220727
   Number of active neurons: 5
 >> iter 21000, loss: 0.309160
 >> iter 22000, loss: 0.486223
 >> iter 23000, loss: 0.367944
 >> iter 24000, loss: 0.211407
 >> iter 25000, loss: 0.241584
 >> iter 26000, loss: 0.335945
 >> iter 27000, loss: 0.160357
 >> iter 28000, loss: 0.184583
 >> iter 29000, loss: 0.263915
 >> iter 30000, loss: 0.529764
   Number of active neurons: 5
 >> iter 31000, loss: 0.440515
 >> iter 32000, loss: 0.307793
 >> iter 33000, loss: 0.170776
 >> iter 34000, loss: 0.360242
 >> iter 35000, loss: 0.461103
 >> iter 36000, loss: 0.320423
 >> iter 37000, loss: 0.503507
 >> iter 38000, loss: 0.401514
 >> iter 39000, loss: 0.456865
 >> iter 40000, loss: 0.300523
   Number of active neurons: 5
 >> iter 41000, loss: 0.215837
 >> iter 42000, loss: 0.251444
 >> iter 43000, loss: 0.214262
 >> iter 44000, loss: 0.190731
 >> iter 45000, loss: 0.190852
 >> iter 46000, loss: 0.123526
 >> iter 47000, loss: 0.167922
 >> iter 48000, loss: 0.241972
 >> iter 49000, loss: 0.238465
 >> iter 50000, loss: 0.383153
   Number of active neurons: 3
 >> iter 51000, loss: 0.447160
 >> iter 52000, loss: 0.247291
 >> iter 53000, loss: 0.370224
 >> iter 54000, loss: 0.450140
 >> iter 55000, loss: 0.358065
 >> iter 56000, loss: 0.237829
 >> iter 57000, loss: 0.254043
 >> iter 58000, loss: 0.311856
 >> iter 59000, loss: 0.390221
 >> iter 60000, loss: 0.347154
   Number of active neurons: 3
 >> iter 61000, loss: 0.246480
 >> iter 62000, loss: 0.242496
 >> iter 63000, loss: 0.206845
 >> iter 64000, loss: 0.273236
 >> iter 65000, loss: 0.320243
 >> iter 66000, loss: 0.194985
 >> iter 67000, loss: 0.296134
 >> iter 68000, loss: 0.287784
 >> iter 69000, loss: 0.277348
 >> iter 70000, loss: 0.250014
   Number of active neurons: 3
 >> iter 71000, loss: 0.291644
 >> iter 72000, loss: 0.210009
 >> iter 73000, loss: 0.147790
 >> iter 74000, loss: 0.125654
 >> iter 75000, loss: 0.126162
 >> iter 76000, loss: 0.112514
 >> iter 77000, loss: 0.196233
 >> iter 78000, loss: 0.187614
 >> iter 79000, loss: 0.183884
 >> iter 80000, loss: 0.163071
   Number of active neurons: 3
 >> iter 81000, loss: 0.137687
 >> iter 82000, loss: 0.231952
 >> iter 83000, loss: 0.292425
 >> iter 84000, loss: 0.252896
 >> iter 85000, loss: 0.293300
 >> iter 86000, loss: 0.266370
 >> iter 87000, loss: 0.424456
 >> iter 88000, loss: 0.343216
 >> iter 89000, loss: 0.188652
 >> iter 90000, loss: 0.377593
   Number of active neurons: 3
 >> iter 91000, loss: 0.336082
 >> iter 92000, loss: 0.417491
 >> iter 93000, loss: 0.233634
 >> iter 94000, loss: 0.223579
 >> iter 95000, loss: 0.246907
 >> iter 96000, loss: 0.170658
 >> iter 97000, loss: 0.166914
 >> iter 98000, loss: 0.148920
 >> iter 99000, loss: 0.365871
 >> iter 100000, loss: 0.297608
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.086289
 >> iter 2000, loss: 9.505947
 >> iter 3000, loss: 4.387053
 >> iter 4000, loss: 2.113805
 >> iter 5000, loss: 1.223490
 >> iter 6000, loss: 0.991223
 >> iter 7000, loss: 0.727683
 >> iter 8000, loss: 0.789331
 >> iter 9000, loss: 0.566878
 >> iter 10000, loss: 0.722728
   Number of active neurons: 4
 >> iter 11000, loss: 0.656179
 >> iter 12000, loss: 0.522076
 >> iter 13000, loss: 0.481646
 >> iter 14000, loss: 0.491427
 >> iter 15000, loss: 0.452661
 >> iter 16000, loss: 0.350159
 >> iter 17000, loss: 0.398637
 >> iter 18000, loss: 0.580361
 >> iter 19000, loss: 0.532238
 >> iter 20000, loss: 0.466997
   Number of active neurons: 4
 >> iter 21000, loss: 0.359911
 >> iter 22000, loss: 0.609879
 >> iter 23000, loss: 0.350386
 >> iter 24000, loss: 0.437964
 >> iter 25000, loss: 0.267609
 >> iter 26000, loss: 0.413027
 >> iter 27000, loss: 0.569629
 >> iter 28000, loss: 0.321729
 >> iter 29000, loss: 0.364521
 >> iter 30000, loss: 0.178072
   Number of active neurons: 4
 >> iter 31000, loss: 0.211064
 >> iter 32000, loss: 0.336474
 >> iter 33000, loss: 0.458476
 >> iter 34000, loss: 0.509354
 >> iter 35000, loss: 0.420828
 >> iter 36000, loss: 0.368183
 >> iter 37000, loss: 0.682397
 >> iter 38000, loss: 0.711123
 >> iter 39000, loss: 0.584775
 >> iter 40000, loss: 0.566792
   Number of active neurons: 4
 >> iter 41000, loss: 0.439630
 >> iter 42000, loss: 0.350039
 >> iter 43000, loss: 0.379330
 >> iter 44000, loss: 0.524443
 >> iter 45000, loss: 0.399583
 >> iter 46000, loss: 0.536724
 >> iter 47000, loss: 0.473793
 >> iter 48000, loss: 0.506154
 >> iter 49000, loss: 0.368787
 >> iter 50000, loss: 0.372593
   Number of active neurons: 4
 >> iter 51000, loss: 0.348854
 >> iter 52000, loss: 0.426780
 >> iter 53000, loss: 0.633362
 >> iter 54000, loss: 0.480907
 >> iter 55000, loss: 0.393183
 >> iter 56000, loss: 0.622543
 >> iter 57000, loss: 0.607935
 >> iter 58000, loss: 0.671657
 >> iter 59000, loss: 0.552470
 >> iter 60000, loss: 0.544304
   Number of active neurons: 4
 >> iter 61000, loss: 0.569327
 >> iter 62000, loss: 0.574755
 >> iter 63000, loss: 0.534919
 >> iter 64000, loss: 0.653787
 >> iter 65000, loss: 0.524603
 >> iter 66000, loss: 0.321958
 >> iter 67000, loss: 0.446734
 >> iter 68000, loss: 0.446160
 >> iter 69000, loss: 0.322698
 >> iter 70000, loss: 0.342960
   Number of active neurons: 4
 >> iter 71000, loss: 0.408339
 >> iter 72000, loss: 0.580737
 >> iter 73000, loss: 0.570346
 >> iter 74000, loss: 0.414768
 >> iter 75000, loss: 0.415790
 >> iter 76000, loss: 0.251811
 >> iter 77000, loss: 0.462250
 >> iter 78000, loss: 0.450750
 >> iter 79000, loss: 0.343988
 >> iter 80000, loss: 0.337174
   Number of active neurons: 4
 >> iter 81000, loss: 0.589694
 >> iter 82000, loss: 0.695184
 >> iter 83000, loss: 0.461780
 >> iter 84000, loss: 0.562542
 >> iter 85000, loss: 0.460569
 >> iter 86000, loss: 0.529513
 >> iter 87000, loss: 0.379747
 >> iter 88000, loss: 0.351844
 >> iter 89000, loss: 0.391565
 >> iter 90000, loss: 0.594180
   Number of active neurons: 4
 >> iter 91000, loss: 0.499206
 >> iter 92000, loss: 0.479082
 >> iter 93000, loss: 0.529793
 >> iter 94000, loss: 0.358119
 >> iter 95000, loss: 0.337104
 >> iter 96000, loss: 0.466006
 >> iter 97000, loss: 0.370047
 >> iter 98000, loss: 0.552796
 >> iter 99000, loss: 0.391641
 >> iter 100000, loss: 0.430166
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.672505
 >> iter 2000, loss: 8.422417
 >> iter 3000, loss: 3.578948
 >> iter 4000, loss: 1.549781
 >> iter 5000, loss: 0.736565
 >> iter 6000, loss: 0.773828
 >> iter 7000, loss: 0.406520
 >> iter 8000, loss: 0.342051
 >> iter 9000, loss: 0.494524
 >> iter 10000, loss: 0.487917
   Number of active neurons: 7
 >> iter 11000, loss: 0.433237
 >> iter 12000, loss: 0.229220
 >> iter 13000, loss: 0.206852
 >> iter 14000, loss: 0.243540
 >> iter 15000, loss: 0.194808
 >> iter 16000, loss: 0.478254
 >> iter 17000, loss: 0.320736
 >> iter 18000, loss: 0.246772
 >> iter 19000, loss: 0.281938
 >> iter 20000, loss: 0.336249
   Number of active neurons: 6
 >> iter 21000, loss: 0.388747
 >> iter 22000, loss: 0.413616
 >> iter 23000, loss: 0.362239
 >> iter 24000, loss: 0.384328
 >> iter 25000, loss: 0.292020
 >> iter 26000, loss: 0.181560
 >> iter 27000, loss: 0.202526
 >> iter 28000, loss: 0.436138
 >> iter 29000, loss: 0.450417
 >> iter 30000, loss: 0.233456
   Number of active neurons: 6
 >> iter 31000, loss: 0.294371
 >> iter 32000, loss: 0.299592
 >> iter 33000, loss: 0.310692
 >> iter 34000, loss: 0.235908
 >> iter 35000, loss: 0.462496
 >> iter 36000, loss: 0.282535
 >> iter 37000, loss: 0.290108
 >> iter 38000, loss: 0.384029
 >> iter 39000, loss: 0.400636
 >> iter 40000, loss: 0.192036
   Number of active neurons: 6
 >> iter 41000, loss: 0.314123
 >> iter 42000, loss: 0.326583
 >> iter 43000, loss: 0.248307
 >> iter 44000, loss: 0.237849
 >> iter 45000, loss: 0.351622
 >> iter 46000, loss: 0.314886
 >> iter 47000, loss: 0.352505
 >> iter 48000, loss: 0.319797
 >> iter 49000, loss: 0.197096
 >> iter 50000, loss: 0.204127
   Number of active neurons: 5
 >> iter 51000, loss: 0.162022
 >> iter 52000, loss: 0.226935
 >> iter 53000, loss: 0.167250
 >> iter 54000, loss: 0.279272
 >> iter 55000, loss: 0.303728
 >> iter 56000, loss: 0.320569
 >> iter 57000, loss: 0.287533
 >> iter 58000, loss: 0.375033
 >> iter 59000, loss: 0.345942
 >> iter 60000, loss: 0.328352
   Number of active neurons: 4
 >> iter 61000, loss: 0.220118
 >> iter 62000, loss: 0.181039
 >> iter 63000, loss: 0.269441
 >> iter 64000, loss: 0.231444
 >> iter 65000, loss: 0.146850
 >> iter 66000, loss: 0.123864
 >> iter 67000, loss: 0.102252
 >> iter 68000, loss: 0.262005
 >> iter 69000, loss: 0.188015
 >> iter 70000, loss: 0.313008
   Number of active neurons: 4
 >> iter 71000, loss: 0.219586
 >> iter 72000, loss: 0.117393
 >> iter 73000, loss: 0.331609
 >> iter 74000, loss: 0.337897
 >> iter 75000, loss: 0.324404
 >> iter 76000, loss: 0.213106
 >> iter 77000, loss: 0.300465
 >> iter 78000, loss: 0.186643
 >> iter 79000, loss: 0.159219
 >> iter 80000, loss: 0.393731
   Number of active neurons: 4
 >> iter 81000, loss: 0.211799
 >> iter 82000, loss: 0.268029
 >> iter 83000, loss: 0.209278
 >> iter 84000, loss: 0.191160
 >> iter 85000, loss: 0.229161
 >> iter 86000, loss: 0.264055
 >> iter 87000, loss: 0.149945
 >> iter 88000, loss: 0.246480
 >> iter 89000, loss: 0.178566
 >> iter 90000, loss: 0.165763
   Number of active neurons: 4
 >> iter 91000, loss: 0.165819
 >> iter 92000, loss: 0.132656
 >> iter 93000, loss: 0.318083
 >> iter 94000, loss: 0.334614
 >> iter 95000, loss: 0.288003
 >> iter 96000, loss: 0.389968
 >> iter 97000, loss: 0.193010
 >> iter 98000, loss: 0.226995
 >> iter 99000, loss: 0.278607
 >> iter 100000, loss: 0.289087
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.312706
 >> iter 2000, loss: 8.116491
 >> iter 3000, loss: 3.855948
 >> iter 4000, loss: 1.717384
 >> iter 5000, loss: 1.195940
 >> iter 6000, loss: 0.741287
 >> iter 7000, loss: 0.555160
 >> iter 8000, loss: 0.588994
 >> iter 9000, loss: 0.476210
 >> iter 10000, loss: 0.494547
   Number of active neurons: 6
 >> iter 11000, loss: 0.339907
 >> iter 12000, loss: 0.428405
 >> iter 13000, loss: 0.323191
 >> iter 14000, loss: 0.221223
 >> iter 15000, loss: 0.211559
 >> iter 16000, loss: 0.302760
 >> iter 17000, loss: 0.284877
 >> iter 18000, loss: 0.388154
 >> iter 19000, loss: 0.284075
 >> iter 20000, loss: 0.308830
   Number of active neurons: 4
 >> iter 21000, loss: 0.261199
 >> iter 22000, loss: 0.134657
 >> iter 23000, loss: 0.147065
 >> iter 24000, loss: 0.344158
 >> iter 25000, loss: 0.412171
 >> iter 26000, loss: 0.338880
 >> iter 27000, loss: 0.511155
 >> iter 28000, loss: 0.342777
 >> iter 29000, loss: 0.301571
 >> iter 30000, loss: 0.322777
   Number of active neurons: 4
 >> iter 31000, loss: 0.298536
 >> iter 32000, loss: 0.243563
 >> iter 33000, loss: 0.356103
 >> iter 34000, loss: 0.204556
 >> iter 35000, loss: 0.247372
 >> iter 36000, loss: 0.326821
 >> iter 37000, loss: 0.415276
 >> iter 38000, loss: 0.369381
 >> iter 39000, loss: 0.440764
 >> iter 40000, loss: 0.376230
   Number of active neurons: 4
 >> iter 41000, loss: 0.312283
 >> iter 42000, loss: 0.356438
 >> iter 43000, loss: 0.312763
 >> iter 44000, loss: 0.218114
 >> iter 45000, loss: 0.292292
 >> iter 46000, loss: 0.191840
 >> iter 47000, loss: 0.286683
 >> iter 48000, loss: 0.420648
 >> iter 49000, loss: 0.306525
 >> iter 50000, loss: 0.346843
   Number of active neurons: 3
 >> iter 51000, loss: 0.311012
 >> iter 52000, loss: 0.290497
 >> iter 53000, loss: 0.274101
 >> iter 54000, loss: 0.213065
 >> iter 55000, loss: 0.152545
 >> iter 56000, loss: 0.197138
 >> iter 57000, loss: 0.257740
 >> iter 58000, loss: 0.360173
 >> iter 59000, loss: 0.264316
 >> iter 60000, loss: 0.268120
   Number of active neurons: 3
 >> iter 61000, loss: 0.202232
 >> iter 62000, loss: 0.105907
 >> iter 63000, loss: 0.150379
 >> iter 64000, loss: 0.236937
 >> iter 65000, loss: 0.183819
 >> iter 66000, loss: 0.239735
 >> iter 67000, loss: 0.154390
 >> iter 68000, loss: 0.315553
 >> iter 69000, loss: 0.255060
 >> iter 70000, loss: 0.272846
   Number of active neurons: 3
 >> iter 71000, loss: 0.206868
 >> iter 72000, loss: 0.431050
 >> iter 73000, loss: 0.238040
 >> iter 74000, loss: 0.264224
 >> iter 75000, loss: 0.169874
 >> iter 76000, loss: 0.173171
 >> iter 77000, loss: 0.229680
 >> iter 78000, loss: 0.239892
 >> iter 79000, loss: 0.313913
 >> iter 80000, loss: 0.335034
   Number of active neurons: 3
 >> iter 81000, loss: 0.294739
 >> iter 82000, loss: 0.365161
 >> iter 83000, loss: 0.290548
 >> iter 84000, loss: 0.461195
 >> iter 85000, loss: 0.426877
 >> iter 86000, loss: 0.210201
 >> iter 87000, loss: 0.336358
 >> iter 88000, loss: 0.228639
 >> iter 89000, loss: 0.144834
 >> iter 90000, loss: 0.177608
   Number of active neurons: 3
 >> iter 91000, loss: 0.203890
 >> iter 92000, loss: 0.201064
 >> iter 93000, loss: 0.294897
 >> iter 94000, loss: 0.174437
 >> iter 95000, loss: 0.279384
 >> iter 96000, loss: 0.213392
 >> iter 97000, loss: 0.181947
 >> iter 98000, loss: 0.162600
 >> iter 99000, loss: 0.163091
 >> iter 100000, loss: 0.244337
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 18.376010
 >> iter 2000, loss: 8.610792
 >> iter 3000, loss: 3.843908
 >> iter 4000, loss: 1.955634
 >> iter 5000, loss: 1.015023
 >> iter 6000, loss: 0.847408
 >> iter 7000, loss: 0.869843
 >> iter 8000, loss: 0.458314
 >> iter 9000, loss: 0.696482
 >> iter 10000, loss: 0.493110
   Number of active neurons: 6
 >> iter 11000, loss: 0.328631
 >> iter 12000, loss: 0.390133
 >> iter 13000, loss: 0.386408
 >> iter 14000, loss: 0.305704
 >> iter 15000, loss: 0.308723
 >> iter 16000, loss: 0.336086
 >> iter 17000, loss: 0.461174
 >> iter 18000, loss: 0.411775
 >> iter 19000, loss: 0.453385
 >> iter 20000, loss: 0.349685
   Number of active neurons: 4
 >> iter 21000, loss: 0.214514
 >> iter 22000, loss: 0.270001
 >> iter 23000, loss: 0.297042
 >> iter 24000, loss: 0.269969
 >> iter 25000, loss: 0.350057
 >> iter 26000, loss: 0.234682
 >> iter 27000, loss: 0.429778
 >> iter 28000, loss: 0.302643
 >> iter 29000, loss: 0.257202
 >> iter 30000, loss: 0.418718
   Number of active neurons: 4
 >> iter 31000, loss: 0.233358
 >> iter 32000, loss: 0.262603
 >> iter 33000, loss: 0.210263
 >> iter 34000, loss: 0.360817
 >> iter 35000, loss: 0.436651
 >> iter 36000, loss: 0.462256
 >> iter 37000, loss: 0.290649
 >> iter 38000, loss: 0.216752
 >> iter 39000, loss: 0.386726
 >> iter 40000, loss: 0.329577
   Number of active neurons: 4
 >> iter 41000, loss: 0.318423
 >> iter 42000, loss: 0.377174
 >> iter 43000, loss: 0.315134
 >> iter 44000, loss: 0.224690
 >> iter 45000, loss: 0.212129
 >> iter 46000, loss: 0.117174
 >> iter 47000, loss: 0.408223
 >> iter 48000, loss: 0.249821
 >> iter 49000, loss: 0.139699
 >> iter 50000, loss: 0.409518
   Number of active neurons: 3
 >> iter 51000, loss: 0.304496
 >> iter 52000, loss: 0.252131
 >> iter 53000, loss: 0.422172
 >> iter 54000, loss: 0.441666
 >> iter 55000, loss: 0.393936
 >> iter 56000, loss: 0.207875
 >> iter 57000, loss: 0.246486
 >> iter 58000, loss: 0.216421
 >> iter 59000, loss: 0.286306
 >> iter 60000, loss: 0.196081
   Number of active neurons: 3
 >> iter 61000, loss: 0.189593
 >> iter 62000, loss: 0.157931
 >> iter 63000, loss: 0.244435
 >> iter 64000, loss: 0.370057
 >> iter 65000, loss: 0.408809
 >> iter 66000, loss: 0.345553
 >> iter 67000, loss: 0.316303
 >> iter 68000, loss: 0.271103
 >> iter 69000, loss: 0.367402
 >> iter 70000, loss: 0.263956
   Number of active neurons: 3
 >> iter 71000, loss: 0.217940
 >> iter 72000, loss: 0.267424
 >> iter 73000, loss: 0.265030
 >> iter 74000, loss: 0.435308
 >> iter 75000, loss: 0.217177
 >> iter 76000, loss: 0.470110
 >> iter 77000, loss: 0.303769
 >> iter 78000, loss: 0.281792
 >> iter 79000, loss: 0.280659
 >> iter 80000, loss: 0.165925
   Number of active neurons: 3
 >> iter 81000, loss: 0.149744
 >> iter 82000, loss: 0.135580
 >> iter 83000, loss: 0.393006
 >> iter 84000, loss: 0.304646
 >> iter 85000, loss: 0.358217
 >> iter 86000, loss: 0.240852
 >> iter 87000, loss: 0.238980
 >> iter 88000, loss: 0.320138
 >> iter 89000, loss: 0.319833
 >> iter 90000, loss: 0.165600
   Number of active neurons: 3
 >> iter 91000, loss: 0.197987
 >> iter 92000, loss: 0.331523
 >> iter 93000, loss: 0.250089
 >> iter 94000, loss: 0.279193
 >> iter 95000, loss: 0.152937
 >> iter 96000, loss: 0.079459
 >> iter 97000, loss: 0.268781
 >> iter 98000, loss: 0.220461
 >> iter 99000, loss: 0.211168
 >> iter 100000, loss: 0.290793
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

