 > Problema: tomita5nueva
 > Args:
   - Hidden size: 2
   - Noise level: 0.0
   - Regu L1: 0.0
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.639259
 >> iter 2000, loss: 10.480897
 >> iter 3000, loss: 8.585860
 >> iter 4000, loss: 7.870614
 >> iter 5000, loss: 7.619391
 >> iter 6000, loss: 7.327902
 >> iter 7000, loss: 6.955244
 >> iter 8000, loss: 6.774549
 >> iter 9000, loss: 6.690086
 >> iter 10000, loss: 6.644168
   Number of active neurons: 2
 >> iter 11000, loss: 6.621121
 >> iter 12000, loss: 6.600059
 >> iter 13000, loss: 6.589881
 >> iter 14000, loss: 6.568778
 >> iter 15000, loss: 6.563409
 >> iter 16000, loss: 6.543253
 >> iter 17000, loss: 6.543362
 >> iter 18000, loss: 6.519589
 >> iter 19000, loss: 6.514960
 >> iter 20000, loss: 6.486985
   Number of active neurons: 2
 >> iter 21000, loss: 6.481932
 >> iter 22000, loss: 6.455331
 >> iter 23000, loss: 6.451768
 >> iter 24000, loss: 6.426811
 >> iter 25000, loss: 6.426581
 >> iter 26000, loss: 6.403668
 >> iter 27000, loss: 6.404813
 >> iter 28000, loss: 6.383936
 >> iter 29000, loss: 6.386310
 >> iter 30000, loss: 6.366570
   Number of active neurons: 2
 >> iter 31000, loss: 6.369808
 >> iter 32000, loss: 6.358237
 >> iter 33000, loss: 6.357962
 >> iter 34000, loss: 6.346278
 >> iter 35000, loss: 6.346218
 >> iter 36000, loss: 6.332347
 >> iter 37000, loss: 6.334760
 >> iter 38000, loss: 6.319486
 >> iter 39000, loss: 6.323391
 >> iter 40000, loss: 6.310562
   Number of active neurons: 2
 >> iter 41000, loss: 6.313189
 >> iter 42000, loss: 6.300787
 >> iter 43000, loss: 6.302574
 >> iter 44000, loss: 6.291389
 >> iter 45000, loss: 6.294428
 >> iter 46000, loss: 6.286988
 >> iter 47000, loss: 6.289631
 >> iter 48000, loss: 6.294138
 >> iter 49000, loss: 6.291895
 >> iter 50000, loss: 6.292044
   Number of active neurons: 2
 >> iter 51000, loss: 6.288505
 >> iter 52000, loss: 6.288440
 >> iter 53000, loss: 6.285213
 >> iter 54000, loss: 6.283227
 >> iter 55000, loss: 6.281790
 >> iter 56000, loss: 6.280367
 >> iter 57000, loss: 6.279090
 >> iter 58000, loss: 6.277991
 >> iter 59000, loss: 6.274573
 >> iter 60000, loss: 6.278361
   Number of active neurons: 2
 >> iter 61000, loss: 6.274131
 >> iter 62000, loss: 6.278323
 >> iter 63000, loss: 6.272895
 >> iter 64000, loss: 6.281027
 >> iter 65000, loss: 6.272063
 >> iter 66000, loss: 6.278079
 >> iter 67000, loss: 6.268187
 >> iter 68000, loss: 6.278805
 >> iter 69000, loss: 6.267081
 >> iter 70000, loss: 6.279984
   Number of active neurons: 2
 >> iter 71000, loss: 6.266383
 >> iter 72000, loss: 6.282688
 >> iter 73000, loss: 6.266778
 >> iter 74000, loss: 6.284023
 >> iter 75000, loss: 6.264965
 >> iter 76000, loss: 6.282532
 >> iter 77000, loss: 6.263850
 >> iter 78000, loss: 6.282085
 >> iter 79000, loss: 6.261851
 >> iter 80000, loss: 6.388405
   Number of active neurons: 2
 >> iter 81000, loss: 6.297768
 >> iter 82000, loss: 6.402041
 >> iter 83000, loss: 6.304370
 >> iter 84000, loss: 6.402805
 >> iter 85000, loss: 6.301810
 >> iter 86000, loss: 6.402424
 >> iter 87000, loss: 6.301428
 >> iter 88000, loss: 6.404257
 >> iter 89000, loss: 6.299438
 >> iter 90000, loss: 6.404725
   Number of active neurons: 2
 >> iter 91000, loss: 6.297324
 >> iter 92000, loss: 6.406596
 >> iter 93000, loss: 6.296468
 >> iter 94000, loss: 6.403524
 >> iter 95000, loss: 6.295661
 >> iter 96000, loss: 6.402785
 >> iter 97000, loss: 6.298037
 >> iter 98000, loss: 6.404192
 >> iter 99000, loss: 6.297465
 >> iter 100000, loss: 6.406961
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.640547
 >> iter 2000, loss: 10.483767
 >> iter 3000, loss: 8.587247
 >> iter 4000, loss: 7.871437
 >> iter 5000, loss: 7.620985
 >> iter 6000, loss: 7.513704
 >> iter 7000, loss: 7.488213
 >> iter 8000, loss: 7.462728
 >> iter 9000, loss: 7.468498
 >> iter 10000, loss: 7.453653
   Number of active neurons: 2
 >> iter 11000, loss: 7.462463
 >> iter 12000, loss: 7.171936
 >> iter 13000, loss: 6.873569
 >> iter 14000, loss: 6.733533
 >> iter 15000, loss: 6.667890
 >> iter 16000, loss: 6.629890
 >> iter 17000, loss: 6.613032
 >> iter 18000, loss: 6.591124
 >> iter 19000, loss: 6.583042
 >> iter 20000, loss: 6.561588
   Number of active neurons: 2
 >> iter 21000, loss: 6.559009
 >> iter 22000, loss: 6.538218
 >> iter 23000, loss: 6.536571
 >> iter 24000, loss: 6.510993
 >> iter 25000, loss: 6.505476
 >> iter 26000, loss: 6.478814
 >> iter 27000, loss: 6.473491
 >> iter 28000, loss: 6.449268
 >> iter 29000, loss: 6.446360
 >> iter 30000, loss: 6.423001
   Number of active neurons: 2
 >> iter 31000, loss: 6.422739
 >> iter 32000, loss: 6.402646
 >> iter 33000, loss: 6.402802
 >> iter 34000, loss: 6.383336
 >> iter 35000, loss: 6.384703
 >> iter 36000, loss: 6.364949
 >> iter 37000, loss: 6.368154
 >> iter 38000, loss: 6.352016
 >> iter 39000, loss: 6.353937
 >> iter 40000, loss: 6.339726
   Number of active neurons: 2
 >> iter 41000, loss: 6.340221
 >> iter 42000, loss: 6.326887
 >> iter 43000, loss: 6.326596
 >> iter 44000, loss: 6.313633
 >> iter 45000, loss: 6.315407
 >> iter 46000, loss: 6.306749
 >> iter 47000, loss: 6.308304
 >> iter 48000, loss: 6.294311
 >> iter 49000, loss: 6.301783
 >> iter 50000, loss: 6.288048
   Number of active neurons: 2
 >> iter 51000, loss: 6.295487
 >> iter 52000, loss: 6.298024
 >> iter 53000, loss: 6.296427
 >> iter 54000, loss: 6.293730
 >> iter 55000, loss: 6.292637
 >> iter 56000, loss: 6.289575
 >> iter 57000, loss: 6.288875
 >> iter 58000, loss: 6.285641
 >> iter 59000, loss: 6.283254
 >> iter 60000, loss: 6.284450
   Number of active neurons: 2
 >> iter 61000, loss: 6.281746
 >> iter 62000, loss: 6.282747
 >> iter 63000, loss: 6.279472
 >> iter 64000, loss: 6.283562
 >> iter 65000, loss: 6.277567
 >> iter 66000, loss: 6.278626
 >> iter 67000, loss: 6.272619
 >> iter 68000, loss: 6.277536
 >> iter 69000, loss: 6.270523
 >> iter 70000, loss: 6.277600
   Number of active neurons: 2
 >> iter 71000, loss: 6.269111
 >> iter 72000, loss: 6.280249
 >> iter 73000, loss: 6.269198
 >> iter 74000, loss: 6.283060
 >> iter 75000, loss: 6.267668
 >> iter 76000, loss: 6.284106
 >> iter 77000, loss: 6.267250
 >> iter 78000, loss: 6.285332
 >> iter 79000, loss: 6.265640
 >> iter 80000, loss: 6.286335
   Number of active neurons: 2
 >> iter 81000, loss: 6.262023
 >> iter 82000, loss: 6.284474
 >> iter 83000, loss: 6.262252
 >> iter 84000, loss: 6.287170
 >> iter 85000, loss: 6.259784
 >> iter 86000, loss: 6.388643
 >> iter 87000, loss: 6.296967
 >> iter 88000, loss: 6.404469
 >> iter 89000, loss: 6.300153
 >> iter 90000, loss: 6.406246
   Number of active neurons: 2
 >> iter 91000, loss: 6.298549
 >> iter 92000, loss: 6.407788
 >> iter 93000, loss: 6.297600
 >> iter 94000, loss: 6.404355
 >> iter 95000, loss: 6.296674
 >> iter 96000, loss: 6.403339
 >> iter 97000, loss: 6.298949
 >> iter 98000, loss: 6.404544
 >> iter 99000, loss: 6.298291
 >> iter 100000, loss: 6.407188
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 16.5736685266
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.757652
 >> iter 2000, loss: 10.526837
 >> iter 3000, loss: 8.603316
 >> iter 4000, loss: 7.877473
 >> iter 5000, loss: 7.623173
 >> iter 6000, loss: 7.514377
 >> iter 7000, loss: 7.487862
 >> iter 8000, loss: 7.456956
 >> iter 9000, loss: 7.109180
 >> iter 10000, loss: 6.844080
   Number of active neurons: 2
 >> iter 11000, loss: 6.722163
 >> iter 12000, loss: 6.660392
 >> iter 13000, loss: 6.630387
 >> iter 14000, loss: 6.606626
 >> iter 15000, loss: 6.595177
 >> iter 16000, loss: 6.574135
 >> iter 17000, loss: 6.569848
 >> iter 18000, loss: 6.548323
 >> iter 19000, loss: 6.547497
 >> iter 20000, loss: 6.525602
   Number of active neurons: 2
 >> iter 21000, loss: 6.522010
 >> iter 22000, loss: 6.494526
 >> iter 23000, loss: 6.488186
 >> iter 24000, loss: 6.461250
 >> iter 25000, loss: 6.458064
 >> iter 26000, loss: 6.433460
 >> iter 27000, loss: 6.432066
 >> iter 28000, loss: 6.410143
 >> iter 29000, loss: 6.410754
 >> iter 30000, loss: 6.389012
   Number of active neurons: 2
 >> iter 31000, loss: 6.391404
 >> iter 32000, loss: 6.373094
 >> iter 33000, loss: 6.374873
 >> iter 34000, loss: 6.361447
 >> iter 35000, loss: 6.361691
 >> iter 36000, loss: 6.347212
 >> iter 37000, loss: 6.348785
 >> iter 38000, loss: 6.332900
 >> iter 39000, loss: 6.335792
 >> iter 40000, loss: 6.322396
   Number of active neurons: 2
 >> iter 41000, loss: 6.324142
 >> iter 42000, loss: 6.311616
 >> iter 43000, loss: 6.312422
 >> iter 44000, loss: 6.299700
 >> iter 45000, loss: 6.302714
 >> iter 46000, loss: 6.295527
 >> iter 47000, loss: 6.297442
 >> iter 48000, loss: 6.284709
 >> iter 49000, loss: 6.292228
 >> iter 50000, loss: 6.295499
   Number of active neurons: 2
 >> iter 51000, loss: 6.293211
 >> iter 52000, loss: 6.293174
 >> iter 53000, loss: 6.290083
 >> iter 54000, loss: 6.287425
 >> iter 55000, loss: 6.286189
 >> iter 56000, loss: 6.283936
 >> iter 57000, loss: 6.283027
 >> iter 58000, loss: 6.280810
 >> iter 59000, loss: 6.278021
 >> iter 60000, loss: 6.280506
   Number of active neurons: 2
 >> iter 61000, loss: 6.277136
 >> iter 62000, loss: 6.279697
 >> iter 63000, loss: 6.275450
 >> iter 64000, loss: 6.281447
 >> iter 65000, loss: 6.274116
 >> iter 66000, loss: 6.277607
 >> iter 67000, loss: 6.269771
 >> iter 68000, loss: 6.277775
 >> iter 69000, loss: 6.268325
 >> iter 70000, loss: 6.278718
   Number of active neurons: 2
 >> iter 71000, loss: 6.267414
 >> iter 72000, loss: 6.281879
 >> iter 73000, loss: 6.267857
 >> iter 74000, loss: 6.284561
 >> iter 75000, loss: 6.266435
 >> iter 76000, loss: 6.284314
 >> iter 77000, loss: 6.265679
 >> iter 78000, loss: 6.283819
 >> iter 79000, loss: 6.263567
 >> iter 80000, loss: 6.284179
   Number of active neurons: 2
 >> iter 81000, loss: 6.259838
 >> iter 82000, loss: 6.388178
 >> iter 83000, loss: 6.299712
 >> iter 84000, loss: 6.402207
 >> iter 85000, loss: 6.302034
 >> iter 86000, loss: 6.403411
 >> iter 87000, loss: 6.302233
 >> iter 88000, loss: 6.405129
 >> iter 89000, loss: 6.300203
 >> iter 90000, loss: 6.405343
   Number of active neurons: 2
 >> iter 91000, loss: 6.298005
 >> iter 92000, loss: 6.407066
 >> iter 93000, loss: 6.297101
 >> iter 94000, loss: 6.403859
 >> iter 95000, loss: 6.296239
 >> iter 96000, loss: 6.403024
 >> iter 97000, loss: 6.298569
 >> iter 98000, loss: 6.404369
 >> iter 99000, loss: 6.297957
 >> iter 100000, loss: 6.407093
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.658322
 >> iter 2000, loss: 10.488241
 >> iter 3000, loss: 8.588720
 >> iter 4000, loss: 7.871879
 >> iter 5000, loss: 7.620844
 >> iter 6000, loss: 7.512854
 >> iter 7000, loss: 7.425579
 >> iter 8000, loss: 7.017578
 >> iter 9000, loss: 6.803481
 >> iter 10000, loss: 6.701172
   Number of active neurons: 2
 >> iter 11000, loss: 6.652448
 >> iter 12000, loss: 6.621641
 >> iter 13000, loss: 6.606763
 >> iter 14000, loss: 6.586382
 >> iter 15000, loss: 6.577769
 >> iter 16000, loss: 6.557028
 >> iter 17000, loss: 6.555596
 >> iter 18000, loss: 6.534065
 >> iter 19000, loss: 6.533105
 >> iter 20000, loss: 6.506673
   Number of active neurons: 2
 >> iter 21000, loss: 6.500967
 >> iter 22000, loss: 6.473614
 >> iter 23000, loss: 6.468572
 >> iter 24000, loss: 6.442606
 >> iter 25000, loss: 6.440996
 >> iter 26000, loss: 6.417365
 >> iter 27000, loss: 6.417385
 >> iter 28000, loss: 6.396042
 >> iter 29000, loss: 6.397666
 >> iter 30000, loss: 6.376582
   Number of active neurons: 2
 >> iter 31000, loss: 6.379606
 >> iter 32000, loss: 6.364664
 >> iter 33000, loss: 6.365579
 >> iter 34000, loss: 6.353913
 >> iter 35000, loss: 6.353534
 >> iter 36000, loss: 6.339338
 >> iter 37000, loss: 6.341247
 >> iter 38000, loss: 6.325659
 >> iter 39000, loss: 6.329094
 >> iter 40000, loss: 6.316049
   Number of active neurons: 2
 >> iter 41000, loss: 6.318241
 >> iter 42000, loss: 6.305550
 >> iter 43000, loss: 6.307022
 >> iter 44000, loss: 6.295104
 >> iter 45000, loss: 6.298208
 >> iter 46000, loss: 6.291369
 >> iter 47000, loss: 6.293393
 >> iter 48000, loss: 6.297406
 >> iter 49000, loss: 6.295063
 >> iter 50000, loss: 6.295147
   Number of active neurons: 2
 >> iter 51000, loss: 6.291427
 >> iter 52000, loss: 6.291082
 >> iter 53000, loss: 6.287812
 >> iter 54000, loss: 6.285482
 >> iter 55000, loss: 6.284107
 >> iter 56000, loss: 6.282279
 >> iter 57000, loss: 6.281162
 >> iter 58000, loss: 6.279506
 >> iter 59000, loss: 6.276390
 >> iter 60000, loss: 6.279503
   Number of active neurons: 2
 >> iter 61000, loss: 6.275708
 >> iter 62000, loss: 6.279071
 >> iter 63000, loss: 6.274241
 >> iter 64000, loss: 6.281171
 >> iter 65000, loss: 6.273109
 >> iter 66000, loss: 6.277858
 >> iter 67000, loss: 6.269024
 >> iter 68000, loss: 6.278336
 >> iter 69000, loss: 6.267758
 >> iter 70000, loss: 6.279445
   Number of active neurons: 2
 >> iter 71000, loss: 6.266968
 >> iter 72000, loss: 6.282541
 >> iter 73000, loss: 6.267445
 >> iter 74000, loss: 6.284628
 >> iter 75000, loss: 6.265854
 >> iter 76000, loss: 6.283695
 >> iter 77000, loss: 6.264892
 >> iter 78000, loss: 6.282977
 >> iter 79000, loss: 6.262746
 >> iter 80000, loss: 6.389034
   Number of active neurons: 2
 >> iter 81000, loss: 6.298530
 >> iter 82000, loss: 6.402952
 >> iter 83000, loss: 6.305261
 >> iter 84000, loss: 6.403514
 >> iter 85000, loss: 6.302611
 >> iter 86000, loss: 6.403017
 >> iter 87000, loss: 6.302173
 >> iter 88000, loss: 6.404680
 >> iter 89000, loss: 6.300109
 >> iter 90000, loss: 6.405042
   Number of active neurons: 2
 >> iter 91000, loss: 6.297952
 >> iter 92000, loss: 6.406855
 >> iter 93000, loss: 6.297066
 >> iter 94000, loss: 6.403744
 >> iter 95000, loss: 6.296227
 >> iter 96000, loss: 6.402979
 >> iter 97000, loss: 6.298572
 >> iter 98000, loss: 6.404350
 >> iter 99000, loss: 6.297966
 >> iter 100000, loss: 6.407096
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.564652
 >> iter 2000, loss: 10.452814
 >> iter 3000, loss: 8.575384
 >> iter 4000, loss: 7.866721
 >> iter 5000, loss: 7.618135
 >> iter 6000, loss: 7.386508
 >> iter 7000, loss: 6.988488
 >> iter 8000, loss: 6.790076
 >> iter 9000, loss: 6.697620
 >> iter 10000, loss: 6.648444
   Number of active neurons: 2
 >> iter 11000, loss: 6.623684
 >> iter 12000, loss: 6.602094
 >> iter 13000, loss: 6.591506
 >> iter 14000, loss: 6.570361
 >> iter 15000, loss: 6.564733
 >> iter 16000, loss: 6.544591
 >> iter 17000, loss: 6.544614
 >> iter 18000, loss: 6.521244
 >> iter 19000, loss: 6.516841
 >> iter 20000, loss: 6.488880
   Number of active neurons: 2
 >> iter 21000, loss: 6.483705
 >> iter 22000, loss: 6.457036
 >> iter 23000, loss: 6.453329
 >> iter 24000, loss: 6.428293
 >> iter 25000, loss: 6.427941
 >> iter 26000, loss: 6.404983
 >> iter 27000, loss: 6.406034
 >> iter 28000, loss: 6.385114
 >> iter 29000, loss: 6.387431
 >> iter 30000, loss: 6.367511
   Number of active neurons: 2
 >> iter 31000, loss: 6.370759
 >> iter 32000, loss: 6.358879
 >> iter 33000, loss: 6.358718
 >> iter 34000, loss: 6.347012
 >> iter 35000, loss: 6.346932
 >> iter 36000, loss: 6.333035
 >> iter 37000, loss: 6.335399
 >> iter 38000, loss: 6.320092
 >> iter 39000, loss: 6.323954
 >> iter 40000, loss: 6.311140
   Number of active neurons: 2
 >> iter 41000, loss: 6.313699
 >> iter 42000, loss: 6.301246
 >> iter 43000, loss: 6.303009
 >> iter 44000, loss: 6.291785
 >> iter 45000, loss: 6.294812
 >> iter 46000, loss: 6.287165
 >> iter 47000, loss: 6.289885
 >> iter 48000, loss: 6.294311
 >> iter 49000, loss: 6.292130
 >> iter 50000, loss: 6.292237
   Number of active neurons: 2
 >> iter 51000, loss: 6.288729
 >> iter 52000, loss: 6.288595
 >> iter 53000, loss: 6.285410
 >> iter 54000, loss: 6.283352
 >> iter 55000, loss: 6.281963
 >> iter 56000, loss: 6.280459
 >> iter 57000, loss: 6.279241
 >> iter 58000, loss: 6.278059
 >> iter 59000, loss: 6.274706
 >> iter 60000, loss: 6.278392
   Number of active neurons: 2
 >> iter 61000, loss: 6.274243
 >> iter 62000, loss: 6.278325
 >> iter 63000, loss: 6.272989
 >> iter 64000, loss: 6.280983
 >> iter 65000, loss: 6.272134
 >> iter 66000, loss: 6.278013
 >> iter 67000, loss: 6.268244
 >> iter 68000, loss: 6.278733
 >> iter 69000, loss: 6.267130
 >> iter 70000, loss: 6.279929
   Number of active neurons: 2
 >> iter 71000, loss: 6.266433
 >> iter 72000, loss: 6.282707
 >> iter 73000, loss: 6.266850
 >> iter 74000, loss: 6.284122
 >> iter 75000, loss: 6.265062
 >> iter 76000, loss: 6.282673
 >> iter 77000, loss: 6.263958
 >> iter 78000, loss: 6.282192
 >> iter 79000, loss: 6.261943
 >> iter 80000, loss: 6.388490
   Number of active neurons: 2
 >> iter 81000, loss: 6.297850
 >> iter 82000, loss: 6.402148
 >> iter 83000, loss: 6.304460
 >> iter 84000, loss: 6.402899
 >> iter 85000, loss: 6.301894
 >> iter 86000, loss: 6.402502
 >> iter 87000, loss: 6.301504
 >> iter 88000, loss: 6.404313
 >> iter 89000, loss: 6.299507
 >> iter 90000, loss: 6.404773
   Number of active neurons: 2
 >> iter 91000, loss: 6.297390
 >> iter 92000, loss: 6.406634
 >> iter 93000, loss: 6.296530
 >> iter 94000, loss: 6.403554
 >> iter 95000, loss: 6.295718
 >> iter 96000, loss: 6.402811
 >> iter 97000, loss: 6.298091
 >> iter 98000, loss: 6.404213
 >> iter 99000, loss: 6.297514
 >> iter 100000, loss: 6.406979
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.682735
 >> iter 2000, loss: 10.497317
 >> iter 3000, loss: 8.592031
 >> iter 4000, loss: 7.872988
 >> iter 5000, loss: 7.620676
 >> iter 6000, loss: 7.439123
 >> iter 7000, loss: 7.024250
 >> iter 8000, loss: 6.806472
 >> iter 9000, loss: 6.705433
 >> iter 10000, loss: 6.652468
   Number of active neurons: 2
 >> iter 11000, loss: 6.626053
 >> iter 12000, loss: 6.604008
 >> iter 13000, loss: 6.593220
 >> iter 14000, loss: 6.572046
 >> iter 15000, loss: 6.566140
 >> iter 16000, loss: 6.545953
 >> iter 17000, loss: 6.545883
 >> iter 18000, loss: 6.522913
 >> iter 19000, loss: 6.518901
 >> iter 20000, loss: 6.490983
   Number of active neurons: 2
 >> iter 21000, loss: 6.485705
 >> iter 22000, loss: 6.458940
 >> iter 23000, loss: 6.455075
 >> iter 24000, loss: 6.429929
 >> iter 25000, loss: 6.429438
 >> iter 26000, loss: 6.406412
 >> iter 27000, loss: 6.407356
 >> iter 28000, loss: 6.386383
 >> iter 29000, loss: 6.388628
 >> iter 30000, loss: 6.368517
   Number of active neurons: 2
 >> iter 31000, loss: 6.371764
 >> iter 32000, loss: 6.359449
 >> iter 33000, loss: 6.359468
 >> iter 34000, loss: 6.347752
 >> iter 35000, loss: 6.347660
 >> iter 36000, loss: 6.333737
 >> iter 37000, loss: 6.336051
 >> iter 38000, loss: 6.320709
 >> iter 39000, loss: 6.324526
 >> iter 40000, loss: 6.311730
   Number of active neurons: 2
 >> iter 41000, loss: 6.314216
 >> iter 42000, loss: 6.301712
 >> iter 43000, loss: 6.303448
 >> iter 44000, loss: 6.292185
 >> iter 45000, loss: 6.295198
 >> iter 46000, loss: 6.287443
 >> iter 47000, loss: 6.290207
 >> iter 48000, loss: 6.294625
 >> iter 49000, loss: 6.292444
 >> iter 50000, loss: 6.292560
   Number of active neurons: 2
 >> iter 51000, loss: 6.289026
 >> iter 52000, loss: 6.288863
 >> iter 53000, loss: 6.285673
 >> iter 54000, loss: 6.283578
 >> iter 55000, loss: 6.282196
 >> iter 56000, loss: 6.280644
 >> iter 57000, loss: 6.279448
 >> iter 58000, loss: 6.278204
 >> iter 59000, loss: 6.274887
 >> iter 60000, loss: 6.278498
   Number of active neurons: 2
 >> iter 61000, loss: 6.274399
 >> iter 62000, loss: 6.278388
 >> iter 63000, loss: 6.273122
 >> iter 64000, loss: 6.280984
 >> iter 65000, loss: 6.272235
 >> iter 66000, loss: 6.277975
 >> iter 67000, loss: 6.268323
 >> iter 68000, loss: 6.278670
 >> iter 69000, loss: 6.267193
 >> iter 70000, loss: 6.279863
   Number of active neurons: 2
 >> iter 71000, loss: 6.266488
 >> iter 72000, loss: 6.282695
 >> iter 73000, loss: 6.266919
 >> iter 74000, loss: 6.284187
 >> iter 75000, loss: 6.265153
 >> iter 76000, loss: 6.282787
 >> iter 77000, loss: 6.264061
 >> iter 78000, loss: 6.282270
 >> iter 79000, loss: 6.262028
 >> iter 80000, loss: 6.388530
   Number of active neurons: 2
 >> iter 81000, loss: 6.297921
 >> iter 82000, loss: 6.402225
 >> iter 83000, loss: 6.304543
 >> iter 84000, loss: 6.402972
 >> iter 85000, loss: 6.301973
 >> iter 86000, loss: 6.402566
 >> iter 87000, loss: 6.301579
 >> iter 88000, loss: 6.404355
 >> iter 89000, loss: 6.299573
 >> iter 90000, loss: 6.404807
   Number of active neurons: 2
 >> iter 91000, loss: 6.297452
 >> iter 92000, loss: 6.406664
 >> iter 93000, loss: 6.296590
 >> iter 94000, loss: 6.403577
 >> iter 95000, loss: 6.295774
 >> iter 96000, loss: 6.402831
 >> iter 97000, loss: 6.298143
 >> iter 98000, loss: 6.404228
 >> iter 99000, loss: 6.297563
 >> iter 100000, loss: 6.406992
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.563266
 >> iter 2000, loss: 10.451793
 >> iter 3000, loss: 8.574980
 >> iter 4000, loss: 7.866680
 >> iter 5000, loss: 7.618969
 >> iter 6000, loss: 7.512565
 >> iter 7000, loss: 7.486289
 >> iter 8000, loss: 7.274370
 >> iter 9000, loss: 6.929177
 >> iter 10000, loss: 6.764326
   Number of active neurons: 2
 >> iter 11000, loss: 6.685479
 >> iter 12000, loss: 6.642081
 >> iter 13000, loss: 6.619883
 >> iter 14000, loss: 6.598298
 >> iter 15000, loss: 6.587491
 >> iter 16000, loss: 6.566497
 >> iter 17000, loss: 6.563533
 >> iter 18000, loss: 6.542281
 >> iter 19000, loss: 6.541815
 >> iter 20000, loss: 6.518150
   Number of active neurons: 2
 >> iter 21000, loss: 6.512896
 >> iter 22000, loss: 6.485304
 >> iter 23000, loss: 6.479397
 >> iter 24000, loss: 6.452856
 >> iter 25000, loss: 6.450322
 >> iter 26000, loss: 6.426137
 >> iter 27000, loss: 6.425364
 >> iter 28000, loss: 6.403701
 >> iter 29000, loss: 6.404766
 >> iter 30000, loss: 6.383254
   Number of active neurons: 2
 >> iter 31000, loss: 6.385954
 >> iter 32000, loss: 6.368520
 >> iter 33000, loss: 6.370284
 >> iter 34000, loss: 6.358646
 >> iter 35000, loss: 6.358171
 >> iter 36000, loss: 6.343691
 >> iter 37000, loss: 6.345363
 >> iter 38000, loss: 6.329595
 >> iter 39000, loss: 6.332733
 >> iter 40000, loss: 6.319494
   Number of active neurons: 2
 >> iter 41000, loss: 6.321448
 >> iter 42000, loss: 6.308931
 >> iter 43000, loss: 6.310008
 >> iter 44000, loss: 6.297505
 >> iter 45000, loss: 6.300637
 >> iter 46000, loss: 6.293631
 >> iter 47000, loss: 6.295608
 >> iter 48000, loss: 6.282706
 >> iter 49000, loss: 6.290507
 >> iter 50000, loss: 6.294114
   Number of active neurons: 2
 >> iter 51000, loss: 6.291815
 >> iter 52000, loss: 6.291826
 >> iter 53000, loss: 6.288783
 >> iter 54000, loss: 6.286327
 >> iter 55000, loss: 6.285051
 >> iter 56000, loss: 6.283023
 >> iter 57000, loss: 6.282014
 >> iter 58000, loss: 6.280079
 >> iter 59000, loss: 6.277129
 >> iter 60000, loss: 6.279936
   Number of active neurons: 2
 >> iter 61000, loss: 6.276352
 >> iter 62000, loss: 6.279315
 >> iter 63000, loss: 6.274778
 >> iter 64000, loss: 6.281246
 >> iter 65000, loss: 6.273549
 >> iter 66000, loss: 6.277683
 >> iter 67000, loss: 6.269340
 >> iter 68000, loss: 6.278004
 >> iter 69000, loss: 6.267984
 >> iter 70000, loss: 6.279026
   Number of active neurons: 2
 >> iter 71000, loss: 6.267134
 >> iter 72000, loss: 6.282166
 >> iter 73000, loss: 6.267600
 >> iter 74000, loss: 6.284552
 >> iter 75000, loss: 6.266095
 >> iter 76000, loss: 6.283926
 >> iter 77000, loss: 6.265225
 >> iter 78000, loss: 6.283212
 >> iter 79000, loss: 6.263058
 >> iter 80000, loss: 6.283793
   Number of active neurons: 2
 >> iter 81000, loss: 6.259428
 >> iter 82000, loss: 6.387914
 >> iter 83000, loss: 6.299352
 >> iter 84000, loss: 6.401771
 >> iter 85000, loss: 6.301618
 >> iter 86000, loss: 6.403012
 >> iter 87000, loss: 6.301840
 >> iter 88000, loss: 6.404788
 >> iter 89000, loss: 6.299837
 >> iter 90000, loss: 6.405105
   Number of active neurons: 2
 >> iter 91000, loss: 6.297677
 >> iter 92000, loss: 6.406866
 >> iter 93000, loss: 6.296790
 >> iter 94000, loss: 6.403693
 >> iter 95000, loss: 6.295946
 >> iter 96000, loss: 6.402895
 >> iter 97000, loss: 6.298296
 >> iter 98000, loss: 6.404256
 >> iter 99000, loss: 6.297698
 >> iter 100000, loss: 6.407005
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.600566
 >> iter 2000, loss: 10.466595
 >> iter 3000, loss: 8.580627
 >> iter 4000, loss: 7.868875
 >> iter 5000, loss: 7.619870
 >> iter 6000, loss: 7.513038
 >> iter 7000, loss: 7.487170
 >> iter 8000, loss: 7.437553
 >> iter 9000, loss: 7.050523
 >> iter 10000, loss: 6.817682
   Number of active neurons: 2
 >> iter 11000, loss: 6.710070
 >> iter 12000, loss: 6.654395
 >> iter 13000, loss: 6.627024
 >> iter 14000, loss: 6.604116
 >> iter 15000, loss: 6.592836
 >> iter 16000, loss: 6.571659
 >> iter 17000, loss: 6.567854
 >> iter 18000, loss: 6.546465
 >> iter 19000, loss: 6.545814
 >> iter 20000, loss: 6.523541
   Number of active neurons: 2
 >> iter 21000, loss: 6.519397
 >> iter 22000, loss: 6.491831
 >> iter 23000, loss: 6.485597
 >> iter 24000, loss: 6.458768
 >> iter 25000, loss: 6.455770
 >> iter 26000, loss: 6.431287
 >> iter 27000, loss: 6.430078
 >> iter 28000, loss: 6.408237
 >> iter 29000, loss: 6.408990
 >> iter 30000, loss: 6.387302
   Number of active neurons: 2
 >> iter 31000, loss: 6.389793
 >> iter 32000, loss: 6.371703
 >> iter 33000, loss: 6.373498
 >> iter 34000, loss: 6.360764
 >> iter 35000, loss: 6.360705
 >> iter 36000, loss: 6.346182
 >> iter 37000, loss: 6.347774
 >> iter 38000, loss: 6.331915
 >> iter 39000, loss: 6.334881
 >> iter 40000, loss: 6.321528
   Number of active neurons: 2
 >> iter 41000, loss: 6.323338
 >> iter 42000, loss: 6.310858
 >> iter 43000, loss: 6.311713
 >> iter 44000, loss: 6.299036
 >> iter 45000, loss: 6.302087
 >> iter 46000, loss: 6.294950
 >> iter 47000, loss: 6.296887
 >> iter 48000, loss: 6.283211
 >> iter 49000, loss: 6.291365
 >> iter 50000, loss: 6.294825
   Number of active neurons: 2
 >> iter 51000, loss: 6.292688
 >> iter 52000, loss: 6.292615
 >> iter 53000, loss: 6.289624
 >> iter 54000, loss: 6.286979
 >> iter 55000, loss: 6.285793
 >> iter 56000, loss: 6.283560
 >> iter 57000, loss: 6.282672
 >> iter 58000, loss: 6.280489
 >> iter 59000, loss: 6.277702
 >> iter 60000, loss: 6.280245
   Number of active neurons: 2
 >> iter 61000, loss: 6.276854
 >> iter 62000, loss: 6.279489
 >> iter 63000, loss: 6.275201
 >> iter 64000, loss: 6.281297
 >> iter 65000, loss: 6.273899
 >> iter 66000, loss: 6.277542
 >> iter 67000, loss: 6.269596
 >> iter 68000, loss: 6.277754
 >> iter 69000, loss: 6.268177
 >> iter 70000, loss: 6.278722
   Number of active neurons: 2
 >> iter 71000, loss: 6.267285
 >> iter 72000, loss: 6.281884
 >> iter 73000, loss: 6.267738
 >> iter 74000, loss: 6.284496
 >> iter 75000, loss: 6.266298
 >> iter 76000, loss: 6.284141
 >> iter 77000, loss: 6.265511
 >> iter 78000, loss: 6.283569
 >> iter 79000, loss: 6.263379
 >> iter 80000, loss: 6.283981
   Number of active neurons: 2
 >> iter 81000, loss: 6.259675
 >> iter 82000, loss: 6.388060
 >> iter 83000, loss: 6.299577
 >> iter 84000, loss: 6.402038
 >> iter 85000, loss: 6.301883
 >> iter 86000, loss: 6.403260
 >> iter 87000, loss: 6.302092
 >> iter 88000, loss: 6.405001
 >> iter 89000, loss: 6.300073
 >> iter 90000, loss: 6.405252
   Number of active neurons: 2
 >> iter 91000, loss: 6.297889
 >> iter 92000, loss: 6.406992
 >> iter 93000, loss: 6.296992
 >> iter 94000, loss: 6.403795
 >> iter 95000, loss: 6.296136
 >> iter 96000, loss: 6.402973
 >> iter 97000, loss: 6.298473
 >> iter 98000, loss: 6.404325
 >> iter 99000, loss: 6.297866
 >> iter 100000, loss: 6.407059
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.683770
 >> iter 2000, loss: 10.499948
 >> iter 3000, loss: 8.593385
 >> iter 4000, loss: 7.872982
 >> iter 5000, loss: 7.502329
 >> iter 6000, loss: 7.031176
 >> iter 7000, loss: 6.809550
 >> iter 8000, loss: 6.702067
 >> iter 9000, loss: 6.652320
 >> iter 10000, loss: 6.621091
   Number of active neurons: 2
 >> iter 11000, loss: 6.606122
 >> iter 12000, loss: 6.585806
 >> iter 13000, loss: 6.578268
 >> iter 14000, loss: 6.557609
 >> iter 15000, loss: 6.554005
 >> iter 16000, loss: 6.533631
 >> iter 17000, loss: 6.533241
 >> iter 18000, loss: 6.506226
 >> iter 19000, loss: 6.500905
 >> iter 20000, loss: 6.473093
   Number of active neurons: 2
 >> iter 21000, loss: 6.469030
 >> iter 22000, loss: 6.443103
 >> iter 23000, loss: 6.440649
 >> iter 24000, loss: 6.416403
 >> iter 25000, loss: 6.417067
 >> iter 26000, loss: 6.394553
 >> iter 27000, loss: 6.396372
 >> iter 28000, loss: 6.375979
 >> iter 29000, loss: 6.378732
 >> iter 30000, loss: 6.361781
   Number of active neurons: 2
 >> iter 31000, loss: 6.364104
 >> iter 32000, loss: 6.352717
 >> iter 33000, loss: 6.352494
 >> iter 34000, loss: 6.341116
 >> iter 35000, loss: 6.341326
 >> iter 36000, loss: 6.327675
 >> iter 37000, loss: 6.330435
 >> iter 38000, loss: 6.315395
 >> iter 39000, loss: 6.319586
 >> iter 40000, loss: 6.306568
   Number of active neurons: 2
 >> iter 41000, loss: 6.309665
 >> iter 42000, loss: 6.297924
 >> iter 43000, loss: 6.299692
 >> iter 44000, loss: 6.288721
 >> iter 45000, loss: 6.291815
 >> iter 46000, loss: 6.301773
 >> iter 47000, loss: 6.294016
 >> iter 48000, loss: 6.295044
 >> iter 49000, loss: 6.291276
 >> iter 50000, loss: 6.291122
   Number of active neurons: 2
 >> iter 51000, loss: 6.287303
 >> iter 52000, loss: 6.287451
 >> iter 53000, loss: 6.284062
 >> iter 54000, loss: 6.282364
 >> iter 55000, loss: 6.280757
 >> iter 56000, loss: 6.279718
 >> iter 57000, loss: 6.278198
 >> iter 58000, loss: 6.277510
 >> iter 59000, loss: 6.273795
 >> iter 60000, loss: 6.278119
   Number of active neurons: 2
 >> iter 61000, loss: 6.273489
 >> iter 62000, loss: 6.278293
 >> iter 63000, loss: 6.272376
 >> iter 64000, loss: 6.281317
 >> iter 65000, loss: 6.271701
 >> iter 66000, loss: 6.278567
 >> iter 67000, loss: 6.267935
 >> iter 68000, loss: 6.279401
 >> iter 69000, loss: 6.266904
 >> iter 70000, loss: 6.280527
   Number of active neurons: 2
 >> iter 71000, loss: 6.266221
 >> iter 72000, loss: 6.282848
 >> iter 73000, loss: 6.266504
 >> iter 74000, loss: 6.283781
 >> iter 75000, loss: 6.264571
 >> iter 76000, loss: 6.282248
 >> iter 77000, loss: 6.263468
 >> iter 78000, loss: 6.387478
 >> iter 79000, loss: 6.300956
 >> iter 80000, loss: 6.403463
   Number of active neurons: 2
 >> iter 81000, loss: 6.303639
 >> iter 82000, loss: 6.403734
 >> iter 83000, loss: 6.305300
 >> iter 84000, loss: 6.402757
 >> iter 85000, loss: 6.302081
 >> iter 86000, loss: 6.402269
 >> iter 87000, loss: 6.301641
 >> iter 88000, loss: 6.404162
 >> iter 89000, loss: 6.299659
 >> iter 90000, loss: 6.404685
   Number of active neurons: 2
 >> iter 91000, loss: 6.297547
 >> iter 92000, loss: 6.406624
 >> iter 93000, loss: 6.296701
 >> iter 94000, loss: 6.403591
 >> iter 95000, loss: 6.295893
 >> iter 96000, loss: 6.402864
 >> iter 97000, loss: 6.298261
 >> iter 98000, loss: 6.404272
 >> iter 99000, loss: 6.297678
 >> iter 100000, loss: 6.407035
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.748674
 >> iter 2000, loss: 10.523359
 >> iter 3000, loss: 8.601851
 >> iter 4000, loss: 7.876823
 >> iter 5000, loss: 7.622969
 >> iter 6000, loss: 7.514410
 >> iter 7000, loss: 7.488411
 >> iter 8000, loss: 7.462679
 >> iter 9000, loss: 7.468124
 >> iter 10000, loss: 7.451515
   Number of active neurons: 2
 >> iter 11000, loss: 7.190270
 >> iter 12000, loss: 6.882333
 >> iter 13000, loss: 6.739729
 >> iter 14000, loss: 6.668794
 >> iter 15000, loss: 6.634339
 >> iter 16000, loss: 6.609176
 >> iter 17000, loss: 6.598734
 >> iter 18000, loss: 6.576454
 >> iter 19000, loss: 6.571173
 >> iter 20000, loss: 6.550324
   Number of active neurons: 2
 >> iter 21000, loss: 6.549340
 >> iter 22000, loss: 6.527686
 >> iter 23000, loss: 6.523510
 >> iter 24000, loss: 6.496023
 >> iter 25000, loss: 6.490573
 >> iter 26000, loss: 6.464353
 >> iter 27000, loss: 6.460157
 >> iter 28000, loss: 6.436658
 >> iter 29000, loss: 6.434925
 >> iter 30000, loss: 6.412194
   Number of active neurons: 2
 >> iter 31000, loss: 6.412881
 >> iter 32000, loss: 6.393166
 >> iter 33000, loss: 6.393984
 >> iter 34000, loss: 6.375288
 >> iter 35000, loss: 6.376933
 >> iter 36000, loss: 6.360241
 >> iter 37000, loss: 6.362329
 >> iter 38000, loss: 6.345967
 >> iter 39000, loss: 6.348159
 >> iter 40000, loss: 6.334259
   Number of active neurons: 2
 >> iter 41000, loss: 6.335111
 >> iter 42000, loss: 6.322009
 >> iter 43000, loss: 6.322085
 >> iter 44000, loss: 6.309362
 >> iter 45000, loss: 6.311438
 >> iter 46000, loss: 6.302827
 >> iter 47000, loss: 6.304740
 >> iter 48000, loss: 6.291617
 >> iter 49000, loss: 6.298900
 >> iter 50000, loss: 6.285228
   Number of active neurons: 2
 >> iter 51000, loss: 6.292755
 >> iter 52000, loss: 6.295785
 >> iter 53000, loss: 6.294051
 >> iter 54000, loss: 6.291530
 >> iter 55000, loss: 6.290421
 >> iter 56000, loss: 6.287597
 >> iter 57000, loss: 6.286865
 >> iter 58000, loss: 6.283946
 >> iter 59000, loss: 6.281458
 >> iter 60000, loss: 6.282992
   Number of active neurons: 2
 >> iter 61000, loss: 6.280140
 >> iter 62000, loss: 6.281610
 >> iter 63000, loss: 6.278074
 >> iter 64000, loss: 6.282693
 >> iter 65000, loss: 6.276348
 >> iter 66000, loss: 6.278074
 >> iter 67000, loss: 6.271585
 >> iter 68000, loss: 6.277401
 >> iter 69000, loss: 6.269705
 >> iter 70000, loss: 6.277811
   Number of active neurons: 2
 >> iter 71000, loss: 6.268480
 >> iter 72000, loss: 6.280697
 >> iter 73000, loss: 6.268711
 >> iter 74000, loss: 6.283616
 >> iter 75000, loss: 6.267273
 >> iter 76000, loss: 6.284474
 >> iter 77000, loss: 6.266833
 >> iter 78000, loss: 6.285118
 >> iter 79000, loss: 6.265053
 >> iter 80000, loss: 6.285621
   Number of active neurons: 2
 >> iter 81000, loss: 6.261292
 >> iter 82000, loss: 6.283887
 >> iter 83000, loss: 6.261604
 >> iter 84000, loss: 6.388010
 >> iter 85000, loss: 6.297103
 >> iter 86000, loss: 6.402549
 >> iter 87000, loss: 6.302217
 >> iter 88000, loss: 6.405902
 >> iter 89000, loss: 6.300787
 >> iter 90000, loss: 6.406080
   Number of active neurons: 2
 >> iter 91000, loss: 6.298578
 >> iter 92000, loss: 6.407563
 >> iter 93000, loss: 6.297596
 >> iter 94000, loss: 6.404223
 >> iter 95000, loss: 6.296692
 >> iter 96000, loss: 6.403278
 >> iter 97000, loss: 6.298981
 >> iter 98000, loss: 6.404537
 >> iter 99000, loss: 6.298336
 >> iter 100000, loss: 6.407216
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 16.5736685266
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 15.659541
 >> iter 2000, loss: 10.488937
 >> iter 3000, loss: 8.588905
 >> iter 4000, loss: 7.871624
 >> iter 5000, loss: 7.615441
 >> iter 6000, loss: 7.171029
 >> iter 7000, loss: 6.876392
 >> iter 8000, loss: 6.735451
 >> iter 9000, loss: 6.669925
 >> iter 10000, loss: 6.632103
   Number of active neurons: 2
 >> iter 11000, loss: 6.613510
 >> iter 12000, loss: 6.593327
 >> iter 13000, loss: 6.584303
 >> iter 14000, loss: 6.563330
 >> iter 15000, loss: 6.558831
 >> iter 16000, loss: 6.538596
 >> iter 17000, loss: 6.538758
 >> iter 18000, loss: 6.513297
 >> iter 19000, loss: 6.508112
 >> iter 20000, loss: 6.480170
   Number of active neurons: 2
 >> iter 21000, loss: 6.475583
 >> iter 22000, loss: 6.449292
 >> iter 23000, loss: 6.446270
 >> iter 24000, loss: 6.421650
 >> iter 25000, loss: 6.421867
 >> iter 26000, loss: 6.399150
 >> iter 27000, loss: 6.400634
 >> iter 28000, loss: 6.379959
 >> iter 29000, loss: 6.382535
 >> iter 30000, loss: 6.363502
   Number of active neurons: 2
 >> iter 31000, loss: 6.366673
 >> iter 32000, loss: 6.355503
 >> iter 33000, loss: 6.355228
 >> iter 34000, loss: 6.343677
 >> iter 35000, loss: 6.343755
 >> iter 36000, loss: 6.329993
 >> iter 37000, loss: 6.332584
 >> iter 38000, loss: 6.317427
 >> iter 39000, loss: 6.321477
 >> iter 40000, loss: 6.308559
   Number of active neurons: 2
 >> iter 41000, loss: 6.311421
 >> iter 42000, loss: 6.299247
 >> iter 43000, loss: 6.301085
 >> iter 44000, loss: 6.290029
 >> iter 45000, loss: 6.293103
 >> iter 46000, loss: 6.302751
 >> iter 47000, loss: 6.295107
 >> iter 48000, loss: 6.296044
 >> iter 49000, loss: 6.292304
 >> iter 50000, loss: 6.292036
   Number of active neurons: 2
 >> iter 51000, loss: 6.288239
 >> iter 52000, loss: 6.288236
 >> iter 53000, loss: 6.284899
 >> iter 54000, loss: 6.283041
 >> iter 55000, loss: 6.281505
 >> iter 56000, loss: 6.280248
 >> iter 57000, loss: 6.278850
 >> iter 58000, loss: 6.277920
 >> iter 59000, loss: 6.274367
 >> iter 60000, loss: 6.278374
   Number of active neurons: 2
 >> iter 61000, loss: 6.273971
 >> iter 62000, loss: 6.278409
 >> iter 63000, loss: 6.272776
 >> iter 64000, loss: 6.281240
 >> iter 65000, loss: 6.272003
 >> iter 66000, loss: 6.278370
 >> iter 67000, loss: 6.268168
 >> iter 68000, loss: 6.279144
 >> iter 69000, loss: 6.267091
 >> iter 70000, loss: 6.280319
   Number of active neurons: 2
 >> iter 71000, loss: 6.266403
 >> iter 72000, loss: 6.282893
 >> iter 73000, loss: 6.266759
 >> iter 74000, loss: 6.284075
 >> iter 75000, loss: 6.264898
 >> iter 76000, loss: 6.282533
 >> iter 77000, loss: 6.263774
 >> iter 78000, loss: 6.282588
 >> iter 79000, loss: 6.261950
 >> iter 80000, loss: 6.388591
   Number of active neurons: 2
 >> iter 81000, loss: 6.297778
 >> iter 82000, loss: 6.402007
 >> iter 83000, loss: 6.304302
 >> iter 84000, loss: 6.402737
 >> iter 85000, loss: 6.301732
 >> iter 86000, loss: 6.402360
 >> iter 87000, loss: 6.301351
 >> iter 88000, loss: 6.404214
 >> iter 89000, loss: 6.299370
 >> iter 90000, loss: 6.404687
   Number of active neurons: 2
 >> iter 91000, loss: 6.297258
 >> iter 92000, loss: 6.406567
 >> iter 93000, loss: 6.296407
 >> iter 94000, loss: 6.403504
 >> iter 95000, loss: 6.295604
 >> iter 96000, loss: 6.402767
 >> iter 97000, loss: 6.297984
 >> iter 98000, loss: 6.404178
 >> iter 99000, loss: 6.297415
 >> iter 100000, loss: 6.406950
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.719594
 >> iter 2000, loss: 10.511952
 >> iter 3000, loss: 8.597559
 >> iter 4000, loss: 7.874735
 >> iter 5000, loss: 7.587654
 >> iter 6000, loss: 7.096457
 >> iter 7000, loss: 6.840134
 >> iter 8000, loss: 6.716996
 >> iter 9000, loss: 6.660127
 >> iter 10000, loss: 6.625951
   Number of active neurons: 2
 >> iter 11000, loss: 6.609511
 >> iter 12000, loss: 6.589612
 >> iter 13000, loss: 6.581287
 >> iter 14000, loss: 6.560399
 >> iter 15000, loss: 6.556356
 >> iter 16000, loss: 6.536029
 >> iter 17000, loss: 6.536000
 >> iter 18000, loss: 6.509688
 >> iter 19000, loss: 6.504423
 >> iter 20000, loss: 6.476537
   Number of active neurons: 2
 >> iter 21000, loss: 6.472222
 >> iter 22000, loss: 6.446106
 >> iter 23000, loss: 6.443377
 >> iter 24000, loss: 6.418940
 >> iter 25000, loss: 6.419390
 >> iter 26000, loss: 6.396774
 >> iter 27000, loss: 6.398432
 >> iter 28000, loss: 6.377887
 >> iter 29000, loss: 6.380558
 >> iter 30000, loss: 6.361981
   Number of active neurons: 2
 >> iter 31000, loss: 6.365067
 >> iter 32000, loss: 6.353938
 >> iter 33000, loss: 6.353747
 >> iter 34000, loss: 6.342297
 >> iter 35000, loss: 6.342459
 >> iter 36000, loss: 6.328757
 >> iter 37000, loss: 6.331442
 >> iter 38000, loss: 6.316347
 >> iter 39000, loss: 6.320473
 >> iter 40000, loss: 6.307478
   Number of active neurons: 2
 >> iter 41000, loss: 6.310474
 >> iter 42000, loss: 6.298487
 >> iter 43000, loss: 6.300312
 >> iter 44000, loss: 6.289298
 >> iter 45000, loss: 6.292394
 >> iter 46000, loss: 6.302100
 >> iter 47000, loss: 6.294460
 >> iter 48000, loss: 6.295415
 >> iter 49000, loss: 6.291707
 >> iter 50000, loss: 6.291474
   Number of active neurons: 2
 >> iter 51000, loss: 6.287700
 >> iter 52000, loss: 6.287746
 >> iter 53000, loss: 6.284415
 >> iter 54000, loss: 6.282613
 >> iter 55000, loss: 6.281071
 >> iter 56000, loss: 6.279901
 >> iter 57000, loss: 6.278468
 >> iter 58000, loss: 6.277640
 >> iter 59000, loss: 6.274030
 >> iter 60000, loss: 6.278176
   Number of active neurons: 2
 >> iter 61000, loss: 6.273682
 >> iter 62000, loss: 6.278283
 >> iter 63000, loss: 6.272531
 >> iter 64000, loss: 6.281213
 >> iter 65000, loss: 6.271809
 >> iter 66000, loss: 6.278409
 >> iter 67000, loss: 6.268012
 >> iter 68000, loss: 6.279219
 >> iter 69000, loss: 6.266962
 >> iter 70000, loss: 6.280380
   Number of active neurons: 2
 >> iter 71000, loss: 6.266281
 >> iter 72000, loss: 6.282837
 >> iter 73000, loss: 6.266605
 >> iter 74000, loss: 6.283899
 >> iter 75000, loss: 6.264711
 >> iter 76000, loss: 6.282352
 >> iter 77000, loss: 6.263594
 >> iter 78000, loss: 6.295592
 >> iter 79000, loss: 6.266680
 >> iter 80000, loss: 6.390376
   Number of active neurons: 2
 >> iter 81000, loss: 6.298403
 >> iter 82000, loss: 6.402116
 >> iter 83000, loss: 6.304314
 >> iter 84000, loss: 6.402646
 >> iter 85000, loss: 6.301672
 >> iter 86000, loss: 6.402275
 >> iter 87000, loss: 6.301293
 >> iter 88000, loss: 6.404149
 >> iter 89000, loss: 6.299317
 >> iter 90000, loss: 6.404637
   Number of active neurons: 2
 >> iter 91000, loss: 6.297209
 >> iter 92000, loss: 6.406534
 >> iter 93000, loss: 6.296363
 >> iter 94000, loss: 6.403481
 >> iter 95000, loss: 6.295564
 >> iter 96000, loss: 6.402749
 >> iter 97000, loss: 6.297947
 >> iter 98000, loss: 6.404166
 >> iter 99000, loss: 6.297381
 >> iter 100000, loss: 6.406939
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.742622
 >> iter 2000, loss: 10.521326
 >> iter 3000, loss: 8.601181
 >> iter 4000, loss: 7.876625
 >> iter 5000, loss: 7.622909
 >> iter 6000, loss: 7.514400
 >> iter 7000, loss: 7.488382
 >> iter 8000, loss: 7.462609
 >> iter 9000, loss: 7.467784
 >> iter 10000, loss: 7.419862
   Number of active neurons: 2
 >> iter 11000, loss: 7.034432
 >> iter 12000, loss: 6.809357
 >> iter 13000, loss: 6.705628
 >> iter 14000, loss: 6.651088
 >> iter 15000, loss: 6.624362
 >> iter 16000, loss: 6.602002
 >> iter 17000, loss: 6.592937
 >> iter 18000, loss: 6.570495
 >> iter 19000, loss: 6.566340
 >> iter 20000, loss: 6.545617
   Number of active neurons: 2
 >> iter 21000, loss: 6.545111
 >> iter 22000, loss: 6.522419
 >> iter 23000, loss: 6.516954
 >> iter 24000, loss: 6.489291
 >> iter 25000, loss: 6.484150
 >> iter 26000, loss: 6.458197
 >> iter 27000, loss: 6.454537
 >> iter 28000, loss: 6.431358
 >> iter 29000, loss: 6.430117
 >> iter 30000, loss: 6.407617
   Number of active neurons: 2
 >> iter 31000, loss: 6.408687
 >> iter 32000, loss: 6.389128
 >> iter 33000, loss: 6.390208
 >> iter 34000, loss: 6.372002
 >> iter 35000, loss: 6.373702
 >> iter 36000, loss: 6.358543
 >> iter 37000, loss: 6.359983
 >> iter 38000, loss: 6.343544
 >> iter 39000, loss: 6.345793
 >> iter 40000, loss: 6.331961
   Number of active neurons: 2
 >> iter 41000, loss: 6.332983
 >> iter 42000, loss: 6.319986
 >> iter 43000, loss: 6.320212
 >> iter 44000, loss: 6.307570
 >> iter 45000, loss: 6.309783
 >> iter 46000, loss: 6.301285
 >> iter 47000, loss: 6.303286
 >> iter 48000, loss: 6.290281
 >> iter 49000, loss: 6.297615
 >> iter 50000, loss: 6.283054
   Number of active neurons: 2
 >> iter 51000, loss: 6.291235
 >> iter 52000, loss: 6.294514
 >> iter 53000, loss: 6.292937
 >> iter 54000, loss: 6.290395
 >> iter 55000, loss: 6.289417
 >> iter 56000, loss: 6.286667
 >> iter 57000, loss: 6.285984
 >> iter 58000, loss: 6.283162
 >> iter 59000, loss: 6.280673
 >> iter 60000, loss: 6.282331
   Number of active neurons: 2
 >> iter 61000, loss: 6.279440
 >> iter 62000, loss: 6.281084
 >> iter 63000, loss: 6.277458
 >> iter 64000, loss: 6.282289
 >> iter 65000, loss: 6.275810
 >> iter 66000, loss: 6.277806
 >> iter 67000, loss: 6.271124
 >> iter 68000, loss: 6.277337
 >> iter 69000, loss: 6.269345
 >> iter 70000, loss: 6.277861
   Number of active neurons: 2
 >> iter 71000, loss: 6.268187
 >> iter 72000, loss: 6.280818
 >> iter 73000, loss: 6.268466
 >> iter 74000, loss: 6.283747
 >> iter 75000, loss: 6.267054
 >> iter 76000, loss: 6.284444
 >> iter 77000, loss: 6.266575
 >> iter 78000, loss: 6.284835
 >> iter 79000, loss: 6.264720
 >> iter 80000, loss: 6.285157
   Number of active neurons: 2
 >> iter 81000, loss: 6.260910
 >> iter 82000, loss: 6.283531
 >> iter 83000, loss: 6.261277
 >> iter 84000, loss: 6.387828
 >> iter 85000, loss: 6.296838
 >> iter 86000, loss: 6.402236
 >> iter 87000, loss: 6.301910
 >> iter 88000, loss: 6.405612
 >> iter 89000, loss: 6.300497
 >> iter 90000, loss: 6.405829
   Number of active neurons: 2
 >> iter 91000, loss: 6.298306
 >> iter 92000, loss: 6.407390
 >> iter 93000, loss: 6.297355
 >> iter 94000, loss: 6.404085
 >> iter 95000, loss: 6.296467
 >> iter 96000, loss: 6.403159
 >> iter 97000, loss: 6.298767
 >> iter 98000, loss: 6.404442
 >> iter 99000, loss: 6.298134
 >> iter 100000, loss: 6.407133
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 16.5736685266
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.816814
 >> iter 2000, loss: 10.549470
 >> iter 3000, loss: 8.611858
 >> iter 4000, loss: 7.880687
 >> iter 5000, loss: 7.624293
 >> iter 6000, loss: 7.514463
 >> iter 7000, loss: 7.479304
 >> iter 8000, loss: 7.090378
 >> iter 9000, loss: 6.837352
 >> iter 10000, loss: 6.717496
   Number of active neurons: 2
 >> iter 11000, loss: 6.660863
 >> iter 12000, loss: 6.626725
 >> iter 13000, loss: 6.610175
 >> iter 14000, loss: 6.589883
 >> iter 15000, loss: 6.580665
 >> iter 16000, loss: 6.559764
 >> iter 17000, loss: 6.557935
 >> iter 18000, loss: 6.536503
 >> iter 19000, loss: 6.535957
 >> iter 20000, loss: 6.510260
   Number of active neurons: 2
 >> iter 21000, loss: 6.504606
 >> iter 22000, loss: 6.477159
 >> iter 23000, loss: 6.471864
 >> iter 24000, loss: 6.445721
 >> iter 25000, loss: 6.443844
 >> iter 26000, loss: 6.420047
 >> iter 27000, loss: 6.419844
 >> iter 28000, loss: 6.398417
 >> iter 29000, loss: 6.399887
 >> iter 30000, loss: 6.378644
   Number of active neurons: 2
 >> iter 31000, loss: 6.381588
 >> iter 32000, loss: 6.365034
 >> iter 33000, loss: 6.366691
 >> iter 34000, loss: 6.355277
 >> iter 35000, loss: 6.354922
 >> iter 36000, loss: 6.340649
 >> iter 37000, loss: 6.342500
 >> iter 38000, loss: 6.326857
 >> iter 39000, loss: 6.330208
 >> iter 40000, loss: 6.317104
   Number of active neurons: 2
 >> iter 41000, loss: 6.319224
 >> iter 42000, loss: 6.306562
 >> iter 43000, loss: 6.307922
 >> iter 44000, loss: 6.295749
 >> iter 45000, loss: 6.298906
 >> iter 46000, loss: 6.292022
 >> iter 47000, loss: 6.294045
 >> iter 48000, loss: 6.297787
 >> iter 49000, loss: 6.295564
 >> iter 50000, loss: 6.295555
   Number of active neurons: 2
 >> iter 51000, loss: 6.291907
 >> iter 52000, loss: 6.291471
 >> iter 53000, loss: 6.288256
 >> iter 54000, loss: 6.285809
 >> iter 55000, loss: 6.284501
 >> iter 56000, loss: 6.282556
 >> iter 57000, loss: 6.281514
 >> iter 58000, loss: 6.279708
 >> iter 59000, loss: 6.276693
 >> iter 60000, loss: 6.279649
   Number of active neurons: 2
 >> iter 61000, loss: 6.275971
 >> iter 62000, loss: 6.279136
 >> iter 63000, loss: 6.274459
 >> iter 64000, loss: 6.281166
 >> iter 65000, loss: 6.273287
 >> iter 66000, loss: 6.277752
 >> iter 67000, loss: 6.269151
 >> iter 68000, loss: 6.278173
 >> iter 69000, loss: 6.267851
 >> iter 70000, loss: 6.279260
   Number of active neurons: 2
 >> iter 71000, loss: 6.267041
 >> iter 72000, loss: 6.282399
 >> iter 73000, loss: 6.267522
 >> iter 74000, loss: 6.284639
 >> iter 75000, loss: 6.265978
 >> iter 76000, loss: 6.283849
 >> iter 77000, loss: 6.265059
 >> iter 78000, loss: 6.283117
 >> iter 79000, loss: 6.262899
 >> iter 80000, loss: 6.294463
   Number of active neurons: 2
 >> iter 81000, loss: 6.263263
 >> iter 82000, loss: 6.389503
 >> iter 83000, loss: 6.299890
 >> iter 84000, loss: 6.401870
 >> iter 85000, loss: 6.301613
 >> iter 86000, loss: 6.402922
 >> iter 87000, loss: 6.301768
 >> iter 88000, loss: 6.404700
 >> iter 89000, loss: 6.299766
 >> iter 90000, loss: 6.405039
   Number of active neurons: 2
 >> iter 91000, loss: 6.297613
 >> iter 92000, loss: 6.406813
 >> iter 93000, loss: 6.296730
 >> iter 94000, loss: 6.403657
 >> iter 95000, loss: 6.295892
 >> iter 96000, loss: 6.402870
 >> iter 97000, loss: 6.298246
 >> iter 98000, loss: 6.404235
 >> iter 99000, loss: 6.297651
 >> iter 100000, loss: 6.406991
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.592907
 >> iter 2000, loss: 10.462896
 >> iter 3000, loss: 8.579044
 >> iter 4000, loss: 7.868122
 >> iter 5000, loss: 7.619167
 >> iter 6000, loss: 7.510823
 >> iter 7000, loss: 7.228925
 >> iter 8000, loss: 6.904694
 >> iter 9000, loss: 6.752282
 >> iter 10000, loss: 6.677142
   Number of active neurons: 2
 >> iter 11000, loss: 6.640093
 >> iter 12000, loss: 6.614159
 >> iter 13000, loss: 6.601323
 >> iter 14000, loss: 6.580367
 >> iter 15000, loss: 6.572930
 >> iter 16000, loss: 6.552555
 >> iter 17000, loss: 6.551733
 >> iter 18000, loss: 6.529932
 >> iter 19000, loss: 6.527820
 >> iter 20000, loss: 6.500467
   Number of active neurons: 2
 >> iter 21000, loss: 6.494775
 >> iter 22000, loss: 6.467634
 >> iter 23000, loss: 6.463036
 >> iter 24000, loss: 6.437409
 >> iter 25000, loss: 6.436254
 >> iter 26000, loss: 6.412891
 >> iter 27000, loss: 6.413291
 >> iter 28000, loss: 6.392106
 >> iter 29000, loss: 6.393988
 >> iter 30000, loss: 6.373245
   Number of active neurons: 2
 >> iter 31000, loss: 6.376377
 >> iter 32000, loss: 6.361834
 >> iter 33000, loss: 6.362781
 >> iter 34000, loss: 6.351208
 >> iter 35000, loss: 6.351031
 >> iter 36000, loss: 6.337006
 >> iter 37000, loss: 6.339076
 >> iter 38000, loss: 6.323587
 >> iter 39000, loss: 6.327184
 >> iter 40000, loss: 6.314239
   Number of active neurons: 2
 >> iter 41000, loss: 6.316559
 >> iter 42000, loss: 6.303915
 >> iter 43000, loss: 6.305523
 >> iter 44000, loss: 6.294039
 >> iter 45000, loss: 6.297013
 >> iter 46000, loss: 6.290182
 >> iter 47000, loss: 6.292240
 >> iter 48000, loss: 6.296375
 >> iter 49000, loss: 6.294004
 >> iter 50000, loss: 6.294082
   Number of active neurons: 2
 >> iter 51000, loss: 6.290419
 >> iter 52000, loss: 6.290130
 >> iter 53000, loss: 6.286901
 >> iter 54000, loss: 6.284651
 >> iter 55000, loss: 6.283290
 >> iter 56000, loss: 6.281561
 >> iter 57000, loss: 6.280430
 >> iter 58000, loss: 6.278928
 >> iter 59000, loss: 6.275747
 >> iter 60000, loss: 6.279052
   Number of active neurons: 2
 >> iter 61000, loss: 6.275149
 >> iter 62000, loss: 6.278752
 >> iter 63000, loss: 6.273762
 >> iter 64000, loss: 6.281061
 >> iter 65000, loss: 6.272735
 >> iter 66000, loss: 6.277889
 >> iter 67000, loss: 6.268728
 >> iter 68000, loss: 6.278479
 >> iter 69000, loss: 6.267527
 >> iter 70000, loss: 6.279650
   Number of active neurons: 2
 >> iter 71000, loss: 6.266784
 >> iter 72000, loss: 6.282685
 >> iter 73000, loss: 6.267260
 >> iter 74000, loss: 6.284544
 >> iter 75000, loss: 6.265604
 >> iter 76000, loss: 6.283414
 >> iter 77000, loss: 6.264587
 >> iter 78000, loss: 6.282763
 >> iter 79000, loss: 6.262483
 >> iter 80000, loss: 6.388782
   Number of active neurons: 2
 >> iter 81000, loss: 6.298292
 >> iter 82000, loss: 6.402637
 >> iter 83000, loss: 6.304964
 >> iter 84000, loss: 6.403363
 >> iter 85000, loss: 6.302375
 >> iter 86000, loss: 6.402903
 >> iter 87000, loss: 6.301956
 >> iter 88000, loss: 6.404589
 >> iter 89000, loss: 6.299905
 >> iter 90000, loss: 6.404988
   Number of active neurons: 2
 >> iter 91000, loss: 6.297763
 >> iter 92000, loss: 6.406814
 >> iter 93000, loss: 6.296885
 >> iter 94000, loss: 6.403704
 >> iter 95000, loss: 6.296054
 >> iter 96000, loss: 6.402942
 >> iter 97000, loss: 6.298408
 >> iter 98000, loss: 6.404315
 >> iter 99000, loss: 6.297809
 >> iter 100000, loss: 6.407068
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.836402
 >> iter 2000, loss: 10.557109
 >> iter 3000, loss: 8.614517
 >> iter 4000, loss: 7.881572
 >> iter 5000, loss: 7.624786
 >> iter 6000, loss: 7.515118
 >> iter 7000, loss: 7.488748
 >> iter 8000, loss: 7.462900
 >> iter 9000, loss: 7.468514
 >> iter 10000, loss: 7.453489
   Number of active neurons: 2
 >> iter 11000, loss: 7.454735
 >> iter 12000, loss: 7.091651
 >> iter 13000, loss: 6.835725
 >> iter 14000, loss: 6.715594
 >> iter 15000, loss: 6.658840
 >> iter 16000, loss: 6.624605
 >> iter 17000, loss: 6.609578
 >> iter 18000, loss: 6.587702
 >> iter 19000, loss: 6.580179
 >> iter 20000, loss: 6.558873
   Number of active neurons: 2
 >> iter 21000, loss: 6.556686
 >> iter 22000, loss: 6.535786
 >> iter 23000, loss: 6.533694
 >> iter 24000, loss: 6.507412
 >> iter 25000, loss: 6.501801
 >> iter 26000, loss: 6.475223
 >> iter 27000, loss: 6.470155
 >> iter 28000, loss: 6.446101
 >> iter 29000, loss: 6.443480
 >> iter 30000, loss: 6.420288
   Number of active neurons: 2
 >> iter 31000, loss: 6.420259
 >> iter 32000, loss: 6.400256
 >> iter 33000, loss: 6.400578
 >> iter 34000, loss: 6.381268
 >> iter 35000, loss: 6.382717
 >> iter 36000, loss: 6.363421
 >> iter 37000, loss: 6.366515
 >> iter 38000, loss: 6.350381
 >> iter 39000, loss: 6.352386
 >> iter 40000, loss: 6.338281
   Number of active neurons: 2
 >> iter 41000, loss: 6.338864
 >> iter 42000, loss: 6.325593
 >> iter 43000, loss: 6.325399
 >> iter 44000, loss: 6.312501
 >> iter 45000, loss: 6.314356
 >> iter 46000, loss: 6.305649
 >> iter 47000, loss: 6.307340
 >> iter 48000, loss: 6.293601
 >> iter 49000, loss: 6.301026
 >> iter 50000, loss: 6.287333
   Number of active neurons: 2
 >> iter 51000, loss: 6.294782
 >> iter 52000, loss: 6.297603
 >> iter 53000, loss: 6.295885
 >> iter 54000, loss: 6.293300
 >> iter 55000, loss: 6.292126
 >> iter 56000, loss: 6.289163
 >> iter 57000, loss: 6.288402
 >> iter 58000, loss: 6.285299
 >> iter 59000, loss: 6.282835
 >> iter 60000, loss: 6.284165
   Number of active neurons: 2
 >> iter 61000, loss: 6.281375
 >> iter 62000, loss: 6.282544
 >> iter 63000, loss: 6.279154
 >> iter 64000, loss: 6.283419
 >> iter 65000, loss: 6.277290
 >> iter 66000, loss: 6.278575
 >> iter 67000, loss: 6.272393
 >> iter 68000, loss: 6.277560
 >> iter 69000, loss: 6.270341
 >> iter 70000, loss: 6.277743
   Number of active neurons: 2
 >> iter 71000, loss: 6.268988
 >> iter 72000, loss: 6.280462
 >> iter 73000, loss: 6.269115
 >> iter 74000, loss: 6.283305
 >> iter 75000, loss: 6.267609
 >> iter 76000, loss: 6.284310
 >> iter 77000, loss: 6.267189
 >> iter 78000, loss: 6.285372
 >> iter 79000, loss: 6.265530
 >> iter 80000, loss: 6.286217
   Number of active neurons: 2
 >> iter 81000, loss: 6.261864
 >> iter 82000, loss: 6.284363
 >> iter 83000, loss: 6.262105
 >> iter 84000, loss: 6.388285
 >> iter 85000, loss: 6.297501
 >> iter 86000, loss: 6.403058
 >> iter 87000, loss: 6.302733
 >> iter 88000, loss: 6.406247
 >> iter 89000, loss: 6.301236
 >> iter 90000, loss: 6.406363
   Number of active neurons: 2
 >> iter 91000, loss: 6.298995
 >> iter 92000, loss: 6.407780
 >> iter 93000, loss: 6.297980
 >> iter 94000, loss: 6.404372
 >> iter 95000, loss: 6.297047
 >> iter 96000, loss: 6.403397
 >> iter 97000, loss: 6.299318
 >> iter 98000, loss: 6.404646
 >> iter 99000, loss: 6.298661
 >> iter 100000, loss: 6.407312
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 16.5736685266
   - Test - Long: 23.8738063097
   - Test - Big: 16.3048369516
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.611276
 >> iter 2000, loss: 10.469881
 >> iter 3000, loss: 8.581718
 >> iter 4000, loss: 7.869191
 >> iter 5000, loss: 7.619841
 >> iter 6000, loss: 7.512707
 >> iter 7000, loss: 7.480255
 >> iter 8000, loss: 7.113160
 >> iter 9000, loss: 6.849376
 >> iter 10000, loss: 6.724791
   Number of active neurons: 2
 >> iter 11000, loss: 6.665089
 >> iter 12000, loss: 6.629771
 >> iter 13000, loss: 6.612068
 >> iter 14000, loss: 6.591327
 >> iter 15000, loss: 6.581759
 >> iter 16000, loss: 6.560927
 >> iter 17000, loss: 6.558861
 >> iter 18000, loss: 6.537492
 >> iter 19000, loss: 6.536925
 >> iter 20000, loss: 6.511490
   Number of active neurons: 2
 >> iter 21000, loss: 6.505807
 >> iter 22000, loss: 6.478333
 >> iter 23000, loss: 6.472917
 >> iter 24000, loss: 6.446708
 >> iter 25000, loss: 6.444716
 >> iter 26000, loss: 6.420855
 >> iter 27000, loss: 6.420555
 >> iter 28000, loss: 6.399081
 >> iter 29000, loss: 6.400481
 >> iter 30000, loss: 6.379203
   Number of active neurons: 2
 >> iter 31000, loss: 6.382105
 >> iter 32000, loss: 6.365467
 >> iter 33000, loss: 6.367122
 >> iter 34000, loss: 6.355695
 >> iter 35000, loss: 6.355315
 >> iter 36000, loss: 6.341016
 >> iter 37000, loss: 6.342843
 >> iter 38000, loss: 6.327184
 >> iter 39000, loss: 6.330509
 >> iter 40000, loss: 6.317389
   Number of active neurons: 2
 >> iter 41000, loss: 6.319489
 >> iter 42000, loss: 6.306845
 >> iter 43000, loss: 6.308166
 >> iter 44000, loss: 6.295938
 >> iter 45000, loss: 6.299101
 >> iter 46000, loss: 6.292206
 >> iter 47000, loss: 6.294224
 >> iter 48000, loss: 6.297902
 >> iter 49000, loss: 6.295698
 >> iter 50000, loss: 6.295651
   Number of active neurons: 2
 >> iter 51000, loss: 6.292025
 >> iter 52000, loss: 6.291563
 >> iter 53000, loss: 6.288364
 >> iter 54000, loss: 6.285885
 >> iter 55000, loss: 6.284597
 >> iter 56000, loss: 6.282619
 >> iter 57000, loss: 6.281599
 >> iter 58000, loss: 6.279752
 >> iter 59000, loss: 6.276765
 >> iter 60000, loss: 6.279682
   Number of active neurons: 2
 >> iter 61000, loss: 6.276035
 >> iter 62000, loss: 6.279148
 >> iter 63000, loss: 6.274512
 >> iter 64000, loss: 6.281162
 >> iter 65000, loss: 6.273329
 >> iter 66000, loss: 6.277722
 >> iter 67000, loss: 6.269181
 >> iter 68000, loss: 6.278130
 >> iter 69000, loss: 6.267873
 >> iter 70000, loss: 6.279212
   Number of active neurons: 2
 >> iter 71000, loss: 6.267058
 >> iter 72000, loss: 6.282361
 >> iter 73000, loss: 6.267541
 >> iter 74000, loss: 6.284639
 >> iter 75000, loss: 6.266008
 >> iter 76000, loss: 6.283886
 >> iter 77000, loss: 6.265101
 >> iter 78000, loss: 6.283156
 >> iter 79000, loss: 6.262939
 >> iter 80000, loss: 6.288904
   Number of active neurons: 2
 >> iter 81000, loss: 6.261213
 >> iter 82000, loss: 6.388735
 >> iter 83000, loss: 6.299604
 >> iter 84000, loss: 6.401800
 >> iter 85000, loss: 6.301585
 >> iter 86000, loss: 6.402941
 >> iter 87000, loss: 6.301774
 >> iter 88000, loss: 6.404722
 >> iter 89000, loss: 6.299773
 >> iter 90000, loss: 6.405053
   Number of active neurons: 2
 >> iter 91000, loss: 6.297618
 >> iter 92000, loss: 6.406822
 >> iter 93000, loss: 6.296733
 >> iter 94000, loss: 6.403661
 >> iter 95000, loss: 6.295895
 >> iter 96000, loss: 6.402872
 >> iter 97000, loss: 6.298248
 >> iter 98000, loss: 6.404236
 >> iter 99000, loss: 6.297652
 >> iter 100000, loss: 6.406990
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.755922
 >> iter 2000, loss: 10.528698
 >> iter 3000, loss: 8.604177
 >> iter 4000, loss: 7.877850
 >> iter 5000, loss: 7.623453
 >> iter 6000, loss: 7.514701
 >> iter 7000, loss: 7.488669
 >> iter 8000, loss: 7.463000
 >> iter 9000, loss: 7.468771
 >> iter 10000, loss: 7.454103
   Number of active neurons: 2
 >> iter 11000, loss: 7.464733
 >> iter 12000, loss: 7.450401
 >> iter 13000, loss: 7.233319
 >> iter 14000, loss: 6.899566
 >> iter 15000, loss: 6.745381
 >> iter 16000, loss: 6.670332
 >> iter 17000, loss: 6.636309
 >> iter 18000, loss: 6.609114
 >> iter 19000, loss: 6.598242
 >> iter 20000, loss: 6.576783
   Number of active neurons: 2
 >> iter 21000, loss: 6.571558
 >> iter 22000, loss: 6.550678
 >> iter 23000, loss: 6.548670
 >> iter 24000, loss: 6.526741
 >> iter 25000, loss: 6.523684
 >> iter 26000, loss: 6.497132
 >> iter 27000, loss: 6.490763
 >> iter 28000, loss: 6.465782
 >> iter 29000, loss: 6.461429
 >> iter 30000, loss: 6.437240
   Number of active neurons: 2
 >> iter 31000, loss: 6.435688
 >> iter 32000, loss: 6.415055
 >> iter 33000, loss: 6.414262
 >> iter 34000, loss: 6.394282
 >> iter 35000, loss: 6.395066
 >> iter 36000, loss: 6.373545
 >> iter 37000, loss: 6.376842
 >> iter 38000, loss: 6.358251
 >> iter 39000, loss: 6.360965
 >> iter 40000, loss: 6.346625
   Number of active neurons: 2
 >> iter 41000, loss: 6.346839
 >> iter 42000, loss: 6.333262
 >> iter 43000, loss: 6.332493
 >> iter 44000, loss: 6.319225
 >> iter 45000, loss: 6.320591
 >> iter 46000, loss: 6.312016
 >> iter 47000, loss: 6.313020
 >> iter 48000, loss: 6.298521
 >> iter 49000, loss: 6.305809
 >> iter 50000, loss: 6.291751
   Number of active neurons: 2
 >> iter 51000, loss: 6.299070
 >> iter 52000, loss: 6.285208
 >> iter 53000, loss: 6.293293
 >> iter 54000, loss: 6.293868
 >> iter 55000, loss: 6.294104
 >> iter 56000, loss: 6.291449
 >> iter 57000, loss: 6.290850
 >> iter 58000, loss: 6.287398
 >> iter 59000, loss: 6.285076
 >> iter 60000, loss: 6.285950
   Number of active neurons: 2
 >> iter 61000, loss: 6.283374
 >> iter 62000, loss: 6.283960
 >> iter 63000, loss: 6.280906
 >> iter 64000, loss: 6.284507
 >> iter 65000, loss: 6.278824
 >> iter 66000, loss: 6.279267
 >> iter 67000, loss: 6.273696
 >> iter 68000, loss: 6.277879
 >> iter 69000, loss: 6.271426
 >> iter 70000, loss: 6.277489
   Number of active neurons: 2
 >> iter 71000, loss: 6.269790
 >> iter 72000, loss: 6.279867
 >> iter 73000, loss: 6.269720
 >> iter 74000, loss: 6.282518
 >> iter 75000, loss: 6.268081
 >> iter 76000, loss: 6.283573
 >> iter 77000, loss: 6.267619
 >> iter 78000, loss: 6.285239
 >> iter 79000, loss: 6.266127
 >> iter 80000, loss: 6.286820
   Number of active neurons: 2
 >> iter 81000, loss: 6.262681
 >> iter 82000, loss: 6.285255
 >> iter 83000, loss: 6.262979
 >> iter 84000, loss: 6.283809
 >> iter 85000, loss: 6.258972
 >> iter 86000, loss: 6.388299
 >> iter 87000, loss: 6.297214
 >> iter 88000, loss: 6.404976
 >> iter 89000, loss: 6.300696
 >> iter 90000, loss: 6.406793
   Number of active neurons: 2
 >> iter 91000, loss: 6.299092
 >> iter 92000, loss: 6.408262
 >> iter 93000, loss: 6.298108
 >> iter 94000, loss: 6.404693
 >> iter 95000, loss: 6.297129
 >> iter 96000, loss: 6.403621
 >> iter 97000, loss: 6.299378
 >> iter 98000, loss: 6.404772
 >> iter 99000, loss: 6.298698
 >> iter 100000, loss: 6.407367
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 16.5736685266
   - Test - Long: 23.8738063097
   - Test - Big: 16.3048369516
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.710064
 >> iter 2000, loss: 10.508951
 >> iter 3000, loss: 8.596544
 >> iter 4000, loss: 7.874156
 >> iter 5000, loss: 7.521536
 >> iter 6000, loss: 7.042283
 >> iter 7000, loss: 6.814667
 >> iter 8000, loss: 6.704526
 >> iter 9000, loss: 6.653625
 >> iter 10000, loss: 6.621957
   Number of active neurons: 2
 >> iter 11000, loss: 6.606821
 >> iter 12000, loss: 6.586762
 >> iter 13000, loss: 6.579010
 >> iter 14000, loss: 6.558260
 >> iter 15000, loss: 6.554558
 >> iter 16000, loss: 6.534183
 >> iter 17000, loss: 6.533889
 >> iter 18000, loss: 6.507019
 >> iter 19000, loss: 6.501715
 >> iter 20000, loss: 6.473888
   Number of active neurons: 2
 >> iter 21000, loss: 6.469774
 >> iter 22000, loss: 6.443807
 >> iter 23000, loss: 6.441294
 >> iter 24000, loss: 6.417007
 >> iter 25000, loss: 6.417626
 >> iter 26000, loss: 6.395093
 >> iter 27000, loss: 6.396878
 >> iter 28000, loss: 6.376446
 >> iter 29000, loss: 6.379184
 >> iter 30000, loss: 6.360931
   Number of active neurons: 2
 >> iter 31000, loss: 6.363946
 >> iter 32000, loss: 6.352816
 >> iter 33000, loss: 6.352682
 >> iter 34000, loss: 6.341310
 >> iter 35000, loss: 6.341529
 >> iter 36000, loss: 6.327872
 >> iter 37000, loss: 6.330623
 >> iter 38000, loss: 6.315573
 >> iter 39000, loss: 6.319754
 >> iter 40000, loss: 6.306737
   Number of active neurons: 2
 >> iter 41000, loss: 6.309820
 >> iter 42000, loss: 6.298031
 >> iter 43000, loss: 6.299811
 >> iter 44000, loss: 6.288828
 >> iter 45000, loss: 6.291925
 >> iter 46000, loss: 6.301866
 >> iter 47000, loss: 6.294115
 >> iter 48000, loss: 6.295133
 >> iter 49000, loss: 6.291368
 >> iter 50000, loss: 6.291203
   Number of active neurons: 2
 >> iter 51000, loss: 6.287387
 >> iter 52000, loss: 6.287523
 >> iter 53000, loss: 6.284138
 >> iter 54000, loss: 6.282428
 >> iter 55000, loss: 6.280826
 >> iter 56000, loss: 6.279770
 >> iter 57000, loss: 6.278259
 >> iter 58000, loss: 6.277552
 >> iter 59000, loss: 6.273850
 >> iter 60000, loss: 6.278151
   Number of active neurons: 2
 >> iter 61000, loss: 6.273537
 >> iter 62000, loss: 6.278310
 >> iter 63000, loss: 6.272415
 >> iter 64000, loss: 6.281325
 >> iter 65000, loss: 6.271735
 >> iter 66000, loss: 6.278571
 >> iter 67000, loss: 6.267965
 >> iter 68000, loss: 6.279404
 >> iter 69000, loss: 6.266932
 >> iter 70000, loss: 6.280539
   Number of active neurons: 2
 >> iter 71000, loss: 6.266250
 >> iter 72000, loss: 6.282883
 >> iter 73000, loss: 6.266540
 >> iter 74000, loss: 6.283835
 >> iter 75000, loss: 6.264612
 >> iter 76000, loss: 6.282298
 >> iter 77000, loss: 6.263506
 >> iter 78000, loss: 6.387444
 >> iter 79000, loss: 6.300968
 >> iter 80000, loss: 6.403496
   Number of active neurons: 2
 >> iter 81000, loss: 6.303675
 >> iter 82000, loss: 6.403767
 >> iter 83000, loss: 6.305335
 >> iter 84000, loss: 6.402786
 >> iter 85000, loss: 6.302113
 >> iter 86000, loss: 6.402293
 >> iter 87000, loss: 6.301671
 >> iter 88000, loss: 6.404180
 >> iter 89000, loss: 6.299687
 >> iter 90000, loss: 6.404700
   Number of active neurons: 2
 >> iter 91000, loss: 6.297574
 >> iter 92000, loss: 6.406636
 >> iter 93000, loss: 6.296726
 >> iter 94000, loss: 6.403601
 >> iter 95000, loss: 6.295916
 >> iter 96000, loss: 6.402873
 >> iter 97000, loss: 6.298282
 >> iter 98000, loss: 6.404280
 >> iter 99000, loss: 6.297698
 >> iter 100000, loss: 6.407042
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.585505
 >> iter 2000, loss: 10.461070
 >> iter 3000, loss: 8.578439
 >> iter 4000, loss: 7.867491
 >> iter 5000, loss: 7.571348
 >> iter 6000, loss: 7.084699
 >> iter 7000, loss: 6.835325
 >> iter 8000, loss: 6.715403
 >> iter 9000, loss: 6.659519
 >> iter 10000, loss: 6.625782
   Number of active neurons: 2
 >> iter 11000, loss: 6.609257
 >> iter 12000, loss: 6.588935
 >> iter 13000, loss: 6.580719
 >> iter 14000, loss: 6.559966
 >> iter 15000, loss: 6.555963
 >> iter 16000, loss: 6.535666
 >> iter 17000, loss: 6.535532
 >> iter 18000, loss: 6.509084
 >> iter 19000, loss: 6.503762
 >> iter 20000, loss: 6.475883
   Number of active neurons: 2
 >> iter 21000, loss: 6.471589
 >> iter 22000, loss: 6.445501
 >> iter 23000, loss: 6.442807
 >> iter 24000, loss: 6.418401
 >> iter 25000, loss: 6.418876
 >> iter 26000, loss: 6.396268
 >> iter 27000, loss: 6.397947
 >> iter 28000, loss: 6.377438
 >> iter 29000, loss: 6.380117
 >> iter 30000, loss: 6.361680
   Number of active neurons: 2
 >> iter 31000, loss: 6.364722
 >> iter 32000, loss: 6.353592
 >> iter 33000, loss: 6.353416
 >> iter 34000, loss: 6.341989
 >> iter 35000, loss: 6.342169
 >> iter 36000, loss: 6.328481
 >> iter 37000, loss: 6.331186
 >> iter 38000, loss: 6.316105
 >> iter 39000, loss: 6.320247
 >> iter 40000, loss: 6.307244
   Number of active neurons: 2
 >> iter 41000, loss: 6.310268
 >> iter 42000, loss: 6.298331
 >> iter 43000, loss: 6.300146
 >> iter 44000, loss: 6.289140
 >> iter 45000, loss: 6.292239
 >> iter 46000, loss: 6.302024
 >> iter 47000, loss: 6.294349
 >> iter 48000, loss: 6.295334
 >> iter 49000, loss: 6.291601
 >> iter 50000, loss: 6.291394
   Number of active neurons: 2
 >> iter 51000, loss: 6.287601
 >> iter 52000, loss: 6.287680
 >> iter 53000, loss: 6.284328
 >> iter 54000, loss: 6.282558
 >> iter 55000, loss: 6.280993
 >> iter 56000, loss: 6.279865
 >> iter 57000, loss: 6.278402
 >> iter 58000, loss: 6.277615
 >> iter 59000, loss: 6.273972
 >> iter 60000, loss: 6.278172
   Number of active neurons: 2
 >> iter 61000, loss: 6.273636
 >> iter 62000, loss: 6.278295
 >> iter 63000, loss: 6.272494
 >> iter 64000, loss: 6.281252
 >> iter 65000, loss: 6.271785
 >> iter 66000, loss: 6.278461
 >> iter 67000, loss: 6.267996
 >> iter 68000, loss: 6.279275
 >> iter 69000, loss: 6.266950
 >> iter 70000, loss: 6.280426
   Number of active neurons: 2
 >> iter 71000, loss: 6.266268
 >> iter 72000, loss: 6.282844
 >> iter 73000, loss: 6.266580
 >> iter 74000, loss: 6.283868
 >> iter 75000, loss: 6.264674
 >> iter 76000, loss: 6.282322
 >> iter 77000, loss: 6.263560
 >> iter 78000, loss: 6.386498
 >> iter 79000, loss: 6.300736
 >> iter 80000, loss: 6.403462
   Number of active neurons: 2
 >> iter 81000, loss: 6.303766
 >> iter 82000, loss: 6.403790
 >> iter 83000, loss: 6.305441
 >> iter 84000, loss: 6.402829
 >> iter 85000, loss: 6.302221
 >> iter 86000, loss: 6.402341
 >> iter 87000, loss: 6.301779
 >> iter 88000, loss: 6.404214
 >> iter 89000, loss: 6.299787
 >> iter 90000, loss: 6.404728
   Number of active neurons: 2
 >> iter 91000, loss: 6.297670
 >> iter 92000, loss: 6.406661
 >> iter 93000, loss: 6.296818
 >> iter 94000, loss: 6.403623
 >> iter 95000, loss: 6.296003
 >> iter 96000, loss: 6.402895
 >> iter 97000, loss: 6.298365
 >> iter 98000, loss: 6.404300
 >> iter 99000, loss: 6.297777
 >> iter 100000, loss: 6.407059
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 16.5716685666
   - Test - Long: 23.8738063097
   - Test - Big: 16.3038369616
   - Test - A: 16.1055929605
   - Test - B: 7.35950936604

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

