 > Problema: tomita4nueva
 > Args:
   - Hidden size: 12
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.524914
 >> iter 2000, loss: 8.663046
 >> iter 3000, loss: 4.161617
 >> iter 4000, loss: 2.070671
 >> iter 5000, loss: 1.033653
 >> iter 6000, loss: 0.658031
 >> iter 7000, loss: 0.439049
 >> iter 8000, loss: 0.516823
 >> iter 9000, loss: 0.363651
 >> iter 10000, loss: 0.342349
   Number of active neurons: 5
 >> iter 11000, loss: 0.249822
 >> iter 12000, loss: 0.359341
 >> iter 13000, loss: 0.293261
 >> iter 14000, loss: 0.435259
 >> iter 15000, loss: 0.234327
 >> iter 16000, loss: 0.197220
 >> iter 17000, loss: 0.113398
 >> iter 18000, loss: 0.241685
 >> iter 19000, loss: 0.351060
 >> iter 20000, loss: 0.527325
   Number of active neurons: 5
 >> iter 21000, loss: 0.468200
 >> iter 22000, loss: 0.455230
 >> iter 23000, loss: 0.333397
 >> iter 24000, loss: 0.275128
 >> iter 25000, loss: 0.343934
 >> iter 26000, loss: 0.315589
 >> iter 27000, loss: 0.316542
 >> iter 28000, loss: 0.299752
 >> iter 29000, loss: 0.204715
 >> iter 30000, loss: 0.440548
   Number of active neurons: 4
 >> iter 31000, loss: 0.352008
 >> iter 32000, loss: 0.241924
 >> iter 33000, loss: 0.326113
 >> iter 34000, loss: 0.440783
 >> iter 35000, loss: 0.500846
 >> iter 36000, loss: 0.247189
 >> iter 37000, loss: 0.226721
 >> iter 38000, loss: 0.333439
 >> iter 39000, loss: 0.191842
 >> iter 40000, loss: 0.328209
   Number of active neurons: 4
 >> iter 41000, loss: 0.266320
 >> iter 42000, loss: 0.192987
 >> iter 43000, loss: 0.173531
 >> iter 44000, loss: 0.179096
 >> iter 45000, loss: 0.141620
 >> iter 46000, loss: 0.180253
 >> iter 47000, loss: 0.207382
 >> iter 48000, loss: 0.184056
 >> iter 49000, loss: 0.208992
 >> iter 50000, loss: 0.152985
   Number of active neurons: 4
 >> iter 51000, loss: 0.160803
 >> iter 52000, loss: 0.308402
 >> iter 53000, loss: 0.191197
 >> iter 54000, loss: 0.408010
 >> iter 55000, loss: 0.377029
 >> iter 56000, loss: 0.261040
 >> iter 57000, loss: 0.150342
 >> iter 58000, loss: 0.216266
 >> iter 59000, loss: 0.254381
 >> iter 60000, loss: 0.182879
   Number of active neurons: 4
 >> iter 61000, loss: 0.109499
 >> iter 62000, loss: 0.224217
 >> iter 63000, loss: 0.178296
 >> iter 64000, loss: 0.169967
 >> iter 65000, loss: 0.240153
 >> iter 66000, loss: 0.180623
 >> iter 67000, loss: 0.376421
 >> iter 68000, loss: 0.239537
 >> iter 69000, loss: 0.162313
 >> iter 70000, loss: 0.196053
   Number of active neurons: 4
 >> iter 71000, loss: 0.244592
 >> iter 72000, loss: 0.187311
 >> iter 73000, loss: 0.298190
 >> iter 74000, loss: 0.191925
 >> iter 75000, loss: 0.231214
 >> iter 76000, loss: 0.243486
 >> iter 77000, loss: 0.251131
 >> iter 78000, loss: 0.323508
 >> iter 79000, loss: 0.289107
 >> iter 80000, loss: 0.204113
   Number of active neurons: 4
 >> iter 81000, loss: 0.155663
 >> iter 82000, loss: 0.225304
 >> iter 83000, loss: 0.308250
 >> iter 84000, loss: 0.215785
 >> iter 85000, loss: 0.183937
 >> iter 86000, loss: 0.136862
 >> iter 87000, loss: 0.251544
 >> iter 88000, loss: 0.151677
 >> iter 89000, loss: 0.216311
 >> iter 90000, loss: 0.165646
   Number of active neurons: 3
 >> iter 91000, loss: 0.110093
 >> iter 92000, loss: 0.107034
 >> iter 93000, loss: 0.204981
 >> iter 94000, loss: 0.224992
 >> iter 95000, loss: 0.176622
 >> iter 96000, loss: 0.170966
 >> iter 97000, loss: 0.210331
 >> iter 98000, loss: 0.245015
 >> iter 99000, loss: 0.184924
 >> iter 100000, loss: 0.229760
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.364117
 >> iter 2000, loss: 8.786420
 >> iter 3000, loss: 3.840912
 >> iter 4000, loss: 2.073075
 >> iter 5000, loss: 1.161386
 >> iter 6000, loss: 0.702758
 >> iter 7000, loss: 0.682999
 >> iter 8000, loss: 0.367914
 >> iter 9000, loss: 0.541613
 >> iter 10000, loss: 0.437113
   Number of active neurons: 5
 >> iter 11000, loss: 0.463524
 >> iter 12000, loss: 0.515553
 >> iter 13000, loss: 0.619021
 >> iter 14000, loss: 0.435433
 >> iter 15000, loss: 0.524040
 >> iter 16000, loss: 0.549351
 >> iter 17000, loss: 0.329547
 >> iter 18000, loss: 0.429378
 >> iter 19000, loss: 0.298430
 >> iter 20000, loss: 0.463100
   Number of active neurons: 5
 >> iter 21000, loss: 0.385009
 >> iter 22000, loss: 0.460927
 >> iter 23000, loss: 0.437594
 >> iter 24000, loss: 0.464558
 >> iter 25000, loss: 0.438376
 >> iter 26000, loss: 0.381109
 >> iter 27000, loss: 0.256179
 >> iter 28000, loss: 0.126452
 >> iter 29000, loss: 0.463860
 >> iter 30000, loss: 0.394401
   Number of active neurons: 5
 >> iter 31000, loss: 0.255179
 >> iter 32000, loss: 0.475388
 >> iter 33000, loss: 0.489961
 >> iter 34000, loss: 0.333941
 >> iter 35000, loss: 0.440802
 >> iter 36000, loss: 0.467736
 >> iter 37000, loss: 0.397720
 >> iter 38000, loss: 0.283288
 >> iter 39000, loss: 0.283925
 >> iter 40000, loss: 0.407735
   Number of active neurons: 5
 >> iter 41000, loss: 0.291737
 >> iter 42000, loss: 0.332733
 >> iter 43000, loss: 0.273387
 >> iter 44000, loss: 0.497346
 >> iter 45000, loss: 0.591511
 >> iter 46000, loss: 0.344149
 >> iter 47000, loss: 0.253435
 >> iter 48000, loss: 0.201252
 >> iter 49000, loss: 0.363589
 >> iter 50000, loss: 0.341744
   Number of active neurons: 5
 >> iter 51000, loss: 0.296386
 >> iter 52000, loss: 0.170607
 >> iter 53000, loss: 0.297240
 >> iter 54000, loss: 0.253173
 >> iter 55000, loss: 0.381964
 >> iter 56000, loss: 0.221683
 >> iter 57000, loss: 0.166479
 >> iter 58000, loss: 0.450425
 >> iter 59000, loss: 0.340514
 >> iter 60000, loss: 0.320503
   Number of active neurons: 4
 >> iter 61000, loss: 0.228524
 >> iter 62000, loss: 0.368356
 >> iter 63000, loss: 0.346339
 >> iter 64000, loss: 0.356796
 >> iter 65000, loss: 0.338257
 >> iter 66000, loss: 0.301117
 >> iter 67000, loss: 0.186459
 >> iter 68000, loss: 0.239895
 >> iter 69000, loss: 0.291964
 >> iter 70000, loss: 0.354295
   Number of active neurons: 4
 >> iter 71000, loss: 0.280396
 >> iter 72000, loss: 0.355191
 >> iter 73000, loss: 0.270756
 >> iter 74000, loss: 0.356022
 >> iter 75000, loss: 0.273030
 >> iter 76000, loss: 0.286690
 >> iter 77000, loss: 0.409149
 >> iter 78000, loss: 0.422815
 >> iter 79000, loss: 0.344616
 >> iter 80000, loss: 0.278895
   Number of active neurons: 4
 >> iter 81000, loss: 0.590722
 >> iter 82000, loss: 0.380587
 >> iter 83000, loss: 0.212271
 >> iter 84000, loss: 0.412659
 >> iter 85000, loss: 0.436647
 >> iter 86000, loss: 0.314307
 >> iter 87000, loss: 0.162707
 >> iter 88000, loss: 0.259067
 >> iter 89000, loss: 0.240911
 >> iter 90000, loss: 0.425533
   Number of active neurons: 4
 >> iter 91000, loss: 0.414409
 >> iter 92000, loss: 0.316890
 >> iter 93000, loss: 0.306177
 >> iter 94000, loss: 0.226757
 >> iter 95000, loss: 0.269020
 >> iter 96000, loss: 0.320581
 >> iter 97000, loss: 0.272310
 >> iter 98000, loss: 0.212378
 >> iter 99000, loss: 0.224523
 >> iter 100000, loss: 0.395976
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.498987
 >> iter 2000, loss: 9.315025
 >> iter 3000, loss: 4.578418
 >> iter 4000, loss: 1.997855
 >> iter 5000, loss: 0.971909
 >> iter 6000, loss: 0.841886
 >> iter 7000, loss: 0.503993
 >> iter 8000, loss: 0.482580
 >> iter 9000, loss: 0.432233
 >> iter 10000, loss: 0.460814
   Number of active neurons: 5
 >> iter 11000, loss: 0.483578
 >> iter 12000, loss: 0.507653
 >> iter 13000, loss: 0.538911
 >> iter 14000, loss: 0.523576
 >> iter 15000, loss: 0.459209
 >> iter 16000, loss: 0.524212
 >> iter 17000, loss: 0.293810
 >> iter 18000, loss: 0.457084
 >> iter 19000, loss: 0.330157
 >> iter 20000, loss: 0.404913
   Number of active neurons: 4
 >> iter 21000, loss: 0.493464
 >> iter 22000, loss: 0.281947
 >> iter 23000, loss: 0.398452
 >> iter 24000, loss: 0.276382
 >> iter 25000, loss: 0.224505
 >> iter 26000, loss: 0.303651
 >> iter 27000, loss: 0.401932
 >> iter 28000, loss: 0.328926
 >> iter 29000, loss: 0.321552
 >> iter 30000, loss: 0.635195
   Number of active neurons: 3
 >> iter 31000, loss: 0.590423
 >> iter 32000, loss: 0.407082
 >> iter 33000, loss: 0.298922
 >> iter 34000, loss: 0.183965
 >> iter 35000, loss: 0.142888
 >> iter 36000, loss: 0.527200
 >> iter 37000, loss: 0.311289
 >> iter 38000, loss: 0.361843
 >> iter 39000, loss: 0.293252
 >> iter 40000, loss: 0.327626
   Number of active neurons: 3
 >> iter 41000, loss: 0.261474
 >> iter 42000, loss: 0.196885
 >> iter 43000, loss: 0.542456
 >> iter 44000, loss: 0.292836
 >> iter 45000, loss: 0.304770
 >> iter 46000, loss: 0.342415
 >> iter 47000, loss: 0.167681
 >> iter 48000, loss: 0.235004
 >> iter 49000, loss: 0.242060
 >> iter 50000, loss: 0.224978
   Number of active neurons: 3
 >> iter 51000, loss: 0.236583
 >> iter 52000, loss: 0.456067
 >> iter 53000, loss: 0.293652
 >> iter 54000, loss: 0.244330
 >> iter 55000, loss: 0.348188
 >> iter 56000, loss: 0.422406
 >> iter 57000, loss: 0.267160
 >> iter 58000, loss: 0.336224
 >> iter 59000, loss: 0.416295
 >> iter 60000, loss: 0.237506
   Number of active neurons: 3
 >> iter 61000, loss: 0.154632
 >> iter 62000, loss: 0.301385
 >> iter 63000, loss: 0.544585
 >> iter 64000, loss: 0.302079
 >> iter 65000, loss: 0.383719
 >> iter 66000, loss: 0.446860
 >> iter 67000, loss: 0.281216
 >> iter 68000, loss: 0.287718
 >> iter 69000, loss: 0.292680
 >> iter 70000, loss: 0.188459
   Number of active neurons: 3
 >> iter 71000, loss: 0.323609
 >> iter 72000, loss: 0.423981
 >> iter 73000, loss: 0.381893
 >> iter 74000, loss: 0.248048
 >> iter 75000, loss: 0.143822
 >> iter 76000, loss: 0.199750
 >> iter 77000, loss: 0.268295
 >> iter 78000, loss: 0.293175
 >> iter 79000, loss: 0.231495
 >> iter 80000, loss: 0.167313
   Number of active neurons: 3
 >> iter 81000, loss: 0.212214
 >> iter 82000, loss: 0.251125
 >> iter 83000, loss: 0.293401
 >> iter 84000, loss: 0.212372
 >> iter 85000, loss: 0.182552
 >> iter 86000, loss: 0.130818
 >> iter 87000, loss: 0.199640
 >> iter 88000, loss: 0.110248
 >> iter 89000, loss: 0.342412
 >> iter 90000, loss: 0.254381
   Number of active neurons: 3
 >> iter 91000, loss: 0.136835
 >> iter 92000, loss: 0.133889
 >> iter 93000, loss: 0.211896
 >> iter 94000, loss: 0.139909
 >> iter 95000, loss: 0.101984
 >> iter 96000, loss: 0.101055
 >> iter 97000, loss: 0.213732
 >> iter 98000, loss: 0.338034
 >> iter 99000, loss: 0.428280
 >> iter 100000, loss: 0.382082
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.265559
 >> iter 2000, loss: 9.655393
 >> iter 3000, loss: 4.503324
 >> iter 4000, loss: 2.303308
 >> iter 5000, loss: 1.268435
 >> iter 6000, loss: 0.941453
 >> iter 7000, loss: 0.644456
 >> iter 8000, loss: 0.757452
 >> iter 9000, loss: 0.467744
 >> iter 10000, loss: 0.469198
   Number of active neurons: 5
 >> iter 11000, loss: 0.430471
 >> iter 12000, loss: 0.565546
 >> iter 13000, loss: 0.627335
 >> iter 14000, loss: 0.480930
 >> iter 15000, loss: 0.641776
 >> iter 16000, loss: 0.575911
 >> iter 17000, loss: 0.706400
 >> iter 18000, loss: 0.462586
 >> iter 19000, loss: 0.386155
 >> iter 20000, loss: 0.366837
   Number of active neurons: 4
 >> iter 21000, loss: 0.541049
 >> iter 22000, loss: 0.392556
 >> iter 23000, loss: 0.661231
 >> iter 24000, loss: 0.486118
 >> iter 25000, loss: 0.545758
 >> iter 26000, loss: 0.529862
 >> iter 27000, loss: 0.634988
 >> iter 28000, loss: 0.526947
 >> iter 29000, loss: 0.474937
 >> iter 30000, loss: 0.427479
   Number of active neurons: 4
 >> iter 31000, loss: 0.501545
 >> iter 32000, loss: 0.537530
 >> iter 33000, loss: 0.500825
 >> iter 34000, loss: 0.469946
 >> iter 35000, loss: 0.426277
 >> iter 36000, loss: 0.443717
 >> iter 37000, loss: 0.520546
 >> iter 38000, loss: 0.499983
 >> iter 39000, loss: 0.607753
 >> iter 40000, loss: 0.458261
   Number of active neurons: 4
 >> iter 41000, loss: 0.332586
 >> iter 42000, loss: 0.372365
 >> iter 43000, loss: 0.343747
 >> iter 44000, loss: 0.314339
 >> iter 45000, loss: 0.471823
 >> iter 46000, loss: 0.364441
 >> iter 47000, loss: 0.254566
 >> iter 48000, loss: 0.266283
 >> iter 49000, loss: 0.209543
 >> iter 50000, loss: 0.402740
   Number of active neurons: 4
 >> iter 51000, loss: 0.452705
 >> iter 52000, loss: 0.403681
 >> iter 53000, loss: 0.429045
 >> iter 54000, loss: 0.451130
 >> iter 55000, loss: 0.421739
 >> iter 56000, loss: 0.555867
 >> iter 57000, loss: 0.420475
 >> iter 58000, loss: 0.464721
 >> iter 59000, loss: 0.309217
 >> iter 60000, loss: 0.380142
   Number of active neurons: 4
 >> iter 61000, loss: 0.330294
 >> iter 62000, loss: 0.476389
 >> iter 63000, loss: 0.411569
 >> iter 64000, loss: 0.481334
 >> iter 65000, loss: 0.377583
 >> iter 66000, loss: 0.236935
 >> iter 67000, loss: 0.410182
 >> iter 68000, loss: 0.410190
 >> iter 69000, loss: 0.504954
 >> iter 70000, loss: 0.655071
   Number of active neurons: 4
 >> iter 71000, loss: 0.645004
 >> iter 72000, loss: 0.349441
 >> iter 73000, loss: 0.298498
 >> iter 74000, loss: 0.621347
 >> iter 75000, loss: 0.546389
 >> iter 76000, loss: 0.462496
 >> iter 77000, loss: 0.526893
 >> iter 78000, loss: 0.387931
 >> iter 79000, loss: 0.291016
 >> iter 80000, loss: 0.409891
   Number of active neurons: 4
 >> iter 81000, loss: 0.334843
 >> iter 82000, loss: 0.325825
 >> iter 83000, loss: 0.362699
 >> iter 84000, loss: 0.538254
 >> iter 85000, loss: 0.331902
 >> iter 86000, loss: 0.582374
 >> iter 87000, loss: 0.464372
 >> iter 88000, loss: 0.375744
 >> iter 89000, loss: 0.397243
 >> iter 90000, loss: 0.361216
   Number of active neurons: 4
 >> iter 91000, loss: 0.342983
 >> iter 92000, loss: 0.597263
 >> iter 93000, loss: 0.504144
 >> iter 94000, loss: 0.471212
 >> iter 95000, loss: 0.357167
 >> iter 96000, loss: 0.349029
 >> iter 97000, loss: 0.509496
 >> iter 98000, loss: 0.527457
 >> iter 99000, loss: 0.606694
 >> iter 100000, loss: 0.373566
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.626968
 >> iter 2000, loss: 8.641496
 >> iter 3000, loss: 3.961944
 >> iter 4000, loss: 1.949020
 >> iter 5000, loss: 1.048606
 >> iter 6000, loss: 0.605888
 >> iter 7000, loss: 0.555811
 >> iter 8000, loss: 0.539883
 >> iter 9000, loss: 0.497042
 >> iter 10000, loss: 0.589345
   Number of active neurons: 6
 >> iter 11000, loss: 0.479856
 >> iter 12000, loss: 0.558092
 >> iter 13000, loss: 0.374555
 >> iter 14000, loss: 0.407605
 >> iter 15000, loss: 0.545753
 >> iter 16000, loss: 0.495227
 >> iter 17000, loss: 0.338654
 >> iter 18000, loss: 0.214286
 >> iter 19000, loss: 0.275938
 >> iter 20000, loss: 0.238447
   Number of active neurons: 5
 >> iter 21000, loss: 0.305703
 >> iter 22000, loss: 0.270585
 >> iter 23000, loss: 0.334953
 >> iter 24000, loss: 0.358886
 >> iter 25000, loss: 0.251521
 >> iter 26000, loss: 0.278789
 >> iter 27000, loss: 0.393617
 >> iter 28000, loss: 0.299204
 >> iter 29000, loss: 0.469990
 >> iter 30000, loss: 0.389474
   Number of active neurons: 5
 >> iter 31000, loss: 0.378320
 >> iter 32000, loss: 0.352496
 >> iter 33000, loss: 0.325595
 >> iter 34000, loss: 0.291298
 >> iter 35000, loss: 0.221997
 >> iter 36000, loss: 0.298562
 >> iter 37000, loss: 0.364415
 >> iter 38000, loss: 0.300003
 >> iter 39000, loss: 0.212978
 >> iter 40000, loss: 0.228250
   Number of active neurons: 5
 >> iter 41000, loss: 0.477710
 >> iter 42000, loss: 0.564854
 >> iter 43000, loss: 0.289844
 >> iter 44000, loss: 0.269369
 >> iter 45000, loss: 0.363933
 >> iter 46000, loss: 0.313522
 >> iter 47000, loss: 0.258578
 >> iter 48000, loss: 0.260895
 >> iter 49000, loss: 0.369825
 >> iter 50000, loss: 0.328687
   Number of active neurons: 5
 >> iter 51000, loss: 0.227208
 >> iter 52000, loss: 0.190618
 >> iter 53000, loss: 0.253723
 >> iter 54000, loss: 0.297140
 >> iter 55000, loss: 0.469080
 >> iter 56000, loss: 0.416980
 >> iter 57000, loss: 0.321833
 >> iter 58000, loss: 0.293290
 >> iter 59000, loss: 0.329616
 >> iter 60000, loss: 0.183816
   Number of active neurons: 5
 >> iter 61000, loss: 0.374409
 >> iter 62000, loss: 0.263225
 >> iter 63000, loss: 0.448077
 >> iter 64000, loss: 0.243170
 >> iter 65000, loss: 0.264532
 >> iter 66000, loss: 0.214204
 >> iter 67000, loss: 0.176287
 >> iter 68000, loss: 0.333414
 >> iter 69000, loss: 0.224354
 >> iter 70000, loss: 0.156775
   Number of active neurons: 4
 >> iter 71000, loss: 0.494576
 >> iter 72000, loss: 0.378832
 >> iter 73000, loss: 0.233771
 >> iter 74000, loss: 0.255094
 >> iter 75000, loss: 0.244133
 >> iter 76000, loss: 0.179822
 >> iter 77000, loss: 0.328678
 >> iter 78000, loss: 0.188989
 >> iter 79000, loss: 0.138549
 >> iter 80000, loss: 0.144050
   Number of active neurons: 4
 >> iter 81000, loss: 0.437421
 >> iter 82000, loss: 0.263345
 >> iter 83000, loss: 0.288758
 >> iter 84000, loss: 0.298816
 >> iter 85000, loss: 0.341260
 >> iter 86000, loss: 0.326742
 >> iter 87000, loss: 0.242926
 >> iter 88000, loss: 0.281893
 >> iter 89000, loss: 0.178505
 >> iter 90000, loss: 0.264478
   Number of active neurons: 4
 >> iter 91000, loss: 0.149709
 >> iter 92000, loss: 0.233099
 >> iter 93000, loss: 0.241956
 >> iter 94000, loss: 0.198622
 >> iter 95000, loss: 0.139736
 >> iter 96000, loss: 0.214114
 >> iter 97000, loss: 0.174576
 >> iter 98000, loss: 0.366082
 >> iter 99000, loss: 0.267871
 >> iter 100000, loss: 0.133854
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.831502
 >> iter 2000, loss: 8.613741
 >> iter 3000, loss: 3.857199
 >> iter 4000, loss: 1.668533
 >> iter 5000, loss: 0.847397
 >> iter 6000, loss: 0.505415
 >> iter 7000, loss: 0.469889
 >> iter 8000, loss: 0.345394
 >> iter 9000, loss: 0.494201
 >> iter 10000, loss: 0.349959
   Number of active neurons: 6
 >> iter 11000, loss: 0.236638
 >> iter 12000, loss: 0.247744
 >> iter 13000, loss: 0.181792
 >> iter 14000, loss: 0.283809
 >> iter 15000, loss: 0.237848
 >> iter 16000, loss: 0.541658
 >> iter 17000, loss: 0.440243
 >> iter 18000, loss: 0.471989
 >> iter 19000, loss: 0.448296
 >> iter 20000, loss: 0.553754
   Number of active neurons: 6
 >> iter 21000, loss: 0.361134
 >> iter 22000, loss: 0.269995
 >> iter 23000, loss: 0.447569
 >> iter 24000, loss: 0.436974
 >> iter 25000, loss: 0.383114
 >> iter 26000, loss: 0.331501
 >> iter 27000, loss: 0.191428
 >> iter 28000, loss: 0.332069
 >> iter 29000, loss: 0.282026
 >> iter 30000, loss: 0.233803
   Number of active neurons: 6
 >> iter 31000, loss: 0.220719
 >> iter 32000, loss: 0.405424
 >> iter 33000, loss: 0.292402
 >> iter 34000, loss: 0.332688
 >> iter 35000, loss: 0.208885
 >> iter 36000, loss: 0.160617
 >> iter 37000, loss: 0.184559
 >> iter 38000, loss: 0.149593
 >> iter 39000, loss: 0.503219
 >> iter 40000, loss: 0.340733
   Number of active neurons: 5
 >> iter 41000, loss: 0.436219
 >> iter 42000, loss: 0.332292
 >> iter 43000, loss: 0.362491
 >> iter 44000, loss: 0.282676
 >> iter 45000, loss: 0.259363
 >> iter 46000, loss: 0.283452
 >> iter 47000, loss: 0.264257
 >> iter 48000, loss: 0.358482
 >> iter 49000, loss: 0.349807
 >> iter 50000, loss: 0.403184
   Number of active neurons: 5
 >> iter 51000, loss: 0.440340
 >> iter 52000, loss: 0.333749
 >> iter 53000, loss: 0.362799
 >> iter 54000, loss: 0.255901
 >> iter 55000, loss: 0.277808
 >> iter 56000, loss: 0.390200
 >> iter 57000, loss: 0.245026
 >> iter 58000, loss: 0.224866
 >> iter 59000, loss: 0.308091
 >> iter 60000, loss: 0.217472
   Number of active neurons: 4
 >> iter 61000, loss: 0.259531
 >> iter 62000, loss: 0.241417
 >> iter 63000, loss: 0.301595
 >> iter 64000, loss: 0.289532
 >> iter 65000, loss: 0.224644
 >> iter 66000, loss: 0.262593
 >> iter 67000, loss: 0.210238
 >> iter 68000, loss: 0.292377
 >> iter 69000, loss: 0.216027
 >> iter 70000, loss: 0.287797
   Number of active neurons: 4
 >> iter 71000, loss: 0.204169
 >> iter 72000, loss: 0.241566
 >> iter 73000, loss: 0.440288
 >> iter 74000, loss: 0.264109
 >> iter 75000, loss: 0.368919
 >> iter 76000, loss: 0.255119
 >> iter 77000, loss: 0.237466
 >> iter 78000, loss: 0.450180
 >> iter 79000, loss: 0.205475
 >> iter 80000, loss: 0.143410
   Number of active neurons: 4
 >> iter 81000, loss: 0.327883
 >> iter 82000, loss: 0.229982
 >> iter 83000, loss: 0.208604
 >> iter 84000, loss: 0.639643
 >> iter 85000, loss: 0.405262
 >> iter 86000, loss: 0.249877
 >> iter 87000, loss: 0.203801
 >> iter 88000, loss: 0.441369
 >> iter 89000, loss: 0.444832
 >> iter 90000, loss: 0.232862
   Number of active neurons: 4
 >> iter 91000, loss: 0.316221
 >> iter 92000, loss: 0.260015
 >> iter 93000, loss: 0.144375
 >> iter 94000, loss: 0.162072
 >> iter 95000, loss: 0.155841
 >> iter 96000, loss: 0.454264
 >> iter 97000, loss: 0.457595
 >> iter 98000, loss: 0.389601
 >> iter 99000, loss: 0.240056
 >> iter 100000, loss: 0.207111
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.863207
 >> iter 2000, loss: 8.798189
 >> iter 3000, loss: 3.754258
 >> iter 4000, loss: 2.091889
 >> iter 5000, loss: 1.041324
 >> iter 6000, loss: 0.625648
 >> iter 7000, loss: 0.525000
 >> iter 8000, loss: 0.496142
 >> iter 9000, loss: 0.410674
 >> iter 10000, loss: 0.337613
   Number of active neurons: 4
 >> iter 11000, loss: 0.353038
 >> iter 12000, loss: 0.418799
 >> iter 13000, loss: 0.486731
 >> iter 14000, loss: 0.285595
 >> iter 15000, loss: 0.237185
 >> iter 16000, loss: 0.378886
 >> iter 17000, loss: 0.180903
 >> iter 18000, loss: 0.249235
 >> iter 19000, loss: 0.193209
 >> iter 20000, loss: 0.259501
   Number of active neurons: 4
 >> iter 21000, loss: 0.222927
 >> iter 22000, loss: 0.326360
 >> iter 23000, loss: 0.502628
 >> iter 24000, loss: 0.355667
 >> iter 25000, loss: 0.188851
 >> iter 26000, loss: 0.373207
 >> iter 27000, loss: 0.322653
 >> iter 28000, loss: 0.518636
 >> iter 29000, loss: 0.369006
 >> iter 30000, loss: 0.332380
   Number of active neurons: 4
 >> iter 31000, loss: 0.328942
 >> iter 32000, loss: 0.439293
 >> iter 33000, loss: 0.328941
 >> iter 34000, loss: 0.265525
 >> iter 35000, loss: 0.395341
 >> iter 36000, loss: 0.493979
 >> iter 37000, loss: 0.442836
 >> iter 38000, loss: 0.337005
 >> iter 39000, loss: 0.307068
 >> iter 40000, loss: 0.170131
   Number of active neurons: 4
 >> iter 41000, loss: 0.170266
 >> iter 42000, loss: 0.248356
 >> iter 43000, loss: 0.418933
 >> iter 44000, loss: 0.268336
 >> iter 45000, loss: 0.354723
 >> iter 46000, loss: 0.308986
 >> iter 47000, loss: 0.299546
 >> iter 48000, loss: 0.520750
 >> iter 49000, loss: 0.429896
 >> iter 50000, loss: 0.339000
   Number of active neurons: 4
 >> iter 51000, loss: 0.403724
 >> iter 52000, loss: 0.297147
 >> iter 53000, loss: 0.167023
 >> iter 54000, loss: 0.535666
 >> iter 55000, loss: 0.531814
 >> iter 56000, loss: 0.370687
 >> iter 57000, loss: 0.209741
 >> iter 58000, loss: 0.197613
 >> iter 59000, loss: 0.207474
 >> iter 60000, loss: 0.536349
   Number of active neurons: 4
 >> iter 61000, loss: 0.292150
 >> iter 62000, loss: 0.597774
 >> iter 63000, loss: 0.330861
 >> iter 64000, loss: 0.320880
 >> iter 65000, loss: 0.291367
 >> iter 66000, loss: 0.310996
 >> iter 67000, loss: 0.334312
 >> iter 68000, loss: 0.618087
 >> iter 69000, loss: 0.404339
 >> iter 70000, loss: 0.439159
   Number of active neurons: 4
 >> iter 71000, loss: 0.452834
 >> iter 72000, loss: 0.371521
 >> iter 73000, loss: 0.189582
 >> iter 74000, loss: 0.312261
 >> iter 75000, loss: 0.236592
 >> iter 76000, loss: 0.239145
 >> iter 77000, loss: 0.185279
 >> iter 78000, loss: 0.346346
 >> iter 79000, loss: 0.203054
 >> iter 80000, loss: 0.387811
   Number of active neurons: 4
 >> iter 81000, loss: 0.336839
 >> iter 82000, loss: 0.370943
 >> iter 83000, loss: 0.241233
 >> iter 84000, loss: 0.352146
 >> iter 85000, loss: 0.391985
 >> iter 86000, loss: 0.299934
 >> iter 87000, loss: 0.387868
 >> iter 88000, loss: 0.378238
 >> iter 89000, loss: 0.222038
 >> iter 90000, loss: 0.137634
   Number of active neurons: 4
 >> iter 91000, loss: 0.242499
 >> iter 92000, loss: 0.227807
 >> iter 93000, loss: 0.129317
 >> iter 94000, loss: 0.222045
 >> iter 95000, loss: 0.148402
 >> iter 96000, loss: 0.145234
 >> iter 97000, loss: 0.195762
 >> iter 98000, loss: 0.116925
 >> iter 99000, loss: 0.274402
 >> iter 100000, loss: 0.274368
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.548711
 >> iter 2000, loss: 10.334768
 >> iter 3000, loss: 4.596965
 >> iter 4000, loss: 2.225304
 >> iter 5000, loss: 1.108549
 >> iter 6000, loss: 0.620384
 >> iter 7000, loss: 0.432836
 >> iter 8000, loss: 0.523960
 >> iter 9000, loss: 0.298881
 >> iter 10000, loss: 0.289470
   Number of active neurons: 5
 >> iter 11000, loss: 0.388818
 >> iter 12000, loss: 0.279819
 >> iter 13000, loss: 0.318090
 >> iter 14000, loss: 0.280905
 >> iter 15000, loss: 0.294550
 >> iter 16000, loss: 0.190633
 >> iter 17000, loss: 0.296339
 >> iter 18000, loss: 0.174276
 >> iter 19000, loss: 0.404437
 >> iter 20000, loss: 0.346275
   Number of active neurons: 5
 >> iter 21000, loss: 0.271449
 >> iter 22000, loss: 0.224099
 >> iter 23000, loss: 0.241215
 >> iter 24000, loss: 0.362485
 >> iter 25000, loss: 0.317262
 >> iter 26000, loss: 0.350745
 >> iter 27000, loss: 0.331954
 >> iter 28000, loss: 0.235953
 >> iter 29000, loss: 0.192284
 >> iter 30000, loss: 0.170372
   Number of active neurons: 5
 >> iter 31000, loss: 0.253740
 >> iter 32000, loss: 0.262796
 >> iter 33000, loss: 0.600544
 >> iter 34000, loss: 0.373447
 >> iter 35000, loss: 0.321349
 >> iter 36000, loss: 0.405603
 >> iter 37000, loss: 0.267044
 >> iter 38000, loss: 0.169650
 >> iter 39000, loss: 0.151174
 >> iter 40000, loss: 0.140140
   Number of active neurons: 4
 >> iter 41000, loss: 0.108845
 >> iter 42000, loss: 0.225031
 >> iter 43000, loss: 0.291566
 >> iter 44000, loss: 0.167824
 >> iter 45000, loss: 0.183896
 >> iter 46000, loss: 0.154641
 >> iter 47000, loss: 0.123521
 >> iter 48000, loss: 0.188024
 >> iter 49000, loss: 0.144958
 >> iter 50000, loss: 0.337661
   Number of active neurons: 4
 >> iter 51000, loss: 0.290557
 >> iter 52000, loss: 0.252534
 >> iter 53000, loss: 0.396429
 >> iter 54000, loss: 0.353077
 >> iter 55000, loss: 0.177499
 >> iter 56000, loss: 0.153411
 >> iter 57000, loss: 0.367175
 >> iter 58000, loss: 0.397540
 >> iter 59000, loss: 0.255740
 >> iter 60000, loss: 0.186085
   Number of active neurons: 4
 >> iter 61000, loss: 0.322835
 >> iter 62000, loss: 0.197062
 >> iter 63000, loss: 0.183035
 >> iter 64000, loss: 0.287120
 >> iter 65000, loss: 0.227584
 >> iter 66000, loss: 0.143369
 >> iter 67000, loss: 0.220107
 >> iter 68000, loss: 0.259567
 >> iter 69000, loss: 0.255134
 >> iter 70000, loss: 0.168892
   Number of active neurons: 4
 >> iter 71000, loss: 0.191798
 >> iter 72000, loss: 0.138046
 >> iter 73000, loss: 0.216974
 >> iter 74000, loss: 0.289540
 >> iter 75000, loss: 0.149756
 >> iter 76000, loss: 0.349443
 >> iter 77000, loss: 0.349098
 >> iter 78000, loss: 0.447736
 >> iter 79000, loss: 0.324493
 >> iter 80000, loss: 0.309271
   Number of active neurons: 4
 >> iter 81000, loss: 0.199487
 >> iter 82000, loss: 0.325620
 >> iter 83000, loss: 0.261107
 >> iter 84000, loss: 0.360523
 >> iter 85000, loss: 0.225762
 >> iter 86000, loss: 0.211485
 >> iter 87000, loss: 0.264816
 >> iter 88000, loss: 0.221342
 >> iter 89000, loss: 0.350585
 >> iter 90000, loss: 0.260645
   Number of active neurons: 4
 >> iter 91000, loss: 0.326878
 >> iter 92000, loss: 0.332822
 >> iter 93000, loss: 0.208681
 >> iter 94000, loss: 0.203784
 >> iter 95000, loss: 0.526348
 >> iter 96000, loss: 0.348223
 >> iter 97000, loss: 0.188294
 >> iter 98000, loss: 0.294801
 >> iter 99000, loss: 0.242216
 >> iter 100000, loss: 0.278672
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 17.709517
 >> iter 2000, loss: 8.915094
 >> iter 3000, loss: 4.180850
 >> iter 4000, loss: 2.193170
 >> iter 5000, loss: 1.096460
 >> iter 6000, loss: 0.888754
 >> iter 7000, loss: 0.685730
 >> iter 8000, loss: 0.587277
 >> iter 9000, loss: 0.450996
 >> iter 10000, loss: 0.668333
   Number of active neurons: 4
 >> iter 11000, loss: 0.626866
 >> iter 12000, loss: 0.400383
 >> iter 13000, loss: 0.533856
 >> iter 14000, loss: 0.412501
 >> iter 15000, loss: 0.408323
 >> iter 16000, loss: 0.301924
 >> iter 17000, loss: 0.638318
 >> iter 18000, loss: 0.460793
 >> iter 19000, loss: 0.618415
 >> iter 20000, loss: 0.593974
   Number of active neurons: 4
 >> iter 21000, loss: 0.475965
 >> iter 22000, loss: 0.507151
 >> iter 23000, loss: 0.726503
 >> iter 24000, loss: 0.490126
 >> iter 25000, loss: 0.491394
 >> iter 26000, loss: 0.519021
 >> iter 27000, loss: 0.431810
 >> iter 28000, loss: 0.375879
 >> iter 29000, loss: 0.480420
 >> iter 30000, loss: 0.302184
   Number of active neurons: 4
 >> iter 31000, loss: 0.440882
 >> iter 32000, loss: 0.453477
 >> iter 33000, loss: 0.477614
 >> iter 34000, loss: 0.635002
 >> iter 35000, loss: 0.355118
 >> iter 36000, loss: 0.580452
 >> iter 37000, loss: 0.581313
 >> iter 38000, loss: 0.467479
 >> iter 39000, loss: 0.510046
 >> iter 40000, loss: 0.514857
   Number of active neurons: 4
 >> iter 41000, loss: 0.388503
 >> iter 42000, loss: 0.385409
 >> iter 43000, loss: 0.591473
 >> iter 44000, loss: 0.537636
 >> iter 45000, loss: 0.495723
 >> iter 46000, loss: 0.448310
 >> iter 47000, loss: 0.376296
 >> iter 48000, loss: 0.374561
 >> iter 49000, loss: 0.556862
 >> iter 50000, loss: 0.678116
   Number of active neurons: 4
 >> iter 51000, loss: 0.523321
 >> iter 52000, loss: 0.481850
 >> iter 53000, loss: 0.297159
 >> iter 54000, loss: 0.544654
 >> iter 55000, loss: 0.573577
 >> iter 56000, loss: 0.675770
 >> iter 57000, loss: 0.455471
 >> iter 58000, loss: 0.351325
 >> iter 59000, loss: 0.571977
 >> iter 60000, loss: 0.743239
   Number of active neurons: 4
 >> iter 61000, loss: 0.643385
 >> iter 62000, loss: 0.737040
 >> iter 63000, loss: 0.475792
 >> iter 64000, loss: 0.321118
 >> iter 65000, loss: 0.415776
 >> iter 66000, loss: 0.454632
 >> iter 67000, loss: 0.550800
 >> iter 68000, loss: 0.378579
 >> iter 69000, loss: 0.346464
 >> iter 70000, loss: 0.604623
   Number of active neurons: 4
 >> iter 71000, loss: 0.343277
 >> iter 72000, loss: 0.581526
 >> iter 73000, loss: 0.347643
 >> iter 74000, loss: 0.571779
 >> iter 75000, loss: 0.680434
 >> iter 76000, loss: 0.397412
 >> iter 77000, loss: 0.383801
 >> iter 78000, loss: 0.296537
 >> iter 79000, loss: 0.472551
 >> iter 80000, loss: 0.447629
   Number of active neurons: 4
 >> iter 81000, loss: 0.535740
 >> iter 82000, loss: 0.615578
 >> iter 83000, loss: 0.347905
 >> iter 84000, loss: 0.463815
 >> iter 85000, loss: 0.560952
 >> iter 86000, loss: 0.264372
 >> iter 87000, loss: 0.308933
 >> iter 88000, loss: 0.565959
 >> iter 89000, loss: 0.406762
 >> iter 90000, loss: 0.281827
   Number of active neurons: 4
 >> iter 91000, loss: 0.339490
 >> iter 92000, loss: 0.437794
 >> iter 93000, loss: 0.555568
 >> iter 94000, loss: 0.570989
 >> iter 95000, loss: 0.393750
 >> iter 96000, loss: 0.624858
 >> iter 97000, loss: 0.570441
 >> iter 98000, loss: 0.475923
 >> iter 99000, loss: 0.397256
 >> iter 100000, loss: 0.468522
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.780094
 >> iter 2000, loss: 9.231209
 >> iter 3000, loss: 4.554981
 >> iter 4000, loss: 2.268128
 >> iter 5000, loss: 1.302812
 >> iter 6000, loss: 1.097117
 >> iter 7000, loss: 0.957400
 >> iter 8000, loss: 0.753024
 >> iter 9000, loss: 0.810205
 >> iter 10000, loss: 0.473080
   Number of active neurons: 6
 >> iter 11000, loss: 0.628313
 >> iter 12000, loss: 0.662490
 >> iter 13000, loss: 0.427668
 >> iter 14000, loss: 0.317707
 >> iter 15000, loss: 0.413744
 >> iter 16000, loss: 0.653951
 >> iter 17000, loss: 0.567089
 >> iter 18000, loss: 0.547477
 >> iter 19000, loss: 0.499404
 >> iter 20000, loss: 0.699138
   Number of active neurons: 6
 >> iter 21000, loss: 0.619255
 >> iter 22000, loss: 0.351508
 >> iter 23000, loss: 0.484118
 >> iter 24000, loss: 0.350694
 >> iter 25000, loss: 0.391042
 >> iter 26000, loss: 0.533957
 >> iter 27000, loss: 0.473509
 >> iter 28000, loss: 0.351571
 >> iter 29000, loss: 0.666513
 >> iter 30000, loss: 0.580296
   Number of active neurons: 5
 >> iter 31000, loss: 0.560784
 >> iter 32000, loss: 0.509177
 >> iter 33000, loss: 0.384743
 >> iter 34000, loss: 0.604198
 >> iter 35000, loss: 0.741381
 >> iter 36000, loss: 0.705052
 >> iter 37000, loss: 0.684162
 >> iter 38000, loss: 0.608546
 >> iter 39000, loss: 0.431606
 >> iter 40000, loss: 0.508631
   Number of active neurons: 5
 >> iter 41000, loss: 0.390114
 >> iter 42000, loss: 0.586037
 >> iter 43000, loss: 0.465695
 >> iter 44000, loss: 0.571310
 >> iter 45000, loss: 0.445072
 >> iter 46000, loss: 0.262168
 >> iter 47000, loss: 0.282943
 >> iter 48000, loss: 0.516170
 >> iter 49000, loss: 0.509553
 >> iter 50000, loss: 0.410244
   Number of active neurons: 5
 >> iter 51000, loss: 0.377470
 >> iter 52000, loss: 0.359633
 >> iter 53000, loss: 0.403410
 >> iter 54000, loss: 0.563627
 >> iter 55000, loss: 0.453308
 >> iter 56000, loss: 0.438400
 >> iter 57000, loss: 0.278498
 >> iter 58000, loss: 0.416828
 >> iter 59000, loss: 0.409112
 >> iter 60000, loss: 0.454001
   Number of active neurons: 4
 >> iter 61000, loss: 0.701011
 >> iter 62000, loss: 0.629332
 >> iter 63000, loss: 0.602225
 >> iter 64000, loss: 0.629957
 >> iter 65000, loss: 0.665782
 >> iter 66000, loss: 0.475195
 >> iter 67000, loss: 0.608878
 >> iter 68000, loss: 0.504240
 >> iter 69000, loss: 0.500625
 >> iter 70000, loss: 0.533137
   Number of active neurons: 4
 >> iter 71000, loss: 0.557432
 >> iter 72000, loss: 0.631427
 >> iter 73000, loss: 0.509533
 >> iter 74000, loss: 0.382153
 >> iter 75000, loss: 0.443988
 >> iter 76000, loss: 0.500750
 >> iter 77000, loss: 0.375422
 >> iter 78000, loss: 0.287934
 >> iter 79000, loss: 0.250566
 >> iter 80000, loss: 0.558969
   Number of active neurons: 4
 >> iter 81000, loss: 0.478001
 >> iter 82000, loss: 0.584172
 >> iter 83000, loss: 0.370212
 >> iter 84000, loss: 0.609700
 >> iter 85000, loss: 0.490688
 >> iter 86000, loss: 0.360180
 >> iter 87000, loss: 0.313386
 >> iter 88000, loss: 0.457042
 >> iter 89000, loss: 0.682099
 >> iter 90000, loss: 0.727698
   Number of active neurons: 4
 >> iter 91000, loss: 0.435376
 >> iter 92000, loss: 0.411703
 >> iter 93000, loss: 0.345876
 >> iter 94000, loss: 0.359845
 >> iter 95000, loss: 0.506730
 >> iter 96000, loss: 0.499746
 >> iter 97000, loss: 0.658458
 >> iter 98000, loss: 0.413531
 >> iter 99000, loss: 0.396204
 >> iter 100000, loss: 0.355419
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 17.072994
 >> iter 2000, loss: 7.757108
 >> iter 3000, loss: 3.500451
 >> iter 4000, loss: 1.548924
 >> iter 5000, loss: 0.829233
 >> iter 6000, loss: 0.628307
 >> iter 7000, loss: 0.622444
 >> iter 8000, loss: 0.394301
 >> iter 9000, loss: 0.352263
 >> iter 10000, loss: 0.319647
   Number of active neurons: 6
 >> iter 11000, loss: 0.537283
 >> iter 12000, loss: 0.546051
 >> iter 13000, loss: 0.286138
 >> iter 14000, loss: 0.332575
 >> iter 15000, loss: 0.275994
 >> iter 16000, loss: 0.308022
 >> iter 17000, loss: 0.302356
 >> iter 18000, loss: 0.210841
 >> iter 19000, loss: 0.368366
 >> iter 20000, loss: 0.269025
   Number of active neurons: 5
 >> iter 21000, loss: 0.266148
 >> iter 22000, loss: 0.312691
 >> iter 23000, loss: 0.236367
 >> iter 24000, loss: 0.193110
 >> iter 25000, loss: 0.325105
 >> iter 26000, loss: 0.582662
 >> iter 27000, loss: 0.317012
 >> iter 28000, loss: 0.314896
 >> iter 29000, loss: 0.552248
 >> iter 30000, loss: 0.585544
   Number of active neurons: 4
 >> iter 31000, loss: 0.550955
 >> iter 32000, loss: 0.268565
 >> iter 33000, loss: 0.226996
 >> iter 34000, loss: 0.337612
 >> iter 35000, loss: 0.220790
 >> iter 36000, loss: 0.354538
 >> iter 37000, loss: 0.456711
 >> iter 38000, loss: 0.355093
 >> iter 39000, loss: 0.386747
 >> iter 40000, loss: 0.294277
   Number of active neurons: 3
 >> iter 41000, loss: 0.290246
 >> iter 42000, loss: 0.283029
 >> iter 43000, loss: 0.305233
 >> iter 44000, loss: 0.228383
 >> iter 45000, loss: 0.265304
 >> iter 46000, loss: 0.231742
 >> iter 47000, loss: 0.350734
 >> iter 48000, loss: 0.203899
 >> iter 49000, loss: 0.405928
 >> iter 50000, loss: 0.245039
   Number of active neurons: 3
 >> iter 51000, loss: 0.209774
 >> iter 52000, loss: 0.366096
 >> iter 53000, loss: 0.321514
 >> iter 54000, loss: 0.292695
 >> iter 55000, loss: 0.235721
 >> iter 56000, loss: 0.463715
 >> iter 57000, loss: 0.329793
 >> iter 58000, loss: 0.221357
 >> iter 59000, loss: 0.283235
 >> iter 60000, loss: 0.256299
   Number of active neurons: 3
 >> iter 61000, loss: 0.483422
 >> iter 62000, loss: 0.475242
 >> iter 63000, loss: 0.455271
 >> iter 64000, loss: 0.357365
 >> iter 65000, loss: 0.322472
 >> iter 66000, loss: 0.259143
 >> iter 67000, loss: 0.230820
 >> iter 68000, loss: 0.198270
 >> iter 69000, loss: 0.128037
 >> iter 70000, loss: 0.297868
   Number of active neurons: 3
 >> iter 71000, loss: 0.236094
 >> iter 72000, loss: 0.201028
 >> iter 73000, loss: 0.182292
 >> iter 74000, loss: 0.227369
 >> iter 75000, loss: 0.245485
 >> iter 76000, loss: 0.291071
 >> iter 77000, loss: 0.308296
 >> iter 78000, loss: 0.339896
 >> iter 79000, loss: 0.412999
 >> iter 80000, loss: 0.378187
   Number of active neurons: 3
 >> iter 81000, loss: 0.311953
 >> iter 82000, loss: 0.156662
 >> iter 83000, loss: 0.320226
 >> iter 84000, loss: 0.296856
 >> iter 85000, loss: 0.210223
 >> iter 86000, loss: 0.276280
 >> iter 87000, loss: 0.221176
 >> iter 88000, loss: 0.294242
 >> iter 89000, loss: 0.181720
 >> iter 90000, loss: 0.248780
   Number of active neurons: 3
 >> iter 91000, loss: 0.276332
 >> iter 92000, loss: 0.168474
 >> iter 93000, loss: 0.188692
 >> iter 94000, loss: 0.155981
 >> iter 95000, loss: 0.242478
 >> iter 96000, loss: 0.225729
 >> iter 97000, loss: 0.214762
 >> iter 98000, loss: 0.307148
 >> iter 99000, loss: 0.194432
 >> iter 100000, loss: 0.169574
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.856969
 >> iter 2000, loss: 10.258872
 >> iter 3000, loss: 4.607989
 >> iter 4000, loss: 2.000927
 >> iter 5000, loss: 0.980424
 >> iter 6000, loss: 0.687274
 >> iter 7000, loss: 0.391311
 >> iter 8000, loss: 0.318437
 >> iter 9000, loss: 0.335553
 >> iter 10000, loss: 0.434348
   Number of active neurons: 6
 >> iter 11000, loss: 0.427345
 >> iter 12000, loss: 0.339205
 >> iter 13000, loss: 0.253637
 >> iter 14000, loss: 0.452593
 >> iter 15000, loss: 0.354084
 >> iter 16000, loss: 0.382724
 >> iter 17000, loss: 0.429218
 >> iter 18000, loss: 0.327837
 >> iter 19000, loss: 0.339258
 >> iter 20000, loss: 0.331209
   Number of active neurons: 6
 >> iter 21000, loss: 0.213643
 >> iter 22000, loss: 0.217756
 >> iter 23000, loss: 0.319181
 >> iter 24000, loss: 0.230016
 >> iter 25000, loss: 0.258189
 >> iter 26000, loss: 0.243428
 >> iter 27000, loss: 0.324423
 >> iter 28000, loss: 0.296716
 >> iter 29000, loss: 0.312356
 >> iter 30000, loss: 0.236716
   Number of active neurons: 6
 >> iter 31000, loss: 0.389881
 >> iter 32000, loss: 0.301663
 >> iter 33000, loss: 0.284015
 >> iter 34000, loss: 0.377335
 >> iter 35000, loss: 0.364557
 >> iter 36000, loss: 0.241288
 >> iter 37000, loss: 0.213958
 >> iter 38000, loss: 0.219155
 >> iter 39000, loss: 0.590162
 >> iter 40000, loss: 0.311531
   Number of active neurons: 3
 >> iter 41000, loss: 0.207341
 >> iter 42000, loss: 0.248420
 >> iter 43000, loss: 0.202740
 >> iter 44000, loss: 0.234117
 >> iter 45000, loss: 0.271542
 >> iter 46000, loss: 0.329192
 >> iter 47000, loss: 0.217903
 >> iter 48000, loss: 0.181391
 >> iter 49000, loss: 0.196723
 >> iter 50000, loss: 0.381057
   Number of active neurons: 3
 >> iter 51000, loss: 0.301198
 >> iter 52000, loss: 0.244425
 >> iter 53000, loss: 0.319752
 >> iter 54000, loss: 0.303734
 >> iter 55000, loss: 0.257990
 >> iter 56000, loss: 0.319335
 >> iter 57000, loss: 0.225675
 >> iter 58000, loss: 0.261873
 >> iter 59000, loss: 0.157936
 >> iter 60000, loss: 0.164508
   Number of active neurons: 3
 >> iter 61000, loss: 0.497487
 >> iter 62000, loss: 0.360860
 >> iter 63000, loss: 0.250709
 >> iter 64000, loss: 0.285701
 >> iter 65000, loss: 0.425565
 >> iter 66000, loss: 0.385127
 >> iter 67000, loss: 0.392473
 >> iter 68000, loss: 0.460154
 >> iter 69000, loss: 0.330343
 >> iter 70000, loss: 0.296992
   Number of active neurons: 3
 >> iter 71000, loss: 0.429423
 >> iter 72000, loss: 0.339910
 >> iter 73000, loss: 0.304098
 >> iter 74000, loss: 0.221239
 >> iter 75000, loss: 0.337338
 >> iter 76000, loss: 0.267721
 >> iter 77000, loss: 0.183170
 >> iter 78000, loss: 0.106091
 >> iter 79000, loss: 0.165895
 >> iter 80000, loss: 0.398002
   Number of active neurons: 3
 >> iter 81000, loss: 0.254577
 >> iter 82000, loss: 0.204964
 >> iter 83000, loss: 0.266155
 >> iter 84000, loss: 0.256813
 >> iter 85000, loss: 0.254411
 >> iter 86000, loss: 0.248852
 >> iter 87000, loss: 0.265448
 >> iter 88000, loss: 0.268784
 >> iter 89000, loss: 0.305868
 >> iter 90000, loss: 0.319294
   Number of active neurons: 3
 >> iter 91000, loss: 0.234541
 >> iter 92000, loss: 0.366527
 >> iter 93000, loss: 0.187140
 >> iter 94000, loss: 0.283719
 >> iter 95000, loss: 0.252745
 >> iter 96000, loss: 0.226071
 >> iter 97000, loss: 0.310861
 >> iter 98000, loss: 0.304509
 >> iter 99000, loss: 0.340053
 >> iter 100000, loss: 0.218641
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 17.726425
 >> iter 2000, loss: 8.390958
 >> iter 3000, loss: 3.563136
 >> iter 4000, loss: 1.565998
 >> iter 5000, loss: 0.979047
 >> iter 6000, loss: 0.617813
 >> iter 7000, loss: 0.415859
 >> iter 8000, loss: 0.438776
 >> iter 9000, loss: 0.418579
 >> iter 10000, loss: 0.332325
   Number of active neurons: 6
 >> iter 11000, loss: 0.181979
 >> iter 12000, loss: 0.278901
 >> iter 13000, loss: 0.333205
 >> iter 14000, loss: 0.250777
 >> iter 15000, loss: 0.308629
 >> iter 16000, loss: 0.435985
 >> iter 17000, loss: 0.374243
 >> iter 18000, loss: 0.386023
 >> iter 19000, loss: 0.303382
 >> iter 20000, loss: 0.291489
   Number of active neurons: 6
 >> iter 21000, loss: 0.584356
 >> iter 22000, loss: 0.341387
 >> iter 23000, loss: 0.241244
 >> iter 24000, loss: 0.325246
 >> iter 25000, loss: 0.481050
 >> iter 26000, loss: 0.313622
 >> iter 27000, loss: 0.252317
 >> iter 28000, loss: 0.315501
 >> iter 29000, loss: 0.446150
 >> iter 30000, loss: 0.360652
   Number of active neurons: 5
 >> iter 31000, loss: 0.363829
 >> iter 32000, loss: 0.365542
 >> iter 33000, loss: 0.378865
 >> iter 34000, loss: 0.331791
 >> iter 35000, loss: 0.375479
 >> iter 36000, loss: 0.228815
 >> iter 37000, loss: 0.289363
 >> iter 38000, loss: 0.284631
 >> iter 39000, loss: 0.319441
 >> iter 40000, loss: 0.589391
   Number of active neurons: 5
 >> iter 41000, loss: 0.396698
 >> iter 42000, loss: 0.371325
 >> iter 43000, loss: 0.422692
 >> iter 44000, loss: 0.330439
 >> iter 45000, loss: 0.303956
 >> iter 46000, loss: 0.164373
 >> iter 47000, loss: 0.259640
 >> iter 48000, loss: 0.298006
 >> iter 49000, loss: 0.357819
 >> iter 50000, loss: 0.230531
   Number of active neurons: 4
 >> iter 51000, loss: 0.218552
 >> iter 52000, loss: 0.441920
 >> iter 53000, loss: 0.293732
 >> iter 54000, loss: 0.257704
 >> iter 55000, loss: 0.197543
 >> iter 56000, loss: 0.115929
 >> iter 57000, loss: 0.221235
 >> iter 58000, loss: 0.239435
 >> iter 59000, loss: 0.230679
 >> iter 60000, loss: 0.169144
   Number of active neurons: 4
 >> iter 61000, loss: 0.129601
 >> iter 62000, loss: 0.104906
 >> iter 63000, loss: 0.214259
 >> iter 64000, loss: 0.233410
 >> iter 65000, loss: 0.191114
 >> iter 66000, loss: 0.512276
 >> iter 67000, loss: 0.284642
 >> iter 68000, loss: 0.359843
 >> iter 69000, loss: 0.311695
 >> iter 70000, loss: 0.303487
   Number of active neurons: 4
 >> iter 71000, loss: 0.312898
 >> iter 72000, loss: 0.206989
 >> iter 73000, loss: 0.227134
 >> iter 74000, loss: 0.135299
 >> iter 75000, loss: 0.249051
 >> iter 76000, loss: 0.190829
 >> iter 77000, loss: 0.270566
 >> iter 78000, loss: 0.231464
 >> iter 79000, loss: 0.280808
 >> iter 80000, loss: 0.201352
   Number of active neurons: 4
 >> iter 81000, loss: 0.155104
 >> iter 82000, loss: 0.125653
 >> iter 83000, loss: 0.191290
 >> iter 84000, loss: 0.248914
 >> iter 85000, loss: 0.178922
 >> iter 86000, loss: 0.244476
 >> iter 87000, loss: 0.245216
 >> iter 88000, loss: 0.133649
 >> iter 89000, loss: 0.159641
 >> iter 90000, loss: 0.296259
   Number of active neurons: 4
 >> iter 91000, loss: 0.276578
 >> iter 92000, loss: 0.239042
 >> iter 93000, loss: 0.266624
 >> iter 94000, loss: 0.289770
 >> iter 95000, loss: 0.430922
 >> iter 96000, loss: 0.305244
 >> iter 97000, loss: 0.426464
 >> iter 98000, loss: 0.504861
 >> iter 99000, loss: 0.314621
 >> iter 100000, loss: 0.315808
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.811971
 >> iter 2000, loss: 10.174006
 >> iter 3000, loss: 4.786813
 >> iter 4000, loss: 2.502939
 >> iter 5000, loss: 1.444888
 >> iter 6000, loss: 1.146918
 >> iter 7000, loss: 0.664845
 >> iter 8000, loss: 0.434374
 >> iter 9000, loss: 0.520458
 >> iter 10000, loss: 0.637860
   Number of active neurons: 4
 >> iter 11000, loss: 0.602113
 >> iter 12000, loss: 0.561305
 >> iter 13000, loss: 0.630586
 >> iter 14000, loss: 0.539928
 >> iter 15000, loss: 0.615498
 >> iter 16000, loss: 0.499821
 >> iter 17000, loss: 0.576147
 >> iter 18000, loss: 0.543912
 >> iter 19000, loss: 0.543515
 >> iter 20000, loss: 0.512348
   Number of active neurons: 4
 >> iter 21000, loss: 0.450390
 >> iter 22000, loss: 0.385041
 >> iter 23000, loss: 0.323673
 >> iter 24000, loss: 0.341731
 >> iter 25000, loss: 0.490572
 >> iter 26000, loss: 0.541672
 >> iter 27000, loss: 0.470106
 >> iter 28000, loss: 0.476100
 >> iter 29000, loss: 0.608033
 >> iter 30000, loss: 0.448570
   Number of active neurons: 4
 >> iter 31000, loss: 0.369765
 >> iter 32000, loss: 0.498732
 >> iter 33000, loss: 0.484201
 >> iter 34000, loss: 0.313108
 >> iter 35000, loss: 0.333370
 >> iter 36000, loss: 0.478529
 >> iter 37000, loss: 0.387995
 >> iter 38000, loss: 0.398861
 >> iter 39000, loss: 0.418595
 >> iter 40000, loss: 0.451874
   Number of active neurons: 4
 >> iter 41000, loss: 0.556828
 >> iter 42000, loss: 0.456437
 >> iter 43000, loss: 0.571139
 >> iter 44000, loss: 0.326595
 >> iter 45000, loss: 0.359730
 >> iter 46000, loss: 0.506559
 >> iter 47000, loss: 0.358544
 >> iter 48000, loss: 0.352739
 >> iter 49000, loss: 0.405059
 >> iter 50000, loss: 0.472180
   Number of active neurons: 4
 >> iter 51000, loss: 0.375756
 >> iter 52000, loss: 0.426353
 >> iter 53000, loss: 0.647444
 >> iter 54000, loss: 0.440401
 >> iter 55000, loss: 0.606456
 >> iter 56000, loss: 0.450762
 >> iter 57000, loss: 0.417663
 >> iter 58000, loss: 0.686614
 >> iter 59000, loss: 0.587871
 >> iter 60000, loss: 0.559006
   Number of active neurons: 4
 >> iter 61000, loss: 0.417850
 >> iter 62000, loss: 0.328178
 >> iter 63000, loss: 0.557905
 >> iter 64000, loss: 0.462606
 >> iter 65000, loss: 0.392428
 >> iter 66000, loss: 0.550094
 >> iter 67000, loss: 0.639956
 >> iter 68000, loss: 0.500099
 >> iter 69000, loss: 0.641111
 >> iter 70000, loss: 0.493203
   Number of active neurons: 4
 >> iter 71000, loss: 0.487277
 >> iter 72000, loss: 0.397893
 >> iter 73000, loss: 0.326038
 >> iter 74000, loss: 0.198293
 >> iter 75000, loss: 0.306466
 >> iter 76000, loss: 0.517206
 >> iter 77000, loss: 0.579783
 >> iter 78000, loss: 0.547263
 >> iter 79000, loss: 0.645782
 >> iter 80000, loss: 0.596896
   Number of active neurons: 4
 >> iter 81000, loss: 0.468084
 >> iter 82000, loss: 0.381718
 >> iter 83000, loss: 0.404199
 >> iter 84000, loss: 0.531007
 >> iter 85000, loss: 0.355946
 >> iter 86000, loss: 0.435699
 >> iter 87000, loss: 0.323027
 >> iter 88000, loss: 0.415649
 >> iter 89000, loss: 0.435586
 >> iter 90000, loss: 0.725398
   Number of active neurons: 4
 >> iter 91000, loss: 0.555578
 >> iter 92000, loss: 0.490565
 >> iter 93000, loss: 0.460122
 >> iter 94000, loss: 0.616443
 >> iter 95000, loss: 0.634268
 >> iter 96000, loss: 0.380654
 >> iter 97000, loss: 0.432962
 >> iter 98000, loss: 0.300503
 >> iter 99000, loss: 0.468596
 >> iter 100000, loss: 0.591412
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.715806
 >> iter 2000, loss: 8.833485
 >> iter 3000, loss: 3.856957
 >> iter 4000, loss: 2.051505
 >> iter 5000, loss: 1.085671
 >> iter 6000, loss: 0.559151
 >> iter 7000, loss: 0.305289
 >> iter 8000, loss: 0.343239
 >> iter 9000, loss: 0.279387
 >> iter 10000, loss: 0.368556
   Number of active neurons: 5
 >> iter 11000, loss: 0.274733
 >> iter 12000, loss: 0.157109
 >> iter 13000, loss: 0.249148
 >> iter 14000, loss: 0.186298
 >> iter 15000, loss: 0.445365
 >> iter 16000, loss: 0.282247
 >> iter 17000, loss: 0.351651
 >> iter 18000, loss: 0.364509
 >> iter 19000, loss: 0.250232
 >> iter 20000, loss: 0.315108
   Number of active neurons: 5
 >> iter 21000, loss: 0.292598
 >> iter 22000, loss: 0.240665
 >> iter 23000, loss: 0.185227
 >> iter 24000, loss: 0.275052
 >> iter 25000, loss: 0.295828
 >> iter 26000, loss: 0.208145
 >> iter 27000, loss: 0.221295
 >> iter 28000, loss: 0.273718
 >> iter 29000, loss: 0.243360
 >> iter 30000, loss: 0.463558
   Number of active neurons: 5
 >> iter 31000, loss: 0.458875
 >> iter 32000, loss: 0.450390
 >> iter 33000, loss: 0.319697
 >> iter 34000, loss: 0.294071
 >> iter 35000, loss: 0.371561
 >> iter 36000, loss: 0.353865
 >> iter 37000, loss: 0.384323
 >> iter 38000, loss: 0.271792
 >> iter 39000, loss: 0.332555
 >> iter 40000, loss: 0.308055
   Number of active neurons: 3
 >> iter 41000, loss: 0.262470
 >> iter 42000, loss: 0.288227
 >> iter 43000, loss: 0.319193
 >> iter 44000, loss: 0.218756
 >> iter 45000, loss: 0.164591
 >> iter 46000, loss: 0.179052
 >> iter 47000, loss: 0.274305
 >> iter 48000, loss: 0.230548
 >> iter 49000, loss: 0.196308
 >> iter 50000, loss: 0.261772
   Number of active neurons: 3
 >> iter 51000, loss: 0.466726
 >> iter 52000, loss: 0.470778
 >> iter 53000, loss: 0.561584
 >> iter 54000, loss: 0.372373
 >> iter 55000, loss: 0.230754
 >> iter 56000, loss: 0.218129
 >> iter 57000, loss: 0.305023
 >> iter 58000, loss: 0.295829
 >> iter 59000, loss: 0.342847
 >> iter 60000, loss: 0.270810
   Number of active neurons: 3
 >> iter 61000, loss: 0.218733
 >> iter 62000, loss: 0.196856
 >> iter 63000, loss: 0.125899
 >> iter 64000, loss: 0.172361
 >> iter 65000, loss: 0.296242
 >> iter 66000, loss: 0.247729
 >> iter 67000, loss: 0.221770
 >> iter 68000, loss: 0.393347
 >> iter 69000, loss: 0.471696
 >> iter 70000, loss: 0.271051
   Number of active neurons: 3
 >> iter 71000, loss: 0.352468
 >> iter 72000, loss: 0.224890
 >> iter 73000, loss: 0.140809
 >> iter 74000, loss: 0.296796
 >> iter 75000, loss: 0.220039
 >> iter 76000, loss: 0.217612
 >> iter 77000, loss: 0.138074
 >> iter 78000, loss: 0.210773
 >> iter 79000, loss: 0.160639
 >> iter 80000, loss: 0.334420
   Number of active neurons: 3
 >> iter 81000, loss: 0.275121
 >> iter 82000, loss: 0.277923
 >> iter 83000, loss: 0.216713
 >> iter 84000, loss: 0.221879
 >> iter 85000, loss: 0.271894
 >> iter 86000, loss: 0.266895
 >> iter 87000, loss: 0.321874
 >> iter 88000, loss: 0.343750
 >> iter 89000, loss: 0.346890
 >> iter 90000, loss: 0.222858
   Number of active neurons: 3
 >> iter 91000, loss: 0.196315
 >> iter 92000, loss: 0.180811
 >> iter 93000, loss: 0.227487
 >> iter 94000, loss: 0.170818
 >> iter 95000, loss: 0.125672
 >> iter 96000, loss: 0.192919
 >> iter 97000, loss: 0.316471
 >> iter 98000, loss: 0.226995
 >> iter 99000, loss: 0.280060
 >> iter 100000, loss: 0.468476
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.996845
 >> iter 2000, loss: 11.242489
 >> iter 3000, loss: 5.831514
 >> iter 4000, loss: 2.647633
 >> iter 5000, loss: 1.263789
 >> iter 6000, loss: 0.721953
 >> iter 7000, loss: 0.503067
 >> iter 8000, loss: 0.387830
 >> iter 9000, loss: 0.295818
 >> iter 10000, loss: 0.310179
   Number of active neurons: 4
 >> iter 11000, loss: 0.391300
 >> iter 12000, loss: 0.391057
 >> iter 13000, loss: 0.267632
 >> iter 14000, loss: 0.189019
 >> iter 15000, loss: 0.251608
 >> iter 16000, loss: 0.146905
 >> iter 17000, loss: 0.215220
 >> iter 18000, loss: 0.215046
 >> iter 19000, loss: 0.303359
 >> iter 20000, loss: 0.262676
   Number of active neurons: 4
 >> iter 21000, loss: 0.222590
 >> iter 22000, loss: 0.437722
 >> iter 23000, loss: 0.368653
 >> iter 24000, loss: 0.257699
 >> iter 25000, loss: 0.206398
 >> iter 26000, loss: 0.162606
 >> iter 27000, loss: 0.221668
 >> iter 28000, loss: 0.246510
 >> iter 29000, loss: 0.189676
 >> iter 30000, loss: 0.400595
   Number of active neurons: 4
 >> iter 31000, loss: 0.181030
 >> iter 32000, loss: 0.207501
 >> iter 33000, loss: 0.173831
 >> iter 34000, loss: 0.285004
 >> iter 35000, loss: 0.319333
 >> iter 36000, loss: 0.146745
 >> iter 37000, loss: 0.186821
 >> iter 38000, loss: 0.169231
 >> iter 39000, loss: 0.275780
 >> iter 40000, loss: 0.435255
   Number of active neurons: 3
 >> iter 41000, loss: 0.356556
 >> iter 42000, loss: 0.223503
 >> iter 43000, loss: 0.154871
 >> iter 44000, loss: 0.098625
 >> iter 45000, loss: 0.170389
 >> iter 46000, loss: 0.155522
 >> iter 47000, loss: 0.216749
 >> iter 48000, loss: 0.337772
 >> iter 49000, loss: 0.328865
 >> iter 50000, loss: 0.316767
   Number of active neurons: 3
 >> iter 51000, loss: 0.324649
 >> iter 52000, loss: 0.467656
 >> iter 53000, loss: 0.258719
 >> iter 54000, loss: 0.256691
 >> iter 55000, loss: 0.299393
 >> iter 56000, loss: 0.334092
 >> iter 57000, loss: 0.398188
 >> iter 58000, loss: 0.292132
 >> iter 59000, loss: 0.324933
 >> iter 60000, loss: 0.260008
   Number of active neurons: 3
 >> iter 61000, loss: 0.237176
 >> iter 62000, loss: 0.288686
 >> iter 63000, loss: 0.267070
 >> iter 64000, loss: 0.200755
 >> iter 65000, loss: 0.125483
 >> iter 66000, loss: 0.120473
 >> iter 67000, loss: 0.103940
 >> iter 68000, loss: 0.150873
 >> iter 69000, loss: 0.267810
 >> iter 70000, loss: 0.339469
   Number of active neurons: 3
 >> iter 71000, loss: 0.261830
 >> iter 72000, loss: 0.342968
 >> iter 73000, loss: 0.217678
 >> iter 74000, loss: 0.318081
 >> iter 75000, loss: 0.452162
 >> iter 76000, loss: 0.381502
 >> iter 77000, loss: 0.241347
 >> iter 78000, loss: 0.197596
 >> iter 79000, loss: 0.105612
 >> iter 80000, loss: 0.328526
   Number of active neurons: 3
 >> iter 81000, loss: 0.272882
 >> iter 82000, loss: 0.202618
 >> iter 83000, loss: 0.313688
 >> iter 84000, loss: 0.266640
 >> iter 85000, loss: 0.265552
 >> iter 86000, loss: 0.313295
 >> iter 87000, loss: 0.276376
 >> iter 88000, loss: 0.176752
 >> iter 89000, loss: 0.165214
 >> iter 90000, loss: 0.262574
   Number of active neurons: 3
 >> iter 91000, loss: 0.142623
 >> iter 92000, loss: 0.226752
 >> iter 93000, loss: 0.211691
 >> iter 94000, loss: 0.249444
 >> iter 95000, loss: 0.159100
 >> iter 96000, loss: 0.175845
 >> iter 97000, loss: 0.292735
 >> iter 98000, loss: 0.212863
 >> iter 99000, loss: 0.302923
 >> iter 100000, loss: 0.366746
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 17.773462
 >> iter 2000, loss: 8.706135
 >> iter 3000, loss: 3.594318
 >> iter 4000, loss: 1.775587
 >> iter 5000, loss: 0.808143
 >> iter 6000, loss: 0.671064
 >> iter 7000, loss: 0.354995
 >> iter 8000, loss: 0.523035
 >> iter 9000, loss: 0.311555
 >> iter 10000, loss: 0.247008
   Number of active neurons: 5
 >> iter 11000, loss: 0.248484
 >> iter 12000, loss: 0.434255
 >> iter 13000, loss: 0.340586
 >> iter 14000, loss: 0.322082
 >> iter 15000, loss: 0.365208
 >> iter 16000, loss: 0.238168
 >> iter 17000, loss: 0.129133
 >> iter 18000, loss: 0.320653
 >> iter 19000, loss: 0.342514
 >> iter 20000, loss: 0.198758
   Number of active neurons: 5
 >> iter 21000, loss: 0.162015
 >> iter 22000, loss: 0.293346
 >> iter 23000, loss: 0.420628
 >> iter 24000, loss: 0.223339
 >> iter 25000, loss: 0.223510
 >> iter 26000, loss: 0.224326
 >> iter 27000, loss: 0.303592
 >> iter 28000, loss: 0.336386
 >> iter 29000, loss: 0.165948
 >> iter 30000, loss: 0.173617
   Number of active neurons: 4
 >> iter 31000, loss: 0.176696
 >> iter 32000, loss: 0.143028
 >> iter 33000, loss: 0.262653
 >> iter 34000, loss: 0.168844
 >> iter 35000, loss: 0.154525
 >> iter 36000, loss: 0.321447
 >> iter 37000, loss: 0.165867
 >> iter 38000, loss: 0.241273
 >> iter 39000, loss: 0.258425
 >> iter 40000, loss: 0.204235
   Number of active neurons: 3
 >> iter 41000, loss: 0.182181
 >> iter 42000, loss: 0.201102
 >> iter 43000, loss: 0.505996
 >> iter 44000, loss: 0.231856
 >> iter 45000, loss: 0.271248
 >> iter 46000, loss: 0.233534
 >> iter 47000, loss: 0.362516
 >> iter 48000, loss: 0.256976
 >> iter 49000, loss: 0.424735
 >> iter 50000, loss: 0.339073
   Number of active neurons: 3
 >> iter 51000, loss: 0.382888
 >> iter 52000, loss: 0.333062
 >> iter 53000, loss: 0.280627
 >> iter 54000, loss: 0.253554
 >> iter 55000, loss: 0.330992
 >> iter 56000, loss: 0.204390
 >> iter 57000, loss: 0.100076
 >> iter 58000, loss: 0.222662
 >> iter 59000, loss: 0.233223
 >> iter 60000, loss: 0.195728
   Number of active neurons: 3
 >> iter 61000, loss: 0.153629
 >> iter 62000, loss: 0.141062
 >> iter 63000, loss: 0.198249
 >> iter 64000, loss: 0.211525
 >> iter 65000, loss: 0.279025
 >> iter 66000, loss: 0.233624
 >> iter 67000, loss: 0.277921
 >> iter 68000, loss: 0.282430
 >> iter 69000, loss: 0.208993
 >> iter 70000, loss: 0.101099
   Number of active neurons: 3
 >> iter 71000, loss: 0.154769
 >> iter 72000, loss: 0.279390
 >> iter 73000, loss: 0.352889
 >> iter 74000, loss: 0.327162
 >> iter 75000, loss: 0.440108
 >> iter 76000, loss: 0.423186
 >> iter 77000, loss: 0.265530
 >> iter 78000, loss: 0.251345
 >> iter 79000, loss: 0.183514
 >> iter 80000, loss: 0.140631
   Number of active neurons: 3
 >> iter 81000, loss: 0.152268
 >> iter 82000, loss: 0.180311
 >> iter 83000, loss: 0.283381
 >> iter 84000, loss: 0.200160
 >> iter 85000, loss: 0.170325
 >> iter 86000, loss: 0.460298
 >> iter 87000, loss: 0.306925
 >> iter 88000, loss: 0.408330
 >> iter 89000, loss: 0.261645
 >> iter 90000, loss: 0.368917
   Number of active neurons: 3
 >> iter 91000, loss: 0.238417
 >> iter 92000, loss: 0.343272
 >> iter 93000, loss: 0.378528
 >> iter 94000, loss: 0.358031
 >> iter 95000, loss: 0.237238
 >> iter 96000, loss: 0.184742
 >> iter 97000, loss: 0.233424
 >> iter 98000, loss: 0.253601
 >> iter 99000, loss: 0.167348
 >> iter 100000, loss: 0.261328
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.673123
 >> iter 2000, loss: 8.312278
 >> iter 3000, loss: 3.658367
 >> iter 4000, loss: 1.703413
 >> iter 5000, loss: 0.889448
 >> iter 6000, loss: 0.557564
 >> iter 7000, loss: 0.383041
 >> iter 8000, loss: 0.259839
 >> iter 9000, loss: 0.407951
 >> iter 10000, loss: 0.410821
   Number of active neurons: 6
 >> iter 11000, loss: 0.321119
 >> iter 12000, loss: 0.496405
 >> iter 13000, loss: 0.459007
 >> iter 14000, loss: 0.250346
 >> iter 15000, loss: 0.432767
 >> iter 16000, loss: 0.478789
 >> iter 17000, loss: 0.327590
 >> iter 18000, loss: 0.432196
 >> iter 19000, loss: 0.455270
 >> iter 20000, loss: 0.514029
   Number of active neurons: 6
 >> iter 21000, loss: 0.352514
 >> iter 22000, loss: 0.480837
 >> iter 23000, loss: 0.397283
 >> iter 24000, loss: 0.316088
 >> iter 25000, loss: 0.202421
 >> iter 26000, loss: 0.230619
 >> iter 27000, loss: 0.150558
 >> iter 28000, loss: 0.160158
 >> iter 29000, loss: 0.150671
 >> iter 30000, loss: 0.159116
   Number of active neurons: 4
 >> iter 31000, loss: 0.229709
 >> iter 32000, loss: 0.417173
 >> iter 33000, loss: 0.325313
 >> iter 34000, loss: 0.241917
 >> iter 35000, loss: 0.404999
 >> iter 36000, loss: 0.261884
 >> iter 37000, loss: 0.226710
 >> iter 38000, loss: 0.256264
 >> iter 39000, loss: 0.430040
 >> iter 40000, loss: 0.347491
   Number of active neurons: 4
 >> iter 41000, loss: 0.439215
 >> iter 42000, loss: 0.319090
 >> iter 43000, loss: 0.236906
 >> iter 44000, loss: 0.298773
 >> iter 45000, loss: 0.364671
 >> iter 46000, loss: 0.334838
 >> iter 47000, loss: 0.188940
 >> iter 48000, loss: 0.224808
 >> iter 49000, loss: 0.356029
 >> iter 50000, loss: 0.213562
   Number of active neurons: 4
 >> iter 51000, loss: 0.190390
 >> iter 52000, loss: 0.158478
 >> iter 53000, loss: 0.406088
 >> iter 54000, loss: 0.377241
 >> iter 55000, loss: 0.205654
 >> iter 56000, loss: 0.230781
 >> iter 57000, loss: 0.411970
 >> iter 58000, loss: 0.330683
 >> iter 59000, loss: 0.362723
 >> iter 60000, loss: 0.374799
   Number of active neurons: 4
 >> iter 61000, loss: 0.334610
 >> iter 62000, loss: 0.242755
 >> iter 63000, loss: 0.385827
 >> iter 64000, loss: 0.403102
 >> iter 65000, loss: 0.265421
 >> iter 66000, loss: 0.232331
 >> iter 67000, loss: 0.214244
 >> iter 68000, loss: 0.248495
 >> iter 69000, loss: 0.445129
 >> iter 70000, loss: 0.364364
   Number of active neurons: 4
 >> iter 71000, loss: 0.236473
 >> iter 72000, loss: 0.276892
 >> iter 73000, loss: 0.282826
 >> iter 74000, loss: 0.320446
 >> iter 75000, loss: 0.220335
 >> iter 76000, loss: 0.308325
 >> iter 77000, loss: 0.428004
 >> iter 78000, loss: 0.364916
 >> iter 79000, loss: 0.504492
 >> iter 80000, loss: 0.367329
   Number of active neurons: 4
 >> iter 81000, loss: 0.167451
 >> iter 82000, loss: 0.337057
 >> iter 83000, loss: 0.317919
 >> iter 84000, loss: 0.244883
 >> iter 85000, loss: 0.322014
 >> iter 86000, loss: 0.308785
 >> iter 87000, loss: 0.242102
 >> iter 88000, loss: 0.190449
 >> iter 89000, loss: 0.134310
 >> iter 90000, loss: 0.083721
   Number of active neurons: 4
 >> iter 91000, loss: 0.146894
 >> iter 92000, loss: 0.303451
 >> iter 93000, loss: 0.276221
 >> iter 94000, loss: 0.331941
 >> iter 95000, loss: 0.165095
 >> iter 96000, loss: 0.109849
 >> iter 97000, loss: 0.167478
 >> iter 98000, loss: 0.225767
 >> iter 99000, loss: 0.268679
 >> iter 100000, loss: 0.179435
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455176
   Number of active neurons: 0
 >> iter 1000, loss: 18.249961
 >> iter 2000, loss: 8.691830
 >> iter 3000, loss: 3.794069
 >> iter 4000, loss: 1.710992
 >> iter 5000, loss: 0.764098
 >> iter 6000, loss: 0.433910
 >> iter 7000, loss: 0.290871
 >> iter 8000, loss: 0.411752
 >> iter 9000, loss: 0.639921
 >> iter 10000, loss: 0.411843
   Number of active neurons: 4
 >> iter 11000, loss: 0.333115
 >> iter 12000, loss: 0.353368
 >> iter 13000, loss: 0.398936
 >> iter 14000, loss: 0.375719
 >> iter 15000, loss: 0.294914
 >> iter 16000, loss: 0.315088
 >> iter 17000, loss: 0.196739
 >> iter 18000, loss: 0.277444
 >> iter 19000, loss: 0.297361
 >> iter 20000, loss: 0.195012
   Number of active neurons: 4
 >> iter 21000, loss: 0.386071
 >> iter 22000, loss: 0.258305
 >> iter 23000, loss: 0.231902
 >> iter 24000, loss: 0.240280
 >> iter 25000, loss: 0.529525
 >> iter 26000, loss: 0.335304
 >> iter 27000, loss: 0.324945
 >> iter 28000, loss: 0.351758
 >> iter 29000, loss: 0.425722
 >> iter 30000, loss: 0.233261
   Number of active neurons: 4
 >> iter 31000, loss: 0.206643
 >> iter 32000, loss: 0.410333
 >> iter 33000, loss: 0.326438
 >> iter 34000, loss: 0.275695
 >> iter 35000, loss: 0.224807
 >> iter 36000, loss: 0.251452
 >> iter 37000, loss: 0.195665
 >> iter 38000, loss: 0.261437
 >> iter 39000, loss: 0.266996
 >> iter 40000, loss: 0.302940
   Number of active neurons: 4
 >> iter 41000, loss: 0.318228
 >> iter 42000, loss: 0.340883
 >> iter 43000, loss: 0.281987
 >> iter 44000, loss: 0.358404
 >> iter 45000, loss: 0.491058
 >> iter 46000, loss: 0.423604
 >> iter 47000, loss: 0.272407
 >> iter 48000, loss: 0.236945
 >> iter 49000, loss: 0.162249
 >> iter 50000, loss: 0.124177
   Number of active neurons: 3
 >> iter 51000, loss: 0.129681
 >> iter 52000, loss: 0.222699
 >> iter 53000, loss: 0.223521
 >> iter 54000, loss: 0.211230
 >> iter 55000, loss: 0.173134
 >> iter 56000, loss: 0.274411
 >> iter 57000, loss: 0.244638
 >> iter 58000, loss: 0.348239
 >> iter 59000, loss: 0.355896
 >> iter 60000, loss: 0.322412
   Number of active neurons: 3
 >> iter 61000, loss: 0.309494
 >> iter 62000, loss: 0.199244
 >> iter 63000, loss: 0.261783
 >> iter 64000, loss: 0.180168
 >> iter 65000, loss: 0.246370
 >> iter 66000, loss: 0.255702
 >> iter 67000, loss: 0.421894
 >> iter 68000, loss: 0.280278
 >> iter 69000, loss: 0.286264
 >> iter 70000, loss: 0.297766
   Number of active neurons: 3
 >> iter 71000, loss: 0.313780
 >> iter 72000, loss: 0.217299
 >> iter 73000, loss: 0.204400
 >> iter 74000, loss: 0.350886
 >> iter 75000, loss: 0.365291
 >> iter 76000, loss: 0.243666
 >> iter 77000, loss: 0.186440
 >> iter 78000, loss: 0.253601
 >> iter 79000, loss: 0.318627
 >> iter 80000, loss: 0.326870
   Number of active neurons: 3
 >> iter 81000, loss: 0.232806
 >> iter 82000, loss: 0.170024
 >> iter 83000, loss: 0.309377
 >> iter 84000, loss: 0.362495
 >> iter 85000, loss: 0.365325
 >> iter 86000, loss: 0.331408
 >> iter 87000, loss: 0.287830
 >> iter 88000, loss: 0.222359
 >> iter 89000, loss: 0.189350
 >> iter 90000, loss: 0.167329
   Number of active neurons: 3
 >> iter 91000, loss: 0.248009
 >> iter 92000, loss: 0.277636
 >> iter 93000, loss: 0.281251
 >> iter 94000, loss: 0.153041
 >> iter 95000, loss: 0.197902
 >> iter 96000, loss: 0.233151
 >> iter 97000, loss: 0.386654
 >> iter 98000, loss: 0.215669
 >> iter 99000, loss: 0.498151
 >> iter 100000, loss: 0.300993
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.240897
 >> iter 2000, loss: 11.385689
 >> iter 3000, loss: 5.534550
 >> iter 4000, loss: 2.636102
 >> iter 5000, loss: 1.348379
 >> iter 6000, loss: 0.561168
 >> iter 7000, loss: 0.329626
 >> iter 8000, loss: 0.334100
 >> iter 9000, loss: 0.474059
 >> iter 10000, loss: 0.335084
   Number of active neurons: 3
 >> iter 11000, loss: 0.299976
 >> iter 12000, loss: 0.274016
 >> iter 13000, loss: 0.262483
 >> iter 14000, loss: 0.198036
 >> iter 15000, loss: 0.208970
 >> iter 16000, loss: 0.303519
 >> iter 17000, loss: 0.313685
 >> iter 18000, loss: 0.229281
 >> iter 19000, loss: 0.171505
 >> iter 20000, loss: 0.281204
   Number of active neurons: 3
 >> iter 21000, loss: 0.278691
 >> iter 22000, loss: 0.200864
 >> iter 23000, loss: 0.302547
 >> iter 24000, loss: 0.214930
 >> iter 25000, loss: 0.199558
 >> iter 26000, loss: 0.372377
 >> iter 27000, loss: 0.259333
 >> iter 28000, loss: 0.254339
 >> iter 29000, loss: 0.205506
 >> iter 30000, loss: 0.180978
   Number of active neurons: 3
 >> iter 31000, loss: 0.295979
 >> iter 32000, loss: 0.258184
 >> iter 33000, loss: 0.272350
 >> iter 34000, loss: 0.249675
 >> iter 35000, loss: 0.281393
 >> iter 36000, loss: 0.259779
 >> iter 37000, loss: 0.228783
 >> iter 38000, loss: 0.118294
 >> iter 39000, loss: 0.159295
 >> iter 40000, loss: 0.162714
   Number of active neurons: 3
 >> iter 41000, loss: 0.281586
 >> iter 42000, loss: 0.333812
 >> iter 43000, loss: 0.222841
 >> iter 44000, loss: 0.207104
 >> iter 45000, loss: 0.263245
 >> iter 46000, loss: 0.159453
 >> iter 47000, loss: 0.236981
 >> iter 48000, loss: 0.194492
 >> iter 49000, loss: 0.192353
 >> iter 50000, loss: 0.200361
   Number of active neurons: 3
 >> iter 51000, loss: 0.418150
 >> iter 52000, loss: 0.275077
 >> iter 53000, loss: 0.179445
 >> iter 54000, loss: 0.246876
 >> iter 55000, loss: 0.168166
 >> iter 56000, loss: 0.203742
 >> iter 57000, loss: 0.202365
 >> iter 58000, loss: 0.198509
 >> iter 59000, loss: 0.230408
 >> iter 60000, loss: 0.215368
   Number of active neurons: 3
 >> iter 61000, loss: 0.278565
 >> iter 62000, loss: 0.191357
 >> iter 63000, loss: 0.140008
 >> iter 64000, loss: 0.312783
 >> iter 65000, loss: 0.245830
 >> iter 66000, loss: 0.202625
 >> iter 67000, loss: 0.256917
 >> iter 68000, loss: 0.141228
 >> iter 69000, loss: 0.137814
 >> iter 70000, loss: 0.213227
   Number of active neurons: 3
 >> iter 71000, loss: 0.261484
 >> iter 72000, loss: 0.328224
 >> iter 73000, loss: 0.275211
 >> iter 74000, loss: 0.291366
 >> iter 75000, loss: 0.411848
 >> iter 76000, loss: 0.227882
 >> iter 77000, loss: 0.191077
 >> iter 78000, loss: 0.154923
 >> iter 79000, loss: 0.146523
 >> iter 80000, loss: 0.207517
   Number of active neurons: 3
 >> iter 81000, loss: 0.137765
 >> iter 82000, loss: 0.117302
 >> iter 83000, loss: 0.259360
 >> iter 84000, loss: 0.213905
 >> iter 85000, loss: 0.336024
 >> iter 86000, loss: 0.203581
 >> iter 87000, loss: 0.248565
 >> iter 88000, loss: 0.212055
 >> iter 89000, loss: 0.173342
 >> iter 90000, loss: 0.263341
   Number of active neurons: 3
 >> iter 91000, loss: 0.194717
 >> iter 92000, loss: 0.337402
 >> iter 93000, loss: 0.248112
 >> iter 94000, loss: 0.153437
 >> iter 95000, loss: 0.092934
 >> iter 96000, loss: 0.203520
 >> iter 97000, loss: 0.298721
 >> iter 98000, loss: 0.183024
 >> iter 99000, loss: 0.200279
 >> iter 100000, loss: 0.258880
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

