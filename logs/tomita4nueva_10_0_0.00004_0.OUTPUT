 > Problema: tomita4nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 4e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 14.858918
 >> iter 2000, loss: 5.575690
 >> iter 3000, loss: 2.069927
 >> iter 4000, loss: 0.774923
 >> iter 5000, loss: 0.296903
 >> iter 6000, loss: 0.287837
 >> iter 7000, loss: 0.119637
 >> iter 8000, loss: 0.055466
 >> iter 9000, loss: 0.030863
 >> iter 10000, loss: 0.141574
   Number of active neurons: 4
 >> iter 11000, loss: 0.069141
 >> iter 12000, loss: 0.373536
 >> iter 13000, loss: 0.151686
 >> iter 14000, loss: 0.067714
 >> iter 15000, loss: 0.034957
 >> iter 16000, loss: 0.226845
 >> iter 17000, loss: 0.141088
 >> iter 18000, loss: 0.139277
 >> iter 19000, loss: 0.061373
 >> iter 20000, loss: 0.278573
   Number of active neurons: 4
 >> iter 21000, loss: 0.296307
 >> iter 22000, loss: 0.124501
 >> iter 23000, loss: 0.057587
 >> iter 24000, loss: 0.067363
 >> iter 25000, loss: 0.034381
 >> iter 26000, loss: 0.021941
 >> iter 27000, loss: 0.160897
 >> iter 28000, loss: 0.069927
 >> iter 29000, loss: 0.053121
 >> iter 30000, loss: 0.410642
   Number of active neurons: 4
 >> iter 31000, loss: 0.168341
 >> iter 32000, loss: 0.074900
 >> iter 33000, loss: 0.036970
 >> iter 34000, loss: 0.184318
 >> iter 35000, loss: 0.097025
 >> iter 36000, loss: 0.045683
 >> iter 37000, loss: 0.101189
 >> iter 38000, loss: 0.079388
 >> iter 39000, loss: 0.053652
 >> iter 40000, loss: 0.058680
   Number of active neurons: 3
 >> iter 41000, loss: 0.049512
 >> iter 42000, loss: 0.218280
 >> iter 43000, loss: 0.091325
 >> iter 44000, loss: 0.299758
 >> iter 45000, loss: 0.215432
 >> iter 46000, loss: 0.210281
 >> iter 47000, loss: 0.107562
 >> iter 48000, loss: 0.050543
 >> iter 49000, loss: 0.231890
 >> iter 50000, loss: 0.096771
   Number of active neurons: 3
 >> iter 51000, loss: 0.170954
 >> iter 52000, loss: 0.074294
 >> iter 53000, loss: 0.036759
 >> iter 54000, loss: 0.021984
 >> iter 55000, loss: 0.033886
 >> iter 56000, loss: 0.020172
 >> iter 57000, loss: 0.040386
 >> iter 58000, loss: 0.022681
 >> iter 59000, loss: 0.232519
 >> iter 60000, loss: 0.127768
   Number of active neurons: 3
 >> iter 61000, loss: 0.079105
 >> iter 62000, loss: 0.042026
 >> iter 63000, loss: 0.113284
 >> iter 64000, loss: 0.051635
 >> iter 65000, loss: 0.138695
 >> iter 66000, loss: 0.061433
 >> iter 67000, loss: 0.079421
 >> iter 68000, loss: 0.038078
 >> iter 69000, loss: 0.035730
 >> iter 70000, loss: 0.020735
   Number of active neurons: 3
 >> iter 71000, loss: 0.086294
 >> iter 72000, loss: 0.039921
 >> iter 73000, loss: 0.081380
 >> iter 74000, loss: 0.038317
 >> iter 75000, loss: 0.081854
 >> iter 76000, loss: 0.038698
 >> iter 77000, loss: 0.215121
 >> iter 78000, loss: 0.090402
 >> iter 79000, loss: 0.140410
 >> iter 80000, loss: 0.061388
   Number of active neurons: 3
 >> iter 81000, loss: 0.065983
 >> iter 82000, loss: 0.032688
 >> iter 83000, loss: 0.062978
 >> iter 84000, loss: 0.030719
 >> iter 85000, loss: 0.059232
 >> iter 86000, loss: 0.029056
 >> iter 87000, loss: 0.018213
 >> iter 88000, loss: 0.013307
 >> iter 89000, loss: 0.044650
 >> iter 90000, loss: 0.080030
   Number of active neurons: 3
 >> iter 91000, loss: 0.044344
 >> iter 92000, loss: 0.043326
 >> iter 93000, loss: 0.095583
 >> iter 94000, loss: 0.042582
 >> iter 95000, loss: 0.046046
 >> iter 96000, loss: 0.023675
 >> iter 97000, loss: 0.031896
 >> iter 98000, loss: 0.018659
 >> iter 99000, loss: 0.078558
 >> iter 100000, loss: 0.037165
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0019999600008
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.900134
 >> iter 2000, loss: 6.766772
 >> iter 3000, loss: 2.553415
 >> iter 4000, loss: 0.956504
 >> iter 5000, loss: 0.371840
 >> iter 6000, loss: 0.227367
 >> iter 7000, loss: 0.098374
 >> iter 8000, loss: 0.046363
 >> iter 9000, loss: 0.195942
 >> iter 10000, loss: 0.083067
   Number of active neurons: 7
 >> iter 11000, loss: 0.075611
 >> iter 12000, loss: 0.037435
 >> iter 13000, loss: 0.074362
 >> iter 14000, loss: 0.076894
 >> iter 15000, loss: 0.102670
 >> iter 16000, loss: 0.047507
 >> iter 17000, loss: 0.047251
 >> iter 18000, loss: 0.026142
 >> iter 19000, loss: 0.045867
 >> iter 20000, loss: 0.059099
   Number of active neurons: 6
 >> iter 21000, loss: 0.105232
 >> iter 22000, loss: 0.200844
 >> iter 23000, loss: 0.085399
 >> iter 24000, loss: 0.040998
 >> iter 25000, loss: 0.048476
 >> iter 26000, loss: 0.041914
 >> iter 27000, loss: 0.039548
 >> iter 28000, loss: 0.159763
 >> iter 29000, loss: 0.069087
 >> iter 30000, loss: 0.034492
   Number of active neurons: 4
 >> iter 31000, loss: 0.043038
 >> iter 32000, loss: 0.027818
 >> iter 33000, loss: 0.048560
 >> iter 34000, loss: 0.066764
 >> iter 35000, loss: 0.055963
 >> iter 36000, loss: 0.071177
 >> iter 37000, loss: 0.067663
 >> iter 38000, loss: 0.032747
 >> iter 39000, loss: 0.035222
 >> iter 40000, loss: 0.020652
   Number of active neurons: 3
 >> iter 41000, loss: 0.033955
 >> iter 42000, loss: 0.019827
 >> iter 43000, loss: 0.182700
 >> iter 44000, loss: 0.075293
 >> iter 45000, loss: 0.054122
 >> iter 46000, loss: 0.073271
 >> iter 47000, loss: 0.034606
 >> iter 48000, loss: 0.020001
 >> iter 49000, loss: 0.064217
 >> iter 50000, loss: 0.033854
   Number of active neurons: 3
 >> iter 51000, loss: 0.063109
 >> iter 52000, loss: 0.105888
 >> iter 53000, loss: 0.078726
 >> iter 54000, loss: 0.063557
 >> iter 55000, loss: 0.030476
 >> iter 56000, loss: 0.018009
 >> iter 57000, loss: 0.023149
 >> iter 58000, loss: 0.015950
 >> iter 59000, loss: 0.026407
 >> iter 60000, loss: 0.167084
   Number of active neurons: 3
 >> iter 61000, loss: 0.077574
 >> iter 62000, loss: 0.149096
 >> iter 63000, loss: 0.081316
 >> iter 64000, loss: 0.145218
 >> iter 65000, loss: 0.062202
 >> iter 66000, loss: 0.243476
 >> iter 67000, loss: 0.156716
 >> iter 68000, loss: 0.176729
 >> iter 69000, loss: 0.118219
 >> iter 70000, loss: 0.131272
   Number of active neurons: 3
 >> iter 71000, loss: 0.057794
 >> iter 72000, loss: 0.029671
 >> iter 73000, loss: 0.069265
 >> iter 74000, loss: 0.085789
 >> iter 75000, loss: 0.039469
 >> iter 76000, loss: 0.100429
 >> iter 77000, loss: 0.144409
 >> iter 78000, loss: 0.062283
 >> iter 79000, loss: 0.031000
 >> iter 80000, loss: 0.144744
   Number of active neurons: 3
 >> iter 81000, loss: 0.081331
 >> iter 82000, loss: 0.172640
 >> iter 83000, loss: 0.118594
 >> iter 84000, loss: 0.052332
 >> iter 85000, loss: 0.104297
 >> iter 86000, loss: 0.047116
 >> iter 87000, loss: 0.025171
 >> iter 88000, loss: 0.016276
 >> iter 89000, loss: 0.066414
 >> iter 90000, loss: 0.031880
   Number of active neurons: 3
 >> iter 91000, loss: 0.134027
 >> iter 92000, loss: 0.057682
 >> iter 93000, loss: 0.060372
 >> iter 94000, loss: 0.029912
 >> iter 95000, loss: 0.088132
 >> iter 96000, loss: 0.040235
 >> iter 97000, loss: 0.066441
 >> iter 98000, loss: 0.031957
 >> iter 99000, loss: 0.036511
 >> iter 100000, loss: 0.020460
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0129998700013
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 16.432097
 >> iter 2000, loss: 6.488065
 >> iter 3000, loss: 2.414027
 >> iter 4000, loss: 0.902997
 >> iter 5000, loss: 0.344367
 >> iter 6000, loss: 0.152611
 >> iter 7000, loss: 0.066184
 >> iter 8000, loss: 0.154184
 >> iter 9000, loss: 0.089404
 >> iter 10000, loss: 0.046036
   Number of active neurons: 4
 >> iter 11000, loss: 0.052934
 >> iter 12000, loss: 0.203604
 >> iter 13000, loss: 0.085313
 >> iter 14000, loss: 0.040711
 >> iter 15000, loss: 0.024158
 >> iter 16000, loss: 0.019148
 >> iter 17000, loss: 0.014848
 >> iter 18000, loss: 0.917659
 >> iter 19000, loss: 0.520729
 >> iter 20000, loss: 0.207862
   Number of active neurons: 4
 >> iter 21000, loss: 0.087978
 >> iter 22000, loss: 0.042001
 >> iter 23000, loss: 0.023805
 >> iter 24000, loss: 0.024658
 >> iter 25000, loss: 0.100407
 >> iter 26000, loss: 0.373670
 >> iter 27000, loss: 0.149992
 >> iter 28000, loss: 0.180267
 >> iter 29000, loss: 0.075328
 >> iter 30000, loss: 0.155339
   Number of active neurons: 4
 >> iter 31000, loss: 0.240486
 >> iter 32000, loss: 0.212415
 >> iter 33000, loss: 0.170695
 >> iter 34000, loss: 0.184579
 >> iter 35000, loss: 0.077812
 >> iter 36000, loss: 0.156203
 >> iter 37000, loss: 0.126056
 >> iter 38000, loss: 0.058858
 >> iter 39000, loss: 0.111506
 >> iter 40000, loss: 0.170223
   Number of active neurons: 4
 >> iter 41000, loss: 0.166287
 >> iter 42000, loss: 0.119967
 >> iter 43000, loss: 0.098404
 >> iter 44000, loss: 0.047230
 >> iter 45000, loss: 0.057570
 >> iter 46000, loss: 0.142829
 >> iter 47000, loss: 0.061145
 >> iter 48000, loss: 0.038056
 >> iter 49000, loss: 0.329727
 >> iter 50000, loss: 0.160093
   Number of active neurons: 4
 >> iter 51000, loss: 0.132851
 >> iter 52000, loss: 0.173637
 >> iter 53000, loss: 0.137574
 >> iter 54000, loss: 0.175505
 >> iter 55000, loss: 0.214331
 >> iter 56000, loss: 0.090301
 >> iter 57000, loss: 0.042564
 >> iter 58000, loss: 0.147180
 >> iter 59000, loss: 0.158470
 >> iter 60000, loss: 0.216079
   Number of active neurons: 4
 >> iter 61000, loss: 0.191474
 >> iter 62000, loss: 0.191211
 >> iter 63000, loss: 0.183053
 >> iter 64000, loss: 0.078576
 >> iter 65000, loss: 0.037325
 >> iter 66000, loss: 0.139650
 >> iter 67000, loss: 0.085136
 >> iter 68000, loss: 0.155789
 >> iter 69000, loss: 0.065235
 >> iter 70000, loss: 0.195900
   Number of active neurons: 4
 >> iter 71000, loss: 0.092836
 >> iter 72000, loss: 0.042801
 >> iter 73000, loss: 0.049397
 >> iter 74000, loss: 0.028169
 >> iter 75000, loss: 0.098049
 >> iter 76000, loss: 0.165115
 >> iter 77000, loss: 0.164277
 >> iter 78000, loss: 0.074032
 >> iter 79000, loss: 0.210479
 >> iter 80000, loss: 0.090480
   Number of active neurons: 4
 >> iter 81000, loss: 0.066055
 >> iter 82000, loss: 0.142357
 >> iter 83000, loss: 0.086705
 >> iter 84000, loss: 0.154861
 >> iter 85000, loss: 0.105595
 >> iter 86000, loss: 0.050193
 >> iter 87000, loss: 0.089488
 >> iter 88000, loss: 0.047671
 >> iter 89000, loss: 0.102848
 >> iter 90000, loss: 0.067821
   Number of active neurons: 4
 >> iter 91000, loss: 0.032803
 >> iter 92000, loss: 0.084231
 >> iter 93000, loss: 0.038879
 >> iter 94000, loss: 0.402007
 >> iter 95000, loss: 0.161690
 >> iter 96000, loss: 0.069680
 >> iter 97000, loss: 0.115935
 >> iter 98000, loss: 0.157630
 >> iter 99000, loss: 0.067036
 >> iter 100000, loss: 0.159157
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.527342
 >> iter 2000, loss: 6.434925
 >> iter 3000, loss: 2.385964
 >> iter 4000, loss: 0.933951
 >> iter 5000, loss: 0.462034
 >> iter 6000, loss: 0.184955
 >> iter 7000, loss: 0.137824
 >> iter 8000, loss: 0.066275
 >> iter 9000, loss: 0.109389
 >> iter 10000, loss: 0.171664
   Number of active neurons: 7
 >> iter 11000, loss: 0.075344
 >> iter 12000, loss: 0.335412
 >> iter 13000, loss: 0.136552
 >> iter 14000, loss: 0.374940
 >> iter 15000, loss: 0.172747
 >> iter 16000, loss: 0.271706
 >> iter 17000, loss: 0.198727
 >> iter 18000, loss: 0.137384
 >> iter 19000, loss: 0.060501
 >> iter 20000, loss: 0.035720
   Number of active neurons: 5
 >> iter 21000, loss: 0.156123
 >> iter 22000, loss: 0.067759
 >> iter 23000, loss: 0.105526
 >> iter 24000, loss: 0.054087
 >> iter 25000, loss: 0.031650
 >> iter 26000, loss: 0.213815
 >> iter 27000, loss: 0.188135
 >> iter 28000, loss: 0.079592
 >> iter 29000, loss: 0.082324
 >> iter 30000, loss: 0.039084
   Number of active neurons: 5
 >> iter 31000, loss: 0.069312
 >> iter 32000, loss: 0.159363
 >> iter 33000, loss: 0.088856
 >> iter 34000, loss: 0.220717
 >> iter 35000, loss: 0.090866
 >> iter 36000, loss: 0.057727
 >> iter 37000, loss: 0.068397
 >> iter 38000, loss: 0.122874
 >> iter 39000, loss: 0.053271
 >> iter 40000, loss: 0.207762
   Number of active neurons: 5
 >> iter 41000, loss: 0.114556
 >> iter 42000, loss: 0.064984
 >> iter 43000, loss: 0.065167
 >> iter 44000, loss: 0.150014
 >> iter 45000, loss: 0.111863
 >> iter 46000, loss: 0.053523
 >> iter 47000, loss: 0.121797
 >> iter 48000, loss: 0.163260
 >> iter 49000, loss: 0.148644
 >> iter 50000, loss: 0.235633
   Number of active neurons: 5
 >> iter 51000, loss: 0.159837
 >> iter 52000, loss: 0.181400
 >> iter 53000, loss: 0.100378
 >> iter 54000, loss: 0.156757
 >> iter 55000, loss: 0.199504
 >> iter 56000, loss: 0.276858
 >> iter 57000, loss: 0.115088
 >> iter 58000, loss: 0.053877
 >> iter 59000, loss: 0.129827
 >> iter 60000, loss: 0.059396
   Number of active neurons: 5
 >> iter 61000, loss: 0.131148
 >> iter 62000, loss: 0.159610
 >> iter 63000, loss: 0.137110
 >> iter 64000, loss: 0.171076
 >> iter 65000, loss: 0.207007
 >> iter 66000, loss: 0.087486
 >> iter 67000, loss: 0.137368
 >> iter 68000, loss: 0.061784
 >> iter 69000, loss: 0.214364
 >> iter 70000, loss: 0.193101
   Number of active neurons: 5
 >> iter 71000, loss: 0.082318
 >> iter 72000, loss: 0.150028
 >> iter 73000, loss: 0.167970
 >> iter 74000, loss: 0.072427
 >> iter 75000, loss: 0.102812
 >> iter 76000, loss: 0.243182
 >> iter 77000, loss: 0.100376
 >> iter 78000, loss: 0.129830
 >> iter 79000, loss: 0.056656
 >> iter 80000, loss: 0.232573
   Number of active neurons: 4
 >> iter 81000, loss: 0.173001
 >> iter 82000, loss: 0.072724
 >> iter 83000, loss: 0.108760
 >> iter 84000, loss: 0.052230
 >> iter 85000, loss: 0.144973
 >> iter 86000, loss: 0.063632
 >> iter 87000, loss: 0.031792
 >> iter 88000, loss: 0.138427
 >> iter 89000, loss: 0.058989
 >> iter 90000, loss: 0.031199
   Number of active neurons: 4
 >> iter 91000, loss: 0.103477
 >> iter 92000, loss: 0.049498
 >> iter 93000, loss: 0.025367
 >> iter 94000, loss: 0.137308
 >> iter 95000, loss: 0.182461
 >> iter 96000, loss: 0.190293
 >> iter 97000, loss: 0.080215
 >> iter 98000, loss: 0.154320
 >> iter 99000, loss: 0.064780
 >> iter 100000, loss: 0.048607
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.343320
 >> iter 2000, loss: 6.043101
 >> iter 3000, loss: 2.251702
 >> iter 4000, loss: 0.879834
 >> iter 5000, loss: 0.338372
 >> iter 6000, loss: 0.136552
 >> iter 7000, loss: 0.062012
 >> iter 8000, loss: 0.128102
 >> iter 9000, loss: 0.057365
 >> iter 10000, loss: 0.129238
   Number of active neurons: 4
 >> iter 11000, loss: 0.057817
 >> iter 12000, loss: 0.128270
 >> iter 13000, loss: 0.057437
 >> iter 14000, loss: 0.127283
 >> iter 15000, loss: 0.056823
 >> iter 16000, loss: 0.121133
 >> iter 17000, loss: 0.054126
 >> iter 18000, loss: 0.029200
 >> iter 19000, loss: 0.018853
 >> iter 20000, loss: 0.110107
   Number of active neurons: 4
 >> iter 21000, loss: 0.048778
 >> iter 22000, loss: 0.026640
 >> iter 23000, loss: 0.017210
 >> iter 24000, loss: 0.109492
 >> iter 25000, loss: 0.048112
 >> iter 26000, loss: 0.025019
 >> iter 27000, loss: 0.016539
 >> iter 28000, loss: 0.015166
 >> iter 29000, loss: 0.052150
 >> iter 30000, loss: 0.027105
   Number of active neurons: 4
 >> iter 31000, loss: 0.016635
 >> iter 32000, loss: 0.021670
 >> iter 33000, loss: 0.015880
 >> iter 34000, loss: 0.012783
 >> iter 35000, loss: 0.010757
 >> iter 36000, loss: 0.014781
 >> iter 37000, loss: 0.022254
 >> iter 38000, loss: 0.015869
 >> iter 39000, loss: 0.080218
 >> iter 40000, loss: 0.036055
   Number of active neurons: 3
 >> iter 41000, loss: 0.026225
 >> iter 42000, loss: 0.027510
 >> iter 43000, loss: 0.016490
 >> iter 44000, loss: 0.013539
 >> iter 45000, loss: 0.010558
 >> iter 46000, loss: 0.151631
 >> iter 47000, loss: 0.083308
 >> iter 48000, loss: 0.076365
 >> iter 49000, loss: 0.034772
 >> iter 50000, loss: 0.019787
   Number of active neurons: 3
 >> iter 51000, loss: 0.015006
 >> iter 52000, loss: 0.012417
 >> iter 53000, loss: 0.015133
 >> iter 54000, loss: 0.058590
 >> iter 55000, loss: 0.027732
 >> iter 56000, loss: 0.019948
 >> iter 57000, loss: 0.098484
 >> iter 58000, loss: 0.050289
 >> iter 59000, loss: 0.175508
 >> iter 60000, loss: 0.074281
   Number of active neurons: 3
 >> iter 61000, loss: 0.079607
 >> iter 62000, loss: 0.106496
 >> iter 63000, loss: 0.110518
 >> iter 64000, loss: 0.049178
 >> iter 65000, loss: 0.142528
 >> iter 66000, loss: 0.061530
 >> iter 67000, loss: 0.120841
 >> iter 68000, loss: 0.114518
 >> iter 69000, loss: 0.050851
 >> iter 70000, loss: 0.124084
   Number of active neurons: 3
 >> iter 71000, loss: 0.138739
 >> iter 72000, loss: 0.165865
 >> iter 73000, loss: 0.070308
 >> iter 74000, loss: 0.097903
 >> iter 75000, loss: 0.162820
 >> iter 76000, loss: 0.175156
 >> iter 77000, loss: 0.137887
 >> iter 78000, loss: 0.085261
 >> iter 79000, loss: 0.267153
 >> iter 80000, loss: 0.247089
   Number of active neurons: 3
 >> iter 81000, loss: 0.102799
 >> iter 82000, loss: 0.047818
 >> iter 83000, loss: 0.026381
 >> iter 84000, loss: 0.027900
 >> iter 85000, loss: 0.017815
 >> iter 86000, loss: 0.025511
 >> iter 87000, loss: 0.016043
 >> iter 88000, loss: 0.123698
 >> iter 89000, loss: 0.051855
 >> iter 90000, loss: 0.029342
   Number of active neurons: 3
 >> iter 91000, loss: 0.016725
 >> iter 92000, loss: 0.124024
 >> iter 93000, loss: 0.051501
 >> iter 94000, loss: 0.109272
 >> iter 95000, loss: 0.046329
 >> iter 96000, loss: 0.122448
 >> iter 97000, loss: 0.051232
 >> iter 98000, loss: 0.025585
 >> iter 99000, loss: 0.254361
 >> iter 100000, loss: 0.100806
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.502311
 >> iter 2000, loss: 6.089316
 >> iter 3000, loss: 2.264062
 >> iter 4000, loss: 0.849585
 >> iter 5000, loss: 0.363778
 >> iter 6000, loss: 0.145329
 >> iter 7000, loss: 0.213436
 >> iter 8000, loss: 0.091589
 >> iter 9000, loss: 0.148544
 >> iter 10000, loss: 0.067160
   Number of active neurons: 4
 >> iter 11000, loss: 0.140897
 >> iter 12000, loss: 0.067230
 >> iter 13000, loss: 0.161297
 >> iter 14000, loss: 0.073293
 >> iter 15000, loss: 0.037378
 >> iter 16000, loss: 0.071893
 >> iter 17000, loss: 0.325891
 >> iter 18000, loss: 0.282531
 >> iter 19000, loss: 0.138855
 >> iter 20000, loss: 0.151234
   Number of active neurons: 4
 >> iter 21000, loss: 0.065626
 >> iter 22000, loss: 0.148334
 >> iter 23000, loss: 0.062865
 >> iter 24000, loss: 0.032591
 >> iter 25000, loss: 0.019013
 >> iter 26000, loss: 0.138818
 >> iter 27000, loss: 0.058072
 >> iter 28000, loss: 0.540543
 >> iter 29000, loss: 0.213718
 >> iter 30000, loss: 0.162504
   Number of active neurons: 4
 >> iter 31000, loss: 0.068903
 >> iter 32000, loss: 0.152189
 >> iter 33000, loss: 0.064399
 >> iter 34000, loss: 0.152359
 >> iter 35000, loss: 0.090498
 >> iter 36000, loss: 0.158836
 >> iter 37000, loss: 0.119188
 >> iter 38000, loss: 0.055241
 >> iter 39000, loss: 0.089590
 >> iter 40000, loss: 0.062204
   Number of active neurons: 4
 >> iter 41000, loss: 0.031262
 >> iter 42000, loss: 0.020234
 >> iter 43000, loss: 0.186472
 >> iter 44000, loss: 0.078822
 >> iter 45000, loss: 0.133279
 >> iter 46000, loss: 0.062647
 >> iter 47000, loss: 0.145065
 >> iter 48000, loss: 0.066419
 >> iter 49000, loss: 0.033266
 >> iter 50000, loss: 0.142138
   Number of active neurons: 4
 >> iter 51000, loss: 0.133195
 >> iter 52000, loss: 0.060002
 >> iter 53000, loss: 0.141388
 >> iter 54000, loss: 0.170877
 >> iter 55000, loss: 0.072818
 >> iter 56000, loss: 0.151304
 >> iter 57000, loss: 0.111106
 >> iter 58000, loss: 0.217015
 >> iter 59000, loss: 0.089760
 >> iter 60000, loss: 0.041853
   Number of active neurons: 4
 >> iter 61000, loss: 0.106451
 >> iter 62000, loss: 0.048807
 >> iter 63000, loss: 0.279574
 >> iter 64000, loss: 0.116978
 >> iter 65000, loss: 0.054151
 >> iter 66000, loss: 0.142160
 >> iter 67000, loss: 0.061802
 >> iter 68000, loss: 0.150434
 >> iter 69000, loss: 0.101928
 >> iter 70000, loss: 0.068543
   Number of active neurons: 4
 >> iter 71000, loss: 0.136750
 >> iter 72000, loss: 0.059970
 >> iter 73000, loss: 0.106383
 >> iter 74000, loss: 0.050318
 >> iter 75000, loss: 0.119501
 >> iter 76000, loss: 0.067393
 >> iter 77000, loss: 0.084784
 >> iter 78000, loss: 0.044219
 >> iter 79000, loss: 0.024275
 >> iter 80000, loss: 0.139287
   Number of active neurons: 4
 >> iter 81000, loss: 0.058925
 >> iter 82000, loss: 0.030129
 >> iter 83000, loss: 0.091448
 >> iter 84000, loss: 0.161748
 >> iter 85000, loss: 0.117071
 >> iter 86000, loss: 0.053300
 >> iter 87000, loss: 0.027794
 >> iter 88000, loss: 0.134723
 >> iter 89000, loss: 0.131678
 >> iter 90000, loss: 0.058404
   Number of active neurons: 4
 >> iter 91000, loss: 0.073882
 >> iter 92000, loss: 0.039321
 >> iter 93000, loss: 0.022125
 >> iter 94000, loss: 0.133648
 >> iter 95000, loss: 0.057118
 >> iter 96000, loss: 0.108784
 >> iter 97000, loss: 0.094480
 >> iter 98000, loss: 0.044869
 >> iter 99000, loss: 0.101339
 >> iter 100000, loss: 0.046255
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.009999800004
   - Test - Long: 0.0949952502375
   - Test - Big: 0.00999990000101
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 15.940264
 >> iter 2000, loss: 6.260688
 >> iter 3000, loss: 2.322469
 >> iter 4000, loss: 0.867861
 >> iter 5000, loss: 0.330907
 >> iter 6000, loss: 0.132021
 >> iter 7000, loss: 0.103150
 >> iter 8000, loss: 0.048083
 >> iter 9000, loss: 0.070768
 >> iter 10000, loss: 0.036196
   Number of active neurons: 5
 >> iter 11000, loss: 0.024100
 >> iter 12000, loss: 0.017462
 >> iter 13000, loss: 0.122930
 >> iter 14000, loss: 0.055690
 >> iter 15000, loss: 0.038750
 >> iter 16000, loss: 0.022899
 >> iter 17000, loss: 0.168900
 >> iter 18000, loss: 0.073220
 >> iter 19000, loss: 0.036801
 >> iter 20000, loss: 0.022547
   Number of active neurons: 5
 >> iter 21000, loss: 0.021886
 >> iter 22000, loss: 0.016261
 >> iter 23000, loss: 0.043264
 >> iter 24000, loss: 0.024356
 >> iter 25000, loss: 0.028223
 >> iter 26000, loss: 0.018139
 >> iter 27000, loss: 0.051462
 >> iter 28000, loss: 0.027565
 >> iter 29000, loss: 0.176561
 >> iter 30000, loss: 0.075259
   Number of active neurons: 4
 >> iter 31000, loss: 0.036260
 >> iter 32000, loss: 0.021970
 >> iter 33000, loss: 0.031235
 >> iter 34000, loss: 0.174698
 >> iter 35000, loss: 0.073399
 >> iter 36000, loss: 0.035302
 >> iter 37000, loss: 0.186182
 >> iter 38000, loss: 0.079333
 >> iter 39000, loss: 0.038640
 >> iter 40000, loss: 0.113278
   Number of active neurons: 4
 >> iter 41000, loss: 0.051114
 >> iter 42000, loss: 0.027357
 >> iter 43000, loss: 0.052196
 >> iter 44000, loss: 0.027266
 >> iter 45000, loss: 0.068997
 >> iter 46000, loss: 0.033361
 >> iter 47000, loss: 0.128452
 >> iter 48000, loss: 0.055968
 >> iter 49000, loss: 0.028609
 >> iter 50000, loss: 0.093351
   Number of active neurons: 4
 >> iter 51000, loss: 0.076318
 >> iter 52000, loss: 0.036958
 >> iter 53000, loss: 0.059929
 >> iter 54000, loss: 0.030660
 >> iter 55000, loss: 0.077661
 >> iter 56000, loss: 0.143246
 >> iter 57000, loss: 0.092927
 >> iter 58000, loss: 0.044537
 >> iter 59000, loss: 0.076487
 >> iter 60000, loss: 0.038945
   Number of active neurons: 4
 >> iter 61000, loss: 0.022295
 >> iter 62000, loss: 0.016679
 >> iter 63000, loss: 0.072103
 >> iter 64000, loss: 0.044078
 >> iter 65000, loss: 0.023730
 >> iter 66000, loss: 0.024099
 >> iter 67000, loss: 0.017194
 >> iter 68000, loss: 0.424873
 >> iter 69000, loss: 0.181229
 >> iter 70000, loss: 0.639464
   Number of active neurons: 5
 >> iter 71000, loss: 0.296997
 >> iter 72000, loss: 0.122054
 >> iter 73000, loss: 0.073375
 >> iter 74000, loss: 0.036226
 >> iter 75000, loss: 0.027350
 >> iter 76000, loss: 0.685738
 >> iter 77000, loss: 0.335050
 >> iter 78000, loss: 0.578229
 >> iter 79000, loss: 0.233136
 >> iter 80000, loss: 0.305293
   Number of active neurons: 4
 >> iter 81000, loss: 0.134473
 >> iter 82000, loss: 0.181508
 >> iter 83000, loss: 0.078885
 >> iter 84000, loss: 0.159856
 >> iter 85000, loss: 0.068811
 >> iter 86000, loss: 0.511017
 >> iter 87000, loss: 0.209188
 >> iter 88000, loss: 0.339388
 >> iter 89000, loss: 0.211793
 >> iter 90000, loss: 0.168446
   Number of active neurons: 6
 >> iter 91000, loss: 0.072896
 >> iter 92000, loss: 0.036336
 >> iter 93000, loss: 0.021920
 >> iter 94000, loss: 0.073562
 >> iter 95000, loss: 0.035490
 >> iter 96000, loss: 0.433352
 >> iter 97000, loss: 0.172683
 >> iter 98000, loss: 0.165727
 >> iter 99000, loss: 0.071351
 >> iter 100000, loss: 0.037530
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 15.864204
 >> iter 2000, loss: 6.611175
 >> iter 3000, loss: 2.465896
 >> iter 4000, loss: 0.926209
 >> iter 5000, loss: 0.355833
 >> iter 6000, loss: 0.143848
 >> iter 7000, loss: 0.135087
 >> iter 8000, loss: 0.061921
 >> iter 9000, loss: 0.033899
 >> iter 10000, loss: 0.022771
   Number of active neurons: 6
 >> iter 11000, loss: 0.364775
 >> iter 12000, loss: 0.184129
 >> iter 13000, loss: 0.081193
 >> iter 14000, loss: 0.041483
 >> iter 15000, loss: 0.049074
 >> iter 16000, loss: 0.027888
 >> iter 17000, loss: 0.093136
 >> iter 18000, loss: 0.082409
 >> iter 19000, loss: 0.039317
 >> iter 20000, loss: 0.022939
   Number of active neurons: 3
 >> iter 21000, loss: 0.051154
 >> iter 22000, loss: 0.031993
 >> iter 23000, loss: 0.019365
 >> iter 24000, loss: 0.016330
 >> iter 25000, loss: 0.079204
 >> iter 26000, loss: 0.068191
 >> iter 27000, loss: 0.224998
 >> iter 28000, loss: 0.094181
 >> iter 29000, loss: 0.043116
 >> iter 30000, loss: 0.026454
   Number of active neurons: 3
 >> iter 31000, loss: 0.148579
 >> iter 32000, loss: 0.139532
 >> iter 33000, loss: 0.060023
 >> iter 34000, loss: 0.030169
 >> iter 35000, loss: 0.018699
 >> iter 36000, loss: 0.023085
 >> iter 37000, loss: 0.143705
 >> iter 38000, loss: 0.061685
 >> iter 39000, loss: 0.030661
 >> iter 40000, loss: 0.020807
   Number of active neurons: 3
 >> iter 41000, loss: 0.048700
 >> iter 42000, loss: 0.099691
 >> iter 43000, loss: 0.044058
 >> iter 44000, loss: 0.023576
 >> iter 45000, loss: 0.221397
 >> iter 46000, loss: 0.152204
 >> iter 47000, loss: 0.064233
 >> iter 48000, loss: 0.034694
 >> iter 49000, loss: 0.019864
 >> iter 50000, loss: 0.018633
   Number of active neurons: 3
 >> iter 51000, loss: 0.013455
 >> iter 52000, loss: 0.129096
 >> iter 53000, loss: 0.382771
 >> iter 54000, loss: 0.153121
 >> iter 55000, loss: 0.066280
 >> iter 56000, loss: 0.037542
 >> iter 57000, loss: 0.021998
 >> iter 58000, loss: 0.128789
 >> iter 59000, loss: 0.055174
 >> iter 60000, loss: 0.138540
   Number of active neurons: 3
 >> iter 61000, loss: 0.082228
 >> iter 62000, loss: 0.149242
 >> iter 63000, loss: 0.062539
 >> iter 64000, loss: 0.143385
 >> iter 65000, loss: 0.155952
 >> iter 66000, loss: 0.178200
 >> iter 67000, loss: 0.499160
 >> iter 68000, loss: 0.196886
 >> iter 69000, loss: 0.153665
 >> iter 70000, loss: 0.067462
   Number of active neurons: 3
 >> iter 71000, loss: 0.034208
 >> iter 72000, loss: 0.028036
 >> iter 73000, loss: 0.018042
 >> iter 74000, loss: 0.117767
 >> iter 75000, loss: 0.050770
 >> iter 76000, loss: 0.142362
 >> iter 77000, loss: 0.136588
 >> iter 78000, loss: 0.057837
 >> iter 79000, loss: 0.028499
 >> iter 80000, loss: 0.131626
   Number of active neurons: 3
 >> iter 81000, loss: 0.158961
 >> iter 82000, loss: 0.556928
 >> iter 83000, loss: 0.218736
 >> iter 84000, loss: 0.091859
 >> iter 85000, loss: 0.043617
 >> iter 86000, loss: 0.109913
 >> iter 87000, loss: 0.049060
 >> iter 88000, loss: 0.035260
 >> iter 89000, loss: 0.020651
 >> iter 90000, loss: 0.124871
   Number of active neurons: 3
 >> iter 91000, loss: 0.053338
 >> iter 92000, loss: 0.135562
 >> iter 93000, loss: 0.057181
 >> iter 94000, loss: 0.145372
 >> iter 95000, loss: 0.060838
 >> iter 96000, loss: 0.030308
 >> iter 97000, loss: 0.017759
 >> iter 98000, loss: 0.128193
 >> iter 99000, loss: 0.134043
 >> iter 100000, loss: 0.058008
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.685245
 >> iter 2000, loss: 5.872538
 >> iter 3000, loss: 2.197211
 >> iter 4000, loss: 0.820528
 >> iter 5000, loss: 0.347688
 >> iter 6000, loss: 0.140982
 >> iter 7000, loss: 0.183301
 >> iter 8000, loss: 0.161475
 >> iter 9000, loss: 0.151130
 >> iter 10000, loss: 0.462991
   Number of active neurons: 6
 >> iter 11000, loss: 0.205907
 >> iter 12000, loss: 0.088965
 >> iter 13000, loss: 0.072171
 >> iter 14000, loss: 0.079306
 >> iter 15000, loss: 0.227181
 >> iter 16000, loss: 0.095696
 >> iter 17000, loss: 0.396142
 >> iter 18000, loss: 0.159558
 >> iter 19000, loss: 0.155204
 >> iter 20000, loss: 0.068260
   Number of active neurons: 5
 >> iter 21000, loss: 0.132249
 >> iter 22000, loss: 0.086254
 >> iter 23000, loss: 0.206623
 >> iter 24000, loss: 0.087595
 >> iter 25000, loss: 0.073325
 >> iter 26000, loss: 0.110345
 >> iter 27000, loss: 0.061601
 >> iter 28000, loss: 0.082298
 >> iter 29000, loss: 0.055258
 >> iter 30000, loss: 0.067101
   Number of active neurons: 5
 >> iter 31000, loss: 0.052907
 >> iter 32000, loss: 0.151856
 >> iter 33000, loss: 0.075916
 >> iter 34000, loss: 0.035925
 >> iter 35000, loss: 0.094842
 >> iter 36000, loss: 0.060014
 >> iter 37000, loss: 0.029364
 >> iter 38000, loss: 0.182054
 >> iter 39000, loss: 0.080406
 >> iter 40000, loss: 0.172222
   Number of active neurons: 4
 >> iter 41000, loss: 0.145107
 >> iter 42000, loss: 0.063364
 >> iter 43000, loss: 0.064976
 >> iter 44000, loss: 0.179952
 >> iter 45000, loss: 0.291791
 >> iter 46000, loss: 0.120914
 >> iter 47000, loss: 0.074458
 >> iter 48000, loss: 0.095370
 >> iter 49000, loss: 0.085404
 >> iter 50000, loss: 0.083273
   Number of active neurons: 5
 >> iter 51000, loss: 0.183076
 >> iter 52000, loss: 0.184018
 >> iter 53000, loss: 0.078296
 >> iter 54000, loss: 0.329451
 >> iter 55000, loss: 0.290473
 >> iter 56000, loss: 0.254621
 >> iter 57000, loss: 0.106491
 >> iter 58000, loss: 0.076543
 >> iter 59000, loss: 0.140024
 >> iter 60000, loss: 0.313486
   Number of active neurons: 5
 >> iter 61000, loss: 0.145747
 >> iter 62000, loss: 0.064354
 >> iter 63000, loss: 0.205063
 >> iter 64000, loss: 0.088049
 >> iter 65000, loss: 0.056316
 >> iter 66000, loss: 0.184542
 >> iter 67000, loss: 0.102478
 >> iter 68000, loss: 0.048485
 >> iter 69000, loss: 0.122029
 >> iter 70000, loss: 0.055087
   Number of active neurons: 5
 >> iter 71000, loss: 0.134358
 >> iter 72000, loss: 0.202218
 >> iter 73000, loss: 0.107230
 >> iter 74000, loss: 0.127805
 >> iter 75000, loss: 0.137944
 >> iter 76000, loss: 0.160287
 >> iter 77000, loss: 0.069491
 >> iter 78000, loss: 0.558741
 >> iter 79000, loss: 0.304002
 >> iter 80000, loss: 0.124501
   Number of active neurons: 5
 >> iter 81000, loss: 0.091805
 >> iter 82000, loss: 0.052815
 >> iter 83000, loss: 0.077528
 >> iter 84000, loss: 0.045392
 >> iter 85000, loss: 0.120792
 >> iter 86000, loss: 0.110664
 >> iter 87000, loss: 0.072463
 >> iter 88000, loss: 0.097085
 >> iter 89000, loss: 0.044650
 >> iter 90000, loss: 0.171203
   Number of active neurons: 5
 >> iter 91000, loss: 0.226902
 >> iter 92000, loss: 0.238979
 >> iter 93000, loss: 0.101909
 >> iter 94000, loss: 0.049247
 >> iter 95000, loss: 0.103668
 >> iter 96000, loss: 0.085189
 >> iter 97000, loss: 0.056468
 >> iter 98000, loss: 0.036169
 >> iter 99000, loss: 0.080990
 >> iter 100000, loss: 0.110504
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.675958
 >> iter 2000, loss: 6.147367
 >> iter 3000, loss: 2.285950
 >> iter 4000, loss: 0.856647
 >> iter 5000, loss: 0.328045
 >> iter 6000, loss: 0.131832
 >> iter 7000, loss: 0.172403
 >> iter 8000, loss: 0.074807
 >> iter 9000, loss: 0.037659
 >> iter 10000, loss: 0.023110
   Number of active neurons: 5
 >> iter 11000, loss: 0.206073
 >> iter 12000, loss: 0.088227
 >> iter 13000, loss: 0.042992
 >> iter 14000, loss: 0.070652
 >> iter 15000, loss: 0.035555
 >> iter 16000, loss: 0.021919
 >> iter 17000, loss: 0.084141
 >> iter 18000, loss: 0.039667
 >> iter 19000, loss: 0.127425
 >> iter 20000, loss: 0.057146
   Number of active neurons: 5
 >> iter 21000, loss: 0.228722
 >> iter 22000, loss: 0.097904
 >> iter 23000, loss: 0.046735
 >> iter 24000, loss: 0.026867
 >> iter 25000, loss: 0.033076
 >> iter 26000, loss: 0.092891
 >> iter 27000, loss: 0.059307
 >> iter 28000, loss: 0.030936
 >> iter 29000, loss: 0.018939
 >> iter 30000, loss: 0.014781
   Number of active neurons: 5
 >> iter 31000, loss: 0.212031
 >> iter 32000, loss: 0.088041
 >> iter 33000, loss: 0.152973
 >> iter 34000, loss: 0.069064
 >> iter 35000, loss: 0.152653
 >> iter 36000, loss: 0.112630
 >> iter 37000, loss: 0.051643
 >> iter 38000, loss: 0.128049
 >> iter 39000, loss: 0.068344
 >> iter 40000, loss: 0.034456
   Number of active neurons: 4
 >> iter 41000, loss: 0.021119
 >> iter 42000, loss: 0.194296
 >> iter 43000, loss: 0.082427
 >> iter 44000, loss: 0.065435
 >> iter 45000, loss: 0.032752
 >> iter 46000, loss: 0.021844
 >> iter 47000, loss: 0.037918
 >> iter 48000, loss: 0.021676
 >> iter 49000, loss: 0.045669
 >> iter 50000, loss: 0.024226
   Number of active neurons: 4
 >> iter 51000, loss: 0.016096
 >> iter 52000, loss: 0.014247
 >> iter 53000, loss: 0.035274
 >> iter 54000, loss: 0.021029
 >> iter 55000, loss: 0.172406
 >> iter 56000, loss: 0.098750
 >> iter 57000, loss: 0.044981
 >> iter 58000, loss: 0.025687
 >> iter 59000, loss: 0.034800
 >> iter 60000, loss: 0.372060
   Number of active neurons: 4
 >> iter 61000, loss: 0.150844
 >> iter 62000, loss: 0.066345
 >> iter 63000, loss: 0.033886
 >> iter 64000, loss: 0.022127
 >> iter 65000, loss: 0.017122
 >> iter 66000, loss: 0.165722
 >> iter 67000, loss: 0.070742
 >> iter 68000, loss: 0.034942
 >> iter 69000, loss: 0.020936
 >> iter 70000, loss: 0.249656
   Number of active neurons: 4
 >> iter 71000, loss: 0.179002
 >> iter 72000, loss: 0.075497
 >> iter 73000, loss: 0.096991
 >> iter 74000, loss: 0.195889
 >> iter 75000, loss: 0.212121
 >> iter 76000, loss: 0.089931
 >> iter 77000, loss: 0.043520
 >> iter 78000, loss: 0.025286
 >> iter 79000, loss: 0.138743
 >> iter 80000, loss: 0.061284
   Number of active neurons: 4
 >> iter 81000, loss: 0.151220
 >> iter 82000, loss: 0.067097
 >> iter 83000, loss: 0.069693
 >> iter 84000, loss: 0.034798
 >> iter 85000, loss: 0.159923
 >> iter 86000, loss: 0.069144
 >> iter 87000, loss: 0.076443
 >> iter 88000, loss: 0.039069
 >> iter 89000, loss: 0.088252
 >> iter 90000, loss: 0.118838
   Number of active neurons: 4
 >> iter 91000, loss: 0.053066
 >> iter 92000, loss: 0.029457
 >> iter 93000, loss: 0.167179
 >> iter 94000, loss: 0.079776
 >> iter 95000, loss: 0.038459
 >> iter 96000, loss: 0.149488
 >> iter 97000, loss: 0.065194
 >> iter 98000, loss: 0.199994
 >> iter 99000, loss: 0.086293
 >> iter 100000, loss: 0.047971
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.606383
 >> iter 2000, loss: 6.228389
 >> iter 3000, loss: 2.316076
 >> iter 4000, loss: 0.867202
 >> iter 5000, loss: 0.331640
 >> iter 6000, loss: 0.133712
 >> iter 7000, loss: 0.098356
 >> iter 8000, loss: 0.045837
 >> iter 9000, loss: 0.181976
 >> iter 10000, loss: 0.079069
   Number of active neurons: 5
 >> iter 11000, loss: 0.061130
 >> iter 12000, loss: 0.032784
 >> iter 13000, loss: 0.042502
 >> iter 14000, loss: 0.027909
 >> iter 15000, loss: 0.070821
 >> iter 16000, loss: 0.036206
 >> iter 17000, loss: 0.089873
 >> iter 18000, loss: 0.052157
 >> iter 19000, loss: 0.304350
 >> iter 20000, loss: 0.127441
   Number of active neurons: 4
 >> iter 21000, loss: 0.143509
 >> iter 22000, loss: 0.065784
 >> iter 23000, loss: 0.052892
 >> iter 24000, loss: 0.028919
 >> iter 25000, loss: 0.298050
 >> iter 26000, loss: 0.122869
 >> iter 27000, loss: 0.286285
 >> iter 28000, loss: 0.120359
 >> iter 29000, loss: 0.086684
 >> iter 30000, loss: 0.042068
   Number of active neurons: 4
 >> iter 31000, loss: 0.055728
 >> iter 32000, loss: 0.029385
 >> iter 33000, loss: 0.095873
 >> iter 34000, loss: 0.044871
 >> iter 35000, loss: 0.140017
 >> iter 36000, loss: 0.062342
 >> iter 37000, loss: 0.073348
 >> iter 38000, loss: 0.036242
 >> iter 39000, loss: 0.179694
 >> iter 40000, loss: 0.077585
   Number of active neurons: 4
 >> iter 41000, loss: 0.066281
 >> iter 42000, loss: 0.035617
 >> iter 43000, loss: 0.100757
 >> iter 44000, loss: 0.048094
 >> iter 45000, loss: 0.088340
 >> iter 46000, loss: 0.041953
 >> iter 47000, loss: 0.163019
 >> iter 48000, loss: 0.170444
 >> iter 49000, loss: 0.073746
 >> iter 50000, loss: 0.082888
   Number of active neurons: 3
 >> iter 51000, loss: 0.121692
 >> iter 52000, loss: 0.054627
 >> iter 53000, loss: 0.242712
 >> iter 54000, loss: 0.100630
 >> iter 55000, loss: 0.067732
 >> iter 56000, loss: 0.033600
 >> iter 57000, loss: 0.027875
 >> iter 58000, loss: 0.017955
 >> iter 59000, loss: 0.110550
 >> iter 60000, loss: 0.049384
   Number of active neurons: 3
 >> iter 61000, loss: 0.080892
 >> iter 62000, loss: 0.129368
 >> iter 63000, loss: 0.101139
 >> iter 64000, loss: 0.046094
 >> iter 65000, loss: 0.070402
 >> iter 66000, loss: 0.033963
 >> iter 67000, loss: 0.064486
 >> iter 68000, loss: 0.031593
 >> iter 69000, loss: 0.371166
 >> iter 70000, loss: 0.149753
   Number of active neurons: 3
 >> iter 71000, loss: 0.064870
 >> iter 72000, loss: 0.032311
 >> iter 73000, loss: 0.089061
 >> iter 74000, loss: 0.041258
 >> iter 75000, loss: 0.065013
 >> iter 76000, loss: 0.031875
 >> iter 77000, loss: 0.045843
 >> iter 78000, loss: 0.023885
 >> iter 79000, loss: 0.108411
 >> iter 80000, loss: 0.048184
   Number of active neurons: 3
 >> iter 81000, loss: 0.039301
 >> iter 82000, loss: 0.055916
 >> iter 83000, loss: 0.074229
 >> iter 84000, loss: 0.034908
 >> iter 85000, loss: 0.038596
 >> iter 86000, loss: 0.030690
 >> iter 87000, loss: 0.017801
 >> iter 88000, loss: 0.019598
 >> iter 89000, loss: 0.146858
 >> iter 90000, loss: 0.116824
   Number of active neurons: 2
 >> iter 91000, loss: 0.050319
 >> iter 92000, loss: 0.420195
 >> iter 93000, loss: 0.231558
 >> iter 94000, loss: 0.192730
 >> iter 95000, loss: 0.123691
 >> iter 96000, loss: 0.145684
 >> iter 97000, loss: 0.167952
 >> iter 98000, loss: 0.148734
 >> iter 99000, loss: 0.196185
 >> iter 100000, loss: 0.169771
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 15.576240
 >> iter 2000, loss: 5.867055
 >> iter 3000, loss: 2.175780
 >> iter 4000, loss: 0.812824
 >> iter 5000, loss: 0.316171
 >> iter 6000, loss: 0.345664
 >> iter 7000, loss: 0.139339
 >> iter 8000, loss: 0.061501
 >> iter 9000, loss: 0.064603
 >> iter 10000, loss: 0.033104
   Number of active neurons: 5
 >> iter 11000, loss: 0.185413
 >> iter 12000, loss: 0.080169
 >> iter 13000, loss: 0.115228
 >> iter 14000, loss: 0.052740
 >> iter 15000, loss: 0.085590
 >> iter 16000, loss: 0.040307
 >> iter 17000, loss: 0.029831
 >> iter 18000, loss: 0.019840
 >> iter 19000, loss: 0.147874
 >> iter 20000, loss: 0.064625
   Number of active neurons: 4
 >> iter 21000, loss: 0.039196
 >> iter 22000, loss: 0.110927
 >> iter 23000, loss: 0.049965
 >> iter 24000, loss: 0.027475
 >> iter 25000, loss: 0.073051
 >> iter 26000, loss: 0.232821
 >> iter 27000, loss: 0.207459
 >> iter 28000, loss: 0.087156
 >> iter 29000, loss: 0.128648
 >> iter 30000, loss: 0.058872
   Number of active neurons: 5
 >> iter 31000, loss: 0.133458
 >> iter 32000, loss: 0.058869
 >> iter 33000, loss: 0.168480
 >> iter 34000, loss: 0.122487
 >> iter 35000, loss: 0.128372
 >> iter 36000, loss: 0.093049
 >> iter 37000, loss: 0.079866
 >> iter 38000, loss: 0.039934
 >> iter 39000, loss: 0.070015
 >> iter 40000, loss: 0.142360
   Number of active neurons: 5
 >> iter 41000, loss: 0.061749
 >> iter 42000, loss: 0.143928
 >> iter 43000, loss: 0.062202
 >> iter 44000, loss: 0.032489
 >> iter 45000, loss: 0.043231
 >> iter 46000, loss: 0.023574
 >> iter 47000, loss: 0.049614
 >> iter 48000, loss: 0.025896
 >> iter 49000, loss: 0.099215
 >> iter 50000, loss: 0.046544
   Number of active neurons: 4
 >> iter 51000, loss: 0.123731
 >> iter 52000, loss: 0.055821
 >> iter 53000, loss: 0.092946
 >> iter 54000, loss: 0.043070
 >> iter 55000, loss: 0.247466
 >> iter 56000, loss: 0.103598
 >> iter 57000, loss: 0.074455
 >> iter 58000, loss: 0.037487
 >> iter 59000, loss: 0.052454
 >> iter 60000, loss: 0.027594
   Number of active neurons: 4
 >> iter 61000, loss: 0.123685
 >> iter 62000, loss: 0.055178
 >> iter 63000, loss: 0.050932
 >> iter 64000, loss: 0.113171
 >> iter 65000, loss: 0.059694
 >> iter 66000, loss: 0.030306
 >> iter 67000, loss: 0.082207
 >> iter 68000, loss: 0.039281
 >> iter 69000, loss: 0.051655
 >> iter 70000, loss: 0.134509
   Number of active neurons: 4
 >> iter 71000, loss: 0.136904
 >> iter 72000, loss: 0.060461
 >> iter 73000, loss: 0.052642
 >> iter 74000, loss: 0.104896
 >> iter 75000, loss: 0.072971
 >> iter 76000, loss: 0.037149
 >> iter 77000, loss: 0.071930
 >> iter 78000, loss: 0.035373
 >> iter 79000, loss: 0.103786
 >> iter 80000, loss: 0.047604
   Number of active neurons: 4
 >> iter 81000, loss: 0.046892
 >> iter 82000, loss: 0.128221
 >> iter 83000, loss: 0.247386
 >> iter 84000, loss: 0.103007
 >> iter 85000, loss: 0.109692
 >> iter 86000, loss: 0.050499
 >> iter 87000, loss: 0.042739
 >> iter 88000, loss: 0.024090
 >> iter 89000, loss: 0.131812
 >> iter 90000, loss: 0.058490
   Number of active neurons: 3
 >> iter 91000, loss: 0.155696
 >> iter 92000, loss: 0.068469
 >> iter 93000, loss: 0.062751
 >> iter 94000, loss: 0.032817
 >> iter 95000, loss: 0.041908
 >> iter 96000, loss: 0.023328
 >> iter 97000, loss: 0.081881
 >> iter 98000, loss: 0.038418
 >> iter 99000, loss: 0.041900
 >> iter 100000, loss: 0.116360
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0039999200016
   - Test - Long: 0.0
   - Test - Big: 0.0079999200008
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.867471
 >> iter 2000, loss: 5.950508
 >> iter 3000, loss: 2.265649
 >> iter 4000, loss: 0.953154
 >> iter 5000, loss: 0.407247
 >> iter 6000, loss: 0.285315
 >> iter 7000, loss: 0.207354
 >> iter 8000, loss: 0.157190
 >> iter 9000, loss: 0.178328
 >> iter 10000, loss: 0.080851
   Number of active neurons: 7
 >> iter 11000, loss: 0.190184
 >> iter 12000, loss: 0.083372
 >> iter 13000, loss: 0.041349
 >> iter 14000, loss: 0.153765
 >> iter 15000, loss: 0.194644
 >> iter 16000, loss: 0.326191
 >> iter 17000, loss: 0.133647
 >> iter 18000, loss: 0.319685
 >> iter 19000, loss: 0.306418
 >> iter 20000, loss: 0.129562
   Number of active neurons: 6
 >> iter 21000, loss: 0.058686
 >> iter 22000, loss: 0.288792
 >> iter 23000, loss: 0.395657
 >> iter 24000, loss: 0.161618
 >> iter 25000, loss: 0.074964
 >> iter 26000, loss: 0.160803
 >> iter 27000, loss: 0.164749
 >> iter 28000, loss: 0.071610
 >> iter 29000, loss: 0.094263
 >> iter 30000, loss: 0.044420
   Number of active neurons: 4
 >> iter 31000, loss: 0.176009
 >> iter 32000, loss: 0.191267
 >> iter 33000, loss: 0.081134
 >> iter 34000, loss: 0.155185
 >> iter 35000, loss: 0.092929
 >> iter 36000, loss: 0.156147
 >> iter 37000, loss: 0.123799
 >> iter 38000, loss: 0.155887
 >> iter 39000, loss: 0.136198
 >> iter 40000, loss: 0.170703
   Number of active neurons: 4
 >> iter 41000, loss: 0.098831
 >> iter 42000, loss: 0.160565
 >> iter 43000, loss: 0.178646
 >> iter 44000, loss: 0.122873
 >> iter 45000, loss: 0.238432
 >> iter 46000, loss: 0.098177
 >> iter 47000, loss: 0.044999
 >> iter 48000, loss: 0.144876
 >> iter 49000, loss: 0.113686
 >> iter 50000, loss: 0.167522
   Number of active neurons: 4
 >> iter 51000, loss: 0.120748
 >> iter 52000, loss: 0.168537
 >> iter 53000, loss: 0.102175
 >> iter 54000, loss: 0.161961
 >> iter 55000, loss: 0.068434
 >> iter 56000, loss: 0.152506
 >> iter 57000, loss: 0.070470
 >> iter 58000, loss: 0.063502
 >> iter 59000, loss: 0.030756
 >> iter 60000, loss: 0.142664
   Number of active neurons: 4
 >> iter 61000, loss: 0.135365
 >> iter 62000, loss: 0.174613
 >> iter 63000, loss: 0.097312
 >> iter 64000, loss: 0.158514
 >> iter 65000, loss: 0.067477
 >> iter 66000, loss: 0.269985
 >> iter 67000, loss: 0.109514
 >> iter 68000, loss: 0.286630
 >> iter 69000, loss: 0.116276
 >> iter 70000, loss: 0.290154
   Number of active neurons: 4
 >> iter 71000, loss: 0.155255
 >> iter 72000, loss: 0.066891
 >> iter 73000, loss: 0.033434
 >> iter 74000, loss: 0.130798
 >> iter 75000, loss: 0.056510
 >> iter 76000, loss: 0.085461
 >> iter 77000, loss: 0.039710
 >> iter 78000, loss: 0.328049
 >> iter 79000, loss: 0.131628
 >> iter 80000, loss: 0.100421
   Number of active neurons: 4
 >> iter 81000, loss: 0.045977
 >> iter 82000, loss: 0.260494
 >> iter 83000, loss: 0.105803
 >> iter 84000, loss: 0.465318
 >> iter 85000, loss: 0.255057
 >> iter 86000, loss: 0.106277
 >> iter 87000, loss: 0.049390
 >> iter 88000, loss: 0.258840
 >> iter 89000, loss: 0.106012
 >> iter 90000, loss: 0.279024
   Number of active neurons: 4
 >> iter 91000, loss: 0.113298
 >> iter 92000, loss: 0.308143
 >> iter 93000, loss: 0.124500
 >> iter 94000, loss: 0.161812
 >> iter 95000, loss: 0.068688
 >> iter 96000, loss: 0.363033
 >> iter 97000, loss: 0.147001
 >> iter 98000, loss: 0.063200
 >> iter 99000, loss: 0.031475
 >> iter 100000, loss: 0.135753
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0019999600008
   - Test - Long: 0.0
   - Test - Big: 0.0079999200008
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 16.092562
 >> iter 2000, loss: 6.136243
 >> iter 3000, loss: 2.275008
 >> iter 4000, loss: 0.850219
 >> iter 5000, loss: 0.388596
 >> iter 6000, loss: 0.154309
 >> iter 7000, loss: 0.146280
 >> iter 8000, loss: 0.065236
 >> iter 9000, loss: 0.198275
 >> iter 10000, loss: 0.085393
   Number of active neurons: 6
 >> iter 11000, loss: 0.114185
 >> iter 12000, loss: 0.053217
 >> iter 13000, loss: 0.238393
 >> iter 14000, loss: 0.101066
 >> iter 15000, loss: 0.047888
 >> iter 16000, loss: 0.038108
 >> iter 17000, loss: 0.065516
 >> iter 18000, loss: 0.413651
 >> iter 19000, loss: 0.191974
 >> iter 20000, loss: 0.082126
   Number of active neurons: 5
 >> iter 21000, loss: 0.139891
 >> iter 22000, loss: 0.061892
 >> iter 23000, loss: 0.102660
 >> iter 24000, loss: 0.151985
 >> iter 25000, loss: 0.280414
 >> iter 26000, loss: 0.117956
 >> iter 27000, loss: 0.207822
 >> iter 28000, loss: 0.088222
 >> iter 29000, loss: 0.148343
 >> iter 30000, loss: 0.065316
   Number of active neurons: 5
 >> iter 31000, loss: 0.079438
 >> iter 32000, loss: 0.042623
 >> iter 33000, loss: 0.113632
 >> iter 34000, loss: 0.051808
 >> iter 35000, loss: 0.170292
 >> iter 36000, loss: 0.193109
 >> iter 37000, loss: 0.088166
 >> iter 38000, loss: 0.299022
 >> iter 39000, loss: 0.122419
 >> iter 40000, loss: 0.054993
   Number of active neurons: 5
 >> iter 41000, loss: 0.161601
 >> iter 42000, loss: 0.072276
 >> iter 43000, loss: 0.035950
 >> iter 44000, loss: 0.025156
 >> iter 45000, loss: 0.119425
 >> iter 46000, loss: 0.097829
 >> iter 47000, loss: 0.045358
 >> iter 48000, loss: 0.120888
 >> iter 49000, loss: 0.053901
 >> iter 50000, loss: 0.275535
   Number of active neurons: 5
 >> iter 51000, loss: 0.127025
 >> iter 52000, loss: 0.057098
 >> iter 53000, loss: 0.093373
 >> iter 54000, loss: 0.610456
 >> iter 55000, loss: 0.381583
 >> iter 56000, loss: 0.157853
 >> iter 57000, loss: 0.070133
 >> iter 58000, loss: 0.151571
 >> iter 59000, loss: 0.067387
 >> iter 60000, loss: 0.142298
   Number of active neurons: 5
 >> iter 61000, loss: 0.063380
 >> iter 62000, loss: 0.137109
 >> iter 63000, loss: 0.061296
 >> iter 64000, loss: 0.151086
 >> iter 65000, loss: 0.089952
 >> iter 66000, loss: 0.047394
 >> iter 67000, loss: 0.056218
 >> iter 68000, loss: 0.034828
 >> iter 69000, loss: 0.027481
 >> iter 70000, loss: 0.476426
   Number of active neurons: 6
 >> iter 71000, loss: 0.204369
 >> iter 72000, loss: 0.086461
 >> iter 73000, loss: 0.059328
 >> iter 74000, loss: 0.068318
 >> iter 75000, loss: 0.159480
 >> iter 76000, loss: 0.070531
 >> iter 77000, loss: 0.288918
 >> iter 78000, loss: 0.119417
 >> iter 79000, loss: 0.054499
 >> iter 80000, loss: 0.030076
   Number of active neurons: 3
 >> iter 81000, loss: 0.101621
 >> iter 82000, loss: 0.045820
 >> iter 83000, loss: 0.041614
 >> iter 84000, loss: 0.063290
 >> iter 85000, loss: 0.101459
 >> iter 86000, loss: 0.136074
 >> iter 87000, loss: 0.084265
 >> iter 88000, loss: 0.039441
 >> iter 89000, loss: 0.042115
 >> iter 90000, loss: 0.024117
   Number of active neurons: 3
 >> iter 91000, loss: 0.034924
 >> iter 92000, loss: 0.118767
 >> iter 93000, loss: 0.053133
 >> iter 94000, loss: 0.130459
 >> iter 95000, loss: 0.055860
 >> iter 96000, loss: 0.140373
 >> iter 97000, loss: 0.112102
 >> iter 98000, loss: 0.049649
 >> iter 99000, loss: 0.149616
 >> iter 100000, loss: 0.064526
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0069999300007
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.072900
 >> iter 2000, loss: 6.108039
 >> iter 3000, loss: 2.284236
 >> iter 4000, loss: 0.855057
 >> iter 5000, loss: 0.452367
 >> iter 6000, loss: 0.180611
 >> iter 7000, loss: 0.207976
 >> iter 8000, loss: 0.089325
 >> iter 9000, loss: 0.183641
 >> iter 10000, loss: 0.119011
   Number of active neurons: 4
 >> iter 11000, loss: 0.114151
 >> iter 12000, loss: 0.053314
 >> iter 13000, loss: 0.052086
 >> iter 14000, loss: 0.219406
 >> iter 15000, loss: 0.115962
 >> iter 16000, loss: 0.052900
 >> iter 17000, loss: 0.114215
 >> iter 18000, loss: 0.051616
 >> iter 19000, loss: 0.158117
 >> iter 20000, loss: 0.067807
   Number of active neurons: 4
 >> iter 21000, loss: 0.108589
 >> iter 22000, loss: 0.048309
 >> iter 23000, loss: 0.025645
 >> iter 24000, loss: 0.018189
 >> iter 25000, loss: 0.279688
 >> iter 26000, loss: 0.115315
 >> iter 27000, loss: 0.124494
 >> iter 28000, loss: 0.056201
 >> iter 29000, loss: 0.456003
 >> iter 30000, loss: 0.185117
   Number of active neurons: 4
 >> iter 31000, loss: 0.080142
 >> iter 32000, loss: 0.039437
 >> iter 33000, loss: 0.023474
 >> iter 34000, loss: 0.018182
 >> iter 35000, loss: 0.040558
 >> iter 36000, loss: 0.023445
 >> iter 37000, loss: 0.462241
 >> iter 38000, loss: 0.189592
 >> iter 39000, loss: 0.081993
 >> iter 40000, loss: 0.040895
   Number of active neurons: 4
 >> iter 41000, loss: 0.059459
 >> iter 42000, loss: 0.052792
 >> iter 43000, loss: 0.238576
 >> iter 44000, loss: 0.100281
 >> iter 45000, loss: 0.047039
 >> iter 46000, loss: 0.028256
 >> iter 47000, loss: 0.209402
 >> iter 48000, loss: 0.107868
 >> iter 49000, loss: 0.158973
 >> iter 50000, loss: 0.071246
   Number of active neurons: 4
 >> iter 51000, loss: 0.099222
 >> iter 52000, loss: 0.046758
 >> iter 53000, loss: 0.045037
 >> iter 54000, loss: 0.025891
 >> iter 55000, loss: 0.120181
 >> iter 56000, loss: 0.107688
 >> iter 57000, loss: 0.100892
 >> iter 58000, loss: 0.046931
 >> iter 59000, loss: 0.115187
 >> iter 60000, loss: 0.064465
   Number of active neurons: 4
 >> iter 61000, loss: 0.032537
 >> iter 62000, loss: 0.021176
 >> iter 63000, loss: 0.507769
 >> iter 64000, loss: 0.203743
 >> iter 65000, loss: 0.086854
 >> iter 66000, loss: 0.042226
 >> iter 67000, loss: 0.027568
 >> iter 68000, loss: 0.018577
 >> iter 69000, loss: 0.678673
 >> iter 70000, loss: 0.268671
   Number of active neurons: 3
 >> iter 71000, loss: 0.111341
 >> iter 72000, loss: 0.050926
 >> iter 73000, loss: 0.040125
 >> iter 74000, loss: 0.022856
 >> iter 75000, loss: 0.087539
 >> iter 76000, loss: 0.040962
 >> iter 77000, loss: 0.025877
 >> iter 78000, loss: 0.017062
 >> iter 79000, loss: 0.063462
 >> iter 80000, loss: 0.031197
   Number of active neurons: 3
 >> iter 81000, loss: 0.675089
 >> iter 82000, loss: 0.273177
 >> iter 83000, loss: 0.113127
 >> iter 84000, loss: 0.052200
 >> iter 85000, loss: 0.078694
 >> iter 86000, loss: 0.037833
 >> iter 87000, loss: 0.035992
 >> iter 88000, loss: 0.021013
 >> iter 89000, loss: 0.089931
 >> iter 90000, loss: 0.041685
   Number of active neurons: 3
 >> iter 91000, loss: 0.094246
 >> iter 92000, loss: 0.043514
 >> iter 93000, loss: 0.119512
 >> iter 94000, loss: 0.053536
 >> iter 95000, loss: 0.284769
 >> iter 96000, loss: 0.117065
 >> iter 97000, loss: 0.063691
 >> iter 98000, loss: 0.032348
 >> iter 99000, loss: 0.094139
 >> iter 100000, loss: 0.043733
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.083674
 >> iter 2000, loss: 6.427824
 >> iter 3000, loss: 2.468755
 >> iter 4000, loss: 0.925391
 >> iter 5000, loss: 0.353027
 >> iter 6000, loss: 0.209597
 >> iter 7000, loss: 0.161420
 >> iter 8000, loss: 0.070701
 >> iter 9000, loss: 0.196335
 >> iter 10000, loss: 0.085841
   Number of active neurons: 4
 >> iter 11000, loss: 0.041659
 >> iter 12000, loss: 0.150718
 >> iter 13000, loss: 0.222522
 >> iter 14000, loss: 0.093685
 >> iter 15000, loss: 0.043989
 >> iter 16000, loss: 0.105028
 >> iter 17000, loss: 0.078268
 >> iter 18000, loss: 0.228800
 >> iter 19000, loss: 0.300164
 >> iter 20000, loss: 0.242481
   Number of active neurons: 4
 >> iter 21000, loss: 0.213262
 >> iter 22000, loss: 0.090455
 >> iter 23000, loss: 0.194713
 >> iter 24000, loss: 0.190992
 >> iter 25000, loss: 0.162863
 >> iter 26000, loss: 0.073575
 >> iter 27000, loss: 0.091260
 >> iter 28000, loss: 0.158787
 >> iter 29000, loss: 0.097883
 >> iter 30000, loss: 0.154757
   Number of active neurons: 4
 >> iter 31000, loss: 0.065614
 >> iter 32000, loss: 0.040839
 >> iter 33000, loss: 0.021892
 >> iter 34000, loss: 0.135194
 >> iter 35000, loss: 0.056874
 >> iter 36000, loss: 0.032772
 >> iter 37000, loss: 0.018369
 >> iter 38000, loss: 0.014211
 >> iter 39000, loss: 0.136141
 >> iter 40000, loss: 0.142618
   Number of active neurons: 4
 >> iter 41000, loss: 0.078829
 >> iter 42000, loss: 0.111069
 >> iter 43000, loss: 0.128436
 >> iter 44000, loss: 0.124212
 >> iter 45000, loss: 0.055360
 >> iter 46000, loss: 0.147897
 >> iter 47000, loss: 0.062737
 >> iter 48000, loss: 0.154808
 >> iter 49000, loss: 0.191856
 >> iter 50000, loss: 0.206537
   Number of active neurons: 4
 >> iter 51000, loss: 0.085872
 >> iter 52000, loss: 0.165150
 >> iter 53000, loss: 0.069752
 >> iter 54000, loss: 0.160637
 >> iter 55000, loss: 0.067311
 >> iter 56000, loss: 0.104995
 >> iter 57000, loss: 0.046871
 >> iter 58000, loss: 0.079129
 >> iter 59000, loss: 0.038736
 >> iter 60000, loss: 0.023305
   Number of active neurons: 4
 >> iter 61000, loss: 0.317127
 >> iter 62000, loss: 0.230133
 >> iter 63000, loss: 0.096182
 >> iter 64000, loss: 0.157611
 >> iter 65000, loss: 0.091347
 >> iter 66000, loss: 0.135809
 >> iter 67000, loss: 0.058835
 >> iter 68000, loss: 0.034212
 >> iter 69000, loss: 0.045952
 >> iter 70000, loss: 0.025921
   Number of active neurons: 4
 >> iter 71000, loss: 0.016024
 >> iter 72000, loss: 0.059643
 >> iter 73000, loss: 0.028685
 >> iter 74000, loss: 0.019035
 >> iter 75000, loss: 0.156281
 >> iter 76000, loss: 0.176221
 >> iter 77000, loss: 0.076076
 >> iter 78000, loss: 0.180884
 >> iter 79000, loss: 0.076225
 >> iter 80000, loss: 0.154256
   Number of active neurons: 4
 >> iter 81000, loss: 0.066630
 >> iter 82000, loss: 0.150566
 >> iter 83000, loss: 0.089586
 >> iter 84000, loss: 0.157755
 >> iter 85000, loss: 0.134884
 >> iter 86000, loss: 0.061703
 >> iter 87000, loss: 0.139153
 >> iter 88000, loss: 0.063444
 >> iter 89000, loss: 0.031847
 >> iter 90000, loss: 0.022034
   Number of active neurons: 4
 >> iter 91000, loss: 0.014781
 >> iter 92000, loss: 0.013605
 >> iter 93000, loss: 0.012417
 >> iter 94000, loss: 0.138168
 >> iter 95000, loss: 0.057298
 >> iter 96000, loss: 0.112954
 >> iter 97000, loss: 0.074921
 >> iter 98000, loss: 0.034473
 >> iter 99000, loss: 0.108363
 >> iter 100000, loss: 0.050513
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.00599988000241
   - Test - Long: 0.0049997500125
   - Test - Big: 0.0089999100009
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 15.447918
 >> iter 2000, loss: 6.139208
 >> iter 3000, loss: 2.282460
 >> iter 4000, loss: 0.859970
 >> iter 5000, loss: 0.347717
 >> iter 6000, loss: 0.140300
 >> iter 7000, loss: 0.097144
 >> iter 8000, loss: 0.215143
 >> iter 9000, loss: 0.092127
 >> iter 10000, loss: 0.106659
   Number of active neurons: 6
 >> iter 11000, loss: 0.075780
 >> iter 12000, loss: 0.038415
 >> iter 13000, loss: 0.047748
 >> iter 14000, loss: 0.027910
 >> iter 15000, loss: 0.034979
 >> iter 16000, loss: 0.251697
 >> iter 17000, loss: 0.104703
 >> iter 18000, loss: 0.049264
 >> iter 19000, loss: 0.173411
 >> iter 20000, loss: 0.077252
   Number of active neurons: 5
 >> iter 21000, loss: 0.076813
 >> iter 22000, loss: 0.039324
 >> iter 23000, loss: 0.071956
 >> iter 24000, loss: 0.036834
 >> iter 25000, loss: 0.288120
 >> iter 26000, loss: 0.242589
 >> iter 27000, loss: 0.121894
 >> iter 28000, loss: 0.055916
 >> iter 29000, loss: 0.092581
 >> iter 30000, loss: 0.044222
   Number of active neurons: 3
 >> iter 31000, loss: 0.097858
 >> iter 32000, loss: 0.046021
 >> iter 33000, loss: 0.254186
 >> iter 34000, loss: 0.108650
 >> iter 35000, loss: 0.051143
 >> iter 36000, loss: 0.029302
 >> iter 37000, loss: 0.070847
 >> iter 38000, loss: 0.035042
 >> iter 39000, loss: 0.327568
 >> iter 40000, loss: 0.136457
   Number of active neurons: 3
 >> iter 41000, loss: 0.174428
 >> iter 42000, loss: 0.075136
 >> iter 43000, loss: 0.395734
 >> iter 44000, loss: 0.163585
 >> iter 45000, loss: 0.072376
 >> iter 46000, loss: 0.036934
 >> iter 47000, loss: 0.040696
 >> iter 48000, loss: 0.022941
 >> iter 49000, loss: 0.074251
 >> iter 50000, loss: 0.035782
   Number of active neurons: 3
 >> iter 51000, loss: 0.068249
 >> iter 52000, loss: 0.033383
 >> iter 53000, loss: 0.291131
 >> iter 54000, loss: 0.123200
 >> iter 55000, loss: 0.229161
 >> iter 56000, loss: 0.096420
 >> iter 57000, loss: 0.045222
 >> iter 58000, loss: 0.025130
 >> iter 59000, loss: 0.277766
 >> iter 60000, loss: 0.116393
   Number of active neurons: 3
 >> iter 61000, loss: 0.097563
 >> iter 62000, loss: 0.046014
 >> iter 63000, loss: 0.101133
 >> iter 64000, loss: 0.047397
 >> iter 65000, loss: 0.174167
 >> iter 66000, loss: 0.075552
 >> iter 67000, loss: 0.117688
 >> iter 68000, loss: 0.053291
 >> iter 69000, loss: 0.201111
 >> iter 70000, loss: 0.084050
   Number of active neurons: 3
 >> iter 71000, loss: 0.074886
 >> iter 72000, loss: 0.036226
 >> iter 73000, loss: 0.260790
 >> iter 74000, loss: 0.110707
 >> iter 75000, loss: 0.116144
 >> iter 76000, loss: 0.053183
 >> iter 77000, loss: 0.045197
 >> iter 78000, loss: 0.029725
 >> iter 79000, loss: 0.173082
 >> iter 80000, loss: 0.083448
   Number of active neurons: 3
 >> iter 81000, loss: 0.043367
 >> iter 82000, loss: 0.025298
 >> iter 83000, loss: 0.149004
 >> iter 84000, loss: 0.066623
 >> iter 85000, loss: 0.098614
 >> iter 86000, loss: 0.046558
 >> iter 87000, loss: 0.058321
 >> iter 88000, loss: 0.029840
 >> iter 89000, loss: 0.218974
 >> iter 90000, loss: 0.092977
   Number of active neurons: 3
 >> iter 91000, loss: 0.065688
 >> iter 92000, loss: 0.072358
 >> iter 93000, loss: 0.097957
 >> iter 94000, loss: 0.045392
 >> iter 95000, loss: 0.283242
 >> iter 96000, loss: 0.117942
 >> iter 97000, loss: 0.053972
 >> iter 98000, loss: 0.053151
 >> iter 99000, loss: 0.035191
 >> iter 100000, loss: 0.052828
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.957861
 >> iter 2000, loss: 6.177262
 >> iter 3000, loss: 2.290764
 >> iter 4000, loss: 0.855141
 >> iter 5000, loss: 0.382117
 >> iter 6000, loss: 0.151032
 >> iter 7000, loss: 0.177208
 >> iter 8000, loss: 0.164474
 >> iter 9000, loss: 0.215299
 >> iter 10000, loss: 0.092268
   Number of active neurons: 5
 >> iter 11000, loss: 0.180856
 >> iter 12000, loss: 0.078266
 >> iter 13000, loss: 0.047484
 >> iter 14000, loss: 0.026272
 >> iter 15000, loss: 0.188148
 >> iter 16000, loss: 0.080375
 >> iter 17000, loss: 0.180975
 >> iter 18000, loss: 0.077868
 >> iter 19000, loss: 0.037921
 >> iter 20000, loss: 0.088487
   Number of active neurons: 5
 >> iter 21000, loss: 0.284808
 >> iter 22000, loss: 0.117259
 >> iter 23000, loss: 0.052769
 >> iter 24000, loss: 0.250005
 >> iter 25000, loss: 0.138152
 >> iter 26000, loss: 0.062508
 >> iter 27000, loss: 0.145012
 >> iter 28000, loss: 0.165857
 >> iter 29000, loss: 0.106329
 >> iter 30000, loss: 0.131173
   Number of active neurons: 5
 >> iter 31000, loss: 0.058422
 >> iter 32000, loss: 0.030918
 >> iter 33000, loss: 0.133431
 >> iter 34000, loss: 0.059073
 >> iter 35000, loss: 0.036932
 >> iter 36000, loss: 0.023546
 >> iter 37000, loss: 0.128185
 >> iter 38000, loss: 0.057069
 >> iter 39000, loss: 0.124698
 >> iter 40000, loss: 0.103230
   Number of active neurons: 5
 >> iter 41000, loss: 0.093439
 >> iter 42000, loss: 0.223279
 >> iter 43000, loss: 0.184419
 >> iter 44000, loss: 0.244912
 >> iter 45000, loss: 0.161765
 >> iter 46000, loss: 0.286928
 >> iter 47000, loss: 0.153507
 >> iter 48000, loss: 0.068556
 >> iter 49000, loss: 0.044010
 >> iter 50000, loss: 0.025695
   Number of active neurons: 5
 >> iter 51000, loss: 0.104615
 >> iter 52000, loss: 0.046986
 >> iter 53000, loss: 0.160538
 >> iter 54000, loss: 0.067556
 >> iter 55000, loss: 0.246241
 >> iter 56000, loss: 0.102844
 >> iter 57000, loss: 0.137451
 >> iter 58000, loss: 0.060988
 >> iter 59000, loss: 0.184724
 >> iter 60000, loss: 0.079591
   Number of active neurons: 5
 >> iter 61000, loss: 0.098493
 >> iter 62000, loss: 0.045945
 >> iter 63000, loss: 0.239146
 >> iter 64000, loss: 0.217040
 >> iter 65000, loss: 0.311463
 >> iter 66000, loss: 0.130008
 >> iter 67000, loss: 0.097136
 >> iter 68000, loss: 0.046222
 >> iter 69000, loss: 0.048941
 >> iter 70000, loss: 0.144723
   Number of active neurons: 5
 >> iter 71000, loss: 0.085379
 >> iter 72000, loss: 0.041412
 >> iter 73000, loss: 0.189583
 >> iter 74000, loss: 0.081535
 >> iter 75000, loss: 0.091104
 >> iter 76000, loss: 0.045675
 >> iter 77000, loss: 0.072811
 >> iter 78000, loss: 0.035510
 >> iter 79000, loss: 0.164240
 >> iter 80000, loss: 0.072139
   Number of active neurons: 4
 >> iter 81000, loss: 0.077376
 >> iter 82000, loss: 0.038210
 >> iter 83000, loss: 0.068939
 >> iter 84000, loss: 0.151799
 >> iter 85000, loss: 0.307641
 >> iter 86000, loss: 0.134455
 >> iter 87000, loss: 0.165861
 >> iter 88000, loss: 0.083454
 >> iter 89000, loss: 0.269290
 >> iter 90000, loss: 0.113974
   Number of active neurons: 4
 >> iter 91000, loss: 0.070800
 >> iter 92000, loss: 0.035817
 >> iter 93000, loss: 0.139213
 >> iter 94000, loss: 0.062363
 >> iter 95000, loss: 0.287566
 >> iter 96000, loss: 0.121088
 >> iter 97000, loss: 0.074062
 >> iter 98000, loss: 0.037104
 >> iter 99000, loss: 0.265517
 >> iter 100000, loss: 0.111500
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 15.619918
 >> iter 2000, loss: 6.036980
 >> iter 3000, loss: 2.242732
 >> iter 4000, loss: 0.839123
 >> iter 5000, loss: 0.503375
 >> iter 6000, loss: 0.200639
 >> iter 7000, loss: 0.142729
 >> iter 8000, loss: 0.402915
 >> iter 9000, loss: 0.166234
 >> iter 10000, loss: 0.193198
   Number of active neurons: 5
 >> iter 11000, loss: 0.083429
 >> iter 12000, loss: 0.207587
 >> iter 13000, loss: 0.088168
 >> iter 14000, loss: 0.043531
 >> iter 15000, loss: 0.242739
 >> iter 16000, loss: 0.102503
 >> iter 17000, loss: 0.072847
 >> iter 18000, loss: 0.037708
 >> iter 19000, loss: 0.084875
 >> iter 20000, loss: 0.040533
   Number of active neurons: 5
 >> iter 21000, loss: 0.118607
 >> iter 22000, loss: 0.053684
 >> iter 23000, loss: 0.198495
 >> iter 24000, loss: 0.084975
 >> iter 25000, loss: 0.041261
 >> iter 26000, loss: 0.246717
 >> iter 27000, loss: 0.144208
 >> iter 28000, loss: 0.065145
 >> iter 29000, loss: 0.033356
 >> iter 30000, loss: 0.025451
   Number of active neurons: 5
 >> iter 31000, loss: 0.017968
 >> iter 32000, loss: 0.368409
 >> iter 33000, loss: 0.149480
 >> iter 34000, loss: 0.066489
 >> iter 35000, loss: 0.033789
 >> iter 36000, loss: 0.114955
 >> iter 37000, loss: 0.100737
 >> iter 38000, loss: 0.048431
 >> iter 39000, loss: 0.056908
 >> iter 40000, loss: 0.032096
   Number of active neurons: 5
 >> iter 41000, loss: 0.086246
 >> iter 42000, loss: 0.041120
 >> iter 43000, loss: 0.083921
 >> iter 44000, loss: 0.167970
 >> iter 45000, loss: 0.204184
 >> iter 46000, loss: 0.088906
 >> iter 47000, loss: 0.402958
 >> iter 48000, loss: 0.166594
 >> iter 49000, loss: 0.073821
 >> iter 50000, loss: 0.038398
   Number of active neurons: 4
 >> iter 51000, loss: 0.023722
 >> iter 52000, loss: 0.220988
 >> iter 53000, loss: 0.148564
 >> iter 54000, loss: 0.074607
 >> iter 55000, loss: 0.062407
 >> iter 56000, loss: 0.146391
 >> iter 57000, loss: 0.119023
 >> iter 58000, loss: 0.082237
 >> iter 59000, loss: 0.039313
 >> iter 60000, loss: 0.138695
   Number of active neurons: 3
 >> iter 61000, loss: 0.212741
 >> iter 62000, loss: 0.265967
 >> iter 63000, loss: 0.111755
 >> iter 64000, loss: 0.052620
 >> iter 65000, loss: 0.218544
 >> iter 66000, loss: 0.093555
 >> iter 67000, loss: 0.237367
 >> iter 68000, loss: 0.184013
 >> iter 69000, loss: 0.079749
 >> iter 70000, loss: 0.039838
   Number of active neurons: 4
 >> iter 71000, loss: 0.212562
 >> iter 72000, loss: 0.090410
 >> iter 73000, loss: 0.044496
 >> iter 74000, loss: 0.025056
 >> iter 75000, loss: 0.113614
 >> iter 76000, loss: 0.051414
 >> iter 77000, loss: 0.030679
 >> iter 78000, loss: 0.019694
 >> iter 79000, loss: 0.020424
 >> iter 80000, loss: 0.015472
   Number of active neurons: 4
 >> iter 81000, loss: 0.178999
 >> iter 82000, loss: 0.075926
 >> iter 83000, loss: 0.036804
 >> iter 84000, loss: 0.022481
 >> iter 85000, loss: 0.096973
 >> iter 86000, loss: 0.044466
 >> iter 87000, loss: 0.037037
 >> iter 88000, loss: 0.138171
 >> iter 89000, loss: 0.154217
 >> iter 90000, loss: 0.093370
   Number of active neurons: 3
 >> iter 91000, loss: 0.043467
 >> iter 92000, loss: 0.024957
 >> iter 93000, loss: 0.244957
 >> iter 94000, loss: 0.101925
 >> iter 95000, loss: 0.061990
 >> iter 96000, loss: 0.031149
 >> iter 97000, loss: 0.039766
 >> iter 98000, loss: 0.122194
 >> iter 99000, loss: 0.375113
 >> iter 100000, loss: 0.153108
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 16.999161
 >> iter 2000, loss: 7.299848
 >> iter 3000, loss: 2.727105
 >> iter 4000, loss: 1.020529
 >> iter 5000, loss: 0.392735
 >> iter 6000, loss: 0.156250
 >> iter 7000, loss: 0.190039
 >> iter 8000, loss: 0.081621
 >> iter 9000, loss: 0.044947
 >> iter 10000, loss: 0.025849
   Number of active neurons: 5
 >> iter 11000, loss: 0.056096
 >> iter 12000, loss: 0.029640
 >> iter 13000, loss: 0.027081
 >> iter 14000, loss: 0.114934
 >> iter 15000, loss: 0.051649
 >> iter 16000, loss: 0.179194
 >> iter 17000, loss: 0.076292
 >> iter 18000, loss: 0.037183
 >> iter 19000, loss: 0.083285
 >> iter 20000, loss: 0.039917
   Number of active neurons: 5
 >> iter 21000, loss: 0.085060
 >> iter 22000, loss: 0.040473
 >> iter 23000, loss: 0.085678
 >> iter 24000, loss: 0.040786
 >> iter 25000, loss: 0.093700
 >> iter 26000, loss: 0.044411
 >> iter 27000, loss: 0.199883
 >> iter 28000, loss: 0.084803
 >> iter 29000, loss: 0.303526
 >> iter 30000, loss: 0.124633
   Number of active neurons: 5
 >> iter 31000, loss: 0.056885
 >> iter 32000, loss: 0.030312
 >> iter 33000, loss: 0.036661
 >> iter 34000, loss: 0.036693
 >> iter 35000, loss: 0.021607
 >> iter 36000, loss: 0.024980
 >> iter 37000, loss: 0.016456
 >> iter 38000, loss: 0.026352
 >> iter 39000, loss: 0.016474
 >> iter 40000, loss: 0.030167
   Number of active neurons: 5
 >> iter 41000, loss: 0.024035
 >> iter 42000, loss: 0.036904
 >> iter 43000, loss: 0.115349
 >> iter 44000, loss: 0.098771
 >> iter 45000, loss: 0.249818
 >> iter 46000, loss: 0.104699
 >> iter 47000, loss: 0.119077
 >> iter 48000, loss: 0.123359
 >> iter 49000, loss: 0.119623
 >> iter 50000, loss: 0.117708
   Number of active neurons: 5
 >> iter 51000, loss: 0.132863
 >> iter 52000, loss: 0.141170
 >> iter 53000, loss: 0.061696
 >> iter 54000, loss: 0.156932
 >> iter 55000, loss: 0.068511
 >> iter 56000, loss: 0.271954
 >> iter 57000, loss: 0.112504
 >> iter 58000, loss: 0.112579
 >> iter 59000, loss: 0.051635
 >> iter 60000, loss: 0.144972
   Number of active neurons: 5
 >> iter 61000, loss: 0.062337
 >> iter 62000, loss: 0.148864
 >> iter 63000, loss: 0.163555
 >> iter 64000, loss: 0.068911
 >> iter 65000, loss: 0.129029
 >> iter 66000, loss: 0.056710
 >> iter 67000, loss: 0.029275
 >> iter 68000, loss: 0.018299
 >> iter 69000, loss: 0.014106
 >> iter 70000, loss: 0.019693
   Number of active neurons: 3
 >> iter 71000, loss: 0.034230
 >> iter 72000, loss: 0.115568
 >> iter 73000, loss: 0.134490
 >> iter 74000, loss: 0.124175
 >> iter 75000, loss: 0.053273
 >> iter 76000, loss: 0.134784
 >> iter 77000, loss: 0.056867
 >> iter 78000, loss: 0.137829
 >> iter 79000, loss: 0.452806
 >> iter 80000, loss: 0.178402
   Number of active neurons: 3
 >> iter 81000, loss: 0.075189
 >> iter 82000, loss: 0.039113
 >> iter 83000, loss: 0.022343
 >> iter 84000, loss: 0.121484
 >> iter 85000, loss: 0.052069
 >> iter 86000, loss: 0.127180
 >> iter 87000, loss: 0.177434
 >> iter 88000, loss: 0.172950
 >> iter 89000, loss: 0.071580
 >> iter 90000, loss: 0.136898
   Number of active neurons: 3
 >> iter 91000, loss: 0.232710
 >> iter 92000, loss: 0.095919
 >> iter 93000, loss: 0.042958
 >> iter 94000, loss: 0.122438
 >> iter 95000, loss: 0.117556
 >> iter 96000, loss: 0.154975
 >> iter 97000, loss: 0.087863
 >> iter 98000, loss: 0.137732
 >> iter 99000, loss: 0.081256
 >> iter 100000, loss: 0.123566
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

