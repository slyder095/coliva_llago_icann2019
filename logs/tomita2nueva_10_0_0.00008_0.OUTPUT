 > Problema: tomita2nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 8e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.876308
 >> iter 2000, loss: 4.027209
 >> iter 3000, loss: 1.500154
 >> iter 4000, loss: 0.567705
 >> iter 5000, loss: 0.224146
 >> iter 6000, loss: 0.096764
 >> iter 7000, loss: 0.050097
 >> iter 8000, loss: 0.032247
 >> iter 9000, loss: 0.026007
 >> iter 10000, loss: 0.023314
   Number of active neurons: 7
 >> iter 11000, loss: 0.022730
 >> iter 12000, loss: 0.022094
 >> iter 13000, loss: 0.022218
 >> iter 14000, loss: 0.021764
 >> iter 15000, loss: 0.021856
 >> iter 16000, loss: 0.021283
 >> iter 17000, loss: 0.021341
 >> iter 18000, loss: 0.020732
 >> iter 19000, loss: 0.020681
 >> iter 20000, loss: 0.020018
   Number of active neurons: 5
 >> iter 21000, loss: 0.019977
 >> iter 22000, loss: 0.019409
 >> iter 23000, loss: 0.019399
 >> iter 24000, loss: 0.018784
 >> iter 25000, loss: 0.018758
 >> iter 26000, loss: 0.018222
 >> iter 27000, loss: 0.018250
 >> iter 28000, loss: 0.017755
 >> iter 29000, loss: 0.017781
 >> iter 30000, loss: 0.017291
   Number of active neurons: 5
 >> iter 31000, loss: 0.017311
 >> iter 32000, loss: 0.016845
 >> iter 33000, loss: 0.016895
 >> iter 34000, loss: 0.016543
 >> iter 35000, loss: 0.016648
 >> iter 36000, loss: 0.016374
 >> iter 37000, loss: 0.016520
 >> iter 38000, loss: 0.016287
 >> iter 39000, loss: 0.016439
 >> iter 40000, loss: 0.016253
   Number of active neurons: 5
 >> iter 41000, loss: 0.016393
 >> iter 42000, loss: 0.016207
 >> iter 43000, loss: 0.016339
 >> iter 44000, loss: 0.016147
 >> iter 45000, loss: 0.016242
 >> iter 46000, loss: 0.015966
 >> iter 47000, loss: 0.015992
 >> iter 48000, loss: 0.015723
 >> iter 49000, loss: 0.015779
 >> iter 50000, loss: 0.015524
   Number of active neurons: 4
 >> iter 51000, loss: 0.015572
 >> iter 52000, loss: 0.015295
 >> iter 53000, loss: 0.015249
 >> iter 54000, loss: 0.014970
 >> iter 55000, loss: 0.014910
 >> iter 56000, loss: 0.014627
 >> iter 57000, loss: 0.014530
 >> iter 58000, loss: 0.014218
 >> iter 59000, loss: 0.014087
 >> iter 60000, loss: 0.013798
   Number of active neurons: 4
 >> iter 61000, loss: 0.013737
 >> iter 62000, loss: 0.013498
 >> iter 63000, loss: 0.013479
 >> iter 64000, loss: 0.013297
 >> iter 65000, loss: 0.013302
 >> iter 66000, loss: 0.013152
 >> iter 67000, loss: 0.013174
 >> iter 68000, loss: 0.013048
 >> iter 69000, loss: 0.013066
 >> iter 70000, loss: 0.012958
   Number of active neurons: 4
 >> iter 71000, loss: 0.012978
 >> iter 72000, loss: 0.012879
 >> iter 73000, loss: 0.012919
 >> iter 74000, loss: 0.012821
 >> iter 75000, loss: 0.012857
 >> iter 76000, loss: 0.012768
 >> iter 77000, loss: 0.012804
 >> iter 78000, loss: 0.012716
 >> iter 79000, loss: 0.012757
 >> iter 80000, loss: 0.012667
   Number of active neurons: 4
 >> iter 81000, loss: 0.012715
 >> iter 82000, loss: 0.012628
 >> iter 83000, loss: 0.012678
 >> iter 84000, loss: 0.012599
 >> iter 85000, loss: 0.012640
 >> iter 86000, loss: 0.012566
 >> iter 87000, loss: 0.012607
 >> iter 88000, loss: 0.012549
 >> iter 89000, loss: 0.012584
 >> iter 90000, loss: 0.012523
   Number of active neurons: 4
 >> iter 91000, loss: 0.012556
 >> iter 92000, loss: 0.012507
 >> iter 93000, loss: 0.012541
 >> iter 94000, loss: 0.012488
 >> iter 95000, loss: 0.012528
 >> iter 96000, loss: 0.012472
 >> iter 97000, loss: 0.012512
 >> iter 98000, loss: 0.012455
 >> iter 99000, loss: 0.012499
 >> iter 100000, loss: 0.012448
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.902824
 >> iter 2000, loss: 4.035617
 >> iter 3000, loss: 1.503203
 >> iter 4000, loss: 0.569534
 >> iter 5000, loss: 0.225463
 >> iter 6000, loss: 0.097851
 >> iter 7000, loss: 0.050904
 >> iter 8000, loss: 0.032903
 >> iter 9000, loss: 0.026418
 >> iter 10000, loss: 0.023308
   Number of active neurons: 6
 >> iter 11000, loss: 0.022345
 >> iter 12000, loss: 0.021377
 >> iter 13000, loss: 0.021250
 >> iter 14000, loss: 0.020581
 >> iter 15000, loss: 0.020684
 >> iter 16000, loss: 0.019983
 >> iter 17000, loss: 0.020181
 >> iter 18000, loss: 0.019741
 >> iter 19000, loss: 0.020033
 >> iter 20000, loss: 0.019633
   Number of active neurons: 5
 >> iter 21000, loss: 0.019905
 >> iter 22000, loss: 0.019446
 >> iter 23000, loss: 0.019604
 >> iter 24000, loss: 0.019080
 >> iter 25000, loss: 0.019236
 >> iter 26000, loss: 0.018751
 >> iter 27000, loss: 0.018931
 >> iter 28000, loss: 0.018444
 >> iter 29000, loss: 0.018606
 >> iter 30000, loss: 0.018149
   Number of active neurons: 5
 >> iter 31000, loss: 0.018357
 >> iter 32000, loss: 0.017953
 >> iter 33000, loss: 0.018117
 >> iter 34000, loss: 0.017744
 >> iter 35000, loss: 0.017860
 >> iter 36000, loss: 0.017542
 >> iter 37000, loss: 0.017656
 >> iter 38000, loss: 0.017310
 >> iter 39000, loss: 0.017320
 >> iter 40000, loss: 0.016995
   Number of active neurons: 4
 >> iter 41000, loss: 0.016958
 >> iter 42000, loss: 0.016634
 >> iter 43000, loss: 0.016625
 >> iter 44000, loss: 0.016348
 >> iter 45000, loss: 0.016327
 >> iter 46000, loss: 0.016032
 >> iter 47000, loss: 0.015989
 >> iter 48000, loss: 0.015697
 >> iter 49000, loss: 0.015703
 >> iter 50000, loss: 0.015459
   Number of active neurons: 4
 >> iter 51000, loss: 0.015490
 >> iter 52000, loss: 0.015307
 >> iter 53000, loss: 0.015352
 >> iter 54000, loss: 0.015226
 >> iter 55000, loss: 0.015289
 >> iter 56000, loss: 0.015174
 >> iter 57000, loss: 0.015241
 >> iter 58000, loss: 0.015141
 >> iter 59000, loss: 0.015213
 >> iter 60000, loss: 0.015119
   Number of active neurons: 4
 >> iter 61000, loss: 0.015208
 >> iter 62000, loss: 0.015099
 >> iter 63000, loss: 0.015179
 >> iter 64000, loss: 0.015086
 >> iter 65000, loss: 0.015158
 >> iter 66000, loss: 0.015074
 >> iter 67000, loss: 0.015142
 >> iter 68000, loss: 0.015071
 >> iter 69000, loss: 0.015120
 >> iter 70000, loss: 0.015058
   Number of active neurons: 4
 >> iter 71000, loss: 0.015100
 >> iter 72000, loss: 0.015042
 >> iter 73000, loss: 0.015101
 >> iter 74000, loss: 0.015037
 >> iter 75000, loss: 0.015089
 >> iter 76000, loss: 0.015031
 >> iter 77000, loss: 0.015078
 >> iter 78000, loss: 0.015019
 >> iter 79000, loss: 0.015070
 >> iter 80000, loss: 0.015004
   Number of active neurons: 4
 >> iter 81000, loss: 0.015060
 >> iter 82000, loss: 0.014995
 >> iter 83000, loss: 0.015057
 >> iter 84000, loss: 0.014994
 >> iter 85000, loss: 0.015043
 >> iter 86000, loss: 0.014986
 >> iter 87000, loss: 0.015033
 >> iter 88000, loss: 0.014999
 >> iter 89000, loss: 0.015031
 >> iter 90000, loss: 0.014993
   Number of active neurons: 4
 >> iter 91000, loss: 0.015020
 >> iter 92000, loss: 0.014996
 >> iter 93000, loss: 0.015029
 >> iter 94000, loss: 0.014993
 >> iter 95000, loss: 0.015032
 >> iter 96000, loss: 0.014993
 >> iter 97000, loss: 0.015030
 >> iter 98000, loss: 0.014989
 >> iter 99000, loss: 0.015032
 >> iter 100000, loss: 0.014997
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455175
   Number of active neurons: 0
 >> iter 1000, loss: 10.857085
 >> iter 2000, loss: 4.016930
 >> iter 3000, loss: 1.495171
 >> iter 4000, loss: 0.565323
 >> iter 5000, loss: 0.223147
 >> iter 6000, loss: 0.096401
 >> iter 7000, loss: 0.050017
 >> iter 8000, loss: 0.032323
 >> iter 9000, loss: 0.026022
 >> iter 10000, loss: 0.023155
   Number of active neurons: 5
 >> iter 11000, loss: 0.022359
 >> iter 12000, loss: 0.021636
 >> iter 13000, loss: 0.021682
 >> iter 14000, loss: 0.021261
 >> iter 15000, loss: 0.021490
 >> iter 16000, loss: 0.020933
 >> iter 17000, loss: 0.021121
 >> iter 18000, loss: 0.020577
 >> iter 19000, loss: 0.020792
 >> iter 20000, loss: 0.020281
   Number of active neurons: 5
 >> iter 21000, loss: 0.020496
 >> iter 22000, loss: 0.020053
 >> iter 23000, loss: 0.020325
 >> iter 24000, loss: 0.019928
 >> iter 25000, loss: 0.020225
 >> iter 26000, loss: 0.019831
 >> iter 27000, loss: 0.020128
 >> iter 28000, loss: 0.019720
 >> iter 29000, loss: 0.019995
 >> iter 30000, loss: 0.019582
   Number of active neurons: 3
 >> iter 31000, loss: 0.019814
 >> iter 32000, loss: 0.019306
 >> iter 33000, loss: 0.019355
 >> iter 34000, loss: 0.018751
 >> iter 35000, loss: 0.018599
 >> iter 36000, loss: 0.018016
 >> iter 37000, loss: 0.017871
 >> iter 38000, loss: 0.017347
 >> iter 39000, loss: 0.017204
 >> iter 40000, loss: 0.016732
   Number of active neurons: 3
 >> iter 41000, loss: 0.016579
 >> iter 42000, loss: 0.016156
 >> iter 43000, loss: 0.016073
 >> iter 44000, loss: 0.015780
 >> iter 45000, loss: 0.015779
 >> iter 46000, loss: 0.015554
 >> iter 47000, loss: 0.015607
 >> iter 48000, loss: 0.015418
 >> iter 49000, loss: 0.015484
 >> iter 50000, loss: 0.015294
   Number of active neurons: 3
 >> iter 51000, loss: 0.015367
 >> iter 52000, loss: 0.015222
 >> iter 53000, loss: 0.015291
 >> iter 54000, loss: 0.015184
 >> iter 55000, loss: 0.015258
 >> iter 56000, loss: 0.015154
 >> iter 57000, loss: 0.015225
 >> iter 58000, loss: 0.015132
 >> iter 59000, loss: 0.015205
 >> iter 60000, loss: 0.015116
   Number of active neurons: 3
 >> iter 61000, loss: 0.015206
 >> iter 62000, loss: 0.015100
 >> iter 63000, loss: 0.015181
 >> iter 64000, loss: 0.015091
 >> iter 65000, loss: 0.015164
 >> iter 66000, loss: 0.015083
 >> iter 67000, loss: 0.015150
 >> iter 68000, loss: 0.015083
 >> iter 69000, loss: 0.015132
 >> iter 70000, loss: 0.015074
   Number of active neurons: 3
 >> iter 71000, loss: 0.015115
 >> iter 72000, loss: 0.015062
 >> iter 73000, loss: 0.015121
 >> iter 74000, loss: 0.015060
 >> iter 75000, loss: 0.015112
 >> iter 76000, loss: 0.015058
 >> iter 77000, loss: 0.015107
 >> iter 78000, loss: 0.015051
 >> iter 79000, loss: 0.015103
 >> iter 80000, loss: 0.015041
   Number of active neurons: 3
 >> iter 81000, loss: 0.015099
 >> iter 82000, loss: 0.015038
 >> iter 83000, loss: 0.015102
 >> iter 84000, loss: 0.015043
 >> iter 85000, loss: 0.015095
 >> iter 86000, loss: 0.015041
 >> iter 87000, loss: 0.015091
 >> iter 88000, loss: 0.015061
 >> iter 89000, loss: 0.015098
 >> iter 90000, loss: 0.015064
   Number of active neurons: 3
 >> iter 91000, loss: 0.015096
 >> iter 92000, loss: 0.015076
 >> iter 93000, loss: 0.015114
 >> iter 94000, loss: 0.015084
 >> iter 95000, loss: 0.015129
 >> iter 96000, loss: 0.015095
 >> iter 97000, loss: 0.015140
 >> iter 98000, loss: 0.015103
 >> iter 99000, loss: 0.015155
 >> iter 100000, loss: 0.015124
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 10.870368
 >> iter 2000, loss: 4.024347
 >> iter 3000, loss: 1.498303
 >> iter 4000, loss: 0.566281
 >> iter 5000, loss: 0.222827
 >> iter 6000, loss: 0.095420
 >> iter 7000, loss: 0.048437
 >> iter 8000, loss: 0.030272
 >> iter 9000, loss: 0.023680
 >> iter 10000, loss: 0.020693
   Number of active neurons: 3
 >> iter 11000, loss: 0.019717
 >> iter 12000, loss: 0.018776
 >> iter 13000, loss: 0.018521
 >> iter 14000, loss: 0.017876
 >> iter 15000, loss: 0.017804
 >> iter 16000, loss: 0.017255
 >> iter 17000, loss: 0.017260
 >> iter 18000, loss: 0.016790
 >> iter 19000, loss: 0.016896
 >> iter 20000, loss: 0.016538
   Number of active neurons: 3
 >> iter 21000, loss: 0.016708
 >> iter 22000, loss: 0.016402
 >> iter 23000, loss: 0.016608
 >> iter 24000, loss: 0.016326
 >> iter 25000, loss: 0.016556
 >> iter 26000, loss: 0.016280
 >> iter 27000, loss: 0.016524
 >> iter 28000, loss: 0.016207
 >> iter 29000, loss: 0.016392
 >> iter 30000, loss: 0.016105
   Number of active neurons: 3
 >> iter 31000, loss: 0.016308
 >> iter 32000, loss: 0.016048
 >> iter 33000, loss: 0.016260
 >> iter 34000, loss: 0.016040
 >> iter 35000, loss: 0.016237
 >> iter 36000, loss: 0.016037
 >> iter 37000, loss: 0.016234
 >> iter 38000, loss: 0.016043
 >> iter 39000, loss: 0.016225
 >> iter 40000, loss: 0.016063
   Number of active neurons: 2
 >> iter 41000, loss: 0.016218
 >> iter 42000, loss: 0.016014
 >> iter 43000, loss: 0.016070
 >> iter 44000, loss: 0.015799
 >> iter 45000, loss: 0.015825
 >> iter 46000, loss: 0.015572
 >> iter 47000, loss: 0.015621
 >> iter 48000, loss: 0.015378
 >> iter 49000, loss: 0.015398
 >> iter 50000, loss: 0.015087
   Number of active neurons: 2
 >> iter 51000, loss: 0.015064
 >> iter 52000, loss: 0.014776
 >> iter 53000, loss: 0.014722
 >> iter 54000, loss: 0.014436
 >> iter 55000, loss: 0.014334
 >> iter 56000, loss: 0.014014
 >> iter 57000, loss: 0.013902
 >> iter 58000, loss: 0.013641
 >> iter 59000, loss: 0.013590
 >> iter 60000, loss: 0.013387
   Number of active neurons: 2
 >> iter 61000, loss: 0.013392
 >> iter 62000, loss: 0.013210
 >> iter 63000, loss: 0.013233
 >> iter 64000, loss: 0.013085
 >> iter 65000, loss: 0.013116
 >> iter 66000, loss: 0.012987
 >> iter 67000, loss: 0.013025
 >> iter 68000, loss: 0.012915
 >> iter 69000, loss: 0.012944
 >> iter 70000, loss: 0.012846
   Number of active neurons: 2
 >> iter 71000, loss: 0.012874
 >> iter 72000, loss: 0.012784
 >> iter 73000, loss: 0.012829
 >> iter 74000, loss: 0.012738
 >> iter 75000, loss: 0.012780
 >> iter 76000, loss: 0.012696
 >> iter 77000, loss: 0.012736
 >> iter 78000, loss: 0.012653
 >> iter 79000, loss: 0.012697
 >> iter 80000, loss: 0.012611
   Number of active neurons: 2
 >> iter 81000, loss: 0.012662
 >> iter 82000, loss: 0.012579
 >> iter 83000, loss: 0.012631
 >> iter 84000, loss: 0.012555
 >> iter 85000, loss: 0.012598
 >> iter 86000, loss: 0.012528
 >> iter 87000, loss: 0.012571
 >> iter 88000, loss: 0.012515
 >> iter 89000, loss: 0.012551
 >> iter 90000, loss: 0.012493
   Number of active neurons: 2
 >> iter 91000, loss: 0.012527
 >> iter 92000, loss: 0.012481
 >> iter 93000, loss: 0.012515
 >> iter 94000, loss: 0.012464
 >> iter 95000, loss: 0.012505
 >> iter 96000, loss: 0.012451
 >> iter 97000, loss: 0.012492
 >> iter 98000, loss: 0.012437
 >> iter 99000, loss: 0.012481
 >> iter 100000, loss: 0.012431
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 10.882812
 >> iter 2000, loss: 4.028415
 >> iter 3000, loss: 1.499923
 >> iter 4000, loss: 0.567500
 >> iter 5000, loss: 0.223992
 >> iter 6000, loss: 0.096613
 >> iter 7000, loss: 0.049926
 >> iter 8000, loss: 0.032139
 >> iter 9000, loss: 0.025751
 >> iter 10000, loss: 0.022854
   Number of active neurons: 6
 >> iter 11000, loss: 0.022013
 >> iter 12000, loss: 0.021227
 >> iter 13000, loss: 0.021148
 >> iter 14000, loss: 0.020628
 >> iter 15000, loss: 0.020816
 >> iter 16000, loss: 0.020212
 >> iter 17000, loss: 0.020474
 >> iter 18000, loss: 0.019975
 >> iter 19000, loss: 0.020314
 >> iter 20000, loss: 0.019888
   Number of active neurons: 6
 >> iter 21000, loss: 0.020230
 >> iter 22000, loss: 0.019835
 >> iter 23000, loss: 0.020175
 >> iter 24000, loss: 0.019795
 >> iter 25000, loss: 0.020135
 >> iter 26000, loss: 0.019759
 >> iter 27000, loss: 0.020098
 >> iter 28000, loss: 0.019716
 >> iter 29000, loss: 0.020073
 >> iter 30000, loss: 0.019712
   Number of active neurons: 6
 >> iter 31000, loss: 0.020057
 >> iter 32000, loss: 0.019677
 >> iter 33000, loss: 0.019996
 >> iter 34000, loss: 0.019639
 >> iter 35000, loss: 0.019810
 >> iter 36000, loss: 0.019426
 >> iter 37000, loss: 0.019493
 >> iter 38000, loss: 0.019066
 >> iter 39000, loss: 0.019069
 >> iter 40000, loss: 0.018720
   Number of active neurons: 5
 >> iter 41000, loss: 0.018729
 >> iter 42000, loss: 0.018416
 >> iter 43000, loss: 0.018431
 >> iter 44000, loss: 0.018137
 >> iter 45000, loss: 0.018141
 >> iter 46000, loss: 0.017888
 >> iter 47000, loss: 0.017960
 >> iter 48000, loss: 0.017756
 >> iter 49000, loss: 0.017865
 >> iter 50000, loss: 0.017670
   Number of active neurons: 5
 >> iter 51000, loss: 0.017767
 >> iter 52000, loss: 0.017569
 >> iter 53000, loss: 0.017618
 >> iter 54000, loss: 0.017446
 >> iter 55000, loss: 0.017457
 >> iter 56000, loss: 0.017194
 >> iter 57000, loss: 0.017145
 >> iter 58000, loss: 0.016885
 >> iter 59000, loss: 0.016816
 >> iter 60000, loss: 0.016571
   Number of active neurons: 4
 >> iter 61000, loss: 0.016540
 >> iter 62000, loss: 0.016289
 >> iter 63000, loss: 0.016240
 >> iter 64000, loss: 0.015986
 >> iter 65000, loss: 0.015920
 >> iter 66000, loss: 0.015715
 >> iter 67000, loss: 0.015713
 >> iter 68000, loss: 0.015565
 >> iter 69000, loss: 0.015578
 >> iter 70000, loss: 0.015478
   Number of active neurons: 4
 >> iter 71000, loss: 0.015521
 >> iter 72000, loss: 0.015444
 >> iter 73000, loss: 0.015516
 >> iter 74000, loss: 0.015434
 >> iter 75000, loss: 0.015501
 >> iter 76000, loss: 0.015428
 >> iter 77000, loss: 0.015492
 >> iter 78000, loss: 0.015417
 >> iter 79000, loss: 0.015486
 >> iter 80000, loss: 0.015406
   Number of active neurons: 4
 >> iter 81000, loss: 0.015482
 >> iter 82000, loss: 0.015404
 >> iter 83000, loss: 0.015484
 >> iter 84000, loss: 0.015411
 >> iter 85000, loss: 0.015481
 >> iter 86000, loss: 0.015414
 >> iter 87000, loss: 0.015482
 >> iter 88000, loss: 0.015437
 >> iter 89000, loss: 0.015497
 >> iter 90000, loss: 0.015447
   Number of active neurons: 4
 >> iter 91000, loss: 0.015503
 >> iter 92000, loss: 0.015469
 >> iter 93000, loss: 0.015528
 >> iter 94000, loss: 0.015486
 >> iter 95000, loss: 0.015555
 >> iter 96000, loss: 0.015507
 >> iter 97000, loss: 0.015578
 >> iter 98000, loss: 0.015528
 >> iter 99000, loss: 0.015604
 >> iter 100000, loss: 0.015562
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.985515
 >> iter 2000, loss: 4.066806
 >> iter 3000, loss: 1.514527
 >> iter 4000, loss: 0.573906
 >> iter 5000, loss: 0.228029
 >> iter 6000, loss: 0.100111
 >> iter 7000, loss: 0.053456
 >> iter 8000, loss: 0.035747
 >> iter 9000, loss: 0.029497
 >> iter 10000, loss: 0.026473
   Number of active neurons: 5
 >> iter 11000, loss: 0.025477
 >> iter 12000, loss: 0.024415
 >> iter 13000, loss: 0.024178
 >> iter 14000, loss: 0.023433
 >> iter 15000, loss: 0.023329
 >> iter 16000, loss: 0.022465
 >> iter 17000, loss: 0.022331
 >> iter 18000, loss: 0.021588
 >> iter 19000, loss: 0.021582
 >> iter 20000, loss: 0.020965
   Number of active neurons: 5
 >> iter 21000, loss: 0.021075
 >> iter 22000, loss: 0.020634
 >> iter 23000, loss: 0.020887
 >> iter 24000, loss: 0.020539
 >> iter 25000, loss: 0.020854
 >> iter 26000, loss: 0.020529
 >> iter 27000, loss: 0.020868
 >> iter 28000, loss: 0.020544
 >> iter 29000, loss: 0.020884
 >> iter 30000, loss: 0.020577
   Number of active neurons: 4
 >> iter 31000, loss: 0.020908
 >> iter 32000, loss: 0.020582
 >> iter 33000, loss: 0.020836
 >> iter 34000, loss: 0.020472
 >> iter 35000, loss: 0.020626
 >> iter 36000, loss: 0.020200
 >> iter 37000, loss: 0.020223
 >> iter 38000, loss: 0.019731
 >> iter 39000, loss: 0.019666
 >> iter 40000, loss: 0.019189
   Number of active neurons: 3
 >> iter 41000, loss: 0.019059
 >> iter 42000, loss: 0.018556
 >> iter 43000, loss: 0.018413
 >> iter 44000, loss: 0.017917
 >> iter 45000, loss: 0.017752
 >> iter 46000, loss: 0.017260
 >> iter 47000, loss: 0.017148
 >> iter 48000, loss: 0.016769
 >> iter 49000, loss: 0.016745
 >> iter 50000, loss: 0.016356
   Number of active neurons: 2
 >> iter 51000, loss: 0.016313
 >> iter 52000, loss: 0.015996
 >> iter 53000, loss: 0.015969
 >> iter 54000, loss: 0.015701
 >> iter 55000, loss: 0.015631
 >> iter 56000, loss: 0.015313
 >> iter 57000, loss: 0.015217
 >> iter 58000, loss: 0.014915
 >> iter 59000, loss: 0.014809
 >> iter 60000, loss: 0.014489
   Number of active neurons: 2
 >> iter 61000, loss: 0.014354
 >> iter 62000, loss: 0.014019
 >> iter 63000, loss: 0.013924
 >> iter 64000, loss: 0.013673
 >> iter 65000, loss: 0.013629
 >> iter 66000, loss: 0.013435
 >> iter 67000, loss: 0.013426
 >> iter 68000, loss: 0.013273
 >> iter 69000, loss: 0.013270
 >> iter 70000, loss: 0.013143
   Number of active neurons: 2
 >> iter 71000, loss: 0.013149
 >> iter 72000, loss: 0.013037
 >> iter 73000, loss: 0.013066
 >> iter 74000, loss: 0.012956
 >> iter 75000, loss: 0.012985
 >> iter 76000, loss: 0.012887
 >> iter 77000, loss: 0.012916
 >> iter 78000, loss: 0.012821
 >> iter 79000, loss: 0.012855
 >> iter 80000, loss: 0.012759
   Number of active neurons: 2
 >> iter 81000, loss: 0.012802
 >> iter 82000, loss: 0.012709
 >> iter 83000, loss: 0.012755
 >> iter 84000, loss: 0.012671
 >> iter 85000, loss: 0.012707
 >> iter 86000, loss: 0.012630
 >> iter 87000, loss: 0.012667
 >> iter 88000, loss: 0.012606
 >> iter 89000, loss: 0.012637
 >> iter 90000, loss: 0.012573
   Number of active neurons: 2
 >> iter 91000, loss: 0.012602
 >> iter 92000, loss: 0.012552
 >> iter 93000, loss: 0.012582
 >> iter 94000, loss: 0.012528
 >> iter 95000, loss: 0.012565
 >> iter 96000, loss: 0.012507
 >> iter 97000, loss: 0.012545
 >> iter 98000, loss: 0.012487
 >> iter 99000, loss: 0.012528
 >> iter 100000, loss: 0.012475
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.909681
 >> iter 2000, loss: 4.038791
 >> iter 3000, loss: 1.503756
 >> iter 4000, loss: 0.568554
 >> iter 5000, loss: 0.224079
 >> iter 6000, loss: 0.096414
 >> iter 7000, loss: 0.049647
 >> iter 8000, loss: 0.031897
 >> iter 9000, loss: 0.025723
 >> iter 10000, loss: 0.022929
   Number of active neurons: 4
 >> iter 11000, loss: 0.022141
 >> iter 12000, loss: 0.021306
 >> iter 13000, loss: 0.021208
 >> iter 14000, loss: 0.020593
 >> iter 15000, loss: 0.020549
 >> iter 16000, loss: 0.019856
 >> iter 17000, loss: 0.019846
 >> iter 18000, loss: 0.019290
 >> iter 19000, loss: 0.019378
 >> iter 20000, loss: 0.018883
   Number of active neurons: 4
 >> iter 21000, loss: 0.019011
 >> iter 22000, loss: 0.018618
 >> iter 23000, loss: 0.018832
 >> iter 24000, loss: 0.018497
 >> iter 25000, loss: 0.018751
 >> iter 26000, loss: 0.018426
 >> iter 27000, loss: 0.018690
 >> iter 28000, loss: 0.018355
 >> iter 29000, loss: 0.018602
 >> iter 30000, loss: 0.018171
   Number of active neurons: 3
 >> iter 31000, loss: 0.018249
 >> iter 32000, loss: 0.017808
 >> iter 33000, loss: 0.017898
 >> iter 34000, loss: 0.017487
 >> iter 35000, loss: 0.017532
 >> iter 36000, loss: 0.017167
 >> iter 37000, loss: 0.017221
 >> iter 38000, loss: 0.016867
 >> iter 39000, loss: 0.016884
 >> iter 40000, loss: 0.016567
   Number of active neurons: 3
 >> iter 41000, loss: 0.016606
 >> iter 42000, loss: 0.016351
 >> iter 43000, loss: 0.016452
 >> iter 44000, loss: 0.016254
 >> iter 45000, loss: 0.016356
 >> iter 46000, loss: 0.016153
 >> iter 47000, loss: 0.016276
 >> iter 48000, loss: 0.016091
 >> iter 49000, loss: 0.016243
 >> iter 50000, loss: 0.016061
   Number of active neurons: 3
 >> iter 51000, loss: 0.016213
 >> iter 52000, loss: 0.016054
 >> iter 53000, loss: 0.016140
 >> iter 54000, loss: 0.015907
 >> iter 55000, loss: 0.015921
 >> iter 56000, loss: 0.015699
 >> iter 57000, loss: 0.015718
 >> iter 58000, loss: 0.015515
 >> iter 59000, loss: 0.015523
 >> iter 60000, loss: 0.015264
   Number of active neurons: 2
 >> iter 61000, loss: 0.015215
 >> iter 62000, loss: 0.014932
 >> iter 63000, loss: 0.014866
 >> iter 64000, loss: 0.014589
 >> iter 65000, loss: 0.014482
 >> iter 66000, loss: 0.014175
 >> iter 67000, loss: 0.014038
 >> iter 68000, loss: 0.013771
 >> iter 69000, loss: 0.013679
 >> iter 70000, loss: 0.013482
   Number of active neurons: 2
 >> iter 71000, loss: 0.013434
 >> iter 72000, loss: 0.013280
 >> iter 73000, loss: 0.013276
 >> iter 74000, loss: 0.013141
 >> iter 75000, loss: 0.013148
 >> iter 76000, loss: 0.013033
 >> iter 77000, loss: 0.013048
 >> iter 78000, loss: 0.012941
 >> iter 79000, loss: 0.012966
 >> iter 80000, loss: 0.012861
   Number of active neurons: 2
 >> iter 81000, loss: 0.012897
 >> iter 82000, loss: 0.012797
 >> iter 83000, loss: 0.012837
 >> iter 84000, loss: 0.012747
 >> iter 85000, loss: 0.012779
 >> iter 86000, loss: 0.012697
 >> iter 87000, loss: 0.012730
 >> iter 88000, loss: 0.012664
 >> iter 89000, loss: 0.012692
 >> iter 90000, loss: 0.012625
   Number of active neurons: 2
 >> iter 91000, loss: 0.012651
 >> iter 92000, loss: 0.012597
 >> iter 93000, loss: 0.012625
 >> iter 94000, loss: 0.012568
 >> iter 95000, loss: 0.012603
 >> iter 96000, loss: 0.012543
 >> iter 97000, loss: 0.012579
 >> iter 98000, loss: 0.012517
 >> iter 99000, loss: 0.012558
 >> iter 100000, loss: 0.012503
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 10.859322
 >> iter 2000, loss: 4.021205
 >> iter 3000, loss: 1.497686
 >> iter 4000, loss: 0.566385
 >> iter 5000, loss: 0.223008
 >> iter 6000, loss: 0.095651
 >> iter 7000, loss: 0.048813
 >> iter 8000, loss: 0.030770
 >> iter 9000, loss: 0.024331
 >> iter 10000, loss: 0.021419
   Number of active neurons: 4
 >> iter 11000, loss: 0.020545
 >> iter 12000, loss: 0.019622
 >> iter 13000, loss: 0.019510
 >> iter 14000, loss: 0.018866
 >> iter 15000, loss: 0.018824
 >> iter 16000, loss: 0.018062
 >> iter 17000, loss: 0.017987
 >> iter 18000, loss: 0.017330
 >> iter 19000, loss: 0.017336
 >> iter 20000, loss: 0.016782
   Number of active neurons: 4
 >> iter 21000, loss: 0.016780
 >> iter 22000, loss: 0.016292
 >> iter 23000, loss: 0.016411
 >> iter 24000, loss: 0.016055
 >> iter 25000, loss: 0.016242
 >> iter 26000, loss: 0.015924
 >> iter 27000, loss: 0.016150
 >> iter 28000, loss: 0.015840
 >> iter 29000, loss: 0.016018
 >> iter 30000, loss: 0.015710
   Number of active neurons: 4
 >> iter 31000, loss: 0.015896
 >> iter 32000, loss: 0.015622
 >> iter 33000, loss: 0.015821
 >> iter 34000, loss: 0.015593
 >> iter 35000, loss: 0.015778
 >> iter 36000, loss: 0.015576
 >> iter 37000, loss: 0.015764
 >> iter 38000, loss: 0.015576
 >> iter 39000, loss: 0.015752
 >> iter 40000, loss: 0.015603
   Number of active neurons: 4
 >> iter 41000, loss: 0.015757
 >> iter 42000, loss: 0.015604
 >> iter 43000, loss: 0.015765
 >> iter 44000, loss: 0.015634
 >> iter 45000, loss: 0.015787
 >> iter 46000, loss: 0.015649
 >> iter 47000, loss: 0.015806
 >> iter 48000, loss: 0.015649
 >> iter 49000, loss: 0.015804
 >> iter 50000, loss: 0.015644
   Number of active neurons: 4
 >> iter 51000, loss: 0.015805
 >> iter 52000, loss: 0.015676
 >> iter 53000, loss: 0.015819
 >> iter 54000, loss: 0.015718
 >> iter 55000, loss: 0.015857
 >> iter 56000, loss: 0.015755
 >> iter 57000, loss: 0.015887
 >> iter 58000, loss: 0.015792
 >> iter 59000, loss: 0.015924
 >> iter 60000, loss: 0.015832
   Number of active neurons: 4
 >> iter 61000, loss: 0.015980
 >> iter 62000, loss: 0.015865
 >> iter 63000, loss: 0.016001
 >> iter 64000, loss: 0.015900
 >> iter 65000, loss: 0.016023
 >> iter 66000, loss: 0.015925
 >> iter 67000, loss: 0.016040
 >> iter 68000, loss: 0.015945
 >> iter 69000, loss: 0.015984
 >> iter 70000, loss: 0.015796
   Number of active neurons: 3
 >> iter 71000, loss: 0.015779
 >> iter 72000, loss: 0.015609
 >> iter 73000, loss: 0.015623
 >> iter 74000, loss: 0.015458
 >> iter 75000, loss: 0.015456
 >> iter 76000, loss: 0.015246
 >> iter 77000, loss: 0.015163
 >> iter 78000, loss: 0.014931
 >> iter 79000, loss: 0.014843
 >> iter 80000, loss: 0.014602
   Number of active neurons: 3
 >> iter 81000, loss: 0.014493
 >> iter 82000, loss: 0.014218
 >> iter 83000, loss: 0.014065
 >> iter 84000, loss: 0.013797
 >> iter 85000, loss: 0.013684
 >> iter 86000, loss: 0.013484
 >> iter 87000, loss: 0.013424
 >> iter 88000, loss: 0.013282
 >> iter 89000, loss: 0.013249
 >> iter 90000, loss: 0.013130
   Number of active neurons: 3
 >> iter 91000, loss: 0.013113
 >> iter 92000, loss: 0.013021
 >> iter 93000, loss: 0.013018
 >> iter 94000, loss: 0.012932
 >> iter 95000, loss: 0.012942
 >> iter 96000, loss: 0.012858
 >> iter 97000, loss: 0.012875
 >> iter 98000, loss: 0.012794
 >> iter 99000, loss: 0.012817
 >> iter 100000, loss: 0.012746
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 10.899950
 >> iter 2000, loss: 4.034011
 >> iter 3000, loss: 1.502132
 >> iter 4000, loss: 0.568397
 >> iter 5000, loss: 0.224605
 >> iter 6000, loss: 0.097020
 >> iter 7000, loss: 0.050268
 >> iter 8000, loss: 0.032375
 >> iter 9000, loss: 0.026012
 >> iter 10000, loss: 0.023144
   Number of active neurons: 6
 >> iter 11000, loss: 0.022430
 >> iter 12000, loss: 0.021733
 >> iter 13000, loss: 0.021809
 >> iter 14000, loss: 0.021358
 >> iter 15000, loss: 0.021513
 >> iter 16000, loss: 0.020914
 >> iter 17000, loss: 0.020980
 >> iter 18000, loss: 0.020340
 >> iter 19000, loss: 0.020321
 >> iter 20000, loss: 0.019696
   Number of active neurons: 5
 >> iter 21000, loss: 0.019701
 >> iter 22000, loss: 0.019166
 >> iter 23000, loss: 0.019234
 >> iter 24000, loss: 0.018746
 >> iter 25000, loss: 0.018904
 >> iter 26000, loss: 0.018516
 >> iter 27000, loss: 0.018763
 >> iter 28000, loss: 0.018424
 >> iter 29000, loss: 0.018704
 >> iter 30000, loss: 0.018378
   Number of active neurons: 5
 >> iter 31000, loss: 0.018594
 >> iter 32000, loss: 0.018256
 >> iter 33000, loss: 0.018472
 >> iter 34000, loss: 0.018187
 >> iter 35000, loss: 0.018377
 >> iter 36000, loss: 0.018109
 >> iter 37000, loss: 0.018231
 >> iter 38000, loss: 0.017883
 >> iter 39000, loss: 0.017954
 >> iter 40000, loss: 0.017663
   Number of active neurons: 4
 >> iter 41000, loss: 0.017686
 >> iter 42000, loss: 0.017356
 >> iter 43000, loss: 0.017382
 >> iter 44000, loss: 0.017090
 >> iter 45000, loss: 0.017097
 >> iter 46000, loss: 0.016754
 >> iter 47000, loss: 0.016728
 >> iter 48000, loss: 0.016420
 >> iter 49000, loss: 0.016481
 >> iter 50000, loss: 0.016238
   Number of active neurons: 4
 >> iter 51000, loss: 0.016350
 >> iter 52000, loss: 0.016169
 >> iter 53000, loss: 0.016284
 >> iter 54000, loss: 0.016143
 >> iter 55000, loss: 0.016259
 >> iter 56000, loss: 0.016123
 >> iter 57000, loss: 0.016230
 >> iter 58000, loss: 0.016091
 >> iter 59000, loss: 0.016120
 >> iter 60000, loss: 0.015891
   Number of active neurons: 3
 >> iter 61000, loss: 0.015910
 >> iter 62000, loss: 0.015680
 >> iter 63000, loss: 0.015701
 >> iter 64000, loss: 0.015493
 >> iter 65000, loss: 0.015464
 >> iter 66000, loss: 0.015198
 >> iter 67000, loss: 0.015123
 >> iter 68000, loss: 0.014870
 >> iter 69000, loss: 0.014766
 >> iter 70000, loss: 0.014504
   Number of active neurons: 3
 >> iter 71000, loss: 0.014355
 >> iter 72000, loss: 0.014061
 >> iter 73000, loss: 0.013928
 >> iter 74000, loss: 0.013685
 >> iter 75000, loss: 0.013609
 >> iter 76000, loss: 0.013427
 >> iter 77000, loss: 0.013391
 >> iter 78000, loss: 0.013242
 >> iter 79000, loss: 0.013234
 >> iter 80000, loss: 0.013102
   Number of active neurons: 3
 >> iter 81000, loss: 0.013115
 >> iter 82000, loss: 0.012997
 >> iter 83000, loss: 0.013020
 >> iter 84000, loss: 0.012916
 >> iter 85000, loss: 0.012936
 >> iter 86000, loss: 0.012842
 >> iter 87000, loss: 0.012866
 >> iter 88000, loss: 0.012791
 >> iter 89000, loss: 0.012811
 >> iter 90000, loss: 0.012736
   Number of active neurons: 3
 >> iter 91000, loss: 0.012756
 >> iter 92000, loss: 0.012695
 >> iter 93000, loss: 0.012718
 >> iter 94000, loss: 0.012654
 >> iter 95000, loss: 0.012684
 >> iter 96000, loss: 0.012619
 >> iter 97000, loss: 0.012651
 >> iter 98000, loss: 0.012585
 >> iter 99000, loss: 0.012621
 >> iter 100000, loss: 0.012562
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455164
   Number of active neurons: 0
 >> iter 1000, loss: 10.838168
 >> iter 2000, loss: 4.014362
 >> iter 3000, loss: 1.495402
 >> iter 4000, loss: 0.565960
 >> iter 5000, loss: 0.223567
 >> iter 6000, loss: 0.096557
 >> iter 7000, loss: 0.049860
 >> iter 8000, loss: 0.031804
 >> iter 9000, loss: 0.025227
 >> iter 10000, loss: 0.022150
   Number of active neurons: 4
 >> iter 11000, loss: 0.021202
 >> iter 12000, loss: 0.020303
 >> iter 13000, loss: 0.020206
 >> iter 14000, loss: 0.019652
 >> iter 15000, loss: 0.019630
 >> iter 16000, loss: 0.018896
 >> iter 17000, loss: 0.018769
 >> iter 18000, loss: 0.018106
 >> iter 19000, loss: 0.018046
 >> iter 20000, loss: 0.017430
   Number of active neurons: 4
 >> iter 21000, loss: 0.017347
 >> iter 22000, loss: 0.016770
 >> iter 23000, loss: 0.016783
 >> iter 24000, loss: 0.016351
 >> iter 25000, loss: 0.016486
 >> iter 26000, loss: 0.016117
 >> iter 27000, loss: 0.016303
 >> iter 28000, loss: 0.015976
 >> iter 29000, loss: 0.016147
 >> iter 30000, loss: 0.015817
   Number of active neurons: 4
 >> iter 31000, loss: 0.015991
 >> iter 32000, loss: 0.015703
 >> iter 33000, loss: 0.015895
 >> iter 34000, loss: 0.015659
 >> iter 35000, loss: 0.015841
 >> iter 36000, loss: 0.015633
 >> iter 37000, loss: 0.015819
 >> iter 38000, loss: 0.015627
 >> iter 39000, loss: 0.015803
 >> iter 40000, loss: 0.015651
   Number of active neurons: 4
 >> iter 41000, loss: 0.015806
 >> iter 42000, loss: 0.015650
 >> iter 43000, loss: 0.015812
 >> iter 44000, loss: 0.015679
 >> iter 45000, loss: 0.015834
 >> iter 46000, loss: 0.015694
 >> iter 47000, loss: 0.015853
 >> iter 48000, loss: 0.015694
 >> iter 49000, loss: 0.015850
 >> iter 50000, loss: 0.015689
   Number of active neurons: 4
 >> iter 51000, loss: 0.015850
 >> iter 52000, loss: 0.015720
 >> iter 53000, loss: 0.015864
 >> iter 54000, loss: 0.015762
 >> iter 55000, loss: 0.015901
 >> iter 56000, loss: 0.015798
 >> iter 57000, loss: 0.015930
 >> iter 58000, loss: 0.015834
 >> iter 59000, loss: 0.015965
 >> iter 60000, loss: 0.015871
   Number of active neurons: 4
 >> iter 61000, loss: 0.016017
 >> iter 62000, loss: 0.015900
 >> iter 63000, loss: 0.016034
 >> iter 64000, loss: 0.015928
 >> iter 65000, loss: 0.016047
 >> iter 66000, loss: 0.015942
 >> iter 67000, loss: 0.016015
 >> iter 68000, loss: 0.015821
 >> iter 69000, loss: 0.015810
 >> iter 70000, loss: 0.015633
   Number of active neurons: 3
 >> iter 71000, loss: 0.015630
 >> iter 72000, loss: 0.015471
 >> iter 73000, loss: 0.015479
 >> iter 74000, loss: 0.015272
 >> iter 75000, loss: 0.015195
 >> iter 76000, loss: 0.014965
 >> iter 77000, loss: 0.014876
 >> iter 78000, loss: 0.014640
 >> iter 79000, loss: 0.014528
 >> iter 80000, loss: 0.014256
   Number of active neurons: 3
 >> iter 81000, loss: 0.014104
 >> iter 82000, loss: 0.013826
 >> iter 83000, loss: 0.013718
 >> iter 84000, loss: 0.013510
 >> iter 85000, loss: 0.013447
 >> iter 86000, loss: 0.013289
 >> iter 87000, loss: 0.013261
 >> iter 88000, loss: 0.013145
 >> iter 89000, loss: 0.013131
 >> iter 90000, loss: 0.013027
   Number of active neurons: 3
 >> iter 91000, loss: 0.013022
 >> iter 92000, loss: 0.012940
 >> iter 93000, loss: 0.012945
 >> iter 94000, loss: 0.012865
 >> iter 95000, loss: 0.012881
 >> iter 96000, loss: 0.012802
 >> iter 97000, loss: 0.012823
 >> iter 98000, loss: 0.012745
 >> iter 99000, loss: 0.012772
 >> iter 100000, loss: 0.012704
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.857488
 >> iter 2000, loss: 4.017886
 >> iter 3000, loss: 1.495784
 >> iter 4000, loss: 0.565688
 >> iter 5000, loss: 0.223142
 >> iter 6000, loss: 0.095899
 >> iter 7000, loss: 0.048933
 >> iter 8000, loss: 0.030773
 >> iter 9000, loss: 0.024210
 >> iter 10000, loss: 0.021126
   Number of active neurons: 4
 >> iter 11000, loss: 0.019990
 >> iter 12000, loss: 0.018816
 >> iter 13000, loss: 0.018462
 >> iter 14000, loss: 0.017736
 >> iter 15000, loss: 0.017787
 >> iter 16000, loss: 0.017160
 >> iter 17000, loss: 0.017311
 >> iter 18000, loss: 0.016721
 >> iter 19000, loss: 0.016814
 >> iter 20000, loss: 0.016238
   Number of active neurons: 4
 >> iter 21000, loss: 0.016353
 >> iter 22000, loss: 0.015876
 >> iter 23000, loss: 0.016050
 >> iter 24000, loss: 0.015633
 >> iter 25000, loss: 0.015827
 >> iter 26000, loss: 0.015473
 >> iter 27000, loss: 0.015710
 >> iter 28000, loss: 0.015433
 >> iter 29000, loss: 0.015653
 >> iter 30000, loss: 0.015360
   Number of active neurons: 4
 >> iter 31000, loss: 0.015547
 >> iter 32000, loss: 0.015285
 >> iter 33000, loss: 0.015475
 >> iter 34000, loss: 0.015258
 >> iter 35000, loss: 0.015428
 >> iter 36000, loss: 0.015235
 >> iter 37000, loss: 0.015407
 >> iter 38000, loss: 0.015229
 >> iter 39000, loss: 0.015390
 >> iter 40000, loss: 0.015252
   Number of active neurons: 4
 >> iter 41000, loss: 0.015390
 >> iter 42000, loss: 0.015248
 >> iter 43000, loss: 0.015392
 >> iter 44000, loss: 0.015252
 >> iter 45000, loss: 0.015378
 >> iter 46000, loss: 0.015241
 >> iter 47000, loss: 0.015385
 >> iter 48000, loss: 0.015247
 >> iter 49000, loss: 0.015390
 >> iter 50000, loss: 0.015238
   Number of active neurons: 4
 >> iter 51000, loss: 0.015378
 >> iter 52000, loss: 0.015255
 >> iter 53000, loss: 0.015376
 >> iter 54000, loss: 0.015279
 >> iter 55000, loss: 0.015396
 >> iter 56000, loss: 0.015298
 >> iter 57000, loss: 0.015408
 >> iter 58000, loss: 0.015317
 >> iter 59000, loss: 0.015427
 >> iter 60000, loss: 0.015340
   Number of active neurons: 4
 >> iter 61000, loss: 0.015466
 >> iter 62000, loss: 0.015360
 >> iter 63000, loss: 0.015476
 >> iter 64000, loss: 0.015385
 >> iter 65000, loss: 0.015493
 >> iter 66000, loss: 0.015410
 >> iter 67000, loss: 0.015514
 >> iter 68000, loss: 0.015444
 >> iter 69000, loss: 0.015529
 >> iter 70000, loss: 0.015467
   Number of active neurons: 4
 >> iter 71000, loss: 0.015546
 >> iter 72000, loss: 0.015488
 >> iter 73000, loss: 0.015588
 >> iter 74000, loss: 0.015521
 >> iter 75000, loss: 0.015614
 >> iter 76000, loss: 0.015554
 >> iter 77000, loss: 0.015644
 >> iter 78000, loss: 0.015580
 >> iter 79000, loss: 0.015674
 >> iter 80000, loss: 0.015605
   Number of active neurons: 4
 >> iter 81000, loss: 0.015706
 >> iter 82000, loss: 0.015638
 >> iter 83000, loss: 0.015741
 >> iter 84000, loss: 0.015677
 >> iter 85000, loss: 0.015769
 >> iter 86000, loss: 0.015710
 >> iter 87000, loss: 0.015801
 >> iter 88000, loss: 0.015759
 >> iter 89000, loss: 0.015842
 >> iter 90000, loss: 0.015793
   Number of active neurons: 4
 >> iter 91000, loss: 0.015871
 >> iter 92000, loss: 0.015834
 >> iter 93000, loss: 0.015911
 >> iter 94000, loss: 0.015865
 >> iter 95000, loss: 0.015948
 >> iter 96000, loss: 0.015889
 >> iter 97000, loss: 0.015968
 >> iter 98000, loss: 0.015900
 >> iter 99000, loss: 0.015937
 >> iter 100000, loss: 0.015776
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.905800
 >> iter 2000, loss: 4.036916
 >> iter 3000, loss: 1.502970
 >> iter 4000, loss: 0.568450
 >> iter 5000, loss: 0.224405
 >> iter 6000, loss: 0.096977
 >> iter 7000, loss: 0.050306
 >> iter 8000, loss: 0.032570
 >> iter 9000, loss: 0.026342
 >> iter 10000, loss: 0.023551
   Number of active neurons: 6
 >> iter 11000, loss: 0.022861
 >> iter 12000, loss: 0.022188
 >> iter 13000, loss: 0.022353
 >> iter 14000, loss: 0.022003
 >> iter 15000, loss: 0.022317
 >> iter 16000, loss: 0.021925
 >> iter 17000, loss: 0.022219
 >> iter 18000, loss: 0.021779
 >> iter 19000, loss: 0.021949
 >> iter 20000, loss: 0.021471
   Number of active neurons: 6
 >> iter 21000, loss: 0.021651
 >> iter 22000, loss: 0.021210
 >> iter 23000, loss: 0.021390
 >> iter 24000, loss: 0.020952
 >> iter 25000, loss: 0.021175
 >> iter 26000, loss: 0.020789
 >> iter 27000, loss: 0.021060
 >> iter 28000, loss: 0.020683
 >> iter 29000, loss: 0.020925
 >> iter 30000, loss: 0.020443
   Number of active neurons: 4
 >> iter 31000, loss: 0.020499
 >> iter 32000, loss: 0.019909
 >> iter 33000, loss: 0.019851
 >> iter 34000, loss: 0.019294
 >> iter 35000, loss: 0.019206
 >> iter 36000, loss: 0.018649
 >> iter 37000, loss: 0.018520
 >> iter 38000, loss: 0.017976
 >> iter 39000, loss: 0.017848
 >> iter 40000, loss: 0.017379
   Number of active neurons: 3
 >> iter 41000, loss: 0.017281
 >> iter 42000, loss: 0.016820
 >> iter 43000, loss: 0.016679
 >> iter 44000, loss: 0.016277
 >> iter 45000, loss: 0.016202
 >> iter 46000, loss: 0.015864
 >> iter 47000, loss: 0.015817
 >> iter 48000, loss: 0.015449
 >> iter 49000, loss: 0.015380
 >> iter 50000, loss: 0.015023
   Number of active neurons: 3
 >> iter 51000, loss: 0.014949
 >> iter 52000, loss: 0.014603
 >> iter 53000, loss: 0.014475
 >> iter 54000, loss: 0.014130
 >> iter 55000, loss: 0.014023
 >> iter 56000, loss: 0.013749
 >> iter 57000, loss: 0.013697
 >> iter 58000, loss: 0.013486
 >> iter 59000, loss: 0.013478
 >> iter 60000, loss: 0.013305
   Number of active neurons: 3
 >> iter 61000, loss: 0.013333
 >> iter 62000, loss: 0.013167
 >> iter 63000, loss: 0.013203
 >> iter 64000, loss: 0.013063
 >> iter 65000, loss: 0.013102
 >> iter 66000, loss: 0.012977
 >> iter 67000, loss: 0.013020
 >> iter 68000, loss: 0.012911
 >> iter 69000, loss: 0.012943
 >> iter 70000, loss: 0.012845
   Number of active neurons: 3
 >> iter 71000, loss: 0.012875
 >> iter 72000, loss: 0.012785
 >> iter 73000, loss: 0.012832
 >> iter 74000, loss: 0.012740
 >> iter 75000, loss: 0.012782
 >> iter 76000, loss: 0.012698
 >> iter 77000, loss: 0.012739
 >> iter 78000, loss: 0.012655
 >> iter 79000, loss: 0.012700
 >> iter 80000, loss: 0.012614
   Number of active neurons: 3
 >> iter 81000, loss: 0.012665
 >> iter 82000, loss: 0.012581
 >> iter 83000, loss: 0.012634
 >> iter 84000, loss: 0.012557
 >> iter 85000, loss: 0.012601
 >> iter 86000, loss: 0.012530
 >> iter 87000, loss: 0.012573
 >> iter 88000, loss: 0.012517
 >> iter 89000, loss: 0.012553
 >> iter 90000, loss: 0.012495
   Number of active neurons: 3
 >> iter 91000, loss: 0.012528
 >> iter 92000, loss: 0.012482
 >> iter 93000, loss: 0.012517
 >> iter 94000, loss: 0.012466
 >> iter 95000, loss: 0.012507
 >> iter 96000, loss: 0.012453
 >> iter 97000, loss: 0.012493
 >> iter 98000, loss: 0.012438
 >> iter 99000, loss: 0.012482
 >> iter 100000, loss: 0.012432
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455159
   Number of active neurons: 0
 >> iter 1000, loss: 10.821010
 >> iter 2000, loss: 4.006009
 >> iter 3000, loss: 1.492384
 >> iter 4000, loss: 0.565530
 >> iter 5000, loss: 0.224475
 >> iter 6000, loss: 0.098256
 >> iter 7000, loss: 0.052111
 >> iter 8000, loss: 0.034565
 >> iter 9000, loss: 0.028360
 >> iter 10000, loss: 0.025452
   Number of active neurons: 4
 >> iter 11000, loss: 0.024568
 >> iter 12000, loss: 0.023535
 >> iter 13000, loss: 0.023301
 >> iter 14000, loss: 0.022477
 >> iter 15000, loss: 0.022223
 >> iter 16000, loss: 0.021315
 >> iter 17000, loss: 0.021048
 >> iter 18000, loss: 0.020188
 >> iter 19000, loss: 0.019914
 >> iter 20000, loss: 0.019117
   Number of active neurons: 3
 >> iter 21000, loss: 0.018906
 >> iter 22000, loss: 0.018271
 >> iter 23000, loss: 0.018209
 >> iter 24000, loss: 0.017675
 >> iter 25000, loss: 0.017673
 >> iter 26000, loss: 0.017213
 >> iter 27000, loss: 0.017315
 >> iter 28000, loss: 0.016902
 >> iter 29000, loss: 0.016999
 >> iter 30000, loss: 0.016640
   Number of active neurons: 2
 >> iter 31000, loss: 0.016777
 >> iter 32000, loss: 0.016461
 >> iter 33000, loss: 0.016569
 >> iter 34000, loss: 0.016203
 >> iter 35000, loss: 0.016242
 >> iter 36000, loss: 0.015914
 >> iter 37000, loss: 0.015972
 >> iter 38000, loss: 0.015670
 >> iter 39000, loss: 0.015699
 >> iter 40000, loss: 0.015373
   Number of active neurons: 2
 >> iter 41000, loss: 0.015317
 >> iter 42000, loss: 0.014959
 >> iter 43000, loss: 0.014883
 >> iter 44000, loss: 0.014540
 >> iter 45000, loss: 0.014432
 >> iter 46000, loss: 0.014064
 >> iter 47000, loss: 0.013972
 >> iter 48000, loss: 0.013666
 >> iter 49000, loss: 0.013649
 >> iter 50000, loss: 0.013398
   Number of active neurons: 2
 >> iter 51000, loss: 0.013422
 >> iter 52000, loss: 0.013225
 >> iter 53000, loss: 0.013259
 >> iter 54000, loss: 0.013103
 >> iter 55000, loss: 0.013145
 >> iter 56000, loss: 0.013003
 >> iter 57000, loss: 0.013049
 >> iter 58000, loss: 0.012922
 >> iter 59000, loss: 0.012975
 >> iter 60000, loss: 0.012856
   Number of active neurons: 2
 >> iter 61000, loss: 0.012926
 >> iter 62000, loss: 0.012798
 >> iter 63000, loss: 0.012862
 >> iter 64000, loss: 0.012751
 >> iter 65000, loss: 0.012811
 >> iter 66000, loss: 0.012708
 >> iter 67000, loss: 0.012768
 >> iter 68000, loss: 0.012677
 >> iter 69000, loss: 0.012723
 >> iter 70000, loss: 0.012641
   Number of active neurons: 2
 >> iter 71000, loss: 0.012682
 >> iter 72000, loss: 0.012605
 >> iter 73000, loss: 0.012662
 >> iter 74000, loss: 0.012581
 >> iter 75000, loss: 0.012632
 >> iter 76000, loss: 0.012558
 >> iter 77000, loss: 0.012606
 >> iter 78000, loss: 0.012532
 >> iter 79000, loss: 0.012583
 >> iter 80000, loss: 0.012505
   Number of active neurons: 2
 >> iter 81000, loss: 0.012562
 >> iter 82000, loss: 0.012485
 >> iter 83000, loss: 0.012543
 >> iter 84000, loss: 0.012472
 >> iter 85000, loss: 0.012520
 >> iter 86000, loss: 0.012454
 >> iter 87000, loss: 0.012501
 >> iter 88000, loss: 0.012450
 >> iter 89000, loss: 0.012490
 >> iter 90000, loss: 0.012436
   Number of active neurons: 2
 >> iter 91000, loss: 0.012472
 >> iter 92000, loss: 0.012429
 >> iter 93000, loss: 0.012466
 >> iter 94000, loss: 0.012419
 >> iter 95000, loss: 0.012462
 >> iter 96000, loss: 0.012411
 >> iter 97000, loss: 0.012454
 >> iter 98000, loss: 0.012401
 >> iter 99000, loss: 0.012447
 >> iter 100000, loss: 0.012399
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.850296
 >> iter 2000, loss: 4.015651
 >> iter 3000, loss: 1.495152
 >> iter 4000, loss: 0.565454
 >> iter 5000, loss: 0.223017
 >> iter 6000, loss: 0.095766
 >> iter 7000, loss: 0.048906
 >> iter 8000, loss: 0.030918
 >> iter 9000, loss: 0.024401
 >> iter 10000, loss: 0.021407
   Number of active neurons: 5
 >> iter 11000, loss: 0.020387
 >> iter 12000, loss: 0.019404
 >> iter 13000, loss: 0.019158
 >> iter 14000, loss: 0.018588
 >> iter 15000, loss: 0.018713
 >> iter 16000, loss: 0.018271
 >> iter 17000, loss: 0.018511
 >> iter 18000, loss: 0.018144
 >> iter 19000, loss: 0.018427
 >> iter 20000, loss: 0.018094
   Number of active neurons: 5
 >> iter 21000, loss: 0.018373
 >> iter 22000, loss: 0.018052
 >> iter 23000, loss: 0.018332
 >> iter 24000, loss: 0.018017
 >> iter 25000, loss: 0.018302
 >> iter 26000, loss: 0.017983
 >> iter 27000, loss: 0.018272
 >> iter 28000, loss: 0.017948
 >> iter 29000, loss: 0.018229
 >> iter 30000, loss: 0.017913
   Number of active neurons: 4
 >> iter 31000, loss: 0.018107
 >> iter 32000, loss: 0.017745
 >> iter 33000, loss: 0.017908
 >> iter 34000, loss: 0.017541
 >> iter 35000, loss: 0.017594
 >> iter 36000, loss: 0.017233
 >> iter 37000, loss: 0.017268
 >> iter 38000, loss: 0.016892
 >> iter 39000, loss: 0.016918
 >> iter 40000, loss: 0.016618
   Number of active neurons: 4
 >> iter 41000, loss: 0.016630
 >> iter 42000, loss: 0.016325
 >> iter 43000, loss: 0.016320
 >> iter 44000, loss: 0.016033
 >> iter 45000, loss: 0.016058
 >> iter 46000, loss: 0.015828
 >> iter 47000, loss: 0.015906
 >> iter 48000, loss: 0.015695
 >> iter 49000, loss: 0.015798
 >> iter 50000, loss: 0.015608
   Number of active neurons: 4
 >> iter 51000, loss: 0.015731
 >> iter 52000, loss: 0.015583
 >> iter 53000, loss: 0.015698
 >> iter 54000, loss: 0.015585
 >> iter 55000, loss: 0.015700
 >> iter 56000, loss: 0.015590
 >> iter 57000, loss: 0.015701
 >> iter 58000, loss: 0.015602
 >> iter 59000, loss: 0.015715
 >> iter 60000, loss: 0.015621
   Number of active neurons: 4
 >> iter 61000, loss: 0.015753
 >> iter 62000, loss: 0.015640
 >> iter 63000, loss: 0.015763
 >> iter 64000, loss: 0.015668
 >> iter 65000, loss: 0.015782
 >> iter 66000, loss: 0.015696
 >> iter 67000, loss: 0.015808
 >> iter 68000, loss: 0.015734
 >> iter 69000, loss: 0.015828
 >> iter 70000, loss: 0.015762
   Number of active neurons: 4
 >> iter 71000, loss: 0.015851
 >> iter 72000, loss: 0.015789
 >> iter 73000, loss: 0.015898
 >> iter 74000, loss: 0.015825
 >> iter 75000, loss: 0.015926
 >> iter 76000, loss: 0.015860
 >> iter 77000, loss: 0.015956
 >> iter 78000, loss: 0.015884
 >> iter 79000, loss: 0.015982
 >> iter 80000, loss: 0.015902
   Number of active neurons: 4
 >> iter 81000, loss: 0.016003
 >> iter 82000, loss: 0.015919
 >> iter 83000, loss: 0.016015
 >> iter 84000, loss: 0.015925
 >> iter 85000, loss: 0.015936
 >> iter 86000, loss: 0.015753
 >> iter 87000, loss: 0.015733
 >> iter 88000, loss: 0.015583
 >> iter 89000, loss: 0.015569
 >> iter 90000, loss: 0.015423
   Number of active neurons: 3
 >> iter 91000, loss: 0.015389
 >> iter 92000, loss: 0.015194
 >> iter 93000, loss: 0.015090
 >> iter 94000, loss: 0.014884
 >> iter 95000, loss: 0.014780
 >> iter 96000, loss: 0.014559
 >> iter 97000, loss: 0.014425
 >> iter 98000, loss: 0.014165
 >> iter 99000, loss: 0.013995
 >> iter 100000, loss: 0.013755
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 10.862587
 >> iter 2000, loss: 4.020648
 >> iter 3000, loss: 1.496849
 >> iter 4000, loss: 0.565891
 >> iter 5000, loss: 0.222884
 >> iter 6000, loss: 0.095466
 >> iter 7000, loss: 0.048641
 >> iter 8000, loss: 0.030634
 >> iter 9000, loss: 0.024213
 >> iter 10000, loss: 0.021185
   Number of active neurons: 5
 >> iter 11000, loss: 0.020218
 >> iter 12000, loss: 0.019327
 >> iter 13000, loss: 0.019194
 >> iter 14000, loss: 0.018669
 >> iter 15000, loss: 0.018788
 >> iter 16000, loss: 0.018257
 >> iter 17000, loss: 0.018463
 >> iter 18000, loss: 0.018040
 >> iter 19000, loss: 0.018310
 >> iter 20000, loss: 0.017939
   Number of active neurons: 5
 >> iter 21000, loss: 0.018224
 >> iter 22000, loss: 0.017888
 >> iter 23000, loss: 0.018189
 >> iter 24000, loss: 0.017865
 >> iter 25000, loss: 0.018174
 >> iter 26000, loss: 0.017848
 >> iter 27000, loss: 0.018165
 >> iter 28000, loss: 0.017840
 >> iter 29000, loss: 0.018156
 >> iter 30000, loss: 0.017851
   Number of active neurons: 5
 >> iter 31000, loss: 0.018161
 >> iter 32000, loss: 0.017816
 >> iter 33000, loss: 0.018025
 >> iter 34000, loss: 0.017744
 >> iter 35000, loss: 0.017936
 >> iter 36000, loss: 0.017704
 >> iter 37000, loss: 0.017904
 >> iter 38000, loss: 0.017697
 >> iter 39000, loss: 0.017884
 >> iter 40000, loss: 0.017722
   Number of active neurons: 5
 >> iter 41000, loss: 0.017879
 >> iter 42000, loss: 0.017710
 >> iter 43000, loss: 0.017870
 >> iter 44000, loss: 0.017718
 >> iter 45000, loss: 0.017847
 >> iter 46000, loss: 0.017654
 >> iter 47000, loss: 0.017786
 >> iter 48000, loss: 0.017586
 >> iter 49000, loss: 0.017667
 >> iter 50000, loss: 0.017347
   Number of active neurons: 4
 >> iter 51000, loss: 0.017363
 >> iter 52000, loss: 0.017082
 >> iter 53000, loss: 0.017050
 >> iter 54000, loss: 0.016779
 >> iter 55000, loss: 0.016756
 >> iter 56000, loss: 0.016507
 >> iter 57000, loss: 0.016473
 >> iter 58000, loss: 0.016218
 >> iter 59000, loss: 0.016166
 >> iter 60000, loss: 0.015940
   Number of active neurons: 4
 >> iter 61000, loss: 0.015965
 >> iter 62000, loss: 0.015781
 >> iter 63000, loss: 0.015845
 >> iter 64000, loss: 0.015712
 >> iter 65000, loss: 0.015790
 >> iter 66000, loss: 0.015682
 >> iter 67000, loss: 0.015769
 >> iter 68000, loss: 0.015681
 >> iter 69000, loss: 0.015755
 >> iter 70000, loss: 0.015679
   Number of active neurons: 4
 >> iter 71000, loss: 0.015750
 >> iter 72000, loss: 0.015681
 >> iter 73000, loss: 0.015775
 >> iter 74000, loss: 0.015698
 >> iter 75000, loss: 0.015787
 >> iter 76000, loss: 0.015719
 >> iter 77000, loss: 0.015805
 >> iter 78000, loss: 0.015735
 >> iter 79000, loss: 0.015826
 >> iter 80000, loss: 0.015751
   Number of active neurons: 4
 >> iter 81000, loss: 0.015849
 >> iter 82000, loss: 0.015776
 >> iter 83000, loss: 0.015876
 >> iter 84000, loss: 0.015807
 >> iter 85000, loss: 0.015897
 >> iter 86000, loss: 0.015832
 >> iter 87000, loss: 0.015921
 >> iter 88000, loss: 0.015873
 >> iter 89000, loss: 0.015953
 >> iter 90000, loss: 0.015896
   Number of active neurons: 4
 >> iter 91000, loss: 0.015970
 >> iter 92000, loss: 0.015924
 >> iter 93000, loss: 0.015995
 >> iter 94000, loss: 0.015936
 >> iter 95000, loss: 0.016005
 >> iter 96000, loss: 0.015862
 >> iter 97000, loss: 0.015832
 >> iter 98000, loss: 0.015664
 >> iter 99000, loss: 0.015648
 >> iter 100000, loss: 0.015506
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 10.833429
 >> iter 2000, loss: 4.009852
 >> iter 3000, loss: 1.492308
 >> iter 4000, loss: 0.563737
 >> iter 5000, loss: 0.221711
 >> iter 6000, loss: 0.094756
 >> iter 7000, loss: 0.048128
 >> iter 8000, loss: 0.030428
 >> iter 9000, loss: 0.024186
 >> iter 10000, loss: 0.021503
   Number of active neurons: 6
 >> iter 11000, loss: 0.020863
 >> iter 12000, loss: 0.020282
 >> iter 13000, loss: 0.020419
 >> iter 14000, loss: 0.020115
 >> iter 15000, loss: 0.020453
 >> iter 16000, loss: 0.020120
 >> iter 17000, loss: 0.020467
 >> iter 18000, loss: 0.020147
 >> iter 19000, loss: 0.020495
 >> iter 20000, loss: 0.020192
   Number of active neurons: 6
 >> iter 21000, loss: 0.020516
 >> iter 22000, loss: 0.020215
 >> iter 23000, loss: 0.020522
 >> iter 24000, loss: 0.020199
 >> iter 25000, loss: 0.020512
 >> iter 26000, loss: 0.020182
 >> iter 27000, loss: 0.020495
 >> iter 28000, loss: 0.020146
 >> iter 29000, loss: 0.020433
 >> iter 30000, loss: 0.020071
   Number of active neurons: 4
 >> iter 31000, loss: 0.020251
 >> iter 32000, loss: 0.019737
 >> iter 33000, loss: 0.019791
 >> iter 34000, loss: 0.019290
 >> iter 35000, loss: 0.019267
 >> iter 36000, loss: 0.018739
 >> iter 37000, loss: 0.018656
 >> iter 38000, loss: 0.018135
 >> iter 39000, loss: 0.017999
 >> iter 40000, loss: 0.017549
   Number of active neurons: 4
 >> iter 41000, loss: 0.017471
 >> iter 42000, loss: 0.017087
 >> iter 43000, loss: 0.017044
 >> iter 44000, loss: 0.016699
 >> iter 45000, loss: 0.016686
 >> iter 46000, loss: 0.016388
 >> iter 47000, loss: 0.016432
 >> iter 48000, loss: 0.016195
 >> iter 49000, loss: 0.016307
 >> iter 50000, loss: 0.016104
   Number of active neurons: 4
 >> iter 51000, loss: 0.016241
 >> iter 52000, loss: 0.016083
 >> iter 53000, loss: 0.016210
 >> iter 54000, loss: 0.016083
 >> iter 55000, loss: 0.016208
 >> iter 56000, loss: 0.016083
 >> iter 57000, loss: 0.016200
 >> iter 58000, loss: 0.016080
 >> iter 59000, loss: 0.016194
 >> iter 60000, loss: 0.016073
   Number of active neurons: 3
 >> iter 61000, loss: 0.016170
 >> iter 62000, loss: 0.015932
 >> iter 63000, loss: 0.015941
 >> iter 64000, loss: 0.015723
 >> iter 65000, loss: 0.015734
 >> iter 66000, loss: 0.015538
 >> iter 67000, loss: 0.015538
 >> iter 68000, loss: 0.015296
 >> iter 69000, loss: 0.015206
 >> iter 70000, loss: 0.014963
   Number of active neurons: 3
 >> iter 71000, loss: 0.014861
 >> iter 72000, loss: 0.014614
 >> iter 73000, loss: 0.014495
 >> iter 74000, loss: 0.014206
 >> iter 75000, loss: 0.014048
 >> iter 76000, loss: 0.013789
 >> iter 77000, loss: 0.013688
 >> iter 78000, loss: 0.013490
 >> iter 79000, loss: 0.013442
 >> iter 80000, loss: 0.013281
   Number of active neurons: 3
 >> iter 81000, loss: 0.013270
 >> iter 82000, loss: 0.013133
 >> iter 83000, loss: 0.013142
 >> iter 84000, loss: 0.013026
 >> iter 85000, loss: 0.013035
 >> iter 86000, loss: 0.012933
 >> iter 87000, loss: 0.012949
 >> iter 88000, loss: 0.012868
 >> iter 89000, loss: 0.012883
 >> iter 90000, loss: 0.012803
   Number of active neurons: 3
 >> iter 91000, loss: 0.012818
 >> iter 92000, loss: 0.012753
 >> iter 93000, loss: 0.012772
 >> iter 94000, loss: 0.012705
 >> iter 95000, loss: 0.012732
 >> iter 96000, loss: 0.012664
 >> iter 97000, loss: 0.012693
 >> iter 98000, loss: 0.012625
 >> iter 99000, loss: 0.012658
 >> iter 100000, loss: 0.012598
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 10.876533
 >> iter 2000, loss: 4.026248
 >> iter 3000, loss: 1.498771
 >> iter 4000, loss: 0.566752
 >> iter 5000, loss: 0.223638
 >> iter 6000, loss: 0.096634
 >> iter 7000, loss: 0.050178
 >> iter 8000, loss: 0.032464
 >> iter 9000, loss: 0.026083
 >> iter 10000, loss: 0.023268
   Number of active neurons: 6
 >> iter 11000, loss: 0.022575
 >> iter 12000, loss: 0.021959
 >> iter 13000, loss: 0.022102
 >> iter 14000, loss: 0.021776
 >> iter 15000, loss: 0.022124
 >> iter 16000, loss: 0.021731
 >> iter 17000, loss: 0.022111
 >> iter 18000, loss: 0.021739
 >> iter 19000, loss: 0.022109
 >> iter 20000, loss: 0.021740
   Number of active neurons: 5
 >> iter 21000, loss: 0.022064
 >> iter 22000, loss: 0.021682
 >> iter 23000, loss: 0.021971
 >> iter 24000, loss: 0.021563
 >> iter 25000, loss: 0.021812
 >> iter 26000, loss: 0.021347
 >> iter 27000, loss: 0.021479
 >> iter 28000, loss: 0.020840
 >> iter 29000, loss: 0.020824
 >> iter 30000, loss: 0.020173
   Number of active neurons: 4
 >> iter 31000, loss: 0.020154
 >> iter 32000, loss: 0.019518
 >> iter 33000, loss: 0.019422
 >> iter 34000, loss: 0.018813
 >> iter 35000, loss: 0.018733
 >> iter 36000, loss: 0.018255
 >> iter 37000, loss: 0.018249
 >> iter 38000, loss: 0.017795
 >> iter 39000, loss: 0.017773
 >> iter 40000, loss: 0.017395
   Number of active neurons: 3
 >> iter 41000, loss: 0.017348
 >> iter 42000, loss: 0.016991
 >> iter 43000, loss: 0.016981
 >> iter 44000, loss: 0.016666
 >> iter 45000, loss: 0.016640
 >> iter 46000, loss: 0.016313
 >> iter 47000, loss: 0.016320
 >> iter 48000, loss: 0.016038
 >> iter 49000, loss: 0.016095
 >> iter 50000, loss: 0.015861
   Number of active neurons: 3
 >> iter 51000, loss: 0.015963
 >> iter 52000, loss: 0.015792
 >> iter 53000, loss: 0.015898
 >> iter 54000, loss: 0.015771
 >> iter 55000, loss: 0.015883
 >> iter 56000, loss: 0.015764
 >> iter 57000, loss: 0.015875
 >> iter 58000, loss: 0.015769
 >> iter 59000, loss: 0.015885
 >> iter 60000, loss: 0.015786
   Number of active neurons: 3
 >> iter 61000, loss: 0.015920
 >> iter 62000, loss: 0.015802
 >> iter 63000, loss: 0.015929
 >> iter 64000, loss: 0.015829
 >> iter 65000, loss: 0.015946
 >> iter 66000, loss: 0.015855
 >> iter 67000, loss: 0.015971
 >> iter 68000, loss: 0.015891
 >> iter 69000, loss: 0.015987
 >> iter 70000, loss: 0.015915
   Number of active neurons: 3
 >> iter 71000, loss: 0.016004
 >> iter 72000, loss: 0.015934
 >> iter 73000, loss: 0.016042
 >> iter 74000, loss: 0.015959
 >> iter 75000, loss: 0.016055
 >> iter 76000, loss: 0.015975
 >> iter 77000, loss: 0.016061
 >> iter 78000, loss: 0.015951
 >> iter 79000, loss: 0.015948
 >> iter 80000, loss: 0.015751
   Number of active neurons: 2
 >> iter 81000, loss: 0.015745
 >> iter 82000, loss: 0.015570
 >> iter 83000, loss: 0.015574
 >> iter 84000, loss: 0.015409
 >> iter 85000, loss: 0.015364
 >> iter 86000, loss: 0.015136
 >> iter 87000, loss: 0.015041
 >> iter 88000, loss: 0.014830
 >> iter 89000, loss: 0.014719
 >> iter 90000, loss: 0.014488
   Number of active neurons: 2
 >> iter 91000, loss: 0.014336
 >> iter 92000, loss: 0.014077
 >> iter 93000, loss: 0.013908
 >> iter 94000, loss: 0.013684
 >> iter 95000, loss: 0.013584
 >> iter 96000, loss: 0.013414
 >> iter 97000, loss: 0.013361
 >> iter 98000, loss: 0.013226
 >> iter 99000, loss: 0.013204
 >> iter 100000, loss: 0.013097
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 10.862758
 >> iter 2000, loss: 4.020939
 >> iter 3000, loss: 1.497505
 >> iter 4000, loss: 0.566852
 >> iter 5000, loss: 0.224093
 >> iter 6000, loss: 0.096761
 >> iter 7000, loss: 0.049714
 >> iter 8000, loss: 0.031539
 >> iter 9000, loss: 0.025006
 >> iter 10000, loss: 0.021925
   Number of active neurons: 5
 >> iter 11000, loss: 0.020913
 >> iter 12000, loss: 0.019908
 >> iter 13000, loss: 0.019738
 >> iter 14000, loss: 0.019078
 >> iter 15000, loss: 0.019106
 >> iter 16000, loss: 0.018442
 >> iter 17000, loss: 0.018517
 >> iter 18000, loss: 0.017960
 >> iter 19000, loss: 0.018037
 >> iter 20000, loss: 0.017496
   Number of active neurons: 4
 >> iter 21000, loss: 0.017570
 >> iter 22000, loss: 0.017113
 >> iter 23000, loss: 0.017212
 >> iter 24000, loss: 0.016792
 >> iter 25000, loss: 0.016913
 >> iter 26000, loss: 0.016480
 >> iter 27000, loss: 0.016578
 >> iter 28000, loss: 0.016148
 >> iter 29000, loss: 0.016255
 >> iter 30000, loss: 0.015861
   Number of active neurons: 4
 >> iter 31000, loss: 0.015979
 >> iter 32000, loss: 0.015658
 >> iter 33000, loss: 0.015815
 >> iter 34000, loss: 0.015547
 >> iter 35000, loss: 0.015701
 >> iter 36000, loss: 0.015481
 >> iter 37000, loss: 0.015654
 >> iter 38000, loss: 0.015459
 >> iter 39000, loss: 0.015627
 >> iter 40000, loss: 0.015473
   Number of active neurons: 4
 >> iter 41000, loss: 0.015619
 >> iter 42000, loss: 0.015464
 >> iter 43000, loss: 0.015616
 >> iter 44000, loss: 0.015483
 >> iter 45000, loss: 0.015627
 >> iter 46000, loss: 0.015488
 >> iter 47000, loss: 0.015639
 >> iter 48000, loss: 0.015492
 >> iter 49000, loss: 0.015638
 >> iter 50000, loss: 0.015475
   Number of active neurons: 4
 >> iter 51000, loss: 0.015620
 >> iter 52000, loss: 0.015488
 >> iter 53000, loss: 0.015618
 >> iter 54000, loss: 0.015516
 >> iter 55000, loss: 0.015643
 >> iter 56000, loss: 0.015541
 >> iter 57000, loss: 0.015662
 >> iter 58000, loss: 0.015570
 >> iter 59000, loss: 0.015693
 >> iter 60000, loss: 0.015605
   Number of active neurons: 4
 >> iter 61000, loss: 0.015744
 >> iter 62000, loss: 0.015636
 >> iter 63000, loss: 0.015767
 >> iter 64000, loss: 0.015675
 >> iter 65000, loss: 0.015797
 >> iter 66000, loss: 0.015713
 >> iter 67000, loss: 0.015832
 >> iter 68000, loss: 0.015759
 >> iter 69000, loss: 0.015859
 >> iter 70000, loss: 0.015793
   Number of active neurons: 4
 >> iter 71000, loss: 0.015886
 >> iter 72000, loss: 0.015823
 >> iter 73000, loss: 0.015936
 >> iter 74000, loss: 0.015861
 >> iter 75000, loss: 0.015965
 >> iter 76000, loss: 0.015894
 >> iter 77000, loss: 0.015991
 >> iter 78000, loss: 0.015913
 >> iter 79000, loss: 0.016007
 >> iter 80000, loss: 0.015916
   Number of active neurons: 3
 >> iter 81000, loss: 0.015981
 >> iter 82000, loss: 0.015794
 >> iter 83000, loss: 0.015785
 >> iter 84000, loss: 0.015611
 >> iter 85000, loss: 0.015606
 >> iter 86000, loss: 0.015451
 >> iter 87000, loss: 0.015442
 >> iter 88000, loss: 0.015267
 >> iter 89000, loss: 0.015173
 >> iter 90000, loss: 0.014958
   Number of active neurons: 3
 >> iter 91000, loss: 0.014853
 >> iter 92000, loss: 0.014649
 >> iter 93000, loss: 0.014520
 >> iter 94000, loss: 0.014281
 >> iter 95000, loss: 0.014113
 >> iter 96000, loss: 0.013852
 >> iter 97000, loss: 0.013722
 >> iter 98000, loss: 0.013522
 >> iter 99000, loss: 0.013452
 >> iter 100000, loss: 0.013306
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 10.900123
 >> iter 2000, loss: 4.036063
 >> iter 3000, loss: 1.503705
 >> iter 4000, loss: 0.569753
 >> iter 5000, loss: 0.225860
 >> iter 6000, loss: 0.098233
 >> iter 7000, loss: 0.051357
 >> iter 8000, loss: 0.033285
 >> iter 9000, loss: 0.026887
 >> iter 10000, loss: 0.023897
   Number of active neurons: 5
 >> iter 11000, loss: 0.023115
 >> iter 12000, loss: 0.022144
 >> iter 13000, loss: 0.021995
 >> iter 14000, loss: 0.021358
 >> iter 15000, loss: 0.021330
 >> iter 16000, loss: 0.020540
 >> iter 17000, loss: 0.020458
 >> iter 18000, loss: 0.019784
 >> iter 19000, loss: 0.019750
 >> iter 20000, loss: 0.019089
   Number of active neurons: 4
 >> iter 21000, loss: 0.019013
 >> iter 22000, loss: 0.018405
 >> iter 23000, loss: 0.018372
 >> iter 24000, loss: 0.017834
 >> iter 25000, loss: 0.017861
 >> iter 26000, loss: 0.017364
 >> iter 27000, loss: 0.017434
 >> iter 28000, loss: 0.016961
 >> iter 29000, loss: 0.017040
 >> iter 30000, loss: 0.016545
   Number of active neurons: 4
 >> iter 31000, loss: 0.016563
 >> iter 32000, loss: 0.016133
 >> iter 33000, loss: 0.016229
 >> iter 34000, loss: 0.015917
 >> iter 35000, loss: 0.016049
 >> iter 36000, loss: 0.015799
 >> iter 37000, loss: 0.015958
 >> iter 38000, loss: 0.015740
 >> iter 39000, loss: 0.015899
 >> iter 40000, loss: 0.015729
   Number of active neurons: 4
 >> iter 41000, loss: 0.015871
 >> iter 42000, loss: 0.015704
 >> iter 43000, loss: 0.015857
 >> iter 44000, loss: 0.015714
 >> iter 45000, loss: 0.015862
 >> iter 46000, loss: 0.015715
 >> iter 47000, loss: 0.015863
 >> iter 48000, loss: 0.015697
 >> iter 49000, loss: 0.015850
 >> iter 50000, loss: 0.015686
   Number of active neurons: 4
 >> iter 51000, loss: 0.015845
 >> iter 52000, loss: 0.015713
 >> iter 53000, loss: 0.015855
 >> iter 54000, loss: 0.015752
 >> iter 55000, loss: 0.015889
 >> iter 56000, loss: 0.015785
 >> iter 57000, loss: 0.015915
 >> iter 58000, loss: 0.015818
 >> iter 59000, loss: 0.015949
 >> iter 60000, loss: 0.015855
   Number of active neurons: 4
 >> iter 61000, loss: 0.016001
 >> iter 62000, loss: 0.015885
 >> iter 63000, loss: 0.016021
 >> iter 64000, loss: 0.015918
 >> iter 65000, loss: 0.016040
 >> iter 66000, loss: 0.015941
 >> iter 67000, loss: 0.016055
 >> iter 68000, loss: 0.015959
 >> iter 69000, loss: 0.016003
 >> iter 70000, loss: 0.015815
   Number of active neurons: 3
 >> iter 71000, loss: 0.015796
 >> iter 72000, loss: 0.015624
 >> iter 73000, loss: 0.015637
 >> iter 74000, loss: 0.015470
 >> iter 75000, loss: 0.015469
 >> iter 76000, loss: 0.015260
 >> iter 77000, loss: 0.015176
 >> iter 78000, loss: 0.014943
 >> iter 79000, loss: 0.014854
 >> iter 80000, loss: 0.014611
   Number of active neurons: 3
 >> iter 81000, loss: 0.014502
 >> iter 82000, loss: 0.014227
 >> iter 83000, loss: 0.014074
 >> iter 84000, loss: 0.013805
 >> iter 85000, loss: 0.013690
 >> iter 86000, loss: 0.013490
 >> iter 87000, loss: 0.013429
 >> iter 88000, loss: 0.013287
 >> iter 89000, loss: 0.013253
 >> iter 90000, loss: 0.013134
   Number of active neurons: 3
 >> iter 91000, loss: 0.013117
 >> iter 92000, loss: 0.013025
 >> iter 93000, loss: 0.013021
 >> iter 94000, loss: 0.012934
 >> iter 95000, loss: 0.012945
 >> iter 96000, loss: 0.012861
 >> iter 97000, loss: 0.012877
 >> iter 98000, loss: 0.012796
 >> iter 99000, loss: 0.012819
 >> iter 100000, loss: 0.012747
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455178
   Number of active neurons: 0
 >> iter 1000, loss: 10.876877
 >> iter 2000, loss: 4.025039
 >> iter 3000, loss: 1.498156
 >> iter 4000, loss: 0.566482
 >> iter 5000, loss: 0.223707
 >> iter 6000, loss: 0.096949
 >> iter 7000, loss: 0.050675
 >> iter 8000, loss: 0.033101
 >> iter 9000, loss: 0.026795
 >> iter 10000, loss: 0.023810
   Number of active neurons: 3
 >> iter 11000, loss: 0.022810
 >> iter 12000, loss: 0.021630
 >> iter 13000, loss: 0.021132
 >> iter 14000, loss: 0.020188
 >> iter 15000, loss: 0.019873
 >> iter 16000, loss: 0.018881
 >> iter 17000, loss: 0.018561
 >> iter 18000, loss: 0.017757
 >> iter 19000, loss: 0.017664
 >> iter 20000, loss: 0.017075
   Number of active neurons: 3
 >> iter 21000, loss: 0.017091
 >> iter 22000, loss: 0.016564
 >> iter 23000, loss: 0.016603
 >> iter 24000, loss: 0.016131
 >> iter 25000, loss: 0.016259
 >> iter 26000, loss: 0.015862
 >> iter 27000, loss: 0.016055
 >> iter 28000, loss: 0.015697
 >> iter 29000, loss: 0.015914
 >> iter 30000, loss: 0.015552
   Number of active neurons: 3
 >> iter 31000, loss: 0.015690
 >> iter 32000, loss: 0.015367
 >> iter 33000, loss: 0.015522
 >> iter 34000, loss: 0.015269
 >> iter 35000, loss: 0.015414
 >> iter 36000, loss: 0.015197
 >> iter 37000, loss: 0.015347
 >> iter 38000, loss: 0.015152
 >> iter 39000, loss: 0.015293
 >> iter 40000, loss: 0.015141
   Number of active neurons: 3
 >> iter 41000, loss: 0.015257
 >> iter 42000, loss: 0.015107
 >> iter 43000, loss: 0.015227
 >> iter 44000, loss: 0.015102
 >> iter 45000, loss: 0.015211
 >> iter 46000, loss: 0.015082
 >> iter 47000, loss: 0.015196
 >> iter 48000, loss: 0.015069
 >> iter 49000, loss: 0.015187
 >> iter 50000, loss: 0.015056
   Number of active neurons: 3
 >> iter 51000, loss: 0.015163
 >> iter 52000, loss: 0.015038
 >> iter 53000, loss: 0.015114
 >> iter 54000, loss: 0.015019
 >> iter 55000, loss: 0.015098
 >> iter 56000, loss: 0.015004
 >> iter 57000, loss: 0.015082
 >> iter 58000, loss: 0.014999
 >> iter 59000, loss: 0.015078
 >> iter 60000, loss: 0.014998
   Number of active neurons: 3
 >> iter 61000, loss: 0.015093
 >> iter 62000, loss: 0.014996
 >> iter 63000, loss: 0.015080
 >> iter 64000, loss: 0.014997
 >> iter 65000, loss: 0.015073
 >> iter 66000, loss: 0.014998
 >> iter 67000, loss: 0.015069
 >> iter 68000, loss: 0.015006
 >> iter 69000, loss: 0.015057
 >> iter 70000, loss: 0.015002
   Number of active neurons: 3
 >> iter 71000, loss: 0.015046
 >> iter 72000, loss: 0.014995
 >> iter 73000, loss: 0.015055
 >> iter 74000, loss: 0.014996
 >> iter 75000, loss: 0.015049
 >> iter 76000, loss: 0.014997
 >> iter 77000, loss: 0.015045
 >> iter 78000, loss: 0.014991
 >> iter 79000, loss: 0.015042
 >> iter 80000, loss: 0.014981
   Number of active neurons: 3
 >> iter 81000, loss: 0.015038
 >> iter 82000, loss: 0.014977
 >> iter 83000, loss: 0.015039
 >> iter 84000, loss: 0.014980
 >> iter 85000, loss: 0.015030
 >> iter 86000, loss: 0.014976
 >> iter 87000, loss: 0.015023
 >> iter 88000, loss: 0.014992
 >> iter 89000, loss: 0.015025
 >> iter 90000, loss: 0.014991
   Number of active neurons: 3
 >> iter 91000, loss: 0.015017
 >> iter 92000, loss: 0.014997
 >> iter 93000, loss: 0.015030
 >> iter 94000, loss: 0.014997
 >> iter 95000, loss: 0.015036
 >> iter 96000, loss: 0.015001
 >> iter 97000, loss: 0.015038
 >> iter 98000, loss: 0.015000
 >> iter 99000, loss: 0.015043
 >> iter 100000, loss: 0.015011
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

