 > Problema: tomita3nueva
 > Args:
   - Hidden size: 14
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.298646
 >> iter 2000, loss: 11.842532
 >> iter 3000, loss: 5.553883
 >> iter 4000, loss: 2.645634
 >> iter 5000, loss: 1.657803
 >> iter 6000, loss: 0.971108
 >> iter 7000, loss: 0.898171
 >> iter 8000, loss: 0.799661
 >> iter 9000, loss: 0.599556
 >> iter 10000, loss: 0.446505
   Number of active neurons: 8
 >> iter 11000, loss: 0.385509
 >> iter 12000, loss: 0.436922
 >> iter 13000, loss: 0.368103
 >> iter 14000, loss: 0.429306
 >> iter 15000, loss: 0.475410
 >> iter 16000, loss: 0.367553
 >> iter 17000, loss: 0.431122
 >> iter 18000, loss: 0.435042
 >> iter 19000, loss: 0.537065
 >> iter 20000, loss: 0.335514
   Number of active neurons: 8
 >> iter 21000, loss: 0.310803
 >> iter 22000, loss: 0.342088
 >> iter 23000, loss: 0.367686
 >> iter 24000, loss: 0.465803
 >> iter 25000, loss: 0.542996
 >> iter 26000, loss: 0.368382
 >> iter 27000, loss: 0.360020
 >> iter 28000, loss: 0.305109
 >> iter 29000, loss: 0.487163
 >> iter 30000, loss: 0.419981
   Number of active neurons: 7
 >> iter 31000, loss: 0.281150
 >> iter 32000, loss: 0.339267
 >> iter 33000, loss: 0.354279
 >> iter 34000, loss: 0.323600
 >> iter 35000, loss: 0.384980
 >> iter 36000, loss: 0.393889
 >> iter 37000, loss: 0.290397
 >> iter 38000, loss: 0.378711
 >> iter 39000, loss: 0.516171
 >> iter 40000, loss: 0.323131
   Number of active neurons: 7
 >> iter 41000, loss: 0.401045
 >> iter 42000, loss: 0.409631
 >> iter 43000, loss: 0.331745
 >> iter 44000, loss: 0.325303
 >> iter 45000, loss: 0.380714
 >> iter 46000, loss: 0.304172
 >> iter 47000, loss: 0.394265
 >> iter 48000, loss: 0.370074
 >> iter 49000, loss: 0.401645
 >> iter 50000, loss: 0.505957
   Number of active neurons: 7
 >> iter 51000, loss: 0.418656
 >> iter 52000, loss: 0.450332
 >> iter 53000, loss: 0.368924
 >> iter 54000, loss: 0.345991
 >> iter 55000, loss: 0.370698
 >> iter 56000, loss: 0.279505
 >> iter 57000, loss: 0.484105
 >> iter 58000, loss: 0.377418
 >> iter 59000, loss: 0.429697
 >> iter 60000, loss: 0.423216
   Number of active neurons: 7
 >> iter 61000, loss: 0.378229
 >> iter 62000, loss: 0.389537
 >> iter 63000, loss: 0.399348
 >> iter 64000, loss: 0.270660
 >> iter 65000, loss: 0.325339
 >> iter 66000, loss: 0.365654
 >> iter 67000, loss: 0.270202
 >> iter 68000, loss: 0.183434
 >> iter 69000, loss: 0.324894
 >> iter 70000, loss: 0.191685
   Number of active neurons: 7
 >> iter 71000, loss: 0.211816
 >> iter 72000, loss: 0.260799
 >> iter 73000, loss: 0.312423
 >> iter 74000, loss: 0.266471
 >> iter 75000, loss: 0.429630
 >> iter 76000, loss: 0.330093
 >> iter 77000, loss: 0.290203
 >> iter 78000, loss: 0.278641
 >> iter 79000, loss: 0.358362
 >> iter 80000, loss: 0.263229
   Number of active neurons: 7
 >> iter 81000, loss: 0.257921
 >> iter 82000, loss: 0.244432
 >> iter 83000, loss: 0.258408
 >> iter 84000, loss: 0.256904
 >> iter 85000, loss: 0.335302
 >> iter 86000, loss: 0.269108
 >> iter 87000, loss: 0.283992
 >> iter 88000, loss: 0.215344
 >> iter 89000, loss: 0.255459
 >> iter 90000, loss: 0.203350
   Number of active neurons: 6
 >> iter 91000, loss: 0.214718
 >> iter 92000, loss: 0.262922
 >> iter 93000, loss: 0.255245
 >> iter 94000, loss: 0.319222
 >> iter 95000, loss: 0.290095
 >> iter 96000, loss: 0.230147
 >> iter 97000, loss: 0.149913
 >> iter 98000, loss: 0.158716
 >> iter 99000, loss: 0.290535
 >> iter 100000, loss: 0.373588
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.126420
 >> iter 2000, loss: 13.191848
 >> iter 3000, loss: 6.367161
 >> iter 4000, loss: 3.102842
 >> iter 5000, loss: 1.499300
 >> iter 6000, loss: 0.809250
 >> iter 7000, loss: 0.582058
 >> iter 8000, loss: 0.416599
 >> iter 9000, loss: 0.527802
 >> iter 10000, loss: 0.442441
   Number of active neurons: 7
 >> iter 11000, loss: 0.293793
 >> iter 12000, loss: 0.208080
 >> iter 13000, loss: 0.191714
 >> iter 14000, loss: 0.404564
 >> iter 15000, loss: 0.390727
 >> iter 16000, loss: 0.303557
 >> iter 17000, loss: 0.233977
 >> iter 18000, loss: 0.336804
 >> iter 19000, loss: 0.355781
 >> iter 20000, loss: 0.310232
   Number of active neurons: 7
 >> iter 21000, loss: 0.238575
 >> iter 22000, loss: 0.325109
 >> iter 23000, loss: 0.366795
 >> iter 24000, loss: 0.354781
 >> iter 25000, loss: 0.322720
 >> iter 26000, loss: 0.335982
 >> iter 27000, loss: 0.253060
 >> iter 28000, loss: 0.300092
 >> iter 29000, loss: 0.323293
 >> iter 30000, loss: 0.397660
   Number of active neurons: 7
 >> iter 31000, loss: 0.367077
 >> iter 32000, loss: 0.243030
 >> iter 33000, loss: 0.222161
 >> iter 34000, loss: 0.239550
 >> iter 35000, loss: 0.420928
 >> iter 36000, loss: 0.259979
 >> iter 37000, loss: 0.316415
 >> iter 38000, loss: 0.287387
 >> iter 39000, loss: 0.347977
 >> iter 40000, loss: 0.207344
   Number of active neurons: 7
 >> iter 41000, loss: 0.198518
 >> iter 42000, loss: 0.218947
 >> iter 43000, loss: 0.144298
 >> iter 44000, loss: 0.264883
 >> iter 45000, loss: 0.299780
 >> iter 46000, loss: 0.248322
 >> iter 47000, loss: 0.214104
 >> iter 48000, loss: 0.191094
 >> iter 49000, loss: 0.206339
 >> iter 50000, loss: 0.155584
   Number of active neurons: 6
 >> iter 51000, loss: 0.280868
 >> iter 52000, loss: 0.236422
 >> iter 53000, loss: 0.173328
 >> iter 54000, loss: 0.259734
 >> iter 55000, loss: 0.192089
 >> iter 56000, loss: 0.223599
 >> iter 57000, loss: 0.161146
 >> iter 58000, loss: 0.185465
 >> iter 59000, loss: 0.244991
 >> iter 60000, loss: 0.183589
   Number of active neurons: 6
 >> iter 61000, loss: 0.328428
 >> iter 62000, loss: 0.340366
 >> iter 63000, loss: 0.221023
 >> iter 64000, loss: 0.272849
 >> iter 65000, loss: 0.297445
 >> iter 66000, loss: 0.212157
 >> iter 67000, loss: 0.139219
 >> iter 68000, loss: 0.181156
 >> iter 69000, loss: 0.271863
 >> iter 70000, loss: 0.331283
   Number of active neurons: 5
 >> iter 71000, loss: 0.175315
 >> iter 72000, loss: 0.253162
 >> iter 73000, loss: 0.284843
 >> iter 74000, loss: 0.288656
 >> iter 75000, loss: 0.242171
 >> iter 76000, loss: 0.314889
 >> iter 77000, loss: 0.272035
 >> iter 78000, loss: 0.326530
 >> iter 79000, loss: 0.281545
 >> iter 80000, loss: 0.275589
   Number of active neurons: 5
 >> iter 81000, loss: 0.245092
 >> iter 82000, loss: 0.199868
 >> iter 83000, loss: 0.191765
 >> iter 84000, loss: 0.130957
 >> iter 85000, loss: 0.132464
 >> iter 86000, loss: 0.273430
 >> iter 87000, loss: 0.206883
 >> iter 88000, loss: 0.278393
 >> iter 89000, loss: 0.207970
 >> iter 90000, loss: 0.200618
   Number of active neurons: 5
 >> iter 91000, loss: 0.439152
 >> iter 92000, loss: 0.291151
 >> iter 93000, loss: 0.311792
 >> iter 94000, loss: 0.230834
 >> iter 95000, loss: 0.162431
 >> iter 96000, loss: 0.144333
 >> iter 97000, loss: 0.192214
 >> iter 98000, loss: 0.155983
 >> iter 99000, loss: 0.369499
 >> iter 100000, loss: 0.245229
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.899839
 >> iter 2000, loss: 10.161440
 >> iter 3000, loss: 4.245864
 >> iter 4000, loss: 2.132435
 >> iter 5000, loss: 1.388270
 >> iter 6000, loss: 0.714190
 >> iter 7000, loss: 0.685696
 >> iter 8000, loss: 0.555465
 >> iter 9000, loss: 0.472974
 >> iter 10000, loss: 0.402430
   Number of active neurons: 9
 >> iter 11000, loss: 0.254182
 >> iter 12000, loss: 0.432067
 >> iter 13000, loss: 0.590712
 >> iter 14000, loss: 0.418418
 >> iter 15000, loss: 0.399963
 >> iter 16000, loss: 0.363918
 >> iter 17000, loss: 0.369373
 >> iter 18000, loss: 0.364178
 >> iter 19000, loss: 0.490719
 >> iter 20000, loss: 0.263269
   Number of active neurons: 8
 >> iter 21000, loss: 0.350985
 >> iter 22000, loss: 0.367837
 >> iter 23000, loss: 0.258744
 >> iter 24000, loss: 0.251371
 >> iter 25000, loss: 0.540972
 >> iter 26000, loss: 0.417237
 >> iter 27000, loss: 0.332412
 >> iter 28000, loss: 0.327022
 >> iter 29000, loss: 0.409344
 >> iter 30000, loss: 0.265365
   Number of active neurons: 8
 >> iter 31000, loss: 0.256841
 >> iter 32000, loss: 0.368357
 >> iter 33000, loss: 0.316619
 >> iter 34000, loss: 0.286892
 >> iter 35000, loss: 0.361972
 >> iter 36000, loss: 0.280582
 >> iter 37000, loss: 0.302061
 >> iter 38000, loss: 0.344200
 >> iter 39000, loss: 0.343972
 >> iter 40000, loss: 0.270635
   Number of active neurons: 8
 >> iter 41000, loss: 0.377031
 >> iter 42000, loss: 0.408278
 >> iter 43000, loss: 0.457836
 >> iter 44000, loss: 0.331639
 >> iter 45000, loss: 0.346052
 >> iter 46000, loss: 0.366659
 >> iter 47000, loss: 0.372045
 >> iter 48000, loss: 0.301907
 >> iter 49000, loss: 0.297453
 >> iter 50000, loss: 0.215811
   Number of active neurons: 8
 >> iter 51000, loss: 0.294327
 >> iter 52000, loss: 0.378038
 >> iter 53000, loss: 0.309535
 >> iter 54000, loss: 0.336850
 >> iter 55000, loss: 0.414508
 >> iter 56000, loss: 0.398656
 >> iter 57000, loss: 0.332045
 >> iter 58000, loss: 0.389647
 >> iter 59000, loss: 0.385193
 >> iter 60000, loss: 0.245192
   Number of active neurons: 7
 >> iter 61000, loss: 0.272194
 >> iter 62000, loss: 0.446373
 >> iter 63000, loss: 0.290310
 >> iter 64000, loss: 0.159768
 >> iter 65000, loss: 0.188902
 >> iter 66000, loss: 0.297076
 >> iter 67000, loss: 0.359912
 >> iter 68000, loss: 0.334517
 >> iter 69000, loss: 0.399994
 >> iter 70000, loss: 0.414241
   Number of active neurons: 6
 >> iter 71000, loss: 0.361576
 >> iter 72000, loss: 0.387099
 >> iter 73000, loss: 0.373720
 >> iter 74000, loss: 0.228697
 >> iter 75000, loss: 0.248549
 >> iter 76000, loss: 0.208729
 >> iter 77000, loss: 0.396408
 >> iter 78000, loss: 0.336921
 >> iter 79000, loss: 0.314808
 >> iter 80000, loss: 0.295326
   Number of active neurons: 6
 >> iter 81000, loss: 0.306711
 >> iter 82000, loss: 0.350615
 >> iter 83000, loss: 0.351350
 >> iter 84000, loss: 0.374965
 >> iter 85000, loss: 0.282824
 >> iter 86000, loss: 0.320994
 >> iter 87000, loss: 0.316375
 >> iter 88000, loss: 0.335916
 >> iter 89000, loss: 0.299533
 >> iter 90000, loss: 0.271517
   Number of active neurons: 6
 >> iter 91000, loss: 0.274755
 >> iter 92000, loss: 0.223863
 >> iter 93000, loss: 0.370079
 >> iter 94000, loss: 0.373575
 >> iter 95000, loss: 0.409828
 >> iter 96000, loss: 0.276285
 >> iter 97000, loss: 0.304490
 >> iter 98000, loss: 0.311320
 >> iter 99000, loss: 0.309653
 >> iter 100000, loss: 0.383287
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.919990
 >> iter 2000, loss: 11.160391
 >> iter 3000, loss: 4.899224
 >> iter 4000, loss: 2.113595
 >> iter 5000, loss: 1.091544
 >> iter 6000, loss: 0.585974
 >> iter 7000, loss: 0.304579
 >> iter 8000, loss: 0.370581
 >> iter 9000, loss: 0.373576
 >> iter 10000, loss: 0.351501
   Number of active neurons: 8
 >> iter 11000, loss: 0.278176
 >> iter 12000, loss: 0.303770
 >> iter 13000, loss: 0.218796
 >> iter 14000, loss: 0.297942
 >> iter 15000, loss: 0.208879
 >> iter 16000, loss: 0.246248
 >> iter 17000, loss: 0.339144
 >> iter 18000, loss: 0.325096
 >> iter 19000, loss: 0.388427
 >> iter 20000, loss: 0.253859
   Number of active neurons: 8
 >> iter 21000, loss: 0.181419
 >> iter 22000, loss: 0.265128
 >> iter 23000, loss: 0.221851
 >> iter 24000, loss: 0.312598
 >> iter 25000, loss: 0.336531
 >> iter 26000, loss: 0.246660
 >> iter 27000, loss: 0.232921
 >> iter 28000, loss: 0.212347
 >> iter 29000, loss: 0.248611
 >> iter 30000, loss: 0.274253
   Number of active neurons: 8
 >> iter 31000, loss: 0.267119
 >> iter 32000, loss: 0.230377
 >> iter 33000, loss: 0.258735
 >> iter 34000, loss: 0.183754
 >> iter 35000, loss: 0.183807
 >> iter 36000, loss: 0.278052
 >> iter 37000, loss: 0.186464
 >> iter 38000, loss: 0.181722
 >> iter 39000, loss: 0.152382
 >> iter 40000, loss: 0.257888
   Number of active neurons: 7
 >> iter 41000, loss: 0.256445
 >> iter 42000, loss: 0.184837
 >> iter 43000, loss: 0.208169
 >> iter 44000, loss: 0.160685
 >> iter 45000, loss: 0.255149
 >> iter 46000, loss: 0.276379
 >> iter 47000, loss: 0.252582
 >> iter 48000, loss: 0.242390
 >> iter 49000, loss: 0.274745
 >> iter 50000, loss: 0.180671
   Number of active neurons: 6
 >> iter 51000, loss: 0.148054
 >> iter 52000, loss: 0.213708
 >> iter 53000, loss: 0.151467
 >> iter 54000, loss: 0.223978
 >> iter 55000, loss: 0.225383
 >> iter 56000, loss: 0.166142
 >> iter 57000, loss: 0.172811
 >> iter 58000, loss: 0.213506
 >> iter 59000, loss: 0.200806
 >> iter 60000, loss: 0.192819
   Number of active neurons: 6
 >> iter 61000, loss: 0.339245
 >> iter 62000, loss: 0.320425
 >> iter 63000, loss: 0.242643
 >> iter 64000, loss: 0.212971
 >> iter 65000, loss: 0.282722
 >> iter 66000, loss: 0.364466
 >> iter 67000, loss: 0.226854
 >> iter 68000, loss: 0.321966
 >> iter 69000, loss: 0.221225
 >> iter 70000, loss: 0.273744
   Number of active neurons: 6
 >> iter 71000, loss: 0.158565
 >> iter 72000, loss: 0.106382
 >> iter 73000, loss: 0.168519
 >> iter 74000, loss: 0.344653
 >> iter 75000, loss: 0.223949
 >> iter 76000, loss: 0.133329
 >> iter 77000, loss: 0.152402
 >> iter 78000, loss: 0.185000
 >> iter 79000, loss: 0.242466
 >> iter 80000, loss: 0.208815
   Number of active neurons: 6
 >> iter 81000, loss: 0.374211
 >> iter 82000, loss: 0.287797
 >> iter 83000, loss: 0.337593
 >> iter 84000, loss: 0.243085
 >> iter 85000, loss: 0.204687
 >> iter 86000, loss: 0.131797
 >> iter 87000, loss: 0.266957
 >> iter 88000, loss: 0.208463
 >> iter 89000, loss: 0.249858
 >> iter 90000, loss: 0.161072
   Number of active neurons: 6
 >> iter 91000, loss: 0.241602
 >> iter 92000, loss: 0.181814
 >> iter 93000, loss: 0.194249
 >> iter 94000, loss: 0.195920
 >> iter 95000, loss: 0.212907
 >> iter 96000, loss: 0.176064
 >> iter 97000, loss: 0.271204
 >> iter 98000, loss: 0.169688
 >> iter 99000, loss: 0.416543
 >> iter 100000, loss: 0.223893
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.001121
 >> iter 2000, loss: 11.767356
 >> iter 3000, loss: 5.894864
 >> iter 4000, loss: 3.074390
 >> iter 5000, loss: 1.801222
 >> iter 6000, loss: 1.207861
 >> iter 7000, loss: 0.983488
 >> iter 8000, loss: 0.798070
 >> iter 9000, loss: 0.651494
 >> iter 10000, loss: 0.699540
   Number of active neurons: 6
 >> iter 11000, loss: 0.752733
 >> iter 12000, loss: 0.659517
 >> iter 13000, loss: 0.573390
 >> iter 14000, loss: 0.576180
 >> iter 15000, loss: 0.608298
 >> iter 16000, loss: 0.563526
 >> iter 17000, loss: 0.585698
 >> iter 18000, loss: 0.399974
 >> iter 19000, loss: 0.530998
 >> iter 20000, loss: 0.532734
   Number of active neurons: 6
 >> iter 21000, loss: 0.582200
 >> iter 22000, loss: 0.626803
 >> iter 23000, loss: 0.618148
 >> iter 24000, loss: 0.672613
 >> iter 25000, loss: 0.546188
 >> iter 26000, loss: 0.366899
 >> iter 27000, loss: 0.387757
 >> iter 28000, loss: 0.445278
 >> iter 29000, loss: 0.442699
 >> iter 30000, loss: 0.481981
   Number of active neurons: 6
 >> iter 31000, loss: 0.381852
 >> iter 32000, loss: 0.377767
 >> iter 33000, loss: 0.428594
 >> iter 34000, loss: 0.481373
 >> iter 35000, loss: 0.632834
 >> iter 36000, loss: 0.444696
 >> iter 37000, loss: 0.560568
 >> iter 38000, loss: 0.451652
 >> iter 39000, loss: 0.543803
 >> iter 40000, loss: 0.407785
   Number of active neurons: 6
 >> iter 41000, loss: 0.292629
 >> iter 42000, loss: 0.303442
 >> iter 43000, loss: 0.321290
 >> iter 44000, loss: 0.412291
 >> iter 45000, loss: 0.555714
 >> iter 46000, loss: 0.324455
 >> iter 47000, loss: 0.364294
 >> iter 48000, loss: 0.464401
 >> iter 49000, loss: 0.526315
 >> iter 50000, loss: 0.508118
   Number of active neurons: 6
 >> iter 51000, loss: 0.547360
 >> iter 52000, loss: 0.603738
 >> iter 53000, loss: 0.460915
 >> iter 54000, loss: 0.610985
 >> iter 55000, loss: 0.562983
 >> iter 56000, loss: 0.460896
 >> iter 57000, loss: 0.572196
 >> iter 58000, loss: 0.327980
 >> iter 59000, loss: 0.594699
 >> iter 60000, loss: 0.493740
   Number of active neurons: 6
 >> iter 61000, loss: 0.508276
 >> iter 62000, loss: 0.379605
 >> iter 63000, loss: 0.418352
 >> iter 64000, loss: 0.391192
 >> iter 65000, loss: 0.338808
 >> iter 66000, loss: 0.314920
 >> iter 67000, loss: 0.451762
 >> iter 68000, loss: 0.465126
 >> iter 69000, loss: 0.350790
 >> iter 70000, loss: 0.375143
   Number of active neurons: 6
 >> iter 71000, loss: 0.472190
 >> iter 72000, loss: 0.341817
 >> iter 73000, loss: 0.284814
 >> iter 74000, loss: 0.443187
 >> iter 75000, loss: 0.549491
 >> iter 76000, loss: 0.476909
 >> iter 77000, loss: 0.522035
 >> iter 78000, loss: 0.506351
 >> iter 79000, loss: 0.427480
 >> iter 80000, loss: 0.448022
   Number of active neurons: 6
 >> iter 81000, loss: 0.444556
 >> iter 82000, loss: 0.460196
 >> iter 83000, loss: 0.482219
 >> iter 84000, loss: 0.499465
 >> iter 85000, loss: 0.460616
 >> iter 86000, loss: 0.366070
 >> iter 87000, loss: 0.429395
 >> iter 88000, loss: 0.241398
 >> iter 89000, loss: 0.546043
 >> iter 90000, loss: 0.343232
   Number of active neurons: 6
 >> iter 91000, loss: 0.516499
 >> iter 92000, loss: 0.441082
 >> iter 93000, loss: 0.318510
 >> iter 94000, loss: 0.263754
 >> iter 95000, loss: 0.354895
 >> iter 96000, loss: 0.393531
 >> iter 97000, loss: 0.409392
 >> iter 98000, loss: 0.412085
 >> iter 99000, loss: 0.492579
 >> iter 100000, loss: 0.511316
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455166
   Number of active neurons: 0
 >> iter 1000, loss: 18.960724
 >> iter 2000, loss: 11.333612
 >> iter 3000, loss: 5.424115
 >> iter 4000, loss: 2.781421
 >> iter 5000, loss: 1.567129
 >> iter 6000, loss: 1.189937
 >> iter 7000, loss: 0.657250
 >> iter 8000, loss: 0.533138
 >> iter 9000, loss: 0.607790
 >> iter 10000, loss: 0.415335
   Number of active neurons: 7
 >> iter 11000, loss: 0.474186
 >> iter 12000, loss: 0.339119
 >> iter 13000, loss: 0.378681
 >> iter 14000, loss: 0.476825
 >> iter 15000, loss: 0.414832
 >> iter 16000, loss: 0.351650
 >> iter 17000, loss: 0.241188
 >> iter 18000, loss: 0.336581
 >> iter 19000, loss: 0.304471
 >> iter 20000, loss: 0.355673
   Number of active neurons: 7
 >> iter 21000, loss: 0.385232
 >> iter 22000, loss: 0.549994
 >> iter 23000, loss: 0.480926
 >> iter 24000, loss: 0.504559
 >> iter 25000, loss: 0.424327
 >> iter 26000, loss: 0.260139
 >> iter 27000, loss: 0.458201
 >> iter 28000, loss: 0.395463
 >> iter 29000, loss: 0.269130
 >> iter 30000, loss: 0.443942
   Number of active neurons: 7
 >> iter 31000, loss: 0.299473
 >> iter 32000, loss: 0.480364
 >> iter 33000, loss: 0.303888
 >> iter 34000, loss: 0.372849
 >> iter 35000, loss: 0.504735
 >> iter 36000, loss: 0.344394
 >> iter 37000, loss: 0.290594
 >> iter 38000, loss: 0.319521
 >> iter 39000, loss: 0.305698
 >> iter 40000, loss: 0.375938
   Number of active neurons: 7
 >> iter 41000, loss: 0.555815
 >> iter 42000, loss: 0.467011
 >> iter 43000, loss: 0.354483
 >> iter 44000, loss: 0.322805
 >> iter 45000, loss: 0.454064
 >> iter 46000, loss: 0.402922
 >> iter 47000, loss: 0.324589
 >> iter 48000, loss: 0.320988
 >> iter 49000, loss: 0.340850
 >> iter 50000, loss: 0.338085
   Number of active neurons: 7
 >> iter 51000, loss: 0.416297
 >> iter 52000, loss: 0.299641
 >> iter 53000, loss: 0.484199
 >> iter 54000, loss: 0.358041
 >> iter 55000, loss: 0.276174
 >> iter 56000, loss: 0.322688
 >> iter 57000, loss: 0.288449
 >> iter 58000, loss: 0.209922
 >> iter 59000, loss: 0.250075
 >> iter 60000, loss: 0.432330
   Number of active neurons: 7
 >> iter 61000, loss: 0.590852
 >> iter 62000, loss: 0.503156
 >> iter 63000, loss: 0.358670
 >> iter 64000, loss: 0.261237
 >> iter 65000, loss: 0.272766
 >> iter 66000, loss: 0.421897
 >> iter 67000, loss: 0.488874
 >> iter 68000, loss: 0.285947
 >> iter 69000, loss: 0.368662
 >> iter 70000, loss: 0.357654
   Number of active neurons: 7
 >> iter 71000, loss: 0.239759
 >> iter 72000, loss: 0.382117
 >> iter 73000, loss: 0.472093
 >> iter 74000, loss: 0.335765
 >> iter 75000, loss: 0.380824
 >> iter 76000, loss: 0.388811
 >> iter 77000, loss: 0.258116
 >> iter 78000, loss: 0.331790
 >> iter 79000, loss: 0.216276
 >> iter 80000, loss: 0.176278
   Number of active neurons: 7
 >> iter 81000, loss: 0.141406
 >> iter 82000, loss: 0.176916
 >> iter 83000, loss: 0.112229
 >> iter 84000, loss: 0.212677
 >> iter 85000, loss: 0.177700
 >> iter 86000, loss: 0.228869
 >> iter 87000, loss: 0.151278
 >> iter 88000, loss: 0.178657
 >> iter 89000, loss: 0.318280
 >> iter 90000, loss: 0.214733
   Number of active neurons: 7
 >> iter 91000, loss: 0.137824
 >> iter 92000, loss: 0.154746
 >> iter 93000, loss: 0.151235
 >> iter 94000, loss: 0.210131
 >> iter 95000, loss: 0.397378
 >> iter 96000, loss: 0.302605
 >> iter 97000, loss: 0.353481
 >> iter 98000, loss: 0.200059
 >> iter 99000, loss: 0.238461
 >> iter 100000, loss: 0.215127
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.167450
 >> iter 2000, loss: 12.866769
 >> iter 3000, loss: 5.820992
 >> iter 4000, loss: 2.517530
 >> iter 5000, loss: 1.523656
 >> iter 6000, loss: 0.722915
 >> iter 7000, loss: 0.653210
 >> iter 8000, loss: 0.424829
 >> iter 9000, loss: 0.468795
 >> iter 10000, loss: 0.506180
   Number of active neurons: 9
 >> iter 11000, loss: 0.499453
 >> iter 12000, loss: 0.468665
 >> iter 13000, loss: 0.566543
 >> iter 14000, loss: 0.362200
 >> iter 15000, loss: 0.265557
 >> iter 16000, loss: 0.336725
 >> iter 17000, loss: 0.296661
 >> iter 18000, loss: 0.269010
 >> iter 19000, loss: 0.356884
 >> iter 20000, loss: 0.288070
   Number of active neurons: 9
 >> iter 21000, loss: 0.166685
 >> iter 22000, loss: 0.162292
 >> iter 23000, loss: 0.287207
 >> iter 24000, loss: 0.303062
 >> iter 25000, loss: 0.288500
 >> iter 26000, loss: 0.220757
 >> iter 27000, loss: 0.250977
 >> iter 28000, loss: 0.319763
 >> iter 29000, loss: 0.209876
 >> iter 30000, loss: 0.296415
   Number of active neurons: 9
 >> iter 31000, loss: 0.217705
 >> iter 32000, loss: 0.323868
 >> iter 33000, loss: 0.338880
 >> iter 34000, loss: 0.332689
 >> iter 35000, loss: 0.389350
 >> iter 36000, loss: 0.288543
 >> iter 37000, loss: 0.276808
 >> iter 38000, loss: 0.145167
 >> iter 39000, loss: 0.193117
 >> iter 40000, loss: 0.178108
   Number of active neurons: 8
 >> iter 41000, loss: 0.285803
 >> iter 42000, loss: 0.241232
 >> iter 43000, loss: 0.230414
 >> iter 44000, loss: 0.277847
 >> iter 45000, loss: 0.392787
 >> iter 46000, loss: 0.384452
 >> iter 47000, loss: 0.311279
 >> iter 48000, loss: 0.306515
 >> iter 49000, loss: 0.303352
 >> iter 50000, loss: 0.246224
   Number of active neurons: 7
 >> iter 51000, loss: 0.166884
 >> iter 52000, loss: 0.248472
 >> iter 53000, loss: 0.292493
 >> iter 54000, loss: 0.304163
 >> iter 55000, loss: 0.327374
 >> iter 56000, loss: 0.311121
 >> iter 57000, loss: 0.204119
 >> iter 58000, loss: 0.169393
 >> iter 59000, loss: 0.215057
 >> iter 60000, loss: 0.174753
   Number of active neurons: 7
 >> iter 61000, loss: 0.201328
 >> iter 62000, loss: 0.293384
 >> iter 63000, loss: 0.281266
 >> iter 64000, loss: 0.401968
 >> iter 65000, loss: 0.329473
 >> iter 66000, loss: 0.198351
 >> iter 67000, loss: 0.180077
 >> iter 68000, loss: 0.190033
 >> iter 69000, loss: 0.162253
 >> iter 70000, loss: 0.157831
   Number of active neurons: 7
 >> iter 71000, loss: 0.155508
 >> iter 72000, loss: 0.205204
 >> iter 73000, loss: 0.185287
 >> iter 74000, loss: 0.184319
 >> iter 75000, loss: 0.328000
 >> iter 76000, loss: 0.233008
 >> iter 77000, loss: 0.191148
 >> iter 78000, loss: 0.150364
 >> iter 79000, loss: 0.300139
 >> iter 80000, loss: 0.234113
   Number of active neurons: 5
 >> iter 81000, loss: 0.263840
 >> iter 82000, loss: 0.180767
 >> iter 83000, loss: 0.282455
 >> iter 84000, loss: 0.291789
 >> iter 85000, loss: 0.338705
 >> iter 86000, loss: 0.298089
 >> iter 87000, loss: 0.272005
 >> iter 88000, loss: 0.265361
 >> iter 89000, loss: 0.249983
 >> iter 90000, loss: 0.309553
   Number of active neurons: 5
 >> iter 91000, loss: 0.196171
 >> iter 92000, loss: 0.232466
 >> iter 93000, loss: 0.254192
 >> iter 94000, loss: 0.236111
 >> iter 95000, loss: 0.158902
 >> iter 96000, loss: 0.193752
 >> iter 97000, loss: 0.284013
 >> iter 98000, loss: 0.251398
 >> iter 99000, loss: 0.259008
 >> iter 100000, loss: 0.230366
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 19.309956
 >> iter 2000, loss: 13.264206
 >> iter 3000, loss: 7.093872
 >> iter 4000, loss: 3.000868
 >> iter 5000, loss: 1.409035
 >> iter 6000, loss: 0.876105
 >> iter 7000, loss: 0.448902
 >> iter 8000, loss: 0.285588
 >> iter 9000, loss: 0.316946
 >> iter 10000, loss: 0.240725
   Number of active neurons: 7
 >> iter 11000, loss: 0.230252
 >> iter 12000, loss: 0.209369
 >> iter 13000, loss: 0.178274
 >> iter 14000, loss: 0.227815
 >> iter 15000, loss: 0.222381
 >> iter 16000, loss: 0.246952
 >> iter 17000, loss: 0.283466
 >> iter 18000, loss: 0.221795
 >> iter 19000, loss: 0.214091
 >> iter 20000, loss: 0.179287
   Number of active neurons: 7
 >> iter 21000, loss: 0.145075
 >> iter 22000, loss: 0.272365
 >> iter 23000, loss: 0.213952
 >> iter 24000, loss: 0.234804
 >> iter 25000, loss: 0.207975
 >> iter 26000, loss: 0.246031
 >> iter 27000, loss: 0.172135
 >> iter 28000, loss: 0.161945
 >> iter 29000, loss: 0.128566
 >> iter 30000, loss: 0.256735
   Number of active neurons: 6
 >> iter 31000, loss: 0.166560
 >> iter 32000, loss: 0.132215
 >> iter 33000, loss: 0.228921
 >> iter 34000, loss: 0.170921
 >> iter 35000, loss: 0.276399
 >> iter 36000, loss: 0.247649
 >> iter 37000, loss: 0.216115
 >> iter 38000, loss: 0.176710
 >> iter 39000, loss: 0.283565
 >> iter 40000, loss: 0.282031
   Number of active neurons: 5
 >> iter 41000, loss: 0.194943
 >> iter 42000, loss: 0.128829
 >> iter 43000, loss: 0.194123
 >> iter 44000, loss: 0.147036
 >> iter 45000, loss: 0.522451
 >> iter 46000, loss: 0.341512
 >> iter 47000, loss: 0.277107
 >> iter 48000, loss: 0.199953
 >> iter 49000, loss: 0.256782
 >> iter 50000, loss: 0.146005
   Number of active neurons: 5
 >> iter 51000, loss: 0.225182
 >> iter 52000, loss: 0.173091
 >> iter 53000, loss: 0.176708
 >> iter 54000, loss: 0.257288
 >> iter 55000, loss: 0.192426
 >> iter 56000, loss: 0.131073
 >> iter 57000, loss: 0.155946
 >> iter 58000, loss: 0.190381
 >> iter 59000, loss: 0.293719
 >> iter 60000, loss: 0.252580
   Number of active neurons: 5
 >> iter 61000, loss: 0.208223
 >> iter 62000, loss: 0.376075
 >> iter 63000, loss: 0.311256
 >> iter 64000, loss: 0.460728
 >> iter 65000, loss: 0.331255
 >> iter 66000, loss: 0.190925
 >> iter 67000, loss: 0.141467
 >> iter 68000, loss: 0.291935
 >> iter 69000, loss: 0.232311
 >> iter 70000, loss: 0.345977
   Number of active neurons: 5
 >> iter 71000, loss: 0.182753
 >> iter 72000, loss: 0.250731
 >> iter 73000, loss: 0.261676
 >> iter 74000, loss: 0.308105
 >> iter 75000, loss: 0.222693
 >> iter 76000, loss: 0.261780
 >> iter 77000, loss: 0.163611
 >> iter 78000, loss: 0.225252
 >> iter 79000, loss: 0.209352
 >> iter 80000, loss: 0.194258
   Number of active neurons: 5
 >> iter 81000, loss: 0.147131
 >> iter 82000, loss: 0.148556
 >> iter 83000, loss: 0.147434
 >> iter 84000, loss: 0.214743
 >> iter 85000, loss: 0.195545
 >> iter 86000, loss: 0.230887
 >> iter 87000, loss: 0.171542
 >> iter 88000, loss: 0.177789
 >> iter 89000, loss: 0.160757
 >> iter 90000, loss: 0.157309
   Number of active neurons: 5
 >> iter 91000, loss: 0.142548
 >> iter 92000, loss: 0.233710
 >> iter 93000, loss: 0.169600
 >> iter 94000, loss: 0.218182
 >> iter 95000, loss: 0.195214
 >> iter 96000, loss: 0.167364
 >> iter 97000, loss: 0.178233
 >> iter 98000, loss: 0.116775
 >> iter 99000, loss: 0.202293
 >> iter 100000, loss: 0.271428
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.143009
 >> iter 2000, loss: 11.077705
 >> iter 3000, loss: 5.230081
 >> iter 4000, loss: 2.492329
 >> iter 5000, loss: 1.661689
 >> iter 6000, loss: 0.990566
 >> iter 7000, loss: 0.905035
 >> iter 8000, loss: 0.484565
 >> iter 9000, loss: 0.459116
 >> iter 10000, loss: 0.306771
   Number of active neurons: 7
 >> iter 11000, loss: 0.328430
 >> iter 12000, loss: 0.321948
 >> iter 13000, loss: 0.231795
 >> iter 14000, loss: 0.243569
 >> iter 15000, loss: 0.232993
 >> iter 16000, loss: 0.250502
 >> iter 17000, loss: 0.335288
 >> iter 18000, loss: 0.249076
 >> iter 19000, loss: 0.330427
 >> iter 20000, loss: 0.272455
   Number of active neurons: 7
 >> iter 21000, loss: 0.333047
 >> iter 22000, loss: 0.230790
 >> iter 23000, loss: 0.191009
 >> iter 24000, loss: 0.139102
 >> iter 25000, loss: 0.227610
 >> iter 26000, loss: 0.287243
 >> iter 27000, loss: 0.363744
 >> iter 28000, loss: 0.217084
 >> iter 29000, loss: 0.281675
 >> iter 30000, loss: 0.278340
   Number of active neurons: 7
 >> iter 31000, loss: 0.282618
 >> iter 32000, loss: 0.411183
 >> iter 33000, loss: 0.237957
 >> iter 34000, loss: 0.283914
 >> iter 35000, loss: 0.268935
 >> iter 36000, loss: 0.413619
 >> iter 37000, loss: 0.306166
 >> iter 38000, loss: 0.180430
 >> iter 39000, loss: 0.260158
 >> iter 40000, loss: 0.255886
   Number of active neurons: 7
 >> iter 41000, loss: 0.186868
 >> iter 42000, loss: 0.290531
 >> iter 43000, loss: 0.258644
 >> iter 44000, loss: 0.250857
 >> iter 45000, loss: 0.285501
 >> iter 46000, loss: 0.216873
 >> iter 47000, loss: 0.246856
 >> iter 48000, loss: 0.252582
 >> iter 49000, loss: 0.207282
 >> iter 50000, loss: 0.151852
   Number of active neurons: 7
 >> iter 51000, loss: 0.203146
 >> iter 52000, loss: 0.334782
 >> iter 53000, loss: 0.408302
 >> iter 54000, loss: 0.526711
 >> iter 55000, loss: 0.305974
 >> iter 56000, loss: 0.332216
 >> iter 57000, loss: 0.233958
 >> iter 58000, loss: 0.338420
 >> iter 59000, loss: 0.262887
 >> iter 60000, loss: 0.224785
   Number of active neurons: 7
 >> iter 61000, loss: 0.141894
 >> iter 62000, loss: 0.140320
 >> iter 63000, loss: 0.198092
 >> iter 64000, loss: 0.215727
 >> iter 65000, loss: 0.293250
 >> iter 66000, loss: 0.167503
 >> iter 67000, loss: 0.190109
 >> iter 68000, loss: 0.267809
 >> iter 69000, loss: 0.341876
 >> iter 70000, loss: 0.276799
   Number of active neurons: 7
 >> iter 71000, loss: 0.175758
 >> iter 72000, loss: 0.159715
 >> iter 73000, loss: 0.344162
 >> iter 74000, loss: 0.245150
 >> iter 75000, loss: 0.238949
 >> iter 76000, loss: 0.215299
 >> iter 77000, loss: 0.233069
 >> iter 78000, loss: 0.260732
 >> iter 79000, loss: 0.184312
 >> iter 80000, loss: 0.272981
   Number of active neurons: 5
 >> iter 81000, loss: 0.211749
 >> iter 82000, loss: 0.165154
 >> iter 83000, loss: 0.256117
 >> iter 84000, loss: 0.383486
 >> iter 85000, loss: 0.221653
 >> iter 86000, loss: 0.200764
 >> iter 87000, loss: 0.205458
 >> iter 88000, loss: 0.172433
 >> iter 89000, loss: 0.352861
 >> iter 90000, loss: 0.224578
   Number of active neurons: 5
 >> iter 91000, loss: 0.245537
 >> iter 92000, loss: 0.238432
 >> iter 93000, loss: 0.280138
 >> iter 94000, loss: 0.209411
 >> iter 95000, loss: 0.196000
 >> iter 96000, loss: 0.198852
 >> iter 97000, loss: 0.233328
 >> iter 98000, loss: 0.164524
 >> iter 99000, loss: 0.285978
 >> iter 100000, loss: 0.223240
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.924833
 >> iter 2000, loss: 12.136660
 >> iter 3000, loss: 5.408066
 >> iter 4000, loss: 2.528960
 >> iter 5000, loss: 1.303356
 >> iter 6000, loss: 0.788009
 >> iter 7000, loss: 0.711745
 >> iter 8000, loss: 0.581076
 >> iter 9000, loss: 0.436479
 >> iter 10000, loss: 0.332735
   Number of active neurons: 7
 >> iter 11000, loss: 0.269649
 >> iter 12000, loss: 0.427321
 >> iter 13000, loss: 0.426743
 >> iter 14000, loss: 0.337964
 >> iter 15000, loss: 0.291284
 >> iter 16000, loss: 0.300644
 >> iter 17000, loss: 0.539262
 >> iter 18000, loss: 0.430994
 >> iter 19000, loss: 0.409822
 >> iter 20000, loss: 0.317620
   Number of active neurons: 7
 >> iter 21000, loss: 0.222855
 >> iter 22000, loss: 0.149707
 >> iter 23000, loss: 0.213509
 >> iter 24000, loss: 0.190655
 >> iter 25000, loss: 0.259959
 >> iter 26000, loss: 0.251376
 >> iter 27000, loss: 0.308063
 >> iter 28000, loss: 0.383044
 >> iter 29000, loss: 0.235334
 >> iter 30000, loss: 0.183303
   Number of active neurons: 7
 >> iter 31000, loss: 0.276055
 >> iter 32000, loss: 0.198930
 >> iter 33000, loss: 0.249805
 >> iter 34000, loss: 0.234219
 >> iter 35000, loss: 0.363330
 >> iter 36000, loss: 0.327921
 >> iter 37000, loss: 0.312426
 >> iter 38000, loss: 0.231147
 >> iter 39000, loss: 0.317358
 >> iter 40000, loss: 0.286287
   Number of active neurons: 7
 >> iter 41000, loss: 0.365009
 >> iter 42000, loss: 0.276361
 >> iter 43000, loss: 0.207966
 >> iter 44000, loss: 0.400387
 >> iter 45000, loss: 0.252183
 >> iter 46000, loss: 0.211327
 >> iter 47000, loss: 0.217386
 >> iter 48000, loss: 0.251729
 >> iter 49000, loss: 0.230653
 >> iter 50000, loss: 0.262430
   Number of active neurons: 7
 >> iter 51000, loss: 0.213382
 >> iter 52000, loss: 0.351943
 >> iter 53000, loss: 0.297276
 >> iter 54000, loss: 0.357910
 >> iter 55000, loss: 0.217345
 >> iter 56000, loss: 0.243625
 >> iter 57000, loss: 0.362809
 >> iter 58000, loss: 0.395995
 >> iter 59000, loss: 0.318116
 >> iter 60000, loss: 0.267078
   Number of active neurons: 7
 >> iter 61000, loss: 0.175412
 >> iter 62000, loss: 0.238117
 >> iter 63000, loss: 0.308664
 >> iter 64000, loss: 0.320764
 >> iter 65000, loss: 0.318195
 >> iter 66000, loss: 0.339200
 >> iter 67000, loss: 0.220276
 >> iter 68000, loss: 0.168069
 >> iter 69000, loss: 0.142121
 >> iter 70000, loss: 0.177029
   Number of active neurons: 7
 >> iter 71000, loss: 0.363534
 >> iter 72000, loss: 0.330429
 >> iter 73000, loss: 0.315472
 >> iter 74000, loss: 0.211384
 >> iter 75000, loss: 0.245892
 >> iter 76000, loss: 0.195279
 >> iter 77000, loss: 0.150754
 >> iter 78000, loss: 0.141982
 >> iter 79000, loss: 0.153765
 >> iter 80000, loss: 0.267430
   Number of active neurons: 7
 >> iter 81000, loss: 0.193644
 >> iter 82000, loss: 0.277205
 >> iter 83000, loss: 0.298218
 >> iter 84000, loss: 0.256865
 >> iter 85000, loss: 0.153246
 >> iter 86000, loss: 0.117099
 >> iter 87000, loss: 0.148520
 >> iter 88000, loss: 0.272855
 >> iter 89000, loss: 0.206788
 >> iter 90000, loss: 0.159468
   Number of active neurons: 7
 >> iter 91000, loss: 0.381025
 >> iter 92000, loss: 0.366680
 >> iter 93000, loss: 0.228568
 >> iter 94000, loss: 0.367531
 >> iter 95000, loss: 0.259545
 >> iter 96000, loss: 0.263856
 >> iter 97000, loss: 0.368385
 >> iter 98000, loss: 0.253005
 >> iter 99000, loss: 0.345554
 >> iter 100000, loss: 0.427938
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 19.314017
 >> iter 2000, loss: 12.530791
 >> iter 3000, loss: 7.776859
 >> iter 4000, loss: 4.006094
 >> iter 5000, loss: 2.189205
 >> iter 6000, loss: 1.157208
 >> iter 7000, loss: 0.664412
 >> iter 8000, loss: 0.526753
 >> iter 9000, loss: 0.312282
 >> iter 10000, loss: 0.306920
   Number of active neurons: 6
 >> iter 11000, loss: 0.285676
 >> iter 12000, loss: 0.256904
 >> iter 13000, loss: 0.468495
 >> iter 14000, loss: 0.454755
 >> iter 15000, loss: 0.479867
 >> iter 16000, loss: 0.338540
 >> iter 17000, loss: 0.493521
 >> iter 18000, loss: 0.415432
 >> iter 19000, loss: 0.287933
 >> iter 20000, loss: 0.397597
   Number of active neurons: 5
 >> iter 21000, loss: 0.389899
 >> iter 22000, loss: 0.286764
 >> iter 23000, loss: 0.258108
 >> iter 24000, loss: 0.438071
 >> iter 25000, loss: 0.252420
 >> iter 26000, loss: 0.252108
 >> iter 27000, loss: 0.363412
 >> iter 28000, loss: 0.310134
 >> iter 29000, loss: 0.302576
 >> iter 30000, loss: 0.305748
   Number of active neurons: 5
 >> iter 31000, loss: 0.403394
 >> iter 32000, loss: 0.234796
 >> iter 33000, loss: 0.319246
 >> iter 34000, loss: 0.292304
 >> iter 35000, loss: 0.396985
 >> iter 36000, loss: 0.417640
 >> iter 37000, loss: 0.313896
 >> iter 38000, loss: 0.244114
 >> iter 39000, loss: 0.211130
 >> iter 40000, loss: 0.238771
   Number of active neurons: 5
 >> iter 41000, loss: 0.468259
 >> iter 42000, loss: 0.390322
 >> iter 43000, loss: 0.448974
 >> iter 44000, loss: 0.412747
 >> iter 45000, loss: 0.313626
 >> iter 46000, loss: 0.338244
 >> iter 47000, loss: 0.515542
 >> iter 48000, loss: 0.366590
 >> iter 49000, loss: 0.300488
 >> iter 50000, loss: 0.260662
   Number of active neurons: 5
 >> iter 51000, loss: 0.247281
 >> iter 52000, loss: 0.283629
 >> iter 53000, loss: 0.345036
 >> iter 54000, loss: 0.317691
 >> iter 55000, loss: 0.283707
 >> iter 56000, loss: 0.369501
 >> iter 57000, loss: 0.428856
 >> iter 58000, loss: 0.350758
 >> iter 59000, loss: 0.341619
 >> iter 60000, loss: 0.257624
   Number of active neurons: 5
 >> iter 61000, loss: 0.359798
 >> iter 62000, loss: 0.345945
 >> iter 63000, loss: 0.401066
 >> iter 64000, loss: 0.497688
 >> iter 65000, loss: 0.377640
 >> iter 66000, loss: 0.436947
 >> iter 67000, loss: 0.480374
 >> iter 68000, loss: 0.489084
 >> iter 69000, loss: 0.399498
 >> iter 70000, loss: 0.310801
   Number of active neurons: 5
 >> iter 71000, loss: 0.527873
 >> iter 72000, loss: 0.461121
 >> iter 73000, loss: 0.484325
 >> iter 74000, loss: 0.407652
 >> iter 75000, loss: 0.323933
 >> iter 76000, loss: 0.290116
 >> iter 77000, loss: 0.384223
 >> iter 78000, loss: 0.388393
 >> iter 79000, loss: 0.350968
 >> iter 80000, loss: 0.328039
   Number of active neurons: 5
 >> iter 81000, loss: 0.254486
 >> iter 82000, loss: 0.321531
 >> iter 83000, loss: 0.326302
 >> iter 84000, loss: 0.333486
 >> iter 85000, loss: 0.366172
 >> iter 86000, loss: 0.350564
 >> iter 87000, loss: 0.470438
 >> iter 88000, loss: 0.456772
 >> iter 89000, loss: 0.374071
 >> iter 90000, loss: 0.445864
   Number of active neurons: 5
 >> iter 91000, loss: 0.498879
 >> iter 92000, loss: 0.455545
 >> iter 93000, loss: 0.499915
 >> iter 94000, loss: 0.404311
 >> iter 95000, loss: 0.322260
 >> iter 96000, loss: 0.389586
 >> iter 97000, loss: 0.706471
 >> iter 98000, loss: 0.459015
 >> iter 99000, loss: 0.486249
 >> iter 100000, loss: 0.397098
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0139997200056
   - Test - Long: 0.0
   - Test - Big: 0.0189998100019
   - Test - A: 0.0
   - Test - B: 13.4524365042
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 19.005632
 >> iter 2000, loss: 12.566371
 >> iter 3000, loss: 5.949835
 >> iter 4000, loss: 2.582087
 >> iter 5000, loss: 1.268192
 >> iter 6000, loss: 0.707761
 >> iter 7000, loss: 0.429945
 >> iter 8000, loss: 0.328989
 >> iter 9000, loss: 0.395866
 >> iter 10000, loss: 0.366834
   Number of active neurons: 10
 >> iter 11000, loss: 0.228722
 >> iter 12000, loss: 0.333980
 >> iter 13000, loss: 0.312552
 >> iter 14000, loss: 0.291730
 >> iter 15000, loss: 0.283419
 >> iter 16000, loss: 0.296693
 >> iter 17000, loss: 0.354732
 >> iter 18000, loss: 0.203478
 >> iter 19000, loss: 0.301587
 >> iter 20000, loss: 0.287515
   Number of active neurons: 10
 >> iter 21000, loss: 0.257161
 >> iter 22000, loss: 0.222085
 >> iter 23000, loss: 0.150749
 >> iter 24000, loss: 0.332518
 >> iter 25000, loss: 0.295463
 >> iter 26000, loss: 0.236210
 >> iter 27000, loss: 0.171242
 >> iter 28000, loss: 0.181567
 >> iter 29000, loss: 0.315905
 >> iter 30000, loss: 0.344706
   Number of active neurons: 8
 >> iter 31000, loss: 0.255992
 >> iter 32000, loss: 0.331599
 >> iter 33000, loss: 0.320478
 >> iter 34000, loss: 0.464976
 >> iter 35000, loss: 0.289624
 >> iter 36000, loss: 0.263498
 >> iter 37000, loss: 0.221315
 >> iter 38000, loss: 0.204857
 >> iter 39000, loss: 0.157893
 >> iter 40000, loss: 0.179535
   Number of active neurons: 8
 >> iter 41000, loss: 0.226828
 >> iter 42000, loss: 0.208839
 >> iter 43000, loss: 0.197240
 >> iter 44000, loss: 0.140527
 >> iter 45000, loss: 0.134066
 >> iter 46000, loss: 0.189823
 >> iter 47000, loss: 0.179536
 >> iter 48000, loss: 0.131784
 >> iter 49000, loss: 0.349931
 >> iter 50000, loss: 0.222782
   Number of active neurons: 8
 >> iter 51000, loss: 0.182339
 >> iter 52000, loss: 0.160050
 >> iter 53000, loss: 0.129120
 >> iter 54000, loss: 0.238272
 >> iter 55000, loss: 0.268065
 >> iter 56000, loss: 0.242629
 >> iter 57000, loss: 0.207550
 >> iter 58000, loss: 0.200162
 >> iter 59000, loss: 0.144422
 >> iter 60000, loss: 0.184511
   Number of active neurons: 6
 >> iter 61000, loss: 0.162689
 >> iter 62000, loss: 0.159289
 >> iter 63000, loss: 0.212065
 >> iter 64000, loss: 0.321754
 >> iter 65000, loss: 0.272981
 >> iter 66000, loss: 0.217707
 >> iter 67000, loss: 0.125237
 >> iter 68000, loss: 0.176207
 >> iter 69000, loss: 0.367715
 >> iter 70000, loss: 0.385694
   Number of active neurons: 6
 >> iter 71000, loss: 0.226857
 >> iter 72000, loss: 0.272716
 >> iter 73000, loss: 0.293105
 >> iter 74000, loss: 0.259857
 >> iter 75000, loss: 0.351563
 >> iter 76000, loss: 0.312785
 >> iter 77000, loss: 0.383213
 >> iter 78000, loss: 0.243456
 >> iter 79000, loss: 0.259776
 >> iter 80000, loss: 0.171439
   Number of active neurons: 5
 >> iter 81000, loss: 0.290155
 >> iter 82000, loss: 0.206142
 >> iter 83000, loss: 0.301444
 >> iter 84000, loss: 0.222656
 >> iter 85000, loss: 0.177801
 >> iter 86000, loss: 0.156380
 >> iter 87000, loss: 0.111131
 >> iter 88000, loss: 0.096230
 >> iter 89000, loss: 0.361126
 >> iter 90000, loss: 0.247413
   Number of active neurons: 5
 >> iter 91000, loss: 0.175876
 >> iter 92000, loss: 0.174822
 >> iter 93000, loss: 0.185970
 >> iter 94000, loss: 0.247204
 >> iter 95000, loss: 0.191948
 >> iter 96000, loss: 0.142239
 >> iter 97000, loss: 0.173186
 >> iter 98000, loss: 0.121758
 >> iter 99000, loss: 0.172062
 >> iter 100000, loss: 0.183117
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.793236
 >> iter 2000, loss: 9.807880
 >> iter 3000, loss: 4.383647
 >> iter 4000, loss: 1.879608
 >> iter 5000, loss: 0.908469
 >> iter 6000, loss: 0.703339
 >> iter 7000, loss: 0.418649
 >> iter 8000, loss: 0.394207
 >> iter 9000, loss: 0.424998
 >> iter 10000, loss: 0.441564
   Number of active neurons: 8
 >> iter 11000, loss: 0.297032
 >> iter 12000, loss: 0.300832
 >> iter 13000, loss: 0.248730
 >> iter 14000, loss: 0.233907
 >> iter 15000, loss: 0.232441
 >> iter 16000, loss: 0.297743
 >> iter 17000, loss: 0.309771
 >> iter 18000, loss: 0.331022
 >> iter 19000, loss: 0.328455
 >> iter 20000, loss: 0.472777
   Number of active neurons: 7
 >> iter 21000, loss: 0.369843
 >> iter 22000, loss: 0.292726
 >> iter 23000, loss: 0.263019
 >> iter 24000, loss: 0.365328
 >> iter 25000, loss: 0.367365
 >> iter 26000, loss: 0.405480
 >> iter 27000, loss: 0.364674
 >> iter 28000, loss: 0.390107
 >> iter 29000, loss: 0.456291
 >> iter 30000, loss: 0.320216
   Number of active neurons: 7
 >> iter 31000, loss: 0.386142
 >> iter 32000, loss: 0.341371
 >> iter 33000, loss: 0.422585
 >> iter 34000, loss: 0.350305
 >> iter 35000, loss: 0.274331
 >> iter 36000, loss: 0.322635
 >> iter 37000, loss: 0.376029
 >> iter 38000, loss: 0.262762
 >> iter 39000, loss: 0.302865
 >> iter 40000, loss: 0.352785
   Number of active neurons: 7
 >> iter 41000, loss: 0.575106
 >> iter 42000, loss: 0.466098
 >> iter 43000, loss: 0.311381
 >> iter 44000, loss: 0.469366
 >> iter 45000, loss: 0.374979
 >> iter 46000, loss: 0.393657
 >> iter 47000, loss: 0.435075
 >> iter 48000, loss: 0.323942
 >> iter 49000, loss: 0.233739
 >> iter 50000, loss: 0.423822
   Number of active neurons: 7
 >> iter 51000, loss: 0.241734
 >> iter 52000, loss: 0.329922
 >> iter 53000, loss: 0.380979
 >> iter 54000, loss: 0.395046
 >> iter 55000, loss: 0.283423
 >> iter 56000, loss: 0.228815
 >> iter 57000, loss: 0.302134
 >> iter 58000, loss: 0.306971
 >> iter 59000, loss: 0.278430
 >> iter 60000, loss: 0.265721
   Number of active neurons: 7
 >> iter 61000, loss: 0.235709
 >> iter 62000, loss: 0.331727
 >> iter 63000, loss: 0.483895
 >> iter 64000, loss: 0.297097
 >> iter 65000, loss: 0.505265
 >> iter 66000, loss: 0.304680
 >> iter 67000, loss: 0.505375
 >> iter 68000, loss: 0.381508
 >> iter 69000, loss: 0.226423
 >> iter 70000, loss: 0.190300
   Number of active neurons: 7
 >> iter 71000, loss: 0.241712
 >> iter 72000, loss: 0.342144
 >> iter 73000, loss: 0.302704
 >> iter 74000, loss: 0.196828
 >> iter 75000, loss: 0.162105
 >> iter 76000, loss: 0.157560
 >> iter 77000, loss: 0.151379
 >> iter 78000, loss: 0.114522
 >> iter 79000, loss: 0.189892
 >> iter 80000, loss: 0.276798
   Number of active neurons: 7
 >> iter 81000, loss: 0.328950
 >> iter 82000, loss: 0.352217
 >> iter 83000, loss: 0.297472
 >> iter 84000, loss: 0.284240
 >> iter 85000, loss: 0.174857
 >> iter 86000, loss: 0.185716
 >> iter 87000, loss: 0.349338
 >> iter 88000, loss: 0.246787
 >> iter 89000, loss: 0.161087
 >> iter 90000, loss: 0.189462
   Number of active neurons: 5
 >> iter 91000, loss: 0.191435
 >> iter 92000, loss: 0.190007
 >> iter 93000, loss: 0.381507
 >> iter 94000, loss: 0.193873
 >> iter 95000, loss: 0.205578
 >> iter 96000, loss: 0.202703
 >> iter 97000, loss: 0.252359
 >> iter 98000, loss: 0.204266
 >> iter 99000, loss: 0.203953
 >> iter 100000, loss: 0.195979
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.361104
 >> iter 2000, loss: 10.275600
 >> iter 3000, loss: 4.389802
 >> iter 4000, loss: 1.923397
 >> iter 5000, loss: 0.991541
 >> iter 6000, loss: 0.495215
 >> iter 7000, loss: 0.259475
 >> iter 8000, loss: 0.250490
 >> iter 9000, loss: 0.225031
 >> iter 10000, loss: 0.139990
   Number of active neurons: 6
 >> iter 11000, loss: 0.353016
 >> iter 12000, loss: 0.274683
 >> iter 13000, loss: 0.200011
 >> iter 14000, loss: 0.324926
 >> iter 15000, loss: 0.329609
 >> iter 16000, loss: 0.350889
 >> iter 17000, loss: 0.249645
 >> iter 18000, loss: 0.255390
 >> iter 19000, loss: 0.231920
 >> iter 20000, loss: 0.187702
   Number of active neurons: 6
 >> iter 21000, loss: 0.134982
 >> iter 22000, loss: 0.294918
 >> iter 23000, loss: 0.285994
 >> iter 24000, loss: 0.279003
 >> iter 25000, loss: 0.244612
 >> iter 26000, loss: 0.246423
 >> iter 27000, loss: 0.287820
 >> iter 28000, loss: 0.183412
 >> iter 29000, loss: 0.233912
 >> iter 30000, loss: 0.285598
   Number of active neurons: 6
 >> iter 31000, loss: 0.299401
 >> iter 32000, loss: 0.373238
 >> iter 33000, loss: 0.363945
 >> iter 34000, loss: 0.254914
 >> iter 35000, loss: 0.291977
 >> iter 36000, loss: 0.227345
 >> iter 37000, loss: 0.224947
 >> iter 38000, loss: 0.201634
 >> iter 39000, loss: 0.295708
 >> iter 40000, loss: 0.209848
   Number of active neurons: 6
 >> iter 41000, loss: 0.267104
 >> iter 42000, loss: 0.184214
 >> iter 43000, loss: 0.279480
 >> iter 44000, loss: 0.177509
 >> iter 45000, loss: 0.304172
 >> iter 46000, loss: 0.282352
 >> iter 47000, loss: 0.295217
 >> iter 48000, loss: 0.295993
 >> iter 49000, loss: 0.177399
 >> iter 50000, loss: 0.277570
   Number of active neurons: 6
 >> iter 51000, loss: 0.354128
 >> iter 52000, loss: 0.361590
 >> iter 53000, loss: 0.275333
 >> iter 54000, loss: 0.165952
 >> iter 55000, loss: 0.233089
 >> iter 56000, loss: 0.234552
 >> iter 57000, loss: 0.244965
 >> iter 58000, loss: 0.204161
 >> iter 59000, loss: 0.142008
 >> iter 60000, loss: 0.188739
   Number of active neurons: 6
 >> iter 61000, loss: 0.269533
 >> iter 62000, loss: 0.290979
 >> iter 63000, loss: 0.219727
 >> iter 64000, loss: 0.262265
 >> iter 65000, loss: 0.195979
 >> iter 66000, loss: 0.220367
 >> iter 67000, loss: 0.263195
 >> iter 68000, loss: 0.224547
 >> iter 69000, loss: 0.143521
 >> iter 70000, loss: 0.224115
   Number of active neurons: 6
 >> iter 71000, loss: 0.255526
 >> iter 72000, loss: 0.202472
 >> iter 73000, loss: 0.130739
 >> iter 74000, loss: 0.181861
 >> iter 75000, loss: 0.166443
 >> iter 76000, loss: 0.299893
 >> iter 77000, loss: 0.267748
 >> iter 78000, loss: 0.257234
 >> iter 79000, loss: 0.340360
 >> iter 80000, loss: 0.183477
   Number of active neurons: 6
 >> iter 81000, loss: 0.263423
 >> iter 82000, loss: 0.210209
 >> iter 83000, loss: 0.203548
 >> iter 84000, loss: 0.294506
 >> iter 85000, loss: 0.355337
 >> iter 86000, loss: 0.240797
 >> iter 87000, loss: 0.239172
 >> iter 88000, loss: 0.210094
 >> iter 89000, loss: 0.361000
 >> iter 90000, loss: 0.269738
   Number of active neurons: 6
 >> iter 91000, loss: 0.197361
 >> iter 92000, loss: 0.216931
 >> iter 93000, loss: 0.299995
 >> iter 94000, loss: 0.210448
 >> iter 95000, loss: 0.206353
 >> iter 96000, loss: 0.182275
 >> iter 97000, loss: 0.285013
 >> iter 98000, loss: 0.190239
 >> iter 99000, loss: 0.188071
 >> iter 100000, loss: 0.249494
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.226664
 >> iter 2000, loss: 11.178283
 >> iter 3000, loss: 4.596845
 >> iter 4000, loss: 1.969838
 >> iter 5000, loss: 0.974158
 >> iter 6000, loss: 0.543176
 >> iter 7000, loss: 0.414563
 >> iter 8000, loss: 0.302821
 >> iter 9000, loss: 0.308536
 >> iter 10000, loss: 0.200925
   Number of active neurons: 9
 >> iter 11000, loss: 0.325172
 >> iter 12000, loss: 0.360728
 >> iter 13000, loss: 0.354869
 >> iter 14000, loss: 0.329037
 >> iter 15000, loss: 0.374818
 >> iter 16000, loss: 0.213341
 >> iter 17000, loss: 0.177513
 >> iter 18000, loss: 0.280432
 >> iter 19000, loss: 0.200583
 >> iter 20000, loss: 0.209827
   Number of active neurons: 9
 >> iter 21000, loss: 0.189708
 >> iter 22000, loss: 0.260925
 >> iter 23000, loss: 0.540704
 >> iter 24000, loss: 0.402659
 >> iter 25000, loss: 0.299291
 >> iter 26000, loss: 0.230285
 >> iter 27000, loss: 0.308805
 >> iter 28000, loss: 0.275007
 >> iter 29000, loss: 0.223756
 >> iter 30000, loss: 0.283763
   Number of active neurons: 8
 >> iter 31000, loss: 0.183324
 >> iter 32000, loss: 0.195479
 >> iter 33000, loss: 0.426014
 >> iter 34000, loss: 0.500545
 >> iter 35000, loss: 0.304586
 >> iter 36000, loss: 0.278637
 >> iter 37000, loss: 0.335727
 >> iter 38000, loss: 0.215224
 >> iter 39000, loss: 0.291803
 >> iter 40000, loss: 0.263596
   Number of active neurons: 8
 >> iter 41000, loss: 0.294726
 >> iter 42000, loss: 0.233203
 >> iter 43000, loss: 0.207990
 >> iter 44000, loss: 0.228061
 >> iter 45000, loss: 0.300366
 >> iter 46000, loss: 0.212132
 >> iter 47000, loss: 0.290674
 >> iter 48000, loss: 0.193581
 >> iter 49000, loss: 0.117784
 >> iter 50000, loss: 0.201248
   Number of active neurons: 7
 >> iter 51000, loss: 0.204233
 >> iter 52000, loss: 0.203926
 >> iter 53000, loss: 0.316108
 >> iter 54000, loss: 0.309784
 >> iter 55000, loss: 0.292426
 >> iter 56000, loss: 0.253684
 >> iter 57000, loss: 0.140965
 >> iter 58000, loss: 0.120486
 >> iter 59000, loss: 0.237554
 >> iter 60000, loss: 0.261422
   Number of active neurons: 6
 >> iter 61000, loss: 0.343943
 >> iter 62000, loss: 0.267315
 >> iter 63000, loss: 0.285690
 >> iter 64000, loss: 0.197198
 >> iter 65000, loss: 0.193205
 >> iter 66000, loss: 0.174310
 >> iter 67000, loss: 0.260265
 >> iter 68000, loss: 0.220396
 >> iter 69000, loss: 0.256802
 >> iter 70000, loss: 0.200967
   Number of active neurons: 5
 >> iter 71000, loss: 0.391634
 >> iter 72000, loss: 0.297457
 >> iter 73000, loss: 0.299192
 >> iter 74000, loss: 0.323083
 >> iter 75000, loss: 0.228084
 >> iter 76000, loss: 0.225414
 >> iter 77000, loss: 0.142231
 >> iter 78000, loss: 0.214810
 >> iter 79000, loss: 0.254199
 >> iter 80000, loss: 0.328969
   Number of active neurons: 5
 >> iter 81000, loss: 0.228871
 >> iter 82000, loss: 0.237599
 >> iter 83000, loss: 0.206336
 >> iter 84000, loss: 0.204138
 >> iter 85000, loss: 0.136344
 >> iter 86000, loss: 0.310435
 >> iter 87000, loss: 0.198698
 >> iter 88000, loss: 0.206482
 >> iter 89000, loss: 0.293854
 >> iter 90000, loss: 0.166374
   Number of active neurons: 5
 >> iter 91000, loss: 0.377950
 >> iter 92000, loss: 0.349973
 >> iter 93000, loss: 0.311605
 >> iter 94000, loss: 0.230085
 >> iter 95000, loss: 0.327798
 >> iter 96000, loss: 0.275578
 >> iter 97000, loss: 0.217578
 >> iter 98000, loss: 0.147683
 >> iter 99000, loss: 0.213492
 >> iter 100000, loss: 0.317414
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.115489
 >> iter 2000, loss: 10.952324
 >> iter 3000, loss: 4.623943
 >> iter 4000, loss: 1.993201
 >> iter 5000, loss: 1.091647
 >> iter 6000, loss: 0.548652
 >> iter 7000, loss: 0.534697
 >> iter 8000, loss: 0.328095
 >> iter 9000, loss: 0.250392
 >> iter 10000, loss: 0.226831
   Number of active neurons: 9
 >> iter 11000, loss: 0.196757
 >> iter 12000, loss: 0.256670
 >> iter 13000, loss: 0.255968
 >> iter 14000, loss: 0.310948
 >> iter 15000, loss: 0.513515
 >> iter 16000, loss: 0.308696
 >> iter 17000, loss: 0.368709
 >> iter 18000, loss: 0.461078
 >> iter 19000, loss: 0.234661
 >> iter 20000, loss: 0.422227
   Number of active neurons: 9
 >> iter 21000, loss: 0.328999
 >> iter 22000, loss: 0.203954
 >> iter 23000, loss: 0.324761
 >> iter 24000, loss: 0.208142
 >> iter 25000, loss: 0.252718
 >> iter 26000, loss: 0.246637
 >> iter 27000, loss: 0.177164
 >> iter 28000, loss: 0.236754
 >> iter 29000, loss: 0.241284
 >> iter 30000, loss: 0.284756
   Number of active neurons: 8
 >> iter 31000, loss: 0.258425
 >> iter 32000, loss: 0.248306
 >> iter 33000, loss: 0.310124
 >> iter 34000, loss: 0.303567
 >> iter 35000, loss: 0.272079
 >> iter 36000, loss: 0.386307
 >> iter 37000, loss: 0.364702
 >> iter 38000, loss: 0.432766
 >> iter 39000, loss: 0.385291
 >> iter 40000, loss: 0.213497
   Number of active neurons: 7
 >> iter 41000, loss: 0.144118
 >> iter 42000, loss: 0.152144
 >> iter 43000, loss: 0.200029
 >> iter 44000, loss: 0.258113
 >> iter 45000, loss: 0.190208
 >> iter 46000, loss: 0.141058
 >> iter 47000, loss: 0.138045
 >> iter 48000, loss: 0.168857
 >> iter 49000, loss: 0.114564
 >> iter 50000, loss: 0.170762
   Number of active neurons: 7
 >> iter 51000, loss: 0.249922
 >> iter 52000, loss: 0.224609
 >> iter 53000, loss: 0.239328
 >> iter 54000, loss: 0.186561
 >> iter 55000, loss: 0.177293
 >> iter 56000, loss: 0.378251
 >> iter 57000, loss: 0.211455
 >> iter 58000, loss: 0.259015
 >> iter 59000, loss: 0.274276
 >> iter 60000, loss: 0.336706
   Number of active neurons: 6
 >> iter 61000, loss: 0.340046
 >> iter 62000, loss: 0.194052
 >> iter 63000, loss: 0.178441
 >> iter 64000, loss: 0.125513
 >> iter 65000, loss: 0.242224
 >> iter 66000, loss: 0.174076
 >> iter 67000, loss: 0.135075
 >> iter 68000, loss: 0.367477
 >> iter 69000, loss: 0.347552
 >> iter 70000, loss: 0.320742
   Number of active neurons: 6
 >> iter 71000, loss: 0.232660
 >> iter 72000, loss: 0.250170
 >> iter 73000, loss: 0.193273
 >> iter 74000, loss: 0.187989
 >> iter 75000, loss: 0.135886
 >> iter 76000, loss: 0.168038
 >> iter 77000, loss: 0.134217
 >> iter 78000, loss: 0.151477
 >> iter 79000, loss: 0.239529
 >> iter 80000, loss: 0.174733
   Number of active neurons: 6
 >> iter 81000, loss: 0.290313
 >> iter 82000, loss: 0.154636
 >> iter 83000, loss: 0.167495
 >> iter 84000, loss: 0.190263
 >> iter 85000, loss: 0.203614
 >> iter 86000, loss: 0.165778
 >> iter 87000, loss: 0.152210
 >> iter 88000, loss: 0.109137
 >> iter 89000, loss: 0.134086
 >> iter 90000, loss: 0.193100
   Number of active neurons: 6
 >> iter 91000, loss: 0.308980
 >> iter 92000, loss: 0.165916
 >> iter 93000, loss: 0.147035
 >> iter 94000, loss: 0.280536
 >> iter 95000, loss: 0.333496
 >> iter 96000, loss: 0.195456
 >> iter 97000, loss: 0.378951
 >> iter 98000, loss: 0.395570
 >> iter 99000, loss: 0.290527
 >> iter 100000, loss: 0.175309
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.888160
 >> iter 2000, loss: 10.202323
 >> iter 3000, loss: 4.599770
 >> iter 4000, loss: 2.186703
 >> iter 5000, loss: 1.271434
 >> iter 6000, loss: 0.641371
 >> iter 7000, loss: 0.404676
 >> iter 8000, loss: 0.365404
 >> iter 9000, loss: 0.253399
 >> iter 10000, loss: 0.296841
   Number of active neurons: 7
 >> iter 11000, loss: 0.385320
 >> iter 12000, loss: 0.228622
 >> iter 13000, loss: 0.254350
 >> iter 14000, loss: 0.270997
 >> iter 15000, loss: 0.207038
 >> iter 16000, loss: 0.252698
 >> iter 17000, loss: 0.442986
 >> iter 18000, loss: 0.428067
 >> iter 19000, loss: 0.389535
 >> iter 20000, loss: 0.311726
   Number of active neurons: 7
 >> iter 21000, loss: 0.305443
 >> iter 22000, loss: 0.234539
 >> iter 23000, loss: 0.264680
 >> iter 24000, loss: 0.226409
 >> iter 25000, loss: 0.237539
 >> iter 26000, loss: 0.149658
 >> iter 27000, loss: 0.133959
 >> iter 28000, loss: 0.351856
 >> iter 29000, loss: 0.483631
 >> iter 30000, loss: 0.294402
   Number of active neurons: 7
 >> iter 31000, loss: 0.291343
 >> iter 32000, loss: 0.360293
 >> iter 33000, loss: 0.397612
 >> iter 34000, loss: 0.364736
 >> iter 35000, loss: 0.364617
 >> iter 36000, loss: 0.245488
 >> iter 37000, loss: 0.333129
 >> iter 38000, loss: 0.324035
 >> iter 39000, loss: 0.292100
 >> iter 40000, loss: 0.252843
   Number of active neurons: 6
 >> iter 41000, loss: 0.230406
 >> iter 42000, loss: 0.327667
 >> iter 43000, loss: 0.277016
 >> iter 44000, loss: 0.226323
 >> iter 45000, loss: 0.205494
 >> iter 46000, loss: 0.178644
 >> iter 47000, loss: 0.214318
 >> iter 48000, loss: 0.163457
 >> iter 49000, loss: 0.190762
 >> iter 50000, loss: 0.181873
   Number of active neurons: 6
 >> iter 51000, loss: 0.138773
 >> iter 52000, loss: 0.166435
 >> iter 53000, loss: 0.279634
 >> iter 54000, loss: 0.221257
 >> iter 55000, loss: 0.178613
 >> iter 56000, loss: 0.182592
 >> iter 57000, loss: 0.241949
 >> iter 58000, loss: 0.234302
 >> iter 59000, loss: 0.203182
 >> iter 60000, loss: 0.315193
   Number of active neurons: 5
 >> iter 61000, loss: 0.285176
 >> iter 62000, loss: 0.286899
 >> iter 63000, loss: 0.178824
 >> iter 64000, loss: 0.157415
 >> iter 65000, loss: 0.167912
 >> iter 66000, loss: 0.206690
 >> iter 67000, loss: 0.194909
 >> iter 68000, loss: 0.151659
 >> iter 69000, loss: 0.181699
 >> iter 70000, loss: 0.173753
   Number of active neurons: 4
 >> iter 71000, loss: 0.208500
 >> iter 72000, loss: 0.294585
 >> iter 73000, loss: 0.169912
 >> iter 74000, loss: 0.136307
 >> iter 75000, loss: 0.209206
 >> iter 76000, loss: 0.227622
 >> iter 77000, loss: 0.343784
 >> iter 78000, loss: 0.277013
 >> iter 79000, loss: 0.241185
 >> iter 80000, loss: 0.193752
   Number of active neurons: 4
 >> iter 81000, loss: 0.209411
 >> iter 82000, loss: 0.250631
 >> iter 83000, loss: 0.173332
 >> iter 84000, loss: 0.286092
 >> iter 85000, loss: 0.187604
 >> iter 86000, loss: 0.207975
 >> iter 87000, loss: 0.436659
 >> iter 88000, loss: 0.252517
 >> iter 89000, loss: 0.141792
 >> iter 90000, loss: 0.281363
   Number of active neurons: 4
 >> iter 91000, loss: 0.284239
 >> iter 92000, loss: 0.365021
 >> iter 93000, loss: 0.283796
 >> iter 94000, loss: 0.180432
 >> iter 95000, loss: 0.150803
 >> iter 96000, loss: 0.201017
 >> iter 97000, loss: 0.182503
 >> iter 98000, loss: 0.164036
 >> iter 99000, loss: 0.217018
 >> iter 100000, loss: 0.309658
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 19.030384
 >> iter 2000, loss: 12.884651
 >> iter 3000, loss: 6.057048
 >> iter 4000, loss: 2.792231
 >> iter 5000, loss: 1.348782
 >> iter 6000, loss: 1.013329
 >> iter 7000, loss: 0.695000
 >> iter 8000, loss: 0.485981
 >> iter 9000, loss: 0.465084
 >> iter 10000, loss: 0.529276
   Number of active neurons: 9
 >> iter 11000, loss: 0.510760
 >> iter 12000, loss: 0.471835
 >> iter 13000, loss: 0.336915
 >> iter 14000, loss: 0.391627
 >> iter 15000, loss: 0.363567
 >> iter 16000, loss: 0.364900
 >> iter 17000, loss: 0.545559
 >> iter 18000, loss: 0.359315
 >> iter 19000, loss: 0.534632
 >> iter 20000, loss: 0.542980
   Number of active neurons: 9
 >> iter 21000, loss: 0.378583
 >> iter 22000, loss: 0.272326
 >> iter 23000, loss: 0.249019
 >> iter 24000, loss: 0.360784
 >> iter 25000, loss: 0.476160
 >> iter 26000, loss: 0.502153
 >> iter 27000, loss: 0.323324
 >> iter 28000, loss: 0.339290
 >> iter 29000, loss: 0.391271
 >> iter 30000, loss: 0.369595
   Number of active neurons: 9
 >> iter 31000, loss: 0.366693
 >> iter 32000, loss: 0.326917
 >> iter 33000, loss: 0.250771
 >> iter 34000, loss: 0.310020
 >> iter 35000, loss: 0.432813
 >> iter 36000, loss: 0.352013
 >> iter 37000, loss: 0.379810
 >> iter 38000, loss: 0.354045
 >> iter 39000, loss: 0.533791
 >> iter 40000, loss: 0.318533
   Number of active neurons: 9
 >> iter 41000, loss: 0.385505
 >> iter 42000, loss: 0.417887
 >> iter 43000, loss: 0.278990
 >> iter 44000, loss: 0.361841
 >> iter 45000, loss: 0.357511
 >> iter 46000, loss: 0.239705
 >> iter 47000, loss: 0.622664
 >> iter 48000, loss: 0.472863
 >> iter 49000, loss: 0.352523
 >> iter 50000, loss: 0.274514
   Number of active neurons: 9
 >> iter 51000, loss: 0.308830
 >> iter 52000, loss: 0.215170
 >> iter 53000, loss: 0.202756
 >> iter 54000, loss: 0.321490
 >> iter 55000, loss: 0.363242
 >> iter 56000, loss: 0.254425
 >> iter 57000, loss: 0.212238
 >> iter 58000, loss: 0.231138
 >> iter 59000, loss: 0.373604
 >> iter 60000, loss: 0.268605
   Number of active neurons: 9
 >> iter 61000, loss: 0.398527
 >> iter 62000, loss: 0.347597
 >> iter 63000, loss: 0.299731
 >> iter 64000, loss: 0.369774
 >> iter 65000, loss: 0.287625
 >> iter 66000, loss: 0.238426
 >> iter 67000, loss: 0.220600
 >> iter 68000, loss: 0.251574
 >> iter 69000, loss: 0.262194
 >> iter 70000, loss: 0.290787
   Number of active neurons: 8
 >> iter 71000, loss: 0.301859
 >> iter 72000, loss: 0.319049
 >> iter 73000, loss: 0.613167
 >> iter 74000, loss: 0.327072
 >> iter 75000, loss: 0.240578
 >> iter 76000, loss: 0.341628
 >> iter 77000, loss: 0.320184
 >> iter 78000, loss: 0.281127
 >> iter 79000, loss: 0.268796
 >> iter 80000, loss: 0.347890
   Number of active neurons: 8
 >> iter 81000, loss: 0.248725
 >> iter 82000, loss: 0.322234
 >> iter 83000, loss: 0.346614
 >> iter 84000, loss: 0.360128
 >> iter 85000, loss: 0.812527
 >> iter 86000, loss: 0.424969
 >> iter 87000, loss: 0.349659
 >> iter 88000, loss: 0.414249
 >> iter 89000, loss: 0.309284
 >> iter 90000, loss: 0.361729
   Number of active neurons: 8
 >> iter 91000, loss: 0.434171
 >> iter 92000, loss: 0.259491
 >> iter 93000, loss: 0.510494
 >> iter 94000, loss: 0.268587
 >> iter 95000, loss: 0.340497
 >> iter 96000, loss: 0.279903
 >> iter 97000, loss: 0.426640
 >> iter 98000, loss: 0.256729
 >> iter 99000, loss: 0.193681
 >> iter 100000, loss: 0.217752
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.109107
 >> iter 2000, loss: 10.960490
 >> iter 3000, loss: 5.405448
 >> iter 4000, loss: 2.901465
 >> iter 5000, loss: 1.547994
 >> iter 6000, loss: 1.207153
 >> iter 7000, loss: 1.178999
 >> iter 8000, loss: 1.106687
 >> iter 9000, loss: 0.802020
 >> iter 10000, loss: 0.642782
   Number of active neurons: 6
 >> iter 11000, loss: 0.640943
 >> iter 12000, loss: 0.586856
 >> iter 13000, loss: 0.533504
 >> iter 14000, loss: 0.494422
 >> iter 15000, loss: 0.502863
 >> iter 16000, loss: 0.572482
 >> iter 17000, loss: 0.668392
 >> iter 18000, loss: 0.703691
 >> iter 19000, loss: 0.578692
 >> iter 20000, loss: 0.488551
   Number of active neurons: 6
 >> iter 21000, loss: 0.597014
 >> iter 22000, loss: 0.554396
 >> iter 23000, loss: 0.481044
 >> iter 24000, loss: 0.419123
 >> iter 25000, loss: 0.650133
 >> iter 26000, loss: 0.478114
 >> iter 27000, loss: 0.686881
 >> iter 28000, loss: 0.699288
 >> iter 29000, loss: 0.723137
 >> iter 30000, loss: 0.668534
   Number of active neurons: 6
 >> iter 31000, loss: 0.707921
 >> iter 32000, loss: 0.614751
 >> iter 33000, loss: 0.561646
 >> iter 34000, loss: 0.510550
 >> iter 35000, loss: 0.700930
 >> iter 36000, loss: 0.493144
 >> iter 37000, loss: 0.466339
 >> iter 38000, loss: 0.411139
 >> iter 39000, loss: 0.503758
 >> iter 40000, loss: 0.562230
   Number of active neurons: 6
 >> iter 41000, loss: 0.631642
 >> iter 42000, loss: 0.633993
 >> iter 43000, loss: 0.529693
 >> iter 44000, loss: 0.419167
 >> iter 45000, loss: 0.501083
 >> iter 46000, loss: 0.600608
 >> iter 47000, loss: 0.641047
 >> iter 48000, loss: 0.523356
 >> iter 49000, loss: 0.455275
 >> iter 50000, loss: 0.444377
   Number of active neurons: 6
 >> iter 51000, loss: 0.444359
 >> iter 52000, loss: 0.482713
 >> iter 53000, loss: 0.530249
 >> iter 54000, loss: 0.597991
 >> iter 55000, loss: 0.589243
 >> iter 56000, loss: 0.450112
 >> iter 57000, loss: 0.517885
 >> iter 58000, loss: 0.356893
 >> iter 59000, loss: 0.523267
 >> iter 60000, loss: 0.665049
   Number of active neurons: 6
 >> iter 61000, loss: 0.540106
 >> iter 62000, loss: 0.457851
 >> iter 63000, loss: 0.641421
 >> iter 64000, loss: 0.486038
 >> iter 65000, loss: 0.371528
 >> iter 66000, loss: 0.487903
 >> iter 67000, loss: 0.575383
 >> iter 68000, loss: 0.510572
 >> iter 69000, loss: 0.690749
 >> iter 70000, loss: 0.502636
   Number of active neurons: 6
 >> iter 71000, loss: 0.596012
 >> iter 72000, loss: 0.537657
 >> iter 73000, loss: 0.505028
 >> iter 74000, loss: 0.523624
 >> iter 75000, loss: 0.527672
 >> iter 76000, loss: 0.517511
 >> iter 77000, loss: 0.416890
 >> iter 78000, loss: 0.421236
 >> iter 79000, loss: 0.641914
 >> iter 80000, loss: 0.617831
   Number of active neurons: 6
 >> iter 81000, loss: 0.650329
 >> iter 82000, loss: 0.487142
 >> iter 83000, loss: 0.483672
 >> iter 84000, loss: 0.511030
 >> iter 85000, loss: 0.503192
 >> iter 86000, loss: 0.326664
 >> iter 87000, loss: 0.527546
 >> iter 88000, loss: 0.387138
 >> iter 89000, loss: 0.382202
 >> iter 90000, loss: 0.380025
   Number of active neurons: 6
 >> iter 91000, loss: 0.460216
 >> iter 92000, loss: 0.431462
 >> iter 93000, loss: 0.453992
 >> iter 94000, loss: 0.638052
 >> iter 95000, loss: 0.678671
 >> iter 96000, loss: 0.417520
 >> iter 97000, loss: 0.344971
 >> iter 98000, loss: 0.471338
 >> iter 99000, loss: 0.523343
 >> iter 100000, loss: 0.571812
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 19.164233
 >> iter 2000, loss: 11.033679
 >> iter 3000, loss: 4.918023
 >> iter 4000, loss: 2.153373
 >> iter 5000, loss: 0.946360
 >> iter 6000, loss: 0.632069
 >> iter 7000, loss: 0.328052
 >> iter 8000, loss: 0.343555
 >> iter 9000, loss: 0.362586
 >> iter 10000, loss: 0.239791
   Number of active neurons: 10
 >> iter 11000, loss: 0.177913
 >> iter 12000, loss: 0.176212
 >> iter 13000, loss: 0.323549
 >> iter 14000, loss: 0.218796
 >> iter 15000, loss: 0.453071
 >> iter 16000, loss: 0.457442
 >> iter 17000, loss: 0.350372
 >> iter 18000, loss: 0.258603
 >> iter 19000, loss: 0.298825
 >> iter 20000, loss: 0.228094
   Number of active neurons: 9
 >> iter 21000, loss: 0.346210
 >> iter 22000, loss: 0.342043
 >> iter 23000, loss: 0.356987
 >> iter 24000, loss: 0.226518
 >> iter 25000, loss: 0.168186
 >> iter 26000, loss: 0.284476
 >> iter 27000, loss: 0.191608
 >> iter 28000, loss: 0.260281
 >> iter 29000, loss: 0.259183
 >> iter 30000, loss: 0.330829
   Number of active neurons: 9
 >> iter 31000, loss: 0.382150
 >> iter 32000, loss: 0.261146
 >> iter 33000, loss: 0.234704
 >> iter 34000, loss: 0.200096
 >> iter 35000, loss: 0.202775
 >> iter 36000, loss: 0.281070
 >> iter 37000, loss: 0.261785
 >> iter 38000, loss: 0.157412
 >> iter 39000, loss: 0.130695
 >> iter 40000, loss: 0.095929
   Number of active neurons: 6
 >> iter 41000, loss: 0.131916
 >> iter 42000, loss: 0.105229
 >> iter 43000, loss: 0.145003
 >> iter 44000, loss: 0.144172
 >> iter 45000, loss: 0.173270
 >> iter 46000, loss: 0.175573
 >> iter 47000, loss: 0.200389
 >> iter 48000, loss: 0.146901
 >> iter 49000, loss: 0.185636
 >> iter 50000, loss: 0.285732
   Number of active neurons: 6
 >> iter 51000, loss: 0.211582
 >> iter 52000, loss: 0.234074
 >> iter 53000, loss: 0.150990
 >> iter 54000, loss: 0.162814
 >> iter 55000, loss: 0.251710
 >> iter 56000, loss: 0.243236
 >> iter 57000, loss: 0.150442
 >> iter 58000, loss: 0.165757
 >> iter 59000, loss: 0.143147
 >> iter 60000, loss: 0.208698
   Number of active neurons: 6
 >> iter 61000, loss: 0.175746
 >> iter 62000, loss: 0.253371
 >> iter 63000, loss: 0.204662
 >> iter 64000, loss: 0.282097
 >> iter 65000, loss: 0.238244
 >> iter 66000, loss: 0.276052
 >> iter 67000, loss: 0.244726
 >> iter 68000, loss: 0.199010
 >> iter 69000, loss: 0.124527
 >> iter 70000, loss: 0.152688
   Number of active neurons: 6
 >> iter 71000, loss: 0.200064
 >> iter 72000, loss: 0.235966
 >> iter 73000, loss: 0.188975
 >> iter 74000, loss: 0.148973
 >> iter 75000, loss: 0.223719
 >> iter 76000, loss: 0.209043
 >> iter 77000, loss: 0.170464
 >> iter 78000, loss: 0.226495
 >> iter 79000, loss: 0.231483
 >> iter 80000, loss: 0.249606
   Number of active neurons: 6
 >> iter 81000, loss: 0.170723
 >> iter 82000, loss: 0.177737
 >> iter 83000, loss: 0.255744
 >> iter 84000, loss: 0.153514
 >> iter 85000, loss: 0.197609
 >> iter 86000, loss: 0.207011
 >> iter 87000, loss: 0.134821
 >> iter 88000, loss: 0.182385
 >> iter 89000, loss: 0.204978
 >> iter 90000, loss: 0.202790
   Number of active neurons: 6
 >> iter 91000, loss: 0.180208
 >> iter 92000, loss: 0.321262
 >> iter 93000, loss: 0.379045
 >> iter 94000, loss: 0.282509
 >> iter 95000, loss: 0.188297
 >> iter 96000, loss: 0.316051
 >> iter 97000, loss: 0.199677
 >> iter 98000, loss: 0.267049
 >> iter 99000, loss: 0.253400
 >> iter 100000, loss: 0.193948
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

