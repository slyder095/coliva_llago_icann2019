 > Problema: tomita7nueva
 > Args:
   - Hidden size: 18
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455181
   Number of active neurons: 0
 >> iter 1000, loss: 17.293265
 >> iter 2000, loss: 9.722001
 >> iter 3000, loss: 5.626944
 >> iter 4000, loss: 2.774422
 >> iter 5000, loss: 1.436916
 >> iter 6000, loss: 0.804353
 >> iter 7000, loss: 0.532394
 >> iter 8000, loss: 0.464104
 >> iter 9000, loss: 0.594691
 >> iter 10000, loss: 0.456237
   Number of active neurons: 9
 >> iter 11000, loss: 0.429530
 >> iter 12000, loss: 0.384184
 >> iter 13000, loss: 0.304763
 >> iter 14000, loss: 0.306093
 >> iter 15000, loss: 0.398432
 >> iter 16000, loss: 0.424192
 >> iter 17000, loss: 0.316455
 >> iter 18000, loss: 0.359630
 >> iter 19000, loss: 0.425056
 >> iter 20000, loss: 0.347786
   Number of active neurons: 9
 >> iter 21000, loss: 0.296125
 >> iter 22000, loss: 0.351467
 >> iter 23000, loss: 0.443047
 >> iter 24000, loss: 0.271902
 >> iter 25000, loss: 0.294258
 >> iter 26000, loss: 0.267278
 >> iter 27000, loss: 0.333911
 >> iter 28000, loss: 0.376544
 >> iter 29000, loss: 0.292260
 >> iter 30000, loss: 0.319070
   Number of active neurons: 9
 >> iter 31000, loss: 0.269187
 >> iter 32000, loss: 0.238266
 >> iter 33000, loss: 0.195721
 >> iter 34000, loss: 0.163807
 >> iter 35000, loss: 0.205056
 >> iter 36000, loss: 0.259930
 >> iter 37000, loss: 0.270810
 >> iter 38000, loss: 0.201837
 >> iter 39000, loss: 0.242649
 >> iter 40000, loss: 0.175794
   Number of active neurons: 9
 >> iter 41000, loss: 0.249331
 >> iter 42000, loss: 0.229633
 >> iter 43000, loss: 0.301225
 >> iter 44000, loss: 0.217052
 >> iter 45000, loss: 0.236608
 >> iter 46000, loss: 0.194786
 >> iter 47000, loss: 0.241780
 >> iter 48000, loss: 0.203119
 >> iter 49000, loss: 0.266943
 >> iter 50000, loss: 0.205671
   Number of active neurons: 9
 >> iter 51000, loss: 0.268853
 >> iter 52000, loss: 0.172742
 >> iter 53000, loss: 0.195381
 >> iter 54000, loss: 0.184820
 >> iter 55000, loss: 0.267632
 >> iter 56000, loss: 0.273497
 >> iter 57000, loss: 0.178156
 >> iter 58000, loss: 0.186173
 >> iter 59000, loss: 0.203850
 >> iter 60000, loss: 0.227613
   Number of active neurons: 9
 >> iter 61000, loss: 0.229484
 >> iter 62000, loss: 0.265516
 >> iter 63000, loss: 0.193878
 >> iter 64000, loss: 0.351735
 >> iter 65000, loss: 0.338629
 >> iter 66000, loss: 0.286244
 >> iter 67000, loss: 0.241652
 >> iter 68000, loss: 0.256962
 >> iter 69000, loss: 0.229554
 >> iter 70000, loss: 0.248361
   Number of active neurons: 9
 >> iter 71000, loss: 0.218307
 >> iter 72000, loss: 0.239145
 >> iter 73000, loss: 0.148561
 >> iter 74000, loss: 0.279721
 >> iter 75000, loss: 0.254067
 >> iter 76000, loss: 0.236009
 >> iter 77000, loss: 0.306509
 >> iter 78000, loss: 0.319210
 >> iter 79000, loss: 0.312546
 >> iter 80000, loss: 0.220224
   Number of active neurons: 8
 >> iter 81000, loss: 0.211349
 >> iter 82000, loss: 0.243440
 >> iter 83000, loss: 0.201335
 >> iter 84000, loss: 0.214133
 >> iter 85000, loss: 0.261374
 >> iter 86000, loss: 0.275388
 >> iter 87000, loss: 0.271387
 >> iter 88000, loss: 0.298326
 >> iter 89000, loss: 0.288840
 >> iter 90000, loss: 0.259314
   Number of active neurons: 8
 >> iter 91000, loss: 0.258620
 >> iter 92000, loss: 0.307084
 >> iter 93000, loss: 0.203858
 >> iter 94000, loss: 0.260965
 >> iter 95000, loss: 0.434580
 >> iter 96000, loss: 0.319799
 >> iter 97000, loss: 0.292930
 >> iter 98000, loss: 0.297056
 >> iter 99000, loss: 0.378904
 >> iter 100000, loss: 0.297269
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.626428
 >> iter 2000, loss: 9.425480
 >> iter 3000, loss: 4.186672
 >> iter 4000, loss: 1.832024
 >> iter 5000, loss: 0.937469
 >> iter 6000, loss: 0.474052
 >> iter 7000, loss: 0.424738
 >> iter 8000, loss: 0.453576
 >> iter 9000, loss: 0.371858
 >> iter 10000, loss: 0.339444
   Number of active neurons: 10
 >> iter 11000, loss: 0.321619
 >> iter 12000, loss: 0.213924
 >> iter 13000, loss: 0.216305
 >> iter 14000, loss: 0.244235
 >> iter 15000, loss: 0.365868
 >> iter 16000, loss: 0.288698
 >> iter 17000, loss: 0.256728
 >> iter 18000, loss: 0.300220
 >> iter 19000, loss: 0.251302
 >> iter 20000, loss: 0.263706
   Number of active neurons: 10
 >> iter 21000, loss: 0.218782
 >> iter 22000, loss: 0.172417
 >> iter 23000, loss: 0.239040
 >> iter 24000, loss: 0.258464
 >> iter 25000, loss: 0.232527
 >> iter 26000, loss: 0.233780
 >> iter 27000, loss: 0.332465
 >> iter 28000, loss: 0.258705
 >> iter 29000, loss: 0.317750
 >> iter 30000, loss: 0.274142
   Number of active neurons: 10
 >> iter 31000, loss: 0.317979
 >> iter 32000, loss: 0.344303
 >> iter 33000, loss: 0.271128
 >> iter 34000, loss: 0.296192
 >> iter 35000, loss: 0.282868
 >> iter 36000, loss: 0.253545
 >> iter 37000, loss: 0.326790
 >> iter 38000, loss: 0.280267
 >> iter 39000, loss: 0.276622
 >> iter 40000, loss: 0.376356
   Number of active neurons: 10
 >> iter 41000, loss: 0.429736
 >> iter 42000, loss: 0.334257
 >> iter 43000, loss: 0.329610
 >> iter 44000, loss: 0.257414
 >> iter 45000, loss: 0.424102
 >> iter 46000, loss: 0.292700
 >> iter 47000, loss: 0.296186
 >> iter 48000, loss: 0.269518
 >> iter 49000, loss: 0.368454
 >> iter 50000, loss: 0.307596
   Number of active neurons: 9
 >> iter 51000, loss: 0.313989
 >> iter 52000, loss: 0.310728
 >> iter 53000, loss: 0.278989
 >> iter 54000, loss: 0.260719
 >> iter 55000, loss: 0.279287
 >> iter 56000, loss: 0.343014
 >> iter 57000, loss: 0.321420
 >> iter 58000, loss: 0.294699
 >> iter 59000, loss: 0.246542
 >> iter 60000, loss: 0.289552
   Number of active neurons: 6
 >> iter 61000, loss: 0.374681
 >> iter 62000, loss: 0.325327
 >> iter 63000, loss: 0.368417
 >> iter 64000, loss: 0.250391
 >> iter 65000, loss: 0.257458
 >> iter 66000, loss: 0.234432
 >> iter 67000, loss: 0.345238
 >> iter 68000, loss: 0.289791
 >> iter 69000, loss: 0.314508
 >> iter 70000, loss: 0.341234
   Number of active neurons: 6
 >> iter 71000, loss: 0.247650
 >> iter 72000, loss: 0.275921
 >> iter 73000, loss: 0.240398
 >> iter 74000, loss: 0.235745
 >> iter 75000, loss: 0.343810
 >> iter 76000, loss: 0.204086
 >> iter 77000, loss: 0.211480
 >> iter 78000, loss: 0.216729
 >> iter 79000, loss: 0.245426
 >> iter 80000, loss: 0.235868
   Number of active neurons: 6
 >> iter 81000, loss: 0.339393
 >> iter 82000, loss: 0.392496
 >> iter 83000, loss: 0.367631
 >> iter 84000, loss: 0.357334
 >> iter 85000, loss: 0.373220
 >> iter 86000, loss: 0.289345
 >> iter 87000, loss: 0.366571
 >> iter 88000, loss: 0.277558
 >> iter 89000, loss: 0.328563
 >> iter 90000, loss: 0.284536
   Number of active neurons: 6
 >> iter 91000, loss: 0.372904
 >> iter 92000, loss: 0.362959
 >> iter 93000, loss: 0.355710
 >> iter 94000, loss: 0.353084
 >> iter 95000, loss: 0.338156
 >> iter 96000, loss: 0.297935
 >> iter 97000, loss: 0.368509
 >> iter 98000, loss: 0.332824
 >> iter 99000, loss: 0.360120
 >> iter 100000, loss: 0.343063
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455160
   Number of active neurons: 0
 >> iter 1000, loss: 16.187039
 >> iter 2000, loss: 9.305513
 >> iter 3000, loss: 5.830317
 >> iter 4000, loss: 3.715692
 >> iter 5000, loss: 2.222406
 >> iter 6000, loss: 1.574663
 >> iter 7000, loss: 1.323172
 >> iter 8000, loss: 1.035499
 >> iter 9000, loss: 1.143486
 >> iter 10000, loss: 0.968937
   Number of active neurons: 7
 >> iter 11000, loss: 0.902559
 >> iter 12000, loss: 0.891154
 >> iter 13000, loss: 0.659306
 >> iter 14000, loss: 0.534746
 >> iter 15000, loss: 0.503904
 >> iter 16000, loss: 0.564104
 >> iter 17000, loss: 0.606707
 >> iter 18000, loss: 0.377989
 >> iter 19000, loss: 0.559026
 >> iter 20000, loss: 0.569748
   Number of active neurons: 7
 >> iter 21000, loss: 0.493392
 >> iter 22000, loss: 0.486750
 >> iter 23000, loss: 0.483895
 >> iter 24000, loss: 0.402483
 >> iter 25000, loss: 0.444085
 >> iter 26000, loss: 0.407189
 >> iter 27000, loss: 0.541429
 >> iter 28000, loss: 0.597082
 >> iter 29000, loss: 0.513709
 >> iter 30000, loss: 0.457026
   Number of active neurons: 7
 >> iter 31000, loss: 0.448827
 >> iter 32000, loss: 0.573039
 >> iter 33000, loss: 0.586798
 >> iter 34000, loss: 0.525657
 >> iter 35000, loss: 0.463901
 >> iter 36000, loss: 0.607605
 >> iter 37000, loss: 0.465841
 >> iter 38000, loss: 0.447458
 >> iter 39000, loss: 0.353113
 >> iter 40000, loss: 0.391381
   Number of active neurons: 6
 >> iter 41000, loss: 0.486995
 >> iter 42000, loss: 0.524104
 >> iter 43000, loss: 0.580924
 >> iter 44000, loss: 0.442885
 >> iter 45000, loss: 0.609567
 >> iter 46000, loss: 0.526416
 >> iter 47000, loss: 0.598568
 >> iter 48000, loss: 0.482334
 >> iter 49000, loss: 0.549396
 >> iter 50000, loss: 0.395131
   Number of active neurons: 6
 >> iter 51000, loss: 0.503562
 >> iter 52000, loss: 0.516881
 >> iter 53000, loss: 0.435709
 >> iter 54000, loss: 0.423024
 >> iter 55000, loss: 0.399050
 >> iter 56000, loss: 0.382784
 >> iter 57000, loss: 0.480924
 >> iter 58000, loss: 0.542555
 >> iter 59000, loss: 0.503766
 >> iter 60000, loss: 0.516061
   Number of active neurons: 6
 >> iter 61000, loss: 0.645332
 >> iter 62000, loss: 0.550165
 >> iter 63000, loss: 0.538470
 >> iter 64000, loss: 0.476816
 >> iter 65000, loss: 0.528061
 >> iter 66000, loss: 0.482506
 >> iter 67000, loss: 0.615926
 >> iter 68000, loss: 0.528171
 >> iter 69000, loss: 0.625927
 >> iter 70000, loss: 0.636174
   Number of active neurons: 5
 >> iter 71000, loss: 0.546767
 >> iter 72000, loss: 0.455349
 >> iter 73000, loss: 0.433396
 >> iter 74000, loss: 0.473136
 >> iter 75000, loss: 0.542655
 >> iter 76000, loss: 0.559597
 >> iter 77000, loss: 0.607680
 >> iter 78000, loss: 0.664309
 >> iter 79000, loss: 0.683348
 >> iter 80000, loss: 0.529687
   Number of active neurons: 7
 >> iter 81000, loss: 0.663850
 >> iter 82000, loss: 0.472359
 >> iter 83000, loss: 0.562498
 >> iter 84000, loss: 0.449937
 >> iter 85000, loss: 0.715628
 >> iter 86000, loss: 0.648909
 >> iter 87000, loss: 0.523800
 >> iter 88000, loss: 0.674909
 >> iter 89000, loss: 0.531517
 >> iter 90000, loss: 0.471565
   Number of active neurons: 4
 >> iter 91000, loss: 0.541183
 >> iter 92000, loss: 0.443297
 >> iter 93000, loss: 0.449658
 >> iter 94000, loss: 0.401656
 >> iter 95000, loss: 0.463718
 >> iter 96000, loss: 0.525702
 >> iter 97000, loss: 0.425863
 >> iter 98000, loss: 0.512292
 >> iter 99000, loss: 0.447252
 >> iter 100000, loss: 0.505560
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.512773
 >> iter 2000, loss: 9.789064
 >> iter 3000, loss: 5.854548
 >> iter 4000, loss: 2.869545
 >> iter 5000, loss: 1.398593
 >> iter 6000, loss: 0.865298
 >> iter 7000, loss: 0.495330
 >> iter 8000, loss: 0.461890
 >> iter 9000, loss: 0.471614
 >> iter 10000, loss: 0.442894
   Number of active neurons: 9
 >> iter 11000, loss: 0.406044
 >> iter 12000, loss: 0.303979
 >> iter 13000, loss: 0.345582
 >> iter 14000, loss: 0.247288
 >> iter 15000, loss: 0.276852
 >> iter 16000, loss: 0.315240
 >> iter 17000, loss: 0.298077
 >> iter 18000, loss: 0.344993
 >> iter 19000, loss: 0.322546
 >> iter 20000, loss: 0.463713
   Number of active neurons: 9
 >> iter 21000, loss: 0.391251
 >> iter 22000, loss: 0.429637
 >> iter 23000, loss: 0.355788
 >> iter 24000, loss: 0.288228
 >> iter 25000, loss: 0.323722
 >> iter 26000, loss: 0.391224
 >> iter 27000, loss: 0.345208
 >> iter 28000, loss: 0.337365
 >> iter 29000, loss: 0.315885
 >> iter 30000, loss: 0.374788
   Number of active neurons: 9
 >> iter 31000, loss: 0.457709
 >> iter 32000, loss: 0.332258
 >> iter 33000, loss: 0.353417
 >> iter 34000, loss: 0.423279
 >> iter 35000, loss: 0.438133
 >> iter 36000, loss: 0.334840
 >> iter 37000, loss: 0.298555
 >> iter 38000, loss: 0.312946
 >> iter 39000, loss: 0.366921
 >> iter 40000, loss: 0.453721
   Number of active neurons: 9
 >> iter 41000, loss: 0.408970
 >> iter 42000, loss: 0.315389
 >> iter 43000, loss: 0.309245
 >> iter 44000, loss: 0.274278
 >> iter 45000, loss: 0.343610
 >> iter 46000, loss: 0.280276
 >> iter 47000, loss: 0.390725
 >> iter 48000, loss: 0.314323
 >> iter 49000, loss: 0.402875
 >> iter 50000, loss: 0.278085
   Number of active neurons: 9
 >> iter 51000, loss: 0.225851
 >> iter 52000, loss: 0.231824
 >> iter 53000, loss: 0.409327
 >> iter 54000, loss: 0.407633
 >> iter 55000, loss: 0.363286
 >> iter 56000, loss: 0.324384
 >> iter 57000, loss: 0.368320
 >> iter 58000, loss: 0.279707
 >> iter 59000, loss: 0.224416
 >> iter 60000, loss: 0.306039
   Number of active neurons: 9
 >> iter 61000, loss: 0.326245
 >> iter 62000, loss: 0.449840
 >> iter 63000, loss: 0.295760
 >> iter 64000, loss: 0.347918
 >> iter 65000, loss: 0.405682
 >> iter 66000, loss: 0.302343
 >> iter 67000, loss: 0.201477
 >> iter 68000, loss: 0.297424
 >> iter 69000, loss: 0.360212
 >> iter 70000, loss: 0.398427
   Number of active neurons: 9
 >> iter 71000, loss: 0.272019
 >> iter 72000, loss: 0.354888
 >> iter 73000, loss: 0.326323
 >> iter 74000, loss: 0.255046
 >> iter 75000, loss: 0.307719
 >> iter 76000, loss: 0.387012
 >> iter 77000, loss: 0.319669
 >> iter 78000, loss: 0.245058
 >> iter 79000, loss: 0.294279
 >> iter 80000, loss: 0.291700
   Number of active neurons: 9
 >> iter 81000, loss: 0.274006
 >> iter 82000, loss: 0.341288
 >> iter 83000, loss: 0.318891
 >> iter 84000, loss: 0.302698
 >> iter 85000, loss: 0.332130
 >> iter 86000, loss: 0.327362
 >> iter 87000, loss: 0.346214
 >> iter 88000, loss: 0.449522
 >> iter 89000, loss: 0.316595
 >> iter 90000, loss: 0.263034
   Number of active neurons: 9
 >> iter 91000, loss: 0.334713
 >> iter 92000, loss: 0.282473
 >> iter 93000, loss: 0.247475
 >> iter 94000, loss: 0.301561
 >> iter 95000, loss: 0.271187
 >> iter 96000, loss: 0.391064
 >> iter 97000, loss: 0.323344
 >> iter 98000, loss: 0.302282
 >> iter 99000, loss: 0.331017
 >> iter 100000, loss: 0.249427
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 16.318322
 >> iter 2000, loss: 9.761622
 >> iter 3000, loss: 6.051714
 >> iter 4000, loss: 3.440126
 >> iter 5000, loss: 1.993289
 >> iter 6000, loss: 1.198242
 >> iter 7000, loss: 0.897074
 >> iter 8000, loss: 0.704970
 >> iter 9000, loss: 0.432168
 >> iter 10000, loss: 0.294337
   Number of active neurons: 7
 >> iter 11000, loss: 0.431812
 >> iter 12000, loss: 0.332923
 >> iter 13000, loss: 0.369620
 >> iter 14000, loss: 0.350625
 >> iter 15000, loss: 0.365920
 >> iter 16000, loss: 0.353301
 >> iter 17000, loss: 0.345570
 >> iter 18000, loss: 0.307606
 >> iter 19000, loss: 0.264218
 >> iter 20000, loss: 0.302329
   Number of active neurons: 7
 >> iter 21000, loss: 0.302154
 >> iter 22000, loss: 0.207971
 >> iter 23000, loss: 0.260415
 >> iter 24000, loss: 0.344583
 >> iter 25000, loss: 0.337743
 >> iter 26000, loss: 0.397100
 >> iter 27000, loss: 0.289131
 >> iter 28000, loss: 0.349649
 >> iter 29000, loss: 0.235351
 >> iter 30000, loss: 0.219889
   Number of active neurons: 6
 >> iter 31000, loss: 0.224020
 >> iter 32000, loss: 0.284413
 >> iter 33000, loss: 0.271955
 >> iter 34000, loss: 0.314318
 >> iter 35000, loss: 0.345160
 >> iter 36000, loss: 0.288661
 >> iter 37000, loss: 0.342918
 >> iter 38000, loss: 0.263057
 >> iter 39000, loss: 0.228472
 >> iter 40000, loss: 0.179335
   Number of active neurons: 6
 >> iter 41000, loss: 0.318436
 >> iter 42000, loss: 0.373138
 >> iter 43000, loss: 0.393398
 >> iter 44000, loss: 0.333701
 >> iter 45000, loss: 0.513372
 >> iter 46000, loss: 0.477570
 >> iter 47000, loss: 0.383969
 >> iter 48000, loss: 0.503269
 >> iter 49000, loss: 0.474897
 >> iter 50000, loss: 0.302335
   Number of active neurons: 5
 >> iter 51000, loss: 0.220290
 >> iter 52000, loss: 0.288668
 >> iter 53000, loss: 0.313144
 >> iter 54000, loss: 0.351188
 >> iter 55000, loss: 0.344342
 >> iter 56000, loss: 0.277979
 >> iter 57000, loss: 0.308817
 >> iter 58000, loss: 0.362594
 >> iter 59000, loss: 0.433993
 >> iter 60000, loss: 0.423974
   Number of active neurons: 5
 >> iter 61000, loss: 0.420515
 >> iter 62000, loss: 0.333031
 >> iter 63000, loss: 0.317795
 >> iter 64000, loss: 0.304277
 >> iter 65000, loss: 0.278499
 >> iter 66000, loss: 0.309747
 >> iter 67000, loss: 0.307124
 >> iter 68000, loss: 0.368328
 >> iter 69000, loss: 0.393114
 >> iter 70000, loss: 0.346417
   Number of active neurons: 5
 >> iter 71000, loss: 0.380683
 >> iter 72000, loss: 0.299332
 >> iter 73000, loss: 0.398318
 >> iter 74000, loss: 0.308806
 >> iter 75000, loss: 0.302238
 >> iter 76000, loss: 0.273435
 >> iter 77000, loss: 0.465181
 >> iter 78000, loss: 0.389450
 >> iter 79000, loss: 0.303708
 >> iter 80000, loss: 0.361705
   Number of active neurons: 5
 >> iter 81000, loss: 0.384266
 >> iter 82000, loss: 0.289138
 >> iter 83000, loss: 0.328028
 >> iter 84000, loss: 0.295795
 >> iter 85000, loss: 0.360240
 >> iter 86000, loss: 0.323816
 >> iter 87000, loss: 0.434643
 >> iter 88000, loss: 0.419802
 >> iter 89000, loss: 0.435210
 >> iter 90000, loss: 0.279467
   Number of active neurons: 5
 >> iter 91000, loss: 0.267612
 >> iter 92000, loss: 0.297689
 >> iter 93000, loss: 0.301746
 >> iter 94000, loss: 0.312683
 >> iter 95000, loss: 0.250830
 >> iter 96000, loss: 0.337853
 >> iter 97000, loss: 0.479630
 >> iter 98000, loss: 0.496169
 >> iter 99000, loss: 0.414789
 >> iter 100000, loss: 0.426270
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.735681
 >> iter 2000, loss: 9.426719
 >> iter 3000, loss: 4.709428
 >> iter 4000, loss: 2.482586
 >> iter 5000, loss: 1.167929
 >> iter 6000, loss: 0.853498
 >> iter 7000, loss: 0.519591
 >> iter 8000, loss: 0.473428
 >> iter 9000, loss: 0.406410
 >> iter 10000, loss: 0.452979
   Number of active neurons: 8
 >> iter 11000, loss: 0.410616
 >> iter 12000, loss: 0.311391
 >> iter 13000, loss: 0.307279
 >> iter 14000, loss: 0.277311
 >> iter 15000, loss: 0.338968
 >> iter 16000, loss: 0.305009
 >> iter 17000, loss: 0.372664
 >> iter 18000, loss: 0.324842
 >> iter 19000, loss: 0.399275
 >> iter 20000, loss: 0.310288
   Number of active neurons: 8
 >> iter 21000, loss: 0.350592
 >> iter 22000, loss: 0.288690
 >> iter 23000, loss: 0.416040
 >> iter 24000, loss: 0.289341
 >> iter 25000, loss: 0.296362
 >> iter 26000, loss: 0.318682
 >> iter 27000, loss: 0.323302
 >> iter 28000, loss: 0.338843
 >> iter 29000, loss: 0.288979
 >> iter 30000, loss: 0.286796
   Number of active neurons: 7
 >> iter 31000, loss: 0.263379
 >> iter 32000, loss: 0.430197
 >> iter 33000, loss: 0.403890
 >> iter 34000, loss: 0.409441
 >> iter 35000, loss: 0.283973
 >> iter 36000, loss: 0.391444
 >> iter 37000, loss: 0.477581
 >> iter 38000, loss: 0.405837
 >> iter 39000, loss: 0.256350
 >> iter 40000, loss: 0.264078
   Number of active neurons: 7
 >> iter 41000, loss: 0.289976
 >> iter 42000, loss: 0.299283
 >> iter 43000, loss: 0.352899
 >> iter 44000, loss: 0.480031
 >> iter 45000, loss: 0.321603
 >> iter 46000, loss: 0.307062
 >> iter 47000, loss: 0.279071
 >> iter 48000, loss: 0.284795
 >> iter 49000, loss: 0.243796
 >> iter 50000, loss: 0.252017
   Number of active neurons: 7
 >> iter 51000, loss: 0.393234
 >> iter 52000, loss: 0.400342
 >> iter 53000, loss: 0.445359
 >> iter 54000, loss: 0.362383
 >> iter 55000, loss: 0.383391
 >> iter 56000, loss: 0.408279
 >> iter 57000, loss: 0.312213
 >> iter 58000, loss: 0.317112
 >> iter 59000, loss: 0.321064
 >> iter 60000, loss: 0.316208
   Number of active neurons: 7
 >> iter 61000, loss: 0.296650
 >> iter 62000, loss: 0.191608
 >> iter 63000, loss: 0.263084
 >> iter 64000, loss: 0.315800
 >> iter 65000, loss: 0.354903
 >> iter 66000, loss: 0.314557
 >> iter 67000, loss: 0.350658
 >> iter 68000, loss: 0.322812
 >> iter 69000, loss: 0.303530
 >> iter 70000, loss: 0.288479
   Number of active neurons: 7
 >> iter 71000, loss: 0.478180
 >> iter 72000, loss: 0.375520
 >> iter 73000, loss: 0.447280
 >> iter 74000, loss: 0.311867
 >> iter 75000, loss: 0.355533
 >> iter 76000, loss: 0.367255
 >> iter 77000, loss: 0.248747
 >> iter 78000, loss: 0.183410
 >> iter 79000, loss: 0.358676
 >> iter 80000, loss: 0.335935
   Number of active neurons: 7
 >> iter 81000, loss: 0.358745
 >> iter 82000, loss: 0.303220
 >> iter 83000, loss: 0.274041
 >> iter 84000, loss: 0.319752
 >> iter 85000, loss: 0.347504
 >> iter 86000, loss: 0.301043
 >> iter 87000, loss: 0.275796
 >> iter 88000, loss: 0.362568
 >> iter 89000, loss: 0.214584
 >> iter 90000, loss: 0.335066
   Number of active neurons: 7
 >> iter 91000, loss: 0.316233
 >> iter 92000, loss: 0.292593
 >> iter 93000, loss: 0.315684
 >> iter 94000, loss: 0.278424
 >> iter 95000, loss: 0.323343
 >> iter 96000, loss: 0.285021
 >> iter 97000, loss: 0.332883
 >> iter 98000, loss: 0.269025
 >> iter 99000, loss: 0.417815
 >> iter 100000, loss: 0.317502
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 16.207344
 >> iter 2000, loss: 9.173119
 >> iter 3000, loss: 4.667339
 >> iter 4000, loss: 2.328213
 >> iter 5000, loss: 1.300745
 >> iter 6000, loss: 0.787658
 >> iter 7000, loss: 0.743734
 >> iter 8000, loss: 0.616491
 >> iter 9000, loss: 0.448399
 >> iter 10000, loss: 0.391405
   Number of active neurons: 7
 >> iter 11000, loss: 0.406096
 >> iter 12000, loss: 0.407231
 >> iter 13000, loss: 0.336885
 >> iter 14000, loss: 0.370833
 >> iter 15000, loss: 0.297670
 >> iter 16000, loss: 0.558664
 >> iter 17000, loss: 0.325814
 >> iter 18000, loss: 0.261422
 >> iter 19000, loss: 0.285117
 >> iter 20000, loss: 0.360414
   Number of active neurons: 7
 >> iter 21000, loss: 0.352210
 >> iter 22000, loss: 0.378528
 >> iter 23000, loss: 0.508393
 >> iter 24000, loss: 0.472707
 >> iter 25000, loss: 0.352237
 >> iter 26000, loss: 0.353336
 >> iter 27000, loss: 0.216961
 >> iter 28000, loss: 0.217869
 >> iter 29000, loss: 0.252376
 >> iter 30000, loss: 0.328972
   Number of active neurons: 7
 >> iter 31000, loss: 0.295045
 >> iter 32000, loss: 0.317409
 >> iter 33000, loss: 0.383428
 >> iter 34000, loss: 0.300151
 >> iter 35000, loss: 0.326693
 >> iter 36000, loss: 0.340557
 >> iter 37000, loss: 0.280493
 >> iter 38000, loss: 0.326094
 >> iter 39000, loss: 0.312130
 >> iter 40000, loss: 0.294157
   Number of active neurons: 7
 >> iter 41000, loss: 0.336209
 >> iter 42000, loss: 0.270995
 >> iter 43000, loss: 0.398878
 >> iter 44000, loss: 0.335518
 >> iter 45000, loss: 0.390260
 >> iter 46000, loss: 0.337168
 >> iter 47000, loss: 0.421090
 >> iter 48000, loss: 0.301803
 >> iter 49000, loss: 0.351071
 >> iter 50000, loss: 0.314161
   Number of active neurons: 7
 >> iter 51000, loss: 0.423059
 >> iter 52000, loss: 0.435751
 >> iter 53000, loss: 0.432766
 >> iter 54000, loss: 0.411223
 >> iter 55000, loss: 0.406806
 >> iter 56000, loss: 0.358353
 >> iter 57000, loss: 0.282479
 >> iter 58000, loss: 0.293263
 >> iter 59000, loss: 0.314329
 >> iter 60000, loss: 0.481309
   Number of active neurons: 7
 >> iter 61000, loss: 0.442567
 >> iter 62000, loss: 0.302823
 >> iter 63000, loss: 0.229080
 >> iter 64000, loss: 0.207901
 >> iter 65000, loss: 0.320625
 >> iter 66000, loss: 0.359349
 >> iter 67000, loss: 0.330233
 >> iter 68000, loss: 0.372397
 >> iter 69000, loss: 0.418500
 >> iter 70000, loss: 0.414926
   Number of active neurons: 7
 >> iter 71000, loss: 0.424593
 >> iter 72000, loss: 0.455199
 >> iter 73000, loss: 0.385826
 >> iter 74000, loss: 0.411695
 >> iter 75000, loss: 0.388805
 >> iter 76000, loss: 0.439954
 >> iter 77000, loss: 0.378907
 >> iter 78000, loss: 0.270517
 >> iter 79000, loss: 0.216809
 >> iter 80000, loss: 0.262420
   Number of active neurons: 7
 >> iter 81000, loss: 0.265220
 >> iter 82000, loss: 0.161774
 >> iter 83000, loss: 0.282131
 >> iter 84000, loss: 0.267403
 >> iter 85000, loss: 0.404180
 >> iter 86000, loss: 0.426305
 >> iter 87000, loss: 0.399848
 >> iter 88000, loss: 0.339612
 >> iter 89000, loss: 0.312013
 >> iter 90000, loss: 0.459372
   Number of active neurons: 7
 >> iter 91000, loss: 0.428531
 >> iter 92000, loss: 0.433860
 >> iter 93000, loss: 0.434876
 >> iter 94000, loss: 0.424501
 >> iter 95000, loss: 0.383828
 >> iter 96000, loss: 0.298333
 >> iter 97000, loss: 0.339058
 >> iter 98000, loss: 0.422075
 >> iter 99000, loss: 0.360422
 >> iter 100000, loss: 0.442580
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.679854
 >> iter 2000, loss: 10.152808
 >> iter 3000, loss: 6.243580
 >> iter 4000, loss: 2.781112
 >> iter 5000, loss: 1.299137
 >> iter 6000, loss: 0.614268
 >> iter 7000, loss: 0.543669
 >> iter 8000, loss: 0.374082
 >> iter 9000, loss: 0.306138
 >> iter 10000, loss: 0.411984
   Number of active neurons: 16
 >> iter 11000, loss: 0.424112
 >> iter 12000, loss: 0.372912
 >> iter 13000, loss: 0.384928
 >> iter 14000, loss: 0.303749
 >> iter 15000, loss: 0.408282
 >> iter 16000, loss: 0.318802
 >> iter 17000, loss: 0.287319
 >> iter 18000, loss: 0.335640
 >> iter 19000, loss: 0.293081
 >> iter 20000, loss: 0.357285
   Number of active neurons: 13
 >> iter 21000, loss: 0.295420
 >> iter 22000, loss: 0.290789
 >> iter 23000, loss: 0.373027
 >> iter 24000, loss: 0.289361
 >> iter 25000, loss: 0.230867
 >> iter 26000, loss: 0.305736
 >> iter 27000, loss: 0.376493
 >> iter 28000, loss: 0.368855
 >> iter 29000, loss: 0.263744
 >> iter 30000, loss: 0.219063
   Number of active neurons: 11
 >> iter 31000, loss: 0.240579
 >> iter 32000, loss: 0.267860
 >> iter 33000, loss: 0.325802
 >> iter 34000, loss: 0.250272
 >> iter 35000, loss: 0.284287
 >> iter 36000, loss: 0.421191
 >> iter 37000, loss: 0.312819
 >> iter 38000, loss: 0.288368
 >> iter 39000, loss: 0.226234
 >> iter 40000, loss: 0.247599
   Number of active neurons: 10
 >> iter 41000, loss: 0.272065
 >> iter 42000, loss: 0.189342
 >> iter 43000, loss: 0.272754
 >> iter 44000, loss: 0.326733
 >> iter 45000, loss: 0.351273
 >> iter 46000, loss: 0.318164
 >> iter 47000, loss: 0.334945
 >> iter 48000, loss: 0.343635
 >> iter 49000, loss: 0.328068
 >> iter 50000, loss: 0.379372
   Number of active neurons: 10
 >> iter 51000, loss: 0.228571
 >> iter 52000, loss: 0.259257
 >> iter 53000, loss: 0.244551
 >> iter 54000, loss: 0.286846
 >> iter 55000, loss: 0.399420
 >> iter 56000, loss: 0.271910
 >> iter 57000, loss: 0.232849
 >> iter 58000, loss: 0.186114
 >> iter 59000, loss: 0.326520
 >> iter 60000, loss: 0.300312
   Number of active neurons: 10
 >> iter 61000, loss: 0.310966
 >> iter 62000, loss: 0.219982
 >> iter 63000, loss: 0.361382
 >> iter 64000, loss: 0.447051
 >> iter 65000, loss: 0.380229
 >> iter 66000, loss: 0.290984
 >> iter 67000, loss: 0.260758
 >> iter 68000, loss: 0.332846
 >> iter 69000, loss: 0.330746
 >> iter 70000, loss: 0.319025
   Number of active neurons: 10
 >> iter 71000, loss: 0.255117
 >> iter 72000, loss: 0.323614
 >> iter 73000, loss: 0.312311
 >> iter 74000, loss: 0.269428
 >> iter 75000, loss: 0.331075
 >> iter 76000, loss: 0.289403
 >> iter 77000, loss: 0.272166
 >> iter 78000, loss: 0.302530
 >> iter 79000, loss: 0.263743
 >> iter 80000, loss: 0.414766
   Number of active neurons: 8
 >> iter 81000, loss: 0.293665
 >> iter 82000, loss: 0.294395
 >> iter 83000, loss: 0.487257
 >> iter 84000, loss: 0.244126
 >> iter 85000, loss: 0.311519
 >> iter 86000, loss: 0.359620
 >> iter 87000, loss: 0.441643
 >> iter 88000, loss: 0.383037
 >> iter 89000, loss: 0.256038
 >> iter 90000, loss: 0.297542
   Number of active neurons: 8
 >> iter 91000, loss: 0.416263
 >> iter 92000, loss: 0.281302
 >> iter 93000, loss: 0.324939
 >> iter 94000, loss: 0.402637
 >> iter 95000, loss: 0.356282
 >> iter 96000, loss: 0.264587
 >> iter 97000, loss: 0.250669
 >> iter 98000, loss: 0.305337
 >> iter 99000, loss: 0.394561
 >> iter 100000, loss: 0.294191
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.500185
 >> iter 2000, loss: 9.384013
 >> iter 3000, loss: 5.445571
 >> iter 4000, loss: 2.944622
 >> iter 5000, loss: 1.748168
 >> iter 6000, loss: 1.187712
 >> iter 7000, loss: 0.907353
 >> iter 8000, loss: 1.005836
 >> iter 9000, loss: 0.655030
 >> iter 10000, loss: 0.710913
   Number of active neurons: 8
 >> iter 11000, loss: 0.747551
 >> iter 12000, loss: 0.556483
 >> iter 13000, loss: 0.437831
 >> iter 14000, loss: 0.369064
 >> iter 15000, loss: 0.498767
 >> iter 16000, loss: 0.418586
 >> iter 17000, loss: 0.407625
 >> iter 18000, loss: 0.475854
 >> iter 19000, loss: 0.491893
 >> iter 20000, loss: 0.342737
   Number of active neurons: 7
 >> iter 21000, loss: 0.335976
 >> iter 22000, loss: 0.382488
 >> iter 23000, loss: 0.433960
 >> iter 24000, loss: 0.530519
 >> iter 25000, loss: 0.485340
 >> iter 26000, loss: 0.425157
 >> iter 27000, loss: 0.364649
 >> iter 28000, loss: 0.309647
 >> iter 29000, loss: 0.328876
 >> iter 30000, loss: 0.352575
   Number of active neurons: 6
 >> iter 31000, loss: 0.420012
 >> iter 32000, loss: 0.607633
 >> iter 33000, loss: 0.669007
 >> iter 34000, loss: 0.553413
 >> iter 35000, loss: 0.571713
 >> iter 36000, loss: 0.552255
 >> iter 37000, loss: 0.492007
 >> iter 38000, loss: 0.461136
 >> iter 39000, loss: 0.392714
 >> iter 40000, loss: 0.548019
   Number of active neurons: 10
 >> iter 41000, loss: 0.421748
 >> iter 42000, loss: 0.294144
 >> iter 43000, loss: 0.357045
 >> iter 44000, loss: 0.470344
 >> iter 45000, loss: 0.386145
 >> iter 46000, loss: 0.417793
 >> iter 47000, loss: 0.520107
 >> iter 48000, loss: 0.595120
 >> iter 49000, loss: 0.468789
 >> iter 50000, loss: 0.488647
   Number of active neurons: 6
 >> iter 51000, loss: 0.380098
 >> iter 52000, loss: 0.533704
 >> iter 53000, loss: 0.511677
 >> iter 54000, loss: 0.449899
 >> iter 55000, loss: 0.393798
 >> iter 56000, loss: 0.417825
 >> iter 57000, loss: 0.334052
 >> iter 58000, loss: 0.370244
 >> iter 59000, loss: 0.412698
 >> iter 60000, loss: 0.411293
   Number of active neurons: 6
 >> iter 61000, loss: 0.409968
 >> iter 62000, loss: 0.458099
 >> iter 63000, loss: 0.528979
 >> iter 64000, loss: 0.509571
 >> iter 65000, loss: 0.530650
 >> iter 66000, loss: 0.709454
 >> iter 67000, loss: 0.696196
 >> iter 68000, loss: 0.577225
 >> iter 69000, loss: 0.513052
 >> iter 70000, loss: 0.445099
   Number of active neurons: 6
 >> iter 71000, loss: 0.518017
 >> iter 72000, loss: 0.482067
 >> iter 73000, loss: 0.430062
 >> iter 74000, loss: 0.414425
 >> iter 75000, loss: 0.469854
 >> iter 76000, loss: 0.302755
 >> iter 77000, loss: 0.388908
 >> iter 78000, loss: 0.381443
 >> iter 79000, loss: 0.458988
 >> iter 80000, loss: 0.363329
   Number of active neurons: 5
 >> iter 81000, loss: 0.512225
 >> iter 82000, loss: 0.399592
 >> iter 83000, loss: 0.686659
 >> iter 84000, loss: 0.548022
 >> iter 85000, loss: 0.489372
 >> iter 86000, loss: 0.475361
 >> iter 87000, loss: 0.538063
 >> iter 88000, loss: 0.429906
 >> iter 89000, loss: 0.482033
 >> iter 90000, loss: 0.412892
   Number of active neurons: 5
 >> iter 91000, loss: 0.425808
 >> iter 92000, loss: 0.476671
 >> iter 93000, loss: 0.630568
 >> iter 94000, loss: 0.501061
 >> iter 95000, loss: 0.436179
 >> iter 96000, loss: 0.354392
 >> iter 97000, loss: 0.671670
 >> iter 98000, loss: 0.672102
 >> iter 99000, loss: 0.637177
 >> iter 100000, loss: 0.500786
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 16.561429
 >> iter 2000, loss: 9.936234
 >> iter 3000, loss: 5.265375
 >> iter 4000, loss: 2.430896
 >> iter 5000, loss: 1.204432
 >> iter 6000, loss: 0.733464
 >> iter 7000, loss: 0.492396
 >> iter 8000, loss: 0.439048
 >> iter 9000, loss: 0.319973
 >> iter 10000, loss: 0.367185
   Number of active neurons: 11
 >> iter 11000, loss: 0.243823
 >> iter 12000, loss: 0.254406
 >> iter 13000, loss: 0.304057
 >> iter 14000, loss: 0.323552
 >> iter 15000, loss: 0.399366
 >> iter 16000, loss: 0.298936
 >> iter 17000, loss: 0.236175
 >> iter 18000, loss: 0.181080
 >> iter 19000, loss: 0.293861
 >> iter 20000, loss: 0.343846
   Number of active neurons: 11
 >> iter 21000, loss: 0.426211
 >> iter 22000, loss: 0.285133
 >> iter 23000, loss: 0.257928
 >> iter 24000, loss: 0.282768
 >> iter 25000, loss: 0.313898
 >> iter 26000, loss: 0.305033
 >> iter 27000, loss: 0.318827
 >> iter 28000, loss: 0.237778
 >> iter 29000, loss: 0.311246
 >> iter 30000, loss: 0.255867
   Number of active neurons: 10
 >> iter 31000, loss: 0.295666
 >> iter 32000, loss: 0.258526
 >> iter 33000, loss: 0.277304
 >> iter 34000, loss: 0.251612
 >> iter 35000, loss: 0.315357
 >> iter 36000, loss: 0.412249
 >> iter 37000, loss: 0.327731
 >> iter 38000, loss: 0.257155
 >> iter 39000, loss: 0.270454
 >> iter 40000, loss: 0.276401
   Number of active neurons: 10
 >> iter 41000, loss: 0.228698
 >> iter 42000, loss: 0.292642
 >> iter 43000, loss: 0.331318
 >> iter 44000, loss: 0.370660
 >> iter 45000, loss: 0.243282
 >> iter 46000, loss: 0.216571
 >> iter 47000, loss: 0.380276
 >> iter 48000, loss: 0.338670
 >> iter 49000, loss: 0.418807
 >> iter 50000, loss: 0.298388
   Number of active neurons: 9
 >> iter 51000, loss: 0.362581
 >> iter 52000, loss: 0.324080
 >> iter 53000, loss: 0.378234
 >> iter 54000, loss: 0.302914
 >> iter 55000, loss: 0.275338
 >> iter 56000, loss: 0.248071
 >> iter 57000, loss: 0.363906
 >> iter 58000, loss: 0.345020
 >> iter 59000, loss: 0.316094
 >> iter 60000, loss: 0.291754
   Number of active neurons: 9
 >> iter 61000, loss: 0.311946
 >> iter 62000, loss: 0.269190
 >> iter 63000, loss: 0.349480
 >> iter 64000, loss: 0.307168
 >> iter 65000, loss: 0.299216
 >> iter 66000, loss: 0.323911
 >> iter 67000, loss: 0.374369
 >> iter 68000, loss: 0.354683
 >> iter 69000, loss: 0.274727
 >> iter 70000, loss: 0.297825
   Number of active neurons: 9
 >> iter 71000, loss: 0.427641
 >> iter 72000, loss: 0.316520
 >> iter 73000, loss: 0.228582
 >> iter 74000, loss: 0.339587
 >> iter 75000, loss: 0.452609
 >> iter 76000, loss: 0.261174
 >> iter 77000, loss: 0.223167
 >> iter 78000, loss: 0.248556
 >> iter 79000, loss: 0.258032
 >> iter 80000, loss: 0.334566
   Number of active neurons: 8
 >> iter 81000, loss: 0.246493
 >> iter 82000, loss: 0.277136
 >> iter 83000, loss: 0.486768
 >> iter 84000, loss: 0.425179
 >> iter 85000, loss: 0.384631
 >> iter 86000, loss: 0.259441
 >> iter 87000, loss: 0.300410
 >> iter 88000, loss: 0.277601
 >> iter 89000, loss: 0.327275
 >> iter 90000, loss: 0.317274
   Number of active neurons: 7
 >> iter 91000, loss: 0.333044
 >> iter 92000, loss: 0.288276
 >> iter 93000, loss: 0.418404
 >> iter 94000, loss: 0.382228
 >> iter 95000, loss: 0.326305
 >> iter 96000, loss: 0.269178
 >> iter 97000, loss: 0.301599
 >> iter 98000, loss: 0.262927
 >> iter 99000, loss: 0.242096
 >> iter 100000, loss: 0.198977
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 17.478339
 >> iter 2000, loss: 10.287746
 >> iter 3000, loss: 5.993787
 >> iter 4000, loss: 2.641578
 >> iter 5000, loss: 1.234557
 >> iter 6000, loss: 0.701060
 >> iter 7000, loss: 0.335012
 >> iter 8000, loss: 0.314554
 >> iter 9000, loss: 0.233332
 >> iter 10000, loss: 0.244981
   Number of active neurons: 13
 >> iter 11000, loss: 0.256666
 >> iter 12000, loss: 0.299585
 >> iter 13000, loss: 0.263653
 >> iter 14000, loss: 0.238068
 >> iter 15000, loss: 0.239558
 >> iter 16000, loss: 0.321972
 >> iter 17000, loss: 0.260967
 >> iter 18000, loss: 0.266370
 >> iter 19000, loss: 0.316112
 >> iter 20000, loss: 0.400378
   Number of active neurons: 12
 >> iter 21000, loss: 0.404813
 >> iter 22000, loss: 0.271080
 >> iter 23000, loss: 0.345736
 >> iter 24000, loss: 0.275166
 >> iter 25000, loss: 0.207090
 >> iter 26000, loss: 0.315218
 >> iter 27000, loss: 0.321249
 >> iter 28000, loss: 0.196741
 >> iter 29000, loss: 0.215165
 >> iter 30000, loss: 0.280814
   Number of active neurons: 12
 >> iter 31000, loss: 0.442545
 >> iter 32000, loss: 0.336351
 >> iter 33000, loss: 0.281924
 >> iter 34000, loss: 0.237905
 >> iter 35000, loss: 0.342086
 >> iter 36000, loss: 0.301689
 >> iter 37000, loss: 0.355690
 >> iter 38000, loss: 0.286823
 >> iter 39000, loss: 0.264524
 >> iter 40000, loss: 0.280298
   Number of active neurons: 11
 >> iter 41000, loss: 0.300339
 >> iter 42000, loss: 0.264345
 >> iter 43000, loss: 0.242986
 >> iter 44000, loss: 0.322511
 >> iter 45000, loss: 0.388371
 >> iter 46000, loss: 0.380993
 >> iter 47000, loss: 0.315800
 >> iter 48000, loss: 0.299540
 >> iter 49000, loss: 0.308137
 >> iter 50000, loss: 0.345300
   Number of active neurons: 11
 >> iter 51000, loss: 0.467670
 >> iter 52000, loss: 0.345426
 >> iter 53000, loss: 0.421160
 >> iter 54000, loss: 0.416824
 >> iter 55000, loss: 0.358256
 >> iter 56000, loss: 0.290463
 >> iter 57000, loss: 0.308863
 >> iter 58000, loss: 0.349042
 >> iter 59000, loss: 0.359498
 >> iter 60000, loss: 0.294909
   Number of active neurons: 11
 >> iter 61000, loss: 0.262314
 >> iter 62000, loss: 0.318278
 >> iter 63000, loss: 0.299546
 >> iter 64000, loss: 0.302996
 >> iter 65000, loss: 0.321824
 >> iter 66000, loss: 0.465842
 >> iter 67000, loss: 0.355227
 >> iter 68000, loss: 0.294067
 >> iter 69000, loss: 0.282792
 >> iter 70000, loss: 0.195074
   Number of active neurons: 9
 >> iter 71000, loss: 0.327164
 >> iter 72000, loss: 0.391211
 >> iter 73000, loss: 0.475785
 >> iter 74000, loss: 0.422946
 >> iter 75000, loss: 0.383637
 >> iter 76000, loss: 0.286719
 >> iter 77000, loss: 0.357194
 >> iter 78000, loss: 0.345225
 >> iter 79000, loss: 0.294799
 >> iter 80000, loss: 0.302880
   Number of active neurons: 9
 >> iter 81000, loss: 0.211662
 >> iter 82000, loss: 0.315896
 >> iter 83000, loss: 0.295402
 >> iter 84000, loss: 0.267531
 >> iter 85000, loss: 0.416435
 >> iter 86000, loss: 0.451528
 >> iter 87000, loss: 0.407867
 >> iter 88000, loss: 0.338696
 >> iter 89000, loss: 0.408971
 >> iter 90000, loss: 0.309950
   Number of active neurons: 8
 >> iter 91000, loss: 0.340481
 >> iter 92000, loss: 0.386566
 >> iter 93000, loss: 0.400717
 >> iter 94000, loss: 0.404006
 >> iter 95000, loss: 0.289367
 >> iter 96000, loss: 0.373456
 >> iter 97000, loss: 0.382782
 >> iter 98000, loss: 0.275099
 >> iter 99000, loss: 0.459933
 >> iter 100000, loss: 0.440173
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 17.212785
 >> iter 2000, loss: 10.341723
 >> iter 3000, loss: 6.081579
 >> iter 4000, loss: 3.207040
 >> iter 5000, loss: 1.739516
 >> iter 6000, loss: 0.878050
 >> iter 7000, loss: 0.486078
 >> iter 8000, loss: 0.357516
 >> iter 9000, loss: 0.343356
 >> iter 10000, loss: 0.282346
   Number of active neurons: 9
 >> iter 11000, loss: 0.295600
 >> iter 12000, loss: 0.355498
 >> iter 13000, loss: 0.245611
 >> iter 14000, loss: 0.223967
 >> iter 15000, loss: 0.192060
 >> iter 16000, loss: 0.334962
 >> iter 17000, loss: 0.257794
 >> iter 18000, loss: 0.221821
 >> iter 19000, loss: 0.211203
 >> iter 20000, loss: 0.165832
   Number of active neurons: 8
 >> iter 21000, loss: 0.287920
 >> iter 22000, loss: 0.209991
 >> iter 23000, loss: 0.174970
 >> iter 24000, loss: 0.271739
 >> iter 25000, loss: 0.244948
 >> iter 26000, loss: 0.227548
 >> iter 27000, loss: 0.178877
 >> iter 28000, loss: 0.231172
 >> iter 29000, loss: 0.230300
 >> iter 30000, loss: 0.265005
   Number of active neurons: 8
 >> iter 31000, loss: 0.199928
 >> iter 32000, loss: 0.138557
 >> iter 33000, loss: 0.228923
 >> iter 34000, loss: 0.207353
 >> iter 35000, loss: 0.239769
 >> iter 36000, loss: 0.278062
 >> iter 37000, loss: 0.207403
 >> iter 38000, loss: 0.226901
 >> iter 39000, loss: 0.204484
 >> iter 40000, loss: 0.294390
   Number of active neurons: 8
 >> iter 41000, loss: 0.302621
 >> iter 42000, loss: 0.225775
 >> iter 43000, loss: 0.167014
 >> iter 44000, loss: 0.239195
 >> iter 45000, loss: 0.193069
 >> iter 46000, loss: 0.186295
 >> iter 47000, loss: 0.212774
 >> iter 48000, loss: 0.191461
 >> iter 49000, loss: 0.229301
 >> iter 50000, loss: 0.305352
   Number of active neurons: 6
 >> iter 51000, loss: 0.260469
 >> iter 52000, loss: 0.265140
 >> iter 53000, loss: 0.292170
 >> iter 54000, loss: 0.257447
 >> iter 55000, loss: 0.329704
 >> iter 56000, loss: 0.227228
 >> iter 57000, loss: 0.231983
 >> iter 58000, loss: 0.206207
 >> iter 59000, loss: 0.232247
 >> iter 60000, loss: 0.216111
   Number of active neurons: 6
 >> iter 61000, loss: 0.276816
 >> iter 62000, loss: 0.206085
 >> iter 63000, loss: 0.312813
 >> iter 64000, loss: 0.292525
 >> iter 65000, loss: 0.226087
 >> iter 66000, loss: 0.205986
 >> iter 67000, loss: 0.291361
 >> iter 68000, loss: 0.219544
 >> iter 69000, loss: 0.259218
 >> iter 70000, loss: 0.243098
   Number of active neurons: 5
 >> iter 71000, loss: 0.227527
 >> iter 72000, loss: 0.224825
 >> iter 73000, loss: 0.270323
 >> iter 74000, loss: 0.292042
 >> iter 75000, loss: 0.323882
 >> iter 76000, loss: 0.235078
 >> iter 77000, loss: 0.240686
 >> iter 78000, loss: 0.307405
 >> iter 79000, loss: 0.233717
 >> iter 80000, loss: 0.265719
   Number of active neurons: 5
 >> iter 81000, loss: 0.297010
 >> iter 82000, loss: 0.264213
 >> iter 83000, loss: 0.372052
 >> iter 84000, loss: 0.240772
 >> iter 85000, loss: 0.314958
 >> iter 86000, loss: 0.269102
 >> iter 87000, loss: 0.277937
 >> iter 88000, loss: 0.216754
 >> iter 89000, loss: 0.264455
 >> iter 90000, loss: 0.208462
   Number of active neurons: 5
 >> iter 91000, loss: 0.249115
 >> iter 92000, loss: 0.210157
 >> iter 93000, loss: 0.270261
 >> iter 94000, loss: 0.173041
 >> iter 95000, loss: 0.213708
 >> iter 96000, loss: 0.213546
 >> iter 97000, loss: 0.229379
 >> iter 98000, loss: 0.210351
 >> iter 99000, loss: 0.338271
 >> iter 100000, loss: 0.318699
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 16.833530
 >> iter 2000, loss: 10.079932
 >> iter 3000, loss: 6.351237
 >> iter 4000, loss: 3.362110
 >> iter 5000, loss: 2.163298
 >> iter 6000, loss: 1.333919
 >> iter 7000, loss: 1.261340
 >> iter 8000, loss: 0.978802
 >> iter 9000, loss: 0.843401
 >> iter 10000, loss: 0.837845
   Number of active neurons: 7
 >> iter 11000, loss: 0.795986
 >> iter 12000, loss: 0.773000
 >> iter 13000, loss: 0.747706
 >> iter 14000, loss: 0.792319
 >> iter 15000, loss: 0.848970
 >> iter 16000, loss: 0.639843
 >> iter 17000, loss: 0.534232
 >> iter 18000, loss: 0.537793
 >> iter 19000, loss: 0.672088
 >> iter 20000, loss: 0.599647
   Number of active neurons: 7
 >> iter 21000, loss: 0.601979
 >> iter 22000, loss: 0.560373
 >> iter 23000, loss: 0.660666
 >> iter 24000, loss: 0.623933
 >> iter 25000, loss: 0.589517
 >> iter 26000, loss: 0.522241
 >> iter 27000, loss: 0.572392
 >> iter 28000, loss: 0.668940
 >> iter 29000, loss: 0.663508
 >> iter 30000, loss: 0.761807
   Number of active neurons: 7
 >> iter 31000, loss: 0.824850
 >> iter 32000, loss: 0.720969
 >> iter 33000, loss: 0.658616
 >> iter 34000, loss: 0.523571
 >> iter 35000, loss: 0.625714
 >> iter 36000, loss: 0.691090
 >> iter 37000, loss: 0.695963
 >> iter 38000, loss: 0.426451
 >> iter 39000, loss: 0.460815
 >> iter 40000, loss: 0.638644
   Number of active neurons: 7
 >> iter 41000, loss: 0.626283
 >> iter 42000, loss: 0.559926
 >> iter 43000, loss: 0.651587
 >> iter 44000, loss: 0.554666
 >> iter 45000, loss: 0.617100
 >> iter 46000, loss: 0.570908
 >> iter 47000, loss: 0.689283
 >> iter 48000, loss: 0.730499
 >> iter 49000, loss: 0.704495
 >> iter 50000, loss: 0.658382
   Number of active neurons: 7
 >> iter 51000, loss: 0.625542
 >> iter 52000, loss: 0.761950
 >> iter 53000, loss: 0.666342
 >> iter 54000, loss: 0.542547
 >> iter 55000, loss: 0.766129
 >> iter 56000, loss: 0.742891
 >> iter 57000, loss: 0.569735
 >> iter 58000, loss: 0.578907
 >> iter 59000, loss: 0.569817
 >> iter 60000, loss: 0.575678
   Number of active neurons: 7
 >> iter 61000, loss: 0.545294
 >> iter 62000, loss: 0.497473
 >> iter 63000, loss: 0.561493
 >> iter 64000, loss: 0.414428
 >> iter 65000, loss: 0.433381
 >> iter 66000, loss: 0.462410
 >> iter 67000, loss: 0.544572
 >> iter 68000, loss: 0.423797
 >> iter 69000, loss: 0.348137
 >> iter 70000, loss: 0.376533
   Number of active neurons: 6
 >> iter 71000, loss: 0.388730
 >> iter 72000, loss: 0.403446
 >> iter 73000, loss: 0.366294
 >> iter 74000, loss: 0.415186
 >> iter 75000, loss: 0.385452
 >> iter 76000, loss: 0.345217
 >> iter 77000, loss: 0.312354
 >> iter 78000, loss: 0.385942
 >> iter 79000, loss: 0.468170
 >> iter 80000, loss: 0.438712
   Number of active neurons: 6
 >> iter 81000, loss: 0.421810
 >> iter 82000, loss: 0.380838
 >> iter 83000, loss: 0.515736
 >> iter 84000, loss: 0.598315
 >> iter 85000, loss: 0.429285
 >> iter 86000, loss: 0.481813
 >> iter 87000, loss: 0.405735
 >> iter 88000, loss: 0.526370
 >> iter 89000, loss: 0.427791
 >> iter 90000, loss: 0.484369
   Number of active neurons: 5
 >> iter 91000, loss: 0.515709
 >> iter 92000, loss: 0.449611
 >> iter 93000, loss: 0.349532
 >> iter 94000, loss: 0.435526
 >> iter 95000, loss: 0.421085
 >> iter 96000, loss: 0.543437
 >> iter 97000, loss: 0.713984
 >> iter 98000, loss: 0.628849
 >> iter 99000, loss: 0.531997
 >> iter 100000, loss: 0.486592
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 11.8792080528
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 17.192809
 >> iter 2000, loss: 10.381011
 >> iter 3000, loss: 6.787355
 >> iter 4000, loss: 3.381931
 >> iter 5000, loss: 1.646825
 >> iter 6000, loss: 0.935884
 >> iter 7000, loss: 0.665666
 >> iter 8000, loss: 0.525960
 >> iter 9000, loss: 0.489881
 >> iter 10000, loss: 0.484606
   Number of active neurons: 12
 >> iter 11000, loss: 0.523245
 >> iter 12000, loss: 0.462123
 >> iter 13000, loss: 0.449237
 >> iter 14000, loss: 0.423348
 >> iter 15000, loss: 0.334983
 >> iter 16000, loss: 0.298506
 >> iter 17000, loss: 0.285920
 >> iter 18000, loss: 0.378713
 >> iter 19000, loss: 0.477956
 >> iter 20000, loss: 0.418884
   Number of active neurons: 10
 >> iter 21000, loss: 0.343404
 >> iter 22000, loss: 0.282122
 >> iter 23000, loss: 0.435904
 >> iter 24000, loss: 0.325865
 >> iter 25000, loss: 0.320308
 >> iter 26000, loss: 0.377090
 >> iter 27000, loss: 0.217030
 >> iter 28000, loss: 0.247881
 >> iter 29000, loss: 0.385235
 >> iter 30000, loss: 0.339926
   Number of active neurons: 10
 >> iter 31000, loss: 0.289865
 >> iter 32000, loss: 0.246620
 >> iter 33000, loss: 0.277969
 >> iter 34000, loss: 0.244531
 >> iter 35000, loss: 0.245895
 >> iter 36000, loss: 0.267434
 >> iter 37000, loss: 0.361927
 >> iter 38000, loss: 0.287950
 >> iter 39000, loss: 0.247421
 >> iter 40000, loss: 0.280206
   Number of active neurons: 10
 >> iter 41000, loss: 0.356605
 >> iter 42000, loss: 0.259440
 >> iter 43000, loss: 0.320863
 >> iter 44000, loss: 0.324845
 >> iter 45000, loss: 0.357649
 >> iter 46000, loss: 0.327166
 >> iter 47000, loss: 0.299744
 >> iter 48000, loss: 0.469849
 >> iter 49000, loss: 0.405168
 >> iter 50000, loss: 0.373188
   Number of active neurons: 10
 >> iter 51000, loss: 0.365007
 >> iter 52000, loss: 0.333779
 >> iter 53000, loss: 0.265102
 >> iter 54000, loss: 0.304896
 >> iter 55000, loss: 0.373528
 >> iter 56000, loss: 0.320894
 >> iter 57000, loss: 0.395111
 >> iter 58000, loss: 0.309787
 >> iter 59000, loss: 0.328533
 >> iter 60000, loss: 0.327246
   Number of active neurons: 10
 >> iter 61000, loss: 0.297846
 >> iter 62000, loss: 0.382278
 >> iter 63000, loss: 0.344006
 >> iter 64000, loss: 0.268350
 >> iter 65000, loss: 0.215445
 >> iter 66000, loss: 0.347922
 >> iter 67000, loss: 0.313399
 >> iter 68000, loss: 0.248835
 >> iter 69000, loss: 0.216292
 >> iter 70000, loss: 0.168559
   Number of active neurons: 10
 >> iter 71000, loss: 0.204548
 >> iter 72000, loss: 0.331637
 >> iter 73000, loss: 0.193539
 >> iter 74000, loss: 0.227357
 >> iter 75000, loss: 0.235387
 >> iter 76000, loss: 0.247345
 >> iter 77000, loss: 0.249936
 >> iter 78000, loss: 0.268979
 >> iter 79000, loss: 0.335696
 >> iter 80000, loss: 0.375734
   Number of active neurons: 10
 >> iter 81000, loss: 0.320584
 >> iter 82000, loss: 0.247377
 >> iter 83000, loss: 0.215387
 >> iter 84000, loss: 0.278890
 >> iter 85000, loss: 0.282557
 >> iter 86000, loss: 0.488238
 >> iter 87000, loss: 0.358921
 >> iter 88000, loss: 0.449916
 >> iter 89000, loss: 0.370659
 >> iter 90000, loss: 0.427020
   Number of active neurons: 10
 >> iter 91000, loss: 0.303282
 >> iter 92000, loss: 0.197629
 >> iter 93000, loss: 0.287094
 >> iter 94000, loss: 0.279823
 >> iter 95000, loss: 0.313187
 >> iter 96000, loss: 0.239633
 >> iter 97000, loss: 0.285838
 >> iter 98000, loss: 0.367468
 >> iter 99000, loss: 0.376347
 >> iter 100000, loss: 0.331295
   Number of active neurons: 10
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.355296
 >> iter 2000, loss: 10.504139
 >> iter 3000, loss: 5.260549
 >> iter 4000, loss: 2.445016
 >> iter 5000, loss: 1.268650
 >> iter 6000, loss: 0.654231
 >> iter 7000, loss: 0.452585
 >> iter 8000, loss: 0.414174
 >> iter 9000, loss: 0.438317
 >> iter 10000, loss: 0.324826
   Number of active neurons: 9
 >> iter 11000, loss: 0.296274
 >> iter 12000, loss: 0.229017
 >> iter 13000, loss: 0.321396
 >> iter 14000, loss: 0.264723
 >> iter 15000, loss: 0.347654
 >> iter 16000, loss: 0.326839
 >> iter 17000, loss: 0.330657
 >> iter 18000, loss: 0.233998
 >> iter 19000, loss: 0.289729
 >> iter 20000, loss: 0.211282
   Number of active neurons: 7
 >> iter 21000, loss: 0.206333
 >> iter 22000, loss: 0.218784
 >> iter 23000, loss: 0.269908
 >> iter 24000, loss: 0.169532
 >> iter 25000, loss: 0.323016
 >> iter 26000, loss: 0.261818
 >> iter 27000, loss: 0.296276
 >> iter 28000, loss: 0.311350
 >> iter 29000, loss: 0.253872
 >> iter 30000, loss: 0.232958
   Number of active neurons: 7
 >> iter 31000, loss: 0.286856
 >> iter 32000, loss: 0.204811
 >> iter 33000, loss: 0.224337
 >> iter 34000, loss: 0.227963
 >> iter 35000, loss: 0.234455
 >> iter 36000, loss: 0.236991
 >> iter 37000, loss: 0.194634
 >> iter 38000, loss: 0.235096
 >> iter 39000, loss: 0.230008
 >> iter 40000, loss: 0.252305
   Number of active neurons: 7
 >> iter 41000, loss: 0.211420
 >> iter 42000, loss: 0.237288
 >> iter 43000, loss: 0.307956
 >> iter 44000, loss: 0.280206
 >> iter 45000, loss: 0.344145
 >> iter 46000, loss: 0.251159
 >> iter 47000, loss: 0.207382
 >> iter 48000, loss: 0.187764
 >> iter 49000, loss: 0.167996
 >> iter 50000, loss: 0.180035
   Number of active neurons: 6
 >> iter 51000, loss: 0.170777
 >> iter 52000, loss: 0.168945
 >> iter 53000, loss: 0.231341
 >> iter 54000, loss: 0.233266
 >> iter 55000, loss: 0.250871
 >> iter 56000, loss: 0.283852
 >> iter 57000, loss: 0.237921
 >> iter 58000, loss: 0.342351
 >> iter 59000, loss: 0.300779
 >> iter 60000, loss: 0.198928
   Number of active neurons: 5
 >> iter 61000, loss: 0.225509
 >> iter 62000, loss: 0.202312
 >> iter 63000, loss: 0.240143
 >> iter 64000, loss: 0.233264
 >> iter 65000, loss: 0.262473
 >> iter 66000, loss: 0.194694
 >> iter 67000, loss: 0.206655
 >> iter 68000, loss: 0.134460
 >> iter 69000, loss: 0.145026
 >> iter 70000, loss: 0.264294
   Number of active neurons: 5
 >> iter 71000, loss: 0.222220
 >> iter 72000, loss: 0.172341
 >> iter 73000, loss: 0.223439
 >> iter 74000, loss: 0.255101
 >> iter 75000, loss: 0.273717
 >> iter 76000, loss: 0.242381
 >> iter 77000, loss: 0.224670
 >> iter 78000, loss: 0.287570
 >> iter 79000, loss: 0.233105
 >> iter 80000, loss: 0.219329
   Number of active neurons: 5
 >> iter 81000, loss: 0.224418
 >> iter 82000, loss: 0.181287
 >> iter 83000, loss: 0.166983
 >> iter 84000, loss: 0.221315
 >> iter 85000, loss: 0.209538
 >> iter 86000, loss: 0.202138
 >> iter 87000, loss: 0.256369
 >> iter 88000, loss: 0.162729
 >> iter 89000, loss: 0.137760
 >> iter 90000, loss: 0.222966
   Number of active neurons: 5
 >> iter 91000, loss: 0.192174
 >> iter 92000, loss: 0.153503
 >> iter 93000, loss: 0.238278
 >> iter 94000, loss: 0.214600
 >> iter 95000, loss: 0.162069
 >> iter 96000, loss: 0.134335
 >> iter 97000, loss: 0.139907
 >> iter 98000, loss: 0.281017
 >> iter 99000, loss: 0.232000
 >> iter 100000, loss: 0.159154
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 16.540157
 >> iter 2000, loss: 9.772332
 >> iter 3000, loss: 5.616161
 >> iter 4000, loss: 2.911076
 >> iter 5000, loss: 1.569808
 >> iter 6000, loss: 1.068453
 >> iter 7000, loss: 0.749322
 >> iter 8000, loss: 0.614490
 >> iter 9000, loss: 0.540871
 >> iter 10000, loss: 0.630557
   Number of active neurons: 6
 >> iter 11000, loss: 0.587475
 >> iter 12000, loss: 0.547128
 >> iter 13000, loss: 0.710810
 >> iter 14000, loss: 0.512688
 >> iter 15000, loss: 0.535233
 >> iter 16000, loss: 0.439109
 >> iter 17000, loss: 0.461159
 >> iter 18000, loss: 0.685345
 >> iter 19000, loss: 0.504780
 >> iter 20000, loss: 0.499962
   Number of active neurons: 6
 >> iter 21000, loss: 0.440184
 >> iter 22000, loss: 0.382486
 >> iter 23000, loss: 0.507382
 >> iter 24000, loss: 0.357000
 >> iter 25000, loss: 0.509151
 >> iter 26000, loss: 0.403110
 >> iter 27000, loss: 0.384092
 >> iter 28000, loss: 0.273053
 >> iter 29000, loss: 0.210216
 >> iter 30000, loss: 0.160918
   Number of active neurons: 6
 >> iter 31000, loss: 0.262616
 >> iter 32000, loss: 0.300113
 >> iter 33000, loss: 0.324803
 >> iter 34000, loss: 0.260318
 >> iter 35000, loss: 0.311950
 >> iter 36000, loss: 0.345683
 >> iter 37000, loss: 0.372288
 >> iter 38000, loss: 0.261986
 >> iter 39000, loss: 0.260709
 >> iter 40000, loss: 0.242887
   Number of active neurons: 6
 >> iter 41000, loss: 0.227158
 >> iter 42000, loss: 0.383322
 >> iter 43000, loss: 0.370991
 >> iter 44000, loss: 0.370079
 >> iter 45000, loss: 0.306243
 >> iter 46000, loss: 0.367763
 >> iter 47000, loss: 0.436595
 >> iter 48000, loss: 0.324661
 >> iter 49000, loss: 0.399795
 >> iter 50000, loss: 0.446593
   Number of active neurons: 6
 >> iter 51000, loss: 0.371697
 >> iter 52000, loss: 0.460149
 >> iter 53000, loss: 0.420837
 >> iter 54000, loss: 0.454804
 >> iter 55000, loss: 0.312473
 >> iter 56000, loss: 0.385201
 >> iter 57000, loss: 0.304254
 >> iter 58000, loss: 0.413674
 >> iter 59000, loss: 0.442729
 >> iter 60000, loss: 0.325265
   Number of active neurons: 6
 >> iter 61000, loss: 0.410788
 >> iter 62000, loss: 0.398805
 >> iter 63000, loss: 0.575977
 >> iter 64000, loss: 0.421610
 >> iter 65000, loss: 0.275890
 >> iter 66000, loss: 0.311053
 >> iter 67000, loss: 0.342250
 >> iter 68000, loss: 0.465040
 >> iter 69000, loss: 0.373688
 >> iter 70000, loss: 0.313708
   Number of active neurons: 6
 >> iter 71000, loss: 0.256928
 >> iter 72000, loss: 0.255938
 >> iter 73000, loss: 0.301978
 >> iter 74000, loss: 0.274255
 >> iter 75000, loss: 0.253450
 >> iter 76000, loss: 0.257693
 >> iter 77000, loss: 0.230070
 >> iter 78000, loss: 0.307677
 >> iter 79000, loss: 0.292638
 >> iter 80000, loss: 0.296236
   Number of active neurons: 6
 >> iter 81000, loss: 0.232217
 >> iter 82000, loss: 0.222309
 >> iter 83000, loss: 0.309501
 >> iter 84000, loss: 0.377399
 >> iter 85000, loss: 0.388880
 >> iter 86000, loss: 0.327864
 >> iter 87000, loss: 0.236146
 >> iter 88000, loss: 0.230847
 >> iter 89000, loss: 0.371267
 >> iter 90000, loss: 0.395923
   Number of active neurons: 6
 >> iter 91000, loss: 0.326699
 >> iter 92000, loss: 0.418625
 >> iter 93000, loss: 0.342601
 >> iter 94000, loss: 0.333485
 >> iter 95000, loss: 0.283335
 >> iter 96000, loss: 0.276782
 >> iter 97000, loss: 0.272569
 >> iter 98000, loss: 0.251586
 >> iter 99000, loss: 0.321103
 >> iter 100000, loss: 0.356181
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455165
   Number of active neurons: 0
 >> iter 1000, loss: 16.587349
 >> iter 2000, loss: 9.787252
 >> iter 3000, loss: 6.681819
 >> iter 4000, loss: 4.517537
 >> iter 5000, loss: 2.828179
 >> iter 6000, loss: 1.719044
 >> iter 7000, loss: 1.018907
 >> iter 8000, loss: 0.668863
 >> iter 9000, loss: 0.533105
 >> iter 10000, loss: 0.543761
   Number of active neurons: 8
 >> iter 11000, loss: 0.685817
 >> iter 12000, loss: 0.571325
 >> iter 13000, loss: 0.566796
 >> iter 14000, loss: 0.580265
 >> iter 15000, loss: 0.517237
 >> iter 16000, loss: 0.378086
 >> iter 17000, loss: 0.335615
 >> iter 18000, loss: 0.449308
 >> iter 19000, loss: 0.394740
 >> iter 20000, loss: 0.331868
   Number of active neurons: 8
 >> iter 21000, loss: 0.414031
 >> iter 22000, loss: 0.374644
 >> iter 23000, loss: 0.385145
 >> iter 24000, loss: 0.397402
 >> iter 25000, loss: 0.408487
 >> iter 26000, loss: 0.375437
 >> iter 27000, loss: 0.383527
 >> iter 28000, loss: 0.382194
 >> iter 29000, loss: 0.404725
 >> iter 30000, loss: 0.352745
   Number of active neurons: 8
 >> iter 31000, loss: 0.487735
 >> iter 32000, loss: 0.402386
 >> iter 33000, loss: 0.340834
 >> iter 34000, loss: 0.471590
 >> iter 35000, loss: 0.325135
 >> iter 36000, loss: 0.287983
 >> iter 37000, loss: 0.399095
 >> iter 38000, loss: 0.486633
 >> iter 39000, loss: 0.566291
 >> iter 40000, loss: 0.452128
   Number of active neurons: 6
 >> iter 41000, loss: 0.600267
 >> iter 42000, loss: 0.491927
 >> iter 43000, loss: 0.441592
 >> iter 44000, loss: 0.423138
 >> iter 45000, loss: 0.452106
 >> iter 46000, loss: 0.480139
 >> iter 47000, loss: 0.468642
 >> iter 48000, loss: 0.509720
 >> iter 49000, loss: 0.563790
 >> iter 50000, loss: 0.530029
   Number of active neurons: 6
 >> iter 51000, loss: 0.456023
 >> iter 52000, loss: 0.636882
 >> iter 53000, loss: 0.490129
 >> iter 54000, loss: 0.429980
 >> iter 55000, loss: 0.415118
 >> iter 56000, loss: 0.479344
 >> iter 57000, loss: 0.474638
 >> iter 58000, loss: 0.536779
 >> iter 59000, loss: 0.370352
 >> iter 60000, loss: 0.413760
   Number of active neurons: 5
 >> iter 61000, loss: 0.430623
 >> iter 62000, loss: 0.433729
 >> iter 63000, loss: 0.461299
 >> iter 64000, loss: 0.545980
 >> iter 65000, loss: 0.568866
 >> iter 66000, loss: 0.491081
 >> iter 67000, loss: 0.417448
 >> iter 68000, loss: 0.430112
 >> iter 69000, loss: 0.552317
 >> iter 70000, loss: 0.484607
   Number of active neurons: 5
 >> iter 71000, loss: 0.613416
 >> iter 72000, loss: 0.457729
 >> iter 73000, loss: 0.517553
 >> iter 74000, loss: 0.404596
 >> iter 75000, loss: 0.317488
 >> iter 76000, loss: 0.351006
 >> iter 77000, loss: 0.481955
 >> iter 78000, loss: 0.394637
 >> iter 79000, loss: 0.341531
 >> iter 80000, loss: 0.421095
   Number of active neurons: 5
 >> iter 81000, loss: 0.369533
 >> iter 82000, loss: 0.327181
 >> iter 83000, loss: 0.345584
 >> iter 84000, loss: 0.482124
 >> iter 85000, loss: 0.560152
 >> iter 86000, loss: 0.533285
 >> iter 87000, loss: 0.593357
 >> iter 88000, loss: 0.512431
 >> iter 89000, loss: 0.543214
 >> iter 90000, loss: 0.643104
   Number of active neurons: 5
 >> iter 91000, loss: 0.479547
 >> iter 92000, loss: 0.461919
 >> iter 93000, loss: 0.513858
 >> iter 94000, loss: 0.493659
 >> iter 95000, loss: 0.511227
 >> iter 96000, loss: 0.549643
 >> iter 97000, loss: 0.512486
 >> iter 98000, loss: 0.550692
 >> iter 99000, loss: 0.548719
 >> iter 100000, loss: 0.561353
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455177
   Number of active neurons: 0
 >> iter 1000, loss: 16.670146
 >> iter 2000, loss: 9.850131
 >> iter 3000, loss: 5.458305
 >> iter 4000, loss: 2.474147
 >> iter 5000, loss: 1.115918
 >> iter 6000, loss: 0.588414
 >> iter 7000, loss: 0.397584
 >> iter 8000, loss: 0.344592
 >> iter 9000, loss: 0.265272
 >> iter 10000, loss: 0.229411
   Number of active neurons: 10
 >> iter 11000, loss: 0.320227
 >> iter 12000, loss: 0.218216
 >> iter 13000, loss: 0.221945
 >> iter 14000, loss: 0.235898
 >> iter 15000, loss: 0.238917
 >> iter 16000, loss: 0.159498
 >> iter 17000, loss: 0.173619
 >> iter 18000, loss: 0.244905
 >> iter 19000, loss: 0.324548
 >> iter 20000, loss: 0.243722
   Number of active neurons: 10
 >> iter 21000, loss: 0.267251
 >> iter 22000, loss: 0.419250
 >> iter 23000, loss: 0.326103
 >> iter 24000, loss: 0.313799
 >> iter 25000, loss: 0.239615
 >> iter 26000, loss: 0.247221
 >> iter 27000, loss: 0.237933
 >> iter 28000, loss: 0.221438
 >> iter 29000, loss: 0.289768
 >> iter 30000, loss: 0.250520
   Number of active neurons: 9
 >> iter 31000, loss: 0.269004
 >> iter 32000, loss: 0.239520
 >> iter 33000, loss: 0.279160
 >> iter 34000, loss: 0.264015
 >> iter 35000, loss: 0.372264
 >> iter 36000, loss: 0.281231
 >> iter 37000, loss: 0.261720
 >> iter 38000, loss: 0.360598
 >> iter 39000, loss: 0.306856
 >> iter 40000, loss: 0.292901
   Number of active neurons: 8
 >> iter 41000, loss: 0.262722
 >> iter 42000, loss: 0.287614
 >> iter 43000, loss: 0.301490
 >> iter 44000, loss: 0.254936
 >> iter 45000, loss: 0.214399
 >> iter 46000, loss: 0.252746
 >> iter 47000, loss: 0.272103
 >> iter 48000, loss: 0.310522
 >> iter 49000, loss: 0.313034
 >> iter 50000, loss: 0.261547
   Number of active neurons: 7
 >> iter 51000, loss: 0.332871
 >> iter 52000, loss: 0.276083
 >> iter 53000, loss: 0.193581
 >> iter 54000, loss: 0.253108
 >> iter 55000, loss: 0.212468
 >> iter 56000, loss: 0.196236
 >> iter 57000, loss: 0.251039
 >> iter 58000, loss: 0.286070
 >> iter 59000, loss: 0.206521
 >> iter 60000, loss: 0.260035
   Number of active neurons: 7
 >> iter 61000, loss: 0.171856
 >> iter 62000, loss: 0.265649
 >> iter 63000, loss: 0.210659
 >> iter 64000, loss: 0.226575
 >> iter 65000, loss: 0.220613
 >> iter 66000, loss: 0.251851
 >> iter 67000, loss: 0.227984
 >> iter 68000, loss: 0.205945
 >> iter 69000, loss: 0.173192
 >> iter 70000, loss: 0.222518
   Number of active neurons: 6
 >> iter 71000, loss: 0.279524
 >> iter 72000, loss: 0.252337
 >> iter 73000, loss: 0.254412
 >> iter 74000, loss: 0.186086
 >> iter 75000, loss: 0.214518
 >> iter 76000, loss: 0.206429
 >> iter 77000, loss: 0.229901
 >> iter 78000, loss: 0.182740
 >> iter 79000, loss: 0.153322
 >> iter 80000, loss: 0.191634
   Number of active neurons: 6
 >> iter 81000, loss: 0.189445
 >> iter 82000, loss: 0.152031
 >> iter 83000, loss: 0.208121
 >> iter 84000, loss: 0.271020
 >> iter 85000, loss: 0.220763
 >> iter 86000, loss: 0.151279
 >> iter 87000, loss: 0.172728
 >> iter 88000, loss: 0.188968
 >> iter 89000, loss: 0.188437
 >> iter 90000, loss: 0.288750
   Number of active neurons: 6
 >> iter 91000, loss: 0.258442
 >> iter 92000, loss: 0.155949
 >> iter 93000, loss: 0.314291
 >> iter 94000, loss: 0.252481
 >> iter 95000, loss: 0.198598
 >> iter 96000, loss: 0.199718
 >> iter 97000, loss: 0.181934
 >> iter 98000, loss: 0.179720
 >> iter 99000, loss: 0.246725
 >> iter 100000, loss: 0.157960
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455180
   Number of active neurons: 0
 >> iter 1000, loss: 17.511123
 >> iter 2000, loss: 10.769368
 >> iter 3000, loss: 7.572985
 >> iter 4000, loss: 4.152976
 >> iter 5000, loss: 2.227016
 >> iter 6000, loss: 1.243796
 >> iter 7000, loss: 0.843018
 >> iter 8000, loss: 0.646639
 >> iter 9000, loss: 0.411957
 >> iter 10000, loss: 0.389613
   Number of active neurons: 10
 >> iter 11000, loss: 0.472375
 >> iter 12000, loss: 0.470210
 >> iter 13000, loss: 0.387716
 >> iter 14000, loss: 0.326479
 >> iter 15000, loss: 0.387725
 >> iter 16000, loss: 0.345411
 >> iter 17000, loss: 0.220669
 >> iter 18000, loss: 0.397577
 >> iter 19000, loss: 0.429577
 >> iter 20000, loss: 0.261603
   Number of active neurons: 10
 >> iter 21000, loss: 0.224985
 >> iter 22000, loss: 0.230416
 >> iter 23000, loss: 0.364804
 >> iter 24000, loss: 0.368728
 >> iter 25000, loss: 0.273210
 >> iter 26000, loss: 0.255875
 >> iter 27000, loss: 0.237775
 >> iter 28000, loss: 0.276876
 >> iter 29000, loss: 0.213871
 >> iter 30000, loss: 0.222984
   Number of active neurons: 10
 >> iter 31000, loss: 0.254604
 >> iter 32000, loss: 0.227729
 >> iter 33000, loss: 0.263841
 >> iter 34000, loss: 0.275813
 >> iter 35000, loss: 0.252668
 >> iter 36000, loss: 0.286964
 >> iter 37000, loss: 0.311526
 >> iter 38000, loss: 0.268979
 >> iter 39000, loss: 0.328621
 >> iter 40000, loss: 0.356450
   Number of active neurons: 9
 >> iter 41000, loss: 0.295171
 >> iter 42000, loss: 0.302810
 >> iter 43000, loss: 0.319552
 >> iter 44000, loss: 0.402081
 >> iter 45000, loss: 0.405816
 >> iter 46000, loss: 0.357222
 >> iter 47000, loss: 0.366495
 >> iter 48000, loss: 0.271416
 >> iter 49000, loss: 0.236553
 >> iter 50000, loss: 0.273066
   Number of active neurons: 8
 >> iter 51000, loss: 0.277854
 >> iter 52000, loss: 0.257719
 >> iter 53000, loss: 0.245541
 >> iter 54000, loss: 0.231812
 >> iter 55000, loss: 0.178874
 >> iter 56000, loss: 0.300225
 >> iter 57000, loss: 0.320340
 >> iter 58000, loss: 0.310350
 >> iter 59000, loss: 0.359852
 >> iter 60000, loss: 0.294284
   Number of active neurons: 8
 >> iter 61000, loss: 0.313932
 >> iter 62000, loss: 0.419416
 >> iter 63000, loss: 0.403761
 >> iter 64000, loss: 0.272361
 >> iter 65000, loss: 0.303683
 >> iter 66000, loss: 0.304363
 >> iter 67000, loss: 0.348441
 >> iter 68000, loss: 0.337792
 >> iter 69000, loss: 0.322746
 >> iter 70000, loss: 0.300840
   Number of active neurons: 8
 >> iter 71000, loss: 0.267149
 >> iter 72000, loss: 0.364098
 >> iter 73000, loss: 0.424573
 >> iter 74000, loss: 0.319449
 >> iter 75000, loss: 0.432738
 >> iter 76000, loss: 0.442096
 >> iter 77000, loss: 0.354414
 >> iter 78000, loss: 0.446722
 >> iter 79000, loss: 0.310186
 >> iter 80000, loss: 0.324293
   Number of active neurons: 7
 >> iter 81000, loss: 0.449672
 >> iter 82000, loss: 0.404733
 >> iter 83000, loss: 0.468925
 >> iter 84000, loss: 0.321096
 >> iter 85000, loss: 0.278944
 >> iter 86000, loss: 0.247510
 >> iter 87000, loss: 0.295116
 >> iter 88000, loss: 0.361075
 >> iter 89000, loss: 0.270219
 >> iter 90000, loss: 0.213673
   Number of active neurons: 6
 >> iter 91000, loss: 0.250277
 >> iter 92000, loss: 0.222513
 >> iter 93000, loss: 0.322953
 >> iter 94000, loss: 0.272242
 >> iter 95000, loss: 0.382386
 >> iter 96000, loss: 0.430666
 >> iter 97000, loss: 0.504295
 >> iter 98000, loss: 0.370721
 >> iter 99000, loss: 0.336002
 >> iter 100000, loss: 0.331272
   Number of active neurons: 5
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 17.211858
 >> iter 2000, loss: 10.167545
 >> iter 3000, loss: 7.197505
 >> iter 4000, loss: 4.924185
 >> iter 5000, loss: 2.997488
 >> iter 6000, loss: 1.804581
 >> iter 7000, loss: 1.254423
 >> iter 8000, loss: 0.903667
 >> iter 9000, loss: 0.718639
 >> iter 10000, loss: 0.646707
   Number of active neurons: 10
 >> iter 11000, loss: 0.782730
 >> iter 12000, loss: 0.716712
 >> iter 13000, loss: 0.726202
 >> iter 14000, loss: 0.859270
 >> iter 15000, loss: 0.690719
 >> iter 16000, loss: 0.708293
 >> iter 17000, loss: 0.468712
 >> iter 18000, loss: 0.447920
 >> iter 19000, loss: 0.598633
 >> iter 20000, loss: 0.559048
   Number of active neurons: 10
 >> iter 21000, loss: 0.550978
 >> iter 22000, loss: 0.607900
 >> iter 23000, loss: 0.629893
 >> iter 24000, loss: 0.638057
 >> iter 25000, loss: 0.476982
 >> iter 26000, loss: 0.561149
 >> iter 27000, loss: 0.442407
 >> iter 28000, loss: 0.508738
 >> iter 29000, loss: 0.368071
 >> iter 30000, loss: 0.425791
   Number of active neurons: 9
 >> iter 31000, loss: 0.442756
 >> iter 32000, loss: 0.463054
 >> iter 33000, loss: 0.421530
 >> iter 34000, loss: 0.425238
 >> iter 35000, loss: 0.494424
 >> iter 36000, loss: 0.487139
 >> iter 37000, loss: 0.479695
 >> iter 38000, loss: 0.490478
 >> iter 39000, loss: 0.534004
 >> iter 40000, loss: 0.636138
   Number of active neurons: 8
 >> iter 41000, loss: 0.562280
 >> iter 42000, loss: 0.471244
 >> iter 43000, loss: 0.737911
 >> iter 44000, loss: 0.776685
 >> iter 45000, loss: 0.623328
 >> iter 46000, loss: 0.593617
 >> iter 47000, loss: 0.492072
 >> iter 48000, loss: 0.590653
 >> iter 49000, loss: 0.626577
 >> iter 50000, loss: 0.690045
   Number of active neurons: 7
 >> iter 51000, loss: 0.488467
 >> iter 52000, loss: 0.468429
 >> iter 53000, loss: 0.408875
 >> iter 54000, loss: 0.367714
 >> iter 55000, loss: 0.449724
 >> iter 56000, loss: 0.424642
 >> iter 57000, loss: 0.579683
 >> iter 58000, loss: 0.423755
 >> iter 59000, loss: 0.496053
 >> iter 60000, loss: 0.503630
   Number of active neurons: 7
 >> iter 61000, loss: 0.529114
 >> iter 62000, loss: 0.669565
 >> iter 63000, loss: 0.707388
 >> iter 64000, loss: 0.679963
 >> iter 65000, loss: 0.529071
 >> iter 66000, loss: 0.425873
 >> iter 67000, loss: 0.469642
 >> iter 68000, loss: 0.491517
 >> iter 69000, loss: 0.481789
 >> iter 70000, loss: 0.512425
   Number of active neurons: 6
 >> iter 71000, loss: 0.509261
 >> iter 72000, loss: 0.514343
 >> iter 73000, loss: 0.730643
 >> iter 74000, loss: 0.664697
 >> iter 75000, loss: 0.603525
 >> iter 76000, loss: 0.516021
 >> iter 77000, loss: 0.489630
 >> iter 78000, loss: 0.486375
 >> iter 79000, loss: 0.522927
 >> iter 80000, loss: 0.549541
   Number of active neurons: 6
 >> iter 81000, loss: 0.515039
 >> iter 82000, loss: 0.507304
 >> iter 83000, loss: 0.404650
 >> iter 84000, loss: 0.482382
 >> iter 85000, loss: 0.398353
 >> iter 86000, loss: 0.417194
 >> iter 87000, loss: 0.430055
 >> iter 88000, loss: 0.544917
 >> iter 89000, loss: 0.564061
 >> iter 90000, loss: 0.524386
   Number of active neurons: 5
 >> iter 91000, loss: 0.428391
 >> iter 92000, loss: 0.453306
 >> iter 93000, loss: 0.480709
 >> iter 94000, loss: 0.386367
 >> iter 95000, loss: 0.722099
 >> iter 96000, loss: 0.490862
 >> iter 97000, loss: 0.486125
 >> iter 98000, loss: 0.433470
 >> iter 99000, loss: 0.610001
 >> iter 100000, loss: 0.418548
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

