 > Problema: tomita3nueva
 > Args:
   - Hidden size: 10
   - Noise level: 0.0
   - Regu L1: 2e-05
   - Shock: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.193888
 >> iter 2000, loss: 6.967764
 >> iter 3000, loss: 2.592835
 >> iter 4000, loss: 0.972903
 >> iter 5000, loss: 0.372762
 >> iter 6000, loss: 0.149495
 >> iter 7000, loss: 0.074263
 >> iter 8000, loss: 0.037074
 >> iter 9000, loss: 0.022769
 >> iter 10000, loss: 0.016749
   Number of active neurons: 9
 >> iter 11000, loss: 0.014255
 >> iter 12000, loss: 0.012843
 >> iter 13000, loss: 0.012208
 >> iter 14000, loss: 0.011615
 >> iter 15000, loss: 0.011342
 >> iter 16000, loss: 0.010939
 >> iter 17000, loss: 0.010792
 >> iter 18000, loss: 0.010481
 >> iter 19000, loss: 0.010404
 >> iter 20000, loss: 0.010141
   Number of active neurons: 7
 >> iter 21000, loss: 0.010117
 >> iter 22000, loss: 0.009891
 >> iter 23000, loss: 0.009926
 >> iter 24000, loss: 0.009643
 >> iter 25000, loss: 0.031642
 >> iter 26000, loss: 0.017399
 >> iter 27000, loss: 0.012356
 >> iter 28000, loss: 0.010257
 >> iter 29000, loss: 0.106532
 >> iter 30000, loss: 0.045421
   Number of active neurons: 7
 >> iter 31000, loss: 0.024836
 >> iter 32000, loss: 0.015018
 >> iter 33000, loss: 0.033657
 >> iter 34000, loss: 0.018584
 >> iter 35000, loss: 0.013848
 >> iter 36000, loss: 0.010878
 >> iter 37000, loss: 0.016758
 >> iter 38000, loss: 0.011866
 >> iter 39000, loss: 0.026580
 >> iter 40000, loss: 0.015597
   Number of active neurons: 7
 >> iter 41000, loss: 0.072471
 >> iter 42000, loss: 0.032746
 >> iter 43000, loss: 0.018102
 >> iter 44000, loss: 0.012557
 >> iter 45000, loss: 0.010565
 >> iter 46000, loss: 0.009685
 >> iter 47000, loss: 0.012895
 >> iter 48000, loss: 0.010527
 >> iter 49000, loss: 0.024954
 >> iter 50000, loss: 0.017102
   Number of active neurons: 7
 >> iter 51000, loss: 0.012209
 >> iter 52000, loss: 0.009804
 >> iter 53000, loss: 0.014254
 >> iter 54000, loss: 0.010566
 >> iter 55000, loss: 0.043887
 >> iter 56000, loss: 0.021801
 >> iter 57000, loss: 0.020453
 >> iter 58000, loss: 0.013231
 >> iter 59000, loss: 0.010230
 >> iter 60000, loss: 0.009184
   Number of active neurons: 7
 >> iter 61000, loss: 0.017902
 >> iter 62000, loss: 0.012198
 >> iter 63000, loss: 0.009915
 >> iter 64000, loss: 0.009340
 >> iter 65000, loss: 0.011239
 >> iter 66000, loss: 0.009458
 >> iter 67000, loss: 0.008747
 >> iter 68000, loss: 0.009161
 >> iter 69000, loss: 0.011470
 >> iter 70000, loss: 0.009551
   Number of active neurons: 6
 >> iter 71000, loss: 0.008654
 >> iter 72000, loss: 0.012275
 >> iter 73000, loss: 0.049366
 >> iter 74000, loss: 0.024050
 >> iter 75000, loss: 0.014236
 >> iter 76000, loss: 0.014802
 >> iter 77000, loss: 0.017848
 >> iter 78000, loss: 0.012563
 >> iter 79000, loss: 0.010115
 >> iter 80000, loss: 0.013382
   Number of active neurons: 6
 >> iter 81000, loss: 0.013271
 >> iter 82000, loss: 0.010574
 >> iter 83000, loss: 0.010324
 >> iter 84000, loss: 0.013596
 >> iter 85000, loss: 0.010530
 >> iter 86000, loss: 0.009426
 >> iter 87000, loss: 0.008934
 >> iter 88000, loss: 0.013309
 >> iter 89000, loss: 0.010235
 >> iter 90000, loss: 0.013343
   Number of active neurons: 6
 >> iter 91000, loss: 0.010077
 >> iter 92000, loss: 0.012451
 >> iter 93000, loss: 0.009790
 >> iter 94000, loss: 0.011532
 >> iter 95000, loss: 0.009478
 >> iter 96000, loss: 0.011869
 >> iter 97000, loss: 0.009572
 >> iter 98000, loss: 0.012324
 >> iter 99000, loss: 0.009715
 >> iter 100000, loss: 0.012594
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 5.66628891407
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.380596
 >> iter 2000, loss: 7.466816
 >> iter 3000, loss: 2.786702
 >> iter 4000, loss: 1.057092
 >> iter 5000, loss: 0.405390
 >> iter 6000, loss: 0.162738
 >> iter 7000, loss: 0.076847
 >> iter 8000, loss: 0.039045
 >> iter 9000, loss: 0.024311
 >> iter 10000, loss: 0.034621
   Number of active neurons: 10
 >> iter 11000, loss: 0.022446
 >> iter 12000, loss: 0.017342
 >> iter 13000, loss: 0.014985
 >> iter 14000, loss: 0.013791
 >> iter 15000, loss: 0.013100
 >> iter 16000, loss: 0.012659
 >> iter 17000, loss: 0.012334
 >> iter 18000, loss: 0.012138
 >> iter 19000, loss: 0.011904
 >> iter 20000, loss: 0.011798
   Number of active neurons: 10
 >> iter 21000, loss: 0.011603
 >> iter 22000, loss: 0.011550
 >> iter 23000, loss: 0.011365
 >> iter 24000, loss: 0.011358
 >> iter 25000, loss: 0.011169
 >> iter 26000, loss: 0.011157
 >> iter 27000, loss: 0.011004
 >> iter 28000, loss: 0.011013
 >> iter 29000, loss: 0.010861
 >> iter 30000, loss: 0.010892
   Number of active neurons: 10
 >> iter 31000, loss: 0.010735
 >> iter 32000, loss: 0.010772
 >> iter 33000, loss: 0.010608
 >> iter 34000, loss: 0.010674
 >> iter 35000, loss: 0.010505
 >> iter 36000, loss: 0.010585
 >> iter 37000, loss: 0.010435
 >> iter 38000, loss: 0.010495
 >> iter 39000, loss: 0.010335
 >> iter 40000, loss: 0.010403
   Number of active neurons: 10
 >> iter 41000, loss: 0.010202
 >> iter 42000, loss: 0.010312
 >> iter 43000, loss: 0.566320
 >> iter 44000, loss: 0.261860
 >> iter 45000, loss: 0.105796
 >> iter 46000, loss: 0.047325
 >> iter 47000, loss: 0.025350
 >> iter 48000, loss: 0.016913
 >> iter 49000, loss: 0.013623
 >> iter 50000, loss: 0.012210
   Number of active neurons: 9
 >> iter 51000, loss: 0.011595
 >> iter 52000, loss: 0.011259
 >> iter 53000, loss: 0.011052
 >> iter 54000, loss: 0.010904
 >> iter 55000, loss: 0.010781
 >> iter 56000, loss: 0.010694
 >> iter 57000, loss: 0.010604
 >> iter 58000, loss: 0.010548
 >> iter 59000, loss: 0.010462
 >> iter 60000, loss: 0.010428
   Number of active neurons: 9
 >> iter 61000, loss: 0.010325
 >> iter 62000, loss: 0.010304
 >> iter 63000, loss: 0.010196
 >> iter 64000, loss: 0.010187
 >> iter 65000, loss: 0.010062
 >> iter 66000, loss: 0.010061
 >> iter 67000, loss: 0.009905
 >> iter 68000, loss: 0.009953
 >> iter 69000, loss: 0.009755
 >> iter 70000, loss: 0.009835
   Number of active neurons: 9
 >> iter 71000, loss: 0.009664
 >> iter 72000, loss: 0.009771
 >> iter 73000, loss: 0.009615
 >> iter 74000, loss: 0.009726
 >> iter 75000, loss: 0.009579
 >> iter 76000, loss: 0.009718
 >> iter 77000, loss: 0.009552
 >> iter 78000, loss: 0.009685
 >> iter 79000, loss: 0.009514
 >> iter 80000, loss: 0.009663
   Number of active neurons: 9
 >> iter 81000, loss: 0.009492
 >> iter 82000, loss: 0.009624
 >> iter 83000, loss: 0.009439
 >> iter 84000, loss: 0.009634
 >> iter 85000, loss: 0.009451
 >> iter 86000, loss: 0.009587
 >> iter 87000, loss: 0.009335
 >> iter 88000, loss: 0.009617
 >> iter 89000, loss: 0.009378
 >> iter 90000, loss: 0.009555
   Number of active neurons: 9
 >> iter 91000, loss: 0.009268
 >> iter 92000, loss: 0.009665
 >> iter 93000, loss: 0.009350
 >> iter 94000, loss: 0.009481
 >> iter 95000, loss: 0.009198
 >> iter 96000, loss: 0.009842
 >> iter 97000, loss: 0.009335
 >> iter 98000, loss: 0.154278
 >> iter 99000, loss: 0.062888
 >> iter 100000, loss: 0.030481
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 1.37324178388
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.280434
 >> iter 2000, loss: 7.089323
 >> iter 3000, loss: 2.636358
 >> iter 4000, loss: 0.987520
 >> iter 5000, loss: 0.377076
 >> iter 6000, loss: 0.150286
 >> iter 7000, loss: 0.065591
 >> iter 8000, loss: 0.033476
 >> iter 9000, loss: 0.021075
 >> iter 10000, loss: 0.016001
   Number of active neurons: 8
 >> iter 11000, loss: 0.013790
 >> iter 12000, loss: 0.012704
 >> iter 13000, loss: 0.226859
 >> iter 14000, loss: 0.092864
 >> iter 15000, loss: 0.042628
 >> iter 16000, loss: 0.023504
 >> iter 17000, loss: 0.016149
 >> iter 18000, loss: 0.013108
 >> iter 19000, loss: 0.011824
 >> iter 20000, loss: 0.011161
   Number of active neurons: 8
 >> iter 21000, loss: 0.010800
 >> iter 22000, loss: 0.010554
 >> iter 23000, loss: 0.010332
 >> iter 24000, loss: 0.010165
 >> iter 25000, loss: 0.158989
 >> iter 26000, loss: 0.065382
 >> iter 27000, loss: 0.030666
 >> iter 28000, loss: 0.017724
 >> iter 29000, loss: 0.012902
 >> iter 30000, loss: 0.011026
   Number of active neurons: 8
 >> iter 31000, loss: 0.010277
 >> iter 32000, loss: 0.009930
 >> iter 33000, loss: 0.009731
 >> iter 34000, loss: 0.009593
 >> iter 35000, loss: 0.009469
 >> iter 36000, loss: 0.009360
 >> iter 37000, loss: 0.009266
 >> iter 38000, loss: 0.009163
 >> iter 39000, loss: 0.009082
 >> iter 40000, loss: 0.009014
   Number of active neurons: 7
 >> iter 41000, loss: 0.008952
 >> iter 42000, loss: 0.008875
 >> iter 43000, loss: 0.008813
 >> iter 44000, loss: 0.008729
 >> iter 45000, loss: 0.287831
 >> iter 46000, loss: 0.112670
 >> iter 47000, loss: 0.174973
 >> iter 48000, loss: 0.070902
 >> iter 49000, loss: 0.032302
 >> iter 50000, loss: 0.017884
   Number of active neurons: 7
 >> iter 51000, loss: 0.012514
 >> iter 52000, loss: 0.010437
 >> iter 53000, loss: 0.009647
 >> iter 54000, loss: 0.009293
 >> iter 55000, loss: 0.009156
 >> iter 56000, loss: 0.009048
 >> iter 57000, loss: 0.009014
 >> iter 58000, loss: 0.008917
 >> iter 59000, loss: 0.008965
 >> iter 60000, loss: 0.008776
   Number of active neurons: 6
 >> iter 61000, loss: 0.008911
 >> iter 62000, loss: 0.008620
 >> iter 63000, loss: 0.095057
 >> iter 64000, loss: 0.040698
 >> iter 65000, loss: 0.020513
 >> iter 66000, loss: 0.012951
 >> iter 67000, loss: 0.010145
 >> iter 68000, loss: 0.009043
 >> iter 69000, loss: 0.008658
 >> iter 70000, loss: 0.008420
   Number of active neurons: 6
 >> iter 71000, loss: 0.078113
 >> iter 72000, loss: 0.034347
 >> iter 73000, loss: 0.018089
 >> iter 74000, loss: 0.011989
 >> iter 75000, loss: 0.009763
 >> iter 76000, loss: 0.008827
 >> iter 77000, loss: 0.008598
 >> iter 78000, loss: 0.008301
 >> iter 79000, loss: 0.028168
 >> iter 80000, loss: 0.015384
   Number of active neurons: 6
 >> iter 81000, loss: 0.010510
 >> iter 82000, loss: 0.008666
 >> iter 83000, loss: 0.008024
 >> iter 84000, loss: 0.007762
 >> iter 85000, loss: 0.007936
 >> iter 86000, loss: 0.007715
 >> iter 87000, loss: 0.062212
 >> iter 88000, loss: 0.027745
 >> iter 89000, loss: 0.015034
 >> iter 90000, loss: 0.010338
   Number of active neurons: 6
 >> iter 91000, loss: 0.008666
 >> iter 92000, loss: 0.008019
 >> iter 93000, loss: 0.007889
 >> iter 94000, loss: 0.007729
 >> iter 95000, loss: 0.007845
 >> iter 96000, loss: 0.007688
 >> iter 97000, loss: 0.008248
 >> iter 98000, loss: 0.007717
 >> iter 99000, loss: 0.007670
 >> iter 100000, loss: 0.007549
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 19.426366
 >> iter 2000, loss: 8.879571
 >> iter 3000, loss: 3.303119
 >> iter 4000, loss: 1.235449
 >> iter 5000, loss: 0.469683
 >> iter 6000, loss: 0.185244
 >> iter 7000, loss: 0.088049
 >> iter 8000, loss: 0.042571
 >> iter 9000, loss: 0.024858
 >> iter 10000, loss: 0.017669
   Number of active neurons: 9
 >> iter 11000, loss: 0.014776
 >> iter 12000, loss: 0.013330
 >> iter 13000, loss: 0.214047
 >> iter 14000, loss: 0.087786
 >> iter 15000, loss: 0.040386
 >> iter 16000, loss: 0.022444
 >> iter 17000, loss: 0.015709
 >> iter 18000, loss: 0.012995
 >> iter 19000, loss: 0.011885
 >> iter 20000, loss: 0.011326
   Number of active neurons: 10
 >> iter 21000, loss: 0.010996
 >> iter 22000, loss: 0.143965
 >> iter 23000, loss: 0.061057
 >> iter 24000, loss: 0.029756
 >> iter 25000, loss: 0.018096
 >> iter 26000, loss: 0.013481
 >> iter 27000, loss: 0.011651
 >> iter 28000, loss: 0.010774
 >> iter 29000, loss: 0.010367
 >> iter 30000, loss: 0.010087
   Number of active neurons: 9
 >> iter 31000, loss: 0.009924
 >> iter 32000, loss: 0.009781
 >> iter 33000, loss: 0.009643
 >> iter 34000, loss: 0.009571
 >> iter 35000, loss: 0.009413
 >> iter 36000, loss: 0.009380
 >> iter 37000, loss: 0.009214
 >> iter 38000, loss: 0.009208
 >> iter 39000, loss: 0.009035
 >> iter 40000, loss: 0.009115
   Number of active neurons: 9
 >> iter 41000, loss: 0.008914
 >> iter 42000, loss: 0.008954
 >> iter 43000, loss: 0.008737
 >> iter 44000, loss: 0.008944
 >> iter 45000, loss: 0.009347
 >> iter 46000, loss: 0.008817
 >> iter 47000, loss: 0.008633
 >> iter 48000, loss: 0.098335
 >> iter 49000, loss: 0.236264
 >> iter 50000, loss: 0.107782
   Number of active neurons: 8
 >> iter 51000, loss: 0.045343
 >> iter 52000, loss: 0.022281
 >> iter 53000, loss: 0.013795
 >> iter 54000, loss: 0.010676
 >> iter 55000, loss: 0.009528
 >> iter 56000, loss: 0.009143
 >> iter 57000, loss: 0.008928
 >> iter 58000, loss: 0.008951
 >> iter 59000, loss: 0.008756
 >> iter 60000, loss: 0.009135
   Number of active neurons: 9
 >> iter 61000, loss: 0.008719
 >> iter 62000, loss: 0.008493
 >> iter 63000, loss: 0.009004
 >> iter 64000, loss: 0.008400
 >> iter 65000, loss: 0.008223
 >> iter 66000, loss: 0.020851
 >> iter 67000, loss: 0.012768
 >> iter 68000, loss: 0.009791
 >> iter 69000, loss: 0.008728
 >> iter 70000, loss: 0.033717
   Number of active neurons: 7
 >> iter 71000, loss: 0.017538
 >> iter 72000, loss: 0.014710
 >> iter 73000, loss: 0.010508
 >> iter 74000, loss: 0.009070
 >> iter 75000, loss: 0.008471
 >> iter 76000, loss: 0.010685
 >> iter 77000, loss: 0.048483
 >> iter 78000, loss: 0.022825
 >> iter 79000, loss: 0.013213
 >> iter 80000, loss: 0.010242
   Number of active neurons: 7
 >> iter 81000, loss: 0.008579
 >> iter 82000, loss: 0.008944
 >> iter 83000, loss: 0.013605
 >> iter 84000, loss: 0.009772
 >> iter 85000, loss: 0.008489
 >> iter 86000, loss: 0.015219
 >> iter 87000, loss: 0.655680
 >> iter 88000, loss: 0.252909
 >> iter 89000, loss: 0.102536
 >> iter 90000, loss: 0.046149
   Number of active neurons: 7
 >> iter 91000, loss: 0.024707
 >> iter 92000, loss: 0.016407
 >> iter 93000, loss: 0.013016
 >> iter 94000, loss: 0.011620
 >> iter 95000, loss: 0.010784
 >> iter 96000, loss: 0.010325
 >> iter 97000, loss: 0.010071
 >> iter 98000, loss: 0.009851
 >> iter 99000, loss: 0.009754
 >> iter 100000, loss: 0.009576
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00599994000061
   - Test - A: 0.0
   - Test - B: 5.81961202586
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.641896
 >> iter 2000, loss: 7.568102
 >> iter 3000, loss: 2.859160
 >> iter 4000, loss: 1.105630
 >> iter 5000, loss: 0.423820
 >> iter 6000, loss: 0.169656
 >> iter 7000, loss: 0.074508
 >> iter 8000, loss: 0.038225
 >> iter 9000, loss: 0.024287
 >> iter 10000, loss: 0.018404
   Number of active neurons: 10
 >> iter 11000, loss: 0.016026
 >> iter 12000, loss: 0.014638
 >> iter 13000, loss: 0.014106
 >> iter 14000, loss: 0.013504
 >> iter 15000, loss: 0.014186
 >> iter 16000, loss: 0.013036
 >> iter 17000, loss: 0.027776
 >> iter 18000, loss: 0.017937
 >> iter 19000, loss: 0.017376
 >> iter 20000, loss: 0.013541
   Number of active neurons: 10
 >> iter 21000, loss: 0.015084
 >> iter 22000, loss: 0.012504
 >> iter 23000, loss: 0.012556
 >> iter 24000, loss: 0.011412
 >> iter 25000, loss: 0.079624
 >> iter 26000, loss: 0.036265
 >> iter 27000, loss: 0.038496
 >> iter 28000, loss: 0.021126
 >> iter 29000, loss: 0.014809
 >> iter 30000, loss: 0.012332
   Number of active neurons: 9
 >> iter 31000, loss: 0.014569
 >> iter 32000, loss: 0.011829
 >> iter 33000, loss: 0.010960
 >> iter 34000, loss: 0.010568
 >> iter 35000, loss: 0.020450
 >> iter 36000, loss: 0.013843
 >> iter 37000, loss: 0.022369
 >> iter 38000, loss: 0.014592
 >> iter 39000, loss: 0.011860
 >> iter 40000, loss: 0.010789
   Number of active neurons: 9
 >> iter 41000, loss: 0.082127
 >> iter 42000, loss: 0.037072
 >> iter 43000, loss: 0.035592
 >> iter 44000, loss: 0.019696
 >> iter 45000, loss: 0.013713
 >> iter 46000, loss: 0.011356
 >> iter 47000, loss: 0.021626
 >> iter 48000, loss: 0.014187
 >> iter 49000, loss: 0.011455
 >> iter 50000, loss: 0.010366
   Number of active neurons: 9
 >> iter 51000, loss: 0.058480
 >> iter 52000, loss: 0.027537
 >> iter 53000, loss: 0.015879
 >> iter 54000, loss: 0.011596
 >> iter 55000, loss: 0.016091
 >> iter 56000, loss: 0.011688
 >> iter 57000, loss: 0.018943
 >> iter 58000, loss: 0.012785
 >> iter 59000, loss: 0.010608
 >> iter 60000, loss: 0.009834
   Number of active neurons: 9
 >> iter 61000, loss: 0.009625
 >> iter 62000, loss: 0.009518
 >> iter 63000, loss: 0.009543
 >> iter 64000, loss: 0.009519
 >> iter 65000, loss: 0.009568
 >> iter 66000, loss: 0.009555
 >> iter 67000, loss: 0.009598
 >> iter 68000, loss: 0.009595
 >> iter 69000, loss: 0.009624
 >> iter 70000, loss: 0.009622
   Number of active neurons: 9
 >> iter 71000, loss: 0.009652
 >> iter 72000, loss: 0.009640
 >> iter 73000, loss: 0.009673
 >> iter 74000, loss: 0.009653
 >> iter 75000, loss: 0.009682
 >> iter 76000, loss: 0.009674
 >> iter 77000, loss: 0.009695
 >> iter 78000, loss: 0.009688
 >> iter 79000, loss: 0.009705
 >> iter 80000, loss: 0.009683
   Number of active neurons: 9
 >> iter 81000, loss: 0.009694
 >> iter 82000, loss: 0.009671
 >> iter 83000, loss: 0.009675
 >> iter 84000, loss: 0.009653
 >> iter 85000, loss: 0.009670
 >> iter 86000, loss: 0.009647
 >> iter 87000, loss: 0.009653
 >> iter 88000, loss: 0.009638
 >> iter 89000, loss: 0.009627
 >> iter 90000, loss: 0.009608
   Number of active neurons: 9
 >> iter 91000, loss: 0.009591
 >> iter 92000, loss: 0.009571
 >> iter 93000, loss: 0.009565
 >> iter 94000, loss: 0.009541
 >> iter 95000, loss: 0.009555
 >> iter 96000, loss: 0.009517
 >> iter 97000, loss: 0.009533
 >> iter 98000, loss: 0.009495
 >> iter 99000, loss: 0.009520
 >> iter 100000, loss: 0.009477
   Number of active neurons: 9
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.801650
 >> iter 2000, loss: 7.934828
 >> iter 3000, loss: 3.026825
 >> iter 4000, loss: 1.142917
 >> iter 5000, loss: 0.438118
 >> iter 6000, loss: 0.179261
 >> iter 7000, loss: 0.077725
 >> iter 8000, loss: 0.040837
 >> iter 9000, loss: 0.024486
 >> iter 10000, loss: 0.020277
   Number of active neurons: 10
 >> iter 11000, loss: 0.015798
 >> iter 12000, loss: 0.015453
 >> iter 13000, loss: 0.013347
 >> iter 14000, loss: 0.012947
 >> iter 15000, loss: 0.012025
 >> iter 16000, loss: 0.033440
 >> iter 17000, loss: 0.157611
 >> iter 18000, loss: 0.111657
 >> iter 19000, loss: 0.049383
 >> iter 20000, loss: 0.028691
   Number of active neurons: 9
 >> iter 21000, loss: 0.018151
 >> iter 22000, loss: 0.024489
 >> iter 23000, loss: 0.015882
 >> iter 24000, loss: 0.015685
 >> iter 25000, loss: 0.012376
 >> iter 26000, loss: 0.041237
 >> iter 27000, loss: 0.021786
 >> iter 28000, loss: 0.016838
 >> iter 29000, loss: 0.012526
 >> iter 30000, loss: 0.015246
   Number of active neurons: 8
 >> iter 31000, loss: 0.011818
 >> iter 32000, loss: 0.014369
 >> iter 33000, loss: 0.011337
 >> iter 34000, loss: 0.013686
 >> iter 35000, loss: 0.010884
 >> iter 36000, loss: 0.012977
 >> iter 37000, loss: 0.010460
 >> iter 38000, loss: 0.011676
 >> iter 39000, loss: 0.009848
 >> iter 40000, loss: 0.213548
   Number of active neurons: 8
 >> iter 41000, loss: 0.085564
 >> iter 42000, loss: 0.041609
 >> iter 43000, loss: 0.021461
 >> iter 44000, loss: 0.017597
 >> iter 45000, loss: 0.012392
 >> iter 46000, loss: 0.013758
 >> iter 47000, loss: 0.010888
 >> iter 48000, loss: 0.013223
 >> iter 49000, loss: 0.010646
 >> iter 50000, loss: 0.013588
   Number of active neurons: 8
 >> iter 51000, loss: 0.010623
 >> iter 52000, loss: 0.013797
 >> iter 53000, loss: 0.010467
 >> iter 54000, loss: 0.012613
 >> iter 55000, loss: 0.009968
 >> iter 56000, loss: 0.011838
 >> iter 57000, loss: 0.009582
 >> iter 58000, loss: 0.010803
 >> iter 59000, loss: 0.009054
 >> iter 60000, loss: 0.010210
   Number of active neurons: 8
 >> iter 61000, loss: 0.008817
 >> iter 62000, loss: 0.009295
 >> iter 63000, loss: 0.008447
 >> iter 64000, loss: 0.008913
 >> iter 65000, loss: 0.008304
 >> iter 66000, loss: 0.008899
 >> iter 67000, loss: 0.008297
 >> iter 68000, loss: 0.008724
 >> iter 69000, loss: 0.210986
 >> iter 70000, loss: 0.088791
   Number of active neurons: 8
 >> iter 71000, loss: 0.038305
 >> iter 72000, loss: 0.020065
 >> iter 73000, loss: 0.013083
 >> iter 74000, loss: 0.011143
 >> iter 75000, loss: 0.009747
 >> iter 76000, loss: 0.009538
 >> iter 77000, loss: 0.009124
 >> iter 78000, loss: 0.009200
 >> iter 79000, loss: 0.009002
 >> iter 80000, loss: 0.009125
   Number of active neurons: 8
 >> iter 81000, loss: 0.008962
 >> iter 82000, loss: 0.009090
 >> iter 83000, loss: 0.008942
 >> iter 84000, loss: 0.009084
 >> iter 85000, loss: 0.008935
 >> iter 86000, loss: 0.009086
 >> iter 87000, loss: 0.009579
 >> iter 88000, loss: 0.009849
 >> iter 89000, loss: 0.009077
 >> iter 90000, loss: 0.009058
   Number of active neurons: 7
 >> iter 91000, loss: 0.008852
 >> iter 92000, loss: 0.009252
 >> iter 93000, loss: 0.008888
 >> iter 94000, loss: 0.009099
 >> iter 95000, loss: 0.008870
 >> iter 96000, loss: 0.009170
 >> iter 97000, loss: 0.189493
 >> iter 98000, loss: 0.089293
 >> iter 99000, loss: 0.039191
 >> iter 100000, loss: 0.020714
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 14.479034731
   - Test - B: 17.0921938537
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.267861
 >> iter 2000, loss: 7.233255
 >> iter 3000, loss: 2.692266
 >> iter 4000, loss: 1.009722
 >> iter 5000, loss: 0.386577
 >> iter 6000, loss: 0.154748
 >> iter 7000, loss: 0.068267
 >> iter 8000, loss: 0.035238
 >> iter 9000, loss: 0.022577
 >> iter 10000, loss: 0.017199
   Number of active neurons: 10
 >> iter 11000, loss: 0.015002
 >> iter 12000, loss: 0.013669
 >> iter 13000, loss: 0.013090
 >> iter 14000, loss: 0.012457
 >> iter 15000, loss: 0.012205
 >> iter 16000, loss: 0.011761
 >> iter 17000, loss: 0.011620
 >> iter 18000, loss: 0.011251
 >> iter 19000, loss: 0.011149
 >> iter 20000, loss: 0.010827
   Number of active neurons: 9
 >> iter 21000, loss: 0.010781
 >> iter 22000, loss: 0.010516
 >> iter 23000, loss: 0.010507
 >> iter 24000, loss: 0.010283
 >> iter 25000, loss: 0.010291
 >> iter 26000, loss: 0.010101
 >> iter 27000, loss: 0.010114
 >> iter 28000, loss: 0.009948
 >> iter 29000, loss: 0.009968
 >> iter 30000, loss: 0.009819
   Number of active neurons: 8
 >> iter 31000, loss: 0.009849
 >> iter 32000, loss: 0.009710
 >> iter 33000, loss: 0.009738
 >> iter 34000, loss: 0.009611
 >> iter 35000, loss: 0.009644
 >> iter 36000, loss: 0.009517
 >> iter 37000, loss: 0.009557
 >> iter 38000, loss: 0.009429
 >> iter 39000, loss: 0.009483
 >> iter 40000, loss: 0.009364
   Number of active neurons: 8
 >> iter 41000, loss: 0.009405
 >> iter 42000, loss: 0.009294
 >> iter 43000, loss: 0.009330
 >> iter 44000, loss: 0.009231
 >> iter 45000, loss: 0.009262
 >> iter 46000, loss: 0.009167
 >> iter 47000, loss: 0.009174
 >> iter 48000, loss: 0.009080
 >> iter 49000, loss: 0.009076
 >> iter 50000, loss: 0.008983
   Number of active neurons: 8
 >> iter 51000, loss: 0.008993
 >> iter 52000, loss: 0.008916
 >> iter 53000, loss: 0.008913
 >> iter 54000, loss: 0.008830
 >> iter 55000, loss: 0.008834
 >> iter 56000, loss: 0.008758
 >> iter 57000, loss: 0.008771
 >> iter 58000, loss: 0.008694
 >> iter 59000, loss: 0.008708
 >> iter 60000, loss: 0.008648
   Number of active neurons: 8
 >> iter 61000, loss: 0.008669
 >> iter 62000, loss: 0.008607
 >> iter 63000, loss: 0.008642
 >> iter 64000, loss: 0.008583
 >> iter 65000, loss: 0.008617
 >> iter 66000, loss: 0.008561
 >> iter 67000, loss: 0.008584
 >> iter 68000, loss: 0.008526
 >> iter 69000, loss: 0.008532
 >> iter 70000, loss: 0.008480
   Number of active neurons: 8
 >> iter 71000, loss: 0.008493
 >> iter 72000, loss: 0.008438
 >> iter 73000, loss: 0.008456
 >> iter 74000, loss: 0.008398
 >> iter 75000, loss: 0.008424
 >> iter 76000, loss: 0.008377
 >> iter 77000, loss: 0.008392
 >> iter 78000, loss: 0.008352
 >> iter 79000, loss: 0.008372
 >> iter 80000, loss: 0.008328
   Number of active neurons: 8
 >> iter 81000, loss: 0.008349
 >> iter 82000, loss: 0.008311
 >> iter 83000, loss: 0.008330
 >> iter 84000, loss: 0.008291
 >> iter 85000, loss: 0.008322
 >> iter 86000, loss: 0.008279
 >> iter 87000, loss: 0.008305
 >> iter 88000, loss: 0.008274
 >> iter 89000, loss: 0.008286
 >> iter 90000, loss: 0.008267
   Number of active neurons: 8
 >> iter 91000, loss: 0.008271
 >> iter 92000, loss: 0.008253
 >> iter 93000, loss: 0.008258
 >> iter 94000, loss: 0.008239
 >> iter 95000, loss: 0.008259
 >> iter 96000, loss: 0.008227
 >> iter 97000, loss: 0.008245
 >> iter 98000, loss: 0.008216
 >> iter 99000, loss: 0.008240
 >> iter 100000, loss: 0.008207
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 13.0924605026
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.306889
 >> iter 2000, loss: 7.613883
 >> iter 3000, loss: 2.902590
 >> iter 4000, loss: 1.087708
 >> iter 5000, loss: 0.414286
 >> iter 6000, loss: 0.164127
 >> iter 7000, loss: 0.070878
 >> iter 8000, loss: 0.035577
 >> iter 9000, loss: 0.022091
 >> iter 10000, loss: 0.016584
   Number of active neurons: 10
 >> iter 11000, loss: 0.014312
 >> iter 12000, loss: 0.013131
 >> iter 13000, loss: 0.012538
 >> iter 14000, loss: 0.012080
 >> iter 15000, loss: 0.011789
 >> iter 16000, loss: 0.011504
 >> iter 17000, loss: 0.011311
 >> iter 18000, loss: 0.011094
 >> iter 19000, loss: 0.010965
 >> iter 20000, loss: 0.010773
   Number of active neurons: 10
 >> iter 21000, loss: 0.010720
 >> iter 22000, loss: 0.011086
 >> iter 23000, loss: 0.010674
 >> iter 24000, loss: 0.012372
 >> iter 25000, loss: 0.010834
 >> iter 26000, loss: 0.010165
 >> iter 27000, loss: 0.010028
 >> iter 28000, loss: 0.009986
 >> iter 29000, loss: 0.009847
 >> iter 30000, loss: 0.010322
   Number of active neurons: 8
 >> iter 31000, loss: 0.009738
 >> iter 32000, loss: 0.009493
 >> iter 33000, loss: 0.009473
 >> iter 34000, loss: 0.010333
 >> iter 35000, loss: 0.009541
 >> iter 36000, loss: 0.009259
 >> iter 37000, loss: 0.009184
 >> iter 38000, loss: 0.009089
 >> iter 39000, loss: 0.009106
 >> iter 40000, loss: 0.009055
   Number of active neurons: 8
 >> iter 41000, loss: 0.009070
 >> iter 42000, loss: 0.009046
 >> iter 43000, loss: 0.009038
 >> iter 44000, loss: 0.009033
 >> iter 45000, loss: 0.009011
 >> iter 46000, loss: 0.009000
 >> iter 47000, loss: 0.008978
 >> iter 48000, loss: 0.008963
 >> iter 49000, loss: 0.008945
 >> iter 50000, loss: 0.008925
   Number of active neurons: 8
 >> iter 51000, loss: 0.008912
 >> iter 52000, loss: 0.008891
 >> iter 53000, loss: 0.008867
 >> iter 54000, loss: 0.008845
 >> iter 55000, loss: 0.008831
 >> iter 56000, loss: 0.008811
 >> iter 57000, loss: 0.008803
 >> iter 58000, loss: 0.008778
 >> iter 59000, loss: 0.008772
 >> iter 60000, loss: 0.008748
   Number of active neurons: 8
 >> iter 61000, loss: 0.008745
 >> iter 62000, loss: 0.008705
 >> iter 63000, loss: 0.008705
 >> iter 64000, loss: 0.008663
 >> iter 65000, loss: 0.008661
 >> iter 66000, loss: 0.008618
 >> iter 67000, loss: 0.008625
 >> iter 68000, loss: 0.008582
 >> iter 69000, loss: 0.008581
 >> iter 70000, loss: 0.008541
   Number of active neurons: 8
 >> iter 71000, loss: 0.008553
 >> iter 72000, loss: 0.008511
 >> iter 73000, loss: 0.008532
 >> iter 74000, loss: 0.008483
 >> iter 75000, loss: 0.008507
 >> iter 76000, loss: 0.008465
 >> iter 77000, loss: 0.008484
 >> iter 78000, loss: 0.008446
 >> iter 79000, loss: 0.008471
 >> iter 80000, loss: 0.008430
   Number of active neurons: 8
 >> iter 81000, loss: 0.008457
 >> iter 82000, loss: 0.008419
 >> iter 83000, loss: 0.008449
 >> iter 84000, loss: 0.008409
 >> iter 85000, loss: 0.008448
 >> iter 86000, loss: 0.008410
 >> iter 87000, loss: 0.008445
 >> iter 88000, loss: 0.008411
 >> iter 89000, loss: 0.008440
 >> iter 90000, loss: 0.008407
   Number of active neurons: 8
 >> iter 91000, loss: 0.008429
 >> iter 92000, loss: 0.008390
 >> iter 93000, loss: 0.008414
 >> iter 94000, loss: 0.008370
 >> iter 95000, loss: 0.008409
 >> iter 96000, loss: 0.008354
 >> iter 97000, loss: 0.008399
 >> iter 98000, loss: 0.008342
 >> iter 99000, loss: 0.008391
 >> iter 100000, loss: 0.008329
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 15.8122791814
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.121416
 >> iter 2000, loss: 7.349614
 >> iter 3000, loss: 2.744695
 >> iter 4000, loss: 1.031389
 >> iter 5000, loss: 0.391543
 >> iter 6000, loss: 0.153811
 >> iter 7000, loss: 0.065536
 >> iter 8000, loss: 0.031947
 >> iter 9000, loss: 0.055934
 >> iter 10000, loss: 0.027694
   Number of active neurons: 10
 >> iter 11000, loss: 0.017071
 >> iter 12000, loss: 0.012939
 >> iter 13000, loss: 0.012337
 >> iter 14000, loss: 0.010699
 >> iter 15000, loss: 0.041924
 >> iter 16000, loss: 0.021659
 >> iter 17000, loss: 0.022403
 >> iter 18000, loss: 0.014338
 >> iter 19000, loss: 0.012763
 >> iter 20000, loss: 0.010601
   Number of active neurons: 10
 >> iter 21000, loss: 0.016400
 >> iter 22000, loss: 0.011719
 >> iter 23000, loss: 0.010072
 >> iter 24000, loss: 0.009432
 >> iter 25000, loss: 0.009371
 >> iter 26000, loss: 0.009193
 >> iter 27000, loss: 0.015890
 >> iter 28000, loss: 0.011575
 >> iter 29000, loss: 0.027876
 >> iter 30000, loss: 0.015762
   Number of active neurons: 10
 >> iter 31000, loss: 0.011375
 >> iter 32000, loss: 0.009737
 >> iter 33000, loss: 0.023236
 >> iter 34000, loss: 0.013974
 >> iter 35000, loss: 0.012307
 >> iter 36000, loss: 0.009959
 >> iter 37000, loss: 0.009458
 >> iter 38000, loss: 0.008727
 >> iter 39000, loss: 0.021911
 >> iter 40000, loss: 0.013235
   Number of active neurons: 8
 >> iter 41000, loss: 0.011211
 >> iter 42000, loss: 0.009391
 >> iter 43000, loss: 0.008764
 >> iter 44000, loss: 0.008579
 >> iter 45000, loss: 0.008589
 >> iter 46000, loss: 0.008582
 >> iter 47000, loss: 0.008611
 >> iter 48000, loss: 0.008633
 >> iter 49000, loss: 0.008633
 >> iter 50000, loss: 0.008650
   Number of active neurons: 8
 >> iter 51000, loss: 0.008630
 >> iter 52000, loss: 0.008666
 >> iter 53000, loss: 0.008629
 >> iter 54000, loss: 0.008648
 >> iter 55000, loss: 0.008638
 >> iter 56000, loss: 0.008612
 >> iter 57000, loss: 0.008635
 >> iter 58000, loss: 0.008566
 >> iter 59000, loss: 0.008548
 >> iter 60000, loss: 0.008510
   Number of active neurons: 7
 >> iter 61000, loss: 0.008656
 >> iter 62000, loss: 0.008483
 >> iter 63000, loss: 0.008385
 >> iter 64000, loss: 0.008395
 >> iter 65000, loss: 0.008790
 >> iter 66000, loss: 0.008444
 >> iter 67000, loss: 0.008296
 >> iter 68000, loss: 0.008316
 >> iter 69000, loss: 0.008736
 >> iter 70000, loss: 0.008404
   Number of active neurons: 7
 >> iter 71000, loss: 0.008257
 >> iter 72000, loss: 0.008280
 >> iter 73000, loss: 0.034414
 >> iter 74000, loss: 0.017675
 >> iter 75000, loss: 0.011501
 >> iter 76000, loss: 0.009280
 >> iter 77000, loss: 0.008762
 >> iter 78000, loss: 0.008351
 >> iter 79000, loss: 0.008179
 >> iter 80000, loss: 0.008188
   Number of active neurons: 7
 >> iter 81000, loss: 0.043647
 >> iter 82000, loss: 0.021284
 >> iter 83000, loss: 0.097618
 >> iter 84000, loss: 0.041171
 >> iter 85000, loss: 0.020518
 >> iter 86000, loss: 0.012562
 >> iter 87000, loss: 0.009688
 >> iter 88000, loss: 0.008676
 >> iter 89000, loss: 0.008569
 >> iter 90000, loss: 0.008323
   Number of active neurons: 7
 >> iter 91000, loss: 0.008267
 >> iter 92000, loss: 0.008293
 >> iter 93000, loss: 0.008440
 >> iter 94000, loss: 0.008350
 >> iter 95000, loss: 0.008397
 >> iter 96000, loss: 0.008371
 >> iter 97000, loss: 0.008630
 >> iter 98000, loss: 0.008434
 >> iter 99000, loss: 0.008440
 >> iter 100000, loss: 0.008406
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0049997500125
   - Test - Big: 0.0
   - Test - A: 5.97293513766
   - Test - B: 0.0333311112592
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.262164
 >> iter 2000, loss: 7.581180
 >> iter 3000, loss: 2.833901
 >> iter 4000, loss: 1.073875
 >> iter 5000, loss: 0.413347
 >> iter 6000, loss: 0.170133
 >> iter 7000, loss: 0.075850
 >> iter 8000, loss: 0.055676
 >> iter 9000, loss: 0.030838
 >> iter 10000, loss: 0.019271
   Number of active neurons: 9
 >> iter 11000, loss: 0.014516
 >> iter 12000, loss: 0.013791
 >> iter 13000, loss: 0.022950
 >> iter 14000, loss: 0.015307
 >> iter 15000, loss: 0.012094
 >> iter 16000, loss: 0.010730
 >> iter 17000, loss: 0.018598
 >> iter 18000, loss: 0.013022
 >> iter 19000, loss: 0.011105
 >> iter 20000, loss: 0.010347
   Number of active neurons: 9
 >> iter 21000, loss: 0.016212
 >> iter 22000, loss: 0.012887
 >> iter 23000, loss: 0.011047
 >> iter 24000, loss: 0.010423
 >> iter 25000, loss: 0.010216
 >> iter 26000, loss: 0.010370
 >> iter 27000, loss: 0.010161
 >> iter 28000, loss: 0.010176
 >> iter 29000, loss: 0.010093
 >> iter 30000, loss: 0.010152
   Number of active neurons: 9
 >> iter 31000, loss: 0.010044
 >> iter 32000, loss: 0.010022
 >> iter 33000, loss: 0.009936
 >> iter 34000, loss: 0.009910
 >> iter 35000, loss: 0.009828
 >> iter 36000, loss: 0.009816
 >> iter 37000, loss: 0.009728
 >> iter 38000, loss: 0.009700
 >> iter 39000, loss: 0.009635
 >> iter 40000, loss: 0.009623
   Number of active neurons: 9
 >> iter 41000, loss: 0.009566
 >> iter 42000, loss: 0.009583
 >> iter 43000, loss: 0.009517
 >> iter 44000, loss: 0.009643
 >> iter 45000, loss: 0.009484
 >> iter 46000, loss: 0.013738
 >> iter 47000, loss: 0.010633
 >> iter 48000, loss: 0.009551
 >> iter 49000, loss: 0.009117
 >> iter 50000, loss: 0.009261
   Number of active neurons: 9
 >> iter 51000, loss: 0.009127
 >> iter 52000, loss: 0.177310
 >> iter 53000, loss: 0.073251
 >> iter 54000, loss: 0.033707
 >> iter 55000, loss: 0.026010
 >> iter 56000, loss: 0.015656
 >> iter 57000, loss: 0.011931
 >> iter 58000, loss: 0.074781
 >> iter 59000, loss: 0.034135
 >> iter 60000, loss: 0.018925
   Number of active neurons: 7
 >> iter 61000, loss: 0.012701
 >> iter 62000, loss: 0.089848
 >> iter 63000, loss: 0.039312
 >> iter 64000, loss: 0.024752
 >> iter 65000, loss: 0.014935
 >> iter 66000, loss: 0.011246
 >> iter 67000, loss: 0.009906
 >> iter 68000, loss: 0.009513
 >> iter 69000, loss: 0.009333
 >> iter 70000, loss: 0.009408
   Number of active neurons: 7
 >> iter 71000, loss: 0.009327
 >> iter 72000, loss: 0.035399
 >> iter 73000, loss: 0.018693
 >> iter 74000, loss: 0.012345
 >> iter 75000, loss: 0.010582
 >> iter 76000, loss: 0.009187
 >> iter 77000, loss: 0.008694
 >> iter 78000, loss: 0.021718
 >> iter 79000, loss: 0.091960
 >> iter 80000, loss: 0.039552
   Number of active neurons: 7
 >> iter 81000, loss: 0.019901
 >> iter 82000, loss: 0.032079
 >> iter 83000, loss: 0.017059
 >> iter 84000, loss: 0.011463
 >> iter 85000, loss: 0.009404
 >> iter 86000, loss: 0.008796
 >> iter 87000, loss: 0.008552
 >> iter 88000, loss: 0.027318
 >> iter 89000, loss: 0.015399
 >> iter 90000, loss: 0.010801
   Number of active neurons: 7
 >> iter 91000, loss: 0.009578
 >> iter 92000, loss: 0.008535
 >> iter 93000, loss: 0.008194
 >> iter 94000, loss: 0.008251
 >> iter 95000, loss: 0.008250
 >> iter 96000, loss: 0.013382
 >> iter 97000, loss: 0.012965
 >> iter 98000, loss: 0.009860
 >> iter 99000, loss: 0.014436
 >> iter 100000, loss: 0.010433
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.00199998000021
   - Test - A: 0.0
   - Test - B: 4.85300979935
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.847685
 >> iter 2000, loss: 7.710370
 >> iter 3000, loss: 2.876390
 >> iter 4000, loss: 1.090803
 >> iter 5000, loss: 0.418199
 >> iter 6000, loss: 0.167772
 >> iter 7000, loss: 0.073748
 >> iter 8000, loss: 0.038054
 >> iter 9000, loss: 0.024040
 >> iter 10000, loss: 0.018489
   Number of active neurons: 9
 >> iter 11000, loss: 0.015659
 >> iter 12000, loss: 0.014658
 >> iter 13000, loss: 0.013567
 >> iter 14000, loss: 0.013474
 >> iter 15000, loss: 0.012638
 >> iter 16000, loss: 0.014113
 >> iter 17000, loss: 0.012521
 >> iter 18000, loss: 0.012839
 >> iter 19000, loss: 0.011834
 >> iter 20000, loss: 0.101981
   Number of active neurons: 9
 >> iter 21000, loss: 0.045344
 >> iter 22000, loss: 0.024593
 >> iter 23000, loss: 0.016032
 >> iter 24000, loss: 0.013288
 >> iter 25000, loss: 0.011537
 >> iter 26000, loss: 0.012736
 >> iter 27000, loss: 0.011254
 >> iter 28000, loss: 0.011807
 >> iter 29000, loss: 0.010840
 >> iter 30000, loss: 0.075958
   Number of active neurons: 9
 >> iter 31000, loss: 0.035243
 >> iter 32000, loss: 0.020284
 >> iter 33000, loss: 0.014039
 >> iter 34000, loss: 0.019370
 >> iter 35000, loss: 0.013636
 >> iter 36000, loss: 0.013099
 >> iter 37000, loss: 0.011215
 >> iter 38000, loss: 0.011628
 >> iter 39000, loss: 0.010626
 >> iter 40000, loss: 0.026462
   Number of active neurons: 9
 >> iter 41000, loss: 0.015840
 >> iter 42000, loss: 0.011926
 >> iter 43000, loss: 0.010518
 >> iter 44000, loss: 0.010296
 >> iter 45000, loss: 0.009902
 >> iter 46000, loss: 0.010438
 >> iter 47000, loss: 0.009920
 >> iter 48000, loss: 0.010573
 >> iter 49000, loss: 0.009944
 >> iter 50000, loss: 0.010404
   Number of active neurons: 9
 >> iter 51000, loss: 0.009834
 >> iter 52000, loss: 0.010237
 >> iter 53000, loss: 0.009749
 >> iter 54000, loss: 0.010436
 >> iter 55000, loss: 0.009784
 >> iter 56000, loss: 0.009985
 >> iter 57000, loss: 0.009570
 >> iter 58000, loss: 0.019279
 >> iter 59000, loss: 0.012912
 >> iter 60000, loss: 0.010680
   Number of active neurons: 9
 >> iter 61000, loss: 0.009830
 >> iter 62000, loss: 0.010219
 >> iter 63000, loss: 0.009587
 >> iter 64000, loss: 0.009713
 >> iter 65000, loss: 0.009398
 >> iter 66000, loss: 0.009920
 >> iter 67000, loss: 0.009399
 >> iter 68000, loss: 0.009556
 >> iter 69000, loss: 0.009241
 >> iter 70000, loss: 0.009620
   Number of active neurons: 8
 >> iter 71000, loss: 0.009219
 >> iter 72000, loss: 0.009425
 >> iter 73000, loss: 0.009136
 >> iter 74000, loss: 0.009378
 >> iter 75000, loss: 0.009095
 >> iter 76000, loss: 0.009324
 >> iter 77000, loss: 0.009042
 >> iter 78000, loss: 0.009272
 >> iter 79000, loss: 0.009003
 >> iter 80000, loss: 0.009231
   Number of active neurons: 8
 >> iter 81000, loss: 0.008973
 >> iter 82000, loss: 0.009195
 >> iter 83000, loss: 0.008940
 >> iter 84000, loss: 0.009140
 >> iter 85000, loss: 0.008900
 >> iter 86000, loss: 0.009106
 >> iter 87000, loss: 0.008865
 >> iter 88000, loss: 0.009078
 >> iter 89000, loss: 0.008839
 >> iter 90000, loss: 0.009060
   Number of active neurons: 8
 >> iter 91000, loss: 0.008822
 >> iter 92000, loss: 0.009034
 >> iter 93000, loss: 0.008814
 >> iter 94000, loss: 0.009016
 >> iter 95000, loss: 0.008820
 >> iter 96000, loss: 0.008989
 >> iter 97000, loss: 0.008805
 >> iter 98000, loss: 0.008950
 >> iter 99000, loss: 0.008792
 >> iter 100000, loss: 0.008950
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 18.845410306
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.679912
 >> iter 2000, loss: 7.684460
 >> iter 3000, loss: 2.890132
 >> iter 4000, loss: 1.087453
 >> iter 5000, loss: 0.422373
 >> iter 6000, loss: 0.205429
 >> iter 7000, loss: 0.089050
 >> iter 8000, loss: 0.045100
 >> iter 9000, loss: 0.039569
 >> iter 10000, loss: 0.025158
   Number of active neurons: 10
 >> iter 11000, loss: 0.018517
 >> iter 12000, loss: 0.015793
 >> iter 13000, loss: 0.121985
 >> iter 14000, loss: 0.057847
 >> iter 15000, loss: 0.088552
 >> iter 16000, loss: 0.042380
 >> iter 17000, loss: 0.024556
 >> iter 18000, loss: 0.017630
 >> iter 19000, loss: 0.034545
 >> iter 20000, loss: 0.187534
   Number of active neurons: 10
 >> iter 21000, loss: 0.152731
 >> iter 22000, loss: 0.065247
 >> iter 23000, loss: 0.048251
 >> iter 24000, loss: 0.025484
 >> iter 25000, loss: 0.027989
 >> iter 26000, loss: 0.018032
 >> iter 27000, loss: 0.013878
 >> iter 28000, loss: 0.012347
 >> iter 29000, loss: 0.011908
 >> iter 30000, loss: 0.011823
   Number of active neurons: 10
 >> iter 31000, loss: 0.011832
 >> iter 32000, loss: 0.011914
 >> iter 33000, loss: 0.102284
 >> iter 34000, loss: 0.046752
 >> iter 35000, loss: 0.046504
 >> iter 36000, loss: 0.052102
 >> iter 37000, loss: 0.027163
 >> iter 38000, loss: 0.017299
 >> iter 39000, loss: 0.013575
 >> iter 40000, loss: 0.012495
   Number of active neurons: 10
 >> iter 41000, loss: 0.011605
 >> iter 42000, loss: 0.011405
 >> iter 43000, loss: 0.011314
 >> iter 44000, loss: 0.011655
 >> iter 45000, loss: 0.011323
 >> iter 46000, loss: 0.019543
 >> iter 47000, loss: 0.013962
 >> iter 48000, loss: 0.012251
 >> iter 49000, loss: 0.015729
 >> iter 50000, loss: 0.014272
   Number of active neurons: 10
 >> iter 51000, loss: 0.011998
 >> iter 52000, loss: 0.011505
 >> iter 53000, loss: 0.010960
 >> iter 54000, loss: 0.011212
 >> iter 55000, loss: 0.245876
 >> iter 56000, loss: 0.102894
 >> iter 57000, loss: 0.045417
 >> iter 58000, loss: 0.023895
 >> iter 59000, loss: 0.219175
 >> iter 60000, loss: 0.089751
   Number of active neurons: 8
 >> iter 61000, loss: 0.157250
 >> iter 62000, loss: 0.066894
 >> iter 63000, loss: 0.032521
 >> iter 64000, loss: 0.019528
 >> iter 65000, loss: 0.014577
 >> iter 66000, loss: 0.012736
 >> iter 67000, loss: 0.298978
 >> iter 68000, loss: 0.120926
 >> iter 69000, loss: 0.052935
 >> iter 70000, loss: 0.028212
   Number of active neurons: 8
 >> iter 71000, loss: 0.036672
 >> iter 72000, loss: 0.021357
 >> iter 73000, loss: 0.015346
 >> iter 74000, loss: 0.013017
 >> iter 75000, loss: 0.012045
 >> iter 76000, loss: 0.011653
 >> iter 77000, loss: 0.023808
 >> iter 78000, loss: 0.015994
 >> iter 79000, loss: 0.012872
 >> iter 80000, loss: 0.012055
   Number of active neurons: 8
 >> iter 81000, loss: 0.011261
 >> iter 82000, loss: 0.011145
 >> iter 83000, loss: 0.011755
 >> iter 84000, loss: 0.012529
 >> iter 85000, loss: 0.011255
 >> iter 86000, loss: 0.011631
 >> iter 87000, loss: 0.010843
 >> iter 88000, loss: 0.011100
 >> iter 89000, loss: 0.025083
 >> iter 90000, loss: 0.016724
   Number of active neurons: 8
 >> iter 91000, loss: 0.033079
 >> iter 92000, loss: 0.019194
 >> iter 93000, loss: 0.033771
 >> iter 94000, loss: 0.019241
 >> iter 95000, loss: 0.379144
 >> iter 96000, loss: 0.150373
 >> iter 97000, loss: 0.063311
 >> iter 98000, loss: 0.030690
 >> iter 99000, loss: 0.034886
 >> iter 100000, loss: 0.056735
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0039999200016
   - Test - Long: 0.0
   - Test - Big: 0.0049999500005
   - Test - A: 0.0
   - Test - B: 6.38624091727
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.878724
 >> iter 2000, loss: 7.864448
 >> iter 3000, loss: 2.927059
 >> iter 4000, loss: 1.096558
 >> iter 5000, loss: 0.418138
 >> iter 6000, loss: 0.166354
 >> iter 7000, loss: 0.072059
 >> iter 8000, loss: 0.036591
 >> iter 9000, loss: 0.022727
 >> iter 10000, loss: 0.017244
   Number of active neurons: 10
 >> iter 11000, loss: 0.014736
 >> iter 12000, loss: 0.013584
 >> iter 13000, loss: 0.012849
 >> iter 14000, loss: 0.012431
 >> iter 15000, loss: 0.012070
 >> iter 16000, loss: 0.011787
 >> iter 17000, loss: 0.011562
 >> iter 18000, loss: 0.011308
 >> iter 19000, loss: 0.011198
 >> iter 20000, loss: 0.010980
   Number of active neurons: 9
 >> iter 21000, loss: 0.011148
 >> iter 22000, loss: 0.010723
 >> iter 23000, loss: 0.011031
 >> iter 24000, loss: 0.010384
 >> iter 25000, loss: 0.012705
 >> iter 26000, loss: 0.010780
 >> iter 27000, loss: 0.013058
 >> iter 28000, loss: 0.010795
 >> iter 29000, loss: 0.012583
 >> iter 30000, loss: 0.010519
   Number of active neurons: 9
 >> iter 31000, loss: 0.012058
 >> iter 32000, loss: 0.010216
 >> iter 33000, loss: 0.010775
 >> iter 34000, loss: 0.009631
 >> iter 35000, loss: 0.010380
 >> iter 36000, loss: 0.009395
 >> iter 37000, loss: 0.009767
 >> iter 38000, loss: 0.009080
 >> iter 39000, loss: 0.009403
 >> iter 40000, loss: 0.008865
   Number of active neurons: 9
 >> iter 41000, loss: 0.008828
 >> iter 42000, loss: 0.008673
 >> iter 43000, loss: 0.008835
 >> iter 44000, loss: 0.008677
 >> iter 45000, loss: 0.008797
 >> iter 46000, loss: 0.008696
 >> iter 47000, loss: 0.008823
 >> iter 48000, loss: 0.008738
 >> iter 49000, loss: 0.008855
 >> iter 50000, loss: 0.008757
   Number of active neurons: 8
 >> iter 51000, loss: 0.008849
 >> iter 52000, loss: 0.008758
 >> iter 53000, loss: 0.008825
 >> iter 54000, loss: 0.008737
 >> iter 55000, loss: 0.008808
 >> iter 56000, loss: 0.008723
 >> iter 57000, loss: 0.008794
 >> iter 58000, loss: 0.008703
 >> iter 59000, loss: 0.008762
 >> iter 60000, loss: 0.008674
   Number of active neurons: 9
 >> iter 61000, loss: 0.008718
 >> iter 62000, loss: 0.008622
 >> iter 63000, loss: 0.008663
 >> iter 64000, loss: 0.008580
 >> iter 65000, loss: 0.008623
 >> iter 66000, loss: 0.008529
 >> iter 67000, loss: 0.008572
 >> iter 68000, loss: 0.008475
 >> iter 69000, loss: 0.008514
 >> iter 70000, loss: 0.008419
   Number of active neurons: 9
 >> iter 71000, loss: 0.008474
 >> iter 72000, loss: 0.008374
 >> iter 73000, loss: 0.008442
 >> iter 74000, loss: 0.008337
 >> iter 75000, loss: 0.008408
 >> iter 76000, loss: 0.008307
 >> iter 77000, loss: 0.008368
 >> iter 78000, loss: 0.008270
 >> iter 79000, loss: 0.008337
 >> iter 80000, loss: 0.008240
   Number of active neurons: 9
 >> iter 81000, loss: 0.008312
 >> iter 82000, loss: 0.008222
 >> iter 83000, loss: 0.008293
 >> iter 84000, loss: 0.008203
 >> iter 85000, loss: 0.008274
 >> iter 86000, loss: 0.008209
 >> iter 87000, loss: 0.008280
 >> iter 88000, loss: 0.008219
 >> iter 89000, loss: 0.008270
 >> iter 90000, loss: 0.008210
   Number of active neurons: 8
 >> iter 91000, loss: 0.008254
 >> iter 92000, loss: 0.008200
 >> iter 93000, loss: 0.008242
 >> iter 94000, loss: 0.008187
 >> iter 95000, loss: 0.008241
 >> iter 96000, loss: 0.008169
 >> iter 97000, loss: 0.008222
 >> iter 98000, loss: 0.008152
 >> iter 99000, loss: 0.008204
 >> iter 100000, loss: 0.008151
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.00799984000319
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 19.3920405306
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 18.742889
 >> iter 2000, loss: 8.314947
 >> iter 3000, loss: 3.097593
 >> iter 4000, loss: 1.159460
 >> iter 5000, loss: 0.441231
 >> iter 6000, loss: 0.174333
 >> iter 7000, loss: 0.074712
 >> iter 8000, loss: 0.037022
 >> iter 9000, loss: 0.022565
 >> iter 10000, loss: 0.016721
   Number of active neurons: 10
 >> iter 11000, loss: 0.014297
 >> iter 12000, loss: 0.013103
 >> iter 13000, loss: 0.012520
 >> iter 14000, loss: 0.012105
 >> iter 15000, loss: 0.011891
 >> iter 16000, loss: 0.011689
 >> iter 17000, loss: 0.011584
 >> iter 18000, loss: 0.011434
 >> iter 19000, loss: 0.011362
 >> iter 20000, loss: 0.011251
   Number of active neurons: 10
 >> iter 21000, loss: 0.011213
 >> iter 22000, loss: 0.011127
 >> iter 23000, loss: 0.011101
 >> iter 24000, loss: 0.011028
 >> iter 25000, loss: 0.011025
 >> iter 26000, loss: 0.010954
 >> iter 27000, loss: 0.010942
 >> iter 28000, loss: 0.010860
 >> iter 29000, loss: 0.010857
 >> iter 30000, loss: 0.010771
   Number of active neurons: 10
 >> iter 31000, loss: 0.010795
 >> iter 32000, loss: 0.010687
 >> iter 33000, loss: 0.010731
 >> iter 34000, loss: 0.010611
 >> iter 35000, loss: 0.010673
 >> iter 36000, loss: 0.010543
 >> iter 37000, loss: 0.010605
 >> iter 38000, loss: 0.010457
 >> iter 39000, loss: 0.010529
 >> iter 40000, loss: 0.010388
   Number of active neurons: 10
 >> iter 41000, loss: 0.010463
 >> iter 42000, loss: 0.010325
 >> iter 43000, loss: 0.010415
 >> iter 44000, loss: 0.010284
 >> iter 45000, loss: 0.010382
 >> iter 46000, loss: 0.010241
 >> iter 47000, loss: 0.010324
 >> iter 48000, loss: 0.010198
 >> iter 49000, loss: 0.010276
 >> iter 50000, loss: 0.010146
   Number of active neurons: 10
 >> iter 51000, loss: 0.010226
 >> iter 52000, loss: 0.010102
 >> iter 53000, loss: 0.010175
 >> iter 54000, loss: 0.010050
 >> iter 55000, loss: 0.010122
 >> iter 56000, loss: 0.009998
 >> iter 57000, loss: 0.010077
 >> iter 58000, loss: 0.009955
 >> iter 59000, loss: 0.010032
 >> iter 60000, loss: 0.009926
   Number of active neurons: 10
 >> iter 61000, loss: 0.010002
 >> iter 62000, loss: 0.009874
 >> iter 63000, loss: 0.009943
 >> iter 64000, loss: 0.009819
 >> iter 65000, loss: 0.009889
 >> iter 66000, loss: 0.009768
 >> iter 67000, loss: 0.009842
 >> iter 68000, loss: 0.009722
 >> iter 69000, loss: 0.009789
 >> iter 70000, loss: 0.009671
   Number of active neurons: 8
 >> iter 71000, loss: 0.009746
 >> iter 72000, loss: 0.009622
 >> iter 73000, loss: 0.009702
 >> iter 74000, loss: 0.009570
 >> iter 75000, loss: 0.009656
 >> iter 76000, loss: 0.009524
 >> iter 77000, loss: 0.009611
 >> iter 78000, loss: 0.009474
 >> iter 79000, loss: 0.009568
 >> iter 80000, loss: 0.009421
   Number of active neurons: 8
 >> iter 81000, loss: 0.009515
 >> iter 82000, loss: 0.009369
 >> iter 83000, loss: 0.009463
 >> iter 84000, loss: 0.009309
 >> iter 85000, loss: 0.009410
 >> iter 86000, loss: 0.009258
 >> iter 87000, loss: 0.009346
 >> iter 88000, loss: 0.009193
 >> iter 89000, loss: 0.009264
 >> iter 90000, loss: 0.009118
   Number of active neurons: 8
 >> iter 91000, loss: 0.009184
 >> iter 92000, loss: 0.009049
 >> iter 93000, loss: 0.009114
 >> iter 94000, loss: 0.008991
 >> iter 95000, loss: 0.009063
 >> iter 96000, loss: 0.008941
 >> iter 97000, loss: 0.009013
 >> iter 98000, loss: 0.008900
 >> iter 99000, loss: 0.008975
 >> iter 100000, loss: 0.008865
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 20.4653023132
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 18.533530
 >> iter 2000, loss: 7.252035
 >> iter 3000, loss: 2.695453
 >> iter 4000, loss: 1.008605
 >> iter 5000, loss: 0.384589
 >> iter 6000, loss: 0.152765
 >> iter 7000, loss: 0.066498
 >> iter 8000, loss: 0.033732
 >> iter 9000, loss: 0.021278
 >> iter 10000, loss: 0.016077
   Number of active neurons: 10
 >> iter 11000, loss: 0.013991
 >> iter 12000, loss: 0.012809
 >> iter 13000, loss: 0.012288
 >> iter 14000, loss: 0.011774
 >> iter 15000, loss: 0.011543
 >> iter 16000, loss: 0.011222
 >> iter 17000, loss: 0.011120
 >> iter 18000, loss: 0.010916
 >> iter 19000, loss: 0.010871
 >> iter 20000, loss: 0.010665
   Number of active neurons: 10
 >> iter 21000, loss: 0.010642
 >> iter 22000, loss: 0.010526
 >> iter 23000, loss: 0.010479
 >> iter 24000, loss: 0.010280
 >> iter 25000, loss: 0.010240
 >> iter 26000, loss: 0.010061
 >> iter 27000, loss: 0.010028
 >> iter 28000, loss: 0.009865
 >> iter 29000, loss: 0.009851
 >> iter 30000, loss: 0.009704
   Number of active neurons: 10
 >> iter 31000, loss: 0.009706
 >> iter 32000, loss: 0.009554
 >> iter 33000, loss: 0.009554
 >> iter 34000, loss: 0.009411
 >> iter 35000, loss: 0.009411
 >> iter 36000, loss: 0.009275
 >> iter 37000, loss: 0.009283
 >> iter 38000, loss: 0.009151
 >> iter 39000, loss: 0.009173
 >> iter 40000, loss: 0.009048
   Number of active neurons: 9
 >> iter 41000, loss: 0.009066
 >> iter 42000, loss: 0.008945
 >> iter 43000, loss: 0.008967
 >> iter 44000, loss: 0.008860
 >> iter 45000, loss: 0.008880
 >> iter 46000, loss: 0.008769
 >> iter 47000, loss: 0.008789
 >> iter 48000, loss: 0.008703
 >> iter 49000, loss: 0.008710
 >> iter 50000, loss: 0.008633
   Number of active neurons: 8
 >> iter 51000, loss: 0.008637
 >> iter 52000, loss: 0.008583
 >> iter 53000, loss: 0.008577
 >> iter 54000, loss: 0.008530
 >> iter 55000, loss: 0.008526
 >> iter 56000, loss: 0.008484
 >> iter 57000, loss: 0.008487
 >> iter 58000, loss: 0.008446
 >> iter 59000, loss: 0.008452
 >> iter 60000, loss: 0.008415
   Number of active neurons: 8
 >> iter 61000, loss: 0.008411
 >> iter 62000, loss: 0.008360
 >> iter 63000, loss: 0.008363
 >> iter 64000, loss: 0.008304
 >> iter 65000, loss: 0.008294
 >> iter 66000, loss: 0.008239
 >> iter 67000, loss: 0.008248
 >> iter 68000, loss: 0.008197
 >> iter 69000, loss: 0.008188
 >> iter 70000, loss: 0.008149
   Number of active neurons: 7
 >> iter 71000, loss: 0.008151
 >> iter 72000, loss: 0.008111
 >> iter 73000, loss: 0.008116
 >> iter 74000, loss: 0.008082
 >> iter 75000, loss: 0.008082
 >> iter 76000, loss: 0.008063
 >> iter 77000, loss: 0.008041
 >> iter 78000, loss: 0.008029
 >> iter 79000, loss: 0.008023
 >> iter 80000, loss: 0.008003
   Number of active neurons: 7
 >> iter 81000, loss: 0.007991
 >> iter 82000, loss: 0.007982
 >> iter 83000, loss: 0.007980
 >> iter 84000, loss: 0.007954
 >> iter 85000, loss: 0.007983
 >> iter 86000, loss: 0.007933
 >> iter 87000, loss: 0.007956
 >> iter 88000, loss: 0.007909
 >> iter 89000, loss: 0.007936
 >> iter 90000, loss: 0.007888
   Number of active neurons: 7
 >> iter 91000, loss: 0.007913
 >> iter 92000, loss: 0.007865
 >> iter 93000, loss: 0.007894
 >> iter 94000, loss: 0.007845
 >> iter 95000, loss: 0.007882
 >> iter 96000, loss: 0.007829
 >> iter 97000, loss: 0.007857
 >> iter 98000, loss: 0.007813
 >> iter 99000, loss: 0.007836
 >> iter 100000, loss: 0.007805
   Number of active neurons: 7
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 13.605759616
   - Test - B: 5.89294047064
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.249631
 >> iter 2000, loss: 7.386058
 >> iter 3000, loss: 2.747383
 >> iter 4000, loss: 1.028715
 >> iter 5000, loss: 0.392271
 >> iter 6000, loss: 0.155937
 >> iter 7000, loss: 0.067746
 >> iter 8000, loss: 0.034412
 >> iter 9000, loss: 0.023205
 >> iter 10000, loss: 0.016655
   Number of active neurons: 9
 >> iter 11000, loss: 0.023207
 >> iter 12000, loss: 0.016056
 >> iter 13000, loss: 0.017096
 >> iter 14000, loss: 0.013277
 >> iter 15000, loss: 0.019614
 >> iter 16000, loss: 0.013914
 >> iter 17000, loss: 0.012940
 >> iter 18000, loss: 0.011069
 >> iter 19000, loss: 0.010574
 >> iter 20000, loss: 0.010142
   Number of active neurons: 9
 >> iter 21000, loss: 0.011140
 >> iter 22000, loss: 0.010121
 >> iter 23000, loss: 0.010702
 >> iter 24000, loss: 0.009654
 >> iter 25000, loss: 0.009400
 >> iter 26000, loss: 0.009371
 >> iter 27000, loss: 0.009336
 >> iter 28000, loss: 0.009436
 >> iter 29000, loss: 0.009397
 >> iter 30000, loss: 0.012857
   Number of active neurons: 9
 >> iter 31000, loss: 0.192895
 >> iter 32000, loss: 0.082954
 >> iter 33000, loss: 0.048107
 >> iter 34000, loss: 0.023451
 >> iter 35000, loss: 0.022674
 >> iter 36000, loss: 0.013890
 >> iter 37000, loss: 0.010674
 >> iter 38000, loss: 0.009544
 >> iter 39000, loss: 0.009087
 >> iter 40000, loss: 0.010145
   Number of active neurons: 9
 >> iter 41000, loss: 0.009272
 >> iter 42000, loss: 0.009782
 >> iter 43000, loss: 0.008902
 >> iter 44000, loss: 0.008695
 >> iter 45000, loss: 0.008524
 >> iter 46000, loss: 0.008674
 >> iter 47000, loss: 0.008610
 >> iter 48000, loss: 0.052042
 >> iter 49000, loss: 0.034920
 >> iter 50000, loss: 0.017690
   Number of active neurons: 9
 >> iter 51000, loss: 0.011839
 >> iter 52000, loss: 0.009288
 >> iter 53000, loss: 0.008414
 >> iter 54000, loss: 0.008153
 >> iter 55000, loss: 0.008030
 >> iter 56000, loss: 0.008183
 >> iter 57000, loss: 0.008149
 >> iter 58000, loss: 0.008269
 >> iter 59000, loss: 0.009740
 >> iter 60000, loss: 0.008925
   Number of active neurons: 7
 >> iter 61000, loss: 0.008295
 >> iter 62000, loss: 0.009563
 >> iter 63000, loss: 0.008520
 >> iter 64000, loss: 0.008254
 >> iter 65000, loss: 0.008130
 >> iter 66000, loss: 0.008140
 >> iter 67000, loss: 0.008222
 >> iter 68000, loss: 0.009808
 >> iter 69000, loss: 0.008528
 >> iter 70000, loss: 0.008169
   Number of active neurons: 6
 >> iter 71000, loss: 0.008599
 >> iter 72000, loss: 0.007962
 >> iter 73000, loss: 0.007820
 >> iter 74000, loss: 0.008130
 >> iter 75000, loss: 0.007783
 >> iter 76000, loss: 0.007816
 >> iter 77000, loss: 0.007760
 >> iter 78000, loss: 0.007878
 >> iter 79000, loss: 0.007805
 >> iter 80000, loss: 0.007890
   Number of active neurons: 6
 >> iter 81000, loss: 0.007798
 >> iter 82000, loss: 0.008399
 >> iter 83000, loss: 0.007872
 >> iter 84000, loss: 0.007863
 >> iter 85000, loss: 0.007705
 >> iter 86000, loss: 0.008145
 >> iter 87000, loss: 0.007683
 >> iter 88000, loss: 0.008664
 >> iter 89000, loss: 0.007756
 >> iter 90000, loss: 0.008209
   Number of active neurons: 6
 >> iter 91000, loss: 0.007646
 >> iter 92000, loss: 0.008101
 >> iter 93000, loss: 0.007622
 >> iter 94000, loss: 0.008139
 >> iter 95000, loss: 0.007663
 >> iter 96000, loss: 0.008180
 >> iter 97000, loss: 0.007696
 >> iter 98000, loss: 0.008185
 >> iter 99000, loss: 0.007723
 >> iter 100000, loss: 0.008178
   Number of active neurons: 6
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.1999900005
   - Test - Big: 0.0
   - Test - A: 0.706619558696
   - Test - B: 7.67948803413
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 18.823098
 >> iter 2000, loss: 8.245389
 >> iter 3000, loss: 3.080531
 >> iter 4000, loss: 1.160629
 >> iter 5000, loss: 0.445309
 >> iter 6000, loss: 0.178981
 >> iter 7000, loss: 0.079110
 >> iter 8000, loss: 0.077657
 >> iter 9000, loss: 0.040667
 >> iter 10000, loss: 0.025819
   Number of active neurons: 9
 >> iter 11000, loss: 0.019691
 >> iter 12000, loss: 0.017019
 >> iter 13000, loss: 0.015567
 >> iter 14000, loss: 0.014778
 >> iter 15000, loss: 0.014208
 >> iter 16000, loss: 0.013840
 >> iter 17000, loss: 0.013591
 >> iter 18000, loss: 0.013253
 >> iter 19000, loss: 0.013238
 >> iter 20000, loss: 0.012878
   Number of active neurons: 9
 >> iter 21000, loss: 0.122986
 >> iter 22000, loss: 0.054593
 >> iter 23000, loss: 0.028037
 >> iter 24000, loss: 0.017987
 >> iter 25000, loss: 0.014252
 >> iter 26000, loss: 0.012679
 >> iter 27000, loss: 0.012143
 >> iter 28000, loss: 0.011781
 >> iter 29000, loss: 0.011809
 >> iter 30000, loss: 0.011540
   Number of active neurons: 9
 >> iter 31000, loss: 0.011774
 >> iter 32000, loss: 0.011416
 >> iter 33000, loss: 0.011719
 >> iter 34000, loss: 0.011309
 >> iter 35000, loss: 0.011642
 >> iter 36000, loss: 0.011191
 >> iter 37000, loss: 0.011515
 >> iter 38000, loss: 0.011060
 >> iter 39000, loss: 0.011352
 >> iter 40000, loss: 0.010949
   Number of active neurons: 9
 >> iter 41000, loss: 0.011317
 >> iter 42000, loss: 0.010880
 >> iter 43000, loss: 0.011115
 >> iter 44000, loss: 0.010778
 >> iter 45000, loss: 0.011065
 >> iter 46000, loss: 0.010701
 >> iter 47000, loss: 0.010887
 >> iter 48000, loss: 0.010598
 >> iter 49000, loss: 0.010801
 >> iter 50000, loss: 0.010509
   Number of active neurons: 9
 >> iter 51000, loss: 0.010645
 >> iter 52000, loss: 0.010413
 >> iter 53000, loss: 0.010550
 >> iter 54000, loss: 0.010309
 >> iter 55000, loss: 0.010392
 >> iter 56000, loss: 0.010194
 >> iter 57000, loss: 0.010268
 >> iter 58000, loss: 0.010088
 >> iter 59000, loss: 0.010135
 >> iter 60000, loss: 0.009997
   Number of active neurons: 9
 >> iter 61000, loss: 0.010034
 >> iter 62000, loss: 0.009925
 >> iter 63000, loss: 0.009965
 >> iter 64000, loss: 0.009879
 >> iter 65000, loss: 0.009905
 >> iter 66000, loss: 0.009830
 >> iter 67000, loss: 0.009838
 >> iter 68000, loss: 0.009778
 >> iter 69000, loss: 0.009766
 >> iter 70000, loss: 0.009728
   Number of active neurons: 9
 >> iter 71000, loss: 0.009719
 >> iter 72000, loss: 0.009683
 >> iter 73000, loss: 0.009681
 >> iter 74000, loss: 0.009645
 >> iter 75000, loss: 0.009647
 >> iter 76000, loss: 0.009632
 >> iter 77000, loss: 0.009621
 >> iter 78000, loss: 0.009611
 >> iter 79000, loss: 0.009605
 >> iter 80000, loss: 0.009596
   Number of active neurons: 9
 >> iter 81000, loss: 0.009593
 >> iter 82000, loss: 0.009589
 >> iter 83000, loss: 0.009582
 >> iter 84000, loss: 0.009579
 >> iter 85000, loss: 0.009578
 >> iter 86000, loss: 0.009579
 >> iter 87000, loss: 0.009564
 >> iter 88000, loss: 0.009580
 >> iter 89000, loss: 0.009550
 >> iter 90000, loss: 0.009575
   Number of active neurons: 9
 >> iter 91000, loss: 0.009535
 >> iter 92000, loss: 0.009558
 >> iter 93000, loss: 0.009526
 >> iter 94000, loss: 0.009546
 >> iter 95000, loss: 0.009534
 >> iter 96000, loss: 0.009531
 >> iter 97000, loss: 0.009520
 >> iter 98000, loss: 0.009513
 >> iter 99000, loss: 0.009510
 >> iter 100000, loss: 0.009483
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 18.765415639
   - Test - B: 1.13325778281
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 19.419859
 >> iter 2000, loss: 8.896284
 >> iter 3000, loss: 3.380320
 >> iter 4000, loss: 1.281235
 >> iter 5000, loss: 0.493084
 >> iter 6000, loss: 0.205933
 >> iter 7000, loss: 0.090796
 >> iter 8000, loss: 0.055486
 >> iter 9000, loss: 0.032748
 >> iter 10000, loss: 0.025904
   Number of active neurons: 10
 >> iter 11000, loss: 0.020347
 >> iter 12000, loss: 0.017846
 >> iter 13000, loss: 0.017493
 >> iter 14000, loss: 0.015898
 >> iter 15000, loss: 0.015132
 >> iter 16000, loss: 0.014646
 >> iter 17000, loss: 0.014331
 >> iter 18000, loss: 0.014060
 >> iter 19000, loss: 0.013840
 >> iter 20000, loss: 0.013621
   Number of active neurons: 10
 >> iter 21000, loss: 0.013483
 >> iter 22000, loss: 0.013309
 >> iter 23000, loss: 0.013180
 >> iter 24000, loss: 0.013022
 >> iter 25000, loss: 0.012920
 >> iter 26000, loss: 0.012810
 >> iter 27000, loss: 0.012708
 >> iter 28000, loss: 0.013986
 >> iter 29000, loss: 0.012956
 >> iter 30000, loss: 0.017144
   Number of active neurons: 10
 >> iter 31000, loss: 0.013952
 >> iter 32000, loss: 0.013374
 >> iter 33000, loss: 0.012482
 >> iter 34000, loss: 0.331767
 >> iter 35000, loss: 0.133149
 >> iter 36000, loss: 0.058599
 >> iter 37000, loss: 0.029814
 >> iter 38000, loss: 0.020277
 >> iter 39000, loss: 0.015207
 >> iter 40000, loss: 0.013297
   Number of active neurons: 10
 >> iter 41000, loss: 0.012490
 >> iter 42000, loss: 0.012193
 >> iter 43000, loss: 0.012024
 >> iter 44000, loss: 0.011968
 >> iter 45000, loss: 0.011878
 >> iter 46000, loss: 0.011843
 >> iter 47000, loss: 0.011752
 >> iter 48000, loss: 0.012725
 >> iter 49000, loss: 0.011925
 >> iter 50000, loss: 0.015569
   Number of active neurons: 10
 >> iter 51000, loss: 0.012960
 >> iter 52000, loss: 0.014880
 >> iter 53000, loss: 0.012590
 >> iter 54000, loss: 0.012183
 >> iter 55000, loss: 0.011332
 >> iter 56000, loss: 0.012097
 >> iter 57000, loss: 0.011249
 >> iter 58000, loss: 0.011119
 >> iter 59000, loss: 0.011370
 >> iter 60000, loss: 0.010925
   Number of active neurons: 10
 >> iter 61000, loss: 0.438692
 >> iter 62000, loss: 0.185182
 >> iter 63000, loss: 0.075665
 >> iter 64000, loss: 0.035175
 >> iter 65000, loss: 0.020155
 >> iter 66000, loss: 0.014650
 >> iter 67000, loss: 0.012612
 >> iter 68000, loss: 0.011872
 >> iter 69000, loss: 0.011724
 >> iter 70000, loss: 0.011490
   Number of active neurons: 9
 >> iter 71000, loss: 0.011367
 >> iter 72000, loss: 0.011340
 >> iter 73000, loss: 0.011245
 >> iter 74000, loss: 0.011212
 >> iter 75000, loss: 0.011134
 >> iter 76000, loss: 0.011101
 >> iter 77000, loss: 0.011035
 >> iter 78000, loss: 0.010999
 >> iter 79000, loss: 0.010958
 >> iter 80000, loss: 0.010897
   Number of active neurons: 9
 >> iter 81000, loss: 0.011773
 >> iter 82000, loss: 0.013598
 >> iter 83000, loss: 0.011542
 >> iter 84000, loss: 0.010788
 >> iter 85000, loss: 0.010832
 >> iter 86000, loss: 0.010514
 >> iter 87000, loss: 0.010407
 >> iter 88000, loss: 0.010361
 >> iter 89000, loss: 0.010503
 >> iter 90000, loss: 0.010442
   Number of active neurons: 9
 >> iter 91000, loss: 0.329464
 >> iter 92000, loss: 0.129625
 >> iter 93000, loss: 0.055239
 >> iter 94000, loss: 0.027460
 >> iter 95000, loss: 0.017039
 >> iter 96000, loss: 0.013201
 >> iter 97000, loss: 0.011589
 >> iter 98000, loss: 0.013592
 >> iter 99000, loss: 0.011608
 >> iter 100000, loss: 0.010808
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0129998700013
   - Test - A: 0.0
   - Test - B: 21.3585760949
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 18.211685
 >> iter 2000, loss: 7.182561
 >> iter 3000, loss: 2.729456
 >> iter 4000, loss: 1.024283
 >> iter 5000, loss: 0.391204
 >> iter 6000, loss: 0.155779
 >> iter 7000, loss: 0.240747
 >> iter 8000, loss: 0.101107
 >> iter 9000, loss: 0.174880
 >> iter 10000, loss: 0.078715
   Number of active neurons: 10
 >> iter 11000, loss: 0.038305
 >> iter 12000, loss: 0.022510
 >> iter 13000, loss: 0.016339
 >> iter 14000, loss: 0.013659
 >> iter 15000, loss: 0.012524
 >> iter 16000, loss: 0.011808
 >> iter 17000, loss: 0.011547
 >> iter 18000, loss: 0.011170
 >> iter 19000, loss: 0.011002
 >> iter 20000, loss: 0.010771
   Number of active neurons: 9
 >> iter 21000, loss: 0.010663
 >> iter 22000, loss: 0.010547
 >> iter 23000, loss: 0.010437
 >> iter 24000, loss: 0.010624
 >> iter 25000, loss: 0.010192
 >> iter 26000, loss: 0.011205
 >> iter 27000, loss: 0.010244
 >> iter 28000, loss: 0.012013
 >> iter 29000, loss: 0.010488
 >> iter 30000, loss: 0.014704
   Number of active neurons: 9
 >> iter 31000, loss: 0.011374
 >> iter 32000, loss: 0.012559
 >> iter 33000, loss: 0.010530
 >> iter 34000, loss: 0.092170
 >> iter 35000, loss: 0.041084
 >> iter 36000, loss: 0.024299
 >> iter 37000, loss: 0.015138
 >> iter 38000, loss: 0.013966
 >> iter 39000, loss: 0.011207
 >> iter 40000, loss: 0.012852
   Number of active neurons: 9
 >> iter 41000, loss: 0.010756
 >> iter 42000, loss: 0.013343
 >> iter 43000, loss: 0.011146
 >> iter 44000, loss: 0.013853
 >> iter 45000, loss: 0.224842
 >> iter 46000, loss: 0.264672
 >> iter 47000, loss: 0.106640
 >> iter 48000, loss: 0.051232
 >> iter 49000, loss: 0.026087
 >> iter 50000, loss: 0.016561
   Number of active neurons: 9
 >> iter 51000, loss: 0.012934
 >> iter 52000, loss: 0.011476
 >> iter 53000, loss: 0.010830
 >> iter 54000, loss: 0.010641
 >> iter 55000, loss: 0.010274
 >> iter 56000, loss: 0.011203
 >> iter 57000, loss: 0.010339
 >> iter 58000, loss: 0.012462
 >> iter 59000, loss: 0.010764
 >> iter 60000, loss: 0.013066
   Number of active neurons: 9
 >> iter 61000, loss: 0.010986
 >> iter 62000, loss: 0.013339
 >> iter 63000, loss: 0.011100
 >> iter 64000, loss: 0.013292
 >> iter 65000, loss: 0.011224
 >> iter 66000, loss: 0.013534
 >> iter 67000, loss: 0.011159
 >> iter 68000, loss: 0.013232
 >> iter 69000, loss: 0.011064
 >> iter 70000, loss: 0.012938
   Number of active neurons: 9
 >> iter 71000, loss: 0.010890
 >> iter 72000, loss: 0.012668
 >> iter 73000, loss: 0.010730
 >> iter 74000, loss: 0.012277
 >> iter 75000, loss: 0.010538
 >> iter 76000, loss: 0.011846
 >> iter 77000, loss: 0.010338
 >> iter 78000, loss: 0.011288
 >> iter 79000, loss: 0.010100
 >> iter 80000, loss: 0.010365
   Number of active neurons: 9
 >> iter 81000, loss: 0.009730
 >> iter 82000, loss: 0.010026
 >> iter 83000, loss: 0.009602
 >> iter 84000, loss: 0.009855
 >> iter 85000, loss: 0.009541
 >> iter 86000, loss: 0.009929
 >> iter 87000, loss: 0.009554
 >> iter 88000, loss: 0.009680
 >> iter 89000, loss: 0.009463
 >> iter 90000, loss: 0.009687
   Number of active neurons: 8
 >> iter 91000, loss: 0.009467
 >> iter 92000, loss: 0.009604
 >> iter 93000, loss: 0.009445
 >> iter 94000, loss: 0.009637
 >> iter 95000, loss: 0.009456
 >> iter 96000, loss: 0.009543
 >> iter 97000, loss: 0.009428
 >> iter 98000, loss: 0.009542
 >> iter 99000, loss: 0.009411
 >> iter 100000, loss: 0.009495
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.189990500475
   - Test - Big: 0.000999990000096
   - Test - A: 0.0
   - Test - B: 19.0653956403
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 17.941719
 >> iter 2000, loss: 6.966328
 >> iter 3000, loss: 2.590718
 >> iter 4000, loss: 0.970828
 >> iter 5000, loss: 0.371035
 >> iter 6000, loss: 0.148205
 >> iter 7000, loss: 0.065038
 >> iter 8000, loss: 0.033473
 >> iter 9000, loss: 0.021351
 >> iter 10000, loss: 0.016341
   Number of active neurons: 9
 >> iter 11000, loss: 0.014264
 >> iter 12000, loss: 0.013144
 >> iter 13000, loss: 0.012622
 >> iter 14000, loss: 0.012172
 >> iter 15000, loss: 0.011957
 >> iter 16000, loss: 0.011676
 >> iter 17000, loss: 0.011558
 >> iter 18000, loss: 0.011346
 >> iter 19000, loss: 0.011270
 >> iter 20000, loss: 0.011111
   Number of active neurons: 9
 >> iter 21000, loss: 0.011061
 >> iter 22000, loss: 0.010934
 >> iter 23000, loss: 0.010872
 >> iter 24000, loss: 0.010758
 >> iter 25000, loss: 0.010695
 >> iter 26000, loss: 0.010605
 >> iter 27000, loss: 0.010530
 >> iter 28000, loss: 0.010454
 >> iter 29000, loss: 0.010364
 >> iter 30000, loss: 0.010298
   Number of active neurons: 8
 >> iter 31000, loss: 0.010214
 >> iter 32000, loss: 0.010153
 >> iter 33000, loss: 0.010065
 >> iter 34000, loss: 0.010022
 >> iter 35000, loss: 0.009937
 >> iter 36000, loss: 0.009899
 >> iter 37000, loss: 0.009809
 >> iter 38000, loss: 0.009769
 >> iter 39000, loss: 0.009692
 >> iter 40000, loss: 0.009663
   Number of active neurons: 8
 >> iter 41000, loss: 0.009592
 >> iter 42000, loss: 0.009562
 >> iter 43000, loss: 0.009489
 >> iter 44000, loss: 0.009467
 >> iter 45000, loss: 0.009403
 >> iter 46000, loss: 0.009376
 >> iter 47000, loss: 0.009315
 >> iter 48000, loss: 0.009304
 >> iter 49000, loss: 0.009249
 >> iter 50000, loss: 0.009242
   Number of active neurons: 8
 >> iter 51000, loss: 0.009190
 >> iter 52000, loss: 0.009198
 >> iter 53000, loss: 0.009144
 >> iter 54000, loss: 0.009149
 >> iter 55000, loss: 0.009096
 >> iter 56000, loss: 0.009099
 >> iter 57000, loss: 0.009056
 >> iter 58000, loss: 0.009055
 >> iter 59000, loss: 0.009015
 >> iter 60000, loss: 0.009023
   Number of active neurons: 8
 >> iter 61000, loss: 0.008985
 >> iter 62000, loss: 0.008988
 >> iter 63000, loss: 0.008954
 >> iter 64000, loss: 0.008962
 >> iter 65000, loss: 0.008925
 >> iter 66000, loss: 0.008931
 >> iter 67000, loss: 0.008881
 >> iter 68000, loss: 0.008882
 >> iter 69000, loss: 0.008829
 >> iter 70000, loss: 0.008839
   Number of active neurons: 8
 >> iter 71000, loss: 0.008806
 >> iter 72000, loss: 0.008792
 >> iter 73000, loss: 0.008786
 >> iter 74000, loss: 0.008768
 >> iter 75000, loss: 0.008768
 >> iter 76000, loss: 0.008746
 >> iter 77000, loss: 0.008727
 >> iter 78000, loss: 0.008689
 >> iter 79000, loss: 0.008670
 >> iter 80000, loss: 0.008633
   Number of active neurons: 8
 >> iter 81000, loss: 0.008623
 >> iter 82000, loss: 0.008593
 >> iter 83000, loss: 0.008590
 >> iter 84000, loss: 0.008558
 >> iter 85000, loss: 0.008566
 >> iter 86000, loss: 0.008536
 >> iter 87000, loss: 0.008538
 >> iter 88000, loss: 0.008517
 >> iter 89000, loss: 0.008513
 >> iter 90000, loss: 0.008492
   Number of active neurons: 8
 >> iter 91000, loss: 0.008484
 >> iter 92000, loss: 0.008456
 >> iter 93000, loss: 0.008449
 >> iter 94000, loss: 0.008412
 >> iter 95000, loss: 0.008416
 >> iter 96000, loss: 0.008361
 >> iter 97000, loss: 0.008369
 >> iter 98000, loss: 0.008313
 >> iter 99000, loss: 0.008331
 >> iter 100000, loss: 0.008264
   Number of active neurons: 8
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 14.8790080661
   - Test - B: 20.1719885341

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

