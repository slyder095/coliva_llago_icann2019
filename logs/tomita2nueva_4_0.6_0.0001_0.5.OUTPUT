 > Problema: tomita2nueva
 > Args:
   - Hidden size: 4
   - Noise level: 0.6
   - Regu L1: 0.0001
   - Shock: 0.5
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.572564
 >> iter 2000, loss: 4.430552
 >> iter 3000, loss: 1.699617
 >> iter 4000, loss: 0.680871
 >> iter 5000, loss: 0.302718
 >> iter 6000, loss: 0.143054
 >> iter 7000, loss: 0.080636
 >> iter 8000, loss: 0.061638
 >> iter 9000, loss: 0.075888
 >> iter 10000, loss: 0.067777
   Number of active neurons: 4
 >> iter 11000, loss: 0.061838
 >> iter 12000, loss: 0.045885
 >> iter 13000, loss: 0.057631
 >> iter 14000, loss: 0.059855
 >> iter 15000, loss: 0.061872
 >> iter 16000, loss: 0.055011
 >> iter 17000, loss: 0.080918
 >> iter 18000, loss: 0.055176
 >> iter 19000, loss: 0.084183
 >> iter 20000, loss: 0.052777
   Number of active neurons: 4
 >> iter 21000, loss: 0.044320
 >> iter 22000, loss: 0.039291
 >> iter 23000, loss: 0.042837
 >> iter 24000, loss: 0.052335
 >> iter 25000, loss: 0.046208
 >> iter 26000, loss: 0.037191
 >> iter 27000, loss: 0.056358
 >> iter 28000, loss: 0.060984
 >> iter 29000, loss: 0.049979
 >> iter 30000, loss: 0.047040
   Number of active neurons: 4
 >> iter 31000, loss: 0.051530
 >> iter 32000, loss: 0.037133
 >> iter 33000, loss: 0.047915
 >> iter 34000, loss: 0.044815
 >> iter 35000, loss: 0.050298
 >> iter 36000, loss: 0.060159
 >> iter 37000, loss: 0.040368
 >> iter 38000, loss: 0.046729
 >> iter 39000, loss: 0.036511
 >> iter 40000, loss: 0.037896
   Number of active neurons: 4
 >> iter 41000, loss: 0.077315
 >> iter 42000, loss: 0.071986
 >> iter 43000, loss: 0.071279
 >> iter 44000, loss: 0.059485
 >> iter 45000, loss: 0.063897
 >> iter 46000, loss: 0.056667
 >> iter 47000, loss: 0.068607
 >> iter 48000, loss: 0.073573
 >> iter 49000, loss: 0.049774
 >> iter 50000, loss: 0.049873
   Number of active neurons: 3
 >> iter 51000, loss: 0.051833
 >> iter 52000, loss: 0.050023
 >> iter 53000, loss: 0.034609
 >> iter 54000, loss: 0.031212
 >> iter 55000, loss: 0.030060
 >> iter 56000, loss: 0.048122
 >> iter 57000, loss: 0.054861
 >> iter 58000, loss: 0.051216
 >> iter 59000, loss: 0.052330
 >> iter 60000, loss: 0.039132
   Number of active neurons: 3
 >> iter 61000, loss: 0.051060
 >> iter 62000, loss: 0.037728
 >> iter 63000, loss: 0.054603
 >> iter 64000, loss: 0.040433
 >> iter 65000, loss: 0.061052
 >> iter 66000, loss: 0.067785
 >> iter 67000, loss: 0.051800
 >> iter 68000, loss: 0.062902
 >> iter 69000, loss: 0.042298
 >> iter 70000, loss: 0.043091
   Number of active neurons: 2
 >> iter 71000, loss: 0.041635
 >> iter 72000, loss: 0.039821
 >> iter 73000, loss: 0.038978
 >> iter 74000, loss: 0.055886
 >> iter 75000, loss: 0.064347
 >> iter 76000, loss: 0.062290
 >> iter 77000, loss: 0.047266
 >> iter 78000, loss: 0.057094
 >> iter 79000, loss: 0.047260
 >> iter 80000, loss: 0.040360
   Number of active neurons: 2
 >> iter 81000, loss: 0.034529
 >> iter 82000, loss: 0.040039
 >> iter 83000, loss: 0.046881
 >> iter 84000, loss: 0.059682
 >> iter 85000, loss: 0.050642
 >> iter 86000, loss: 0.042888
 >> iter 87000, loss: 0.057423
 >> iter 88000, loss: 0.051195
 >> iter 89000, loss: 0.039109
 >> iter 90000, loss: 0.033422
   Number of active neurons: 2
 >> iter 91000, loss: 0.039790
 >> iter 92000, loss: 0.036754
 >> iter 93000, loss: 0.047902
 >> iter 94000, loss: 0.041819
 >> iter 95000, loss: 0.063277
 >> iter 96000, loss: 0.056795
 >> iter 97000, loss: 0.056163
 >> iter 98000, loss: 0.042959
 >> iter 99000, loss: 0.038142
 >> iter 100000, loss: 0.041064
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 0:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.440545
 >> iter 2000, loss: 4.353130
 >> iter 3000, loss: 1.689009
 >> iter 4000, loss: 0.693347
 >> iter 5000, loss: 0.289435
 >> iter 6000, loss: 0.169820
 >> iter 7000, loss: 0.110922
 >> iter 8000, loss: 0.088784
 >> iter 9000, loss: 0.091971
 >> iter 10000, loss: 0.061133
   Number of active neurons: 3
 >> iter 11000, loss: 0.046523
 >> iter 12000, loss: 0.050765
 >> iter 13000, loss: 0.041701
 >> iter 14000, loss: 0.046835
 >> iter 15000, loss: 0.033348
 >> iter 16000, loss: 0.051912
 >> iter 17000, loss: 0.037399
 >> iter 18000, loss: 0.038762
 >> iter 19000, loss: 0.043730
 >> iter 20000, loss: 0.053839
   Number of active neurons: 3
 >> iter 21000, loss: 0.044713
 >> iter 22000, loss: 0.051101
 >> iter 23000, loss: 0.062378
 >> iter 24000, loss: 0.071252
 >> iter 25000, loss: 0.064847
 >> iter 26000, loss: 0.044681
 >> iter 27000, loss: 0.047772
 >> iter 28000, loss: 0.039333
 >> iter 29000, loss: 0.056894
 >> iter 30000, loss: 0.046411
   Number of active neurons: 3
 >> iter 31000, loss: 0.045950
 >> iter 32000, loss: 0.044717
 >> iter 33000, loss: 0.054190
 >> iter 34000, loss: 0.037396
 >> iter 35000, loss: 0.057628
 >> iter 36000, loss: 0.062027
 >> iter 37000, loss: 0.046640
 >> iter 38000, loss: 0.056255
 >> iter 39000, loss: 0.060519
 >> iter 40000, loss: 0.044640
   Number of active neurons: 3
 >> iter 41000, loss: 0.041647
 >> iter 42000, loss: 0.056428
 >> iter 43000, loss: 0.052862
 >> iter 44000, loss: 0.049071
 >> iter 45000, loss: 0.077979
 >> iter 46000, loss: 0.053008
 >> iter 47000, loss: 0.051433
 >> iter 48000, loss: 0.044104
 >> iter 49000, loss: 0.049105
 >> iter 50000, loss: 0.048102
   Number of active neurons: 3
 >> iter 51000, loss: 0.047076
 >> iter 52000, loss: 0.050206
 >> iter 53000, loss: 0.046017
 >> iter 54000, loss: 0.050249
 >> iter 55000, loss: 0.040852
 >> iter 56000, loss: 0.048087
 >> iter 57000, loss: 0.044208
 >> iter 58000, loss: 0.041707
 >> iter 59000, loss: 0.035339
 >> iter 60000, loss: 0.047845
   Number of active neurons: 3
 >> iter 61000, loss: 0.050423
 >> iter 62000, loss: 0.054616
 >> iter 63000, loss: 0.071867
 >> iter 64000, loss: 0.044158
 >> iter 65000, loss: 0.042641
 >> iter 66000, loss: 0.053158
 >> iter 67000, loss: 0.044874
 >> iter 68000, loss: 0.037841
 >> iter 69000, loss: 0.040963
 >> iter 70000, loss: 0.044539
   Number of active neurons: 3
 >> iter 71000, loss: 0.033178
 >> iter 72000, loss: 0.038300
 >> iter 73000, loss: 0.044905
 >> iter 74000, loss: 0.048802
 >> iter 75000, loss: 0.047743
 >> iter 76000, loss: 0.046336
 >> iter 77000, loss: 0.045715
 >> iter 78000, loss: 0.035417
 >> iter 79000, loss: 0.045720
 >> iter 80000, loss: 0.075856
   Number of active neurons: 3
 >> iter 81000, loss: 0.045984
 >> iter 82000, loss: 0.032628
 >> iter 83000, loss: 0.031886
 >> iter 84000, loss: 0.043762
 >> iter 85000, loss: 0.037931
 >> iter 86000, loss: 0.044950
 >> iter 87000, loss: 0.045638
 >> iter 88000, loss: 0.062764
 >> iter 89000, loss: 0.044965
 >> iter 90000, loss: 0.040084
   Number of active neurons: 3
 >> iter 91000, loss: 0.044203
 >> iter 92000, loss: 0.033589
 >> iter 93000, loss: 0.042988
 >> iter 94000, loss: 0.044985
 >> iter 95000, loss: 0.044092
 >> iter 96000, loss: 0.043795
 >> iter 97000, loss: 0.045687
 >> iter 98000, loss: 0.036520
 >> iter 99000, loss: 0.045552
 >> iter 100000, loss: 0.049629
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 1:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.486514
 >> iter 2000, loss: 4.348518
 >> iter 3000, loss: 1.685332
 >> iter 4000, loss: 0.673864
 >> iter 5000, loss: 0.283486
 >> iter 6000, loss: 0.165523
 >> iter 7000, loss: 0.094310
 >> iter 8000, loss: 0.065019
 >> iter 9000, loss: 0.048349
 >> iter 10000, loss: 0.040980
   Number of active neurons: 3
 >> iter 11000, loss: 0.054597
 >> iter 12000, loss: 0.056084
 >> iter 13000, loss: 0.040944
 >> iter 14000, loss: 0.046418
 >> iter 15000, loss: 0.035647
 >> iter 16000, loss: 0.036972
 >> iter 17000, loss: 0.044371
 >> iter 18000, loss: 0.053558
 >> iter 19000, loss: 0.041954
 >> iter 20000, loss: 0.059408
   Number of active neurons: 3
 >> iter 21000, loss: 0.053537
 >> iter 22000, loss: 0.046856
 >> iter 23000, loss: 0.053826
 >> iter 24000, loss: 0.040463
 >> iter 25000, loss: 0.039167
 >> iter 26000, loss: 0.053093
 >> iter 27000, loss: 0.048543
 >> iter 28000, loss: 0.050679
 >> iter 29000, loss: 0.046415
 >> iter 30000, loss: 0.061234
   Number of active neurons: 3
 >> iter 31000, loss: 0.044016
 >> iter 32000, loss: 0.045427
 >> iter 33000, loss: 0.046302
 >> iter 34000, loss: 0.048626
 >> iter 35000, loss: 0.063791
 >> iter 36000, loss: 0.070983
 >> iter 37000, loss: 0.060421
 >> iter 38000, loss: 0.047744
 >> iter 39000, loss: 0.043657
 >> iter 40000, loss: 0.033051
   Number of active neurons: 3
 >> iter 41000, loss: 0.040600
 >> iter 42000, loss: 0.037839
 >> iter 43000, loss: 0.051788
 >> iter 44000, loss: 0.057346
 >> iter 45000, loss: 0.071960
 >> iter 46000, loss: 0.059207
 >> iter 47000, loss: 0.063363
 >> iter 48000, loss: 0.048667
 >> iter 49000, loss: 0.055194
 >> iter 50000, loss: 0.051065
   Number of active neurons: 3
 >> iter 51000, loss: 0.045549
 >> iter 52000, loss: 0.039861
 >> iter 53000, loss: 0.056543
 >> iter 54000, loss: 0.046376
 >> iter 55000, loss: 0.058361
 >> iter 56000, loss: 0.044881
 >> iter 57000, loss: 0.037322
 >> iter 58000, loss: 0.042789
 >> iter 59000, loss: 0.071392
 >> iter 60000, loss: 0.062388
   Number of active neurons: 3
 >> iter 61000, loss: 0.074415
 >> iter 62000, loss: 0.057589
 >> iter 63000, loss: 0.054532
 >> iter 64000, loss: 0.045327
 >> iter 65000, loss: 0.042930
 >> iter 66000, loss: 0.046278
 >> iter 67000, loss: 0.046249
 >> iter 68000, loss: 0.042635
 >> iter 69000, loss: 0.050499
 >> iter 70000, loss: 0.045459
   Number of active neurons: 3
 >> iter 71000, loss: 0.035450
 >> iter 72000, loss: 0.053352
 >> iter 73000, loss: 0.046966
 >> iter 74000, loss: 0.042238
 >> iter 75000, loss: 0.060268
 >> iter 76000, loss: 0.050710
 >> iter 77000, loss: 0.036796
 >> iter 78000, loss: 0.038164
 >> iter 79000, loss: 0.066963
 >> iter 80000, loss: 0.053685
   Number of active neurons: 2
 >> iter 81000, loss: 0.040539
 >> iter 82000, loss: 0.039364
 >> iter 83000, loss: 0.041910
 >> iter 84000, loss: 0.036625
 >> iter 85000, loss: 0.031584
 >> iter 86000, loss: 0.023081
 >> iter 87000, loss: 0.050586
 >> iter 88000, loss: 0.045203
 >> iter 89000, loss: 0.045060
 >> iter 90000, loss: 0.046269
   Number of active neurons: 2
 >> iter 91000, loss: 0.050190
 >> iter 92000, loss: 0.043700
 >> iter 93000, loss: 0.042355
 >> iter 94000, loss: 0.033686
 >> iter 95000, loss: 0.037516
 >> iter 96000, loss: 0.043336
 >> iter 97000, loss: 0.036579
 >> iter 98000, loss: 0.033728
 >> iter 99000, loss: 0.043908
 >> iter 100000, loss: 0.045690
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 2:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.708290
 >> iter 2000, loss: 4.527851
 >> iter 3000, loss: 1.749466
 >> iter 4000, loss: 0.728514
 >> iter 5000, loss: 0.319913
 >> iter 6000, loss: 0.159351
 >> iter 7000, loss: 0.093897
 >> iter 8000, loss: 0.079663
 >> iter 9000, loss: 0.070208
 >> iter 10000, loss: 0.070027
   Number of active neurons: 4
 >> iter 11000, loss: 0.050046
 >> iter 12000, loss: 0.047853
 >> iter 13000, loss: 0.050276
 >> iter 14000, loss: 0.052899
 >> iter 15000, loss: 0.040877
 >> iter 16000, loss: 0.051290
 >> iter 17000, loss: 0.049275
 >> iter 18000, loss: 0.041601
 >> iter 19000, loss: 0.043972
 >> iter 20000, loss: 0.037433
   Number of active neurons: 3
 >> iter 21000, loss: 0.048607
 >> iter 22000, loss: 0.058593
 >> iter 23000, loss: 0.054586
 >> iter 24000, loss: 0.048875
 >> iter 25000, loss: 0.061645
 >> iter 26000, loss: 0.052416
 >> iter 27000, loss: 0.052768
 >> iter 28000, loss: 0.041978
 >> iter 29000, loss: 0.038619
 >> iter 30000, loss: 0.027761
   Number of active neurons: 3
 >> iter 31000, loss: 0.028000
 >> iter 32000, loss: 0.059029
 >> iter 33000, loss: 0.048383
 >> iter 34000, loss: 0.052383
 >> iter 35000, loss: 0.044016
 >> iter 36000, loss: 0.042704
 >> iter 37000, loss: 0.041737
 >> iter 38000, loss: 0.046073
 >> iter 39000, loss: 0.039651
 >> iter 40000, loss: 0.052146
   Number of active neurons: 2
 >> iter 41000, loss: 0.044855
 >> iter 42000, loss: 0.047425
 >> iter 43000, loss: 0.032190
 >> iter 44000, loss: 0.034808
 >> iter 45000, loss: 0.031706
 >> iter 46000, loss: 0.036823
 >> iter 47000, loss: 0.041364
 >> iter 48000, loss: 0.040503
 >> iter 49000, loss: 0.046750
 >> iter 50000, loss: 0.049350
   Number of active neurons: 2
 >> iter 51000, loss: 0.080071
 >> iter 52000, loss: 0.069162
 >> iter 53000, loss: 0.042318
 >> iter 54000, loss: 0.038237
 >> iter 55000, loss: 0.050888
 >> iter 56000, loss: 0.035828
 >> iter 57000, loss: 0.037175
 >> iter 58000, loss: 0.056338
 >> iter 59000, loss: 0.052729
 >> iter 60000, loss: 0.048013
   Number of active neurons: 2
 >> iter 61000, loss: 0.039838
 >> iter 62000, loss: 0.030778
 >> iter 63000, loss: 0.063897
 >> iter 64000, loss: 0.043763
 >> iter 65000, loss: 0.049358
 >> iter 66000, loss: 0.044880
 >> iter 67000, loss: 0.038221
 >> iter 68000, loss: 0.052366
 >> iter 69000, loss: 0.068419
 >> iter 70000, loss: 0.050615
   Number of active neurons: 2
 >> iter 71000, loss: 0.037542
 >> iter 72000, loss: 0.049701
 >> iter 73000, loss: 0.046713
 >> iter 74000, loss: 0.057316
 >> iter 75000, loss: 0.047522
 >> iter 76000, loss: 0.047341
 >> iter 77000, loss: 0.047653
 >> iter 78000, loss: 0.057477
 >> iter 79000, loss: 0.049729
 >> iter 80000, loss: 0.048583
   Number of active neurons: 2
 >> iter 81000, loss: 0.068915
 >> iter 82000, loss: 0.045338
 >> iter 83000, loss: 0.038025
 >> iter 84000, loss: 0.045955
 >> iter 85000, loss: 0.046374
 >> iter 86000, loss: 0.058521
 >> iter 87000, loss: 0.088830
 >> iter 88000, loss: 0.054880
 >> iter 89000, loss: 0.054039
 >> iter 90000, loss: 0.042984
   Number of active neurons: 2
 >> iter 91000, loss: 0.034179
 >> iter 92000, loss: 0.038969
 >> iter 93000, loss: 0.041052
 >> iter 94000, loss: 0.040294
 >> iter 95000, loss: 0.046102
 >> iter 96000, loss: 0.049058
 >> iter 97000, loss: 0.041722
 >> iter 98000, loss: 0.038752
 >> iter 99000, loss: 0.039423
 >> iter 100000, loss: 0.029916
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 3:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.455700
 >> iter 2000, loss: 4.419561
 >> iter 3000, loss: 1.716120
 >> iter 4000, loss: 0.679461
 >> iter 5000, loss: 0.306721
 >> iter 6000, loss: 0.151808
 >> iter 7000, loss: 0.101347
 >> iter 8000, loss: 0.073850
 >> iter 9000, loss: 0.084702
 >> iter 10000, loss: 0.057532
   Number of active neurons: 4
 >> iter 11000, loss: 0.069913
 >> iter 12000, loss: 0.073299
 >> iter 13000, loss: 0.059609
 >> iter 14000, loss: 0.050474
 >> iter 15000, loss: 0.043428
 >> iter 16000, loss: 0.040268
 >> iter 17000, loss: 0.046604
 >> iter 18000, loss: 0.061284
 >> iter 19000, loss: 0.050443
 >> iter 20000, loss: 0.058017
   Number of active neurons: 4
 >> iter 21000, loss: 0.049837
 >> iter 22000, loss: 0.043859
 >> iter 23000, loss: 0.040010
 >> iter 24000, loss: 0.056194
 >> iter 25000, loss: 0.060442
 >> iter 26000, loss: 0.083182
 >> iter 27000, loss: 0.060802
 >> iter 28000, loss: 0.042635
 >> iter 29000, loss: 0.054117
 >> iter 30000, loss: 0.072347
   Number of active neurons: 4
 >> iter 31000, loss: 0.062459
 >> iter 32000, loss: 0.042615
 >> iter 33000, loss: 0.038400
 >> iter 34000, loss: 0.052497
 >> iter 35000, loss: 0.045327
 >> iter 36000, loss: 0.046921
 >> iter 37000, loss: 0.047587
 >> iter 38000, loss: 0.040907
 >> iter 39000, loss: 0.041351
 >> iter 40000, loss: 0.039565
   Number of active neurons: 4
 >> iter 41000, loss: 0.043871
 >> iter 42000, loss: 0.046650
 >> iter 43000, loss: 0.049853
 >> iter 44000, loss: 0.057099
 >> iter 45000, loss: 0.050444
 >> iter 46000, loss: 0.060521
 >> iter 47000, loss: 0.079164
 >> iter 48000, loss: 0.051308
 >> iter 49000, loss: 0.054501
 >> iter 50000, loss: 0.055244
   Number of active neurons: 3
 >> iter 51000, loss: 0.060090
 >> iter 52000, loss: 0.053001
 >> iter 53000, loss: 0.045186
 >> iter 54000, loss: 0.072842
 >> iter 55000, loss: 0.053505
 >> iter 56000, loss: 0.076034
 >> iter 57000, loss: 0.072002
 >> iter 58000, loss: 0.064605
 >> iter 59000, loss: 0.060891
 >> iter 60000, loss: 0.049061
   Number of active neurons: 3
 >> iter 61000, loss: 0.053835
 >> iter 62000, loss: 0.048343
 >> iter 63000, loss: 0.048839
 >> iter 64000, loss: 0.064054
 >> iter 65000, loss: 0.055663
 >> iter 66000, loss: 0.054504
 >> iter 67000, loss: 0.045692
 >> iter 68000, loss: 0.057432
 >> iter 69000, loss: 0.053222
 >> iter 70000, loss: 0.042334
   Number of active neurons: 3
 >> iter 71000, loss: 0.039272
 >> iter 72000, loss: 0.033547
 >> iter 73000, loss: 0.051375
 >> iter 74000, loss: 0.086135
 >> iter 75000, loss: 0.062494
 >> iter 76000, loss: 0.050844
 >> iter 77000, loss: 0.038106
 >> iter 78000, loss: 0.050184
 >> iter 79000, loss: 0.044892
 >> iter 80000, loss: 0.050300
   Number of active neurons: 3
 >> iter 81000, loss: 0.046051
 >> iter 82000, loss: 0.051632
 >> iter 83000, loss: 0.059252
 >> iter 84000, loss: 0.061595
 >> iter 85000, loss: 0.056489
 >> iter 86000, loss: 0.044454
 >> iter 87000, loss: 0.037568
 >> iter 88000, loss: 0.034501
 >> iter 89000, loss: 0.048438
 >> iter 90000, loss: 0.036091
   Number of active neurons: 3
 >> iter 91000, loss: 0.045131
 >> iter 92000, loss: 0.038263
 >> iter 93000, loss: 0.041814
 >> iter 94000, loss: 0.037766
 >> iter 95000, loss: 0.042739
 >> iter 96000, loss: 0.047140
 >> iter 97000, loss: 0.039652
 >> iter 98000, loss: 0.051688
 >> iter 99000, loss: 0.041036
 >> iter 100000, loss: 0.038466
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 4:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.474740
 >> iter 2000, loss: 4.423298
 >> iter 3000, loss: 1.721254
 >> iter 4000, loss: 0.681088
 >> iter 5000, loss: 0.296199
 >> iter 6000, loss: 0.135298
 >> iter 7000, loss: 0.098762
 >> iter 8000, loss: 0.067339
 >> iter 9000, loss: 0.083903
 >> iter 10000, loss: 0.073128
   Number of active neurons: 4
 >> iter 11000, loss: 0.076808
 >> iter 12000, loss: 0.054454
 >> iter 13000, loss: 0.046089
 >> iter 14000, loss: 0.084752
 >> iter 15000, loss: 0.069346
 >> iter 16000, loss: 0.056145
 >> iter 17000, loss: 0.050746
 >> iter 18000, loss: 0.046489
 >> iter 19000, loss: 0.048222
 >> iter 20000, loss: 0.049604
   Number of active neurons: 4
 >> iter 21000, loss: 0.071794
 >> iter 22000, loss: 0.065087
 >> iter 23000, loss: 0.050589
 >> iter 24000, loss: 0.057659
 >> iter 25000, loss: 0.053543
 >> iter 26000, loss: 0.039318
 >> iter 27000, loss: 0.036185
 >> iter 28000, loss: 0.032929
 >> iter 29000, loss: 0.062791
 >> iter 30000, loss: 0.062899
   Number of active neurons: 3
 >> iter 31000, loss: 0.051305
 >> iter 32000, loss: 0.041024
 >> iter 33000, loss: 0.054949
 >> iter 34000, loss: 0.044616
 >> iter 35000, loss: 0.038283
 >> iter 36000, loss: 0.033556
 >> iter 37000, loss: 0.040785
 >> iter 38000, loss: 0.038853
 >> iter 39000, loss: 0.044210
 >> iter 40000, loss: 0.055594
   Number of active neurons: 3
 >> iter 41000, loss: 0.062280
 >> iter 42000, loss: 0.064786
 >> iter 43000, loss: 0.056903
 >> iter 44000, loss: 0.057115
 >> iter 45000, loss: 0.058762
 >> iter 46000, loss: 0.059004
 >> iter 47000, loss: 0.047239
 >> iter 48000, loss: 0.044528
 >> iter 49000, loss: 0.047164
 >> iter 50000, loss: 0.048320
   Number of active neurons: 3
 >> iter 51000, loss: 0.055955
 >> iter 52000, loss: 0.067133
 >> iter 53000, loss: 0.054125
 >> iter 54000, loss: 0.057422
 >> iter 55000, loss: 0.056994
 >> iter 56000, loss: 0.041909
 >> iter 57000, loss: 0.031123
 >> iter 58000, loss: 0.028369
 >> iter 59000, loss: 0.050948
 >> iter 60000, loss: 0.040167
   Number of active neurons: 3
 >> iter 61000, loss: 0.053420
 >> iter 62000, loss: 0.054187
 >> iter 63000, loss: 0.058615
 >> iter 64000, loss: 0.050457
 >> iter 65000, loss: 0.051883
 >> iter 66000, loss: 0.045968
 >> iter 67000, loss: 0.062403
 >> iter 68000, loss: 0.050962
 >> iter 69000, loss: 0.054688
 >> iter 70000, loss: 0.057960
   Number of active neurons: 3
 >> iter 71000, loss: 0.045867
 >> iter 72000, loss: 0.052747
 >> iter 73000, loss: 0.041218
 >> iter 74000, loss: 0.046666
 >> iter 75000, loss: 0.044580
 >> iter 76000, loss: 0.057426
 >> iter 77000, loss: 0.053435
 >> iter 78000, loss: 0.048410
 >> iter 79000, loss: 0.045793
 >> iter 80000, loss: 0.036128
   Number of active neurons: 3
 >> iter 81000, loss: 0.037562
 >> iter 82000, loss: 0.053221
 >> iter 83000, loss: 0.060864
 >> iter 84000, loss: 0.064393
 >> iter 85000, loss: 0.048568
 >> iter 86000, loss: 0.053878
 >> iter 87000, loss: 0.064474
 >> iter 88000, loss: 0.040248
 >> iter 89000, loss: 0.042724
 >> iter 90000, loss: 0.048326
   Number of active neurons: 2
 >> iter 91000, loss: 0.038409
 >> iter 92000, loss: 0.049474
 >> iter 93000, loss: 0.039802
 >> iter 94000, loss: 0.045251
 >> iter 95000, loss: 0.043367
 >> iter 96000, loss: 0.040592
 >> iter 97000, loss: 0.061441
 >> iter 98000, loss: 0.042540
 >> iter 99000, loss: 0.043387
 >> iter 100000, loss: 0.046214
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 5:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.434599
 >> iter 2000, loss: 4.376653
 >> iter 3000, loss: 1.688458
 >> iter 4000, loss: 0.650234
 >> iter 5000, loss: 0.304535
 >> iter 6000, loss: 0.160364
 >> iter 7000, loss: 0.089334
 >> iter 8000, loss: 0.073680
 >> iter 9000, loss: 0.061957
 >> iter 10000, loss: 0.055018
   Number of active neurons: 4
 >> iter 11000, loss: 0.047589
 >> iter 12000, loss: 0.040400
 >> iter 13000, loss: 0.043692
 >> iter 14000, loss: 0.054811
 >> iter 15000, loss: 0.066353
 >> iter 16000, loss: 0.073009
 >> iter 17000, loss: 0.056092
 >> iter 18000, loss: 0.048026
 >> iter 19000, loss: 0.046004
 >> iter 20000, loss: 0.038928
   Number of active neurons: 4
 >> iter 21000, loss: 0.048673
 >> iter 22000, loss: 0.053129
 >> iter 23000, loss: 0.038682
 >> iter 24000, loss: 0.053103
 >> iter 25000, loss: 0.047285
 >> iter 26000, loss: 0.056803
 >> iter 27000, loss: 0.040539
 >> iter 28000, loss: 0.047792
 >> iter 29000, loss: 0.051602
 >> iter 30000, loss: 0.048857
   Number of active neurons: 4
 >> iter 31000, loss: 0.054089
 >> iter 32000, loss: 0.050337
 >> iter 33000, loss: 0.059329
 >> iter 34000, loss: 0.052703
 >> iter 35000, loss: 0.037921
 >> iter 36000, loss: 0.034023
 >> iter 37000, loss: 0.049830
 >> iter 38000, loss: 0.049514
 >> iter 39000, loss: 0.066162
 >> iter 40000, loss: 0.055130
   Number of active neurons: 3
 >> iter 41000, loss: 0.049476
 >> iter 42000, loss: 0.046498
 >> iter 43000, loss: 0.053099
 >> iter 44000, loss: 0.053402
 >> iter 45000, loss: 0.067086
 >> iter 46000, loss: 0.053766
 >> iter 47000, loss: 0.051074
 >> iter 48000, loss: 0.042405
 >> iter 49000, loss: 0.041254
 >> iter 50000, loss: 0.037855
   Number of active neurons: 3
 >> iter 51000, loss: 0.031613
 >> iter 52000, loss: 0.038825
 >> iter 53000, loss: 0.046581
 >> iter 54000, loss: 0.046126
 >> iter 55000, loss: 0.058430
 >> iter 56000, loss: 0.060444
 >> iter 57000, loss: 0.051532
 >> iter 58000, loss: 0.045271
 >> iter 59000, loss: 0.066043
 >> iter 60000, loss: 0.050287
   Number of active neurons: 3
 >> iter 61000, loss: 0.044513
 >> iter 62000, loss: 0.059112
 >> iter 63000, loss: 0.043589
 >> iter 64000, loss: 0.070936
 >> iter 65000, loss: 0.039552
 >> iter 66000, loss: 0.038055
 >> iter 67000, loss: 0.040784
 >> iter 68000, loss: 0.036560
 >> iter 69000, loss: 0.054007
 >> iter 70000, loss: 0.052219
   Number of active neurons: 3
 >> iter 71000, loss: 0.057874
 >> iter 72000, loss: 0.052642
 >> iter 73000, loss: 0.055017
 >> iter 74000, loss: 0.041437
 >> iter 75000, loss: 0.030532
 >> iter 76000, loss: 0.045849
 >> iter 77000, loss: 0.041125
 >> iter 78000, loss: 0.037625
 >> iter 79000, loss: 0.046930
 >> iter 80000, loss: 0.062981
   Number of active neurons: 3
 >> iter 81000, loss: 0.044694
 >> iter 82000, loss: 0.037235
 >> iter 83000, loss: 0.046863
 >> iter 84000, loss: 0.035181
 >> iter 85000, loss: 0.041985
 >> iter 86000, loss: 0.048705
 >> iter 87000, loss: 0.041376
 >> iter 88000, loss: 0.047122
 >> iter 89000, loss: 0.048030
 >> iter 90000, loss: 0.051648
   Number of active neurons: 3
 >> iter 91000, loss: 0.054637
 >> iter 92000, loss: 0.055523
 >> iter 93000, loss: 0.075489
 >> iter 94000, loss: 0.055794
 >> iter 95000, loss: 0.039471
 >> iter 96000, loss: 0.053885
 >> iter 97000, loss: 0.051929
 >> iter 98000, loss: 0.040288
 >> iter 99000, loss: 0.043021
 >> iter 100000, loss: 0.057617
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 6:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455170
   Number of active neurons: 0
 >> iter 1000, loss: 11.508654
 >> iter 2000, loss: 4.502072
 >> iter 3000, loss: 1.787901
 >> iter 4000, loss: 0.735403
 >> iter 5000, loss: 0.318885
 >> iter 6000, loss: 0.157137
 >> iter 7000, loss: 0.094060
 >> iter 8000, loss: 0.078091
 >> iter 9000, loss: 0.093120
 >> iter 10000, loss: 0.076064
   Number of active neurons: 4
 >> iter 11000, loss: 0.070166
 >> iter 12000, loss: 0.046394
 >> iter 13000, loss: 0.060685
 >> iter 14000, loss: 0.068462
 >> iter 15000, loss: 0.067551
 >> iter 16000, loss: 0.059829
 >> iter 17000, loss: 0.068626
 >> iter 18000, loss: 0.056778
 >> iter 19000, loss: 0.048165
 >> iter 20000, loss: 0.049060
   Number of active neurons: 4
 >> iter 21000, loss: 0.057794
 >> iter 22000, loss: 0.058440
 >> iter 23000, loss: 0.053731
 >> iter 24000, loss: 0.047138
 >> iter 25000, loss: 0.043602
 >> iter 26000, loss: 0.041700
 >> iter 27000, loss: 0.052969
 >> iter 28000, loss: 0.041308
 >> iter 29000, loss: 0.048968
 >> iter 30000, loss: 0.045161
   Number of active neurons: 4
 >> iter 31000, loss: 0.064100
 >> iter 32000, loss: 0.048928
 >> iter 33000, loss: 0.041529
 >> iter 34000, loss: 0.053638
 >> iter 35000, loss: 0.060632
 >> iter 36000, loss: 0.059460
 >> iter 37000, loss: 0.054075
 >> iter 38000, loss: 0.067543
 >> iter 39000, loss: 0.080931
 >> iter 40000, loss: 0.065387
   Number of active neurons: 3
 >> iter 41000, loss: 0.063871
 >> iter 42000, loss: 0.052676
 >> iter 43000, loss: 0.048549
 >> iter 44000, loss: 0.040004
 >> iter 45000, loss: 0.038234
 >> iter 46000, loss: 0.040859
 >> iter 47000, loss: 0.035345
 >> iter 48000, loss: 0.033765
 >> iter 49000, loss: 0.038650
 >> iter 50000, loss: 0.037495
   Number of active neurons: 3
 >> iter 51000, loss: 0.041903
 >> iter 52000, loss: 0.051414
 >> iter 53000, loss: 0.051779
 >> iter 54000, loss: 0.061414
 >> iter 55000, loss: 0.068470
 >> iter 56000, loss: 0.064355
 >> iter 57000, loss: 0.049370
 >> iter 58000, loss: 0.041071
 >> iter 59000, loss: 0.055372
 >> iter 60000, loss: 0.040485
   Number of active neurons: 3
 >> iter 61000, loss: 0.043905
 >> iter 62000, loss: 0.045531
 >> iter 63000, loss: 0.055398
 >> iter 64000, loss: 0.050057
 >> iter 65000, loss: 0.045592
 >> iter 66000, loss: 0.038146
 >> iter 67000, loss: 0.072541
 >> iter 68000, loss: 0.050797
 >> iter 69000, loss: 0.036972
 >> iter 70000, loss: 0.049312
   Number of active neurons: 3
 >> iter 71000, loss: 0.043183
 >> iter 72000, loss: 0.057276
 >> iter 73000, loss: 0.056001
 >> iter 74000, loss: 0.038760
 >> iter 75000, loss: 0.047742
 >> iter 76000, loss: 0.053175
 >> iter 77000, loss: 0.064138
 >> iter 78000, loss: 0.066217
 >> iter 79000, loss: 0.049934
 >> iter 80000, loss: 0.037100
   Number of active neurons: 3
 >> iter 81000, loss: 0.047822
 >> iter 82000, loss: 0.039549
 >> iter 83000, loss: 0.037024
 >> iter 84000, loss: 0.037930
 >> iter 85000, loss: 0.038337
 >> iter 86000, loss: 0.070011
 >> iter 87000, loss: 0.047110
 >> iter 88000, loss: 0.051462
 >> iter 89000, loss: 0.064513
 >> iter 90000, loss: 0.065132
   Number of active neurons: 2
 >> iter 91000, loss: 0.059611
 >> iter 92000, loss: 0.046041
 >> iter 93000, loss: 0.042568
 >> iter 94000, loss: 0.040508
 >> iter 95000, loss: 0.036567
 >> iter 96000, loss: 0.057123
 >> iter 97000, loss: 0.060703
 >> iter 98000, loss: 0.044382
 >> iter 99000, loss: 0.046631
 >> iter 100000, loss: 0.055491
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 7:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.517043
 >> iter 2000, loss: 4.375926
 >> iter 3000, loss: 1.690361
 >> iter 4000, loss: 0.684466
 >> iter 5000, loss: 0.286060
 >> iter 6000, loss: 0.150051
 >> iter 7000, loss: 0.110389
 >> iter 8000, loss: 0.075576
 >> iter 9000, loss: 0.050084
 >> iter 10000, loss: 0.047352
   Number of active neurons: 3
 >> iter 11000, loss: 0.047989
 >> iter 12000, loss: 0.056657
 >> iter 13000, loss: 0.085659
 >> iter 14000, loss: 0.063799
 >> iter 15000, loss: 0.065251
 >> iter 16000, loss: 0.047428
 >> iter 17000, loss: 0.073790
 >> iter 18000, loss: 0.069778
 >> iter 19000, loss: 0.046973
 >> iter 20000, loss: 0.044686
   Number of active neurons: 3
 >> iter 21000, loss: 0.049200
 >> iter 22000, loss: 0.039564
 >> iter 23000, loss: 0.036011
 >> iter 24000, loss: 0.037025
 >> iter 25000, loss: 0.060867
 >> iter 26000, loss: 0.046114
 >> iter 27000, loss: 0.039684
 >> iter 28000, loss: 0.041651
 >> iter 29000, loss: 0.044952
 >> iter 30000, loss: 0.054808
   Number of active neurons: 3
 >> iter 31000, loss: 0.049468
 >> iter 32000, loss: 0.046130
 >> iter 33000, loss: 0.042807
 >> iter 34000, loss: 0.053705
 >> iter 35000, loss: 0.076376
 >> iter 36000, loss: 0.059870
 >> iter 37000, loss: 0.057629
 >> iter 38000, loss: 0.041892
 >> iter 39000, loss: 0.047699
 >> iter 40000, loss: 0.039729
   Number of active neurons: 2
 >> iter 41000, loss: 0.043868
 >> iter 42000, loss: 0.043732
 >> iter 43000, loss: 0.046052
 >> iter 44000, loss: 0.051007
 >> iter 45000, loss: 0.073461
 >> iter 46000, loss: 0.057303
 >> iter 47000, loss: 0.046836
 >> iter 48000, loss: 0.035624
 >> iter 49000, loss: 0.048567
 >> iter 50000, loss: 0.050634
   Number of active neurons: 2
 >> iter 51000, loss: 0.064147
 >> iter 52000, loss: 0.066880
 >> iter 53000, loss: 0.055310
 >> iter 54000, loss: 0.061276
 >> iter 55000, loss: 0.054630
 >> iter 56000, loss: 0.043477
 >> iter 57000, loss: 0.052914
 >> iter 58000, loss: 0.047386
 >> iter 59000, loss: 0.040436
 >> iter 60000, loss: 0.058310
   Number of active neurons: 2
 >> iter 61000, loss: 0.045736
 >> iter 62000, loss: 0.052316
 >> iter 63000, loss: 0.037444
 >> iter 64000, loss: 0.051701
 >> iter 65000, loss: 0.062045
 >> iter 66000, loss: 0.047387
 >> iter 67000, loss: 0.033253
 >> iter 68000, loss: 0.036786
 >> iter 69000, loss: 0.042718
 >> iter 70000, loss: 0.047180
   Number of active neurons: 2
 >> iter 71000, loss: 0.048302
 >> iter 72000, loss: 0.039714
 >> iter 73000, loss: 0.053947
 >> iter 74000, loss: 0.078608
 >> iter 75000, loss: 0.044065
 >> iter 76000, loss: 0.045881
 >> iter 77000, loss: 0.039472
 >> iter 78000, loss: 0.040717
 >> iter 79000, loss: 0.032596
 >> iter 80000, loss: 0.031309
   Number of active neurons: 2
 >> iter 81000, loss: 0.036451
 >> iter 82000, loss: 0.038605
 >> iter 83000, loss: 0.046308
 >> iter 84000, loss: 0.033159
 >> iter 85000, loss: 0.043368
 >> iter 86000, loss: 0.058298
 >> iter 87000, loss: 0.040086
 >> iter 88000, loss: 0.050070
 >> iter 89000, loss: 0.036204
 >> iter 90000, loss: 0.054293
   Number of active neurons: 2
 >> iter 91000, loss: 0.043372
 >> iter 92000, loss: 0.043730
 >> iter 93000, loss: 0.045096
 >> iter 94000, loss: 0.050174
 >> iter 95000, loss: 0.033996
 >> iter 96000, loss: 0.031607
 >> iter 97000, loss: 0.039133
 >> iter 98000, loss: 0.031111
 >> iter 99000, loss: 0.035564
 >> iter 100000, loss: 0.040702
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 8:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455169
   Number of active neurons: 0
 >> iter 1000, loss: 11.417654
 >> iter 2000, loss: 4.364543
 >> iter 3000, loss: 1.740888
 >> iter 4000, loss: 0.677047
 >> iter 5000, loss: 0.301996
 >> iter 6000, loss: 0.173105
 >> iter 7000, loss: 0.095348
 >> iter 8000, loss: 0.060040
 >> iter 9000, loss: 0.058578
 >> iter 10000, loss: 0.055445
   Number of active neurons: 4
 >> iter 11000, loss: 0.064881
 >> iter 12000, loss: 0.051592
 >> iter 13000, loss: 0.046487
 >> iter 14000, loss: 0.046934
 >> iter 15000, loss: 0.043314
 >> iter 16000, loss: 0.046566
 >> iter 17000, loss: 0.054765
 >> iter 18000, loss: 0.057091
 >> iter 19000, loss: 0.052193
 >> iter 20000, loss: 0.056071
   Number of active neurons: 4
 >> iter 21000, loss: 0.051412
 >> iter 22000, loss: 0.054397
 >> iter 23000, loss: 0.047154
 >> iter 24000, loss: 0.064661
 >> iter 25000, loss: 0.072110
 >> iter 26000, loss: 0.051046
 >> iter 27000, loss: 0.057182
 >> iter 28000, loss: 0.060174
 >> iter 29000, loss: 0.074429
 >> iter 30000, loss: 0.078578
   Number of active neurons: 4
 >> iter 31000, loss: 0.058860
 >> iter 32000, loss: 0.066434
 >> iter 33000, loss: 0.058322
 >> iter 34000, loss: 0.052881
 >> iter 35000, loss: 0.066645
 >> iter 36000, loss: 0.048696
 >> iter 37000, loss: 0.045267
 >> iter 38000, loss: 0.043364
 >> iter 39000, loss: 0.042584
 >> iter 40000, loss: 0.042863
   Number of active neurons: 4
 >> iter 41000, loss: 0.047688
 >> iter 42000, loss: 0.034645
 >> iter 43000, loss: 0.041115
 >> iter 44000, loss: 0.038560
 >> iter 45000, loss: 0.044039
 >> iter 46000, loss: 0.047053
 >> iter 47000, loss: 0.048657
 >> iter 48000, loss: 0.032354
 >> iter 49000, loss: 0.055597
 >> iter 50000, loss: 0.057761
   Number of active neurons: 4
 >> iter 51000, loss: 0.041360
 >> iter 52000, loss: 0.063960
 >> iter 53000, loss: 0.043105
 >> iter 54000, loss: 0.045648
 >> iter 55000, loss: 0.049334
 >> iter 56000, loss: 0.045413
 >> iter 57000, loss: 0.043934
 >> iter 58000, loss: 0.034787
 >> iter 59000, loss: 0.055683
 >> iter 60000, loss: 0.044958
   Number of active neurons: 4
 >> iter 61000, loss: 0.073352
 >> iter 62000, loss: 0.041664
 >> iter 63000, loss: 0.065035
 >> iter 64000, loss: 0.054663
 >> iter 65000, loss: 0.079194
 >> iter 66000, loss: 0.064436
 >> iter 67000, loss: 0.059173
 >> iter 68000, loss: 0.056800
 >> iter 69000, loss: 0.047400
 >> iter 70000, loss: 0.053408
   Number of active neurons: 4
 >> iter 71000, loss: 0.047065
 >> iter 72000, loss: 0.054363
 >> iter 73000, loss: 0.061969
 >> iter 74000, loss: 0.050203
 >> iter 75000, loss: 0.053848
 >> iter 76000, loss: 0.048474
 >> iter 77000, loss: 0.033986
 >> iter 78000, loss: 0.041319
 >> iter 79000, loss: 0.038190
 >> iter 80000, loss: 0.045993
   Number of active neurons: 4
 >> iter 81000, loss: 0.064519
 >> iter 82000, loss: 0.057239
 >> iter 83000, loss: 0.062649
 >> iter 84000, loss: 0.062599
 >> iter 85000, loss: 0.053238
 >> iter 86000, loss: 0.036354
 >> iter 87000, loss: 0.043317
 >> iter 88000, loss: 0.035054
 >> iter 89000, loss: 0.033847
 >> iter 90000, loss: 0.033436
   Number of active neurons: 4
 >> iter 91000, loss: 0.049937
 >> iter 92000, loss: 0.043752
 >> iter 93000, loss: 0.051725
 >> iter 94000, loss: 0.041832
 >> iter 95000, loss: 0.044853
 >> iter 96000, loss: 0.038709
 >> iter 97000, loss: 0.043675
 >> iter 98000, loss: 0.033476
 >> iter 99000, loss: 0.044073
 >> iter 100000, loss: 0.053507
   Number of active neurons: 4
 ----------- DONE -----------

 > Ejecucion 9:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455168
   Number of active neurons: 0
 >> iter 1000, loss: 11.679549
 >> iter 2000, loss: 4.557467
 >> iter 3000, loss: 1.749716
 >> iter 4000, loss: 0.713510
 >> iter 5000, loss: 0.305022
 >> iter 6000, loss: 0.144344
 >> iter 7000, loss: 0.083999
 >> iter 8000, loss: 0.059609
 >> iter 9000, loss: 0.071642
 >> iter 10000, loss: 0.053491
   Number of active neurons: 3
 >> iter 11000, loss: 0.046883
 >> iter 12000, loss: 0.062867
 >> iter 13000, loss: 0.049858
 >> iter 14000, loss: 0.073806
 >> iter 15000, loss: 0.073380
 >> iter 16000, loss: 0.048091
 >> iter 17000, loss: 0.047073
 >> iter 18000, loss: 0.053950
 >> iter 19000, loss: 0.044393
 >> iter 20000, loss: 0.038911
   Number of active neurons: 3
 >> iter 21000, loss: 0.041337
 >> iter 22000, loss: 0.054999
 >> iter 23000, loss: 0.077845
 >> iter 24000, loss: 0.068349
 >> iter 25000, loss: 0.044051
 >> iter 26000, loss: 0.065857
 >> iter 27000, loss: 0.039215
 >> iter 28000, loss: 0.038424
 >> iter 29000, loss: 0.052296
 >> iter 30000, loss: 0.050230
   Number of active neurons: 3
 >> iter 31000, loss: 0.063955
 >> iter 32000, loss: 0.054924
 >> iter 33000, loss: 0.052113
 >> iter 34000, loss: 0.050610
 >> iter 35000, loss: 0.049952
 >> iter 36000, loss: 0.044844
 >> iter 37000, loss: 0.052790
 >> iter 38000, loss: 0.037724
 >> iter 39000, loss: 0.032683
 >> iter 40000, loss: 0.050714
   Number of active neurons: 3
 >> iter 41000, loss: 0.037898
 >> iter 42000, loss: 0.041970
 >> iter 43000, loss: 0.053325
 >> iter 44000, loss: 0.052094
 >> iter 45000, loss: 0.053092
 >> iter 46000, loss: 0.046993
 >> iter 47000, loss: 0.051943
 >> iter 48000, loss: 0.061760
 >> iter 49000, loss: 0.042241
 >> iter 50000, loss: 0.050448
   Number of active neurons: 3
 >> iter 51000, loss: 0.044067
 >> iter 52000, loss: 0.039246
 >> iter 53000, loss: 0.037218
 >> iter 54000, loss: 0.049475
 >> iter 55000, loss: 0.051558
 >> iter 56000, loss: 0.065733
 >> iter 57000, loss: 0.049895
 >> iter 58000, loss: 0.044760
 >> iter 59000, loss: 0.051143
 >> iter 60000, loss: 0.059341
   Number of active neurons: 3
 >> iter 61000, loss: 0.055341
 >> iter 62000, loss: 0.050141
 >> iter 63000, loss: 0.040019
 >> iter 64000, loss: 0.040249
 >> iter 65000, loss: 0.072461
 >> iter 66000, loss: 0.058212
 >> iter 67000, loss: 0.043333
 >> iter 68000, loss: 0.044190
 >> iter 69000, loss: 0.067747
 >> iter 70000, loss: 0.066791
   Number of active neurons: 3
 >> iter 71000, loss: 0.057885
 >> iter 72000, loss: 0.056138
 >> iter 73000, loss: 0.048524
 >> iter 74000, loss: 0.052493
 >> iter 75000, loss: 0.042061
 >> iter 76000, loss: 0.045617
 >> iter 77000, loss: 0.044243
 >> iter 78000, loss: 0.037891
 >> iter 79000, loss: 0.048640
 >> iter 80000, loss: 0.041018
   Number of active neurons: 3
 >> iter 81000, loss: 0.043796
 >> iter 82000, loss: 0.044941
 >> iter 83000, loss: 0.063761
 >> iter 84000, loss: 0.047086
 >> iter 85000, loss: 0.044626
 >> iter 86000, loss: 0.042649
 >> iter 87000, loss: 0.052737
 >> iter 88000, loss: 0.044076
 >> iter 89000, loss: 0.071762
 >> iter 90000, loss: 0.044021
   Number of active neurons: 2
 >> iter 91000, loss: 0.053724
 >> iter 92000, loss: 0.044930
 >> iter 93000, loss: 0.030274
 >> iter 94000, loss: 0.044622
 >> iter 95000, loss: 0.049834
 >> iter 96000, loss: 0.040469
 >> iter 97000, loss: 0.035794
 >> iter 98000, loss: 0.039817
 >> iter 99000, loss: 0.040969
 >> iter 100000, loss: 0.033236
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 10:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.355311
 >> iter 2000, loss: 4.347763
 >> iter 3000, loss: 1.676101
 >> iter 4000, loss: 0.678230
 >> iter 5000, loss: 0.282124
 >> iter 6000, loss: 0.148189
 >> iter 7000, loss: 0.104308
 >> iter 8000, loss: 0.059769
 >> iter 9000, loss: 0.055329
 >> iter 10000, loss: 0.069313
   Number of active neurons: 4
 >> iter 11000, loss: 0.071010
 >> iter 12000, loss: 0.073125
 >> iter 13000, loss: 0.068407
 >> iter 14000, loss: 0.048944
 >> iter 15000, loss: 0.042290
 >> iter 16000, loss: 0.056819
 >> iter 17000, loss: 0.048000
 >> iter 18000, loss: 0.048224
 >> iter 19000, loss: 0.044033
 >> iter 20000, loss: 0.050166
   Number of active neurons: 3
 >> iter 21000, loss: 0.051343
 >> iter 22000, loss: 0.058699
 >> iter 23000, loss: 0.058601
 >> iter 24000, loss: 0.040039
 >> iter 25000, loss: 0.055283
 >> iter 26000, loss: 0.056610
 >> iter 27000, loss: 0.050083
 >> iter 28000, loss: 0.053233
 >> iter 29000, loss: 0.046690
 >> iter 30000, loss: 0.036858
   Number of active neurons: 3
 >> iter 31000, loss: 0.070584
 >> iter 32000, loss: 0.052285
 >> iter 33000, loss: 0.048097
 >> iter 34000, loss: 0.067459
 >> iter 35000, loss: 0.052955
 >> iter 36000, loss: 0.048698
 >> iter 37000, loss: 0.050510
 >> iter 38000, loss: 0.056686
 >> iter 39000, loss: 0.041963
 >> iter 40000, loss: 0.039035
   Number of active neurons: 3
 >> iter 41000, loss: 0.061888
 >> iter 42000, loss: 0.048069
 >> iter 43000, loss: 0.054730
 >> iter 44000, loss: 0.050053
 >> iter 45000, loss: 0.052113
 >> iter 46000, loss: 0.066136
 >> iter 47000, loss: 0.048683
 >> iter 48000, loss: 0.052865
 >> iter 49000, loss: 0.061007
 >> iter 50000, loss: 0.063031
   Number of active neurons: 3
 >> iter 51000, loss: 0.044155
 >> iter 52000, loss: 0.031625
 >> iter 53000, loss: 0.039122
 >> iter 54000, loss: 0.061294
 >> iter 55000, loss: 0.069117
 >> iter 56000, loss: 0.051859
 >> iter 57000, loss: 0.063571
 >> iter 58000, loss: 0.049677
 >> iter 59000, loss: 0.063991
 >> iter 60000, loss: 0.038715
   Number of active neurons: 3
 >> iter 61000, loss: 0.051470
 >> iter 62000, loss: 0.041141
 >> iter 63000, loss: 0.040058
 >> iter 64000, loss: 0.041784
 >> iter 65000, loss: 0.044043
 >> iter 66000, loss: 0.050402
 >> iter 67000, loss: 0.060979
 >> iter 68000, loss: 0.054125
 >> iter 69000, loss: 0.044974
 >> iter 70000, loss: 0.050316
   Number of active neurons: 3
 >> iter 71000, loss: 0.044342
 >> iter 72000, loss: 0.054152
 >> iter 73000, loss: 0.047814
 >> iter 74000, loss: 0.047283
 >> iter 75000, loss: 0.069576
 >> iter 76000, loss: 0.048374
 >> iter 77000, loss: 0.041087
 >> iter 78000, loss: 0.062746
 >> iter 79000, loss: 0.051214
 >> iter 80000, loss: 0.042520
   Number of active neurons: 3
 >> iter 81000, loss: 0.040865
 >> iter 82000, loss: 0.038630
 >> iter 83000, loss: 0.038878
 >> iter 84000, loss: 0.039000
 >> iter 85000, loss: 0.061542
 >> iter 86000, loss: 0.051745
 >> iter 87000, loss: 0.046489
 >> iter 88000, loss: 0.036024
 >> iter 89000, loss: 0.051503
 >> iter 90000, loss: 0.048962
   Number of active neurons: 3
 >> iter 91000, loss: 0.047351
 >> iter 92000, loss: 0.040202
 >> iter 93000, loss: 0.044705
 >> iter 94000, loss: 0.040986
 >> iter 95000, loss: 0.035647
 >> iter 96000, loss: 0.038617
 >> iter 97000, loss: 0.045539
 >> iter 98000, loss: 0.042783
 >> iter 99000, loss: 0.043327
 >> iter 100000, loss: 0.054787
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 11:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455173
   Number of active neurons: 0
 >> iter 1000, loss: 11.674723
 >> iter 2000, loss: 4.464109
 >> iter 3000, loss: 1.715983
 >> iter 4000, loss: 0.673583
 >> iter 5000, loss: 0.294970
 >> iter 6000, loss: 0.158769
 >> iter 7000, loss: 0.105856
 >> iter 8000, loss: 0.072420
 >> iter 9000, loss: 0.056570
 >> iter 10000, loss: 0.068657
   Number of active neurons: 3
 >> iter 11000, loss: 0.056305
 >> iter 12000, loss: 0.056040
 >> iter 13000, loss: 0.069987
 >> iter 14000, loss: 0.062032
 >> iter 15000, loss: 0.048680
 >> iter 16000, loss: 0.041413
 >> iter 17000, loss: 0.046926
 >> iter 18000, loss: 0.060524
 >> iter 19000, loss: 0.047618
 >> iter 20000, loss: 0.039022
   Number of active neurons: 3
 >> iter 21000, loss: 0.043137
 >> iter 22000, loss: 0.043575
 >> iter 23000, loss: 0.055856
 >> iter 24000, loss: 0.038197
 >> iter 25000, loss: 0.048091
 >> iter 26000, loss: 0.050237
 >> iter 27000, loss: 0.036623
 >> iter 28000, loss: 0.046554
 >> iter 29000, loss: 0.045965
 >> iter 30000, loss: 0.043792
   Number of active neurons: 3
 >> iter 31000, loss: 0.035627
 >> iter 32000, loss: 0.063500
 >> iter 33000, loss: 0.057657
 >> iter 34000, loss: 0.063939
 >> iter 35000, loss: 0.084134
 >> iter 36000, loss: 0.053448
 >> iter 37000, loss: 0.044781
 >> iter 38000, loss: 0.067307
 >> iter 39000, loss: 0.065397
 >> iter 40000, loss: 0.066551
   Number of active neurons: 3
 >> iter 41000, loss: 0.058498
 >> iter 42000, loss: 0.042036
 >> iter 43000, loss: 0.048245
 >> iter 44000, loss: 0.068673
 >> iter 45000, loss: 0.051630
 >> iter 46000, loss: 0.038809
 >> iter 47000, loss: 0.036948
 >> iter 48000, loss: 0.046275
 >> iter 49000, loss: 0.047882
 >> iter 50000, loss: 0.071446
   Number of active neurons: 3
 >> iter 51000, loss: 0.059922
 >> iter 52000, loss: 0.062296
 >> iter 53000, loss: 0.042851
 >> iter 54000, loss: 0.054742
 >> iter 55000, loss: 0.053885
 >> iter 56000, loss: 0.051304
 >> iter 57000, loss: 0.041342
 >> iter 58000, loss: 0.037928
 >> iter 59000, loss: 0.054180
 >> iter 60000, loss: 0.046742
   Number of active neurons: 2
 >> iter 61000, loss: 0.045863
 >> iter 62000, loss: 0.047755
 >> iter 63000, loss: 0.066149
 >> iter 64000, loss: 0.040951
 >> iter 65000, loss: 0.048581
 >> iter 66000, loss: 0.039064
 >> iter 67000, loss: 0.037955
 >> iter 68000, loss: 0.026393
 >> iter 69000, loss: 0.039898
 >> iter 70000, loss: 0.037091
   Number of active neurons: 2
 >> iter 71000, loss: 0.037412
 >> iter 72000, loss: 0.045604
 >> iter 73000, loss: 0.058139
 >> iter 74000, loss: 0.065086
 >> iter 75000, loss: 0.070495
 >> iter 76000, loss: 0.045819
 >> iter 77000, loss: 0.042321
 >> iter 78000, loss: 0.036476
 >> iter 79000, loss: 0.044923
 >> iter 80000, loss: 0.063738
   Number of active neurons: 2
 >> iter 81000, loss: 0.057663
 >> iter 82000, loss: 0.058054
 >> iter 83000, loss: 0.043480
 >> iter 84000, loss: 0.032444
 >> iter 85000, loss: 0.036524
 >> iter 86000, loss: 0.035798
 >> iter 87000, loss: 0.053508
 >> iter 88000, loss: 0.046596
 >> iter 89000, loss: 0.056962
 >> iter 90000, loss: 0.043792
   Number of active neurons: 2
 >> iter 91000, loss: 0.035144
 >> iter 92000, loss: 0.026388
 >> iter 93000, loss: 0.031124
 >> iter 94000, loss: 0.043768
 >> iter 95000, loss: 0.035596
 >> iter 96000, loss: 0.042026
 >> iter 97000, loss: 0.049599
 >> iter 98000, loss: 0.032265
 >> iter 99000, loss: 0.042653
 >> iter 100000, loss: 0.030357
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 12:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455174
   Number of active neurons: 0
 >> iter 1000, loss: 11.528403
 >> iter 2000, loss: 4.419078
 >> iter 3000, loss: 1.701929
 >> iter 4000, loss: 0.685213
 >> iter 5000, loss: 0.293788
 >> iter 6000, loss: 0.142897
 >> iter 7000, loss: 0.094428
 >> iter 8000, loss: 0.074364
 >> iter 9000, loss: 0.053765
 >> iter 10000, loss: 0.059554
   Number of active neurons: 4
 >> iter 11000, loss: 0.080979
 >> iter 12000, loss: 0.062286
 >> iter 13000, loss: 0.044396
 >> iter 14000, loss: 0.057623
 >> iter 15000, loss: 0.055167
 >> iter 16000, loss: 0.048288
 >> iter 17000, loss: 0.041634
 >> iter 18000, loss: 0.054234
 >> iter 19000, loss: 0.070844
 >> iter 20000, loss: 0.050549
   Number of active neurons: 4
 >> iter 21000, loss: 0.067341
 >> iter 22000, loss: 0.062553
 >> iter 23000, loss: 0.055363
 >> iter 24000, loss: 0.042943
 >> iter 25000, loss: 0.039513
 >> iter 26000, loss: 0.045293
 >> iter 27000, loss: 0.049610
 >> iter 28000, loss: 0.049965
 >> iter 29000, loss: 0.073526
 >> iter 30000, loss: 0.051119
   Number of active neurons: 4
 >> iter 31000, loss: 0.052769
 >> iter 32000, loss: 0.060914
 >> iter 33000, loss: 0.056447
 >> iter 34000, loss: 0.049497
 >> iter 35000, loss: 0.058438
 >> iter 36000, loss: 0.048307
 >> iter 37000, loss: 0.049372
 >> iter 38000, loss: 0.050877
 >> iter 39000, loss: 0.073173
 >> iter 40000, loss: 0.053385
   Number of active neurons: 4
 >> iter 41000, loss: 0.043199
 >> iter 42000, loss: 0.048397
 >> iter 43000, loss: 0.044294
 >> iter 44000, loss: 0.052725
 >> iter 45000, loss: 0.049652
 >> iter 46000, loss: 0.037567
 >> iter 47000, loss: 0.033959
 >> iter 48000, loss: 0.045112
 >> iter 49000, loss: 0.047506
 >> iter 50000, loss: 0.051624
   Number of active neurons: 4
 >> iter 51000, loss: 0.046702
 >> iter 52000, loss: 0.057671
 >> iter 53000, loss: 0.057885
 >> iter 54000, loss: 0.047481
 >> iter 55000, loss: 0.042375
 >> iter 56000, loss: 0.055097
 >> iter 57000, loss: 0.054444
 >> iter 58000, loss: 0.056157
 >> iter 59000, loss: 0.056423
 >> iter 60000, loss: 0.054689
   Number of active neurons: 4
 >> iter 61000, loss: 0.053303
 >> iter 62000, loss: 0.036512
 >> iter 63000, loss: 0.053253
 >> iter 64000, loss: 0.050072
 >> iter 65000, loss: 0.057487
 >> iter 66000, loss: 0.049756
 >> iter 67000, loss: 0.034338
 >> iter 68000, loss: 0.039483
 >> iter 69000, loss: 0.043379
 >> iter 70000, loss: 0.057872
   Number of active neurons: 3
 >> iter 71000, loss: 0.042939
 >> iter 72000, loss: 0.035157
 >> iter 73000, loss: 0.057251
 >> iter 74000, loss: 0.047740
 >> iter 75000, loss: 0.040140
 >> iter 76000, loss: 0.036545
 >> iter 77000, loss: 0.064297
 >> iter 78000, loss: 0.050838
 >> iter 79000, loss: 0.052569
 >> iter 80000, loss: 0.043507
   Number of active neurons: 3
 >> iter 81000, loss: 0.039122
 >> iter 82000, loss: 0.056622
 >> iter 83000, loss: 0.044025
 >> iter 84000, loss: 0.046452
 >> iter 85000, loss: 0.035889
 >> iter 86000, loss: 0.052025
 >> iter 87000, loss: 0.050664
 >> iter 88000, loss: 0.036686
 >> iter 89000, loss: 0.056679
 >> iter 90000, loss: 0.043500
   Number of active neurons: 3
 >> iter 91000, loss: 0.039994
 >> iter 92000, loss: 0.050202
 >> iter 93000, loss: 0.045781
 >> iter 94000, loss: 0.047786
 >> iter 95000, loss: 0.051360
 >> iter 96000, loss: 0.042031
 >> iter 97000, loss: 0.052932
 >> iter 98000, loss: 0.034986
 >> iter 99000, loss: 0.042776
 >> iter 100000, loss: 0.037958
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 13:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.739074
 >> iter 2000, loss: 4.695486
 >> iter 3000, loss: 1.885628
 >> iter 4000, loss: 0.757879
 >> iter 5000, loss: 0.337294
 >> iter 6000, loss: 0.165638
 >> iter 7000, loss: 0.089522
 >> iter 8000, loss: 0.063817
 >> iter 9000, loss: 0.052085
 >> iter 10000, loss: 0.051267
   Number of active neurons: 3
 >> iter 11000, loss: 0.046699
 >> iter 12000, loss: 0.061246
 >> iter 13000, loss: 0.066569
 >> iter 14000, loss: 0.041062
 >> iter 15000, loss: 0.044429
 >> iter 16000, loss: 0.047446
 >> iter 17000, loss: 0.056095
 >> iter 18000, loss: 0.075938
 >> iter 19000, loss: 0.061710
 >> iter 20000, loss: 0.046616
   Number of active neurons: 3
 >> iter 21000, loss: 0.041326
 >> iter 22000, loss: 0.054502
 >> iter 23000, loss: 0.052045
 >> iter 24000, loss: 0.049945
 >> iter 25000, loss: 0.057132
 >> iter 26000, loss: 0.054829
 >> iter 27000, loss: 0.040000
 >> iter 28000, loss: 0.033635
 >> iter 29000, loss: 0.041969
 >> iter 30000, loss: 0.057538
   Number of active neurons: 2
 >> iter 31000, loss: 0.053591
 >> iter 32000, loss: 0.043709
 >> iter 33000, loss: 0.039076
 >> iter 34000, loss: 0.046882
 >> iter 35000, loss: 0.067429
 >> iter 36000, loss: 0.046659
 >> iter 37000, loss: 0.043811
 >> iter 38000, loss: 0.034672
 >> iter 39000, loss: 0.037041
 >> iter 40000, loss: 0.036577
   Number of active neurons: 2
 >> iter 41000, loss: 0.052911
 >> iter 42000, loss: 0.055030
 >> iter 43000, loss: 0.051975
 >> iter 44000, loss: 0.049868
 >> iter 45000, loss: 0.037681
 >> iter 46000, loss: 0.048030
 >> iter 47000, loss: 0.064443
 >> iter 48000, loss: 0.052175
 >> iter 49000, loss: 0.049228
 >> iter 50000, loss: 0.051025
   Number of active neurons: 2
 >> iter 51000, loss: 0.035895
 >> iter 52000, loss: 0.052370
 >> iter 53000, loss: 0.062041
 >> iter 54000, loss: 0.066848
 >> iter 55000, loss: 0.061748
 >> iter 56000, loss: 0.039293
 >> iter 57000, loss: 0.045319
 >> iter 58000, loss: 0.046136
 >> iter 59000, loss: 0.036537
 >> iter 60000, loss: 0.034141
   Number of active neurons: 2
 >> iter 61000, loss: 0.040524
 >> iter 62000, loss: 0.041708
 >> iter 63000, loss: 0.051353
 >> iter 64000, loss: 0.054120
 >> iter 65000, loss: 0.039079
 >> iter 66000, loss: 0.043772
 >> iter 67000, loss: 0.039936
 >> iter 68000, loss: 0.045215
 >> iter 69000, loss: 0.058215
 >> iter 70000, loss: 0.045787
   Number of active neurons: 2
 >> iter 71000, loss: 0.069749
 >> iter 72000, loss: 0.065623
 >> iter 73000, loss: 0.053924
 >> iter 74000, loss: 0.041023
 >> iter 75000, loss: 0.035593
 >> iter 76000, loss: 0.035586
 >> iter 77000, loss: 0.041248
 >> iter 78000, loss: 0.051009
 >> iter 79000, loss: 0.048733
 >> iter 80000, loss: 0.056685
   Number of active neurons: 2
 >> iter 81000, loss: 0.032564
 >> iter 82000, loss: 0.044317
 >> iter 83000, loss: 0.044535
 >> iter 84000, loss: 0.041581
 >> iter 85000, loss: 0.046014
 >> iter 86000, loss: 0.057821
 >> iter 87000, loss: 0.041861
 >> iter 88000, loss: 0.051572
 >> iter 89000, loss: 0.034588
 >> iter 90000, loss: 0.048913
   Number of active neurons: 2
 >> iter 91000, loss: 0.052186
 >> iter 92000, loss: 0.040888
 >> iter 93000, loss: 0.032255
 >> iter 94000, loss: 0.034743
 >> iter 95000, loss: 0.052473
 >> iter 96000, loss: 0.042021
 >> iter 97000, loss: 0.049584
 >> iter 98000, loss: 0.037515
 >> iter 99000, loss: 0.030705
 >> iter 100000, loss: 0.037550
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 14:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.602928
 >> iter 2000, loss: 4.477571
 >> iter 3000, loss: 1.725616
 >> iter 4000, loss: 0.693602
 >> iter 5000, loss: 0.299087
 >> iter 6000, loss: 0.148706
 >> iter 7000, loss: 0.107749
 >> iter 8000, loss: 0.063683
 >> iter 9000, loss: 0.071369
 >> iter 10000, loss: 0.060596
   Number of active neurons: 4
 >> iter 11000, loss: 0.077867
 >> iter 12000, loss: 0.064633
 >> iter 13000, loss: 0.056796
 >> iter 14000, loss: 0.066252
 >> iter 15000, loss: 0.052837
 >> iter 16000, loss: 0.041991
 >> iter 17000, loss: 0.047378
 >> iter 18000, loss: 0.057675
 >> iter 19000, loss: 0.073992
 >> iter 20000, loss: 0.059337
   Number of active neurons: 4
 >> iter 21000, loss: 0.058035
 >> iter 22000, loss: 0.043951
 >> iter 23000, loss: 0.042334
 >> iter 24000, loss: 0.046352
 >> iter 25000, loss: 0.050406
 >> iter 26000, loss: 0.048674
 >> iter 27000, loss: 0.053845
 >> iter 28000, loss: 0.041806
 >> iter 29000, loss: 0.045920
 >> iter 30000, loss: 0.033028
   Number of active neurons: 2
 >> iter 31000, loss: 0.046481
 >> iter 32000, loss: 0.069154
 >> iter 33000, loss: 0.062172
 >> iter 34000, loss: 0.040863
 >> iter 35000, loss: 0.043196
 >> iter 36000, loss: 0.043177
 >> iter 37000, loss: 0.038473
 >> iter 38000, loss: 0.039276
 >> iter 39000, loss: 0.047839
 >> iter 40000, loss: 0.053022
   Number of active neurons: 2
 >> iter 41000, loss: 0.070933
 >> iter 42000, loss: 0.063948
 >> iter 43000, loss: 0.042684
 >> iter 44000, loss: 0.038864
 >> iter 45000, loss: 0.031199
 >> iter 46000, loss: 0.038476
 >> iter 47000, loss: 0.059255
 >> iter 48000, loss: 0.051200
 >> iter 49000, loss: 0.032172
 >> iter 50000, loss: 0.046224
   Number of active neurons: 2
 >> iter 51000, loss: 0.050579
 >> iter 52000, loss: 0.047549
 >> iter 53000, loss: 0.033369
 >> iter 54000, loss: 0.039225
 >> iter 55000, loss: 0.032530
 >> iter 56000, loss: 0.058211
 >> iter 57000, loss: 0.058026
 >> iter 58000, loss: 0.051738
 >> iter 59000, loss: 0.051325
 >> iter 60000, loss: 0.051763
   Number of active neurons: 2
 >> iter 61000, loss: 0.036814
 >> iter 62000, loss: 0.041903
 >> iter 63000, loss: 0.039905
 >> iter 64000, loss: 0.044723
 >> iter 65000, loss: 0.036140
 >> iter 66000, loss: 0.029362
 >> iter 67000, loss: 0.054521
 >> iter 68000, loss: 0.048804
 >> iter 69000, loss: 0.054530
 >> iter 70000, loss: 0.062553
   Number of active neurons: 2
 >> iter 71000, loss: 0.046799
 >> iter 72000, loss: 0.069522
 >> iter 73000, loss: 0.052307
 >> iter 74000, loss: 0.034431
 >> iter 75000, loss: 0.060042
 >> iter 76000, loss: 0.060415
 >> iter 77000, loss: 0.059242
 >> iter 78000, loss: 0.039742
 >> iter 79000, loss: 0.038657
 >> iter 80000, loss: 0.039018
   Number of active neurons: 2
 >> iter 81000, loss: 0.050668
 >> iter 82000, loss: 0.040539
 >> iter 83000, loss: 0.040969
 >> iter 84000, loss: 0.037937
 >> iter 85000, loss: 0.035429
 >> iter 86000, loss: 0.044501
 >> iter 87000, loss: 0.048096
 >> iter 88000, loss: 0.039491
 >> iter 89000, loss: 0.057035
 >> iter 90000, loss: 0.045429
   Number of active neurons: 2
 >> iter 91000, loss: 0.048183
 >> iter 92000, loss: 0.044865
 >> iter 93000, loss: 0.060127
 >> iter 94000, loss: 0.041502
 >> iter 95000, loss: 0.035672
 >> iter 96000, loss: 0.031437
 >> iter 97000, loss: 0.036230
 >> iter 98000, loss: 0.032119
 >> iter 99000, loss: 0.029092
 >> iter 100000, loss: 0.034813
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 15:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455172
   Number of active neurons: 0
 >> iter 1000, loss: 11.376632
 >> iter 2000, loss: 4.339993
 >> iter 3000, loss: 1.674691
 >> iter 4000, loss: 0.667257
 >> iter 5000, loss: 0.295697
 >> iter 6000, loss: 0.151354
 >> iter 7000, loss: 0.097688
 >> iter 8000, loss: 0.062402
 >> iter 9000, loss: 0.075182
 >> iter 10000, loss: 0.048798
   Number of active neurons: 3
 >> iter 11000, loss: 0.047892
 >> iter 12000, loss: 0.045608
 >> iter 13000, loss: 0.067507
 >> iter 14000, loss: 0.062189
 >> iter 15000, loss: 0.061855
 >> iter 16000, loss: 0.043390
 >> iter 17000, loss: 0.053682
 >> iter 18000, loss: 0.060530
 >> iter 19000, loss: 0.048251
 >> iter 20000, loss: 0.061090
   Number of active neurons: 3
 >> iter 21000, loss: 0.050579
 >> iter 22000, loss: 0.043351
 >> iter 23000, loss: 0.057146
 >> iter 24000, loss: 0.043047
 >> iter 25000, loss: 0.035304
 >> iter 26000, loss: 0.042139
 >> iter 27000, loss: 0.040507
 >> iter 28000, loss: 0.033954
 >> iter 29000, loss: 0.041092
 >> iter 30000, loss: 0.046736
   Number of active neurons: 3
 >> iter 31000, loss: 0.038729
 >> iter 32000, loss: 0.055332
 >> iter 33000, loss: 0.040292
 >> iter 34000, loss: 0.036617
 >> iter 35000, loss: 0.038835
 >> iter 36000, loss: 0.054201
 >> iter 37000, loss: 0.046538
 >> iter 38000, loss: 0.045966
 >> iter 39000, loss: 0.050811
 >> iter 40000, loss: 0.036787
   Number of active neurons: 3
 >> iter 41000, loss: 0.046650
 >> iter 42000, loss: 0.059031
 >> iter 43000, loss: 0.041528
 >> iter 44000, loss: 0.040124
 >> iter 45000, loss: 0.044761
 >> iter 46000, loss: 0.043772
 >> iter 47000, loss: 0.044403
 >> iter 48000, loss: 0.039512
 >> iter 49000, loss: 0.051460
 >> iter 50000, loss: 0.038903
   Number of active neurons: 3
 >> iter 51000, loss: 0.043186
 >> iter 52000, loss: 0.033943
 >> iter 53000, loss: 0.066250
 >> iter 54000, loss: 0.046530
 >> iter 55000, loss: 0.048640
 >> iter 56000, loss: 0.057496
 >> iter 57000, loss: 0.055689
 >> iter 58000, loss: 0.040139
 >> iter 59000, loss: 0.050279
 >> iter 60000, loss: 0.055159
   Number of active neurons: 3
 >> iter 61000, loss: 0.043379
 >> iter 62000, loss: 0.039944
 >> iter 63000, loss: 0.051054
 >> iter 64000, loss: 0.038982
 >> iter 65000, loss: 0.053677
 >> iter 66000, loss: 0.046673
 >> iter 67000, loss: 0.043416
 >> iter 68000, loss: 0.066558
 >> iter 69000, loss: 0.059096
 >> iter 70000, loss: 0.039104
   Number of active neurons: 3
 >> iter 71000, loss: 0.034241
 >> iter 72000, loss: 0.055963
 >> iter 73000, loss: 0.045445
 >> iter 74000, loss: 0.048335
 >> iter 75000, loss: 0.040626
 >> iter 76000, loss: 0.046446
 >> iter 77000, loss: 0.074654
 >> iter 78000, loss: 0.045088
 >> iter 79000, loss: 0.039276
 >> iter 80000, loss: 0.038915
   Number of active neurons: 3
 >> iter 81000, loss: 0.039352
 >> iter 82000, loss: 0.042431
 >> iter 83000, loss: 0.057279
 >> iter 84000, loss: 0.073414
 >> iter 85000, loss: 0.045083
 >> iter 86000, loss: 0.062699
 >> iter 87000, loss: 0.041800
 >> iter 88000, loss: 0.042388
 >> iter 89000, loss: 0.037169
 >> iter 90000, loss: 0.036097
   Number of active neurons: 3
 >> iter 91000, loss: 0.050765
 >> iter 92000, loss: 0.050226
 >> iter 93000, loss: 0.068561
 >> iter 94000, loss: 0.048721
 >> iter 95000, loss: 0.050856
 >> iter 96000, loss: 0.072744
 >> iter 97000, loss: 0.080056
 >> iter 98000, loss: 0.056471
 >> iter 99000, loss: 0.056213
 >> iter 100000, loss: 0.046981
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 16:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.693160
 >> iter 2000, loss: 4.466211
 >> iter 3000, loss: 1.711966
 >> iter 4000, loss: 0.679256
 >> iter 5000, loss: 0.313179
 >> iter 6000, loss: 0.163058
 >> iter 7000, loss: 0.081442
 >> iter 8000, loss: 0.057715
 >> iter 9000, loss: 0.056192
 >> iter 10000, loss: 0.057922
   Number of active neurons: 3
 >> iter 11000, loss: 0.077997
 >> iter 12000, loss: 0.060809
 >> iter 13000, loss: 0.050672
 >> iter 14000, loss: 0.044574
 >> iter 15000, loss: 0.038558
 >> iter 16000, loss: 0.037411
 >> iter 17000, loss: 0.040102
 >> iter 18000, loss: 0.046587
 >> iter 19000, loss: 0.045713
 >> iter 20000, loss: 0.041760
   Number of active neurons: 3
 >> iter 21000, loss: 0.059459
 >> iter 22000, loss: 0.039986
 >> iter 23000, loss: 0.036980
 >> iter 24000, loss: 0.049594
 >> iter 25000, loss: 0.057267
 >> iter 26000, loss: 0.054228
 >> iter 27000, loss: 0.052322
 >> iter 28000, loss: 0.053848
 >> iter 29000, loss: 0.045747
 >> iter 30000, loss: 0.053691
   Number of active neurons: 3
 >> iter 31000, loss: 0.069361
 >> iter 32000, loss: 0.061795
 >> iter 33000, loss: 0.074798
 >> iter 34000, loss: 0.050214
 >> iter 35000, loss: 0.048911
 >> iter 36000, loss: 0.051066
 >> iter 37000, loss: 0.053129
 >> iter 38000, loss: 0.057194
 >> iter 39000, loss: 0.043167
 >> iter 40000, loss: 0.039067
   Number of active neurons: 3
 >> iter 41000, loss: 0.046732
 >> iter 42000, loss: 0.044817
 >> iter 43000, loss: 0.046554
 >> iter 44000, loss: 0.050288
 >> iter 45000, loss: 0.051175
 >> iter 46000, loss: 0.051194
 >> iter 47000, loss: 0.046428
 >> iter 48000, loss: 0.050181
 >> iter 49000, loss: 0.037221
 >> iter 50000, loss: 0.065138
   Number of active neurons: 3
 >> iter 51000, loss: 0.060087
 >> iter 52000, loss: 0.044729
 >> iter 53000, loss: 0.058946
 >> iter 54000, loss: 0.047523
 >> iter 55000, loss: 0.066281
 >> iter 56000, loss: 0.045747
 >> iter 57000, loss: 0.047581
 >> iter 58000, loss: 0.047145
 >> iter 59000, loss: 0.043172
 >> iter 60000, loss: 0.043095
   Number of active neurons: 3
 >> iter 61000, loss: 0.040146
 >> iter 62000, loss: 0.065592
 >> iter 63000, loss: 0.057008
 >> iter 64000, loss: 0.044115
 >> iter 65000, loss: 0.039548
 >> iter 66000, loss: 0.047154
 >> iter 67000, loss: 0.039485
 >> iter 68000, loss: 0.052126
 >> iter 69000, loss: 0.076134
 >> iter 70000, loss: 0.062562
   Number of active neurons: 3
 >> iter 71000, loss: 0.048390
 >> iter 72000, loss: 0.076321
 >> iter 73000, loss: 0.046010
 >> iter 74000, loss: 0.036290
 >> iter 75000, loss: 0.056852
 >> iter 76000, loss: 0.038550
 >> iter 77000, loss: 0.062082
 >> iter 78000, loss: 0.073178
 >> iter 79000, loss: 0.055020
 >> iter 80000, loss: 0.054032
   Number of active neurons: 3
 >> iter 81000, loss: 0.041977
 >> iter 82000, loss: 0.067985
 >> iter 83000, loss: 0.057893
 >> iter 84000, loss: 0.063396
 >> iter 85000, loss: 0.062096
 >> iter 86000, loss: 0.065702
 >> iter 87000, loss: 0.047713
 >> iter 88000, loss: 0.052434
 >> iter 89000, loss: 0.070733
 >> iter 90000, loss: 0.057668
   Number of active neurons: 3
 >> iter 91000, loss: 0.045281
 >> iter 92000, loss: 0.041456
 >> iter 93000, loss: 0.038570
 >> iter 94000, loss: 0.042259
 >> iter 95000, loss: 0.041924
 >> iter 96000, loss: 0.045300
 >> iter 97000, loss: 0.062687
 >> iter 98000, loss: 0.046287
 >> iter 99000, loss: 0.033820
 >> iter 100000, loss: 0.048449
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 17:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455167
   Number of active neurons: 0
 >> iter 1000, loss: 11.632222
 >> iter 2000, loss: 4.501005
 >> iter 3000, loss: 1.728842
 >> iter 4000, loss: 0.673204
 >> iter 5000, loss: 0.297185
 >> iter 6000, loss: 0.144585
 >> iter 7000, loss: 0.096594
 >> iter 8000, loss: 0.088789
 >> iter 9000, loss: 0.067357
 >> iter 10000, loss: 0.066556
   Number of active neurons: 3
 >> iter 11000, loss: 0.077329
 >> iter 12000, loss: 0.055648
 >> iter 13000, loss: 0.048458
 >> iter 14000, loss: 0.042861
 >> iter 15000, loss: 0.049234
 >> iter 16000, loss: 0.053421
 >> iter 17000, loss: 0.037761
 >> iter 18000, loss: 0.043239
 >> iter 19000, loss: 0.061998
 >> iter 20000, loss: 0.045602
   Number of active neurons: 2
 >> iter 21000, loss: 0.035046
 >> iter 22000, loss: 0.065440
 >> iter 23000, loss: 0.053982
 >> iter 24000, loss: 0.046066
 >> iter 25000, loss: 0.057161
 >> iter 26000, loss: 0.051209
 >> iter 27000, loss: 0.042304
 >> iter 28000, loss: 0.064762
 >> iter 29000, loss: 0.061955
 >> iter 30000, loss: 0.039971
   Number of active neurons: 2
 >> iter 31000, loss: 0.040980
 >> iter 32000, loss: 0.057088
 >> iter 33000, loss: 0.044167
 >> iter 34000, loss: 0.048318
 >> iter 35000, loss: 0.053062
 >> iter 36000, loss: 0.047439
 >> iter 37000, loss: 0.039894
 >> iter 38000, loss: 0.044250
 >> iter 39000, loss: 0.040152
 >> iter 40000, loss: 0.042838
   Number of active neurons: 2
 >> iter 41000, loss: 0.031254
 >> iter 42000, loss: 0.041657
 >> iter 43000, loss: 0.057433
 >> iter 44000, loss: 0.054582
 >> iter 45000, loss: 0.039082
 >> iter 46000, loss: 0.051677
 >> iter 47000, loss: 0.044274
 >> iter 48000, loss: 0.033391
 >> iter 49000, loss: 0.039248
 >> iter 50000, loss: 0.043357
   Number of active neurons: 2
 >> iter 51000, loss: 0.034732
 >> iter 52000, loss: 0.037905
 >> iter 53000, loss: 0.063173
 >> iter 54000, loss: 0.063014
 >> iter 55000, loss: 0.056634
 >> iter 56000, loss: 0.045693
 >> iter 57000, loss: 0.053111
 >> iter 58000, loss: 0.038573
 >> iter 59000, loss: 0.034486
 >> iter 60000, loss: 0.035617
   Number of active neurons: 2
 >> iter 61000, loss: 0.049666
 >> iter 62000, loss: 0.037637
 >> iter 63000, loss: 0.043987
 >> iter 64000, loss: 0.034144
 >> iter 65000, loss: 0.047913
 >> iter 66000, loss: 0.035192
 >> iter 67000, loss: 0.054298
 >> iter 68000, loss: 0.056655
 >> iter 69000, loss: 0.043151
 >> iter 70000, loss: 0.050944
   Number of active neurons: 2
 >> iter 71000, loss: 0.043649
 >> iter 72000, loss: 0.047563
 >> iter 73000, loss: 0.041717
 >> iter 74000, loss: 0.064152
 >> iter 75000, loss: 0.056320
 >> iter 76000, loss: 0.053886
 >> iter 77000, loss: 0.051038
 >> iter 78000, loss: 0.039769
 >> iter 79000, loss: 0.048354
 >> iter 80000, loss: 0.050388
   Number of active neurons: 2
 >> iter 81000, loss: 0.042801
 >> iter 82000, loss: 0.040131
 >> iter 83000, loss: 0.042443
 >> iter 84000, loss: 0.044787
 >> iter 85000, loss: 0.042191
 >> iter 86000, loss: 0.038151
 >> iter 87000, loss: 0.045060
 >> iter 88000, loss: 0.047390
 >> iter 89000, loss: 0.042399
 >> iter 90000, loss: 0.042609
   Number of active neurons: 2
 >> iter 91000, loss: 0.035368
 >> iter 92000, loss: 0.047750
 >> iter 93000, loss: 0.042584
 >> iter 94000, loss: 0.037724
 >> iter 95000, loss: 0.060424
 >> iter 96000, loss: 0.054229
 >> iter 97000, loss: 0.060726
 >> iter 98000, loss: 0.050371
 >> iter 99000, loss: 0.056043
 >> iter 100000, loss: 0.056620
   Number of active neurons: 2
 ----------- DONE -----------

 > Ejecucion 18:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0
data INPUT has 50001 characters, 3 unique.
data OUTPUT has 50001 characters, 2 unique.
Función de activación: TANH
 > Entrenando...
 >> iter 0, loss: 27.455171
   Number of active neurons: 0
 >> iter 1000, loss: 11.384911
 >> iter 2000, loss: 4.326453
 >> iter 3000, loss: 1.665615
 >> iter 4000, loss: 0.673133
 >> iter 5000, loss: 0.300858
 >> iter 6000, loss: 0.150525
 >> iter 7000, loss: 0.095070
 >> iter 8000, loss: 0.088303
 >> iter 9000, loss: 0.075527
 >> iter 10000, loss: 0.074113
   Number of active neurons: 4
 >> iter 11000, loss: 0.070953
 >> iter 12000, loss: 0.074402
 >> iter 13000, loss: 0.074982
 >> iter 14000, loss: 0.071718
 >> iter 15000, loss: 0.053946
 >> iter 16000, loss: 0.047070
 >> iter 17000, loss: 0.058622
 >> iter 18000, loss: 0.051144
 >> iter 19000, loss: 0.050161
 >> iter 20000, loss: 0.048700
   Number of active neurons: 4
 >> iter 21000, loss: 0.050176
 >> iter 22000, loss: 0.049084
 >> iter 23000, loss: 0.048506
 >> iter 24000, loss: 0.044467
 >> iter 25000, loss: 0.050357
 >> iter 26000, loss: 0.049502
 >> iter 27000, loss: 0.041702
 >> iter 28000, loss: 0.062197
 >> iter 29000, loss: 0.075974
 >> iter 30000, loss: 0.069271
   Number of active neurons: 4
 >> iter 31000, loss: 0.048921
 >> iter 32000, loss: 0.053054
 >> iter 33000, loss: 0.042309
 >> iter 34000, loss: 0.062109
 >> iter 35000, loss: 0.061804
 >> iter 36000, loss: 0.049851
 >> iter 37000, loss: 0.042586
 >> iter 38000, loss: 0.052070
 >> iter 39000, loss: 0.046418
 >> iter 40000, loss: 0.045057
   Number of active neurons: 3
 >> iter 41000, loss: 0.043832
 >> iter 42000, loss: 0.045831
 >> iter 43000, loss: 0.043317
 >> iter 44000, loss: 0.057149
 >> iter 45000, loss: 0.057665
 >> iter 46000, loss: 0.072467
 >> iter 47000, loss: 0.054790
 >> iter 48000, loss: 0.047551
 >> iter 49000, loss: 0.041745
 >> iter 50000, loss: 0.035579
   Number of active neurons: 3
 >> iter 51000, loss: 0.053722
 >> iter 52000, loss: 0.041072
 >> iter 53000, loss: 0.048677
 >> iter 54000, loss: 0.063639
 >> iter 55000, loss: 0.044081
 >> iter 56000, loss: 0.041792
 >> iter 57000, loss: 0.035977
 >> iter 58000, loss: 0.054015
 >> iter 59000, loss: 0.038517
 >> iter 60000, loss: 0.028551
   Number of active neurons: 3
 >> iter 61000, loss: 0.038553
 >> iter 62000, loss: 0.033978
 >> iter 63000, loss: 0.030435
 >> iter 64000, loss: 0.027795
 >> iter 65000, loss: 0.045206
 >> iter 66000, loss: 0.047775
 >> iter 67000, loss: 0.040388
 >> iter 68000, loss: 0.036597
 >> iter 69000, loss: 0.069312
 >> iter 70000, loss: 0.053042
   Number of active neurons: 3
 >> iter 71000, loss: 0.048192
 >> iter 72000, loss: 0.039531
 >> iter 73000, loss: 0.044284
 >> iter 74000, loss: 0.044400
 >> iter 75000, loss: 0.052263
 >> iter 76000, loss: 0.050291
 >> iter 77000, loss: 0.041199
 >> iter 78000, loss: 0.043001
 >> iter 79000, loss: 0.043595
 >> iter 80000, loss: 0.051866
   Number of active neurons: 3
 >> iter 81000, loss: 0.036735
 >> iter 82000, loss: 0.031271
 >> iter 83000, loss: 0.068799
 >> iter 84000, loss: 0.054576
 >> iter 85000, loss: 0.067407
 >> iter 86000, loss: 0.042434
 >> iter 87000, loss: 0.043713
 >> iter 88000, loss: 0.053247
 >> iter 89000, loss: 0.061476
 >> iter 90000, loss: 0.038124
   Number of active neurons: 3
 >> iter 91000, loss: 0.054725
 >> iter 92000, loss: 0.042885
 >> iter 93000, loss: 0.046583
 >> iter 94000, loss: 0.037412
 >> iter 95000, loss: 0.039475
 >> iter 96000, loss: 0.051083
 >> iter 97000, loss: 0.039243
 >> iter 98000, loss: 0.035978
 >> iter 99000, loss: 0.039387
 >> iter 100000, loss: 0.050964
   Number of active neurons: 3
 ----------- DONE -----------

 > Ejecucion 19:
   - Train: 0.0
   - Test - Long: 0.0
   - Test - Big: 0.0
   - Test - A: 0.0
   - Test - B: 0.0

 > Terminadas 20 ejecuciones...

---------------------------------------- TERMINADO OK ----------------------------------------

